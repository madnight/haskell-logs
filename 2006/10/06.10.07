00:00:02 <lispy> it's not like you can write a program that looks at an element and see it as not yet constructed
00:00:28 <lispy> as soon as you 'demand' an elemnt of the array it will get constructed...even if that means others have to be constructed so that one can be built
00:09:54 <jajs> "Haskell : Computing on demand" will IBM hire the Simons :> ?
00:14:12 <dons> ?users #haskell
00:14:13 <lambdabot> Maximum users seen in #haskell: 250, currently: 217 (86.8%), active: 14 (6.5%)
00:14:18 <dons> whoa!
00:14:21 <dons> we hit a new record last night
00:17:24 <lispy> nice
00:17:52 <lispy> jajs: as usual MS already beat IBM to it :)
00:18:19 <lispy> well, i can almost get the OOHaskell example to compile
00:18:30 <lispy> and we have Data.HList now :)
00:18:38 * lispy plans to send in some darcs patches for that
00:18:42 <dons> ?seen lambdabot
00:18:42 <lambdabot> Yes, I'm here. I'm in #ScannedInAvian, #perl6, #oasis, #darcs, #ghc, #gentoo-haskell, #haskell_ru, #haskell.es, #haskell.se, #haskell.it, #haskell-overflow, #haskell-blah and #haskell
00:19:03 <weitzman> ScannedInAvian?...
00:19:31 <dons> not sure how active that is atm
00:19:38 <weitzman> Looks very sparse
00:19:40 <dons> ?users #ScannedInAvian
00:19:40 <lambdabot> Maximum users seen in #ScannedInAvian: 5, currently: 3 (60.0%), active: 0 (0.0%)
00:19:45 <dons> ?users #perl6
00:19:45 <lambdabot> Maximum users seen in #perl6: 148, currently: 125 (84.5%), active: 1 (0.8%)
00:29:41 * lispy grumbles at the type errors
00:31:22 <lokadin> dai(empathy)
00:55:29 <skew> quit
01:05:23 <lispy> skew: sorry!
01:05:35 <lispy> hey, i get mentoined on hwn and i had no clue
01:13:37 <usux> hi haskell is dumb
01:14:00 <basti_> lol
01:15:15 <weitzman> @protontorpedo
01:15:16 <lambdabot> why haskell over say smalltalk
01:21:36 <basti_> lol
01:21:39 <basti_> what was this?
01:30:37 <Heffalump> dons: fixed
01:35:15 <lispy> heh, this rectangle constructor in OOHaskell has a longer type signature than the code
02:22:35 <musasabi> morning
03:18:59 <Phillemann> There seems to be no select for synchronous I/O multiplexing available in Haskell. I'd like to execute an operation every 5 seconds an simultaneously wait for socket actions.
03:19:09 <Phillemann> +d
03:24:09 <int-e> use forkIO.
03:24:50 <dons> ?docs Control.Concurrent
03:24:51 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Control-Concurrent.html
03:25:03 <dons> you're looking for threadDelay and forkIO
03:25:22 <Phillemann> Is that a solution where you start a new thread?
03:25:42 <dons> forkIO, yes. a "micro" haskell thread, layered over select
03:26:00 <Phillemann> o_PO
03:26:12 <Phillemann> I'll try to understand it. ;)
03:26:14 <dons> so fork a thread to sleep for 5 seconds, and do whatever it does, whlie the main thread reads from a socket
03:27:07 <Phillemann> dons: That seems a bit like a hack. Using select you can usually avoid using threads (because then you have to watch out for race conditions, synchronization and stuff).
03:27:26 <dons> its pretty easy with forkIO. try it. your problem is about 2 lines of code
03:27:29 <int-e> the RTS uses select for this.
03:28:23 <Phillemann> "Scheduling of Haskell threads is done internally in the Haskell runtime system, and doesn't make use of any operating system-supplied thread packages." - Ah, so those are not "real" threads?
03:28:40 <int-e> Threads are just an abstraction that allows the RTS to collect all the fds that it should wait on using select.
03:28:59 <dons> e.g.
03:29:01 <dons> main = do forkIO sleeper; reader
03:29:01 <dons> reader  = forever $ hGetLine socket >>= print
03:29:01 <dons> sleeper = forever $ threadDelay 5 seconds >> some action
03:29:02 <dons> forever a = a >> forever a
03:29:15 <int-e> forkIO creates a lightweight Haskell thread. forkOS creates an Operating system thread (like clone() and friends)
03:30:09 <dons> and compile with -threaded so IO won't block all threads
03:30:12 <Phillemann> dons: Wow, looks nice and short. :)
03:30:26 <Phillemann> So thanks dons and int-e.
03:30:37 <dons> "20:27  dons> its pretty easy with forkIO. try it." ;)
03:31:07 <dons> a good concurrent haskell tutorial is the "Tackling the Awkward Squad" paper
03:31:08 <Phillemann> dons: Just wanted to find out if that's really what I want.
03:31:20 <dons> :)
03:33:14 <dons> forkIO is truly one of the joys of haskell programming
03:33:37 <dons> you can toss around threads like candy
03:33:38 <int-e> I love MVars.
03:34:24 <dons> yeah, all the concurrency stuff I learnt as an undergrad obsolete with one little primitive :)
03:34:56 <dons> Phillemann: let us know how you go with the threaded solution
03:35:26 <int-e> The Haskell RTS feels like a microkernel.
03:35:30 <int-e> it's fun.
03:35:30 <dons> you know lambdabot forks a thread on every line of input ... :)
03:35:31 <jajs> with forkIO and Channels, haskell sounds like a static Erlang :-)
03:36:05 <int-e> I was vaguely aware of that.
03:36:29 <int-e> You handle time limits that way.
03:37:06 <dons> ah, this is what I was looking for, http://shootout.alioth.debian.org/gp4/benchmark.php?test=chameneos&lang=all
03:37:09 <lambdabot> Title: chameneos benchmark | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Computer Languag ..., http://tinyurl.com/lrhoa
03:37:13 <dons> poor erlang :)
03:37:53 <dons> they just pip us here though, http://shootout.alioth.debian.org/gp4/benchmark.php?test=message&lang=all
03:37:55 <lambdabot> Title: cheap-concurrency benchmark | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Computer ..., http://tinyurl.com/njtgc
03:38:35 <Phillemann> dons: I'm just trying to create a small irc quizbot in Haskell and have to learn all the deep underlying concepts of the language. It's a steep learning curve. ;)
03:38:51 <dons> hehe. and you're reading the tutbot tutorial?
03:39:04 <dons> yeah, you're getting 20 years of language research in 2 days...
03:39:17 <dons> but its good for you :)
03:39:37 <Phillemann> dons: I did and then digressed into some monad tutorials. It's all spinning in my head. :)
03:39:56 <dons> i started turning the tutbot into a multithreaded irc client
03:39:59 <dons> let me find it for you
03:40:01 <psi> the erlang source does say "contributed by (some name) (erlang novice)" :)
03:40:22 <dons> http://www.cse.unsw.edu.au/~dons/code/irchin/irchin.hs
03:40:23 <lambdabot> http://tinyurl.com/gfhpm
03:40:25 <int-e> hmm, that wants a takeAndPutMVar :)
03:40:55 <Phillemann> dons: Thanks, I'll take a look at that, too.
03:41:02 <dons> Phillemann: note how it forksIO's a reader thread that takes commands from stdin
03:42:31 <int-e> takeAndPutMVar is silly. But putAndTakeMVar writevar readvar val :: MVar a -> MVar b -> a -> IO b  could perhaps help request-handling code, and also this example. The idea is that the thread can be suspended immediately, waiting for the next request.
03:42:41 <dons> psi, that's Isaac. he's the guy who runs the shootout on that box :)
03:42:49 <psi> hugs doesn't seem to have System.Console.Readline :(
03:42:52 <dons> so a famous erlang novice :)
03:42:56 <psi> ah :)
03:44:34 <flipdons> multithreaded irc clients with forkIO. yay!
03:45:05 <dcoutts> heh
03:45:06 <Heffalump> it's a shame we can't get lambdabot to fork himself with @eval ;-)
03:45:14 <flipdons> hehe
03:45:21 <resiak> Isn't lambdabot female?
03:45:27 <dcoutts> yep
03:45:35 <dcoutts> just ask @vixen
03:45:40 * resiak wonders where dcoutts went to evade freshers
03:45:43 <ulfdoz> Its name sounds more like a shemale. ;)
03:45:56 <flipdons> @vixen you're female, right?
03:45:57 <lambdabot> of course i'm female
03:46:25 <dcoutts> resiak, some middle-aged pub :-)
03:46:28 <dons> irc clients are fun.
03:46:33 <resiak> dcoutts: heh.
03:47:00 <Heffalump> I'm sure lambdabot used to be male.
03:47:07 <int-e> > reverse . take 23 . cycle "male"
03:47:09 <lambdabot>    Expecting a function type, but found `[a]'
03:47:09 <lambdabot>    Expected type: a1 -> [a...
03:47:13 <dons> $
03:47:14 <int-e> > reverse . take 23 . cycle $ "male"
03:47:16 <lambdabot>  "lamelamelamelamelamelam"
03:47:21 <Heffalump> @vixen you're male, right?
03:47:22 <lambdabot> correct
03:47:25 <Heffalump> see?
03:47:27 <dcoutts> hah hah
03:47:28 <dons> yikes
03:49:18 <dons> ?users #haskell
03:49:21 <lambdabot> Maximum users seen in #haskell: 250, currently: 218 (87.2%), active: 17 (7.8%)
03:49:26 <dons> we reached a new milestone last night
03:56:22 <andrea> hi! is there any hscurses expert listening?
03:58:29 <psi_> *test*
03:58:57 <ValarQ> psi_: *chirp*
03:59:20 <psi_> dons: the client wouldn't work under hugs. it stopped after Connecting ... done.
04:00:26 <psi_> /me pinches ValarQ
04:05:15 <dons> i've not tested under hugs, with the forkIO stuff. thanks.
04:12:02 <wilx> .
04:12:51 <dons> '
04:16:19 <psi> that confused me for a while :D
04:18:35 <psi> oh! _two_ episodes of BSG were released last night. /me downloads.
04:19:03 <dons> mmm!
05:12:18 <xah`> wee http://www.flickr.com/photos/pankaj/199566322/
05:12:22 <lambdabot> Title: haskell logo on Flickr - Photo Sharing!, http://tinyurl.com/hffpn
05:13:04 <xah`> and don't forget http://xahlee.org/haskell/haskell-logo.html
05:13:06 <lambdabot> Title: Xah: A Haskell A Day: Haskell Logo
05:13:07 <Phillemann> dons: This "Taking the Awkward Squad" seems to constitute a very good introduction to Haskell's monad system.
05:18:02 <Syzygy-> Taking the awkward squad?
05:18:32 <dons> Tackling.
05:18:50 <Phillemann> Eh...yes.
05:19:02 <Phillemann> Didn't take the time to look it up. ;)
05:19:17 <dons> yeah, its a great intro paper
05:31:08 <araujo> morning!
05:37:53 <phr-newbie> morn
05:38:01 <phr-newbie> -- compute sum (map sqrt [1..n]) using tail recursion
05:38:01 <phr-newbie> ssqrt n = ssqrt' 0 n where
05:38:01 <phr-newbie>   ssqrt' acc 0 = acc
05:38:01 <phr-newbie>   ssqrt' acc n = ssqrt' (acc + sqrt n) (n-1)
05:38:09 <phr-newbie> any idea why that blows out the gc?
05:38:48 <dons> its not tail recursive
05:38:51 <phr-newbie> it's not?
05:39:06 <phr-newbie> hmm
05:39:07 <dons> oh, sorry, ssqrt /= sqrt :}
05:39:48 * dons pokes around a bit at the code
05:39:58 <Igloo> You want to force the (acc + sqrt n) probably
05:40:27 <phr-newbie> uh, how?
05:40:30 <dons> yeah
05:40:48 <Igloo> let x = acc + sqrt n in x `seq` ssqrt' x (n-1)
05:41:29 <dons> what kind of input were you giving it, btw?
05:41:40 <phr-newbie> Main> ssqrt 1000000
05:41:40 <phr-newbie> ERROR - Garbage collection fails to reclaim sufficient space
05:41:44 <phr-newbie> it does 10000 ok
05:42:03 <dons> oh, hugs?
05:42:07 <phr-newbie> yeah
05:42:24 <phr-newbie> i still haven't installed ghc
05:42:40 <yip> > ssqrt 10000
05:42:41 <lambdabot>  Not in scope: `ssqrt'
05:42:48 <yip> @hoogle ssqrt
05:42:49 <lambdabot> No matches found
05:43:06 <phr-newbie> yip scroll back a little
05:43:34 <int-e> > let ssqrt n = ssqrt' 0 n where ssqrt' acc 0 = acc; ssqrt' acc n = ssqrt' (acc + sqrt n) (n-1) in ssqrt 1000
05:43:36 <lambdabot>  21097.45588748073
05:43:37 <dons> this seems to run in constant space,
05:43:39 <dons> ssqrt n = ssqrt' 0 n
05:43:39 <dons>     where ssqrt'  acc  0 = acc
05:43:39 <phr-newbie> does ghc handle stuff like this better?
05:43:40 <dons>           ssqrt'  acc  n = acc `seq` ssqrt' (acc + sqrt n) (n-1
05:44:08 <dons> but yeah, just a typical space leak
05:44:21 <dons> you're making a recursive call with two unevaluated arguments
05:44:28 <dons> so that's going to build a big chain of 'thunks'
05:44:30 <int-e> ghc is more or less forbidden to strictify the accumulator.
05:44:58 <dons> so the simple solution is to tell the compiler to evaluate the accumulator strictly
05:45:01 <int-e> it can only do that if the operations involved are all safe.
05:45:10 <dons> with ghc 6.6 you'd write: ssqrt' !acc n = ssqrt' (acc + sqrt n) (n-1
05:45:13 <dons> which is nicer
05:45:14 <int-e> and sqrt isn't safe :/
05:45:39 <int-e> (and the compiler's knowledge about what's safe *and* cheap is rather limited, too)
05:45:49 <phr-newbie> what's safe?
05:46:06 <int-e> can't result in bottom; can't produce errors.
05:46:22 <int-e> (I'm not sure if that's standard terminology, probably not.)
05:46:37 <Syzygy-> On my ghc, the code that int-e used works fine up to a stack overflow somewhere just under 100000
05:46:45 <Syzygy-> (i.e. 10000 works fine, 100000 doesn't)
05:46:53 <int-e> Syzygy-: that was just the original version on one line.
05:47:02 <dons> phr-newbie: so yeah, acc `seq` ssqrt' (acc + sqrt n) ... is enough for it work hugs. tested with 1000000
05:47:13 <dons> though hugs is a bit slow for this kind of thing.
05:47:13 <Syzygy-> int-e: I didn't get far enough to actually compare. :)
05:47:48 <phr-newbie> :hoogle seq
05:47:48 <int-e> > foldl' (+) 0 [sqrt n | n <- [0..100000]] -- slightly different rounding behaviour
05:47:51 <lambdabot>  2.1082008973917928e7
05:48:05 <dons> ?hoogle seq
05:48:06 <lambdabot> Prelude.seq :: a -> b -> b
05:48:06 <lambdabot> Prelude.sequence :: Monad m => [m a] -> m [a]
05:48:06 <lambdabot> Prelude.sequence_ :: Monad m => [m a] -> m ()
05:48:10 <phr-newbie> oops
05:48:14 <dons> strictly evaluates its first argument, returning the second
05:48:55 <dolio> > foldl' (+) 0 [sqrt n | n <- reverse [0..100000]]
05:48:57 <lambdabot>  2.108200897391742e7
05:49:33 <int-e> dolio: ouch :) use [100000,99999..0] instead.
05:49:44 <dolio> :)
05:49:59 <dons> phr-newbie: got it working?
05:50:11 <phr-newbie> i'm still staring at your example
05:50:38 <dons> this code:
05:50:39 <dons> ssqrt n = ssqrt' 0 n
05:50:39 <dons>     where ssqrt'  acc  0 = acc
05:50:40 <dons>           ssqrt'  acc  n = acc `seq` ssqrt' (acc + sqrt n) (n-1)
05:50:48 <dons> just your code, with the acc strictly evaluated
05:50:51 <phr-newbie> trying it
05:51:20 <phr-newbie> running slow :)
05:51:29 <phr-newbie> seems to run slower on smaller cases too
05:51:32 <phr-newbie> but yeah it works
05:51:42 <phr-newbie> Main> ssqrt 1000000
05:51:42 <phr-newbie> 666667166.458801
05:52:21 <dons> try ghc if you care about speed :)
05:52:41 <Syzygy-> Can I get ghci to time an execution?
05:52:46 <phr-newbie> sum $ map sqrt [1..1000000] is a lot faster  :)
05:52:56 <int-e> > let merge [a] = a; merge as = merge (merge' as); merge' (a:b:bs) = let s = a+b in s `seq` s : merge' bs; merge' bs = bs in merge [sqrt n | n <- reverse [0..100000]]
05:52:58 <lambdabot>  2.108200897391774e7
05:53:12 <phr-newbie> ?????
05:53:37 <int-e> just trying to get more precise answers.
05:53:57 <dons> _.-+'
05:54:59 <phr-newbie> i think i understand, you strictly evaluated acc because it was deferred from a previous call and it would have gotten wrapped in another thunk without the seq
05:55:09 <int-e> Floating point arithmetic doesn't behave nicely when you add numbers of vastly different size, so this code combines the numbers in pairs to reduce that effect.
05:55:54 <dons> phr-newbie: right.
05:56:20 <dolio> Making n strict as well might make things a little faster.
05:56:35 <dolio> Unless that's done automatically.
05:56:40 <int-e> but ghc should be clever enough to do that itself.
05:56:54 <dolio> What about hugs? Isn't that what he's using?
05:56:59 <int-e> because the recursive call compares n to 0 - which means it can be safely made strict.
05:57:06 <int-e> I don't know about hugs.
05:57:30 <int-e> but adding seq probably won't make things run faster.
05:57:45 <int-e> for n
05:57:56 <dons> phr-newbie: so rather than form a big chain of: (((sqrt 1...) + sqrt (n-1)) + sqrt n), you evaluate each sqrt, before recursing
05:58:23 <phr-newbie> yeah, this is messy, it would be great if the compiler could flag things like that
05:59:11 <dons> they're pretty obvious though. either space is really bad, or it runs in constant space. and the place to look for them is recursive calls. so in general not a problem.
05:59:15 <dons> once you know what you're looking for
05:59:53 <dons> its also nicer with the bang pattern syntax:           ssqrt' !acc  n = ssqrt' (acc + sqrt n) (n-1)
06:00:05 <phr-newbie> that's a ghc6 extension?
06:00:08 <dons> yep
06:00:33 <phr-newbie> is there going to be haskell 08 or anything like that?  post-98
06:00:42 <dons> yeah, haskell'
06:00:47 <phr-newbie> heh
06:00:58 <dons> ?where haskell-prime
06:00:59 <lambdabot> http://hackage.haskell.org/trac/haskell-prime
06:01:55 <sylvan> Hopefully it won't get called haskell' in the end though... A lot of people wouldn'
06:02:00 <sylvan> t get it
06:02:02 <dons> hehe
06:02:33 <sylvan> And also: "haskell''s type system is nice" looks weird
06:02:59 <dolio> It's a better codename than C++ 0x, or whatever. :)
06:09:35 <lisppaste2> hn pasted "Types" at http://paste.lisp.org/display/27543
06:11:20 <hn> anyone active?
06:12:22 <phr-newbie> morn
06:13:53 <hn> not a lot of people typing anything here today?
06:17:02 <phr-newbie> there were earlier, i looked at your paste but dunno what to make of it,
06:17:12 <phr-newbie> i'm not up on this stuff yet
06:17:45 <hn> okey
06:18:11 <hn> thanks anyway :)
06:18:42 <twanvl> hn: what is your question/problem/error?
06:18:46 <hn> this channel use to be more active
06:19:02 <hn> i got an error, but just solved the problem
06:19:12 <Philippa_> for the majority of haskell users it's the morning or close to on a saturday
06:19:18 <Philippa_> lack of activity is thus unsurprising...
06:19:21 <hn> some type erro
06:20:12 <hn> aha okey! yeah, for me its noon now..
06:25:18 <Philippa_> it's gone 2pm in the UK, but that's still a bit early to expect many people to actually pay attention :-)
06:35:18 <dcoutts> dons, I was just reading the 1995 Haskell Workshop proceedings. There's a paper on the design of the standard libs. It talks about PackedStrings and the overhead of String. :-)
06:35:30 <dcoutts> so we're only 10 years late
06:35:56 <dons> hehe
06:37:40 <integral> hmm
06:38:40 <dcoutts> it says "This module is based on the PackedString module distributed with GHC."
06:38:49 <dcoutts> the same one that just got deprecated
06:39:00 <Philippa_> heh
06:39:01 <Philippa_> that figures
06:39:17 <dons> 10 years was too long
06:39:21 <dcoutts> aye
06:39:31 <dons> too many papers, not enough code
06:39:50 <dcoutts> @remember dons too many papers, not enough code
06:39:58 <dons> heh
06:40:00 <Syzygy-> Hehe
06:40:26 <dcoutts> does lambdabot not confirm remembered quotes ?
06:40:33 <int-e> not anymore.
06:40:37 <dcoutts> oh ok
06:40:41 <dons> right. it just remembers them now.
06:40:46 <ndm> if PackedString has been depreciated, does that mean it will be gone by 6.8?
06:40:47 <int-e> dons removed all sorts of acknowledgements.
06:41:01 <dcoutts> ndm, no, it'll have a totalyl new api and implementation
06:41:19 <Igloo> Why do you ask, ndm?
06:41:20 <ndm> dcoutts, the totally new API sounds like a "yes" to me
06:41:22 <dons> though there's not much point using it. [Char] is better time wise, if you need unicode
06:41:37 <dons> ndm. heh.
06:41:41 <ndm> Igloo: Yhc still uses it heavily, and nhc, and they're a pain to touch
06:41:49 <dons> new api, new module name, new code. same packed string!
06:42:10 <int-e> so will ghc use bytestring now?
06:42:14 <dcoutts> I think the plan is to implement Data.PackedString based on a one of UTF 8/16/32 using ByteString style techniques
06:42:46 <dcoutts> hopefully with the same api as Data.ByteString.[Lazy].Char8
06:42:47 <ndm> keeping the existing API and semantics?
06:42:57 <ndm> ah, now thats still not keeping it
06:43:02 <dons> probably not. it uses the old fooPS style
06:43:18 <ndm> in that case how long will the existing interface hang round?
06:43:25 <dcoutts> ndm, 'til 6.8
06:43:45 <ndm> i.e. it will be in 6.8, or it won't?
06:43:49 <dcoutts> and in the mean time it'll generate deprecation warnings
06:43:53 <dons> well, its not ike it will be removed from the universe. it would also function as a standalone module to drop into nhc/yhc
06:43:54 <dcoutts> ndm, it will not
06:44:00 <dcoutts> because it'll be replaced
06:44:04 <ndm> hmm, that kind of sucks...
06:44:06 <dons> though its just a little scary nhc would use Data.PackedString...
06:44:22 <ndm> FiniteMap bit the dust a bit too quickly for my liking, and PackedString ditto
06:44:24 <ndm> why?
06:44:41 <dons> its got really poor performance. i'd not want to base my compiler on it
06:44:49 <ndm> we survive :)
06:45:04 <ndm> it sadly means though that we'll have to upgrade before 6.8 is out
06:45:19 <ndm> which means Yhc will _only_ compile with GHC 6.6, no versions other than that
06:45:24 <dons>                           FPS7       SPS     PS      [a]
06:45:26 <ndm> which isn't a great compatability advert
06:45:32 <dons> drop                      0.000      0.000   11.768  0.130
06:45:33 <dons> takeWhile                 0.000      1.498   0.000   0.000
06:45:33 <dons> dropWhile                 0.000      1.985   8.447   0.130
06:45:33 <dons> span                      0.000      9.289   11.144  0.131
06:45:33 <dons> break                     0.000      9.383   11.268  0.133
06:45:40 <dons> PS == PackedString
06:45:48 <dcoutts> ndm, you can still use it, it'll just generate warnings
06:45:57 <int-e> and SPS?
06:45:58 <dcoutts> so no need to depend on 6.6
06:46:08 <ndm> dcoutts, yes, but once 6.8 comes out, we'll have to flip "overnight", which is not doable
06:46:12 <dons> that's a temporary fork of PS that Simon MArlow was working on
06:46:18 <ndm> so we'll have to upgrade during the 6.6 cycle
06:46:27 <dcoutts> ndm, you can provide a compat thing that does fooPS = PS.foo
06:46:38 <ndm> yay, compatability gunk :)
06:46:46 <dons> yeah, audreyt has one of those around somewhere already
06:46:52 <dcoutts> ndm, or switch to String
06:47:03 <ndm> i'm not writing a compatability layer with conditional inclusions, preprocessor junk which will only last for 0.2 releases
06:47:07 <dons> reverse                   0.024      12.997  13.018  1.622
06:47:07 <dons> concat                    0.000      12.701  11.459  1.163
06:47:07 <dons> cons                      0.016      2.064   8.358   0.131
06:47:14 <ndm> easier to switch straight to fps
06:47:26 <dcoutts> ndm, if you need unicode...
06:47:28 <ndm> and its not that easy, since we use Reverse-Packed-Strings
06:47:30 <ndm> we don't
06:47:39 <ndm> i only speak english :)
06:47:41 <dons> tail                      0.000      0.000   14.490  0.130  !!
06:47:59 <dons> no O(1) substrings on PackedString
06:48:00 <int-e> oh, copying bites.
06:48:25 <dcoutts> ndm, reverse packed string?
06:48:34 <dons> and that's an old version of fps its measured against too. i should run against the stream fused version sometime
06:49:00 <int-e> where's the point - the numbers are almost all 0.000 already ;)
06:49:02 <ndm> dcoutts, yes :)
06:49:08 <dons> int-e: heh
06:49:23 <dcoutts> ndm, what is that and why?
06:49:27 <ndm> edulerP.lanretnI.chY
06:49:33 <dons> yeah, the imiting factor was the PackedString couldn't handle input bigger than 5M
06:49:35 <ndm> dcoutts, really, no idea :)
06:49:42 <dons> which is too small to get meaningful info from FPS.
06:49:55 <int-e> hmm, due to all the copying?
06:50:15 <ndm> dcoutts, something about appending to the head or tail being cheaper and the interaction with the parser
06:50:32 <dons> it uses hGetBuf and some nasty thing causing a stack overflow if you try to pull in a larger array
06:50:46 <dcoutts> ndm, appending/prepending to a PackedString is always slow.
06:51:07 <int-e> use a lazy bytestring :)
06:51:13 <ndm> dcoutts, one is cheaper, not sure which one
06:51:19 <dcoutts> or a StringBuilder
06:51:25 <dons> yeah
06:51:33 <dcoutts> ndm, that's odd, both involve copying the whole thing
06:51:48 <int-e> prepending a short chunk to a lazy bytestring should be very cheap indeed.
06:51:50 <dcoutts> dons, for ByteString, cons and snoc are the same cost right?
06:51:59 <dons> yep
06:52:00 <dcoutts> for strict, that is
06:52:01 <int-e> because it's basically a list of string chunks :)
06:52:17 <dons>         memcpy p (f `plusPtr` s) (fromIntegral l)
06:52:17 <dons>         poke (p `plusPtr` l) c
06:52:18 <dons> versus
06:52:22 <dons>         poke p c
06:52:22 <dons>         memcpy (p `plusPtr` 1) (f `plusPtr` s) (fromIntegral l)
06:52:24 <dons> :)
06:52:27 <dcoutts> right :-)
06:52:29 <ndm> dcoutts, alegedly one is cheaper, that may or may not be actually true, but its what i was told was the reason
06:53:16 <dcoutts> methinks that decision could be revisited
06:53:35 <int-e> ah, LPS cons builds chunks of length 16. .. uh, of length 17 actually.
06:53:43 <int-e> that's an odd size.
06:54:08 <dons> talk to dcoutts about that
06:54:25 <dcoutts> int-e, 17?
06:54:35 <dons> I think we measured this at some point
06:54:38 <int-e> dcoutts: cons c (LPS (s:ss)) | P.length s <= 16 = LPS (P.cons c s : ss)
06:54:39 <dmhouse> Isn't it meant to be optimised to the size of the L1 cache?
06:54:40 <dons> cons :: Word8 -> ByteString -> ByteString
06:54:41 <dons> cons c (LPS (s:ss)) | P.length s <= 16 = LPS (P.cons c s : ss)
06:54:41 <dons> cons c (LPS ss)                        = LPS (P.singleton c : ss)
06:54:42 <ndm> dcoutts, i agree, fancy submitting a patch to use fps ;)
06:54:53 <dcoutts> ndm, :-)
06:55:10 <dons> dmhouse: this is a coalescing trick for cons.
06:55:12 <int-e> dons: yes. that adds another char when the length is 16
06:55:22 <dcoutts> int-e, dons, aye, fair enough
06:55:22 <int-e> hence 17
06:55:27 <dcoutts> that wasn't on purpose
06:55:39 <dmhouse> Ah, sorry, I'm missing context.
06:55:40 <dons> its probably supposed to be < 16 :}
06:55:53 <dcoutts> we never measured the optimal coaleasing size
06:55:57 <dcoutts> we should do
06:56:02 <dons> ah we just talked about it.
06:56:13 <dons> sometime in the next 10 years then
06:56:18 <dcoutts> heh
06:56:47 <dcoutts> int-e, feel free to send in a patch
06:57:04 <dcoutts> whatever the length, it should be a multiple of 8
06:57:45 <dons> should try to get fps 0.8 tagged after SF, and then fps 0.9 "merrily-rowing-down-the-streams" out before PADL, dcoutts
06:57:57 <dcoutts> aye
06:58:14 <dcoutts> dons, remind me, what's SF ?
06:58:16 <dons> i'll tag current stable when ghc comes out
06:58:21 <dcoutts> ok
06:58:21 <dons> oh, that's the Google SoC summit
06:58:24 <dons> next weekend
06:58:26 <dcoutts> ah yes
06:58:46 <dcoutts> dons, so are you going to go to PADL? I hope so! It'd be nice to meet again.
06:58:46 <ndm> dcoutts, bug openned for moving to Data.ByteString - http://code.google.com/p/yhc/issues/detail?id=57&can=2&q= - feel free to do it :)
06:58:49 <lambdabot> Title: yhc - Google Code, http://tinyurl.com/zvpyk
06:58:55 <dons> yeah, i'll be there i'm pretty sure
06:59:25 <dcoutts> dons, great.
06:59:36 <dcoutts> dons, do you think rl will go too?
06:59:58 <dons> and rl too, yeah, he's submitting something for the multicore fp workshop that spj is running
07:00:06 <dcoutts> cool
07:00:26 <dcoutts> is that co-located with PADL/POPL too ?
07:00:32 <dons> yep. so ... beers all round :)
07:00:50 <dons> and ChilliX probably as well, for POPL
07:01:01 <dcoutts> yay
07:03:20 <dons> i'm still scratching my head about this, http://newbabe.pobox.com/~mjd/blog/2006/10/03/#isc-hop
07:03:24 <lambdabot> Title: The Universe of Discourse, http://tinyurl.com/l7g8b
07:03:38 <dons> perl, "a lazy generator based on the lazy stream"
07:04:20 <dons> not sure why its higher order..
07:05:20 <dons> oh, though enumerate might just be a concatMap ?
07:05:27 <dons> or something list monadish
07:05:34 <Heffalump> has anyone read HOP?
07:06:03 <dons> could it be a misuse of 'higher order' ?
07:06:25 <dcoutts> dons, I have a concurrency concern about ByteString and in particular lazy ByteString
07:06:35 <dons> ah yes?
07:06:48 <dcoutts> dons, in smp ghc, we don't lock thunks when we enter them
07:07:01 <dons> hmm
07:07:12 <dcoutts> dons, we rely on them being pure so that we don't get problems if we enter them twice
07:07:29 <dcoutts> with all the imperitive stuff we do, can we be sure that is safe ?
07:08:10 <dons> so you're imagining concurrent threads getting into the thunk of an unevaluated lazy bytestring, and doing something weird?
07:08:21 <dons> when they hit the unsafePerformIO?
07:08:24 <dcoutts> not just lazy
07:08:25 <dcoutts> right
07:08:36 <dcoutts> it'd be the ones where we make new chunks that I'd worry about
07:08:49 <dcoutts> accessing an existing one should be fine as they are immutable
07:09:03 <int-e> but doesn't that just cause loss of sharing?
07:09:10 <dcoutts> not sure
07:09:17 <dcoutts> I'd like someone to convince me :-)
07:10:12 <dons> wouldn't this be a problem with any allocating code? if it is a problem? say, arrays of some form? or Handle buffers?
07:10:20 <dcoutts> hmm
07:10:52 <dons> we'd have to ask SimonM for the dirt on this.
07:10:56 <dcoutts> yeah
07:11:08 <dcoutts> I want to ask him about my StringBuilder idea
07:11:12 <dons> I suspect its only sharing that might suffer, but can't be sure.
07:11:20 <dcoutts> that'd be ideal
07:13:53 <araujo> eh .. mmm .. what could be a reason for keep getting: Failed to load interface for `ModuleG'
07:14:04 <araujo> Everytime i try to compile a file ...
07:14:17 <araujo> The weird thing is that i can load it with ghci
07:14:24 <dons> missing --make ?
07:14:36 <araujo> mm..
07:15:03 <araujo> dons++
07:15:08 * dons >>= return . sleep
07:15:17 <int-e> good night dons
07:15:30 <dcoutts> g'night dons
07:15:31 <int-e> dcoutts: dons has a patch for cons in his mail.
07:15:38 <dcoutts> great
07:15:39 <dcoutts> ta
07:19:19 <int-e> dcoutts: I've left the size at 16, which seems to be a good idea with a cache line size of 32 bytes - a chunk will lie in a single cache line with probability 3/4. I've not measured anything.
07:19:40 <dcoutts> int-e, ok
07:21:29 <SamB> how do you lock a thunk?
07:21:38 <Heffalump> with a very small key
07:21:52 <SamB> seriously!
07:21:58 <dcoutts> SamB, the rts would do it automatically
07:22:07 <dcoutts> SamB, but it doesn't do so, which is rather cunning
07:22:17 <dcoutts> see the ghc-smp paper
07:22:38 <dcoutts> SamB, and if it were to do so, it'd use atomic memory operations
07:22:53 <SamB> oh, you mean it is cunning that it does not do so for *every* thunk...
07:22:55 <SamB> right...
07:23:08 <dcoutts> but those are expensive, so using a lockfree system is faster
07:23:12 <dcoutts> exactly
07:23:32 <dcoutts> and the cunning bit is making the lockfree system safe
07:24:06 <SamB> so, wouldn't it make sense to have a way to make it lock a given expression's thunk?
07:24:16 <dcoutts> not sure
07:24:34 <dcoutts> you should be writing non-side effecting code so it shouldn't matter
07:25:11 <SamB> what if you don't want that loss of sharing?
07:25:18 <dcoutts> dunno
07:25:49 <ndm> @seen psnl
07:25:50 <lambdabot> psnl is in #ghc, #darcs, #haskell-blah and #haskell. I last heard psnl speak 22h 35s ago.
07:26:18 <SamB> though, occasionally you might *want* a loss of sharing
07:26:50 <ndm> if you do, you certainly don't want it randomly based on race conditions :)
07:26:55 <SamB> yes
07:27:01 <SamB> I was thinking that too
07:27:27 <SamB> I bet you know why I was thinking you might want it ;-)
07:27:34 <dcoutts> I dunno, it's just when you're getting a lot of concurrent access that you might want to reduce sharing ;-)
07:28:11 * SamB looks at Yhc thingy
07:28:18 <ndm> Yhc thingy?
07:28:33 <SamB> the presentation
07:28:36 <ndm> oh, we have one thread running at a time - no locks, no race conditions, no SMP useage
07:29:12 <dcoutts> I'm hoping that for a StringBuilder it can be built in a lock-free way such that if there is a race condition, that it is detectable and one or both threads unshare.
07:31:34 <SamB> ndm: what about this "Computer A" and "Computer B" business
07:32:59 <SamB> doesn't it depend on how NU the MA is between the threads?
07:35:13 <ndm> SamB, NU? MA?
07:35:18 <SamB> as in NUMA
07:35:41 <ndm> ah, those run in parallel, although locking operations are entirely unknown on those
07:35:49 <SamB> oh, I should probably have directed that second comment at dcoutts ;-)
07:36:10 <dcoutts> huh?
07:36:15 <ndm> the Computer A, Computer B stuff isn't for shared memory machines, so we don't have lock issues
07:37:38 <SamB> dcoutts: would unsharing help if you were running on a UMA architecture?
07:37:51 <dcoutts> yes
07:37:56 <SamB> how?
07:38:09 <dcoutts> even on SMP, bouncing cachelines back and forth between cpus is really slow
07:38:30 <SamB> ... doesn't that only happen if you *write*?
07:38:35 <dcoutts> yes
07:38:42 <dcoutts> read only is fine
07:39:18 <SamB> hmm, why am I thinking about STM
07:40:33 <dcoutts> hmm, seems I need atomic compare and swap
07:40:41 <SamB> ndm: why are there no patches for me to pull?
07:40:50 <SamB> dcoutts: hmm?
07:41:00 <ndm> SamB, because no ones committed any? where are you pulling from?
07:41:00 <dcoutts> SamB, for the StringBuilder
07:41:14 <dcoutts> but I'd like to avoid even that
07:41:32 <SamB> ndm: Pulling from "neil@darcs.haskell.org:/home/darcs/yhc"...
07:41:41 <ndm> SamB, then no one committed anything :)
07:42:12 <ndm> http://darcs.haskell.org/darcsweb/darcsweb.cgi?r=yhc;a=summary - thats the darcs web
07:42:15 <lambdabot> Title: darcs - yhc, http://tinyurl.com/g4skr
07:42:41 <ndm> dcoutts, did you see we have a gentoo ebuild now?
07:42:50 <dcoutts> ndm, oh, cool
07:42:54 <dcoutts> ndm, send it in
07:43:20 <ndm> dcoutts, http://code.google.com/p/yhc/issues/detail?id=34
07:43:23 <lambdabot> Title: yhc - Google Code, http://tinyurl.com/l28z6
07:43:25 <dcoutts> ndm, you've got our darcs overlay ?
07:43:37 <SamB> darcs overlay?
07:44:06 <dcoutts> SamB, it's a portage overlay that we maintain using darcs
07:44:13 <SamB> oh
07:44:18 <ndm> dcoutts, i don't even understand the question - i didn't do it
07:44:21 <dcoutts> it contains all the gentoo haskell testing ebuilds
07:44:37 <dcoutts> ndm, you wrote the instructions yourself! :-)
07:44:39 <SamB> dcoutts: whats an overlay?
07:45:00 <dcoutts> SamB, it's a collection of ebuilds to use in additon to the main portage collection
07:45:20 <dcoutts> ndm, darcs get --partial http://haskell.org/~gentoo/gentoo-haskell/
07:45:27 <ndm> dcoutts, i can't answer any questions other than send you a link to the ebuild :) - my knowledge is none
07:45:51 <bringert> is there a way to block the current thread until it gets an exception?
07:46:07 <bringert> I'm looping doing threadDelay now
07:46:08 <dcoutts> ndm, darcs add dev-lang/yhc/yhc-darcs-9999.ebuild; darcs record; darcs send
07:46:12 <bringert> fells silly
07:46:16 <bringert> feels
07:46:37 <fasta> When I do foo <some input> in ghci in Emacs, I see that my CPU does not get used, nor does the function return.
07:46:41 <SamB> bringert: have you tried taking an empty MVar known only to that thread?
07:46:45 <lambdabot> Title: Index of /~gentoo/gentoo-haskell
07:46:57 <bringert> SamB: guess I could do that
07:47:01 <bringert> fells like a hack
07:47:07 <bringert> feels dammit
07:47:10 <SamB> it does doesn't it ;-)
07:47:38 <fasta> Hmm, seems like The impossible happened...
07:47:49 <SamB> but if it works it should work nicely
07:49:38 * mux yawns and strecthes
07:50:18 <bringert> SamB: works fine, thanks for the suggestion. wait = newEmptyMVar >>= takeMVar
07:51:21 <ndm> dcoutts, have just prodded our maintainer, he's sending it over shortly
07:51:28 <dcoutts> ndm, cool
07:51:43 <dcoutts> ndm, I added the instructions to your bug report
07:52:03 <ndm> dcoutts, i saw :) we have a bug tracker mailing list as well
07:52:09 <dcoutts> right
07:53:03 <fasta> Hmm, I seem to be introducing some infinite recursion... that's no good...
07:53:46 <fasta> I get a stack space overflow within  0m0.088s
07:54:27 <fasta> Is that a new record? ;)
07:58:00 <SamB> fasta: comment out your type signatures and look for the "a"
07:58:02 <int-e> dcoutts: the thing I'd be really worried about in the SMP case is doing lazy IO, i.e. hGetContents for lazy bytestrings. Allocating memory in otherwise pure code shouldn't cause a problem - you have the thunk containing unsafePerformIO that will return equivalent values each time.
07:58:04 <SamB> ;-)
07:58:22 <dcoutts> int-e, right
07:58:49 <fasta> SamB: I don't get the joke, sorry.
07:59:00 <dcoutts> int-e, actually for IO is should be ok because all Handle ops are locked with an MVar
07:59:12 <SamB> @type let forever p = p >> forever p in forever
07:59:24 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b
07:59:27 <fasta> I think I already see it.
07:59:38 <SamB> in this case it is actaully a "b"
07:59:39 <int-e> Ah. I wondered about that.
08:00:04 <fasta> It's foobar foo = do foo<- flabber foo
08:00:13 <fasta> Basically something like this
08:00:41 <SamB> how is that recursive?
08:01:35 <fasta> SamB: good point, it isn't.
08:01:47 <fasta> SamB: well, then obviously, it must be something else.
08:01:56 <fasta> how annoying
08:02:18 <SamB> if that were one of those "mdo" things, it would be different...
08:02:44 <fasta> SamB: yes, I thought about that, but no.
08:07:30 <int-e> dcoutts: But can't you still lose complete chunks? Let's say you have LPS <xxx> where <xxx> is an unevaluated thunk. you have a race and manage to enter <xxx> twice. the first thread reads a block and updates <xxx> accordingly, then the second thread also reads a block and updates <xxx> again. I don't see how the lock on the handle would help here. In fact I don't see how unsafeInterleaveIO could work at all, doing IO.
08:07:52 <ndm> dcoutts, the Gentoo ebuild has now been sent
08:07:56 <dcoutts> ndm, ta
08:08:00 <dcoutts> int-e, hmm
08:08:20 <ndm> dcoutts, please drop any ebuild issues to the yhc mailing list, if you need any help
08:08:45 <dcoutts> int-e, yes, I can't see that it'd be safe, we should talk to JaffaCake
08:08:51 <dcoutts> ndm, ok, ta
08:11:58 <hygge> hello
08:12:42 <ndm> hi hygge
08:13:07 <nomeata> ndm: Hi. Seen my patch with the PropLang workaround?
08:13:11 <ValarQ> welcome mr Hygge
08:13:18 <hygge> :)
08:13:24 <fasta> Heh, I introduced a cycle.
08:13:37 <ndm> nomeata: ah, yes, i was away for the end of the last week, so i saw them, but haven't looked at them yet
08:13:45 <hygge> i came here because i'v a got a problem, as usual
08:14:18 <hygge> when i use "newtype" based on Int, can i combine it somehow with the Deriving-keyword to make it a member of Num and Random too? Just as Int is...
08:14:20 <nomeata> ndm: it's just a clumpsy workaround, about the same as in glade IIRC. now I have no I idea what to do next with proplang :-]
08:14:51 <ndm> nomeata: so any disadvantages to freezing the thing to a string?
08:15:13 <ndm> next thing that needs doing is more complete API coverage, i think
08:15:24 <ndm> and a tutorial
08:15:54 <nomeata> ndm: I have not seen a gtk property that stores not a string...
08:16:12 <ndm> enabled?
08:16:37 <SamB> hygge: yes, using GHC's newtype deriving extension
08:16:52 <nomeata> I don't think enabled has the same problem. Probably the function has to be renamed to include "StringWorkaround" or something, and the original one can be used for boolean etc.
08:17:26 <nomeata> good by, cu later
08:17:33 <hygge> samb, im working in hugs now. does hugs got it?
08:17:43 <SamB> hygge: dunno!
08:17:51 <hygge> okej :)
08:18:21 <nomeata> welcome back
08:18:33 <hygge> hmm, maybe i can solve it using Instance Num mynewtype?
08:18:36 <dmhouse> When building typed LC interpreters, what's the general typechecking strategy? I.e., when should it be done?
08:18:40 <SamB> hygge: no
08:18:46 <hygge> ah :/
08:18:56 <dmhouse> I'm thinking before evaluation starts (just after parsing), and after each reduction, but perhaps that's superfluous.
08:19:10 <SamB> try "newtype Foo = Foo Int deriving (Eq,Ord,Show,Num)"
08:19:29 <dmhouse> Well, hmm, you have to typecheck when you perform an application, e.g. (\x:T. t) y, as you have to check that y:T.
08:19:32 <SamB> (pass -98)
08:20:00 <SamB> dmhouse: wouldn't you have checked that already?
08:20:29 <dmhouse> Yeah, I suppose so.
08:20:42 <dmhouse> So just before evaluation, that's all?
08:20:56 <ndm> SamB, have you got any response to your IdSupply patch?
08:21:15 <SamB> ndm: no
08:21:39 <ndm> SamB, consider that as meaning "no one objects, or no one understands that area" - and just push it anyway
08:21:45 <SamB> I did already
08:21:51 <SamB> ;-)
08:21:52 <ndm> cool :)
08:22:30 <SamB> Also I got tired of importing Id everywhere, so I've had Info (and so IntState) export it
08:22:38 <ndm> fair enough
08:25:21 <yip> what is WASH?
08:25:59 <SamB> Web And Something-or-other involving H
08:26:16 <SamB> that is, I don't know what anything but the W stands for
08:26:25 <yip> Web Authoring System Haskell. but is it any good?
08:26:28 <ndm> Haskell?
08:26:46 * SamB has no clue
08:27:18 <Heffalump> it seems too hard to actually do stuff with it, IME
08:27:32 <yip> is it anything like HAppS?
08:34:58 <ndm> dcoutts, how much work is it likely to be to add hat support to Cabal?
08:35:06 <dcoutts> no idea
08:35:12 <dcoutts> I don't know how hat works
08:35:27 <ndm> if you imagine hat is a preprocessor that must be called on all source files first
08:35:37 <ndm> and that at link time, you need to link with an additional package
08:35:49 <SamB> ndm: so what can Yhc's "State" pseudo-monad do that you can't do with (ReaderT r (State s))?
08:36:01 <SamB> besides have different input and output state types?
08:36:15 <ndm> SamB, is ReaderT Haskell 98, does it require rank-2 types?
08:36:25 <SamB> ndm: point
08:36:43 <ndm> it might be easier to turn State into a real monad
08:36:51 <ndm> which shouldn't be that hard
08:37:00 <ndm> then in the future, it can be aliased to ReaderT
08:37:16 <dcoutts> ndm, does the hat version of a lib get installed too ?
08:37:28 <SamB> ergh, that State in the second thing was referring to the State in Control.Monad.State, which also requires extensions...
08:37:31 <ndm> dcoutts, imagine hat without libs
08:37:58 <ndm> dcoutts, but yes, if you wanted to trace a program that used that library
08:38:09 <SamB> actually, both of them need MPTCs and fundeps (for the MonadReader and MonadState classes)
08:38:37 <ndm> can you not do a really simple state monad, without MPTC's?
08:38:41 <SamB> sure
08:39:10 <ndm> feel free to do whats nicest, ideally moving to real monads with do notation, but rank-2 types can't be allowed for now
08:39:31 <SamB> but you can't overload the names without typeclasses
08:39:48 <ndm> you can use type classes, just not MPTC
08:40:25 <ndm> given a few years we can probably relax that with Haskell', but for now we have to keep to Haskell 98
08:40:27 <SamB> but, of course, if we only use the one sort of monad, we don't need a typeclass at all
08:40:34 <ndm> indeed
08:40:45 <SamB> probably by Haskell' we will be using ATs
08:41:04 <ndm> unlikely
08:41:24 <ndm> maybe Haskell''
08:41:35 <SamB> (And a typeclass that wasn't an MPTC wouldn't help, and without fundeps it is debatable whether that would be any help, and you'd probably need scoped type variables...)
08:42:05 <SamB> well, lets just say it doesn't look like we are getting fundeps, and MPTCs are next to useless without them
08:42:14 <ndm> i don't know whats going on
08:42:24 <ndm> but the fact that people are still rewriting the rules to match them worries me
08:43:43 <Igloo> dcoutts, ndm: It would be nice to have a generic way of building librarys in different ways, e.g. normal, prof, hat, unreg
08:43:56 <dcoutts> aye
08:48:47 <ndm> indeed, who wants to code it up ;)
08:51:20 <SamB> ndm: doesn't it need an interface though?
08:53:43 <yip> is HaXml supposed to compile with ghc-6.5.20060930?
08:54:30 <dcoutts> depends on the version
08:54:42 <yip> 1.13.2
08:54:45 <dcoutts> yep
08:55:24 <yip> i get an error during make:
08:55:30 <yip> cd tools; mv a.out DtdToHaskell
08:55:32 <yip> mv: cannot stat `a.out': No such file or directory
08:55:55 <SamB> what platform?
08:55:59 <dcoutts> I don't use the makefile, I use Cabal
08:55:59 <SamB> no wait.
08:56:10 <SamB> well, yes. what platform?
08:57:25 <yip> um... linux i guess
08:57:54 <aFlag> hello, I hear the type inferer is exponential, does anyone know of an example of a program that shows that? I mean, some relatively small program that takes really long to compile?
08:58:21 <SamB> aFlag: exponential *in what*?
08:59:06 <Philippa_> term size
08:59:23 <Philippa_> I know of an example but don't have it to hand...
09:00:12 <yip> what is an orphan instance?
09:00:47 <aFlag> SamB, in the number of type inferences it has to do
09:05:15 <ndm> SamB, oh, yeah, there are all kind of copmlex .hx files (.hi for .hat)
09:08:55 <SamB> yip: it is an instance that isn't in the same module as either the type or the class, or something like that...
09:16:20 <yip> problems building HAppS: Could not find module `Text.Regex': it is a member of package regex-compat-0.71, which is hidden
09:17:27 <therp> the inverted T symbol (\perp in latex) as shown in the haskell report is equal to Prelude.undefined?
09:17:46 <mauke> pretty much, yes
09:19:30 <therp> the haskell report page 33 tells (\ ~(x:xs) -> x:x:xs) T = T:T:T  (T:=inverted T=undefined).. but I can't reconstruct this result in ghci. it seems a bit unplausible to me.
09:20:34 <hn> how can I generate a random number using StdGen?
09:21:10 <mauke> > length $ take 2 $ (\~(x:xs) -> x:x:xs) undefined
09:21:10 <lambdabot>  Parse error
09:21:11 <dcoutts> hn, using functions from the Random module
09:21:18 <mauke> > length $ take 2 $ (\ ~(x:xs) -> x:x:xs) undefined
09:21:25 <lambdabot>  2
09:21:31 <mauke> therp: seems to work
09:21:41 <dcoutts> ndm, I haven't got the ebuild you sent
09:22:37 <Cale> hn: http://www.haskell.org/hawiki/HaskellNewbie_2fWorkingWithRandomNumbers
09:22:40 <lambdabot> Title: HaskellNewbie/WorkingWithRandomNumbers - The Haskell Wiki, http://tinyurl.com/zdvsy
09:22:44 <ndm> dcoutts: Successfully sent patch bundle to: Gentoo-Haskell <gentoo@haskell.org>.
09:22:58 <deadbeef> (anyone knows if sel4 is available somewhere ?)
09:23:05 <deadbeef> (i'd really like to give it a try)
09:23:05 <ndm> dcoutts, that popped up after, but they are not on the maililng list, has it been caught in a spam trap?
09:23:06 <dcoutts> ndm, and your local mail works?
09:23:14 <Philippa_> therp: it says you can pattern-match on the :s in the result, but if you try to use the values in the list then you end up with an undefined function
09:23:16 <ndm> dcoutts, not me, but yes, i guess it does
09:23:46 <dcoutts> ndm, we don't have a spam trap for gentoo@haskell.org
09:23:58 <therp> mauke: why do I have to use take here? I'm confused to see 'undefined' used as if it would be a list. is undefined a list, maybe a cons with "car and cdr" (speakign of in lisp terms) pointing to itself? .. the prelude definition on page 114 haskell report just is undefined = error "Prelude.undefined"
09:24:05 <ndm> dcoutts, i'm getting him to redo with darcs send -o
09:24:18 <int-e> > case (\~(x:xs) -> x:x:xs) undefined of a:b:c -> True; _ -> False
09:24:19 <lambdabot>  Parse error
09:24:28 <int-e> > case (\ ~(x:xs) -> x:x:xs) undefined of a:b:c -> True; _ -> False
09:24:30 <lambdabot>  True
09:25:01 <ndm> > case [] of {~(x:xs) -> "here"; [] -> "else"}
09:25:02 <dcoutts> ndm, darcs send can say it worked, but all it means is that the local sendmail prog accepted it, not that it necessarily got relayed
09:25:03 <lambdabot>  "here"
09:25:15 <ndm> dcoutts, yep, its being resent
09:25:29 <ndm> can anyone give a good reason why the above is "sensible" in any possible way?
09:25:42 <Cale> therp: undefined is a value of every type.
09:25:49 <Cale> @type undefined
09:25:51 <lambdabot> forall a. a
09:26:02 <int-e> > let x:xs = [] in "here"
09:26:04 <lambdabot>  "here"
09:26:07 <therp> cale: but how is it possible to match undefined against the pattern x:xs?
09:26:16 <dcoutts> ndm, you mean why should sendmail accept the mail if it isn't configured to relay it ?
09:26:16 <int-e> ndm: it's exactly the same situation as this one
09:26:30 <ndm> int-e: but thats not what i wrote! i did a case and it didn't match, and it lied to me!
09:26:43 <Cale> therp: doing so would be an error, unless the pattern is lazy, in which case it's only an error if x or xs is demanded
09:26:46 <ndm> int-e: for let it has reasonable interpretation, for the other it doesn't
09:27:13 <Cale> > let f (x:xs) = undefined in f [1,2,3]
09:27:15 <lambdabot>  Add a type signature
09:27:16 <ndm> dcoutts, sent manually with darcs send -o, then emailed
09:27:21 <dcoutts> ok
09:27:26 <Cale> > let f (x:xs) = undefined :: Int in f [1,2,3]
09:27:28 <lambdabot>  Undefined
09:27:32 <Cale> > let f ~(x:xs) = undefined :: Int in f [1,2,3]
09:27:34 <lambdabot>  Undefined
09:27:42 <Cale> oh, heh, I suppose you can't tell here :)
09:27:46 <int-e> ndm: I don't understand your problem. It's what irrefutable patterns do.
09:27:47 <Cale> > let f ~(x:xs) = 5 :: Int in f undefined
09:27:50 <lambdabot>  5
09:27:52 <Cale> > let f (x:xs) = 5 :: Int in f undefined
09:27:54 <lambdabot>  Undefined
09:27:58 <dcoutts> ndm, usually it's just a matter of adding a relay smtp server in the config of the local mail system
09:27:59 <therp> cale: but they are demanded, aren't they? at least in the haskell report example. x:x:xs is the functions body
09:28:05 <ndm> int-e: but my example is clearly confusing, let is a different construct, and is reasonable
09:28:18 <Cale> therp: where is the full example?
09:28:22 <int-e> ndm: no, it's the same thing, down at the semantic level.
09:28:46 <ndm> int-e: i know it is, what i'm asking is if there is any possible reason that it should be
09:28:57 <Cale> (\ ~(x:xs) -> x:x:xs) this?
09:28:58 <ndm> int-e: i.e. its broken because its semantics are really silly
09:29:14 <Cale> > length ((\ ~(x:xs) -> x:x:xs) undefined)
09:29:15 <therp> cale: http://www.haskell.org/onlinereport/exps.html - 3.17
09:29:16 <lambdabot>  Undefined
09:29:17 <lambdabot> Title: The Haskell 98 Report: Expressions
09:29:44 <int-e> ndm: you're just giving a silly example. lazy patterns are useful for matching yet-to-be computed values.
09:29:56 <Cale> > length (take 2 ((\ ~(x:xs) -> x:x:xs) undefined))
09:29:57 <lambdabot>  2
09:29:59 <ndm> int-e: but if you match without actually testing, why use a case and not a let?
09:30:02 <Cale> aha
09:30:10 <int-e> ndm: if you don't want the behaviour, don't use ~. ~ asks the compiler to lie to you so why are you complaining about it?
09:30:16 <Cale> there's an example
09:30:19 <Cale> > length (take 2 ((\ ~(x:xs) -> x:x:xs) undefined))
09:30:21 <lambdabot>  2
09:30:45 <ndm> int-e: if we had an option to add a # to the start of a True and if its at an even character position change it to a False, would you say thats  a good idea?
09:30:49 <therp> cale: doesn't this result imply that there is a match?
09:30:57 <therp> cale: hence the pattern matching is demanded..?
09:30:59 <Cale> ~ patterns *always* match
09:31:04 <ndm> i.e. if there is a good reason, fine, but if there isn't adding an optional feature isn't a good idea
09:31:11 <ndm> yes, which means that in a case, they are't sensible
09:31:14 <Cale> but the values of x and xs here were never demanded
09:31:28 <Cale> since I only asked for the length of the take 2 of the list
09:31:32 <int-e> look, just because you happen to dislike a feature doesn't make it bad. it's predictable, even if it's a bit obscure.
09:31:44 <ndm> what if we introduce if~ which always executes the true statement, regardless of the value?
09:31:47 <pejo> aflag, "Deciding ML Typabililty is complete for deterministic exponential time" by Mairson contains the examples. Nested lets basically.
09:31:52 <Cale> and take 2 (x:x:xs) = [x,x] regardless of what x and xs are
09:31:57 <Cale> and the length of that is 2
09:32:04 <ndm> int-e: i accept that, what i am asking is if its useful inside a case statement
09:32:06 <Baughn> @where house
09:32:07 <lambdabot> http://www.cse.ogi.edu/~hallgren/House/
09:32:08 <therp> cale: ah ok, so ":" isn't a strict function that demand evaluation of its arguments. of course it's not strict..
09:32:12 <Cale> right
09:32:29 <ndm> dcoutts, got the email through yet?
09:32:35 <dcoutts> ndm, yep
09:32:52 <Cale> > let 1 = 2 in 1 + 1
09:32:55 <lambdabot>  2
09:32:58 <ndm> dcoutts, send any follow up on it to yhc@haskell
09:33:01 <int-e> ndm: you realize the translation of let in the haskell report is a case expression?
09:33:06 <therp> cale: but how should one ever arrive at the result  _|_:_|_:_|_?
09:33:13 <ndm> int-e: yes, but it doesn't have to be
09:33:25 <Cale> therp: well, testing for bottom-ness is tricky :)
09:33:30 <aFlag> pejo, thanks
09:33:36 <dcoutts> ndm, we'll patch it in our repo, so changes should be sent using darcs against our repo
09:33:45 <ndm> int-e: and just because it translates to a case expression, doesn't mean you have to put that in the original source language (although i realise its useful)
09:33:47 <Cale> since evaluating a bottom will result in nontermination or your program dying with an error
09:33:53 <int-e> ndm: anyway, while they are not strictly necessary, irrefutable patterns are useful.
09:34:02 <Cale> (at least in general)
09:34:06 <ndm> dcoutts, cheers, although i suspect it would be you changing it more than us ;)
09:34:08 <ndm> int-e: for?
09:34:12 <dcoutts> ndm, do you need any particular version of ghc? eg 6.2.2 or 6.4 ?
09:34:18 <Cale> but in this case, you carry that out algebraically
09:34:19 <ndm> dcoutts, 6.4
09:34:23 <therp> cale: right :) .. so I was wondering if this is the "true" result.
09:34:32 <Cale> Well, we can observe that it is
09:34:38 <ndm> but only because of Data.Map
09:34:38 <dcoutts> ndm, ok, ta, any needed version of scons ?
09:34:44 <ndm> we can also use Hugs :)
09:34:46 <Cale> > length (take 3 ((\ ~(x:xs) -> x:x:xs) undefined))
09:34:48 <lambdabot>  Undefined
09:34:51 <dcoutts> ndm, great
09:34:56 <Cale> > length (take 2 ((\ ~(x:xs) -> x:x:xs) undefined))
09:34:58 <lambdabot>  2
09:35:12 <Cale> so the list has at most 2 real conses
09:35:15 <ndm> dcoutts, any
09:35:18 <dcoutts> ok
09:35:23 <therp> cale: my guess would be that we can deduce this from the type of the function .. (?)
09:35:41 <Cale> no, this behaviour you can't tell from the type
09:35:48 <int-e> > fix (\ ~ (a,b) -> (42, a))
09:35:50 <lambdabot>  (42,42)
09:36:01 <ndm> > (42,42)
09:36:03 <lambdabot>  (42,42)
09:36:12 <Cale> do you see why my evaluations show that the produced list has exactly two conses, and is thereafter undefined?
09:36:13 <ndm> I fail to believe thats a valid use for lazy patterns :)
09:37:03 <therp> cale: yes, I understand that - because of the non-strictness of : and no need to eval the content of the cons cells.
09:37:05 <Cale> (length . take n) will in general try to match exactly n conses from the start of a list.
09:37:28 <Cale> so we know that it's at least as defined as  _|_ : _|_ : _|_
09:37:37 <Cale> now we just have to test the elements :)
09:37:52 <Cale> > head ((\ ~(x:xs) -> x:x:xs) undefined)
09:37:54 <lambdabot>  Add a type signature
09:37:57 <Cale> > head ((\ ~(x:xs) -> x:x:xs) undefined) :: Int
09:37:59 <lambdabot>  Undefined
09:38:06 <Cale> > (head . tail) ((\ ~(x:xs) -> x:x:xs) undefined) :: Int
09:38:08 <lambdabot>  Undefined
09:38:09 <int-e> > let assert [] _ = []; assert (a:as) ~(b:bs) = b:assert as bs in length $ assert [1..5] undefined
09:38:11 <lambdabot>  5
09:38:52 <int-e> ndm: irrefutable patterns are useful for creating data structures with holes (future values).
09:38:54 <Cale> and we know that we can't pattern match against that last _|_ already, so it's at most _|_ as well.
09:39:14 <Cale> so it really is _|_ : _|_ : _|_
09:39:22 <ndm> int-e: ok, i'm willing to accept that one, although a translation to a where seems better, since thats not a "broken" pattern match
09:40:12 <int-e> maybe we should just call them 'future pattern matches'
09:40:22 <Cale> If you use pattern bindings, a ~ is stuck in front of them implicitly
09:40:30 <int-e> because they delay the pattern match until some part of them is needed.
09:40:46 <Cale> Most instances of wanting lazy pattern matches come from pattern bindings
09:40:49 <int-e> but you miss the assertive nature of these 'matches'.
09:42:04 <Cale> > let fibs@(_:xs) = 0 : 1 : zipWith (+) fibs xs in fibs
09:42:06 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
09:42:59 <fasta> Do I also get a profile when I get a stack overflow?
09:43:06 <therp> cale: what is the difference between a pattern match and a pattern binding? I would say that the \~(x,xs) -> ... is a pattern binding, but that must be wrong as nobody would write ~ if it's implicit
09:43:56 <Cale> therp: by pattern binding, I mean in the sense of the report, that is, it's a type of declaration
09:44:24 <Cale> where the lhs is not a function name together with patterns for its arguments, but just a pattern
09:44:38 <Cale> > let x = 5 in x + x
09:44:40 <lambdabot>  10
09:44:47 <Cale> x = 5 there is a pattern binding
09:45:00 <Cale> > let f x = 5 in f x + f x
09:45:02 <lambdabot>  Not in scope: `x'
09:45:04 <Cale> er
09:45:07 <Cale> > let f x = 5 in f 0 + f 0
09:45:09 <lambdabot>  10
09:45:15 <Cale> now it's a function binding
09:45:36 <Cale> > let (x:xs) = [1..10] in x + x
09:45:39 <lambdabot>  2
09:45:46 <Cale> > let (x:xs) = [1..10] in xs ++ xs
09:45:47 <lambdabot>  [2,3,4,5,6,7,8,9,10,2,3,4,5,6,7,8,9,10]
09:45:57 <yip> i'm running change_state.hs example from happs tutorial, but the redirect for /change doesn't seem to work!
09:46:14 <therp> the last two statements are pattern bindings?
09:46:18 <Cale> yeah
09:46:22 <Cale> expressions :)
09:46:38 <Cale> well, the (x:xs) = [1..10] part is the pattern binding
09:47:01 <Cale> so let's see if I can show the difference in behaviour...
09:48:40 <yip> dons: what can you tell me about the "Fix lazyness of take, drop & splitAt" fps patch?
09:48:43 <dcoutts> ndm, you could tag & checkpoint the yhc repo
09:48:47 <therp> cale: would a pattern binding be the thing that is translated in 3.12 (first translation?)
09:48:47 <dcoutts> Copying patch 103 of 712...
09:49:03 <ndm> dcoutts, give me instructions, and i'll do that now :)
09:49:14 <Cale> therp: no, that's a let-expression
09:49:19 <dcoutts> ndm, darcs checkpoint --optimise
09:49:40 <ndm> dcoutts, what about darcs tag ?
09:49:40 <therp> cale: ah ok. because that the only thing where I spotted implicit patterns (the translation adds ~ everywhere)
09:49:42 <Cale> therp: look at 4.4.3
09:49:54 <Cale> and in particular, 4.4.3.2
09:49:58 <dcoutts> ndm, it'll use the last checkpoint tag
09:50:02 <dcoutts> ndm, assuming there is one
09:50:33 <therp> 4.4.3.2 refers to 3.12
09:50:43 <therp> in particular these translations of 3.12
09:50:43 <ndm> dcoutts, darcs says it doesn't know about checkpoints
09:50:45 <Cale> ah, probably :)
09:51:02 <dcoutts> ndm, maybe you never made any
09:51:22 <Cale> oh, that's an interesting translation to bother talking about
09:51:36 <ndm> darcs checkpoint --optimise
09:51:38 <ndm> darcs failed:  Invalid command 'checkpoint'!
09:51:49 <ndm> dcoutts, right after doing a tag
09:51:56 <dcoutts> ndm, ah other way around, sorry. darcs optimize --checkpoint
09:52:27 <ndm> dcoutts, done, should now be tagged
09:52:36 <dcoutts> ndm, ok great
09:52:47 <dcoutts> ndm, just testing the ebuild now...
09:52:48 <Cale> but to understand what function and pattern bindings are, the 4.4.3.2 section does a better job of explaining it
09:52:58 <ndm> it was checkpointed, but moving the repo over didn't keep the checkpoint
09:53:29 <musasabi> yip: I can help you with HAppS stuff, but very sporadically on irc tonight (at a party)
09:55:10 <fasta> It seems my GHC is not referential transparant :(
09:55:21 <SamB> how so?
09:55:27 <fasta> When I do all the steps individually the correct answer is computed.
09:55:35 <SamB> for what?
09:56:04 <fasta> When I do them using a function, it fills the stack.
09:56:41 <fasta> SamB: I would have to post 500 lines of code for you to reproduce it.
09:56:50 <SamB> ah.
09:57:13 <SamB> insofar as a stack overflow could be considered to be a value...
09:57:17 <SamB> I suppose you are right.
09:57:59 <fasta> I would like to see what ghci _is_ doing, though.
09:59:27 <therp> cale: let me ask one more question before I go and read these sections, it seems kind of a stretch to me to give T:T:T (T=_|_) as result, because as soon as we inspect the value the whole computation result becomes T. it's ok to conclude (length (take 2..) because we know that the result must be of the form x:x:y with x, and y still waiting for evaluation. evaluating them seperately will always yield x=undefined y=undefined, but i
09:59:28 <therp> t somehow seems wrong to conclude T:T:T because as soon as we inspect it the overall computation result changes and doesn't even have the x:x:y form but T.
10:00:08 <Cale> Well, that's what _|_ is all about, in some sense.
10:00:21 <Cale> You have to admit that _|_ : _|_ is a different value from _|_
10:00:48 <therp> cale: is there actually a way to print T:T:T? as given in the example. is there a way to test for bottomness in a way that confirms this result?
10:00:58 <int-e> > case undefined of a:bs -> True; _ -> False
10:01:00 <lambdabot>  Undefined
10:01:04 <int-e> > case undefined:undefinedf of a:bs -> True; _ -> False
10:01:06 <lambdabot>  Not in scope: `undefinedf'
10:01:08 <int-e> > case undefined:undefined of a:bs -> True; _ -> False
10:01:09 <lambdabot>  True
10:01:19 <Cale> well, there are modules which will let you detect specific bottoms generated in a special way
10:01:39 <Cale> but the semantics here are different, let me give a simpler example...
10:01:44 <dcoutts> ndm, it'd be nice to have the testsuite work in the ebuild too, do you have any instructions on how to run the testsuite from within the build tree (ie without having installed yet)
10:01:48 <therp> cale: right, but the match that implies _|_:_|_ is one that never can happen
10:01:51 <Cale> > (length . take 1) (undefined : undefined)
10:01:52 <lambdabot>  1
10:01:55 <Cale> > (length . take 1) (undefined)
10:01:58 <lambdabot>  Undefined
10:02:03 <ndm> dcoutts, scons test
10:02:08 <Cale> So undefined : undefined cannot be equal to undefined
10:02:09 <fasta> Does Hugs also understand -fno-monomorphism-restriction in an OPTIONS comment?
10:02:09 <dcoutts> great
10:02:25 <int-e> ghci can help a bit
10:02:25 <ndm> dcoutts, its not set up to run the test suite with an installed copy
10:02:31 <Cale> because (length . take 1) is a function which behaves differently on each
10:02:33 <int-e> Prelude> map (const ()) (undefined : undefined : undefined) ==> [(),()*** Exception: Prelude.undefined
10:02:51 <dcoutts> ndm, ok, perfect, we need it to work with the version still in the build tree.
10:03:04 <int-e> note that it prints two values before running into the last 'undefined'
10:03:08 <dcoutts> ndm, will that command fail if the testsuite fails?
10:03:09 <Cale> yeah, you can do that sort of thing too if you have an interactive environment which prints things immediately, unlike lambdabot :)
10:03:11 <therp> cale: I'm not arguing against that, but the result x:x depends on the fact that undefined can be matched with (x:xs), but that can never be the case
10:03:25 <Cale> hmm
10:03:30 <basti_> it can't ^^
10:03:31 <basti_> ?
10:03:32 <dcoutts> ndm, if so it'll prevent the installation of the ebuild - which is indeed what we want.
10:03:46 <basti_> undefined is of any type
10:03:49 <Cale> > (length . take 2) ((\(x:xs) -> x:x:xs) undefined)
10:03:51 <lambdabot>  Undefined
10:03:53 <Cale> > (length . take 2) ((\~(x:xs) -> x:x:xs) undefined)
10:03:54 <lambdabot>  Parse error
10:03:58 <Cale> er
10:04:00 <dcoutts> ndm, well, at least if you normally expect the testsuite to work :-)
10:04:01 <Cale> > (length . take 2) ((\ ~(x:xs) -> x:x:xs) undefined)
10:04:03 <lambdabot>  2
10:04:09 <ndm> dcoutts, yes
10:04:18 <basti_> so, undefined can be of type "list" too, and if it is, it'd not out of the question to think it could be a cons, too
10:04:23 <Cale> um, I don't know what the confusion is, I suppose
10:04:26 <basti_> if we never look at it, it might be
10:04:27 <ndm> dcoutts, with the error code incremented by one for each failure
10:04:34 <dcoutts> ndm, nice
10:04:45 <Cale> therp: undefined isn't being matched against x:xs
10:04:51 <Cale> in the lazy pattern case
10:04:58 <basti_> actually, how should we find out that undefined is undefined, if we don't look at it?
10:04:59 <therp> cale: the only escape from that trap is to argue that (let's name it) f ~(x:xs) = x:x:xs :: [a] -> [a] and as _|_ is part of every type the result of f _|_ must be _|_:_|_:_|_ - but it seems unplausible to argue from the evaluation rule, because they diverge on any attempt to do so
10:05:50 <Cale> therp: the only problem is that *printing* _|_ : _|_ : _|_ is impossible, and results in failure, because one will attempt to print the first element
10:05:59 <therp> cale: I'm just arguing that we can't conclude this result from any evaluation, and that the "=>" (standing for evaluates to) is not going to happen in any way
10:06:01 <Cale> in memory, that is very different from _|_ along
10:06:04 <Cale> alone*
10:06:11 <Cale> oh, we can
10:06:17 <basti_> i see it like that: the evaluation goes like: match, fine, return (thunk of head match):(thunk of head match):(thunk of tail match)
10:06:26 <Cale> we can conclude it in the way that I discussed
10:06:45 <Philippa_> basti_: not with a lazy match, it does the matching in the thunks
10:06:49 <Cale> We know that  (length . take 2) (f undefined) = 2
10:06:54 <basti_> yea thats what i meant
10:06:56 <Philippa_> so in fact it only tries to pattern match when you force one of those thunks
10:06:58 <Cale> and that (length . take 3) (f undefined) = undefined
10:07:05 <basti_> the thunk that would do "head match"
10:07:24 <Cale> which tells us that (f undefined) = x : y : undefined for some x and y
10:07:29 <therp> cale: that's only an indirect evidence :) .. the result could also be "aaa":1:undefined
10:07:41 <Cale> therp: yes, and then
10:07:51 <Cale> we can do head (f undefined)
10:07:58 <Cale> which is undefined
10:08:06 <fasta> Heh, it seems that the Hugs parser is stupid.
10:08:07 <Cale> and that tells us that x = undefined here
10:08:15 <Cale> and head (tail (f undefined))
10:08:23 <Cale> which tells us that y is undefined as well
10:08:51 <fasta> Hmm, no, it's just ghci being quite smart.
10:09:23 <Cale> therp: of course, it couldn't be "aaa":1:undefined, since that's actually a type error, so it can't happen
10:09:39 <Cale> but until we check the first two elements, we don't know that it isn't 1:2:undefined
10:09:49 <Cale> > (length . take 2) (1 : 2 : undefined)
10:09:51 <lambdabot>  2
10:09:56 <Cale> > (1 : 2 : undefined) !! 0
10:09:59 <lambdabot>  1
10:10:00 <Cale> > (1 : 2 : undefined) !! 1
10:10:02 <lambdabot>  2
10:10:02 <dcoutts> ndm, one thing we're concerned about is that the build does it's own checkouts of online repos using darcs and svn
10:10:06 <Cale> > (1 : 2 : undefined) !! 2
10:10:09 <lambdabot>  Undefined
10:10:20 <dcoutts> ndm, the usual practice is for the ebuild to fetch all the source
10:10:37 <Cale> > (length . take 2) (undefined : undefined : undefined)
10:10:38 <lambdabot>  2
10:10:43 <Cale> > (undefined : undefined : undefined) !! 0
10:10:45 <lambdabot>  Add a type signature
10:10:47 <Cale> > (undefined : undefined : undefined) !! 0 :: Int
10:10:50 <lambdabot>  Undefined
10:10:53 <fasta> I get  - Undefined type constructor "Endo" in Hugs, while in ghc everything works. Is my version of Hugs too old?
10:11:06 <fasta> 20050308
10:11:31 <vegai> ?type (undefined : undefined)
10:11:33 <lambdabot> forall a. [a]
10:11:44 <fasta> Otherwise I would need to open up the can of worms called macros.
10:12:01 <Cale> therp: does that all make it clearer?
10:12:03 <dcoutts> ndm, we'll want to modify the ebuild so that the ebuild fetches the source. I assume the list of things to get is fixed.
10:12:26 <musasabi> yip: if you are aroung in 4 hours I will have time for discussing more about HAppS - or send a message to the ML
10:12:34 <ndm> dcoutts, it is
10:12:36 <musasabi> -> sauna
10:12:49 <ndm> dcoutts, and if they are already checked out, then the scons won't do it
10:12:54 <dcoutts> ndm, ok
10:13:29 <Cale> therp: it might help to tell you that in memory, if it was as evaluated as possible without killing the program, (undefined : undefined) would be represented as a cons-cell with a pointer to a bit of code which crashes for the head, and a pointer to a bit of code which crashes for the tail
10:13:32 <ndm> scons update will do pull's for each of the trees though, if thats useful at all
10:13:35 <fasta> The Hugs version in Debian is two releases behind.
10:14:07 <SamB> fasta: at least it is better than the one I used to have!
10:14:16 <SamB> which had no Data.Map
10:14:24 <fasta> SamB: heh
10:15:04 <Cale> isn't there a repository somewhere with updated Haskell packages?
10:15:28 <fasta> Cale: I would hope that those people just become Debian maintainers.
10:15:37 <fasta> Cale: Isaac Jones is listed as maintainer.
10:16:01 <Cale> yeah, there's an experimental repo for Haskell packages which has newer stuff I think
10:16:53 <therp> cale: I will have to stare a few holes into this grey wall in front of me, I guess. My intuition tells me that this evaluation result can't be derived from the evaluation rules -- is there a lambda calculus extention that has pattern matching? -- and also I think it illegitimate to probe the results and therefore judge the overall form. but I can't find any arguments against, so I guess I have to accept that for a while (at least
10:16:53 <therp> until there have a few holes!)
10:17:47 <Cale> therp: it can be, obviously, as lambdabot implements the evaluation rules
10:17:48 <fasta> config.status: executing ultra-evil commands
10:18:00 <therp> cale: actually, it's not a real major issue, maybe only a strange side-effect where usually physics laws doesn't apply as we get closer to the diverging calculation singularity
10:18:02 <Cale> but note that the spec doesn't say how to evaluate Haskell
10:18:26 <therp> cale: thank you very much for explaining (length . take 2) .. that helped a lot
10:18:51 <Cale> but a sane evaluation rule is to expand the *outermost* function first
10:19:41 <Cale> Let's actually do it, because I think it will be informative :)
10:20:09 <Cale> length (take 2 (undef : undef : undef))
10:20:13 <Cale> well,
10:20:16 <Cale> length [] = 0
10:20:22 <Cale> length (x:xs) = 1 + length xs
10:20:36 <Cale> so we need to know if (take 2 (undef : undef : undef)) is [] or (x:xs)
10:20:40 <therp> cale: I'm not taking about the length take example!
10:20:46 <therp> cale: that's perfectly clear to me!
10:20:48 <Cale> okay
10:21:11 <therp> cale: I'm talking about the particular evaluation result _|_:_|_:_|_.
10:21:16 <Cale> okay
10:21:32 <Cale> (\ ~(x:xs) -> x : x : xs) undef
10:21:34 <Cale> in that case?
10:21:38 <Philippa_> _|_ isn't a crash. *Evaluating* _|_ is a crash
10:21:40 <therp> yes :)
10:22:09 <Cale> that evaluates to something along the lines of
10:22:13 <emk> Hello! Does anyone know what the first paper on using monads for logic programming was? I'm aware of "Replacing failure with a list of successes" (which is premonadic), but after that, nothing until after 2000 or so.
10:22:27 <Cale> let x = head undefined; xs = tail undefined in x : x : xs
10:22:40 <Philippa_> emk: it was folklore for a long time
10:22:43 <fasta> Philippa_: I extended the parser a larger language and that also went very smoothly.
10:22:44 <Cale> obviously, x and xs here are both _|_
10:22:51 <therp> philippa: _|_:_|_:_|_ can only be concluded if we matched (x:xs) against _|_ successfully in the past. that can never be that case, as there is no plausible past for _|_:_|_:_|_ .. it can't be the result. that's my logic (flawed maybe)
10:22:51 <Philippa_> fasta: cool
10:22:57 <Philippa_> therp: no, it can't
10:22:59 <Cale> because head and tail of undefined are not defined
10:23:13 <Philippa_> in fact, those _|_s are the result of pattern-match failure
10:23:17 <fasta> Philippa_: only now, I have a bit of a problem with probably a bug in ghci
10:23:35 <Cale> Philippa_: you're aware of the result we're talking about?
10:23:54 <Cale> oh, silly me, I just typed the expression :)
10:24:02 <Philippa_> think of it as x:x:xs where x = case undef of (y:ys) -> y; xs = ... (much the same)
10:24:17 <Philippa_> when it finally forces that case, it evaluates to _|_
10:24:37 <emk> Philippa_: So there's really nobody to cite besides the pre-monadic Wadler stuff?
10:25:01 <Philippa_> emk: that I'm aware of paper-wise. There're discussions on mailing lists, probably some in here as well
10:25:10 <therp> cale: why isn't it plausible to argue that (let x = head undefined; xs = tail undefined in x : x : xs) => undefined?
10:25:19 <Philippa_> or you can just describe it as folklore - we know about the list monad, so we had non-determinism and then logic variables were something to try hacking in
10:25:34 <Cale> because that value behaves differently from undefined when you apply various functions to it
10:26:00 <Cale> if f x is not the same as f y, then x cannot be the same as y
10:26:06 <Philippa_> right, you can munch the two cons cells (although not the items associated with them) at the start safely
10:26:07 <therp> cale: is it actually "ok" (by whatever means) to view "x = head undefined => undefined" as an evaluation "on it's own right" that won't cause an exception to abort the whole evaluation?
10:26:31 <Cale> the definition that x = head undefined there isn't used until x is demanded
10:26:47 <Cale> if we never look at x, then the head undefined is never evaluated
10:26:49 <Philippa_> so you can pass x around as much as you like
10:27:01 <emk> Philippa_: Thanks! I was surprised to not find something specific in the literature. Usually the Haskell hackers are pretty good about getting published. :-)
10:27:06 <therp> cale: but we are obviously (in a very human way) demand that calculation by writing the result to paper or irc
10:27:15 <Philippa_> emk: a specific result's actually quite a lot of work
10:27:25 <Philippa_> therp: no, we're not
10:27:33 <Philippa_> we're demanding the outermost function
10:27:40 <Philippa_> that may or may not demand stuff on the inside
10:27:52 <Philippa_> (actually it's the outermost /value/ - it may or may not be a function but functions're a bugger to print)
10:27:55 <Cale> well, as humans, we're evaluating the thing as much as possible, and sticking _|_ in the holes where we know we can't evaluate without failing
10:28:09 <emk> _The Reasoned Schemer_ is actually the best presentation I've seen.
10:28:19 <Cale> obviously, a machine can't do that too easily :)
10:28:51 <Philippa_> emk: making it all type nicely in Haskell's actually been quite tricky, the typical level of type-fu in the 90s was much less
10:29:06 <Cale> but you could actually use some very dirty hacks to write an undefined-tester in GHC. (Wouldn't catch infinite loops of course, but things which specifically raised that exception)
10:29:09 <Philippa_> right, unless you actually defined it that way with undefined
10:29:21 <Philippa_> right, catching pattern-match failure's doable
10:29:30 <Philippa_> and it's *very* doable from the IO monad
10:30:11 <therp> cale: I would agree that that is the best result we could obtain.. let me rephrase my question, wouldn't it be valit to derive _|_ as result too? it would be weaker than your result, but wouldn't the evaluation rules allow that too?
10:30:20 <Philippa_> no, they wouldn't
10:30:28 <Cale> no, Haskell is non-strict
10:30:40 <Philippa_> they specifically don't in order to ensure that you can always get that best result
10:30:44 <emk> Philippa_: I can believe that. Most of the Haskell type-checkers from the late 90s seem well-aware of the basic technique, even if they don't try to arbitrarily generalize it. Thanks again!
10:30:54 <Cale> basically, if any evaluation *can* succeed under *some* order of evaluation, then it *must* succeed
10:31:07 <Philippa_> emk: right, there're plenty of monomorphic unification monads out there
10:31:40 <Cale> so, for instance, forcing one of those undefined values, and causing the whole expression to become undefined is not allowed
10:32:28 <therp> cale: I'm arguing that the evaluation "let f ~(x:xs) = x:x:xs in f undefined => undefined" can succeed.
10:32:48 <emk> Philippa_: Is the generalization to arbitrary types at all similar to (say) the way newSTRef allocates typed variables?
10:32:51 <int-e> therp: the result is distinguishable from undefined.
10:33:15 <int-e> therp: so it must be a different value.
10:33:18 <therp> cale: it would be weaker than your result and the evaluation order should never do so, but wouldn't it be possible draw such a deviation tree?
10:33:30 <Cale> not really
10:33:50 <Cale> unless you're permitting that undefined to end up being refined to undefined : undefined later
10:34:02 <Cale> but that's a confusing way to look at it
10:34:43 <therp> > let f ~(x:xs) = x:x:xs in f undefined
10:34:44 <lambdabot>  Add a type signature
10:35:35 <Philippa_> emk: it'd require something akin to ST in general, yeah
10:36:09 <Philippa_> well, I don't know about with GADTs - it's definitely possible to write the ST monad as pure code in GHC's new intermediate language
10:36:46 <therp> > let f ~(x:xs) = (x:x:xs::[Int]) in f undefined
10:36:48 <lambdabot>  Undefined
10:37:11 <Philippa_> were you expecting that?
10:37:11 <therp> in some ways lambdabot seems to positively confirm my question whether this deviation is possible :)
10:37:30 <Philippa_> nope, there you've directly requested the entire list by trying to print it
10:37:56 <therp> philippa: why should I be not allowed to do so?
10:37:58 <Philippa_> and printing it tries to translate it to a string, and /that/ will have failed
10:38:17 <Heffalump> Philippa_: pure code in what sense? You could implement ST in pure Haskell if you weren't bothered about the runtime in-place updates, surely?
10:38:31 <Philippa_> Heffalump: it's not typable in H98
10:38:34 <int-e> > let f ~(x:xs) = (x:x:xs::[Int]) in head $ show $ f undefined
10:38:36 <lambdabot>  '['
10:38:50 <basti_> looool
10:38:54 <emk> ?type runST
10:38:55 <basti_> int-e: you're sick
10:38:55 <lambdabot> Not in scope: `runST'
10:38:58 <Heffalump> ah, ok
10:39:05 <int-e> > let f ~(x:xs) = (undefined::[Int]) in head $ show $ f undefined
10:39:06 <emk> ?type Control.Monad.ST.runST
10:39:06 <lambdabot>  Undefined
10:39:07 <lambdabot> forall a. (forall s. GHC.ST.ST s a) -> a
10:39:19 <fasta> Hugs needs a lot of help to understand my code :(
10:39:32 <SamB> > undefined : undefined
10:39:34 <lambdabot>  Add a type signature
10:39:38 <emk> Heffalump: The nested forall isn't Haskell98-friendly.
10:39:38 <SamB> > undefined : undefined :: [()]
10:39:40 <lambdabot>  Undefined
10:39:47 <SamB> hmm
10:39:56 <Philippa_> emk: it's worse than that, you need to maintain a polymorphic map
10:40:09 <SamB> > take 0 undefined :: [()]
10:40:11 <lambdabot>  []
10:40:13 <Philippa_> and that's not typeable in H98+rank-n polymorphism
10:40:15 <emk> Philippa_: Yeah, and that's several different flavors of ugly.
10:40:36 <Philippa_> yeah? Personally I don't think it's too bad in Fc
10:40:37 <therp> however, I think I will continue to read the haskell report, thanks again cale, int-e, philippa for participating in this really interesting discussion
10:40:46 <fasta> Hmm, Hugs does detect the loop(?) in my program...
10:40:48 <Heffalump> I don't quite see what GHC's new intermediate language has to do with it, though
10:41:12 <SamB> Philippa_: are you talking about @let?
10:41:12 <Cale> therp: let me give you a cool little module
10:41:14 <int-e> basti_: it's the same trick as using ghci to look where the 'Undefined' error occurs.
10:41:22 <therp> cale: ok :)
10:41:30 <Cale> lisppaste2: url
10:41:31 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
10:41:51 <Philippa_> coercions - which're sufficient to recover the type of a value in a cell from its reference (which'll carry the coercion)
10:42:01 <emk> Philippa_: Are there good papers on typing polymorphic maps?
10:42:12 <lisppaste2> Cale pasted "definedness tester" at http://paste.lisp.org/display/27550
10:42:25 <Philippa_> emk: not specifically, that I'm aware of
10:42:31 <Cale> this is the dirty hack I was mentioning :)
10:42:40 <Cale> So now if you type something like
10:42:50 <SamB> Cale: using seq and Control.Exception?
10:42:54 <Cale> SamB: indeed
10:43:05 <SamB> I haven't looked yet ;-)
10:43:37 <emk> Phillipa_: I can't get anywhere with "data Cell = (forall a. Cell a (Cell a -> a))", can I?
10:43:38 <Cale> *Main> (\ ~(x:xs) -> x:x:xs) undefined :: [Defined]
10:43:38 <Cale> [Undefined,Undefined*** Exception: Prelude.undefined
10:44:10 <Philippa_> emk: nope, because you just flushed away the type of the value in the cell and you need it
10:44:11 <SamB> ooooh
10:44:13 <Cale> It doesn't catch the failure of the tail to evaluate though
10:44:14 <SamB> neeaat
10:44:31 <SamB> but still!
10:44:38 <Cale> *Main> [undefined, undefined, Defined]
10:44:39 <Cale> [Undefined,Undefined,Defined]
10:44:54 <SamB> I was thinking you would just be checking if something could be reduced to WHNF
10:45:20 <Cale> if the evaluation of a value of type Defined commits a runtime exception, then it will show as Undefined :)
10:45:23 <SamB> you know, perhaps it should say "undefined" instead of "Undefined"
10:45:48 <therp> cale: hm, that's quite neat.
10:46:06 <Cale> I'm of course, abusing the evaluation mechanism of Haskell to do this :)
10:46:16 <SamB> how long has paste.lisp.org had paren matching?
10:46:25 <vincenz> no idea
10:46:30 <vincenz> but it's fancy and multicolored
10:46:33 <vincenz> great for lispish languages
10:46:33 <SamB> yes I see
10:46:37 <Cale> unsafePerformIO is a hook into the runtime system which basically lets you do anything at all
10:46:41 <SamB> how many colors?
10:46:51 <vincenz> 'many'
10:46:59 <SamB> would be cool if emacs had that ;-)
10:47:03 <emk> Philippa_: Yeah, it looks like I loose with all the obvious approaches. Is there some type system extension I should go read up on?
10:47:15 <SamB> I could use that when editing types ;-)
10:49:16 <therp> cale: the church rosser theorem isn't valid for diverging computations, isn't it?
10:49:25 <Maddas> SamB: There are such Emacs modes
10:49:33 <Maddas> (or just hacks, I'm not sure which)
10:49:34 <therp> or maybe, s/cale:// - a question to all
10:50:04 <Cale> therp: basically, yeah, it says that if there is a normal form, then it is unique
10:50:06 <SamB> hmm, they use span elements with "paren" classes... http://paste.lisp.org/lisppaste.css has the CSS, I guess...
10:50:21 <Cale> but Haskell really isn't the lambda calculus
10:50:29 <SamB> only six colors!
10:50:55 <SamB> Maddas: hacks?
10:51:09 <Maddas> SamB: for Emacs  -- as opposed to an actual mode :-)
10:51:20 <Philippa_> emk: I've not sat down and worked out how to make this work with GADTs. The intermediate language I mentioned is derived from System Fc, and google shows the right thing as the first result if you google it
10:51:25 <SamB> I wouldn't expect it to be part of a mode
10:51:31 <SamB> I'd expect it to be fairly global ;-)
10:51:39 <SamB> like the ordinery paren handling...
10:51:59 <Maddas> SamB: Actually, never mind me, I was confused. I think it was a mode, but I'm not sure whether it was anything used by anyone
10:52:07 <Maddas> There were even a few different approaches to highlighting
10:52:15 <vincenz> SamB: "only 6"??
10:52:20 <vincenz> GAH
10:52:28 <dcoutts> @tell SyntaxNinja the Distribution/PreProcess/Unlit.hs is borken and has been for some time. It makes building haddock docs for HUnit fail when using cpphs.
10:52:29 <lambdabot> Consider it noted.
10:52:30 <Cale> but I suppose Church-Rosser still holds in Haskell, with the right semantics
10:52:54 <emk> Philippa_: Ah, thanks! I can take it from there.
10:53:14 <SamB> Maddas: you've hovered over parenthesized things on paste.lisp.org lately?
10:53:34 <Maddas> No.. *ducks and tries it*
10:53:36 <dcoutts> @tell SyntaxNinja it's definately the unlit code though, it can be reproduced on its own, jsut using that function. It simply breaks the code, so that haddock cannot parse it.
10:53:37 <lambdabot> Consider it noted.
10:53:42 <SamB> Maddas: why duck?
10:54:02 <SamB> I'm just saying, if you haven't, go do it so you'll know exactly what kind of paren-matching I mean ;-)
10:54:06 <Maddas> I didn't actually bother checking whether I was referring to the exact same thing as you, I just assumed it :-)
10:54:16 <dcoutts> @tell SyntaxNinja although that code path only gets used when cpphs is being used.
10:54:17 <lambdabot> Consider it noted.
10:54:29 <Maddas> I'm familiar with the first type of colouring it had, but that isn't new.
10:54:43 <SamB> which?
10:54:47 <Maddas> Hm, the same thing.
10:54:49 <dcoutts> anyone want to help me fix Distribution/PreProcess/Unlit.hs in time for the ghc-6.6 release?
10:54:59 <SamB> Maddas: how long has it had that for Haskell?
10:55:13 <Maddas> I don't know -- I only saw it tested on Lisp/Scheme code.
10:55:20 * dcoutts has to go out now
10:55:30 <fasta> Ok, I found the bug. What a horrible one!
10:56:01 <SamB> well, I've never noticed it before, and I think it is really neat. I would like it if Emacs knew how to do that, only using point instead of the mouse cursor ;-)
10:56:53 <Maddas> SamB: Right. I think the Emacs modes/modifications which I saw doing that were brought up in the context of adding the feature to lisppaste. I don't seem to be able to find any links...
10:57:10 <therp> so, I actually think that _|_:_|_:_|_ is equal to _|_. let's us an analogy from the definition of real numbers as the collection of all limit-values of series. when _|_ is a diverging computation and x is the result of the non-converging limit-value, x=(lim n->\infty n), then in both cases the argument is invalid that when we apply functions to both results (_|_ and x) the results must change. 1+x will still be x. and actually _|_
10:57:10 <therp> :_|_ = _|_. but that's a weird though..
10:57:36 <fasta> Hugs is pretty fast, when compared to ghci, however.
10:57:50 <SamB> fasta: for running or for parsing?
10:58:03 <Cale> therp: it can't be equal, for the reason that I've explained at least twice now :)
10:58:17 <Cale> because, let's suppose that _|_ : _|_ : _|_ = _|_
10:58:18 <fasta> SamB: parsing + type checking, probably
10:58:36 <fasta> Ironically, the debugging code was causing the error...
10:58:42 <Cale> then (length . take 2) (_|_ : _|_ : _|_) = (length . take 2) _|_
10:58:54 <Cale> but then 2 = _|_
10:59:18 <therp> cale: right, there is something missing in my analogy..
10:59:19 <SamB> Cale: you should specify 2 :: Int
10:59:27 <therp> cale: or it's wrong all together :)
10:59:28 <Cale> yes, okay :)
10:59:39 <Cale> It breaks equational reasoning to say that _|_ : _|_ = _|_
11:00:01 <Cale> so that just isn't a useful semantics for understanding Haskell
11:00:07 <Cale> you have to treat them as different
11:00:11 <Cale> : is non-strict
11:00:26 <Cale> If it *was* strict, then those *would* be equal
11:00:32 <Maddas> SamB: http://foldr.org/~michaelw/emacs/ has some, um, rather adventerous-looking examples :-)
11:00:34 <lambdabot> Title: michaelw's Emacs Hackery
11:00:58 <fasta> It seems Hugs needs more type annotations than ghc.
11:01:26 <therp> cale: 1+x = x does also break a few things in real number mathematics.. but when we see that x is a limit-value of a non-converging series (similar to diverging computations) these things start to make sense..
11:02:01 <Philippa_> but we don't have limit values
11:02:03 <Cale> there is no real number for which 1 + x = x
11:02:12 <therp> cale: sure, infinity
11:02:19 <Cale> no, that's not a real number
11:02:26 <SamB> Maddas: the parens are conspicuously absent!
11:02:28 <fasta> Isn't there software that automatically adds type annotations to all top-level values?
11:02:41 <fasta> That would be a practical porting tool.
11:02:43 <therp> cale: I think so. if I recall the definition of real number correctly.. as the set of all possible limit-values of series
11:02:55 <Cale> of *Cauchy* sequences
11:03:13 <Cale> there's no Cauchy sequence of rationals which is unbounded
11:03:29 <Maddas> SamB: Indeed, he replaced them by colours completely. IIRC, lisppaste initially coloured the entire expressions too, not just the parens. (But that was changed rather soon, I believe)
11:03:49 <SamB> Maddas: probably as soon as they figured out how?
11:03:56 <Cale> every real number will have a rational number larger than it
11:04:01 <SamB> maybe not.
11:04:02 <Cale> (and smaller than it)
11:04:20 <int-e> (but not both at the same time)
11:04:25 * SamB is thinking about the :hover -based coloring they have right now
11:04:27 <Maddas> SamB: Hah, perhaps (I think it was intended, though).
11:04:44 <weitzman> @quote math
11:04:44 <lambdabot>  2^20 ~= 10^6
11:05:04 <Cale> I mean strictly larger, and strictly smaller in this case, but of course they can't be the same number
11:05:22 <therp> cale: I can remember for sure that my math professor scribbled that definition on the blackbord. maybe it's not real numbers, but there is a set for sure that includes all limit-values; not only those of cauchy sequences.
11:05:42 <Cale> Well, that wouldn't be the reals :)
11:06:05 <Cale> In haskell, we do have some things, like values xs such that 1 : xs = xs
11:06:19 <weitzman> therp: That might be a topology definition of some kind?
11:06:27 <Cale> but in this case, _|_ and _|_:_|_ are not the same
11:06:48 <Cale> and neither is the solution to xs = _|_ : xs
11:06:49 <SamB> Maddas: see, they nest spans of class "paste" inside the parens (which are in spans of class paren[1-6])
11:07:09 <jammaj> So, does anyone have a favorite document on writing/understanding monads??
11:07:20 <therp> http://mathworld.wolfram.com/AffinelyExtendedRealNumbers.html that seems to be that set
11:07:22 <lambdabot> Title: Affinely Extended Real Numbers -- from Wolfram MathWorld, http://tinyurl.com/gouxp
11:07:55 <SimonRC> jammaj: I understood them by reading the library docs, then trying to use them, and repeat.
11:07:57 <Cale> jammaj: well, if you haven't seen my tutorial, I recommend it :)
11:08:07 <therp> just one thing, am I supposed to private message the long url to lambdabot for tinyurl-ification?
11:08:19 <Cale> It's called Monads as Containers
11:08:21 <Philippa_> I really should finish off the one I had on writing monads
11:08:26 <jammaj> Cale: ok
11:08:33 <SamB> ndm: why do I have three files in _darcs/inventories where the Yhc repo has only one?
11:08:44 <ndm> SamB, no idea...
11:09:10 <SamB> is it because I ran "darcs optimize --reorder"?
11:09:13 <Cale> jammaj: It doesn't really get into the practice of designing monads, but it goes part of the way to understanding how you might do it
11:09:26 <ndm> SamB, possibly - i just tagged Yhc in the main repo
11:09:52 <SamB> that still doesn't explain why the repo only has one of them
11:10:03 <SamB> you are supposed to get *more* when you tag, not *less*
11:10:11 <SamB> (aren't you?)
11:10:12 <ndm> i tagged very recently
11:10:16 <ndm> in the last few hours
11:10:20 <ndm> so might be a new thing
11:10:36 <ndm> when i copied over it didn't take the old tags
11:10:40 <ndm> which might explain it
11:10:43 <SamB> it must have them
11:10:49 <fasta> How often did you port code from GHC to Hugs?
11:10:55 <Cale> therp: but anyway, the thing here is that existence of solutions to things like xs = _|_ : xs does not make an argument for _|_ being the same as _|_:_|_
11:11:07 <fasta> I am disappointed by the lack of type inferencing in Hugs.
11:11:46 <psnl> ndm: wrt hat, working on it nowish
11:12:00 <ndm> psnl: neat, on hat-gui?
11:12:13 <ndm> we're moving to darcs in the next week or so
11:12:15 <Cale> the solution to xs = _|_:xs has the property that for every n,  (length . take n) xs = n and xs !! n = _|_
11:12:15 <psnl> aye
11:12:19 <ndm> and i want to reoganise the repo
11:12:23 <ndm> what have you done to hat-gui?
11:12:34 <Cale> no other list has that property.
11:12:41 <psnl> ndm: for hat? that saves me making one ;-)
11:12:51 <psnl> ndm: nothing big yet, sorry
11:13:01 <Cale> therp: does that make sense? :)
11:13:04 <ndm> psnl: what are you hoping to do?
11:13:19 <ndm> psnl: just so that the stuff i look into doesn't duplicate work
11:13:28 <Cale> therp: the better analogy is ordinal numbers
11:14:06 * monochrom jumps up and down on ordinal numbers
11:14:13 <Cale> therp: where you have things like omega, which is the smallest ordinal which is greater than all the naturals
11:14:19 <Cale> and then omega + 1, which is separate
11:14:27 <Cale> it's the successor of omega
11:14:27 * weitzman has discovered that there is a mathematical set known as the surreal numbers, and is amused
11:14:37 <Cale> weitzman: yeah, they are amusing
11:14:48 <Cale> though they aren't a set :)
11:14:55 <Cale> they're a proper class
11:15:04 <therp> cale: yes it does. maybe the difference is that mathematics does not know an evaluation order. laws like \infty+x = \infty are valid, because there are no partial results or computations that are not needed as in (length . take 2). that's the point where this analogy breaks down I think
11:15:06 <weitzman> Are there too many to fit in a set?
11:15:10 <Cale> yeah
11:15:20 <therp> cale: yes it does referring to "does that make sense"
11:15:32 <psnl> ndm: the short answer is port the sort of tools already created to a gui interface
11:15:33 <Cale> well, Haskell has a semantics such that it doesn't know an evaluation order
11:15:48 <ndm> psnl: splitting them into a library and doing it that way?
11:15:49 <Cale> well, sort of :)
11:15:54 <psnl> ndm: yeah
11:15:56 <ndm> psnl: and which ones were on your "hit list"?
11:15:56 <Cale> some evaluation orders are bad :)
11:16:16 <ndm> psnl: i agreed to do a port of hat-check, hat-pretty and hat-delta with Bob
11:16:26 <ndm> psnl: although if you want to do any of them, i'll let you do it
11:16:29 <Cale> but if there is an evaluation order which will produce a defined value for some expression, then the evaluation must result in that value.
11:16:44 <ndm> and i can keep them separate until after your project is done
11:17:02 <Cale> and any evaluation order which produces that defined value consistently is okay.
11:17:46 <therp> cale: "normal order" guarantees these properties, right?
11:17:51 <Cale> So, for instance, you could do something like alternating between outermost and innermost evaluation (and skipping user-defined errors until the last moment)
11:17:53 <Cale> yes
11:18:10 <psnl> hat-stack, hat-cover, hat search and hat detect
11:18:12 <Cale> Outermost-first (normal order) evaluation will always work, if any order does
11:18:24 <ndm> psnl: hat-search?
11:18:31 <ndm> hat-stack and hat-cover are already done
11:18:45 * psnl kicks himslef
11:18:56 <psnl> hat-observe
11:18:59 <Cale> and lazy evaluation is outermost-first, together with the optimisation that if two parts of an expression came from the same bound variable, then when one is evaluated, the result will be shared
11:19:04 <ndm> ah, neat :)
11:19:08 <ndm> hat-delta == hat-detect
11:19:11 <ndm> so i won't do that one
11:19:18 <psnl> thanks
11:19:19 <Cale> and lazy evaluation is what most Haskell implementations use, with some small devices to control it
11:19:22 <ndm> but i do have an agreement with Bob for him to write an API for hat-detect
11:19:35 <ndm> so you can use that, GUI it up etc, but he'll do that API
11:19:40 <psnl> thanks
11:19:59 <psnl> I also want to write some new tools, mainly based on monad stuff
11:20:03 <ndm> are you going to keep checking your things into the hat darcs? (once it exists?)
11:20:05 <jammaj> I think seq and monads are my two major mental hurdles for haskell
11:20:18 <ndm> thats fine, new monad tools won't effect anything that i do
11:20:27 <psnl> ndm: will do
11:20:38 <ndm> people want to put out a hat release before christmas, so anything you have done by then can get in the next release
11:20:46 <ndm> particularly hat-observe in hat-gui would be really handy :)
11:20:58 <psnl> ndm: I have a local repo of code, but its better to keep it togethert
11:21:04 <ndm> indeed :)
11:21:19 <psnl> ndm: I hope to be finshed by christmas, howwise I may be f*cked
11:21:49 <ndm> cool, well good luck :)
11:22:06 <ndm> i'll contact you as soon as bob gets to me with a hat-detect API
11:22:17 <psnl> thanks
11:22:20 <ndm> if i was to add new tools to the GUI entirely separate from you, would that harm your project in any way?
11:22:29 <ndm> i.e. if i shove in hat-pretty and hat-check as tools
11:22:32 <Cale> So, for instance, if we have that square x = x * x, and we evaluate square (square 5), then evaluation proceeds like: square (square 5) => let y = 5 * 5 in square y => let y = 5 * 5 in y * y => let y = 25 in y * y => 25 * 25 => 625
11:22:40 <ndm> on separate tabs, with no interaction
11:22:45 <psnl> I'll be working on it next week
11:23:00 <Cale> where I've used let to show the sharing that's going on
11:23:04 <ndm> i'm more thinking for assessment purposes
11:23:12 <psnl> ndm: I'll ask paul wrt the uni rules, but I think as long as a vcs is used it should be fine
11:23:14 <Cale> otherwise, it would look like
11:23:14 <ndm> as i guess its important for you to show whats yours, and whats not
11:23:19 <psnl> yes
11:23:40 <ndm> psnl: thanks, let me know what he says, but i'll try and keep a very hands off approach til you finish
11:23:44 <Cale> square (square 5) => square 5 * square 5 => (5 * 5) * (5 * 5) => 25 * 25 => 625
11:23:48 <ndm> (which is entirely the way open source is not meant to work!)
11:23:50 <SamB> ndm: actually I have four now...
11:23:58 <ndm> SamB, they're breeding :)
11:24:00 <psnl> thanks
11:24:01 <Cale> therp: that should make sense, I think?
11:25:14 <SamB> hmm
11:25:34 <Cale> therp: is that cool?
11:26:01 <ndm> SamB, if you ask in #darcs they can probably tell you
11:26:11 * SamB cds out of the fptools repo before he messes something up
11:26:34 * ndm -> food
11:26:36 <SamB> oh, I wgot the "email" and "author" files in _darcs/prefs from the other repo ;-)
11:28:51 <fasta> Ok, done porting.
11:29:42 <Cale> therp: It may help to actually understand how evaluation proceeds in a practical Haskell implementation. The data representing undefined and undefined : undefined are quite different.
11:29:47 <shahn> hi!
11:29:52 <Cale> shahn: hello!
11:29:58 <shahn> i tried to use hsffig
11:29:58 <fasta> My application could be ported almost automatically from GHC to Hugs.
11:30:29 <shahn> and to ocnvert the out (.hsc) to haskellcode with hsc2hs
11:30:38 <shahn> but i get errors:
11:31:00 <shahn> JACK.hsc:318: error: syntax error before ‘}’ token
11:31:05 <fasta> So, if anyone wants a "project": build a tools that finds the types for all top-level identifiers and add them to the source when they are not available.
11:31:14 <fasta> tool, even
11:31:15 <shahn> JACK.hsc:318: error: void value not ignored as it ought to be
11:31:34 <shahn> and a lot of them
11:31:40 <shahn> any advice?
11:31:50 <shahn> using hsffig1.0
11:32:45 <Cale> shahn: hmm
11:32:53 <Cale> I recommend posting to Haskell-cafe
11:33:19 <shahn> ok
11:33:24 <Cale> because I think the author of that tool reads it -- you could also ask golubovsky at gmail dot com directly
11:33:38 <shahn> ok
11:33:44 <shahn> will try that
11:34:48 <SamB> fasta: heh
11:35:16 <fasta> SamB: oh, I have no real use for it anymore, since I manually ported it.
11:35:17 <SamB> fasta: too bad it couldn't contract type synonyms where appropriate, or I might even be able to use that tool ;-)
11:36:37 <SamB> ndm: how come I don't see any recent tags by you?
11:36:51 <fasta> SamB: oh, right, that would be nice too.
11:37:41 <lightstep> how can i convert a producer to a lazy list, like IO (Maybe a) -> [a]?
11:38:00 <mauke> you can't get rid of IO
11:38:01 <SamB> unsafeInterleaveIO
11:38:12 <LiquidEngineer> wow
11:38:16 <LiquidEngineer> that sounds impressive
11:38:16 <shahn> Cale: oh, i forgot to pass -t template-hsffig.h to hsc2hs
11:38:23 <dcoutts_> mauke, you shouldn't get rid of IO ;-)
11:38:29 <SamB> LiquidEngineer: well, mainly it is just dangerous
11:39:04 <lightstep> SamB, how lazy is it? do i need unsafeInterleaveIO for every cons?
11:39:18 <dcoutts_> lightstep, yes
11:39:52 <SamB> dcoutts: oh, someone expressed concern regarding lazy bytestring input and SMP?
11:39:54 <dcoutts_> lightstep, eg look at the ByteString.Lazy code, or the zlib binding
11:40:05 <dcoutts_> SamB, yes, that was me :-)
11:40:15 <SamB> wouldn't those concerns be equally valid WRT ordinary lazy input?
11:40:35 <dcoutts_> SamB, possibly, I'm really not sure
11:40:49 <dcoutts_> SamB, I don't understand the mechanism enough, I need to ask JaffaCake
11:41:09 <lightstep> stream action = action >>= maybe (return []) (unsafeInterleaveIO . stream action) -- something like this?
11:41:09 <dylan> does haskell have a FUSE binding?
11:41:21 <SamB> dcoutts: well, I mean, unsafeInterleaveIO isn't going to be any safer than whatever you are using, is it?
11:41:48 <monochrom> IO (Maybe a) is a type of producers?  I don't understand.
11:41:53 <dcoutts_> SamB, right, we use a combination of unsafeInterleaveIO and unsafePerformIO and even inlinePerformIO
11:42:14 <dcoutts_> monochrom, it gives you an 'a' or Nothing each time you run it
11:42:19 <dylan> n/m, found hfuse.
11:42:20 <lightstep> monochrom, each time you call it, it gives you a new value. until the last time, when it returns Nothing
11:42:23 <dcoutts_> that allows you to unfold a list
11:43:03 <monochrom> OK, one can write f :: IO (Maybe a) -> IO [a], and in f you use unsafeInterleaveIO.
11:44:16 <dcoutts_> right, and then you could use unsafePerformIO at the top level
11:44:31 <dcoutts_> this is essentially what goes on in the lazy bytestring code
11:44:42 <dcoutts_> it's not that easy to get right
11:44:47 <monochrom> Is that safe?
11:44:54 <dcoutts_> so I have a monad now to do it
11:44:58 <lightstep> will this allow the list to be fused with its consumer?
11:44:59 <yip> ghc releases are not binary compatible, so if i update ghc, i have to recompile all of the libraries i've installed?
11:45:04 <dcoutts_> monochrom, it depends on what IO you are doing
11:45:13 <dcoutts_> yip, yes
11:45:29 <dcoutts_> monochrom, so, no it's not safe in general
11:45:45 <dcoutts_> lightstep, no
11:45:53 <yip> dcoutts: what if i'm using ghc-6.6 darcs branch. everytime i update my darcs i have to recompile all my libraries?
11:46:08 <dcoutts_> lightstep, the only fusable things are those that are expressed in terms of fusable primitives
11:46:26 <dcoutts_> yip, theoretically yes
11:46:45 <dcoutts_> yip, in practice you can often get away with not doing
11:47:59 <yip> dcoutts: wow, that's pretty rough. does ghc have the goal of eventually reaching some sort of state where binary compatibility will be maintained between releases?
11:48:07 <lightstep> dcoutts_, the fps docs have a bug in the beginning of the low level section - the heading comes before the docs for sortBy
11:48:09 <dcoutts_> no
11:48:28 <dcoutts_> lightstep, feel free to send in a patch
11:49:00 <yip> dcoutts: is the reason that there is no such goal because it is deemed too difficult?
11:49:33 <dcoutts_> yip, no, mostly because it'd prevent many performance opportunities, like cross-module inlining
11:49:56 <dcoutts_> you really really want to be able to inline map for example
11:51:37 <lightstep> if my function isn't fusable, does that mean that functions like getContents aren't? and that every program that uses them will allocate the whole string?
11:51:52 <dcoutts_> it's not strict
11:52:03 <dcoutts_> it doesn't allocate the whole string at once
11:52:28 <dcoutts_> but yes it will allocate each cons cell
11:52:33 <dcoutts_> that's what fusion eliminates
11:52:52 <dcoutts_> and getContents isn't fusable
11:52:59 <lightstep> so it's of the same complexity, but slower?
11:53:11 <dcoutts_> right
11:53:40 <lightstep> cool
11:54:08 <SamB> dcoutts: are you talking about Prelude. or Data.ByteString.Lazy. ?
11:54:18 <dcoutts_> SamB, prelude
11:54:28 <dcoutts_> SamB, but actually it applies to both
11:54:50 <dcoutts_> getContents isn't fusabile under either system
11:55:08 <dcoutts_> but actually, it's not clear what a fusable ByteString.Lazy.getContents would be
11:55:24 <dcoutts_> since you really do need to get the OS to copy the data into a buffer
11:55:51 <dcoutts_> so there's not much you can eliminate
11:59:36 <lispy> dcoutts_: does cabal havee any more verobes output that --verbose?
11:59:58 <dcoutts_> I think there is -v1 .. -v5
12:00:00 <lispy> dcoutts_: if not, it may help with debugging...seems like it's hiding a lot of information even with --verbose
12:00:15 <lispy> it seems like i tried those before
12:00:19 <lispy> i know ghc supports those
12:00:42 <lispy> one thing that would be nice is to see the explicit commands that are being run
12:00:48 <dcoutts_> lispy, sorry, I can suggest looking at the code
12:00:53 <lispy> but maybe ghc is the one hiding
12:00:58 <lispy> :)
12:01:07 <dcoutts_> lispy, mostly for external commands that are run, cabal will report them with -v
12:01:34 <lispy> i see, so i wonder then if ghc is the one not reporting all the 'commands' used
12:02:01 <lispy> i only mention it because of your email about the RC and the problem I was having with linking...
12:02:08 <lispy> seems like in both cases, maybe more output would help
12:02:45 <dcoutts_> yes, it probably would
12:02:57 <dcoutts_> logging is one of the areas in cabal that could do with some refactoring
12:03:07 <dcoutts_> I'm seeking volunteers
12:03:20 <lispy> :)
12:03:24 <lispy> i can't this weekend :(
12:03:31 <lispy> but i should look at it
12:03:40 <lispy> i would appreciate better logging
12:04:10 <lispy> actually, i think haskell could probably use a nice general purpose logging facility...perhaps something built on to of Debug.Trace but understands verbosity levels
12:04:12 <yip> is there some sort of script i need to run for modifying file permissions after checking out ghc darcs? because during make i get an error that rts/gmp/configure is not executable, and it indeed is not
12:04:13 <dcoutts_> I'd really like to see cabal's internal code structre move in the direction of separation between the code that decides what needs to be done, and actually doing it
12:04:36 <dcoutts_> lispy, no need for that, just generate the list of things to be done
12:04:48 <dcoutts_> lispy, eg a writer monad
12:05:02 <lispy> yip: when you 'get' the repository you can run --make-scripts-executable but it's a hack...i'd say just chmod the file...
12:05:02 <reilly> can anyone give me a quick tip on compiling 6.6?  I have a working build of ghc-6.5.20060724, but when I use it to build 6.6 (from darcs) it fails because it can't find the package regex-compat.  I assume this is because 20060724 predates the library re-org.  Is there an easy way to fix this?
12:05:04 <waern> lispy, there are lots of logging libraries around, e.g. in missingH
12:05:21 <lispy> dcoutts_: the writter monad has bad performance with strings though
12:05:24 <dcoutts_> reilly, use ghc-6.4.2 to build
12:05:32 <lispy> waern: oh, cool
12:05:36 <reilly> i can't.  I am on an intel mac
12:05:43 <dcoutts_> lispy, then use lists of strings
12:06:06 <dcoutts_> reilly, you'll have to ask one of the other intel mac users, sorry
12:06:06 <yip> lispy: alrighty then thanks!
12:06:15 <MarcWeber> I want to send some data using method=post using httplib. I specify the body when creating the request. Do you know a lib to create the multipart body?
12:06:48 <lispy> yip: some work was started to fix this aspect of darcs but i don't think it made it into a stable release yet :(
12:08:21 <lispy> dcoutts_: one reason for doing it on top of Trace.Debug is that it would behave correctly in windows :)
12:08:36 <lispy> dcoutts_: Debug.Trace is the only output library which seems to be safe there...
12:08:43 <dcoutts_> lispy, Trace.debug should not be used for anything serious
12:08:50 <lispy> writing to stdout can cause your program to cash
12:08:52 <lispy> er crash
12:09:00 <lispy> well, they have a non pure trace function
12:09:10 <lispy> i'd say emphasize that instead of 'trace'
12:09:29 <dcoutts_> I'm sure you can use something that also uses the win32 debug output method
12:10:01 <lispy> yeah, i need to see how Debug.Trace is implemented some time..
12:12:02 <int-e> hmm. trace = seq . unsafePerformIO . putStrLn ?
12:12:27 <lispy> int-e: not on windows, just because putStrLn can make a program crash if stdout is not available
12:12:51 <lispy> int-e: but i bet that's the basic idea
12:13:22 <Heffalump> I think trace uses stderr
12:13:30 <int-e> hmm, it has its own function to do it, and the use unsafePerformIO with a final return
12:13:54 <int-e> in ghc trace uses 'debugBelch' from the RTS.
12:14:07 <lispy> nice
12:14:13 <Heffalump> hehe
12:14:18 <lispy> i should look at missingH as waern suggested
12:14:26 <lispy> what i want may already exist :)
12:15:04 <lispy> the first time i ran my program without the console in windows i was pretty confused as to why it kept crashing
12:15:20 <lispy> turns out i used 'print' to log to the screen
12:16:08 <lispy> it's amazing how little things like that can confuse you for a long while
12:16:26 <lispy> it's trivial and stupid, yet a huge waste of time if it catches you at the wrong moment
12:17:11 <yip> after i succesfully complete the "make" step of compiling ghc. i can safely delete my old version of ghc, and "make install" will still work, right?
12:18:13 <lispy> i'd try to keep the old one around for a while just to be safe, but really i'm not sure
12:29:16 <dcoutts_> xerox, yay, I've got the L-System stuff drawing ok using HOpenGL
12:29:29 <dcoutts_> xerox, so extending the practical to 3D will now be easy
12:29:55 <dcoutts_> HOpenGL + Gtk2Hs == coolness
12:30:13 <yip> dcoutts_: what about gtk2hs + ghci?
12:30:28 <dcoutts_> yip, aye, that's a pita
12:30:41 <yip> dcoutts_: is there a light at the end of the tunnel?
12:30:48 <dcoutts_> yes, I've said so before
12:31:24 <weitzman> Darcs needs to be more verbose
12:31:36 <weitzman> I used to think it was hanging and ssh wasn't working
12:31:44 <weitzman> But it's apparently doing something
12:31:49 <weitzman> Because a file is growing
12:36:31 * dylan always uses strace before determining what is hanging in a process. :)
12:37:01 <weitzman> I don't know what strace is, but I"m betting my OS doesn't have it
12:37:21 <lightstep> weitzman, you use windows?
12:37:23 <ndm> SamB, i did the tag in Tom's name
12:37:31 <weitzman> lightstep: I do indeed
12:37:36 <SamB> ndm: Ah.
12:37:37 <lightstep> or vax?
12:37:49 <ndm> SamB, by accident, of course :)
12:38:06 <weitzman> Although I like to imagine an alternate reality where everyone is using Plan 9
12:38:49 <SamB> ndm: ... of course!
12:38:52 <SamB> by accident.
12:39:08 * SamB tries to figure out how that can be done by accident
12:39:09 <ndm> i logged into haskell.org to do it, and Tom is set up as teh default author
12:39:23 <SamB> oh, oops
12:39:39 <SamB> is that what that thing is for...
12:39:52 * SamB rms it
12:40:42 <musasabi> yip: did you get the issues solved?
12:41:19 <yip> musasabi: i'm compiling latest version of darcs ghc-6.6
12:41:25 <yip> musasabi: have 4 hours passed?
12:42:02 <musasabi> I'm still at the party, just playing asocial for a while.
12:42:31 <SamB> ndm: you can blame me for that
12:42:51 <SamB> now if anyone does that, they'll probably have done it in *your* name by accident ;-)
12:43:19 <SamB> or perhaps neil@monk's name
12:47:23 * mux polishes his now-working rev.2d
12:47:30 <dmhouse> Evening all.
12:47:31 <mux> Program area: 1920 (smaller is better)
12:47:53 <dmhouse> People are still working on the ICFP stuff?
12:47:59 <mux> yes :-)
12:48:11 <SamB> I ran out of RAM already, so not me
12:48:15 <mux> it's fun, I do it by small bits
12:49:29 <mux> Program area: 1920 (smaller is better)
12:49:32 <mux> oops
12:49:34 <mux> misfire :)
12:50:49 <mux> funny how I come to polish the aesthetics of my 2d modules :-P
12:51:39 <mux> mult and rev were funny, but raytrace looks more annoying
12:52:24 <aFlag> musasabi, you're accessing the irc from a party?
12:56:48 <dmhouse> Woo :) I've got the 'I fought with Linux multimedia support and won' feeling.
12:56:56 * dmhouse smiles as he listens to his M4As
12:58:14 <Lemmih> You successfully installed mplayer?
12:58:30 <gmh33> pacman -S mplayer mplayer-codec
12:58:31 <gmh33> >_>;
12:58:56 <yip> prt-get depinst mplayer
13:05:10 <jajs> damn, i can't evaluate expressions in lambdabot, got a " hClose: resource vanished (Broken pipe)" :/
13:08:51 <yip> jajs: try it in here
13:09:02 <yip> oh, you mean you can't evaluate *any* expression?
13:09:03 <gmh33> @bf .+[.+].
13:09:04 <lambdabot>  !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijk...
13:09:28 <jajs> yip, no, i can't
13:10:32 <jajs> maybe it's a problem with hs-plugins
13:16:10 <user317> is sequence lazy?
13:16:17 <jajs> ok, i figured it out :-)
13:17:09 <user317> what i mean to ask, is that sequence [io], will return a io [], so if i take the head of that, will it consume the entire list of io objects?
13:17:28 <Heffalump> user317: no
13:17:43 <user317> cool, thanks
13:17:53 <Heffalump> oh, hangon, let me think about that again
13:18:06 <Heffalump> your lower case letters confused me about what you were asking
13:18:41 <Heffalump> sorry, it would depend on the monad in question, and since IO is strict, it would also be strict.
13:19:55 <Heffalump> using unsafeInterleaveIO is one way to change that, though
13:20:49 <Igloo_> Is there another way?
13:21:32 <Igloo> (other than uPIO and doing the same things after converting to ST)
13:21:41 <user317> so sequence [IO] >>= head will consume the entire list before returning the first element?
13:22:01 <user317> basically this wont terminate if i pass a infinite list of IOs?
13:22:12 <ThreeQ> > head $ sequence $ repeat [1]
13:22:13 <lambdabot>  Exception: <<loop>>
13:22:18 <weitzman> If by "consume", you mean it would perform the complete action, "sequence [IO]"
13:22:22 <weitzman> Then yes
13:22:55 <user317> thats a bummer man
13:23:02 <Heffalump> Igloo: probably not
13:23:02 <Lemmih> user317: Lazy IO is tricky. Are you sure you need it?
13:23:18 <mauke> makes sense, though: a >>= \x -> b >>= \y -> x : y
13:23:26 <user317> lemmih, its software, there is a way around anything, just takes more work :)
13:23:50 <Heffalump> lazy IO is semantically unsound, it gives you a way of observing when things are evaluated
13:23:51 <user317> but since this is haskell, it will end up the same lines of code anyways
13:23:53 <weitzman> Well, the whole point of the IO monad is to specify the order in which things happen
13:24:00 <Lemmih> user317: Lazy IO isn't always the best solution. Are you sure it's the best solution to your problem?
13:24:02 <weitzman> So in this case it's by-design
13:24:30 <user317> Lemmih, its an elegant solution, i have a stream from a file/socket that i am processing and outputting as i process it
13:24:50 <Heffalump> you know about hGetContents?
13:25:00 <Lemmih> user317: Can't you use the normal IO functons?
13:25:04 <jammaj> Lazy IO is only inconvenient because operating systems haven't caught up to Haskell.
13:25:13 <SamB> heh
13:25:16 <Heffalump> (which uses unsafeInterleaveIO under the hood)
13:25:17 <weitzman> Maybe instead of using sequence, you want to use map followed by sequence?
13:25:50 <user317> maybe that will work
13:26:15 <Heffalump> which?
13:26:30 <user317> i dont really need to sequence, just get the first n elements
13:27:21 <Heffalump> if you are reading from a handle, why not use hGetContents and process the result functionally?
13:28:22 <user317> i am doing that, but i have to use a C library that i wrapped, and the result is IO, thats how i end up with [IO]
13:28:45 <user317> so, pull from a handle, call C, -> [IO]
13:28:51 <Heffalump> is the C library doing something pure?
13:29:47 <user317> no, its fftw
13:29:56 <user317> running the fft does io
13:30:09 <Heffalump> really? What kind of IO?
13:31:12 <user317> it does the fft inplace, so i need to marshal the data from the output array back
13:31:23 <Heffalump> ah, right
13:32:01 <user317> i was really pleasently surprised how easy it was to use the ffi with c2hs especially
13:32:02 <Heffalump> but then it's not really very safe to not know which bits were evaluated and which weren't
13:32:09 <user317> yea, its not
13:32:16 <user317> i think it has to be an io operation
13:32:36 <Heffalump> well, then it's not safe to have a list of IO actions be evaluated lazily
13:33:06 <weitzman> unsafePerformIO doesn't interleave IO, right?
13:33:15 <weitzman> Might still be reasonable to use it?...
13:33:22 <user317> why not?  they are not dependent on each other
13:33:51 <Heffalump> user317: is the only thing that reads the updated-in-place array the thing that marshals the data in and out?
13:33:58 <user317> Heffalump, yea
13:34:11 <Heffalump> in that case I suggest you wrap that function in an unsafePerformIO and make it pure.
13:34:24 <Heffalump> Cos _that_ is.
13:34:35 <user317> Heffalump, my wrapper takes an input list, marshals it, runs the fft, then marshalls the data back into a list and returns it
13:35:10 <user317> i guess, as long as those operations are done in that order, then it should be fine, and its pure otherwise
13:35:54 <SamB> user317: ... why are you using lists ?
13:35:56 <Heffalump> right, so that's the right place to put the unsafePerformIO
13:36:36 <user317> SamB, lists are easy to use, i dont need random access into the input/output
13:37:24 <user317> SamB, running a filter over the spectrum returned by the fft, requires me to read every element anyways, so its really no point to use an array
13:38:18 <SamB> hmm.
13:38:32 <Heffalump> lists are the natural Haskell datatype, you know :-)
13:38:39 <SamB> is there a way to turn a Ptr into a UArray?
13:38:42 <Heffalump> and fusion should make them efficient if everything works out
13:38:51 <mauke> why are there types for * and ? but not for +?
13:38:56 <SamB> Heffalump: it won't fuse if the list is built in IO, will it?
13:39:04 <user317> thanks for the tip, ill see if the interleaveIO thing works
13:39:31 <Heffalump> user317: I really think unsafePerformIO on your wrapper would be the best solution here
13:39:46 <Heffalump> SamB: no, but it isn't being built in IO
13:39:51 <Philippa_> <Heffalump> lists are the natural Haskell datatype, you know :-) <- nearly. They're natural with a bit extra added...
13:40:01 <SamB> Heffalump: how will it look?
13:40:05 <SamB> and how will it fuse?
13:40:13 <SamB> you said "unsafePerformIO on your wrapper"
13:40:19 <SamB> wouldn't the list be built inside the wrapper?
13:40:20 <Heffalump> Philippa_: you what?
13:40:46 <Heffalump> SamB: no, currently there is a list of IO actions, each obtained be calling the wrapper
13:40:49 <Heffalump> (AIUI)
13:41:24 <Philippa_> Heffalump: perhaps it'd work better if I wrote Natural rather than natural. The bit extra being the attached data
13:41:25 <SamB> Heffalump: that doesn't sound so great either!
13:41:52 <Heffalump> SamB: what doesn't?
13:43:13 <dmhouse> How do you get ls to follow symlinks?
13:43:59 <gmh33> dmhouse ls shows symlinks..
13:57:44 <shahn> how can i convert CFloat to Float and back again?
13:58:40 <SamB> shahn: good question
13:58:49 <Igloo> realToFrac
13:58:55 <shahn> honestly?
13:59:03 <norpan> the first question is why
13:59:28 <lightstep> ?hoogle CFloat -> Float
13:59:29 <lambdabot> No matches, try a more general search
13:59:33 <SamB> @type realToFrac
13:59:35 <lambdabot> forall b a. (Fractional b, Real a) => a -> b
13:59:43 <norpan> realToFrac, both ways
14:01:07 <shahn> so, both Float and CFloat are subtypes of Real and Fractional?
14:01:19 <SamB> shahn: not subtypes, no...
14:01:23 <SamB> instances
14:01:38 <shahn> hmm
14:04:10 <malsyned> as an exercise in understanding classes, I tried to implement a class called "Gdiv" which has only the operation `gdiv`.  I want it to be / on Fractionals and div on Integrals.  I was able to get it to work, but only by defining Integer, Int, Float and Double instances specifically.  Is there a way to attach the methods to Fractional and Integral instead of all four types?
14:04:35 <user317> using unsafePerformIO/interleaveIO feels like cheating
14:05:07 <shahn> why isn't there a function convert :: (Real a, Real b) => a -> b
14:05:18 <shahn> ?
14:05:26 <norpan> malsyned: yeah, you can do instance Integral a => Gdiv a
14:05:47 <norpan> but you're in trouble if something is both Integral and Fractional
14:06:09 <lightstep> mauke, there's Either
14:06:23 <user317> is there a way to attach a destructor to a type?
14:06:44 <lightstep> user317, check out ForeignPtr
14:06:53 <norpan> for normal types, what's the point
14:07:27 <user317> lightstep, thanks
14:08:19 <malsyned> norpan, if I try that with both Integral and Fractional, I get an overlapping instances error
14:08:50 <lightstep> there's -fallow-overlapping-instances
14:08:50 <norpan> malsyned: compile with -fallow-overlapping-instances or whatsitsname
14:09:25 <malsyned> is there a corresponding switch for Hugs?
14:09:37 <malsyned> ah.  +o.  got it.
14:10:55 <malsyned> 'cept that that didn't work.
14:12:54 <lightstep> they might be undecidable
14:16:37 <malsyned> Integral and Fractional are disjoint subsets of Num, right?
14:16:50 <SamB> *should* be
14:17:20 <malsyned> SamB, what could cause them not to be?  defining a class that inherits from both?
14:17:37 <SamB> ... no...
14:17:55 <malsyned> I'm like two days into Haskell, there's a good chance I'm misunderstanding fundamentals.
14:18:00 <SamB> writing both "instance Integral Foo" and "instance Fractional Foo"
14:18:05 <SamB> yes you are ;-)
14:18:10 <SamB> or not understanding them
14:18:27 <SamB> but thats what comes of calling those things classes, I guess
14:19:06 <malsyned> Yeah, that was an unfortunate naming choice.  I'm so busy remembering what they aren't, I haven't gotten a good enough grasp of what they are.
14:19:21 <mauke> they're interfaces
14:19:58 <SamB> I never said it was unfortunate, I just said that having people misunderstanding fundamentals is a result of the name...
14:25:10 <malsyned> Yeah, thinking of them as interfaces does help.
14:25:57 <norpan> TYPEclasses
14:26:16 <malsyned> Is it possible for a subclass to specify a different default method implementation for a function defined in its parent class?
14:26:24 <norpan> no
14:26:55 <SamB> it would *almost* be nice
14:27:01 <SamB> but only *almost*
14:27:18 <mathewm> heck, even the term "type" means something different for C programmers...
14:27:19 <malsyned> Yeah.  I've got to split, thanks for your help, guys.
14:27:20 * SamB really wishes he knew how to get rid of the *almost*
14:27:40 <malsyned> SamB, no doubt it'll bug me tonight while I'm trying to get to sleep.  thanks again.
14:27:51 <norpan> it would be horrendous; changing semantics if some particular instance was visible or not
14:28:01 <SamB> norpan: huh?
14:28:09 <SamB> norpan: nothing like that.
14:28:16 <norpan> no?
14:28:39 <SamB> take Functor, for instance.
14:29:10 <SamB> and Monad.
14:29:48 <SamB> say you have a Monad instance for your type in terms of >>= and return
14:29:58 <norpan> yes
14:29:59 <SamB> why should you have to write fmap?
14:31:00 <norpan> Monad should be a subclass of Functor, you're right there
14:31:05 <norpan> but that's another issue
14:31:14 <SamB> you'd still need to write fmap!
14:31:39 <norpan> it's not hard to write
14:32:18 <ThreeQ> why wouldn't instance Monad m => Functor m where fmap = ... work?
14:32:18 <SamB> no, but it would be nice if there was a way to make a default fmap for Monads...
14:32:40 <norpan> ThreeQ: no, not all functors are monads
14:32:56 <norpan> SamB: i don't see it as a big issue, how many monads do you write
14:32:58 <SamB> ThreeQ: it would overlap with all the other Functor instances?
14:33:06 <ThreeQ> oh, right
14:33:08 <SamB> norpan: that was just an example
14:33:44 <norpan> i agree that the type class system is not clean in all corners
14:34:49 <SamB> basically, the reason you can't do stuff like that is that it would be too unpredictable, because it would depend on what typeclasses were known to the compiler, and could have conflicts between typeclasses...
14:35:01 <SamB> well, maybe not which were known...
14:35:09 <SamB> but which instances you wrote...
14:35:18 <SamB> (and were found elsewhere)
14:36:05 <SamB> perhaps "fmap = default from Monad" would be a nice way to avoid that kind of issue...
14:36:17 <lightstep> maybe we just need finer classes
14:36:27 <SamB> finer?
14:36:32 <norpan> class aliases will solve that
14:36:40 <SamB> ah, I've heard about that before
14:36:42 <norpan> maybe
14:36:46 <norpan> :)
14:36:59 <SamB> I've often thought something of that nature might be a good idea...
14:37:07 <norpan> if i say something incoherent it's because i've had a few cognacs
14:37:16 <SamB> in case you wanted to split a class in two...
14:37:21 <SamB> where do I read about those again?
15:18:58 <dmhouse> If you use import Foo (blah), do the modules re-exported by Foo get imported?
15:20:02 <dmhouse> ?where report
15:20:03 <lambdabot> http://www.haskell.org/onlinereport/
15:20:56 <dmhouse> Or, rather, are the instances exported from modules re-exported by Foo get imported?
15:21:19 <dmhouse> I'd guess they do, as instances have an annoying tendency to propagate like that.
15:22:43 <Heffalump> I believe all instances are automatically exported.
15:24:22 <dmhouse> I'll be a bit more clear.
15:24:52 <dmhouse> Module A defines an instance. Module B imports and re-exports A. I import B. Do I get A's instance?
15:31:47 <dmhouse> Next question :)
15:32:08 <dmhouse> What's the most elegant way to say 'If x matches pattern P or y matches pattern Q, then ...'
15:32:48 <dmhouse> Pattern guards, perhaps, but 1) they have no way to express 'if this pattern or this pattern matches' and 2) they'd be the only non-H98 code in my program.
15:32:52 <SamB> dmhouse: you have to say z = ... and then refer to that later...
15:33:00 <mauke> if (case (x, y) of (P, _) -> True; (_, Q) -> True; _ -> False)
15:33:03 <dmhouse> Case expressions are going to be an awful pain.
15:33:21 <SamB> hmm?
15:33:24 <dmhouse> Hrm, mauke's approach might work.
15:33:32 <dmhouse> SamB: what do you mean?
15:33:46 <SamB> or, well, mauke's works too
15:33:52 <SamB> I've seen it in Yhc
15:33:58 * dmhouse wishes patterns were first class
15:34:12 <SamB> they bind vars, though
15:34:30 <dmhouse> I don't actually need binding here, just the reflection.
15:34:42 <dmhouse> But in general, true.
15:36:28 <mauke> argh, why did Network.Socket rename all the functions?
15:43:30 <mauke> ?pl f x = x >> f x
15:43:30 <lambdabot> f = fix (ap (>>))
15:43:33 <SamB> to annoy you?
15:44:11 <dmhouse> mauke: ooh, pretty :)
15:44:41 <mauke> ?pl let z = x >> z in z
15:44:41 <lambdabot> fix (x >>)
15:49:27 <mauke> ?index fix
15:49:27 <lambdabot> Control.Monad.Fix, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Error
15:52:49 <dmhouse> Wow, here's a curiosity:
15:53:34 <dmhouse> I had a case branch 'err@(Left _) -> err', which wasn't typechecking. I changed it to 'Left err -> Left err', and it work.
15:53:38 <dmhouse> s/work/works/
15:54:01 <lispy> dmhouse: the either types are prorably different
15:54:04 <dmhouse> Which is weird, because you expect them to be identical.
15:54:11 <lispy> like Either a b -> Either a c
15:54:38 <dmhouse> lispy: yeah, in the first one, the Right type was Type, but the result of the case expression needed to have a Right type (Type, Type).
15:54:43 <mauke> oh, I used to get bitten by that all the time
15:54:48 <mauke> mostly for Maybe
15:55:23 <dmhouse> It shows up at times like this:
15:55:25 <dmhouse> > show Nothing
15:55:26 <lambdabot>  Add a type signature
15:55:27 <lispy> dmhouse: in the first case you reuse the Left, which in turn reuses the Either and in the second case you construct a new Left
15:55:36 <dmhouse> lispy: precisely.
15:55:44 <lispy> okay, as long as you understang :)
15:55:49 <dmhouse> It's just an oddity, at first glance they seem to be identitcal.
15:55:58 <dmhouse> lispy: I realised what the problem was, that's how I came up with the solution ;)
15:56:03 <lispy> (from you comment, i thought maybe it was not something you understood)
15:56:26 <dmhouse> > show [] -- this one might not work either
15:56:27 <lambdabot>  Add a type signature
15:56:42 <lispy> > show ([] :: [Int])
15:56:43 <lambdabot>  "[]"
15:57:01 <lispy> > show ([] :: [Char])
15:57:01 <dmhouse> I'd have thought that because the instance for Show [a] is polymorphic, the compiler would know it doesn't matter.
15:57:02 <lambdabot>  "\"\""
15:57:13 <lispy> but it does
15:57:31 <dmhouse> base:Prelude> show []
15:57:31 <dmhouse> "[]"
15:57:34 <lispy> in the case of Nothing I agree though
15:57:51 <Igel> hi there,
15:58:02 <lispy> dmhouse: what does :t [] say?
15:58:13 <dmhouse> [] :: [a]
15:58:16 <lispy> here it says forall a. [a]
15:58:32 <lispy> Igel: hi
15:58:38 <lispy> Igel: welocome to #haskell
15:58:49 <Igel> is there a function like concat, which takes arguments [a] and [[a]] and mixes the concatenation?
15:58:53 <Igel> i mean like:
15:59:10 <Igel> catWith :: [[a]] -> [a]
15:59:29 <dmhouse> 'Mixes the concatenation'?
15:59:34 <Igel> catWith ["ab", "cd", "ef"] " "
15:59:40 <Igel> -> "ab cd ef"
15:59:45 <dmhouse> Ah. No, there isn't, annoyingly.
15:59:48 <Igel> you see? :)
15:59:54 <dmhouse> You can get there with intersperse, though.
16:00:05 <lispy> ?hoogle [a] -> [[a]] -> [[a]]
16:00:06 <lambdabot> No matches, try a more general search
16:00:19 <lispy> Igel: you want interprese
16:00:26 <lispy> intersperse*
16:00:28 <Igel> where do i find it?
16:00:30 <mauke> @type (concat .) . intersperse
16:00:31 <lambdabot> forall a. [a] -> [[a]] -> [a]
16:00:36 <Igel> prelude?
16:00:37 <mauke> @index intersperse
16:00:38 <lambdabot> Data.List
16:01:22 <mauke> ?type liftM (liftM join) intersperse
16:01:24 <lambdabot> forall a. [a] -> [[a]] -> [a]
16:01:39 <dmhouse> *cough* Show off.
16:02:01 <dmhouse> :P
16:02:45 <lispy> > (concat .) . intersprese "\n" ["blah", "blah", "blah"]
16:02:46 <lambdabot>  Not in scope: `intersprese'
16:02:57 <lispy> > (concat .) . intersperse "\n" ["blah", "blah", "blah"]
16:02:58 <lambdabot>    Expecting a function type, but found `[a]'
16:02:58 <lambdabot>    Expected type: a2 -> a1...
16:03:02 <mauke> EPRECEDENCE
16:03:09 <lispy> > (concat .) . intersperse $ "\n" ["blah", "blah", "blah"]
16:03:09 <lambdabot>    The function `"\n"' is applied to one arguments,
16:03:10 <lambdabot>   but its type `[Char...
16:03:19 <lispy> heh
16:03:25 <lispy> i give up for now
16:03:30 <mauke> > ((concat .) . intersperse) "\n" ["blah", "blah", "blah"]
16:03:31 <lambdabot>  "blah\nblah\nblah"
16:03:40 <mauke> ROCKET SURGERY
16:03:51 <lispy> yeah, it's weird that my ($) didn't work there
16:04:00 <mauke> no, it isn't
16:04:16 <mauke> a b $ c d is (a b) (c d)
16:04:34 <Igel> mauke: thanks :)
16:04:44 <lispy> > (concat .) . intersperse $ "\n" $ ["blah", "blah", "blah"]
16:04:44 <lambdabot>  Couldn't match `a -> b' against `[Char]'
16:05:06 <mauke> a $ b $ c is a (b c)
16:05:30 <lispy> is this why people say the associativety of ($) is wrong?
16:05:34 <ThreeQ> > (concat .) . interperse "\n" $ ["blah", "blah", "blah"]
16:05:35 <lambdabot>  Not in scope: `interperse'
16:06:00 <ThreeQ> > (concat .) . intersperse "\n" $ ["blah", "blah", "blah"]
16:06:00 <lambdabot>  Couldn't match `a1 -> [[a]]' against `[a2]'
16:06:01 <mauke> > concat . intersperse "\n" $ ["blah", "blah", "blah"]
16:06:03 <lambdabot>  "blah\nblah\nblah"
16:06:09 <lispy> the best thing about intersperse is how easily you misspell it :)
16:06:17 <ThreeQ> heh
16:06:24 <mauke> yeah, haskell needs Symbol::Approx::Sub
16:06:44 <mauke> http://search.cpan.org/~davecross/Symbol-Approx-Sub-2.02/Sub.pm
16:06:47 <lambdabot> Title: Symbol::Approx::Sub - Perl module for calling subroutines by approximate names!  ..., http://tinyurl.com/bgy43
16:06:47 <lispy> what does it mean to give a type to a type?
16:07:30 <lispy> ?type [Int] :: [Char]
16:07:32 <lambdabot> Not in scope: data constructor `Int'
16:07:34 <Heffalump> lispy: that's what Haskell calls kinds
16:07:47 <lispy> Symbol::Approx::Sub is a kind?
16:07:51 <Heffalump> for example, the Maybe type constructor is of kind * -> *
16:08:00 <Heffalump> errm, I doubt that
16:08:06 <lispy> yeah, that's what i thought the notation for kinds were
16:08:18 <Heffalump> I was referring to "[00:06] <lispy> what does it mean to give a type to a type?"
16:08:24 <lispy> maybe it's just a weird perilms?
16:08:33 <lispy> perlism*
16:08:39 <mauke> I think Perl stole it from C++
16:08:46 <Heffalump> stole what?
16:08:50 <lispy> Oh, it's name spaces?
16:08:51 <mauke> the ::
16:08:57 <Heffalump> oh, I see.
16:08:59 <lispy> <mauke> yeah, haskell needs Symbol::Approx::Sub
16:09:19 * lispy thought we were talking about haskell
16:09:26 <ndm__> xtruppaw: got bounced by my network, and can't private chat until the nick name ndm expires, since i don't have any other accounts registered...
16:09:56 <lispy> ndm__: you can 'ghost' it
16:10:04 <lispy> ndm__: /msg nickserv help
16:10:14 <ndm__> lispy: sounds like too much effort...
16:10:29 <lispy> no, you just send a msg to nickser telling it to drop you
16:10:33 <lispy> you just need your passowrd
16:10:42 <lispy> takes just a second :)
16:11:27 <ndm> lispy: done, thanks :)
16:11:35 <lispy> np, glad it worked :)
16:17:19 <lispy> someday i should probably learn some perl
16:17:35 <lispy> or maybe make a haskell program to safely generate perl
16:18:05 <ndm> i once wrote a program in Perl
16:18:16 * Heffalump is writing code in Perl right now
16:18:26 <ndm> rewrote it in Javascript when i realised i'd need to change it slightly, since Perl is definately write once, read never
16:18:42 <ndm> although that was my first perl program, so was nasty
16:21:11 <mauke> is there a simple string parsing function in haskell?
16:21:26 <Heffalump> to parse it into what?
16:21:32 <Heffalump> @type read
16:21:34 <lambdabot> forall a. (Read a) => String -> a
16:21:44 <lispy> ?type readS
16:21:46 <lambdabot> Not in scope: `readS'
16:21:54 <lispy> oh maybe that's a class
16:21:56 <Heffalump> @info readS
16:21:57 <lambdabot> readS
16:22:01 <lispy> ?instances ReadS
16:22:02 <Heffalump> @info ReadS
16:22:03 <lambdabot> Not a class! Perhaps you need to import the  module that defines it? Try @help instances-importing.
16:22:03 <lambdabot> ReadS
16:22:04 <mauke> I have a string in the format "<number> , <number>" and I need the numbers as, uh, numbers
16:22:16 <Heffalump> what does @info do and why is it not like :i ? :-)
16:22:25 <lispy> mauke: what kind of numbers?
16:22:31 <Heffalump> @type reads
16:22:31 <weitzman> @help info
16:22:32 <lispy> mauke: more than one digit?  floatings?
16:22:32 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
16:22:33 <lambdabot> forall a. (Read a) => ReadS a
16:22:38 <mauke> non-negative integers
16:22:54 <weitzman> Well that's odd
16:23:00 <mauke> in decimal
16:23:05 <weitzman> I guess there's no help for info
16:23:06 <lispy> mauke: then readInt :: String -> Int; readInt = read, might work
16:23:26 <Heffalump> > (\xs -> read ("(" ++ xs ++ ")") :: (Int, Int)) "5, 3"
16:23:27 <lambdabot>  (5,3)
16:23:39 <mauke> haha, evil
16:23:46 * Heffalump is lazy :-)
16:23:47 <lispy> heh
16:23:50 <lispy> that is nice
16:24:12 <mauke> it's also safe, right?
16:24:23 <Heffalump> well, it'll throw an error on bad input
16:24:27 <Heffalump> > (\xs -> read ("(" ++ xs ++ ")") :: (Int, Int)) "5,"
16:24:28 <lambdabot>  Exception: Prelude.read: no parse
16:24:31 <Heffalump> so no, not very
16:24:48 <Heffalump> you need to use reads if you want to handle that kind of problem locally
16:24:56 <mauke> hmm, yeah
16:25:06 <mauke> is it possible to write something like scanf in haskell?
16:25:28 <Heffalump> well, giving it a type is a bit tricky
16:25:42 <Heffalump> though there are various tricks for typing printf that would presumably work similarly
16:25:49 <mauke> recursive typeclass hackery, yeah
16:25:57 <Heffalump> but really you should just use Parsec or something
16:26:09 <mauke> no, parsec is too heavy
16:26:25 <Heffalump> well, scanf is quite heavy too, implementation-wise
16:26:34 <lispy> if you think parsec is too heavy, you probably shouldn't use read
16:26:47 <lispy> there is some evidence that suggests read is very slow for parsing ints
16:27:00 <Heffalump> your actual "format string" with Parsec is just something like int <;> char ',' <;> int (I don't know what the actual combinators are in Parsec, but that kind of thing)
16:27:06 <lispy> mauke: could you use Data.ByteString.readInt?
16:27:09 <lispy> it's very fast
16:27:14 <mauke> I don't care about speed
16:27:24 <lispy> what does heavy mean?
16:27:37 <mauke> I have to write more code / think harder
16:28:24 <mauke> with scanf it's just: Scanf.sscanf s " %u , %u %!" $ fun p1 p2 -> ( ...
16:28:37 <Heffalump> that's just cos you know scanf format strings
16:28:44 * Heffalump has no clue what %! means, for example
16:28:55 <Heffalump> (and happens to know %u but that's just cos I have C experience)
16:28:58 <lispy> mauke: then stick to the read hack for now :)
16:29:00 <mauke> it's OCaml's scanf; %! means end-of-input
16:29:34 <Heffalump> it's not a hack, it's a highly principled piece of code reuse!
16:29:53 <Heffalump> (and reads really isn't much harder to use than read, and does give you local error recovery. I'm not sure what else 'safe' could mean)
16:30:17 <ndm__> but reads is quite a sucky interface
16:30:20 <mauke> accepts other input, for example
16:30:21 <ndm__> no error reporting
16:30:34 <Heffalump> mauke: wdym by that?
16:30:46 <yip> @seen musasabi
16:30:46 <lambdabot> musasabi is in #ghc, #haskell-overflow, #haskell-blah and #haskell. I last heard musasabi speak 3h 48m 45s ago.
16:30:49 <Heffalump> ndm__: error reporting and 'light' probably don't coexist
16:30:59 <mauke> e.g. lisp's read skips comments, among other things
16:31:07 <lispy> ?where parsec
16:31:08 <lambdabot> http://www.cs.ruu.nl/~daan/parsec.html
16:31:20 <lispy> lisp's read is very powerful
16:31:30 <mauke> it's basically eval :-)
16:31:48 <Heffalump> so basically you want the moon-on-a-stick?
16:32:03 <lispy> in lisp you can make lisp by (print (eval (read))) ;; right? :)
16:32:22 <mauke> (loop (print (eval (read))))
16:32:37 <matthew-_> just 4 pairs of parens?!
16:32:38 <lispy> hmm...where is the parsec repository?
16:32:45 <Heffalump> wow, no wonder it's called the REPL
16:32:54 <mauke> no, that's exactly what I don't want
16:33:05 <Heffalump> hi ChilliX
16:33:07 <lispy> yeah, the fact that it is so easy is such a problem :)
16:33:14 <ChilliX> Hi Heffalump!
16:33:22 <mauke> Parsec is highly non-intuitive, I'm never sure when to use try
16:33:33 <yip> yay, musasabi spoke the truth, the "Fix lazyness of take, drop & splitAt" fps patch was indeed applied to GHC a few days ago
16:34:02 <lispy> i could have sworn parsec was at darcs.haskell.org
16:34:39 <mauke> wait, failed let bindings in a monad "fail", right?
16:34:52 <lispy> ah
16:34:53 <lispy> http://darcs.haskell.org/packages/parsec/
16:34:53 <Heffalump> yes
16:34:55 <lambdabot> Title: Index of /packages/parsec
16:35:01 <mauke> so I get an IO exception, which is exactly what I want
16:35:04 <lispy> just had to google parsec _darcs
16:35:15 <ChilliX> Heffalump: How are things?
16:35:33 <Heffalump> ChilliX: not bad, you?
16:36:07 <ChilliX> Heffalump: The usual chaos ;)
16:36:19 <Heffalump> :-)
16:36:32 <ChilliX> After more or less getting in control of email and stuff after the ICFP trip, trying to get into hacking gfhc again.
16:36:36 <mauke> how do IO exceptions interact with threads?
16:36:52 <mauke> i.e. what happens when a thread doesn't catch an exception?
16:37:47 * lispy wonders who ChilliX is
16:38:08 <lispy> ChilliX: Manuel? (maybe misspelled it?)
16:38:31 * Heffalump wonders if the darcs problems with the ghc repos got sorted out
16:39:15 <lispy> so if i hacked parsec to work with bytestring, what would the module names be?
16:39:26 <ChilliX> lispy: yes - just joking
16:39:27 <lispy> ByteString.ParserCombinators?
16:39:48 <ChilliX> (yes, as in , yes I am Manuel)
16:39:53 <lispy> ah cool
16:39:59 <ChilliX> Heffalump: You mean with the merging?
16:40:04 <Heffalump> ChilliX: yeah
16:40:11 <lispy> we met briefly one day, i was there with droundy
16:40:15 <dmhouse> What's an antonym of 'criticism'?
16:40:19 <ChilliX> Well, they are still working at it.
16:40:25 <weitzman> praise?
16:40:33 <ChilliX> lispy: ah, ic
16:40:39 <lispy> i would say something more like apathy
16:40:51 <SamB> apathetic praise?
16:40:56 <mauke> why isn't bracket in System.IO?
16:41:06 <lispy> a yes man is the opposite of a critic...
16:41:12 <dmhouse> I was hoping for a word ending in 'icism', but 'praise' will do.
16:41:20 <ChilliX> Heffalump: luckily, the fc branch has now be merged into the HEAD, so it's not much a worry for me, right now
16:41:29 <lispy> sweet
16:41:33 <SamB> apathetic prais-ism?
16:41:48 <ChilliX> Heffalump: although, it will be again, when the ndp project gets to the point where we need to implement the program transformation
16:42:05 <lispy> any thought os where a bytestring version of parsec should sit in libraries?
16:42:54 <SamB> Text.ParserCombinators.ParsecBS ?
16:44:10 <Heffalump> I would say under Parsec rather than under ByteString
16:44:28 <SamB> Text.ParserCombinators.Parsec.BS?
16:44:34 <Heffalump> but not .ParsecBS, .Parsec.ByteString
16:44:35 <musasabi> yip: here.
16:44:49 <SamB> Heffalump: but that is so long!
16:45:06 <ChilliX> SamB: who cares?
16:45:10 <lispy> oi like Text.ParserCombinators.Parsec.ByteString
16:45:21 <SamB> Text.ParserCombinators.Parsec.ByteString.Supercalafragilisticexpialadocious?
16:45:21 <yip> musasabi: hi :) is there some trick for running a HAppS program from ghci?
16:46:09 <musasabi> yip: it just works at least on *nix, on windows I am not sure if there are RTS bugs in GHC which make it harder.
16:47:20 <yip> musasabi: it works, but when i do :reload, ghci recompiles it, but when i run it again with main, it's like it's running the old version of the code
16:47:20 <lispy> then the quuestion is, should it use Lazy or strict bytestring
16:47:26 <lispy> probably strict?
16:47:28 <yip> musasabi: i'm on *nix
16:47:37 <lispy> i seem to recall strict parers are usualyl easier/more sensible
16:48:14 <SamB> it depends!
16:48:20 <musasabi> the problem is with reload and threading interacting.
16:48:34 * SamB wishes he didn't know that overloading would probably make it slower
16:48:38 <yip> musasabi: how do i solve this problem?
16:49:28 <lispy> it's so easy to switch, i'll just use the strict one and then compare to the lazy
16:49:37 <Heffalump> can't you use SPECIALIZE directives to avoid that?
16:49:52 <lispy> talking to me?
16:50:02 <Heffalump> well, to SamB
16:50:15 <musasabi> personally I just stop/start ghci since that is the easest way. There way a #ifdef for storing away all thread ids created and a function to kill all old threads, but that is not very maintained. And not enabled by default in builds since that has a high performance overhead.
16:50:48 <SamB> Heffalump: possibly
16:50:58 <SamB> but superspecialize would be *so* much better
16:51:11 <yip> musasabi: when main finishes, shouldn't it kill all of it's threads?
16:53:10 <musasabi> yip: there is no way in GHC to say "kill all child threads" and actually keeping a list of the child threads that are alive (must be weak references) is quite costly.
16:53:23 <musasabi> yip: and won't work on any external code which uses forkIO
16:54:47 <yip> hm... so when i'm in ghci, and main exits, there are threads that are still running? :O
16:55:00 <musasabi> yes.
16:55:28 <yip> and the only way to kill them is with that #ifdef hack?
16:56:05 <ChilliX> yip: Think about it.  When you use forkIO directly in ghci, would you expect the new thread to die immediately?
16:56:32 <yip> i think that yes, that would be the best behaviour
16:56:42 <ChilliX> yip: Now if you define "main = forkIO bla", why should that be different?
16:57:34 <yip> actually, i guess the best solution is to be able to say "kill all child threads"
16:57:55 <ChilliX> Yes, which is what the hack musasabi describes does.
16:58:27 <ChilliX> Now, it maybe would be nice if the library had some general support for that, then leaving it to the application.
16:58:40 <ChilliX> then = rather than
16:58:48 <yip> yeah, that's what i mean
16:59:01 <ChilliX> ok, yes, that would be a nice feature
16:59:15 <mauke> is there a quick and dirty way to parse "%2X%2X%2X%2X:%4X" in haskell?
16:59:18 <musasabi> ChilliX: that would be very nice. Having threads in trees and being able to control them.
16:59:53 <yip> it seems almost like a critical feature
17:00:07 <lispy> heh, parsec has a lot of code in the internals that i don't get
17:00:53 <yip> hm.... how can i make a hyperlink in Text.Html?
17:05:51 <musasabi> there was a function for it, but don't remember the name :-(
17:06:06 <musasabi> and no access to source code from here
17:06:49 <ChilliX> I think, it is anchor
17:07:10 <musasabi> @type Text.Html.anchor
17:07:11 <lambdabot> Text.Html.Html -> Text.Html.Html
17:07:23 <musasabi> and there is href.
17:08:46 <ChilliX> Ah - right
17:10:41 <yip> (anchor ! [href "http://haskell.org"]) (stringToHtml "Haskell!")
17:10:44 <yip> is that the right way to do it?
17:11:15 <ChilliX> Seems alright to me
17:11:49 <musasabi> yip: the stringToHtml may be superfluous.
17:12:55 <ChilliX> you can use toHtml, but there needs to be some function
17:13:05 <lispy> does daan use #haskell at all?
17:13:11 <ChilliX> (anchor is not overloeaded)
17:13:36 <Heffalump> lispy: I don't recall seeing him here.
17:13:46 <lispy> maybe i'll shoot him an email...
17:14:03 <lispy> some of this internal parsec code is confusingme
17:14:21 <yip> toHtml seems to do the same as stringToHtml
17:34:51 <yip> does HAppS have something like django's urlconf?
17:35:51 <lispy> i've never used either so i have no idea :)
17:36:48 <yip> django allows you to match regular expressions against the requested url, and map the matching regex to an http response function
17:37:22 <lispy> sounds similar in spirit to apache mod_rewrite
17:37:33 <yip> yes, it's similar to that
17:38:40 <yip> django doesn't serve files from a filesystem. it serves the result of a function. to find out which function to run, it goes through the list of regexes, and the first one to match has it's assigned function called
17:39:34 <lispy> you could probably simulate that in haskell with Data.map
17:42:24 <jmob> hrmm, I was going to tell Cale that I enjoyed his "monads as containers" article :(
17:54:53 <wolverian> heh, http://photos1.blogger.com/blogger2/1715/1669/1600/larson-oct-1987.gif static typing without type inference
17:54:55 <lambdabot> http://tinyurl.com/joqce
17:55:40 <jgrimes> wolverian, haha..
17:58:25 <JohnMeacham> @seen musasabi
17:58:25 <lambdabot> musasabi is in #ghc, #haskell-overflow, #haskell-blah and #haskell. I last heard musasabi speak 46m 36s ago.
17:59:02 <JohnMeacham> documenting some jhc internals: http://repetae.net/john/computer/jhc/big-picture.pdf
17:59:05 <lambdabot> http://tinyurl.com/onuzw
18:02:39 <mauke> ?pl \f g x -> liftM2 f id g x
18:02:40 <lambdabot> flip liftM2 id
18:03:11 <mauke> ?pl \c f x y -> x `c` f y
18:03:11 <lambdabot> flip . ((.) .)
18:05:47 <Cale> jmob: cool :)
18:05:52 <yip> does HAppS have support for file uploads?
18:10:30 <jgrimes> JohnMeacham, cool.
18:12:08 <JohnMeacham> does anyone know of a way to include a legend in graphviz?
18:18:00 <dcoutts> JohnMeacham, you can cheat, export as .svg and edit in inkscape
18:20:12 <JohnMeacham> hmm.. making a fake disconnected graph with an example of everything and what it represents as its label seems to work well.
18:20:17 <JohnMeacham> well, work okay.
18:20:56 <JohnMeacham> Hmm.. I need to distinguish edges that perform transformations, and ones that just represent code motion. solid edges are code movement, dashed lines are metainfo movement.
18:23:01 <dons> ?users
18:23:23 <lambdabot> Maximum users seen in #haskell: 256, currently: 230 (89.8%), active: 17 (7.4%)
18:24:27 <Pete_I> how's it know how many are active?
18:24:43 <Stinger_> they dont shut up :P
18:24:57 <Stinger_> at a guess
18:25:00 <Pete_I> hmm
18:25:11 <dons> it counts those who've spoken in the last 4 hours
18:25:17 <dons> wow. new record again. 256
18:25:17 <Pete_I> ah
18:25:21 <Pete_I> ?users
18:25:22 <Stinger_> woo, what do I win
18:25:22 <lambdabot> Maximum users seen in #haskell: 256, currently: 230 (89.8%), active: 19 (8.3%)
18:25:25 <Pete_I> :)
18:25:34 <Pete_I> i'm active! yay
18:25:50 <Stinger_> I was gonna say, one more and we go back to 0 but that'd be now :)
18:26:23 <Stinger_> oh no wait, only 230 now
18:26:36 <dons> "only" hehe
18:26:40 <aFlag> lambdabot actually gets its info from fbi. They have cams all over the us. I'm in brazil though, so I'll never be considered active
18:26:48 <dons> ?users #perl6
18:26:49 <lambdabot> Maximum users seen in #perl6: 148, currently: 132 (89.2%), active: 4 (3.0%)
18:27:14 <Pete_I> only 4 people? that's not many...
18:27:27 <aFlag> ?users #debian
18:27:28 <lambdabot> Maximum users seen in #debian: 1, currently: 0 (0.0%), active: 0 (NaN%)
18:27:36 <dons> doesn't know about channels its not in
18:27:39 <dons> probably should check that...
18:28:03 <Heffalump> I guess "NaN%" is kind of a reasonable response. On some level.
18:28:37 <Adamant> zero is NaN?
18:28:38 <aFlag> I don't know, I never tried to divide not a number to 100
18:28:40 <Pete_I> well, that'd be 0/1, 0/1 is a number :/
18:28:43 <dons> 1/0 is NaN
18:28:51 <dons> > 1/0 :: Double
18:28:52 <lambdabot>  Infinity
18:29:06 <aFlag> cool, dons found the infinity
18:29:12 <dons> > 0/0 :: Double
18:29:13 <SamB_XP> > 0/0
18:29:13 <lambdabot>  NaN
18:29:14 <lambdabot>  NaN
18:29:23 <Pete_I> i thought infinity was in 42...
18:29:35 <SamB_XP> Pete_I: what?
18:29:38 <SamB_XP> 42 is the answer
18:29:41 <SamB_XP> not infinity!
18:29:43 <aFlag> no, 1/0 is the number infinity
18:29:43 <Pete_I> nevermind :)
18:29:47 <Heffalump> what's the question?
18:30:04 <SamB_XP> Heffalump: nobody has figured that out yet
18:30:05 <Pete_I> Heffalump, 42!
18:30:58 <jmob> Has anyone successfully built GHC on Mac OS X?
18:31:25 <SamB_XP> yes
18:31:28 <dons> thankfully, yes. many.
18:31:38 <jmob> Intel?
18:31:51 <dons> yeah, audreyt for eample. and seafood
18:32:43 <lisppaste2> jmob pasted "build failure" at http://paste.lisp.org/display/27563
18:33:32 <jmob> genprimopcode is a haskell program, which I can't build, since I'm trying to do a bootstrap build
18:33:48 <dons> and you're following the bootstrapping steps from the user's guide?
18:33:56 <Igloo> jmob: http://hackage.haskell.org/trac/ghc/wiki/X86OSXGhc
18:33:59 <lambdabot> Title: X86OSXGhc - GHC - Trac, http://tinyurl.com/fnmrx
18:34:16 <jmob> oh wow, thanks
18:34:25 <aFlag> how do you guys feel about using glasgow extensions? Is it a good idea to use them or not?
18:34:48 <Igloo> You don't need Prim.hs if you are going to bootstrap, though. You can just remove the dep in libraries/base/Makefile
18:35:26 <dons> aFlag: using particular ones is often essential
18:35:30 <dons> ?where haskell-exts
18:35:30 <lambdabot> http://hackage.haskell.org/trac/haskell-prime/wiki/HaskellExtensions
18:35:39 <dons> gives an overview of the portabitlity of the various extensions
18:38:38 <jmob> Igloo: cool, thank you
18:38:39 <mauke> let (b1 : b2 : b3 : b4 : b5 : b6 : b7 : b8 : ':' : p1 : p2 : p3 : p4 : "") = s  -- whee
18:48:59 <zeeeee> hi all, is there any way for me to verify that my function was written tail-recursively?
18:50:00 <zeeeee> (aside from eyeballing it of course)
18:50:11 <zeeeee> (seeking automagic solution)
18:51:11 <dons> you want a tool that returns 'YES' when a function is tail recursive?
18:51:31 <dons> (i know of no easy tool for this)
18:51:57 <lispy>  the basic rule i was told was, if hte last thing the function does in return it will be tail recursive
18:52:08 <lispy> if it does something else like build a value then no
18:52:16 <lispy> i think i explained that poorly
18:52:42 <dons> right. f x = .... : f x
18:53:07 <Korollary> thats a bit fishy
18:53:23 <lispy> yeah, i think dons meant fix \f x -> ... : f x
18:53:37 <dons> heh
18:54:15 <dons> there would be some research papers from the 80s on this topic, though, I'd htink
18:54:30 <lispy> or just check a scheme tutorial
18:54:37 <lispy> they probably lay out the rules
18:54:41 <Korollary> r5rs describes exactly what is tail recursive for scheme.
18:58:20 <zeeeee> i understand tail recursion. it would just be nice if i could, say, annotate some haskell to verify that it's tail-recursive and run it through an analysis tool (i imagine it would not be the most complicated analysis)
18:58:56 <emu> is there a computable function to determine the property of "Tail recursiveness" ?
18:59:38 <mauke> is tail recursion useful in haskell?
18:59:47 <zeeeee> mauke: performance?
19:00:33 <zeeeee> emu: check the call graph for a cycle that involves no calls to any other functions in the return path
19:00:41 <mauke> yeah, isn't tail recursion inefficient?
19:01:06 <zeeeee> mauke: it's efficient because it can be flattened out into a loop; see http://en.wikipedia.org/wiki/Tail_recursion
19:01:12 <cakoose> mauke: Tail recursion is when the recursive call is a tail call and therefore doesn't require a new stack frame.
19:01:43 <cakoose> mauke: Tail recursion is a little trickier in Haskell because lazy evaluation can cause more data to be retained than you expect.
19:02:14 <Korollary> This thread may be interesting: http://groups.google.com/group/comp.lang.functional/browse_thread/thread/7db715e2808f7e3f/26e7373bbbb1380a?hl=en#26e7373bbbb1380a
19:02:17 <zeeeee> cakoose: shouldn't that be: "function calls are trickier in haskell..."
19:02:17 <lambdabot> Title: Google Groups: comp.lang.functional, http://tinyurl.com/zuzef
19:02:31 <cakoose> zeeeee: Yeah...
19:07:29 <satan> hello, I'm trying to define my own AND operator, say &&v and I've define it as (&&v) :: Bool -> Bool -> Bool, but ghci complains with "Type signature given for an expression"
19:07:40 <zeeeee> cakoose: actually, you may be more right than i gave credit... from the Eager Haskell page: "Why use eager evaluation? There are a number of good reasons. First, eager evaluation is more intuitive. Every month there is a posting to the Haskell mailing list of the form "I wrote a tail-recursive loop, and hugs is running out of stack. This should be efficient. What's going on?" The answer is that the space behavior of lazy programs is diffic
19:07:40 <zeeeee> ult to grasp, and it can be especially frustrating to express iteration. Often explicit strictness annotations are required. This detracts severely from the declarative nature of the language. In Eager Haskell, tail-recursive computations will run in constant space just as they would in ML or C."
19:07:44 <mauke> &&v is not an operator
19:07:52 <zeeeee> woops
19:08:07 <satan> mauke: so how would i define my own?
19:08:17 <mauke> use operatory symbols, like &&*
19:08:27 <satan> mauke: oh ok
19:08:49 <satan> mauke: thanks, i didnt know that
19:10:05 <zeeeee> i wish haskell had (a variant of) the loop syntax from pH (parallel haskell)...that would "solidify" tail recursion into the code while still being purely functional
19:10:14 <satan> mauke: where would i find more information on that?
19:11:50 <mauke> http://haskell.org/onlinereport/lexemes.html I guess
19:11:51 <lambdabot> Title: Haskell 98 Lexical Structure
19:12:46 <satan> mauke: ok cool, thanks
19:18:58 <Cale> zeeeee: hm?
19:19:16 <Cale> zeeeee: what do you mean by solidify?
19:19:21 <zeeeee> Cale: well, make explicit
19:20:00 <Cale> how are things like foldl' not explicit?
19:20:30 <Cale> or do you mean that you want to write loops?
19:20:47 <Cale> you can use the ST monad to get an imperative sort of syntax
19:21:16 <Cale> (while keeping guarantees that the code is pure)
19:21:17 <zeeeee> Cale: i'm unawares of foldl'
19:21:27 <zeeeee> Cale: where do i find it
19:21:34 <Cale> okay, foldl' is a left fold which is strict and tail recursive
19:21:42 <Cale> it's in the module Data.List
19:21:53 <Cale> > foldl' (+) 0 [1..1000000]
19:21:56 <lambdabot>  500000500000
19:22:56 <zeeeee> Cale: why wouldn't foldl be written tail recursively?
19:23:01 <Cale> it is
19:23:08 <Cale> but foldl isn't strict
19:23:23 <Cale> so you don't get much out of that tail recursion
19:23:27 <Cale> (usually)
19:23:36 <Cale> what happens with foldl:
19:23:42 <Cale> foldl (+) 0 [1,2,3]
19:23:53 <Cale> = foldl (+) (0 + 1) [2,3]
19:24:02 <Cale> = foldl (+) ((0 + 1) + 2) [3]
19:24:11 <Cale> = foldl (+) (((0 + 1) + 2) + 3) []
19:24:15 <Cale> = (((0 + 1) + 2) + 3)
19:24:23 <Cale> = ((1 + 2) + 3
19:24:30 <Cale> = 3 + 3
19:24:33 <Cale> = 6
19:24:52 <zeeeee> Cale: thanks for that incredibly lucid explanation :)
19:25:01 <Cale> so you can see the expression building up there
19:25:10 <zeeeee> i see...so is foldl' magic, or can i make any function strict?
19:25:11 <Cale> it's going to take as much memory as the original list
19:25:22 <Cale> you can make any function strict with seq
19:25:50 <Cale> seq does a very small amount of evaluation, but can be used to build larger devices for forcing evaluation as much as you want
19:26:29 <Cale> (x `seq` y) is an expression, which when forced, will force the evaluation of x up to determining the first dataconstructor, and then return y.
19:27:09 <Cale> so if x is a list, say, it will determine if x is a cons or if it is nil before returning y
19:27:43 <Cale> @type seq
19:27:44 <lambdabot> forall b a. a -> b -> b
19:28:34 <Cale> you can't quite write it in the language, but you could write it for specific types individually by cleverly using case. There used to be a seq typeclass, but it wasn't quite as general.
19:28:59 <Cale> also
19:29:01 <zeeeee> Cale: so i can write guaranteed efficient-tail-recursive functions using this construct?
19:29:07 <Cale> yes
19:29:08 <dons> and the problem was that adding strictness would involve propogating Eval constraints through your code
19:29:11 <Cale> foldl' has this
19:29:24 <dons> which would be really nasty wihen trying to hunt down space leaks
19:29:32 <Cale> foldl' f z [] = z
19:30:03 <Cale> foldl' f z (x:xs) = let u = f z x in u `seq` foldl' f u xs
19:31:30 <Cale> foldl' (+) 0 [1,2,3]
19:31:59 <Cale> = let u = 0 + 1 in u `seq` foldl' (+) u [2,3]
19:32:11 <Cale> = foldl' (+) 1 [2,3]
19:32:27 <Cale> = let u = 1 + 2 in u `seq` foldl' (+) u [3]
19:32:40 <Cale> = foldl' (+) 3 [3]
19:32:55 <Cale> = let u = 3 + 3 in u `seq` foldl' (+) u []
19:33:04 <Cale> = foldl' (+) 6 []
19:33:06 <Cale> = 6
19:33:19 <Cale> so you can see that it doesn't build up any large expressions
19:33:30 <Cale> by forcing the evaluation as it proceeds down the list
19:34:02 <Cale> also, there's a handy device
19:34:09 <Cale> f $! x = x `seq` f x
19:34:30 <Cale> though it has the wrong associativity, so isn't quite as convenient as you might want :/
19:34:59 <Cale> also, very low precedence, it's rather like $ which if you haven't seen it, is just defined as f $ x = f x
19:35:17 <Cale> zeeeee: does that all make sense?
19:36:32 <Cale> ping?
19:36:45 <zeeeee> so it already seems to me (as a newcomer to haskell) that a problem with haskell is the ease with which one can write inefficient code, and have no idea that they did. the first version of a simple program i wrote was beautifully simple, readable, etc. but then i found i was appending long strings at each level of recursion (i come from imperative languages, where appends are fast). the second version flipped the list construction, and rev
19:36:45 <zeeeee> ersed the end result. my third version - written in tail-recursive form - became even less 'clean'. now the fourth version, using this newfound seq, will be even worse. i'm wondering if most (experienced) haskell users just settle for the simplicity.
19:37:28 <Cale> Actually, a lot of the time, code gets messy when people optimise because they take the wrong road to optimisation
19:37:39 <Cale> There are two ways to optimise a piece of Haskell code
19:37:51 <Cale> You can make it stricter, forcing evaluation to occur sooner
19:38:09 <Cale> Or you can make it lazier, ensuring that things are not demanded until actually needed
19:38:17 <Korollary> @wiki performance
19:38:17 <lambdabot> http://www.haskell.org/haskellwiki/performance
19:38:21 <Cale> the latter route actually tends to result in cleaner code
19:38:28 <dannnn> hi channel
19:38:38 <Cale> hello dannnn
19:38:40 <dannnn> i have a question about pattern matching strings
19:38:47 <dannnn> ive got this type right
19:38:54 <dannnn> to represent logic statements
19:39:00 <dannnn> P v Q
19:39:03 <dannnn> P -> Q
19:39:04 <dannnn> etc
19:39:12 <dannnn> but i want to design  a read class for it
19:39:21 <Cale> zeeeee: another thing you can do is just replace all your strings with Data.ByteString, which will both make the thing strict in larger blocks, and will often make things as fast as C code :)
19:39:33 <Cale> (without compromising clarity)
19:39:36 <dannnn> and the only examples use prefix datatypes
19:39:41 <dannnn> like the tree in the tutorial
19:39:53 <dannnn> with char : string matching
19:40:00 <dannnn> and if i try and match string ++ string
19:40:02 <Cale> You can use infix data constructors, but they have to start with :
19:40:03 <dannnn> hugs doesnt like it
19:40:07 <Cale> right
19:40:11 <Cale> oh
19:40:12 <Cale> okay
19:40:16 <dannnn> i want the user to be able to type in infix
19:40:22 <Korollary> dannnn: ++ is a function. You can't use it to match data.
19:40:25 <dannnn> ahh
19:40:26 <Cale> yeah, you can't pattern match on ++ because ++ is not a data constructor
19:40:34 <dannnn> hmm
19:40:50 <dannnn> hmm
19:40:56 <dannnn> so my representation for logic is prefix
19:40:59 <Cale> : is a data constructor, which means that it directly reflects how the data is stored, and there's a unique way to write a (nonempty) string as x : xs
19:41:08 <Korollary> so you can do 'a':_ to signal a string that begins with an a.
19:41:09 <dannnn> but i want to read it in from infix strings
19:41:23 <dannnn> hmm
19:41:25 <Cale> dannnn: perhaps you want to write a proper parser?
19:41:27 <zeeeee> Korollary: the quality of the haskell wiki is great. thanks for the link.
19:41:31 <Cale> There are tools like parsec
19:41:42 <Cale> for constructing and manipulating parsers at runtime
19:41:46 <dannnn> hmm
19:42:06 <Korollary> you can use Text.Regex
19:42:32 <dannnn> ahh
19:44:16 <dannnn> yea im working on a theorem prover
19:44:25 <dannnn> its' here if anyone wants to see
19:44:29 <dannnn> http://taz.cs.wcupa.edu/~dmead/code/logic.hs
19:47:06 * edwardk waves hello.
19:47:13 <dannnn> =o
19:47:35 <dannnn> korollary
19:48:14 <dannnn> is there a quick way of matching strings like that
19:48:15 <dannnn> say like
19:48:35 <dannnn> 'a':_:'b'
19:49:10 <ThreeQ> dannnn: "if x then True else False" is equivalent to just "x"
19:49:40 <dannnn> ?
19:49:43 <dannnn> o0
19:49:46 <ThreeQ> prove a = if  (member((Nil), (take (resolvelength(a )) ( makeresolveset(a))))) then True
19:49:47 <ThreeQ> 	   else False
19:50:15 <ThreeQ> prove a = member (Nil, take (resolvelength a) (makeresolveset a))
19:50:25 <dannnn> oh right
19:50:26 <dannnn> yea
19:50:26 <ThreeQ> these are the same
19:50:34 <dannnn> its not finished
19:50:39 <ThreeQ> hehe
19:50:41 <dannnn> the thing will print out a formal proof
19:50:49 <dannnn> i have that there for a place holder
19:51:35 <SamB_XP> lisp programming are we?
19:51:44 <dannnn> ha really
19:53:27 <dons> dannnn: you seen the list of theorem provers on haskell.org?
19:53:53 <dannnn> yea
19:54:00 <dannnn> im trying to not taint myself by reading them
19:54:04 <dons> heh
19:54:10 <dons> add yours when its done.
19:54:14 <dannnn> i will
19:54:15 <dannnn> :)
19:54:49 <LiquidEngineer> Hey
19:55:00 <dannnn> i was suprised how rapid as shit haskell is
19:55:02 <LiquidEngineer> Is there a way to convert an integer to an int?
19:55:05 <dannnn> faster than ml even
19:55:11 <dannnn> probably :)
19:55:22 <LiquidEngineer> Where might I find such a function?
19:55:28 <dons> fromIntegral
19:55:30 <edwardk> fromIntegral? =)
19:55:35 <edwardk> @type fromIntegral
19:55:37 <lambdabot> forall b a. (Num b, Integral a) => a -> b
19:55:45 <dons> > (1 :: Integer) :: Int
19:55:46 <lambdabot>  Couldn't match `Int' against `Integer'
19:55:54 <dons> > fromIntegral (1 :: Integer) :: Int -- heh
19:55:55 <lambdabot>  1
19:56:05 <ThreeQ> somebody should make a plugin for lambdabot that generates conversions between numeric types
19:56:09 <LiquidEngineer> Thanks.
19:56:16 <LiquidEngineer> I'll name my first child after part of your name.
19:56:22 <dannnn> haha
19:56:39 <dannnn> programming on a saturday
19:56:42 <dannnn> nerds =/
19:56:46 <edwardk> =P
19:56:50 <dons> its a sunday though!
19:57:03 <dannnn> 11pm here =p
19:57:03 <edwardk> the weekend is when i get to do the fun programming =)
19:57:14 <dannnn> hehe
19:57:22 <dannnn> im doin haskell stuff for a school project
19:57:54 <dons> yeah, compiled haskell with ghc is pretty blazing fast these days
19:58:18 <dannnn> i read its second only to vanilla C
19:58:21 <dannnn> and asm
19:59:29 <dons> depends on the program, of course. but yeah, for some aps you can beat C, for others we trail it by 1.2-2x
20:00:05 <dannnn> well i get pretty good fps in frag =)
20:00:17 <dons> yeah, and Frag is limited to 60 fps anyway, right?
20:00:19 <edwardk> which is quite disturbing given the general lack of branch-predictability in haskell code as compiled by ghc.
20:00:21 <dons> it can do higher if you hack it
20:00:51 <dannnn> if its 60 itls proably just  matching to the display's refresh rate
20:00:52 <dons> Frag is kind of unoptimised too. I'm hoping someone will step up and maintain it..
20:01:08 <dannnn> yea, and build a network stack and a nice ui =)
20:01:44 <dannnn> did quake haskell ever get finished?
20:01:54 <dannnn> or did it fizzle
20:02:08 <dons> haven't heard anything recently
20:02:14 <dannnn> hm
20:02:35 <dannnn> you guys all use emacs i guess?
20:02:49 <dons> or vim.
20:03:12 <dons> probably around half and half
20:03:26 <dannnn> ahh
20:04:13 <Adamant> is there any SLIME-alike for Haskell?
20:05:10 <dannnn> slime alike?
20:05:26 <Adamant> SLIME - Superior Lisp Interaction Mode for Emacs
20:05:27 <dannnn> as in cmu lisp?
20:05:31 <dannnn> ah
20:05:48 <dannnn> yea haskell-mode is in portage for gentoo
20:05:54 <dannnn> and theres a website for it somewhere
20:06:09 <Adamant> ah, so Haskell-Mode is close enough to it?
20:06:20 <dannnn> wtf network
20:06:21 <dannnn> yea
20:06:30 <dannnn> i have hugs running in inferior mode
20:06:35 <dannnn> with haskell-mode, etc
20:06:54 <dannnn> same thing as slime
20:07:25 <dannnnnnnnnnnnnn> whats with this network
20:07:28 <dannnnnnnnnnnnnn> elkghalkeja
20:07:51 <dmead> jesus
20:07:53 <dons> "Nick collision from services"
20:08:00 <dmead> poo
20:08:01 <dons> try registering , and identifying
20:08:05 <dmead> k
20:10:24 <dmead> whats the command to register?
20:11:02 <Stinger_> /msg NickServ help
20:11:37 <dmead> k
20:50:57 <usux> awsome new haskell site wowomg.com
20:50:59 <usux> omg its awsome
20:51:15 --- mode: ChanServ set +o dons
20:51:21 --- mode: dons set +b *!*n=none@*.sbtnvt.adelphia.net
20:51:21 --- kick: usux was kicked by dons (troll)
20:51:26 --- mode: ChanServ set -o dons
20:51:39 <edwardk> thanks dons =)
20:51:45 <Adamant> you have to be pretty bored to troll a programming language channel.
20:51:51 <edwardk> heh
20:52:15 <ikegami--> hehe : new haskell site
20:52:16 <dons> the human race is full of idiots
20:52:35 * dons tries not to be grumpy 
20:52:58 <Adamant> dons, relax. I don't think too many people in here click on random links.
20:53:09 <dons> :)
20:53:19 <Adamant> think happy thoughts
20:53:26 <Adamant> then properly type them. :)
20:53:30 <dons> hehe
20:53:33 <dons> ?yow!
20:53:34 <lambdabot> With YOU, I can be MYSELF ...  We don't NEED Dan Rather ...
20:54:31 <scsibug> Could someone tell me what the name/meaning of the symbol ⊢ is?  (in the context of evaluation rules)
20:55:12 <dan_quakeTime> o0
21:03:23 <satan> if i declare an enumerated type like so: data Direction = North | East | South | West 	deriving (Eq, Ord, Enum, Show)
21:03:33 <satan> do i still have to define the toEnum and fromEnum functions?
21:03:45 <satan> or does deriving it from Enum take care of that automatically?
21:04:26 <dons> nope. that's what deriving does.
21:04:43 <satan> ok so then toEnum North should give me 0, right?
21:04:48 <dons> you get the methods of the Enum class produced for you
21:04:56 <dons> > toEnum LT
21:04:57 <lambdabot>  Couldn't match `Int' against `Ordering'
21:05:13 <dons> ?type fromEnum
21:05:14 <lambdabot> forall a. (Enum a) => a -> Int
21:05:20 <satan> i get errors about how toEnum cant match Direction against Int and so on
21:05:20 <dons> > fromEnum True
21:05:22 <lambdabot>  1
21:05:28 <dons> > fromEnum LT
21:05:30 <lambdabot>  0
21:05:47 <dons> fromEnum North == 0
21:06:40 <satan> hmm
21:06:41 <dons> int-e++ --patches
21:07:00 <scsibug> hrm, maybe using unicode in my question was a bad idea.  I was asking about vertical bar next to a dash, like |--
21:07:04 <satan> any idea why it doesnt work?
21:07:13 <dons> ?paste it?
21:07:14 <lambdabot> http://paste.lisp.org/new/haskell
21:07:26 <dons> scsibug: oh, that's a 'turnstyle'
21:07:51 <dons> so you'd write it as: G |- e : t , meaning "Under Gamma, e hastype t"
21:07:53 <dons> for exapmle.
21:08:02 <dons> scsibug: should be an explanation here:
21:08:05 <dons> ?where plbook
21:08:05 <lambdabot> http://www-2.cs.cmu.edu/~rwh/plbook/
21:08:14 <scsibug> dons: sweet, thank you very much
21:08:52 <dons> in general, |- is used for making 'judgements'
21:09:02 <scsibug> it kind of popped up without much explanation in 'types and programming languages'... I had a good understanding of what they were using it for, but no idea what it was called
21:09:18 <dons> yeah, there's an introduction to judegmenets in the above plbook
21:09:54 <scsibug> thanks again, I'll take a look at the pdf (I think I have that book in my list of things to read already)
21:09:56 <dons> so, |- e : t , is the judgement that: e has type t
21:10:29 <dons> and , Gamma |- e : t would be "in the context of Gamma (or "Under gamma"), e has type t.
21:11:04 <dons> where Gamma is an environment. (this is just a typical use (for typing judgements), but you'll find them for reasoning about all kinds of aspects of programming languages
21:11:08 <scsibug> I wish I had learned all this before I sat through most of the ICFP talks ;)
21:11:13 <dons> heh
21:16:46 <scsibug> This looks like a much gentler introduction to PL theory than the Pierce book (although I'm really loving TPL)
21:17:29 <dons> I think the plbook is more aimed at 3rd year undergrads, while TaPL is for postgrads starting out in PL research (?)
21:17:36 <dons> or maybe an advanced PL course.
21:17:43 <skew> TaPL is fun for the whole family!
21:17:47 <dons> hehe
21:18:14 <skew> I got TaPL as a first year undergrad.
21:18:25 <skew> or somewhere thereabouts, anyway.
21:18:27 <dons> oh nice.
21:22:02 <edwardk> yeah i would have liked to have seen tapl before i finished my comp sci cirriculum  ;)
21:22:18 <edwardk> now i feel like i'm playing catchup
21:22:45 <scsibug> same here, actually rather miffed that I didn't get proper exposure to this stuff during my undergrad
21:22:48 <edwardk> curriculum even
21:22:53 <edwardk> *nods*
21:22:58 <dons> yeah, I remember that feeling. "what your professor didn't teach you about computer science"
21:23:18 <scsibug> I'd love to replace my knowledge of circuits and assembler with type/PL theory
21:23:22 <dons> we should start a class action to bring PL theory into the undergrad curriculum
21:23:33 <skew> I was just kind of lucky - it was one of those sporadic "whatever the prof wants to teach this year" courses
21:23:35 <edwardk> yeah i've been trying to show the current generation of undergrads and grads at my university what they have been missing
21:23:55 <jmob> PL theory?
21:24:02 <edwardk> yeah
21:24:15 <jmob> Is type theory really an established field yet?
21:24:23 <dons> yeah :)
21:24:37 <edwardk> there is more than enough in type theory to teach a couple semesters and barely scratch the surface
21:24:40 <skew> seems to be quiteestablished
21:24:41 <dons> check the 'Research papers' page on the haskell wiki for 50 years of research :)
21:24:45 <edwardk> heh
21:24:58 <dons> more. 100 years, going back to Frege and Schonfinkel
21:25:14 <dons> yay for theoretical computer science
21:26:01 <jmob> What does PL standr for?
21:26:07 <jmob> Programming language?
21:26:08 <dons> "programming language"
21:27:31 <edwardk> hrmm does anyone know of a good source of information on writing an affine logic theorem prover?
21:27:47 <skew> automated theorem prover?
21:27:51 <dan_quakeTime> o0
21:27:55 <dan_quakeTime> im working on one now
21:27:57 <edwardk> i wanted to try modeling some instruction set optimizations as affine logic problems
21:28:04 <dmead> affline?
21:28:08 <skew> I'm thinking it would be pretty easy to formalize your affine logic in some existing prover
21:28:15 <edwardk> skew: yeah
21:28:37 <dmead> ed
21:28:49 <dmead> i'm working on one now that does boolean satisfiability
21:28:53 <edwardk> skew: well, was hoping to find an existing
21:29:13 <edwardk> dmead: may i ask what the goal was?
21:29:39 <dmead> it just proves a logic sentence valid or invalid using theorem resolution
21:29:59 <skew> heh, I see these people writing oO or affline? and I'm expecting them to be like "what are you talking about", but they're like "hey, me too"
21:30:01 <edwardk> i mostly want to be able to plug in a set of transitions/axioms and a goal and get back whether or not it is solvable exploiting the decidability of full affine logic.
21:30:15 <edwardk> yeah =)
21:30:26 <dmead> you can do that too
21:30:37 <dmead> what i've have working so far
21:30:39 <dmead> is
21:30:45 <dmead> it takes a logic sentance
21:30:58 <dmead> converts it to conjuctive normal form
21:31:08 <dmead> and creates a database out of the conjucts
21:31:23 <dmead> then does resolution to try and find nil by combing database items
21:31:58 <dmead> it's a valid process if you want to start with a set of rules/axioms or just a single expression
21:32:13 <edwardk> then i can go back and define my opcodes as consuming a set of "linear" (affine) resources for registers, and producing affine state in the flags, etc. and consuming a cycle resource. then given one solution i should be able to find if there is a better one by solving whether or not i can get there in fewer cycles or with fewer registers
21:32:39 <dmead> mmm
21:32:41 <dmead> i dont follow
21:32:45 <dmead> can you give me an example?
21:33:19 <edwardk> basically want to play with using an affine theorem prover to optimize over a simple set of assembly instructions while all operands are in registers.
21:34:10 <dmead> affline?
21:34:14 <dmead> wiki doesn't have anything on it
21:34:19 <edwardk> affine, no l
21:34:29 <edwardk> affine = linear with weakening
21:35:16 <dmead> interesting
21:35:28 <edwardk> dmead: different than intuitionistic or classical logic
21:35:32 <edwardk> which it sounds like you are implementing
21:35:43 <edwardk> affine and linear logics are 'resource conscious' logics.
21:36:15 <dmead> ahh
21:36:15 <edwardk> in fact i think i have a hackish perl script that solves the kind of first-order logic you are working in around here somewhere =)
21:36:38 <dmead> kewl
21:36:39 <dmead> heres mine
21:36:43 <dmead> http://taz.cs.wcupa.edu/~dmead/code/logic.hs
21:36:55 <dmead> im working on predicates now
21:37:06 <dmead> first order logic works fine
21:37:42 <edwardk> @paste
21:37:42 <lambdabot> http://paste.lisp.org/new/haskell
21:37:58 <lisppaste2> edwardk pasted "cheesy resolution-based theorem prover" at http://paste.lisp.org/display/27572
21:38:04 <dmead> hehe
21:38:15 <chessguy> you misspelled chessy :)
21:38:54 <dons> for so long I read 'chessguy' as 'cheeseguy'. my brain is weird
21:39:01 <dmead> hehe
21:39:02 <dmead> neat
21:39:03 <edwardk> heh
21:39:18 <chessguy> you should go to ##java and do ~chessguy
21:39:36 <dons> what happens then?
21:39:44 <lisppaste2> dmead pasted "crappy first order logic prover" at http://paste.lisp.org/display/27573
21:40:00 <chessguy> you get a factoid explaining the difference between "chessguy" and "cheeser"
21:40:11 <dons> heh
21:40:30 <chessguy> because there's a really good java guy there named cheers who everyone always gets confused with me
21:40:30 <dons> ?fact-set chessguy is not cheeseguy
21:40:31 <lambdabot> Fact recorded.
21:40:39 <chessguy> lol
21:41:19 <chessguy> good for the bot to know :)
21:41:23 <edwardk> dmead: bah you should change P Q R S T for named propositions so you don't have to repeat the rules several times
21:41:53 <skew> why did you make a paste for a url?
21:42:32 <dmead> hmm
21:42:33 <skew> couldn't you just derinve Eq here?
21:42:43 <skew> or am I missing something tricky?
21:42:48 <dmead> ?
21:43:25 <skew> data Expression a = ... deriving Eq?
21:43:34 <dmead> oh
21:43:39 <dmead> you can do that?
21:43:43 <skew> yes!
21:43:45 <dmead> hehe
21:43:52 <dmead> i just followed that tutorial for trees
21:44:01 <dmead> give it an equality, etc etc
21:44:18 <skew> which tutorial? sounds like it needs to be amended
21:44:51 <dmead> http://haskell.org/tutorial/stdclasses.html#sect8.4
21:44:53 <lambdabot> Title: A Gentle Introduction to Haskell: Standard Classes, http://tinyurl.com/hqaes
21:45:05 <skew> ok
21:45:17 <skew> I think the second paragraph says it all
21:45:19 <dmead> what do you suggest i do instead?
21:45:30 <chessguy> lol, there's an example right in there
21:45:31 <skew> "Fortunately, we don't need to go through this tedium every time we need equality operators for a new type"
21:45:32 <chessguy> data  Tree a            =  Leaf a | Branch (Tree a) (Tree a)  deriving Eq
21:45:37 <dmead> ahh
21:45:51 <dmead> it'll infer what i've spelled out explicitly?
21:46:03 <skew> yes
21:46:06 <dmead> k
21:46:20 <skew> It seems to me that section says pretty clearly you get the same Eq as above
21:46:40 <dmead> gotcha
21:46:48 <dmead> and i suppose this is still overloading ==
21:47:42 <skew> Personally, I like the Gentle Introduction. It's very /efficient/, but that means you have to read carefully, and absorb all the information from each word.
21:48:19 <dmead> right right
21:48:25 <dmead> i started haskell 3 weeks ago =)
21:48:28 <skew> the text doesn't actually seem to specify it, but you do get structural equality
21:48:44 <skew> things are equal only if they were made with the same constructor and corresponding terms are equal
21:49:17 <dmead> right
21:49:50 <skew> why all the cases for makeDatabase?
21:50:25 <skew> what about (Conj a b) = mkdb a ++ mkdb a; mkdb e = e
21:51:26 <dmead> whats the semicolon about?
21:51:39 <skew> or a linebreak
21:52:32 <dmead> ah i see what you mean
21:52:50 <skew> you can use a semicolon instead of a newline (sometimes you need to add some {} braces too) - read about layout for details
21:53:09 <skew> mostly, I just use it for typing thing in IRC so what I'm writing is actually valid syntax
21:53:30 <dmead> gothca
21:53:58 <skew> also, if somebody gets whiny about syntactically significant whitepsace they can use braces and semicolons everywhere and pretend they're writing Java.
21:54:09 <dmead> oh, i did it this way to account for structures like P & (Q & ( P & R))
21:54:24 <dmead> so each proposition gets put into it's own database entry
21:54:36 <skew> my definition should do that too
21:55:44 * glguy just bought a gameboy ds lite... pretty sweet :)
21:55:46 <skew> mkdb (P&(Q&(P&R))=> mkdb P++mkdb (Q&(P&R)) => [P]++mkdb Q++mkdb (P&R) => [P]++[Q]++mkdb P++mkdb R
21:56:15 <glguy> and wtf is a "part" my kaluha bottle says "kaluha and milk: 1 1/2 parts kaluha, fill cup with milk"
21:56:47 <skew> a part is implicitly universally quantified, like a in a type
21:57:01 <dmead> ahh
21:57:02 <dmead> yea
21:57:12 <dmead> i just tried it, seems to work just as well
21:57:17 <skew> 1.5*(1L) kaluha + (1L) milk, for example
21:57:17 <dmead> =)
21:57:24 <glguy> skew: so... however much I think i need, use 50% more?
21:57:34 <skew> Usually it's used in several places...
21:57:46 <glguy> skew: yeah, I know what it means when it is used in several places :)
21:57:50 <skew> isn't that 1.5 part Kahlua + 1 part milk?
21:57:52 <glguy> but not when they say fill the rest with milk
21:58:03 <skew> oh, that is a bit odd
21:58:18 <skew> I guess just pick the value of "part" you like
21:58:26 <glguy> and that would make for an *strong* kaluha and milk :)
21:58:35 <glguy> s/an/a
21:58:44 <skew> perhaps it does have some fixed meaning there?
21:59:00 <skew> I think the volume units for mixing are "jiggers"
21:59:17 <glguy> is that "one shot"?
21:59:25 <jmob> sadness, I really cannot get anything fun to build on osx
21:59:37 <skew> http://en.wikipedia.org/wiki/Jigger_%28bartending%29
21:59:39 <lambdabot> http://tinyurl.com/khjbs
21:59:43 <Patterner> isn't it basically a BSD?
21:59:59 <ThreeQ> jmob: what are you trying to build?
22:00:43 <edwardk> dmead: are you sure your theorem prover works for more than toy examples?
22:00:49 <dmead> nope
22:00:58 * glguy had yet considered complaining about the joy that is OS X (c:
22:00:59 <edwardk> dmead: kind of leery of your disjunction resolve cases
22:01:12 <dmead> yea it's very hackish
22:01:33 <edwardk> Disj a (Disj b c) can lead to corner cases you don't handle
22:01:38 <skew> dmead: you can also derive Show, like deriving (Eq, Show)
22:01:48 <dmead> i haven't found a really good explanation of how to combine database items in a resolution problem
22:01:50 <skew> it won't be quite a pretty, it will put the constructors in prefix
22:01:53 <edwardk> skew yeah though, show won't give him his exact output format
22:02:06 <jmob> ThreeQ: Well, the latest hugs from their download site builds find, but OpenGL for exampled doesn't function correctly.
22:02:13 <skew> unless you start using symbolic constructors like :\/ :& :--> :<-->
22:02:19 <ThreeQ> oh yeah, opengl is in a strange place on os x
22:02:28 <dmead> i derrived wrote the show class as is because my proff wanted it to output in a nice infix form
22:02:29 <skew> then you could also declare their precedence and get the same parens
22:02:33 <edwardk> heh thats what i'm using in my current hacked up version ;)
22:02:39 <jmob> ThreeQ: it'll start up, but die because something threw a signal at it that it didn't like
22:02:52 <skew> hmm, maybe you could filter (/=':')?
22:03:08 <skew> if you don't mind \/ and /\ instead of v and &
22:03:12 <dmead> who, me?
22:03:23 <skew> sure
22:03:28 <edwardk> yeah but then it breaks the show/read rule
22:03:29 <dmead> ahh sorry i wasn't paying attention
22:03:31 <glguy> couldn't be, then who?
22:03:37 <edwardk> dmead: yeah you =)
22:03:40 <dmead> =p
22:03:45 <ThreeQ> jmob: hmm, weird
22:04:05 <dmead> show/read rule?
22:04:11 <skew> edwardk: I meant postprocessing - you couldn't cram the filter in to show without defining it yourself
22:04:11 <dmead> and filter?
22:04:25 <skew> edwardk: which is counterproductive if you're trying to derive Show...
22:05:11 <skew> dmead: you could get very similar printing from deriving (Eq, Show) if you don't mind \/ /\, and leaving negation printed ate (Not exp)
22:05:14 <edwardk> dmead: basically data Expression a = ... deriving (Show) would give you a quick and dirty form of showexpression
22:05:22 <dmead> ah yea
22:05:54 <dmead> but then i guess itll be a string version of the data constructors
22:06:05 <skew> then changing around some of your constructors to use infix names like :-> would get you closer
22:06:14 <dmead> yea?
22:06:19 <dmead> how do you do infix like this
22:06:30 <dmead> its not in the docs =(
22:06:38 <skew> it should be somewhere
22:06:39 <dmead> ML is real easy
22:06:39 <dmead> like
22:06:42 <dmead> infix ->;
22:06:44 <dmead> done
22:07:00 <skew> Haskell again uses lexical conventions - make a name out of symbol characters, and it's assumed infix
22:07:08 <skew> start it with :, and it's a constructor
22:07:16 <dmead> ahh
22:07:16 <edwardk> you can ay something like data Exp = Prop String | Exp :\/ Exp | Exp :/\ Exp
22:07:27 <dmead> Oh1
22:07:28 <dmead> !
22:07:32 <edwardk> then write infixl 4 :/\
22:07:38 <edwardk> infixr 5 :\/
22:07:38 <skew> yeah, to set fixity
22:07:41 <edwardk> or something like that
22:07:46 <skew> and the derived show will and parens where appropriate
22:08:12 <skew> if you want to produce slightly nicer output, you could filter out the colons from the result of show
22:08:55 <dmead> i gotcha
22:09:32 <skew> on the other had, if you are looking for very nice output, you probably should switch to pretty printing combinators eventually, to get sensible linebreaking
22:09:43 <skew> other hand
22:10:03 <dmead> whats very nice ?
22:10:29 <skew> like a really long term being split into several lines, with the broken lines indented
22:10:41 <skew> maybe always breaking before the disjunction, if that's what you want
22:10:41 <dmead> ahh right
22:11:09 <skew> at the very least, you could use the trick from showsPrec in showExpression
22:11:21 <skew> give it an extra numeric first argument, for precedence level
22:12:02 <skew> then instead of showExpression2, call showExpression 2
22:12:49 <dmead> ah
22:12:55 <dmead> what trick are you referring to?
22:13:35 <dmead> hmm
22:13:45 <dmead> i added derving (Eq, Show)
22:13:49 <dmead> to my type defintion
22:14:00 <dmead> but now (Disj P Q) throws an error in hugs
22:14:09 <dmead> can't find show function
22:14:10 <dmead> =/
22:14:54 <edwardk> @paste
22:14:55 <lambdabot> http://paste.lisp.org/new/haskell
22:15:14 <lisppaste2> edwardk pasted "dmead theorem prover cleanup part 1." at http://paste.lisp.org/display/27574
22:15:39 <edwardk> still writing
22:15:45 <edwardk> but i thought i should show something =)
22:16:10 <dmead> neat
22:17:15 <edwardk> coming along. the current form does most of its normalization using those functions as you add things to the statement
22:17:49 <edwardk> a more rigorous normal form would use two forms of expression types to ensure you remained in normal form
22:18:48 <edwardk> that way you could get more benefit from the type system
22:19:24 <dmead> ;o
22:22:59 <lisppaste2> skew pasted "showPrec trick" at http://paste.lisp.org/display/27575
22:23:29 <skew> that makes \/ bind tighter, and associate right
22:24:05 <skew> it should be equivalent to the show derived if you declare e.g. infixr 2 :\/ infixr 1 :/\
22:24:27 <dibblego> dons, another good idea for a wiki entry - a trivial function and then testing it with quickcheck - I can't figure it out from the quickcheck documentation
22:24:36 <skew> test True?
22:24:57 <skew> True is the most trivial function I can think of
22:25:01 <skew> and it passes1
22:25:06 <skew> > test True
22:25:07 <lambdabot>  Not in scope: `test'
22:25:15 <skew> > Test.QuickCheck.test True
22:25:16 <lambdabot>  Not in scope: `Test.QuickCheck.test'
22:25:20 <dmead> ;o
22:25:24 <dmead> hmm
22:25:35 <skew> Loading package QuickCheck-1.0 ... linking ... done.
22:25:39 <skew> OK, passed 100 tests.
22:26:24 <skew> dibblego: have you looked at the QuickCheck paper?
22:26:45 <dmead> ooohh i see what your doing
22:27:23 <dmead> cool
22:27:37 <dibblego> skew, only http://www.cs.chalmers.se/~rjmh/QuickCheck/manual_body.html
22:27:41 <lambdabot> http://tinyurl.com/krrsp
22:28:00 <dmead> how do you add line breaks without the layout getting confused?
22:28:04 <dibblego> ?index test
22:28:05 <lambdabot> Test.HUnit.Base, Test.HUnit, Test.QuickCheck, Debug.QuickCheck
22:28:14 <skew> dmead: read the section on layout about five times
22:28:24 <skew> like, the rules for translating layout into explicit grouping
22:28:25 <skew> worked for me
22:28:54 <skew> dibblego: that manual doesn't do it for you? I starts right off with "A Simple Example"
22:29:12 <dmead> k
22:29:14 <skew> dmead: or, try indenting more
22:29:52 <dibblego> skew, I can't get it to work - the document assumes more familiarity with the environment I assume
22:30:24 <skew> hmm, it seems to be talking about a script
22:30:35 <skew> see Test.QuickCheck in the GHC manual, and compare
22:30:41 <dibblego> yes that is one of two files to download
22:30:56 <skew> Test.QuickCheck.test is what they call "quickCheck" in that manual
22:31:03 <dibblego> ok
22:31:11 <skew> ah, QuickCheck ships with the standard libraries nowdays
22:31:36 <dibblego> > test (reverse (reverse xs) == xs)
22:31:37 <lambdabot>  Not in scope: `xs'
22:31:48 <dibblego> > test (reverse (reverse [1,2,3]) == [1,2,3])
22:31:49 <lambdabot>  Not in scope: `test'
22:32:02 <dibblego> > Test.QuickCheck.test (reverse (reverse [1,2,3]) == [1,2,3])
22:32:04 <lambdabot>  Not in scope: `Test.QuickCheck.test'
22:32:04 <skew> lambdabot won't do it - test is in IO anyway
22:32:16 <skew> @qc \xs -> reverse (reverse xs) == xs
22:32:16 <lambdabot> Maybe you meant: . bf ft ghc id pl v wn
22:32:31 <skew> @sc \xs -> reverse (reverse xs) == xs
22:32:33 <lambdabot>  Add a type signature
22:32:39 <dibblego> ?type Test.QuickCheck.test
22:32:41 <lambdabot> forall a. (Test.QuickCheck.Testable a) => a -> IO ()
22:34:13 <skew> @check \(xs::[Int]) -> reverse (reverse xs) == xs
22:34:14 <lambdabot>  Parse error in pattern
22:34:27 <dons> no pattern type sigs in h98
22:34:32 <skew> @check (\xs -> reverse (reverse xs) == xs)::[Int]->[Int]
22:34:33 <lambdabot>  Couldn't match `[Int]' against `Bool'
22:34:38 <skew> @check (\xs -> reverse (reverse xs) == xs)::[Int]->Bool
22:34:39 <lambdabot>  OK, passed 500 tests.
22:34:43 <dons> @check \xs -> (s :: T) == (reverse . reverse) s
22:34:44 <lambdabot>  Not in scope: `s'
22:34:52 <dons> well, modulo silliness
22:37:24 <dons> dibblego: did you already see the QuickCheck intro on the wiki?
22:37:36 <dons> http://haskell.org/haskellwiki/Introduction_to_QuickCheck
22:37:38 <lambdabot> Title: Introduction to QuickCheck - HaskellWiki, http://tinyurl.com/fx5ob
22:37:52 <dons> 'a trivial function, and testing it with quickCheck' :)
22:38:08 <dibblego> yay! it didn't pop up in google
22:38:20 <dons> its on reddit atm.
22:38:28 <dons> so google will find it in a day or so
22:39:00 <dibblego> do you prefer qc to hunit or do you use both or?
22:39:10 <dons> i tend to only use QC now.
22:39:22 <dibblego> that was my guess
22:39:24 <skew> it seems like hunit might be useful to organize QC properties
22:39:52 <dons> you can generate hunits from QC properties these days, anyway. with HTF.
22:39:56 <skew> but I rarely write anything big and test it anyway
22:40:05 <skew> and if I get good enough with Coq I might just stop testing entirely
22:40:08 <dibblego> ?index quickCheck
22:40:08 <lambdabot> Test.QuickCheck, Debug.QuickCheck
22:41:16 <dons> i can't emphasise enough how QuickCheck made Data.ByteString possible. it just wouldn't have been feasible to produce so much code, so quickly, without all the QuickChecks running on each commit.
22:41:50 <skew> QuickCheck beats the hell out of writing a bunch of regression cases by hand
22:42:03 <dibblego> did you write the quickchecks first, second or iterate it?
22:42:04 <dons> ever new function we added got 2 or 3 QC properties, which run on ecah darcs commit. this kept us honest. and made it possible for 2 devs to churn out the 1000s of lines in just a few weeks.
22:42:15 <dons> and since then, only a couple of bugs have come up. all in stuff we didn't have QC properties for.
22:42:35 <dons> you'd write a function, and work out its QC properties, simultaneously
22:42:50 <dons> then, commiting a feature involved commiting the actual code, plus the associated properties.
22:42:54 <dibblego> the "QC property" is really just a formal spec. isn't it?
22:43:09 <dons> its a spec of sorts, yes.
22:43:21 <skew> I've been reading stuff about dependent type and theorem provers recently - do you think it might work to develop a function and the appropriate typing simultaneously?
22:43:30 <dons> stating either checks against a model, or else invariants that hold on the functoin
22:43:57 <dons> skew: the Isabelle/Microkernel guys seem to do that, roughly.
22:43:58 <Cale> > let diagonal xss = map head =<< scanl (flip (:) . map tail) [] xss in diagonal [[(x,y) | x <- [1..]] | y <- [1..]]
22:44:00 <lambdabot>  [(1,1),(1,2),(2,1),(1,3),(2,2),(3,1),(1,4),(2,3),(3,2),(4,1),(1,5),(2,4),(3,...
22:44:08 <skew> damn, I'm trying to prove reverse (xs++ys) == reverse xs++reverse ys
22:44:25 <dons> i should write up my experience with QC and ByteString at some point
22:44:41 <skew> you already have a rather nice paper
22:44:42 <Cale> skew: you might have problems with that :)
22:45:05 <dons> skew: just a blog entry on why QuickCheck works, and how it helps productivity, i was thinking
22:45:14 <ThreeQ> ?check \xs ys -> reverse (xs++ys) == reverse xs++reverse ys :: [Int] -> Bool
22:45:14 <lambdabot>    Expecting a function type, but found `Bool'       Expected type: [Int] -...
22:45:21 <dons> i really think it was crucial to the success of ByteString
22:45:22 <skew> yeah - too bad the automation in Coq doesn't seem to be set up to have a go at proving the negation of your goal, just in case you're being stupid
22:45:25 <ThreeQ> ?check \xs ys -> reverse (xs++ys) == reverse xs++reverse ys :: [Int] -> [Int] -> Bool
22:45:26 <lambdabot>    Expecting a function type, but found `Bool'       Expected type: [Int] -...
22:45:36 <Cale> ?check \xs ys -> reverse (xs++ys) == reverse xs++reverse ys :: [Int]
22:45:37 <lambdabot>  Couldn't match `[Int]' against `Bool'
22:45:43 <Cale> ?check \xs ys -> reverse (xs++ys) == reverse xs++reverse (ys :: [Int])
22:45:45 <lambdabot>  Falsifiable, after 4 tests: [-1,-5,2], [5,3,5,-5]
22:45:47 <skew> dons: I thought your paper was a perfect description of developing a library in Haskell
22:45:59 <dibblego> skew, which paper exactly
22:46:00 <dibblego> ?
22:46:02 <Cale> [1] and [2] work well enough :)
22:46:07 <Cale> ?scheck \xs ys -> reverse (xs++ys) == reverse xs++reverse (ys :: [Int])
22:46:08 <dons> oh, you mean the rewriting paper?
22:46:12 <lambdabot>   Failed test no. 623540. Test values follow.: [-1], [-1,-1,-1,-1,-1,-1,-1,0]
22:46:17 <Cale> whoa
22:46:31 <Cale> 623540?!
22:46:45 <dons> the talk on fps describes the dev process a bit clearer, I think, than the paper (at least I thought it did)
22:46:55 <dibblego> maybe the first 600000 were lists of length 2
22:47:02 <skew> dons: Oh yeas, I'm thinking of the talk slides
22:47:48 <skew> well, maybe not the development process, but the library design process
22:47:57 <dibblego> dons, do you happen to be watching Bathurst?
22:48:50 <dibblego> there is a Ford racing car with a big bold sticker on the windscreen "INDEPENDANT" -- someone should really let them know that there is no such word
22:48:58 <dons> heh
22:50:21 <dibblego> cripes, I'm using -- in my punctuation as well
22:52:47 <skew> I don't understand coarbitrary
22:54:08 <AI_coder> So how is haskell for general purpose programming?
22:54:18 <dolio> It's awesome.
22:54:30 <AI_coder> I'm new, just started reading a few tutorials and it is cool but I don't know how good it is for doing real programming.
22:54:54 <Eidolos> Like what?
22:55:42 <dons> some examples, http://haskell.org/haskellwiki/Example_code
22:55:43 <lambdabot> Title: Example code - HaskellWiki
22:55:48 <AI_coder> I don't know, say controlling a robot that receives an angle to move towards and then telling the robot how to get to by adjusting speeds on the wheels at 20 hz.
22:55:58 <dons> and more http://haskell.org/haskellwiki/Libraries_and_tools
22:56:00 <lambdabot> Title: Libraries and tools - HaskellWiki, http://tinyurl.com/j6sf3
22:56:07 <dolio> ?where yampa
22:56:08 <lambdabot> http://www.haskell.org/yampa/
22:56:08 <dons> there's a whole field on controlling robots in haskell, btw.
22:56:14 <dons> let me find the link
22:56:14 <dibblego> dons, why does Bruno Martínez even think he needs to touch the filesystem to test that function? It seems only to read from stdin
22:56:27 <dolio> Yampa is robot stuff.
22:56:36 <dons> http://haskell.org/haskellwiki/Libraries_and_tools/Robots
22:56:39 <lambdabot> Title: Libraries and tools/Robots - HaskellWiki, http://tinyurl.com/gwlag
22:56:43 <AI_coder> lol
22:56:48 <AI_coder> Wouldn'ta Haskell robot just sit there and be lazy
22:56:58 <skew> you might have some trouble cramming the code into a microcontroller, but that's hardly "general purpose programming" anymore
22:57:01 <Cale> AI_coder: IO forces evaluation of expressions
22:57:22 <Cale> AI_coder: If you could use C++ for something, then you could use Haskell for that thing about as well.
22:57:37 <Cale> (barring the existence of fairly special-purpose libraries)
22:58:00 <dons> and finally, http://haskell.org/haskellwiki/Research_papers/Functional_reactive_programming
22:58:02 <lambdabot> Title: Research papers/Functional reactive programming - HaskellWiki, http://tinyurl.com/jsfmb
22:58:02 <Cale> There's a good FFI, so if you can call things from C, then you can call them from Haskell as well.
22:58:18 <dons> "Lambda in Motion: Controlling Robots With Haskell
22:58:18 <dons>     John Peterson, Paul Hudak, and Conal Elliott In the proceedings of PADL '99."
22:58:24 <skew> Cale: it's more correct and only slightly more aggresive to say "at least as well"
22:58:33 <Cale> hehe
22:58:34 <Cale> yeah
22:59:16 <dmead> skew
22:59:18 <skew> In particular it's a lot easier to get the Haskell compiler to check that you are writing correct code, and to fill in bits of things for you
22:59:21 <satan> How would i define the positive numbers as a recursive datatype? I presume it's supposed to be similar to data Nat = Zero | Succ Nat
22:59:21 <AI_coder> So why do so many intelligent people like haskell is it just hard to use or do you have any reason in particular for using it?
22:59:33 <satan> but how would i specify a 1 instead of Zero there?
22:59:39 <dons> its a nice langauge, very expressive. and fun
22:59:41 <Cale> AI_coder: programs are easier to write
22:59:47 <skew> most of it is probably possible with templates and enough suffering
22:59:49 <dolio> data PNat = One | Succ PNat?
23:00:03 <dmead> satan
23:00:10 <dmead> [1..]
23:00:10 <skew> dmead: yes?
23:00:11 <dmead> =p
23:00:14 <dmead> hey
23:00:17 <dmead> in your estimation
23:00:24 <dmead> if you try and resolve two items in a database
23:00:24 <satan> dolio: i tried that, didnt work
23:00:26 <Cale> I wrote one particular program in Haskell which was about 600 lines of actual code, 1200 if you count comments. In C, it would have been around 15000 lines of code.
23:00:31 <satan> dmead: oh ok, lemme try that
23:00:43 <dmead> which don't have any terms that cancell to nil
23:00:52 <AI_coder> Cale: What type of program was it?
23:00:56 <dmead> do you combine them in a distjunt
23:01:00 <satan> dmead: nope, doesnt work :(
23:01:02 <dmead> or leave the oroginal
23:01:19 <dmead> hehe i was kidding satan
23:01:20 <Cale> AI_coder: it was a pipeline scheduler for map type loops in PowerPC+Altivec
23:01:31 <dmead> you'd do like
23:01:40 <skew> dmead: I have no idea.
23:01:44 <dolio> What about it didn't work?
23:01:45 <AI_coder> pipeline?
23:01:56 <skew> AI_coder: like, instruction scheduling
23:02:19 <AI_coder> skew: So it was something like a parallel instruction scheduler?
23:02:51 <Cale> AI_coder: basically -- the G4 and G5 have a bunch of units which can execute different instructions
23:03:00 <dmead> err
23:03:02 <dmead> satan
23:03:07 <satan> dmead: yes?
23:03:08 <dmead> just use a list comprehension
23:03:10 <skew> and you can start a new instruction every clock cycle or so, but can't get at the result for three or for
23:03:40 <satan> so data Positive = [x | x-< 1..n] ?
23:03:42 <skew> so you have to find something to do that doesn't depend on the instructions you just did, to use the chip and maximum efficiency
23:03:46 <Cale> (at the same time, if various constraints are satisfied)
23:03:47 <AI_coder> Cale: That sounds like a compiler.
23:03:52 <satan> but that makes the datatype a list, right?
23:03:53 <Cale> yes, it was part of a compiler
23:04:15 <Cale> satan: what?
23:04:28 <satan> hey cale, how's it going?
23:04:30 <skew> AI_coder: about Haskell being hard, if you do a bit of deep thinking at the start, then it's much easier to write the program than in other languages
23:04:33 <Cale> hi
23:04:44 <dmead> satan
23:04:54 <satan> Cale: just trying to define the positive numbers as a recursive datatype
23:05:00 <dmead> pints = 1:[n+1 | n <- pints]
23:05:02 <dmead> so then
23:05:05 <dmead> take 10 pints
23:05:09 <dmead> gives 1 - 10
23:05:17 <skew> AI_coder: In C (especially) you have to keep a lot of simple details in mind while you code. You can remember a lot fewer things while you write Haskell code, even if some of them are a bit more abstract.
23:05:19 <satan> dmead: hmm
23:05:22 <Cale> satan: looks about the same as naturals :)
23:05:35 <dmead> but its in the grammar
23:05:39 <dmead> at hugs do
23:05:42 <AI_coder> skew: You know I've been thinking about that.
23:05:43 <Cale> data PositiveInteger = One | Succ PositiveInteger
23:05:46 <dmead> [1...10000]
23:05:54 <satan> Cale: i tried that and it didnt work
23:06:03 <Cale> dmead: no, he wants a recursive datatype
23:06:08 <dmead> oh
23:06:14 <Cale> satan: oh?
23:06:21 <Cale> Is Succ used for something else?
23:06:21 <dmead> well then
23:06:28 <dmead> data pints = 1:[n+1 | n <- pints]
23:06:34 <satan> Cale: nope, my bad, works now
23:06:37 <Cale> dmead: that's a syntax error
23:06:47 <AI_coder> skew: It seems like if you make a section of code rely on more than 5 to 10 variables in C it get's very difficult to keep track of exactly what is going on, does haskell provide a way to let you make more complicated things more simply?
23:06:48 <dmead> wee wait no
23:06:50 <dmead> yea
23:06:58 <dmead> @check pints  = 1:[n+1 |n <- pints ]
23:06:58 <lambdabot>  Parse error
23:07:04 <dmead> parse error o rly
23:07:12 <dmead> do i have to quote something?
23:07:15 <satan> -i had data Pos = One | Succ Pos and it wasnt working, but i guess it was a silly error somewhere
23:07:17 <satan> thanks :)
23:07:19 <skew> AI_coder: or perhaps, lets you write down the way in which it really is simple
23:07:30 <dons> AII suggest checking out haskell.org and diving in :)
23:07:36 <Cale> dmead: check expects an expression, you gave a declaration
23:07:40 <dons> AI_coder: its pretty easy to get started.
23:07:46 <dmead> ahh
23:07:51 <Cale> > let pints  = 1 : [n+1 | n <- pints] in pints
23:07:52 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
23:08:08 <skew> AI_coder: at the very least, even if you are building something complicated, you just need to think about how each part fits with the two or three parts it touches directly
23:08:10 <dmead> whats in do?
23:08:13 <dmead> in pints
23:08:20 <Cale> let <decls> in <expr>
23:08:22 <dons> questoins like "does haskell provide a way to let you make more complicated things more simply?" are really huge topics to talk about on irc. much simpler to just learn the language ;)
23:08:23 <skew> AI_coder: often you can get avoid ever having that many variables live
23:08:25 <dmead> ah
23:09:04 <skew> AI_coder: how about "here are some things I'm interested in, where should I start learning?"
23:09:10 <Cale> AI_coder: the short story is that Haskell provides some really incredible abstractions which are harder to get hold of in other languages
23:09:49 <Cale> laziness alone makes it possible to write programs in completely new ways, often much more clearly than would otherwise be possible
23:10:10 <Adamant> but it also lacks some abstractions, like macros.
23:10:28 <skew> Template Haskell is fairly servicable
23:10:29 <Cale> Well, there's TH
23:10:37 <emu> a lot of things people use macros for are unnecessary in haskell
23:10:39 <Adamant> ah, I need to check that out then.
23:10:46 <Cale> I've never found the need for macros, really
23:10:46 <dons> and most uses of macros are subsumed by laziness and higher order functions
23:10:54 <dons> yeah, neither.
23:10:57 <Cale> Usually you can write a monad which does the trick.
23:11:02 <skew> and if that fails, a DSL can almost always be done with monads
23:11:05 <Cale> or just design a combinator library
23:11:11 <skew> I've used macros for some syntactic things
23:11:11 <dons> macros are really the tool of a less expressive language.
23:11:21 <skew> easpecially around Parsec - opening up that TokenParser record
23:11:30 <dons> yeah, some syntax tricks need macros yeah.
23:11:32 <Cale> laziness gives you control over the order of evaluation
23:11:48 <Cale> so you really shouldn't need macros unless you really have to do something at compile time.
23:11:52 <skew> macros are not quite totally unecessary until you get the dependent types in full swing
23:12:00 <AI_coder> skew: Ok, I'm interested in writing a program that classifies any type of data, I've considered using Genetic Algorithms and Neural Nets as well as Bayesian Nets, my primary interest is writing a program that can classify any type of data using genetic programming, that is the program should write a program that can write other programs, and tell whether or not an item belongs to a set by using one or more programs on each item in the se
23:12:10 <skew> http://www.eecs.berkeley.edu/~adamc/papers/LaconicTR/
23:12:12 <lambdabot> Title: Scrap Your Web Application Boilerplate, or Metaprogramming with Row Types, http://tinyurl.com/lskqx
23:12:19 <AI_coder> Where should I start learning?
23:12:29 <dmead> haskell.org/tutorial
23:12:31 <dmead> is good
23:12:41 <skew> sounds like you mostly care about libraries for lots of sorts of classifiers?
23:12:44 <Cale> AI_coder: well, I have no idea *how* you're going to do that, but I recommend starting with YAHT
23:12:49 <Cale> @where yaht
23:12:50 <lambdabot> http://www.cs.utah.edu/~hal/docs/daume02yaht.pdf
23:13:09 <skew> I don't know of any tutorials that particularly mention classifiers either
23:13:25 <AI_coder> skew: Yes, but I'm also interested in generating new classifiers.
23:13:46 <Cale> I believe one of xerox's friends was writing data clustering algorithms in Haskell
23:13:48 <skew> Ah, Genetic Programming.
23:13:51 <skew> Hal Daume?
23:14:21 <AI_coder> http://hampshire.edu/lspector/pubs/push3-gecco2005.pdf#search=%22push3%22 Lee Spector has written a programming language in lisp that can generate new programs in his own programming language push3 that has generated programs that can sort and reverse lists etc.
23:14:24 <lambdabot> http://tinyurl.com/fy87x
23:14:42 <Cale> AI_coder: yeah, it's easy enough to do that sort of thing
23:15:04 <Cale> AI_coder: you can create a new datatype with the abstract syntax for your new language and write an evaluation function
23:15:07 <skew> maybe this would be interesintg - http://citeseer.ist.psu.edu/vestin97genetic.html
23:15:08 <AI_coder> Yes, I admit it is easy, but it is also a very good starting point since gp is relatively new.
23:15:11 <lambdabot> http://tinyurl.com/rvn95
23:15:37 <Cale> or, more often, you just write a bunch of functions, and functions which act on them, to build up a language of primitives and combinators.
23:15:39 <skew> for genetic programming you could probably start looking at stuff on interpreters
23:16:42 <Cale> I've considered using something like a supply monad for genetic programming, passing in the genome, and allowing the program to consume it one symbol at a time.
23:17:38 <Cale> But if you don't know much Haskell yet, I recommend just starting with small example programs in one of the general tutorials
23:17:51 <Cale> It's a rather different mindset which takes a bunch of getting used to
23:18:06 <Cale> (but it's worth it)
23:21:14 <dolio> ?seen phr-newbie
23:21:15 <lambdabot> phr-newbie is in #haskell. I don't know when phr-newbie last spoke.
23:21:43 <AI_coder> ?seen AI_coder
23:21:43 <lambdabot> You are in #haskell. I last heard you speak just now.
23:21:58 <AI_coder> ?seen lambdabot
23:21:58 <lambdabot> Yes, I'm here. I'm in #ScannedInAvian, #perl6, #oasis, #darcs, #ghc, #gentoo-haskell, #haskell_ru, #haskell.es, #haskell.se, #haskell.it, #haskell-overflow, #haskell-blah and #haskell
23:21:59 <dons> for those of you who've written for the old haskell wiki, and are happy to have that work relicensed and moved to the new wiki, could you add your name to the list here: http://haskell.org/haskellwiki/HaWiki_migration
23:22:01 <lambdabot> Title: HaWiki migration - HaskellWiki, http://tinyurl.com/o54ux
23:22:02 <skew> AI_coder: I'd recommend getting "The essence of functional programming" and checking periodically to see if you can follow it
23:22:08 <skew> http://homepages.inf.ed.ac.uk/wadler/topics/monads.html#essence
23:22:11 <lambdabot> Title: Wadler: Monads, http://tinyurl.com/pfu7z
23:22:23 <dons> Cale: for example.. :)
23:22:26 <skew> It's a rather old paper, but it describes building up lots of interpreters
23:22:55 <AI_coder> Thanks for the links, good to be amongst intelligent company.
23:25:32 <Cale> http://www.research.att.com/~njas/sequences/A074981 -- nice open problem :)
23:25:35 <lambdabot> Title: The On-Line Encyclopedia of Integer Sequences, http://tinyurl.com/rbubg
23:29:32 <dolio> ?remember dons "academic" is such an amusing insult.
23:29:59 <AI_coder> ?remember AI_coder the
23:30:26 <dolio> @quote AI_coder
23:30:27 <lambdabot>  the
23:30:47 <skew> Adamant: I'd say that macros are automation rather than an abstraction
23:31:19 <skew> you can build abstractions with them, but you need to separately make sure the macro actually follows the abstraction
23:31:30 <dons> dolio: heh
23:31:36 <dolio> :)
23:31:49 <dons> dolio: it just bugged me, after posting the socket bot tut only a few days earlier... :)
23:32:17 <dibblego> dons, what exactly?
23:32:28 <dons> dibblego: oh just silly comments from ruby programmers
23:32:30 <Adamant> skew, I can see that. I guess it depends on your POV as to what is a fundamental abstraction
23:32:36 <skew> on the other hand, if something is a function you get various nice properties, like knowing it doesn't mess up your namespace, and respects referential transparency of your arguments
23:32:36 <dons> them and their silly slow language
23:32:42 <dibblego> dons, I'm interested in exploring those comments
23:32:46 <dolio> :) Yeah, that's kind of an attack on a lot of the work you've done.
23:32:49 <dons> dibblego: oh, on reddit.
23:33:01 <Adamant> Ruby is a nice language.
23:33:34 <skew> Adamant: you can make abstractions with macros, it's just that you don't automatically have useful "abstractness properties" about something you make as a macro.
23:33:56 <dons> dolio: yeah, since we are writing kernels, compilers, web servers, theorem provers, irc bots ... :)
23:34:05 <dons> comments about real world ruby seem just silly
23:34:29 <dons> or, more to the point, "academic" projects
23:34:34 <Adamant> Ruby is getting increasingly real world, thanks to RoR
23:34:43 <dons> it is, yes.
23:34:46 <Adamant> but saying Haskell can't do stuff is silly
23:34:47 <skew> how else is it "real world", though?
23:35:05 <Eidolos> I'm learning Ruby now.. I'm really enjoying it. I still haven't taken a serious stab at learning Haskell though. :/
23:35:07 <dibblego> dons, I agree and I have challenged those kind of comments before
23:35:19 <dons> it seems that haskell is used in a far more diverse range of applicatoins than ruby. would that be right?
23:35:21 <dibblego> though not on internet forums (time is precious)
23:35:24 <skew> I haven't heard of it being applied any more than Haskell in other areas...
23:35:27 <dibblego> dons, I see no such comments here http://programming.reddit.com/info/ktep/comments
23:35:30 <lambdabot> Title: Roll your own Haskell IRC bot (reddit.com), http://tinyurl.com/jhst2
23:35:51 <dons> i'd think the speed issues with ruby would hamper use in say, micro kernels or compilers (let alone other language issues) ?
23:36:18 <dons> dibblego: no no. on the higher order perl thread. (I think higher order is a misnomre there though, from what I can grok of the code)
23:36:54 <skew> It seems to be rather nice as far as untyped languages with extensive reflection go
23:37:09 <dons> yep
23:37:28 <Adamant> is Ruby untyped? I know they have flirted with duck typing
23:37:34 <dons> the comment was, for those trying to follow, "Yes, but you would write a TCP socket-based server in Ruby, but you wouldn't in Haskell. This isn't just some academic exercise"
23:37:34 <ThreeQ> it's not untyped
23:37:37 <ThreeQ> it's dynamically typed
23:37:40 <dolio> Well, Ruby is just executed as an interpreted AST right now. Not even compiled to a bytecode. I wouldn't expect to see something like that in a microkernel.
23:38:01 <dibblego> dons, yeah I saw it - I'd ignore it
23:38:06 <dons> :)
23:38:11 <skew> when I say typed, I mean something I can spin through curry-howard and abuse to do my thinking for me
23:38:29 <Adamant> strong typing is strong typing.
23:38:37 <Adamant> static typing is something else
23:38:45 <dons> we need OReilly to start publishing truckloads of FP books...
23:39:13 <dibblego> dons, often I see the distinction between "real world" and "academia" or "in practice" and "in theory" attributable to an person with an opposing position simply because they refuse to gain the required knowledge in order to make an informed statement
23:39:35 <dibblego> lol @ slava
23:39:43 <dibblego> he's one clever guy
23:39:54 <skew> where are you reading this stuff?
23:40:02 <dibblego> http://programming.reddit.com/info/l434/comments
23:40:04 <Adamant> instead of debating this, why not put this to the test? Have a Haskell programmer write a TCP based server and a Ruby programming write one
23:40:06 <lambdabot> Title: Ask Reddit: Erlang, Haskell, OCaml; which functional language and why? (reddit.c ..., http://tinyurl.com/fjrx2
23:40:16 <dibblego> Slava Pestov wrote the Factor language
23:40:20 <Eidolos> I must say I'm really impressed by Haskell's compilability.
23:40:30 <dolio> He wrote jEdit when he was a real youngster, as well.
23:40:35 <dibblego> yeah
23:40:37 <dons> well, we've got several already, Adamant. that's the point: e.g. the 10 line irc bot posted only a few days ago.
23:40:37 <Adamant> submit it to reddit
23:40:53 <Adamant> dons, I mean more, do it for an article
23:40:54 <dons> haskell gets quite a bit of coverage on reddit. its good.
23:40:57 <AI_coder> I wish I had a way to just learn things all day without any obligations.
23:41:10 <Adamant> I know Haskell has plenty of server proggies
23:41:19 <Adamant> just lambdabot alone is proof of that. :)
23:41:30 <skew> besides, academic people are usually smart - it sounds like "You may be smarter than me, but look how good am at lifting heavy objects"
23:41:42 <dons> sethk: hehe.
23:41:46 <dons> skew ^^ :}
23:42:02 <dibblego> skew, perhaps, but there are a lots of not-so-smart ones as well, I spend most of my time unteaching my students in my lectures
23:42:03 <dons> Adamant: ah, http://programming.reddit.com/info/ktep/comments :)
23:42:05 <lambdabot> Title: Roll your own Haskell IRC bot (reddit.com), http://tinyurl.com/jhst2
23:42:19 <dibblego> skew, they have been misguided by already misguided "academics"
23:43:42 <Adamant> dons, checking that out now
23:44:06 <dons> would be interesting to see a ruby version
23:44:47 <skew> hmm, those comments are getting long
23:45:06 <skew> I was considering saying something about purity, but it looks like it would be lost in the noise
23:45:17 <dons> skew, yeah. too nosiy
23:46:20 <dibblego> you could say it in terms of "software"
23:46:27 <dibblego> given some requirement, it is intrinsic that it holds forever
23:46:35 <dibblego> failing that is a failure of contract
23:46:53 <skew> I was rather going to talk about the value of distinguishing the pure and impure parts of the program
23:47:17 <dibblego> I point out to the guys who use JUnit at work - that at one millisecond after "test execution", the test that was just executed may not necessarily hold
23:47:34 <dibblego> you could do that, but you'd enter religious debates
23:47:39 <dibblego> the common ground is "software"
23:48:15 <skew> hmm, knowing you don't have to worry that some function frobs globals seems pretty down-to-earth to me
23:48:19 <dibblego> it is not that sum 2 2 returns 4, it is that sum 2 2 forever returns 4
23:48:39 <dons> dibblego: I think skew is talking about the same thing here.
23:48:52 <dons> referential transparency is a really important property
23:49:02 <dibblego> you don't hand your software over to a client and say "it worked on my machine but I do not guarantee that it will work at any time from now into the future"
23:49:27 <dibblego> skew, but you realise there are refutations to that argument
23:49:34 <skew> I think it would be nice to stratify Haskell a bit more, to have terminating functions, and start doing the dependent types thing
23:49:54 <dons> skew: yeah, lennart was saying the same thing just the other day
23:50:07 <arcatan> why nobody has told me that there's do .. where syntax?
23:50:27 <arcatan> hmm, I've been looking for a good irc bot, maybe I should write my own...
23:50:29 <skew> I don't know! It's handy
23:50:32 <dibblego> arcatan, because tutorials don't tell people things - they work on the "pull" model?
23:50:35 <dons> after using epigram for a bit, i find i'd like non-terminating stuff in their own monad
23:50:51 <dons> arcatan: heh
23:51:02 <dons> arcatan: so you're reading the irc bot page? dive in. :)
23:51:08 <dons> its easy to hack up one.
23:51:08 <skew> I think we need to work out some sugar around commutative monads to make that really work
23:51:45 <ThreeQ> is there any good way to parse bytestrings a la parsec?
23:52:01 <dons> ThreeQ: yeah, talk to lispy. he's written a bytestring Parsec now, iirc
23:52:01 <skew> perhaps marking types / uses of types as finite or infinite would make it practical to mostly use terminating functions
23:52:24 <skew> but I still think you'd be writing enough in each mode to want some nice sugaring
23:52:25 <dibblego> I think we just need to teach software developers that we don't exist in a black hole and therefore, referential transparency is an intrinsic property of software requirements and therefore, software
23:52:43 <skew> that sounds much more religious that what I had in mind
23:52:43 <dibblego> in the first semester of tertiary education
23:52:44 <ThreeQ> @seen lispy
23:52:45 <lambdabot> lispy is in #oasis, #darcs, #ghc, #haskell-blah and #haskell. I last heard lispy speak 4h 58m 7s ago.
23:52:46 <dolio> We might exist in a black hole. :)
23:53:16 <dibblego> skew, perhaps then, "assuming wew don't live in a black hole..."
23:53:19 <dibblego> *we
23:53:24 <flipdons> irc clients for all!
23:53:48 <skew> I mean, you are making sweeping statements about the way software developers should relate to their clients
23:54:00 <flipdons> arcatan, you could modify tutbot (or irchin) if you wish
23:54:31 <arcatan> I'll go for tutbot, I guess
23:54:37 <satan> hmm time for another question from this book :)
23:54:46 <int-e> hmm, black holes and lazy evaluation ... we should be grateful this isn't physics.
23:54:55 <flipdons> this irchin client i'm using now is just tubotbot + 5 or 6 lines of code
23:54:55 <dibblego> skew, I am making an assumption - it may not necessarily hold, but if you approach your clients with something like "this software behaved this way at this time, but I make no guarantees about any other points in time in the future - it may even format your hard disk", then my assumption does not hold
23:55:07 <satan> Use the fusion law to prove that + is commutative, where the fusion law is: f . foldn g a = foldn h b
23:55:23 <flipdons> arcatan, here http://www.cse.unsw.edu.au/~dons/code/irchin/
23:55:24 <lambdabot> Title: Index of /~dons/code/irchin
23:55:25 <dibblego> assert(sum 2 2 == 4) -- forever
23:55:33 <dibblego> or
23:55:40 <skew> dibblego: I'm just saying I find the distinction between pure and impure code helpful for keeping my own program organized, and thinking about it
23:55:42 <dibblego> assert(sum 2 2 == 4) -- today, but tomorrow it might format your hard disk
23:55:47 * int-e throws an 'out of memory' at dibblego 
23:55:53 <dons> dibblego: don't start on about clients and time and software please. it gets really confusing
23:56:04 <dons> and distracting to the channel
23:56:04 <dibblego> skew, yes, but that's you, and someone else might equally argue that they don't find it helpful, so now what?
23:56:51 <dibblego> ok, but it should be relative to some common axiom (software?), and not the observer (you, me, etc.)
23:57:00 <dons> dibblego: please... :)
23:57:07 <dibblego> ok, but
23:57:19 <phr-newbie> dolio, looking for me?
23:57:21 <int-e> . o O ( #haskell-religion )
23:57:33 <dons> no software + relativity metaphors. its just too distracting to everyone
23:57:50 <phr-newbie> bwahahahaha  </hewitt>
23:58:21 <dibblego> I think it's unfortunate that it is a "distraction", but I will yield nonetheless
23:58:43 <dons> much appreciated :)
23:58:50 <phr-newbie> > ?type foldl'
23:58:51 <lambdabot>  Parse error
23:58:56 <phr-newbie> > :t foldl'
23:58:57 <lambdabot>  Parse error
23:59:01 <dons> ?type foldl'
23:59:02 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
23:59:03 <dibblego> ?type foldl'
23:59:04 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
23:59:04 <dolio> phr-newbie: Yeah. I posted on your (I think) comp.lang.functional thread. Hopefully it has something you didn't already know. :)
23:59:10 <lisppaste2> skew pasted "Coq says reverse . reverse == id" at http://paste.lisp.org/display/27578
23:59:38 <dons> skew: nice!
23:59:42 <phr-newbie> dolio, thanks!  that post was very helpful.  i'd never heard of foldl' and hugs doesn't recognize it.
23:59:48 <skew> it's fairly impossible to follow this sort of thing if you don't step through it, though
23:59:59 <dons> skew, i'd love a tut on proving haskellish things in Coq .. :)
