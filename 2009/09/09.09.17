00:00:01 <psykotic> (or at least that's part of the reason)
00:00:01 <Smokey`> joy... but I don't care about OpenGL state, I just want a memory address ;)
00:00:06 <nvoorhies> framebuffer layout's another thing that makes it annoying
00:00:07 <stanv> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9442#a9442  why i catch *** Exception: stack overflow
00:00:10 <stanv> ?
00:00:20 <psykotic> if you think swizzling from the software rendering days were bad, oh boy...
00:00:34 <nvoorhies> Smokey`: yeah but it means you basically flush the pipeline... and the pipeline's 3000 stages long
00:00:41 <psykotic> block-linear = happy fun time
00:01:23 <nvoorhies> I think a lot of the pain will go away once people start spending more money for CUDA stuff though
00:01:25 <Smokey`> nvoorhies: you already have to flush the opengl context anyway (which I'm assuming flushes the whole pipeline?) before you can do CUDA<->OpenGL interop...
00:01:32 <Smokey`> anyway there's clearly a lot more to it than what I understand :P
00:02:08 <psykotic> nvoorhies: that's a chicken and egg issue, to an extent. with cuda they always wanted to point to a specific customer with any specific request. like, they would buy X cards if we did this.
00:02:12 <copumpkin> stanv: you didn't write compare
00:02:20 <copumpkin> stanv: didn't it warn you that you didn't write enough methods for Ord?
00:02:24 <psykotic> although now that it has some momentum, it might get out of that hole
00:02:24 <Smokey`> My #1 gripe with CUDA is still lack of debugging/profiling tools,  the visual profiler is just borked 50% of the time, cuda-gdb is runtime only, and nexus requires GT2xx+ -_-
00:02:28 <nvoorhies> Smokey`: yeah but you could double buffer it and so on, right
00:02:38 <Smokey`> s/runtime/runtime api/
00:02:54 <copumpkin> stanv: from the docs, "Minimal complete definition: either compare or <=. Using compare can be more efficient for complex types."
00:02:59 <nvoorhies> hopefully it'll mature nicely now that it's clear that there's some money in it
00:03:12 <Smokey`> well, CUDA certainly has potential :)
00:03:25 <nvoorhies> and that people are interested in doing things like writing haskell front ends that talk to it and so on
00:03:32 <psykotic> yeah
00:03:39 <Smokey`> CUDA is essentially cutting our hardware/software costs by 60-70%... so we're pretty heavily invested
00:03:44 <psykotic> i only heard about the guy who did gpugen as an intern after the fact, so i didn't chat to him
00:03:47 <psykotic> but i thought that was cool
00:03:58 <psykotic> Smokey`: nice!
00:04:11 <Smokey`> on a per unit level, when selling thousands of units... that's hundreds of thousands / millions of dollars in savings >_>
00:04:22 <nvoorhies> But in 2003/2004 or thereabouts they were just wildly guessing and the thinking was like "ok, how can we open up the hardware to general purpose computation without risking too much loss if no one uses it"
00:04:44 <psykotic> that's right
00:05:01 <psykotic> but even until recently they had a fairly narrow way of measuring cuda success, i.e. measuring how much the compute business unit was bringing it
00:05:09 <psykotic> when a lot of the value is in differentiation of the whole brand
00:05:20 <stanv> copumpkin: == auto derived dereving (Eq)
00:05:33 <copumpkin> stanv: it isn't smart enough to figure it out
00:05:40 <copumpkin> @src Ord
00:05:40 <lambdabot> class  (Eq a) => Ord a  where
00:05:40 <lambdabot>     compare      :: a -> a -> Ordering
00:05:40 <lambdabot>     (<), (<=), (>), (>=) :: a -> a -> Bool
00:05:40 <lambdabot>     max, min         :: a -> a -> a
00:05:42 <psykotic> it's kind of silly that something as gimmicky as 3d vision can be justified purely on the basis of differentiation and cuda cannot. of course, cuda is a way bigger investment, but it's also a way bigger differentiator.
00:05:45 <copumpkin> bah
00:06:27 <nvoorhies> I wonder how much traction larrabee will get with haskell and clojure and other directions people are going for general purpose parallelism at a high level
00:06:47 <psykotic> the 3d vision thing fucking boggles my mind. finally the hardware side is okay (but still pretty horrible and rife with problems) but the software side is a non-starter. it's so fucking buggy and unusable that customers should sue nvidia, i can't believe we shipped that turd.
00:06:48 <copumpkin> what's its selling point?
00:06:55 <Smokey`> I think larrabee is a prime target for parallel haskell...
00:06:57 <stanv> "Minimal complete definition: either compare or <=." I have grand ">"
00:07:05 <psykotic> yeah, larrabee has an interesting curve in terms of investment/performance.
00:07:09 <copumpkin> stanv: yes...
00:07:12 <psykotic> to get really good performance, you need to program it a lot like you would cuda.
00:07:24 <nvoorhies> Smokey`: yeah.  I just wonder if it's gonna sell enough to keep them from killing it
00:07:35 <psykotic> but the difference is that there's a much more gradual incremental curve from slow-ish scalar performance to cuda-like performance
00:07:38 <okie> can bare, lone GPUs be bought in low quantities? is there support to do anything with them that way?
00:07:59 <psykotic> you can just buy a normal gpu
00:08:10 <psykotic> in fact it's much cheaper to do it that way than to get one of the compute-only gpus
00:08:13 <psykotic> it's a big scam.
00:08:14 <psykotic> :)
00:08:17 <nvoorhies> okie: without the rest of the video card?
00:08:27 <okie> nvoorhies: yes
00:08:39 <psykotic> the teslas don't have dvi ports
00:08:48 <psykotic> but they're more expensive, despite being the same
00:08:54 <copumpkin> psykotic: they just have more RAM, right?
00:08:56 <psykotic> they don't have ECC memory or anything
00:08:58 <psykotic> just some ram
00:08:59 <psykotic> yes
00:09:10 <copumpkin> so it's just appealing to academics with big budgets?
00:09:14 <nvoorhies> I think they only ever sell the whole card unless you're doing high volume embedded things and what have you
00:09:17 <psykotic> it's basically a pure marketing thing
00:09:19 <copumpkin> who assume it's more powerful because it's 10x more expensive
00:09:22 <copumpkin> and has a cute box?
00:09:26 <psykotic> as in, when you're selling to certain business you have a different price point
00:09:29 <Smokey`> nvoorhies: I don't think Intel are too worried about how much they sell initially, as opposed to how much they can refine the architecture to be as cheap as possible for entry-mid level graphics
00:09:33 <psykotic> and you justify that by superficial differentiation that means nothing
00:09:37 <copumpkin> psykotic: interesting
00:09:48 <psykotic> it's common in every part of business
00:09:56 <psykotic> and the customers of tesla are happy
00:09:59 <Smokey`> nvoorhies: I'm pretty sure, despite all the hihg-performance hype going on, Intel only care about stealing revenue from ATI/nVidia in terms of your 'average' home user's desktop
00:10:30 <psykotic> smokey: the reason that makes no sense is this
00:10:33 <nvoorhies> Smokey`: yeah but more conventional fixed function stuff is probably going to be cheaper still.  And I bet there's internal politicking over how it encroaches on the server chip space's territory
00:10:53 <psykotic> let's assume, out of proportion with even the most extreme expectations, that intel swallows up all of the graphics marketshare from nvidia and ati
00:10:54 <okie> nvoorhies: that's unfortunate. i will stick to dsps and fpgas then
00:11:05 <psykotic> that would constitute a 10% growth of their revenue. 10%. that's pathetic in business terms.
00:11:19 <psykotic> and the gpu market is pretty much saturated, so there's not much growth. in fact it's oversaturated because of insane schemes like sli, etc
00:11:41 <nvoorhies> Smokey`: I think it's because a lot of people at intel want to own the high ground in parallel computation, and selling it as a graphics chip is a palatable way to do it without stepping on toes
00:11:46 <Smokey`> nvoorhies: FF is definately cheaper, but if 110% of your staff are all x86 experts, would you waste R&D on something that only applies to a very small portion of your business, or keep it relevant and potentially get gains all across the company?
00:11:53 <psykotic> so, the only thing that makes sense is the parallel computing battleground
00:12:31 <Smokey`> nvoorhies: that is true too... in terms of parallel programming their current multi-core CPUs can't compete to other architectures...
00:12:58 <Smokey`> I guess my mind has been so fixated on nVidia for parallel programming I somewhat forgot Intel existed ;)
00:13:11 <psykotic> anyway i'm really looking forward to larrabee's launch
00:13:17 <psykotic> it'll be a lot of fun to hack around with it, if nothing else
00:13:20 <nvoorhies> Also, long term, there's an argument that all cpus will be cheap commodity parts since everyone will be running stuff written in C that doesn't scale past 4 threads, and in that world the parallel parts are the key to big profits
00:13:28 <psykotic> right
00:13:41 <psykotic> i'm pretty sure jen-hsun has made these arguments for the last 2 years every company meeting :)
00:13:58 <psykotic> so if he didn't believe it himself initially, he's said it enough by now to convince himself
00:14:01 <psykotic> heh
00:14:04 <nvoorhies> I'd be shocked if they moved away from non-parallel cpus like they did with memory chips years ago, but it could happen
00:14:43 <nvoorhies> intel's paranoid enough to worry about dying that way, however unlikely it might seem, I bet
00:14:44 <psykotic> that seems a bit different
00:14:46 <Smokey`> It's hard to see 10/20 years into the future though... the two likely won't be too different at all then
00:15:02 <psykotic> it's interesting that they've recently gotten into other things like SSDs
00:15:11 <porges> argh/ is this even possible? I've been staring at the screen for too lon
00:15:11 <porges> g
00:15:12 <psykotic> with memory chips you have a lot of analog parts
00:15:13 <porges> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3632#a3633
00:15:28 <psykotic> DRAMs and so on, so there aren't so many synergies with their semiconductor fabs
00:15:42 <Smokey`> porges: haven't we all? (I've been chatting on IRC for 4 hours...)
00:15:56 <Smokey`> porges: at least you're being productive :P
00:15:59 <nvoorhies> psykotic: yeah but that used to be almost all of their business
00:16:23 <nvoorhies> and microprocessors was a cute parlour trick for calculator manufacturers
00:16:38 <copumpkin> porges: seems like it should be possible, hm
00:16:57 <psykotic> nvoorhies: interesting, didn't know that
00:17:19 <okie> i have problem sets due at 6am and 9:30am. wtf?
00:17:38 * absentia has a problem with 6:30am
00:17:41 <psykotic> okie: just in time for the TAs to grade them for the classes at 11am? heh
00:18:07 <porges> i've been going over edward kmett's code, but that's all for fully polymorphic functors
00:18:09 <nvoorhies> psykotic: I pretty much only know it because I just read a book on intel's early history last week, heh
00:18:15 <stanv> > ((>) . flip fromEnum . fromEnum) 'a' 'b'
00:18:16 <lambdabot>   Couldn't match expected type `b -> c'
00:18:16 <lambdabot>         against inferred type `GHC.Ty...
00:18:27 <stanv> what is wrong here?
00:19:14 <porges> flip fromEnum?
00:19:26 <copumpkin> porges: not just instance (f :â¤³ g, g :â¤³ h) => (f :â¤³ h) where (âˆ˜) = ... ?
00:19:33 <copumpkin> porges: what's the type family doing there?
00:19:44 <copumpkin> porges: you'll need undecidable instances though
00:19:48 <porges> copumpkin: well that will be undecidable
00:19:50 <porges> yeah :)
00:20:05 <porges> so i wanted a newtype for composition, but I can't see how that would work
00:20:21 <copumpkin> newtype Compose f g a = f (g a) ?
00:20:35 <porges> f & g aren't polymorphic
00:20:47 <porges> maybe Point g ~ a, Point f ~ g
00:20:49 <porges> hrm
00:21:52 <porges> newtype (Point g ~ a, Point f ~ g) â‡’ Compose f g a = Compose f
00:23:01 * ski wonders what "f & g aren't polymorphic" means ..
00:23:31 <porges> you can't apply f to another type, it's already full :P
00:23:38 <copumpkin> porges: oh, I see
00:23:48 <ski> oh, you meant s/polymorphic/parametric/, then ?
00:23:57 <porges> oh yes :)
00:24:12 <copumpkin> porges: just embrace undecidability ;)
00:24:40 <porges> well that doesn't even work because you get overlap straight away with (e.g.) Functor [a] [b]
00:24:48 <copumpkin> aw
00:24:51 <porges> i'm trying to get Sets to be a functor, basically :P
00:24:51 * ski undecides embracability
00:25:12 <porges> plus have composition
00:25:26 <ski> functors are parametric types
00:25:50 <porges> ski: but you can't have constraints on the parameters
00:26:06 <copumpkin> porges: have you seen RMonad?
00:26:08 <ski> porges : unless you restrict the source category, yes
00:26:27 <copumpkin> porges: aren't Sets already a functor in the standard sense?
00:26:34 <copumpkin> porges: I thought Pointed was the problem
00:26:53 <ksf> do we have a haiku port?
00:27:07 * ksf just stumbled across it on reddit and became nostalgic
00:27:12 <copumpkin> I guess they aren't a Functor instance :o
00:27:26 <porges> well you can make a class Functor f f' where (.) :: f a â†’ f' b
00:27:31 <porges> then they work
00:27:33 <ksf> nostalgic in the "I want to use a 10-yo OS that's more modern than anything out there"-sense
00:27:34 <ski> @type Data.Set.map
00:27:35 <lambdabot> forall a b. (Ord a, Ord b) => (a -> b) -> S.Set a -> S.Set b
00:27:55 <copumpkin> oh I see
00:28:11 <ski> porges : s/::/:: (a -> b) ->/ ?
00:28:25 <porges> err, yeah
00:28:31 <porges> sorry :)
00:31:22 <ski> i suppose if  f  or  f'  is a functor, and you have a natural transformation from  f  to  f'  , then you can construct that
00:32:04 <Axman6> ok, anyone find this really interesting? http://www.pcpro.co.uk/news/351619/arm-launches-attack-on-intels-netbook-stranglehold
00:34:10 <nvoorhies> Axman6: it looks like a good chip.  High density applications where power's the main thing is the other thing people seem to be promotign it for
00:34:27 <nvoorhies> I saw 2W @ 2GHz cited somewhere
00:34:47 <Axman6> yeah, that's pretty damn good
00:35:14 <Axman6> s/disadvantage/advantage -> "The one huge disadvantage ARM faces is that its processors are incompatible with Windows."
00:35:15 <psykotic> arm's general approach is interest. they're the anti-intel.
00:35:31 <psykotic> i don't see why that would be permanent
00:35:50 <psykotic> as far as i know they still maintain internal ports to a few other platforms
00:36:21 <nvoorhies> I wonder if MS is leaning on intel with threats of an arm port yet
00:36:43 <psykotic> i wouldn't be surprised if there is one already
00:36:47 <psykotic> not necessarily shippable
00:37:10 <Smokey`> ARM11's are pretty damn good - not sure about this new cortex a9 though (I'm sure it's fine, just no personal experience) :)
00:37:20 <nvoorhies> Yeah, I wouldn't be surprised for the kernel itself, if only as a byproduct of xbox work
00:37:21 <Axman6> according to the article, Windows CE and and Mobile run on ARM (if i understoof it correctly)
00:37:34 <Smokey`> Biggest pitfall with ARM is lack of fast DDR support
00:37:57 <Smokey`> ARM only supports LPDDR... which is like 400-500Mhz tops iirc
00:38:03 <nvoorhies> ick
00:38:13 <Axman6> Smokey`: so far
00:38:34 <psykotic> if they're aiming for servers with these new cpus, obviously that has been changed
00:38:40 <Axman6> indeed
00:38:52 <EnglishGent> hello :)
00:38:53 <Smokey`> Axman6: if that changes... eg: DDR2/3 support, I forsee an Ion port... in which case we'll jump right on it :P
00:39:03 <Axman6> Ion?
00:39:10 <Smokey`> nvidia igp/chipset
00:39:15 <Axman6> ah
00:39:17 * ivanm is getting sick of polyparse failing to parse something, but not saying _where_ or _why_ it failed to parse :@
00:39:23 <nvoorhies> psykotic: I'm not sure how much of a target it is, but I know someone who's working for some startup trying to make it work
00:39:45 <porges> ski: I guess it's not a big deal, when you need composition you can just (f âˆ˜) âˆ˜ x :)
00:39:59 <okie> nvoorhies: may i ask what you're talking about?
00:40:24 * ski fails to guess what `âHX' means, there ..
00:40:30 * Axman6 always found this interesting: "Provides up to 3x reduction on code size for Just-in-time (JIT) and ahead-of-time compilation of bytecode languages while also supporting direct byte code execution of Java instructions for acceleration in traditional virtual machines"
00:40:39 <okie> nvoorhies: regarding the startup trying to make something work
00:40:45 <nvoorhies> okie: ARM's new higher performance cpu and building servers with a pile of them instead of an intel chip
00:40:49 <porges> should be . then :)
00:41:23 <Axman6> Smokey`: seems this chip does support DDR2
00:41:36 <Smokey`> Axman6: nice!
00:41:45 <Axman6> search for DDR2 on http://www.arm.com/products/CPUs/ARMCortex-A9_MPCore.html
00:41:46 <okie> nvoorhies: the A9?
00:41:54 <nvoorhies> okie: yeah
00:42:00 <ski> @type (.) . (.)
00:42:02 <ski> @type \f x -> (f .) . x
00:42:02 <lambdabot> forall a b c a1. (b -> c) -> (a -> a1 -> b) -> a -> a1 -> c
00:42:02 <lambdabot> forall b c a a1. (b -> c) -> (a1 -> a -> b) -> a1 -> a -> c
00:42:19 * Axman6 hates it when lambdabot uses a1 and a
00:42:26 <Smokey`> Axman6: that's pretty awesome, that has the potential yo bring ARM to the desktop then! :D
00:42:34 <Axman6> i hope so :)
00:42:39 <Axman6> i'd love an ARM machine
00:42:45 <ski> porges : were you talking about "passing on" two (curried) arguments ?
00:42:58 <Smokey`> MIPS are pretty sweet too
00:43:10 * Axman6 is the maintainer of the HARM emulator on hackage, but doesn't know much about it
00:43:17 <Smokey`> more expensive though (we're talking workstations with hundreds/thousands of mips processors :P)
00:43:27 <psykotic> MIPS are great so long as i don't have to program them
00:43:34 <psykotic> RISC fail
00:43:51 <copumpkin> ooh, someone made a gzip fix point
00:44:03 <nvoorhies> neat
00:44:05 <copumpkin> http://www.maximumcompression.com/selfgz.gz
00:44:31 <psykotic> any details on how they did it?
00:44:49 <psykotic> if they could do it incrementally, it's yet another demonstration why you should not conflate compression with cryptographic mixing, in case it wasn't clear already :)
00:45:10 <koala_man> omg, awesome
00:45:12 <nvoorhies> went forward in time to after they gzipped it, then came back with the file
00:45:18 <psykotic> that would work
00:45:26 * psykotic is reminded of one of aaronson's lectures.
00:45:38 <psykotic> here we go: http://www.scottaaronson.com/democritus/lec19.html
00:45:41 <copumpkin> psykotic: only thing I could find on it is http://www.maximumcompression.com/compression_fun.php
00:45:51 <copumpkin> psykotic: one sentence about it :/
00:45:54 <psykotic> there's also anthropic computing where you make a random guess and kill yourself if it's wrong
00:46:04 <okie> psykotic: i almost chose aaronson as my advisor
00:46:05 <copumpkin> http://groups.google.com/group/comp.compression/browse_thread/thread/c57c322e15c782aa/350d9fb166fdf11f
00:46:05 <psykotic> if you find yourself a survivor, you must have the right answer  :P
00:46:21 <psykotic> okie: you should have. he seems like a wicked smart and also cool dude.
00:46:35 <psykotic> he's pretty much solely responsible for reviving my interest in complexity theory.
00:47:03 <okie> psykotic: i love his stuff on PvsNP and physics
00:47:26 <okie> i think he's thinking in the right direction
00:48:47 * psykotic has some an old time travel monad.
00:48:57 <copumpkin> time travel monad?
00:48:59 <Smokey`> as you do :P
00:49:04 <okie> psykotic: i went with sussman instead
00:49:16 <psykotic> okie: is he still active as an advisor?
00:49:47 <okie> psykotic: evidently. he is my advisor as of a couple weeks ago
00:49:58 <psykotic> copumpkin: if you read about the deutsch interpretation of closed timelike loops on that page, you can probably guess the idea.
00:50:33 <psykotic> actually not too profound unless you give it that interpretation, it's also related to what dan said in his talk about 'cups' correspond to information traveling backwards in time.
00:51:14 <psykotic> okie: cool!
00:51:29 <psykotic> okie: got any ideas for your thesis yet?
00:51:54 <Axman6> okie: as in the SICP guy?
00:52:07 <psykotic> sussman's old advisee continued some of steele and sussman's old work on propagators, right?
00:52:12 <psykotic> or i should say, previous advisee
00:52:13 <ski> 'The' Modal Fallacy - Time Travel <http://www.sfu.ca/philosophy/swartz/modal_fallacy.htm#timetravel>, Time Travel - Visiting the Past <http://www.sfu.ca/philosophy/swartz/time_travel1.htm>
00:53:21 <psykotic> when i was teaching myself circuits years ago, i spent a lot of time meditating on sussman and stallman's old paper on constraint propagation, where one of the main applications is solving complicated circuits not amenable to linear methods
00:53:29 <psykotic> that's an awesome and underappreciated paper
00:53:39 <okie> psykotic: yep, he actually mentioned that paper to me when i first met him
00:53:54 <absentia> I can not igure out analog circuits
00:53:56 <ivanm> gah! the graphviz specs lie! they say that numbers don't contain exponents, but they do! :@
00:53:57 <absentia> I just can't do it.
00:54:04 <psykotic> absentia: it took me forever too
00:54:05 <okie> psykotic: the art of the propagator
00:54:18 <absentia> I've tried for decades.  I really just need someone who knows how it works to sit down and show me (teach me) ...
00:54:41 <psykotic> part of the problem is that kirchoff's laws are nonlocal
00:54:53 <psykotic> so you don't have any kind of simplistic local modularity the way you have with most programming languages
00:54:58 <absentia> anyway, back to writing bad code...
00:55:33 <psykotic> but at least you have equivalence theorems that makes modularity doable
00:55:47 <psykotic> anyway, i think all programmers should whip themselves into really grokking circuits
00:56:07 <hyko> hi everyone
00:56:19 <psykotic> okie: art of the propagator wasn't the original one, was it?
00:56:22 <psykotic> i thought that was the name of the latest one
00:56:45 <psykotic> the semi-sad thing about the recent work of his on propagators is that it's anachronistic
00:56:47 <okie> i learned analog circuits before i really started learning programming, and i think it made me like dataflow languages.
00:56:50 <FunnyCrap> Ciruits is what lies behind
00:56:52 <copumpkin> psykotic: that's an interesting article
00:56:52 <psykotic> he seems to have not kept up with developments for the last 30 years
00:56:58 <okie> psykotic: no, it's the latest one
00:57:40 <porges> yay, set monad: http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3634#a3634
00:57:41 <psykotic> not that reinvention isn't cool but in an academic setting, when you're of sussman's stature, it seems a bit weird
00:58:10 <psykotic> okie: right
00:58:18 <FunnyCrap> I failed to understand monad
00:58:20 <psykotic> okie: have you read the original one with stallman?
00:58:31 <FunnyCrap> Cuz I learn OOP then  functional programming
00:58:42 <FunnyCrap> I find monad is hard to understand
00:58:44 <okie> psykotic: no
00:59:00 <psykotic> okie: it's interesting because it was in the days when all those guys thought in terms of AI
00:59:12 <psykotic> so it feels completely different than constraint propagation its more modern guise, or even in the guise you find in steele's ph.d. thesis
00:59:26 <psykotic> that's probably why he hasn't kept up with developments, because even though they are relevant, they are from a different angle
00:59:52 <psykotic> the optimization and concurrent logic programming angle may be a bit alien to that
01:00:01 <okie> psykotic: that group at MIT really banged out some work spanning many topics
01:00:08 <psykotic> yep
01:00:24 <copumpkin> porges: why call the type function Point by the way?
01:00:31 <psykotic> did you watch that awesome talk by sussman where he talks about watches?
01:00:31 <porges> dunno
01:00:39 <porges> it's like a "point" in the object?
01:00:44 <FunnyCrap> where can I watch that
01:00:48 <psykotic> i have the same insane obsession with understanding shti like that, so i loved that
01:00:48 <copumpkin> porges: it seems more like extract from Copointed :P
01:00:52 <okie> i think they've been pretty dormant since they quit doing LSD
01:01:04 <porges> well there is a class I didn't include there
01:01:06 <copumpkin> porges: but I guess both work
01:01:11 <psykotic> http://mitworld.mit.edu/video/126
01:02:09 <FalconNL> Does anyone happen to have an example of how to call Haskell code from .NET using hs-dotnet?
01:02:11 <porges> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3634#a3635
01:02:12 <copumpkin> porges: I like your approach to that problem by the way :) it's a lot more elegant than the RMonad one, at the expense of needing new classes
01:02:41 <porges> then you have coPointed where extract :: f -> Point f
01:03:00 <copumpkin> yeah
01:03:11 <copumpkin> I'd call return point though :P
01:03:22 <copumpkin> never been a fan of the return name
01:03:29 <copumpkin> seems like a false friend to mislead newbies :P
01:03:34 <porges> well i'm using it with NoImplicitPrelude
01:03:42 <porges> so GHC gets angry if return doesn't exist :)
01:03:45 <copumpkin> oh boo
01:03:52 <copumpkin> silly GHC
01:04:45 <copumpkin> porges: so you gave up on the composition of functors for now?
01:04:53 <porges> yeah :P
01:05:14 <porges> newtypes with applied types inside them mess my head up for some reason
01:06:17 <copumpkin> hmm
01:06:22 * copumpkin plays with it
01:08:40 <malcolmw> ivanm: so what _does_ polyparse tell you on failure?
01:09:09 <ivanm> malcolmw: I get the exact parser it's failing
01:09:21 <ivanm> using adjustErr doesn't seem to always work :s
01:10:13 <malcolmw> ivanm: that probably means the failing parser isn't the one you have annotated with adjustErr
01:10:29 <malcolmw> it just looks similar
01:10:54 <ivanm> the overall one (i.e. the one that calls the one that calls the one that fails) has an adjustErr but doesn't say anything...
01:10:56 <ivanm> should it?
01:12:01 <malcolmw> ivanm: are you using the lazy variant, or the plain strict ones
01:12:02 <copumpkin> porges: this is rather mindbending, I see what you mean :)
01:12:05 <ksf> are Enum Instances of Number types expected to provide the next integer on succ?
01:12:18 <ivanm> malcolmw: lazy... :s
01:12:21 <ksf> that is, would stuff (including expectations) horribly break if it isn't so?
01:12:28 <malcolmw> ivanm: ah, yes, I thought so
01:12:36 <porges> ksf, well the floating classes already fail a bit
01:13:05 <ksf> ...yeah, but they do approximate integer increments.
01:13:20 <malcolmw> ivanm: if a strong error (i.e. unrecoverable) happens in the inner call, then the outer nested adjustErr will not be used
01:13:26 <ivanm> :(
01:13:58 <malcolmw> ivanm: that is the price we pay for lazy parsing I'm afraid - errors behave slightly differently
01:14:00 <ivanm> malcolmw: so if I used a non-lazy one, it would at least tell me what failed (i.e. what bit of text didn't match the expected parser)?
01:14:10 <malcolmw> ivanm: yes, probably
01:14:40 <ivanm> :(
01:15:08 <malcolmw> ivanm: my usual strategy is to have a separate lexing pass over the input, before the parser, and have the lexer attach source positions to the tokens it emits.  then the parsers can give good locations
01:15:19 <malcolmw> ivanm: even the lazy ones
01:15:32 <ivanm> have any examples online?
01:17:18 <malcolmw> ivanm: HaXml has a separate lexer, e.g. http://www.cs.york.ac.uk/fp/HaXml-devel/HaXml/src/Text/XML/HaXml/Lex.html
01:17:26 * ivanm has at least worked out which line of input fails...
01:17:54 <ivanm> gah! negative numbers!
01:18:08 <copumpkin> porges: I don't think it's possible, actually
01:18:15 <porges> :P
01:18:28 <copumpkin> porges: simply because your functor class has "kind" * -> * -> *
01:18:41 <copumpkin> and no newtype you stick there could fill two of those slots
01:19:00 <porges> yeah I was thinking maybe just newtype one of them
01:19:10 <porges> although it looks a bit weird
01:19:41 <copumpkin> even with that, it wants undecidable instances
01:19:49 <psykotic> does anyone know of programs/libraries using haskell-src-exts to do interesting things? i have an experiment in mind and would like to check out some other uses of the libraries first before i dive in.
01:21:04 <psykotic> e.g. applicative functor brackets
01:21:19 <porges> read my email :P
01:21:32 <porges> re; applicative brackets :)
01:21:37 <porges> not haskell-src-exts
01:21:37 <ivanm> psykotic: hlint
01:21:54 <ivanm> psykotic: and I'm using it atm for my sourcegraph app
01:22:23 <psykotic> ivanm: do you know anything that does syntax extention rather than just parsing?
01:22:40 <psykotic> it doesn't seem well suited for it but i thought i'd ask
01:22:50 <ivanm> psykotic: ummm.... not sure what you're asking here
01:23:28 <FalconNL> Any hs-dotnet users here?
01:23:31 <psykotic> in the simplest case you'd stick a preprocessor around the parser and do some processing of the output ast
01:23:40 <copumpkin> psykotic: I wanted that, but it looked very painful so I gave up
01:23:48 <psykotic> copumpkin: yeah, i'm fearing the same
01:23:50 <copumpkin> psykotic: you might want to look at SHE for syntax extension
01:24:01 <ivanm> psykotic: yes, but what would you do with it?
01:24:01 <copumpkin> it has a pretty minimal simple parser in it
01:24:04 <ksf> instance (Denominator a) => Enum (Fixed a) where
01:24:05 <ksf>     toEnum = Fixed . (* (denom (undefined :: a))) . fromIntegral
01:24:06 <ivanm> print the code back?
01:24:10 <ksf> how can I do what I want to do?
01:24:12 <psykotic> no
01:24:13 <malcolmw> psykotic: what you need is an input language that is in some way self-describing, i.e. you can write the desugarring of your new syntax as part of the input itself
01:24:14 <psykotic> prettification
01:24:15 <ivanm> (i.e. use HSX for code manipulation?)
01:24:37 <psykotic> i want to write a computer algebra system as sugared haskell for some of the user side
01:24:45 <psykotic> i already have a crapload of backend code i've written over the years
01:24:49 * copumpkin just wanted to extend haskell syntax in a preprocessor, without having to write a whole new parser for everything that's already there
01:25:20 <psykotic> malcolmw: that would obviously be especially nice.
01:25:28 <ksf> combinator parsing should actually be quite amendable to extension.
01:25:29 <psykotic> part of the problem is that parsers usually aren't modular, if you know whati  mean.
01:25:36 <psykotic> yes, but that requires it to be exposed in that way first.
01:25:54 <psykotic> one of the few examples of a full language implementation with self-extendable grammar i know of is metalua
01:26:04 <ivanm> malcolmw: if I have pa `onFail` pb, shouldn't pb be used if pa fails?
01:26:11 <psykotic> (worth checking out, btw)
01:26:18 <ksf> well, I bet copumpkin is going to bounce happily as soon as he discovers that he only needs to re-implement everything that's there _once_
01:26:23 <psykotic> haha
01:26:26 <dolio> camlp4 lets you extend the grammar of the language, too, I think.
01:26:38 <copumpkin> :)
01:26:41 <psykotic> dolio: that's kind of kludgy and preprocessor-ish
01:26:54 <psykotic> the way metalua does it is neat
01:26:56 <dolio> Is it? I've never used it.
01:27:10 <psykotic> aside from having a full reflective tower, you can extend the grammar (recursively) from the higher meta levels
01:27:27 <ksf> copumpkin, while you're at it, you could specify an sexpr syntax that the standard syntax desugars to.
01:27:28 <psykotic> the way it deals with extension is not as nice as combinator parsing, alas, but it's better than something like camlp4
01:27:45 <psykotic> the big problem with libraries extending syntax fundamentally is non-commutativity of extensions
01:27:58 <psykotic> so you need to have static analysis to detect such issues, ideally
01:28:04 <dolio> I'm not sure I see how combinator parsing is great for extending things.
01:28:13 <psykotic> metalua's approach is a rather hacky approach of assigning priorities to productions but that's non-composable
01:28:24 <psykotic> dolio: well, it lets you do anything.
01:28:36 <psykotic> you don't have some limited first-order language limiting the means of combination.
01:28:38 <ksf> dolio, because you can wrap whe whole of parsec in data constructors and then interpret/mess with them.
01:28:41 <ivanm> malcolmw: because I have a case where it doesn't :s
01:28:46 <dolio> Because if you need to add something at level n, you need to change things at every level of parsing k<n, too, because they're no longer the defaults.
01:28:56 <malcolmw> ivanm: with plain strict combinators, yes, but not necessarily in a lazy setting.
01:29:02 <ivanm> :s
01:29:02 <psykotic> dolio: right, you'd really need something like arrows allowing for static analysis as well
01:29:09 <ivanm> it's worked everywhere else so far, why not here :(
01:29:16 <psykotic> unfortunately what i've seen of arrow parsing made me throw up a little in my mouth
01:29:27 <ski> porges : which email ?
01:29:28 <malcolmw> ivanm: (failBad "urk") `onFail` pb   will not use pb
01:29:38 <psykotic> it would be really nice to approach it in terms of abstract interpretation
01:29:38 <ivanm> malcolmw: well, I don't have a failBad
01:29:47 <psykotic> so static analysis would just be a specific abstract interpretation
01:29:59 <ivanm> I know exactly where and why the first parser fails; it just doesn't want to try the next one
01:30:16 <malcolmw> ivanm: but maybe there is a failBad hidden inside some other combinator you use
01:30:28 <nlogax> ksf: just tried haiku again, now that you mentioned it. pretty nice! too bad the bundled web browser takes longer to start than the OS. :)
01:30:32 <malcolmw> ivanm: paste it for me
01:30:38 <psykotic> anyway, for what i want i don't need arbitrary self extension
01:30:47 <porges> ski: on Haskell-cafÃ©; just a short idea about writing an extension/preprocessor to have a more extensible syntax
01:31:09 <psykotic> porges: btw what's SHE? can't find anything on google
01:31:14 <mmorrow> , [$i| (,,) "asdf" [0..4] [Nothing,Just()] |]
01:31:16 <lunabot>  [('a',0,Nothing),('a',0,Just ()),('a',1,Nothing),('a',1,Just ()),('a',2,N...
01:31:19 <dolio> @hackage she
01:31:19 <lambdabot> http://hackage.haskell.org/package/she
01:31:22 <porges> Strathclyde Haskell Extension
01:31:26 <ksf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9443#a9443
01:31:34 <ksf> someone please tell me how to do stuff.
01:31:38 <porges> s/enhancement
01:31:52 <ksf> I'm obviously lacking type information there.
01:32:04 <psykotic> version 0.0, nice
01:32:22 <psykotic> i do remember seeing conor's post about that, now
01:32:44 <porges> where did I say SHE? :)
01:32:57 <psykotic> maybe it was someone else
01:33:03 <copumpkin> twas I
01:33:37 <psykotic> in that case, thanks :)
01:33:41 <copumpkin> psykotic: there's a minimal parser in there called parsley or parsely, that he used to expand the syntax
01:33:53 <psykotic> it may be enough for what i want
01:33:56 <copumpkin> porges: alright, I give up :P
01:34:10 <psykotic> since i don't anticipate this algebraic extension being used for anything too fancy
01:34:10 <mmorrow> psykotic: here's a quick hack (for this one particular program, although it should work for arbitrary modules) to instrument every function to print out the closure-type of its args when it's evaluated  http://moonpatio.com/repos/hs_instrument.hs
01:34:23 <psykotic> mmorrow: thanks!
01:34:26 <mmorrow> psykotic: but either way, that's an example of using haskell
01:34:27 <mmorrow> np
01:34:28 <mmorrow> :)
01:34:35 <mmorrow> *-src-exts
01:34:39 <ksf> so, how do I select a class instance of a phantom type that's in the _return_ value of a function?
01:34:47 <copumpkin> porges: I can write the instance head, but not the definition of the value-level function :(
01:34:54 <ski> porges : <http://www.haskell.org/pipermail/haskell-cafe/2009-September/066414.html> ?
01:35:11 <porges> yeah
01:35:37 <porges> some kind of thing that lets you write 'template' operators in TH, that are spliced in
01:35:37 <mmorrow> psykotic: (in case you try to build a module you've run through that, you may need to fiddle with how it's importing Prelude qualified (the particular module that was originally for was doing that..))
01:35:49 <porges> plus brackets :P
01:35:59 <mmorrow> (importing Prelude qualified in the generated code, that is)
01:36:00 <psykotic> mmorrow: it's surprisingly not-ugly, your code
01:36:12 <psykotic> i mean, from judging from the api docs
01:36:17 <psykotic> i was expecting it to be ickier :)
01:36:22 <mmorrow> yeah, it's super easy
01:36:47 <ivanm> malcolmw: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9444#a9444
01:37:13 <mmorrow> psykotic: well, "super easy" may be an understatement, but not by too much ;)
01:38:03 <psykotic> easier than expected is good enough for me :P
01:38:18 <mmorrow> psykotic: here's what that does too: http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3536#a3536
01:39:00 <mmorrow> (all the way at the bottom in the third paste is (part of) the instrumented code for that module)
01:39:49 <ivanm> malcolmw: for some reason, having the negative there makes a difference :s
01:40:10 <ivanm> malcolmw: is it because of the commit usage?
01:40:50 <malcolmw> ivanm: OK, I believe the problem is here: intDblPoint = (liftM (uncurry PointD . first fI) $ commaSep' parseUnqt parseStrictFloat) ...
01:40:57 <ivanm> yeah
01:41:02 <ivanm> but _why_? :s
01:41:33 <malcolmw> ivanm: liftM is essentially applicative I think
01:41:41 <ivanm> liftM == fmap for monads
01:41:45 <mmorrow> psykotic: this one adds the classes you specify at the cmd line to all the "deriving(..here..)" parts of each data decls in the given module http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3637#a3637
01:42:05 <malcolmw> ivanm: so you are guaranteeing to return a PointD
01:42:14 <porges> liftM should be stabbed
01:42:15 <ivanm> yup
01:42:19 <malcolmw> ivanm: whose contents might contain errors
01:42:30 <ivanm> malcolmw: OK, thing it was the usage of commit in parseSigned
01:42:36 <ivanm> porges: why?
01:42:45 <porges> so we just have fmap :)
01:43:06 <malcolmw> once the consumer of the PointD has seen the PointD, it can't then backtrack to the other `onFail' possibilities
01:43:18 <ivanm> malcolmw: I needed intDblPoint there because cases like "1,2.3" were being parsed as (Point 1 2) with a trailing ".3" rather than (PointD 1.0 2.3)
01:43:56 <mmorrow> psykotic: and finally, this prog is super handy to format code (machine-generated code in particular, e.g. the output of Show), and i usually use this as the beginning template for cmd-line utils that do something to a module stdin->stdout   http://moonpatio.com/repos/derive-gadt/tools/hstidy.hs
01:44:08 <psykotic> mmorrow: you're a star, thanks for all the code :)
01:44:27 <mmorrow> psykotic: no problem
01:45:25 <ivanm> malcolmw: well, AFAICT the problem was that when parsing that case, it parsed "-1.8" as "-1" and couldn't find the comma next; but because parseSigned used commit it couldn't then backtrack
01:45:47 <malcolmw> ivanm: yes, I think you are right
01:46:12 <ivanm> I know that removing commit from there fixed it, that's just my guess of _why_
01:46:31 <malcolmw> ivanm: if any of the interior of pa uses commit (in pa `onFail` pb), then pb will never be reached
01:46:44 <ivanm> *nod*
01:47:07 <psykotic> btw is there an easy way of decoupling infix operators from type classes without running afoul of the monomorphism restriction?
01:47:07 <malcolmw> ivanm: that is, if the control flow of pa takes it through the execution path where commit is used
01:47:25 <psykotic> in the past i've had to force NoMonomorphismRestriction to deal with that
01:47:26 <ivanm> *nod*
01:51:49 <ksf> providing type signatures
01:52:27 <ksf> it's not like the polymorphic types are illegal, haskell98 just refuses to infer them.
01:53:50 <quicksilver> psykotic: the monomorphism restriction is stupid, ignore it
01:54:01 <quicksilver> psykotic: you can either turn it off, or just give explicit type signatures
01:54:13 * ksf is still wondering how to parametrize the 64 in
01:54:14 <quicksilver> psykotic: but certainly don't feel you are "doing something wrong" if you fall afoul of it.
01:54:14 <ksf> instance Enum (Fixed a) where
01:54:14 <ksf>     toEnum = Fixed . (* 64) . fromIntegral
01:54:34 <quicksilver> ksf: well, have you seen how the existing Data.Fixed does it?
01:55:12 <ksf> zomg.
01:55:18 <ksf> I GOOGLED HALF AN HOUR!
01:55:56 <ski> (ksf : s/polymorphic/constrained polymorphic/)
01:55:59 <ivanm> ksf: did you goggle at the google results? :p
01:57:20 <ksf> uh Data.Fixed doesn't seem to do it.
01:57:40 <ksf> it doesn't seem to enumerate in integer steps
01:58:01 <quicksilver> > [0,0.1..1.0] :: [Double]
01:58:02 <lambdabot>   [0.0,0.1,0.2,0.30000000000000004,0.4000000000000001,0.5000000000000001,0.60...
01:58:06 <quicksilver> > [0,0.1..1.0] :: [Micro]
01:58:06 <lambdabot>   [0.000000,0.100000,0.200000,0.300000,0.400000,0.500000,0.600000,0.700000,0....
01:58:28 <ksf> > succ 0.1 :: Micro
01:58:29 <lambdabot>   0.100001
01:58:37 <quicksilver> no, it enumerates in 'smallest increment' steps
01:58:42 <ksf> > (succ.succ) 0.1 :: Micro
01:58:42 <lambdabot>   0.100002
01:58:45 <psykotic> quicksilver: i know, it was more a random question :)
01:58:47 <quicksilver> arguably a better way.
01:58:55 <ksf> ...but not standard num.
01:58:57 <psykotic> quicksilver: every time i write anything in haskell i incrementally end up adding three lines of -X flags :)
01:59:05 <ksf> ...and exacly the problem I was having.
01:59:14 <ksf> > (succ.succ) 0.1 :: Float
01:59:15 <lambdabot>   2.1
01:59:22 <quicksilver> psykotic: you should use {-# LANGUAGE #-}
01:59:31 <psykotic> quicksilver: that's the 'all in' one?
01:59:35 <psykotic> didn't know that. doh.
01:59:42 <quicksilver> no, it's just a way of putting flags in the source
01:59:47 <quicksilver> not on the command line
01:59:54 <psykotic> oh, i do put it in files
01:59:57 <psykotic> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9423#a9423
02:00:07 <quicksilver> yes, btu don't use OPTIONS
02:00:16 <quicksilver> OPTIONS is evil and made of torturing kittens
02:00:18 <psykotic> oh that way you don't have to specify -X?
02:00:19 <quicksilver> use LANGUAGE
02:00:24 <psykotic> i see
02:00:29 <psykotic> but i hate kittens
02:00:53 <psykotic> i will take great pleasure in using OPTIONS from now on, thank you for your valuable information, sir
02:04:05 <quicksilver> psykotic: seriously, OPTIONS is ghc specific
02:04:16 <quicksilver> LANGUAGE is the proposed compiler-neutral standard
02:04:18 <bastl> i need assistance with getting scion+vim to run under ubuntu: scion needs python 2.7, ubuntu only has python 2.6 :-( . vim has to be recompiled to use another python version (like python3). Can anyone help ?
02:04:23 <quicksilver> and much more likely to be intelligently recognised by tools
02:04:48 <psykotic> gotcha
02:07:12 <quicksilver> psykotic: most of the common GHC language extensions are perfectly sane. OverlappingInstances and IncoherentInstances are pretty nasty, and I'm not fond of ImplicitParameters.
02:07:38 <psykotic> yeah, ImplicitParameters is particularly weird.
02:08:01 <psykotic> OverlappingInstances can be the most natural way to do a lot of things, it's not quite in the same category, imo.
02:09:18 * ski agrees that it is nasty
02:09:36 <copumpkin> ImplicitParameters would be quite nice if it behaved more "composably"
02:09:57 <copumpkin> (as a way of emulating typeclasses and making them do things that typeclasses don't normally do)
02:10:03 <psykotic> right
02:10:17 <psykotic> scala emulates type classes that way, it can be nice but it has composable issues, as you say
02:10:17 <ski> `ImplicitParameters' is a (weak) kind of side-effect
02:11:05 <ketil> I'm trying to install cabal-install using bootstrap.sh, but there's a problem with -lgmp missing.  Anybody know which version is needed?  The system has libgmp-3.3.3
02:11:16 <psykotic> ski: is that supposed to make us recoil in horror? :)
02:11:36 <copumpkin> ski: so are typeclasses :P
02:11:36 <ski> psykotic : i don't know :)
02:12:10 <ski> copumpkin : agreed. but the uniqueness of instances removes most of the trouble
02:12:24 <copumpkin> I'd recoil in horror if the implicit instances set inside a scope affected the outside of it
02:12:39 <copumpkin> I mean
02:12:42 <copumpkin> implicit parameters :)
02:12:51 <ski> elaborate ?
02:12:56 <amckinley> stupid question: how can i stop execution and print a string to stdout from any arbitrary location in my haskell program?
02:13:23 <copumpkin> ski: not even sure what I mean, now that I think of it... it's so horrific it can't even be thought of coherently :P
02:13:25 * ski doesn't think side-effects are inherently bad, only that one should be aware of when they are used, and use them in moderation
02:13:35 <copumpkin> probably just me @ 5:15 am
02:13:47 <psykotic> amckinley: you can use unsafePerformIO but be aware of the usual issues with strictness
02:13:55 <bastl> is there any gtk2hs mage around?
02:13:56 <amoeba> amckinley: import Debug.Trace and use trace maybe?
02:14:00 <amckinley> psykotic: awesome sauce, thanks
02:14:08 <ski> amckinley : if this is for debugginf, try `Debug.Trace.trace' ?
02:14:16 <psykotic> and trac is good for just printing if you dn't want to stop execution
02:14:18 <psykotic> *trace
02:14:34 <amckinley> ski: yep, this is for debugging. should i check out that module before busting out unsafePerformIO?
02:14:35 <copumpkin> amckinley: if you want some sort of "logging" behavior in your program, and it isn't just for debugging
02:14:38 <copumpkin> oh ok
02:14:39 <ketil> ..that is, the RPM package is gmp-4.1.4, but it contains libgmp.so.3.3.3.
02:14:52 <copumpkin> amckinley: it just uses unsafePerformIO behind the scenes :) but probably better
02:14:52 <ski> amckinley : certainly !
02:15:10 <psykotic> it has a reassuring name
02:15:10 <saynte> ketil: perhaps try linking libgmp.so -> libgmp.so.3.3.3 in /usr/lib ? not sure if thats really a nice solution though....
02:15:14 <psykotic> totallySafeTrace
02:15:27 <ski> amckinley : you don't want to use `unsafePerformIO' unless you really need to, and aware of the full implications
02:15:36 <copumpkin> amckinley: anyway, for less nasty (if more work) way to do it, look at Writer too :)
02:15:43 <ski> s/and aware/and are aware/
02:16:01 <ksf> ketil, gmp-dev?
02:16:20 <amckinley> ski: copumpkin: i know, im just doing a quick and dirty debugging job :) hopefully the haskell gods wont strike me down...
02:16:21 <psykotic> even better would be to just use a debugger if you're trying to inspect a single value at some point in the execution
02:16:25 <ketil> ksf: ah, it needs to link statically, no?
02:16:29 <psykotic> of course i have no idea if the ghci debugger is actually usable
02:16:32 <ksf> ...binary distros tend to lack header files, which would explain cabal thinking gmp isn't there.
02:16:38 <copumpkin> it is, but it takes getting used
02:16:39 <copumpkin> to
02:16:55 <psykotic> well there are the strictness issues
02:17:00 <psykotic> but they should be the same in thsi case as with logging
02:17:05 <ksf> (depends on whether you get a configure or a linker error)
02:17:17 <amoeba> amckinley: you can also use the ghci debugger maybe
02:17:18 * psykotic remembers reading the original paper on the debuger
02:17:18 <ski> amckinley : `trace' is made for that situation
02:17:47 <Alpounet> http://ro-che.blogspot.com/2009/09/ccc-6-hwn.html haha nice
02:18:13 <ski> @hoogle callWithHaskellGod
02:18:13 <lambdabot> No results found
02:18:25 <psykotic> callOfCthulhu you mean
02:19:00 <psykotic> Ia, Shub-Niggurath!
02:19:08 <psykotic> that's what you should be required to intone instead of the pedantic-sounding unsafePerformIO
02:19:30 <porges> copumpkin: issues when I introduce guard
02:19:33 <porges> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3634#a3638
02:19:38 <porges> becomes ambiguous :P
02:19:45 <copumpkin> oh no
02:20:28 <copumpkin> porges: by the way, this feels very much like an alt-stdlib ;)
02:20:44 <copumpkin> porges: which conveniently we just founded a channel for!
02:20:55 <copumpkin> porges: #alt-stdlib :P
02:25:35 <amckinley> ski: copumpkin: psykotic: im having problems understanding how Debug.Trace.trace and System.IO.Unsafe.performUnsafeIO are interacting with my existing monadic code
02:25:51 <copumpkin> amckinley: you shouldn't have to use unsafePerformIO with trace
02:25:57 <copumpkin> it's doing it for you behind the scenes
02:26:03 <Tobsan> :t Debug.Trace.trace
02:26:03 <lambdabot> forall a. String -> a -> a
02:26:09 <amckinley> copumpkin: i know, im saying i tried both and i cant get either one to work :)
02:26:10 <copumpkin> but if you're already in IO, you shouldn't need trace
02:26:23 <amckinley> mostly because im too tired to decipher typecheck errors :P
02:26:26 <ski> <ski> amckinley : you don't want to use `unsafePerformIO' unless you really need to, and are aware of the full implications
02:26:27 <copumpkin> amckinley: trace will only print something when the thunk gets evaluated
02:26:44 <ksf> what's the preferred representation of simple 2d-vectors?
02:26:49 <ski> amckinley : try pasting the code for scrutiny ?
02:26:50 <copumpkin> amckinley: oh, in terms of types, it behaves just like id
02:26:52 <ksf> (parametrized over member types)
02:26:52 <porges> uvector?
02:27:06 <ski> @paste
02:27:06 <lambdabot> Haskell pastebin: http://moonpatio.com/fastcgi/hpaste.fcgi/
02:27:19 <opqdonut> ksf: good question. most code goes with something custom like TwoVector a = TwoVector a a
02:27:31 <opqdonut> but there are many libraries that implement vector math too
02:27:46 <amckinley> ski: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9445#a9445
02:27:49 <copumpkin> I wouldn't use uvector if you're talking about R^3 kind of vectors
02:28:17 <copumpkin> amckinley: ooh facebook! I know someone who works there
02:28:20 <ksf> uvector seems to be overkill
02:28:29 <ksf> ...looks more like an array library.
02:28:45 <copumpkin> ksf: yeah, it is
02:28:49 <amckinley> copumpkin: cool stuff! :D
02:29:01 <ski> amckinley> :t parseConf
02:29:17 <ksf> yep, I'm just looking for a library that spares me the agony of writing a num instance for TwoVector a.
02:29:50 <ksf> (I don't even need fancy stuff like multiplication)
02:29:51 <porges> R^3 is barely legal to call a vector ;)
02:30:02 <copumpkin> lol
02:31:37 <amckinley> ski: i was actually trying to figure that out, going back and looking at this code :)
02:33:02 <ski> amckinley : if you remove that nonsensical `unsafePerformIO ...' line, does it typecheck ? (and what type do you get for `parseConf' then ?)
02:33:54 <amckinley> ski: yep, it typechecks fine. give me one sec...
02:35:05 <ski> @index second
02:35:05 <lambdabot> Control.Arrow
02:38:05 <amckinley> ski: *Main> :t DnsParse3.parseConf
02:38:05 <amckinley> DnsParse3.parseConf
02:38:06 <amckinley>   :: String
02:38:06 <amckinley>      -> String
02:38:06 <amckinley>      -> Either Text.Parsec.Error.ParseError [DnsTypes.DnsObject]
02:38:20 <ski> (ok, `Either ParseError', ty)
02:39:07 * ksf is puzzled by the fact that my math book doesn't define cross products for 2-vectors
02:40:09 <psykotic> you mean the perp dot product?
02:40:24 <ski> ksf : it's only defined on 0-,1-,3-,7- dimensional vectors, iirc
02:40:40 <psykotic> there's a scalar-valued "cross product" in R^2
02:40:42 <ziman> what's the rule behind those numbers?
02:40:49 <psykotic> namely, counterclockwise rotate the second operand and dot it with the first
02:40:55 <psykotic> err, by 90 degrees
02:41:11 <porges> aha!
02:41:15 <ksf> well, that isn't typeable as a num instance.
02:41:29 <psykotic> that gives the same answer as if you embedded R^2 in the xy plane of R^3, took the cross product (which will be perpendicular to the xy plane) and extract its signed magnitude
02:42:31 <psykotic> i.e. it equals the product of the magnitudes times the sine of the directed angle between the vectors
02:43:10 <psykotic> ski: even in R^7 you don't have all the nice properties you might expect, but you're right.
02:44:24 <psykotic> by taking a vector space with any cross product and adjoining a vector, denoted 1, that is a formal multiplicative unit with respect to the cross product, you get an n+1 dimensional normed real division algebra
02:44:36 <psykotic> and there's a standard classification theorem for them that says they only exist in dimensions 1, 2, 4 and 8
02:45:02 <ksf> speaking about a new numeric prelude, such basic things have to be part of that.
02:45:15 <ski> amckinley : hum, forgot about answering for a short while .. you can try prefixing your `runParser ...' line with `traceShow tokens $ '
02:45:32 <psykotic> whenever i start thinking about numeric preludes, etc, i end up being unable to decide between simplicity and extremely fine granularity
02:45:38 <psykotic> in the 'tower' of algebraic structures
02:45:47 <ksf> ...of course including the right classes to differentiate between cross and scalar products etc.
02:45:51 <psykotic> i think that's part of why there's no real consensus
02:46:08 <ksf> what about a simple frontend to a fine-grained backend?
02:46:34 <ksf> ...that is, hide the complexity for commonly used features.
02:46:46 <psykotic> sure
02:46:49 <psykotic> i mean, you can already do that
02:47:03 <psykotic> but if oyu don't expose the fine grained intermediate levels in the standard then people won't code against it and they might as well not exist
02:47:03 <ksf> basic vector algrebra is quite standard, just think of 2d and 3d graphics.
02:47:14 <psykotic> those are also extreme special cases
02:47:22 <ksf> it's mostly addition and substraction.
02:48:04 <Smokey`> vector algebra is an extreme special case!?!
02:48:08 <psykotic> in 2d and 3d
02:48:17 <psykotic> in terms of the general algebraic structure of vector spaces, even inner product spaces
02:48:34 <ksf> ...with "simple frontend" I mean something that you can just use without knowing anything about "real" algrebra. Not to hide stuff, but to simplify to say high-school level.
02:48:39 <psykotic> what i'm saying is that if you build your type classes around the case of 2d and 3d vectors, you get a special case mess
02:48:42 <psykotic> right
02:48:42 <Smokey`> most vector algebra can be written independant of dimensionality...
02:48:55 <psykotic> smokey: except for things like the cross product, which is bread and butter of 3d vector geometry
02:48:59 <psykotic> that's what we were talking about
02:49:19 <Smokey`> indeed, cross product is a bit different though - not only does it depend on dimensionality, but coordinate system
02:49:20 <psykotic> if you want to do cross product like things in any dimension, you need clifford algebra
02:49:29 <psykotic> not coordinate system
02:49:31 <psykotic> it only depends on orientation
02:49:58 <Smokey`> left/right handed cross products are different if i'm not mistaken
02:50:01 <psykotic> yes
02:50:05 <psykotic> that's what orientation means
02:50:08 <Smokey`> that's what i meant by coordinate system :P
02:50:08 <ksf> ...do your clifford stuff (whatever that is), and provide separate Vector2 and Vector3 modules so I can use it.
02:50:13 <psykotic> a coordinate system is much more specific
02:50:13 <amckinley> ski: that does exactly what i want :) thanks!
02:50:32 <psykotic> it doesn't depend on whether you're computing in an orthonormal or a skew coordinate system, for example
02:51:05 <Smokey`> orthonormal and skew 'coordinate systems'?  I think we have very different backgrounds in our terminology :)
02:51:10 <psykotic> the only thing that matters is the sign of the determinant of the linear map that connects two coordinate systems, i.e. there's two equivalence class of coordinate systems corresponding to same and opposite determinantal sign
02:51:25 <Smokey`> *nods*
02:51:41 <psykotic> by skew i meant non-orthogonal
02:52:08 <psykotic> the kind graphics programmers like to forget about :)
02:52:13 <Smokey`> :P
02:52:23 <psykotic> everything's so much easier when you can just transform between coordinate systems by taking dot products :)
02:52:37 <Smokey`> cross product can also technically be written independant of dimensionality, but you're right - you'd need special cases
02:52:48 <psykotic> no, it can't if you want basic properties to hold
02:53:00 <psykotic> you can define an exterior product but that produces a bivector, not a vector
02:53:11 <opqdonut> phantom dimensions
02:53:14 <ksf> psykotic, there's much more fun coordinate systems.
02:53:17 <ksf> like hexgrids.
02:53:18 <opqdonut> Vector Three Double
02:53:19 <psykotic> in 3d a bivector is hodge dual to a vector, so in that specific case you can use that to define a vector-valued exterior product
02:54:25 * ksf would also like to see a haskell implementation of synergetics.
02:54:40 <psykotic> ksf: those are not coordinate systems in the vector space sense
02:54:52 <ksf> (the only math-related book I ever actually came close to grokking)
02:54:56 <psykotic> well, they are, but they are sometimes called frames rather than bases because of the redundancy/non-uniqueness
02:56:01 * porges1 wants monad comprehensions
02:56:10 <psykotic> porges: hack she! )
02:56:20 * psykotic misses them too sometimes
02:56:26 <porges1> I have a feeling it would be easier to change GHC
02:56:33 <psykotic> heh, most likely right
02:56:34 <porges1> probably just swap concatMap for (=<<)
02:56:37 <porges1> etc
02:57:07 <porges1> I don't have enough hd space for a GHC build at the moment though :(
02:57:21 <ksf> didn't they already open up comprehensions for the stream types?
02:57:34 <ksf> ...you could just bind =<< to concatMap...
02:58:29 <porges1> I think comprehensions are still hardcoded to lists
02:59:23 <porges1> yup
03:00:59 <ski> (porges1 : is `combo' supposed to be roughly `liftA2 (,)' ?)
03:02:27 <porges1> i was just using it to test 'guard'
03:02:41 <ivanm> is there a better approach than (\ d -> d == fromIntegral (round d)) to see if a Double is an "integral" value?
03:06:30 <psykotic> the floating point gods weep at your non-tolerance-based equality test
03:06:47 <psykotic> fortunately doubles have exact representation of all integers less than 53 bits :)
03:07:00 <ivanm> hmmm?
03:07:59 <psykotic> my point is, when i put my numerical analysis hat on, i'd have to ask for context to decide whether that's a good test or not. anyway, not related to haskell per se.
03:08:21 <ksf> why does properFraction return a tuple?
03:08:37 <ksf> the first one is equivalent to truncate, anyway, so what's the point?
03:09:05 <lilac> what about (<*>)? :)
03:09:21 <psykotic> ksf: presumably it's to mirror divMod, etc
03:09:23 * lilac caught out by the Dangers Of Scrollback again
03:10:07 <ksf> ...well yes, but there's separate div and mod methods, too.
03:11:29 <ivanm> psykotic: well, I want it because when printing Doubles, to match upstream I should print "2" and not "2.0"
03:11:36 <ivanm> lilac: lol
03:11:45 <psykotic> in that case it's fine
03:11:55 <ksf> and I want to have properFraction without implementing Real and Fractional, I don't wanna have division.
03:12:14 <psykotic> (as long as you don't expect to use it for serialization)
03:12:27 <ivanm> psykotic: *phew*
03:12:28 <ivanm> ;-)
03:12:30 <psykotic> hehe
03:12:33 <psykotic> well, i'm just saying
03:12:36 <psykotic> floating point makes me paranoid
03:13:05 <ivanm> heh
03:13:08 <psykotic> i've spent several years doing physics simulation work, so when i see an exact equality test involving floats, my eyebrows twitch :)
03:13:16 <ivanm> @remember psykotic floating point makes me paranoid
03:13:16 <lambdabot> It is stored.
03:13:18 <ksf> (actually I just want to avoid implementing recip etc. for vectors in a wrong way)
03:13:35 <psykotic> ksf: just leave them unimplemented
03:13:38 <ksf> ...all those round and truncate functions make sense and are useful.
03:13:50 <psykotic> that's pretty much your only option with the numeric prelude, because of how horrible it is
03:14:20 <stanv> is it possible to observe (>) definition for Data Char ?
03:14:31 <ksf> is there some wiki page of guys doing numeric preludes where I can add use cases?
03:16:17 <psykotic> i don't know of any concerted effort. i've seen a bunch of distinct proposals, probably haskell-cafe is a good place to search
03:17:23 <ksf> well I'm not really interested in working on it, I'm just worried that math guys are going to use rings in a way that is as penetratable to mortals as chain mail.
03:18:05 <psykotic> right, because haskell lays out the red carpet for those people already :)
03:18:09 <nextstep> Hi. Is it anywhere list of primary needed haskell libs/programms that should be written?
03:18:27 <ksf> a new numeric prelude.
03:18:32 <ksf> step right into the discussion.
03:18:36 <psykotic> writing one is easy
03:18:38 <lilac> stanv: instance Ord Char is defined here: http://hackage.haskell.org/packages/archive/base/3.0.3.1/doc/html/src/GHC-Base.html
03:18:40 <psykotic> the problem is consensus
03:19:44 <lilac> stanv: but (>) for Char for GHC just unboxes then calls the gtChar# primop, so i don't think it's particularly enlightening
03:20:30 <ksf> let's make a deal: guide me in writing a boilerplate wrapper for your favourite one to do sub-pixel 2d arithmetic and I'm going to use it.
03:21:32 <stanv> lilac: thanks
03:21:48 <ksf> ...I don't really care about its backend as long as I've got (+) and (-), multiplication with scalars and splitting a vector into two integer-part/fractional-part vectors.
03:21:51 <psykotic> just use floats, they have more than enough precision for texture mapping. unless you are doing hardware, you don't need to do fixed point for that.
03:22:10 <ManateeLazyCat> I wonder someone have create package that accept input and return completion list for English Word, if have it, i like reference. Otherwise i will create it self.
03:23:17 <psykotic> oh, you're talking about the num instance for vectors
03:23:54 <ksf> ...I'm using fixed points as that's what freetype uses. also, it doesn't make sense to raster glyphs at arbitrary sub-pixel positions. 64 (*64) are already more than enough.
03:24:25 <psykotic> i'm not talking about rastering them at arbitrary precision but having enough for the intermediate arithmetic
03:24:28 <psykotic> anyway
03:24:35 <psykotic> i guess i don't see the problem
03:25:02 <stanv> lilac: I'm interesting how ghci dereving Ord for user defined type such as: data Temp = Cold | Hot
03:25:10 <psykotic> make a vector a list of numbers, use unzip on properFraction to split it into a pair of vectors of integral and fractional components
03:25:53 <ksf> uhm I just think I'm worried about breaking invariants of the hinter algorithms when I don't add my vectors at the same resolution.
03:26:23 <ksf> ...I only need 2-Vectors.
03:26:41 <psykotic> that's even easier, i still don't see the problem though?
03:27:21 <psykotic> don't implement properFraction for your vector, if that's what you're thinking
03:27:25 <psykotic> just define a new function.
03:27:56 <psykotic> this is super simple, i'm not sure why you're stressing about non-standard numeric preludes
03:28:09 <ksf> there's no problem. But it'd be a pity if such a specialisation wouldn't be expressible in a new numeric prelude without leaving methods unimplemented.
03:28:35 <psykotic> i don't think properFraction is the kind of thing that should be implemented as part of a type class for vectors
03:28:37 <ksf> why shouldn't I implement properfraction?
03:28:37 <pozic> There is a numeric prelude, which is pretty complete, but it is GPL.
03:29:12 <psykotic> because the natural semantics of vectors aren't compatible with the laws expected of properfraction
03:29:22 <psykotic> for example, here's a natural invariant:
03:29:33 <psykotic> taking the proper fraction and dividing the components again should yield the original input
03:29:52 <ksf> I don't plan on implementing division
03:29:54 <psykotic> unless you define arithmetic for vectors pointwise (which is usually not what you want), that wouldn't hold
03:30:10 <psykotic> right
03:32:17 <ksf> ...but then, interpreting * and / as wheighted scaling actually _does_ make sense.
03:33:29 <psykotic> what you're doing there is modding out by a lattice
03:33:57 <ksf> ...what I'm doing is implementing a boilerplate numeric type for 2d graphics.
03:34:00 <psykotic> if the lattice was skew, it wouldn't be pointwise arithmetic
03:34:39 <psykotic> i was trying to explain why the pointwise interpretation makes sense in that specific case but not for general lattices. anyway, if i were you, i'd stop worrying and start coding, since there's no problem here.
03:37:09 <lilac> stanv: ah well, that's a different story. see here for details on that: http://www.haskell.org/onlinereport/derived.html
03:37:42 <lilac> stanv: in short, it's basically a lexicographic ordering (including the contructors which are ordered in the order you give them)
03:39:32 <quicksilver> most of the standard deriving violate code transformation invariants (yay!)
03:39:35 <quicksilver> alpha-conversion etc.
03:40:20 <psykotic> quicksilver: that's true if you can print the name of types, even :)
03:40:46 <quicksilver> of course.
03:40:47 <psykotic> so it's not as dirty as it sounds
03:40:49 <lilac> quicksilver: that's a surprise (apart from for Read and Show, where it's clearly desired); do you have an example
03:40:56 <quicksilver> it's worth than it sounds, psykotic
03:41:07 <quicksilver> it breaks all kinds of interesting refactorings and even possibly optimisations.
03:41:36 <quicksilver> lilac: well, Ord breaks the isomorphism between "data Foo = Bar | Baz" and "data Foo = Baz | Bar"
03:41:39 <psykotic> if you're trying to print a value of a type alongside its name, you need to specify it somehow
03:41:51 <psykotic> i don't think hard coding the name in a string literal is an improvement in terms of refactoring, on the contray
03:42:10 <psykotic> but i agree about the ord thing you just mentioned
03:42:46 <psykotic> but i agree if you're trying to do e.g. robust serialization you need to decouple names in code from names in data files
03:42:48 <lilac> quicksilver: i assume you mean the reordering one rather than the alpha-conversion one :)
03:42:55 <psykotic> ideally not even using names but maybe guids or some other stable identifiers
03:43:47 <quicksilver> lilac: haha :) yes.
03:43:51 <lilac> quicksilver: i guess it's clearer in 'data Maybe a = Just a | Nothing' versus 'data Maybe a = Nothing | Just a'
03:44:10 <quicksilver> yes.
03:44:34 <psykotic> if you want a specific order isomorphism with numbers, say, you should say it out loud :)
03:44:55 <psykotic> i'm glad that ghc has some DWIMness
03:45:40 <lilac> two things i've often wondered about derived instances: 1) does the derived Ord start with a comparison on the tag, or does it do a case analysis? 2) does the derived Eq start with a pointer comparison?
03:46:04 <lilac> (or are they both implemented the same way that we would implement them in real haskell?)
03:46:05 <quicksilver> lilac: no, in each case they produce something that could have been written in normal haskell, afaik.
03:46:16 <quicksilver> psykotic: I'm not saying it's not an understandable trade-off ;)
03:46:19 <psykotic> hehe
03:46:21 <quicksilver> there are reasons you might want these things.
03:46:42 <quicksilver> but it amuses me that they do violate some of the things that, at other times, we claim to be the advantages of haskell.
03:46:47 <psykotic> yes, it's true
03:46:52 <psykotic> and most people probably don't realize it
03:47:07 <psykotic> i haven't thought through all the different classes but i had explicitly thought of the ord issue before
03:47:16 <psykotic> and show/read is kind of obvious
03:47:23 <quicksilver> > let constr x = takeWhile (/=' ') . show in constr (Just 3)
03:47:23 <lambdabot>   {()->"()"}
03:47:30 * quicksilver blinks
03:47:41 <quicksilver> > let constr = takeWhile (/=' ') . show in constr (Just 3)
03:47:42 <lambdabot>   "Just"
03:47:54 <ziman> wow
03:48:14 <ziman> > takeWhile (/=' ') . sho
03:48:15 <lambdabot>   Not in scope: `sho'
03:48:15 <lilac> > let constr = takeWhile (/=' ') . show in constr (3 :+ 4)
03:48:16 <lambdabot>   "3.0"
03:48:17 <ziman> > takeWhile (/=' ') . show
03:48:18 <lambdabot>   {()->"()"}
03:48:20 <quicksilver> psykotic: deriving Binary (which is not built in, of course) is far far more evil though.
03:48:26 <psykotic> never used that but i can imagine
03:48:27 <ziman> ^^ what's that?
03:48:49 <lilac> ziman: looks like (Typeable a, Typeable b) => Show (a -> b)
03:48:51 <quicksilver> psykotic: the Binary class has no versioning support and no error checking
03:48:58 <emk> hi all. is there a GUI toolkit written in Haskell?
03:49:01 <quicksilver> ziman: a weird (but clever) show instance from smallcheck
03:49:06 <quicksilver> > const 4
03:49:06 <psykotic> for automagic serialization, you need things like automatic versioning and other things to have a mild chance of sanity
03:49:07 <lambdabot>   {()->4}
03:49:10 <Saizan> > (+)
03:49:10 <lambdabot>   -3->
03:49:10 <lambdabot>    {-3->-6;-2->-5;-1->-4;0->-3;1->-2;2->-1;3->0}
03:49:10 <lambdabot>  -2->
03:49:10 <lambdabot>    {-3->-5;-2->...
03:49:14 <psykotic> doh, you got there first :)
03:49:23 <ziman> oh
03:49:23 <ziman> wow
03:49:24 <lilac> yow
03:49:33 <Saizan> a bit noisy
03:49:36 <quicksilver> psykotic: if the core Binary instance for [a] changes, then all Binary serialisation breaks.
03:49:39 <psykotic> yep
03:49:47 <quicksilver> psykotic: of course, this isn't news - the binary guys do know this of course.
03:49:53 <lilac> > map
03:49:54 <lambdabot>   {{()->()}->{[]->[];[()]->[()];[(),()]->[(),()];[(),(),()]->[(),(),()]}}
03:50:00 <psykotic> i've worked on a large code base where we had a pretty nice way of doing backward/forward compatible serialization
03:50:03 <ziman> > id
03:50:03 <quicksilver> but it is something scary about deriving binary.
03:50:04 <lambdabot>   {()->()}
03:50:14 <quicksilver> I always use explicit file formats.
03:50:16 <psykotic> with versioning for untagged serialization and tagged serialization otherwise
03:50:18 <quicksilver> (using Get/Put is fine)
03:50:42 <ziman> > isSpace
03:50:42 <psykotic> tagged serialization means that you basically have a name table per serialization file and use indices for that in place of full names, etc
03:50:43 <lambdabot>   {'a'->False;'b'->False;'c'->False;'d'->False}
03:50:51 <psykotic> so it's not too bloated
03:51:01 * quicksilver thinks smallcheck could at least put "..." at the end ;)
03:51:16 <quicksilver> psykotic: yeah.
03:51:23 <psykotic> this was a code base with a few million lines of code and probably 5000 serializable classes
03:51:23 <lilac> > (&&)
03:51:23 <lambdabot>   {True->{True->True;False->False};False->{True->False;False->False}}
03:51:37 <psykotic> it worked pretty well. we also had a way of doing forward compatibility, which is somewhat unnormal.
03:51:55 <psykotic> it involved a custom object system though.
03:52:08 <ziman> > fmap
03:52:09 <lambdabot>   No instances for (Test.SmallCheck.Serial (f a),
03:52:09 <lambdabot>                    GHC.Show...
03:52:34 <ziman> > flip fmap [3,4,5]
03:52:34 <lambdabot>   {{-3->();-2->();-1->();0->();1->();2->();3->()}->[(),(),()]}
03:52:36 <psykotic> (forward compatibility meaning that you can upgrade schemas without doing any work to upgrade versions of the old schema, in standard cases)
03:52:37 <Saizan> psykotic: like google's protocol-buffers ?
03:52:39 <lilac> psykotic: we have something similar here. for C++. it's a maze of templates, macros and code generation, but it works pretty well :)
03:52:50 <psykotic> *upgrade instances
03:53:10 <psykotic> Saizan: it involved a custom scripting language, so quite a bit fancier
03:53:16 <psykotic> (i'm talking about unreal engine)
03:53:31 <ksf> what's "betrag" called in english? i.e. |v| = sqrt vx^2 + vy^2
03:53:43 <psykotic> ksf: norm
03:53:45 <lilac> our one involves parsing the header files, reading the classes and generating metadata that way :)
03:53:47 <int-e> absolute value
03:53:56 <lilac> modulus
03:54:07 <psykotic> modulus is usually limited to complex numbers
03:54:17 <int-e> lilac: do you know german? because I do ;)
03:54:28 <lilac> norm is usually written with double vertical bars in my experience :)
03:54:29 <psykotic> i've never seen anyone call a general norm an absolute value either
03:54:45 <psykotic> lilac: depends but you're right, it's usually double bars
03:54:51 <psykotic> the reason is to denote the L^2 norm
03:55:05 <lilac> int-e: i know a few words, but not enough to hold a conversation
03:55:08 <ksf> "norm" sounds like "normalized vector" to me, which is |v| == 1
03:55:32 <psykotic> trust me, norm is the word :)
03:56:00 <int-e> "Betrag" is short for "absoluter Betrag" and that's "absolute value", not any of its generalisations.
03:56:04 <ksf> heck I'm just going to write |v|.
03:56:08 <psykotic> you could say positive-definite homogeneous quadratic form but that's a bit excessive
03:56:29 * psykotic forgot subadditive.
03:56:37 <int-e> (not that "norm" is wrong.)
03:56:55 <Smokey`> norm isn't uncommon
03:56:58 <psykotic> even in danish we say 'normeret vektorrum' for instance
03:57:10 <psykotic> in geometry some people just say 'length'
03:57:12 <Smokey`> magnitude is more common, depending on what area of mathematics you're in
03:57:25 <psykotic> mathematicians would say norm :)
03:57:32 <ksf> lenght is a good idea. magnitude even more so.
03:57:53 <psykotic> then you run into the fun fact that length means something else in haskell :)
03:57:56 <Smokey`> fwiw though, |v| generally denotes the absolute value, ||v|| would be the magnitude
03:58:10 <Smokey`> but you clarified via sqrt cx^2 ...  so it made sense :P
03:58:14 <Smokey`> vx^2*
03:58:28 <ksf> well, luckily enough haddock comments live in a different namespace than bindings.
03:58:38 <psykotic> ah, i thought you were using it as an identifier
03:58:39 <lilac> Smokey`: in my experience 'norm' is more common for ||.|| (for instance in the context of a normed vector space)
03:58:51 <lilac> Smokey`: but as you say, different areas of mathematics...
03:58:59 <ksf> no, I'm just documenting the behaviour of toRational wrt. vectors.
03:59:05 <Smokey`> lilac: again I think it really depends on who you tend to deal with, different fields use very different terminology :)
03:59:19 <psykotic> engineers have strange terminology :)
03:59:32 <Smokey`> engineers not only have strange terminology, but it varies wildly between engineers ;)
04:00:16 <lilac> i always like to imagine engineers are working with quarternions when they use j
04:00:21 <psykotic> heh
04:01:01 <psykotic> fortunately the algebras generated by {1,i}, {1,j} and {1,k} within H are all isomorphic, so that interpretation works!
04:01:31 <lilac> i often wonder how universal mathematical notation is. is the notation i've been taught the same as the notation which people are taught at other universities?
04:01:41 * psykotic is trying to think of his least favorite engineering math convention
04:01:59 <psykotic> lilac: i learned all my mathematics before university in english, self study and so on
04:02:09 <psykotic> i remember some weird terminological surprises when i went
04:02:27 <psykotic> e.g. hull being 'hylster'
04:02:28 <quicksilver> lilac: there are quite a few areas of difference
04:02:40 <psykotic> and covering space being 'overlaegningsrum' and so on
04:02:47 <psykotic> but i don't remember much notational difference
04:02:53 <lilac> i think part of it is the more esoteric fields make up their own notations, often overlapping existing, more 'conventional' ones
04:02:56 <quicksilver> lilac: but a general trend towards internationally accepted texts and the internet itself pushes towards standards.
04:03:21 <quicksilver> I believe there are still people who write function application backwards, and occasionally superscript.
04:03:25 <psykotic> i remember reading an old-ish british high school maths book that denoted multiplication by a baseline dot
04:03:28 <psykotic> as in, not centered
04:03:30 <psykotic> that was fucking weird
04:03:47 <quicksilver> psykotic: absolutely, that's correct :)
04:03:52 <quicksilver> centered dot is the decimal point
04:03:57 <quicksilver> baseline dot for multiplication.
04:03:58 <psykotic> yeah, that's fucked up right there
04:04:04 <psykotic> people still use that in the uk?
04:04:10 <lilac> i've not seen that
04:04:14 <quicksilver> almost all my maths teaching used a baseline dot for multiplication, yes.
04:04:27 <lilac> quicksilver: where abouts in the uk? :)
04:04:52 <psykotic> the other obvious thing is , vs . (baseline) for decimal points
04:05:00 <psykotic> i guess in most of continental europe, you use ,
04:05:20 <Smokey`> are you guys being serious? :|
04:05:26 <lilac> Smokey`: sadly yes
04:05:33 <Smokey`> wow, there's a lot more variation than I realised :|
04:06:05 <psykotic> pet peeve with engineers:
04:06:22 <psykotic> engineers who think they've graduated to sophistication by regarding a vector as 'an arrow with direction and magnitude' rather than 'a list of numbers'
04:06:41 <psykotic> that makes me want to ask them what the angle is between the polynomials 3x^3 + x + 6 and 6x^6 + x^3 + 2
04:06:55 <quicksilver> lilac: cam
04:07:06 <lilac> quicksilver: interesting. likewise :)
04:07:33 <quicksilver> lilac: then you perhaps weren't looking too carefully at the blackboards? ;)
04:07:39 <psykotic> haha
04:07:53 <lilac> well, my eyesight isn't great and i wasn't sitting at the front, so maybe ;)
04:07:56 <quicksilver> lilac: it is difficult to see the difference between a baseline dot and a centered dot in scrawled lecturer handwriting
04:08:03 <psykotic> in books it's damn easy
04:08:08 <psykotic> i still can't read it now without doing a double take
04:08:17 <quicksilver> but my definition impression is the majority baselined it for multiplication if they wrote it at all
04:08:27 <psykotic> i also remember a few other things that were weird, minor things
04:08:32 <psykotic> like writing arrows over every vector variable
04:08:33 <quicksilver> of course you don't write it often because in so many contexts you can omit it.
04:08:36 <lilac> quicksilver: i don't think i saw more than half a dozen decimal points in my three years of undergrad :)
04:09:13 <psykotic> or writing cross product as /\
04:09:17 <quicksilver> psykotic: I think writing a tilde  ~ was slightly more common in my time
04:09:20 <Smokey`> psykotic: they each that in aus... (arrow over all vectors, unless it's a unit vector...)
04:09:20 <psykotic> (which make sense once you learn clifford algebra)
04:09:31 <psykotic> and for unit vectors it's a hat, right?
04:09:35 <quicksilver> (the tilde is really a sign to the type-setting company to set this symbol in bold font)
04:09:35 <Smokey`> yea
04:09:41 <psykotic> it's kind of like a primitive type system for hand writing :)
04:09:48 <Smokey`> lol
04:10:08 <psykotic> actually i shouldn't say primitive. i mean, it's dependently typed! it can distinguish unit from non-unit vectors!
04:11:02 <psykotic> then there are things like square vs round vs straight brackets for matrices
04:11:30 <eevar2> @src parMap
04:11:30 <lambdabot> Source not found. Maybe if you used more than just two fingers...
04:11:30 <psykotic> i wonder if a battle was over fought over that preference
04:11:32 <quicksilver> the unit vectors are a separate type :)
04:11:42 <psykotic> quicksilver: then you need to have subtyping :)
04:11:52 <quicksilver> it's just they have an embedding into the type of all vectors
04:12:01 <quicksilver> and we omit that embedding when it's not ambiguous
04:12:17 <psykotic> type inference in F_sub is undecidable isn't it? :)
04:13:46 <Smokey`> I should probably note they don't enforce the arrow/hat symbolism here (from what I've seen), in fact I don't think it was used in half my math classes - but it was used religiously in physics...  they definately go out of their way to make sure you understand it though, but not enforce it...  it also varies between unis, and schools vary even more so (which is why unis make sure everyone learns, in case they haven't previously been taught)
04:13:53 <psykotic> btw here's one weird thing i remembered noticing when i was reading some elementary high school text books written in the us
04:14:04 <psykotic> the fact that the had all these weird rules called things like FOIL for multiplying binomials
04:14:11 <psykotic> first, outer, inner, last or something
04:14:31 <lilac> psykotic: yeah, i've heard americans refer to that before
04:14:37 <psykotic> and one time when i squared (x+y)^2 as x^2 + y^2 + 2xy, an american noted how bizarre it was that i didn't write the 2xy in the middle
04:14:55 <psykotic> but i always learned it that way, so even though i recognize the middle form is more symmetric, i just don't do it that way
04:15:05 <psykotic> you pick up strange habits like that
04:15:22 <psykotic> another one is division
04:15:52 <lilac> i was never taught long division until i needed to divide polynomials at uni
04:15:59 <psykotic> haha
04:16:10 <psykotic> i think the mechanics are clearer with polynomials anyway
04:16:21 <psykotic> since you're forced to recognize how the element breaks down into a linear combinations of powers
04:16:27 <lilac> "today you will learn galois theory and long division" :)
04:16:31 <psykotic> haha
04:16:49 <Smokey`> lol :D
04:17:12 <fbru02> i learned about linear combination of powers/primes in high school
04:17:14 <psykotic> for some reason we were also never taught synthetic euclidean geometry
04:17:27 <psykotic> except for some basic things with playing around with figures in 5th grade or whatever
04:17:37 <psykotic> i taught myself that much later by reading euclid when i was already past university, that was fun
04:18:13 <psykotic> it's such a totally different approach when you're used to analytic means
04:18:14 <fbru02> in highschool i had even one teacher taught us formal topology
04:18:39 <fbru02> but i guess each country has different ways
04:18:53 <psykotic> fbru02: i think they used to teach that in denmark. i looked at one of my father's textbooks from his freshman high school year, and it had stuff on combinatorial topology of polyhedra, covering euler numbers and other things.
04:19:11 <psykotic> fbru02: eastern europe?
04:19:20 <fbru02> psykotic: no, Uruugay
04:19:50 <fbru02> psykotic: my highschool was the best in Uruguay though then i went to a crappy university
04:20:23 <EnglishGent> hello! :)
04:20:29 <fbru02> hi !!
04:20:37 <EnglishGent> hi fbru02 :)
04:20:59 <EnglishGent> does anyone know a library function Integer -> String that will give you a hex string encoding a number?
04:21:17 <maurer_> @src toHex
04:21:17 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
04:21:19 <EnglishGent> I could write one - but it seems like the sort of thing you'd expect to be in a library somewhere
04:21:28 <psykotic> i think the biggest problem with the way math is taught in pre-university is not so much the lack of advanced mathematics as the plug-and-chug, cookiecutter nature of the problems
04:21:35 <EnglishGent> hello maurer_ :)
04:21:41 <EnglishGent> hi psykotic
04:21:54 <psykotic> of course that depends on the country too. i have some friends who grew up in eastern europe who did some really hardcore problem solving in mathematics in public school.
04:21:56 <SubStack> there's showHex
04:22:08 <maurer_> Ah, yeah, that was what it was calle.d
04:22:09 <EnglishGent> and psykotic - for what it's worth... I think that's a *big* problem (dont know if is _the_ biggest, but certainly a major contributor)
04:22:14 <EnglishGent> ah thanks SubStack
04:22:25 <EnglishGent> @hoogle showHex
04:22:25 <lambdabot> Numeric showHex :: Integral a => a -> ShowS
04:22:46 <psykotic> EnglishGent: well, there are two things but i think that's a symptom of the underlying problem, which has to do with teaching mathematics as a series of tricks
04:23:00 <Smokey`> @set showIntAtBase
04:23:00 <lambdabot>   Parse error: SemiColon
04:23:04 <Smokey`> @src showIntAtBase
04:23:04 <lambdabot> Source not found. You type like i drive.
04:23:18 <SubStack> > showHex 64 ""
04:23:19 <lambdabot>   "40"
04:23:20 <Smokey`> meh, hoogle showIntAtBase :) and showHex as others suggested
04:24:13 <psykotic> you could easily teach something like farmer's Groups and Symmetry or Knots and Surfaces to reasonably bright fifth graders with the right teacher and a small enough class
04:24:16 <fbru02> psykotic i guess the biggest problem is yippie parents not wanting the kids to fail, at any time, failure is good for you, failure at high schools is good, math is hard, programming is hard , so, you should fail at some point in time when dealing with those topics
04:24:25 <psykotic> but the nature of the school system means that such is impossible outside of special cases
04:24:47 <psykotic> fbru02: good point
04:25:16 <psykotic> another problem is a weird attitude about the status of mathematics compared to the more liberal arts
04:25:38 <psykotic> it's okay to justify the study of english literature as a subject intrinsically worthy, something that grows culture in a person, etc
04:25:44 <psykotic> with mathematics it has to be reduced to a mechanical tool
04:26:12 <Smokey`> depends on the culture...
04:26:19 <EnglishGent> I'd teach a functional language (seriously) - and introduce ideas like higher-order-functions that way
04:26:21 <psykotic> i can't name a culture where that isn't true
04:26:33 <EnglishGent> eventually you could start building up number systems
04:26:55 <psykotic> for example, in the parts of east asia i know well, they have respect for mathematics generally, but they don't appreciate it in the way i mentioned, at least not in the general culture
04:27:02 <EnglishGent> data Nat = Zero | Succ Nat
04:27:09 <EnglishGent> then define plus, multiply & power
04:27:10 <blackdog> psykotic: read CP Snow's Two Cultures?
04:27:14 <EnglishGent> and then start to generalise
04:27:14 <psykotic> and perhaps that's not too much to ask, but the average person has a proxy appreciation of shakespeare's value, even if they cannot read him with pleasure themselves
04:27:20 <psykotic> blackdog: yep
04:27:42 <blackdog> it's an interesting take on it, hey.
04:28:13 <blackdog> never really understood why people think it's cute to be ignorant
04:28:22 <psykotic> it's not so much ignorance
04:28:33 <psykotic> although there's that too
04:28:54 <blackdog> well, a scientist would be embarrassed to admit they'd never read shakespeare
04:29:00 <Smokey`> some people are artists, others socialists, other's scientists...  I think you can tell which one has a more profound appreciation for mathematics. :P
04:29:00 <psykotic> i think even the attitude of an engineer competent with mathematics is not a good model for the ideal attitude of general society
04:29:01 <fbru02> psykotic: anyway , i guess that "it is NOT" my problem , i have with years become skeptic about changing the system in general, i will teach my kids to understand mathematics as a formal system of logic then go to topology and then set theory and then... ok you know the idea
04:29:06 <Smokey`> others*
04:29:25 <blackdog> but you'll find literary types who can't explain basic principles like thermodynamics
04:29:31 <psykotic> right
04:29:53 <blackdog> and proud of it! That's the weird bit.
04:30:10 <psykotic> i guess i'm saying mathematics is weird because it has a very useful hard-nosed kind of application but if you reduce it to that, i wouldn't care about it the least
04:30:19 <jkff> @seen vixey
04:30:19 <lambdabot> Unknown command, try @list
04:30:22 <psykotic> but that usefulness makes it easy for people to reduce its status to that
04:30:23 <jkff> @list
04:30:23 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
04:30:39 <psykotic> if it SEEMS useless, then it's paradoxically easier to justify it on intrisinc grounds
04:31:00 <psykotic> i mean, we've been doing this stuff for 3000 years and it seems useless, so there must be something intrinsically good about it, even if i can't see it, etc
04:31:30 <Smokey`> psykotic: I think you're going to end up getting caught in a philosophical dilemma if you continue thinking about this :)
04:31:33 <psykotic> hehe
04:31:38 <psykotic> anyway, sorry for the tangent
04:31:42 <fbru02> i will write a post about this recurring conversation, how would I teach mathematics..
04:31:50 <psykotic> incidentally, apropos what fbru02 said, i would never take a logic-first approach.
04:31:53 <jkff> Hey, have they disabled the '@seen' command'? It's present in the commands list but doesn't work
04:32:01 <fbru02> psykotic: what would you take ?
04:32:08 <quicksilver> jkff: yes.
04:32:17 <psykotic> as arnold said, geometry is when you use both parts of the brain :)
04:32:18 <quicksilver> jkff: it had a memory leak and wasn't reliable anyway.
04:32:25 <EnglishGent> btw... silly question - why do showHex & showBase take an extra string to postpend?
04:32:25 <quicksilver> jkff: preflex has a more reliable one
04:32:29 <quicksilver> preflex: seen jkff
04:32:29 <preflex>  jkff was last seen on #haskell 36 seconds ago, saying: Hey, have they disabled the '@seen' command'? It's present in the commands list but doesn't work
04:32:37 <jkff> preflex: seen vixey
04:32:37 <preflex>  vixey was last seen on #haskell 121 days, 11 hours, 50 minutes and 55 seconds ago, saying: @djinn int -> int -> int
04:32:41 <jkff> quicksilver: Thanks
04:32:42 <ksf> uhm... is it usual to have an applicative instance for a thing that's supposed to be a number type?
04:33:03 <EnglishGent> I would have expected it to simply be showHex :: Integer -> String - not showHex :: (Integral a) => a -> String -> String
04:33:04 <jkff> ...Hmm.. What again was vixey's second nick?..
04:33:15 <quicksilver> ksf: well if you're doing something like pointwise additions of functions perhaps
04:33:19 <psykotic> when it comes to such things as what basic kinds of numbers are, i think you can address it precisely without devolving into rigid axiomatics.
04:33:32 <quicksilver> ksf: but I would make the point that Num has kind * and Applicative has kind * -> *
04:33:40 <quicksilver> ksf: so the comparison is a little fuzzy.
04:33:42 <ksf>     (*) = liftA2 (*)
04:33:46 <psykotic> but i have a friend who taught his child ordinals and cardinals by a formal approach before anything else
04:33:47 <Smokey`> EnglishGent: I'm assuming because some people may require "0x0f" instead of "0x0F" or some such... so instead of having two special cases, they decided just to let people to choose for themselves? (just stabbing in the dark here, not sure on the real reason)
04:33:49 <SamB_XP> quicksilver: eh?
04:33:50 <psykotic> that seems like child abuse
04:34:03 <fbru02> psykotic: but that's the way everybody gets introduced to numbers in elementary school
04:34:09 <quicksilver> SamB_XP: ?
04:34:11 <ksf> yep there's the pure issue.
04:34:14 <jkff> Oh well, then you guys check it out, to my mind it's genial: http://gelisam.blogspot.com/2009/09/samuels-really-straightforward-proof-of.html
04:34:17 <psykotic> fbru02: the problem is that the teachers aren't competent enough to understand the issues either.
04:34:19 <SamB_XP> you mean the *parameter* has that kind in each case ?
04:34:28 <psykotic> fbru02: you have to be able to have a clear view of multiple issues and know how to present them.
04:34:37 <ksf> pure is currently duplicating its argument into both components of the vector, while fromInteger and stuff leave the y-component at 0.
04:34:38 <quicksilver> SamB_XP: yes, indeed. That is common usage as far as I know.
04:34:43 <fbru02> i guess a good way it is to teach numbers the straight way in elementary school and do a "reset" and then start from an axiomatic point of view on high school
04:34:52 <quicksilver> SamB_XP: hence "higher-kinded type classes"
04:35:01 <quicksilver> SamB_XP: (of which Monad was the motivating example)
04:35:33 <psykotic> fbru02: i think it's fine to take a somewhat formal approach to some things and justifications as long as it doesn't try to show mathematics as a formal game.
04:35:38 <SamB_XP> quicksilver: well, with multi-parameter typeclasses, that usage is just confusing!
04:35:43 <psykotic> i.e. not bourbaki for kindergarten
04:36:00 <quicksilver> SamB_XP: that's the arity, not the kind
04:36:04 <quicksilver> SamB_XP: but, I take your point :)
04:36:08 <SamB_XP> psykotic: but mathematics *is* a formal game
04:36:13 <SamB_XP> it's a pretty fun one, too
04:36:17 <psykotic> for example, if you're trying to explain why -1 * -1 = 1, you can certainly use a formal justification based on the distributive rule, but ideally you can also talk about reflections
04:36:19 * SamB_XP goes to do some Coq
04:36:20 <Smokey`> SamB_XP: now you've done it...
04:36:35 <SamB> no, I haven't done it
04:36:42 <quicksilver> SamB_XP: type classes can't be partially applied, so the number of parameters isn't much like a kind.
04:36:44 <SamB> I'm not *that* fast!
04:36:47 <psykotic> SamB_XP: i'm a platonist. the formal rules are expository and organizational, not the ultimate ontological foundation.
04:37:03 <SamB> psykotic: oh, sure
04:37:04 <fbru02> psykotic: hey man , im going to take off to see the dan piponi video before work , see u guys later
04:37:18 <psykotic> fbru02: that's an awesome video, you have a treat in store!
04:37:19 <psykotic> later
04:37:42 <SamB> okay, I guess mathematics is more of a game where you make formal games
04:38:09 <psykotic> i can recommend gian-carlo rota's excellent book of essays indiscrete thoughts
04:38:24 <psykotic> he probably has the best discussion i've seen anywhere of the relationship between axiomatics and mathematics as a practice
04:38:44 <psykotic> and also notions of mathematical aesthetics and many other things
04:38:57 <psykotic> also, he describes his first meeting with alonzo church in a hilarious way
04:39:04 <Saizan> which video?
04:39:07 <psykotic> "He looked like a cross between an owl and a penguin"
04:39:08 <SamB> okay, well ... Coq is a formal game at least ;-P
04:39:15 <SamB> and it's a pretty entertaining one at that
04:39:44 <psykotic> p.s. i like proof theory and type theory and topos theory and even set theory :)
04:39:58 <SamB> you ... like ... set ... theory ?
04:40:02 <psykotic> a little bit
04:40:03 <SamB> ... weird
04:40:09 <psykotic> higher cardinals and ordinals
04:40:12 <psykotic> i don't mean foundatoins
04:40:28 <SamB> I think I'm scared of set theory
04:40:36 <SamB> did you see what they did to that poor sphere?
04:40:44 <psykotic> haha
04:40:50 <psykotic> blame banach and tarski
04:40:55 <psykotic> it's always the polish
04:41:04 <SamB> they didn't write the axioms ;-P
04:41:23 <psykotic> everyone accepted the axiom of choice implicitly before anyone thought to question it
04:41:40 <psykotic> i mean, OF COURSE a cartesian product of an arbitrary family of nonempty sets is nonempty :)
04:41:41 <psykotic> hehe
04:42:16 <SamB> psykotic: how is that the same as the axiom of choice ?
04:42:22 <psykotic> it is
04:42:32 <psykotic> showing nonemptiness is equivalent to picking an element from each set of the family
04:42:47 <psykotic> you hadn't seen that equivalent characterization? :)
04:42:47 <SamB> okay, what do you mean by arbitrary family ?
04:42:52 <psykotic> a set of sets
04:42:57 <psykotic> any set of any nonempty sets
04:43:06 <SamB> ah, that's your issue
04:43:21 <SamB> you need a list of proofs of nonemptiness
04:43:25 <psykotic> that's right
04:43:31 <SamB> not just a set of sets
04:43:36 <psykotic> once you have picked out an element of each (as a proof witness of nonemptiness) you don't have the problem
04:43:44 <psykotic> that's why the axiom of choice is trivially true in intuitionistic logics
04:43:59 * Smokey` stares dumbfoundly at the screen
04:44:03 <SamB> hmm. I thought it was only true at specific types
04:44:11 <psykotic> right
04:44:23 <psykotic> but that's because cross types you don't have a meaningful notion of equality
04:44:35 <psykotic> and that's only with type theories rather than arbitrary intuitionistic logics anyway
04:44:37 <psykotic> i was being vague :)
04:45:47 <psykotic> basically the nonemptiness of the product is witnessed by the product of nonemptiness proofs
04:45:55 <psykotic> so there really isn't anything deep there in the unsorted case, i believe
04:46:06 <Smokey`> sometimes I wonder what'd be like to know as much as someone like psykotic...
04:46:10 <Smokey`> psykotic: how old are you by the way?
04:46:39 <psykotic> 26, and don't be ridiculous
04:46:47 <byorgey> Smokey`: I imagine it would be much like what it is to know as much as someone like Smokey`, only a little more so.
04:47:30 <Smokey`> Let me rephrase, I tend to wonder what it would be like if I had a more thorough educational history in mathematics...
04:47:48 <byorgey> well, only one way to find out ;)
04:47:51 <psykotic> that's a better question. the answer is that if you want to fix that, you can
04:47:53 <Smokey`> indeed.
04:48:17 <psykotic> i'd like to be good at drawing and music and a lot of shit
04:48:43 <psykotic> i'm pretty sure i could do it if i just made the time, but you can't do everything
04:49:02 <Smokey`> :)
04:49:09 <psykotic> Smokey: anyway, you've advanced a lot since we hung out on #flipcode a decade ago
04:49:19 <psykotic> you used to be an annoying little snot-nosed kid :)
04:49:23 <Smokey`> psykotic: well last time we spoke I think I was 17?
04:49:27 <Smokey`> maybe younger
04:49:38 <psykotic> probably younger
04:50:25 <psykotic> more like 14-15?
04:50:42 <psykotic> anyway, you should be proud of how far you've come rather than holding yourself to some arbitrary standard
04:50:57 <Smokey`> I was about 15 or so when I first started frequenting #flipcode... I can't recall when you left though
04:51:55 <psykotic> byorgey: when's your next species extravaganza coming?
04:52:10 <psykotic> byorgey: your posts finally made me go back and read combinatorial species and tree-like structures
04:52:23 <psykotic> glad i did
04:52:54 <psykotic> and then i ended up trawling through stanley's books, so you indirectly triggered my renewed interest in algebraic combinatorics, for which many thanks.
04:53:20 <byorgey> psykotic: excellent!
04:53:26 <byorgey> psykotic: soon, I hope
04:53:58 <byorgey> I can't get the darn recursively defined species to work.  I think I need to send my code to Oleg.
04:54:04 <psykotic> haha
04:54:21 <kalven> Smokey`: and then you left :/
04:54:24 <psykotic> btw 'the handbook of combinatorics' i found to be an amazing book
04:54:29 <psykotic> unlike most handbooks
04:54:41 <byorgey> psykotic: thanks for the tip, I haven't seen that one
04:55:03 <psykotic> my favorite chapter is probably the one by anders bjorner on topological methods in combinatorics, but there were a lot of other insightful articles in there.
04:55:09 <psykotic> lots of things you don't see in textbooks
04:55:11 <Smokey`> kalven: a few people frustrated me a bit too much to take #flipcode seriously anymore - I've since returned though (upon request by associat0r)...
04:55:29 <byorgey> neat
04:56:00 <psykotic> like--how the face poset construction gives a relationship between inclusion-exclusion counting in the general moebius sense and homology
04:56:26 <psykotic> for example, the euler characteristic of the simplicial complex associated to a poset (the face poset) is an example of combinatorial inclusion-exclusion counting in this view
04:56:30 <psykotic> i thought that was pretty damn neat
04:56:51 <psykotic> bjorner gives some amazing applicatiosn of high-powered topology like the lefschetz fixed point theorem for homology
04:57:04 <psykotic> and you get some nice results that are way more powerful than the usual tricks for e.g. counting sets with involutions
04:57:41 <psykotic> and there's a chapter on species too! :)
04:58:45 <psykotic> i've been trying to apply those topological interpretations to species
04:58:58 <kalven> Smokey`: he seems to be the only one active recently (or in the year before I left).
04:59:01 <psykotic> for example, the fact that the derivative operator is so much like the adjoint of the boundary operator in topology
04:59:07 <psykotic> there has to be a way of relating that to what bjorner is talking about
04:59:16 <byorgey> wow, cool!
04:59:44 <Smokey`> kalven: DP still talks a bit, as does reaVer... not frequently though - but on occasion.
05:00:13 <Smokey`> kalven: I have to admit, #haskell sees much more interesting and lively discussions than I ever remember seeing in #flipcode
05:00:51 <Smokey`> probably more to a shift in general interests on my part though
05:01:34 <kalven> yep
05:01:48 * ksf is trying to do
05:01:50 <ksf>     truncate (V2 x y) = V2 (truncate x) (truncate y)
05:02:01 <ksf> but fails due to rigid type variables.
05:02:19 <ksf> ...the return type is fixed to Intregral a => a
05:02:35 <ksf> ...which is exactly what I'm returning.
05:02:41 <byorgey> @type truncate
05:02:41 <lambdabot> forall a b. (RealFrac a, Integral b) => a -> b
05:03:09 <ksf> ...well, that is, V2 has an Integral instance.
05:03:16 <ksf> but the type checker doesn't seem to know that.
05:03:48 <byorgey> ksf: I wonder if it's upset because it doesn't know that (truncate x) and (truncate y)  have to be the same type
05:04:12 <ksf> they're of the same type.
05:04:25 <ksf> (data V2 a = V2 a a)
05:04:59 <byorgey> right, but I mean taken on their own, the calls to (truncate x) and (truncate y) might not necessarily produce the same output type.
05:05:39 <byorgey> and since the desired result type is type-class polymorphic... I'm not sure, just a gut feeling
05:06:49 <byorgey> If that is indeed the problem, it's generally something you could fix with ScopedTypeVariables, but I don't think you're allowed to put type signatures for class method implementations...?
05:07:18 <ksf> yep.
05:07:30 <ksf> tried that, already.
05:07:59 <byorgey> oh, ok
05:08:13 <ksf> I've also tried annotating the result type with (Integral a, Integral V2 a) => V2 a
05:08:15 <byorgey> hrm.  well, I'd have to see the code I guess.
05:10:30 <ksf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9446#a9446
05:11:43 <ksf> I'd be happy to use an alternative numeric prelude if it avoids pain, btw.
05:13:36 <byorgey> oh!  of course.  The problem is that truncate is supposed to be able to return ANY Integral type, but you are returning a specific one (V2).
05:13:59 <ksf> ...and how am I supposed to return any type?
05:15:08 <byorgey> Well, you have to return something of type  Integral a => a.  how you do that depends.
05:15:24 <byorgey> I kind of doubt that a RealFrac instance for V2 makes sense, actually.
05:15:36 <ksf> it does.
05:15:52 <ksf> I want to do subpixel arithmetic.
05:16:09 <ksf> ...the rasterizer gets the subpixel part of the vector, the blitter the pixel part.
05:16:42 <ksf> erm grit-fitter.
05:16:43 <ksf> whatever.
05:16:48 <ksf> *grid
05:17:22 <byorgey> I don't know what that means.  What types are the subpixel and pixel parts?
05:17:39 <ksf> Data.Fixed, both of them.
05:17:44 <sioraiocht> why is this : data F f = Functor f => Fold (forall a. (f a -> a) -> a) an existential type?
05:17:52 <ksf> Data.Fixed already comes with a RealFrac instance.
05:18:06 <sioraiocht> I understand that it's using rank 2 polymorphism, but how is it existentially quantified?
05:19:24 <jkff> sioraiocht: Doesn't look like an existential to me.
05:19:37 <ksf> data.fixed uses the Rational instance, though.
05:19:37 <jkff> It would be an existential if the forall would be before 'Fold'.
05:19:38 <sioraiocht> jkff: I didn't think so, GHC said I had to enable ExistentialTypes, though
05:19:49 <sioraiocht> jkff: okay, that's what I thought
05:19:56 <byorgey> sioraiocht: it's existentially quantified if you look at it from the outside.  I.e. it's isomorphic to  exists a. Fold ((f a -> a) -> a)
05:19:56 <jkff> Probably the extension just enables higher-rank polymorphism
05:20:06 <jkff> byorgey: It is not
05:20:37 <byorgey> sorry, I guess I'm confused
05:20:57 <sioraiocht> byorgey: isn't it forall a. Fold ((f a -> a) -> a)) ~ Fold (exists a (f a -> a) -> a)
05:21:05 <jkff> What you are telling is "The argument of Fold can be any term such that exists a: term::((f a -> a) -> a)", but what is actually means is "The argument of Fold *must* be polymorphic"
05:21:50 <sioraiocht> jkff: okay, good, that's what I want =)
05:21:52 <sioraiocht> thanks =)
05:22:10 <byorgey> ksf: RealFrac seems like it is only for one-dimensional types.
05:22:30 <byorgey> ksf: for example, truncate on a V2 must be able to return (say) an Int
05:24:23 <ksf> well it _could_, via toInteger or such, but the type system doesn't know that.
05:25:52 <ksf> It's a lesson in not assuming Integral a => a means "some type you can use Integral's methods on), but "any type that has an integral instance"
05:27:43 <byorgey> ksf: right.  the former would be  exists a. Integral a => a  (if that were a legal type)
05:28:51 <psykotic> byorgey: he wants to take a quotient by the pixel lattice but he won't listen :)
05:29:02 <ksf> ...I'm going to leave the instance out, there's fmap, after all.
05:29:14 <psykotic> (back from food)
05:30:08 <ksf> ...and I'm a hell a lot more comfortable with functors that with lettuces.
05:30:16 <psykotic> lettuce is awesome
05:30:42 <ksf> did you know that laticces burn more energy than you gain while digesting?
05:30:44 <psykotic> dividing by a lattice means breaking down a vector into lattice points (in this case, vectors with integral coordinates) and differences, i.e. remainders
05:32:46 <psykotic> in this case it just works out to the entrywise arithmetic goodness but part of the reason you're having pain doing it your way is your making a generalization about what's going on in the wrong direction.
05:32:49 <psykotic> but that's my two cents.
05:33:13 <ksf> so you're saying I should be treating the coordinates as  ((pixelx, pixely),(subx,suby)) instead of ((pixelx,subx),(pixely,suby))?
05:33:24 <psykotic> that is correct
05:33:46 <psykotic> the point is that the two vectors are each vectors in their own right
05:34:02 <psykotic> adding them up yields the original, etc
05:34:36 <psykotic> this is stuff you can do over any abelian group
05:34:37 <ksf> while that's not consistent with how freetype represents them, it actually makes sense.
05:35:38 <sioraiocht> for generalisations of fold, do we prefer the term fold still, or catamorphism?
05:35:47 * psykotic calls them folds
05:36:26 <psykotic> mostly as a protest against the proliferation of *morphism names for some weird kind of pattern that has been seen a total of 3 times in the history of the universe
05:36:50 <Je`> haskell est bonne à baiser la fille ? :-)
05:36:50 <psykotic> hierobolicmorphism is next up, mark my words
05:37:05 * ksf 's brain calls them crunches
05:37:13 <psykotic> ksf: i like that too!
05:37:31 <psykotic> the patterson-hinze paper on finger trees talks about 'crushes'
05:37:40 <psykotic> which is reducing over a monoid
05:38:03 <ksf> and hylomorphisms are a forest fire followed by new trees growing on the ashes.
05:38:18 <ksf> "hylo" means wood (among other things), after all.
05:38:38 <psykotic> i always wished that instead of hylomorphism it would be catanamorphism
05:38:48 <psykotic> mnemonic, euphonic, cool
05:39:01 <psykotic> you feel like a ninja when you write one
05:39:05 <Je`> Et les putes elles sont où ?
05:39:10 * ksf snickers
05:39:21 <Je`> ah c'est bon ça les snickers
05:39:46 <sioraiocht> psykotic: haha, and then anacatamorphism for the dual?
05:40:42 <psykotic> and actually i would prefer katanamorphism, now i think about it
05:40:50 <psykotic> it's closer to the original greek and closer to the japanese
05:41:21 <psykotic> missed opportunity. now we're stuck with hylomorphism.
05:42:05 <psykotic> sioraiocht: sounds good to me. there are famous theorems in mathematics called things like the up-and-down lemma, so why not this? :)
05:42:32 <sioraiocht> psykotic: hey, I'm not disagreeing =)
05:42:39 <psykotic> http://en.wikipedia.org/wiki/Going_up_and_going_down
05:43:02 <psykotic> or maybe it should be called an elevatormorphism
05:43:27 <psykotic> suitably hellenized
05:44:15 <psykotic> but i'm actually serious in disliking the morphism terminology. it misses the opportunity to think up memorable, evocative names. folds and unfolds are pretty good that way.
05:45:26 <psykotic> we should take it further. :)
05:45:39 <psykotic> fold = death, unfold = birth, hylomorphism = resurrection
05:45:41 <Jafet> But it intimidates newbies! Haskell must be kept leet
05:46:16 <dolio> hylo is unfold followed by fold.
05:46:17 <psykotic> i think we've got the intimidation angle permanently covered
05:46:35 <psykotic> good point
05:46:44 <psykotic> phoenix? :)
05:47:03 <psykotic> of course that makes it ambiguous whether it's kata-ana or ana-kata
05:47:20 <psykotic> do any of you know the language E?
05:47:35 <psykotic> one of the cool things about it is that they thought a lot about memorable names for various kinds of novel constructs
05:48:14 * psykotic prods kpreid 
05:48:56 <kpreid> yo
05:48:59 <Jafet> Maybe they should let a bunch of physicists fork haskell and see what names we end up with
05:49:30 <kpreid> psykotic: it's not an E thing, it's a MarkM thing :-)
05:49:34 <psykotic> haha
05:49:37 <psykotic> well, E is an MarkM thing :)
05:50:06 <psykotic> it means that i can still remember a lot of weird names despite the fact i never coded in it
05:50:09 <psykotic> like vat
05:50:11 <psykotic> that's an awesome name
05:51:05 <psykotic> mirrors, strongbox, etc
05:51:27 <kpreid> neither of those are E terms...
05:51:36 <psykotic> well
05:51:52 <psykotic> i saw him use mirror in his thesis
05:52:05 <psykotic> doh, i'm thinking of gilad brache
05:52:10 <ksf> ...so I'm just going to introduce a data type of a square lattice of square lattices and see if I get far enough to be able to blame psykotic for teaching me algebra.
05:52:17 <psykotic> i was trying to remember the name of the design pattern he uses for retracting privileges
05:52:30 <kpreid> caretaker?
05:52:32 <psykotic> by a side channel represented by a mutable variable shared through a closure
05:52:45 <kpreid> yes
05:53:11 <psykotic> is it lockbox instead of strongbox?
05:53:19 <kpreid> no
05:53:24 <psykotic> anyway, i guess i'm kind of defeating my own argument if i was making the argument they were memorable :)
05:53:36 <kpreid> you have enthusiam. that's a good sign!
05:53:38 <psykotic> ksf: you'll thank me... eventually.
05:54:04 <psykotic> what's the container for public-key protected data?
05:54:08 <psykotic> there's something boxy
05:55:34 <kpreid> you're thinking of sealed boxes, which are not cryptographic except when necessary (and not in any existant implementation)
05:56:01 <psykotic> ahh, membrane not mirror
05:56:03 <psykotic> that's what i remembered
05:56:23 <psykotic> and i think i was thinking of powerbox
05:56:27 <psykotic> anyway
06:06:28 <kpreid> psykotic: sorry to be a bit of a wet blanket there.
06:07:45 <psykotic> you were not, thanks for jogging my memory.
06:07:55 <psykotic> you are probably one of the few people in the world still hacking e, so i figured you'd know
06:08:24 <kpreid> unfortunately, yes.
06:14:41 * psykotic wonders if he's outlandish for wishing the default composition and application syntax was arrow polymorphic rather than tied to the identity arrow
06:15:56 <psykotic> i guess that would run into circular issues
06:16:01 <opqdonut> mhmm
06:16:09 <Lanjiao> anyone knows where is the detailed doc of Template Haskell? I google but only found some simple doc. Not detailed enough
06:16:10 <quicksilver> composition would be fine.
06:16:19 <quicksilver> arrows don't in general have application, remember :)
06:16:22 <psykotic> right
06:16:29 <psykotic> well.
06:16:45 <psykotic> in a general category, application to a point x is composition with the morphism 1 -> x
06:16:50 <quicksilver> I don't find I often deal with non-function arrows though. (In the "Control.Arrow" sense anyway)
06:17:05 <psykotic> where 1 is the initial object
06:17:13 <quicksilver> indeed.
06:17:24 <psykotic> of course then you have a problem getting "the element out"
06:17:28 <psykotic> that's what i meant about circularity
06:17:48 <psykotic> quicksilver: i've dealt with some things recently where some kind of enriched function would be very useful
06:18:09 <psykotic> even if their 'forgetful' semantics are the usual function ones, they can carry additional information about the domain and range, for example
06:18:28 <quicksilver> I have more often wanted something like Arrow, but with the opposite of pure
06:18:30 <psykotic> it's the kind of thing that's trivial in scala because you can just subclass the Function classes
06:18:53 <psykotic> for what/
06:18:55 <quicksilver> instead of pure, "interpret :: (a ~> b) -> (a -> b)
06:19:03 <quicksilver> ADTs which describe functions
06:19:08 <quicksilver> but have richer structure
06:19:09 <psykotic> gotcha
06:19:09 <quicksilver> can be optimised etc.
06:19:19 <psykotic> it would be nice an arrow algebra
06:19:26 <psykotic> to make an analogy to M-algebras over a monad M
06:19:29 <psykotic> err, it would be like
06:19:49 <psykotic> (an M-algebra is just a 'run' function for a monad)
06:20:17 <psykotic> there's some coherence laws that say that an interior 'run' must be the same effect as an interior 'join'
06:20:24 <psykotic> which justifies the definition of join as an internal interpretation function.
06:20:34 <psykotic> (which is a point of view i haven't seen expressed much by haskellers)
06:21:04 <psykotic> what you're talking about sounds like the same thing but with arrows
06:22:00 <psykotic> with a bifunctor instead of a monofunctor but otherwise the same pattern
06:22:16 <quicksilver> that's because so many monads don't have run functions, surely?
06:22:26 <psykotic> quicksilver: what is?
06:22:28 * quicksilver is slightly distracted and a few sentences behind
06:22:31 <psykotic> sorry
06:22:40 <quicksilver> the reason that that point of view is not often expressed by haskellers
06:22:44 <psykotic> oh right
06:22:54 <psykotic> that's true but if you think of moggi's view of monads in terms of 'two worlds', etc
06:22:58 * quicksilver nods
06:23:01 <quicksilver> the intuition is clear
06:23:05 <psykotic> right
06:23:33 <psykotic> it's fun to go through mac lane's chapter on monads and reinterpret everything in terms of haskell, it becomes crystal clear
06:23:47 <psykotic> i harvested a lot of insights like the one i just mentioned--things i had sensed before but hadn't known how to make precise or express so clearly
06:23:50 <quicksilver> I never bought mac lane I just perma-borrowed it from the library.
06:23:55 <quicksilver> so I dont' have a copy any more.
06:24:04 <quicksilver> abusing-grad-borrowing-privileges++
06:24:07 <psykotic> hehe
06:24:44 <psykotic> i think monads in haskell are sometimes harder to understand because of the use of the type system for constructing a subcategory
06:24:56 <psykotic> the first time i really understood monads was when i read moggi's original paper on computational lambda calculi
06:25:08 <psykotic> because there you have genuinely different kinds of worlds, so there's no confusoin
06:25:27 <quicksilver> I found monads in category theory easy to understand on a mechanical level
06:25:30 <quicksilver> but very hard to motivate.
06:25:36 <quicksilver> I found adjoints easer though.
06:25:39 <psykotic> right, you sort of have to care about algebraic theories first
06:25:42 <psykotic> then it makes sense
06:25:53 <quicksilver> so normally I thought of monads as being a construction on adjoints
06:26:16 <quicksilver> I found rather a lot of CT hard to motivate to be honest.
06:26:24 <psykotic> i'm curious what your background is? i remember finding adjoints tricky in the beginning when i was trying to learn from computer sciency sources.
06:26:36 <psykotic> it was only when i read mac lane and saw all the somewhat deep non-trivial examples of adjoints from all over mathematics that it really clicked
06:26:52 <psykotic> because when you're looking at CS-ish sources
06:27:07 <psykotic> everything is obvious examples of free and forgetful functor pairs, iterated ad infinitum
06:27:30 <psykotic> of course there's a sense in which everything is like that, but the insights come from non-obvious cases of that pattern, rather than reiterating it for monoids, semirings, modules, algebras, etc, etc
06:27:51 <quicksilver> psykotic: 4-year degree in pure maths followed by comp sci phd in logic.
06:27:56 <psykotic> okay, that makes sense
06:28:04 <quicksilver> no masters. Must have taken a wrong turn somewhere.
06:28:08 <quicksilver> (or was it a right turn?)
06:28:18 <psykotic> i was going to say that a pure CS person might have trouble. unless he's a logician who needs no motivation for anything :)
06:28:35 <Haskell_Lover90> hello
06:28:54 <psykotic> it's good to know some galois theory, and some covering space theory, and some riemann surfaces
06:28:59 <psykotic> then you get some fun examples
06:29:28 <psykotic> and then you can cover etale fundamental groups and crazy generalizations and see how it can be derived in terms of the abstract nonsense
06:29:52 <psykotic> mmm, etale
06:32:44 <psykotic> quicksilver: i think the most magical thing about adjoint functors for me are the existence theorems.
06:32:49 <psykotic> it's slightly unsettling when you get something for nothing.
06:33:12 <psykotic> that's how it feels anyway.
06:36:04 <jpcooper> hello
06:36:51 <quicksilver> psykotic: I learnt those proofs off by heart for my exams. Damned if I can remember them now ;)
06:36:58 <jpcooper> has anyone figured out a way in which to make components such as VBoxes, top-level? I'm aware that this is possible with Gtkbuilder, but gtk2hs doesn't support this.
06:37:08 <psykotic> quicksilver: since you're in logic/cs, do you know of any applications there?
06:37:18 <psykotic> quicksilver: maybe the adjoint of the syntax functor for getting semantics or something?
06:37:45 * psykotic is vaguely trying to recall some of the syntax/semantics adjointness stuff in lawvere
06:39:03 <psykotic> it seems like some of the domain theory nonsense for constructing fixed points and so on could potentially be gotten by an existence theorem
06:39:12 <psykotic> (for untyped lambda calculus)
06:41:26 <quicksilver> psykotic: was, not am :)
06:41:48 <psykotic> quicksilver: couldn't stomach it? since you were at cambridge, were you studying with hyland?
06:41:56 <quicksilver> psykotic: isn't syntax normally recovered in the internal language of the topos that holds the semantics?
06:42:08 <quicksilver> I loved it. I couldn't get the RA position I wanted.
06:42:13 <psykotic> ah
06:42:26 <quicksilver> hyland was my part III supervisor and I worked with him a little on a research project after I left
06:42:58 <psykotic> i read some cool slides by him recently--why the category of automata was 'obviously' equivalent to the category of regular languages
06:43:14 <psykotic> and the joke was that it took 70 slides to establish the viewpoint that made the equivalence obvious :)
06:43:53 <psykotic> or at least i hope he meant it as a joke, or i'm scared
06:44:11 <SubStack> > mapM (const [False,True]) $ replicate 3 ()
06:44:12 <lambdabot>   [[False,False,False],[False,False,True],[False,True,False],[False,True,True...
06:44:17 <SubStack> ^_^
06:44:55 <ksf> the problem with the ((pixelx,pixely),(subx,suby)) is dealing with subpixel overflow. while it's certainly iso to a vector of fixed-prescision numbers, the representation is just awkward.
06:45:03 <saml> > let (^_^)  = (+) in 1 ^_^ 2
06:45:03 <lambdabot>   <no location info>: parse error on input `)'
06:45:13 <int-e> > replicateM 3 [False ..]
06:45:14 <lilac> > filterM (const [False, True]) [1,2,3]
06:45:14 <lambdabot>   [[False,False,False],[False,False,True],[False,True,False],[False,True,True...
06:45:14 <lambdabot>   [[],[3],[2],[2,3],[1],[1,3],[1,2],[1,2,3]]
06:45:45 <ksf> ...and how am I supposed to concentrate with people tearing down the faccade in front of my window, anyway?
06:45:58 <psykotic> this is the one: http://www.dpmms.cam.ac.uk/~martin/Research/Slides/marktoberdorf07.pdf
06:46:27 <psykotic> ksf: are you living in a condemned building?
06:47:03 <ksf> nah, it's just the isolation.
06:47:57 <ksf> the building was built in the 60s or so, it's gonna stand some hundred years.
06:48:10 <psykotic> nice
06:48:21 <psykotic> one of the things i like about european buildings is that they're built to last
06:48:32 <psykotic> in korea, where i've been living for the last four years, it's rare to see a building older than 5 years
06:48:39 <psykotic> and once it's 5 years or older, it looks like it's 25 years old
06:49:21 <Athas> psykotic: well, not all European buildings.
06:49:26 <psykotic> hehe
06:49:30 <Athas> We have bullshit glass palaces too.
06:49:35 <psykotic> that's true
06:49:43 <ksf> pre-war flats are nice. 3m high walls...
06:49:46 <psykotic> but e.g. the study i went to university in, the majority of buildings are probably 50 years minimum
06:50:05 <psykotic> many quite older, and they're nothing special, the trick is to build it well up front and invest money in continual renovation rather than tearing shit down constantly
06:50:06 <Athas> It's just that we have a lot of construction funded with public money, and while they may be expensive, the results are very sturdy.
06:50:15 <psykotic> err, the city i went to university in, i meant
06:50:31 <Athas> And of course, the >century old buildings will outlast both you and I.
06:50:35 <psykotic> in seoul the real estate prices are the dominant part of the cost, so it makes business sense to build new stuff constantly
06:50:40 <jmcarthur> psykotic, quicksilver: i see you guys talked about some ideas for the Category/Arrow hierarchy. either of you interested in volunteering these ideas to the alt-stdlib project?
06:51:30 <jmcarthur> we're trying to get it a bit more organized at the moment, but earlier is better for getting new ideas in
06:51:43 <psykotic> do you have any wiki page about the goals, etc?
06:51:51 * psykotic is not quite sure of the aim
06:52:43 <Alpounet> psykotic: not yet, but it'll come
06:53:05 <jmcarthur> psykotic: not yet, but *my* goals with it are generality and a more fine grained type class hierarchy
06:53:15 <jmcarthur> and i think that holds for at least most of the interested parties
06:53:31 <psykotic> is it targeted for haskell'?
06:53:36 <jmcarthur> not strictly
06:53:50 <jmcarthur> we are just using current ghc-haskell for now
06:54:03 <psykotic> but is the idea to have a drop in replacement that just happens to be more refined?
06:54:12 <jmcarthur> as close to possible
06:54:33 <benmachine> I thought you weren't worried about backward-compatibility?
06:54:37 <jmcarthur> nope
06:54:45 <benmachine> (which is what "drop-in" sounds like to me)
06:54:52 <psykotic> well
06:54:58 <psykotic> i guess my point is whether it's a clean slate kind of thing.
06:54:59 <jmcarthur> oh, well, no, that isn't the idea if that's what was meant
06:55:01 <psykotic> which i'm not too interested in
06:55:05 <jmcarthur> clean slate, yeah
06:55:09 <psykotic> if it breaks too much stuff
06:55:09 <jmcarthur> okay
06:55:11 <psykotic> hehe
06:55:16 <jmcarthur> it will break everything
06:55:31 <Alpounet> no backward compatibility worries there
06:55:45 <psykotic> i'm not sure i have the stomach for such ultra long term planning :)
06:55:55 <psykotic> what about usefulness in the mean time? no concern?
06:57:13 <jmcarthur> won't really be useful until we hammer some things down and get some IO in it
06:57:39 <jho> is there a step-by-step guide anywhere on how to get the sdl bindings to work under windows? after finally getting Setup.lhs to configure the package and find the sdl libs, i now get errors from the linker complaining about multiple definitions of 'main'
06:58:54 <jmcarthur> psykotic: but we aren't just "planning," of course. we are "exploring." i have already written a foundation of code (which is all subject to change) on which we can simply try out our ideas
06:59:04 <jmcarthur> the idea being that the good things will stay and the bad things will be removed
06:59:07 <psykotic> jmcarthur: sorry, i didn't mean to suggest otherwise.
06:59:26 <benmachine> jmcarthur: where can I get it?
06:59:31 <benmachine> (if anywhere)
06:59:32 <Alpounet> it's a bit like Boost for C++, at least at its beginning.
06:59:34 <benmachine> (just curious)
06:59:37 <jmcarthur> benmachine: http://patch-tag.com/r/alt-stdlib/home
06:59:44 <psykotic> i'm interested in discussing things if you think it would be useful but as for my own use i guess i'm a little short sighted in terms of medium term utility for my hacking.
06:59:52 <jmcarthur> benmachine: #alt-stdlib if you are interested in following
07:03:19 <Athas> Is there a Haskell compiler targeting ARM yet?
07:03:37 <wdonnelly> I think the haskell-iphone team is working on ARM stuff
07:03:46 <psykotic> can't you use the gcc mode>
07:03:49 <wdonnelly> so it must be possible, at least
07:04:06 <dcoutts> jpcooper: what do you mean by toplevel, when talking about VBoxes
07:04:50 <ziman> Athas, jhc can compile to C
07:05:10 <Haskell_Lover90> yeah
07:05:14 <ziman> (portable C, they claim)
07:05:35 <Athas> ziman: portable C?  Even with garbage collection?
07:06:31 <ziman> hm, fun to google "arm hugs", i didn't get what i expected at all
07:06:44 <ziman> Athas, i suppose GC/RTS is included in the C source
07:10:50 <tinloaf_> hey guys
07:11:09 <tinloaf_> why does ghc complain at the first "putStrLn" in http://pastebin.com/m166dda0b ?
07:11:10 <Athas> ziman: well yes, but isn't good GC pretty architecture- and OS-dependent?
07:11:54 <tinloaf_> it complains about a "parse error"
07:13:18 <benmachine> tinloaf_: if you remove all the braces and semicolons it should work
07:13:38 <benmachine> because the compiler can work out where to put them based on the indentation
07:13:40 <Athas> I'm not sure why you get a parse error, but it certainly looks like a type error.
07:13:45 <benmachine> and is better at it than you :P
07:14:02 <Athas> 'putStrLn "<<< " ++ line' parses as '(putStrLn "<<< ") ++ line'.
07:14:08 <ziman> Athas, I don't know; I've just noticed support for different targets here http://repetae.net/computer/jhc/manual.html#crosscompilation
07:14:26 <benmachine> what Athas said, too
07:14:29 <tinloaf_> Athas: i know, i already added a $
07:15:06 <tinloaf_> indeed, without the braces and semicolons it works *sigh*
07:15:35 <tinloaf_> i was so happy that i "may" add braces and semicolons (so that an editor with a different indentation style won't mess up the code)...
07:17:00 <int-e> tinloaf_: if you use braces, you need one for the let, too: let { output = ...; }
07:28:52 <quicksilver> Athas: GHC compiles unregisterised to ARM
07:28:55 <quicksilver> Athas: it's slow but it works.
07:29:16 <Athas> Hrm.  I guess I will put off doing Haskell dev work on ARM.
07:30:54 <shepheb> I'm learning ARM for a course and may give the ARM back-end some basic registerizing love in the new year
07:31:13 <shepheb> that same course is way too much work to allow time for GHC hacking now
07:32:34 <quicksilver> quite a few people are interested in having a registerised backend
07:32:41 <quicksilver> include, IIRC, at least one commercial entity.
07:38:30 <pozic> What exactly is meant by a registerised backend? Just mapping some memory locations to registers?
07:39:06 <pozic> Or does it also have to do this in a very smart way? E.g. by using graph coloring approaches or something like it.
07:39:18 <quicksilver> it's a bit of a misnomer, really
07:39:39 <quicksilver> I should have said 'native' backend
07:39:41 <dons> custom manipulation of the generated assembly for the target machine
07:39:48 <quicksilver> i.e. one that actually generates true machine code.
07:39:48 <dons> rather than just 'whatever gcc does'
07:39:53 <dons> including pinning registers.
07:39:58 <dons> quicksilver: registerised /= native code gen
07:39:59 <quicksilver> "registerised" is an obsolete half-way step
07:40:08 <pozic> Pinning registers?
07:40:13 <ksf> wagh. ...and I thought I need subpixel hinting to get half-way decent results.
07:40:40 <quicksilver> (the via-C backend)
07:40:44 <dons> the primary difference is that the evil mangler isn't used in unregisterised code
07:40:45 <ksf> it figures that freetype uses a negative y axis so I moved the glyphs into the wrong direction on the x axis.
07:40:58 <quicksilver> it was a terrible but clever hack to rearrange the assembly generated by the C to improve performance.
07:41:10 <pozic> So, if gcc was omniscient, there would be no need for a native backend?
07:41:11 <quicksilver> but like I say, it's most obsolete
07:41:33 <quicksilver> so the normal dichotomy now is between "unregistered" (naive via-C) and "native"
07:41:45 <quicksilver> the registerised via-C path is the obsolete one in the middle.
07:41:57 <dons> getting obsoleted, yeah
07:42:05 <quicksilver> pozic: only if you believe C can express everything you want to express
07:42:14 <quicksilver> pozic: actually C is a truly terrible compilation target
07:42:49 <ksf> ...as it appears, freetype doesn't advance with sub-pixel precision.
07:43:21 <pozic> quicksilver: what do you mean by that? C can express everything.
07:43:45 <quicksilver> pozic: C can't express tail calls.
07:44:01 <pozic> quicksilver: you can do that transformation yourself, beforehand.
07:44:33 <ksf> no you can't, because c compilers choke on 100k-line funcitons.
07:44:58 <quicksilver> pozic: C can't express the types used by modern processors, such as 4x32 or 8x16 vector registers
07:45:12 <pozic> ksf: How does the via-C approach to it then?
07:45:13 <ksf> well gcc can.
07:45:17 <quicksilver> pozic: C can't express the basic functionality of 20 year old processors, such as a carry flag.
07:45:19 <ksf> a trampoline.
07:45:29 <Axman6> quicksilver: sounds like an ideal job for LLVM...
07:45:39 <pozic> ksf: which is a non-standard C feature, you mean?
07:45:52 <ksf> ...which isn't a tail call.
07:46:01 <ksf> it's returning a function pointer to call.
07:46:02 <quicksilver> Axman6: http://www.haskell.org/pipermail/glasgow-haskell-users/2007-January/011838.html
07:46:08 <ksf> that's not the same, there's indirection added.
07:46:17 <lilac> llvm technically doesn't have the ability to write guaranteed tail-calls either iirc
07:46:26 <lilac> it only has the ability to say 'you're allowed a tail call here if you like'
07:46:30 <pozic> ksf: if there is only O(1) overhead, I would call it "the same".
07:46:49 <ksf> ...it's O(n), where n is the number of function calls.
07:46:56 <ksf> ...or rather thunk reductions.
07:47:05 <ksf> anyway, that's a lot of ones you're adding there.
07:47:31 <quicksilver> surely getting it wrong (and using a normal call) only has O(1) overhead per call.
07:47:37 <quicksilver> it's O(1) time *and* O(1) stack, though.
07:47:42 <quicksilver> and that's the painful bit ;)
07:48:10 <quicksilver> pozic: C can't express CAS
07:48:36 <quicksilver> C is just a terrible terrible language for a compilation target...
07:48:43 <dumael> quicksilver: afaik, there' more recent work attempting to integrate ghc/llvm togethC[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cer.
07:48:45 <ksf> ...c can't put data right in front of functions.
07:48:58 <dumael> *together
07:49:06 <pozic> quicksilver: what's CAS?
07:49:14 <psykotic> compare and swap
07:49:26 <psykotic> (i assume)
07:49:28 <quicksilver> dumael: yes, there is.
07:49:34 <etpace> Hmm, I'm reading RWH and all of a sudden it jumps into CharParser () from GenParser () st, without talking about st or CharParser, what's the difference?
07:49:52 <quicksilver> dumael: I'm not sure which of those shortcomings have been solved and which have been worked around.
07:49:54 <Axman6> dumael: attempting? it's been around for a while.
07:50:17 <quicksilver> Axman6: it has? where?
07:50:44 <Axman6> well, OS X has shipped with LLVM-gcc since late in 10.4 i think...
07:50:50 <quicksilver> Axman6: g*H*c
07:50:59 <Axman6> oh, ha, right
07:51:21 <quicksilver> there is a project ( http://hackage.haskell.org/trac/ghc/wiki/LlvmBackend ) but afaik nothign has emerged into public view yet.
07:51:22 <Axman6> anyway, someone at UNSW is working on it
07:51:37 <lilac> well, then, llvm-gcc plus -via-c and you're golden :)
07:51:50 <benmachine> etpace: it looke like CharParser st a = GenParser Char st a
07:52:06 <benmachine> (via a type synonym)
07:52:10 <benmachine> more than that I don't know
07:52:13 <Axman6> lilac: golden? maybe bronze :P
07:52:32 <benmachine> (aside from the fact that parsec-3.0.1 doesn't seem to *have* CharParser)
07:52:41 <etpace> Hmm, ok thanks
07:52:48 <pastah> $ cabal install base
07:52:48 <etpace> I guess it'll explain st in due time
07:52:49 <pastah> Resolving dependencies...
07:52:51 <pastah> cabal: internal error: impossible
07:52:55 <pastah> what gives?
07:52:59 <pastah> impossible?
07:53:03 <quicksilver> don't use cabal to install base
07:53:10 <quicksilver> if you succeeded you would destroy your computer
07:53:13 <quicksilver> and possibly the universe.
07:53:13 <pastah> quicksilver: why not?
07:53:17 <pastah> hehe
07:53:21 <quicksilver> base comes with a GHC version
07:53:25 <benmachine> etpace: a parser can store state; having st as () just means you don't need to do that
07:53:27 <quicksilver> you only ever upgrade it by installing the new GHC version
07:53:55 <benmachine> err, I could have phrased that better
07:54:06 <pastah> quicksilver: so how do i go about installing ghc 6.10 then?
07:54:14 <pastah> download and compile manually?
07:54:29 <Saizan> or download the binary
07:55:38 * pastah downloads the 6.10.4 binary
07:55:48 <pastah> this is gonna make my computer explode
07:55:50 <pastah> i promise
07:56:03 <quicksilver> pastah: sure, you can compile base as part of a GHC compile, just don't try to use cabal to do it :)
07:56:20 <quicksilver> but really there isn't much point in compiling GHC yourself if there is a binary for your platform.
08:03:25 <Kamujin> I have recently started learning haskell and I figured it would be useful to listen in on other haskell users discussions about their issues. I am surprised to see so many people in this room as I don't run into to many haskell programmers in my business dealings. In what areas is haskell in common use? Is there a stereotypical haskell programmer?
08:04:10 <arw_> interesting question.
08:04:20 <opqdonut> the stereotypical haskell programmer is a university student in maths or cs probably
08:04:22 <arw_> i know haskell mostly from university.
08:05:17 <Axman6> Kamujin: it's mainly used for academic things, but don't be fooled into thinking that means it's not useful. it's an extremely powerful language and has uses in potentially every indusutry
08:05:17 <dons> Kamujin: its a general purpose language, so its hard to characterize the average user.
08:05:24 <dons> it is used in open source, research and industry
08:05:40 <Axman6> s/industry/programming industry
08:05:50 <dons> the open source community is the largest, the research community the oldest, and the industrial users make the most money.
08:06:13 <jmcarthur_work> Kamujin, and this channel is so huge because the haskell community is so helpful!
08:06:17 <dons> Kamujin: welcome. we have a very large, organized community
08:06:31 <pastah> Kamujin: one field where you might see haskell stand a bit more is in compiler construction
08:07:15 * jmcarthur_work has used haskell for games, web sites, number crunching, one-shot scripts, all kinds of various things
08:07:16 <Kamujin> Thanks guys. I wouldn't waste my time trying to learn haskell if I didn't think it would be useful, so I hope you don't think I my question is intended as a slight.
08:07:16 <benmachine> Alternative is really the same as MonadPlus, isn't it?
08:07:21 <dons> also in finance.
08:07:24 <benmachine> both of which are pretty darn similar to Monoid
08:07:28 <pastah> Kamujin: haskell is great for most things, but if i'm writing a compiler or interpreter, i wouldn't want to do it in any other language :)
08:08:03 <dons> Kamujin: since you're new, the key resources to get to know are: the open source libraries: http://hackage.haskell.org/packages/archive/pkg-list.html ; and the industrial haskell group, http://haskell.org/haskellwiki/Haskell_in_industry
08:08:08 <Axman6> Kamujin: haskell makes concurrent and parallel programming a joy :)
08:08:41 <Kamujin> Thanks again.
08:08:51 <pastah> quicksilver: ok, i've extracted the ghc 6.10.4 binary file..., looking at the INSTALL file now...
08:09:14 <Petrosian> I've been meaning to take a look at the concurrency stuff
08:09:17 <pastah> now do i want to replace my old version of ghc or do i want to place it in my ~ directory?
08:09:44 <pastah> Petrosian: STM :D
08:09:47 <Petrosian> How/What would I use to translate something like hand-over-hand locking of a tree in C, say
08:10:17 <Petrosian> Is low level/fine grained locking possible and feasible, or is better to just take a higher level view?
08:10:32 <Axman6> locking? who needs locking?
08:10:34 <dons> you can have very fine grained locks, or atomic transactions
08:10:46 <pastah> i don't know much about concurrency, but check this out Petrosian: http://www.haskell.org/haskellwiki/Software_transactional_memory
08:10:52 <Petrosian> dons: What could you use for that?
08:10:52 <dons> here's a recent tutorial, http://donsbot.wordpress.com/2009/09/05/defun-2009-multicore-programming-in-haskell-now/
08:11:08 <dons> MVars for locks, STM for transactions.
08:11:10 <Petrosian> Excellent, thanks pastah / dons
08:11:13 <dons> they're both very easy to pick up.
08:11:17 <Petrosian> Right, and what about message passing?
08:11:26 <Axman6> use MVars/Chans
08:11:42 <dons> you can do async message passing via throwTo, or typed messages via Chans. there's actors libraries built on top
08:12:37 <Petrosian> I assume all this stuff is bundled with GHC?
08:12:42 <pozic> Is there an alternative to the mtl which does not use functional dependencies which works in 6.10.4?
08:12:44 <dons> this is your key competitive advantage as a haskell programmer: you can write fast, concurrent code that will parallelize on multicore, and be more productive   than in any other language.
08:12:53 <dino-> This was handy to me as well to illustrate STM: http://www.haskell.org/haskellwiki/Background_thread_example
08:12:58 <dons> pozic: mtl-tf
08:13:04 <dons> Petrosian: that's right.
08:13:10 <Petrosian> Excellent.
08:13:15 <dons> Petrosian: get it from the haskell platform, http://hackage.haskell.org/platform/
08:13:46 <Petrosian> I just need a contrived concurrent app to try and write as an excuse to try all this stuff out
08:13:59 <dons> RWH (online and in book form) has great stuff on concurrent and parallel/multicore haskell programming
08:14:05 <pastah> Petrosian: as i said, i don't know much about paralellism/concurrency, but i just sat down and read the type signatures and docs here: http://hackage.haskell.org/packages/archive/base/4.1.0.0/doc/html/GHC-Conc.html
08:14:13 <dons> do something on the network , and hide latency with 1000s of haskell threads
08:14:27 <Axman6> Petrosian: things like forkIO make concurrency super easy (forkIO :: IO () -> IO ThreadId)
08:15:02 <Petrosian> Axman6: That would spawn a new thread, pressumable?
08:15:03 <Axman6> Petrosian: it's also light weight, so as dons said, you can have thousands of threads, and you won't have any problems
08:15:13 <pastah> i understood most of it, so if i wanted i could probably make stuff work, using lubricant and hammers...
08:15:20 <Petrosian> Are there any drawbacks to the lightweight threads?
08:15:25 <Axman6> Petrosian: yup. give it an IO action, and it'll spawn it off, and give you back the ThreadId
08:15:38 <psykotic> late to the party but to follow up on what don said
08:15:45 <Axman6> Petrosian: you can't use CURL/OpenGL in them easily? maybe? :\
08:15:50 <Petrosian> That seems almost too simple! I'm suspect.
08:15:51 <psykotic> imo haskell has the best "low-level" concurrency library of any language, bar none
08:16:07 <Axman6> Petrosian: you'll find out it's just as simple as you think :)
08:16:12 <psykotic> the 'concurrent haskell' paper is one of my favorites. and with the recent refactoring of the lower level primitives, you can go any lower
08:16:38 <pozic> dons: is it a complete port?
08:16:58 <psykotic> and i'm not an unqualified haskell groupie like don :) so when i say that it's pretty high praise
08:17:08 <Petrosian> Haha
08:17:20 <psykotic> i remember seeing ayrnieu praise concurrent haskell, i.e. mvars and so on
08:17:23 <psykotic> that should tell you something
08:17:31 <psykotic> that's like mccarthy writing a panegyric for karl marx
08:17:33 * Axman6 really likes Ada's concurrency support, but it's aimed at different things than Haskell does
08:18:21 <Petrosian> I heard a lot of commotion about Erlangs concurrency support
08:18:35 <psykotic> erlang has a very opinionated view of concurrency
08:18:35 <Petrosian> By the sounds of it, Haskell's support is better?
08:18:39 <psykotic> it's both good and bad
08:18:52 <psykotic> what it does, it does very well, but it's a take-it-or-leave-it kind of approach
08:18:57 <Petrosian> I see.
08:18:57 <Axman6> erlang is great for distrbiuted concurrency, but i dislike it's basically total lack of typing
08:19:14 <psykotic> haskell has the best concurrency foundation of any language ever designed and on top of that it builds a number of higher level frameworks
08:19:46 <psykotic> but even if you stick to the foundation it's imo a close competitor for many other languages
08:19:57 <Axman6> i also sort of dislike Erlang's security. either you fully trust a remote host (they can run arbitrary erlang code on your machine), or you don't trust them at all
08:20:08 <psykotic> erlang's security was never designed for wan operation, axman
08:20:11 <psykotic> that's why it's so weird
08:20:15 <Axman6> yeah
08:20:16 <Petrosian> Are there any large, concurrency rife applications/libs on Hackage?
08:20:24 <Petrosian> I wouldn't mind taking a look at their guts
08:20:37 <psykotic> Petrosian: can i read two papers with some low level details?
08:20:48 <psykotic> one is the original 'concurrent haskell' paper by peyton jones, et al
08:21:01 <psykotic> the other is the more recent paper on the refactoring of ghc's concurrency primitives
08:21:18 <Petrosian> I've got the ones linked in here bookmarked for later study
08:21:22 <psykotic> into 'primitive transactional memory' or whatever it's called, the paper is also coauthored by peyton jones and a guy called, i believe, ping
08:21:28 <porges> is GHC.Prim.Any equivalent to (forall a. a)
08:21:56 <porges> or am I just confused :)
08:22:08 <Petrosian> Ahh, nevermind, noticed the "Projects using STM" section just now
08:23:39 <Axman6> Petrosian: you can do stuff like: main = do { var1 <- newEmptyMVar; var2 <- newEmptyMVar; forkIO (doSomeExpensiveWorkAndPlaceItIn var1); forkIO (someOtherExpensiveStuffPlacedIn var2); res1 <- takeMVar var1; res2 <- takeMVar var2; print var1; print var2 }
08:23:55 <psykotic> porges: isn't it a bit like a void* with type tagging?
08:23:58 <psykotic> err, without type tagging
08:24:35 <porges> well I only found it by playing with type families
08:24:43 <psykotic> i always got the impression it was supposed to be used much like void* is in c, i.e. when you know something you can't tell the type system
08:24:44 <porges> and everything I know about it is by poking it :P
08:24:44 <Petrosian> Axman6: That's pretty implicit about what concurrency is going on, how good (objectively speaking!) is GHC at making the best use of your CPU with something like that?
08:24:58 <Axman6> Petrosian: very good
08:25:57 <Axman6> it'll create one thread per core/CPU you have, and they will run the threads you fork (haskell threads are run inside OS threads, which makes the performance _much_ better. much less context switching etc)
08:26:02 <pastah> quicksilver: where are you? i'm scared
08:26:10 <porges> psykotic: are there any actual docs? or is it meant to be hidden like unsafePerformIO#? :)
08:26:35 <psykotic> i'm not sure what you mean by actual docs. there are a few things in ghc's docs
08:26:47 <porges> hrm
08:26:49 <RayNbow> hmm, in sigfpe's talk ( http://www.vimeo.com/6590617 ), are there mistakes in his "Type III Reidemeister Move" slide (00h39m)?
08:27:02 <porges> the most recent GHC.Prims docs I can find date from 6.8 or so :\
08:27:07 <psykotic> it basically says that any is like void *, in so many words, and unsafeCoerce can be used with Any as source/target much like you can do casts in C
08:27:16 <psykotic> again, it doesn't use that terminology but that's what the 'moral' meaning i get from it
08:27:17 * RayNbow believes the "i" in the diagram on the right should be a "j"
08:27:33 <porges> RayNbow: I think it might just be the low resolution :)
08:27:38 <Axman6> Petrosian: you should check out http://www.haskell.org/ghc/docs/latest/html/libraries/base/Control-Concurrent.html
08:28:02 <RayNbow> also, there's a mistake in the last line of code on that slide
08:28:44 <RayNbow> (j'',i'') <- over (i,k')  -- this should be: (j'',i'') <- over (i',j')
08:28:56 <psykotic> porges: http://www.haskell.org/ghc/docs/latest/html/libraries/ghc-prim/GHC-Prim.html#t%3AAny
08:29:01 <psykotic> i assume you've seen this?
08:29:11 <psykotic> and see the accompanying entry immediately below for unsafeCoerce
08:29:20 <porges> gah :|
08:29:28 <porges> why doesn't that show up when i search for it
08:29:32 <psykotic> google it
08:29:33 <Axman6> Petrosian: also, MVars are fantastic to work with. can be used as a locking mechanism, communication channel, and other things i can't even think of
08:29:52 <porges> I only get http://www.haskell.org/ghc/docs/6.6/html/libraries/base/GHC-Prim.html
08:30:15 <psykotic> anyway, from that, don't you get the sense that it's just like a void*?
08:30:38 <porges> sounds like it
08:30:45 <porges> the second point especially
08:30:51 <porges> "DON'T TOUCH THIS"
08:30:53 <psykotic> hehe
08:31:03 <psykotic> i think i've seen applications of this to dynamic types
08:31:19 <psykotic> basically you define a dynamic value as a tuple of a type tag and an 'any
08:31:25 <Axman6> dons: are there docs anywhere showsing how you can use exceptions to send messages between threads? i never quite got the point of throwTo.
08:31:30 <psykotic> and you can do a safe runtime cast by comparing type tags and unsafe-coercing if they match
08:31:41 <porges> sounds about right
08:31:43 <psykotic> (returning Nothing if no match)
08:32:00 <Saizan> yeah, that's Data.Dynamic
08:32:09 <porges> I was just intrigued when my type family instantiated as (C x GHC.Prim.Any)
08:32:25 <porges> didn't realise it actually had a constructor :P
08:32:26 <psykotic> i guess that's because it basically 'desugars'
08:32:40 <psykotic> as in, it's trying to 'desugar' some type fanciness that can't be represented by the core calculus or something
08:32:52 * Axman6 goes to sleep. o/
08:32:53 <Saizan> porges: if you see Any in types it's often a bug
08:33:08 <mmorrow> Axman6: `throwTo' is the kill() of forkIO threads
08:33:13 <psykotic> Saizan: compiler bug?
08:33:20 * Saizan didn't follow the discussion though
08:33:28 <porges> Saizan: yeah I got a couple of "THE IMPOSSIBLE HAPPENED!" around the same time
08:33:31 <psykotic> well, you said 'often', so i was wondering
08:33:35 <porges> but I couldn't get a sane test case out of it
08:33:37 <Saizan> psykotic: type checker bug, yeah
08:33:50 <mmorrow> Axman6: killThread TID <=analogy=> kill -9 PID
08:34:06 <Vanadium> Can threads not catch KillThread?
08:34:09 <Axman6> mmorrow: does it necessarilly kill the thread? can't it handle the exception and keep on running?
08:34:10 <Vanadium> And, like, handle/ignore it
08:34:15 <Saizan> psykotic: in some cases it's just a monomorphic type variable that doesn't get unified with anything for legitimate reasons
08:34:23 <mmorrow> Valodim: not positive, but i believe not
08:34:25 <mmorrow> well
08:34:28 <mmorrow> you can block
08:34:39 <mmorrow> so maybe not quite kill -9
08:34:41 <Saizan> yes, they can catch it
08:34:44 <psykotic> doesn't ghc have some async exception goodness?
08:34:50 <psykotic> i thought the whole point was to deal with issues like that
08:35:08 <Saizan> KillThread is not a special exception, it behaves like the other
08:35:16 <mmorrow> Axman6: killThread TID <=analogy=> kill -TERM PID    ;)
08:35:17 <mishrak> > new
08:35:18 <lambdabot>   Not in scope: `new'
08:35:39 <Axman6> so how do you catch exceptions in forkIO'd threads>/
08:35:41 <Axman6> ?*
08:35:41 <lambdabot> Maybe you meant: . ? @ v
08:35:49 <Valodim> whut?
08:35:53 <mmorrow> catch ?
08:35:53 <Saizan> Axman6: with Control.Exception.catch
08:35:54 <psykotic> stakeImmolateAndDecapitateThread
08:36:09 <psykotic> dieDieDie
08:36:21 <Vanadium> unsafePerformThreadicide
08:36:37 <psykotic> i've developed some really bad kill -9 habits from impatience
08:36:49 <mmorrow> i usually only use kill -9 :)
08:36:51 <psykotic> i know you shouldn't use -9, i think this makes me a morally bad person
08:36:59 <psykotic> hehe
08:37:05 <porges> I don't think I can talk to you any more
08:37:19 <mmorrow> killing-flies-with-nuclear-weapons++
08:37:24 <Axman6> Saizan: so, if you wanted to use exceptions to send messages between threads, you'd wrap the thread in try/catch? (or something, been a while since i look at exceptions in haskell
08:37:32 <psykotic> mmorrow: i think it's a bigger issue with daemons that have to persist their state or something like that
08:38:18 <psykotic> fortunately i don't do any sysadmin work
08:38:19 <mmorrow> psykotic: well yeah, i (usually) shut those down appropriately
08:38:36 <mmorrow> except when they're being uppity
08:38:36 <psykotic> nukeFromOrbit
08:38:41 <Saizan> Axman6: forkIO (catch (<something that waits>) (\e -> <got a message e>))
08:38:49 <psykotic> then you have to unsafeBitchSlap them into submission, yeah
08:38:59 <Axman6> righto.
08:39:06 <Axman6> anyway, really need to sleep. night all
08:39:21 <psykotic> gotta get your daemonic hoes in a row
08:39:32 <porges> 03:39
08:41:00 <jpcooper> dcoutts, a VBox being the top-level element rather than a typical one like a Window
08:41:23 <Vanadium> I cannot really see where I would want to use throw/catch instead of Chans or MVars :|
08:42:12 <psykotic> asynchronous vs synchronous
08:42:28 <psykotic> and probably other distinctions i'm forgetting
08:43:26 <Saizan> throw/catch are the synchronous ones, tbc :)
08:43:49 <Saizan> but i'd implement a synchronous Chan with MVars instead
08:44:03 <Vanadium> But throwing exceptions at a thread that is not expecting them seeems rather irresponsible? :\
08:44:15 <Vanadium> At the point where the thread is expecting them it might as well check a mvar
08:44:20 <porges> ack. who wrote the thing recently about the specialized versions of Foldable?\
08:44:37 <porges> to allow fast folding for things like Bytestring etc
08:44:54 <MyCatVerbs> Vanadium: could be an optimisation. If the exception is almost never thrown, then it might save time to throw an async exception rather than polling for it.
08:45:15 <Vanadium> Hm, okay.
08:45:23 <Saizan> Vanadium: if it's already waiting on a MVar it might be clearer to throw an exception at it, rather than add another possible value to the one communicated via the mvar
08:48:37 <porges> ah, kmett
08:48:45 <porges> should have known -_-
08:52:42 <dons> Axman6: i give an example in my tutorial
08:52:54 <dons> its very erlang-like (in that you interrupt the thread, so it better handle it)
08:54:11 <quicksilver> porges: edwardk, maybe?
08:54:14 <quicksilver> porges: ah, you beat me to it.
08:55:48 <porges> the thing I don't like about it is that there is a disconnect between when you want the specialized versions and when you don't
08:55:57 <porges> it would be nice if it were automatic
09:00:18 <Phyx-> func
09:01:13 <codejedi> Hi every one, my first post on this channel, will ask question if needed and answer when i can
09:01:30 <psykotic> codejedi: welcome. ask away!
09:02:21 <codejedi> psykotic: tell me abt u
09:02:47 <codejedi> just getting ti know peers
09:02:53 <psykotic> random haskeller
09:03:03 <codejedi> ok
09:03:06 <psykotic> :)
09:03:20 <codejedi> professional?
09:03:23 <psykotic> no
09:03:32 <psykotic> though there are some of those here, too
09:03:36 * psykotic prods don
09:03:36 <codejedi> working?
09:03:53 <Philippa> psyk: what're you doing these days, anyway?
09:04:13 <psykotic> Philippa: resigned my job to go backpack hacking for a year
09:04:23 <Philippa> ah, cool
09:04:25 <psykotic> right now busy selling off my last things in korea so i can get on the move
09:04:51 <psykotic> trying to get rid of my sports car without losing too much money in the process but the general financial woes of korea aren't helping
09:04:55 <Philippa> I'm starting to find a little time to code in again
09:04:56 <Philippa> ow
09:05:39 <psykotic> that and a few more vaccinations and i'm off!
09:05:53 <RayNbow> preflex: seen malcolmw
09:05:53 <preflex>  malcolmw was last seen on #haskell 7 hours, 18 minutes and 45 seconds ago, saying: ivanm: that is, if the control flow of pa takes it through the execution path where commit is used
09:07:06 <benmachine> @hoogle (a -> Maybe a) -> a -> a
09:07:06 <lambdabot> Data.IntMap update :: (a -> Maybe a) -> Key -> IntMap a -> IntMap a
09:07:06 <lambdabot> Data.Maybe mapMaybe :: (a -> Maybe b) -> [a] -> [b]
09:07:06 <lambdabot> Data.IntMap mapMaybe :: (a -> Maybe b) -> IntMap a -> IntMap b
09:08:15 * benmachine is wondering if iterMaybe f a = fromMaybe a (iterMaybe (f a) a) is in a module somewhere
09:08:31 <codejedi> psykotic: best of luck
09:08:39 <psykotic> thanks!
09:08:51 <psykotic> in the mean time i'm enjoying my spare hacking time
09:09:02 <codejedi> me too in a way
09:09:14 <codejedi> finished my ms this june
09:09:21 <codejedi> now searching for job
09:09:39 <codejedi> and enjoying the haskell dalliance
09:10:05 <psykotic> what was your thesis subject?
09:10:31 <codejedi> it was related to throttling in dataflow based soc arch
09:10:34 <benmachine> wait my definition doesn't make sense
09:10:36 * benmachine fixes it
09:11:01 <codejedi> an extensive and fast design space exploration
09:11:47 <codejedi> experimental work based on some heavy duty abstractions and development of a hybrid simulator
09:12:19 <psykotic> so you're in ee/ce?
09:12:25 <codejedi> cs
09:12:48 <psykotic> but with a hardware bent, it sounds like. cool.
09:13:19 <codejedi> thanks, ya but now looking forward to functional programming
09:13:38 <codejedi> trying hands on trading etc too
09:13:48 <codejedi> means algorithmic trading
09:14:05 <codejedi> in haskell
09:14:20 <jpcooper> codejedi, where are you starting?
09:14:37 <jpcooper> I'm interested in writing a kind of arbitrage bot for my bachelor's thesis
09:15:00 <codejedi> jpcooper: nowhere, looking for job
09:15:10 <psykotic> does arbitrage require advanced real-time analytics? i naively assumed it was all about fast-finger-on-the-trigger :)
09:15:14 <codejedi> no functional prog jobs in my country
09:15:26 <jpcooper> psykotic, at least something that finds the odds for me and compares them is good
09:15:52 <psykotic> codejedi: not that many in any country alas
09:15:56 * EnglishGent writes a piece of code to do algorithmic trading circa october last year
09:16:08 <EnglishGent> trade = do sell ; trade
09:16:10 <EnglishGent> :)
09:16:10 <codejedi> i am looking more towards volatility based atbitrage
09:16:10 <jpcooper> EnglishGent, any success?
09:16:28 <codejedi> gud
09:16:42 <codejedi> i will use code if i don't get a job
09:16:56 <psykotic> EnglishGent: i guess anything involving computers is technically algorithmic at some level, eh? :P
09:16:59 * EnglishGent also wishes there were more jobs going in Haskell :|
09:17:01 <jpcooper> replicateM sell surely would have been better?
09:17:30 <psykotic> jpcooper: for fast speed in arbitrage, i have a manually unrolled sellSellSellSellSellSell function
09:18:06 <psykotic> gotta exploit those short-term differentials, every femtosecond counts
09:19:44 * lvillani is trying to learn Haskell and he's struggling with Haskell's type system
09:20:12 <psykotic> lvillani: the good part is that most of haskell is in the type system, so once you got that, you know almost everything :)
09:20:30 * psykotic is conveniently ignoring space leaks
09:20:40 <Berengal> s/once/if
09:20:47 <psykotic> hehe
09:20:51 <sleepynate> nice
09:21:08 <jpcooper> lvillani, what's the problem?
09:21:12 <psykotic> and of course ghc's type system is a fast moving target
09:21:16 <jpcooper> just struggling to make things compile?
09:21:16 <lvillani> psykotic: heh :)
09:21:25 <lvillani> jpcooper: mostly, yes
09:21:44 <sleepynate> > (+ 4::Int 5::Integer)
09:21:45 <lambdabot>   <no location info>: parse error on input `::'
09:21:50 <sleepynate> oh noes!
09:21:52 <sleepynate> :)
09:21:57 <lvillani> trying to do a simple program which uses DBus to query DeviceKit-power for battery charge
09:22:12 <psykotic> that's pretty cool
09:22:25 <psykotic> where's the types hurtin'?
09:22:25 <sleepynate> yea, that sounds pretty badass
09:22:37 <lvillani> my main problem is that the whole syntax is so compact and full with arrows, symbols, syntatic sugar
09:22:42 <lvillani> that I find it hard to follow
09:22:48 <lvillani> especially example code
09:23:08 <psykotic> yeah it takes some getting used to
09:23:33 <lvillani> heh, I remember I didn't have such problems learning C/C++
09:23:58 <Berengal> Follow the types
09:24:05 <psykotic> c++'s learning curve is different
09:24:06 <sleepynate> 'cause c++ is 9 billion times as verbose :D
09:24:16 <Philippa> you don't trust ghc's inliner, huh? :-)
09:24:32 <psykotic> 'learning' c++ means learning what parts to avoid :)
09:24:38 <Berengal> Hehe
09:24:55 <psykotic> there's the honeymoon period where you think learning every template trick in the book is what 'learning' is about
09:24:59 <jmcarthur_work> c++ is easy to learn at first, but then you find its flaws an you are suddenly afraid to do anything else
09:25:23 <Berengal> In my experience, 'learning' a language usually comes in two stages: learn the syntax, then learn the semantics.
09:25:26 <quicksilver> psykotic: then there's the period where you learn why not to use the every template trick in the book?
09:25:31 <Berengal> Haskell, on the other hand, only has 'learn the syntax'
09:25:35 <psykotic> quicksilver: exactly.
09:26:04 <psykotic> quicksilver: which requires enormous discipline. it's kind of like learning that not all code needs to be golfed down to point free style :P
09:26:12 <aefjt> Because you can never fully comprehend the semantics
09:26:14 <jmcarthur_work> psykotic, nonsense!
09:26:17 <jmcarthur_work> ;)
09:26:18 <Berengal> psykotic, you mean it doesn't?
09:26:31 <psykotic> ssh, don't tell anyone
09:26:52 <psykotic> but once you've learned something that's cute and powerful and have invested a lot of effort, you feel like you SHOULD use it.
09:26:59 <jpcooper> it's a shame that there's hardly anything online on the reader monad
09:27:05 <Saizan> most of the time you golf up to point-free style
09:27:12 <jmcarthur_work> point free is really bad if you don't have a complete enough set of meaningful combinators to work with
09:27:14 <psykotic> actually the analogy is imperfect because C++ templates have all kinds of hidden costs that are unlike the other example i gave
09:27:24 <psykotic> but in terms of restraint and professionalism i'd say it's similar in some ways
09:27:27 <lvillani> Berengal: yeah, and I have to learn it very well, because I'm still used to C-style syntax.. and just "discovered" that my simple program didn't compile because of that :p
09:27:54 <jmcarthur_work> but i think point free is excellent almost always *with the right abstractions*
09:27:58 <jmcarthur_work> which we often don't have
09:28:10 <Berengal> I actually get sort of happy when my programs don't compile. Means the compiler found a bug
09:28:22 <jmcarthur_work> me too.... with haskell
09:28:25 <psykotic> jmcarthur_work: i guess i should have said 'code compression' instead.
09:28:35 <psykotic> the point being that sometimes syntactic compression is the same as semantic compression
09:28:36 <jmcarthur_work> with any other language it just reminds me of how many bugs the compiler is probably *not* finding
09:28:37 <psykotic> which is good
09:28:43 <EnglishGent> I wish the error messages were better though
09:28:44 <psykotic> but other times it's spurious
09:29:06 <Berengal> Yeah, coding java a compile/deploy failure usually means I need to dive into 15 layers of xml-hell to find which libraries are acting weird
09:29:07 <EnglishGent> from my pov at least the compiler often goes "your code is bugged :P~~~~~~"
09:29:23 <psykotic> anyway i golf like mad because i don't have to have anyone else maintain what i write :)
09:29:28 <psykotic> it's part of the fun
09:29:47 <jmcarthur_work> i golf like mad because it helps me find good abstractions
09:29:51 <psykotic> that too
09:29:55 <Berengal> jmcarthur_work, ditto
09:30:03 <jmcarthur_work> if i golf and it comes out ugly, there's probably something i can do about it
09:30:07 <jpcooper> golf?
09:30:11 <Berengal> My golfing usually consists of extracting utility functions into top-level functions
09:30:15 <psykotic> but i do it maybe 10% beyond what a balance between readability and other factors would dictate
09:30:22 <jmcarthur_work> jpcooper, golfing == shrinking the code as much as possible
09:30:28 <lvillani> I was calling DBus.Message.newMethodCall("arg1" "arg2" "arg3") instead of doing it without parenthesis, then *poof* it compiled, but I really didn't understand that because of the error message though...
09:30:31 <dcoutts> jpcooper: I see, no, only a Window can be a free standing on-screen window. What are you really trying to do?
09:30:33 <jpcooper> right
09:30:52 <aefjt> You could use an apl keyboard to type arrows
09:30:59 <porges> are there some unresolved Coverage Condition warnings when using fundeps with type families?
09:31:01 <aefjt> That probably counts.
09:31:10 <jmcarthur_work> i seriously just golf until it sucks and then make it readable with new combinators
09:31:16 <jpcooper> dcoutts, Glade supports VBox being top-level if Gtkbuilder is used. I want to create composable parts of my GUI so I can just load a widget from a file and add it
09:31:18 <jmcarthur_work> then i golf some more
09:31:18 <psykotic> jmcarthur_work: anyway there's a difference between syntactic golfing and the kind of reduction that comes from thinking deeply about the structure of your code.
09:31:28 <dcoutts> jpcooper: you can have stuff in a glade file that you do not use for a top level window
09:31:33 <jmcarthur_work> psykotic, true. shrinking identifier names is not what i have in mind
09:31:36 <psykotic> when you take a clear do-expression and start making it point free to shave off 10 characters...
09:31:46 <psykotic> not always a good idea
09:31:46 <jpcooper> dcoutts, how can I create such a thing in Glade itself?
09:31:58 <jpcooper> putting the VBox in its own window doesn't work, as I can't see to change it parent
09:32:03 <jmcarthur_work> actually, do notation in particular i tend to golf out
09:32:04 <porges> psykotic: applicative helps ;
09:32:19 <jpcooper> going into the actual glade file and manually removing the outer window works, but I can't work on that file in Glade later on
09:32:21 <psykotic> jmcarthur_work: i do when it makes sense
09:32:23 <jmcarthur_work> when i feel like i need do notation it's often because i need a combinator i don't have or know about
09:32:25 <Berengal> I tend to use a bit too much applicatives
09:32:30 <dcoutts> jpcooper: oh, I was going to suggest reparenting
09:32:34 <jmcarthur_work> i tend to leave do notation alone in the IO monad though
09:32:41 <saml> > (.)
09:32:41 <lambdabot>   {{()->()}->{{()->()}->{()->()}}}
09:32:42 <dcoutts> jpcooper: the alternative is to bind GtkBuilder in gtk2hs, which should be done anyway
09:32:43 <psykotic> the applicative ascii syntax is so repulsive that i stay away more than i should
09:32:43 <Berengal> often mixing function and other applicatives in the same 30-character line
09:32:53 <psykotic> i need to have emacs display them as hearts and fluffy bunnies or something
09:33:06 <jpcooper> dcoutts, I thought of that but I can't seem to figure out how I'd do this while adding a page to a notebook
09:33:12 <jmcarthur_work> i'm not a fan of f <$> a <*> b
09:33:16 <dcoutts> jpcooper: it should mostly be a copy'n'paste of the binding code for libglade
09:33:17 <porges> I have <$> = âˆ˜, <*> = âŠ™, $ = â‹…
09:33:19 <jmcarthur_work> but i like liftA2 and company
09:33:27 <dcoutts> jpcooper: but using sensible error reporting mechanisms
09:33:30 <porges> because <*> should really be <$> anyway ;)
09:33:33 <Berengal> psykotic, use she, so you can go (|f a b c d |)
09:33:36 <psykotic> porges: in emacs or as unicode ops in haskell?
09:33:41 <jmcarthur_work> porges, it is in alt-stdlib, right now :)
09:33:42 <porges> haskell
09:33:50 <psykotic> i hate entering unicode
09:33:51 <jpcooper> dcoutts, I'm sadly too lazy to do that right now
09:33:55 <porges> jmcarthur: link?
09:33:59 <jpcooper> I don't have experience with C or FFI anyway
09:34:01 <psykotic> i'd rather just use ascii with a display-only substitution
09:34:10 <porges> psykotic: I have them wired in with my keyboard :P
09:34:10 <psykotic> that way you can also do it for `functionslikeThese`
09:34:12 <dcoutts> jpcooper: you mean you're making multiple copies, using it as a template?
09:34:15 <jmcarthur_work> porges, it's just a very early work in progress: http://patch-tag.com/r/alt-stdlib
09:34:20 <porges> just like Î± Î» â†’ :: âˆ€
09:34:38 <jmcarthur_work> porges, #alt-stdlib if it interests you
09:34:39 <jpcooper> dcoutts, that's what I'd like to do
09:34:50 <psykotic> porges: is lambda mapped to your space bar for easy access? :)
09:35:09 <jpcooper> I'm trying to make a chat GUI where I have a notebook for the channels and I have a text entry and a text area for each channel
09:35:15 <jmcarthur_work> i like agda-mode's unicode entry
09:35:18 <porges> psykotic: well I don't actually use lambda, since there is no unicode substitute for \ in GHC atm :P
09:35:27 <sleepynate> hah
09:35:28 <dcoutts> jpcooper: loading a glade file constructs all the stuff just once, so each time you get a reference to a widget, it's the same one. You'd have to load it multiple times to get multiple instances
09:35:30 <psykotic> you can use emacs to prettify things
09:35:38 <jpcooper> oh bugger
09:35:41 <benmachine> I think forever should be :: m a -> m ()
09:35:47 <Joshc9> can someone tell me why my c++ code isn't compiling?????????????????????? it's bugging the shit outta me
09:35:49 <Berengal> Someone needs to make a haskell keymap...
09:35:52 <jpcooper> dcoutts, is there no cloning function in GTK+?
09:35:52 <psykotic> one thing emacs isn't great about is multi-character display substitutions
09:36:01 <psykotic> because of the interaction between display and buffer. not really usable.
09:36:09 <lilac> benmachine: i think it should be :: m a -> m Void
09:36:10 <porges> {-# LANGUAGE NoImplicitPrelude #-}
09:36:10 <porges> module Prelude where
09:36:14 <porges> nice :D
09:36:16 <Joshc9> anyone fluent in C++????
09:36:20 <psykotic> i think you'll need to implement it using some kind of 'shadow buffer' mirroring with substitutions
09:36:21 <saml> yes i am
09:36:23 <benmachine> lilac: equally good I suppose
09:36:28 <dcoutts> jpcooper: I don't think so, what would it do with signals etc
09:36:29 <Joshc9> saml you are fluent in c++
09:36:31 <Joshc9> ?
09:36:34 <saml> Joshc9, yes
09:36:45 <lilac> Joshc9: this is the wrong channel for that sort of inquiry, though
09:36:50 <Joshc9> awesome oculd you take a quick look at a code of mine if i sent it to you
09:36:54 <jpcooper> dcoutts, so how is this idiom carried out? How would design reusable parts, in Glade?
09:36:55 <Joshc9> idk where else to go
09:37:01 <saml> there's ##C++
09:37:01 <Joshc9> it's probably an easy error
09:37:07 <lilac> Joshc9: ##c++ if you wear dragonskin armour
09:37:14 <jmcarthur_work> porges, yeah, this is supposed to replace the use of base :)
09:37:16 <psykotic> ##c is worse
09:37:32 <Joshc9> so what should i do?
09:37:40 <sleepynate> ##proggit will both help and deride you, most likely :)
09:37:43 <psykotic> you have zhivago refusing to answer your question if you make a linguistic mistake of confusing 'object' with 'value' or 'variable' in the terminology of the c standard
09:37:43 <aefjt> Go to ##c++
09:37:44 <lilac> benmachine: m a -> m b has the disadvantage that you can accidentally use the result. m a -> m () makes that less likely, and m a -> m Void rules it out entirely
09:37:52 <psykotic> it's a pretty hilariously bad channel
09:37:56 <Joshc9> what's the link to it
09:38:01 <saml> ask in ##proggit
09:38:01 <sleepynate> um
09:38:11 <lilac> Joshc9: ime ##c++ is no better
09:38:13 <dcoutts> jpcooper: I would use the trick of sticking it in a top level window and just loading it each time I want a new instance. Reparenting is supposed to work.
09:38:20 <sleepynate> irc://##proggit :P
09:38:32 <psykotic> ##proggit has actual programming talk? news to me
09:38:33 <benmachine> lilac: yeah, that was what I was thinking... along a similar line of argument, do you think main should be forced to IO Void?
09:38:36 <porges> jmcarthur_work: one thing I'd like to see would be for tuples to be replace with HList (or a nicer version of HList)
09:38:42 <jpcooper> dcoutts, could you suggest how I'd add this new widget to a new tab?
09:38:50 <lilac> Joshc9: i once accidentally said c++99 isntead of c++98 and i still have burn marks on the left side of my body
09:38:52 <porges> they just aren't very nice ATM :P
09:38:54 <jpcooper> using notebookAppendPage won't work
09:38:54 <sleepynate> psykotic: it's hidden in the memes and insults :P
09:39:04 <maltem> how comes someone on IRC asks for the link to an IRC channel (on the same network)?
09:39:09 <jmcarthur_work> porges, i have little experience with HList, but maybe you could try to start a discussion in #alt-stdlib?
09:39:20 <porges> probably not the best time
09:39:24 <jmcarthur_work> i'd be interested in seeing what people think the pros and cons are
09:39:25 <porges> it's 4:40 am
09:39:27 <jmcarthur_work> ah
09:39:31 <jmcarthur_work> that's no good
09:39:39 <dcoutts> jpcooper: you mean how do you reparent from the window to the notebook tab?
09:39:44 <jpcooper> dcoutts, yes
09:39:53 <jmcarthur_work> the thing is, tuples are built in syntax, so it really makes a lot of sense to use them
09:39:58 <dcoutts> jpcooper: using widgetReparent
09:40:23 <jpcooper> dcoutts, but don't I first need to add a new page for it to have a parent?
09:40:29 <dcoutts> jpcooper: sure
09:40:38 <jpcooper> can I add empty pages?
09:40:47 <porges> jmcarthur_work: yup, but they just aren't very extensible... I'm going to be looking at this a bit more tomorrow
09:41:19 <jmcarthur_work> porges, sweet
09:41:22 <dcoutts> jpcooper: yup
09:41:25 <porges> dear Haskell: please have unary operators
09:41:30 <jpcooper> dcoutts, could you tell me how?
09:41:45 <dcoutts> jpcooper: a (v/h)box?
09:41:50 <lilac> porges: ghc does unary postfix operators now
09:41:55 <lilac> ish
09:42:01 <porges> you still have to bracket them
09:42:16 <Berengal> porges, if you can find a reasonable place for them in the grammar...
09:42:17 <jpcooper> dcoutts, so I have to create a new vbox which I'm not going to use, every time I append a page?
09:42:42 <dcoutts> jpcooper: if you want to use the reparenting trick
09:43:09 <porges> : limsup xs = â‹€ â‹ xs
09:43:12 <jpcooper> dcoutts, does it matter at all which empty thing I give to the append page?
09:43:13 <Berengal> I can live without unary operators if it means I get to keep an easy to read grammar
09:43:43 <dcoutts> jpcooper: I don't understand what you're asking
09:43:43 <porges> maybe we can special case characters with "N-ARY" in their unicode names
09:44:12 <Berengal> That means I'll have to memorize which characters have "N-ARY" in their unicode names
09:44:16 <jpcooper> dcoutts, this vbox which I'm never going to use. Does it have to be a vbox?
09:44:16 * quicksilver thinks functions are unary prefix operators
09:44:25 <dcoutts> jpcooper: no, any container will do
09:44:29 <jpcooper> okay
09:44:41 <jpcooper> so I suppose that it doesn't even matter if it's a button
09:44:44 <porges> â‹€â‹â‹ƒâ‹‚â¨€â¨â¨‚â¨ƒâ¨„â¨…â¨†â¨‰â«¿â…€âˆâˆâˆ‘
09:44:47 <porges> there you go :)
09:44:51 <dcoutts> jpcooper: right
09:44:56 <Berengal> I'd rather have every operator starting with ~ be unary prefix, and ending with ~ be unary postfix
09:45:03 <jpcooper> maybe I can reuse this dummy
09:45:14 <Berengal> And let ~ be unary negate
09:45:16 <jpcooper> it's not going to have a huge efficiency impact anyway. Thanks for the help
09:45:51 <dcoutts> jpcooper: reparenting is tricky for some reason (containers have to know about their children and vice-versa) so there's no simple way to remove a widget from a heirarchy, gtk just provides the "all in one" reparent.
09:45:56 <quicksilver> Berengal: usable prefix and postfix for consistency!
09:46:10 <quicksilver> Berengal: ~~5 == ~5~ == 5~~ == 5 !
09:46:54 <Berengal> ~5~4 == ??? == profit
09:47:17 <porges> xs >>= f = â‹ƒ f âˆ˜ xs -- bind for sets :>
09:49:50 <Berengal> porges, speaking of bind for sets, I'd rather have context synonyms/context families than unary operators
09:50:41 <porges> my "bind for sets" and your "bind for sets" line up pixel-for-pixel on my screen :D
09:51:47 <porges> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3634#a3639
09:52:51 <porges> that's my workaround so far
09:53:41 <jmcarthur_work> porges, aha! i was wondering what kind of advantages there might be in that type family approach
09:54:09 <Berengal> That seems to work nicely
09:54:28 <porges> (>>) is a bit hacky there because it should *really* be a part of Applicative (notice the Monad () f to force it to work)
09:56:08 <abbe> hi all. Is there any patch for haskell-mode for emacs, which replaces \ with lambda glyph and similar tokens with similar glyphs.
09:57:51 <porges> abbe: I believe so, I tried one once but I haven't  used emacs for a lonnng time
09:58:05 <M_o_C> abbe: http://mult.ifario.us/p/emacs-haskell-mode-unicode-cuteness
09:58:45 <M_o_C> (I don't use emacs but the vim counter module also refers to "haskell-unicode-cuteness".)
09:59:36 <abbe> thank M_o_C :)
09:59:40 <abbe> s/nk/nks/
10:00:29 * maltem doesn't really like replacing \ by a lambda. Why care about a symbol that doesn't mean anything anyways
10:01:24 <Blub\0> maltem: because it's always about the looks!
10:03:48 <maltem> Blub\0, ok, but, I'd rather care about pretty identifiers. if for example I were to hack up something that somewhere must keep track of some wavelength ...
10:04:48 <maltem> or thermodynamics, even
10:14:27 <leimy> I've got a function/action in a monad transformer that's a ReaderT combined with IO.
10:14:47 <leimy> but I've a function that computes a Maybe, and I wanted to use fmap with it inside this function to map Just vs Nothing etc.
10:14:59 <leimy> and the function being fmap'd does IO
10:15:25 <leimy> so far the only funtion I've come up with that works for me is a nasty combination of liftIO $ fromMaybe etc etc.
10:15:43 <leimy> it really looks pretty bad :-)
10:16:17 <leimy> any suggestions for that situation, where you feel you're fighting the type system?
10:17:14 <leimy> I mean, I realize I need to get in and out of Maybe
10:20:37 <lilac> benmachine: no, i don't think main should be :: IO Void. IO Void would/should be the type of IO computations which never finish. a main which terminates seems fine to me ;-)
10:21:34 <mauke> clearly main should be :: [String] -> [String] -> IO Int
10:22:24 <lilac> leimy: for clarity: you're in ReaderT r IO, you have v :: Maybe a, and f :: a -> IO b. you want, from that, a value :: ReaderT r IO (Maybe b) ?
10:23:08 <copumpkin> are "associated GADTs" possible?
10:23:11 <leimy> lilac: ReaderT ImmutableContext IO
10:23:40 <PeakerWork> leimy: convert to MaybeT for a short while in there?
10:23:40 <lilac> copumpkin: i don't see an immediate reason why not, try it! :)
10:23:48 <leimy> PeakerWork: run a new Reader?
10:24:00 <jmcarthur_work> copumpkin, i think i have done that
10:24:09 <leimy> PeakerWork: I figure it's probably easier to get in and out of maybe with fromMaybe or fromJust
10:24:33 <leimy> fromJust (blah `mplus` Just "Default") is the same as fromMaybe (Just Default) blah
10:24:36 <PeakerWork> leimy: not a new reader
10:24:38 <leimy> as far as I can tell :-)
10:24:40 <PeakerWork> can you paste the code?
10:24:48 <leimy> Unfortunately I can't :-)
10:25:00 <lilac> @type \f v -> liftIO $ Data.Traversable.sequence (f <$> v)
10:25:01 <lambdabot> forall (m :: * -> *) a a1 (t :: * -> *). (MonadIO m, Data.Traversable.Traversable t) => (a -> IO a1) -> t a -> m (t a1)
10:25:07 <leimy> it's for work, and I have a solution, it's just ugly! :-)
10:25:14 <lilac> leimy: Data.Traversable.sequence :: Maybe (IO a) -> IO (Maybe a) will help
10:26:20 <sleepynate> listen, i'm gonna let ya'll finish, but Reader was the best monad this year.
10:27:02 <jmcarthur_work> of ALL TIME
10:27:29 <copumpkin> jmcarthur_work: hmm, I don't think associated GADTs are possible
10:29:04 <maltem> @type \f v -> liftIO . f <$> v
10:29:05 <lambdabot> forall a (m :: * -> *) a1 (f :: * -> *). (MonadIO m, Functor f) => (a1 -> IO a) -> f a1 -> f (m a)
10:29:27 <maltem> crap, wrong way around
10:30:14 * benmachine ponders the relative merits for instance (Monoid m) => Monoid (Maybe m) of mempty = Nothing and mempty = Just mempty
10:30:18 <copumpkin> whoa
10:30:32 <copumpkin> associated GADTs cause some odd behavior in ghc ;)
10:30:43 <benmachine> they seem to both satisfy the laws, anyone know any interesting different between them?
10:31:05 <benmachine> *difference
10:31:26 <maltem> benmachine, mempty = Just mempty feels better
10:31:43 <jmcarthur_work> copumpkin, ???
10:31:44 <benmachine> maltem: it seemed more obvious to me, but...
10:31:50 <benmachine> > mempty :: Maybe [a]
10:31:50 <lambdabot>   Nothing
10:31:56 <copumpkin> jmcarthur_work: got a ghc crash that didn't involve the impossible happening :P
10:32:01 <maltem> benmachine, interesting
10:32:06 <copumpkin> jmcarthur_work: ghc says "fromJust: Nothing"
10:32:08 <copumpkin> :P
10:32:21 <jmcarthur_work> O_o
10:32:42 <jmcarthur_work> "fromJust: Nothing" == "ouch, don't do that please"
10:33:00 <copumpkin> [1 of 1] Compiling Main             ( AssocGADT.hs, interpreted )
10:33:00 <copumpkin> *** Exception: Maybe.fromJust: Nothing
10:33:18 <PeakerWork> benmachine: I think that isn't pretty, because it seems that you can't use that Monoid instance to create Nothings.. without external Nothings, the Monoid instance doesn't do anything beyond the internal Monoid instance
10:33:54 <Berengal> PeakerWork, depends on what Nothing does in +
10:33:59 <dons> can anyone think of a trick to get:  mdo fix everything
10:34:01 <dons> to type check?
10:34:06 <dons> or 'fix everything' for that matter
10:34:16 <jmcarthur_work> :t everything
10:34:17 <lambdabot> forall r a. (Data a) => (r -> r -> r) -> GenericQ r -> a -> r
10:34:21 <copumpkin> :o
10:34:45 <benmachine> PeakerWork: hmm, I suppose so
10:35:20 <benmachine> aww, I can't define a partial function in a class and the rest of the function in an instance :P
10:36:02 <copumpkin> jmcarthur_work: aha, http://hackage.haskell.org/trac/ghc/ticket/2417
10:37:37 <sshc> how are unicode charactors > 0xffff escaped with "\u" ?
10:37:57 <mauke> > length "\ufff"
10:37:58 <lambdabot>   <no location info>:
10:37:58 <lambdabot>      lexical error in string/character literal at chara...
10:38:20 <mauke> what's \u?
10:38:32 <porges> unicode
10:38:44 <mauke> where?
10:39:03 <porges> > length "\uffff"
10:39:04 <lambdabot>   <no location info>:
10:39:04 <lambdabot>      lexical error in string/character literal at chara...
10:39:14 <porges> > length "\u2018"
10:39:15 <lambdabot>   <no location info>:
10:39:15 <lambdabot>      lexical error in string/character literal at chara...
10:39:25 <sshc> > length "\u02345678"
10:39:26 <lambdabot>   <no location info>:
10:39:26 <lambdabot>      lexical error in string/character literal at chara...
10:39:35 <mauke> uh, stop please?
10:40:19 <porges> oh it's just \x
10:40:23 <porges> confused :P
10:40:31 <porges> > "\x2018"
10:40:32 <lambdabot>   "\8216"
10:40:50 <mauke> > length "\x12345"
10:40:50 <sshc> > "\x12345"
10:40:50 <lambdabot>   1
10:40:51 <lambdabot>   "\74565"
10:41:06 <sshc> > length "\x12345"
10:41:07 <lambdabot>   1
10:41:42 <sshc> thanks (\x)
10:42:00 <mauke> I never use \x in Haskell
10:42:07 <mauke> decimal escapes seem more useful
10:43:02 <Berengal> > text "\248\ \65"
10:43:03 <lambdabot>   Ã¸65
10:43:21 <porges> do you write Unicode references with decimal?
10:43:25 <mauke> yes
10:43:27 <porges> odd
10:43:29 <porges> :)
10:43:30 <tinLoaf> hum.. I/O actions are performed just when these are returned from main(), right? not when they are created?
10:43:34 <mauke> > text "\248\&65"
10:43:35 <lambdabot>   Ã¸65
10:43:46 <mauke> tinLoaf: yes
10:43:52 <Berengal> tinLoaf, only when they're sequenced in a sequence starting at main... ish
10:43:53 <tinLoaf> that's a pity :-/
10:44:25 <porges> consider: fmap :: (a -> b) -> f a -> f b, (generalized)zipWith :: (a -> b -> c) -> f a -> f b -> f c
10:44:27 <mauke> the only thing that's executed is the action bound to 'main'; if you want to execute something, you have to make it a part of that
10:44:41 <mauke> (not counting unsafePerformIO and friends)
10:44:43 <Berengal> tinLoaf, why is that bad?
10:44:47 <porges> and generalizedZipWith can implement applicative
10:44:59 <tinLoaf> Berengal: i have a list which i want to map over "lazyly"
10:45:21 <tinLoaf> and this seems not to work with mapM (most probably because it needs the complete list before sequencing it)
10:45:36 <mauke> right
10:46:19 <PeakerWork> mapM lazily sequences the list, but if the monad needs the entire sequence, that's not mapM's fault. At least that's IIUC
10:46:27 <tinLoaf> i read from a socket, split it up using "lines" and then i want to "give an answer" to each line, thus using "map answer $ lines readbuf"
10:46:57 <Berengal> That's a can of worms right there
10:47:05 <PeakerWork> tinLoaf: do you use a lazy I/O read from the socket?
10:47:19 <benmachine> tinLoaf: have a look at hGetContents?
10:47:41 <PeakerWork> that's a really weak spot in Haskell, IMO.  Iteratee is kind of sucky, and lazy I/O is really sucky
10:48:05 <tinLoaf> benmachine: i use Network.Socket, not Network, because i dont want the socket to be buffered
10:48:09 <Berengal> I'd use something like iteratee, or something custom combinator
10:48:11 <PeakerWork> yairchu (with a bit of my help) tried making a nicer Iteratee, but we stopped after a first attempt..
10:48:32 <PeakerWork> we have something that is nicer than iteratee in some ways, but doesn't guarantee some of the niceness Iteratee does
10:48:57 <tinLoaf> or can i have the handles from "Network" being line buffered for reads and packet buffered for writes?
10:49:16 <porges> re my earlier comment <http://comonad.com/reader/2008/zipping-and-unzipping-functors/> kmett has already done it :P
10:49:22 <tinLoaf> i think that the stuff i write to the network is not "correct" (i.e. not conforming to the RFC) because the buffer ist line-buffered
10:49:41 <mauke> wat
10:49:51 <mauke> what protocol is this?
10:49:55 <tinLoaf> RFC
10:49:56 <tinLoaf> err
10:49:57 <tinLoaf> IRC
10:50:08 <mauke> then buffering is irrelevant
10:50:14 <mauke> (modulo timing)
10:50:27 <benmachine> it's TCP
10:50:27 <tinLoaf> hum. i thoght that somehow the line endings would be messed up by haskell
10:50:33 <tinLoaf> because IRC needs \r\n
10:50:38 <mauke> no, it doesn't
10:50:46 <mauke> IRC needs \13\10
10:51:03 <tinLoaf> sorry. that's what \r\n spawns on my linux ;)
10:51:13 <Berengal> > "\r"
10:51:13 <lambdabot>   "\r"
10:51:19 <mauke> yes, but I don't think that's required by the standard
10:51:21 <Berengal> > ord '\r'
10:51:22 <lambdabot>   13
10:51:22 <benmachine> well, my IRC bot that I made with Network works fine
10:51:35 <Berengal> Everyone ignored the IRC RFCs anyway
10:51:38 <Berengal> ignores*
10:51:45 <benmachine> (most IRC servers are fairly generous anyway)
10:51:46 <tinLoaf> benmachine: do you have the code somewhere?
10:51:55 <mauke> I don't think haskell on linux ever touches your line endings
10:51:57 <tinLoaf> benmachine: i'd be interested in the I/O code..
10:52:08 <benmachine> tinLoaf: um, I haven't released it as such
10:52:14 <mauke> and on windows the socket shouldn't be in text mode
10:52:30 <benmachine> I could do but I'd have to read the BSD licence first :P
10:52:34 <tinLoaf> hrhr
10:52:45 <benmachine> or, something
10:53:11 <tinLoaf> well.. so i started learning functional programming, and i finally end up spending days doing stupid I/O stuff..
10:53:44 <benmachine> well, the I/O in my code is pretty boring
10:53:47 <burp> you shouldn't care about IO that much in the beginning ;)
10:53:48 <PeakerWork> why did Internet RFC's use the retarded newline?
10:53:53 <PeakerWork> and not \n ?
10:53:58 <mauke> \n is not a character
10:53:58 <Berengal> Encodings and stuff is stupid in any language
10:54:11 <benmachine> pretty much just connectTO and then hPutStr/hGetLine
10:54:14 <tinLoaf> burp: you can't code anything interesting without I/O ;)
10:54:16 <benmachine> *connectTo
10:54:19 <benmachine> hmm
10:54:25 * benmachine wonders what hGetLine would do on windows
10:54:30 <PeakerWork> mauke: well, it represents one
10:54:35 <benmachine> perhaps I should install ghc in wine
10:55:01 <mauke> PeakerWork: in any given context, yes. the problem is that \n is not defined enough
10:55:13 <PeakerWork> tinLoaf: sure you can, many interesting libraries on Hackage are without I/O
10:55:14 <benmachine> tinLoaf: you can code interesting functions to load in ghci
10:55:26 <lilac> hmm, what should i do with http://control.monad.st
10:55:28 <benmachine> or yeah, for other people to use with IO
10:55:37 <tinLoaf> yeah, but i like projects that compile and run ;)
10:55:42 <etpace> > Nothing `mappend` (Just 5)
10:55:43 <lambdabot>   Ambiguous type variable `a' in the constraints:
10:55:43 <lambdabot>    `GHC.Num.Num a' arising ...
10:55:53 <PeakerWork> mauke: does anyone treat it as anything but 10 ?
10:55:55 <mauke> my IRC bot is written in Haskell and it's completely IO based
10:56:03 <PeakerWork> > Nothing `mplus` Just 5
10:56:04 <lambdabot>   Just 5
10:56:09 <mauke> PeakerWork: yes, old MacOS has \n == 13
10:56:11 <etpace> aha thanks
10:56:28 <benmachine> fortunately, nobody has old MacOS
10:56:30 <PeakerWork> mauke: ah.  Well, why didn't internet RFC's specify 10 as the newline? Why 2 characters?
10:56:36 <mauke> PeakerWork: I have no idea
10:57:25 <PeakerWork> having 2-character newlines adds a lot of ugly corner cases that are unclear how to deal with
10:57:31 <dons> mauke: have you seen elliott's FRP-based irc bot?
10:57:34 <dons> all FRP based
10:57:35 <lilac> PeakerWork: it's so those people who type HTTP requests in on VT22s are OK
10:57:45 <benmachine> PeakerWork: does it?
10:57:52 <mauke> dons: no
10:58:00 <dons> i wonder if he released it.
10:58:04 <dons> elliottt: ??
10:58:07 <PeakerWork> benmachine: how do you deal with these characters appearing in reverse order? One without the other? etc
10:58:11 <jmcarthur_work> conal, ^^
10:58:15 <lilac> elliot iirc
10:58:22 <jmcarthur_work> elliott
10:58:31 <c_wraith> 2-character newlines made sense when output was done via line printers.  form feed and carriage return being two independent commands was good.
10:58:31 <dons> ttt
10:58:36 <benmachine> PeakerWork: how do you deal with them not appearing?
10:58:42 <c_wraith> Some protocols are just stuck back in the day. :)
10:58:42 <lilac> Connalll
10:58:46 <benmachine> sounds like the same problem to me
10:58:53 <mauke> preflex: seen elliottt
10:58:53 <preflex>  elliottt was last seen on #haskell 8 days, 21 hours, 8 minutes and 52 seconds ago, saying: i'm having some trouble installing a 6.11 snapshot, and i can't really understand the error i'm getting :)
10:58:56 <jmcarthur_work> is conal == elliottt (nicks)?
10:58:57 <dons> dcoutts_: http://hackage.haskell.org/package/QuickCheck-2.1.0.2
10:58:58 <PeakerWork> benmachine: well, that's one possible way to handle it
10:59:01 <c_wraith> err, line feed, not form feed
10:59:03 <dons> do we know if this is a legit upload of QuickCheck ?
10:59:20 <PeakerWork> benmachine: the problem is there are many ways, its an unnecessary choice for implementations, which can be a source for standards' deviations
11:00:09 <lilac> dons: (maybe you're not the right person but) it'd be lovely if hackage could show me diffs between versions of packages
11:00:19 <benmachine> PeakerWork: I suppose so, but I can't really see it being difficult to deal with in real situations
11:00:49 <benmachine> PeakerWork: in a sense the question of what to do with \n when expecting \r\n is the same question as what to do with \r when expecting \n
11:01:39 <PeakerWork> benmachine: My guess is that most implementations don't  just ignore them
11:01:53 <lilac> benmachine: if '\n' means 'go to start of next line' and '\r' means 'go to start of this line' then '\n', '\r\n' and '\n\r' all mean the same thing
11:02:10 <dons> lilac: yeah
11:02:48 <seanmcl> I'm an FFI newbie.  I need the finalizers (via ForeignPtr) to be run in a certain order.  E.g., I use A to create B on the C heap, and then need to run the B finalizer before the A finalizer.  Is there a way to do this?  I'm segfaulting when A is freed first.
11:02:57 <lilac> dons: also it'd be lovely to have an interactive haskell debugger with a live heap monitor and... another pony?
11:02:59 <benmachine> PeakerWork: yeah, but that's not to say they couldn't if they wanted to
11:03:15 <benmachine> um
11:03:19 <benmachine> to change the subject entirely
11:03:32 <Saizan> since the first pony was really an unicorn
11:03:40 <benmachine> are repeated calls to hGetChar likely to be similarly efficient to hGetLine?
11:03:48 <PeakerWork> seanmcl: My guess would be to encode these dependencies as references
11:03:51 <mauke> @src hGetLine
11:03:51 <lambdabot> Source not found. My pet ferret can type better than you!
11:03:56 <PeakerWork> seanmcl: (not an FFI expert myself)
11:04:23 <seanmcl> PeakerWork: I'm not sure what you mean.  How do I make B refer to A?
11:04:40 <lilac> data B = B A BPtr
11:05:09 <seanmcl> OK, I'll give it a shot.  Thanks!
11:05:11 <lilac> you'd prbably be better off having B's finalizer hold a reference to A
11:05:37 <benmachine> man, the System.IO source is complicated
11:05:47 <lilac> since in the above situation i could still imagine A being freed first
11:05:49 <benmachine> I suppose it probably depends on my buffering setting
11:06:00 <benmachine> hmm
11:06:09 <benmachine> it would be nice to have a buffer that
11:06:31 <benmachine> every time I read a character, it read as much input as it could and then returned the character, putting the rest in the buffer
11:06:51 <benmachine> rather than every time I read a character, it read exactly a line/number of bytes/nothing and waited until that was available
11:06:59 <benmachine> or maybe it already does this
11:07:03 * benmachine gets out an strace
11:07:10 <kyagrd> quick question about dealing with arrays when doing FFI stuff: what library should I use? Is carray package the ting to use?
11:07:20 <kyagrd> s/ting/thing/
11:07:32 <seanmcl> How can I have the finalizer hold the reference?  The only way I know to grab a finalize is, e.g, foreign import ccall "header.h &delete_A"
11:08:04 <PeakerWork> seanmcl: there's some "touch" or something I think, that doesn't do anything to a foreign-ptr except hold a reference to it
11:08:12 <PeakerWork> seanmcl: I haven't used it myself, so I don't remember
11:08:15 <PeakerWork> @src withForeignPtr
11:08:16 <lambdabot> Source not found. There are some things that I just don't know.
11:09:06 <seanmcl> PeakerWork: Thanks.  I'll try it out
11:09:27 <PeakerWork> seanmcl: http://www.haskell.org/ghc/docs/6.2.2/html/libraries/base/Foreign.ForeignPtr.html#v%3AtouchForeignPtr
11:09:34 <PeakerWork> seanmcl: and withForeignPtr too
11:10:27 <lilac> seanmcl: so your B finalizer would be 'finalizeB b >> touchForeignPtr a'
11:11:25 * lilac wonders if there's a risk of A getting finalized first if the finalizer is the other way around
11:11:46 <PeakerWork> lilac: you mean if its touch >> finalizeB ?
11:13:59 * benmachine wonders why his reading produces a select system call with a timeout of 134.217727 seconds
11:17:40 <lvillani> has anyone tried the DBus package yet? I can't even get the examples to compile...
11:18:58 <Berengal> Grrr....
11:19:47 <Berengal> Orphan instances are bad. How to solve? Simply don't export your type!
11:19:55 * Berengal wants Serializeable for UTCTime
11:20:08 <Lemmih> lvillani: Which DBus package?
11:20:35 <lvillani> Lemmih: http://hackage.haskell.org/package/DBus
11:23:00 <lvillani> oh, here's why: the darcs repository with the "demos" is from a very old version of HDBus
11:23:17 <Lemmih> lvillani: Import Control.OldException instead of Control.Exception.
11:23:36 <Lemmih> lvillani: Or use ghc-6.8. Exception handling changed in ghc-6.10.
11:24:04 <lvillani> uhm it complains about "Type constructor DBus.Message.Arg used as a class"
11:24:49 <ksf> someone stop me from creating top-level tvars.
11:24:52 <Lemmih> lvillani: Is this the repository you're using: http://darcs.haskell.org/~lemmih/hdbus/ ?
11:25:26 <lilac> > showHex 134217727 " -- benmachine, i guess that's why"
11:25:27 <lambdabot>   "7ffffff -- benmachine, i guess that's why"
11:25:56 <lvillani> Lemmih: nope, I was using the old one, I think (the one from the original author?)
11:26:26 <lvillani> I didn't find a reference to your darcs repository :)
11:26:42 <lilac> > 2^27 - 1
11:26:43 <lambdabot>   134217727
11:26:58 <lilac> seems rather arbitrary. maybe someone forgot an 'f'?
11:27:12 <Saizan> ksf: stop!
11:27:23 <ksf> but it's so easy!
11:27:39 <Saizan> the nasal demons will come for you!
11:27:44 <ksf> If I weren't supposed to, there'd be no unsafePerformIO!
11:27:55 <Saizan> that's only for ffi
11:27:58 <Lemmih> lvillani: Keep in mind that DBus is a horrible abomination and that the Haskell binding is no longer maintained.
11:27:58 <lilac> ksf: i hereby relicense ghc under the 'old ghc license with ksf exception' license which means you're no longer allowed top-level tvars on pain of copyright infringement
11:28:36 <lvillani> Lemmih: the C api is an abomination, that's why they suggest to use the GLib one
11:28:48 <ksf> does... does that mean I have to roll a Reader monad and do exactly the same, but hide it under the carpet?
11:29:17 * ksf has never used unsafePerformIO with the ffi
11:29:29 <Lemmih> lvillani: The core design is an abomination. There's pretty much no way of writing a high-level interface to DBus.
11:29:35 <lvillani> uhm...
11:29:59 <lilac> ksf: nah. just indent all your code a bit and put a 'myEntryPoint = <whatever> where' at the top
11:30:48 <ksf> and, tbh, why should I even care about using unsafePerformIO at the top level if sdl has a per-program instance?
11:31:07 <lvillani> Lemmih: well, QtDBus seems like an high level interface to me
11:31:22 <lvillani> I don't like the design either but It's used almost everywhere on Linux...
11:33:07 <Cale> Saizan: Hehe, that'd be a funny idea: GHC is BSD licensed, except for unsafePerformIO, which is GPL'ed and infects anything which uses it with a GPL license.
11:33:20 <lvillani> and I need it to query DeviceKit-power, unless I want to reimplement DeviceKit in Haskell...
11:33:40 <Cale> (Of course probably everything would be infected by now that way :/)
11:34:24 <lvillani> and this goes beyond what I expected to do as an Haskell newbie :)
11:41:39 * ksf haz kerning
11:50:48 <vininim> lol, this troll in l4-hurd is actually amusing.
11:50:55 <vininim> err.. wrong channel.
11:53:49 <sunrayser> I have a problem with haskell-src-exts: when I use parseFile, it returns an IO: parseFile "test_main.hs" :: IO (ParseResult Module) how can I parse a source file that returns a pure ParseResult?
11:57:37 * ksf thinks you shouldn't be using something like src-exts if you don't know that
11:57:41 <Saizan> parseFile reads the file from disk, that's why it's in IO
11:57:58 <Alpounet> parsing a file puts you in the IO monad. You can't get out of it and AFAIK you can only use either do-notation or explicit binds to operate on it with functions taking pure ParseResult s
11:58:35 <Saizan> you can use parseFileContents if you already have the content of the file as a String
11:58:48 <leimy> main puts you in IO :-)
11:59:20 <leimy> so you can "hGetContents" the file, then parse it pure as a big honkin string
11:59:29 <ksf> that's why pure programmers only code at the type level.
11:59:44 * leimy is a dirty dirty programmer
12:00:00 <ziman> if you have a function `f :: ParseResult -> a', then you can fmap f over the IO ParseResult to obtain `IO a'
12:00:24 <leimy> ziman: can't you use applicative there?
12:00:33 <leimy> to avoid fmap? :-)
12:00:48 <sunrayser> with parseFileContents, this is my best result: (readFile "test_main.hs") >>= (return . parseFileContents) but that's again returns IO
12:00:59 <leimy> I'm never sure when to use fmap vs liftM vs Applicative stuff :-)
12:01:01 <sunrayser> I actually need to get information from the parse tree
12:01:28 <Alpounet> leimy, why avoiding 'fmap' ?
12:01:30 <benmachine> leimy: well, all monads should also be functors, so liftM should be redundant
12:01:31 <ziman> yeah, possibilities are broooad, <$>, fmap, liftM, return+ap, pure+<*>, ... ;)
12:01:44 <leimy> Alpounet: no idea :-)
12:01:55 <leimy> benmachine: Yes, it "should" :-)
12:02:09 <leimy> I was thinking <$> is nice to look at over fmap
12:02:11 <leimy> but it might not be :-)
12:02:23 <benmachine> I do usually use <$> rather than fmap
12:02:24 <Saizan> leimy: class Functor f => Applicative f where
12:02:30 <ziman> me too ;)
12:02:34 <leimy> Saizan: right :-)
12:02:44 <Saizan> and "(<$>) = fmap" is the actual definition
12:03:00 <leimy> also, not all Functors have to be Applicative
12:03:06 <benmachine> indeed not
12:03:06 <leimy> so in some cases fmap is all you get :-)
12:03:17 <benmachine> in conclusion, fmap *everything*
12:03:19 <benmachine> always.
12:03:23 <leimy> ooh where's pointed in the hierarchy
12:03:30 <leimy> benmachine: that makes it a lot more general
12:03:43 <benmachine> leimy: I was told that pointed comes between functor and applicative
12:03:59 <leimy> I thought as much, but I'm not sure why Pointed is useful
12:04:04 <leimy> except as a bridging step
12:04:14 <leimy> like, if you can get to Pointed, Applicative isn't far :-)
12:04:39 <benmachine> yeah, hence Applicative includes pure
12:04:48 <benmachine> and Pointed is more or less optional
12:05:16 <benmachine> I did once wonder if you could get non-pointed applicatives, but I couldn't come up with a useful one
12:06:02 <conal> hm.  maybe Data.Map is a non-pointed applicative.
12:06:23 <conal> i.e., has <*> but not pure
12:06:26 <leimy> conal: clever!
12:06:27 <benmachine> maybe
12:07:15 <benmachine> would that be like, a map of keys -> functions <*> a map of keys -> values in domain = a map of keys -> values in codomain
12:07:17 <ziman> is there something that is pointed but does not have fmap?
12:07:19 <benmachine> or something
12:07:35 <benmachine> ziman: can't imagine so
12:07:58 <benmachine> pretty much every data structure has fmap
12:08:07 * Baughn pokes Set
12:08:09 <ziman> Data.Set does not
12:08:20 <conal> ben.  yeah.  like the ((->) key) applicative.  which is nice, since maps are like functions.
12:08:21 <mlesniak> join #darcs
12:08:29 <mlesniak> Well... :)
12:08:48 <ziman> or (-> e), i guess
12:08:59 <benmachine> why doesn't Set have functor? couldn't it just be fromList . fmap f . toList?
12:09:14 <ziman> elements of Set must belong to Ord
12:09:35 <benmachine> oh, I see what you mean
12:10:05 <benmachine> so Set couldn't be pointed either?
12:10:15 <ziman> it seems so...
12:10:45 <ziman> well, one definition of Pointed is class Pointed f where unit :: () -> f (), iirc
12:11:03 * shapr boings confusedly
12:11:08 <benmachine> oh
12:11:15 <benmachine> I had always seen it as a -> f a
12:12:30 <ziman> well, if you have fmap, you can write `pure x' in terms of those
12:13:03 <benmachine> how?
12:13:14 <benmachine> oh
12:13:14 <ziman> pure x = fmap (const x) (unit ())
12:13:18 <benmachine> I see what you mean
12:13:36 <benmachine> (is there any point in () -> f () as opposed to just f ()?)
12:13:53 <benmachine> (no pun intended)
12:14:08 <Berengal> class Pointed f where point :: f ()
12:14:10 <c_wraith> Not that I can see.
12:14:41 <ziman> i'd say it's a natural transformation from 1 to f
12:14:54 <c_wraith> any function that takes () as input seems like it could just be a constant.
12:15:14 <Berengal> c_wraith, it might be strict
12:15:32 <Berengal> But then again, the constant might not be entirely defined either
12:15:33 <ziman> well, i'd just say it's closer to CT stuff, i'm not sure much about the details :)
12:18:26 <ziman> i've just seen a non-usual Applicative definition where unit :: f (); distr :: f a -> f b -> f (a,b), IIRC, instead of common pure+ap
12:19:23 <Berengal> How do you get ap from that?
12:19:30 <c_wraith> You need fmap, still
12:19:33 <shapr> grussgott delYsid
12:19:35 <c_wraith> to get ap out of that.
12:19:44 <msteele___> I've got a fairly simple CHP test posted at http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9455#a9455. When I compile with "ghc --make Test.hs" it works fine, but when I compile with "ghc --make Test.hs -threaded" I get an error that reads "Thread terminated with: thread killed" at program exit. Am I doing something obviously wrong?
12:19:50 <Berengal> Ah, i see it now
12:19:57 <ziman> yes, I think the constraint was Functor f => Applicative f
12:20:28 <Berengal> ap a b = fmap ($) (distr a b)
12:20:44 <c_wraith> I think you need a curry in there
12:20:50 <Berengal> I was just about to say
12:20:59 <msteele___> At first I thought that I wasn't handling poisoning correctly, but now I've simplified things quite a bit and can't see what I may be missing.
12:21:12 <c_wraith> :t curry
12:21:16 <lambdabot> forall a b c. ((a, b) -> c) -> a -> b -> c
12:21:19 <Berengal> uncurry, actually
12:21:23 <c_wraith> yeah, that is uncurry
12:21:46 <c_wraith> Ah, I see why I get the names for those backwards in my head.
12:21:50 * benmachine finds that he almost never uses curry
12:22:10 <Berengal> I've never had any use for curry, except on food...
12:22:24 <c_wraith> I was thinking in terms of the operation it's performing on the args, rather than the operation it's performing on the function.
12:22:30 <c_wraith> And the former really makes no sense at all.
12:23:10 <c_wraith> Well.  I don't think I'll get those confused anymore :)
12:23:29 <Berengal> Well... in a way, (a, b) -> (a -> b -> c) -> c "curries" the arguments...
12:26:50 <ksf> msteele___, that's the console thread getting killed.
12:27:06 <ksf> there's a comment mentioning that message in the source.
12:27:58 <ksf> ...the thing thats "wrong" might be that the console adapter doesn't contain that exception.
12:28:35 <msteele___> ksf: Thanks.  I see that message.
12:28:57 <ksf> ...and the reason for you not getting the error with a non-threaded rts is that those threads don't block on input with a non-threaded rts.
12:33:55 <msteele___> ksf: It's good to know where the error is coming from
12:35:18 * ksf is wondering whether one could do tricks like writing EOF to one's own stdin to circumvent that.
12:36:28 <pastah> is there some way to rename typeclasses?
12:37:01 <pastah> e.g. IO a -> Contaminated a / FilthyFilthyDirty a
12:37:07 <ksf> you can do aliases, if you can live with UndecidableInstances
12:37:17 <pastah> cool :)
12:37:19 <ksf> IO isn't a type class.
12:37:31 <pastah> oh, type
12:37:33 <pastah> sorry
12:38:17 <ksf> newtype Filthy a = Filthy {unFilthy :: IO a} deriving (Monad)
12:38:36 <pastah> hehe
12:38:56 <ksf> have a look at mtl, stacking monads is a commonly used technique.
12:38:59 <benmachine> unFilthy doesn't make things less filthy, though :(
12:39:02 <pastah> that would be great for teaching the kidz how it works
12:39:13 <pastah> benmachine: bleach = unsafePerformIO
12:39:20 <benmachine> heh
12:40:30 <leimy> I have reader and writer stacked with IO
12:40:34 <leimy> quite handly
12:40:43 <leimy> and lets you completely isolate mutable from immutable state
12:40:46 <ksf> preflex, nickometer BfrOv3rfl0w
12:40:46 <preflex>  BfrOv3rfl0w is 99.4000% lame
12:41:02 <leimy> preflex, nickometer leimy
12:41:02 <preflex>  leimy is 0% lame
12:41:05 <leimy> woot!
12:41:13 <jmcarthur_work> preflex, nickometer jmcarthur
12:41:13 <preflex>  jmcarthur is 0% lame
12:41:26 <jmcarthur_work> preflex, nickometer geezusfreeek
12:41:27 <preflex>  geezusfreeek is 0% lame
12:41:38 <jmcarthur_work> sweetastic
12:41:42 <leimy> preflex, nickometer pwn3d
12:41:42 <preflex>  pwn3d is 31% lame
12:42:03 <Badger> preflex: nickometer 1
12:42:03 <preflex>  1 is 22% lame
12:42:05 <Badger> preflex: nickometer 12
12:42:05 <preflex>  12 is 27% lame
12:42:09 <Badger> preflex: nickometer 123456789
12:42:09 <preflex>  123456789 is 83% lame
12:42:14 <Badger> not enough!
12:42:17 <leimy> preflex, nickometer preflex
12:42:17 <preflex>  preflex is 0% lame
12:42:28 <Badger> preflex: nickometer 1a2b3c4d5e6f7g8h9i
12:42:28 <preflex>  1a2b3c4d5e6f7g8h9i is 99.986351% lame
12:42:33 <jmcarthur_work> preflex, nickometer sux0rz
12:42:33 <preflex>  sux0rz is 31% lame
12:42:55 <jmcarthur_work> preflex, nickometer sux0rz1337
12:42:55 <preflex>  sux0rz1337 is 96.32% lame
12:43:07 <Badger> preflex: nickometer 1a2b3c4d5e6f7g8h9i10j11k12l13m14n15o
12:43:08 <preflex>  1a2b3c4d5e6f7g8h9i10j11k12l13m14n15o is 99.989864% lame
12:43:13 <Badger> So close!
12:44:43 <leimy> you need to be less than one epsilon off :-)
12:45:15 <jmcarthur_work> preflex, nickometer 1337133713371337133713371337133713371337133713371337133713371337
12:45:15 <preflex>  1337133713371337133713371337133713371337133713371337133713371337 is 99.938763% lame
12:45:41 <jmcarthur_work> preflex, nickometer 1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t
12:45:42 <preflex>  1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t1l3e3e7t is 99.99176537% lame
12:45:57 <jmcarthur_work> i quit
12:46:11 <trzkril> preflex: nickometer -_]3h/'`H[;:={~,.<>
12:46:11 <preflex>  -_]3h/'`H[;:={~,.<> is 99.99247886% lame
12:46:31 <ksf> preflex, nickometer 123)(*&)%"?+|aoCUeoDAeCetkSAeCQz:
12:46:31 <preflex>  123)(*&)%"?+|aoCUeoDAeCetkSAeCQz: is 99.99277286% lame
12:46:33 <jmcarthur_work> preflex, nickometer _|_
12:46:33 <preflex>  _|_ is 97.05% lame
12:46:35 <c_wraith> preflex: nickometer preflex
12:46:36 <preflex>  preflex is 0% lame
12:46:36 <jmcarthur_work> :(
12:46:41 <c_wraith> just checking :)
12:47:05 <sinelaw> Hi, I'm home. Wait, what's going on here? Where's Mom?
12:47:14 <sinelaw> Put that preflex away.
12:47:48 <ikke> preflex: nickometer ninja
12:47:48 <preflex>  ninja is 0% lame
12:47:53 <ikke> preflex: nickometer lame_
12:47:53 <preflex>  lame_ is 69% lame
12:49:08 <Philonous> preflex: nickometer 100%_lame
12:49:09 <preflex>  100%_lame is 98.28% lame
12:50:18 <c_wraith> preflex: nickometer 98.28%_lame
12:50:19 <preflex>  98.28%_lame is 99.0664% lame
12:50:32 <jmcarthur_work> haha, fix nickometer
12:50:33 <c_wraith> I see.  reducing lameness increases lameness
12:50:54 <jmcarthur_work> preflex, nickometer 99.0664%_lame
12:50:54 <preflex>  99.0664%_lame is 99.4069% lame
12:51:10 <c_wraith> there must be a fixed point of this calculation somewhere!
12:51:21 <c_wraith> (not true at all, by the way)
12:51:36 <jmcarthur_work> if it converges to 100%_lame then it doesn't converge
12:51:47 <sinelaw> > fix nickometer
12:51:49 <lambdabot>   Not in scope: `nickometer'
12:51:58 <sinelaw> duh
12:54:23 <Philonous> It circles 99.4513% -> 99.6033% -> 99.6238% -> 99.4513%
12:55:18 <Twey> Ooh, a nickometer.
12:55:21 <Twey> preflex: nickometer Twey
12:55:21 <preflex>  Twey is 0% lame
12:55:24 <Twey> \o/
12:55:26 <Twey> preflex: nickometer Dude-X
12:55:27 <preflex>  Dude-X is 67% lame
12:55:42 <Philonous> preflex: nickometer \o/
12:55:42 <preflex>  \o/ is 14% lame
12:55:44 <benmachine> the nickometer tends to get quite large quite quickly
12:55:48 <benmachine> or
12:55:48 <benmachine> not
12:55:52 <Twey> Heh
13:02:39 <dschoepe> I have a list existentials like data Foo = forall a. SomeClass a => Foo a, some of which are Read and Show instances, but some aren't. What's the best way to store that in the list? As a method of SomeClass?
13:03:33 <dschoepe> *list of existentials
13:04:35 <opqdonut> how about data Foo = forall a. (SomeClass a,Read a) => Readable a | forall a. (SomeClass a,Show a) => Showable a
13:04:58 <opqdonut> or something to that effect
13:05:05 <dschoepe> opqdonut: good idea, thanks.
13:10:47 <ksf> ...googling for "total fit tex" gives me fitness training in texas
13:13:21 <djahandarie> preflex: nickometer djahandarie
13:13:22 <preflex>  djahandarie is 0% lame
13:13:30 <opqdonut> wow
13:13:39 <opqdonut> preflex: nickometer opqdonut
13:13:39 <preflex>  opqdonut is 0% lame
13:13:45 <opqdonut> huh? i recall being quite lame
13:13:49 <djahandarie> preflex: nickometer opqdonut
13:13:49 <preflex>  opqdonut is 0% lame
13:13:54 <opqdonut> preflex: nickometer 0pqdonu7
13:13:54 <preflex>  0pqdonu7 is 38% lame
13:14:00 <opqdonut> guess they changed the algorithm
13:15:13 <djahandarie> preflex: nickometer 1234
13:15:14 <preflex>  1234 is 52% lame
13:15:16 <djahandarie> preflex: nickometer 12344
13:15:16 <preflex>  12344 is 59% lame
13:15:19 <djahandarie> preflex: nickometer 123499999999
13:15:19 <preflex>  123499999999 is 91.90% lame
13:15:23 <Raevel> too interesting
13:15:30 <Raevel> preflex: nickometer Raevel
13:15:30 <preflex>  Raevel is 0% lame
13:15:32 <djahandarie> Probably should stop spamming the channel
13:15:32 <Raevel> sweet
13:15:33 <djahandarie> :P
13:15:34 <jfoutz> preflex: nickometer jfoutz
13:15:34 <preflex>  jfoutz is 0% lame
13:16:27 <Vulpyne> In 1234, which part is the non-lame 48%? :)
13:16:42 <jfoutz> 1 and most of 4
13:23:44 <Makoryu> preflex: nickometer Makoryu
13:23:45 <preflex>  Makoryu is 0% lame
13:23:50 <Makoryu> Awesome
13:24:16 <codeyman> preflex: nickometer codeyman
13:24:17 <preflex>  codeyman is 0% lame
13:24:19 <infrared> has anyone successfully built the hs-gtk2hs port on freebsd?
13:28:33 <ksf> http://defoe.sourceforge.net/folio/knuth-plass.html
13:28:38 <ksf> finally. I found it again.
13:35:53 <thoughtpolice> preflex: nickometer thoughtpolice
13:35:53 <preflex>  thoughtpolice is 0% lame
13:36:01 <thoughtpolice> preflex: nickometer poop
13:36:01 <preflex>  poop is 0% lame
13:36:04 <thoughtpolice> :>
13:41:13 <jmcarthur_work> conal, i've been bouncing in my seat to see your GPU work, fyi :)
13:44:03 <sinelaw> we had someone start a project for implementing distance-mapping (stereo vision) on a GPU but it never went anywhere
13:44:51 <sinelaw> conal, maybe with this it will be easier? if i understand correctly you're working on running a functional language on GPU?
13:45:52 <naren> hello
13:45:59 <conal> jmcarthur_work: :)  sry the the delays.  i'm staring to get the hang of iphone/objc programming.
13:46:38 <naren> How do you import a local module? I have two files A and B. A imports B, but compilation fails if I do ghc A.hs B.hs
13:46:48 <jmcarthur_work> iphone eh?
13:47:22 <conal> sinelaw: yes, i'm working on a haskell-embedded compiler that generates gpu code.  the code runs insanely fast.
13:47:41 <naren> anyone?
13:48:06 <ziman> naren, what does the error message say?
13:48:07 <sinelaw> cool
13:48:10 <Makoryu> naren: Tried ghc --make?
13:48:12 <thaldyron> naren: try ghc --make A.hs
13:48:29 <naren> it says it can't find B
13:48:42 * ClaudiusMaximus has a vague idea for forking electricsheep in haskell/gpu (thanks to mux for originally mentioning it in passing last month...)
13:48:44 <naren> can i import it with "import path_to_file"?
13:48:54 <Makoryu> naren: No.
13:48:55 <thaldyron> naren: I suppose A and B are in the same directory?
13:48:57 <Badger> ClaudiusMaximus: do it, do it!
13:48:58 <naren> yes
13:48:59 <Badger> :)
13:49:14 <sinelaw> conal, because they failed that approach someone else built the distance-mapper in VHDL on an FPGA. needless to say, it wasn't a walk in the park
13:49:38 <conal> sinelaw: distance-mapper ?
13:50:00 <sinelaw> mapping a pair of stereo frames into a distance image
13:50:10 <conal> oh
13:50:37 <sinelaw> i think it does ~30 fps of PAL
13:50:39 <thaldyron> naren: do you have the line "module B where" in B.hs?
13:51:00 <sinelaw> i wonder if the GPU can handle that rate
13:51:24 <conal> btw, there's neat work going on at york on fast fpga execution of pure lazy functional programs.
13:51:38 <sinelaw> reduceron?
13:51:43 <conal> sinelaw: yeah
13:51:44 <naren> yes
13:51:52 <naren> thaldyron: yes
13:52:02 <sinelaw> yeah, saw that. would be nice to buy a reduceron laptop one day :)
13:52:25 <Makoryu> naren: And does A.hs say "import B"?
13:52:38 <sinelaw> i think the advantage there stems mainly from the harvard architecture, right?
13:52:40 <naren> Makoryu: it says import qualified B as Q
13:52:49 <Makoryu> naren: Okay, that works too
13:52:56 <conal> sinelaw: i don't know
13:53:03 <Makoryu> naren: So type: ghc --make A.hs
13:53:49 <ClaudiusMaximus> Badger: progress so far (note: written in C because i know OpenGL/C better than HOpenGL)  http://claudiusmaximus.goto10.org/cm/2009-08-28_fl4m6e_proof_of_concept.html
13:53:51 <naren> Makoryu: figured it out....the module name for A did not match the filenmame
13:53:53 <naren> thanks
13:54:00 <sinelaw> from what i understood in their presentations, they can concurrently reduce different parts efficiently because they have many small memory modules, each one near another are of FPGA elementary blocks
13:54:05 <sinelaw> *area
13:54:11 <sinelaw> so it's a little like working with a GPU
13:54:24 <Makoryu> naren: Ah, yeah. The module name should be either the filename or Main
13:56:08 <sinelaw> i shouldn't have said Harvard, just that there are many small memory modules with a dedicated bus for each
14:04:46 <maxstahl> Hi everybody!
14:05:12 <benmachine> hi
14:07:14 <ksf> the important bit about skillfull procastination is admiring something you've already done.
14:07:25 <maxstahl> does anyone know how big of an array is too big to be futzing about with? I have a function I wanna memoize for values 1..4e7, and I'm getting either stack overflows or pitiful performance and tons of memory taken up. Tried arrays and maps and neither is sparse or lazy enough I think to do it quickly.
14:08:33 <ksf> > 4*10^7
14:08:34 <lambdabot>   40000000
14:08:46 <sinelaw> you can also admire things you're about to do
14:08:52 <ksf> > 4*10^7 * 4 / 1024 / 1024
14:08:53 <lambdabot>   152.587890625
14:09:13 <ksf> that's megabytes, ain't it?
14:09:17 <Makoryu> Yeeeuuuup.
14:09:28 <ksf> ...and 4 bytes is quite a low estimate.
14:09:30 <Makoryu> (Bonjjeeeoooooorno.)
14:09:49 <Makoryu> ksf: Yeah, if it's boxed data or Doubles, it'll go up pretty fast.
14:09:51 <maxstahl> I don't think any of these values should be exceeding 32bit, probably less if I can get away with it.
14:10:00 <maxstahl> They're ints.
14:10:09 <Makoryu> maxstahl: Unboxed ints?
14:10:25 <maxstahl> I think...? Just Ints.
14:10:26 <ksf> ...reduced to normal form?
14:10:59 <ksf> you know, haskell is perfectly happy to memorize gazillions of computations that once forced will give you an int.
14:11:04 <maxstahl> I'm memoizing, so the only real requirement is that it always evaluate in order.
14:11:26 <maxstahl> Normal form, eh?
14:11:49 <ksf> well, (1 + 1) takes up more space than 2.
14:12:11 <maxstahl> ahhhhhhh right.
14:13:10 <maxstahl> mapping the function to a list and having it reference into that list works but once I bump the problem up to full size it falters and takes up a lot of memory. Could it be that unevaluated thunks are just piling up?
14:13:58 <ksf> if you access the list sparsely, that's likely.
14:14:09 <maxstahl> I worked out that it was (!!) that was blowing out the stack, but is there a structure like a map or something that can be sparse?
14:14:28 <ksf> Data.Map
14:14:43 <ksf> or IntMap
14:14:46 <maxstahl> Oki! I was just looking at that. Is there a way to construct one lazily?
14:14:53 <ksf> or bytestring-trie, depends on your key type.
14:15:15 <maxstahl> The keys are Integers, the values can be Ints.
14:15:18 <ksf> last i've heard it's quite lazy.
14:15:42 <ksf> ...in that it doesn't automagically force the values you insert.
14:16:22 <maxstahl> hmm really? When I tried just doing fromList in my memoization I think it was evaluating the entire list in the process.
14:16:40 <svendt> Doing some homework on GADT here ... I'm supposed to construct a stack, with basic ops (push/pop). And maybe im misunderstanding the assignment, but is there some way to, via this GADT type show, to include logic, so that if you pop the last element of a list, you get an empty list back (and thus, can't pop more from it?). the code im working on is here http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3642#a3642. Any way to make Pop go from "Stack
14:17:15 <ksf> ...well, afair it doesn't expect the keys to be in order.
14:17:30 <ksf> ...which means that it has to force the end of the list to give you a lookup failure.
14:17:55 <svendt> The posted code allows "rubbish" such as "Pop $ Pop $ Push 1 Base". Any way to remedy?
14:18:28 <ksf> svendt, you can save the stack depth in its type.
14:18:38 <ksf> ...just as you can do with lists.
14:18:49 <ksf> that's type level programming, though.
14:19:09 <arw_> svendt: the signature of Pop is wrong for that, it can never return Stack a Empty
14:19:15 <ksf> doesn't seem to be a usual homework requirement.
14:19:18 <sioraiocht> I have a datatype F a x, but it is a functor for (F a)
14:19:55 <ksf> sioraiocht, you can do data F x a and have a functor for (F Foo)
14:19:58 <svendt> arw_: I know, but I'm just not sure how to "fix it".
14:20:19 <sioraiocht> ksf: right, but when  is (F a) as a functor for another type class
14:20:33 <sioraiocht> it seems to try to unify that "a" with another type variable in the type class
14:20:44 <arw_> svendt: well, if you want to change only a little from your code you can do something like 'data Flag = Empty | NotEmpty'
14:20:51 <sioraiocht> when really I want any a for (F a) to be acceptable
14:21:01 <sioraiocht> is there a way to express this? am I being too vague?
14:21:05 <arw_> svendt: and write Pop :: Stack a Flag -> Stack a Flag
14:21:18 <ksf> you can't write a functor instace for F a when you have F a x
14:21:49 <sioraiocht> ksf: I have instance Functor (F a) where and that is fine..
14:22:00 <sioraiocht> I think I used an extension
14:22:07 <arw_> svendt: but there are nicer solutions.
14:22:12 <ksf> the Functor class expects a * -> * kind, and there's no way to get F a out of F a x. you can only do F x
14:22:56 <ksf> ...that last F x does'nt express what I wanted to explain.
14:23:02 <svendt> arw_: wouldn't that still allow me to construct the value "Pop $ Pop $ Push 1 Base" ?`
14:23:21 <ksf> put into other terms: there's no equivalent of "flip" on the type level.
14:23:45 <sioraiocht> hrm, I thnk I am not explaining myself right, heh
14:23:50 <arw_> svendt: it would.
14:23:55 <maxstahl> ksf: here's both versions of my functions: https://gist.github.com/c53f28c5fa99868c713b .
14:23:58 <ksf> (well, there might be, with type families. would have to try that)
14:25:49 <ksf> well, if you're not having spare indices, Map won't give you any advantages.
14:26:05 <maxstahl> They won't all be evaluated simultaneously though is I guess why I wanted something sparse.
14:26:14 <svendt> arw_: any way to prevent that then?
14:26:29 <maxstahl> ksf: See, with the map version of that function even small values take a very long time to evaluate.
14:26:33 <ksf> you should also be fine if you don't hold onto the beginning of the list as you access latter values.
14:27:08 <maxstahl> I think it's impossible to know when earlier values in the list aren't needed anymore....
14:27:14 <ksf> could it be that fromList overwrites keys?
14:27:33 <maxstahl> maybe?
14:27:37 <ksf> ...if it's right-biased, then that'd explain stuff.
14:27:52 <ksf> maxstahl, the garbage collector knows.
14:28:14 <ksf> wait.
14:28:18 <maxstahl> ksf: oh right. But if the entire list or map has a name then it'll remember the earlier values anyway.
14:29:01 <ksf> you're holding on to !! in the recursion and thus to the whole of the list.
14:29:16 <maxstahl> yeah.
14:29:42 <maxstahl> Since I'm only looking for values of this function that return a certain value, maybe I could filter that and then only get back the ones that returned 25?
14:30:09 <arw_> svendt: http://en.wikibooks.org/wiki/Haskell/GADT <- the safe-list example here is almost what you want.
14:31:14 * ksf thinks you should'nt be generating that much data and memoizing, in the first place.
14:31:30 <maxstahl> : ( I know but I'm out of ideas over here.
14:31:45 <ksf> looks like one of those tricky-dynamic-programming euler problems to me.
14:31:55 <maxstahl> it totally is.
14:32:12 <maxstahl> If I could write a totient function that doesn't take for damn ever in Ruby I'd totally go that route instead.
14:33:19 <svendt> arw_: cheers, will give it a read :)
14:34:15 <maxstahl> ksf: one thing of course that gives me pause about it is that you're only looking for prime number totient chains, so maybe there's some property about them (besides totient(p) being p - 1).
14:34:47 <maxstahl> I can compute all those prime numbers up to 40,000,000 super-quick using a prime wheel.
14:35:10 <ksf> sinelaw, the problem with admiring things that I'm about to do is that I'm getting to perfectionistic and starting to design beauty bottom-up.
14:35:26 <ksf> ...and that has undecidable termination properties.
14:35:51 <ksf> there's even a package for prime wheels.
14:36:03 <pikhq> maxstahl: ... "Calculate"? I just define what the list of primes is and let the computer figure it out for me.
14:36:06 <pikhq> :)
14:36:08 <sinelaw> ksf, wasn't procrastination the ultimate goal?
14:36:26 <maxstahl> yeah I straight up stole that from the haskellwiki, and the package I've got is faaaaaaaast.
14:36:26 <ksf> nah, it's the ultimate skill of productivity.
14:36:50 <ksf> by managing procrastination, you give your brain the freedom to figure out what to do next without you interfering.
14:37:15 <sinelaw> not if your brain is busy googling random words
14:37:34 <ksf> ...that's why it's important to admire what you've done.
14:39:38 <ksf> how long do those chains get?
14:39:55 <ksf> ...you only need to have one in memory at a time, anyway.
14:41:08 <anavarro> Hi there
14:41:11 <ksf> and /me bets that the prime chains are the first ones to have different followup numbers.
14:41:51 <ksf> ...that is, 5 and 7 have 4 and 6 as successor, if there can't be any other predecessors to 2 that 4 and 6, that's all prime chains with a length of 4.
14:42:16 <maxstahl> ksf: I'm looking for ones of length 25 and the chain lengths, in general, seem to increase with the value of the number.
14:45:37 <maxstahl> ksf: I think since this is just an ill-advised approach there's probably some kind of pattern I'm missing that would reduce the solution space.
14:46:19 <deech> Anyone here using the haskell-mode in emacs notice that tab completion in the Haskell buffer doesn't work?
14:46:49 <sioraiocht> deech: never was supposed to, afaik
14:46:58 <ksf> don't ever use emacs tty emulation.
14:47:06 <deech> sioraiocht: oh
14:47:09 <ksf> in fact, just don't use emacs and you're fine.
14:47:12 <maxstahl> don't ever use emacs ;P
14:47:25 * cygnus gasps
14:47:32 * sioraiocht uses emacs
14:47:33 <wchogg> Do not anger Lord Emacs
14:47:37 * sioraiocht uses it all the time EVERYWHERE
14:48:05 <sioraiocht> Arnar: Ertu Ãslendingur?
14:48:43 <maxstahl> oh crap I didn't mean to start a whole thing in here....
14:48:46 <ksf> the ip looks swedish.
14:49:03 <sioraiocht> ksf: yeah, but the name is Icelandic
14:49:17 <sioraiocht> indeed, according to his chalmers page, he is from Iceland
14:50:59 <deech> ok, what's a good development environment for haskell? By good I mean one which finds functions in modules so I don't have to go hunting around Hayoo.
14:51:03 <pronik> does anyone here use HAT?
14:51:18 <gwern> so google names their new language 'noop'
14:51:22 <pronik> I'm trying to compile some code using it, but it looks for some weird includes which are not there
14:51:38 <ksf> pronik, use ghc --make
14:51:50 <gwern> you would think, of every single one of the millions of companies in the world, google would be the *one* company that would understand, deep down in its core, to PICK A NAME THAT CAN BE GOOGLED
14:52:00 <gwern> pronik: far as I know, hat is bitrotten
14:52:10 <pronik> ksf: to compile the code? I'm trying to build some tracing into it using hat
14:52:14 * pronik is a noob
14:52:33 <pronik> i.e. trying to do "hmake -hat Main"
14:52:46 <ksf> ah. no idea.
14:52:58 <pronik> but this requires some includes in /usr/include/hat-2.0.5 dir for every external library
14:53:04 <ksf> most of the times people get linker errors is because they call ghc without --make.
14:53:17 <pronik> ah, a typical FAQ ;)
14:55:07 <Lemmih> pronik: Hat is not all that easy to use. It tends to be faster to pipe your code through #haskell.
14:57:54 <sereven> deech: not an emacs user, but there's probably some sort of ctags hasktags integration, so at least you can navigate the stuff you have installed.
14:58:26 <dancor> @faq Can haskell ruin you if you aren't a mathematical genius?
14:58:26 <lambdabot> The answer is: Yes! Haskell can do that.
14:59:04 <sereven> @faq Can haskell make you a mathematical genius if you get confused shopping for groceries?
14:59:04 <lambdabot> The answer is: Yes! Haskell can do that.
14:59:49 <pronik> Lemmih: would be difficult in this case, it's not quite my code, only something I'm debugging for a kick :)
15:00:31 <pronik> What I would really appreciate is some tool that would write every evaluation ghc is doing while actually running the program
15:00:57 <pronik> I thought HAT is the closest you get, but maybe there are other solutions?
15:03:53 <Lemmih> pronik: Not really, sorry.
15:03:56 <Saizan> you could try the ghci debugger maybe
15:06:04 <maxstahl> just did a test computing the chain lengths for the first 10,000 primes both with and without memoization and it was a little over three times slower with memoization, so I'm giving up on that approach. Thanks for the help I've learned some stuff I think I can use elsewhere.
15:07:37 <maxstahl> I think I just need to figure out which numbers are likely to have a totient length that large and just search around that region.
15:09:10 <gwern> > tail []
15:09:11 <lambdabot>   * Exception: Prelude.tail: empty list
15:10:02 <gwern> @check \x -> if length x > 0 then drop 1 x == tail x else True
15:10:03 <lambdabot>   "OK, passed 500 tests."
15:10:47 <c_wraith> I really suspect it passed [] in to all 500 of those checks
15:11:31 <camio> c_wraith: why's that?
15:11:34 <gwern> doubt it
15:11:43 <gwern> qc doesn't repeat, or at least tries not to
15:11:55 <camio> cwraith: because the type isn't explicit?
15:12:01 <c_wraith> Well, it depends on the Arbitrary instance for []
15:12:16 <c_wraith> I suppose it might actually create cons cells
15:12:22 <gwern> 'aaand... Monads presented by a cute and very smart young girl.' http://www.youtube.com/watch?v=9fohXBj2UEI <-- well, compared to the usual girls in any tech field, she is pretty cute
15:13:13 <kyagrd> This may be an FFI FAQ but how do I convert between CDouble Double?
15:13:42 <gwern> > 0.2 :: CDouble
15:13:43 <lambdabot>   Not in scope: type constructor or class `CDouble'
15:13:47 <gwern> bah
15:14:17 <kyagrd> @type realToFrac
15:14:18 <lambdabot> forall a b. (Real a, Fractional b) => a -> b
15:15:21 <kyagrd> > realToFrac (2.0 :: CDouble) :: Double
15:15:22 <lambdabot>   Not in scope: type constructor or class `CDouble'
15:15:43 <kyagrd> ah anyway this seem to work but ... I thought there must have been a library function :(
15:17:14 <kyagrd> Has anyone defiend and uploaded to hackage a library of the QuickCheck Arbitrary instances for CDouble and all those C types?
15:21:08 <maxstahl> Heyyyyyyyy so I did a little bit more research over here and the totient chain length rises roughly logarithmically. So maybe I can reduce the size of this problem.
15:30:21 <dancor> @check \ x -> x == []
15:30:22 <lambdabot>   "Falsifiable, after 2 tests:\n[(),()]\n"
15:31:18 <dancor> @check \ x -> length (nub x) == 1
15:31:19 <lambdabot>   "Falsifiable, after 0 tests:\n[]\n"
15:31:26 <dancor> @check \ x -> length (nub x) < 2
15:31:27 <lambdabot>   "OK, passed 500 tests."
15:31:58 <kyagrd> Defaulting to () sucks for QuickCheck
15:32:05 <kyagrd> especially for Ord instances
15:32:48 <dancor> @check \ (x :: [Int]) -> sum x < 100000
15:32:49 <lambdabot>   Parse error in pattern at "->" (column 16)
15:33:01 <dancor> @check \ x -> sum (x :: [Int]) < 100000
15:33:01 <lambdabot>   "OK, passed 500 tests."
15:33:07 <Axman6> :o
15:33:18 <Axman6> that's not so good...
15:34:18 <dancor> ya.  also i think ScopedTypeVariables would be really good here.
15:35:02 <dancor> @check \ x -> product (x :: [Int]) < 100000
15:35:03 <lambdabot>   "Falsifiable, after 38 tests:\n[17,-5,19,-3,-15,-16]\n"
15:35:21 <Axman6> > product [17,-5,19,-3,-15,-16]
15:35:22 <lambdabot>   1162800
15:35:31 <dancor> are you checking check :)
15:35:41 <dancor> @check yoself
15:35:42 <lambdabot>   Not in scope: `yoself'
15:36:41 <camio> How valuable would a bunch of quickcheck cases on quickcheck be?
15:36:56 <dancor> but i don't know if it's really reasonable for the [Int] generator to make something with sum over 100k in the first 500 tests.
15:43:19 <surgeon> hi all, I try to compile a program where I import something from the graphics module: import Graphics.HGL main = putStrLn "test". when I try to compile with ghc test.hs -o test I get an error message, while running with ghci is fine
15:44:04 <camio> surgeon: use ghc --make.
15:44:05 <surgeon> which is: test.o: In function `sxI_info':
15:44:06 <surgeon> (.text+0x1c3): undefined reference to `__stginit_HGLzm3zi2zi0zi0_GraphicsziHGL_'
15:44:13 <surgeon> camio: ah thx :///
15:44:29 <camio> surgeon: np. I've made that mistake a few times myself.
15:45:08 <surgeon> anyway, whoever gave me the tip with "The Haskell School of Expression", thanks! it just rocks
15:45:48 <kyagrd> Oh shit, CDouble and Double has different behavior on some calculations
15:46:26 <kyagrd> Can get away with some given tolerance bounds :(
15:46:52 <kyagrd> matrix multiplication for CDouble fied and Double field does not satisfy == relation
15:47:08 <kyagrd> (modulo realToFrac)
15:47:27 <aavogt> > maxBound :: CDouble
15:47:28 <lambdabot>   Not in scope: type constructor or class `CDouble'
15:47:36 <aavogt> > maxBound :: Foreign.CDouble
15:47:37 <lambdabot>   Not in scope: type constructor or class `Foreign.CDouble'
15:47:44 <kyagrd> , maxBound
15:47:46 <lunabot>  ()
15:47:50 <kyagrd> , maxBound :: CDouble
15:47:51 <lunabot>  luna: Not in scope: type constructor or class `CDouble'
15:47:59 <kyagrd> luna doesn't have it either
15:48:46 <altmattr> greeting from Haiku, it is 1996 again in my virtual machine
15:49:13 <c_wraith> how's the haskell support on haiku? :)
15:49:44 <altmattr> so far nill, Haiku is posix compatible in the same way windows is, so it will take some doing I guess
15:49:55 <altmattr> :)
15:50:03 <altmattr> still, nostalgia is fun
15:50:16 <altmattr> but... back to work!
15:50:23 <copumpkin> it'd be neat to extend the with* pattern to be generic, with an existential to prevent escapage
15:50:26 * altmattr gets back to important things and apologises for the distraction
15:56:24 <aconbere> I'm writing my first cabal file
15:56:35 <dcoutts> yay!
15:56:36 <aconbere> and when running cabal install I'm getting an error about Char not being found
15:56:42 <aconbere> (I know a cause for celebration)
15:56:45 <dcoutts> :-)
15:57:02 <aconbere> I've included base in the build-requires section
15:57:12 <aconbere> but I'm not really solid on how that works
15:57:20 <dcoutts> aconbere: Char is in the haskell98 package, not base
15:57:28 * aconbere nods
15:57:30 <dcoutts> aconbere: we normally use Data.Char now
15:57:33 <aconbere> ah
15:57:58 <dcoutts> aconbere: notice how the message ghc gave you mentioned the haskell98 package
15:58:06 <dcoutts> http://haskell.org/cabal/FAQ.html#hidden-packages-a
16:00:09 <aconbere> dcoutts: yep, that makes more sense now
16:00:28 <dcoutts> great
16:02:53 <kyagrd> Oh, it was not becase of the difference between CDouble and Double
16:03:14 <kyagrd> associativity does not hold for floating points :(
16:03:25 <kyagrd> @check \ x y z -> (x*y)*z ::Double == x*(y*z)
16:03:25 <lambdabot>   Parse error at "==" (column 29)
16:03:33 <kyagrd> @check \ x y z -> ((x*y)*z ::Double) == x*(y*z)
16:03:34 <lambdabot>   "Falsifiable, after 2 tests:\n1.2\n-4.4\n-0.6666666666666667\n"
16:03:47 <copumpkin> yep
16:03:58 <copumpkin> pretty much all you get with FP is commutativity
16:04:03 <copumpkin> on the main operations
16:11:12 <aconbere> dcoutts: thanks, cabal install is working wonderfully now
16:11:24 <dcoutts> great
16:16:04 <mrsolo> so are $ and . the prefer style than ( ) ?
16:16:09 <kmc> @check \x y -> (x :: Double) * y == y*x
16:16:10 <lambdabot>   "OK, passed 500 tests."
16:16:16 <kmc> mrsolo, depends what you're doing
16:16:34 <mrsolo> i assume hardly any performance impact of using those....
16:16:37 <kmc> none
16:16:46 <kmc> at least with a decent compiler
16:17:51 <mrsolo> do you know of any style guildline?
16:20:13 <kmc> personally i prefer f $ g $ h x
16:20:46 <bos> @seen dons
16:20:46 <lambdabot> Unknown command, try @list
16:20:53 <kmc> the exception being, if h takes two args that are complicated expressions, and are symmetric somehow, i'll write f $ g $ h (complicated arg 1) (complicated arg 2) rather than special-casing the last
16:20:53 <bos> whuh?
16:21:08 <bos> @seen dcoutts
16:21:08 <lambdabot> Unknown command, try @list
16:21:11 <bos> @list
16:21:12 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
16:21:16 <dcoutts> @yarr!
16:21:17 <lambdabot> Arrr!
16:21:32 <dcoutts> bos: hia
16:21:33 <kmc> @nixon
16:21:33 <lambdabot> Any change is resisted because bureaucrats have a vested interest in the chaos in which they exist.
16:21:41 <bos> hey dcoutts, do you ever get into food fights with the inliner?
16:21:49 <dcoutts> bos: :-)
16:21:50 <mrsolo> kmc: oic
16:22:02 <sereven> mrsolo: I find this style very nice/usable, but I'm no pro. http://github.com/tibbe/haskell-style-guide
16:22:09 <bos> dcoutts: the compiler is stubbornly refusing to DWIM, and i'm at a loss
16:22:20 <dcoutts> bos: what are the details?
16:22:27 <Peaker> kmc: in that case sure, but I think generally f . g . h $ x  is better -- because its easier to take any subset of that pipeline out to a different function, or eliminate the x arg altogether
16:22:44 <dcoutts> bos: yes, when doing bytestring and binary I did have to look at quite a bit of core output
16:22:58 <kmc> yeah that's fair
16:23:07 <sereven> @hackage hlint
16:23:07 <lambdabot> http://hackage.haskell.org/package/hlint
16:23:10 <kmc> tbh i hadn't though of doing that until i'd written a lot of code using ($)
16:23:20 <bos> dcoutts: yeah
16:23:25 <kmc> often though there are intermediate small args to f and g
16:23:32 <kmc> is it still more readable then? don't know
16:23:47 <Peaker> dcoutts: don't you feel that defeats some of the purposes of high-level programming?
16:23:50 <sereven> mrsolo: you might like some of the recommendations from hlint ^ but it goes a little overboard on points free sometimes
16:23:53 <kyagrd> Another crazyness of floating point cacluation and more crazy solution to that: optimization gives you correctness for the code not correct before optimization http://www.haskell.org/pipermail/glasgow-haskell-users/2004-August/006955.html
16:24:11 <dcoutts> Peaker: it's not high level programming, and the ability to do high and low level in the same language I think is a great advantage.
16:24:22 <Saizan> kmc: like "filter p . map g . iterate h"?
16:24:29 <bos> dcoutts: so this is what goes wrong:
16:24:29 <bos> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9460#a9460
16:24:35 <kmc> yeah
16:24:41 <kmc> guess that's fine
16:24:54 <bos> dcoutts: my manually-inlined function gets completely inlined, but the other one is always called out of line
16:25:04 <bos> and the fully inlined code is about 2x faster in a tight loop.
16:25:04 <Peaker> dcoutts: yeah.. I'm not well versed in the lower side of Haskell yet..
16:25:12 <mrsolo> thanks folks!
16:25:31 <bos> the fully inlined code is silly-fast.
16:25:52 <Peaker> @type \w f -> takeWhile w . iterate f
16:25:53 <lambdabot> forall a. (a -> Bool) -> (a -> a) -> a -> [a]
16:26:05 <bos> dcoutts: i know the ghc manual says it won't inline an inlined function into another inlined function, but that's exactly what i want it to do here...
16:26:26 <Peaker> why not inline recursively?
16:26:26 * bos is baffled.
16:26:31 <bos> Peaker: code blow-up
16:26:45 <Peaker> bos: not unless its only called once
16:26:54 <Peaker> also, why 1-level of inlining is good and 2 isn't? Its quite arbitrary
16:26:56 <bos> Peaker: i'm just citing the reason given in the manual.
16:27:08 <Peaker> shouldn't it be a function of how large the function is, more than how deep it is inlined?
16:27:52 <bos> there are various ways it could be more sophisticated. i'm just wondering if there's anything i can do based on how it currently behaves.
16:28:58 <dcoutts> bos: why do you want uniform2 to be inlined?
16:29:16 <bos> dcoutts: because inlining it makes the code calling it go 3x faster.
16:29:48 <dcoutts> bos: what is a Gen ?
16:30:00 <bos> dcoutts: it's a UArr from uvector
16:30:11 <bos> hidden via newtype
16:30:18 <dcoutts> ok, so data, not a newtype
16:30:20 <dcoutts> erm
16:30:23 <dcoutts> not a function
16:30:44 <bos> right. it's the state of the PRNG.
16:31:46 <dcoutts> bos: so basically the whole thing boils down to a dozen memory reads, writes and a bit of arithmetic
16:31:52 <bos> dcoutts: yep.
16:32:04 <bos> dcoutts: and the jmp/ret pair seems to add a lot of overhead.
16:32:06 <bos> not surprisingly.
16:32:08 <dcoutts> bos: so the only benefit of inlining is eliminating call overhead
16:32:17 <bos> dcoutts: correct.
16:32:46 <bos> code at http://darcs.serpentine.com/statistics in case it's useful
16:33:04 <bos> but when that jmp/ret costs 3x in performance, that makes me pay some attention.
16:33:16 <dcoutts> bos: so inline means that it keeps the function in its original form, basically it completely defers optimising it
16:33:18 <bos> i've got a version of the code that will fill out a UArr instead.
16:33:21 <bos> dcoutts: correct.
16:33:36 <dcoutts> bos: which is why inline into an inlined thing makes little sense
16:33:52 <c_wraith> @src reverse
16:33:52 <lambdabot> reverse = foldl (flip (:)) []
16:34:03 <dcoutts> bos: so at the call site, which function is being called out of line?
16:34:16 <dcoutts> uniform, uniform2 or wordsTo64Bit ?
16:34:28 <bos> dcoutts: uniform2
16:35:06 <dcoutts> bos: but uniform3 does get inlined?
16:35:23 <bos> dcoutts: yep
16:36:10 <kmc> @pl \m x f -> fromMaybe (return ()) (M.lookup m x >>= return . f)
16:36:10 <lambdabot> ((fromMaybe (return ()) .) .) . flip flip (return .) . (((.) . (>>=)) .) . M.lookup
16:36:34 <bos> dcoutts: i can see that wordsTo64Bit gets inlined into the out-of-line specialised use of uniform2
16:36:45 <kmc> is there a version of pl that will simplify without going all out?
16:37:08 <dcoutts> bos: so it should end up the same size as uniform3
16:37:37 <bos> dcoutts: yes, and the compiler is nevertheless stubbornly leaving it out of line.
16:38:21 <benmachine> @pl \m x f -> fromMaybe (return ()) (fmap f $ M.lookup m x)
16:38:21 <lambdabot> (((fromMaybe (return ()) .) . flip fmap) .) . M.lookup
16:38:51 <benmachine> kmc: what I find useful is omitting some of the parameters to partially-pl
16:38:53 <benmachine> like
16:38:59 <benmachine> @pl \m x -> fromMaybe (return ()) (fmap f $ M.lookup m x)
16:38:59 <lambdabot> ((fromMaybe (return ()) . fmap f) .) . M.lookup
16:39:12 <benmachine> @pl \x -> fromMaybe (return ()) (fmap f $ M.lookup m x)
16:39:12 <lambdabot> fromMaybe (return ()) . fmap f . M.lookup m
16:39:21 <kmc> aha, it does free vars
16:39:22 <kmc> thanks
16:40:11 <kmc> @pl fromMaybe $ return ()
16:40:12 <lambdabot> fromMaybe (return ())
16:40:16 <kmc> seems like that should have a name
16:40:33 <kmc> :t (`mplus` return ())
16:40:34 <lambdabot> forall (m :: * -> *). (MonadPlus m) => m () -> m ()
16:40:45 <Makoryu> :t fromMaybe $ return ()
16:40:45 <lambdabot> forall (m :: * -> *). (Monad m) => Maybe (m ()) -> m ()
16:41:13 <Saizan> ?type fromMaybe (return ())
16:41:14 <lambdabot> forall (m :: * -> *). (Monad m) => Maybe (m ()) -> m ()
16:41:26 <Saizan> heh
16:41:35 <benmachine> so the thing you're trying to @pl won't even typecheck unless m is a map from keys to ()s
16:41:44 <benmachine> er, m ()s
16:42:08 <benmachine> :t \m x f -> fromMaybe (return ()) (fmap f $ M.lookup m x)
16:42:09 <lambdabot> forall (m :: * -> *) a k. (Monad m, Ord k) => k -> M.Map k a -> (a -> m ()) -> m ()
16:42:21 <benmachine> oh no I am wrong
16:42:27 <benmachine> because of the fmap
16:42:49 <kmc> actually, what i want is some unholy mix of "when" and pattern guards
16:43:19 <kmc> when (Just v <- M.lookup k m) $ f v
16:43:24 <kmc> but this requires things be first class that aren't
16:45:48 <benmachine> :t \m x f -> maybe (return ()) (fmap f) (M.lookup m x)
16:45:48 <lambdabot> forall (m :: * -> *) a k. (Monad m, Functor m, Ord k) => k -> M.Map k (m a) -> (a -> ()) -> m ()
16:46:01 <benmachine> :t \m x f -> maybe (return ()) (liftM f) (M.lookup m x)
16:46:01 <lambdabot> forall (m :: * -> *) a1 k. (Monad m, Ord k) => k -> M.Map k (m a1) -> (a1 -> ()) -> m ()
16:46:16 <benmachine> hmm
16:46:25 <benmachine> not the same!
16:51:20 <blackh> Is there some standard library func that's equivalent to foldr (.) id?  I can't think what it might be.
16:51:30 <aavogt> blackh: mconcat
16:51:57 <aavogt> > mconat [(+1),(*2)] 1
16:51:57 <lambdabot>   Not in scope: `mconat'
16:52:03 <aavogt> > mconcat [(+1),(*2)] 1
16:52:04 <lambdabot>   Ambiguous type variable `a' in the constraints:
16:52:04 <lambdabot>    `GHC.Num.Num a' arising ...
16:52:38 <blackh> aavogt: Dear Sir, I write this letter to give my sincere thanks for your assistance and I wish good health to you and your family, Yours Sincerely Stephen Blackheath esq.
16:53:27 <Saizan> > (appEndo . mconcat . map Endo) [(+1),(*2)] 1
16:53:28 <lambdabot>   3
16:54:06 <aavogt> > mconcat [fmap (+1),fmap (*2)] (Just 1)
16:54:07 <lambdabot>   Ambiguous type variable `a' in the constraints:
16:54:07 <lambdabot>    `GHC.Num.Num a' arising ...
16:54:27 <kmc> @type mconcat
16:54:28 <lambdabot> forall a. (Monoid a) => [a] -> a
16:54:43 <kmc> endofunctions are a monoid?
16:54:52 <Saizan> ?type Endo
16:54:52 <lambdabot> forall a. (a -> a) -> Endo a
16:54:55 <Saizan> sure
16:55:09 <kmc> but you need a wrapper :/
16:55:34 <Saizan> yeah, the naked instance for (->) is Monoid b => Monoid (a -> b)
16:56:11 <Saizan> i.e. using return/liftM2 for the ((->) a) monad to lift the operations
16:56:55 <Saizan> > mconcat [return . (+1),return . (*2)] (Just 1)
16:56:56 <lambdabot>   No instance for (Data.Monoid.Monoid (m (Data.Maybe.Maybe t)))
16:56:56 <lambdabot>    arising fr...
16:57:26 <Saizan> > mconcat [return . (+1),return . (*2)] 1 :: Maybe Int
16:57:26 <lambdabot>   No instance for (Data.Monoid.Monoid GHC.Types.Int)
16:57:27 <lambdabot>    arising from a use of...
16:57:42 <Saizan> ah, Maybe it's like that too
16:57:48 <Saizan> > mconcat [return . (+1),return . (*2)] 1 :: [Int]
16:57:49 <lambdabot>   [2,2]
16:58:47 <deech> How involved is to roll your own syntax like the 'do ...' for monads?
16:59:19 <ivanm> deech: I'm not sure if you can, really
16:59:27 <ivanm> not without having some kind of preprocessor or TH hackery
16:59:47 <Saizan> you can by hacking ghc
16:59:55 <Saizan> or using TH's quasiquotation
17:00:00 <ivanm> Saizan: true, but it isn't very portable then ;-)
17:00:10 <ivanm> (the "hacking GHC" solution)
17:00:42 <Saizan> there's always the augustss' option :)
17:00:52 <deech> I was confused because I was reading the source for Control.Monad and I didn't see any mention of the 'do ...' syntax. Same thing for Control.Arrow
17:01:05 <deech> Saizan: huh?
17:01:13 <ivanm> Saizan: oh? what's that?
17:01:21 <ivanm> overloading (+), etc. again? :p
17:01:35 <ivanm> deech: do notation is inbuilt syntactic sugar
17:01:40 <Saizan> deech: the notations are not defined in haskell itself, they are implemented directly in the compiler
17:02:49 <deech> Saizan: oh, so no go.
17:03:01 <Saizan> ivanm: http://augustss.blogspot.com/2009/02/regression-they-say-that-as-you-get.html
17:03:27 <ivanm> Saizan: yeah, that's what I was thinking of
17:03:41 <ivanm> that uses overloaded Nums and monads or something, doesn't it?
17:03:50 <Saizan> deech: there's a fairly recent feature called quasiquoting, which is a part of TemplateHaskell, that let you define your own syntax
17:04:17 <Saizan> ivanm: yeah, i don't know the details though
17:04:17 <ivanm> though isn't TH hard to get into and understand?
17:04:26 <Saizan> not really
17:04:32 <deech> cool thanks!
17:05:04 <Saizan> the AST is somewhat big, but you can always just ask ghci to print it for the kind of expressions you'd like to construct
17:05:36 <Saizan> and haskell-src-meta is handy
17:15:18 <kmc> afaik quasiquoting is kind of all-or-nothing, you can't just add an extra bit of syntax to haskell
17:15:24 <kmc> it's intended for quoting other languages entirely
17:16:09 <kmc> so you'd have to redo a lot of work or hook into an existing haskell parser
17:16:18 <Saizan> yeah, there's that
17:16:27 <kmc> in some cases you might want to custom-preprocess your source, possibly into TH code
17:16:38 <kmc> anyway i think this would be a good area for improvement
17:16:48 <kmc> it's a lot harder than in the world of s-expressions :)
17:16:54 <Saizan> well, it's really the same work you'd have to do to write a preprocessor
17:17:38 <kmc> well, my quasiquoter for Haskell + my weird extension has to return a Q Exp, hence parse haskell entirely
17:17:53 <kmc> whereas you can sometimes get by with quite dumb preprocessors that pass through large parts of the language
17:18:11 <kmc> quasiquoter + hook into GHC parser would be a decent solution
17:18:41 <kmc> btw not too relevant but i love the way haskell's layout rule is specified
17:19:00 <Saizan> haskell-src-exts is a quite reliable stand-alone parser
17:19:06 <kmc> layout is totally optional and there's a mechanical way to recover a whitespace-independent program with explicit delimiters
17:19:16 <kmc> i haven't used it much, i'll take a look
17:20:28 <kmc> okay so haskell-src-meta is what you want for writing haskell syntax extensions
17:33:12 <BMeph> Are functions defined (ab)using the Reader Monad faster-performing, or just quicker to write? :)
17:35:49 <c_wraith> fewer arguments.
17:36:40 <blackh> aavogt: Get this - mconcat is not equivalent to foldr (.) id
17:37:27 <blackh> aavogt: It uses the monoidness of the return value.  So it'll work if I make the things I'm mconcatting into monnoids.
17:37:28 <c_wraith> If you determine a value at some high level, and want to use it at some low level, it's really convenient to not have to pass it down a call chain.
17:39:45 <blackh> aavogt: Actually it won't work, because it's mconcatting the output of the function as applied to the same input.  So it's different.
17:39:54 <blackh> I have learnt something.
17:45:35 <Saizan> blackh: have you seen my "appEndo . mconcat . map Endo"?
17:46:12 <blackh> blackh: No - point me at it and I'll study it.
17:46:18 <Voltanator> Hi, All. I have an STM question. Any takers?
17:46:44 <Saizan> > (appEndo . mconcat . map Endo) [(+1),(*2)] 1
17:46:45 <lambdabot>   3
17:46:59 <Voltanator> Are there any methodological reasons why atomic has type "STM a -> IO a", and not "STM a -> a".
17:47:04 <Voltanator> ??
17:47:06 <Saizan> blackh: see Data.Monoid for the Monoid (Endo a) instance
17:47:24 <blackh> Saizan: Thanks - I will!
17:48:14 <Saizan> Voltanator: because it does have the side effect of reading/writing the TVars
17:48:26 <Saizan> and they aren't encapsulated like in ST
17:48:41 <Saizan> since the whole point is to interact with other threads
17:51:32 <arw_> Voltanator: if i had to guess, i would say atomicity is a side-effect because ordering is important there, and therefore its IO.
17:51:46 <arw_> Voltanator: but i don't really have a clue about STM, so its just a guess.
18:22:18 <Voltanator> Thanks Saizan! Sorry for the long delay.
18:57:37 <aconbere> I feel like I have lots of functions that look a bit like this in my code
18:57:43 <aconbere> split :: EditBuffer -> (String,String)
18:57:44 <aconbere> split buffer = splitAt (absPosition buffer) (contents buffer)
18:58:22 <aconbere> so I have some data type, and some functions that modify it
18:58:55 <aconbere> and I feel like there should be a cleaner way to represent that
18:59:16 <aconbere> (this is a pretty simple example, but sometimes these things get more gnarled)
18:59:54 <aavogt> @pl \buffer -> splitAt (absPosition buffer) (contents buffer)
18:59:54 <lambdabot> liftM2 splitAt absPosition contents
19:00:41 <aavogt> aconbere: perhaps (contents buffer) should be a zipper instead of a string?
19:01:31 <aavogt> ie. stored in a split form, with the begining half reversed
19:01:43 <jfoutz> is there a better way to do this? like without traversing the lists twice?
19:01:45 <jfoutz> > (\ls -> let len = maximum (map length ls); pad l = take len $ l ++ repeat ' ' in map pad ls) ["a","abcd","d"]
19:01:46 <lambdabot>   ["a   ","abcd","d   "]
19:02:34 <aavogt> jfoutz: is that operation really taking that much time?
19:02:38 <aconbere> aavogt: almost certainly :)
19:02:48 <aconbere> aavogt: but I started the backwards way before
19:02:49 <jfoutz> aavogt: no, i'm just curious.
19:03:02 <aconbere> where I had a fancy buffer data object, and I got bogged down in implimentation
19:03:07 <aconbere> now I'm trying the other direction
19:03:20 <aconbere> I'm using a dumb buffer, and defining and interface
19:03:27 <aconbere> and then going back and making it smarter
19:03:34 <aconbere> (perhaps this is a time to make is smarter)
19:04:04 <aavogt> @hackage statistics-fusion
19:04:04 <lambdabot> http://hackage.haskell.org/package/statistics-fusion
19:04:11 <jfoutz> it seems like i could transform the lists to continuations, but i can't figure out how to get the continuations to coordinate how many more characters to return in a clean way.
19:05:37 <ivanm> aavogt: isn't that dead?
19:05:56 <ivanm> I thought dons officially said that bos' statistics package was the successor...
19:06:15 <bos> ivanm: it is
19:06:38 <copumpkin> it says so right on that page
19:06:58 <aavogt> yes, but it is a simple example of writing all function in terms of folds, which gets the optimizer to merge them into one loop.
19:07:27 * copumpkin is proud of his fold in that library!
19:07:43 <aavogt> but maybe that is in specific cases that can't translate into that pad function.
19:07:46 <aavogt> I don't know
19:08:02 <andresCanavesi> @version
19:08:02 <lambdabot> lambdabot 4.2.2.1
19:08:02 <lambdabot> darcs get http://code.haskell.org/lambdabot
19:08:23 <Gracenotes> copumpkin succeeded in many folds, such as filter, map.. uh.. zip, even?
19:10:01 <Gracenotes> true story though
19:10:18 <aavogt> @quote unfold
19:10:18 <lambdabot> No quotes match. I am sorry.
19:14:56 <aconbere> aavogt: are you aware of a gap buffer library for Haskell?
19:21:12 <jfoutz> those are really nice folds
19:21:34 <jonh> why thank you
19:22:03 <aavogt> aconbere: I don't know of anything in particular. Maybe yi or something else on hackage has some nice buffer representation?
19:22:42 <jfoutz> i think yi goes with a zipper
19:32:47 <dm2> ghc packages are driving me crazy
19:33:05 <dm2> Trying to install iteratee, and keep getting conflicts between transformers and mtl
19:45:23 <forgot> is it just me.. or is it that when you use spaces instead of tabs you have to press backspace eight times to unindent something instead of once?
19:45:36 <copumpkin> nope
19:45:37 <impl> only if your editor sucks
19:45:43 <copumpkin> I mean, it is just you
19:46:25 <|Steve|> :t assoc
19:46:25 <ivanm> I don't know... I use tab for indenting, not spaces...
19:46:26 <lambdabot> Not in scope: `assoc'
19:46:32 <forgot> how do you configure your editor so that you don't have to press space or backspace eight times?
19:46:34 <bos> hmm, uvector's IO code is on crack.
19:46:46 <copumpkin> bos: yeah :P
19:46:57 <ivanm> forgot: depends on your editor
19:47:13 <copumpkin> bos: trying to serialize a UArr to disk?
19:47:13 <ivanm> bos: have you found its supplier? ;-)
19:47:32 <bos> copumpkin: trying to read from /dev/urandom
19:48:03 <copumpkin> bos: ah, yeah, I'm not a fan of the UIO class... it's very specific to a certain scenario
19:48:21 <bos> yes, i.e. almost completely useless :-\
19:48:59 <copumpkin> I have a Binary instance in my version of it, but it's not fully tested yet, so I haven't sent dons the patches
19:52:04 <|Steve|> I guess assoc is supposed to be the map (x,(y,z)) |-> ((x,y),z).
19:52:28 <copumpkin> bos: you're welcome to my code, if it helps
19:52:36 <copumpkin> but that may be more yak shaving for you :)
19:52:58 <bos> copumpkin: i'm afraid it would be, but thanks
19:56:33 <wwkeyboard> Does anyone know what cpuTimePrecision is limited by? It keeps telling me the best precision I can get is 10ms.
19:56:41 <wwkeyboard> And I don't buy that...
19:57:09 <copumpkin> check its source?
19:58:21 <wwkeyboard> I'm not sure where to start, I'm new here..
19:59:11 <Orclev> how would one go about doing something like runErrorT . runReaderT?... I'm trying to modify some code that was originally runErrorT (runReaderT ev env), and I figured I'd eliminate the arguments... but apparently (.) can't be used in this fashion
19:59:50 <Saizan> \ev -> runErrorT . runReaderT ev
19:59:55 <Saizan> ?pl \ev -> runErrorT . runReaderT ev
19:59:55 <lambdabot> (runErrorT .) . runReaderT
20:01:10 <Orclev> ah, that works, thanks
20:01:27 <Orclev> now to figure out WHY that works...
20:04:53 <|Steve|> \x -> f . g x  <==> \x -> (.) f (g x) <==> \x -> (f .) (g x) <==> \x -> ((f .) . g) x <==> (f .) . g, if that's what you were asking.
20:05:41 <sereven> :t (?f .) . ?g
20:05:42 <lambdabot> forall b c a a1. (?g::a1 -> a -> b, ?f::b -> c) => a1 -> a -> c
20:05:50 <sereven> :t ?f . ?g
20:05:51 <lambdabot> forall b c a. (?g::a -> b, ?f::b -> c) => a -> c
20:06:11 <sereven> says g should gobble params twice
20:06:27 <|Steve|> What does ?f mean?
20:06:46 <SamB_XP_> |Steve|: it's a feature that's basically only useful with :t
20:06:56 <SamB_XP_> it's for "implicit parameters" or somesuch
20:07:03 <sereven> implicit parameter, just a convenient way to have ghci or lambdabot show function types separately
20:07:07 <SamB_XP_> a lame-ass version of dynamic parameters
20:07:17 <SamB_XP_> er. dynamic binding
20:07:20 <|Steve|> Ah, okay.
20:07:46 <sereven> say you're building something up in ghci and don't have details of a function yet, but know the overall structure, it's a nice way to quickly find out what you're looking for
20:07:59 <aavogt> SamB_XP_: where can I find unlame implicit parameters? Do they exist?
20:08:12 * aavogt only knows implicit params
20:08:28 <Saizan> edwardk's reflect?
20:08:32 <tommd> Who here is coming to HacPDX?
20:08:37 <SamB_XP_> aavogt: well, I'm thinking the closest sane thing is a reader monad ...
20:09:29 <copumpkin> the reflection package is pretty cool
20:09:35 <aavogt> so everywhere else they have dynamic binding, you run into the same problems as implicit params
20:10:08 <Orclev> ok, so the issue was that I was trying to use (b -> c) -> (a -> b) against (c -> d) -> (a -> b -> c)... or something like that
20:10:09 <SamB_XP_> aavogt: not all of them
20:10:35 <Saizan> Orclev: yeah
20:10:43 <SamB_XP_> anyway, I'm off to bed now
20:10:46 <SamB_XP_> so bye guys!
20:10:55 <Orclev> ok, thanks for the help and explanation everyone
20:10:58 <aavogt> good night
20:11:26 <c_wraith> tommd: when is hackPDX?  I'm local.  I might make it.
20:11:41 <|Steve|> @pl \x -> f x >>= g
20:11:41 <lambdabot> (g =<<) . f
20:12:35 <copumpkin> :t \f g x -> f x >>= g
20:12:36 <c_wraith> err.  Hac
20:12:36 <lambdabot> forall t (m :: * -> *) a b. (Monad m) => (t -> m a) -> (a -> m b) -> t -> m b
20:12:43 <copumpkin> :t (>=>)
20:12:43 <lambdabot> forall a (m :: * -> *) b c. (Monad m) => (a -> m b) -> (b -> m c) -> a -> m c
20:12:57 <copumpkin> |Steve|:
20:13:20 <|Steve|> copumpkin: Same function or just same type?
20:13:30 <copumpkin> |Steve|: you tell me ;)
20:13:38 <copumpkin> |Steve|: how many functions of that type exist?
20:13:51 <copumpkin> (useful functions, that is)
20:14:08 <|Steve|> Beats me.
20:14:28 <|Steve|> But certainly more than 1 exists. =)
20:15:12 <copumpkin> well think about it, you have two functions (a -> m b), and (b -> m c)
20:15:17 <copumpkin> and all you have after that is a
20:15:24 <copumpkin> what is the only thing you can do with it?
20:15:55 <Saizan> copumpkin: you could run one or both any number of times before returning the 'c' result
20:16:02 <copumpkin> true :)
20:16:13 <copumpkin> actually
20:16:17 <copumpkin> how?
20:17:14 <Saizan> ?type \f g a -> let m = f a in replicateM 10 m >> m >>= g
20:17:15 <lambdabot> forall t (m :: * -> *) a b. (Monad m) => (t -> m a) -> (a -> m b) -> t -> m b
20:17:29 <copumpkin> oh :)
20:17:48 <centrinia> Those 10 replications of m are useless. :|
20:17:58 <copumpkin> centrinia: their effects will still be "felt"
20:18:04 <|Steve|> Why are they useless?
20:18:12 <centrinia> Nevermind. :p
20:18:17 <copumpkin> > (\f g a -> let m = f a in replicateM 10 m >> m >>= g) (+) (+) 4 5
20:18:18 <lambdabot>   14
20:18:31 <copumpkin> > (>=>) (+) (+) 4 5
20:18:33 <lambdabot>   14
20:18:46 <Gracenotes> cute emoticon too
20:19:12 <copumpkin> zomg! :P
20:19:13 <copumpkin> QED ;)
20:19:15 <centrinia> :t (>=>)
20:19:17 <lambdabot> forall a (m :: * -> *) b c. (Monad m) => (a -> m b) -> (b -> m c) -> a -> m c
20:19:49 <Gracenotes> so, I am watching Go at the moment. very good cinematography
20:19:49 <Orclev> hmm... is there a version of (.) that could somehow work on functions taking arbitrary number of arguments? Something like (b -> c) -> (a -> ... -> b) -> (a -> c)
20:20:02 <Gracenotes> at least, not sleep-inducing
20:20:41 <tommd> c_wraith: Portland State University
20:20:45 <c_wraith> Gracenotes:  I love the way that movie was assembled, too.  (The way the various storylines all link together)
20:20:50 <c_wraith> tommd: when?
20:21:02 <Gracenotes> good to know :) I'm just 8:48 in
20:21:03 <tommd> c_wraith: 4th and Hawthorne
20:21:04 <Saizan> Orclev: you can write one with some typeclass hackery, but i'm not sure how pleasant to use it'd be
20:21:07 <copumpkin> Orclev: it'd be hard, but probably possible
20:21:12 <tommd> c_wraith: 25,26,27 of Sept.
20:21:13 <Gracenotes> girl is visiting the master drug dealer. or something.
20:22:04 <|Steve|> Orclev: It's not clear to me how that would work, exactly.
20:22:07 <Saizan> oleg has a deepFmap afterall, this would be an instance of that
20:22:16 <c_wraith> tommd: probably not going to make it to that.  I have tickets to a football game in the middle.
20:22:19 * copumpkin tries to use his Function type family
20:22:26 <tommd> c_wraith: As you wish
20:22:40 <tommd> cwraith: No harm in making it for just a day if you want.
20:22:41 <copumpkin> Orclev: you'd need to replicate all those arguments in the output value too though
20:23:01 <copumpkin> Orclev: the fully general version would allow the output of the second function to be an n-tuple :P
20:23:09 <Orclev> copumpkin: hmm... true...
20:23:56 <Orclev> I guess it would have a final output of (a -> ... -> c), where of course ... would be an arbitrary number of arguments... so whatever the haskell equivalent of varargs is, if there even is such a thing
20:24:02 <Saizan> ah, yeah, the result should be a -> ... -> c
20:24:07 <centrinia> Orclev, you could make some generalized uncurry with Template Haskell.
20:24:14 <|Steve|> @pl \(f,g) (x,y) -> (f x,g y)
20:24:14 <lambdabot> uncurry (flip flip snd . (ap .) . flip flip fst . ((.) .) . flip . (((.) . (,)) .))
20:24:47 <Orclev> eugh, that's the sort of thing I was trying to avoid... that's horrendously unreadable
20:24:49 <Draconx> @unpl uncurry (flip flip snd . (ap .) . flip flip fst . ((.) .) . flip . (((.) . (,)) .))
20:24:50 <lambdabot> uncurry (\ aa f -> (\ p w -> ((,)) (aa (fst p)) (f w)) >>= \ af -> snd >>= \ ae -> return (af ae))
20:25:10 <|Steve|> @pl uncurry (\ aa f -> (\ p w -> ((,)) (aa (fst p)) (f w)) >>= \ af -> snd >>= \ ae -> return (af ae))
20:25:10 <lambdabot> uncurry (flip flip ((snd >>=) . (return .)) . ((>>=) .) . flip . (((.) . (,)) .) . (. fst))
20:25:21 <|Steve|> No fixed point yet.
20:25:24 <Saizan> Orclev: haskell doesn't have explicit support for varargs, though as usual you can abuse typeclasses for it
20:25:31 <copumpkin> Orclev: I can write it for homogeneous functions
20:25:59 <|Steve|> :t uncurry
20:25:59 <lambdabot> forall a b c. (a -> b -> c) -> (a, b) -> c
20:26:05 <|Steve|> Ah.
20:26:19 <centrinia> @djinn (a -> b -> c -> d) -> (a,b,c) -> d
20:26:19 <lambdabot> f a (b, c, d) = a b c d
20:26:22 <Orclev> the whole reason behind all of this is I decided to run hlint over a tutorial I downloaded the other day (partially because the tutorial was out of date and I was curious what hlint would make of it)
20:27:29 <centrinia> copumpkin, why are you making an Algebra module?
20:27:32 <Orclev> anyway, one of the lines I decided I'd see if I could rewrite just for practice was "runEval3 env ev  = runIdentity (runErrorT (runReaderT ev env))", which I did, but it lost readability in the transition to "runEval3 = flip ((runIdentity .) . ((runErrorT .) . runReaderT))"
20:27:44 <copumpkin> centrinia: why not?
20:28:04 <centrinia> It has already been done: http://hackage.haskell.org/package/algebra
20:28:27 <copumpkin> centrinia: uh :)
20:28:37 <copumpkin> centrinia: it has one class in it ;)
20:28:52 <centrinia> That's minimalism. ;)
20:29:02 <|Steve|> Is it some sort of R-module class?
20:29:04 <Saizan> Orclev: i'd write "runEval3 env = runIdentity . runErrorT . flip runReaderT env"
20:29:52 <centrinia> Magmas are general. :O
20:30:48 <bjorkintosh> does debian just hate haskell's guts or is it the other way around?
20:30:59 <|Steve|> centrinia: Sure, and pretty useless.
20:31:04 <|Steve|> Hey look, I've got a binary operator!
20:31:17 <ivanm> bjorkintosh: probably more indifference
20:31:21 <Makoryu> bjorkintosh: Are they still on 6.4 like certain other distros which will not be named?
20:31:23 <copumpkin> centrinia: I'm pretty annoyed that someone would take such a general package name and leave it like htat
20:31:23 <ivanm> in that no-one before has bothered to do it, etc.
20:32:03 <Saizan> Makoryu: which?
20:32:16 <Makoryu> Saizan: <Makoryu> which will not be named
20:32:19 <ivanm> Saizan: what part of "will not be named" don't you understand? ;-)
20:32:20 <Makoryu> Those ones
20:32:25 <Saizan> 6.4 is preme!
20:32:34 <Makoryu> Prewut?
20:32:50 <Saizan> well, i thought we could make an exception
20:33:25 <|Steve|> They're not pure.
20:33:31 <bjorkintosh> Makoryu, the official whatsitcalled is 6.8 i think.
20:33:32 <Saizan> pre my first use of haskell
20:33:43 <ivanm> Saizan: oh, "pre-me"
20:33:47 <bjorkintosh> but there's gotta be a linux distro with all the current goodies included.
20:33:52 <bjorkintosh> i couldn't find a cabal binary.
20:33:59 <ivanm> bjorkintosh: arch, gentoo
20:34:00 <bjorkintosh> and the compilation seems to be stuck.
20:34:03 <bjorkintosh> arch?
20:34:12 <ivanm> yes
20:34:13 <Saizan> archlinux
20:34:14 <Orclev> yeah, arch linux
20:34:28 <Saizan> however there's a ghc binary on www.haskell.org/ghc
20:34:34 <Makoryu> bjorkintosh: Arch gets a lot of love. It seems to stay up-to-date really well, and the server-side binary build system is a big help
20:34:35 <Saizan> no need to build it from source
20:35:01 <ivanm> Makoryu: "server-side"?
20:35:03 <bjorkintosh> Saizan, for cabal too?
20:35:10 <ivanm> it's called "devs build it and upload it"
20:35:28 <ivanm> bjorkintosh: well, new ghc ships with new cabal
20:35:35 <Makoryu> ivanm: Oh. I thought they had a build farm
20:35:38 <ivanm> but I would assume dons has included a PKGBUILD for cabal if it's needed
20:35:41 <ivanm> Makoryu: I doubt it
20:35:42 <Saizan> bjorkintosh: no, you'd need to build cabal-install separately
20:36:00 <ivanm> I don't know of any distro that actually has servers just for build farms, except for possibly commercial ones like RHEL
20:36:07 <Saizan> unless you mean Cabal the library which is shipped with ghc
20:36:16 <centrinia> Wow, there is such a thing as The Comonad.Reader :O
20:36:21 <bjorkintosh> ivanm, so how do i access this new cabal? 'cause i've got the 6.10.4 binary on this machine.
20:36:22 <ivanm> oh, you mean cabal-install?
20:36:35 <ivanm> cabal-install /= Cabal
20:36:43 <bjorkintosh> okay.
20:36:55 <ivanm> but I would assume it's there
20:37:01 <ivanm> also, it's not hard to install as a per-user
20:37:12 <ivanm> there's an automatic build script for it that gets whatever deps it needs, etc.
20:37:28 <bjorkintosh> it does, but how long ought it take?
20:37:34 <ivanm> not long
20:37:40 <bjorkintosh> this one has been going for close to 3 hrs.
20:37:41 <Saizan> bjorkintosh: untar this and run the bootstrap.sh script http://hackage.haskell.org/packages/archive/cabal-install/0.6.2/cabal-install-0.6.2.tar.gz
20:38:07 <bjorkintosh> i have all of that. cabal -install and Cabal
20:38:22 <bjorkintosh> Cabal is installed, but cabal-install is just pounding my harddrive
20:38:37 <ivanm> bjorkintosh: run "ghc-pkg check"
20:38:39 <Saizan> that's weird, unless you have very little ram
20:38:42 <ivanm> it shouldn't return anything
20:38:56 <copumpkin> Orclev: I think I may have it, or did you figure it out?
20:39:21 <Orclev> copumpkin: no, I actually got pulled into a discussion in another channel
20:39:39 <copumpkin> Orclev: just a sec, still trying to figure it out :)
20:40:12 <bjorkintosh> it didn't return anything.
20:40:29 <bjorkintosh> ivanm, what do i do with the results of ghc-pkg check?
20:40:35 <Saizan> bjorkintosh: what's the last thing the bootstrap.sh script printed?
20:42:21 <bjorkintosh> Saizan, it printed Linking setup
20:42:31 <bjorkintosh> and then it started molesting my harddrive.
20:43:28 <Saizan> heh, yeah, ld can do that if it doesn't have enough ram, like > 300mb or so
20:44:24 <Saizan> it's probably using a lot of swap right now
20:46:09 <bjorkintosh> it is.
20:46:13 <bjorkintosh> it's an old machine.
20:47:00 <Saizan> recompiling ghc disabling object splitting may help
20:47:43 <Saizan> also switching to gold
20:48:11 <Saizan> the new, somewhat experimental, linker in binutils
20:49:29 <bjorkintosh> can boostrap be made more verbose?
20:49:51 <bjorkintosh> i'd at least like to know that something's happening when i hear the pleas from the drive.
20:52:32 <Saizan> well, it's stuck on completing a single invocation of ld, i'm not sure if ld has a flag to report progress
20:52:54 <Saizan> however try ./bootstrap.sh --help
20:53:24 <Saizan> apparently not
20:54:20 <copumpkin> damn, I've got the type down on this arbitrary function composition but I can't write the function
20:55:32 <bjorkintosh> i thought cabal-install was an apt-get package or somefink.
20:56:24 <Haudrex> copumpkin: What function?
20:56:26 <bos> @pl \w->(True,w)
20:56:26 <lambdabot> (,) True
20:56:53 <copumpkin> Haudrex: the function composition that works on any functions
20:57:32 <centrinia> copumpkin, What is the type?
20:57:40 <copumpkin> (âˆ™) :: (b -> c) -> (a :~> b) -> (a :~> c)
20:57:53 <copumpkin> not quite as general as it could be yet
20:58:02 <jmcarthur> what is :~>?
20:58:18 <copumpkin> type family (:~>) a b :: *
20:58:18 <copumpkin> type instance (:~>) (a, ()) b = a -> b
20:58:18 <copumpkin> type instance (:~>) (a, (b, c)) d = a -> (:~>) (b, c) d
20:58:38 <copumpkin> not convinced it's even correct yet
20:58:48 <centrinia> copumpkin has gone over to the dark side with dependent types. :O
20:58:58 <copumpkin> lol
20:59:04 <copumpkin> it's not dependent!
20:59:06 <jmcarthur> that's not dependent types
20:59:21 <centrinia> Oh.
20:59:54 <copumpkin> oh, my problem is that I don't have an inverse for it
21:00:01 <copumpkin> damn, usual problem
21:00:53 <copumpkin> hrm
21:01:14 <copumpkin> there needs to be a way to tell GHC the inverse of a type function :P
21:01:27 <copumpkin> I keep running into this
21:02:06 <jmcarthur> what do you mean?
21:02:24 <copumpkin> so I think that type is good
21:02:29 <jmcarthur> be able to go from a -> b to (a, ()) :-> b?
21:02:32 <copumpkin> yeah
21:02:51 <copumpkin> oh wait, it did figure it out
21:03:09 <copumpkin> *Main> :t (+1) âˆ™ (+)
21:03:09 <copumpkin> (+1) âˆ™ (+)
21:03:09 <copumpkin>   :: (Integer -> Integer -> Integer ~ a :~> b, Num b) => a :~> b
21:03:41 <Orclev> that's cool... but what the heck character is that?
21:03:48 <jmcarthur> \cdot
21:04:03 <jmcarthur> looks like to me, anyway
21:04:04 <copumpkin> Orclev: I have the type, but the function is currently undefined :P
21:04:11 <copumpkin> yeah, that's what I was going for
21:05:23 <copumpkin> so it's still confused
21:05:53 <copumpkin> http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=9468#a9468
21:07:53 <centrinia> copumpkin, Put parentheses around (+) :: Integer -> Integer -> Integer
21:08:34 <copumpkin> it accepts that, but won't agree that the output is Integer -> Integer -> Integer
21:12:45 <copumpkin> any ideas?
21:16:32 <centrinia> copumpkin, What is the implementation of (\cdot)?
21:17:05 <copumpkin> it has none
21:17:13 <copumpkin> I'm just trying to get the types to work so far
21:17:20 <copumpkin> or rather, = undefined
21:25:55 <copumpkin> so no ideas?
21:26:11 <stanv> is it possible write: where (CircleNG r (x1, y1)) = s1
21:26:14 <stanv> ?
21:26:30 <tommd> Yes, you can have pattern matching in a where clause.
21:26:34 <tommd> stanv: ^^
21:27:53 <stanv> :)
21:28:04 <stanv> i got: <interactive>:1:51: parse error (possibly incorrect indentation)
21:28:23 <copumpkin> follow its hint ;)
21:28:44 <tommd> Umm... did you write that line in ghci?
21:29:06 <tommd> stanv: GHCI is not ment to write named functions in, particularly one long enough to justify a where clause.
21:29:53 <stanv> ah
21:30:22 <tommd> Where clauses can't stand alone - if that is your misunderstanding.  You are thinking of a 'let' clause.  Where must come after a function (and indented)
21:30:30 <stanv> with identation all fine
21:30:41 <Makoryu> stanv: If you desugar it (ie. let { foo = blargh; etc }) and put it all on one line, it'll work.
21:31:04 <Makoryu> stanv: However, this is a gigantic pain. Don't tase yourself, bro.
21:31:14 <stanv> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=9471#a9471
21:33:38 <tommd> stanv: You can pattern match in the function definition - there is no need for a where clause there, just FYI.
21:34:21 <Makoryu> tommd: It's quite clear with a where clause. It would be harder to read if he put it all on one line.
21:34:32 <Makoryu> You'd have to scan across looking for the (=)
21:34:57 <tommd> makoryu: Yeah, its a style thing, which is why I said FYI.   You don't need to scan for the '=' if its the last thing on the line, which I see often.
21:35:18 <stanv> thanks, .... i have mistake in testsuit
21:39:02 <cloudhead> is there a way I could rewrite this, where  `z` would have access to x & y ? http://www.friendpaste.com/6Nqma5pjN3BxS6m0M82vdG
21:41:40 <aconbere> I just asked this a moment ago, but I have a little more time now
21:41:51 <aconbere> I have a really dumb buffer data type right now
21:42:05 <aconbere> basically a string with a cursor that keeps track of it's coordinates within the buffer
21:42:23 <aconbere> I'm familiar with Gap Buffers
21:42:37 <aconbere> and Zippers, but I've never implimented the former nor used the latter
21:43:11 <aconbere> a gap buffer seems pretty easy to build
21:44:08 <aconbere> three strings + a buffer length
21:44:15 <aconbere> pre, post, and buf strings
21:44:43 <aconbere> when the buf extends beyond buffer length, you append the buffer to pre
21:45:24 <aconbere> this all seems very much geared towards a language with arrays that are constructed in memory and difficult to deal with size changing
22:03:51 <travisbrady> anyone have any recommendations for a Haskell library to do a bit of XML parsing/querying?
22:05:45 <copumpkin> so, I have a problem
22:05:58 <copumpkin> and I bet everyone wants to hear it
22:07:12 <BMeph> copumpkin: Well, I'd like to, but I'm pretty deaf to the Internet. Why don't you type it instead? ;p
22:07:13 <Makoryu> travisbrady: Here's one: http://hackage.haskell.org/package/xml-parsec-1.0.3
22:07:25 <Makoryu> travisbrady: Haven't ever used it, though. No guarantees
22:07:25 <copumpkin> so if I have data Z; data S a; for type-level peano naturals
22:08:06 <travisbrady> Makoryu: yeah, i've googled and looked at hxt, haxml etc but was hoping to figure out which lib seems to have most mindshare
22:08:33 <copumpkin> can I represent infinity? at the value level, I could do fix S. At the type level, I can do Mu S, but then it's not the same representation and I need to special-case Mu handling
22:09:01 <Makoryu> travisbrady: I get the impression most Haskell programmers would rather run as far away from XML as possible, leaving the Java folks to deal with it ;)
22:10:17 <travisbrady> Makoryu: haha, i feel the same way, unfortunately sometimes you're stuck with xml
22:15:50 <JoePeck> this made me chuckle
22:15:53 <JoePeck> shell> ghci --help
22:16:10 <JoePeck> cannot use `--interactive' with `--help'
22:16:17 <JoePeck> Usage: For basic information, try the `--help' option.
22:16:21 <JoePeck> =( thats what I did!
22:16:22 <Makoryu> Hah
22:16:27 <Makoryu> Try ghc --help
22:16:30 <copumpkin> is this bad?
22:16:31 <copumpkin> type family Mu (a :: * -> *) :: *
22:16:31 <copumpkin> type instance Mu f = f (Mu f)
22:16:36 <JoePeck> yah, I figured that after ;)
22:16:40 <Berengal> ghci is just an alias for ghc -i
22:17:17 <cdsmithus> On the other hand, ghci --help works fine with GHC 6.10.4, at least.  Must have been fixed already.
22:17:31 <Orclev> Makoryu: honestly most java programers if they actually had to deal with XML directly would probably run away from it as well, but there's a whole ton of libraries and utilities built on top of xml, so they mostly just shrug and pretend it's the worlds ugliest config file
22:17:43 <JoePeck> hmm, I was 6.8.3, good to know cdsmithus  thanks
22:18:13 <Makoryu> Orclev: That's the funny thing about Java. Too many libraries to know what to do with.
22:19:21 <Orclev> Makoryu: sometimes thats a good problem to have though... particularly from the standpoint of a business that would rather throw cash at a problem than time... even if that sort of thinking tends to bite them in the end
22:19:35 <dibblego> Java has too few useful libraries, which on its own is annoying, but being drowned out by useless libraries makes it utterly impossible
22:19:59 <Berengal> Java lacks a hackage/CPAN
22:20:07 <Berengal> And that is it's major flaw
22:20:16 <dibblego> maven is the "solution" to that
22:20:28 <Orclev> dibblego: maven isn't the solution to anything
22:20:29 <dibblego> but it also lacks a useful library to put on there
22:20:34 <dibblego> Orclev, neither is Java
22:20:37 <Makoryu> Berengal: That's.... not even on my list of the bad parts of Java.
22:20:43 <Orclev> dibblego: fair enough
22:21:16 <Berengal> Makoryu, not talking about the language itself here, of which I've got another list as long as my leg...
22:21:44 <copumpkin> damn, that Mu family isn't very useful
22:22:21 <Berengal> Java has a far too complicated build process, and is severely lacking in interactive development
22:22:49 <Orclev> Java isn't my least favorite language though, that honor belongs to C++
22:23:05 <Berengal> I don't know C++, and I don't think I ever want to
22:23:16 <Jafet> C++ is merely Haskell for masochists
22:23:20 <Orclev> lol
22:24:18 <Orclev> C++ is C with all the nice bits stripped out and all the ugliest bits of Java bolted on with extra helpings of STL duct tape
22:24:30 <cdsmithus> I once wrote (an old version of) the BrainBench certification test for C++, and even I hate it.
22:26:03 <Makoryu> Berengal: Nobody really knows C++.
22:26:16 <Berengal> Makoryu, nobody really knows haskell either
22:26:27 <aconbere> Really I think all of programming would be made much better if every language had cabal
22:26:33 <Jafet> They plan to add these new and innovative features to C++ next year: * type classes * anonymous procedures * type inference
22:26:39 <Orclev> anyone seen D? It's a nice concept I suppose, but it suffers greatly from a fragmented standard library and almost no library support
22:27:14 <kyagrd> aconbere: Perl has CPAN
22:27:15 <Berengal> D suffers from being too new a language without any really new concepts
22:27:50 <aconbere> kyagrd: yeah but I can't ever get that to work as nicely as cabal
22:27:56 <Orclev> Berengal: well, it was never meant to have new concepts, but rather to do all the old concepts better... it was more or less supposed to be C++ minus all the suck
22:28:12 <Berengal> "C++ without the ugly bits" isn't good enough to make people change language, especially when there's no libraries
22:28:21 <Berengal> And there won't be libraries unless people change
22:28:44 <kyagrd> Berengal: when there are no libraries why ever bother to use impure languages without type inference?
22:28:45 <Orclev> Berengal: catch 22... I know, I tried to play around with D myself but couldn't manage to do anything useful with it
22:28:46 <Berengal> My guess is people will have moved to Haskell by the time D builds up enough steam
22:29:19 <aconbere> kyagrd: that cabal works absolutely seemlessly without elevated permissions, and no special terminal applications make is much more usable for me
22:29:56 <Berengal> Although yes, it does seem like a nice language. My brother loves it, and claims it's getting more and more functional pieces ducttaped on
22:30:25 <Orclev> Berengal: I don't know, one of its core targets was the embedded devices market... how does haskell hold up for doing embedded development?... can you even inline something like C or ASM in haskell? I think I remember seeing something about that, but once again I'm a noob at haskell still
22:31:20 <Makoryu> Berengal: D seems to be the favorite of Perl programmers who would never admit (especially to themselves) that they could ever possibly learn or enjoy Perl
22:31:31 <Makoryu> I have no idea how that happened :p
22:31:41 <Berengal> Hehe
22:32:25 <Berengal> Orclev, I've never seen inline assembly, but I've seen an assembly EDSL, but that only built up a list of enums that could be converted to bits and written to disk by an assembler
22:32:47 * copumpkin wants infinite types dammit :(
22:33:03 <E_G> hi copumpkin :)
22:33:15 <copumpkin> hi E_G
22:34:00 <Jafet> C for embedded devices is completely stupid
22:34:01 <EnglishGent> what do you want infinite types for copumpkin?
22:34:06 <Jafet> Use forth
22:34:23 <copumpkin> type-level fix of the peano successor function
22:34:31 <copumpkin> I want infinity in my type-level naturals
22:34:39 <copumpkin> without Mu, so I can use a uniform representation
22:35:14 <EnglishGent> okay... regressing a step - why do you want type-level naturals?
22:35:23 <EnglishGent> and why do you need to be able to represent infinity?
22:35:30 <Jafet> (You want the compiler to do cardinal induction?)
22:35:41 <kyagrd> copumpkin: I hope I had the similar thing. Z, S, and Inf where S(Inf) ~ Inf
22:35:41 <copumpkin> for sized vectors, and I want infinite lists :P
22:35:50 <copumpkin> you can do it fine at the value level
22:35:57 <EnglishGent> ah!
22:36:17 <copumpkin> I could make a separate type for infinity, but I'd prefer not to
22:36:26 <copumpkin> then I need to deal with it every time I deal with naturals
22:36:43 <kyagrd> The problem is we can't really infrom GHC to do type level proofs like successor of infinity is same as infiniti and so on on the type level
22:36:59 <copumpkin> well, I can easily do Mu S
22:37:02 <EnglishGent> it seems to me that types you _know_ are infinite are not the same - you cant define reverse, or length over infinite vectors for example
22:37:02 <copumpkin> where data S a
22:37:17 <EnglishGent> (well I suppose you could define length - given you want a representation of 'infinite')
22:37:18 <EnglishGent> :)
22:37:36 <EnglishGent> brb - rl
22:37:42 <copumpkin> well, that's the point
22:37:56 <copumpkin> you wouldn't  be allowed to reverse a list that's known to be infinite
22:38:02 <copumpkin> not all lists have a known size of course
22:39:39 <Jafet> > head $ reverse $ map (1/) [1..] -- "0"!
22:39:45 <lambdabot>   mueval: ExitFailure 1
22:39:48 <copumpkin> lol
22:39:51 <Orclev> speaking of languages, I wish I could get my hands on the version of L4 someone implemented in haskell, I'd love to look through that
22:42:25 <JBGood> should you use ordinals or cardinals to represent the length of a list?
22:42:41 <JBGood> how long is [1..] ++ [1] ?
22:43:14 <mauke> .oO( 256 )
22:45:11 <Orclev> JBGood: I think that's the use case behind floating point INF values
22:46:03 <copumpkin> JBGood: aleph 0
22:46:14 <EnglishGent> back
22:46:22 <JBGood> ok, cardinals it is
22:48:45 * JBGood attempts to think of a way to construct a list with cardinality beth 1
22:49:24 <copumpkin> beth 1?
22:49:46 <copumpkin> is beth the next character?
22:50:48 <JBGood> beth 1 is 2 ^ { aleph 0}
22:50:52 <JBGood> roughly
22:51:00 <copumpkin> how is that different from aleph 1?
22:51:28 <copumpkin> oh I see
22:51:30 <JBGood> aleph 1 is the next cardinal number after aleph 0
22:52:30 <copumpkin> so they are the same if continuum hypothesis?
22:52:37 <copumpkin> (/me is just reading wikipedia here)
22:52:40 <JBGood> right
22:55:34 <dm2> no, aleph 0 /= aleph 1.  That is proven by diagonalization.  Continuum hypothesis is about whether there might be sizes in between
22:56:16 <copumpkin> dm2: I meant beth 1 == aleph 1 if CH
22:56:49 <dm2> oh, never mind.  Sorry, wasn't following.
22:57:01 <JBGood> there are, by definition, no sizes between aleph 0 and aleph 1 :)
22:57:36 <Orclev> ... speaking of not following, I'm going back to my tutorial reading before I get sucked into yet another subject that I'm going to have to spend a week reading about before I understand
22:59:58 <dm2> Is there really no way to convince cabal to install source code automatically?
23:02:45 <kyagrd> @where Expr
23:02:45 <lambdabot> http://twan.home.fmf.nl/blog/haskell/simple-reflection-of-expressions.details
23:06:21 <EnglishGent> interesting papere, relevant to set sizes & the continuum hypotheis -- http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.7026
23:06:26 <EnglishGent> :)
23:18:17 <_nickel> exclamation :: [Algebra] -> [Of] -> [Programming] -> [Awesome]
23:20:09 <_nickel> is there any interest in a language extension for the purposes of using underscore function names interchangeably with with camel case?
23:20:18 <_nickel> this_function = thisFunction
23:21:04 <_nickel> are there any obvious issues with that idea?
23:21:36 <EnglishGent> the only one that springs instantly to mind is clashes with existing functions named in camel case form
23:21:46 <EnglishGent> of which there probably arent many
23:21:52 <EnglishGent> but I'm no expert _nickel
23:21:54 <EnglishGent> :)
23:22:11 <_nickel> thats the purpose though
23:22:26 <_nickel> to be able to call those functions with underscores
23:23:02 <Phyx-> but why would you want to?
23:23:09 <_nickel> because I hate camel case :D
23:23:20 <Phyx-> then don't use it
23:23:32 <_nickel> Phyx-:  hate is a strong word maybe
23:23:49 <_nickel> yes but its bothersome having to use camelcase libraries when your's aren't
23:24:01 <_nickel> consistency!
23:24:10 * EnglishGent wishes haskell would allow dashes in function names .. and optionally ending function names in a '?'
23:24:13 <EnglishGent> is-even?
23:24:27 <_nickel> Phyx-: I'm not arguing that this is a dire need in haskell
23:24:28 * jjohnsson agrees in all parts with _nickel.
23:24:33 <ivanm> > let isEven? = even in isEven? 2
23:24:35 <lambdabot>   <no location info>: parse error on input `='
23:24:39 <Alpounet> send-through-network. "Hi"
23:24:42 <ivanm> heh, guess it doesn't
23:24:52 * ivanm completely disagrees with _nickel
23:24:57 <Phyx-> say the library has 1000 functions in camelcase, your extension would generate 1000functions using underscore, of wich 99% will never be used. I just don't see the real use
23:25:01 <Alpounet> so do I.
23:25:01 <ivanm> ending in a question mark might be OK
23:25:08 <_nickel> ivanm: its a very personal opinion to most
23:25:34 <ivanm> _nickel: I was responding more to jjohnsson
23:25:46 <EnglishGent> well ending in a ? tradditionally means predicate .. ! is normally (think scheme here) for things which have side effects... and haskell really doesnt do side-effects in the same way
23:25:49 <_nickel> ivanm: in equal parts I'm suggesting that libraries written with underscores be usable in camel case
23:25:58 <ivanm> EnglishGent: "traditionally"?
23:26:00 <EnglishGent> though I guess it might still be a useful lexical convention
23:26:12 <ivanm> I admit, it would be nice to do, but I'm not sure if it's really "traditional"
23:26:20 <ivanm> how many languages support that and have a culture of doing so?
23:26:20 <EnglishGent> in the Scheme community ivanm :)
23:26:30 <ivanm> EnglishGent: yes, but they're not exactly representative ;-)
23:26:41 <ivanm> (I realise that it's done in scheme)
23:26:45 <EnglishGent> their representative of people who use elegant languages :P
23:26:46 <EnglishGent> :)
23:26:53 <_nickel> Phyx-: It wouldn't even have to generate functions, at compile time the reference would simply point to the camel case version
23:26:54 <ivanm> _nickel: I don't recall any library using underscores...
23:26:58 <EnglishGent> not that Haskell isnt elegant too - it is -- very
23:26:58 <EnglishGent> :)
23:27:16 <ivanm> EnglishGent: if they're so representative, then Haskell _mustn't_ be an elegant language
23:27:18 <_nickel> ivanm: either way really :D
23:27:19 <kyagrd> EnglishGent: you can use Agda?
23:27:26 <ivanm> since I would guess that number of haskell users > number of scheme users
23:27:36 <EnglishGent> er.. define 'use agda'
23:27:46 <EnglishGent> write anything of any use in it -- no, not yet
23:27:54 <ivanm> (that is, people who willingly or want to use language Foo, not just those learning it because their uni says they have to)
23:28:26 <sereven> quit_var <- new_io_ref False; fork_io (main >> write_io_ref quit_var True)
23:28:36 <sereven> vs quitVar <- newIORef False; forkIO (main >> writeIORef quitVar True)
23:29:14 <sereven> hmm, guess I could get used to it, but seems confusing to me personally for std libs
23:29:18 * EnglishGent has _never_ learn a language just beacuase a uni said I had to
23:29:30 <EnglishGent> all the ones they said I had to know... I already knew before I went :)
23:30:14 <ivanm> EnglishGent: you willingly learnt Java? :o
23:30:37 <EnglishGent> ivanm - yes, but in a moment of weakness
23:30:42 <ivanm> ahhhh
23:30:52 <EnglishGent> (seriously I learnt Java when it was still in alpha & the idea of an applet was new)
23:31:17 <EnglishGent> I'd been banging out about virtual machines to people for about 18 months prior to that ... so when a VM based language came out...
23:31:22 <_nickel> sereven: thats the beauty you can use either! Its the same thing
23:31:27 <psykotic> that was when java was cool and the only source of documentation were the official java docs
23:31:31 <psykotic> with the cute cat guy
23:31:33 <EnglishGent> yes
23:31:39 * psykotic remembers that
23:31:47 <EnglishGent> it was once a small neat, quite nice to use language
23:31:53 <EnglishGent> those days are _long_ past
23:31:54 <Alpounet> @where Hask
23:31:55 <lambdabot> I know nothing about hask.
23:32:12 <ivanm> EnglishGent: then it came out of alpha? :p
23:32:12 <sereven> _nickel: well that's what I mean, were I to read some of your work it would be confusing trying to recogize std functions mixed in with your locally defined ones.
23:32:15 <psykotic> the days before Hask had monads :)
23:32:31 <_nickel> sereven: your editor could easily convert between eh?
23:32:37 * EnglishGent never new Haskell before monads
23:32:37 <ivanm> IIRC, emacs can...
23:32:39 <psykotic> i remember reading one of the really early haskell reports and they talked about continuation io
23:33:06 <psykotic> and maybe stream io
23:33:36 <psykotic> that was after i had learned a bit of standard ml, so everything until that point in the report was smooth sailing, and then it was like 'what the fuck is this'
23:33:57 <psykotic> ah, youth
23:34:19 <EnglishGent> ivanm - yes :P
23:35:00 <sereven> _nickel: aye, possibly, although not sure there would be enough adoption of such a thing for editor plugins to get implemented. But don't let my opinion weigh for much. :-)
23:35:15 <EnglishGent> I'm sure there's an emacs package to do that
23:35:22 <_nickel> sereven: I think that would be an easy, easy thing to do
23:35:34 <EnglishGent> I mean - it even has a built-in psycotheapist for crying out loud! :)
23:35:40 <EnglishGent> there's an emacs package for _everything_
23:35:53 * EnglishGent 's favourite editor by far
23:36:06 <ivanm> EnglishGent: I have already says there is!
23:36:10 <EnglishGent> (I conceed it's not perfect, it has it's faults - but I've yet to see any real competition)
23:36:29 <EnglishGent> ah sorry missed it
23:36:33 <Phyx-> eeeww emacs :P
23:36:35 <EnglishGent> what's the package called?
23:36:43 <ivanm> inbuilt, AFAIK
23:36:49 <ivanm> goggles is the mode IIRC
23:39:58 <Gracenotes> WHAT
23:41:24 <ivanm> Gracenotes: s/H//
23:41:24 <ivanm> ;-)
23:41:37 <Phyx-> whoops, flash did it again... another crashed tab
23:42:34 <jafet> And there will be weeping and flashing of teeth.
23:43:27 <Phyx-> and saying of untypable words at adobe
23:43:30 <EnglishGent> did it take the entire browser with it Phyx-? or are you using one written by people who understand this newfangled 'threads' idea?
23:43:35 <EnglishGent> :|
23:44:05 <Phyx-> EnglishGent: nah, it just took a browser tab
23:44:49 * EnglishGent wanting to know why a multi-threaded firefox cannot be expected anytime soon :|
23:45:22 <Phyx-> It seems the quality of the flash player has been decreasing considerably ever since adobe bought them. which is strange considering how rock solid photoshop is
23:45:41 <jafet> I have about 500 tabs open regularly, threaded firefox would kill the kernel with hellfire
23:45:43 <EnglishGent> it's ludicrous - it took *ages* before everyone finally got around to using pre-emptive multitasking on their operating system
23:45:55 <EnglishGent> so then the applications have to go & reintroduce the problem _all over again_
23:46:02 <Phyx-> lol
23:47:01 <Gracenotes> jafet: you should write a novel about your tab setup or something then
23:47:05 <EnglishGent> jafet - Erlang style threading perhaps?
23:47:13 <ivanm> jafet: but if they used "green-thread" style threads like Haskell, Erlang, etc. use...
23:47:25 * EnglishGent believes jafet - I ofen have a few hundred tabs open
23:47:38 <ivanm> Gracenotes: I don't think I have 500 tabs, but I generally have at least 4 or 5 rows of tabs...
23:47:38 * Axman6 has never gone past 75
23:47:49 <ivanm> Axman6: you actually bothered to _count_? :o
23:48:02 <jafet> Count the rows
23:48:14 <Axman6> Safari tells you before you quit: "You have XX tabs open, are you sure you want to quit?"
23:48:18 <Phyx-> lol
23:48:21 <ivanm> ahhhh
23:48:21 <Gracenotes> May I take this time to publicly advertise Tab Counter for Firefox: https://addons.mozilla.org/en-US/firefox/addon/4346
23:48:31 <EnglishGent> and as ivanm says - do it with Erlang style threading & you could do without slaughtering the system
23:48:31 <ivanm> Axman6: oh, so you're one of the Mac people...
23:48:43 <Axman6> yep
23:48:53 <Phyx-> lol, people actively want to know how many tabs they have open? is this some kind of epenis thing?
23:48:55 <jafet> Unfortunately, C++ does not come with Erlang style threading
23:49:15 * Phyx- has noticed #haskell has alot of those Mac people
23:49:21 <DarkUnicorn> whats the sense in having so many pages open?
23:49:22 <EnglishGent> and? nobody *made* them write in an inferior language :P
23:49:37 <jafet> EnglishGent, Netscape.
23:49:42 <Phyx-> rofl
23:49:50 <sereven> vimperator kindly tells you in the status display, but it's mostly useful to jump the right amount of tabs forward or back when know you want some near the ends
23:50:14 <EnglishGent> DarkUnicorn - I find when you keep stacking up more & more 'to read' stuff
23:50:42 <EnglishGent> and the problem with web-pages .. is one *cannot* be sure that if one reloads them you'll get the same content back
23:50:44 <DarkUnicorn> EnglishGent: isn't it better to use bookmarks then?
23:50:57 <EnglishGent> see the statement I just made DarkUnicorn
23:51:02 <DarkUnicorn> okay, maybe evernote or something
23:51:09 <EnglishGent> I dont know evernote
23:51:20 <Phyx-> hmm i wonder how windows 7's live previews would handle 500tabs..
23:51:26 <jafet> DarkUnicorn, because firefox has a useless cache and bookmark management system but decent tabbing code
23:51:37 <Gracenotes> oh, as for the copious number of bookmarks I have... you don't even want to know... -_-
23:51:43 <DarkUnicorn> but if you quit firefox, all is gone
23:51:58 <Gracenotes> I need to go on a purge in that department
23:52:02 <EnglishGent> Gracenotes - in the 10s of thousands? (literally?)
23:52:10 * EnglishGent passed the 10K bookmark barrier a while back :|
23:52:42 <ivanm> bookmarks are so passe... I just use my browser's history ;-)
23:52:48 * Axman6 doesn't bookmark. that's what he has tabs for
23:53:02 <ivanm> jafet: I find firefox' caching sufficient
23:53:03 <Phyx-> Axman6: so a powerfailure would make you cry?
23:53:07 <jafet> The firefox history browser is stone age in terms of efficiency
23:53:08 * copumpkin just uses his excellent memory
23:53:17 <Axman6> nope. browser remembers the tabs
23:53:23 <ivanm> though recently it doesn't remember sites I'm logged into...
23:53:30 * EnglishGent borrows copumpkin's memory
23:53:33 <EnglishGent> :)
23:53:34 <Gracenotes> I find that Firefox slows down with too much history
23:53:45 * Phyx- duplicates copumpkin's memory
23:53:56 <copumpkin> :)
23:54:16 <Gracenotes> by too much I do mean tens of thousands of links. it scales enough though.
23:54:17 * ski discards copumpkin's memory
23:54:31 * Gracenotes turns on copumpkin's privacy mode
23:54:53 <jafet> Gracenotes, that's merely because the usual UI toolkits die horribly and do not scale
23:54:54 * Phyx- runs from copumpkin's memory's automated drones
23:55:12 <jafet> And firefox just uses your native UI toolkit
23:55:24 <copumpkin> :o
23:56:31 * Phyx- won't say which browser he uses because that would probably get him banned from #haskell
23:56:34 <Phyx-> :P
23:56:35 <Gracenotes> jafet: well. It does make threads where necessary to alleviate concurrency problems. I just get the feeling that the overhead of maintaining all the history links in operations that are expected to be lightening fast -- like adding an item -- has its effects, er, I forgot how I began this sentence
23:56:39 <Phyx-> exiled or something
23:56:51 <Axman6> ... not IE6? :O
23:56:53 <jafet> What sort of operations are you talking about?
23:57:01 <Gracenotes> adding an item
23:57:07 <jafet> To the history list?
23:57:08 <Phyx-> Axman6: close enough :P IE8
23:57:23 * Phyx- runs for the hills
23:57:26 <Gracenotes> yes. or, perhaps, querying items to color visited links. just a conjecture.
23:57:30 <jafet> Well, I hope they don't use bubble sorted linked lists, but you never know.
23:57:58 <Gracenotes> at some n it gets sluggish
23:58:37 * Phyx- wonders if Axman6 has entered shock
23:58:44 <jafet> (I believe the ocaml compiler uses linked lists for type representation -- very handy for when you actually want to use some polymorphism)
23:58:54 * Axman6 groggily wakes up
23:58:58 <Axman6> wha... happened....
23:59:05 <Axman6> o.0
23:59:07 <Gracenotes> although, I'd hope they'd use a Bloom filter for coloring visited links
23:59:27 <Phyx-> Axman6: lol, but in all fairness, I do have my reasons for using it :P
23:59:29 <Gracenotes> or something like
23:59:43 <jafet> I hope they would not make the UI non-deterministic like that
