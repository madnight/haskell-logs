00:03:07 <Gilly> http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=8094#a8094
00:04:12 <Gilly> Trinithis: that ought to work :P i'm not sure if there are faster implementations, though
00:04:39 <Trinithis> cool
00:05:15 <PetRat> @unmtl StateT s Maybe
00:05:15 <lambdabot> err: `StateT s Maybe' is not applied to enough arguments, giving `/\A. s -> Maybe (A, s)'
00:05:30 <PetRat> @unmtl StateT s Maybe a
00:05:31 <lambdabot> s -> Maybe (a, s)
00:05:53 <PetRat> @unmtl MaybeT (State s) a
00:05:54 <lambdabot> s -> (Maybe a, s)
00:08:34 <PetRat> :kind StateT s Maybe
00:08:44 <PetRat> @kind StateT s Maybe
00:08:46 <lambdabot> Not in scope: type variable `s'
00:08:53 <PetRat> @kind StateT s Maybe a
00:08:55 <lambdabot> Not in scope: type variable `s'
00:08:55 <lambdabot> Not in scope: type variable `a'
00:09:01 <PetRat> @kind succ
00:09:02 <lambdabot> Not in scope: type variable `succ'
00:09:12 <PetRat> @kind Int->Int
00:09:13 <lambdabot> *
00:09:21 <PetRat> @kind Maybe
00:09:23 <lambdabot> * -> *
00:09:31 <PetRat> @kind Monad
00:09:33 <lambdabot> Class `Monad' used as a type
00:09:39 <PetRat> @kind []
00:09:41 <lambdabot> * -> *
00:09:47 <PetRat> @kind StateT
00:09:49 <lambdabot> * -> (* -> *) -> * -> *
00:09:54 <Trinithis> Gilly: seems to work like a charm :D
00:10:03 <PetRat> @kind MaybeT
00:10:04 <lambdabot> Not in scope: type constructor or class `MaybeT'
00:10:46 <PetRat> Does MaybeT exist anywhere yet?
00:11:09 <PetRat> Brent refers to it in Typeclassopedia
00:11:28 <Gilly> Trinithis: I modified it a bit, now it includes the empty sequence and has better code: http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=8094#a8096
00:12:05 <PetRat> @unmtl StateT s Maybe a
00:12:06 <lambdabot> s -> Maybe (a, s)
00:12:15 <PetRat> @unmtl StateT s (Maybe a)
00:12:16 <lambdabot> err: `StateT s (Maybe a)' is not applied to enough arguments, giving `/\A. s -> Maybe a (A, s)'
00:12:31 <PetRat> @unmtl (StateT s) Maybe a)
00:12:31 <lambdabot> err: Parse error
00:12:36 <PetRat> @unmtl ((StateT s) Maybe a)
00:12:36 <lambdabot> s -> Maybe (a, s)
00:14:00 <Trinithis> Gilly: thx
00:14:24 <dancor> PetRat: http://hackage.haskell.org/package/MaybeT
00:14:33 <PetRat> @kind StateT
00:14:34 <lambdabot> * -> (* -> *) -> * -> *
00:15:12 <dancor> what can you do with kind-level programming
00:15:20 <hackagebot> hS3 0.5.1 - Interface to Amazon's Simple Storage Service (S3) (GregHeartsfield)
00:16:07 <Trinithis> Gilly: Well, I gtg. Again, thanks
00:16:42 <PetRat> dancor: thanks. So am I saying this right... MaybeT is in hackage, meaning someone wrote it (obviously) but hasn't been added to the standard libraries that come with ghci yet?
00:17:28 <c_wraith> > let subs [] = []; subs (x:xs) = (let s = subs xs in [[x]] ++ s ++ map (x:) s) in subs [1..3]
00:17:30 <lambdabot>   [[1],[2],[3],[2,3],[1,2],[1,3],[1,2,3]]
00:17:45 <c_wraith> what was wrong with that implementation?
00:17:51 <dancor> PetRat: ya idk, more info at http://www.ultraviolet.org/mail-archives/haskell-cafe.2008/msg14981.html
00:18:42 <dancor> "It's equivalent to ErrorT ()  - but ErrorT String is almost always a
00:18:46 <dancor> better option anyway"
00:20:38 <PetRat> dancor: thanks
00:20:42 <PetRat> @kind ErrorT
00:20:43 <lambdabot> * -> (* -> *) -> * -> *
00:21:01 <Nafai> Anyone else having problems pulling from the Leksah repo?
00:21:12 <Nafai> darcs failed:  Couldn't fetch `0000052442-26d623b68f9766fab5b6032d257cb2a773bdc9e07da7ff8fef9564831ae619a9'
00:21:15 <Nafai> in subdir pristine.hashed from sources:
00:22:02 <PetRat> So the kind of StateT is *->(*->*)->*->*. Can that be interpreted as : StateT needs a type for the state (first *), a monad (*->*), a type to supply to the monad (second*) and gives a type (last *)???
00:22:37 <dancor> or, it takes a type and a monad to a monad
00:22:52 <dancor> sinec * -> * is the same as (* -> *)
00:22:54 <dancor> since
00:22:58 <PetRat> I see.
00:23:56 <PetRat> What is the term for functions that use a type variable instead of an explicit type. Polymorphic?
00:24:23 <dobblego> yes, poly=many, morph=form
00:24:54 <PetRat> Is the same term used for a constructor of kind *->*?
00:25:10 <dancor> length :: [a] -> Int   has parametric polymorphism (unspecified type a with no class constraint)
00:25:38 <dancor> show :: (Show a) => a -> String  has ad-hoc polymorphism (has constraint)
00:25:58 <Saizan> PetRat: no, that's monomorphic, there aren't kind variables involved there
00:26:13 <Saizan> (there's no kind polymorphism in haskell)
00:27:05 <PetRat> Saizan: not sure if I phrased that right. For example, is Maybe a "polymorphic type"?
00:28:24 <PetRat> or "polymorphic type constructor"?
00:28:39 <Saizan> "Maybe" isn't a polymorphic type, "forall a. Maybe a" is. though the forall is often implicit
00:28:47 <Saizan> Maybe is just a type constructor
00:29:17 <Saizan> the term polymorphic doesn't really apply here
00:29:51 <PetRat> I was just thinking that we "encounter" Maybe in "many forms".. that is, Maybe Int, Maybe String, ...
00:31:53 <Saizan> well, you don't call all the functions polymorphic, but they can equally be applied to many values
00:34:06 <PetRat> Thanks, everyone. Off to bed.
00:51:11 <eflister> hi.  i'm trying to implement System.Random.Random for all Bounded Enums.  it works, except i'm getting an Overlapping instance when i try to use it simultaneously with Doubles, as if Doubles were Bounded Enums, which they aren't (they are Enum, but minBound::Double gives 'no instance').
00:51:14 <eflister> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8098
00:52:45 <Deewiant> "instance Random Double" and "instance EB a => Random a" overlap, regardless of whether "instance EB Double" exists.
00:53:12 <Saizan> the context isn't taken into consideration when deciding which instance to pick, it's only checked after the fact
00:53:22 <eflister> deewiant: oh, huh.  thx.  that sucks.
00:53:26 <Saizan> that's why it also doesn't matter for overlapping purpouses
00:53:35 <eflister> any way to do what i want?
00:54:04 <Deewiant> Yes, OverlappingInstances :-P
00:54:14 <eflister> oh :)
00:54:42 <eflister> yep that worked
00:54:44 <eflister> thanks!
00:55:19 <eflister> i don't know when to add extensions unless told to do so by the compiler error :(
01:11:42 <eflister> in RWH (http://book.realworldhaskell.org/read/monads.html#id644179), we use System.Random.StdGen in the State monad.  how would we generalize this to any RandomGen?
01:12:24 <Saizan> make RandomState take a g parameter
01:12:33 <Saizan> but then it's just State renamed
01:13:04 <eflister> right, is there any way to enforce "RandomGen g =>" in a type?
01:13:10 <Saizan> no
01:13:35 <Saizan> you'll just have that context on the functions using it
01:13:41 <eflister> that sort of makes sense to me, since types are for synonyms.  so i was trying to do it with a newtype, and it wasn't working out.
01:14:01 <Saizan> it doesn't work well for data either
01:14:27 <Saizan> the standard procedure is to not enforce such contexts
01:14:42 <Saizan> yaour use of the values will.
01:14:48 <Saizan> *your
01:15:45 <eflister> am i missing something by thinking that it would be good to enforce it at the type (of state, rather than every individual function)?
01:19:07 <quicksilver> eflister: it would be nice in a way, but it doesn't matter as much as it appears at first.
01:19:28 <quicksilver> you can do it that way with GHC if you like (it's a small part of the GADT feature)
01:20:19 <eflister> ah.  i have tried to tackle that topic a few times and been thwarted.  :)
01:42:32 <Baconizer> Hi. I'm on x86 Debian, with all the GHC requirements installed from repo
01:42:57 <Baconizer> I'm trying to compile the latest GHC so that I can get the Haskell Platform fully working
01:43:06 <Baconizer> But sh boot does not work
01:43:08 <Baconizer> :<
01:43:19 <Baconizer> Oops, forgot pastebin, be right back
01:45:25 <Baconizer> http://pastebin.com/m7a4dff11
01:45:30 <Baconizer> Sorry about that >_>
01:47:11 <Baconizer> ./configure gets to "checking for ld," then unexpected EOF at line 11121
01:47:25 <alc> why not download the latest ghc binary from http://haskell.org/ghc/
01:47:59 <Baconizer> alc: I guess I can do that
01:48:05 <Baconizer> Thanks
01:48:09 <Baconizer> Sorry :<
01:49:11 <alc> np
01:49:15 <quicksilver> Baconizer: bootstrapping GHC like that is for experts only.
01:49:24 <quicksilver> Baconizer: either just download a binary, or use the debian package GHC to compile GHC.
01:49:42 <Baconizer> quicksilver: ok
01:49:45 <int-e> Baconizer: by 'latest' you mean 6.10.4?
01:49:52 <Baconizer> int-e: yea
01:50:42 <Baconizer> The latest version in the Debian repo is 6.8.2
01:50:44 <Baconizer> :<
01:53:09 <int-e> Baconizer: try http://int-e.home.tlink.de/haskell/ghc-6.10.4-autoconf.diff
01:54:24 <int-e> (the syntax error is that the generated configure script contains fifi instead of fi fi in some places, with autoconf 2.64)
01:58:10 <Baconizer> barg
01:58:21 <Baconizer> 10-second long powerout :P
02:06:33 <Baconizer> int-e: yea, but I installed from binary
02:06:38 <Baconizer> It's running now
02:06:41 <Baconizer> :D
02:06:46 <Baconizer> Thanks though
02:14:47 <Gilly> c_wraith: This is what was wrong:
02:14:50 <Gilly> > let subs [] = []; subs (x:xs) = (let s = subs xs in [[x]] ++ s ++ map (x:) s) in subs [1..4]
02:14:51 <lambdabot>   [[1],[2],[3],[4],[3,4],[2,3],[2,4],[2,3,4],[1,2],[1,3],[1,4],[1,3,4],[1,2,3...
02:16:15 <Gilly> This is the best implementation I got so far:
02:16:21 <Gilly> > let subs = concat . subs' where subs' [] = [[[]]] ; subs' (x:xs) = reverse $ foldl (\(z:zs) y -> map (x:) y : (z ++ y) : zs) [[]] (subs' xs) in subs [1..4]
02:16:22 <lambdabot>   [[],[1],[2],[3],[4],[1,2],[1,3],[1,4],[2,3],[2,4],[3,4],[1,2,3],[1,2,4],[1,...
02:16:51 <Baconizer> hrmm
02:16:56 <Baconizer> I installed GHC via binary
02:17:08 <Baconizer> Installing Haskell platform via source
02:17:15 <Baconizer> ./configure said everything was okay
02:17:20 <Gilly> I don't know if this can be made faster, though :) the reverse irritates me but I'm not sure if it decreases the performance
02:17:36 <Baconizer> make went without problems
02:17:43 <Baconizer> sudo make install returns:
02:18:03 <Baconizer> scripts/install.sh:
02:18:04 <Baconizer> Installing mtl-1.1.0.2...
02:18:04 <Baconizer> Error:
02:18:04 <Baconizer> The mtl-1.1.0.2/Setup script does not exist or cannot be run
02:18:04 <Baconizer> make: *** [install] Error 2
02:19:29 <Gilly> That implementation takes 6.6 secs on [1..24] and this implementation takes about 15 secs:
02:19:32 <Gilly> > let subs [] = [[]] ; subs (x:xs) = concatMap (\g -> g ++ map (x:) g) (groupBy ((==) `on` length) (subs xs)) in subs [1..4]
02:19:33 <lambdabot>   [[],[1],[2],[3],[4],[1,2],[1,3],[1,4],[2,3],[2,4],[3,4],[1,2,3],[1,2,4],[1,...
02:20:37 <Baconizer> :<
02:20:44 <Baconizer> :(
02:20:49 <Baconizer> D:
02:33:21 <eflister> i'm trying to build some intuition by using >>= on State directly.  i would think that "let sup = State (\x -> (head x,tail x)) in (return [1 .. 5] >>= sup >>= sup)" should return (2,[3..5])
02:34:13 <quicksilver> no, that's not how you inject the state
02:34:28 <quicksilver> also, your sup isn't the right type for >>= in the first place.
02:35:14 <quicksilver>  let sup = State (\x -> (head x,tail x)) in runState (sup >> sup) [1..5]
02:35:22 <quicksilver> > let sup = State (\x -> (head x,tail x)) in runState (sup >> sup) [1..5]
02:35:24 <lambdabot>   (2,[3,4,5])
02:35:28 <quicksilver> that's the answer you were after :)
02:35:36 <quicksilver> you have to use runState to inject the initial state.
02:35:51 <quicksilver> and sup is just an action, not a funciton, so you can't use >>= with it.
02:36:28 <eflister> huh, i don't get how the state is propagated if we use >>
02:36:44 <quicksilver> eflister: that is precisely the point of the state monad.
02:36:53 <quicksilver> eflister: it propagates the state behind the scenes.
02:38:11 <eflister> hmm.  having trouble following the src.
02:39:21 <eflister> where is s coming from in the def of return?
02:39:36 <int-e> it's lambda-bound.
02:39:52 <quicksilver> return x = State (\s -> (x,s))
02:39:53 <int-e> ultimately it's coming from runState and friends.
02:40:06 <quicksilver> so, "return" builds the state-modification-action which does not modify the state
02:40:11 <quicksilver> (and returns 'x' in the value place)
02:40:21 <int-e> (but that's getting ahead of us, because you need the definition of bind (>>=) to see that)
02:40:47 <quicksilver> eflister: the state monad is just convenient syntactic sugar to build functions of type (s -> s)
02:40:54 <quicksilver> and, also, functions of type (s -> (a,s))
02:41:00 <c_wraith> @src State (>>=)
02:41:01 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
02:41:07 <quicksilver> that is, functions which basically work over "s" and may or may not also return some other value.
02:41:48 <eflister> ok, i was looking at the src of >>=, but got confused and thought i should consider the simpler 'return' first.  :)
02:41:50 <quicksilver> "return x" is one of the simplest functions of type (s -> (a,s))
02:41:59 <quicksilver> I think your instincts are good.
02:42:03 <quicksilver> return is a simple case to look at.
02:42:54 <eflister> what would be an example of using >>= directly?
02:43:58 <quicksilver> get >>= \s -> put (s+1)
02:44:06 <Baconizer> When I try to do a make install, I get an error about how the mtl script does not exist or cannot be run (Debian x86, latest haskell platform)
02:45:29 <eflister> runState, etc made sense to me, but then i asked myself "why is this a monad?" (other than wanting to protect the state)
02:45:39 <quicksilver> monads are not necessary
02:45:45 <quicksilver> they're just a convenient set of combinators.
02:45:54 <quicksilver> the purpose of the state monad is to avoid explicitly threading the state
02:46:08 <quicksilver> which, among other things, helps you not accidentally refer to an old version of the state
02:46:19 <quicksilver> which is easy to do in s,s',s'',s''',s'''' style code.
02:46:47 <quicksilver> the state monad has no magic, and gives you no power you didn't already have. It's just a convenient (sometimes) set of combinators for building up functions.
02:47:17 <eflister> i think i got that part, now trying to understand how the monad combinators do this for us.
02:49:03 <ksf> eflister, by nesting lambdas.
02:49:42 <ksf> a chain of >>=s has a set data dependency order.
02:50:43 <eflister> ah, so the insight is that modifying state is sequential
02:51:02 <ksf> at the same time, the a -> m a style of functions prevent you from pattern-matching the m type, which prevents you from breaking the abstraction.
02:51:09 <Gilly> is there a monadic version of if available?
02:51:10 <ksf> eflister, yep.
02:51:22 <ksf> "sequece" isn't the right word for every monad, though.
02:51:31 <ksf> like, for example, Maybe.
02:51:36 <quicksilver> I don't think that's a good insight at all
02:51:39 <quicksilver> (sorry)
02:51:50 <quicksilver> state is no more sequential than functions normally are.
02:52:11 <eflister> well i meant that once you're thinking sequential, you're thinking >>= chains
02:52:31 <ksf> you could also be thinknig fold.
02:52:51 <quicksilver> if you would desribe "length . filter (>5) . map (+1)" as sequential
02:52:56 <quicksilver> then, yes, it's sequential.
02:53:30 <eflister> hmm, yeah.  seems like state could be defined in terms of fold.
02:53:51 <ksf> well that would make branching quite impossible.
02:54:10 <quicksilver> state could be defined in terms of functiosn.
02:54:12 <quicksilver> And, it is :)
02:54:33 <eflister> something like "fold [list of state transformations] init"
02:54:34 <ksf> the return value of a monadic action can influence later actions, that's the raison d'etre for them.
02:54:48 <ksf> otherwise we could just use Functors and Foldables for abstraction.
02:55:03 <eflister> why couldn't the state transformations branch?
02:55:14 <quicksilver> because lists don't branch.
02:55:40 <eflister> if one of the tranforms were "if blah then..."
02:56:01 <benmachine> eflister: what if it were, if blah then terminate?
02:56:06 <benmachine> or if blah then loop
02:56:15 <quicksilver> but the state monad can branch into a different part of the list
02:56:21 <quicksilver> [A,B,C,D]
02:56:26 <quicksilver> C can decide not to do D at all
02:56:29 <quicksilver> but instead do E,G
02:56:33 <Peaker> eflister: "fold [list of state transformations] init" is less powerful than the State monad combinators, because you have to pre-choose the list items, and not depending on the state
02:56:34 <ksf> it can even loop back to itself.
02:56:34 <quicksilver> that's why it's not just a list.
02:56:51 <Peaker> The State  *Applicative*  is very much like such a list :-)
02:57:17 <Peaker> At least, I'm pretty sure that it is :)
02:57:31 <eflister> yeah i had just run across applicative
02:58:49 <quicksilver> Peaker: yes, it is. The fundamental theorem of applicatives is that any expression can be rewritten in the form "f <$> sequence [A,B,C,D,E,F]"
02:59:00 <quicksilver> (although that's not quite how it's stated in the paper)
03:00:28 <quicksilver> (you have to be a bit precise about what "any expression" means, as well)
03:03:25 <Peaker> basically, I see Monads as dynamic Applicatives that get to choose which computation to do next based on previous results.  And Applicatives as static
03:06:22 <eflister> where is the spacesuit then?  :b  where is class MonadState declared?
03:07:02 <eflister> @src MonadState
03:07:03 <lambdabot> Source not found.
03:07:31 <ksf> eflister, see it as a good opportunity to write your first monad =)
03:07:46 <ksf> state is one of the most trivial ones.
03:07:46 <int-e> Control.Monad.State.Class
03:09:09 <jkff> I've been reading Monad.Reader Issue 14 today, and my brain completely exploded at the corecursive queue monad
03:11:08 <jkff> Has anyone also read it and succeeded in understanding what the hell is going on in that article? :)
03:14:42 <eflister> i think what i'm not getting is what all the \s's are binding to.  in the def of get, for example.  get doesn't take any parameters.  and yet it gets \s from somewhere.
03:15:36 <jkff> @src get
03:15:36 <lambdabot> Source not found.
03:15:53 <eflister>  get   = State $ \s -> (s, s)
03:16:17 <eflister> but     get :: m s
03:17:47 <Peaker> eflister: Each value of the State value *is* a function from state to ...  so the \s is in the value
03:17:48 <jkff> m = State s
03:17:48 <jkff> newtype State s a = State { runState :: s -> (a, s) }
03:17:48 <jkff> get :: State s s
03:17:48 <jkff> get = State { runState = \s -> (s, s) }
03:17:48 <jkff> What's wrong?
03:20:12 <Peaker> eflister: a state computation is a function from state to a result and a new state.  So a value of State would always have a \s -> .. in it.   following?
03:21:36 <Peaker> eflister: each such State value takes its state from the result tuple of a previous computation when bound to it. The entire State computation (or the first state computation in it, if you wish), takes its initial state from the execution, e.g:  evalState (a >>= f >>= g) thisGoesIntoAsState
03:21:41 <eflister> peaker: right, but what does it get applied to when i just write "get" -- where is the state coming from?
03:21:41 <eflister> i think so...
03:21:42 <eflister> just don't see where the functions are getting the state from, when they are running in the monad
03:22:41 <Peaker> eflister: the state is coming from either the previous state value's result tuple which is bound before the get, or the evalState, if the get is the first in the state bind chain
03:22:54 <jkff> Well... sum = \xs -> foldr (+) 0 xs. Where is the xs coming from?
03:23:23 <Peaker> eflister: The monad value is allowed to be "open to an argument", and not be determined yet.  The monad's value describes a *computation*, not necessarily a readily-available result. It may be made readily available only after applying it with an initial state to run from
03:23:57 <eflister> that all makes sense to me, but still feels like >>= is needed to chain the state along, whereas >> was the answer to my OP, because somehow the \s doesn't need to be dealt with explicitly
03:24:18 <jkff> No, >>= is needed to chain the result along
03:24:50 <jkff> If you look at the definition of >>= for State, you'll see that the state isn't thrown away even if the result is.
03:24:55 <Peaker> eflister: >> in the case of state just ignores the "a" result in the tuple, but it doesn't ignore the "s" result in the tuple, that's still chained as an input arg to the next computation
03:25:11 <Peaker> @src State (>>=)
03:25:11 <lambdabot> Source not found. You untyped fool!
03:25:33 <eflister> OH
03:26:35 <eflister> peaker's exp sovles it for me then, except i now have to re-learn >>.
03:26:39 <eflister> in my head it is "doesn't care what happened before"
03:27:50 <Peaker> State f >> State g = State $ \s -> let (_, s') = f s in g s'
03:28:13 <Peaker> take an s, give it to f, takes the result s', give it to g, hand out the final result
03:30:10 <Peaker> State x >>= g = State $ \s -> let   (r, s') = x s ; State y = g r    in  y s'
03:30:21 <eflister> is this specific to state tho?  >> is defined in terms of >>=, right?  so there's something about state's >>= that is violating my "doesn't care what happened before" rule?
03:30:33 <eflister> (when used by >>)
03:31:17 <Peaker> x >> y  =  x >>= \_ -> y
03:31:33 <Peaker> eflister: note that the right-hand arg for (>>=) is a function that ignores its arg which will be the "a", not the "s"
03:31:47 <Peaker> eflister: when using (>>) and (>>=) the "s" doesn't appear anywhere, only monadic result "a"s
03:32:05 <Peaker> eflister: only the implementation of (>>) and (>>=) and stuff like "get" and "put" see the "s"s
03:32:09 <Saizan> eflister: in which sense >> doesn't care about what happened before, in your view?
03:33:10 <eflister> well, "a >> b throws away the result from a" (in my head)
03:33:25 <Saizan> it throws away the result, but it keeps the side effects
03:33:34 <benmachine> eflister: but putChar 'x' >> return () still puts a char
03:33:45 <Saizan> and in the state monad the side effects are the transformation of the state
03:33:48 <Peaker> eflister: a >> b    still retains the state manipulations of "a"
03:33:49 <eflister> but i guess i have not been distinguishing monadic results from ...
03:33:54 <Peaker> eflister: like the IO >> examples
03:34:15 <eflister> yeah, i hadn't been thinking of side effects generally enough
03:34:29 <Saizan> eflister: if a >> b completely discared a you could just use b :)
03:34:40 <Daimonic> @src reverse
03:34:41 <lambdabot> reverse = foldl (flip (:)) []
03:34:58 <int-e> > [] >> return "It's all about side effects."
03:34:58 <Peaker> and (>>) would not exist, yeah
03:34:59 <lambdabot>   []
03:35:02 <int-e> > [1..10] >> return "It's all about side effects."
03:35:03 <lambdabot>   ["It's all about side effects.","It's all about side effects.","It's all ab...
03:35:54 <eflister> yeah, making sense now.  but still not seeing the mechanics of how s makes it through >>.
03:35:55 <benmachine> @src replicate
03:35:55 <lambdabot> replicate n x = take n (repeat x)
03:36:13 <benmachine> aw, not [1..n] >> return x
03:36:34 <Peaker> eflister: assuming State was type and not newtype, I could have   x >> y = \s -> let (_, s') = x s in y s'
03:37:24 <eflister> peaker: is that by substituting the def of >> with the src from state's >>=?
03:37:40 <Peaker> eflister: I just wrote that, but the substitution should end up the same
03:38:27 <Peaker> if (>>=) is:    x >>= f  =  \s -> let (r, s') = x s in f r s'
03:38:57 <Peaker> eflister: then calling (>>=) with a \_ -> some_state_computation       means that "f" will ignore its first arg, but still use its "s" arg (that is inside the "some_state_computation" value)
03:39:22 <Peaker> eflister: so only the first in the tuple's result is ignored
03:40:01 <Peaker> eflister: you can think of (>>=)'s right side argument, in the case of State, to be a function of 2 args. And when (>>) is defined as ignoring one, it still does not ignore the latter, which is the previous state, after all of the manipulations
03:41:15 <Peaker> eflister: following?
03:41:27 <eflister> still chewing..
03:42:03 <Peaker> If Haskell had a non-textual editor, I could press a button to switch from textual view to a pipeline view that would show these lambda's chained together nicely and graphically :)
03:42:36 <Peaker> Some things are best expressed with textual syntax, but some could really be understood more easily by graphic chaining
03:43:04 <jkff> Or by removing the "do" syntax
03:43:10 <int-e> eflister: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8102#a8102
03:43:32 <int-e> equational reasoning is fun :)
03:43:33 <Peaker> jkff: a lot of let bindings to build a chain (the result of removing "do") is much less readable than a nice graphic diagram
03:43:57 <Peaker> int-e: f r s'
03:44:16 <int-e> Right. Sorry about that
03:44:50 <int-e> (especially since that's the point of the exercise.)
03:44:59 <int-e> fixed it in an annotation.
03:45:08 <Peaker> oops, we both added?
03:45:09 <Peaker> heh
03:45:49 <eflister> right, all makes sense now.  working through that substitution was what i needed.  :)
04:00:54 <sunshine> Anyone online? Im new
04:01:01 <soupdragon>  hey
04:01:05 <soupdragon> I am online
04:01:15 <soupdragon> whats going down
04:01:39 <sunshine> Hey man hows it going? God dam all the other chats seemed empty, so Ive ended up in Haskell, even tho its not haskeel help i need
04:01:46 <sunshine> Haskell was last semester for me lol
04:01:50 <soupdragon> what other chats :p
04:02:06 <sunshine> O got in through some chatroom list
04:02:07 <soupdragon> I wont even go into what I had last semester...
04:02:16 <soupdragon> but let me say Haskell is a lot more fun
04:02:26 <sunshine> Haha, Im a first year, we did haskeel to start lol
04:02:41 <lilac> sunshine: so you're on a compsci course then?
04:02:42 <sunshine> Now in second sem, doing Java and SQL
04:02:53 <soupdragon> SQL is a lot like Haskell
04:02:54 <sunshine> Yer Software Engn
04:02:56 <Daimonic> @src transpose
04:02:57 <lambdabot> transpose []             = []
04:02:57 <lambdabot> transpose ([]   : xss)   = transpose xss
04:02:57 <lambdabot> transpose ((x:xs) : xss) = (x : [h | (h:t) <- xss]) : transpose (xs : [ t | (h:t) <- xss])
04:03:00 <soupdragon> it's really nice to program in
04:03:04 <lilac> which uni starts with haskell? that's pretty cool...
04:03:08 <sunshine> ANU
04:03:16 <Daimonic> :t transpose
04:03:18 <lambdabot> forall a. [[a]] -> [[a]]
04:03:42 <anders^^> lilac: chalmers does it too
04:03:51 <anders^^> (sweden)
04:03:58 <ksf> > transpose [[1],[2,3],[4,5,6]]
04:04:00 <lambdabot>   [[1,2,4],[3,5],[6]]
04:04:01 <sunshine> Well its an SQL question I have, we just started, I know this is haskell chat, anyone mind?
04:04:14 <ksf> > (transpose . transpose) [[1],[2,3],[4,5,6]]
04:04:15 <Daimonic> @src permutation
04:04:16 <lambdabot> Source not found. My mind is going. I can feel it.
04:04:16 <lambdabot>   [[1,3,6],[2,5],[4]]
04:04:21 <Daimonic> @src permutations
04:04:21 <lambdabot> Source not found. I feel much better now.
04:04:24 <Peaker> soupdragon: SQL is like a tiny tiny subset of Haskell with a poor syntax and too much uppercase :)
04:04:26 <soupdragon> sunshine what have you written so far with SQL
04:04:27 <ksf> > (transpose. transpose . transpose) [[1],[2,3],[4,5,6]]
04:04:28 <Ke> Helsinki university of technology used to have scheme as first course for cs students
04:04:29 <lambdabot>   [[1,2,4],[3,5],[6]]
04:05:01 <sunshine> Just little bits and pieces of queries, working with the MAX function atm
04:05:24 <sunshine> SELECT prodID, description, SUM(quantity)
04:05:24 <soupdragon> sunshine, you should write matrix multiplication and game of lifee
04:05:37 <soupdragon> sunshine, the beauty of there in SQL is stunning
04:05:39 <sunshine> Whoops, didnt copy and paste what I wanted
04:07:30 <sunshine> soup, did you get a private query from me?
04:07:59 <soupdragon> yeah sunshine
04:09:14 <sunshine> Actually can anyone help with SQL? This thread contains my question http://www.plus2net.com/forum/viewtopic.php?f=10&t=1753
04:10:31 <quicksilver> sunshine: No. this is a haskell channel.
04:10:39 <quicksilver> There are probably SQL channels, but this isn't one.
04:11:05 <quicksilver> there appears to be a #sql for example.
04:11:33 <opqdonut> shouldn't it be ##sql to be in line with the freenode naming conventions
04:11:42 <soupdragon> heh
04:12:38 <quicksilver> yes, I think it should, and that's what I tried first.
04:13:08 <quicksilver> but discussing what the channel should be called is even more offtopic and even less interesting :)
04:50:16 <philed> Does anyone have any idea what this quote might mean: "All implementations of Haskell are recognisably interpreters. (Some of them, notably HBC and GHC, use dynamic specialization techniques to achieve very good performance, but they’re still technically interpreters.)"?
04:50:34 <philed> It's from the comments of this blog post: http://cdsmith.wordpress.com/2007/07/29/37-reasons-to-love-haskell-playing-off-the-ruby-article/
04:50:36 <quicksilver> philed: sounds like misguided and/or false pedantry
04:51:08 <Peaker> philed: by that definition, I don't think there are any compilers at all
04:51:13 <quicksilver> philed: interpreter to compiler is a continuum, there is no hard line, but GHC is very much at the compiler end of the spectrum.
04:51:25 <philed> quicksilver: Is there some real pedantic definition of a compiler which would make all Haskell implementations interpreters?
04:51:42 <quicksilver> philed: it generates actual, real, opcode by opcode machine code with register allocation et al. That's pretty compilery.
04:54:45 <philed> quicksilver: That was my reaction, but judging by his/her other comments, they do not appear ignorant of Haskell. I was wondering if I was unaware of some definition of "compiler" which would disqualify GHC.
04:55:13 <quicksilver> sorear is generally a smart guy, yes.
04:55:19 <quicksilver> but I have not the faintest idea what he means.
04:55:29 <quicksilver> even smart people say stupid or wrongheaded things sometimes :)
04:58:00 <philed> quicksilver: Thanks. Just wanted a second opinion.
05:02:24 <malcolmw> technically, modern Intel processors interpret the native code that they run - they convert it from CISC to some RISC-like instruction set internally
05:02:37 <matsuura> 壺＿壺
05:02:53 <quicksilver> amiddelk:
05:03:09 <amiddelk> quicksilver: ?
05:03:15 <quicksilver> malcolmw: another example of the dangerous adverb "technically"
05:03:20 <quicksilver> amiddelk: sorry, mis-tab
05:03:27 <amiddelk> no problem :)
05:03:31 <matsuura> please teach me
05:03:45 <quicksilver> malcolmw: you could call that "interpretation". But you could call the normal operation of a CPU "interpretation" anyway.
05:03:48 <Makoryu> matsuura: Hi. What are you trying to learn?
05:03:55 <quicksilver> malcolmw: what is a CPU if not a hardware interpreter for its opcodes?
05:04:05 <quicksilver> malcolmw: I think it's quite hard to form meaningful distinctions.
05:04:18 <quicksilver> it's all just shades of mauve.
05:04:34 <malcolmw> all compilation is staged in ways we are barely aware of
05:04:37 <int-e> Maybe implementing one's own stack and relying on GC makes an interpreter.
05:04:49 <matsuura> Makoryu: I am trying to learn all nihongo
05:04:55 * int-e would be more curious about what's supposed to be dynamic about ghc's specialisations.
05:05:13 <quicksilver> malcolmw: agreed.
05:05:17 <matsuura> Makoryu: however, there are too many questions I have unanswered and my teacher doesn't understand my questions
05:05:28 <matsuura> Makoryu: and my book doesn't explain very well
05:06:03 <quicksilver> malcolmw: your ALU may have a microcode, your FPU may have a (notionally distinct) microcode, and the CPU may re-order/translate source opcodes into those.
05:06:17 <quicksilver> malcolmw: no doubt there will be MMUs with microcode, or already are.
05:06:37 <philed> int-e: Or being under the control of a runtime. I would go with quicksilver though and say it is all pretty blurry.
05:06:57 <philed> If we allow that translation to intermediate bytecode is also compilation, then GHC doesn't have an interpreter.
05:07:44 <mmorrow> woohoo, tcc just got (rudimentary) x86_64 support! just wrote a repl frontend http://moonpatio.com/repos/tcci/ metacircular C with hard code and no tmp files!
05:07:49 <philed> int-e: Dynamic partial evaluation?
05:08:10 <int-e> hmm, perhaps
05:08:42 <quicksilver> philed: GCC is then, an interpreter.
05:08:45 <mmorrow> ah nice, seems like this is currently on-topic-ish too
05:08:46 <quicksilver> philed: witness, libcrt.a
05:09:59 * Makoryu peers into mmorrow's code, then withers and dies upon gazing into the macros of eternity
05:10:05 <quicksilver> philed: of course taht depends what you meant by "under control of"
05:11:33 <mmorrow> Makoryu: hehe
05:12:06 <mux> tcc isn't dead? wow.
05:25:53 <Daimonic> I want to write a bracket test and I remember I nicely workaround which filters everytime the input string for a "()"-Pair
05:26:03 <philed> quicksilver: Yeah, I think it would start getting fuzzy there as well. What's libcrt, by the way?
05:26:10 <Daimonic> howiever I don't know how to write the (a -> Bool) function
05:26:16 <Daimonic> sth. like elemen "()" xs
05:26:25 <Daimonic> elem "()" xs*
05:27:30 <quicksilver> philed: the C Run Time library
05:27:37 <philed> int-e: My guess is that partial specialisation means emitting monomorphic functions from polymorphic functions as an optimisation. As I understand, F# always does this when a polymorphic function is declared inline.
05:27:58 <philed> quicksilver: Thanks.
05:28:03 <quicksilver> Daimonic: elem is for single elements.
05:28:08 <quicksilver> Daimonic: "()" is two elements
05:28:12 <Daimonic> jep, that's the point
05:28:13 <quicksilver> assuming you're talking about String.
05:28:20 <matsuura> can someone help me with my japanese?
05:28:28 <Daimonic> sure - but I cannot remember how we did it back then
05:28:30 <quicksilver> matsuura: this channel is for discussing Haskell.
05:28:35 <quicksilver> you should discuss japanese somewhere else.
05:28:36 <matsuura> quicksilver: true
05:28:42 <Daimonic> or sth. like delete () out of the string
05:28:43 <matsuura> I need help though
05:28:44 <matsuura> :(
05:28:50 <int-e> philed: but there's nothing dynamic about that in my mind
05:29:38 <philed> int-e: Maybe it does it at runtime based on usage?
05:29:38 <quicksilver> Daimonic: if you're trying to handle nesting correctly, it's not trivial.
05:29:45 <philed> Totally guessing.
05:30:01 <quicksilver> that would certainly be dynamic, philed
05:30:09 <quicksilver> but none of the haskell implementations we're talking about do that.
05:30:21 <quicksilver> GHC erases all types.
05:30:46 <quicksilver> (which incidentally, is a strong argument to call it a compiler not an interpreter - its erasing the key properties of the source language)
05:31:31 <philed> quicksilver: Good point.
05:31:57 <quicksilver> mind you, I think that ghci's interpreter is also type-erased :)
05:32:39 <int-e> and arguably it's not a haskell interpreter but a bytecode interpreter
05:32:41 <lilac> i'm confident professor futamura would argue that a specializing interpreter /is/ a compiler
05:33:36 <Milo-> according to RWH, Tail recursion happens in constant space, but why does 'lenList (x:xs) = 1 + lenList xs' crash for stack overflow with big lists?
05:33:46 <quicksilver> Milo-: because that's not tail recursion.
05:33:56 <Milo-> how so?
05:34:02 <quicksilver> tail recursion looks like this:
05:34:03 <Milo-> that seems like a tail recursion to me
05:34:11 <quicksilver> f (x:xs) = f (something)
05:34:25 <quicksilver> it has to return a call to 'f'.
05:34:54 <mmorrow> quicksilver: ghc erases types, then ghci has to walk the heap similar to vacuum, and try to re-deduce the types of things (but at this point it's not 100% tractable)
05:35:07 <quicksilver> lenList acc (x:xs) = lenList (acc+1) xs
05:35:09 <mmorrow> it seems like shooting yourself in the leg
05:35:13 <quicksilver> ^^ that's tail recursive, milo.
05:35:23 <quicksilver> mmorrow: why does ghci have to try to re-deduce the type of things at all?
05:35:24 <Milo-> quicksilver oh
05:35:26 <mmorrow> then wrapping it in bandaids
05:35:44 <mmorrow> quicksilver: for ":t" and future bindings
05:35:53 <mmorrow> i'
05:36:07 <mmorrow> m not positive though on /exactly/ why
05:36:11 <quicksilver> surely :t is a static thing, not dynamic.
05:36:19 <quicksilver> it can just use the type-checker
05:36:32 <quicksilver> it operates on source strings, not object values
05:36:40 <mmorrow> quicksilver: yeah, i'm getting confused now. /me finds the helpful comment in the code that does this
05:36:49 <quicksilver> I can believe it tries to do it for the debugger, or something
05:36:54 <Saizan> it does so for the debugger
05:36:57 <Milo-> quicksilver that still gives stack overflow :o
05:37:03 <quicksilver> Milo-: it does, yes.
05:37:06 <quicksilver> Milo-: for a different reason now.
05:37:10 <mmorrow> yeah, for the debugger, although iirc ghci needed this too i thought
05:37:16 <mmorrow> but maybe it's just for the debugger
05:37:18 <quicksilver> Milo-: the recursion operates in constanct space
05:37:27 <Milo-> quicksilver oh, but?
05:37:38 <quicksilver> Milo-: but you build a very big (1+(1+(1+(1+(1+(1+...))))))) thunk on the heap
05:37:39 <quicksilver> which is fine
05:37:45 <Milo-> ah
05:37:45 <quicksilver> but your stack overflows when you try to evaluate it.
05:37:57 <quicksilver> this is when laziness hurts.
05:38:08 <quicksilver> if you had compiled that code, it would have worked out that parameter is used strictly
05:38:10 <Milo-> ah, so is there a way around it?
05:38:16 <quicksilver> and the optimiser would have solved the problem.
05:38:28 <quicksilver> otherwise, you use seq to make it strict
05:38:43 <quicksilver> lenList acc (x:xs) = acc `seq` lenList (acc+1) xs
05:39:23 <Milo-> great, that works, it's slow, but it works
05:39:54 <quicksilver> GHC has an extension call BangPatterns which gives you a different notation for strict parameters
05:40:02 <quicksilver> lenList !acc (x:xs) = lenList (acc+1) xs
05:40:14 <mmorrow> quicksilver: (i'm searching for that comment, but) what's unfortunate though about erasing types (in the interpreted/dynamic setting) is that there's no way to tell the type of some arbitrary closure given just a ptr to it (say it just came in over the network, and the library containing the datatype it's made of isn't even installed on this system, let alone linked in to the current proc)
05:40:23 <quicksilver> although in some respects I think it's more helpful as a learning process to just learn what seq does
05:40:49 <quicksilver> mmorrow: but in the context these systems are designed for, you never need to, because types are determined statically
05:40:52 <mmorrow> well, i'm not sure actually what i'm after though in thinking about this.
05:40:59 <quicksilver> mmorrow: so you always know what type you're expecting.
05:41:08 <quicksilver> obviously there *are* advantages to RTTI though.
05:41:43 <mmorrow> quicksilver: totally. so trying to use them for other interesting possibilities runs into fundamental problems
05:42:03 <quicksilver> but RTTI-everywhere is a non-trivial overhead.
05:42:13 <quicksilver> just ask anyone who's written a compliant C++ compiler
05:42:21 <mmorrow> oh definitely. i just mean "when you need it"
05:42:28 <quicksilver> Oh, hang on, you can't. They've all gone totally stark raving mad.
05:42:31 <mmorrow> ".. to do what you intend at all"
05:42:38 <Daimonic> is there no filter possibility to filter one pair of () ?
05:42:39 <quicksilver> writing a compliant C++ compiler is basically fatal.
05:42:47 <mmorrow> haha
05:43:21 <Ke> but stroustrup says C++ isn't inherently slower =o(
05:43:32 <Ke> !
05:44:01 <Makoryu> quicksilver: I guess Walter Bright is a zombie, huh?
05:44:15 <quicksilver> Ke: in *principle* the compiler can deduce (conservatively) where RTTI is actually going to be used, and only pay the cost of the overhead in those cases where the user uses it.
05:44:16 <Deewiant> It's not fully compliant
05:44:24 <Deewiant> (Where "It" == "DMC")
05:44:45 <Makoryu> Deewiant: Ah, that's how he cheated death
05:45:10 <mmorrow> quicksilver: i dunno, i don't really have a 100% clear idea of what i'm thinking of quite yet, but consider the case where you're in haskell code, and you're given a [(Int,[(String{-C/asm label of closure-},[Int{-ptrs-}],[Word])]]. so you have two options if you want to reify that graph
05:45:11 <Deewiant> I don't think any compiler is fully compliant
05:45:13 <quicksilver> Ke: GHC takes a rather simpler conservative approach and ties the generation of RTTI information to a typelcass.
05:45:16 <Deewiant> Except maybe Comeau
05:45:23 <quicksilver> if you mention Typeable, the dictionary gets generated there.
05:45:31 <quicksilver> it's actually a very elegant solution to some parts of the problem.
05:46:04 <quicksilver> mmorrow: sure, but you're talking about trying to build an introspection tool for a staged, type-erased, compiled language.
05:46:09 <quicksilver> mmorrow: nobody said that was going to be easy ;)
05:46:25 <quicksilver> mmorrow: that's why we need people like you, who aren't put off by it being impossible and just do it.
05:46:32 <mmorrow> (1) being to build it in some (malloced or pinned) memory buffer, then one way or another get the current addresses of the info tables for those closure types (the label is deducible from the original pkg/mod/con name), then apply relocations yourself
05:46:59 <Ke> I though typeclasses work like templates with type inference
05:47:19 <mmorrow> or (2) fabricate entirely new info tables (you have all the info you need), write them to mem with the closures. the thing here though is that info tables also have executable code, which you'd also need to fabricate
05:47:45 <quicksilver> Ke: not really, no.
05:47:59 <mmorrow> quicksilver: doable for sure :)
05:48:01 <quicksilver> Ke: templates are like macros, which generate new code for each instance
05:48:18 <quicksilver> Ke: typeclasses are about being able to use the same code for different instances.
05:48:54 <Ke> sounds difficult
05:49:20 <Makoryu> Typeclasses are essentially vtables under the hood, aren't they?
05:49:50 <quicksilver> they might be.
05:49:57 <quicksilver> that's not the only way you can implement them.
05:50:11 <quicksilver> but note that templates are not vtables :)
05:50:29 <quicksilver> typeclass methods don't have to be functions, either.
05:51:51 <pozic> quicksilver: how can a type-class method not be a function? Unless, you consider a constant not to be a function.
05:52:58 <quicksilver> type-class methods might have the type String, or IO(), or Monoid m => Writer m (Data.Sequence.Seq (Data.Tree.Tree Int))
05:53:02 <quicksilver> none of which is a function.
06:00:09 <pozic> Some teachers of functional programming say that '5' is the function which returns 5, but I can certainly see how you would not see that as a function. It's a uninteresting language detail.
06:00:47 <Raevel> i would not call 5 a function :-o
06:01:14 <Raevel> what's their definition of one?
06:03:35 <philed> pozic: In logic, constants are sometimes defined as a 0-argument function, but I don't think that's appropriate for anything based on lambda calculus.
06:04:15 <philed> For starters, in pure lambda calculus, all functions have exactly one-argument.
06:05:29 <Raevel> in pure lambda calculus, 5 would be represented as a function though :-)
06:06:17 <mux> in pure lambda calculus, 5 doesn't exist!
06:06:58 <Raevel> in soviet russia, lambda calculus applies you
06:07:04 <philed> mux: It's a Church numeral.
06:07:06 <mux> hahaha.
06:07:22 <mux> philed: yes, but it's not 5 ;-)
06:08:01 <philed> mux: Platonist!
06:08:15 <mux> I admit that
06:11:50 <Raevel> well in that case 5 occuring anywhere in a computer is arguably not 5, just a representation, perhaps not too helpful to put it that way
06:11:51 <lilac> quicksilver: surely a type class (as opposed to an instance) can't have a method of type String or IO ()?
06:12:22 <lilac> don't the method types have to contain at least one instance of each parameter to the type class itself (modulo functional dependencies)?
06:12:51 <lilac> </nitpick>
06:16:22 <Raevel> to sum things up, "is 5 a function?" devolved into platonism. this is #haskell, folks?
06:25:51 <Philippa> pozic: considering a constant of non-function type to not be a function pretty much comes under "well duh" in haskell
06:26:08 <Philippa> you have to be using a notion of function taken from another context entirely for it to possibly make sense
06:32:41 <DrSyzygy> OTOH, if you want to talk about the platonic Hask category, viewing constants as functions () -> a _is_ helpful. It's not going to be how it's represented, but it is going to help with the formalism.
06:32:57 <DrSyzygy> Hrm. morphisms () -> a, I mean.
06:39:42 <williamwho> In "The haskell road to logic, math and programming" from 2004 they write "Haskell, a member of the Lisp family"
06:40:02 <williamwho> which part of Haskell do they refer to?
06:40:08 <matsuura> none
06:40:13 <blackdog> grandad lisp
06:40:28 <quicksilver> people quite often ask about that sentences
06:40:35 <quicksilver> it is a peculiarly poor choice of words.
06:40:49 <williamwho> but the book is meaningful otherwise?
06:40:49 <blackdog> always sitting in the chair, complaining about uncle Hindley and talking about carving his own cons cells
06:41:01 <williamwho> blackdog: :)
06:41:02 <quicksilver> I"m not sure, I've never seen the book :)
06:41:18 * blackdog is starting to get delirious, probably time to go to bed...
06:41:39 <quicksilver> lilac: true, but you can encode it in trivial ways
06:41:45 <quicksilver> lilac: (a,String) for example
06:42:06 <quicksilver> lilac: or Second a String where data Second a b = MkSecond b
06:42:38 <philed> williamwho: Might be historical. ML was written in Lisp by people with similar goals and part of the same academic community.
06:43:48 <williamwho> philed: actually I also imagined "a coupld possible meanings" but is is a pretty unfortunate wording
06:43:50 <williamwho> Tim Sweeneys annual "we need pure FP for game engine coding" happened again and on LtU they asked "who will write the language". I thoughts efforts like Manuel Chak.'s are going in the right direction?
06:43:53 <Peaker> philed: was an ML compiler written in Lisp, or an interpreter?
06:44:17 <blackdog> williamwho: he keeps rewriting the DSL :)
06:44:32 <Peaker> Tim Sweeney refines his game engine slides?
06:44:36 <williamwho> blackdog: I see.
06:44:42 <Peaker> I like his slides that I saw a while ago
06:45:04 <blackdog> i've been chasing the PLS guys about the CUDA bindings for ages - Sean Lee apparently had his own set that never got released, and now Trevor's got something going, but nothing public
06:45:08 <williamwho> Peaker: actually the id Tech 5 slides also talk about "stateless" etc. etc.
06:45:16 <Peaker> williamwho: where is that?
06:45:23 <williamwho> Peaker: the id one?
06:45:28 <philed> Peaker: Not sure. But I'm fairly sure Milner's first ML was written in Lisp. But any decent ML nowadays should be written in ML, of course.
06:46:08 <Peaker> philed: Unless you love Haskell as a general-purpose language, and think ML is appropriate for some special purpose (not compiler writing)
06:46:15 <williamwho> oh and AMD releasing Cuda or was it OpenCL for x86. oh man, this is getting funny. I guess OpenCL is supposed to work on highly parallel general purpose CPUs
06:46:29 <Peaker> I haven't tried ML, but I think any statically typed language without type-classes is one I'd probably not want to use
06:46:44 <williamwho> http://s09.idav.ucdavis.edu/talks/05-JP_id_Tech_5_Challenges.pdf
06:46:50 <quicksilver> the lack of type classes is not really the problem I have with ML.
06:46:56 <quicksilver> it's the lack of purity that upsets me.
06:47:03 <quicksilver> and on a more trivial level, the value restriction.
06:47:11 <Peaker> that would bother me greatly too, after Haskell exposure :)
06:47:14 <blackdog> Peaker: I think ML modules are pretty powerful - didn't chak prove you could reduce one to the other?
06:47:14 <quicksilver> (which is actually not unrelated to the impurity)
06:47:28 <quicksilver> blackdog: yes, but you can reduce both ML and haskell to lisp
06:47:29 <philed> Peaker: ML's module system is pretty powerful, but doesn't allow you to do any overloading.
06:47:40 <quicksilver> blackdog: reducing things to each other doesn't really say much about their practical utility.
06:47:52 <quicksilver> not that it wasn't an interesting result.
06:47:55 <Peaker> blackdog: I am not sure. Its likely that you could, by explicit type-class passing/etc. But that sounds like a lot more effort
06:48:55 <blackdog> Peaker: i think it was a reasonably natural reduction, but i could be wrong, it's been a while
06:52:22 <mmmulani> if I have a base case for f _ (1,a,b) = (a,b)
06:52:28 <mmmulani> how is this definition improper:
06:52:29 <mmmulani> f (a,b,c) (d,e,f) = f (d,e,f) (mod a d, b - ((quot a d)*e), c - ((quot a d)*f))
06:52:59 <quicksilver> well, do you get an error when you use it?
06:53:00 <philed> Peaker: Ocaml's also got an impressive object system with structural subtyping. I haven't used it much though.
06:53:26 <Peaker> philed: what kind of "object system"? the typical boring single-dispatch?
06:53:30 <mmmulani> quicksilver: yeah, ghc thinks that I'm applying f to too many arguments
06:53:49 <quicksilver> mmmulani: you have two 'f's
06:53:57 <mmmulani> whoa
06:54:02 <quicksilver> mmmulani: one, the function you are defining, and one the third component of its second argument
06:54:08 <Makoryu> Peaker: OCaml implements statically checked duck typing
06:54:20 <quicksilver> mmmulani: that will make the universe implode.
06:54:26 <mmmulani> quicksilver: ahahahaha thanks a lot :P
06:54:27 <philed> Peaker: Yep. What's interesting about it is that it's statically inferred but supports structural subtyping.
06:54:54 <quicksilver> and don't forget the polymorphic variants, too.
06:54:56 <mux> structural subtyping seems like the only sane way to implement subtyping to me
06:54:56 <Peaker> Makoryu: Which is kind of like unspecified type-classes, I guess?
06:55:02 <quicksilver> for another kind of subtyping.
06:55:17 <Peaker> damn. learning Haskell before ML OCaml sucks. Now I can't learn ML/OCaml without being discouraged that they suck
06:55:26 <philed> If I write foo x = x#bar then x is automatically typed as an object which supports some method bar and possibly other methods.
06:55:36 <Peaker> same goes to Scala and a few others
06:55:52 <Peaker> Learning Haskell killed any chance of being motivated about learning those others
06:56:35 <quicksilver> and if you write foo x = `Bar x, then it's typed as a variant which supports the constructor Bar and possibly other constructors.
06:56:47 <quicksilver> although I probably have the syntax not quite right.
06:57:06 <Makoryu> Peaker: Work in C++ for a while (without so much as glancing at Haskell code) and you'll be back in business learning lesser languages than Haskell ;)
06:57:33 <Makoryu> That is, just about anything will be a breath of fresh air
06:57:43 <Peaker> Makoryu: heh, I can't go back to that. its hard to use Python anymore without seeing all those Maybes and binds I'm constantly writing manually
06:57:55 <philed> quicksilver: No, that's right.
06:58:03 <Peaker> "Now I'm writing a manual fold". "Now I'm writing a Maybe bind". and so on
06:58:13 <Peaker> that's how it feels to write Python now
06:58:23 <quicksilver> Peaker: ocaml has a lot of interesting innovations in the type system which are worth learning about.
06:58:38 <quicksilver> Peaker: and ML signatures/functors are also worth learning about - they're not ocaml-specific, they're standard ml
06:58:52 <quicksilver> the things which bother me about ocaml are mostly trivial annoyances.
06:58:57 <quicksilver> (and the impurity)
06:59:14 <Peaker> quicksilver: I guess I'll add it to a huge mental todo list
06:59:18 <philed> quicksilver: The minor and pointless syntactic differences between Ocaml and SML really annoy me.
06:59:33 <quicksilver> philed: I think they annoyed me too but I've forgotten all about them now.
07:00:01 <Makoryu> philed: Stuff like the precedence of the semicolon, and the use of (~) for negation instead of (-)?
07:00:33 <philed> quicksilver: And I would prefer it if Ocaml was based on images (especially since I use it for interactive theorem proving), had proper concurrency support, and implemented reflection.
07:00:54 <quicksilver> philed: reflection is mostly just a temptation to sin.
07:01:03 <quicksilver> languages without reflection cause you to be worthy.
07:01:07 <quicksilver> force you, even.
07:01:24 <philed> Makoryu: IIRC, they exchange :: and : and exchange , with ;.
07:01:32 <philed> But I might be thinking of Ocaml versus Haskell.
07:02:20 <Peaker> Haskell sort of has reflection, with Typeable
07:02:23 <Makoryu> philed: You are
07:03:26 <philed> Makoryu: Okay, here's one: fn versus fun.
07:03:40 <Peaker> clearly one of those languages abhors fun
07:03:52 <Makoryu> philed: I actually don't remember what that does in either of them.
07:03:58 <Makoryu> Lambda notation?
07:04:05 <philed> Makoryu: Yeah.
07:05:02 <Makoryu> Hmm, SML uses [,] for lists
07:05:10 <Makoryu> Weird
07:05:11 <philed> quicksilver: You might be right about the reflection thing, but I like it for writing debugging and interactive tools. I never use it in the actual release code (when working in Lisp anyway).
07:05:54 <quicksilver> philed: I was half-joking.
07:05:58 <mxc> there are a few upsides to ocaml..  but the object system is not one of them
07:06:17 <quicksilver> philed: but it *is* true that in languages with reflection, anecdotally, I see it abused more often than it's well-used, IYSQIM.
07:06:34 <mxc> the module system and polymorphic variants are quite nice
07:06:42 <quicksilver> philed: reflection breaks abstraction, which makes it a nasty thing to have in your core language.
07:06:54 <mxc> also, the built in, FAST binary marshalling is nice
07:07:01 <mxc> Data.Binary is great, but not there yet
07:08:11 <philed> mxc: I also haven't been able to find any build tools that I'm happy with. Most libraries are built with autoconf. We need something like cabal standardised.
07:08:30 <mxc> i forget what we used
07:08:33 <mxc> i think it was omake?
07:09:09 <mxc> but we didn't distribute anything, it was all used internally, so something like cabal would have been nice but it was manageable w.out it
07:09:21 <mxc> i think ocaml code tends to be more readable by non experts
07:10:54 <mxc> than haskell
07:11:48 <quicksilver> is that likely to be a fact about the language, though, or just about the people that tend to use it for whatever reason?
07:12:04 <Makoryu> OCaml has too many keywords flying in all directions
07:12:38 * Axman6 dismissed ocaml when he saw that @@ was used for concatenation
07:12:56 <quicksilver> Axman6: :P
07:13:14 <Makoryu> It's like someone put a tornado in a language grammar factory and wrapped the whole thing in duct tape in the general resemblance of ML
07:13:19 <Peaker> Languages which offer less abstractions will be more readable by non-experts, but less readable/writable by experts
07:13:37 <mxc> true
07:13:43 <mxc> oops
07:15:02 <Peaker> using (>>=) on your Maybe type means your readers need to know a lot more than an explicit if/else checking for Nothing/Just which is an abstraction more widely known (if less appropriate here)
07:16:47 <mxc> thats true
07:16:48 <philed> Peaker: I use Extlib.Option.map on my Option types in Ocaml.
07:17:03 <Peaker> philed: that sounds like fmap, not (>>=)?
07:17:20 <philed> Peaker: It is the equivalent of fmap, without the overloading.
07:17:30 <philed> Peaker: Sorry, misunderstood.
07:17:30 <lilac> our C++ library includes a type isomorphic to Maybe. when we start using c++0x with its (crippled) lambdas i fully intend to give it a bind operator
07:17:50 <Peaker> philed: do they have the equivalent of (>>=) without the overloading?
07:18:01 <philed> Peaker: Hang on. Isn't (>>=) exactly the same as fmap?
07:18:04 <lilac> for now it's (x && foo(*x))
07:18:15 <Peaker> philed: nope
07:18:20 <Peaker> @src Maybe fmap
07:18:20 <lambdabot> fmap _ Nothing       = Nothing
07:18:21 <lilac> or rather x ? foo(*x) : Nothing
07:18:21 <lambdabot> fmap f (Just a)      = Just (f a)
07:18:23 <Peaker> @src Maybe (>>=)
07:18:23 <lambdabot> (Just x) >>= k      = k x
07:18:23 <lambdabot> Nothing  >>= _      = Nothing
07:18:57 <Peaker> lilac: Well, that probably won't scale nicely
07:19:01 <quicksilver> >>= is fmap followed by join.
07:19:09 <quicksilver> (in all monads)
07:19:15 <lilac> philed: flip fmap :: (a -> b) -> (f a -> f b), flip (>>=) :: (a -> f b) -> (f a -> f b)
07:19:27 <lilac> they're both lifts in some sense, but the latter is more general
07:19:29 <Peaker> lilac: no flip on fmap there
07:19:39 <lilac> Peaker: oops, yeah, good catch :)
07:19:51 <Peaker> lilac: the latter is more powerful, less general, is the usual way to describe generality, no?
07:21:14 <lilac> Peaker: i'm not sure. in common parlance, if an object can be used for all the things another object can be used for, and more, then the former object is more general
07:21:41 <lilac> i'm often confused when people say 'this is more general' when the 'this' seems more specific to me :-)
07:22:23 <Peaker> lilac: I guess it depends on what "used" means. Functor is more general because it has more instances that "use" it.  I don't think I've seen Monad be categorized as more general than Functor anywhere
07:22:32 <Peaker> Functor vs. Monad there
07:22:59 <lilac> yeah, the /type/ of fmap is more general (in that it has more inhabitants), but an /instance/ of (=<<) is arguably more general than one of fmap for the same Monad
07:23:06 <Peaker> I think that a type-class is more "general" if it provides less power, so more types can be instances
07:23:21 <lilac> yeah, i'd agree with that
07:24:10 <Taejo> @hoogle Char -> Int
07:24:11 <lambdabot> Data.Char digitToInt :: Char -> Int
07:24:11 <lambdabot> Data.Char ord :: Char -> Int
07:24:11 <lambdabot> Data.ByteString.Char8 count :: Char -> ByteString -> Int
07:24:12 <Rotaerk> x is more general than y if y can be implemented in terms of x, but x can do more
07:24:38 <lilac> Rotaerk: i like that definition. So Monad is more general than Functor, but (>>=) is more general than fmap
07:25:16 <lilac> or at least ((>>=), return) is more general than fmap
07:26:12 <Peaker> lilac: Why not say "more powerful" instead?
07:27:08 <Rotaerk> "more powerful" and "more general" tend to be used synonymously IME
07:27:33 <Peaker> I think they're really opposites in these cases
07:28:15 <jkff> Hi folks. Anyone know about which languages have relatively developed effect systems? I know of Disciplined Disciple Haskell, and Java's checked exceptions also probably count to an extent. Haskell type system magic together with monads can be used to emulate them somewhat, too.
07:28:29 <Taejo> that reminds me of my crypto lecturer, who uses "in general" in the normal sense during mathematics lectures :(
07:29:09 <lilac> Taejo: as in, "usually but not always"?
07:29:17 <Taejo> lilac: yes
07:29:44 <lilac> jkff: i think i read that Clean has something like that
07:30:09 <jkff> Apart from its uniqueness types?
07:30:58 <mmorrow> i think a good definition for "A is more general than B" is "A ==> B, but not conversely"
07:31:15 <mmorrow> Monad implies Functor
07:31:25 <Rotaerk> define "implies"
07:31:39 * EvilTerran reads "is more general than" as "includes all the types of", in the case of typeclasses
07:31:41 <mmorrow> "m is a monad" ==> "m is a functor"
07:32:23 <EvilTerran> superset of values, rather than behaviours
07:32:39 <Rotaerk> mmorrow, that doesn't encapsulate all "more general than" relationships
07:33:29 <jkff> lilac: Briefly looking through The Clean Manual 2.1 TOC didn't reveal anything that'd look like an effect system to me..
07:33:30 <Rotaerk> take for instance functions f and g, f operates on a superset of the domain of g, and for all x in g's domain, f x == g x
07:33:44 <mmorrow> Rotaerk: well, i guess it depends on your definition of "is a" in the general ;) case
07:33:52 <lilac> jkff: perhaps i was just thinking of the uniqueness types then, sorry
07:34:41 <mmorrow> Rotaerk: so,  f : A -> C, and  g : B -> C,  where  B `subset` A
07:34:45 <jkff> I wonder why effect systems are so much underused
07:34:46 <lilac> i find it interesting that different people here have precisely opposite notions of 'more general than'
07:34:47 <Rotaerk> mmorrow, "is a" doesn't usually include functions that are supersets of one-another
07:35:29 <Rotaerk> mmorrow, to say that A is more general than B, if B is-a A, but then the meaning of "is-a" is loose... so you haven't really gotten anywhere
07:35:30 <lilac> i suppose that's because 'A is more general than B (A has more implementations than B)' <=> 'B is more general than A (B can be used in more situations than A)'
07:36:13 <mmorrow> Rotaerk: sure it does. "is a" means (==>), both of which are really just particular ways of saying (->) in whatever category we're talking in
07:36:30 <mmorrow> so, "more general" is (->)
07:36:32 <jkff> As I understood from DCiPL, explicitly typed effects are very verbose, so one needs effect inference for an effect system to be of any practical use (as is in the case of DDC). However, that should not be an unsurmountable kind of complication .
07:36:42 <lilac> i suggest the former meaning be called 'larger' as in 'Functor is larger than Monad' and the latter be called 'more useful' as in 'Monad is more useful than Functor'
07:36:55 <Rotaerk> oh you must be referring to some mathematical domain as your context
07:37:01 <Rotaerk> category theory?
07:37:16 <Rotaerk> haven't really read anything about that
07:37:28 <jkff> 'more useful' can be understood in two opposite ways, too. A more general concept  is more useful because it can be used in more contexts, but a more specific is more useful because it can do more by itself
07:38:47 <mmorrow> Rotaerk: all that fancypants talk means is that say we're considering a particular situation where we have some A and some B, and it's the case that "A -> B" for some choice of "->"
07:39:31 <Rotaerk> mmorrow, my point is that you're delegating the definition of "more general than" to "->" without actually defining "->", and thus you've not actually defined anything
07:39:40 <quicksilver> he's been celverer than that
07:39:51 <quicksilver> he's chosen a definition of "->" which automatically includes "<-"
07:39:58 <quicksilver> so both arguments are therefore equally valid :)
07:45:09 <mmorrow> Rotaerk: and of course, down is up if you're standing on the ceiling
07:47:36 <Rotaerk> mmorrow, there's a difference between the definition of down depending on the orientation of the observer, and the definition of "more general than" being *equivalent to* that of -> (whatever that definition may be)
07:48:37 <goomba> down should always be the empty whatever
07:57:42 <mmorrow> Rotaerk: but "ceiling" is relative to you, viewing yourself standing on it, in which case your up is your imaginary self's down and vice-versa (to beat the metaphor like a dead horse:)
07:58:56 <mmorrow> Rotaerk: and the map (here manifested by your imagination) from you to your imaginary self is the dualizing functor
08:00:07 <mmorrow> but yeah, everything seems to get circular when trying to map words to concepts, because words seem to usually have some assumed absolute orientation
08:02:21 <mmorrow> so then the determination of which direction the "->"'s pointing in depends on your choice of what constitutes "more" of something, which in turn depends on which direction the "->" is pointing in..
08:06:34 <RyanT5000> I'm having this problem with cabal: cabal: 1: openFile: does not exist (No such file or directory)
08:06:49 <RyanT5000> I have to delete ~/.cabal/config every time i want to issue any cabal command
08:07:18 <RyanT5000> i'm on ghc6.10.4 with cabal-install 0.6.2 and Cabal 1.6.0.3
08:07:32 <mux> did you try to run this with strace to figure out which file is missing ?
08:07:41 <RyanT5000> no; i'll try that
08:07:43 <mux> that could yield some more clues
08:09:33 <RyanT5000> it's not clear at all to me what's going on from that
08:09:57 <RyanT5000> i'll paste it
08:10:39 <jeffersonheard> how does one export a newtype in the module header?
08:10:51 <quicksilver> the same way as a Data
08:11:08 <mmorrow> Rotaerk: "definition of "more general than" being *equivalent to* that of -> (whatever that definition may be)". right. i guess i'm saying that i'm _defining_ "more general than" to be (->) *regardless of the definition of (->)*
08:11:33 <jeffersonheard> quicksilver: thanks.  figured, but just making sure
08:12:10 <Rotaerk> mmorrow, that reduces to "isMoreGeneralThan = (->)"
08:12:19 <mmorrow> Rotaerk: exactly!
08:12:21 <Rotaerk> mmorrow, which alone is useless...
08:12:27 <Rotaerk> I gave it an actual definition :P
08:12:36 <RyanT5000> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8108#a8108
08:12:39 <quicksilver> mmorrow -> useless
08:12:43 <RyanT5000> strace of failing cabal command
08:13:04 <quicksilver> it's trying to open a file called "1"
08:13:06 <quicksilver> I wonder why
08:13:15 <RyanT5000> yeah; pretty weird
08:13:19 <Rotaerk> mmorrow, A -> B means A is more general than B meaning (my proposed definition): B can be implemented or described in terms of A, but A can do more
08:13:21 <RyanT5000> it's also not reading the entire config file
08:13:27 <RyanT5000> just the comment and a blank line under it
08:13:51 <mmorrow> Rotaerk: "can do more.." ... of doing less?
08:13:56 <quicksilver> RyanT5000: no, it's reading the whole file
08:14:05 <quicksilver> RyanT5000: strace just trims it
08:14:10 <quicksilver> (that's what the ... means)
08:14:16 <Rotaerk> perhaps an insufficient definition, but more tangible than the tautology "x isMoreGeneralThan y === x -> y"
08:14:18 <quicksilver> well it reads 1720 bytes
08:14:22 <quicksilver> presumably everything
08:14:25 <RyanT5000> quicksilver: ah, i see
08:14:31 <mmorrow> Rotaerk: it's not a tautology, it's a *definition*
08:14:33 <RyanT5000> right; that makes sense
08:14:40 <RyanT5000> (i've never used strace before)
08:15:02 <quicksilver> RyanT5000: that looks very odd. I think you need a dcoutts or a Saizan.
08:15:15 <quicksilver> RyanT5000: it's possible your package database is made out of cheese.
08:15:23 <RyanT5000> hm
08:15:32 <RyanT5000> well, deleting ~/.cabal/config solves the problem
08:15:39 <RyanT5000> but only for one command
08:15:54 <Peaker> IntMap is a radix map/trie, not a hash table, right?
08:15:54 <ManateeLazyCat> @hoogle (Ord a, Monad m) => (a -> m Bool) -> Set a -> m (Maybe a)
08:15:55 <lambdabot> Data.Generics.Basics gmapM :: (Data a, Monad m) => (a -> m a) -> a -> m a
08:15:55 <lambdabot> Data.Foldable mapM_ :: (Foldable t, Monad m) => (a -> m b) -> t a -> m ()
08:15:55 <lambdabot> Data.Foldable forM_ :: (Foldable t, Monad m) => t a -> (a -> m b) -> m ()
08:16:08 <quicksilver> Peaker: yes.
08:16:08 <Rotaerk> mmorrow, given just your "definition", you could define -> to be "loves to eat", and then, as a result, "x is more general than y" == "x -> y" == "x loves to eat y"
08:16:16 <quicksilver> Peaker: a patricia trie, I think.
08:16:29 <mmorrow> Rotaerk: right
08:16:30 <Peaker> patricia tree = trie based on the bits of the number?
08:16:34 <quicksilver> yes.
08:16:38 <Rotaerk> mmorrow, which is why it's insufficient
08:16:50 <Rotaerk> all it is, is a tautology
08:16:59 <Peaker> oh, I see the difference
08:17:16 <mmorrow> Rotaerk: only if you additionally compare "more general than" and "loves to eat" in the context of their additional meaning given the english language
08:17:26 <Peaker> quicksilver: there's a slight difference -- the tree nodes have substrings of various lengths on them rather than just "the next element"
08:17:48 <Rotaerk> eh?
08:17:51 <mmorrow> rather than compare them as the meaningless s/meaningless/now meaningful because we just defined them/ symbols that i'm considering them as
08:18:07 <Rotaerk> those are english predicates, so of course we're comparing them in the context of english
08:18:18 <quicksilver> Peaker: perhaps. I always forget the details :)
08:18:56 <Peaker> quicksilver: Jon Harrop successfully stirred up a fuss about Haskell's poor support of hash tables...  dons raised IntMap as a response, but it doesn't seem to answer the same requirements
08:19:50 <Peaker> I think Jon Harrop is basically using the "OMG Haskell has no hash table" line everywhere, when a Haskell discussion is up
08:20:24 <mmorrow> Rotaerk: but we just defined an english predicate to be another english predicate, but in the context of english they aren't (==).. so you're saying the (:=) then is invalid, and i'm saying the (==) is invalid, so i guess this all comes down to that we're considering this in/from two entirely different contexts
08:20:44 <quicksilver> Peaker: well, listening to what jon harrop says is not very productive.
08:21:03 <Peaker> quicksilver: It would be nice to have a good response though. Hash tables can be the fastest way to look up some things
08:21:03 <mmorrow> Rotaerk: which are mutually incompatible
08:21:07 <quicksilver> Peaker: IntMap is a fast container; what actually are the requirements?
08:21:37 <Peaker> quicksilver: Really small constant for average lookup/insert/delete
08:21:49 <quicksilver> Peaker: that's what IntMap has.
08:22:04 <quicksilver> you can write a true hash table with a good hashing function plus IOUArray, if you like.
08:22:10 <quicksilver> I bet it turns out slower than IntMap.
08:22:28 <dino-> Is this on Haskell-cafe?
08:22:34 <Peaker> quicksilver: is its constant as small as a hash table's?  A hash table with no collisions has those with a constant of about hashing + pointer arithmetic/dereference times, which is very quick
08:22:54 <dcoutts> RyanT5000: I've seen this reported several times now but have no idea what is going wrong and I cannot reproduce it
08:23:15 <quicksilver> Peaker: it's all down to the hash algorithm.
08:23:18 <RyanT5000> dcoutts: well, i just made a fresh reinstall of Ubuntu
08:23:18 <dcoutts> RyanT5000: what is that name of the file it's trying to open? is it a non-printable filename ?
08:23:24 <quicksilver> Peaker: Most hash algorithms are O(key length)
08:23:28 <Peaker> quicksilver: or you can throw more waste at it to reduce collisions too
08:23:29 <RyanT5000> dcoutts: it's always a single character
08:23:37 <RyanT5000> dcoutts: and it's frequently unprintable
08:23:40 <quicksilver> Peaker: (which means that the hash table is not really O(1), but O(log n), just like IntMap)
08:23:54 <Peaker> quicksilver: The O() is less interesting here, just the constant
08:24:00 <dcoutts> RyanT5000: that's consistent with the other reports I've seen
08:24:12 <quicksilver> Peaker: I can easily imagine cases where a hash algorithm has a constant larger than intmap.
08:24:18 <quicksilver> Peaker: following an intmap in a cache line is very very fast.
08:24:32 <quicksilver> Peaker: if you wish to prove that's not true, be my guest :)
08:24:56 <ManateeLazyCat> :t Data.Set.filter
08:25:00 <lambdabot> forall a. (Ord a) => (a -> Bool) -> S.Set a -> S.Set a
08:25:02 <Peaker> quicksilver: yet another thing to add to my already huge todo list :)
08:25:10 <mmorrow> ooh, i've got a C intmap implem if someone is benchmarking stuff :)
08:25:21 <RyanT5000> dcoutts: I think you'd be able to reproduce by installing Ubuntu 9.04 amd64, then installing ghc 6.10.4 manually from the site, then installing cabal-install
08:25:22 <Rotaerk> mmorrow, "more general than" is an english predicate with unclear technical meaning. the whole point of the discussion was to try to come up with a precise definition for it.  "loves to eat" was intended to be construed as a concrete predicate that would give meaning to ->, logically deduce (by your equivalence relation) that it must then be equivalent to "more general than", and thus show that the mere equivalence of "mo
08:25:22 <Rotaerk> re general than" and (->) is insufficient.
08:25:24 <ManateeLazyCat> @hoogle (Ord a) => (a -> m Bool) -> Set a -> m (Set a)
08:25:25 <lambdabot> Data.Traversable traverse :: (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
08:25:25 <lambdabot> Data.Traversable mapM :: (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
08:25:25 <lambdabot> Data.Traversable for :: (Traversable t, Applicative f) => t a -> (a -> f b) -> f (t b)
08:26:07 <dcoutts> RyanT5000: hmm, I wonder if x86 would do.
08:26:42 <Peaker> quicksilver: could be a useful benchmark labeled "Jon Harrop is a silly troll" to point at whereever he spouts his anti-Haskell rubbish :)
08:26:44 <RyanT5000> dcoutts: not sure; i've never run x64 before, so it could be the change that caused it
08:27:01 <quicksilver> Peaker: jdh is not dissauded by such simple tactics.
08:27:11 <quicksilver> stooping to them will just get you covered in muck.
08:27:22 <Peaker> quicksilver: if IntMap is indeed a bit smaller, can just use the IO HashTable module benchmark instead
08:27:37 <Peaker> ManateeLazyCat: Set has an RMonad instance, I think. RMonad should have filterM like normal Monads
08:28:04 <dcoutts> RyanT5000: it'd be useful to know if that's part of the pattern
08:28:09 <Rotaerk> mmorrow, i.e. the incompatibility of the english predicates is the proof that "moreGeneralThan == (->)" is insufficient to define moreGeneralThan satisfactorily
08:28:20 <Rotaerk> anyway .. enough of this
08:28:21 <ManateeLazyCat> Peaker: RMonad?
08:28:25 <RyanT5000> dcoutts: well, before, i was running 6.10.4 on ubuntu x86
08:28:58 <Peaker> ManateeLazyCat: Restricted Monad. A Monad that requires some type-class constraints. in the case of Set, you need (Ord k) for it to be a Monad..
08:29:07 <RyanT5000> dcoutts: but i had the ghc6 apt-get packages installed as well, so that muddles things
08:29:16 <Peaker> ManateeLazyCat: it sounds like you're looking for filterM over sets right?
08:29:36 <dcoutts> RyanT5000: but this was using the ghc binary from haskell.org/ghc/download right ?
08:29:36 <ManateeLazyCat> Peaker: Yep, i'm looking for filterM for Data.Set
08:29:44 <Peaker> ManateeLazyCat: oh wait, silly me, you're looking over filterM that doesn't need Set to be a monad
08:29:56 <Peaker> @type Set.toList
08:29:57 <lambdabot> Couldn't find qualified module.
08:30:00 <Peaker> @type Data.Set.toList
08:30:01 <lambdabot> forall a. S.Set a -> [a]
08:30:25 <RyanT5000> dcoutts: yes, that's the 6.10.4 in both instances
08:30:29 <ManateeLazyCat> Peaker: I see, i transform Set to list first, then use filterM
08:30:46 <Peaker> ManateeLazyCat: yeah, just have a function that does that
08:30:49 <Peaker> and back
08:30:49 * lilac thinks a decent ST hash table would be pretty nice (and probably none too hard to write)
08:31:05 <RyanT5000> dcoutts: for what it's worth, i chose the top download option this time (of the x64 ones), and i don't recall which one i chose last time, but i suspect it was the top one (of the x86 ones)
08:31:08 <Peaker> @type \f xs -> Data.Set.fromList <$> filterM f (Data.Set.toList xs)
08:31:10 <lambdabot> forall a (f :: * -> *). (Ord a, Monad f, Functor f) => (a -> f Bool) -> S.Set a -> f (S.Set a)
08:31:30 <ManateeLazyCat> Peaker: Thanks
08:31:50 <Peaker> @type \f xs -> Data.Set.fromList `liftM` filterM f (Data.Set.toList xs)
08:31:51 <lambdabot> forall a (m :: * -> *). (Ord a, Monad m) => (a -> m Bool) -> S.Set a -> m (S.Set a)
08:32:03 <Peaker> lilac: putting a Map rather than a [] as its bins could bind its worst-case more nicely too
08:33:20 <quicksilver> lilac: backed by STUArray?
08:33:44 <quicksilver> Peaker: (but at the cost of increasing the constant factor in the best case, I fear)
08:34:02 <quicksilver> lilac: no, by an STArray.
08:34:12 <quicksilver> lilac: and then you get bitten by the mutable array GC pain.
08:35:23 <mmorrow> Rotaerk: by "define" i mean "take as an axiom"
08:35:44 <mmorrow> Rotaerk: (which i'm not claiming is the same as your definition of "define")
08:36:33 <quicksilver> lilac: still, it would be nice if someone did the experiment.
08:36:40 <MyCatVerbs> @pl let fzz x  y = (x,y) : fzz (x+1) y in fzz
08:36:41 <lambdabot> fix (ap (ap . ((:) .) . (,)) . (. (1 +)))
08:37:26 <Axman6> :t (`(,)` 2)
08:37:27 <lambdabot> parse error on input `('
08:37:29 <Axman6> :(
08:37:38 <Axman6> :t (, 2)
08:37:39 <lambdabot> parse error on input `2'
08:37:45 <Axman6> shame that
08:37:49 <Makoryu> Axman6: A patch for that is coming soon
08:37:55 <Axman6> excellent
08:38:05 <Makoryu> It should be in the next 6.x GHC release, IIRC
08:38:10 <pikhq> Until then, (,) is a wart.
08:38:14 <pikhq> Kinda like unary -.
08:38:17 <Axman6> :t flip (,)
08:38:18 <lambdabot> forall a b. b -> a -> (a, b)
08:38:27 <Axman6> :t flip (,) 5
08:38:28 <lambdabot> forall a b. (Num b) => a -> (a, b)
08:38:29 <SamB_XP> so ...
08:38:30 <Makoryu> pikhq: That's another thing I'd like to see a fix for.
08:38:45 <sbahra> :t (,) 2
08:38:46 <lambdabot> forall t b. (Num t) => b -> (t, b)
08:38:53 <pikhq> :t (`(+)` 2)
08:38:54 <SamB_XP> pikhq: how would `(,1,)` work ?
08:38:55 <lambdabot> parse error on input `('
08:39:02 <RayNbow> > 1 , 2  -- if , were to be an infix operator :p
08:39:05 <lambdabot>   <no location info>: parse error on input `,'
08:39:15 <sbahra> :t (+ 2)
08:39:16 <pikhq> SamB_XP: ... Not all that well.
08:39:17 <lambdabot> forall a. (Num a) => a -> a
08:39:20 <pikhq> :P
08:39:41 <SamB_XP> pikhq: in other words, it's not very like negation
08:39:53 <Makoryu> I think multiple holes are supported in the patch. I don't remember
08:40:12 <quicksilver> they are, yes.
08:40:21 <quicksilver> (,1,) becoems \x y -> (x,1,y)
08:40:25 <quicksilver> note, no ``
08:40:43 <quicksilver> I suspect they won't be allowed.
08:41:02 <quicksilver> The thing about , is it's syntax, not an operator. That's a concession to the limited ascii alphabet and convention.
08:41:24 <Makoryu> I'm curious as to why infix quoting uses two backticks instead of one
08:41:55 <quicksilver> it's also used in module defintions, record syntax, list comprehension syntax, list literals, and surely other stuff.
08:42:01 <SamB_XP> quicksilver: I suspect that's also partly because it would be hard to get (1,2,3) to mean the right thing otherwise ;-)
08:42:06 <quicksilver> Makoryu: no good reason, I don't think.
08:42:22 <quicksilver> SamB_XP: yup.
08:43:45 <SamB_XP> Makoryu: probably because this ain't no lisp?
08:47:50 <RyanT5000> dcoutts: my temporary solution to the cabal issue: terminal with "watch rm -f ~/.cabal/config"
08:48:29 <PetRat> As an exercise I tried to implement the State monad. Can someone check out http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8109#a8109 and see if I'm right? I just realized I ignored the newtype wrapper but maybe I got the essence.
08:48:31 <dcoutts> sigh
08:48:44 <RyanT5000> dcoutts: lol
08:49:05 <dcoutts> RyanT5000: if you can build cabal-install from source and reproduce it, then try annotating it with debug stuff to try and track it down
08:49:26 <RyanT5000> dcoutts: i'll see if i can find the time to do that
08:49:39 <dcoutts> RyanT5000: thanks, I appreciate it
08:49:51 <RyanT5000> no problem
08:50:31 <lilac> quicksilver: (sorry, occupied elsewhere) what's the mutable GC pain?
08:50:42 <lilac> *mutable array GC pain
08:51:38 <int-e> RyanT5000: did you look at the generated configuration file?
08:52:47 <quicksilver> lilac: mutable arrays (STArrays, IOArrays), if you make a single change, have to be exhaustively scanned by the GC in every collection, because it doesn't know which bits changes. Or something like that.
08:53:04 <quicksilver> lilac: so mutable arrays slow down GC disproportionately to their size.
08:53:10 <quicksilver> I don't understand the exact details.
08:53:10 <PetRat> Also, question about State. If a computation within a State monad is neither getting nor putting the state, does it follow that the state is passed unchanged?
08:53:33 <quicksilver> PetRat: well, that depends what you mean.
08:53:34 <RyanT5000> int-e: well, i looked at it, but i didn't know what to be looking for
08:53:36 <lilac> quicksilver: sounds nasty. i didn't know that the GC kept state from one collection to the next; that sounds pretty clever
08:53:58 <quicksilver> PetRat: you might be using other functions which use get and put in their implementation.
08:54:06 <SamB_XP> lilac: for mutable objects it's pretty sane ;-)
08:54:08 <quicksilver> PetRat: "modify (+1)" doesn't appear to get or put, but it certanly modifies the state.
08:54:24 <quicksilver> lilac: recall that most of the haskell heap is mutable, which is great for a generational GC.
08:54:30 <quicksilver> lilac: *IM*mutable, sorry.
08:54:56 <quicksilver> lilac: now start to think about how you'd have to change your GC to accomodate the fact that (as an unusual case) you do also store mutable data in the heap.
08:55:14 <quicksilver> lilac: more details than that I don't know.
08:55:46 <PetRat> quicksilver: I get it. Maybe one question I'm asking is that the implementation of >>= does nothing with the state except pass it unchanged, correct?
08:56:06 <PetRat> BTW I just realized my implementation of State is probably messed up. Revising that now...
08:56:19 <ski> PetRat : yes
08:56:20 <lilac> quicksilver: i'm still pondering how to make a GC which makes good use of immutability
08:56:57 <SamB_XP> PetRat: yeah, that's exactly what >>= is supposed to do
08:57:28 <quicksilver> PetRat: the implementaiton of >>= is supposed to pull the ending state from the thing on the left and pass it onto the thing on the right
08:57:32 <quicksilver> (as is >>)
08:58:18 <lilac> i suppose one could find a set of gc roots for a particular generation, and know that generation and (higher ones) doesn't need examining if all the roots are still live
09:01:11 <PetRat> Can someone look at http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8109#a8109 and check my implementation of State. I ignored the newtype wrapper, but maybe got the essence.
09:02:10 <quicksilver> PetRat: it's not quite right.
09:02:16 <PetRat> Oh, drat, typo in return. Wrong order of components in the tuple.
09:02:17 <SamB_XP> lilac: I think the idea is that you know you don't need to even look at a particular generation and higher, except mutated nodes, when doing a low-numbered generation
09:02:29 <quicksilver> PetRat: you're giving the old state to the "k" action in >>=
09:02:43 <quicksilver> PetRat: you're supposed to be using the new state out of (h y)
09:02:59 <quicksilver> PetRat: another way of saying this is you are totally ignoring (snd (h y))
09:03:25 <SamB_XP> lilac: because that's the only way to have backreferences ...
09:03:31 <PetRat> quicksilver: okay I get it. I'll try to revise it.
09:05:50 <quicksilver> PetRat: personally I find it instructive to write (>>), which is simpler
09:06:01 <quicksilver> even though you don't actually need to, because it can be defined in terms of >>=
09:06:07 <jeffwheeler> Is it possible to install Gtk2Hs with GHC 6.10.4 on Windows? The binary only works for GHC 6.10.3, and I have no idea how to build it from source on Windows.
09:06:46 <jeffwheeler> Heck, Windows can't even extract from a tarball, I don't know where to start. :P
09:07:19 <dcoutts> jeffwheeler: those are your options, use ghc-6.10.3, build from source or wait.
09:07:38 <jeffwheeler> dcoutts: hmm, I guess I'll keep trying to figure out how to build from source then; thanks :)
09:07:42 <PetRat> quicksilver: can you look at my revision? thanks :)
09:07:48 * jeffwheeler googles about extracting tarballs on win7
09:09:06 <PetRat> quicksilver: I guess when you write >> you concentrate on doing the right thing with the state.
09:09:38 <quicksilver> PetRat: yes, exactly.
09:09:57 <quicksilver> PetRat: and yes, that looks right now.
09:10:27 <brad_larsen> With GADTs, currently, detection of partial pattern matches in is buggy.  Anyone know if there are plans to fix this?
09:10:34 <quicksilver> @djinn (s -> (a,s)) -> (a -> s -> (b,s)) -> (s -> (b,s))
09:10:35 <lambdabot> f a b c =
09:10:36 <lambdabot>     case a c of
09:10:36 <lambdabot>     (d, e) -> b d e
09:11:00 <quicksilver> PetRat: you should find that is very similar to yours, modulo variable renaming and using case instead of let.
09:11:16 <quicksilver> brad_larsen: is it decidable in general?
09:11:33 <PetRat> quicksilver: does djinn work entirely by a type of proof or deduction?
09:11:44 <brad_larsen> quicksilver, I don't know.
09:12:06 <quicksilver> PetRat: yes.
09:12:16 <quicksilver> PetRat: the above is a simple proof in intuitionistic logic.
09:12:20 <PetRat> That is cool.
09:12:26 <quicksilver> (although @djinn does slightly more than intuitionistic logic)
09:12:57 <brad_larsen> quicksilver, I believe so, because if you try adding cases for patterns that ghc says are not checked, the type checker calls you out
09:13:50 <quicksilver> I recall there was some discussion about it being hard to get right
09:13:53 <quicksilver> but I can't remember why
09:15:37 <PetRat> quicksilver: I think one thing that tripped me up was I was thinking ">>= doesn't do anything with the state", then looking at every variable of type s and seeing the same variable. Actually I think the way to put it is, ">>= doesn't do anything with the state that results from the first computation." @djinn makes no assumption that s -> (a,s) means the second s is the same variable as the first. This is not the case with 'put' or
09:15:37 <PetRat> 'modify'
09:16:53 <quicksilver> it's true.
09:17:05 <quicksilver> although intuitionistic logic would be free to make the same mistake you did
09:17:17 <quicksilver> - that is, there is another proof which reuses the first s
09:17:19 <quicksilver> your y.
09:17:36 <quicksilver> @djinn has some relevant tendency which makes it tend to prefer using stuff it hasn't used before.
09:17:37 <lambdabot> -- f cannot be realized.
09:17:51 <PetRat> quicksilver: i.e. it produces a consistent result, but not a "fully right" result?
09:18:05 <quicksilver> it always produces a correct result.
09:18:15 <quicksilver> given multiple correct results, it prefers those which use stuff
09:18:25 <quicksilver> as opposed to ones which ignore some arguments.
09:18:32 <quicksilver> @djinn (a,a) -> (a,a)
09:18:32 <lambdabot> f a = a
09:18:37 <PetRat> "correct" means it has the right type?
09:18:41 <quicksilver> @djinn a -> a -> (a,a)
09:18:42 <lambdabot> f a b = (b, a)
09:18:42 <quicksilver> yes
09:18:53 <quicksilver> it could equally have replied f a b = (a,a) or (b,b)
09:19:00 <quicksilver> but it chose the one which used both arguments
09:19:18 <PetRat> It also had to choose an order randomly.
09:19:28 <quicksilver> well I doubt it was random
09:19:35 <quicksilver> but it was arbitrary, yes
09:19:39 <PetRat> Without a good rationale?
09:20:05 <PetRat> Never mind I get it.
09:20:19 <brad_larsen> quicksilver, here is an example:  http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8112#a8112
09:21:16 <brad_larsen> and here is a ticket for it:  http://hackage.haskell.org/trac/ghc/ticket/2006
09:21:24 <brad_larsen> fixed last month!  woohoo
09:21:38 <PetRat> quicksilver: one thing I do in implementation of Monads and other parameterized types is to use a different name for the variable and the type variable. For example the type variable is 's', but I used 'y' for the variable. This is because I am prone to getting confused, I guess. :)
09:21:49 <mmorrow> wait, but doesn't the GC still have to scan the each item in each immutable array as well, since what if that array holds the sole ptr to some closure, if you didn't scan the entire array, you wouldn't know to copy that closure. so by that logic, i don't see any additional problem with mutable arrays. (if i'm unaware of some huge optimization i'd be thrilled though :)
09:21:51 <quicksilver> nice.
09:22:49 <PetRat> I forget where, maybe "Real World Haskell", but when I was in the earlier stages of learning Haskell I was confused by an example that used s for both the type and the variable.
09:23:44 <Berengal> mmorrow, immutable arrays tend to not be updated as often. At least that's the gist I've caught
09:23:46 <quicksilver> it is both potenitally confusing and potentially helpful
09:24:30 <mmorrow> Berengal: but you still need to determine what they point to, in order to (1) copy those closures and (2) update each ptr in the array with the new ptr
09:24:42 <PetRat> It's helpful if you already are clear on the distinction between type variables and regular variables.
09:27:15 <mmorrow> let m = Map.fromList (zip [0..] [<the only refs to a crapload of massive objects>]); x = listArray (0,999) (replicate 999 mempty ++ [m]); .... discard reference to `m' ... GC occurs ....... (x ! 999) {- if the whole array wasn't scanned, wouldn't this segfault? -}
09:27:59 <mmorrow> (segfault because the memory holding that huge Map is now freed and garbage)
09:28:38 <kpreid> er, the array contains a reference to m, no?
09:29:08 <mmorrow> kpreid: exactly, but it would hold the ptr to the now-garbage memory if you didn't scan the array
09:29:21 <kpreid> Ummm. Why do you think it wouldn't scan the array?
09:29:51 * DrSyzygy is spending this week writing a conference paper about Gröbner bases, operads and Haskell. Wheeeeee!
09:30:03 <mmorrow> kpreid: because people were saying that mutable arrays are expensive GC-wise since they need to be scanned each GC, but that immutable arrays don't
09:30:44 <kpreid> mmorrow: maybe they're talking about generational GC
09:30:48 <mmorrow> which startled me because i'm scanning arrays currently in GC for a project of mine, and i didn't even think twice about the necessity of this
09:31:16 <mmorrow> kpreid: ah, ok. so then we're saying that it's known that all the ptrs in an array point into an older generation?
09:31:31 <kpreid> I'm guessing so
09:31:38 <mmorrow> (one that won't be touched in the current collection)
09:31:40 <mmorrow> ah, ok.
09:31:43 <kpreid> I'm not a GC wizard, I just know some of the complications
09:31:44 <Berengal> mmorrow, http://hackage.haskell.org/trac/ghc/ticket/650 has some kind of explaination. Something about a mutable list or something
09:32:02 <kpreid> when you have mutation, you can have old objects pointing to new objects
09:32:24 <Berengal> Which I guess is the same as the generation thing
09:32:30 <mmorrow> kpreid: ahhh, now the situation is clear
09:33:12 <quicksilver> and also the business about re-scanning the entire array
09:33:16 <quicksilver> when only one pointer has changed
09:33:23 <Berengal> That too
09:38:11 <lilac> in effect, does that mean that mutable arrays never leave the first generation?
09:39:31 <mmorrow> lilac: hmm, that's seem to me like a good way to look at it (although what i know about generational GC is only from reading, not first-hand experience)
09:40:29 <mmorrow> or rather, looking at it that way gives me a better picture in my head of what's happening
09:41:39 <quicksilver> lilac: they're allowed to migrate down migrations if they don't change
09:41:42 <mmorrow> lilac: err, actually you could just have a "dirty" bit or something possibly on mutable arrays, and somehow only set it on the first write
09:41:48 <quicksilver> lilac: but they get bumped back up when they do, I think.
09:43:04 <mmorrow> i wonder how to keep track on dirtiness without intercepting each write
09:44:13 <mmorrow> s/on/of/
09:45:19 <quicksilver> mmorrow: if you read the trac ticket then you will know as much as I do :)
09:45:36 <quicksilver> probably more, since there is a real probability you will absorb it better.
09:46:42 <mmorrow> quicksilver: i've got that one GC book laying around too, but never was particularly interested in the generational part(s) until now
09:47:11 <gbacon> ?ty fromListWith (+) . map (flip (,) 1)
09:47:12 <lambdabot> Not in scope: `fromListWith'
09:47:18 <gbacon> ?ty Data.Map.fromListWith (+) . map (flip (,) 1)
09:47:19 <lambdabot> forall a b. (Num b, Ord a) => [a] -> M.Map a b
09:47:55 <SamB> @hoogle (a -> a -> Bool) -> [a] -> [a]
09:47:55 <lambdabot> Data.List nubBy :: (a -> a -> Bool) -> [a] -> [a]
09:47:56 <lambdabot> Data.List deleteBy :: (a -> a -> Bool) -> a -> [a] -> [a]
09:47:56 <lambdabot> Data.List deleteFirstsBy :: (a -> a -> Bool) -> [a] -> [a] -> [a]
09:48:02 <SamB> @hoogle (a -> a -> Bool) -> [a] -> ([a], [a])
09:48:03 <lambdabot> No results found
09:48:04 <lilac> quicksilver: so behaviourally (from a GC pov) they're just like immutable arrays then, only without the copying?
09:48:10 <gbacon> ?ty let f = Data.Map.fromListWith (+) . map (flip (,) 1) in f
09:48:11 <lambdabot> forall a b. (Ord a, Num b) => [a] -> M.Map a b
09:48:14 <mmorrow> @type foldl' (\m a -> M.insertWith' (+) a 1 m) mempty
09:48:16 <lambdabot> forall b a. (Num a, Ord b) => [b] -> M.Map b a
09:48:24 <SamB> @docs Data.List
09:48:25 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-List.html
09:48:38 <gbacon> with ghci-6.10.3, it's inferring [()] -> Data.Map.Map () Integer
09:48:38 * jeffwheeler never knew about @docs; that's awesome
09:49:00 <jeffwheeler> @type [()]
09:49:02 <lambdabot> [()]
09:49:10 <mmorrow> @docs Zebra-Kaleidoscope
09:49:11 <lambdabot> Zebra-Kaleidoscope not available
09:49:19 <mmorrow> heh, they're smart too
09:49:33 <mmorrow> @hackage Zebra-Kaleidoscope
09:49:34 <lambdabot> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/Zebra-Kaleidoscope
09:49:41 <lilac> @docs Zebra.Kaleidoscope
09:49:42 <lambdabot> Zebra.Kaleidoscope not available
09:49:59 <lilac> @docs Control.Monad.ST.Strict
09:49:59 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Control-Monad-ST-Strict.html
09:51:27 <lilac> hmm... it looks like using a deque built from STArrays would solve the GC problems
09:54:41 <mmorrow> quicksilver: ah nice, yeah that ticket's informative
09:55:54 <mmorrow> lilac: newtype SeqArray s a = Sequence (STArray s a) -- maybe
09:55:59 <mmorrow> err
09:56:09 <mmorrow> lilac: newtype SeqArray s a = Asdf (Seq (STArray s a))
09:56:10 <mmorrow> ;)
09:56:36 <lilac> mmorrow: i was thinking more data Deque s a = Deque (STArray s (STArray s a))
09:56:46 <mmorrow> hmm
09:57:00 <lilac> possibly plus bookkeeping
09:57:02 <mmorrow> yeah, that seems better actually
09:57:29 <mmorrow> well, i guess better if you're not appending/etc the top-level
09:57:58 <mmorrow> (which wasn't what i had in mind by using Seq anyway)
09:59:38 <mmorrow> lilac: so you wouldn't ever been mutating the top-most array, right?
10:00:12 <lilac> not unless enough elements are allocated that it's worth doing
10:01:13 <hydo> Can anyone give me any pointers on running a process, presumably in a thread, on a timer?  ie. fire off this function every minute, etc.  Searching for all combinations of haskell and timer have not been fruitful.
10:01:18 <skorpan> ,timers
10:01:20 <lunabot>  luna: Not in scope: `timers'
10:01:26 <skorpan> oops, i thought this was #emacs
10:01:50 <mmorrow> @type \msec -> forkIO (forever (threadDelay msec doIt))
10:01:52 <lambdabot> Not in scope: `forkIO'
10:01:52 <lambdabot> Not in scope: `threadDelay'
10:01:52 <lambdabot> Not in scope: `doIt'
10:02:13 <hydo> ah!  the key is threadDelay?
10:02:25 <mmorrow> maybe have an MVar that you `tryTake' every few times to see if you should bail too
10:02:28 <hydo> I knew about forkio, but I guess I didn't read thoroughly enough.
10:03:18 <mmorrow> you could also just (killThread tid) to stop it too
10:04:02 <RyanT5000> so, i'm trying to figure out how to represent infinitely large, infinitely detailed planes
10:04:29 <hydo> Thanks everyone!
10:04:40 <RyanT5000> e.g.: imagine an infinitely large heightmap that you can zoom in arbitrarily far on
10:04:54 <RyanT5000> all generated from a single random seed
10:05:33 <RyanT5000> i've got some ideas for algorithms to use to implement such a thing, but I'm not sure what a useful type signature would be
10:05:38 <mmorrow> RyanT5000: by randomly generating the parameters of some equational representation of the surface, i'd imagine
10:06:06 <RyanT5000> mmorrow: right, but i'm trying to figure out what would be a convenient interface for such a massive plane
10:06:34 <RyanT5000> i don't think IArray will quite do
10:07:04 <mmorrow> RyanT5000: :o you wouldn't actually represent it by explicitly storing some sampling of its points
10:07:38 <mmorrow> just store the equation that you hand (x,y) and it computes the z
10:07:49 <mmorrow> and randgen the coefficient to that equation
10:07:54 <ksf> Data a => Data ([] a)
10:07:58 <mmorrow> coefficientS
10:08:16 <ksf> hey does that mean that I can treat a [Word32] as Ptr Word32?
10:08:37 <RyanT5000> mmorrow: well, i'd like to be able to, e.g., apply a filter to the entire thing
10:08:55 <mmorrow> a discrete filter?
10:09:47 <mmorrow> RyanT5000: you could always sample some finite grid of points before via the equation before you filter
10:09:55 <RyanT5000> mmorrow: i'm not sure what you mean by that (my knowledge of signal theory is quite minimum)
10:10:17 <RyanT5000> mmorrow: right, but don't you think that's a kind of a dirty representation?
10:10:18 <ksf> actually, I'm looking for a fast and painless way to marshal float arrays.
10:10:52 <RyanT5000> what i'd really like to be able to do is say: "alright, here's an infinite expanse of randomly-chosen Floats between 0 and 1; now i'm going to apply a wavelet noise filter"
10:11:25 <RyanT5000> (i think that it might be necessary that all such filters are refinable in order for them to be sane)
10:11:29 <chadz_> hey, are lazy bytestrings lazy enough that if i wanted to split a file upon multiple parsers, would it be easier to do a unfold over the bytestring and somehow twiddle the boundaries to the nearest newlines. or, would it be easier to go from handles, seek to the nearest newlines, then create bytestrings from that?
10:11:39 <RyanT5000> (this is based on my ridiculously sparse knowledge of multiresolution analysis)
10:11:42 <mmorrow> RyanT5000: so would your filter be e.g.  [[0,0.125,0],[0.125,0.5,0.125],[0,0.125,0]] or f(x,y) = a*cos(x)+b*sin(y) ?
10:12:13 <RyanT5000> the filter would be more like the first i think - that's a filter kernel you're talking about?
10:12:20 <mmorrow> right
10:12:42 <RyanT5000> i imagine that it would be necessary to make all filter kernels be bounded
10:12:57 <RyanT5000> unless there's some weird situation like unlimited-precision floats being used as the output
10:14:10 <RyanT5000> but here's the thing: suppose my filter kernel is 3x3; i don't want to recompute all the underlying points 9 times
10:14:11 <mmorrow> RyanT5000: so with images, you can consider them to be a surface, where (x,y) are (width,height) pixel coords, and the image a mapping of ([0..w-1],[0..h-1])->[0.0..1.0]
10:14:15 <RyanT5000> so there needs to be some kind of memoization
10:14:42 <RyanT5000> mmorrow: that doesn't work as well when your signal is infinitely large :P
10:14:44 <mmorrow> (actually, they map the 2D (w,h) to a 3D (or 4D) space, depending on the colorspace)
10:15:00 <RyanT5000> mmorrow: but i was thinking an unlimited-precision float would suffice
10:15:10 <mmorrow> RyanT5000: right, but your filter is of finite width
10:15:22 <RyanT5000> yeah, that's true
10:15:59 <mmorrow> usually with images you only consider the immediate 8 pixels surrounding any one pixel
10:16:33 <eliotn> Is this a channel about programming?
10:16:34 <mmorrow> oh, wait. that filter isn't a kernel in the sense that it's a matrix representing some function
10:16:49 <eliotn> does anyone here know java?
10:16:57 <chadz_> fail troll
10:17:09 <RyanT5000> eliotn: many people here know java, but this channel is about haskell (another language)
10:17:20 <sinelaw> can someone explain simply what Automatic Differentiation is about? How does the numerical evaluation occur?
10:17:20 <RyanT5000> eliotn: you should /join #java
10:17:35 <eliotn> RyanT5000: wait
10:17:42 <mmorrow> but rather you "overlay" that over a 9 pixel square, multiply each pixel by the corresponding entry in that [[Double]], then sum them to get the result for the center pixel
10:17:56 <eliotn> wait, haskell is a programming language?
10:18:03 <eliotn> wow
10:18:17 <mmorrow> > fix error
10:18:19 <lambdabot>   "* Exception: * Exception: * Exception: * Exception: * Exception: * Excepti...
10:18:23 <eliotn> And by the way, I already searched for #java, could not find it
10:18:29 <eliotn> ?haskell
10:18:29 <lambdabot> Unknown command, try @list
10:18:33 <ray> maybe try ##java
10:18:34 <eliotn> @list
10:18:34 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
10:18:41 <eliotn> ray: nope
10:18:41 <ray> this network is like that sometimes
10:18:43 <sinelaw> RyanT5000, funny, I just finished implementing a convolution kernel in VHDL :)
10:18:52 <sinelaw> i mean filter
10:19:05 <RyanT5000> sinelaw: if i recall correctly, automatic differentiation basically works by overloading all the members of Num, etc.
10:19:09 <ray> or learn haskell and do your programming in that.. that's what i'd do
10:19:40 <sinelaw> RyanT5000, so as you construct a calculation, the derivative is automatically constructed as well?
10:19:52 <RyanT5000> sinelaw: yeah, more or less
10:20:15 <RyanT5000> sinelaw: there's one implementation (conal's?) that produces an entire tower of derivatives
10:20:19 <RyanT5000> an infinite one
10:20:23 <sinelaw> yeah i've seen that paper
10:20:41 <sinelaw> didn't go through it, missing some background knowledge :)
10:20:57 <RyanT5000> sinelaw: do you have any opinion on the representation of infinite signals?
10:21:26 <mmorrow> sinelaw: have you looked at Lava at all? i know it has some stuff for generating vhdl given _?_, but i'm not sure hte details
10:21:34 <RyanT5000> (by which i mean an infinitely large image (or whatever) that you can zoom in on as far as you like)
10:21:49 <sinelaw> mm_freak, unfortunately i had to do this in VHDL (assignment)
10:21:55 <mmorrow> sinelaw: at the very least, iirc it has some vhdl pprinting capability
10:21:56 <sinelaw> directly
10:22:00 <mmorrow> ah
10:23:25 <ksf> is there an integer sqrt somewhere in the libs?
10:23:56 <sinelaw> RyanT5000, i saw that discussion in what's his name blog about that
10:24:05 <_randomwords_> ksf: Don't think so
10:24:18 <_randomwords_> at least I've looked for one before
10:25:09 <ManateeLazyCat> How to use caseSensitive in Text.Regex.TDFA?
10:25:33 <_randomwords_> ksf: Are you after something like (floor . sqrt . fromIntegral), or something wittier?
10:25:44 <ManateeLazyCat> I want match some regex but don't care case.
10:26:13 <ksf> well, I won't hit double's maxbound, so it's fine.
10:26:50 <RyanT5000> sinelaw: which blog?
10:26:58 <_randomwords_> ksf: I'm sure with some judicious use of number theory you could construct something clever, I may have a look at it tonight
10:27:50 * ksf wonders whether that fine Integer log from the cafe made it into the libs
10:27:54 <sinelaw> RyanT5000, http://lukepalmer.wordpress.com/?s=semantic+design
10:28:21 <sinelaw> RyanT5000, actually here: http://lukepalmer.wordpress.com/2008/07/18/semantic-design/
10:28:58 <RyanT5000> huh
10:29:25 <RyanT5000> looks interesting
10:29:26 <sinelaw> the example he discusses is precisely that of an image
10:30:27 <_randomwords_> ksf: Integer log?
10:32:42 <chadz_> hey, are lazy bytestrings lazy enough that if i wanted to parallelize parsing a file, would it be easier to do a unfold over the bytestring and somehow twiddle the boundaries to the nearest newlines. or, would it be easier to go from handles, seek to the nearest newlines, then create bytestrings from that?
10:36:29 <ksf> _randomwords_, this one: http://www.haskell.org/pipermail/haskell-cafe/2008-February/039640.html
10:38:15 <_randomwords_> That's neat
10:38:29 <ksf> chadz_, the easiest way is just not to bother about bytestring's internal chunking.
10:38:31 <RyanT5000> alright, so, when things get forced in haskell, the results replace the original thunk; but what if the result requires significantly more memory?  is there a reasonable way to revert the thunk back to its original state after some period of time (e.g.: before the next GC, after 10 seconds, after RAM usage exceeds a particular amount, etc.)?
10:39:04 <RyanT5000> for example, suppose i have the thunk [1..], and i have something that runs through it out to some (finite) distance every couple of minutes
10:39:11 <ksf> just use lines on your file, then pass it to a map or something parallel.
10:39:20 <RyanT5000> i don't want to keep all those list elements around in the intervening time
10:39:32 <RyanT5000> but i'd still like to expose it as a pure value
10:39:43 <ksf> you can, of course, re-pack the bytestrings after chunking but it shouldn't be worth the bother.
10:42:37 <ksf> RyanT5000, I guess everybody would love to do that, and everybody shudders thinking of the massively evil api it would require.
10:43:53 <harlekin> Is there recent documentation on bootstrapping available? The documentation here: http://hackage.haskell.org/trac/ghc/wiki/Building/Porting seems to be outdated for ghc 6.10.4.
10:46:26 <RyanT5000> ksf: well, is there any way to make the api less evil?
10:46:28 <Berengal> RyanT5000, the solution is to create a function 'infiniteList () = [1..]'
10:46:32 <Berengal> Then call that function
10:46:48 <RyanT5000> Berengal: that seems like an annoying/silly solution
10:46:52 <Berengal> (and make sure you're not holding onto the list, obviously)
10:46:56 <RyanT5000> what i'd really like is something like:
10:46:57 <chadz_> ksf: if I attempt that htough, wouldn't I need to have the entire file in memory to efficiently split it?
10:47:13 <RyanT5000> manage :: ResourceManagementProfile -> a -> a
10:47:36 <RyanT5000> where RMP describes how and when the thing should be reverted
10:47:51 <RyanT5000> possibly it should be RMP -> a -> IO a
10:48:18 <RyanT5000> (though I can imagine situations where it's well and truly pure)
10:48:40 <RyanT5000> chadz_: many of the built-in file-reading functions are lazy
10:48:49 <Berengal> RyanT5000, it's quite possible the value might be forced before the IO action is run. Even IO doesn't make this "safe"
10:49:04 <michaelfeathers> Another blog where I try to figure out good Haskell style: http://blog.objectmentor.com/articles/2009/08/11/naming-and-body-language-in-functional-code
10:49:17 <RyanT5000> Berengal: oh right; that makes sense
10:49:32 <RyanT5000> Berengal: well what if it's RMP -> (b -> a) -> IO a?
10:49:51 <RyanT5000> well, (() -> a), i suppose, for the second argument
10:49:58 <chadz_> RyanT5000: yes, but if I have to unfoldr over all the lines it's no longer really lazy (and really memory intensive)
10:50:14 <Berengal> RyanT5000, why not just () -> a?
10:50:16 <ksf> chadz_, you can use getContents.
10:50:19 <RyanT5000> chadz_: ah, well, i suppose i wasn't paying enough attention to your problem :)
10:50:32 <RyanT5000> Berengal: i want to make a way that users of the resulting "a" don't need to do memory management on their own
10:50:36 <chadz_> ksf: from the handles? that's what I started to code up
10:50:46 <RyanT5000> Berengal: so handing a (() -> a) to them doesn't really solve the problem
10:50:54 <ksf> that gives you all contents, lazily, if you use lazy bytestrings.
10:50:59 <RyanT5000> Berengal: also, i don't want the a to be *constantly* recomputed; i want something in between
10:51:02 <ksf> it's a bit dirty, but it works.
10:51:57 <ksf> that is, if you write to the file after calling getContents, you're more or less breaking referential transparancy.
10:52:04 <chadz_> ksf: the problem then is overlap. if i create a few handles and seek to different locations, i don't want to reread over any data. i think i probably have to get into bytestring internals and limit the length
10:52:06 <ksf> ...welcome to the wonders of the IO sin bin.
10:52:07 <Rotaerk> I've got a BattleState type for a RPG.  It contains a grid that is an Array (Int, Int) Panel.  A Panel is, for now, just a Maybe CombatantID (indicating its occupant).  A CombatantID is just an Int.  The BattleState also contains a Map CombatantID CombatantState.
10:52:13 <RyanT5000> Berengal: basically, suppose i'm generating a large array from a random seed or some other small generator; i want to hand off the array to another subsystem (which doesn't know or care about memory management), which will periodically do many reads from the array, in short bursts
10:52:28 <jeffersonheard> http://www.haskell.org/haskellwiki/GHC/Using_the_FFI#Callbacks_into_Haskell_from_foreign_code in this they define a function called "wrap" but I don't see its definition anywhere
10:52:31 <Rotaerk> is this scheme reasonable, for dealing with identity of characters
10:52:35 <Rotaerk> or is there a better way
10:52:45 <jeffersonheard> I need to define a callback...
10:52:47 <ksf> chadz_, if you don't force it, bytestring won't read it.
10:52:51 <Rotaerk> s/characters/combatants/
10:53:05 <chadz_> ksf: hmm, true
10:53:06 <ksf> ...it may mmap a bit further at the borders, though, but that shouldn't hurt.
10:53:40 <ksf> actually, if you're really in for performance, you can use bytestring-mmap.
10:53:42 <Berengal> RyanT5000, in that case it sounds better to just hand them a function Int -> RandomNumber
10:54:13 <ksf> http://hackage.haskell.org/packages/archive/bytestring-mmap/0.2.1/doc/html/System-IO-Posix-MMap.html
10:54:35 <RyanT5000> Berengal: well, suppose the computation of the entire array has to be done at once, so that looking up a particular cell costs the same as recomputing the entire array
10:54:49 <chadz_> ksf: that's nice -- can you seek wwith a bytestring though?
10:55:08 <chadz_> i suppose there's soem unsafeIndex, right?
10:55:12 <ksf> you've got O(1) read inside a strict bytestring.
10:55:23 <ksf> ...just use !!.
10:55:26 <Berengal> RyanT5000, then I'd very much like the array not to be recomputed
10:55:57 <ksf> taking substrings is O(1), too.
10:56:16 <RyanT5000> Berengal: it's not that simple, though! memory is too limited to store the array forever, and the accesses are sporadic anyway
10:56:17 <ksf> ...at least it should be O(1).
10:56:32 <RyanT5000> so the goal is to recompute the array right before large bursts of reads, and throw it away after that
10:56:45 <jeffwheeler> Wow, a speed test of the Gtk UI for Yi just went from 25 seconds to 2 seconds in the last few patches.
10:56:49 <chadz_> ksf: k, thx for the info
10:57:02 <RyanT5000> i can see, i think, that making the resource management thing extend to *all* types might not work very well
10:57:12 <RyanT5000> e.g.: how do you un-force an IOUArray?
10:57:16 <Makoryu> ksf: I believe the substring gets copied to a new array
10:57:37 <Makoryu> Might be wrong
10:57:40 <RyanT5000> i could see how that might require large changes to the underlying execution engine and/or GC
10:58:02 <RyanT5000> but it might make sense to build a ManagedIOUArray
10:58:21 <ksf> well, there's always good, ole mmap if you want to fumble around with Ptr's yourself...
10:59:02 <Berengal> RyanT5000, I think the solution is to buy more RAM
10:59:12 <RyanT5000> Berengal: i'm talking about iPhone development here :P
10:59:23 <Berengal> ... buy an android?
10:59:31 <RyanT5000> i'm *selling to* people with iphones
10:59:50 <Makoryu> RyanT5000: You could always.... not do that. I guess.
10:59:51 <RyanT5000> so unless i'm going to upgrade everyone's phone in the world
10:59:51 <RyanT5000> that's not a very viable strategy :P
11:00:38 <Makoryu> Although, about six months ago, Haskell-on-the-iPhone was widely regarded as impossible
11:00:44 <Berengal> The array user should take the function, then calculate the array just before it does lots of reading and throw it away afterwards, keeping the function
11:01:31 <RyanT5000> Makoryu: well, my company developed the ghc-iphone port; we're pretty determined to make this thing work
11:01:46 <Makoryu> Ah, so you're the ones...
11:02:14 <RyanT5000> Makoryu: yup :)
11:02:20 <RyanT5000> iPwn Studios
11:02:23 <RyanT5000> (ipwnstudios.com)
11:02:38 <RyanT5000> can i add @where things to lambdabot for that?
11:04:49 <Botje> it's @where+ i think
11:05:02 <RyanT5000> Botje: ah, cool
11:08:18 <jeffersonheard> so my question was is the foreign import ccall "wrapper" thing that wraps a Haskell function into a C callback magical, or do I have to write the "wrapper" function?
11:12:12 <tommd> jeffersonheard: Typically you import the C function as "c_func :: CTypes -> CTypes" then you write a haskell wrapper "func" in terms of "c_func" that also converts between the CTypes and their Haskell equivalents.
11:17:49 <hackagebot> darcs-benchmark 0.1 - Comparative benchmark suite for darcs. (PetrRockai)
11:20:33 <jeffwheeler> Why does the Hackage search use Google UK?
11:20:41 <jeffwheeler> The one on the right side, here: http://hackage.haskell.org/packages/archive/pkg-list.html
11:23:30 <tommd> jeffwheeler: Perhaps because a large amount of the community is in the UK and they just went with what they know.  At any rate, I always use CTRL-f to find packages.
11:24:53 <jeffwheeler> tommd: yeah; I was setting up a shortcut, and thought it might be a neater search; turned out to be boring
11:24:59 <jeffwheeler> oh well
11:27:26 <jeffersonheard> tommd: other way around -- I need to use a Haskell function as a C callback.  Reading the doc for Foreign.Ptr it looks like "wrapper" is a magic stub
11:27:53 <jeffersonheard> Sven isn't going to be able to write/maintain OpenCL, so I'm working on it.
11:28:09 <jeffersonheard> Now that AMD has a driver for it, and nVidia's are in beta, I've got a test platform
11:29:07 <jeffersonheard> will follow the same pattern as Sven's other Open* libraries, e.g. I'm working on the "raw" wrapper which I'll release as a separate package and then I'll write a "cooked" wrapper which uses StateVar, Tensor, and ObjectIds
11:30:17 <jeffersonheard> Anyone wants to provide feedback / proofreading for it, I will probably make a blog post Friday when I get done with the raw wrapper.  One thing we'll need in the end is a DSL for creating kernels in OpenCL/C.
11:30:51 <dons> shapr: http://www.nabble.com/-scala--Scala-job-in-Boston-writing-quantitative-finance-software-td20780369.html
11:32:41 <jeffersonheard> OpenCL, by the way, is the new Apple-authored and Chronos-adopted standard for heterogenous supercomputing on multicore CPUs and GPUs
11:33:02 <erikc> jeffersonheard: sure, i'd take a look
11:33:33 <erikc> CUDA vs OpenCL vs Direct Compute is like 3dfx Glide vs OpenGL vs Direct3D all over again :P
11:33:51 <erikc> dominanet hardware vendor vs standards body vs dominent software vendor
11:34:16 <jeffersonheard> yeah, and look who won over and over again...
11:34:28 <erikc> ...microsoft? :P
11:34:33 <jeffersonheard> well...
11:34:35 <jeffersonheard> yeah...
11:34:36 <jeffersonheard> okay.
11:34:42 <jeffersonheard> but still, OpenGL is pretty alive
11:34:47 <erikc> nah, totally
11:35:18 <erikc> the hardware vendor gets roasted usually
11:35:32 <CrazyAzrael1> erikc: As far as I can tell, this time the hardware vendor isn't even fighting.
11:35:35 <jeffersonheard> and nVidia isn't exactly "competing" with CUDA.  CUDA is just the arch. and they're releasing OpenCL drivers for it.  The CUDA-C language and libCuda bindings will probably be deprecated in favor of OpenCL eventually
11:35:57 <jeffersonheard> Apple worked with nVidia to develop it, after all
11:35:59 <CrazyAzrael1> Yeah, nvidia seems to be behnid OpenCL if anything.
11:36:14 <jeffersonheard> and Intel's happy with it, because it should support larrabee pretty well
11:37:18 <CrazyAzrael1> I just hope that we don't run into one of those issues where the interface is nicer, but can't do some things as fast (there's a reason why game devs use DirectX, and it's not just because Microsoft forces it on them)
11:37:26 <erikc> CrazyAzrael1: yea, i kid mostly, CUDA is basically work nvidia needed to do anyway to have an IL for opengl and directcompute
11:37:47 <erikc> with upward compat
11:37:49 <jeffersonheard> I don't think that'll be a problem in this case.  Microsoft's never been terribly interested in supercomputing
11:38:11 <jeffersonheard> Adobe would be the people I'd suspect would introduce competition and they haven't
11:38:16 <jeffersonheard> they said "we like it"
11:38:32 <CrazyAzrael1> Adobe has no leverage though--they don't control any major OS or hardware.
11:38:36 <ksf> erikc, you forgot to mention GLSL
11:38:55 <CrazyAzrael1> ksf:GLSL does not do the same thing.
11:38:55 <ksf> ...which is gpgpu-capable w/o extensions since opengl 3.0
11:39:08 <CrazyAzrael1> ksf: Oh, maybe GL 3 added something
11:39:23 <erikc> i see GLSL more in the GLSL vs Cg vs HLSL battle
11:39:27 <ksf> yep, general render-to texture.
11:39:31 <CrazyAzrael1> ksf: But as of fairly recently, you had alot of problems with buffer control.
11:39:47 <jeffersonheard> ksf: you still can't use GLSL to address memory outside the sample/vertex you're working on without a sampler
11:39:54 <hackagebot> hp2any-core 0.9.0 - Heap profiling helper library (GergelyPatai)
11:39:54 <hackagebot> hp2any-graph 0.5.0 - Real-time heap graphing utility and profile stream server with a reusable graphing module. (GergelyPatai)
11:40:15 <athos> Oh MyN gODd
11:40:16 <CrazyAzrael1> ksf: Ah, yeah, that's going to be a problem--for larger things you need to be able to "render" to more than just textures.
11:40:36 <ksf> like, what?
11:40:54 <hackagebot> hp2any-manager 0.4.1 - A utility to visialise and compare heap profiles. (GergelyPatai)
11:41:03 <jeffersonheard> ksf: like you need to support operations better than just  by saying "it can be expressed as a convolution"
11:41:03 <CrazyAzrael1> ksf: Biggest one is pixel buffer objects--specifically because textures have a bunch of read/write limitations.
11:41:14 <CrazyAzrael1> For example, if I wanted to do nbody with just textures, I'd be screwed.
11:41:23 <jeffersonheard> Exactly
11:41:52 <jeffersonheard> Also, I did a pretty neat weighted mean thingie the other day for GIS in CUDA that would have been impossible to express in GLSL
11:41:56 <CrazyAzrael1> With pixel buffers though, you're in the clear--just put a barrier before you up date the buffer so that the relevant people have read, and you should be fine.
11:43:06 <CrazyAzrael1> jeffersonheard: You mentioned earlier you were making openCL bindings. Will these allow us to pass in haskell functions via some kind of magicalness, or will it require C-esque functions a la GLSL?
11:43:21 <harlekin> When entering `make hc-file-bunle` it tries to tar a bunch of files which do not exist in rts/. Could the Makefile be broken or does this mean I have done something wrong?
11:43:49 <harlekin> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3294#a3294
11:43:54 <jeffersonheard> It will for now be a straight-up binding to OpenCL, so you will have to write any OpenCL functions in OpenCL's C-like language
11:44:11 <CrazyAzrael1> jeffersonheard: OK, so still useful, but no superpowers.
11:44:34 <jeffersonheard> however, the idea is that with the binding out of the way, someone will make a DSL for writing CL functions, or will port the Data.Array.Parallel stuff to OpenCL
11:45:17 <ksf> no matter what you guys tell me, I won't stop trying to get code on the only parallel hardware I got
11:45:22 <ksf> ...which speaks glsl.
11:46:40 <CrazyAzrael1> ksf: Are you sure it only speaks GLSL? Most cards these days speak CUDA or CTM
11:46:45 <CrazyAzrael1> (if you want them to)
11:47:30 <p_l> CrazyAzrael1: to be exact, if it's maker deigned to make it so
11:47:32 <CrazyAzrael1> jeffersonheard: Makes sense. Some kind of a CL monad for compositing and hooking together CL actions might be cool, but that's also a later kind of thing.
11:47:51 <p_l> ksf: what hardware it is?
11:48:02 <ksf> nah, cuda works only with >= geforce 8xxx
11:48:07 <ksf> i've got a 7600 gs
11:48:24 <CrazyAzrael1> ksf: Ah. OK, go ahead and use GLSL, you are correct. (Though 8000 series cards are under $50 these days)
11:48:36 <ksf> ...agp?
11:48:50 <CrazyAzrael1> ksf: Ah, your entire computer is ancient, my bad.
11:48:51 * p_l is in worse condition, having Radeon M56 (X1600 Mobile). Even new drivers don't support it
11:49:11 * jeffersonheard has a Tesla...
11:49:29 <CrazyAzrael1> jeffersonheard: You work with a research group or something?
11:49:33 <jeffersonheard> yep
11:49:38 <jeffersonheard> visualization
11:49:39 <CrazyAzrael1> I have access to a tesla, but I have to borrow a guy's account to get it.
11:49:47 <ksf> well it _has_ a native word size of 64 bit...
11:50:23 <p_l> ksf: non-Quadro nvidia cards approximate their calculations and I heard that integer performance wasn't really good, for some reason
11:50:29 <ksf> and a single core of today's cpus doesn't get faster, anyway.
11:51:16 <ksf> which means that until people start to agressively program for multicores, i'm fine.
11:51:19 <CrazyAzrael1> ksf: Depends on your CPU. The clock speed on these newer ones is a very different number--check the intel manuals sometime, the big speedups across generations of CPUs are primarily in reducing the # of cycles to do an operation.
11:51:46 <ksf> model name      : AMD Athlon(tm) 64 Processor 3200+
11:51:46 <ksf> stepping        : 8
11:51:46 <ksf> cpu MHz         : 2000.000
11:51:50 <p_l> ksf: it's hard to improve performance of a cpu, especially x86
11:52:03 <centrinia> Hey, that's my CPU.
11:52:14 <chadz_> he's in your cpus
11:52:15 <tommd> Unless you define performance in terms of power consumption.
11:52:19 <ksf> last time I looked, they sold multi-cores at lower mhz.
11:52:31 * centrinia steals my CPU back from ksf.
11:52:54 <ksf> the biggest speedup I could get right now is a ssd.
11:53:03 * p_l only has TL50 and a C2D T5500. TL-50 looks better in comparison, despite being bought nearly 3 years ago
11:54:35 <CrazyAzrael1> ksf: http://en.wikipedia.org/wiki/Instructions_per_second
11:54:49 <CrazyAzrael1> ksf: Clock speed is only a relevant comparator within a single line.
11:54:54 <ksf> ...well i've got 4000 bogomips.
11:55:11 <p_l> ... and here I though I wouldn't hear about IPS for a while :/
11:55:42 <Ke> so I guess performance isn't the number of cores here
11:56:01 <Ke> which will double quite soon
11:56:07 <CrazyAzrael1> And a modern CPU gets around 50k bogomips (unless you get an expensive one)
11:56:25 <ksf> well, but then you get more pipeline stalls...
11:56:52 <Berengal> My CPU has 4x6000 bogomips, and it's a pretty bitchin cpu
11:57:03 <ksf> and, yes, I'd by a dual quadcore system right away, if I had the money.
11:57:03 <Berengal> 50k is pushing it a bit
11:57:17 <Berengal> bogomips are bogus anyway
11:57:28 <CrazyAzrael1> Berengal: That was based on wikipedia, and it was in MIPS as opposed to bogomips
11:57:47 <CrazyAzrael1> Berengal: Stats may be wrong, they're based on my link from earlier, rounding down a bit to drop the "EXTEREME" qualifiers on the chips.
11:58:38 <Berengal> Ah, in that case, I've got 60k mips
11:58:56 <CrazyAzrael1> Berengal: closer to what I expected :P
11:59:24 <CrazyAzrael1> Anyways, I don't really want to argue this, I just wanted to be clear that you couldn't use clock speed as a meaningful measure between lines.
12:00:03 <p_l> real benchmarking is near-impossible
12:00:25 <CrazyAzrael1> p_l: Except on a per-application, specified workload basis.
12:00:34 <Berengal> real benchmarking is an oxymoron
12:00:36 <ksf> heh I've got more l2 cache than those brand-new phenoms.
12:00:42 <ksf> ...per core, that is.
12:00:43 <p_l> CrazyAzrael1: that'w "near" in my statement
12:01:22 <p_l> ksf: except they got separate memory controllers instead of a single one, so two cores can access separate memory areas at the same time
12:01:37 <ksf> well, i've got a single memory controller per core, too.
12:01:55 <CrazyAzrael1> It is true thought that most systems will benefit from an SSD more than from a RAM or CPU upgrade though these days.
12:01:58 <p_l> ksf: nope, you've got one 128bit controller. There's a difference
12:02:19 <ksf> I've got one 40bit controller. on-die.
12:02:26 <ksf> 48bits virtual.
12:02:37 <p_l> ksf: 40 bit addressing, 128bit *data bus*
12:02:42 <ksf> er yes.
12:03:14 * Berengal doesn't really care as much about performance; he's still amazed computers work at all
12:03:30 <p_l> the so called "dual channel" on most motherboards is just that instead of performing one 64bit-long read, you do a 128bit read using two modules
12:03:59 <p_l> basically, striped RAM
12:04:06 <SamB> hmm, I wonder how you get the kernel to favour the SSD for swap?
12:04:34 <Berengal> SamB, put the swap partition on the ssd?
12:04:36 <koala_man> SamB: swapon -p to set the priority
12:04:38 <SamB> p_l: they used to stripe them 8 ways!
12:04:39 <p_l> SamB: avoid SSD for swap? I'd rather get a separate, slow DRAM-based drive for swap
12:04:44 <SamB> for each bit in a byte ;-P
12:04:55 <SamB> p_l: hmm.
12:05:03 <p_l> SamB: my Alpha got quad-channel memory controller in this nomenclature :P
12:05:09 <SamB> was thinking you might use the SSD for swap
12:05:18 <SamB> but I guess that's bad for it
12:05:26 <CrazyAzrael1> SamB: Recommend against using SSD for swap.
12:05:29 <p_l> SamB: Flash still burns out, no matter what marketroids tell
12:05:30 <SamB> okay, well, you could use it for long-term caching
12:05:35 <Berengal> I'd rather just buy more RAM
12:05:36 <CrazyAzrael1> Sure.
12:05:48 <CrazyAzrael1> RAM is cheaper though for what you're getting.
12:05:58 <SamB> of files that don't change often at all
12:06:01 <CrazyAzrael1> Most of what you're paying for in SSD is NV
12:06:02 <SamB> or something
12:06:05 <koala_man> p_l: how many ssds have you burnt out so far?
12:06:40 <p_l> SamB: interesting perspective are filesystems designed for using both a flash-based storage and magnetic, using them both at the same time
12:07:06 <CrazyAzrael1> Personally, I'd use SSD to store:
12:07:06 <CrazyAzrael1> Databases
12:07:06 <CrazyAzrael1> Shared libs
12:07:06 <CrazyAzrael1> commonly accessed apps
12:07:06 <CrazyAzrael1> kernel
12:07:07 <CrazyAzrael1> cache directories
12:07:09 <CrazyAzrael1> mail (if it's a mailserver)
12:07:18 <p_l> koala_man: none, because I found that with official burnout rates for their flash chips, they don't fit my budget (a drive is supposed to stay around for >10 years, IMHO)
12:07:20 <CrazyAzrael1> I don't think there's much else that super benefits from it.
12:07:56 <CrazyAzrael1> But if you're running a database you NEED one of these things (their primary disk access mode is random, which is hell on a platter drive)
12:07:57 <roconnor> http://www.reddit.com/r/programming/comments/99ncz/naming_and_body_language_in_functional_code/
12:08:12 <koala_man> I haven't burnt out any either, and I don't know of any who has. if current trends continue, they'll outlive me!
12:08:39 <ksf> gosh you'd have to use a dram disk with at least 4 sata cables in a raid...
12:09:02 <p_l> CrazyAzrael1: there are other ways they go around those problems :P
12:09:30 <p_l> multi-tier storage being the oldest method, I guess :D
12:09:36 <CrazyAzrael1> p_l: There are, but they're alot more complicated.
12:09:37 <CrazyAzrael1> Yeah.
12:09:40 <HugoDaniel> hi
12:09:50 <CrazyAzrael1> Also, for apps/libs on a laptop, SSDs are godlike.
12:10:04 <CrazyAzrael1> Also FF cache
12:10:06 <p_l> ksf: s/sata/sas/ <--- why use lesser? :P
12:10:28 <ksf> uhm... because I still have empty sata ports.
12:10:31 <CrazyAzrael1> p_l: SAS drives are prohibitively expensive for most people?
12:10:35 <ksf> pata, too.
12:10:49 <CrazyAzrael1> p_l: The only SAS drives I have are on the mailserver I run, and we kind of cringed when we bought them.
12:10:55 <p_l> CrazyAzrael1: I find SSD prohibitvely expensive as well :)
12:11:21 <ksf> tbh, memory expansion shouldn't be done via harddrive interfaces, but pcie or something.
12:11:22 <CrazyAzrael1> p_l: True
12:11:42 <p_l> otoh, I once worked for a company that considered "50k per server" a small cost
12:12:06 <CrazyAzrael1> p_l: The only cases where I've seriously considered SSD are at work, where we have a half retarded SQL server that's always IO bound, and in my personal laptop, where I once tried it and found that everything was faster, with better battery
12:12:21 <CrazyAzrael1> p_l: That's ridiculous--for that price I could build you a small cluster.
12:12:29 <p_l> CrazyAzrael1: They clustered those
12:12:48 <CrazyAzrael1> p_l: Were you running POWER or something?
12:12:58 <p_l> CrazyAzrael1: how did you guess? ;D
12:12:59 <CrazyAzrael1> (also we're horribly off topic :P)
12:13:14 <CrazyAzrael1> p_l: Only server that expensive that would be bought by someone smart enough to cluster them.
12:14:29 <p_l> CrazyAzrael1: the whole unit in which I worked was based on POWER, SPARC, few x86 (usually running Solaris), ~4 GS1280 Alphas and some embedded stuff
12:14:55 <CrazyAzrael1> Working with Solaris and SPARC must have been kind of annoying.
12:15:05 <ksf> there's always the possibility to haul one of those http://www.sun.com/products/sunmd/s20/gallery/index.xml?t=1&p=1&s=1 into your backyard.
12:16:25 <p_l> those Alphas were being replaced at that time with POWER-based AIX systems
12:16:26 <roconnor> I'm thinking of renaming my Data.Colour module to simply Colour.  Any opinions (opinions not about the Colour/Color debate)?
12:16:36 <roconnor> The Data. prefix seems to be totally useless.
12:16:40 <ksf> colour++
12:16:48 <ksf> ise++
12:16:52 <Zao> roconnor: Apart from decluttering?
12:17:18 <roconnor> Zao: Do you think the Data. prefix declutters?
12:17:21 <Zao> Say that I've got Omg.Wtf and Omg.Wtf.Colour. Wouldn't your top-level module conflict then?
12:17:24 <Vq> colour++
12:17:32 <Zao> If I tried using Colour from inside Wtf.
12:18:22 <roconnor> Zao: hmm, I don't think so.  Omg.Wtf or anything else has to import module names fully qualified.
12:18:36 <esdee> I have a "master" list A, and a list of lists B, where the lists in B are all some subset of A.  I am trying to find the smallest number of lists from B that will add up to be equal to A.  Is there an easy way to apply a function to every combination of elements in a list?
12:18:50 <roconnor> Module names are always imported fully qualified.
12:18:59 <roconnor> AFAIK
12:19:10 <Botje> esdee: map . powerSet :)
12:19:24 <Botje> esdee: with powerSet = filterM (const [True, False])
12:19:27 <CrazyAzrael1> I would vote for keeping the Data. prefix, if only based on the fact that everything else is using it, and if we're going to change it it should be changed for everything at once.
12:19:33 <roconnor> ksf, Vq: are those votes of support for dropping the Data. prefix?
12:19:34 <Botje> that generates all possible subsets of a list
12:20:21 <Vq> roconnor: no, just supporting the spelling :)
12:20:40 <ksf> I like the data so I can easily see what data stuff is available in the overview.
12:20:40 <roconnor> CrazyAzrael1: I think everyone changing at once is impossible.  There might be a few modules worth of the Data. prefix, but I'm not even certain of that.
12:21:14 <roconnor> ksf: hmm.  is Colour suitably datay?  Probably.
12:21:26 <roconnor> Vq: no comments about spelling! :P
12:21:41 <CrazyAzrael1> roconnor: It might be hard, but in the meantime we've got
12:21:41 <CrazyAzrael1> import Data.Graph
12:21:41 <CrazyAzrael1> import Colour
12:21:50 <CrazyAzrael1> Which is incredibly unintuitive
12:22:43 <CrazyAzrael1> Alternatively, double export and suggest the usage "import Colour", allowing people using other Data. modules to keep the old convention?
12:22:58 <roconnor> dropping the Data. prefix also makes import qualified Colour far more useful.
12:23:18 <roconnor> CrazyAzrael1: that is an interesting suggestion.
12:24:39 <heatsink> I like hierarchical module names, as they avoid namespace clutter.
12:24:45 <djahandarie> Why the British spelling?
12:24:51 <_randomwords_> Because it's correct
12:25:08 <ksf> because haskell is very british.
12:25:12 <athos> ?seen cosmicray
12:25:13 <lambdabot> I saw cosmicray leaving #haskell-blah, #haskell-overflow and #haskell 7m 20h 37m 1s ago, and .
12:25:24 <athos> @seen cosmicray
12:25:25 <lambdabot> I saw cosmicray leaving #haskell-blah, #haskell-overflow and #haskell 7m 20h 37m 12s ago, and .
12:25:29 <athos> Okay.
12:25:38 <jeffersonheard> lol.  I write everything british by force of habit
12:25:46 <heatsink> module Color where { import Colour; type Color = Colour; newColor = newColour
12:25:47 <ksf> ...and BE tends to be taught at school in non-english speaking countries.
12:25:50 <roconnor> no spelling comments,  You'll all get distracted! \o/
12:25:54 <jeffersonheard> too much reading P.G. Wodehouse, Agatha Christie, and J.R.R. Tolkien as a kid
12:26:21 <roconnor> maybe I should be talking about a hypothetical Data.Wizzle
12:27:29 <_randomwords_> Why are you using the american spelling of Whizzle?
12:27:34 <roconnor> hackage uploads warns about uploading things outside the Data.* etc. heirachy.  I wonder why?
12:27:42 <lilac> esdee: you know that's an NP-complete problem? :)
12:27:43 <p_l> I think only "Color" variation got accepted outside US
12:27:49 <roconnor> _randomwords_: ahh :D
12:28:17 <roconnor> who would be responsible for such a hackage warning so I might ask what is on their mind?
12:29:05 <esdee> lilac: yeah, the list is small though
12:33:16 <heatsink> So I got this bulk e-mail from Intel advertising one of their workshops.  The heading says "Func<Question, Answer> answerer = q => answerQuestion(q);"
12:33:23 <heatsink> Which is basically \x -> f x
12:33:30 <heatsink> Which should be simplified to just f
12:33:59 <roconnor> heatsink: answerQustion!
12:34:05 <jeffersonheard> I wish documentation were more open.  I'd like to be able to put the OpenCL doc directly into the code and write the whole of OpenCL up as literate haskell, but the license restrictions are too much
12:34:11 <heatsink> And this bugs me because they're ostensibly teaching how to write fast code
12:34:28 <roconnor> http://www.reddit.com/r/haskell/comments/99ole/removing_my_data_prefix/
12:35:03 <jeffersonheard> roconnor: by the way, I just want to say that the colour library, whatever it's called is one of the most awesome libraries i've ever used.
12:35:05 <heatsink> roconnor, modulo renaming of free variables :p
12:35:30 <roconnor> jeffersonheard: thanks.  Have any opinion about the module renaming, since you are my poweruser?
12:37:10 <lilac> @type sum . zipWith ($) (replicate ?y length ++ [const ?x]) $ lines ?contents
12:37:12 <lambdabot> (?contents::String, ?x::Int, ?y::Int) => Int
12:37:20 <jeffersonheard> personally, I'd leave it on, but I also came to Haskell from Java, meaning that I am used to insanely long module names
12:37:55 <jeffersonheard> To me, it makes it clear that it's about manipulating the data contained in colours as opposed to being a collection of constants or something directly to do with graphics
12:38:13 <roconnor> jeffersonheard: well java has at least some reasoning behind the names.  I would also be happy renaming it Ca.R6.Colour if people preferred that.
12:39:06 <jeffersonheard> Nah.  if you're going to change it, just remove the Data. prefix, I'd say
12:39:07 <lilac> roconnor: i rather like the module name heirarchy. it makes it easy to guess what modules are called. adding an incompatible convention would ruin that; please don't :)
12:39:08 <ksf> what about org.dyndns.roconnor.data.colour ?
12:39:22 <lilac> ksf: my brain just puked
12:39:33 <roconnor> ksf:  I don't have roconnor.dyndns.org registered.
12:39:35 <jeffersonheard> I can't imagine doing anything else.  and yes, I got the joke
12:40:15 <jeffersonheard> org.renci.heard.jeff.graphics.rendering.Hieroglyph!!!
12:40:27 <roconnor> jeffersonheard: No joke intended.  Using domain names to prevent module name collision is a good idea.  I actually think Haskell probably ought to addopt it.
12:40:45 <roconnor> but I haven't thought the idea through.
12:40:46 <jeffersonheard> roconnor: I'd rather see ontology than domain names.
12:40:59 <lilac> roconnor: for package names, you might have a point. but as long as i can do package-qualified imports, i'd rather have non-ugly module names
12:41:09 <ksf> I'd rather see relative module names.
12:41:18 <roconnor> lilac: oh we can import packages-qualified?
12:41:20 <CrazyAzrael1> roconnor: I shouldn't need to remember the website of the guy who made the module to import it.
12:41:24 <ksf> wait, we got those.
12:41:29 <lilac> import "packagename" Foo.Bar
12:41:37 <jeffersonheard> problem with domain names is that it's difficult to see if the thing you're about to write is already out there somewheres in the hackageverse
12:41:43 <roconnor> lilac: that works?
12:41:47 <ksf> no, we don't.
12:41:55 <lilac> as a GHC extension (and some other compilers, i don't know which)
12:42:14 <roconnor> lilac: don't we end up with the same problem for package nams?
12:42:16 <ksf> there sholud be some way to stick a directory onto the front of a whole module hierarchy, without touching the source.
12:42:39 <lilac> roconnor: yeah. for packages which aren't registered with hackage, using domain names sounds like a good idea
12:42:50 <ksf> also, things like Graphics.Rendering/GL.FBO.hs
12:43:37 <roconnor> CrazyAzrael1: certianly domain names have some issues, but at least they are solving some problem.  AFAIK the Data. prefix doesn't do anything but make qualified names longer.  Though apparently some people here disagree, which is interesting.
12:43:41 <ksf> ...with java, many deployments end up consisting of classes a..zz, anyway.
12:43:58 <roconnor> lilac: that seems like a fair compromise.
12:44:29 <ksf> why should we introduce domains? we already have cabal packages.
12:44:36 <ksf> java doesn't know of such a thing.
12:44:38 <CrazyAzrael1> roconnor: It might be interesting to add them as a conflict resolution or implementation specific selector (i.e. if I need the version of OpenGL written buy this guy, not that guy), but in general we should be author agnostic on imports.
12:45:07 <ksf> ...you can tell ghc which package to link to.
12:45:22 <CrazyAzrael1> ksf: Yes, so perhaps this would be better specified as a #pragma
12:45:37 <CrazyAzrael1> ksf: (if it's not already available, I'm just talking on the hypothetical idea of author control)
12:45:54 <ksf> it's available as cabal dependencies...
12:46:17 <CrazyAzrael1> ksf: Nevermind, it's not important.
12:46:26 <roconnor> The use of domain names to prefix modules in Java isn't required.  It is simply a convention to avoid module name clashing AFAIK.
12:46:44 <ksf> javac warns you if you don't.
12:47:06 <ziman> @index MaybeT
12:47:07 <lambdabot> bzzt
12:47:23 <roconnor> There is already one package with modules that clashes with my Data.Colour
12:49:12 <mkaemmer> Hrm... I need the help of someone who understands Arrows better than I do.
12:49:52 <roconnor> mkaemmer: How well do you understand Arrows?
12:50:39 <mkaemmer> roconnor: well, I understand how normal functions are arrows, but I've never really used arrows in any other form
12:51:17 <roconnor> throw out your problem, who knows, maybe I can help.
12:51:34 <djahandarie> Damn symbols causing problems. :P
12:51:35 <mkaemmer> so, unlike with Monads/Comonads/Functors/Applicative Functors, I lack the ability to tell if something could make an arrow.
12:52:02 * roconnor is no sure that he knows more about arrows anymore.
12:52:03 <mkaemmer> http://www.haskell.org/arrows/ claims that the type: "data Hyper b c = H (Hyper c b -> c)" forms an arrow
12:52:53 * mkaemmer is bothered by left-recursion
12:52:55 <roconnor> I don't even know how to parse that type
12:53:07 <roconnor> oh now I see
12:53:15 <ksf> uh... ain't that the same as Hyper a on both sides, or am I missing some type magic?
12:53:17 <roconnor> newtype Hyper b c = H ((Hyper c b) -> c)
12:53:20 <mkaemmer> roconnor: as best I can tell, it represents functions of the type (...->b->a->b->a)
12:53:29 <dolio> ((((... -> c) -> b) -> c) -> b) -> c
12:53:45 <mkaemmer> yes, what dolio said
12:53:48 <roconnor> stupid non-strictly-positive data types
12:53:48 <djahandarie> Damn currying always causing problems. :(
12:54:49 <mkaemmer> I'm at a loss for how to define "arr"
12:54:52 <mkaemmer> @type arr
12:54:54 <lambdabot> forall b c (a :: * -> * -> *). (Arrow a) => (b -> c) -> a b c
12:55:02 <dolio> Yeah, it's not obvious to me, either.
12:55:44 <mkaemmer> I have a function w/ type (b->c) and have to generate something that has result type c, but I have no b to apply the function to :(
12:56:59 <roconnor> arr f = fix \w -> \g -> f (g w)
12:57:03 <roconnor> that is my guess
12:57:18 <roconnor> I need some wrapping and unwrapping in there too
12:57:43 <roconnor> not sure that actually works
12:58:01 <lilac> arr f = let r = H s; s (H g) = f (g r)
12:58:10 <skorpan> @pl putStrLn . unlines
12:58:11 <lambdabot> putStrLn . unlines
12:58:18 <lilac> ... in r
12:58:29 <roconnor> lilac: that might be what i was trying to say
12:58:50 <roconnor> I think it is
12:59:22 <roconnor> you have the proper wrapping and unwrapping
12:59:39 <lilac> my Hyper b c is: given a Hyper c b, extract its Hyper b c -> b function, apply it to my Hyper b c, and apply f to the resultant b
12:59:39 <roconnor> I want to use this data structure now!
13:00:04 <lilac> my brain asplode when trying to figure out what it /does/ though
13:00:12 <dolio> arr f = fix $ \hcb -> H $ \hbc -> f $ unH hcb
13:00:17 <dolio> @yow!
13:00:17 <lilac> what's the (.) for this category?
13:00:17 <lambdabot> This PORCUPINE knows his ZIPCODE ... And he has "VISA"!!
13:00:17 <roconnor> lilac: the types work, so it must be right!
13:00:34 <mkaemmer> lilac: cool.  Not sure if arrow laws work yet, but you got a definition that typechecks, which is more than I could do
13:00:36 <lilac> roconnor: that's what i figured :)
13:01:05 <roconnor> mkaemmer: the trick is to use fix ... assuming lilac and I are right
13:01:33 <roconnor> (lilac implicitly is using fix, ... or fix is implicitly using recursive let)
13:01:40 <mkaemmer> roconnor: under what conditions is that not equal to _|_?
13:02:38 <mkaemmer> perhaps I should have more faith in 'fix'... I still find non-strictness a bit weird to reason about
13:03:46 <CrazyAzrael1> Random curiosity, does anyone know if the leksah project died or if people are still working on it?
13:05:10 <blackh> CrazyAzrael1: People are definitely working on it.
13:05:21 <blackh> There's been a fair bit of work recently.
13:05:36 <CrazyAzrael1> blackh: Cool. I checked it out about 6 months ago, and just got reminded of it.
13:05:44 <CrazyAzrael1> I should probably see how it's doing after work.
13:06:10 <mkaemmer> @type first
13:06:11 <lambdabot> forall (a :: * -> * -> *) b c d. (Arrow a) => a b c -> a (b, d) (c, d)
13:06:54 <blackh> CrazyAzrael1: My experience is that it can work really well, but there are still some frustrations.  It takes a little bit of tinkering to get it going, but once it's going the bugs aren't too bad.
13:07:34 <lilac> H f . g = H (\h -> f (g . h))
13:07:43 <lilac> my brain hurts now
13:08:07 <skorpan> what's H?
13:08:31 <c_wraith> I'm assuming a 2-arg data constructor
13:08:38 <mkaemmer> skorpan: the constructor for a datatype: "data Hyper b c = H {unH :: Hyper c b -> c}
13:08:47 <CrazyAzrael1> At the very least, there's nothing data killing?
13:09:18 <roconnor> mkaemmer: const!
13:09:38 <CrazyAzrael1> blackh: i.e. if I write code in leksah, and save it, it's not going to at some point later eat that code.
13:09:52 <CrazyAzrael1> (again, in your experience)
13:09:59 <c_wraith> CrazyAzrael1:  isn't that what source control is for, though?
13:10:04 <mkaemmer> roconnor: right... I suppose since it doesn't have to evaluate its first argument
13:10:23 <roconnor> mkaemmer: it vaguely reminds me of a protocol between b and c.
13:11:01 <mkaemmer> roconnor: oh? do tell :)
13:11:25 <roconnor> er
13:11:27 <roconnor> it's very vague
13:11:31 <blackh> CrazyAzrael1: I did have one slight headache... I think it automatically added a space after some symbol, which was only a problem when I used it to edit C++ code. :)  I think this might apply in "screen candy" mode only, though.
13:12:10 <roconnor> mkaemmer: const is the terminial of the protocal, which would probably correspond the the first message, "Hello, I'm foo"
13:12:11 <blackh> Apart from this one thing, it doesn't seem to do any mangling.
13:12:21 <CrazyAzrael1> blackh: That's fine, for C++ I'll use something else, it was mostly the idea of possible documentation generation and easy package viewing in haskell that I was looking for.
13:12:28 <roconnor> mkaemmer: then you can take that and respond, and then it will take your response and respond
13:12:38 <roconnor> mkaemmer: ... that's all I got
13:12:44 <roconnor> might totally be wrong
13:12:49 <blackh> CrazyAzrael1: Leksah has a lot of potential, but it has only achieved some of it so far.
13:13:05 <mkaemmer> interesting
13:13:08 <roconnor> maybe reading this paper would help
13:13:51 <mkaemmer> was it this one: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.7652?
13:14:19 <mkaemmer> er... forget the trailing '?'
13:16:30 <roconnor> mkaemmer: that looks right
13:16:59 <mkaemmer> roconnor: I suspect it would be a good read, if I had the cat-theory background to understand the notation
13:19:19 <roconnor> mkaemmer: oh, it is very short
13:20:16 * roconnor tries to translate the catagory theory to type theory
13:20:18 <dolio> It kind of looks like a fancier version of FixK r = (FixK r -> r) -> r
13:20:23 <roconnor> I could use google translate about now
13:21:06 <sbahra> http://www.pillowsopher.com/blog/?p=116
13:21:08 <sbahra> Great. :-P
13:21:33 <sbahra> Tempting to turn that into an actual track...
13:21:50 <roconnor> *lol* ``While the semantic relevance and programming potential of hyperfunctions are still unclear ...
13:22:03 <roconnor> So they aren't going to tell us what they are used for.
13:22:13 <mkaemmer> roconnor: hehheh
13:22:21 <dolio> No one knows!
13:23:29 <mkaemmer> dolio: nope, but 3 internets to the first person to find a cool application
13:23:58 <dolio> Non-strictly positive types are evil, and should be eliminated, so there is no application. :)
13:24:03 <harlekin> @hoogle Int -> a -> [a]
13:24:03 <lambdabot> Prelude replicate :: Int -> a -> [a]
13:24:03 <lambdabot> Data.List replicate :: Int -> a -> [a]
13:24:03 <lambdabot> Prelude drop :: Int -> [a] -> [a]
13:24:24 <mkaemmer> dolio: no internets for you then :o
13:24:43 <dolio> Actually, it's the type "FixDK r o = (FixDK r o -> o) -> r"
13:25:11 <dolio> Where "DK r o a = (a -> o) -> r" is the indexed monad you use for delimited continuations.
13:25:20 <roconnor> dolio: Type Dom = Dom (Dom -> Dom) seems somewhat useful, or at least something like this might be useful.
13:25:33 <mauke> that's lambda calculus
13:25:34 <dolio> As opposed to the monad "K r a = (a -> r) -> r" for abortive continuations.
13:25:46 <roconnor> mauke: which is useful!
13:26:28 <dolio> I may have mixed up some rs and os in that DK, of course. I don't have the right order memorized.
13:26:29 <mkaemmer> dolio: what are your beliefs on non-regular types?
13:27:17 <dolio> They're okay? Why?
13:27:43 <mkaemmer> dolio: just wondering, since you're agains non-strictly positive types
13:27:51 <mkaemmer> althought they're a whole other bag
13:27:57 <roconnor> what are non-regular types?  Types with -> ?
13:27:58 <dolio> Non-regular types are actually allowed in the harder core type theories.
13:28:22 <mkaemmer> also, I find it annoying that "fold" wont type-check for non-regular types
13:28:32 <mkaemmer> at least without some weird existential-type-fu
13:28:46 <dolio> Stuff like 'data Foo a = Nub | Bang a (Foo (a,a))'
13:28:57 <mkaemmer> roconnor: nonregular types are ones that recursively call themselves with different arguments
13:29:14 <mkaemmer> dolio: yeah, like that.
13:30:49 <dolio> I'm actually not that against non-strictly postive types.
13:31:24 <dolio> Negative types lead to bad stuff if you're looking for a total language.
13:31:39 <dolio> But then positive-but-not-strictly-positive types get thrown out with them.
13:32:07 <dolio> And I've never seen an example of where the latter yields problems.
13:32:21 <roconnor> mkaemmer: ooh.  Non-regular types are awesome
13:32:30 <roconnor> I got them added to Coq
13:33:05 <mkaemmer> cool :)
13:33:47 <ksf> so, did anyone of you already start working on that cool book "The Agda Road to Logic"?
13:33:57 <Saizan_> so coq had gadts but not non-regular types?
13:34:11 <roconnor> Saizan_: more or less I think
13:35:24 <roconnor> Saizan_: you could sort of do non-regular types, but it ended up bumping up a universe level somewhere and eventually I got a universe inconstency when doing the lambda calculus example.
13:35:28 <Saizan_> ksf: link?
13:35:37 <ksf> Well, you're supposed to write it.
13:35:44 <roconnor> Saizan_: now it works fine
13:35:47 <dolio> How does that even work? Aren't non-regular types a special case of inductive families?
13:36:05 <roconnor> dolio: universe level issues
13:36:11 <dolio> Ah.
13:36:46 <Saizan_> mh, i think i've never learned properly how the universe levels work
13:36:50 <dolio> I guess you had to use indices previously, or something? And quantify over the type at the constructor level?
13:37:03 <lucas_> hey
13:37:19 <lucas_> in haskell if define as a special form ?
13:37:20 <ksf> the rationale is that dependent typing / type theory is bleeding interesting and mostly intuitive to programmers, but all those books and papers about logical systems aren't.
13:37:22 <heatsink> I tried to embed System F into Coq once, and ran into the negative type restriction when trying to embed functions.  I don't recall why.  As I recall, the negative occurrences were at a structurally smaller type.
13:37:23 <dolio> I don't actually know Coq very well.
13:37:42 <lucas_> or if works as normal order and haskell is lazyu language so if doesnt define as a special form
13:37:48 <lucas_> wich one is true ?
13:37:54 <roconnor> dolio: I didn't understand your question
13:38:03 <mauke> lucas_: 'if' is special, it's built into the language
13:38:10 <dolio> roconnor: Well, I can write it in agda...
13:38:10 <roconnor> heatsink: system F supports non-terminating functions?
13:38:15 <lucas_> why special
13:38:16 <mauke> lucas_: but you could also write your own 'if'
13:38:21 <lucas_> because of working style ?
13:38:30 <ksf> as nowadays one doesn't even learn how to do proofs in maths, there's just a gap to be filled.
13:38:34 <mauke> because someone liked the 'if X then Y else Z' syntax
13:38:40 <dolio> roconnor: "data Foo (a : Set) : Set where Bar :: Foo (a,a) -> Foo a" wasn't allowed...
13:38:43 <lucas_> mauke,
13:38:53 <lucas_> can i write if as applicitive order in haskell
13:39:16 <mauke> if_ c t e = case c of True -> t; False -> e
13:39:19 <dolio> roconnor: But "data Foo : Set -> Set1 where Bar :: {a : Set} -> Foo (a,a) -> Foo a" was, which has the universe bump.
13:39:19 <roconnor> dolio: that was disallowed in the similar Coq code.  Now it is allowed
13:39:26 <roconnor> dolio: that is correct
13:39:28 <mauke> what's applicative order?
13:39:34 <heatsink> roconnor, System F is terminating according to TAPL
13:39:55 <roconnor> heatsink: interesting.
13:39:56 <yitz> @let if' prop th el | prop = th | otherwise = el
13:39:58 <lambdabot>  Defined.
13:40:17 <lucas_> applicitive oder evaluates identifer when function call lazy wait until identifier is needed
13:40:21 <mkaemmer> yeah, it was my understanding System F was terminating as well
13:40:39 <dolio> As long as you don't add fix as a primitive or something.
13:40:40 <jmcarthur_work> mine as well
13:40:49 <dolio> Or something equivalent.
13:41:44 <resistor> does anyone know the status of GHC 64-bit on Mac OS X?
13:42:36 <Saizan_> lucas_: to write an if in a strict language you can make it of type :: Bool -> (() -> a) -> (() -> a)
13:43:03 <lucas_> strict = lazy
13:43:04 <lucas_> ?
13:43:24 <mauke> strict ≠ lazy
13:43:28 <ksf> well you can lazyfy your language if it's strict.
13:43:36 <lucas_> functions are strict or arguemnts are strict
13:43:36 <ksf> it's harder to strictify a lazy language.
13:44:00 <lucas_> lazyfy this is legal world ?
13:44:01 <lucas_> :d
13:44:05 <ksf> lazify.
13:44:13 <lucas_> sorry
13:44:29 <ksf> lazyfication.
13:44:33 <mkaemmer> ksf: is there a pure way to make a lazy language strict?  I though that "seq" was just a hack
13:44:40 <ksf> lazyficationing.
13:44:44 <lucas_> what exact mean of strict language
13:44:44 <ksf> lazificationing?
13:45:07 <mkaemmer> ksf: sounds like lazy vacationing :D
13:45:14 <ksf> mkaemmer, I guess you could do something with bogous arguments to introduce moar data dependencies.
13:45:59 <ksf> ahh yes haskell isn't lazy, it's non-strict.
13:46:20 <mauke> lucas_: in a strict language all function arguments are evaluated before the function is called
13:46:20 <ksf> full lazyness is a completely different beast, albeit a very, very interesting one.
13:46:27 <dolio> You can write seq yourself for just about anything except functions.
13:46:30 <mkaemmer> ksf: I guess I don't understand/appreciate the distinction
13:46:43 <dolio> And it shouldn't work on functions anyhow.
13:47:07 <lucas_> mauke,
13:47:11 <ksf> seq breaks purity, anyway.
13:47:13 <lucas_> this is also lazy
13:47:20 <ksf> ...wrt. bottoms, that is.
13:47:22 <lucas_> this seems it is lazy definition
13:47:45 <mauke> lucas_: no, in a lazy language the function is called before any argument is evaluated
13:48:26 <lucas_> function is evaluated
13:48:29 <lucas_> hmm
13:48:44 <lucas_> i am bit confused
13:49:03 <ksf> ...and in c it's quite easy to only pass closures, never values.
13:49:13 <lucas_> because i read something that said in lazy language argument are evaluated when they are needed
13:49:22 <ksf> yep.
13:49:23 <lucas_> i mean argument evaluated in the function body
13:49:27 <mauke> yes
13:49:36 <ksf> and "when they are needed" isn't "when control passes into the function"
13:49:47 <ksf> > const 1 undefined
13:49:48 <lambdabot>   1
13:49:57 <ksf> > const error "foo" 1
13:49:59 <lambdabot>   No instance for (GHC.Num.Num [GHC.Types.Char])
13:49:59 <lambdabot>    arising from the literal ...
13:50:07 <ksf> > const (error "foo") 1
13:50:08 <lambdabot>   * Exception: foo
13:50:13 <mauke> > (\x y -> x) 1 2
13:50:15 <lambdabot>   1
13:50:21 <mkaemmer> const 1 (last [1..])
13:50:27 <mkaemmer> > const 1 (last [1..])
13:50:28 <lambdabot>   1
13:51:19 <MarcWeber> nominolo: I've seen you've cherry-picked my patches. Do they work for you?
13:51:33 <lucas_> i ask something
13:51:46 <lucas_> why if is defined as a special form
13:51:55 <lucas_> if  works in lazy
13:51:56 <lilac> Some Arrow laws for Hyper proved: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8118#a8118
13:51:57 <nominolo> MarcWeber: no.  not with my version of vim
13:51:59 <lucas_> haskell is lazy
13:52:05 <Saizan_> lucas_: it's just syntactic sugar
13:52:14 <nominolo> some python error about a missing/unknown function
13:52:23 <lucas_> define as a special form syntatic sugar ?
13:52:27 <ksf> if it wasn't syntax, there wouldn't be a then and else.
13:52:50 <Saizan_> lucas_: the only special thing about if in haskell is the syntax
13:53:16 <ksf> it should desugar into a case-match.
13:53:17 <Saizan_> lucas_: you could simply use a function and get the same, but without the "then" and "else" to separate the branches
13:53:36 <jmcarthur_work> if a then b else c  ==  case a of True -> b; False -> c
13:54:29 <MarcWeber> nominolo: Can you tell me which function is causing the trouble? It should just work.
13:54:31 <mauke> if_ a b c = [c, b] !! fromEnum a
13:54:45 <ksf> mauke, stop being evil.
13:54:57 <mauke> mwahahaha
13:55:32 <lucas_> wnfnwngfw
13:55:42 <ksf> if' a b c = [c,b] !! unsafeCoerce a
13:55:51 <lilac> if_ a b c = last $ zipWith const [c,b] [False..a]
13:56:04 <lucas_> what is it
13:56:05 <lucas_> :D
13:56:27 <nominolo> MarcWeber: ah, ok, so apparently my macvim version doesn't have the subprocess module.  hm, let me check with my other vim build
13:57:08 <ray> lol lilac
13:57:18 <MarcWeber> nominolo: I guess it's a python problem then..
13:57:24 <ksf> if' a b c = unsafePerformIO $ peekByteOf (newArray [c,b]) $ unsafeCoerce a
13:57:30 <lilac> mauke took my usual standby for obscure if', so i needed a new one :)
13:57:46 <jmcarthur_work> lilac, you are in love with zipWith today, i see
13:57:50 <mauke> if' = id
13:57:52 <nominolo> MarcWeber: yeah, OS X's default version is too old
13:58:02 <mauke> (lambda calculus)
13:58:03 <mkaemmer> lilac: awesome, thanks :)
13:58:03 <lilac> jmcarthur_work: today and every day :)
13:58:33 <lilac> mkaemmer: my head asplode many times doing that :)
13:59:23 <ray> the poor Ix instance doesn't get enough love
14:00:44 <ray> > let not = inRange (False,False) in not True
14:00:46 <yitz> if' prop th el = fromJust $ (guard prop >> return th) `mplus` return el
14:00:46 <lambdabot>   False
14:01:20 <nominolo> MarcWeber: and when i call background typecheck it says evalscionAssign is not defined, that might be related though.
14:01:39 <nominolo> because the subprocess error happens earlier, when i try to complete after the load command
14:02:11 <MarcWeber> nominolo: Yes. I think python evaluation stops when there is an error
14:02:33 <mkaemmer> lilac: sorry about your head :o
14:03:04 <mkaemmer> I'm unfortunately still struggling to write composition, since Control.Arrow uses >>> instead of .
14:03:19 <mkaemmer> its a bit different than you'd think
14:03:24 <mkaemmer> @type (>>>)
14:03:26 <lambdabot> forall (cat :: * -> * -> *) a b c. (Control.Category.Category cat) => cat a b -> cat b c -> cat a c
14:03:46 <lilac> mkaemmer: you're still using base-3 then?
14:04:28 <monochrom> Control.Arrow provides <<< too.
14:04:29 <lilac> if' b t e = last $ zip (show b) (cycle [t,e])
14:05:25 <mkaemmer> oh O_o apparently I am
14:05:50 <ray> if' p t f = (t:f:[]) !! (index (False,True) p)
14:05:55 <mkaemmer> I guess my desktop is less up to date than my laptop
14:05:58 <ray> there's my Ix one
14:06:02 <mkaemmer> been awhile since I've used it
14:06:10 <jmcarthur_work> mkaemmer, all Arrows are Categories, and Category has (.)
14:06:47 <jmcarthur_work> mkaemmer, well, depending on your version of base
14:06:55 <mkaemmer> not on my system it doesn't :(
14:06:56 <lilac> if' b t e = listArray (False,True) [e,t] ! b
14:07:00 <lilac> ray: ^^ or that
14:07:06 <jmcarthur_work> http://www.haskell.org/ghc/docs/latest/html/libraries/base/Control-Category.html
14:07:12 <ray> that one uses Ix for its intended purpose even
14:07:14 <mkaemmer> jmcarthur_work: but yes, you are right to point that out
14:07:25 <lilac> ray: yeah, it almost seems like cheating
14:08:31 <maxote> hi guys, what need i to build GHC-6.10.4 from scratch?
14:08:40 <lilac> bonus points for the first person to do it with Bool's Random instance :)
14:08:41 <HugoDaniel> maxote: a compiler
14:09:01 <MarcWeber> nominolo: I'd like to add some module completion. Are you fine with iDM -> import Data.Map, iqDM -> import qualified Data.Map ?
14:09:08 <maxote> is there any issue about circular dependencies?
14:09:32 <nominolo> MarcWeber: i'd prefer a space
14:09:40 <jmcarthur_work> maxote, usually you use a bootstrap compiler
14:09:49 <jmcarthur_work> maxote, a binary ghc or something
14:09:56 <nominolo> MarcWeber: i.e., i[TAB]DM[TAB]
14:10:02 <maxote> grrrr
14:10:06 <Berengal> ghc 6.4 can be compiled from gcc I think
14:10:13 <MarcWeber> How many tabs do you have to type? We can have all.
14:10:13 <nominolo> and the first [TAB] expands to "import "
14:10:22 <jmcarthur_work> maxote, rumor has it that you can use ghc to give you c code to compile with a c compiler
14:10:34 <nominolo> MarcWeber: hm?
14:10:35 <jmcarthur_work> from another platform, that is
14:11:00 <dino-> maxote: Are you getting set up on a platform that has no GHC yet? Just curious.
14:11:16 <maxote> the problem is that i'm using old linux distro, and the recent binary GHC compiler fails to run due to i've not the latest GLIBC for it :(
14:11:19 <burp> :t newArray
14:11:20 <lambdabot> Not in scope: `newArray'
14:11:25 <burp> @hoogle newArray
14:11:26 <lambdabot> Data.Array.Base newArray :: (MArray a e m, Ix i) => (i, i) -> e -> m (a i e)
14:11:26 <lambdabot> Data.Array.MArray newArray :: (MArray a e m, Ix i) => (i, i) -> e -> m (a i e)
14:11:26 <lambdabot> Data.Array.MArray newArray :: (MArray a e m, Ix i) => (i, i) -> e -> m (a i e)
14:12:16 <dino-> ah, the generic precompiled 6.10.4 no good. :/ bleh
14:12:33 <monochrom> Bootstrapping is overrated.
14:12:42 <monochrom> Err, wrong wording.
14:13:10 <monochrom> "I really need to build from source" is overrated.
14:13:41 <lucas_> hey
14:13:48 <mauke> I NEED TO BUILD FROM UML DIAGRAMS
14:13:58 <lucas_> can someone suggest any tutorial i am beginner on lambda calculus
14:13:59 <Berengal> Get a newer version of glibc, or compile a statically linked version of ghc on another computer
14:14:11 <monochrom> "This particular OS has a policy of building everything except gcc from source"  I'm sorry to hear that, but that policy sucks. I say, vote with your feet.
14:14:14 <lucas_> i mean this tutrial explain everything step by step
14:14:15 <nominolo> WHAT? U EM EL?
14:14:26 <yitz> @google alligator eggs
14:14:27 <c_wraith> what did you call me?
14:14:27 <lambdabot> http://worrydream.com/AlligatorEggs/
14:14:27 <lambdabot> Title: Alligator Eggs!
14:14:41 <yitz> lucas_: see above link
14:14:54 <dino-> I don't see so much of that in the job listings. Has that dirty old UML fallen out of favor?
14:14:55 <lucas_> alligatorEggs
14:15:06 <lucas_> okey
14:15:25 <Vulpyne> http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=8119 -- I'm trying to figure out why this program consumes so much memory. The input file is about 170mb, and has 6.3mil entries. It takes around 800mb just to load, and when using the data it grows significently more.
14:15:38 <Vulpyne> It doesn't run out of stack, but I guess I have some sort of space leak.
14:15:38 <maxote> what are the minimal OS's library requirements of the 6.10.4 binary?
14:15:52 <maxote> i need these data to pick the OS
14:16:20 <dino-> Vulpyne: Without looking at anything yet, 'bytestring' instantly popped into my head first.
14:16:35 <Vulpyne> dino: It's using bytestrings.
14:16:39 <dino-> ok
14:16:57 <Vulpyne> It's building a fairly complex map of maps from the input data.
14:17:24 <mkaemmer> Vulpyne: dunno, but you could probably use less "++", since it has to copy its first argument
14:17:56 <Vulpyne> mkaemmer: There is no ++ (Except when concatenating the string it prints out at the end.)
14:17:56 <Cale> Vulpyne: Are you sure that's an unreasonable amount of overhead?
14:17:56 <mkaemmer> are the strings long?
14:17:57 <Cale> Vulpyne: What's the average size of the 'prefix' entry?
14:17:57 <yitz> @hoogle lines
14:17:59 <lambdabot> Prelude lines :: String -> [String]
14:17:59 <lambdabot> Data.List lines :: String -> [String]
14:17:59 <lambdabot> Data.ByteString.Char8 lines :: ByteString -> [ByteString]
14:18:10 <Vulpyne> cale: It's phone numbers, so about 10 characters.
14:18:49 <lilac> Vulpyne: if the first digit is always less than 2, you could save memory by using an Int *ducks*
14:19:09 <Vulpyne> Heh, it's not.
14:19:13 <maxote> Vulpyne, is not "using data" on demand while the app is loading it because Haskell is lazy?
14:19:38 <Vulpyne> maxote: I'm not completely sure what you're asking.
14:19:57 <Vulpyne> Printing out the sizes of the maps and sub maps is forcing some of it to be evaluated though.
14:20:37 <maxote> briefly, the lazy evaluator doesn't 2 stages, 1st loading it, 2nd using it, the lazy evaluator does loading and reusing it one to one on demand.
14:20:49 <lilac> Vulpyne: the code looks superficially ok to me, sorry :(
14:20:59 <Vulpyne> lilac: Thanks for looking.
14:21:03 <jmcarthur_work> Vulpyne, have you done any profiling?
14:21:04 <yitz> Vulpyne: did you try it with different size smaller data sets? is this linear?
14:22:10 <Vulpyne> Hmm, I haven't tried profiling yet. I couldn't profile the actual program since not every lib was compiled with profiling.
14:22:14 <Vulpyne> I should do that.
14:22:35 <Vulpyne> I've tried different sized data sets and it seems like it uses more than I would expect given the input size.
14:22:57 <dino-> Vulpyne: I know it doesn't help, but this amount and type of data makes me think this is for some real job stuff. If so, awesome.
14:23:17 <Vulpyne> dino: It is. :) I love Teliax, they let me do most of coding in Haskell.
14:23:35 <yitz> Vulpyne: I know it looks like too much - the question is, is the too much a linear or non-linear function of the input data size?
14:24:16 <monochrom> I wonder if "sum" is the right function to use.
14:24:33 <lilac> Vulpyne: random suggestion: in subf, you might want to update the new record so the prefix matches the existing one
14:24:49 <lilac> Vulpyne: i know they're the same, but if you do the update they'll also be shared
14:25:16 <lilac> Vulpyne: you could take that a step further and not store the prefix in the Rate, just as a map key
14:26:11 <dino-> hm, is sum non strict?
14:26:37 <c_wraith> How could it be?
14:26:38 <lilac> it's as strict as (+) is for your Num iirc
14:26:43 <Berengal> No, sum isn't strict, but it should be
14:26:46 <Berengal> @src sum
14:26:47 <lambdabot> sum = foldl (+) 0
14:26:50 <monochrom> map (M.size . snd) . M.toList  is better off as  map M.size . M.elems
14:26:59 <Berengal> > sum [1..1000000]
14:27:01 <lambdabot>   * Exception: stack overflow
14:27:07 <Berengal> > foldl' (+) 0 [1..1000000]
14:27:09 <lambdabot>   500000500000
14:27:13 <lilac> Vulpyne: strict bytestrings might be more appropriate for your prefixes anyway
14:27:16 <maxote> @src sum'
14:27:16 <lambdabot> Source not found. My pet ferret can type better than you!
14:27:33 <maxote> @src foldl'
14:27:34 <lambdabot> foldl' f a []     = a
14:27:34 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
14:27:36 <maxote> @src foldl
14:27:36 <lambdabot> foldl f z []     = z
14:27:36 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
14:28:36 <Vulpyne> lilac: Hmm.
14:28:48 <Vulpyne> lilac: It completed running with 183mb max used when I eliminated prefix.
14:29:25 <Vulpyne> The updating thing didn't seem to have an effect when I tried that.
14:30:39 <copumpkin> anyone know when the next boston haskell user group meeting is?
14:31:20 <MarcWeber> http://dpaste.com/78479/ @ nominolo
14:31:25 <copumpkin> anyone know when the next boston haskell user group meeting is? (not sure if this went through just now)
14:31:49 <MarcWeber> I have something like this in mind
14:32:10 <Vulpyne> lilac: Actually, 400mb. I was accidently using the price as the prefix. Heh. That is still an improvement though.
14:32:16 <dino-> copumpkin: I don't know but I bet shapr would know.
14:33:46 <yitz> Vulpyne: without calculating anything, my gut feeling is that Cale is right - that is really the overhead for these data structures (lots of lists inside maps)
14:33:52 <soupdragon> boston donuts
14:35:19 <Cale> Vulpyne: you might also try -funbox-strict-fields and see if it helps at all
14:35:59 <Vulpyne> Once it starts to actually pull stuff out of that structure, the memory used grew way more. It hit 2gb and ran out of swap.
14:36:44 <esdee> is there a function to get just the keys or values from an assoc list?
14:37:01 <Berengal> map (fst/snd)
14:37:06 <jmcarthur_work> map fst and map snd
14:37:12 <jmcarthur_work> blast, beaten
14:38:35 <Vulpyne> yitz: Is there another data structure that would be more efficient for this?
14:39:31 <Vulpyne> I think pulling the prefix field out of Rate may have fixed the main issue though. It seems to be generating stats using a constant amount of memory after loading.
14:39:40 <Vulpyne> It's still using 700mb, but I can live with that.
14:39:50 <yitz> Vulpyne: it depends what you need to do with this data. Do your really need the whole thing to be resident in memory all at once?
14:40:14 <Vulpyne> yitz: It's basically a list of prices. I have to send a large amount of queries for items in it.
14:40:27 <Vulpyne> And generate statistics at the end. So any of those queries could require any item in the set.
14:41:03 <jmcarthur_work> sounds like this data might belong in a proper database or something, to me
14:41:27 <Vulpyne> It is.
14:41:29 <yitz> Vulpyne: I was about to say what jmcarthur_work said (blast!)
14:41:53 <jmcarthur_work> Vulpyne, why not do database queries then?
14:41:59 <maxote> Vulpyne, use   sum' = foldl' (+) 0   instead of sum
14:42:01 <Vulpyne> I expected loading it into memory and running queries against the memory to be considerably more efficient than generating 6mil SQL queries or so.
14:42:14 <yitz> maxote: well spotted!
14:42:19 <jmcarthur_work> Vulpyne, don't generate a million SQL queries then :P
14:42:41 <Vulpyne> maxote: The sum part is just summing the sizes of the maps (and there are only 10 or so zones.)
14:42:44 <jmcarthur_work> Vulpyne, use a few complex SQL queries that the database can optimize server-side or something
14:42:49 <mike-burns> Databases are really good at this.
14:43:15 <mmorrow> mauke: ping
14:43:49 <Vulpyne> maxote: And that part's just for printing status out.
14:44:25 <Berengal> If I've got lots of relatively small indendent IO () actions, is mapM_ forkIO a good strategy?
14:44:47 <Vulpyne> jmcarthur: Oh, there are complex SQL queries for doing this. :) It just seems counterintuitive that knowing the exact algorithm, I can't do it more efficiently in memory, without any overhead of SQL parsing or any of the other things that aren't needed.
14:44:51 <Vulpyne> Not to mention network traffic.
14:45:20 <jmcarthur_work> Vulpyne, sounds to me like you have discovered that this way is not so efficient after all ;)
14:45:39 <yitz> Berengal: only if they need to run concurrently. Or if you have lots of CPUs you want to use.
14:45:40 <jmcarthur_work> Vulpyne, if you are only after statistics, surely you could just use SQL to generate them
14:45:45 <maxote> don't map, use infinite lists only
14:46:03 <ksf> map works with infinite lists.
14:46:26 <ksf> > map (2^) [1..]
14:46:28 <lambdabot>   [2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,26...
14:46:30 <Vulpyne> jmcarthur: In this specific case I just want statistics, but the same data will be used for other stuff. Also, the statistics aren't just based on the price info alone.
14:46:34 <Berengal> yitz, let's say I'm on a regular quad-core and have nothing else to do besides these
14:46:59 <jmcarthur_work> Vulpyne, this still sounds like the kind of thing databases are designed for
14:47:09 <Berengal> yitz, they don't /need/ to run concurrently, but hopefully it'll be four times as fast
14:47:29 <jmcarthur_work> if you are using a SQL database merely for storage and not for processing, you're missing out on a lot of the nice things about databases
14:47:38 <ksf> Berengal, well, be carefull not to spawn too many threads.
14:47:52 <ksf> forkIO is dead cheap in haskell, but still there's overhead.
14:47:53 <jmcarthur_work> well, SQL isn't such a hot language, but the paradigm is perfect for a lot of things
14:48:10 <dino-> Also, if the main thread quits, will it take those forks with it?
14:48:15 <maxote> the cartesian product of tables A x B, it matters the order of picking 1st the left and later the right tables, or viceversa, depending of how length is A or B
14:48:27 <ksf> dino-, yes.
14:48:31 <yitz> Berengal: if you can use forkIO or par to divide them into not all that much more than 4 subsets, otherwise it may not be worth it.
14:48:41 <dino-> So wait for all those kids to complete
14:49:02 <jmcarthur_work> maxote, a good rdbms will make good choices about those things in its optimizer
14:49:25 <maxote> for AxB, if A is much longer than B then it's interesting to eval 1st B to stay in memory, and use A as if it's an infinite list.
14:49:32 <nominolo> MarcWeber: Actually, I'm not concerned about front-end issues.  How much of this would concern the back-end?
14:50:08 <Berengal> yitz, so something like 'mapM_ (mapM_ forkIO) . divideInFourLists $ ioList' would be better?
14:50:34 <Berengal> (assuming divideInFourLists :: [a] -> [[a]])
14:50:55 <mmorrow> Berengal: "fix (\o -> forkIO (mapM_ forkIO [o,o]) >> return())" is a good one
14:51:01 <mmorrow> especially in ghci
14:51:09 <mmorrow> (get ^Z ready)
14:51:34 <pikhq> mmorrow: Nice forkbomb.
14:51:46 <pikhq> Well, threadbomb. :)
14:51:55 <mmorrow> i love how it returns immediately, then .5 seconds later you start swapping
14:52:12 <Berengal> Hmm...
14:52:14 * Berengal tries
14:52:30 <Vulpyne> jmcarthur: I'm fairly familiar with database systems, and the database is used for more than just storage in many cases. I thought that I could in this specific case do it more efficiently.
14:52:31 <mmorrow> i haven't tried it in compiled code
14:52:53 <mmorrow> (though i'd imagine it has the same behavior)
14:53:07 <Berengal> didn't return...
14:53:09 <Vulpyne> I know for sure that I could if I wrote it in C.
14:53:15 <Berengal> But ate lots of memory
14:53:29 <pikhq> Vulpyne: Then do it in C and use the FFI?
14:53:51 <mmorrow> Berengal: mine returned immediate in 6.10.1 ghci
14:53:56 <mmorrow> *immediately
14:54:14 <Vulpyne> pikhq: Haskell is far more fun to program in.
14:54:17 <mmorrow> Berengal: maybe the next line just didn't get flushed out to your terminal
14:54:44 <pikhq> Vulpyne: Truth.
14:54:45 <Vulpyne> Given great enough expertise in Haskell, from what I have seen, you can get quite close to C performance.
14:55:01 <pikhq> Yup.
14:55:08 <Berengal> mmorrow, maybe, but it's repeatable (6.10.4)
14:55:13 <Vulpyne> So when I write something in Haskell that has performance characteristics that far below C, I look for help and a way to expand my knowledge so I can write it in Haskell. :)
14:55:33 <jmcarthur_work> but we don't know that this is even below what a C version would do
14:55:42 <pikhq> Vulpyne: Well, that's a good way of going about it.
14:55:54 <maxote> Vulpyhne, GHC has FFI, implement C subroutines for your needs.
14:56:12 * mmorrow tries in 6.10.3 then HEAD
14:56:20 <mmorrow> i don't have 6.10.4 though
14:56:58 <Vulpyne> I'm pretty sure you could write it in C to use roughly the same amount of memory as the data set.
14:57:05 <jmcarthur_work> mmorrow, doesn't return for me on 6.10.4 either
14:57:33 <mmorrow> Berengal: right, it doesn't come back in 6.10.3, but ^Z works immediately though
14:57:42 <jmcarthur_work> yeah ^Z worked for me, too
14:57:45 <Berengal> Yeah, ^Z worked right away
14:57:53 <Berengal> It didn't in 6.10.1?
14:57:58 <mmorrow> whereas ^Z took a while for 6.10.1, but i think that was because i was already swapping by the time i hit it
14:58:01 <soupdragon> haskell
14:58:24 <jmcarthur_work> Vulpyne, the map and everything?
14:58:37 <mmorrow> err, that must be it i guess (swapping caused the delay) since non-kernel whatever shouldn't be able to cause a delay with ^Z
15:00:12 <soupdragon> :(
15:00:19 <Vulpyne> jmcarthur: Well, it's two layers of maps, so the first is quite small. The internal maps wouldn't use much more than the data size because a hash would just be an array of pointers in C, so even if it was fairly sparse, wouldn't use that much.
15:01:03 <Berengal> swap is essential when doing haskell...
15:01:14 <etpace> if I have average xs = sum xs / len xs, does it transverse the list twice, if so -- is there an implementation of average that doesn't?
15:01:27 <soupdragon> etpace
15:01:47 <soupdragon> look
15:01:49 <maxote> Vulpyne, use divide-and-conquer (dividing the rectangle of the cartesian product to subrectangles, eval them individually, and eval merged them)
15:01:55 <sjanssen> etpace: the list is traversed twice in that example
15:02:07 <soupdragon> if sum = foldr sumCons sumNil
15:02:11 <etpace> something like averages [] s l = s/l, averages (x:xs) = averages xs (s+x) (l+1) i guess?
15:02:13 <dons> jobs for all!
15:02:24 <soupdragon>  & len = foldr lenCons lenNil
15:02:45 <ksf> google is hiring 1000 haskell devs?
15:02:50 <Berengal> dons, we have jobs now?
15:02:54 <sjanssen> etpace: uncurry (/) $ foldl' (\(!s, !n) x -> (s + x, n)) (0, 0) xs
15:02:59 <soupdragon> average = uncurry (/) . foldr ?1 ?2
15:03:01 <dons> check the mailing list.
15:03:04 <Vulpyne> maxote: Non sequitur?
15:03:16 <mmorrow> , let mean xs = let n = fromIntegral (length xs); m = fromIntegral (foldl' (+) 0 xs) in n `par` m `seq` m / (n::Double) in mean [0..999999] {- etspace -}
15:03:19 <lunabot>  499999.5
15:03:21 <soupdragon> 1 and 2 are derived
15:03:24 <dons> http://www.mail-archive.com/haskell@haskell.org/
15:03:38 <sjanssen> mmorrow: that only works by chance :)
15:04:19 <mmorrow> iirc seq beat the pseq one when i timed them
15:04:22 <maxote> it will consume how much 1/4 of memory
15:04:24 <Berengal> yay(ne street)!
15:04:26 <etpace> What does ? and ! do?
15:04:30 <mmorrow> sjanssen: (if that's what you're talking about)
15:04:40 <jmcarthur_work> dons, it's funny that you guys have foosball listed as a benefit. we have the same thing listed as a benefit where i work :)
15:05:02 <mmorrow> sjanssen: but who knows what that means (if anything)
15:05:05 <dons> oh, i was supposed to add snooker and ping pong to that. doh
15:05:11 <dons> the ping pong guys will be annoyed
15:05:13 <jmcarthur_work> haha
15:05:24 <dons> (seriously, i forgot to revise!)
15:05:50 <sjanssen> mmorrow: I feel like par is cheating, asymptotic memory use might change if the implementation of par changes
15:05:52 <ksf> heh. at elkware, we had free beer.
15:05:55 <pikhq> etpace: I'm not sure, but I *think* that GHC optimises that into a single traversal.
15:05:57 <jmcarthur_work> dons, thinking about what would happen if i were to, theoretically, apply and get hired at galois, i would probably scare you guys with my aggressive foosball style
15:06:15 <jmcarthur_work> we play very very aggressively (badly) here
15:06:20 <sjanssen> pikhq: you're wrong
15:06:23 <mmorrow> sjanssen: ah, yeah it totally feels like cheating :)
15:06:26 <ksf> ...same here.
15:06:32 <shepheb> I think foosball is gloves-off serious business everywhere.
15:06:35 <glguy> Other than their super-class constraints, are MonadPlus and Alternative different?
15:06:38 <pikhq> sjanssen: So, GHC isn't quite as smart as I want it to be.
15:06:39 <pikhq> Darn!
15:06:51 <Philippa> dons: no arcade machines? :-)
15:06:57 <jmcarthur_work> fail!
15:06:58 <dons> we have a wii
15:07:02 <sjanssen> etpace: ! is a bang pattern, it tells the compiler to strictly evaluate that argument
15:07:12 <jmcarthur_work> mame cabinet :)
15:07:13 <dons> and rock band, iirc
15:07:19 <yitz> who would waste time with foosball pingpong and snooker when you could do something productive, like hanging out on #haskell
15:07:22 <Philippa> ...I guess the wii got a GGXX^Core release
15:07:28 <dons> mwhaah
15:07:44 <etpace> why is the strictness needed?
15:07:45 <jmcarthur_work> we stopped doing rock band because it was too distracting
15:07:48 <etpace> :t uncurry
15:07:49 <shepheb> dons: why must you tempt a poor undergrad so?
15:07:50 <lambdabot> forall a b c. (a -> b -> c) -> (a, b) -> c
15:07:50 <Philippa> still, I figure you know I'm not applying and why, so hey
15:07:56 <jmcarthur_work> don't think we have a wii sitting around anywhere
15:08:21 <sjanssen> etpace: otherwise a big chain of (1 + (1 + ...)) will be built, wasting memory and potentially overflowing the stack at the end
15:08:42 <jmcarthur_work> if you guys have ping pong, though, then galois is a step ahead of us yet
15:08:54 <sjanssen> etpace: ghc -O2 is probably smart enough that the explicit ! annotations aren't required in this case, but I wanted to be thorough
15:09:00 <etpace> Hmm.. Why do you use foldl' and !s !n, don't they do the same thing?
15:09:09 <dons> shepheb: finish your studies, young man!
15:09:38 <Nafai> It would be fun to work at galois, I think
15:09:44 <ksf> foldl' only forces the tuple, not its contents.
15:09:46 <sjanssen> etpace: foldl' will only force the value to WHNF, which will reveal the tuple constructor, but not the two numbers inside it
15:09:56 <Berengal> Who needs studies when you can have foosball and haskell (and money)?
15:09:57 <Nafai> But, 1) it's in Oregon.  2) I'm not experienced enough in FP and only have a Bachelor's
15:10:04 <dons> Nafai: 1) is a benefit.
15:11:00 <etpace> ok, thanks
15:11:20 * ksf is always puzzled by us companies listing things as benefits that are required by law around here.
15:11:36 <c_wraith> benefit: lunch breaks allowed
15:11:46 <Philippa> there's also the bit where some things (eg 401K) don't 'translate' if you're not from the US
15:11:54 <sjanssen> ksf: because USA /= around ksf, apparently
15:12:58 <dons> ksf: espresso is required by law?
15:13:19 <jmcarthur_work> it should be
15:13:28 <Berengal> espression is in the constitution
15:13:34 <Berengal> wow...
15:13:35 <ksf> nah, but health insurance (not only for employees, but everyone) and paid vacation (well, not for freelancers)
15:14:02 <ksf> pension, too.
15:14:09 <shepheb> dons: does Galois do any internships with Masters students?
15:14:24 <dons> we don't have an official intern program, but it is possible
15:14:55 <shapr> I want to do an internship!
15:15:14 <shapr> But first, it's time for capoeira!
15:15:39 <shapr> dons: Oh hey, I found ~250 build failures on hackage when I did a full build, I'll ask you about NMUs when I get back.
15:15:54 <dons> exciting.
15:15:55 <dons> good work.
15:16:03 <dons> and good idea.
15:16:09 <dons> time to start checking things work for 6.12
15:16:28 * dons challenges the other .coms to do a 3rd hiring call today
15:16:47 <shepheb> dons: what would be the best way to inquire about that in a few months?
15:17:16 <sjanssen> shapr: NMU?
15:17:19 <dons> i would say: email me, and describe areas you're interested in, and experience
15:19:23 <shepheb> dons: excellent, thank you.
15:19:51 * jmcarthur_work vows that if he is ever with a group of Pikewerks people in Portland come to Galois snapping our fingers and wearing suspenders and challenge you guys to a foosball throwdown
15:20:11 <jmcarthur_work> that was horrible english
15:20:44 <shepheb> but a hilarious image
15:20:50 <laynor> hi, I'd like to start learning haskell, as I feel I'm missing something ignoring it. Could you suggest me some good online didactic material?
15:21:14 <Cale> laynor: Sure, maybe start with learnyouahaskell
15:21:21 <Cale> @where lyah
15:21:21 <lambdabot> www.learnyouahaskell.com
15:21:32 <Cale> laynor: There's also Real World Haskell
15:21:35 <Cale> @where rwh
15:21:36 <lambdabot> http://www.realworldhaskell.org/blog/ read it online: http://book.realworldhaskell.org/read/
15:21:36 <jmcarthur_work> @rwh
15:21:37 <lambdabot> Maybe you meant: rc run wn
15:21:38 <jmcarthur_work> grr
15:21:44 <Cale> @where yaht
15:21:44 <lambdabot> PDF: http://darcs.haskell.org/yaht/yaht.pdf Wikibook: http://en.wikibooks.org/wiki/Haskell/YAHT
15:21:47 <Cale> @where wikibook
15:21:48 <lambdabot> http://en.wikibooks.org/wiki/Haskell
15:21:54 <Cale> and other tutorials :)
15:22:15 <Cale> and of course, feel free to ask any questions you might have here
15:22:29 <Cale> There are lots of people around who like to answer beginner questions :)
15:22:37 <etpace> I think I need a project to make in Haskell so I can learn it more
15:22:58 <maxote> Vulpyne, why ratetype = Interstate for all Zone?
15:23:06 <badsheepy> yeah, this is an incredibly helpful channel for beginners
15:23:24 <badsheepy> i think its because haskells learning curve leaves people as beginners for approximately 5 years :p
15:23:32 <laynor> Cale: great :) thanks
15:24:06 <laynor> is ghc a good compiler to start learning?
15:24:07 <jmcarthur_work> badsheepy, it's because we all keep learning, so in many sense we are all beginners
15:24:10 <jmcarthur_work> laynor, the best
15:24:22 <laynor> made the right choice then ^^
15:24:28 <badsheepy> and cause haskell is busy changing beneath our feet in confusing ways:)
15:24:30 <Philippa> badsheepy: that depends a bit on what you're doing in those 5 years - though it's easy to /feel/ like a beginner for that long, the curve's distinctly exponential in terms of what you can get done. Once you get out of the sub-linear part of the curve, that's a hell of a ride
15:25:06 <blackh> laynor: GHC is "the" compiler.
15:25:26 <laynor> are haskell's basics so hard to grasp?
15:25:41 <pikhq> laynor: Just different.
15:25:49 <jmcarthur_work> laynor, you will find it easy at first, then hard, then easy, then hard, then easy, etc...
15:26:13 <laynor> that's good, sounds interesting
15:26:14 <jmcarthur_work> (as you approach new ideas, then master them, then approach new ideas, then master them, etc.)
15:26:26 <jmcarthur_work> but the very basics are pretty trivial, IMO
15:27:06 * ksf is in the nasty "I see I could have exponential productivity, but can't express it" phase.
15:27:18 <badsheepy> yeah, its more training your brain to think on a much higher, more productive level than haskell being hard
15:27:21 <blackh> laynor: Haskell's basics are simple, abstract and powerful, and that makes them a bit different to other languages.  So the learning curve comes from the initial unfamiliarity, as well as the huge potential for extending the basics.
15:27:58 <jmcarthur_work> laynor, the hardest part is not learning new things but unlearning old things
15:28:13 <pikhq> Most other languages are low-level by comparison.
15:28:21 <blackh> laynor: Example: In Haskell, exceptions are not "built in" - the language is general enough that they can be defined in terms of the basics.
15:28:45 <jmcarthur_work> blackh, well, there are "real" (IO) exceptions, too
15:28:54 <ksf> and bottoms.
15:29:08 <_randomwords_> Hi, I've asked this but haven't got the root yet, so sorry for spamming. http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3271 has a space leak caused by strategies. Profiling indicates that the lists (in entirity) are not being freed when they should be (e.g. after printing). The leak doesn't occur with parList, but does with parListChunk (even with chunksize 1).
15:29:09 <blackh> jmcarthur_work: Bad example. :)
15:29:31 <ksf> and an rts that kills your program if you're waiting on a mutex that can't be written to.
15:29:35 <laynor> blackh: I'm used to common lisp, and happy to read haskell is quite general too
15:30:03 <ksf> err that can't be unlocked.
15:30:52 <laynor> the things that puzzle me as an outsider is the syntax and monads, the latter mostly because reading online it seems they're hard to grasp
15:30:57 <ksf> laynor, you'll miss the ease of macroing with sexprs, but find many other new friends.
15:31:30 <jmcarthur_work> laynor, monads are much more abstract than any tutorial could possibly explain without being mathy, btw
15:31:31 <laynor> ksf: eheh yeah :) I think that it will be an interesting experience the same
15:31:39 <blackh> laynor: One thing about Haskell is that there's very little syntax.  A lot of things that look like syntax are really library functions.
15:31:43 <ksf> monads are easy as soon as you realize that they are more like a bottle of beer than a sixpack.
15:31:49 <pikhq> The syntax, I found, is easy to grasp.
15:32:07 <pikhq> Monads are so simple but so abstract that it's hard to wrap your mind around them.
15:32:23 <laynor> pikhq: I like this kind of challenges XD
15:32:28 <ksf> monads are also much easier than one's willing to accept before one understands them.
15:32:49 <jmcarthur_work> ksf, very much agreed
15:33:07 <jmcarthur_work> monads are so simple that it's laughable how hard people make it to learn
15:33:14 <jmcarthur_work> (i was one of these people)
15:33:42 <laynor> oh, I was wondering, best development environment?
15:33:52 <ksf> now I need someone to have the same insight about dependent types, and write "The Agda Road To Logic"
15:33:56 <ksf> laynor, vim.
15:33:56 <jmcarthur_work> laynor, text editor and shell
15:34:02 <ksf> zsh!
15:34:04 <jmcarthur_work> laynor, i like emacs, others like vim :)
15:34:14 <jmcarthur_work> we agree on zsh though :)
15:34:24 <kulakowski> zsh indeed
15:34:25 <pikhq> laynor: Emacs.
15:34:30 <pikhq> And zsh, the Emacs of shells. :D
15:34:37 <laynor> ahah
15:34:42 <ksf> zsh has vi bindings.
15:34:45 <jmcarthur_work> pikhq, don't you mean Emacs, the Emacs of shells?
15:34:53 <pikhq> jmcarthur_work: Also true.
15:34:57 <blackh> laynor: There's an IDE called Leksah but it is in its fairly early stages.  Also an unmaintained Eclipse plugin.  But unfortunately you're still best off going lo-tech.
15:34:59 <pikhq> (I'm aware of eshell. :))
15:35:18 <Philippa> laynor: the one thing that's 'hard' about haskell is that you basically have to learn how to program again. So it takes longer than learning most new languages
15:35:21 <jmcarthur_work> there are also some Visual Studio and XCode things, but i have no idea what states they are in
15:35:28 <ksf> the eclipse plugin is being worked on...
15:35:35 <ksf> gsoc.
15:35:39 <laynor> uhm, I'd rather stick with emacs
15:35:43 <blackh> ksf: That's great news - thanks for that.  I'm very interested!
15:35:45 <laynor> with vi bindings of course
15:35:46 <laynor> ^^
15:35:52 <ksf> and there's yi, the one editor to emulate them all to come.
15:35:54 <jmcarthur_work> laynor, haskell-mode is a must, in that case
15:36:21 <laynor> I'm spoiled because of slime lol
15:36:38 * jmcarthur_work has never used slime, but always hears good things
15:36:38 <laynor> slime is maybe the greatest environment I've programmed with
15:36:38 <blackh> laynor: Well, I'm soiled because of slime!
15:36:49 <lucas_> hey i need a source for beta reduction normal form in lambda calculus i am beginner can you just suggest a beginner tutorial
15:36:50 * jao misses slime when hacking haskell too
15:36:55 * blackh lives in a muddy place
15:36:59 <laynor> lol
15:37:23 <laynor> does haskell mode come with emacs?
15:37:26 * ksf suggests the original lambda papers
15:37:31 <jmcarthur_work> laynor, not normally
15:37:37 <laynor> ok, going to look for it
15:37:38 <laynor> :)
15:38:02 <ksf> http://library.readscheme.org/page1.html
15:38:25 <dons> if you learn haskell first, does that make learning other languages easier?
15:38:26 <ksf> Lambda, the ultimate topic.
15:38:32 <dons> if other languages don't really help you learn haskell
15:38:44 <jmcarthur_work> dons, it probably makes learning other languages more painful
15:38:50 <jmcarthur_work> maybe easier, though
15:38:56 <dons> but their concepts become  clearer, perhaps
15:38:58 <_randomwords_> dons: Some do, like other ML family languages
15:39:00 <jmcarthur_work> exactly
15:39:03 <dons> and ad hoc-ness :)
15:39:10 <jmcarthur_work> which is why it's simultaneously easier and more painful
15:39:18 <ksf> I guess prolog, too.
15:39:22 <ksf> anything declerative.
15:39:26 <dons> i always thought of perl context (list vs scalar) as a type class issue
15:39:33 <dons> and perl taint tracking monadically
15:39:37 <laynor> i guess that's the same thing that happens with lisps
15:39:40 <dons> but i learned haskell before i learned perl
15:39:48 <laynor> the other languages feel too "tight" after
15:40:01 <_randomwords_> Going from sml to haskell is fairly painless - the other way is probably even easier
15:40:12 <dons> yeah, they're very close
15:40:17 <dons> you get all the type system fun
15:41:01 * ksf wants to learn agda to understand haskell better.
15:41:23 <ksf> that's why I'm trying to coerce you guys into writing "The Agda Road To Logic" for days now.
15:41:31 <bcw> hi.  i second the prolog comment, learning prolog first has made learning haskell more intuitive for me.
15:41:32 <jmcarthur_work> laynor, going from haskell to most other languages feels like you are intentionally throwing away your contact lenses. you can basically see, but you can't be sure of what you are seeing
15:41:48 <bcw> (i'm just a newbie at haskell.)
15:42:05 * ksf didn't ever write a prolog program
15:42:14 <skorpan> i learned haskell before even trying prolog... i still don't get prolog.
15:42:17 <soupdragon> why aren't you in #agda
15:42:18 <jmcarthur_work> (the analogy is supposed to reflect what it feels like to lose haskell's awesome type system and the safety and clarity it brings)
15:42:27 <jmcarthur_work> and the purity
15:42:29 <ksf> ...and I'm still way sceptical about its evaluation mode.
15:42:40 <soupdragon> there is no evaluation in prolog
15:42:56 <_randomwords_> No.
15:42:57 <bcw> skorpan, well i don't either for really complicated things.
15:43:05 <ksf> soupdragon, because I didn't tell xchat to auto-join #agda, and because there's noone there.
15:43:19 <bcw> prolog needs something like the IO monad concept
15:43:27 <skorpan> bcw: i know just super little prolog (not even that anymore really) but it all seemed like magic to me
15:43:30 <jmcarthur_work> i don't really get the big deal with prolog, honestly. it's just a functional language with nondeterminism built in, right?
15:43:45 <laynor> ok, time to start learning XD
15:43:49 <soupdragon> bcw, if you want a haskell version of prolog then there's merc...... ah scratch that, Haskell
15:44:06 <jmcarthur_work> bcw, mercury has that covered
15:44:12 <bcw> skorpan, mm.  magified haskel perhaps?
15:44:15 <jmcarthur_work> err, yeah, what soupdragon said ;)
15:44:24 <skorpan> bcw: haskell is magic too
15:44:34 <skorpan> bcw: if you don't believe me look at something written by dons
15:44:51 <jmcarthur_work> s/dons/oleg/
15:44:52 <ksf> haskell has the list monad, scheme has amb... so what's prolog useful for?
15:45:11 <skorpan> i haven't seen any of oleg's work, but that's a different type of magic
15:45:18 <bcw> soupdragon, i actually like haskell better. much more general, it seems from what i've read
15:45:20 <dons> LogicT gets used a lot these days for search problems
15:45:30 <dons> glguy's playing with search right now, paramaterizing search
15:45:43 <dons> "your language is our library"
15:45:48 <soupdragon> ksf (and others) Prolog is more than just 'search'
15:45:53 * dons has a EDSL slogan for 2009
15:46:02 <blackh> "all your language are belong to us"
15:46:02 <Cale> ksf: Prolog's unification is much more general than the list monad's though...
15:46:39 <ksf> oh no, they planted us a semantics!
15:46:40 <Cale> ksf: It's kind of hard to do full Prolog-style unification in a pretty DSL in Haskell, since we don't really have a great way to define new binding forms.
15:46:51 <Cale> Though perhaps something involving TH could work.
15:47:10 <ksf> yeah, oleg has been complaining about that in his oohaskell paper.
15:47:17 <soupdragon> something you should bear in mind when thinking about other paradaigms is:  No it's NOT just a monadic interpreter, it's not just a function from State -> State.. If you can't forget that you aren't thinking about in a different paradaigm
15:47:42 <ksf> newtype Ident = Ident
15:48:07 <ksf> there's even a flag that lets you write newtype Ident , without rhs.
15:48:28 <dons> woo. HacPDX!!
15:49:10 <ksf> soupdragon, it's a graph rewrite system?
15:49:14 <Nafai> dons: Yay!
15:49:36 <Philippa> Cale: yeah. Though really, moving to more generic constraints is often good anyway
15:50:05 <Philippa> jmcarthur: prolog is search + equality constraints on terms
15:50:13 * dons thinks HacPDX will be big
15:50:17 <Philippa> the constraints matter. A lot.
15:50:34 <ksf> what's currently completely beyond me is how people can actually come up with ways to extend the type system.
15:51:04 <soupdragon> ksf, it's just adding it bits of dependenty typed programming one at a time
15:51:26 <dons> hey, its just a simple logical framework, http://www.galois.com/~dons/images/fc-tr.png
15:51:28 <soupdragon> (or weird constraint stuff that's way out my domain to comment on)
15:51:30 <dons> do the math :)
15:51:34 <Philippa> Greg Egan had a nice metaphor in Diaspora - essentially, you explore the 'rock face' around the edge of the current system and other related research
15:52:16 <soupdragon> hey Phillipa
15:52:22 <Philippa> hey
15:52:35 * Philippa shouldn't be hanging around too long, there's this 'sleep' thing I hear is good if you're tired...
15:52:43 <soupdragon> okay
15:53:02 <ksf> intuitiveness seems to be antiproportional to the amount of greek variables involved...
15:53:57 <bcw> ksf, unless you're greek (which i'm not, but still)
15:54:05 <nominolo> dons: what's the X in F_C(X)?
15:54:10 <ksf> well, I could cope with cyrillic.
15:54:27 <Philippa> ksf: it's more complicated than that. It depends a lot on whether you had the right set of intuitions going in, and we keep accumulating them
15:54:28 <zloog> Hi, im trying to write something that will allow me to pause and resume some IO actions. So far im just stubbing out the basic ideas, I have this 5 line clip that ghci wont compile due to some kind of type generalization problem http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8120#a8120 . does anyone know what is going on?
15:54:40 <poucet> @tell byorgey I saw your blog on derivative types.  Very well written, though it seems you are just reformulating what has already been said many types, so did I miss something?
15:54:40 <lambdabot> Consider it noted.
15:54:53 <ksf> I've never had any math lectures beyond integrals.
15:55:09 <Philippa> it's not about 'beyond', it's more like a different direction
15:55:36 <Philippa> you can teach the simply-typed lambda calculus to primary school kids with a bit of effort and maybe a few glyph swaps
15:55:47 <ksf> symbol processing actually comes quite natural to me, in contrast to analytology and numericology, but still...
15:56:08 <Philippa> constraints maybe a little bit later, but if you can do algebra, you can handle simple constraint systems
15:56:16 <soupdragon> trigology
15:56:23 <Philippa> (they're key for doing inference)
15:56:42 <soupdragon> they don't teach rewrite systems in computing
15:56:56 <Philippa> after that, you mostly need to cover logic
15:56:56 <nominolo> they don't?
15:57:00 * ksf thinks assertions and typeclasses when he hears "constraints"
15:57:10 <yitz> zloog: drop the return
15:57:21 <nominolo> ksf: unification is also a constraint
15:57:52 <nominolo> i.e., if x :: a and f :: b then f x :: exists c. b == a -> c
15:58:06 <Philippa> ksf: they're a more general thing. For example, any time you apply a function, the typechecker constraints its type to /be/ a function - and the type of the parameter to match it
15:58:15 <hydo> Yay!  a hackathon near me, finally.  Gonna be all up in it.
15:58:32 <nominolo> what is "near" in the US?
15:58:33 <soupdragon> :(
15:58:36 <yitz> zloog: also, unpack the value out of next (which is in IO)
15:58:38 <nominolo> 200 mi?
15:58:51 <nominolo> 500?
15:58:55 <hydo> nominolo:  yea, something like that.  The hackathon is in portland and I'm in seattle.
15:59:01 <zloog> yitz: wow, thanks
15:59:05 <kniu> @pl (\v -> [(n, v)])
15:59:05 <lambdabot> return . (,) n
15:59:14 <nominolo> ok, that's near
15:59:24 <hydo> Maybe I should post something in reply to that thread.  I have a van and could take some sea people to and fro, possibly.
15:59:28 <bcw> soupdragon, formal grammar is partly a rewriting system.  but they don't teach other ones like L-systems, that's true
15:59:29 <ksf> erm ok, but beta-equivalence isn't decidable in non-total lanuages.
15:59:35 <yitz> zloog: np. gl.
16:00:05 <bcw> at least not in basic CS courses
16:00:12 <ksf> which might point to my problem: I don't know how to do the proofs that allow some unificator to unificate.
16:00:46 <soupdragon> you're trying to work some particular proof?
16:00:47 <nominolo> ksf: oh, that's not too hard (in first-order types)
16:01:19 <ksf> ...which is why I'm trying to get you guys to write "The Agda Road To Logic"
16:01:28 <Philippa> heh
16:01:36 <ksf> Did I mention that "The Agda Road To Logic" would be a cool book to have?
16:01:46 <Philippa> yeah, it's an important catch that you can't do /everything/ without user input once you have rank-n polymorphism
16:02:16 <nominolo> MLF gets by with just lambda-argument annotations
16:02:24 <nominolo> but the types get a bit weirder
16:02:38 <nominolo> harder to read, mostly
16:02:47 <Philippa> *nod*
16:03:05 <Philippa> I'd like to see some general properties about composing constraints in various ways...
16:03:07 <nominolo> and the unification algorithm for MLF graphic type is a bitch
16:03:26 <nominolo> but it's linear
16:03:45 <Philippa> which would mostly come down to various conditions under which they're orthogonal, I guess
16:04:06 <nominolo> isn't that highly dependent on the types of constraints?
16:05:43 <Philippa> well yes: finding out in what ways would be useful though
16:06:12 * soupdragon sighs
16:06:19 <laynor> uhm, is indentation significant in haskell?
16:06:23 <Philippa> we know on an intuitive level that the constraints in qualified types don't do anything messy combined with equality constraints, for example
16:06:25 <soupdragon> yes
16:06:29 <Philippa> laynor: mostly
16:06:35 <Armored_Azrael> laynor: Yes, unless you use explicit sequencing.
16:06:50 <Philippa> you can write the equivalent code using {;} instead, and if you do then the whitespace doesn't matter
16:08:03 <eflister> is it expected to be able to far outperform Data.List.sort in both time and space for lists with a small nub?
16:08:09 <eflister> (\y -> concat $ zipWith ($) (zipWith ($) (repeat (filter . (==))) (sort $ nub y)) (repeat y))
16:08:13 <ksf> laynor, in do-blocks and a few other corners of the syntax that one usually doesn't notice, yes.
16:08:18 <laynor> Philippa: uhm, no idea what ; does, but I guess I've seen something similar in caml? I just noticed because my stupid function declaration was not at bol.
16:09:20 <Philippa> laynor: it's the separator for bindings, cases and the like
16:09:49 <Philippa> case foo of {Bar -> ...; Baz -> ...}
16:10:31 <laynor> thanks :)
16:11:16 <ksf> soupdragon, nope, I'm trying to get a better understanding of type systems in general because types are the wall I'm currently hitting in haskell.
16:11:33 <tommd> All, HacPDX has finally been announced.  http://www.haskell.org/haskellwiki/HacPDX
16:11:38 <dons> rock out!
16:11:59 <soupdragon> I can't help you ksf
16:12:01 <dons> this will be a lot of fun.
16:12:03 <tommd> I'm still working issues like food, internet access, and power strips - but we have a room and the rest is simple enough to work out.
16:12:09 <dons> yep
16:13:14 <leimy> When is hacpdx?
16:13:19 <tommd> Sept 25-27
16:13:23 <tommd> Thats a weekend.
16:13:48 <leimy> Hmmm.  I wonder if i should drive down.
16:13:49 * leimy is in Seattle
16:13:58 <dons> there's some people driving down
16:14:01 <dons> check haskell-cafe@
16:14:04 <tommd> leimy: Someone from Seattle already e-mailed the cafe.
16:14:09 <leimy> Cool
16:14:13 <dons> or catch the train
16:14:23 <tommd> Humm, four people in under ten minutes.  I might need a bigger room.
16:14:26 <leimy> I will have to check when i am not on my mobile
16:14:43 <dons> tommd: srsly. it could be big.
16:14:58 <shepheb> sigh, and I'm flying back to Ontario on the 29th of August.
16:14:59 <tommd> I've been worrying that it might be a dud.
16:15:01 <dons> tommd: did you see how many people turned up for the ICFP speakers?
16:15:03 <erikc> hmm...5 hours from vancouver eh
16:15:13 <tommd> dons: No, I had finals - it was a bad week.
16:15:18 <leimy> Yeah... I am thinking I may need help with my haskell 9P implementation.
16:15:19 <dons> so we had maybe 60 ?
16:15:25 <tommd> yikes!
16:15:26 <dons> after planning for 25
16:15:45 <dons> people come up from Corvalis, Eugene etc for tech talks. They'll come further for hacking
16:15:53 <leimy> Anyone played with network-fancy?
16:15:53 <tommd> I'm planning 25.  I can fit in the 60 range with the larger room.
16:16:17 <dons> ok. you requested names/registration?
16:16:19 <tommd> leimy: Not me.  I posted the first project as a Network API project to somewhat replace all the others.
16:16:38 <leimy> Ah
16:16:40 <maxote> americans are wasting more energy in flights than chineses :o
16:16:48 <tommd> dons: Yes!  I would like names so I have an idea of who is coming.  There is also the slim but ugly change the guards and IT folks will want names.
16:16:55 <dons> right
16:16:56 <laynor> take and drop remind me of apl ^^;
16:17:21 <tommd> s/who is/how many are/
16:18:55 <leimy> Well it sounds like fun... I will check cafe later.
16:18:59 <jfoutz> maxote: it's our way. ;)
16:19:23 <eflister> anyone have a quick thought on my sort question above?  i thought my alg was O(n log (length . nub)), but it seems to be much worse than Data.List.sort when (length . nub) ~ n
16:19:58 <bcw> darn, i was hoping the "what links here" on HaskellWiki:Copyrights would link to every page on the wiki (including itself?) -- but only because i'm sometimes a smarta** like that, not because i really need a link to all pages
16:20:03 <jfoutz> @src nub
16:20:03 <lambdabot> nub = nubBy (==)
16:20:09 <jfoutz> @src nubBy
16:20:09 <lambdabot> nubBy eq []             =  []
16:20:09 <lambdabot> nubBy eq (x:xs)         =  x : nubBy eq (filter (\ y -> not (eq x y)) xs)
16:20:46 <eflister> jfoutz: it's just removing dupes
16:21:02 <eflister> which is linear i hope?
16:21:35 <pikhq> Looks both linear and maximally lazy.
16:22:09 <Saizan_> linear?
16:22:12 <Saizan_> it's quadratic.
16:22:19 <pikhq> Erm. XD
16:22:21 <pikhq> So it is.
16:22:25 <eflister> oh right
16:22:27 <eflister> :(
16:23:01 <leimy> Linear nub would be awesome!
16:23:07 <blackh> leimy: Use Set.fromList . Set.toList
16:23:20 <blackh> Or the other way around. :)
16:23:27 <leimy> Heh
16:23:31 <Saizan_> that's O(n log n)
16:23:35 <blackh> Not linear,...
16:23:35 <Saizan_> but it's less lazy
16:24:08 <pikhq> nubBy lets you do a nice bit of prime number generation.
16:24:10 <pikhq> Something to be said for that.
16:24:17 <Saizan_> a lazier O(n log n) version keeps a Set of "already seen" elements and test new ones for non-membership there
16:24:30 <Saizan_> *tests
16:24:37 <Vanadium> How is that not O(n²) :C
16:24:44 <jfoutz> you can do an accumulator with a set.. oh heh. what he said.
16:25:07 <Vanadium> Do you use a tree for the set?
16:25:19 <jfoutz> yeah.
16:25:38 <jfoutz> Data.Map i think.
16:25:53 <bcw> pikhq, really? i've been looking for a way to generate primes with haskell.  there's a nice python recipe for that...
16:25:54 <Saizan_> yeah, Data.Set.Set uses a size-balanced binary search tree
16:26:03 <eflister> only worst case O(n log n) right?  if the nub is small, it would be linear?
16:26:49 <pikhq> Hmm. Where was that... Something like nubBy ((gcd .) < 1) [1..] ...
16:27:08 <Saizan_> >  nubBy (((gcd .).) < 1)
16:27:09 <lambdabot>   Couldn't match expected type `a -> a -> GHC.Bool.Bool'
16:27:12 <Saizan_> >  nubBy (((gcd .).) < 1) [1..]
16:27:14 <lambdabot>   Couldn't match expected type `a -> a -> GHC.Bool.Bool'
16:27:18 <Saizan_> gah
16:27:28 <Saizan_> oh, of course
16:27:37 <Vanadium> You are applying < to a function and a number, I think?
16:27:50 <jfoutz> eflister: if you do your own accumulator, you can count the elements as you go, sort like you wanted with the nub and then repeat the element count times.
16:27:51 <Saizan_> eflister: the size of the list doesn't matter, the composition might
16:27:54 <Saizan_> Vanadium: yeah
16:28:22 <ksf> bcw, http://hackage.haskell.org/package/primes
16:28:27 <Asztal> http://www.haskell.org/haskellwiki/Blow_your_mind for the primes = nubBy ... thing
16:28:41 <Asztal> > nubBy (((>1).).gcd) [2..]
16:28:43 <lambdabot>   [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101...
16:29:08 <jfoutz> that is awesome!
16:29:11 <bcw> ksf, thank you!  (and thanks to pikhq and Saizan_ for trying too)
16:29:16 <eflister> Saizan_: how could size not matter?
16:29:19 <bcw> and Asztal
16:30:04 <eflister> anyway, i was surprised that my alg above is way faster than the default sort when the nub is small.
16:30:07 <Saizan_> eflister: the O(n log n) is already parametrized on size, the 'n'
16:30:14 <Cale> > let isPrime n = all (\p -> n `mod` p /= 0) . takeWhile (\p -> p*p <= n) $ primes; primes = 2 : filter isPrime [3,5..] in primes
16:30:15 <lambdabot>   [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101...
16:30:26 <Saizan_> eflister: you could argue that for small n the log n factor is very small
16:31:10 <jfoutz> you could argue 2^256 > electrons in the universe, therefore log n == constant
16:31:26 <eflister> Saizan_: i mean that the "log n" factor vanishes if your list of "already seens" is very short -- even though n is very large -- resulting in a linear best case, right?
16:32:43 <Cale> I wonder if someone has written the polynomial-time primality testing algorithm in Haskell.
16:32:44 <Saizan_> eflister: nub doesn't keep a set of "already seens" it just filters out from the rest every value already seen, so it's all proportional to n
16:33:07 <eflister> Saizan_: i meant the set implementation
16:34:02 <Saizan_> eflister: ops, got confused for a moment, still there you're not talking about size of the input list, you're talking about its composition
16:34:28 <Saizan_> the set will be small if there's little different elements compared to the list
16:34:41 <Saizan_> size of the list
16:34:52 <Saizan_> so, yeah, i guess it's been a misunderstanding :)
16:34:53 <fbru02> what is the command for lambdabot to show source ?
16:35:48 <eflister> Saizan_: right -- best case of "removing dupes" is "linear in size of list" (if all elements equal)
16:35:57 <eflister> @src nub
16:35:58 <lambdabot> nub = nubBy (==)
16:36:09 <fbru02> @src Maybe
16:36:09 <lambdabot> data Maybe a = Nothing | Just a
16:37:42 <Vanadium> This primes thing is scary as hell :(
16:37:48 <soupdragon> yeah
16:37:53 <soupdragon> I hate prime numbers
16:37:54 <Vanadium> Partial application of . scares the hell out of me
16:38:09 <soupdragon> as soon as someone finds out you are a "mathematician" they go:
16:38:18 <soupdragon> (1) Youre a genous lol!! wow!!! you are soooo smart
16:38:29 <soupdragon> (2) cool I like prime numbers
16:38:50 <soupdragon> and then say basic shit about primes for an hour
16:39:04 <maxote> i like fibonacci numbers
16:39:07 <soupdragon> it's better than (1) I guess
16:39:37 <soupdragon> yeah it's the arty folks that go, "I studied fibs while living off only mescaline for 3 years in the desert"
16:39:37 <leimy> Then they yeach you to spell genius?
16:40:20 <jfoutz> eflister: have you heard of bucket sort? if you can guarantee the list is made of a set of discrete elements, you can do your sort in linear time. the set accumulator approximates that, as you found, because of so many duplicates. i think the set accumulation version is n log m where m is the count of unique elements.
16:40:20 <maxote> leimy, or genuine?
16:42:00 <maxote> the fastest sort is O(n)
16:42:25 <eflister> jfoutz: cool, thx, i'll check it out.  i definitely had not heard of any linear sorts!
16:42:59 <eflister> jfoutz: but isn't every list ultimately made of discrete elements?  :)
16:43:10 <pikhq> eflister: Bucket sort is not a comparison sort. Thus why it has a lower than O(n log n) bound.
16:43:39 <mle> is that another term for a radix sort?  generalized perhaps?
16:44:04 <pikhq> mle: It's a closely related algorithm.
16:44:48 <Cale> Does anyone know if there are interesting lower bounds on the amount of time it takes to test primality?
16:45:09 <jfoutz> mle: i think bucket is like the inverse? you make an array, and just increment the value at index.
16:45:09 <yitz> Cale: it's been proven polynomial
16:45:20 <Cale> yitz: Yeah, but that's an upper bound
16:45:34 <yitz> oh I get your question
16:45:57 <mle> jfoutz: ah.  That won't always be feasible, heh.
16:46:00 <Cale> Like "any algorithm which runs faster than this can't be testing primality"
16:46:16 <fbru02> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=3300#a3300 im trying to write my first monad , but then when i try it in ghci like >MyMaybe "2" i get not in scope data constructor MyMaybe... why is this ? :)
16:46:38 <yitz> Cale: so it has to test primality of any number, right?
16:46:46 <heatsink> fbru02, Did you import your module in ghci?
16:46:48 <jfoutz> mle: i think you can play a game with perfect hashing, since you know your values up front.
16:46:53 <Cale> yitz: yeah
16:47:50 <fbru02> heatsink : im adding the  source file right on i get "[1 of 1] Compiling Main             ( /Users/federicobrubacher/src/haskell/monads.hs, interpreted )"
16:48:24 <heatsink> fbru02, values you type at the ghci prompt are values, but MyMaybe is a type
16:48:38 <heatsink> fbru02, try   :t MyMaybe
16:48:38 <inimino> Cale: wouldn't that be a lower bound?
16:48:44 <Cale> yitz: I think the current algorithms are something like O(n^6) or O(n^4) (where n is the number of bits in the number in question). It would be interesting to know something like that O(n) is impossible.
16:49:18 <yitz> Cale: sounds hard
16:49:45 <heatsink> fbru02, Okay, you're importing the file then.
16:50:08 <Cale> inimino: Yeah, I'm interested to know if there are lower bounds on the time it takes to test primality.
16:50:37 <bcw> Cale, sounds like a question that would be answered in #math
16:51:02 <heatsink> fbru02, you should be able to input values fine.  For your data type, values include things like "Nothing1" and "Just1 100".
16:51:03 <inimino> s/answered/discussed without resolution/
16:51:03 <fbru02> heatsink : weird when i do :t MyMonad i get the same thing that the type constructor is not in schope :(
16:51:28 <Cale> bcw: Well, there are a lot of computer scientists here :)
16:51:29 <heatsink> fbru02, Sorry, I made a mistake.  Try :i MyMaybe.
16:51:32 <mle> fbru02: try :t Just1 Int
16:51:40 <mle> well
16:51:41 <mle> not int
16:51:47 <mle> heh, Char, or something
16:52:01 <mle> Or even better just :t Just1
16:52:03 <jfoutz> Cale: isn't primality just as hard as factorization?
16:52:16 <bcw> Cale, just suggesting you try #math, not criticizing you for bringing it up here
16:52:17 <heatsink> fbru02, Your data type has one type constructor, "MyMaybe", and two data constructors, "Nothing1" and "Just1".
16:52:25 <bcw> jfoutz, no it isn't
16:52:32 <Cale> jfoutz: It's much easier.
16:52:33 * jfoutz boggles
16:52:52 <Cale> jfoutz: At least, it *seems* much easier, in that we have much faster algorithms for it.
16:53:06 <bcw> jfoutz, it's possible to prove that a number is *not* prime without factoring it.  proving that *is*, however, is sometimes harder
16:53:20 <Cale> It's not really clear that there aren't polynomial-time factorisation algorithms, but we don't know of any.
16:53:31 <fbru02> heatsink, mle : thanks now i get it
16:53:48 <Cale> There's a polynomial-time algorithm for deterministically testing primality now.
16:54:01 <jfoutz> hrm. i see. a factor of n is much easier than the factors of n.
16:54:22 <yitz> no just whether n has a factor
16:54:29 <yitz> not what the factor is
16:54:47 <fbru02> Cale : Sieve of Eratosthenes is not polynomial ?
16:54:49 <jfoutz> wow. that's pretty amazing.
16:54:54 <Cale> fbru02: No, it's exponential.
16:55:16 <Cale> fbru02: The input size is the number of bits in the integer.
16:55:17 <fbru02> Cale : i see this new alg must be pretty cool
16:55:45 <eflister> my favorite aspect of prolog is that the arguments can be either input or output -- a predicate expresses the relationship between all its args, so you get "once and only once".  is there a way to do this in haskell?
16:56:45 <soupdragon> eflister yeah but it doesn't interact well with normal haskell functions
16:57:11 <eflister> soupdragon: is there a wiki page or place to read up on it?
16:57:19 <fbru02> @src Either
16:57:19 <lambdabot> Source not found. Maybe you made a typo?
16:57:20 <yitz> since long before an actual polynomial time primality test was known, we've known how to test primality quickly using monte-carlo techniques (and this is still the only practical method)
16:57:57 <bcw> fbru02, i don't know all the details, but basically, there are some properties that prime numbers must have, which most composites don't, and which have nothing to do with its actual factors (if any)
16:58:18 <maxote> mathematician == cracker ? xD
16:58:24 <fbru02> bcw : cool and mind blowing !!
16:59:01 <jfoutz> yitz: i'm poking around wikipediea, the probalistic tests made a lot of sense to me, i don't know enough about Elliptic curves to ... speak coherently. it looks pretty neat.
16:59:23 <yitz> bcw: fermat's theorem is a good one - a^p  = a mod p for all a
16:59:28 <_randomwords_> prima primality test
16:59:33 <_randomwords_> ignore that
16:59:42 <maxote> elliptic curves are a specialization of non-lineal multivariate polynomials
17:00:00 <bcw> yitz, yea, i've heard of that but i forgot. thanks.
17:00:03 <_randomwords_> I meant to say - aks primality test. That's the deterministic one
17:01:22 <_randomwords_> it's reasoably transparent as well with a little number theory http://en.wikipedia.org/wiki/AKS_primality_test
17:02:00 <fbru02> as a noob to haskell one thing i dont get is that is pretty darn cool that to you can chain computations of the same type very easily using monads but when combining different Monads, Monads transformers are pretty cumbersome
17:03:40 <Cale> fbru02: Monad transformers should be viewed as a way to construct the foundation of certain types of libraries, and not as a general application programming tool, I think.
17:04:51 <blackh> fbru02: If you're writing a function that works on a particular monad, say, a State monad, a good way is to refer to it as a type class, and then it works with any state monad, whether it's part of a transformer stack or not.
17:04:51 <skorpan> StateT with IO is pretty darn common though
17:05:03 <Cale> fbru02: While it's easy to say "Let's combine these monads" it makes very little sense in general to do that, and even when it does make sense, a lot of extra information is usually required to specify exactly how the effects get combined.
17:05:04 <heatsink> I keep forgetting whether f^2 x = (f x)^2 or f (f x)
17:05:13 <heatsink> in mathematical notation I mean
17:05:17 <_randomwords_> f (f x) traditionally
17:05:21 <Cale> StateT over IO seems excessive
17:05:31 <Cale> heatsink: depends
17:05:51 <_randomwords_> heatsink: Although f^2 x could mean something completely different in other contexts
17:05:52 <maxote> heatsink, anything^2 is anything*anything
17:06:25 <Cale> heatsink: It's generally whichever one makes sense in context. If you're talking about category theory, it definitely means composition. If you're talking only about functions of real numbers, and multiplication seems reasonable, it could very well mean that.
17:06:38 <Cale> Generally, it's a good idea to clarify which is meant.
17:07:06 <_randomwords_> Cale: It would be pretty abusive for f^2 x to mean (f x)^2, but I take your point
17:07:23 <Cale> _randomwords_: It happens a lot.
17:07:30 <heatsink> Hmm, so I'll have to take context into account.
17:07:58 <heatsink> In this case, I guess AKS runs in (log n)^6 time rather than log (log (log (log (log (log n))))) time.
17:08:12 <Cale> _randomwords_: People will define multiplication of functions to be pointwise.
17:08:28 <Cale> heatsink: Oh, yes, in that case, that's right.
17:08:28 <_randomwords_> I never want to meet those people
17:08:34 <maxote> heatsink, log ( log ( ... is going to zero, xD
17:08:35 <blackh> fbru02: Monad transformers do have to be used with care - generally you don't overdo it.  I usually use them just to get from one place to another, so to speak.
17:08:37 <Cale> Where n is the actual number being tested
17:08:39 <maxote> with many decimals
17:09:02 <Cale> The only reason the log is there is that the input size for the algorithm is really the number of bits in the number to be tested, and not the number itself.
17:09:29 <Cale> You could also say that it's O(n^6), where n is the number of bits in the number to be tested for primality.
17:09:47 <fbru02> blackh, Cale : thanks , i get what you mean it is better to write to write an instance of how to display your data constructors instead of combining StateM and IO for example
17:10:38 <maxote> generate A, is_AKS_prime(A)? yes, then generate B, is_AKS_prime(B)? yes, then apply RSA, otherwise repeat the experiment.
17:10:39 <Cale> fbru02: http://cale.yi.org/index.php/How_To_Use_Monad_Transformers
17:10:48 <_randomwords_> Inconsistency in mathematical notation irks me - it can be painful when about 50% of authors define application to be from the right and 50% from the left
17:10:48 <bcw> jfoutz, i'm sorry, i confused another person for you earlier :/
17:10:50 <eflister> soupdragon: or were you saying that having args be both input and output wouldn't make sense in haskell's semantics?  (cuz that's what it seems like to me -- but then i don't get why other declarative/functional languages aren't desperate to incorporate this feature -- it is the most elegant semantics i've ever seen!)
17:11:21 <Cale> _randomwords_: It's something you just get used to. Not everyone agrees on what the best notation is, and sometimes everyone is right.
17:11:34 <bcw> (but i'm glad that fbru02 thought it was interesting too)
17:11:44 <Cale> _randomwords_: After all, not everyone is working on the same problems.
17:12:09 <soupdragon> eflister, yeah. It's possible to use this style but it doesn't fit in really nicely
17:12:15 <_randomwords_> Cale: Often they are though. For example in algebra, left and right actions are seemingly just a matter of taste, but there's no clear convention
17:12:35 <eflister> soupdragon: ok cool, any examples?
17:12:44 <jfoutz> bcw: no worries :) i never had enough number theory to get to Euler's totient function. i always learn something here.
17:12:58 <Cale> _randomwords_: well... it's on whichever side you write it on ;)
17:13:40 <bcw> jfoutz, i haven't been here long, but i'm learning too :)
17:14:47 <Cale> _randomwords_: I tend to like using exponential notation for conjugation, and that really does have a right way to define things :)
17:14:50 <Petrosian> Where abouts are the applicative instances for GenParser located?
17:14:56 <Petrosian> Or do I need to define those myself?
17:15:37 <_randomwords_> Cale: Also. some people write conjugation on the left
17:15:44 <_randomwords_> I have no idea why
17:15:51 <Cale> _randomwords_: you mean in an exponent on the left?
17:16:04 <Cale> _randomwords_: it would be whether they want the left or right conjugate.
17:16:12 <jfoutz> eflister: i think you're stuck using the type system's unifier
17:16:22 <_randomwords_> Cale: I mean in situations where they are the same
17:17:09 <fbru02> hey guys i will connect later :) see u
17:17:22 <eflister> jfoutz: is there an example to look at?  :)  any idea why this design isn't more pervasive?
17:18:14 <Cale> You can either define x^g = g^-1 x g or x^g = g x g^-1. If you define it as the latter though, you get that (x^g)^h = h (g x g^-1) h^-1 = (h g) x (h g)^-1 = x^(hg), which is backwards.
17:18:26 <Cale> So you definitely want x^g = g^-1 x g
17:18:55 <Cale> But if you really do want the left conjugate, it makes sense to write it before.
17:20:28 <Cale> With g^x = g x g^-1 (with the understanding that the g is the superscript), you have h^(g^x) = h (g x g^-1) h^-1 = (h g) x (h g)^-1 = (h g)^x
17:21:02 <Cale> So I suspect it's those people who prefer left conjugates that would write the exponents before the element.
17:21:05 <Axman6> ok, so, anyone else think we need a high performance vectors package? just for small fectors than can then be compiled to use things like SSE/Altivec
17:21:46 <Cale> Axman6: I think this should be DPH's responsibility ;)
17:21:52 <jfoutz> eflister: looking... there's the list example here http://www.haskell.org/haskellwiki/GADT i'll see if i can find something more abusive of the type system.
17:22:34 <Axman6> possibly, but seems like something that would be nice to have things like (+) :: Vec4 -> Vec4 -> Vec4, which has a direct translation
17:23:09 <Axman6> just thinking about how much nicer the n-bodies benchmark could be
17:23:12 <sjanssen> Axman6: I don't think it's straightforward for pure Haskell libraries to use primitives like SSE
17:23:28 <soupdragon> jfoutz GADT is the best :)
17:23:29 <heatsink> Axman6, there's kind of a babel of different degrees of vector support that makes it hard to program vectors directly with any degree of portability.
17:23:33 <Axman6> yeah, it would need compiler support
17:23:49 <sjanssen> Axman6: they'd have to go via FFI, where the FFI call overhead overshadows any gains
17:25:15 <Axman6> well, if the compiler could produce the code, there'd be no need for the FFI
17:25:43 <heatsink> I think there was a ticket for adding vector types to the cmm backend.
17:25:50 <heatsink> *vector operations
17:26:00 <jfoutz> eflister: here, this is pretty horrible, http://okmij.org/ftp/Haskell/types.html#binary-arithm
17:28:11 <eflister> i have had the intuition that the primitive recursive operations are similar to the SIMD vectorizable operations.  at least, writing vector code in matlab feels alot like using higher-order functions in haskell.
17:30:56 <Axman6> maybe this can be some research i'll do when i've finished my degree
17:31:05 <_randomwords_> Cale: I agree but then people who define x^g = g x g^-1 could be the people who take the composition (f o g) x = g (f x), in which case (x^g)^h is naturally (x^hg)
17:31:40 <eflister> jfoutz: hm, i'm not seeing how those examples eliminate the concepts of input and output...
17:32:36 <Cale> _randomwords_: I suppose. Those people are a bit strange though :)
17:33:00 <Cale> _randomwords_: If you're going to reverse the order of composition, you're better off reversing application too
17:33:01 <eflister> jfoutz: i've seen peano arithmetic in the type system before, but is that equivalent somehow?
17:33:06 <jfoutz> eflister: the type system is a unifier like prolog, if you can construct your problem as a nesting of types you get both directions of computation, but only at the type level :)
17:33:22 <_randomwords_> Cale: I know. To be honest I was being obtuse because you showed I was wrong, and I don't like being wrong
17:35:12 <eflister> jfoutz: that makes some sense...
17:35:13 <roconnor> hey neat, there is supposedly a method for asking for module namespace: http://www.haskell.org/hierarchical-modules/libraries/reference-libraries.html
17:35:25 <soupdragon> lisp and haskell functional programming is on the left of ::
17:35:30 <roconnor> last modified 6 years ago
17:35:34 <soupdragon> things like prolog is on the right of ::
17:35:41 <soupdragon> stuff like Coq is both sides
17:36:07 <roconnor> ``the contents of this document are still under discussion on the libraries@haskell.org  mailing list, and are subject to change.
17:38:04 <gwern> heh heh. almost immediately after an ann that jane street is still hiring, dons sends an ann that galois is hiring
17:38:14 <gwern> how nice
17:38:37 <roconnor> gwern: where?
17:38:45 <gwern> -cafe I assume
17:38:52 <gwern> IT IS IN MY INTERNETS
17:40:10 <Cale> :O apparently yi is up to 124 modules!
17:40:17 <SubStack> !_!
17:40:29 <gwern> and yet, it takes much longer to compile than xmc with ~180 modules
17:40:34 * SubStack should give yi another go
17:40:34 <gwern> so much longer :(
17:40:40 <SubStack> so hard to break my vim addiction
17:40:46 <_randomwords_> Cale: is that a good :O or a bad :O?
17:41:00 <Cale> _randomwords_: just surprised
17:41:20 <_randomwords_> Does yi support vim-plugins?
17:41:33 <Cale> My friend said she had left the cabal install yi for 3.5 hours and it still wasn't finished (she needed to compile lots of the deps too though)
17:41:54 <_randomwords_> What computer does she have, an abacus?
17:42:00 <ski> bcw : have you looked at i/o in Mercury ?
17:42:02 <ski> eflister : "once and only once"
17:42:03 <gwern> not to mention the ~700MB you need to store dist/
17:42:10 <dcoutts> Cale: that does sound a bit extreme
17:42:20 <Cale> dcoutts: yeah...
17:42:29 <Cale> dcoutts: I think she's on a slow machine.
17:43:14 <Cale> oh, and then another 120 to compile...
17:51:33 --- mode: irc.freenode.net set +o ChanServ
17:51:56 <ski> eflister : a "mode" of a predicate (or function, for that matter) is a pattern of input and output amongst the parameters, e.g. append/3 has (+,+,+),(+,+,-),(-,-,+),(+,-,+) as common modes
17:51:57 <eflister> ski: so do you have insight into why this hasn't pervaded functional/declarative languages?
17:51:57 <tommd> HA!  "Conal Elliot is the expert on FRP, but is rather hard to understand at times."
17:51:58 <ski> eflister : e.g. Mercury has a static mode system for checking modes (each mode of a predicate is compiled to separate machine code)
17:51:58 <dolio> Functions are a particular mode, so it's unsurprising that "functional" languages wouldn't deal in others.
17:51:58 <bcw> ski, sorry, i was afk.  did you mean to address me earlier?
17:51:58 <ski> eflister : Prolog (partly) and Mercury are declarative languages (as are Haskell, SML, et.c.)
17:52:23 <monochrom> The true opposite of "imperative" is "declarative".
17:52:46 <monochrom> "imperative" is tell computer how. "declarative" is tell computer what.
17:52:57 <ski> bcw : earlier you said something about Prolog needing something like the `IO' monad
17:53:00 <dolio> Or, I suppose you could look at functions as predicates that have only one, deterministic mode, or something like that.
17:53:06 <gwern> @quote tuned
17:53:08 <lambdabot> BillWood says: it became obvious that when a Prolog program is tuned by removing non-determinism it moves towards a functional program.
17:53:14 <ski> bcw : Mercury has "something like the `IO' monad", in a sense
17:53:20 <dolio> But there are many such modes.
17:53:44 <bcw> ski, ah.  well, i know nothing about Mercury, so the answer is obviously no.
17:54:11 <bcw> (once that's said, that is)
17:54:13 <ski> dolio : sometimes it could be useful to define bijections, or to run injections backwards (will possible failure)
17:54:28 <ski> (s/will/with/)
17:55:13 <ski> (dolio : Mercury allows such backward modes for functions)
17:55:26 <ski> bcw : how about Clean ?
17:55:49 <dolio> Ah, interesting.
17:56:07 <dolio> I only knew they had a special declaration form for functions, since that mode is common.
17:56:20 <bcw> ski, also never heard of it.  i never got really deep into i/o in prolog, so i guess i was somewhat talking out of my you-know-what when i said that it "needs" something there ;)
17:56:23 <Plouj> yo homies
17:56:30 --- mode: ChanServ set +o monochrom
17:56:38 <Plouj> how can I terminate stdin input when running main = interact myFunction in ghci?
17:56:47 <Plouj> ^D doesn't do it
17:56:51 <Plouj> in Linuxx
17:57:15 <ski> bcw : Prolog i/o is imperative, but both Mercury and Clean do i/o by transforming an input world to an output world
18:02:22 <Boney> wow, talk of Mercury in #haskell.
18:03:37 --- mode: irc.freenode.net set +o monochrom
18:03:37 --- mode: irc.freenode.net set +o ChanServ
18:03:51 <ManateeLazyCat> I want make regex express: "haskell" =~ "ha" :: Bool    don't care sensitive, how to do it?
18:03:52 <BMeph> soupdragon: I really don't think it was you. Unless you can do it again...? ;)
18:03:52 <ski> (dolio : for functions, the "forward / function" mode is implied, if you don't specify any mode yourself, but it is possible to specify other modes)
18:03:52 <dolio> Ah.
18:03:52 <ski> (BMeph : careful what you ask for .. :)
18:03:59 <Petrosian> Has anyone used IndentParser for Parsec?
18:04:04 <ManateeLazyCat> Have any website or document that explain Text.Regex.TDFA completely?
18:04:12 <Petrosian> Having problems getting started with it
18:04:15 <Boney> wow, talk of Mercury in #haskell.
18:04:15 <tommd> BMeph: Aren't you on this west coast some where?  I can't quite remember.
18:04:21 <Petrosian> Even the basic examples don't appear to want to work for me
18:04:26 <arsenm> ManateeLazyCat: you do something like defaultCompOption {caseSensitive = False } and use that with makeRegexOpts, then there are various regex matching functions you use. you can't use =~ with options as far as I can tell
18:04:31 <ski> hello Boney
18:04:32 <Cale> Prelude> :m + Text.Regex.TDFA
18:04:36 <Cale> Prelude Text.Regex.TDFA> "haskell" =~ "ha" :: Bool
18:04:36 <Cale> True
18:04:49 <Boney> ski: hi.
18:04:59 <Cale> ManateeLazyCat: oh, you want to set case sensitivity options?
18:05:08 <ManateeLazyCat> Cale: Yep
18:06:38 <ski> (if anyone is interested further in Mercury, there is a #mercury channel)
18:07:18 <SubStack> delicious heavy metals
18:07:26 <monochrom> drinkable
18:08:10 * dolio needs to get back to learning lambda prolog.
18:08:34 <ManateeLazyCat> Cale: How to make "Haskell" =~ "ha" :: Bool  return True?
18:08:48 <SubStack> oh goodness, mercury distinguishes variables with uppercase letters? :/
18:08:51 <ManateeLazyCat> > "Haskell" =~ "ha" :: Bool
18:08:53 <lambdabot>   False
18:08:55 <llimllib> so. I know what the with function does in Haskell, but I'm trying to link to a description of it
18:09:06 <llimllib> It's remarkably un-googleable. Anybody have a link handy?
18:09:23 <dolio> SubStack: In true Prolog fashion, no?
18:09:26 <pikhq> @hoogle with
18:09:27 <lambdabot> Foreign.Marshal.Utils with :: Storable a => a -> (Ptr a -> IO b) -> IO b
18:09:27 <lambdabot> System.Environment withArgs :: [String] -> IO a -> IO a
18:09:27 <lambdabot> Foreign.Marshal.Array withArray :: Storable a => [a] -> (Ptr a -> IO b) -> IO b
18:09:44 <pikhq> @src with
18:09:45 <lambdabot> Source not found. Are you on drugs?
18:09:57 <tommd> BMeph: Ahh, San Diego - no wonder I forget, I always purge it from my mind.
18:10:20 <llimllib> is it a statement?
18:10:20 <SubStack> the question is not "Are you on drugs?" but instead "Which drugs are you on?"
18:10:43 <Cale> ManateeLazyCat: I'm not sure there's a way to set the compilation options while using =~ but you can do it with matchTest
18:11:03 * monochrom is on the empty drug.
18:11:04 <Cale> Prelude Text.Regex.TDFA> matchTest (makeRegexOpts (defaultCompOpt { caseSensitive = False }) defaultExecOpt "ha") "Haskell"
18:11:04 <Cale> True
18:11:25 <Boney> SubStack: yes.  Mercury uses prolog term syntax.  For a while the compiler was written in the subset of Mercury and a particular prolog.  Now we have a bootstrapping compiler without having to re-write it :-)
18:11:40 <SubStack> crazy!
18:11:58 <monochrom> llimllib: http://www.haskell.org/ghc/docs/latest/html/libraries/base/Foreign-Marshal-Utils.html#v%3Awith
18:12:15 <ManateeLazyCat> Cale: You mean i must set compilation options (like caseSensitive) before i using =~ ?
18:12:35 <llimllib>  haha I'm an idiot
18:12:51 <llimllib> sorry to bug everyone :) multiple languages making me confuse words
18:12:53 <Cale> ManateeLazyCat: As far as I can see, if you want to use =~ there is no way to set compilation options
18:13:17 <Petrosian> Anyone know of some examples of using IndentParser for Parsec?
18:13:41 <Cale> ManateeLazyCat: though...
18:13:51 <Cale> ManateeLazyCat: Let me try something
18:14:24 <ManateeLazyCat> Cale: Thanks
18:16:53 <arsenm> Anyone have any examples of using evaluation strategies with things other than lists? like Data.Map?
18:17:27 <Cale> ManateeLazyCat: By adding a stupid instance of RegexMaker, it's possible to use =~ with makeRegexOpts
18:19:21 <abuiles> Hi all, I have been trying to understand this function, but I can't see when the recursivity ends, I supposed it is when pSym '(' doesn't match . and it will return [] when trying to do the comprehension of the function with the 4 arguments  and the empty from pSym.. http://gist.github.com/166215
18:20:13 <ManateeLazyCat> @let tt source regex = matchTest (makeRegeOpts (defaultCompOpt {caseSensitive = False}) defaultExecOpt regex) source
18:20:14 <lambdabot>  <local>:19:29: Not in scope: `makeRegeOpts'
18:20:14 <lambdabot>  
18:20:14 <lambdabot>  <local>:19:59: Not in scope: ...
18:20:24 <ManateeLazyCat> @let tt source regex = matchTest (makeRegexOpts (defaultCompOpt {caseSensitive = False}) defaultExecOpt regex) source
18:20:25 <lambdabot>  <local>:19:60: Not in scope: `caseSensitive'
18:20:49 <Cale> Lambdabot doesn't have that package installed
18:21:42 <ManateeLazyCat> Cale: Above `tt` function okay?
18:21:44 <pikhq> Eh, parser > regular expression.
18:21:47 <pikhq> :P
18:22:30 <heatsink> abuiles, I think it didn't get formatted properly.  Is this the definition of function 'pReturn'?
18:23:12 <Cale> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8121#a8121
18:24:10 <Cale> pikhq: I'm inclined to agree with you
18:24:17 <Cale> Also, the regex libraries are insane.
18:24:27 <pikhq> Cale: Only half-joking, really.
18:24:36 <pikhq> After all, Parsec is *very* nice.
18:24:36 <SubStack> nested grammars ^_^
18:25:22 <Cale> Personally, I would use Parsec for essentially everything that other people might use regular expressions for, unless there was a real need to make use of the fact that the language was regular.
18:25:25 <abuiles> heatsink: sorry, I forgot something.
18:25:44 <pikhq> Parsec is quite a bit easier to deal with than regexps...
18:26:05 <pikhq> Not to mention much nicer with error conditions.
18:26:09 <Cale> and if there was, I certainly would not want to write my regular expressions in the brutally horrific string syntax that everyone uses
18:26:36 <Cale> (I'd go with an algebraic datatype which was easy to manipulate)
18:26:43 <pikhq> The string syntax is... I'm not entirely sure.
18:26:51 <pikhq> Historical reasoning?
18:26:55 <heatsink> [>+++<---]-.
18:27:23 <abuiles> heatsink: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8122#a8122
18:27:29 <bcw> ah, brainf***
18:27:30 <pikhq> heatsink: Yes, I too know Brainfuck.
18:27:44 <abuiles> heatsink: a better version.
18:27:56 <heatsink> Ah, that's more readable.
18:28:41 <abuiles> haetsink: yeah man, sorry about it..
18:28:42 <moonpatrol> List comprehensions are awesome.
18:29:36 <abuiles> heatsink: It just blew my mind :(
18:29:48 * ManateeLazyCat pasted "=~^" at http://paste2.org/get/374189
18:29:49 <ManateeLazyCat> Cale: I got above function, thanks!
18:30:10 <Cale> ManateeLazyCat: aha, that works well
18:30:35 <lucas_> hey
18:30:44 <lucas_> can we do "memoization" in haskell
18:30:47 <heatsink> abuiles, You're right that recursion will stop when pSym '(' doesn't match.  At that point, execution will jump over to pReturn 0.
18:31:10 <bcw> i can think of a reason to use regexes: when the users of your program know them better than haskell
18:31:51 <Cale> lucas_: yes
18:32:08 <bcw> er, when you have to allow the user to specify the pattern and they know regexes better
18:32:33 <Cale> lucas_: It's usually as simple as defining a lazily evaluated constant which consists of the values of the function to memoise, and then defining the (recursive) function to make use of memo table
18:32:50 <Cale> lucas_: There is also a more abstract way, using the MemoCombinators library
18:33:00 <Cale> http://hackage.haskell.org/package/data-memocombinators
18:33:15 <lucas_> so
18:33:19 <heatsink> abuiles, After you've been programming in Haskell for a while you'll get used to defining new control flow patterns as functions.
18:33:24 <lucas_> i read something on plai
18:33:32 <lucas_> book said haskell can cache the value
18:33:43 <lucas_> what is the difference between memoization and cache
18:33:53 <Cale> that's a common misconception
18:34:04 <monochrom> An oversimplification.
18:34:24 <lucas_> but book said
18:34:27 <Cale> Results of function applications are not automatically memoised, because it would result in horrifying memory usage.
18:34:42 <Cale> Even though it would indeed be correct to do it.
18:34:44 <lucas_> Memoization associates a cache with each function
18:34:46 <sm> it's funny, I had that idea when I started haskell also
18:34:49 <monochrom> "sin 0 + sin 0" no one is obliged to cache the result of "sin 0".
18:35:06 <Cale> lucas_: which book?
18:35:08 <monochrom> "let x = sin 0 in x+x" this specifies caching.
18:35:08 <heatsink> @source zipWithM_
18:35:09 <lambdabot> zipWithM_ not available
18:35:13 <lucas_> plai
18:35:16 <Cale> plai?
18:35:25 <lucas_> just a second
18:35:28 <monochrom> "professor lai" that's me!
18:35:35 <abuiles> heatsink: in that point, if pSym fail , so the return in the left side would be [] ?  and the final return [(0,xs)]
18:35:50 <lucas_> http://www.cs.brown.edu/~sk/Publications/Books/ProgLangs/2007-04-26/plai-2007-04-26.pdf look at page 81
18:36:19 <monochrom> I bet 99.9% chance the book is right and says it right, but the reader reads it wrong and partial and out of context and completely butchers.
18:36:24 <Cale> physical page 81, or 81 of the pdf?
18:36:30 <heatsink> abuiles, I haven't seen the definition of <|>, but I think you're right.
18:36:33 <Cale> ah, physical 81
18:37:19 <abuiles> heatsink: P p1 <|> P p2 = P (\x -> p1 x   ++ p2 x )
18:37:24 <Cale> lucas_: right, what it says about memoisation is correct.
18:37:44 <heatsink> Ah, yes.
18:38:44 <heatsink> abuiles, parens is called once for each value returned by pSym '('.  When pSym '(' returns [], parens is called zero times.
18:38:48 <lucas_> but what is the diffentence between memoizatioıon and cache
18:39:17 <lucas_> this is not homework but my TA ask me question like that
18:39:21 <Cale> lucas_: Um, nothing, on the face of it. Lazy evaluation's caching is different from memoisation though.
18:39:28 <lucas_> i didnt give any answer
18:39:54 <heatsink> abuiles, So the result of the left side is [], and the result of the right side is [(0, xs)], so the overall result is [] ++ [(0, xs)] = [(0, xs)]
18:40:10 <Cale> Lazy evaluation specifies that parameters to a function which occur more than once in the function body are evaluated at most once, and the results of that evaluation are shared between the copies.
18:40:31 <Petrosian> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8124#a8124 Anyone know what this is supposed to be?
18:40:37 <Cale> However, if you have something like f 5 + f 5, you'll still evaluate f twice
18:40:40 <Petrosian> It's part of the IndentParser example
18:40:47 <Petrosian> But refuses to typecheck
18:42:04 <abuiles> heatsink: this is weird,  http://hpaste.org/fastcgi/hpaste.fcgi/view?id=8125#a8125  , isn't in that way ?
18:42:06 <tommd> Petrosian: My knee-jerk reaction is to think the package deps aren't well specified (or aren't specified at all, if you aren't using cabal).
18:42:34 <ManateeLazyCat> Cale: How to make =~^ at middle default? And not left default.
18:42:51 <Petrosian> tommd: I am using cabal, tho' I did just install parsec 3 ontop of 2.1, could that cause a problem?
18:43:29 <tommd> Petrosian: Yes!  It has for me in the past.
18:43:45 <heatsink> abuiles, If the first character of the input is not '(', then test will return [], because pSym doesn't match.
18:43:55 <tommd> Hackage package devs are very lazy (in the bad sense) about specifying upper bounds of the package deps.
18:44:19 <Petrosian> tommd: I don't suppose there's a simple solution?
18:44:30 <heatsink> abuiles, If the first character of the input is '(', then pSym will match, and test will return  (\ _ b _ d -> (1+b) `max` d) ()
18:44:39 <Cale> ManateeLazyCat: ?
18:44:42 <heatsink> That is, (\b _ d -> (1+b) `max` d)
18:44:49 <Petrosian> Short of reinstalling the Haskell platform
18:44:49 <Cale> ManateeLazyCat: It's an operator symbol, you use it as an operator
18:45:03 <ManateeLazyCat> Cale: What's =~ ?
18:45:13 <Cale> ManateeLazyCat: Also an operator symbol
18:45:14 <tommd> Petrosian: Unregister Parsec-3 or edit the .cabal to ensure this package says parsec < 3.0
18:45:16 <ManateeLazyCat> Cale: I want make =~^ works like =~
18:45:20 <Cale> ManateeLazyCat: it should
18:45:28 <Petrosian> tommd: I'll give it a try, thanks
18:45:34 <Cale> ManateeLazyCat: You shouldn't have to do anything
18:45:44 <heatsink> abuiles, In the original function, each <*> passes one argument to the function inside pReturn.  Now that you have only one <*>, you're only passing one argument.
18:45:59 * tommd -> Dinner
18:46:14 <abuiles> heatsink: exaclty ! in that case I should be getting [] instead of  ( No instance for (Show (Integer -> t -> Integer -> Integer))  ), although (null it = True ). Why  do I get that error, even when the list is empty ?
18:46:15 <Cale> ManateeLazyCat: it was defined like  (=~^) source regex = ...  but you could also have written   source =~^ regex = ...
18:46:20 <Cale> ManateeLazyCat: which is the same thing
18:46:26 <ski> (s/still evaluate f twice/still evaluate 'f 5' twice/)
18:46:36 <Cale> ManateeLazyCat: In any case, you can use it as an infix operator automatically
18:46:43 <Cale> ski: right.
18:47:29 <heatsink> abuiles, Well, the result is always a list of functions.  IIt could be an empty list of functions, or a nonempty list of functions.  Either way, the interpreter doesn't know how to display the list.
18:47:36 <heatsink> (or the compiler)
18:48:15 <ski> (presumably s/interpreter/interactor/)
18:48:35 <Saizan_> abuiles: that one is a type error, typechecking doesn't care if your list will be empty or not, since generally it can't be known statically
18:48:46 <Cale> ManateeLazyCat: any string of symbol characters is automatically an infix operator
18:49:04 <kniu> @src const
18:49:04 <lambdabot> const x _ = x
18:49:36 * ManateeLazyCat pasted "=~^" at http://paste2.org/get/374197
18:49:37 <ManateeLazyCat> Cale: Above is improve version, works fine. :)
18:49:52 <ManateeLazyCat> Cale: Thanks again! :)
18:50:04 <Saizan_> i guess we could have singleton types and add a Show instance for S([])
18:50:08 <abuiles> heatsink : That makes things clear. I was thinking that and empty list was always interpreted as [] without care about its type inside.
18:50:16 <ManateeLazyCat> @src (=~)
18:50:16 <lambdabot> Source not found. Are you on drugs?
18:50:21 <abuiles> Saizan_: Thanks !
18:50:36 <abuiles> heatsink : Thanks for you help and your time :)
18:50:44 <ManateeLazyCat> Cale: You know any website or document that explain Text.Regex.TDFA completely?
18:50:59 <Cale> ManateeLazyCat: There's the Haddock for it...
18:51:05 <heatsink> abuiles, The type is checked before it checks what's in the list, as Saizan mentioned.
18:51:05 <Cale> and regex-base
18:51:18 <heatsink> abuiles, glad I could help.
18:51:21 <Cale> ManateeLazyCat: But it's fundamentally a very confusing library.
18:51:47 <Cale> ManateeLazyCat: http://hackage.haskell.org/packages/archive/regex-base/0.93.1/doc/html/Text-Regex-Base-RegexLike.html
18:51:50 <Cale> ^^ start with that
18:52:11 <Cale> It describes the typeclasses that the various regex libraries define instances of
18:52:19 <ManateeLazyCat> More?
18:53:04 <Cale> http://hackage.haskell.org/packages/archive/regex-tdfa/1.1.2/doc/html/Text-Regex-TDFA-Common.html
18:53:33 <Cale> Much of that is internal though, and not exported from the library, but you will want to know about CompOption and ExecOption
18:53:44 <Cale> The Regex type is opaque.
18:54:05 <ManateeLazyCat> Cale: opaque?
18:54:13 <Cale> (you can't actually see the constructor which is documented there -- you're meant to use the general interface to construct Regex values)
18:54:44 <ManateeLazyCat> I see.
18:55:00 <Cale> If you can understand the RegexLike module, that's most of it.
18:55:05 <abuiles> heatsink: Yeah, Apparently is  a long path still to be walked :)
18:55:20 <gwern> @hoogle zipWith3
18:55:21 <lambdabot> Prelude zipWith3 :: (a -> b -> c -> d) -> [a] -> [b] -> [c] -> [d]
18:55:21 <lambdabot> Data.List zipWith3 :: (a -> b -> c -> d) -> [a] -> [b] -> [c] -> [d]
18:55:21 <ManateeLazyCat> Cale: Thanks, i reading those pages.
18:57:13 <Plouj> allo?
19:20:14 <RyanT50001> if one were to write a library for multiresolution analysis, where would that belong in the hierarchy?
19:20:31 <RyanT50001> is there an "Analysis" branch in root?
19:20:35 <dolio> Data :)
19:20:39 <RyanT50001> huh
19:20:45 <copumpkin> Math. ?
19:20:51 <dolio> That wasn't a serious suggestion.
19:20:57 <dolio> But almost everything gets put in Data.
19:21:06 <RyanT50001> well, i could see Data.MultiresolutionSignal or something :P
19:21:19 <RyanT50001> copumpkin: yeah, i guess Math would be it
19:21:26 <RyanT50001> maybe Math.Analysis.Multiresolution
19:21:35 <Veinor> I am going to write an mpd client in haskell. because I can.
19:21:44 <copumpkin> although the .Analysis seems odd
19:21:50 <copumpkin> but maybe not
19:22:02 <RyanT50001> well, Analysis is one of the branches of math, no?
19:22:07 <copumpkin> yeah
19:22:15 <RyanT50001> that's where i got that idea :P
19:25:01 <BMeph> Is it possible to: 1) make a closed typeclass; 2) get GHC to "understand" that a typeclass is closed? :|
19:25:31 <dolio> 2 is a definite no.
19:25:42 <dolio> 1 is potentially yes, depending on what you mean by that.
19:26:15 <copumpkin> you can make a typeclass that it's impossible to write a good instance for
19:26:20 <copumpkin> unless you're one of the intended instances
19:26:35 <copumpkin> but GHC will still let you write bad instances
19:27:13 <dolio> Well, you can set things up so that you can't write instances, because doing so requires that you write instances for things that are hidden.
19:27:37 <copumpkin> ah, I see
19:27:52 <copumpkin> that seems simple enough
19:28:01 <dolio> I think that's one way to do it, at least. Someone mentioned it on -cafe not too long ago.
19:31:21 <dolio> Oh, except generalized newtype deriving breaks things.
19:31:41 <dolio> Forgot about that minor detail.
19:32:02 <copumpkin> but that doesn't allow you to make arbitrary new instances, just isomorphic ones, doesn't it?
19:32:10 <dolio> Yeah.
19:32:34 <copumpkin> that sounds reasonable enough to me
19:34:55 <dolio> It's an issue when it causes problems with type soundness. But I can't remember if there are still problems with that.
19:35:29 <dolio> At least, not how to demonstrate it.
19:35:48 <RyanT50001> it seems like it could cause a problem if they automatically derive your class, and re-implement one of the classes that your instance depends on
19:35:55 <RyanT50001> i'm not sure how that would work
19:36:04 <RyanT50001> e.g.: if your instance depends on Eq a, and they redefine Eq...
19:36:38 <dolio> Well, the weirdness comes from the fact that newtypes don't actually get real instances written for them.
19:36:52 <RyanT50001> how so?
19:37:40 <dolio> Newtypes disappear at compile time, since they're represented identically to the type they wrap.
19:38:04 <RyanT50001> right, i know that, but you can write new instances for newtypes, right?
19:38:06 <dolio> And in GHC's intermediate language, they're implemented like "newtype Foo a = Foo a" becomes "Foo a ~ a".
19:38:17 <dolio> You can, but generalized newtype deriving doesn't, I think.
19:38:32 <RyanT50001> right
19:38:35 <dolio> It just takes advantage of the fact that it can use the type equality, and assumes you could write the instance by hand, even if you couldn't.
19:38:44 <RyanT50001> yeah
19:40:15 <dolio> I assume it just sticks in dictionaries for the underlying type.
19:40:23 <dolio> After type checking.
19:40:57 <RyanT50001> yeah, i suppose it probably does that
19:57:15 <greap> Can anyone explain how the [Memoization with recursion] example works at [http://www.haskell.org/haskellwiki/Memoization]?
19:58:58 <Saizan_> greap: the list is recursively defined using itself
19:59:36 <Saizan_> the recursion doesn't loop endlessly because of fib's base cases though
20:00:11 <Saizan_> ah, by "the list" i mean (map fib [0..])
20:01:19 <Saizan_> > let fibs = zipWith (+) fibs (tail fibs) in fibs
20:01:24 <lambdabot>   mueval-core: Prelude.read: no parse
20:01:24 <lambdabot>  mueval: ExitFailure 1
20:01:32 <Saizan_> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs
20:01:34 <lambdabot>   [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946...
20:01:40 <Saizan_> similar use of value recursion
20:14:41 <anothergit> I'm using the System.Time module but I'd like to know if I can get more accuracy (like nanoseconds)? Here's my current code: http://codepad.org/FT69Lawv
20:17:29 <SANDERS_> I am building a "list" of items and list, so I wrapped each item in a type...
20:17:36 <SANDERS_> is there a better way to do that
20:17:38 <SANDERS_> ?
20:17:49 <akdom> [type]
20:18:46 <Saizan_> SANDERS_: so you've data T a = Elem a | List [a] and you use a [T a] ?
20:18:58 <SANDERS_> Saizan_: yeah
20:19:20 <Saizan_> it seems quite reasonable
20:19:36 <pikhq> Looks a lot like a Haskell representation of an S expression.
20:20:03 <SANDERS_> I can not make my type a  member of the functor typeclass though
20:20:12 <SANDERS_> I get a kind error
20:20:27 <SamB> SANDERS_: true
20:20:32 <SamB> types can't be members of that class
20:20:36 <SamB> it's actually a constructor class
20:20:54 <Saizan_> instance Functor T where fmap f (Elem a) = Elem (f a); fmap f (List xs) = List (fmap f xs)
20:21:01 <Saizan_> that works
20:21:04 <MichaelGG> are these two equivalent "filter (_,x) -> x > 1000000" and "filter (< 1000000) . snd" ?
20:22:02 <aavogt> > (>1) 2
20:22:03 <lambdabot>   True
20:22:03 <Saizan_> filter (\(_,x) -> x > 1000000) is equivalent to filter ((< 1000000) . snd)
20:22:08 <aavogt> > 2 < 1
20:22:09 <lambdabot>   False
20:22:15 <SANDERS_> Saizan_: perhaps because my type looks like: data Special = St String | Sa [String]
20:22:28 <SamB> MichaelGG: you missed a λ, I think
20:22:33 <MichaelGG> SamB yea
20:23:11 <Saizan_> SANDERS_: ah, in that case you can't, since to be a Functor it nees to be parametric on the type of the elements contained
20:23:25 <MichaelGG> is it ever proper to call it eta reduction if you go pointfree with fst? i.e.,  ((< 1000000) . fst) ?
20:24:39 <MichaelGG> yea i guess why wouldnt it be
20:24:54 <aavogt> MichaelGG: you're aware that you flipped the > to < without changing the order of the arguments
20:25:15 <MichaelGG> aavogt, yea sorry i was changing from F# code
20:25:40 <MichaelGG> not the first time ive been bit by that :P
20:26:02 <aavogt> MichaelGG: F# has sections that don't let you implicitly apply 'flip' ?
20:26:23 <MichaelGG> aavogt, i dont think there's any flip ever in F#
20:26:40 <MichaelGG> unless you write and apply it yourself. i dont recall seeing it in the libraries anyways
20:26:51 <aavogt> @type (`elem` "hello")
20:26:52 <lambdabot> Char -> Bool
20:26:58 <aavogt> @type ('c' `elem`)
20:26:59 <lambdabot> [Char] -> Bool
20:27:04 <MichaelGG> whoa
20:27:13 <MichaelGG> thats handy
20:28:03 <MichaelGG> F#'s missing backticks to allow using any function infix
20:28:27 <gwern> backticks might confuse the perl programmers
20:28:35 <aavogt> I wonder if we'll get ghc-6.12 this year (with proper tuple sections!)
20:29:02 <MichaelGG> gwern, it only matters if it confuses C# and VB programmers. hence the big rename of 'a and 'b to 'T, 'U ....
20:29:43 <BMeph> Wierd: annihilators invalidate cancellation. :)
20:30:06 <BMeph> Weird: I just misspelt "weird'! ;p
20:30:17 <aavogt> @seen Wierd
20:30:17 <lambdabot> I haven't seen Wierd.
20:31:50 * BMeph vows to start clauses with dashes instead of colons, so-as not to confuse the ITC-izans. I promise. ;)
20:33:03 <SamB> BMeph: well, you've managed to confuse me!
20:33:12 <SamB> what the heck is an ITC-izan?
20:34:12 <aavogt> IRC-izan perhaps?
20:34:13 <BMeph> Sorry - *IRC-izens. Wife had me in a head-lock...Yum! ;)
20:34:13 <MichaelGG> Does Haskell have quotations or reified code at runtime? Template haskell seems to be compile time only, and "haskell quotations" finds quotes by some girl named colleen.
20:34:24 <hellues> nightmare to remember !!!!
20:34:43 <gwern> quasiquotations might be a better term tosearch, but those are compile-time too aren't they?
20:34:51 <gwern> MichaelGG: maybe you want an eval, which would be ghc api
20:34:55 <SamB> haskell quotations syntax?
20:35:20 <MichaelGG> well like to be able to convert the source tree into other representations on the fly
20:35:35 <roconnor> I think implementations have no reified code at runtime
20:35:41 <roconnor> most implementation
20:35:46 <roconnor> s
20:35:49 <MichaelGG> roconnor, thats what i figured
20:36:07 <SamB> roconnor: TH allows you to have code at runtime, but not if you actually want to run it ;-)
20:36:23 <MichaelGG> SamB thats fine - just need the representation
20:36:53 <aavogt> look also at haskell-src-exts
20:40:46 <anothergit> alright, noob here, how do I recursively loop through each character in a string?
20:40:57 <anothergit> all I have right now is: http://codepad.org/dNVnYpjj but I can't get the pattern matching to work
20:41:00 <soupdragon> anothergit: and ? do something with it
20:41:02 <soupdragon> or what
20:41:06 <soupdragon> just looping doesn't make sense
20:41:16 <aavogt> map
20:41:17 <anothergit> yeah it doesn't
20:41:29 <soupdragon> anothergit, oh you want to sun seah element
20:41:39 <soupdragon> you can use foldr
20:41:44 <anothergit> soupdragon, I should have just said that in the first place
20:41:50 <anothergit> yep, I'm doing project Eulers
20:41:55 <soupdragon> what you have with foldr is
20:42:29 <soupdragon> foldr (\x ys -> __ in here 'x' is the char and ys is the rest of the sum _ ) 0
20:42:40 <anothergit> wait wait let me get this straight
20:42:43 <soupdragon> so ys is the recursion done already
20:43:01 <SamB_XP> wouldn't foldl' be better ?
20:43:01 <anothergit> so foldr takes a function that takes two functions and returns the type of the second function as the first function
20:43:09 <anothergit> then takes another value and then a list
20:43:12 <gwern> > sum $ map (\x -> read x ::Int) "1111222"
20:43:13 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
20:43:21 <anothergit> and returns a value? I'm at this site: http://www.zvon.org/other/haskell/Outputprelude/foldr_f.html
20:43:21 <SamB_XP> anothergit: you lost me!
20:43:22 <gwern> > sum $ map (\x -> (read x) ::Int) "1111222"
20:43:24 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
20:43:27 <aavogt> anothergit: what happens when the recursion finally gets to: (sumIntStr [])
20:43:28 <gwern> hm.
20:43:37 <gwern> > map (\x -> (read x) ::Int) "1111222"
20:43:39 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
20:43:50 <soupdragon> anothergit, you can think of it replacing all the (:) in the list with a function and the [] with a value (0 in this case)
20:44:07 <aavogt> > map (read . (:[])) "1111222" :: [Int]
20:44:08 <lambdabot>   [1,1,1,1,2,2,2]
20:44:08 <gwern> > (read "111222") :: [Int]
20:44:09 <soupdragon> so you whip the tablecloth out and it falls down into the total
20:44:10 <lambdabot>   * Exception: Prelude.read: no parse
20:44:17 <gwern> bah, no [Int] instance?
20:44:27 <roconnor> @type traverse ?f "Hello"
20:44:29 <lambdabot> Not in scope: `traverse'
20:44:31 <roconnor> bah
20:44:32 <copumpkin> > (read "[1,2,3]") :: [Int]
20:44:34 <lambdabot>   [1,2,3]
20:44:35 <aavogt> gwern: overlapping, no?
20:44:38 <soupdragon> > let (.) ] fmap in (read . "111222") :: [Int]
20:44:40 <lambdabot>   <no location info>: parse error on input `]'
20:44:40 <anothergit> fucking Xchat
20:44:42 <soupdragon> > let (.) ] fmap in (read . "111222") :: [Int]
20:44:43 <lambdabot>   <no location info>: parse error on input `]'
20:44:45 <soupdragon> > let (.) = fmap in (read . "111222") :: [Int]
20:44:47 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
20:44:58 <anothergit> don't press control-a
20:45:04 <soupdragon> > let (.) = fmap in ((read . return) . "111222") :: [Int]
20:45:06 <lambdabot>   Couldn't match expected type `GHC.Types.Char -> GHC.Types.Char'
20:45:17 <monochrom> > foldr (+) 0 [a,b,c]
20:45:19 <lambdabot>   a + (b + (c + 0))
20:45:22 <gwern> > sum $ map (read . (:[])) "1111222" :: [Int]
20:45:23 <lambdabot>   No instance for (GHC.Num.Num [GHC.Types.Int])
20:45:23 <lambdabot>    arising from a use of `Dat...
20:45:30 <gwern> > sum (map (read . (:[])) "1111222" :: [Int])
20:45:32 <lambdabot>   10
20:45:47 <aavogt> > ord '0'
20:45:48 <lambdabot>   48
20:46:04 <gwern> @src print
20:46:04 <lambdabot> print x = putStrLn (show x)
20:46:06 <aavogt> > ord '9'
20:46:07 <lambdabot>   57
20:46:09 <gwern> anothergit: btw. printLn . show == show
20:46:19 <gwern> er. == print
20:47:06 <runhigh> hi
20:47:50 <anothergit> anyway, I'm not exactly for sure that foldr is what I need
20:47:55 <anothergit> I mean from looking at the examples
20:48:23 <monochrom> It is necessary but not sufficient.
20:49:02 <anothergit> monochrom, so what else is missing?
20:49:04 <gwern> @src sum
20:49:05 <lambdabot> sum = foldl (+) 0
20:49:23 <anothergit> or maybe I should just try figuring out how to get pattern matching on a [char] working again
20:50:00 <monochrom> I don't know your specification. I am not inclined to look at Project Euler.
20:50:02 <gwern> anothergit: do you see now? You need to treat each Char independently as an Int, so that calls for a map; but you need to combine and collapse the list down to a single value using +, which calls for a fold (foldr)
20:50:14 <gwern> sum packages up that common fold
20:51:15 <anothergit> gwern, but I can't map read to every char
20:51:42 <anothergit> you mean like: map read ["9", "7"]
20:51:44 <anothergit> ?
20:52:24 <aavogt> so convert "97" to ["9","7"]
20:52:38 <dobblego> @type cojoin
20:52:39 <lambdabot> Not in scope: `cojoin'
20:53:06 <pikhq> > map (:[]) "97"
20:53:08 <lambdabot>   ["9","7"]
20:53:14 <roconnor> @type extend
20:53:16 <lambdabot> Not in scope: `extend'
20:54:02 <pikhq> So, basically, you want: sum . map . read . (:[])
20:54:12 <hydo> gwern: is it out of line to ask for a haskellwiki here?  I hesitate to send email to two of the contacts on the new accounts page, but I sent email to magnus@therning.org some time ago and I haven't heard back.
20:54:21 <hydo> err.. ask for a haskellwiki login.
20:56:54 <copumpkin> > sum . map . read . (:[]) $ "1234"
20:56:55 <lambdabot>   Couldn't match expected type `[a]'
20:57:15 <shapr> What's the XLanguageExtensions for GADTs?
20:57:21 <copumpkin> GADTs
20:57:47 <m3ga> whats the status of Network.HTTP vs Network.Curl? is the former being deprecated in favour of the latter?
20:57:59 <Trinithis> > sum . map $ read . (:[]) $ "1234"
20:58:01 <lambdabot>   Couldn't match expected type `[a]'
20:58:05 <anothergit> : (
20:58:12 <anothergit> I've been trying these in gchi
20:58:14 <anothergit> *ghci
20:59:31 <monochrom> > (sum . map . read . (:[])) "1984"
20:59:32 <lambdabot>   Couldn't match expected type `[a]'
20:59:42 <monochrom> Oh I see.
21:00:11 <Trinithis> @faq Can Haskell easily proove cats > dogs?
21:00:12 <lambdabot> The answer is: Yes! Haskell can do that.
21:00:21 <monochrom> > (sum . map (read . (:[])) ) "1984"
21:00:23 <lambdabot>   22
21:00:29 <monochrom> Works.
21:00:30 <anothergit> success
21:00:31 <anothergit> !
21:00:33 <anothergit> thanks
21:00:37 <monochrom> I hate $ anyway.
21:00:40 <anothergit> wow, I have no idea how that works
21:00:42 <anothergit> but it works
21:00:43 <anothergit> sweet
21:00:49 <Makoryu> @let robotMonkey = (:[])
21:00:51 <lambdabot>  Defined.
21:00:55 <Trinithis> lol
21:01:11 <ray> :[] is the omnomnom operator that gobbles up a value and makes it a singleton list
21:01:14 <Makoryu> > sum . map (read . robotMonkey) $ "1984"
21:01:16 <lambdabot>   22
21:01:26 <pikhq> > sum . map (read . (:[])) $ ['1'..'9']
21:01:28 <lambdabot>   45
21:01:45 <Cale> m3ga: I think if I had to do anything complicated with regard to the HTTP requests I was making, I would use Network.HTTP, and for simple downloading across a range of protocols, perhaps the curl binding would be simpler.
21:02:17 <monochrom> > map (read . (:[])) "1984"
21:02:18 <lambdabot>   [* Exception: Prelude.read: no parse
21:02:34 <aavogt> > read "()"
21:02:35 <lambdabot>   ()
21:02:37 <ray> needs a type
21:02:44 <Trinithis> > 0 + map (read . (:[])) "1984"
21:02:45 <lambdabot>   No instance for (GHC.Num.Num [a])
21:02:45 <lambdabot>    arising from the literal `0' at <inter...
21:02:46 <monochrom> > map (read . (:[])) "1984" :: [String]
21:02:48 <lambdabot>   ["* Exception: Prelude.read: no parse
21:02:56 <m3ga> Cale: thanks. makes sense. i just remembered that Curl does so much more than just HTTP.
21:03:07 <pikhq> > (map (read . (:[])) "1984" :: [Num]
21:03:08 <RyanT50001> is there a place where haddock syntax is documented?
21:03:08 <lambdabot>   <no location info>: parse error (possibly incorrect indentation)
21:03:12 <ray> > map (read . (:[])) "1234" :: [Int]
21:03:14 <monochrom> Oh, not String.
21:03:14 <lambdabot>   [1,2,3,4]
21:03:19 <pikhq> > map (read . (:[])) "1984" :: [Num]
21:03:20 <lambdabot>   Class `GHC.Num.Num' used as a type
21:03:29 <monochrom> There is no Num.
21:03:30 * ray smacks pikhq
21:03:31 <Makoryu> pikhq: There's no such type as Num
21:03:35 <Trinithis> > read "(())"
21:03:37 <lambdabot>   ()
21:03:41 <Trinithis> > read "((()))"
21:03:42 <pikhq> Makoryu: XD
21:03:42 <lambdabot>   ()
21:03:52 <ray> > read "())"
21:03:54 <lambdabot>   * Exception: Prelude.read: no parse
21:03:54 <Trinithis> > read "((), ())"
21:03:55 <lambdabot>   * Exception: Prelude.read: no parse
21:03:56 <pikhq> ray: LIES. LIES AND TYPECLASSES, SAY I
21:03:58 <ray> zomg it's a parentheses balancer
21:04:21 <monochrom> Programming is about composition.
21:04:23 <vav> RyanT50001: http://www.haskell.org/haddock/doc/html/index.html
21:04:26 <aavogt> > read $ replicate 1000 '(' ++ replicate 1000 ')'
21:04:27 <lambdabot>   ()
21:04:30 <pikhq> > read "((), ())" :: ((), ())
21:04:31 <Makoryu> > read "((),())" :: ((),())
21:04:32 <lambdabot>   ((),())
21:04:33 <lambdabot>   ((),())
21:04:37 <Makoryu> O RLY
21:04:43 <Trinithis> > read ""
21:04:45 <lambdabot>   * Exception: Prelude.read: no parse
21:04:50 <Trinithis> > read "[]"
21:04:50 <ray> > read $ replicate 1000 '(' ++ replicate 1001 ')'
21:04:52 <lambdabot>   * Exception: Prelude.read: no parse
21:04:52 <lambdabot>   * Exception: Prelude.read: no parse
21:05:00 <Cale> m3ga: actually, probably if I knew that I was only going to be using HTTP from the outset, maybe I'd use Network.HTTP there too. That's a bit more of a matter of taste though. Network.HTTP's framework is nice. If it had support for other protocols, that would be awesome.
21:05:02 <ray> take that
21:05:03 <Makoryu> > read "Just"
21:05:05 <lambdabot>   * Exception: Prelude.read: no parse
21:05:19 <Cale> m3ga: there's http://hackage.haskell.org/packages/archive/HTTP/4000.0.8/doc/html/Network-Browser.html
21:05:27 <pikhq> > read "Just 1" :: String
21:05:28 <lambdabot>   "* Exception: Prelude.read: no parse
21:05:37 <pikhq> ...
21:05:41 <pikhq> :t read
21:05:42 <lambdabot> forall a. (Read a) => String -> a
21:05:43 <Makoryu> > read "book"
21:05:44 <lambdabot>   * Exception: Prelude.read: no parse
21:05:52 <pikhq> @instances Read
21:05:53 <lambdabot> (), (a, b), (a, b, c), (a, b, c, d), All, Any, Bool, Char, Double, Dual a, Either a b, First a, Float, Int, Integer, Last a, Maybe a, Ordering, Product a, Sum a, [a]
21:05:55 <Trinithis> > read "\"Just 1\"" :: String
21:05:56 <inimino> pikhq: needs more quotes
21:05:57 <lambdabot>   "Just 1"
21:06:04 <pikhq> inimino: Ah.
21:06:06 <Cale> > read "Just 1" :: Maybe Integer
21:06:07 <lambdabot>   Just 1
21:06:12 <Makoryu> @src id
21:06:13 <lambdabot> id x = x
21:06:42 <Trinithis> would be cooler if id could be defined pointfree: "id ="
21:06:46 <Makoryu> > let id :: a -> a; id = read . show in map id "pizza"
21:06:48 <lambdabot>   Could not deduce (GHC.Read.Read a) from the context ()
21:06:48 <lambdabot>    arising from a us...
21:06:57 <ray> a pointless way to write id would be cool
21:07:00 <soupdragon> Trinithis, haha
21:07:19 <Trinithis> > let id = id in id 5
21:07:24 <lambdabot>   mueval-core: Prelude.read: no parse
21:07:24 <lambdabot>  mueval: ExitFailure 1
21:07:39 <soupdragon> let id = s k id
21:07:46 <dino-> > read "Just 1" :: Maybe a
21:07:48 <lambdabot>   Could not deduce (GHC.Read.Read a) from the context ()
21:07:48 <lambdabot>    arising from a us...
21:07:53 <pikhq> > let id = ap const id in id 1
21:07:55 <lambdabot>   1
21:08:09 <Trinithis> thats cheating
21:08:21 <pikhq> No, it's combinators.
21:08:22 <dino-> > read "Just 1" :: Num a => Maybe a
21:08:24 <lambdabot>   Could not deduce (GHC.Read.Read a) from the context (GHC.Num.Num a)
21:08:24 <lambdabot>    aris...
21:08:36 <pikhq> ... Granted, const isn't written pointfree.
21:08:42 <pikhq> But ap sure is.
21:08:46 <pikhq> @src ap
21:08:46 <lambdabot> ap = liftM2 id
21:08:49 <pikhq> ^_^
21:08:58 <Trinithis> see cheating
21:09:01 <Trinithis> circular defn
21:09:08 <soupdragon> wait does it work?
21:09:18 <soupdragon> > let ap = liftM2 id ; id = ap const id in id 3
21:09:20 <lambdabot>   Occurs check: cannot construct the infinite type: a = b -> a
21:09:26 <pikhq> > let ap = liftM2 ($); id = ap const id in id 1
21:09:28 <lambdabot>   1
21:09:48 <Trinithis> uhhh
21:09:53 <pikhq> Trinithis: liftM2 id is the same as liftM2 ($).
21:10:08 <Trinithis> oh for functions tho
21:10:10 <aavogt> but you still have liftM2 and ($) to deal with
21:10:21 <Trinithis> or in general?
21:10:23 <aavogt> which makes that still 'cheating'
21:10:24 <Cale> :t let id = ap const id in id
21:10:25 <lambdabot> forall b. b -> b
21:10:33 <pikhq> :t liftM2 ($)
21:10:35 <lambdabot> forall a2 b (m :: * -> *). (Monad m) => m (a2 -> b) -> m a2 -> m b
21:10:39 <pikhq> :t liftM2 id
21:10:41 <lambdabot> forall a2 r (m :: * -> *). (Monad m) => m (a2 -> r) -> m a2 -> m r
21:10:47 <Cale> :t fix (ap const)
21:10:48 <lambdabot> forall b. b -> b
21:10:56 <soupdragon> > let id = liftM2 id const id in id 3
21:10:58 <lambdabot>   Occurs check: cannot construct the infinite type: a = b -> a
21:11:15 <soupdragon> why doesn't mine work
21:11:28 <soupdragon> id = fromJust . Just
21:11:35 <Trinithis> lol
21:11:45 <soupdragon> id = unsafePerformIO . return
21:11:58 <Saizan> soupdragon: no polymorphic recursion without type signatures
21:12:00 <Cale> > let id :: a -> a; id = liftM2 id const id in id 3
21:12:02 <lambdabot>   * Exception: stack overflow
21:12:06 <soupdragon> id = unsafeCoerce
21:12:18 <Trinithis> :t unsafeCoerce
21:12:19 <lambdabot> Not in scope: `unsafeCoerce'
21:12:29 <Trinithis> :t asTypeOf
21:12:31 <lambdabot> forall a. a -> a -> a
21:12:31 <soupdragon> unsafeCoerce :: a -> b
21:12:33 <pikhq> > let id :: a -> a;id = liftM2 id $ const (\_->()) in id 3
21:12:35 <lambdabot>   Couldn't match expected type `a' against inferred type `b -> ()'
21:13:01 <pikhq> But it throws away the third argument. Damned type checking, throwing away my fun.
21:13:09 <pikhq> > let id :: a -> a;id = liftM2 id $ const (\_->undefined) in id 3
21:13:11 <lambdabot>   Couldn't match expected type `a' against inferred type `b -> r'
21:13:19 <Saizan> > let id :: a -> a; id = liftM2 id const (\x -> x) in id 3
21:13:22 <lambdabot>   * Exception: stack overflow
21:13:30 <Saizan> pikhq: why the $?
21:13:38 <pikhq> Saizan: ... I'm not sure.
21:14:07 <Cale> > fix (ap const) 3
21:14:09 <lambdabot>   3
21:14:22 <Trinithis> :t ap const
21:14:24 <lambdabot> forall b a. (b -> a) -> b -> b
21:14:39 <pikhq> > let id :: a -> a;id = (\x y z -> x z (y z)) (\x y -> x) (\_->undefined) in id 3
21:14:40 <lambdabot>   3
21:15:06 <abbe> I realized most of the mistakes/issues I encountered during learning Haskell, are due to the operator precedence rules...:-D
21:15:13 <Cale> I = Y (S K)
21:15:23 <Cale> apparently
21:15:37 <Cale> abbe: what about them?
21:15:52 <Cale> abbe: function application always binds more tightly than any operator symbol
21:16:17 <abbe> like incorrectly using (.) and ($) operators.
21:16:22 <Trinithis> @djinn a->a
21:16:22 <lambdabot> f a = a
21:16:25 <Cale> ah, hmm
21:16:34 <Trinithis> @djinn forall b a. (b -> a) -> b -> b
21:16:34 <lambdabot> f _ a = a
21:16:42 <soupdragon> it
21:16:57 <Cale> Usually, I like to chain a bunch of functions together with (.) and apply the composite to a value just at the end with ($)
21:16:57 <abbe> I'm now slowly getting accustomed to folding, and other common operations, Haskell is really enlightening...:)
21:17:24 <pikhq> > (\x y z->x.z$y.z)(\x y->x)(\_->undefined)3
21:17:25 <lambdabot>   Occurs check: cannot construct the infinite type: a = a -> c
21:17:37 <Trinithis> There should be a backwards $ :D
21:17:40 <pikhq> Obfuscated Haskell FTW?
21:17:44 <Cale> If you have more than one ($) chained together, it's a good idea to replace one of them with (.)
21:17:53 <Trinithis> why
21:18:11 <SamB_XP> because some of us plan a revolution one day
21:18:11 <Cale> Because (.) is a nicer operation, it's associative
21:18:27 <Cale> and yes, it fits in well with the idea of flipping the associativity of ($)
21:19:00 * abbe prays to God to give a shot to Haskell (or Perl6) instead of Perl...
21:19:03 <pikhq> > ((\x y z->x.z$y.z)(\x _->x)(\_->undefined)::a->a)3
21:19:05 <lambdabot>   Occurs check: cannot construct the infinite type: a = a -> c
21:19:20 <SamB_XP> and this is why the right to bare arms is so important ;-)
21:19:20 <pikhq> > (((\x y z->x.z$y.z)(\x _->x)(\_->undefined))::a->a)3
21:19:22 <lambdabot>   Occurs check: cannot construct the infinite type: a = a -> c
21:19:28 <pikhq> :(
21:19:54 <Cale> In general, if you have a choice between (.) and ($), you should always pick (.) though, because you have f . (g . h) = (f . g) . h which helps in rearranging and understanding code. ($) doesn't have that, and usually only one of the two corresponding expressions will even be well-typed.
21:19:57 <pikhq> SamB_XP: I prefer the right to arm bears.
21:20:04 <Trinithis> > fix const 3
21:20:05 <lambdabot>   Occurs check: cannot construct the infinite type: a = b -> a
21:20:29 <Cale> abbe: Avoid success at all costs.
21:21:00 <Trinithis> oh
21:21:02 <SamB_XP> pikhq: how about the right arms of bears?
21:21:14 <Trinithis> > fix (flip const) 3
21:21:16 <lambdabot>   3
21:21:18 <abbe> thanks Cale :)
21:22:20 <soupdragon> > (fix . const) 3
21:22:22 <lambdabot>   3
21:22:34 <Cale> abbe: Success makes programming languages hard to change, which means that the stuff which is bad remains bad forever.
21:22:55 <Cale> abbe: If you want a good programming language then, it must be unpopular.
21:23:17 <SamB_XP> that's why we're going to have to move channel soon
21:23:58 <abbe> yeah, never thought about that, true.. so we'll have to keep forking a language into another dialect whenever it become popular :)
21:24:26 <Trinithis> Haskell >>= dialect
21:25:44 <Trinithis> s/dialect/newDialect
21:29:45 <dancor> what is something that is EXPSPACE-complete?
21:30:04 <dancor> nm on wikipedia
21:58:55 <resistor> anyone familiar with the GHC build system around?
22:00:49 <Makoryu> I guess some people in #ghc might be
22:01:53 <resistor> thanks
22:02:31 <Makoryu> Incidentally, I hear there's an alternative to cabal-install
22:02:37 <Makoryu> Anyone know what that might be?
22:02:46 <dons> hmm. there isn't really
22:02:53 <dons> there was franchise
22:57:19 <tommd> Yo hydo, glad you're coming to the hackathon!
22:58:09 <hydo> tommd: Yessir!  I might come a day early actually.  I lived there for ~12 years or so.  Only been away for about four.  So many places to go eat!
22:58:35 <Yrogirg> Hello! How do I make type which is exactly 2D Array, but one dimension is fixed? (3 x n)
22:59:01 <tommd> Good!  You can help figure out where would be good for lunch and/or dinner - I've only been here for a matter of months so I haven't figured out what food is good on the weekends for the SW area.
22:59:23 <tommd> Yrogirg: You want Data.Array
22:59:53 <hydo> Oh, I can hook you up!
23:00:23 <hydo> I can just taste an Ole' burrito from Ole' Ole' .... mmmm... Nothing like a burrito with a chile relleno in the middle of it.
23:00:24 <tommd> Sweet!  Feel free to add a page on the wiki, link to a google map or some such.
23:01:45 <Yrogirg> tommd: I need only special kind of Array --- that ((1,1)(3, n)) array and to call this type as Configuration
23:02:41 <Yrogirg> and to make a type that is array ((1,1), (6, n)) and make both this types instances of one typeclass
23:03:29 <hydo> tommd: Hrm, yea I might have to do that.  But now, I sleep.
23:04:05 <hydo> I mean, Yea, I'll do that... anything I can do to help people have a good time at the event.
23:04:17 <BMeph> Yrogirg: Just a warning/clarification - in an Array, both/all dimensions are fixed. :)
23:05:49 <BMeph> Yrogirg: But we "smell what you're stepping in". ;)
23:06:09 <Yrogirg> but I can create array with various lengths 2x3, 4x7 and so on. I need a type that is only 3x12, 3x4, 3x87, 3x101 etc. 2D array.
23:08:32 * tommd -> Bed
23:09:09 <jfoutz> :k tommd -> Bed
23:09:10 <lambdabot> Not in scope: type variable `tommd'
23:09:11 <lambdabot> Not in scope: type constructor or class `Bed'
