00:03:39 <vy> I'm looking at 6.12.1 documentation (@ http://www.haskell.org/ghc/docs/6.12.1/html/) but couldn't spot any chapter about regular expressions. Is Text.Regex.Posix removed from the core?
00:03:58 <kmc> vy, most likely.  it will be in Haskell Platform for 6.12.1 when that drops
00:04:03 <vy> Which module supplies (=~) op?
00:04:19 <kmc> for now if you must use 6.12.1 you can cabal-install the right package
00:04:22 <Twey> Text.Regex
00:04:23 <kmc> which, i cannot tell you which one it is
00:04:45 <vegai> regex-base, regex-posix, regex-compat
00:05:02 * vegai is fighting with the package split right now :p
00:05:37 <vegai> I kinda liked the centralization of important libs
00:06:04 <copumpkin> it's nice that they can be updated independently now
00:06:11 <copumpkin> and at a faster pace than ghc, possibly
00:06:25 <vegai> yeah, that's a benefit
00:06:40 <kmc> yeah, the idea is for the centralization to be Platform, not GHC
00:07:16 <vegai> then again, most distros will treat the platform as just a metapackage
00:07:19 <vegai> , right?
00:07:20 <lunabot>  luna: Not in scope: `right'
00:07:40 <dibblego> can any HXT users tell me how to write a Text.XML.HXT.Arrow.Pickle.Xml for a disjoint union type such as Either?
00:08:13 <dibblego> Text.XML.HXT.Arrow.Pickle.Xml.XmlPickler
00:08:18 <copumpkin> omnom
00:09:59 * BMeph is not hungry for some Text.XML.HXT.Arrow.Pickle.Xml.XmlIceCream!
00:10:03 <BMeph> *now
00:10:26 <merehap> that's only complete with some tabasco sauce
00:10:43 <kmc> XML seems like a reasonable data model with an awful text serialization format
00:10:46 <kmc> how did this happen
00:11:20 <merehap> same way java happened: verbosity always wins
00:12:03 <kmc> i think those are side effects in both cases
00:12:14 <kmc> Java is not popular because it's verbose
00:12:39 <dibblego> one need only work for the machine itself to know why Java is popular
00:12:45 <lament> perl is also popular
00:13:12 <kmc> java and perl are both mediocre solutions to problems that were extremely pressing when they were introduced
00:13:43 <danblick> I'll play devil's advocate... I think "verbose" is not a good word for XML.  "Verbose" implies extra words.  Vocabulary used in XML documents is not part of XML.
00:14:04 <kmc> XML is information sparse in the very literal sense that it compresses well
00:14:27 <dibblego> can you get a type isomorphic to Either using Maybe alone?
00:14:38 <Twey> Nnnno
00:14:43 <kmc> define "alone"
00:14:48 * dibblego grasps at straws
00:15:08 <lament> alone in the existential sense
00:15:08 <dibblego> such that I can use an exponential functor (TheType -> Either) and (Either -> TheType)
00:15:12 <Twey> No
00:15:17 <ivanm> dibblego: bendy straws or normal straws?
00:15:30 <dibblego> PU straws
00:15:33 <dibblego> http://www.fh-wedel.de/~si/HXmlToolbox/hdoc/Text-XML-HXT-Arrow-Pickle-Xml.html
00:15:52 <Twey> Not unless one of the values is a natural encodable in a sort of Peano encoding using Justs
00:16:08 <dibblego> Twey, right, I'm wanting polymorphic
00:16:38 <ivanm> :o I crashed google! :o
00:16:44 <Axman6> :O
00:16:55 <ivanm> OK, it's back again...
00:17:00 <lament> kmc: xml does compress well, but of course any human-readable format compresses well
00:17:02 <Twey> Did you type ‚ÄòGoogle‚Äô into Google?
00:17:03 <ivanm> somehow searching for "define:PU" crashed it...
00:17:05 <ivanm> Twey: heh
00:17:08 <Twey> Because you know that will break the Internet
00:17:17 <lament> kmc: i'd like to see a comparison of different programming languages by compression factor
00:17:28 <kmc> APL will win
00:17:33 <kmc> err, for certain definitions of "win"
00:17:45 <copumpkin> haskell is pretty high up there in density
00:17:46 <lament> possibly
00:17:47 <kmc> XML goes far beyond the level of repetition that is comforting to humans
00:17:55 <kmc> to a level which is downright annoying
00:17:55 <lament> copumpkin: haskell will lose a lot on whitespace :)
00:18:12 <copumpkin> :)
00:18:20 <lament> kmc: yeah, i guess that's more descriptive
00:18:53 <kmc> @where fold.diagrams
00:18:53 <lambdabot> http://cale.yi.org/index.php/Fold_Diagrams
00:21:01 <kmc> @pl \f -> foldr (\x xs -> f x : xs) []
00:21:02 <lambdabot> flip foldr [] . ((:) .)
00:21:19 <kmc> @pl \x xs -> f x : xs
00:21:19 <lambdabot> (:) . f
00:22:48 <tass> Hot damn!
00:23:01 <vy> How can I parse a timestamp of form "Mon, 07 Apr 2008 09:08:58 +0300 (EEST)" into a ClockTime?
00:23:08 <kmc> map f = foldr ((:) . f) []  -- :)
00:23:10 <tass> My haskell bot is waaaaay faster than it's perl irssi predecessor!
00:23:25 <Twey> Well, that's fairly unsurprising :√æ
00:23:37 <tass> Really?
00:23:51 <tass> Dunno, I'm using PCRE extensively in my haskell bot, too.
00:24:04 <Twey> Do you actually need PCRE?
00:24:14 <Twey> If not, try Thompson ‚Äî they're a lot faster
00:24:18 <tass> I prefer regexing stuff over pattern matching : P
00:24:37 <kmc> is there a standard name for the dominant Perl implementation other than "perl"?
00:24:39 <tass> (Since I _know_ regex)
00:24:43 <ivanm> kmc: AFAIK, that's it
00:24:45 <kmc> :(
00:24:50 <kmc> i will call it CPerl
00:24:57 <ivanm> kmc: AFAIK, perl5 has only one implementation...
00:24:58 <Axman6> tass: bad preference
00:25:13 <vy> Data.Time.Format, it appears to be...
00:25:17 <Twey> tass: Thompson is regex
00:25:22 <tass> Axman6: How so?
00:25:24 <kmc> ivanm, sure, it's still worth distinguishing between the language and the implementation
00:25:25 <Twey> It's just a saner implementation than PCRE
00:25:37 <tass> Twey: Ah, I see
00:25:48 <tass> kmc: There's really only one perl implementation.
00:25:54 <Twey> http://swtch.com/~rsc/regexp/regexp1.html
00:25:58 <Axman6> tass: because regexs are extremely difficult to debug, and are used for far more than they ever should be
00:26:03 <kmc> tass, i know, i stand by my statement
00:26:17 <medfly> :)
00:26:18 <ivanm> kmc: perl vs Perl looks like the distinction
00:26:22 <kmc> eew
00:26:24 <tass> Axman6: Difficult to debug? Not really imo.
00:26:29 <ivanm> well, Perl == language; perl == implementation
00:26:38 <Twey> To quote: ¬´ The trends shown in the graph continue: the Thompson NFA handles a 100-character string in under 200 microseconds, while Perl would require over 1015 years. ¬ª
00:26:46 <ivanm> heh
00:26:54 <Twey> Er, that's 10¬π‚Åµ, sorry
00:26:57 <medfly> wait, what?
00:27:19 <ivanm> Twey: even better ;-)
00:27:22 <Twey> medfly: There are certain patterns at which PCRE is tremendously slow at matching.
00:28:16 <Twey> For this reason, Thompson should be your default when using regexes, and PCRE avoided unless absolutely necessary.
00:28:39 <tass> Twey: Does it have any syntax quirks?
00:28:43 <Twey> No
00:28:55 <medfly> how can something be that slow for a 100-character string?
00:29:06 <napping> exponential backtracking
00:29:12 <kmc> 2^100 is a big number
00:29:22 <elly> 2^(2^100) is an even bigger number
00:29:27 <dibblego> xpAlt
00:29:29 <napping> apparently some people never learned all that stuff about dfa construction
00:29:29 <medfly> years?
00:29:46 <napping> you know, the reason they are called "regular" expressions in the first place
00:29:48 <kmc> napping, yeah, we don't need theory, we're *practical* programmers ;)
00:29:48 <Twey> The paper goes into it in detail if you're interested, medfly
00:30:07 <medfly> :o
00:30:08 <Twey> It's heavy reading, but you don't need much foreknowledge
00:30:29 <Twey> ‚Ä¶ did I just call a Web page explaining something a ‚Äòpaper‚Äô?
00:30:34 <medfly> lol
00:30:36 <Twey> Argh, I'm going native
00:30:38 <medfly> yes you did.
00:30:59 <lament> a "scroll"
00:31:03 <Twey> Haha
00:31:04 <ivanm> Twey: :(
00:31:12 <ivanm> lament: parchment, hide, etc.
00:31:19 <Twey> Papyrus!
00:31:24 <tass> Heh... yeaaah, I've got a *lot* of regex going on in my code
00:32:23 <tass> It's nice, though. Since I can specify how ambigious input can be.
00:33:37 * medfly reads.
00:34:15 <tass> And security is greatly improved from it's predecessor, now it actually checks the hostmask to determine if it's me or not, instead of only the nickname : D
00:35:30 <Twey> tass: If you tell the server you support CAPAB IDENTIFY-MSG, you can just check the nick and the identification status
00:35:46 <Twey> And let NickServ handle authentication
00:36:59 <tass> Twey: I loath NickServ, don't even run it on my own network, so that's not plausible. : )
00:37:09 <Twey> Tsk, tsk :√æ
00:37:35 <copumpkin> loathe!
00:37:41 <ray> NO THORNS
00:37:48 <ray> speaking of loathing
00:37:52 <copumpkin> DRONG IS A CAT
00:37:59 <ray> take your thorns back to iceland
00:38:06 <kmc> @quote ˛
00:38:06 <lambdabot> No quotes match. Just try something else.
00:38:25 <tass> s/\\s(loath)\\s/loathe/
00:38:30 <Twey> kmc: Encoding fail :√æ
00:38:57 <ray> the only fail is the letter thorn
00:38:58 <Twey> ray: Would you prefer a flower instead? ‚öò
00:39:13 <Twey> What do you have against the letter thorn?
00:39:15 <Twey> It's a lovely letter.
00:39:36 <Twey> And also makes a good tongue.
00:39:39 <ray> that is an objectively wrong opinion my friend
00:39:50 <ray> thorns are only good for making hate websites about
00:40:06 <Twey> Psht
00:40:22 <medfly> thanks guys, I guess I'll get some sleep. night
00:40:35 <Twey> ray: Why do you hate Icelanders‚ÄΩ  :√æ
00:40:38 <Twey> medfly: 'night!
00:40:45 * Twey gets another cup of tea.
00:40:57 * elly enjoys the phrase "objectively wrong opinion"
00:45:09 <Twey> elly: Hehe
00:48:44 <merehap> ugh, can't figure out how to write a thorn :(
00:49:09 <Twey> Compose t h
00:49:20 <Twey> By default in English locales
00:49:30 <merehap> compose?
00:49:41 <Twey> http://en.wikipedia.org/wiki/Compose_key
00:50:03 <merehap> ah, thanks
00:51:31 <mjsor> anyone in here ever install the chart package via cabal?  I'm having a heck of a time getting it to pick up the gtk and cairo dependencies.
00:51:59 <dcoutts> mjsor: do you have gtk2hs installed?
00:52:16 <dcoutts> with gtk2hs installed it should just work
00:52:20 <mjsor> lemme check
00:52:34 <dcoutts> ghc-pkg list gtk
00:52:55 <mjsor> nope
00:53:13 <dcoutts> @where gtk2hs
00:53:13 <lambdabot> http://haskell.org/gtk2hs/
00:53:28 <merehap> i failed doing it through cabal but pacman did it sucessfully for me
00:53:32 <dcoutts> mjsor: or your linux distro might have packages already
00:53:37 <merehap> I don't know if you are using arch, though
00:53:43 <mjsor> i'm checking -- i'm on the latest ubuntu release.
00:53:59 <merehap> yeah, just use the apt one
00:54:14 <mjsor> I wonder how hard it would be to have the cabal install bail out saying "check for gtk2hs" instead of asking for gtk and cairo installs that I made sure to install.  :-)
00:54:17 <merehap> i couldn't find in on cabal
00:54:56 <dcoutts> mjsor: thing is, cabal does not know where to find the gtk package
00:55:07 <dcoutts> gtk2hs does not use cabal and it's not on hackage
00:55:52 <mjsor> sure
00:59:55 <mjsor> crud.  installing gtk2hs got me further, and now template-haskell is failing to build.
01:00:17 <merehap> ha, I think that's the same thing that happened to me
01:00:25 <merehap> I didn't get past that part though
01:00:27 <dcoutts> mjsor: you should not need to install TH, it should be installed already
01:00:35 <BMeph> Twey: I prick you with my prickly exterior! :˛
01:00:36 <mjsor> hmm.
01:00:43 <mjsor> how do I convince cabal of that?
01:01:01 <dcoutts> mjsor: see --dry-run -v, see what it says it's going to install.
01:01:03 <merehap> BMeph: you beat me to it
01:01:15 <merehap> I still can't get it on my US keyboard
01:01:27 <dcoutts> mjsor: it may be that the package you're tring to install wants an older version of TH than the one you've currently got
01:02:57 <mjsor> yeah - i have v2.3.0 installed, and I guess the chart package wants 2.4.0.
01:11:39 <Mark1> so... i have this list of strings ["aa","hh","b","l","a","h"], and i'm passing it to takeWhile (\(x:xs) -> all (==x) xs), which I thought would give me ["aa", "hh"]
01:11:52 <Mark1> but for some reason it's giving me ["aa","hh","b","l","a","h"]
01:12:05 <Mark1> does anyone know what i'm doing wrong?
01:12:10 <kmc> Mark1, "all p []" is true for every predicate p
01:12:20 <mauke> yes, you thought it would give you ["aa", "hh"]
01:12:25 <kmc> every element of [] is a live chicken
01:12:27 <mauke> everything else looks right
01:13:09 <kmc> every negative natural number is colored blue
01:14:00 <kmc> @src all
01:14:01 <lambdabot> all p =  and . map p
01:14:06 <kmc> > all (== 17) []
01:14:08 <lambdabot>   True
01:14:15 <kmc> @src and
01:14:15 <lambdabot> and   =  foldr (&&) True
01:15:00 <Twey> Odd
01:15:03 <Twey> I'd expect False
01:15:12 <ski>   foldr (&&) True . map p  =  foldr ((&&) . p) True
01:15:25 <ski> `True' is the unit of `(&&)'
01:15:45 <kmc> > product [] -- Do you expect 0?
01:15:46 <lambdabot>   1
01:16:06 <ski> > odd True
01:16:08 <lambdabot>   No instance for (GHC.Real.Integral GHC.Bool.Bool)
01:16:08 <lambdabot>    arising from a use of ...
01:16:12 <Mark1> i'm a bit lost... why does [] behave that way?
01:16:13 <kmc> it's important that:  all p (x:xs) = (p x) && (all p xs)
01:16:14 <mauke> > foldr f z [a,b,c]
01:16:15 <lambdabot>   f a (f b (f c z))
01:16:35 <merehap> True is the identity of &&
01:16:35 <kmc> if (all p []) is false, then "all" always returns false
01:16:36 <mauke> Twey: if z = False and f = (&&), it would return False all the time
01:16:51 <Twey> Oh, yeah, I guess
01:16:55 <kmc> Mark1, it's a question of why "all" behaves that way
01:17:04 <ski> Mark1 : every character in the list  []  is an  'a'  .. can you point at one which isn't ?
01:17:49 <Mark1> i see
01:17:52 <kmc> Mark1, we also want this identity:  all p xs = not (any (not . p) xs)
01:18:02 <kmc> p holds for every element of xs, iff there is no element where p does not hold
01:18:10 <kmc> clearly if xs is [] then there is no element where p does not hold
01:18:13 <kmc> there is no element *period*
01:18:15 <Axman6> > map (foldr f z) (inits [a,b,c])
01:18:16 <lambdabot>   [z,f a z,f a (f b z),f a (f b (f c z))]
01:18:17 <mauke> kmc: GET OUT OF MY MIND
01:18:20 <kmc> haha
01:18:26 <Axman6> > map (foldr (+) z) (inits [a,b,c])
01:18:27 <lambdabot>   [z,a + z,a + (b + z),a + (b + (c + z))]
01:18:49 <mauke> > scanl f z [a,b,c]
01:18:50 <lambdabot>   [z,f z a,f (f z a) b,f (f (f z a) b) c]
01:19:03 <kmc> Mark1, it's the same way in mathematics
01:19:22 <kmc> sum [] = 0; product [] = 1; all [] = True; any [] = False
01:19:47 <kmc> because (0, 1, True, False) are the identities of (+, *, &&, ||) respectively
01:19:47 * ski hands kmc two `_'s
01:19:59 <kmc> __?
01:20:06 * Twey hands kmc four ()s
01:20:09 <Mark1> ok, cool. that's very enlightening.
01:20:10 <kmc> err sure
01:20:10 <Mark1> thanks
01:20:12 <ski>   all _ [] = True
01:20:32 <kmc> i meant: and [] = True; or [] = False
01:20:35 <Mark1> what i was trying to do with my function map head . takeWhile (\(x:xs)-> all (==x) xs) . transpose was get longest common prefixes
01:20:47 <kmc> and = all id; or = any id
01:21:06 <kmc> > all id
01:21:08 <lambdabot>   []->
01:21:08 <lambdabot>    True
01:21:08 <lambdabot>  [True]->
01:21:08 <lambdabot>    True
01:21:08 <lambdabot>  [True,True]->
01:21:10 <lambdabot> [3 @more lines]
01:21:13 <mauke> M ‚äÇ N := ‚àÄx‚ààM. x‚ààN
01:21:42 <ski> Mark1 : btw, what should happen when one of the strings in the list is the empty string ?
01:21:48 <mauke> ‚àÖ ‚àà {42} ?
01:21:55 <mauke> er
01:21:59 <mauke> subset, not elem
01:22:07 <Mark1> ignore it, i think
01:22:27 <merehap> pattern match fails
01:22:31 <kmc> mauke, ‚àÖ ‚àà 42 however ;)
01:22:53 <ski> hm, i suppose `transpose' won't produce an empty element list ..
01:23:00 <mauke> oh, you
01:23:30 <ski> > foldr (zipWith (:)) (repeat []) []  -- however ..
01:23:31 <lambdabot>   [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]...
01:23:55 <Mark1> would replacing all with any work?
01:24:06 <ski> Mark1 : "work" meaning ?
01:24:23 <Mark1> return the longest common prefix?
01:24:26 <kmc> Mark1, it seems you want a slightly unnatural function on these strings
01:24:41 <merehap> you could filter out all elements that are less than 2 in length
01:24:41 <Mark1> maybe i should explain my real goal
01:24:53 <merehap> and then use your code
01:25:02 <merehap> and I think you will get what you intend
01:25:30 <juhp> dcoutts: any thoughts on:  Perhaps you haven't installed the "p_dyn" libraries for package `haskell98'?
01:25:38 <Mark1> i was reading a java solution for the longest repeating substring problem today, and i thought it would be good practice to try converting it from the imperative idiom to the functional idiom
01:25:47 <juhp> guess i need to build ghc with p_dyn?
01:25:56 <dcoutts> juhp: looks like it
01:26:07 <juhp> ok
01:26:18 <dcoutts> juhp: are there any dyn versions of the core libs?
01:26:25 <juhp> dcoutts: yeah
01:26:26 <kmc> > let p s = case s of [] -> False; [_] -> False; (x:xs) -> all (== x) xs in filter p ["", "a", "abc", "aa", "bcd", "bb"]
01:26:27 <lambdabot>   ["aa","bb"]
01:26:38 <dcoutts> juhp: ok so there's plain dyn, but not profiling + dyn
01:26:46 <juhp> dcoutts: right
01:27:13 <kmc> > transpose $ words "hello world how are you today"
01:27:14 <lambdabot>   ["hwhayt","eooroo","lrweud","lla","ody"]
01:27:23 <dcoutts> juhp: then that's probably more of a build system issue, I don't think there's a toggle to get one and not the other
01:27:25 <juhp> dcoutts: hits when I try to build a binlib package configured with shared and dynamic
01:27:33 <juhp> yeah
01:27:55 <dcoutts> juhp: I guess the people who did the OSX patches didn't consider dyn + prof together
01:27:56 <juhp> guess it is ok
01:28:03 <juhp> aha
01:28:21 <juhp> dcoutts: guess there is no configure option to ghc for p_dyn
01:28:25 <juhp> ?
01:28:49 <ski> > iterate transpose ["ab","c","","defg"]
01:28:50 <lambdabot>   [["ab","c","","defg"],["acd","be","f","g"],["abfg","ce","d"],["acd","be","f...
01:28:53 <dcoutts> juhp: right, there's profiling and theres dyn, but I'd expect if you use both that you should get all four combinations.
01:29:05 <juhp> ok
01:29:26 <juhp> wonder if I should try to build ghc with -dynamic?
01:29:29 <juhp> anyone tried that
01:29:39 <mauke> ‚äÇ‚äÉ‚äÑ‚äÖ yay
01:29:52 <juhp> lol
01:30:35 <Mark1> ok, thank you. i'll get to work dissecting that function and figuring out how it works.
01:31:51 <kmc> i feel like http://www.willamette.edu/~fruehr/haskell/evolution.html could use an update
01:32:12 <Mark1> i haven't seen [_] before.. is there a term for that?
01:32:22 <kmc> Mark1, that is (_:[])
01:32:25 <Twey> A list of one element, whose identity we don't care about
01:32:26 <dibblego> pattern matching the list of one element
01:32:41 <kmc> that page should definitely have a type-families variant of the static one
01:32:42 <Zao> References?
01:32:45 <kmc> probably some GADTs
01:32:46 <Twey> kmc: Perhaps into the realm of monad tutorials?  :√æ
01:32:53 <kmc> some template haskell
01:32:59 <Mark1> ok, cool. thanks.
01:33:10 <Zao> Heh, thought you were referring to (read that n+k patterns are ‚Äúa disgusting part of Haskell‚Äù [1] and joined the ‚ÄúBan n+k patterns‚Äù-movement [2])
01:33:21 <kmc> aha that too
01:33:27 <Twey> :<
01:33:37 * Twey wants n*k patterns, too
01:33:52 <kmc> maybe some view patterns while we're at it
01:33:57 <dcoutts> juhp: I wouldn't use ghc built with -dynamic as your default choice for a distro just yet, however there's no harm in experimenting.
01:33:58 <Twey> Hehe
01:34:12 <kmc> a version of the interpretive one which compiles via LLVM
01:34:46 <juhp> dcoutts: ok :)
01:35:05 <Adamant> Twey: if there is thorn, is there also octothorn? :P
01:35:35 <mauke> „ãâ
01:36:23 <kmc> ‚ò≠
01:36:39 <copumpkin> October!
01:36:49 <copumpkin> that's a really awkward character
01:36:49 <kmc> preflex, karma ‚ò≠
01:36:49 <preflex>  ‚ò≠ has no karma
01:36:55 <kmc> ‚ò≠++
01:36:57 <kmc> preflex, karma ‚ò≠
01:36:57 <preflex>  ‚ò≠: 1
01:37:07 <Twey> Haha, there's an October character?  Nice
01:37:23 <Adamant> n√∂w w√Øth √´xtr√§ √ºml√§√ºt
01:37:27 <Twey> TELEGRAPH SYMBOL, apparently
01:37:37 <kmc> dunno what you guys see but it's a hammer and sickle
01:37:48 <Adamant> yeah, it's all commie
01:38:23 <Axman6> kmc: that's what i'm getting
01:38:36 <shambler> in soviet russia ‚ò≠ karma you
01:38:51 <Mark1> i think i'm getting it! :-) thanks everyone for your help. haskell is a pleasure to learn, and you guys are extremely helpful.
01:38:53 <mauke> stop talking about different things without realizing it
01:38:55 <Twey> kmc: „ãâ ‚Äî this one
01:39:03 <kmc> I ‚ò≠ NY
01:39:04 <Twey> Mark1: Feel welcome ‚ò∫
01:39:21 <kmc> Twey, i have no idea what that is
01:39:29 <mauke> <copumpkin> October!
01:39:29 <Mark1> thanks! have a good night.
01:39:30 <kmc> looks like a squashed "10" and a really squashed Han character of some kind
01:39:33 <kmc> that's "october"?
01:39:37 <Twey> Yep
01:39:43 <kmc> in what language / symbology?
01:39:47 <Twey> Compression of 10Êúà
01:39:48 <Adamant> kmc: that sounds like something that would be a big hit on a bumper sticker around there
01:39:51 <copumpkin> Êúà
01:39:57 <Twey> Generic CJK
01:39:59 <kmc> Adamant, heh... where abouts is that?
01:40:09 <Adamant> kmc: da dirty Souf
01:40:13 <kmc> haha
01:40:14 <Twey> In Japanese it's read ‚Äòzyuugatu‚Äô‚Ä¶ don't know about the rest, but they'll have their own
01:40:26 <kmc> CJK, really?  even K?
01:40:37 <Twey> Antiquatedly, yes
01:41:16 <kmc> see when copumpkin said "October" i thought he was overcome with revolutionary spirit after seeing my ‚ò≠
01:41:25 <Adamant> so did I
01:41:30 <Twey> Hehe
01:41:33 <Twey> As in Red?
01:41:37 <kmc> the reddest
01:41:46 <copumpkin> lol
01:41:47 <Adamant> or the October Revolution :P
01:42:03 <mauke> which happened in November
01:42:14 <Adamant> mauke: unless you're a real Russian
01:42:32 <kmc> yeah, Red October meaning October Revolution
01:42:35 <SnailRacer> Blah, have a red and green xmas
01:42:35 <kmc> mauke, papist!
01:42:53 <Adamant> kmc: I think the Orthodox use other insults
01:42:54 <kmc> the gregorian calendar is a plot by the catholic church
01:43:08 <Adamant> papist is more of a Proddy thing
01:43:08 <kmc> yeah well i'm not orthodox so, whatevs
01:43:17 <mauke> a plot to provide us with a better calendar!
01:44:20 <Adamant> mauke: and increase the size of Vatican territory over the long run via calenderic subversion
01:44:55 <Adamant> sooner or later you will see the real inner workings of this conspiracy
01:45:01 <Adamant> :P
01:45:15 <kmc> just like leap seconds are a plot by the sorcerers of BIPM
01:48:20 <mreh> i only get half of these unicode characters
01:50:57 <mreh> where do the square boxes with numbers inside come from?
01:51:20 <mauke> well, when a number and a box love each other very much, ...
01:51:27 <dcoutts> mreh: that's showing you code points where you've got no font
01:52:31 <mreh> cool
01:53:21 <mreh> was reading about hacking last night, aside from the usual fencepost programming errors, haskell seems entirely free from vulnerability from buffer overrun exploits
01:53:27 <mreh> software written in haskell that is
01:54:09 <mreh> how does GHC manage memory?
01:54:24 <mauke> magic!
01:54:33 <ahf> correctly :)
01:54:38 <mauke> and a copying garbage collector
01:56:15 <kmc> there are plenty of ways to do unsafe memory access in GHC Haskell
01:56:32 <kmc> but you have to go out of your way to do it
01:56:45 <adu> you know ... Haskell has the perfect type system
01:57:12 <copumpkin> the perfect type system would give you dependent types with no compromises!
01:57:14 <mjsor> quick question.  I want to print an error message when the wrong number of arguments are passed to a program.  I have this code (http://pastebin.com/d20dd1bbe) that takes the result of getArgs, and is intended to print an error and then exit if <1 args present or return nothing if 1 or more args is present.  Why does adding a putStrLn "blah" to the do block in the then clause cause it to not type check?
01:57:20 <kmc> adu, i doubt it ;P
01:57:47 <copumpkin> dependent types, inference, subtyping, and various other more esoteric typing strategies, all at once!
01:57:49 <mauke> mjsor: hard to tell without the code or the error
01:57:57 <adu> copumpkin: oh, ya, perfect minus deptypes
01:58:45 <kmc> H98's type system is relatively weak compared to what's implemented in GHC
01:58:53 <mjsor> pasted the wrong one in.  Here's the correct paste...  http://pastebin.com/m567b2c2f
01:58:53 <kmc> and what's implemented in GHC is far from perfect
01:58:56 <adu> I was wondering, does CL's (deftype ...)'s (satisfies ...) type specifier allow definition of dependent types?
01:59:09 <mauke> mjsor: wrong indentation
01:59:16 <kmc> mjsor, "exitFailure" should align with "putStrLn"
01:59:19 <copumpkin> adu: nope
01:59:24 <kmc> what you have there is:  putStrLn "Blah" exitFailure
01:59:28 <adu> copumpkin: why not?
01:59:29 <kmc> which fails because putStrLn won't take two args
01:59:45 <mjsor> erm... it does in the editor.
01:59:51 <kmc> mjsor, don't use tabs
01:59:52 <kmc> ever
01:59:54 <mauke> mjsor: are you using tabs?
01:59:58 <kmc> tabs = the devil
02:00:32 * kmc feels very strongly about tabs
02:00:34 <mjsor> ugh.
02:00:49 <kmc> if you must use them, you need to set your editor to a tabstop of 8
02:00:54 <ben0x539> tabs are betwen 2 to 4 devils
02:00:56 <copumpkin> adu: I didn't think it was statically verified
02:00:57 <kmc> because that is the tabstop specified in the Haskell Report
02:01:00 <mauke> kmc: actually, no
02:01:02 <Ytinasni> and what kmc means is "use spaces/tabs _consistently" :D
02:01:07 <mjsor> invisible syntax....  gotta love it.
02:01:12 <kmc> Ytinasni, no, what i mean is never use tabs ever, they are the devil
02:01:15 <kmc> but your advice is good too ;)
02:01:16 <Ytinasni> :D
02:01:19 <mauke> mjsor: no one forced you to use it :-)
02:01:26 <mjsor> heh.
02:01:29 <kmc> mjsor, you can always replace indentation with { } ;
02:01:37 <adu> copumpkin: oh you mean compile-time dependent types... thats a different story ;)
02:01:38 <kmc> do { putStrLn "Blah"; exitFailure }
02:01:47 <copumpkin> adu: well at runtime it's trivial
02:01:47 <kmc> indeed the whitespace is pre-processed to this form before it hits the parser
02:02:11 <kmc> also, you can write this as (putStrLn "Blah" >> exitFailure)
02:02:11 <mjsor> true.  this is what I get for "upgrading" from my comfortable, working emacs config to textmate.
02:02:27 <kmc> and, you don't need "do" on a single statement.  "do e" is just "e"
02:02:31 <Axman6> mjsor: it is an upgrade ;)
02:02:48 <kmc> mauke, tabs aren't 8 chars in the report?
02:02:49 <mjsor> heh.  yeah - it upgraded me to making dumb mistakes.
02:03:04 * ski sometimes uses `do' on a single command
02:03:14 <mauke> http://pastebin.com/m4b61cd13
02:03:21 <mauke> kmc: you don't have to use 8 space tabs
02:03:32 <mjsor> yeah, i know about the excessive do's.  I go a bit do-happy when I'm debugging.
02:03:45 <mauke> all of my earlier code is written with 4-space tabs
02:03:50 <kmc> mjsor, or:  validateArgs s = when (length s < 1) (putStrLn "Blah" >> exitFailure)
02:03:56 <kmc> :t when
02:03:57 <lambdabot> forall (m :: * -> *). (Monad m) => Bool -> m () -> m ()
02:04:11 <mjsor> kmc: i like that.  thanks.
02:04:12 * Axman6 uses 4 space tabs
02:04:15 <kmc> :)
02:04:19 <mauke> mjsor: see my paste
02:04:42 <kmc> mauke, sure -- but you're using them consistently in such a way that GHC is happy thinking they are 8 spaces, correct?
02:04:48 <mjsor> mauke: thanks
02:04:48 <ben0x539> Maybe there would be fewer indentation errors if we stopped using 8 space tabs and used 8 underscore tabs instead
02:04:57 <kmc> or 8 skull and crossbones
02:05:37 <mauke> I use them to mark indentation levels (only)
02:05:44 <ski> @help redo
02:05:44 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
02:05:49 <ski> @help do
02:05:49 <lambdabot> do <expr>
02:05:50 <lambdabot> Translate Monad operators to do notation.
02:06:07 * ski seems to remember the command was called `do' ..
02:06:17 <ski> (er, `redo', i meant)
02:06:31 <kmc> @do x >> y
02:06:31 <lambdabot> do { x; y}
02:06:33 <mauke> @do 1
02:06:34 <lambdabot> 1
02:06:34 <kmc> @do x >>= y
02:06:35 <lambdabot> do { a <- x; y a}
02:06:37 <ski> @do e
02:06:37 <lambdabot> e
02:06:38 <ski> :(
02:06:44 <kmc> @vixen do e
02:06:44 <lambdabot> ouch! I just spilt hot coffee on myself!
02:06:49 <mauke> @do a >>= b
02:06:49 <lambdabot> do { c <- a; b c}
02:07:25 <adu> copumpkin: so are you saying (deftype ... (satisfies ...)) does allow the definition of dependent types (at runtime)?
02:07:29 <mauke> @. pl . undo do a >>= b
02:07:29 <lambdabot> b =<< a
02:07:46 <ski> @do (runKleisli . first . Kleisli) hGetLine
02:07:46 <kmc> adu, is the idea of "dependent types" meaningful in a dynamically-typed system?
02:07:46 <lambdabot> (runKleisli . first . Kleisli) hGetLine
02:07:59 <adu> kmc: yes
02:08:04 <copumpkin> adu: I don't consider runtime checking of conditions to be dependent types. But then again, I don't consider dynamic typing to be a type system
02:08:09 <mauke> are lisp types meaningful?
02:08:14 <kmc> then Python is dependently typed
02:08:30 <mauke> I mean, what can you do with them?
02:08:54 <luite> @do a >=> b
02:08:55 <lambdabot> a >=> b
02:08:56 <adu> mauke: you can infer them, you can check them, etc.
02:08:56 <kmc> i think it's a bit extreme to say that "dynamic typing is not typing".  but it's a reasonable opinion to say that only static type systems are interesting
02:09:12 <kmc> do you really "infer" dynamic types?
02:09:19 <adu> kmc: why?
02:09:26 <kmc> why which?
02:09:26 <mauke> adu: how do you check them if there are no type annotations?
02:09:36 <juhp> hmm
02:09:40 <kmc> i don't hold this opinion
02:09:53 <kmc> but i think it's reasonable -- everyone has to choose what things they're interested in studying
02:09:54 <juhp> dcoutts: dunno if this is due to p_dyn: http://koji.fedoraproject.org/koji/getfile?taskID=1885634&name=build.log&offset=-5000
02:09:56 <copumpkin> THAT OPINION IS OBJECTIVELY WRONG
02:10:05 <juhp> guess i have to try a local test build
02:10:11 <ski> adu : how do you check e.g. `f : forall x : N. exists y : N. ProperDivisorOf (y,x+2)' at run-time ?
02:10:24 <adu> yes, if a pojo has an internal property __type__ set to "MissleLauncher" one can INFER that it is of type MissleLauncher :)
02:10:37 <copumpkin> I think you can call dynamic types a type system, but I think it just devalues the concept, as it has none of the challenges or benefits of a static type system
02:10:47 <dcoutts> juhp: "file not recognized: File truncated" doesn't look related.
02:11:00 <kmc> hmm i do not think that idea of "inference" is meaningfully similar to HM-style type inference
02:11:02 <copumpkin> dynamic types are just tags
02:11:07 <juhp> dcoutts: right - it doesn't look good either ;) :)
02:11:10 <kmc> copumpkin, but you do gain the benefits of a safe type system
02:11:25 <copumpkin> you don't get silent corruption
02:11:26 <juhp> perhaps I should retry
02:11:34 <mauke> kmc, copumpkin: unless you're using lisp
02:11:51 <ski> (which lisp ?)
02:11:56 <mauke> common lisp
02:12:18 <kmc> making programs fail early, loudly, and deterministically is a big deal
02:12:23 <kmc> making them fail at compile time is even better
02:12:45 <mauke> CL lets you declare types for variables
02:13:06 <mauke> if the actual runtime value doesn't match the declared type, the behavior is undefined
02:13:08 <adu> copumpkin: I guess i'm starting to look at type systems through the eyes of LLVM, where compile-time type inference might happen at run-time
02:13:14 <copumpkin> kmc: but there's no difference between associating a rule with a tag and calling it a dependent type, and just adding an assertion when you set a value of that type
02:14:48 <kmc> copumpkin, sure
02:15:10 <copumpkin> which is why I say, sure you can call it that
02:15:16 <copumpkin> but it doesn't really add anything to the discussion
02:15:18 <kmc> adu, not sure what you mean, but i think LLVM is far too low a level to see most of the interesting things going on in type systems
02:15:47 <kmc> of course you can have a staged / dynamic / just-in-time compiler, which still does static checking on code before running it
02:15:59 <wferi> Hi! What's now the preferred way to parse SNMP messages in Haskell?
02:16:26 <adu> well, then replace LLVM with GHC and it the rest of my statement makes sense
02:16:36 <pozic> Is there a function to get the file size of a FilePath?
02:16:44 <wferi> The ASN1 package on Hackage has some BER pieces, but I'm confused about it's present state.
02:17:02 <wferi> The darcs version is name PER, for example...
02:17:10 <mauke> @hoogle filesize
02:17:11 <lambdabot> System.IO hFileSize :: Handle -> IO Integer
02:17:11 <lambdabot> System.IO hSetFileSize :: Handle -> Integer -> IO ()
02:17:12 <kmc> adu, sort of
02:17:28 <ski> ("PER" meaning "Partial Equivalent Relation" ?)
02:17:35 <kmc> adu, as a statement about staged compilation / checking rather than dynamic types
02:17:37 <wferi> And the NewBinary dependency is somewhat disturbing.
02:17:45 <wferi> PER as Packaged Encoding Rules
02:17:54 <kmc> you can pass Haskell code to hint at runtime; that code is statically checked
02:18:02 <wferi> ski: Or Packed, rather
02:18:16 <adu> kmc: what I mean is taking the RULES syntax from GHC and the runtime optimization from LLVM, and i can see maybe applying GHC rules at runtime (not only at compiletime)
02:18:26 <wferi> it's a "subset" of BER.
02:18:27 <konnertz> hi
02:18:27 <kmc> ah, now that's a very interesting idea :)
02:18:58 <konnertz> :t "huoihuio"
02:18:59 <lambdabot> [Char]
02:19:15 <konnertz> ah :)
02:19:30 <copumpkin> RULES don't really have much to do with types though
02:19:36 <wferi> Isn't Dominic Steinitz (the asn1 maintainer) present here?
02:19:42 <Alpounet> @index toU
02:19:42 <lambdabot> bzzt
02:20:14 <adu> copumpkin: of course they do
02:20:44 <adu> copumpkin: maybe not in GHC, but the general idea has everything to do with types
02:21:08 <copumpkin> ah, yeah, I was talking about ghc
02:22:14 <adu> like if rules were applied at the type level as well, then one could make the rule Map Int a = IntMap a, or the like
02:23:24 <copumpkin> that would be nice, but we'd need a way of mapping all the functions on that type too
02:23:53 <adu> true
02:24:12 <copumpkin> now if Map were a type function :)
02:24:20 <adu> lol
02:24:31 <copumpkin> data family Map k v :: *
02:24:41 <copumpkin> data instance Map Int v = IntMap v
02:25:03 <copumpkin> but then we can't write the generic catch-all instance :(
02:25:12 <adu> :(
02:25:16 <Alpounet> wow
02:25:24 <Alpounet> this actually is template specialisation :-p
02:25:52 <adu> I thought data families were written differently...
02:25:58 <copumpkin> oh true
02:26:07 <copumpkin> I really meant type family
02:26:29 <copumpkin> but if you were actually doing something like this, you'd probably use a data family and write the wrappers yourself
02:26:36 <copumpkin> which would make everything work nicely etc. etc.
02:28:09 <kmc> copumpkin, also, i don't think the ideas of dependent typing map to even run-time checks in the context of a dynamic type system.  for example it's quite easy to write a Python function which returns a type, but it's not clear (to me) that this allows you to attach assertion properties to your type tags
02:28:35 <kmc> i have not thought very much about this
02:28:55 <copumpkin> you could do it in ruby, if you made sure your functions actually checked the assertions
02:29:04 <copumpkin> haven't done enough python to know, but I doubt it's very different
02:29:21 <kmc> it seems like you would just use smart constructors, which doesn't have much to do with types that depend on values
02:30:47 <kmc> type(type) is type
02:31:41 <adu> kmc: well, I think it really just comes down to everything that can be done at compiletime can also be done at runtime, if you keep enough of the source around
02:31:46 <kmc> i think i will tell people that Python's "type" has an infinite kind ;)
02:32:10 <kmc> adu, yes
02:32:34 <adu> also, theres omtype in OpenMath's ECC. type(omtype) = undefined
02:32:36 <copumpkin> in the end it's turing complete :P
02:33:12 <kmc> is that "om" for "omega"?
02:33:17 <adu> om = openmath
02:33:20 <kmc> oh :/
02:33:44 <copumpkin> lol
02:34:50 <adu> I've been noticing that a lot of openmath stuff is based on algebraic datatypes
02:35:23 <adu> but the ECC type system doesn't have tagged unions...
02:35:33 <copumpkin> ECC?
02:35:37 <danblick> oh, hmm. project euler had me run into a problem I did not forsee... stack overflow. http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14831#a14831 ; i guess its clear i'm not doing proper tail recursion
02:35:44 <adu> ECC = extended calculus of constructions
02:36:03 <copumpkin> oh
02:36:13 <kmc> danblick, this is not related to your problem but... you really should use several equations for "primesUpTo"
02:36:23 <kmc> rather than nested if-then-else that marches off the screen
02:36:34 <adu> ECC has tuples and functions
02:36:34 <kmc> primesUpTo n | (n < 2) = []
02:36:37 <danblick> kmc, suggestion well-taken
02:36:38 <kmc> primesUpTo 2 = [2]
02:36:40 <kmc> etc.
02:36:54 <kmc> it can't be tail-recursive at all
02:37:01 <copumpkin> adu: dependent tuples/sums?
02:37:20 <adu> huh?
02:37:26 <kmc> (primesUpTo n) does not reduce to (primesUpTo k) for some k
02:37:44 <copumpkin> adu: by tuples, do you mean dependent sums? sigma types, that is?
02:37:56 <copumpkin> or just plain ones
02:38:18 <kmc> danblick, after the call to primesUpTo (n - 1) returns, there is still work to be done -- the conditional, another call to hasDivisorIn, possibly a list append
02:38:23 <adu> copumpkin: yes, in fact ECC calls it SigmaType
02:38:35 <kmc> oh, also, ([n] ++ l) is (n : l)
02:38:37 <Twey> danblick: Try compiling with -O3 before you start optimising
02:38:45 <Twey> GHC can optimise a lot of stack overflows away
02:38:55 <Twey> (or was it -O2?  I think it's -O2, sorry.  I forget.)
02:39:06 <Saizan> however you don't need "tail recursion" here
02:39:06 <copumpkin> adu: so disjoint unions are easy to make using those
02:39:20 <adu> copumpkin: really?
02:39:44 <Saizan> or maybe you do? however i suspect that "sum" at the end.
02:40:02 <adu> http://www.openmath.org/cd/ecc.xhtml#SigmaType
02:40:21 <copumpkin> adu: data Tag = Left | Right; Either a b = Sigma Tag (\x -> case x of Left -> a; Right -> b)
02:40:42 <Saizan> that's a weird way to get the primes, and quite inefficient i'd say
02:40:43 <adu> copumpkin: right, but you can't do (Left | Right) in ECC
02:41:10 <danblick> ok, so my take away is - along with the helpful language idiom tips - it's a conceptual flaw on my part "don't attempt recursion on a non-recursive function definition"?
02:41:41 <adu> copumpkin: oh, well I guess you can do Left :: Tag, Right :: Tag
02:41:53 <adu> n/m
02:42:12 <adu> :)
02:42:13 <Saizan> danblick: i don't get the quoted sentence
02:42:24 * copumpkin has yet to actually read about ECC :) I have his book lying around but not the prerequisite knowledge to read it
02:43:03 <adu> copumpkin: I don't know anything about it except what I've learned from this paper:
02:43:04 <adu> http://www.openmath.org/standard/ecc.pdf
02:43:04 <Axman6> jlouis: you around by any chance?
02:43:43 * hackagebot upload: unicode-symbols 0.1.1.2 - Unicode alternatives for common functions and operators (RoelVanDijk)
02:43:45 <Saizan> danblick: this, and the links, are a good read to understand the situation http://www.haskell.org/haskellwiki/Stack_overflow
02:43:56 <danblick> Saizan: thanks
02:44:16 <adu> copumpkin: what prerequisites?
02:44:19 <Saizan> danblick: in particular what "tail recursive" or better, what doesn't use stack while recursing, is quite different in a lazy language
02:44:22 <Baughn> Saizan: Hm. Maybe I should add a section on GHC's evaluation model to that page?
02:44:30 <copumpkin> adu: lots more type theory (for Luo's book)
02:44:58 <copumpkin> that pdf you linked to doesn't look too heavy-duty
02:45:22 <adu> "Program Specification and Data Refinement in Type Theory."?
02:47:18 <copumpkin> computation and reasoning: a type theory for computer science
02:47:18 <copumpkin> I think
02:47:35 <copumpkin> it's on another continent right now
02:47:36 <Saizan> Baughn: yes, i think it'd help
02:49:15 <simk318> hi, i have some datatype as data Expr = Num Double  | Add Expr Expr  | Mul Expr Expr and want to generate random expression when click on a button how should i precede this any suggestions ?
02:49:41 <Axman6> rgh, why doesn't Array-0.3.0.0 have Data.Array.Diff?
02:50:37 <adu> simk318: template Haskell?
02:51:02 <Baughn> adu: I very much doubt it
02:51:10 <Axman6> simk318: QuickCheck's arbitrary class can do it
02:51:21 <adu> ya, qc would be better
02:51:31 <Baughn> simk318: Start by making a function that does it. The "click on a button" bit can be added later, or preferably never.
02:51:43 <Baughn> And yes, arbitrary is best
02:52:01 <simk318> but i get Gen type mismatch error
02:52:32 <simk318> like "Couldn't match expected type `Expr' against inferred type `Gen Expr'
02:52:32 <simk318> "
02:53:00 <Axman6> simk318: we're going to need a hell of a lot more info from you to be able to help you :)
02:53:15 <kmc> Baughn, haha
02:54:30 <simk318> ok fine will QuickCheck arbitrary may solve the problem ?
02:55:51 <Axman6> maybe, depends on what your problem is
02:57:21 <Saizan> arbitrary won't do this automatically for you anyhow, you've to make an instance Arbitrary Expr, but it's not hard to write it
02:58:09 <Baughn> $(deriveTH makeArbitrary ''Expr)
02:58:29 <Alpounet> @index (&&&)
02:58:29 <lambdabot> Control.Arrow
02:58:43 <Saizan> simk318: and to extract an Expr out of a Gen Expr you can use "generate"
02:58:52 <Saizan> generate :: Int -> StdGen -> Gen a -> a
02:59:31 <simk318> ok
03:00:59 <ski> @hoogle RandomGen g => Int -> g -> Gen a -> (a,g)
03:01:00 <lambdabot> Network.BufferType buf_splitAt :: BufferOp a -> Int -> a -> (a, a)
03:01:00 <lambdabot> Data.Generics.Twins gmapAccumQr :: Data d => (r' -> r -> r) -> r -> (a -> e -> (a, r')) -> a -> d -> (a, r)
03:01:00 <lambdabot> Data.Generics.Twins gmapAccumQl :: Data d => (r -> r' -> r) -> r -> (a -> e -> (a, r')) -> a -> d -> (a, r)
03:01:46 <Baughn> Saizan: A function that is sadly missing in quickcheck-2
03:02:02 <simk318> ya i could not find either
03:02:08 <Baughn> You use unGen instead.
03:02:18 <kmc> i like how hoogle will come up with comedy options
03:02:21 <kmc> if it's stumped
03:02:55 <Baughn> I like how my cryptographic PRNG is five times faster than System.Random. ;)
03:03:04 <Alpounet> @pl \x y -> compare (snd y) (snd x)
03:03:04 <lambdabot> flip (compare . snd) . snd
03:03:12 <kmc> most languages have terrible built-in PRNGs
03:03:24 <Axman6> Alpounet: use Data.Ord's comparing function
03:03:26 <Axman6> :t comparing
03:03:27 <lambdabot> forall b a. (Ord a) => (b -> a) -> b -> b -> Ordering
03:03:36 <Axman6> :t comparing snd
03:03:37 <lambdabot> forall a b. (Ord b) => (a, b) -> (a, b) -> Ordering
03:03:50 <Alpounet> oh yeah forgot about it
03:03:51 <Alpounet> thanks
03:04:13 <therp> the biggest design mistake of Haskell was the absence of the equivalent of "::" as in CL. grr.
03:04:34 <therp> :: = we do not care about the export definition of a module, give me the content.
03:04:35 <ski> therp : where `::' in CL does ?
03:05:04 <Baughn> therp: No, having that would hobble the optimizer
03:05:12 <therp> I find the GHC totally unusable for me purposes and I find myself copying whole source files simply because I can not modify that
03:05:31 <therp> Baughn: I don't see any reason for that.
03:05:48 <Baughn> therp: What are you doing to need that kind of access?
03:05:54 <Baughn> I've never felt the need for such
03:05:59 <kmc> i have
03:06:00 <therp> also this is falsified because there is enough of optimizers in Lisp and they still can give me that feature
03:06:25 <kmc> sometimes you want to get the constructor of an abstract type in order to do dodgy things to it
03:06:31 <Baughn> kmc: I tend to fix the original instead. Then send patches. They usually end up accepted.
03:06:35 <kmc> i wanted this  when implementing rank-3 callCC
03:06:37 <therp> Baughn: I want to construct my own HsCompile object. HsCompile(..) is exported from the GHC, but none of the stuff that is usually made of, such as genericHscCompile and friends
03:06:46 <kmc> iirc ContT is exported but Cont isn't
03:07:07 <kmc> could be wrong
03:07:15 <therp> Baughn: this happens to me all the time with GHC. and it simply annoys me to the point where I give up
03:07:16 <Saizan> ?type Cont
03:07:17 <lambdabot> forall a r. ((a -> r) -> r) -> Cont r a
03:07:54 <Peaker> kmc: what's a rank-3 callCC?
03:08:00 <Baughn> therp: Go ask the GHC developers why it isn't exported. You may find that they had a good reason.
03:08:02 <Peaker> kmc: as opposed to a callCC?
03:08:02 <Saizan> therp: the ghc "api" is quite experimental, i'd think they'd accept patches
03:08:03 <kmc> :t callCC
03:08:05 <lambdabot> forall a (m :: * -> *) b. (MonadCont m) => ((a -> m b) -> m a) -> m a
03:08:19 <kmc> Peaker, for full generality, the "forall b" should be moved to the innermost function type
03:08:29 <kmc> that makes the overall type a rank-3 type, i believe
03:08:35 <kmc> hence not Haskell 98, but supported by GHC
03:08:43 <ski> therp : btw, GHCi seems to allow access of unexported entities in modules loaded from source
03:08:54 <kmc> if you want to save continuations in a datastructure you pass around, and use them in various and sundry places, this is useful
03:09:10 <Axman6> anyone know what happened to Data.Array.Diff?
03:09:13 <Peaker> kmc: I see
03:09:16 <therp> I don't have time to wait full release cycles for such trivial fixes. I want to override them with a hack, and later converge on the clean method if the fix is actually released.
03:09:31 <ivanm> Axman6: canned in 6.12
03:09:31 <Peaker> therp: hold a repo fork then
03:09:32 <Axman6> ghci
03:09:35 <Axman6> whoops
03:09:39 <ivanm> Axman6: IIRC, it was made an external library
03:09:41 <kmc> Prelude>
03:09:43 <ivanm> see the release notes
03:09:44 <Axman6> urgh
03:09:57 <ivanm> Axman6: because it needed another library IIRC
03:09:59 <kmc> Not in scope: `urgh'
03:10:00 <therp> Peaker: I guess my users won't get a fork shipped by their distros. that approach doesn't work socially :/)
03:10:17 <ski> Peaker : .. presumably `forall a. ((forall b. a -> m b) -> m a) -> m a'
03:11:36 <malosh> Hi. Can anyone give me an example use of Data.Data.gfoldl, for instance on a list ?
03:11:58 <kmc> malosh, did you read the SYB paper?
03:11:59 <kmc> @where SYB
03:12:00 <lambdabot> http://www.cs.vu.nl/boilerplate
03:12:03 <malosh> yes
03:12:26 <malosh> the examples there do not compile. I get an "inferred type is less polymorphic than expected"  error
03:12:37 <kmc> :/
03:12:46 <kmc> :t gfoldl
03:12:47 <lambdabot> forall (c :: * -> *) a. (Data a) => (forall d b. (Data d) => c (d -> b) -> d -> c b) -> (forall g. g -> c g) -> a -> c a
03:12:53 <malosh> my question was : what the fuck did I miss ?
03:13:19 <malosh> > main=print $ gfoldl ($) id [1,2,3]
03:13:20 <lambdabot>   <no location info>: parse error on input `='
03:13:33 <malosh> > print $ gfoldl ($) id [1,2,3]
03:13:34 <lambdabot>   Inferred type is less polymorphic than expected
03:13:34 <lambdabot>    Quantified type variable...
03:13:44 <kmc> does ($) have the required polymorphic type?
03:13:44 <ski> @type Data.Data.gfoldl (\cf d -> fmap ($ d) cf) (\x -> Node x []) "abc"  -- probably useless example
03:13:45 <lambdabot> Tree [Char]
03:14:08 <EvilTerran> ?type gfoldl id id
03:14:09 <lambdabot>     Inferred type is less polymorphic than expected
03:14:09 <lambdabot>       Quantified type variable `d' escapes
03:14:09 <lambdabot>     In the first argument of `gfoldl', namely `id'
03:14:13 <malosh> :t ($)
03:14:14 <lambdabot> forall a b. (a -> b) -> a -> b
03:14:19 <EvilTerran> ah, i see the problem
03:14:26 <Saizan> 'c' and 'g'
03:14:34 <Saizan> ehm, no only 'c'
03:14:49 <EvilTerran> things escape the existential quantification; that'd be d and/or b, shurely?
03:15:03 <ski> @type Data.Data.gfoldl (\cf d -> fmap ($ d) cf) Identity "abc"  -- more useless example
03:15:04 <lambdabot> Identity [Char]
03:15:05 <malosh> d escapes
03:15:14 <Saizan> EvilTerran: only because you try to unify them with a type containing 'c'
03:15:31 <EvilTerran> oh, that's what you mean. i see now :)
03:16:03 <ski> EvilTerran : the problem there is that `c' can't be instantiated to `id'
03:16:22 <Saizan> typelevel id
03:16:27 <ski> *nod*
03:16:47 <adu> hi ski!
03:16:59 <ski> er .. hello ?
03:17:31 <adu> we had a chat about the Y combinator ... about a year ago ... you probably don't remember
03:18:02 <Axman6> heh
03:18:34 * ski seems to recognize the nick, at least
03:18:50 <adu> :)
03:20:56 * therp .oO("Y combinator = small talk")
03:21:39 <weakish> Which one is preferred in coding .lhs? #1 >code (immediate followed by code)  #2 > code(followed by a whitespace)
03:21:44 * ski agrees with therp
03:22:01 <Jafet> :t (\f x -> f f x)
03:22:02 <lambdabot>     Occurs check: cannot construct the infinite type: t = t -> t1 -> t2
03:22:02 <lambdabot>     Probable cause: `f' is applied to too many arguments
03:22:02 <lambdabot>     In the expression: f f x
03:22:07 <Botje> second looks nicer
03:22:26 * ski would go with #2, just out of impulse .. no idea what's generally preferred, though
03:24:14 <dibblego> @pl \t -> (k t, v t) -- why doesn't this give (&&&) ?
03:24:15 <lambdabot> liftM2 (,) k v
03:24:32 <ivanm> @type (&&&)
03:24:33 <lambdabot> forall (a :: * -> * -> *) b c c'. (Arrow a) => a b c -> a b c' -> a b (c, c')
03:24:41 <ivanm> @type \ t -> (k t, v t)
03:24:43 <lambdabot>     Couldn't match expected type `t -> t1' against inferred type `Expr'
03:24:43 <lambdabot>     In the expression: k t
03:24:43 <lambdabot>     In the expression: (k t, v t)
03:24:43 <Twey>  I'd prefer the second; I believe it to be the dominant style, too
03:24:49 <ivanm> @type \ k v t -> (k t, v t)
03:24:51 <lambdabot> forall t t1 t2. (t -> t1) -> (t -> t2) -> t -> (t1, t2)
03:24:52 <ivanm> @pl \ k v t -> (k t, v t)
03:24:52 <lambdabot> liftM2 (,)
03:25:00 <dibblego> I hate it
03:25:32 <dibblego> bah
03:25:33 <copumpkin> dibblego: I think it just doesn't know about Control.Arrow
03:25:39 <ivanm> that's probably it
03:25:48 <dibblego> but it once did, I am certain
03:25:55 <Twey> Aye
03:25:55 <copumpkin> you could probably modify its rules so it does
03:26:18 <ivanm> @pl \ f g (a,b) -> (f a, g b)
03:26:18 <lambdabot> flip flip snd . (ap .) . flip flip fst . ((.) .) . flip . (((.) . (,)) .)
03:26:19 <dibblego> but I would be suspicious of why it was modified in the first place for removal
03:26:22 <ivanm> heh
03:27:28 <ivanm> dibblego: possibly it existed in a repo that was lost when lispy's machine went down or something... >_>
03:27:40 <ivanm> or maybe Control.Arrow doesn't fit in with Caleskell? :p
03:28:32 <dibblego> it's a shame; others could learn from it
03:33:07 <jlouis> Axman6: yes
03:33:15 <Axman6> o/
03:34:09 <jlouis> Axman6: my RTT is around 50 minutes it seems, not bad
03:34:34 <Axman6> i've started some initial hacking on your haskell-torrent code. got it working with 6.12.1 (by taking the HCodecs builder and parser code and putting it directly into codebase, thus avoiding all the pain of getting HCodecs installed)
03:34:57 <jlouis> oh, cool!
03:35:14 <jlouis> I definitely agree that the parser and builder should have been split from HCodecs
03:35:15 <Axman6> since it's BSD3 licenced code, i couldn't see a problem with doing that
03:35:32 <Axman6> me too :)
03:35:39 <jlouis> It is actually BSD2 licensed, but cabal doesn't allow for that :)
03:35:56 <weakish> Well, google code search file:\.lhs$ >import gives 171 results and "> import" gives 3k.
03:36:16 <jlouis> Axman6: any bumps in that conversion_
03:36:18 <jlouis> ?
03:36:26 <Axman6> surprisingly no
03:36:27 <jlouis> To GHC 6.12.1 I mean
03:36:52 <jlouis> oh, that surprises me as well.
03:36:58 <Axman6> just dropped in the builder/parser code and removed the depednancy on HCodecs
03:37:17 <jlouis> You are using the recent cabalized variant, no?
03:37:29 <jlouis> I built some bad cabal-stuff yesterday that needs work
03:37:51 <jlouis> i.e., that was my first cabal package
03:37:52 <Axman6> i'm using whatever's on git
03:38:29 <jlouis> check, then you should have the most recent code
03:39:10 <Axman6> yup
03:39:16 <Axman6> trying to figure out git now...
03:39:37 <jlouis> any darcs knowledge?
03:39:44 <Axman6> sure
03:39:56 <jlouis> darcs record == git add --patch
03:40:09 <jlouis> will probably save you some headache :)
03:40:57 <ivanm> what else do you add in git if not a patch?
03:41:15 <jlouis> anyway, the simplest thing is to use `git format patch` to produce a patch-set and mail it to me
03:41:28 <jlouis> ivanm: the whole file you add
03:41:41 <ivanm> ahh
03:41:44 <jlouis> sometimes you want a single hunk only
03:41:59 <ahf> format-patch :P
03:42:07 <jlouis> thanks ahf
03:42:13 <ahf> very useful, but np :P
03:44:21 <Axman6> jlouis: how do i make and send a patch? i already did git add on the files (i didn't use --patch)
03:45:12 <jlouis> commit it
03:45:44 <jlouis> then git format-patch origin/master IIRC. ahf will probably correct me now :)
03:46:23 <Axman6> 3... 2.. 1. ahf
03:46:34 <jlouis> haha
03:47:30 <Axman6> i made one change you probably won't like, but i dislike it when pointfree code makes it harder to read what's going on, so i changed push (Queue front back) = Queue front . (: back) to push (Queue front back) x = Queue front (x:back)
03:47:56 <jlouis> Well, adding something prepares it in the index for the next commit, so running git commit -m <commit-msg> should commit it to your current branch (master)
03:48:19 <mmorrow> :o
03:48:32 <jlouis> then git format-patch origin/master..master should prepare patches on the path from origin/master to master in the repository
03:48:46 * mmorrow thinks the original is nicer (also, prettier)
03:48:50 <jlouis> Axman6: that change was actaully hlint
03:48:57 <Axman6> heh
03:49:03 <Axman6> yeah there's a lot in hlint i don't like
03:49:39 <jlouis> I just needed a queue, so I handwrote the classic amortized O(1) variant
03:50:03 <Axman6> i've never seen a queue implemented in haskell before, and quite liked that one
03:50:15 * Saizan sticks to git commit -a -m 'message' or git commit -m 'message' -- FILES
03:50:28 <mmorrow> ([a],[a]) ftw
03:50:43 <mmorrow> (or Queue [a] [a] ;)
03:52:04 <ski> (`Queue :: * -> * -> *' ?)
03:52:06 <jlouis> Axman6: to prove the amortized bound you tie a credit invariant to the back stack of the queue. Add one credit on insert, remove all credits on the reverse. Credits are never going to be less than 0. Bam
03:52:58 <Axman6> anything wrong with using Seq as a queue?
03:53:11 <Axman6> this probably works just as well as Seq anyway
03:53:18 <malosh> Still don't understand SYB. What it the purpose of asking a (forall a b. c (d->b)->a->b) function in gfoldl ? Could'nt life be as simple as list foldl, that accepts a (a->b->a) for all a and b ?
03:53:19 <jlouis> Data.Seq?
03:53:41 <Axman6> yeah
03:53:42 <Saizan> malosh: the paper provides the motivation
03:54:20 <ivanm> Seq is rather cool
03:55:13 <jlouis> Seq is cool because it is universal. It usually yields good bounds and is one of my favorite drop-ins
03:55:18 <copumpkin_> malosh: then it wouldn't be generic. a list fold only has those parameters because of the underlying structure of a list
03:55:52 <merijn> GHC has make-like functionality built in? "If ghc notices that it has already compiled a source file into an object file, it will only recompile the source file if we've modified it."
03:56:08 <malosh> Ah ok, what I do not understand now is the difference between the Foldable typeclass and SYB
03:56:30 <Saizan> malosh: SYB is much more general
03:56:35 <jlouis> Axman6: any luck in the git battle?
03:56:35 * ivanm has never used Syb, but wouldn't have thought there would be a connection
03:56:40 <Saizan> merijn: yeah
03:57:07 <Axman6> jlouis: not really, i still don't how i can send a patch after doing a git commit... or ... yeah really confused >_<
03:57:09 <Saizan> ivanm: you can probably write a generic foldMap using SYB
03:57:12 <merijn> Saizan: Nice
03:57:50 <ivanm> Saizan: hmmmm....
03:57:56 <jlouis> Axman6: run `git format-patch origin/master..master`
03:58:10 <jlouis> it should generate a file 0001-.....patch
03:58:19 <Axman6> ah, yep
03:58:35 <Axman6> that is one messed up looking command
03:59:05 <Saizan> if you're on github the usual way is to fork the repo and let the others pull from you, i think
03:59:19 <Axman6> jlouis: then do i need to email that to you>
03:59:20 <copumpkin_> yep
03:59:21 <Axman6> ?*
03:59:21 <lambdabot> Maybe you meant: . ? @ v
03:59:34 <jlouis> format-patch prepares email patches, origin/master..master is a designation that says: Give me the commits from the tag origin/master to the tag master
03:59:46 <jlouis> Axman6: yeah, check AUTHORS
03:59:46 <copumpkin_> seems easier to do this the regular way
03:59:53 <Axman6> ok, thanks
04:00:00 * Axman6 dislikes git even more now
04:00:06 <jlouis> I am also happy with pulling from people on github
04:00:18 <copumpkin_> Axman6: it'd be a lot easier if you did it the traditional git way :P
04:00:18 <jlouis> or any repo that is
04:00:29 <Axman6> copumpkin_: which is?
04:00:39 <copumpkin_> you fork the repo, and just push to your own repo
04:00:44 <copumpkin_> tell the maintainer to pull/fetch from your repo
04:00:47 <Axman6> hmm
04:00:52 <copumpkin_> and avoid any explicit mention of patches anywhere
04:00:56 <Axman6> maybe i could do that instead
04:01:18 <copumpkin_> github automates some of that
04:01:23 <jlouis> mm, yes
04:01:37 <copumpkin_> and provides step-by-step instructions for the rest of it
04:02:05 <Axman6> hmm, well, hitting the fork button gave me a login screen, then a completely blank page
04:02:16 <copumpkin_> you have an account?
04:02:44 <Axman6> yes
04:02:46 <sinelaw> ivanm, you're the author/maintainer of Graphviz?
04:02:54 <Axman6> ah ha, there we go
04:03:02 <jlouis> \o/
04:03:12 <Axman6> only took 4 attempts
04:04:19 <geoaxis> hey people, I want an example of drawing a square in gtk2hs, some thing like in paint
04:04:21 <Axman6> ok, so, i have a fork now... what do i do from there?
04:04:28 <ivanm> sinelaw: yup
04:04:41 <copumpkin_> Axman6: clone that locally, make the changes, commit, push back to your version
04:04:48 <copumpkin_> then tell jlouis to pull from your fork
04:05:07 <sinelaw> ivanm, first of all, cool.
04:05:19 <ivanm> \o/
04:05:26 <sinelaw> ivanm, i'm working on a graphical ui for editing graphs
04:05:35 <ivanm> nice!
04:05:54 <sinelaw> ivanm, this is my old pythonic prototype: http://www.youtube.com/watch?v=RT87JfTYIvo
04:06:19 <kuribas> Which search structure has efficient update (memory)?
04:06:23 <Axman6> copumpkin_: how can i apply the patch i made earlier first?
04:06:33 <ivanm> kuribas: a tree? *shrug*
04:06:39 <ivanm> probably depends on what you're going to be doing with it
04:06:48 <copumpkin_> kuribas: without more details, I'm going to say a list ;)
04:07:00 <ivanm> sinelaw: the CHP guy had a demo of a semi GUI graph thingy IIRC...
04:07:15 <sinelaw> ivanm, CHP guy?
04:07:21 <jlouis> Neil Brown
04:07:30 <ivanm> I'm not sure how well graphviz will work for your app though, since you'd have to do all the rendering yourself
04:07:35 <ivanm> jlouis: yeah, that's the one
04:07:49 <sinelaw> ivanm, that demo i pasted used graphviz behind the scenes
04:07:55 <sinelaw> i did do the rendering myself
04:08:03 <ivanm> *nod*
04:08:06 <kuribas> I have a set of properties, which regularly change, depending of the context, and I need efficient searching of the properties, and efficient insertion.
04:08:17 <Peaker> sinelaw: where are the discoverable key bindings? :)
04:08:21 <ivanm> kuribas: depending on what you're doing, a bloom filter might also suffice
04:08:29 <sinelaw> Peaker, that was an older version
04:08:35 <copumpkin_> kuribas: Data.Map maybe?
04:08:40 <kuribas> ivanm: Ah, that sounds new to me...
04:08:58 <ivanm> wikipedia has an article on it, RWH has a chapter on it
04:09:00 <copumpkin_> a bloom filter is a probabilistic set
04:09:01 <sinelaw> ivanm, anyway my question is how to find the size of the graph
04:09:08 <copumpkin_> it sounds like you want a map
04:09:14 <ivanm> IIRC, the first haskell implementation was by ketil
04:09:18 <sinelaw> i need to scale/normalize the coordinates returned from Data.Graphviz
04:09:31 <ivanm> kuribas: basically, they're used when its OK to have some false positives (but no false negatives)
04:09:35 <ivanm> e.g. spellchecker
04:09:54 <ivanm> sinelaw: hmmm.... you can probably do it carefully
04:09:56 <Axman6> jlouis: any idea how i can apply that patch i made earlier?
04:10:05 <kuribas> ivanm: No, I need to now exactly the value of the property...
04:10:20 <sinelaw> ivanm, doesn't dot return that?
04:10:27 <ane_> are the GHC web docs broken?
04:10:28 <ivanm> kuribas: then a bloom filter isn't for you
04:10:39 <ivanm> sinelaw: if you use on of the graphToGraph thingies or something, then yes
04:10:43 <ane_> hoogle results point to 404s
04:10:49 <ivanm> sinelaw: but the scaling part is up to you ;-)
04:10:58 <ivanm> ane_: yeah, links probably have to be updated for the new ghc
04:11:11 <jlouis> Axman6: the 0001... ?
04:11:15 <Axman6> yeah
04:11:16 * ivanm wonders if hoogle should just point to the version on hackage...
04:11:23 <jlouis> Axman6: cd to the new clone, git am 0001...
04:11:35 <Axman6> ok
04:11:44 <sinelaw> ivanm, where does graphToGraph place the global (graph) attributes?
04:12:06 <ivanm> sinelaw: in that case, it ignores them
04:12:07 <sinelaw> it returns a graph with attributes on nodes and edges
04:12:16 <sinelaw> ivanm, so who doesn't?
04:12:30 <ivanm> sinelaw: so, you'd want a DotGraph -> Graph converter?
04:12:38 * ivanm can probably do that...
04:12:55 <sinelaw> ivanm, i'd want a Graph -> (GraphAttributes, Graph)
04:13:00 <sinelaw> (pass through dot)
04:13:27 <Peaker> sinelaw: how's the new graph different?
04:13:50 <sinelaw> Peaker, right, mistake
04:13:55 <Axman6> jlouis: ok, my changes are on http://github.com/axman6/haskell-torrent
04:14:03 <sinelaw> ivanm, i'd want a Graph  a b-> (GraphAttributes, Graph (NodeAttr,a) (EdgeAttrs,b))
04:14:19 <jlouis> Axman6: cool, i'll pull as soon as my work-obligations are done :)
04:14:22 <ivanm> hmmmm......
04:14:30 <Axman6> no worries :)
04:14:49 <sinelaw> ivanm, just an addition of the GraphAttributes part, the rest already exists in the library
04:14:57 <ivanm> sinelaw: how about Graph -> DotGraph (via dot), then a DotGraph -> Graph (and you grab the global attributes yourself)
04:15:12 <sinelaw> ivanm, ok
04:15:13 <ivanm> because I was thinking of doing that kind of a split anyway
04:15:18 <copumpkin> Axman6: what's the 6?
04:15:20 <sinelaw> sure
04:15:38 <Axman6> copumpkin: 2*3 is 6
04:15:39 <Axman6> >_>
04:15:46 <copumpkin> lol
04:15:53 <ivanm> sinelaw: bigger question: when do you want it? :p
04:16:26 <copumpkin> 6 is also zeta(2) / pi^2
04:16:40 <sinelaw> ivanm, :)
04:16:40 <copumpkin> oh wait,
04:16:46 <copumpkin> pi^2 / zeta(2) :)
04:16:47 <sinelaw> ivanm, whenever you can
04:17:19 <ivanm> sinelaw: end of Jan OK?
04:17:29 <Peaker> awesome! ghc 6.12 added discard warnings about use of IO actions that are not IO ()
04:18:31 <sinelaw> ivanm, ok - do i have a way to do it in the meanwhile?
04:19:17 <ivanm> sinelaw: create your dot graph, and run it via Dot using the Commands module
04:19:33 <ivanm> there's no real -> graph conversion yet though, unless you copy/paste what I do in GraphViz
04:19:57 <sinelaw> ivanm, ok i'll take a look
04:20:00 <jlouis> Axman6: You want to kill off HCodecs from haskelltorrent.cabal as well?
04:20:14 <Axman6> i did, but apparently that didn't make it into the patch
04:20:36 <jlouis> perhaps there is a 0002...patch also? :)
04:21:30 <Axman6> well, i've changed it here locally, just trying to figure out again how to commit those changes and send them to my repo
04:21:58 <jlouis> git add haskelltorrent.cabal; git commit -m '...'; git push
04:22:13 <Axman6> ... git add doesn't add new files? >_<
04:22:21 <sinelaw> ivanm, i implemented something similar (but more limited) to your lib in Python
04:22:28 <jlouis> Axman6: no, it adds changes to the index
04:22:33 <Axman6> urgh
04:22:39 <sinelaw> ivanm, for my prototype. it was a pleasure to discover the work was already done in Haskell
04:22:56 <jlouis> Axman6: granted, they use a *completely* different terminlogy than most other out there
04:23:28 * Axman6 stabs linus
04:23:33 <jlouis> hah
04:24:14 <Axman6> ok, more changes committed
04:31:24 <Axman6> jlouis: any reason you chose to use the cml package over just using what's built in?
04:33:26 <kuribas> I get a message 'To many parameters for class `BreakPoint`': http://paste.lisp.org/display/92473
04:33:32 <ivanm> sinelaw: there was already a graphviz library for python IIRC
04:33:39 <kuribas> What should I use?
04:34:05 <sinelaw> ivanm, possibly :)
04:34:13 <sinelaw> maybe not when i did it
04:34:20 <sinelaw> (it was 4 years ago)
04:34:28 <ivanm> ahhh, fair enough then
04:34:57 <ivanm> AFAIK, I have the most advanced "bindings" of any language that I could find (not really bindings, more of a Dot code generator)
04:35:06 <ivanm> since I care about quotations, etc.
04:35:07 <ivanm> and parsing
04:35:22 <sinelaw> I'd like to find a clear and simple explanation of the algorithm they use in dot
04:35:33 <sinelaw> but i can't decipher it from their papers, not to mention the code
04:36:05 <kuribas> (I am writing a version of Knuth's paragraph breaking algorithm)
04:36:15 <ivanm> sinelaw: see the comment by one of the Graphviz deps on my blog (third comment): http://ivanmiljenovic.wordpress.com/2009/11/30/the-problems-with-graphviz/#comments
04:37:04 <merijn> If I want to create a higher order function which takes a function N arguments of type a and returns a value of type b (say for example a -> a -> b and a -> a -> a -> a -> b) is there any reasonable way to make my function work with all functions regardless of the value of N?
04:37:14 <sinelaw> ivanm, cool!
04:37:43 <jlouis> Axman6: I've done CML before in Standard ML
04:38:03 <Axman6> fair enough
04:38:16 <jlouis> Axman6: I toyed with the idea of using CHP and the low-level MVar primitive though
04:38:25 <Axman6> anything wrong with Chans?
04:38:39 <jlouis> Also, CML fits rather simply with the etorrent work I did
04:38:48 <jlouis> Nothing wrong with Chans
04:39:13 <epokal> merijn: is [a] -> b an option?
04:39:15 <aep> wow the ffi is cake. why did i even waste time with hscurses. heh
04:40:15 * hackagebot upload: hmatrix 0.7.2.1 - Linear algebra and numerical computations (AlbertoRuiz)
04:40:23 <Saizan_> merijn: it can be done but requires some pretty advanced typeclass hackery
04:40:24 <jlouis> Axman6: I like your WireProtocol changes
04:40:41 <Axman6> hooray :)
04:40:48 <Axman6> working on some changes to
04:40:49 <jlouis> Axman6: Also, could you add yourself to AUTHORS with an identity you wish to be recognized with?
04:40:52 <merijn> epokal: That will be hard, unless I can somehow figure out how long a list [a] the function expects
04:40:53 <Axman6> consoleP
04:40:58 <Axman6> sure
04:41:17 <byorgey> merijn: what would be the implementation of your function?
04:43:11 <ski> merijn : how would you apply the function, if you don't know how many argument it wants ?
04:43:31 <merijn> To make it more concrete: I'm doing an evolutionary computing class and our framework is rather crappy and bloated and I figured I'd take a stab at implementing something similar in Haskell as practice. My function would need to take a function that takes N parents from the current population and creates a new individual from that. The value of N is dependent on whatever function you're trying to use for creating new individuals
04:47:33 <calsaverini> :src (.)
04:47:43 <calsaverini> @src (.)
04:47:43 <lambdabot> (f . g) x = f (g x)
04:47:50 <mmorrow> merijn: i'd have the function take the /entire/ population, cull it, and return to you an (a,Pop)
04:48:01 <calsaverini> I'm having a pretty silly doubt.
04:48:05 <merijn> ski: That's what I'm trying to figure out :p I suppose I could just require an argument that specifies the value of N. But I figured I'd try and figure out if there's a nicer way
04:48:12 <mmorrow> where the `a' is whatever result it gives
04:48:15 <mmorrow> (if any)
04:48:20 <calsaverini> Generally f.g is different from f $ g, right?
04:48:26 <calsaverini> @src ($)
04:48:26 <lambdabot> f $ x = f x
04:48:31 <mmorrow> @src (.)
04:48:32 <lambdabot> (f . g) x = f (g x)
04:48:40 <ski> merijn : i mean, if a function of type `a -> a -> a -> b' is passed, how will you compute the three `a' values ?
04:48:45 <calsaverini> hummm
04:48:54 <calsaverini> I can't see the difference
04:49:05 <ski> merijn : maybe you want to use some `split :: a -> (a,a)' to generate arguments for extra arguments
04:49:09 <mmorrow> @type (+1) . (*2)
04:49:09 <lambdabot> forall a. (Num a) => a -> a
04:49:12 <mmorrow> @type (+1) $ (*2)
04:49:14 <lambdabot> forall a. (Num (a -> a), Num a) => a -> a
04:49:18 <mmorrow> bad example
04:49:24 <mmorrow> @type show . show . show
04:49:25 <lambdabot> forall a. (Show a) => a -> String
04:49:28 <ski> (merijn : my question was about the essential operational semantics, not how to encode it in haskell, btw)
04:49:31 <mmorrow> @type show $ show
04:49:32 <lambdabot> String
04:49:37 <Axman6> calsaverini: you can use $ anywhere you can use ., but not the other way around
04:49:39 <mmorrow> , show . show . show $ 42
04:49:40 <lunabot>  "\"\\\"42\\\"\""
04:49:44 <mmorrow> , show . show . show . show $ 42
04:49:45 <lunabot>  "\"\\\"\\\\\\\"42\\\\\\\"\\\"\""
04:49:46 <ski> (hm, s/operational //, i suppose)
04:50:00 <mmorrow> , foldr (.) id (replicate 8 show) 42
04:50:00 <Guest25597> Hi i am stuck i a problem and posted in forum can you guys give me some hints on this http://www.linuxquestions.org/blog/primenu-494688/2009/12/22/creating-a-random-expression-in-haskell-2504/
04:50:01 <lunabot>  luna: No instance for (GHC.Num.Num GHC.Base.String)
04:50:10 <ryo_hazuki> hey guys... anyone who has a minute left to help me fix a type error? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14833
04:50:12 <mmorrow> , foldr (.) id (replicate 8 show) "42"
04:50:13 <lunabot>  "\"\\\"\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\...
04:50:19 <mmorrow> , fix show
04:50:20 <lunabot>  "\"\\\"\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\...
04:50:41 <mmorrow> calsaverini: one way to see it is that (.) is analogous to unix pipes
04:50:46 <mmorrow> id is analogous to cat
04:51:01 <mmorrow> just the args to (.) are flipped wrt those of "|"
04:51:02 <merijn> ski: Normally you have a selection operator which returns an individual from the population (random uniform drawing, weighted random drawing, deterministic fitness based).
04:51:14 <mmorrow> cat | cat | cat
04:51:17 <mmorrow> id . id . id
04:51:33 <ski> > (sin $ cos) 3  -- Axman6
04:51:34 <mmorrow> wc -l | tac
04:51:34 <lambdabot>   No instance for (GHC.Float.Floating (a -> a))
04:51:34 <lambdabot>    arising from a use of `GHC...
04:51:38 <mmorrow> oops
04:51:45 <Axman6> ah, my bad
04:51:50 <mmorrow> cut -d' ' -f1 | tac
04:52:00 <kuribas> Am I forced to use parens instead of ($)? : http://paste.lisp.org/display/92473#1
04:52:09 <mmorrow> reverse . fmap (head . words)
04:52:23 <ski> merijn : so `a' is type for which you can generate random values for ?
04:52:39 <kuribas> "Couldn't match expected type `a1' against inferred type `a'"
04:53:24 <kuribas> It seems to work with parens...
04:53:40 <mmorrow> calsaverini: and ($) would be analogous (using the unix pipes analogy) to providing a cmd with a cmd-line arg or something
04:54:15 <ski> (mmorrow : more like `< my_file' ?)
04:54:20 <mmorrow> grep $ -E $ '^[ab]' $ a.txt
04:54:21 <simk138> Hi i am stuck i a problem and posted in forum can you guys give me some hints on this http://www.linuxquestions.org/blog/primenu-494688/2009/12/22/creating-a-random-expression-in-haskell-2504/
04:54:26 <byorgey> kuribas: the type of argument previous expects doesn't seem to match the ouptut of pos_history, does it?  (on the last two lines)
04:54:32 <mmorrow> to abuse notation :)
04:55:14 <ski> simk138 : Redirection loop detected
04:55:26 <merijn> ski: a is a type "individual" (which is some arbitrary data type) of which there is a collection (the population) and a selection operator which given a population would return a random value a. So what I'd want is to automagically pass an appropriate number of a's selected this way as arguments to the function creating a new value a. I see my initial type scheme was flawed to, I guess it should be a -> a -> a and a -> a -> a -> a -> a
04:55:48 <mmorrow> ski: perhaps
04:56:33 <ski> merijn : i don't see why the result type need to be the same as `a' ..
04:57:03 <mmorrow> data Pop a = Pop {sizeP :: Int, indivsP :: Set a, otherStuffP :: OtherStuff}
04:57:12 <ski> merijn : i suspect one can do what you want with basically the standard "vararg" trick, though
04:57:34 <merijn> ski: Perhaps, I don't know what that is, though
04:57:40 <mmorrow> type AnArgToMyFun a = Pop a -> Pop a
04:57:55 <byorgey> simk138: note that Gen a  = MkGen { unGen :: StdGen -> Int -> a }
04:58:06 <byorgey> aw, they left
04:59:00 <ski> merijn : would the 2nd-order function roughly have type `(a -> ... -> a -> b) -> c' ? .. `a',`b',`c' being ?
04:59:59 <ketil> ivanm: the Bloom filter implementation is by Bryan O'Sullivan. I'm just using it.
05:00:04 <ski> (i.e., i need more details, to be able to write this)
05:00:11 <ivanm> ketil: ahhh, fair enough
05:00:21 * hackagebot upload: base-unicode-symbols 0.1.1 - Unicode alternatives for common functions and operators (RoelVanDijk)
05:00:48 <merijn> ski: Hold on, lemme try and think up a sensible type annotation
05:01:03 <ketil> I'm currently running an experiment to see if I can speed up a Map/Set heavy program using a Bloom filter.  So far it is looking good.
05:01:27 <ketil> But I have to verify I get the same output as well.  Speed in itself does not a good program make.
05:02:14 <aep> hm how do i unbox  IO (Int,Int)  ?
05:02:15 <Axman6> Jules_: what do you think of these changes? (i intend to make more) http://github.com/axman6/haskell-torrent/blob/master/src/Main.hs http://github.com/axman6/haskell-torrent/blob/master/src/ConsoleP.hs
05:02:25 <Axman6> aep: unbox?
05:02:27 <ski> aep : "unbox" meaning ?
05:02:34 <aep> umm wrong word i guess
05:02:52 <Axman6> do you mean you want to get at the (Int,Int)?
05:02:54 <aep> how do i get the result of    foo ::  Int -> IO (int,int)
05:02:57 <aep> yes
05:03:12 <ski> aep : maybe you want `do (m,n) <- foo 42; ..x..y..' ?
05:03:13 <Axman6> in the IO monad, you use (x,y) <- foo z
05:03:17 <aep> (a,b) <- foo  doesnt seem to work
05:03:25 <aep> hm
05:03:27 <Axman6> well, you need to give foo an argument
05:03:28 <ski> `foo' wants an argument of type `Int'
05:03:52 <aep> riight.  thanks :D
05:04:07 <ski> (if you don't know what to give it, `42' will surely be a good choice !)
05:04:30 <Axman6> you can never go wrong with 42
05:05:09 <mmorrow> merijn: the parts that i'm unclear about are, (1) select take e.g. a (Set indiv) and returns *one* random individual?, and (2) given (1), do you then apply select N times to the population, then apply this makeNewIndiv function to that new set of N individuals, and repeat this apply-select-N-times-make-new-individual M times to create a new population of size M ?
05:05:32 <merijn> ski: The function would be more of this type "(i -> ... -> i -> i) -> ([i] -> i) -> [i] -> [i]"  ([i] just being a collection of i, not necessarily a list as I think a list is probably ill-suited here
05:05:35 <mmorrow> or does select /itself/ create a the new individual
05:05:41 <mmorrow> s/the//
05:06:30 <merijn> mmorrow: select returns an existing individual, the other function returns a new individual based on N>=1 existing ones
05:07:04 <ski> merijn : an which do you want to use to generate the inputs to the function argument ?
05:07:08 <mmorrow> merijn: ok. so could this other function just take a pair of (random individual, entire pop) ?
05:07:19 <ski> merijn : `select' for the first one, and the other function for the other ones (when present) ?
05:07:41 <kuribas> byorgey: let's see...
05:07:56 <mmorrow> and if not, what other info is needed for this other function to choose which subset of the population it considers in addition to this randomly selected individual in creating a new individual?
05:08:12 <mmorrow> i think that's the question to ask here
05:08:51 <mmorrow> rather than how to make this function take N arguments, since you can always simply hand it a Set, which is a subset of the population
05:09:22 <merijn> mmorrow: Hmm, maybe I'm not sure. I think I need to think on this some more, on account of trying to solve the wrong problem :p
05:10:08 <merijn> I'm gonna try applying more brain power and if that fails I'll be back with more (and hopefully slightly clearer) questions.
05:10:11 <byorgey> kuribas: previous takes an int and a pair, so I would expect (pos_history pos) to be a list of pairs, but pos_history pos will be... a list of lists of pairs, if I'm doing type inference in my head correctly?
05:10:13 <ketil> Is there a way to make an executable run with specific RTS options set by default?  I'm particular, I'm thinking of +RTS -N2, but other options might apply as well (GC options, heap size, etc)
05:10:14 <ski> (maybe merijn want to ensure the function argument can't depend on more arguments that it (statically) wants ?)
05:10:21 <mmorrow> merijn: :) there're a few genetic algo (programming?) packages on hackage which might give you some ideas (by just reading the haddock docs or peaking at the code, or both)
05:11:42 <byorgey> kuribas: how would you want it parenthesized without all the $'s?
05:11:48 <ski> (simk138 : it might be simpler to converse if you didn't leave all the time :)
05:12:02 <kuribas> byorgey: I made some mistakes with the types...
05:12:28 <byorgey> kuribas: a b $ c d $ e f $ g h  is the same as  a b (c d (e f (g h)))
05:13:06 <byorgey> > f b $ f d $ f c $ f a
05:13:08 <lambdabot>   Ambiguous type variable `b' in the constraints:
05:13:08 <lambdabot>    `GHC.Show.Show b'
05:13:08 <lambdabot>      a...
05:13:13 <ski> @pl a b $ c d $ e f $ g h
05:13:14 <lambdabot> a b (c d (e f (g h)))
05:13:17 <Saizan_> ketil: you've to link in some C code, iirc, it should be described in the GHC manual
05:13:17 <mmorrow> ski: what if it wants 394?
05:13:17 <mmorrow> ohhhh.
05:13:20 <mmorrow> is this function the "combining" one?
05:13:22 <mmorrow> so it only takes like two or three?
05:13:30 <mmorrow> in that case, you can fold the subset of the population using this or something maybe
05:13:46 <ketil> This is fun: write a program, start it running, and then see if you can optimize it quickly enough that the optimized version catches up.  Repeat as necessary :-)
05:13:56 <ski> mmorrow : i'm not sure what you're referring to, atm
05:14:21 <Stinger> hmmm hoogle is giving me a lot of broken links
05:14:26 <ketil> Saizan_, right - I did this for heap size once upon a time.
05:14:32 <mmorrow> ski: iirc the Genetic Programming algorithm as defined is {select,combine,..}
05:14:53 <mmorrow> ski: so it's completely specified
05:15:00 <Stinger> but hayoo works, yay
05:15:01 <mmorrow> (i just don't recall the pieces)
05:15:10 * ski knows next to nothing about GP :)
05:15:11 <kuribas> byorgey: yes
05:15:39 <ski> mmorrow : but maybe you're agreeing with "<ski> merijn : `select' for the first one, and the other function for the other ones (when present) ?" ?
05:16:00 <mmorrow> what is "one" there?
05:16:02 <mmorrow> (args?)
05:16:28 <ski> sorry, yes
05:16:29 <merijn> mmorrow: Genetic Programming is only one of 4 main branches in evolutionary computing, though
05:17:02 <mmorrow> merijn: right, but which algo are you looking to implement at the moment?
05:17:06 <kuribas> byorgey: http://paste.lisp.org/display/92473#2
05:17:20 <kuribas> Expected type: ([(a1, bk)], [[(a1, bk)]])
05:17:33 * ski wants to abstract from the particular algorithm wanted
05:17:37 <kuribas> Inferred type: ListPos (a, bk)
05:17:42 <mmorrow> ski: ah, yeah sounds reasonable (i'd probably use a datatype though)
05:18:11 <kuribas> But I have type ListPos a = ([a], [[a]])
05:18:12 <mmorrow> ski: as in, purely from a coding-in-and-organizing-haskell-code perspective you mean?
05:18:35 <byorgey> kuribas: hmm, I wonder if you need ScopedTypeVariables
05:18:44 <mmorrow> ski: (if so, i'm totally on another tangent :)
05:18:46 <byorgey> kuribas: but unfortunately, I have to go proctor a final exam
05:19:19 <kuribas> byorgey: No problem.
05:19:23 <ski> mmorrow : yes. afaiu, the main problem presented was how to conveniently conjure and pass `n' values to any function (of appropriate type), which wants `n' arguments
05:19:36 <mmorrow> ah, ok.
05:19:48 <ski> in some sense, the opposite of the usual "varargs" problem
05:20:41 <merijn> ski: Generalising the problem is what I was trying to do, but I think I just don't know exactly enough what my problem is for others to help solve it. So I'm just coding up a concrete implementation of one of the algorithms, and abstract my way up from there. Which'll hopefully clear up what I'm trying to do
05:20:51 <mmorrow> that seems like spinning of on a tangent of type class and/or type system hackery though
05:21:04 <ski> mmorrow : indeed
05:21:06 <mmorrow> ski: which would distract from any concrete problem-at-hand
05:21:14 <merijn> mmorrow: Sure, but that's the fun learning part :p
05:21:22 <mmorrow> oh, ok. :)
05:21:31 * mmorrow wasn't sure what the exercise here was :)
05:21:59 <merijn> It's not really a concrete problem-at-hand as much as an academical exercise and Haskell practice while I wait for my 20+ hour simulation runs to finish :p
05:22:44 <Saizan_> a great resource for type hackery is oleg's website
05:23:17 <mmorrow> merijn: cool. (although, personally i'd never use such hackery if i was actual writing a serious implem of some algo, which may or may not be completely beside the point here, but just so it's said :)
05:23:40 <mmorrow> yeah, oleg's site is good
05:23:58 <merijn> We already have a framework for the class, but it's a monster of a beast using like 20 mb of Java and XML for something that seems like it should be fairly trivial when done right. At first I was gonna redo it in Python, but I'm already reasonably well versed in python so didn't seem as worthwhile
05:24:54 <mmorrow> merijn: you could totally write a fast implem in haskell, and i'd imagine you could beat the java one easy (even if it's running with JIT)
05:25:54 <mmorrow> whoa
05:26:00 <mmorrow> 20MB of /code/?
05:26:23 <mmorrow> so maybe not a haskell replacement "easy" (since that must be a crapload of features)
05:27:18 <mmorrow> but a correct and fast haskell implem of some subset of it would be do-able for sure as a Haskell-learning-exercise
05:27:26 <merijn> Well, more like 8MB tbh, but still :p
05:27:30 <mmorrow> heh
05:27:41 * mmorrow wonders how many LOC that is
05:27:56 <kiris> gwern: what's that word that means "to dung upon"?
05:28:19 <gwern> ...is that what I shall forever be known for? (it's bescumber)
05:28:24 <kiris> cheers
05:28:36 <Peaker> is writeIORef atomic?
05:28:49 <Peaker> (not writing half a ref)
05:28:55 <gwern> ...he came here *just* for that? o.0
05:29:02 <mmorrow> Peaker: if pointer writes are atomic on your machine it is
05:29:20 <Peaker> mmorrow: atomicModifyIORef would seem a better choice, but seems to be atomic w.r.t reading previous value, which I don't need
05:30:12 <mmorrow> yeah, that gives you read/examine/write atomicity, but for just write-with-no-corruption writeIORef is ok
05:30:21 <mmorrow> unless you're on like SPARC or something
05:31:07 <mmorrow> well, even then, isn't it two instrs to /load/ a ptr, but just one to write to mem?
05:32:05 <mmorrow> it must be i guess
05:33:13 <Peaker> mmorrow: ok, thanks
05:33:33 <jlouis> Axman6: that is pretty good work!
05:33:43 <Axman6> :)
05:34:14 <jlouis> Axman6: by the way, there are some graphviz diagrams in doc if you haven't seen them
05:34:20 <Axman6> hmm, not sure where the problem comes from, but the test torrent fails on 6.12.1. guessing it's got to do with the new UTF stuff... maybe
05:34:55 <jlouis> Perhaps it also fails on 6.10.4, I did some type changes here and there, so I might have broken it again
05:35:16 <Axman6> heh, fair enough
05:36:21 <jlouis> I'll make a check later today and fix my bugs, it can only seed at the moment and I only tested against rtorrent
05:36:29 <Axman6> maybe using bytestrings would be easier...
05:37:04 <aep> hm can lists be "produced" by an iterator function or something? I wonder if i can use them as interface to a stream
05:37:05 <jlouis> It might very well be that using ByteString all over would be the best thing to do
05:37:43 <jlouis> aep: unfolds in general can produce lists
05:38:10 <ski> > unfoldr (Just . graph succ) 0  -- aep ?
05:38:11 <lambdabot>   [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,...
05:38:17 <jlouis> aep: Data.List.unfoldr is worth checking out
05:38:30 <aep> aye thanks
05:39:55 <calsaverini> how do I turn on advanced text formatting in GHCi?
05:40:10 <aep> would you say a list is an aprorpiate data  type for a "model"  (model from oops mvc)
05:40:21 <calsaverini> like being able to use Home and End, and Control Right, etc...
05:40:40 <calsaverini> is there a way?
05:40:41 <ski> aep : depends wholly on what it is supposed to model, imo
05:41:12 <ski> calsaverini : maybe you want emacs ?
05:41:17 <aep> well, an abstract representation of a list of data items
05:41:39 <aep> where the source is abstracted. it could be sql
05:41:44 <aep> or in my case it is imap
05:41:44 <calsaverini> ski, no, I just want a few text navigation capabilities while editing a single line
05:42:28 <calsaverini> I was able to do that before, i.e. , hitting Home took me to the beggining of the line
05:42:40 <calsaverini> now it just inserts a H character
05:42:56 <ski> usually GHCi is compiled in such a way as to include line editing. if not, `rlwrap' or `ledit' might help
05:43:07 <calsaverini> Or hitting Control + Right I could navigate word for word, now it just inserts a ~5
05:44:12 <calsaverini> hum, what are those? Command line flags?
05:44:18 <ski> programs
05:44:27 <calsaverini> hum
05:44:59 <ski> (your package manager might include them)
05:45:17 <calsaverini> ah!! thanks!
05:46:49 <ski> (hm, though maybe you should first try whether `C-a' and `M-f' works .. maybe only something is wrong with how your terminal interprets things)
05:48:37 <ski> preflex: seen preflex_
05:48:38 <preflex>  preflex_ was last seen on ##c 138 days, 1 hour, 24 minutes and 11 seconds ago, saying:  gcc -std=c89 -pedantic -Wall -W -Wno-missing-field-initializers -Wundef -Wendif-labels -Wshadow -Wpointer-arith -Wbad-function-cast -Wcast-align -Wwrite-strings -Wstrict-prototypes -Wmissing-prototypes -Wnested-externs -O2
05:48:48 * ski raises eyebrow
05:49:28 <Botje> HERESY!
05:49:58 <Saizan_> calsaverini: which version of ghc?
05:50:15 <koeien37> is this ghc 6.10.x , where x < 4 ?
05:58:08 <ivanm> sinelaw: hmmm.... I'm working on adding a DotGraph -> Graph function, but I've remembered why I haven't done so before: there's no way of getting the proper node/edge labels back
05:58:48 <Kim^Walkman> @pl (\s xs -> f s (g xs))
05:58:48 <lambdabot> (. g) . f
06:02:03 <ivanm> OK, if I use an if statement to construct a function a -> a, then I have to wrap it in parens to apply it and can't just use $ :s
06:05:50 <aep> umm. i cant have multiple variables inside a closure?
06:06:09 <ski> ?
06:06:20 <aep> multiple arguments
06:06:30 <aep> something like \x,y ->
06:06:38 <vowyer> without comma
06:06:40 <copumpkin> > (\x y -> x + y) 3 4
06:06:40 <aep> maybe i'm doing it wrong.
06:06:41 <lambdabot>   7
06:06:45 <aep> ah!  thanks
06:06:48 <copumpkin> we don't use commas :)
06:06:52 <aep> heh
06:06:57 <osfameron> you could do \(x,y) ;-P
06:06:59 <ski> > zipWith (\x y -> reverse x ++ y) ["","a","bc","def"] ["ghi","jk","l",""]
06:07:00 <lambdabot>   ["ghi","ajk","cbl","fed"]
06:07:13 <ski> > map (\(x,y) -> reverse x ++ y) (zip ["","a","bc","def"] ["ghi","jk","l",""])
06:07:15 <lambdabot>   ["ghi","ajk","cbl","fed"]
06:07:36 <aep> cool
06:07:51 <ivanm> @ask sinelaw would you be satisfied if I exposed the dotAttributes function from inside Data.GraphViz (or something similar)? That way, you can manually pass the DotGraph through dot, neato, etc. and then augment the graph by hand as well as having the new DotGraph available to get the top-level attributes (otherwise, there's the question of _which_ attributes to return; just those for the overall graph or also for clusters?) ?
06:07:51 <lambdabot> Consider it noted.
06:08:09 <ivanm> copumpkin: yeah, we can't afford them... >_>
06:09:18 <kmis138> how to convert IO a -> a type ?
06:09:24 <ski> kmis138 : no
06:09:28 <Twey> kmis138: Mu
06:09:28 <copumpkin> lol
06:09:36 <koeien37> kmis138: you don't.
06:09:38 <copumpkin> Moo
06:09:55 <copumpkin> kmis138: instead of taking something out of IO, you put whatever you wanted to do with the a inside IO
06:09:56 <ski> kmis138 : use `do ...; my_a <- my_IO_a; ..my_a..'
06:10:12 <aep> hmm how would i run a map only on a specific range?
06:10:21 <Twey> :t splitAt
06:10:23 <lambdabot> forall a. Int -> [a] -> ([a], [a])
06:10:49 <ski> > map (^2) (range (-3,3))
06:10:50 <lambdabot>   [9,4,1,0,1,4,9]
06:10:52 <Twey> uncurry (++) . (map (+ 2) &&& id) . splitAt 3 $ [1 .. 15]
06:10:57 <Twey> > uncurry (++) . (map (+ 2) &&& id) . splitAt 3 $ [1 .. 15]
06:10:58 <lambdabot>   Couldn't match expected type `[a]'
06:10:58 <lambdabot>         against inferred type `([a1], [a...
06:11:02 <Twey> :<
06:11:15 <Twey> > uncurry (++) . (map (+ 2) *** id) . splitAt 3 $ [1 .. 15]
06:11:17 <lambdabot>   [3,4,5,4,5,6,7,8,9,10,11,12,13,14,15]
06:11:22 <Twey> Always get those two mixed up
06:11:41 <Twey> Or full-arrow style:
06:11:55 <koeien37> yeah, *** and &&&
06:12:09 <koeien37> is there some trick to remember that?
06:12:11 <Twey> > splitAt 5 >>> (map (+ 2) *** id) >>> uncurry mappend $ [1 .. 15]
06:12:12 <lambdabot>   [3,4,5,6,7,6,7,8,9,10,11,12,13,14,15]
06:12:20 <aep> hm. let me try to explain. i have an infinite list of data. now i want to display the result in "pages" that is 20 entries and the user can choose the next 20.  my display function is  :: Int -> String -> IO()
06:12:25 <Twey> koeien37: I guess it's that &&& duplicates
06:12:46 <Twey> aep: See Data.List.Split.chunk, from the ‚Äòsplit‚Äô package
06:12:53 <aep> aye thanks
06:12:59 <ski> > map (\(i,a) -> (if inRange (3,5) i then (^ 2) else id) a) (zip [0..] "foobarbaz")
06:13:00 <lambdabot>   No instance for (GHC.Num.Num GHC.Types.Char)
06:13:01 <lambdabot>    arising from a use of `GHC....
06:13:11 <koeien37> Twey: yeah, might be useful :)
06:13:23 <Twey> koeien37: Funnily enough, I never mistakenly use *** instead of &&& ‚Äî it's always the other way around
06:13:31 <ski> > map (\(i,a) -> (if inRange (3,5) i then toUpper else id) a) (zip [0..] "foobarbaz")  -- better :)
06:13:32 <lambdabot>   "fooBARbaz"
06:13:54 <Peaker> @let inEnum f = toEnum . f . fromEnum
06:13:55 <lambdabot>  Defined.
06:13:56 <aep> wouldnt it be "better"  to sort of apply the monad to the infinite list and then get a new monad which can be run with a range parameter or something?
06:14:03 <Peaker> > inEnum (^2) 'a'
06:14:04 <lambdabot>   * Exception: Prelude.Enum.().toEnum: bad argument
06:14:07 <Twey> What's this ‚ÄòinRange‚Äô stuff?  What happened to my lovely >< operator?  :√æ
06:14:11 <Peaker> > inEnum (+5) 'a'
06:14:12 <lambdabot>   * Exception: Prelude.Enum.().toEnum: bad argument
06:14:15 <merijn> Question: If I need like a short-circuiting fold (i.e. it recurses like fold but only N times (or until a certain condition is true) rather then until the end of the list) is there a common way to express this or should I just create a function using explicit recursion that does this?
06:14:27 <Peaker> > inEnum (^2) 'a' :: Char
06:14:28 <lambdabot>   '\9409'
06:14:39 <ski> @type inEnum
06:14:41 <lambdabot> forall a1 a. (Enum a, Enum a1) => (Int -> Int) -> a1 -> a
06:14:43 <osfameron> git gui
06:14:46 <koeien37> merijn: this sounds like it could be a foldr. Depends on the exact problem
06:14:46 <Peaker> oops
06:14:49 <Peaker> @undef
06:14:53 <osfameron> oops
06:14:55 <ski> Peaker : maybe you wanted `Enum a => (Int -> Int) -> (a -> a)'
06:14:56 <ski> ?
06:14:58 <Peaker> Ya
06:15:11 <Peaker> @let inEnum :: Enum a => (Int -> Int) -> a -> a ; inEnum f = toEnum . f . fromEnum
06:15:12 <lambdabot>  Defined.
06:15:12 <koeien37> merijn: foldr "short-circuits"
06:15:17 <Peaker> > inEnum (^2) 'a'
06:15:18 <lambdabot>   '\9409'
06:15:26 <koeien37> > foldr (&&) True $ [True, False, True, undefined]
06:15:27 <Twey> koeien37: ?
06:15:27 <lambdabot>   False
06:15:39 <Twey> Mm
06:15:41 <koeien37> Twey: ?
06:15:48 <koeien37> what is your question/problem?
06:15:56 <Twey> That's a property of && rather than foldr, though
06:16:00 <koeien37> Twey: yes.
06:16:04 <koeien37> well, both
06:16:22 <Jafet> > foldr (:) [] [0..]
06:16:23 <lambdabot>   [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,...
06:16:24 <Peaker> > foldl (&&) True $ [True, False, True, undefined]
06:16:25 <lambdabot>   False
06:16:35 <Twey> koeien37: The point is that it stops when it encounters a certain element‚Ä¶ but say if you're folding into a list, and you want to simply stop processing, foldr doesn't allow this as far as I'm aware
06:16:36 <merijn> koeien37: Yeah, I thought foldr does that, but it's hard to see how I'd combine it
06:16:55 <Twey> Or, even worse, if you want to return the remainder of the list intact, without processing
06:17:06 <Peaker> Twey: foldr gives the binary function a second argument which is a thunk -- which if not evaluated, "stops" processing
06:17:17 <ski> Twey : the type disallows the latter
06:17:22 <Twey> Yes
06:17:33 <Twey> Peaker: Hmm?
06:17:35 <koeien37> > foldr (\x y -> if x == 37 then [] else (x:y)) 0 [1..] -- hmm, let's try something like this
06:17:36 <lambdabot>   No instance for (GHC.Num.Num [a])
06:17:36 <lambdabot>    arising from the literal `0' at <inter...
06:17:38 <Peaker> a non-recursive foldr would be a nice middle-func between pattern matching and foldr
06:17:47 <koeien37> > foldr (\x y -> if x == 37 then [] else (x:y)) [] [1..] -- hmm, let's try something like this
06:17:48 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
06:17:50 <Jafet> :t foldr'
06:17:51 <lambdabot> Not in scope: `foldr''
06:17:56 <koeien37> > foldr (\x y -> if x == 10 then [] else (x:y)) [] [1..] -- hmm, let's try something like this
06:17:56 <lambdabot>   [1,2,3,4,5,6,7,8,9]
06:18:07 <Peaker> > let null = foldr (const . const $ True) False in map null [[], [1..]]
06:18:08 <lambdabot>   [False,True]
06:18:10 <Twey> Peaker: Not evaluating the next item doesn't result in processing ceasing
06:18:11 <Peaker> oops
06:18:14 <Peaker> opposite :)
06:18:19 <Twey> For example‚Ä¶
06:18:49 <koeien37> Jafet: a strict foldr would make little sense
06:18:51 <Twey> > foldr (\x y -> if x == 2 then 5 else x + y) 0 [1, 1, 1, 1]
06:18:53 <lambdabot>   4
06:19:10 <Twey> Did I get them backwards?
06:19:16 <Twey> > foldr (\y x -> if x == 2 then 5 else x + y) 0 [1, 1, 1, 1]
06:19:18 <lambdabot>   6
06:19:20 <Twey> There we are
06:19:43 <koeien37> the first argument is the list element in foldr
06:19:54 <Twey> The x == 2 case doesn't evaluate the next item, but the rest of the items are still folded into the result of that step
06:19:56 <Jafet> Indeed, it would.
06:19:57 <Twey> Yes
06:20:15 <mauke> I always write foldr (\x z ->
06:20:34 <Twey> I usually call the accumulator ‚Äòt‚Äô and the item ‚Äòx‚Äô
06:20:48 <mauke> what does the t stand for?
06:20:49 <koeien37> the item x, the accumulator varies i guess. sometimes a, sometimes y
06:20:57 <Twey> mauke: ‚ÄòTotal‚Äô
06:21:05 <Jafet> I assign variables based on the smallest unused letter
06:21:16 <Jafet> Like a real programmer.
06:21:17 <Twey> Jafet: Descriptive names!  :√æ
06:21:20 <Twey> Heheh.
06:21:47 <koeien37> you can write fortran in any language
06:21:53 <Peaker> Twey: the x==2 case uses "x" which processes the rest of the list.. I'm not sure I follow
06:22:12 <Peaker> Twey: (second arg to the binop represents the processing of the rest of the list)
06:22:44 <koeien37> Twey: your function is strict in its second argument.
06:22:45 <Peaker> foldr (\x r -> ..)  or foldr (\x rest ->..)
06:22:46 <Twey> Peaker: Huh?  x is the accumulator
06:22:56 <Peaker> Twey: I don't see it as an "accumulator" :)
06:23:12 <koeien37> \y x -> is a little obfuscated imo
06:23:15 <Twey> Returning something that isn't based on the accumulator would be useless
06:23:20 <Twey> koeien37: Yeah.  Sorry.
06:23:26 <Peaker> Twey: what about the null example?
06:24:04 <Twey> Peaker: That's not really a fold
06:24:11 <Peaker> its a foldr...
06:24:20 <ski> > evalCont . callCC $ \k -> foldrM (\y x -> if x == 2 then k 5 else return (x + y)) (return 0) [1, 1, 1, 1]
06:24:21 <lambdabot>   5
06:24:22 <aep> is there anything like map that ignores the return value? it doesn't seem to work inside do, since the return is [IO()]
06:24:25 <Twey> It's expressed in terms of foldr, but conceptually it's not a fold ‚ò∫
06:24:31 <koeien37> aep: you might want mapM or mapM_
06:24:31 <mauke> aep: mapM_
06:24:36 <aep> thanks
06:24:37 <koeien37> :t mapM
06:24:38 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
06:24:38 <koeien37> :t mapM_
06:24:39 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m ()
06:25:17 <ski> Twey : that example does what you want, yes ?
06:25:26 <koeien37> > mapM (\i -> [i,i]) [1..5]
06:25:27 <lambdabot>   [[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1...
06:25:48 <Twey> ski: The callCC one?
06:25:57 <ski> aye
06:26:15 <Twey> No, not really
06:26:24 <Peaker> foldr (*) 1 (x:y:z:[]) = (x*(y*(z*1))) --  what's the "accumulator" ?
06:26:50 <Peaker> foldl (*) 1 (x:y:z:[]) = (((1*x)*y)*z)
06:26:56 <Twey> Here's an example: you have a list of fifteen elements, Nums, of which you want to sum the first five into the first element of a new list and leave the rest of the list intact
06:27:21 <Twey> s/fifteen/an indeterminate and possibly infinite number of/
06:27:33 <Saizan_> foldr does allow you to stop processing..
06:27:44 <Saizan_> > foldr const undefined [1..]
06:27:45 <koeien37> summing an infinite number of numbers is undefined for most Nums
06:27:45 <lambdabot>   1
06:27:58 <Saizan_> you folding function just has to be lazy in its second argument
06:28:19 <Twey> So, for example, [1, 2, 3, 4, 5, 6, 7, 8 ..] becomes (1 + 2 + 3 + 4 + 5) : [6, 7 ..]
06:28:28 <Peaker> Twey: ah, you don't mean "stopping processing", you mean the ability to get some tail in the list
06:28:40 <Twey> koeien37: But we're not folding an infinite number ‚Äî we're only folding the first few
06:28:45 <Saizan_> (\x y -> if x == 2 then 5 else x + y) isn't lazy because it uses 'y' in the result
06:28:59 <Twey> Peaker: By ‚Äòstopping processing‚Äô I mean ceasing the fold and just returning the rest of the list as-is.
06:29:14 <Peaker> Twey: the latter clause doesn't seem to be implied by the words "stopping processing", though
06:29:49 <merijn> Saizan_: How would you accomplish something similar the right way, then?
06:29:57 <koeien37> yeah, I would see "stopping processing" as something like our foldr (&&) True infinite_list
06:30:10 <Saizan_> Twey: you want a paramorphism rather than a catamorphism, then, not that "paramorphism" has to say something to you
06:30:18 <Saizan_> merijn: take a list?
06:30:35 <Saizan_> merijn: err, what's the subject?
06:30:37 <Twey> Saizan_: Yes
06:31:12 <peternovice> Say that I want to implement an instance of Read for certain type with a constructor of the form: ValConstr Comp1 Comp2 where Read Comp1,Read Comp2  are defined. I guess I should start with: readPrec = do; Ident "ValConstr" <- lexP; "extract Comp1,Comp2". I.e. I am a bit uncertain how I should tackle the extraction of Comp1,2 since they have read defined already.
06:31:16 <Peaker> I agree it would be nice to have:   list :: (a -> [a] -> b) -> b -> [a] -> b ; list _ z [] = z ; list f _ (x:xs) = f x xs
06:31:28 <Peaker> Calling it list because of "maybe" and "either"
06:31:37 <Peaker> @let list :: (a -> [a] -> b) -> b -> [a] -> b ; list _ z [] = z ; list f _ (x:xs) = f x xs
06:31:37 <lambdabot>  Defined.
06:31:40 <Stinger> ok why does print undefined, give an exception while try (print undefined) give you a Left prelude.undefined
06:32:10 <koeien37> :t try
06:32:11 <lambdabot> Not in scope: `try'
06:32:15 <Saizan_> Stinger: because try catches the exception
06:32:41 <Peaker> > map (list (,) (0,[])) [[], [1..]]
06:32:42 <lambdabot>   [(0,[]),(1,[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25...
06:32:47 <koeien37> Control.Exception.try ?
06:32:54 <Stinger> result <- try (return undefined) throws an exception
06:33:04 <Stinger> no Control.OldException.try
06:33:12 <Stinger> reading from RWH
06:33:15 <koeien37> ok.
06:33:25 <Peaker> Then, foldr f z = list (\x xs -> f x (foldr f z xs)) z
06:33:49 <Stinger> I guess it's more about how ghc handles undefined
06:33:53 <Peaker> Who are the guys maintaining an alternate stdlib?
06:33:54 <Stinger> or ghci
06:33:59 <Peaker> jmcarthur: you have one, right?
06:34:00 <Saizan_> peternovice: just use readsPrec for those
06:34:24 <koeien37> Stinger: "return undefined" doesn't throw an exception
06:34:26 <Saizan_> Stinger: "try (return $! undefined)"
06:34:33 <koeien37> Stinger: this is a bit tricky to see
06:34:33 <ski> Twey : what if the list has fewer than five elements ?
06:34:45 <Twey> ski: Explosion!
06:34:50 <Saizan_> Stinger: the point is that you've to force the undefined to trigger the exception
06:34:54 <Stinger> yeah I know the book says its ghci throwing the exception
06:35:19 <Stinger> but then why doesnt it throw the exception when dealing with the Left prelude.undefined
06:35:22 <Saizan_> Stinger: and you've to trigger the exception before try returns to catch it
06:35:39 <koeien37> Stinger: "return undefined" doesn't throw an exception. Then you bind its result to "result", and upon evaluating "result", you evaluate "undefined", which causes an exception to be thrown
06:36:07 <Saizan_> Stinger: what you see inside the Left is the message that was inside the exception
06:36:08 <koeien37> "print undefined" DOES throw an exception, because to print it, you need to evaluate "undefined"
06:36:33 <Saizan_> Stinger: it isn't getting rethrown
06:36:57 <koeien37> and try returns an Either Exception a. so you get a Left Exception, or a Right a (the result of your computation if there were no exceptions thrown)
06:37:07 <ski> > foldr (\a r -> maybe (a : r Nothing) $ \(i,s) -> if i > 0 then r (Just (i-1,s+a)) else s : r Nothing) (\_ -> error "Explosion!") [10,20..] (Just (5,0))  -- Twey ?
06:37:08 <lambdabot>   [150,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,2...
06:37:20 <koeien37> what you see in ghci is the value Left your_exception, which gets printed like you observed
06:38:07 * ski sometimes thinks `Wrong' should be a constructor synonym of `Left'
06:38:18 <EvanR-work> left is wrong?
06:38:25 <EvanR-work> i was using right :S
06:38:28 <Stinger> it's not right :)
06:40:59 * koeien37 likes Left and Right
06:41:02 <ski> Stinger : also try `print =<< try undefined'
06:41:13 <Stinger> ok in result <- try (return z) it's the exception is occuring within ghci right? when it trys to print out the result?
06:41:27 <koeien37> yes
06:41:31 <koeien37> return z doesn't throw an exception
06:42:19 <Stinger> sorry z is let z = undefined, I don't think I typed that
06:42:36 <koeien37> ok. but return undefined also doesn't throw an exception
06:42:45 <koeien37> return $! undefined does, like Saizan said
06:42:53 <EvanR-work> > return undefined
06:42:53 <lambdabot>   No instance for (GHC.Show.Show (m a))
06:42:54 <lambdabot>    arising from a use of `M8182741901...
06:43:04 <Stinger> yeah like evaluate
06:43:24 <EvanR-work> > return (!undefined)
06:43:25 <lambdabot>   No instance for (GHC.Show.Show (m (GHC.Arr.Array i e -> e)))
06:43:25 <lambdabot>    arising fro...
06:43:27 <koeien37> but return $! [undefined] doesn't throw an exception
06:43:46 <Stinger> but how does result <- try (print z) not cause ghci to cause an exception when printing Left undefined?
06:44:09 <koeien37> because the exception is not undefined. The exception has a value, like Exception "prelude.undefined"
06:44:25 <Stinger> so undefined isnt prelude.undefined
06:44:29 <koeien37> it is
06:44:38 <mauke> Stinger: "undefined" is not undefined
06:44:40 <mauke> one is a string
06:44:40 <Stinger> brain .. broken :(
06:44:53 <mauke> IT'S JUST TEXT
06:45:15 <koeien37> the exception has a value, like, Exception "You tried to evaluate Prelude.undefined. This is not supported and this is the exception that is thrown by trying to evaluate it."
06:45:28 <ski> > (return $! undefined :: IO ()) `seq` ()
06:45:29 <lambdabot>   * Exception: Prelude.undefined
06:45:30 <mauke> oh, but if you want an undefined exception, type 'fix error'
06:45:32 <Stinger> but Left "Text" gives "Left \"Text\""
06:45:33 <ski> > (Control.Exception.evaluate undefined :: IO ()) `seq` ()  -- :(
06:45:34 <lambdabot>   Not in scope: `Control.Exception.evaluate'
06:46:18 <Jonno_FTW> is this accurate?http://i.imgur.com/hF6mS.jpg
06:46:39 <koeien37> Jonno_FTW: heh. pretty accurate
06:49:32 <jlouis> Axman6: Pushed :)
06:50:32 <Gracenotes> I don't get most of the cells
06:51:06 <Gracenotes> it's not just specific language fanboys against each other, but mainly various factions: static typing, garbage collection, etc.
06:51:14 <Peaker> I don't get why PHP fans see C as a fat dude with a computer
06:51:35 <EvanR-work> quote this! ^
06:51:37 <Stinger> old school systems nerds?
06:51:54 <Stinger> as opposed to trendy web programmers
06:52:13 <EvanR-work> god i hate being trendy
06:52:30 <Gracenotes> I don't think a majority of PHP programmers are that into "trends"
06:52:38 <Raynes> Is there a more concise way of writing `foo == 0 && bar == 0'?
06:52:50 <ski> (EvanR-work : .. then stop ? ;)
06:52:55 <koeien37> Raynes: not really. although if you can pattern match, it's better
06:53:10 <Raynes> Alright. Thanks. :)
06:53:11 <EvanR-work> Raynes: (foo,bar) == (0,0) ?
06:53:25 <EvanR-work> but yeah pattern matching
06:53:25 <koeien37> EvanR-work: yeah, but a little bit more obfucated imo
06:53:26 <Peaker> Raynes: ((&&) `on` (==0)) foo bar :)
06:53:27 <Gracenotes> Raynes: if you're getting into combinators, join (liftM2 (&&)) (0==)
06:53:34 <Raynes> Aha, yeah that would work.
06:53:44 <Twey> Haha, nice image
06:53:46 <Gracenotes> er. Peaker's is a bit shorter
06:53:55 <Gracenotes> more precise I should say
06:53:57 <Peaker> Gracenotes: why join? foo, bar are two different arguments
06:54:10 <Peaker> oh, I see
06:54:11 <Stinger> ok in result <- try (print undefined) and result <- try (return undefined), result will both contain a Left undefined or a Right undefined (where undefined is the same thing) is that correct?
06:54:18 <Gracenotes> Peaker: ah, true. perhaps two different Num instances. But in this case, probably not.
06:54:27 <koeien37> Stinger: no.
06:54:34 <Stinger> ok
06:54:41 <Peaker> Gracenotes: `on` destroys generality too
06:54:41 <Raynes> @src on
06:54:42 <lambdabot> (*) `on` f = \x y -> f x * f y
06:54:43 <Gracenotes> oh wait, you might have a point. not enough arguments.
06:54:44 <koeien37> Stinger: in the first case, it will contain Left (Exception "You tried to evaluate Prelude.undefined")
06:54:49 <Peaker> > fix error
06:54:50 <lambdabot>   "* Exception: * Exception: * Exception: * Exception: * Exception: * Excepti...
06:54:51 <koeien37> Stinger: in the second case, it will contain Right undefined
06:54:57 <Gracenotes> consider it fixed
06:55:21 * hackagebot upload: haskell-src-exts 1.3.5 - Manipulating Haskell source: abstract syntax, lexer, parser, and pretty-printer (NiklasBroberg)
06:55:23 * hackagebot upload: HJScript 0.4.6 - HJScript is a Haskell EDSL for writing JavaScript programs. (NiklasBroberg)
06:55:55 <alinp> hi guys
06:56:04 <alinp> in order to understand better the monads stuff, I'l need a little help from you please
06:56:07 <Stinger> hmmm when I try result <- return Left "undefined" in my ghci it prints the quotes, in the other instance it does not
06:56:14 <koeien37> Stinger: the first value, is completely well-defined. The second one, however, will cause an exception to be thrown if you print it, for example
06:56:26 <koeien37> alinp: sure. where are yous tuck?
06:56:52 <koeien37> Stinger: ? that is not a valid expression
06:56:54 <alinp> koeien37: one sec please, I'm writing it on a pastie or something
06:57:08 <alinp> it's a code snippet that I want to show you first
06:57:13 <Stinger> sorry result <- return (Left "undefined")
06:57:41 <koeien37> if you now print result, it will say something like Left "undefined"
06:57:50 <mauke> > show (Left "undefined")
06:57:51 <aep> hm what could couse an undefined reference to stuff like __stginit_networkzm2zi2zi1zi2_Network_
06:57:52 <lambdabot>   "Left \"undefined\""
06:57:56 <Gracenotes> that is relatively equivalent to let result = Left "undefined", if your monad is a proper monad
06:58:03 <Gracenotes> aep: linking problems, likely. try --make?
06:58:09 <alinp> http://pastie.org/753134
06:58:19 <alinp> koeien37: obviously ... Maybe monad
06:58:26 <Axman6> oh hooraym new HJScript
06:58:28 <koeien37> alinp: yes
06:58:33 <Stinger> koeien37, it does not give me quotes
06:58:40 <alinp> so, regarding binding operator >>=
06:58:54 <alinp> if I'm doing: Just 4 >>= \x -> x
06:59:02 <mauke> type error
06:59:05 <koeien37> that is not well typed
06:59:07 <Stinger> also :t result after that line gives Either Exeption ()
06:59:12 <alinp> the lambda function should return also a Maybe type ?
06:59:15 <koeien37> yes.
06:59:18 <Axman6> :t (>>+)
06:59:18 <koeien37> :t (>>=)
06:59:18 <EvilTerran> alinp, note the type of >>= in the definition of Monad
06:59:19 <lambdabot> Not in scope: `>>+'
06:59:19 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
06:59:21 <Axman6> :t (>>=)
06:59:21 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
06:59:24 <alinp> where that is specified ?
06:59:28 <Axman6> :t (\x -> x)
06:59:29 <lambdabot> forall t. t -> t
06:59:30 <alinp> I mean, in the code that I paste it
06:59:33 <mauke> in the type of (>>=)
06:59:35 <koeien37> :t (>>=) :: Maybe a -> (a -> Maybe b) -> Maybe b
06:59:36 <lambdabot> forall a b. Maybe a -> (a -> Maybe b) -> Maybe b
06:59:40 <aep> Gracenotes: that works, thanks
06:59:41 <mauke> in the definition of class Monad
06:59:45 <alinp> Just x >>= f = f x
06:59:48 <alinp> this one, right ?
06:59:53 <mauke> no
06:59:56 <EvilTerran> alinp, when you say "instance Monad Maybe", that refers back to wherever in the libraries "class Monad m" is defined
06:59:57 <alinp> but ?
07:00:03 <mauke> <mauke> in the definition of class Monad
07:00:16 <EvilTerran> alinp, and that definition of "class Monad m" is where the types of >>= and return are fixed
07:00:16 <Gracenotes> aep: okay, great. That makes some interface files and the like, which might interfere with loading in ghci.. don't know what the state of that is. okay.
07:00:21 <alinp> EvilTerran: it was just an example
07:00:33 <mux> is someone working on repairing hackage's build bot?
07:00:48 <EvilTerran> alinp, well, it generalises in the obvious way
07:00:54 <jlouis> Axman6: Next target for me is the PieceMgr code, http://dl.dropbox.com/u/196031/PieceManager.pdf
07:01:18 <alinp> so, what's the type of >>= ?
07:01:21 <koeien37> :t (>>=)
07:01:22 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
07:01:26 <alinp> oh
07:01:29 <alinp> silly me ...
07:01:41 <Axman6> jlouis: i'll keep playing around the edges until i understand the code more. i might tomorrow try rewriting the BCode thing to use bytestrings
07:01:42 <koeien37> :t (>>=) :: Maybe a -> (a -> Maybe b) -> Maybe b -- in the Maybe monad
07:01:43 <lambdabot> forall a b. Maybe a -> (a -> Maybe b) -> Maybe b
07:01:48 <EvilTerran> "when you write 'instance Foo Bar where ... eek = ...', the type of eek is fixed by the definition 'class Foo a where ... eek :: ...'."
07:02:00 <alinp> hmmm, so it's mandatory to return the same type as the input
07:02:08 <Lemmih> Axman6: What BCode?
07:02:14 <koeien37> alinp: no, Maybe a and Maybe b are different
07:02:15 <mauke> alinp: not quite, a and b can be different
07:02:18 <jlouis> Axman6: rewriting the BCode to use ByteString is nice and pretty selfcontained
07:02:22 <mauke> but you must stay in the same monad
07:02:27 <alinp> koeien37: yeah, are different
07:02:28 <EvilTerran> alinp, indeed, >>= doesn't let you "get out of" the monad you're working in
07:02:33 <alinp> but it's the "box" that is the same
07:02:34 <Axman6> Lemmih: in jlouis's haskell-torrent project
07:02:36 <alinp> I mean, the monad
07:02:46 <jlouis> Lemmih: http://github.com/jlouis/haskell-torrent src/BCode
07:02:47 <koeien37> alinp: but you can't escape from the monad without an escape hatch. The absence of this is very useful in for example IO. But most monads have an "escape"
07:02:58 <alinp> I can do an escape hatch
07:03:03 <alinp> one sec
07:03:04 <jlouis> It looks fairly like the old Conjures version
07:03:08 <koeien37> alinp: in Maybe, you can just pattern match or use the maybe function
07:03:19 <Raynes> Ew. I forgot an Ord instance. ._.
07:03:27 <mauke> alinp: there are cases where m >>= \x -> x is valid and even useful :-)
07:03:32 <koeien37> alinp: yeah, that's join :)
07:03:41 <koeien37> @src join
07:03:42 <lambdabot> join x =  x >>= id
07:03:54 <koeien37> > join (*) 2
07:03:55 <lambdabot>   4
07:03:55 <alinp> mauke: I know, but I was just asking in order to help me understand better
07:03:56 <alinp> :)
07:04:07 <koeien37> > join [[1],[2,3]]
07:04:08 <lambdabot>   [1,2,3]
07:04:14 <mauke> > join Nothing
07:04:14 <lambdabot>   Nothing
07:04:22 <koeien37> > join (Just Nothing)
07:04:23 <lambdabot>   Nothing
07:04:37 <Lemmih> Axman6, jlouis: Any reasons not use the use bencode/torrent packages from hackage?
07:04:51 <mauke> > join (Just (Just "unjust"))
07:04:52 <lambdabot>   Just "unjust"
07:05:02 <EvilTerran> note that, as
07:05:04 <EvilTerran> (>>=) :: (Monad m) => m a -> (a -> m b) -> m b, in (>>= id)
07:05:21 <Raynes> > concatMap id [[1],[2,3]
07:05:23 <lambdabot>   <no location info>: parse error (possibly incorrect indentation)
07:05:23 <jlouis> Lemmih: pure sillyness, It took 10 minutes to hack a working version and I was irritated on the other project I had at that time
07:05:25 <Raynes> > concatMap id [[1],[2,3]]
07:05:26 <lambdabot>   [1,2,3]
07:05:27 <EvilTerran> er, s/, in (>>= id)//
07:05:38 <jlouis> Lemmih: using the hackage library is *definitely* an option
07:05:47 <mauke> join :: Maybe (Maybe a) -> Maybe a. the end.
07:05:51 <EvilTerran> ... the type variables end up fixed so that a = m b
07:05:55 <alinp> let test :: Maybe Int -> Int; test (Just a) = a + 1
07:06:02 <alinp> this is a way to "leave" the monad ?
07:06:04 <EvilTerran> ie, id is specialised to m b -> m b
07:06:07 <alinp> test (Just 6)
07:06:09 <mauke> alinp: yeah
07:06:10 <koeien37> alinp: yes. Although your function is partial
07:06:12 <alinp> will return 7
07:06:16 <alinp> yeah
07:06:16 <mauke> alinp: that's pattern matching
07:06:17 <alinp> I know
07:06:25 <mauke> <koeien37> alinp: in Maybe, you can just pattern match or use the maybe function
07:06:30 <alinp> partial because no Nothing case was considered
07:06:30 <EvilTerran> ?src maybe
07:06:31 <lambdabot> maybe n _ Nothing  = n
07:06:31 <lambdabot> maybe _ f (Just x) = f x
07:06:38 <koeien37> > maybe 7 (+1)
07:06:39 <lambdabot>   {Nothing->7;Just (-2)->-1;Just (-1)->0;Just 0->1;Just 1->2;Just 2->3}
07:06:51 <koeien37> this is an example of "leaving" the Maybe monad
07:06:53 <jlouis> Lemmih: ok, those packages ought to be worked into the game
07:07:01 <koeien37> but in general there is no function :: Monad m => m a -> a
07:07:19 <mauke> koeien37: unsafeCoerce
07:07:20 <alinp> Guys, I don't want to be rude or something, but I don't want to know the situation where the maybe monad is used
07:07:22 * mauke runs away
07:07:24 <koeien37> e.g. the IO monad doesn't have one
07:07:28 <alinp> just used it as a reference for monads
07:07:30 <koeien37> mauke: I deny the existence of that :P
07:07:39 <alinp> in order to get a little bit more about the binding operator
07:07:41 <alinp> that's all
07:07:42 <koeien37> good
07:07:54 <koeien37> the Maybe monad is a good place to start with monads imo
07:08:07 <EvilTerran> alinp, i don't see anyone telling you the situation where the maybe monad is used
07:08:11 <alinp> yeah, that's why I'm here koeien37 ;)
07:08:12 <koeien37> if you understand it, you can try the [] monad next
07:08:21 <alinp> since now I thought IO is the best place
07:08:25 <EvilTerran> just telling you how to use it, as an example of a monad
07:08:27 <alinp> but it seems that i was wrong
07:08:32 <alinp> also [] monad
07:08:32 <koeien37> well, IO is a bit strange monad
07:08:34 <EvilTerran> IO is a bit of a weird one
07:08:34 <alinp> indeed
07:08:40 <Axman6> Lemmih: one reason for not using your bencode package is that it has no docs...
07:08:52 <alinp> I'm using this article: http://ertes.de/articles/monads.html
07:08:54 <koeien37> but you'll understand it, too :)
07:09:01 <mauke> is ST more or less weird than IO?
07:09:09 <koeien37> even weirder
07:09:11 <Lemmih> Axman6: Yeah, I pondered that myself. I don't understand why the haddock docs fail to build.
07:09:15 <EvilTerran> i'd say less weird
07:09:17 <alinp> what is ST ?
07:09:27 <mauke> alinp: a monad that gives you mutable variables
07:09:29 <EvilTerran> in that you could write it purely with a single unsafeCoerce
07:09:30 <koeien37> :t runST
07:09:31 <lambdabot> forall a. (forall s. ST s a) -> a
07:09:34 <alinp> oh
07:09:36 <alinp> as in STM
07:09:38 <koeien37> this is a quite strange type
07:09:41 <mauke> alinp: but it also has a run function that makes the whole computation pure
07:09:46 <alinp> is ST related to STM ?
07:09:49 <EvilTerran> alinp, no, STM is concurrency; ST is just mutable variables
07:09:50 <mauke> alinp: no
07:09:56 <alinp> ok
07:09:59 <Axman6> Lemmih: looked at http://hackage.haskell.org/packages/archive/bencode/0.5/logs/failure/ghc-6.10 ?
07:10:06 <mux> ST is sexy
07:10:10 <mauke> (software transactional memory vs. state thread)
07:10:17 <EvilTerran> STM is "software transactional memory"; ST is "state thread"
07:10:24 <alinp> ok ...
07:10:26 <mux> it's great when you want mutability for implementation a function efficiently, but still want it to be pure
07:10:29 <koeien37> yeah, the M doesn't mean Monad there
07:10:32 <mux> it allows you not to stick it into IO
07:10:33 <alinp> the names seems sort of the same :)
07:10:44 <mauke> historical reasons
07:10:57 <alinp> and also mutability it's a big stuff coming into threading context
07:11:05 <mux> :t runSTUArray
07:11:06 <koeien37> yes, I've used ST to directly translate imperative algorithms into Haskell, without tainting the rest of the program w/IO
07:11:06 <lambdabot> Not in scope: `runSTUArray'
07:11:07 <Lemmih> Axman6: Yeah, it compiles file but fails on haddock. Makes no sense to me.
07:11:16 <mux> :t runSTArray
07:11:17 <lambdabot> Not in scope: `runSTArray'
07:11:25 <alinp> ok, good to know that
07:11:41 <alinp> thanks guys
07:12:01 <alinp> like I said, it really helped me your explanations
07:12:13 <Axman6> Lemmih: also, i think your parser might suffer from the same problem we've run into, mainly that some of the parts of the file we're using to test don't map onto Chars i think
07:12:37 <koeien37> http://haskell.org/haskellwiki/Monads_as_computation
07:12:51 <koeien37> alinp: I like this article. but it may be a bit dense
07:12:52 <jlouis> Nowadays, torrent files have both a name and a UTF8 name
07:13:13 <alinp> yeah, I know that one too
07:13:19 <koeien37> http://haskell.org/haskellwiki/Monads_as_containers
07:13:20 <koeien37> and this one
07:13:22 <alinp> and indeed, seems to be a little dense
07:13:28 <Axman6> would be nice if we there were a Data.Text parser. i wonder if there is yet
07:13:39 <Lemmih> Axman6: All the more reason to make a working library available on hackage.
07:14:32 <koeien37> alinp: these are two ways to look at monads. It turns out that they are equivalent. Mathematicians like to think in terms of join and fmap, and Haskell programmers often use return and (>>=)
07:14:38 <alinp> I think I have one funny joke: "What happens in Monad, stays in Monad"
07:14:39 <alinp> :D
07:14:42 <mauke> > runST (do x <- newSTRef 0; forM_ [1 .. 100] $ \i -> modifySTRef x (+ i); readSTRef x)
07:14:43 <lambdabot>   5050
07:14:50 <mauke> bam!
07:15:12 <Jafet> > runST (do x <- newSTRef 0; forM_ [1 .. 10000] $ \i -> modifySTRef x (+ i); readSTRef x)
07:15:13 <lambdabot>   50005000
07:15:13 <jlouis> I think it would be beneficial to work towards using bencode / torrent and get them into the game.
07:15:21 <Jafet> > sum [1..10000]
07:15:22 <alinp> I think it's pretty appropriate to the >>= behavior ;)
07:15:22 <lambdabot>   50005000
07:15:26 <EvilTerran> koeien37, iirc, the join/fmap version needs return as well
07:15:34 <Jafet> > runST (do x <- newSTRef 0; forM_ [1 .. 100000] $ \i -> modifySTRef x (+ i); readSTRef x)
07:15:35 <lambdabot>   5000050000
07:15:40 <koeien37> EvilTerran: ah, yes, otherwise you can't inject anything
07:15:40 <Jafet> > sum [1..100000]
07:15:42 <lambdabot>   5000050000
07:15:55 <mux> Jafet: n * (n + 1) `div` 2?
07:15:57 <mux> :-)
07:16:14 <mux> closed formula > mutability :-P
07:16:16 <Jafet> Oh, missing a zero
07:16:19 <mux> (I know, this doesn't make any sense)
07:16:20 <Jafet> > sum [1..1000000]
07:16:22 <lambdabot>   * Exception: stack overflow
07:16:26 <Jafet> > runST (do x <- newSTRef 0; forM_ [1 .. 1000000] $ \i -> modifySTRef x (+ i); readSTRef x)
07:16:26 * EvilTerran quite likes the "functor (fmap); pointed (return); applicative(ap); monad (join/bind)" stack
07:16:29 <lambdabot>   * Exception: stack overflow
07:16:37 <Jafet> Durr hurr.
07:16:59 <mauke> > runST (do x <- newSTRef 0; forM_ [1 .. 1000000] $ \i -> modifySTRef x ((i +) $!); readSTRef x)
07:17:02 <lambdabot>   * Exception: stack overflow
07:17:13 <mux> > let foo n = n * (n + 1) `div` 2 in foo 1000000
07:17:14 <lambdabot>   500000500000
07:17:21 <koeien37> EvilTerran: yeah. definitely something for Haskell' imo
07:17:45 <deepix> can someone help me? http://pastie.org/753151
07:18:08 <koeien37> deepix: what is the type of aux ?
07:18:35 <mauke> btw, you're leaking a filehandle
07:18:36 <deepix> sorry   aux :: IO (String) -> [String]
07:18:45 <mauke> deepix: that type is impossible
07:18:47 <koeien37> that is a very strange function
07:18:54 <mauke> also, (String) better written as String
07:19:21 <koeien37> because aux is not going to do I/O itself.
07:19:26 <koeien37> since it returns [String]
07:19:42 <deepix> the error is exactly that     Couldn't match expected type `String'
07:19:42 <koeien37> it cannot use its argument. It will be a constant function
07:19:43 <deepix>            against inferred type `IO String'
07:19:54 <EvilTerran> mauke, aux = const [":P"]
07:20:01 <mux> haha
07:20:12 <mauke> EvilTerran: technically that's whatever -> [String]
07:20:30 <koeien37> deepix: yes. myBreakLines will be something like: do { x <- myReadFile; return (lines x) }
07:20:41 <mauke> EvilTerran: I can't think of a natural way to get an inferred type of IO (String) -> [String]
07:20:48 <EvilTerran> i could muck around with asTypeOf, i just chose not to for the sake of tersity
07:21:14 <mux> koeien37: that is "lines `fmap` myReadFile" return in a verbose way
07:21:23 <koeien37> mux: yep. or liftM
07:21:26 <mux> s/return/written/ -- I really need sleep
07:21:30 <deepix> koeien37, but i want use the return more times, so what you said will not work (i think)
07:21:44 <koeien37> deepix: you want to return more times??
07:22:14 <EvanR-work> return 'foo' >> return 'bar' ;)
07:22:17 <koeien37> "return" does something different then in most other programming languages
07:22:44 <aep> why do i get x :: IO Int when i do x <- f  where f :: IO [Int]  ?
07:22:49 <EvilTerran> deepix, after say "ls <- lines `fmap` myReadFile" in a do-block, ls will have the lines of the file in it; the action will only be run when the "ls <- ..." line is hit, and the value can be used repeatedly thereafter with no more side effects
07:22:52 <mauke> :t \x -> const [":P"] (x `asTypeOf` getLine)
07:22:53 <lambdabot> IO String -> [[Char]]
07:23:07 <koeien37> aep: then x is of type [Int].
07:23:14 <aep> nope. :(
07:23:14 <deepix> koeien37, yes, after that i will replacing characters to the list
07:23:15 <mauke> aep: you don't
07:23:40 <koeien37> deepix: good. Generally, you want very few functions to be of type IO something.
07:23:40 <aep> well when i try to use x in a map, it complains it cant match [a]  to infered type IO Int
07:23:56 <EvilTerran> aep, the type of x is being mis-inferred from elsewhere
07:23:56 <mauke> aep: then you did something wrong
07:23:57 <merijn> I'm trying to create a type synonym for a tuple "type myType a = (a,a)" later in my program it complains that it cannot deduce Eq a from context. How do I define my type so that it only holds for tuples that are comparable?
07:24:00 <koeien37> deepix: so I recommend to write those functions first, as pure functions
07:24:14 <mauke> merijn: you can't
07:24:27 <aep> actually i'm trying map (\s ->  show s) x
07:24:28 <koeien37> aep: we need more code
07:24:29 <EvilTerran> merijn, you can't; you can, however, add Eq a to the context
07:24:34 <aep> aye
07:24:55 <merijn> "function :: (Eq a) => functiontype"?
07:24:57 <EvilTerran> aep, for all f and x, (\x -> f x) = f :)
07:24:58 <deepix> koeien37, i already have them
07:25:12 <mauke> aep: is that the whole statement?
07:25:33 <koeien37> deepix: very good. then you will have a program that looks like do { x <- ... read file ...; putStrLn (pure_function x) }
07:25:43 <EvilTerran> (well, if x is a pattern that may fail, that's a refinement instead of an equality, but the idea is there)
07:26:04 <Gracenotes> well, if that typechecks in the first place, then for sure
07:26:10 <mauke> EvilTerran: what if f = undefined?
07:26:26 <deepix> koeien, look the all stuff http://pastie.org/753160
07:27:06 <koeien37> deepix: string2linst. This function has a very strange type
07:27:07 <Gracenotes> mauke: getting f in WHNF will yield a bzzzt, as will getting either applied to an argument.. I think
07:27:08 <EvilTerran> mauke, okok, maybe i should've said (\x -> f x) and f are mutually coherent (as in `lub` and the like)
07:27:24 <aep> http://codepad.org/iRVlOGqZ
07:27:32 <Gracenotes> actually, getting the first in WHNF should be fine. nevermind then.
07:27:35 <benmachine> cabal list cabal-install says Latest version installed: [ Not installed ]... what?
07:27:41 <Gracenotes> at least, Haskell's version of it
07:27:52 <koeien37> aep: map (\u -> show u) ul is not of the correct type. It should be of type IO a for some a
07:28:02 <deepix> koeien37, i know it shouldn't be there, it was just a test
07:28:13 <koeien37> deepix: well, that causes GHC to complain
07:28:16 <aep> koeien37: huh?
07:28:27 <koeien37> aep: it is in a do block
07:28:28 <benmachine> (and why does it download 0.6.4 instead of 0.8?)
07:28:31 <aep> oooh
07:28:47 <koeien37> aep: it should be a monadic value, in this case an IO value
07:29:12 <deepix> koeien37, i can comment them
07:29:13 <koeien37> deepix: ok
07:29:23 <aep> yeah of course.  thanks
07:29:40 <koeien37> deepix: yeah. your separaLinhas is of the wrong type. I would just use String -> [String] there. (or just use "lines")
07:30:21 <koeien37> you should only use "do" and <- notation for I/O values.
07:30:33 <koeien37> carefully determine for each function whether it is an I/O function, or not
07:30:41 <Saizan> benmachine: cabal-install doesn't keep track of executables
07:30:53 <Saizan> benmachine: and, maybe you're missing a cabal update?
07:30:53 <EvanR-work> only use do and <- for IO generally?
07:31:20 <benmachine> Saizan: I cabal updated a few times, but it wouldn't install 0.8 until I asked for it specifically
07:31:22 <koeien37> EvanR-work: no. for monads. I specialized it to IO now
07:31:25 <EvilTerran> EvanR-work, no; only use them for monadic stuff, if you want to be general
07:31:42 <koeien37> EvanR-work: in order not to confuse her/him any further :)
07:31:48 <EvanR-work> oh
07:32:03 <Saizan> benmachine: mh, something's weird, what command did you run specifically? did you use sudo?
07:32:06 <EvanR-work> so basically 'dont defined >>= in a non monadic context and proceed to use do notation' :)
07:32:25 <benmachine> sudo cabal install 'cabal-install>0.7'
07:33:12 <Saizan> benmachine: sudo cabal .. generally causes problems, "cabal install --global --root-cmd=sudo" instead
07:33:16 <deepix> koeien37, http://pastie.org/753172
07:33:34 <benmachine> hmph that is more typing
07:33:57 <merijn> I have the nagging feeling I should be able to do this using fold{l,r} (or some other standard function) but I can't figure out how: http://dpaste.com/136606/ (note: I don't really care whether it uses a list or some other collection)
07:34:26 <koeien37> deepix: I am not sure what you are trying to do (I don't speak Spanish (?)). But your separarLinhas function is not well-typed. The argument to separaLinhas is of type IO String, and that is not equal to String
07:34:37 <Saizan> you can put those in the ~/.cabal/config, "root-cmd: sudo" and "user-install: False"
07:34:48 <Saizan> benmachine: ^^
07:35:08 <koeien37> merijn: look at "take", "filter" and "map"
07:35:37 <benmachine> ah
07:35:42 <mux> merijn: as far as I can see, this is not expressible as a fold
07:35:45 <benmachine> thx2u
07:35:52 <koeien37> merijn: but I'm not entirely sure what your function does
07:36:06 <mux> merijn: but as proved by graham hutton, it's necessarily expressible as a fold + a small function
07:36:44 <deepix> koeien37, (Portugal), do you know how i should do it? i know that the type is different, but i don't know how to IO String -> String
07:36:57 <mux> you cannot have that
07:36:59 <koeien37> deepix: right. You can't. That's the point :)
07:37:07 <deepix> haa :(
07:37:19 <koeien37> functions in Haskell don't have side effects and are referentially transparent
07:37:19 <merijn> koeien37: It's returninga list of n values from collection p (where p is a list right now). But it doesn't necessarily return the first n so take, map and filter probably don't do me much good
07:37:22 <mux> deepix: you don't extract values out of IO, you push pure functions into the IO monad so that they act on IO foo instead
07:37:39 <mux> deepix: so you just want to push a String -> String function in your IO monad
07:37:39 <koeien37> deepix: what is the problem you are trying to solve ?
07:37:59 <deepix> there's a way of transforming the contents of a file into a string?
07:38:00 <mux> deepix: either with fmap, liftM or <$>, or explicitely using do notation
07:38:16 <mux> deepix: the contents of a file is a string to begin with when you use getContents
07:38:33 <koeien37> deepix: yes. do { x <- readFile "..." ; ... x ... }. Then x has the value String inside this do block
07:38:38 <koeien37> s/the value/the type
07:38:56 <koeien37> but the whole do-block is again of type IO something
07:39:24 <deepix> because i need to use IO to get the file location
07:39:38 <deepix> (sorry, very young on haskell :/ )
07:40:27 <koeien37> deepix: that is true. basically you use do-notation for IO, and no do-notation for pure functions. We try to make as many functions as possible pure, since they are easy to test and reason about
07:41:29 <koeien37> so, say you want to do a certain computation, like reversing all lines in a file. We then make a function f = unlines . map reverse . lines
07:42:01 <xerox> ?type interact
07:42:03 <lambdabot> (String -> String) -> IO ()
07:42:05 <koeien37> and then something like main = do { putStrLn "Enter filename."; filename <- getLine; content <- readFile filename; putStrLn (f content) }
07:42:16 <xerox> that makes it easy, you then pipe the file in stdin
07:42:34 <koeien37> xerox: yeah, if you can use interact, it's perfect.
07:42:50 <xerox> (I didn't read the whole discussion)
07:43:26 <deepix> koeien37, yes, i'm getting the point, but i really need to do a lot of things with the contents of the file
07:44:24 <luite> deepix: then you make f more complicated
07:44:26 <luite> :)
07:44:45 <koeien37> deepix: do you need to do other I/O, like making network connections? If not, you can do what you want without using I/O except for the one function lerFicheiro you just defined (modulo a small modification)
07:45:12 <deepix> koeien37, like this replace http://pastie.org/753186
07:45:34 <koeien37> that is a very nice pure function, although you can write it as a map
07:45:43 * hackagebot upload: storable-tuple 0.0.2 - Storable instance for pairs and triples (HenningThielemann)
07:46:24 <koeien37> and a more natural ordering of the arguments would be: replace a b xs
07:46:43 <deepix> from IO i think i only need user interaction
07:46:56 <koeien37> then you can easily compose it, e.g.   replace 'a' 'x' . replace 'È©¨' 'Áâõ'
07:47:02 <aep> can i combine a list and a monad to another list?  sort of use the monad as filter
07:47:21 <koeien37> :t filterM -- aep ?
07:47:21 <lambdabot> forall a (m :: * -> *). (Monad m) => (a -> m Bool) -> [a] -> m [a]
07:47:27 <aep> nice. thanks
07:48:41 <aep> hm no, not that. filter was the wrong word
07:48:58 <koeien37> aep: yeah, you were a bit vague. Can you think of the type your function should have?
07:49:28 <aep> i have an infinite list :: [Int] , and a function  f :: Int -> IO String  and i want the resulting list top be an infinite list :: [String]
07:49:53 <koeien37> :t mapM
07:49:54 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
07:50:09 <koeien37> although you should be careful with infinite lists here
07:50:31 <aep> yeah i wasnt sure how lazy eavluatzion works there
07:50:56 <Saizan> aep: you can't really do that, because IO side-effects aren't lazily executed
07:51:04 <Saizan> aep: unless you use unsafeInterleaveIO
07:51:06 <aep> yeah :(
07:51:32 <aep> its a const C function, so it has no side effects ( i hope)
07:51:47 <koeien37> oh. Then you are "allowed" to use unsafePerformIO
07:51:51 <Saizan> you can FFI import it with a pure ty√®e
07:51:54 <quicksilver> the you are probably justified in importing it pure
07:51:54 <Saizan> *type
07:51:57 <koeien37> or import FFI pure, yeah
07:52:07 <aep> Saizan: result String instead of IO String?
07:52:14 <koeien37> yeah
07:52:15 <aep> didnt know thats possible. thanks
07:52:35 <Saizan> though i'm not sure if you can really use String directly for ffi imports?
07:52:47 <aep> no you can't. but i have a wrapper
07:54:08 <aep> err no, it DOES have side effects. it reads from a buffer
07:54:21 <aep> hence calling it multiple times yields different results
07:55:20 <aep> the buffer is not truly infinite, but i dont want to read it completely (that'd take minutes) but rather display results in chunks
07:55:51 <aep> i'll just try map..
07:55:58 <Saizan> mapM
07:56:19 <Saizan> you can process the resulting String's one at a time
07:56:41 <Saizan> mapM (\x -> do s <- f x; .. do something with s ..) infiniteListHere
07:57:02 <pozic> How can I do foldM with an escape action?
07:57:05 <Saizan> or mapM_ maybe
07:57:21 <Saizan> pozic: exceptions/continuations
07:57:35 <aep> nah i want mapM. since i want to use split.chunk on the result
07:57:50 <aep> in the hopes it will only run the monad on the input it needs
07:57:52 <pozic> Saizan: runErrorT and so on. I would like to have something already in some library which does this.
07:58:02 <Saizan> aep: it will run all the side effects
07:58:19 <aep> that's fine.
08:00:15 <aep> um. mapM expects the inner function to return a monad again oO  i have a string
08:00:26 <aep> a pure string
08:00:35 * aep confused
08:00:39 * aep pastes code
08:00:44 <EvanR-work> it performs a list of actions
08:01:08 <EvanR-work> if the action was to read a file, it reads those files and returns IO String
08:01:13 <EvanR-work> a list of
08:01:17 <EvanR-work> something...
08:02:09 <EvanR-work> :t mapM
08:02:10 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
08:02:15 <EvanR-work> IO [String]
08:03:18 <ziman> mapM merges multiple IO actions in one that, when performed, executes them all and returns a list of their results
08:03:44 <ziman> well, in the case of IO; mapM works on other monads as well
08:05:07 <aep> more useful description with code: http://codepad.org/c5MVK9VK
08:05:59 <ziman> aep, you can write (\x -> return $ toString x)
08:06:10 <ziman> if i'm reading that correctly
08:06:16 <aep> hmm
08:06:40 <ziman> return lifts a pure value into a monad, for example:
08:06:51 <ziman> :t return :: String -> IO String
08:06:52 <lambdabot> String -> IO String
08:06:53 <aep> ah!
08:07:05 <aep> :t mapM
08:07:06 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
08:07:28 <aep> hm. ok now when i run the result of map, i get the entire list :/
08:07:46 <ziman> and what do you want to get?
08:07:59 <aep> well its "infinite", so i want to use take or chunk
08:08:12 <aep> (its not really infinite, but quite big)
08:08:16 <EvanR-work> aep: you want the lines of a file? dont use mapM
08:08:25 <EvanR-work> 1024 byte chunks?
08:08:29 <aep> similar. its imap
08:08:36 <aep> no, pages of lines
08:08:47 <Phyx-> Hi, anyone know what's up with hackage these days?
08:09:04 <aep> fetch is the action that will take an emails uid and return the mail
08:09:05 <EvanR-work> then make a function pages that takes the entire contents and returns a list of pages
08:09:10 * jneira reading http://blog.sigfpe.com/2007/11/io-monad-for-people-who-simply-dont.html
08:09:19 <EvanR-work> then laziness takes over
08:09:36 <aep> EvanR-work: you mean filter _before_ executing the action?
08:10:00 <EvanR-work> pages of uids?
08:10:06 <aep> that'll work yeah.
08:10:13 <EvanR-work> okay :S
08:10:18 <aep> i was under the impression haskell is all about chaining list operations
08:10:23 <Stinger> > take 4 . map (+1) $ [1..]
08:10:24 <lambdabot>   [2,3,4,5]
08:10:26 <aep> so i tried :/
08:10:35 <aep> Stinger: yeah like that!  but with monads. heh
08:10:50 <copumpkin> > take 4 $ (+1) . [1..]
08:10:52 <lambdabot>   [2,3,4,5]
08:10:53 * copumpkin coughs
08:10:58 <EvanR-work> you dont need monads for this...
08:11:18 <aep> i already have one. instead of (+1)
08:11:19 <ziman> copumpkin, haha
08:11:19 <jneira> uf
08:11:32 <EvanR-work> aep: you mean a function
08:11:36 <copumpkin> :)
08:11:41 <Phyx-> is hackage foobared or is it just me?
08:11:55 <ziman> Phyx-, hackage seems to work here
08:11:58 <aep> EvanR-work: i have fetch :: Int -> IO ByteString
08:12:16 <jneira> :t (+1) . [1..]
08:12:17 <lambdabot> forall a. (Num a, Enum a) => [a]
08:12:19 <Phyx-> ziman: well, some documentation links are missing, and cabal-install fails with a stream error
08:12:23 <EvanR-work> aep: thats not a monad
08:12:31 <ziman> Phyx-, i'm just browsing the docs of a random hackage package
08:12:32 <aep> EvanR-work: oh
08:12:33 <EvanR-work> its a function that returns an action
08:12:45 <aep> EvanR-work: ok. i have that :D
08:13:01 <ziman> Phyx-, oh, some doc links have always missed (no clue why), and I haven't tried cabal0intall recently
08:13:06 <Phyx-> ziman: well, for instance, if you search on hoogle, anything in the base package will be missing after you click on it. it takes you to a hackage page and gives 404
08:13:06 <EvanR-work> aep: so mapM fetch uids
08:13:21 <aep> EvanR-work: then i can't use take.
08:13:26 <EvanR-work> yes you can
08:13:32 <jneira> :t [1..]
08:13:34 <lambdabot> forall t. (Num t, Enum t) => [t]
08:13:38 <Phyx-> does cabal update work for anyone?
08:13:42 <ziman> Phyx-, yeah but that's not hackage, i think
08:13:45 <EvanR-work> take 5 (mapM fetch uids)
08:13:56 <EvanR-work> err
08:13:59 <aep> nope :P
08:14:05 <EvanR-work> emails <- mapM fetch uids
08:14:08 <EvanR-work> take 5 emails
08:14:08 <aep> mapM  returns m [a]  not [m a]
08:14:20 <ziman> Phyx-, hoogle uses wrong links
08:14:21 <aep> nope.  emails are ALL of them
08:14:24 <aep> its not lazy
08:14:31 <ziman> Phyx-, http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html is wrong; http://haskell.org/ghc/docs/latest/html/libraries/base-4.2.0.0/Prelude.html is correct
08:14:31 <EvanR-work> no
08:14:39 <EvanR-work> aep: it returns actions that get emails
08:14:43 <EvanR-work> ...
08:14:47 <EvanR-work> :S
08:14:51 <Phyx-> ziman: hmm ok
08:14:54 <EvanR-work> why wouldnt it be lazy
08:14:59 <aep> i read  m [a]  as  "it returns an actiuon that gets a list of mails"
08:15:08 <Phyx-> ziman: so somewhere along the line the url changed
08:15:14 <aep> i dunno. i did exactly what you said and it fetches them all
08:15:21 <EvanR-work> the entire list? getContents gets a lazy list of file contents
08:15:22 <ziman> Phyx-, yes, i suppose so
08:15:33 <EvanR-work> aep: because you evaluated the entire list
08:15:40 <Phyx-> ziman: but the more annoying problem i have is this "cabal: Codec.Compression.Zlib: premature end of compressed stream"
08:15:52 <Stinger> copumpkin, whats going on there, that doesnt work in my ghci
08:15:59 <ziman> Phyx-, what package are you trying to install?
08:16:01 <copumpkin> Stinger: Caleskell
08:16:08 <copumpkin> Stinger: (.) = fmap on lambdabot
08:16:10 <Phyx-> ziman: none, i'm trying to first do an update
08:16:12 <aep> EvanR-work: nope.  even emails <- mapM fetch uids  gets them all. without even looking at the list
08:16:25 <EvanR-work> how would you know?
08:16:30 <aep> i just tried
08:16:32 <Stinger> okay right, thought I was going mad
08:16:33 <EvanR-work> tried what
08:16:40 <aep> exactly that code
08:16:45 <EvanR-work> ... looking at the result??
08:16:48 <aep> no
08:16:55 <copumpkin> :)
08:16:59 <ziman> Phyx-, hm, cabal update seems to work okay here
08:17:08 <aep> EvanR-work: i see it in tcpdump
08:17:25 * Raynes slaps copumpkin with a pumpkin.
08:17:45 <Phyx-> ziman: then i'm confused
08:17:52 <Stinger> so does that work for normal functions cause of reader monad then?
08:19:11 <Phyx-> ziman: my cabal 0.6.2 seems to work, but cabal 0.7.5 gives the error
08:19:18 <aep> EvanR-work: i'll make a testcase.  hang on ;)
08:19:21 <EvanR-work> aep: when you bind the list of actions to main, it executes them
08:19:45 <aep> really?  that might explain it
08:19:45 <EvanR-work> aep: use a different code. xs <- mapM..., then show x one at a time
08:20:20 <EvanR-work> with a threadDelay or something
08:20:22 <aep> umm. but whats the difference between xs and x there?
08:20:41 <EvanR-work> dunno. x is one of them
08:20:54 <aep> i have something like main = do  x <- mapM   fetch list
08:21:20 <aep> and you're saying my problem is that x is evaluated because its bound to main., right?
08:21:22 <EvanR-work> so for each x, do print x; threadDelay 1000000;
08:21:46 <EvanR-work> aep: i put xs to mean a lsit
08:21:58 <aep> uh whats a lsit?
08:22:02 <EvanR-work> list
08:22:06 <aep> oh. heh
08:22:17 <aep> yeah i have that.
08:22:19 <Axman6> jlouis: still around?
08:22:25 <aep> let me make a testcase to show you
08:22:25 <ziman> Phyx-, i've got the 0.6.2
08:22:47 <ketil> does ghc print out the current profiling info if a program is interrupted?
08:22:51 <Phyx-> ziman: yeah, i got both since i need  the 0.7.5 for ghc 6.12
08:22:58 <EvanR-work> let loop (x:xs) = do print x; threadDelay 10^6; loop xs; in do emails <- mapM fetch uids; loop emails
08:23:02 <Phyx-> i'll see if the darcs version has been updated
08:23:06 <ziman> Phyx-, ..and i don't have ghc-6.12 :)
08:23:11 <EvanR-work> aep: probably a better way to write that, but im new
08:23:27 <Phyx-> ziman: i need it, for a bug fixed in it
08:24:39 <jneira> "If something is of type IO a then it's a command returning an value of type a. Otherwise it's an expression. That's the rule"
08:24:54 <jneira> is that the rule?
08:25:07 <EvanR-work> sounds like barber of seville or something ;)
08:25:38 <Axman6> Phyx-: you talking about cabal-install?
08:25:38 <EvanR-work> jneira: its an action that when executed does something and returns something of type a
08:26:05 <Phyx-> Axman6: yup, getting a weird error from it
08:26:36 <Saizan> Phyx-: there's a released 0.8 that works with 6.12, you should use that
08:26:37 <jneira> command=an action that when executed does something
08:26:46 <jneira> i think..
08:27:06 <jneira> monads are easy!! :-P
08:27:12 <Phyx-> Saizan: the binary on http://www.haskell.org/cabal/download.html is still pointing to 0.6.2
08:27:33 <Saizan> ?hackage cabal-install
08:27:33 <lambdabot> http://hackage.haskell.org/package/cabal-install
08:27:35 <Axman6> Phyx-: on 6.12.1? if so, you need to use cabal install 'cabal-install >= 0.8'
08:28:07 <EvanR-work> jneira: well a doesnt get returns until executed, i think it needs to be spelled out
08:28:15 <Saizan> except that with cabal update not working..
08:28:17 <EvanR-work> because i might think the command is immediately executed
08:28:49 <Phyx-> Saizan: yeah, i'll grab the source by hand and recompile
08:30:29 <jneira> jum
08:32:32 <EvanR-work> :t getContents
08:32:32 <lambdabot> IO String
08:32:41 <EvanR-work> :t String
08:32:42 <lambdabot> Not in scope: data constructor `String'
08:32:48 <koeien37> String is not a value
08:32:48 <EvanR-work> :i String
08:32:53 <aep> EvanR-work: main = mapM (\x -> getLine)   [1..]  >>= (\x -> putStrLn $ take 1 x !! 0)
08:33:03 <koeien37> type String = [Char]
08:33:23 <aep> EvanR-work: acording to you, that will read one line and print it. unfortunately not true
08:33:30 <EvanR-work> aep: what i pasted was a more direct test of your particular actions
08:33:55 <aep> well that reproduces it.  its the same thing
08:34:00 <EvanR-work> ...
08:34:05 <aep> hm√ü
08:34:07 <aep> ?
08:34:15 <EvanR-work> im not a fan of testing a particular thing with something totally different
08:34:31 <aep> um. its called a testcase. but sure, i can send you the entire code
08:34:43 <EvanR-work> aep: use my code dammit.
08:34:47 <aep> i did
08:34:55 <EvanR-work> your thing doesnt have a delay, how would you even tell if its happened all at once or not
08:35:31 <aep> by seeing that it never ends readLine and never prints anything
08:35:43 <EvanR-work> use my code.
08:35:48 <EvanR-work> that is to say, what i wrote
08:35:50 <EvanR-work> above
08:36:04 <aep> i did.
08:36:10 <EvanR-work> fetch the list of emails, then slowly print them out
08:36:17 <EvanR-work> then look at your tcpdump
08:36:28 <aep> i did
08:36:43 <EvanR-work> 'by seeing that it never ends readLine' ?
08:36:49 <aep> nothing is printed the first 10 minutes, and tcpdump shows high traffic
08:36:52 <aep> then i got tired of waiting
08:37:17 <EvanR-work> great
08:38:04 <aep> does that convince you? :P
08:38:26 <aep> that's why i made a testcase, so you can just smack it into ghci and see for yourself
08:38:33 <EvanR-work> no you made no sense
08:38:52 <aep> what else do you need?
08:39:09 <EvanR-work> threadDelay 10^6, so each second it should print an email
08:39:14 <EvanR-work> if that didnt happen, you did it wrong
08:39:20 <aep> it doesnt, the first 10 minutes, as i said
08:39:27 <EvanR-work> then you did it wrong
08:39:38 <aep> i'm certain i did it wrong, thats why i am asking for help
08:39:44 <EvanR-work> >_<
08:40:26 <EvanR-work> try printing the contents of some other list slowly
08:40:34 <EvanR-work> then go back to the emails, then get that to work
08:40:37 <EvanR-work> then look at tcpdump
08:41:12 <aep> well, "some other list" will of course work, if the list is finite and already fetched in memory
08:41:31 <EvanR-work> then you the result of getContents instead, its the same thing
08:41:34 <EvanR-work> then use*
08:41:37 <aep> i've got an infinite, not fetched list, and delaying an operation that is never executed has no effect
08:41:50 <EvanR-work> of course it does
08:42:18 <aep> um i though haskell code is executes sequentially. even with lazy fetch
08:42:18 <EvanR-work> the point is that an infinite list semantically behaves the same as a finite list, except sometimes the thread will block if the next thing isnt available
08:42:37 <EvanR-work> and even finite lists dont have to be fully computed
08:42:40 <aep> it blocks in <-
08:42:56 <EvanR-work> are you sure? then it means you have network problems
08:42:59 <aep> a simple putStrLn after <- is never executed
08:43:09 <aep> yes downloading 60Gb mail will take a while
08:43:23 <EvanR-work> while blocking you see high traffic?
08:43:23 <Phyx-> i'm getting an error when compiling network 2.2.1.5 "Network\Socket.hsc:737:6: Not in scope: `writeRawBufferPtr'"
08:43:26 <aep> thats why i dont want to download ALL of them
08:43:29 <Phyx-> anyone know what's up with that?
08:44:27 <EvanR-work> aep: so while blocking it shows high traffic, as if it gettings them all
08:44:49 <EvanR-work> @src mapM
08:44:49 <aep> EvanR-work: i think we have a slight misunderstanding? the code you showed will work of course, except it takes a very long time to download the entire mailbox before i can access the list. what i wanted is use lazy evaluation for the actual _fetching_ of mails
08:44:49 <lambdabot> mapM f as = sequence (map f as)
08:44:52 <aep> EvanR-work: yes
08:45:02 <EvanR-work> @src sequence
08:45:02 <lambdabot> sequence []     = return []
08:45:03 <lambdabot> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs)
08:45:03 <lambdabot> --OR
08:45:03 <lambdabot> sequence xs = foldr (liftM2 (:)) (return []) xs
08:45:17 <EvanR-work> aep: see these functions build a list, applying 'fetch' in sequence
08:45:24 <EvanR-work> it shouldnt for no reason do all of them
08:45:29 <aep> aye
08:45:48 <EvanR-work> unless were using some sort of strict flag
08:46:09 <aep> well i'm still guessing  [m a] is not the same as m [a]
08:46:14 <EvanR-work> it isnt
08:46:21 <aep> but yeah, i'm a noob so i wouldnt know
08:46:26 <EvanR-work> but mapM does the above, so it build the [a] one by one
08:46:42 <EvanR-work> like getContents which returns [Char]
08:46:47 <EvanR-work> IO [Char]
08:47:35 <EvanR-work> aep: im basically a noob too. anyway, i would do more tests with mapM and IO, but i have work ._.
08:47:36 <aep> actually sequence looks like a loop to me. odd
08:47:43 <EvanR-work> its a loop
08:47:51 <EvanR-work> recursive definition
08:47:55 <aep> yeah, so it loops over all input before returning
08:48:00 <EvanR-work> lots of lists are constructed like that
08:48:04 <EvanR-work> no it doesnt
08:48:09 <zygoloid> sequence basically 'does' each thing in the list, and produces the list of results. for some monad-specific value of 'does' and 'produces'
08:48:26 <aep> yeah that we agree on.  just not when it "does" it :D
08:48:39 <EvanR-work> let ones = 1 : ones
08:48:48 <EvanR-work> thats what sequence looks like to me
08:48:59 <aep> aye
08:49:00 <copumpkin> > let lotsofones = 1 : lotsofones in lotsofones
08:49:01 <EvanR-work> which does not 'loop'
08:49:02 <lambdabot>   [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...
08:49:30 <copumpkin> > fix ("monkey":)
08:49:31 <lambdabot>   ["monkey","monkey","monkey","monkey","monkey","monkey","monkey","monkey","m...
08:49:34 <zygoloid> > sequence ([Just 1, Just 2, Nothing, Just 3] ++ cycle [Just 0])
08:49:35 <lambdabot>   Nothing
08:49:48 <zygoloid> ^^ this doesn't loop over each item in the list, in some sense.
08:50:00 <Axman6> cycle [x] = repeat x
08:50:13 <copumpkin> > sequence [[1,2,3], [2,3], []]
08:50:15 <lambdabot>   []
08:50:22 <aep> well as i said, this loops for ever for me and never reaches the second action:  http://codepad.org/QtbzvMhI
08:50:49 <EvanR-work> thats bad
08:50:57 <EvanR-work> bbl
08:51:03 <zygoloid> aep: well, yes, that would. IO is ordered, and you've ordered infinitely many getLines before anything else
08:51:14 <aep> exactly my point
08:51:27 <zygoloid> aep: right, but that's the nature of IO, not of sequence.
08:51:28 <EvanR-work> aep: paste my test case
08:51:31 <aep> a second ago i was told map doesnt do that
08:51:37 <aep> EvanR-work: you had a testcase?
08:51:42 <EvanR-work> aep: YES!
08:51:51 <EvanR-work> >_<
08:51:57 <aep> sorry, didn't see it then
08:51:58 <Phyx-> anyone gotten network to compile on 6.12?
08:52:12 <aep> other then the threadsleep. which isnt a testcase
08:52:13 <EvanR-work> 10:20 < EvanR-work> let loop (x:xs) = do print x; threadDelay 10^6; loop xs; in do emails <- mapM fetch uids; loop emails
08:52:28 <zygoloid> aep: mapM is exactly the same. in some monads, an 'infinite' chain of >>=s, associated correctly, can produce results. IO is not such a monad.
08:52:32 <aep> EvanR-work: thats not a testcase
08:52:39 <EvanR-work> yes it is
08:52:50 <EvanR-work> why dont you friggin try it
08:52:57 <aep> zygoloid: i see. so the answer is, i can't do it with IO
08:53:14 <aep> EvanR-work: i did. i said that multiple times
08:53:17 <zygoloid> aep: not without using another combinator which allows that sort of shenanigans, such as unsafeInterleaveIO or forkIO
08:53:28 <EvanR-work> zygoloid: the issue is that he is trying to get a lazy list of results of fetch :: IO String
08:53:41 <EvanR-work> why wouldnt mapM work
08:53:54 <ryo_hazuki> hey guys...
08:54:02 <zygoloid> EvanR-work: the IO monad is deterministically ordered (by default)
08:54:18 <EvanR-work> the resulting list is ordered too
08:54:23 <EvanR-work> >_<
08:54:32 <ryo_hazuki> is it possible to use case(lookup x xs) of ... with sets and tuples (xs is the set with (x,y)(x,y)...)
08:54:47 <doserj> zygoloid: the matter is not ordering, but that the IO monad (i.e., bind in the IO monad) is strict
08:55:00 <EvanR-work> 'the IO monad is strict' <---- ah.
08:55:16 <EvanR-work> so getContents is a fluke
08:55:22 <zygoloid> EvanR-work: right, but you want to defer an IO action (such as reading something) until that thing is used by pure code. and that violates referential transparency.
08:55:40 <doserj> getContents is using unsafeInterleaveIO under the hood
08:55:41 <zygoloid> EvanR-work: yes. getContents internally uses unsafeInterleaveIO to get its weird semantics.
08:56:00 <Peaker> ListT or Iteratee can be used instead
08:56:45 <aep> so my get function likely has no side effects.  should i use unsafeInterleaveIO  or should i just use a classical imperative for loop ?
08:56:56 <aep> s/function/monad
08:57:08 <aep> s/monad/action
08:57:10 <zygoloid> doserj: strictness of bind isn't the issue. if i write (replicateM 2 getLine >>= print), both the left and right hand sides can be `seq`d as much or as little as you like with no change of semantics.
08:58:06 <aep>  huh. haskell.org down?
08:58:41 <Asztal> aep: not for me
08:59:08 <syntaxfree> not for me either.
08:59:18 <aep> D:
08:59:29 <Asztal> http://www.downforeveryoneorjustme.com/haskell.org :)
08:59:47 <burp> lol nice domain
08:59:57 <aep> right the site works. just not http://www.haskell.org/ghc/docs/latest/html/libraries/base/System-IO-Unsafe.html
09:00:00 <syntaxfree> many smileys are revertible, such as ( :. :D isn't one of them.
09:00:19 <syntaxfree> further debate of the smiley reversibility issue should be conducted on #haskell-blah, though.
09:03:58 <zygoloid> aep: http://www.haskell.org/ghc/docs/6.12.1/html/libraries/base-4.2.0.0/System-IO-Unsafe.html
09:05:02 <aep> yeah thanks
09:06:00 <syntaxfree> so I'm trying to "learn" substructural logic. any hints on how to proceed, besides getting Jean-Yves Girard's classic papers?
09:07:10 <Phyx-> Saizan: ok, i updated cabal, and i still get it
09:07:25 <Phyx-> Saizan: "cabal: Codec.Compression.Zlib: premature end of compressed stream"
09:09:48 <EvanR-work> a lot of googles results of haskell docs are broken
09:10:45 <Phyx-> ah screw it, i'll get the new package by hand
09:15:31 <aep> wew ok unsafePerformIO _does_ what i expected it to do in the first place
09:15:47 <aep> it evaluates the action when the result is needed
09:16:07 <aep> i still don't understand why it doesn't do that anyway though
09:16:29 <EvanR-work> since performing IO actions can do anything, it might break your functional semantics
09:16:46 <aep> hm
09:16:52 <EvanR-work> its safe if you do IO while in the IO monad
09:17:19 <aep> good :)
09:17:23 <aep> thanks alot
09:17:40 <EvanR-work> which explains why you cant do what i thought was possible and 'perform' and IO action within the bowels of the sequence function
09:17:47 <EvanR-work> s/and/an/
09:17:48 <syntaxfree> it's safe if you use the same compiler with the same nonstandard semantics always. Probably GHC will always handle the unsafe stuff the same.
09:17:50 <pikhq> unsafePerformIO is one of those tricks that can be useful, but is sure to break if you do it wrong.
09:18:30 <pikhq> Mostly make your program function somewhat different from what you thought.
09:18:32 <syntaxfree> isn't the need for unsafe IO a sign that you might want to use some other tool?
09:18:34 <Peaker> If you prove some composition of impure IO actions is pure (has no visible outside effects), it makes sense to use it
09:18:47 <pikhq> foo = unsafePerformIO launchTheMissiles
09:19:00 <pikhq> syntaxfree: Not necessarily...
09:19:18 <pikhq> unsafePerformIO someCFunctionThatIsActually100PercentTotallyPure
09:19:20 <syntaxfree> I asked that tentatively. I'm speculating.
09:19:28 <EvanR-work> Peaker: an http request (or imap in this case) counts as having an outside effect?
09:19:36 <quicksilver> syntaxfree: it's safe in any compiler if you obey the proof obligation
09:19:36 <syntaxfree> oh, ok. But that's just interfacing.
09:19:49 <pikhq> Trivial example.
09:19:52 <aep> quicksilver: whats that?
09:19:55 <quicksilver> syntaxfree: namely that it makes no difference to the semantics of your program if the effects occur zero, one, or many times.
09:20:06 <aep> ah
09:20:10 * hackagebot upload: dom-lt 0.1.2 - The Lengauer-Tarjan graph dominators algorithm. (MattMorrow)
09:20:12 * hackagebot upload: haddock 2.6.0 - A documentation-generation tool for Haskell libraries (DavidWaern)
09:20:23 <syntaxfree> quicksilver: oh. ok.
09:20:59 <aep> so i can unsafe on anything that obeys that rule?
09:21:12 <Phyx-> is Text.Regex only in regex-compat? that won't install on 6.12 :s
09:21:21 <pikhq> aep: Yes.
09:21:28 <aep> nice
09:21:48 <pikhq> Maybe you shouldn't do so, but it's at least not going to break if you squint at it wrong.
09:21:59 <aep> whats the alnterative?
09:22:15 <EvanR-work> but isnt downloading something an 'outside effect'
09:22:38 <aep> yes, but it doesnt matter if it is executed multiple times. neither in what order etc
09:22:47 <pikhq> unsafePerformIO launchTheMissiles
09:22:58 <Axman6> @tell jlouis I managed to get everything working using ByteStrings :D (ie, you can run cabal configure; cabal build, and it all compiles correctly, and seems to be able to parse torrent files just fine). I think i'll eventually release the Builder/Parser package as my own, because i've made it into a pretty powerful ByteString parser package
09:22:58 <lambdabot> Consider it noted.
09:23:12 <doserj> aep: if it doesn't matter, why are you downloading at all?
09:23:26 <Vulpyne> ByteString parser package?
09:23:28 * Vulpyne perks up.
09:23:30 <Axman6> yup
09:23:33 <aep> doserj: um?
09:23:41 <mmorrow> EvanR-work: depends of the abstraction(s) you've built
09:23:43 <Vulpyne> This is relevant to my interests.
09:24:03 <Axman6> Vulpyne: http://github.com/axman6/haskell-torrent/blob/master/src/Data/ByteString/Parser.hs
09:24:09 <Vulpyne> It made me sad when I found that parsec could only consume ByteStrings.
09:24:14 <Vulpyne> Thanks, I will have to take a look at that.
09:24:41 <Jedai> Vulpyne: parsec 3 can parse bytestrings
09:24:49 <Vulpyne> Jedai: It consumes them.
09:25:07 <Jedai> What do you mean by that ?
09:25:08 <quicksilver> aep: it must surely matter if it doesn't occur at all.
09:25:09 <Vulpyne> Jedai: But something like "many anyChar" results in a [Char]
09:25:12 <quicksilver> aep: otherwise why are you downloading it?
09:25:24 <quicksilver> aep: therefore, you don't meet the proof obligation.
09:25:29 <Axman6> Vulpyne: the code is stolen from the HCodecs package, where it really shouldn't have been (the parser is far more useful than the rest of the package imo), and i've added a few common functions, like many, many1, count
09:25:36 <aep> quicksilver: ooh i see.
09:25:51 <Jedai> Vulpyne: oh, that's just a question of definition of many
09:25:52 <Vulpyne> Axman6: Have you done any sort of performance testing compared to say Parsec?
09:26:00 <aep> hm if if it includes "may never happen". whats the point of it then?
09:26:01 <Axman6> none at all :)
09:26:19 <Vulpyne> Jedai: Well, when you're writing a parser, pretty much everything uses many or other things that result in multiples of the token type.
09:26:27 <aep> i dont care _when_ it happens, as long as the data is available when it is used
09:26:30 <Axman6> the only reason this is here is because it was necessary to stop using parsec because we couldn't read in torrent files as strings
09:26:46 <Vulpyne> You could only read them in as ByteStrings?
09:26:54 <Axman6> yeah
09:27:01 <Jedai> Vulpyne: you could write a version of many specialized on Char (or Word8 rather) that produce a ByteString
09:27:02 <pikhq> aep: Then you should probably do it in IO, using the nice concurrency primitives?
09:27:08 <Vulpyne> You could have used Parsec3, but it still would have resulted in you getting [Char] back. :(
09:27:11 <Axman6> getcontents wasn't happy with some of the bytes
09:27:15 <pikhq> Or (even simpler) just do it and then continue on executing?
09:27:20 <Vulpyne> Jedai: Or I could just wait for someone like Axman to do the work for me. :)
09:27:25 <Axman6> yeah, not really after Strings anymore
09:27:37 <Peaker> EvanR-work: An HTTP request is a visible external effect, yeah
09:27:38 <ryo_hazuki> how to use maximumBy on lists with tuples? i want to compare the snd in the tuples and find the maximum
09:27:49 <aep> pikhq: yeah, in C i would just write a state engine  (note down the position i was at, then later continue).  i was under the impression haskell works different
09:27:51 <Peaker> EvanR-work: Unless the HTTP request is internal to the implementation black box
09:28:04 <Jedai> Vulpyne: ok, but parsec isn't innately limited in its application to ByteString
09:28:12 <syntaxfree> ryo_hazuki You can always use curry and uncurry
09:28:16 <syntaxfree> :t curry
09:28:17 <lambdabot> forall a b c. ((a, b) -> c) -> a -> b -> c
09:28:21 <syntaxfree> :t uncurry
09:28:22 <lambdabot> forall a b c. (a -> b -> c) -> (a, b) -> c
09:28:24 <Jedai> Vulpyne: it just doesn't provide convenient functions to handle the√π
09:28:50 <quicksilver> aep: Right. then the action honestly isn't pure so you shouldn't try to unsafePerformIO it.
09:28:56 <Vulpyne> Jedai: Well, I'd consider the combinators to be pretty core to Parsec...
09:28:58 <aep> quicksilver: aye
09:28:58 <quicksilver> aep: you should just model it correctly in IO
09:29:13 <aep> quicksilver: applying the same logic as i'd use in C?
09:29:28 <aep> ("imperative programing" i think)
09:29:42 <pikhq> aep: Roughly.
09:29:56 <Jedai> Vulpyne: Not really, why ?
09:29:58 <Vulpyne> Jedai: If you're writing a parser, and you can't use string, many, many1, between, endBy, etc, you're pretty limited.
09:30:11 <aep> okay, so haskell is more a mix of pure and impure and actions are bridges?
09:30:22 <Jedai> Vulpyne: that's just a specialization of Parsec for [Char]
09:30:25 <ryo_hazuki> any other chance to use maximumBy ((max) . snd) or something similar?
09:30:38 <Axman6> aep: technically, it's all pure (but ghc cheats)
09:30:41 <mmorrow> i've found also that if you're going to use unsafePerformIO for non-trivial IO actions (i.e. not just a single function call or similar), it's best to do /everything/ in IO (or a FooT IO wrapper monad), then put a single unsafePerformIO at the very top
09:30:46 <aep> hehe
09:30:48 <mmorrow> stuff like
09:30:57 <pikhq> aep: Technically, it's all pure. main just evaluates to impure stuff. :P
09:30:57 <Vulpyne> Jedai: It's because there parser is for a token type, and it spits out lists of that token type for many and such.
09:31:04 <syntaxfree> aep: What is this, enhanced interrogation? IO is impure by definition. Haskell is pure, and when it has to contact IO, it shrouds IO in decent clothes.
09:31:07 <Jedai> Vulpyne: I agree that it's not convenient not to have the same combinators for ByteString, but it's not a technical limitation
09:31:08 <mmorrow> ... let x = unsafePerformIO (....); y = 42; z = unsafePerformIO (....) in ....
09:31:14 <syntaxfree> s/decent clothes/burqa, but anyway.
09:31:18 <mmorrow> always turns out badly
09:31:18 <Vulpyne> Jedai: For example, there's a TagSoup parser for Parsec, and it results in lists of tags.
09:31:27 <ziman> FooT (ShooT Bang)
09:31:59 <Vulpyne> Jedai: For it to work natively with ByteStrings, it would have to not result in [token_type], it would have to have a typeclass or something for combining tokens into something.
09:32:02 <mmorrow> ZapM (Maybe Pow)
09:32:09 <aep> aye. thanks a lot!
09:32:22 <mk64ftw> hey so I have been working on a r5rs implementation, stealing some ideas from the 48 hour scheme tutorial, but I am running into problems with things like actually getting constant time modification of vector elements, it seems like to do that I will need to pull almost everything into the IO monad, is there something I am overlooking?
09:32:26 <Vulpyne> And then you could just plugin ByteString.cons or whatever.
09:33:11 <Jedai> Vulpyne: it would be problematic since many is not specialized to Char, what you're asking for is another implementation of string, not really of many
09:34:00 <quicksilver> aep: yes perhaps; although threads in haskell are much more lightweight feeling than threads in C so you might consider threads for a fault-tolerant resumable download (if that's what we were talking about)
09:34:12 <Jedai> Vulpyne: Parsec3 doesn't really use list in its lower level, it use the notion of Stream, which wouldn't be a problem to produce ByteString from
09:34:43 <aep> quicksilver: indeed.  i'll look into it, thanks
09:34:50 <Vulpyne> Jedai: I looked at the source for many, and it's implemented in terms of manyAccum (or something similar, I forget the exact name) but if the parser token type is a you get [a] back.
09:35:23 <syntaxfree> why is a private chat with lambdabot not working anymore?
09:35:26 <Jedai> Vulpyne: Right, which is normal since many isn't specialized, you can't put a generic a in a ByteString anyway
09:35:41 <monochrom> @botsnack
09:35:41 <lunabot>  :o
09:35:42 <lambdabot> :)
09:36:10 <Vulpyne> Jedai: Yeah... To be honest, I wasn't 100% sure of what I wanted. If there was a typeclass that it used to determine how it combined the tokens it parsed, then it could be more flexible though.
09:36:10 <mauke> works here
09:36:14 <monochrom> works for me. (but not shown)
09:36:35 <Vulpyne> Jedai: It made me sad when my parser consumed a ByteString and resulted in a String (or forced me to pack strings to ByteStrings if I wanted to use a ByteString later on)
09:36:36 <syntaxfree> oh, works now.
09:37:20 <Vulpyne> The thing I was using it for was really performance sensitive.
09:37:54 <Jedai> Vulpyne: I see your point, but that's really not a problem of Parsec itself (not that that makes it less inconvenient of course)
09:38:48 <Vulpyne> I got Parsec and it didn't do what I wanted it to, so naturally, I blamed it. ;)
09:38:59 <syntaxfree> I blame the sea.
09:39:37 <Vulpyne> I can't blame the sea, I live in a landlocked state.
09:39:40 <ryo_hazuki> in which package is "on" ? i want to use it like this: "compare `on` snd"
09:39:51 <Jedai> ryo_hazuki: Data.Function
09:39:55 <Jedai> @hoogle on
09:39:56 <lambdabot> Data.Function on :: (b -> b -> c) -> (a -> b) -> a -> a -> c
09:39:56 <lambdabot> Text.PrettyPrint.HughesPJ OneLineMode :: Mode
09:39:56 <lambdabot> Text.Parsec.Char oneOf :: Stream s m Char => [Char] -> ParsecT s u m Char
09:39:56 <ryo_hazuki> thx
09:40:05 <ryo_hazuki> ah cool
09:40:06 <Jedai> ryo_hazuki: use @hoogle next time :)
09:40:12 <koeien37> or the real hoogle
09:40:13 <ryo_hazuki> didn't know that =)
09:41:48 <Jedai> mk64ftw: not really
09:42:39 <Jedai> mk64ftw: you're not overlooking anything, and since Scheme is impure it's quite normal that you need to interpret it in IO (how would you execute print otherwise ?)
09:43:26 <mk64ftw> Jedai: yeah but I think i need to do the parsing in IO as well, to build vectors that can have vector-set! called on them in constant time
09:43:48 <Jedai> mk64ftw: no, that you don't need to
09:45:02 <mk64ftw> Jedai: hm, okay, I actually just got an idea, thank you
09:47:33 <Perry__> Hi all, I am new to Haskell. Still trying to figure out how 'Either' works.
09:47:41 <koeien37> do you know how Maybe works?
09:47:48 <Perry__> Yes I do
09:47:54 <koeien37> good.
09:47:56 <koeien37> @src Either
09:47:56 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
09:48:03 <koeien37> data Either a b = Left a | Right b
09:48:21 <Perry__> Oh I see.
09:48:25 <koeien37> so an "Either a b" is either a Left a or a Right b
09:48:30 <koeien37> :t Right "Hello world"
09:48:31 <lambdabot> forall a. Either a [Char]
09:48:40 <Perry__> Since I made a function that returns either Int or String.
09:48:47 <koeien37> :t Left 37 :: Either Int String
09:48:48 <lambdabot> Either Int String
09:48:58 <Perry__> but when I made it return a string HUGS complained about returning a String not an 'Either Int String'
09:49:04 <koeien37> yes
09:49:12 <koeien37> you need to pack it into a Right constructor then
09:49:17 <Perry__> now it's happy
09:49:22 <Perry__> Thank you very much koeien37.
09:49:22 <Jedai> Perry__: You must returns either a Left int or a Right string
09:49:30 <Perry__> Yep, thank you Jedai
09:49:32 <Perry__> I got it now.
09:54:07 <BMeph> That would be kind of interesting if making an 'Either A B' also made a typeclass that "automagically" accepted an A or B and made it that Either A B. Overlapping instances would be a chrome-plated bitch, though. Not to mention more dramatic whining about 'abusing the stack frames'... ;p
10:01:28 <syntaxfree> I always felt Either misses a couple of trivial utility functions that should be in the default  namespace. Nothing that can't be fixed with a couple lines of code, but one's code gets more idiosyncratic and less idiomatic..
10:01:51 <koeien37> :t either
10:01:52 <lambdabot> forall a c b. (a -> c) -> (b -> c) -> Either a b -> c
10:01:57 <koeien37> what more do you want?
10:02:01 <koeien37> :t (|||)
10:02:03 <lambdabot> forall (a :: * -> * -> *) b d c. (ArrowChoice a) => a b d -> a c d -> a (Either b c) d
10:02:20 <koeien37> although (|||) isn't in the Prelude
10:02:42 <doserj> @type (+++)
10:02:43 <lambdabot> forall (a :: * -> * -> *) b c b' c'. (ArrowChoice a) => a b c -> a b' c' -> a (Either b b') (Either c c')
10:03:15 <BMeph> Yeah, it's (+++) that should have a Prelude equivalent; (|||) is Either, as an Arrow.
10:03:32 <Axman6> s/E/e?
10:03:43 <BMeph> Err, *either...right. :)
10:03:47 <Axman6> :)
10:29:04 <lispy> good morning haskellers
10:29:12 <mxc> strange..  something was failing to compile with a parse error, but GHCi loaded it no problem
10:29:30 <EvanR-work> mxc: main not defined..?
10:29:34 <mxc> no no
10:29:49 <mxc> wasn't due to any strange syntax extension
10:30:11 <joe_> how hard is it to define a haskell interface to a c library? is it a big deal?
10:30:13 <mxc> the weird thing is the way I fixed it was I changed import System.Process (proc) to import qualified System.Process as SP
10:30:21 <mxc> and qualified the call to proc
10:32:14 <doserj> mxc: proc is a keyword when using the arrows extension
10:32:23 <mxc> aaah
10:32:25 <mxc> ty
10:32:36 <koeien37> lispy: good evening :)
10:32:50 <koeien37> joe_: very doable
10:33:12 <koeien37> joe_: I think RWH has a chapter on the Foreign Function Interface
10:33:22 <koeien37> there are some tools to help the process
10:34:32 <joe_> thanks koeien37
10:34:43 <joe_> will check out rwh
10:36:17 <tommd> it does
10:36:30 <tommd> And the tools you probably want to look at are c2hs and hsc2hs
10:36:43 <tommd> I'd go with c2hs personally, but admit that hsc2hs currently has more features.
10:38:47 <joe_> i need to read data from a device using the device manufacturer's C library. I can add the haskell interface to the C library or use the sample program to read the data into a pipe and let haskell take it from there. it is streaming data at atleast 10MB/sec.
10:39:20 <koeien37> i guess both are doable.
10:39:41 <joe_> again, summarizing, would you recommend: (1) haskell library to the C library, or (2) c library -> pipe -> haskell program?
10:39:41 <tommd> joe_: I'd made a C binding to the library and import all the streaming data as ByteStrings if I were you.
10:39:51 <koeien37> how simple is the interface ?
10:40:05 <koeien37> tommd: yeah, that is the fastest. and probably not much harder than the alternative
10:40:18 <joe_> http://www.intra2net.com/en/developer/libftdi/
10:40:36 <joe_> the above url has the library that I am talking about.
10:40:59 <koeien37> the example seems pretty easy
10:41:08 <koeien37> i would write a Haskell binding to C. isn't very hard to do
10:41:47 <koeien37> (i.e. follow tommd's suggestion)
10:41:49 <joe_> the documentation is at : http://www.intra2net.com/en/developer/libftdi/documentation/
10:42:18 <joe_> thanks koeien37 and tommd, will check out the haskell binding route.
10:42:42 <koeien37> yeah, check out c2hs and hsc2hs
10:42:51 <koeien37> with some luck, you have almost no keyboarding
10:43:03 <tommd> Down with hsc2hs!  </propaganda>
10:43:10 <joe_> that would be cool..
10:43:26 <koeien37> tommd: why? :)
10:43:36 <joe_> would you recommend rolling something out to hackage too?
10:43:38 <tommd> Because how hsc2hs works
10:43:42 <joe_> if the interface works?
10:43:47 <koeien37> joe_: definitely
10:43:55 <tommd> koeien37: It has no prayer of ever cross compiling.
10:44:11 <koeien37> joe_: it is pretty easy to make a package. maybe somebody else can benefit :)
10:44:16 <aep> um how do i wake up select() from a different haskell thread?
10:44:29 <tommd> Its a limited design and thus should die out and let the newer, better design prosper (c2hs).
10:44:50 <tommd> Unfortunately, there are many large libraries that use hsc2hs and hsc2hs also has more features.
10:45:24 <tommd> aep: You are manually calling select?
10:45:37 <aep> nope.  ncurses does
10:45:46 <tommd> You can throw signals to haskell threads if you know the thread id, but other than that...
10:45:46 <aep> but i could.
10:45:56 <tommd> hummm, curse ncurses.
10:45:58 <aep> signals? ugh.
10:46:15 <aep> so haskell encourages threads but has no integration into select?
10:46:19 <aep> odd
10:46:46 <tommd> Well haskell thread /= os thread.
10:46:51 <aep> you need select() for everything. not just curses
10:47:18 <tommd> How would you hope to wake from it?  Even in C you shouldn't design a program to require one thread to wake another from a select block.
10:47:26 <tommd> You should have a timeout on select if that is the desire.
10:47:32 <aep> well i guess you can use blocking r/w, but then how do you wake up those?
10:47:48 <aep> in C i wouldnt use threads
10:47:58 <tommd> aep: What is it you are trying to do?  It sounds like you have a design issue.
10:48:16 <aep> just using HaskellNet.IMap
10:48:20 <aep> which is blocking only
10:48:21 <tommd> Feel free to create hundreds or thousands of haskell threads and if one blocks, so what?
10:48:46 <aep> yeah but i need to sync the data somehow :D
10:48:53 <tommd> And MVar?
10:48:57 <aep> hum
10:48:59 <tommd> s/And/An/
10:49:21 <aep> i cant see how that helps waking up select
10:49:25 <tommd> I really like TVars because 'retry' makes them much like a semaphore and conditional variable combined.
10:49:49 <aep> or read() if it matters
10:49:53 <tommd> aep: I still think your desire to wake select is evidence of a design that needs rethought.
10:50:05 <aep> ok so lets say i use blocking r/w
10:50:11 <aep> how do i wake those up?
10:50:28 <tommd> ... the OS will when the op completes
10:50:45 <aep> yes, but obviously i need it earlier, since some other thread has new data
10:51:00 <aep> usually in C i'd just stick eveverything into one global select
10:51:05 <tommd> so why does the thread performing the write have to service the new data?
10:51:36 <aep> um in my case a new email is downloaded via blocking imap i/o. i want ti display that email in the curses thread
10:51:39 <aep> or any ui thread
10:51:51 <aep> tommd: or any ui thread
10:52:21 <aep> let's say i use.. bare blocking i/o on  stdout/stdin
10:52:26 <tommd> So you have a global {M,T}Var that is your inbox.
10:52:31 <aep> since you seem to not like haskell :D
10:52:36 <aep> err curses
10:52:59 <aep> okay. but how does that help me wake up the ui thread?
10:53:08 <tommd> And your curses thread should run a moderately tight loop reading that.  Exactly how curses is designed to block indefinately is odd, but I'm sure there is something more to it.
10:53:35 <aep> ok so i'm supposed to poll for the data
10:53:37 <tommd> This is a curses design bug, not a Haskell/select or whatever issue.
10:54:00 <tommd> If you really want to wake curses then you need to understand what the normal method of waking it is.
10:54:06 <tommd> And it doesn't sound like you do.
10:54:10 <aep> not using 100% cpu for doing nothing is a design bug? um
10:54:36 <aep> well usually with C, you stick the network fd into the same select() as stdin
10:54:40 <tommd> lol, polling being equivilant to 100% utilization is funny but so is your assumption that you must poll.
10:54:42 <aep> so it wakes up on either+
10:54:52 <aep> hm
10:54:59 <tommd> I sayd you can tight loop around a read... which can use STM 'retry'... which will be woken when the data is altered.
10:55:02 <aep> "tight loop" sounded like polling. sorry
10:55:05 <tommd> s/sayd/said/
10:55:17 <aep> whats a tight loop then?
10:55:25 <Berengal> orElse is the retry of STM
10:55:25 <aep> if it isnt a spinlock
10:55:45 <tommd> aep: I should have said: use STM, read the inbox, compare to the old inbox, and call 'retry' if they are the same (no new data).
10:56:03 <Berengal> I usually just fork off threads doing IO on one channel, the send the input off into a TChan other threads can read as they like
10:56:20 <tommd> Yeah, Chan or TChan is another good idea.
10:56:25 <aep> yes but that still doesn't wake up read()
10:56:45 <tommd> I still think he'll have other reasons for a "global" inbox, but that might be orthogonal.
10:57:07 <Berengal> aep: Can you put the read call in another thread?
10:57:20 <aep> hm
10:57:30 <tommd> read >>= \dat -> writeChan newMessageChannel dat
10:57:42 <tommd> That should be the extent of your "read" thread.
10:57:47 <tommd> never needs to be "woken up"
10:57:55 <Berengal> Also, forever $
10:57:57 <aep> split read/write into threads?  that would couse serious locking overhead
10:58:10 <copumpkin> forever $$$ :D
10:58:12 <tommd> nope
10:58:32 <Berengal> Speaking of STM, is there a good way to do timeouts in STM?
10:58:57 <tommd> Berengal: Not without something like throwing exceptions, I think.
10:59:50 <c_wraith> Berengal: there is.  let me look it up
10:59:52 <aep> um ok thanks. i think i'll just write my own imap stuff so i can use select
11:00:04 <c_wraith> Berengal: registerDelay
11:00:13 <tommd> wow, really
11:00:14 <Berengal> c_wraith: Thanks. Module?
11:00:17 <tommd> @hoogle registerDelay
11:00:17 <lambdabot> No results found
11:00:33 <c_wraith> Control.Concurrent.STM
11:01:12 <Berengal> I just found my own solution as well...
11:01:26 <Berengal> But registerDelay seems the better choice
11:01:39 <c_wraith> err.  hpaste is broken.
11:01:43 <Berengal> Or at least I can build my atomicWithDelay with it
11:01:45 <c_wraith> @where paste
11:01:45 <lambdabot> http://hpaste.org/new
11:01:49 <tommd> Ahh, so you use 'orElse' on this and check for truth? cool.
11:02:09 <c_wraith> Berengal: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14844#a14844
11:04:44 <c_wraith> Note that it won't interrupt a long-running calculation inside of STM.  You need an exception for that.
11:04:59 <c_wraith> But it will interrupt something that's been blocking for a while
11:07:38 <Berengal> c_wraith: long-running calculations are bad anyway..
11:07:51 <Berengal> (Still, it'd be nice to have that too)
11:09:07 <c_wraith> Berengal: Agreed on both counts
11:12:01 <Berengal> I guess that would have to be implemented as a primitive
11:15:16 <RayNbow> http://blog.omega-prime.co.uk/?p=61 <-- are there any plans to implement this as a GHC extension?
11:17:26 <copumpkin> RayNbow: yeah
11:18:26 <RayNbow> copumpkin: so this means we may finally have elegant restricted monads in Haskell? :)
11:18:32 <copumpkin> eventually
11:19:20 <larrytheliquid> are there plans to roll something like Catch into ghc? http://community.haskell.org/~ndm/catch/
11:20:05 * hackagebot upload: AspectAG 0.1.4 - Attribute Grammars in the form of an EDSL (MarcosViera)
11:21:03 <tommd> larrytheliquid: Catch has existed for a while now, outside of GHC, and I don't know of any efforts to fit it into GHC (unfortunately)
11:21:03 <roconnor> > (\ x x -> x) 1 2
11:21:04 <lambdabot>   Conflicting definitions for `x'
11:21:04 <lambdabot>  In a lambda abstraction
11:21:09 <roconnor> > (\ x -> \x -> x) 1 2
11:21:13 <lambdabot>   2
11:21:17 <tommd> If things like that interest you then I would look at Dana Xu's work on ESC Haskell.
11:21:21 <tommd> @where ESC
11:21:22 <lambdabot> I know nothing about esc.
11:21:27 <tommd> @where Xu
11:21:27 <lambdabot> I know nothing about xu.
11:22:29 <tommd> @where+ Xu http://www.cl.cam.ac.uk/~nx200/
11:22:30 <lambdabot> It is forever etched in my memory.
11:22:31 <meanburrito920_> I'm working through the exercises in real world haskell, and I'm having a bit of an issue writing the following function: http://pastebin.com/m4f48461d
11:22:36 <tommd> @where+ esc http://www.cl.cam.ac.uk/~nx200/
11:22:36 <lambdabot> Okay.
11:22:40 <meanburrito920_> maybe someone could give me a pointer?
11:23:09 <Berengal> preflex: users
11:23:22 <meanburrito920_> here's the updated version, with error message: http://pastebin.com/m24d18c2b
11:23:31 <monochrom> hahahaha monads are really like burritos  (http://blog.plover.com/prog/burritos.html as referenced from the HWN)
11:23:46 <tommd> meanborrito920_: 'y' is not a list
11:24:00 <meanburrito920_> oops :)
11:24:01 <tommd> meanborrito920_: 'y' is an element.  To use it with ++ you must use [y].
11:24:03 <meanburrito920_> thanks
11:24:07 <tommd> or use concat (:)
11:24:17 <larrytheliquid> tommd: thx will take a look
11:24:23 <meanburrito920_> tommd: awesome, that worked.
11:25:02 <tommd> good!
11:27:04 <lispy> :t pure
11:27:05 <lambdabot> forall a (f :: * -> *). (Applicative f) => a -> f a
11:27:18 <lispy> > pure 1 :: [Int]
11:27:19 <lambdabot>   [1]
11:27:36 <lispy> I guess is the singleton function I've often wanted
11:27:36 <monochrom> @hoogle pure
11:27:37 <lambdabot> Control.Applicative pure :: Applicative f => a -> f a
11:27:43 <lispy> I guess "pure"
11:27:55 <monochrom> Hrm?! There is Control.Arrow.pure too.
11:28:10 <lispy> :t Control.Arrow.pure
11:28:11 <lambdabot> Not in scope: `Control.Arrow.pure'
11:28:17 <lispy> blasphemy! ;)
11:28:32 <copumpkin> .arr
11:28:42 <lispy> What is pure in the arrow context?
11:28:47 <copumpkin> arr
11:28:57 <copumpkin> ARR MATEY
11:29:05 <lispy> I guess for functions pure == const?
11:29:07 <vic_> :t arr
11:29:08 <lambdabot> forall b c (a :: * -> * -> *). (Arrow a) => (b -> c) -> a b c
11:29:15 <vic_> Heh
11:29:26 <copumpkin> lispy: it's id
11:29:46 <dons> tommd: seen the rumours about the oregon summer school this year?
11:29:52 <monochrom> converts pure function into arrow function
11:30:23 <lispy> copumpkin: ah
11:31:05 <dons> tommd:  "Logic, Languages, Compilation and Verification.", w/ Launchbury(?), Harper, Leroy, McBride, Morrisett, Pfenning, Pierce, Tolmach...
11:32:25 <monochrom> http://www.haskell.org/ghc/docs/6.8.3/html/libraries/base/Control-Arrow.html#v%3Apure Control.Arrow.pure \o/
11:32:46 * monochrom knew he wasn't hallucinating
11:33:15 <c_wraith> dons: Is Zena still running Summer School?
11:34:04 <c_wraith> Well, looks like she is from a local sense.  She was one of my favorite professors.
11:34:05 <copumpkin> monochrom: that's the old name :)
11:34:16 <tommd> dons: No, I'm not informed about that
11:34:53 <roconnor> How should I do a topological sort of a DAG in Haskell?
11:35:06 <tommd> Funny, type that quote into google and Tolmach is the second link.
11:35:49 <dons> tommd: june.
11:35:49 <dons> should be good.
11:36:09 <tommd> Absolutely
11:39:15 * hackagebot upload: epic 0.1.4 - Compiler for a supercombinator language (EdwinBrady)
11:40:28 <lispy> roconnor: that sounds like something the inductive graph package would support
11:40:43 <lispy> roconnor: although, I don't know for sure if it does
11:41:11 <stepcut> is there an up to date guide on reading core? The example in the manual looks nothing like what ghc is outputing to me
11:42:01 <roconnor> lispy: sure, but I don't have a general graph, I have a dag.
11:42:03 <roconnor> hmm
11:43:52 <c_wraith> wow.  when's supercompilation supposed to be integrated into GHC?
11:44:09 <ryo_hazuki> Data.Set is a lot faster than Data.List, is that correct?
11:44:17 * hackagebot upload: ivor 0.1.11 - Theorem proving library based on dependent type theory (EdwinBrady)
11:44:38 <stepcut> ryo_hazuki: a lot faster for what?
11:44:55 <ryo_hazuki> i try to memoize tuples in a list ... but it's awfully slow
11:44:59 <ryo_hazuki> so i thought of a set
11:45:02 <monochrom> beer mug is a lot faster than coffee mug
11:45:21 * hackagebot upload: idris 0.1.4 - Dependently Typed Functional Programming Language (EdwinBrady)
11:45:52 <ryo_hazuki> so faster for iterating and finding
11:47:47 <c_wraith> slower for iterating.  faster for searching.  But a Data.Set can't contain duplicates, nor can it be infinite.  Also, Data.Set has an Ord constraint, where lists don't.
11:48:31 <ryo_hazuki> searching sounds good... no duplicates sounds good... ord constraint is okay too
11:48:42 <ryo_hazuki> gonna try that one then =)
11:48:59 <kmc_> ryo_hazuki, did you see data-memocombinators?
11:49:31 <monochrom> haskell platform, I long for thee
11:50:15 <ryo_hazuki> not yet ... i wanted to try to "port" a python-imperative script to haskell with "exactly" the same datatypes =)
11:51:01 <koeien37> if you use python lists, you should replace them with lists or arrays as applicable.
11:51:16 <koeien37> lists don't have fast random access in Haskell
11:51:26 <koeien37> use of (!!) is probably a mistake
11:52:09 <ryo_hazuki> nice to know
11:52:28 <koeien37> if translated correctly, Haskell should be a lot faster
11:52:45 <ryo_hazuki> hopefully...
11:53:07 <ryo_hazuki> i used case (lookup x list) of ....... is it possible to use that with Sets as well?
11:53:28 <Jedai> ryo_hazuki: Map
11:53:34 <koeien37> :t Data.List.lookup
11:53:35 <lambdabot> forall a b. (Eq a) => a -> [(a, b)] -> Maybe b
11:53:47 <koeien37> yeah, you want Map in that case
11:53:48 <EvanR-work> :t Data.Set.lookup
11:53:49 <lambdabot> Not in scope: `Data.Set.lookup'
11:53:51 <Jedai> ryo_hazuki: Data.Map (or IntMap if your keys are Int)
11:54:01 <koeien37> :t Data.Map.lookup
11:54:02 <lambdabot> forall k a. (Ord k) => k -> M.Map k a -> Maybe a
11:54:12 <ryo_hazuki> my keys are ints, yes ...
11:54:21 <ryo_hazuki> how about the performance of Map?
11:54:22 <ccasin> any word on when hoogle links will be working again?
11:54:26 <ryo_hazuki> compared to Lists or Sets
11:54:27 <Jedai> ryo_hazuki: Then IntMap should be nicely fast
11:54:27 <Vulpyne> :t Data.Set.elem
11:54:28 <lambdabot> Not in scope: `Data.Set.elem'
11:54:38 <ryo_hazuki> okay.. superb
11:54:40 <Vulpyne> :t Data.Set.member
11:54:41 <lambdabot> forall a. (Ord a) => a -> S.Set a -> Bool
11:54:42 <koeien37> ryo_hazuki: that is documented. O(log n) for retrieval
11:54:42 <Vulpyne> There it is.
11:55:01 <koeien37> Data.Set loosely corresponds to set() in Python; Data.Map is more like a dict.
11:55:14 <Jedai> ryo_hazuki: or even Array, depending on if your keys are consecutives, and if you don't need to modify your array after initialization
11:55:41 <koeien37> (although the underlying implementation is probably different from Python's)
11:55:58 <Jedai> koeien37: Right, since Python use an hashtable of cours
11:56:01 <monochrom> Someone needs to say "insufficient data for a meaningful answer"
11:56:09 <kmc_> ryo_hazuki, there's also Data.Sequence
11:56:12 <koeien37> insufficient data for a meaningful answer
11:56:17 <koeien37> monochrom: ^   :)
11:56:20 <ryo_hazuki> @Vulpyne: so it is possible to change the case expession to case (Set.member x set) of .....
11:56:20 <lambdabot> Unknown command, try @list
11:56:35 <koeien37> ryo_hazuki: then you get True or False
11:57:02 <ryo_hazuki> Jedai: no, i dont modify the list/set after initialization
11:57:04 <roconnor> @hoggle thenST
11:57:05 <lambdabot> No results found
11:57:08 <Berengal> You can't get just one item out of a set...
11:57:20 <ryo_hazuki> mhhhh...
11:57:26 <koeien37> :t Data.Set.delete
11:57:27 <lambdabot> forall a. (Ord a) => a -> S.Set a -> S.Set a
11:57:30 <Berengal> Individual items in a set have no key to look them up by
11:57:30 <Jedai> ryo_hazuki: then if your keys are consecutive, an immutable array may be just the thing for you
11:58:05 <ryo_hazuki> items can still be appended to an immutable arrays, right?
11:58:05 <Jedai> ryo_hazuki: maybe the simplest thing to do would be for you to say what you intend to do with this data structure, with more details
11:58:18 <ryo_hazuki> hehe, true
11:58:18 <Jedai> ryo_hazuki: Not really no
11:58:40 <Berengal> ryo_hazuki: Nothing can be appended to any array. All arrays are fixed size.
11:59:11 <ryo_hazuki> i'm trying to solve project euler problem 14 (collatz) with haskell... my python solutions works very well and i wanted to port it to haskell
11:59:29 <Jedai> ryo_hazuki: Right, I used an Array to do that
11:59:37 <Berengal> Arrays work nicely for that
11:59:45 <copumpkin> that's a nice on for lazy arrays
11:59:46 <Berengal> But you don't know the upper bound
11:59:57 <ryo_hazuki> i'm coming from the java side of the world, so everytime someone talks about arrays i think of arraylists =) - but you're right...
12:00:12 <Jedai> ryo_hazuki: I just cut at a certain limit, and did it without memoization upward of this limit
12:00:23 <koeien37> Jedai: that sounds like a reasonable plan
12:00:31 <koeien37> Jedai: if it's too slow, you could increase the limit
12:00:33 <Jedai> koeien37: It works pretty well IIRC
12:00:39 <Jedai> koeien37: it's very fast
12:00:46 <koeien37> yeah, it should be :)
12:00:55 <koeien37> did you use ST ?
12:00:55 <Berengal> There's also tries
12:01:00 <Jedai> And it's reasonably short too
12:01:00 <Berengal> As in MemoTrie
12:01:16 <Jedai> Berengal: Well IntMap _is_ a trie
12:01:31 <Berengal> The tries were a bit slow, but no slower than the memoising python version using dictionaries
12:01:44 <Jedai> Berengal: it's pretty fast too, but if I remember correctly, you can't use Int there, you have to use Integer
12:01:48 <Berengal> Jedai: I also used loeb...
12:02:17 <Berengal> Jedai: I think you remember wrong. It only goes to a million, and the longest chain isn't _that_ long
12:02:59 <Jedai> some of the collatz sequence go over 2G I think (of course on a 64 bit machine there is no problem)
12:03:07 <ryo_hazuki> how about the performance Data.Array compared to Data.Map?
12:03:21 <monochrom> "insufficient data for a meaningful answer"
12:03:23 <koeien37> ryo_hazuki: they are very different data structures
12:03:29 <Jedai> ryo_hazuki: Array is faster, since it's a more restricted data structure
12:03:37 <Berengal> ryo_hazuki: Data.Map is a treemap, Array is an array
12:03:45 <Jedai> As long as you don't have to modify it of course...
12:04:04 <Berengal> Jedai: Also, sparse keysets
12:04:15 <koeien37> it really depends
12:04:30 * Berengal wants clojure-type arrays
12:04:33 <koeien37> i'd use an array in the ST monad here, I guess
12:04:34 <Jedai> Berengal: Well yes, of course... I was thinking in terms of euler 14
12:04:40 <Berengal> Or fingerlists!
12:04:40 <koeien37> Berengal: what are those?
12:04:43 <Jedai> koeien37: you don't need to
12:04:54 <Berengal> koeien37: high fanout trees with array leaves
12:04:57 <Jedai> koeien37: you just use a lazy array
12:05:01 <Berengal> koeien37: Immutable such
12:05:24 <monochrom> You can use a lazy immutable array since it is write-once.
12:05:27 <koeien37> Berengal: I see. so you get "reasonable" performance for lots of uses?
12:05:28 <ryo_hazuki> i haven't done anything with monads yet, do i HAVE TO use any monads to work with Data.Array?
12:05:33 <Jedai> koeien37: it might be faster in ST but I don't think the little difference is worth the cost in code complexity
12:05:50 <Jedai> ryo_hazuki: No, not with immutable arrays
12:05:58 <ryo_hazuki> okay
12:06:10 <koeien37> although monads aren't that complicated or scary.
12:06:19 <Jedai> ryo_hazuki: and since they're lazy they're perfect for memoization and dynamic programming
12:06:23 <EvanR-work> you could have invented monads!
12:06:26 * EvanR-work runs
12:06:29 <koeien37> yes, you could :)
12:06:31 <lament> I will not fear monads. Fear is the mind-killer...
12:06:55 <lament> You COULD have invented monads, but you DIDN'T, because you're STUPID.
12:07:01 <ryo_hazuki> that's what most people say... thou i first want to habe the basic under my belt =)
12:07:08 <koeien37> sure
12:07:24 <tensorpudding> don't fear the monads
12:07:29 <koeien37> and you will need to understand type classes first :)
12:07:31 <cwvh> learning how to "work" with monads is different from "learning" monads.
12:07:40 <monochrom> you could have invented higher-order functions
12:07:41 <cwvh> I recommend the former as early as possible.
12:09:27 <Berengal> monochrom: It's been done. Repeatedly. Badly more times than not :(
12:10:13 <aep> is there a non blocking network module for haskell?
12:10:30 <monochrom> No.
12:10:44 <copumpkin> aep: why do you want it?
12:10:46 <EvanR-work> aep: there is a select binding.
12:10:50 * EvanR-work runs
12:10:56 <copumpkin> built into the runtime
12:11:07 <EvanR-work> hSelect
12:11:20 <EvanR-work> aep: really you should use forkIO instead
12:11:32 <koeien37> threads are cheap
12:11:33 * Berengal does the forkIO dance
12:11:34 <mle> non-blocking io *should* be unnecessary.
12:11:48 * copumpkin joins Berengal 
12:11:58 <Berengal> mapM_ forkIO philosophersWithForks
12:12:10 * EvanR-work grabs his forks
12:12:14 <tommd> I thought they had chopsticks?
12:12:19 * benmachine grabs EvanR-work's forks
12:12:22 <vic_> The Chopstick Monad
12:12:25 <Berengal> Can't eat spaghetti with chopsticks
12:12:25 <EvanR-work> yeah why would they need two forks
12:12:26 <aep> okay then. i see the door, thanks ;)
12:12:28 <tommd> tommd callus unsafeGrabFork
12:12:39 <copumpkin> aep: what do you need nonblocking net for?
12:12:47 <tommd> aep: it isn't that we are trying to be unhelpful
12:12:51 <c_wraith> uh-oh.  I see the runtime raising a foodfight exception soon
12:12:55 <monochrom> I ate spaghetti with chopsticks. No big deal.
12:13:03 <Jedai> ryo_hazuki: Well, on my 4 year old computer, my solution needs a little less than 2s, how much time did your python solution take ?
12:13:04 <tommd> aep: Its just that what you want to do is counter to how most people here design a program.
12:13:05 <koeien37> i can barely eat anything with chopsticks :)
12:13:31 <Berengal> I can't even eat the chopsticks if I wanted...
12:13:44 <aep> tommd: i know. i see that, and i'd rather not get into the discussion why this is wrong again. So i'll just not use haskell. heh
12:13:55 <napping> http://hackage.haskell.org/package/epoll
12:14:08 <ryo_hazuki> Jedai: my python solution takes about 20s
12:14:20 <tommd> aep: Good luck with your app!
12:14:26 <EvanR-work> aep: 'there is no non blocking networking in haskell' is false. if you leave, just dont take that with you ;)
12:14:37 <benmachine> aep: pretty much any non-blocking network stuff you want to do can be done easily with threading
12:14:39 <Jedai> ryo_hazuki: ok, so Haskell should be faster (my solution takes 6 lines of code
12:14:40 <Berengal> aep: It's not too hard to build your own select for anything with a few threading primitives
12:14:41 <copumpkin> aep: wow, that's a little excessive. We suggested not using them because haskell abstracts select away from you. It uses it behind the scenes but because it has green threads, you get to think of each socket as blocking, and the runtime takes care of select() for you
12:14:41 <koeien37> aep: what i'd do, is create a thread that listens for network events with a Chan.
12:14:43 <aep> napping: yeah, but that means wrapping every single low level C lib with ffi
12:15:00 <monochrom> There was no discussion, apart from claiming that the #haskell-recommended way is slow, and the claim was without evidence. Where is your data?
12:15:11 <ryo_hazuki> Jedai: 18 lines of code here =)
12:15:23 <napping> It's not clear exactly what you are looking for
12:15:38 <benmachine> aep: threading in haskell has the added bonus of making you feel warm and fluffy inside
12:15:48 <aep> napping: for standard unix i/o. but more high level. hehe
12:15:57 <copumpkin> aep: we generally prefer questions that explain what people want on a high level, rather than specific things they expect from other languages, because things tend to be very different in haskell
12:16:02 <EvanR-work> it uses standard unix i/o, behind the scenes
12:16:14 <ryo_hazuki> bbl - trying IntMap now :)))
12:16:18 <aep> copumpkin: true true.
12:16:37 <napping> I don't see how using one library or another for IO changes how you have to interface with low level libraries - unless they deal directly in fd's and aio structs and stuff
12:16:41 <aep> EvanR-work: blocking is not standard actually.  unix doesn't require threads for anything
12:16:58 <copumpkin> EvanR: the blocking is simulated on the green threads of haskell
12:17:03 <copumpkin> aep, I mean
12:17:04 <aep> napping: yeah, well epoll is pretty much that.
12:17:11 <copumpkin> aep: it isn't actually using blocking calls behind the scenes
12:17:17 <EvanR-work> aep: question is why do you want to do the low level stuff
12:17:21 <aep> copumpkin: why does it need spinlocks then?
12:17:28 <copumpkin> aep: ?
12:17:41 <Phyx-> Hi, i'm having some problems with SYB, can't get it to give me what i expect, my Generic Programming is a bit rusty, anyone mind taking a look http://phyx.pastebin.com/d4a28b485
12:17:57 <Berengal> aep: It doesn't spinlock. The runtime does the low-level select calls, but it also schedules the green threads. You can run a threaded haskell program on a single-threaded runtime
12:17:58 <aep> copumpkin: well i asked earlier how to wake up select() and the answer was using a wait 0 and doing busy loop
12:18:01 <napping> aep: skimming over the patch here shold give you a quick idea of how the ordinary IO works in GHC:http://www.serpentine.com/blog/2009/12/17/making-ghcs-io-manager-more-scalable/
12:18:12 <aep> napping: nice thanks
12:20:54 <hooopy> > sum (concat (inits [1..12]))
12:20:55 <lambdabot>   364
12:21:08 <hooopy> on the first day of christmas my true love gave to me...
12:21:33 <monochrom> Oh, neat.
12:21:34 <vic_> A monad.
12:21:50 <monochrom> I wonder which day is the missing day.
12:22:07 <BMeph> ...in a tree!
12:22:25 <napping> Phyx-: what's wrong with it?
12:22:47 <monochrom> http://www.vex.net/~trebla/humour/twelve-math.txt
12:22:49 * copumpkin is working on a monstrous proof
12:22:51 <Phyx-> napping: well, in the link, i also have a "desired output" and "received output"
12:23:00 <Phyx-> it's basically doing more traversals than i expect
12:23:28 <napping> well, that's what everything does - it goes for every node
12:24:26 <vic_> copumpkin: hahaha
12:24:30 <Phyx-> right, but for the type application nodes i only need it to go down 1 level on it's own, i should probably use a gmapQ then
12:24:39 <napping> yeah, something like that
12:25:19 <aep> wait, are haskell threads actually state systems on standard select() ?
12:25:25 <necroforest> Anyone here use hmatrix? I'm trying to do some basic vector stuff (normalizing a vector, taking the vector's length) and can't find functions to do those things... does it not include them or am I just not seeing them?
12:25:26 <napping> yes
12:25:31 <BMeph> monochrom: ...in a tree!
12:25:33 <aep> wow thats ... awesome
12:25:37 <kmc_> aep, they're not *only* that
12:25:43 <copumpkin> aep: well, ghc has a pretty decent scheduler apart from those
12:25:43 <koeien37> necroforest: i have used it some time ago. THose functions definitely exist
12:25:46 <Phyx-> napping: thanx
12:25:47 <aep> why can't i stick my own fd in it then?
12:25:51 <copumpkin> so you can block and wait on other things that aren't IO-related
12:25:56 <koeien37> necroforest: let me find some code
12:25:58 <EvanR-work> aep: you can, with forkIO
12:26:01 <napping> aep: you can make a handle from an fd
12:26:05 <aep> but forkIO is a thread
12:26:14 <copumpkin> aep: a green thread
12:26:16 <kmc_> a Haskell thread is not a fd
12:26:20 <kmc_> a therad can block on a fd
12:26:34 <copumpkin> aep: not necessarily a system thread, although it can live on a different system thread
12:26:35 <napping> and when a thread blocks on an fd, that fd goes into the select loop
12:26:39 <koeien37> necroforest: i calculated the 2-norm with pnorm PNorm2
12:27:07 <EvanR-work> clearly creating and switching between green threads is faster, but are they also faster at blocking/unblocking?
12:27:12 <copumpkin> aep: GHC's threads use a couple hundred bytes each and you can spawn millions of them in no time at all, if you feel like it :P
12:27:24 <koeien37> necroforest: Numeric.LinearAlgebra.Algorithms
12:27:28 <copumpkin> aep: that's why we rule the shootout thread-ring benchmark by 10 or 20x :P
12:27:37 <necroforest> koeien, 2-norm is the same as v/||v|| ?
12:27:37 <aep> sounds like they might be _exactly_ what i am doing in C anyway
12:27:43 <aep> only the API smells javaish
12:27:46 <napping> aep: it's not exactly like e.g. gsk because there's also another thread per core that keeps running unblocked ForkIO threads, and it's fully preemptive
12:28:19 <koeien37> necroforest: no, the p-norm of a vector (x1, ..., xn) is (|x1|^p + ... + |xn|^p)^(1/p)
12:28:26 <kmc_> yes, actually one million threads
12:28:27 <koeien37> (so a real number)
12:28:42 <copumpkin> kmc_: over 9000 threads!
12:28:42 <aep> when i read "all io is blocking because it is so easy" i am quickly reminded of java and how they apparantly have a different definition of easy
12:28:53 <necroforest> oh ok... so 2-norm is basically euclidean vector length
12:28:54 <kmc_> aep, you may enjoy this presentation: http://donsbot.wordpress.com/2009/09/05/defun-2009-multicore-programming-in-haskell-now/
12:28:58 <vic_> 12 Days of X-Mas, the obfuscated version http://research.microsoft.com/en-us/um/people/tball/papers/XmasGift/
12:28:59 <koeien37> necroforest: yes
12:29:02 <aep> thanks kmc_
12:29:09 <copumpkin> aep: most nonblocking IO is used to avoid thread overheads, and you basically take care of multiplexing it yourself. I can't think of many uses for it other than that
12:29:10 <necroforest> now that you mention it, i remember doing p-norm in some math class
12:29:14 <napping> oh, except I think network IO on windows might not be multiplexed nicely
12:29:33 <kmc_> it talks about parallelism and concurrency in GHC.  we actually make a meaningful distinction between the two: if all you want is the compute throughput of multiple cores, you shouldn't need to spawn threads or write synchronization code
12:30:01 <kmc_> explicit threads are for programs with concurrent semantics, not merely multi-core implementation
12:30:18 <koeien37> necroforest: i used complex-valued matrices and vectors of size about 2^9. worked fine. most functions i wanted were there.
12:30:29 <aep> copumpkin: thats my use case indeed
12:30:33 <Berengal> I thought about implementing a coroutine-based single-threaded concurrency library
12:30:42 <necroforest> koeien, heh... i'm planning on using vectors of most size 4 ;)
12:30:49 <Berengal> For concurrency where you don't need multiple threads
12:30:58 <Berengal> Just multiple execution paths
12:31:01 <koeien37> necroforest: although i had to implement gram-schmidt myself. wasn't too hard.
12:31:15 <kmc_> Berengal, there's GNU Pth
12:31:21 <napping>  http://phyx.pastebin.com/d4a28b485
12:31:33 <napping> wait, not that
12:31:37 <napping> http://www.cis.upenn.edu/~stevez/papers/abstracts.html#LZ07
12:31:44 <napping> Berengal: have you looked at that?
12:31:46 <Phyx-> lol
12:31:47 <Berengal> kmc_: I was thinking more continuations
12:31:49 <koeien37> necroforest: there are various functions for e.g. calculating the eigenspaces. all in all i was very happy with hmatrix :)
12:31:53 <kmc_> aep, if you want to avoid the overhead of OS-level threads, you can tell ghc to put all your Haskell threads onto one OS thread
12:31:58 <kmc_> this is indeed the default behavior
12:32:07 <Berengal> napping: Nope, I haven't
12:32:13 <kmc_> you will still get the blocking semantics you desire
12:32:15 <Berengal> But looks interesting
12:33:12 <koeien37> happy that i didn't have to use C or Fortran :)
12:33:21 <EvanR-work> kmc_: doesnt that block all threads when you do a system call
12:33:22 <aep> kmc_: i dont _want_ the blocking api actually :D  i find it hard to use
12:33:57 <EvanR-work> aep: you will find it easy to use if you try
12:34:09 <aep> i find jva extremely hard to use. i tried
12:34:10 <EvanR-work> it is nothing like java
12:34:20 <aep> yey
12:34:34 <koeien37> why is there a comparison between java and blocking IO ? :/
12:34:51 <copumpkin> blocking IO is a lot easier to think about, it's not just java
12:34:52 <aep> is there any tutorial that helps me with the transition from non blocking to haskell threads?
12:35:05 <copumpkin> "if I don't have data, I'll wait until I do, as I can't do anything without my data"
12:35:26 <EvanR-work> read about MVar's and Chan's, then theres STM which everyone here loves
12:35:34 <aep> copumpkin: i usually think more like "tell me when you have my data so i can work with it"
12:35:43 <EvanR-work> aep: and loop? ;)
12:35:48 <copumpkin> aep: that's what blocking is though
12:35:49 <koeien37> aep: yeah, that's why you can use Chans :)
12:35:55 <EvanR-work> do you have it yet? do you have it yet?
12:36:11 <aep> EvanR-work: select doesnt work like that
12:36:11 <kmc_> aep, http://book.realworldhaskell.org/read/sockets-and-syslog.html
12:36:21 <aep> kmc_: thanks.
12:36:22 <napping> aep: are you familiar with CPS?
12:36:23 <kmc_> aep, and the other RWH chapters
12:36:25 <copumpkin> aep: if each thread is only concerned with its own data, then there's no notion of telling you about more than one thing. And telling you about one thing is just to stop blocking
12:36:33 <aep> napping: no
12:36:38 <EvanR-work> aep: i know how select works. but you would use select if you wanted to do something else until something is ready to read
12:36:38 <benmachine> aep: select blocks until something interesting happens
12:36:45 <benmachine> which is what your threads do, too
12:36:47 <kmc_> like the one after, which addresses STM
12:38:20 <EvanR-work> benmachine: or a timeout
12:38:32 <monochrom> Like I said yesterday, I just read the docs of forkIO and MVar.
12:38:58 <aep> the point is that with select() i dont have to start threads, and everything stays deterministic. i find it very easy to program that way
12:39:00 <benmachine> EvanR-work: timeouts are interesting :)
12:39:16 <benmachine> aep: haskell threads are as deterministic as select
12:39:18 <benmachine> and as easy
12:39:21 <aep> other then having to think in concurrency and locks and whatnot
12:39:22 <EvanR-work> easier
12:39:29 <EvanR-work> there are no locks
12:39:36 <EvanR-work> there are MVars
12:39:44 <aep> hum
12:39:48 <EvanR-work> you read and write them, you do not lock them
12:39:49 <koeien37> hmm. interesting. I find select() confusing
12:39:57 <aep> i really need to read some stuff and then continue asking stupid questions
12:39:57 <monochrom> Why do you think threads imply locks?
12:39:58 <benmachine> I like select()
12:40:20 <koeien37> i like the fact that haskell abstracts it
12:40:24 <benmachine> aep: that's how I learn :)
12:40:26 <aep> monochrom: how else do you protect against race coinditions in non deterministic environement
12:40:35 <napping> by not using mutable variables?
12:40:51 <monochrom> If two threads have to exchange something, sure you need locks or equivalent. But if the two threads don't exchange anything, why is there a lock?
12:40:59 <aep> using an IPC makes things even more complex
12:41:04 <napping> also MVars are safe
12:41:05 <benmachine> MVars ensure everything you need ensured, really
12:41:11 <aep> hm
12:41:15 <koeien37> nah, you still have to be careflu with MVars
12:41:25 <napping> but not because of races
12:41:39 <koeien37> yes, if there is more than one MVar
12:41:48 <monochrom> If you use the select() paradigm, there are race conditions too.
12:42:07 <napping> no, not in the strict sense of access to shared memory without synchronization
12:42:08 <aep> yes but they are obvious and easy to prevent
12:42:14 <c_wraith> Really, if you want to have multiple threads communicate with anything more complicated than Chan constructs, you should use STM
12:42:30 <aep> reentrance is an issue with reactive programming, indeed
12:42:33 <EvanR-work> aep: MVars are more obvious
12:42:48 <aep> mvars,mvars,mvars.  all right! i'll go reading :D
12:42:53 <aep> thanks!
12:43:01 <copumpkin> don't forget about them TVars
12:43:02 <copumpkin> :P
12:43:02 <EvanR-work> and also consider the case of audio, you typically use a lock free queue to transfer from one thread to another
12:43:13 <EvanR-work> another case where you dont have locks
12:43:20 <aep> EvanR-work: yeah of course. but i see a point using threads there
12:43:32 <EvanR-work> why?
12:43:33 <benmachine> the only thing that tripped me up about MVars is readMVar being just takeMVar and putMVar
12:43:35 <c_wraith> lock-free guaranteed-advancement algorithms are pretty awesome.
12:43:39 <aep> whereeas i find them pointless with networking, since networking doesnt use cpu at all
12:43:47 <EvanR-work> neither does audio
12:43:56 <aep> well it typically does :P
12:43:59 <EvanR-work> the sound card doesnt need data very often
12:44:09 <EvanR-work> decoding an mp3 is another story
12:44:23 <EvanR-work> the audio callback thread usually blocks waiting until it needs more samples
12:44:26 <EvanR-work> its just like networking
12:44:35 <aep> i find 64ms often. doesnt work with java _at all_
12:44:45 <monochrom> I'll just agree to disagree that races in the select() paradigm are more obvious and easier to prevent.
12:44:53 <aep> no it doesnt. thats an abstraction :P
12:45:08 <theorbtwo> How do I convert an Int to an Integer?
12:45:16 <koeien37> :t fromIntegral
12:45:16 <lambdabot> forall a b. (Integral a, Num b) => a -> b
12:45:25 <theorbtwo> That should work, thanks.
12:45:30 <EvanR-work> aep: downloading something where you get a packet more often than 64ms still uses no cpu
12:45:46 <EvanR-work> its I/O bound
12:45:50 <aep> EvanR-work: yeah well, i'm thinking of a different use case i think
12:45:50 <koeien37> :t toInteger
12:45:51 <lambdabot> forall a. (Integral a) => a -> Integer
12:46:02 <koeien37> @src fromIntegral
12:46:02 <lambdabot> fromIntegral = fromInteger . toInteger
12:46:13 <EvanR-work> aep: the point is that audio almost always uses asynch I/O because it makes more sense
12:46:16 <aep> EvanR-work: i work in audio stuff. what we have here is multiple threads with very cpu intensive stuff like decoding and producing sound
12:46:26 <EvanR-work> in the C world you do single threaded to keep your sanity
12:46:33 <EvanR-work> in haskell you can be sane and concurrent
12:46:38 <aep> hmm
12:46:42 <EvanR-work> aep: yes thats another story
12:47:13 <EvanR-work> i brought up audio just because you dont necessarily need locks
12:47:13 <koeien37> a few simpler threads can be an easier-to-understand design than a huge select() imo
12:47:17 <aep> well i'm really poisoned by java. its aproach to programming really started to make me hate garbage collection, vms, threads, everaything
12:47:36 <theorbtwo> You should hate garbage collection, when you need to care about it at all.
12:47:56 <aep> i didnt notice it in haskell so far. good sign
12:48:03 <theorbtwo> aep: Very much so, yes.
12:48:59 <EvanR-work> gc has the potential to be faster than manual malloc / free
12:49:08 <EvanR-work> os should support it!
12:49:50 <koeien37> it may have "the potential". Is it faster in practice?
12:49:56 <koeien37> ime the answer is "no"
12:49:56 <aep> if the gc doesn't freeze your app for 3/4 of the cpu time, sure :P
12:50:06 <EvanR-work> right, the java way
12:50:11 <koeien37> but i'd love to be proven wrong
12:50:46 <aep> well he said potential. its possible to invent algorythms that make is super fast without breaking existing programs
12:50:52 <EvanR-work> koeien37: i tried to implement one... the gc book has a lot in it. but its so complex :(
12:50:54 <aep> can't do that in C
12:51:08 <EvanR-work> aep: well you have conservative collectors...
12:51:25 <aep> fortunately :P
12:51:27 <luite> the right way to do it is to make sure that there are no existing programs :p
12:51:34 <EvanR-work> i like that philosophy
12:51:40 <aep> hehe
12:51:45 <koeien37> luite: and the best way to ensure that, is to avoid success at all costs
12:52:00 <Berengal> Smash computers!
12:52:30 <luqui> EvanR-work, can you elaborate?  where does this potential come from?
12:52:38 <jlouis> Axman6: oh, that is awfully cool, I appreciate it
12:52:38 <lambdabot> jlouis: You have 1 new message. '/msg lambdabot @messages' to read it.
12:53:34 <vic_> @quote C++
12:53:35 <lambdabot> cjs says: I have to explain this shit to people. I mean, I start out right, "Hey, you know how you always have these bugs because what you thought was in the variable is not there?" And I get all of
12:53:35 <lambdabot> these nods of agreement. "Well, I've found a new language that solves that problem." Audience: "Ooooh! How?" Me: "There's no variables!" And then they all start moving away from me slowly....
12:53:35 <monochrom> Once you start sharing data heavily, manual deallocation is unsafe or unoptimal.
12:54:20 <EvanR-work> luqui: its a complex topic. strictly speaking the basic semispace collector has unlimited efficiency (as opposed to the malloc and free algorithms). but your program freezes during collection
12:55:03 <luqui> unlimited efficiency?
12:55:19 <EvanR-work> in terms of total time in memory management vs else where
12:55:45 <luqui> because of parallelism?  or because it doesn't have to run often?
12:55:48 <napping> aep: threads + STM in Haskell is almost exactly the same semantics as an event based system
12:56:08 <EvanR-work> so you got your incremental, your generational, your concurrent etc etc schemes to try and make gc interactive and also efficient
12:56:18 <EvanR-work> luqui: no just because its a simpler algorithm
12:57:05 <napping> EvanR-work: are  you just saying that any collector that only visits live objects is asymptotically really fast as you have more and more heap?
12:57:51 <EvanR-work> yeah, the unlimited comes from having more and more memory. in the semispace collector the advantage is that you basically never have to collect and allocating is trivial
12:57:54 <vic_> @quote Perl
12:57:54 <lambdabot> cjeris says: i have a little perl script that aliases gcc -freduced-suckage to ghc
12:58:07 <EvanR-work> napping: if you didnt mind the freezes its the best! ;)
12:58:12 <luqui> EvanR-work, I guess I don't understand where "unlimited" comes from.  It has to have a complexity...
12:58:32 <EvanR-work> theres also 'in principle' benefits in heap compaction but i read those almost never actually come true
12:58:34 <monochrom> The example I like is the Observer pattern in the OO world, similarly Tangible Value in the FP world. At no point in your code can you say "this is the right place to insert the deallocation call to deallocate this listener". You never know how many other things are still using that listener. If you just don't deallocate until whole program ends, that is called "memory leak". And screw reference-counting as soon as you want t
12:58:34 <monochrom> o allow cyclic things.
12:58:35 <vic_> @quote Ruby
12:58:35 <lambdabot> dobblego says: many of my colleagues used to be [fond of ruby] as well until I was let loose on them
12:58:35 <Alpounet> @type (***)
12:58:36 <lambdabot> forall (a :: * -> * -> *) b c b' c'. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
12:58:38 <copumpkin> O(0)
12:59:01 <napping> luqui: if the GC is O(live memory), and your program constantly allocates but has a fixed live fraction, then in the limit as your heap goes to infinity you spend no time collecting
12:59:22 <copumpkin> bah, bedtime, I'm so jetlagged :(
12:59:35 <luqui> napping, okay i think i get that
12:59:42 <napping> I've seen numbers like occupancy around 6x live as the crossover between bohem and manual allocation
13:00:22 <monochrom> If you see memory leaks from popular programs written in C/C++ (e.g. firefox), I bet you it is because of the problem I have just described. No GC, safe manual deallocation implies belated deallocation.
13:00:47 <ryo_hazuki> Jedai: i'm getting an out of memory after a minute ... http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14845 is my code at the moment
13:00:47 <Zao> If it was written in proper C++, it'd use sane resource management idioms.
13:00:51 <koeien37> you can easily have memory leaks in GC'd environments, too
13:00:59 <monochrom> So much for "GC being inefficient". I'm sorry, lack of GC is even more inefficient.
13:01:06 <Zao> Unforuntately, the Mozilla C++ guidelines are draconic and stuck in pre-standard C++ land.
13:01:18 <andrewe> hpaste.org gives an error (500 Internal Server Error), is that a known problem? Can someone reproduce that problem?
13:01:19 <jlouis> GC is hardly inefficient if you do it right
13:01:33 <Alpounet> monochrom, one of the problems being that people actually write stuffs like "C/C++", and that in many people's mind, this is a programming language
13:01:47 <Alpounet> i.e C style code withing classes, end of the story.
13:01:48 <c_wraith> andrewe: it's doing that to everyone.  appears to be a malformed utf-8 string in a post name or the like.
13:01:48 <koeien37> yeah "C/C++" is not a language
13:02:00 <Zao> Alpounet: I write things in ML/Haskell all the time!
13:02:10 <c_wraith> andrewe: if you just go to hpaste.org/new you can still create a new entry
13:02:12 <Alpounet> Zao, I write ASM/Prolog
13:02:13 <monochrom> Of course I mean C/C++ as two languages. Firefox uses both.
13:02:15 <Alpounet> haha
13:02:18 <Zao> And let's not forget Pascal/Delphi.
13:02:25 <roconnor> @type ap
13:02:27 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
13:02:43 <ryo_hazuki> Zao: which do you prefer?
13:02:52 <Zao> ryo_hazuki: C++.
13:02:55 <Alpounet> I still hesitate to put my thoughts about why haskellers should not hate "modern C++"
13:02:56 <andrewe> c_wraith: thank you, maybe someone should change the link in the #haskell channel description to reflect that.
13:02:59 <Alpounet> on a blog post.
13:03:05 <ryo_hazuki> Zao: ML or Haskell, i ment =)
13:03:07 <Zao> I see no real reason to use C for anything but ninja low level twiddling.
13:03:08 <luqui> there is C/Haskell.  The C syntax is a bit different...
13:03:10 <Alpounet> it'd be the beginning of a war, and I don't want to be killed yet.
13:03:11 <luite> parts of firefox are written in Java/Script
13:03:22 <Zao> ryo_hazuki: Oh. Haskell. I can't quite accept the strictness and syntax of ML.
13:03:28 <Zao> ryo_hazuki: Even though I'm brought up on Standard ML.
13:03:30 <monochrom> GHC is C/Haskell. Or Haskell/C. You can begin fighting now.
13:03:39 <koeien37> Alpounet: the things I hate in C++ mostly stem from the almost-backwards compatibility with C.
13:03:41 <roconnor> @type (\f x -> ap f (return x))
13:03:42 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> a -> m b
13:03:54 <roconnor> @pl (\f x -> ap f (return x))
13:03:55 <lambdabot> (. return) . ap
13:04:05 * EvanR-work throws C-- into the fray
13:04:09 <Alpounet> haha
13:04:21 <monochrom> One reason to use C is "all *nix have compilers out of the box"
13:04:26 <roconnor> (\f x -> ap f (return x)) -- is there a name for this?
13:05:01 <Zao> monochrom: Unless you use carebear Linux distros that consider compilers optional.
13:05:03 <monochrom> Of course we would all prefer Adga compilers to be installed by default by ubuntu.
13:05:03 <jlouis> roconnor: get the type, check in Hoogle?
13:05:18 <jlouis> Or Coq.
13:05:19 <roconnor> hoogle sucks for type constructors
13:05:26 <roconnor> @hoggle m (a -> b) -> a -> m b
13:05:27 <lambdabot> Control.Applicative (<*>) :: Applicative f => f (a -> b) -> f a -> f b
13:05:27 <lambdabot> Control.Monad ap :: Monad m => m (a -> b) -> m a -> m b
13:05:27 <lambdabot> Control.Applicative (<**>) :: Applicative f => f a -> f (a -> b) -> f b
13:05:35 <koeien37> I don't think desktops should ship compilers by default. binary distribution ftw
13:05:41 <ryo_hazuki> can someone look at my code and tell me where i can speed it up? my python solutions needs 4seconds and my haskell code just runs out of mem
13:05:42 <ryo_hazuki> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14845
13:05:45 <andrewe> I'm trying to understand phantom types. Should this sample (http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14846#a14846) type check? I don't think so, but it does.
13:06:08 <kmc_> andrewe, why shouldn't it typecheck?
13:06:16 <koeien37> andrewe: why shouldn't it?
13:06:24 <kmc_> t and t2 both have type T String
13:06:30 <kmc_> t by itself would have type T a
13:06:39 <kmc_> but the use of idt forces both to infer a = String
13:06:50 <jlouis> I've yet to play with Agda, perhaps I should
13:06:55 <andrewe> Then I don't see the whole point of phantom types.
13:07:06 <kmc_> the type in the data constructor field is unrelated to the type in the type constructor's parameter
13:07:25 <copumpkin> jlouis: we have a channel on this network too :)
13:07:26 <koeien37> kmc_: t has type forall a. T a
13:07:36 <jlouis> copumpkin: I know :)
13:07:43 <kmc_> andrewe, the idea is to write functions with types fixed to be intentionally less polymorphic
13:07:48 <kmc_> and only export those functions, not the constructor
13:07:48 <copumpkin> oh you're in there :P
13:07:51 <jlouis> copumpkin: I even lurk in said channel :)
13:07:59 * copumpkin needs to sleep more :P
13:08:49 <kmc_> data Raw = LitInt Int | Sum Raw Raw | Eq Raw Raw;  data Expr a = Expr Raw -- phantom type
13:09:00 <kmc_> litInt :: Int -> Expr Int; litInt = Expr . LitInt
13:09:04 <andrewe> kmc_: if I add the type signature: t :: T Int, it begins to make sense.
13:09:05 <monochrom> The point of phantom type is that end users see two incompatible types but the implementer can mix them at the implementer's discretion, i.e., the implementer knows what is safe, but don't trust end users.
13:09:54 <kmc_> eq :: Expr Int -> Expr Int -> Expr Bool; eq (Expr a) (Expr b) = Expr (Eq a b)
13:10:10 <kmc_> andrewe, note that "litInt" and "eq" have type sigs that are less polymorphic than they could be
13:10:25 <andrewe> kmc_: I see
13:10:34 <kmc_> we could have eq :: Expr a -> Expr b -> Expr c, but that would defeat the purpose of modeling our object language's types using Haskell's types
13:10:43 <kmc_> andrewe, these days it would be more common to use GADTs for this
13:10:59 <andrewe> Why?
13:11:11 <kmc_> andrewe, like this example: http://www.haskell.org/ghc/docs/latest/html/users_guide/data-type-extensions.html#gadt
13:11:22 <kmc_> andrewe, it's more straightforward.  you don't make the "unsafe" Raw type and then manually wrap it
13:11:39 <kmc_> you just declare the actual constructors to have constrained types
13:11:54 <andrewe> ok
13:11:54 <koeien37> GADTs are cool :)
13:12:29 <increpare> anyone else here use Uniplate?  I was just trying it out, but there seem not to be any full examples I can find online...was trying a test case here -> http://pastebin.com/m40e22845 , but not sure how to do it.  The main doc page ( http://community.haskell.org/~ndm/darcs/uniplate/uniplate.htm ) says that making things typeable and data should be enough, but that doesn't seem to be the case...
13:13:21 <andrewe> I'd better listen to the low battery warning. :-/
13:14:37 <lispy> gadts allow you to enter into the space between forall and exists in a meaningful way when specifying types
13:15:20 <aep> hm ok so much for the theory. anyone has a code example for me how i'd stick my own fd (for example stdin) into the whole haskell threadfing magic ?
13:15:22 <lispy> Regular parametric polymorphism tends to be all or nothing
13:16:05 <Botje> increpare: i don't think you have to define a Uniplate instance.
13:16:11 <lispy> aep: Oh, fd = file descriptor?
13:16:21 <aep> yes
13:16:24 <napping> aep: http://www.haskell.org/ghc/docs/latest/html/libraries/unix-2.4.0.0/System-Posix-IO.html#10
13:16:34 <aep> thanks
13:16:39 <lispy> I was thinking of functional dependencies
13:16:45 <aep> :D  sorry
13:16:55 <increpare> Botje: if I don't then I get an error message
13:17:21 <increpare> Botje: (saying 'no instance for U.Uniplate Tree')
13:17:25 <Botje> increpare: ah.
13:17:34 <Botje> increpare: you have to import Data.Generics.PlateData for the auto deriving stuff
13:17:47 <aep> napping: i very much like the side note on that one. smells like someone did it right. *happy*
13:17:52 <Jedai> ryo_hazuki: I think you have a problem if you use Int
13:18:08 <Jedai> ryo_hazuki: except if you're on a 64 bit machine
13:18:11 <increpare> Botje: putting in Data.Generics.PlateData doesn't seem to make a difference
13:18:31 <ryo_hazuki> Jedai: btw i let my python code run again and it took 4 seconds (:
13:18:34 <Jedai> ryo_hazuki: also you're code does waste a lot of opportunity to update the cache
13:18:43 <ryo_hazuki> Jedai: you mean i should use Map instead of IntMap?
13:18:43 * increpare thinks it might be because I'm on 6.12
13:18:45 <Jedai> *your
13:18:58 <ryo_hazuki> mhhhh
13:19:27 <Jedai> ryo_hazuki: Well that would work, but it would probably be pretty slow.. (but at least it wouldn't start to wrap around and go to negatives and in an infinite list
13:19:46 <Jedai> s/list/loop
13:19:47 <Alpounet> <koeien37> Alpounet: the things I hate in C++ mostly stem from the almost-backwards compatibility with C. <<< I understand...
13:20:50 <kmc_> aep, you just make a thread that interacts with stdin
13:21:05 <ryo_hazuki> gonna try that...
13:21:10 <kmc_> using whatever Haskell IO routines -- it doesn't need to be specially low level
13:21:14 <napping> oh yeah, there's a stdin :: Handle already
13:21:28 <EvanR-work> aep: probably dont want to try to write a c program in haskell
13:22:03 <aep> of course not. i'm trying to adapt to haskells brain set slowly. i'm not just translating the code
13:22:23 <Botje> increpare: hmm, not importing Uniplate and just working with PlateData directly works here
13:22:31 <EvanR-work> but it might be interesting to try ;)
13:22:37 <kmc_> anyway you do not need to do anything explicit to associate a thread with a fd.  that happens simply by that thread executing blocking IO on that fd
13:22:49 <napping> is there any reason not to get your handles from the Haskell IO libraries?
13:22:50 <Jedai> ryo_hazuki: note that doing it directly, without memoization, should be pretty fast already, definitely under 10s
13:23:26 <increpare> Botje: oho - seems to work with me as well.  Might be worth pinging NM about the strangeness?
13:23:53 <aep> kmc_: so i have 2 fds in that program. what i would do is: forkIO an action which does blocking read() from the one fd, then read() on the other fd().  right?
13:24:06 <aep> kmc_: but then both threads are blocked. how do i wake them up?
13:24:07 <ryo_hazuki> i tried it directly and crashed with stack overflow ... =)
13:24:11 <aep> :(  threads are hard
13:24:22 <EvanR-work> send them stuff to read
13:24:28 <Jedai> ryo_hazuki: You need to be tail recursive of course
13:24:38 <kmc_> aep, they wake up when the read completes
13:24:55 <Botje> good idea :)
13:24:59 <aep> the problem is, only one wakes up, not the other
13:25:05 <kmc_> why?
13:25:27 <EvanR-work> make one thread for each handle
13:25:27 <Jedai> ryo_hazuki: like "collatz n = go n 0 where go 1 !l = l; go n !l = go (next n) (l+1)"
13:25:32 <aep> so if i have read(stdin) in one and read(network) in the other, i have no way of writing to the gui on network eventsy since the gui is busy waiting for input
13:26:00 <aep> so the user has to press a key to see new network data. thats pretty ugly
13:26:12 <EvanR-work> have stdin, network, input threads all write to the gui thread or whatever is calling the shots to the gui
13:26:12 <kmc_> aep, you can use both fds from both threads
13:26:24 <Jedai> aep: the GUI shouldn't be in the same thread as the read(stdin)
13:26:25 <aep> isn't that unsafe?
13:26:32 <kmc_> one thread can do a blocking read on a network socket, while another thread writes to the same socket
13:26:43 <aep> Jedai: but the gui IS stdin
13:26:49 <kmc_> i don't think so.  i am not an expert at UNIX file semantics
13:26:53 <napping> aep: you mean stdout?
13:26:57 <Jedai> aep: no, it's stdout
13:27:02 <aep> yes strdout/stdin
13:27:05 <aep> aaah!
13:27:17 <EvanR-work> stdin == gui sounds pretty misengineered
13:27:24 <aep> ok so i want 3 threads. for stdin/stdout/network
13:27:26 <aep> odd
13:27:29 <kmc_> it makes total sense conceptually to read and write a network socket at the same time
13:27:31 <geoaxis> hello people,whats a no brainer way to generate random numbers in haskell
13:27:43 <kmc_> aep, do you expect long blocking writing to stdout?
13:27:47 <koeien37> :t randomRIO
13:27:47 <sproingie> System.Random
13:27:48 <lambdabot> forall a. (Random a) => (a, a) -> IO a
13:27:50 <EvanR-work> geoaxis: print 4
13:28:02 <aep> kmc_: no.  stdout should be instant. its a  terminal (usually)
13:28:03 <koeien37> EvanR-work: you didn't throw a die, did you? ;)
13:28:10 <kmc_> aep, so it doesn't need its own thread
13:28:16 <EvanR-work> koeien37: nah, i just made it up
13:28:19 <sproingie> anyone want to take a crack at adding some vroom vroom to the NeHe lesson 11?
13:28:20 <Jedai> geoaxis: depend if you just need to do it in IO or you would like to do some random in pure code
13:28:21 <kmc_> because whatever other thread wants to write to stdout can just do it
13:28:22 <sproingie> http://haskell.pastebin.com/mecd569e
13:28:25 <ryo_hazuki> Jedai: what does this ! in front of the l do?
13:28:29 <EvanR-work> koeien37: i used xkcd rand as a seed
13:28:34 <aep> kmc_: that sounds pretty unsafe again.  oO
13:28:37 <sproingie> it runs at around 3FPS.  compared to 192 FPS with unoptimized C
13:28:37 <koeien37> EvanR-work: i thought so :)
13:28:40 <kmc_> urgh, mttxr--
13:28:41 <geoaxis> sproingie: example perhaps
13:28:48 <sproingie> geoaxis: see the pastebin
13:28:57 <kmc_> aep, how so?
13:29:19 <aep> kmc_: one thread writes "foo"  ther other writes "bar"  and it ends up as  "fbaroo"
13:29:21 <monochrom> Is this a provocative tactic to get other people to write code for you?
13:29:24 <Jedai> ryo_hazuki: well that says that go should be strict in its l argument, if you don't do that, the (1+) are not applied immediately and so you find yourself needing to unravel them at the end (thus stack overflow)
13:29:35 <kmc_> aep, yes, that will happen
13:29:37 <geoaxis> Jedai: pure would be nice
13:29:39 <Alpounet> Haagen Dazs for the win.
13:29:40 <sproingie> no it's just me going through the NeHe tutorials and fixing them to run
13:29:48 <kmc_> sorry, i thought you meant something else by "unsafe"
13:29:49 <Vulpyne> aep: You can have 2 threads write to stdout and nothing bad will happen, other than the output being garbled.
13:29:51 <aep> kmc_: so i need locking. which makes things complex D:
13:29:55 <kmc_> aep, no
13:29:56 <ryo_hazuki> Jedai: oh ok
13:29:58 <kmc_> you can just create a queue
13:30:02 <Jedai> ryo_hazuki: on the other hand, GHC is smart enough that it will realize itself that l should be strict if you use -O2
13:30:08 <kmc_> have a thread that just reads the queue and writes whole lines to stdout
13:30:13 <kmc_> any number of threads that dump stuff into the queue
13:30:16 <sproingie> they're all fine til i get to that one where it becomes a slideshow
13:30:19 <geoaxis> sproingie: was that pastebin for me
13:30:20 <EvanR-work> aep: dont write to the same fd. but note that you can write to same Chan or MVar just fine
13:30:39 <aep> see, multi threading is hard :D
13:30:43 <kmc_> EvanR-work, aep, I think the right model is that writing to the same fd is like writing to a (Chan Char) one at a time
13:30:54 <aeter> geoaxis: how about http://www.vex.net/~trebla/haskell/random.xhtml
13:31:03 <kmc_> whereas by making your own Chan you can have the atomic unit be something bigger than Char, i.e. [Char]
13:31:07 <EvanR-work> so the chan would be a list of String rather than Char
13:31:07 <kmc_> or MyStructuredMessageType
13:31:14 <aep> yeah
13:31:19 <sproingie> geoaxis: no sorry got my wires crossed
13:31:22 <kmc_> aep, we don't often need explicit locks in threaded Haskell code
13:31:26 <sproingie> that pastebin isn't a good example of how to do anything :)
13:31:28 <kmc_> people use MVars sort of as locks
13:31:35 <kmc_> but there are also message channels
13:31:39 <sproingie> except make opengl run real slow
13:31:45 <kmc_> and there's STM which is fancy and lockless
13:31:47 <monochrom> Control.Concurrent.Chan is very easy to use. You don't even realize it does some sync primitive inside. And stop your "but it's slow" drivel until you have benchmarks to prove it.
13:31:48 <EvanR-work> also theres no reason why there need to be locks at all. but its in the implementation, so dont worry about it
13:32:06 <aep> is there really no simple non blocking network in haskell?  i find having a huge threading,messaging,locking framework rather obscure for something simple as two fds :(
13:32:13 <kmc_> aep, threading is hard, but it's easier in Haskell than in most languages.  and it's more flexible than writing everything around one select loop
13:32:14 <Vulpyne> aep: Your stdout printing thread could just look like this: stdoutThread ch = forever $ atomically (readTChan ch) >>= putStrLn
13:32:23 <Vulpyne> aep: Where ch :: TChan String
13:32:30 <EvanR-work> aep: the whole thing is probably like four lines of haskell...
13:32:47 <aep> Vulpyne: hey thats cute, but how do i clean thatr thread up  when i'm done with it?
13:33:05 <Vulpyne> aep: forkIO gives you a threadID you could use to kill it if you wanted.
13:33:14 <sproingie> i bet i'd be better off ditching the IOUArray and just generating a whole new array every frame
13:33:15 <kmc_> aep, i don't think anyone said there's no way to do select() in Haskell
13:33:18 <monochrom> Oh God, someone else suggests my random tutorial!
13:33:22 * sproingie notes he did not write that code
13:33:25 <aep> really? just like that?  isn't that unsafe and leaves the GC in odd states?
13:33:27 <EvanR-work> kmc_: i specifically said otherwise
13:33:30 <Vulpyne> aep: Or you could use a TChan (Maybe String) and send a Nothing through to stop it.
13:33:31 <kmc_> just that it's not the cleanest way to do what you want
13:33:42 <aeter> monochrom: did you write it? It's awesome
13:33:49 <monochrom> Thanks, I wrote it.
13:33:55 <kmc_> Vulpyne, why do you need STM?  doesn't a regular Chan have individually atomic ops?
13:33:57 <Jedai> aep: No, it would be a rather poor solution if it didd
13:33:58 <luqui> aep, threads can block being killed.  they use this to keep things safe (eg. in stm)
13:34:16 <Vulpyne> kmc: No special reason, I'm just in the habit of using STM for everything.
13:34:17 <kmc_> aep, where do you get your ideas about which things are "unsafe"?
13:34:19 <monochrom> Perhaps Vulpyne brings up STM just for the awesomeness.
13:34:20 <kmc_> Haskell is not C++
13:34:28 <kmc_> Vulpyne, fair enough
13:34:44 <monochrom> Using int is unsafe.
13:34:46 <luqui> stm scales better than the other prims if you need to combine operations
13:35:01 <aep> kmc_: heh i don't know!  all i know about all this opscure threading/messaging/blocking/whatnot, i have from university. i never needed threads for anything other then cpu bound
13:35:02 <luqui> in the code effort sense, not necessarily the performance sense
13:35:23 <kmc_> aep, yes, other languages are in the dark ages with respect to concurrency and parallelism
13:35:33 <aep> so it is safe and ok to just kill a thread despite it is blocked?
13:35:46 <kmc_> aep, i believe so
13:35:47 <luqui> don't be fooled, haskell is also in the dark aes
13:35:51 <kmc_> if you try it and have problems, you can blame me
13:35:53 <luqui> we just have a slightly less oppressive church
13:35:55 <kmc_> can't say i've done this
13:35:57 <sproingie> this is weird.  time warp operating system, it's a distributed OS with only one synchronization primitive: rollback
13:36:02 <luqui> (by having a more oppressive compiler)
13:36:05 <Vulpyne> aep: Why do you want to kill it, though?
13:36:08 <EvanR-work> aep: for networking, you can also simply close the socket, then the thread will stop blocking due to an exception and die
13:36:15 <EvanR-work> use catch
13:36:17 <kmc_> luqui, the church of alonzo church
13:36:20 <Vulpyne> aep: Most likely at the point you're never going to want to print something to stdout, your programing is going to exit anyway.
13:36:21 <zoheb> Is there anyway to get a directory listing in Haskell in a platform independent way?
13:36:25 <Jedai> aep: if it is blocked then you can't kill it (that's the whole point of the block) but I don't think you have any reason to block in your case
13:36:28 <luqui> kmc_, :-D
13:36:29 <kmc_> there's that awful "separation of church and state" pun
13:36:32 <zoheb> I see System>posix
13:36:43 <Vulpyne> Jedai: He meant waiting on the TChan, I think.
13:36:47 <zoheb> which is not installed on GHC windows
13:36:49 <aep> EvanR-work: can i close the fd from a different thread without problems?
13:36:52 <kmc_> aep, threads you spawn with forkIO will not block the program's exit if the "main" thread quits
13:37:07 <kmc_> aep, i would not close a fd that another thread is operating on
13:37:10 <EvanR-work> aep: yes. the same exact exception occurs if the other end closed it
13:37:17 <Jedai> Vulpyne: oh ok
13:37:19 <EvanR-work> but then kmc_ says so
13:37:20 <doserj> zoheb: System.Directory.getDirectoryContents
13:37:20 <EvanR-work> no
13:37:21 <kmc_> EvanR-work, that works?
13:37:25 <kmc_> well, i'm guessing here
13:37:49 <EvanR-work> kmc_: thats what happens. no idea about portability (away from ghc) or stability
13:37:56 <zoheb> thanks
13:37:58 <kmc_> okay
13:38:10 <aep> well what do YOU do?  have complex message frameworks in threads to close fds, threads and whatnot?
13:38:13 <zoheb> I completely missed that when looking at the documentation
13:38:24 <zoheb> @doserj thanks
13:38:24 <lambdabot> Unknown command, try @list
13:38:33 <vic_> Good topic http://stackoverflow.com/questions/211216/hidden-features-of-haskell
13:38:37 <Jedai> ryo_hazuki: how does it go ?
13:38:45 <EvanR-work> aep: you seem to think that there is more to do that forkIO, writeMVar, writeChan, and the blocking read
13:38:49 <EvanR-work> than*
13:39:12 <EvanR-work> or killThread, if it suits you
13:39:12 <aep> EvanR-work: yeah, i just can't believe threads are easy. they have been a serious pain for me for years
13:39:36 <kmc_> aep, well i won't claim they are carefree, but i think we have a better approach
13:39:39 <aep> and the usual answer i get from java guys is "its easy! it just crashes randomly, but its sooo easy"
13:39:43 <Jedai> threads are much easier in Haskell than in most other languages
13:39:43 <kmc_> and a lot more to gain
13:39:53 <vic_> How about Erlang?
13:40:07 <Vulpyne> aep: What sort of program are you actually writing?
13:40:27 <monochrom> Of course Erlang has the best story. But Haskell's is quite good already.
13:40:33 <aep> Vulpyne: uh a mail program for fun and research. i'm planning on using haskell for a large scale server if it does what i need
13:40:34 <vic_> Indeed
13:40:45 <Jedai> aep: Haskell being pure, it encourages by itself a style which avoid most threading problems, with STM for most other cases, it makes threading in Haskell much safer and easier
13:40:48 <EvanR-work> aep: im writing a mud server, btw
13:41:03 <EvanR-work> the IO part is a joy compared to C
13:41:04 <aep> EvanR-work: ah cool. and you start a thread for each client?
13:41:16 <aep> i find i/o in C extremly easy :(
13:41:17 <EvanR-work> i have one to read from each client
13:41:21 <Vulpyne> aep: If you're sending mails, you'd generally have one thread per connection, and you wouldn't ever have to use the same handle from a different thread.
13:41:30 <Vulpyne> aep: Pretty much the same thing if a mailserver handling clients.
13:41:30 <EvanR-work> yes im a c master, and i found it easy. this is much easier
13:41:39 <sproingie> haskell threads are super-cheap.  it uses select under the covers when they're waiting on IO
13:41:41 <kmc_> aep, you may want to read: http://research.microsoft.com/en-us/um/people/simonpj/Papers/marktoberdorf/
13:41:48 <kmc_> that paper is 9 years old though
13:41:52 <sproingie> hopefully that patch to make it use epoll gets used soon
13:41:54 <aep> kmc_: aye.
13:41:56 <YuleAthas> sproingie: that does mean you can't use select() yourself, though, doesn't it?
13:42:00 <aep> EvanR-work: good to hear
13:42:13 <napping> YuleAthas: you can also call select on your own, if you really wanted to
13:42:14 <aep> EvanR-work: and you just kill the threads and dont care?  no problems with that?
13:42:44 <EvanR-work> aep: thats what killThread is for
13:42:45 <sproingie> YuleAthas: not on the same fd that a thread is waiting on, no.  you couldn't do that sanely anywhere
13:42:46 <napping> YuleAthas: there's another system where you can make foreign calls that may block, and the runtime will make more OS threads if too many get sucked into those calls
13:43:19 <EvanR-work> aep: you need to make sure you get rid of the ThreadID or it wont be GC'd though
13:43:20 <aep> EvanR-work: yeah i was just wondering if it doesnt leak or something or makes the GC behave odd. i'm quite .. not believing it :D
13:43:32 <aep> yeah thatws obvious
13:43:36 <sproingie> you're always free to write your own select reactor, tho it probably won't integrate as nicely into the thread scheduler
13:43:54 <aep> kmc_: that times out.  got a google keyword for me, so i know what you wanted me to read?
13:44:01 <kmc_> Tackling the Awkward Squad:
13:44:01 <kmc_> monadic input/output, concurrency, exceptions, and
13:44:01 <kmc_> foreign-language calls in Haskell
13:44:08 <kmc_> urgh sorry for \n
13:44:08 <aep> ah that one. thanks
13:44:14 <aep> i didnt understand it :(
13:44:19 <kmc_> aep, the research.microsoft.com http server has really odd behavior
13:44:26 <kmc_> some people are consistently unable to access it
13:44:32 <aep> i bet it is erlang. lol
13:44:33 <EvanR-work> kmc_: heh, that paper goes all over the place. gets pretty off topic ;)
13:44:37 <monochrom> It has some implementation details, that is why.
13:44:41 <napping> aep: have you used something like GSK or Twisted?
13:44:56 <aep> i read  twisted code, but never users it myself
13:45:04 <aep> i found it... odd
13:45:07 <napping> so just raw select calls?
13:45:14 <aep> for me? yes of course
13:45:25 <aep> for c++ i like boost::asio
13:45:35 <Berengal> non-blocking reads: do {var <- newEmptyMVarIO; forkIO $ readLine {- Or whatever -} >>= putMVar var; maybeReadValue <- tryTakeMVar var; return maybeReadValue}
13:45:40 <Berengal> Loop as neccessary
13:45:45 <napping> ah, okay. That is going to be a bit more change
13:46:00 <aep> ah great, you seem to understand my confusion :D
13:46:25 <napping> I suppose you've never done anything big enough that you wanted to modularize the code that handles different sorts of events
13:46:26 * hackagebot upload: dom-lt 0.1.3 - The Lengauer-Tarjan graph dominators algorithm. (MattMorrow)
13:46:52 <aep> napping: well i've used libs for that. like Qt
13:47:03 <napping> oh, Qt has an event system?
13:47:07 <EvanR-work> napping: in c, id do that after the raw select
13:47:17 <aep> yes, very similar to boost::asio.  its just callbacks
13:47:33 <napping> well, anyway think about the lifecycle of a socket or something
13:47:41 <aep> write fd data callback_when_done
13:47:50 <napping> there's IO that needs to happen, and then a callback with more work which sets up more IO and so on
13:47:53 <aep> cake
13:48:02 <aep> hmh
13:48:12 <napping> an even if there's shared data structures you don't have races so much because only one thread runs at a time
13:48:29 <ryo_hazuki> Jedai: the implementation without memoization doesnt work... ghc doesnt like the "!" and the memoized implementation still crashes with an overflow
13:48:31 <napping> but it's not exactly deterministic because you don't know what order clients will reply to you or whatever
13:48:45 <aep> napping: yeah thats obvious. same in C/select
13:48:56 <napping> so probably you don't really care about determinism but just that one thread at a time is working on the shared data
13:49:10 <aep> right
13:49:15 <Jedai> ryo_hazuki: oops sorry, the ! is an extension, you need to put {-# LANGUAGE BangPatterns #-} at the beginning of your file
13:49:56 <napping> so the only important part is that the state changes after the IO happen atomically w.r.t the state frobbing from other clients
13:49:58 <Jedai> ryo_hazuki: do you want to see my implementation ?
13:50:17 <ryo_hazuki> Jedai: i know your implementation, its in the thread and on haskell-euler
13:50:20 <ryo_hazuki> =)
13:50:21 <napping> in Haskell you could forkIO a separate thread for each client, and do the state manipulation in STM and get the same guarantees
13:50:37 <aep> napping: interesting.
13:50:39 <Jedai> ryo_hazuki: oh right :)
13:51:07 <Jedai> Did GHC like the ! better with BangPatterns ?
13:52:06 <aep> Berengal: thanks for that example. sounds nice
13:52:32 <Jedai> ryo_hazuki: you don't need it to be honest, you could use seq, but I find it nicer
13:52:58 <Jedai> ryo_hazuki: like "collatz n = go n 0 where go 1 l = l; go n l = l `seq` go (next n) (l+1)"
13:53:15 <Berengal> aep: The idea is just to fork off a thread that does the blocking IO, then puts the result in some thread-safe, non-blocking-readable container, such as an MVar, a TVar or a Chan
13:53:43 <kmc_> :t let unsafePerformIO :: IO a -> a; unsafePerformIO _ = error "bzzt" in unsafePerformIO
13:53:44 <lambdabot> forall a. IO a -> a
13:54:09 <joe____> i am about to work on a module that I plan to release on hackage. I find the link at http://www.hackage.rog/haskellwiki/How_to_write_a_Haskell_program very informative. Being a git user, I am wondering if such documentation exists for git instead of using darcs.
13:54:12 <aep> Berengal: but how do you act on that in the mainthread without again blocking it?
13:54:24 <Berengal> aep: Do the non-blocking read on the container
13:54:48 <kmc_> aep, if all your thread does is process events, you can do a blocking read on a single queue which gets every event
13:54:49 <Berengal> aep: tryTakeMVar, for example, returns a Maybe whateverIsInside
13:54:52 <ryo_hazuki> Jedai: crashes with stack overflow
13:54:56 <napping> aep: the main thread won't delay any other threads
13:55:04 <monochrom> I have a sequence of actions, "X; write; Y", the three actions are conceptually one sequence. My gripe with "write fd callback_when_done" is it splits out the Y part. I have one conceptual thing and you require me to shred it up, scatter one sequence over two places. See, in the Haskell paradigm, I just write "forkIO (X; write; Y)", I don't cruelly separate a family into two countries.
13:55:17 <Jedai> ryo_hazuki: ok, are you compiling with optimization ?
13:55:22 <napping> monochrom: it's just CPS
13:55:36 <Jedai> ryo_hazuki: "ghc -O2 --make p14.hs"
13:55:40 <aep> kmc_: aah!  can i can write into that from every thread. i see
13:55:41 <Berengal> aep: And STM has a very nice primitive, orElse, which splits the atomic transaction, allowing any path (but only one) to finish
13:55:42 <kmc_> it seems that a good model for replacing select() is: one thread per fd, each writes events into a shared queue; main thread does blocking read on this queue
13:55:50 <kmc_> aep, yes
13:55:56 <ryo_hazuki> Jedai: never used O2 before ... gimme a minute
13:56:02 <aep> Berengal: yeah the doc lost me on that one. gotta read more
13:56:13 <Jedai> ryo_hazuki: it helps some with the stack overflow (since GHC see the strictness) and it helps a lot with the speed
13:56:19 <monochrom> It is not consistently CPS until you do the whole thing in CPS. Split out the write part too.
13:56:44 <kmc_> if you need a periodic timeout, spawn a thread like forever (writeChan queue MyTimeoutEvent >> threadDelay someAmount)
13:56:50 <monochrom> Rewrite X to become X callback_when_done0, and have callback_when_done0 do write.
13:57:03 <monochrom> Moreover CPS in C is very hard to write and read.
13:57:17 <kmc_> it is very cool that the body of a thread is a first-class value and can be manipulated with functions
13:57:29 <kmc_> this is a good example of why functional programming is essential for imperative programming
13:57:32 <Berengal> aep: The concept is simple. "read a `orElse` read b" will return the contents of a if it's ready (that is, it doesn't call retry, which it does if it's empty), or else it will return the contents of b it is ready, or else it will retry the whole thing
13:57:39 <EvanR-work> aep: i just have an interesting solution to the imap thing. you do these two things in a forkIO forever....  email <- fetch uid; writeChan out email;  the reader thread makes a lazy list from the channel, and you have a 'lazy' downloader
13:57:41 <Cale> monochrom: You'd have to do lambda lifting and closure conversion yourself.
13:57:49 <ryo_hazuki> Jedai: runs in less than 5 seconds... any chance to use a time-function or something?
13:58:11 <EvanR-work> aep: see getChanContents
13:58:18 <napping> Cale: the compiler passes for urweb are impressive
13:58:32 <EvanR-work> aep: oops. nevermind you need an MVar ;)
13:58:36 <Jedai> ryo_hazuki: there are some, but if you just want to time your executable, try calling it with "+RTS -sstderr" in parameter
13:58:43 <mle> Berengal: if neither are ready, will it correctly wait for either, or just a, or busywait?
13:58:45 <aep> EvanR-work: nice
13:58:58 <napping> mle: both
13:59:04 <EvanR-work> theres no MVar -> lazy list function, but you could make one ;)
13:59:07 <mle> slick.
13:59:25 <napping> the thread gets added to the wait list on both variables, and unblocked when either changes, then it tries again
13:59:28 <Berengal> mle: I don't know the details, but I haven't seen 100% CPU useage on my machine when playing with this... that's all I really know. It should retry when any of the vars change, not just the first though.
13:59:37 <kmc_> EvanR-work, lazy IO is dodgy...
13:59:50 <EvanR-work> kmc_: :\
14:00:10 <EvanR-work> yeah it would only work in IO, but i think that was the original plan
14:00:12 <Berengal> I know very little about how STM is implemented, but I know a bit about how nice it is to use :)
14:00:23 <aep> kmc_: i need it, sort of. but i can implement a standard state engine.  just would be cute if it worked with haskell list sstyle
14:00:58 <ryo_hazuki> Jedai: 3,06s (((((:
14:01:20 <aep> anyway. need to experiment with this thread thing first. got quite some headsploding input now :D
14:01:24 <napping> aep: threads are usually tricky because you have mutable state
14:01:24 <ryo_hazuki> Jedai: my memoized impl doesnt finish when it compiled (waited around two minutes)...
14:01:40 <Jedai> ryo_hazuki: that's the time for direct calculation ? skipping the even I guess ?
14:01:46 <aep> napping: yeah. thats why i hate threads
14:01:54 <napping> just try writing some threads that do IO and don't share IORef's between them and it should work
14:02:11 <aep> but if threads are so cheap, i assume i can just fire a few hundret for stuff i need
14:02:28 <napping> see, that's why we get rid of variables, not threads
14:02:35 <Jedai> ryo_hazuki: I'm curious as to the time my implementation would take on your computer, could you try it ?
14:02:38 <aep> hehe
14:02:44 <ryo_hazuki> Jedai: dont know exactly, there is a point "Total time      3.06 (..."
14:02:49 <napping> by the way, there's nothing dangerous about sharing around pure code
14:02:53 <ryo_hazuki> Jedai: sure, gimme a minute
14:03:00 <napping> lazy evaluation is implemented to take care of itself
14:03:08 <kmc_> well, we didn't get rid of variables
14:03:11 <monochrom> Shared variables die die die.
14:03:14 <kmc_> they are just not the default
14:03:48 <kmc_> if you buy a TV you usually do not want to authorize Best Buy to break into your house and adjust your TV while you sleep
14:03:54 <monochrom> Note that in an alternative universe, channels are hardware-accelerated primitives and shared variables are considered slow.
14:04:07 <napping> like, your system in 5 years?
14:04:07 <kmc_> if you do, it is worth stating so explicitly
14:04:15 <monochrom> (think transputer for starters)
14:04:35 <aep> monochrom: build it!  i'd buy :P
14:04:40 <ryo_hazuki> Jedai: takes 1,17s
14:04:41 <napping> cache coherence can only stretch so far
14:04:58 <ryo_hazuki> Jedai: compiled with O2
14:05:23 <Jedai> ryo_hazuki: Yep, I'm sure you can do better, but at this point, it should be fast enough, probably ;)
14:05:37 <EvanR-work> if you tried to build it, linus was come destroy your plans because 'microkernels suck'
14:06:13 <napping> EvanR-work: aha, but we'd run everything in kernal space because we get memory safety from the compiler
14:06:25 <ryo_hazuki> Jedai: hehe, true... btw i'm curious what most peopple use as editor/ide?
14:06:45 <Jedai> ryo_hazuki: I use emacs mostly
14:06:51 <EvanR-work> napping: yes you would. because i was talking about haskell kernel ;)
14:06:52 <lament> vim, and the people who say emacs are lying
14:07:08 <troutwine> Emacs. Also, I always lie.
14:07:21 <Jedai> ryo_hazuki: leksah or eclipsefp are probably the closest to an IDE you can find
14:07:49 <Jedai> But emacs and vim are pretty good (as long as you're willing to learn to use one of them)
14:08:49 <lament> eclipsefp is pretty damn close to an IDE, being an IDE
14:08:59 <ryo_hazuki> i'm a bit into vim... would choose than one then
14:09:12 <ryo_hazuki> any nice plugins to integrate compiling, interpreter und stuff?
14:09:29 <ryo_hazuki> code completation if possible
14:09:50 <Jedai> lament: I meant by that that eclipsefp bring a lot of what you would expect of an _Haskell-specific_ IDE, not just the basic Eclipse environment
14:10:28 <lament> ryo_hazuki: supposedly vim has all of that
14:10:28 <Jedai> ryo_hazuki: haskell-mode for emacs, and there's something for vim too, I think the haskellwiki has details
14:10:28 <EvanR-work> ryo_hazuki: ctrl+N in vim ;)
14:10:39 <lament> there's a good page on vim
14:10:41 <emias> ryo_hazuki: http://projects.haskell.org/haskellmode-vim/
14:10:51 <lament> this is the vim page: http://www.cs.kent.ac.uk/people/staff/cr3/toolbox/haskell/Vim/vim.html
14:12:51 <sproingie> hah.  switching to boxed GLfloats instead of doing all that reboxing sped it up like 20x
14:14:53 <sproingie> ide-wise i'm a fan of emacs+flymake myself
14:15:39 <ryo_hazuki> nice, thanks ... gonna try the vim-haskell then =)
14:15:45 <ryo_hazuki> does vim
14:16:56 <ryo_hazuki> has vim something like flymake as well?
14:18:00 <sproingie> there's a port, it doesn't work that well
14:19:57 <sproingie> i had to hack flymake a little myself to make it deal with haskell warnings
14:21:48 <lifflander> What is the syntax for exporting from a module a "type"?
14:22:06 <EvanR-work> the name of the type
14:22:21 <EvanR-work> module Foo (Type) where
14:22:25 <monochrom> module Mine(Int) where
14:22:27 <lifflander> Nevermind, I thought that didn't work, but it does...
14:22:33 <lifflander> Had another problem...
14:25:55 <BMeph> Programming is EASY in Haskell:
14:26:01 <BMeph> > "Hello, world!"
14:26:02 <lambdabot>   "Hello, world!"
14:26:06 <BMeph> DONE!
14:26:12 <sproingie> if you want to export all constructors, you do Module Foo(Type(..)) where
14:26:39 <ryo_hazuki> WOW
14:26:41 <ryo_hazuki> AWESOME
14:26:42 <ryo_hazuki> !!!
14:26:45 <ryo_hazuki> (;
14:26:48 <BMeph> ;p
14:26:52 <sproingie> BMeph: not as easy as hq9+, where that program is "h"
14:26:53 <lifflander> Thanks for the help, I forgot a comma and thought it wasn't working...
14:27:06 <ryo_hazuki> not as easy whitespace
14:27:06 <BMeph> (For Twey: ;˛)
14:27:08 <ryo_hazuki>   
14:27:10 <ryo_hazuki> hehe
14:27:12 <ryo_hazuki> (((:
14:30:19 <sauf_> hi, how can the home key move the cursor to the beginning of the line instead of printing H like it does at the moment [in ghci]
14:30:20 <gwern> @quote weekend
14:30:21 <lambdabot> No quotes match. BOB says:  You seem to have forgotten your passwd, enter another!
14:30:27 <gwern> good grief
14:30:42 <gwern> @remember ndm I was browsing through the Yhc standard libraries, as one does on the weekend, and was drawn to Yhc's sort function.
14:30:42 <lambdabot> Done.
14:30:45 <gwern> @flush
14:31:05 <gwern> sauf_: that's unpleasant readline business. it likely involves changing termianls or editing .inputrc
14:31:07 <sauf_> same for the end key which prints an F instead of..
14:31:13 * gwern lights a candle for sauf_ 
14:31:54 <sauf_> strange for it works well outside ghci
14:32:05 <CalJohn> sauf_: interesting problem.  what terminal?
14:32:24 <sauf_> bash
14:32:31 <CalJohn> terminal, not shell :)
14:32:38 <CalJohn> ie: xterm or urxvt
14:32:56 <sauf_> ?
14:33:03 <CalJohn> type "echo $TERM"
14:33:06 <sauf_> kubuntu
14:33:21 <sauf_> xterm !
14:33:37 * BMeph lights two candles for sauf_
14:33:44 <ryo_hazuki> thanks everyone for the help btw... again i learned a lot =)
14:34:01 <sauf_> thx CalJohn
14:34:15 <sauf_> why BMeph ?
14:34:16 <BMeph> ryo_hazuki: Thanks for playing along, you've been great! :D
14:34:43 <ryo_hazuki> FAR TOO KIND OF YOU!!! ;)
14:35:14 <joe____> is there any haskell module that can translate C code into haskell code. I am not talking about FFI but literal rewriting the code from C to haskell
14:35:27 <j4cbo> ... how would that work?
14:35:34 <sproingie> lots of peek and poke
14:35:42 <sproingie> you would end up with C in haskell
14:36:10 <EvanR-work> switch -> case, f(int a, int b) -> f a b, malloc -> , ;)
14:36:12 <j4cbo> sure, you *could*, but i'm not sure why that could have any possible advantage over an FFI...
14:36:19 <sproingie> and no there's no such tool
14:36:22 <joe____> ok, thanks. before I embarked on the venture of porting the code from C files to haskell, just wanted to check if there was any utility that could help.
14:36:51 <jmcarthur> joe____: why are you doing this?
14:36:53 <j4cbo> if you want an idiomatic port, there's no possible way to do that automatically
14:36:56 <napping> why not use the FFI?
14:36:56 <gwern> compilign c to haskell? madness!
14:37:00 <j4cbo> not with the current state of AI, anyway :P
14:37:11 <EvanR-work> i want to do this
14:37:11 <holmak> well, maybe if you interfaced with #haskell
14:37:14 * EvanR-work starts writing
14:37:15 <gwern> or... genius? yo dawg
14:37:16 <joe____> i mean not compiling c to haskell, translate c code to haskell code.
14:37:18 <chrisf|work> you could compile c to haskell, and then compile it back to c ;)
14:37:27 <j4cbo> joe____: yeah.... no.
14:37:28 <gwern> joe____: er. that's the same thing
14:37:30 <sproingie> compilers are translators
14:37:35 <gwern> compilation = translation
14:37:41 <jmcarthur> joe____: that's called compiling
14:37:45 * EvanR-work defines pointers real fast...
14:37:56 <joe____> or maybe rewrite, would be the word I am looking for.
14:38:01 <jmcarthur> same thing
14:38:02 <gwern> same thing still
14:38:09 <napping> it should be pretty easy to rewrite a small part, and use FFI to call the C you haven't replaced
14:38:12 <j4cbo> no, i think he's asking for something which will produce output such that you can then throw away the C and only maintain the output?
14:38:14 <dons> look at Language.C for C generation
14:38:18 <sproingie> tho source->source translators aren't always constrained by managing to translate everything correctly
14:38:23 <dons> or LLVM and Harpy for programmatic asm generaiton
14:38:33 <j4cbo> i.e. an idiomatic source to source translation
14:38:35 <gwern> @hoogle parSort
14:38:36 <lambdabot> No results found
14:38:46 <j4cbo> which just won't happen
14:38:48 <joe____> j4cbo, yes that is what I am looking for.
14:38:51 <jmcarthur> j4cbo: sounds like an even more difficult compiler ;)
14:38:52 <gwern> hm. do the strategies carry overhead in the single-thread runcase?
14:39:36 <j4cbo> joe____: i suggest you try writing it, to see what it'd be like :P
14:39:44 <joe____> there is a C library that does what I want. I could re-write it in haskell (probably a few hours) or I could build a FFI to it. which one would you recommend?
14:39:47 <napping> I guess they would still show up as calls
14:39:52 <jmcarthur> joe____: FFI
14:39:54 <BMeph> EvanR-work: While you're at it, would you translate some FORTRAN for me? Since I haven't used is actively for over 25 years, I've gotten a little rusty, and all those goto statements make me dizzy. Thanks a lot! ;˛
14:40:07 <EvanR-work> no prob
14:40:08 <BMeph> haven't used *it
14:40:20 <jmcarthur> joe____: only rewrite it if it's trivial
14:40:34 <EvanR-work> FORTRAN, BASIC, COBOL <- languages why they invented caps lock
14:40:46 <benmachine> I think there should be more pure haskell libraries
14:40:49 * sproingie ports his code to HASKELL
14:40:51 <benmachine> so I'd say rewrite
14:40:55 <benmachine> but it depends on your priorities
14:40:57 <joe____> the library is http://www.intra2net.com/en/developer/libftdi/download/libftdi-0.17.tar.gz
14:40:59 <troutwine> Is it even theoretically possible to do idiomatic translation for arbitrary programs between any two languages?
14:40:59 <jmcarthur> joe____: if you consider a few hours to be trivial, go for it
14:41:15 <jmcarthur> joe____: i don't really want to download a library just to see what it is ;)
14:41:19 <sproingie> depends on how you define "idiomatic"
14:41:30 <benmachine> troutwine: a lot of things are *theoretically* possible...
14:41:47 <troutwine> sproingie: True.
14:42:00 <joe____> http://www.intra2net.com/en/developer/libftdi/documentation/index.html
14:42:10 <sinelaw> luqui, i have real performance trouble with your lib
14:42:10 <lambdabot> sinelaw: You have 1 new message. '/msg lambdabot @messages' to read it.
14:42:23 <troutwine> benmachine: Perhaps I should have said tractable.
14:42:30 <lpsmith> preflex:  seen dolio
14:42:30 <preflex>  dolio was last seen on #haskell 14 hours, 48 minutes and 39 seconds ago, saying: Presumably it's not a book on "my misunderstanding of how to properly apply diagonalization to some structure proves that there's no correct way to do it."
14:42:34 <sproingie> well i got nehe11 to run at an acceptable speed if not awesomely fast
14:42:45 <sinelaw> preflex, seen conal
14:42:45 <preflex>  conal was last seen on #haskell-blah 2 hours, 26 minutes and 5 seconds ago, saying: :)
14:42:47 <theorbtwo> It's especially hard between languages that really don't translate well.  Translating from Pascal to C is maybe not so hard.  From Haskell to C, really quite hard.
14:42:50 <sproingie> the old one ran at glacial speed because it was as literal a port as could be
14:43:19 <jmcarthur> joe____: you think that will only take a few hours?
14:43:22 <holmak> ftdi looks like a solid FFI candidate
14:43:36 <jmcarthur> joe____: if that's true then you are a better coder than i
14:43:45 <joe____> jmcarthur: it is a wrapper around libusb?
14:43:58 <joe____> jmcarthur, i am not a better coder than you.
14:44:10 <sproingie> theorbtwo: translating haskell to C is done with a compiler :)
14:44:12 <joe____> but I see that lot of the functions are just sending control messages to usb
14:44:18 <jmcarthur> joe____: you are making assumptions
14:44:37 <jmcarthur> joe____: do we have a libusb binding already?
14:45:14 <joe____> i have played around with usb haskell module
14:45:15 <theorbtwo> sproingie: *idiomatic* translation -- translation from readable haskell to readable c, at least.
14:45:18 <joe____> is that what you mean?
14:45:28 <jmcarthur> joe____: i was just asking if one exists
14:45:28 <sproingie> what is this ... "readable c" of which you speak?
14:45:34 <napping> theorbtwo: ghc -fvia-C --keep-hc-files
14:45:41 <joe____> jmcarthur: yes.
14:46:09 <sauf_> gwern: I don't have a .inputrc neither in /home nor in /usr. Do you know if I can safely try to install another terminal ?
14:46:14 <joe____> jmcarthur: yes, we even have ls-usb which is a wrapper on the usb bindings.
14:46:16 <gwern> of course you can
14:46:26 <gwern> sauf_: .inpturc is for changing defaults basically
14:46:27 <sproingie> const char *haskell_source; run_haskell(haskell_source);
14:46:29 <sproingie> there
14:46:30 <gwern> when you need to voerride
14:46:35 <napping> joe____: that looks like the sort of library that's full of knowledge about obscure hardware. Probably better to wrap it than to try to stay in sync
14:46:55 <CalJohn> I am using the maybe monad to model failure.  I would quite like to return an error message (String).  Either seems like the obvious way to do this, but it's not monadic.  Ideas?
14:46:56 <troutwine> sauf_: On my system it's /etc/inputrc
14:47:01 <sinelaw> luqui, do you think there's a way to make your library cache pre-rendered surface or something like that? I don't know much about opengl
14:47:06 <joe____> yes, the sync is what I am worried about.
14:47:09 <theorbtwo> The FTDI chip isn't terribly obscure.
14:47:12 <jmcarthur> joe____: well, i don't know this library, but i would use FFI
14:47:18 <jmcarthur> based on what i know
14:47:25 <sauf_> thx troutwine
14:47:25 <sinelaw> luqui, because i don't exactly know why, performance really degrades quickly
14:48:07 <kmc_> Cale, (Either String) is a monad
14:48:09 <kmc_> @instances Monad
14:48:10 <lambdabot> ((->) r), ArrowMonad a, Cont r, ContT r m, Either e, ErrorT e m, IO, Maybe, RWS r w s, RWST r w s m, Reader r, ReaderT r m, ST s, State s, StateT s m, Writer w, WriterT w m, []
14:48:19 <joe____> i read through the ffi documentation on RWH and I find that it entails almost the same effort as re-writing in haskell.
14:48:27 <kmc_> > do { throwError "whoops"; return 3} :: Either String Int
14:48:27 <lambdabot>   Left "whoops"
14:48:29 <CalJohn> kmc_: erm, where you talking to me?
14:48:33 <joe____> it could be my beginner's assumption?
14:48:33 <kmc_> whoops
14:48:34 <sauf_> # allow the use of the Home/End keysn"\e[1~": beginning-of-linen"\e[4~": end-of-linen
14:48:34 <kmc_> sorry Cale
14:48:35 <lunabot>  luna: parse error on input `of'
14:48:36 <kmc_> yes CalJohn
14:49:01 <kmc_> > do { return 3} :: Either String Int
14:49:01 <sproingie> i suspect Cale knows already :)
14:49:02 <lambdabot>   Right 3
14:49:02 <sauf_> ok but what the relation  with ghci
14:50:04 <CalJohn> kmc_: that is not monadic in the prelude, where is that instance defined?
14:50:10 <kmc_> maybe Control.Monad
14:50:13 <kmc_> i thought it was in the prelude
14:50:43 <kmc_> ah, it's Control.Monad.Error
14:50:51 <jmcarthur> joe____: even if the effort is the same, it's more reliable to not reinvent the wheel. the FFI is simply tedious, while reimplementing is both tedious and error prone
14:51:11 * kmc_ wishes they'd created an "Error" type isomorphic to Either, instead of corrupting the symmetric Either with this asymmetric property
14:51:18 <jmcarthur> joe____: plus what was said earlier about staying in sync
14:51:29 <joe____> jmcarthur: thanks, then I will go the FFI route.
14:51:41 <napping> joe____: also, check out c2hs
14:52:26 <kmc_> ah i asked this yesterday but here goes: if i have some audio samples, and just want to dump them to the sound card, what's a good Haskell library for this?
14:52:31 <joe____> napping: yes, i have been reading up on it.
14:52:34 <kmc_> need only work on Linux
14:53:06 <jmcarthur> joe____: something else too at is the bindings-DSL package. i recently became rather attached to it
14:53:12 <jmcarthur> *else to look at
14:53:12 <CalJohn> kmc_: thanks for that
14:53:23 <joe____> jmcarthur: i will check it out.
14:53:34 <sproingie> kmc_: alsa perhaps
14:54:26 <joe____> bindings-dsl looks very interesting. I will read up on it.
14:54:55 <troutwine> sauf_: How did you install ghc, with apt?
14:55:09 <kmc_> sproingie, hmm, it's a thin FFI wrapper.  still, plenty of C-language ALSA tutorials, i should be able to figure it out
14:55:10 <kmc_> thanks
14:55:31 <EvanR-work> alsa is a beast
14:56:08 <EvanR-work> but unless you join the pulse cult or alsa gets better oss compatabilty, were stuck
14:56:46 <EvanR-work> kmc_: port audio?
14:56:49 * Cale can't stand pulseaudio and its insidious tentacles.
14:57:06 <EvanR-work> http://hackage.haskell.org/package/portaudio
14:57:10 <kmc_> looks a bit more documented
14:57:16 <kmc_> i mean, there are dozens of audio libs on hackage
14:57:16 <Cale> "Let's make sound on linux completely broken by default!"
14:57:17 <kmc_> i've looked at some
14:57:22 <medfly> yay!
14:57:34 <kmc_> i was hoping for a specific recommendation
14:57:38 <EvanR-work> Cale: three years after they made it not broken by default, with widespread alsa support
14:57:45 <EvanR-work> ubuntu is cool like that
14:58:04 <kmc_> audio on linux is a classic case of too many wheels, not enough rolling
14:58:09 <Cale> EvanR-work: I have the latest ubuntu, and still have to remove pulseaudio to get anything to work.
14:58:13 <sauf_> troutwine: yes, aptitude exactly
14:58:26 <kmc_> how many next generation audio plugin frameworks / network-transparent realtime audio servers are there?
14:58:33 <kmc_> and how many can deliver on even basic functionality?
14:58:50 <EvanR-work> jack works but its not meant for general 'play my audio' scenarios
14:58:55 <Cale> EvanR-work: Specifically, if I don't remove pulseaudio, there's only one master volume control, and my headphones don't work at all.
14:59:25 <EvanR-work> kmc_: /dev/dsp for the win ;)
14:59:26 <Cale> (and I'm not sure, but I think also my microphone didn't work)
14:59:34 * kmc_ has had no use for a sound daemon, except over network in specific use cases
14:59:46 <kmc_> It is nice to play video on a projector and get audio on my laptop
15:00:01 <troutwine> sauf_: Peculiar. Home/End work just fine on my Debian system, though I'm using urxvt rather than xterm.
15:00:08 <EvanR-work> Cale: in #sdl and #lad most audio problems on ubuntu are solved with 'remove pulse'
15:00:10 <Cale> Alsa might be stupidly complicated, but at least has the nice property of actually working.
15:00:41 <ehird> ossv4 is good i hear
15:00:53 <ehird> not so good code, but low latency, high quality, simple, open source
15:01:05 <CalJohn> yeah, open source _now_
15:01:12 <kmc_> isn't oss dead as rocks?
15:01:21 <ehird> kmc_: no, oss <v4 is
15:01:24 <ehird> but ossv4 is shiny and new
15:01:29 <monochrom> ubuntu and pulseaudio work for me, I didn't do anything. oops wrong window.
15:01:29 <CalJohn> no, it's always been alive, but it went proprietory for a long time
15:01:35 <sauf_> troutwine: what is that ? [I can't see urxvt in aptitude]
15:01:42 <ehird> monochrom: oh the wit.
15:01:43 <kmc_> do people really want another upheaval of linux audio drivers?
15:01:51 <ehird> sauf_: the package is rxvt-unicode
15:01:53 <kmc_> what's wrong with alsa that we need to ditch it for ossv4?
15:02:02 <ehird> rxvt = like xterm but with less backwards compatibility rubbish; u = unicode
15:02:18 <ehird> kmc_: high-latency, too low-level in capabilities (which is why we have pulseaudio)
15:02:21 <sauf_> ehird: thx.
15:02:37 <CalJohn> well, the original thing is that they fixed the problems with ossv3, but never released those fixes, so ALL of alsa had to be written and ALL of pulse had to be written to "fix" alsa
15:02:40 <troutwine> sauf_: It's rxvt-unicode. Sorry about that.
15:03:17 <monochrom> urxvt = u rxvt where { rxvt = xterm `delete` backward; u = unicode }
15:03:18 <CalJohn> sound in linux could have been working a decade ago, but fools prevented it
15:03:41 <sinelaw> luqui, actually i think my problem is elsewhere...never mind.
15:04:56 <luqui> sinelaw, fwiw, display list caching is possible, but it doesn't buy you all that much
15:05:01 <sauf_> troutwine: no problem. ok, I installed it. Is it on the graphical menus or have I type something [from xterm !]
15:05:20 <luqui> sinelaw, and involves talking to the GC and other ugly crap
15:05:31 <svk_> How do I use the FFI with ghc? I'm trying to export some functions but I can't get it to compile
15:05:32 <sinelaw> luqui, it's ok, i think my problem was excessive redraw, more than my computer can handle (and too many times a second)
15:05:36 <troutwine> sauf_: No idea. I use xmonad and dmenu. :)
15:05:43 <svk_> It says "invalid type signature" at the foreign export line
15:06:09 <troutwine> sauf_: Maybe if you're using Gnome you can press Alt+F2 and type rxvt?
15:06:43 <increpare> more uniplate runins- it seems not to be recursing into my structures, and I'm not sure why ( -> http://pastebin.com/m2de237aa )
15:06:50 <ehird> troutwine: urxvt, rather
15:07:05 <monochrom> svk_: {-# LANGUAGE ForeignFunctionInterface #-}
15:07:50 <increpare> ah, it seems to work if I replace the set with a list : (
15:07:50 <svk_> Hm, thanks, that seems to work
15:08:14 <sinelaw> luqui, my problem is actually how to redraw the screen at up to some maximum rate,
15:08:18 <troutwine> ehird: Quite right. (Though they might be symlinked, as they are on most Debian systems.)
15:08:23 <sauf_> ok, I typed rxvy [in xterm] then the new terminal, then ghci, then some keys, then home but prints '7~'
15:08:25 <sinelaw> luqui, my program uses Yampa so i'm not sure how to do that
15:08:35 <sauf_> :[
15:08:45 <luqui> sinelaw, sample by an event?
15:08:53 <luqui> i haven't used yampa
15:09:02 <sinelaw> luqui, yeah but mouse motion events pop up too often
15:09:29 <ehird> sauf_: you'll have to tell the terminal about your keys :P
15:09:51 <sinelaw> luqui, i'm using it because i don't know of any _working_ alternative
15:09:53 <luqui> sinelaw, i mean you have a continuous SF a b.  sample it by an event that happens 30 times per second, getting an SF a (Maybe b)
15:09:58 <luqui> and then join it back together?
15:10:33 <sauf_> ehird: is it sufficient to modify inputrc with vi ?
15:10:34 <sinelaw> something like that, except my mouse motion events are currently events, not continuous
15:10:51 <sinelaw> luqui, now that my program actually works, i need to re-think a few things
15:10:54 <ehird> sauf_: i think it's the terminal you want to inform not the shell
15:10:59 <luqui> sinelaw, yeah that's okay, they get folded into the rest of your program, giving you a continuous output signal
15:11:14 <sauf_> ehird: how can I do that ?
15:11:28 <luqui> sinelaw, i am speaking with very little knowledge though.  but that strikes me as "The frp way" to do it
15:11:29 * increpare curses his internet connection
15:11:34 <sinelaw> luqui, not continuous, but very dense if the user is moving his mouse
15:11:40 <ehird> sauf_: not sure
15:11:47 <EvanR-work> if you curse your internet connection, wont that make it worse?
15:11:53 <luqui> sinelaw, by continuous i mean without a Maybe in the codomain
15:12:07 <sinelaw> holy cow
15:12:09 <troutwine> suaf_: This question is probably better suited to #ubuntu, I'm afraid.
15:12:17 * sinelaw nearly had a heart attack, a balloon just exploded over his head
15:12:41 <luqui> i would expect a near heart attack to look more like  sinelaw: 4hhhwt09[jut409
15:12:52 <joe____> jmcarthur: I cannot make much sense of bindings-dsl. how does it help? I am looking at the code of bindings-libusb and it seems to be similar to hsc2hs
15:12:55 <sauf_> troutwine: but the problem is within ghci !
15:13:05 <increpare> EvanR: indeed.
15:13:05 <sauf_> troutwine: only
15:13:14 <sinelaw> luqui, :)
15:13:19 <jmcarthur> joe____: have you looked at bindings-dsl's documentation?
15:13:54 <joe____> jmcarthur: i am looking at the bitbucket.org/mauricio/bindings-dsl/wiki/... . is there a better documentation?
15:14:07 <troutwine> sauf_: Quite so, but it's still system specific and is, likely, a configuration error.
15:14:28 <troutwine> sauf_: https://bugs.launchpad.net/ubuntu/+source/ghc6/+bug/483455
15:14:30 * kmc_ generates a waveform in GHCi with a list comprehension and sends it to portaudio
15:14:32 <kmc_> it worked!
15:14:37 <sinelaw> luqui, looks like yampa has sample :: Time -> SF a (Event a)
15:15:06 <sinelaw> i can use that
15:15:10 <joe____> jmcarthur: sorry if I am not in the correct path.
15:15:42 <troutwine> sauf_: Presumably this is the problem of which you complain?
15:15:47 <luqui> together with a step function: a -> SF (Event a) a
15:16:00 <sauf_> troutwine: yes, many thanks !
15:16:33 <troutwine> sauf_: Sure, no problem. I googled "ghci ubuntu home end".
15:17:05 <lhoersten> It's not possible to make a class and then use that class as the list type is it? ex: class A... data D = D [A]
15:17:19 <kmc_> lhoersten, no
15:17:22 <kmc_> a class is not a type
15:17:23 <EvanR-work> kmc_: btw, how is haskell for real time sound generation.
15:17:34 <jmcarthur> joe____: perhaps you would learn the value of macro packages like bindings-dsl after you try writing a binding without it first
15:17:40 <lhoersten> kmc_: to make a "heterogenious collection" i need to use an algebraic data type then?
15:17:49 <kmc_> this is allowed by a GHC extension: data D = forall a. (A a) => D [a]
15:17:51 <joe____> jmcarthur: ok, will do so..
15:17:54 <kmc_> that's called an existential type
15:17:58 <joe____> jmcarthur: thanks.
15:18:37 <kmc_> EvanR-work, i have no idea, i'm just starting a stupid simple project
15:18:38 <lhoersten> kmc_: that means for every instance of A?
15:18:44 <kmc_> lhoersten, http://haskell.org/haskellwiki/Existential_type
15:18:47 <pikhq> kmc_: Hmm. Y'know, it's kinda funny.
15:18:47 <lhoersten> thanks
15:19:01 <pikhq> I learned predicate logic *after* learning about existential types.
15:19:08 <kmc_> lhoersten, it means that when you pattern match on the constructor D, you know that the type in the list is some member of the class A, but the actual concrete type is hidden
15:19:20 <kmc_> this is indeed how to make a heterogeneous collection in Haskell
15:19:28 <pikhq> So, the meaning of "forall a. (A a)" clicked in the middle of learning predicate logic... XD
15:19:33 <lhoersten> kmc_: ok thanks
15:19:40 <kmc_> or you can use Data.Dynamic, which is sort of an open-ended existential wrapper over every type in the language
15:19:54 <lhoersten> pikhq: what part of predicate logic made this click?
15:19:55 <jmcarthur> luqui: heh, so you continue to be haunted by frp. i keep finding myself doing the same thing. i try to get by without but fail
15:19:58 <EvanR-work> is there any way to do it without the extension
15:20:04 <kmc_> pikhq, yeah... but it's weird how Haskell uses a universal quantifier to express an existential
15:20:37 <lhoersten> kmc_: I'm weighing the pros and cons of this vs. just an algebraic data type
15:21:03 <pikhq> lhoersten: Well, the existential types thing amounts to a (very bizarre, barebones) predicate logic in the typesystem...
15:21:08 <kmc_> the idea i think is that the Church encoding of the type above is: forall r. (forall a. (A a) => [a] -> r) -> r
15:21:09 <pikhq> kmc_: Yeah... Kinda is.
15:21:16 <kmc_> which is a rank-2 universally quantified type
15:21:58 <kmc_> lhoersten, it's a question of "closed" versus "open"
15:22:10 <kmc_> if you can enumerate right now the alternatives, it's best to use an algebraic type with multiple constructors
15:22:13 <lhoersten> closed definitely is looking better =)
15:22:22 <kmc_> if users need to be able to define their own types and add them, you need typeclass + existential
15:22:39 <lhoersten> yeah that's not needed here
15:22:53 <kmc_> existential quantification of a class-bounded type models something not entirely unlike object-oriented programming with interfaces
15:22:57 <lhoersten> I was going typeclass because I was trying to clean up the pattering matching in the functions
15:23:29 <kmc_> you might have a use for typeclasses even setting aside the existential
15:23:42 <lhoersten> that brings me to my next question. is it possible to pattern match the data constructor without matching the rest of the type?
15:23:53 <kmc_> if you factor in typeclasses from the beginning, it can be easier to change representation later
15:24:02 <kmc_> lhoersten, well, matching the data constructor does not match the type at all
15:24:15 <kmc_> you mean without matching the data fields?
15:24:19 <lhoersten> yeah sorry
15:24:21 <lhoersten> that's exactly what I mean
15:24:22 <kmc_> you can use _, the pattern which matches anything and ignores it
15:24:27 <kmc_> but you need the right number of _ still
15:24:28 <lhoersten> right but i don't even want those
15:24:33 <kmc_> > case Just 3 of Just _ -> ()
15:24:34 <lambdabot>   ()
15:24:44 <kmc_> then you'd have to resort to something like Data.Data
15:24:53 <kmc_> which reifies constructors
15:25:04 <Vulpyne> > case undefined of _ -> ()
15:25:04 <lambdabot>   ()
15:25:12 <kmc_> > toConstr (Just 3)
15:25:12 <lambdabot>   Just
15:25:20 <lhoersten> reifies?
15:25:20 <kmc_> :t toConstr (Just 3)
15:25:21 <lambdabot> Constr
15:25:26 <kmc_> lhoersten, makes real or "first-class"
15:25:34 <lhoersten> awesome
15:25:39 <Vulpyne> :t toConstr
15:25:40 <lambdabot> forall a. (Data a) => a -> Constr
15:25:40 <lhoersten> that looks like my best bet
15:25:44 <Vulpyne> Interesting.
15:25:49 <kmc_> > constrRep . toConstr $ Just 3
15:25:51 <lambdabot>   AlgConstr 2
15:25:56 <kmc_> > constrRep . toConstr $ Nothing
15:25:57 <lambdabot>   Ambiguous type variable `a' in the constraint:
15:25:57 <lambdabot>    `Data.Data.Data a'
15:25:57 <lambdabot>      a...
15:26:02 <kmc_> > constrRep . toConstr $ (Nothing :: Maybe ())
15:26:03 <lambdabot>   AlgConstr 1
15:26:21 <lhoersten> well let me explain my problem a bit more. Maybe there are better higher level solutions I'm not aware of
15:26:32 <kmc_> lhoersten, that's always great to hear :)
15:26:45 <kmc_> > toConstr "foo"
15:26:46 <lambdabot>   (:)
15:26:53 <kmc_> > toConstr 'x'
15:26:54 <lhoersten> I have 3 types, each one has the same fields plus more than the last (so A is bigger than B is bigger than C)
15:26:54 <lambdabot>   x
15:27:05 <lhoersten> and they all can go into a list and then I want to pull them out and inspect
15:27:41 <Raynes> @hoogle on
15:27:42 <lambdabot> Data.Function on :: (b -> b -> c) -> (a -> b) -> a -> a -> c
15:27:42 <lambdabot> Text.PrettyPrint.HughesPJ OneLineMode :: Mode
15:27:42 <lambdabot> Text.Parsec.Char oneOf :: Stream s m Char => [Char] -> ParsecT s u m Char
15:27:42 <lhoersten> so 'data R = A Int Int Int | B Int Int | C Int' and then some other type 'data X = [R]'
15:27:52 <Vulpyne> Why not make more constructors in the same type?
15:28:17 <Vulpyne> data ABC = A Int | B Int Int | C Int Int Int or whatever.
15:28:19 <lhoersten> because the first two ints are both basically ID. I want to use record syntax for accessing
15:28:44 <kmc_> "data X = [R]" isn't valid; if you want a simple synonym it'd be "type X = [R]"
15:29:07 <kmc_> each alternative on the RHS of "data" must introduce a constructor
15:29:11 <lhoersten> kmc_: that was just shorthand for something like "data X = { stuff :: [R] }"
15:29:26 <kmc_> well, you're still missing a constructor there, but okay
15:29:34 <lhoersten> yeah but you get the idea
15:29:43 <lhoersten> "data X = X { stuff :: [R] }"
15:30:33 <lhoersten> so I want to look through Xs stuff list for all the A ctrs of R
15:30:57 <lhoersten> but then I have to pattern match the whole type apart to just check the constructor
15:31:05 <kmc_> yeah, Data.Data can solve this problem
15:31:11 <Vulpyne> filter (\i -> case i of { A _ -> True ; _ -> False } list_of_rs
15:31:12 <lhoersten> cool I'll read up on that
15:31:13 <lhoersten> thanks
15:31:16 <Vulpyne> You could do something like that.
15:31:21 <ane_> you can also use pattern matching with list comprehensions
15:31:23 <kmc_> if it's really this simple, i would just write the _ patterns
15:31:25 <kmc_> perhaps once
15:31:27 <lhoersten> yeah I'm using filter too but then the filter function has to do it etc
15:31:38 <kmc_> isA :: R -> Bool; isA (A _) = True; isA _ = False
15:31:53 <lhoersten> well the R datatype is much more complicated and has some overlapping field in each constructor
15:31:54 <Vulpyne> Well, if you have a list of things and you want to extract just certain items from it, it's going to be the same either way.
15:32:04 <kmc_> lhoersten, GHC can derive instances of Typeable and Data, with the appropriate extension
15:32:32 <lhoersten> I'll have to read up on Data.Data. I've never looked at it before
15:32:39 <lhoersten> that may be what I want
15:32:50 <kmc_> lhoersten, it comes from the Scrap Your Boilerplate generic-programming stuff
15:32:51 <kmc_> @where SYB
15:32:52 <lambdabot> http://www.cs.vu.nl/boilerplate
15:33:00 <lhoersten> I actually think the 'isA' might be fine
15:33:12 <kmc_> much of SYB isn't relative to this problem, but is interesting and good to know about
15:33:12 <dibblego> can any HXT users help out with this problem? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14850#a14850
15:33:21 <lhoersten> thanks
15:34:58 <kmc_> > dataTypeOf (Just 'x')
15:34:59 <lambdabot>   DataType {tycon = "Prelude.Maybe", datarep = AlgRep [Nothing,Just]}
15:35:13 <kmc_> > typeOf (Just 'x')
15:35:14 <lambdabot>   Maybe Char
15:35:29 * ksf is wondering whatever happened to synchronous languages
15:35:40 <kmc_> > toConstr (\x -> x ())
15:35:41 <lambdabot>   Ambiguous type variable `t' in the constraint:
15:35:41 <lambdabot>    `Data.Data.Data t'
15:35:41 <lambdabot>      a...
15:35:54 <ksf> I've done a fair bit of googling, and it seems that the only living languages are lustre, which is proprietary, and atom
15:35:56 <kmc_> > toConstr (\x -> (x :: () -> Char) ())
15:35:57 <lambdabot>   * Exception: toConstr
15:35:58 <Raynes> @src on
15:35:59 <lambdabot> (*) `on` f = \x y -> f x * f y
15:36:07 <kmc_> > typeOf (\x -> (x :: () -> Char) ())
15:36:08 <lambdabot>   (() -> Char) -> Char
15:36:24 <kmc_> > dataTypeOf (\x -> (x :: () -> Char) ())
15:36:25 <lambdabot>   DataType {tycon = "Prelude.(->)", datarep = NoRep}
15:36:34 <Berengal> dibblego: What is the problem?
15:36:53 <dibblego> Berengal, the tags list is empty when running, where I expect two entries
15:37:24 <ksf> well, and then there's some graphical environments geared mostly towards dsp programming
15:42:07 <dons> btw, in case anyone needs a reference on how to sort large arrays in Haskell, http://haskell.org/haskellwiki/Sorting_large_arrays
15:42:14 <dons> for whatever nefarious purpose.
15:42:31 <dibblego> Berengal, I'm following the example at http://www.haskell.org/haskellwiki/HXT/Conversion_of_Haskell_data_from/to_XML
15:43:02 <Berengal> dibblego: I'm sorry, but I haven't really used that part of HXT
15:43:12 <joe____> jmcarthur, quick question: is bindings-dsl hardcoded on top of hsc2hs or does it work with c2hs?
15:43:21 <dibblego> Berengal, which part have you used?
15:43:38 <joe____> jmcarthur: sorry if it is a stupid question. just want to know before I go off on a tangent.
15:44:10 <joe____> bindings-libusb uses hsc2hs
15:44:19 <Berengal> dibblego: The filter arrow part, mostly
15:44:25 <joe____> but everybody has been raving about c2hs.
15:44:28 <dons> dolio: did you ever look at parallel uvector algos?
15:45:09 <chrisdone> so I really want to write a web site using a logic language for the database
15:45:23 <chrisdone> do you think I could layer a logic language as query language ontop of happstack?
15:45:52 <kmc_> Prolog on Paddleboats
15:46:03 <Berengal> chrisdone: Do you mean the happstack-state part?
15:46:26 <chrisdone> possibly. I don't know much about it, just curious
15:46:55 <dons> kmc_: roxors
15:46:57 <Berengal> Happstack lives in IO, so you can pretty much do what you want.
15:47:49 <elly> open question, #haskell: one of my professors, who is a kernel hacker, sent me an email asking which Haskell book I'd recommend. Any suggestions?
15:47:49 <chrisdone> kmc_: is that a library? google turns up not much
15:47:51 <Berengal> chrisdone: I don't imagine you'd have any more trouble doing any sort of database stuff in happstack than anywhere else
15:47:55 <kmc_> nah, it's a joke
15:47:57 <dons> the IO monad is *freedom*
15:48:03 <dons> chrisdone: :P
15:48:21 <dons> ok. we so need to get some "Prolog on Paddleboats" stickers printed up for ICFP
15:48:29 <Berengal> dons: Freedom enough to shoot yourself in the foot
15:48:29 <chrisdone> haha
15:48:37 <joe____> if I want to use bindings-dsl, should I use hsc2hs or can I use c2hs?
15:48:42 <kmc_> just enough rope to shoot yourself in the foot
15:48:46 <dons> also "Enemy of the State" haskell stickers
15:48:49 <kmc_> haha
15:48:51 <dons> mwhaha
15:49:10 <monochrom> elly: I recommend Bird's "introduction to functional programming using haskell" 2nd edition to profs.
15:49:21 <elly> he already knows Standard ML
15:49:31 <ksf> joe____, I'd use c2hs unless I'm working on code that already contains hsc2hs stuff
15:49:43 <dons> if you know SML, then I'd say RWH.
15:49:52 <elly> okay, excellent
15:49:52 <dons> elly: one of the authors is a kernel hacker. so they may know each other.
15:50:07 <monochrom> Then he can skip the first 3 or 5 chapters. There are things in the rest he has never thought of.
15:50:11 <dons> its the only haskell book written from the perspective of someone who might just want to actually hack a kernel.
15:50:18 <ksf> hsc2hs is basically an evil hack, albeit a very elegant one.
15:50:34 <joe____> ok, i will go with c2hs.
15:51:06 <joe____> is there some good documentation on c2hs? other than RWH?
15:51:12 <dons> c2hs is ultimately smarter, as it is based on static analysis, rather than metaprogramming
15:51:50 <dibblego> Berengal, I have it half figured out
15:51:52 <cwraith> nick c_wraith
15:51:58 <ksf> it's also more future-safe... or, rather, has much more space left to add additional features.
15:51:59 <cwraith> gah.  sorry :(
15:53:13 * BMeph thinks the next web framework should be called, "Haskell in Hovercrafts"
15:53:25 <ksf> someday, we'll be having a feature-complete language.c with interpreter. and supercompilation. then we can just import+compile C libraries without ever leaving ghc.
15:53:32 <chrisdone> Haskthulu in Lovecrafts
15:53:32 <c_wraith> I was wondering about hot air balloons
15:53:49 <dons> its very chirpy in here today. yay #haskel
15:53:50 <dons> l
15:53:57 * dons has had too much coffees
15:54:10 <ksf> you can't have had more than me.
15:54:13 <merijn> I fail to see the relation between hovercrafts and web 3.0 >.>
15:54:20 <BMeph> chrisdone: No, that's a Lisp product. They corner the market in fthagn!
15:54:21 <ksf> and mine count four times, they're double espressos.
15:54:24 <kmc_> hovercrafts go in the cloud
15:54:25 <skorpan> i drank over 9000 coffees today
15:54:35 <chrisdone> BMeph: drat!
15:55:12 <dons> mine too. via http://www.facebook.com/photo.php?pid=1549464&id=660195979
15:55:41 <dons> galois' powered by that machine.
15:55:43 * BMeph wants to make himself a "Haskell Monad State" sweatshirt...
15:55:49 <dons> i suspect hackage would go down if that machine is unplugged
15:56:00 * ksf won't register with facebook to have a look
15:56:10 <ksf> does it have a sticker that says "/dev/coffee"?
15:56:14 <monochrom> Galois is a machine that turns coffee machines into programming machines.
15:56:41 <sinelaw> has anyone have trouble using SDL.pollEvent?
15:56:42 <dons> i think its a public link.
15:56:42 <monochrom> (Don't you like it being a higher-order combinator?)
15:56:49 <dons> :)
15:58:06 <BMeph> HOly Futamura, Batman! Machine transformers?!?
15:58:06 <ksf> ah, there it is: http://www.ietf.org/rfc/rfc2324.txt
15:59:06 <lpsmith> I don't suppose anybody's written code so that you can write triggers and stored procedures for Postgres in Haskell?
15:59:29 <kmc_> i know someone who has
16:00:11 <kmc_> i'll let you know if i can find the code or contact him
16:00:29 <lpsmith> sweet
16:00:32 <dolio> lpsmith: monochrom gave the example "pro = do pro ; l <- get ; put (True : l)" yesterday.
16:01:15 <monochrom> But that was not designed to be a stored procedure for Postgres...
16:01:16 <dolio> Which, even if you keep the state pair lazy, causes an infinite loop with CBV continuation passing.
16:01:25 <monochrom> OTOH I'm very proud of it.
16:01:35 <lpsmith> hahaha
16:01:46 <dibblego> @pl \(a, b, c) -> f a b c
16:01:46 <lambdabot> (line 1, column 7):
16:01:47 <lambdabot> unexpected ","
16:01:47 <lambdabot> expecting letter or digit, operator or ")"
16:01:47 <lambdabot> ambiguous use of a non associative operator
16:01:53 <dibblego> orly
16:02:03 <dibblego> @pl k (a, b, c) = f a b c
16:02:04 <lambdabot> (line 1, column 13):
16:02:04 <lambdabot> unexpected "="
16:02:04 <lambdabot> expecting variable, "(", operator or end of input
16:03:33 <dibblego> @hoogle curry3
16:03:33 <lambdabot> No results found
16:03:41 <dibblego> @hoogle uncurry3
16:03:41 <lambdabot> No results found
16:03:58 <dolio> No (un)curry3.
16:04:04 <dolio> Or fst3/snd3/thd3.
16:04:49 <dons> lpsmith: yeah, someone's worked on this.
16:04:51 <monochrom> "Hi I am using a 14-tuple, is there a thirteenth function?"
16:04:55 <dons> hehe
16:06:03 <edwinb> I did get disappointed by the lack of a liftM7 the other day
16:06:06 <Vulpyne> ghc only supports up to 53 tuples or something like that. :(
16:06:18 <edwinb> then I realised I probably Shouldn't Do That
16:06:19 <beutdeuce> why doesn't this work, read <- getLine :: Int
16:06:22 <dibblego> edwinb, use Applicative
16:06:33 <kmc_> beutdeuce, because getLine :: IO Int
16:06:38 <kmc_> well actually, getLine :: IO String
16:06:39 <kmc_> :t getLine
16:06:40 <lambdabot> IO String
16:06:42 <edwinb> well exactly
16:06:57 <kmc_> you're binding a string locally and naming it "read"
16:07:03 <kmc_> probably you want to instead *call* the function read
16:07:08 <kmc_> standard function
16:07:25 <beutdeuce> well
16:07:28 <kmc_> :t readLn
16:07:28 <lambdabot> forall a. (Read a) => IO a
16:07:29 <beutdeuce> getLine returns IO String
16:07:37 <kmc_> getLine *is* IO String
16:07:40 <monochrom> getLine >>= read ?
16:07:43 <beutdeuce> i would i pull the string out?
16:07:48 <beutdeuce> with binding
16:07:49 <beutdeuce> out*
16:07:50 <edwinb> (Incidentally, I still find Applicative a bit noisy)
16:07:57 <kmc_> beutdeuce, how about "x <- readLn :: IO Int"
16:08:05 <kmc_> after that line, "x :: Int" within the same do block
16:08:11 <beutdeuce> yeah, i was thinking of using getLn
16:08:18 <monochrom> Oh oops, getLine>>=read is wrong.
16:08:28 <kmc_> you don't ever pull values out of IO.  you pull things you want to do into IO
16:08:38 <kmc_> read <$> getLine
16:08:54 <monochrom> do { x<-getLine; let {y=read x}; now you can use y }
16:08:55 <kmc_> but i expect readLn = read <$> getLine
16:09:10 <lpsmith> I need to learn to set a ulimit before I mess around with ghci flippatantly
16:09:26 <monochrom> readLn is actually getLine>>=readIO
16:09:30 <lpsmith> It can allocate memory in a tight loop
16:09:37 <kmc_> :t readIO
16:09:38 <lambdabot> forall a. (Read a) => String -> IO a
16:09:46 <kmc_> ah
16:09:53 <kmc_> throws errors in IO?
16:09:54 <Vulpyne> lpsmith: In those cases ^Z then kill -9 usually works better than ^C. :)
16:09:54 <monochrom> readIO is only impure when there is a parse error. It throws exception. That is all.
16:10:20 <beutdeuce> k
16:10:20 <beutdeuce> thnx
16:10:21 <lpsmith> Vulpyne:  good point,  I'll have to keep it that in mind
16:10:39 <ksf> dibblego, there's nthable on hackage
16:10:49 <dibblego> ksf, cheers
16:11:49 * ksf really, really thinks someone should resolve all than record/tuple/heterogenous list pain.
16:12:16 <ksf> ...by changing haskell, that is, not by writing a library.
16:12:27 <lpsmith> nice one monochrom
16:12:52 <lpsmith> Is that supposed to be anything more than a much simpler example of the phenomenon I pointed out?
16:12:53 <monochrom> Thanks. The important thing is head-recursion (as opposed to tail-recursion).
16:13:37 <monochrom> (and as opposed to head-explosion!)
16:13:44 <lpsmith> hahaha
16:14:04 <monochrom> Sorry, I don't know which phenomenon you pointed out.
16:15:06 <monochrom> mom calls for dinner. I have to be afk for half an hour.
16:17:24 <lpsmith> oh,  I see what you are doing.
16:17:39 <lpsmith> It doesn't matter what the initial state is
16:23:49 * lpsmith goes off and reads yesterday's logs more carefully
16:24:38 <aep> so Concurrent.Chan uses alot of cpu.  should i use something else?
16:25:08 <Baughn> aep: Concurrent.Chan is broken, you should use TChan instead.
16:25:13 <aep> aye
16:25:21 <Baughn> aep: ..unless it's fixed in 6.12 or 6.10.4, which is likely.
16:25:32 * Baughn still hasn't found the bug report
16:26:09 <Baughn> aep: Anyway, it's not broken in a "uses lots o' cpu" sense, but in a "sometimes deadlocks" sense. If it uses lots o' cpu, you're doing something wrong.
16:28:37 <dons> Baughn: ??
16:28:56 <dons> aep: its an unbounded chan, but relatively efficient. your first move might be to replace it with a strict chan
16:29:01 <dons> (in the strict-concurrency package)
16:29:17 <dons> it has a simple additional constraint: values are evaluated prior to insertion into the queue.
16:29:29 <dons> that can often simplify some of the design issues.
16:29:30 <dolio> lpsmith: The strictness of the state doesn't really matter. What matters is how the data dependencies of the state determine the evaluation order of the computations, so to speak.
16:29:31 <aep> readTChan doesn't return an IO().  i have no idea how to use that
16:29:40 <dons> you use it in the STM monad.
16:29:44 <kmc_> :t readTChan
16:29:45 <lambdabot> Not in scope: `readTChan'
16:29:48 <dons> but try the strict-concurrency package first.
16:29:52 <kmc_> aep, read the last chapter of RWH
16:29:53 <aep> i don't have any STM monad. all i have is IO
16:30:06 <dons> my guess: your lazy computations are migrating down the chan to be evaluated in the host thread.
16:30:16 <Baughn> aep: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=14853#a14853 <-- STM is nifty. Here, have a leaky bucket implementation using it.
16:30:27 <dons> Baughn: not sure you're helping :)
16:30:33 <dolio> And continuation passing enforces that evaluation order even if you keep the state pair lazy.
16:30:39 <Baughn> Possibly not. I'll go look up the bug report instead.
16:31:02 * aep 's head asplodes
16:31:18 <aep> all i wanted is read from stdin *sigh*
16:31:26 <lpsmith> @hoogle readTChan
16:31:27 <lambdabot> Control.Concurrent.STM.TChan readTChan :: TChan a -> STM a
16:31:33 <lpsmith> :)
16:31:47 <Baughn> @type atomically
16:31:48 <lambdabot> Not in scope: `atomically'
16:31:51 <dons> aep: there's no simple reason why Chan would "use lots of cpu".
16:31:52 <Baughn> @hoogle atomically
16:31:52 <lambdabot> Control.Exception data NestedAtomically
16:31:52 <lambdabot> Control.Exception NestedAtomically :: NestedAtomically
16:31:52 <lambdabot> Control.OldException NestedAtomically :: Exception
16:31:59 <dons> Baughn: stop talking about stm for a little whlie.
16:32:18 <aep> dons: ok, how do i find the reason?
16:32:26 <dons> aep: so, i recommended the most common case for problems with Chan, namely, switching to strict-concurrency, but without more info, we can't diagnose the problem.
16:32:32 <dons> aep: the best thing to do is profile your code.
16:32:41 <dons> compile it with -prof -auto-all and run it with +RTS -p
16:32:46 <dons> then inspect the profiling log
16:32:49 <aep> aye. sounds easy enough
16:32:50 <dons> to see what costs the most.
16:33:07 <Cale> aep: What are you working on?
16:33:23 <dons> Chan's by themselves have very little computational overhead. but listen to Cale, and talk more about what're you're actually working on.
16:33:59 <aep> Cale: select(networkfd,stdin)  --->  huge comples haskell thread thingy with inter thread thingy. i don't know anymoire actually.  at start it was a mua project
16:34:21 <kmc_> Cale, the task at hand is to do asynchronous IO
16:34:32 <aep> aye
16:34:40 <kmc_> we recommended using threads instead of select()
16:34:50 <lpsmith> dolio:   Well, the laziness or strictness of the state pair doesn't matter so much,  as it migrates from the result of a function to a parameter
16:34:51 <Cale> Doesn't Haskell *normally* do asynchronous I/O?
16:34:54 <Cale> Yeah.
16:34:57 <Cale> Just forkIO
16:35:09 <aep> dons: -auto-all makes it whine about not findind libs
16:35:18 <dolio> lpsmith: http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=5514#a5514
16:36:03 <Cale> What's a mua?
16:36:04 <aep> actually -prof does
16:36:14 <aep>     Could not find module `HaskellNet.IMAP':
16:36:19 <aep> Cale: male user agent
16:36:27 <aep> ouch... MAIL
16:36:31 <Cale> heh
16:36:32 <Cale> okay
16:37:31 <Cale> All right, so it seems pretty natural to use a thread there while talking to the mail server, so that you can grab mail in the background.
16:37:37 <aep> yeah, i dont have "profoling libraries" whatever that meansw
16:37:43 * lpsmith wonders if one can distinguish Control.Monad.State.Strict from the continuation passing state monad
16:37:44 <dolio> Well, the motivation for strict state in my experience is to prevent stack overflows from large pair rebuilding/projection, which is about keeping the pair evaluated.
16:37:57 <aep> Cale: not natural to me. i'm from a unix background. need to learn all the threading stuff from scratch
16:38:21 <Cale> aep: Well, it's very simple if you already know how to do basic I/O in Haskell.
16:38:48 <aep> its simple in a "black box" sense, yes
16:38:48 <dolio> I think that uncurried CPS state loses that bit.
16:38:56 <Baughn> Oh. It's just isEmptyChan.
16:39:05 <dolio> Or perhaps it doesn't, I'm not really sure.
16:39:08 <Cale> aep: Well, you should not worry about the implementation details, as they *will* change.
16:39:11 <aep> unfortunately i still dont understand what happens in the background, and 50% cpu for passing 1message/second is not good
16:39:35 <Baughn> aep: How much code do you actually have? Could we see it?
16:39:39 <Saizan> aep: do you have the code up somewhere?
16:39:43 <aep> not much.  i can show, sure
16:39:50 <aep> wait a second
16:39:52 <Cale> In particular, the RTS is currently using select to manage asynchronous I/O, and that is going to be replaced with epoll/kqueue.
16:39:57 <Baughn> @paste
16:39:57 <lambdabot> Haskell pastebin: http://moonpatio.com/fastcgi/hpaste.fcgi/
16:40:24 <Cale> (work is actually proceeding on that, by the looks of the ticket on the GHC trac :)
16:40:41 <lpsmith> dolio:  I don't think that's lazy enough for mine or monochrom's purposes
16:40:41 <Saizan> maybe the fact that channel is unbounded is killing you, since it might be reading in requests faster than it can consume it
16:41:03 <aep> http://codepad.org/Kj3F09Wy
16:41:07 <lpsmith> That's basically the same as the codensity-ish monad given in my paper
16:41:07 <Saizan> "consume them"
16:41:11 <lpsmith> Let me try though
16:41:28 <kmc_> holy curses batman
16:41:30 <aep> should work out of the box with any imap server.  just cabal install haskelnet
16:41:30 <dolio> lpsmith: Right. The continuation passing still orders things such that you go into an infinite loop with... left recursion.
16:41:33 <Baughn> aep: FYI, there's a perfectly fine ncurses binding on hackage
16:41:39 <aep> Baughn: its broken
16:41:48 <Baughn> How so?
16:42:01 <kmc_> what about vty?
16:42:19 <aep> Baughn: the only imported function to ptint something throws "user error -1"
16:42:33 <aep> Baughn: the implementation of that function isnt very smart anyway.
16:42:53 <aep> mvwaddstr that is
16:42:59 <kmc_> did you initialize curses properly?
16:43:05 <aep> i know curses..
16:43:20 <dons> aep: did you get an answer of how to fix the -prof error? (you need to cabal install -p those libs)
16:43:31 <aep> dons: ah! thanks
16:44:09 <dons> you can make -p the default in your .cabal config
16:44:18 <aep> aye
16:44:24 <dons> it builds a version of the lib with profiling hooks attached
16:44:32 <kmc_> aep, did you initalize with "initScr" or "initCurses"?
16:44:41 <kmc_> with the HsCurses binding i believe you should use the latter
16:44:52 <kmc_> maybe it don't matter
16:44:58 <aep> kmc_: i know curses :P   yes i did.  what i posted there works fine btw. we were talking about hscurses being broken
16:45:08 <aep> oh
16:45:10 <kmc_> yes you know curses.  initCurses is not a curses function
16:45:20 <kmc_> it's specific to the HsCurses binding
16:45:21 <aep> yeah just realized
16:46:02 <aep> i think i used the same as in the example program
16:46:05 <kmc_> aep, you can mark your foreign imports "unsafe", unless they call back to Haskell
16:46:12 <aep> HsCurses.Helper.start or something
16:46:17 <kmc_> that will improve performance although i seriously doubt it's the iussue here
16:46:36 <aep> aye thanks. but yeah, it worked fine before i added threads
16:47:45 <aep> i think i'm not getting the whole threading thing once again and doing some stupid locks or whatever
16:47:48 <lpsmith> dolio:   well, my intuition with your S monad is that you *must* call the continuation,  and you can't jump around
16:48:01 <lpsmith> I.e. you can't really call the continuation multiple times
16:48:51 <lpsmith> So once you exit the continuation,  you have to call a final continuation you give it when you want to run it,  and this continuation can only be called once
16:49:02 <lpsmith> So you have one "end point"
16:49:06 <Cale> aep: no locks :)
16:49:07 <aep> maybe this channel thing needs to serialize data, and i should use a primitive type like int instead of the polymorphic type i have?
16:49:17 <Cale> aep: What's going on with reverse?
16:49:23 <Cale> eventKey a key =
16:49:23 <Cale>     let b = a { minibuffer= key:(minibuffer a) }
16:49:23 <Cale>     in do eventMiniBuff b ( reverse ( minibuffer b ))
16:49:23 <Cale>           return b
16:49:38 <lpsmith> dolio:  The lazy state seems to start from the end,  somehow,  as particularly well illustrated by monochrom's example
16:49:58 <Cale> aep: You're building up a list of characters like a stack and then reversing it?
16:49:59 <aep> Cale: umm, slightly noobish, but i dont know how to append a char to a string :D
16:50:06 <aep> so i prepended it
16:50:13 <Berengal> aep: The chan is just a clever bit of referencing. It's all just mutable variables underneath
16:50:23 <lpsmith> But if you add continuations,  you potentially have multiple endings.... the final continuation can be called more than once or not at all...
16:50:37 <lpsmith> So where would a lazy state monad based on continuations "start" from?
16:51:00 <Cale> aep: Well, as long as it's not going to be a very long string, you can just write  minibuffer a ++ [key]
16:51:17 <aep> i read that this is quite inefficient since it needs to walk the entire string
16:51:17 <Cale> aep: But note that xs ++ ys takes O(length xs) steps to evaluate fully
16:51:24 <aep> yeah
16:51:28 <Cale> reverse is also O(n) of course
16:51:33 <aep> oh
16:51:39 <lpsmith> So maybe you can implement the lazy state monad using the higher ranked-types of the codensity monad,  maybe
16:51:54 <Berengal> Repeated application of ++ [x] is O(n^2)
16:52:14 <Cale> Berengal: so is repeated application of reverse :P
16:52:25 <aep> i assumed reverse is pretty much free
16:52:33 <kmc_> nope
16:52:39 <kmc_> Strings are singly-linked lists
16:52:44 * Berengal didn't read the code...
16:52:44 <kmc_> of chars
16:52:48 <aep> since it would just flip the iterator :D  yeah well...
16:52:51 <aep> ah!
16:53:01 <kmc_> if you need something more like a packed buffer of chars, see ByteString
16:53:10 <kmc_> comes in various flavors (strict, lazy, etc.)
16:53:18 <Cale> But this is just user-I/O stuff
16:53:21 <aep> yeah will do later. i doubt its the issue here, since that part isnt even called
16:53:28 <Cale> So I doubt that any performance problem is coming from here
16:53:46 <Cale> aep: what is the slow part?
16:53:49 * aep recompiling everything with -p
16:53:50 <Berengal> I'd be nice to see some profiling...
16:54:04 <aep> yeah, i'm working on it! :D
16:54:21 <aep> Cale: runmailstuff
16:54:32 <Saizan> mh, maybe it needs to be compiled with -threaded ?
16:54:40 <aep> specificaly the mapM_ and whatever happens due to it
16:55:13 <Cale> aep: Well, that's just a straightforward loop
16:55:20 <Cale> How long is the list ul?
16:55:32 <Cale> btw, that may look prettier as a forM_
16:55:33 <aep> around 120000 entries
16:55:43 <Cale> forM_ ul $ \u ->
16:55:55 <Cale>   do x <- fetchHeader imap u
16:56:01 <Cale>      status ...
16:56:46 <Saizan> i'd compile with -threaded, and also add some debug printing to eventloop
16:56:51 <Cale> aep: So, that loop is going to run 120000 times.
16:57:07 <aep> Cale: yeah.  around once a second, thats how long it takes to download a message
16:57:08 <Cale> aep: (and is not concurrent)
16:57:47 <Cale> So, it has nothing to do with any of the Haskell functions or Chan being slow...
16:57:48 <aep> right. i dont actually want real concurency, for the sake of convincing me that these haskel threads are indeed not evil :P
16:58:01 <aep> it doesn't?
16:58:01 <Castranegros> Channel for Haskell users to chat about racial issues, in the event that they hate nigras
16:58:05 <Castranegros> #chimpout
16:58:06 <lunabot>  luna: Not in scope: `chimpout'
16:58:13 --- mode: ChanServ set +o Cale
16:58:13 <kmc_> ah this again
16:58:18 --- mode: Cale set +b *!*@201.170.169.23.dsl.dyn.telnor.net
16:58:18 --- kick: Castranegros was kicked by Cale (Cale)
16:58:26 --- mode: Cale set -o Cale
16:59:01 <aep> Cale: not sure what else would take cpu.  the wm?
16:59:03 <Cale> aep: Well, if fetching the header takes a second, and that loop is going to run 120000 times, it'll take 120000 seconds to run
16:59:11 <aep> err wait, haskell doesnt have a wm *facepalm*
16:59:21 <aep> Cale: yes. so?
16:59:23 <kmc_> wm?
16:59:26 <kmc_> vm?
16:59:27 <Zao> Wirtual Machine?
16:59:34 <aep> vm. and ignore that sentence
16:59:46 <aep> Cale: the slowness is I/O bound, not cpu
16:59:48 <benmachine> haskell has a window manager!
16:59:48 <kmc_> ghc doesn't use a VM, but there are still runtime services
16:59:55 <aep> benmachine: xmonad? :P
17:00:02 <Cale> aep: mhm
17:00:03 <benmachine> quite
17:00:05 <kmc_> and other Haskell implementations can use a VM
17:00:14 <kmc_> so it's best not to say "haskell doesn't have a VM"
17:00:18 <kmc_> just as Java can run without one
17:00:36 <Saizan> aep: does it also use a lot of memory?
17:00:43 <aep> Saizan: let me check
17:00:54 <Cale> aep: So you're seeing high CPU usage?
17:00:56 <aep> (still compiling cabal with -p btw)
17:01:22 <Cale> aep: I guess we can look at what fetchHeader does
17:01:33 <dmhouse> Here's a bit of fun: make a list of the ways of making `x' from a sum of `n' squares: http://pastebin.com/m398a449a
17:01:46 <Saizan> you can run it with "+RTS -s" to see some basic statistics too
17:02:03 <Saizan> and -hT to produce a simple heap profile
17:02:05 <aep> Saizan: no, not really. it doesnt increase either, which i find odd since that eventloop should actually build up stack
17:02:17 <aep> Cale: yes high cpu usage.  fetchheader just gets stuff from network+
17:02:33 <aep> Saizan: aye will do
17:03:30 <aep> does that tell you anything?  http://codepad.org/V1V35flr
17:04:10 <Saizan> that it's allocating and GC'ing a lot
17:04:12 <Cale> aep: Your program spent most of its time collecting garbage.
17:04:29 <aep> D:
17:04:34 <aep> what did i do?
17:04:45 <Saizan> though it actually spent most of the time waiting for IO
17:04:52 <Cale> which makes sense, as you're downloading and immediately throwing away the headers?
17:04:57 <aep> yeah as expected.
17:05:02 <aep> Cale: indeed
17:05:09 <aep> i'm not using them yet and they are huge
17:05:51 <monochrom> "hatemail"??!!
17:05:52 <aep> so if i'm  using the headers, the program will actually speed up? heh
17:06:12 <Cale> Yeah, so for 82.8% of the time it wasn't blocked waiting for I/O, it was cleaning up all the garbage which was dropped on the floor :)
17:06:17 <aep> monochrom: yeah i love to name things in a morbid humor way :P
17:06:27 <Cale> Possibly
17:06:36 <dmwit> > 2500/7
17:06:37 <lambdabot>   357.14285714285717
17:06:39 <monochrom> That is not morbid enough. "haskelldiediedie" is better
17:06:55 <aep> well here goes garbage collector love again :(
17:07:00 <Cale> Though, the program didn't run very long.
17:07:09 <aep> i will never understand how to work around them i guess
17:07:10 <kmc_> the haskell, the
17:07:19 <Cale> aep: Well, you also really wouldn't want to *not* GC all that stuff
17:07:24 <aep> Cale: a minute or something. should i run it longer?
17:07:36 <Cale> oh, hmm
17:07:57 <monochrom> 12000 deallocations take a while no matter you do it the C way or the GC way.
17:08:15 <kmc_> indeed, it's not like memory management is free in C
17:08:21 <aep> right
17:08:23 <Cale> aep: Er, wow. It says that it spent 1.83s total computation time.
17:08:34 <kmc_> a problem with GC is when things *are* being used, but you still have to traverse them over and over
17:08:42 <Cale> (including GC)
17:08:44 <aep> Cale: yeah the rest is I/O i assume.  oh and ... GC
17:08:47 <aep> including? oO
17:08:52 <monochrom> I just love that you keep churning out mistaken blame analysis.
17:08:55 <Cale> The GC was only 1.52s
17:09:06 <Cale> With 1.90 seconds actual wall-clock time
17:09:07 <aep> 50% cpu means it should at least be 30 seconds  computation time
17:09:14 <aep> odd
17:09:33 <kmc_> "1.5% of total elapsed"
17:09:50 <Cale> Weird, I wonder what's causing that.
17:09:51 <Saizan> +9.1
17:10:00 <kmc_> so it spend 66 ms waiting on system for every 1 ms processing?
17:10:02 <Saizan> 10.6% so
17:10:25 <Cale> Looks that way to me.
17:10:31 <kmc_> aep, you can run your program under "/usr/bin/time -v"
17:10:37 <kmc_> to get lots more info at the system level
17:10:40 <aep> aye
17:10:41 <Cale> aep: Could you build with -prof -auto-all and run with +RTS -p ?
17:10:51 <aep> i have -prof in a second
17:10:54 <aep> yes
17:10:57 <Cale> Oh, try kmc_'s suggestion too
17:11:00 <kmc_> hmm, -prof will tell you where your waiting on system time went?
17:11:15 <aep> ew more libs...
17:11:16 <kmc_> can strace profile time spent in system calls?
17:11:18 <Cale> Well, I'd like to see what that looks like
17:11:23 <lispy> I've read things by experienced C hackers that indicate C's allocation time (and worse, the time to free()), has historically been a problem in programs
17:11:54 <kmc_> lispy, yeah. an advantage of copying GC is that you needn't chase down free blocks here and there; you can just allocate at the end
17:12:13 <aep> kmc_: my time doesnt have -v oO
17:12:21 <kmc_> aep, the binary, not the shell builtin
17:12:35 <aep> oh. i dont have that
17:12:47 <lispy> The source of at least one mud engine that I was reading about 8 years ago (all in C) used it's own allocation pool internally to avoid malloc/free
17:12:50 <aep> but i have a -prof binary now
17:12:51 <lispy> For performance reasons
17:13:14 <kmc_> it is really application-dependent whether gc or explicit management will burn more computation time.  it's fairly certain however that gc leads to unexpected latency jumps for realtime apps
17:13:19 <lispy> At that point, a GC'd language would have saved them development time!
17:13:24 <Cale> aep: I don't know if the .prof output will show anything useful, but who knows, maybe something strange will show up :)
17:13:27 <kmc_> lispy, yeah, high-performance C or C++ code rarely uses system allocator
17:13:33 <kmc_> but often uses a custom memory pool that is also explicit
17:14:16 <aep> prof http://codepad.org/qNx39Uhk
17:15:00 <aep> does that actually say it spend most of the time in curses and imapparser?
17:15:04 <kmc_> yeah i think this does not say much about where your real time is going
17:15:10 <kmc_> "total time  =        1.32 secs"
17:15:14 <kmc_> it took longer than that, right?
17:15:20 <aep> yes
17:15:26 <aep> 30 seconds
17:15:35 <Cale> aep: yeah, that must be it. Probably the profiler doesn't measure time spent in FFI calls(?)
17:15:41 <lispy> kmc_: It's interesting that GHC, as performance oriented and viable for industrial use as it is, doesn't have a way to change the allocator
17:15:54 <kmc_> aep, maybe run under "strace -c"
17:15:55 <aep> Cale: mvwaddstr is ffi
17:16:00 <aep> kmc_: good idea
17:16:19 <Cale> I wonder what the HaskellNet library uses to parse IMAP
17:16:49 <Cale> actually, I think it's a natively implemented client
17:16:54 <aep> kmc_: that just shows it spend 90% time in select()  waiting for network
17:17:00 <kmc_> yeah well...
17:17:12 <kmc_> i'm not sure how you can improve that by improving your code
17:17:25 <aep> Cale: Text.IMAPParsers
17:17:26 <kmc_> do you have another application that downloads similar data?
17:17:28 <monochrom> haskellnet has a dependency on haxml and parsec
17:17:54 <aep> kmc_: yeah same thing in C.  takes almost zero cpu
17:18:02 <kmc_> this takes 1.5% cpu
17:18:06 <kmc_> says ghc
17:18:14 <aep> but i didnt free stuff, so its cheat
17:18:17 <Cale> aep: Yeah, that looks like a Parsec parser. So no FFI there, and it'll actually count toward your profiling time.
17:18:44 <kmc_> aep, is the issue you're trying to solve the real wall-clock time, or the CPU time / percentage?
17:18:55 <aep> kmc_: the stuff i posted?  depends on your cpu of course :D  i am on an eepcs right now with a VERY weak FSB
17:19:03 <aep> kmc_: cpu time
17:19:09 <kmc_> ah okay then
17:19:18 * kmc_ will shut up about profiling syscalls then
17:19:18 <aep> the clock time is fine. it waits for network. nothing haskell can do
17:20:24 <Saizan> @faq can haskell speed my network ?
17:20:25 <lambdabot> The answer is: Yes! Haskell can do that.
17:20:34 <aep> heh
17:20:44 <Alpounet> @pl \f (x,y) -> (f x, y)
17:20:44 <lambdabot> (`ap` snd) . (. fst) . ((,) .)
17:21:00 <monochrom> @hackage FasterThanLight
17:21:00 <lambdabot> http://hackage.haskell.org/package/FasterThanLight
17:21:15 <aep> ok thanks. i'll try to work around the GC and see
17:22:08 <Saizan> well, according to GHC's statistics it's not even the GC, but they might not be so accurate
17:22:28 <Cale> aep: However, select is apparently slow, and there are faster things which are going to replace it in the GHC RTS, at which point we should see an automatic performance boost for all the Haskell network stuff.
17:22:35 <monochrom> Do something real and non-toy.
17:23:35 <Botje> select is O(number of filehandles)
17:23:47 <Botje> epoll is O(1), and there's others still
17:24:11 <aep> yeah select() is not so nice for large scale apps
17:24:22 <monochrom> Some versions of Parsec 3 may be slow. Also creates lots of intermediate data structures to be disposed later.
17:24:24 <aep> actually i think it even fails over a specific amount of fds
17:24:34 <QtPlaty[HireMe]> aep: Wy is that?
17:26:25 <aep> QtPlaty[HireMe]: in which way it fails? can't remember. but some posix guru basicly said you shouldnt use it in large scale
17:26:44 <aep> poll() is supposed to be better, and epoll even more
17:26:50 <Berengal> I think it has an upper limit of 1024...
17:27:03 <Berengal> I may be imagining things
17:27:06 <QtPlaty[HireMe]> aep: I would perfer studies or something.
17:27:31 <QtPlaty[HireMe]> Berengal: Most unixs have a fd limit around 1024 so thats kinda moot
17:27:35 <aep> yeah what Berengal said, but i dont have docs
17:27:50 <aep> they do?
17:27:54 <Botje> QtPlaty[HireMe]: http://monkey.org/~provos/libevent/libevent-benchmark2.jpg
17:28:09 <QtPlaty[HireMe]> fd per process
17:28:15 <Botje> that's reason alone to switch to epoll, no? :]
17:28:26 <monochrom> http://cacm.acm.org/magazines/2009/5/24646-api-design-matters/fulltext
17:29:20 <QtPlaty[HireMe]> epoll looks like its worce for smaller number of fd's though
17:29:21 <Cale> epoll does look like it does a poor job for small numbers of fds thought
17:29:24 <Cale> though*
17:29:33 <Cale> yeah
17:29:35 <Cale> heh
17:29:52 <Cale> kqueue is the clear winner
17:31:19 <QtPlaty[HireMe]> Though for less thn 500 fd's there much of a muchness,  I expect using one over the other is a bit of premature optimization unless it turns out that select is your bottelneck.
17:33:03 <stoop> <QtPlaty[HireMe]> Berengal: Most unixs have a fd limit around 1024 so thats kinda moot
17:33:08 <aug_triad> Merry Xmas! I am implementing a single-linkage clustering algorithm, and my approach is to use minimum spanning trees for that task. I have found the graph library FLG, and I have managed to compute a minimum spanning tree from an arbitrary fully connected graph with 5 nodes. This function returns [ [(4,0) ] , [ (3,1) , (4,0) ] , [ (1,1) , (3,1) , (4,0) ] , [ (2,3) , (4,0) ] , [ (5,12) , (2,3) , (4,0) ] ], where the first number in the tuplets is the 
17:33:08 <aug_triad> number and the second is the edge cost. Now, for doing a dendrogram, I need to traverse this list, and my question is now if anybody could advise me an effective way of doing this with a suitable data structure? Because Haskell has no pointers like C, I can't think of a effective way of doing it.
17:33:24 <stoop> QtPlaty[HireMe], what kind of limit are you talking about? Maybe a resource limit, sure. :-)
17:33:39 <stoop> QtPlaty[HireMe], (resource limits are easy to change)
17:33:56 <dmwit> aug_triad: You're asking how to traverse a list?
17:34:07 <QtPlaty[HireMe]> stoop: Yeah a resource limt.
17:34:17 <dmwit> aug_triad: If so: explicit recursion with pattern matching, map, foldr/foldl, and filter all spring to mind as good starting points.
17:34:33 <aug_triad> dmwit: No, how to make a dendrogram
17:35:12 <dmwit> aug_triad: A dendrogram is a kind of tree?
17:35:17 <Cale> aug_triad: I don't know what a dendrogram is, but lists of pairs are usually better encoded as a Data.Map
17:35:17 <Botje> that's a tree, right? :]
17:35:19 <aep> i guess thats a tree?
17:35:21 <dmwit> (Based on 30s reading of wikipedia.)
17:35:25 <aep> heh
17:35:26 <dmwit> Cale: list of lists
17:35:45 <dmwit> ?src Tree
17:35:46 <lambdabot> Source not found. :(
17:35:54 <dmwit> ?docs Data.Tree
17:35:55 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/containers/Data-Tree.html
17:35:59 <Cale> So I guess a list of Data.Maps?
17:36:11 <aep> if its a binary tree, i'd actually use a vector
17:36:17 <dmwit> http://www.haskell.org/ghc/docs/latest/html/libraries/containers-0.3.0.0/Data-Tree.html
17:36:22 <Cale> aep: Why?
17:36:23 <aep> err, is  (a,b) even called a vector?
17:36:34 <stoop> It is a tuple.
17:36:44 <aep> ah. i mean a tuple then :P
17:36:51 <Cale> data BinTree a = Tip | Branch a (Tree a) (Tree a)
17:36:54 <stoop> A vector could be represented as (a, a) though. :-P
17:37:11 <aep> Cale: nice!
17:38:20 <Cale> er, s/Tree/BinTree/g
17:40:29 <jlaire> @pl \(k,v) -> maybe False (maybe True (== v)) (Map.lookup k m)
17:40:30 <lambdabot> uncurry (flip (maybe False . maybe True . (==)) . flip Map.lookup m)
17:41:33 <drdr> ello haskellers
17:41:43 <aug_triad> It is not a binary tree. It is quite difficult to explain the problem, if you don't know about hierarchical clustering and dendrograms, but the problem is, that when traversing the list, the edges with the lowest cost should be merged together and the edges with the next-lowest cost should then be merges together with the ones with the lowest cost. Doing that for all costs will give n levels, and therefore it is possible to use f.x. level 3 and get x
17:41:43 <aug_triad> different clusters 
17:41:58 <drdr> any hugs maintainers herre?
17:42:20 <skorpan> why do people still use hugs?
17:42:37 <aep> aug_triad: not sure if i get the problem, but whats the problem with merging a list of lists?
17:42:38 <drdr> well i was going to
17:42:48 <aug_triad> But as you can see from [ [(4,0) ] , [ (3,1) , (4,0) ] , [ (1,1) , (3,1) , (4,0) ] , [ (2,3) , (4,0) ] , [ (5,12) , (2,3) , (4,0) ] ], it is not trivial to extract these informations
17:42:52 <drdr> but after deleting some old kernal images
17:42:58 <drdr> ive moved to ghc
17:43:11 <drdr> ubunut needs to get smaller
17:43:30 <aep> aug_triad: you want to merge those (5,12)  int  12 ?
17:44:04 * dmwit can not see from [blah] that it is not trivial to extract these informations
17:44:21 <dmwit> But partly that is because dmwit does not understand exactly what "these informations" are.
17:44:33 * aep neither
17:44:37 <Alpounet> @type (***)
17:44:38 <lambdabot> forall (a :: * -> * -> *) b c b' c'. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
17:44:41 <drdr> Anyone got uses for haskell?
17:45:03 <drdr> i see like ziltch outisde of map reduction
17:45:08 <kmc_> haha
17:45:13 <Cale> drdr: map reduction?
17:45:15 <Alpounet> @pl \(x,y) -> (f x, f y)
17:45:15 <lambdabot> f *** f
17:45:18 <kmc_> http://www.haskell.org/haskellwiki/Haskell_in_industry
17:45:18 <dmwit> Don't feed the trolls!
17:45:45 <drdr> not a troll just a person with a limited break and ide rather not waste it
17:45:46 <Cale> drdr: I use it for general purpose scripting, mathematical computation, and other random stuff.
17:46:16 <aep> drdr: i use it to steal its ideas and apply it to real world code :P
17:46:31 <dmwit> I use it to configure my window manager.
17:46:37 <aep> and that
17:46:38 <Alpounet> > (+1) *** (+1) $ (1,2)
17:46:39 <lambdabot>   (2,3)
17:46:48 <kmc_> most industrial uses of haskell involve using it to implement a specialized library or language for a particular task
17:46:49 <drdr> so youve found the x11 specs?
17:46:52 <dmwit> I use it to do version control.
17:47:01 <Cale> drdr: It's my favourite general purpose programming language out of the 15 or 20 or so that I know.
17:47:02 <drdr> i know about darcs
17:47:06 <kmc_> e.g. cryptography, hard realtime systems programming, hardware design, financial modeling
17:47:13 <dmwit> I use it to write fast, correct code quickly.
17:47:15 <aug_triad> Actually, the dendogram is: level 1-> (1,3,4), level 3 -> (2, (1,3,4)), level 12 -> (2,1,3,4, (5) )
17:47:31 <drdr> my main think it i want HEX and BIT manipulation functions
17:47:33 <monochrom> I use haskell to detect trolls
17:47:36 <lispy> I use it to reason help me reason about the code I write
17:47:42 <Cale> drdr: ?
17:47:46 <aug_triad> That will say, that at level 0 we have all the disjoint sets, (1,2,3,4,5)
17:47:47 <kmc_> @faq Can Haskell detect trolls in polylogarithmic time?
17:47:47 <lambdabot> The answer is: Yes! Haskell can do that.
17:47:49 <drdr> for editing files
17:47:54 <aep> aug_triad: can you show a simple input -> output in one line? i don't think i understand the algprythm you are trying to apply
17:47:56 <kmc_> drdr, see Data.Bits
17:48:02 <drdr> ok
17:48:02 <dmwit> I use it to play go on the DGS web server.
17:48:10 <Cale> drdr: You would use Data.ByteString and Data.Bits
17:48:15 <kmc_> > 0x27
17:48:17 <drdr> righty then
17:48:17 <lambdabot>   39
17:48:23 <aug_triad> aep: yes, I will try...
17:48:24 <dmwit> I use Haskell to whip up a Turing machine simulator to help me grade homeworks.
17:48:37 <lpsmith> I've done that
17:48:45 <dmwit> I use Haskell to preprocess my TeX.
17:48:52 <aep> really?
17:48:54 <drdr> allright well i need to go put out a fire thats stared in one of my server ta ta
17:48:57 <dmwit> aep: yup
17:49:02 <aep> url?
17:49:04 <dmwit> Well, not any more.
17:49:08 <dmwit> We have a better way now. =)
17:49:26 <dmwit> aep: Meh, it was only a ten-line hack.  Hardly even worth a URL. =P
17:49:31 <aep> ah :D
17:49:33 <monochrom> I wonder if your better way eliminates TeX and just keeps the Haskell part.
17:49:42 <dmwit> monochrom: Hah, I wish.
17:49:53 <aep> haskell.template | webkit ? :P
17:50:04 <dmwit> I use Haskell to generate beautiful progress indicators.
17:50:34 <dmwit> hm
17:50:38 <dmwit> I use Haskell a lot. ^_^
17:50:54 <lispy> Most importantly, I use Haskell to get laid in 2010, see #14: http://www.techzone-vn.net/2009/12/predictions-for-2010.html
17:51:08 <theorbtwo> Once upon a time, I used Haskell to implement parts of perl 6.  Very, very small parts, personally, but the project was huge, and really helped create the era of actually making perl 6 into something that's actually usable.
17:51:46 <dmwit> Oh, did you hack on Pugs?
17:51:48 <theorbtwo> (I've since forgotten almost everything I knew about haskell.)
17:51:50 <dmwit> Sounds like fun. =)
17:51:55 <theorbtwo> dmwit: I did indeed.
17:55:19 <iammisc> Anyone try out Go, the language from google?
17:55:30 <iammisc> Sorry, wrong channel
17:55:38 <aug_triad> [ [(4,0) ] , [ (3,1) , (4,0) ] , [ (1,1) , (3,1) , (4,0) ] , [ (2,3) , (4,0) ] , [ (5,12) , (2,3) , (4,0) ] ] is the minimum spanning tree. From that I would create a dendrogram. [ (1,1) , (3,1) , (4,0) ]  is telling that node 1,3 and 4 has the same cost, namely cost 1. Therefore these are merged at level 1. At level 1 we now have 3 clusters: (1,3,4), 2 and 5. Now the next-lowest should be merged, that is 2 and 4. BUT because 4 is already merged in the
17:55:38 <aug_triad> cluster (1,3,4), we should merge (1,3,4) and 2 at level 3 (because the cost is 3). Now at level 3 we have 2 clusters, (1,2,3,4) and 5. Now we merge the last one at level 12: (1,2,3,4,5), and we are finished. As you can see, depending on the level we have different number of clusters, and that is the point of the dendrogram
17:55:54 <aug_triad> (that was not 1 line :) )
17:56:42 <lispy> iammisc: I wrote about half of a Go parser in Haskell
17:56:48 <lda> so I was hoping to try haskell on this machine, but I can't seem to install anything via cabal. http://paste.pocoo.org/show/159013/ . Ghci works though. Any clue?
17:56:58 <dmwit> That doesn't make sense. 1, 3, and 4 do not have the same cost.
17:57:27 <dmwit> Also, how did we get three clusters?  Up to that point, you talked only about 1, 3, and 4.
17:58:26 <aug_triad> dmwit: yes, the 0 is a stupid syntax, it is because the algorithm has started with node 4 and therefore no edge has been picked yet
17:58:36 <dmwit> Also also, how do you go from [[(Int, Int)]] to a spanning tree?
17:59:57 <dmwit> lda: Does that really mean you can't install *anything*, or is only tagsoup failing?
18:00:21 <aug_triad> The number of nodes are 5: (1,2,3,4,5). If you cluster (1,3,4) then you have 3 cluster: (1,3,4) and 2 and 5
18:00:25 <lda> dmwit: well every other package i could think of failed with the same erro, including "cabal install cabal-install"
18:01:19 <dmwit> lda: ok
18:01:33 <dmwit> lda: You may want to ping dcoutts.
18:02:16 <dmwit> lda: I'm using cabal-install on Arch with no problem.
18:02:23 <aug_triad> It's quite cumbersome, the problem can be seen as: I want to merge x to y, but depending on if y has some relation to other objects, these objects should be merged also
18:03:02 <aug_triad> Using pointers it would be quite easy
18:03:06 <lda> dmwit: it worked on my 32bits machine a few weeks back, so I guess I'm missing something :/
18:03:14 <lda> dcoutts: *ping*
18:03:47 <lda> i reinstalled both ghc and cabal-install and -Syu my box but no luck
18:06:17 <aep> lda: err see that pacman error
18:06:45 <aep> you seem to have killed your previous haskell installation?
18:06:49 <lpsmith> heh,  monochrom:   I still don't completely understand your code example.   I like it!
18:07:22 <lda> aep: i had tried a few times before resorting to pasting this log
18:07:45 <lda> but after reinstalling and rm -rf ~/.cabal the msg was gone
18:07:46 <lpsmith> It makes me rethink certain things I thought were true
18:09:01 <lpsmith> monochrom:  have you ever played with the reverse state monad?
18:09:45 <aep> lda: err yeah, never mind. its not related
18:09:58 <cads> Wow, you guys check this out: "GPU Kernels as Data-Parallel Array Computations in Haskell (2009)" http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.144.6176
18:10:51 <Alpounet> @index (***)
18:10:51 <lambdabot> Control.Arrow
18:11:14 <beutdeuce> question, what is wrong with: reverse' (x:xs) = reverse' (xs):x
18:11:18 <aep> lda: it looks a bit odd. check the file /usr/bin/ar, if it is broken
18:11:46 <dmwit> beutdeuce: the type
18:12:07 <lda> aep: not sure how i do that. would reinstalling the package that owns ar do the trick?
18:12:24 <aep> lda:  file /usr/bin/ar
18:12:27 <beutdeuce> hmm
18:12:32 <aep> lda: what does it say?
18:13:02 <lda> /usr/bin/ar: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.18, stripped
18:13:12 <lispy> beutdeuce: what is the type of (:)?
18:13:23 <aep> hum. all good then.
18:13:29 <lda> wow it worked!
18:13:46 <lda> ar was corrupt, thanks a bunch aep
18:13:47 <Alpounet> lda, ?
18:13:49 <Alpounet> wow
18:14:18 <Alpounet> I've never seen that.
18:14:31 <beutdeuce> oh
18:14:43 <lda> yeah ext4 hates me
18:14:47 <beutdeuce> hmm
18:14:56 <beutdeuce> reverse' (x:xs) = reverse' (xs) ++ x doesnt work either
18:15:09 <lispy> beutdeuce: what is the type of x?
18:15:19 <beutdeuce> a
18:15:29 <lispy> and the type of (++)?
18:15:37 <beutdeuce> oh
18:15:37 <beutdeuce> right
18:15:40 <beutdeuce> thanks!
18:15:45 <lispy> :)
18:16:19 <dibblego> beutdeuce, that's a poor implementation of reverse
18:16:42 <beutdeuce> i'm open to better :) currently learning as much as i can
18:16:57 <lispy> beutdeuce: Do you know why it's a poor implementation?
18:17:11 <beutdeuce> hmm
18:17:15 <dibblego> beutdeuce, I use reverse when teaching; then ask students (who almost always write it that way) to find out why it is poor
18:17:53 <lispy> It wasn't obvious to me when I was new
18:18:53 * lispy heads out
18:19:08 <lispy> beutdeuce: think about the big-O of the implementation (that's my hint)
18:19:11 <beutdeuce> oh
18:19:17 <beutdeuce> i was thinking about that
18:19:25 <beutdeuce> well
18:19:42 <beutdeuce> isn't it O(n)?
18:19:46 <dibblego> no
18:19:57 <beutdeuce> hm
18:21:06 <beutdeuce> oh
18:21:30 <beutdeuce> well, if i have [1,2,3]
18:21:33 <roconnor> @src reverse
18:21:34 <lambdabot> reverse = foldl (flip (:)) []
18:22:02 <theorbtwo> It's O(n) calls to reverse', isn't it?
18:22:07 <beutdeuce> [2,3] ++ [1],   [3] ++ [2] ++ 1, [] ++ [3] ++ [2] ++ 1
18:22:28 <beutdeuce> [1]
18:22:41 <theorbtwo> Oh.  You meant it's O() of list constrution?
18:23:02 <roconnor> beutdeuce: you need parenthesis around your ++ to understand how it associates
18:23:38 <roconnor> ++ is denotationally associative but the association has very different operational behaviour
18:23:47 <beutdeuce> oh
18:23:49 <beutdeuce> so
18:24:10 <beutdeuce> n^2?
18:24:36 <roconnor> yes
18:24:53 <roconnor> n calls to (++) each call taking O(n) time
18:25:03 <beutdeuce> indeed
18:25:21 <roconnor> foldl (flip (:)) [] is faster
18:25:33 <dibblego> let him write it out with an accumulator
18:28:45 <beutdeuce> hm
18:28:47 <beutdeuce> i got something liek
18:28:54 <beutdeuce> foldl (\xs x -> [x] ++ xs) [] [1,2,3]
18:29:04 <beutdeuce> but thats practically the same
18:29:08 <dibblego> that's close enough
18:29:10 <beutdeuce> i dont get that flip part
18:29:13 <dibblego> [x] ++ is the same as x:
18:29:22 <lpsmith> @src flip
18:29:22 <lambdabot> flip f x y = f y x
18:29:28 <dibblego> foldl (\xs x -> x : xs) [] [1,2,3] -- same
18:29:36 <beutdeuce> ah, k
18:29:56 <pikhq> @src ++
18:29:56 <lambdabot> []     ++ ys = ys
18:29:56 <lambdabot> (x:xs) ++ ys = x : (xs ++ ys)
18:29:56 <lambdabot> -- OR
18:29:56 <lambdabot> xs ++ ys = foldr (:) ys xs
18:30:07 <pikhq> ^ ought to be enlightening, as well.
18:30:12 <lpsmith> == foldl (flip (\x xs -> x : xs)) [] [1,2,3]
18:30:36 <beutdeuce> so, foldl (\xs x -> x:xs) [] [1,2,3] is O(n) ?
18:30:44 <dibblego> yes
18:30:47 <beutdeuce> hmm, how so?
18:30:52 <dibblego> \xs x -> x:xs is the same as flip (:)
18:31:12 <Gracenotes> beutdeuce: do you get the sense in which foldl uses an accumulator?
18:31:30 <dibblego> it pulls the head off the given list then prepends it to a new list (starting at [])
18:31:41 <beutdeuce> i understand how it generally works. I understand the notion of a functional reduce
18:31:55 <theorbtwo> I'm somewhat surprised that such a common operation as ++ is O(n).  There's an obvious implementation that's O(1).  (But, of course, makes other things more expensive.)
18:31:55 <Gracenotes> the accumulator starts out as whatever the second argument is: in this case []. Then, for every element of the list in order, it takes that accumulator and alters it according to a function (which returns a new one)
18:32:59 <Gracenotes> theorbtwo: traditional asymptotic analysis of algorithms is not very functionality minded (let along lazily minded). Not having mutability helps in some ways and doesn't in others.
18:32:59 <beutdeuce> i'll brb
18:33:06 <beutdeuce> thnx btw
18:33:12 <roconnor> @unpl flip (:)
18:33:13 <lambdabot> (\ b c -> (:) c b)
18:33:16 <Gracenotes> ah, I was gonna explain the accum in this case. see you though
18:33:18 <roconnor> pft
18:33:23 <beutdeuce> brb very very soon
18:33:25 <beutdeuce> i'm interesed
18:33:27 <beutdeuce> sted
18:33:29 <Gracenotes> if you think about them as stacks, it helps
18:34:05 <roconnor> I remember when I first deduced the foldl version of reverse
18:34:08 <roconnor> it was awesome
18:34:17 <roconnor> foldl can actually be useful for something!
18:34:20 <theorbtwo> Yeah, I suppose the obvious O(1) can be pretty simply described as "be lazy", which isn't useful here, since the lazyness is already built in on a higher level then the implementaiton of ++.
18:34:40 <Gracenotes> theorbtwo: oh, that version. I thought you meant fiddling with the links :)
18:35:08 <pikhq> theorbtwo: There's an obvious O(1) implementation on the arrays, yes.
18:35:22 <Gracenotes> I suppose "normal form" is a good enough criterion here
18:35:22 <pikhq> Of course, we're discussing singly linked lists. ;)
18:36:12 <Cale> theorbtwo: There is no implementation of (++) on lists which is O(1)
18:36:28 <theorbtwo> When you see xs ++ ys, just create a new list that goes "look at xs, then look at ys".
18:37:05 <Cale> You can refer to ys as a tail of your list, but you can't just refer to xs
18:37:12 <tensorpudding> @src (++)
18:37:12 <lambdabot> []     ++ ys = ys
18:37:12 <lambdabot> (x:xs) ++ ys = x : (xs ++ ys)
18:37:12 <lambdabot> -- OR
18:37:12 <lambdabot> xs ++ ys = foldr (:) ys xs
18:37:16 <pikhq> Except that linked lists don't work like that.
18:37:17 <Cale> Because (:) takes an element and a list
18:37:34 <Cale> So the best implementation is O(length xs)
18:37:40 <pikhq> theorbtwo: Sounds like a tree, not a list.
18:37:41 <pikhq> :P
18:37:46 <ColonelJ> yor argument is flawed
18:37:55 <ColonelJ> I can think of an easy way to do O(1) list appends)
18:37:56 <beutdeuce> back
18:38:06 <ColonelJ> well not for normal lists
18:38:10 <beutdeuce> btw, i dont see how O(1) is possible
18:38:13 <beutdeuce> for a reversal
18:38:19 <pikhq> ColonelJ: How?
18:38:20 <beutdeuce> it has to depend on the size of the list
18:38:21 <pikhq> beutdeuce: It isn't.
18:38:25 <Gracenotes> beutdeuce: well, O(n)
18:38:29 <beutdeuce> oh, ok. I thought someone mentioned O(1)
18:38:44 <pikhq> We're discussing how O(1) ++ is impossible on the lists.
18:38:55 <beutdeuce> oh, k
18:39:04 <theorbtwo> No reason you can't implement [] lists as trees, or as whatever you like, so long as it fits in the interface.
18:39:24 <ColonelJ> basically you can make a data structure to represent the appends, I guess that's actually a list tree
18:39:24 <beutdeuce> what is O(1) besides insertion and retrieval?
18:39:32 <Cale> The usual trick is to replace lists with something that does have fast appends, along with an easy way to convert back to lists.
18:39:39 <ehird> insertion and retrieval aren't O(1) on lists
18:39:43 <Gracenotes> er. it is an extremely limited interface. If something expects an [Int], it is structurally limited
18:39:44 <joe____> c2hs vs hsc2hs: i am finding c2hs to be tough-going. not a lot of helpful material on the web. is that why everyone prefers hsc2hs?
18:39:47 <beutdeuce> even most retrieval is O(log n)
18:39:50 <pikhq> theorbtwo: ... Yes there is.
18:39:50 <dibblego> newtype DList a = DList ([a] -> [a])
18:39:56 <Cale> For instance functions which add elements to the beginning of a list can be treated as lists
18:39:58 <ehird> prepending, taking the first element, and chopping the first element t off
18:40:00 <ehird> *element off
18:40:02 <ehird> are the O(1) ops on lists
18:40:03 <Cale> and concatenation becomes composition
18:40:07 <pikhq> The interface for a list wholy consists of two constructors.
18:40:09 <Gracenotes> there's not really such a thing as O(1) retrieval for all elements
18:40:11 <Cale> (and composition is obviously O(1))
18:40:11 <pikhq> (:) and [].
18:40:28 <Cale> You replace [] with id, and [x] with (x:)
18:40:31 <Gracenotes> unless you know what the elements are anyway
18:40:35 <pikhq> This defines not what a list must support, but what a list (is)...
18:40:38 <ColonelJ> in my list tree thing, even retrieval of the first element isn't O(1)
18:40:47 <theorbtwo> Clearly it doesn't; you need to get things back out.  Otherwise, lists could easily be O(0).
18:40:49 <ehird> pikhq: technically (:) could be a function and [] some value
18:40:49 <pikhq> s/(/*/ s/)/*/
18:40:49 <Cale> and then to get back a list, you simply apply the resulting function to an empty list
18:40:57 <ehird> but pattern matching would have to be special-cased
18:41:09 <ehird> Cale: ah yes, concatenation is O(1) on lazy lists
18:41:16 <Cale> ehird: what?
18:41:18 <ehird> erm, wait, no
18:41:28 <pikhq> theorbtwo: you can pattern match on constructors.
18:41:31 <ehird> i really ought to double-check my brain state before serialising it to English
18:41:31 <ColonelJ> ehird: yes it is, but it exhibits the same problem as mine
18:41:32 <Cale> I'm not talking about lazy lists, I'm talking about using functions [a] -> [a] as if they were lists
18:41:38 * dibblego runs away
18:41:44 <Gracenotes> beutdeuce: well, so the accumulator starts at []. Suppose the list you want to reverse is. [1,2,3]. You can think of that as a stack with 1 at the top and three at the bottom. Imagine taking that stack and moving elements to an empty stack, piling them as you remove them from the original list. What you end up with is a stack with 1 at the bottom and 3 at the top. That's fundamentally what's...
18:41:45 <Gracenotes> ...happening with reverse, but in a more functional way.
18:41:47 <ehird> dibblego: To join the circus?
18:41:54 <dibblego> to escape it :)
18:42:09 <Axman6> heh
18:42:27 <theorbtwo> pikhq: Then that's part of the API of a list.
18:42:43 <beutdeuce> i see
18:43:15 <pikhq> Yes, the API is: data [a] = a : [a] | []
18:43:36 <dibblego> pikhq, perhaps you don't know; some people have a very sloppy idea of what "interface" means
18:43:39 <ehird> theorbtwo: pattern matching cannot be abstracted in haskell
18:43:47 <pikhq> dibblego: Apparently.
18:43:55 <ehird> if you're talking about the implementation special-casing it then yeah okay
18:44:07 <dibblego> pikhq, I mean, this sloppy idea comes from a certain arena and is popular
18:44:07 <Gracenotes> foldl runs from the top of the stack to the bottom, aka from left to right. You start with [], then you get one and put it on the bottom with [1]. Then you find 2 and put it on top of that, [2, 1]. Finally, the function is called with three, and that's put on the top, [3, 2, 1]. and so on.
18:44:19 <Gracenotes> in the last level of foldl, the accumulator is the final result
18:44:36 <theorbtwo> I'm talking about implementing a haskell compiler, not about writing in haskell.
18:45:00 <ColonelJ> Gracenotes: you mean foldr?
18:45:11 <beutdeuce> i see now
18:45:15 <ColonelJ> and right to left
18:45:36 <Gracenotes> no, talking about foldl and reverse
18:45:42 <pikhq> Yes, of course the implementation can special-case it. But, then, the implementation could have an inexplicably O(n ^^ n) implementation of +, and we would still consider 2 + 2 O(1) for most intents and purposes.
18:46:03 <ColonelJ> Gracenotes: oh yeah, sorry, wouldn't foldl' be better?
18:46:04 <Gracenotes> ColonelJ: running it on the list [1, 2, 3], starting with accumulator []
18:46:44 * pikhq shudders at the idea of big O notation requiring up-arrow notation
18:46:46 <Gracenotes> ColonelJ: the funny part is, it isn't. Because at any step, the accumulator has changed at most by the (:) link you added, meaning that seq (which has the goal of putting the first argument in WHNF) already has WHNF.
18:47:05 <Gracenotes> so it doesn't have any additional semantic effect
18:47:16 <ColonelJ> I thought foldl' used less stack space
18:47:32 <Gracenotes> well, heap space.
18:47:37 <ColonelJ> no stack
18:47:39 <Gracenotes> in GHC terms anyhow
18:47:43 <beutdeuce> isnt it insignificant?
18:47:49 <ColonelJ> I don't think so
18:47:53 <beutdeuce> how so?
18:48:00 <ColonelJ> one of the bots in here could tell you that sort of thing
18:48:03 <Gracenotes> foldl' still invokes some unneeded overhead
18:48:16 <Gracenotes> for implementing reverse as I described
18:48:51 <beutdeuce> that means that it would need to be foldl' (\x xs -> xs:x) [[],1,2,3]
18:49:17 <ColonelJ> isn't that just (:)?
18:49:24 <dibblego> flip (:)
18:49:25 <Gracenotes> anyhow, there is a stack, but that's in charge of returning from functions that have been entered, not ensuring that arguments are evaluated. GHC ensures that any application of a constructor is saturated, meaning it doesn't make thunks on the heap. (in this case anyhow)
18:49:26 <pikhq> beutdeuce: Doesn't type-check.
18:49:41 <Gracenotes> sorry to spout GHC nonsense
18:49:43 <Axman6> , time (foldl' (flip (:)) [] [1..100000])
18:49:46 <lunabot>  (1.5998e-2,[100000,99999,99998,99997,99996,99995,99994,99993,99992,99991,...
18:49:51 <Axman6> , time (foldl' (flip (:)) [] [1..1000000])
18:49:53 <lunabot>  (0.169974,[1000000,999999,999998,999997,999996,999995,999994,999993,99999...
18:49:59 <Axman6> , time (foldl (flip (:)) [] [1..1000000])
18:50:01 <lunabot>  (0.450932,[1000000,999999,999998,999997,999996,999995,999994,999993,99999...
18:50:06 <pikhq> [] is of type [a], 1, 2, and 3 are of type (Num a) => a
18:50:06 <Axman6> , time (foldl' (flip (:)) [] [1..1000000])
18:50:08 <lunabot>  (0.168975,[1000000,999999,999998,999997,999996,999995,999994,999993,99999...
18:50:11 <Axman6> , time (foldl (flip (:)) [] [1..1000000])
18:50:13 <lunabot>  (0.44093299999999996,[1000000,999999,999998,999997,999996,999995,999994,9...
18:50:20 <Gracenotes> heh. interesting.
18:50:21 <ColonelJ> clear winner
18:50:25 <ColonelJ> as expected
18:50:35 <ColonelJ> wait I think you did it wrong
18:50:37 <Axman6> seems foldl' is faster, but i bet that's just because it gets better optimised
18:50:55 <ColonelJ> , time $ (foldl (flip (:)) [] [1..1000000])
18:50:58 <lunabot>  (0.448932,[1000000,999999,999998,999997,999996,999995,999994,999993,99999...
18:51:00 <Gracenotes> maybe there are some hitches in strictness analysis that allow it to make shortcuts
18:51:02 <ColonelJ> , time $ (foldl' (flip (:)) [] [1..1000000])
18:51:04 <lunabot>  (0.172973,[1000000,999999,999998,999997,999996,999995,999994,999993,99999...
18:51:07 <beutdeuce> , time (foldl (\x xs -> xs:x) [] [1..1000000])
18:51:09 <lunabot>  (0.46393,[1000000,999999,999998,999997,999996,999995,999994,999993,999992...
18:51:11 <Axman6> , time (sum (foldl (flip (:)) [] [1..1000000]))
18:51:14 <lunabot>  Stack space overflow: current size 8388608 bytes.
18:51:14 <lunabot>  Use `+RTS -Ksize' to increase it.
18:51:30 <Axman6> , time (foldl' (+) 0 (foldl (flip (:)) [] [1..1000000]))
18:51:32 <lunabot>  (0.7138909999999999,500000500000)
18:51:38 <Axman6> , time (foldl' (+) 0 (foldl' (flip (:)) [] [1..1000000]))
18:51:40 <lunabot>  (0.343948,500000500000)
18:51:56 <beutdeuce> lol, why is that?
18:51:58 <Axman6> , time (foldl' (+) 0 [1..1000000])
18:51:59 <Gracenotes> anyhow, there *should* be overhead from the seq, but GHC must get rid of it at some point. I'd love to see why this is the case.
18:52:01 <lunabot>  (0.19497,500000500000)
18:52:18 <theorbtwo> @src foldl
18:52:18 <lambdabot> foldl f z []     = z
18:52:18 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
18:52:23 <theorbtwo> @src foldl'
18:52:24 <lambdabot> foldl' f a []     = a
18:52:24 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
18:52:39 <Gracenotes> does lunabot compile at O2?
18:52:48 <beutdeuce> foldl is one of the simplest, yet most efficient and important functions i have come across.
18:53:04 <Axman6> foldl' is more efficient
18:53:05 <ColonelJ> umm... no...
18:53:14 <beutdeuce> i meant folding in genreal
18:53:16 <Axman6> usually anyway
18:53:18 <beutdeuce> the idea of a fold
18:53:24 <beutdeuce> not foldl specifically
18:53:39 <pikhq> @src (+)
18:53:39 <lambdabot> Source not found. I feel much better now.
18:53:41 <pikhq> :P
18:53:49 <ColonelJ> @src (:)
18:53:49 <lambdabot> Source not found. Just what do you think you're doing Dave?
18:53:54 <Gracenotes> anyhow. as written, it's less efficient, unless GHC is transforming in mucho interesante ways
18:54:08 <pikhq> ColonelJ: (:) is kinda baked into Haskell.
18:54:09 <Gracenotes> which it seems to be.
18:54:19 <ColonelJ> foldl' is tail recursive, foldl isn't, why don't you see that???
18:54:21 <Axman6> @src []
18:54:21 <beutdeuce> tail?
18:54:21 <lambdabot> data [] a = [] | a : [a]
18:54:22 <pikhq> (though it's equivalent to: data [a] = a : [a] | [])
18:54:34 <beutdeuce> :t foldl'
18:54:35 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
18:54:39 <beutdeuce> :t foldl
18:54:41 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
18:54:47 <beutdeuce> ...
18:54:47 <Axman6> ColonelJ: they're both tail recursive...
18:54:56 * j4cbo doesn't really like how lists get special syntax...
18:54:56 <Gracenotes> beutdeuce: foldl is more like reduce in imperative languages. foldr, on the other hand, seems more intrinsically mathematical, having parallels in category theory and other kinds of higher-level algebra
18:55:15 * theorbtwo boggles.
18:55:27 <theorbtwo> Aren't they exactly the same except for the associvity?
18:55:28 <Gracenotes> not like you need to understand those algebras
18:55:38 <Axman6> theorbtwo: strictness
18:55:40 <pikhq> j4cbo: It makes it so you can write [1,2,3,4] instead of 1:2:3:4:[]
18:55:45 <beutdeuce> isnt foldr just like (f(f(f(f(f(f(x))))))
18:55:52 <Axman6> no
18:56:01 <Axman6> > foldr f z [a,b,c]
18:56:02 <pikhq> @src foldr
18:56:02 <lambdabot> foldr f z []     = z
18:56:02 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
18:56:02 <lambdabot>   f a (f b (f c z))
18:56:25 <j4cbo> pikhq: sure, but their *type* also has that syntax
18:56:28 <dibblego> \f k r -> foldl f k is the same as the imperative: var i = k; foreach(t in r) { i = f i t; } return i;
18:56:36 <Cale> foldr is the good one
18:56:39 <Gracenotes> they have different semantics. foldr just seems to be closer to what's found in mathland. Kan extensions and the like
18:56:44 <Gracenotes> indeed, Cale would know about it :)
18:56:45 <pikhq> j4cbo: Sadly, yes.
18:56:56 <Cale> Well, just from a structural perspective
18:57:13 <pikhq> Actually, if it weren't for the notation, it would be more like: data List a = a : List a | Nil.
18:57:21 <Cale> foldr f z replaces each (:) in the list with f and the [] at the end with z
18:57:24 <pikhq> And you'd write 1 : 2 : 3 : 4 : Nil
18:57:39 <j4cbo> it's almost exactly that in ML :P
18:57:43 <dibblego> > [1,2,3] :: [] Int -- j4cbo just use this syntax
18:57:45 <lambdabot>   [1,2,3]
18:57:51 <beutdeuce> would foldr ever work when foldl wouldnt?
18:57:57 <ColonelJ> yes
18:58:03 <Cale> foldl f z sort of reverses the list structure while it's at it
18:58:09 <Cale> beutdeuce: absolutely
18:58:10 <dibblego> beutdeuce, if by "work" you mean "terminate", yes
18:58:17 <Cale> foldr is, in a sense, O(1)
18:58:21 <ColonelJ> @src map
18:58:22 <lambdabot> map _ []     = []
18:58:22 <lambdabot> map f (x:xs) = f x : map f xs
18:58:26 <Cale> @src foldr
18:58:27 <lambdabot> foldr f z []     = z
18:58:27 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
18:58:27 <pikhq> Yes. foldr can terminate on a (lazy) infinite list.
18:58:37 <Axman6> beutdeuce: many places. foldl can't be used on infinite lists, foldr can
18:58:40 <Cale> In the nonempty list case, it immediately passes control to f
18:58:46 <j4cbo> infixr 5 :: ; datatype 'a list = nil | :: of 'a * 'a list
18:58:58 <Cale> and f needs to use its second parameter if the folding is to continue
18:59:00 <beutdeuce> how is it that foldr works on an infinite set?
18:59:05 <Gracenotes> whether foldr goes through the whole list or not depends on whether you need the results from the remainder of the list (I hesitate to call it an accumulator) at each step
18:59:06 <j4cbo> no special magic for list types :P
18:59:10 <Cale> beutdeuce: I'm in the middle of explaining that
18:59:14 <beutdeuce> k
18:59:19 <Gracenotes> anyway, it's possible not to need it. others will explain :o
18:59:41 <pikhq> > foldr (++) [1..] ([2..])
18:59:41 <lambdabot>   No instance for (GHC.Enum.Enum [t])
18:59:42 <lambdabot>    arising from the arithmetic sequence...
18:59:43 <Giarome> hello is there anybody who can help me? http://pastebin.com/m3bb28c33
18:59:44 <Cale> So if f can produce a data constructor without looking at its second parameter, the foldr doesn't need to continue
19:00:00 <Jackdaw> is there a prelude function to convert a single char (from a string) into an int? hoogle isnt linked right so im having trouble
19:00:03 <Axman6> Giarome: only if you tell us what your problem is
19:00:04 <pikhq> ...
19:00:05 <Cale> On the other hand
19:00:07 <Cale> @src foldl
19:00:07 <lambdabot> foldl f z []     = z
19:00:07 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
19:00:20 <Cale> foldl does nothing but call itself until it reaches the end of the list
19:00:23 <theorbtwo> Jackdaw: I needed to do that earlier today.
19:00:26 <theorbtwo> :type fromEnum
19:00:27 <Cale> which in an infinite list, never happens
19:00:37 <Giarome> @Axman6 syntax problem, dont know how to create right list of lists
19:00:37 <lambdabot> Unknown command, try @list
19:00:39 <Cale> f doesn't get a chance to evaluate or decide anything until then
19:00:43 <beutdeuce> hmm
19:00:45 <Jackdaw> ah thanks theorbtwo
19:00:50 <pikhq> > ord 'a'
19:00:51 <lambdabot>   97
19:01:00 <pikhq> :t ord
19:01:01 <lambdabot> Char -> Int
19:01:15 <theorbtwo> Oh... what's the difference between fromEnum and ord?
19:01:16 <Jackdaw> pikhq i get a not in scope for ord
19:01:23 <Axman6> Giarome: that code is very confusing
19:01:26 <Cale> Giarome: It would be much clearer to use let/where to capture and pattern match on the result of the span
19:01:28 <pikhq> :t fromEnum
19:01:28 <lambdabot> forall a. (Enum a) => a -> Int
19:01:33 <Jackdaw> and fromEnum '3' -> 51 which i presume is the asci code
19:01:37 <Axman6> :t span
19:01:38 <lambdabot> forall a. (a -> Bool) -> [a] -> ([a], [a])
19:01:39 <Jackdaw> but i really wanted f '3' -> 3
19:01:42 <monochrom> fromEnum is general. ord is specific for char
19:01:47 <j4cbo> can ghc optimize strings into actual sequences of bytes as opposed to cons cells of chars?
19:01:52 <Axman6> > span even [2,3,4,5,6,7]
19:01:53 <lambdabot>   ([2],[3,4,5,6,7])
19:02:01 <Axman6> j4cbo: no
19:02:04 <Axman6> > span even [2,4,5,6,7]
19:02:05 <lambdabot>   ([2,4],[5,6,7])
19:02:05 <j4cbo> D:
19:02:12 <beutdeuce> foldr1 (+) [1..] would never finish though
19:02:13 <pikhq> j4cbo: Changes semantics to do so.
19:02:19 <Axman6> that's what bytestrings are for j4cbo
19:02:24 <ColonelJ> :t skip
19:02:26 <lambdabot> Not in scope: `skip'
19:02:28 <Jackdaw> > fromEnum '3'
19:02:30 <lambdabot>   51
19:02:36 <Jackdaw> > ord '3'
19:02:37 <lambdabot>   51
19:02:39 <Giarome> ok, ill try this
19:02:40 <j4cbo> pikhq: a whole-program optimizer could do it just fine
19:03:03 * Alpounet considering to release his library the 25th at 1 or 2 AM.
19:03:15 <Axman6> j4cbo: it would still change the semantics
19:03:40 <theorbtwo> Axman6: Changing semantics is OK for a whole-program optimizer, if it can prove that you never care about those semantics.
19:03:44 <j4cbo> Axman6: by definition, a correct optimization wouldn't :P
19:03:44 <Jackdaw> ok so can just subtract off the offset to get the numbers but will this work in any localisation?
19:04:07 <beutdeuce> can someone give me an example of when foldr is significantly superior to foldl?
19:04:09 <j4cbo> what theorbtwo said.
19:04:13 <Axman6> j4cbo: well, infinite strings don't do too well when transformed into byte sequences
19:04:14 <beutdeuce> and vice versa?
19:04:16 <ColonelJ> Jackdaw: you can always find the offset using the code you just used
19:04:17 <dibblego> beutdeuce, write map using foldr
19:04:27 <dibblego> beutdeuce, now write length
19:04:32 <dibblego> or reverse as in your case
19:04:42 <Axman6> beutdeuce: there are things you can do with foldr that you just can't with foldl
19:04:56 <j4cbo> you change the representation if and when it's known to be safe to do so, and generate code to change it back to the "normal" way if that's needed
19:05:03 <theorbtwo> Jackdaw: It works so long as you only care about plain old ASCII digits -- haskell uses unicode character numbers by defintion.  That said, I expect there's a better way to solve the actual problem you have.
19:05:16 <j4cbo> Axman6: in many programs, infinite strings rarely come up :P
19:05:22 <Axman6> > foldr (&&) True (False : repeat True)
19:05:23 <lambdabot>   False
19:05:32 <beutdeuce> > foldr (\x xs -> xs + 1) 0 [1..5]
19:05:32 <Axman6> > foldl (&&) True (False : repeat True)
19:05:33 <lambdabot>   5
19:05:39 <beutdeuce> that would be length
19:05:39 <lambdabot>   mueval: ExitFailure 1
19:06:14 <ColonelJ> @src length
19:06:15 <lambdabot> Source not found. You speak an infinite deal of nothing
19:06:31 <Cale> Giarome: http://pastebin.com/m36e56de0
19:06:32 <Axman6> :t foldl (const (+1)) 0
19:06:37 <lambdabot> forall a. (Num a) => [a] -> a
19:06:52 <Axman6> :t foldl (flip const (+1)) 0
19:06:53 <lambdabot>     Occurs check: cannot construct the infinite type: a = b -> a
19:06:53 <lambdabot>     Probable cause: `const' is applied to too many arguments
19:06:53 <lambdabot>     In the first argument of `flip', namely `const'
19:06:54 <monochrom> It is not like '5' in Chinese is different from '5' in English. And it is not like anyone uses EBCDIC.
19:07:08 <Giarome> Cale, thx a lot!
19:07:13 <beutdeuce> monochrom: heavens no
19:07:13 <Giarome> at all!
19:07:32 <Jackdaw> theorbtwo: yeah probably, im just trying to do the SPOJ palindrome problem and i wanted to turn a string from the stdin "325" into [3,2,5] so i could work my magic
19:07:41 <Cale> Giarome: Oh, it just occurred to me what you'd meant to write
19:07:44 <pikhq> :t flip (const (+1))
19:07:45 <lambdabot> forall a b. (Num a) => a -> b -> a
19:07:46 <dibblego> Jackdaw, map read
19:07:54 <Cale> Giarome: Did you mean to write [z] in place of z:[] ?
19:08:05 <theorbtwo> monochrom: Actually, it *is* like '5' in Chinese is different from '5' in English.  People *do* use EBCDIC, but Haskell doesn't.
19:08:17 <Jackdaw> dibblego: i tried map read but i got an "ambiguous type variable" error
19:08:25 <Jackdaw> dibblego: thanks for the suggestion, i haev to run anyway
19:08:26 <Jackdaw> thanks all
19:08:30 <monochrom> Please show me '5' in Chinese.
19:08:31 <dibblego> Jackdaw, you'll have to give it a type signature in certain cases
19:09:03 <Cale> monochrom: ‰∫î
19:09:05 <Giarome> Cale, should be a list of lists returned, dunno how to get this when i have one list
19:09:09 <gwern> don't the chinese and japanese often use arabic numerals?
19:09:15 <Cale> gwern: they do
19:09:23 <pikhq> gwern: Yes.
19:09:25 <beutdeuce> is tails O(1) ?
19:09:29 <pikhq> They also have Chinese numerals.
19:09:31 <ColonelJ> monochrom: http://www.mandarintools.com/cgi-bin/ugif/4E94.gif
19:09:33 <Cale> beutdeuce: in a sense.
19:09:39 <theorbtwo> ‰ºç ‰∫î 5
19:09:49 <Cale> beutdeuce: Of course, it's O(n) if you evaluate the whole thing, but constant time per element.
19:09:56 <theorbtwo> All three have the same numeric value.
19:10:17 <pikhq> theorbtwo: All nice and archaic with that first one there. :P
19:10:26 <Cale> beutdeuce: and O(n) space technically, but typically only one cell of the list will be in memory at a time.
19:10:49 <ColonelJ> pikhq: actually I think that's just their formal writing style?
19:10:54 <mattam> Hmm, is idempotent the right word to say than "union s s = s" ?
19:10:59 <beutdeuce> Cale: so, isn't it technically O(1) space?
19:11:02 <beutdeuce> at any given point in time?
19:11:14 <Cale> beutdeuce: Well... this all depends on what you're measuring
19:11:28 <pikhq> ColonelJ: For Chinese, it's the way of writing 5 in financial contexts. In Japanese, it's just an archaicism.
19:11:30 <ColonelJ> Cale: wtf are you talking about
19:11:50 <Cale> beutdeuce: You have to pick a certain amount of evaluation to do, and decide what it is that you're going to hold on to.
19:11:58 <darinm> mattam: yes
19:11:59 <beutdeuce> given an environment with 2 units of memory, shouldn't it be able to compute tails given each time tails run, it takes up a unit?
19:12:03 <mattam> thx
19:12:21 <Cale> If you hold on to the entire result of tails, and you force the entire list, then it's O(n) time and space.
19:12:29 <Cale> (where n is the length of the original list)
19:12:47 <monochrom> If I asked " 'five' in English ", you would be right to say " ‰ºç ‰∫î in Chinese ".  But I specifically did not do that.
19:12:49 <ColonelJ> Accessing already existent data is O(0) space
19:12:58 <Cale> Just enough time to walk down the original list, and just enough space to build a list of conses which point at its tails.
19:12:59 <theorbtwo> It makes sense; otherwise it's easy to forge what should be 2, ‰∫å, into looking like 3, ‰∏â.
19:13:03 <beutdeuce> so take 2 tails [1..5] would be O(2)  ~= O(1) space and time?
19:13:19 <Cale> ColonelJ: yes, but you're making a list of the tails, which is a genuinely new list
19:13:33 <Cale> beutdeuce: yeah
19:13:41 <Cale> beutdeuce: (needs more parens)
19:13:44 <ColonelJ> oh right, O(1) per iteration then
19:13:49 <theorbtwo> monochrom: And the original question specificly talked about localization.
19:13:54 <beutdeuce> right, take 2 $ tails [1..5]
19:14:00 <beutdeuce> , take 2 $ tails [1..5]
19:14:01 <lunabot>  [[1,2,3,4,5],[2,3,4,5]]
19:14:09 <pikhq> theorbtwo: Japanese uses Â£±,Âºê,ÂèÇ instead of ‰∏Ä,‰∫å,‰∏â, but otherwise leaves the numbers the same, for that reason.
19:14:16 <beutdeuce> , time . take 2 $ tails [1..]
19:14:18 <lunabot>  (0.0,[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,...
19:14:31 <beutdeuce> , time . take 100 $ tails [1..]
19:14:33 <lunabot>  (0.0,[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,...
19:14:37 <theorbtwo> pikhq: Ah, interesting.
19:14:37 <monochrom> I have not seen any localization that converts string "5" to English "five" or Chinese "‰∫î".
19:14:44 <beutdeuce> , time . take 1000000 $ tails [1..]
19:14:46 <lunabot>  (0.0,[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,...
19:14:54 <ColonelJ> beutdeuce it's not doing anything
19:15:02 <Giarome> how can i create a list of lists [[a]] having one single list [a]
19:15:20 <monochrom> I specifically had localization in mind too.
19:15:21 <Cale> Giarome: depends which list of lists you want to create
19:15:28 <pikhq> monochrom: That's because in horizontal writing, 5 is an acceptable way of writing ‰∫î. In vertical writing, one should just use Chinese numerals.
19:15:30 <beutdeuce> , time . take 1000000 $ tails [1..] !! 1
19:15:32 <lunabot>  (0.0,[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,...
19:15:34 <pikhq> Computers don't really do vertical writing.
19:15:39 <beutdeuce> hmm
19:15:41 <Axman6> jlouis: around by any chance?
19:15:44 <beutdeuce> , time . take 1000000 $ tails [1..] !! 10
19:15:46 <lunabot>  (1.0e-3,[11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,3...
19:16:00 <theorbtwo> monochrom: I have, but in any case, I was just being through.
19:16:13 <ColonelJ> > 3 !! 4
19:16:15 <theorbtwo> I have seen people try to enter Ôºï into a numeric field, too.
19:16:15 <lambdabot>   No instance for (GHC.Num.Num [a])
19:16:15 <lambdabot>    arising from the literal `3' at <inter...
19:16:23 <beutdeuce> , time . take 1000000 $ tails [1..] !! 100
19:16:25 <lunabot>  (0.0,[101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117...
19:16:29 <Giarome> if i have two single lists i want to join them into a list of lists [1,2,3] and [4,5,6] -> [[1,2,3],[4,5,6]]
19:16:34 <beutdeuce> hmm, how is that O(1)
19:16:48 <Giarome> i know this is easy....
19:17:00 <Axman6> Giarome: [1,2,3]:[4,5,6]:[]
19:17:02 <theorbtwo> (Hm, not sure if I've actually seen that, but I've certianly seen people write entire posts using fullwidth latin characters.)
19:17:15 <Cale> Giarome: I think the function you actually want to write maybe looks like  splitWith f [] = []; splitWith f (x:xs) = (x:ys) : splitWith f zs where (ys,zs) = span f xs
19:17:34 <Cale> Giarome: But I'm not sure.
19:17:39 <beutdeuce> time . take 1000000  (tails [1..]) !! 100
19:17:43 <Axman6> Cale: i was thinking the same thing
19:17:47 <beutdeuce> , time . take 1000000  (tails [1..]) !! 100
19:17:48 <lunabot>  luna: precedence parsing error
19:18:09 <ColonelJ> , time . take 1000000 (tails [1..] !! 100)
19:18:09 <beutdeuce> , time (take 1000000  (tails [1..]) !! 100)
19:18:10 <lunabot>  luna: Couldn't match expected type `a -> b' against inferred type `[t]'
19:18:11 <lunabot>  (0.0,[101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117...
19:18:16 <Cale> Giarome: Oh, that's easy [[1,2,3],[4,5,6]]
19:18:18 <beutdeuce> , time (take 1000000  (tails [1..]) !! 100)
19:18:19 <ColonelJ> oops
19:18:20 <lunabot>  (0.0,[101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117...
19:18:28 <Cale> Giarome: That works if the lists are variables as well
19:18:33 <Cale> Giarome: [xs,ys]
19:18:36 <beutdeuce> i dont undersatand how that is constant access
19:18:51 <Axman6> it's not
19:18:53 <Cale> xs !! n takes O(n) time
19:18:53 <Giarome> ok, almost right thanks, i have to tune this
19:19:11 <Axman6> time puts things in WHNF, which is constant in that case
19:19:13 <ColonelJ> , time . take 1000000000 $ tails [1..] !! 100
19:19:16 <lunabot>  (0.0,[101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117...
19:19:34 <beutdeuce> , reverse $ take 5 $ tails [1..]
19:19:35 <lunabot>  [[5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,3...
19:19:38 <ColonelJ> erm I think the list is lazy or something
19:19:49 <beutdeuce> oops
19:19:58 <beutdeuce> , map reverse $ take 5 $ tails [1..]
19:20:02 <lunabot>  Killed.
19:20:13 <ColonelJ> ??
19:20:16 <beutdeuce> ?
19:20:18 <Cale> You can't reverse an infinite list.
19:20:22 * theorbtwo is glad lunabot is smart enough not to try to dump an entire infinite string into IRC.
19:20:26 <beutdeuce> but im only taking 5
19:20:29 <dibblego> he didn't
19:20:33 <Cale> Well, you can, but it takes forever
19:20:33 <ColonelJ> I was confused as to why you were trying to reverse an infinite list
19:20:36 <dibblego> you can't reverse 1
19:20:43 <dibblego> , reverse $ take 5 $ tails [1..]
19:20:44 <Cale> dibblego: huh?
19:20:44 <lunabot>  [[5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,3...
19:21:01 <Cale> dibblego: I'm talking about the one with map reverse
19:21:12 <Cale> The tails of [1..] are all infinite lists.
19:21:14 <dibblego> oh tails, not tail, sorry
19:21:20 <cads> cale, what if it's an infinite list with a finite upper bound?
19:21:27 <Cale> cads: ?
19:21:27 <beutdeuce> , foldr1 (\x xs -> xs:x) $ take 5 [1..]
19:21:28 <lunabot>  luna: Occurs check: cannot construct the infinite type: a = [a]
19:21:30 <ColonelJ> , reverse (take 6 (tails [1..]))
19:21:31 <theorbtwo> cads: Then it's a finite list.
19:21:31 <lunabot>  [[6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,...
19:21:44 <monochrom> Show me an infinite list with a finite upper bound.
19:21:47 <beutdeuce> , foldr (\x xs -> xs:x) [] $ take 5 [1..]
19:21:48 <Cale> cads: "finite upper bound"? It doesn't matter what the elements of the list are.
19:21:48 <lunabot>  luna: Occurs check: cannot construct the infinite type: b = [b]
19:22:29 <ColonelJ> , reverse (take 100000000 (tails [1..]))
19:22:33 <lunabot>  Killed.
19:22:34 * monochrom just uses the scientific method. I call you bluff. Show me what you're talking about.
19:22:38 <Cale> reverse = foldl (flip (:)) []  and foldl never finishes when applied to an infinite list
19:22:42 <ColonelJ> beutdeuce: see, it's not constant time, happy?
19:23:04 <beutdeuce> but its applied to a list of 5 lists, not an inf list
19:23:11 <dolio> > [10,9..]
19:23:12 <lambdabot>   [10,9,8,7,6,5,4,3,2,1,0,-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,...
19:23:16 <ColonelJ> , time $ reverse (take 1000000 (tails [1..]))
19:23:18 <lunabot>  (0.419936,[[1000000,1000001,1000002,1000003,1000004,1000005,1000006,10000...
19:23:22 <Cale> beutdeuce: I was talking about the map reverse version
19:23:26 <dolio> Upper bound = 10.
19:23:30 <beutdeuce> Cale: oh, k
19:24:41 <cads> well, consider the sequence 1/2, 3/4, 5/6, 7/8, and so on which has no greatest element
19:25:56 <cads> a limit operator says this list converges to 1
19:26:12 <theorbtwo> cads: It has a finite sum, sure.  (Or, to be technical, the sum approaches a finite value.)  That isn't relelvant, though, it still has an infite number of elements.
19:27:07 <theorbtwo> ...so you can't reverse it, in Haskell.  (You couldn't possibly reverse it, and then look at it's first element, since it doesn't *have* a last element, so it's reversal doesn't have a last element.)
19:27:11 <cads> so if we were to reverse our list in our imagination, we might imagine an infinite string of 1s, which differ from each other by only imaginary infinitesimal amounts
19:27:29 <monochrom> How do you write an algorithm to do it?
19:27:50 <monochrom> And consider the sequence: cycle [True,False].
19:27:54 <theorbtwo> I'm not convinced that your infinitesimals are any more imaginary then your ones.
19:27:58 <monochrom> > cycle [True,False]
19:27:59 <lambdabot>   [True,False,True,False,True,False,True,False,True,False,True,False,True,Fal...
19:28:20 <monochrom> Tell me the correct answer to: head (reverse (cycle [True,False]))  and why.
19:28:36 <cads> I think this is just the problem of calculuting a limit or supremum to a series of numbers
19:28:54 <cads> which is probably undecidable in general
19:29:13 <theorbtwo> cads: Not all lists are series of numbers.
19:30:02 <gwern> so, I was thinking of agitating for Data.List.sort to be replaced with yhc's sort based on http://neilmitchell.blogspot.com/2008/03/sorting-at-speed.html
19:30:09 <gwern> any downsides to this?
19:30:28 <cads> monochrom, the limit of that sequence is a stable orbit between true and false, but you're right, that breaks my original notion of a single limit
19:30:54 <beutdeuce> can someone give me an example of how foldr would work with an infinite list?
19:31:02 <beutdeuce> some example where foldl would fail
19:31:13 <monochrom> Now try: map sin [0..]
19:31:17 <dibblego> beutdeuce, foldl will always fail; have you written map with foldr yet?
19:31:30 <Giarome> i almost got it thx for thy help! http://pastebin.com/d1dcf21ce
19:31:36 <beutdeuce> will try now
19:32:10 <cads> monochrom, I don't think that sequence converges to any kind of regular pattern?
19:32:26 <beutdeuce> wait
19:32:27 <beutdeuce> map?
19:32:38 <dibblego> let map' = foldr ...
19:32:40 <monochrom> It doesn't. I want to see what your algorithm does.
19:32:56 <monochrom> Or see you reveal that you have no algorithm.
19:33:17 * monochrom is an oracle of counterexamples to debunkable ideas
19:33:45 <dolio> I don't even see how 1/2, 3/4, ... works.
19:34:05 <cads> my algorithm times out after evaluating some stupid number of terms in the sequence
19:34:08 <monochrom> Don't start writing code or paper until you have passed the monochrom test.
19:34:22 <dolio> That sequence doesn't contain anything that's "infinitesimally less than 1", so you can't put such things at the start of the reversed list.
19:35:12 <dmwit> What a surreal argument.
19:35:19 <monochrom> haha
19:35:29 <cads> Sup {1/2, 3/4, .., n/(n+1), ...} etc only works in a lattice
19:36:38 <gwern> (hm. I guess no sorting fanatics are awake)
19:36:39 <beutdeuce> hmm, i keep getting it to return a single value
19:36:50 <dibblego> beutdeuce, how's it look?
19:37:03 <dolio> gwern: I support it.
19:37:07 <beutdeuce> hm
19:37:29 <gwern> dolio: that's not a valid answer to my question about downsides :)
19:37:49 <dolio> There are no downsides.
19:37:58 <beutdeuce> yes!
19:37:59 <beutdeuce> did it!
19:38:21 <gwern> dolio: ever hear the story about daniel boone speaking to his voters? 'I know some of you are for the repeal of the tariff, and I know some of you are for the renewal of the tariff. I just want to let you: I'm for it too'
19:38:29 <beutdeuce> map' f coll = foldr (\x xs -> f x : xs) [] coll
19:38:32 <dibblego> now call map' on an infinite list
19:38:48 <dibblego> there's foldr working on an infinite list and terminating
19:38:54 <beutdeuce> oh snap
19:38:58 <beutdeuce> awesome!
19:39:50 <monochrom> What I learn from that story: English needs variables.
19:40:17 <Gracenotes> some variables aren't that variable in Haskell
19:40:52 <beutdeuce> , let map' f coll = foldr (\x xs -> f x : xs) [] coll
19:40:53 <lunabot>  luna: parse error on input `)'
19:41:25 <Gracenotes> the variability is of variable visibility
19:46:53 <beutdeuce> so, foldr is lazy by nature?
19:47:12 <beutdeuce> an axiom of lazy evaluation?
19:48:01 <BMeph> beutdeuce: s/foldr/Haskell/ ;)
19:48:15 <beutdeuce> s?
19:48:32 <BMeph> (substitute)
19:48:48 <stroan> regex syntax
19:48:50 <beutdeuce> hm
19:49:07 <monochrom> It is less ambiguous than the other common notation "*Haskell"
19:49:23 <BMeph> s/<take every place you see this>/<and put this instead>/
19:50:19 <dmwit> "Haskell is lasy by nature."
19:50:25 <beutdeuce> ah
19:50:40 <BMeph> beutdeuce: You can even follow the replacement slash with a 'g' for <do it globally, not just once> :)
19:50:44 <monochrom> The other day I illustrated the ambiguous notation with this. Someone said "xxx yyy zzz" by mistake, should be "xxx zzz". I said "*".
19:51:17 * BMeph thinks monochrom is a super '*'... ;)
19:52:02 <beutdeuce> hmm, foldl (\x xs -> xs:x) [] coll  works, but foldr doesn't, why?
19:52:23 <aavogt> @type foldl
19:52:24 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
19:52:25 <aavogt> @type foldr
19:52:26 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
19:52:45 <aavogt> beutdeuce: match up the a and bs
19:52:49 <monochrom> yeah, because of type error.
19:52:56 <dibblego> beutdeuce, the arguments to the function in foldr are flipped
19:54:05 <cads> monochrom, I was only stating that we might imagine a computable sequence of elements to formally extend to a transfinite, —°th element, and maybe beyond. Consider  Cycl n = cycle [True, False] !! n. Then Cycl —° might be said to be either True or False, but not something else. And also we might say that Cycle —°+n = not Cycle —°+n-1. I was just talking about an imaginary operator/algorithm that might categorize some of these sequences
19:54:07 <beutdeuce> yes, but if i flip them, reverse doesnt do anything
19:54:18 <dibblego> then you have an identity function :)
19:54:26 <dibblego> foldr (:) [] x == x
19:54:43 <beutdeuce> interesting
19:54:45 <dibblego> note that (:) and [] are the two list constructors
19:54:53 <cads> dolio, you're right to point out that this kind of analysis might be surreal
19:55:40 <beutdeuce> g2g for the night, thnx to everyone who helped clear a lot of fog
19:57:54 <magicman> Data.Pattern is... interesting.
19:58:03 <cads> dolio, but consider f n = n/(n+1). Then it's clear we want to say f —° = —°/(—°+1) ‚âÉ —°/—° = 1, because that is the limit point of that function, and similarly f —°+n = f —° = 1
19:58:40 <dolio> Are you sure you can divide ordinals?
19:59:19 <monochrom> , even 3
19:59:20 <lunabot>  False
19:59:29 <dibblego> newtype NonEmptyList a = NEL a [a] -- is this on hackage?
19:59:38 <dibblego> er s/newtype/data
20:00:23 <monochrom> @botsmack
20:00:23 <lunabot>  :o
20:00:24 <lambdabot> :)
20:01:57 <ray> http://hackage.haskell.org/package/NonEmpty
20:02:14 <dibblego> oh duh thanks
20:03:50 <cads> dolio, heh, I agree that the math is a bit suspect :) but at least from the perspective of equating —° with infinity, then saying  f —° = limit_{n -> inf} f n = limit x/(x+1) = 1 lets us reconnect with a basic fact from calculus
20:07:27 <cads> so I guess what i'm claiming is that  reverse (take —° (map f [1..])), where f n = n/(n+1)   might under some outlandish yet consistent theory yield the list [1, 1, 1, 1 ...]
20:08:06 <dolio> It would only have a single 1, presumably.
20:08:23 <dolio> And deciding what to put after that is a problem.
20:08:32 <monochrom> Do you have reverse (reverse xs) = xs ?
20:08:49 <Gracenotes> so it converges to 1 at some point
20:11:50 <dolio> I'm not sure I really like definitions that involve doing things —° or more times. It seems non-constructive.
20:11:58 <cads> monochrom, that would require an axiom like well ordering, but one that gives every sequence (even transfinite ones) an upper bound - I'm not sure this would be consistent
20:12:19 <dolio> At least, I don't like them from a constructive view.
20:13:08 <cads> reverse . reverse x = x would be a nice identity to have though :)
20:13:47 <darinm> there's nothing wrong from a constructive point of view with doing things \omega many times, only in doing something \omega many times in a finite bit of computation
20:14:15 <cads> I think that with computable representations of —° you just turn infinity into an interesting dance of finite math providing representations
20:16:10 <cads> yeah, what's nonconstructive is, e.g., saying that a process will do something after some unknowable cardinal has been reached
20:16:10 <darinm> yes, e.g., coinductive definitions let you denote infinite objects through finite representations
20:16:58 <dolio> Coinductive definitions aren't the same as, say, iterating the surreal numbers construction —° times.
20:17:42 <darinm> dolio: why not?
20:17:50 <darinm> you can use a (coinductive) stream
20:17:56 <darinm> to iterate
20:18:29 <dolio> Well, for instance, there was a blog post I read recently that was talking about doing a similar —° construction for trees.
20:18:42 <dolio> Such a tree would have infinitely long paths that end in a node.
20:18:52 <cads> strangely enough going back to dolio's comment about the surreality of the idea of a infinitesimaly differing element in an infinite sequence, we have the concept of the infinitesimal object in category theory http://ncatlab.org/nlab/show/infinitesimal+object which seems to go back to the original surreal numbers with infinitesimals upon which calculus was orginally conceptualized
20:19:03 <dolio> But coinductive trees are just potentially infinite trees. They don't have nodes at the end of infinitely long paths.
20:19:16 <darinm> oh, I see what you mean
20:19:42 <darinm> yes, for those situations I don't see a nice way to handle them constructively
20:20:35 <cads> at least not a way that doesn't turn into limiting yourself to a countable subset of possible representations
20:21:31 <cads> but I think there must be interesting dynamics that happen in such infinite settings, even if our understanding of them is through finite machinery
20:22:02 <cads> otherwise we wouldn't have all these n-categories and —°-categories
20:24:02 <cads> I mean, geeze, what can even be meant by taking the arrows between the arrows between the arrows ... (^—°) .. between the arrows of a category
20:25:03 <darinm> cads: that's actually not all that mysterious with the right representation.  For example, you can give a definition of weak \omega categories in Agda through a coinductive representation of globular sets.
20:25:05 <monochrom> I think we have just agreed there is a difference between "taking the arrows between the arrows between the arrows ... (^—°) .. of a category" and "taking the arrows between the arrows between the arrows ... (^—°) .. between the arrows of a category"
20:26:25 <dolio> —°-categories have (n+1)-cells between n-cells, but they don't have —°-cells, right?
20:26:27 <joe____> i am finding that c2hs is a lot difficult than hsc2hs, being a beginner. Any thoughts, please?
20:27:05 <dolio> I suppose that's a bit of a disconnect from the usual n-category.
20:28:16 <j4cbo> joe____: what are you actually trying to do, again?
20:28:33 <j4cbo> joe____: please don't reply with "write an idiomatic source-to-source translator from c to haskell"
20:28:49 <joe____> ffi for libftdi and I cannot seem to find something that helps with c2hs.
20:29:06 <Cale> joe____: They are completely different.
20:29:08 <darinm> they have \omega-cells
20:29:12 <joe____> I am scrapping anything I can find from google and every example seems to have a different approach.
20:29:30 <Cale> joe____: Have you read the FFI report?
20:29:55 <joe____> the pdf file is linked to springer, which is asking for $25
20:30:03 <Cale> ?
20:30:09 <Cale> http://www.cse.unsw.edu.au/~chak/haskell/ffi/ffi/ffi.html
20:30:11 <joe____> Cale: the pdf report file.
20:30:40 <Cale> I don't know what springer is up to, but all the Haskell standards are freely available
20:31:30 <joe____> found th report that Cale linked to.
20:31:39 <joe____> I will read through it. Thanks for the guidance.
20:32:19 <Cale> (actually most if not all of the papers written about Haskell are also freely available)
20:32:47 <Cale> Most of them are either on CiteSeer or available from the researchers' pages directly.
20:32:58 <cads> darinm, globular sets and coinduction I've heard of... but never understood the definitions when I looked them up.
20:33:13 <joe____> not the link from http://www.cse.unsw.edu.au/~chak/haskell/c2hs
20:33:23 <joe____> under documentation.
20:33:24 <monochrom> http://www.haskell.org/  then look for "language definition" then use that link instead.
20:33:40 <cads> for that matter, —°-categories are this huge mysterious subject for me, could you recommend an enlightening paper or two, darinm?
20:34:17 <joe____> thanks monochrom.
20:35:52 <darinm> cads: I don't know that much about them myself actually, only started learning a little bit after talking with someone who works in that area.  I get the impression that they're still mysterious to category theorists and that one of the problems with trying to learn more about them is that there are several different definitions of what they actually are
20:36:00 <darinm> and it's non-trivial to translate between them
20:37:42 <darinm> there's the globular version of \omega-category theory, the simplicial version, and another that I forget
20:37:56 <cads> Yeah, the area of foundations for higher category theory seems to have a lot of pet theories
20:38:04 <darinm> probably the globular one is the easiest to grok for Haskell/Agda folk
20:38:41 <darinm> If you want to find out more, I'd probably look at some of Awodey's recent papers and look for some pointers there
20:38:49 <darinm> or papers from his collaborators
20:39:30 <dolio> They do have —°-cells? What do they go between?
20:40:06 <darinm> well, I mean they have a countable infinity of cells
20:40:07 <copumpkin> you trying to describe the agda category?
20:40:19 <dolio> I thought the idea was to take the limit, so they have n-cells for all n.
20:40:25 <dolio> All finite n, that is.
20:40:31 <darinm> yes, sorry that's what I meant
20:40:35 <dolio> Okay.
20:41:04 <darinm> copumpkin: no
20:41:15 <darinm> at least I wasn't :)
20:41:32 <copumpkin> :)
20:42:12 <Cale> The trouble with higher dimensional categories is that there are so many variations on possible definitions -- some are more inclusive but harder to work with, and some easier to work with but miss things that we might like to capture.
20:43:34 <copumpkin> it'd be interesting to formally construct a description of agda from a CT point of view
20:43:37 <Cale> The first problem comes with defining exactly how associativity ought to work out -- either exactly (which tends to be called 'strict') or only up to isomorphism, or perhaps even only just that there ought to exist maps of some sort between the associations.
20:43:52 <copumpkin> since it doesn't have to be as much of a compromise as haskell is
20:44:23 <Cale> Or if there's isomorphisms, you usually want those isomorphisms to not just be *some* isomorphisms, but either they should be unique or else coherent in some way (every diagram of them should commute)
20:44:46 <dolio> Yeah, apparently there are pretty settled definitions of strict —°-categories. It's the weak ones that have all the different definitions.
20:44:55 <Cale> yeah
20:45:14 <Cale> and then the same problems come about when discussing functors between these things
20:45:35 <Cale> Just what ought to be preserved and to what extent
20:45:38 <dolio> And n-categories don't typically aren't strict.
20:45:59 <Cale> Right, there are a lot of great examples of weak n-categories which we'd like to get at
20:46:11 <Cale> (especially for small n)
20:46:41 <dolio> You start at n-cells, and define 'equivalence' as equality, and then you for k < n, you define equivalences on k-cells up to equivalences on k+1-cells.
20:48:25 <dolio> But I guess you have a problem with —°-categories because there's nowhere to start that.
20:49:00 <joe____> Cale: why do you say that hsc2hs is completely different from c2hs? is it because of how they work? i understand that they are different approaches to ffi. am I wrong?
20:49:33 <Cale> joe____: Well, they're both preprocessors which give you various shorthands for writing ffi declarations
20:49:54 <Cale> joe____: But they parse completely different languages for doing that.
20:50:02 <Cale> (they are not close to being compatible with each other)
20:50:44 <joe____> i find that hsc2hs has a lot more examples and is more easy to understand. do you feel the same?
20:50:49 <joe____> Cale: i find that hsc2hs has a lot more examples and is more easy to understand. do you feel the same?
20:51:14 <joe____> though i read that the development on c2hs is far more active
20:51:29 <Cale> joe____: I haven't really had a lot of experience with either.
20:51:38 <Cale> I've used c2hs a little bit.
20:52:03 <joe____> and did you find it easy. What did you use to pick it up? RWH? or the haskell report?
20:52:05 <Cale> But I tend to just write my ffi declarations by hand, as it's not really that much trouble unless you're doing a ton of it
20:52:13 <Cale> I just used the c2hs documentation.
20:52:55 * hackagebot upload: convertible-text 0.2.0.1 - Typeclasses and instances for converting between types (MichaelSnoyman)
20:53:06 <Cale> How large is the binding that you're writing? If you're just importing a handful of functions, it's simpler just to write the FFI declarations directly.
20:53:15 <joe____> what do you mean by "write my ffi declarations by hand"?
20:53:34 <joe____> do you mean study the output of c2hs and just do it without c2hs?
20:54:09 <Cale> Well... you *could* do that, but that's a silly way to learn to use FFI
20:54:28 <Cale> Just read the FFI spec, which is fairly tutorial in nature.
20:55:34 <Cale> I guess there are probably other tutorials if you find it hard to read
20:56:07 <joe____> i can follow the spec until marshalling and I am lost at that point.
20:56:17 <joe____> i will search for other ffi tutorials, then.
20:56:31 <EvanR> four _ ?
20:56:33 <EvanR> heh
20:56:52 <EvanR> ##c kicks you if you have two ;)
20:56:53 <lunabot>  luna: parse error on input `if'
20:56:55 <joe____> that is nickname that the system assigned to me.
20:57:02 <Cale> joe____: Well, the section on marshalling is mostly just documentation of the various libraries to help with that
20:57:08 <Cale> joe____: Are you familiar with C?
20:57:24 <joe____> Cale: yes.
20:58:33 <Cale> Okay, so sometimes you'll want to be able to allocate, inspect, and update memory from the Haskell side of things, in order to be able to get data into or out of the form necessary for executing C code.
20:59:06 <Cale> For that purpose, we have (Ptr a) values which are just plain pointers to values of type a
21:00:05 <Cale> In order to define how Haskell values are translated back and forth to C values, how much space they'll take, and so on, there is a typeclass called Storable.
21:00:33 <Cale> Storable is already implemented for many basic types, so you usually don't have to worry about implementing it yourself
21:01:11 <Cale> But the operations are useful -- they give you a way of dereferencing pointers (peek) and writing to the memory location pointed to (poke)
21:01:36 <joe____> Cale: oh, ok. that is very helpful. thanks.
21:01:40 <Cale> There's also  malloc :: (Storable a) => IO (Ptr a), which allocates memory large enough for a value of type a
21:02:00 <Cale> (and free :: Ptr a -> IO () to free the memory again)
21:02:18 <Cale> Actually, more convenient is alloca :: (Storable a) => (Ptr a -> IO b) -> IO b
21:02:46 <copumpkin> it would be nice if there were an existential-based interface to avoid the pointer leaking
21:03:05 <Cale> it takes an IO function which needs a pointer to a, allocates memory for that pointer passing it to the function and executes the action before freeing the memory again
21:03:46 <Cale> copumpkin: I'm not sure that would be terribly useful -- most of the time you care about what type of pointer it is.
21:03:50 <Cale> Hmm...
21:04:03 <Cale> Well, maybe an extra phantom parameter might work.
21:04:03 <copumpkin> Cale: an additional type argument on Ptr ?
21:04:15 <Cale> You'd also need one on IO
21:04:34 <Cale> (I think)
21:04:38 <copumpkin> and all your API functions must not allow you to get the raw ptr :)
21:04:42 <copumpkin> :t runST
21:04:43 <lambdabot> forall a. (forall s. ST s a) -> a
21:05:44 <Cale> joe____: There are also handy functions for allocating arrays of values and marshalling Haskell lists to and from them.
21:05:55 <Cale> (Additionally in GHC, there is a Storable array type)
21:06:17 <copumpkin> whoa, another crank on mathit, yay
21:06:52 <lpsmith> was the one you posted a genuine crank or a troll?
21:06:53 <Cale> joe____: If you need to do C cleanup whenever a pointer ends up being garbage collected, then there's ForeignPtr, to which you can attach finalisers.
21:07:01 <copumpkin> lpsmith: a genuine crank, it seems
21:07:08 <Cale> finali*z*ers, sorry ;)
21:07:14 <copumpkin> lol
21:07:30 <newsham> yay americanize
21:07:38 <copumpkin> americanise
21:07:49 * copumpkin goes back to his roots
21:07:59 <newsham> ?tick iau
21:07:59 <lambdabot> IAU: 106.22 -0.77 (-0.72%) @ 12/22/2009 4:00pm
21:08:28 <Cale> I'm not sure if it's USian or British, but I tend to prefer -ise endings somehow. The OED seems to prefer -ize for some reason.
21:09:22 <Cale> I guess that z wouldn't see too much use otherwise. (Or should that be otherwize? ;)
21:10:02 <newsham> z is for zelda who flew off to mars, she zigged and she zagged past a zillion bright stars
21:10:15 <copumpkin> surely you mean marz
21:11:26 <Cale> Could that be the plot of the next Zelda adventure? "Link... in SPACE!"
21:12:04 * Jafet chokes
21:12:06 <newsham> http://www.kidnkaboodle.net/alphabet.html <- see 'z'
21:12:26 <Cale> Open the pod bay doors Ganondorf! I'm sorry Link, I can't do that! MUAHAHAHAHA!
21:13:02 <Jafet> Cue Link/Samus crack pairing
21:13:14 <mmorrow> newsham: awesome.
21:14:30 <newsham> my son has a cd of those songs
21:15:03 <Cale> I wonder why there's a ton of whitespace at the end of that page.
21:15:39 <newsham> I imagine "Graphix by snogirl" has something to do with it
21:16:19 <Cale> Wow, it was explicitly placed there: <td width="1" height="30511"><spacer type="block" width="1" height="30511"></td>
21:16:35 <Jafet> Maybe they like apples.
21:16:50 <copumpkin> wow, background music on her site
21:17:38 <lpsmith> here's a fun math fact:   given a finite set A,  the probability of a random function chosen uniformly from the set of all functions A -> A not having a fixed point f(x) = x  is approximately the same as a randomly chosen permutation being a derangement,  at least for large cardinalities of A
21:18:28 <lpsmith> Surely there's got to be a combinatorial-like reason for that
21:18:30 <Cale> That's happy.
21:18:54 <EvanR> is it possible to use deriving on a newtype
21:19:10 <Cale> EvanR: yes
21:19:20 <newsham> "aproximately the same"?
21:19:30 <lpsmith> {-# LANGUAGE GeneralizedNewtypeDerving #-}  is handy :-)
21:19:38 <EvanR> so it may derive different things than the type it is 'mimic'ing
21:19:38 <lpsmith> the limit is exactly the same,  1/e
21:20:13 <lpsmith> But say,  you choose a small cardinality,  say 3
21:20:15 <Cale> EvanR: It is even possible, with an extension, to derive almost any typeclass for which there's an instance on the original type -- which is useful when you want to implement some typeclasses differently and others in the same way
21:21:34 <lpsmith> there are 8 functions without a fixed point from a set of 27,  but 3 derangements from a set of 6 permutations
21:21:40 <BMeph> lpsmith: Isn't it definitional? ISo b/t A -> A and permutations, so derangement <-> no f(x) = x :)
21:21:56 <mmorrow> lpsmith: so in other words, the distribution of derangements among permutations is uniform?
21:22:09 <lpsmith> err wait,  2 derangements
21:22:15 * mmorrow thinks that's what that's indirectly saying
21:22:31 <BMeph> lpsmith: Assuming the functions are total, anyway. :)
21:23:03 <lpsmith> well, basically,  if you choose a large finite set,   the probability of not getting a fixed point doesn't matter if you choose a random function or a permutation
21:23:51 <BMeph> Duh; also, if the function's partial, you're guaranteed a fixed point (pigeonhole). :)
21:24:21 <lpsmith> is it?
21:24:25 <lpsmith> it's not definitional
21:24:35 <lpsmith> I am assuming functions are total
21:25:07 <BMeph> Oopsie. Not total, I meant er...injective? :)
21:25:38 <lpsmith> injective would imply a permutation,  as the domain and codomain are the same cardinality
21:26:19 <raceRider> is there a list container that keeps only unique, sorted Integers?
21:26:24 <EvanR> when we for example import A hiding (a, b, c, ...  what are a, b, c? symbols? entities? names? identifiers?
21:26:34 <kmc> raceRider, that's more like a set
21:26:36 <BMeph> Ah, wrong again, I meant surjection. Blasted new-fangled wordisms... ;)
21:26:37 <mmorrow> an injection identifies the domain with a subobject of the range
21:26:48 <kmc> raceRider, use Data.Set
21:26:53 <raceRider> kmc, thanks.
21:27:03 <copumpkin> zomg one more case of the proof filled in!
21:27:04 <kmc> for unordered, unique values with fast testing of membership
21:27:12 <mmorrow> subobjects can actually be /defined/ as equivalence classes of injections
21:27:15 <kmc> in this case "unordered" means "if you ask for an order it will always be sorted"
21:27:28 <lpsmith> sub-object?
21:27:34 <lpsmith> Don't know that term
21:27:35 <raceRider> kmc, cool
21:27:42 <mmorrow> sub-{set,group,field,category,..}
21:27:59 <lpsmith> what's an object?
21:28:06 <andersca> hello
21:28:09 <mmorrow> the things in a category
21:28:23 <copumpkin> mmorrow: by subobject are you talking about the topos idea?
21:28:26 <mmorrow> the dual of sub-object is quotient-object
21:28:27 <lpsmith> oh right...  I'm really not up on category theory :-D
21:28:36 <mmorrow> copumpkin: not in particular
21:28:39 <copumpkin> ah
21:28:56 <mmorrow> sub-object is really common in math, i think you're thinking too hard
21:29:02 <andersca> shapr!
21:29:15 <lpsmith> BMeph:   I think you might be confusing fixpoint as used in the haskell world/ domain theory versus fixpoint in math,  where f(x) = x on the domain and range
21:29:18 <mmorrow> a subset of a set is a set
21:29:24 <mmorrow> a subset of a group is a group
21:29:24 <lpsmith> They are basically the same thing
21:29:31 <mmorrow> gah!
21:29:34 <lpsmith> hahaha
21:29:36 <mmorrow> a subgroup of a group is a group
21:29:47 <mmorrow> a subobject of an object is an object
21:29:57 <BMeph> lpsmith: Okay, how did I mess up things now?
21:30:06 <lpsmith> But the fixpoint that I'm talking about is domain and range,   not a domain.  Argh
21:30:21 <lpsmith> Two different meanings of domain
21:30:28 <mmorrow> heh, yeah
21:30:42 <mmorrow> source/target disambiguates
21:31:01 * mmorrow s|domain/range|source/target|
21:31:15 <lpsmith> :t fix
21:31:16 <lambdabot> forall a. (a -> a) -> a
21:31:40 <lpsmith> fix (\fact n -> if n == 0 then 1 else n * fact (n-1))
21:31:48 <lpsmith> > fix (\fact n -> if n == 0 then 1 else n * fact (n-1)) 7
21:31:50 <lambdabot>   5040
21:33:05 <lpsmith> So fix computes a fixpoint on a complete partial order of something
21:33:32 <BMeph> What I mean is that it sounds like the problem assumes surjective, if not bijective, functions, otherwise there isn't the automatic correspondence between functions and permutations.
21:33:35 <lpsmith> In this case,   a function that takes two arguments
21:33:54 <lpsmith> Well, I did mention that the domain and range were the same finite set
21:34:29 <lpsmith> So say you choose a set of size 5,   there are 5^5 functions from the set to itself
21:34:37 <lpsmith> but 5! permutations
21:35:12 <lpsmith> 4^5 of those functions won't have a value that maps to itself
21:36:07 <lpsmith> whereas... 44 derangements
21:36:25 <lpsmith> >  (4/5) ^ 5
21:36:25 <lambdabot>   0.3276800000000002
21:36:31 <lpsmith> > 44 / 120
21:36:32 <lambdabot>   0.36666666666666664
21:37:02 <lpsmith> Not the same,  but both values converge to 1/e as the size of the set gets larger
21:37:05 <lpsmith> > 1 / e
21:37:06 <lambdabot>   1 / e
21:37:12 <lpsmith> > 1 / exp 1
21:37:13 <lambdabot>   0.36787944117144233
21:37:42 <BMeph> lpsmith: Sometimes when people talk of the range of a function they mean codomain, but not image. Does that make sense? :)
21:37:59 <mmorrow> the collection of all permutations of a set, with ((.),id) is a group
21:38:01 <lpsmith> yeah, that might be it
21:38:02 <mmorrow> http://en.wikipedia.org/wiki/File:GrapheCayley-S4-Plan.svg
21:38:12 <lpsmith> I was referring to range as the codomain,  not image
21:38:26 <mmorrow> yeah, the image is different
21:38:37 <mmorrow> f : A -> B
21:38:44 <mmorrow> Im(f) := f(A)
21:38:52 <mmorrow> which might not be all of B
21:39:07 <mmorrow> (e.g., the canonical injection of Z_n into Z)
21:39:49 <mmorrow> , 0 : interleave (iterate (+3) 0) (iterate (subtract 3) 0)
21:39:50 <lunabot>  [0,0,0,3,-3,6,-6,9,-9,12,-12,15,-15,18,-18,21,-21,24,-24,27,-27,30,-30,33...
21:40:07 <mmorrow> `subset` Integers
21:40:25 <mmorrow> (and `subgroup` Integers too)
21:40:37 <BMeph> Right. and according to http://en.wikipedia.org/wiki/Bijection#Properties, "...for a finite set S, there is a bijection between the set of possible total orderings of the elements and the set of bijections from S to S."
21:41:08 <mrd> perrmutations
21:41:11 <BMeph> ..."That is to say, the number of permutations of elements of S is the same as the number of total orderings of that set -- namely, n!."
21:41:33 <lpsmith> right,  bijections are permutations,  and vice versa
21:42:10 <lpsmith> (are infinite permutations allowed?  I dunno)
21:42:14 <BMeph> And derangements are bijections w/o a fixed point.
21:42:19 <lpsmith> correct
21:42:21 <mrd> bijections from a set onto itself
21:42:31 <lpsmith> mrd:  good point
21:43:29 <lpsmith> Anyway,  not that important,  but it's a fun fact I didn't know until a few days ago :-)
21:44:35 <BMeph> Finite set; you can have non-injective infinite permutations, e.g. n -> 2n
21:45:19 <BMeph> Hmm, I'm not sure if that would make sense, though.... Never mind. :)
21:46:50 <lpsmith> well,  if one were to define permutations on an infinite set,  I'd define it as a bijection from the set to itself,  maybe with other properties to make them "nicer" depending on context
21:49:32 <BMeph> Yeah; Wikipedia says they're explicitly bijections on finite sets. I'm still looking for infinite set definitions.
21:49:56 <tensorpudding> x |-> -x is a "permutation" on an infinite set, of a kind
21:50:15 <tensorpudding> when -x makes sense, anyway
21:52:05 <lpsmith>  yep
21:53:35 <tensorpudding> you could call the permutations on G the subgroup of Aut(G) with finite order
21:53:51 <tensorpudding> err, subgroup of elements of finite order
21:54:25 <napping> isn't it enough for the elements to be invertible?
21:54:51 <napping> oh, and could someone type some unicode?
21:55:18 <tensorpudding> what?
21:55:38 <dmwit> some unicode
21:55:43 <napping> things like n -> 2n wouldn't be in a group
21:55:47 <dolio> —°
21:55:49 <copumpkin> ‚äò
21:56:27 <BMeph> dmwit: :˛
21:56:38 <tensorpudding> napping: yes, that wouldn't have finite order
21:58:29 <EvanR> can a case case have multiple patterns in a pattern. hah. i know. i mean like this: case (something) of {x y -> expr; [] _ -> expr;}
21:58:45 <tensorpudding> if G is finite, then every element in Aut(G) has finite order, since Aut(G) is itself finite
22:01:58 * mmorrow loves going off on extended rants only to realize he's disconnected..
22:02:26 <tensorpudding> reflections in the plane will be "permutations" by this definition
22:02:32 <BMeph> WvanR: No; you can, however put guards on the (options?) of the case..
22:03:07 <BMeph> Yikes! EvanR: The above comment was for you. :)
22:03:19 <napping> oh, that's a good example. rotations not rational in pi will have infinite order and inverses
22:03:21 <EvanR> no auto complete for you it seems
22:03:45 <EvanR> right guards
22:03:52 <mmorrow> <mmorrow> BMeph: the nice thing about "objects" and morphisms of them is that you usually ensure that in situations where the function is surjective and not injective (i.e. not a bijection, but many-to-one on the image) it's the case that there's some sort of empty subobject, and it's exactly there that all the subobjects not present in the image are mapped (which is a collapsed version of the original preimage)
22:04:08 <mmorrow> (re: Finite set; you can have non-injective infinite permutations, e.g. n -> 2n)
22:04:51 <mmorrow> so what that says is that in, say A and B are Monoids, and () is the trivial monoid (i.e. the monoid generated by mempty)
22:05:17 <mmorrow> so in f : A -> B, a morphism of monoids, if B `subset` Im(f) *then* if you trace backwards from Im(f) everything that mapped to the monoid (), then you get exactly the submonoids of A which were collapsed
22:06:12 <mmorrow> <mmorrow> if Im(f)==B as sets (i.e. f is surjective) and the inverse image of () under f  is (), then f is an isomorphism of monoids
22:06:12 <mmorrow> <==> f is injective iff (inverseImage f {mempty} `iso` {mempty})
22:06:12 <mmorrow> </flood>
22:06:27 * mmorrow sighed x4 when he realized he typed that all out to a dead connection :)
22:08:06 <mmorrow> so the moral of this in my opinion is that only considering morphisms/homomorphisms/maps/whatever-you-want-to-call-them of objects/things point-wise misses out on a lot of the structure
22:10:07 <mmorrow> and that morphisms are really acting on structure of the objects themselves
22:11:08 <tensorpudding> what are the higher structures of groups and rings?
22:11:17 <Cale> mmorrow: Uh, what was that about non-injective permutations?
22:11:18 <tensorpudding> the normal subgroups/ideals?
22:11:29 <Cale> (permutations are bijections by definition, aren't they?)
22:11:35 <mmorrow> tensorpudding: right, ideals in particular
22:11:56 <tensorpudding> topology is all about morphisms between sets that preserve special subsets
22:11:58 <mmorrow> Cale: right, i took a tangent ;)
22:12:39 <tensorpudding> continuous mapping = preimage of open sets are open
22:12:41 <Cale> tensorpudding: preimages of special subsets
22:13:29 <mmorrow> tensorpudding: e.g. the ideals of a commutative ring and the subvarieties of affine varieties (e.g. (n-dim) curves and stuff) are duals
22:13:38 <mmorrow> well, the prime ideals
22:13:56 <tensorpudding> i don't know a damn thing about AG, i'm afraid
22:14:43 <Cale> prime ideals <-> irreducible varieties, maximal ideals <-> points
22:14:55 <mmorrow> in other words, an adjoint functor pair between algebra and geometry (errr, adjoint right?)
22:15:18 <tensorpudding> but this sounds intriguing now
22:15:29 <tensorpudding> i'll add some varieties to my learning queue
22:15:49 <Cale> tensorpudding: They're the sets of points on which a collection of polynomials are all 0
22:16:05 <Cale> (polynomials in n indeterminates)
22:16:26 <tensorpudding> which collections of polynomials?
22:16:51 <Cale> Well, arbitrary sets
22:17:57 <tensorpudding> arbitrary sets of polynomials wouldn't appear to have a set of common roots
22:17:58 <Cale> Like, let's say we have some set of polynomials F subset R[x,y,z], then the set of points {(x,y,z) : for all f in F, f(x,y,z) = 0} is a variety in R^3
22:18:34 <tensorpudding> though I'm thinking of the case of n=1 most since that is the one I'm familiar with
22:18:55 <Cale> Of course, they might have no points in common and give you the empty variety
22:19:11 <Cale> But in general, you want varieties to be closed under intersection
22:19:33 <Cale> and in higher dimensions, that's problematic if you only have one polynomial each
22:20:23 <tensorpudding> also, polynomials in R[x,y,z] are not uniquely defined by their roots are they?
22:20:31 <Cale> That's right
22:21:07 <lpsmith> mmorrow: lpsmith: so in other words, the distribution of derangements among permutations is uniform?
22:21:12 <lpsmith> What did you mean by that?
22:21:14 <Cale> If you take a set of points in R^3 however, you can take the set of all polynomials having those points as roots
22:21:18 <Cale> and you get an ideal
22:21:57 <Cale> and if you take the variety corresponding to that ideal, it's a sort of "closure", the smallest variety containing that set of points
22:22:19 <tensorpudding> wait
22:22:20 <Cale> (you can sort of see the monad of the adjunction in that)
22:22:54 <tensorpudding> what guarantees that the variety that corresponds to that ideal is not countably infinite
22:23:10 <Cale> Uh, it might be finite
22:23:11 <tensorpudding> wait, nvm, that's silly
22:23:58 <tensorpudding> the variety is the intersections of the sets of roots of each polynomial in the ideal
22:24:00 <Cale> For example, the ideal generated by xyz will have a variety consisting of just a single point
22:24:10 <Cale> (The point (0,0,0))
22:24:15 <Cale> yeah
22:25:14 <Cale> Or: the intersection of all the varieties containing at least those points
22:25:30 <tensorpudding> if you generate an ideal I of R[x,y,z] using a set X in R^3, why should the variety contain points not in X?
22:25:52 <Cale> Maybe the set of points wasn't the set of roots of a polynomial?
22:26:30 <tensorpudding> is that possible if the base field is algebraically closed?
22:26:36 <Cale> yes, quite possible
22:26:44 <Cale> The set of points may be infinite
22:27:29 <tensorpudding> oh
22:27:34 <tensorpudding> yes there is that possiblity
22:27:37 <mmorrow> tensorpudding: so if the polynomials that generate an ideal each map to 0 on s subset of the underlying (to that polynomial ring) field, then that entire ideal does. also, if I and J are ideals this ring of polynomials, and every polynomial (i.e. the generators) of I and J are 0 on some set of points, then the ideals I*J and I+J and   V(I*J) = V(I) \/ V(J)   V(I+J) = V(I) /\ V(J)
22:27:43 <Cale> For example, the set of points {(x,y,sin(x)) : x,y in R} isn't the set of roots of some polynomial
22:28:15 <tensorpudding> what does that /\ and \/ mean
22:28:24 <Cale> union and intersection, probably
22:28:24 <mmorrow> where V is the functor from (Category of commutative rings) to (category of affine algebraic varieties)
22:28:28 <mmorrow> yeah
22:28:55 <mmorrow> if I and J are prime ideals, then V(I) and V(J) are irreducible affine varieties
22:29:30 <Cale> Once you have this ideal, you can also attach a ring, called the coordinate ring, to each variety, by quotienting out R[x,y,z] by the ideal.
22:29:59 <mmorrow> then you can do stuff like forgetting about algebraically closed fields, and work over, say Z[x], by just looking at the prime ideals of that ring
22:30:21 <tensorpudding> i don't see how that works
22:30:32 <mmorrow> tensorpudding: it's kind of a sneaky step
22:31:15 <tensorpudding> what does I*J and I+J mean
22:31:23 <tensorpudding> can't remember
22:32:07 <mmorrow> oh, the ideals generated by all products of generators and all sums of generators of I and J
22:32:44 <mmorrow> say I = Z_5, J = Z_7
22:32:50 <Cale> tensorpudding: IJ = {a_1 b_1 + a_2 b_2 + ... + a_n b_n : a_i in I, b_i in J}, I+J = {a+b : a in I, b in J}
22:33:02 <tensorpudding> ah
22:33:07 <tensorpudding> that makes sense
22:33:35 <tensorpudding> Cale: what are the arrows in the latter category in that functor
22:34:15 <Cale> tensorpudding: Well, for the moment, just inclusions.
22:34:41 <tensorpudding> also do these varieties have unique coordinate rings
22:39:00 <Cale> tensorpudding: This stuff is starting to get a little hazy in my head, as it was several years ago that I last looked at it, but I believe there are further adjunctions between the category of varieties in some space and polynomial (or birational?) maps between them, and certain categories of rings, constructed by quotienting out the polynomial ring by the ideals.
22:39:15 <Cale> I forget the details at this point, maybe mmorrow knows :)
22:39:40 <tensorpudding> i don't know what an adjunction is yet
22:39:56 <Cale> ah, okay, that I can do :)
22:40:28 <tensorpudding> i have postponed category theory to work more on big rudine lately
22:41:51 <tensorpudding> rudin*
22:42:06 <copumpkin> rudin?
22:42:33 <Cale> Well, the easiest definition to grasp (in my opinion), is that you have two functors pointing in opposite directions, F: C <- D and G: C -> D, along with natural transformations epsilon: FG -> 1, and eta: 1 -> GF, satisfying some fairly natural laws
22:42:33 <tensorpudding> the graduate analysis book that rudin wrote
22:43:22 <Cale> tensorpudding: You wouldn't happen to know already what a Galois connection is?
22:44:00 <mmorrow> Cale: yeah, that's pretty much all of it i can remember from studying it in a class or two
22:44:54 <tensorpudding> no
22:45:30 <Cale> Okay, I'll skip that analogy -- it turns out that Galois connections are adjunctions between preorder categories
22:45:41 <Cale> (the definition reduces to the same thing)
22:46:10 <Cale> But okay, suppose we have some adjoint functors like above, it turns out that we can make a monad out of them.
22:46:21 <Cale> Specifically, GF is a monad
22:46:38 <Cale> We already have eta (return)  1 -> GF
22:46:43 <mmorrow> which also comes up in galois theory and covering spaces
22:46:55 <Cale> and we just need a mu (join)  GFGF -> GF
22:47:10 <Cale> which we can get by applying the epsilon to the middle FG
22:47:35 <Cale> and it turns out that every monad comes from at least two adjunctions, and possibly more
22:47:44 <tensorpudding> i'll get there when i get there
22:47:48 <Cale> okay :)
22:48:02 <tensorpudding> is there a good book for learning about affine varieties?
22:48:10 <mmorrow> tensorpudding: err, i meant in "then you can do stuff like forgetting about algebraically closed fields, and work over, say Z[x], by just looking at the prime ideals of that ring"
22:48:13 <mmorrow> to say
22:48:17 <mmorrow> just Z (!)
22:48:46 <Cale> That, I don't know. I could really use a good textbook myself, to abstain from having it all slip away from me since I took that course in algebraic curves :)
22:49:50 <Cale> We actually worked over R for the most part, which is not really as nice as working over C, but it's easier to draw pictures.
22:50:49 <Cale> I heard that sometimes when that course is held, they do a beeline for projective varieties in C, and do everything there.
22:50:56 <mmorrow> i took a commutative algebra course and the textbooks were
22:51:24 <mmorrow> http://www.amazon.com/Introduction-Commutative-Algebra-Demand-Michael/dp/0201407515/ref=sr_1_2?ie=UTF8&s=books&qid=1261550980&sr=8-2
22:51:52 <mmorrow> (intial parts of this, the next semester continued to the rest) http://www.amazon.com/Algebraic-Geometry-Graduate-Texts-Mathematics/dp/0387902449/ref=sr_1_1?ie=UTF8&s=books&qid=1261551005&sr=8-1
22:51:55 <copumpkin> wow, beautiful cover
22:52:00 * copumpkin judges that book by its cover
22:52:09 <mmorrow> and this was recommended for "reference"
22:52:12 <Cale> hehe
22:52:19 <mmorrow> http://www.amazon.com/Commutative-Algebra-Algebraic-Geometry-Mathematics/dp/0387942696/ref=sr_1_1?ie=UTF8&s=books&qid=1261550980&sr=8-1
22:52:32 <mmorrow> heh, that little green one is super old-school
22:52:34 <Cale> Oh, Hartshorne of course.
22:52:41 <Cale> I've heard quite a bit about that one
22:53:09 <mmorrow> yeah, that's "the" standard one
22:53:19 <tensorpudding> atiyah-macdonald I've tried reading a bit into it but lost interest
22:54:10 <Cale> Heh, I actually have a djvu of Eisenbud here.
22:54:34 <Cale> er, looks like the text is a bit messed up though
22:55:55 <Cale> Oh, hey, there's Atiyah/Macdonald...
22:56:07 * Cale moves it into his main mathematics books directory
22:59:54 * Cale does 'locate Hartshorne' and finds 3.4 GB of books he forgot about. :O
22:59:55 <luite> do you read those books from screen?
23:00:01 <Cale> yeah
23:00:03 <mmorrow> yeah, that one can get a little dry by itself
23:00:06 <mmorrow> heh, and the other ones are more referece/"here's four lifetimes of information written as tersely as possibly, kbai"
23:00:13 <mmorrow> i don't know of one that i'd consider written from a tutorial perspective actually (i'd like to know one though)
23:00:13 <Cale> heh
23:01:40 <tensorpudding> i'm curious why varieties are interesting though
23:02:59 <Cale> tensorpudding: Well, I sort of found them intrinsically interesting because they encompass a lot of the shapes and curves that we'd normally care about.
23:03:23 <copumpkin> also, they apparently explain why you can derive a list from a meaningless type expression
23:03:29 <copumpkin> although I have yet to read about them
23:03:43 <Cale> Oh, really? That's curious.
23:03:51 <copumpkin> I thought you told me :)
23:03:53 <copumpkin> you or byorger
23:03:54 <copumpkin> y
23:05:52 <copumpkin> I was talking about that List a = 1 + (a * List a) => List a - a * List a = 1 => (1 - a) * List a = 1 => List a = 1 / (1 - a) => List a = 1 + a + a^2 + a^3 + ...
23:06:21 <dmwit> varieties == species?
23:06:28 <copumpkin> oh maybe I was confused :)
23:07:37 * copumpkin goes back to his hopeless proof
23:07:38 <Cale> ah, yeah, that's more like it :)
23:08:16 <Cale> The people doing combinatorics have known what it means to differentiate a data structure for much longer than the people in CS ;)
23:08:43 <dmwit> ...and do other more interesting operations, too
23:08:46 <tensorpudding> ugh, i hate how often i end up closing chrome on accident
23:09:05 <dmwit> Perhaps byorgey will lift us up to the standards of math from 100 years ago. =)
23:09:10 <Gracenotes> Cale: there must be some category construct for things that are differentiatable, no?
23:09:36 <Cale> Gracenotes: hmmm
23:10:08 <Gracenotes> Cale: also very interesting, http://matt.might.net/articles/implementation-of-regular-expression-matching-in-scheme-with-derivatives/
23:10:16 <Gracenotes> a candidate member
23:10:17 <Cale> Gracenotes: Well, since species are actually functors, perhaps, yes.
23:10:44 <Cale> The main thing which makes something a "derivative" is that is satisfies some sort of product rule.
23:11:00 <Gracenotes> yeah, that seems to be the most peculiar feature
23:11:22 <Gracenotes> which regex derivatives follow
23:12:10 <Cale> iirc, for regular expressions the product rule was actually just a little bit strange
23:12:19 <Cale> but pretty much the same idea.
23:12:45 <Gracenotes> oh. hm.. it's more of a partial derivative
23:13:06 <Cale> that delta works its way in on one side
23:13:06 <Gracenotes> okay, it is a bit odd. didn't catch that.
23:13:45 <Gracenotes> concatenation might not exactly correspond to product. that's more intersection, which textual regex don't support, although they certainly could
23:14:08 <Cale> Because the intention is that the derivative of the regular expression with respect to c be the regular expression which matches exactly that set of strings x for which the first RE matches cx.
23:14:10 <copumpkin> preflex: seen HaskellLove
23:14:10 <preflex>  HaskellLove was last seen on #haskell 23 hours, 39 minutes and 29 seconds ago, saying: copumpkin that means i should send here or not? lot of them won't be haskell related, i guess i should find a proofs stuff chanel
23:14:28 <dolio> Shhh!
23:14:41 * copumpkin does the *love-summoning dance ;)
23:14:48 <Cale> It's really stupid that regex libraries don't support intersection, imo.
23:15:07 <dolio> And complement.
23:15:09 <Cale> There have been a lot of times I wanted operations like intersection and complement, and they just weren't there.
23:15:10 <Cale> yeah
23:15:47 <copumpkin> don't worry, my verified regex module in agda will support those!
23:15:48 <copumpkin> ;)
23:15:51 <Gracenotes> it is mostly hard for humans to think in terms of intersection, at least from an anthropomorphized regex engine perspective
23:15:56 <Cale> I mean, if there's any benefit to parsing with regular expressions at all, it's all the nice operations they're closed under.
23:16:38 <Cale> and the performance, of course
23:16:39 <Gracenotes> how do you match two expressions at the same time on the same bit of string? isn't not immediately obvious how it'd be useful. (of course, context-free and context-sensitive regex constructs don't aid this so much either)
23:16:41 <dolio> Clearly it's much more important to be able to write arbitrary backtracking stuff using a terrible syntax.
23:16:45 <Cale> But perl rejects both of those.
23:17:05 <copumpkin> recently on proggit there was a proposal for recursive regexes
23:17:08 <ray> perl thinks the benefit to regular expressions is that perl supports them
23:17:21 <ray> recursive regular expressions? uh
23:17:31 <Cale> Perl rejects both the good performance, by choosing a stupid implementation, and the closure under lots of operations by simply not having a syntax for them.
23:18:02 <Gracenotes> nothing regular about them
23:18:10 <mle> if it's re...yeah.
23:18:12 <Cale> (and posix before it)
23:18:26 <mle> "Highly irregular."
23:18:39 <Cale> Well, I don't know how most posix implementations work, but they don't have a syntax for the other operations you'd want
23:18:55 <dolio> Well, it uses the slow implementation to allow the constructs that break the nice properties that regexes are closed under, presumably.
23:19:24 <Gracenotes> now, if someone could only invent a pithy (very sugary) way of expressing real production-rule-based grammars, that would be.. nice.
23:19:47 <Cale> Gracenotes: we have one, it's called Parsec ;)
23:19:57 <mle> Parsec + Control.Applicative does quite well
23:20:05 <Cale> Well, that's not full production grammars.
23:20:06 <Gracenotes> I suppose yacc, parsec, etc., are nice, but nothing really matching the string-based compiledness of regex
23:20:10 <mle> and it works equally well on binary syntaxes
23:20:32 <Gracenotes> that's made it quite popular for shell tools and parsing-where-parsers-would-be-more-appropriate alike
23:20:32 <Cale> Gracenotes: Parsec is much easier to read than the string-based regexes, I find.
23:20:36 <luite> Gracenotes: is that really an advantage?
23:20:37 <Cale> At least, for a lot of things.
23:21:03 <Gracenotes> it is pretty clear. I'm sure you might agree it's not too sugary, but it is expressive.
23:21:46 <Cale> what is?
23:22:38 <Gracenotes> parsec.
23:22:42 <Cale> yeah
23:22:50 <Cale> I suppose that regexes are very very good at the trivial and almost-trivial cases, but they scale horribly.
23:23:39 <Gracenotes> the sorts of cases people have been using with perl's "recursive regex", those are good use cases for what I have in mind.
23:24:19 <Gracenotes> something along the lines of EBNF-in-code, but even terser. and this is all too vague.
23:25:58 <ivanm> How long has filepath been a boot lib of ghc?
23:28:45 <ivanm> since the base split in 6.8?
23:28:59 <Mark1> is something like foldl1 (\x:xs y:ys -> somefunction) [[]] allowed, or is it impossible to use a list of lists with foldl1?
23:29:24 <copumpkin> sure it is
23:29:27 <ivanm> should be possible
23:29:36 <ivanm> as long as your folding function is correct
23:29:43 <ivanm> though I think you need some parens in there...
23:30:56 <Mark1> awesome, thanks. i'll start writing the function.
23:32:06 <joe____> can you please help ffi the below line in hsc2hs (using bindings-DSL):
23:32:08 <joe____> #define DIV_VALUE(rate) (rate > 6000000)?0:((6000000/rate -1) > 0xffff)? 0xffff: (6000000/rate -1)
23:32:09 <lunabot>  luna: Not in scope: `define'
23:32:44 <joe____> should I just make it a normal haskell function?
23:33:08 <copumpkin> why not?
23:33:23 <copumpkin> you can't FFI to a macro
23:33:56 <joe____> ok, then I will define it is a normal haskell function.
23:33:58 <joe____> thanks.
23:36:40 <joe____> another quick question, should I define rate as a Float or Double?
23:37:28 <copumpkin> be general
23:39:02 <ivanm> make your functions general, but use Double for your overall program
23:46:59 <chrisdone> use Rational and then convert when you need to display!
23:47:01 <chrisdone> :P
23:53:57 <joe____> i successfully defined my first ffi using hsc2hs, though i have one issue. I had to put the full path of the bindings.dsl.h file in the .hsc file. Somehow, hsc2hs is not able to read the include file from my local cabal directory. Any thoughts, please?
23:54:17 <joe____> I need to define the local cabal include directory to hsc2hs
23:55:05 <joe____> i could use hsc2hs -i="include file path" but am wondering if there is a better way.
