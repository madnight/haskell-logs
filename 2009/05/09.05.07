00:00:21 <mmorrow> , fromDynamic (toDyn (print 42)) :: Maybe String  {- ;) -}
00:00:22 <lunabot>  Nothing
00:00:44 <JoshTriplett> , ) `seq` ("hello") --
00:00:45 <lunabot>  luna: parse error (possibly incorrect indentation)
00:01:02 <mmorrow> hah yeah, one annoying thing about wrapping in show(...) is -- doesn't work
00:01:37 <mmorrow> lunabot could parse the input, then wrap in "show("...")" at the ast level to fix that, but i'm too lazy :)
00:01:38 <trofi^w> lambdabot solved it by newlining second ')'
00:01:51 <mmorrow> ah yeah, that's a good idea too
00:03:02 <mmorrow> and that would also mean i have to take lunabot down:
00:03:05 <mmorrow> mmorrow  11442  0.1  0.1 229488 10932 pts/2    Sl+  Mar17 105:22 ./bot +RTS -N8 -RTS
00:03:07 <mmorrow> :)
00:03:24 <mmorrow> impressive, since it's forkIO'ing a thread for *every* incoming message
00:03:46 <mmorrow> (Mar17)
00:03:51 <trofi^w> :]
00:04:44 <JoshTriplett> , ) `seq` (\_ -> "") (
00:04:45 <lunabot>  luna: no output
00:04:46 <trofi^w> luna isn't so popular as lambdabot yet
00:04:57 <JoshTriplett> , ) `seq` (\_ -> undefined) (
00:04:58 <lunabot>  luna: Ambiguous type variable `a' in the constraint:
00:05:02 <JoshTriplett> , ) `seq` (\_ -> undefined :: String) (
00:05:04 <lunabot>  luna: Prelude.undefined
00:05:07 <JoshTriplett> , ) `seq` (\_ -> undefined :: Int) (
00:05:39 <mmorrow> trofi^w: yeah, lunabot only does eval though
00:05:44 <mmorrow> whereas  lambdabot
00:05:49 <mmorrow> @. vixen nixon
00:05:49 <lambdabot> is that why?
00:05:50 <trofi^w> yep
00:06:13 <trofi^w> @@ quote go i've forgot syntax
00:06:13 <lambdabot>  quote go i've forgot syntax
00:06:55 <ziman> @@ foo bar baz
00:06:55 <lambdabot>  foo bar baz
00:07:33 <trofi^w> @help @@
00:07:34 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
00:07:37 <trofi^w> @help @
00:07:37 <lambdabot>  @ [args].
00:07:37 <lambdabot>  @ executes plugin invocations in its arguments, parentheses can be used.
00:07:37 <lambdabot>  The commands are right associative.
00:07:37 <lambdabot>  For example:    @ @pl @undo code
00:07:39 <lambdabot>  is the same as: @ (@pl (@undo code))
00:08:11 * ski wonders why there's `@' inside the command, there
00:08:55 <Twey> It's the prefix for the commands
00:08:57 <ski> @. pl undo do {a <- ma; f <- mf; return (f a)}
00:08:58 <lambdabot> (`fmap` mf) . flip id =<< ma
00:09:17 <ski> yes .. so why is the prefix required *inside* a command string ?
00:10:06 <ski> (i was under the impression that the prefex was for singling out irc messages as commands to be interpreted by the bot in question .. inside the command the bot should already know that it's intended for it)
00:10:07 <ziman> @ @pl @undo do {a <- ma; f <- mf; return $ f a }
00:10:43 <JoshTriplett> , ) `seq` (\_ -> unsafeCoerce 5 :: String) (
00:10:44 <lunabot>  luna: Not in scope: `unsafeCoerce'
00:10:49 <JoshTriplett> Ah, good. ;)
00:11:17 <ski> (this is a similar level of irritation as people who insist on talking about "the function strlen()" in C (as opposed to "the function strlen"))
00:11:51 <JoshTriplett> ski: Heh.  I have the same reaction when people talk about "malloc(3)".
00:12:14 <Twey> ski: Truly
00:12:21 <ski> well, at least there the parens are (for some reason) to specify the section
00:12:28 <Twey> Could just be a consistency thing
00:12:46 <ski> (rather inconsistency, imnsho ..)
00:13:27 <JoshTriplett> mmorrow: Random nit, for if you ever do take lunabot down: could you please make it not require the , prefix when talking to it via /msg?
00:13:44 <JoshTriplett> mmorrow: It already knows I want to talk to it since I've used /msg, so it shouldn't need a prefix.
00:13:52 <mmorrow> JoshTriplett: ahh, that's a good point
00:14:00 <mmorrow> JoshTriplett: will do
00:14:08 <JoshTriplett> mmorrow: Thanks!
00:14:11 <mmorrow> :)
00:14:22 <ski> ty
00:14:39 <JoshTriplett> Heh:
00:14:40 <JoshTriplett> ,,
00:14:41 <lunabot>  luna: No instance for (GHC.Show.Show (a -> b -> (a, b)))
00:14:54 <JoshTriplett> ,,,
00:14:55 <lunabot>  luna: No instance for (GHC.Show.Show (a -> b -> c -> (a, b, c)))
00:15:01 <mmorrow> ha
00:15:12 <JoshTriplett> ,++
00:15:13 <lunabot>  luna: No instance for (GHC.Show.Show ([a] -> [a] -> [a]))
00:15:16 <Cale> I propose that we always refer to Haskell functions in casual conversation with the URL of the documentation in parens afterward.
00:15:21 <JoshTriplett> Nice way to get types. :)
00:15:22 <ski> , [$ty| , |]
00:15:25 <lunabot>  luna: Exception when trying to run compile-time code:
00:15:25 <mmorrow> ,,)(4)(2)(
00:15:26 <lunabot>  luna: Couldn't match expected type `t -> t1 -> () -> a'
00:15:33 <mmorrow> oh
00:15:38 <JoshTriplett> ,\x -> undefined
00:15:39 <lunabot>  luna: No instance for (GHC.Show.Show (t -> a))
00:15:57 <mmorrow> ski: show (,)
00:16:02 <ski> i see
00:16:05 <JoshTriplett> ,5:
00:16:06 <lunabot>  luna: No instance for (GHC.Show.Show ([a] -> [a]))
00:16:23 <mmorrow> wuh
00:16:27 <JoshTriplett> Huh.  Odd that it didn't mention Num there.
00:16:34 <mmorrow> , show (,5:)
00:16:35 <lunabot>  luna: parse error on input `5'
00:16:43 <mmorrow> , (,5:)
00:16:44 <lunabot>  luna: parse error on input `5'
00:16:46 * ski was for a few seconds thinking lunabot implemented Caml-style tuples / tuple constructors
00:17:08 <JoshTriplett> mmorrow: Uh, the comma comes from lunabot's prefix. :)
00:17:11 * mmorrow doesn't get how "show (,5:)" even parses
00:17:13 <JoshTriplett> , show (5:)
00:17:14 <lunabot>  luna: No instance for (GHC.Show.Show ([a] -> [a]))
00:17:16 <mmorrow> ahhhh
00:17:17 <mmorrow> haha
00:17:22 <JoshTriplett> ,
00:17:22 <lunabot>  luna: <stdin>: Data.ByteString.hGetLine: end of file
00:17:25 <JoshTriplett> ,
00:17:25 <lunabot>  luna: <stdin>: Data.ByteString.hGetLine: end of file
00:17:30 <mmorrow> grr, i should fix that too
00:17:38 * mmorrow makes a list
00:17:57 <JoshTriplett> , \x -> x x
00:17:58 <lunabot>  luna: Occurs check: cannot construct the infinite type: t = t -> t1
00:18:21 <JoshTriplett> , \f x -> f f x
00:18:22 <lunabot>  luna: Occurs check: cannot construct the infinite type: t = t -> t1 -> t2
00:18:37 <mmorrow> i also should get the lunabot code organized and actually in a state where compiling it isn't epic
00:18:40 <Cale> , \f x -> f (f x)
00:18:41 <lunabot>  luna: No instance for (GHC.Show.Show ((t -> t) -> t -> t))
00:18:51 <mmorrow> and release it
00:19:05 <JoshTriplett> , \f -> f.f
00:19:06 <lunabot>  luna: No instance for (GHC.Show.Show ((c -> c) -> c -> c))
00:19:22 <JoshTriplett> Fun.  I wonder why it uses t in one case and c in the other? :)
00:19:40 <JoshTriplett> , \_ _ _ _ _ _ _ _ -> undefined
00:19:41 <lunabot>  luna: No instance for (GHC.Show.Show
00:19:45 <JoshTriplett> Oooh.
00:19:46 <Cale> :t (.)
00:19:47 <lambdabot> forall b c a. (b -> c) -> (a -> b) -> a -> c
00:19:50 <JoshTriplett> What happened *there*?
00:19:59 <JoshTriplett> , \_ _ _ _ _ -> undefined
00:20:00 <lunabot>  luna: No instance for (GHC.Show.Show (t -> t1 -> t2 -> t3 -> t4 -> a))
00:20:03 <JoshTriplett> , \_ _ _ _ _ _ -> undefined
00:20:04 <lunabot>  luna: No instance for (GHC.Show.Show
00:20:09 <Twey> Too long, truncated
00:20:14 <Gracenotes> line break, that's what happened!
00:20:17 <Twey> Ah, no
00:20:18 <mmorrow> , ) where show () = const ("OH HAI") (
00:20:19 <lunabot>  luna: parse error on input `where'
00:20:20 <Twey> Linebreak, yeah :)
00:20:22 <Twey> Try it in GHCi
00:20:39 <Gracenotes> , [ $ty | \_ _ _ _ _ _ -> undefined |]
00:20:40 <lunabot>  luna: parse error on input `|]'
00:20:41 <JoshTriplett> mmorrow: Heh, cute idea. :)
00:20:43 <Gracenotes> :.
00:20:44 <mmorrow> no where, since it's compiling it as an expression..
00:21:01 <mmorrow> JoshTriplett: i was excited for a second there.. ;)
00:21:01 <ski> JoshTriplett : probably the name `c' came from an explicit type signature of `(.)'
00:22:06 <mmorrow> , [$bf|.+[.+]|]
00:22:08 <lunabot>  luna: No instance for (GHC.Show.Show
00:22:08 <mmorrow> , [$bf|.+[.+]|] ""
00:22:09 <lunabot>  "\NUL\SOH\STX\ETX\EOT\ENQ\ACK\a\b\t\n\v\f\r\SO\SI\DLE\DC1\DC2\DC3\DC4\NAK...
00:22:28 <JoshTriplett> bf?
00:22:41 <mmorrow> , [$bf2|,+.>+++++.|] "012"
00:22:43 <lunabot>  ("1\ENQ",(1,Mem (fromList [(0,49),(1,5)])))
00:22:48 <Twey> Brainfuck :)
00:22:51 <mmorrow> brainfuckQQ! :)
00:22:53 <JoshTriplett> Ah. :)
00:23:21 <JoshTriplett> , let f = [$bf|.+[.+]|] in [$ty|f|]
00:23:24 <lunabot>  forall a . FromExpr a => a
00:23:25 <mmorrow> , [$ty| (bf, [$bf| .+ \|], [$bf2| .+ \|]) |]
00:23:28 <lunabot>  (QuasiQuoter, String -> String, String -> (String, (Ptr, Mem)))
00:23:36 <mmorrow> (Ptr := Int)
00:23:42 <mmorrow> (Mem := IntMap)
00:23:55 <mmorrow> err, newtype Mem = Mem (IntMap Int)
00:23:59 <JoshTriplett> FromExpr?
00:24:13 <mmorrow> ah, that SimpleReflect
00:24:21 <mmorrow> , [$bf|.+|]
00:24:22 <lunabot>  luna: No instance for (GHC.Show.Show
00:24:25 <mmorrow> , [$bf|,.|]
00:24:26 <lunabot>  luna: No instance for (GHC.Show.Show
00:24:27 <mmorrow> , [$bf|,.|] "z"
00:24:29 <lunabot>  "z"
00:24:31 <mmorrow> , [$bf|,.|] ""
00:24:32 <lunabot>  "*** Exception: bf blocked on input"
00:24:48 <mmorrow> the QQ results in an expression :: String -> String
00:24:58 <JoshTriplett> , [$ty|f|]
00:25:01 <lunabot>  forall a . FromExpr a => a
00:25:03 <JoshTriplett> , [$ty|x|]
00:25:04 <mmorrow> , f
00:25:05 <lunabot>  luna: Ambiguous type variable `a' in the constraints:
00:25:06 <lunabot>  Expr
00:25:11 <mmorrow> @type f
00:25:12 <lambdabot> forall a. (SimpleReflect.FromExpr a) => a
00:25:29 <mmorrow> iirc that's in the "Show" pkg on hackage
00:25:47 <mmorrow> , foldl f z [0..9]
00:25:49 <lunabot>  f (f (f (f (f (f (f (f (f (f z 0) 1) 2) 3) 4) 5) 6) 7) 8) 9
00:26:54 <JoshTriplett> , f x
00:26:55 <lunabot>  luna: Ambiguous type variable `a' in the constraints:
00:26:58 <JoshTriplett> , f 5
00:26:59 <lunabot>  luna: Ambiguous type variable `a' in the constraints:
00:27:04 <JoshTriplett> , f "5"
00:27:06 <lunabot>  luna: Ambiguous type variable `a' in the constraints:
00:27:36 <JoshTriplett> , f "5" :: String -> Expr
00:27:37 <lunabot>  luna: No instance for (GHC.Show.Show
00:27:54 <JoshTriplett> , (f :: Int -> Expr) 5
00:27:56 <lunabot>  f 5
00:27:56 <Gracenotes> lambdabot can halp too
00:28:03 <JoshTriplett> , (f :: String -> Expr) "5"
00:28:05 <lunabot>  f "5"
00:28:55 <JoshTriplett> , (f :: Expr -> Expr) f
00:28:57 <lunabot>  f f
00:29:51 <JoshTriplett> , (f :: Expr -> Expr) (f :: Expr)
00:29:53 <lunabot>  f f
00:29:58 <JoshTriplett> , (f :: Expr -> Expr) (f :: Expr -> Expr)
00:29:59 <lunabot>  luna: Couldn't match expected type `Luna.SimpleReflect.Expr'
00:30:21 * JoshTriplett wonders if "instance Category Expr" would work.
00:30:24 <JoshTriplett> With 6.10.
00:31:36 <mmorrow> JoshTriplett: here's that bf module: http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=2354#a2354
00:32:10 <mmorrow> , [$bf|++++++++++[>+++++++>++++++++++>+++>+<<<<-]>++.>+.+++++++..+++.>++.<<+++++++++++++++.>.+++.------.--------.>+.>.|]
00:32:12 <lunabot>  luna: No instance for (GHC.Show.Show
00:32:12 <mmorrow> , [$bf|++++++++++[>+++++++>++++++++++>+++>+<<<<-]>++.>+.+++++++..+++.>++.<<+++++++++++++++.>.+++.------.--------.>+.>.|] ""
00:32:14 <lunabot>  "Hello World!\n"
00:32:27 <mmorrow> i always forget the ""..
00:35:18 <wli> Maybe there's some dynamic programming one can use when trying to do addition chain multiplication for long strings of sequential numbers.
00:35:55 <Hunner> Is there already a BF compiler/interpreter in haskell?
00:36:01 <boegel> is it possible, in general, to reach C-like performance with (pure) Haskell? or are there case in which it just can"t be done?
00:36:12 <boegel> Hunner: BF = Brainfuck?
00:36:25 <boegel> Hunner: there must be
00:36:26 <JoshTriplett> mmorrow: Do you have a list of the stuff available inside luna?
00:36:26 <Hunner> Yeah. Well, assumedly there is, since it did it
00:36:50 <mmorrow> JoshTriplett: i'll make one
00:36:51 <Twey> boegel: In general, yes
00:37:07 <JoshTriplett> mmorrow: Let me ask another way.  Do you have the source available somewhere? :)
00:37:20 <Twey> Depends how you define ‘pure Haskell’, of course
00:37:42 <mmorrow> JoshTriplett: heh. yeah, i'm actually gonna package lunabot right now.
00:37:44 <Twey> You can write custom assembly in a perfectly Haskellish monad
00:37:58 <mmorrow> JoshTriplett: it should only take about 15 minutes i'd say
00:39:02 <boegel> Twey: how are you interpreting C-like here? equally fast?
00:39:29 <boegel> Twey: well, let's say without writing assembly or using FFI
00:39:52 <boegel> Twey: so, let the Haskell compiler generate the code from Haskell
00:40:12 <Twey> boegel: No, you don't understand
00:40:27 <Twey> It's possible to write Haskell that generates custom assembly, then run it
00:40:50 <Twey> There's a library
00:41:11 <JoshTriplett> Twey: I think you've dodged his question. :)
00:41:16 <Twey> Or rather, I suppose, generates machine code
00:41:29 <Twey> No, the answer is still ‘in general, yes’
00:41:34 <JoshTriplett> boegel: Yes, even without using FFI or non-Haskell code, you can generally achieve equal or better performance than C.
00:42:01 <Twey> With care, it's possible to write C-speed code fairly easily for most (but not all) situations
00:42:32 <Twey> (but to balance out that ‘not all’, there are also places where idiomatic Haskell tends to exceed the speed of idiomatic C)
00:42:57 * SubStack is happy so long as it's a constant coefficient away
00:43:07 <opqdonut> :D
00:43:12 <JoshTriplett> SubStack: Ditto.
00:43:28 <Twey> But there are an awful lot of things one can do in Haskell
00:43:30 <SubStack> haskell can be so pretty and c so correspondingly hideous
00:43:31 <JoshTriplett> SubStack: Actually, lately I'll settle for "doesn't exhaust the heap". :)
00:43:48 <SubStack> and vice-versa, but much less so
00:44:01 <Twey> Writing custom machine code in Haskell may not be idiomatic, but it's still Haskell — it's expressed as a monad
00:44:04 <johnw> i find C to be one of the best languages to code review
00:44:22 <Twey> 'cause you can find lots of bugs?  :-P
00:44:24 <johnw> because you don't have to wonder about how many hidden actions might be taking place that you don't know about because you haven't reviewed that section yet...
00:44:50 <Twey> Well, Haskell solves that too, in a rather different way
00:44:59 <boegel> I'm trying to come up with a function which implements Euclidean distance in n-dimensional space, and have so far been unsuccesful to reach C-like performance from it, although I'm closing in
00:45:03 <johnw> true
00:45:32 <SubStack> johnw: sounds like you don't get to review much event-driven c code
00:45:42 <JoshTriplett> What SubStack said. :)
00:45:49 <johnw> no, i mostly work with compilers
00:45:51 <opqdonut> boegel: i'd like to see the various versions you've come up with
00:45:52 * SubStack hates writing gl apps in c
00:45:55 <johnw> pretty A->Z
00:46:06 <boegel> opqdonut: I plan to post them on haskell-cafe sometime today
00:46:10 <zoheb> you mean sum$ map sq
00:46:17 <boegel> opqdonut: I'm running a bunch of experiments first to benchmark the lot
00:46:22 <opqdonut> boegel: good, good :)
00:46:25 <SubStack> opengl in haskell is fun times
00:46:33 <boegel> opqdonut: but, let me show you in short what I have already :)
00:46:43 <mux> johnw: I'd agree with you until macros come into the picture :)
00:46:54 <johnw> ah, true!
00:46:55 <zoheb> @type (sum.map) sq
00:46:56 <lambdabot> Not in scope: `sq'
00:47:00 <johnw> i recently had a case where there was a non-uppercase macro
00:47:01 <zoheb> @type (sum.map) square
00:47:02 <lambdabot> Not in scope: `square'
00:47:07 <johnw> and sure enough, I misused it
00:47:19 <mux> those are evil
00:47:28 <johnw> C teaches you to make assumptions about what you see
00:47:37 <johnw> ("Oh, it looks like a function, I can take its address...")
00:48:18 <SubStack> pesky von neumann machines!
00:49:10 <boegel> opqdonut: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677
00:49:17 <boegel> opqdonut: that's the Haskell and C version
00:49:34 <opqdonut> 2
00:49:36 <opqdonut> -2
00:49:39 <boegel> opqdonut: Haskell is compiled with -O2 -fexcess-precision -fvia-C -optc-O3, gcc with -O3
00:49:42 <JoshTriplett> , let square x = x*x in [$ty| sqrt sum . map square |]
00:49:45 <lunabot>  luna: Exception when trying to run compile-time code:
00:49:49 <JoshTriplett> , let square x = x*x in [$ty| sqrt . sum . map square |]
00:49:51 <lunabot>  luna: Exception when trying to run compile-time code:
00:49:53 <opqdonut> boegel: thanks
00:49:58 <mmorrow> that doesn't work, although it could be made to
00:50:14 <JoshTriplett> , [$ty| sqrt . sum . map (\x -> x*x) |]
00:50:15 <boegel> opqdonut: I'm still collecting data for the benchmarking, but for dim. 10 C is like 20x faster
00:50:17 <lunabot>  forall a . Floating a => [] a -> a
00:50:18 <mmorrow> , let x = [0..4] in [$here|[0..4] is $(x)|]
00:50:20 <lunabot>  "[0..4] is [0,1,2,3,4]"
00:50:26 <boegel> opqdonut: for dim. 100 C is only 60% faster though, it seems
00:51:41 <JoshTriplett> mmorrow: What does $here do?
00:51:49 <mmorrow> , let xs = ["a","b"]; t = "foo" in [$here|SELECT $(hcat . punctuate comma . fmap text $ xs) FROM $(t);|]
00:51:51 <lunabot>  "SELECT a,b FROM \"foo\";"
00:51:55 <mmorrow> grr
00:51:55 <boegel> you might say the C version is pretty straightforward, while using the uvector package is somewhat less straightforward, but still pretty easy
00:52:00 <mmorrow> , let xs = ["a","b"]; t = "foo" in [$here|SELECT $(hcat . punctuate comma . fmap text $ xs) FROM $(text t);|]
00:52:02 <lunabot>  "SELECT a,b FROM foo;"
00:52:17 <mmorrow> boegel: it's a "heredoc" QQ which also can splice in haskell
00:52:30 <mmorrow> (that's in lunabot's source too)
00:52:40 <JoshTriplett> mmorrow: What type goes in the $() inside it?
00:52:46 <JoshTriplett> mmorrow: String, or any Show?
00:52:52 <mmorrow> JoshTriplett: forall a. (Show a) => a
00:53:11 <opqdonut> boegel: how about giving euclidean an explicit type sig Double->Double->Double ? i don't know whether ghc is smart enough to specialize it as it is
00:53:38 <JoshTriplett> Or alternatively, {-# SPECIALIZE ... #-}
00:53:53 <boegel> opqdonut: hmm
00:53:57 <opqdonut> JoshTriplett: well yeah, but that's not h98 :P
00:54:01 <opqdonut> (not that it matters...)
00:54:10 <mmorrow> , [$here| $(42::Int) $([0..4]) $(take 2 (levels (fix (\x -> Node () [x,x]))))|]
00:54:13 <lunabot>  " 42 [0,1,2,3,4] [[()],[(),()]]"
00:54:15 <boegel> opqdonut: I'd expect it to be smart enough, but I can try :)
00:55:11 <JoshTriplett> opqdonut: It most certainly *is* Haskell 98.  It parses as a comment, and thus has no semantic effect. ;)
00:55:32 <mmorrow> heh
00:55:38 <Twey> But the resulting code that uses it isn't :-P
00:55:51 <Twey> I wouldn't worry too much about sticking to h98
00:55:53 <Twey> It's old
00:55:55 <mmorrow> why isn't it?
00:55:58 <JoshTriplett> Twey: Sure it is.  It just doesn't necessarily run as fast. ;)
00:56:09 <JoshTriplett> Twey: But in general I agree with you.
00:56:10 <Twey> Well, in this particular case :-P
00:56:16 <opqdonut> one would expect the type sig to have exactly the same effect
00:56:24 <opqdonut> on any compiler that supports SPECIALIZE
00:57:55 <mmorrow> ooh, i'd forgotten:
00:57:57 <boegel> opqdonut: the Haskell version is kicking C's ass on dimension 1000 and up though...
00:58:07 <opqdonut> great \o/
00:58:08 <mmorrow> , [$pl| \a b c -> g (f a b c) |]
00:58:10 <lunabot>  ((g .) .) . f
00:58:23 <mmorrow> i extracted @pl from lambdabot and made a QQ
00:58:24 <zoheb> can you paste your haskell code boegel?
00:58:44 <boegel> zoheb: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677
00:59:05 <mmorrow> , (parseExp . render) [$pl| \a b c -> g (f a b c) |]
00:59:08 <lunabot>  Right (InfixE (Just (InfixE (Just (InfixE (Just (VarE g)) (VarE .) Nothin...
00:59:20 <boegel> I wonder if my C version is as optimal as can be (being still C, not assembly, that is)
00:59:41 <boegel> I guess the compiler should avoid computing p1[i] - p2[i] twice...
01:01:36 <zoheb> How do you generate the input data?
01:01:37 <mmorrow> boegel: gcc most likely, ghc probably not
01:01:52 <mmorrow> boegel: i'd use a "let" if you're talking about haskell
01:02:24 <mmorrow> (once a single "let" to save computing something trivial like that twice took my prog from 9 seconds to 2 seconds)
01:02:37 <zoheb> It should be easy for GHC to eliminae common subexpr, I would think
01:02:46 <zoheb> ref transparency and all
01:03:00 <mmorrow> zoheb: but it doesn't :)
01:03:08 <JoshTriplett> zoheb: Trivial, yes.  But sometimes a bad idea.
01:03:25 <JoshTriplett> zoheb: CSE can cause a haskell program to unexpectedly use more memory.
01:03:37 <JoshTriplett> zoheb: Due to sharing you didn't expect.
01:03:50 <johnw> sharing I didn't expect used to be such a good thing
01:03:55 <johnw> in kindergarten...
01:04:03 <johnw> something special
01:04:12 <opqdonut> :D
01:04:19 <zoheb> can you give an example Josh?
01:05:59 <boegel> mmorrow: no, I was talking about C :)
01:06:15 <JoshTriplett> zoheb: Sure.  (fuseableListProcessing (generateHugeList "foo"), fuseableListProcessing2 (generateHugeList "foo"))
01:06:29 <boegel> mmorrow: I am using let in the Haskell code to avoid stuff being computed twice
01:07:01 <JoshTriplett> zoheb: You might *want* to generate the list twice, and consume it as you create it both times.
01:07:13 <JoshTriplett> zoheb: Whereas if you CSE it, you might use much more memory than you expect.
01:07:17 <JoshTriplett> zoheb: Make sense?
01:08:54 <zoheb> yes thanks Josh
01:09:22 <boegel> nice graph @ http://users.elis.ugent.be/~kehoste/eucl_dist_v1_2009-05-07_10-07-06.pdf
01:09:22 <mmorrow> boegel: nice. but really the case i'm thinking of i was like "oh that's trivial and i'm too lazy to add a let", and then was floored when i added it and my prog instantly got 7 seconds fast :)
01:09:56 <boegel> mmorrow: I find it somewhat strange that GHC isn't able to figure these things out, but patches welcome, I guess :P
01:10:31 <mmorrow> boegel: yeah, i'm not sure what exactly happened in the case i'm thinking of, but it seems like it was something weird to me
01:10:45 <mmorrow> (because 9 secs to 2 secs!!!@ wtf)
01:11:00 <boegel> mmorrow: :)
01:11:08 <mmorrow> (i'm trying to find the code i'm thinking of to show..)
01:11:21 <boegel> mmorrow: well, maybe it was part of your hot code path, that would explain it
01:11:34 <boegel> mmorrow: although it would need to be _very_ hot :)
01:12:51 <boegel> I wonder if I could get Haskell as fast a C for the smaller dimensions
01:13:03 <boegel> because I'm mostly focussed on the range 10-100
01:13:48 <boegel> in dimension 100k, Haskell is 3x faster than C, which is tr?s cool
01:16:24 <zoheb> How do you time the function and generate input data?
01:16:50 <zoheb> I mean have you evaluated the whole list before calling the function?
01:19:14 <boegel> zoheb: yes, I make sure the whole list is evaluated
01:19:22 <mmorrow> boegel: weird, now the slower version is around 2.8 seconds and the faster one 1.7 seconds... i must have made another change(s) too from the 9 seconds version (this was a month or so ago, so i don't recall)  http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=2355
01:19:34 <boegel> zoheb: I'm using the Microbench package with some hackery, because part of Microbench is broken with GHC 6.10
01:19:48 <boegel> zoheb: I'll post details on this later on haskell-cafe, and probably my blog too
01:19:53 <mmorrow> err, s/2.8/2.3/
01:20:22 <boegel> mmorrow: a 4.5x speedup did seem spectacular just by using let :P
01:20:47 <mmorrow> boegel: yeah, i was freaked out at the time :)
01:21:11 <JoshTriplett> , runST $ do r <- unsafeInterleaveST (newSTRef "hello") ; v1 <- unsafeInterleaveST (readSTRef r) ; modifySTRef r reverse ; v2 <- unsafeInterleaveST (readSTRef r) ; return (v1, v2)
01:21:12 <lunabot>  ("olleh","olleh")
01:21:30 <edwardk> mmorrow is there a reason why lunabot doesn't parse comments?
01:21:47 <boegel> opqdonut: specializing euclidean to Double doesn't seem to make any difference, so I suppose GHC is able to figure that out itself
01:21:56 <mmorrow> edwardk: it wraps every incoming expression \e -> ("show (" ++ e ++ ")") for convenience
01:22:12 <mmorrow> that could be fixed easy enough though... (laziness :)
01:22:27 <edwardk> kk
01:22:35 <edwardk> heading to bed
01:22:58 <JoshTriplett> I guess you can't really do anything dangerous (security-wise) with unsafeInterleaveST.
01:23:06 <mmorrow> i'm packaging lunabot as we speak though..
01:28:59 <JoshTriplett> mmorrow: I look forward to seeing it...in the morning. :)
01:29:43 <boegel> hmm, maybe GHC isn't inlining the dist call, while C is
01:29:44 <zoheb> So ghc computes 100 dim faster than 10 dim?
01:29:48 <mmorrow> JoshTriplett: cool. i'll @tell you with the URL in the meantime
01:30:00 <boegel> that would explain why Haskell is slower for smaller dimensions, because the dist call itself takes less long
01:30:24 <boegel> how can I enforce inlining if the dist function is defined in another module? is that possible? inlining functions which are defined in another module?
01:31:16 <boegel> zoheb: hmm, good point
01:31:19 <boegel> strange
01:31:35 <ski> , let {scramble as = newSTRef as >>= \ref -> mapM (\_ -> unsafeInterleaveST (readSTRef ref >>= \(a:as) -> writeSTRef ref as >> return a)) as} in let stxs = scramble [0,1,2,3] in runST stxs == reverse (runST stxs)
01:31:36 <lunabot>  True
01:31:42 <ski> , let {scramble as = newSTRef as >>= \ref -> mapM (\_ -> unsafeInterleaveST (readSTRef ref >>= \(a:as) -> writeSTRef ref as >> return a)) as} in let stxs = scramble [0,1,2,3] in runST stxs
01:31:43 <lunabot>  [0,1,2,3]
01:31:44 <boegel> zoheb: I can imagine there's a large overhead cost when the vectors are small
01:31:53 <ski> , let {scramble as = newSTRef as >>= \ref -> mapM (\_ -> unsafeInterleaveST (readSTRef ref >>= \(a:as) -> writeSTRef ref as >> return a)) as} in let stxs = scramble [0,1,2,3] in drop 2 (runST stxs)
01:31:55 <lunabot>  [0,1]
01:32:02 <zoheb> Also, maybe you shoud eliminate the extra floating pt subtraction in C
01:32:10 <boegel> zoheb: although that result in strange, indeed
01:32:19 <boegel> zoheb: tried that, makes no difference
01:32:29 <boegel> zoheb: GCC optimizes that away by CSE
01:32:49 <ski> , let {scramble as = newSTRef as >>= \ref -> mapM (\_ -> unsafeInterleaveST (readSTRef ref >>= \(a:as) -> writeSTRef ref as >> return a)) as} in let xs = runST (scramble [0,1,2,3]) in length (reverse xs) `seq` xs
01:32:50 <lunabot>  [0,1,2,3]
01:32:59 <ski> , let {scramble as = newSTRef as >>= \ref -> mapM (\_ -> unsafeInterleaveST (readSTRef ref >>= \(a:as) -> writeSTRef ref as >> return a)) as} in let xs = runST (scramble [0,1,2,3]) in sum (reverse xs) `seq` xs
01:33:00 <lunabot>  [3,2,1,0]
01:33:08 <ski> , let {scramble as = newSTRef as >>= \ref -> mapM (\_ -> unsafeInterleaveST (readSTRef ref >>= \(a:as) -> writeSTRef ref as >> return a)) as} in let xs = runST (scramble [0,1,2,3]) in sum (drop 2 xs) `seq` xs
01:33:09 <lunabot>  [2,3,0,1]
01:33:45 <zoheb> How the hell is Haskell so much faster on large numbers?
01:33:53 <mmorrow> zoheb: gmp possibly
01:34:01 <mmorrow> (if you're talking about Integer)
01:34:06 <mmorrow> gmp is lightning
01:34:06 <zoheb> I just can't imagine the machine code for haskell being that much better
01:34:19 <mmorrow> (gmp is C ;)
01:34:21 <zoheb> than C
01:34:38 <mmorrow> all Integer computation call into gmp
01:35:25 <mmorrow> but if you're talking about floating point, then i'm stunned
01:36:18 <zoheb> whats gmp?
01:36:32 <mmorrow> gnu multiprecision arithmetic library
01:36:34 <boegel> mmorrow: it's all Double
01:36:38 <mmorrow> boegel: :o
01:36:57 <zoheb> does double mean the same thing in both haskell and C?
01:36:59 <boegel> I don't know what's going on either
01:37:04 <mmorrow> boegel: are you sure the Haskell and C are actually computing the same thing?
01:37:10 <zoheb> I think the best thing to do is look at the assembly
01:37:12 <boegel> mmorrow: yeah, Euclidean distance :)
01:37:18 <boegel> zoheb: probably, yeah
01:37:20 <mmorrow> like, is the Haskell only computing part of it that you're actually printing/using
01:37:23 <johnw> zoheb: I thought Haskell just used the same IEEE numbers as C does
01:37:35 <mmorrow> boegel: what arch are you on?
01:37:39 <boegel> mmorrow: Core i7
01:37:52 <boegel> mmorrow: but I'm looking at numbers for different arch's too as we speak
01:37:53 <mmorrow> ghc uses sse on x86_64, but the x87 fp stuff on x86
01:38:04 <zoheb> The only possible problem with the C code could be instead of p[i] you could increment p
01:38:27 <boegel> mmorrow: core i7 is x86_64
01:38:37 <mmorrow> boegel: cool
01:38:48 <boegel> zoheb: how would that help? prefetching?
01:39:13 <boegel> the gcc is 4.3.3 btw
01:39:25 <zoheb> shouldn't help much at all
01:39:29 <zoheb> actually
01:39:34 <boegel> zoheb: don't think so too
01:39:54 <zoheb> gcc -S should show the assembly
01:40:10 <boegel> mmorrow: I think I'm enforcing everything in the Haskell version, but I'm not 100% sure
01:40:15 <mmorrow> zoheb: actually (module ghc unboxing as an optim, which it usually does) Double in haskell is data Double = D# Double#, where Double# is a machine double
01:40:32 <mmorrow> so it's even more surprising that haskell is beating C here
01:40:41 <boegel> mmorrow: I can't print the result of each dist call to enforce it's evaluation, because I'm calling dist a huge amount of times
01:40:58 <mmorrow> boegel: i've gotta believe that laziness is working for you somehow here
01:41:12 <boegel> mmorrow: which is not what I want, let me stress that :)
01:41:16 <mmorrow> heh
01:41:35 <mmorrow> zoheb: err, s/module/modulo/
01:42:07 <mmorrow> like, consider this:
01:42:31 <boegel> mmorrow: this is my benchmarking function
01:42:32 <boegel> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4680
01:42:33 <mmorrow> , head $ fft (fmap (:+0) [0..2^14-1])
01:42:35 <lunabot>  1.34209536e8 :+ 0.0
01:42:41 <mmorrow> boom, laziness
01:42:45 <boegel> mmorrow: yeah, I know :)
01:43:01 <mmorrow> (i thought that fft example is pretty cool myself ;)
01:43:08 <boegel> mmorrow: but since my benchmark function is in the IO monad, I think I'm safe...
01:43:17 * mmorrow looks
01:43:36 <boegel> Microbench is using mapM_, which isn't enforcing evaluation though
01:43:45 <mmorrow> why a performGC?
01:44:08 <boegel> mmorrow: oh, just to ensure GC isn't messing with the next benchmark call
01:44:15 <boegel> mmorrow: i.e., enforce cleanup
01:44:28 <mmorrow> ah, hmm
01:45:15 <boegel> mmorrow: I've checked through profiling that a) it takes longer if the n parameter is higher, and b) that almost 100% of the time is spent in the dist* function, not in benchmark or main
01:45:24 <boegel> mmorrow: so I _think_ I'm good
01:46:01 <boegel> I think inlining is to blame here...
01:46:22 <boegel> at least for the part where Haskell is less good for small dimensions
01:46:36 <boegel> I don't know why Haskell is faster than C though :)
01:47:29 <trofi^w> > sum $ take 3 [1..10^12]
01:47:31 <lambdabot>   6
01:47:49 <fasta> How hard is it to get a representation of all the Haskell code below a certain directory, do a source to source transformation in which all the calls to (/) are replaced by a version of (/) which contains the current line number and a check for isNaN? I am thinking it is a lot more than an hour of work. These things should be easy :(
01:49:24 <QtPlaty[1ireMe]> Dare I say it sounds like a job for perl.
01:51:07 <QtPlaty[HireMe]> Though is sounds like what you should be able to do is add a line import Prelude hiding ((/))
01:51:42 <QtPlaty[HireMe]> Then import your safe slash from some libary.  Though I'm a beginner at haskell.
01:52:07 <fasta> QtPlaty[HireMe]: in every module... and even then, I don't actually want to change anything. I just want the source to source transformation be applied and compiled, but I don't actually want to change the source.
01:52:27 <fasta> QtPlaty[HireMe]: also you need to do these things on an AST representation.
01:53:10 <QtPlaty[HireMe]> fasta: IIRC Template haskell permits AST transformations.
01:53:47 <fasta> QtPlaty[HireMe]: TH has bad documentation and all kinds of technical limitations.
01:55:25 <boegel> mmorrow: do you think my benchmark function will enforce evaluation fully n times? or will some part be left out due to laziness?
02:13:35 <Alpounet> ghc -e 'something' file.hs lets us execute the 'something' function from file.hs right ?
02:21:05 <mmorrow> boegel: this is interesting: asm comparison gcc and ghc: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4681
02:22:07 <mmorrow> boegel: gcc seems to be doing something weird with sqrt==> it's doing "sqrtsd  %xmm1, %xmm0" in every loop, then calling sqrt() at then end
02:22:16 <mmorrow> while ghc only calls sqrt() at the end
02:24:33 <mmorrow> boegel: this is much clearer: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4683
02:25:48 <lukeo05> If I have a function which returns a IO String, and another function which takes a String, is it possible to use the IO String as the String parameter?
02:26:04 <zoheb> no
02:26:21 <zoheb> You can fmap it I guess
02:26:24 <Alpounet> lukeo05, >>=
02:26:44 <Alpounet> :t (>>=)
02:26:44 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
02:26:49 <mmorrow> but if (foo :: String -> a) and you have (s :: IO String), then (return . foo =<< s) :: IO a
02:27:04 <Alpounet> here, 'm' is 'IO'
02:27:06 <mmorrow> (foo `fmap` s)
02:27:09 <mmorrow> (foo <$> s)
02:27:15 <mmorrow> (foo `liftM` s)
02:27:25 <mmorrow> are all the same as (return . foo =<< s)
02:27:43 <mmorrow> (and are all :: IO a)
02:28:27 <zoheb> The main thing is that you will get an IO a object when myfun :: String -> a
02:28:39 <zoheb> You won't get a pure a
02:28:57 <mmorrow> and if you have a (bar :: a -> b) you just do the same thing to get an (IO b)
02:29:07 <mmorrow> and so on
02:29:41 <lukeo05> hmmm, thank you. not quite sure I get this IO stuff....
02:30:02 <mmorrow> return . (baz . <blah stuff> . bar . foo) =<< (s :: IO String)
02:30:13 <zoheb> The idea is that performing IO destroys referential transparency
02:30:17 <mmorrow> so you put all your pure stuff:
02:30:25 <mmorrow> return . <here> =<< s
02:30:31 <mmorrow> (s :: IO String)
02:30:40 <zoheb> so all the computation you do with IO must happen inside the monad
02:30:59 <mmorrow> but your pure stuff is none-the-wiser that it's wrapped in IO
02:31:18 <zoheb> the type system enforces that by letting you return only an IO a object instead of a when IO is involved
02:31:25 <mmorrow> main = print . oneThousandLinePureFunction =<< getContents
02:31:28 <mmorrow> could be your prog
02:31:40 <Berengal> Also, interact
02:31:42 <Berengal> @type interact
02:31:43 <lambdabot> (String -> String) -> IO ()
02:31:47 <zoheb> The standard technique is to write a separate pure function
02:31:50 <mmorrow> @src interact
02:31:50 <lambdabot> interact f = do s <- getContents; putStr (f s)
02:31:54 <zoheb> like say interact
02:32:08 <mmorrow> main = putStr . f =<< getContents
02:32:13 <zoheb> and then combine the IO and pure function at the very top level in main
02:33:37 <lukeo05> I kind of see I think. Thanks :)
02:33:40 <zoheb> s/interact/first param of interact/
02:37:18 <boegel> mmorrow: wow, thanks for the asm study
02:37:33 <boegel> mmorrow: so, in fact, GHC is doing a much better job than gcc in generating code for this?
02:37:41 <mmorrow> boegel: it's interesting. i wonder why gcc is doing sqrtsd in ever loop?
02:37:54 <mmorrow> boegel: heh, suprisingly i think it actually is :)
02:38:18 <boegel> mmorrow: what happens if you compile with ghc -O2 -fvia-C -optc-O3?
02:38:26 <mmorrow> hmm, i'll see
02:38:28 <boegel> mmorrow: does the sqrtsd thing happen too then?
02:38:49 <zoheb> theres a jg L4 before the sqrtsd
02:39:06 <zoheb> is it calling it in the loop, doesn't look like it
02:39:27 <fasta> mmorrow: don't let Bulat hear this
02:40:54 <boegel> mmorrow: I agree with zoheb, I think the sqrtsd is out of the loop
02:41:45 <Alpounet> Where is kmeans's Vector data type defined ?
02:42:31 <mmorrow> boegel: oddly it doesn't
02:42:44 <mmorrow> (ghc -O2 -fvia-C -optc-O3 -optc-fomit-frame-pointer -S)
02:43:07 <mmorrow> zoheb: ahhh, oops
02:43:10 <boegel> mmorrow: :)
02:43:11 <mmorrow> fasta: heh
02:43:25 <boegel> mmorrow: seems like the Haskell version has a lot more cruft in the loop
02:43:32 <mmorrow> boegel: yeah
02:43:47 <boegel> mmorrow: could you tell whether the functions are inlined, both in C and Haskell?
02:43:54 <mmorrow> hmm, that's odd still though.. why is gcc doing sqrtsd *and* calling sqrt?
02:43:55 <boegel> mmorrow: I'm guessing the C one was inlined?
02:44:03 * boegel looks up sqrtsd
02:44:47 <mmorrow> i compiled the C one with -O3, which implies -finline-functions iirc
02:44:59 <boegel> "compute square root of scalar double-precision floating-point value"
02:45:56 <zoheb> It looks like it calls sqrt only conditionally
02:46:02 <boegel> mmorrow: there's no sqrt instruction, so I'm guessing the label matching 'sqrt' is just cleanup code?
02:46:16 <mmorrow> ohhh, i think what it's doing is computing it with sqrtsd first, then doing ucomisd, and if certain flags are set discard that sqrt result and uses math.h's
02:46:18 <zoheb> if somehow the sqrtsd failed or smthng
02:46:27 <zoheb> precision error perhaps
02:46:43 <boegel> mmorrow: hmm
02:46:49 <boegel> could be
02:47:02 <boegel> but that can't be the reason for the huge different in performance though, right?
02:47:17 <zoheb> I think it is a timing measurement issue
02:47:48 <boegel> C gets worse compared to Haskell when the loop gets larger, but sqrt is called _after_ the loop
02:47:57 <zoheb> how are you measuring it? How do you get the clock ticks?
02:48:09 <mmorrow> boegel: yeah, i can't understand why the haskell is faster to be honest :)
02:48:18 <mmorrow> it's gotta be something with laziness
02:48:31 <mmorrow> the haskell just is computing less than the C is or something
02:48:36 <boegel> zoheb: I'm using what Microbench uses in Haskell, which is getCurrentTime and diffUTCtime
02:48:42 <boegel> zoheb: in C, I'm using gettimeofday
02:49:02 <boegel> mmorrow: how do I check? :)
02:49:13 <zoheb> I mean are you using the CPU clock or the timer interrupt
02:49:22 <mmorrow> boegel: i'm not sure, actually :)
02:49:27 <zoheb> I think you are using the timer interrupt and that can be off
02:49:40 <mmorrow> because the only real way to force everything is to print it, which will kill the time comparison
02:49:45 <boegel> zoheb: I'm doing 20 runs of each experiment, and averaging them
02:49:46 <mmorrow> well, i guess you could use rnf
02:49:48 <zoheb> getCurrentTime most probably gets down to the OS
02:49:51 <boegel> zoheb: variance is pretty low across runs
02:50:09 <boegel> mmorrow: the trick is to make it compute it's result _n_ times though
02:50:29 <mmorrow> boegel: hmmm
02:50:45 <mmorrow> ahh, "replicate n ..."
02:50:48 <boegel> mmorrow: did you check out my benchmark function?
02:50:51 <boegel> ah, you did
02:51:11 <boegel> mmorrow: yeah, I need the "replicate n" part to avoid GHC computing the value just once
02:51:14 <mmorrow> yeah, ghc might be just computing it once too
02:51:18 <mmorrow> ah, hmm
02:51:37 <mmorrow> i'm not sure what's happening :)
02:51:41 <boegel> mmorrow: doing dist_fast p1 p2, and mapping that using const to a list doesn't work, because the result of dist_fast is computing prior to mapping
02:52:08 <boegel> mmorrow: when I'm using partial evaluation, and given the same argument n times, then it seems like it's computing the result n times too
02:52:18 <boegel> mmorrow: although I'm not 100% sure of that
02:52:51 <boegel> mmorrow: I'm basically trying to outsmart GHC, and make it compute the same thing n times :P
02:53:29 <boegel> mmorrow: but you're right, since I'm not using 'r' anymore, it might be lazy
02:53:47 <boegel> benchmarking shit in Haskell is _hard_
02:53:58 <mmorrow> heh. one thing is that "replicate n x" will make a list of n ptrs to the same x, so maybe mapM'ing over such a list will only compute it once no matter what
02:54:16 <mmorrow> , vaccum (replicate 4 0)
02:54:17 <lunabot>  luna: Not in scope: `vaccum'
02:54:21 <mmorrow> , vacuum (replicate 4 0)
02:54:24 <lunabot>  [(0,[1,2]),(1,[]),(2,[1,3]),(3,[1,4]),(4,[1,5]),(5,[])]
02:54:28 <mmorrow> , vacuum [0,0,0,0]
02:54:30 <lunabot>  [(0,[1,2]),(1,[]),(2,[3,4]),(3,[]),(4,[5,6]),(5,[]),(6,[7,8]),(7,[]),(8,[])]
02:54:38 <McManiaC> @pl \h c -> c { foo = h }
02:54:38 <lambdabot> (line 1, column 11):
02:54:38 <lambdabot> unexpected "{"
02:54:38 <lambdabot> expecting variable, "(", operator or end of input
02:55:00 <lukeo05> I have had to write a function which does nothing to make my call to maybe work, because it won't let me not call a function on my lookup. as in, value k tb = maybe "No Entry" (lookup k tb) doesn't work but value k tb = maybe "No Entry" nothing (lookup k tb) does. I must be doing something wrong, right?
02:56:32 <mmorrow> , maybe "No Entry" id (lookup 2 [(1,"asdf"),(2,"qwerty")]
02:56:33 <lunabot>  luna: parse error (possibly incorrect indentation)
02:56:34 <mmorrow> , maybe "No Entry" id (lookup 2 [(1,"asdf"),(2,"qwerty")])
02:56:35 <lunabot>  "qwerty"
02:56:50 <mmorrow> , maybe "No Entry" reverse (lookup 2 [(1,"asdf"),(2,"qwerty")])
02:56:52 <lunabot>  "ytrewq"
02:56:53 <zoheb> why dont you add and subtract one from the last element of the list?
02:56:58 <boegel> mmorrow: well, using replicate will avoid making n copies of the 'x', but that doesn't mean it'll avoid computing dist n times, right?
02:57:01 <zoheb> and re-evaluate the list
02:57:13 <mmorrow> boegel: that's the thing i'm unsure about
02:57:35 <boegel> mmorrow: it depends whether or not GHC is smart enough to figure out that I'm applying a partial function n times to the same argument
02:57:40 <boegel> zoheb: mm?
02:57:45 <mmorrow> boegel: exactly
02:57:56 <boegel> mmorrow: question is, how does one make sure :)
02:58:06 <zoheb> I think GHC will be able to figure that out
02:58:13 <boegel> mmorrow: with larger n, the time to compute the whole time is rising, that's for sure
02:58:25 <zoheb> figuring out shared partial applications is not hard
02:58:38 <mmorrow> , vacuum (mapM return (replicate 2 0) :: Maybe [Int])
02:58:40 <lunabot>  [(0,[1]),(1,[2,3]),(2,[]),(3,[2,4]),(4,[])]
02:58:43 <boegel> mmorrow: so then, where would the cost with higher n come from? making the list of n pointers with replicate?
02:58:47 <mmorrow> , vacuum (mapM return [0,0] :: Maybe [Int])
02:58:49 <lunabot>  [(0,[1]),(1,[2,3]),(2,[]),(3,[4,5]),(4,[]),(5,[])]
02:58:55 <mmorrow> ooh
02:59:08 <boegel> mmorrow: ?
02:59:18 <boegel> I'll have to run in 1m guys, lunch
02:59:29 <mmorrow> i think that shows that it *is* smart enough
02:59:30 <boegel> I'll be back in 1h orso though
02:59:36 <boegel> mmorrow: howso?
02:59:45 <mmorrow> oh wait
02:59:49 <boegel> @type vaccum
02:59:50 <lambdabot> Not in scope: `vaccum'
02:59:54 <boegel> @type vacuum
02:59:54 <lukeo05> mmorrow: Ah, yes, id works and means I don't have to include my own nothing method. Is it just an annoying quirk that you have to call a function on the value you get even if you don't want to do anything with it?
02:59:55 <lambdabot> Not in scope: `vacuum'
03:00:08 <boegel> mmorrow: what's vacuum?
03:00:13 <mmorrow> it's http://moonpatio.com/vacuum/
03:00:25 <mmorrow> it walks the heap graph and sucks out a rep
03:00:42 <boegel> hmm
03:01:14 <Alpounet> is there a SPJ facts page ?
03:01:16 <Alpounet> heh
03:01:18 <mmorrow> one think you could do is replicateM i think
03:01:33 <mmorrow> that should ensure it's computed n times (i believe)
03:02:10 <mmorrow> , vacuum (replicateM 2 (return 0) :: Maybe [Int])
03:02:12 <lunabot>  [(0,[1]),(1,[2,3]),(2,[]),(3,[2,4]),(4,[])]
03:02:24 <mmorrow> err, no it doesn't i guess (in this trivial case)
03:02:44 <boegel> GHC is too damn smart!!
03:02:47 <mmorrow> heh
03:02:53 <boegel> anyway, time for lunch (and some peace of mind)
03:02:59 <mmorrow> have fun
03:03:00 <boegel> I'll be back!
03:13:45 <markw2> Where does cabal install put the package source files that you are building and install
03:14:09 <Peaker> markw2: ~/.cabal/packages/hackage.haskell.org
03:14:22 <dcoutts_> markw2: downloaded tarballs are cached under ~/.cabal/packages/$server/
03:14:46 <dcoutts_> unpacked sources are not installed anywhere
03:15:07 <dcoutts_> if you want to unpack one then you can run $ cabal unpack foobar
03:15:17 <markw2> Ah thats what I want; thanks
03:15:28 <dcoutts_> (it needs the latest version 0.6.2)
03:29:11 <billls> what does the \\ operator do ?
03:29:57 <dibblego> @type (\\)
03:29:58 <lambdabot> forall a. (Eq a) => [a] -> [a] -> [a]
03:30:09 <dibblego> > [1,2,3] \\ [2,3,4]
03:30:10 <lambdabot>   [1]
03:30:33 <dibblego> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-List.html#v%3A\\
03:32:10 <billls> so.. what exactly is that doing? sorry :/
03:32:15 <billls> oh
03:32:18 <billls> didn't see link
03:33:27 <billls> > [1,2,3,4] \\ [1,2,3,4]
03:33:29 <lambdabot>   []
03:33:37 <billls> um
03:34:05 <billls> any chance you could explain what it's doing dibblego?
03:34:12 <Alpounet> it keeps elements belonging to the first list only
03:34:28 <Alpounet> @src (\\)
03:34:28 <lambdabot> (\\) = foldl (flip delete)
03:35:11 <billls> gotcha
03:35:12 <billls> thank you
04:15:08 <boegel> hiya all!
04:15:18 <boegel> mmorrow: any updates? ;-)
04:16:21 <wjt> is Lennart Kolmodin here?
04:16:28 <mmorrow> boegel: no update, but i was thinking that one possible easy way to be sure to compute n times would be just to have both the hs and the C evalute it on each of [0..9]
04:17:08 <Vq^> wjt: his nick seems to be here
04:18:06 <wjt> oh yeah!
04:18:42 <wjt> kolmodin: hey. so daf and I (well, mostly daf) are writing a pure Haskell implementation of a  D-Bus client library. We've just noticed that according to ohloh, so have you :/
04:18:46 <wjt> kolmodin: how far have you got?
04:20:33 <wjt> kolmodin: heh. it seems "quite a long way" is the answer
04:22:59 <boegel> mmorrow: I'm not sure what you mean?
04:23:33 <boegel> mmorrow: the dist functions are of type Double -> Double -> Double, there's no Int parameter in there?
04:26:06 <mmorrow> boegel: oh, hrm. what is r <- mapM (\y -> return $! f y) (replicate n x) ?
04:26:40 <mmorrow> am i misunderstanding where we're talking about?
04:28:01 <mmorrow> boegel: also, now that i think of it, why are we trying to figure out how to have the haskell evaluate everything? :)
04:29:15 <mmorrow> boegel: ooh, just thought of some code that might give you ideas about how to force everything. the haskell "binary trees" entry in the "computer language benchmark shootout" (or whatever the name is)
04:29:31 <mmorrow> it has to force everything to get built artificially
04:35:19 <simon> where is the Haskell silly questions channel?
04:37:18 <osfameron> heh
04:38:13 <osfameron> simon: I'd guess you just ask here and see if people would prefer you to ask elsewhere?
04:38:14 <dibblego> #haskell ask away
04:39:02 <simon> what is the equivalent of 'as' from Standard ML? like, fun foo (x::(xs as _::_)) = ...
04:40:17 <simon> ah, never mind. I RTFM'ed.
04:40:38 <simon> I like this comment in a nearby channel topic: "Monologues permitted." :-)
04:42:41 <byorgey_> hehe
04:43:03 <byorgey_> simon: no questions are silly here, if they're asked in good faith =)
04:43:17 <Alpounet> where is <$> defined ?
04:43:23 <beelsebob> Control.Applicative
04:43:27 <Alpounet> thanks
04:44:05 <osfameron> simon: what was the answer? ;-) (I don't know ML)
04:45:56 <byorgey_> osfameron: @, I presume
04:46:01 <byorgey_> (I don't really know ML either)
04:46:25 <osfameron> ah, that would make sense, yeah
04:46:31 <boegel> mmorrow: the 'f' in the mapM is a partial application of the distance function, i.e. it only has the first vector given... I then replicate the 2nd vector n times, and use mapM to map the distance function to each of the n copies of the 2nd vector
04:46:33 * osfameron doesn't really know haskell either of course...
04:47:02 <boegel> mmorrow: the binary trees app is forcing the same evaluation of something n times? that would seem strange to me :)
04:47:18 <simon> osfameron, yes, @.
04:47:19 <boegel> mmorrow: this kind of thing would only be useful when benchmarking something...
04:49:44 <ahf> what a retarded quit message.
04:50:24 <billls> guys i've got a line of code that seems to be being missed, could anyone take a look? the 'repeats' clause works, but anything else skips straight down to the 'swears' part http://foxyurl.com/1Pl
04:50:30 <billls> it's at the very bottom of the code
04:50:56 <mmorrow> boegel: the bintree benchmark has to ensure that the entirety of the tree (or trees, i'm not sure) gets constructed
04:52:15 <boegel> mmorrow: hmmk, I'll look into it
04:53:07 <jelly12gen> @sort
04:53:07 <lambdabot> Maybe you meant: more part src
04:53:16 <Phyx-> Hello, i was wondering if there's anyway to create an instance of a class which expects *->* when you have a datatype which is (*->*)->*
04:53:16 <boegel> @type sort
04:53:17 <lambdabot> forall a. (Ord a) => [a] -> [a]
04:53:20 <boegel> @src sort
04:53:20 <lambdabot> sort = sortBy compare
04:53:27 <boegel> jelly12gen: ^ ?
04:53:38 <Leftblank> @type group
04:53:40 <lambdabot> forall a. (Eq a) => [a] -> [[a]]
04:53:43 <jelly12gen> boegel: just testing how the bot works
04:53:47 <boegel> jelly12gen: ah, k :)
04:53:58 <jelly12gen> but Leftblank could also do :t forall in ghci
04:54:09 <jelly12gen> or winhugs
04:54:13 <Leftblank> only if jelly12gen  wasn't distracting him
04:54:14 <Leftblank> :(
04:55:43 <yitz> Phyx-: sure, as long as none of the member functions have any problem with that.
04:55:55 <yitz> usually it's fine
04:56:03 <boegel> mmorrow: seems like they are using mapM_ and rnf
04:56:50 <mmorrow> boegel: ah, yeah rnf'd do it (as long as your datatype is an instance of NFData)
04:56:53 <Phyx-> yitz: well, i'm getting a kind error atm, since it's correctly saying the first argument was expected to be a *->* but was given a *
04:57:06 <boegel> mmorrow: [Double] is :)
04:57:09 <mmorrow> there's weird stuff going on in uvector though, with the fusion and all, so
04:57:10 <mmorrow> ahh
04:57:13 <mmorrow> nicde
04:57:17 <mmorrow> *nice
04:57:28 <boegel> mmorrow: one dist call just gives you a Double, so...
04:57:31 <saml> > [Int, Num a]
04:57:32 <lambdabot>   Not in scope: data constructor `Int'Not in scope: data constructor `Num'
04:57:55 <mmorrow> ah, true.. i had a skewed picture of what you were doing until right this moment :)
04:59:10 <yitz> Phyx-: I guess I'd have to see it.
05:01:44 <boegel> mmorrow: I'm just trying to figure out how long it takes to do one dist call
05:02:06 <boegel> mmorrow: but because the function is so small, I need to run it n times in order to get a long enough runtime to be meaningful
05:02:24 <billls> how do I need to change this, considering getResponsePhrase needs the input to have had words applied to it, but getResponse's output needs to be unworded
05:02:26 <billls> getResponse :: String -> String -> String
05:02:26 <billls> getResponse str str1 = words str str1 (getResponsePhrase str str1)
05:02:43 <boegel> mmorrow: if I could apply it easily to 2n different parameters, that would be fine too, but that would lead to a whole lot of GC'ing which would obfuscate the real working on dist
05:02:49 <boegel> s/on dist/of dist
05:03:27 <Phyx-> yitz: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4685#a4685
05:03:31 <PeakerWork> Phyx-: then probably the class  uses the type arg as a (*->*)?
05:04:22 <Phyx-> i have other instances already that are just *
05:04:43 <boegel> mmorrow: no difference with this: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4686
05:04:49 <Phyx-> so basically i'm asking if there's a workaround, or if it's just not possible
05:05:35 <yitz> Phyx-: the def'n of Kart forces the param of Bar to be a function - Bar a doesn't make sense unless a is a function
05:06:12 <mmorrow> boegel: ohhh. what about finding the distance between two massive vectors, and just doing it once?
05:06:32 <Phyx-> yitz: yeah, what i thought, but i though i'd ask, since everytime i think something's not possible, someone here proves me wrong
05:06:36 <Phyx-> lol
05:06:39 <yitz> heh
05:06:41 <mmorrow> boegel: like, say 100000000 elems long
05:07:07 <billls> anyone at all ? :( http://foxyurl.com/1Pw
05:08:17 <yitz> Phyx-: what you're doing probably *is* possible, but you'll have to write it so that the types are consistent. That's what gives Haskell its power.
05:08:49 <boegel> mmorrow: I'm doing that, that's what the 100k dimensionality is about
05:09:25 <boegel> mmorrow: but I also need to know how fast the function is to compute the distance between two 3D points, or two 10D points (which is the case I'll be using the function for)
05:09:34 <Phyx-> yitz: yeah, thanks for taking a look
05:10:15 <boegel> mmorrow: see http://users.elis.ugent.be/~kehoste/eucl_dist_v1_2009-05-07_10-07-06.pdf
05:10:27 <boegel> the X-axis show how big the vectors are
05:11:11 <PeakerWork> yitz: so is it broken because the compiler knows 'g' in Foo g a is either (*->*)->* or *->*   but not both?
05:11:39 <PeakerWork> yitz: Because "Foo g a" seems OK for an 'a' which is a function, and "Foo g (Bar a)" seems ok for a (Bar a) which is not a function
05:14:04 <quicksilver> mmorrow: very slowly. GHC code takes a while to grok and I've been tired the last couple of weeks.
05:14:28 <quicksilver> mmorrow: it lacks the instant gratification of spinning force-based layout algorithms :)
05:15:23 <frwmanners>  that's what the 100k dimensionality is about
05:15:23 <frwmanners> 12:09 < boegel> mmorrow: but I also need to know how fast the function is to compute the distance between two 3D points, or two 10D points (which is the case I'll be using the  function for)
05:15:31 <frwmanners> sorry
05:16:13 <boegel> frwmanners: computing a distance in a 100k-dim space doesn't tell me anything about a 3D-space though?
05:20:22 <yitz> PeakerWork: The constraint Foo g a means foo declares a as kind *, so Bar a makes no sense.
05:21:08 <PeakerWork> yitz: why does Foo g a mean a is kind *?
05:21:20 <PeakerWork> class Foo g a where foo :: g a -- can't "a" be any kind at all here?
05:21:20 <yitz> PeakerWork: look at the type of foo
05:21:26 <yitz> no
05:21:43 <PeakerWork> yitz: can't g be (anykindatall -> *) ?
05:21:52 <yitz> it can be a function, but as a type variable it has to be of kind *
05:22:11 <quicksilver> type variables don't have to have kind *.
05:22:12 <QtPlaty[HireMe]> yitz: Why is that?
05:22:22 <PeakerWork> @src MonadTrans
05:22:23 <lambdabot> Source not found.
05:22:26 <yitz> quicksilver: in this case?
05:22:26 <PeakerWork> @info MonadTrans
05:22:27 <lambdabot> MonadTrans
05:22:28 <quicksilver> but I think classes have to have a fixed kind.
05:22:45 <PeakerWork> quicksilver: and are assumed to be * unless otherwise mentioned?
05:23:06 <quicksilver> I'm not sure how the inference proceeds, technically.
05:23:40 <quicksilver> in a class declaration, unknown type variables at the end of kind inference get set to '*' ?
05:23:44 <quicksilver> would be my guess.
05:24:17 <marcusb> my first haskell programm (some type of insertion sort) http://pastebin.com/m76e820e5
05:24:18 <jelly12gen> @src first
05:24:18 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
05:24:26 <quicksilver> you infer the constraints (a :: k), (g :: k -> *)
05:24:38 <quicksilver> and then you just 'default' the unknown k to *, I suppose.
05:24:45 <voker57> how to compile a program, including certain .hs with modules? I'm getting 'undefined reference' errors if i just compile it in same directory
05:25:09 <quicksilver> ghc --make
05:25:10 <osfameron> dibblego: this is the question I was failing to explain a week or so ago (if you were interested) http://greenokapi.net/blog/2009/05/07/is-currying-monadic/
05:26:37 <jelly12gen> is there a reference with all things you can map
05:30:47 <boegel> mmorrow: great suggestion by beelsebob in #haskell-in-depth -> use trace to figure out the strictness enforcing, see http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4691
05:31:03 <simon> is this tail recursive? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4692#a4692
05:31:08 <boegel> mmorrow: it's printing as much as I expected, so each call to dist* _is_ being evaluated
05:31:42 <beelsebob> simon: no
05:31:59 <simon> beelsebob, alright, thanks.
05:32:00 <beelsebob> because you need to call compress to evaluate the if
05:32:12 <beelsebob> so it's not the last thing being evaluated
05:33:25 <mmorrow> boegel: this works decently (i think) http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4693
05:33:57 <mmorrow> the only question with that is how accurate getCPUTime is in timing each
05:34:02 <heltav> 4. forall A. false => A
05:34:11 <heltav> If you've studied logic, what, if anything, do you find suspicious about the proposition of question 4?
05:34:35 <heltav> http://www.eecs.harvard.edu/~govereau/cs252r/
05:34:45 <heltav> ^^ functional programming at harvard
05:35:42 <mmorrow> boegel: these are the times on my machine http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4694
05:36:40 <mmorrow> the C seems to take around 2/3 the time of the haskell
05:37:03 <boegel> mmorrow: getCurrentTime and diffUTCTime is what Microbench (and thus, me) is using
05:37:23 <mmorrow> oh nice
05:37:28 * mmorrow makes a note of that
05:38:00 <mmorrow> boegel: that code though with those substited in in "timeIt" should work well (i believe)
05:38:07 <mmorrow> *substituted
05:38:32 <PeakerWork> heltav: I haven't studied logic - but I'd guess you just can't know anything about A?  (False implies x) tells you nothing about x
05:38:38 <Alpounet> is Generative Programming used in Haskell ?
05:38:45 <boegel> strange that you're seeing C is faster than Haskell, even for large vectors
05:40:00 <boegel> mmorrow: why "_ <- return $! n" and not "n `seq` putStrLn" ?
05:40:01 <mmorrow> boegel: if i add another 0 on the size of the vectors my (4GB ram) laptop start swapping :/
05:40:13 <mmorrow> boegel: no reason in particular
05:40:15 <boegel> 10M-size vectors?
05:40:18 <boegel> now that's weird
05:40:23 <boegel> that's not _that_ big
05:40:46 <boegel> mmorrow: what kind of arch are you on? core2?
05:40:50 <mmorrow> (it never gets past the init step)
05:40:57 <mmorrow> yeah, core2 x86_64
05:41:07 <mmorrow> , length [0..10000000]
05:41:09 <lunabot>  10000001
05:41:15 <mmorrow> heh, duh
05:41:27 <mmorrow> , length [0..10000000] * 8 * 2
05:41:29 <lunabot>  160000016
05:41:37 <mmorrow> bytes for the Ptr CDoubles
05:41:51 <mmorrow> then + the UArr's (that i don't force til later though)
05:42:31 <boegel> mmorrow: why the zip unzip in init?
05:42:36 <mmorrow> ohh, and then the extra mem for the two haskell lists themselves
05:42:43 <yitz> > length [0..10000000] * 8 * 2 `div` (1024*1024)
05:42:45 <lambdabot>   152
05:42:46 <mmorrow> boegel: so they're the same length for when i pokeArray
05:43:03 <mmorrow> yeah, the unzip . zip might be doing it too
05:43:13 <boegel> mmorrow: and what's pokeArray?
05:43:32 <mmorrow> it writes each member of the list to the Ptr'ed to mem
05:43:42 <mmorrow> it's equiv to
05:44:16 <mmorrow> \xs -> forM_ (zip [0..] xs) (\(i,x) -> pokeElemOff ptr i x)
05:44:17 <boegel> k...
05:44:32 <boegel> still weird that your results are so different from mine...
05:44:36 <mmorrow> yeah
05:44:40 <mmorrow> what ghc are you on?
05:44:46 <mmorrow> i'm on 6.10.1
05:45:02 <Alpounet> can GHC optimize, e.g, zip . unzip ?
05:45:05 <mmorrow> (and i built the C with -O3 -fomit-frame-ptr, not that that probably matters any)
05:45:13 <Alpounet> (make it 'id')
05:45:37 <mmorrow> Alpounet: it's not id though, because it chops the longer list to the length of the shorter
05:46:01 <boegel> mmorrow: could you try http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4695 on your machine?
05:46:07 <mmorrow> sure
05:46:19 <Alpounet> mmorrow, oh, yeah, right
05:46:32 <boegel> mmorrow: I'm trying to figure out why my C version is so slow compared to yours...
05:46:50 <boegel> mmorrow: well, you're using FFI, but still, that can't make the C version faster :)
05:46:54 <heltav> what should a makefile be called?
05:48:17 <mmorrow> boegel: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4696
05:48:34 <mmorrow> $ gcc -O3 -fomit-frame-pointer -lm boegel.c
05:48:50 <Alpounet> mmorrow, and what about fst &&& snd $ (1,2) ?
05:48:55 <mmorrow> (no reason why i always use -fomit-frame-pointer... just a habit ;)
05:49:06 <mmorrow> Alpounet: that's id
05:49:11 <Alpounet> yeah
05:49:15 <Alpounet> but does GHC guess it ?
05:49:25 <mmorrow> Alpounet: i'm not sure
05:49:41 <mmorrow> Alpounet: that would need a rewrite rule i'd think to get optimized away
05:51:20 <Alpounet> ok
05:52:04 <vixey> don't write  fst &&& snd  though
05:52:05 <heltav> shold a makefile just be called make? no suffix?
05:52:09 <heltav> isnt make a command?
05:52:23 <mmorrow> {-# RULES "fst&&&snd/id"     fst &&& snd = id #-}
05:52:24 <heltav> > fst &&& snd (1,2)
05:52:25 <lambdabot>       Overlapping instances for Show ((a, b) -> (a, c'))
05:52:25 <lambdabot>        arising from ...
05:52:27 <simon> a Makefile should be called Makefile, and make is the command that invokes it.
05:52:29 <heltav> > fst &&& snd $ (1,2)
05:52:30 <lambdabot>   (1,2)
05:52:40 <mmorrow> > snd && fst $ (1,2)
05:52:42 <lambdabot>   Couldn't match expected type `Bool'
05:52:44 <mmorrow> > snd &&& fst $ (1,2)
05:52:44 <vixey> nobody writes  fst&&&snd though
05:52:45 <lambdabot>   (2,1)
05:52:46 <heltav> > fst &&& 1+ . snd $ (1,2)
05:52:47 <lambdabot>   <no location info>: parse error on input `.'
05:52:57 <heltav> > fst &&& ((+1) . snd) $ (1,2)
05:52:57 <mmorrow> > uncurry (flip (,)) (1,2)
05:52:58 <lambdabot>   (1,3)
05:52:59 <lambdabot>   (2,1)
05:53:09 <vixey> if you have got say   fst &&& foo  where foo is sometimes  snd  that never gets optimized does it?
05:53:38 <fasta> Is it possible to create NaN with only the multiplication operator and no NaN inputs to begin with? I was pretty sure that was impossible, but I looking at a result which is supposed to be implemented only with multiplications.
05:53:40 <mmorrow> vixey: it would if you wrote the rule:
05:53:42 <mmorrow> {-# RULES "fst&&&snd/id"     fst &&& snd = id #-}
05:53:51 <quicksilver> unless it gets inlined, vixey
05:54:00 <quicksilver> then the static analyser can "see" the foo is snd
05:54:14 <quicksilver> but if it's "too dynamic" and foo crosses a module boundary, for example
05:54:17 <boegel> mmorrow: that's just 2 runs?
05:54:17 <quicksilver> then the RULE won't fire.
05:54:19 <vixey> mmorrow: I think rules only happen at compile time
05:54:35 <doserj> fasta: 0*Infinity=NaN
05:54:47 <mmorrow> boegel: err, i think so (?)
05:54:49 <boegel> mmorrow: oh, wait, that's 10M and 100M
05:54:56 <mmorrow> boegel: ahh, yeah
05:54:57 <PeakerWork> {-# RULES "fst&&&/first"    (fst &&&) = second #-}
05:55:00 <fasta> doserj: and if there are no Infinities in the input?
05:55:20 <doserj> fasta: 10*10*10*.... eventually becomes Infinity
05:55:33 <fasta> doserj: ah, that must be it.
05:55:38 <lukeo05> So, loop takes an argument of type Table. load returns type IO Table, so I put these two together with 'loop =<< load'. This is good. Now, addToHistory takes arguments of type Table and History, but using 'addToHistory =<< load history' doesn't work. How can I pass multiple arguments with this Monad thing confusing everything I do?!
05:55:45 <mmorrow> @type (fst &&&)
05:55:46 <lambdabot> forall a b c'. ((a, b) -> c') -> (a, b) -> (a, c')
05:55:49 <mmorrow> @type (second
05:55:50 <lambdabot> parse error (possibly incorrect indentation)
05:55:51 <mmorrow> @type second
05:55:52 <lambdabot> forall (a :: * -> * -> *) b c d. (Arrow a) => a b c -> a (d, b) (d, c)
05:55:59 <fasta> doserj: I am using the maximum Double value there is and then do something with it. So, that is the bug.
05:56:09 <mmorrow> @type [(fst &&&), second]
05:56:10 <lambdabot>     Occurs check: cannot construct the infinite type: b = (a, b)
05:56:10 <lambdabot>       Expected type: ((a, b) -> c') -> (a, b) -> (a, c')
05:56:10 <lambdabot>       Inferred type: ((a, b) -> c') -> (a, (a, b)) -> (a, c')
05:56:26 <boegel> wait, so, the C version takes 350,000 microseconds @ 10M, but using FFI in Haskell @ 1M only takes 3500 microseconds??
05:56:31 <mmorrow> @type [(fst ***), second]
05:56:32 <lambdabot>     Occurs check: cannot construct the infinite type: a = (a, b)
05:56:32 <lambdabot>       Expected type: (b' -> c') -> ((a, b), b') -> (a, c')
05:56:32 <lambdabot>       Inferred type: (b' -> c') -> ((a, b), b') -> ((a, b), c')
05:56:48 <mmorrow> boegel: hmmm, weird
05:56:58 <boegel> mmorrow: something is wrong there :P
05:56:59 <mmorrow> boegel: i think getCPUTime might be to blame here
05:57:30 <boegel> mmorrow: yeah... could you retry the Haskell version with getCurrentTime? and diffUTCTime?
05:57:44 <mmorrow> boegel: ohh, and the haskell code isn't counting allocation and vector creation time (which is non-trivial)
05:58:32 <boegel> mmorrow: well, yeah, but it's strange that's there a factor 100 difference between Haskell 1M and C 100M :)
05:58:37 <boegel> err
05:58:38 <boegel> C 10M
05:58:53 <boegel> mmorrow: in C, is pretty trivial :P
05:59:05 <boegel> malloc 10M sizeof(Double), fill it with junk, compute dist
05:59:07 <boegel> ;-)
05:59:38 <mmorrow> boegel: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4697
06:00:23 <mmorrow> boegel: ah true, the excessive time for initStuff in that code must be from having to compute the entire haskell list
06:00:31 <mmorrow> *listS
06:00:48 <mmorrow> (in order to pokeArray)
06:01:27 <LeCamarade> I'm totally proud of my lambdacat here. http://arcanux.org/lambdacats.html The one of Gentle Introduction. :o)
06:03:30 <geemike> @src fix
06:03:30 <lambdabot> fix f = let x = f x in x
06:04:08 <boegel> mmorrow: still, the numbers you're showing now show an inconsistency between the C app and the Haskell app using FFI
06:04:22 <geemike> is there a function similar to f that has a limit?
06:04:27 <geemike> similar to fix
06:04:35 <boegel> C app with 10M was 350k microseconds, thus 0.35s, while the Haskell FFI one shows 0.003s for 1M ?
06:04:46 * boegel scratches his head
06:04:59 <geemike> f_0 . f_1 . ... . f_n
06:05:03 <boegel> I must be missing something here
06:05:08 <quicksilver> geemike: iterate
06:06:27 <geemike> quicksilver: ah, ok
06:06:46 <geemike> so can i say that first limit ordinal is fix S (where S is successor function)?
06:06:53 <geemike> that is model it as
06:08:19 <heltav> isnt make a command?
06:08:26 <heltav> if i have a file make
06:08:32 <heltav> how do I run it?
06:08:37 <simon> heltav, you must have a file Makefile and the command is make.
06:09:54 <heltav> makefile:2: *** missing separator.  Stop.
06:10:08 <vixey> geemike: yes
06:10:37 <vixey> geemike: they have this in lambdabot right now called 'infinity'
06:10:39 <vixey> e.g.
06:10:45 <geemike> :t infinity
06:10:46 <lambdabot> Natural
06:10:46 <vixey> > genericLength [1..100] < infinity
06:10:48 <lambdabot>   True
06:10:57 <geemike> @src infinity
06:10:58 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
06:10:59 <vixey> > genericLength [1..] > (200::Natural)
06:11:01 <lambdabot>   True
06:11:03 <vixey> infinity = fix S
06:11:07 <geemike> ahhhhh
06:11:16 <geemike> okay
06:11:56 <mmorrow> boegel: hmmm. the only thing i can think of is that the haskell diffUTCTime is not in microseconds
06:12:57 <simon> I think this one is tail recursive, but is there a trick to avoid the list ending up backwards while preserving tail recursion? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4699#a4699
06:13:32 <mmorrow> boegel: re NominalDiffTime:
06:13:34 <mmorrow> It has a precision of 10^-12 s
06:16:24 <vixey> simon: forget tail recursion
06:17:14 <mmorrow> (according to the haddocks)
06:17:19 <vixey> simon: like this  compress [] = [] ; compress [x] = [x] ; compress (x:y:zs) | x == y = compress (x:zs) | otherwise = x : compress (y:zs)
06:17:44 <vixey> simon: try my and your version for example on the infinite list  map (`div`2) [1..]
06:19:04 <voker57> how to build a list by running some IO n times?
06:20:16 <quicksilver> voker57: replicateM
06:20:30 <mmorrow> vixey: tail recursive still applies when a thunk actually gets *evaluated* and it producing any result at all depends on the entirety of the structure to be evaluated
06:20:42 <heltav> how do I force a printf statement in a FFI call? now it just gets ignored
06:21:21 <heltav> and can I pass a: struct name *n; via haskell into a C-function and get the result back?
06:21:40 <mmorrow> heltav: read the FFI manual :)
06:22:10 <mmorrow> heltav: http://www.cse.unsw.edu.au/~chak/haskell/ffi/
06:22:24 <mmorrow> (the answer to your second question is yes)
06:29:43 <simon> vixey, thanks for pointing me in the right direction.
06:29:46 <lukeo05> How commonly is haskell being used in real situations at the moment...?
06:30:29 <simon> lukeo05, far enough for there to have been published a book called Real World Haskell.
06:32:43 <lukeo05> But is it actually used in real world? Real World Haskell sounds like a (no doubt very good) attempt at showing that it CAN be used... But are there jobs out there and areas where it is being used?
06:33:18 <quicksilver> @go haskellwiki haskell in industry
06:33:20 <lambdabot> http://www.haskell.org/haskellwiki/Haskell_in_industry
06:33:20 <lambdabot> Title: Haskell in industry - HaskellWiki
06:33:30 <boegel> mmorrow: I'm trying to add the FFI c_dist to my tool as well, to see if the timings match the c timings on my end
06:33:38 <geemike> :t infinity
06:33:39 <lambdabot> Natural
06:33:47 <geemike> > infinity * infinity
06:33:50 <lambdabot>   * Exception: stack overflow
06:33:57 <geemike> :)
06:34:01 <vixey> it takes forever to find out if the result is zero or not
06:34:09 <quicksilver> lukeo05: yes, although not that much perhaps.
06:36:32 <lukeo05> quicksilver: ah that link looks interesting, thanks. apparently my CS course is one of the most haskell oriented in england (though I haven't done any others so I can't compare). Do you think that is good... The lecturer keeps saying functional programming is where industry is heading to in the next decade
06:37:14 <p_l> lukeo05: where you are?
06:37:36 <lukeo05> nottingham
06:38:11 <fasta> lukeo05: that's just where the lecturer wants industry to go ;)
06:38:16 <ivanm> lukeo05: I thought that if you were in this channel, it was a given that industry is heading towards functional programming...
06:38:31 <ivanm> unless of course you're an anti-functional troll...
06:38:58 <flux> ivanm, impossible to like functional programming unless you think that's where the industry is going?-)
06:39:32 <ivanm> flux: unless you want to keep it as our private little members-only secret club...
06:39:35 <lukeo05> ivanm: haha no, I'm not trolling! It seems rather cool to me everything, but it is taking me a while to get my head round it.
06:39:36 <quicksilver> lukeo05: nottingham is a hotbed of functional programming :)
06:39:51 <quicksilver> lukeo05: the industry is certainly moving toward ideas which have come from functional programming
06:39:52 <fasta> lukeo05: Functional programming and imperative programming are exactly the same, it is just that you use less general mechanisms in functional programming to reduce the state-space of your program.
06:40:07 <quicksilver> that doesn't meant haskell is going to replace C#
06:40:12 <quicksilver> tomorrow or next year :)
06:40:33 <ivanm> quicksilver: isn't it now two years, four months and seven days when C# gets replaced?
06:40:34 <ivanm> ;-)
06:40:43 <mgsloan> I hope to god that the industry is going this way ;)
06:40:46 <geemike> C# has already been replaced
06:40:54 <ivanm> geemike: by what?
06:41:11 <boegel> mmorrow: seems like something is wrong with my isolated C-app
06:41:22 <boegel> mmorrow: timings are way off compared to the Haskell version
06:41:23 <ivanm> boegel: you mean apart from the language? :p
06:41:33 <lukeo05> quicksilver: the haskell in industry link you sent me, took me to a job listing for functional programming lecturer at notts, ha :)
06:41:56 <boegel> ivanm: :)
06:41:59 <p_l> C# is at 3rd or 4th iteration, already. Much nicer language than Java, IMHO
06:42:01 <flux> ivanm, wanting something and believing something are two different things ;)
06:42:11 <boegel> ivanm: I think it just shows that is easier to create a buggy program in C :P
06:42:30 <ivanm> boegel: I CAN HAZ SEGFAULT? KTHX BYE
06:42:35 <geemike> ivanm: haskell
06:42:58 <ivanm> geemike: if it's been replaced, then why do more people use C# than Haskell?
06:43:14 <ivanm> also, typically when you replace something, you use something newer than the thing you're replacing...
06:43:28 <QtPlaty[HireMe]> ivanm: Not necceraly
06:43:41 <boegel> mmorrow: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4701
06:44:03 <boegel> Haskell's FFI is making C code ~10x faster!!
06:44:09 <boegel> or, something is wrong with my C tool
06:44:18 <heltav> haskell is magic!
06:44:21 <fasta> boegel: what do you think it is?
06:44:29 <boegel> fasta: :)
06:44:31 <QtPlaty[HireMe]> If anything F# is C#'s functional replacement.
06:44:50 <billls> how do i apply words to two variables and then call a function with them?
06:44:56 <billls> getResponse str str1 = words str str1 (getResponsePhrase str str1)
06:45:02 <billls> I know that doesn't work, but gives you the idea
06:45:02 <geemike> ivanm: C# will never replace haskell
06:45:05 <Zao> Apply it to both.
06:45:13 <heltav> .net is a VM right?
06:45:21 <geemike> what nevermind
06:45:29 <geemike> ivanm: my joke is going nowhere
06:45:33 <QtPlaty[HireMe]> heltav: CLR is .net's VM.
06:45:33 <billls> Zao: (words str str1)?
06:45:41 <Zao> heltav: The CLR is the runtime, .NET is a fancy name for the library.
06:45:48 <Zao> billls: (foo bar) (foo baz)
06:46:14 <QtPlaty[HireMe]> C# and haskell arn't even in compeating niches.
06:46:16 <Zao> (foo bar baz) associates to ((foo bar) baz)
06:46:36 * boegel solves the silly bug is his C tool and decides to never speak of it again
06:46:37 <billls> ok
06:46:40 <Zao> Which would be quite sane if (foo bar) returned a function.
06:47:13 <fasta> boegel: was it speed_haskell * = 10; ?
06:47:24 <fasta> boegel: er make that 100
06:47:36 * QtPlaty[HireMe] recalled optimizing something to be increably fast, then finding that it did so by not workin correctly.
06:48:06 <boegel> fasta: no, but it damn close to that :)
06:48:59 <boegel> fasta: if you really want to know... I was using 10e6 instead of 1e6 as denominator when computing time per call in the C-only tool
06:49:00 <simon> QtPlaty[HireMe], return 0; is incredibly fast.
06:49:19 * boegel smacks his head into a wall
06:49:28 <boegel> ok, but this means Haskell is pretty slow compared to C
06:49:31 <QtPlaty[HireMe]> simon: It was almost doing that.
06:49:43 <fasta> boegel: that is because it does more work.
06:49:54 <boegel> and, that mmorrow will be pissed at me for making him wonder how I made Haskell 3x faster than C
06:50:11 <boegel> fasta: no, it does the exact same thing, i.e. compute the Euclidean distance
06:50:14 <QtPlaty[HireMe]> boegel: Everything is slow compared to C.  The only thing faster is hand crafted ASM.
06:50:24 <daf> not actually true
06:50:28 <boegel> fasta: I'm only timing the function calls itself, not the time of the entire Haskell app
06:50:37 <fasta> boegel: yes, but it still does more work, because it computes it differently.
06:50:58 <fasta> boegel: that is because the compiler is not smart enough to see that the extra work it does is actually redundant.
06:51:09 <boegel> fasta: well, then, I want it to compute as fast as possible, hopefully getting close to the C speed
06:51:21 <boegel> fasta: have you seen the implementation I'm using?
06:51:23 <fasta> boegel: all high-level languages have this
06:51:35 <fasta> boegel: I peaked at it for a a few seconds.
06:51:38 <boegel> fasta: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677 (see dist_fast)
06:51:40 <fasta> peeked*
06:51:47 <boegel> fasta: there's not much redundant work in there, I think
06:52:08 <boegel> fasta: but I agree, it's more high-level, and thus means slower for some low-level stuff
06:52:21 <boegel> fasta: question is, how do I squeeze every last bit out of it
06:52:33 <boegel> fasta: while still using Haskell, that is :)
06:52:37 <fasta> boegel: why is it so important?
06:53:41 <boegel> fasta: well, because I'm implementing a tool which depends on dist greatly, i.e. computes a huge amount of distances
06:53:56 <boegel> fasta: I had an initial version in C, but it quickly became a nightmare to maintain
06:54:25 <boegel> fasta: I hope it'll be better in Haskell, and I'm trying to avoid sacrificing a huge amount of performance by heavily tuning the bottleneck function, i.e. dist
06:54:34 <fasta> boegel: did you try the ST monad?
06:55:48 <boegel> fasta: no, should I?
06:56:00 <boegel> fasta: what does it do that might help me?
06:57:20 <fasta> boegel: well, to begin with it doesn't create a persistent data structure.
06:57:49 <fasta> boegel: single-threaded data structures are always faster than persistent ones if only one thread is being used.
06:59:01 <boegel> fasta: ok... what's the exact definition of persistent here?
06:59:49 <fasta> boegel: not the meaning as used in storing stuff on your harddisk.
07:00:12 <boegel> fasta: what does it mean then?
07:00:40 <fasta> boegel: if you check google and find 2 other definitions, you can ask again. AFAIK, there is only one other.
07:07:39 <noob123> hi folks. i have a question about profiling in GHC
07:08:05 <noob123> anyone familiar?
07:08:25 <boegel> noob123: ask away
07:09:17 <noob123> ok, first i dont know what CAF means
07:09:42 <boegel> neither do I (exactly)
07:09:50 <boegel> but someone in here might...
07:10:05 <tromp> constant applicative form
07:10:29 <tromp> a top level constant (0 arg function)
07:11:01 <boegel> noob123: besically a value that only needs to be evaluated once throughout the program, it's value will never change
07:11:12 <boegel> noob123: see Real World Haskell, i.e. http://book.realworldhaskell.org/read/profiling-and-optimization.html
07:13:12 <sayyestolife> I'm not sure which channel I should asked this in (but I know there is a whole lot of enlightened people here), but here goes. I'm trying to do a very basic compiler (I know a bit about the front-end stuff), but I'd like to understand more about the backend side of stuff, like for example how do I actually create an executable (in linux for example)?
07:14:46 <sayyestolife> Anyone has some good resources on this?
07:14:58 <noob123> i read this one... http://www.haskell.org/ghc/docs/latest/html/users_guide/profiling.html my problem is that i don't get timings for all the functions in the program. only 4 are displayed
07:15:07 <noob123> sayyes search: ghc
07:15:23 <pejo> sayyestolife, either you output assembler from your compiler and run it through 'as', or output some other language and run it through a compiler for that language.
07:15:51 <wh1t3> or you compile to some sort of bytecode
07:15:53 <noob123> [and these 4 things are Main GHC.handle (?) GHC.Conc (?) and Control.Monad.State.Lazy]
07:16:03 <sayyestolife> pejo ah, thanks
07:16:04 <wh1t3> altho that is pretty similar to compiling to an intermediate language
07:19:18 <heltav> can you make a function: toInt :: CInt -> Int ?
07:20:11 <noob123> " When you say       -auto-all to the compiler, it automatically       inserts a cost centre annotation around every top-level function       in your program" that is what i did, but how do they define "top-level function" ?
07:21:02 <fasta> noob123: they don't, the Haskell 98 language report does that for them.
07:21:19 <noob123> okay, how is it defined?
07:22:11 <roconnor> a function that occurs directly inside the module block?
07:22:30 <noob123> you can have a look at the program i talk about: http://homepages.cwi.nl/~tromp/go/SimpleGo.hs .... the only thing i deleted is "module Go where" to make it an executable instead of library
07:23:02 <roconnor> noob123: executables should be cold module Main where
07:23:04 <roconnor> called
07:23:28 <noob123> okay, perhas that is the mistake, i am trying
07:24:11 <noob123> great, it works. thank you
07:24:15 <tromp> that program is not meant to be the least bit efficient
07:24:37 <noob123> yes, i just want to understand it with my little haskell knowledge
07:25:37 * edwardk waves hello.
07:26:27 <fasta> tromp: that is a very readable program.
07:29:31 <roconnor> [['A'..]!!(x -1)]
07:29:33 <roconnor> wow
07:29:59 <saml> >  [['A'..]!!(x -1)]
07:30:00 <lambdabot>   Couldn't match expected type `Int' against inferred type `Expr'
07:30:15 <saml> >  [['A'..]!!7]
07:30:17 <lambdabot>   "H"
07:30:32 <saml> >  [['ㅁ'..]!!7]
07:30:34 <lambdabot>   "\12616"
07:30:46 <saml> >  [['0'..]!!7]
07:30:47 <lambdabot>   "7"
07:31:03 <saml> ghci doesn't let you enter unicode characters?
07:31:52 <tromp> thx, fasta
07:32:33 <fasta> tromp: your binary lambda interpreter stuff is also quite interesting. Not directly applicable, but a nice demonstration.
07:32:38 <saml> maybe it's my urxvt setting  hrmz
07:33:20 <tromp> it's a tool for studying AIT
07:33:28 <fasta> tromp: yes, I am a fan ;)
07:34:15 <noob123> is it the data structure which makes the program so slow?
07:34:43 <tromp> representing positions as functions is
07:34:57 * byorgey waves hello back to edwardk 
07:35:07 <tromp> shld really be a an array
07:35:46 <noob123> how can i access an array in haskell effectively? by using "!!" operator?
07:35:55 <Zao> By array, do you mean list?
07:35:55 <tromp> within ST monad
07:36:34 <tromp> STUArray and friends
07:37:15 <O1athe> Does anyone know how to get ghc in my home directory on OS X without an admin account ?  I can't build the source since I don't have ld.
07:37:35 <byorgey> noob123: lists in Haskell (things of type [a] for some a) are singly-linked lists.  !! is for indexing into lists, it is O(n).
07:37:50 <byorgey> noob123: if you want a random-access array, you have to use an array library
07:38:08 <quicksilver> O1athe: non-admin OSX accounts can build GHC, but they do need the dev tools to be installed on the machine.
07:38:15 <O1athe> Ahh
07:38:21 <quicksilver> O1athe: otherwise you'll have to install a binary
07:38:43 <O1athe> Are there any binaries that don't require installing things to /opt ?
07:39:00 <fasta> tromp: http://www.maths.bris.ac.uk/~maadb/research/seminars/online/fgfut/ is a dead link on your website: http://homepages.cwi.nl/~tromp/pearls.html
07:39:09 <marcot> Good morning.
07:39:17 <marcot> http://www.haskell.org/alex/doc/html/charsets.html
07:39:36 <klugez> w?
07:39:36 <klugez> 17:34 -!- byorgey_ is now known as byorgey
07:39:36 <klugez> 17:34 < tromp> representing positions as functions is
07:39:45 <heltav> topologists have a lot of fun huh?
07:39:48 <klugez> Oops, sorry.
07:39:48 <heltav> klein bottle
07:39:52 <marcot> Is the set definition right?  Shouldn't it be something as set := set0 | set ['#' set0]
07:39:55 <quicksilver> O1athe: not that I know of.
07:40:02 <heltav> klein bagel
07:40:25 <tromp> ok, i'll fix it, fasta
07:40:32 <O1athe> Alright
07:41:15 <byorgey> marcot: yeah, that seems infinitely recursive, doesn't it?
07:41:28 <marcot> byorgey: It seems to me.
07:43:30 <quicksilver> O1athe: arguably there should be.
07:43:42 <quicksilver> O1athe: in practice, OSX users seem to have admin permissions so it's not been a big deal.
07:44:36 <marcot> byorgey: It's corrected in darcs.
07:44:46 <byorgey> marcot: ah, ok.
07:45:41 <quicksilver> it's a co-grammar!
07:45:42 <quicksilver> ;)
07:48:16 <byorgey> quicksilver: hehe =)
07:53:40 <MiniCow> Is it possible to attach a where clause to a lambda expression? I can't seem to get the scoping I want.
07:53:54 <dcoutts_> no but you can use let
07:54:13 <MiniCow> Ah ok, I'll just have to turn it on it's head ;-)
07:54:34 <dcoutts_> the distinction is that where is attached to a declaration
07:54:40 <dcoutts_> let and lambda are expressions
07:54:42 <quicksilver> MiniCow: where attaches to definitions. let to expressions.
07:55:23 <MiniCow> Ok, I'll try to remember that
07:55:58 <ibid> if you absolutelu must have a where, you can use a dummy case: \x -> case x of _ -> ... where ...
07:56:28 <ibid> or even case () of _ - ... where ...
07:56:55 <MiniCow> No. I just like where because then it reads like a mathematical definition
07:57:39 <ibid> MiniCow: let does, too :)
07:59:28 <MiniCow> I guess. 'Let' just feels imperative to me, and 'where' functional. I know that's not true....
08:02:40 <EvilTerran> "let" tends to separate things that you'd expect to go together, i find
08:03:32 <EvilTerran> say, in "fix f = x where x = f x", the "fix f = x" is one equation, and the "x = f x" another; "fix f = let x = f x in x" doesn't read linearly in the same way
08:04:42 <MiniCow> Ahh, that didn't get me what I wanted either. Anybody suggest how to write this? Look at the 'where' version. http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=2358#a2359
08:05:03 <MiniCow> The problem is d is not in scope because the where attaches to the definition
08:06:39 <quicksilver> yes, you have characterised the problem :P
08:06:57 <quicksilver> you could do
08:07:08 <doserj> MiniCow: closedCircuit diluent topup setPoint d = GasMix o2 n2 he where ...
08:07:16 <quicksilver> doserj: no.
08:07:20 <quicksilver> doserj: he's sharing deliberately
08:07:25 <quicksilver> to prevent recalculation
08:07:26 <quicksilver> I presume?
08:07:31 <MiniCow> Indeed
08:07:39 <quicksilver> you could have
08:08:03 <quicksilver> put the \d -> before the let
08:08:20 <quicksilver> closedCircuit diluent topup setPoint = \d -> <newline> let o2 =....
08:08:21 <MiniCow> Yep, that would work.
08:08:28 <MiniCow> I'll play
08:08:29 <quicksilver> then the d is in scope in mixRatio
08:09:10 <EvilTerran> why not "closedCircuit diluent topup setPoint d = ..." ?
08:09:36 <MiniCow> because I have other functions which return lambdas of the same type
08:09:51 <MiniCow> The results of each of them can be used in the same place
08:10:18 <quicksilver> what I said also loses sharing
08:10:22 <quicksilver> I'm not being very bright here :P
08:10:33 <MiniCow> Partly it's to make what I'm doing obvious
08:11:20 <MiniCow> Hmm, other problems now... but I think I'm on my way. Ta
08:20:14 * dolio double curries all his functions.
08:22:15 <edwardk> dolio: good to know
08:22:37 <edwardk> :t curry . curry
08:22:38 <lambdabot> forall a b b1 c. (((a, b), b1) -> c) -> a -> b -> b1 -> c
08:23:09 <dolio> I was reading osfameron's blog on 'is currying monadic'.
08:23:24 <edwardk> ah, didn't see it yet
08:23:34 <Ferdirand> hi all
08:25:23 <edwardk> ah, yeah so basically he has an indexed state monad with the argument stack
08:27:23 <dolio> Yeah, I guess that view makes sense.
08:27:33 <mmorrow> quicksilver: how are prospects for sse on x86 looking?
08:27:47 <quicksilver> mmorrow: I answered you before. You need to turn up your hearing aid :P
08:28:02 <dolio> Get off mmorrow's lawn!
08:28:12 <mmorrow> quicksilver: back in my day we just tried harder to hear!
08:28:21 <quicksilver> 13:14 < quicksilver> mmorrow: very slowly. GHC code takes a while to grok and  I've been tired the last couple of weeks.
08:28:24 <quicksilver> 13:14 < quicksilver> mmorrow: it lacks the instant gratification of spinning  force-based layout algorithms :)
08:28:27 <mmorrow> quicksilver: :)
08:28:57 <quicksilver> I note today that AMD have announced they will support AVX
08:29:03 <edwardk> mmorrow, quicksilver: using sse how?
08:29:05 <quicksilver> (256-bit vector instructions)
08:29:06 <mmorrow> quicksilver: yeah, it does take a while to grok... foreach part too
08:29:07 <edwardk> quicksilver: yeah
08:29:15 <quicksilver> edwardk: using it at all.
08:29:23 <edwardk> quicksilver: from ghc?
08:29:23 <osfameron> ah, "indexed monad" is what Ganesh mentioned in comments for that too.  I was hoping it would all magically Just Work without additional plumbing :-)
08:29:26 <quicksilver> edwardk: the i386 codegen doesn't generate any SSE code.
08:29:28 <quicksilver> edwardk: yes.
08:29:44 <edwardk> tricky for it do to with the silly ghc alignment of 4 or 8 bytes on everything
08:29:53 <quicksilver> edwardk: (a) using it for FP code will save registers at least
08:29:55 <mmorrow> quicksilver: i have minimal useful grokkage for ghci/*, main/*, and 50% minimal grokkage for cmm/*
08:30:03 <edwardk> yeah
08:30:08 <quicksilver> edwardk: (b) then maybe propagate some actual vector types through the machops
08:30:15 <quicksilver> so you can produce vectors directly
08:30:29 <quicksilver> and then (c) maybe experiment with RULES to vectorise some simple cases automatically.
08:30:39 <sbahra> <edwardk> tricky for it do to with the silly ghc alignment of 4 or 8 bytes on everything
08:30:43 <Lemmih> mmorrow: Where did you learn the word 'grok', OOI?
08:30:53 <sbahra> You mean ghc aligns everything to 4 or 8 bytes, why is this a problem edwardk?
08:31:04 <mmorrow> Lemmih: i don't recall exactly, but i usually take words and run with them ;)
08:31:22 <dolio> osfameron: Even with indexed state, you still only get something like an isomorphic result.
08:31:23 <quicksilver> sbahra: efficient SSE code requires 8 or 16 byte aligned data.
08:31:29 <edwardk> sbahra: well, if i want to load a full sse reg its nice to know the alignment mod 16 =)
08:31:32 <Zao> I learnt it when reading through the Jargon file, front to back. :)
08:31:37 <mmorrow> i thought is was 16 exactly?
08:31:40 <mmorrow> it
08:31:50 <edwardk> mmorrow: you can load a half reg off an 8 byte alignment
08:31:52 <mmorrow> oh, maybe that's just for doubles
08:31:56 <mmorrow> ah
08:32:02 <dolio> osfameron: IState (a,(b,(c,()))) () d = (a,(b,(c,()))) -> ((),d) ~ (a,b,c) -> d.
08:32:14 <quicksilver> edwardk: but even using the regs at all will help
08:32:18 <dolio> Not quite isomorphic due to bottoms.
08:32:24 <edwardk> quicksilver: sure
08:32:24 <osfameron> isomorphic?
08:32:38 <quicksilver> edwardk: the x87 codegen generates a thousand stack instructions per real floating point instruction :)
08:32:41 <sbahra> mmorrow, it is 16.
08:32:44 <roconnor> @quote anal
08:32:44 <lambdabot> ghc says: CPR Analysis tried to take the lub of a function and a tuple
08:32:44 <sbahra> edwardk, sure.
08:33:02 <sbahra> But I'm not sure why alignment can't be changed easily from 4 to 8 to 8 to 16.
08:33:04 <quicksilver> edwardk: ...but it would be easier to grab the SSE2 stuff out of x86_64 than do something sensible for x87
08:33:32 <edwardk> quicksilver: i put together a cheesy little unboxed list like test a while back using cons cells that held 3 simd slots with an optional usage count for dealing with head and tail cells and it was a speedy little test
08:33:49 <quicksilver> that sounds cute.
08:33:52 <quicksilver> where did you put it?
08:34:31 <edwardk> quicksilver: it was a quick c hack to benchmark if doing tiny unboxed lists like that would be viable in a functional language i wrote it as a throwaway a couple years ago
08:34:48 <edwardk> i concluded that fusion was better when it worked ;)
08:34:56 <dolio> osfameron: Conceptually, having an ((),d) is the same as having a d, since you could establish a one-to-one mapping between the values of the two. Except you can't atually in Haskell, because ((),d) has extra elements involving bottoms.
08:35:05 <mmorrow> @tell boegel gah, i didn't see you /msg until right this moment :/
08:35:05 <lambdabot> Consider it noted.
08:35:39 <quicksilver> edwardk: ah, fair enough.
08:35:42 <edwardk> and that i'd do better off focusing on superword level parallelism than magic unboxed constructor types.. funny how thats come full circle ;)
08:35:54 <osfameron> dolio: sorry, I don't understand at all :-)  I'll read up on IState though, I don't know anything about it now.
08:36:05 <mmorrow> quicksilver: you might find this interesting http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4677#a4683
08:36:14 <comex>     `[]' is not applied to enough type arguments
08:36:14 <comex>     Expected kind `??', but `[]' has kind `* -> *'
08:36:21 <comex> what a great error message :D
08:36:21 <mmorrow> quicksilver: it's a side-by-side gcc/ghc for euclidean distance asm
08:36:31 <edwardk> osfameron: undefined is different than (undefined,undefined) is all he means by 'the extra bottom'
08:36:35 <mmorrow> quicksilver: (dunno if you were around earlier for this)
08:36:37 <dolio> osfameron: IState just lets you change the state type as you go through the computation. The two parameters tell you what the current state type is.
08:36:43 <sbahra> edwardk, where is this code?
08:37:01 <sbahra> edwardk, (list test)
08:37:32 <dolio> osfameron: So 'IState i j a' is is the type of a computation that expects a state of type i coming in, produces state with type j coming out, and yields an a.
08:37:39 <quicksilver> mmorrow: I was, but I wasn't paying much attention.
08:37:52 <edwardk> sbahra: i don't know that i kept it. all i really concluded was that i wanted to keep my data structures aligned to the simd unit to encourage its use (mainly because then i can load pairs of pointers as well, etc)
08:38:01 <mmorrow> quicksilver: interestingly, gcc seems to be first trying the sqrtsd instruction, then using ucomisd to see if some flag is set, and in the case that it is it discards that sqrt result and falls back to math.h's sqrt
08:38:14 <edwardk> quicksilver: did you ever see jaewook shin's stuff on superword level parallelism?
08:38:15 <osfameron> dolio: and do all the IStates at every parameter need to be the same?
08:38:25 <osfameron> same type, even
08:38:41 <comex> the problem is I typed [] as a type by mistake
08:38:43 <osfameron> ah no, the next one could have type j coming in, and k going out?
08:38:46 <comex> but honestly, great error
08:38:56 <dolio> osfameron: ireturn :: a -> IState i i a (doesn't change the state type), ibind :: (IState i j a) -> (a -> IState j k b) -> IState i k b.
08:39:10 <edwardk> quicksilver: not vectorizing but looking for opportunities to pack identical operations by loading things into the simd unit, so it has the property that it gracefully degrades unlke old-school vector optimizations
08:41:00 <quicksilver> edwardk: you mean a peephole optimisation at the asm or Cmm level?
08:41:13 <quicksilver> edwardk: I was thinking of something like that, but Smart People were unconvinced.
08:41:19 <osfameron> dolio: and bind = ibind, return = ireturn?
08:42:00 <dolio> Well, they're the indexed versions of the normal monad operations.
08:42:42 <osfameron> hmmm, I don't actually understand what you mean by "indexed" here?  We started off with it being a state type that could return a different type of state in outpout
08:42:56 <osfameron> *output (though I quite like "outpout")
08:43:00 <edwardk> quicksilver: its a bit broader scope than peephole, unroll a few times and looks for instruction sequences that are performing the same operations, and make the register allocator smart enough to pack them together if the cost is low
08:43:10 <dolio> The state types are the indices.
08:43:24 <dolio> But there are other indexed monads that don't have to do with state.
08:43:51 <edwardk> quicksilver: i happen to be very fond of it because it fits with the execution model of my jit. =)
08:44:46 <dolio> You can use an indexed Cont to support delimited continuations in a type class (with normal Cont, you have to write separate functions for each type, because the types don't work out).
08:45:21 <quicksilver> edwardk: GHC doesn't have an unroll pass as such, at the moment
08:45:33 <quicksilver> edwardk: although I think such things might be included in the codegen revamp.
08:45:39 <edwardk> i could take a trace and unroll it, shove everything else off onto side exits, and then try to pack similar chains into xmm regs.
08:45:39 <sbahra> edwardk, ok. :)
08:46:02 <edwardk> quicksilver: sure, its not a good 'global' optimization, hence why i like it for the jit
08:46:35 <edwardk> anyways, jaewook shin wrote http://portal.acm.org/citation.cfm?id=1048983 and a dissertation on the topic which I thought were pretty good
08:47:45 * quicksilver copies the title in Google Copyright Violator ^W^W Scholar
08:48:14 <pozic> quicksilver: how is Google Scolar a copyright violator?
08:48:20 <edwardk> heh
08:48:43 <quicksilver> pozic: because organisations like the ACM wish the prevent the dissemination of these articles
08:48:48 <quicksilver> pozic: because they wish to charge money for it
08:49:02 <quicksilver> therefore they (often but not always) make the author sign away their copyright.
08:49:10 <pozic> quicksilver: and where does Google violate copyright in that?
08:49:27 <quicksilver> google scholar is specifically design to help you find other copies of the article on the net
08:49:31 <quicksilver> that you can download for free :)
08:49:40 <pozic> quicksilver: yes, and where does Google violate copyright in that?
08:50:11 <quicksilver> it doesn't.
08:50:15 <quicksilver> it's a tool to help other people do so.
08:50:37 <pozic> quicksilver: how does it help other people to do so?
08:50:44 <quicksilver> I have just explained that.
08:51:03 <pozic> quicksilver: no, AFAIK, it just points to the webpages of the authors most of the time.
08:51:09 <pozic> quicksilver: nothing wrong with that.
08:51:19 <quicksilver> this is not an interesting conversation for this channel.
08:51:22 <pozic> quicksilver: there are no links to torrent versions of papers or whatever.
08:51:26 <quicksilver> feel free to continue it in -blah or on pm if you like.
08:51:33 <tromp> so those authors are in violatoin
08:51:52 <tromp> and google helps them to be found
08:52:01 <pozic> tromp: #haskell-blah
08:52:21 <quicksilver> edwardk: interesting paper, anyway.
08:52:30 <pejo> ACM allows author to archive pre- and post-prints.
08:52:31 <quicksilver> edwardk: I will ponder it. The GHC codegen is a lot to absorb ;)
08:52:43 <dolio> osfameron: I'm not sure you'll find that all this has to do with currying though, now that I think about it. :)
08:53:03 <edwardk> yeah, usually its just a preprint or something
08:53:03 <edwardk> quicksilver: yeah. like i said, it was a good fit for me, but maybe not so good in general
08:53:20 <edwardk> osfameron: i think all you've found with the currying stuff is that you can always write a function in monadic style using the identity monad =)
08:53:53 <edwardk> or that you can view the passed arguments as an indexed state for an indexed state monad
08:54:51 <edwardk> quicksilver: but in the end you're probably done for on x86 because of 4 byte alignment
08:56:52 <mxc> ?seen ndm
08:56:52 <lambdabot> I haven't seen ndm.
08:57:17 <osfameron> dolio, edwardk: heh, fair enough... I was wondering whether progressively binding arguments to each intermediate function layer didn't seem monadic (similar to what I understand of the Cont monad, for example).  I guess not then ;-)
08:57:49 <jeltsch> :t getChanContents
08:57:50 <lambdabot> Not in scope: `getChanContents'
08:57:55 <jeltsch> :t getChanContent
08:57:56 <lambdabot> Not in scope: `getChanContent'
08:57:56 <jeffersonheard> does anyone know offhand how to use weak pointers correctly?
08:58:01 <jeltsch> :t Channel
08:58:03 <lambdabot> Not in scope: data constructor `Channel'
08:58:29 <jeltsch> ?help
08:58:29 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
08:58:30 <jeffersonheard> Trying to use them to create a cache, and they always seem to have been collected by the next time I touch them
08:58:43 <jeltsch> ?list
08:58:43 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
08:58:46 <edwardk> osfameron: one model for a haskell argument stack is to 'push arguments onto a stack' and 'enter' the function, which then tries to take all it needs off the value stack. in that basically you pop the stack as a monadic action in the stack as state monad like you're thinking
08:59:29 <quicksilver> jeffersonheard: they'll be removed at the next GC, yes.
08:59:37 <quicksilver> jeffersonheard: (that's rather the point, isn't it?)
09:00:05 <jeffersonheard> yes, that is the point
09:00:14 <quicksilver> edwardk: well that's annoying but it isn't game over
09:00:15 <jeffersonheard> but I don't see any reason for the GC to have run
09:00:25 <quicksilver> the GC runs fairly often..
09:00:29 <jeffersonheard> there's like less than a second's difference
09:00:39 <edwardk> quicksilver: well, its nice to let cache like pointers to live a bit longer and be collected less frequently
09:00:41 <jeffersonheard> between when I put them in and when they go away
09:00:54 <quicksilver> edwardk: of course it is :)
09:00:59 <quicksilver> but that's not what weak pointers do.
09:01:04 <quicksilver> they're just pointers which are ignored by the GC.
09:01:07 <edwardk> quicksilver: ghc is pretty aggressive about cleaning up its mess, so a weak pointer cache is going to basically not find anything =)
09:01:12 <edwardk> quicksilver: sure
09:01:31 <jeffersonheard> well, it was a nice thought.
09:01:46 <edwardk> quicksilver: but ghc doesn't offer any collect-it-if-you-REALLY-need-the-space types ;)
09:01:46 <quicksilver> edwardk: (back to see) if you at least give the codegen use of the registers
09:01:55 <jeffersonheard> Last time I used weak pointers it was in Java and that's basically how they work there
09:02:15 <quicksilver> edwardk: then you can hope that several FLOPs in succession manage to stay in registers
09:02:15 <jeffersonheard> so I suppose I'll have to write my own LRU caching code instead of relying on things to hang around for a few minutes
09:02:33 <quicksilver> edwardk: the stack shuffling that GHC generates now is horrid.
09:02:34 <edwardk> quicksilver: i'm completely on board with using the registers, although, if you emit c code, it should be using them, if only for general arguments because it generates code using the x86-64 abi!
09:02:52 <edwardk> yeah
09:02:55 <quicksilver> jeffersonheard: java doesn't allocate memory the way GHC does :)
09:03:06 <quicksilver> jeffersonheard: consider that ever single (,) and (:) is a memory allocation.
09:03:14 <quicksilver> jeffersonheard: they are much more common than java's "new"
09:03:22 <jeffersonheard> yeah, I'm reading Simon's paper now
09:03:36 <quicksilver> so, as a result GHC collects much more agressively than java
09:03:40 <edwardk> the only real use of weak pointers is for things like hash consing
09:03:45 <quicksilver> especially in typical programs
09:04:02 <quicksilver> edwardk: there are some use cases where one part of the program has a real pointer
09:04:02 <edwardk> its hard to use them for cache like operations like you would in java, etc.
09:04:15 <edwardk> sure
09:04:20 <quicksilver> edwardk: and a different part has a weak pointer, which remains useful as long as the first part keeps it live
09:04:23 <quicksilver> etc.
09:04:36 <quicksilver> although such things are also code smell and suggest failure to layer your abstractions :)
09:04:57 <quicksilver> sounds a bit too much like a 'parent' pointer in a tree.
09:04:59 <quicksilver> yuck.
09:05:04 <edwardk> quicksilver: yeah, just most of the time when i want that.. its to hash cons something ;)
09:05:09 <jeffersonheard> quicksilver: what, caching, or?
09:05:19 <quicksilver> jeffersonheard: no, this was a different usage
09:05:22 <jeffersonheard> right
09:05:30 <quicksilver> it's more like "I kind of want to hold onto this value here, but not if that causes a memory leak"
09:05:46 <quicksilver> so you have a weak pointer, and you only hold onto it for as long as some other bit of your code keeps it live.
09:05:52 <quicksilver> such things don't seem to happen all that often.
09:05:55 <quicksilver> well, not to me, anyway :)
09:06:09 <jeffersonheard> nothing in Hackage that implements caching, either
09:06:11 <edwardk> quicksilver: i've been trying to figure out a graceful way to 'clone' the top level of a thunk so i could do that very same style of optimization on cheaply recomputable thunks
09:06:56 <edwardk> i.e. take a thunk and generate a forgetful copy of it, that holds a weak pointer to the answer and a copy of the original thunk.
09:07:05 <edwardk> for when the environments are smaller than the result generated
09:07:19 <edwardk> and the computation is cheap enough that i don't care about sharing
09:08:01 <quicksilver> jeffersonheard: yes, that's a bit surprising isn't it?
09:08:08 <quicksilver> jeffersonheard: I've been surprised by that.
09:08:18 <quicksilver> jeffersonheard: there is some caching code inside the monster that is happs, I think.
09:08:25 <edwardk> jeffersonheard: sounds like someone needs to write a package. i nominate the person with a need for it =)
09:08:26 <jeffersonheard> yes, well, i'm not touching that
09:08:34 <jeffersonheard> yeah yeah yeah.  I hear ya ;-)
09:09:42 <edwardk> one option might be to just make an LRU that sits off in a priority queue somewhere holding onto stuff for dedicated timeouts using a forked io thread to drop the pointers from the cache
09:09:57 <edwardk> and to provide weak references to clients of the lib
09:10:32 <jeffersonheard> or limit size and run on the same thread, just letting pointers "fall off the end"
09:10:36 <quicksilver> not sure I like forked IO threads and timeouts.
09:10:45 <jeffersonheard> references rather
09:10:45 <edwardk> it'd be nice to be able to query the gc about memory pressure, is there?
09:10:50 <quicksilver> much rather just limit by size or by a custom measure.
09:11:02 <edwardk> quicksilver: sure
09:11:23 <edwardk> quicksilver: bah, clearly you need a pluggable cache management strategy ;)
09:13:04 <jeffersonheard> edwardk: clearly because of the deadline I'm under I need something I can implement today ;-)
09:13:43 <quicksilver> edwardk: just a ordered monoid, I think
09:13:59 <quicksilver> edwardk: give each item a monoidal weight, and have an upper bound
09:14:13 <quicksilver> edwardk: and start removing least recently used items until you're back under the bound.
09:14:50 <quicksilver> maybe that's false generality
09:14:54 <quicksilver> maybe just an Int
09:15:06 * quicksilver shrugs
09:27:59 <jadrian> I'm looking at the Tree definition in
09:28:03 <jadrian> http://www.eyrie.org/~zednenem/2004/hsce/Data/InfiniteTree.hs
09:28:23 <jadrian> (T s v l r)
09:28:31 <jadrian> what does the 's' stands for?
09:28:51 <jadrian> v = value, l = left , r = right
09:28:58 <Saizan> seed
09:29:33 <jadrian> ok thanks Saizan I guess I see the idea
09:30:46 <Saizan> though i'm not sure what the advantage over a standard binary tree, considering haskell lazyness
09:31:22 <Saizan> s/what/what's/
09:34:28 <Saizan> edwardk: that InfiniteTree above correponds to what you talked about the density comonad of the algebra of a functor over itself?
09:35:07 <jeffersonheard> @hoogle b -> (a -> a) -> a -> a
09:35:07 <lambdabot> Prelude maybe :: b -> (a -> b) -> Maybe a -> b
09:35:08 <lambdabot> Data.Maybe maybe :: b -> (a -> b) -> Maybe a -> b
09:35:08 <lambdabot> Data.Generics.Aliases mkQ :: (Typeable a, Typeable b) => r -> (b -> r) -> a -> r
09:35:31 <dan> Where can I find haskell sources for download, for windows? I only found a sources installer for linux
09:35:51 <Saizan> for ghc you mean
09:35:53 <Saizan> ?
09:36:03 <dan> indeed, and the standard modules
09:36:19 <Saizan> the source package is the same, but you need mingw/msys installed, afaik
09:36:39 <Saizan> that's why windows users prefer the installer
09:37:06 <dan> i used the regular windows installer - but i think it just includes compiled libraries
09:38:08 <Saizan> yup, however the libraries' source is available separately and can be built with Cabal alone in many cases
09:38:42 <dan> ah, where is it available? and are most libraries written in C or haskell? :0
09:39:02 <Saizan> haskell with a bit of C for OS interaction
09:39:21 <Saizan> http://darcs.haskell.org/libraries has the repos for the ones shipped with ghc
09:39:34 <Saizan> and others
09:40:12 <dan> Great. Thanks!
09:40:47 <Saizan> however you can also go under libraries/ in ghc's source package, where you'll find a snapshot of each repo
09:41:42 <Saizan> it all depends on what you want to do in the end :)
09:46:25 <dan> doesn't really matter, i'm just looking to look at some source :)
09:53:28 <PeakerWork> dan: hpaste.org has links to the sources of hpaste, which I hear are pretty nice to look at
09:54:37 <PeakerWork> dan: git clone http://code.haskell.org/hpaste.git
10:18:45 <PeakerWork> ghc switched to git, right? http://github.com/ghc-hq/ghc/tree/master says its only a mirror?
10:48:45 <yitz> @users
10:48:46 <lambdabot> Maximum users seen in #haskell: 658, currently: 617 (93.8%), active: 8 (1.3%)
10:49:17 * QtPlaty[HireMe] wonders if it would make sence to have user definable type operators.
10:53:37 <byorgey> QtPlaty[HireMe]: what do you mean?  we do have user definable type operators.
10:54:12 <byorgey> data (f :.: g) a = O { unO :: f (g a) }
10:54:15 <byorgey> for example
10:54:40 <skorpan> type operators?
10:54:47 <kpreid> can that be a newtype?
10:54:54 <byorgey> kpreid: yeah, it can
10:55:05 <byorgey> probably should =)
10:56:02 <TomMD> @users
10:56:03 <lambdabot> Maximum users seen in #haskell: 658, currently: 619 (94.1%), active: 13 (2.1%)
10:56:14 <byorgey> skorpan: so in the above example,  :.: is a type operator -- if f and g are types (of kind * -> *) then so is  f :.: g, just like if x and y are values of type Int, then so is  x + y
10:56:42 <byorgey> 'operator' here referring to the infix syntax
10:57:22 <t345> are there any parts of the Haskell Default toolchain that would require me to sign a contributor agreement before I can send in any kind of diff, how trivial it may be?
10:58:14 <TomMD> t345: Not that I know of, but you can ask the group you hope to send the patch to.
10:58:20 <byorgey> t345: not to my knowledge.
10:58:44 <t345> sounds promising
10:58:46 <byorgey> I've never even heard of signing contributor agreements.
10:58:48 <kpreid> what does a toolchain have to do with licensing?
10:59:22 <Berengal> We all love partial application, don't we?
10:59:55 <TomMD> Yes - people who don't should have left long ago.
11:00:37 <Berengal> What if we could partially apply arguments appearing after arguments we'd like unapplied easily?
11:01:06 <Berengal> We can do that now by using lambdas, somethink like (\a b -> foo a b c)
11:01:11 <byorgey> Berengal: that would certainly be nice every now and then
11:01:17 <Berengal> something*
11:01:25 <byorgey> but it would only save a bit of typing.
11:01:52 <dolio> @type (curry .) . flip . uncurry
11:01:53 <lambdabot> forall b c a b1. (a -> b1 -> b -> c) -> b -> a -> b1 -> c
11:02:34 <Berengal> @pl (\a b c -> foo a x b y c z)
11:02:34 <lambdabot> flip flip z . (flip .) . flip flip y . flip foo x
11:02:37 <byorgey> (\a b -> foo a b c) ===>  foo _ _ c, perhaps
11:02:56 <Berengal> byorgey: Yes, I was thinking just the same thing
11:03:14 <Berengal> Except surrounded in parenthesis
11:03:21 <Berengal> But I don't know if that'd be useful or not
11:03:25 <byorgey> eh? why parentheses?
11:03:40 <Berengal> Completely arbitrary
11:03:48 <dolio> @type (curry . curry .) . flip . uncurry . uncurry
11:03:49 <lambdabot>     The operator `.' [infixr 9] of a section
11:03:49 <lambdabot>         must have lower precedence than the operand `(.)' [infixr 9]
11:03:49 <lambdabot>         in the section: `(curry . curry .)'
11:03:58 <dolio> @type ((curry . curry) .) . flip . uncurry . uncurry
11:03:59 <lambdabot> forall b c b1 a b2. (a -> b2 -> b1 -> b -> c) -> b -> a -> b2 -> b1 -> c
11:03:59 <t345> kpreid: I was trying to scope the question in the constraints of popularly used haskell framework/compiler/....
11:04:04 <byorgey> Berengal: no, I mean, why do you need something to 'escape' it at all
11:04:20 <byorgey> oh, wait, sorry, I see what you meant
11:04:25 <byorgey> I was confused
11:04:51 <Berengal> Anyway, would something like this be interesting to people?
11:06:03 <Berengal> byorgey: I thought it might be a bit hard to disambiguate between foo _ _ c d e ==> (\a b -> foo a b c d e) and (foo _ _ c) d e ==> (\a b -> foo a b c) d e
11:07:35 <byorgey> Berengal: oh, you're right, that's a little tricky
11:08:36 <byorgey> then perhaps it wouldn't be that good of an idea after all.  It means that you can no longer interpret application in a naive left-associative sort of way
11:08:55 <byorgey> that is,  foo x y z  is not necessarily  ((foo x) y) z,  if one of  x,y,z  is a _
11:09:09 <Berengal> byorgey: We might not need to require the parenthesis though, as it would be effectively be enforced by the type system
11:09:30 <Berengal> But we could still write something like foo' = foo _ _ c
11:10:02 <byorgey> well, I guess I'd have to see a detailed proposal before I could decide whether it would be interesting or not.
11:10:14 <byorgey> but at this point I'm leaning towards thinking that it would be more trouble than it's worth.
11:10:49 <Cale> People have proposed that underscore thing and things like it for a long time, but I think for all the good it would do, lambdas are easier to deal with.
11:11:56 <Cale> There is something special about the usual applicative order partial evaluation too, which features of that type would perhaps help to obscure.
11:13:02 <Cale> Particularly, if you partially apply a function to some of its parameters in the usual way, it can be partially evaluated, whereas current implementations of Haskell don't evaluate under lambdas.
11:13:04 <edwardk> the _ thing is tricky because you want a nice set of rules for it and what do they scope out to? the parens? now parens change meaning, the function?
11:14:00 <Cale> So writing (foo _ x) would turn into a lambda and not get evaluated under, while (foo x) might be possible to reduce somewhat.
11:14:15 <Cale> (even if it's still a function)
11:14:31 <Berengal> Even flip foo x?
11:14:37 <Cale> That's similar
11:14:47 <Berengal> Yeah, okay
11:14:50 <Cale> flip foo x just evaluates to the lambda
11:14:58 <Cale> and then no more
11:15:15 <monadic_kid> oh are you guys discusing about adding support for generalized partial application?
11:15:24 <Berengal> Yes
11:15:25 <Cale> yeah
11:15:35 <Berengal> Well, I wasn't completely sold on the idea myself
11:16:03 <dolio> foo _ _ c conflicts with magic underscore!
11:16:12 <monadic_kid> is this for haskell platform? if its a library solution then that would be a no brainy
11:16:24 <Berengal> I still think it's a good idea, but we either need to do it differently or it might not be possible to do without breaking some things
11:16:41 <monadic_kid> well do you guys know about boost bind?
11:16:51 <monadic_kid> or nemerle
11:17:13 <Berengal> monadic_kid: There's no need for a library for this
11:17:27 <Berengal> I doubt a library could reduce it further than lambdas do
11:17:37 <edwardk> dolio: yeah thats what i thought they were talking about at first =)
11:18:25 <dolio> I'm surprised no one's added that to GHC yet.
11:18:47 <Cale> For an example of what I was talking about, try this in ghci:
11:18:58 <Cale> let foo x = let y = product [1..x] in \z -> z + y
11:19:09 <Cale> let f = foo 20000
11:19:13 <Cale> f 1
11:19:14 <Cale> f 2
11:19:15 <monadic_kid> nemerle supports more generalized partial application, http://nemerle.org/New_features#Partial_application_on_steroids
11:19:31 <Cale> and you'll see that f 1 takes a while, but thereafter, f 2 is fast.
11:19:38 <monadic_kid> it's like how you guys are saying
11:19:48 <Cale> because the value of y associated with it is already evaluated
11:20:15 <Berengal> Cale: I hadn't noticed that before
11:20:59 <copumpkin> that's cool
11:21:31 <edwardk> cale: thats because it got captured in the environment of the lambda and is already evaluated
11:21:38 <Cale> edwardk: yeah
11:21:48 <dolio> @go full-laziness
11:21:49 <lambdabot> http://encyclopedia2.thefreedictionary.com/full+laziness
11:21:50 <lambdabot> Title: full laziness definition of full laziness in the Free Online Encyclopedia.
11:22:08 <dolio> Well, that isn't helpful.
11:22:40 <dolio> Oh, wait, yes it is. That page just confused my browser.
11:22:56 <copumpkin> http://nemerle.org/New_features#Partial_application_on_steroids seems like it'd be a pretty easy addition to haskell?
11:23:24 <copumpkin> would just add a little bit of sugar on top of a lambda
11:23:31 <Cale> My point is that the order of arguments actually matters.
11:24:30 <copumpkin> sure, but you could still get behavior that matched nemerle, if you wanted it?
11:24:46 <BONUS> i think (\x y -> foo 1 x 2 y) is readable and concisce enough
11:24:46 <mmorrow> i hacked together (the start of) a "haddock for C" out of desperation for something that doesn't suck, and just packaged it and put it here if anyone wants to mess with it:  http://moonpatio.com/flounder/  (note: i "had" to modify hscolour slightly and language-c a little more than slightly, so there are *-flounder packages for those two.. but i'm gonna eventually see if i can get my patches accepted)
11:24:48 <Cale> Oh, I don't know what nemerle does.
11:25:03 <Cale> (That page is not loading quickly for me)
11:25:13 <Cale> BONUS: I agree.
11:25:26 <mmorrow> this is the output for: $ flounder -o flounder-sample `ls *.{c,h}`
11:25:27 <copumpkin> if I have f :: a -> b -> c -> d and I call f _ 5, it could give me a a -> c -> d
11:25:28 <mmorrow> http://moonpatio.com/flounder/flounder-sample/
11:25:50 <Cale> It might be worth considering mechanisms to aid the compiler in deciding on partial evaluations to provide.
11:26:04 <Cale> Though, argument order is usually sufficient.
11:26:08 <edwardk> foo (3 + _) -- passes a function to foo, but _.foo (3, _) -- makes a two argument function. thats not exactly intuitive ;)
11:26:52 <edwardk> foo (3, _) -- is a unary function but foo (3 + _) is nullary, passing a function, not exactly the kind of semantics i want to slip into my language
11:27:01 <Cale> I think the underscore notation is easily as bad, if not worse than mathematica's #/& syntax.
11:27:04 <opqdonut> clojure has a syntax like #(foo %2 (+ %1 3)) for ad-hoc lambdas
11:27:13 <opqdonut> which is nice enough
11:27:31 <edwardk> opqdonut: yeah, if you have some 'reset' like delimiter, go ahead and shift whatever you want
11:27:33 <Cale> At least in mathematica, they have & at the end to let you know where the scope ends.
11:27:53 <Cale> But it generally makes things really unreadable.
11:28:16 <Berengal> Aren't lambdas ad-hoc enough by themselves?
11:28:22 <Cale> I always replace it with Function[...] when I see it in mathematica code, because it's just too hard to understand otherwise, normally.
11:28:52 <copumpkin> how is mathematica? is it fun to program in?
11:28:54 <dolio> > (length "#(foo %2 (+ %1 3))", length "\x y -> foo y (+ x 3)")
11:28:55 <lambdabot>   <no location info>:
11:28:55 <lambdabot>      lexical error in string/character literal at chara...
11:29:00 <copumpkin> I was reading the spiel about how awesome it was to program wolfram alpha in it
11:29:04 <dolio> > (length "#(foo %2 (+ %1 3))", length "\\x y -> foo y (+ x 3)")
11:29:05 <lambdabot>   (18,21)
11:29:06 <copumpkin> but clearly they have an incentive to tell you that
11:29:15 <Cale> copumpkin: It's lispish, with a better syntax.
11:29:31 <tombom> lisp with a better syntax?
11:29:35 <tombom> obviously impossible
11:29:45 <Berengal> Lisp doesn't have syntax...
11:29:48 <Cale> tombom: It's similar to M-expressions.
11:29:48 <edwardk> in the end its all sugar for adding shift and reset to the language. viva la continuations ;)
11:29:51 <mauke> s/impossible/trivial/
11:29:56 <Cale> Or whatever those were called.
11:30:01 <dolio> Xah Lee endorses Mathematica.
11:30:05 <mauke> and yes, Lisp does have syntax, it just sucks
11:30:13 <copumpkin> omg xah lee
11:30:15 <copumpkin> it must be good
11:30:20 <Cale> The alternative to S-expressions which was initially considered for lisp-1
11:30:27 <copumpkin> I assume it doesn't do any of that tail recursion bullshit then?
11:30:29 <Cale> Mathematica's evaluation model is insane though.
11:30:43 <copumpkin> xah lee most certainly does not approve of tail recursion
11:30:46 <edwardk> dolio: xah lee endorses many things, its funny how little his endorsement or lack there of correlates to the usefulness of said tool ;)
11:30:48 <tombom> lisp has syntax, it's just relatively simple
11:30:59 <mauke> tombom: haha. no.
11:31:03 <tombom> :I
11:31:09 <Cale> It's possible to do things like make a definition like Cos[a] ^= 2, which becomes part of the definition of 'a' rather than of the definition of Cos.
11:31:10 <mauke> (only lisp can parse Lisp)
11:31:20 <dolio> Funny perhaps. Surprising, probably not.
11:31:49 <Cale> But only one level deep.
11:31:55 <Cale> (for somewhat obvious reasons)
11:32:05 <monadic_kid> you know (due to limitions of C++ of-course) boost bind uses _1, _2, _3, ..._N for binding parameters
11:32:41 <Berengal> Lisp is the only language where I had the syntax down in five minutes
11:32:42 <monadic_kid> and boost mpl for meta functions
11:32:54 <Cale> Mathematica's evaluation is basically a not-very-restricted kind of tree rewriting.
11:33:00 <monadic_kid> boost::is_pod<_1> <--- generates meta lamdba function
11:33:57 <heltav> http://article.gmane.org/gmane.comp.lang.haskell.cafe/21951
11:34:02 <Cale> On the surface it appears true that lisp's syntax is simple, but once you involve macros, it's almost arbitrarily complicated.
11:34:32 <Berengal> Cale: I wouldn't say that's part of the syntax though
11:34:44 <Berengal> Unless you're talking about read macros
11:34:45 <Cale> I would. You can introduce new kinds of binding forms.
11:35:23 <Cale> It allows you to introduce new syntactic abstractions -- that's what macros are.
11:36:55 <Berengal> Well, I consider it's syntax to be sexp syntax, possibly a few other minor details like ',`
11:37:27 <Cale> I include all the special forms as parts of the syntax.
11:38:58 <Berengal> In that case I'd agree with you
11:39:25 <mauke> bonus question: what is #4(1 :f "y" 42 "\n") ?
11:40:25 <copumpkin> what do I get for answering it?
11:40:32 <mauke> praise
11:40:42 <dcoutts_> a biscuit
11:41:06 <copumpkin> mmm biscuit
11:41:54 <mauke> Berengal: hey, you said you learned lisp's syntax in five minutes :-)
11:42:23 <edwardk> hah given how much code I've lost over the years I was greatly amused by http://www.budiu.info/blog/2007/05/03/an-interview-with-leslie-lamport/ where he mentioned how he had a set of emacs macros that could replicate the state of any code he'd written down to about a minute back to 1993.
11:42:43 <copumpkin> is that lamport of lamport signatures?
11:42:54 <mauke> LaTeX
11:42:55 <Cale> He's the LaTeX guy
11:43:14 <copumpkin> ah, but also lamport signatures, apparently :)
11:43:30 <edwardk> and paxos, lamport signatures, byzantine generals, ...
11:43:59 <edwardk> oh, and that lovely bakery algorithm that shouldn't work but does
11:45:37 <copumpkin> btw, can anyone explain the UMP succinctly?
11:46:00 <Jedai> ump ?
11:46:12 <Cale> Which UMP?
11:46:21 <copumpkin> universal mapping property
11:46:25 <edwardk> the statistics test?
11:46:26 <Cale> Yes, which one?
11:46:27 <edwardk> oh
11:46:29 <Cale> There are a lot of them :)
11:46:43 <copumpkin> the one introduced near the beginning of the awodey book that I had glossed over before :P
11:46:53 <copumpkin> let me find it
11:47:26 <Cale> In general, universal mapping properties are ones of the form   for all diagrams of some shape with some conditions, there exists a unique arrow with some properties
11:47:53 <copumpkin> oh I see, UMP of M(A), where M(A) is the free monoid on A
11:47:58 <Cale> yes
11:48:41 <Cale> So you'd like an explanation of how that one works?
11:48:51 <copumpkin> if you don't mind :)
11:50:01 <copumpkin> I mostly don't get the role of N in that explanation
11:50:07 <copumpkin> if you have the PDF in front of you
11:50:19 <Cale> Okay, so it's saying that we have some function i from the set A, to the underlying set of the free monoid on A
11:51:03 <Cale> This is going to turn out to be the "obvious" function which takes an element of A to the word which consists of just A.
11:51:07 <Cale> er
11:51:10 <Cale> just that element
11:51:19 <Cale> okay
11:51:26 <Cale> So, N is any other monoid
11:51:44 <copumpkin> oh
11:51:45 <Cale> Suppose we pick a function f: A -> |N|
11:52:05 <Cale> That is, an assignment of each of the generators of the free monoid M(A) to an element of |N|
11:52:32 <Cale> It's saying that we can find a unique homomorphism from M(A) -> N which preserves those assignments.
11:52:41 <copumpkin> so (ab)* maps to all words consisting of 'a' and 'b', but the function i simply takes 'a' to 'a' and 'b' to 'b' ?
11:53:11 <Cale> I would perhaps say a to "a" and b to "b"
11:53:17 <copumpkin> fair enough
11:54:19 <Cale> This universal mapping property -- that there is a unique homomorphism for every assignment of the generators to the underlying set of N -- can be taken as the definition of a free monoid in general.
11:54:54 <copumpkin> ah, so the |f| in that case is taking {"a", "b"} (using the distinction you made earlier) to all words of a and b
11:54:55 <Cale> That is, the existence of this set A with this special property is what makes the monoid "free"
11:54:56 <copumpkin> ?
11:55:30 <Cale> No, it sends "a" and "b" to wherever f sent a and b
11:55:42 <copumpkin> hmm
11:56:02 <Cale> and it sends, say, abbabab to f(a)f(b)f(b)f(a)f(b)f(a)f(b)
11:56:18 <Cale> that is, the only thing it could possibly send it to, given that it's supposed to be a homomorphism
11:56:26 <copumpkin> yeah
11:57:04 <Cale> The point is that every element of M(A) is either the identity (which has to be sent by a homomorphism to the identity), or it can be written as a nonempty product of (the images of) elements of A
11:57:11 <vrul8> http://smst1.mybrute.com
11:57:19 <vrul8> pretty cool game :P
11:57:19 <copumpkin> okay, I think I get it... I think I was trying to shoehorn the kleene star into it
11:57:23 --- mode: ChanServ set +o dcoutts_
11:57:24 <copumpkin> vrul8: um  no
11:57:35 <vrul8> um ye
11:57:41 <Cale> and so if we know where (the images of) elements of A need to be sent in N, then we know where everything needs to go
11:57:46 <dcoutts_> vrul8: no spamming please, thanks.
11:57:46 <vrul8> try it before you speak of it
11:57:47 <copumpkin> vrul8: wow, you're actually a real person, at least
11:57:55 <copumpkin> vrul8: you should try haskell :)
11:57:57 <Cale> vrul8: What does it have to do with Haskell?
11:58:00 <vrul8> well lol it's a game
11:58:02 <vrul8> not a virus haha
11:58:12 <Cale> vrul8: Why are you talking about it here then?
11:58:14 <vrul8> try it it's pretty fun not best game but ok
11:58:24 <vrul8> why shouldn't i?
11:58:30 <mauke> vrul8: because this is #haskell
11:58:31 <Cale> vrul8: This channel is for discussion of haskell and related topics.
11:58:36 <copumpkin> THIS IS SPARTA
11:58:42 <vrul8> lol
11:58:43 <copumpkin> I mean haskell
11:58:49 <vrul8> well you guys can atleast try it out
11:58:54 <vrul8> here's the site again xd
11:58:56 <copumpkin> I did, I went directly to mybrute.com
11:58:57 <vrul8> - http://smst1.mybrute.com
11:58:58 <vixey> vrul8: don't link it again
11:58:59 --- mode: ChanServ set +o mauke
11:58:59 --- mode: ChanServ set +o Cale
11:59:33 --- mode: Cale set +b *!*=vrul*@*
11:59:49 --- mode: Cale set -o Cale
11:59:51 --- mode: ChanServ set -o dcoutts_
11:59:55 <copumpkin> Cale: okay, I think I get it now, thanks :)
11:59:59 --- mode: mauke set -o mauke
12:00:21 <mauke> whoo, multi-op action
12:00:50 <RayNbow> a rare occasion :p
12:01:07 <Botje> the stereo quote seems oddly appropriate
12:02:15 <edwardk> #haskell, where all your link spam is answered by kickbanning in majestic stereo!
12:02:43 <Phyx-> lol, speaking of games "3D Realms, developer of Duke Nukem Forever, has been shut down, according to a report by Shacknews." <-- shocker
12:02:47 <Phyx-> :P
12:02:54 <edwardk> phyx: bout time
12:03:07 <edwardk> 12 years of 'when its done' is enough ;)
12:03:18 <Cale> http://duke.a-13.net/
12:03:19 <copumpkin> it's sad :(
12:03:38 <Phyx-> the trailer wasn't even impressive
12:03:46 <copumpkin> but it was duke nukem!!!
12:03:48 <Phyx-> doubt it would have sold well
12:04:05 <RayNbow> would they have finished the game if they had used Haskell? :p
12:04:22 <IndependentlyTyp> is dependent types for doing stuff like: blah :: Int -> (a -> b) -> [b,b,b] ; ?
12:04:29 <vixey> no
12:04:34 <Cale> RayNbow: Perhaps they could have switched graphics engines just by writing different adapters for Reactive :)
12:05:09 <edwardk> wow its funny how much ken silverman has apparently not changed over the intervening decade and a half: http://www.advsys.net/ken/
12:05:15 <Cale> IndependentlyTyp: What do you mean [b,b,b]?
12:05:30 <Cale> Do you mean [(b,b,b)] ?
12:05:31 <copumpkin> it'd be nice to have some syntactic sugar for à la carte -style types
12:05:52 <copumpkin> I think he meant specifically a list of length 3?
12:06:06 <vixey> I think he is nonsensical
12:06:23 * cypher- thought dn will be in development *forever*
12:06:25 <copumpkin> well, he's asking about dependent types, so having a list of a particular length might make sense in that context
12:06:32 * copumpkin shrugs, he's gone
12:06:33 <vixey> not really
12:06:40 <copumpkin> I guess not, eh
12:06:41 <Cale> It would be like
12:07:00 <copumpkin> yeah, that could still be done without dependent types, couldn't it
12:07:16 <edwardk> cypher: little did we know that 'forever' in the title was intended to be the amount of time until release.
12:07:56 <Cale> Maybe something like  blah :: (n :: Int) -> a -> List n a
12:08:04 <copumpkin> that makes sense, yeah
12:08:14 <copumpkin> that would be replicate? :P
12:08:18 <Cale> yeah
12:08:22 <Cale> for counted lists
12:08:22 <copumpkin> mmm I want that
12:08:48 <Cale> IndependentlyTyp: ah, you're back
12:09:05 <Cale> IndependentlyTyp: Basically, dependent types allow you to have types which depend on values
12:09:46 <Cale> IndependentlyTyp: A simple example is a type of lists where the length of the list is specified in the type as an Integer parameter.
12:10:00 <roconnor> f 0 = Bool; f (n+1) = Integer -> f n
12:11:12 <IndependentlyTyp> is the dragon book of compilers good learning how to write a compiler fo functional languages?
12:11:19 <IndependentlyTyp> or should I just stick to SPJs book on implementing func langs?
12:11:27 <Botje> the dragon book focuses mostly on parsing
12:11:31 <Botje> unfortunately :(
12:11:39 <cypher-> I disagree
12:11:54 <cypher-> there is quite a bit about comipler optimizations in the dragon book
12:12:28 <cypher-> IndependentlyTyp: my view is that while it does not focus on functional languages, every aspiring compiler writer should read the dragon book
12:12:34 <cypher-> just in case ;-)
12:13:01 <cypher-> hmm.. you can dl a free copy of SPJ's book on implementing functional languages IIRC
12:13:19 <copumpkin> :t Kleisli
12:13:20 <lambdabot> forall a (m :: * -> *) b. (a -> m b) -> Kleisli m a b
12:13:52 <cypher-> IndependentlyTyp: Pierce's TaPL is a good start (although I don't like it personally)
12:14:19 <Cale> cypher-: What don't you like about it?
12:14:37 <roconnor> :k Kleisli
12:14:38 <lambdabot> (* -> *) -> * -> * -> *
12:14:53 <alexbobp> what's the difference between Int and Integer?
12:14:59 <copumpkin> Integer is bigger ;)
12:15:03 <cypher-> Cale: nothing in particular, the content is good, etc, but the style of writing and the way it's structured do not appeal to me
12:15:11 <roconnor> > maxBound :: Int
12:15:13 <lambdabot>   9223372036854775807
12:15:20 <ziman> Integer is arbitrary large, Int guarantees 29 bits
12:15:21 <Cale> alexbobp: Int is a machine integer, limited in size, Integer is any integer, up to the size of your memory
12:15:22 <alexbobp> > maxBound :: Integer
12:15:23 <lambdabot>       No instance for (Bounded Integer)
12:15:23 <lambdabot>        arising from a use of `maxBoun...
12:15:26 <cypher-> Cale: but on the other hand I don't have to like a textbook, as long as I learn from it what I need ;-)
12:15:26 <alexbobp> haha, okay
12:15:35 <alexbobp> okay.  How do I convert an Int to an Integer?
12:15:38 <cypher-> btw. what would be a good introduction to category theory?
12:15:46 * cypher- is looking for some summer rea
12:15:47 <cypher-> *read
12:15:51 <Cale> cypher-: Awodey's book is really good
12:15:53 <ziman> you can use fromIntegral to convert between integral types
12:16:22 <ziman> (also Integral to any other Num)
12:16:23 <Lemmih> IndependentlyTyp: Reading about GRIN would give you a good understanding about the data model of non-strict functional languages.
12:16:30 <Lemmih> IndependentlyTyp: http://www.cs.chalmers.se/~boquist/phd/index.html
12:16:33 <ziman> :t fromIntegral
12:16:34 <lambdabot> forall a b. (Num b, Integral a) => a -> b
12:16:51 <alexbobp> so, "fromIntegral theInt 0" then?
12:16:56 <ziman> why is Num b listed first here? It always confuses me
12:16:56 <cypher-> Cale: http://www.amazon.co.uk/Category-Theory-Oxford-Logic-Guides/dp/0198568614 this one?
12:17:07 <ziman> alexbobp, what is theInt?
12:17:26 <alexbobp> ziman: it's digitToInt (from Data.Char) applied to a Char
12:17:57 <Cale> cypher-: I think so, yes.
12:18:08 <ziman> well, "fromIntegral theInt" will give you the code as an Integer; I don't know why the 0 is there
12:18:26 <Cale> ziman: It means that b is any type of number
12:18:44 <Cale> ziman: Do you know about typeclasses in general?
12:19:01 <ziman> Cale, yes, i'm just asking, why b is *first* :)
12:19:15 <ziman> (Num b, Integral a) => a -> b looks strange to me :)
12:19:19 <alexbobp> ziman: ah... okay, I misread the type signature
12:19:22 <alexbobp> thanks
12:19:28 <Cale> ziman: Ah, it would be nice if it would sort the class contexts better.
12:20:17 <Cale> cypher-: The biggest criticism I have of TaPL is that the examples in ML are a bit ugly (and not just because they're in ML and not Haskell). He abuses exceptions.
12:20:29 <ziman> hm, i see, in general case there might not be any intuitive ordering on the constraints
12:20:54 <edwardk> cale: there is a set of haskell implementations of the tapl programs
12:21:17 <edwardk> http://code.google.com/p/tapl-haskell/
12:21:17 <Cale> ziman: It could at least take a shot at ordering them in terms of the order that the variables occur in the type, say.
12:22:04 <edwardk> ziman: contexts are unordered
12:25:06 <copumpkin> > runKleisli (Kleisli (filter (>2)) >>> Kleisli (replicate 2)) [1..10]
12:25:07 <lambdabot>   [3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10]
12:25:19 <edwardk> hrmm, just noticed the ghc status report. lock-free work stealing queues. wonder how bad they'd be to replace with lockfree workstealing deques so you can get spark processor affinity
12:25:25 <copumpkin> there needs to be a flip runKleisli function
12:25:43 <edwardk> @let flipRunKleisli = flip runKleisli
12:25:44 <lambdabot>  Defined.
12:25:46 <edwardk> there
12:25:48 <copumpkin> thank you
12:25:50 <copumpkin> ;)
12:26:14 <copumpkin> > flipRunKleisli [1..10] $ Kleisli (replicate 2) <<< Kleisli (filter (>2))
12:26:15 <lambdabot>   [3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10]
12:26:44 <copumpkin> pretty exciting function
12:28:19 <dcoutts_> edwardk: what you mean about the workstealing deques?
12:30:22 <edwardk> dcoutts: well lockfree workstealing deques are nicer that lockfree workstealing queues in that they can be used to allow other processors to steal work from the dequeue's bottom when they get bored and you can implement them without a CAS on the 'worker' side, only needing CAS to steal or claim the last element
12:30:59 <phercek> How do I write string literal "Aa" where instead of A I want to use Greek capital lambda? So it would be something like "\x39Ba" but then the letter 'a' is understood as part of the hex code, I do not want that ... and do not want to write it like "\x39B"++"a" too. So I'm actually asking if there is some delimiter to finish the hex code with.
12:31:12 <edwardk> dcoutts: so they typically require less synchronization than a work queue but serve much the same purpose. you 'spark' something for yourself to do later and if someone gets around to it before you do, all good.
12:31:30 <roconnor> > "\x039Ba"
12:31:31 <lambdabot>   "\14778"
12:31:36 <roconnor> > "\x000039Ba"
12:31:37 <Berengal> > "\x39B\ \a"
12:31:38 <lambdabot>   "\14778"
12:31:38 <lambdabot>   "\923a"
12:31:59 <edwardk> dcoutts: but since you sparked it for yourself you're more likely to have it in cache, etc and be in a position to evaluate it without going out to main memory, invalidating cache, etc.
12:32:08 <dcoutts_> edwardk: apart from the CAS, I don't see how it's different. Isn't the workstealing queue exactly to add sparks onto that other cpus can steal work from?
12:32:12 <copumpkin> , "\923a"
12:32:15 <lunabot>  "\923a"
12:32:20 <copumpkin> :P
12:32:27 <roconnor> > "\x39B\ \a"
12:32:28 <lambdabot>   "\923a"
12:32:35 <phercek> so is it "\ "?
12:32:42 <Berengal> "\ \"
12:32:47 <copumpkin> , text "\923a"
12:32:49 <lunabot>  ۡ
12:32:53 <copumpkin> :o
12:32:54 <edwardk> dcoutts: the cas is the big deal because then you come back down to it in stack order yourself, while its likely to be in cache
12:33:00 <dcoutts_> edwardk: you never want to steal from your own queue as that'd not add any parallelism
12:33:14 <Berengal> \ followed by whitespace indicates the string literal stops. \ starts it again, and the slashes and all whitespace inbetween is removed
12:33:29 <edwardk> dcoutts: often others have enough to do =) you don't steal from yourself., you just need the result before someone else got to stealing it
12:33:55 <Berengal> "a\ \b\ \c"
12:34:02 <Berengal> > "a\ \b\ \c"
12:34:03 <lambdabot>   "abc"
12:34:12 <phercek> Berengal: ach right, thanks
12:34:16 <edwardk> dcoutts: and if you made it you are probably holding onto more of the pieces needed to evaluate it than some random other processor
12:34:30 <dcoutts_> edwardk: these sparks are always for optional, not compulsory work. The whole lot can be discarded without loosing any info.
12:34:35 <inimino> > "\x39B\&\a"
12:34:36 <lambdabot>   "\923\a"
12:34:38 <edwardk> dcoutts: its a common pattern used by high throughput task pooling systems
12:34:55 <inimino> erm
12:34:56 <copumpkin> I wonder if there's any advantage to using Kleisli for []
12:34:59 <inimino> > "\x39B\&a"
12:35:00 <lambdabot>   "\923a"
12:35:15 <dcoutts_> edwardk: right but in those cases they're using the queue in a different way arn't they? they're using them for "future work I need to do"
12:35:30 <edwardk> dcoutts: sure. i merely point out that the workstealing deque seems to be the tool of choice throughout the rest of the industry for a reason.
12:36:46 <edwardk> dcoutts: and the fact is that it doubles as the same thing you're using them for. if someone steals it it costs a cas like the workstealing deque, but the cheaper case is cheaper and the implementation isn't all that terribly more complicated
12:37:12 <IndependentlyTyp> anyone know a good article on programming to avoid cache misses?
12:37:17 <dcoutts_> edwardk: given the use case I don't see that it's better, correct me if I'm wrong but you can add things to the queue with no CAS and other cpus can remove items with a CAS. Yes?
12:37:20 <edwardk> dcoutts: i merely pointed out the alternative technology existed, i'm not wedded to its selection =)
12:38:17 <edwardk> dcoutts: and you can take from your own deque without a cas, and often if other threads are busy working on items they generated themselves in their own deques which are more likely to use resources in their own caches, they won't be casing to steal from you
12:38:38 <dcoutts_> edwardk: right, ok
12:38:54 <edwardk> dcoutts: so what happens is you get a little bit of stack like behavior that keeps everyone busy with a lot less synchronization
12:39:41 <edwardk> and the cache gets abused less because you're more likely to be working on stuff you touched recently
12:40:18 <dcoutts_> edwardk: though if they steal a spark and as a result of evaluation they make more sparks (quite likely) then it'll go on that cpu's spark queue and it'll only go back to the original cpu's spark queue if it's own one runs empty
12:40:21 <vixey> mauke do you know the control code for turning off buffering/turning on character mode through telnet?
12:40:47 <IndependentlyTyp> function = do name <- P.many P.anyChar; P.space; var  <- P.many P.anyChar; P.space >> P.char '='; return (name, var); why doesnt that match "add x =" ?
12:41:01 * vixey needs to have a control code equiv. of hSetBuffering stdin NoBuffering
12:41:26 <dcoutts_> edwardk: hmm, so I'm wrong then, the cpus that steal sparks are likely to want to take sparks from their own queues. It's only the "main" thread that would never take from it's own queue.
12:41:37 <edwardk> dcoutts: sure, but they deal from the bottom of the deque, so they likely steal stuff that will generate lots of sparks locally, so they start to build up their own context. and processors pitch in when bored. nearly no overhead when everyone is working
12:41:47 <edwardk> dcoutts: yeah
12:42:15 <dcoutts_> edwardk: check with Simon Marlow, he implemented the thing.
12:42:20 <mauke> vixey: no such thing AFAIK
12:42:35 <Cale> IndependentlyTyp: because Parsec parsers are LL(1) by default, and don't backtrack.
12:42:38 <vixey> mauke ohh.. that explains how I didn't find it, thank you
12:42:44 <edwardk> dcoutts: sure, its not something i'm terribly passionate about, its just something i've done a lot of work on in the past for other systems
12:42:47 <Cale> IndependentlyTyp: Hence, the P.many P.anyChar eats the whole string
12:42:50 <vixey> how the hell does telnet work though.
12:43:03 <dcoutts_> edwardk: sure, just double check that he's aware of the issue.
12:43:04 <edwardk> dcoutts: so i felt i should at least mention the possibility ;)
12:43:15 <edwardk> dcoutts: will do
12:43:17 <dcoutts_> edwardk: right, just make sure you tell the right person. :-)
12:43:33 <dbelange> DCC SEND "ff???f?" 0 0 0
12:43:38 <dbelange> :(
12:44:03 <edwardk> vixey: what do you mean? how does it work? its a socket with a thin little IAC WILL/WONT/DO/DONT protocol on top
12:44:28 <vixey> edwardk: I mean specifically character at a time input - rather than line based
12:44:37 <edwardk> vixey: those escape sequences are how you toggle the mode
12:44:40 <IndependentlyTyp> function = do name <- P.many P.anyChar; P.space; var  <- P.many P.anyChar; P.space >> P.char '='; return (name, var); why doesnt that match "add x =" ?
12:44:40 <vixey> maybe I have to reprogram the keys to also send newlines
12:44:51 <vixey> hm,,,,,
12:44:59 <Cale> IndependentlyTyp: I seem to recall explaining that only moments ago.
12:45:17 <IndependentlyTyp> ah i missed somehow
12:45:51 <vixey> DO	253	do	Indicates the request that the other party perform, or confirmation that you are expecting the other party to perform, the indicated option.
12:45:53 <vixey> sweet
12:46:21 <edwardk> vixey: yeah i.e. IAC WILL ECHO tells the client that you the server will take care of the echoing of chars
12:46:58 <edwardk> when you get back IAC DO ECHO -- you've been told 'go ahead boss!'
12:47:20 <vixey> ooh cool
12:47:27 <vixey> I got try these out
12:48:03 <edwardk> vixey: you can go pretty far down this rabbit hole depending on how much of the telnet IAC stuff you want to implement. and know window sizes, etc.
12:48:50 <edwardk> IAC WILL ECHO IAC WILL SUPPRESS-GO-AHEAD IAC DO SUPPRESS-GO-AHEAD -- is usually what you want to send to just work char at a time
12:49:14 <Cale> equanimity: It appears that you are vulnerable to the dcc send bug, you might want to look into it.
12:49:16 <edwardk> then you'll have to deal with the reply spam
12:53:15 <IndependentlyTyp> Cale: so how do you do it then? this seems very common to me. what is LL1 and why do I need to backtrack anywy?
12:53:46 <Gracenotes> ugh. it pains me so much to write accessors and mutators instead of using public variables, with OOP. But I must enforce my immutability constraints! :\
12:53:57 <IndependentlyTyp> oh wait i see perhaps. P.space i a char?
12:54:09 <Gracenotes> Haskell's module system makes this a bit more flexible, at least...
12:54:10 <Botje> I wonder if Data couldn't be abused to generate getters and setters
12:59:03 <sirk390> Hi all, I just did some haskell for the first time, and was a little disappointed  I couldn't define the * operator for my matrix multiplications without putting as instance of Num..... Is there really no way??
12:59:25 <lament> there isn't
12:59:36 <IndependentlyTyp> sirk390: why do you consider that bad?
12:59:37 <copumpkin> sirk390: you can get rid of Num, and define your own *, but you probably don't want that
12:59:41 <tromp> :t (*)
12:59:42 <lambdabot> forall a. (Num a) => a -> a -> a
13:00:37 <sirk390> IndependentlyTyp: I consider that bad for readability, I don't want to have 50 types of ^_^ -.-
13:00:38 <lament> matrix multiplication is SO asking for dependent types... :)
13:00:51 <lament> sirk390: but you can just define Num for matrices
13:01:03 <lament> it's a perfectly natural definition
13:01:08 <copumpkin> the problem then becomes things like fromIntegral and signum
13:01:15 <copumpkin> and scalar multiplication
13:01:34 <sirk390> lament; yeah maybe Num for matrixes ... but for vector you can't...
13:01:48 <copumpkin> pointwise multiplication? :P
13:01:55 <copumpkin> but I agree, Num is a bit of a pain :)
13:02:13 <IndependentlyTyp> for whch I did fromInteger = error "Not applicable to matrices"
13:02:16 <tromp> @src Num
13:02:16 <lambdabot> class  (Eq a, Show a) => Num a  where
13:02:16 <lambdabot>     (+), (-), (*)           :: a -> a -> a
13:02:16 <lambdabot>     negate, abs, signum     :: a -> a
13:02:16 <lambdabot>     fromInteger             :: Integer -> a
13:02:17 <copumpkin> you could in theory define your own, and import Prelude qualified
13:03:16 <lament> copumpkin: hrm yeah
13:03:21 <lament> copumpkin: signum is problematic :)
13:03:21 <tromp> how does Complex deal with abs,signum?
13:03:22 <kerlo> For square matrices, I'd just make fromInteger be a multiple of the identity matrix.
13:03:33 <copumpkin> I guess fromInteger could just be the 1x1 matrix with that integer in it :P
13:03:36 <copumpkin> or that
13:03:49 <copumpkin> yeah, kerlo's definition might be nicer, but it's still not exactly natural
13:03:53 <sirk390> yes what is strange is that the default Complex type accepts different operators
13:04:12 <IndependentlyTyp> how can I match in Parsec against : some chars, then a space?
13:04:13 <tromp> @src Complex
13:04:14 <lambdabot> data (RealFloat a) => Complex a = !a :+ !a
13:04:18 <lament> "For a complex number z, abs z is a number with the magnitude of z, but oriented in the positive real direction, whereas signum z  has the phase of z, but unit magnitude. "
13:04:24 <kerlo> And then signum could be whatever root of the determinant.
13:04:33 <IndependentlyTyp> and is applicative better than monads for language parsers?
13:04:38 <tromp> @instances Complex
13:04:39 <lambdabot> Couldn't find class `Complex'. Try @instances-importing
13:04:46 <tromp> @instances Num
13:04:47 <lambdabot> Double, Float, Int, Integer
13:04:48 <copumpkin> IndependentlyTyp: Monads are more powerful, but Applicative is enough for CFLs
13:04:59 <kerlo> Square root for a 2x2 matrix, cube root for a 3x3, and so on.
13:05:01 <copumpkin> IndependentlyTyp: and is prettier :)
13:05:07 <kerlo> ...not signum, absolute value.
13:05:11 <copumpkin> yeah
13:05:11 <edwardk> independentlyTyped: you mean like char ':' >> many isAlphaNum >> space   ?
13:05:18 <kerlo> Then you get signum by dividing by the absolute value.
13:05:23 <copumpkin> what about absolute value of nonsquare matrix though?
13:05:57 <edwardk> signum and abs in Num make me sad
13:06:21 <kerlo> I don't like nonsquare matrices.
13:06:34 <copumpkin> most parts of Num make me sad
13:06:40 <kerlo> I wonder how you would define signum and abs for a finite field.
13:07:01 <edwardk> copumpkin: non-square matrices can't be an instance of Num. try to multiply two of them your types will differ if you're sufficiently specific
13:07:21 <copumpkin> yeah, but I don't think most people encode the sizes into the type
13:07:46 <copumpkin> unless it's hmatrix-static
13:07:59 <edwardk> kerlo: there lies the rub. abs is at least a seminorm, and you don't have the requirements for a seminorm in a finite field
13:08:07 <kerlo> I guess if all elements but 0 are roots of unity, you can say that abs is 1 for all nonzero inputs and signum is the identity function.
13:08:26 <edwardk> well, you have the requirements for the trivial seminorm, but that fails the arbitrayr abs * signum rule
13:08:52 <copumpkin> > let x = (1 :+ 5) in abs x * signum x
13:08:54 <lambdabot>   1.0 :+ 5.0
13:09:00 <copumpkin> whee
13:09:24 <copumpkin> > liftM2 (*) abs signum $ 1 :+ 5
13:09:25 <lambdabot>   1.0 :+ 5.0
13:09:32 <kerlo> Is there anything wrong with letting abs be 1 for all nonzero inputs?
13:09:40 <Hunner> @source reverse
13:09:40 <lambdabot> reverse not available
13:09:43 <kerlo> > let x = (1 :: Integer :+ 5) in abs x
13:09:44 <lambdabot>   Not in scope: type constructor or class `:+'Only unit numeric type pattern ...
13:09:52 <copumpkin> doesn't let you use Integers
13:09:55 <kerlo> > let x = ((1 :: Integer) :+ 5) in abs x
13:09:56 <lambdabot>       No instance for (RealFloat Integer)
13:09:56 <edwardk> checking
13:09:56 <lambdabot>        arising from a use of `abs' ...
13:09:58 <copumpkin> it's gotta be a RealFloat :(
13:10:16 <kerlo> C'est la Num.
13:10:53 <edwardk> abs m >= 0 holds. abs m == zero => m == zero holds
13:11:28 <edwardk> abs (m + n) <= abs m + abs n works
13:11:45 <edwardk> r * abs m = abs (r *. m) -- probably breaks though
13:11:57 <IndependentlyTyp> CFLs?
13:11:59 <edwardk> definitely breaks that is
13:12:32 <IndependentlyTyp> kerlo: dont like nonsquare ones? ok well you dont have a chocie always?
13:13:26 <IndependentlyTyp> edwardk: I want to parse a function in my language Jig. it has the form let functioname = ...
13:13:43 <cypher-> can someone point me at a simple lock free concurrent stack in java or another OO language?
13:15:27 <IndependentlyTyp> cypher: #Java can probably
13:15:41 <kerlo> edwardk: what is *.?
13:15:54 <IndependentlyTyp> anything dot
13:16:02 <Botje> simple and concurrent don't seem compatible
13:16:02 <IndependentlyTyp> oh wait nevermind
13:16:15 <cypher-> IndependentlyTyp: sure, I'll ask there
13:16:28 <cypher-> my experience is that haskellers are good at everything, hence I'm asking here ;-)
13:17:40 <IndependentlyTyp> lol so true
13:17:53 <copumpkin> lol
13:19:11 <Jedai> abs minBound :: Int
13:19:16 <Jedai> > abs minBound :: Int
13:19:18 <lambdabot>   -9223372036854775808
13:19:25 <dons> mux: had time to test the platform on BSD?
13:20:30 <IndependentlyTyp> so do i haveb to write my own parser generator or maybe happy is better than parsec?
13:20:47 <IndependentlyTyp> pretty lame if parsec cant do this since it is touted so louldy by the haskell community
13:22:29 <Jedai> IndependentlyTyp: What do you want to do ?
13:23:47 <IndependentlyTyp> write a parser for my language
13:23:49 <IndependentlyTyp> for example
13:23:51 <IndependentlyTyp> function:
13:24:03 <IndependentlyTyp> let <functionanme> = implementation
13:24:12 <IndependentlyTyp> i cant even do this part:
13:24:13 <IndependentlyTyp> let <functionanme> =
13:24:24 <Jedai> I don't see why ?
13:24:33 <Jedai> it's just something like :
13:24:38 <beelsebob> IndependentlyTyp: what's wrong with parseFunction = text "let" *> parseFunctionName <* text "="
13:24:39 <beelsebob> ?
13:26:30 <IndependentlyTyp> let <functionanme> <var1> <var2> =
13:26:37 <Jedai> I would probably use Parsec.Language for something like that and put some token in the mix to accounts for meaningless whitespace but beelsebob proposition is very nice
13:27:11 <copumpkin> Jedai: that's fun
13:27:40 <beelsebob> IndependentlyTyp: parseFunction = text "let" *> (MyLHSConstructor <$> parseFunction <*> manyOne parseVar) <* text "="
13:27:41 <IndependentlyTyp> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4709#a4709
13:27:42 <beelsebob> that?
13:27:57 * beelsebob suggests you stop using monads for it
13:28:08 <beelsebob> while Parsers may be monads, they are best used as applicatives
13:28:36 <IndependentlyTyp> monads generalize applicatives?
13:28:48 <magthe> I can't seem to find a function `linkFile`, similar to `copyFile` but creating (symbolic) link instead... where should I be looking for it?
13:28:50 <Jedai> IndependentlyTyp: "name <- many P.anyChar" ???
13:28:50 <copumpkin> yeah, the monad bit gives the power to be context-sensitive
13:29:00 <IndependentlyTyp> but why doesnt that run into the problem P.many P.anyChar does?
13:29:13 <beelsebob> IndependentlyTyp: http://noordering.wordpress.com/2009/03/31/how-you-shouldnt-use-monad/
13:29:24 <Jedai> IndependentlyTyp: Your function name can contains any character ??? Are you kidding ?
13:29:55 <Jedai> IndependentlyTyp: Of course you'll run into some problem trying to parse something so ambiguous, no matter the means
13:30:36 <IndependentlyTyp> its a draft and that isnt the problem
13:30:47 <IndependentlyTyp> it is that it consuems the hwoel thing
13:31:06 <Jedai> Well it is for me... Sure it consumes the whole thing given that it can
13:31:08 <beelsebob> IndependentlyTyp: yes – that's the problem then
13:31:13 <IndependentlyTyp> so P.space is anyChar?
13:31:14 <beelsebob> if your function names can be *any* character
13:31:18 <beelsebob> then it'll consume the whole thing
13:31:29 <beelsebob> eating up every thing that's *any* character
13:31:35 <beelsebob> looking for the end of the function name
13:32:32 <IndependentlyTyp> a alphaNum works...
13:33:39 <Jedai> IndependentlyTyp: You seems to want something that try every way to make your rule match to the string and tell you if it can... Unfortunately something like that is extremely inefficient
13:34:07 <ksf> Do we have anything like Language.C++, usable for generating code?
13:34:18 <ksf> I know that C++ is a hell to parse, and I don't need to.
13:34:28 <edwardk> kerlo: thats addition for the module over the ring
13:34:34 <edwardk> http://comonad.com/haskell/monoids/dist/doc/html/monoids/Data-Ring-Module.html
13:35:04 <edwardk> head down to 'Normed' where i define normed modules
13:35:37 <edwardk> over arbitrary (left|right)-seminearrings
13:35:41 <copumpkin> what's the probability of one of my ssh public keys containing the string VIGNEON in base64?
13:35:51 <Jedai> IndependentlyTyp: So Parsec doesn't try every which way, you can indicate to it that one rule can fail it will then be a little more forgiving but if you don't it will fail as soon as a rule needed to consume its input to check if it succeeded
13:36:33 <kerlo> Unless this notation is particularly special, r * abs m = abs (r *. m) will usually be false unless r is positive.
13:36:55 * kerlo shrugs.
13:37:12 <Jedai> IndependentlyTyp: But using the try function everywhere is pretty inefficient (since that's equivalent to that hypothetic parser that would try every single possibility)
13:37:21 <copumpkin> ksf: not that I know of... but thoughtpolice was working on a c generation library, maybe he has thoughts
13:37:41 <edwardk> kerlo: nah, because r there would be a semiring like the positive rationals or positive reals
13:37:54 <edwardk> er non-negative
13:38:05 <Jedai> IndependentlyTyp: So instead it's better to be precise in your grammar so that it don't consume everything uselessly
13:39:03 <Jedai> IndependentlyTyp: Of course here your description was very wrong anyway (just think of what it would have matched if you had two definitions in your source)
13:39:08 <edwardk> http://www.springerlink.com/content/h60g6120414v8745/ uses the same general notation/terminology
13:39:36 <edwardk> ah they use an |\lambda x| = |\lambda||x|
13:39:42 <edwardk> i need to update my comment
13:40:43 <IndependentlyTyp> Jedai: but I could try against the different language constructs right(that was what i wa thinking), Function, Struct, etc?
13:40:57 <Chaker> heil jew !
13:41:09 <edwardk> i hate it when i google for something and i'm the top 4 hits
13:42:12 <RayNbow> edwardk: were you googling for comonads? :p
13:42:26 <edwardk> raynbow r-normed modules ;)
13:43:33 <RayNbow> I have no idea what those are :p
13:43:43 * ksf likes polyparse.
13:43:49 <edwardk> you know what an inner product is or a dot product?
13:44:02 * edwardk really needs to finish parsimony. =/
13:44:04 <tsLight> is there any prelude function or so to convert a character, such as 'a', to its literal string representation ("a")?
13:44:09 <copumpkin> :[]
13:44:12 <ksf> less bells+whistles, less complexity, less confusion, less bugs.
13:44:14 <copumpkin> or return
13:44:16 <RayNbow> edwardk: for vectors, yes
13:44:17 <copumpkin> or pure
13:44:30 <copumpkin> > (:[]) 'a'
13:44:31 <lambdabot>   "a"
13:44:35 <copumpkin> > pure 'a'
13:44:36 <lambdabot>       Ambiguous occurrence `pure'
13:44:36 <lambdabot>      It could refer to either `Control.Appl...
13:44:41 <copumpkin> > pure 'a' :: String
13:44:42 <lambdabot>       Ambiguous occurrence `pure'
13:44:42 <lambdabot>      It could refer to either `Control.Appl...
13:44:48 <copumpkin> > Control.Applicative.pure 'a' :: String
13:44:49 <lambdabot>   "a"
13:44:52 <copumpkin> :P
13:45:55 <copumpkin> lol
13:45:58 <IndependentlyTyp> how can I match against a pattern that repeats X times?
13:46:42 <edwardk> RayNbow: ok, generalize to any ring-like structure and any module over that ring. i.e. vectors of naturals, and try to retain the useful properties of the length of a vector. which can be found with |x| = sqrt (x . x) -- in the normal euclidean inner product/dot product you know and move
13:46:52 <applicative_kid> it's hard to find many uses of applicative in heavy monadic code :(
13:47:11 <edwardk> IndependentlyTyp: count 3 isAlphaNum -- or something like that
13:47:11 * applicative_kid wants to be applicative
13:47:17 <edwardk> applicative_kid: is it?
13:47:37 <edwardk> i use very few monads these days
13:47:38 <ksf> I use it all the time.
13:48:04 <ksf> a strategically placed fmap can save you from mentioning monads in many cases.
13:48:10 <copumpkin> dons: do you have any problem with moving the uvector repo to darcs-2 format? I was thinking of converting my repo but it'll break compatibility with yours...
13:48:44 <RayNbow> edwardk: ah ok
13:48:51 <applicative_kid> yes I know but I'm using SDL and most functions are of the form a -> .... -> m a
13:49:03 <ksf> the usual getStrLn >>= return . map toUpper    ->    fmap (map toUpper) getStrLn    thingie.
13:49:23 <ksf> map toUpper <$> getStrLn
13:50:00 <copumpkin> why is <$> in Applicative btw?
13:50:09 <edwardk> RayNbow: basically all you want is a notion of a 'length' of a 'vector-like-thing'
13:50:13 <applicative_kid> copumpkin: infix of fmap
13:50:13 <edwardk> @type (<$>)
13:50:14 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
13:50:17 <Cale> copumpkin: because it goes with <*>
13:50:22 <copumpkin> applicative_kid: I know what it is :P but it doesn't need applicative
13:50:27 <edwardk> its not Applicative, its just in the module and fits the syntax of <*>
13:50:30 <copumpkin> Cale: but it's useful on its own too, just on a regular functor
13:50:32 <ksf> it shouldn't exist, at all, it's the same as (.).
13:50:37 <Cale> It's part of the applicative notation, I suppose.
13:50:42 <Cale> But yeah
13:50:54 <edwardk> ksf: i find the Category definition of (.) more satisfying than the Functor one
13:50:54 <dons> copumpkin: sounds good
13:51:12 <edwardk> and they are unfortunately incompatible =(
13:51:13 <Cale> edwardk: But I've yet to see enough convincing instances.
13:51:29 <Cale> There are *lots* of useful functors which could use the (.) syntax
13:51:46 <Cale> But only a few "Category" instances
13:51:58 <copumpkin> dons: cool, thanks
13:52:02 <edwardk> cale: fair enough. not enough folks using category-extras apparently ;)
13:52:03 <ksf> what's the difference, anyway?
13:52:12 <Cale> (because it's not really a general category, it's something *way* more specific than that)
13:52:22 <ksf> i assumed that the difference is just in the type constraint, same as with map/fmap
13:52:28 <edwardk> though i agree there are a lot more Functors around
13:52:43 <Cale> I like the notion that commonly used things should get the best names.
13:52:47 <ksf> > toUpper . "foo"
13:52:48 <lambdabot>   Couldn't match expected type `a -> Char'
13:52:53 <copumpkin> lol
13:52:53 <ksf> > toUpper <$> "foo"
13:52:54 <lambdabot>   "FOO"
13:53:03 <ksf> that's rubyesque.
13:53:16 <copumpkin> I'm not convinced toUpper . "foo" should work, yeah
13:53:22 <Cale> I am. :)
13:53:27 <copumpkin> although . = fmap is nice
13:53:37 <edwardk> copumpkin: yeah it goes all to hell with overloaded strings =)
13:54:08 <Cale> Oh, well, yes, the interaction with overloaded strings is very strange.
13:54:36 <copumpkin> with overloaded strings, it treats string literals as fromString x ?
13:54:40 <Cale> yeah
13:55:08 <copumpkin> I guess it could be weird if you could figure out a meaningful functor instance for numbers too then?
13:55:12 <Cale> I'm not altogether convinced that the overloaded strings thing is necessary, since you can easily invent a one-character function name for packing, and then you get a syntax like b"foo"
13:55:20 <ksf> ...so you could do compile . "(foo)+"
13:55:29 <ksf> nah, you couldn't.
13:55:38 <Cale> (which is what other languages use)
13:55:39 <edwardk> cale: i really like the clarity of fromString = string -- in a parsec or other style parser.
13:55:48 <IndependentlyTyp> how is an "image" different from a file?
13:55:49 <Cale> That is true.
13:55:58 <Cale> IndependentlyTyp: In what context?
13:55:58 <edwardk> cale: yeah but we're better than them =)
13:56:08 <IndependentlyTyp> smalltalk image
13:56:09 <Twey> > read"3" :: Int
13:56:11 <lambdabot>   3
13:56:15 <Twey> Oh ah
13:56:19 <applicative_kid> how can i make this more applicative 		bgColor		<-	(mapRGB . surfaceGetPixelFormat) screen 0xff 0xff 0xff
13:56:19 <applicative_kid> 		clipRect	<-	Just <$> (getClipRect screen)
13:56:19 <applicative_kid> 		fillRect screen clipRect bgColor
13:56:33 * Twey doesn't like
13:56:37 <Cale> IndependentlyTyp: A smalltalk image is a snapshot of the state of the entire environment you're working in.
13:56:42 <IndependentlyTyp> and should i write my compiler in C? i mean i cant port ghc to a microcontroller can i?
13:57:04 <ksf> applicative_kid, i wouldn't, two binds deserve a do.
13:57:05 <Cale> IndependentlyTyp: Do you plan to compile your compiler on the microcontroller?
13:57:06 <IndependentlyTyp> Cale: so a haskell image would be the whole OS?
13:57:20 <Cale> IndependentlyTyp: Uh... it's not meaningful in the context of Haskell?
13:57:26 <IndependentlyTyp> Cale: hmm i guess i dont have to i could just move the object file?
13:57:36 <Cale> IndependentlyTyp: That's what most people do.
13:57:39 <ksf> otherwise, the visible plumbing is way more involved than the code.
13:57:45 <sinelaw> IndependentlyTyp, what controller is it?
13:58:08 <Cale> IndependentlyTyp: In fact, for such things, I think it's more common to compile the programs you're running on a normal computer, and transfer *those* to the device.
13:58:17 <edwardk> fillRect screen <*> (Just <$> getClipRect screen) <*> (mapRGB . surfaceGetPixelFormat) screen 0xff 0xff 0xff
13:59:35 <edwardk> ksf: what plumbing? =)
13:59:46 <applicative_kid> hmmm i think I need to think more about partial application to find more applications of applicatives
13:59:56 <applicative_kid> :P
14:00:00 <ksf> hm. I just noticed that I never really got to terms with <*>.
14:00:06 <Cale> applicative_kid: Have you looked at Reactive?
14:00:34 <applicative_kid> Cale: I Have it but not used yet
14:01:06 <Cale> applicative_kid: Conal's blog entries about it are educational, though actually using it is required to internalise them properly, I find.
14:01:47 <Cale> (even if only to write very small demos :)
14:02:02 <Gracenotes> it seems there's only either reactive psuedocode or reactive serious-huge-application
14:02:02 <edwardk> ah i think i may have screwed that up, there is a join missing
14:02:04 <applicative_kid> Cale: I'm not sure what you're saying to me, internalise them propertly?
14:02:23 <Gracenotes> unfortunately, simple sample code seems difficult to come by :o
14:02:46 <applicative_kid> *properly
14:02:56 <Cale> applicative_kid: As in, to understand the information in such a way that it's actually useful. More literally, to make it a part of yourself :)
14:03:39 <applicative_kid> Cale: Sorry I feel like I've missed a paragraph or something lol
14:04:12 <Cale> I'll get a link to his blog for you.
14:04:18 <applicative_kid> Cale: i've seen them
14:04:28 <applicative_kid> Cale: i'm just not sure what you're trying to tell me
14:04:43 <applicative_kid> Cale: i'm not using reactive at the moment
14:04:49 <Cale> applicative_kid: I'm saying that in order to fully understand what his blog posts say, you have to actually use the library.
14:05:32 <applicative_kid> Cale: sure but that doesn't mean i can't make my code more applicative in general ;)
14:05:55 <Cale> Right, but Reactive is a lovely example case.
14:06:04 <edwardk> i still think its more interesting to use viewpatterns in monadic code than to use applicative =)
14:06:22 <vixey> f -> x <- g  stuff? :p
14:06:24 <edwardk> foo -> x <- bar baz -- rather than x <- foo <$> bar baz
14:06:29 <vixey> llo
14:06:34 <edwardk> yeah, saves a fmap =)
14:06:39 <copumpkin> zomg
14:06:50 <edwardk> and its really clear that you're getting the x! =)
14:07:23 <Cale> I wouldn't normally recommend setting out to define applicatives or monads or arrows, etc.  It's best just to design a library and then decide if it happens to be an applicative or monad or what-have-you.
14:07:48 <copumpkin> contrafunctor!
14:08:02 <copumpkin> edwardk: what ended up happening to your fancy expansion on folds? :D
14:08:06 <edwardk> i had fun with my parsers by defining a 'free' GADT for applicative and then seeing what i could do to optimize it after the fact
14:08:16 <edwardk> copumpkin: the articles?
14:08:16 <Cale> If it is, then that's nice, but I'm not sure I'd recommend bending your DSL design awkwardly to make it happen.
14:08:24 <copumpkin> edwardk: and associated code!
14:08:31 <IndependentlyTyp> hmm i saw something about a PhD on Chalmers about verifying programs. maybe it had to d with hardware
14:08:36 <edwardk> copumpkin: blog got corrupted had to reload from backups
14:08:39 <IndependentlyTyp> maybe i should go to chalmers?
14:08:40 <copumpkin> oh no :(
14:08:47 <IndependentlyTyp> after high school
14:08:57 <edwardk> copumpkin: so i lost the ones on ana/cata/para and the index
14:09:10 <copumpkin> boo
14:09:14 <IndependentlyTyp> chalmers is well-known abroad?
14:09:15 <edwardk> i resurrected some of it in the knol
14:09:28 <edwardk> IndependentlyTyp: among haskell/type theory types
14:09:43 <applicative_kid> you guys where joking about the view patterns right? :P
14:10:01 <copumpkin> applicative_kid: -> no <-
14:10:01 <edwardk> applicative_kid: actually, i do use it. because it really does save an fmap ;)
14:10:19 <RayNbow> edwardk: I miss your recursion scheme index page actually... too bad it hasn't been cached by web.archive.org and Google
14:10:41 <edwardk> RayNbow: there is always Control.Morphism.*
14:10:59 <ksf> "->" is still one character more than ".".
14:11:21 <IndependentlyTyp> does  file has a endOfFile char?
14:11:31 <edwardk> ksf yeah but fewer traversal of the monadic structure =)
14:12:08 <edwardk> er but one fewer
14:12:35 <edwardk> one day i'll stop typing faster than i think and my words will come across coherently
14:12:45 <roconnor> @remember Lamport Programmers will find any excuse to dismiss an approach that would require them to learn something new.
14:12:45 <lambdabot> Nice!
14:14:05 * RayNbow stumbles upon ContraFunctor... O_O
14:15:03 <ksf> edwardk, aren't there rewrite rules for that kind of thing?
14:15:11 <edwardk> raynbow: data Pred a = Pred (a -> Bool) -- there you go
14:15:22 <ksf> ...or doesn't the complier trust the monad laws?
14:16:43 <edwardk> no rewrite rules for fmap in GHC.Base
14:16:48 <copumpkin> boo
14:17:47 <ksf> so haskell programmers are now honour-bound to use views instead of fmap in the same way c programmers are honour-bound to use >> 1 instead of / 2?
14:18:21 <wli> How on earth are views and fmap remotely comparable?
14:18:31 <Baughn> fmap fmap . fmap
14:18:43 <ksf> only in conjunction with bind.
14:19:06 <RayNbow> edwardk: to be honest, I'm still puzzled :p
14:19:30 <roconnor> fmap fmpa `fmap` fmap
14:19:30 <ksf> foo >>= (\(bar -> baz) ...) == fmap bar foo >>= ...
14:19:43 <Baughn> fmap fmap <$> fmap
14:19:46 <ksf> oh, foo >>= (\(bar -> baz) ->  ...) == fmap bar foo >>= ...
14:19:59 <roconnor> (<$>) (<$>) <$> (<$>)
14:20:04 <dons> ksf: mysterious. where do views come in?
14:20:12 <ksf> the first "->"
14:20:33 <dons> oh, who's proposing that notation? i think you're the first!
14:20:45 <ksf> <vixey> f -> x <- g  stuff? :p
14:20:45 <ksf> <edwardk> foo -> x <- bar baz -- rather than x <- foo <$> bar baz
14:20:48 <edwardk> {-# RULES "fmap id" forall (g :: forall a. a -> a) fmap g = id #-} -- would only replace bottoms with values ;)
14:20:58 <IndependentlyTyp> is: 10 >> 2; faster than 10/2; ?
14:21:04 <edwardk> dons: just using view patterns
14:21:10 * ksf especially likes the hand-of-eris aspect there.
14:21:10 <dcoutts_> dons: that's SPJ's proposal for view patterns
14:21:16 <applicative_kid> and caausing me brain damage
14:21:17 <RayNbow> IndependentlyTyp: depends on the CPU
14:21:24 <dons> dcoutts_: no, i mean in monadic contexts
14:21:35 <dcoutts_> ah
14:21:38 <sjanssen> edwardk: not sure I'm comfortable with RULES on overloaded functions
14:21:42 <edwardk> dons: it works there like anywhere no?
14:21:44 <dons> i've only ever seen views used in:   f (a -> b) = ...
14:21:50 <dons> edwardk: probably.
14:21:57 <edwardk> dons: i've never had a problem with it =)
14:22:01 <sjanssen> I would assume views work in all patterns?
14:22:09 <ksf> the proposal says "patterns", not "function definitions"
14:22:10 <dcoutts_> dons: right, it should desugar ok
14:22:33 <dons> so what's the idea, ksf? to replace uses of fmap with desguared do-notation using views?
14:22:46 <edwardk> its great fun at parties, in arrow sugar...
14:23:08 <ksf> no, we're trying to avoid to write a rewrite rule for fmap.
14:23:20 <edwardk> i mostly use view patterns when i want to kill an named temporary
14:23:28 <edwardk> foo (runWhatever -> (a,b)) = ...
14:24:03 <edwardk> foo m (snoc m -> m') = ...
14:24:10 <edwardk> that last one is particularly evil
14:24:19 <RayNbow> IndependentlyTyp: http://www.gamedev.net/community/forums/topic.asp?topic_id=146697&whichpage=1&#821608 <-- this is about mul vs bitshifting (not about division however)
14:24:45 <RayNbow> btw IndependentlyTyp, x >> 2 is different from x / 2... the former is division by 4
14:25:05 <ksf> IndependentlyTyp, you can convert a lot of divisions to shifts, powers of two being the trivial one-shift-no-xor case.
14:25:45 <ksf> I guess modern cpus already do it internally, so compilers don't have to be as smart as in the past, and programmers can be more ignorant.
14:25:47 <tiglionabbit> argh, I can't get this stuff to work on my mac.  I can't install the nano-hmac package because my mac's openssl library isn't the right one, and I can't figure out how to make cabal use the right one.  So I tried installing everything on macports, but when I install ghc it says "your version of perl probably wont work".  So I tried installing a new version of perl, but it still says it
14:25:50 <wli> Most compilers will do strength reduction automatically.
14:25:50 <Berengal> I keep reading >> as "then"...
14:26:04 <edwardk> ksf: if you're careful about using a signed shift, etc. its amazing how many bugs i've had to fix due to bad manual strength reductions
14:26:14 <RayNbow> btw edwardk, could you give me a hint in constructing contramap for Pred? :)
14:26:53 <edwardk> use fmap ... = Pred (f . g)
14:26:53 <dcoutts_> tiglionabbit: in theory, to specify your openssl headers etc it's just cabal --extra-lib-dirs= and --extra-include-dirs=
14:27:26 <wli> Various compilers will even reduce all sorts of funny bitpatterns into shifts and so on.
14:28:12 <edwardk> raynbow: the (.) goes in the opposite order as for the Functor instance for (->)e
14:29:47 <edwardk> ksf: a lot of folks got into that habit back when compilers like turbo pascal used to spit out absolutely abysmal assembly.
14:30:07 <edwardk> TP in particular used to curl my hair with what it would generate
14:30:12 * ksf hopes view patterns are going to be agressively let-floated
14:30:16 <copumpkin> mmm curly hair
14:31:01 <ksf> I used to get used to it after realising that javac doesn't do it, and that our internal source mangler works on the bleeding token stream.
14:31:13 <ksf> *got used
14:31:25 <edwardk> i love view patterns i just wish there was a more terse syntax for foo (bar -> (x:xs)) = ... foo (bar -> []) = .. when you are using the same viewpattern over and over than reverting to case
14:31:45 <Cale> http://www.qwantz.com/
14:31:56 <vixey> edwardk: I also worry about it computing bar twice
14:32:07 <Cale> ^^ - more about the DNF thing :)
14:32:12 <copumpkin> :P
14:32:20 <copumpkin> that's gotta be the laziest comic ever
14:32:24 <applicative_kid> i haven't read about haskell' view patterns but i'm guessing they are more flexible than F#'s active patterns
14:32:28 <ksf> top-level lets?
14:32:57 <edwardk> vixey: the docs seem to indicate that its smart about that sort of thing
14:33:07 <tiglionabbit> dcoutts_: I tried that, but it still uses the wrong ones
14:33:07 <edwardk> applicative_kid: actually its about the same with worse syntax ;)
14:33:20 <applicative_kid> which one are you saying is worse?
14:33:32 <RayNbow> edwardk: I just had an aha-Erlebnis :p
14:33:35 <edwardk> applicative_kid: the nice thing about active patterns in f# is that you don't have any real 'noise'
14:33:36 <tiglionabbit> dcoutts_: the documentation for cabal says those options add the libraries at the end of the list, not the start, so it prefers the system libraries anyway
14:33:40 <RayNbow> (damn, that took me a while :p)
14:34:00 <tiglionabbit> so I need to mask some libraries or esomething
14:34:33 <edwardk> applicative_kid: foo (Cart x y) (Polar r m) = ... -- and you just go, no 'oh crap i need to shoehorn this view into 30 cases' =)
14:34:46 <Cale> Somehow I imagine that the original graphic for Dinosaur Comics is a windows metafile graphic :)
14:35:17 <applicative_kid> edwardk: they do look more sensible syntatically
14:35:50 <edwardk> applicative_kid: otoh, the (foo -> ...) syntax reuses a hole in the grammar so it doesn't break anyone, and doesn't require a whole new type/kind/whatever for pattern constructors
14:36:02 <edwardk> so i'll take what i can get
14:36:26 <applicative_kid> partial active patterns makes it nice with sub-typing
14:36:34 <edwardk> its just the active pattern stuff is more useful when you want to use the same view for multiple pattern matches
14:37:14 <edwardk> applicative_kid: yeah, but you can do the same here foo (bar -> Just x) = ... ; foo (baz -> Just x) = ...
14:37:22 <edwardk> just uglier
14:38:24 <applicative_kid> shame F# seems  a bit underrated, it's not haskell but it's still pretty nice language in light mode
14:38:35 <edwardk> what mostly saddens me about it is that it forces you to that heavy paren style that feels more MLish than haskellish to me. I'd love to be able to say foo (xs ++ ys) = ... and define a nice view pattern for splitting a container, etc.
14:39:08 <edwardk> applicative_kid: wake me when they add rank-2 types or a module system and then i can write any of the apps i wanted to write in it ;)
14:39:08 <ksf> pattern synonyms are nice, too.
14:39:25 <hatds> pattern synonyms?
14:39:33 <applicative_kid> edwardk: well i doubt that will happen
14:39:47 <edwardk> applicative_kid: sure, but a man can dream ;)
14:39:53 <edwardk> gotta run
14:40:00 <ksf> but then, we might as well get ourselves proper metaprogramming.
14:40:24 <ksf> http://hackage.haskell.org/trac/haskell-prime/wiki/PatternSynonyms  , also in the page about view patterns
14:40:40 <copumpkin> > let f xs:"moo" = xs:[] in f "baamoo" -- :(
14:40:41 <lambdabot>   <no location info>: Parse error in pattern
14:40:51 <copumpkin> actually, that should probably be
14:40:53 <copumpkin> xs []
14:41:27 <Twey> let f (xs : "moo")
14:41:49 <Twey> But it only matches one character before "moo"
14:42:00 <copumpkin> yeah, I want it all! :P
14:42:11 <copumpkin> but my syntax fails anyway :(
14:42:45 <copumpkin> > let f (xs : "moo") = xs [] in f "baamoo" -- is probably what I meant
14:42:46 <lambdabot>   Couldn't match expected type `[a] -> t'
14:43:03 <hatds> I've once wished I had "pattern variables"... so you could define something like "pat = x:xs" and then matching on pat which would bind the names x and xs
14:43:47 <Twey> copumpkin: I doubt it
14:43:51 * ksf wants define-syntax
14:44:04 <Twey> copumpkin: That requires "baa" to be a function, even assuming it would match
14:44:50 <hatds> define-syntax?
14:45:08 <hatds> oh I understand :)
14:45:15 <copumpkin> Twey: well, the idea is that "baamoo" is 'b':'a':'a':"moo" so pattern matching would give me 'b':'a':'a', which would magically get a cons slapped on to make sense, and thus be a function
14:45:21 <hatds> I think that would be confusing to anyone else who reads you program :)
14:45:23 <copumpkin> but I agree, it's pretty far-fetched
14:45:34 <vixey> ksf scheme use then  :p
14:45:37 <ksf> in the end, there's only one solution to the syntax problem: use sexprs and provide define-syntax
14:45:40 <Twey> copumpkin: But that's not what you've got
14:46:21 <Twey> You can't do that ‘magical cons-slapping’; it's nonsensical
14:46:24 <dolio> The only solution to the syntax problem is to force yourself to use bad-looking syntax all the time. :)
14:46:32 <hatds> sometimes too much control is a bad thing
14:46:44 <IndependentlyTyp> a
14:46:44 <Twey> A list is defined around its nil.  Without a nil, a list is nothing.
14:46:55 <ksf> well, you can define-syntax the whole current haskell syntax.
14:47:15 <mgee> hey, lets assume x is a record and has the attributes name and subtitle. instead of writing map (\ x -> (name x, subtitle x)) does map (name &&& subtitle) produce the same result?
14:47:19 <hatds> if I could redefine syntax at will I would be less inclined to question whether my solution is right
14:47:28 <lament> > [1..] -- Twey?
14:47:29 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
14:47:53 <Baughn> @type (&&&)
14:47:55 <lambdabot> forall (a :: * -> * -> *) b c c'. (Arrow a) => a b c -> a b c' -> a b (c, c')
14:48:04 <Twey> lament: It has a nil, or at least it approaches one
14:48:19 <lament> it doesn't, and it doesn't
14:48:29 <ksf> there's going to be some fun involving operator precedence, but otherwise it's straight forward, mindboggingly useful, and, in contrast to TH, invisible.
14:48:39 <Baughn> mgee: Certainly looks like it. name/subtitle are just standard functions, anyway.
14:48:52 <dolio> > [1..80] ++ undefined
14:48:52 <Baughn> mgee: ..well, excepting ghc's disambiguation extension
14:48:53 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
14:48:59 <Twey> Ooh
14:49:00 <dolio> There's no nil in that list.
14:49:06 <mgee> ok thanks guys
14:49:10 <centrinia> > [1..10] ++ undefined
14:49:11 <hatds> mgee: why not just use non-record syntax?
14:49:11 <lambdabot>   [1,2,3,4,5,6,7,8,9,10* Exception: Prelude.undefined
14:49:12 <Twey> That's it
14:49:15 <Twey> copumpkin: HaRP can do what you want
14:49:55 <Twey> lament: It does: it doesn't end because it has no nil to end it
14:50:00 <Twey> It can only end once it finds its nil
14:50:06 <mgee> hatds: i can't change the data structure, it is not my code... i just have to use it in another code portion
14:50:19 <hatds> well that's a good reason :)
14:50:35 <mgee> :)
14:50:39 <lament> Twey: i'm not a philosopher
14:50:54 <copumpkin> Twey: yeah, the magical cons-slapping was pretty ridiculous :P
14:50:59 * inimino sees "magical cons-slapping" and wonders what he missed
14:51:00 <Twey> So what you've got there is basically not a list
14:51:07 * Twey laughs.
14:51:07 <lament> [1..] is not a list?
14:51:23 <centrinia> I think that 1:[2..] is a list.
14:51:32 <hatds> it is
14:51:33 <Baughn> [1..10] is data, [1..] is codata?
14:51:35 <hatds> head [1..]
14:51:38 <hatds> > head [1..]
14:51:39 <lambdabot>   1
14:51:50 <copumpkin> Twey: how about f (c "moo") = c [] in f "baamoo -- should give me "baa" if I can match constructors
14:51:50 <vixey> Baughn: everything is codata
14:51:57 <dolio> [1..10] is codata, and [1..] is data. :)
14:51:57 <Twey> The type-system thinks it's a list, but it's clearly not if you evaluate it all the way
14:52:03 <lament> [1..] is obviously a list in haskell, i guess Twey was arguing on philosophical grounds
14:52:05 <Twey> (for a start, you can't evaluate it all the way)
14:52:15 <lament> Twey: there's no requirement that lists be finite
14:52:16 <roconnor> all haskell types are codata
14:52:19 <Baughn> Twey: Given infinite time?
14:52:33 <QP> can anyone explain why I'm getting a seg fault from the program i've uploaded to hpaste?
14:52:33 <siezer> what is codata
14:52:36 <roconnor> not even that, they are beyond codata
14:52:37 <inimino> if you evaluate it all the way, 1=2
14:52:42 <inimino> (since you can't)
14:52:45 <hatds> Twey: if it looks like a duck and you can pattern match on it like a duck it's a duck
14:52:46 <QP> i'm trying to write a binary file
14:52:48 <roconnor> siezer: greated fixpoint
14:52:48 <Twey> Baughn: * Exception: Maths.undefined
14:52:51 <copumpkin> QP: you gonna make us look up the link ourselves?
14:52:54 <roconnor> siezer: greatest fixpoint
14:53:03 <vixey> how is that roconnor?
14:53:08 <centrinia> Twey, you can still pass infinite lists to a function and get back a result.
14:53:13 <copumpkin> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4710
14:53:15 <centrinia> > head [1..]
14:53:16 <lambdabot>   1
14:53:18 <Twey> copumpkin: Unfortunately (a : b) is the constructor, not (a : b : c : d)
14:53:22 <QP> sorry
14:53:26 <roconnor> vixey: data WTF = WTF (WTF ->  WTF) | ...
14:53:29 <Twey> centrinia: Of course
14:53:30 <QP> my client won't paste...
14:53:31 <copumpkin> Twey: foiled again!
14:53:35 <vixey> hmmm
14:53:40 <lament> roconnor: WTF
14:53:47 <vixey> I think it's still a GFP
14:53:48 <roconnor> lament: exactly
14:53:50 <copumpkin> Twey: how about getting the partially applied constructor out? :P
14:53:54 <copumpkin> this is all hypothetical, of course
14:53:54 <Baughn> Twey: Not.. necessarily. It depends on what you actually do with the list.
14:53:57 <Twey> No
14:53:59 <Twey> You can't do it
14:54:00 <roconnor> vixey: I don't think so
14:54:01 <Twey> Honestly :-P
14:54:04 <copumpkin> :'(
14:54:08 <Twey> The only way to do what you want is to use HaRP, as far as I know
14:54:10 <roconnor> vixey: although I don't know what a GFP is
14:54:17 <vixey> greatxed fixed point
14:54:24 <lament> blessed greased fixed point
14:54:30 <roconnor> vixey: the problem is the functor isn't monotonic
14:54:44 <roconnor> vixey: and in this case there is no fixpoint
14:55:09 * roconnor isn't sure he is making sense
14:55:13 <roconnor> is what I say true?
14:55:16 <Jig> why do you use strict fields in datas?
14:55:27 <Jig> liek data Blah = Blah !Ha !Ga
14:55:28 <RayNbow> =
14:55:28 <dolio> It makes some sense, since type theories typically only deal with strictly positive types.
14:55:30 <copumpkin> QP: you're trying to access the memory at location 42
14:55:31 <RayNbow> ah crap
14:55:37 <QP> what?
14:55:47 <roconnor> I forget what happens when your functor isn't monotonic.  Bad things.
14:55:51 <copumpkin> QP: intPtrToPtr 42 -- ?
14:55:53 <QP> i thought i was writing the value 42 to a file
14:55:55 <hatds> often when you write to data you want to know it isn't a thunk
14:56:12 <dolio> You get to prove false.
14:56:30 <QP> @type intPtrToPtr
14:56:31 <lambdabot> Not in scope: `intPtrToPtr'
14:56:43 <Twey> Let me guess
14:56:50 <roconnor> dolio: oh right.
14:56:51 <Twey> Ptr Int -> Ptr a
14:56:52 <Twey> :-P
14:56:55 <dolio> I'm not sure it makes sense to say there's no fixed point, though.
14:56:57 <Twey> It seems unsafe
14:57:04 <roconnor> vixey: so there is no coinductive principles to go with the data type.
14:57:14 <QP> that's not what it says in the library documentation
14:57:15 <vixey> roconnor:  will in a situation like fix (\i -> i) it's still a fixed point, just a really rubbish one
14:57:17 <roconnor> vixey: which means your "corecurive" functions may not terminate.
14:57:24 <QP> it says IntPtr -> Ptr a
14:57:43 <QP> i'm confused...
14:58:10 <copumpkin> QP: it's converting a number to a pointer
14:58:11 <roconnor> dolio: ya I'm starting to think that.  But I'm not sure.
14:58:22 <copumpkin> QP: it's not giving you a pointer to a number, as far as I know
14:58:35 <centrinia> QP, you could alloca an array, put the Int 42 in it, hPutBuf, and then proceed with the rest of the function. :p
14:58:49 <copumpkin> or you could just use Data.Binary.Put
14:58:50 <dolio> I've never read a paper that specifically mentioned the semantics of non-strictly positive and negative types.
14:58:56 <copumpkin> and not be dependent on the native endianness
14:59:01 <QP> copumpkin: so you say I'm trying to acces RAM at location 42?
14:59:16 <copumpkin> QP: that's what I get out of what I see in the docs and your program
14:59:27 <copumpkin> but I haven't ever used IntPtr before, so can't be sure :P
14:59:39 <copumpkin> a segfault sounds like reasonable behavior though in that case
14:59:39 <centrinia> QP, you are trying to access the logical memory addressed by the address 42.
14:59:40 <dolio> Other than to throw them out because they lead to inconsistent logics.
15:00:01 <QP> logical memory?
15:00:08 <roconnor> @hoogle (* -> * -> *) -> * -> *
15:00:08 <lambdabot> Parse error:
15:00:08 <lambdabot>   --count=20 "(* -> * -> *) -> * -> *"
15:00:08 <lambdabot>                 ^
15:00:09 <Jig> why do you use strict fields in datas?
15:00:11 <Jig> liek data Blah = Blah !Ha !Ga
15:00:12 <roconnor> damn
15:00:13 <centrinia> QP, uh, virtual memory.
15:00:26 <QP> in GHC? or in the OS?
15:00:26 <roconnor> is there a Join for types out there?
15:00:28 <copumpkin> Jig: saves you from writing seq
15:00:32 <centrinia> QP, in the machine.
15:00:34 <copumpkin> Jig: and allows the compiler to unbox it more easily
15:00:57 <QP> what machine?
15:01:09 <copumpkin> QP: you get the point :P
15:01:23 <QP> no i don't---where is the memory?
15:01:36 <copumpkin> in those sticks attached to your motherboard
15:01:36 <QP> is it hardware or software?
15:01:39 <vixey> type Join f a = f a a
15:01:39 <QP> ok
15:01:43 <QP> so hardware
15:01:45 <copumpkin> but not necessarily
15:02:18 <copumpkin> @hackage binary
15:02:18 <lambdabot> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/binary
15:02:18 <centrinia> copumpkin, memory locations may also be used for IO.
15:02:23 <copumpkin> QP: that's your best bet
15:02:27 <copumpkin> centrinia: hence my not necessarily
15:03:51 <QP> well thanks for the help; i'll try Data.Binary.Put next...
15:05:16 <Jig> when writing your own compiler/language, how is a good way to write a spec? I made a draft here:
15:05:17 <Jig> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4711#a4711
15:05:30 <Jig> but anyone know of a simple spec that is a good example?
15:06:41 <centrinia> Here are two specifications for two simple languages: http://barker.linguistics.fas.nyu.edu/Stuff/Iota/
15:07:18 <centrinia> They even have reference implementations.
15:09:23 <Jig> what is Urban Boquist doing today?
15:10:22 <vixey> Jig: R5RS is the best example of a specification
15:10:27 <vixey> Jig: and ALGOL 60 too
15:10:42 <vixey> you sshould read both in detail but that takes a long time
15:12:19 <pejo> Jig, http://www.cs.chalmers.se/~rjmh/jobs-in-fp/programme.htm -- working for Ericsson it seems.
15:14:09 <copumpkin> centrinia: how about unlambda?
15:14:24 <centrinia> Unlambda is too complicated.
15:14:27 <Jig> does functional programming decrease caching?
15:16:55 <nomeata> Hi. With parsec (v3, if it matters), is it expected that when I abort parsing with (fail "Some message"), that the error output still contians information on expected and unexpected input?
15:16:56 <lambdabot> nomeata: You have 1 new message. '/msg lambdabot @messages' to read it.
15:17:40 <centrinia> Can quines have infinite length?
15:18:10 <vixey> you don't really have infinite programs
15:18:34 <vixey> some people study them in theory though...
15:19:09 <centrinia> Wouldn't an infinite list of instructions count as a program?
15:19:28 <lament> centrinia: the standard definition of algorithm involves it being finite
15:19:44 <Berengal> If you consider cat an interpreter (every program is a quite) then an infinite program is an infinite quine...
15:19:56 <Berengal> quine*
15:20:11 <Berengal> yes | cat
15:20:19 <copumpkin> meow
15:20:33 <lament> quines in non-tc languages are not very interesting
15:20:41 <lament> and cat is *particularly* non-tc :)
15:20:50 <Berengal> how about php? ;)
15:21:10 <vixey> oh yeah that reminds me that rule 30 or whatever it was used infinite programs
15:21:13 <vixey> the CA crap
15:21:35 <lament> yeah, it's not quite clear what to do with CA in this context
15:22:12 <lament> you can't really have a finite CA (capable of holding arbitrary memory)
15:22:48 <lament> on the other hand the description of the initial state of the CA can be finite
15:22:57 <lament> which it is for those infinite programs
15:23:23 <lament> so you can say that the infinite CA is generated by a finite program and it's somehow OK
15:23:25 <Jig> does functional programming decrease caching?
15:23:41 <copumpkin> lazy functional programming might
15:23:45 <centrinia> Is there an (infinite) initial state that causes Rule 30 to become periodic?
15:24:01 <dons> Jig: caching in the L2 sense?
15:24:08 <dons> i.e. do FP idioms affect locality?
15:24:18 <Jig> anyway my language will be a haskell inspired replacement for C. manual memory management, pure functions, side-effectful procedures, structs, constannts, address and access instead of pointers.
15:24:20 <dons> adversely, compared to imperative idioms?
15:24:25 <dons> Jig: ah!
15:24:36 <dons> there's quite a bit of work on "Systems Haskell"
15:24:37 <Jig> ?
15:24:42 <dons> e.g. Timber, Hobbit
15:25:06 <Gracenotes> is there a term for "pure except for variable modification"?
15:25:16 <copumpkin> Gracenotes: ST?
15:25:17 <copumpkin> :P
15:25:18 <centrinia> Impure?
15:25:19 <dons> pure + localized memory effects.
15:25:24 <hatds> mutator?
15:25:26 <dons> e.g. ST
15:25:38 <Gracenotes> yeah. ST is an implementation..
15:25:42 <dons> or do you mean unrestricted memory effects?
15:25:54 <dons> can the effect's result escape scope?
15:26:14 <kolmodin> wjt: hi
15:26:19 <Gracenotes> making it so that a variable referring to one thing can be modified to refer to another
15:26:23 <Peaker> Jig: hmm -- that's quite similar to what I (and a couple of coworkers) want to do!
15:26:29 <kolmodin> wjt: yes, I've done some work on a pure D-Bus lib
15:26:34 <Gracenotes> and anything containing that variable will notice the change as well
15:26:46 <Gracenotes> not like accessing raw memory or anything
15:26:49 <kolmodin> wjt: it can call remote objects, and somewhat listen to signals
15:26:58 <centrinia> Gracenotes, callbacks?
15:27:05 <kolmodin> wjt: but not yet expose objects/functions itself
15:27:26 <Peaker> Jig: There's such a huge space for low-level languages around C semantics that seems to be quite unpopulated.. I don't see any reason that typeclass-style vtables cannot be added to C without costing much, and be of much more benefit than C++ vtables. Also parametrized types, existential quantifications, etc
15:27:28 <hatds> IORef a -> IO () :)
15:27:32 <wjt> kolmodin: hrm. it seems like daf got what i started to roughly that stage too
15:27:35 <kolmodin> wjt: unfortunately I've not worked on it in a while, I got stuck with restructuring the code and never finished
15:27:39 <copumpkin> Gracenotes: like a "function" called setGlobalVariable(int newValue); ?
15:27:46 <Gracenotes> centrinia: such that could do Fisher-Yates with it, or something like
15:27:47 <wjt> kolmodin: i know that feeling well
15:28:04 <kolmodin> :)
15:28:20 <kolmodin> wjt: yes, an IDE with refactoring support would be nice... :)
15:28:28 <Gracenotes> I suppose that necessitates not only writable memory, but contiguous blocks of it, e.g. arrays
15:28:49 <daf> kolmodin: heh, that sounds almost exactly where we just got to
15:29:29 <Gracenotes> the supposed difference between strict functional and strict imperative styles in terms of performance, log(n) factor and so on
15:30:02 <daf> kolmodin: I think it would be best if we joined forces somehow, but I'm not sure how to go about it
15:30:17 <tsLight> what was the other function composition operator, different from . ?
15:30:21 <copumpkin> fmap
15:30:25 <applicative_kid> I don't tink you're going to win many people over with a different syntax than C
15:30:29 <copumpkin> tsLight: <<<
15:30:30 <copumpkin> ?
15:30:34 <copumpkin> or >>>
15:30:39 <pejo> Gracenotes, do these factors bother you in practice?
15:30:43 <applicative_kid> i mean people who use C/C++ in particular
15:30:44 <kolmodin> daf: right
15:30:54 <tsLight> thats the one where a <<< b is b . a?
15:31:00 <daf> kolmodin: I guess I should read over your code to see how different the approaches are
15:31:07 <copumpkin> nah, a <<< b === a . b
15:31:13 <kolmodin> daf: I won't have time to work on it in a while
15:31:14 <copumpkin> a >>> b === b . a
15:31:21 <tsLight> ok, thanks :P
15:31:22 <copumpkin> otherwise, you can use fmap
15:31:25 <Gracenotes> pejo: not in the coding I've done... although if I wanted to complete a task in, say, 4 seconds instead of 5, I would switch possibly
15:31:37 <Gracenotes> lazy lists help quite a bit
15:31:40 <Berengal> Hmm, @@IDENTITY doesn't seem to work with HDBC
15:31:44 <daf> kolmodin: it's been testing the limits of my haskell-fu, so it will actually be interesting to see how someone else has done it
15:31:48 <Berengal> Anyone got an alternative?
15:32:02 <kolmodin> daf: aye. I'm not completely satisfied with the current released stuff, but I guess it works
15:32:11 <Gracenotes> and if it needs to scale... which I have done a few times. pulling out ST for a function, like accumulating frequencies
15:32:34 <wjt> kolmodin: where's your actual repository? the one on ohloh is dons' git clone of it
15:32:52 <pejo> Gracenotes, do you truly need lazy lists, or perhaps just circular definitions like ones = 1:ones?
15:33:17 <daf> I get the impression that dons just mirrors stuff so that they can get onto ohloh :)
15:33:24 <daf> (a useful service)
15:33:26 <kolmodin> wjt: a git clone of my work?
15:33:34 <daf> kolmodin: https://www.ohloh.net/p/12245
15:33:58 <kolmodin> daf: http://haskell.org/~kolmodin/code/dbus-haskell/
15:34:00 <copumpkin> I like this: http://blog.inquirylabs.com/2009/05/07/visualizing-typed-functions/
15:34:41 <daf> kolmodin: cheers
15:34:42 <kolmodin> daf: oh I see, nice :)
15:34:57 <Gracenotes> pejo: not necessarily infinite lists, no. lazy lists help because if you have (map f .  filter g . map h $ xs), when you access one element you f.g.h. it, and then the next element f.g.h that, etc. It's like imperative programming where you iterate through single elements, but written in a style like you modify an entire list in an operation
15:35:40 <daf> kolmodin: wow, there are striking similarities :)
15:35:40 <Gracenotes> taking apart the list as you construct it, so that it becomes more of a structure that guides the control flow your code than an actual data structure
15:36:13 <daf> your class Wire is our class DValue
15:36:19 <Gracenotes> plus most algorithms don't require random access
15:36:28 <Gracenotes> that I tend to muck with anyway...
15:36:56 <daf> I uses ReaderT for the endianness
15:36:56 <pejo> Gracenotes, wouldn't deforestation in the compiler solve that problem?
15:37:02 <kolmodin> daf: with the offset counting?
15:37:40 <Jig> why do they add MORE features to C++ ?
15:37:43 <Twey> With deforestation, it really does become a control structure — the list is never actually built
15:37:44 <daf> it's a ReaderT Endianness (StateT Put a) (), IIRC
15:37:46 <Jig> i mean just kill the monster
15:37:58 <Gracenotes> pejo: yeah. But you get the semantics of a pure functional language, of course
15:38:02 <kolmodin> daf: nice, we've used similar approaches then :)
15:38:21 <Twey> I'm half considering learning F#, but the thought of functional programming without my lazy infinite data-structures seems a bit tricky
15:38:28 <daf> kolmodin: one of Get or Put already counts bytes
15:38:30 <Gracenotes> laziness is nice in that regard, the compiler super-optimized it, possibly on demand
15:38:49 <Cale> Jig: perhaps that's the idea
15:38:57 <applicative_kid> Twey: you can have it
15:39:03 <Cale> Jig: Just keep adding features until nobody can stand it anymore
15:39:10 <Twey> Haha
15:39:11 <copumpkin> like c++0x?
15:39:12 <applicative_kid> Twey: lazy lists and lazy sequences
15:39:21 <copumpkin> oh
15:39:24 <copumpkin> I missed the context :P
15:39:25 <Twey> The problem is that people seem to have a very high threshold for that sort of thing
15:39:26 <Jig> how can smething be allowed in ghci but fail in ghc?
15:39:33 <Twey> applicative_kid: In F#?  I thought F# was strict
15:39:36 <hatds> example, Jig?
15:39:45 <Alpounet> F# is strict.
15:39:52 <Twey> Jig: GHCi does some stuff to make interactiveness easier
15:39:53 <Berengal> I generally don't like strict functional languages too much
15:40:00 <Twey> Automatic lifting to IO, for a start
15:40:04 <Berengal> It's too hard to remain pure
15:40:09 <Twey> That can have some impact on types and so on
15:40:11 <kolmodin> daf: Get stores bytes read
15:40:20 <Twey> Berengal: From what I understand, F# doesn't even try
15:40:26 <pejo> Berengal, why?
15:40:27 <applicative_kid> Twey: it is strict by default but you can make infinite data structures with lazy or f# sequences
15:40:27 <daf> kolmodin: right, so we left it out of our equivalent of Unmarshal
15:40:31 <Cale> Automatic lifting to IO? You mean how it applies print to things?
15:40:41 <Twey> Oh right
15:41:00 <Berengal> pejo: pure strict languages are strictly weaker than impure strict or pure lazy languages (pardon the pun)
15:41:02 <daf> kolmodin: we don't really have a master repo, but http://rhydd.org/darcs/haskell-dbus/ is most up-to-date right now, I think
15:41:08 <Twey> Cale: I was thinking more how you could do ‘putStrLn "foo"’ and have it print immediately
15:41:15 <Twey> Bad terminology, probably
15:41:17 <Gracenotes> you can also do something like (str <- openFile "blah.txt") in GHCI
15:41:35 <copumpkin> I thought it was the equivalent of a giant do block
15:41:36 <Gracenotes> which is nice :) that it supports <-
15:41:36 * Twey nods.
15:41:44 <Gracenotes> as sugar
15:41:44 <Twey> copumpkin: Not quite
15:41:48 <Cale> Yeah, GHCi lets you run individual IO actions, which is a little different from how you do things with a compiled program.
15:41:49 <Twey> Kind of
15:42:08 <pejo> Berengal, when was the last time you had that problem?
15:42:09 <copumpkin> Twey: how does it differ? I know it doesn't actually desugar it to bind etc.
15:42:21 <copumpkin> it also does more defaulting doesn't it?
15:42:29 <Twey> Yeah
15:42:37 <Cale> The existence of 'it' is also a little different :)
15:42:45 * Twey nods.
15:42:57 <Berengal> pejo: the last time I programmed python functional style
15:43:16 <Gracenotes> in addition, you tend to run into GHC.Any in ghci
15:43:31 <applicative_kid> Berengal: apart from .NET libraries if you where sticking strictly to pure F# you could stay pure using computation expressions, which is like do notation in F#
15:43:31 <Gracenotes> if you're not careful. polymorphism behaves differently
15:43:41 <Gracenotes> subtly. afaik.
15:43:49 <Twey> Yeah, that's weird
15:43:57 <Twey> I don't know how to handle GHC.Any
15:44:13 <Berengal> applicative_kid: You still run into the problem that some algorithms are weaker in strictly pure langauges than impure or lazy languages
15:44:23 * Berengal goes digging for the paper
15:44:26 <pejo> Berengal, would that problem have remained if you were in a suitable monad?
15:44:37 <defun> Hi. Has anyone here dabbled in the Factor language (or similar languages, like Forth)? If so, what advantages do these languages have over Haskell and vice-versa?
15:44:52 <Twey> defun: They're a completely different species
15:44:56 <Gracenotes> Twey: possibly with existential quantification
15:45:11 <Gracenotes> although that opens up a whole new bag of... coconuts? /mixed idioms
15:45:17 <applicative_kid> Berengal: you need to define weaker here, i'm not disagreeing with you
15:45:37 <Berengal> applicative_kid: Weaker as in higher big-O
15:45:45 <defun> Twey: very helpful...
15:45:45 <vixey> @farmer
15:45:46 <lambdabot> I'm going to down-peddle that aspect.
15:45:48 <vixey> @farmer
15:45:49 <lambdabot> Those are good practices to avoid.
15:45:52 <vixey> @farmer
15:45:52 <lambdabot> It cuts like a hot knife through solid rock.
15:45:53 <Twey> defun: They're not really comparable
15:46:02 <vixey> @farmer
15:46:03 <lambdabot> They are very far and few between.
15:46:18 <applicative_kid> Berengal: ok that makes more sense
15:46:19 <defun> I see. That makes this situation all the more interesting...
15:46:27 <defun> Thanks.
15:46:41 <tsLight> is there any prelude function or so to convert a character, such as 'a', to its literal string representation ("a")?
15:46:43 <Twey> defun: In fact, they're about as different as two programming languages can get
15:46:47 <Gracenotes> @botsmack
15:46:48 <lambdabot> :)
15:46:48 <lunabot>  :)
15:47:02 <Twey> Stack-based languages don't even have ‘functions’
15:47:04 <kolmodin> daf: dbus-haskell has been on hackage, but I requested it to be removed as I thought it was not usable enough/doesn't have a stable API. clearly it's still possible to do some things with it. maybe if I would have left it you wouldn't have had to duplicate the work
15:47:05 <Jig> how do I parse, digits >> maybe a '.' >> more digits `?
15:47:13 <Gracenotes> Twey: everything is a function ;)
15:47:14 <Jig> P.<|> for or
15:47:20 <Gracenotes> like in pointfree style
15:47:28 <Berengal> applicative_kid: ftp://ftp.comlab.ox.ac.uk/pub/Documents/techpapers/Geraint.Jones/FP-1-96.ps.Z
15:47:31 <Gracenotes> applicative style, so to say
15:47:31 <wjt> kolmodin: i started our one ~1½ years ago
15:47:33 <Twey> Gracenotes: Nay, that's not really how it works
15:47:45 <wjt> kolmodin: i didn't have an internet connection, so it being on hackage wouldn't've helped :)
15:47:46 <kolmodin> wjt: aha
15:47:52 <kolmodin> ok :)
15:47:56 <applicative_kid> Berengal: it's okay i know what you're talking about now
15:47:57 <Twey> I mean, you can look at it like that, but it doesn't reflect it very well at all
15:47:57 <Gracenotes> Twey: well, if you look at how Haskell is compiled down... :) it's the principles
15:47:57 <daf> it languished for a while
15:47:59 <wjt> kolmodin: and then life took over and i never got it to a working state
15:48:06 <vixey> tsLight: return can do that
15:48:13 <daf> but I found time to hack on recently
15:48:21 <vixey> tsLight: or \x -> [x]
15:48:31 <Gracenotes> (:[]) (:[]) (:[]) (:[]) (:[]) (:[]) (:[])
15:48:41 <tsLight> vixey, k, I havent learntI/O yet
15:48:45 <hatds> now what are you grinning about? :)
15:48:47 <kolmodin> wjt: right. commit logs shows I worked about two weeks from my initial commit. last commit is about 1.5 years old
15:48:55 <vixey> tsLight: nothing to do with IO
15:48:58 <wjt> kolmodin: again, sounds familiar
15:49:07 <kolmodin> :D
15:49:12 <daf> it's almost uncanny
15:49:13 <Twey> [[[[[[[]]]]]]]
15:49:30 <Twey> Wait
15:49:35 <Twey> [[[[[[(:[])]]]]]]
15:49:41 <Gracenotes> stack languages are entirely applicative in style, though
15:49:50 <Gracenotes> most. without fancy extensions
15:49:58 <SamB> tsLight: what do you want the result for '\n' to be ?
15:50:01 <Gracenotes> there are no explicit variables. they're quite neat
15:50:07 <tsLight> vixey, return has (or so google tells me)
15:50:08 <lament> stack languages are ugley
15:50:09 <kolmodin> wjt: for a neat trick, see src/System/DBus/TH.hs
15:50:13 <Gracenotes> Factor is a neat language, too. quotations are like a bit between lambda abstractions and C macros
15:50:17 <tsLight> SamB, I dont need that, I only have to convert alphabetic characters :P
15:50:20 <vixey> tsLight: it doesn't
15:50:26 <tsLight> vixey, ok :p
15:50:38 <Gracenotes> lament: perhaps so... functions aren't always immediately understandable.
15:51:02 <daf> kolmodin: !!!
15:51:24 <Gracenotes> it requires greater familiarity with a problem domain and implementation... but it is quite flexible. ish.
15:51:29 <lament> Gracenotes: i agree, but they somehow feel more natural - i suspect this is not mere familiarity
15:52:09 <wjt> kolmodin: *blink*
15:52:55 <wjt> kolmodin: that's neat!
15:53:21 <hatds> a stack reifies name scoping
15:53:25 <hatds> maybe?
15:53:34 <kolmodin> daf: it creates a function that takes exactly one argument. that argument is also a function and has the type of a DBus signature
15:53:44 <lament> hatds: name? what name? :)
15:53:53 <hatds> lament: variable names
15:54:29 <kolmodin> daf: it's supposed to help creating/maintaning DBus APIs. of course, I've not written any of those yet, but.... eum... :) anyway, it might be useful
15:54:54 <daf> kolmodin: I guessed it reified D-Bus types somehow
15:54:55 <wjt> kolmodin: so it's a magic thing to let you do generated Haskell bindings for DBus APIs with ~no boilerplate beyond the dbus types, right?
15:55:00 <Gracenotes> :O
15:55:17 <kolmodin> daf: yes
15:55:21 <wjt> tbh. my head is exploding :-)
15:55:32 <kolmodin> wjt: kind of, yes :)
15:56:25 <kolmodin> wjt: of course, if you generate bindings you could also generate the proper types without using TH at all. this is more for hand written bindings
15:56:45 <wjt> ah, right
15:56:58 <mmorrow> here's the explanation of exactly what's going on at the top-level in ghci: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4712#a4713
15:58:33 <sjanssen> kolmodin, wjt: I'm just cominmg into this conversation, are there new DBUS bindings in the works?
15:58:55 <wjt> sjanssen: kolmodin and { daf and i } have independently written haskell reimplementations :)
15:59:02 <kolmodin> sjanssen: there are two (three?) partial implementations :)
15:59:13 <mziulu> (join #lisp
15:59:19 <wjt> sjanssen: have you secretly written a third? :-/
15:59:25 <kolmodin> sjanssen: two pure, and one with bindings to the C lib
15:59:27 <sjanssen> mziulu: hilarious typo!
15:59:38 <sjanssen> wjt: I haven't written any
15:59:42 <wjt> excellent :)
15:59:46 <sjanssen> but some nice DBUS would be useful
15:59:54 <kolmodin> wjt: have you seen this one? http://neugierig.org/software/hdbus/
15:59:57 <daf> kolmodin: hmm, where does getResponse come from?
16:00:09 <daf> kolmodin: we're aware of it, yeah
16:00:16 <mziulu> sjansess: yeah, too bad this morning I made a worse one =D
16:00:27 <kolmodin> daf: ./System/DBus/Message.hs:getResponse :: Connection -> Serial -> IO Message
16:00:28 <sjanssen> eg. I'd like to try to write an automounter using HAL/WhatEverItIsCalledKit
16:00:33 <ziman> on Slovak/Czech keyboard layout these keys are next to each other :)
16:00:51 <kolmodin> aye, a DBus lib would be quite useful
16:00:54 <wjt> yeah
16:00:54 <ziman> are they on the italian one?
16:01:02 <daf> *Kit :(
16:01:17 <wjt> my d-bus sequence diagram tool has a very small C bit to actually do the d-bus :)
16:01:32 <kolmodin> or so I thought a couple of years ago. unfortunately I didn't have a project to give my DBus lib a reason to exist
16:01:48 <daf> kolmodin: aha, right
16:01:57 <sjanssen> so which library should I try to use?
16:02:01 <daf> kolmodin: so we both used a map of serial -> MVar for async calls :)
16:02:34 <sjanssen> daf: it's a good design, xhb uses something like that as well
16:02:35 <daf> kolmodin: why the unsafeInterleaveIO though?
16:02:39 <kolmodin> sjanssen: if mine is continued it'll probably get a new API. I got stuck restructuring it, which is the reason it was put on hold..
16:02:54 <kolmodin> daf: where?
16:03:01 <daf> kolmodin: in getResponse
16:03:24 <kolmodin> daf: ah, right. it only forces a block if the result is going to be used
16:03:41 <daf> oh, right
16:03:42 <kolmodin> daf: so you can do a lot of asyncronous requests as long as they are independant
16:03:59 <daf> hmm, not sure I quite follow
16:04:38 <kolmodin> daf: which is the key to get fast performance. syncronous calls are quite slow. I'm not 100% it's the way to do it though
16:04:46 <kolmodin> daf: it leaks memory if you never use your result
16:04:58 <daf> oh, huh
16:05:18 <daf> how's that?
16:05:58 <daf> sjanssen: the libdbus binding is probably the most complete right now
16:06:01 <kolmodin> or so I recalled. mind you I've not worked on this for almost two years :)
16:06:25 <defun> How would one go about sending some kind of 'signal' or 'input'/'output' directly to a USB port from haskell?
16:06:28 <daf> I was assuming I'd have to make messages you didn't expect a reply to explicit
16:06:44 <kolmodin> daf: mm. maybe it wasn't so bad as I remembered
16:06:46 <daf> sjanssen: but I hope we can merge the two pure ones and have something useful
16:07:08 <daf> kolmodin: I think the main thing we have that you don't is a test suite ;)
16:07:47 <kolmodin> daf: bah! :D
16:08:42 <kolmodin> daf: I've got some tiny examples working :)
16:08:50 <sjanssen> kolmodin: you should be able to do async responses without memory leaks
16:08:57 <daf> which mostly consists of (value, big-endian serialization, little-endian serialization) triples
16:09:09 <kolmodin> sjanssen: right. I'm trying to recall why I thought it was that way
16:09:10 <sjanssen> eg. with MVar (Map SequenceID (MVar AwaitingResponse))
16:09:42 <daf> kolmodin: well, I should go to bed
16:09:47 <daf> kolmodin: what's your timezone?
16:09:49 <kolmodin> sjanssen: right. and if you never collect your response?
16:10:17 <sjanssen> kolmodin: the ID is removed when it is delivered
16:10:24 <kolmodin> daf: Gothenburg, +2
16:10:29 <kolmodin> ?localtime
16:10:32 <lambdabot> Local time for kolmodin is Fri May  8 01:10:23 2009
16:10:40 <daf> kolmodin: ok, I'm in Helsinki
16:10:45 <sjanssen> the client that wants to collect the response later will hold a reference to the MVar AwaitingResponse
16:10:49 <kolmodin> sjanssen: iirc that's the way I do it
16:11:02 <daf> ditto
16:11:06 <kolmodin> sjanssen: sorry for the confusion
16:11:13 <kolmodin> gah, I've got a meeting starting in 8 hours
16:11:14 <daf> actually, I wrote a lookupRemove
16:11:28 <kolmodin> daf: hah, nice :)
16:11:36 <daf> :: [(a, b)] -> a -> Maybe (b, [(a, b)])
16:11:45 <daf> which seems like it should be in Data.Map
16:11:46 <kolmodin> daf: I'll visit Helsinki in ~3 weeks
16:11:59 <daf> :)
16:12:03 <daf> I might still be around then
16:12:14 <kolmodin> daf: it'll be work work work though...
16:12:47 <daf> well, if you find you have time to go to a pub...
16:13:32 <kolmodin> daf: I'd like to, but it might be tight on the schedule. I'll only be there for two days. it'd be cool though :) 1-2nd of June
16:13:37 <kolmodin> preliminary
16:13:47 <daf> well, no worries if you can't
16:13:52 <kolmodin> daf: you don't happen to work for Planmeca, do you? ;)
16:14:04 <daf> kolmodin: heh, no
16:14:13 <kolmodin> daf: ok :)
16:14:18 <daf> kolmodin, wjt: so, what next?
16:14:32 <kolmodin> ok, I've got to go to bed
16:14:35 <daf> I'm not particularly partial to my code given that kolmodin's is so similar
16:14:43 <kolmodin> daf, wjt: nice meeting you guys
16:14:49 <daf> kolmodin: ok, ttyl
16:15:02 <kolmodin> see you, g'night
16:15:11 <wjt> kolmodin: you too!
16:21:08 <applicative_kid> http://www.pagetable.com/?p=64
16:37:41 <Jig> anyone have an implementation of hindley-milner in haskell lying around?
16:38:14 <lament> ghc? :)
16:39:40 <pumpkin_> lol
16:40:26 <Jig> hmm i guess the source code contains it?
16:40:55 <Jig> i guess general implementation doesnt make much sense sinc eit depends on your hmm, ast?
16:41:04 <Saizan> well, yeah, but the typecheker is much more complex to deal with all the extenions
16:41:46 <Saizan> yes, it'll depend on your AST, however most LC ASTs are essentially the same
16:42:35 <Saizan> Jig: have you implemented unification for the representation of types?
16:43:22 <Jig> dont know what that means :P
16:43:27 <Jig> im in over my head here
16:43:35 <Jig> but im gonna jave some sort of typeinference
16:43:45 <yitz> does, say, jhc have a simpler HM implementation?
16:43:56 <Saizan> http://notvincenz.blogspot.com/2008/01/using-typechecker-monad-to-type-check.html <- this is for the simply typed lambda calculus, but it's not hard to extend it with a case for let
16:43:57 <QtPlaty[HireMe]> jave?
16:44:53 <Saizan> yitz: jhc's type checker is quite complex too
16:45:16 <yitz> oh well
16:45:58 <Saizan> for let you use generalize instead of nogeneralize
16:46:18 <Peaker> Jig: simplified explanation of unification, say you have:  id :: a->a ; (+) :: Int->Int->Int  ; 1,2::Int  ;   id (+) 1 2  ;  the application means id has type ((Int->Int->Int)->(Int->Int->Int)). its also known to be (a->b) -- uniting those recursively unites a with (Int->Int->Int) and ditto for b
16:47:46 <Saizan> (an STLC type inferrer is 3 lines of prolog in its simplest form)
16:48:46 <Jig> hmm whats so abd about goto if you constrain your use? i mean it is just recursion really... sure its bad if you jump all over the place but in asm for example it normal do define a proc that moves some stuff to some registers to prepare for the main loop and then in the main loop you use goto to loop the procs inner loop. and if you abolish goto. i mean you dont, it is used under the hood obv.
16:49:17 <Jig> it is jumping between procedures that is bad, not jump itself
16:49:17 <drumking88> hello world
16:49:21 <Jig> you agree?
16:49:50 <Saizan> it's not uncommon to build nice abstractions over horrible primitives
16:50:08 <Saizan> as it can be the case for recursion/functions over goto
16:50:18 <Saizan> however nothing is bad per se
16:50:37 <Saizan> it's just that complex control flow is hard to understand/reason about
16:50:43 <daf> goto isn't recursion
16:50:45 <Jig> yes
16:50:50 * kerlo attempts to write a traversable graph
16:50:50 <Jig> no it isnt recursion
16:50:57 <Jig> but kind of :)
16:51:22 <Jig> tailrecursion and using jumps in procs is almost the same kind of thinking
16:51:26 <Saizan> it's not recursion, but recursion, or just function calls are implemented with goto i.e. jumps
16:52:02 <vixey> what is goto :P
16:52:05 <kerlo> Hmm. Is it possible nowadays to compile GHC using a compiler other than GHC?
16:52:10 <daf> you can argue that current Haskell implementations are all built on horrible primitives
16:52:12 <vixey> Peaker, (unifies)
16:52:22 <kerlo> vixey: he means "shift". :-P
16:52:26 <Saizan> daf: sure, i've used that as premise
16:52:32 <Jig> shift?
16:52:43 <kerlo> Delimited continuations' shift.
16:52:46 <Peaker> Jig: goto's are too unrestricted.. a restricted form of goto is indeed not that horrible
16:53:04 <kerlo> drumking88: welcome back.
16:53:25 <drumking88> thanks Kerlo
16:53:27 <pejo> kerlo, not likely
16:53:39 <drumking88> bit of a haskell n00b here
16:53:52 <dolio> I have a sort of Hindley-Milner implementation somewhere.
16:54:04 <dolio> It's just for the lambda calculus, though. No let or fix.
16:54:31 <Saizan> no let?
16:54:38 <dolio> Nope.
16:54:40 <QtPlaty[HireMe]> where is just a let written in a funny way.
16:54:45 <Saizan> so no polumorphic variables?
16:54:49 <QtPlaty[HireMe]> Is that correct?
16:54:56 <pumpkin_> @src length
16:54:56 <lambdabot> Source not found. Just try something else.
16:55:02 <kerlo> QtPlaty[HireMe]: mostly.
16:55:18 <kerlo> where can get into some places that let can't, but it behaves just as you would expect.
16:55:24 <dolio> Well, it will infer "\x -> x" as something like "a -> a".
16:55:25 <kerlo> Unless there's something silly I'm not aware of.
16:55:49 <Saizan> where belongs to declarations
16:55:50 <Twey> Desugaring where to let also involves desugaring pattern guards to case
16:55:59 <Saizan> while let .. in is part of expressions
16:56:16 <Twey> There's a hidden scope in there, and where is basically a let in there
16:57:00 <hatds> where can refer to the names bound by patterns, but a let wrapped around on a function can't see those names, basically
16:57:07 <Saizan> in desugared form you only have lamdas let and case
16:57:18 * Twey nods.
16:58:37 <lasindi> Forgive me if this is a dumb question, but is it possible to declare a function that takes more than two arguments?
16:58:54 <TomMD> lasindi: Yes
16:58:56 <hatds> yes, like f x y = x+y
16:58:57 <Twey> lasindi: And no
16:59:02 <kerlo> lasindi: taking more than two is as easy as taking two.
16:59:11 <TomMD> Well, no too, but don't confuse the poor fellow.
16:59:13 <kerlo> add3 x y z = x + y + z
16:59:17 * Twey chuckles.
16:59:35 <kerlo> > let add3 x y z = x + y + z in add3 1 10 100
16:59:36 <lasindi> Oh ... that easy
16:59:36 <lambdabot>   111
16:59:39 <Twey> Technically, that's sugar
16:59:40 <lasindi> Okay works :-)
17:00:05 <skorpan> technically, that's haskell
17:00:08 <Twey> ‘add3 x y z = x + y + z’ means ‘add3 = \x -> \y -> \z -> x + y + z
17:00:20 <kerlo> > let (x ??? y) z = x + y + z in (1 ??? 10) 100
17:00:21 <lambdabot>   111
17:00:33 <Twey> i.e. every function takes only one argument and returns a function that takes the next argument
17:00:46 <Twey> That's what enables Haskell's handy automatic currying :)
17:00:55 <Berengal> Mmm, curry
17:00:58 <skorpan> i love it when people always try to come up with the weirdest shit possible to solve a specific problem in this channel
17:01:04 * Twey laughs.
17:01:07 <Twey> It's highly educational
17:01:09 <skorpan> it's like an infinite obfuscated code contest
17:01:16 <hatds> curry and syntactic sugar
17:01:18 <hatds> :)
17:01:24 <Twey> Hehe
17:01:54 * kerlo draws a cute little reference cube, a graph of eight nodes containing a path connecting all of them
17:02:08 <kerlo> Now to represent this graph.
17:02:37 <Twey> [Vertice Node Node] :-P
17:02:42 <Twey> Er
17:02:49 <Twey> [Edge Vertice Vertice] :-P
17:02:51 <Berengal> Reading enterprise documentation is painful
17:02:55 <Twey> (nobody said I was good at maths)
17:03:26 <codebliss> After numerous headaches, and some bad code, I'm finally getting better at using mapM, bind, return, fmap, etc XD
17:03:28 <codebliss> http://haskell.pastebin.com/m5b169e82
17:03:52 <kerlo> I believe you mean "vertex".
17:05:52 <Twey> kerlo: Yes
17:05:53 <marcusb> hi again
17:06:00 <Twey> Nobody said I was good at English either :-P
17:06:07 * Twey curls up in his corner.
17:06:23 <marcusb> in a pattern I can match single characters/list-elements with x:y:z:rest.  can I match multiple character like 10,10,20,rest ?
17:06:37 <Twey> marcusb: Not without HaRP
17:06:53 <kerlo> So, I have this chain of nodes going A, B, C, D, E, F, G, H. Node A is connected to nodes B, D and H. Node B is connected to nodes C and G. Node C is connected to nodes D and F. Node D is connected to node E. Node E is connected to notes F and H. Node F is connected to node G. Node G is connected to node H. Node H isn't connected to anything.
17:06:55 <Twey> Ah, if you're thinking of "10" being a string
17:07:03 <vixey> you can do (10:10:20:rest)
17:07:05 <marcusb> no I mean 10 characters, 10 characters, 20
17:07:05 <Twey> You can match multiple-digit numbers, of course
17:07:08 <Twey> Ah
17:07:09 <Twey> No
17:07:19 <kerlo> marcusb: is this going to be a list like [10,10,20,30,50]?
17:07:25 <Twey> (without HaRP)
17:07:30 <marcusb> so how do you unpack binary data structures elegantly?
17:07:32 <kerlo> Oh, I see.
17:07:38 <vixey> kero:  cube = a <- square ; b <- square ; sequence $ zipWith edge a b ; return ()
17:07:41 <vixey> kerlo*
17:07:44 <Twey> marcusb: With Data.Binary
17:07:50 <Twey> Mostly.
17:07:56 <vixey> :t zipWithM
17:07:57 <lambdabot> forall a b (m :: * -> *) c. (Monad m) => (a -> b -> m c) -> [a] -> [b] -> m [c]
17:08:02 <Berengal> There's also view patterns...
17:08:03 <Twey> It has a Get monad for parsing binary data.
17:08:04 <vixey> yeah zipWithM that's better
17:08:05 <Twey> True
17:08:15 <Twey> I think I prefer the monad, though
17:08:16 <kerlo> I think I'm going to stop thinking out loud now so that people will stop trying to help. :-P
17:08:35 <vixey> kerlo don't like what I said?
17:09:21 <dolio> :t mapAndUnzipWithM
17:09:22 <lambdabot> Not in scope: `mapAndUnzipWithM'
17:09:40 <kerlo> It's pretty much irrelevant, which is understandable, as I didn't really say what I was talking about.
17:09:43 <dolio> Oops.
17:10:03 <Berengal> , (\ (splitAt 5 -> (first, (splitAt 5 -> (second, (splitAt 5 -> (third, rest)))))) -> [first,second,third,rest]) [1..20]
17:10:04 <lunabot>  [[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15],[16,17,18,19,20]]
17:11:10 <marcusb> Twey: thanks, I will check it out.  and I thought a recursive descent parser for a binary format would make a nice elementary exercise
17:11:38 <pumpkin_> I need "first-class constructors" with associated types
17:11:40 <pumpkin_> :P
17:11:49 <pumpkin_> but that probably just means I'm doing something wrong
17:11:59 * pumpkin_ refactors
17:12:02 <Saizan_> ?
17:12:26 <pumpkin_> well, I wanted to match on a constructor of an associated type
17:12:37 <Twey> marcusb: If you want to implement it yourself, then there are always view patterns, indeed
17:12:44 <pumpkin_> so I'd kinda need to substitute a variable into a pattern
17:12:51 <Twey> Or you could just split it inside the function
17:12:58 <pumpkin_> yeah, that was the refactoring :P
17:13:21 <Twey> pumpkin_: *blink* *blink*
17:13:35 <pumpkin_> oh, it was relevant for me too :P
17:13:38 <Twey> Haha
17:13:38 <marcusb> Twey: I think that learning the good practices is more important at this step ;)
17:13:46 <Twey> I know — weird coincidence
17:13:48 <kerlo> Does "class Differentiable a b | a -> b where . . .; type D a = forall b. (Differentiable a b) => b" look all right?
17:13:57 <pumpkin_> :)
17:14:16 <Twey> marcusb: Good practice would be to not reinvent the wheel and just use Data.Binary.Get :-P
17:14:29 <marcusb> that's what I am looking at now :)
17:14:53 <Twey> Failing that, it's a toss-up whether you want to go for the non-H98-but-arguably-nicer view patterns or the good ol' standby
17:15:07 <Berengal> You could probably do it as a fold...
17:15:17 <pumpkin_> these lazy uvectors are proving to be complicated
17:15:18 <Twey> That's a point
17:15:25 <Twey> Mmm folds
17:19:38 <Berengal> > reverse $ foldr (\n (r,acc) -> let (h,t) = splitAt n r in (t,h:acc)) ([1..20],[]) (reverse [1,1,4,3])
17:19:39 <lambdabot>   Couldn't match expected type `[a]'
17:19:46 <Berengal> ack
17:20:41 <Berengal> > reverse $ uncurry (flip (++)) $ foldr (\n (r,acc) -> let (h,t) = splitAt n r in (t,h:acc)) ([1..20],[]) (reverse [1,1,4,3])
17:20:42 <lambdabot>       Occurs check: cannot construct the infinite type: a = [a]
17:20:42 <lambdabot>        Expect...
17:20:45 <Berengal> :(
17:21:45 <Peaker> Berengal: where's the 2nd arg of foldr?
17:22:05 <Berengal> > reverse $ uncurry ((++).(:[])) $ foldr (\n (r,acc) -> let (h,t) = splitAt n r in (t,h:acc)) ([1..20],[]) (reverse [1,1,4,3])
17:22:06 <lambdabot>   [[1],[2],[3,4,5,6],[7,8,9],[10,11,12,13,14,15,16,17,18,19,20]]
17:22:28 <kerlo> Hmm, there's a bit of a problem here. The context I want is not a Graph a with an a-shaped hole in it but a Graph a with a Graph a-shaped hole in it.
17:22:31 <Berengal> The foldr always worked, but reconstructing it into a list again was a bit silly
17:22:58 <Berengal> Actually, the whole fold is silly...
17:23:30 <kerlo> And there can be arbitrarily many holes, as well.
17:23:45 <kerlo> It's almost enough to make a person use (Graph a -> Graph a).
17:24:03 * kerlo does that
17:24:17 <Berengal> Peaker: The second arg of the foldr was the ([1..20],[]) bit
17:24:38 <Berengal> With the [1..20] being the actual list operated on
17:28:07 <defun> Can haskell be cross-compiled to RISC (8-bit)?
17:28:32 <mmorrow> kerlo: you can use a newtype to get the infinite type you might be looking for
17:28:43 <kerlo> I think I have a solution.
17:29:36 <kerlo> Hmm, no, I don't.
17:30:19 <kerlo> Okay, call this a puzzle.
17:33:55 <pumpkin_> how can I get ghci to start with the equivalent of :m + x (just from the command line, not from .ghci)
17:34:34 <kerlo> Create a "traversable graph" type: a value of this type holds a graph and a pointer to one of the nodes. There's a function that moves the pointer from one node across an edge to another node; a function that deletes an edge; a function that adds an edge going from A to C given an edge from A to B and one from B to C; a function that creates a new node from the current one and an edge to it; and a function that changes the value at the current node.
17:35:23 <vixey> kerlo use ST for the mutation
17:35:49 <mmorrow> i'd use a zipper on the graph
17:35:56 <vixey> why
17:36:14 <mmorrow> because then you don't have to mutate in ST
17:36:28 <vixey> but mutation in ST is good
17:36:45 <mmorrow> vixey: http://www.cs.tufts.edu/~nr/pubs/zipcfg-abstract.html
17:36:47 <vixey> isn't it ?
17:37:32 <mmorrow> it's not that it's bad, you just then have to deal with mutation
17:41:07 <kerlo> I don't know how ST works; it might be possible.
17:41:34 <kerlo> I suspect that using a zipper would be much easier if it were a tree, but since it's a graph, I don't know how to do that.
17:43:56 <mmorrow> (IntMap IntSet) is a mighty speedy graph rep
17:44:28 <mmorrow> data ZipG = ZipG {focus :: Int, graph :: IntMap IntSet}
17:45:50 * wli has been using something similar to that, albeit with the edges embedded in something that can carry vertex labels, and then edges also in an Intmap.
17:45:55 <vixey> that's wiked, mmorrow
17:46:02 <vixey> the zipper graph paper
17:47:04 <wli> type VertexSet vertLabel = IntMap (vertLabel, IntSet) ; type EdgeSet edgeLabel = IntMap (edgeLabel, Int, Int)
17:47:06 <mmorrow> so edges (A,B) and (B,C) are ==> (42,903), (903,12), so you IM.insertWith IS.union 42 (IS.singleton 12) g
17:47:22 <mmorrow> vixey: totally, i like it a lot too
17:47:55 <mmorrow> newtype G = G (IntMap (Int, IntMap [Int]))
17:47:59 <mmorrow> etc
17:48:09 <mmorrow> so many variation with maps
17:50:30 <mmorrow> vixey: here's my current implem of that http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=2361#a2361
17:50:59 <wli> Well, I like what my representation allows one to do with labels.
17:51:22 <vixey> mmorrow: btw you know   A --> B --> C  reduced to  A --> C  is (it happens everywhere there is a 'B' with exactly one in and one out edge) -- is that transitive reduction?
17:52:31 <mmorrow> vixey: hmm. i think transitive reduction would be like, mapping [(0,4),(0,7),(4,7)] ==> [(0,4),(4,7)]
17:52:54 <vixey> ok so it's slightly different than what  I said?
17:53:03 <wli> Maybe even data Graph vertexLabel edgeLabel = Graph { vertices :: IntMap (vertexLabel, IntSet), edges :: IntMap (edgeLabel, Int, Int) } deriving (Eq, Ord, Read, Show)
17:53:13 <vixey> you've taken out 'redundant' edges
17:53:19 <mmorrow> i think, i'm trying to figure out how to say what you said in a sentence
17:53:24 <vixey> where as I took out 'redundant' nodes
17:53:32 <mmorrow> yeah, hmm
17:53:35 <vixey> (of course they aren't /really/ redundant but I don't really know what to call them)
17:55:02 <mmorrow> hmm, maybe if you take the graph, then think of edges as the nodes, and vertices as the edges, it'd be opposite-transitive reduction
17:55:03 <marcusb> readFile returns a String but Data.Binary wants a ByteString.  how can I marry the two?
17:55:20 <mmorrow> (or something :)
17:55:34 <mmorrow> @hoogle readFile
17:55:34 <lambdabot> Prelude readFile :: FilePath -> IO String
17:55:34 <lambdabot> Data.ByteString readFile :: FilePath -> IO ByteString
17:55:34 <lambdabot> System.IO readFile :: FilePath -> IO String
17:55:35 <pumpkin_> marcusb: the bytestring module has its own readfile
17:55:35 <dolio> Use readFile from the ByteString library.
17:55:47 <vixey> you can take the dual of a planar graph but not sure about nonplanar ones
17:55:59 <marcusb> urgs
17:56:16 <marcusb> not one to judge early, but isn't that kinda lame? O:-)
17:56:43 <dolio> What do you propose?
17:56:46 <pumpkin_> think of modules as super typeclasses and it becomes super pretty
17:56:46 <pumpkin_> ;)
17:56:57 <mmorrow> vixey: i was think in the sense that in (? -a-> 0 -b-> ?), you take 0 as the edge between the nodes 'a' and 'b'
17:57:06 <marcusb> dolio: is this an encoding issue?
17:57:19 <pumpkin_> marcusb: a different representation and goal
17:57:29 <mmorrow> vixey: (is that the same sense that taking the dual of a graph is wrt planar/nonplanar/whatnot ?)
17:57:36 <vixey> no
17:57:54 <marcusb> but a list of octets is a list of octets is a list of octets
17:57:58 <mmorrow> vixey: hmm
17:58:03 <marcusb> unless a String ain't a list of octets of course :)
17:58:17 <marcusb> (Unix: everything is a file)
17:58:17 <mmorrow> , maxBound :: Char
17:58:19 <lunabot>  '\1114111'
17:58:22 <marcusb> ok
17:58:30 <mmorrow> a char is 32 bits
17:58:42 <vixey> lets say we have 0 --a-> 4; 0 --b-> 7; 4 --c-> 7
17:58:56 <mmorrow> ok
17:58:59 <vixey> the dual would be..?
17:59:12 <vixey> a --4-> c
17:59:12 <mmorrow> which dual are we talking about now? :)
17:59:16 <vixey> your one
17:59:22 * marcusb goes back moving stones from corner to the other and back
17:59:24 <mmorrow> oh, ok, so
17:59:53 <mmorrow> vixey: yeah, exactly, a --4-> c
18:00:12 <vixey> that's losing way too much information though
18:00:14 <mmorrow> (would be the fragment of it we can see there)
18:00:51 <mmorrow> vixey: i'm not sure it is, since you could always just flip back and get the graph you started with
18:01:06 <dolio> You could have 'StringClass s => FilePath -> IO s' I guess. But that hasn't been done.
18:01:33 <dolio> You'd probably get some significant pressure trying to work that into the core libraries.
18:01:45 <marcusb> dolio: I know it makes sense, but part of me just wants to go back to 8 bit ASCII
18:03:20 <Jedai> marcusb: You means 7 bits :)
18:03:21 <dolio> Designing an appropriate StringClass that satisfies everyone would be a huge endeavor.
18:03:47 <marcusb> Jedai: hell no, 7 bit bytes are horrible ;)
18:04:01 <Berengal> But ASCII is 7 bits...
18:04:07 <Jedai> marcusb: Well bytestring is close to what you ask
18:04:43 <dolio> Anyhow, ByteStrings aren't even a list of octets, if by list you mean data List a = [] | a : List a.
18:05:02 <marcusb> I don't care what you put in the 128-255 range ;)
18:05:05 <dolio> Lazy byte strings are lists of packed arrays of bytes, and require some fanciness to get input speed to not suck.
18:05:27 <Jedai> marcusb: combined with Data.Binary it's quite nice
18:05:34 <dolio> Which is why they exist, since speed of String sucks.
18:05:38 <marcusb> remember this is my first day with haskell
18:05:42 <marcusb> I've a long way to go
18:06:10 <lasindi> Hi everyone, could someone explain why Haskell has a problem with this function definition?
18:06:11 <lasindi> isfromto (n1,n2) n3 n4 = ((n3 == n1) and (n4 == n2))
18:06:31 <vixey> lasindi what error does it give?
18:06:32 <Berengal> lasindi: '&&', not 'and'
18:06:36 <lasindi> It's complaining about "didn't match expected type 't1 -> t2 -> t' against inferred type 'Bool'
18:06:38 <lasindi> Oh
18:06:49 <lasindi> That's simple enough :-)
18:06:56 <Berengal> @type and
18:06:57 <lambdabot> [Bool] -> Bool
18:07:31 <Berengal> lasindi: Also, infix functions need to be written in backticks, like '4 `elem` [1..10]'
18:07:55 <Berengal> (Not that an infix function is what you want here)
18:08:35 <Berengal> ((Except operators are infix functions already.... I'll shut up now))
18:08:48 <lasindi> Okay that makes sense, thanks!
18:09:36 <marcusb> so, am I to refer to such string types as Data.ByteString.Lazy.Internal.ByteString ?  that's a mouthful
18:10:25 * pumpkin_ craves TH for his current task
18:11:51 <Cale> marcusb: It's really okay to say lazy ByteString :)
18:11:58 <marcusb> in the code I mean :)
18:12:06 <pumpkin_> w00t
18:12:07 <pumpkin_> Prelude Data.Array.Vector> sumLU $ toLU [1..10]
18:12:07 <pumpkin_> 55.0
18:12:09 <marcusb> I want to wrap the decode function
18:12:11 <Cale> marcusb: You can import modules with different names.
18:12:26 <marcusb> and the "internal" is not reason to worry?
18:12:31 <Cale> import qualified Data.ByteString.Lazy as BL
18:12:48 <marcusb> but I need to import Internal to get the type
18:12:49 <Cale> You probably aren't meant to import the Internal modules -- are those even visible?
18:12:54 <pumpkin_> marcusb: nope
18:12:57 <Cale> Oh, really?
18:13:03 <marcusb> well, how else can I define functions operating on those strings?
18:13:11 <pumpkin_> marcusb: the outer .Lazy re-exports ByteString from Internal
18:13:17 <marcusb> mpfh
18:13:19 <pumpkin_> so you don't need to think about the .Internal package
18:13:20 <marcusb> ah
18:13:20 <marcusb> ok
18:13:29 <pumpkin_> *module :P
18:13:31 <marcusb> I only imported readFile because I got an ambiguity on "head"
18:13:51 <Cale> Ah, it's meant to be imported qualified, probably with a better name.
18:14:01 <marcusb> ok
18:14:05 <Cale> import Data.ByteString.Lazy as B
18:14:07 <Cale> er
18:14:11 <Cale> import qualified Data.ByteString.Lazy as B
18:14:15 <marcusb> I didn't know what qualified is, but I can guess what it does
18:14:28 <marcusb> it's the opposite of "using"
18:14:30 <Cale> It forces usage of B.foo to refer to foo in that module
18:14:38 <pumpkin_> pretty much
18:15:04 <marcusb> much nicer now :
18:15:31 <Cale> I also often like to import specific bits of a module unqualified (types especially)
18:15:49 <Cale> like, so on the next line after the qualified import, write something like
18:15:58 <Cale> import Data.ByteString.Lazy (ByteString)
18:16:07 <marcusb> so I can import twice, good
18:17:51 <Cale> Data.Set, Data.Map and Data.Foldable expect a similar situation, since they define a lot of names which are also used in the Prelude.
18:23:30 <dolio> But really, Foldable should be in the prelude. :)
18:25:58 <mdmkolbe> How do I convince lhs2TeX to tell LaTeX to not page-break across \begin{code}\end{code}?
18:26:55 <Jig> hmm do you think writing my own compiler could get me into a good uni alone?
18:27:06 <lasindi> Is there any easier way to pick out the second element of a tuple (x,y)  than (\(x,y) -> y) (x,y)
18:27:08 <SamB> mdmkolbe: well, you could try convincing it to break at some other spot ...
18:27:25 <SamB> by inserting hints that you wouldn't terribly mind at those places
18:28:25 <Saizan_> lasindi: for 2-tuples there's snd
18:28:32 <Saizan_> > snd (1,2)
18:28:34 <lambdabot>   2
18:28:53 <lasindi> Saizan_: Great, thanks!
18:43:59 <pumpkin_> whee, I added (semi-)efficient streamLU
18:44:11 <pumpkin_> but I have a bad feeling
18:46:16 <pumpkin_> boo, I don't want to have to rewrite the entire stream type too
18:48:48 <pumpkin_> :(
18:50:50 <Berengal> hdbc converts bools to string???
18:53:00 <pumpkin_> oh I think I know what to do
18:53:32 <pumpkin_> I can remove explicit length from the current stream and wrap it in something else for explicit length
18:53:38 <pumpkin_> whee!
18:55:34 <Jig> am i the onyl one that think all the applicative stuff make shaskell look like perl? i have a hard time remembering what they do. do each have a real name?
18:56:04 <pumpkin_> <*> is ap if you don't mind Monad
18:56:15 <pumpkin_> and <$> is just fmap/liftA/liftM
18:56:54 <Berengal> I like applicative
18:56:59 <pumpkin_> me too
18:57:03 <Berengal> As long as you don't abuse it
18:57:05 <Jig> ap?
18:57:10 <Berengal> @type ap
18:57:11 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
18:57:18 <Berengal> "apply"
18:57:25 <Jig> is it EXACTLY the same as fmap?
18:57:27 <vixey> Ihate applicative gr!!
18:57:29 <pumpkin_> no, it's <*>
18:57:31 <Axman6> i haven't found a use for it yet. though i haven;t had much time to do anything with haskell recently anyway
18:57:31 <Saizan_> no
18:57:36 <Berengal> @type fmap
18:57:37 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
18:57:52 <Saizan_> fmap f x = pure f <*> x
18:57:54 <Berengal> There's a fundamental difference between fmap and ap
18:57:55 <Saizan_> not the same
18:58:30 <Berengal> You can get fmap from ap (as Saizan_ showed), but not the other way around
18:59:02 <Jig> > fmap (+1) (Just 5)
18:59:03 <lambdabot>   Just 6
18:59:08 <Jig> > <*> (+1) (Just 5)
18:59:09 <lambdabot>   <no location info>: parse error on input `<*>'
18:59:12 <Saizan_> also fmap works for more types, since not all instances of Functor can be made instances of Applicative
18:59:14 <Jig> > (<*>) (+1) (Just 5)
18:59:15 <lambdabot>   Couldn't match expected type `(a -> b) -> a'
18:59:17 <Jig> ?
18:59:20 <pumpkin_> can't you get ap from fmap if you have join?
18:59:27 <Saizan_> > (<*>) (Just (+1)) (Just 5)
18:59:28 <lambdabot>   Just 6
18:59:33 <Draconx|Laptop> pumpkin_, yes.
18:59:47 <Saizan_> Jig: <*> expects both arguments inside the applicative
18:59:50 <Berengal> join gives you bind, which gives ap easily
18:59:54 <Draconx|Laptop> pumpkin_, fmap + join is sufficient to define a monad.
18:59:58 <pumpkin_> yeah :P
19:00:05 <Saizan_> + return
19:00:08 <EvilTerran> Draconx|Laptop, + return
19:00:15 <Draconx|Laptop> er, yeah.
19:01:58 <Berengal> > (\a b c d -> a + b + c + d) <$> Just 1 <*> Just 2 <*> Just 3 <*> Just 4
19:01:59 <lambdabot>   Just 10
19:02:11 <Berengal> > (\a b c d -> a + b + c + d) <$> Just 1 <*> Nothing <*> Just 3 <*> Just 4
19:02:12 <lambdabot>   Nothing
19:02:47 <EvilTerran> > Nothing <*> Just 1
19:02:49 <lambdabot>   Nothing
19:03:01 <Berengal> > Just 1 *> Just 2
19:03:03 <lambdabot>   Just 2
19:03:06 <Berengal> > Nothing *> Just 2
19:03:08 <lambdabot>   Nothing
19:03:12 <adamvo> I want deriving clauses for Traversable et. al.!!
19:03:22 <adamvo> isnt *> just >> ?
19:03:29 <Berengal> Yes
19:03:39 <Berengal> > Just 1 <* Nothing
19:03:40 <lambdabot>   Nothing
19:03:47 <adamvo> :type <<
19:03:57 <adamvo> :t <<
19:03:58 <lambdabot> parse error on input `<<'
19:04:00 <adamvo> :t (<<)
19:04:01 <lambdabot> Not in scope: `<<'
19:04:08 <Berengal> @type (<*)
19:04:09 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f a -> f b -> f a
19:04:25 <pumpkin_> x allo <- x/ =<< oi
19:05:23 <Berengal> ‮getLine >>= putStrLn
19:05:28 <Cale> http://thedailywtf.com/Articles/Sponsor-Appreciation,-Cabling-Confusion,-Dividend-Bling,--More.aspx#Pic10 -- ahahaha
19:05:52 <kerlo> Is there a comonad for IO?
19:06:19 <SamB> kerlo: not a safe one!
19:06:23 <Cale> kerlo: It doesn't naturally form a comonad
19:06:26 <Twey> Yeah, saw that :-D
19:07:03 * SamB is happy that his kernel patch was accepted by the subsystem maintainers: http://repo.or.cz/w/linux-2.6/x86.git?a=commitdiff;h=975e5f45500dff6d15c0001bb662e9aac0ce0076;hp=bf293c17b26b8854241df08b9b63f7270cbde012
19:08:04 <blackh1> SamB: Once I had a kernel patch accepted that was even shorter than yours!
19:08:21 * wli has had long and short patches accepted.
19:08:37 <blackh1> SamB: Congratulations, by the way!
19:08:46 <SamB> wli: you, my friend, are a professional kernel hacker -- I should hope so!
19:08:59 <wli> Congrats BTW.
19:09:15 <SamB> blackh1: I think the key was putting "x86:" at the very beginning of the commit message ;-)
19:09:20 <SamB> thanks!
19:10:28 <ivanm> why are we congratulating SamB?
19:10:48 <SamB> ivanm: got a kernel patch accepted by the x86 subsystem maintainers, as linked above
19:11:01 <ivanm> SamB: I just came in ;-)
19:11:11 <SamB> http://repo.or.cz/w/linux-2.6/x86.git?a=commitdiff;h=975e5f45500dff6d15c0001bb662e9aac0ce0076;hp=bf293c17b26b8854241df08b9b63f7270cbde012
19:11:12 <ivanm> first thing I saw was blackh1 trying to out-patch you :p
19:11:29 <SamB> blackh1: so what did your patch do?
19:11:31 <ivanm> wli: are you really a professional kernel hacker?
19:11:45 <Saizan_> "my patch is smaller than yours"?
19:11:52 <blackh1> SamB: I'm trying to find it... It fixed a denial-of-service in ppp
19:12:22 <ivanm> SamB: in terms of a user, what does that patch do?
19:12:47 <SamB> ivanm: oh, not much except helps out people who are trying to write vm86(2)
19:13:05 <ivanm> which is?
19:13:18 <SamB> well, what I have so far is: http://repo.or.cz/w/man-pages/vm86.git?a=blob;f=man2/vm86.2;hb=HEAD
19:13:33 <ivanm> (wikipedia is a bit slow atm...)
19:14:02 <SamB> ivanm: vm86(2) is the manpage for the system call that dosemu uses to get the CPU to emulate real-mode
19:14:14 <ivanm> *nod*
19:14:29 <SamB> if you look at the one on a typical system, you will discover ... well, not much!
19:14:39 <edwardk1> @quote SamB The kernel may become displeased if the interrupt is not handled in a timely fashion.
19:14:39 <lambdabot> No quotes match. There are some things that I just don't know.
19:14:42 <edwardk1> er
19:14:47 <SamB> which is why I'm working on it ;-)
19:14:51 <edwardk1> @remember SamB The kernel may become displeased if the interrupt is not handled in a timely fashion.
19:14:51 <lambdabot> Done.
19:15:01 <ivanm> SamB: heh
19:15:12 <ivanm> that explains why I couldn't find anything ;-)
19:15:38 <SamB> about the most useful piece of information there is that dosemu uses it, I guess
19:16:21 <edwardk1> most of the rest of the world are just slowly waiting for the need for DOSEMU to die i guess ;)
19:16:24 <SamB> because the dosemu-dev mailing list is where I've been getting the most help with this
19:16:33 <marcusb> how to fix that: when using Data.Binary.Get.getBytes in my binary interface I get:
19:16:33 <marcusb>     Couldn't match expected type `ByteString'
19:16:33 <marcusb>            against inferred type `Data.ByteString.Internal.ByteString'
19:16:55 <SamB> edwardk: well, in time, dosemu may outgrow the need to actually use the syscall
19:17:04 <SamB> but it uses the interface internally even then ;-)
19:17:32 <SamB> well, I mean, it doesn't use it on x86_64, because it doesn't work there ;-)
19:17:45 <Twey> « When specifying long timeouts, be careful not to exceed maxBound :: Int. »
19:17:47 <SamB> maybe some day it will work even on big-endian computers
19:17:49 <Twey> http://www.haskell.org/ghc/docs/latest/html/libraries/base/System-Timeout.html
19:18:02 <Twey> If we have to note that, shouldn't we be using an Integer?
19:18:04 <Saizan_> marcusb: it's a mismatch between normal and .Lazy ByteString
19:18:16 <Saizan_> marcusb: they are called with the same name but are different types
19:19:11 <marcusb> there is a normal ByteString, too?  man...
19:19:42 <Twey> Well, the Lazy is the ‘normal’ bytestring, in Haskell :)
19:19:58 <marcusb> so I have to use L.ByteString everywhere?
19:20:05 <Twey> But yes, that's why most people import them qualified as LB.ByteString and SB.ByteString
19:20:33 <Twey> You don't have to
19:20:43 <Twey> You can hide the strict ByteString, if you're not using it
19:20:43 <marcusb> jesus
19:20:51 <Twey> I would probably say it's clearer, though
19:20:59 <marcusb> why do I have to know which parts use lazy and which non-lazy bytestrings?
19:21:13 <Twey> It's your code, no?
19:21:20 <marcusb> I didn't write the libraries
19:21:39 <Twey> The libraries ought to be consistent in their usage
19:21:51 <marcusb> welcome to my world :)
19:21:53 <Twey> Either it's strict, or it's lazy
19:22:07 <Twey> You shouldn't be mixing and matching, IMO
19:22:27 <Twey> Especially not in the API
19:22:34 <marcusb> Twey: I don't know what I am doing, I just want to read a couple of octets from a file
19:22:39 <marcusb> this is way too hard, let me tell you
19:22:51 * SamB is so happy to find his patch upstream, he goes to bed now ;-)
19:22:55 <marcusb> ok, let's try to get this straight
19:24:19 <marcusb> ok
19:24:55 <marcusb> Twey: the inconsistency is "getBytes" and "getRemainingLazyByteString", the latter is, well, lazy.  the name gives it away, I guess :)
19:25:11 <marcusb> it's all just bytes to me...
19:25:11 <Twey> Oh, well, yeah
19:25:24 <Twey> You probably shouldn't be using that latter, then, if you're using strict bytestrings
19:25:38 <ajdhs> so I have a question about generalized folding
19:25:42 <Twey> The name seems to imply that there's a strict equivalent
19:25:45 <marcusb> well, it's the only way to get what hangs off the file at the end
19:25:47 <Berengal> marcusb: Have you considered just sticking to String?
19:26:00 <Berengal> I'm asking because I've never had a real need for bytestrings yet
19:26:03 <ajdhs> classes like Foldable, Traversable, etc. work on types that work for all element types
19:26:11 <marcusb> I don't need the end, but I like to explore what's out there
19:26:20 <marcusb> Berengal: I am parsing binary files
19:26:29 <Berengal> Ah, that explains it
19:26:31 <marcusb> like, cryptographic keys, BER encoded data etc
19:26:31 <ajdhs> but is there a standard way to generalize folds, maps, etc. across containers that only take one specific (or multiple specific) element types?
19:27:31 <marcusb> Twey: my totally uneducate guess is that because the file may be big, they might want to defer
19:27:33 <marcusb> reading it
19:27:39 <marcusb> hence the lazy
19:27:47 <marcusb> don't know if that makes sense or not
19:27:54 <Saizan_> yes
19:27:57 <Twey> Aye
19:28:09 <Twey> That's possible, but there's still probably a strict equivalent, if it makes sense in your case
19:28:17 <Twey> If not, why are you complaining about it being lazy?  :-P
19:28:23 <marcusb> Twey: not in my manual :)
19:28:32 <marcusb> Twey: i am not complaining, I was just confused
19:28:45 <marcusb> ok, I was complaining, but only about the lack of automatic sugar to hide all these differences
19:28:59 <Saizan_> Twey: when discussing things like these it's better to keep the haddock docs open to avoid confusion
19:29:00 <blackh1> SamB: My claim to fame http://bugs.gentoo.org/show_bug.cgi?id=82201 - actually it's about the same length as your fix.
19:29:07 <ManateeLazyCat> I saw page "http://www.gtk.org/language-bindings.html", why gtk2hs just *partially* support to GTK+ 2.8?
19:29:17 <marcusb> it's the haskell philosophy I guess.  start safe and useless, and work your way up :)
19:29:28 <marcusb> (not *my* words :)
19:29:53 <marcusb> works now
19:30:19 <Saizan_> ManateeLazyCat: gtk2hs doesn't offer all the functionality of gtk, there are some modules that noone has wrote the bindings for yet
19:30:20 <ivanm> ManateeLazyCat: because no-one has bothered to implement the extra things yet?
19:31:05 <marcusb> thanks for your help, guys, and gn!
19:32:28 <ManateeLazyCat> Saizan_: So gtk2hs can support all functionality of gtk, just have no-one write some missing?
19:33:04 <ivanm> AFAICT, gtk2hs - like most haskell bindings - features lazy library development in the true haskell spirit: all functionality exists in potentia (aka thunks) until someone forces development of them because they need it (write by need)
19:33:06 <ivanm> ;-)
19:33:10 <Saizan_> ManateeLazyCat: that's my understanding
19:33:33 <ManateeLazyCat> Saizan_: I see.
19:33:41 * Saizan_ has added a module once, too
19:34:13 <ManateeLazyCat> ivanm: It's better if gtk2hs write for `complete`
19:34:30 <Jig> how can I do: parseExpr :: String -> (Parsed, String) ? Ie match against some part of the string and return a tuple of that and the rest of the string
19:34:56 <ivanm> ManateeLazyCat: well, they're also trying to get gtk2hs cabalised, and AFAIK dcoutts is no longer doing gtk2hs hacking as he's busy with cabal, cabal-install, hp, etc.
19:35:12 <ivanm> Jig: as in parse as much as you can?
19:35:16 <ivanm> IIRC, that's reads...
19:35:18 <ivanm> @hoogle reads
19:35:18 <lambdabot> Prelude reads :: Read a => ReadS a
19:35:18 <lambdabot> Text.Read reads :: Read a => ReadS a
19:35:18 <lambdabot> Prelude type ReadS a = String -> [(a, String)]
19:35:22 <adamvo> is there a 'filter' for Foldable/Traversable?
19:35:51 <adamvo> @hoogle (a -> Bool) -> t a -> t a
19:35:51 <lambdabot> Data.IntMap filter :: (a -> Bool) -> IntMap a -> IntMap a
19:35:51 <lambdabot> Prelude dropWhile :: (a -> Bool) -> [a] -> [a]
19:35:51 <lambdabot> Prelude filter :: (a -> Bool) -> [a] -> [a]
19:35:56 <Saizan_> Jig: you'd usually write a parser using a combinator library, like ReadP or parsec or one of the many others
19:36:25 <Saizan_> Jig: http://haskell.org/ghc/docs/latest/html/libraries/base/Text-ParserCombinators-ReadP.html <- here's the doc of ReadP
19:36:43 <ManateeLazyCat> ivanm: I see, it's not implement problem of Haskell, just no time to implement it.
19:36:52 <ivanm> yup
19:37:08 <ivanm> there could be some specific aspects they don't know how to create the proper interface for, I don't know
19:37:14 <ivanm> but I would think it's more a time/need thing
19:37:28 <ManateeLazyCat> ivanm: How many gtk2hs developers now?
19:37:30 * ivanm reminds himself to one day go through and fully implement all graphviz features in the graphviz library
19:37:34 <ivanm> ManateeLazyCat: 2 or 3 IIRC
19:37:54 <ManateeLazyCat> ivanm: All?
19:38:21 <ivanm> @where gtk2hs
19:38:22 <lambdabot> http://haskell.org/gtk2hs/
19:38:27 <ivanm> ManateeLazyCat: ^^ look there ;-)
19:38:42 <ajdhs> adamvo: I don't think so
19:38:53 * ManateeLazyCat I hope i can do contribution to gtk2hs someday.
19:39:10 <ajdhs> You can implement one for Applicative+Traversable, I think
19:39:15 <Jig> ivanm: no I have a try-parser that matche sagainst language constructs so I want to parse until it fits one then return that and parse next part
19:39:22 <ajdhs> oh and I think you might need Monoid
19:39:32 <ajdhs> basically by using mapM with a state monad
19:39:54 <ajdhs> and combining all of the True values using pure + mappend
19:39:57 <ivanm> Jig: *shrug* if you're using a custom parser, then it sounds like a job for your parser
19:40:08 <mmorrow> preflex: seen vixey
19:40:08 <preflex>  vixey was last seen on #haskell 42 minutes and 41 seconds ago, saying: Ihate applicative gr!!
19:40:34 <Saizan_> Jig: so you're using parsec?
19:40:58 <edwardk> adamvo: i have one in monoids, but i specialized it to Generators
19:41:19 <adamvo> :t fmap (\x -> if ?p x then Just x else Nothing)
19:41:20 <lambdabot> forall a (f :: * -> *). (Functor f, ?p::a -> Bool) => f a -> f (Maybe a)
19:41:34 <Saizan_> Jig: parsec doesn't seem to offer an interface to parse only a prefix
19:41:57 <adamvo> and then an alternative to sequenceA that keeps going when it sees Nothing
19:42:09 <edwardk> adamvo: though allow an arbitrary reducer to be used
19:42:20 <edwardk> adamvo: http://comonad.com/haskell/monoids/dist/doc/html/monoids/src/Data-Generator-Combinators.html#filter
19:42:41 <edwardk> using that I can derive find from filter as well, using the First monoid
19:43:22 <Jig> anyone here took a compiler course? what did you do? did evryoen write their own compiler?  seems like a pretty huge task. or did you form groups and each wrote one part, parser,lexer,codegen etc?
19:44:14 <adamvo> edwardk: interesting
19:44:25 <ksf> in its most basic form, you just need (tokenizer,) parser and codegen
19:44:35 <edwardk> adamvo: just reduce with the list monoid or another container monoid like fingertree/sequence to get the filter you're used to
19:44:39 <ksf> ...both of which are the interesting bits, codegen being the hard one.
19:44:59 <ksf> (interesting in an educational, not academic setting)
19:45:09 <Jig> im using parsec yes
19:45:34 * edwardk figured out a neat complexity optimization for his parser.
19:46:03 <ksf> you could also start with the codegen, and write down the programs you want it to compile in haskell
19:46:21 <edwardk> I can 'move' the pure computations up the tree a little ways and increase sharing at the leaves, so i don't spend so much time on redundant applicative calculations until i've seen enough stuff go past that i have a less ambiguous parse
19:46:40 <Jig> hmm but isnt Parsec a tokenizer and parser?
19:46:53 <Saizan_> Jig: you can use getInput to retrieve the remaining input in a parsec parser, btw
19:46:59 <ksf> both are the same stuff. different passes of the same principle.
19:47:00 <edwardk> Jig: parsec can be used as a scannerless parser, yes.
19:47:07 <ksf> ...though tokenizers usually are simpler.
19:47:45 <edwardk> Jig: team based compiler construction is a daunting exercise, one rockstar can often do what three fumbling undergrads can rarely pull together ;)
19:48:07 <ksf> I'd be surprised if one couldn't come up with grammars that can't be tokenised.
19:48:37 <edwardk> ksf: well, you just use the simplest tokenization strategy, one token per character then ;)
19:48:50 <edwardk> and require a more complicated parser ;)
19:50:38 <Jig> so how the hell do I use
19:50:39 <Jig> Text.Parsec.Prim.ParsecT s u m s
19:50:54 <ksf> don't, if you don't need to.
19:51:00 <Saizan_> with "parse"
19:51:04 <Saizan_> ?type parse
19:51:05 <lambdabot> Not in scope: `parse'
19:51:23 <Saizan_> http://hackage.haskell.org/packages/archive/parsec/3.0.0/doc/html/Text-ParserCombinators-Parsec-Prim.html#v%3Aparse <- this one
19:51:27 <Jig> well P.getInput returns that
19:52:03 <ksf> it's the most general type possible.
19:52:23 <ksf> it's going to return the type you've put into it.
19:53:42 <ksf> If you want to parse a String to a Foo, you've got Parsec [] Char Foo
19:53:52 <ksf> ...which is ParsecT [] Char Identity Foo
19:55:09 <ksf> I'd use polyparse, anyway. It's way simpler, but also has way less docs.
19:55:37 <Saizan_> ReadP ftw
19:58:42 <Berengal> newtype Parser a = Parser {parse:: String -> Maybe (a, String)} ftw
19:58:46 <ksf> dammit. the topic http://video.google.com/videoplay?docid=-1518197558546337776 is about is darn interesting, but I can't keep my concentration as the lecturer is way too boring
19:59:56 <wli> I have been thinking of the oceanic depletion as a mere "fish stock problem" but it appears to be far broader.
20:01:18 <ksf> the problem is the financial crisis. thousands of icelanders loosing their job in high finance and going fishing, again.
20:02:55 <wli> Sorry, meant for #haskell-blah
20:03:13 <edwardk> clearly i'm going to have to fish more of them out of the bay in rejkjavik after this
20:03:45 <edwardk> (i wound up pulling a guy out of the water that fell off the levee when I was at MSFP 08) =)
20:04:10 <edwardk> er yeah thats probably -blah =)
20:05:58 <ivanm> edwardk: so you're a lifeguard or something?
20:06:20 <ivanm> or just a concerned citizen whose house is unfortunately located close to a convenient cliff people like to fall off? :p
20:07:13 <edwardk> ivanm: hah no, i just happened to be walking along and this little icelandic lady came by with this huge dog. the dog flipped out and scared the guy. he fell ~10 feet into the bay and i borrow her leash to fish him out.
20:07:37 <edwardk> ivanm: i was up there for the conference and was just heading back to my hotel
20:07:42 <ivanm> was the dog still attached to the leash? :p
20:07:55 * wli is vaguely interested in updates to the Club of Rome's World3 model to make it more detailed but is clueless as to how to simulate it etc.
20:08:04 <edwardk> nah, she had him by the collar =)
20:08:32 <ivanm> edwardk: heh, the dog might have provided the man with a convenient hand-hold... ;-)
20:09:05 <Jebdm> Is there a function to convert a Seq into a list?
20:09:07 <edwardk> ivanm: hah. yeah but trickier to pull them both up along the granite rocks
20:09:13 <edwardk> Jebdm: toList
20:09:17 <edwardk> Seq is Foldable
20:09:23 <ivanm> true...
20:09:57 <Jebdm> toList isn't defined.
20:10:01 <edwardk> ivanm: thats probably the highest anxiety situation i've been at at an academic conference since i realized there was a problem with the reduction rules i was showing everyone at ICFP 06.
20:10:05 <Jebdm> How would I access it?
20:10:06 <edwardk> Jebdm: import Data.Foldable
20:10:14 <ivanm> edwardk: lol
20:10:21 <Jebdm> ah, danke schön
20:10:29 <ivanm> edwardk: what is MSFP?
20:10:41 <ivanm> something-something-functional-programming?
20:10:44 <edwardk> mathematically structured functional programming
20:10:46 <edwardk> http://msfp.org.uk/
20:11:12 <mgsloan> at least it's not microsoft functional programming ;)
20:11:13 <ivanm> sounds cool
20:11:23 <ivanm> mgsloan: that's what I was thinking
20:11:25 <edwardk> i went up there to hang out and play academic, see dan piponi talk and to, as conor mcbride put it 'be the audience'
20:11:37 <ivanm> even though ghc is in the state it's in largely due to the evil redmondian empire...
20:11:50 <ivanm> edwardk: so you and dan piponi were the only ones there? :o
20:12:04 <Jig> ksf: thanks for the link
20:12:15 <ivanm> edwardk: is there likely to be any future ones?
20:12:19 <edwardk> ivanm: nah, there were probably 30 of us all told
20:12:29 <ivanm> heh
20:12:46 <edwardk> ivanm: probably next year, they had one in 2006 as well.
20:12:54 <ivanm> *nod*
20:13:55 <ksf> @tell Jig http://www.haskell.org/haskellwiki/Video_presentations
20:13:56 <lambdabot> Consider it noted.
20:14:41 <edwardk> i really enjoyed the paper that uustalu presented there, but it doesn't appear to be available online in any form
20:15:41 <edwardk> andrej bauer's presentation was also a lot of fun, but maybe i'm biased because i was able to capstone it by showing him exactly how to implement in haskell the generic effect stuff he claimed he could only do in the ml version ;)
20:16:05 <ivanm> heh
20:16:43 * ivanm should probably stop procastinating and start writing the slides he needs for the talk he's giving next week on lambda calc + church encoding...
20:16:54 <ivanm> which of course first means I need to make sure I know wtf they are :s
20:17:11 <Berengal> lambdas
20:17:47 <edwardk> i'm sitting here procrastinating about trying to figure out the best set of heuristics for moving code up the GADT into higher level nodes to avoid redundant calculation in my parsers.
20:17:51 <ivanm> heh
20:17:55 <andreep> hi, i can compile progrmas using haskell? for .exe ou other extension?
20:18:05 <edwardk> andreep: yes
20:18:31 <andreep> hummm, how?
20:18:40 <edwardk> ghc --make
20:19:13 <ksf> Someone should give spj a non-red pullover as a gift.
20:19:31 <ivanm> ksf: sounds like you just volunteered! :p
20:20:12 <andreep> --make? i try here, but maked nothing
20:20:27 <monochrom> ghc --make whatever.hs
20:20:38 <edwardk> ksf: http://www.phdcomics.com/comics/archive.php?comicid=1161
20:20:39 <andreep> hum...
20:20:54 <ivanm> andreep: and you need a main function in that .hs file
20:21:01 <monochrom> You will tell me it says "file not found". I am a prophet.
20:21:19 <ivanm> edwardk: lol
20:21:32 <ivanm> monochrom: it might say something else but meaning the same things...
20:21:42 <ivanm> in which case, you must only be a half-prophet! :p
20:22:28 <monochrom> I'm already just a half-prophet. A full prophet would know the right filename to use.
20:22:34 <ivanm> heh
20:22:50 <andreep> ivanm: main function to compile?
20:23:13 <ivanm> andreep: well, you need someway of telling ghc what your program is meant to do
20:24:29 <Saizan_> you need a function named main and of type IO a (for some a) in your module
20:24:41 <andreep> hummm
20:24:53 <andreep> i need search more about this
20:25:03 <fulerao> nothing of these can be done using an interpreter, rite?
20:26:35 <ivanm> Saizan_: I thought main had to be IO () :s
20:26:43 <ivanm> fulerao: nothing of these what?
20:26:57 <Saizan_> ivanm: no, the result is just discarded
20:27:03 <fulerao> of the whole compilation stuff
20:27:03 <monochrom> Pronouns should be banned.
20:27:10 <ivanm> fulerao: *nod*
20:27:15 <ivanm> monochrom: why?
20:27:26 <ivanm> fulerao: well, it will run, just not without any optimisations and much slower
20:27:36 <monochrom> "nothing of these" is the most recent example.
20:27:38 <ivanm> that's why it's called an "interpreter" rather than a "compiler" ;-)
20:27:59 <monochrom> Anyway, runghc whatever.hs works. Interpreter.
20:28:08 <ivanm> monochrom: so pronouns such as "I" should be banned as well?
20:28:15 <Saizan_> monochrom: file not found
20:28:25 <lament> I should be banned.
20:28:26 <mmorrow> ivanm: don't take it personally
20:28:38 <ivanm> mmorrow: heh, I'm not
20:28:47 <ivanm> it's just procrastination material ;-)
20:28:59 <ivanm> can we have an ops here? lament wants to be banned from this channel :p
20:29:04 <mmorrow> (personal pronoun;)
20:29:09 <Saizan_> using pronouns is like using a variable without ever defining it
20:29:16 <ivanm> mmorrow: lol
20:29:47 <Saizan_> (which reminds me of perl)
20:29:47 <ksf> argh damn.
20:29:53 <Berengal> I was just about to mention perl
20:30:02 <ksf> you have to write (foo -> bar) <- baz instead of foo -> bar <- baz
20:30:03 <Berengal> ... and apl
20:30:09 --- mode: ChanServ set -o lament
20:30:09 <Berengal> (Except it doesn't have pronouns, does it?
20:30:39 <Saizan_> (i was thinking of e.g. $_)
20:30:55 <ivanm> ksf: heh "foo -> bar <- baz" looks like your'e emphasising bar ;-)
20:31:04 <Berengal> yes, but apl has stuff like verbs and adverbs
20:31:31 <ksf> well, it's the variable fmap foo baz is bound to.
20:32:13 <ksf> more importantly, though, it looks like the five-fingered hand of eris.
20:32:29 <Berengal> -><-
20:33:05 <Berengal> That's never a bad thing
20:33:55 <lament> (except when it is)
20:34:38 * ksf suggests "mIf c a p = if p then c else a" for inclusion in Control.Monad, if not Prelude.
20:35:20 <shachaf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4716 -- has anyone come across this error installing syb-with-class?
20:35:23 <dolio> What does that have to do with monads?
20:35:52 <ksf> it takes the predicate as last argument, so you can say foo >>= mIf bar baz
20:36:01 <shachaf> Oh, this is GHC 6.11.20090501; that might be the cause.
20:36:07 <dolio> So, nothing. :)
20:36:24 <shachaf> Should I go to the trouble of installing 6.10.x, or is it something else?
20:36:45 <ksf> well, you _could_ restrict its type to Bool -> m a -> m a -> m a ...
20:37:04 <dolio> You could, but I wouldn't recommend it. :)
20:37:18 <ksf> yeah, it's the wrong way 'round...
20:38:04 <Berengal> I've been suggesting the removal of if expressions altogether, so we can have it as a function instead...
20:38:32 <monochrom> Make it a typeclass method so you can overload it.
20:38:37 <Berengal> if :: Bool -> a -> a -> a, fi :: a -> a -> Bool -> a
20:39:05 <Berengal> (or if')
20:39:16 <adamvo> it all ends up as case expressions, so use those
20:39:21 <ksf> fi is a good idea, it confuses shell programmers.
20:39:48 <adamvo> case esac
20:40:12 <ksf> I say we only need one keyword, and that's syntax-define.
20:40:45 <Berengal> ‮case foo of Nothing -> "Hello"; Just x -> "O HAI THAR " ++ x
20:40:49 <edwardk> Berengal: i think i heard a scream as if a thousand algol programmers screamed in protest
20:40:55 <Jig> http://www.metabrew.com/article/anti-rdbms-a-list-of-distributed-key-value-stores/
20:40:55 <lambdabot> Jig: You have 1 new message. '/msg lambdabot @messages' to read it.
20:41:00 <Jig> ^^ hmm late to the party perhaps
20:41:05 <allbery_b> <ksf> I say we only need one keyword, and that's syntax-define.
20:41:12 <allbery_b> surely you can do that with template haskell? :)
20:41:26 <Jig> really seems like haskell could be the language for some key-value store database
20:41:27 <dolio> Not really.
20:41:39 <Jig> considering how many erlang ones there are
20:41:44 <edwardk> Next you''ll want to flip around case.. oh wait.
20:41:57 <allbery_b> do ... od
20:41:57 <monochrom> Haskell is the language for everything.
20:42:03 <ksf> template haskell inserts $() all over the place
20:42:08 <edwardk> i should scroll all the way down =)
20:42:14 <bos> it's the language of lunch meat and vegan hamburgers.
20:43:07 <Berengal> Mmm, if-function
20:43:49 <Berengal> edwardk: The ability to remove if-expressions without too much breakage simply goes to show how ammeanable Haskell is to abstractions
20:44:58 <Jig> im looking for persistent storage as an alternative to serializing huge matrices
20:45:08 <Berengal> Jig: hdbc
20:45:13 <edwardk> berengal, i always figured if should piss off both camps and throw the conditional in the middle: foo if cond else bar =)
20:45:22 <ksf> same goes for scheme, you'd still have cond.
20:45:36 <edwardk> you can save a shift/reduce conflict and a lexeme ;)
20:45:40 <Jig> Berengal: hdbc isnt a relational db?
20:45:55 <edwardk> you may need to guard against people firebombing your house though
20:46:03 <ksf> ...in c, you'd have while(c){ ...; break}
20:46:07 <ksf> ...not to mention gotos.
20:46:41 <Berengal> edwardk: I'd be okay with that. Frees up 'then'
20:47:03 * Berengal thinks of all the times he's had to call (>>) 'andThen' and curses
20:47:18 <edwardk> berengal heh
20:47:22 <Berengal> Jig: Wasn't that what you asked for?
20:47:52 <Berengal> how about 'foo unless pred because then bar'?
20:48:47 <Berengal> [if] [then] [else] -> [else] [if] [then]. They're all switched around
20:49:38 <monochrom> I am sometimes fond of Tony Hoare's foo⊲cond⊳bar. Similar to what edwardk said.
20:50:25 <Jig> Berengal: no
20:51:18 <Berengal> monochrom: Didn't someone invent some crazy syntax like that for haskell as well?
20:51:26 <Berengal> Or perhaps that was different
20:51:56 * ksf thinks monadic view patterns move the bound-to ident too far to the right.
20:52:04 <monochrom> We invented something to mimic cond?foo:bar.
20:52:27 <allbery_b> <edwardk> berengal, i always figured if should piss off both camps and throw the conditional in the middle: foo if cond else bar =)
20:52:29 <allbery_b> forth?
20:52:46 <allbery_b> (actually not quite. more like postscript's I guess)
20:53:47 <edwardk> that said, i really like 'fi' i think i'll start using it in view patterns
20:55:31 <Berengal> Hmm, yeah I can see it's usefulness...
20:55:42 <monochrom> This whole syntax group-indulgence is self-inflicted. If you allow your editor to take someone's code and transform it to the format you like --- in fact you can like different formats on different days --- there is no need to design one single syntax that will go into the standard.
20:55:52 <Berengal> I think I prefer if' though, but prime has some connotations...
20:57:13 <edwardk> monochrom: until you go over to help someone else on their computer
20:57:34 <allbery_b> somethimng like: let c <?> (t,e) = if c then t else e; t <:> e = (t,e) in cond <?> true <:> false
20:58:12 <monochrom> Going over is so passe
20:59:13 <edwardk> allery: or c <?> f = f c. t <:> c = \x -> if x then t else c
20:59:27 <edwardk> allery: then you can use <:> in place of 'fi' above
20:59:42 <edwardk> but its a bit evil
20:59:53 <monochrom> The artsies students already write essays together by havint each persons facing his/her own laptop only, with some kind of concurrent version control supporting their collaboration.
21:00:18 <allbery_b> yeh, I've actually done something like that (but not for a ternary if-then-else)
21:00:44 <Saizan_> ?tell ManateeLazyCat i've fixed hbuild wrt cyclic modules, let me know if you try it
21:00:44 <lambdabot> Consider it noted.
21:01:03 <inimino> monochrom: indeed, think of all the arguments over syntax we would never need to have again
21:01:47 <Berengal> > let (<|) a b = (a,b); (|>) (a,b) c x = if b x then a x else c x in ((`div`2) <| even |> ((+1).(*3))) 5
21:01:49 <lambdabot>   16
21:02:35 <ksf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4717#a4717 <-- how to get rid of the do while improving readability?
21:04:15 <gwern> monochrom: like subethaedit or gobby?
21:04:28 <monochrom> I don't know them.
21:04:44 <Berengal> Are there any properly useable ones now?
21:04:49 * Saizan_ thinks we should use a vcs for laws too
21:05:04 <monochrom> But I'm sure artsies students write essays using "just" "oh yuck" Microsoft Office rather than editors.
21:05:11 <ksf> mixfix functions, anyone?
21:10:15 <ksf> @seen conal
21:10:16 <lambdabot> I saw conal leaving #haskell, #ghc and #haskell-in-depth 1d 7h 19m 48s ago, and .
21:10:23 <scutigera> ksf: why do you want to get rid of the do /
21:10:25 <scutigera> ?
21:10:52 <ksf> for the fun in functional
21:11:42 <ksf> ...and because I set out to replace monadic stuff with applicative, and i'm running out of easy cases.
21:12:18 <Gracenotes> () really puts the "unit" in "functional"
21:12:48 <monochrom> unsafePerformIO gives the un in functional
21:13:09 <monochrom> Oh, and the io in functional, too.
21:13:12 <Gracenotes> function - unit = falcon. A mere coincidence? No!
21:13:31 <Gracenotes> er, functional
21:13:41 <Gracenotes> (>^.^)>
21:13:46 <Berengal> So functional = falcon unit?
21:13:53 <Gracenotes> indeed so
21:14:20 <Berengal> Sounds cheesy
21:14:32 <ivanm> Gracenotes: millenium falcon?
21:14:36 <Gracenotes> > ("functional" \\ "falcon unit", "falcon unit" \\ "functional")
21:14:37 <lambdabot>   (""," ")
21:14:47 <Gracenotes> Berengal: I think you mean AWESOME
21:14:59 <Berengal> I didn't say cheesy was bad, did I?
21:15:04 <Berengal> I love cheese
21:15:24 <Gracenotes> incidentally, the internal anagram server says it's also "Oaf Cult Inn"
21:15:25 <monochrom> cheese is sticky
21:15:57 <Berengal> Gracenotes: Strangely relevant, if utterly false
21:16:13 <badtruffle> dons: you around?
21:16:23 <ivanm> @time dons
21:16:24 <simpletext> hey mr tambourine man play a song for me
21:16:25 <lambdabot> Local time for dons is Thu May  7 21:15:05 2009
21:16:54 <Gracenotes> no flu antic.. final count.. fail on, um, something
21:17:52 <Berengal> Gracenotes: When you said internal anagram server, you meant in your head, didn't you?
21:17:59 <monochrom> There is a matching word but it is not very appropriate. :)
21:18:20 <Gracenotes> Berengal: hm. I meant "internet"
21:18:25 <Berengal> Oh
21:18:45 <monochrom> Who knows, the internet is internal to his head, too.
21:19:32 <Berengal> Not _that_ would be awesome
21:19:40 <Berengal> now*
21:20:03 <simpletext> what music soundtrack should i use to learn haskell?
21:20:15 <Berengal> simpletext: nothing else matters
21:20:35 <simpletext> lol you pulled that out quick
21:20:56 <Berengal> It's been on my mind for the last couple of days
21:21:22 <Berengal> And whenever it pops up I can't help but fantasize about writing a program that creates music
21:21:38 <Berengal> Because that song needs to be infinitely long, and repeat just doesn't cut it
21:21:47 <Gracenotes> I use lots of stuff when coding Haskell
21:21:57 <Berengal> (And when I say "that song" I mean the orchestrated version)
21:21:59 <Gracenotes> or.. do anything that doesn't require intense though
21:22:01 <Gracenotes> t
21:22:23 <Gracenotes> for instance right now I'm listening to the Grease soundtrack. although, reading a comic
21:22:34 <simpletext> hm i see
21:22:52 <Berengal> Usually I just listen to C64 remixes
21:22:57 <Gracenotes> *listens to the Dresden Dolls now*
21:23:19 <ksf> simpletext, http://www.jazz.fm/ . the grooveyard.
21:23:34 <simpletext> ah
21:23:50 <scutigera> Gracenotes: truly good taste in music you have
21:23:51 <ksf> ...jazz tends to keep the brain from locking up.
21:24:24 <simpletext> i'll have to try it
21:24:41 <Gracenotes> scutigera: it's .. pretty varied
21:24:46 <simpletext> jazz..lithium grease for the brain
21:24:56 <Berengal> Nice, I needed a jazz station
21:25:17 <Gracenotes> I don't like smooth jazz though :\ in my experience it's so gaudy
21:26:17 <ksf> I chose it scientifically: listen to the first 10 seconds of 100 shoutcast streams, and see if it sucks, then increase the listening length while reducing the data set, rinse, repeat.
21:30:45 <ksf> hmmm... drip temperature of 190 to 220 degrees. I guess i'd stick with WD 40.
21:31:34 <ksf> I just needed something approximately easy listening that includes braindumps.
21:31:35 <simpletext> your brain runs hotter than mine
21:32:25 <ksf> nah, lithium grease is that sticky.
21:32:57 <ksf> if you've got a squeaking door and want to fix it with wd40, you just have to spray it in the approximate direction of your house.
21:42:48 <scutigera> listMatrix :: (Data.Elem.BLAS.Base.Elem e) =>
21:42:48 <scutigera>               (Int, Int) -> [e] -> Matrix e
21:42:48 <scutigera>  
21:42:58 <scutigera> listMatrix (2,2) [ 46.0,37.0,71.0,83.0]
21:43:13 <scutigera> Ambiguous type variable `t' in the constraint:
21:43:44 <Gracenotes> you might want to mention what you're filling the matrix with. Ints? Integers? Doubles?
21:43:58 <Gracenotes> Floats? :o
21:44:05 <scutigera> so ... ::Double ] fixes it. Why ?  Shouldn't ghc figure out that [Double] is there.
21:44:16 <Gracenotes> @type 10.4
21:44:18 <lambdabot> forall t. (Fractional t) => t
21:44:46 <Gracenotes> GHC does have something called "defaults", where a polymorphic numeric value can be reduced to a specific one. Like, 10.4 to a Double
21:45:17 <Gracenotes> however, these don't exist in all cases -- if you put 10.4 in a list, it could be any Fractional type. Specifying Double takes care of this and makes it unambiguous
21:46:44 <Gracenotes> > (2/3 :: Double,   2/3 :: Float,   2/3 :: Rational,   2/3 :: CReal)
21:46:45 <lambdabot>   (0.6666666666666666,0.6666667,2%3,0.6666666666666666666666666666666666666667)
21:48:17 <scutigera> I see, it would even be unable to choose between Float and Double, even ignoring the rest of the members of Fractional
21:50:47 <kerlo> > 2/3 :: CDouble
21:50:48 <lambdabot>       Not in scope: type constructor or class `CDouble'
21:50:53 <kerlo> Whew.
21:51:33 <scutigera> why are CDouble and Double different, don't they both use IEEE double ?
21:53:50 <simpletext> bob dylan 'all i want to do' is my haskell theme for today
21:53:51 <kerlo> I think CReal is 64 bits, Double is 32, and Float is 16.
21:54:07 <kerlo> > maxBound :: Word
21:54:08 <lambdabot>   18446744073709551615
21:54:08 <dolio> CReal is computable real.
21:54:17 <dolio> Double is 64-bit floating point.
21:54:21 <dolio> Float is 32.
21:54:23 <edwardk> scout "CReal" is computable real, not C real
21:54:27 <kerlo> Mm.
21:54:39 <edwardk> you can ask a CReal for arbitrary precision
21:54:40 <kerlo> Is there a C real type?
21:54:49 <edwardk> CFloat and CDouble in Foreign.*
21:55:02 <edwardk> CReal is pretty badly named =)
21:55:06 <kerlo> :-)
21:55:47 <scutigera> CDouble is C interface double.  Which gets back to why can't they be the same type ?  Boxing ?
21:56:25 <edwardk> scutigera: boxing. a haskell double is a reference to a thunk that will evaluate and return a double, not a double itself.
21:56:30 <Jebdm> Is there a library function which returns a list with a given element inserted at a given position?
21:56:37 <Jebdm> It seems like a common case, but I can't find it.
21:56:42 * Jebdm probably just fails.
21:56:52 <kerlo> Is CDouble not a thunk?
21:56:58 <edwardk> there is an unboxed Double# type that is used that is basically a primitive platform double.
21:57:08 <blackh> jebdm: You'll have to make it out of splitAt
21:58:14 <edwardk> as for why CDouble != Double, i think its mostly a matter of bikeshedding, if they want haskell doubles to be divorced from the notion on the platform they can do things like allow you to define an entirely in-haskell double implementation with exponent and mantissa and still be correct
21:58:21 <edwardk> kerlo it is
21:59:11 <scutigera> edwardk: bikeshedding ?  Getting rid of one's cycling apparatus ?
21:59:14 <edwardk> http://www.haskell.org/ghc/docs/latest/html/libraries/base/Foreign-C-Types.html gives a pretty long list of requirements for a C type representation
21:59:20 <dolio> CDouble is just a newtype over Double in GHC.
21:59:47 <dolio> But the CX types are guaranteed to be usable in foreign calls.
22:00:22 <edwardk> scutigera: http://en.wikipedia.org/wiki/Color_of_the_bikeshed
22:00:28 <Jebdm> Huh.  I wonder why that isn't in the prelude, or at least Data.List?
22:01:37 <scutigera> edwardk: funny...
22:01:50 <edwardk> @type \n -> uncurry (\(xs,ys) -> xs ++ z:zs) . splitAt n
22:01:51 <lambdabot> Not in scope: `zs'
22:01:55 <edwardk> er
22:02:07 <edwardk> @type \n z -> uncurry (\(xs,ys) -> xs ++ z:ys) . splitAt n
22:02:08 <lambdabot>     Couldn't match expected type `b -> c' against inferred type `[a]'
22:02:09 <lambdabot>     In the expression: xs ++ z : ys
22:02:09 <lambdabot>     In the first argument of `uncurry', namely
22:02:17 <edwardk> @type splitAt
22:02:18 <lambdabot> forall a. Int -> [a] -> ([a], [a])
22:02:45 <edwardk> er and why did i uncurry that
22:04:55 <edwardk> @type \n z ->  uncurry ((. (z :)) . (++)) . splitAt n
22:04:56 <lambdabot> forall a. Int -> a -> [a] -> [a]
22:05:19 <Jebdm> setIndex :: Int -> a -> [a] -> [a]
22:05:19 <Jebdm> setIndex i v xs = a ++ (v : (tail b))
22:05:19 <Jebdm>   where (a, b) = splitAt (i-1) xs
22:05:29 <Jebdm> I think is a bit simpler ;)
22:06:07 <edwardk> if you're taking a tail there aren't you replacing and not inserting?
22:06:18 <Twey> Jebdm: You don't need any of those brackets, you know
22:06:20 <Jebdm> Yeah, that's what I meant to do.
22:06:25 <edwardk> and if you need that shouldn't you be looking into an array?
22:06:29 <Twey> setIndex i v xs = a ++ v : tail b
22:06:46 <Jebdm> Nah, it's only occasional
22:06:51 <edwardk> at least if you have to do it often. ah ok
22:06:59 <Jebdm> Twey: I find the parenthesis a bit easier to read
22:07:21 <edwardk> hah, koninkje1away just posted on my wife's livejournal telling her she should learn haskell =)
22:07:28 * Jebdm doesn't really like infix notation, either.
22:08:02 <edwardk> Jebdm is obviously a closet lisper sent to infiltrate the channel
22:08:07 <Twey> Jebdm: Ah, a lisper?
22:08:09 <Twey> Heh
22:08:17 <Jebdm> Nah, I just don't like infix.
22:08:21 <scutigera> no he ithn't
22:08:25 <Twey> They're spying on us!
22:08:42 * edwardk believes in the rigorous elimination of spurious parentheses not forced upon him by the grammar ;)
22:08:49 <Twey> setIndex i v xs = (++) a . (:) v $ tail b
22:08:56 <Twey> :-P
22:08:57 * Jebdm does believe in $, though.
22:09:17 * Jebdm also tends to use a lot of where clauses.
22:09:19 <scutigera> Twey: I'm sorry but that's almost pearly
22:09:19 <edwardk> Jebdm: then why are you programming in Haskell and not c#? =)
22:09:29 * Twey laughs.
22:09:48 * edwardk believes in $ too =)
22:09:58 * Jebdm laughs, and abuses /em.
22:10:04 * Jebdm *
22:10:14 <Jebdm> Damnit, I mean /me
22:10:26 <pumpkin_> dons: I'm having to make quite big changes to uvector to support lazy arrays
22:10:30 <Twey> Heh
22:10:58 <Twey> edwardk: Is your wife in the CS scene too?
22:11:49 <edwardk> Twey: Kind of. she was working on a linguistics masters when i dragged her away to come to Boston with me and had a bit of a computational linguistics focus.
22:11:57 <Twey> Oho
22:12:10 <pumpkin_> dons: mostly to the Streams, as they currently have a length field, which I can't know ahead of time (but I'm trying to reuse as much code as possible)
22:12:13 <edwardk> before that was a cognitive science major, so got some comp sci in her undergrad
22:12:26 <edwardk> She knows enough to pat me on the head and send me into my office to play with my friends on the internet.
22:12:48 * Twey grins.
22:13:26 <edwardk> And she gives me constrant crap about the ever increasing rate at which I introduce new terms into my running monologue about what it is i'm working on.
22:13:44 <pumpkin_> when did you get codivorced?
22:14:12 <Twey> Only in #haskell
22:14:38 <edwardk> hah about 2 years ago. but we've been together for 7-8 years and known each other for almost 15.
22:14:44 <pumpkin_> wow :)
22:15:55 <Gracenotes> hm, it feels like a late Friday night... not a late Thursday one. >_>
22:15:57 <shepheb> @remember pumpkin when did you get codivorced?
22:15:58 <lambdabot> Okay.
22:16:04 <edwardk> hah
22:16:37 <Gracenotes> "co" is a pretty good prefix when nicks are taken on an online service
22:17:41 <Jebdm> I'm having a bit of difficulty understanding the use cases of array, sequence, and lists.  It seems like you'd always want to use arrays, since none of them are mutable (i.e., in C you'd use a list because it's extendable, but if you're always making new arrays it doesn't matter).  But lists get optimized (as do Seq's, probably?) so that when you make a new list, it reuses the memory from the old one.
22:18:29 <Jebdm> It seems kind of hard to reason about efficiency in Haskell, given the amount of optimization done and how high level it is.
22:18:31 <Twey> Lists are for reading in order
22:18:37 <Twey> Arrays are for random access
22:18:57 <Twey> Seqs are heavy-weight lists, i.e. reading in order, but doing fancy stuff with, like reading backwards
22:19:20 <pumpkin_> Jebdm: you only reuse lists if you prepend onto them
22:19:21 <edwardk> Jebdm: Seq is better if you need to randomly access and still append/prepend
22:19:22 <lament> Jebdm: lists are the haskell equivalent of for loops
22:19:28 <Lemmih> Jebdm: That lists reuse memory is not an optimization.
22:19:29 <Jebdm> But Seq's are more efficient than lists, unless you're just doing prepends/pushes
22:19:36 <edwardk> Jebdm: arrays are good if you can fix the structure once and forall and just need to index
22:19:44 <Gracenotes> sometimes lists disappear entirely when you compile.
22:19:48 <Twey> And yes, it's been mentioned that lists are really more of a control structure than a data structure in Haskell
22:19:49 <lament> Jebdm: often lists are better seen as computation, not as data
22:20:06 <Gracenotes> if you make a list, then map, filter and fold it, the code might compile down to not using the list structure at all. deforestation at all.
22:20:11 <Gracenotes> *and
22:20:16 <edwardk> i love the way haskell treats lists
22:20:17 <Gracenotes> although I'm not quite familiar to how Haskell does it >_<
22:20:23 <Twey> Jebdm: If you're not just doing prepends and sequential reads, then you don't want lists
22:20:31 <Gracenotes> it's commonly used, so optimized quite a bit
22:20:51 <Twey> Jebdm: It just so happens that the list represents a very common order of operations in functional programming, which is why it's so prominent.
22:21:03 <Gracenotes> lists can be a form of control flow, not just a data structure. as I said, I think.
22:21:04 <edwardk> Gracenotes: that and it tends to naturally map onto the whole idea of coinduction
22:21:42 <Twey> edwardk, I don't know what coinduction is, and I've been Haskelling for a year
22:21:42 <Gracenotes> hm, I've heard a small bit about coinduction lately...
22:21:48 <Twey> You're going to terrify the newbies :-P
22:21:54 <Jebdm> My problem is that my use case isn't particularly simple; I'm implementing a toy VM.
22:21:59 <Twey> (aside, what *is* coinduction?)
22:22:13 <Jebdm> I'm doing a lot of sequential access, but also a fair bit of random access.
22:22:14 <Twey> Jebdm: If it's ugly with lists, then don't use lists.
22:22:24 <Twey> Go with an array
22:22:24 <lament> Jebdm: so if you have a bunch of data and you have the data all it once, the "for-loop like" functionality of lists is useless to you, so use arrays
22:22:39 * Twey nods.
22:22:39 <edwardk> Twey: induction, define base case, build up. coinduction, throw away the base case. (its a little bit trickier than that but its a good intuition)
22:23:07 <Twey> edwardk: Isn't that contrary to the principle of induction and therefore nonsensical?
22:23:12 <Gracenotes> edwardk: you mean, given the whole inductive structure, whittle away the lower parts?
22:23:12 <scutigera> how well optimized is the Array class . Is it better to use one of the more "Monady" arrays ?
22:23:29 <pumpkin_> scutigera: what kind of stuff are you doing with the array? there are different good choices
22:23:29 * Jebdm is using Seq's to handle thread pools and memory pools, and zippers to handle instruction memory
22:23:33 <dolio> But you're not using induction, you're using coinduction. :)
22:23:38 <Gracenotes> Array is pretty fast. Though you may want to use UArray for more speed
22:23:44 <Gracenotes> if applicative
22:23:47 <Gracenotes> applicable.
22:23:50 <pumpkin_> lol
22:23:56 <Twey> dolio: But induction works because of those principles
22:23:58 <scutigera> pumpkin_: typically numerical stuff
22:24:11 <Twey> If coinduction doesn't use them, there must be something else in its place
22:24:19 <dolio> And coinduction works because of its principles.
22:24:21 <Twey> Or it would be incoherent
22:24:23 <pumpkin_> scutigera: if you do a lot of sequential stuff on arrays, using primitive elements, uvector might be good :)
22:24:29 <Jebdm> I thought that Seq's seemed good for the pools because I'm doing a lot of inserting and deleting, as well as a lot of iterating
22:24:29 <Twey> Heh, touché
22:24:34 <edwardk> Twey: You show that if it holds it holds for the larger case it holds for the 'smaller' case. whittle away at an infinite list. you aren't inducting
22:24:48 <Jebdm> I think they're normally implemented with trees, as well.
22:25:02 <pumpkin_> Jebdm: yup, and they have fingers
22:25:16 <Jebdm> The zipper may have been a bad choice, though.
22:25:27 <edwardk> Twey: induction yields the 'greatest' fixed point, coinduction yields a 'least' fixed point.  you pick up bottoms and start reasoning over a complete partial order instead of sets
22:25:28 <Jebdm> It's really nice, except for the terrible random access times.
22:25:29 <Twey> Jebdm: See also Data.DList when thinking of sequential data structures
22:25:37 <lament> zipper for memory is good for brainfuck and the turing machine
22:25:41 <Twey> edwardk: Aha
22:25:42 <lament> why would it be good for anything else?
22:25:42 <Twey> That makes... some sense
22:25:44 <edwardk> Twey: in a lot of ways its a more natural model for computation
22:25:54 <scutigera> pumpkin_: aargh. I think someone told me about them not too long ago and I forgot.  Look exactly right :-)
22:26:05 <pumpkin_> scutigera: I'm working on it right now!
22:26:30 <pumpkin_> scutigera: I'd recommend grabbing the latest one in dons' repo though
22:26:42 <Jebdm> First of all, it's just nice to work with.
22:26:54 <edwardk> Twey: for example, when i code in haskell i'm not usually interested in 'well founded recursion' which is an inductive concept. what i want is 'productive corecursion' -- i want to emit an outermost constructor after a bounded number of steps
22:27:07 <scutigera> pumpkin_: latest is not 0.1.0.3 ?
22:27:16 <edwardk> Twey: because we're lazy, this means that you can then INSPECT the structure to a finite depth in a bounded amount of time
22:27:27 <edwardk> codata is all about later (partial) consumption
22:27:29 * Twey nods.
22:27:30 <Jebdm> But the way I've designed the VM has you creating threads for each function, so that each thread is really small.
22:27:46 <pumpkin_> scutigera: there's an unreleased version with some changes (and a lot more documentation) sitting in the repo :)
22:27:47 <Twey> I see
22:28:02 <Jebdm> Also, you should be creating memory pools for anything larger than some temp variables and such
22:28:12 <dolio> Partial as in computing parts of things?
22:28:14 <Jebdm> Which means that O(N) isn't that bad.
22:28:16 <edwardk> length is not defined for infinite lists. it evaluates out to bottom. it is a 'recursive' concept =)
22:28:38 <edwardk> dolio: yeah
22:28:42 <dolio> Okay.
22:28:52 <scutigera> pumpkin_: is the repo the homepage link from hackage, or different place ?
22:28:56 <edwardk> dolio: i only want to inspect the portions of my codata that i actually need to produce the result.
22:28:57 <pumpkin_> yeah, the link there
22:29:22 * Jebdm should probably just use an array.
22:29:30 <scutigera> pumpkin_: thanks !
22:29:39 <dolio> Right. I just wanted to make sure you didn't mean opposite of total (as in functions).
22:29:44 <edwardk> So basically instead of making the argument smaller, you focus on how you build the result.
22:31:47 <edwardk> anamorphisms are defined as generating a least fixed point. catamorphisms generate a greatest fixed point. you have (usable) hylomorphisms only when these coincide, which thankfully in haskell they do.
22:31:53 <edwardk> er
22:32:01 <edwardk> catamorphisms consume a greatest fixed point
22:32:40 <dolio> Eh?
22:33:00 <dolio> Catamorphisms consume a least fixed point.
22:33:08 <dolio> Anamorphisms generate a greatest fixed point.
22:33:48 <pumpkin_> must've been cocatamorphisms one of you was talking about then
22:34:09 <pumpkin_> :P
22:34:39 <edwardk> hrmm, i may have that backwards =)
22:38:39 <edwardk> nope, cata :: (f a -> a) -> Mu f -> a -- ana :: (a -> f a) -> a -> Nu f
22:39:08 <dolio> Mu is least fixed point.
22:40:01 <edwardk> i always get these backwards =)
22:40:08 * Elly has no idea what you are both talking about and hides
22:40:49 <edwardk> yeah you're right. i just looked through my own writeup on the topic. hah
22:41:03 <edwardk> funny how much information you can flush over a year or two
22:41:49 <ski> `Mu f -> a' is the unique morphism from the initial object to `a', in the category of `f'-algebras
22:41:52 <edwardk> anyways my whole point was there are lots of places where they don't coincide
22:42:58 <QtPlaty[HireMe]> In haskell all functions take one argument, is there a name for this?
22:43:09 <ski> (edwardk : indeed)
22:43:13 <edwardk> which unfortunately precludes a lot of neat things when dealing with HOAS encodings =(
22:43:27 <pumpkin_> QtPlaty[HireMe]: it's related to currying, but I doubt that's what it's called
22:44:19 <dolio> All C functions take one argument, too, if you look at them right.
22:44:35 <edwardk> its just a tuple =)
22:44:42 <ski> yeah, the argument begin an unboxed tuple
22:44:45 <dolio> Each one takes an n-tuple, and tuples can only be constructed in conjunction with function calling.
22:44:47 <ski> s/begin/being/
22:46:18 <dolio> 0-tuples being called (void).
22:46:31 <ski> *nod*
22:47:16 <edwardk> ah neat i got some silly 'top knol' award for the catamorphism knol
22:47:24 * Jebdm wonders what age/education/jobs people here have.
22:47:28 <ski> "knol" ?
22:47:40 <Gracenotes> neat :)
22:47:45 <Gracenotes> link?
22:47:46 <edwardk> ski: http://knol.google.com/k/edward-kmett/catamorphisms/
22:47:53 <ski> ty
22:48:41 <Gracenotes> this mu, it mak no sanse
22:50:03 <ksf> @vixen, a/s/l
22:50:03 <lambdabot> 19/f/California
22:50:22 <ksf> When she's not answering questions, she's a camgirl.
22:50:55 * Jebdm catcalls
22:52:02 <hatds> if you have value, say Int or something, representing time what is the best way to deal with rollovers?
22:52:15 <ksf> use an Integer?
22:52:20 <ksf> ...or Double?
22:52:27 <edwardk> ksf: reboot
22:52:31 <edwardk> er hatds
22:52:38 <lispy> hatds: why use an Int for time?  We have specialized data types for it
22:52:50 <hatds> lispy: such as?
22:52:56 <ksf> reactive uses Double
22:52:56 <Berengal> UTCTime
22:52:57 <lispy> ?hoogle time
22:52:57 <lambdabot> package time
22:52:58 <lambdabot> module Data.Time
22:52:58 <lambdabot> Data.Time.LocalTime data TimeOfDay
22:53:00 <edwardk> or somewhat more tongue in cheek: 'get a better calling plan'
22:53:10 <lispy> edwardk: haha
22:53:11 <hatds> I thought about Integer, but it would use more memory right?
22:53:15 <hatds> over time
22:53:21 <Berengal> ?src Integer
22:53:21 <lambdabot> data Integer = S# Int#
22:53:21 <lambdabot>              | J# Int# ByteArray#
22:53:49 <ksf> yeah. calculate for yourself how many kilobytes you need to count the microseconds from the big bang to now.
22:53:49 <Tsion> what are S# and J#?
22:53:57 <Berengal> Tsion: Constructors
22:54:04 <lispy> Tsion: Single and Jumbo?
22:54:15 <hatds> yea, so logarithmic in time... but it still feels like the wrong solution if I don't actually need it :)
22:54:33 <edwardk> hatds: um, your existing solution is logarithmic in time right up until it crashes
22:54:36 <edwardk> ;)
22:54:37 <ksf> it is the absolutely right solution.
22:54:41 <Twey> Hehe
22:55:13 <edwardk> and if you need to worry about the logarithm of time, you're using the wrong units man, seriously. even on planck scales the duration of the universe shouldn't be THAT big =)
22:55:26 <hatds> edwardk: come again? a single Int uses constant space but you have to accept rollovers
22:55:55 <ksf> @alpha time since big bang in planck seconds
22:55:55 <lambdabot> Unknown command, try @list
22:55:56 <pumpkin_> I remember reading a spiel about explicit import lists and how they're a pain
22:55:58 <pumpkin_> I find them a pain
22:56:03 <pumpkin_> what do you guys think?
22:56:03 <hatds> "feels wrong" has nothing to do with logic, reason or timescale of the universe :)
22:56:04 <ksf> I WANT IT I WANT IT I WANT IT
22:56:19 <lispy> pumpkin_: I like them in large projects
22:56:46 <lispy> pumpkin_: I just wish GHC was a bit better at assisting you in finding the minimal imports
22:56:57 <Cale> pumpkin_: What's the alternative?
22:56:58 <ksf> does anyone here have early access? seems likely with so many phds around.
22:57:08 <edwardk> hatds: planck time = 5.39124 * 10^-44. the duration of the universe until heat death figure 10^100, so just store something that can hold any value up to 10^145 or so and you should be able to represent any practical unit of time =)
22:57:10 <pumpkin_> Cale: I mean on individual imports
22:57:11 <hatds> pumpkin_: if I had a perfect IDE it would automate a lot of imports
22:57:20 <lispy> Cale: "import Data.Char" vs. "import Data.Char (ord)"
22:57:30 <pumpkin_> I was keeping them at first
22:57:35 <ksf> > 10^145
22:57:36 <lambdabot>   100000000000000000000000000000000000000000000000000000000000000000000000000...
22:57:39 <ksf> there.
22:57:43 <pumpkin_> but as I need more/less stuff it just means keeping track of more stuff to add and remove
22:57:45 <Berengal> > log (10^145)
22:57:46 <lambdabot>   333.8748384841366
22:57:47 <ksf> > 10^145 + 1
22:57:47 <edwardk> that would be er.. ~ 483 bits, nuff said =)
22:57:49 <Cale> pumpkin_: Oh, I don't usually use those, unless I've already imported something qualified and I want to import some things without qualification.
22:57:49 <lambdabot>   100000000000000000000000000000000000000000000000000000000000000000000000000...
22:57:51 <pumpkin_> explicit export lists are different
22:57:53 <pumpkin_> I do those
22:57:56 <Berengal> > log (2)
22:57:58 <lambdabot>   0.6931471805599453
22:58:00 <Berengal> :/
22:58:01 <pumpkin_> yeah, I use them in that case too
22:58:29 <edwardk> hatds: in the meantime, grab something out the 'time' package =)
22:58:36 <Berengal> > logBase 2 (10**145)
22:58:37 <lambdabot>   481.6795737586675
22:58:42 <lispy> pumpkin_: it really seems to depend on the code base.  In darcs (the largest Haskell code base I've dealt with) it's really nice to see the explicit imports.  It really saves time when you want to figure out where a function is defined.
22:58:45 <hatds> edwardk: yea, looking into that right now
22:58:53 <quicksilver> if you don't have an explicit import list then there is no way for a reader of your code to know where symbols are coming from - except by examining every other module.
22:58:56 <Berengal> > 482 / 8
22:58:57 <lambdabot>   60.25
22:59:04 <quicksilver> if you don't have explicit import lists you lose forward compatibility.
22:59:05 <Berengal> 61 bytes
22:59:13 <quicksilver> having said that, they're a pain and I don't use them.
22:59:19 <pumpkin_> :P
22:59:20 <quicksilver> but those are the important reasons one should :)
22:59:24 <pumpkin_> I agree those are good reasons to use them
22:59:33 <pumpkin_> but as you said, they're a pain
22:59:41 <pumpkin_> maybe when I start using leksah it can take care of them for me
22:59:41 <edwardk> Berengal: heh, 482 then, thats what i get for doing it using the 10/3rds approximation in my head =)
22:59:57 <Berengal> edwardk: At least you had it in your head :)
23:00:14 <ksf> the problem becomes locality, though. you musn't move your monitor while measuring time on planck scales, or relativity messes up your output.
23:00:15 <edwardk> berengal: 2^10 = 1024 ~ 10^3 = 1000
23:00:26 <lispy> pumpkin_: well, it would be nice if $editor + ghc helped you keep them updated and minimal
23:00:33 <edwardk> useful trick at parties when someone asks you how big 2^64 is
23:01:01 <Berengal> edwardk: I know, but it's not internalized in my brain
23:01:24 <Berengal> It used to be, sometime before I knew programming...
23:01:33 <pumpkin_> lispy: yeah
23:01:56 <ksf> I once new a female hacker who could calculate hex in her head.
23:01:59 <edwardk> Berengal: i really like Fermi problems, and its the kind of thing thats useful for them
23:02:44 <lispy> pumpkin_: if you compile with -Wall ghc will tell you when you forget something...so the hardpart becomes keeping the list minimal
23:03:25 <ksf> otoh, I frequently say "I'm a programmer, I don't need to be able do that in my head" while messing up small change.
23:03:41 <quicksilver> I bet she was a scream at parties.
23:03:57 <hatds> I get strange looks replacing "programmer" with "mathematician"
23:04:00 <Cale> I can calculate quite well if I have paper, but doing stuff in my head is painful.
23:04:16 <ksf> ...I see the amount and available coins as graph reduction and mess up the numbers while optimizing the reduction.
23:04:17 <quicksilver> I can probably calculate 2-digit hex in my head, given a few minutes ;)
23:04:19 <Berengal> I'm usually not too bad with numbers
23:04:28 <edwardk> cale: the whole, "just because i'm a mathematician doesn't mean i can do arithmetic" thing =)
23:04:29 <Berengal> Quite good at keeping state in my head...
23:04:43 <Cale> I don't own a pocket calculator, and so I've been stuck calculating logarithms and such by hand on a couple of exams in my life :)
23:04:47 <Berengal> I keep needing to derive the rules for arithmetic though
23:05:16 <Cale> But, without a piece of paper and something to write with, I'm pretty helpless.
23:05:22 <Jebdm> Cale: Do you dislike them, or do you just not have one?
23:05:30 <Cale> Jebdm: a bit of both
23:05:46 <dolio> edwardk: I thought that's what mathematics was. Like computer science is where you learn to hook up cables to routers and stuff.
23:05:53 <Jebdm> Cale: What's your reason for disliking them?
23:06:25 <quicksilver> dolio: no no no
23:06:26 <Cale> I suppose it's that they don't really do enough to justify the cost for me.
23:06:27 <edwardk> dolio: I get people asking me to help them write papers because i used to do work with linguistics too.
23:06:33 <quicksilver> dolio: computer science is like, word and excel and stuff.
23:06:53 <Berengal> quicksilver: It's true though
23:06:56 <Cale> Well, I'm not really so interested in the sorts of calculations they're capable of.
23:06:56 <vininim> there are some $5 calculators that does logarithm
23:07:06 <vininim> *do
23:07:18 <Berengal> Yesterday I was called upon to help someone who suddenly couldn't use her arrow keys to move the selected cell in excel
23:07:26 <Berengal> Turns out the scroll lock was to blame...
23:07:32 <Jebdm> Huh.  I mean, things fancy HP/TI calculators are pretty overpriced if you're not doing much with them, but you can get a cheapo one for doing simple stuff.
23:07:33 <lispy> Berengal: hahaha
23:07:35 * ksf wants a pandora with ghci on it as a calculator
23:07:42 <Berengal> I can honestly say I wouldn't know how to fix that without my CS education
23:07:51 <pumpkin_> I thought computer science was making games and webpages
23:07:55 <edwardk> I actually really want to know what happened to the old Curta calculator my grandfather had when he passed away.
23:08:00 <edwardk> http://en.wikipedia.org/wiki/Curta_calculator
23:08:04 <dons> pumpkin_: i think lazy arrays should be a separate repo (?)
23:08:06 <Jebdm> Although I guess most people don't do enough math away from their computers to need one.
23:08:09 <Cale> Jebdm: I had one when I was in highschool, but I gave it away when I went to university and realised in the first week that I wasn't really going to need it.
23:08:12 <pumpkin_> dons: oh :/
23:08:15 <dons> well...
23:08:19 <dons> depends on what model you come up with
23:08:22 <dons> is there any reuse?
23:08:23 <Cale> Jebdm: Well, I had a $20 casio thing.
23:08:27 <Jebdm> Cale: What did you study?
23:08:33 <Cale> Pure Mathematics
23:08:43 <ksf> ...the most important thing in a calculator is operator-precedence awareness, logBase 2 and dec/bin/hex conversion.
23:08:44 * Jebdm found his TI-89 quite useful in Calculus.
23:08:47 <pumpkin_> dons: I'm modelling it on lazy bytestrings, and I'm reusing most of the stream stuff (after making changes to it) and the hyperstrict stuff
23:08:51 <lispy> dons: hi.  How were the talks at PSU recently?  I wanted to go but my work had a conference the same day :(
23:08:56 <Jebdm> Of course, I didn't learn all the integration tricks very well.
23:08:57 <pumpkin_> dons: otherwise, the api is mostly identical
23:09:01 <dons> lispy: very good
23:09:03 <dons> pumpkin_: ok.
23:09:04 * hatds has TI-89 sitting next to keyboard
23:09:12 <mgsloan> RPN!!
23:09:28 * mgsloan has hp49G+ at side
23:09:30 <dolio> Well, I read a blog that alleged that Adrian Hey said that Haskell is essentially a sophisticated academic calculator. So obviously Cale doesn't need anything beyond that. :)
23:09:32 <hatds> pretty print has spoiled me on basic hand calculators
23:10:12 <Jebdm> dolio: Technically, all programming languages are sophisticated calculators.
23:10:15 * wli used to be remarkably good at doing symbolic integration by hand.
23:10:40 <Cale> dolio: Well, right. All the calculations that I'm interested in either can't be done by computers at present, or they're the sort of thing which is best served by a CAS. That, or they are so trivial that a calculator would be a waste.
23:10:41 <edwardk> RPN is mathematical Yoda-speak
23:10:48 <pumpkin_> dons: I think it's been turning out nicely so far, but it's added a little bit of complexity (that I plan to try to factor out with more common cases between lazy/strict later)
23:11:02 <lispy> edwardk: I always thought RPN was like japanese.  The verb comes at the end
23:11:08 <dons> interesting.
23:11:17 <ksf> integrals were the point where I couldn't force myself to accept that formalistic school BS any more, and consequently dropped to an F.
23:11:18 <dons> dolio: oh, i think i read that blog
23:11:38 <ksf> rpn == x87
23:11:46 <dolio> dons: I imagine you did. :)
23:12:13 <pumpkin_> the main thing I miss right now is TH support for associated types... I'm using a ruby script to generate all the boilerplate code and it's painful
23:13:06 <ksf> pumpkin_, come join me chanting "Sexpr, oh thou joyful parens!"
23:13:11 <pumpkin_> lol
23:13:25 <pumpkin_> Sexpr, oh thou joyful parens!
23:13:28 <pumpkin_> thy?
23:13:36 <pumpkin_> thy seems to fit better :)
23:14:13 <Berengal> Sexprs are remarkably good at describing data
23:14:27 <ksf> It's an ode to joy cover, so we have to start with a discription of being, not of having...
23:14:31 * Berengal has been working on a sexpr -> xml converter to minimize typing at work
23:15:09 <Jebdm> Berengal: If you allow indentation-based formatting, it's even less typing, and it's easier to read
23:15:15 <ski> (ksf : `F' meaning ?)
23:15:36 <Berengal> Jebdm: Maybe. I need to finish this program first though
23:15:53 <ksf> ski, f?
23:16:00 <ksf> ah, f.
23:16:02 * Jebdm thinks he has one laying around somewhere.
23:16:08 <ski> (".. and consequently dropped to an F.")
23:16:26 <edwardk> ski: failing grade
23:16:54 <Berengal> I've been diving rather deeper than I'm used to into the various haskell libraries lately
23:17:01 <ksf> technically, it was a 5.3 or 6.
23:17:08 <ski> (Berengal : if you ask on #scheme or #lisp, they might suggest already written such converters .. (though probably they're not written in haskell))
23:17:16 <ski> edwardk : ah
23:17:31 <Berengal> First parsec to parse sexprs to xml, then gtk2hs to try to make a proper gui, and now hdbc to make a todo program to keep track of exactly what I'm trying to do
23:17:52 <Berengal> ski: I know they exist, but learning all this stuff is too much fun
23:17:56 <ksf> that's "deficient, minus" and "insufficient"
23:19:47 <lispy> Berengal: What about going even higher level than sexpr and generating the xml?
23:20:16 <lispy> Berengal: haskell makes it quite easy to define an edsl and then generate things from that
23:20:48 <Berengal> lispy: Well, I haven't actually started writing any xml yet, but I've been told I'll have to in about a month or so
23:21:12 <Berengal> lispy: So I don't really know what it's supposed to look like except a few lines given in a demo
23:21:13 <lispy> Berengal: okay.  what does the xml represent?
23:21:28 <Berengal> lispy: That's the best part: "workflows"
23:21:53 <lispy> Berengal: ant?
23:22:15 <lispy> Berengal: or my next question, so how long have you worked at IBM?
23:22:17 <lispy> )
23:22:17 <Berengal> During the demo I inadvertently blurted out "greenspun", and some of the devs working on the project nodded affirmatively
23:22:19 <lispy> ;)
23:22:28 <ksf> "workflow" as in "monad for homeless"?
23:22:41 <Berengal> Basically, it's a lisp EDSL with xml syntax...
23:22:52 <Berengal> (Except it's not embedded in lisp, but rather java)
23:22:53 <lispy> Berengal: I don't get the "greenspun" joke, what is that related to?
23:23:23 <Nafai> Berengal: Greenspun's tenth?
23:23:30 <Berengal> @google greenspuns tenth rule
23:23:31 <lambdabot> http://en.wikipedia.org/wiki/Greenspun's_Tenth_Rule
23:23:31 <lambdabot> Title: Greenspun's Tenth Rule - Wikipedia, the free encyclopedia
23:23:49 <lispy> I have a love hate relationship with xml.  I can see how you can quickly define a new data format by using it, but at the same time, it's ugly and verbose.
23:23:52 <Berengal> lispy: with a name like that I'm surprised you haven't heard of it
23:24:17 <lispy> Berengal: oh! that rule
23:24:25 <lispy> Berengal: Sorry, I forget things :)
23:24:34 <Berengal> Don't we all :)
23:24:57 <lispy> I once read a critique that said, "The problem XML solves is not hard, and the solution in provides is not good."
23:25:06 <Berengal> I tend to agree
23:25:08 <ksf> I tend to prefer ADT's over xml and functions over xslt
23:25:23 <lispy> Well, xslt can be easier than C++
23:25:43 <ksf> sure, foldl typechecks without major contortions.
23:25:43 <lispy> But, I would always prefer ADTs and functions in Haskell over xslt and xml
23:27:12 <Berengal> It would be really nice if I could get my hands on the xml specs and create an edsl though...
23:27:31 <ksf> haxml is really nice.
23:27:37 <Berengal> However, I'm probably the only one writing this xml with any sort of dev experience
23:28:01 <ksf> as soon as you've got your hands on a dtd, you don't need to touch the <> keys, at all.
23:28:07 <ksf> ...except for >>= and the like.
23:28:16 <edwardk> lispy: it can also be a lot harder =)
23:28:24 <edwardk> (xslt that is)
23:28:34 <lispy> ksf: yeah, but at some point we need to update that dtd to haskell bit to handle xsd
23:28:45 <quicksilver> xslt's not so terrible.
23:28:45 <Berengal> Yeah, I'm probably going to use something like that to process the xml at least, but I still need the dtd (and the semantics of the "language2)
23:28:50 <quicksilver> it's pretty declarative
23:29:02 <lispy> ksf: I would have done that actually, except I found a dtd file "just in time" for my schema
23:29:02 <quicksilver> and not as hideously verbose as some parts of the xml biosphere
23:29:14 <Jebdm> Is there a way to use ADT's as an Enum and choose which enum is equivalent to which integer?
23:29:27 <quicksilver> Jebdm: sure. Write your own Enum instance.
23:29:34 <quicksilver> Jebdm: it's your type, you get to choose :)
23:29:53 <edwardk> i';m just amused that xml is the easiest example of a nicely parallelizable parsing format in common use with huge documents
23:29:54 <quicksilver> data Foo = A | B; instance Enum Foo where fromEnum A = 42; fromEnum B = 97;
23:30:22 <edwardk> and that folks have already built specialized parallel parsers for it that do kind of what i'm trying to do in general
23:30:23 <Jebdm> i guess what i was looking for was a simple/nonredundant syntax ;)
23:30:51 <Berengal> edwardk: You and your parallel parsing
23:30:53 <lispy> Jebdm: maybe you need drift or derive
23:31:03 <Berengal> Jebdm: "deriving (Enum)" what you want?
23:31:20 <quicksilver> also, adding a fairly natural restriction to apply-templates makes xslt always terminate.
23:31:25 <edwardk> Jebdm: data Foo' = A | B | C deriving (Enum); newtype Foo = Foo Foo'; instance Enum Foo where ... and then manually use the instance on Foo' ;)
23:31:26 <ksf> edwardk, ebml is even better for that.
23:31:27 <quicksilver> that's nice, for a transformation language.
23:31:32 <Jebdm> No--deriving it sets them automatically
23:31:46 <ksf> ...especially if you have meta-seek information, like matroska does.
23:31:55 <hatds> lol, nice trick there edwardk
23:32:18 <edwardk> Jebdm: i derived in a data type that i wrapped.
23:32:19 <ksf> you don't even need lookahead to find the end of an element or block, in the common case.
23:32:26 <lispy> Jebdm: and don't forget that you can [ 1 .. 10] and then use things like zipWith in the definition to automate the tedious bits of the Enum instance
23:32:35 <ksf> (but then, it's binary)
23:32:50 <Jebdm> edwardk: I don't see it, could you fill out what would go after where?
23:34:12 <hatds> I think he means you supply your manual definition, but you can use the automatically created Foo' instance to help write that definition
23:34:13 <edwardk> Jebdm instance Enum Foo where fromEnum (Foo x) = x - 4; toEnum x = Foo (toEnum x + 4) -- to slide the range around for instance. i didn't say it was GOOD just an option ;)
23:34:35 <Jebdm> Ah.
23:34:38 <edwardk> Jebdm: there is always template haskell =)
23:35:01 <lispy> isn't data.derive a version of template haskell just for this situation?
23:35:02 * Jebdm doesn't want to go there
23:35:59 <edwardk> jebdm: in the end if i need a manual instance i just pretend i'm writing ML and that newtype deriving doesn't exist and i suck it up and write it ;)
23:36:32 <edwardk> how many constructors are we talking anyways?
23:36:48 <Jebdm> edwardk: in the hunderedish range
23:37:00 <edwardk> Jebdm: thats a great application for template haskell =)
23:37:19 <Jebdm> How would template haskell help?
23:37:20 <Berengal> Jebdm: I was about to agree with you on your TH sentiment, but then you go ahead and say something like that...
23:37:31 <Berengal> Well, I'm sure emacs macros could help as well...
23:37:42 <edwardk> Jebdm: you can ask using template haskell for all of the constructors for the type and then do anything you want
23:37:50 <Jebdm> All I'm really looking for is a way to do:
23:37:50 <Jebdm> enum Instruction{ x=0; y=42; }
23:38:03 <Berengal> Or some clever regex substitution... I've learned quite a few tricks coding java...
23:38:13 <Jebdm> It's just a straight enum, nothing complicated :)
23:38:47 <quicksilver> instrTable = [(X,0),(Y,42),....]
23:38:55 <lispy> Jebdm: if it's defined in some other language already, what about using one of the existing parsers to create it?
23:39:03 <Jebdm> lispy: It's not.
23:39:13 <quicksilver> revTable = map (\(x,y) -> (y,x)) instrTable
23:39:34 <quicksilver> instance Enum instrTable where fromEnum i = fromJust $ lookup i instrTable
23:39:38 * inimino wonders idly if the most significant benefit of Java is inducing people to try code generation
23:39:38 <lispy> > let nike = "Just do it." in nike
23:39:40 <lambdabot>   "Just do it."
23:39:45 <quicksilver> toEnum i = fromJust $ lookup i revTable
23:39:47 <quicksilver> job done.
23:40:03 <quicksilver> Jebdm: how's that?
23:40:15 <edwardk> and if you want you can throw a couple of arrays in there to speed up the accesses
23:40:18 <brian6> is there still a problem with forkProcess and -threaded?
23:40:21 <quicksilver> or at least Data.Maps
23:40:52 <Jebdm> quicksilver: It still doesn't save me from having to repeat all of my constructors twice
23:41:07 <quicksilver> <pedant>You're only repeating them once</pedant>
23:41:16 <Berengal> Heh
23:41:16 <Jebdm> Haha, good point.
23:41:26 <Berengal> This is what copy-paste was made for
23:41:36 <Jebdm> Yeah, but it's an actively-changing enum
23:41:41 <Jebdm> as I screw with my instruction set
23:41:48 <Jebdm> thus becoming a pain to maintain
23:41:49 <quicksilver> then generate it with a simple script from a simple definition file.
23:41:55 <Berengal> Jebdm: Emacs macro?
23:41:56 <quicksilver> even CPP is probably enough for this
23:42:25 <quicksilver> have a file full of "INSTR(X,42)"
23:42:43 <Berengal> How to write java: Ctrl-c, Ctrl-v, Ctrl-f, check "enable regexps", code
23:42:44 <edwardk> you could always abuse a c2hs enum *cough*
23:42:48 <quicksilver> #include it onece with #define INSTR(a,b) = ,(a,b)
23:42:52 <quicksilver> (to build the table)
23:42:59 <quicksilver> and once with INSTR(a,b) = | a
23:43:02 <quicksilver> (to build the data type)
23:43:38 <Jebdm> Yeah, fuck it, I guess it's worth writing a little parser.
23:43:56 <Jebdm> It'll save me from having to manually write a lot of array retrievals anyways.
23:44:24 <Jebdm> maybe I'll use XML ;)
23:44:38 <edwardk> http://www.cse.unsw.edu.au/~chak/haskell/c2hs/docu/implementing.html#id314717 -- is probably the simplest but worst 'fix' i can come up with that directly solves the problem with one definition
23:44:52 * wli writes little parsers all the time.
23:44:55 <quicksilver> well my example uses CPP as the parser.
23:44:55 <quicksilver> saves you writing one ;)
23:44:55 <quicksilver> you could use sed or perl if you prefer.
23:44:55 <quicksilver> but ghc does have some support for automatically invoking CPP
23:44:55 <quicksilver> so that's probably simplest.
23:45:24 <Berengal> Or... there's always TH....
23:45:34 <wli> have a -main-is thing for each module, attach a parser and repl to it, test by interacting with the repl.
23:46:18 <lispy> in my exprerience it's good to isolate the generated code into it's own module
23:46:22 <lispy> then just import it
23:46:29 <Jebdm> Well, what I was enumerating was instructions; I figure since I'm already doing code generation, it's probably pretty simple to expand it a bit so that I can do things like automatically generating code to retrieve stuff from memory
23:46:47 <lispy> anyway, good night peeps
23:46:52 <lispy> good luck Jebdm
23:47:13 <Jebdm> lispy: 'night, thanks
23:49:38 <brian6> tibbe: is it still bad to do forkProcess with -threaded?
23:49:54 <tibbe> brian6: afaik yes :(
23:49:54 <lambdabot> tibbe: You have 1 new message. '/msg lambdabot @messages' to read it.
23:51:10 <brian6> tibbe: ok, thanks.
23:51:47 <tibbe> @tell dons I'll look into it. I don't have a windows machine though
23:51:47 <lambdabot> Consider it noted.
23:56:50 <dancor_> is there a better/more-direct way to do  HSH.run ("mkfifo", ["my_fifo"])
23:58:35 <ivanm> dancor_: \ r -> HSH.run (r, [r]) ?
23:58:48 <ivanm> @pl \ r -> HSH.run (r, [r])
23:58:49 <lambdabot> HSH.run . ap (,) return
23:59:14 <Twey> ivanm: ?
23:59:26 <Twey> That's... not what was asked for :-P
23:59:29 <Twey> dancor_: Better how?
23:59:42 <Twey> An internal Haskell approach?
