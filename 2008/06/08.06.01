00:00:21 <dmwit> ?index UArray
00:00:22 <lambdabot> Data.Array.Unboxed
00:13:39 <dmwit> hum
00:13:51 <dmwit> :t ST.runSTUArray $ createFactorCounts 10 -- gives an error
00:13:57 <lambdabot> Couldn't find qualified module.
00:14:17 <dmwit>  :t ST.runSTUArray $ createFactorCounts 10 :: UA.UArray Int Int -- does not give an error
00:16:46 <Lemmih> dmwit: createFactorCounts is too general?
00:17:43 <dmwit> I guess so, but I don't understand how or why.
00:18:20 <dmwit> I thought the big idea of HM type systems was that anything that has some valid type has an automatically-inferrable most general type.
00:27:14 <nolrai_> what does "the eta-reduction property does not hold" mean in an erro about newtype deriving?
00:27:27 <nolrai_> s/erro/error
00:28:17 <nolrai_> never mind i think i got it.
00:31:00 <Twey> nolrai_: That's one scary-lookin' error you got there, sonny-Jim... O.O
01:02:01 <kaol> I'm trying to come up with a way to write code that can both generate XSLT and apply it to a haskell data structure and generate XML. Fun stuff.
01:03:58 <kaol> trying to include some sort of caching logic with those document() XSL functions too
01:05:37 <int-e> hGetContents--
01:44:57 <quicksilver> int-e++
01:49:42 <Saul_> I'm having some problems installing hsql 1.7
01:49:45 <Saul_>     Could not find module `System.Time':
01:49:45 <Saul_>       it is a member of package old-time-1.0.0.0, which is hidden
01:50:48 <Saul_> Does anyone know how to fix this?
01:51:22 <quicksilver> it means hsql hasn't been ported to 6.8.2 I think
01:51:33 <quicksilver> you can try adding old-time to the depends in the cabal
01:51:40 <quicksilver> and keep adding any more packages it complains about
01:53:26 <Saul_> Ok I'll try it
01:56:29 <Saul_> ok I think I got it
01:56:53 <Saul_> I also got a compile error, but adding -fglasgow-exts solved it
01:59:18 <Saul_> Hmmz now I get this error while configuring hsql-mysql
01:59:20 <Saul_> Setup.lhs:8:33:
01:59:20 <Saul_>     Module
01:59:20 <Saul_>     `Distribution.Simple.Utils'
01:59:20 <Saul_>     does not export
01:59:21 <Saul_>     `rawSystemVerbose'
02:02:47 <Saul_> Oh great it even says so on the hackage page
02:02:48 <Saul_> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/hsql-mysql
02:02:50 <lambdabot> http://tinyurl.com/5khq9n
02:19:19 <Saul_> Argh, I figured I would use HDBC sqlite instead, and I get different weird errors :(
02:20:32 <Heffalump> I use hsql-mysql with ghc 6.8.2, but I can't remember if I had to make any local changes
02:21:14 <Heffalump> hmm, none that I can find
02:26:22 <Saul_> :(
02:30:28 <Saul_> It seems like the Setup.lhs file itself is containing compile errors
02:31:08 <Saul_> I took out the explicit import of rawSystemVerbose (it's not even used) but now I got other errors that are less easy to solve
02:35:20 <Heffalump> which cabal are you using?
02:36:58 <Heffalump> you might want to build from the darcs repo at http://code.haskell.org/HSQL/ instead
02:36:58 <lambdabot> Title: Index of /HSQL
02:41:01 <Saul_> I'm using Cabal-1.2.3.0
02:41:46 <Saul_> which appears to be the newest version
02:41:55 <Heffalump> for 6.8.2, yeah
02:42:08 <Heffalump> try that darcs repo for HSQL, I'm fairly sure I've built it ok from that
02:43:08 <Saul_> ok
02:44:50 <Saul_> Setup.lhs:9:7:
02:44:50 <Saul_>     Could not find module `Distribution.PackageDescription.Parse':
02:44:50 <Saul_>       Use -v to see a list of the files searched for.
02:44:57 <Saul_> different error :)
02:48:37 <Heffalump> Wed Apr 16 06:56:15 BST 2008  marco-oweber@gmx.de
02:48:38 <Heffalump>   * fixed verbose flag FIXME in Setup.lhs of MySQL
02:48:40 <Heffalump> unpull that patch
02:50:45 <Saul_> Heffalump: How do I use unpull to unpull that patch?
02:50:58 <Saul_> I'm not that savy with darcs yet
02:51:02 <dmwit> darcs unpull -p "verbose flag FIXME"
02:55:50 <Saul_> ok that seemed to work, thanks dmwit and Heffalump
03:12:26 <mxc_> is anyone here familiar with Data.Binary and laziness?
03:12:47 <mxc_> quesiton is, if i have a tuple (x,y) that I decode
03:13:05 <mxc_> say data MyTup = MyTup (x,y)
03:13:26 <mxc_> and in the get implementation, the data for x is read frist, if I never reference y, will it just lazily ignore it?
03:13:45 <Twey> Yep
03:14:22 <mxc_> cool, so in my situation, x is a single word8 which functions use to determine if they want to decode y (some big ugly record)
03:14:33 <mxc_> speed is important so i only want to decode y when necessary
03:15:22 <mxc_> thanks twey
03:16:09 <Twey> Welcome
03:16:16 <Heffalump> the downside of it being lazily ignored is that the source data will hang around as long as references to y do
03:18:34 <MedeaMelana> morning
03:26:19 <flippo> preflex, be poppavic
03:26:19 <preflex>  dude, you need to stop hollering and either spend more verbage explaining it to them or just DON'T.
03:26:33 <flippo> (Sorry.)
03:27:45 --- mode: ChanServ set +o Heffalump
03:28:04 --- mode: Heffalump set +b *!*@bzq-219-46-202.isdn.bezeqint.net
03:34:51 <vixey> Heffalump, why ban it?
03:35:29 <Twey> Wasn't the real IRSeekBot
03:38:31 <MedeaMelana> it's quiet today
03:40:17 <vixey> > let f91 x | x > 100 = x - 10 | otherwise = f91 . f91 $ x + 11 in map f91 [1..]
03:40:19 <lambdabot>  [91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,...
03:41:28 <MedeaMelana> does that work for other numbers than -10 too?
03:43:36 <Heffalump> vixey: I assumed it was up to something nefarious, given the number of times it's flooded itself of
03:43:41 <MedeaMelana> > let f91 x | x > 100 = x - 9 | otherwise = f91 . f91 $ x + 11 in map f91 [1..]
03:43:42 <Heffalump> do you know something about it?
03:43:43 <lambdabot>  [92,93,92,93,92,93,92,93,92,93,92,93,92,93,92,93,92,93,92,93,92,93,92,93,92,...
03:44:09 <mercury^> MedeaMelana: maybe you have to adjust teh +11 too
03:45:14 <MedeaMelana> > let f91 x | x > 100 = x - 9 | otherwise = f91 . f91 $ x + 10 in map f91 [1..]
03:45:15 <lambdabot>  [92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,...
03:45:24 <MedeaMelana> hmm
03:46:13 <nornagon> > repeat 92
03:46:14 <lambdabot>  [92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,...
03:46:21 <MedeaMelana> Something else I've been wondering about: why isn't ($) defined as id, with type a -> a ?
03:46:31 <nornagon> @src ($)
03:46:31 <lambdabot> f $ x = f x
03:46:35 <vixey> MedeaMelana: that's a valid definition
03:46:46 <MedeaMelana> :t ($)
03:46:48 <lambdabot> forall a b. (a -> b) -> a -> b
03:46:52 <MedeaMelana> :t id
03:46:54 <lambdabot> forall a. a -> a
03:46:58 <vixey> MedeaMelana: (a -> b) -> a -> b is more descriptive though
03:47:17 <MedeaMelana> yes, more descriptive, more restrictive
03:47:26 <nornagon> more restrictive?
03:47:28 <nornagon> how?
03:47:33 <vixey> it's not a restriction
03:47:36 <vixey> id still exists
03:47:44 <nornagon> a -> a is a subset of a -> b
03:48:05 <MedeaMelana> > head `id` [1..]
03:48:06 <lambdabot>  1
03:48:11 <MedeaMelana> > head $ [1..]
03:48:12 <lambdabot>  1
03:48:22 <vixey> > id 3
03:48:23 <lambdabot>  3
03:48:24 <vixey> > ($) 3
03:48:25 <lambdabot>   add an instance declaration for (Num (a -> b))
03:48:42 <MedeaMelana> yes, that makes it more restrictive, I think
03:48:47 <MedeaMelana> id does everything $ does
03:48:49 <nornagon> ah, right.
03:49:05 <vixey> id has a more general type
03:49:16 <nornagon> sry, not thinking :P
03:49:41 <mercury^> MedeaMelana: you can force the type of something with $
03:49:56 <MedeaMelana> Yes. Why is that useful here?
03:50:20 <vixey> > map ($ 3) [(+3), (*2)]
03:50:21 <lambdabot>  [6,6]
03:50:41 <mercury^> MedeaMelana: I had a good example where you needed $ and could not use id
03:50:46 <mercury^> now I just need to remember it
03:50:48 <mercury^> -.-
03:50:58 <MedeaMelana> Maybe vixey's example works?
03:51:03 <vixey> mercury^: I don't think that it exists
03:51:09 <nornagon> > map (`id` 3) [(+3),(*2)]
03:51:10 <MedeaMelana> > map (`id` 3) [(+3), (*2)]
03:51:10 <lambdabot>  [6,6]
03:51:11 <lambdabot>  [6,6]
03:51:14 <vixey> :t id :: (a -> b) -> a -> b
03:51:16 <lambdabot> forall a b. (a -> b) -> a -> b
03:51:17 <nornagon> :D
03:52:11 <MedeaMelana> I realized a while ago that $ is id for functions, but I never realized that it actually *is* id
03:52:21 <vixey> currying
03:52:24 <Heffalump> well, it's not because of the type
03:52:37 <Heffalump> The only reason I can think of for restricting the type is to improve error messages
03:52:50 <MedeaMelana> That's a good reason
03:52:50 <vixey> I think the type is documentation
03:53:47 <Heffalump> I can't think of a good example of it actually improving an error message in any sensible use, though.
03:54:13 <vixey> and f $ x = f x describes its use much better than ($) = id
03:54:16 <MedeaMelana> You have to misuse $ before you get any error messages
03:54:30 <MedeaMelana> How could one misuse $
03:54:39 <vixey> > 7 * ($)
03:54:40 <lambdabot>        add an instance declaration for (Num ((a -> b) -> a -> b))
03:54:48 <MedeaMelana> I mean, what are understandable ways to misuse $
03:54:55 <vixey> there aren't any
03:55:07 <vixey> any badly typed expression is nonsens
03:55:40 <MedeaMelana> What I mean is: some mistakes are easily made and very common.
03:55:47 <MedeaMelana> At least for those who are new to Haskell.
03:56:16 <Heffalump> I meant "any sensible misuse"
03:56:23 <vixey> > let f91 x | x > 100 = x - 10 | otherwise = f91 . f91 $ x + 11 in drop 95 (map f91 [1..])
03:56:24 <lambdabot>  [91,91,91,91,91,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,1...
03:56:26 <Heffalump> i.e. any code that someone might reasonably be trying to write, but got wrong
03:56:37 <MedeaMelana> Exactly
03:57:01 <MedeaMelana> Of course, there's normal misapplication of arguments to functions, and the programmer might have used $ there
03:57:41 <Heffalump> the thing is, as soon as you use it as a fully-applied infix operator, its type is forced to the function type anyway
03:57:46 <Heffalump> since that's the only way it can take two arguments
03:58:04 <Heffalump> so a "sensible misuse" would have to use it as a sectioned operator somehow
03:58:25 <vixey> any misuse of ($) will look like nonsense
03:58:34 <MedeaMelana> > head True
03:58:34 <lambdabot>  Couldn't match expected type `[a]' against inferred type `Bool'
03:58:40 <vixey> just like 7 * ($)
03:58:40 <MedeaMelana> > head $ True
03:58:41 <lambdabot>  Couldn't match expected type `[a]' against inferred type `Bool'
03:58:46 <MedeaMelana> > head `id` True
03:58:47 <lambdabot>  Couldn't match expected type `Bool' against inferred type `[a]'
03:58:53 <MedeaMelana> hehe
03:59:07 <Heffalump> vixey: I'm not completely convinced of that, but I certainly can't think of any good examples to contradict it.
03:59:25 <Heffalump> MedeaMelana: ok, that's actually halfway decent
03:59:26 <vixey> *any* badly typed expression is complete nonsense
03:59:33 <Heffalump> vixey: oh, now that is rubbish
03:59:44 <Heffalump> a simple error can move you from a well-typed expression to an ill-typed one
03:59:46 <vixey> if it doesn't type the expression has no meanin
04:00:05 <Heffalump> the question is how well the implementation does at explaining what is wrong to the user
04:00:12 <vixey> :t 2 ^ 0.5
04:00:14 <lambdabot>     Ambiguous type variable `t' in the constraints:
04:00:14 <lambdabot>       `Integral t' arising from a use of `^' at <interactive>:1:0-6
04:00:14 <lambdabot>       `Fractional t'
04:00:23 <vixey> this -doesn't- take the square root of two
04:00:25 <Heffalump> MedeaMelana: because there's nothing in head $ True that has type [a], so it's a bit odd to see it being inferred for something.
04:02:21 <MedeaMelana> vixey: the question is whether $'s current (restrictive) type could ever improve the quality of error messages
04:02:41 <MedeaMelana> apart from the fact that it's current type describes its common use better
04:02:48 <MedeaMelana> its*
04:02:51 <vixey> > ($) 3
04:02:52 <lambdabot>   add an instance declaration for (Num (a -> b))
04:03:41 <Heffalump> that's a nice example too
04:04:03 <MedeaMelana> i'm not sure what that shows
04:04:20 <Heffalump> > id 3
04:04:21 <lambdabot>  3
04:04:22 <vixey> it's at type error I got from misuse of ($)
04:04:30 <Heffalump> it provides an error that you wouldn't have got from id
04:04:34 <Heffalump> which is useful
04:04:45 <Heffalump> > id 3 2
04:04:46 <lambdabot>   add an instance declaration for (Num (t -> a))
04:04:49 <Heffalump> > ($) 3 2
04:04:50 <lambdabot>   add an instance declaration for (Num (a -> b))
04:04:57 <vixey> anyway the real reason ($) :: (a -> b) -> a -> b is documentation as I said before
04:05:20 <MedeaMelana> probably
04:05:20 <Heffalump> do you actually know this from a historical perspective, or are you just guessing?
04:05:30 <MedeaMelana> which i'm not sure is a good enough reason
04:05:33 <vixey> it suggests:  ((foo :: a -> b) $ (bar :: a)) :: b
04:11:23 <kowey> ?seen gour
04:11:23 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
04:11:43 <Heffalump> I guess it's database is broken
04:11:49 <Heffalump> s/it's/its/
04:12:09 <kowey> hmm... yeah, just signaling the problem
04:22:43 <MedeaMelana> I think it'd be pretty fun if everywhere I wrote id I could write ($) instead :-)
04:23:12 <MedeaMelana> Though id is a better name for identity
04:23:47 <Baughn> $ does have the distinct advantage of being slicable
04:24:06 <Baughn> map (`id` 42) [(+1)] just doesn't have the same feel. ;)
04:24:16 <Baughn> > map (`id` 42) [(+1)] -- does it even work?
04:24:17 <lambdabot>  [43]
04:24:23 <MedeaMelana> What does slicable mean here?
04:24:53 <Baughn> ($ 42) <- There. A slice. Unless of course I completely forgot the right word to use.
04:25:07 <Deewiant> a section, I believe, is the standard term.
04:25:21 <MedeaMelana> Ah, right
04:25:21 <Baughn> Right you are
04:25:40 <MedeaMelana> Maybe $ is more easy to optimize if it is restricted to functions?
04:28:16 <Baughn> @type id
04:28:18 <lambdabot> forall a. a -> a
04:28:23 <Baughn> @type `id` 42
04:28:25 <lambdabot> parse error on input ``'
04:28:29 <Baughn> @type (`id` 42)
04:28:30 <MedeaMelana> you need ()
04:28:31 <lambdabot> forall t t1. (Num t) => (t -> t1) -> t1
04:30:25 <MedeaMelana> Because most (non-section) uses of $ can be trivially rewritten to an expression with $ but with more parentheses. Which might save a reduction?
04:30:52 <MedeaMelana> I meant without $
04:31:27 <Baughn> The optimizer does a fine job. Don't worry about it.
04:31:41 <MedeaMelana> That doesn't help
04:34:56 <Saul_> @seen shapr
04:34:57 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
04:35:08 <Saul_> awesome
04:35:53 <maltem___> Do I remember incorrectly, or wouldn't ($) having the general type of id :: a -> a be impossible in Haskell98?
04:36:22 <mattam> @type flip id
04:36:24 <lambdabot> forall b c. b -> (b -> c) -> c
04:36:35 <Philippa_> MedeaMelana: if you're working with purely unoptimised implementations then yes, $ is slower. Any compiler that can do inlining will inline something as small as $ though
04:36:36 <lambdabot> Philippa_: You have 1 new message. '/msg lambdabot @messages' to read it.
04:36:46 <Baughn> @dict-all pulchritudinous
04:36:46 <lambdabot> Unknown command, try @list
04:37:37 <MedeaMelana> Yes, so what I was asking is: maybe inlining $ is easier if it has type (a -> b) -> a -> b instead of a -> a
04:38:01 <MedeaMelana> But I guess that doesn't make much sense
04:39:08 <Baughn> It gets inferred down to a concrete type either way
04:47:24 <ziman> @pl \f -> f x1 x2
04:47:25 <lambdabot> flip ($ x1) x2
04:47:49 <Saul_> is there any decent documentation out there for either haskelldb or hsql (in a tutorial-like fashion)?
04:48:16 <Saul_> and are they mature enough to use, or should I use something else?
04:49:05 <Baughn> I've done fine with just hdbc
04:49:46 <Baughn> (hsql lacks parametrized queries. Don't use it.)
04:53:12 * MedeaMelana waves
04:57:42 <Heffalump> as long as you're careful about SQL injection, parameterized queries are just an efficiency concern
04:57:53 <jeffz> http://reddit.com/r/prolog/info/6llqb/comments/ might be of general interest to people - "A Wake Up Call for the Logic Programming Community", Haskell is mentioned a few times
05:02:13 <opqdonut> hmm
05:02:25 <xci> mmh
05:04:59 <augustss> mhm
05:06:46 <mattam> hmm
05:06:54 <ivanm> mmh?
05:07:04 <ivanm> oh, what, xci already did that one
05:07:24 <Heffalump> no, xci did the other one
05:07:39 <Heffalump> mhm
05:07:44 <Heffalump> now we're done
05:07:50 <augustss> i did that one
05:07:52 <ivanm> no, xci did mmh...
05:07:59 <ivanm> and opqdonut beat mattam
05:08:05 <Heffalump> no, you did the other one. Can't you tell the difference between your 'm's? :-)
05:08:24 * ivanm 's brain hurts
05:09:49 <int-e> @type liftM2 const
05:09:52 <lambdabot> forall a1 a2 (m :: * -> *). (Monad m) => m a1 -> m a2 -> m a1
05:10:28 <PantheraPardus> err, what does mhm stand for?
05:10:43 <ivanm> PantheraPardus: permutation of "hmm"
05:11:18 <PantheraPardus> hmm
05:12:10 * ivanm resists the temptation to start that nonsense all over again
05:12:48 <PantheraPardus> lol
05:13:00 <Heffalump> llo
05:13:12 <ivanm> *sigh*
05:13:17 * PantheraPardus waits for the last variant
05:13:55 <PantheraPardus> let's do it ;)
05:15:35 <DRMacIver> Hm. gtk2hs appears to have bytestring 0.9.0.5 as a dependency.This is somewhat perplexing as such a package does not exist.
05:16:17 <ivanm> which version of gtk2hs?
05:16:25 <ivanm> there's a bytestring-0.9.1.0 ...
05:16:34 <DRMacIver> Yes, and I have that.
05:16:44 <DRMacIver> gtk2hs 0.9.12.1
05:17:17 <DRMacIver> But the build is failing with ghc-6.8.2: unknown package: bytestring-0.9.0.5 (dependency of cairo-0.9.12.1)
05:17:31 <ivanm> hmmm, I don't have it requring bytestring at all...
05:17:50 <ivanm> though that's because dcoutts didn't set it as a dependenciy in the ebuild ;-)
05:17:56 <ivanm> @seen dcoutts
05:17:56 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
05:18:01 <ivanm> preflex: seen dcoutts
05:18:01 <preflex>  dcoutts was last seen on #gentoo-haskell 1 day, 3 hours, 31 minutes and 38 seconds ago, saying: hia ivanm
05:19:19 <DRMacIver> There's definitely a ByteString dependency in the makefile. Even more curiously, it's set to 0.9.1.0
05:24:25 <DRMacIver> Hm. Couldn't be a ghc compatibility issue could it? gtk2hs only explictly mentions 6.8.1 and 6.6.1, but I'm running 6.8.2. (I can't really imagine that being the problem though)
05:24:44 <ivanm> I doubt it
05:24:55 <ivanm> how are you installing it? make?
05:25:00 <DRMacIver> yeah
05:25:12 <ivanm> ... wierd
05:25:24 <DRMacIver> I'm really good at generating that reaction. :)
05:25:56 <ivanm> lol
05:26:37 <DRMacIver> Anyway, I've tried ghc-pkg hiding the old version of bytestring I also had installed and am rebuilding. Will see if that helps.
05:34:14 <DRMacIver> That seems to have done it
05:43:35 <DRMacIver> Is it normal to find glade completely and utterly maddening?
05:43:48 <TSC> Yes
05:43:56 <DRMacIver> ok. Just wanted to make sure.
05:43:58 <TSC> At least common (:
05:46:07 <kpreid> Disagreement: http://blog.plover.com/prog/glade.html
05:46:08 <lambdabot> Title: The Universe of Discourse : Glade
05:46:18 <DRMacIver> Yes, I saw that.
05:46:31 <DRMacIver> It's a large part of why I decided to give this stuff a try. :)
05:47:06 <DRMacIver> But it's also an example that would be trivial in any GUI builder that even pretends to the name.
05:49:38 <DRMacIver> You never know, I might get used to it and love it. But initial impressions of the w handles widget layout and similar are very far from positive.
05:51:35 <kpreid> DRMacIver: Ah. Yeah, I recognize the difference and was being a bit silly
05:52:00 <DRMacIver> Fair enough. :)
06:17:38 <jaj> I think back then when glade was able to create C/python/whatever code it was quite interesting but now that you have to depend on libglade and you have to have an xml file lying around it's a bit annoying
06:18:26 <DRMacIver> On the other hand makes it a bit easier to use with new languages (like Haskell) :)
06:18:44 <jaj> of course it's quite difficult to support different languages and generate good code for them
06:20:15 <jaj> I think it would be quite interesting to create a DSL which let's you describe a GUI. I never used gtk2hs, perhaps it can do that? :)
06:21:37 <wjt> jaj: perhaps you could write a gladexml -> Hypothetical Gtk DSL converter? :)
06:22:05 <DRMacIver> Hm. I love it when tutorials purport to be for the version of the software you're using and refer to features that flat out don't exist.
06:23:34 <jaj> wjt: that would be interesting :) not sure I'm up to the task but I could try
06:25:37 <DRMacIver> And the fact that the glade documentation is full of sections like "FIXME" and "Please Write Me" continues to make me less than happy with it. :)
06:53:47 <Jaak> deamnit, is hoogle down?
06:56:06 <ivanm> @hoogle map
06:56:06 <lambdabot> Prelude.map :: (a -> b) -> [a] -> [b]
06:56:06 <lambdabot> Data.List.map :: (a -> b) -> [a] -> [b]
06:56:06 <lambdabot> Data.ByteString.map :: (Word8 -> Word8) -> ByteString -> ByteString
06:56:23 <DRMacIver> Jaak: Looks it
06:56:58 <jaj> seems like haskell.org is down
06:59:49 <Jaak> @hoogle queue
06:59:49 <lambdabot> No matches found
06:59:58 <Jaak> @hoogle min
06:59:59 <lambdabot> Prelude.min :: Ord a => a -> a -> a
06:59:59 <lambdabot> Data.Ord.min :: Ord a => a -> a -> a
06:59:59 <lambdabot> Prelude.minBound :: Bounded a => a
07:00:11 <Jaak> @hoogle findMin
07:00:11 <lambdabot> Data.Set.findMin :: Set a -> a
07:00:11 <lambdabot> Data.Map.findMin :: Map k a -> (k, a)
07:00:11 <lambdabot> Data.IntSet.findMin :: IntSet -> Int
07:04:21 <Jaak> and back up
07:06:34 <TomMD> @seen areYouWorking?
07:06:35 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
07:09:48 <DRMacIver> lambdabot is such a great example of how Haskell's strong type system helps you prevent bugs.
07:09:52 <Lycurgus> i'd call that a bug
07:10:02 <jdh30> lol
07:10:05 <DRMacIver> That might have been my point...
07:10:34 <Lycurgus> without the error message it would have been regular in-principle perfect haskell
07:10:38 <jdh30> what are you up to these days DRMacIver?
07:10:51 <TomMD> If only you could force files never to be corrupt using the type system.
07:12:29 <DRMacIver> At work, visualisation software in Scala (though soon to move to ruby due to politics). At home, the usual assortment of random hackery. How about you? Still telling the world why everything except F# and OCaml are awful?
07:12:52 <jdh30> Actually I am currently telling the world why OCaml is awful. :-)
07:13:15 <TomMD> So that only leaves F# as acceptable?
07:13:37 <jdh30> For me, yes. :-(
07:14:01 <TomMD> I take it you don't have *nix as a platform often.
07:14:17 <TomMD> *target platform
07:14:32 <jdh30> DRMacIver: is that JRuby now or Ruby Ruby?
07:15:10 <jdh30> Actually I am still predominantly Linux and several of our products are still Linux/OSX. I'm getting pretty sick of Linux to be honest though.
07:15:38 * Heffalump is very sick of Windows
07:16:11 <DRMacIver> jdh30: JRuby.
07:16:23 <Heffalump> .NET is quite nice though
07:16:27 <DRMacIver> Although we do use Ruby Ruby as well, and will probably try to make most of the code portable between the two.
07:16:45 <DRMacIver> (except for the bits that are explicitly there to use Java libraries of course)
07:16:47 <jdh30> What is JRuby like? I get the impression it is vastly more popular that IronRuby/Python on .NET?
07:17:03 <jdh30> Heffalump: yeah, .NET rocks.
07:17:14 <sclv> pl ftw: any (s ==) . map (second (drop 1) . span (/= '=') . takeWhile (/= ';') ) . map snd . filter ((HeaderName "set-cookie" ==) . fst) $ hs
07:17:35 <jdh30> I actually came here because I saw some of what DonS had written about me here.
07:17:50 <Heffalump> what did he say?
07:17:55 <mrd> sclv: pl? plz... (s ==) ?
07:18:24 <DRMacIver> JRuby seems to be among the most popular of the dynamic languages for the JVM crowd. It's moving along nicely as far as I can tell. But we're way off topic for #haskell
07:18:52 <sclv> its just a function to test if any cookie is set to a particular value on an http response. i was just happy with how condensed it came out.
07:19:06 <Heffalump> how do types work in dynamic languages on the JVM? Is everything an object?
07:19:41 <jdh30> he didn't understand why I alienate portions of the functional programming community, why I don't go to ICFP and so on. Here's a link: http://tuukka.iki.fi/tmp/haskell-2007-12-01.html
07:19:42 <lambdabot> Title: haskell-2007-12-01
07:20:27 <DRMacIver> Heffalump: How do you mean? From a user visible point of view or from an implementation point of view?
07:20:42 <Heffalump> DRMacIver: implementation
07:20:46 <jdh30> DRMacIver: Yeah. I was amazed (and very happy ;-) to see this trend: http://www.google.com/trends?q=f%23%2Cironpython
07:20:46 <lambdabot> Title: Google Trends: f#,ironpython
07:21:17 <DRMacIver> Heffalump: I think JRuby objects implement some interface which has a method pointing to a ruby style class object.
07:21:23 <DRMacIver> And are otherwise just objects.
07:21:25 <Heffalump> jdh30: I vaguely remember that conversation. It seemed accurate at the time and looks that way too now from a quick skim.
07:21:27 <jdh30> I can't explain it though.
07:21:45 <Heffalump> jdh30: but primitive types have to be objects too?
07:21:47 <DRMacIver> Heffalump: I'm not totally sure though. My Ruby foo is weak as hell. :)
07:21:48 <Heffalump> sorry, not jdh30
07:21:56 <DRMacIver> Heffalump: Yes, they typically don't get to use primitive types
07:22:09 <Heffalump> how does performance work out?
07:22:24 <sclv> bad.
07:22:30 <jdh30> I'd have thought you could optimize that away easily enough but apparently many dynamic languages make no attempt to.
07:22:44 <jdh30> But nothing like as bad as Groovy, apparently.
07:22:54 <DRMacIver> Heffalump: As I understand it, they tend to suffer a fair bit on numerics as a result but it's not too awful.
07:23:11 <DRMacIver> Heffalump: They can still take advantage of arrays of primitives as far as I know.
07:23:20 <DRMacIver> which should offset the worst of it.
07:23:24 <Heffalump> true
07:23:29 <DRMacIver> And I suspect a lot of primitive heavy library code is written in Java.
07:24:02 <Heffalump> heh, writing code in java for efficiency
07:24:03 <sclv> I don't know if its true anymore, but a big issue used to be with the jvm that object creation is expensive, compared to what one would need for a simple tagged union type or etc.
07:24:21 <jdh30> I have actually been quite impressed with Java's performance lately.
07:24:26 <sclv> so dynamic languages that represent everything as an object get nailed by the java runtime.
07:24:29 <Heffalump> the .NET type system has a built-in variant style type, I wonder what implementations use it.
07:24:32 <DRMacIver> jdh30: It's harder to do on the JVM, alas. Ruby Ruby does do some optimisations I think.
07:24:44 <jdh30> Right.
07:24:48 <Heffalump> I originally thought it was for VB, but it turns out that VB.NET gets rid of having that kind of thing.
07:25:14 <DRMacIver> sclv: Allocation is pretty fast these days. The problem is more that Java objects weigh a fair bit and there's not much you can do to offset that.
07:25:34 <sclv> java for numerics with a good jit approaches C speeds though, no?
07:25:46 <jdh30> ish, yes.
07:26:10 <sclv> DRMacIver: Right, but then there's also lookup for creation methods etc, too, no?
07:26:24 <Heffalump> sclv: that's statically resolvable, though
07:26:32 <Heffalump> constructors are the one thing that never require virtual dispatch
07:26:32 <jdh30> I ported SciMark2 from Java to OCaml and F# recently. Java on 64-bit Debian AMD64 beats everything else except C (and even beats C on the SOR subtask where aliasing is important).
07:26:39 <sclv> but is it statically resolved in the jvm?
07:27:05 <Heffalump> sclv: yes
07:27:05 <DRMacIver> jdh30: By the way, I don't think the primitives thing is something where .NET wins.
07:27:25 <sclv> ah, good to know.
07:27:41 <DRMacIver> jdh30: As the issue isn't just "good support for primitives" it's "providing a uniform object model over primitives and objects", which needs more low level hackery than I think either provides
07:28:31 <Heffalump> it's not the uniform object model I was thinking of, though that may be an issue too - it's just the lack of static type information
07:28:34 <DRMacIver> (also I suspect the issue with using objects instead of primitives is more that there are a lot of optimisations performed for primitives that aren't for their corresponding objects)
07:28:41 <jdh30> DRMacIver: I see. I've no idea about the performance of dynamic languages on .NET, BTW. AFAICT, nobody uses them.
07:28:47 <Heffalump> you can't represent something as an int if you don't know for sure it'll be an int
07:29:10 <jdh30> You can certainly unbox it locally, which should be all you need for the vast majority of performance-critical sections.
07:29:18 <luite> DRMacIver: some of the optimizations (no need for garbage collection etc) can now be performed in specific cases for objects too, because jvm 1.6 has escape analysis
07:29:40 <DRMacIver> luite: I was thinking more in terms of numerics, loop optimisations, etc.
07:30:24 <Heffalump> luite: as in the JIT in Sun JVM 1.6 does the analysis? Or do you mean that there is something added to the JVM spec to make it easier?
07:31:01 <DRMacIver> Heffalump: I think the sun 1.6 JVM has the capability to do escape analysis but it's switched off
07:32:22 <luite> I read some articles about it, but I'm not sure whether it is actually already used. 1.6 does have some performance improvements, but that might be because of some other optimizations (register allocation)
07:34:28 <DRMacIver> Heffalump: The uniform object model and lack of static type checking are both part of the same issue here though. If you can treat an Int as an object, you need to box it a lot of the time. If you *always* treat an int as an object (because of the dynamic typing) then you have to box it all the time.
07:34:50 <DRMacIver> Scala suffers from the first problem and its a noticable performance hit far more often than I'd like
07:35:01 <DRMacIver> (though not as bad as for the dynamic languages)
07:35:13 <Heffalump> can't you just box it when it's used as an object?
07:35:33 <Heffalump> or do the mutability semantics force that to happen when it's passed to things as well?
07:35:57 <DRMacIver> Yes, and Scala does for the most part. But there are a lot of cases where it does have to be treated as an object.
07:36:20 <DRMacIver> For example you have to box an int to pass it through the identity function.
07:36:39 <DRMacIver> Parameterized things don't get templated for primitives, so basically every time you hit a type parameter you have to box
07:37:17 <Heffalump> ah, yes
07:37:20 <Baughn> That's scala. GHC does specialize them, right?
07:37:31 <Heffalump> Baughn: typically only by inlining
07:37:48 <Heffalump> I think it only specializes if you tell it to (with a pragma) though I could be wrong
07:38:45 <Baughn> Heffalump: Mm. That's one optimization I could see helping - there usually aren't enough types passing through a polymorphic function that boxing is better than specializing, I don't think. There aren't too many that can be unboxed in the first place.
07:39:10 <DRMacIver> Generally speaking comparing Scala optimisations with GHC ones makes the Scala compiler team sad. :)
07:39:21 <Heffalump> Baughn: well, it's a code bloat issue
07:39:25 <Baughn> But if it already has the machinery, and just doesn't do it by default, that suggests I'd be wrong
07:39:28 <Heffalump> DRMacIver: is scala strict or lazy?
07:39:52 <DRMacIver> Strict with optional laziness.
07:40:03 <Baughn> Heffalump: I suppose. There /is/ something to be said for haskell programs fitting in L2 cache
07:40:07 <DRMacIver> Although I have some Issues with the laziness implementation. I keep meaning to see if I can improve it.
07:40:12 <Heffalump> Baughn: if you're talking about GHC, then you can't pass unboxed stuff to polymorphic things anyway
07:40:30 <Heffalump> as an optimisation, you could specialise the thing and unbox the parameter together
07:40:35 <DRMacIver> (It plays very badly with the garbage collector)
07:40:36 <Baughn> Heffalump: Well, not /explicitly/ unboxed stuff
07:40:42 <Heffalump> right
07:40:56 <Heffalump> but since you have to do both together, it's probably rather harder to decide to do so
07:42:20 <Baughn> DRMacIver: If you do look at that, I'd love to have time-driven weak references. That is to say, weak references that get collected in LRU order
07:42:42 <DRMacIver> Sorry, I meant the Scala laziness implementation. :) I wouldn't know where to start with GHC's
07:43:10 <EvilTerran> Baughn, ooh, that's terribly clever
07:43:20 <DRMacIver> And Scala isn't pure, so that's not really appropriate for its laziness.
07:43:27 <pejo> Isn't the implementation in GHC pretty good, considering how well it does in the shootout?
07:43:31 <jdh30> Does Scala get JIT-time type specialized like F#?
07:43:37 <Baughn> pejo: Sure, but it can always get better
07:43:46 <DRMacIver> (But yes, I've often wondered about something like that as well)
07:43:55 <EvilTerran> so, if some big expression gets CSEd and unexpectedly cached for a long time, and it's being held in a weak reference, it can be GCed and re-calculated if there's not enough memory to keep it around
07:44:00 <DRMacIver> jdh30: No more so than anything on the JVM does.
07:44:16 <Baughn> EvilTerran: Yep, that's the idea
07:44:31 <Heffalump> but then the GC would need to roll the expression back to the uncomputed state, too
07:44:40 <EvilTerran> i love it. seems like a great solution to the CSE-isn't-always-an-optimisation problem
07:44:55 <Heffalump> and that might well take up more space anyway..
07:45:10 <EvilTerran> altho Heffalump has a point - a weak reference would have to include a reference to the unevaluated thunk
07:45:11 <Baughn> Heffalump: True. It wouldn't always be a win, so you'd want to do it explicitly
07:45:30 <Heffalump> also, LRU doesn't make too much sense on its own, you need to trace the LRUness right through
07:45:33 <Baughn> EvilTerran: We'd have to play tricks with the local page table, though. I'm not sure how it'd work on platforms that don't /have/ a user-level page table, ie. non-x86
07:46:04 <Baughn> Hm
07:46:35 <EvilTerran> aaaand suddenly the conversation's over my head. never mind, IANA compiler designer :P
07:46:37 <Baughn> Keep a counter of weak-thunks-evaluated, increment and assign every time you dethunk one, store in sorted order?
07:47:00 <Baughn> Or don't keep a counter, and just use the memory location for same
07:47:01 <Heffalump> re the page table, you want to keep all the weak stuff in separate pages that you can just drop?
07:47:29 <Baughn> Yes, and so you can track LRUness by reading the access bit on said table
07:47:46 <Baughn> x86 tracks accesses to pages, both reads and writes. It's very handy
07:48:14 <Baughn> The granularity could be an issue, though.. *ponder*
07:48:19 <Heffalump> yeah
07:48:35 <Heffalump> have you read the PLDI '05 paper on this subject (using page tables with GC)?
07:49:03 <Baughn> No. I'm sure it'd be interesting, but I'm not normally on the internals side of things
07:49:21 <Baughn> (And I have a few hundred papers scheduled to read already. :P)
07:49:47 * EvilTerran notes that it'd be occasionally handy to have (^-) x y = x ^^ (-y)
07:49:57 <jdh30> Are there any industrial programmers here?
07:50:05 <EvilTerran> so you could write stuff like (2^-10)
07:50:15 <Heffalump> how do you define industrial?
07:50:52 <jdh30> Make products and sell them to make money.
07:51:02 <jdh30> So MSR doesn't count.
07:51:10 <Heffalump> even F#?
07:51:32 <jdh30> Not when it was in MSR, no.
07:51:42 <Heffalump> ok, so Don Syme doesn't count?
07:51:50 <jdh30> Don is productizing it.
07:52:01 <Heffalump> he's still in MSR
07:52:21 <jdh30> He's in Redmond.
07:52:48 <Heffalump> that doesn't preclude him being in MSR..
07:52:58 <Heffalump> but fair enough if he's temporarily moved to a product group again
07:53:13 <jdh30> He is in Redmond working on F# with the product team. Yes.
07:53:22 <DRMacIver> Do you consider services companies and/or people developing internal tools to be "industrial"?
07:53:29 <Baughn> So.. weak reference = (reference/thunk, thunk copy, last access time). Keep a global counter for accesses; update the access time anytime you actually dereference it explicitly. In times of memory pressure (must be tunable) allow the GC to collect the /least recently/ accessed reference, copying back the thunk. Problem: If you hang on to references to inside whatever structure your weak ref is holding, you could conceivably get multiple c
07:53:37 <Heffalump> anyway, can you prove MS are going to make money from F#?
07:53:46 <DRMacIver> (Neither of which apply to me. I fit into that category fairly unambiguously)
07:53:51 <jdh30> Yes but they are uninteresting if their work is invisible from the outside.
07:53:52 <Heffalump> given that they probably won't change the price of VS anyway
07:53:57 <DRMacIver> (though not using Haskell, alas)
07:53:59 <jdh30> MS already have made money from F#.
07:54:05 <Heffalump> oh, how?
07:54:16 <Heffalump> people write about internal work they do externally, sometimes
07:54:43 <DRMacIver> Baughn: You cut off at "conceivably get multiple c"
07:55:50 <Baughn> DRMacIver: The thunk can end up being evaluated multiple times, producing multiple, identical data structures that are all held in memory by non-weak references
07:55:57 <Baughn> DRMacIver: The programmer would have to be careful
07:55:58 <jdh30> Yes. The occasional writings can make these things visible from the outside but it is much less interesting that a real product. For example, it would be much more interesting to be able to quantify revenue objectively rather than have someone conjecture as to their work's internal worth.
07:56:27 <Heffalump> jdh30: sure. But the same thing applies to a product that is bundled up with a much bigger thing, like F#.
07:56:37 <Twinside> hello everyone
07:56:41 <jdh30> Heffalump: MS are already making money from F# because people are migrating to .NET because of it and, inevitably, buying VS and other developer tools.
07:56:53 <Heffalump> and you can quantify that?
07:57:01 <jdh30> Quantify what?
07:57:08 <Heffalump> what money they have made from F#
07:57:37 <jdh30> You could make a pretty good estimate for now but they will start making serious money when 1.0 is out later this year.
07:57:46 <pejo> jdh30, isn't VS a necessary evil that doesn't generate any direct revenue for MS?
07:58:04 <Baughn> All things aren't quantifiable. How much money has Foo Company made because their programmers are better as a result of learning haskell, despite their not actually /using/ haskell?
07:58:07 <jdh30> VS generates some revenue but nothing like as much as Office, of course.
07:58:27 <jdh30> Some things are quantifiable, of course.
07:58:32 <Heffalump> jdh30: go on then (make a "pretty good estimate")
07:58:38 <[Justice]> it could be argued that Microsoft's core business is VS
07:58:49 <jdh30> Justice: yes.
07:58:50 <Heffalump> [Justice]: it could be argued, but it'd be wrong :-)
07:58:58 <Twinside> I've got an error of "rigid type" with ghc, but I've got issues to really understand what the problem is, can someone help me?
07:58:59 <sclv> F# is probably keeping some companies from jumping ship away from .NET, actually.
07:59:17 <Baughn> Twinside: Sure, if you post the entire error message and preferably code
07:59:17 <jdh30> Not really, Microsoft depend upon third party developers building the applications that their end users buy. That is the foundation of their entire platform.
07:59:23 <Heffalump> you'd have to make a very indirect argument about VS helping to maintain the dominance of the Windows platform
07:59:28 <Lycurgus> really (re F#)?
07:59:31 <Twinside> Baughn > in channel or in private?
07:59:38 <Baughn> Twinside: In pastebin
07:59:41 <Heffalump> Twinside: http://hpaste.org
07:59:50 <jdh30> Lycurgus: definitely.
08:00:08 <Heffalump> jdh30: got examples?
08:00:10 <[Justice]> not necessarily VS the product, VS the idea of developers writing programs for Windows
08:00:24 <Lycurgus> my impression is that only a miniscule number of .net shops ever heard of F#
08:00:34 <Lycurgus> or haskell for that matter
08:00:37 <[Justice]> .net shops aren't going to write in F#
08:00:40 <[Justice]> or haskell
08:00:49 <jdh30> Lycurgus: that is precisely why it is good: F# will attract people from other platforms (like me) rather than simply stealing from C#.
08:00:53 <sclv> Lycurgus: I know some banks that are moving to increasingly functional methods, and are using F# to work with extant systems.
08:00:55 <[Justice]> .net shops are going to stick with VB7
08:01:02 <EvilTerran> [Justice], ah, you mean "get everyone writing in .net so they'll get vendor lock-in and be stuck on windows"?
08:01:43 <hpaste>  Twinside pasted "Compilation problem" at http://hpaste.org/8018
08:01:47 <pejo> I think we got slightly sidetracked from Haskell all the sudden. Perhaps this conversation should move to #haskell-blah?
08:01:52 <[Justice]> exactly, banks & financial institutions, researchers, etc need F# or functional languages in general
08:02:01 <Lycurgus> i was surprised to find out how mono works
08:02:02 <Twinside> Baughn > done
08:02:06 <jdh30> EvilTerran: Even if it is possible for people to migrate to Mono they won't because it will remain so much worse.
08:02:12 <DRMacIver> The only .NET shop I've worked in (well, it was about half .NET shop half Java shop, but it startd as a .NET shop) used C#. I expect a couple people there had heard of F# but there wouldn't have been a snowball's chance in hell of using it.
08:02:14 <EvilTerran> Lycurgus, in what way?
08:02:22 <Heffalump> pejo: I would argue that language discussions belong here unless they are blatantly not at all to do with Haskell
08:02:28 <Lycurgus> it uses the .net binaries
08:02:33 <EvilTerran> oh, right
08:02:59 <sclv> My understanding is that msoft is very friendly towards the Mono ppl actually.
08:03:06 <[Justice]> MS building a superb platform for developing software is ... a problem?
08:03:09 <EvilTerran> Lycurgus, ... as in the windows runtimes that MS wrote?
08:03:11 <Lycurgus> so it doesn't hit that recreate the world situation
08:03:15 <sclv> although it might go all evil-empire on them later, of course.
08:03:21 <Lycurgus> ET: yes.
08:03:25 <EvilTerran> cunning
08:03:27 <EvilTerran> i like that
08:03:31 <Heffalump> [Justice]: well, it could be, in the same way as them bundling IE with Windows was a problem
08:04:06 <jdh30> DRMacIver: Yes, existing .NET shops are not likely to use F#. Other people will.
08:04:11 * Heffalump is still waiting for jdh30's F# revenue estimates and examples of it stopping people moving away from .NET :-)
08:04:35 <jdh30> sclv: Consider what it would take to threaten Microsoft now and look at how fast Mono is progressing. I can't see the curves ever meeting.
08:04:38 <[Justice]> F# is keeping me hoping for an H# ... there's one example
08:04:44 <Heffalump> Baughn: are you looking at Twinside's error? Otherwise I will, I just don't want to duplicate work as those things usually take some work to understand.
08:05:07 <DRMacIver> Heffalump: It's such an easy estimate to do that it's been left as an exercise for the reader? :)
08:05:14 <Baughn> Heffalump: I'm looking, but I think you'd better do it. THis is into trial-error-and-read territory for me
08:05:17 <jdh30> I would guess $1M just from people toying with F# for now. I'd expect that to rise to $100M over the next few years, as it sees more serious adoption.
08:05:36 * DRMacIver holds up his "citation needed" banner
08:05:39 <Heffalump> jdh30: that sounds like a conjecture, not an objective quantification
08:05:50 <EvilTerran> [Justice], isn't there a Haskell.net project hiding somewhere already?
08:06:02 <[Justice]> *shrug*
08:06:05 <jdh30> Just multiply the cost of VS by the number of relevant F# users.
08:06:10 <Lycurgus> 'conjecture' is kind
08:06:11 <sjanssen> isn't F# free?
08:06:21 <sclv> sjanssen: but VS is not.
08:06:22 <[Justice]> there's an abandoned alpha VS plugin for Haskell
08:06:26 <EvilTerran> if not, it'd be a good use of YHC's pluggable backends
08:06:28 <jdh30> F# is free but you need commercial tools to make it useful.
08:06:33 <Twinside> is my error resulting of a bad design?
08:06:36 <jdh30> VS is also free (you can use F# with the free VS shell).
08:06:47 <Heffalump> jdh30: (a) how do you know how many "relevant F# users" there are and (b) how do you know they wouldn't have bought VS anyway, or just use it from the shell?
08:06:52 <Heffalump> and what commercial tools do you need?
08:06:59 <jdh30> The money comes from things like VS team edition for its profiler. You can't write performant code without a profiler and most F# users will want to.
08:07:31 <Heffalump> but those tools are free if you already have VS for other reasons
08:07:44 <jdh30> The relevant F# users are among our customers, so that is easy. We also do market research among prospective customers and non-MS users account for almost half.
08:07:50 <jdh30> Yes, they are the other half.
08:07:55 <conal> what's the ghc flag for showing which rewrite rules fire
08:07:56 <vixey> someone took the book out the library I wanted
08:08:00 <vixey> I bet it was someone here!
08:08:16 <Heffalump> vixey: what library? :-)
08:08:22 <vixey> conal: -v I think .. notsure
08:08:37 * EvilTerran seems to be in the right country to have taken it, at least
08:08:44 <jdh30> Has anyone tried H
08:08:52 <jdh30> H#, the Haskell for .NET?
08:08:53 <DRMacIver> When you say "our", I can't help but notice that the other members of your company are conspicuously silent...
08:08:55 <conal> vixey: i'll try that. thx.
08:08:59 <Heffalump> Twinside: ok, so the problem is that you haven't made your serialize polymorphic enough
08:09:12 <jdh30> Yes. I am the vocal member. :-)
08:09:21 <Twinside> Heffalump > how's that?
08:09:22 <Heffalump> your type signature says that if you are implementing StrictPixel for a certain b, you have to make serialize work for *any* b
08:09:22 <EvilTerran> vixey, what book, anyway?
08:09:43 <Heffalump> sorry, "implementing it for a certain 'a'"
08:09:45 <DRMacIver> It's not so much "vocal" as "not completely mute and invisible" in this case.
08:09:48 <Heffalump> but you have made b = a
08:10:00 <jdh30> Yes.
08:10:08 <sjanssen> conal: -ddump-simpl-stats
08:10:11 <conal> ah, found it: -ddump-rules
08:10:15 <conal> sjanssen: thx!
08:10:16 <vixey> EvilTerran; did you get any books out by Luo Zhaohui? :p
08:10:24 <EvilTerran> er... no.
08:10:25 <vixey> (like yesterday)
08:10:26 <Twinside> Heffalump > the compiler can't unify this? because a = b is a possible case for me
08:10:48 <Heffalump> Twinside: it's a possible case, but your signature says it must work for *all* cases
08:10:52 <jdh30> She is actually quite visible though, albeit only IRL.
08:10:57 <sclv> you need mptcs and fundeps, maybe?
08:11:09 <EvilTerran> vixey, not out of any oxford library, and definitely not out of a library anywhere else
08:11:09 <Heffalump> either make 'b' be another parameter to the class, or fix the class so that b is always a
08:11:41 * vixey has to wait ages until to get it :/
08:11:59 <Twinside> Heffalump > ok I'm going to try adding another parameter to the class, thanks
08:12:27 <Heffalump> jdh30: H# doesn't really seem to have much sign of life
08:12:51 <jdh30> That is the impression I got. OCamlJava is showing signs of life but it has lots of problems, unfortunately.
08:12:59 <[Justice]> H# isn't a real thing, so far as i know ... i meant, a Haskell on the CLR
08:13:04 <jdh30> I'm surprised they didn't target Mono instead...
08:13:05 <Heffalump> re "relevant F# users", who are they?
08:13:12 <jdh30> Oh.
08:13:24 <jdh30> Relevant F# users are the ones who did not already own .NET dev tools.
08:13:28 <DRMacIver> Haskell seems really unsuited for running on existing virtual machines.
08:13:39 <Heffalump> no, I mean give names. Otherwise we just have your unverified assertions.
08:13:46 <[Justice]> so did ruby and python
08:13:47 <DRMacIver> Is that just a misunderstanding on my part?
08:13:48 <Twinside> Heffalump > thanks it work very well :)
08:13:55 <jdh30> Depending what Haskell users require, that might not be a practically-important concern
08:14:31 <DRMacIver> [Justice]: Not really.
08:14:32 <Heffalump> .NET would be nice to have, cos of all the infrastructure that already exists
08:14:32 <jdh30> I cannot name my customers, of course.
08:14:35 <DRMacIver> [Justice]: Ruby and python execution both fall into the same class of problems as smalltalk, and the JVM at least owes a lot to smalltalk VMs.
08:14:45 <Heffalump> and because it's stupid for to be implementing libraries once per platform
08:15:07 <DRMacIver> And the bits where it doesn't match up terribly well with the smalltalk VMs are exactly where the implementations on the JVM have all the predicted problems. :)
08:15:37 <Heffalump> jdh30: so your claims about revenue to Microsoft are completely unverifiable. It's not even as if you *are* Microsoft, you're just some random consultant who likes evangelizing F#.
08:15:48 <jdh30> Heffalump: absolutely. You don't need .NET though: the creators of Linux-based FPLs could just collaborate on a suitable VM design. Well, that is the theory. In practice, they have never managed to collaborate on anything for long enough to see it through to completion and none of them have ever managed to write a working concurrent GC.
08:16:02 <DRMacIver> Good compilation of Haskell on the other hand seems to rely on a lot of control over the stack (which I think is why ghc doesn't even use the x86 stack?) and heap (e.g. doing a lot of on heap replacement)
08:16:18 <Heffalump> DRMacIver: GHC does a lot of on heap replacement?
08:16:22 <DRMacIver> I thought it did
08:16:26 <DRMacIver> I may be completely wrong!
08:16:32 <Heffalump> I didn't, but I could be wrong too :-)
08:17:04 <jdh30> Heffalump: You can easily verify it by counting them yourself. Just post on a relevant forum and I am sure you will get a lot of responses.
08:17:11 <DRMacIver> I may also be using the wrong terms. Brief possibilities at ARM aside I'm very much not a compiler engineer. :)
08:17:29 <jdh30> I met someone from ARM in my antenatal classes.
08:17:32 <Heffalump> "in-place update" is the term I'd use, but it's clear what you meant
08:17:44 <Heffalump> they're everywhere..
08:17:45 <DRMacIver> but e.g. I was under the impression that when you evaluated a thunk it replaced the original with the result
08:17:59 <jdh30> I suppose if I said "our antenatal classes" someone would accuse me of cloning because my wife is "invisible". ;-)
08:18:03 <Heffalump> DRMacIver: well, it'll overwrite the pointer with the value, yes. But that's not really a big deal.
08:18:17 <Heffalump> jdh30: does your wife actually write F#?
08:18:22 <jdh30> No.
08:18:24 <[Justice]> *shrug* i dunno what ghc does ... but i guess you could check out the C source it emits
08:18:34 <Heffalump> what does she do, then?
08:18:38 <DRMacIver> Heffalump: It is if you have multiple copies of it floating around isn't it?
08:18:42 <jdh30> Publishing and marketing.
08:18:45 <Baughn> [Justice]: I would not recommend that. Read the documentation instead.. really
08:18:50 <jdh30> Graphic design.
08:18:52 <jdh30> etc.
08:19:09 <Heffalump> so you're the only engineer?
08:19:10 <[Justice]> > man ghc
08:19:12 <lambdabot>   Not in scope: `ghc'
08:19:14 <jdh30> Oh, and she is a veterinary surgeon. :-)
08:19:17 <jdh30> Yes.
08:19:28 <[Justice]> lambdabot says the docs are missing
08:19:36 <Heffalump> this is why you saying "our" when talking about technical things tends to sound ridiculous
08:19:53 <vixey> [Justice]: get them from HTTP
08:20:12 <Baughn> [Justice]: http://hackage.haskell.org/trac/ghc/wiki/Commentary
08:20:13 <lambdabot> Title: Commentary - GHC - Trac
08:20:35 <jdh30> Using the plural is perfectly normal in both academia and industry.
08:20:41 <DRMacIver> Heffalump: e.g. if you alias a thunk a lot of times and then evaluate it you need to either update all those aliases, update the current heap location in place, or add an additional level of indirection to make it work.
08:20:59 <Heffalump> DRMacIver: yeah, ok
08:21:03 <DRMacIver> Heffalump: And the third is really the only one you can do on the JVM or .NET because there's no way to replace the object on the heap.
08:21:16 <Heffalump> oh, right. Good point.
08:21:37 <Heffalump> I was thinking of "proper" in-place update where you actually skip the GC step when an object becomes dead and can be reused.
08:21:37 <jdh30> Incidentally, that was a large part of what I was saying before: my perspective is one of an industrial user and not one of a functional programming evangelist.
08:21:43 <DRMacIver> I'm not saying this is a big deal if you control the low level implementation.
08:21:55 <DRMacIver> I'm saying that things like this are why it's not easy if you *don't* have that control.
08:22:07 <Heffalump> jdh30: an industrial user as in you sell products for money (your own definition from above)?
08:22:18 <jdh30> Exactly, yes.
08:22:19 <Heffalump> DRMacIver: yeah, fair enough
08:22:30 <DRMacIver> phew. Glad I'm not totally on the wrong track. :)
08:23:06 <Heffalump> I think the weird control-flow that GHC compiles to is the biggest obstacle, though
08:23:35 <DRMacIver> in what sense?
08:24:05 <Heffalump> it makes verification hard
08:24:12 <DRMacIver> Ah
08:24:25 <Heffalump> current verification is very much based on traditional stack-based structured code
08:24:26 <[Justice]> sure
08:24:46 <[Justice]> and at some point, MS will give us support for lazy evaluations
08:24:46 <Heffalump> (even though bytecode isn't actually structured, functions are well-defined etc)
08:24:58 <Heffalump> [Justice]: on .NET? I find that very unlikely.
08:25:10 <DRMacIver> Why unlikely?
08:25:13 <Heffalump> They won't even add higher-kinded type variables to .NET to make F#'s monads properly abstractable.
08:25:24 <DRMacIver> Politically or technically?
08:25:27 <DRMacIver> Ah
08:25:50 <Heffalump> I dunno which you'd describe it as, but essentially the core design of .NET is "done", AIUI.
08:25:57 <jdh30> AFAIK they have completely stopped developing .NET now.
08:26:13 <vixey> why people are concerned with .net I will never know..
08:26:28 <DRMacIver> That's encouraging. Maybe the JVM will have time to catch up. :)
08:26:33 <jdh30> .NET accounts for most of our revenue. That's why we care about it.
08:26:35 <Heffalump> vixey: because it's very convenient, particularly if you care about binary distribution
08:26:54 <Heffalump> which is why it has so much more traction in the commercial world than in the open-source world
08:28:00 <jdh30> DRMacIver: apparently Sun are still working on tail calls. <yawn>
08:28:05 <[Justice]> it's so easy to write in .net
08:28:19 <jdh30> and its so easy to sell with .NET.
08:28:21 <vixey> jdh30: why "<yawn>"?
08:28:33 <[Justice]> because .net has had tail calls since 1.0
08:28:55 <[Justice]> not C# or VB, but it's in the CLR
08:28:57 <jdh30> They've been talking about tail calls for several years now but have yet to actually implement anything at all.
08:29:22 <sclv> preflex: seen ndm
08:29:22 <preflex>  ndm was last seen on #haskell 2 days, 4 hours, 4 minutes and 33 seconds ago, saying: mm_freak_work: its a lot of work to learn! just trying to help before people search the Prelude, which gets very confusing
08:29:25 <DRMacIver> With the da vinci VM they're starting to do a lot more experimentation with adding new features.
08:29:54 <jdh30> As soon as Sun add tail calls to the JVM there will be a huge flurry of ported and new FPLs built upon the JVM and we shall certainly diversify to them. In the mean time, we're F# only for software products.
08:30:03 <Heffalump> jdh30: so how much money do you make selling F# products?
08:30:24 <jdh30> ~$100k p.a.
08:30:41 <jdh30> Sorry, halve that (the other half is services).
08:31:19 <DRMacIver> There seems to be some work on first class continuations (I suspect that won't ever make it into the real thing, but who knows), Java 1.7 is purported to have tail calls planned although I've not seen an official comment to that effect and a bunch of other interesting features.
08:31:21 <Heffalump> ah, I was about to say that's quite impressive
08:31:24 <vixey> jdh30: why do you think that? If someone wanted to target the jvm it shouldn't think it makes much difference (implementing TCO in the compiler itsself is relatively simple)
08:31:34 <DRMacIver> vixey: No, it's really not. :(
08:31:39 <DRMacIver> Not on the JVM anyway
08:31:41 <Heffalump> I'll be more impressed once you can make more from writing F# than I do from writing Haskell :-)
08:31:46 <clkao> hi! are there cli tools that i can read installed module docs withoug going to hoogle ?
08:31:54 <jdh30> OCaml for Scientists was making a similar amount but it has since all but died. Fortunately the F#.NET Journal rose at exactly the same time.
08:32:03 <Baughn> DRMacIver: Call me when it gets first-class functions
08:32:16 <opqdonut> clkao: haddock
08:32:28 <jdh30> vixey: Like David said, it really isn't easy at all. Even if you manage to implement the workaround the results are awful (obfuscated call stacks and terrible performance).
08:32:54 <jdh30> TCO is absolutely critical for a wide variety of idiomatic code. So the lack of proper tail calls on the JVM is really holding it back as far as FPL implementations are concerned.
08:32:56 <DRMacIver> Baughn: First class functions aren't really a VM detail. The object support works quite happily for them for the most part. But it's getting method handles and lightweight classloading of anonymous classes.
08:32:58 <mtag55> hi
08:33:03 <DRMacIver> Or at least they're planned. Whether it gets them is unknown.
08:33:17 <mtag55> i have a function with a parameter a
08:33:20 <Baughn> DRMacIver: Oh, I meant java 1.7, not the jvm
08:33:31 <DRMacIver> Oh, I don't give a shit about Java 1.7 :)
08:33:38 <vixey> jdh: shouldn't cause performance problems, but yeah you wouldn't get nice backtraces
08:33:41 <mtag55> when i run the program it say type error in application
08:33:46 <mtag55> term a
08:33:51 * DRMacIver hasn't written more than a few hundred lines of Java in the last few months.
08:33:52 <mtag55> type : integer
08:33:57 <Heffalump> vixey: don't you have to make huge methods to work around lack of tailcalls?
08:33:58 <mtag55> does not match : int
08:33:59 <jdh30> vixey: the workaround relies upon exception handling which is really slow on the JVM.
08:34:04 <mtag55> what can i do?
08:34:05 <Heffalump> and how do you tailcall to something that isn't statically known?
08:34:07 <DRMacIver> I'm purely interested in the VM and libraries at this point.
08:34:11 <DRMacIver> jdh30: No, it's not.
08:34:19 <DRMacIver> jdh30: It's consistently better than exception handling on .NET
08:34:26 <DRMacIver> What's slow is stack trace generation.
08:34:29 <DRMacIver> Which is easy to turn off
08:34:32 <jdh30> But 10-30x slower than OCaml.
08:34:42 <vixey> Heffalump: no, you can pass continuations around (a continuation could be as simple as a single integer)
08:35:03 <Heffalump> vixey: oh, I see. Fair enough.
08:35:11 <mtag55> a actually use term "a" also like list !! a and like (a + 1)
08:35:14 <DRMacIver> jdh30: I really doubt it. You're almost certainly comparing with stack trace exceptions to ocaml exceptions.
08:35:19 <mtag55> how must i declare the type of a?
08:35:27 <DRMacIver> Without the stack introspection most of the time hotspot turns exception throwing into gotos.
08:35:45 <mtag55> can anybody help?
08:36:04 <jdh30> Only local exceptions and stack unwinding exceptions from trampolining are anything but local.
08:36:06 <vixey> mtag55: I don't understand what you're asking
08:36:10 <Heffalump> mtag55: hpaste your code
08:36:14 <Heffalump> or at least the error
08:36:22 <mtag55> - Type error in application
08:36:22 <mtag55> *** Expression     : costuri !! a
08:36:22 <mtag55> *** Term           : a
08:36:22 <mtag55> *** Type           : Integer
08:36:22 <mtag55> *** Does not match : Int
08:36:33 <vixey> ohh
08:36:42 <Heffalump> for next time, hpaste = http://hpaste.org, not do it on channel
08:36:50 <mtag55> ok
08:36:51 <vixey> :t fromIntegral :: Integer -> Int
08:36:52 <lambdabot> Integer -> Int
08:36:57 <vixey> so one thing you could do is write
08:37:04 <Heffalump> mtag55: where did a come from?
08:37:04 <vixey> costuri !! (fromIntegral a)
08:37:12 <vixey> but I think it might be better to redefine !!
08:37:22 <mtag55> how?
08:37:26 <Heffalump> I think it would be better to figure out why a needs to be an Integer and stop it being one, if possible!
08:37:41 <Heffalump> if it really needs to be one, then using it for !! would have some issues...
08:37:46 <vixey> (x:_)!!0=x;(_:xs)!!(n+1)=xs!!n
08:38:00 <EvilTerran> ?hoogle [a] -> Integer -> a
08:38:01 <lambdabot> No matches, try a more general search
08:38:15 <vixey> :t let (x:_)!!0=x;(_:xs)!!(n+1)=xs!!n in (!!)
08:38:15 <Heffalump> @type Data.List.genericIndex
08:38:17 <Deewiant> vixey: how about (!!) = genericIndex
08:38:18 <lambdabot> forall t t1. (Integral t1) => [t] -> t1 -> t
08:38:18 <lambdabot> forall b a. (Integral a) => [b] -> a -> b
08:38:19 <EvilTerran> Data.List.genericIndex :: Integral a => [b] -> a -> b
08:38:30 <EvilTerran> that's the one i was thinking of
08:40:03 <DRMacIver> jdh30: As far as I know, it's pretty good about non local exceptions too
08:40:24 <jdh30> DRMacIver: this is the kind of source I got this from: http://debasishg.blogspot.com/2006/03/non-java-languages-on-jvm.html
08:40:26 <lambdabot> Title: Ruminations of a Programmer: Non Java Languages on the JVM, http://tinyurl.com/65am4l
08:40:49 <vixey> yeah maybe #haskell-blah
08:40:54 <jdh30> they list three ways to implement tail calls. "Use of trampolines limit indefinite stack growth, but at the expense of performance, since all calls made by the trampoline are statically unknown method dispatches."
08:40:55 <DRMacIver> Also, hotspot is basically a great big inlining machine, so nonlocal exceptions will often become local.
08:41:11 <[Justice]> is the speed of throwing exceptions important? would fast exceptions mean that it's acceptable to use them to control program flow?
08:41:34 <Heffalump> [Justice]: yes. See O'Caml for an example
08:41:43 <sclv> @tell ndm If you're interested in the cgi testsuite I've been working on, here's its repo: http://code.haskell.org/~sclv/cgicheck/
08:41:43 <lambdabot> Consider it noted.
08:41:44 <DRMacIver> [Justice]: In this case this is an implementation detail. It's often nice to be able to use them for compiler generated control flow.
08:42:04 <jdh30> If you're throwing and catching an exception every time you make a tail call then you're looking at up to 30x performance degradation on current JVMs. So it is serious, yes.
08:42:07 <Heffalump> and of course all the various kinds of Haskell exceptions, at least some of them are definitely fast, and they may well all be.
08:43:01 <jdh30> Justice: Yes. OCaml uses exceptions extensively for ordinary control flow. Incidentally, this is probably the single biggest problem when porting OCaml code to F# where exceptions are 600x slower. You have to convert all of that exception-based control flow into explicit constructs.
08:43:19 <jdh30> How are exceptions handled by GHC?
08:43:21 <[Justice]> hmm
08:43:34 <vixey> jdh30: "30x"?
08:43:45 <vixey> jdh30: what are you measuring against are you just making up numbers
08:44:18 <Heffalump> jdh30: depends on the kind of exception. I was thinking of explicit ones like Either.
08:44:34 <jdh30> Exceptions can be that much slower on the JVM compared to OCaml. I'm assuming function calls are the same.
08:44:39 <[Justice]> Either is an exception?
08:44:55 <Heffalump> [Justice]: yes, Left for the exceptional values and Right for real values.
08:44:56 <jdh30> Isn't either equivalent to returning a variant?
08:45:08 <jdh30> So the performance is different between left and right?
08:45:15 <Heffalump> variants have more options than either
08:45:19 <[Justice]> that's not language/platform exceptions
08:45:22 <DRMacIver> I don't have absolute numbers compared to normal returns, but if you take a look at Odersky's paper comparing two approaches to tail call optimisations, the one using exceptions isn't actually that much slower and is occasionally faster.
08:45:41 <Heffalump> [Justice]: sure, but monads make them look quite like it
08:45:54 <Heffalump> a lot of stuff in Haskell is in the libraries when it would be in the language in other languages
08:46:02 <[Justice]> seems like everything's a monad in H
08:46:17 <DRMacIver> Everything is a monad in most languages. Haskell just makes it explicit. :)
08:46:25 <DRMacIver> (And lets you benefit from it)
08:46:41 <jdh30> Odersky says 20x slower in sec 3.1 http://citeseer.ist.psu.edu/cache/papers/cs/22759/http:zSzzSzlampwww.epfl.chzSzpaperszSzbabel01.pdf/schinz01tail.pdf
08:46:42 <lambdabot> http://tinyurl.com/5eqnze
08:47:57 <DRMacIver> Specifically Odersky says "Here's this technique which we didn't use because it was 25 times slower than the standard version"
08:48:18 <jdh30> Yes.
08:48:43 <DRMacIver> In particular that version doesn't use exceptions at all...
08:49:14 <vixey> I am not sure if this is a #java invasion :p
08:49:29 <jdh30> Would you be interested in a Haskell for the JVM. :-)
08:49:35 <Heffalump> it's a language implementation discussion
08:49:39 <mrd> java is just trying to cash in on haskell popularity
08:49:43 <DRMacIver> Well, it's a #language-implementations invasion which happens to be targeted at the JVM.
08:49:45 <jdh30> lol
08:49:50 <vixey> jdh30: that's why I read through lambdavm
08:49:51 <DRMacIver> jdh30: lambdavm has been around for a while.
08:49:55 <vixey> jdh30: didn't learn much
08:49:57 <Heffalump> mrd: hmm. I think java is still a few orders of magnitude more popular than haskell :-)
08:49:59 <DRMacIver> I don't think anyone uses it. :)
08:50:04 <mrd> pfft
08:50:09 <DRMacIver> Heffalump: Or at least a few orders of magnitude more *used* than Haskell. :)
08:50:16 <DRMacIver> Not neccessarily the same thing.
08:50:19 <jdh30> :-)
08:50:42 <Heffalump> yes, Haskell is very popular with most people who use it.
08:50:44 <[Justice]> someday soon, java will get rid of inner classes and support closures and tail calls
08:50:45 <DRMacIver> jdh30: The relevant point here is that they compare two versions. One uses ordinary returns and one uses exceptions. The two are not noticably different in performance.
08:50:47 <Heffalump> I guess that could make up for it :-)
08:50:58 <DRMacIver> [Justice]: I *like* inner classes.
08:51:05 <vixey> or you could just program in Scheme
08:51:11 <Heffalump> inner classes give you closures, right?
08:51:14 <DRMacIver> The fact that they're a shitty substitute for first class functions doesn't mean they're a bad feature.
08:51:22 <vixey> it's a lot easier to write Scheme in Scheme than Scheme in Java
08:51:25 <jdh30> No. He failed to observe a difference but measuring the wrong thing. Look at his benchmarks: tail calls weren't even relevant for the first three!
08:51:29 <geezusfreeek> java? dangit i want some coffee
08:51:56 <jdh30> Do inner classes automate closing of the environment?
08:52:07 <[Justice]> sort of, yes
08:52:21 <vixey> jdh30: yes that's why they are innerclasses
08:52:27 <vixey> (rather than just normal classes)
08:52:40 <vixey> (but this is kind of offtopic)
08:52:55 <[Justice]> bringing it back on topic, i hear H is getting inner classes
08:52:59 <jdh30> If you want to stress test Odersky's implementation you need to run a program that performs alternative tail and non-tail calls. He didn't do that so his results don't show the worse-case behaviour.
08:53:10 <vixey> [Justice]: "H" is what?
08:53:16 <[Justice]> Haskell
08:53:42 <DRMacIver> jdh30: It's not really relevant. The approach shrinks the stack at a fixed depth regardless of how you reach that depth.
08:53:43 <geezusfreeek> ...
08:53:51 <Heffalump> [Justice]: if you mean associated types, then sort of.
08:54:12 <jdh30> But he optimized repeated tail-only calls and then benchmarked only that, AFAICT.
08:54:15 <geezusfreeek> i don't think that's the same at all
08:54:31 <DRMacIver> It's basically the usual continuation based approach of "make everything a tail call then shrink the stack at a fixed depth"
08:54:51 <DRMacIver> I think. It's been a while since I've actually read this paper.
08:55:07 <augustss_> DRMacIver: is this for Scala?
08:55:22 <DRMacIver> augustss_: No, Scala's tail call optimisation is kinda feeble. This is for his previous work.
08:55:33 <augustss_> oh, ok
08:55:37 <Heffalump> geezusfreeek: it gives you the possibility to make "inner type classes" via a bit of a hack (with wrapping up contexts)
08:55:51 <jdh30> That also begs the question: why did he give up on tail calls if they worked so well?
08:56:00 <jdh30> hi lennart
08:56:05 <augustss_> hi
08:56:14 <DRMacIver> jdh30: They didn't work so well. I'm just using this to demonstrate the reletive performance of exceptions and returns.
08:56:16 <geezusfreeek> Heffalump: hmm. i didn't realize that.
08:56:47 <jdh30> But you can measure the relative performance really easily?
08:56:58 <sclv> whoa (vis a vis inner type classes)
08:57:20 <DRMacIver> Measuring performance on the JVM is never easy. :)
08:57:23 <augustss_> hmmm, what does inner type classes even mean?
08:57:27 <[Justice]> finally, scared someone! no inner classes in haskell, sorry
08:57:33 <sclv> I feel like when ATs start to get real use I'll have to learn haskell all over again.
08:57:54 <geezusfreeek> [Justice]: if you mean me then you are mistaken :P i didn't believe you for a second
08:58:01 <jdh30> There is another problem. The exception optimizations you referred to only work well when the exception does not carry any associated data.
08:58:02 <Heffalump> augustss_: well, I was arbitrarily taking it to mean the same thing as what "associated type classes" would mean if they existed.
08:58:21 <jdh30> Maybe you can work around that by using a global mutable though...
08:58:28 <DRMacIver> jdh30: No, it works pretty well even with the associated data.
08:58:43 <jdh30> Only if the data is static.
08:58:46 <DRMacIver> No
08:58:50 <jdh30> Which it isn't here.
08:58:55 <Heffalump> push the data and jump to the handler, surely?
08:58:58 <DRMacIver> It's perfectly legit to allocate a new exception with the data each time.
08:59:03 <jdh30> It certainly didn't work when I tested it.
08:59:13 <Heffalump> or rather, put the data on the stack after unwinding the stack back to the handler
08:59:29 <DRMacIver> You almost certainly weren't suppressing stack trace generation then.
08:59:33 <Heffalump> (where unwind = modify the stack pointer by the relevant number)
09:00:05 <DRMacIver> http://blogs.sun.com/jrose/entry/longjumps_considered_inexpensive
09:00:12 <jdh30> Conflicts with verification and the concurrent GC make the implementation complicated IIRC. I'm sure I can dig out the code.
09:00:19 <jdh30> Yes, that was the exact article I was working from.
09:00:39 <Heffalump> why would an implementation trick conflict with verification? You verify first, then run.
09:00:47 <jdh30> There is a workaround where you statically allocate an exception with dummy data and use cloning instead...
09:02:02 <Heffalump> I thought DRMacIver was saying that there is a way to turn off stack trace generation, which would negate the whole thing about it being expensive?
09:02:11 <DRMacIver> There is. It's mentioned in the comments there.
09:02:22 <DRMacIver> Here's a larger article about it: http://www.javaspecialists.co.za/archive/Issue129.html
09:02:23 <lambdabot> Title: [JavaSpecialists 129] - Fast Exceptions in RIFE
09:02:51 <Heffalump> is fillInStackTrace part of the standard? That's quite nice, if so.
09:02:56 <DRMacIver> In particular note the comparison between throwing a new exception and throwing a preallocated one.
09:02:59 <DRMacIver> Heffalump: Yes
09:03:04 <DRMacIver> It's just a native method on Throwable
09:03:32 <Heffalump> does the JIT actually notice that you overrode it and do any extra clever stuff? (beyond the gain of not having to actually run it)
09:03:34 <DRMacIver> And thus is specified along with the rest of the standard library
09:03:40 <DRMacIver> Not that I know of
09:03:50 <DRMacIver> But the gain of not having to actually run it is kinda huge
09:03:51 <Heffalump> I guess there could always be an unchecked exception.
09:04:17 <jdh30> Why? I never understood that. Why are exceptions so much slower on the JVM and .NET?
09:04:21 <DRMacIver> Because it basically has to perform some really nastily slow stack inspection in the standard implementation.
09:04:34 <sclv> that trick is quite nice.
09:05:01 <jdh30> Why do other language implementations like OCaml not have to do that?
09:05:12 <Heffalump> they don't offer stack introspection
09:05:19 <DRMacIver> Well, OCaml doesn't do stack traces in the same way.
09:05:28 <Heffalump> the JVM and .NET offer it both for stack traces and for security policies (I think)
09:05:57 <DRMacIver> On top of that, I think a large part of it is because the JVM and .NET use a very C-like stack and lose some optimisation potential as a result
09:06:10 <jdh30> OCaml has stack traces but no security.
09:06:11 <jdh30> interesting
09:06:20 <sclv> @go stackless python
09:06:20 <[Justice]> stack introspection is very nice when your code is wrong ... so you get slower exceptions in development and test, but then you don't throw any exceptions in the first place (hopefully) when your code is out in the wild
09:06:21 <lambdabot> http://www.stackless.com/
09:06:21 <lambdabot> Title: Stackless.com - About Stackless
09:06:22 <vixey> "no security"?
09:06:28 <vixey> I guess type safety doesn't mean anything?
09:06:53 <Heffalump> jdh30: under what circumstances does it provide stack traces?
09:06:54 <jdh30> Not in this context, no.
09:06:58 <sclv> vixey: the JVM has a very fancy security policy for running untrusted code with various levels of sandboxing.
09:07:05 <DRMacIver> In particular if you have a continuations based implementation (I don't know if either Haskell or OCaml do) then you can treat exception throwing as basically just another type of return.
09:07:15 <Heffalump> in principle that kind of thing can be expressed in types, but in practice it isn't
09:07:42 <mar77a> > 7 * 5
09:07:43 <lambdabot>  35
09:08:32 <DRMacIver> (I seem to recall that stack frames are heap allocated in OCaml, which probably helps in a similar way)
09:08:54 <nolrai_> >zipWith take [1..] [x..] :: http://en.wikipedia.org/wiki/Special:Search?go=Go&search=Expr
09:09:08 <vixey> nolrai_: lol
09:09:30 <nolrai_> bwuag!?
09:09:47 <nolrai_> > zipWith take [1..] [x..] :: [ [Expr] ]
09:09:47 <lambdabot>  Couldn't match expected type `[Expr]' against inferred type `Expr'
09:10:02 <[Justice]> > take 5 $ zipWith take [1..] [1..]
09:10:03 <lambdabot>   add an instance declaration for (Enum [a], Num [a])
09:10:04 <vixey> > [x..] :: [Expr]
09:10:06 <lambdabot>  [Exception: not a number
09:10:16 <jdh30> Incidentally, I'd like to make some parallel benchmarks for OCaml, Haskell and F#. Anyone interested in helping?
09:10:30 <jdh30> Does Haskell have a parallel tree-based set implementation?
09:10:42 <nolrai_> > zipWith take [1..] ['a' ..]
09:10:43 <lambdabot>  Couldn't match expected type `[a]' against inferred type `Char'
09:11:00 <Heffalump> jdh30: what do you mean by parallel in that context?
09:11:08 <vixey> > iterate (drop 1) ['a'..]
09:11:09 <lambdabot>  ["abcdefghijklmnopqrstuvwxyz{|}~\DEL\128\129\130\131\132\133\134\135\136\137...
09:11:12 <BONUS> > zipWith take [1..] [['a'..]]
09:11:13 <lambdabot>  ["a"]
09:11:21 <jdh30> As in benefitting from multicore (but not embarassingly parallel).
09:11:34 <Heffalump> wouldn't a tree-based implementation be parallel by default, in the sense of supporting access from multiple threads at once?
09:11:35 <nolrai_> vixey: thats it.
09:11:38 <vixey> > map (take 3) . iterate (drop 1) $ ['a'..]
09:11:39 <lambdabot>  ["abc","bcd","cde","def","efg","fgh","ghi","hij","ijk","jkl","klm","lmn","mn...
09:12:06 <jdh30> I'm looking for a set union implementation that automatically distributes itself over multiple cores.
09:12:17 <Heffalump> oh, right
09:12:21 <Twinside> jdh30 > I remember some benchmark done to compare OCaml and F# in a french developer's forum, they got many issue because OCaml's Garbage COllector is not thread safe
09:12:22 <Heffalump> no, then
09:12:33 <[Justice]> > do { x <- Left 10 ; return "ABC" }
09:12:34 <lambdabot>  Add a type signature
09:12:44 <jdh30> Yes. OCaml will definitely lose until it gets its parallel GC this summer...
09:12:49 <jdh30> really?
09:13:05 <[Justice]> > do { x <- Nothing ; return "ABC" }
09:13:06 <lambdabot>  Nothing
09:13:10 <Twinside> i'm searching the link
09:13:16 <jdh30> i thought the Haskell stdlib would be automagically parallelized...
09:13:17 <BONUS> > map (take 3) . tails $ ['a'..]
09:13:18 <lambdabot>  ["abc","bcd","cde","def","efg","fgh","ghi","hij","ijk","jkl","klm","lmn","mn...
09:13:26 <Heffalump> jdh30: why did you think that?
09:13:50 <malebria> Good afternoon.
09:13:51 <Heffalump> > do { x <- Left "boo!" ; return "ABC" }
09:13:53 <lambdabot>  Left "boo!"
09:13:56 <vixey> hi
09:13:58 <jdh30> I assumed Haskellers would be very keen to leverage their shiny new multicores.
09:14:04 <DRMacIver> Because the web is full of lies and deceit about "Purely functional means you can automagically parallelise!!"
09:14:06 <sclv> jdh: nothing in the haskell stdlibs is auto-parallelized.
09:14:13 <Heffalump> yes, but automagic paralellization is hard..
09:14:17 <DRMacIver> Usually from people who don't know what they're talking about.
09:14:21 <malebria> > (\x -> y where y = x * 2) 2
09:14:21 <lambdabot>  Parse error at "where" (column 10)
09:14:24 <jdh30> Really? Oh bloody hell that sucks.
09:14:33 <malebria> Is it not possible to use where inside of lambda notation?
09:14:36 <malebria> Or am I missing something?
09:14:38 <Heffalump> jdh30: you didn't know that automagic parallelization is hard???
09:14:40 <BONUS> use let
09:14:47 <vixey> malebria: You can't use where at all with lambdabot
09:14:51 <Heffalump> malebria: where applies to declarations, not expressions
09:14:55 <[Justice]> > (\ x -> y where { y = x * 2 }) 2
09:14:55 <lambdabot>  Parse error at "where" (column 11)
09:14:57 <jdh30> I know automagic parallelization is easy in F#. :-)
09:15:00 <Heffalump> the thing immediately inside a lambda is an expression
09:15:02 <sclv> writing a set union in parallel that is across-the-board more performance seems tricky.
09:15:07 <DRMacIver> As I recall there's been research that basically shows that there's very little room for automatic parallelisation even in purely functional code.
09:15:12 <Heffalump> jdh30: it is? how?
09:15:14 <BONUS> > (\x -> let y = x * 2 in y) 2
09:15:15 <lambdabot>  4
09:15:17 <sclv> s/performance/performant/
09:15:24 <jdh30> The next versions of both of our F# libraries are parallel and it was quite easy (with MS's TPL CTP) and I'd assumed the same would be true of Haskell.
09:15:32 <malebria> Heffalump: hum, I think I got the point.
09:15:35 <sclv> writing a unions function across n sets that parallelizes is easy, though...
09:15:40 <Heffalump> jdh30: in what way is that automagic?
09:16:06 <Heffalump> is the code online somewhere? I'd like to understand what precise kind of parallelization you mean.
09:16:08 <sclv> (we could, e.g., turn our mergesort parallel too, but the question is how often it would actually be a win)
09:16:12 <jdh30> sclv: that is actually what I want: map reduce over sets where the reduce operation is set union.
09:16:34 <jdh30> you mean the source code to our products? No, that isn't on-line. :-)
09:16:39 <sclv> oh -- not over just two sets, but over a whole bunch. yeah. that's a one liner.
09:16:42 <pejo> DRMacIver, Satnam Singh and some other people had a paper at ICFP (2007?) that showed very little gain in practice, but in theory a bunch of sequential stuff from nofib could be quite parallel.
09:16:50 <sclv> its just not the default.
09:16:54 <jdh30> Not quite a one-liner, but it is easy enough.
09:17:03 <sclv> jdh30: in haskell it is a one liner.
09:17:09 <jdh30> :-)
09:17:12 <sclv> ?hoogle parMap
09:17:12 <lambdabot> Control.Parallel.Strategies.parMap :: Strategy b -> (a -> b) -> [a] -> [b]
09:17:45 <DRMacIver> pejo: Ah. That's probably what I'm thinking of.
09:17:50 <Heffalump> none of this is automagic, that's the key point. Automagic parallelization doesn't work because compilers don't know what's expensive.
09:17:56 <jdh30> The basic idea is to convey a cost function that gives the approximate number of operations (or time) required for a sub computation. Then you use that to control whether or not divide and conquor algorithms spawn subtasks in parallel or resort to single threaded code.
09:17:59 <Heffalump> And F# doesn't have it any more than Haskell does.
09:18:26 <jdh30> Sure. You have to write it yourself but that covers a lot of practically-important applications.
09:18:29 <Heffalump> jdh30: right, that's the kind of thing data parallel Haskell does (or will do when it works properly)
09:18:32 <Codex_> can we just make compilers know what's expensive? :)
09:18:46 <Baughn> Codex_: Not if we don't know it ourselves
09:18:53 <jdh30> Codex_: Intel's Fortran compiler is actually already quite clever in that respect.
09:18:55 <Heffalump> putting cost into the type system might be neat
09:18:57 <Baughn> Though some runtime optimization would be nice
09:19:06 <pejo> Codex, that's very hard, as Heffalump just said.
09:19:13 <Baughn> Heffalump: How? The cost usually depends on the /size/ of the input data
09:19:15 <EvilTerran> Baughn, :O that's crazy talk!
09:19:20 <Heffalump> Baughn: polymorphism
09:19:37 <Heffalump> if the input data is size x, the output is size 2x and takes 3x time to produce.
09:19:40 <Heffalump> That kind of thing.
09:19:49 <jdh30> Yes. The compiler injects run-time dispatches (when it knows they are cheap) that dispatch to parallel code for large input (= long arrays in Fortran).
09:19:56 <sclv> haha and track the input size with type-level nats!
09:19:59 <Heffalump> I'm just speculating wildly, I'm sure it's really hard in practice too.
09:20:30 <jdh30> It detects O(x^n) complexity for simple nested functions (e.g. rectangular or triangular) and acts accordingly.
09:20:34 <Heffalump> jdh30: for user-written functions, or just specific library functions?
09:20:45 <jdh30> Library specific functions only.
09:20:57 <jdh30> assuming you're talking about what we were talking about. :-)
09:21:01 <Heffalump> ah, that's not very interesting (although still quite useful in practice, no doubt)
09:21:05 <mtag55> i have a list defined like list = [1,2,3,etc] and i want to change an element like list !! 2 = 124
09:21:07 <jdh30> Absolutely.
09:21:10 <mtag55> how can i do that?
09:21:14 <mar77a> :t elems
09:21:16 <lambdabot> forall i e. (Ix i) => Array i e -> [e]
09:21:37 <jdh30> So what 3rd party Haskell libraries have been parallelized?
09:21:43 <Heffalump> it's kind of the moral equivalent of having the compiler implement strcpy/memcpy.
09:21:46 <EvilTerran> mtag55, there isn't a builtin for it
09:22:25 <jdh30> If the compiler does it, yes. I was originally talking about the moral equivalent of calling memcpy yourself. ;-)
09:22:25 <EvilTerran> mtag55, however, i think you should be able to implement it without resorting to explicit recursion
09:22:26 <Baughn> mtag55: You'll need to copy the list up to the element you want to change, and then you can share the rest
09:22:57 <Heffalump> compilers often recognise memory copy loops and change it to the library call.
09:22:58 <Baughn> mtag55: If that's a common operation, may I suggest you use IntMap instead? Or maybe starray, or map, or... yeah, lots of options.
09:23:02 <jdh30> DRMacIver: what gave you the impression that ocaml heap allocated stack frames?
09:23:16 <jdh30> Yes.
09:23:17 <mtag55> ok
09:23:18 <mtag55> tnx
09:23:38 <EvilTerran> mtag55, Baughn has a good point. O(ix) to change the ix'th element of a list
09:23:41 <jdh30> A lot of compilers claim to do such things but suck at them. SGI's Fortran compiler for one...
09:24:12 <DRMacIver> jdh30: Good question. I believe it's a commonly used approach in SML compilers and assumed OCaml did similarly. I vaguely recall I might have had some more specific reason but could be totally wrong.
09:24:23 <Heffalump> ARM's C++ compiler does automatic vectorization
09:24:45 <Botje> @src maybeToList
09:24:45 <lambdabot> maybeToList  Nothing   = []
09:24:45 <lambdabot> maybeToList  (Just x)  = [x]
09:24:50 <jdh30> Heffalump: is that just what the salesman said or do you know that it works?
09:24:51 <Botje> @src listToMaybe
09:24:51 <lambdabot> listToMaybe []        =  Nothing
09:24:52 <lambdabot> listToMaybe (a:_)     =  Just a
09:24:55 <Botje> okay :)
09:25:03 <Baughn> mtag55: If you change elements of a list often, you're doing something wrong.
09:25:08 <Heffalump> jdh30: I know that it works.
09:25:15 <jdh30> Ah, very interesting.
09:25:22 <Heffalump> I think you still have to pay extra for it, though.
09:25:24 <EvilTerran> mtag55, another possibility would be to replace your [a] with a [STRef a], thus rendering the cells mutable
09:25:29 <Baughn> mtag55: (Unless they're always close to the head, in which case the cost is O(1)
09:25:41 <jdh30> Yes. ARM are very good at business as well as technology. :-)
09:25:53 <EvilTerran> mtag55, but that'd only be the best option very occasionally
09:26:01 <jdh30> Ok. Here is another crazy idea.
09:26:02 <Baughn> mtag55: Evilterran has a point, too, though STArray would have less overhead - but we really don't know enough about your program to say
09:26:09 <Heffalump> actually I think they're very good at milking an early success for all its worth
09:26:20 <jdh30> That's the same thing. ;-)
09:26:29 <mtag55> i don't know what STArray is
09:26:31 <EvilTerran> indeed. i was just about to mention Data.Array.ST.STArray
09:26:52 <Heffalump> it doesn't imply that they continue to build good technology consistently (though they do in some cases, certainly)
09:26:54 <mtag55> i want to find the minimum within a matrix and change it
09:27:04 <DRMacIver> The talk about fortran reminds me of something I've been wondering: How much fun you could have with compiler optimisations using some combination of fortran and Haskell feature sets. e.g. if you had a language with a very restricted set of datatypes (say: numerics, records, arrays) + more semantic restrictions (maybe only allowing tail recursion + some fixed combinators), but it was purely functional, had higher order functions, etc.
09:27:06 <jdh30> If GHC had a commerce-friendly intermediate representation like DLLs, could it be used to create a commercial platform where people buy and sell Haskell libraries?
09:27:15 <EvilTerran> mtag55, the ST monad is like the IO monad, except with only mutable values (called STRefs) and no other side-effects
09:27:17 <Baughn> mtag55: STArray is, basically, a mutable array type. A type trick allows you to embed imperative array-mutating code deep inside functional code
09:27:26 <DRMacIver> The GHC array fusion stuff seems to suggest you can do an awful lot for optimising purely functional array code.
09:27:30 <Heffalump> jdh30: "like DLLs"? as in DLLs, or something different?
09:27:41 <Heffalump> it'll get proper DLL support in 6.10, AIUI.
09:27:42 <DRMacIver> And something like clean's uniqueness typing might be a win here too.
09:27:44 <EvilTerran> mtag55, which means that it's impossible for side-effects to escape the monadic action where the mutability is contained
09:27:46 <jdh30> Managed code DLLs, like our F# products.
09:28:12 <Baughn> mtag55: And then there are zippers. Using one of those (google it) allows you to change any data structure repeatedly in the same spot for O(1) cost, but means /moving/ through the structure gets more expensive
09:28:26 <Heffalump> http://www.arm.com/products/DevTools/RVCT.html has an example of the kind of vectorization it does, btw
09:28:27 <lambdabot> Title: RealView Compilation Tools
09:28:36 <jdh30> That's really my single biggest gripe with OCaml: that it is not viable as a commercial platform. I don't believe that will ever be addressed but I spoke to SPJ about this in the context of Haskell and he was interested in the idea.
09:28:49 <Heffalump> jdh30: that requires inventing a whole concept of managed code (and therefore a VM), right?
09:29:04 <gubagem> why isnt ocaml viable as a commerical product/platform?
09:29:12 <vixey> "not viable as a commercial platform" -- not true
09:29:14 <jdh30> Heffalump: I have no idea.
09:29:19 <Heffalump> some people care about binary libraries.
09:29:21 <vixey> gubagem: it is
09:29:26 <vixey> gubagem: that's a blatant lie
09:29:31 <Heffalump> More so in the commercial world than in the OS world. But not universally.
09:29:41 <jdh30> gubagem: you cannot create a market where people can buy and sell OCaml libraries because of the limitations of the language implementation.
09:29:47 <gubagem> oh, is haskell viable as a 'commerical platform'
09:29:47 <Heffalump> jdh30: I'm just trying to understand what you mean.
09:29:48 <EvilTerran> mtag55, hmm?
09:29:56 <Baughn> mtag55: For your particular case of a list, a zipper means just keeping /two/ lists - "ahead" and "behind" - and moving elements from one to the other when you move through the list. Obviously you can then alter the element at the "cursor" easily
09:30:00 <Heffalump> If you just mean DLLs, then what does the "Managed code" bit mean?
09:30:08 <jdh30> gubagem: Haskell is not yet AFAIK.
09:30:19 * obk has a program that goes into an endless loop, *unless* it is run in the debugger - in which case it works fine. ?????
09:30:28 <Heffalump> jdh30: only by your rather restricted definition of "commercial"
09:30:28 <jdh30> gubagem: for exactly the same reasons. However, Haskell is not dead from an evolutionary perspective...
09:30:33 <DRMacIver> Binary libraries aren't the only way to go. Source licenses are totally acceptable.
09:30:42 <Baughn> obk: Fun. Define "endless loop"; also, does it use any concurrency?
09:30:45 <Heffalump> DRMacIver: not everyone thinks that.
09:30:56 <Heffalump> also, binary distribution is important in some environments
09:31:01 <Baughn> obk: (Eg. 100% cpu use loop, 0% use hang, or <<LOOOP>> exception)
09:31:02 <gubagem> i am just learning haskell and i havent seen the line savings yet, then again im passing around lists as state
09:31:03 <obk> Baughn: Nope. Normal "sequential" code. It just hangs in the middle
09:31:04 <Heffalump> even internally to a cmopany
09:31:07 <DRMacIver> Indeed. But "not everyone likes that" is not the same as "not commercially viable"
09:31:19 <cjb> Heffalump: a company that doesn't trust its employees, I guess?
09:31:19 <Heffalump> DRMacIver: yes, indeed.
09:31:20 <Baughn> obk: Try compiling it with -threaded and see what happens
09:31:23 <mtag55> you gave me headacke :P
09:31:32 <obk> 100% CPU, yes
09:31:32 <mtag55> many new information  for a newbie
09:31:33 <Baughn> obk: (That turns on extra deadlock detection code, among other things)
09:31:37 <Heffalump> cjb: not exactly. A company that can't afford to be compiling on every employee's desktop.
09:31:41 <DRMacIver> I'm not saying that having libraries distributable as binaries isn't a good thing. It obviously is. I'm just saying it isn't essential.
09:31:45 * obk will try
09:31:51 <Baughn> obk: Oh. Then it's not a hang, and -threaded won't help. Can try, but..
09:31:56 <DRMacIver> And being able to distribute application binaries is distinct from being able to distribute library binaries
09:32:08 <cjb> Heffalump: Oh, I see.
09:32:13 <Heffalump> yep (but every language supports that, so it doesn't really matter)
09:32:17 <Baughn> obk: I think, at this point, you need to paste the code. And preferably point out which line causes the loop. ;)
09:32:26 <pejo> cjb, having an *identical* binary saves a great deal of pain when trying to reproduce errors.
09:32:29 <DRMacIver> Well, every language other than all the ones which are source interpreted only. :)
09:32:38 <Heffalump> cjb: COM was very successful in certain areas precisely because of this.
09:32:54 <obk> Baughn: ha ha. If I knew that...
09:32:55 <Heffalump> and in some senses .NET is the natural follow-on to COM.
09:32:56 <DRMacIver> But my point was that it's not a case of compiling on *everyone's* desktop, just the developers. :)
09:33:11 <obk> The program isn't excatly small :-(
09:33:30 <jdh30> Heffalump: managed code DLLs have a safe high-level interface.
09:33:33 <Heffalump> DRMacIver: if everyone's desktop can in principle have different combinations of versions, then they all need to compile, or you need binary libraries.
09:34:01 <obk> -threaded didn't help, as expected
09:34:07 <Heffalump> jdh30: safe against what? Malicious code, or just broken code? (In what way is the C calling convention not safe, for the purposes of this discussion?)
09:34:42 <gubagem> obk: do you know which part has the infinite loop? if so through in some I/O and see if its still infinite outside of the debugger
09:35:08 <Heffalump> for safety against broken code, you just need some metadata + the C calling convention. GHC is getting pretty close to having that AIUI.
09:35:09 <jdh30> DRMacIver: we also sell source licences.
09:35:14 <DRMacIver> Heffalump: Hm. I don't follow.
09:35:14 <Baughn> obk: If it's at 100% cpu you could throw the profiler at it
09:35:21 <Heffalump> For safety against malicious code, you need a verification step. Which implies a VM, or PCC.
09:35:26 <obk> gubagem: I guess I can do binary search for the offending loop (in fact have started doing so before hittong on the bright idea of using the debugger)
09:35:39 <jdh30> Heffalump: I meant safe against broken code (i.e. no segfaults) but the JVM and .NET also try to provide security against malicious code.
09:35:51 <obk> The profiler will work even if I kill the program with ^C right? That sounds like a plan...
09:35:53 <Heffalump> DRMacIver: if your environment is built up from a big set of libraries, which each have multiple versions
09:35:57 <jdh30> Heffalump: I'd be happy with safe against broken code.
09:36:09 <jdh30> Heffalump: type safe DLLs.
09:36:10 <Heffalump> then either you need binary libraries and binary compatibility, or you need to recompile for each combination of versions
09:36:17 <gubagem> obk: isolate , tinker, get it to where it doesnt have the bug, then maybe reimplement the buggy part
09:36:37 <Heffalump> jdh30: ok, so that's DLLs + a bit of metadata. As I say I don't think GHC is far off supporting that.
09:36:37 <obk> Sure. I'm just stuck at "isolate" at the moment :-)
09:36:49 <vixey> you don't need any types to be type safe
09:36:59 <vixey> think about a haskell -> scheme translator
09:37:10 <Heffalump> However you'll probably also want binary compatibility between code compiled with different GHC versions, and that's probably further off.
09:37:24 <gubagem> obk: if you code allows it sprinkle with putStrLn's with little messages, and check and see what your variables really are doing
09:37:28 <jdh30> Heffalump: Yes, I think it would be feasible to implement but is it possible to build a commercial market for Haskell libraries?
09:37:30 <malebria> When I call forkProcess $ executeFile .... I get a defunct proccess left.
09:37:38 <malebria> malebria  8129  0.0  0.0      0     0 pts/2    Z+   13:27   0:00          \_ [aplay] <defunct>
09:37:43 <malebria> I used it with aplay.
09:37:45 <Heffalump> jdh30: No idea. You're the expert on selling libraries commercially.
09:38:03 <malebria> Is something being made wrong?
09:38:07 <Heffalump> I've never either wanted to do that or to buy them (either professionally or personally).
09:38:09 <geezusfreeek> i would *guess* that such a market would be very small
09:38:14 <obk> gubagem: Code is 99.99% pure, so it is more 'trace' than putStrLn, but yes that's what I've been doing. However, like I said, it isn't exactly small, so... :-(
09:38:18 <jdh30> Heffalump: Well, I can tell you that we made 25 in three years of selling OCaml code and a hell of a lot more from F#. :-)
09:38:20 <geezusfreeek> unfortunately :(
09:38:38 <Heffalump> who do you sell to (in general terms)?
09:38:38 <Baughn> obk: As I said, you should be able to get some use from the profiler
09:38:41 <jdh30> vixey: yes about type safe.
09:38:49 <Baughn> obk: Any infinite loop is going to show up on that. ;)
09:38:58 <jdh30> Heffalump: I am happy to sell to anyone with money. :-)
09:39:16 <Heffalump> jdh30: no doubt, but where did you get the 25 and the "hell of a lot more" from? :-)
09:39:26 <obk> Baughn: Installing the prof libraries as we speak. This will take a few minutes...
09:39:29 <jdh30> Heffalump: technical computing is our traditional market because I can do that with my eyes closed and we have a name in it but all ideas are welcome. :-)
09:39:41 <gubagem> how do i turn a String into an Integer
09:39:46 <obk> Interesting that it avoids the loop in the debugger though. When I figure it out I'll let you know.
09:39:48 <[Justice]> :t read
09:39:49 <Heffalump> jdh30: right, but what kind of person/institution buys your code?
09:39:49 <opqdonut> gubagem: read
09:39:50 <lambdabot> forall a. (Read a) => String -> a
09:39:53 <vixey> :t read :: String -> Integer
09:39:55 <lambdabot> String -> Integer
09:39:55 <gubagem> oh yea
09:39:57 <Baughn> obk: You don't actually need profiling libraries to profile your own code, although it's mre important in haskell than some other languages
09:39:57 <DRMacIver> I've only come across one library I'd be willing to pay for, though I think there are a few more if my needs were specialised. The problem with libraries is that in order to be commercially viable they have to be kinda niche
09:39:57 <gubagem> thx
09:40:06 <DRMacIver> Niche or really hard to do right
09:40:16 <jdh30> Heffalump: Ah, we sold one copy of Presenta (our technical presentation software written entirely in OCaml) but shelved it because it was so unreliable. We've sold lots of copies of F# for Numerics and F# for Visualization already.
09:40:18 <Heffalump> nag is a good example of a library with fairly broad appeal
09:40:20 <obk> I mean the base profiling libraries - won't link without them
09:40:22 <Baughn> obk: And yes, please do. It's undoubtedly some sort of bug; they're supposed to act identically
09:40:30 <jdh30> DRMacIver: Yes.
09:40:42 <DRMacIver> (the one library is QT incidentally)
09:40:51 <DRMacIver> (QT Jambi specifically)
09:40:53 <jdh30> Heffalump: Yes. F# for Numerics is the new NAG. ;-)
09:41:08 <Heffalump> jdh30: my question is who you sell to (in general terms describing the kind of institution or person, not specific names)
09:41:15 <jdh30> DRMacIver: I also considered buying Qt but their demos segfaulted on my machine so I kept my money.
09:41:29 <Heffalump> jdh30: is the low-level implementation in native code then?
09:41:42 <jdh30> Heffalump: No, the low-level code is currently entirely F#.
09:41:45 <SamB> Baughn: what have you been saying?
09:41:51 <Heffalump> it'll be a while before it's the new NAG then :-)
09:42:24 <DRMacIver> jdh30: One of the demos seg faults on my machine, but most of it works fine and the results are a lot better than any of the other GUI libraries I've looked at.
09:42:31 <DRMacIver> (And the Jambi API is surprisingly pleasant)
09:42:33 <jdh30> Heffalump: Performance-wise, yes. But it is vastly easier to use thanks to an elegant functional interface.
09:42:33 <SamB> Baughn: the profiling RTS is not compatible with the non-profiling RTSs
09:42:54 <jdh30> Heffalump: I'm not actually sure how to pigeon hole our software customers.
09:43:03 <Heffalump> jdh30: no doubt. But NAG can just steal your market by making a similar interface, surely?
09:43:13 <jdh30> Heffalump: I dissected the OCaml for Scientists customers accurately but I think that is quite difficult.
09:43:15 <SamB> (in terms of compiled code, I mean)
09:43:44 <Heffalump> jdh30: well, understanding the market is probably quite important when trying to work out if you might be able to sell something
09:43:52 <jdh30> Heffalump: NAG could steal our interface but they would need to learn how to first and that would basically require them to give us a consultancy contract. :-)
09:43:54 <gubagem> what does prelude.read : no parse mean?
09:44:13 <gubagem> i believe im feeding read correct input...but it is just barfing out on me :(
09:44:23 <jdh30> Heffalump: I believe our F# market is basically completely random. Composed almost entirely of tinkerers who just want something to play with.
09:44:37 <Heffalump> jdh30: I didn't actually mean steal your specific interface, I just meant write a functional interface of their own. And they could do either by just hiring a functional programmer, surely?
09:44:40 <EvilTerran> gubagem, maybe the return value of read's ending up the wrong type?
09:44:46 <[Justice]> > read "10" :: Integer
09:44:48 <lambdabot>  10
09:45:00 <[Justice]> > read "10"
09:45:01 <lambdabot>  Exception: Prelude.read: no parse
09:45:02 <malebria> Shouldn't forkProcess be used then?
09:45:03 <jdh30> Heffalump: If they could find a functional programmer versed in numerical methods, yes. But they don't exactly grow on trees.
09:45:09 <Heffalump> jdh30: interesting. In my experience tinkerers don't spend money.
09:45:21 <SamB> jdh30: what do they grow on?
09:45:28 <Heffalump> quant groups :-)
09:45:32 <[Justice]> make sure you specify what the resulting type should be
09:45:33 <cjb> Heffalump: the .NET world is likely to be more amenable
09:45:34 <jdh30> Heffalump: Right. I think that is really particular to Windows, where users expect to throw money at fun things.
09:45:40 <jdh30> ROTFL
09:45:57 <cjb> just as in the OS X world, people pay $30 for random pieces of shareware.
09:46:12 <jdh30> Yes. We never managed to make any money out of OSX either...
09:46:22 <Heffalump> jdh30: do you really think you need a deep understanding of numerical methods to write a good interface?
09:46:23 <SamB> it's really unbelievable the stuff you have to pay for (or almost do) in Windows
09:46:44 <cjb> SamB: e.g. WinZip
09:46:53 <jdh30> Heffalump: Absolutely, yes. Not just a deep understanding of numerical methods (i.e. the functions themselves) but also how they are used.
09:47:31 <jdh30> Mathematica is an excellent example of what good functional design can bring to technical computing but, of course, it is based around a grindingly-slow general term rewriter.
09:47:32 <Heffalump> Fair enough. Though that requirement wouldn't stop a functional programmer stealing your interface :-)
09:47:36 <hpaste>  gubagem pasted "my offensive newbie code parse no read :-(" at http://hpaste.org/8019
09:48:21 <jdh30> Heffalump: Yes. Conversely, we can steal NAG's performance by licensing the Intel MKL and bundling it into F# for Numerics, just as the Extreme Optimization library for C# does.
09:48:32 <Heffalump> and anyway I reckon that a functional programmer and a numerical methods expert working together would be able to do a good job, the knowledge doesn't need to be in one head
09:48:41 <jdh30> Do many Haskellers use OSX?
09:48:46 <Heffalump> yes, quite a few
09:49:10 <Baughn> Enough that it works well on OS X (except opengl in ghci.. ;(
09:49:13 <Saizan> gubagem: read for string expexcts it in quotes.
09:49:22 <Heffalump> jdh30: matlab has a compiler, I wonder how well that works
09:49:31 <Saizan> > read "\"foo\"" :: String
09:49:32 <lambdabot>  "foo"
09:49:36 <cjb> Heffalump: goes to C, I think?
09:49:43 <Saizan> > read "foo" :: String
09:49:45 <gubagem> Saizan: uhhh how do i pass read just a String value then?
09:49:45 <lambdabot>  "Exception: Prelude.read: no parse
09:49:54 <Heffalump> cjb: no doubt, but that's doesn't tell us much :-)
09:49:57 <jdh30> Mathematica also has a compiler but it only compiles to an interpreted bytecode. I believe MATLAB's is much better. They gave me free copies so I should try them... :-)
09:50:07 <gubagem> > read "1322"::Integer
09:50:09 <lambdabot>  1322
09:50:22 <Saizan> gubagem: why use read at all for myName ?
09:50:27 <Baughn> > read "42" -- It says "no parse". Curious; I wonder what it's defaulting to
09:50:28 <lambdabot>  Exception: Prelude.read: no parse
09:50:40 <gubagem> cause im lazy and it looks nice :(
09:50:50 <cjb> http://hogbaysoftware.com/products/writeroom is my favorite example of how OS X software works :)
09:50:51 <lambdabot> Title: Writeroom
09:51:08 <cjb> ("you want a text editor that can GO FULLSCREEN?  that'll be $24.95, please.")
09:51:13 <Heffalump> :-)
09:51:33 <Saizan> gubagem: (head args) is sufficient, and you don't need a let for each variable
09:51:42 <Saizan> Baughn: ()
09:51:48 <gubagem> > let myVar="happy happy joy joy" in read myVar::String
09:51:50 <Baughn> > read "()"
09:51:50 <lambdabot>  "Exception: Prelude.read: no parse
09:51:51 <lambdabot>  ()
09:51:53 <jdh30> Wow. That application rocks.
09:52:23 <Baughn> > let myVar = show "happy happy zombies" in read myVar :: String
09:52:24 <lambdabot>  "happy happy zombies"
09:52:44 <cjb> hm, maybe I should make a writeroom.el
09:52:46 <jdh30> Incidentally, few of our customers ever actually use what they buy. Some of them even buy multiple copies by accident...
09:53:02 <SamB> jdh30: huh?
09:53:16 <cjb> I don't think "go fullscreen and make the background black and the text green and a blinky block cursor" would be more than five lines of elisp :)
09:53:22 <Heffalump> jdh30: that's an interesting business model you have
09:53:26 <SamB> how do you know they don't use them?
09:53:36 <jdh30> It wasn't deliberate. :-)
09:53:45 <Heffalump> no, I didn't imagine it was :-)
09:53:56 <SamB> that would be a silly business model
09:53:58 <Heffalump> I think I'd be quite worried by it if it was me, though.
09:54:00 <jdh30> They have individual logins and our web server says several have never been used.
09:54:04 <cjb> jdh30: have you considered the options that bartending has to offer?
09:54:26 <DRMacIver> cjb: It certainly guarantees that customers would use his products.
09:54:34 <cjb> :)
09:54:37 <jdh30> I found it quite worrying too so I tracked down some of the people and they explained that they had paid for something like a journal subscription and forgotten about it.
09:54:48 <jdh30> When they were notified it had expired they just bought a new subscription.
09:55:06 <Heffalump> so that's not quite buying the same product multiple times, is it?
09:55:23 <jdh30> other people have bought multiple copies of one library for themselves as well.
09:55:24 <cjb> It's leasing the same product multiple times.
09:55:42 <Heffalump> jdh30: perhaps they think they need it to use them in parallel ;-)
09:55:53 <jdh30> For the journals, yes. They've also done that for single user binary libraries.
09:56:04 <jdh30> ROTFL. Yes, they must have had a dual core... :-)
09:56:15 <Heffalump> isn't that the way M$ works these days?
09:56:23 <Heffalump> get to enough cores and you have to spend more
09:56:51 <Baughn> Heffalump: For values of "enough" that equal variously eight, four and /two/, yes
09:56:59 <jdh30> It is really wierd though, and completely different from the OCaml world where people demand huge amounts of work for pennies.
09:57:07 <cjb> Heffalump: Oracle, especially.
09:57:09 <DRMacIver> Heffalump: It's the way Oracle works. :(
09:57:17 <pejo> Heffalump, it's very much the way Oracle works
09:57:22 <cjb> heh
09:57:28 <pejo> Heh, stereo-quote seems apropriate.
09:57:29 <Heffalump> I see this is a widely-felt sore point :-)
09:57:32 <DRMacIver> Oracle's pricing model was written up by satan.
09:57:42 <jdh30> Yes. I bought Windows XP Pro for 250 for my dual core. I am upgrading to eight cores and realised that I would need a new copy of Windows because my licence only covers 2 cores.
09:57:42 <DRMacIver> There's no other explanation for it.
09:57:50 <Heffalump> it seems mostly reasonable to me to make the charges proportional to the use
09:58:02 <DRMacIver> Heffalump: The story with clustering multiple machines is particularly special
09:58:09 <Heffalump> oh?
09:58:11 <Baughn> Heffalump: I seem to recall some company once wanted to price proportional to the number of /execution units/ in the CPU
09:58:23 <jdh30> I've heard that story before...
09:58:28 <DRMacIver> There are two types of license. The standard and the enterprise license.
09:58:31 <Heffalump> Baughn: why not just do it in proportion to the number of transistors x the clock rate?
09:58:37 <DRMacIver> With the standard license you may cluster up to 4 machines for free.
09:58:41 <pejo> Heffalump, they have some fishy stuff like charging for the amount of physical CPUs in the machine, instead of how many you actually use for example.
09:58:42 <DRMacIver> You may not cluster more than 4 machines.
09:58:48 <jdh30> Or the power dissipation?>
09:58:49 <Baughn> Heffalump: Presumably because that's more or less a secret
09:59:04 <Heffalump> don't CPU manufacturers generally advertise the number of transistors?
09:59:13 <Baughn> Sure. To two significant digits.
09:59:14 <DRMacIver> If you want to cluster more than 4 machines you need to buy the enterprise license for them, which costs > twice the prices of the standard license.
09:59:14 <Heffalump> anyway, jdh30's idea is probably a good proxy (and easier to find out)
09:59:17 <jdh30> It is a bit odd. I hadn't actually thought how we should start to impose such constraints on our own software.
09:59:20 <Heffalump> Baughn: that would be enough.
09:59:31 <Baughn> Heffalump: Well, probably
09:59:39 <Heffalump> jdh30: you're not big enough to make it wortwhile, I suspect. There's a lot of overhead in doing it.
09:59:41 <Baughn> Heffalump: Just don't ask me to run oracle on the gpu
09:59:42 <DRMacIver> But you no longer get those four machines clustered for free. And you have to pay an additional outrageous amount for every machine you want to cluster.
10:00:06 <DRMacIver> </outrage>
10:00:08 <jdh30> Well, we already have customers beating down our door to release new versions of our libraries as soon as a new F# compiler is out.
10:00:20 <Heffalump> well, licence an ARM core and you have to pay an additional amount for every single one you fab :-)
10:00:26 <jdh30> Sooner or later, we shall no doubt start charging money for the priviledge (when everything is out of beta release).
10:00:44 <jdh30> Is that proportional to the floor space of the fab?
10:00:58 <Heffalump> jdh30: I think I'd be pretty annoyed (as a customer) if you charged me to give me a recompiled version of the same source.
10:01:23 <Heffalump> but once F# is out of beta that won't really be necessary anyway
10:01:28 <jdh30> The journals are quite bad in this context, actually. We have two customers who regularly consume more bandwidth than everyone else combined.
10:01:39 <Botje> dammit
10:01:55 <jdh30> There will be several incompatible releases over the next 2-3 years.
10:02:00 <jdh30> We could charge for each.
10:02:03 <Heffalump> jdh30: no, it's per core (with different rates for different cores)
10:02:17 <Baughn> Heffalump: I just had a thought. There are people who charge per cpu core, regardless of whether or not they're actually being /used/?
10:02:30 <Heffalump> Baughn: apparently Oracle do, from the conversation above
10:02:38 <Baughn> Heffalump: I wonder how that's going to work with nanocomputers, where you might conceivably stick a couple million cores in a laptop just in case they come in handy someday
10:02:51 <Heffalump> I think the business models might perhaps change by that time :-)
10:02:52 <DRMacIver> I suspect they'll change the model by then. :)
10:03:13 <jdh30> I wonder what the next model will be...
10:03:14 <Baughn> Hey, could be just a decade. ^^;
10:03:26 <Baughn> jdh30: Heavily DRM'd, I get the impression
10:04:21 <cjb> all this talk of charging people for access to math is making me nauseous :)
10:04:37 * cjb == Linux-using hippy, or something.
10:04:59 <DRMacIver> Charging people for access to maths seems fairly reasonable to me.
10:05:04 * Baughn == Hardware hippy working on self-plugging extension cords
10:05:11 <DRMacIver> Good numerical routines are really hard to do well and efficiently.
10:05:18 <jdh30> True.
10:05:40 <jdh30> However, most of the numerical libraries on .NET are of extremely low quality. That was one of the reasons we went into that market.
10:05:43 <DRMacIver> Although I certainly wouldn't say no to good free numerical libraries.
10:05:58 <cjb> DRMacIver: It's just so far away from any reasonable utopia.  You want to build something, so you go to the math store and buy some math, but only rich people can afford the best math, and blargh.
10:06:04 <u_quark> hello, where can i find some help/documentation on happs ?
10:06:15 <jdh30> Linux has better free numerical libraries than .NET has commercial numerical libraries but there is still huge demand for any numerical libraries on .NET.
10:06:26 <cjb> u_quark: #happs, usually
10:06:39 <jdh30> cjb: what is the alternative?
10:06:44 <u_quark> cjb: no luck :P
10:06:45 <DRMacIver> Ideally the way this would work would be some open standard for the interface and then you could choose between free or commercial implementations.
10:07:02 <DRMacIver> But for most of such the "open standard" is the de facto fortran ones. :)
10:07:10 <Heffalump> cjb: someone has to pay to create the math, though, otherwise it won't be created at all.
10:07:12 <cjb> jdh30: well, having software that no-one owns, of course.  I guess you want to turn my moral nausea into an economic one.
10:07:14 <jdh30> Yes.
10:07:39 <jdh30> cjb: how do the creators of the software feed their kids?
10:07:47 <Heffalump> I think the present world, where open-source and proprietary code compete, works quite well.
10:07:47 <obk> It seems profiling only creates an empty .prof file if the process is interrupted. Back to binary search of the code :-(
10:07:53 <jdh30> cjb: or are you assuming that programmers do not breed?
10:07:57 <Heffalump> obk: do a heap profile, those write out partial results.
10:08:01 <cjb> jdh30: by being bartenders?  :)  I'm regularly unpaid for the software I write.
10:08:08 <obk> Thanks
10:08:17 <DRMacIver> Heffalump: I agree, but I'd like to see more standardisation across the two so it was more easy to get started and transition later.
10:08:37 <Heffalump> DRMacIver: the question is where you draw the balance on allowing lock-in.
10:08:38 <cjb> anyway, I think I'd favor a software tax in this case.  We don't need 30 competing numerical algorithms libraries, we just need a handful of good ones.
10:08:46 <jdh30> cjb: Sure but free software usually really sucks. You get what you pay for. That is even true of FPLs now, IMHO...
10:08:50 <Heffalump> lock-in creates more value for commercial vendors at the expense of everyone else
10:08:58 <DRMacIver> Indeed. It's hard to get right.
10:09:03 <Heffalump> which is good in terms of having them produce stuff, but bad in terms of having that stuff be used efficiently
10:09:43 <jdh30> Heffalump: That is not true. We are benefitting enormously from Microsoft's locked-in customers.
10:09:51 <Heffalump> I think patent and copyright terms for computing stuff should be reduced massively.
10:09:56 <DRMacIver> Heffalump: I don't think lock in is a massive problem in that regards, in that I'm talking about the case of doing well enough on the open source case and then making it easier to migrate to a closed one.
10:10:08 <Heffalump> jdh30: in that context, you are the same commercial vendor as Microsoft.
10:10:50 <DRMacIver> I agree that reduction of patent and copyright issues for software would be a big win.
10:10:54 <jdh30> Heffalump: Then you are talking about lock in to an entire industry, which is silly. Nobody is any more locked in to our libraries than they are to KMail.
10:10:57 <Heffalump> DRMacIver: oh, right. I assumed you meant the other way.
10:11:22 <Heffalump> jdh30: no, I'm talking about lock-in to an entire subset of the industry, where industry = software development and sub-set = the M$ ecosystem
10:11:31 <DRMacIver> Heffalump: No. I'm in favour of commercial software and libraries. What I'm not in favour of is *requiring* their use.
10:11:56 <Heffalump> DRMacIver: right, but I thought you wanted to make it easier to migrate from commerical libraries to open-source ones, but it turned out you meant the other way round.
10:12:00 <DRMacIver> Which is why an open standard that can be shared between commercial and open source implementations are a good thing.
10:12:01 <Heffalump> lock-in is rather more relevant in the former case.
10:12:06 <DRMacIver> Absolutely.
10:12:15 <Heffalump> in any case, I entirely agree about open standards
10:12:26 <jdh30> DRMacIver: That's fair enough but there is an enormous gap between free and commercial software. Look for free alternatives to Mathematica, for example.
10:12:35 <DRMacIver> I know that.
10:12:45 <DRMacIver> I'm talking about a hypothetical "How I'd like things to be" :)
10:12:52 <DRMacIver> Particularly in the case of things like numerical libraries
10:13:57 <obk> heffalump: You sure about the partial results? I'm getting an empty .hp file
10:14:28 <Heffalump> obk: well, I do it all the time, so I'm pretty sure, yes :-)
10:14:40 <obk> +RTS -h<what> ?
10:14:42 <Heffalump> -hc
10:14:51 <Heffalump> what GHC version are you using?
10:15:04 <obk> 6.8.2
10:15:10 <Heffalump> well, -hc is what I usually use, but I've tried all the options. Not sure if I've interrupted them all, though.
10:15:15 <jdh30> DRMacIver: How could commercial software survive without copyright?
10:15:27 <Heffalump> I'm mostly using an early 6.9 snapshot. But I could test with 6.8.2 quickly too, one sec.
10:15:29 <obk> You kill the program before it exits and you get a non-empty .hp file?
10:15:38 <Heffalump> obk: I ^C it
10:15:39 <obk> Thanks
10:15:40 <Heffalump> not kill -9 it
10:15:45 <obk> Me too
10:15:45 <Heffalump> or even kill -TERM
10:15:51 <Heffalump> obk: what platform are you on?
10:15:58 <obk> Ubuntu hardy
10:16:09 <Heffalump> jdh30: I don't think DRMacIver is suggesting abolishing copyright for code, just for standards (if anything)
10:16:24 <DRMacIver> I'm definitely not in favour of abolishing copyright for code.
10:16:32 <DRMacIver> I'm much more so about patents.
10:16:36 <Heffalump> actually, I take that back, I can't test easily with 6.8.2. But I'll test with 6.9 on linux.
10:16:51 <obk> Heffalump: What platform are you using?
10:17:02 <Heffalump> the one I do it on most is Windows
10:17:11 <DRMacIver> It's more that I'd like more openness within the commercial implementations and collaboration with open source versions.
10:17:16 <Heffalump> but I have some profiling-compiled code lying around I'm about to try on Linux
10:17:40 <DRMacIver> An ideal situation would be that companies contributed to open source software and sold their own value added version. (Not quite like what QT do, though that works too)
10:17:55 <Igloo> obk: -h doesn't make a .prof file, you need -p for that
10:18:11 <jdh30> DRMacIver: Consider our closed-source F# for Numerics product and the open source Math.NET, for example. How would you have us collaborate?
10:18:12 <Heffalump> Igloo: obk is talking about the .hp file
10:18:17 <obk> Igloo: I'm doing -hc and looking at the .hp file
10:18:34 <Heffalump> obk: I just did that with 6.9.20080316 and I have a non-empty .hp file.
10:18:43 <Heffalump> ./foo_p +RTS -hc -RTS ; wait a bit ; ^C
10:18:45 <obk> Maybe it is a new 6.9 feature then
10:18:51 <Heffalump> I didn't think it was.
10:18:53 <Igloo> Fair enough, I was going by "[18:07] < obk> It seems profiling only creates an empty .prof file if the process is interrupted. Back to binary search of the code :-("  :-)
10:18:56 <Heffalump> but Igloo can confirm.
10:18:59 <jdh30> DRMacIver: Do you think it is possible to earn money that way?
10:19:05 <Heffalump> Igloo: we moved on frmo that, I suggested a heap profile
10:19:09 <Heffalump> see [18:13]
10:19:15 <Igloo> Ah, OK. It should work in 6.8, anyway
10:19:25 <obk> Igloo: yes, that's true, when I was using -p :-)
10:19:43 <jdh30> DRMacIver: What happens when another open source developer improves the open source version? You can't copy it into your product so they diverge?
10:20:09 <Deewiant> Igloo: this sounds highly platform-dependent unless there are explicit flushes in the code
10:20:09 <DRMacIver> jdh30: Ideally the two would be interface compatible, or have a large subset that was (presumably Math.NET is C# oriented, so this isn't practical here). Sharing some subset of the implementation may be good.
10:20:39 * obk let it run for over a minute, buffered output should have produced _something_ I think...
10:20:41 <DRMacIver> jdh30: And if another open source developer improves the open source version, you'd hopefully be able to integrate those improvements.
10:21:13 <Heffalump> obk: yes, it should have
10:21:21 <DRMacIver> But you would add value in a) Performance (you might even be able to do so more than you would if you developed it on its own) and b) Additional features (this is where the "large subset" becomes an option).
10:21:28 <DRMacIver> As to whether it's possible to make money this way, I don't know.
10:21:40 <DRMacIver> It might be that it's not. Or at least that it's prohibitively difficult.
10:21:46 <DRMacIver> It would be interesting to find out.
10:21:53 <obk> Heffalump: Did you say you have a _p at the end of the executable? I don't!
10:21:59 <jdh30> Interesting idea.
10:22:16 <Heffalump> obk: that's just because I name my profiling executables separately to my non-profiling ones
10:22:17 <obk> I have Gch-Options set to -prof -auto-all and the exe does respond well to +RTS -hc, so ...
10:22:21 <obk> Ah
10:22:21 <obk> Ok
10:22:25 <Heffalump> I used -o foo_p when I compiled
10:22:28 * obk was worried he's running the wrong exe
10:22:40 <Heffalump> the exe wouldn't run with the RTS option if it wasn't compiled for it
10:22:46 <Heffalump> is your code (or binary) available?
10:23:20 <obk> Is ~1600 lines in 7 files
10:23:21 <Igloo> obk: Definitely works here with 6.8.2 on amd64/Linux
10:23:26 <obk> I can zip it to you if you want
10:23:26 * Heffalump is sleepy, and hasn't accomplished any of the stuff he meant to today. Grmph.
10:23:34 <Heffalump> sure.
10:23:39 <obk> Sec
10:23:48 <DRMacIver> jdh30: Even if you offered a very large supset of the open source version in the commercial version, it would be good if one could easily migrate from the open source to the commercial one.
10:23:50 <Heffalump> preferably mail it to ganesh@earth.li
10:24:08 <DRMacIver> jdh30: It may even be that this is *more* profitable, because you can get people hooked on an open source library and then offer them shiny incentives to pay you. :)
10:24:34 <jdh30> Yes. That is much closer to the shareware approach to business. I've never tried it.
10:24:51 <jdh30> Our next major venture may well be a game...
10:25:07 <Heffalump> I'm sure some people would be able to make money this way, and I think it's very likely that it would be fewer people than can make money now.
10:25:07 <DRMacIver> It's different from shareware because it creates an open standard which other people are free to improve upon.
10:25:55 <DRMacIver> Heffalump: Yes. I suspect that's true.
10:26:18 <DRMacIver> Heffalump: But not very many people are making money on libraries anyway are they? At least compared to the application and services markets
10:26:20 <gubagem> is there any physical example for a monad? or is it sooo abstract none exists
10:26:32 <vixey> @instances Monad
10:26:33 <lambdabot> ((->) r), ArrowMonad a, Cont r, ContT r m, Either e, ErrorT e m, IO, Maybe, RWS r w s, RWST r w s m, Reader r, ReaderT r m, ST s, State s, StateT s m, Writer w, WriterT w m, []
10:26:38 <Heffalump> DRMacIver: I wouldn't have thought so, no. But jdh30 is :-)
10:26:38 <vixey> gubagem: there are lots of examples
10:26:49 <DRMacIver> Heffalump: And this might well benefit the latter markets more than it does the former.
10:26:49 <opqdonut> gubagem: all the physical metaphors (containers etc) tend to be pretty poor
10:27:00 <DRMacIver> err
10:27:03 <DRMacIver> more than it hurts the former
10:27:03 <cjb> gubagem: Schroedinger's Box?  :)
10:27:08 <Heffalump> DRMacIver: well, only if a decent set of libraries still got produced.
10:27:32 <DRMacIver> Indeed.
10:27:34 <jdh30> Heffalump: are you Ganesh?
10:27:46 <obk> Heffalump: ben-kiki.org/Obk.tgz
10:27:48 <DRMacIver> I'd rather have a good set of libraries in the current system than a bad in the one I'm suggesting
10:27:49 <Heffalump> well, that's my name, yes.
10:27:55 <jdh30> Oh, hi.
10:27:59 <Heffalump> as /whois should tell you :-)
10:27:59 <jdh30> Hello again. :-)
10:27:59 <DRMacIver> Like I say, I don't really know if this would work. But it's a nice theory. :)
10:28:18 <Heffalump> hi :-) I assumed you would have already worked out who I am :-)
10:28:22 <jdh30> So it does. Wonders never cease...
10:28:34 <jdh30> No, I had no idea. I had some strange images from the name though...
10:29:22 <jdh30> DRMacIver: the sticking point of your idea is giving away half of my work (that already earns me money) for free.
10:29:49 <Lycurgus> sticky sticky
10:29:54 <Heffalump> jdh30: well, it's a sticking point for you, but DRMacIver's thesis is that it  would make the world a better place overall.
10:29:57 <jdh30> Also, you cannot grow such a thing because a commercial product must reach a certain size before anyone will buy it.
10:30:38 <jdh30> Heffalump: Sure, but impractical routes to utopia aren't very useful.
10:30:40 <DRMacIver> jdh30: It doesn't actually need that though. For example, my idea is compatible with you not publishing a single line of code but instead providing a publicly specified API and selling an implementation of that.
10:30:51 * Lycurgus sees a future for jdh30 in ... 
10:30:55 <Heffalump> jdh30: we don't know if it's impractical or not, though
10:30:58 <jdh30> Ah, ok. That is what we already do though.
10:31:12 <Heffalump> obk: your program terminates quite fast when I run it
10:31:17 <jdh30> Well, if it is what we already do then it is clearly practicable. :-)
10:31:19 <obk> Sigh
10:31:22 <obk> As it should
10:31:26 <Heffalump> ghc -prof -auto-all --make -o obk Main.hs
10:31:28 <Lycurgus> management (if you're not there already).
10:31:28 <Heffalump> is how I compiled it
10:31:41 <obk> Maybe I should upgrade to 6.9
10:31:43 <Heffalump> jdh30: that doesn't prove that the alternative is impractical.
10:31:49 <Heffalump> obk: no, this is with 6.8.2
10:31:56 <jdh30> I'd like to try Frag again but I get "Could not find module `Graphics.UI.GLUT'". Can I install it with apt?
10:32:02 <obk> <grrr> Must be some strange environment issue
10:32:07 <jdh30> Heffalump: yes.
10:32:10 <DRMacIver> jdh30: Well, sortof. I suspect it's more of a "here's our API, feel free to have a browse". I'm suggesting it should be unencumbered and vaguely standardised.
10:32:19 <Baughn> jdh30: Yes. Something like libghc6-foo-bar-glut-dev
10:32:34 <Heffalump> DRMacIver: but the conversation above implied that his API in F# for numerics is valuable in itself.
10:33:02 <DRMacIver> Indeed. And I'll grant that that's a potential problem. :)
10:33:20 <jdh30> I already have libghc6-glut-dev
10:33:20 <Heffalump> obk: also, by interrupting it quickly with +RTS -hc -RTS, I still managed to get a partial .hp file.
10:33:24 <obk> Hey!
10:33:31 <obk> If I compile it like you do it works!
10:33:41 <Heffalump> how were you compiling it?
10:33:42 <Igloo> How were you compiling it?
10:33:47 <obk> But if I compile it as part of a package (see the README for the flags) it does not!
10:33:50 <obk> Aha!
10:33:57 <obk> Must be some combination of the extensions
10:34:02 <obk> I'll do a quick binary search on them
10:34:09 <Igloo> Are you compiling the package with -prof?
10:34:22 <Igloo> And -auto-all?
10:34:25 <obk> Just that program but it does not link with the rest of the package
10:34:37 <jdh30> So how do I compile frag?
10:34:46 <Igloo> I didn't follow that
10:35:51 <jdh30> Oh no, wait. I have to use "ghc-6.8.2" instead of just "ghc". Hmm, lots of warnings...
10:36:18 <Baughn> jdh30: Hm, how many ghcs do you have installed?
10:36:28 <Baughn> jdh30: It might be more convenient to use cabal (the binary) to install it
10:37:12 <jdh30> 5 different names for 3 versions. I don't need any though, so I can just remove them.
10:37:33 <obk> Ok, now *this* is strange. If I compile it through runhaskell Setup.hs, it goes into the loop; if I compile it with --make, it works fine.
10:37:47 <obk> How to I see _exactly_ how the cabal is compiling it?
10:37:51 <Heffalump> -v
10:38:03 * obk always felt Cabal not using make is a mistake :-)
10:38:21 <mauke> I have make use cabal
10:38:23 <Heffalump> I tend to agree
10:38:28 <Baughn> obk: make isn't flexible enough. Now, not building them into each other mmight be a mistake
10:38:30 <mauke> EGRAMMAR
10:38:34 <Heffalump> though it's tricky because make isn't cross-platform
10:38:52 <Baughn> Hang on. make, or --make?
10:39:02 <Deewiant> --make.
10:39:03 <Heffalump> make.
10:39:19 <Deewiant> it started with --make. :-)
10:39:26 <Heffalump> it seems there are cross-purposes going on here :-)
10:39:28 <dmwit> runhaskell doesn't compile it.
10:39:28 <obk> Baughn: there's gnu make, and jam, cake, bake, rake, cook, to name a few off the top of my head. We could easily write hake if we wanted to (like rake).
10:39:30 <Baughn> Ow my head -_-
10:39:40 <Heffalump> dmwit: runhaskell Setup.lhs build does
10:39:48 <dmwit> Okay, yes.
10:39:52 <Baughn> obk: The cake is a lie. Might as well use fake
10:39:57 <Heffalump> I want cake now.
10:40:02 <obk> Anyway. I got the list of commands cabal is using. I'll do a binary search to find out what is the offending flag(s)
10:40:20 <alexander> insane how this nick wasn't taken :)
10:40:32 <obk> alexander: They die young :-)
10:41:14 <HairyDude> @hoogle Monoid a => Bool -> a -> a
10:41:14 <lambdabot> GHC.Exts.breakpointCond :: Bool -> a -> a
10:41:14 <lambdabot> Control.Exception.assert :: Bool -> a -> a
10:41:52 <dmwit> :t let ensure p x = guard p >> return (p x) in ensure
10:42:05 <Deewiant> @bot
10:42:05 <lambdabot> :)
10:42:06 <dmwit> *poke*
10:42:07 <lambdabot> thread killed
10:42:11 <dmwit> :t let ensure p x = guard p >> return (p x) in ensure
10:42:12 <Deewiant> @ty let ensure p x = guard p >> return (p x) in ensure
10:42:16 <mauke> dmwit: looks like a type error
10:42:19 <HairyDude> :t ensure b x = if b then x else mempty
10:42:27 <lambdabot> thread killed
10:42:27 <lambdabot> thread killed
10:42:31 <Deewiant> > 1+1
10:42:31 <HairyDude> dmwit: that unnecessarily depends on Monad
10:42:34 <pastorn> @type guard
10:42:34 <lambdabot> thread killed
10:42:38 <pastorn> @type guard
10:42:40 <HairyDude> oh dear, lambda bot is feeling ill again :(
10:42:43 <dmwit> mauke: YOu're right.
10:42:47 <lambdabot>  thread killed
10:42:49 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
10:42:51 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
10:42:55 <Deewiant> > 2+2
10:42:56 <lambdabot>  4
10:42:58 <dmwit> :t let ensure p x = guard (p x) >> return x in ensure
10:43:00 <lambdabot> forall b (m :: * -> *). (MonadPlus m) => (b -> Bool) -> b -> m b
10:43:03 <HairyDude> :t ensure b x = if b then x else mempty
10:43:04 <pastorn> @type guard
10:43:04 <lambdabot> parse error on input `='
10:43:06 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
10:43:14 <HairyDude> :t let ensure b x = if b then x else mempty in ensure
10:43:16 <lambdabot> forall a. (Monoid a) => Bool -> a -> a
10:43:33 <HairyDude> funny that that isn't in Data.Monoid already, it seems useful
10:43:49 <dmwit> HairyDude: I know it depends on MonadPlus, I just want that ensure more often than I want your one. =)
10:44:45 <Heffalump> I don't really understand why that should be called 'ensure'
10:44:46 <HairyDude> dmwit: {-# LANGUAGE FlexibleContexts, OverlappingInstances #-} instance MonadPlus m => Monoid (m a) where { mempty = mzero; mappend = mplus }
10:45:06 <dmwit> sure
10:45:17 <dmwit> Heffalump: Something like this:
10:45:35 <dmwit> Heffalump: [1..10] >>= ensure even
10:45:51 <dmwit> > let ensure p x = guard (p x) >> return x in [1..10] >>= ensure even
10:45:52 <lambdabot>  [2,4,6,8,10]
10:46:20 <mar77a> :t ensure
10:46:21 <lambdabot> Not in scope: `ensure'
10:46:25 <mar77a> doh
10:46:31 <jdh30> bfn
10:46:35 <Heffalump> I understand the MonadPlus one, but not the Monoid one.
10:46:37 <dmwit> (b -> Bool) -> b -> monadPlus b
10:46:59 <HairyDude> Heffalump: the function, or just its name? I'm not attached to that name, in fact I called it something else
10:47:04 <Heffalump> it's name
10:47:10 <Heffalump> s/it's/its/ # gah
10:53:34 * HairyDude wonders why guard has to use m () instead of m a
10:53:59 <vixey> @src guard
10:53:59 <lambdabot> guard True  =  return ()
10:53:59 <lambdabot> guard False =  mzero
10:54:02 <vixey> that's why
10:54:25 <HairyDude> oh wait, that's not the function I was thinking of
10:54:26 <obk> Obvious in retrospect
10:54:32 <HairyDude> I mean when
10:54:34 <obk> Bug was introduced by the -O compile flag
10:54:36 <HairyDude> @src when
10:54:37 <lambdabot> when p s = if p then s else return ()
10:54:43 <obk> Haffelump: Can you verify?
10:54:44 <HairyDude> :t when
10:54:45 <lambdabot> forall (m :: * -> *). (Monad m) => Bool -> m () -> m ()
10:55:43 <dmwit> when doesn't require MonadPlus
10:56:34 <obk> Heffalump: Can you test whether -O also breaks this program on 6.9 ?
10:57:05 <Vq^> i can't grok this memoization with recursion from the haskell wiki
10:57:20 <vixey> Vq^: we could look at fibs if you like?
10:57:25 <HairyDude> ah, so it doesn't
10:57:44 <Heffalump> obk: confirmed that it hangs on 6.8.2
10:57:58 <Vq^> whats so different between "fib n = map fib' [0..] !! n" and "fib = (map fib' [0..] !!)"
10:58:09 <obk> relief! my machine is not haunted by gremlins! :-)
10:58:21 <obk> Heffalump: In 6.9 as well?
10:58:24 <Heffalump> it also doesn't interrupt properly, which probably explains the empty .hp
10:58:38 <Heffalump> oh, though I have a non-empty .hp, actually
10:58:53 <obk> Well, either way, this seems worthy of a bug report.
10:59:03 <obk> Though less so if it was fixed on 6.9
10:59:11 <Heffalump> yeah, just about to try that
10:59:19 <Vq^> vixey: fibs?
11:00:08 <Heffalump> it segfaults!
11:00:21 <vixey> Vq^: it's a good example because the recursion blows up really fast
11:00:27 <obk> Ha!
11:00:30 <obk> Even better
11:00:37 <obk> Ok, I'm entering a bug report on this
11:00:47 <vixey> > let fib 0 = 0 ; fib 1 = 1 ; fib n = fib (n-2) + fib (n-1) in fib 3
11:00:48 <obk> Heffalump: many thanks for the help!
11:00:48 <lambdabot>  2
11:00:50 <ttt--> @src when
11:00:51 <lambdabot> when p s = if p then s else return ()
11:00:52 <vixey> > let fib 0 = 0 ; fib 1 = 1 ; fib n = fib (n-2) + fib (n-1) in fib 300
11:00:55 <Vq^> vixey: well, i understand memoization and every fibonacci example i have seen so far
11:01:03 <lambdabot>  Exception: Time limit exceeded
11:01:08 <obk> Now how do I tell cabal not to use -O ... hmmm... looking up
11:01:34 <vixey> > let fib 0 = 0 ; fib 1 = 1 ; fib n = fib' (n-2) + fib' (n-1) ; fib' n = fibs!!n ; fibs = map fib [0..] in fib 300
11:01:35 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:02:05 <vixey> Vq^: so is it clear why this version memoized?
11:02:14 <Vq^> vixey: yes, very clear
11:02:23 <Heffalump> obk: -O0 as an explicit option
11:02:29 <Vq^> vixey: thought i like the zipWith trick better ;)
11:02:31 <obk> Thanks!
11:02:37 <Heffalump> at a guess, anyway
11:02:45 <Heffalump> it would be silly if that didn't work
11:02:53 <vixey> Vq^: what's that?
11:03:04 <Saizan> obk: configure with --disable-optimization
11:03:12 <vixey> Vq^: changing the entire algorithm just to memo?
11:03:13 <Vq^> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 300
11:03:15 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:03:18 <obk> Saizan: But then my users will suffer
11:03:21 <vixey> yeah not so keen on that
11:03:26 <Deewiant> > let fibs = fix ((0:).scanl (+) 1) in fibs !! 300
11:03:27 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:03:40 <Baughn> obk: You've tracked the loop to the /optimizer/?
11:04:02 <obk> Baughn: Yes!!!
11:04:03 <Heffalump> Baughn: seems so.
11:04:17 <obk> Should have been the 1st thing I tried <sheepish>
11:04:34 <mauke> :t ((. flip (:)) . (flip ($!)))
11:04:35 <lambdabot> forall a. a -> [a] -> [a]
11:04:38 <Baughn> obk: Then. It might be a bit hard, but it would be a very good thing to figure out exactly what causes it - the optimizer should never, ever do that.
11:04:48 <Vq^> my problem is when there is no clear list of memoized values
11:04:49 <Deewiant> @unpl ((. flip (:)) . (flip ($!)))
11:04:50 <lambdabot> (\ j m -> (\ c -> (:) c m) $! j)
11:04:54 <Heffalump> we really could do with a proper reducer for Haskell code
11:05:05 <vixey> Heffalump: what would it do?
11:05:14 <vixey> like an evaluator but step by step?
11:05:15 <Heffalump> cut down test cases like this
11:05:22 <vixey> huh
11:05:25 <Vq^> http://haskell.org/haskellwiki/Memoization#Memoization_with_recursion
11:05:29 <lambdabot> Title: Memoization - HaskellWiki, http://tinyurl.com/65yh9u
11:05:32 <Heffalump> hangon, I'm trying to find the C utility I'm thinking of
11:05:38 <obk> Baughn: I am submitting a bug report with the program
11:05:54 <DRMacIver> Heffalump: You mean delta?
11:05:59 <Heffalump> DRMacIver: yes, I do. Thanks!
11:06:04 <Vq^> im trying to understand how memoized_fib evaluates
11:06:04 <DRMacIver> No problem
11:06:09 <mauke> > let fs = 0 : 1 : zipWith (+) fs (tail fs) in fs !! 10000
11:06:10 <lambdabot>  3364476487643178326662161200510754331030214846068006390656476997468008144216...
11:06:14 <mauke> > let fs = 0 : 1 : zipWith (+) fs (tail fs) in fs !! 100000
11:06:14 <vixey> Vq^: That's exactly the same as my example which you said you understood ...
11:06:16 <lambdabot>  out of memory (requested 1048576 bytes)
11:06:22 <Heffalump> if we had an unlayout utility, we could probably just use delta.
11:06:56 <Vq^> vixey: except you defined fibs
11:07:01 <DRMacIver> unlayout doesn't seem like it should be hard to write if you have a parser and pretty printer for Haskell already
11:07:04 <vixey> Vq^: syntax
11:07:05 <gubagem> @hoogle !!
11:07:09 <Heffalump> agreed.
11:07:12 <lambdabot> Prelude.(!!) :: [a] -> Int -> a
11:07:12 <lambdabot> Data.List.(!!) :: [a] -> Int -> a
11:07:17 <Heffalump> We also need a hsallinone for GHC Haskell.
11:07:23 <DRMacIver> A what?
11:07:32 <Heffalump> merges multiple modules into one
11:07:33 <Vq^> vixey: i guess i don't see that jump :/
11:07:35 <DRMacIver> Oh, right.
11:07:43 <Deewiant> vixey: why doesn't memoized_fib there evaluate the map fib [0..] on each call?
11:07:44 <vixey> Vq^: there is no jump
11:07:49 <DRMacIver> Does delta really need them all in one file?
11:07:56 <vixey> > let fib 0 = 0 ; fib 1 = 1 ; fib n = fib' (n-2) + fib' (n-1) ; fib' n = fibs!!n ; fibs = map fib [0..] in fib 300
11:07:57 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:08:00 <Vq^> vixey: then i guess im just plain confused...
11:08:03 <Heffalump> no, there's multidelta (IIRC) which doesn't. But I think it's much harder to operate.
11:08:09 <DRMacIver> Ah
11:08:14 <Heffalump> and it's nice to have your test case all in one file if at all possible
11:08:43 <obk> Ticket #2327 if anyone is interested - the -O flag producing faulty code
11:09:21 <Vq^> hmm, i guess it's the body of the function/value that is memoized_fib that gets memoized
11:09:24 <Deewiant> > let fib 0 = 0 ; fib 1 = 1 ; fib n = fib' (n-2) + fib' (n-1) ; fib' n = map fib [0..] !!n in fib 300
11:09:25 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:09:26 <DRMacIver> Heffalump: True
11:09:36 <Deewiant> vixey: that one runs much slower for me in GHCi
11:09:52 <DRMacIver> Something like this? http://www.cs.utah.edu/~hal/HAllInOne/index.html
11:09:52 <lambdabot> Title: Haskell All-In-One
11:10:08 <DRMacIver> Oh, it only handles H98
11:10:09 <Heffalump> DRMacIver: yes, precisely that.
11:10:28 <DRMacIver> Oh, sorry
11:10:33 <DRMacIver> I totally misread your comment
11:10:44 <Heffalump> I got the name slightly wrong (HSAllInOne verses HAllInOne)
11:11:33 <DRMacIver> I parsed what you said as "We need this tool" rather than "We need this tool to support GHC's dialect of Haskell"
11:11:41 * DRMacIver fails. :)
11:11:51 <Heffalump> we need such a tool that supports GHC Haskell
11:12:01 <Heffalump> whether it's that tool update or a new one, I don't care
11:13:10 <Vq^> vixey: i guess you are completely right, my problem is only about syntax
11:14:20 <Vq^> it's the big difference between "f = (fs !!)" and "f x = fs !! x" that i seem to be somewhat confused by
11:15:33 <hpaste>  Orchid pasted "Achievement cat... is pround of self" at http://hpaste.org/8022
11:16:53 <ziman> what is the best way to parse two kinds of blocks, one beginning with "Frame ", the other with "FrameMatrix", using Parsec? do i have to factor the grammar or is there a friendlier way? :)
11:17:03 <chessguy> @pl \s -> u s >>= u
11:17:03 <lambdabot> (u =<<) . u
11:17:22 <mauke> @pl \u -> u s >>= u
11:17:22 <lambdabot> (>>=) =<< ($ s)
11:17:27 <mauke> haha
11:18:17 <chessguy> @pl \u s -> u s >.>= u
11:18:18 <lambdabot> flip =<< ((>.>=) .)
11:18:25 <DRMacIver> Hm. Is there any way to tell ghc to recompile all its libraries from source?
11:18:33 <chessguy> @pl \s u -> u s >>= u
11:18:33 <lambdabot> join . ((>>=) .) . flip id
11:18:40 <Heffalump> I don't think it even knows where the source is
11:18:53 <DRMacIver> Ah well
11:19:03 <DRMacIver> I suspect it's time to reinstall ghc. Again.
11:19:07 <Heffalump> why?
11:19:17 <Deewiant> @src (>=>)
11:19:17 <lambdabot> Source not found. You speak an infinite deal of nothing
11:19:18 <Dzlk> ziman: for what value of "best"?
11:19:21 <Deewiant> chessguy: (>=>)
11:19:29 <Deewiant> @ty (>=>)
11:19:30 <DRMacIver> Because I didn't reinstall after I last broke it with that pretty printers bug.
11:19:31 <lambdabot> forall a (m :: * -> *) b c. (Monad m) => (a -> m b) -> (b -> m c) -> a -> m c
11:19:48 <DRMacIver> I just rebuilt some of the modules that depended on it
11:20:08 <DRMacIver> And now I'm finding I can't use the Language.Haskell stuff which dependended on that and can't figure out where to recompile them from.
11:20:32 <Toxaris_> ziman: something like (keyword s = try $ string s >> whitespace), and then (keyword "FrameMatrix" >> ...) <|> (keyword "Frame" >> ...) should work
11:20:37 <Heffalump> ah
11:22:14 <Toxaris_> ziman: if you make sure that (keyword "Frame") does not accept "FrameMatrix", you're on the safe side. The try in keyword enables local backtracking, to allow different keywords to begin with the same prefix
11:22:52 <gpds> how is an int different from an integer?
11:23:03 <Heffalump> smaller range
11:23:06 <Heffalump> integer is unbounded
11:23:16 <gpds> whats the range?
11:23:22 <ziman> Toxaris_, i see, thanks. I thought of `try'ing whole blocks but `try'ing the keyword is clearly better :)
11:23:28 <mauke> > [minBound, maxBound] :: [Int]
11:23:29 <lambdabot>  [-2147483648,2147483647]
11:23:40 <gpds> thanks!
11:23:48 <DRMacIver> Technically the range is unspecified...
11:23:50 <Heffalump> standard says 29 bits minimum, GHC uses machine words
11:24:02 <Toxaris_> ziman: yeah, that's a general design pattern with Parsec: use try on the lexer level, but try :) to avoid it on the parser level
11:24:03 <DRMacIver> At least specified to be within a certain bound
11:24:15 <Toxaris_> ziman: with lexer and parser levels not exactly seperate :)
11:25:26 <ziman> hm, good point
11:25:41 <chessguy> Deewiant:  is that in the libraries somewhere?
11:25:47 <chessguy> @hoogle (>=>)
11:25:48 <lambdabot> Control.Monad.(>=>) :: Monad m => (a -> m b) -> (b -> m c) -> a -> m c
11:26:53 <hpaste>  vicky pasted "fib memo" at http://hpaste.org/8023
11:27:03 <chessguy> guess that answers that question :)
11:27:06 <vixey> Vq^ & Deewiant
11:27:59 <DRMacIver> Heffalump: Well, I was right about it being ridiculously easy to implement NoLayout. Took all of four lines to throw together with Language.Haskell. :)
11:28:07 <DRMacIver> (Well, four lines plus imports)
11:28:24 <mauke> .oO( import XMonad.Layout.NoLayout )
11:28:43 <DRMacIver> Sorry, unlayout
11:28:49 <hpaste>  DRMacIver pasted "unlayout" at http://hpaste.org/8024
11:29:42 <Deewiant> vixey: how about fib2 such that fibs is written inline, i.e. fib3' n = map fib3 [0..] !! n
11:29:44 <Heffalump> DRMacIver: does it work on GHC Haskell? I thought Language.Haskell was H98
11:29:54 <Heffalump> not that it's not a good thing.
11:29:57 <vixey> Deewiant: please paste it with times
11:31:36 <DRMacIver> Heffalump: I was under the impression that the Language.Haskell module provided with ghc used ghc's parser
11:31:39 <chessguy> @seen conal
11:31:39 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
11:31:52 <DRMacIver> Heffalump: Again, I could be totally wrong
11:31:59 <Heffalump> I didn't think it had syntactic elements for non-H98. I also could be wrong.
11:32:01 <mauke> preflex: seen conal
11:32:01 <preflex>  conal was last seen on #haskell 3 hours, 21 minutes and 47 seconds ago, saying: sjanssen: thx!
11:32:12 <ziman> @pl \x -> whitespace >> return x
11:32:13 <lambdabot> (whitespace >>) . return
11:32:33 <gpds> preflex: seen jdh30
11:32:33 <preflex>  jdh30 was last seen on #haskell 46 minutes and 1 second ago, saying: bfn
11:32:38 <Heffalump> http://www.cs.chalmers.se/~d00nibro/haskell-src-exts/
11:32:39 <lambdabot> Title: haskell-src-exts: Haskell-Source with Extensions
11:32:40 <dmwit> :t \x -> liftM (const x) whitespace
11:32:42 <lambdabot> Not in scope: `whitespace'
11:32:58 <dmwit> ziman: flip liftM whitespace . const
11:33:07 <gubagem> thats fib memo code looks wicked simple
11:33:07 <dmwit> Is even less readable. ;-)
11:33:18 <ziman> dmwit, :D
11:33:38 <DRMacIver> Heffalump: Hm. Just tried it, you're right
11:33:50 <hpaste>  Deewiant annotated "fib memo" with "inlining fibs" at http://hpaste.org/8023#a1
11:34:05 <Deewiant> vixey: as I thought, it's the slowest of all four
11:34:09 <Heffalump> haskell-src-exts is the way to go, I suspect
11:34:25 <vixey> Deewiant: I couldn't have predicted that
11:34:36 <BONUS> @src ap
11:34:37 <lambdabot> ap = liftM2 id
11:34:37 <Heffalump> either that or ghc-api
11:34:58 <Deewiant> vixey: it's doing the map fib3 [0..] for each call to fib3', nothing is memoized
11:35:04 * DRMacIver is slightly perplexed that GHC bundles a parser that doesn't handle GHC extensions.
11:35:04 <vixey> Deewiant: I thought it would be equivalent to fib2 actually
11:35:07 <DRMacIver> Oh welll
11:35:09 <vixey> Deewiant: but it makes sense
11:35:15 <vixey> in retrospect
11:35:36 <Vq^> > let fib = (map fib' [0..] !!); fib' 0 = 0; fib' 1 = 1; fib' n = fib (n-2) + fib (n-1) in fib 300
11:35:38 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:35:52 <Deewiant> vixey: what I don't get is why the same doesn't happen with memoized_fib
11:36:05 <Vq^> > let fib n = map fib' [0..] !! n; fib' 0 = 0; fib' 1 = 1; fib' n = fib (n-2) + fib (n-1) in fib 300
11:36:07 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
11:36:11 <vixey> have you timed memoized_fibs?
11:36:17 <vixey> (which of my examples is it equivalent to?)
11:36:24 <Deewiant> has the speed of fib2
11:36:29 <vixey> right
11:36:35 <vixey> so it's the same code
11:36:43 <vixey> just written in a silly way
11:36:53 <vixey> (I think we could impove the wiki article)
11:36:55 <chessguy> @type iterateM
11:36:57 <lambdabot> Not in scope: `iterateM'
11:37:02 <jleedev> > let fibs = 1 : scanl (+) 1 fibs in fibs !! 300
11:37:03 <lambdabot>  359579325206583560961765665172189099052367214309267232255589801
11:37:06 <chessguy> @hoogle iterateM
11:37:06 <lambdabot> No matches found
11:37:17 <Vq^> that last example i pasted doesn't terminate within a minute
11:37:19 <chessguy> @type iterate
11:37:21 <lambdabot> forall a. (a -> a) -> a -> [a]
11:37:42 <Vq^> lambdabot seems to solve it thought :/
11:37:49 <Deewiant> vixey: but it looks like it should have the speed of fib3 :-/
11:37:58 <DRMacIver> Hm. Where can I find the ghc api?
11:38:21 <DRMacIver> Ah, never mind
11:39:02 <Deewiant> vixey: :-OOOO
11:39:07 <chessguy> @hoogle (a -> m a) -> a -> [a]
11:39:07 <Deewiant> vixey: making it pointy slows it down to fib3 speed
11:39:07 <lambdabot> Prelude.iterate :: (a -> a) -> a -> [a]
11:39:07 <lambdabot> Data.List.iterate :: (a -> a) -> a -> [a]
11:39:07 <lambdabot> Prelude.scanl :: (a -> b -> a) -> a -> [b] -> [a]
11:39:18 <chessguy> :hoogle+
11:39:23 <Heffalump> DRMacIver: it bundles a standard library
11:39:27 <chessguy> @hoogle+
11:39:27 <lambdabot> Data.List.scanl :: (a -> b -> a) -> a -> [b] -> [a]
11:39:27 <lambdabot> Prelude.scanr :: (a -> b -> b) -> b -> [a] -> [b]
11:39:27 <lambdabot> Data.List.scanr :: (a -> b -> b) -> b -> [a] -> [b]
11:39:51 <Heffalump> if it produced a datatype that included constructors for non-H98 stuff, that standard library wouldn't be compatible across implementations
11:39:51 <vixey> Deewiant: at least I don't think that these 3 typed of memoization (none, one time, every time) can be written simpler
11:40:26 <chessguy> @hoogle (a -> Maybe a) -> a -> [a]
11:40:27 <lambdabot> No matches, try a more general search
11:40:50 <Vq^> vixey: did you see my last fib?
11:41:22 <adekoba> is there a variable in ghci that stores the last answer?
11:41:35 <mauke> it
11:41:44 <adekoba> <3
11:41:45 <adekoba> thanks
11:42:00 <tusho> what are the monad laws again?
11:42:05 <hpaste>  Deewiant annotated "fib memo" with "pointless vs. pointy" at http://hpaste.org/8023#a2
11:42:07 <tusho> a >>= return       ===     a
11:42:10 <tusho> what else?
11:42:11 <Vq^> vixey: and if you did do you know why lambdabot seems to optimize it to "do memoization"?
11:42:12 <DRMacIver> Heffalump: I'd sortof expect that to be moved out to hackage with the library reorg if it wasn't actually part of ghc.
11:42:16 <DRMacIver> But I guess not.
11:42:24 <chessguy> @type \f x -> takeWhile isJust $ iterate (\x -> x >>= f) x
11:42:26 <lambdabot> forall a. (a -> Maybe a) -> Maybe a -> [Maybe a]
11:42:30 <Deewiant> vixey: see paste, that is weird IMO O_o
11:42:36 <mauke> @wiki Monad_laws
11:42:36 <lambdabot> http://www.haskell.org/haskellwiki/Monad_laws
11:42:49 <chessguy> @pl \x -> x >>= f
11:42:50 <lambdabot> (f =<<)
11:43:00 <Deewiant> or (>>= f) :-P
11:43:20 <chessguy> @pl \f x -> takeWhile isJust $ iterate (>>= f) x
11:43:21 <lambdabot> (takeWhile isJust .) . iterate . (=<<)
11:43:46 <chessguy> @type \f x -> takeWhile isJust $ iterate (>>= f) x
11:43:47 <lambdabot> forall a. (a -> Maybe a) -> Maybe a -> [Maybe a]
11:43:57 <Vq^> Deewiant: did you see lambdabots result from your fib5_ ?
11:44:08 <chessguy> @hoogle [Maybe a] -> a
11:44:09 <lambdabot> No matches, try a more general search
11:44:18 <chessguy> @hoogle [Maybe a] -> [a]
11:44:18 <lambdabot> Data.Maybe.catMaybes :: [Maybe a] -> [a]
11:45:29 <Deewiant> Vq^: yes, can't explain it
11:45:38 <bd_> @src catMaybes
11:45:39 <lambdabot> catMaybes ls = [x | Just x <- ls]
11:45:39 <Deewiant> Vq^: I'm not sure, perhaps lambdabot compiles the code?
11:45:52 <bd_> there needs to be a maybeToMonadPlus :|
11:46:06 <Vq^> it seems that lambdabots compiler sees that the right hand side of !! isn't affected by it's arguments
11:46:19 <Vq^> er, left hand side
11:46:51 <hpaste>  vicky annotated "fib memo" with "clue" at http://hpaste.org/8023#a3
11:47:32 <vixey> Vq^: no I didn't se it
11:47:36 <Deewiant> O_o, why does that happen
11:47:44 <vixey> monomorphism
11:47:57 <gpds> @type zipWith
11:47:59 <lambdabot> forall a b c. (a -> b -> c) -> [a] -> [b] -> [c]
11:48:01 <Deewiant> monomorphism restriction speeds up programs, right
11:48:11 <vixey> well it's about types
11:48:21 <bd_> Deewiant: depends
11:48:23 <vixey> speed up is a possible consequence
11:48:39 <bd_> Deewiant: the goal is to avoid situations where an expression is unexpectedly evaluated twice, with two different types
11:48:40 <Deewiant> sure
11:48:43 <sclv_> any folks familiar with DPH around?
11:48:55 <bd_> by forcing you to explicitly annotate when you want that to happen
11:48:58 <sclv_> The parallels with *lisp are sort of striking me lately.
11:49:05 <Deewiant> bd_: it's just that in this case it unexpectedly causes something to be evaluated only once instead of N times :-)
11:49:17 <sclv_> Was wondering how much influence there was (haven't trawled through all the papers yet)
11:49:32 <dons> sclv_: very little, afaik
11:49:42 <dons> it came out of work on nested data paralellism in the early 90s
11:49:43 <bd_> Deewiant: oO
11:50:11 <dons> sclv_: based on Nesl
11:50:19 <sclv_> the distribution law of the alpha operator in *lisp is pretty cool
11:50:23 <Vq^> the types may not be the cause thought
11:50:41 <dons> http://citeseer.ist.psu.edu/blelloch90nesl.html
11:50:42 <lambdabot> Title: Nesl: A Nested Data-Parallel Language - Blelloch (ResearchIndex)
11:50:53 <dons> "Nesl, a strongly-typed, applicative, data-parallel language."
11:50:57 <bd_> Deewiant: when you bind fibs at the toplevel (in fib2 example), GHC keeps it around until the program terminates
11:50:58 <vixey> hi dons!
11:51:17 <Deewiant> bd_: yep, but I'm looking only at fib5 and fib5_
11:51:38 <vixey> I tried to show that with fib2 vs fib3
11:51:49 <vixey> (specifically timing them twice)
11:52:05 <dons> and the ubiquitous reddit link http://reddit.com/info/6lmsz/comments/
11:52:25 <vixey> I guess not :/
11:52:42 <halberd> where can I find an algorithm or heuristic for representing a graph that is not planar, but that would be planar if a few edges were removed?
11:52:50 <Vq^> you can force the type of fib5 to Num a => Int -> a without any large difference in performance
11:52:52 <bd_> Deewiant: hmm... I guess GHC bound (map fib5' [0..] !!) at the toplevel, thus keeping the (map fib5' [0..]) around too?
11:53:10 <halberd> that is I want an algorithm that will take a non-planar graph and return a small set of edges that can be removed from the graph to make it planar
11:53:28 <Deewiant> bd_: this is GHCi, I wouldn't expect it do that kind of a transformation
11:53:50 <bd_> Deewiant: it might.
11:53:55 <bd_> It's not actually a transformation
11:53:57 <vixey> isn't ghci the same as ghc?
11:54:10 <Deewiant> I don't know, is it?
11:54:15 <bd_> vixey: It optimizes less, and uses a bytecode VM rather than a native code generator
11:54:27 <bd_> the libraries are the same though
11:54:36 <bd_> and the RTS
11:54:37 <Vq^> well, lambdabot transforms  f n = fs !! n   to  f = (fs !!)  causing it to do memoization
11:54:39 <Deewiant> bd_: and sure it is, in this case it changes a temporary to a global o_O
11:54:55 <Deewiant> Vq^: that shouldn't make a difference in terms of memoization, that's just syntax
11:54:55 <Vq^> thats somewhat niftier
11:55:02 <Deewiant> and that's what I'm confused about
11:55:09 <Deewiant> because it is causing memoization
11:55:20 <bd_> Deewiant: Consider that you have (!!) (map fib5' [0..]) - a naive implementation would be to put a partial application of (!!) (with the map term bound into a closure) as a global
11:55:21 <Vq^> Deewiant: it's like bd_ is saying
11:55:33 <bd_> Deewiant: Thus, it's memoized if you don't optimize it much :)
11:55:36 <Vq^> Deewiant: the left hand of !! gets stored between the calls
11:55:48 <Vq^> Deewiant: because it's not dependent on the argument
11:55:55 <Deewiant> bd_: ah, good point, it becomes a closure
11:56:02 <vixey> how can you memo typeclasses
11:56:20 <Deewiant> I wonder if -O2 slows that down :-D
11:56:37 <Vq^> it's a bit tricky to spot which caused my initial confusion
11:56:46 <Deewiant> I still wouldn't expect it to happen
11:56:53 <Deewiant> now I just understand why it does
11:57:01 <Vq^> especially since different implementation handles it differently
11:57:13 <Deewiant> but I definitely wouldn't call the "memoized_fib" on that wiki page a memoized version of fib
11:57:25 <Deewiant> just one that happens to get memoized depending on how the compiler chooses to generate the code for it
11:57:31 <Vq^> Deewiant: not really
11:57:36 <bd_> with fib5_, since n is in scope, and since you're light on the optimizations, fib5_' ends up depending on the outer n
11:58:18 <Vq^> Deewiant: the function is a value, and all dependencies of that value should really just be computed once
11:58:21 <Deewiant> a where- or let- or global binding of fibs = map fib [0..] is what I'd call a memoized one
11:58:45 <ddarius> vixey: The intent that is trying to be communicated is the difference between fib n = let memotable = ... in memotable !! n and fib = let memotable = ... in \n -> memotable !! n
11:58:47 <vixey> A global definition is equivalent to a let isn't it?
11:58:48 <Deewiant> Vq^: should, but nobody's saying you have to
11:59:05 <Deewiant> Vq^: there's a bug that GHC doesn't calculate "1 + 2" at compile-time if they're of type Integer
11:59:09 <bd_> Deewiant: fib5 is isomorphic to such a binding :)
11:59:18 <vixey> ddarius: oh ok
11:59:23 <vixey> that makes sense
11:59:40 <Deewiant> bd_: sure, but it still depends on the compiler running it through the isomorphism :-P
11:59:55 <bd_> Deewiant: not really, the naive implementation of either works similarly :)
12:00:05 <mauke> optimisomorphism
12:00:09 <bd_> How is 'map fib' any different from '(!!) . map fib' ?
12:00:20 <Vq^> Deewiant: you could say that, i would think that it's only a bug if they get recalculated if they isn't part of a function scope
12:00:41 <Deewiant> Vq^: it's a global of the form x = 1 + 2
12:00:51 <Vq^> Deewiant: and with optimizations like the one which speeds up fib5_ it should never be recalculated
12:01:36 <Vq^> Deewiant: then i would expect it to get recalculated unless the compiler optimizes that by seeing which scopes doesn't depend on the function argument
12:02:41 <Deewiant> with ghc -O2 they both appear to run at about the same speed
12:03:20 <Deewiant> but I still think it's dependent on a compiler optimization and not memoized in itself
12:03:34 <Vq^> only fib5_
12:03:47 <Vq^> fib5 doesn't make that assumption
12:03:48 <bd_> Deewiant: check how they're transformed in the core, if you're really curious
12:03:56 <bd_> -ddump-stg
12:04:04 <vixey> ddarius, how is your linear logic stuff going ?
12:04:11 <Vq^> and fib5 is equivalent to memoized_fib in the wiki
12:04:26 <ddarius> vixey: I have a parser.  I'm not sure what all rules LolliMon uses to loosen up the grammar.
12:04:39 <vixey> oh cool
12:05:11 <vixey> do you have any repo online ?
12:05:19 <vixey> like a darcs thing..
12:05:51 <Deewiant> bd_: I can't read core well enough to see the difference :-)
12:05:55 <ddarius> LolliMon accepts a,b -o {c} as being equivalent to a -o b -o {c} which makes sense, but apparently it also accepts a o- sigma U \ f U, top which doesn't make sense syntactically.
12:06:02 <ddarius> vixey: No repo, not even locally yet.
12:06:34 <ddarius> The next step is either kind/type checking or figuring out how the heck I'm going to evaluate this stuff.
12:06:43 <vixey> :D
12:06:54 <vixey> I think pfenning has some text on evalution
12:07:22 <vixey> some of lolli is described heer http://www.cs.cmu.edu/~fp/courses/linear/handouts.html
12:07:23 <lambdabot> Title: 15-816 Linear Logic / Handouts
12:07:36 <vixey> iirc...
12:08:55 <ddarius> The backward chaining part is easy.  The forward chaining probably isn't too hard, but I haven't really thought that hard about it.
12:09:07 <vixey> oh I have no idea about forward chaining
12:09:18 <vixey> is that how things like:  a, b -o c. are evaluated?
12:10:53 <ddarius> The monad {_} starts forward chaining.
12:11:11 <vixey> oh I see
12:11:25 <conal> chessguy: hi
12:11:36 <chessguy> howdy
12:11:42 <sclv_> I actually don't think that *lisp gave anything especially "nested" at all -- the alpha operator's rules are semantically good to think with though.
12:11:42 <conal> chessguy: how's it going?
12:11:47 <chessguy> meh, it's going
12:11:57 <chessguy> life has been crazy
12:12:48 <chessguy> conal: had any chance to look at my code lately? we had talked about trying to figure out why the test harness sucked
12:13:10 <DRMacIver> The fact that there are no less than three tools for converting from darcs to git is vaguely unsettling
12:13:29 <conal> chessguy: i did look at it some, though i didn't delve deeply enough to find a more elegant angle
12:13:51 <bd_> DRMacIver: I tried running one of those on the GHC repo once - darcs proceeded to OOM my machine >_>
12:14:04 <DRMacIver> Ha
12:14:09 <DRMacIver> I wish I could be surprised by that. :)
12:17:16 <ddarius> vixey: If you had a linear context with facts like item(1) and you had the rule item(X), list(XS) -o {list(X:XS)} then if you had the linear fact list([]) then the query {list(XS)} would bind XS to a list of numbers is some non-deterministically chosen order.
12:22:37 <u_quark> hello, where can i find some help/documentation on happs ?
12:22:52 <mauke> u_quark: the internet
12:23:18 <chessguy> conal: the issue seems to be needing a value instead of a type in some places
12:23:39 <sclv_> oh hey, it turns out that CM Lisp did provide Nested operations -- it just only parallelized the bottom layer
12:23:39 <u_quark> mauke: I need something more specific than that ...
12:24:07 <mauke> u_quark: ask a more specific question :-)
12:24:14 <conal> chessguy: interesting.  do you have an example?
12:24:17 <mauke> u_quark: oops, sorry
12:24:31 <mauke> u_quark: I actually got confused by a display error in my client. my fault :(
12:24:43 <u_quark> lol it's ok
12:26:06 <chessguy> conal:  ok, so there's this 'perft'  function in TestHarness.hs
12:26:32 <chessguy> it takes a value of type (Chessboard c) => c, when really all it 'needs' is the type
12:27:28 <Heffalump> it doesn't actually have 'c' anywhere else in the type?
12:27:30 <chessguy> conal:  because any type in Chessboard is going to have a value named 'emptyBoard'
12:28:27 <conal> chessguy: i see.  sounds like a consequence of having Chessboard be a class rather than a type.
12:28:37 <chessguy> conal:  indeed
12:29:09 <chessguy> because the definition has class Chessboard c where ... emptyBoard :: c
12:29:10 <Heffalump> you could wrap it up with an existential
12:29:15 <Heffalump> or turn it into a record
12:29:20 <Heffalump> (instead of a class)
12:29:51 <chessguy> Heffalump:  well, the purpose of the class is to define default behavior, but allow it to be overridden
12:30:02 <Heffalump> you can do that with a record too
12:30:11 <hpaste>  koast pasted "(no title)" at http://hpaste.org/8025
12:30:12 <Heffalump> given record update syntax
12:30:45 <conal> Heffalump: i wonder if your suggestion would amount to making chessguy's dictionaries explicit.
12:30:52 <Heffalump> yes, of course
12:31:00 <quicksilver> explicit dictionaries are much better than classes
12:31:05 <quicksilver> classes are vastly overused :)
12:31:08 <Heffalump> either using existentials or a record type is equivalent to that
12:31:16 <chessguy> quicksilver: 'better' in what way?
12:31:26 <quicksilver> classes have one specific use case : where you want the type-inference enginge in the compiler to pick the dictionary automatically
12:31:33 <Heffalump> indeed, passing an unused value of type 'c' is also equivalent to that, really
12:31:58 <quicksilver> chessguy: 'better' in the sense of more general, more flexible, more expressive
12:32:08 <Heffalump> quicksilver: agreed, but this might be useful in other cases with this same thing.
12:32:15 <quicksilver> of course.
12:32:20 <quicksilver> I haven't studied chessguy 's code
12:32:24 <quicksilver> just making a general observation
12:32:33 <Heffalump> me neither, but it's not stopping me from speculating wildly
12:32:33 <quicksilver> classes are overused and dictionaries are more flexible :)
12:33:44 <chessguy> yeah, but haskell records suck
12:33:53 <Heffalump> not that badly, and not for this purpose
12:33:53 <quicksilver> no more than classes
12:33:59 <lament> yeah, javascript is much better in that sense ;0
12:34:02 <quicksilver> the syntax is beguilingly similar
12:34:20 <Heffalump> also you can't make anonymous type class instances, and you can make anonymous record values
12:34:26 <quicksilver> being able to override one member (method) at a time is very handy.
12:34:44 <quicksilver> so you can specify behaviour (methods) of one value (object) in terms of another
12:34:52 <quicksilver> a bit like what you can do in prototype object systems
12:35:02 <lament> yeah, it's very much like javascript
12:48:07 <wieczyk> Hi, could someone explain me what is a 'type order' in lambda calculus ?
12:48:52 <dmwit> > let fib 0 = 0; fib 1 = 1; fib n | even n = c^2 - a^2 | otherwise = c^2 + b^2 where { n' = div n 2; [a, b, c] = map fib [n'-1..n'+1] } in fib 300
12:48:55 <lambdabot>  Exception: stack overflow
12:49:45 <Philippa_> wieczyk: doesn't mean anything to me. Is this in the same sense as 'higher-order function'?
12:50:02 <dmwit> > let fib 0 = 0; fib 1 = 1; fib 2 = 1; fib n | even n = c^2 - a^2 | otherwise = c^2 + b^2 where { n' = div n 2; [a, b, c] = map fib [n'-1..n'+1] } in fib 300
12:50:03 <lambdabot>  222232244629420445529739893461909967206666939096499764990979600
12:50:49 <dmwit> vixey, Heffalump: Still interested in fib?  That one doesn't even use memoization...
12:51:16 <Heffalump> interested in what sense?
12:51:26 <vixey> that's quite neat :)
12:51:38 <vixey> there are lots of ways to do it
12:51:45 <dmwit> Dunno, you were talking about it a lot, earlier, but I had to go to lunch with my girlfriend.
12:51:52 <wieczyk> Philippa_: well, types with order > 1 are higher-order types.
12:51:56 <dmwit> So it took me 'til now to do what I was thinking of. =)
12:52:07 * Heffalump doesn't even remember that
12:52:09 <vixey> well I was just using it to show some details of memoization
12:52:14 <dmwit> oh
12:52:17 <dmwit> Well, never mind then.
12:52:18 <wieczyk> Philippa_: I am studying lambda on my univ now, and i have exercised. But in my point of view i have a mistake in definition of type order
12:52:19 <dmwit> =P
12:52:29 <wieczyk> Philippa_: but i cannot find any definition on internet.
12:52:46 <dcoutts> obk, Heffalump: if you're using the latest Cabal then you can: cabal configure -O0
12:52:50 <vixey> wieczyk: Why would you want a definition of this word? Where does it come from?
12:53:06 <wieczyk> Philippa_: I have defintion order(t0 -> t1 -> ... -> tn -> a) = 1 + max(1, t0, ..., tn)
12:53:06 <vixey> s/word/phrase/
12:53:11 <obk> dcoutts: Sure, but anyone downloading the package wouldn't know to do so
12:53:21 <wieczyk> vixey: on my home-work list :)
12:53:32 <vixey> what exactly is on your list?
12:53:38 <wieczyk> and in my opinion it should be 1 + max (_0_,...)
12:53:46 <wieczyk> not 1 + max (1,...)
12:54:00 <Socrates`> Is it possible to do type class constraints in a data definition?
12:54:06 <dcoutts> obk: oh you mean it fails with -O1 ? yeah, that'd be bad :-)
12:54:23 <ddarius> Well max(0, ...) is the same as max(...) in this case.
12:54:27 <obk> dcoutts: Just '-O' which AFAIR is the same as '-O1'
12:54:35 <obk> yes, it is bad :-)
12:54:40 <wieczyk> vixey: hm
12:54:42 <vixey> shouldn't it be
12:54:45 <dcoutts> obk: yes, I was just making it explicit
12:54:54 <dcoutts> obk: btw, we are going to use something like make, there's a GSoC project to do a implementation of a make-style framework in Haskell
12:54:56 <Socrates`> So, say rather than Maybe a, you could constrain a to say (Monad m) => m a?
12:54:56 <vixey> 1 + max(1, order(t0), ..., order(tn))
12:55:11 <ddarius> Also, presumably that should be max(order(t0), order(t1), ... )
12:55:16 <obk> dcoutts: Nice! Do you have a URL for it?
12:55:25 <wieczyk> dcoutts: i need to proof some easy think at start, that order(t) = 1 => t = a
12:55:27 <vixey> it's probably not worth defining this yourself
12:55:40 <vixey> if it's used in any proofs you can just figure out what the definition should be
12:55:47 <wieczyk> and type syntax, t = a | t -> t
12:56:17 <wieczyk> it means that a is a type variable, and also some function type is a type.
12:56:18 <wieczyk> and
12:56:19 <dcoutts> obk: http://code.google.com/soc/2008/haskell/appinfo.html?csaid=56D60241D77CA94C
12:56:20 <lambdabot> Title: Google Code - Summer of Code - Application Information, http://tinyurl.com/62c6aw
12:56:21 <vixey> wieczyk: Do you have some test cases?
12:56:37 <vixey> wieczyk: like order(x) = 1, order((a -> b) -> a -> b) = 2 ?
12:56:40 <obk> dcoutts: Thanks! I'll give it a look
12:57:00 <wieczyk> and, if i need to proof order(t) = 1 => t = a, it means that first-order are type-variables, not type of functions. But,
12:57:09 <wieczyk> order(a) = 1 + max(1) = 1 + 1 = 2
12:57:23 <wieczyk> that i have mistake in defintion of order(t) ?
12:57:59 <wieczyk> becuase, if order(a) = 2 by using this defintion, that i cannot proof "order(t) = 1 => t = a"
12:59:16 <wieczyk> Ah.
12:59:27 <wieczyk> a lecturer send a info that it should be 0 in max()
12:59:29 <wieczyk> sorry for problem.
12:59:40 <wieczyk> btw: do yo know some good papers for lambda ?
12:59:47 <nottha_k> what does it mean when a package is hidden? http://hpaste.org/8026
13:00:11 <ddarius> wieczyk: There is tons of good information on the lambda calculus.  Just put it into google or google scholar.
13:00:39 <dmwit> nottha_k: It means you need more packages in the build-depends: line in the .cabal file.
13:01:09 <dmwit> (...I think.)
13:02:13 <nottha_k> dmwit: sounds right. I added "time" to the list of dependencies and got a little farther
13:02:17 <nottha_k> thanks
13:03:09 <oldsalt> @seen shag
13:03:09 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
13:03:31 <mauke> preflex: seen shag
13:03:31 <preflex>  Sorry, I haven't seen shag
13:04:21 <oldsalt> mauke: thx ;)
13:05:16 <dmwit> So, \bot mostly replies to commands that start with ? or @.
13:05:32 <dmwit> But she also has a tinyURL plugin and a title-grabbing plugin.
13:05:35 <dmwit> Are there any others?
13:05:45 <dmwit> (:t, :k, > don't count.)
13:05:47 <mauke> karma, presumably
13:05:52 <dmwit> Ah, karma.
13:07:09 <dons> Igloo: the "GHC 6.8.2 and large source files" mail looks like a good test case generator
13:07:16 <Corun> Ok, ok, it's not haskell.. But isn't this seriously awesome: http://www.youtube.com/watch?v=NHC_Qyov2Xc
13:07:17 <lambdabot> Corun: You have 1 new message. '/msg lambdabot @messages' to read it.
13:08:01 <Frederick> folks does soneone here had a good course in semantics  on the university and can point me out the website for it so I can get exercises and solutions?
13:09:03 <Baughn> Frederick: Semantics of what?
13:10:44 <Igloo> dons: *nod*, and we have some other test cases to look at along similar lines, too
13:13:09 <Frederick> Baughn: imperative languages
13:13:17 <Frederick> Denotational Semantics
13:15:38 <int-e> dcoutts: you have a typo in the gtk2hs motd - it's haskell.org, not hsakell.org
13:15:49 <dcoutts> doh
13:16:07 <dcoutts> int-e: fixed thanks
13:17:30 <dmwit> Good thing we have wetware spelling correctors.
13:21:01 <Frederick> Baughn: suggestions?
13:21:18 <Baughn> Frederick: Apparently not. I haven't seen it, and google is helpless.
13:21:43 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/8027
13:22:03 <Frederick> Baughn: not sure if google is helpless but I could not find the right terms
13:22:06 <int-e> dmwit: actually I pasted the command (it's a darcs pull <url>) and only spotted the mistake after that failed. so it was computer aided spell checking.
13:23:09 <dmwit> oh, heh
13:24:25 <dons> int-e: good work on the git/darcs tool
13:24:35 <dons> you should probably cc. the darcs list too
13:25:08 <dons> Igloo++ Serge sez: "But I think that you have found a bug in the DoCon test program.
13:25:12 <dons> Thank you"
13:25:28 <dons> i wonder when we'll see docon on hackage.
13:27:00 <dons> ah, it is even cabalised.
13:27:25 <int-e> dons: maybe I'll do that for 0.2. right now it's a bit painful to build - it's really of little interest to people who don't know haskell.
13:28:19 * dons tries: cabal install docon
13:28:37 * dcoutts crosses his fingers on dons behalf
13:28:42 <dons> 20k lines of code.
13:29:13 <dons> dcoutts: its all nicely cabalised, http://haskell.org/docon/distrib/2.11/
13:29:22 <dons> we just need to convince serge to upload the source/ bundle
13:29:49 <dcoutts> oh right
13:30:17 <int-e> Oh and I've learned that the darcs repository at darcs.net is slightly inconsistent - at one point there's a patch that renames a Autoconf.lhs file that was never created.
13:31:18 <dons> wow, this really does take a while to compile
13:31:25 <dons> [22 of 83] Compiling VecMatr
13:31:30 <dons> 3 minutes in.
13:31:51 <dons> ghc's doing ok though. 133M heap
13:33:09 <dons> docon needs a better website, and haddocks
13:38:39 <dons> half way..
13:38:55 <ddarius> Conal Elliott and Frank Pfenning.  A family of program derivations for higher order unification.
13:39:49 <dons> that must have been a while ago, ddarius
13:39:53 <Peaker> I converted my ray tracer from using a 2d Array of (Word8, Word8, Word8) to represent the pixels, to a 2d Array of Vector (where: data Vector = Vector (Double, Double, Double))  - this made it a _lot_ slower. Also, just converting from that format back to the array of (Word8,Word8,Word8) takes a looong time.  Why is that?
13:40:03 * dcoutts piles in on the QC library testing debate
13:40:07 <ddarius> dons: 1987
13:40:07 <dons> oh horrible, you use triples, Peaker?
13:40:25 <Peaker> dons, yeah, a Vector is a triplet/tuple yeah
13:40:36 <ddarius> Vector3 !Double !Double !Double
13:40:36 <Peaker> dons, mainly for 3d coordinates but now I am using it for r,g,b colorspace, heh
13:40:41 <dcoutts> Peaker: if you're worrying about performance there are much better representations
13:40:51 <Peaker> dcoutts, I'm pretty new at this :)
13:40:57 <Peaker> ddarius, thanks I'll try that
13:41:04 <dcoutts> you can do better still
13:41:14 <hpaste>  dons pasted "standard vector type for Double" at http://hpaste.org/8029
13:41:16 <dcoutts> eg use a UArray Int Word32
13:41:28 <ndm> dons, dcoutts: not tempted to start using Lazy SmallCheck rather than QuickCheck
13:41:41 <dcoutts> ndm: what makes it Lazy?
13:41:46 <ndm> its become to tool of choice for testing - the tests mean something, you can keep them going to get more results etc.
13:41:52 <dons> ndm, we already use smallcheck + quickcheck + chasing bottoms
13:41:55 <dcoutts> ndm: I have indeed used SmallCheck and it's great for some situations
13:42:07 <ndm> dcoutts, think of it as smallcheck but more efficient - lazy is just an implementation detail
13:42:15 <dons> do smallcheck for the 'inductive' cases, quickcheck for random extra wandering, and bottom testing for other things.
13:42:25 <Peaker> dcoutts, I want a 2d array (UArray (Int,Int) ..)?
13:42:27 <ndm> lazysmallcheck is loads faster, especially if you do validitycondition => test
13:42:29 <conal> i'd like some help with ghc inlining & rules.  i have a rule that would fire if 'id' is inlined and simplified.  it won't fire unless i add a simplification rule saying "id = \ x -> x".
13:42:29 <Peaker> dcoutts, why Word32 and not Vector?
13:42:32 <dcoutts> dons, ndm: I should tidy up my SmallCheck strictness checking variation and release it as StrictCheck
13:42:50 <dcoutts> ndm: ah I see
13:43:00 <Peaker> dons, why the pragma there?
13:43:09 <dons> Peaker: so it doesn't use slow Double math ops
13:43:15 <dons> Peaker: also -fvia-C -optc-O2
13:43:22 <Peaker> dons, will -O3 do?
13:43:26 <dons> nothing
13:43:30 <dcoutts> Peaker: an Array of a structure type has to use pointer indirections to other heap allocated objects
13:43:45 <Peaker> dons, what does the unpack do to avoid double math ops?
13:43:53 <dons> conal: have you checked out the rewrite rules wiki page?
13:43:55 <dcoutts> Peaker: so for maximum performance we do not want to do that, we want to store the colour components directly in the array
13:44:07 <conal> dons: no, i haven't.  looking ...
13:44:08 <Peaker> dcoutts, but I want a 2d array of vectors, how do I store a vector in a Word32?
13:44:16 <dcoutts> Peaker: and 3 Word8's fit comfortably into a Word32
13:44:33 * ndm has just finished 0.5 billion lazy small check tests
13:44:33 <Peaker> dcoutts, ah, but I want to be able to do interesting things to colors.. like averaging them - which is difficult when they wraparound as you add them
13:44:34 <dons> conal: http://haskell.org/haskellwiki/GHC/Using_rules
13:44:42 <dons> ndm, don't tell ian.
13:44:52 <dcoutts> Peaker: it'd require store/fetch functions that pack/unpack
13:44:55 <ndm> dons: only took 2 days :)
13:45:07 <ndm> would hardly make a dent on the buildbots...
13:45:12 <dons> docon now up to 50/80 modules
13:45:19 <conal> dons: thanks much!
13:45:28 <dcoutts> ndm: actually they're pretty sensitive to build times for validation
13:45:40 <dcoutts> ndm: since that's part of their development cycle
13:45:45 <ndm> dcoutts, i know - was joking :)
13:45:54 <Peaker> dons, thanks for the tips
13:46:29 <ndm> dcoutts, for filepath i use the policy of having quickcheck tests and unit tests, and if a quickcheck one ever fails i make that particular case (or a minimal variant) a unit test
13:46:41 <dcoutts> ndm: pretty sensible
13:46:48 <DRMacIver> Idle thought based on current libraries mailing list discussion. How hard would it be to create a setup where a set of quickcheck tests generated a file which creates test cases for the failures
13:47:14 <sclv_> ndm: not to bug you, but did you get my lamdbabot msg?
13:47:24 <DRMacIver> so you had developers running fullblown QC tests and the failures generated tests that could be added to the nightlies
13:47:24 <ndm> DRMacIver: ever tried to do a test setup using cabal? now that's painful! - we need that infrastructure to work basicially before you do anything more
13:47:37 <DRMacIver> Heh. No, I admit I haven't.
13:47:41 <ndm> sclv_: nope, lambdabot often looses messages, or repeats them
13:48:00 <dcoutts> ndm: I consider it non-existent :-)
13:48:02 <DRMacIver> The number of serious Haskell projects I've written is sadly rather minimal
13:48:19 <dcoutts> ndm: the support for tests/testing in Cabal
13:48:42 <ndm> dcoutts, there is a badly designed hook with a constantly changing interface - what more would i want ;)
13:48:47 <sclv_> ndm: if you're not already all set with a testing harness for hoogle4, I have my quickcheck based cgiCheck in a repo now.
13:48:56 <sclv_> http://code.haskell.org/~sclv/cgicheck/
13:49:09 <dcoutts> ndm: oh it's only badly designed, it's not constantly changing
13:49:36 <ndm> dcoutts, it changed at least once, going from returning an ExitCode to () - or vice versa
13:49:37 <sclv_> its usable, but not fully tested and sorta rough in terms of some api refinements -- I want to be able to insert random delays, for example, to force more concurrency issues.
13:49:51 <dcoutts> ndm: oh, right, yeah ok :-)
13:50:26 <dcoutts> ndm: I was going to say we've gone so far to maintain stability that we have an extra parmater to test that does nothing and we can't even figure out what it was ever for :-)
13:50:33 <ndm> sclv_: Hoogle is entirely stateless, and i've been working on the pure test framework, using the console version - but i'll put this in the pile to check out when the CGI is ready for testing
13:51:07 <dons> i'd be interested in seeing short runs each night, but seeded with new seeds
13:51:22 <ndm> dcoutts, cabal-install makes me sufficiently happy that, provided it is bundled with the next full GHC release, i can forgive cabal a lot for the meantime
13:51:26 <dons> over time you'd get rather good exploration of the value space. this is what john hughes set up for the ericcson guys
13:51:53 <dcoutts> dons: right
13:52:11 <dcoutts> dons: with a high 'size' on the Arbitrary instance
13:52:41 <ndm> what you really want is one property language and instance declration structure that can do smallcheck, lazysmallcheck and quickcheck with a simple change of driver call
13:53:01 <ndm> i bring this up with colin once a month, just to keep the idea floating around
13:53:02 <dcoutts> ndm: but you'd write your properties differently I think
13:53:10 <sclv_> ndm: it works pretty well for stateless stuff already actually -- just an easy way to generate and run requests with conditions on the responses. I might have just reinvented a subset of quickCheckM, I guess, but it seems pleasant enough to use for me.
13:53:12 <ndm> dcoutts: how?
13:53:16 * monochrom has successfully built the ghc 6.8.3 release candidate (6.8.2. may 31)
13:53:24 <dcoutts> ndm: especially between sc and qc
13:53:31 <ndm> sclv_: i will check it out once i get there
13:53:44 <dcoutts> ndm: because you have to worry about the size of the state space with SC
13:53:47 <ndm> dcoutts, sc has existentials and uniques - but is a superset of qc
13:54:05 <ndm> i've never had to worry with sc
13:54:15 <ndm> but lazy small check is a lot better for that, which is what i always jump for
13:54:35 <dcoutts> ndm: if your branching factor is too high then you cannot test to depth N where N = ??
13:55:28 <ndm> dcoutts, lazy small check :) - it matters less about the branching factor of the data type, and more about the branching factor of  your test
13:55:29 <dcoutts> ndm: if there is a way to limit the total number of tests with SC then that point is moot
13:55:42 <sclv_> yeah, don't mean to be pushy, just looking for use-cases/feedback.
13:55:46 <ndm> and if your test has a high branching factor, more tests is probably a good idea
13:56:00 <dcoutts> ndm: sure but time is a limitation
13:56:04 <ndm> sclv, no worries - will probably be a few weeks but do want to give it a whirl
13:56:33 <ndm> dcoutts, i've been using it to "prove" parts of my phd - small phd (relatively), and large computers for a weekend :)
13:56:52 <dcoutts> ndm: one thing I worry about for SC/QC is that different tests actually need different test generators for the same types in different tests
13:57:01 <monochrom> wow, ghc src + extralib build tree (source + binary) is approaching 1GB. :)
13:57:57 <dcoutts> ndm: especially in SC actually, eg Char, in testing bytestring. What chars values do you allow?
13:58:05 <ndm> dcoutts, you are like a sales pitch for lazy small check - you just generate everything
13:58:10 <dcoutts> ndm: not too many or the branching factor is insane
13:58:30 <ndm> dcoutts, lazysmallcheck reigns in the branching with some very clever tricks :)
13:58:41 <dcoutts> ndm: it's not about the number that get eliminated, it's the number you actually test with
13:58:52 <ndm> dcoutts, it eliminates them before generating them
13:59:07 <ndm> i.e. if you test all (== 'a') xs
13:59:09 <dcoutts> ndm: so you just add lots of ==> filters and it's all ok
13:59:22 <ndm> it will generate x:xs, for all x in Char
13:59:34 <ndm> but will only generate 'a':x:xs
13:59:54 <ndm> dcoutts, you do nothing, it understands your code, and doesn't even generate "dull" cases
14:00:16 <ndm> ==> filters do the trick, but so does anything, the property itself, whatever
14:00:29 <dcoutts> ndm: how does it know from looking at all (== 'a') xs that we only want 'a' values in some cases?
14:00:54 <dcoutts> isn't the (a -> Bool) part of the property a black box?
14:01:01 <ndm> dcoutts, laziness - it tries with 'b':_|_, sees you never evaluated _|_, and figures that all other tests are irrelevant
14:01:12 <dcoutts> ohhh, sneaky
14:01:17 <dcoutts> using _|_'s
14:01:17 <ndm> its a black box unless you have impure exceptions, or IORefs
14:01:23 <ndm> yeah, its very neat
14:01:44 <ndm> means you don't need to trick out your generators, and it exploits laziness in properties automatically
14:02:01 <dcoutts> ndm: sounds very much like the strictness adaptations I made to SC but with a different purpose
14:02:29 <dcoutts> ndm: LSC uses it to see what was evaluated and guide further tests, I was using it to actually test properties at all partial values
14:02:57 <ndm> yes, does sound similar
14:03:05 <dcoutts> ndm: and there's an example where you do need different properties again, eg with partial values you don't need any pre-conditions :-)
14:03:50 <dcoutts> mind you strictness properties are always going to be different
14:04:16 <ndm> yeah
14:04:22 <dcoutts> it might be useful to test ordinary properties with partial values too though
14:04:25 <ndm> although a sufficiently generic generator could get them all
14:04:39 <ndm> hmm, not sure - you are likely to get partial values back
14:04:41 <dcoutts> eg to distinguish reverse . reverse /= foldr (:) []
14:05:01 <ndm> ok, partial as in infinite, rather than _|_
14:05:05 <dcoutts> both
14:05:08 <dcoutts> all partial values
14:05:25 <dcoutts> eg _|_, _|_ : _|_, 0 : _|_, etc etc
14:05:54 <dcoutts> the ordinary SC generators but extended to generate _|_ as the initial value for every type
14:06:10 <dcoutts> so you generate all partial and total values in domain order
14:06:11 <ndm> yeah
14:06:46 <dcoutts> and you can borrow the === and <== domain equality and refinement operators from the ChasingBottoms lib
14:06:57 <dcoutts> that's basically what I did
14:07:36 <dcoutts> perhaps I should talk to Colin about doing and releasing a variation like that
14:08:34 <ndm> yep, you should!
14:09:21 <monochrom> chasing bottoms sounds fun
14:09:52 <dcoutts> @slap monochrom
14:10:08 <dcoutts> @botsnack?
14:10:38 <dcoutts> monochrom: ah well, no wet fish for you
14:10:44 <monochrom> haha
14:11:41 <jaj> @b52s
14:12:03 <jaj> lazy evaluation...
14:14:58 <dcoutts> @seen dbueno
14:15:33 <dcoutts> doh! lambdabot must be asleep
14:15:47 <EvilTerran> doh
14:16:12 <jaj> @slap lambdabot
14:17:55 <hpaste>  petekaz pasted "Strictness question" at http://hpaste.org/8032
14:18:11 <hpaste>  conal pasted "rewrite example -- why doesn't id inline?" at http://hpaste.org/8033
14:19:22 <conal> i'd appreciate tips on my paste.  i'm trying to figure out when i can count on inlining to help with rule applicability.
14:19:52 <dons> conal: ah, maybe both id and reverse inline at the same time
14:20:03 <dons> you'd have to delay inlining on 'reverse' I think
14:20:05 <petekaz> I'm reading dons on exploiting strictness, laziness, and recursion.  In his definition of length', I asked at one point why 'go' doesn't accumalate thunks due to the (n+1).  Someone told me ghc figures it out all by itself.  So why then do I need to be explicit in my definition of 'mean'?
14:20:06 <SamB> hmm.
14:20:17 <conal> dons: oh
14:20:25 <conal> dons: oh!  that makes sense.
14:20:39 <conal> dons: and my rule pseudo-inlined id early
14:20:43 <SamB> dons: did you know that unstream doesn't seem to have any progress guarentees?
14:20:50 <dons> conal, yeah, that's it.
14:20:54 <dons> i just got it to work.
14:21:10 <conal> dons: thanks.  okay, now i'll see what i can make of my *real* example.
14:21:16 <dons> SamB: sure. you can Skip forever. its not "progress" though, talk to dcoutts.
14:21:22 <monochrom> Perhaps using a tuple blinds the strictness analyzer.
14:21:35 <SamB> dons: why do you say it's not progress?
14:21:44 <hpaste>  dons pasted "control inlining of what you wish to match" at http://hpaste.org/8034
14:21:48 <SamB> coq won't let me write it, that's all I'm sayin' ;-)
14:21:49 <dons> conal: ^
14:22:30 <ddarius> petekaz: go is strict in n, that foldl' is not strict in the components of the tuple (without the !s) although the overall function is strict.
14:22:45 <ddarius> petekaz: Personally, I dislike relying on anything but very basic strictness analysis.
14:24:13 <conal> dons: :).  simple enough.  does all inlining happen after all rewriting?
14:25:12 <petekaz> ddarius: ok, thanks.
14:25:51 <petekaz> ddarius: I guess when I read his post, I would have preferred to see 'go' written wia bang pattern just to be explicit.
14:26:08 <petekaz> I'm a newbie so what do I know anyways.
14:26:10 <dons> conal: its interleaved. see -ddump-simpl-iterations
14:26:22 <dons> you get a phase of different inlinings, then rules, then repeat 3 or 4 times
14:26:24 <dons> or more..
14:26:30 <ddarius> petekaz: Extraneous strictness annotations can decrease performance and that go in length is strict.
14:26:49 <ddarius> (in this case, I doubt it would hurt)
14:26:53 <dons> i think if you've determined the precise strictness you want, making it explicit is a good idea though
14:27:03 <dons> as for type annotations
14:28:50 <petekaz> ddarius: why is the go in length strict? is it only because of the strictness analysis?  or are you saying it is strict regardless?
14:29:20 <petekaz> wouldn't the (n+1) just start accumulating thunks?
14:29:37 <dons> since it is an Int, ghc can see through to the strictness of +#
14:29:48 <monochrom> ghc -O0 will thunk it.
14:29:52 <dons> which works for nice atomic types like Word, Int, etc.
14:29:58 <dons> but relies on -fstrictness
14:29:58 <monochrom> @quote thunk
14:30:00 <ddarius> I'm saying semantically go is strict whereas that foldl' is not strict in the components of the pair without those bangs.
14:30:28 <dons> right. foldl' is kinda broken :)
14:30:37 <ddarius> dons: How so?
14:30:38 <dons> we need foldl_rnf
14:30:55 <dons> its only whnf strict in the accumulator, partially, which confuses people
14:31:00 <ddarius> Blech, we need a library of strict types (which we have now, no?)
14:31:04 <dons> right.
14:31:11 <dons> cabal install strict , peoples!
14:31:20 <dons> probably should be in base though, with more access to the NF class
14:31:33 <ddarius> It should only reduce to whnf.  rnf is almost certainly way too much.
14:31:58 <dons> yeah, it'd be interesting to think about what it would take to get (Int,Int) into (# Int#, Int# ) in an accumulator
14:32:14 <monochrom> superfoldl' :: NFData b => (b -> a -> b) -> b -> [a] -> b  :)
14:32:16 <dons> rnf would work, but could whnf + a bit of the nested CPR analysis (or something like it)
14:32:35 <dons> really, folds are great if you can use tuples to describe register variable layout
14:33:00 * dons thinks we understand what ghc does a lot more than 5 years ago
14:33:14 <ddarius> rnf would turn foldl' (flip (:)) [] from O(n) into O(n^2)
14:33:33 * SamB defines instead a function streamSteps which returns the coq equivalent of [Maybe a] (with a co-inductive list type)
14:33:55 <dons> SamB: oh, you should check Jeremy gibbons paper with the correctness proof for streams
14:34:01 <dons> formalising that would be an awesome HW paper...
14:34:08 <dons> or mechanising metatheorey
14:34:26 <dons> you could write it with swiert
14:34:32 <dons> he's done a few coq papers, iirc
14:35:35 <dons> SamB: http://www.comlab.ox.ac.uk/jeremy.gibbons/publications/adt.pdf
14:35:35 <SamB> heh
14:36:02 <dons> seriously, proving some nice thinks about the stream-fusion combinators would be an ICFP worthy paper
14:36:44 <SamB> I mean ... like I have time to actually write a paper!
14:36:47 <SamB> I've got classes
14:37:03 <dons> well, do the proofs, i'll help you write the paper :)
14:37:13 * dons loves how academia works
14:38:04 <SamB> hmm, nice hint here...
14:38:22 <SamB> two types are different if there is an experiment that shows this, and not different otherwise
14:38:25 <SamB> er.
14:38:27 <SamB> values.
14:39:19 <dcoutts> observational equality
14:39:53 <SamB> yes, but the key there is that I should define inequality inductively, and simply define equality as the negation
14:40:25 <dons> jeremy's paper is quite nice. i should reread it every 6 months till i remember the approach
14:41:16 <dons> dcoutts: was jeremy's paper published in the end?
14:41:33 <dcoutts> dons: not at ICFP last summer, perhaps elsewhere
14:41:46 <dons> its the kind of thing we want to integrate into the jfp stuff
14:41:52 <monochrom> Nice, it begins with "Dijkstra". :)
14:42:01 <dons> that, and janis' two papers that cover streams
14:42:39 <dons> and the constructor specialisation paper. and now also the story for SAT in ghc, and nested CPR
14:42:47 <dons> fills out the performance story, and the correctness story
14:43:10 <dons> we can end the paper with one of those little QED boxes. []
14:43:14 <dcoutts> dons: yes I need to re-read it for one of my thesis chapters
14:43:57 <dons> dcoutts: http://scholar.google.com/scholar?hl=en&lr=&safe=off&cites=8061486271207904370
14:44:22 <dons> crikey, we got cited in a javascript paper..
14:44:45 <dcoutts> heh heh
14:44:51 <SamB> isn't that good?
14:44:53 <dons> dcoutts, "Putting declarative programming into the web: translating curry to javascript"
14:44:58 <dons> well, so it is a haskell guy.
14:45:30 <monochrom> http://www.comlab.ox.ac.uk/jeremy.gibbons/publications/#adt  says "submitted for publication, January 2008" but it doesn't say where and what is happening.
14:46:06 * monochrom personally prefers links like that to going straight to the pdf.
14:46:20 <dons> jan 08, ok. so that's something new.
14:46:29 <SamB> monochrom: me too
14:47:14 <dcoutts> dons: I'll have to find out since I'll be citing it
14:47:18 <monochrom> My heuristic guesses that it is submitted to something like Formal Aspects of Computing due to the long time between submission and hearing back. :)
14:47:39 <BONUS> ugh i still can't decide whether to buy Programming in Haskell or not :[
14:48:31 <dcoutts> BONUS: let me help you: yes. :-)
14:48:45 <dcoutts> BONUS: did you read my review?
14:50:04 * ddarius has inadvertently stumbled over an answer to his lollimon syntax question.
14:50:07 <BONUS> no i didnt
14:50:32 <BONUS> i kind of heard that it's good but very, er, beginner-ish
14:50:48 <BONUS> and i already know all the beginner stuff and some intermediate stuff
14:51:20 <ddarius> Get Algebra of Programming
14:51:25 <dcoutts> BONUS: http://www.cs.nott.ac.uk/~gmh/coutts.pdf
14:51:26 <monochrom> Haha
14:51:48 <BONUS> thanks i'll read that
14:51:48 <BONUS> hmm
14:52:20 <BONUS> dcoutts what did you use to typeset this?
14:52:45 <dcoutts> BONUS: latex with The Monad.Reader style sheet
14:53:14 <BONUS> yeah i thought it was latex but it looks more awesome hehe
14:53:17 <dons> docon is still compiling..
14:53:24 <BONUS> what's the documentclass used
14:53:47 <dcoutts> BONUS: yeah it's nice, check The Monad.Reader advise for authors, it's got all the stuff
14:53:53 <dons> this thing is amazing, Igloo , [67 of 83] after an hour.
14:53:53 <dcoutts> advise/advice
14:54:13 <BONUS> kewl
14:54:13 <dcoutts> dons: heh heh
14:54:21 <dcoutts> dons: at -O2 right?
14:54:41 <dcoutts> dons: clearly we need parallel build in Cabal
14:54:47 <dons> dcoutts: yeah. -O2
14:55:10 <dons> serge's done an awful lot of work here. docon is one of the most underappreciated large haskell systems
14:55:22 * dcoutts wastes 3/4 cores, 3/4 of the time
14:55:30 <dcoutts> dons: yes, he's terrible at publicity :-)
14:55:34 <Lycurgus> on what kind of CPU?
14:55:35 <dons> hey, reminds me, i wonder if my fibonacci primes is still running
14:56:03 <dons> aweseoe, 275432.58835s         34 prime=104911
14:56:17 <Lycurgus> (i.e the docon compile)
14:56:29 <dons> i've been borrowing 3 cores on a server for a week now.
14:56:42 <dcoutts> I bet it's warm
14:57:03 <dons> well, we just have to get to prime 40 for new results.
14:58:16 <dcoutts> dons: is that CPU seconds or real seconds?
14:58:24 <dcoutts> dons: ie 3 CPU days or 1 real day?
14:59:03 <dcoutts> dons: and the time doubles for each one right?
14:59:09 <dons> roughly doubles, yep.
14:59:40 <dons> its this program , with a few custom dons(TM) tweaks,
14:59:40 <dons> http://haskell.org/haskellwiki/Fibonacci_primes_in_parallel
14:59:44 <dcoutts> dons: so you're looking at ~64 days for 40
14:59:48 <dons> the most useful program with `par` in it i've seen so far.
15:00:03 <dons> hey, that's not too bad. the guy i'm competing against had 3.5 years to get to 37
15:00:11 <dcoutts> ooh
15:01:15 <dons> http://www.gristle.to/markup/primes/ppfibs.html
15:01:33 <dons> actually, he says, "34.  fibonacci (104911) is probably prime "
15:01:44 <dons> so i think that means he found a bug in his program, and had to start over.
15:02:26 <shepheb> if I want to fiddle with 6.9 on x86 Linux 32bit, should I grab the HEAD? Is there a way to check if there are any recent nightly builds that worked on my platform?
15:03:25 <hpaste>  Twinside pasted "(no title)" at http://hpaste.org/8036
15:03:38 <Twinside> why ghc give me an error when i put a type signature which is the same that the inferred one?
15:08:15 <MyCatVerbs> Twinside: that sounds strange. hpaste the code and the error, please?
15:08:38 <Twinside>  http://hpaste.org/8036 :)
15:09:28 <BONUS> what does fix do
15:10:16 <dons> recursion
15:10:18 <dons> ?src fix
15:10:35 <dons> lambdabot's not a happy person of late
15:10:40 <BONUS> haha
15:10:50 <MyCatVerbs> BONUS: fix f = f (fix f)
15:10:52 <BONUS> i was looking for it in the 98 report but its not in there
15:10:57 <BONUS> ah
15:11:06 <MyCatVerbs> BONUS: builds an infinite chain of f (f (f (f (f (f...
15:11:10 <BONUS> whats the practical use
15:11:19 <MyCatVerbs> BONUS: none whatsoever.
15:11:25 <MedeaMelana> That's not true
15:11:30 <MyCatVerbs> BONUS: just another way of writing recursions.
15:11:40 <MedeaMelana> Though don't ask me for a good example
15:11:43 <BONUS> ah
15:11:44 <BONUS> haha
15:12:01 <MyCatVerbs> For example, repeat a = fix (a:), equivalent to repeat a = a : repeat a.
15:12:16 <MyCatVerbs> Which expands to a:(a:(a:(a:(... etc.
15:12:33 <MyCatVerbs> Twinside: I have noooo idea. That is making me scratch my head.
15:12:40 <Twinside> yeah me too
15:12:49 <Twinside> if I remove the type signature, it compile just fine
15:13:24 <dons> does it assume -fglasgow-exts perhaps?
15:13:36 <Twinside> yep
15:13:45 <Twinside> i've got the extensions enabled
15:13:58 <BONUS> @src filterM
15:14:02 <monochrom> BONUS: http://www.vex.net/~trebla/haskell/fix.xhtml  "you could have invented fix too"
15:14:10 <BONUS> haha
15:14:11 <BONUS> cool
15:14:56 <monochrom> When you're tired of "let" and "where", and you still need recursion, consider "fix".
15:16:27 <MyCatVerbs> :t let hork f g = f (hork g f) in hork -- I think I actually used this once, but then later came to my senses.
15:16:38 <MyCatVerbs> Oh blast, damnation and \bot.
15:16:41 <BONUS> lol
15:17:10 <BONUS> haha i read the you could have invented monads too article
15:17:13 <BONUS> and i was thinking to myself
15:17:21 <BONUS> no way, i probably wasn't even born when they were invented wtf
15:22:10 <gwern> BONUS: in a counterfactual universe you could have!
15:22:37 <ddarius> BONUS: Well I believe they were first invented/discovered in the 1960s
15:23:07 <BONUS> hm wow
15:23:15 <BONUS> how old is haskell again?
15:23:33 <gwern> 15 years or so
15:23:59 <BONUS> ah well at least i'm older than haskell then
15:25:24 <BONUS> hehe http://en.wikipedia.org/wiki/Timeline_of_programming_languages
15:25:34 <BONUS> it looks like i'm as old as perl (1987)
15:27:03 * dons is going to wikify answers to any questions on the mailing list now.
15:27:07 <ddarius> BONUS: 1987 was when Haskell first started being formulated. 1989 is when the Haskell 1.0 Report was made.
15:27:46 <BONUS> ah
15:27:47 <BONUS> awesome :D
15:28:04 <ddarius> So Haskell is going on 20.
15:28:05 <gwern> dons: a valiant goal, but google taught us that having answers is not the problem, but finding them
15:28:24 <dons> gwern: right. refactoring will help here
15:28:32 <dons> i think this approach has worked well for xmonad
15:28:43 <dons> its just time and tenacity
15:29:03 <andyjgill> Should all new packages use the Cabal 1.2 syntax for the .cabal file?
15:29:16 <andyjgill> What is recommended?
15:29:18 <dcoutts> andyjgill: if you want the new features, yes.
15:29:38 <andyjgill> What are the requirements? 6.8.2+?
15:29:40 <dcoutts> andyjgill: if your package is trivial it doesn't really matter, we're not going to kill off the old syntax any time soon
15:30:16 <dcoutts> andyjgill: Cabal-1.2 was bundled with ghc-6.8.x if that's what you mean, one can of course install it for any version of ghc since 6.2
15:30:17 <dons> we've a wiki page with the old and new library deps
15:30:38 <dons> andyjgill: http://www.haskell.org/haskellwiki/Upgrading_packages
15:30:52 <andyjgill> great.
15:31:58 <andyjgill> I think we'll just use cabal-1.2 syntax. It seems cleaner. Any issues to want for?
15:32:50 <andyjgill> want=>watch
15:32:57 <dcoutts> andyjgill: ahh :-) no, not really
15:33:12 <dons> just checking that you get any lib dependencies correct
15:33:19 <dcoutts> andyjgill: except that older cabal will not understand it at all (no helpful error message)
15:33:29 <andyjgill> Thanks!
15:33:51 <dcoutts> dons: that's upgrading ghc-6.8, not cabal
15:34:00 <andyjgill> What is *build-type*?
15:34:08 <dcoutts> andyjgill: usually Simple
15:34:20 <dons> or Configure if you run a configure script
15:34:27 <dcoutts> andyjgill: unless you need a custom Setup.hs or ./configure script
15:34:42 <andyjgill> Ahh. okay.
15:35:04 <dcoutts> or *shudder* make
15:35:39 <dons> but no one is that crazy, dcoutts
15:35:42 * dcoutts notes that out of the 1 cabal packages on hackage that use the Make build-type, 0 get it correct
15:36:04 <dons> heh. that's a pretty poor percent
15:36:14 <dons> just remove the Make option?
15:36:45 <dcoutts> it's because if you use Make you essentially have to implement your own Haskell build system from scratch
15:37:07 <dcoutts> so you end up ignoring many of the build flags/options that users expect
15:37:11 <dons> wow, docon is really really stressing ghc. its not allocating a lot of memory, but it is now taking 10-20 minutes per module
15:37:42 * dons takes this as a sign that serge has done something interesting
15:37:51 <dcoutts> dons: wx uses it and it needs some fairly complex build stuff
15:38:10 <mm_freak> i'd like to write an MPD frontend using Gtk2hs and Network.MPD, but i can't figure out, how to keep the connection open for the program's lifetime, while allowing it to change  should i use concurrency?
15:38:33 <dons> mm_freak: a process handle and a reader forkIO thread would work.
15:38:52 <dons> mm_freak: see hmp3, perhaps, which talks to mpg321 over a channel, via a concurrent thread
15:39:05 <mm_freak> dons: i used to use Chan for such things
15:39:26 <dons> yeah, that's a good way. you just have a reader or writer thread communicating with the main program over a lazy chan
15:39:39 <mm_freak> ok, thanks
15:39:56 <dcoutts> mm_freak: that's a reasonable idea, use a Chan and that way you can switch network connection without the reader end of the Chan noticing
15:40:32 <dcoutts> mm_freak: you can just kill off the old writer that was connected to the old network channel and fire up a new one to read from the new connection and keep writing into the Chan
15:41:02 <dcoutts> or did I misunderstand the problem?
15:41:20 <mm_freak> yes, that was my initial idea  it's just the monadic interface to MPD, which confused me
15:41:31 <mm_freak> i'm used to handles and functions on them
15:46:10 <mm_freak> seeing that MPD is a MonadIO, is there a better way to do it?  or is that only useful, when the main part of the program consists of MPD actions and IO is only used for some output messages?
15:47:01 <dcoutts> mm_freak: so does MPD only handle output or also input from the network?
15:47:43 <mm_freak> dcoutts: everything
15:47:59 <mm_freak> inside the MPD monad, you can get song info and stuff, add songs, etc.
15:48:24 <dcoutts> mm_freak: hmm, so how do you tell it what channel to use?
15:48:38 <dcoutts> channel/connection whatever
15:49:18 <mm_freak> dcoutts: using withMPDEx, which you give connection informations and an action to run on that connection
15:49:32 <mm_freak> or using withMPD, which is a simple interface to withMPDEx
15:49:45 <dcoutts> mm_freak: so it doesn't let you change connection later
15:49:50 <mm_freak> yes
15:50:37 <mm_freak> there is a 'reconnect' function, but it doesn't allow altering connection info
15:50:47 <dcoutts> ahh
15:51:03 <dcoutts> mm_freak: and that's exactly what you want to do?
15:52:57 <dcoutts> mm_freak: if so, I don't see any obvious workaround, you may just have to change the MPD stuff to be more flexible with the connection handling (either just to allow better reconnects or perhaps letting you manage the input and output separately)
15:53:01 <mm_freak> my question is whether the liftIO is useful at all
15:53:32 <mm_freak> other than for outputting simple status messages
15:54:25 <Saizan> mm_freak: it's useful as much as the IO monad, no?
15:54:40 * SamB wonders why gibbons claims that ordinary ADTs are data, not codata 
15:55:15 <mm_freak> Saizan: in the MPD monad, specifically, but i think i see that i actually need it, at least to read from the channel
15:55:33 <mm_freak> otherwise i'd need to close the connection to do it
15:56:44 <Saizan> yeah, that was what i meant
15:57:11 <dcoutts> SamB: hmm? I thought he does say ADTs are codata. In the abstract and intro.
15:57:36 <SamB> dcoutts: section 3
15:57:36 <dcoutts> SamB: which page are you looking at?
15:58:32 <SamB> "as opposed to the ordinary data inhabiting the more familiar algebraic datatypes introduced by constructions such as Haskell's data declaration
16:00:07 <Philippa_> dcoutts: algebraic datatypes are both in Haskell, but not in strict languages
16:00:27 <Philippa_> SamB: the distinction is essentially that codata is coalgebraic
16:01:07 <dcoutts> Philippa_: yes, and he does mention that on the following page
16:01:26 <SamB> he "as opposed to" implies the negation of "haskell data declarations declare codata"
16:01:28 <Philippa_> SamB: there's this "coincidence" whereby in CPO, initial algebras and final coalgebras are isomorphic
16:02:26 <Philippa_> really it's that haskell's not an ideal choice of example language, that's all
16:03:20 <dcoutts> SamB: he makes that point in the following paragraph
16:03:51 <SamB> he could never get away with this in a formal proof
16:04:14 <Philippa_> he's not presenting something formal
16:04:26 <SamB> yes, it's easy to tell because he wrote it in english ;-)
16:04:48 <Philippa_> no. The thing being presented with english around it /itself/ is not formal
16:05:12 <SamB> what "thing" is that?
16:05:48 <Philippa_> a slightly handwavy notion of 'codata', in the same sense that many people in here have a slightly handwavy notion of 'data' that makes no reference to initial algebras
16:06:15 <Philippa_> and a similarly handwavy encoding into haskell
16:06:16 <dcoutts> SamB: it's an illustration, haskell data is normally intended as data, not co-data
16:06:42 <Philippa_> right. Half the point is "here is an idea, anyone else fancy playing with it?"
16:06:48 <SamB> > cycle "orly"
16:07:04 <SamB> where did lambdabot go???
16:07:28 <jleedev> @seen lambdabot
16:07:32 <SamB> hahaha
16:13:20 <SamB> hmm, very frustrating not being able to convert the streams back to lists :-(...
16:15:55 <dcoutts> SamB: ?
16:16:06 <SamB> I'm not allowed to do that
16:16:13 <ddarius> SamB: data isn't codata, that's the nature of the beast.
16:16:23 <SamB> since it would not have productivity guarentees
16:16:34 <SamB> even with lists as codata
16:16:48 <dcoutts> oh it's just because one is a bigger type than the other
16:17:09 <dcoutts> you have to restrict yourself to the list subset of Stream
16:17:31 <dcoutts> or at least to respecting the equivalences classes in Stream that we map to list
16:18:01 <SamB> I don't have a clue how to convince Coq that I'm doing that ;-)
16:18:20 <dcoutts> hmm, can you define the equivalence classes precisely?
16:18:43 <dcoutts> so there are two problems, co-data to data
16:18:51 <SamB> that isn't it
16:18:55 <dcoutts> and mapping back into a type without Skip
16:19:02 <SamB> that IS it
16:19:18 <dcoutts> and you're working in a system without _|_ too right?
16:19:25 <SamB> indeed
16:19:27 * ddarius should be able to parse anything LolliMon parses now...
16:19:31 <dcoutts> since of course lack of progress is just _|_
16:19:54 <dcoutts> SamB: so you need to guarantee you're not in the pre-image of _|_ in List
16:20:09 <SamB> I don't know how to do that either ;-)
16:20:13 <dcoutts> there's the equivalence class in Stream that is mapped to _|_
16:20:17 <dcoutts> define it, prove you're not in it
16:20:32 <dcoutts> basically no infinite sequences of Skip
16:20:55 <SamB> yeah
16:20:59 <SamB> hmm.
16:21:15 <SamB> I guess that could actually help me get where I want to go.
16:21:50 <dcoutts> so whenever you make one you have to prove that if you're using Skip that you don't keep making more
16:22:13 <SamB> but right now I'd like to define an equality relation that I can prove all three properties for ;-)
16:22:36 <mm_freak> @src undefined
16:22:46 <mm_freak> @src error
16:22:54 <dolio> undefined = error "Prelude.undefined" or something like that.
16:23:02 <mm_freak> > "I am here" :: String
16:23:07 <dcoutts> na, undefined = undefined :-)
16:23:07 <mm_freak> hmm
16:23:16 <dolio> > undefined
16:23:37 <SamB> dolio: it looks like lambdabot decided to just not terminate this time around?
16:23:40 * SamB teases dolio 
16:23:42 <dolio> The error message disagrees with you, I think. :)
16:23:42 <mm_freak> how does 'error' work?
16:24:05 <dolio> Magic.
16:24:19 <SamB> mm_freak: it depends on whether or not you import Control.Exception
16:24:19 <mm_freak> certainly, but what kind of magic?  unsafe magic?
16:24:35 <kadir> hello
16:24:39 <kadir> getSelection :: MonadIO m => m String
16:24:44 <SamB> if you don't, it doesn't really matter...
16:24:48 <kadir> how to get String here
16:24:53 <monochrom> mm_freak: I think you could elaborate your question.
16:24:58 <dolio> It's probably hard wired to the runtime system or something. Although semantically you could write it as 'error s = error s' or any number of other things.
16:24:59 <SamB> if you do, it raises an exception ;-)
16:25:21 <mm_freak> yes, it drops me back to the IO monad, even from pure functions
16:25:25 <mm_freak> that's what confuses me
16:25:37 <SamB> mm_freak: because catching it is not pure
16:25:45 <dcoutts> mm_freak: it's wired in to the rts, in yhc it terminates the prog, in ghc it raises an exception
16:26:08 <mm_freak> ok
16:26:14 <dcoutts> or maybe yhc uses exceptions now, in nhc98 it terminates the prog
16:26:37 <mm_freak> so i shouldn't assume any particular implementation in "error"
16:27:13 <dcoutts> mm_freak: not if you can help it
16:27:19 <mm_freak> like a bottom value for errors
16:27:32 <dcoutts> semantically it is bottom
16:27:38 <mm_freak> ok, thanks
16:29:02 <conal> mm_freak: the reason error handling is handled in IO, is that the semantics of pure values (including functions) is too simple to capture exceptions.  IO has intractable semantics anyway, so exceptions etc are dumped there (the "sin bin").
16:29:59 <mm_freak> conal, SamB: thank you, but that wasn't the source of my confusion  it's just that my understanding is that you can't throw exceptions in pure functions
16:30:12 <SamB> mm_freak: but you can
16:30:15 <augur> tuples are like lists right?
16:30:23 <mm_freak> augur: no
16:30:23 <SamB> there's nothing impure about that
16:30:26 <augur> no?
16:30:29 <conal> augur: yes & no
16:30:32 <SamB> augur: only in Python
16:30:34 <augur> well
16:30:38 <augur> well what i mean is
16:30:42 <augur> they can take any value
16:30:45 <newsham> mmm python
16:30:48 <augur> but only if they're all the same type right?
16:30:52 <mm_freak> augur: they can be heterogenous and have a fixed length
16:30:55 <newsham> > ("test", 23)
16:30:59 <augur> oh i see.
16:31:07 <newsham> ?bot
16:31:09 <lament> augur: they're the same as tuples in math.
16:31:23 <ddarius> Curses!
16:32:31 <kadir> i couldn't find any way to grab String from a monadic one
16:32:33 <mm_freak> @src throw
16:32:35 <mm_freak> oh
16:32:43 <mm_freak> what's wrong with lambdabot ?
16:32:52 <newsham> ?bot temporary
16:32:52 <noBotE> :)
16:32:55 <kadir> could i ask for help?
16:33:13 <newsham> kadir: you could
16:33:48 <mm_freak> SamB: true, then it drops me back to IO, but how is 'throw' implemented?
16:33:57 <kadir>  getSelection :: MonadIO m => m String
16:34:01 <mm_freak> does it need to use a special language feature?
16:34:04 <SamB> mm_freak: magic!
16:34:09 <mm_freak> ok
16:34:11 <kadir> i want String here :)
16:34:20 <kadir> but can't do
16:34:36 <mm_freak> kadir: (>>=) or some monad-specific function
16:34:44 <SamB> as in "rts functions"
16:35:09 <mm_freak> SamB: i understand  i just thought that there is no such magic in haskell =)
16:35:47 <mm_freak> if i wanted to write 'myThrow', would there be any way without resorting to 'throw'?
16:35:58 <SamB> not really
16:35:58 <kadir> i want somehow to concat another string to this string if i extract string from the function
16:36:09 <mm_freak> ok
16:36:21 <mm_freak> kadir: what is 'm'?
16:36:29 <kadir> (foo $ getSelection) ++ "bar"
16:36:37 <kadir> couldn't i do this?
16:36:41 <mm_freak> no
16:37:07 <mm_freak> unless foo is a function specific to a particular 'm', which removes the monad
16:37:39 <kadir> of course i trying to write a function exactly you mention to do
16:37:45 <kadir> but i couldn't
16:38:03 <SamB> dcoutts: well I've found a definition which I can prove reflexivity for...
16:38:15 <kadir> Control.Monad.Trans.MonadIO
16:38:23 <kadir> what the 'm' is
16:38:36 <dcoutts> SamB: sounds good
16:38:53 <mm_freak> kadir: you can't, at that general level
16:39:23 <mm_freak> value extraction is an optional feature for some monads  usually by some 'run' or 'eval' function
16:40:25 <SamB> I'm defining the primitive equality in terms of a Coq equivalent of [Maybe a], since I *can* convert streams to those...
16:41:08 <kadir> ohh :( is haskell structred on the big branch: Monad - non-Monad ?
16:41:51 <kadir> i could'nt obtain simply a String created from a monadic function
16:41:57 <mm_freak> kadir: no, but monads are an integral thing to haskell
16:42:37 <mm_freak> you could, either inside of the monad, or with a special function to 'unwrap' the value
16:42:54 <mm_freak> for example, you do it all the time inside the IO monad
16:43:07 <mm_freak> do { args <- getArgs; print args }
16:43:16 <mm_freak> getArgs :: IO [String]
16:44:00 <malebria> YAHT is for people with some experience in programming, right?  What would you recommend for complete begginers in programming?
16:44:01 <kadir> but i want that args to concat with another string outside there
16:44:11 <kadir> isn't that  possbile
16:45:10 <mm_freak> kadir: it is  inside IO =)
16:45:14 <Torment> kadir: do { [string] <- getArgs; print (pureString ++ string) }
16:45:48 <mm_freak> do { args <- getArgs; print (map (++ "blah") args) }
16:46:21 <kadir> could i tell what i want to do?
16:46:50 <mm_freak> sure, maybe that helps
16:46:59 <kadir> i only wanted to add one usefull keybinding in xmonad
16:47:11 <kadir> but couldn't succeed :(
16:47:19 <malebria> Is there a page comparing GHC with other haskell interpreters/compilers?
16:47:23 <kadir> here is keybinding
16:47:31 <kadir>  ((modMask .|. controlMask, xK_b), runInTerm "echo \"" ++  getSelection ++  "\" | vim -")
16:47:38 <ivanm> kadir: you need to use something like M.union
16:48:02 <mm_freak> kadir: maybe you just need to add parentheses
16:48:10 <malebria> As I see everybody using GHC most of the time, I ask myself what are the reasons to use the others.
16:48:18 <mm_freak> runInTerm ("echo" ++  )
16:48:29 <ivanm> kadir: see how they do it here: http://code.haskell.org/XMonadContrib/XMonad/Config/Xfce.hs
16:48:39 <Jedai> kadir: ((modMask .|. controlMask, xK_b), do { sel <- getSelection; runInTerm "echo \"" ++  sel ++  "\" | vim -")
16:48:41 <dons> they have mainly only niche uses now, malebria
16:48:51 <Jedai> kadir: ((modMask .|. controlMask, xK_b), do { sel <- getSelection; runInTerm "echo \"" ++  sel ++  "\" | vim -" } )
16:48:53 <mm_freak> malebria: you should read the homepages for the other compilers/interpreters  they usually compare themselves to GHC
16:49:39 <Jedai> Or something like that, I'm pretty sure there's a simple way to do it anyway
16:49:47 <malebria> I'll take a look..
16:51:55 <kadir> yep, it compiled :) but didn't work :(
16:57:55 <malebria> mm_freak: this is true for nhc98, but I hugs page, I couldn't find such comparision.
16:58:41 <mm_freak> malebria: because Hugs is one of the more frequently used interpreters  people 'just know' the differences, but maybe the FAQ tells you
16:59:12 <ddarius> Parsing D ::= G -o D | D o- G | ... and G ::= D -o G | G o- D | ... where D \subset G is tricky.
16:59:49 * ddarius should probably just postprocess it.
17:02:59 * dcoutts notes that the new cabal-install dep resolver is now not completely unusable
17:03:19 <dcoutts> it no longer decides to re-install the core libs :-)
17:04:25 <monochrom> Oh, haha :)
17:04:32 <dcoutts> (usually, unless it's essential)
17:26:53 <augur> in haskell
17:27:01 <augur> well wait
17:27:03 <augur> i have a bot
17:27:04 <augur> lol
17:27:10 <augur> > [0] == [0]
17:27:12 <noBotE>  True
17:27:19 <augur> [1,2,3] == [1,2,3]
17:27:24 <dmwit> True
17:27:28 <augur> > [1,2,3] == [1,2,3]
17:27:29 <noBotE>  True
17:27:32 <augur> :P
17:27:40 <augur> ok.
17:27:42 <dmwit> Ah dang, I forgot to prepend a space. =)
17:27:47 <idnar> haha
17:27:48 <lament> augur: it's math, dude
17:27:56 <augur> im just making sure. ;P
17:28:18 <mm_freak> > repeat 0 == repeat 0
17:28:30 <noBotE> Terminated
17:28:37 <augur> whoops :P
17:28:48 <augur> > (repeat 0) == (repeat 0)
17:28:54 <mm_freak> the same ;)
17:28:59 <noBotE> Terminated
17:29:01 <augur> is it? i dont know what repeat does ;)
17:29:02 <mm_freak> but takes some time to compare element by element =)
17:29:08 <mm_freak> > repeat 0
17:29:09 <noBotE>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
17:29:12 <augur> O_O
17:29:20 <lament> augur: perhaps it would be profitable to look at the definition of == for lists
17:29:40 <augur> :P
17:29:53 <dmwit> [] == [] = True; (x:xs) == (y:ys) = x == y && xs == ys; _ == _ = False
17:31:04 <augur> ITS LIKE MAGIC
17:31:10 <augur> :P
17:31:19 <dmwit> ?src [] (==)
17:31:19 <noBotE> []     == []     = True
17:31:19 <noBotE> (x:xs) == (y:ys) = x == y && xs == ys
17:31:19 <noBotE> _xs    == _ys    = False
17:31:20 <monochrom> advanced technology
17:31:29 <dmwit> Dang, I didn't have to type it all.
17:31:57 <dmwit> :t (.)
17:31:58 <noBotE> forall b c a. (b -> c) -> (a -> b) -> a -> c
17:32:03 <monochrom> reduce, reuse, recycle
17:32:04 <dmwit> Oh, no Caleskell? =)
17:32:28 <lament> :t map
17:32:29 <noBotE> forall a b. (a -> b) -> [a] -> [b]
17:32:29 <monochrom> lambdabot died. noBotE is a temp intern
17:33:13 <mauke> preflex: seen lambdabot
17:33:13 <preflex>  lambdabot was last seen on #haskell 4 hours, 25 minutes and 56 seconds ago, saying: Corun: You have 1 new message. '/msg lambdabot @messages' to read it.
17:33:48 <dmwit> Whoa, she's actually still in the room.
17:35:10 <dons> Cale: lambdabot needs some love
17:36:36 <monochrom> Haven't seen Cale for a while either.
17:36:50 <monochrom> preflex: seez Cale
17:37:00 <monochrom> preflex: seen Cale
17:37:00 <preflex>  Cale was last seen on #haskell 1 day, 17 hours, 32 minutes and 23 seconds ago, saying: @src (.)
17:38:27 <Twey> @src (.)
17:38:27 <noBotE> (f . g) x = f (g x)
17:38:34 <Twey> Oh, duh.
17:38:55 <monochrom> Cale's (.) is different
17:40:59 <Twey> How?
17:41:37 <idnar> it's fmap
17:42:45 <Cale> aha...
17:42:57 <Cale> need to ghost it.
17:44:25 <monochrom> @bossnack
17:44:31 <lambdabot> :)
17:44:45 <mauke> @quote
17:44:51 <lambdabot> droundy says: With a higher-kinded monad and phantom existential witness types, darcs would be very fun... (not that it isn't already...)
17:45:20 <SamB> ... higher-kinded monad?
17:45:34 <monochrom> I think it's a made-up term.
17:47:17 <monochrom> @users
17:47:17 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
17:47:49 <mauke> :-|
17:49:31 <TomMD> @quote work
17:49:31 <lambdabot> Botje says: unlike bridges, tentacles work just fine in programming
17:49:43 <mm_freak> monochrom: how does Cale's (.) look like?  using arrows?
17:49:51 <monochrom> @src (.)
17:49:52 <lambdabot> (f . g) x = f (g x)
17:49:52 <lambdabot> -- In lambdabot, it's been generalised to:
17:49:52 <lambdabot> (.) = fmap
17:50:06 <monochrom> using Functor
17:50:11 <mm_freak> oh, ok
17:55:46 <mm_freak> > pi
17:55:47 <lambdabot>  3.141592653589793
17:55:53 <mm_freak> > (fmap sin cos) pi
17:55:55 <lambdabot>  -0.8414709848078965
17:56:04 <mm_freak> indeed
17:56:10 <mauke> preflex: calc (sin cos) pi
17:56:11 <preflex>  -0.8414709848078965
17:57:23 <mm_freak> so a function is a Functor, and mapping a function over it means composition
17:57:46 <mauke> yes
17:58:06 <mm_freak> > (+1) . [1,2,3]
17:58:08 <lambdabot>  [2,3,4]
17:59:53 <mm_freak> > map ($ 3) $ (+) . [1,2,3]
17:59:54 <lambdabot>  [4,5,6]
18:02:32 <augustss_> I think using (.)=fmap in lambdabot is a big mistake
18:03:39 <mm_freak> yeah, i agree  it makes things work for lambdabot, which would fail about everywhere else
18:04:07 <dons> Cale, hear that? The fmap / (.) point has been made, now we're just bored of it.
18:04:10 <augustss_> exactly
18:04:21 <mar77a> is it possible to declare infix functions by default?
18:04:27 <dons> and its frustrating when trying to teach things, since :t map and :t (.) don't work.
18:04:42 <mauke> mar77a: symbols are infix, words are prefix
18:04:42 <ivanm> dons: what point is this that's been made?
18:05:16 <dons> that you can define (.) and map differently without heads breaking, I guess
18:05:24 <ivanm> *nod*
18:05:29 <bd_> :t map
18:05:30 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
18:05:39 <SamB_XP> but it works better if you do it in the de-facto standard library rather than in L.hs
18:06:12 <dolio> When will that be happening? :)
18:06:27 <SamB_XP> dolio: dunno!
18:06:36 <ivanm> Haskell'?
18:07:20 <SamB_XP> it seems unlikely
18:07:26 <augustss_> very
18:07:47 <SamB_XP> we really have got to figure out a way to change stuff like this without having to get standards changed first ;-)
18:08:09 <ivanm> why should (.) and map get generalised to fmap anyway?
18:08:39 <mauke> because things should be polymorphic
18:08:42 <SamB_XP> ivanm: well, renaming fmap to map would just revert the seperation
18:09:06 <ivanm> mauke: you mean wrt the data structure as well as the contents?
18:09:17 <newsham> (.)'s definition in math is pretty established
18:09:20 <ivanm> SamB_XP: so map = fmap; fmap = map ? :p
18:09:35 <SamB_XP> ivanm: don't see why not
18:09:37 <bd_> :t (map, fmap, (.))
18:09:39 <lambdabot> forall a b (f :: * -> *) a1 b1 (f1 :: * -> *) a2 b2 (f2 :: * -> *). (Functor f2, Functor f1, Functor f) => ((a -> b) -> f a -> f b, (a1 -> b1) -> f1 a1 -> f1 b1, (a2 -> b2) -> f2 a2 -> f2 b2)
18:09:42 <dolio> There was no fmap in 1.4.
18:09:48 <ivanm> SamB_XP: because that's an infinite loop?
18:09:53 <SamB_XP> :t [map, fmap, (.)]
18:09:55 <lambdabot> forall a b (f :: * -> *). (Functor f) => [(a -> b) -> f a -> f b]
18:10:05 <SamB_XP> ivan: so are a lot of default method implementations
18:10:29 <SamB_XP> if you don't implement one of the documented combinations
18:10:40 <ivanm> you're saying to have them on a per-functor basis?
18:10:49 <ivanm> newsham: are you saying (.) should stay as is?
18:11:58 <mauke> :t [map, fmap, (.), liftA, liftM, (<$>)]
18:12:00 <lambdabot> forall a b (f :: * -> *). (Monad f, Applicative f) => [(a -> b) -> f a -> f b]
18:12:13 <ivanm> liftA? what's that?
18:12:16 <newsham> ivanm: i think it should use the standard mathematical deifnition, yes
18:12:17 <ivanm> @src liftA
18:12:17 <lambdabot> liftA f a = pure f <*> a
18:12:25 <ivanm> newsham: in that case, I agree with you
18:12:41 <newsham> ?src liftA3
18:12:41 <lambdabot> Source not found. Take a stress pill and think things over.
18:13:00 <dolio> @type fmapDefault
18:13:01 <mauke> @src liftA2
18:13:02 <lambdabot> Not in scope: `fmapDefault'
18:13:02 <lambdabot> liftA2 f a b = f <$> a <*> b
18:13:43 <newsham> amusing one uses pure f <*> and the other f <$>
18:14:28 <dolio> I wonder if that's a problem for the idea of subclass defaults...
18:14:48 <dolio> If you never define fmap, how do you choose between the default from Applicative and the default from Traversable?
18:15:04 <dolio> (Or Foldable, whichever it is.)
18:18:15 <SamB_XP> isn't that what class aliases are for?
18:21:10 <dolio> I'm not sure class aliases solve all the same issues.
18:23:28 <dolio> Functor should be a superclass of Applicative and Traversable, and you can define fmap in terms of their operations, so it might be nice to define a default fmap in the subclasses.
18:24:16 <dolio> At least, that's the rationale for subclass defaults. But what if two different unrelated subclasses define defaults for the same thing (even though they should be semantically equal).
18:24:21 <jdrake> I bet you missed this sesame street: http://next-thing.net/wp-content/bert_ernie_smoking.jpg
18:24:53 <monochrom> evil!
18:48:34 <dons> Cale++ good comment on that guy's blog
18:49:08 <dobblego> link?
18:49:19 <dons> http://jartur.l-square.net/2008/05/is-haskell-really-that-great-as-a-programming-language/
18:49:21 <lambdabot> Title: ~~  Blog Archive  Is Haskell really that&#8230; great as a programming languag ..., http://tinyurl.com/5txbup
18:54:57 <roconnor> yes
18:56:19 <roconnor> ah good ol' Cale
18:57:01 <ddarius> It really took you a year, Cale?
18:57:16 <Cale> ddarius: About that, yeah.
18:57:42 <Cale> ddarius: Of course, I had a full courseload at the time, so it's not like the only thing I was doing.
18:58:10 <Cale> But yeah, about a year, before I could really say that I was comfortable with everything.
18:58:13 <ddarius> I figured that was one aspect and also you are coming from a mathematical rather than CS background.
18:58:34 <ddarius> You're comfortable with -everything- now?
18:59:16 <Cale> Heh, well, everything required for *normal* programming in Haskell anyway.
18:59:35 <ddarius> Okay.
18:59:56 * roconnor is uncomfortable is delimited continuations, in particular "control"
19:01:48 <Cale> Yeah, I still haven't really touched delimited continuations.
19:02:02 <ddarius> I haven't used them much, but I understand them.
19:03:00 <roconnor> I've only used continuations to transparently optimize my monad.
19:03:04 <Saizan> it would be good if we there was a simple example of what they are very good for in haskell
19:03:45 <roconnor> Saizan: they are used to do breadth first search in a tree
19:03:53 <roconnor> Saizan: magically
19:04:24 <roconnor> breadth first traversal
19:05:47 <Saizan> ah, yeah, like on the cc-delcont page?
19:06:05 <roconnor> that's what I'm thinking of
19:06:15 <roconnor> I totally didn't follow that code.
19:06:28 <Saizan> same here
19:06:44 <roconnor> someone should rework that example for more clarity
19:07:03 <roconnor> someone who claims to understand delimited continuations.
19:07:24 * roconnor looks around the channel for anyone who claims to understand delimited continuations
19:07:29 * roconnor looks at ddarius 
19:07:30 <dolio> I'm not sure I understand fully that example, but I thought it was cool. :)
19:07:39 <dolio> Which is why I put it in there.
19:07:49 <dolio> The article I got it from had no real explanation.
19:07:50 <OceanSpray> how do I make a tuple into a list?
19:08:09 <roconnor> OceanSpray: how big of a tuple?
19:08:18 <OceanSpray> three
19:08:27 <roconnor> OceanSpray: are all three elements the same type?
19:08:31 <OceanSpray> yes
19:08:32 <mauke> case (1,2,3) of (x,y,z) -> [x,y,z]
19:08:47 <roconnor> \(x,y,z) -> [x,y,z]
19:08:58 <roconnor> > (\(x,y,z) -> [x,y,z]) (1,2,3)
19:09:01 <lambdabot>  [1,2,3]
19:09:05 <OceanSpray> I thought there was a library function for this, but oh well.
19:09:13 <roconnor> > case (1,2,3) of (x,y,z) -> [x,y,z]
19:09:14 <lambdabot>  [1,2,3]
19:09:21 <mm_freak> > concat $ unzip3 [(1,2,3)]
19:09:22 <lambdabot>  Couldn't match expected type `[[a]]'
19:09:23 <roconnor> OceanSpray: it is a pretty rare requirement
19:09:33 <mm_freak> oh
19:09:51 <Saizan> dolio: since it uses only one reset one could rewrite it using the indexed Cont monad?
19:09:59 <roconnor> > unzip3 [(1,2,3)]
19:10:00 <lambdabot>  ([1],[2],[3])
19:10:20 <roconnor> OceanSpray: it kinda makes me think you are doing something wrong
19:10:47 <dolio> Saizan: I don't think any of the examples in that article actually use multiple prompts, do they (I haven't gone back to it in a while)?
19:11:15 <roconnor> wow MLton sounds pretty buff
19:12:06 <Saizan> dolio: it seems they don't, looking at them
19:12:35 <Saizan> dolio: but they use answer type modification, right?
19:13:00 <dolio> I haven't used ContT delimited continuations extensively, so I'm not too up on which examples do and don't work.
19:13:23 <dolio> I seem to recall having trouble with the iterator type stuff.
19:16:55 <Saizan> i was asking since (a -> s) -> r seems a simpler type to approach when learning how they work
19:17:25 <dolio> Possibly. I don't think you can write control using that type, though.
19:17:47 <dolio> So it won't help you understand the breadth-first traversal example. :)
19:18:10 <Saizan> damn :)
19:18:14 <dolio> There are more complicated types that lets you express control, shift0 and control0, though.
19:18:29 <ddarius> roconnor: What's the link?
19:18:41 <dolio> Let me see if I can find the paper that describes them...
19:18:47 <Saizan> http://www.haskell.org/haskellwiki/Library/CC-delcont#Breadth-first_Traversal
19:18:48 <lambdabot> Title: Library/CC-delcont - HaskellWiki, http://tinyurl.com/2q7t9l
19:21:58 <dolio> Saizan: I suspect the paper is Shift to Control. I have somewhat old Haskell implementations of them. I'll paste them...
19:22:47 <Saizan> for undelimited you can write control like this, right? "control f k = f (\a _ -> k a) id"
19:22:52 <hpaste>  dolio pasted "control/prompt" at http://hpaste.org/8038
19:23:26 <hpaste>  dolio annotated "control/prompt" with "shift0/reset0" at http://hpaste.org/8038#a1
19:23:58 <hpaste>  dolio annotated "control/prompt" with "control0/prompt0" at http://hpaste.org/8038#a2
19:24:54 <dolio> That's a different control.
19:25:21 <mm_freak> i've read somewhere that duples are arrows, is that true?
19:26:11 <Saizan> ah, i'm not familiar with such combinators..
19:26:18 <MechaBlue> Hello
19:26:20 <MechaBlue> I'm working with a rather complex arrangement of mutually recursive modules in GHC 6.8.2 and I'm running into cycles.  Is the .hs-boot/{-# SOURCE #-} feature capable of resolving all situations?
19:26:23 <Saizan> mm_freak: you mean (,) ?
19:26:30 <mm_freak> Saizan: yes
19:26:41 <mm_freak> Saizan: oh well, that notation actually answers my question, thank you =)
19:27:07 <Saizan> i don't think that's an arrow
19:27:30 <mm_freak> > pure (2,3)
19:27:31 <lambdabot>   add an instance declaration for (Show (f (t, t1)))
19:27:39 <Saizan> but we often use Control.Arrow to deal with tuples in \bot
19:27:53 <mm_freak> Saizan: yeah, i've seen that
19:28:08 <Saizan> :t arr id :: (,) a a
19:28:10 <lambdabot>     No instance for (Arrow (,))
19:28:10 <lambdabot>       arising from a use of `arr' at <interactive>:1:0-5
19:28:10 <lambdabot>     Possible fix: add an instance declaration for (Arrow (,))
19:29:37 <EvilTerran> ?instances-importing Control.Arrow Arrow
19:29:38 <lambdabot> (->), Kleisli m
19:30:10 <EvilTerran> MechaBlue, i think so, yes
19:33:00 <MechaBlue> Thanks.  I'll keep looking for a solution.
19:39:28 <OceanSpray> is there a map function for tuples?
19:39:41 <dons> nope.
19:39:55 <mauke> :t join (***)
19:40:00 <lambdabot> forall (a :: * -> * -> *) b c. (Arrow a) => a b c -> a (b, b) (c, c)
19:40:09 <dons> you can play tricks with arrow combinators for pairs
19:40:14 <SamB_XP> mauke: that's not right!
19:40:17 <dons> but in general, no.
19:40:34 <dons> ?pl \f (x,y) -> (f x, f y)
19:40:34 <lambdabot> (`ap` snd) . (. fst) . (flip =<< (((.) . (,)) .))
19:40:36 <dons> hah
19:40:37 <SamB_XP> @djinn (a -> b) -> (c -> d) -> (a, c) -> (b, d)
19:40:37 <lambdabot> f a b (c, d) = (a c, b d)
19:40:40 <mauke> > join (***) succ ('n', 'j')
19:40:42 <lambdabot>  ('o','k')
19:40:53 <OceanSpray> huh
19:40:58 <OceanSpray> oh well.
19:41:00 <SamB_XP> you guys suck at maps
19:41:09 <dons> > @djinn (a -> b) -> (a, a) -> (b, b)
19:41:09 <lambdabot>  Parse error at "@djin..." (column 1)
19:41:10 <SamB_XP> the map for pairs takes two functions!
19:41:23 <ivanm> SamB_XP: what, people here aren't good navigators?
19:41:34 <mauke> :t (***)
19:41:36 <lambdabot> forall (a :: * -> * -> *) b c b' c'. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
19:41:55 <SamB_XP> @free (a -> b) -> (c -> d) -> (a, c) -> (b, d)
19:41:55 <lambdabot> Pattern match failure in do expression at Plugin/Free/FreeTheorem.hs:54:20-34
19:42:03 <SamB_XP> @free t : (a -> b) -> (c -> d) -> (a, c) -> (b, d)
19:42:03 <lambdabot> Extra stuff at end of line
19:42:26 <mauke> > join (++) ":"
19:42:27 <lambdabot>  "::"
19:42:31 <Saizan> @free map :: (a -> b) -> (c -> d) -> (a, c) -> (b, d)
19:42:31 <lambdabot> g . p = q . f => k . f1 = f2 . h => $map_Pair g k . map p f1 = map q f2 . $map_Pair f h
19:42:51 <SamB_XP> @let pairMap :: (a -> b) -> (c -> d) -> (a, c) -> (b, d); pairMap f g (x, y) = (f x, g y)
19:42:52 <lambdabot> Defined.
19:43:01 * SamB_XP barely remembered to double up on the colon
19:43:13 <mauke> :t [pairMap, curry (***)]
19:43:15 <lambdabot>     Occurs check: cannot construct the infinite type: b = (b' -> b, b')
19:43:15 <lambdabot>       Expected type: (b' -> b) -> (c' -> d) -> (b', c') -> (b, d)
19:43:15 <lambdabot>       Inferred type: (b' -> b)
19:43:31 <mauke> oh, whoops
19:43:37 <mauke> strike that curry
19:43:38 <SamB_XP> you know... I think I figured out why ML has lists and type-annotations swapped from Haskell
19:43:38 <Saizan> it's already curried
19:44:00 <SamB_XP> @free pairMap
19:44:02 <lambdabot> g . p = q . f => k . f1 = f2 . h => $map_Pair g k . pairMap p f1 = pairMap q f2 . $map_Pair f h
19:44:11 <SamB_XP> w00t
19:44:55 <Saizan> @free map_Pair
19:44:56 <lambdabot> Extra stuff at end of line in retrieved type "Not in scope: `map_Pair'\n\n"
19:45:09 <Saizan> @free $map_Pair
19:45:10 <lambdabot> Pattern match failure in do expression at Plugin/Free/FreeTheorem.hs:54:20-34
19:45:27 <SamB_XP> Saizan: $map_pair is a function it made up
19:45:37 <SamB_XP> er. $map_Pair
19:46:20 <SamB_XP> theorems for free agrees with me about what a map is
19:46:25 <Saizan> yeah, but it's not just a random function, but the map for pairs, no?
19:46:28 <SamB_XP> ;-)
19:46:34 <SamB_XP> Saizan: yeah
19:47:17 * SamB_XP digs paper out of book bag
19:47:35 <Saizan> so i hoped we could just refer to it
19:47:51 <ivanm> SamB_XP: you have a bag just for books?
19:48:00 <ivanm> I suppose you also have a pen bag, pencil bag, etc.?
19:48:02 <ivanm> :p
19:48:43 <TomMD> So you do get humor!
19:49:01 <ivanm> only when I make it up ;-)
19:49:26 <TomMD> Can't fault you for that, else half the world (including my entire family) would be at odds with me.
19:49:34 <ivanm> heh
19:54:00 <MechaBlue> I'm still not able to find a solution for mutually recursive modules.  module A has a class with functions that use type B.  module B has a class with functions that use type A.  Class A is a super class of class B.
19:54:37 <dons> MechaBlue: you know how to create mutually recursive modules?
19:55:08 <MechaBlue> I know the simple {-# SOURCE #-}/.hs-boot way of doing so.
19:56:18 <SamB_XP> what goes wrong?
19:58:58 <MechaBlue> In order to import class A into module B, I need to have the class function type declared.  But to do that, I need to include module B.
19:59:27 <MechaBlue> Module B exports a subclass of module A, which needs its member functions exposed.
20:00:07 <SamB_XP> hmm, if you made B *really* import A I think you could make it work
20:00:20 <mxc> for anyone who's been following my b1tching about records, I realized that using parameterized types to represent the universe of message types pretty much solves the problem
20:00:56 <MechaBlue> A really imports B already.
20:01:24 <SamB_XP> maybe you should actually just ask in #ghc
20:01:38 <SamB_XP> lower traffic, more chance of a wizard noticing your pleas
20:01:42 <hpaste>  obk pasted "Is there a way to avoid the nesting/repetition in this code?" at http://hpaste.org/8039
20:01:49 <MechaBlue> Thanks for the tip :)
20:10:14 <chessguy> g'day folks
20:11:11 <jdrake> hi
20:11:55 <SamB_XP> chessguy: you are either quite late or about 45 minutes early
20:12:26 <chessguy> bah, it's never too late or early to wish people a good day
20:12:41 <SamB_XP> @localtime chessguy
20:12:42 <lambdabot> Local time for chessguy is 2008-06-01 23:12:41 -0400
20:13:03 * chessguy feels violated
20:13:18 <ddarius> lambdabot asked you the time
20:13:24 <SamB_XP> then tell your client to stop responding to CTCP TIME
20:15:05 <SamB_XP> chessguy: and it's not as if I didn't know what time zone you lived in
20:15:33 <chessguy> yeah, but you _exposed_ me
20:15:47 <ddarius> chessguy is full of secrets
20:16:00 <chessguy> anyway, i'm over it now :)
20:16:03 <SamB_XP> weren't you listed on the HaWiki page with the coordinates on it?
20:16:30 <chessguy> uh......no...that was....the other chessguy
20:16:41 * Twey chuckles.
20:16:42 <SamB_XP> what other chessguy?
20:16:47 <chessguy> ummm
20:16:51 <Twey> SamB_XP: The one that isn't this chessguy.
20:16:52 <Twey> :-P
20:16:57 <shachaf> checkersguy?
20:17:03 <chessguy> exactly Twey
20:17:06 <chessguy> i knew i liked you
20:17:09 <dolio> It was cheeseguy.
20:17:10 <Twey> Haha
20:17:43 <chessguy> anyway, this conversation is way too much silliness
20:17:51 <chessguy> @seen dolio
20:17:51 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
20:18:00 <dolio> Hah!
20:19:21 <orbitz> dmwit: feelings == hurt
20:19:35 <chessguy> so, let's talk about some haskell!
20:19:47 <orbitz> chessguy: hai
20:19:56 <orbitz> chessguy: when are you gunna upgrade to being 'goguy'?
20:20:03 <dmwit> orbitz: sorry
20:20:08 * dmwit shrugs
20:20:11 <chessguy> orbitz:  not in your lifetime
20:20:17 <dmwit> I don't really keep track of names that way. =P
20:20:23 <dmwit> s/way/well/
20:20:28 <chessguy> a.k.a., once i solve chess :)
20:20:36 <dolio> There are too many goguys around here already.
20:20:42 <orbitz> chessguy: what's takin you so long?
20:20:58 <chessguy> orbitz:  real life gets in the way too much
20:21:16 <ray> pff
20:21:18 <orbitz> stop irc'ing
20:21:21 <SamB_XP> dmwit: what are you and orbits on about?
20:21:25 <chessguy> if i had a few months solid, i would so destroy that game :)
20:21:25 <ray> if you'd started your computer running chess 10 years ago...
20:21:36 <dmwit> SamB_XP: He's upset because I didn't recognize him in ##c++.
20:21:50 <dmwit> But everyone knows Baptists don't recognize each other in the liquor store. ;-)
20:21:55 <orbitz> http://www.youtube.com/watch?v=nLZdCsP1kT4&hl=en
20:21:56 <lambdabot> Title: YouTube - The Two Coreys: "We're a team! YOU don't have a team!"
20:21:59 <ray> and updated your chess-solving computer regularly
20:22:05 <SamB_XP> orbitz: what were you doing in ##C++?!??! consorting with the enemy?
20:22:15 <orbitz> SamB_XP: destroying it from th einside
20:22:29 <orbitz> SamB_XP: i have been the reason for #haskells large growth in people as i tell everyoen in tehr eto learn it
20:22:31 <dolio> Maybe he was making fun of how terrible their monads are.
20:22:34 <orbitz> what are you doing for the language?
20:22:44 <ray> it's already destroying itself from the inside by being about c++
20:22:58 <SamB_XP> I, uh, ask people what languages they use sometimes ;-)
20:23:15 <SamB_XP> ray: lol
20:23:57 <Zao> orbitz is the resident ##C++ troll/weirdo.
20:23:59 * chessguy wrote unfoldr and unfoldTree in javascript for a code sample for a recruiter the other day :)
20:24:16 <orbitz> it's true i am
20:24:34 <SamB_XP> Zao: is that how you got here?
20:24:54 <Zao> SamB_XP: No.
20:25:28 <Zao> SamB_XP: I had heard about haskell from someone in the department long ago and decided to look it up.
20:26:07 <orbitz> SamB_XP: the real question is, wha its dmwit doing int ##C++?
20:26:14 <gwern> (long ago in the days of yore, / it all began with a god named thor... I have been listening to too much Jonathan Coulton)
20:26:24 <dolio> Buying liquor, apparently.
20:29:37 <ray> technically, didn't it all begin with a frost giant named ymir?
20:31:00 <dolio> There aren't any comic books about that guy.
20:37:40 <bos> @seen dons
20:37:40 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
20:37:51 <ivanm> preflex: seen dons
20:37:51 <preflex>  dons was last seen on #haskell 43 minutes and 14 seconds ago, saying: MechaBlue: you know how to create mutually recursive modules?
20:37:54 <bos> argh!  that's been broken for days
20:37:58 <ivanm> yup :s
20:43:07 <Lycurgus> preflex: version
20:43:07 <preflex>  0.231
20:43:15 <dmwit> preflex: help
20:43:15 <preflex>  try 'help help' or see 'list' for available commands
20:43:56 <dmwit> preflex: nickometer dmwit
20:43:56 <preflex>  dmwit is 0% lame
20:43:59 <dmwit> Sweet!
20:44:22 <ivanm> does _anyone_ have a lame nick according to preflex?
20:44:31 * dmwit shrugs
20:44:33 <dmwit> dunno!
20:44:38 <dmwit> preflex: nickometer ivanm
20:44:38 <preflex>  ivanm is 0% lame
20:44:42 <dmwit> Probably not!
20:44:46 <Zao> preflex: nickometer |Coolhun|
20:44:46 <preflex>  |Coolhun| is 81% lame
20:44:50 <ivanm> @slap dmwit
20:44:51 * lambdabot submits dmwit's email address to a dozen spam lists
20:45:02 <ivanm> ... interesting...
20:45:13 <ivanm> non-alpha == lame?
20:45:18 <Zao> Quite.
20:45:22 <SamB_XP> preflex: nickometer SamB
20:45:23 <preflex>  SamB is 0% lame
20:45:25 <lament> preflex: nickometer @#$*()&@#$(*&
20:45:25 <preflex>  @#$*()&@#$(*& is 99.99256371% lame
20:45:32 <SamB_XP> preflex: nickometer _anywone_
20:45:32 <preflex>  _anywone_ is 26% lame
20:45:32 <ivanm> must bee
20:45:38 <SamB_XP> preflex: nickometer _anyone_
20:45:38 <preflex>  _anyone_ is 26% lame
20:45:42 <ivanm> preflex: nickometer 1337
20:45:43 <preflex>  1337 is 63% lame
20:45:50 <SamB_XP> preflex: nickometer SamB_XP
20:45:50 <preflex>  SamB_XP is 28% lame
20:45:52 <lament> preflex: nickometer a*
20:45:52 <preflex>  a* is 14% lame
20:46:02 <lament> preflex: nickometer a
20:46:02 <preflex>  a is 0% lame
20:46:06 <lament> preflex: nickometer *
20:46:06 <preflex>  * is 14% lame
20:46:16 <SamB_XP> why is SamB_XP lamer than _anyone_
20:46:22 <ivanm> capitals?
20:46:27 <lament> preflex: nickometer A
20:46:27 <preflex>  A is 8% lame
20:46:29 <lament> yep
20:46:31 <ivanm> preflex: nickometer ChanServ
20:46:31 <preflex>  ChanServ is 0% lame
20:46:39 <TomMD> preflex: nickometer TomMD
20:46:39 <preflex>  TomMD is 18% lame
20:46:40 <ivanm> except for ChanServ obviously...
20:46:47 <lament> preflex: nickometer ChanSeRV
20:46:47 <preflex>  ChanSeRV is 98.67% lame
20:46:50 <SamB_XP> @nickometer ADEpt
20:46:50 <lambdabot> Unknown command, try @list
20:46:55 <SamB_XP> preflex: nickometer ADEpt
20:46:56 <preflex>  ADEpt is 27% lame
20:46:57 <lament> preflex: nickometer ChanSerV
20:46:57 <preflex>  ChanSerV is 98.41% lame
20:47:01 <lament> preflex: nickometer ChanServ
20:47:02 <preflex>  ChanServ is 0% lame
20:47:07 <ivanm> odd number of capital letters?
20:47:10 <SamB_XP> preflex: nickometer a11235
20:47:10 <preflex>  a11235 is 73% lame
20:47:15 <ivanm> preflex: nickometer AA
20:47:16 <preflex>  AA is 14% lame
20:47:17 <SamB_XP> preflex: nickometer _MaK_
20:47:17 <preflex>  _MaK_ is 26% lame
20:47:25 <SamB_XP> preflex: nickometer Heffalump
20:47:25 <preflex>  Heffalump is 0% lame
20:47:31 <TomMD> I think it is excepting of camel case
20:47:34 <ivanm> unless ops aren't lame?
20:47:43 <TomMD> preflex: nickometer ThisIsNotLameIsIt
20:47:43 <preflex>  ThisIsNotLameIsIt is 99.978106% lame
20:47:46 <TomMD> or not.
20:47:47 <ivanm> heh
20:47:50 <SamB_XP> Heffalump: change nick to somehing wierd
20:48:09 <lament> preflex: nickometer >>=
20:48:09 <preflex>  >>= is 97.05% lame
20:48:15 <ivanm> mauke: what's the algorithm for the nickometer?
20:48:16 <lament> you've heard it
20:48:30 <edwardk> preflex: nickometer edwardk
20:48:30 <preflex>  edwardk is 0% lame
20:48:36 <edwardk> hah
20:48:36 <Dzlk> preflex: nickometer Dzlk
20:48:36 <preflex>  Dzlk is 0% lame
20:48:39 <Dzlk> preflex: nickometer dzlk
20:48:39 <preflex>  dzlk is 0% lame
20:48:42 <lament> lowercase letters are never lame
20:48:43 <Dzlk> Foo.
20:48:51 <lament> and camelcase caps aren't lame either
20:49:07 <lament> preflex: nickometer 1
20:49:07 <preflex>  1 is 22% lame
20:49:08 <ivanm> lament: nope, TomMD tried camelcase...
20:49:10 <lament> but digits are
20:49:17 <TomMD> preflex: nickometer TomD
20:49:17 <preflex>  TomD is 0% lame
20:49:25 <edwardk> first char uppercase is ok?
20:49:29 <TomMD> Wow, that M earns me 18% lameness.
20:49:32 <lament> preflex: nickometer ChnaServ
20:49:32 <preflex>  ChnaServ is 0% lame
20:49:36 <lament> not ops
20:49:36 <dons> bos: pong?
20:49:42 <mxc> preflex: nickometer preflex
20:49:42 <preflex>  preflex is 0% lame
20:49:48 <dons> ?seen dons
20:49:48 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
20:49:51 <dons> we should fix that.
20:49:55 <TomMD> Some day
20:49:57 <lament> caps in a row are clearly lame
20:50:08 <dons> i think byorgey should write a new bot
20:50:09 <Dzlk> edwardk: Or at least it doesn't have a preference between first-char upper or lower.
20:50:12 <lament> caps are only ok when they start a word, and when there's only two words
20:50:12 <ivanm> dons: and @users
20:50:25 <lament> preflex: nickometer HaHa
20:50:25 <preflex>  HaHa is 0% lame
20:50:28 <lament> preflex: nickometer HaHaHa
20:50:28 <preflex>  HaHaHa is 99.8268% lame
20:50:30 <lament> see
20:50:34 <lament> more than two words = lame
20:50:35 <TomMD> byorgey certainly has enough time - even more free time starting September.
20:50:37 <ivanm> ahhh
20:50:44 <ivanm> TomMD: why? he's being fired? :p
20:50:49 <SamB_XP> it's silly how enormously lame two words is counted as
20:51:02 <Dzlk> preflex: nickometer B1FF
20:51:02 <preflex>  B1FF is 56% lame
20:51:05 <SamB_XP> er.
20:51:06 <SamB_XP> 3
20:51:07 <TomMD> Starting a trival program often abbreviated "PhD"
20:51:13 <ivanm> ahhh
20:51:15 <ivanm> that thingy
20:51:18 <lament> SamB_XP: having three camelcased words in your nick is definitely lame
20:51:20 <SamB_XP> Tomas: trival?
20:51:30 <SamB_XP> lambdabot: yes but 99% lame?
20:51:31 <dons> lambdabot is a 3 year program
20:51:37 <TomMD> Oh sorry, I forget to close brackets... </sarcasm>
20:51:46 <ivanm> TomMD: when did you open them?
20:52:06 <TomMD> When I was born someone placed them right after the <life> tag.
20:52:19 <ivanm> ahhh
20:52:32 <ivanm> does this mean you won't be sarcastic ever again? :o
20:53:00 <TomMD> Depends how buggy the parser is, doesn't it?
20:53:21 <Pseudonym> preflex: nickometer Pseudonym
20:53:21 <preflex>  Pseudonym is 0% lame
20:53:25 <Pseudonym> Woo.
20:53:36 <ivanm> TomMD: heh
20:53:53 * ivanm gives TomMD a new <sarcasm> tag
20:53:59 <lambdabot> preflex is 110% lame
20:54:09 <ivanm> lol
20:54:31 <Dzlk> preflex: nickometer camelCase
20:54:31 <preflex>  camelCase is 18% lame
20:54:35 <Dzlk> Hm!
20:54:39 <TomMD> but is lambdabot still 110% broken?
20:54:43 <TomMD> @seen TomMD
20:54:44 <lambdabot> Plugin `seen' failed with: too few bytes. Failed reading at byte position 8
20:55:11 <SamB_XP> TomMD: ... are you an SGML document or an XML document?
20:55:13 <dons> so there are some lessons to take away from lambdabot's current state of disrepair
20:55:23 <dons> build it around a rock solid serialisation framework, for one..
20:55:24 <Pseudonym> Can never get enough bytes when you need them.
20:55:31 <shachaf> nickometer shachaf
20:55:45 <shachaf> preflex: nickometer shachaf
20:55:45 <preflex>  shachaf is 0% lame
20:55:51 <SamB_XP> in other words ... do you believe in reincarnation ;-P
20:55:57 <vininim> preflex: nickometer vininim
20:55:57 <preflex>  vininim is 0% lame
20:56:04 * Pseudonym laughs... rock solid serialisation framework... you kill me
20:56:07 <TomMD> dons: I thought I saw a 'maybe' wrapper for Data.Binary - perhaps that would be useful.  I don't think the strictness will hurt.
20:56:14 <vininim> I wonder what I have to do to get win this lameness battle. =P
20:56:14 <Korollary> This nickometer business is the devil's work.
20:56:25 <SamB_XP> Pseudonym: that was what he was suggesting should be done
20:56:27 <Pseudonym> preflex: nickometer devil
20:56:27 <preflex>  devil is 0% lame
20:56:33 <dons> TomMD: there's strict-binary
20:56:40 <Saizan> maybe HAppS-State could help?
20:56:55 <Dzlk> How orthogonal is lambdabot itself from the IRC protocol stuff?
20:57:16 <SamB_XP> hehe
20:57:42 <Twey> Dzlk: Completely, there's a package
20:57:47 <Pseudonym> Serialisation: Robust, easy to use, framework.  Pick at most two.
20:57:47 <Twey> Er
20:57:53 <Twey> For an interpreter
20:58:27 <SamB_XP> Twey: you mean GOA?
20:58:29 <mxc> oh uh, pseudonym, them's fightin' words
20:58:47 <SamB_XP> mxc: he'd hardly be unhappy to be proven wrong
20:58:53 <Pseudonym> Indeed.
20:59:06 <ddarius> That's easy.  Robust and easy to use.
20:59:19 <mxc> Data.Binary is pretty decent
20:59:20 <Pseudonym> Then you want ASN.1, surely?
20:59:32 <Twey> http://haskell.org/haskellwiki/Lambdabot
20:59:33 <lambdabot> Title: Lambdabot - HaskellWiki
20:59:38 * SamB_XP is wondering how you get robust and easy to use without framework
20:59:47 <Dzlk> Er, well, specifically I wondered how hard it'd be to make it speak XMPP. I've got all the pieces to do it but haven't really dug into the lambdabot code.
20:59:47 <Korollary> Serialization is so boring. Parallelization is the shiznit.
20:59:48 <mxc> my only issue wit it is that its not integrated into the language like ocaml marshalling and you have to do a little bit of work
20:59:49 <bd_> Pseudonym: not very robust against schema changes, is it?
21:00:03 <bd_> mxc: there's Data.Derive
21:00:09 <Twey> Dzlk: It's pretty decoupled.
21:00:12 <Pseudonym> bd_: Sure it is, if you design your protocol correctly.
21:00:16 <Pseudonym> But your point is taken.
21:00:28 <bd_> Pseudonym: so is Data.Binary then :P
21:00:59 <mxc> bd_ ok then my complaint is that I dont understand template haskell yet
21:01:09 <mxc> which is more of a complaint about myself
21:01:16 <bd_> Data.Derive isn't TH, I don't think, is it?
21:01:22 <bd_> it's just a preprocessor
21:01:31 <Dzlk> Cool. Now all I need is some spare time...  ngh. :)
21:01:35 <bd_> oh, it might use TH internally
21:01:42 <Saizan> bd_: it's both
21:02:00 <mxc> how does it compare with DrIFT?
21:02:02 <Saizan> bd_: you can use the preprocessor or use the macro directly
21:02:14 <SamB_XP> it doesn't REQUIRE that TH be actually supported by your compiler
21:02:23 <SamB_XP> depending on how you use it
21:02:26 <bd_> so no need to know TH to *use* it, right? :)
21:02:44 <Saizan> no, unless you want to write a new derivation
21:07:36 <ddarius> "Under this view, we will give one of the subgoals, say G1, the whole linear context ; it will consume part of it and return the remaining portion 2 to be used by G2."
21:07:46 <ddarius> That was a bit underwhelming.
21:08:14 * Twey sneezes.
21:08:32 <Twey> Oh... I get it now.
21:08:32 <edwardk> Sorry, unrelated question, but there doesn't appear to be an f# community online (at this hour?). Does anyone know if there is any support at all for rank-n (even rank-2) types in F#?
21:08:41 <Twey> Had to read that about three times.  Heh
21:08:43 <edwardk> I can't seem to find anything which leads me to believe the answer is no.
21:10:26 <Korollary> post a negative assertion to reddit and jdh30 will instantly correct it if it's the case.
21:10:36 <edwardk> lol
21:10:40 <dolio> Hahaha.
21:10:49 <Dzlk> jdh30 = John Harrop?
21:11:03 <dolio> You don't need rank-2 types for commercial development, so it doesn't matter anyway.
21:11:09 <edwardk> heh
21:11:11 <sjanssen> Dzlk: yep
21:11:17 <sjanssen> he was actually in #haskell earlier today
21:11:30 <ivanm> what, everyone knew who JohnHarrop was, so he got a new nick?
21:12:19 <edwardk> anyways the lack of it is making me sad. i'd hoped to port some category theory to f#. without rank-2 thats kinda hard.
21:13:26 <thomashartman1> sudo cabal install plugins
21:13:27 <thomashartman1> [sudo] password for thartman:
21:13:27 <thomashartman1> cabal: Unresolved dependencies: plugins -any
21:13:38 <thomashartman1> how come it didn't pick up the plugins package on hackage?
21:13:43 <thomashartman1> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/plugins
21:13:45 <lambdabot> http://tinyurl.com/5mbt3u
21:14:50 <Saizan> thomashartman1: did you cabal update ?
21:15:19 <vininim> off-topic: anyone know latex tool(or something like graphviz) for making diagrams of network packets formats? =P
21:15:23 <dons> puzzle for someone , http://reddit.com/r/programming/info/6lnnp/comments/c047dpf
21:15:36 <dons> a bit of ugly code sam lee's asking to have cleaned up
21:17:11 <TSC> "... where a (+++) b = (a + b) `mod` m"
21:17:16 <TSC> seems like the way to go
21:17:17 <edwardk> yeah
21:17:46 <TSC> Then the rest is a fold
21:17:49 <thomashartman1> he could have also pattern matched on xs
21:18:00 <bd_> nerf xs m = foldl1' (\x y -> (x + y) `mod` m) xs
21:18:08 <Saizan> can't you just mod at the end?
21:18:08 <ivanm> dons: first of all, wouldn't it be easier to pattern match rather than use a case?
21:18:12 <bd_> partial functions considered harmful :)
21:18:18 <dolio> Does SML do higher rank polymorphism?
21:18:21 <bd_> foldl' with 0 asa base case also good
21:18:21 <edwardk> Saizan: depends on the size of the arguments
21:18:24 <TSC> Saizan: The Int wrapping might break it
21:18:30 <edwardk> dolio: i don't think so in general
21:18:38 <ivanm> dons: my guess is to fold over a sum mod m
21:18:48 <edwardk> dolio: i think its a 'mixed top-down/bottom-up' wobbly type kinda thing
21:18:55 <edwardk> so its probably only haskell-derivatives
21:19:13 <ivanm> since (a + b) `mod` m = ((a `mod` m) + (b `mod` m)) `mod` m
21:20:42 <dons> ?pl (\x y -> (x + y) `mod` m)
21:20:43 <lambdabot> flip flip m . (mod .) . (+)
21:20:45 <dons> hah
21:20:54 <edwardk> > let a # b = (a + b) `mod` m in a # b # c # (d `mod` m)
21:20:54 <dons> ?pl (\x -> (x + y) `mod` m)
21:20:55 <lambdabot> (`mod` m) . (y +)
21:20:55 <lambdabot>  (((a + b) `mod` m + c) `mod` m + d `mod` m) `mod` m
21:20:59 <ivanm> so the biggest problem with it is the length of 4...
21:21:19 <ivanm> so take 4 from the list, and throw an error if it isn't long enough
21:21:32 <thomashartman1> Saizan: yes, I did cabal update. same result.
21:21:35 <edwardk> > let infixr 5 #; a # b = (a + b) `mod` m in a # b # c # (d `mod` m)
21:21:36 <lambdabot>  (a + (b + (c + d `mod` m) `mod` m) `mod` m) `mod` m
21:21:53 <ivanm> or do what you did in your blog post, and scratch the list and make the function take in the parameters as plain Ints :p
21:21:58 <dons> nice work, edwardk
21:22:06 <edwardk> i'll flip it around and post it to reddit
21:22:27 <ivanm> edwardk: using lists or direct inputs?
21:22:44 <edwardk> i'll leave the list, just flipping it to a where
21:22:49 <ivanm> *nod*
21:23:05 <ivanm> how are you going to match for the 4 elements?
21:23:21 <ivanm> or just leave it as is but with a better function?
21:23:26 <edwardk> nerf (k1:k2:k3:k4:[]) m = k4 # k3 # k2 # (k1 `mod` m) where ...
21:23:35 <ivanm> still looks ugly to me though...
21:23:44 <edwardk> yeah
21:23:45 <Saizan> thomashartman1: weird, which version of cabal-install ?
21:23:45 <sjanssen> [k1, k2, k3, k4]
21:23:48 <ivanm> then again, anything like that where it _has_ to have exactly 4 elements is ugly
21:23:50 <edwardk> a fold is more general i admit
21:24:01 <thomashartman1> Saizan: does plugins install for you?
21:24:04 <edwardk> i guess it should be posted with both versions
21:24:15 <sjanssen> ivanm: yeah, seems like a hint that the author is using the wrong structure
21:24:23 <ivanm> edwardk: nerf ks@[k1,k2,k3,k4] = fold # 0 ks
21:24:30 <thomashartman1> Saizan: cabal-install version 0.4.7
21:24:30 <thomashartman1> using version 1.3.11 of the Cabal library
21:24:33 <ivanm> oh, missed the "m"
21:24:38 <ivanm> nerf ks@[k1,k2,k3,k4] m = fold # 0 ks
21:24:40 <bd_> At the very least it should be a 4-tuple, not a list
21:24:46 <ivanm> bd_: yeah
21:24:54 <edwardk> ivanm testing
21:24:56 <ivanm> only nice thing with the list is that it then lets us use a fold
21:25:00 <bd_> nerf ks@[_,_,_,_] m = fold (#) 0 ks
21:25:01 <Saizan> thomashartman1: it doesn't but gives a different error about inconsistent requirements :) and i've 0.4.7
21:25:23 <bd_> ivanm: partial functions are worse than having to form it into a list when you fold it :)
21:25:24 <ivanm> bd_: yeah, that's better than what I did, not least because mine didn't have brackets ;-)
21:25:40 <ivanm> bd_: heh, yeah
21:25:49 <edwardk> @type \ks m -> let infixr 5 #; a # b = (a + b) `mod` m in fold (#) 0 ks
21:25:51 <lambdabot> parse error on input `)'
21:26:01 <Saizan> thomashartman1: i meant 0.4.6
21:26:01 <ivanm> lol
21:26:04 <hpaste>  thomashartman1 pasted "troubles installing plugins -- it tells me I need ghc >= 6.8, but I have it already" at http://hpaste.org/8041
21:26:22 <bd_> ivanm: heck, the list will probably be magically inlined away anyway
21:26:28 <ivanm> edwardk: I can't see whats wrong with it though...
21:26:35 <bd_> ie, in nerf (a,b,c,d) m = fold (#) 0 [a,b,c,e]
21:26:37 <bd_> d*
21:26:37 <ivanm> bd_: *nod* ... its still an ugly structure
21:26:48 <ivanm> *nod*
21:26:49 <sjanssen> thomashartman1: most likely it is referring to the ghc *library*
21:27:04 <bd_> anyway, wouldn't it be easier to add, then mod?
21:27:10 <sjanssen> thomashartman1: output of 'ghc-pkg list ghc'?
21:27:17 <ivanm> hmmm.... with the new git-darcs-import program, does this mean haskell hackers are going to start migrating en-masse to git? ;-)
21:27:19 <bd_> nerf ks@[_,_,_,_] m = sum ks `mod` m
21:27:31 <bd_> I can't see that being much more expensive than doing that many mods, given that it's addition
21:27:38 <bd_> multiplication it might be justified, addition less so
21:27:44 <ivanm> bd_: that works as well, though mod-ding first is at times better if you have the possibility of overflow
21:27:54 <bd_> ivanm: I'm assuming bigints here
21:28:17 <ivanm> I think it was Int, but I doubt they'd be that big anywya
21:28:19 <ivanm> *anyway
21:28:20 <thomashartman1> sjanssen: I don't have it. ghc-pkg list ghc
21:28:20 <thomashartman1> /usr/local/lib/ghc-6.8.2/package.conf:
21:28:20 <thomashartman1> /home/thartman/.ghc/i386-linux-6.8.2/package.conf:
21:28:22 <bd_> oh, it was Int
21:28:28 <ivanm> but yes, in this case you might as well
21:28:29 <edwardk> > let nerf ks m = let a # b = (a + b) `mod` m; infixr 5 # in foldr (#) 0 ks in nerf [a..d] m
21:28:30 <lambdabot>  Exception: not a number
21:28:39 <sjanssen> thomashartman1: that is your problem.  You need to figure out how you managed to install ghc without the ghc library
21:28:55 <bd_> fromInteger $ sum (map toInteger ks) `mod` (toInteger m)   :D
21:28:56 <ivanm> edwardk: you have to provide a value for m... ;-)
21:29:00 <edwardk> heh
21:29:01 <ivanm> bd_: lol
21:29:20 * ivanm gets back to F90 coding
21:29:38 <bd_> better yet, define a new numeric type for operations on Z(m) ;)
21:29:54 <ivanm> I've thought about that actually... but it's probably too much of a PITA
21:29:55 <thomashartman1> sjanssen: I think I used the binary install for 6.8.1.
21:30:04 <thomashartman1> should I have built from source?
21:30:05 <ivanm> since the data structure needs to keep track of m then...
21:30:18 <bd_> well, m needs to be known ahead of time
21:30:20 <edwardk> nerf ks m = foldr (#) 0 ks where infixr 5 #; a # b = (a + b) `mod` m -- seems to work
21:30:20 <thomashartman1> that takes like 11 hours! (or did for 6.6.1)
21:30:23 * ivanm makes sure that that's on its to-do list ;-)
21:30:26 <bd_> otherwise what happens when you add incompatible ones?
21:30:41 <ivanm> thomashartman1: how old is your machine if it takes 11 hours? :o
21:30:55 <thomashartman1> wel that was another machine on another job in another city... it was old.
21:30:59 <ivanm> bd_: hmmm.... true...
21:31:03 <ivanm> thomashartman1: ahhh
21:31:20 <ivanm> bd_: probably either an error or chinese remainder theorem-style stuff
21:31:47 <sjanssen> thomashartman1: I have absolutely no idea what might cause this.  Probably best to ask the ghc users mailing list
21:32:18 <Saizan> ivanm, bd_: see Oleg's functional pearl "implicit configurations" for an implementation :)
21:32:35 <bd_> Saizan: link? :)
21:32:48 <ivanm> you mean someone's already done it?
21:32:56 <bd_> ah, found it
21:33:04 <thomashartman1> do you get ghc 6.8.1 from apt-get install on hardy heron?
21:33:42 <Saizan> thomashartman1: if you got it via apt-get the ghc library might be in another package
21:34:02 <thomashartman1> sjanssen: I will ask the list. ghc users is different from haskell cafe?
21:34:28 <edwardk> ok, replied
21:34:46 <sjanssen> thomashartman1: it is different.  -cafe would be okay if you don't want to subscribe to another list
21:35:12 <ivanm> bd_: link?
21:36:08 <Saizan> thomashartman1: there's also a libghc6-plugins-dev btw
21:36:27 <bd_> ivanm: http://okmij.org/ftp/Haskell/types.html#Prepose
21:36:27 <lambdabot> Title: Haskell Programming: Types
21:36:34 <bd_> haven't read it yet
21:38:35 <ivanm> bd_: I think this is it: http://www.cs.rutgers.edu/~ccshan/prepose/p1214-kiselyov.pdf
21:41:52 <thomashartman1> edwardk: did you check that that compiles?
21:43:02 <edwardk> thomashartman1:   [1 of 1] Compiling Main             ( Nerf.hs, interpreted )\nOk, modules loaded: Main. -- did i have a transcription error?
21:43:13 <thomashartman1> maybe.
21:43:16 <thomashartman1> edwardk: maybe.
21:43:32 <thomashartman1> I copied from reddit into ghci and it seemed to have some problem.
21:43:59 <edwardk> ah it glommed my lines together for the infixr
21:44:16 <thomashartman1> shouldn't reddit always format things right if you indent?
21:44:40 <edwardk> aparently it doesn't. i put > at the beginning of the lines, the just got merged
21:44:42 <edwardk> try now?
21:45:21 <thomashartman1> edwardk: i think your best bet is to indent a couple spaces when reddit pasting.
21:45:51 <edwardk> thomashartman1: this is the first time i have ever successfully gotten code to paste into reddit at all, so you're probably right ;)
21:47:27 <thomashartman1> edwardk: nerf.hs:13:43:
21:47:27 <thomashartman1>     Occurs check: cannot construct the infinite type:
21:47:27 <thomashartman1>       a = (a1 -> a1 -> a1) -> a -> a
21:47:27 <thomashartman1>     Probable cause: `k1' is applied to too many arguments
21:47:31 <thomashartman1>     In the second argument of `(#)', namely `(k1 mod m)'
21:47:34 <thomashartman1>     In the second argument of `(#)', namely `k2 # (k1 mod m)'
21:47:37 <thomashartman1> does it compile for you?
21:48:35 <hpaste>  thomashartman1 pasted "quickchecking edwardk's code (which doesn't yet compile for me)" at http://hpaste.org/8042
21:49:50 <hpaste>  edwardk annotated "quickchecking edwardk's code (which doesn't yet compile for me)" with "my source file" at http://hpaste.org/8042#a1
21:51:15 <edwardk> in my case it works with or without the type annotations too
21:51:23 <thomashartman1> enh.
21:52:41 <hpaste>  newsham pasted "Applicative Idiom brackets in TH" at http://hpaste.org/8043
21:53:06 <al3x> i need a little help with this code: http://pastebin.com/m3d8c2184
21:53:25 <al3x> line 3: i need to filter based on depth
21:53:26 <hpaste>  thomashartman1 annotated "quickchecking edwardk's code (which doesn't yet compile for me)" with "it compiles, but quickcheck runs out of tests." at http://hpaste.org/8042#a2
21:54:09 <edwardk> I didn't say the code was correct. I was still trying to figure out the 'which doesn't compile yet for me' part =)
21:54:20 <ivanm> edwardk: it might have been easier to have "k1 # 0" rather than just "k1 `mod` m"
21:54:27 <ivanm> well, neater and more consistent anyway
21:54:43 <thomashartman1> oh, to get the original code to compile i had m=3 somewhere or something
21:54:51 <edwardk> ivanm: sure
21:56:00 <thomashartman1> Saizan: I am using gutsy. I think this is an ugly place to be, with regards to packages. My other box is a hardy. I'm gonna see if cabal install plugins is better behaved there.
21:56:01 <newsham> is there a way to make the TH syntax nicer?
21:56:17 <thomashartman1> newsham: switch to lisp?
21:56:30 <ivanm> @slap thomashartman1
21:56:31 * lambdabot pokes thomashartman1 in the eye
21:56:34 <newsham> I dont see that as making the syntax nicer.
21:56:41 <ivanm> we're meant to be promoting Haskell here, not lisp!
21:56:42 <newsham> retrograde
21:57:01 <al3x> http://pastebin.com/m3d8c2184, line 3, is there any easy way of doing this?
21:57:14 * thomashartman1 was only kidding
21:57:22 <newsham> I would like to know if there's an alternative to  $(i [| ... |])
21:57:59 * thomashartman1 greatly prefers haskell to lisp, and hasn't even used lisp all that much
21:58:14 <thomashartman1> but TH does kind of make my brain melt.
21:58:44 <newsham> I'm fine with the way TH works.  i just want to know if there's a simpler way to invoke it
22:00:57 <edwardk> @hpaste
22:00:57 <lambdabot> Haskell pastebin: http://hpaste.org/new
22:01:19 <al3x> http://pastebin.com/m3fc8f44, line 13, what would we the best way to do this?
22:01:23 <Dzlk> It strikes me as a hard problem. Every metaprogramming syntax I know of is some degree of unpleasant.
22:01:32 <hpaste>  edward annotated "quickchecking edwardk's code (which doesn't yet compile for me)" with "its the test" at http://hpaste.org/8042#a3
22:01:54 <edwardk> it generated 100 lists, none wound up 4 items long
22:02:11 <geezusfreeek> oh the nerf thing
22:02:19 <geezusfreeek> i did a working quickcheck for it on reddit
22:02:46 <dolio> edwardk: Size increase is based on the number of successful tests.
22:03:04 <dolio> So it's easy to write checks that never generate tests that pass a precondition.
22:03:05 <geezusfreeek> http://reddit.com/info/6lnnp/comments/c047e8c
22:03:57 <edwardk> dolio: sure
22:04:10 <ddarius> newsham: Nope.
22:04:40 <ivanm> geezusfreeek: problem with your nerf2, is that he only wants 4 items in the list
22:04:57 <geezusfreeek> so it should fail if there are not exactly four?
22:05:17 <geezusfreeek> well, as in error?
22:05:43 <ivanm> well, going by what quhuhu provided, that'd be my guess
22:05:47 <edwardk> ivanm: there is a faithful encoding in my post which fails on non-4 just like his, and he has two identical except for foldr foldl versions between myself and geezusfreeek i think the guy's question is answered ;)
22:05:47 <geezusfreeek> because technically this solution still works for four items
22:05:58 <ivanm> edwardk: yeah
22:06:04 <newsham> ddarius: oh well, it was a fun exercise, but it hardly seems worth it to avoid typing <$> and <*>
22:06:23 <ivanm> though if I had a reddit account I would have done "take 4" before applying the fold :p
22:06:51 <geezusfreeek> that would not be any more correct though
22:06:55 <dolio> edwardk: Oh, you weren't the one with the question. :)
22:07:01 <ivanm> or you can do as bd_ said, and do (sum ks) `mod` m (assuming that sum ks <= max int)
22:07:03 <edwardk> dolio: heh
22:07:18 <ivanm> geezusfreeek: well, it ensures it doesn't add any more than 4 elements :p
22:07:26 <thomashartman1> geezusfreak: I think if you pattern matched on an xs with four elements, then nerf2 would be exactly like nerf
22:07:30 <ivanm> and you could do an if statement on the length...
22:07:31 <geezusfreeek> still nothing about any less though
22:07:57 <ivanm> and chuck an error if (length (take 4 ks) < 4)
22:08:20 <thomashartman1> ivanm: why not pattern match on 4 elements, and have an otherwise case that throws an error?
22:08:20 <geezusfreeek> anyway the point is that for any data that would not cause the first one to throw an exception, the second one returns identical results
22:08:58 <geezusfreeek> should be trivial to add the code to throw an exception on different lengths
22:09:19 <ivanm> thomashartman1: well, we had that above using nerf ks@[_,_,_,_] m = ...
22:09:23 <ivanm> however you want it
22:09:30 <ivanm> geezusfreeek: *nod*
22:09:38 <edwardk> typically when someone is asking how to make something more elegant they are more looking for 'what is a better way to do this kinda thing' than a perfectly faithful encoding of all of the flaws of the existing approach ;)
22:10:02 <thomashartman1> good point.
22:10:11 <ivanm> silly people ;-)
22:10:40 <thomashartman1> on the other hand, could be that the OP knew there should always be 4 args in which case...
22:10:55 <thomashartman1> I guess I've just been on a quickCheck kick lately
22:10:59 <ivanm> heh
22:11:39 <thomashartman1> I feel like there's all these clever people writing functions with folds and stuff that I may not immediately grok... but with quickcheck maybe I can catch em out ;)
22:11:46 <edwardk> thomashartman1: in which case the folded versions work in every case and are only distinguishable from the original by not crashing in some places. nothing to see here. move along ;)
22:11:55 <thomashartman1> yeah yeah
22:14:24 <thomashartman1> geezusfreak: by the way, that's a great motivating example for Applicative.
22:14:52 <geezusfreeek> thomashartman1: :)
22:16:25 <geezusfreeek> thomashartman1: i'm thinking it may have been more clear if i had just done this instead though: \xs -> nerf xs m == nerf2 xs m
22:17:03 <geezusfreeek> thomashartman1: i have just gotten so used to resorting to applicative to be more point free that i sometimes forget that point free isn't _always_ the best
22:17:15 <thomashartman1> probably would be easier to read.
22:17:32 <thomashartman1> I consider applicative esoteric.
22:17:44 <edwardk> heading to bed. night all
22:17:53 <thomashartman1> night edwardk
22:18:08 <geezusfreeek> applicative is too useful to be esoteric ;)
22:18:17 <geezusfreeek> it's just easy to abuse
22:18:18 <thomashartman1> anything I haven't gotten around to learning is esoteric
22:27:42 <thomashartman1> bye.
22:27:47 <Saizan> are --foo=bar and --foo= bar to be considered equal in general? or is bar considered a distinct argument/flag in the latter?
22:28:13 <ivanm> probably distinct
23:02:21 <dmwit> I would recommend letting --foo=bar and --foo bar be equivalent, but letting --foo= bar specify an empty foo and an argument bar.
23:02:42 <dmwit> (If you're rolling your own argument parser.)
23:10:24 <Saizan> dmwit: mostly trying to use cabal's one correctly :) it doesnt like --foo bar btw
23:10:49 <dmwit> Oh, bummer.
23:10:52 <dmwit> Good to know, though.
23:13:20 <al-maisan> Hello there!
23:13:30 <dmwit> Hiya, al-maisan!
23:13:53 <al-maisan> Is there a way to group patterns i.e. do the same for 2 or more patterns?
23:14:14 <dmwit> No, you have to manually introduce a let- or where-binding.
23:14:39 <al-maisan> I do a compare and would like to do the same for LT and EQ for example ..
23:14:50 <dmwit> How about using (<=) instead?
23:15:09 <al-maisan> dmwit: OK .. it's not a big deal, I will do what you suggested ..
23:17:09 <Saizan> al-maisan: in your case you can use case compare x y of GT -> ...; _ -> <code for LT and EQ>
23:17:46 <al-maisan> Saizan: thanks, that's a nice suggestion..
23:17:58 <dmwit> Saizan++
23:20:15 <OceanSpray> that lambda-shaped tater on "Real World Haskell"'s blog looks like a pair of gonads.
23:21:44 <Saizan> not monads?
23:42:12 <elliottt> anyone know when quickcheck-2.0 will be released?
23:43:06 <dolio> There hasn't been a change in the darcs repository for a while.
23:43:20 <dolio> Maybe they just haven't released it?
23:45:44 <dolio> Perhaps you should bug them about it. :)
23:45:49 <elliottt> will do :)
23:48:13 <elliottt> it seemed rather complete, though the change to Arbitrary could break a lot of stuff.  maybe that's why it's not been released yet
23:48:37 <dolio> Perhaps.
