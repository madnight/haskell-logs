00:00:41 <lament> current continuation being the context in which call/cc is called; the function that waits for the value of call/cc
00:00:50 <lQg> what would be the "current continuation" ? like xs from (x:xs) ?
00:01:39 <lQg> hmmm is it a strict functional programming anomaly?
00:01:50 <lament> mmm
00:02:15 <lament> no
00:02:33 <lQg> as in does call/cc occur in lazy functional languages ?
00:02:56 <lament> 1 + (callCC blah)  -- the current continuation, with which blah is called, is \c->1 + c
00:03:00 <lament> if that makes sense
00:03:37 <lament> yes, Haskell has continuations but I'm not familiar with the API.
00:03:39 <codacola> interesting. i try to print 1 to the console and i get a happy fac
00:03:54 <luqui> lQg, I'm not sure callCC has well-defined pure semantics
00:03:59 <erikc> is ghc's garbage collector incremental? although i see SPJ has published papers on real-time gc for haskell, i dont see many options in the current ghc release related to it
00:03:59 <luqui> but don't take my word on that
00:04:03 <lQg> codacola: ASCII
00:04:46 <lQg> codacola: show 1
00:04:54 <codacola> lQg: a) its not haskell, b) using c#'s convert.toChar method, its kinda weird.
00:05:15 * codacola now misses haskell
00:05:32 <lQg> yea ASCII 1 is er somewhere above 0x20
00:05:50 <codacola> and?
00:06:05 <codacola> Console.WriteLine(Convert.ToChar(1));, should do the conversion nicely
00:06:05 <lQg> well the happy face is the character for 0x01
00:07:04 <Saizan_> luqui: it has pure semantics in CPS
00:07:16 <hml> @src >>
00:07:17 <lambdabot> m >> k      = m >>= \_ -> k
00:07:19 <luqui> ah yes, that makes sense
00:07:33 <hml> @src >>=
00:07:33 <Saizan_> ?src Cont callCC
00:07:33 <lambdabot> Source not found. :(
00:07:33 <lambdabot> callCC f = Cont $ \c -> runCont (f (\a -> Cont $ \_ -> c a)) c
00:07:44 <lQg> codacola: use 0x31 http://ascii-table.com/img/table.gif
00:08:21 <Pistahh> @src replicate
00:08:21 <lambdabot> replicate n x = take n (repeat x)
00:08:36 <luqui> hml, >>= is a method, it doesn't really have an implementation.  each monad implements it differently.
00:08:46 <dons> i encourage people to downmod this, http://www.reddit.com/r/programming/comments/6t1k5/Why_your_favorite_language_is_unpopular_The_total/
00:08:46 <_zenon_> hml, All about monads
00:08:47 <lambdabot> Title: Why your favorite language is unpopular - "The total world's population of Haske ..., http://tinyurl.com/5cjzz2
00:09:09 <_zenon_> hml, http://www.haskell.org/all_about_monads/html/index.html
00:09:10 <lambdabot> Title: All About Monads
00:09:10 <lQg> codacola: this table with ascii happy face http://game-editor.com/tutorials/images/ascii.jpg
00:09:24 <_zenon_> hml, There you will find the definitions nicely lined up
00:10:13 <Pistahh> @src @src
00:10:13 <lambdabot> Source not found. Just try something else.
00:10:31 <codacola> lQg: that doesnt help when its a standrd function that seems to be screwing up :P
00:11:12 <lQg> codacola: its not an Integer.toChar function
00:11:50 <codacola> note what i said earlier, not a haskell function :P, c#
00:11:57 <codacola> and yes, its the same one ive always used
00:12:35 <lQg> *shrugs* i gave up on java and its derivatives like c# since they are so buggy
00:13:12 * luqui wonders in what way lQg means buggy...
00:13:29 <lament> dons: why?
00:13:31 <O_4> Yeah, since when is C# buggy?
00:13:58 <lQg> well java kinda misses a lot of stuff i use in haskell *shurgs*
00:14:06 <dons> inflamatory titles like that are memes we wish to avoid.
00:14:49 <hml> i have this amazing system for viewing pdfs while coding; anyone know if there's a copy of "all about monads" as a pdf?
00:15:15 <lament> C# is quite nice, but i can't really make myself trust in Mono
00:16:19 <O_4> Mono seems decent, and obviously you have Microsoft's runtime on windows
00:16:20 <lament> on windows it seems pretty much nonpareil, though
00:16:22 <glguy> dons: HA!
00:16:35 <joed> That is almost like saying I miss alot of the stuff I use in the kitchen when I go to the bathroom.
00:16:40 <lament> of course it's better to avoid coding for windows in the first place
00:16:58 <luqui> come to think of it, joed, I often do.
00:17:04 <lQg> joed: nice analogy java is a shitty toilet programming langauge
00:17:24 <joed> lQg: I thought you needed a spatula, but, sure.
00:17:29 <lQg> or c# as a derivative
00:17:51 <lQg> i don't import things really in haskell
00:17:56 <lament> C# is much nicer than java
00:18:02 <lQg> its all plain and kosher
00:18:10 <lament> it has many functional features, too :)
00:18:32 <_zenon_> hml, you can download All about monads to your local machine
00:18:38 <lament> second-order functions in the standard library
00:18:45 <idnar> hmm, a 747 can fit quite a few people ;)
00:18:47 <lQg> my programming teacher didn't like much how i only used recursive functions in my java programming
00:18:49 <_zenon_> hml, Maybe you already knew that, but as a pdf? I don't know
00:19:11 <lQg> i didn't use a single loop
00:19:15 <idnar> recursive functions aren't a great idea in Java :P
00:19:17 <lQg> for a java parser
00:19:30 <Pistahh> idnar: what is a great idea in Java? :P :)
00:19:39 <idnar> Pistahh: you've got me there
00:19:39 <lQg> idnar: thats a java bug
00:19:58 <idnar> lQg: it's a bit more than a bug, I think
00:20:06 <lament> Pistahh: that it was a VM that caught on.
00:20:18 <lQg> idnar: an animal of a problem then?
00:20:23 <lament> a great evolutionary step in mainstream consciousness.
00:20:23 <_zenon_> hml, You could use this http://html2pdf.seven49.net/Web/
00:20:24 <lambdabot> Title: html2pdf - Home
00:20:28 <luqui> java doesn't do tailcall optimization, right, so I can see why your teacher would be uneasy...
00:20:39 <idnar> lQg: what I mean is, it's not something you can really correct without reversing language design decisions
00:20:57 <luqui> (but there is a certain conceptual uneasiness about recursion that many imperative programmers share)
00:21:01 <idnar> or maybe not language design per se
00:21:28 <olsner> recursion => stack overflow :)
00:21:39 <lQg> idnar: design constraints
00:21:52 <luqui> great idea in java:  incorrectly use design patterns too often to win the respect of your peers
00:21:52 <lQg> short sighted designers
00:22:05 <lament> recursion => the way to solve recursive problems.
00:22:09 <idnar> lQg: anyhow, in order to fix it, you'd break other stuff people rely on, so it probably wouldn't fly
00:22:27 <lQg> lament: all problems are recursive
00:22:30 <lament> if a problem is recursive, then to not solve it recursively is wrong (unless optimization)
00:22:33 <idnar> lament: that's a tautology
00:22:54 <olsner> I've seen recommendations that you build your program as a huge state machine rather than calling subroutines, since the default stack on this platform was so small
00:23:00 <lQg> idnar: yea thats the problem with using imperative language compilers
00:23:02 <lament> idnar: no, recursion is a concept in the programming domain and recursive problems are in the problem domain.
00:23:13 <luqui> lQg, except the nonrecursive ones, such as determining when a turing machine halts.
00:23:17 <_zenon_> hml, saying "thanks for the tip" or "thanks" once in a while would not kill you.
00:23:20 <lQg> fix one thing and something else breaks is synonymous with using loops
00:23:48 <lQg> luqui: that can be a recursive process
00:23:51 <luqui> lQg, you have a liberal definition of "synonym", I think
00:24:08 <joed> No shit.
00:24:13 <luqui> lQg, no, that was just a silly math pun.  "recursive" being the math term for 'computable'
00:24:28 <_zenon_> lQg, In fact, there is no counterproof, but also no proof to the claim that all computations can be performed recursively.
00:24:49 <lQg> well haskell does everything recursively
00:25:02 <luqui> _zenon_, I think there is proof, actually.
00:25:05 <lQg> and we with you can program anything in haskell
00:25:12 <lament> problem is some actual real-world problem to solve which you write the program. The problem, or some sub-problem of it, might have recursive nature, such as rendering HTML with nested elements, etc.
00:25:15 <idnar> olsner: that's an interested reason to use a state machine :P
00:25:22 <idnar> *interesting
00:25:28 <luqui> but there is also proof that all computations can be performed iteratively.
00:25:40 <hml> _zenon_: lol; was afk; thanks;
00:26:11 <lQg> well all computations can be performed with assembler
00:26:40 <lQg> i mean thats proven right? like well everything to date anyways
00:27:01 <ski> luqui : `callCC' is an effectful operation
00:27:10 <lament> if a problem does have recursive nature then to not solve it recursively is just wrong. The question is, are subproblems such as 'finding a a labeled object in a container' recursive in nature? Imperative programming thinks, no.
00:27:29 <lament> ...and uses for loops and iteration for such tasks
00:27:35 <luqui> lQg, church-turing thesis:  everything which can reasonably be considered "computable" can be computed with a turing machine (/ lambda calculus / assembler [with infinite memory] / lots of other interesting systems)
00:27:46 <ski> luqui : using monads, one can have it coexisiting in a pure language like haskell .. one can also have it as a side-effecting operation, as in Scheme and SML/NJ
00:28:04 <lQg> luqui: cool
00:28:09 <erikc> ive been doing interviews lately and roughly half the candidates cant convert strcpy to a recursive form
00:28:33 <lament> seems a pretty stupid idea :)
00:28:40 <lQg> lament: non functional programming languages do not claim to be disfunctional
00:29:16 <luqui> there was a great quote about that last week.  Oh yeah, something like "I want codependent types, which are useful for dysfunctional programming"
00:29:29 <pjdelport> @quote dysfunctional
00:29:29 <lambdabot> No quotes match. It can only be attributed to human error.
00:29:35 <baaba> erikc, are you sure they can't do that or they're hung up on how unnatural it would feel to do so?
00:29:37 <ski> luqui : ?
00:30:00 <luqui> ski, ? ?
00:30:11 <luqui> (and re: your comment, thanks, that was the impression I was under)
00:30:35 <ski> luqui : who wanted codependent types .. and what, more specifically, did s/he mean by it ?
00:30:39 <misterbeebee> i was a candidate in an interview where the interviewer said "you're the first person who has written a recursive solution correctly"
00:30:47 <lQg> op its nap time
00:30:48 <lQg> adios
00:30:50 <misterbeebee> I asked "what's the other solution?"
00:30:52 <erikc> probably a bit of both, but its still worrisome
00:30:54 <lQg> amigos
00:30:57 <misterbeebee> "an iterative one"
00:30:59 <Pistahh> misterbeebee: :)
00:31:00 <misterbeebee> "oh, right."
00:31:03 <luqui> ski, I think it was a joke, but I wasn't here for it.  I just saw it on hwn.
00:31:05 <Pistahh> misterbeebee: what was the question?
00:31:20 <ski> luqui, ok then
00:31:37 <misterbeebee> it was something like searching a tree...
00:31:44 <erikc> i also get a lot of itoa implementations with n^2 complexity because of repeatedly calling pow() and strlen()
00:31:56 <baaba> erikc, it would be rather worrisome if implementing strcpy recursively seemed like the natural solution :P
00:32:30 <misterbeebee> he was expecting something like "while (node.child !=null) node=node.child;"
00:33:10 <lament> misterbeebee: that sound shorter than what your functional solution must have been :)
00:33:16 <lament> sounds
00:33:17 <misterbeebee> yes, it was
00:33:20 <misterbeebee> but mine was pure
00:33:25 <lament> haha <3
00:33:30 <misterbeebee> i did not get the job :)
00:33:37 <erikc> sure, but i think the question is quite reasonable :)
00:33:45 <Zao> erikc: if(*dst++ = *src++) rcpy(dst, src); // almost elegant
00:34:12 <lament> Zao: wow, that is pretty
00:34:19 <luqui> now implement strcpy purely =P
00:34:43 <misterbeebee> the problem with interviews is that whiteboards are imperative-code friendly. good functional code gets cut-and-pasted several times as I write.
00:35:29 <Pistahh> luqui: while (*dst++ = *src++);    ;)
00:36:15 * luqui is confused.
00:36:34 <Zao> misterbeebee: I tend to need Just Another Variable and clustering parts together badly when evolving imperative code.
00:36:44 <Zao> Pistahh: Plenty of side effects there.
00:36:56 <lament> so? they're harmless side effects
00:37:03 <luqui> lol
00:37:10 <lament> besides, "string copy" implies side effect
00:37:30 <lament> it would be a monadic action in Haskell
00:37:52 * luqui 's pure strcpy: strcpy x = x
00:38:29 <erikc> i guess what i found odd was that ppl can write the 'while' version and then stare like a deer in headlights when asked to convert to the zao's version
00:38:49 <lament> strcpy :: MemPtr -> MemPtr -> IO ()
00:39:00 <Zao> erikc: It took me a while to adjust to the lack of built-in control structures in Haskell.
00:39:03 * luqui cringes
00:39:08 <lament> it's not pure and it's not strcpy x = x
00:41:08 <lament> sometimes you need to copy strings in memory in C where you don't need to do it in Haskell, but when you do need to copy a string in memory, you'd have to do it in some monad... does IO have this action?
00:41:23 <lament> ah, IORef probably
00:41:40 <lament> no...
00:41:46 <erikc> ive had far more impractical questions in interviews, like 'write a routine to determine a cycle in a (bad) linked list in constant space and infinite time'
00:41:50 <Pistahh> strcpy x = (x,x)   :)
00:41:58 <misterbeebee> newtype IOArray i e = IOArray (STArray RealWorld i e)
00:41:59 <luqui> lament, something like that.  It's hard to say, since you must mean something different by "string" in that context.
00:42:50 <idnar> erikc: wow, I don't think I'd be able to get that one
00:43:00 <opqdonut> erikc: it need only O(n) time :\
00:43:04 <idnar> erikc: but I guess that's just because of the sort of code I work with
00:43:05 <opqdonut> or the good solution does
00:43:18 <idnar> I don't really ever implement my own data structures :P
00:43:27 <lament> luqui: a null-terminated buffer, of course :)
00:43:39 <opqdonut> of course there are multiple polynomial-time constsnt-memory solutions
00:44:16 <erikc> is it O(n), i didnt get it, they hit my limit on that one, i figured it out, but then was too shaken up to prove it
00:44:53 <opqdonut> erikc: the O(n) solution is the classic slow pointer method
00:45:00 <erikc> ah, k
00:45:08 <opqdonut> erikc: you have two pointers advancing through the list, the second one going half the speed
00:45:16 <erikc> yea
00:45:19 <opqdonut> erikc: if there is a cycle, they will meet
00:45:22 <erikc> yup
00:45:30 <erikc> i figured that out, but then had no idea how to prove the complexity
00:45:46 <_Dae_> well... if you can use infinite time, you could presumably make something that more or less makes a guess
00:45:59 <Pistahh> slow_p := (slow_p + slow_p++) / 2
00:46:07 <opqdonut> _Dae_: yeah, for inifinite time one could just search for duplicates
00:46:23 <_Dae_> opqdonut: and then you could do it in constant space
00:46:27 <luqui> opqdonut, I don't think so...
00:46:28 <erikc> opqdonut: not quite, cause you never hit the end of the list
00:47:01 <opqdonut> there is an upper bound on how many elements the slow pointer can look at
00:47:05 <opqdonut> let me get some paper
00:47:13 * luqui 's constant space, infinite time solution:   hasCycle l = _|_
00:47:53 * ski applies luqui's `hasCycle' to an infinite list of ones
00:48:20 <_Dae_> infinite time, constant space, cycles in a linked list, right?
00:48:23 <olsner> heh, "infinite time"? I guess the objective of that problem is weeding out the candidates that don't listen to the full problem description :)
00:49:06 <erikc> they didnt say inifnite time, they said time complexity didnt matter
00:49:09 <erikc> sorry
00:49:15 <opqdonut> thought so :)
00:49:25 <erikc> it was the constant space that was important :)
00:49:34 <ski> so big-oh infinity ?
00:49:39 <_Dae_> erikc: but still constant space? auch..... harder then. I was writing up something exponential here
00:49:57 <olsner> ski: f is O(Inf) for any f, right?
00:50:10 <opqdonut> or o(Inf) ;)
00:50:11 <ski> olsner : that's my take, yes
00:50:20 <luqui> but f still has to be total
00:50:54 <luqui> but there's a tricky corner case which I'm never exactly sure about
00:51:02 <luqui> namely algorithms that terminate with probability 1
00:51:08 <opqdonut> erikc: In the time the slow pointer runs around the loop once, the fast pointer has visited each node in the loop at least once
00:51:29 <opqdonut> pretty easy to observe
00:51:36 <luqui> opqdonut, but that's not a proof
00:51:46 <erikc> but it would have to hit the slow pointer
00:51:46 <luqui> oh, right, I see it
00:51:51 <opqdonut> yeah :)
00:52:03 <opqdonut> it's a bit of a bother to write down properly, I admit
00:52:32 <opqdonut> erikc: that implies them hitting as both proceed monotonically through the list
00:52:53 <olsner> I had to punt on the proof when I got that question on an interview and say something like "I'm sure it's right, the proof is probably on the internet"
00:53:06 <O_4> How do you make sure the function returns?
00:53:42 <O_4> Do you get to assume the list is either correctly terminated OR an infinite loop?
00:53:53 <erikc> yea
00:53:56 <luqui> O_4, you assume that the representation is finite
00:54:02 <lament> If there's a cycle, at some point the pointers will be on neighbour elements, since the distance between them decreases by 2 each iteration. And if the two pointers are on neighbouring elements, that means they meet next iteration.
00:54:19 <luqui> O_4, so the whole thing might not be a cycle; i.e. it might be a finite list followed by a cycle.
00:54:29 <_Dae_> opqdonut: isn't the proof trivial, or am I missing something?
00:54:31 <luqui> but no infinity allowed.
00:55:01 <O_4> luqui: sorry, I meant it either had to be finite or cyclic
00:55:06 <O_4> Not infinite
00:55:18 <luqui> O_4, what other options are there?
00:55:30 <luqui> lament, I think that's the trick.
00:55:36 <misterbeebee> luqui: cell.next = rand()
00:55:48 <misterbeebee> :)
00:55:53 <lament> of course this approach only works on things that are actually indexed by pointers
00:56:17 <_Dae_> lament: but the problem was a linked list, so.....
00:56:19 <luqui> this algorithm is not implementable on haskell lists :-(
00:56:29 <lament> so it does not work on haskell's potentially infinite lists of integers, which are not indexed by pointers
00:56:31 <O_4> luqui: my first thought was "they want to verify a list is valid", but of course if you can't rely on the programmer to have correctly constructed it then it's not safe to assume that there's a clearly marked end point.
00:57:09 <_Dae_> lament: but the whole idea of finding a cycle in an infinite list is a bit of a problem, isn't it?
00:57:38 <olsner> heh, an alternative answer to the problem is "spank the original programmer until no cyclic lists are constructed by the program"
00:57:54 <misterbeebee> cyclic lists have valid uses.
00:57:58 <lament> _Dae_: no, assuming the elements are objects with unique identity, there's no conceptual difficulty
00:58:37 <_Dae_> lament: but if the list is infinite, without a cycle, your algorithm won't return
00:59:01 <lament> sure
00:59:06 <olsner> yes, but you don't know whether the program in question has one of the valid uses of them :)
00:59:15 <lament> _Dae_: but go ahead, generate such a list.
01:00:22 <_Dae_> lament: In haskell? well you could make a list where each element was a digit of pi. There are algortihms for fidning the i'th digit of pi so no problem
01:01:09 <_Dae_> wait..I'm confusing stuff here...pattern mathicn and linked lists, sorry.
01:01:42 <misterbeebee> olsner: suppose you want to count the number of cells in a potentially cyclic list. you can't just scan to the end of the list. you need to check if it is cyclic, then measure the length of the cycle, then do some bonus math that i can't specify at this time of night.
01:02:38 <_Dae_> lament: but your arguement is basicly that infinite lists are not a problem, because no such thing exists unless there is a cycle, correct?
01:04:51 <misterbeebee> actually, i think that "bonus math" is generally impossible, but you could get the answer up to some equivalence classes, I suspect
01:05:52 <_zenon_> how do you leave a message to someone through lambdabot?
01:06:16 <luqui> @tell _zenon_ hello
01:06:17 <lambdabot> Consider it noted.
01:06:18 <lament> _Dae_: for C-style (pointerable) linked lists, yeah
01:06:40 <_zenon_> luqui, thanks.
01:06:41 <lambdabot> _zenon_: You have 1 new message. '/msg lambdabot @messages' to read it.
01:06:53 <lament> unless it's some contrived thing, like you could generate a list of all possible strings
01:07:20 <luqui> lament, but that's not a "linked list"
01:07:24 <misterbeebee> let a = (1:a) in let b = a in b == a -- does not terminate.  so you can't find out the answer, even though ghc relies upon the fact that b == a in its implementation. Unfair.
01:07:26 <ski> _zenon_ : you can also @ask
01:07:55 <_Dae_> lament: you could imagine another sort of linked lists with such a thing as infinite lists? hmm.... I guess if your implementation had a linked list that only stored the current element and a pointer to a computation of the next and previous element...
01:08:32 <luqui> misterbeebee, true.   and allowing it to answer would violate referential transparency (or solve the halting problem, which would be better :-)
01:09:49 <misterbeebee> There should be a  Monad GHCSecrets
01:10:02 <lament> _Dae_: ha, yes, the slow pointer method would not work there.
01:11:01 <lament> since you can't tell if your two pointers are pointing at the same "place" in the list without solving the halting problem
01:11:56 <opqdonut> lament: surely not the general halting problem
01:12:08 <opqdonut> special cases can be handled, of course
01:12:25 <opqdonut> some sort of definitional language might be able to demostrate that equality
01:12:26 <lament> well, the equivalent - running an infinite amount of computation
01:13:00 <lament> an infinite list would also be an infinite loop.
01:13:54 <lament> _|_
01:14:29 * _Dae_ remembers adding two infinite lists and summing them as art of a calculus exam..
01:17:35 <erikc> yay, i think i got it (for myself), you want to proof that for all n > 0, 0 <= o < n, there exists an x such that (2x + o) % n == x % n, which simplifies to 0 == (x + o) mod n, so x (the step on which the match is reached) is n - o, so its O(n)
01:19:16 <misterbeebee> _Dae_, you didn't sum two infinite lists. you proved that by combining the two  lists  in a certain carefully-defined way, you generated a third list that converged to a limit
01:19:32 <misterbeebee> never need to explicitly manipulate anything infinite
01:20:43 <glguy> I haven't tested this math expression I've only proved its correctness?
01:22:03 <_Dae_> misterbeebee: no.... I don't think so. The equality signs for taylor and fourier expansions are just that, equality signs. No limits involved
01:24:26 <misterbeebee> http://en. wikipedia.org/wiki/Series_(mathematics)#Infinite_series
01:25:12 <misterbeebee> i'm looking for a better reference.
01:25:40 <luqui> what's the flag to tell ghc to run the file through the c preproc?
01:26:34 <misterbeebee> but the gist is that, it's impossible to directly prove an infinite computation, obviously, so we use notation like "+ ... =", but when you get down to the most formal mathematical expression, it's in terms of limits.
01:27:15 <luqui> -cpp.  thanks ;-)
01:29:02 <misterbeebee> Aha: http://math.andrej.com/2006/03/27/sometimes-all-functions-are-continuous/ Andrej Bauer. Really heady stuff.
01:29:05 <lambdabot> Title: Mathematics and Computation » Sometimes all functions are continuous, http://tinyurl.com/5sr6e8
01:32:43 <_Dae_> misterbeebee: *laughs* so first part.... I -am- a physicist :p
01:33:52 <misterbeebee> ah, yes. physicists gloss over the part after the first 100 or so significant figures :-)
01:34:49 <dons> kalven: what do you think a more appropriate response would have been?
01:35:55 <misterbeebee> _Dae_: and here's a followup post that talks more directly about "infinity" http://math.andrej.com/2008/02/06/representations-of-uncomputable-and-uncountable-sets/
01:35:57 <lambdabot> Title: Mathematics and Computation » Representations of uncomputable and uncountable se ..., http://tinyurl.com/5m65bp
01:36:01 <misterbeebee> and with that, time for me to sleep
01:36:18 <ski> (misterbeebee : that's an interesting post, yes)
01:36:24 <_Dae_> misterbeebee: actually, our worst crimeis saying that inf*0=1
01:36:27 <kalven> dons: well, I didn't interpret the article as a knock on haskell at all.
01:37:01 <sms_> whom do i have to pay so haddock links to highlighted sources are added on hackage?
01:37:07 <dons> no, i'm taking issue with the title quote used on the reddit submission. it's not related to the article, and needlessly attacks a community.
01:37:14 <codacola> wonderful. 2 labs and 2 classes tomorrow
01:37:20 <dons> but clearly people find that kind of thing funny
01:37:20 <codacola> onne being a haskell lab
01:37:25 <dons> at our expense, sadly.
01:38:03 <kalven> do you really think it has any impact on the community?
01:38:28 <dons> you never know what memes catch on, or where we'll hear that quote again.
01:38:52 <dons> likely its just more noise, but as a community, i think we need to respond to these things preemptively
01:39:08 <kalven> I'm in favor of open discussion, not burying things that might be unpleasant.
01:39:12 <dons> but i'm of the view we should avoid avoiding success.
01:39:19 <dons> oh, by all means, discuss the blog post!
01:39:28 <dons> its not like the blog is taken down, right?
01:39:59 <dons> but note no one is discussing anything except the meijer quote.
01:40:04 <dons> and not even that, in any depth.
01:40:41 <kalven> no, but didn't you encourage people to downvote the article? that could have lead to the post going away from reddit's first page fairly quickly.
01:41:13 <dons> right. i'd have preferred it was just resubmitted with the actual title.
01:41:30 <dons> then there was a chance people would talk about the article itself.
01:41:35 <pierre-> dons, i found that post a rather humoristic article :-) so upmodded
01:41:50 <_Dae_> misterbeebee: I like his arguments, but in the end it boils down to philosophy rather than math, ie "is there such a thing as infinity"
01:42:03 <kalven> dons: fair enough
01:42:46 <earthy> interestingly enough the article isn't all that good either
01:42:51 <misterbeebee> _Dae_: yes (but I'm not here, i'm asleep)
01:43:08 <dons> no, there are better discussions of the barriers to technology adoption.
01:43:09 <_Dae_> misterbeebee: have a good one ;)
01:43:30 <pierre-> honestly, i can't see any attack there
01:44:55 <ibid> wow. someone wrote a icfp contest entry in TeX (+ a perl wrapper for IO)
01:45:23 <dons> we have let our enemies define and perpetuate the stereotypes against us. :) that quote from meijer is along those lines. that kind of thing bugs me.
01:45:45 <hml> i'm working through the all about monads tutorial
01:45:51 <hml> and trying to figure out how this works:
01:45:53 <hml> mothersPaternalGrandfather s = (Just s) `comb` mother `comb` father `comb` father
01:46:09 <hml> ... so are infix operators by default right associateive?
01:46:19 <kalven> Yeah, but.. "enemies". srsly :]
01:46:34 <earthy> dons: this is not dissimilar to the situation with Java in the 1990's
01:46:35 <dons> i use robust language.
01:46:38 <earthy> late 1990's
01:46:43 <mfp> who are "the enemies"??? /me starts firefox
01:46:51 <earthy> i.e. 'Java is slow' 'Java is cumbersome'
01:48:07 <dons> there are perceptions and misconceptions all around
01:48:53 <earthy> and it takes a motherlode of marketing as well as good code to turn that around
01:49:31 <dons> a whole lot of effort.
01:50:56 <erikc> question i get a lot is about the execution model (at the assembly level)
01:51:14 <erikc> which is so alien compared to what most ppl are used to
01:52:18 <earthy> hm. it isn't that alien
01:52:28 <earthy> but maybe I'm braindamaged
01:52:49 <erikc> is there a pretty printer for it?
01:52:50 <Maddas> Or not used to thes ame things as most people
01:53:36 <erikc> a more formal documentation of ghc's abi would go a long way
01:54:13 <dons> the runtime system for dummies?
01:54:17 <erikc> yea
01:54:36 <erikc> and the machine-specific abis
01:54:55 <dons> ah , like this, http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts
01:54:56 <lambdabot> Title: Commentary/Rts - GHC - Trac
01:55:05 <erikc> calling conventions per platform, memory layouts for the closures
01:55:23 <dons> http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/HaskellExecution/CallingConvention
01:55:24 <lambdabot> Title: Commentary/Rts/HaskellExecution/CallingConvention - GHC - Trac, http://tinyurl.com/5qocmh
01:55:29 <earthy> and that is important how?
01:55:52 <dons> people feel more comfortable knowing values are in registers :)
01:56:01 <erikc> its true
01:56:27 <erikc> ppl feel comfortable knowing if the shit hits the fan they can peel off the language and understand the assembly
01:56:28 <earthy> they don't even know that for java
01:56:42 <earthy> hm. right.
01:56:48 <earthy> I see the point
01:56:49 <erikc> i know a lot of developers who know it for java
01:56:53 <erikc> at the bytecode and assembly levels
01:56:57 <erikc> after jitting
01:57:01 <O_4> I thought you could get a reasonable idea of what ghc was doing by looking at the core or whatever?
01:57:13 <earthy> O_4: nah, not really
01:57:22 <dons> yes, i wonder what a python programmer thinks is going on.
01:57:23 <earthy> you have to really grasp the idea of thunks
01:57:34 <O_4> Not down to a register level, but enough to see pretty well what's going on
01:57:39 <earthy> or a ruby programmer for that matter
01:57:57 <erikc> ghc-core is a great tool btw dons, very helpful
01:57:57 <earthy> but yeah, erikc, I see the point. many programmers dislike magic
01:58:02 <earthy> and ghc to them feels like it
01:58:07 <dons> people seem quite happy treating python as a big black box of magic, strangely.
01:58:21 <dons> maybe too many rules have changed in haskell
01:58:25 <O_4> Yeah, and ruby
01:58:30 <dons> so you can't fake it knowledge anymore.
01:58:42 <dons> fake an understanding
01:58:43 <luqui> I'm having trouble 'freeze'ing a StorableArray into an Array (or UArray); I get a stack overflow
01:59:11 <luqui> I think it's a problem in the implementation of freeze, as I see nowhere excess laziness could have crept in
02:00:23 <erikc> simd registers access is also the question i get heh
02:00:41 <luqui> here's an example
02:00:45 <luqui> http://hpaste.org/9114
02:00:46 <erikc> i dunno if there are plans for a set of #VInt prims
02:00:51 <luqui> or not an example so much as the offending code
02:01:06 <erikc> with corresponding prim operations corresponding to a typical simd instruction set
02:01:54 <dons> would be fun. we could probably get by with some harpy code gen magic..
02:07:06 <dons> cool cats, http://www.reddit.com/comments/6t1z1/Hayoo_a_new_Haskell_API_search_engine_with/
02:07:07 <lambdabot> Title: Hayoo, a new Haskell API search engine, with find-as-you-type completion and fuz ..., http://tinyurl.com/6x76pu
02:07:13 <glguy> dons: you're up late :)
02:07:22 <osfameron> is there already a substantial port of grep(1) to haskell?
02:07:25 <dons> glguy: coffee late. :/
02:07:42 <pjdelport> dons: i always thought Python had a particularly clean and straightforward mapping to C
02:07:46 <dons> osfameron: what's grep,  regex + bytestring?
02:08:17 <dons> hmm. this hayoo with full hackage search makes me wonder what we're paying soc money for haddock on.. :)
02:08:21 * sjanssen once wrote a parallel fgrep-alike in Haskell
02:08:21 <osfameron> dons: +recursive + option handling for display/context/summary etc.
02:08:28 <luqui> dons, you mean hoogle?
02:08:39 <dons> hoogle, oops.
02:08:45 <JaffaCake> dons: only 8 hours to get some sleep before the #ghc meeting :)
02:08:45 <osfameron> I know there's the simple prototype in the "unix utilities with haskell" post, but grep(1) has quite a lot of options
02:08:52 <dons> JaffaCake: crikey!
02:09:04 <earthy> it's a holumbus demo
02:09:25 <osfameron> someone was suggesting to me that haskell wasn't a realistic language to write such a utility in, and I disagreed... wanted to check if there was prior art before setting it as my next learning project
02:09:25 <glguy> JaffaCake: Why is this disallowed: newtype T = forall a. D (Maybe a)
02:09:33 <sjanssen> osfameron: sounds like a lot of tedious programming
02:09:38 <earthy> and finding Prelude.fst for [a] -> Bool is not necessarily a good match...
02:09:43 <glguy> JaffaCake: is there a theoretical reason? implementation constraint?
02:09:46 <dons> osfameron: do a parallel grep or some such to make it fun.
02:09:48 <JaffaCake> glguy: you want an existential?
02:09:56 <dons> an existential on a newtype?
02:10:12 <sjanssen> dons: I did that.  It was faster than grep at search the #haskell logs :)
02:10:17 <sjanssen> searching
02:10:22 <dons> awesomness.
02:10:23 <glguy> JaffaCake: yeah, I know it could be done with a data type, but in this case there there is no typeclass context attached to the existential
02:10:28 <sjanssen> ByteString ftw
02:10:33 <glguy> it seems like the type could still be boiled away
02:10:39 <osfameron> sjanssen: really?  I thought it might be quite fun, as there are lots of little combinators, playing with IO, having to use a queue structure (for the context search), folding state through the grep for context/line-numbers etc.
02:10:58 <osfameron> Of course my standards are fairly low: I haven't really done much IO in haskell, or much haskell at all, so anything's fun really
02:11:10 <osfameron> dons: I guess that would be fun... but first things first...
02:11:13 <JaffaCake> glguy: so the constructor would have to stick around in the Core, because it binds a type variable
02:11:29 <sjanssen> osfameron: this was a very stripped down version, no line numbers, only fixed string search, etc.
02:11:34 <JaffaCake> but that ought to be possible
02:11:47 <glguy> JaffaCake: so it's an implementation reason?
02:11:57 <JaffaCake> could be, I'm not sure
02:12:07 <JaffaCake> simonpj would know
02:12:17 <osfameron> sjanssen: yes I agree.  I meant "substantial port of grep(1)" as a constrast to the cute but toylike implementation in that post
02:12:18 <glguy> I suppose: data T = forall a. D !(Maybe a)   would be a close approximation...
02:12:44 <JaffaCake> you really need the newtype semantics?
02:12:51 <JaffaCake> or is it just efficiency?
02:13:25 <glguy> It seemed like a place to newtype at the time, wasn't a necessity
02:13:47 <glguy> and after the compiler told me I couldn't do what I did, I just started wondering why that was :)
02:13:55 <JaffaCake> glguy: I presume there's more to your type than that, because otherwise you can't do much with it :)
02:14:24 <glguy> JaffaCake: there was more, but the 'a' in the example had no constraints
02:14:38 <glguy> There was a "State" type
02:14:41 <glguy> that had a couple of parameters
02:14:48 <glguy> and I only cared about one of them
02:14:57 <osfameron> sjanssen: ah, I missed your comment about fgrep-alike sorry.  I'd be interested to see it if you have it knocking around
02:14:58 <JaffaCake> ok
02:15:17 <cetin> how can I darcs get the graphviz library, darcs get http://code.haskell.org/graphviz does not work o_O?
02:15:36 <glguy> something like: data Example = forall a. C (Int -> State UserId a)
02:15:56 <sjanssen> osfameron: I'm fairly certain it is gone
02:16:36 <glguy> (where State isn't the mtl one)
02:18:04 <glguy> anyway, it's time for bed
02:18:07 <glguy> cya tomorrow don
02:18:26 <osfameron> hmmm, no google hits for "perl is an acceptable haskell"...
02:20:42 <conal> sjanssen: i made a package around your MemoTrie code: http://haskell.org/haskellwiki/MemoTrie
02:20:45 <lambdabot> Title: MemoTrie - HaskellWiki
02:23:58 <nornagon> How would I create a construct whereby I could pass it a bunch of IO actions, and it would try them in sequence until one succeeded?
02:25:03 <conal> nornagon: first reduce the problem to two actions.  then fold.
02:25:08 <pjdelport> nornagon: define "succeeded"
02:25:30 <nornagon> pjdelport: say they're IO Bool
02:25:48 <nornagon> 'succeeded' means it returned True :)
02:26:04 <Maddas> Was Conjure abandoned?
02:26:09 <yango> @oeis 1, 4, 16, 98
02:26:10 <lambdabot> Row sums of triangle A091039 (scaled second columns of (k,k)-Stirling2 arrays).
02:26:10 <lambdabot> [1,4,16,98,1252,39056,3235216,746947664,504955938112,1063702416056576,7035749...
02:26:12 <nornagon> conal: ah, neat idea :)
02:26:12 <Maddas> lambdabot: conjure?
02:27:23 <conal> :)
02:29:09 <nornagon> conal: just seems like there ought to be a clever-mittens way of doing it
02:29:18 <therp> nornagon: I'd rather go for IO (Maybe Result)
02:29:37 <nornagon> therp: that'd work too, i guess.
02:29:53 <therp> (which is practically equivalent to IO Bool if you might discard Result)
02:30:17 <nornagon> but my calulations don't really return a meaningful result :)
02:30:25 <nornagon> so I'd be returning Just () or something.
02:31:34 <dibblego> @type liftM2 (&&)
02:31:49 <lambdabot> thread killed
02:31:53 <nornagon> liftM2 (&&) :: (Monad m) => m Bool -> m Bool -> m Bool
02:32:40 * BeelsebobWork notes that Data.Map needs insertWithZero :: Ord k => (a -> b -> b) -> k -> a -> b -> Map k b -> Map k b
02:33:42 <BeelsebobWork> because insertWithZero (:) k i [] map would be excessively useful
02:33:47 <BeelsebobWork> amongst other things
02:34:17 <nornagon> so I ended up with  doneOrContinue m1 m2 = m1 >>= (\a -> if a then return True else m2)  ;  tryList = foldr doneOrContinue (return False)
02:34:32 <nornagon> i think the first is equivalent to liftM2 (&&)?
02:34:45 <nornagon> @src liftM2
02:34:46 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
02:35:01 <therp> @type (&&)
02:35:04 <lambdabot> Bool -> Bool -> Bool
02:35:18 <nornagon> Prelude Control.Monad> :t liftM and
02:35:18 <nornagon> liftM and :: (Monad m) => m [Bool] -> m Bool
02:35:40 <therp> I guess you want sequence
02:35:54 <nornagon> therp: i don't want [a]
02:35:58 <nornagon> as the return type
02:36:05 <nornagon> i want to stop executing as soon as i hit a True
02:36:12 <therp> @type (liftM and) . sequence
02:36:17 <lambdabot> forall (m :: * -> *). (Monad m) => [m Bool] -> m Bool
02:36:24 <nornagon> ah right
02:36:43 <nornagon> i wonder if that works. *checks*
02:37:22 <nornagon> wuh, ghci doesn't seem to like (liftM and) . sequence
02:37:29 <nornagon>     Ambiguous type variable `m' in the constraint:
02:37:29 <nornagon>       `Monad m' arising from a use of `sequence' at <interactive>:1:27-34
02:37:59 <therp> probably give that function a type signature? [IO Bool] -> IO Bool
02:38:14 <nornagon> ah, that worked.
02:38:25 <nornagon> wonder why it wouldn't let me have my polymorphism, though.
02:38:46 <nornagon> well, that didn't work so well
02:38:51 <nornagon> Prelude Control.Monad> tryAll [return True, print "hi" >> return True]
02:38:51 <nornagon> "hi"
02:38:51 <nornagon> True
02:38:53 <ski> (nornagon : no, the first isn't equivalent to `liftM2 (&&)')
02:39:01 <nornagon> ski: oic :)
02:39:08 <nornagon> @src (&&)
02:39:09 <lambdabot> True  && x = x
02:39:09 <lambdabot> False && _ = False
02:39:34 <therp> nornagon: ah we want "or", or || I guess
02:39:42 <ski> `liftM2 (&&)' still "forces the effects" of the two actions
02:39:51 <nornagon> therp: doesn't work either :)
02:39:58 <nornagon> ski: oh i see
02:41:22 <nornagon> my doneOrContinue/tryList combo works as expected, though.
02:42:26 <ski> hm .. i suppose one could use `unsafeInterleaveIO', though
02:42:32 <nornagon> o.o
02:44:33 <therp> I assumed lazyness prevented side effects from happening.. hmm
02:44:46 <therp> nah that doesn't make sense..
02:45:51 <ski> therp : the `IO'-monad here accounts for the strictness
02:46:11 <therp> ski: that's what I was suspecting.. >>= is strict for IO, right?
02:47:50 <ski> therp : yes, when `ma >>= amb' is run in the `IO'-monad, the action `ma' is first run to get a returned value (possibly not evaluated)
02:49:33 <ski> however, `unsafeInterleaveIO' transfers the effects of an action to some time in the future
02:51:06 <luqui> therp, in the absence of unsafe*, laziness will never produce an observable difference other than not getting into an infinite loop when you think it should.
02:51:46 <luqui> (and stack overflowing when you think it shouldn't, but that's more of a practical issue)
02:52:19 <Cale> and to be fair, there are cases where strict evaluation would stack overflow, but lazy wouldn't :P
02:53:17 <Cale> Though when stack overflow occurs exactly I think requires more than just the evaluation model to determine.
02:53:32 <luqui> aye
02:53:42 <ski> > tryAll [print "foo" >> return False,return True, print "hi" >> return True] >>= print
02:53:45 <ski> "foo"
02:53:48 <ski> True
02:53:57 <lambdabot>  thread killed
02:53:58 <ski> nornagon : that's using `tryAll = liftM or . mapM unsafeInterleaveIO'
02:54:19 <Cale> thread killed?
02:54:20 <Cale> > 1 + 1
02:54:25 <Cale> ...
02:54:28 <lambdabot> Terminated
02:54:34 <Cale> @undefine
02:54:40 <lambdabot> Undefined.
02:54:43 <Cale> > 1 + 1
02:54:45 <ski> lambdabot probably has a bad day
02:54:54 <Cale> I can't ssh to code...
02:54:57 <lambdabot>  2
02:55:05 <Cale> mm... I can, but it's really slow :)
02:55:54 <ski> Cale : who's compiling GHC on the machine ?
02:56:04 <Cale> heh
02:56:31 <luqui> > "looks like it " ++ "got better"
02:56:32 <lambdabot>  "looks like it got better"
02:56:45 <Cale> heh, the process list is full of zombies
02:57:01 <Cale> also, for no good reason, there are two lambdaruns...
02:57:53 <Cale> This has happened before, and I don't understand how it could possibly happen.
02:58:21 <Shinta> btw can haskell be used to program real world stuff
02:58:26 <Cale> Shinta: yes
02:58:30 <luqui> @faq can haskell be used to program real world stuff
02:58:43 <Shinta> awsome
02:58:51 <Shinta> how come its not so popular then?
02:59:23 <Cale> Shinta: Because it's different enough from mainstream languages that the learning curve is a bit steep for programmers who expect something similar to what they already know.
02:59:28 <therp> Shinta: it takes a year of meditation to learn
02:59:36 <luqui> therp, well said
02:59:47 <Shinta> meditation =(
02:59:52 <Shinta> cant I learn it in a week?
03:00:13 <Shinta> its meant to be assumed knowledge for my course =(
03:00:33 <Cale> Well... give it a shot.
03:00:41 <pjdelport> Shinta: http://www.realworldhaskell.org/
03:00:54 <Cale> It's a nice language, and you might be able to pick up enough to be usable throughout your course.
03:00:55 <ski> Shinta : how long did it take to learn <insert whatever language you first started "real" programming in> ?
03:01:28 <Cale> It took me about 2 months to get to the point where I felt that I could really get things done in Haskell, and about a year to really feel comfortable.
03:01:36 <chr1s> does anybody know how to easily lift parsers for tok into parser for [tok] ?
03:01:40 * _zenon_ wonders who killed Lambdabot
03:01:42 <chr1s> e.g., a function GenParser tok st a -> GenParser [tok] st a
03:01:45 <Cale> _zenon_: me.
03:01:55 <_zenon_> For maintenance?
03:01:59 <Cale> _zenon_: yeah.
03:02:01 <pjdelport> Shinta: take a look at http://en.wikibooks.org/wiki/Haskell
03:02:17 <pjdelport> Shinta: start at "Haskell basics", and see how far you get
03:02:18 <earthy> chr1s: that'd be tricky, as you have no way of combining the list of a's into 1 a
03:02:26 <zachk> shinta: dont be scared by the monads
03:02:27 <pjdelport> you can pick up a lot in a short time
03:02:29 <Cale> Okay, I have no idea what was going on... I'll run it again
03:02:37 <pjdelport> you don't have to master Haskell to use it usefully
03:02:43 <Shinta> well my first programming language took me about 3 months till i was overconfident in it... then I learned java at school... maybe say another 3 months... assembly was obvious... c++ took a week to get used to etc etc etc
03:03:01 <earthy> (ofcourse, you could choose to drop all but the first or last result value from the parsed tokens, but still)
03:03:02 <chr1s> earthy: but it's the other way around. I've already lexed my input into a [String].
03:03:05 <zachk> have you ever recursed before?
03:03:18 <Shinta> use recursion?
03:03:20 <Shinta> yeah
03:03:23 <Cale> Shinta: Haskell is a lot more like traditional mathematics than it is like, say, C++
03:03:29 <pjdelport> zachk: "damn and damn again" ?
03:03:38 <Shinta> im not bad with set theory stuff ^_^
03:03:42 <Cale> Shinta: In Haskell, functions are honest mathematical functions.
03:03:43 <Shinta> is it similar?
03:03:57 <Shinta> oh
03:04:00 <ski> @faq can haskell be used to program real world stuff
03:04:03 <Cale> That is, for any given parameter, a function *must* give a unique and consistent result.
03:04:05 <lambdabot> The answer is: Yes! Haskell can do that.
03:04:08 <earthy> chr1s: that sounds as though you'd want a different parser state then, rather than a different token type
03:04:15 <ski> @botsnack
03:04:20 <earthy> each token is still of type String, right?
03:04:23 <lambdabot> :)
03:04:34 <ski> Cale : hm, she still seems a bit laggy, though ..
03:04:38 <pjdelport> Shinta: if you're used to thinking mathematically, Haskell should be particularly comfortable
03:04:44 <Cale> ski: yeah, code.haskell.org is really slow right now.
03:04:48 <chr1s> earthy: yes, each token is a String. But I don't see how a different parser state would help that?
03:04:49 <Shinta> you mean like f(x) = 1 if x < 1 otherwise = 1/x stuff ??
03:04:57 <zachk> shinta: yes
03:05:07 <Shinta> nic4e
03:05:16 <earthy> chr1s: current parser state keeps the remaining string around to parse
03:05:24 <Cale> > let f x | x < 1 = 1 | otherwise = 1/x in map f [-5..5]
03:05:28 <earthy> you want the remaining list of strings kept around to parse
03:05:38 <ski> curse Cale and his fast fingers :)
03:05:46 <earthy> but I'm slightly hazy on the details of Parsec, I must admit
03:05:47 <lambdabot>  thread killed
03:05:49 <Cale> (The server on which lambdabot runs is being really slow)
03:05:50 <Shinta> ooh you specify domain too?
03:05:51 <Cale> ugh
03:06:12 <Shinta> are you sure its a programming language?
03:06:14 <Cale> Shinta: that would have been clearer if I'd laid it out in 2D :)
03:06:17 <chr1s> earthy: well, the tok defines the parser state. I'll just play around a bit more, thanks.
03:06:28 <Cale> f x | x < 1     = 1
03:06:31 <ski> Shinta : yes, you can specify domain and codomain
03:06:35 <Cale>     | otherwise = 1/x
03:06:37 <pjdelport> Shinta: that line actually defines a function, and gives an example of using it
03:06:41 <ski> Cale : sorry
03:06:55 <pjdelport> Shinta: "f x | x < 1 = 1 | otherwise = 1/x" is the function definition
03:06:56 <Shinta> holy shit
03:06:59 <Cale> That's a definition by cases.
03:07:11 <zachk> > do x<-['a'..'c'];y<-[1..3];return (x,y)
03:07:14 <lambdabot>  [('a',1),('a',2),('a',3),('b',1),('b',2),('b',3),('c',1),('c',2),('c',3)]
03:07:20 <zachk> thats cartesian product
03:07:33 <pjdelport> Shinta: "let ... in map f [-5..5]" surrounds the definition, and maps the function across the list [-5..5]
03:07:34 <Cale> Heh...
03:07:34 <luqui> careful...
03:07:43 <Shinta> cartesian product as in relations?
03:07:50 <ski> as in sets
03:08:02 <zachk> yea like Set X Set
03:08:06 <pjdelport> > ['a'..'c'] <*> [1..3]
03:08:08 <Shinta> yeah i get ya
03:08:09 <lambdabot>  Couldn't match expected type `a -> b' against inferred type `Char'
03:08:11 <Cale> However, explaining *why* that's cartesian product might take a bit...
03:08:12 <|Steve|> > ['a'..'c'] >>= (\x -> [1..3] >>= return . (,))
03:08:17 <lambdabot>  Add a type signature
03:08:21 <Cale> > [(x,y) | x <- [1..3], y <- [4..5]]
03:08:26 <lambdabot>  [(1,4),(1,5),(2,4),(2,5),(3,4),(3,5)]
03:08:33 <pjdelport> > (,) <$> ['a'..'c'] <*> [1..3]
03:08:35 <lambdabot>  [('a',1),('a',2),('a',3),('b',1),('b',2),('b',3),('c',1),('c',2),('c',3)]
03:08:38 <Cale> There's list comprehension syntax, which might be easier.
03:08:40 <|Steve|> Is lambda bot just ignoring me?
03:08:44 <luqui> yay! show off session!
03:08:48 <Cale> |Steve|: code.h.o is really slow
03:08:57 <|Steve|> Oh no, it told me to add a type signature.
03:09:19 <Cale> Let's not get into the list monad quite yet :)
03:09:30 <|Steve|> Did I do it correctly?
03:09:38 <|Steve|> No, I didn't.
03:09:38 <Cale> But list comprehensions are nice and should be familiar if you're used to set comprehensions from mathematics
03:09:44 <|Steve|> > ['a'..'c'] >>= (\x -> [1..3] >>= return . (x,))
03:09:44 <lambdabot>  Parse error at "))" (column 46)
03:09:47 <|Steve|> lame.
03:09:55 <|Steve|> > ['a'..'c'] >>= (\x -> [1..3] >>= return . (,) x)
03:09:57 <lambdabot>  [('a',1),('a',2),('a',3),('b',1),('b',2),('b',3),('c',1),('c',2),('c',3)]
03:09:59 <Cale> > [(x,y,z) | x <- [1..20], y <- [x..20], z <- [y..20], x^2 + y^2 == z^2]
03:10:01 <|Steve|> There we go.
03:10:03 <lambdabot>  [(3,4,5),(5,12,13),(6,8,10),(8,15,17),(9,12,15),(12,16,20)]
03:10:13 <|Steve|> What's wrong with (x,)? Why isn't that a section?
03:10:20 <luqui> |Steve|, no good reason, far as I can tell
03:10:32 <zachk> shinta: if you like to jump in head first try http://www.haskell.org/haskellwiki/Roll_your_own_IRC_bot with healthy googling
03:10:34 <ski> did we scare Shinta away yet ?
03:10:35 <lambdabot> Title: Roll your own IRC bot - HaskellWiki
03:10:57 <zachk> i just stay for the coffee
03:11:03 <Cale> Shinta: That is, the list of triples (x,y,z) where x is chosen from [1..20], y is chosen from [x..20], and z is chosen from [y..20] where x^2 + y^2 == z^2 is true.
03:11:15 <Cale> (Pythagorean triples)
03:11:20 <nornagon> ski: oic. still scary to use unsafe* in such a trivial context though :)
03:11:31 <ski> |Steve| : for some stupid reason, tuples don't have section notation
03:11:39 <luqui> zachk, I consider that a good example of jumping head first into "missing the point" of haskell
03:11:59 <luqui> zachk, but it might be good for people who are looking for something familiar
03:12:05 <ski> nornagon : i don't think `unsafeInterleaveIO' is unsafe .. maybe slightly confusing, but not unsafe
03:12:16 <Shinta> nope :p
03:12:26 <nornagon> ski: surely it got called 'unsafe' for a reason :P
03:12:37 <ski> nornagon : that reason may be stupid, no ?
03:12:43 <luqui> nornagon, ski, its semantics are not referentially transparent
03:12:54 <Shinta> Ill learn it in a week :p
03:12:55 <luqui> or rather it creates values without referentially transparent semantics
03:13:01 <Shinta> ada can wait
03:13:10 <|Steve|> Heh, trying to explain referential transparency to my students didn't work so welwl.
03:13:12 <ski> luqui : i'm not convinced of that
03:13:27 <|Steve|> welwl = well
03:13:36 <luqui> ski, oh, the nondeterminism argument?
03:13:47 <luqui> where IO can look into the future?
03:13:58 <ski> luqui : yes, demonic nondeterminism of I/O
03:14:11 <idnar> haha
03:14:20 <ski> |Steve| : math or C.S. students ?
03:14:44 <luqui> I'm still not sure how much of that I buy.  But I think formally it _does_ work.
03:14:50 <ski> (idnar : i'm not kidding, that's an established term)
03:14:57 <luqui> however, its getting farther and farther from a "simple" semantics of IO
03:15:05 <luqui> which is the opposite direction we want to be moving
03:15:07 <idnar> ski: it's still amusing :)
03:15:15 <ski> *nod*
03:15:30 <|Steve|> ski: CS.
03:15:32 <ski> luqui : that i won't argue with :)
03:16:49 <Cale> Shinta: make sure to ask lots of questions here :)
03:17:21 <ski> Shinta : there's also a few tutorials you can start with
03:17:34 <Shinta> thx :p
03:17:46 <ski> @where yaht
03:17:46 <lambdabot> PDF: http://darcs.haskell.org/yaht/yaht.pdf Wikibook: http://en.wikibooks.org/wiki/Haskell/YAHT
03:17:47 <|Steve|> Maybe I'm missing something here, but he hasn't actually asked for help, he merely said he was going to learn it in a week.
03:17:49 <ski> e.g.
03:18:06 <|Steve|> yaht is still not finished.
03:18:17 <Shinta> lemme finish my food first :p
03:18:32 <ski> |Steve| : what?! surely we must flood her/him with help ?
03:19:07 <|Steve|> Why not wait until he asks?
03:19:34 <luqui> @faq Why not wait until he asks?
03:19:34 <lambdabot> The answer is: Yes! Haskell can do that.
03:19:46 <luqui> That's why!
03:19:55 <ski> but can the #haskell channel do that ?
03:20:01 <|Steve|> @quote Cale
03:20:02 <lambdabot> Cale says: GADT pattern match in non-rigid context. There are prescriptions available for that sort of thing.
03:20:17 <|Steve|> Damn, I was hoping for the stereo quote.
03:20:27 <luqui> @quote stereo
03:20:28 <lambdabot> LoganCapaldo says: * LoganCapaldo must resist urge to mention stereo
03:20:41 <ski> :D
03:21:15 <opqdonut> :D
03:21:46 <luqui> ... what is the stereo quote ?
03:22:02 <ski> @quote stereo
03:22:02 <lambdabot> dolio says: fasta: At least the 'stereo' quote is no longer in lambdabot. That was _way_ overused.
03:22:10 <ski> hm
03:22:13 <opqdonut> nah, only metaquotes left
03:22:16 <ski> @quote stereo
03:22:16 <lambdabot> omnId says: geez, how many metastereo quotes are going to be @remembered?  >_>
03:22:21 <opqdonut> :D
03:22:23 <therp> luqui: something like "#haskell, where your questions are answered in stereo."
03:22:32 <opqdonut> glorious stereo, i think
03:22:45 <ski> majestic
03:22:50 <ski> @quote stereo
03:22:50 <lambdabot> omnId says: geez, how many metastereo quotes are going to be @remembered?  >_>
03:23:02 <ski> it appears some people have had some fun
03:26:01 <ski> "Cale says: Welcome to #haskell, where your questions are answered in glorious stereo!" appears to be in atm, but i'm sure it was s/glorious/majestic/
03:26:29 <|Steve|> He hated that one because it flashed his client every time.
03:27:44 <ski> (i'd s/Cale/<undisclosed>/ then ..)
03:28:23 <|Steve|> @remember greeting Welcome to #haskell where your questions are answered in glorious stereo!
03:28:24 <lambdabot> Done.
03:37:35 <Baughn> |Steve|: Pah. *Modern* programming language channels do 5.1
03:38:09 <|Steve|> Well, functional programming has been around for ages, it's hard to call it modern.
03:39:04 <Baughn> Shh. I like to claim haskell is the most modern language around.
03:39:10 <Baughn> *one of the
03:41:38 <luqui> you don't have to use humble words like "most modern" when what you mean to say is "best"
03:43:49 <|Steve|> Baughn: Haskell has been around since 1990.
03:44:12 <Baughn> This does not prevent it from being one of the most modern languages around
03:44:33 <Baughn> (And anyway, the last standard is just ten years old)
03:44:52 <|Steve|> http://en.wikipedia.org/wiki/Timeline_of_programming_languages
03:44:53 <lambdabot> Title: Timeline of programming languages - Wikipedia, the free encyclopedia
03:45:04 <|Steve|> Well by that measure C is more modern.
03:45:19 <Lycurgus> *foreshortening
03:45:20 <Baughn> That's not the measure I was using, though
03:45:42 <|Steve|> I'm not sure why you brought it up then.
03:46:10 <Lycurgus> (of time with advancing age, so that aftwer say, a billion years there is only Now)
03:49:32 <|Steve|> If you're saying the language is new, well, it's not. If you're saying the ideas are new, well, they're not. In what sense is it more modern than, say, Java or C#?
03:50:02 <Baughn> It /uses/ the idea. Java and C# don't.
03:50:06 <Baughn> *ideas
03:50:25 <lilachaze> but many of the ideas date back to the lisp era
03:50:34 <|Steve|> It uses very old ideas.
03:50:42 <lilachaze> ah
03:50:46 <Baughn> That's fine. They're old ideas that map well to modern hardware.
03:50:55 <lilachaze> i get it, haskell's postmodern
03:51:03 <|Steve|> Hardware? What does that have to do with a programming language?
03:51:13 <Baughn> Quite a bit, I would say
03:51:16 <|Steve|> If you want mapping well to hardware, it doesn't get any better than assembly.
03:51:33 <Baughn> ...now you're just being disingenious
03:51:40 <lilachaze> that's odd. i'd have thought von neumann languages like c or pascal map to hardware better than haskell
03:51:41 <|Steve|> I am not, you said hardware.
03:51:52 <Baughn> Fine. How about "program performance per unit of programmer time"?
03:52:01 <ski> <http://math.andrej.com/2007/09/28/seemingly-impossible-functional-programs/> fun!
03:52:01 <lambdabot> http://math.andrej.com/2007/09/28/seemingly-impossible-functional-programs/>
03:52:13 <Baughn> lilachaze: Modern computers aren't really von neumann machines, though. Multicore and all..
03:52:43 <|Steve|> Baughn: I think what you really meant was that Haskell is one of your favorite languages. Nothing wrong with that as long as you realize you're making a personal statement rather than a claim about the language itself.
03:53:24 <Baughn> |Steve|: No, sorry, I really did mean "haskell maps better to modern hardware than most other languages"
03:53:46 <Baughn> It's just that my definition of "better" here doesn't allow for infinite programming time
03:53:54 <|Steve|> Can you give an example of that? How does <*> map to hardware, for example?
03:53:58 * Lycurgus fumbles in pockets. "where's that damn trout when I need it!"
03:54:15 <masak> Baughn: does the fact that modern computers are multicore really invalidate the von Neuman, though?
03:54:23 <Baughn> <*> doesn't. Referential transparency, purity and forkIO do.
03:55:16 <Baughn> masak: Not in the "you can map one to the other sense", but.. yes, I'd say it does. Von neumann, as mangled to fit multicore machines, is no longer a /simple/ description
03:55:29 <lilachaze> memory addresses aren't referentially transparent, though. forking is a software issue not a hardware one. everything is pure if you're prepared to live within State RealWorld or whatever
03:55:31 <masak> http://en.wikipedia.org/wiki/Von_Neumann_syndrome
03:55:33 <|Steve|> Hardware is inherently stateful, I fail to see the connection.
03:55:39 <therp> is there any predefined function that \f (a,b) -> (f a, f b) -- that lifts a function to be applied to both tuple elements?
03:55:51 <masak> Baughn: maybe one can view it as a slippery slope, that we're sliding down at present
03:56:10 <lilachaze> @type uncurry on
03:56:14 <lambdabot> forall b c a. (b -> b -> c, a -> b) -> a -> a -> c
03:56:19 <ski> therp : `(&&&)'
03:56:27 <mauke> :t join (***)
03:56:28 <lambdabot> forall (a :: * -> * -> *) b c. (Arrow a) => a b c -> a (b, b) (c, c)
03:56:43 <ski> therp : er, rather what mauke said :)
03:57:03 <Baughn> |Steve|: Pretending the hardware is pure produces increased programmer productivity that, overall, produces faster applications because they actually /do/ multithread them
03:58:33 <|Steve|> Baughn: But that's not mapping to hardware if you're pretending that the hardware is other than what it is. Programmer productivity is an individual thing. As for faster, the programming language shootout should fix the notion that haskell is faster.
03:58:35 <lilachaze> key word here 'pretending'. increased productivity is not the same as 'maps better to hardware', but it's obviousluy important...
03:58:42 <therp> mauke: thanks :)
03:59:17 <Baughn> |Steve|: The language shootout, last I checked, does not run on four-core machines. Perhaps they should fix that.
03:59:19 <lilachaze> |Steve|: i'm waiting to see the language shootout move to mostly parallel programs. i think haskell will have more of an edge then...
03:59:33 <Baughn> It wouldn't matter, though, since language-shootout programs receive far more optimization than is normal
04:00:24 <|Steve|> lilachaze: Maybe it will, I really have no idea.
04:00:41 <|Steve|> I know how to write safe threaded code in C, haskell not so much.
04:00:45 <|Steve|> But that's just me.
04:08:30 <EvilTerran> it's difficult to write unsafe threaded code in haskell
04:08:54 <EvilTerran> depending on which primitives you're using
04:09:23 <EvilTerran> but STM, and indeed even something very simple like Control.Parallel, both make safety the default, i believe
04:12:04 <Baughn> Depends on how you define "unsafe"
04:12:24 <Baughn> It's pretty easy to get a deadlock - which will be automatically diagnosed - or to leak memory, which won't
04:12:29 <vixey> usafePerfomTwoThingsAtOnce
04:12:29 <lambdabot> vixey: You have 1 new message. '/msg lambdabot @messages' to read it.
04:13:00 <vixey> lambdabot is broken
04:13:17 <Baughn> @messages vixey
04:13:17 <lambdabot> You don't have any new messages.
04:13:30 <Baughn> I see
04:13:41 <|Steve|> What about livelock?
04:14:04 <ski> vixey : i did `@clear-messages' to make it stop ..
04:14:30 <Baughn> |Steve|: Oh, that would work. "work".
04:14:46 <Baughn> Proper lock discipline fixes it, of course
04:15:15 <Baughn> And you don't often see haskell processes trying to grab more than one lock at a time, either
04:15:44 <|Steve|> hmm? I'm asking if you can livelock with haskell and if it'll diagnose it.
04:15:54 <|Steve|> I'd be pretty impressed if it could, live lock is tricky to detect.
04:18:07 <Baughn> No, it won't be diagnosed
04:18:22 <Baughn> The diagnosis it does depends on the GC to figure out a thread is permanently locked
04:18:44 <|Steve|> ah
04:19:27 <Baughn> At which point said thread gets an exception, so you can at least figure out where it was trying to lock. Rather, all threads involved get exceptionsw.
04:19:49 <Baughn> > let x = x in x
04:20:04 <lambdabot>  thread killed
04:20:43 <Baughn> ..right. If LB was working properly, you'd see "exception: <<LOOP>>" there; same general idea.
04:21:52 <|Steve|> *** Exception: stack overflow
04:22:07 <Baughn> You also need to compile with -threaded
04:22:13 <Baughn> And quite possibly -O2
04:22:27 <|Steve|> Compile which? I just did that in ghci.
04:22:30 <Cale> blackhole detection used to work so reliably...
04:23:47 <BeelsebobWork> Cale: is there something special I need to do to get my \bot to talk to ghci properly?
04:24:01 <Cale> BeelsebobWork: talk to ghci?
04:24:23 <Cale> BeelsebobWork: It uses hs-plugins with runplugs to evaluate expressions
04:24:38 <BeelsebobWork> oh, okay, is there something special I need to do to get that working?
04:25:09 <Cale> Nothing too special, other than have the right packages installed. Are you having trouble?
04:25:16 <Baughn> BeelsebobWork: What error are you getting?
04:25:27 <Baughn> __stginit_L missing or some such?
04:26:02 <BeelsebobWork> Cale: yeh -- but I can't get \bot to behave at all atm, I'll poke again later
04:26:20 <vixey> :t \a b c -> c (\x -> (\a b c -> b (\a b c -> a x) (\a b c -> a x)))
04:26:35 <lambdabot> thread killed
04:28:03 <Cale> code.haskell.org is being really slow.
04:28:27 <Baughn> vixey: t -> t1 -> ((t2 -> t3 -> (((t2 -> t7) -> t5 -> t6 -> t7) -> ((t2 -> t10) -> t8 -> t9 -> t10) -> t11) -> t4 -> t11) -> t12) -> t12 <-- Does this make you happy?
04:28:36 <vixey> yes
04:29:56 <Cale> :t \a b c -> c (\x -> (\a b c -> b (\a b c -> a x) (\a b c -> a x)))
04:29:59 <lambdabot> forall t t1 t2 t3 t4 t5 t6 t7 t8 t9 t10 t11 t12. t -> t1 -> ((t2 -> t3 -> (((t2 -> t7) -> t5 -> t6 -> t7) -> ((t2 -> t10) -> t8 -> t9 -> t10) -> t11) -> t4 -> t11) -> t12) -> t12
04:30:15 <Cale> (It'll work, just a bit erratically)
04:30:32 <vixey> â¡xâ¤=\a b c -> a x ; â¡M Nâ¤= \a b c -> bâ¡Mâ¤â¡Nâ¤; â¡\x -> Mâ¤= \a b c -> c (\x -> â¡Mâ¤)
04:31:30 <ski> vixey : it appears maybe you want a cyclic type ?
04:54:29 <ertai> Is there a common haskell name for the S combinator ?
04:54:40 <vixey> :t ap
04:54:44 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
04:54:47 <vixey> I think ap is that ? isn't it
04:55:11 <xerox_> yup
04:55:14 <vixey> :t \x y z -> x z (y z)
04:55:18 <lambdabot> forall t t1 t2. (t -> t1 -> t2) -> (t -> t1) -> t -> t2
04:55:23 <vixey> :t ap :: (t -> t1 -> t2) -> (t -> t1) -> t -> t2
04:55:24 <lambdabot> forall t t1 t2. (t -> t1 -> t2) -> (t -> t1) -> t -> t2
04:55:31 <|Steve|> How is ap used?
04:55:41 <Baughn> Wait, wouldn't S be just (.)?
04:55:59 <Baughn> ..ah. No. Reverse order.
04:58:10 <ski> > return (+) `ap` [1,2,3] `ap` [40,50]
04:58:11 <lambdabot>  [41,51,42,52,43,53]
04:58:36 <_zenon_> âThe use of COBOL cripples the mind; its teaching should, therefore, be regarded as a criminal offense.â
04:58:38 <ToRA> > take 10 $ fix $ (1:) . (1:) . (zipWith (+) `ap` tail)
04:58:40 <lambdabot>  [1,1,2,3,5,8,13,21,34,55]
04:58:51 <_zenon_> From Dijkstra, according to http://thinkexist.com/quotes/edsger_dijkstra/
04:58:54 <earthy> channeling Dijkstra there, zenon? :)
04:59:00 <lambdabot> Title: Edsger Dijkstra quotes
04:59:08 <vixey> The use of LAMBDA cripples the mind; its teaching should, therefore, be regarded as a criminal offense.
04:59:08 <_zenon_> earthy, Yes, I am also talking in tounges
04:59:25 <_zenon_> Talking in Turing
04:59:25 <xerox_> > [id, subtract 10, (*2)] `ap` [1..4]
04:59:27 <lambdabot>  [1,2,3,4,-9,-8,-7,-6,2,4,6,8]
05:00:04 <|Steve|> @type return (+) `ap` [1..3]
05:00:05 <lambdabot> forall a. (Enum a, Num a) => [a -> a]
05:00:25 <|Steve|> Hmm, okay.
05:00:44 <earthy> zenon: but yes, he did say so, in EWD 498 even
05:01:13 <ski> liftM3 f ma mb mc = return f `ap` ma `ap` mb `ap` mc  -- you may generalize
05:01:21 <earthy> (which is a famous text: 'how do we tell truths that may hurt?')
05:01:37 <ertai> vixey: yes S is 'ap' of (-> a), so no special name (like const for K)
05:01:51 <_zenon_> earthy, I think it's hilarious :) He has more of those truths :)
05:02:07 <ski> ertai : s/(-> a)/(a ->)/ or s/(-> a)/(->) a/
05:02:17 <earthy> It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration.
05:02:22 <ertai> ski: right
05:02:30 <earthy> to wit: I'm currently writing VB.Net code. :)
05:02:38 <_zenon_> HAHAAH
05:02:47 <_zenon_> earthy, That was a funny one!
05:02:51 <_zenon_> âObject-oriented programming is an exceptionally bad idea which could only have originated in California.â
05:03:09 <|Steve|> Who said that?
05:03:31 <ski> (vixey : re "Lambda: The Ultimate GOTO" ?)
05:03:46 <vixey> hehe
05:03:48 <vixey> no
05:03:50 <vixey> though
05:04:11 <_zenon_> |Steve|, Dijkstra
05:04:18 <_zenon_> ?
05:04:39 <ndmitchell> earthy: i learnt VB first, its still a language of choice for me
05:05:06 <|Steve|> Meh, who cares what Dijkstra had to say?
05:06:15 <luqui> I learnt ZFC first, there's still an axiom of choice for me
05:06:24 <vixey> |Steve|: You never read any of his books?
05:06:51 <|Steve|> vixey: I've read one of his papers, that was enough for me.
05:06:56 <earthy> ndm: VB.Net is different though
05:07:15 <earthy> (plus, I already knew AppleSoft Basic quite well when VB 1 was published)
05:07:16 <ndmitchell> earthy: i know - http://neilmitchell.blogspot.com/2007/04/visual-basic-story.html
05:07:16 <lambdabot> Title: Neil Mitchell's Haskell Blog: Visual Basic, the story
05:07:20 <vixey> you are probably missing out (or not interested in programming) in that case
05:07:25 <vixey> he's written good books
05:10:30 <|Steve|> vixey: Read the paper about the "THE" operating system and laugh at his claims of having proved his system correct.
05:10:51 <|Steve|> And then read about how graduate students are too stupid to do this research and how you have to have a Ph.D. to do it.
05:11:02 <ndmitchell> read his notes on Ada, and realise they are all spot on - yet they still use Ada...
05:11:37 <|Steve|> I don't actually know Ada, so I wouldn't have anything to compare it to.
05:11:51 <|Steve|> He also wrote that goto was harmful.
05:11:56 <EvilTerran> that was his editor
05:12:14 <EvilTerran> dijkstra came up with a lot of very clever stuff
05:12:21 * _zenon_ nods
05:12:22 <earthy> interrupts, for instance
05:12:34 <|Steve|> He came up with semaphores.
05:12:49 <EvilTerran> sure, he could be very arrogant, but that doesn't affect how influential he was
05:12:50 <|Steve|> They're in the appendix to the paper I mentioned.
05:14:13 <|Steve|> The goto letter is published under his name. There was no editor involved here.
05:14:35 <|Steve|> He was just trying to push his structured programming.
05:14:47 <|Steve|> http://www.cs.utexas.edu/users/EWD/ewd02xx/EWD215.PDF There's the paper, if you'd like.
05:14:48 <lambdabot> Title: cache:http://www.cs.utexas.edu/users/EWD/ewd02xx/EWD215.PDF - Google Search
05:15:53 <EvilTerran> "''a case against the GO TO statement'' was published as a letter entitled ''go-to statement considered harmful''" - i believe the first was his choice of name, not the second
05:16:02 <kryptiskt> Hoare on PL/1: "At first I hoped that such a technically unsound project would collapse but I soon realized it was doomed to success. Almost anything in software can be implemented, sold, and even used given enough determination."
05:16:37 <earthy> it was.
05:17:00 <earthy> he actually later lamented the title put above his letter to the editor
05:17:45 <earthy> (the title was put there by the editor, not by him)
05:17:59 <EvilTerran> that's what i thought
05:18:58 <|Steve|> Oh, I don't care about the title, it's the content that's  dumb.
05:19:36 <vixey> he's written more than that one paper
05:19:52 <EvilTerran> |Steve|, see, there we disagree
05:20:41 <|Steve|> EvilTerran: You care about the title and not the content?
05:26:38 <kryptiskt> |Steve|, what is your problem with the content?
05:28:52 <|Steve|> goto is not inherently bad and it has a number of good uses. For one thing, it compiles directly to an unconditional branch instruction which on modern processors takes no more time than the time to decode. It's useful in kernel code where you want functions to have a single entry point and a single exit point. It's useful for breaking out of nested loops (although perl's last statement would be better) without having to write horribly cont
05:28:52 <|Steve|> rived loop testing logic.
05:29:49 <Shinta> I thought goto was a bad practice
05:30:19 <Shinta> it seems to break the structure of things in typical high level languages
05:30:29 <kryptiskt> well, but the messes created by goto loving programmers of the 60's fed this reaction, goto makes it hard to reason about programs, it's too powerful.
05:30:35 <|Steve|> That's the argument that Dijkstra was making with his structured programming push.
05:31:21 <|Steve|> Hard for who to reason about? Compilers have no more trouble with gotos than they do with other control flow. As for programmers, like everything else, it's all in how you use it.
05:31:42 <Gwern-away> @seen chrisdone
05:31:42 <lambdabot> chrisdone is in #haskell. I don't know when chrisdone last spoke.
05:31:55 <|Steve|> Shinta: Linus has a mildly amusing comment about gotos when someone brought up that point on a linux list.
05:32:14 <Shinta> ???
05:32:22 <gwern> @tell chrisdone I like watchdog better than 'custodian' because watchdogs attack and kill on command; custodians just clean up the mess
05:32:22 <lambdabot> Consider it noted.
05:32:24 <|Steve|> Of course, he's no more of an authority than Dijkstra, as evidenced by his recent masturbating monkeys comment.
05:32:39 <Shinta> wha did he say?
05:32:44 <gwern> |Steve|: linus is just using time-honored troll tactics
05:33:03 <|Steve|> http://kerneltrap.org/node/553/2131
05:33:04 <lambdabot> Title: Linux: Using goto In Kernel Code | KernelTrap
05:33:33 <|Steve|> gwern: In that case, his response isn't trollish.
05:34:49 <|Steve|> Rereading, it's only moderately trollish.
05:34:58 <Shinta> well I havent come across any cases where I had to use goto yet except for once case when I was insining some assembly code in c++
05:35:12 <Shinta> inlining*
05:35:13 <|Steve|> Shinta: That doesn't mean it isn't useful.
05:35:37 <Shinta> well, I'd reckon we could do without it
05:35:40 <|Steve|> I gotos to great effect recently in a z80 simulator I wrote. The options were duplicate a whole bunch of code, or use a goto.
05:36:02 <|Steve|> Well, you're wrong then. Look through the source code of any OS that publishes its source.
05:36:33 <lilachaze> almost all gotos can be eliminated by either pulling some code out into a function, or adding an explicit looping construct
05:36:48 <lilachaze> the remaining cases are where you're doing something deeply weird
05:36:51 <Shinta> OSes are a different story...
05:37:18 <lilachaze> perhaps OSs have a higher proportion of deeply weird constructs
05:37:25 <|Steve|> lilachaze: That's not quite true, you can't break out of nested loops, as I mentioned.
05:37:31 <lilachaze> sure you can
05:37:35 <lilachaze> pull out a function
05:37:41 <lilachaze> and use return instead of goto
05:38:03 <|Steve|> That does not always work and it's not always practical.
05:38:19 <ndmitchell> goto is great, when used in moderation
05:38:32 <lilachaze> it works in almost all cases, and i find it usually makes the code clearer anyway
05:38:33 <|Steve|> Goto is just a tool, neither good nor bad. It's your use.
05:38:35 <ndmitchell> and the whole argument about formal correctness is a load of rubbish, you can't verify C with or without goto
05:38:46 <opqdonut> java has labeled loops and "break label;"
05:38:55 <lilachaze> perl has the same, iirc
05:38:56 <opqdonut> it's a pretty good solution
05:38:59 <vixey> oh you are still talking about goto :/
05:39:03 <ndmitchell> we teach beginners in Ada they can't break out of loops because its bad for verification, totally stupid thing to teach...
05:39:25 <|Steve|> lilachaze: So you pass all of your local variables by reference (or pointer in c) for your loop->function transformation?
05:39:34 <kryptiskt> |Steve|, that's a problem with the language. Anyway, what troubles Dijkstra isn't using gotos as a super-break, it's about using them for program flow control
05:39:37 <vixey> ndmitchell: do you teach verification though?
05:39:44 <|Steve|> lilachaze: Yes, I mentioned perl's last statement above.
05:40:15 <lilachaze> |Steve|: if i'm doing something really complicated, i'd use (depending on the language) either a nested function, or a class to hold my algorithm's state (with my functiosn being members of it), or something similar.
05:40:15 <|Steve|> kryptiskt: Yes, as part of his structured programming push. I've said that three times now. He's still wrong.
05:40:25 <ndmitchell> vixey: about 3 years later, and not in Ada, and not really verification of anything real
05:40:26 <saml> explain turing completeness in terms of categories.
05:40:37 <vixey> ndmitchell: :(
05:40:50 <chessguy> hiya ndmitchell
05:40:51 <ndmitchell> vixey: although there is a small bit about Spark Ada in one of teh advanced courses, and of course that can deal with break no problem
05:40:55 <kryptiskt> |Steve|, I don't think you understand the programming style at that time, he was right
05:40:56 <ndmitchell> hi chessguy
05:41:03 <vixey> ndmitchell: Don't functional languages make it like 100 times easier than Ada though?
05:41:13 * ToRA pitches his opinion: forward goto's are sane (early return, loop break or continue), but all backward-goto's should be explained in terms of a nicer construct (for/while/tail recursion) as they are insane otherwise
05:41:24 <|Steve|> kryptiskt: He may have been right then, that isn't my point. It doesn't hold now.
05:41:27 <chessguy> ndmitchell:  apparently no takers on my GSoC extension idea :(
05:41:29 <ndmitchell> vixey: do to verification? what verified functional languages (excluding dependent types) are you aware of?
05:41:30 <lilachaze> ndmitchell: sure, verifying c code automatically is hard. but in order for a human to understand code, they need to verify it in their heads. that seemed to be dijkstra's point
05:41:39 <ndmitchell> chessguy: seems a shame, its a very neat idea
05:41:42 <TMD> chessguy: I am a silent supporter.
05:41:48 <|Steve|> Dijkstra thought code could be proved correct.
05:41:56 <vixey> ndmitchell: oh. I think I am confused.
05:42:04 <chessguy> TMD: silent supporters are pretty much irrelevant at this stage
05:42:13 <Shinta> code cant be verified if goto is used?
05:42:27 <vixey> ndmitchell: What is verification? I was thinking about proving the programs you wrote work
05:42:29 <ndmitchell> vixey: verification should be easy for functional languages, but no one has done it, other than dependent types
05:42:30 <earthy> chessguy: you sure it's not just the wrong tie of the year?
05:42:32 <lilachaze> |Steve|: that notwithstanding, that didn't seem to be the point of his goto letter. that seemed to be saying, code with lots of gotos is fundamentally harder to reason about.
05:42:35 <TMD> chessguy: What ACTIONS can I take to help? Just an email?  A webpage?  Whats up?
05:42:36 <|Steve|> Shinta: It can't be verified anyway.
05:42:43 <ndmitchell> chessguy: find some students who want it, then the mentors will come
05:42:43 <chessguy> earthy:  how so?
05:42:48 <earthy> verification is not easy, even for functional languages
05:42:57 <saml> aren't programs translated to assembly that contains jump instruction, which is similar to goto?
05:43:00 <earthy> chessguy: holidays in many parts of academia?
05:43:11 <chessguy> TMD:  for right now, just saying on the -cafe thread that you like the idea would help
05:43:12 <|Steve|> lilachaze: And as a result, we've had generations of programmers who are taught that gotos are bad, as this conversation demonstrates.
05:43:14 * ndmitchell wants to write an automated theorem prover for Haskell - Catch is v0.001 of it
05:43:28 <vixey> ndmitchell++
05:43:31 <chessguy> earthy:  ah, i don't know, maybe
05:43:54 <TMD> ndmitchell: If you have an idea for how the developer would use the tool / what the tool would verify I'd love to hear about it.
05:44:02 <vixey> does verification mean a provably corret implementation?
05:44:14 <vixey> I was thinking about proving the programs -I- write work..
05:44:20 <ndmitchell> TMD: verify quickcheck properties, run it by typing "verify Main.hs" - that's all there is to it
05:44:27 <lilachaze> |Steve|: i think only one person here has said that they thought gotos were bad practice.
05:44:28 * ToRA is slowly writing an interactive theorem prover for ghc core
05:44:34 <earthy> 'Plover is an automated property-verifier for Haskell programs that has been under development for the past three years as a component of the Programatica project. In Programatica, predicate definitions and property assertions written in P-logic, a programming logic for Haskell, can be embedded in the text of a Haskell program module.'
05:44:36 <Shinta> think it means formally proving the program to be correct
05:44:40 <ndmitchell> and verify also means check it won't crash
05:44:44 <|Steve|> lilachaze: Both Shinta and EvilTerran did.
05:45:12 <vixey> lilachaze: I haven't said it because everybody that uses goto will not change their ways
05:45:16 <TMD> ndmitchell: So it automatically proves [expr] ==> QC prop
05:45:24 <|Steve|> You know, I think that tomorrow, er today, I'm going to spend a few minutes talking to my students about goto.
05:45:38 <|Steve|> I've been inspired!
05:45:41 <ndmitchell> TMD: yes
05:45:48 <Shinta> teach them how gotos are bad :P
05:46:01 <ndmitchell> TMD: plus the default quickcheck property of will never crash, will always produce a result
05:46:04 <TMD> ndmitchell: What happens when automated proof fails (due to program complexity, I would guess).
05:46:16 <vixey> show them how to implement for if and while using #define and goto
05:46:43 <mauke> vixey: impossible I'd say
05:46:59 <|Steve|> Shinta: You clearly haven't been listening to me.
05:46:59 <vixey> mauke, not even with macro stringification and __LINE__ ?
05:47:05 <ndmitchell> TMD: depends hwo good you can get the checker to be, either supply tactics for beefing up the checker (additional ideas to the checker), beef up the proof (additional lemmas in the program) or simplify the code
05:47:10 <mauke> vixey: no
05:47:11 <Shinta> anyways I dont think people should rely on gotos unless they have to. Its like you read a piece of code and then there is a goto in the middle sending people to the end of the function or something... it doesn't look good
05:47:15 <vixey> mauke :(
05:47:22 <mauke> vixey: I can put multiple while loops on a single line
05:47:24 <ndmitchell> TMD: for example, using Catch, its usually trivial to simplify the code to get things through
05:47:34 <vixey> mauke, grr... good point
05:47:53 <ski> teach them about continuations
05:47:58 <mauke> vixey: also, that scheme breaks in the presence of continue, break, or a preexisting label of the same name
05:48:00 <TMD> ndmitchell: yes, I've used CATCH (thanks!), but not since it release really (to much Glasgow in my Haskell).
05:48:16 <TMD> s/it/its/
05:48:55 <lilachaze> |Steve|: reading back, i can't see EvilTerran saying gotos were bad practice. e said dijkstra's letter wasn't dumb. but dijkstra didn't say they were bad practice, he just pointed out the downsides of using them...
05:50:16 <ndmitchell> TMD: yeah, its got the idea, but its not yet practical - just the direction i would go in
05:50:41 <ndmitchell> TMD: Catch is just an automatic theorem prover which happens to be optmiised towards pattern matches, but the core is perfectly general
05:50:58 <|Steve|> lilachaze: first paragraph he says they should be abolished from all high level languages.
05:51:19 <|Steve|> And by high (actually "higher") he meant anything but assembly.
05:52:04 <osfameron> what's a function to apply functions in a list to a value in turn? something like a -> [a->a] -> a  ?
05:52:47 <mauke> foldr (.) id
05:53:01 <masak> sort of the dual of map
05:53:10 <osfameron> thanks
05:53:37 <ski> map . (flip id)
05:53:56 <ToRA> sequence
05:54:06 <ski> oh .. missed "in turn"
05:54:15 <ToRA> oh, maybe not
05:56:17 <ToRA> @type foldr1 (.)
05:56:18 <lambdabot> forall a. [a -> a] -> a -> a
05:56:59 <Cale> :t foldr (.) id
05:56:59 <lambdabot> forall a. [a -> a] -> a -> a
05:57:16 <Cale> No reason to omit the base case :)
05:57:26 <ToRA> heh, indeed
05:58:31 <ToRA> @type foldr (>>>) ask
05:58:38 <lambdabot> forall (a :: * -> * -> *) b d. (MonadReader d (a b), Arrow a) => [a b b] -> a b d
06:03:10 <Axman6> @src flip
06:03:10 <lambdabot> flip f x y = f y x
06:10:00 <saml> > flip (-) 1 2
06:10:15 <lambdabot>  thread killed
06:11:00 <|Steve|> heh
06:11:07 <|Steve|> > flip (-) 1 2
06:11:08 <lambdabot>  1
06:13:02 <lilachaze> |Steve|: if i said that (n+k) patterns should be abolished from haskell, that wouldn't imply that i think they're necessarily bad practice.
06:14:21 <|Steve|> You wouldn't say that if you thought they were good practice though.
06:14:48 <lilachaze> here's the thing. i do think they are good practice in certain circumstances, but i'd prefer that haskell didn't have them.
06:15:45 <lilachaze> that's because i value haskell being small and easy to teach.
06:16:12 <ndmitchell> they are fairly random
06:16:30 <ndmitchell> 0 = -3 + 3, but they don't work that way...
06:16:31 <SamB_XP_> lilachaze: they should be removed because they don't fit ;-)
06:16:54 <SamB_XP_> they're lovely when writing maths, but not so much when writing code
06:16:56 <lilachaze> sure, plenty of good reasons to remove them, but i still use them occasionally :)
06:17:20 <SamB_XP_> you *USE* them???
06:17:31 <ndmitchell> i think view patterns could be used to somewhat the same effect, in a much more haskell way
06:17:32 <mauke> I'd rather have p++x patterns
06:17:33 <lilachaze> and i think the same is true of gotos. lots of arguments against them, but occasionally they're a really elegant way to express something.
06:17:53 <lilachaze> mauke: for some fixed p?
06:17:54 <SamB_XP_> oh, I don't think gotos should be removed from Haskell ;-)
06:17:58 <mauke> lilachaze: yes
06:18:01 <SamB_XP_> 1) too hard to remove
06:18:07 <SamB_XP_> 2) too damn usefull
06:18:25 <SamB_XP_> 3) Haskell has the prettiest gotos ever
06:18:28 <lilachaze> mauke: that'd be really handy for string constants :)
06:19:23 <SamB_XP_> so you mean c++x patterns?
06:19:36 <SamB_XP_> or ... what would p range over?
06:19:53 <Cale> SamB_XP_: What do you mean about gotos in Haskell?
06:20:03 <SamB_XP_> Cale: tail calls
06:20:19 <SamB_XP_> I especially like what we have instead of phi nodes
06:20:51 <Cale> I've never thought of tail calls as being the same as goto. Of course, it's compiled into a jump, but...
06:21:06 <SamB_XP_> Cale: you just haven't read the right papers
06:21:13 <ndmitchell> but in a lazy language, figuring out a tail call is hard to do
06:21:32 <|Steve|> SamB_XP_: What do you have instead of phi nodes?
06:21:34 <SamB_XP_> there's one about how SSA is equivalent to a certain functional language
06:21:51 <SamB_XP_> |Steve|: parameters
06:21:59 <|Steve|> lilachaze: One thing I've seen is that haskell isn't very easy to teach.
06:22:21 <|Steve|> SamB_XP_: Maybe you're using phi nodes different than I'm used to. A phi node is a conditional.
06:23:36 <SamB_XP_> |Steve|: well, aren't phi nodes just the way you say what value a variable takes on depending on how this basic block was reached?
06:24:20 <|Steve|> I hadn't thought of it that way before, but sure.
06:25:26 <SamB_XP_> I really don't like phi nodes, because they are so non-local ...
06:26:00 <|Steve|> A friend wrote a paper which he submitted to POPL this year (so like 2 weeks ago) that contains theta nodes in addition to phi nodes.
06:26:49 <SamB_XP_> anyway, you can translate an SSA program into a collection of functions, each phi-assigned variable becoming an argument, which moves the information about what value the variable gets to the jump sites...
06:27:08 <|Steve|> Makes sense.
06:27:29 <SamB_XP_> what are theta nodes? ISTR reading about a related type of node
06:27:44 <|Steve|> ISTR?
06:27:56 <SamB_XP_> I Seem To Remember
06:28:12 <|Steve|> theta nodes are just what they decided to call nodes they're using to model loops.
06:28:31 <SamB_XP_> ah. that's not the other kind of node I read about, then ;-)
06:35:12 <ski> <http://www.cc.gatech.edu/~shivers/papers/loop.pdf>, "The Anatomy of a Loop" by Olin Shivers might be interesting here ..
06:36:25 <mbz> ski: not found
06:38:24 <mauke> http://www.ccs.neu.edu/home/shivers/papers/loop.pdf
06:38:25 <lambdabot> Title: The Anatomy of a Loop
06:38:37 <ski> oh, sorry, that appears to be an old link. hopefully this works better : <http://www.ccs.neu.edu/home/shivers/papers/loop.pdf>
06:38:44 <ski> *nod*
06:39:51 <halberd> is there an Either monad?
06:40:15 <mauke> > return 42 :: Either String Int
06:40:20 <Cale> halberd: Yes, though for some reason the instance in the mtl is restricted, and there's no instance in the Prelude.
06:40:28 <lambdabot>  Right 42
06:40:46 <Jedai> halberd: There is one, it's an instance of MonadError
06:40:56 <Cale> halberd: For any type e, Either e is a monad... the definitions of bind and return are the only things they can be :)
06:41:01 <Jedai> @instances MonadError
06:41:01 <lambdabot> IOError IO, e (Either e), e (ErrorT e m), e (RWST r w s m), e (ReaderT r m), e (StateT s m), e (WriterT w m)
06:42:26 <halberd> thanks but where is this documented?
06:42:40 <Cale> In the MTL, they decided to go with making (Either e) a monad only when e is an instance of Error
06:42:45 <Cale> Control.Monad.Error
06:42:53 <Cale> and  Control.Monad.Error.Class
06:43:27 <ski> (.. oft-lamented by some people)
06:43:28 <halberd> ok thanks
06:43:30 <SamB> that was silly of them
06:43:33 <dolio> You're kind of stuck with that if you don't want to just bomb on out fail.
06:43:42 <SamB> oh yeah
06:43:46 <SamB> stupid fail being in Monad
06:44:23 <Cale> We should ignore that fail exists, as much as possible.
06:44:31 <PeakerWork> Pure/Lazy/FP makes the denotational semantics of programs easier to reason about -- but what about operational semantics? How does one reason about those?
06:44:41 <SamB> Peaker: with difficulty
06:45:26 <Cale> PeakerWork: depends on the operational semantics you choose to implement reduction with
06:45:35 <PeakerWork> Cale: ghc's :)
06:46:05 <Cale> You might want to start with reading the STG machine paper...
06:46:30 <Cale> http://citeseer.ist.psu.edu/peytonjones92implementing.html
06:46:31 <lambdabot> Title: Implementing lazy functional languages on stock hardware: the Spineless Tagless  ...
06:48:43 <PeakerWork> Cale: I tried writing a silly game solver -- and its very difficult for me to understand why use of certain denotationally-equivalent constructs causes very different operational semantics (exponential memory usage vs constant usage, etc)
06:48:44 <RayNbow> Cale: 87 pages? O_O
06:48:50 * RayNbow doesn't feel like printing that :p
06:49:48 <Cale> Actually, you don't really need to understand things at that level to understand basic things about performance.
06:49:57 <opqdonut> mhmm
06:50:04 <Cale> You just need to understand how laze evaluation works step-by-step.
06:50:06 <Cale> lazy*
06:50:17 <opqdonut> reasoning about haskell performance is pretty straightforward once you get the hang of it
06:50:23 <opqdonut> of course, the profiler is great too
06:50:40 <PeakerWork> Cale: the problem is that I am using lazy/strict constructs in the library - it seems I have to be very fluent in their internal implementation details to be able to use them -- nullifying modularity
06:50:59 <Cale> Which library?
06:51:14 <PeakerWork> Control.Monad.State and .Lazy/.Strict
06:51:30 <opqdonut> there should be better strictness "annotations" in the documentation imo
06:53:44 <PeakerWork> Cale: I had, as an experiment, put my function in the Control.Monad.State.Lazy monad, without at all using any of the monad's features -- and converting the use of the recursive results with map to mapM -- I expected this to make no difference - but it increased memory usage to be exponential
06:54:29 <Cale> Are you compiling with optimisations?
06:54:42 <PeakerWork> I tried compiling with -O3 and without it
06:54:47 <Cale> -O2
06:54:52 <mauke> -O3 is worse than -O1
06:54:57 <Cale> (though it ought to clip...)
06:55:00 <PeakerWork> confusing scheme :)
06:55:13 <mauke> well, -O3 is not supposed to exist
06:55:20 <PeakerWork> http://hpaste.org/9112 is the difference between monadic/non-monadic one, btw
06:55:38 <Cale> I'm pretty sure that in recent GHCs -O3 is the same as -O2
06:56:01 <Cale> But I can imagine why it might be like that.
06:58:57 <Cale> by the way, the appropriate monad to use here is the list monad :)
07:00:48 <PeakerWork> Cale: I actually want to keep a state - to avoid revisiting the same positions
07:01:03 <PeakerWork> Cale: maybe I need a monad transformer with both a state and the list
07:01:13 <Cale> I usually just go with parameter passing to be honest.
07:01:58 <Cale> But you can build things in terms of a state transformed list monad to work well.
07:02:17 <PeakerWork> Cale: but I need to pass this parameter between the mapped elements
07:02:22 <PeakerWork> Cale: e.g mapAccum
07:03:05 <Cale> Or foldl
07:03:13 <Cale> (foldl')
07:03:18 <PeakerWork> @type foldl'
07:03:22 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
07:04:04 <Cale> It's a strict version, so the accumulating parameter doesn't build up a huge expression.
07:05:13 <PeakerWork> so any idea why the Lazy state monad there would, even though there's no use of state, somehow build up memory usage crazily?
07:05:26 <Cale> But perhaps mapAccumL is more likely for you anyway
07:05:48 <opqdonut> PeakerWork: because it builds a pile of chunks first and then feeds the initial state into them
07:06:20 <SamB> opqdonut: do you mean perhaps "thunks"
07:06:21 <SamB> ?
07:06:28 <opqdonut> yes
07:06:41 <opqdonut> keep getting those two mixed up, lua has chunks
07:07:16 <PeakerWork> opqdonut: but wouldn't memory profiling in that case show that memory is used for thunk structures, almost exclusively?  I have seen most memory was in use by the scoped variables in the thunks
07:07:40 <opqdonut> well isn't that the same thing?
07:09:09 <PeakerWork> opqdonut: I guess it depends on how the thunks are forced
07:09:17 <opqdonut> mhmm
07:10:11 <SamB> PeakerWork: what do you mean, most memory is used by scoped variables in the thunks?
07:11:06 <ertai> does someone know if the S combinator is a shortcut for some noun?
07:11:06 <PeakerWork> SamB: Well, it seems to be holding all the data of all the thunks simultaniously before collapsing it into a small result.  Not just the "outline" of the computation (the thunks structure itself)
07:11:49 <opqdonut> you realise that the outline takes more space than the data?
07:12:22 <opqdonut> well, ok, it depends
07:12:51 <SamB> ertai: probably not in English...
07:13:06 <ertai> SamB: ok
07:20:03 <b_jonas> ertai: good question,
07:20:04 <b_jonas> um
07:20:19 <b_jonas> but I don't know
07:20:57 <b_jonas> maybe look at those papers that explain where the lambda notation originated from
07:21:17 <b_jonas> I don't even know if the name "S" was given by Church or only later
07:22:10 <fophillips> When building Haddock 2.0.0.0 on GHC 6.8.3 it says Cabal is hidden, yet `ghc-pkg` claims it isnât.
07:22:41 <lilachaze> S hit friend bob -> hit bob (friend bob)
07:22:52 <lilachaze> i guess S is like a preposition?
07:22:59 <RayNbow> http://en.wikipedia.org/wiki/SKI_combinator_calculus ?
07:22:59 <lambdabot> Title: SKI combinator calculus - Wikipedia, the free encyclopedia
07:23:03 <pjdelport> "S is a substitution operator"
07:23:37 <waern> fophillips: Haddock 2.0.0.0 doesn't build with GHC 6.8.3
07:23:41 <dcoutts> fophillips: generally that means that the package is missing a declared dependency.
07:23:43 <lilachaze> s/preposition/pronoun/
07:24:09 <dcoutts> waern: nor does 2.1.0.0 right? will there be a point release that builds with 6.8.3?
07:24:36 <waern> yep, coming up...
07:24:53 <fophillips> waern: Even with the HsModule patch?
07:25:07 <waern> fophillips: erm, that might work
07:25:42 <waern> fophillips: what OS are you using?
07:25:58 <fophillips> GNU/Linux
07:26:26 * Cale wishes that Haddock 2.x didn't have usability-destroying bugs in it.
07:26:43 <Cale> Maybe I should look into what might be causing it to obliterate all parens from type signatures.
07:26:54 <waern> fophillips: there is a 2.1.0 version. Try to get it if you can
07:27:08 <waern> Cale: did you get that bug with 2.1.0?
07:27:09 * Cale recommends Haddock 0.9
07:27:10 <Cale> yes
07:27:11 <fophillips> dcoutts: All the dependencies are installed and exposed too.
07:27:25 <Cale> I got it with 2.0.0.0 and 2.1.0
07:27:29 <waern> Cale: ok, I'll try to fix that for the next release
07:27:40 <dcoutts> fophillips: no, I mean the package itself, nothing to do with what you've got installed.
07:27:46 <dolio> Does that happen on all type signatures, or only the multi-line ones as I saw yesterday?
07:27:48 <fophillips> dcoutts: Ah
07:27:48 <Cale> great :)
07:28:04 <fophillips> dcoutts: Well this is a reinstall after an GHC upgrade, so I donât think that is it.
07:28:12 <Cale> Oh, it's possible that it only happens with multiline ones.
07:28:35 <Cale> But it obliterates them in the Synopsis as well.
07:28:56 <Cale> http://hackage.haskell.org/packages/archive/astar/0.1/doc/html/Data-Graph-AStar.html
07:28:57 <lambdabot> Title: Data.Graph.AStar, http://tinyurl.com/5m988m
07:29:00 <Cale> there's an example
07:29:57 <waern> well, Haddock now has an automized test suite, so it's going to become more stable
07:30:14 <waern> if that's any consolidation ;)
07:30:42 <ertai> pjdelport: thanks
07:30:44 <Cale> :)
07:30:55 <dcoutts> waern: give us a shout in #gentoo-haskell when you want to test your next major release. We can test it with 100's of packages.
07:31:29 <dcoutts> waern: in particular, 100's of packages that we know work with haddock-0.9
07:31:37 <waern> dcoutts: ah, that would be awesome!
07:34:09 <chrisdone> gwern: pingâ½
07:34:10 <lambdabot> chrisdone: You have 1 new message. '/msg lambdabot @messages' to read it.
07:34:16 <chrisdone> yay
07:52:06 <cnwdup> I've got a problem with MVars. I have written some kind of queue to communicate between threads much like SampleVar, but my test program fails. It seems as if the main thread isn't woken up if an empty mvar gets filled.
07:52:20 <cnwdup> http://hpaste.org/9115 is the queue module and http://hpaste.org/9116 is the test suit.
07:52:40 <cnwdup> Do you have any suggestions? I don't know why the SampleVar implementation is working and my Queue implementation isn't.
07:53:10 <uccus> hi guys, what's Luke Palmer's nick? is he around?
07:53:15 <cnwdup> (Btw. why isn't there a Queue for thread communication built in? I thought it was pretty common. Or do I miss a standard Lib?)
07:53:33 <dolio> Chan?
07:55:49 <mauke> preflex: seen luqui
07:55:49 <preflex>  luqui was last seen on #haskell 2 hours, 49 minutes and 34 seconds ago, saying: I learnt ZFC first, there's still an axiom of choice for me
07:57:51 <oldsalt> dcoutts: would it be possible to add the source-links to the 100's of packages? :-)
07:58:11 <dcoutts> oldsalt: hmm? what do you mean exactly?
07:58:33 <uccus> I am trying Luke's Omega monad and frankly I'm not very keen on using monads. can anyone help me? http://hpaste.org/9117
07:58:35 <oldsalt> the ghc libs have this source link in the function name row
07:59:19 <ixvey> uccus, you should use return
07:59:29 <uccus> didn't I?
07:59:33 <ixvey> that is, enumerate (Terminal a) = [a] ~~> return a
07:59:55 <uccus> aah... thanks trying it
07:59:57 <ixvey> they might be more to change as well after that
08:00:00 <dcoutts> oldsalt: are you talking about the haddock docs for packages on hackage?
08:00:12 <oldsalt> yes. that is what i am trying to say
08:00:37 <dcoutts> oldsalt: I was talking about the gentoo packages, using them to help test haddock. Since we have a pretty automated build and logging system.
08:00:49 <oldsalt> ah, sorry, then i got you wrong
08:00:57 <dcoutts> oldsalt: certainly it'd be nice to have the haddock docs on hackage also have source links
08:01:02 <uccus> phew! thanks ixvey... I was looking at the wrong problem ;)
08:01:21 <oldsalt> dcoutts: yes, definately. but i wonder whom to ask for it and thought you were talking about it
08:01:53 <pejo> dcoutts, is there anything lint-like or similar for packages for hackage?
08:02:26 <dcoutts> pejo: only very basic, 'cabal check' does the same checks that the hackage server does on upload.
08:03:11 <dcoutts> oldsalt: I hack on Cabal but not the current hackage-scripts really. And I've never been able to find the code that does the builds or generates the haddock docs. I suspect it's some cron job. But the source is not in the hackage-scripts repo.
08:03:33 <pejo> dcoutts, cabal check once the package is installed?
08:03:59 <dcoutts> pejo: no, in the build tree, just before you cabal sdist
08:04:08 <dcoutts> pejo: actually cabal sdist runs cabal check too
08:05:28 <oldsalt> dcoutts: that sounds weird to me. do you know who could know how to change it?
08:05:45 <dcoutts> oldsalt: Ross Patterson
08:05:49 <pejo> dcoutts, does that use darcs sdist?
08:05:55 <dcoutts> pejo: no
08:06:37 <oldsalt> is Ross Patterson sometimes in this channel?
08:06:40 <dcoutts> pejo: cabal sdist only tars up the files that are necessary, and includes any platform independent pre-processed sources
08:06:45 <dcoutts> oldsalt: no
08:07:31 <dcoutts> pejo: and it works on windows as it uses it's own internal tar code, so generates standard tar files rather than gnu tar files.
08:07:39 <oldsalt> dcoutts: ok, thank you
08:08:09 <dcoutts> oldsalt: though I'm also working on a new hackage-server prototype which will do the haddock stuff a bit differently.
08:09:21 <oldsalt> dcoutts: and then you would be able to add it? that would be awesome...
08:09:37 <pejo> dcoutts, is 'cabal' something from an extra package, or in a more recent cabal than the one delivered with ghc 6.8.2?
08:09:47 <dcoutts> oldsalt: though it'll be some time before that prototype is up to speed
08:10:06 <dcoutts> pejo: it's the command line tool in the cabal-install package.
08:10:49 <dcoutts> pejo: we had to name the package cabal-install since the lib is already called Cabal, sorry it's a tad confusing
08:11:05 <pejo> dcoutts, hm. So I can't use gnu tar for packaging stuff? And I need cabal-install to create packages?
08:11:21 <dcoutts> pejo: you can use gnu tar
08:11:40 <dcoutts> pejo: and runghc Setup.hs sdist also works (and uses gnu tar)
08:11:57 <oldsalt> dcoutts: alright, then maybe i will try to annoy ross patterson
08:13:47 <dcoutts> pejo: you don't have to use cabal-install, it's just much easier
08:14:18 <dcoutts> pejo: it's only in a few cases that we add new command line features and we add it to cabal-install and not the runghc Setup.hs command line interface
08:14:23 <dcoutts> like 'check'
08:16:04 <pejo> dcoutts, ok, thanks a bunch. I'll give it a spin.
08:16:42 <dcoutts> pejo: the main bonus is that it lets you 'cabal install foo bar' any packages from hackage, including deps
08:18:17 <pejo> dcoutts, I'm looking forward to HLP, for now I just want to create a cabalized package and do other stuff. :-)
08:18:39 <dcoutts> @localtime dons
08:18:43 <jganetsk> question, i'm an ML guy, and i'm curious as to the performance characteristics of thunking in haskell
08:18:44 <lambdabot> Local time for dons is Wed Jul 23 08:18:42 2008
08:18:54 <jganetsk> doesn't it present a large performance hit?
08:19:23 <dcoutts> jganetsk: it depends on the circumstance. It also allows designs that would be otherwise unworkable.
08:20:31 <dcoutts> jganetsk: people do it in other languages too, they just do it by hand at great verbosity
08:20:49 <dcoutts> jganetsk: they call it a on-demand pattern or something
08:21:00 <jganetsk> dcoutts: but since you can't turn it on, the cost of thunking is felt throughout the program
08:21:09 <jganetsk> dcoutts: i mean, since you can't turn it off
08:21:19 <Shiruka> you can use strictness annotations or seq
08:21:27 <jgw> <dons> i encourage people to downmod this, http://www.reddit.com/r/programming/comments/6t1k5/Why_your_favorite_language_is_unpopular_The_total/
08:21:29 <lambdabot> Title: Why your favorite language is unpopular - "The total world's population of Haske ..., http://tinyurl.com/5cjzz2
08:21:34 <dcoutts> jganetsk: except where it's not necessary when the code is strict, and the compiler then sees that it does not need to thunk
08:21:34 <jgw> dons: i went ahead and upmodded this
08:21:38 <jgw> ;)
08:21:47 <jgw> dukes of haskell r teh dead
08:21:52 <opqdonut> dolio: yeah seemed pretty poor
08:22:02 <dolio> Huh?
08:22:37 <opqdonut> grah
08:22:43 <opqdonut> dons: yeah seemed pretty poor
08:22:45 <opqdonut> the article
08:22:53 <opqdonut> dolio: sorry, tab complete bit me again
08:23:00 <dolio> :)
08:23:30 <dolio> It's mostly my fault. I should change my name to zzzzz.
08:24:12 <dolio> Of course, then I'll get messages for zzzzzz.
08:24:51 <dons> jgw, well the article got a lot of coverage, so at this point its working better as marketing/name awareness.
08:24:51 <lambdabot> dons: You have 2 new messages. '/msg lambdabot @messages' to read them.
08:25:52 <pejo> jganetsk, laziness comes at a cost, there's a lot written about this. Want starting pointers? On the other hand, GHC is getting awfully good at optimizing things nowdays.
08:26:30 <dons> laziness isn't ubiquitous either, ghc only puts it where it decides it is needed.
08:26:58 <pejo> dons, that has to be undecidable?
08:27:14 <Shiruka> AFAIK the biggest speed hit you can't eliminate is the somewhat dubious quality of the low-level code generated by ghc, but I seem to recall hearing that it's supposed to improve in 6.10
08:27:21 <jganetsk> but doesn't it need thunks to call any non-inlined function?
08:27:43 <dons> no.
08:27:46 <Shiruka> (well, "can't eliminate" except with FFI that is)
08:28:09 <dons> Shiruka: its already awfully good. some of the best benchmarks on the shootout use -fasm
08:28:24 <jganetsk> dons: explain? doesn't every function expect thunks for args?
08:28:39 <Shiruka> dons: .. is it architecture dependent then?
08:28:48 <dons> jganetsk: yes, notionally, but strict things have non-thunk register passing of values instead.
08:28:53 <dons> which is remarkably common.
08:29:06 <dons> only if it is fully unambiguously lazy will you have ptr->heap object passed
08:29:10 <Shiruka> when I last looked at disasm of ghc on x86, it didn't even keep variables in tight loops in registers
08:29:19 <hackage> Uploaded to hackage: uhexdump 0.2
08:29:20 <dons> Shiruka: oh, check out this post,
08:29:34 <vixey> is 6.9 good yet?
08:29:43 <dons> some tight loop issues remain, but already a lot of things work just fine.
08:29:55 <dons> Shiruka: http://cgi.cse.unsw.edu.au/~dons/blog/2008/05/16#fast
08:29:56 <lambdabot> Title: Haskell hacking
08:29:58 <jganetsk> pejo: i'll look at starting pointers, and i also dont' know much about declaring strictness
08:30:43 <Shiruka> ah, but that uses floats
08:31:02 <Shiruka> the code I was looking at used ints
08:31:14 <dons> there's few registers on x86 left over, that's true. like hmm 2?
08:31:17 <Shiruka> and on x86 the register sets are different for those, ints go to general-purpose regs
08:31:31 <Shiruka> yeah :-) sucky architecture, admittedly
08:31:34 <dons> so it'll have a hard time getting things in there on x86, i think that's a known problem with hte old register allocator.
08:31:49 <dons> since half the regs are already used for heap ptrs and so on
08:32:17 <Shiruka> I suppose x86_64 works much better?
08:33:04 <dons> i think Simon said that yes, that is the case.
08:34:22 <pejo> Shiruka, the cost for garbage collecting is greater there though.
08:34:37 <Shiruka> unless you don't produce much garbage in your inner loop :-)
08:35:22 <Shiruka> it's mostly interesting for stuff like generating fast code using template haskell or stream fusion -like things
08:35:36 <Shiruka> (it = quality of low-level codegen)
08:35:47 <pejo> shiruka, sure, but the cost of gc is relative to the amount of live memory. (On the ohter hand you might avoid triggering a gc in your tight loop if you don't produce garbage).
08:37:40 <Shiruka> interesting to see how much it can be improved with parallelization
08:38:05 <jganetsk> can anyone point me to reading about the performance hit of laziness?
08:39:00 <Shiruka> I haven't seen any papers on that, unfortunately :-(
08:39:23 <jganetsk> pejo said there is a lot of literature on teh cost of laziness
08:42:16 <Shiruka> dons, btw, the paper on stream fusion was your paper, right? were the ghc optimization issues mentioned in the end eventually resolved?
08:44:06 <dons> yeah, we think things are solved now.
08:45:12 <Shiruka> will it ever become the standard list implementation? :-)
08:47:17 <pejo> jganetsk, there's a thesis by Urban Boquist from the late 90's that covers the issues very well. Robert Ennals thesis on optimistic evaluation is more recent. The pointer tagging paper is the most recent stuff I'm aware of. (http://www.haskell.org/~simonmar/papers/ptr-tagging.pdf)
08:47:18 <lambdabot> Title: Faster laziness using dynamic pointer tagging
08:48:19 <thoughtpolice> pejo: "Code optimization techniques for lazy functional languages"?
08:48:42 <dons> wooot!!!!!!!!!!!!!!
08:48:43 <dons> http://www.reddit.com/comments/6t3pa/Sun_Microsystems_funding_Haskell_on_multicore/
08:48:44 <lambdabot> Title: Sun Microsystems funding Haskell on multicore OpenSPARC! : reddit.com, http://tinyurl.com/57kvkn
08:48:52 <dons> YOU CAN UPMOD THAT!! ;)
08:49:09 <therp> ik, sun. I rather downmod that.
08:49:22 <jganetsk> is everyone here in academia?
08:49:26 <dons> jganetsk: nope.
08:49:43 <jganetsk> do you have a job requiring the use of haskell?
08:49:46 <dogbite> we all just wish we wer ein academia
08:49:47 <dons> yeah.
08:49:48 <thoughtpolice> it's better to have sun supporting something than nothing, as far as I'm concerned
08:49:48 <jganetsk> nice
08:49:51 <uccus> quick question: I need to print a list (of strings) to a file... elements one by one. what do I do? recursive functions are not the way to go as far as I get it
08:50:05 <dogbite> map print
08:50:13 <dons> they have given us a T2 and money to get ghc exploiting all the tricksy parallelism instructions
08:50:20 <dons> so hooray, corporate backing where it counts.
08:50:21 <vixey> uccus: recursive is the way
08:50:24 <thoughtpolice> map writeFile ?
08:50:27 <uccus> my list is infinite and hence would need flushing
08:50:38 <thoughtpolice> dons: who will be leading the way?
08:50:48 <dons> read the announce. its an application process.
08:51:05 <dons> people are invited to apply to work on the sparc port.
08:51:10 <mauke> uccus: hPutStr fh (concat strings)
08:51:38 <uccus> concat strings would work? wow ... yeah of course it would... hPutStr is lazy?
08:51:38 <byorgey> wow, sweet!!
08:51:48 <dons> byorgey: yeah mega awesomo!
08:51:52 <uccus> but I need to flush in between! :(
08:51:59 <pejo> thoughtpolice, I don't remember the title, but it's somewhere on www.cs.chalmers.se/~boquist.
08:51:59 <mauke> uccus: why?
08:52:29 <uccus> because the list is infinite and it would never end... I plan to just interrupt it sometime
08:52:50 <uccus> no specific plan for systematic quitting
08:52:57 <thoughtpolice> dons: awesome. i was looking at the NCG a few days ago to see if there were any easy trac bugs to fix, working on a sparc port would be fun.
08:55:02 <Shiruka> hm, the platform description sounds like it uses hyperthreading
08:55:50 <Shiruka> I wonder how well you can exploit that automatically
08:56:08 * dcoutts encourages everyone to mod up http://www.reddit.com/r/programming/comments/6t3pa/Sun_Microsystems_funding_Haskell_on_multicore/
08:56:09 <lambdabot> Title: Sun Microsystems funding Haskell on multicore OpenSPARC! : programming, http://tinyurl.com/5p7vjj
08:56:21 <dons> :)
08:56:32 <dcoutts> it's really a pretty amazing machine
08:56:45 <dcoutts> and they've given us loads of dosh for a student
08:57:05 <pejo> Shiruka, same concept as HT atleast.
08:57:16 <dcoutts> not really
08:57:23 <therp> hmm $10k is pretty much
08:57:31 <dcoutts> it's 8 cores, but each core multiplexes threads
08:57:39 <dcoutts> that's not the same as hyperthreading at all
08:57:55 <dcoutts> when one thread blocks due to a memory read, the next thread runs
08:58:06 <pejo> dons, who applied for/got the grant?
08:58:06 <dcoutts> so it hides memory latency
08:58:10 <dcoutts> pejo: me
08:58:20 <dons> pejo: dcoutts did all the work.
08:58:20 <Spark> the reason for choosing haskell seems to be "it has threads, locks, and STM"
08:58:22 <therp> dcoutts: congrats
08:58:25 <Spark> but so do lots of other languages
08:58:27 <Shiruka> but HT hides memorly latency by thread switching too
08:58:30 <dcoutts> pejo: and we'll give it to the best student that applies
08:58:34 <pejo> dcoutts, isn't that exactly what HT does, hides memory latency by executing different stuff?
08:58:34 <Shiruka> *memory
08:58:57 <dons> anyone hang out on LtU? the announce is probably worth talking about there.
08:59:07 <Spark> 16:57 < dcoutts> when one thread blocks due to a memory read, the next thread runs
08:59:10 <Spark> that is hyperthreading
08:59:27 <Spark> it only brings a performance benefit if your code is not cache friendly
08:59:29 <Shiruka> I seem to recall that HT is doing a comeback in future intel processors, btw :-)
08:59:32 <pejo> Spark, most other languages aren't pure though.
08:59:34 <dcoutts> Spark: ok, well whatever the definition it's not like Intel's hyperthreading
08:59:47 <therp> dons: I do, but I'd say it's offtopic for LtU
08:59:57 <Spark> but it's quite hard to make cache-friendly code written in high level languages
09:00:01 <pejo> dcoutts, great work on landing the grant!
09:00:02 <therp> dons: probably ok for the forums though
09:00:08 <dons> therp: ah maybe.
09:00:11 <reilly> The Wikipedia page on Intel hyperthreading is entirely consistent with Spark's description
09:00:27 <dcoutts> pejo: ta
09:00:28 <dons> these are true threads in hardware.
09:01:02 <geezusfreeek_> :( too bad i am not familiar with sparc or the ghc back end at all
09:01:03 <vixey> what sort of background do you need to be able help with this opensparc thing?
09:01:06 <dcoutts> Spark: right, so hiding latency by threading is an interesting alternative approach
09:01:22 <vixey> oh "code generation for RISC instruction sets" rules me out
09:01:31 <dcoutts> vixey: right, RISC assembly
09:01:52 <Spark> dcoutts: they share cache though so you have to be quite careful
09:02:04 <Spark> of course sharing cache is a good thing if the threads are doing the same thing
09:02:11 <dcoutts> Spark: right
09:02:13 <reilly> Where's this 747 we're supposed to have, anyway?
09:02:26 <dcoutts> vixey: the larger part of the project is working on ghc's native code generator
09:02:59 <dons> reilly: at galois' top secret headquarters.
09:03:08 <dons> also a hovercraft of immense proportions
09:03:13 <reilly> cool
09:03:18 <dons> but i can't talk about the moon shot program.
09:03:39 <reilly> you just did
09:03:40 <MyCatVerbs> reilly: didn't you get the memo? Please immediately start inducting random passers-by into our cult.
09:03:46 <Spark> i think the only interesting thing about multithreaded haskell is the potential for implicit parallelism, but the last talk i saw suggested that laziness meant it was quite hard to get much extra performance, even if many cores were being utilised 100%
09:04:07 <MyCatVerbs> reilly: if we can get the numbers up within the next few weeks, we'll be able to fund a brand new A380. Much nicer than that old 747.
09:04:07 <dogbite> dons: what about the submarine?
09:04:12 <dons> Spark: hmm, I don't think that's how you'd characterise it.
09:04:20 <Spark> because the work ends up duplicated on the cores
09:04:25 <dons> Spark: if anything, you need more laziness. strict, straightline code is hard to parallelise.
09:04:38 <dons> its those pure thunks that can be speculatively eval'd.
09:04:39 <reilly> The 747 is fine if you're in the front cabin.
09:04:53 <Spark> i can't remember the details, but their bar graphs weren't very impresive
09:04:59 <vixey> I wonder if ill ever write some -useful- code
09:05:04 <dons> i guess that rules Spark out for the job then.
09:05:21 <Spark> is there any work where they took a real world haskell program and incraesed its performance in line with the number of extra cores?
09:05:33 <pejo> dons, think you forgot an "impure" somewhere in the strict part?
09:05:37 <Shiruka> hmm, sounds a bit different from what I read in some papers written by the simon squad
09:05:39 <dons> Spark: yeah, see the ndp paper.
09:05:49 <dons> array/numerics ops scaling up on a 32 core Sun box.
09:05:53 <Shiruka> IIRC they said that the duplication of work is not significant
09:05:58 <Spark> entire programs though?
09:06:14 <dons> ones written for parallelism, yes. but there's not a lot.
09:06:42 <dons> but there's weekly posts on -cafe@ of people having fun utilising all their 2 or 4 cores.
09:06:57 <Apocalisp> dons's parallel fibs program is an enitre program, no?
09:07:07 <dons> cheap threads, natural parallelism, high level locking abstractoins. its all fun.
09:07:18 <dons> Apocalisp: but that's just a tiny benchmark.
09:07:19 <dolio> Not a very exciting program. :)
09:07:30 <Apocalisp> Depends on your perspective
09:07:36 <geezusfreeek_> it is if you're into parallelism
09:07:45 <Spark> i'm not sure you can call it implicit concurrency if you have to design the program for concurrency :)
09:08:07 <Shiruka> um, completely automagick parallelism for arbitrary programs is a pipe dream :-)
09:08:12 <dons> Spark: you know there's *no* implicit parallel solution out there that doesn't at least require changing algorithms.
09:08:13 <vixey> yeah looks like all the pH stuff was given up on
09:08:25 <vixey> Shiruka, why ?
09:08:26 <dons> data parallel haskell needs you to use parallel arrays , for example.
09:08:30 <dons> that's about as light as the changes get
09:08:33 <uccus> can someone explain this? http://hpaste.org/9119
09:08:49 <Shiruka> you have to have some consideration given to parallelism, one interesting way is to write in a restricted sublanguage (such as using parallelizable arrays etc)
09:09:10 <Spark> ah i think these guys didn't require any changes, which is probably why their performance was poor
09:09:12 <Shiruka> vixey: well, there's been a lot of research on that, and I hear it didn't really go anywhere
09:09:25 <dons> Spark: you're thinking of the implicit parallelism paper by Satnam singh.
09:09:30 <dons> thunks were speculatively evaluated
09:09:42 <dons> and that worked for unchanged programs up to about 3 or 4 cores.
09:09:51 <dons> ?go the limits of implicit parallelism singh
09:09:55 <lambdabot> Plugin `search' failed with: No Location header found in 3xx response.
09:09:58 <dons> ?go the limits of implicit parallelism singh
09:10:00 <dons> 3xx huh.
09:10:05 <lambdabot> Plugin `search' failed with: No Location header found in 3xx response.
09:10:19 <vixey> Shiruka, I think that is true, but not reason to suggest this is impossible
09:10:21 <dolio> @yarr!
09:10:22 <lambdabot> Well Ahoy! thar.
09:10:23 <Spark> dons: yeah that was it
09:10:29 <Spark> i was just googling for it
09:10:31 <thoughtpolice> past a certain point you have to control the granularity of the parallelism, otherwise you waste threads on things too trivial and overall you don't get an optimal solution
09:10:33 <Spark> i couldn't find it though
09:10:43 <dons> Spark: so the main thing there was they need *more* lazy thunks to have enough jobs to run.
09:10:44 <Shiruka> vixey: I think it's the reasonable default position until someone proves otherwise, like assuming P != NP :-)
09:10:48 <geezusfreeek> uccus: you didn't happen to redefine (;) did you? ;)
09:11:01 <dons> Spark: and the analysis was inserting `par` calls into programs.
09:11:12 <dons> so its a runtime-profiling transformation
09:11:18 <Spark> i remembered where i saw the talk - it was fun in the afternoon, feb 2008
09:11:22 <uccus> no I didn't! it has to do something with 'do' not understanding what I want to
09:11:24 <Spark> yeah they needed the profiling data
09:11:30 <pejo> Shiruka, the fact that a lot of research has gone into something doesn't mean it's impossible, just means nobody has come up with a good solution yet.
09:11:56 <Apocalisp> dons: https://projects.workingmouse.com/public/functionaljava/trunk/etc/demo/1.5/concurrent/Fibs.java
09:11:58 <lambdabot> http://tinyurl.com/65ldp4
09:12:15 <geezusfreeek> oh i was getting your two cases wrong. i see now that it's the _other_ case that fails
09:12:29 <Shiruka> true, but one does well not holding their breath until a solution arrives.. there's a long time between Fermats and Wileses
09:12:41 <Shiruka> (and you might end up with GÃ¶del instead of Wiles)
09:12:43 * Apocalisp flashes a picture of the maw of evil
09:12:45 <thoughtpolice> i think it's something to keep an eye on, but I'm not expecting anything breaking by next week
09:13:03 <thoughtpolice> in the mean time we might as well be looking into ways to making it easier, instead of totally implicitly done by the compiler
09:13:06 <Saizan_> uccus: you're probably mixing tabs and spaces in your file and so ghc sees a different layout
09:13:20 <Spark> thoughtpolice: the granularity thing is where the profiling was supposed to come in, though
09:13:30 <Spark> compiler optimisations already have problems with that, e.g. inlining and loop unrolling
09:13:43 <uccus> Saizan: that must be it. thanks.
09:13:50 <Spark> so you either mark the long/short bits or plumb the profiling data back into the compiler
09:14:16 <Spark> the singh paper's approach to implicit parallelism seems to be comparable
09:14:25 <vixey> the pH book was really nice
09:14:43 <thoughtpolice> Spark: I'll look into it :)
09:17:00 <vixey> that functionaljava thing is so awful
09:17:13 <Apocalisp> That's Java's fault
09:17:29 <vixey> no it's not
09:17:41 <Spark> closures != functional programming
09:17:55 <Apocalisp> I concur
09:18:12 <Spark> and the problem is bureaucracy
09:18:43 <Spark> sun really doesn't want to change java
09:18:48 <Apocalisp> vixey: Do you have suggestions for improvement?
09:18:53 <vixey> why on earth would anyone do this
09:18:56 <Spark> it costs them lots of money
09:19:03 <vixey> yes
09:19:12 <vixey> use a functional language
09:19:28 <Shiruka> or use Ada to write functional programs
09:19:38 <Spark> it's nothing to do with "functional"
09:19:39 <Shiruka> Okasaki does that, so it must be a good idea
09:19:50 <Spark> it's just people wanting closures because they're nice
09:20:08 <Spark> you could strip closures from haskell and it would still be functional
09:20:08 <Apocalisp> Well, there's Scala. Not purely functional though.
09:20:23 <vixey> java can already close over variables (inner classes)
09:20:38 <Spark> vixey: i like to call that "poor man's closures" :)
09:20:49 <Shiruka> functional programming without closures? my imagination fails me..
09:20:49 <Apocalisp> vixey: The idea is to make Java at least remotely usable, today.
09:20:55 <vixey> I call it inner classes
09:21:03 <vixey> I don't think in fp terms when I program in a non-fp language
09:21:14 <Spark> closure is not a functional programming term
09:21:21 <Spark> i think i'll stop saying this soon as it's not sinking in
09:21:38 <vixey> sorry this is completely off topic, I was just surpised by this horrible misuse of the language
09:21:48 <Toxaris_> isn't closure about implementation?
09:21:53 <dolio> Even when Sun (?) does want to change Java, they get a lot of hate mail for it. :)
09:22:02 <Apocalisp> Java was asking for it. :)
09:22:08 <Apocalisp> It had it coming.
09:22:18 <Spark> Toxaris_: when state is an implementation detail, yes, but when state is part of the semantics, no :)
09:22:48 <Spark> < Shiruka> functional programming without closures? my imagination fails me..
09:22:58 <Shiruka> yeah, closures are about implementation.. all sane languages either have closures or they are called (possibly portable) assembly ;-)
09:23:01 <Spark> it's useful to separate things out
09:23:58 <vixey> Spark: it's not helping to improve communication
09:24:07 <Spark> communication between whom
09:24:08 <vixey> Spark: I don't think it's useful to be pendantic about this
09:24:16 <Shiruka> is your point something like "haskell is a strict, not a lazy language" level thing?
09:24:21 <Spark> if people can't even agree what "functional" means then we have a problem :)
09:24:34 <vixey> Spark, us ... the people having a conversation ..
09:24:48 <Toxaris_> Spark: functional is a very very overloaded term
09:24:52 <vixey> haskell is non-strict :p
09:25:07 <Toxaris_> Spark: so much that there is basically no meaning left
09:25:24 <Shiruka> vixey: oops, that's what I meant, obviously :-P
09:25:35 <chrisdone> it has meaning when compared to âimperativeâ or âproceduralâ
09:25:40 <Spark> maybe we should stop using it altogether then :)
09:25:42 <Associat0r> disfunctional
09:25:47 <Spark> that and "declarative" too
09:25:56 <Spark> i don't actually like the terms anyway
09:25:59 <vixey> no just define the term
09:26:02 <chrisdone> Associat0r: dysfunctional?
09:26:12 <Apocalisp> isn't Haskell an imperative language too ?
09:26:20 <Spark> you could say a language is functional if all its expressions are referentially transparent
09:26:21 <Shiruka> the world's finest, yes
09:26:28 <Spark> but that excludes erlang
09:26:28 <Shiruka> (allegedly)
09:26:46 <Toxaris_> chrisdone: what is "procedural"?
09:26:48 <Spark> i don't think erlang is functional anyway though
09:26:59 <vixey> Spark: yeah that's a completly wrong definition
09:27:11 <Toxaris_> chrisdone: I think these terms make sense for programming styles, not for languages
09:27:14 <chrisdone> toxaris: a synonym for "imperative"
09:27:14 <Shiruka> classifying languages that way is somewhat futile these days
09:27:18 <dolio> Erlang is object oriented, clearly.
09:27:20 <Spark> well if your definition of functional is "the language has closures"
09:27:23 <Spark> dolio: yeah :)
09:27:24 <Shiruka> most languages are more or less multi-paradigm anyway..
09:27:24 <dons> heh, we just passed 1.5M hits on haskell.org's front page.
09:27:25 <Toxaris_> Spark: so why not say "referentially transparent" if that is what we mean
09:27:40 <Spark> dolio: well, without inheritance and stuff
09:27:47 <dolio> :)
09:27:55 <Spark> it's a primitive form of active objects
09:28:03 <Apocalisp> "actor-orientated"
09:28:17 <pejo> Shiruka, Amr Sabry wrote an article called "What is a purely functional language?". Interesting read.
09:28:20 <Spark> vixey: well if your definition of functional is "the language has closures" then that's not a good definition either :)
09:28:22 <Toxaris_> chrisdone: but what about "imperative" languages without callstack, recursion, ... (e.g. turing machines)
09:28:38 <vixey> Spark: ...
09:28:39 <chrisdone> toxaris: what about them?
09:28:44 <vixey> Spark: where did tha come from
09:28:44 <Shiruka> pejo: thanks, I'll look at it :-)
09:28:50 <vixey> Spark: I have never said anything like that
09:28:53 <Toxaris_> chrisdone: I would consider them "imperative", but not "procedural"
09:29:01 <chrisdone> toxaris: that's fine
09:29:12 <pejo> Shiruka, (but he tries to answer what purity is about, not what fp is about).
09:29:19 <hackage> Uploaded to hackage: HXQ 0.8.4
09:29:19 <hackage> Uploaded to hackage: rosezipper 0.1
09:29:21 <Toxaris_> chrisdone: so how can "procedural" be a synonym for "imperative" if the concept have different extension?
09:29:23 <Shiruka> I assumed as much
09:29:29 <Spark> vixey: we were talking about "functional" java
09:29:43 <Spark> vixey: what is your definition then
09:29:55 <vixey> Spark: I haven't even mentioned closures once
09:29:55 <chrisdone> toxaris: well, âproceduralâ can mean âimperativeâ
09:30:02 <PeakerWork> is the Simon Peyton Jones paper from 92 (spineless tagless G-machine) linked by Cale similar at all to how things work nowadays in ghc?
09:30:09 <Spark> vixey: you implied it "I don't think in fp terms when I program in a non-fp language"
09:30:41 <Apocalisp> the "Functional Java" library just adds first-class lambdas. No purity, but that's not achievable anyway in that language.
09:30:57 <vixey> no I didn't
09:31:00 <Toxaris_> chrisdone: yeah, and similiar, functional can mean "referentially transparent" or it can mean "allows functions with proper tail-recursion" or 100 other things depending on context and who you ask
09:31:25 <Shiruka> AFAIK STG machine hasn't disappeared anywhere, but there are some changes caused by parallelism and some new optimizations at least (see the pointer tagging paper at least linked to here a bit earlier today)
09:31:32 <Toxaris_> chrisdone: so there is no information left, just as with "procedural", it can mean "there is a callstack" or it can mean "there are no objects"
09:31:35 <pejo> Peaker, well, the pointer tagging paper added back the tags.
09:31:39 <Shiruka> I haven't looked at GHC code itself though
09:31:42 <chrisdone> toxaris: well, I would make a distinction between imperative, functional and logic languages
09:32:13 <vixey> chrisdone: and you would stop there?
09:32:28 <Spark> chrisdone: is ML functional?
09:32:35 <Toxaris_> vixey: is prolog imperative?
09:32:36 <chrisdone> I don't know ML
09:32:46 <Spark> chrisdone: there are too many grey areas :)
09:32:48 <Toxaris_> vixey, chrisdone: sorry, I meant to ask chrisdone, of course
09:33:10 <reilly> ML is functional, strict, and impure
09:33:12 <chrisdone> toxaris: I would put prolog in "logic"
09:33:22 <Spark> so what's the point of "impure functional"
09:33:46 <Spark> the language makes an effort to be functional but then allows you to subvert it... it's not guaranteeing you anything anymore
09:33:49 <reilly> higher order functions still have expressive value in an impure environment
09:33:54 <Spark> that's like java if you make 90% of things final
09:34:00 <vixey> ML the programming language  or  ML the type system  or  ML the calculus ? :p
09:34:03 <Shiruka> ah, but haskell is also impure functional, as it has FFI and unsafePerformIO ;-)
09:34:25 <Apocalisp> vixey: I think you compartmentalise. The barrier between FP and non-FP is artificial I think
09:34:25 <lilachaze> or ML the idiomatic subset of the programming language even?
09:34:27 <Toxaris_> chrisdone: but in prolog, you write "what the computer should do", like "if you see this in the head of a goal, first output "hello", then compute 3+5, then cut, then unify this, then ..."
09:34:30 <pejo> vixey, are you making a distinction between the implementations and the semantics now?
09:34:37 <Toxaris_> chrisdone: quite imperative for me :)
09:34:49 <Spark> reilly: that's my point really, i think functional programming and HOFs are orthogonal
09:34:50 <Shiruka> but anyway you can write pure programs in impure languages such as ML
09:35:42 <Toxaris_> imho there is FP = Functional Programming, but there is no such thing as a "functional programming language"
09:35:45 <Spark> you can even write pure programs that internally are impure :)
09:36:03 <Spark> Toxaris_: that seems reasonable, but still pretty hard to define i think
09:36:06 <Apocalisp> Toxaris: That makes sense
09:36:15 <chrisdone> toxaris: well, I think you are looking into it too much to the point of meaninglessness. languages generally have a specific kind of use, imo. if a language supports some thing X on the side does not mean that it is in the general X
09:36:19 <Spark> Toxaris_: is it about the API or the implementation of a particular set of code
09:36:21 <Shiruka> all pure programs are internally impure, as they use primitives implemented impurely by the implementation :-)
09:36:43 <Toxaris_> Shiruka: consider pure hardware
09:36:46 <Apocalisp> Shiruka: shh!
09:36:47 <reilly> Spark: I think "functional programming" is defined by more than the avoidance or prohibition of side-effects
09:36:54 <Shiruka> so trying to make distinctions may degenerate into useless philosophy quite easily..
09:36:55 <Spark> chrisdone: that's a subjective argument, one person's idea of the "core" features of a language might be different to yours
09:37:19 <chrisdone> spark: that's why we talk about it to agree on terms
09:37:22 <Toxaris_> Spark: it's a programming methodology, e.g. a theory which describes how programmers should do their job
09:37:30 <vixey> Haskell and Ocaml are functional programming languages
09:37:35 <Spark> chrisdone: what about the people who aren't present in the discussion :)
09:37:46 <chrisdone> spark: what about them?
09:37:54 <reilly> Spark: like any expressive paradigm, it is a loose set of characteristics that isn't rigidly defined
09:37:59 <Toxaris_> Spark: therefore, there are no "functional programs", just "functional programming"
09:38:24 <Spark> i like the way the term is being pushed further from language theory and closer to social science :)
09:38:36 <Spark> soon it will be "there are just functional programmers"
09:38:45 <Toxaris_> I disagree with this step
09:38:45 <Shiruka> yeah, FP makes most sense considered as a style
09:38:59 <Apocalisp> I like Meijer's take on this, about honesty in types being the essential.
09:39:10 <reilly> Spark: I've met a lot of non-functional programmers ...
09:39:11 <Spark> so would you support a motion saying that haskell should stop calling itself a functional programming language? :)
09:39:31 <Apocalisp> Haskell: Purely Honest.
09:39:35 <Toxaris_> the same person can do functional and imperative programming, even at the same time working on the same program
09:39:41 <Toxaris_> (consider dons working on Bytestring)
09:39:44 <Spark> yeah this is true
09:39:59 <Apocalisp> (except for unsafePerformIO, but you know the first rule of unsafePerformIO)
09:40:02 <pejo> Apocalisp, that disqualifies shceme.
09:40:36 <Shiruka> I don't think types are a necessary feature of FP, but then I'm just a heretic..
09:40:43 <Apocalisp> pejo: I'm not going to lose any sleep over that. But it does have a kind of honesty in that it doesn't lie.
09:41:27 <Toxaris_> I think "thinking about the type of something" is an important feature of functional programming, whether it is supported by the language or not
09:41:31 <Shiruka> a program is pure regardless of whether the compiler can understand/verify that or not :-)
09:41:46 <Apocalisp> Meijer's point was (I think) that it's not about functional/imperative, but honest/dishonest.
09:41:51 <Spark> i personally just think of languages in terms of sets of features, but that is flawed since different features are not always orthogonal - they have synergy and they conflict sometimes too
09:42:06 <chrisdone> toxaris: I'd say the difference between imperative and functional is mutation. if you consider kinds of languages that offer ways of thinking about programming, you could consider imperative, functional and logical (and maybe stack-based)
09:43:00 <Shiruka> in the end it's about what kinds of tools you have to support a specific style of programming
09:43:12 <dolio> Joy is a stack-based functional language.
09:43:25 <Toxaris_> chrisdone: mutation is a very important feature, but I don't see it as usefull to use "imperative, functional and logical" when I mean "mutable state, purity and unification"
09:43:26 <Shiruka> the tools a compiler provides are limited, because there's only so much you can implement.. including features as well as optimizations
09:43:28 <chrisdone> dolio: and Lisp is a âfunctional imperative languageâ?
09:43:31 <vixey> Joy should be called misery
09:43:49 <chrisdone> :)
09:43:49 <vixey> Lisp is ... procedural
09:43:55 <dolio> I don't know what you'd call Lisp.
09:44:05 <chrisdone> mostly imperative
09:44:05 <Apocalisp> metamagical
09:44:07 <Toxaris_> Shiruka: indeed, that's how the discussion here started. If I add a toolset to support FP to Java, does that make Java a functional language
09:44:09 <vixey> I would call it procedural, that's most accurate
09:44:30 <Jedai> I don't think types are an intrinsic part of functional programming, though I think that functional programming helps to have expressive and clear typing system
09:44:32 <Shiruka> Toxaris_: if the toolset is sufficiently good, then IMO yes
09:44:54 <Shiruka> the toolsets I've seen for it doing FP are utterly ridiculous though
09:45:10 <Spark> Toxaris_: i think the key difference between logic languages is the way the semantics is based around the idea of exploring a space to find an answer, not that you can do unification in pattern matching
09:45:28 <Toxaris_> Spark: are you talking about datalog or prolog
09:45:28 <Apocalisp> Jedai: Types are intrinsic, but not necessarily explicit :)
09:45:29 <Jedai> Lisp support functional programming much better than most mainstream languages, but it is multi-paradigm (as OCaml is)
09:45:32 <vixey> a library doesn't change a language, just what you do with it
09:45:41 <vixey> Spark: no not really
09:45:41 <Spark> Toxaris_: i only have experience with prolog
09:45:42 <Toxaris_> Spark: afaik Prolog's semantic is based on unification, backtracking and cut
09:45:48 <chrisdone> toxaris: well, it's useful because these terms can be used to categorize languages that focus on them the most. compare "this is a language that mostly and fundamentally focuses on mutation" with "this is an imperative language"
09:46:03 <vixey> Prologs semantics are based on proof search
09:46:04 <Spark> Toxaris_: in prolog,  as i saw it, backtracking is the important bit, cut is the ugly bit, and unification is the boring bit
09:46:17 <vixey> unification and backtracking are implementation details
09:46:33 <vixey> Spark, no not really ..
09:46:36 <Spark> they are semantic details
09:47:06 <Shiruka> backtracking is the I-don't-have-to-write-this-boring-stuff-myself bit, cut the make-this-reasonably-fast bit, unification the hey-this-looks-neat bit
09:47:18 <Spark> yeah that's pretty much what i think
09:47:21 <vixey> in haskell you are programming on the left hand side of the :: (usually)
09:47:30 <vixey> in Prolog, you are programming on the RHS of the ::
09:47:39 <vixey> in Coq, you are programming on both sides, because both sides are one
09:48:11 <Spark> prolog's pattern matching allows you to build complicated things on either side of the = though
09:48:39 <Toxaris_> vixey: Prolog may be inspired by proof search, but prolog is not proof search imho
09:48:50 <vixey> Toxaris_: if you view,
09:48:55 <vixey> foo :- bar, baz, quux.
09:48:57 <Spark> there are no heuristics
09:48:57 <vixey> as,
09:49:00 <Spark> and it doesn't like infinity much
09:49:04 <vixey> foo <- bar <- baz <- quux
09:49:07 <Spark> it's more state exploration
09:49:11 <chrisdone> most of the code you write in haskell is functional, most of the code you write in lisp is imperative, ... prolog ..., etc. just because you can write some pure code in lisp doesn't mean "functional" is meaningless
09:49:12 <vixey> Prolog is trying to djinn that type
09:49:53 <Shiruka> with laziness you can represent the search tree as a lazy data structure and pruning/searching/etc algos as tree transforms :-p cooler than prolog, if not necessarily blazingly fast (but then again prolog's slow too)
09:49:54 <Toxaris_> chrisdone: what I said. the point is "code writing", not languages :)
09:50:04 <vixey> hmmm I should put together my Prolog implementation notes somewhere..
09:50:28 <Jedai> chrisdone: Lisp really allows you to write functional code (I tend to write more functional code in it), after that it's just a choice of the programmer (and sometimes a traditionnal style for the community)
09:50:32 <Toxaris_> vixey: what is the "<-"?
09:50:41 <mib_3om9o4ym> i have got a question about CPS...i tried to write fibonacci CPS style but there seem to be some errors....i will love to walk through it with somebody
09:50:54 <vixey> Toxaris_: a <- b   is  b -> a
09:51:15 <vixey> mib_3om9o4ym, that sounds fun, why don't you hpaste what you have?
09:51:18 <newsham> dcoutts: wow, awesome on the 64-thread sparc project.
09:51:18 <Saizan_> mib_3om9o4ym: can you show us the code?
09:51:21 <Spark> Shiruka: prolog has it as a language feature though, you can always get around the non-presence of a language feature by coding up what you want in something else
09:51:22 <mib_3om9o4ym> sure....one moment
09:51:30 <dcoutts> newsham: aye :-)
09:51:41 <Shiruka> Spark: but then you get to customize it
09:51:45 <geezusfreeek> waitâ¦ 64 thread? is it really 8 threads per core?
09:51:52 <vixey> Shiruka: oh Prolog isn't slow
09:51:52 <Spark> Shiruka: this is a disadvantage of having it as a language feature
09:51:58 <Shiruka> it's the customization I find most fun
09:52:00 <Shiruka> in this case
09:52:01 <mib_3om9o4ym> first helper function...fibh k 1 = 1
09:52:06 <mib_3om9o4ym> fibh k 2 = 2
09:52:15 <mib_3om9o4ym> fibh k n = fibh k (n-1)
09:52:16 <Toxaris_> mib_3om9o4ym: have a look at www.hpaste.org
09:52:18 <newsham> The T5120 server has a T2 UltraSPARC processor with 8 cores running at
09:52:18 <newsham> 1.2GHz. Each core multiplexes 8 threads giving 64 hardware threads
09:52:19 <newsham> overall.
09:52:29 <Toxaris_> mib_3om9o4ym: and post your code there, so we can look at all of it at once
09:52:32 <Shiruka> vixey: to be fair, I haven't really searched for fast implementations, but the ones I used eons ago were slow :-)
09:52:36 <geezusfreeek> ah, i missed that part i guess
09:52:36 <mib_3om9o4ym> hmm....let me look at it...thanks
09:53:10 <vixey> Shiruka: if you suddenly get interested in Prolog compiler tech. check out the WAM, VAM and Aquarius :p
09:53:15 <jeffwheeler> Shiruka: does anybody actually use Prolog for real applications? I thought it was just /interesting/ and people liked the way it worked. :P
09:53:16 <Spark> Shiruka: maybe you're an assembly language programmer at heart then :)
09:53:51 <geezusfreeek> jeffwheeler: iirc, erlang was originally in prolog
09:53:51 <vixey> mib_3om9o4ym, why don't you show what expression it is you are trying to CPS?
09:54:07 <jeffwheeler> geezusfreeek: really? That's pretty awesome, if the case.
09:54:13 <Shiruka> I used to program a lot in C/C++, and when it comes to search problems etc, the need for speed instinct resurfaces pretty fast :-)
09:54:13 <Spark> jeffwheeler: it probably doesn't help you build a multi-tiered sql-backed, web-fronted business application if that's what you mean :)
09:54:15 <vixey> yes erlang evolved from a metacircular Prolog interp., there' sa great article about this online somewhere
09:54:36 <jeffwheeler> I'll search for it later; I didn't know about that.
09:54:36 <vixey> Spark< people use Prolog for webapps
09:55:00 <Spark> people use anything for everything
09:55:09 <vixey> Spark, that's a silly thing to say
09:55:09 <dogbite> quick question: how can i specify the 'step' in an expression such as [1..10]
09:55:17 <Shiruka> vixey: hm, have to take a peek..
09:55:19 <Toxaris_> >[1,2..10]
09:55:20 <vixey> > [1,3..10]
09:55:21 <mauke> > [1,3..10]
09:55:24 <dogbite> thanks
09:55:26 <lambdabot>  [1,3,5,7,9]
09:55:26 <lambdabot>  [1,3,5,7,9]
09:55:30 <geezusfreeek> i find the cynicism in this channel today a bit overwhelming
09:56:05 <mib_3om9o4ym> hopskip, I have hpaste'd it
09:56:17 <Jedai> mib_3om9o4ym: give us the link
09:56:36 <mib_3om9o4ym> oop sorry... http://hpaste.org/9120
09:56:54 <Shiruka> geezusfreeek: I didn't notice any cynicism :-( maybe it's me, spreading my natural cynicism to this den of optimists? :-O
09:58:02 <vixey> mib_3om9o4ym, umm...
09:58:02 <vixey> fib 1 = 1
09:58:02 <vixey> fib 2 = 1
09:58:02 <vixey> fib n = fib (n-1) + fib (n-2)
09:58:10 <vixey> mib_3om9o4ym, it is something like that, we are thinking about ?
09:58:16 <mib_3om9o4ym> right
09:58:23 <vixey> mib_3om9o4ym, ok
09:58:26 <mib_3om9o4ym> but trying to write it CPS style, to understand CPS
09:58:30 <vixey> so it has type Integer -> Integer currently
09:58:35 <vixey> now CPS should have what type?
09:58:52 <vixey> i.e. what is the type (Integer -> Integer) converted for CPS?
09:58:57 <mib_3om9o4ym> well, let us see.... the function should have the same type
09:59:09 <mib_3om9o4ym> wait a second....let me look again
09:59:12 <vixey> it should take a continuation, and an integer
09:59:21 <vixey> but what should it return?
09:59:30 <vixey> well.. the continuation takes an integer doesn't it ?
10:00:09 <mib_3om9o4ym> well, it should, but the function should take two integers, and generate another function, shouldn't it
10:00:18 <vixey> yeah, so far we have..  ((Integer -> ?) -> Integer -> ?)
10:00:35 <Riastradh> (Integer -> answer) -> Integer -> answer
10:00:46 <vixey> does that seem right?
10:00:46 <vixey> so the first line of code sholud be,
10:00:54 <vixey> fib'k :: (Integer -> a) -> Integer -> a
10:01:05 <vixey> (I will call this function fib'k)
10:01:21 <mib_3om9o4ym> ok...go ahead
10:01:40 <vixey> so can you write the cases
10:01:45 <vixey> fib'k k 1 = ?
10:01:47 <vixey> fib'k k 2 = ?
10:02:08 <mib_3om9o4ym> well, k 1 (but k should be id function in both cases)
10:02:25 <vixey> yeah that's right
10:02:28 <newsham> k need not be id
10:02:33 <vixey> well 99% right.. k might be id, but it might not
10:02:35 <vixey> ok :)
10:02:42 <vixey> so now we need two helper functions
10:02:47 <vixey> plus'k k x y = k (x + y)
10:02:55 <vixey> subtract'k k x y = k (x - y)
10:03:01 <mauke> <GumbyBRAIN> If our behavior is strict, we do not need fun!
10:03:31 <mib_3om9o4ym> hmm....ok....
10:03:32 <vixey> mib_3om9o4ym, so the last bit.. fib (n-1) + fib (n-2)
10:03:41 <vixey> I think that you can look at this in the form:
10:03:48 <mib_3om9o4ym> right....we need to get that through helper functions...
10:03:57 <vixey> (+) (fib ((-) n 1)) (fib ((-) n 2))
10:04:04 <mib_3om9o4ym> true
10:04:15 <vixey> and now CPSing it from teh left to right
10:04:48 <newsham> not right to left?
10:05:01 <mib_3om9o4ym> that is good question....what is the eval order?
10:05:11 <newsham> you can pick an eval order
10:05:25 <mib_3om9o4ym> by using parentheses?
10:05:33 <newsham> eval order will be explicit in the cps
10:05:53 <vixey> http://hpaste.org/9120#a2
10:05:53 <newsham> since you are passing results to continuations
10:05:59 <mib_3om9o4ym> well, that would make sense....
10:06:02 <vixey> I put undefined
10:06:05 <vixey> so this typechecks
10:06:17 <vixey> you can modify this step by step.. making sure it type checks along the way
10:06:33 <mib_3om9o4ym> sure, let me try...
10:07:59 <vixey> CPSing is a good case for using types to help you program
10:08:40 <mib_3om9o4ym> yeah, I should be doing type checking as part of writing programs
10:08:55 <vixey> usually in haskell I ignore the type checker
10:09:01 <vixey> it doesn't get in the way which is nice :)
10:10:02 <mib_3om9o4ym> well, as a beginner, I should do type checking :)
10:10:43 <Shiruka> it's good style to give explicit types for toplevel defs anyway
10:11:01 <Shiruka> although that's one of the most common cases where I end up with unexpected type errors.. :-)
10:11:34 <mc__> mib_3om9o4ym: you can set your nick with /nick, just in case you dont know
10:11:41 <jeffwheeler> As a beginner, I usually have the type-checker find the correct type, and then write that to the file so I don't accidentally change it unknowingly.
10:11:43 <Shiruka> "oops, I changed this Int here to Integer, but forgot to tell that to the compiler again in that other toplevel def"
10:12:38 <Jedai> Shiruka: But that's good because it shows you that the function doesn't do what you thought it does (sometimes it's because you made a mistake in the function body, and sometimes it's because you didn't really understood what you were doing)
10:12:46 <mib_3om9o4ym> how about this? with k in fib argument set to id function : http://hpaste.org/9121
10:13:18 <Shiruka> Jedai: or makes me wonder what on earth I'm doing not defining it for Integral a :-)
10:13:46 <vixey> I do not think it's good style to put the annotations everywhere
10:14:20 <Jedai> vixey: Yeah, only on top-level definition (it helps getting "to the point" type error too)
10:14:48 <vixey> just write type correct code, then you don't have to worry about errors
10:14:55 <Jedai> And even then I don't type all my top-level definitions all the time (though all that are exported)
10:15:19 <Jedai> vixey: Right, I'll keep that in mind :D
10:15:46 <vixey> :t fromJust (7 + "sheep")
10:15:48 <lambdabot>     Couldn't match expected type `Maybe a'
10:15:48 <lambdabot>            against inferred type `[Char]'
10:15:48 <lambdabot>     In the first argument of `fromJust', namely `(7 + "sheep")'
10:15:55 <mauke> just write correct code? why haven't I thought of that before?!
10:16:24 <kriomant> How to create function with given name using quasi-quote? I tried "$( [| $(mkName n) = id |] )", but it gives "Parse error in pattern" error.
10:16:45 <Igloo> You need to use [d|
10:16:53 <Igloo> 'd' for declarations
10:17:10 <kriomant> sorry, I actually used [d| |], it gives that error
10:17:37 <Igloo> Ah, and you can't splice in on the left-hand side
10:17:48 <Igloo> You'll have ot use the combinators instead
10:18:02 <Shiruka> Jedai: ah, indeed, I also don't always bother for the non-exported defs :-)
10:19:09 <kriomant> Igloo: so I can write body using quasi-quote, but to construct function I must use FunD, Clause and so on?
10:28:17 <dons> ?yow!
10:28:18 <lambdabot> Couldn't find fortune file
10:28:36 <visq> kriomant:  your error is because of splicing-in a lhs, but you cannot splice into declarations anyway
10:28:44 <Cale> Haskell is lazy, but Template Haskell is surly as well. Template Haskell: It's like Teamsters for your Haskell code! ;)
10:28:57 <dons> "Haskell is like the centre party in a two party democracy. Any time a centre party comes up with a good idea that allows them to grab a significant share of the vote, one or other (or both) of the 'outer' parties will steal the idea and the centre party will lose their votes again. Centre parties can have a major impact on policy making and yet frequently have no more than a few percent of the vote. If your goal is to get good ideas out there, then 
10:29:03 <dons> -- sigfpe
10:29:05 <dons> interesting analogy
10:29:20 <hackage> Uploaded to hackage: Adaptive 0.22
10:29:31 * Cale looks for a Jimmy Hoffa combinator in the Template Haskell documentation.
10:29:44 <mc__> dons: then?
10:30:31 <dons> mc__: ?
10:30:31 <kriomant> visq: you mean I can't use $() inside [d| |] ?
10:30:39 <mc__> dons: nevermind
10:30:40 <Shiruka> dons, IRC doesn't like too long lines, cut off at "there, then"
10:31:01 <dons> hmm. fits on my screen.
10:31:09 <visq> kriomant: seems so: "Declaration splices are not permitted inside declaration brackets"
10:31:09 <Cale> kriomant: not on the left hand side of an equation, apparently
10:31:12 <dons> ... party, keep clear away."
10:31:18 <Cale> ah
10:31:36 <dons> i wonder if my client is showing the full text, but the server chopped it?
10:31:44 <vixey> what sort of thing should go on code.haskell.org
10:31:52 <dons> vixey: haskell projects of any flavour
10:31:53 <Cale> dons: That's likely. Some clients don't autosplit.
10:32:13 <vixey> I wish I had a code.haskell account
10:32:18 <shapr> vixey: Get one!
10:32:23 <vixey> but I am just putting stuff on google
10:32:24 <dons> vixey: just ask, visit community.haskell.org
10:32:26 <Cale> actually, I think it's technically difficult to do right
10:32:28 <dons> you'll have one by the end of the day.
10:32:31 <shapr> vixey: Did you ever get your kakapo account working?
10:32:32 <kriomant> ok, now I try to create only body using quasi-quote, but haskell given "parse error on input $(" for "let body = [| rec { $(field_name) = f ($(field_name) rec) } |]"
10:32:32 <Cale> (splitting lines on IRC)
10:32:37 <vixey> shapr, no..
10:32:43 <vixey> shapr, I did finish my program and put it online though
10:32:47 <shapr> That's cool!
10:35:44 <visq> kriomant: I think you're again splicing-in a lhs (this time in the record update).
10:36:36 <kriomant> visq: rrr... then quasi-quotes are almost useless :-)
10:37:53 <vixey> no luck for me today I guess
10:38:00 <vixey> I got the same error, 500 Internal Server Error Newline in ssh key
10:38:36 <dcoutts_> yo SyntaxNinja
10:38:46 <SyntaxNinja> hi dcoutts_ how's it going?
10:39:01 <dcoutts_> SyntaxNinja: check out http://haskell.org/opensparc/ :-)
10:39:21 <dcoutts_> SyntaxNinja: so, yes, great :-)
10:39:35 <mux> http://www.omega-prime.co.uk/files/GHC-Core-HTML.html
10:39:36 <dcoutts_> SyntaxNinja: I forwarded you a question too
10:39:38 <mux> this rocks :)
10:40:17 * vixey wonders if 3om9o4ym ever figured out how to do the CPS...
10:40:24 <dons> mux: core in html?
10:40:47 <dcoutts_> mux: nice, and hyperlinked ids
10:40:49 <mux> this is one of the new GHC plugins, there's a post about it on planet haskell
10:41:00 <SyntaxNinja> dcoutts_: yeah, I think I already replied.  So that's totally awesome :) nice work wrangling everyone to make this happen.
10:41:10 <SyntaxNinja> y0y0 andyjgill
10:41:22 <dons> dcoutts's gets "offer builder award of the month".
10:41:31 <dcoutts_> :-)
10:41:31 <mux> http://blog.omega-prime.co.uk/2008/07/21/compiler-plugins-for-ghc-week-six/
10:41:33 <lambdabot> Title: 25 :: (Bloggable a) => a -> IO () 17 » Blog Archive 5f » Compiler Plugins For GH ..., http://tinyurl.com/5cqq8t
10:41:38 <andyjgill> Hi SyntaxNinja
10:42:13 <dcoutts_> SyntaxNinja: oh right, thanks. I've just niped into my office to meet Lemmih, so I'll pickup your reply a bit later.
10:42:30 <vixey> maybe I should implementing programming languages and start using them
10:42:32 <SyntaxNinja> dons: we can't start using the Strange Galois Job Titles on dcoutts_ ;)
10:42:34 <vixey> should stop*
10:42:47 <SyntaxNinja> vixey: you can't even say it ;)
10:42:55 <dcoutts_> andyjgill: did I tell you about this before we announced? http://haskell.org/opensparc/
10:42:59 <vixey> it is hard for me ..:p
10:43:02 <dons> SyntaxNinja: helps for when we hire him ;)
10:43:08 <dcoutts_> hah ha
10:43:12 <SyntaxNinja> :)
10:43:13 <vixey> I wonder about making a puzzle game kit for people to make puzzle games with or something
10:43:24 <thoughtpolice> yay! html-highlighted and hyperlinked core output :)
10:43:43 <dcoutts_> dons, SyntaxNinja: though I'd very much like to visit for a couple weeks after ICFP. I should get my schedule organised.
10:43:46 <SyntaxNinja> dcoutts_: coincidnetally, we just had to get ghc building on solaris 8 sparc the other day.
10:43:55 <SyntaxNinja> that would be fun.
10:44:07 <dcoutts_> SyntaxNinja: oh yeah? well we'll have a Solaris 10 build bot from now on
10:44:24 <dcoutts_> dons: though sadly I think pushing it out to the GSoC conference might be over doing it
10:44:50 <dcoutts_> dons: a couple weeks after ICFP would be mid Oct, and the GSoC conference is late Oct
10:45:03 <vixey> hmm
10:45:47 <dons> hmm, right.
10:47:20 <dcoutts_> dons: you lot might be sick of me banging on about Cabal and hackage by the time it got to the GSoC conference ;-)
10:47:21 <saml> in category, what do you call a collection of morphisms that point to the same object?
10:47:36 <dons> dcoutts_: hehe. if its all working by then, i won't complain.
10:47:50 <dcoutts_> dons: pitty the dates don't match up better
10:47:58 <dcoutts_> dons: heh, right. :-)
10:48:24 <dcoutts_> dons: well Lemmih is here again this evening for more hacking, so we'll see
10:57:25 <bos> i'm trying to figure out how to explain why ghci accepts only haskell expressions, and not normal chunks of haskell code.
10:57:41 <bos> i can't really think of a reason, beyond "it does this because this is what it does".
10:57:43 <ndmitchell> bos: bad design?
10:57:59 <bos> i was hoping to sugar-coat it a bit more.
10:58:15 <lament> way easier to implement it this way? somehow
10:58:37 <jeffwheeler> Most other REPLs do support code blocks. That is peculiar.
10:58:47 <vixey> bos: ghci is like a do block
10:58:50 <vixey> you can do things like,
10:58:54 <vixey> foo <- readLine
10:58:56 <vixey> it accepts those too
10:59:03 <bos> vixey: i know what ghci is.
10:59:12 <vixey> me too....
10:59:13 <bos> vixey: what i'm trying to do is explain why it is what it is.
10:59:16 <vixey> I was trying to answer aeou
10:59:17 <ndmitchell> bos: its easier to enter 1 line than many, a 1 line statement is not that useful
10:59:29 <ndmitchell> bos: i.e. console makes entering multiple lines and editing them a chore
10:59:30 <vixey> bos, <bos> i'm trying to figure out how to explain why ghci accepts only haskell expressions, and not normal chunks of haskell code.
10:59:33 <newsham> bos: ghci lets you interactively type haskell code in and see the results.
10:59:37 <vixey> was what I was trying to reply to
10:59:55 <seliopou> you replied well
11:00:01 <dons> bos, mutually-recursive declaration in arbitrary order don't work if entered sequentially?
11:00:20 <dons> well, they do, but it takes a bunch of work that would be different to just evaluating statements in the IO monad.
11:00:24 <thoughtpolice> i would think at the least that multi-line code in ghci (the ':{' and ':}') would be able to accept chunks of code
11:00:28 <thoughtpolice> apparently not
11:00:38 <dons> bos, so I'd argue, haskell isn't a top-to-bottom language, so its non-trivial to munge that into ghci
11:00:53 <dons> thoughtpolice: yeah, it does though, no?
11:01:03 <lament> :}
11:01:07 <thoughtpolice> dons: no, you can't input data declarations for example
11:01:24 <thoughtpolice> if you're getting to that point though, I don't see why it would be much more hassle to just put it in a file and load it
11:01:28 <dons> no, of course. you're sitting in a do-block
11:01:39 <Shiruka> you can use let :-)
11:01:58 <thoughtpolice> is that not what he meant? i.e. just being able to snip out entire parts of a file and input it?
11:02:25 <newsham> vixey answered that already
11:02:32 <ndmitchell> dons: "its hard" is not a good reason, and i don't think its very accurate either, since it can already do template haskell things
11:03:21 <dons> hbi can handle most decls too, fwiw.
11:03:40 <dons> but ghci's "sitting in a do block" is a local sweet spot.
11:03:43 <dons> not an optimal one :)
11:04:06 <dons> i'd imagine its less than a week's work to make everything work in ghci..
11:04:07 <newsham> not as sweet as lambdabot, that vixen.
11:04:09 <Shiruka> improving ghci is a nice idea if someone wants to do it :-)
11:04:31 <ndmitchell> i think the UI means its never going to be practical
11:04:40 <ndmitchell> something like GuiHaskell UI would make it very handy though
11:05:19 <Shiruka> another neat thing would be to have a help like in e.g. python (it could print snippets from haddock docs)
11:05:29 <FordCortina> can i find a description of the "occurs check" anywhere?
11:05:53 <FordCortina> its not known under a different name?
11:05:56 <PeakerWork> ndmitchell: what's GuiHaskell?
11:06:03 <ndmitchell> Shiruka: i wrote it last week, Hoogle 4 has /info, bind that in GHCi and you are done
11:06:06 <ndmitchell> @where guihaskell
11:06:06 <jeffwheeler> Shiruka: I thought I read about something like that; I thought there was :info or something mentioned in Yi discussion
11:06:06 <lambdabot> http://www-users.cs.york.ac.uk/~ndm/projects/guihaskell.php
11:06:24 <ndmitchell> @where+ guihaskell http://www-users.cs.york.ac.uk/~ndm/guihaskell/
11:06:24 <lambdabot> I will never forget.
11:06:31 <ndmitchell> PeakerWork: ^^
11:06:35 <shapr> @quote
11:06:35 <lambdabot> Randroid says: I just wrote a monad that does my laundry. It threads it round and round until it's washed. Now I'm going to work on the Dryer monad.
11:06:39 <ndmitchell> PeakerWork: warning, does not work properly
11:06:59 <PeakerWork> thin ghci frontend?
11:07:17 <ndmitchell> PeakerWork: mid-width GHCi/Hugs/Yhc/GHC front end
11:07:24 <ndmitchell> i.e. profiling is just a single button click
11:07:43 <ndmitchell> but the core evaluation is just GHCi
11:08:27 <twobitwork> what's the best way to match against 2 elements in a list? i.e. "f [] = []; f (x:xs) = x : f xs; f (1:2:xs) = 2 : f xs"
11:08:40 <Shiruka> I like command line interfaces better than gui:s though :-)
11:08:56 <hml> anyone jknow of a hasskell -> javascript or haskell -> flash compiler?
11:09:06 <Shiruka> you can do those pretty well actually, as evidenced by e.g. ipython (of course haskell is a different beast, but still)
11:09:25 <ndmitchell> Shiruka: i disagree, but of course you can have both
11:09:36 <jansz> @pl (\(u,m)->(60*read u)+(read.tail $m))
11:09:36 <lambdabot> uncurry ((. (read . tail)) . (+) . (60 *) . read)
11:09:38 <newsham> 2bit: you can match f (1:2:xs).   make sure to order your matches so properly
11:09:40 <ndmitchell> hml: http://www.haskell.org/haskellwiki/Yhc/Javascript
11:09:41 <lambdabot> Title: Yhc/Javascript - HaskellWiki
11:09:49 <newsham> 2bit: ie. so that it matches (1:2:xs) before it matches (x:xs)
11:09:58 <hml> ndmitchell: thanks
11:10:07 <jeffwheeler> What does the pl command do in lambdabot?
11:10:29 <newsham> makes a points-free (pointless) version of a function
11:10:38 <newsham> ie. with no explicit argument names
11:10:40 <jeffwheeler> Is that always possible?
11:10:51 <atp> yes
11:10:53 <Toxaris> jeffwheeler: yes.
11:10:59 <jeffwheeler> Wow, I didn't realize that.
11:11:11 <atp> jeffwheeler: combinatory algebra and the lambda calculus are equivalent
11:11:16 <Toxaris> jeffwheeler: lookup "SK-calculus" if you are interested
11:11:33 <kryptiskt> not always practical though :)
11:11:36 <jeffwheeler> Alright, I will in a bit.
11:11:57 <atp> jeffwheeler: although what lambdabot does is a reduction to something more akin to the bkcw calculus
11:12:38 <jeffwheeler> atp: you're _way_ above me, but I'll try to look it up
11:13:01 <atp> jeffwheeler: no, i'm not that far above you, i'm just using a term you don't know. :)
11:13:25 <jeffwheeler> atp: Above me in terms, I mean. ;)
11:13:38 <atp> jeffwheeler: s, b, c, w, k and i are standard names for particular "combinators"
11:13:53 <Toxaris> @pl \w h a t s -> t (\h e p r o b l -> e (\m -> t h o (\u g -> h)))
11:13:54 <lambdabot> const (const (const (const . ap id (const . ((const . const . ((const . const) .)) .) . ap (.) . ((const .) .) . (`ap` (const . const)) . (flip .)))))
11:14:18 <atp> jeffwheeler: each takes a function and returns a different function
11:14:40 <jeffwheeler> Hmm, okay.
11:14:47 <Toxaris> in this example, the combinators are: const, ap, id, flip and (.)
11:14:47 <atp> jeffwheeler: (in an untyped world, everything is a function that takes a function to another function)
11:14:56 <dolio> There are some Haskell functions you can't write without pattern matching, because the right eliminators aren't in the standard libraries.
11:15:14 <dolio> But that's kind of a technicality.
11:15:42 <atp> what dolio says is true, technically combinatory algebra and the *untyped* lambda calculus are equivalent
11:15:59 <atp> but since it is generally possible to encode any type in a purely functional manner
11:16:11 <Toxaris> pl doesn't know about case and the library anyway
11:16:26 <atp> also, pl invents some functions
11:16:30 <atp> like if'
11:16:45 <jeffwheeler> How does pl work, anyways?
11:16:49 <atp> because Haskell stupidly lacks a purely functional if function
11:16:52 <atp> even though implementing one is trivial thanks to laziness
11:17:16 <atp> jeffwheeler: there are a number of reductions on lambda expressions that convert to combinatory form
11:17:31 <atp> jeffwheeler: i would expect that lambdabot does it that way, basically.
11:17:47 <jeffwheeler> That's neat. Can I google for the lambdabot source?
11:17:55 <atp> yeah
11:18:05 <atp> building it is... tricky though.
11:18:17 <jeffwheeler> Fortunately, I don't need to. :)
11:18:51 <atp> anyway, in haskell, s = ap, k = const, b = (.), c = flip, and i = id
11:19:28 <tromp> > ap const const
11:19:31 <lambdabot>  Add a type signature
11:19:57 <Baughn> atp: Actually, in the latest version the build script works out of the box
11:20:05 <atp> Baughn: oh good
11:20:09 <Baughn> Or at least I assume it does, on some box, somewhere. Me, I have to edit it a bit.
11:20:18 <atp> haha
11:20:21 <Toxaris> Baughn: is what you say in any way related to windows?
11:20:33 <Baughn> Toxaris: No, cabal-install versions
11:20:58 <Toxaris> Toxaris: so it should work on windows
11:21:04 <visq> @pl \s -> f s >>= g
11:21:04 * Toxaris speaks to himself again
11:21:04 <lambdabot> (g =<<) . f
11:21:11 <Baughn> Toxaris: No, LB won't work on windows
11:21:26 <Baughn> It requires posix - signal support and whatnot
11:21:30 <Toxaris> Baughn: ok, that's what I consider "not related" :)
11:21:35 <Toxaris> too bad :(
11:26:37 <ahunter>  So how about that SPARC project dcoutts just announced?  I'm a bit saddened school's starting up too soon to apply :(
11:27:03 <dcoutts_> ahunter: not so, you can spread the time out over the next 9 months
11:27:15 <dcoutts_> we don't expect people to squeeze it in at the end of summer
11:28:04 <ahunter> dcoutts_: I saw that, yeah...I just got the impression that you'd prefer someone who didn't have two full semesters coming up somehow, maybe I was totally wrong :)
11:28:10 <dcoutts_> ahunter: so if you're interested then do consider it, you can propose a schedule when you apply.
11:28:32 <Shiruka> dear god, the monad tutorial industry is really pretty serious business.. impromptu monad tutorials in reddit comments :-O
11:28:51 <ahunter> dcoutts_: maybe I'll give it a shot then...I mean, I doubt you'll want me--I'm only an undergrad and you can probably find someone with waaaaay more experience in the field--but it'd be really cool
11:28:59 <dcoutts_> ahunter: so what does two semesters mean in practise?
11:29:45 <ahunter> dcoutts_: I'm taking a rather-full undergraduate courseload (i.e., I could probably find 5-10 hours a week to work on this, but not more) september-mid december, and end-of-january through may
11:30:11 <twobitwork> newsham: yeah.... (sorry, distracted)
11:31:08 <ahunter> dcoutts_: otoh, now that I think of it, that includes a couple units of research with my PLs prof, and we have yet to pick a topic...could probably finagle this into place :P
11:31:20 <dcoutts_> ahunter: right, that would be tough, so there'd be a few weeks in Dec, Jan
11:31:50 <ahunter> dcoutts_: comes to about a month there, yeah...add two after graduation in may is about the best I could do
11:32:39 <dcoutts_> ahunter: I had wanted to get the admin sorted out in the spring so we could have someone doing it this summer, but it all took longer than expected. :-(
11:33:24 <ahunter> dcoutts_: understandable, really...
11:39:40 <marcot> I've just uploaded http://hackage.haskell.org/cgi-bin/hackage-scripts/package/interleavableIO-0.0.1 and http://hackage.haskell.org/cgi-bin/hackage-scripts/package/interleavableGen-0.0.1 .  If someone is interested...
11:39:40 <lambdabot> marcot: You have 2 new messages. '/msg lambdabot @messages' to read them.
11:39:41 <lambdabot> Title: HackageDB: interleavableIO-0.0.1, http://tinyurl.com/65a2yz
11:40:03 <byorgey> marcot: what's it do?
11:40:36 <marcot> byorgey: interleavableIO makes it possible to use functions as catch with IO Monad Transformers...
11:41:49 <marcot> byorgey: interleavableGen generates a module with generalized versions of the functions of a given module.
11:42:05 <Toxaris> can I get the *source* of something from hackage with cabal-install?
11:43:07 <byorgey> Toxaris: not that I know of, but that's a neat idea
11:44:14 <Saizan_> "cabal fetch"
11:45:05 <Japsu> TINC.
11:45:54 <dcoutts_> heh, hackage only has source
11:52:35 <roconnor> @hayoo Handle ->
11:52:36 <lambdabot> Unknown command, try @list
12:00:35 <shapr> yarr
12:00:46 <shapr> @yow
12:00:46 <lambdabot> Couldn't find fortune file
12:00:48 <shapr> aww
12:04:40 <jganetsk> when is haskell going to overtake erlang?
12:05:03 <jganetsk> in terms of error-handling and network transparency
12:05:13 <jganetsk> and live code swapping
12:06:49 <byorgey> jganetsk: Saturday
12:07:09 <Shiruka> answer modulo 7? :-)
12:07:10 <byorgey> ;)
12:07:29 <jganetsk> ok, i await
12:08:52 <shapr> jganetsk: You could start on it today!
12:09:46 <jganetsk> shapr: i still have to learn about this spineless, tagless, g-machine
12:10:00 <Shiruka> there was the glasgow distributed haskell thingy, but I don't think it produced anything useful except papers
12:10:06 <lispy> As Pseudonym pointed out recently, erlang threads have seperate heaps.  So to mimic erlang's success you may need to modify one of the run-times to provide that.
12:11:42 <Shiruka> alice ml can do code migration, if ml is close enough to haskell for you :-)
12:12:27 <vixey> start on what?
12:15:13 <vixey> hi
12:15:17 <jganetsk> eralng threads have separate heaps so they can GC each process independently
12:15:31 <jganetsk> for simplicity.. and for real-timishness
12:15:38 <jganetsk> but i think we have better GC technology nowadays
12:15:44 <jganetsk> it might not be as important
12:15:44 <dancor> for a map from unordered pairs, should i just use Set's of two elems
12:15:45 <shapr> Like what?
12:15:57 <jganetsk> shapr: that directed to me?
12:15:57 <vixey> Can I write a FPS in erlang that uses multiple CPUs?
12:16:17 <vixey> dancor: what do you mean by map?
12:16:19 <shapr> jganetsk: yeah, what better gc?
12:16:32 <dancor> vixey: sorry Data.Map
12:16:49 <lispy> vixey: what is FPS in your question?
12:16:55 <vixey> if you want a Data.Map then I don't think you should use Set ...
12:16:56 <shapr> first person shooter?
12:17:00 <jganetsk> shapr: http://citeseer.ist.psu.edu/540674.html
12:17:00 <Shiruka> FPS in erlang sounds like round peg, square hole and a Man With A Hammer
12:17:01 <lambdabot> Title: Scalable Real-time Parallel Garbage Collection for Symmetric Multiprocessors - C ...
12:17:41 <dancor> Shiruka: that will be a good name for it
12:18:08 <kryptiskt> hey, is citesser back from the dead? That's good news
12:18:29 <kryptiskt> citeseer...
12:18:29 <vixey> I'm not sure what to code yet
12:18:54 <dancor> hm maybe i'll just Map from pairs with the contract that the pairs are always (a, b) with a <= b
12:19:29 <lispy> vixey: write a plugin for firefox that can render .tex files on the fly in the browser, bonus points if they look as good as they would as pdf
12:20:16 <dancor> well really i'd like to be able to store (person1, person2, result) and have fast lookups based on person1 and person2
12:20:35 <lispy> You want a map with composite keys?
12:21:01 <dancor> i guess so
12:21:03 <vixey> why don't you have two maps
12:21:09 <dancor> i could double-store
12:21:11 <Shiruka> map with set-of-two as key instead of tuple-of-two
12:21:14 <vixey> Map person1 (person2, result)
12:21:20 <vixey> Map person2 (person1, result)
12:21:44 <Shiruka> you could also make a type for set-of-two and use the (a, b) | a <= b as an implementation detail
12:22:23 <jpcooper> hello
12:22:42 <jpcooper> is there any guide on how to separate things onto multiple lines?
12:23:03 <lispy> The wiki has some style guides
12:23:11 <vovik> using let?
12:23:11 <lispy> ?where haskellwiki
12:23:11 <lambdabot> I know nothing about haskellwiki.
12:23:18 <chr1s> jpcooper: do you have a concrete example?
12:23:20 <shapr> jpcooper: do you have any specific questions you want to paste into hpaste?
12:23:39 <jpcooper> okay
12:24:52 <visq> are there any good examples of designing customizable, application specific monads ?
12:25:01 <jpcooper> hpaste currently isn't loading. I think this case might be solved with the usage of on
12:26:06 <jpcooper> or maybe not
12:26:08 <Plareplane> http://urchin.earth.li/~ian/style/haskell.html
12:26:08 <jpcooper> (updateBank bank (getNumber bank colour) (-1) $ updateBank bank (getNumber bank colour) (+1))
12:26:08 <lambdabot> Title: Good Haskell Style
12:26:18 <jpcooper> how could I write that in a nicer way?
12:26:32 <vixey> use less parens
12:26:52 <vixey> > (+1)
12:26:52 <jpcooper> yes, apart from that
12:26:53 <vixey> > 1
12:26:53 <lambdabot>  <Integer -> Integer>
12:26:54 <lambdabot>  1
12:26:59 <vixey> > (-)
12:27:00 <lambdabot>  <Integer -> Integer -> Integer>
12:27:01 <vixey> > (-1)
12:27:02 <lambdabot>  -1
12:27:28 <Deewiant> let f = updateBank bank (getNumber bank colour) in f (-1) $ f (+1)
12:28:14 <Shiruka> and maybe parameterize f on bank and colour, lift it to toplevel and give it a more descriptive name
12:29:03 <jpcooper> I guess fold can't really be applied to this
12:29:21 <hackage> Uploaded to hackage: iException 0.0.1
12:29:21 <hackage> Uploaded to hackage: AvlTree 3.2
12:29:21 <hackage> Uploaded to hackage: COrdering 2.3
12:29:21 <hackage> Uploaded to hackage: interleavableGen 0.0.1
12:29:21 <hackage> Uploaded to hackage: interleavableIO 0.0.1
12:29:22 <jpcooper> is there a common idiom for f(f(x, y), z) ?
12:29:25 <hml> does the haskell report.pdf crash  xpdf for anyone else?
12:29:32 <vixey> jpcooper: no
12:29:41 <vixey> jpcooper: it is more common to write f (f x y) z
12:29:54 <jpcooper> yes, I was thinking in maths
12:30:27 <vixey> there is no clearer or simpler way to write  f (f x y) z  in haskell
12:30:30 <Deewiant> @pl \f -> f (f x y) z
12:30:30 <lambdabot> flip (ap id (flip ($ x) y)) z
12:30:38 <Deewiant> @pl \f x y z -> f (f x y) z
12:30:38 <lambdabot> (.) =<< (.)
12:30:41 <vixey> other than flip (ap id (flip ($ x) y)) z
12:30:42 <vixey> 20:30:39	<Deewiant> @pl \f x y z -> f (f x y) z
12:30:46 <Deewiant> well, that's not too bad
12:30:52 <Deewiant> (.) >>= (.=
12:30:54 <Shiruka> that's not clearer or simpler..
12:30:56 <Deewiant> s/=/)/
12:31:02 <Deewiant> no, but at least it's shorter. ;-P
12:31:18 <Deewiant> ?ty fmap >>= fmap
12:31:19 <lambdabot> forall a (f :: * -> *). (Functor f) => (a -> f a) -> a -> f (f a)
12:31:20 <jpcooper> what is @pl?
12:31:25 <Deewiant> @pl \x -> x + 1
12:31:25 <lambdabot> (1 +)
12:31:30 <Deewiant> @help pl
12:31:31 <lambdabot> pointless <expr>. Play with pointfree code.
12:31:31 <jpcooper> point free?
12:31:47 <jpcooper> right
12:32:23 <vovik> apparently playing with pointless code means figuring out that \x -> x+1 is the same as (1 +)
12:32:52 <hml> s
12:32:54 <hml> p
12:32:58 <olsner> no, that is only the beginning :D
12:33:06 <lispy> ?pl \x -> x - 1
12:33:07 <lambdabot> subtract 1
12:33:08 <vixey> vovik: I should think not..
12:33:18 <vixey> vovik: would be better to write (+ 1)
12:33:28 <vovik> of course..
12:33:33 <Shiruka> figuring out (+) will not get you very far in the pointlesscated haskell contest :-)
12:33:42 <vixey> the time complexity of a + b may be very different to that of b + a
12:34:10 <lispy> vixey: yes, but look what lambdabot answers:
12:34:14 <lispy> ?pl \x -> x + 1
12:34:14 <lambdabot> (1 +)
12:34:20 <lispy> vixey: she reverses it!
12:34:25 <vixey> why?
12:34:36 <lispy> I have no idea
12:34:47 <ahunter> > foldl 3 (+) [1,2]
12:34:48 <lambdabot>        add an instance declaration for
12:34:48 <lambdabot>       (Num ((a -> a -> a) -> b -> a ->...
12:35:00 <ahunter> erm, oops
12:35:05 <ahunter> > foldl (+) 3 [1,2]
12:35:06 <lambdabot>  6
12:35:24 <ahunter> (+) ((+) 3 1) 2
12:35:25 <lispy> > foldl1 (+) [3,1,2]
12:35:26 <lambdabot>  6
12:35:46 <ahunter> well, that's nicer than (.) =<< (.)
12:36:04 <Shiruka> vixey: that (a+b) vs (b+a) comment made me think wacky thoughts :-D
12:36:12 <lispy> ?qc \(x:xs) -> foldl (+) x xs == foldl1 (+) (x:xs)
12:36:12 <lambdabot> Not enough privileges
12:36:24 <lispy> Whoa, qc is privileged now?
12:36:52 <jganetsk> what does ?pl do?
12:36:54 <Toxaris> @check \(x:xs) -> foldl (+) x xs == foldl1 (+) (x:xs)
12:36:55 <lambdabot>   Non-exhaustive patterns in lambda
12:36:57 <Shiruka> since long thunks like a+(b+(c+(d+...))), like sum function produces, cause eventually stack overflow...
12:37:13 <Shiruka> might you avoid it by switching between (a+b) and (b+a)..
12:37:23 <Shiruka> so that you'd get a binary tree in your thunks, limiting the stack depth to log2 n..
12:38:07 <ahunter> @check \f a b c -> f (f x y) z == foldl1 f [x,y,z]
12:38:09 <lambdabot>   add an instance declaration for (Arbitrary Expr)     In the expression: let...
12:38:09 <olsner> > fix$(.)<$>(:)<*>(<$>).(*).(*2)$1 -- pointlesscated :D
12:38:11 <lambdabot>  [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,2...
12:38:16 <lispy> ?check \as -> case as of {(x:xs) -> foldl (+) x xs == foldl1 (+) (x:xs); _ -> True }
12:38:17 <lambdabot>  OK, passed 500 tests.
12:38:24 <vixey> > iterate (join (+)) 1
12:38:25 <lambdabot>  [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,2...
12:38:29 <Toxaris> Shiruka: but how would you preprocess your input list into an input tree without producing O(n) deep thunks?
12:38:39 <vixey> > extendSequence [1,2,4]
12:38:40 <lambdabot>  [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,2...
12:39:09 <baaba> ?pl \f x -> case x of { (0) -> 0; (1) -> 1; otherwise -> f (x - 1) }
12:39:19 <lambdabot> (line 1, column 19):
12:39:19 <vixey> > map (2^) [0..]
12:39:24 <lambdabot> unexpected "{"
12:39:29 <lambdabot> expecting variable, "(", operator or end of input
12:39:31 <lambdabot>  [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,2...
12:39:31 <olsner> vixey: is that an oeis thingy?
12:39:33 <Toxaris> baaba: pl doesn't understand case afaik
12:39:38 <baaba> oh :(
12:39:56 <lispy> pl has a weird parses, iirc
12:40:06 <lispy> er parser*
12:40:09 <Shiruka> Toxaris: good question :-) I was thinking too simplistically, as if you could do random access to the list
12:40:33 <Toxaris> @pl \f x -> if x == 0 then 0 else if x == 1 then 1 else f (x - 1)
12:40:33 <lambdabot> ap (flip if' 0 . (0 ==)) . ap (flip if' 1 . (1 ==)) . (. subtract 1)
12:40:43 <jpcooper> is there a list function to replace an item at an index?
12:40:53 <jpcooper> like arrays' //
12:41:06 <Toxaris> I like this pl result, it's better extendible then the original term
12:41:11 <vixey> no you will have to write it
12:41:17 <jpcooper> okay
12:41:32 <Toxaris> (e.g., it uses a linear structure to encode the special cases, instead of a nested if structure)
12:42:29 <baaba> @pl \x f -> if x == 0 then 0 else if x == 1 then 1 else f (x - 1)
12:42:29 <lambdabot> ap ((.) . flip if' 0 . (0 ==)) (ap ((.) . flip if' 1 . (1 ==)) (flip id . subtract 1))
12:42:42 <twobitwork> ?where join
12:42:42 <lambdabot> I know nothing about join.
12:42:52 <Toxaris> @src join
12:42:52 <lambdabot> join x =  x >>= id
12:43:03 <Toxaris> not sure whether this helps
12:43:06 <Toxaris> :t join
12:43:11 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
12:43:16 <Toxaris> maybe this is better
12:43:36 <olsner> @pl \n x xs -> take (n-1) xs ++ (x : drop n xs)
12:43:36 <lambdabot> ap ((.) . ap . ((++) .) . take . subtract 1) (flip ((.) . (:)) . drop)
12:43:47 <vixey> > (join (div)`on`(+ 1)) 0
12:43:48 <twobitwork> I'm trying to figure out your "iterate (join (+)) 1" case above
12:43:48 <lambdabot>      Occurs check: cannot construct the infinite type: b = b -> c
12:43:48 <lambdabot>     Probabl...
12:43:48 <vixey> > (join (div)`on`(+ 1)) 1
12:43:49 <lambdabot>      Occurs check: cannot construct the infinite type: b = b -> c
12:43:49 <lambdabot>     Probabl...
12:44:06 <vixey> twobitwork, the type of join is
12:44:13 <vixey> m (m a) -> m a
12:44:13 <geezusfreeek> :t join (+)
12:44:14 <lambdabot> forall a. (Num a) => a -> a
12:44:17 <Toxaris> > map (join (+)) [1..10]
12:44:18 <lambdabot>  [2,4,6,8,10,12,14,16,18,20]
12:44:35 <vixey> the monad used is ((->)e)
12:45:00 <vixey> so,  join :: e -> (e -> a) -> e -> a
12:45:11 <vixey> oops
12:45:18 <vixey> join :: (e -> (e -> a)) -> e -> a
12:45:20 <vixey> anyway,
12:45:37 <vixey> what it means is to duplicate the parameter 'e'
12:45:50 <vixey> so, join (*) = \e -> e * e
12:45:51 <olsner> how can (+) be of type (e -> (e -> a))?
12:46:03 <vixey> e = e = a = Integer
12:46:13 <vixey> (+) :: Integer -> (Integer -> Isteger)
12:46:44 <olsner> oh, yeah, it was :t join (+) and not :t (+) that someone asked lambdabot above
12:46:59 <vixey> twobitwork, did I make sense ?
12:47:17 <dancor> hpaste announce broken?  "template haskell question with happs"  http://hpaste.org/9123
12:47:37 <vixey> whoever runs the hpaste bot hasn't brought it back
12:48:06 <vixey> glguy do you run the bot ?
12:48:16 <vixey> I thought you wrote the hpaste website
12:48:39 <Lemmih> dancor: SetMyState used to be
12:49:54 <Lemmih> dancor: 'setMyState' used to be more general?
12:51:05 <monochrom> hayoo!
12:53:15 <twobitwork> vixey: sorry... I'm half pondering what you said amidst distrctions
12:55:34 <shapr> hmm
12:55:59 <shapr> !paste
12:56:05 * shapr grumbles
12:56:09 <saml> @paste
12:56:10 <lambdabot> Haskell pastebin: http://hpaste.org/new
12:56:42 <olsner> the haskell on sparc project sounds really interesting! too bad I'm not a student anymore...
12:56:47 <shapr> I wonder why the announce bot didn't connect?
12:56:50 <Toxaris> Shiruka: maybe it is possible by processing the list in chunks of size 1, 2, 4 ... and processing each chunk as a binary tree
12:57:05 <shapr> whoops, time to board my plane
12:57:35 <monochrom> bon voyage shapr
12:57:44 * shapr waves
12:59:37 <vixey> bye
12:59:49 * araujo waiting the next openmoko shipment to get one
13:03:03 <BMeph> I'd love to work on the GHC-on-Sparc project...only, I'm a lot too much of a student. ;)
13:04:05 <geezusfreeek> this summer is the end of my studenthood. i don't even know if i am eligible for it
13:04:10 <vixey> BMeph, do you know RISC assembly?
13:04:36 * geezusfreeek does!
13:04:47 <geezusfreeek> although i have not _generated_ it before
13:04:59 <BMeph> vixey: Only by reputation. And even that knowledge is over 15 years old. :)
13:05:27 <monochrom> RISC is cool to generate. Not so cool to hand-code. Writing generator is cool.
13:05:54 <jganetsk> do either of the two simons ever come to this room?
13:05:58 <glguy> yes
13:06:05 <monochrom> RISC is extreme imperative programming. :)
13:06:40 <geezusfreeek> i used to be a computer engineering major and over three courses we covered the design of MIPS architecture
13:06:57 <b_jonas> monochrom: heh
13:07:13 * BMeph was also a computer engineering major...in 1990
13:07:19 <b_jonas> monochrom: except when it's smp, right?
13:08:00 <geezusfreeek> i know absolutely nothing about sparc though
13:09:09 <dons> ?users
13:09:10 <lambdabot> Maximum users seen in #haskell: 483, currently: 481 (99.6%), active: 29 (6.0%)
13:09:16 <dons> hmm. new high score?
13:09:31 <dons> i guess any news *is* good news
13:09:35 <glguy> The winner, it's you!
13:09:37 <dons> yep, new high score.
13:09:41 <idnar> heh
13:09:53 <dons> i'd love to see that 500 mark fall.
13:10:11 * vixey too
13:10:25 <dons> #C is sitting on 520, next up. :)
13:10:47 <dons> oh, i note #django's nearly double #rubyonrails now.
13:11:01 <geezusfreeek> hmm, that is interesting
13:11:03 <dons> that's new.
13:11:24 <dons> ?users
13:11:24 <lambdabot> Maximum users seen in #haskell: 483, currently: 481 (99.6%), active: 28 (5.8%)
13:12:34 <BMeph> Are there any serious Ruby programmers that don't use RoR? Not trolling, honest, just ignorant. :)
13:12:49 <geezusfreeek> BMeph: i was a ruby programmer before rails
13:12:53 <jganetsk> wouldn't you want to ask that question in #ruby?
13:13:02 <vixey> hi jganetsk
13:13:23 <dolio> I used ruby before rails, too.
13:13:35 <dolio> Although I don't know how serious I was.
13:13:36 * vixey too
13:13:51 <dons> people seem to use ruby for little scripting jobs.
13:13:59 <dons> and there's a couple of console apps i know of.
13:14:17 <geezusfreeek> i've written a couple small games and a genetic programming library in ruby
13:14:26 <geezusfreeek> but that was a while ago
13:14:46 <geezusfreeek> interestingly, once rails became popular, a lot of ruby programmers started migrating away from ruby to other languages
13:14:58 <BMeph> geezusfreeek, dolio: Exactly.
13:15:21 <geezusfreeek> to the likes of smalltalk, scheme, haskell, and Io
13:15:37 <Shiruka> huh, I thought ruby was used for similar stuff as python
13:15:46 <Shiruka> after all, they are very similar languages
13:15:48 <dons> http://www.reddit.com/comments/6t58u/Haskell_Weekly_News_busy_busy_busy_Sun/
13:15:49 <lambdabot> Title: Haskell Weekly News: busy, busy, busy! Sun sponsorship, beginners community, zip ..., http://tinyurl.com/6ybqty
13:16:08 <dolio> I can't remember how I lost my interest in ruby exactly. Haskell may have had something to do with it.
13:16:22 <dolio> It was before rails as well, I think.
13:16:37 <dons> is hayoo read to be linked to from haskell.org?
13:16:40 <dons> next to the hoogle link?
13:16:58 <Toxaris> Shiruka: my try on general binary folding to avoid building big thunks: http://hpaste.org/9124
13:17:00 <dolio> It's already linked on hackage.
13:17:04 <BMeph> jganetsk: If I were more than cursorily interested in Ruby, I wouold. :)
13:17:06 <geezusfreeek> i believe it was ruby that sparked my interest in programming languages because i read about matz's goals and stuff, so when i moved away from ruby it was more just to learn other languages
13:17:08 <dons> oh?
13:17:20 <dons> ah yes!
13:18:27 <vixey> why he chose to implement it in C ... in such a horrible style
13:18:40 <Shiruka> Toxaris: haha :-) I didn't think too long about it as it's not a real problem.. after all, you can define sum = foldl' (+) 0 to get O(1) thunk depth
13:18:40 <vixey> he could have learned something from the lua code
13:19:20 <Toxaris> Shiruka: there may be other uses. consider an operation which is faster when called with smaller arguments on both sides
13:20:01 <Shiruka> hmm, true
13:20:45 <Toxaris> > growfold f x 0 [a, b, c, d, e]
13:20:46 <lambdabot>  f a (f b (f c (f d (f e x))))
13:20:56 <Toxaris> hmm not exactly what I hoped for
13:21:03 * Toxaris goes back to coding
13:21:34 <mar77a> is there any situation in which String is better than ByteString
13:21:38 * vixey does not know what to code
13:21:41 <Toxaris> > binfold f x 3 undefined [a, b, c, d, e]
13:21:42 <lambdabot>  f a (f b (f c (f d (f e x))))
13:21:49 <Toxaris> ohh that's the problem
13:21:50 <Shiruka> you could just punt on using plain lists, stuff the things to an IntMap by index and then build the binary tree the obvious way :-)
13:21:55 <Toxaris> lambdabot is a great debugger :)
13:22:25 <Toxaris> Shiruka: but it should stream!
13:23:24 <ptolomy2> Hooray Haskell. I was able to add a major feature to my program by changing a type, passing a function, adding a simple case statement, then trivially resolving the remaining compile errors. Fully working now, a total of 5 lines changed.
13:23:32 <Shiruka> yup, that's the problem with intmap :-)
13:24:10 <Shiruka> your approach of 1, 2, 4, 8, ... sounds like the way to do it for streaming, reminds me of some data structure in some paper by okasaki
13:24:44 <ptolomy2> Oh. I left out "think about it for a day", which was an important step.
13:25:00 <vixey> hehe
13:25:56 <ptolomy2> But the way haskell forces you to structure your code, in my experience, feels a bit awkward to begin with but pays off big-time later when you have to make a big change and it ends up being surprisingly easy.
13:25:58 <vixey> yeah, not a valid proof
13:26:06 <vixey> :S
13:26:12 <vixey> how did I do that
13:26:18 <luntain> Couldn't match expected type `network-2.1.0.0:Network.URI.URI' against inferred type `URI'
13:26:31 <luntain> how to deal with this error?
13:29:15 <Shiruka> mar77a: I haven't used ByteStrings as I haven't had the need for speed there, but I'd hazard a guess simply based on the name that doing Unicode-aware processing with ByteStrings would be more difficult than with Strings
13:30:10 <mar77a> > "Â¥"
13:30:11 <lambdabot>  "\165"
13:30:21 <vixey> > "mar77a"
13:30:22 <lambdabot>  "mar77a"
13:30:39 * mar77a goes back to coding his game in C++
13:34:35 <thoughtpolice> you can always use utf8-string which provides drop-in functions for bytestrings/strings/System.IO for utf8
13:35:04 <ptolomy2> thoughtpolice: Really? It does utf8 bytestring stuff?
13:35:08 * ptolomy2 goes off to hackagedb.
13:35:18 <thoughtpolice> ptolomy2: cabal install utf8-string
13:35:20 <thoughtpolice> :)
13:36:06 <thoughtpolice> luntain: it basically happens when you have package version mismatches
13:36:24 <thoughtpolice> luntain: imagine if you have package A and it depends on network, so you build it against network-2.1, no big deal
13:36:34 <thoughtpolice> then you upgrade network to network-2.2
13:36:48 <thoughtpolice> and try to build something against network *and* package A
13:36:55 <thoughtpolice> so A is built against an old version
13:37:42 * ptolomy2 wishes his computer knew what "cabal install" meant.
13:38:00 <thoughtpolice> luntain: the way to fix it is... suboptimal, to say the least. you will have to go back to all packages that depend on network and rebuild them against the newer version of network
13:38:40 <thoughtpolice> ptolomy2: it's very very useful. install the newest cabal (1.4.0.1) and cabal-install 0.5.1, http://haskell.org/cabal
13:38:41 <lambdabot> Title: The Haskell Cabal
13:38:53 <thoughtpolice> automated package installation through hackage
13:39:09 * ptolomy2 tends to wait until such things are available on macports.
13:39:25 <thoughtpolice> ptolomy2: hah, I would, but I've become so used to compiling my own stuff
13:39:27 <luntain> thoughtpolice: I have cabal-install, can I do it easily with this?
13:39:34 <thoughtpolice> i only use macports for very basic stuff
13:39:46 <thoughtpolice> luntain: you can do 'cabal upgrade' iirc
13:40:00 <thoughtpolice> it will upgrade every package and link everything against the most recent version of.. everything
13:40:53 <thoughtpolice> ptolomy2: but since I installed ghc from a mac installer pkg I can't install anything for ghc off macports which is kind of a drag
13:40:56 <Shiruka> hm, interesting, utf8-string *does* have bytestring-processing functions.. I thought it didn't :-)
13:41:02 <monochrom> w00t, haskell daily news is out!
13:41:46 <luntain> thoughpolice: didn't do anything, is Network.URI and Network.HTTP in one cabal package: Network-2.1.0.0?
13:41:55 <dolio> It's daily now? :)
13:42:13 <lelf> Hehe
13:42:14 <dolio> I suppose compared to the old "weekly" it is.
13:42:17 <monochrom> I always exaggerate. :)
13:42:26 <thoughtpolice> thorkilnaur: i thought Network.HTTP was apart of the http package
13:42:35 <thoughtpolice> URI is part of network I believe
13:42:40 <thoughtpolice> er, luntain
13:42:43 <monochrom> In those days I called it haskell biannual news or something.
13:42:57 <dons> :P
13:43:17 <thoughtpolice> luntain: have you tried 'cabal update' first? it'll get the recent package list off hackage
13:43:34 <monochrom> Nowadays every time it's out my brain subconsciously goes like "again? didn't I just saw another one yesterday or something?" :)
13:43:47 <thoughtpolice> luntain: alternatively, if you have a package that depends on network, but is *built* against an older version
13:43:51 <Shiruka> ah, but even if it is biannual, there still exists a day of publication for each time, so in that sense it would be daily ;-)
13:44:00 <dolio> dons: I played for a few minues with a binary-based Show for byte strings, but my initial, probably unrepresentative test (showing an array of 10 million ()s) says it's slower than String.
13:44:07 <thoughtpolice> luntain: you can do 'cabal upgrade <package>' which will install the latest version, but also build it against all the most recent dependencies
13:44:42 <dolio> Although I may have been doing something wrong.
13:45:19 <dolio> But I think building a big Put from the [()], was a lot of overhead.
13:45:36 <dons> dolio: interesting.
13:45:37 <monochrom> zipper for rose tree on hackage may be royally useful some day.
13:45:46 <luntain> thoughtpolice: yes, I have done cabal update, I think I have http package built against old network
13:46:26 <thoughtpolice> luntain: right, then 'cabal upgrade http'
13:46:36 <thoughtpolice> should take care of it
13:46:37 <dolio> Er, that should be a *list* of 10 million ()s. I'm going to lose my FP license here.
13:46:45 * ptolomy2 wonders about a version of Text.Printf for Bytestring.
13:46:46 <chrisdone> evening
13:46:52 <chrisdone> gwern: ping
13:46:55 <luntain> thoughpolice: wow! works :), thanks a lot
13:47:05 <monochrom> Oh God, haskell tutorial screencast, the guy types out loud!
13:47:09 <thoughtpolice> luntain: excellent! np :)
13:47:25 <dolio> Types out loud?
13:47:34 <dolio> Like, when they narrate what they're typing in TV shows?
13:47:42 <monochrom> The opposite, I mean.
13:48:01 <monochrom> Think of Charlie Chaplin teaching you Haskell in a movie.
13:48:37 <lament> that would be pretty bad.
13:49:21 <dons> dcoutts: how do I know what flags cabal passes to alex?
13:49:22 <monochrom> I commend this author for accelerating the screencast. Video speed is like 10 times his typing speed. The video is under 4 minutes.
13:50:24 <monochrom> Another way to think of this screencast is literate programming on the fly.
13:51:08 <Shiruka> I don't think haskell really needs more simple tutorials, but it would be cool to have ones that showed off cool stuff asap
13:51:11 <MyCatVerbs> monochrom: Charlie Chaplin screencast, as in they're typing code into an editor and inserting comments in order to explain to the viewer what's up?
13:51:32 <monochrom> Yes exactly.
13:51:52 <chrisdone> I've done that kind of thing with shared editors and shared screen sessions
13:51:57 <Shiruka> like some lisp tutorials that jump into macros as soon as humanly possible (and assume of course that the reader knows a couple of common programming languages and is not a newbie as a programmer)
13:52:03 <chrisdone> someCodeHere -- comment about the code here
13:52:40 <monochrom> Well, Shiruka may be right. I think this screencast demonstrates a new technique of screencasting done right. You can now make your own with the content you desire. I commend the technique, not necessarily the content.
13:55:54 <monochrom> "Haskell is lazy function" :)
13:56:43 <Shiruka> I wonder how many programming languages the average haskell programmer has used
13:56:55 <vixey> uncountable
13:57:20 <monochrom> Anyway, interesting technique and crazy guy. :)
13:57:20 <Dr_Foo> _|_
13:59:51 <Shiruka> GHC is a lazy function that takes the world in and spits it out after mangling it a bit
14:00:05 <Shiruka> if you crash it while it does this, you're responsible for the end of the world
14:00:28 <vixey> Error: EOW
14:01:10 <olsner> bah! that'd only be the end of one copy of it; the old world is still around there... as long as you remembered to think about it (lest it be garbage collected)
14:01:13 <chrisdone> use a ``watchdog''
14:03:01 <olsner> hmm... shouldn't this work? time :: World -> World; universe = fix time
14:03:36 <opqdonut> olsner: not really?
14:03:39 <nominolo> @seen keithw
14:03:39 <lambdabot> I haven't seen keithw.
14:03:45 <opqdonut> that would probably give the heat-death state of the universe
14:04:25 <Shiruka> maybe the next version of ghc does call endOfTheWorld when it would otherwise crash
14:04:51 <Shiruka> then it would always work perfectly; we would never be in any of the worlds which end
14:05:25 <Shiruka> until some haskell programmer causes it to crash for all inputs, at which point the multiverse ends
14:06:15 <olsner> there would be some way for the mechanism for ending the world to fail, and so you end up in a world that should've ended but didn't
14:06:26 <monochrom> Nah, GHC will just say "mah brain haz exploded" and move on. :)
14:09:35 <Shiruka> well, at least we'll know what has been tried when we read the news that a sudden meteor shower has obliterated the homes of all ghc developers and they have passed on to eternity :-)
14:10:20 <vixey> im so confused
14:11:08 <BMeph> GHC: The impossible has happened!
14:11:22 <Toxaris> BMeph: :)
14:11:22 <BMeph>      The world has ended
14:11:34 <Toxaris> BMeph: :))))
14:11:43 <Toxaris> sorry to disrupt your joke
14:11:44 <chrisdone> Â·_.
14:11:56 <Toxaris> "Report this as a bug at ..."
14:12:09 <dolio> dons: Incidentally, I don't mean the binary Show is slower than 'pack . show' (that's way slower), just slower than print.
14:14:18 <dons> ah so we can do better.
14:14:21 * BMeph barely escapes from the GHC Wiki - GHC manual link loop
14:14:57 <dolio> dons: Yeah, you can do better than what people usually end up doing.
14:15:45 <chrisdone> BMeph: âGHC load letter? what the fuck does that meanâ½â
14:17:29 <dons> ?users
14:17:30 <lambdabot> Maximum users seen in #haskell: 483, currently: 469 (97.1%), active: 20 (4.3%)
14:18:47 <Botje> \bot should also list how many of those users have a PhD
14:19:10 <name_> haha
14:19:23 <dons> we added two this week, i hear.
14:19:41 <TomMD> who?
14:19:43 <Botje> ah, congratulations to them, then
14:19:45 <TomMD> ndm and?
14:20:18 <byorgey> and Syzygy-
14:20:27 <byorgey> aka Mikael Johansson
14:22:12 <TomMD> I'm going to have to start my course work soon before I'm the only one with 'just a B.S.' ;-)
14:22:19 <Shiruka> nah, not list PhD:s
14:22:36 <Shiruka> it should list people who know some category theory, now that's scary
14:23:37 <Shiruka> and it's sure to be a high number here :-P
14:25:53 <opqdonut> heh, it would be great
14:26:18 <opqdonut> "483, currently: 469 (97.1%), active: 20 (4.3%), PhD: 40 (8,6%)"
14:27:31 <olsner> should count hackage contributors too
14:28:13 <Deewiant> "PhD: 40 (8,6%) Hackage contributors: 40 (8,6%) GHC developers: 40 (8,6%)"
14:29:22 <hackage> Uploaded to hackage: bytestring-lexing 0.1.2
14:30:59 <dons> TomMD: you saw http://haskell.org/opensparc/ ?
14:32:55 <TomMD> dons: I did.  Thank you for asking.
14:33:42 <hml> --- is like //;
14:33:49 <hml> how can I find the  equiv of /* ... */ in haskell?
14:33:57 <kryptiskt> {-
14:33:59 <TomMD> hml: {- -}
14:34:00 <kryptiskt> -}
14:34:23 <TomMD> and, as krptiskt showed, you can nest them.  My comments would have been nested in his.
14:34:35 <kryptiskt> :-)
14:35:07 <monochrom> I recently found a fun fact about XQuery: comments are (: this is a comment :)
14:35:13 <Apocalisp> \/*...*/ is the robot invader operator, right?
14:35:21 <monochrom> They hijacked my smileys for comments!
14:35:58 <Apocalisp> Smiley brackets!
14:36:00 <Apocalisp> how cute
14:36:51 <olsner> > let (/*...*/) = (+) in 1 /*...*/ 1
14:36:55 <lambdabot>  2
14:37:00 <olsner> zomg, it worked
14:37:19 <newsham> making some polyglots?
14:37:44 <MyCatVerbs> olsner: haha, love it.
14:38:31 <Apocalisp> > let (_o/) = (++) in "high" _o/ "five"
14:38:31 <lambdabot>  Parse error in pattern at "in" (column 18)
14:38:42 <Apocalisp> bah
14:38:55 <newsham> underscore is for identifiers
14:39:35 <Shiruka> {- . -} -- this looks like a smiley too, just unrotated
14:41:25 <hml> kryptiskt , TomMD : thanks
14:42:12 <TomMD> As said as it is, my first 'problem' with Haskell was finding a function :: Int -> String.  Suppose I just picked the right tutorial that left that out but included comments ;-)
14:43:06 <TomMD> s/said/sad/
14:43:55 <olsner> my first problem with haskell was the realisation that despite haskell being a functional language you couldn't just throw every kind of data in a list
14:44:14 <Philippa> or to put it another way, that it's not lisp?
14:44:20 <MyCatVerbs> olsner: yes you can. [forall a. a]
14:44:32 <znutar> I had the same problem as TomMD but I ended up just writing a function instead of looking for one
14:44:39 <olsner> Philippa: indeed :)
14:44:41 <MyCatVerbs> olsner: but good luck extracting monomorphic values by means of any procedure other than length. :)
14:44:50 <Philippa> MyCatVerbs: last time I looked that tends to need extra annotations to make the conses work
14:45:26 <vixey> [()]
14:45:36 <vixey> unsafeCoerce back and forth
14:45:37 <Philippa> [forall a.Dynamic a => a] :-)
14:46:29 <MyCatVerbs> Philippa: IIRC [forall a. a] works just fine, provided you don't try to ,actually *do* anything with the values inside. ;)
14:46:47 <MyCatVerbs> s/ ,/ /
14:46:57 <Philippa> MyCatVerbs: at a bare minimum you need to annotate the list somewhere though
14:47:08 <Philippa> which isn't "just" putting stuff in it
14:48:29 <dcoutts_> dons: use build -v to see how cabal calls alex or any other tool, pass extra flags with configure/build --alex-option(s)=
14:49:23 <dcoutts_> dons: --PROG-options= passed to configure are persistent, ones passed to build are only for that run
14:50:25 <kryptiskt> my first problem with haskell was trying to learn it from "a gentle introduction"
14:51:03 <name_> yea i checked that one first too
14:51:05 <name_> diddnt work out so well
14:51:29 <name_> only set me back like 30min though so not like its a huge deal
14:51:37 <luntain> what does it mean if I get 'type mismatch' error on runtime?
14:51:46 <kryptiskt> a gentle introduction for peoplewho has five years FP experience
14:51:52 <Shiruka> gentle introduciton is gentle
14:51:56 <mar77a> lol
14:51:59 <Shiruka> ... compared to the haskell report!
14:52:07 <mar77a> that tutorial is nice if you have read some others
14:52:10 <Valodim> duh
14:52:11 <mar77a> and done a couple of months of haskell
14:52:20 <Philippa> kryptiskt: it was intended for people who knew other FPLs, yes
14:52:25 <Shiruka> but actually, it was the tutorial I read, and it was fine for me :-)
14:52:26 <Valodim> real programmers learn haskell from reading ghc source >:(
14:52:29 <ziman> or been given a course in school :)
14:52:35 <Shiruka> but OTOH I had already used Lisp and Ocaml
14:52:38 <Philippa> it was written at a time when hardly anyone who would read it hadn't
14:52:59 <hml> is there a way I can rewrite 'where mcons p q = p >>= \x -> q >>= \y -> return (x:y)' in the form of : 'where mcons p q = return(...) ...' ?
14:53:11 <kryptiskt> Philippa, I had C, C++ and assembler :-)
14:53:15 <Philippa> and the name was a reference to an older tutorial also aimed at a similar group of programmers
14:53:32 <olsner> hml: mcons = liftM2 (:) or something :)
14:53:33 <MyCatVerbs> kryptiskt: bah. C++ is a fantastic introduction to pure FP languages.
14:53:46 <hml> @src liftM2
14:53:47 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
14:54:01 <MyCatVerbs> kryptiskt: specifically, template metaprogramming. By the time I first touched a line of Haskell, I'd already halfway cottoned on to many of the ideas. ;)
14:54:03 <hml> olsner: very nice; thanks
14:54:13 <dublpaws> >foo :: a -> a -> (a -> a)
14:54:16 <baaba> type classes are concepts!
14:54:33 <kryptiskt> :-)
14:54:35 <olsner> template metaprogramming rocks :D
14:55:06 <dublpaws> is that how a closure signature looks ?
14:55:17 <Shiruka> ahhh, it's certainly funky and all, but it's not something I'd consider clean really.. fails the KISS principle, just like haskell type hackery
14:55:33 <hml> @hoogle liftM2
14:55:48 <lambdabot> Control.Monad.liftM2 :: Monad m => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
14:56:22 <Shiruka> good rule of thumb: "if your types take more than ten 80-character lines to print, please reconsider what you're doing ;-)"
14:56:33 <bwr> lol
14:56:59 <hml> @src liftM2
14:56:59 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
14:57:02 <olsner> I seem to recall someone (in here?) producing a multi-megabyte compiler message using templates
14:57:09 <Philippa> Shiruka: there's a good argument that we need ways of managing types rather bigger than that effectively
14:57:10 <name_> lol
14:57:29 <mar77a> @src liftM
14:57:29 <lambdabot> liftM f m1 = do { x1 <- m1; return (f x1) }
14:57:45 <Philippa> it's actually rather plausible to end up building large types for good engineering reasons
14:59:12 <chrisdone> some kind of variables for types would be nice sometimes >_>. like (Î»x. x -> x -> x) (CGIT IO (Maybe Int)) or whatever..
14:59:57 <Shiruka> Philippa: I don't think a type system like haskell's scales to such things
15:00:42 <dons> the large systems I've worked on typically have fairly broad architectural decisions encode in the type.
15:00:48 <Shiruka> if you need such, then you should be able to take parts of the types out and refer to them concisely
15:01:24 <Shiruka> like, the type of this expression is (SomeTypeFunction argument1 argument2) instead of (SomeTypeFunctionsAndEverythingItCallsFunctionBodiesConcatenatedHereInJustUnderTwentyMegabytes)
15:03:00 <kryptiskt> union types can become pretty big though, and that you can't take apart
15:04:24 <mar77a> is there some code auto-formatting
15:04:27 <mar77a> or format-fixer
15:04:35 <mar77a> that reads the code and aligns everything etc?
15:07:25 <Shiruka> it just seems somehow wrong to start embedding a programming language in types instead of reifying it some way :-)
15:07:51 <dons> Shiruka: http://hackage.haskell.org/packages/archive/sessions/2008.2.28/doc/html/Control-Concurrent-Session.html
15:07:52 <lambdabot> Title: Control.Concurrent.Session, http://tinyurl.com/6dhwft
15:08:20 <Shiruka> ouch...
15:09:11 <Philippa> Shiruka: I agree that as it stands Haskell's type system doesn't scale
15:10:20 <Shiruka> are there any plans on doing something about that, btw?
15:10:21 <matthew-_> oh it's fine
15:10:29 <matthew-_> it's just a little hairy in places ;)
15:11:03 <dons> it's fine. more proofs, less things that can go wrong at runtime
15:11:04 <matthew-_> and I've exposed a few bugs in GHC and the RTS by writing code like that ;)
15:11:41 <waern> and Haddock ;)
15:11:48 <dons> :D
15:11:58 <matthew-_> I'm hoping that will get fixed by Haddock 2 and GHC 6.10
15:13:00 <matthew-_> I'm currently implementing Bell/LaPadula security typings in DSL as a static analysis - i.e. the DSL gets analysed by GHC rather than some runtime typechecker
15:13:12 <Shiruka> dons: no problem about proofs, but it would sure be nicer if it'd be something like "f : a -> b -> c | HasNiceProperty(a, b, c)" and then HasNiceProperty is defined better in some 100-line file instead of a 100-line type carried around everywhere..
15:13:32 <mar77a> re-paste after the netsplit:
15:13:33 <mar77a> 18:04 < mar77a> is there some code auto-formatting
15:13:33 <mar77a> 18:04 < mar77a> or format-fixer
15:13:33 <mar77a> 18:04 < mar77a> that reads the code and aligns everything etc?
15:13:33 <matthew-_> you get used to it after a while - it's a different way of programming, and it's very verbose and slow, but it does work. It's just it's untyped, which is a shame ;)
15:14:58 <pejo> matthew, the stuff you're doing is not for mere mortals though. I wouldn't be able to do it.
15:15:00 <Shiruka> how about implementing a compielr instead? :-)
15:15:18 <Shiruka> *compiler even
15:16:31 <matthew-_> pejo: I think you'd surprise yourself how easy it is
15:16:33 <pejo> matthew, what is your thesis going to be about in the end?
15:16:51 <dons> hmm, type system DSLs
15:16:57 <dons> now that's an interesting idea.
15:17:06 <Shiruka> *horror*
15:17:06 <dons> more than just static checking notation extensions
15:17:12 <matthew-_> pejo: message passing concurrency in haskell
15:17:21 <dons> but an extended DSL for static properities
15:17:27 <dons> go matthew-_ !! go go
15:17:33 <matthew-_> dons: I have the While language implemented as a DSL with static inference of types
15:19:48 <vixey> matthew-: is it online?
15:19:57 <matthew-_> vixey: not yet, no. sorry
15:20:04 <matthew-_> really bleeding edge right now
15:20:13 <hml> how can I simplify this: func a 1 >>= \y -> func y 2 >>= \z -> func z 3 >>= \w -> func w 4 >>= \x -> return x
15:20:18 <vixey> I just put up my compiler
15:20:35 <vixey> it's for a language which is basically while but the programs in it can run in either direction
15:21:08 <vixey> well they added stacks to it .. so it's a little more than thta
15:22:37 <bd_> hml: depending on your definition of 'simple', that's already quite simple
15:22:58 <Dr_Foo> possibly a dumb question, but what is the haskell version of SDL_AddTimer()?
15:23:09 <vixey> let funk = flip funct
15:23:12 <matthew-_> vixey: my one extension is that I can assign booleans to vars and so I have two types: ints and bools and I can infer them and safely allow them to change type
15:23:16 <bd_> Dr_Foo: spawn a thread and sleep
15:23:28 <bd_> Dr_Foo: threads are cheap (ish?) in haskell
15:23:30 <vixey> funk 1 a >>= funk 2 >>= funk 3 >>= funk 4 >>= return
15:24:02 <vixey> hml ^
15:26:18 <dons> bd_: super cheap
15:26:44 <matthew-_> dons: I was going to do live variable analysis statically for a DSL, but then I thought about just how bizarre an idea that is. Security analysis actually seemed to be useful ;)
15:27:28 <Toxaris> > growfold 0 (+) x [0..20]
15:27:29 <lambdabot>  0 + (1 + 2 + (3 + 4 + (5 + 6) + (7 + 8 + (9 + 10) + (11 + 12 + (13 + 14)) + ...
15:28:06 <Toxaris> Shiruka: I think it works now :) http://hpaste.org/9124#a1
15:28:28 <Shiruka> at least by the lambdabot output looks like it works :-)
15:30:08 <chrisdone> as haskell programmers, anyone recommend a ruby tutorial? I need to learn it for a job, but most Ruby tutorials I've looked at are obnoxious and annoying to read
15:30:32 <Toxaris> Shiruka: But I have no clue how to test whether it is good for anything
15:32:05 <Shiruka> try some function that produces bigger values in some sense and works slower and slower for bigger values
15:32:18 <Toxaris> matthew-_: why is it a bizarre idea to do standard static analyses statically for DSLs?
15:32:23 <Shiruka> just (*) for Integers does that, but the performance doesn't degrade too quickly..
15:32:34 <matthew-_> Toxaris: what would you ever use it for?
15:32:40 <Shiruka> maybe iterate (*) a few times?
15:33:02 <matthew-_> do you actually want to be able to write "I only want a programme in this DSL that has x live at the 2nd statement" ?
15:33:22 <Shiruka> not that it's a sensible thing to compute though.. :-\
15:33:32 <Toxaris> matthew-_: as input for an optimizier obviously
15:33:43 <matthew-_> Toxaris: a type level optimiser?
15:33:49 <Toxaris> matthew-_: yes
15:34:14 <matthew-_> so you want to use the haskell type system to optimise embedded dsl programmes?
15:34:24 <Toxaris> sounds cool for me
15:34:30 <matthew-_> can you give me a use case?
15:34:49 <Shiruka> to implement (*) really slowly, you could factor each argument into multisets of primes, then union those and multiply back
15:35:07 <Shiruka> then you would get a function that's faster with growfold than normal fold
15:35:15 <Cale> chrisdone: I can only recommend a ruby tutorial for people who are not in a hurry to learn the language, but instead want to be distracted as much as possible.
15:35:40 <Shiruka> ... maybe. But again, not sensible..
15:37:14 <Toxaris> matthew-_: I'm pretty sure you could sell it as cool (as in: get papers accepted), but I have no use case in mind where you couldn't just dynamically optimize it
15:38:19 <matthew-_> Toxaris: the code would be much bigger and more complex than doing it dynamically and would also be slower
15:38:28 <Toxaris> matthew-_: on the other hand, there is need for user-defined compile-time optimization: consider ghc RULES
15:38:33 <chrisdone> cale: which would that be? I was considering âRuby User's Guideâ, the translated from Japanese one
15:38:57 <Cale> chrisdone: Why's Poignant Guide To Ruby
15:39:04 <Toxaris> matthew-_: the run-time code would be faster, I guess. equally good optimized, but without having to do the optimization
15:39:27 <chrisdone> cale: I think I'll pass on that one. thanks, though
15:39:40 <Cale> chrisdone: "Programming Ruby" seems somewhat sensible
15:39:50 <Toxaris> matthew-_: wouldn't it be nice to perform list deforestation with type-level analysis and optimization, so that we could drop the RULES language and just use Haskell to describe our libraries
15:39:53 <Cale> (http://www.ruby-doc.org/docs/ProgrammingRuby/)
15:39:54 <lambdabot> Title: Programming Ruby: The Pragmatic Programmer's Guide
15:40:12 <chrisdone> cale: ah, thanks :)
15:40:32 <baobab> hello functional people :)
15:40:36 <matthew-_> Toxaris: nice, yes. practical no. I'd want a decent kind system to start with. And some better type level combinators ;)
15:40:41 <chrisdone> cale: yes, this looks similar to Read World Haskell
15:41:34 <baobab> I have a very stupid question to ask... how can I import a module that is in a superdirectory in ghc (where superdirectory = ../ on unix)
15:41:58 <Toxaris> matthew-_: So it is not easy. That doesn't make it bizarre. By proving that it is possible, one could argue for better type-level programming support, making it easy in future languages
15:42:15 <baobab> I keep getting "Failed to load interface for 'X'" -_-
15:42:39 <matthew-_> Toxaris: oh certainly. But to do any meaningful optimisation would require an enourmous amount of work in the type system
15:42:50 <hml> @hoogle FiniteMap
15:43:05 <lambdabot> No matches found
15:43:16 <Toxaris> baobab: generally, it is a good idea to lay out your source files like ghc expects it
15:43:25 <BMeph> kowey: ping
15:43:38 <BMeph> preflex: seen kowey
15:43:38 <preflex>  kowey was last seen on #haskell 52 days, 11 hours, 31 minutes and 29 seconds ago, saying: hmm... yeah, just signaling the problem
15:43:55 <BMeph> Okay, unping. :)
15:44:18 <baobab> Toxaris: does ghc not support import from different directories?
15:44:27 <matthew-_> baobab: you might be able to make it work with -i.. -i.
15:44:27 <Toxaris> baobab: if that is not possible, pass the appropriate flag to ghc to extend the search path
15:44:34 <Toxaris> baobab: which I have forgotten :(
15:44:46 <BMeph> shell
15:44:48 <BMeph> ghci
15:45:03 <baobab> I'll try the -i argument :)
15:45:04 <BMeph> D'Oh! Wrong IRC client, lol. :)
15:45:07 <chrisdone> what kind of bot is preflex?
15:45:57 <Toxaris> matthew-_: I would expect the analysis to be the more complex part, but I have not tried of course
15:46:41 <BMeph> baobab: It's simple to do, but I forget how at the moment. :)
15:46:45 <Toxaris> matthew-_: anyway, I understand why you decided to go for "extending the typechecking" instead of "adding optimization".
15:47:01 <BMeph> baobab: (without the -i option, too.)
15:47:03 <matthew-_> Toxaris: with eg live variable
15:47:07 <Shiruka> btw, the normal term for "superdirectory" is "parent directory", like a parent node in the directory tree :-)
15:47:14 <baobab> it isn't working :(
15:47:15 <matthew-_> Toxaris: I can do the kill sets and the gen sets
15:47:35 <matthew-_> Toxaris: and I can even do the graph edges
15:47:38 <shepheb> I have a newtype Query a = Query (ReaderT Window X a), and I need it to be an instance of MonadTrans so I can lift into it. but it won't derive MonadTrans (with GeneralizedNewtypeDeriving). I can't figure out how to write the instance
15:48:01 <matthew-_> Toxaris: but I'm a little stuck on doing the fixpoint termination...
15:48:07 <baobab> BMeph: mmmh maybe i'll look through ghc manual for it, thx :)
15:48:54 <BMeph> baobab: Well, thank me when I remember how to do it again, and pass it on, heh-heh. I'll take the advance thanks for now, though. :)
15:49:29 <Toxaris> http://www.haskell.org/ghc/docs/latest/html/users_guide/separate-compilation.html#search-path
15:49:30 <lambdabot> Title: 5.6. Filenames and separate compilation, http://tinyurl.com/yyunf2
15:49:31 <baobab> BMeph: haha I'll thank myself later then :D
15:49:49 <Toxaris> I would try ghc -i..
15:50:04 <Toxaris> or ghc -i../ or -i./.. or variations thereof
15:50:29 <baobab> mmh i didn't write the slash, i'll give it a try
15:50:58 <BMeph> baobab: Aye, try a way that works, then hunt for "tricky" other ways. :)
15:51:09 <hml> @hoogle Entry
15:51:09 <lambdabot> No matches found
15:51:23 <baobab> BMeph: k ;)
15:54:39 <Toxaris> > length . show . foldr (*) 1 . replicate 200000 $ 2
15:54:45 <lambdabot>  Exception: Time limit exceeded
15:54:52 <Toxaris> > length . show . growfold 0 (*) 1 . replicate 200000 $ 2
15:54:53 <lambdabot>  60206
15:55:08 <Toxaris> Shiruka: great idea to use (*)
15:55:10 <vixey> Toxaris, @src growfold
15:55:33 <Toxaris> vixey: http://hpaste.org/9124
15:55:38 <hml> hmm; when I import Data.Map; I get a conflict for Prelude.map vs Data.Map.map ; how do I fix this?
15:55:44 <Shiruka> but foldl' still works well enough for that
15:55:50 <Shiruka> length . show . foldl' (*) 1 . replicate 200000 $ 2
15:55:52 <vixey> import Data.Map hiding (map)
15:56:08 <Toxaris> Shiruka: but foldl' has different strictness properties
15:56:09 <pejo> hml, you could hide map, or import Data.Map qulalified.
15:56:22 <Shiruka> true :-)
15:56:30 <Toxaris> Shiruka: which doesn't matter for this case, of course, since (*) is strict anyway
15:57:29 <hml> pejo: got it working; thanks!
15:57:36 <Toxaris> vixey: note that the CPS version doesn't work
15:57:39 <hml> @hoogle addToFM
15:57:39 <lambdabot> No matches found
15:58:05 <vixey> why
15:59:23 <Toxaris> vixey: because f is only used in (f x (k xs)) and never applied to a larger-then-singleton subresult on the left
15:59:27 <Shiruka> Toxaris: but the reason I thought about (*) was a bit different than the foldl' vs foldr
15:59:41 <Toxaris> vixey: so growfold _ = foldr
16:00:08 <Toxaris> vixey: actually, I'm not sure how to keep f in the head position with CPS
16:00:38 <Toxaris> Shiruka: maybe you can do growfold' which is strict and uses the growing binary trees trick?
16:00:47 <Shiruka> because it's more efficient to compute (2*2)*(2*2) than (2*(2*(2*2))), as in the former case the argument size is small for most operations
16:02:14 <Shiruka> ... maybe. I don't recall how the time complexities of karatsuba multiplication etc. work, and this isn't going to matter for small ints..
16:03:17 <Toxaris> well, I'm computing 2^n for some n, you can make that as large as you want
16:04:09 <Shiruka> you could check if you can get better runtimes for growfold than foldl' for sufficiently big values :-)
16:04:49 <MyCatVerbs> Shiruka: you're right, but with the sample data you provided outweigh the asymptotically-interesting terms. ;P
16:05:12 <MyCatVerbs> Er, that sentence was missing... words.
16:05:18 <Shiruka> :-)
16:05:31 <dons> dcoutts: http://www.opensparc.net/news/2008-07/student-opportunity-at-haskell.org.html
16:05:32 <lambdabot> Title: Student Opportunity at Haskell.org | 2008-07 | News, http://tinyurl.com/6bj5xy
16:05:34 <dons> woot
16:05:35 <MyCatVerbs> *but with the sample data you provided, the constant factors outweigh the asymptotically-interesting terms.
16:05:44 <dcoutts> dons: yes! :-)
16:06:18 <dcoutts> dons: did you just notice or did you just get the email I sent a couple min ago? :-)
16:06:25 <dons> just noticed.
16:06:32 <dons> ah i see :)
16:07:32 <Shiruka> MyCatVerbs: and for Ints (as opposed to Integers), the operations are constant-time anyway :-)
16:08:38 <MyCatVerbs> Shiruka: ahem.
16:08:52 <MyCatVerbs> Shiruka: you are using Integers unless there's some specific reason not to, right?
16:09:06 <Arnar> evenin'
16:09:09 <dons> dcoutts: there's a link on the front page of h.o now
16:09:10 <Toxaris> Shiruka: for your use case, you can use binfold directly
16:09:11 <Arnar> @seen vincenz
16:09:11 <lambdabot> vincenz is in #haskell. I don't know when vincenz last spoke.
16:09:11 <MyCatVerbs> Shiruka: otherwise we'll lynch you for premature optimization.
16:09:15 <MyCatVerbs> Arnar: mornin'.
16:09:16 <dcoutts> dons: great
16:09:16 <Toxaris> Shiruka: (for your hypothetical use case)
16:09:19 <dcoutts> dons: thanks
16:09:21 <Shiruka> MyCatVerbs: :-D
16:09:33 <Toxaris> Shiruka: since you don't need the streaming trick of growfold
16:09:42 <Arnar> MyCatVerbs: heh .. we need a formal timezone-independent greeting
16:10:14 <Arnar> can I leave messages for people with lambdabot?
16:10:15 <MyCatVerbs> Arnar: actually, I quite like the current system.
16:10:22 <vixey> @later tell Arnar yes you can
16:10:22 <lambdabot> Unknown command, try @list
16:10:27 <vixey> @tell Arnar yes you can
16:10:27 <lambdabot> Consider it noted.
16:10:42 * vixey obviously misses sarahbot...
16:10:45 <MyCatVerbs> Arnar: its idiosyncrasies please me.
16:10:54 <BMeph> MyCatVerbs: In the Western US, we have one - "Howdy!" ;)
16:10:54 <Toxaris> @help tell
16:10:54 <lambdabot> tell <nick> <message>. When <nick> shows activity, tell them <message>.
16:10:56 <Arnar> MyCatVerbs: yes.. I agree
16:10:56 <lambdabot> Arnar: You have 1 new message. '/msg lambdabot @messages' to read it.
16:11:02 <Arnar> ah.. nice
16:11:03 <Arnar> thanks
16:11:11 <MyCatVerbs> vixey: who was sarahbot?
16:11:20 <BMeph> vixey: Didn't the sarahbot...get Terminated? ;)
16:11:29 <Arnar> @tell vincenz thx for the help many weeks ago: http://www.hvergi.net/2008/07/parsing-annotated-postfix-operators-with-haskell/
16:11:29 <lambdabot> Consider it noted.
16:11:34 <Shiruka> "mornin'" is a good general-purpose greeting
16:11:47 <Arnar> Shiruka: mornin' guvnr
16:11:53 <Shiruka> because morning is defined to be whenever I wake up, and I suppose others have similar self-centric definitions
16:12:09 <MyCatVerbs> BMeph: where I'm from, it's "rite butt?"
16:12:54 * BMeph looks askance at MyCatVerbs' "interesting" cultural greeting...
16:12:54 <MyCatVerbs> Arnar: hee. Quick way to get your hindquarters kicked out of here is to greet people with "allo me luvver."
16:13:24 <MyCatVerbs> BMeph: I missed out the apostrophes. It's: 'right butt'?
16:13:28 <Arnar> MyCatVerbs: understandably
16:13:30 <BMeph> MyCatVerbs: Shouldn't that be "aloe me luvver"? ;)
16:13:45 <MyCatVerbs> BMeph: yeah, probably.
16:14:21 <Shiruka> sounds vaguely like pirate-speak..
16:14:21 <MyCatVerbs> BMeph: as in, "alright butty", but with the... uh, denizens, being too lazy to include the "al" or the "y".
16:14:34 <MyCatVerbs> Shiruka: more like taking the piss out of Somerset.
16:15:02 <Arnar> @arr
16:15:02 <lambdabot> Keelhaul the swabs!
16:15:08 <vixey> @keal
16:15:08 <lambdabot> doctor just give meds not fix prollem
16:15:24 <Shiruka> :-D
16:15:29 <vixey> @seal
16:15:29 <lambdabot> intuitive != imperative
16:15:45 <MyCatVerbs> @arr
16:15:46 <lambdabot> Aye
16:15:49 <MyCatVerbs> I like this one.
16:16:05 <Shiruka> has many important features, this \bot
16:16:24 <MyCatVerbs> @arr Who's a pretty parrot?
16:16:24 <lambdabot> I want me grog!
16:22:22 <maihem_> @arr
16:22:22 <lambdabot> I want me grog!
16:22:39 <bitrot> @blimey
16:22:40 <lambdabot> Unknown command, try @list
16:22:46 <bitrot> awww
16:28:02 <Toxaris> Shiruka: growfold seems to be 9 times faster then foldl' for 2^300000
16:28:14 <Toxaris> Shiruka: http://hpaste.org/9124#a3
16:28:19 <Toxaris> Shiruka: for timings
16:29:41 <Shiruka> interesting :-)
16:31:13 <Toxaris> so everything behaves as you predicted :)
16:31:49 <chrisdone> âit's all going as you predicted, my lordâ
16:33:40 <Toxaris> so once again, it is time to consider starting a blog
16:34:34 <Shiruka> heh, it's a fun enough hack, but looks very much like a solution looking for a problem :-)
16:34:58 <BMeph> Toxaris: "Toarcology" :)
16:35:10 <chrisdone> shiruka: today I read that about higher order functions
16:35:11 <BMeph> Toxaris: s//"Toxarcology" :)
16:36:28 <chrisdone> shiruka: âmetaprogramming, powerful macros, and higher-order functions are solutions in search of problemsâ
16:36:45 <Shiruka> oh, that reddit-linked article
16:37:17 <Shiruka> someone posted an url here too :-)
16:37:20 <Shiruka> *pasted
16:37:28 <chrisdone> I wouldn't know, don't read reddit. probably, though
16:37:33 <Toxaris> Shiruka: That's why I come to #haskell, to do random hacks without thinking about real problems
16:38:34 <Shiruka> I didn't really get what that article was going on about
16:39:24 <Shiruka> it seems to me that there's no big mystery about languages people like to use
16:40:18 <Shiruka> at least in the sense that "why isn't language X being used even though it's really good?", it just means that someone's definition of good is strange :-)
16:40:37 <kevogod> Why?
16:40:52 <Pseudonym> No, I disagree with that, unless you really stretch the definition of "good".
16:41:10 <Pseudonym> Usually, language X not being used despite being good comes down to external factors.
16:41:16 <Shiruka> well, at least people who I usually meet try to choose a good language for the job
16:41:31 <Pseudonym> Management, availability of programmers, third-party support, hysterical raisins etc.
16:41:31 <Shiruka> it's just that "good" includes things like "has good libraries for the task"
16:41:42 <chrisdone> FUD
16:41:51 <Pseudonym> I included FUD in "management".
16:42:31 <Shiruka> Pseudonym: I meant in cases when people use languages they like :-)
16:42:36 <RayNbow> Toxaris: what exactly is this growfold function?
16:42:52 <Pseudonym> Ah, see I'm talking about the real world.
16:43:07 <Shiruka> the article in question included mention about languages popular in sourceforge etc.
16:43:22 <Pseudonym> Even in the open source world, external forces matter.
16:43:27 <chrisdone> it's a pity sourceforge sucks
16:43:28 <vincenz> Arnar: ?
16:43:28 <lambdabot> vincenz: You have 1 new message. '/msg lambdabot @messages' to read it.
16:43:47 <Toxaris> > growfold 0 f x [0..20]
16:43:48 <lambdabot>  f 0 (f (f 1 2) (f (f (f 3 4) (f 5 6)) (f (f (f (f 7 8) (f 9 10)) (f (f 11 12...
16:44:12 <Pseudonym> A friend of mine once commented that everything on Freshmeat at the time tended to be the equivalent of yet another GTK binding for "hello world".
16:44:19 <Toxaris> > foldr f x [0..20]
16:44:20 <lambdabot>  f 0 (f 1 (f 2 (f 3 (f 4 (f 5 (f 6 (f 7 (f 8 (f 9 (f 10 (f 11 (f 12 (f 13 (f ...
16:44:32 <Toxaris> RayNbow: voilà :)
16:44:44 <vincenz> Arnar: cool
16:44:45 <Shiruka> Pseudonym: of course it matters what you mean by "language"
16:44:48 <Pseudonym> I also suspect that new language enthusiasts tend to adopt new languages because they scratch an existing itch, not because they're looking for a new application to write.
16:44:56 <RayNbow> Toxaris: kind of balancing?
16:45:03 <Toxaris> RayNbow: yep
16:45:16 <Shiruka> I tend to include practical things into it, like available libraries, quality of tools, how good the community is, etc
16:45:22 <Toxaris> RayNbow: with growing binary trees
16:45:53 <Shiruka> looking at the language in isolation makes sense if you try to estimate how good it _could_ be though
16:46:07 <RayNbow> Toxaris: might be interesting to see it parallelized :)
16:46:23 <Toxaris> RayNbow: it is specifically meant to stream
16:46:30 <RayNbow> to stream?
16:46:43 <Toxaris> RayNbow: it should be as lazy as foldr
16:48:20 <vincenz> Arnar: interesting, you can limit the actions in a process :)
16:48:23 <Toxaris> RayNbow: so it is meant not to "read ahead" to compose a chunk of input elements to be processed by one thread, while another thread goes one processing the rest of the input list
16:48:27 <vincenz> Arnar: sounds great for security and sandboxing
16:50:48 <Toxaris> RayNbow: for that kind of stuff, I would just use: parfold f i xs = a `par` b `par` f a b where a = foldl' f i (take n xs); b = foldl' f i (drop n xs); n = length xs `div` 2
16:51:07 <Toxaris> RayNbow: (but be aware that i have no real clue about par)
16:51:21 * RayNbow has no idea about `par` either
16:51:47 <RayNbow> the (very) limited experience I have with parallel computing is using C/PVM and HPF
16:52:09 <dons> High Performance Fmap?
16:52:09 <dons> :)
16:52:25 <RayNbow> dons: close... F=Fortran ;)
16:52:40 <Pseudonym> C/Parallel Virtual Mapreduce
16:52:51 <Toxaris> maybe you could read (n / k) chunks of size k instead of k chunks of size (n / k) to distribute n input elements on k threads
16:52:52 <dons> Continuation/Parallel Virtual Monads
16:52:57 <Shiruka> :-D
16:53:04 <RayNbow> Virtual Monads? :p
16:54:52 <Toxaris> What I don't like about this "Why your favorite language is unpopular" stuff is the axiom successfull = popular
16:55:05 <Toxaris> I don't see why that should hold
16:56:07 <Shiruka> you have to define success somehow to talk about it, and popularity is one aspect of it
16:56:17 <baobab> hello guys, my problem with the directories is solved :) I wrote: "module Z.C where"  in file Z/C.hs and "import Z.C" in file ./A.hs
16:56:36 <Shiruka> if a language has 0 users, it's not successful, and if it has only 1 then its successful is somewhat limited, even though it could well do the job it was intended for :-)
16:57:05 <baobab> I can get some sleep now xD
16:57:10 <Shiruka> uh... *successfulness (if such a word exists..)
16:57:17 <baobab> bye bye!
16:57:19 <Toxaris> Shiruka: consider gbeta (a successor of beta, which is a successor of simular)
16:57:27 <monochrom> How many users of x86 assembly are there?
16:57:37 <dons> baobab: cool
16:57:45 <RayNbow> Toxaris: it kind of depends on your definition of popular ;)
16:57:56 <Shiruka> monochrom: about seventy bazillion? :-)
16:58:07 <baobab> dons: ^^
16:58:10 <Pseudonym> The classic example is a "little language".
16:58:15 <Pseudonym> Such a thing might have only one user.
16:58:17 <Toxaris> Shiruka: it is not exactly used by anyone. but it has influenced e.g. the desing of path-dependent types in Scala, which is quite popular
16:58:43 <Toxaris> Shiruka: please ignore all obvious spelling errors :)
16:58:58 <Shiruka> Toxaris: but that's different in the sense as it's the language-in-the-abstract vs. language-as-an-implementation
16:59:23 <Toxaris> Shiruka: sure, and there is no problem with talking about language popularity
16:59:44 <gwern> Shiruka: successfulness = success?
16:59:45 <Shiruka> if you include the former case, then a language might be successful even if it is never implemented, just explained in some paper as a nifty abstract thing
16:59:46 <Toxaris> Shiruka: but silently assuming that popularity == success is wrong imho
17:00:20 <Toxaris> Shiruka: is FOmega a successfull language?
17:00:49 <vixey> what's up
17:00:51 <Toxaris> If I do something, it is successfull if I reach my goals
17:01:03 <vixey> ?
17:01:08 <Toxaris> so I cannot judge success externally, only when I know the goals of the original "doers"
17:01:12 <vixey> I can't sleep
17:01:14 <Shiruka> my strategy with such assumptions is usually to go along with them, and then only object if something contradicts the assumption
17:01:25 <Toxaris> I want the assumptions stated in the articles
17:01:26 <Toxaris> :)
17:01:41 <Shiruka> because human communication becomes too difficult if you have to state every assumption explicitly
17:01:48 <Toxaris> but yeah, one can just read the article as being about popularity, and then it makes sense
17:02:15 <vixey> @quote
17:02:15 <lambdabot> bd_ says: ENOSLEEP_CLOWNSWILLGETME
17:02:17 <vixey> @quote
17:02:18 <lambdabot> OlegFacts says: Oleg solves NP-hard problems in N log N time... in the type system
17:02:33 <Shiruka> gwern: I guess so :-)
17:02:40 <vixey> n log n in the type system!
17:03:10 <Toxaris> @quote OlegFacts
17:03:10 <lambdabot> OlegFacts says: Oleg solves NP-hard problems in N log N time... in the type system
17:03:15 <vixey> I would like to see more type level programming
17:03:21 <Toxaris> hmm there are the oleg facts
17:03:25 <Toxaris> hidden in the quotes
17:03:30 <Toxaris> @quote OlegFacts
17:03:30 <lambdabot> OlegFacts says: Oleg solves NP-hard problems in N log N time... in the type system
17:03:35 <hml> @src break
17:03:35 <lambdabot> break p =  span (not . p)
17:03:36 <Toxaris> but somewhat boring selection
17:03:37 <Pseudonym> OK, only one Oleg fact.
17:03:39 <hml> @span
17:03:39 <lambdabot> Maybe you meant: seen slap
17:03:43 <hml> @src span
17:03:43 <lambdabot> Source not found. Your mind just hasn't been the same since the electro-shock, has it?
17:03:44 <vixey> what can you do with types in Haskell?
17:03:54 <vixey> programming with lambda and types
17:03:56 <Toxaris> @faq
17:03:56 <lambdabot> The answer is: Yes! Haskell can do that.
17:04:03 <RayNbow> vixey: compute factorial
17:04:16 <RayNbow> see http://www.willamette.edu/~fruehr/haskell/evolution.html ;)
17:04:17 <lambdabot> Title: The Evolution of a Haskell Programmer
17:04:18 <gwern> vixey: I think the standard answer is 'with the extensions, anything since its turing-compelte'?
17:04:22 <Shiruka> solving NP-hard problems in N log N time.. for some definitions of N (such as N = 2^M, where M is the "real" problem size ;-)
17:04:47 <vixey> yeah but can you do anything good with it
17:05:17 <vixey> I saw someone wrote a compiler and used types to make sure the types of the object language are preserved
17:05:29 <vixey> that involved some type programming
17:05:48 <vixey> and ST uses types to make sure refs don't escape
17:05:52 <vixey> that's another one..
17:05:59 <vixey> but other than this..? I don't realyl know
17:06:21 <Toxaris> you can simulate some forms of dependent typing
17:06:36 <Pseudonym> ?remember OlegFacts GHC doesn't have a type checker. It emails your types to Oleg for checking.
17:06:37 <lambdabot> I will remember.
17:06:41 <Toxaris> e.g. arrays of statically known size as a library on top of arrays with only dynamically known size
17:08:12 <Toxaris> you can simulate some forms of metaprogramming, e.g. Scrap Your Boilerplate, where the type systems "writes code for you"
17:08:44 <Shiruka> oleg's the guy who has all kinds of mind-blowing type hackery on his web site?-)
17:08:51 <Pseudonym> Yeah.
17:08:53 <Toxaris> Shiruka: indeed.
17:09:03 <Shiruka> hehe
17:09:09 <Toxaris> he writes excellent mini-articles to be posted to mailing lists etc.
17:09:32 <Toxaris> not only about types, about programming in general
17:09:34 <bd_> http://hpaste.org/9127 <-- Is there any theoretical reason for this to not work, or is it just the appropriate special case isn't in GHC?
17:11:08 <jeffwheeler> After building cabal-install, I can't seem to update it. Running cabal-install always seems to get "cabal: recv: resource vanished (Connection reset by peer)", which is a generic http library error, making it hard to diagnose.
17:11:29 <jeffwheeler> Err, "cabal-update", not "cabal-install" is what I ran.
17:11:40 <jeffwheeler> Errr, still wrong: no hyphen.
17:11:55 <lilachaze> bd_: in what way does it fail?
17:13:36 <Toxaris> jeffwheeler: cabal update doesn't update cabal, but updates the cached package list, afaik
17:13:48 <Toxaris> jeffwheeler: ok, doesn't help you :)
17:13:50 <bd_> lilachaze: paste updated
17:14:13 <jeffwheeler> Toxaris: which is exactly what I want to happen; it warns me whenever installing a package that it currently has no package list
17:14:19 <bd_> lilachaze: it's kind of expected - GADTs aren't supposed to allow you to return to a concrete type - but OTOH, the compiler has sufficient information to infer the type of 'b' from the functional dependency
17:15:21 <lilachaze> bd_: suppose you had "instance TypeFunc () Integer" as well. n is not necessarily Int; and, indeed, for the pattern match to have meaning, n must be of type TypeFunc () a => a, where a is rigid.
17:15:26 <Philippa> bd: AFAIK it's just not implemented
17:15:35 <jeffwheeler> When cabal-install works properly, it should be able to determine and install dependencies by itself, correct?
17:15:51 <Toxaris> lilachaze: that instance is not allowed because of fundep
17:15:53 <vixey> it's not about the open world assumption?
17:16:12 * lilachaze reading fundep arrow backwards :(
17:16:14 <Toxaris> I think it's about stupid fundeps which do not work as you want themt o
17:16:21 <Philippa> vixey: nope, that's not an issue
17:16:51 <Philippa> bd: can you do constrained constructors at all yet?
17:17:06 <bd_> Philippa: Well, they're necessary for GADTs
17:17:07 <lilachaze> bd_: what do you get if you remove the ::Int?
17:17:31 <bd_> lilachaze:
17:17:31 <bd_>     Could not deduce (Show b) from the context (TypeFunc () b)
17:17:31 <bd_>       arising from a use of `show' at Test.hs:9:36-41
17:17:35 <lilachaze> heh
17:17:36 <Philippa> bd_: not as far as I know they're not
17:17:41 <lilachaze> that's what i would have guessed :)
17:17:50 <gwern> @quote derive
17:17:50 <lambdabot> tez says: Anyway, I think the lesson is "don't drink and derive".  Or something.
17:17:57 <bd_> Philippa: Well, if you can't add an instance to the context of a GADT constructor, then you can never do anything to the value in there
17:18:00 <vixey> @quone
17:18:00 <lambdabot> greeting says: Welcome to #haskell where your questions are answered in glorious stereo!
17:18:21 <Shiruka> glorious glasgow stereo
17:18:37 <gwern> @quote trippy
17:18:37 <lambdabot> Pseudonym says: Lazy evalution is really, really trippy.
17:18:39 <Philippa> bd_: maybe it's late and I'm misparsing but none of that makes sense to me. GADTs aren't about classes or instancing, they're about coercions
17:19:01 <Philippa> as in, the constructor carries one with it just as an existential carries a type with it
17:19:06 <bd_> Philippa: Well, I mean, if you did: data GADT a where Constructor :: b -> GADT a    then you can never do anything to the value within
17:19:13 * Pseudonym is still having flashbacks from all the lazy evaluation he did in the 90s
17:19:16 <bd_> since 'b' can be anything
17:19:25 <Philippa> bd_: yeah, all you're saying there is that your own type doesn't make sense
17:19:28 <Philippa> (without them)
17:19:36 <Philippa> I'm asking about what GHC implements at all
17:19:36 <bd_> Philippa: oh, I see what you mean
17:19:44 <MyCatVerbs> Pseudonym: that's because you only evaluated those thunks just now.
17:19:46 <bd_> Constructor :: a -> GADT a would make sense
17:20:09 <bd_> Philippa: and, I believe it does implement GADTs with class guards, with the appropriate extensions (I'm testing with -fglasgow-exts)
17:20:20 <Shiruka> Pseudonym: lazy evaluation such as "do this task by monday", "ok, let's defer that until he requests for it again.."
17:20:37 <Philippa> bd_: "constraint" (as in "class constraint") is the canonical term for them AFAIK
17:20:38 <lilachaze> bd_: i think the problem is, the fundep isn't as magical as you want it to be, and for whatever reason, if you have a value of type (TypeFunc () b => b), that's not the same as a value of type Int
17:21:01 <lilachaze> bd_: but i'm not certain about that, and i don't understand why it would be the case :(
17:22:03 <bd_> lilachaze: If I have a class TypeFunc a b | a -> b; and I have an instance TypeFunc a b where a is known, there must exist a unique (or no) solution for b; therefore, it should be possible to derive b, as far as I can tell.
17:22:04 <lilachaze> bd_: if you change the class to "class (Show b) => TypeFunc a b | a -> b", and remove the ::Int, i suspect that fragment might work
17:22:16 <bd_> lilachaze: sure, that might work, but it's not what I want it for :)
17:22:53 <lilachaze> bd_: sure, but it would demonstrate that the problem is that (TypeFunc () b) => b isn't the same as Int.
17:23:13 <vixey> so what is the point in fundeps
17:23:16 <bd_> lilachaze: Show b => works fine :P
17:23:25 <lilachaze> right. :(
17:23:41 <bd_> vixey: to allow the compiler to derive some of the arguments to a instance based on another
17:23:50 <vixey> ..but it's not doing that
17:23:59 <bd_> eg: class (Monad m) => MonadState s m | m -> s
17:24:05 <Philippa> vixey: yes it is. Think of the instance as a relation for a moment
17:24:07 <bd_> vixey: Not when combined with GADTs here
17:24:16 <Philippa> oh, yeah, not here it's not doing currently
17:24:19 <bd_> which I'm beginning to think is a bug :)
17:24:29 <Philippa> bd_: you're probably justified in mailing SPJ or one of the mailing lists and asking WTF
17:24:46 <bd_> which mailing list? :)
17:25:03 <vixey> how come type classes are really complex?
17:25:17 <Philippa> bd_: may as well use -cafe
17:25:18 <vixey> do they need to be?
17:25:24 <Philippa> vixey: yes
17:25:30 <lilachaze> bd_: does this compile: f :: TypeFunc () b -> String; f = show
17:25:40 <lilachaze> (as a simpler example without GADTs)
17:25:42 <vixey> why?
17:25:47 <bd_> lilachaze: No, because TypeFunc isn't a type :P
17:25:50 <Philippa> vixey: coherency's a PITA, basically
17:26:06 <lilachaze> bd_: d'oh. i meant: f :: TypeFunc () b => b -> String; f = show
17:26:07 <Philippa> you can't have non-determinism in instance-picking
17:26:13 <vixey> oh I see
17:26:32 <halberd> since the type of a value is the theorem that it proves, can you interpret x :: B where x is a value and B is a type, as an implication x implies B?
17:26:44 <Philippa> (hypothetically you could allow it so long as you had a means to prove it's all equivalent, but Haskell's not up to that)
17:26:49 <vixey> it seems like something which could be checked before an instance is added
17:26:56 <vixey> maybe that's impossible though
17:27:11 <Philippa> that's precisely what fundeps and associated types are /for/
17:27:16 <lilachaze> bd_: if that works, then try printG (Constructor n) = putStrLn $ f n. if it doesn't, the GADTs are a red herring.
17:27:22 <Philippa> they give the coherency constraints on a class
17:27:28 <vixey> oh
17:27:29 <bd_> hmmm
17:27:35 <bd_>     Could not deduce (Show b) from the context (TypeFunc () b)
17:27:35 <bd_>       arising from a use of `show' at Test.hs:14:4-7
17:27:47 <Philippa> so that you can produce a result with less info than you would need otherwise
17:27:58 <bd_> lilachaze: interesting
17:28:04 <lilachaze> bd_: i guess the upshot is that fundeps don't let you do that :(
17:28:06 <bd_> it seems the GADTs are a red herring
17:28:09 <Philippa> (without them, GHC just says "can't work it out")
17:28:11 <bd_> lilachaze: "Yet!"
17:28:24 <lilachaze> :)
17:28:24 <Shiruka> there's supposedto be some sort of correspondence between haskell type classes and ML modules, but ML modules don't seem as complex to me.. I wonder what's going on with that
17:28:24 <Toxaris> halberd: your sentence doesn't typecheck for me, because implies :: Formula -> Formula -> Formula, but you use it on arguments Proof, Formula
17:29:02 <Philippa> Shiruka: the correspondance is that structure/functor ~= instance, signature ~= class. So Haskell infers which structure to use and how to build it
17:29:21 <Philippa> 'lo ChilliX
17:29:47 <halberd> this is a shot in the dark but in a dependently typed lambda calculus isn't everything a term?
17:29:51 <vixey> halberd, (spoiler) programs aren't really proofs
17:29:55 <halberd> so there's no distinction between proof and formula
17:30:21 <vixey> halberd: in a dependently typed language, hopefully you have some sorts, like .. Prop and Set
17:30:25 <Toxaris> halberd: still, implication means something else
17:30:30 <vixey> halberd: You put Proofs in Prop, and programs in Set
17:30:51 <vixey> halberd: this lets you make a distinction, proofs don't have interesting structure or computational content, where as programs do
17:31:17 <Philippa> vixey: you don't actually /have/ to do that, it's effectively there to allow optimisation :-)
17:31:42 <Toxaris> halberd: "x is a proof of y" means: since x exists, y is true.
17:31:42 <Philippa> programs can still validly be considered proofs
17:31:53 <vixey> you can determine what's a value and what's a type in a dependently typed language
17:32:01 <vixey> how far away is Set or Prop?
17:32:02 <Toxaris> halberd: "x implies y" means: if x is true, y is also true
17:32:04 <monochrom> x is a witness of y
17:32:15 <vixey> i.e. how man ::'s do you have to write to get to *
17:32:25 <Philippa> (actually, IIRC Coq now has some other structural differences between Set and Prop, but hey)
17:32:27 <vixey> \x -> x :: a -> a :: *
17:32:31 <vixey> so \x -> x is a avalue
17:32:41 <vixey> Integer :: *, so Integer is a type
17:32:42 <Toxaris> vixey: this is not about programs vs. proofs, but about programs/proofs vs. types/theorems
17:32:49 <vixey> halberd, does that distinction help?
17:33:31 <Toxaris> there are languages with * :: *, aren't there?
17:33:33 <Philippa> vixey: Coq/CoC is /not/ the only way to do things, okay?
17:33:55 <Philippa> Toxaris: yeah, it allows a paradox but it still gets used for assorted reasons
17:33:57 <lilachaze> bd_: i think it's a separability thing. imagine the TypeFunc () Int instance were in a different module. the compiler can't typecheck printG.
17:34:07 <halberd> well basically what I'm looking for is a more complete explanation of why the type axioms of the dependently typed lambda calculus are as they are
17:34:17 <lilachaze> bd_: there's probably a deeper reason than that
17:34:23 <halberd> all I've found so far simply gives the axioms without going into detail WHY they chose those axioms
17:34:41 <vixey> halberd: have you looked at the whole lambda cube?
17:34:50 <vixey> halberd: the intuition should come from there
17:34:51 <Philippa> halberd: because it's minimal, consistent, makes sense
17:34:53 <Toxaris> halberd: I had a nice brain explosion implementing a type checker for PTS
17:34:58 <Philippa> but yeah, also, look at the lambda cube
17:35:38 <halberd> alright but that sounds like a lot more work just to understand this one piece
17:35:45 <Toxaris> :)
17:36:04 <halberd> i mean that's basically delving into other type systems, isn't it
17:36:46 <Toxaris> well, PTS means you have some simple rules, and some parameters. depending on the parameters, you get different type systems
17:36:54 <Toxaris> the cool thing imho is that the rules are so simple
17:36:54 <Philippa> halberd: you probably know them already. System F, Fomega et al
17:37:29 <bd_> lilachaze: if the instance is in another module, the compilation fails
17:37:45 <bd_> just as if you attempt to use Show SomeType if Show SomeType is in some other module
17:37:55 <Philippa> halberd: you may find it helps to consider that they're all descendents of the simply-typed lambda calculus, too
17:38:09 <halberd> no I haven't looked at anything except simply typed lambda calculus and the dependently typed lambda calculus given in the paper
17:38:21 <Toxaris> halberd: which paper?
17:38:29 <halberd> http://people.cs.uu.nl/andres/LambdaPi/index.html
17:38:29 <lambdabot> Title: A Tutorial Implementation of a Dependently Typed Lambda Calculus
17:38:56 <Toxaris> oh I remember having decided to read that one, but I forgot about it
17:39:22 <Philippa> halberd: ah. Short version: they're about using the lambda and application mechanisms again
17:39:44 <Philippa> you might think of it as the simple dependently-typed \calc
17:39:50 <Arnar> vincenz: oh, hey there
17:39:50 <lambdabot> Arnar: You have 1 new message. '/msg lambdabot @messages' to read it.
17:40:16 <halberd> so I guess what I need to do is sit down and express the axioms in words relating to proofs and conclusions and see if they make intuitive sense that way
17:40:26 <Philippa> pretty much, yeah
17:40:57 <vixey> which axioms are you looking at?
17:41:06 <Philippa> try building a vector type for it, if that helps?
17:41:30 <halberd> at the moment I am looking at the axioms on p.6-7 of http://www.cs.nott.ac.uk/~wss/Talks/ImplDepTypedLambdaCalc-Utrecht.pdf
17:41:32 <lambdabot> Title: Implementing a Dependently Typed Lambda Calculus, http://tinyurl.com/6k3qyz
17:41:51 <halberd> but also the axioms in the paper that I linked before
17:42:01 <Toxaris> halberd: do you mean "rules"?
17:42:24 <halberd> oh yeah they call them rules I didn't know there was a difference
17:42:29 <vixey> halberd: that's not complete
17:42:35 <halberd> I know it isn't vixey
17:42:42 <halberd> I'm also reading the paper I linked to above
17:42:48 <Toxaris> halberd: an axiom is a rule with nothing above the bar
17:42:49 <halberd> I'm just thinking about these ones in particular at the moment
17:42:59 <halberd> ok thanks Toxaris
17:43:31 <adekoba> I'm having a difficult time learning monads. How can a value be extracted from Nothing? See: http://hpaste.org/9128
17:44:14 <Toxaris> adekoba: that's the trick. In case of Nothing, the computation is "aborted" and Nothing is "directly" returned as the end result
17:44:31 <Philippa> adekoba: think of it as an exception
17:44:37 <monochrom> The definition of m>>=f says: if m gives you Nothing, the whole thing is Nothing, don't even bother with f. Therefore there is no extraction.
17:44:41 <Philippa> the whole point is that no value is extracted from Nothing
17:44:53 <Philippa> the Nothing is all you get
17:44:57 <adekoba> Toxaris: I gathered that. I tried using Debug.Trace.trace to show the values in the return statement, but nothing came up.
17:45:11 <Shiruka> it doesn't get to the return statement
17:45:26 <Philippa> right. Lazy evaluation - it's never evaluated because >>= never demands it
17:45:37 <adekoba> Philippa: yeah, it makes sense from that perspective. I'm just wondering how it is it's implimented
17:45:41 <Shiruka> as soon as it gets a Nothing, it stops evaluating the rest
17:46:04 <adekoba> monochrom: oh, ok!
17:46:05 <vixey> Nothing >>= f = Nothing
17:46:10 <vixey> Just x >>= f = f x
17:46:24 <adekoba> Yes, that makes sense. Looking at the source now. Thanks guys.
17:46:38 <vixey> return = Just
17:47:07 <Toxaris> adekoba: http://hpaste.org/9128#a1
17:47:19 <halberd> how should I read x :: (y :: z) ? is that "x is a proof that (y is a proof of z)" or is it "x is a proof of y, and y is a proof of z"?
17:47:32 <vixey> halberd: where is that ?
17:47:42 <vixey> (is there some more context)
17:47:50 <halberd> page 7 of the slide show I linked (second lin)
17:47:51 <halberd> k
17:47:53 <halberd> http://www.cs.nott.ac.uk/~wss/Talks/ImplDepTypedLambdaCalc-Utrecht.pdf
17:47:54 <lambdabot> Title: Implementing a Dependently Typed Lambda Calculus, http://tinyurl.com/6k3qyz
17:48:08 <Cale> halberd: Of course, that's not valid Haskell. I might read it as x is of type (y which is of kind z).
17:48:09 <Toxaris> halberd: looks crazy, since you have to have "::" in the type language to make that well-formed
17:48:33 <Toxaris> or what Cale says
17:48:38 <halberd> it's not Haskell it's this notation they're using
17:48:47 <halberd> except I replaced : with :: otherwise it would look like a list
17:48:50 <oldsalt> @seen dcoutts
17:48:50 <lambdabot> dcoutts is in #gentoo-haskell, #haskell-soc, #haskell-overflow, #ghc and #haskell. I last heard dcoutts speak 1h 39m 31s ago.
17:49:02 <vixey> t1 : (x : sigma) -> t[x]
17:49:03 <vixey> means
17:49:16 <vixey> t1 has the type:  forall x of type sigma,  t[x]
17:50:02 <Toxaris> isn't there a big Pi missing?
17:50:06 <vixey> an example could be... allocateVector : (a : Type) -> ( i : Integer) -> Vector a i
17:50:31 <vixey> which means allocateVector has type, forall types 'a' and integers 'i', it returns a vector of a with length i
17:50:37 <shapr> !paste
17:50:39 <vixey> Toxaris, they use Agda like shorthand there
17:50:42 <shapr> @seen hpaste
17:50:42 <lambdabot> I haven't seen hpaste.
17:50:44 <shapr> foo
17:50:46 * shapr shrugs
17:51:04 <vixey> halberd, does that clear it up?
17:51:10 <vixey> or make .. any sense
17:51:13 <halberd> maybe vixey
17:51:38 <vixey> (+) : Integer -> Integer -> Integer
17:51:44 <vixey> could be written in that notation
17:51:46 <Toxaris> vixey: yeah on page 10 of that pdf is some example code which looks resonable to me
17:51:52 <vixey> (+) : (x : Integer) -> (y : Integer) -> Integer
17:51:58 <vixey> (since x and y aren't used later)
17:53:01 <halberd> "t1 proves the following theorem: if x proves the theorem sigma, then tau is true of x"
17:53:08 * vixey thinks (+) : forall x y : Integer, Integer is better notation ..
17:53:12 <dmwit> That vector example doesn't make sense.
17:53:13 <vixey> halberd: no it's not really about theorems
17:53:15 <shapr> @yow !
17:53:16 <lambdabot> Couldn't find fortune file
17:54:06 <dmwit> vixey: How does it distinguish between type variables and values?
17:54:36 <halberd> I think they make sense now
17:54:38 <vixey> I don't know what you mean
17:55:10 <dmwit> <vixey> an example could be... allocateVector : (a : Type) -> ( i : Integer) -> Vector a i
17:55:10 <dmwit> <vixey> which means allocateVector has type, forall types 'a' and integers 'i', it returns a vector of a with length i
17:55:22 <dmwit> That sounds like "a" is a type variable, and "i" is a data variable.
17:55:43 <vixey> dmwit, yeah the language halberd was thinking about allows that
17:56:18 <dmwit> Okay, it's allowed; so I come back to my original question.  How does it distinguish between type variables and values?
17:56:29 <Philippa> dmwit: you have sorts for that
17:56:36 <dmwit> i.e. what in the signature tells that "i" is a value, but "a" is a type variable?
17:56:38 <vixey> types and values are the same
17:56:49 <dmwit> mm, interesting
17:56:52 <vixey> the left and right of the : are folded into one syntax
17:57:07 <vixey> you can still decide if something is a type or a value or whatever though,
17:57:15 <Philippa> x : * means "x is a type", for example
17:57:51 <Philippa> and often you'd see * : [] (that should be a box) instead of * : *
17:58:06 <Toxaris> dmwit: the signature doesn't tell, and the typechecker finds out by typechecking the type (!). if the type has type *, it was a value variable, if the type has type <the type of *>, it was a type variable
17:58:22 <dmwit> yow
17:58:56 <dmwit> Oh, this is related to dependent typing?
17:59:00 * dmwit scrolls back a bit more
17:59:12 <Philippa> dmwit: yep, this is a dependently typed language being discussed
17:59:37 <Toxaris> but you could add syntactic differences between the various lambdas and foralls allowed in a dependently typed language
17:59:53 <slava> does anyone know of any results for lifting bitwise operations to ranges of values?
18:00:23 <Toxaris> and on the other hand, you could use the folded syntax for FOmega, but disallowing dependent types at type-checking time
18:00:25 <Toxaris> so it is not really related to dependent types
18:02:26 <dmwit> slava: What do you mean by "lifting"?
18:02:59 <slava> like, given [a,b], [c,d] compute the smallest interval [e,f] such that for all x in [a,b] and y in [c,d], x&y is in [e,f]
18:03:27 <dmwit> ah
18:03:37 <slava> ditto for | and ^
18:08:12 <hml> is the error monad a strict super set of the maybe monad? can i view the maybe monad as an error monad with an empty error msg?
18:08:34 <Philippa> yeah
18:08:45 <hml> cool; thanks
18:26:01 <dcoutts> oldsalt: pong
18:26:24 <oldsalt> dcouts: hi, are you the maintainer of gtk2hs?
18:26:30 <dcoutts> oldsalt: one of them, yes
18:26:57 <oldsalt> how much work would it be to update the haddock that generates the api docs to 2.1.0?
18:27:19 <dcoutts> oldsalt: a lot sadly
18:27:22 <lispy> 1 Mega Watt
18:27:32 <dcoutts> lispy: ;-)
18:27:45 <oldsalt> mmh, what a pity
18:27:49 <dcoutts> oldsalt: we are not planning to do that before we move to using Cabal for the build system
18:27:59 <dcoutts> which will still be a while
18:28:08 <oldsalt> ok
18:28:17 <dcoutts> oldsalt: any particular reason?
18:28:46 <dcoutts> trying to generate docs for packages that depend on gtk2hs?
18:29:00 <oldsalt> yes. hackage is on 2.1.0 so it would be easier for me to process the gtk2hs docs
18:30:17 <lispy> ?src dropWhile
18:30:17 <lambdabot> Source not found. You speak an infinite deal of nothing
18:30:56 <oldsalt> dcoutts: i thought that the html of 0.9 significantly differs from 2.1.0's but now i am hopefult that it does not
18:31:19 <dcoutts> oldsalt: right, the output is essentially the same
18:32:03 <SamB> dcoutts: what about the binaries?
18:32:04 <oldsalt> alright, then i think the main difference is when the source links come into play. probably that caused my problems
18:32:19 <dcoutts> SamB: no, the .haddock files are not compatible at all
18:37:22 <Shiruka> slava: at least for &, it looks like one could get a fast algorithm with a little thought, so probably nobody has bothered to publish any such results
18:38:00 <slava> i have algorithms for & | and ^, they're just not as accurate as they could be, so i wanted to look at existing work
18:41:55 * SamB wonders how to disable palatino in non-subpixel-perfect apps
18:48:34 <OceanSpray> What do you guys think of SML?
18:49:17 <darrint> Is there a way to "invert" a value of type Ordering?
18:49:21 <SamB> OceanSpray: it is not pretty to look upon and seems to lack typeclasses
18:49:31 <SamB> darrint: there sure ought to be...
18:49:59 <darrint> SamB: Figured there'd be something in the prelude. :-)
18:49:59 <OceanSpray> hmm
18:50:15 <slava> OceanSpray: sml has the advantage that its strict, but its type system is less flexible
18:50:16 <SamB> darrint: not as far as I know, yet
18:50:40 <OceanSpray> strictness is an advantage now?
18:50:53 <SamB> OceanSpray: oh, also, no polymorphic recursion, which messes up some of Okasaki's datastructures
18:50:58 <slava> OceanSpray: yes
18:51:41 <SamB> slava: but strict languages tend to have few non-strict libraries
18:52:34 <slava> and non-strict languages tend to have unpredictible performance :)
18:52:50 <SamB> true enough
18:53:04 * SamB wonders if you can make a language that is neither strict nor lazy by default?
18:53:05 <lispy> and tend to require more dedicated optimizations to make them efficient
18:53:14 <vixey> SamB: coq
18:53:34 <SamB> vixey: hmm, that doesn't really seem to count
18:53:40 * vixey will count it
18:53:44 <lispy> xslt?
18:54:04 <SamB> I won't count it until there is a "run this program" command in the Vernacular
18:54:20 <vixey> Eval
18:54:27 <SamB> there is?
18:54:30 <SamB> is that in the FAQ?
18:54:33 <vixey> of course
18:54:36 <SamB> hmm.
18:55:07 <MyCatVerbs> Isn't Coq not Turing complete? Hence why all Coq proofs are checkable?
18:55:19 <SamB> MyCatVerbs: certainly it is supposed to be ;-)
18:55:33 <vixey> you can encode a turing machine in it
18:55:39 <MyCatVerbs> SamB: huh. I thought it was supposed to deliberately not be. Nevermind.
18:55:45 <Eelis> MyCatVerbs: i think you're right.
18:55:58 <SamB> MyCatVerbs: supposed to be NOT turing complete, sorry
18:56:00 <MyCatVerbs> (So that termination of Coq programs would always be decidable, that is.)
18:56:08 <MyCatVerbs> SamB: oh, right. Heh.
18:56:08 <vixey> you just can't simulate it (unless you put a bound on the execution or prove termination)
18:56:22 <Eelis> MyCatVerbs: not just decidable; guaranteed
18:57:00 <SamB> it's a bit too paranoid about codata...
18:57:27 <vixey> yeah codata doesn't make sense.. even though we use it all the time in haskell
18:57:48 <SamB> vixey: I mean even when it makes sense!
18:57:58 * vixey hasn't got that far yet :p
18:59:14 <SamB> Coq's current syntax-based restrictions on corecursion don't let me implement "beautiful differentiation"
18:59:59 <vixey> then you must put it together by semantics
19:00:26 * vixey guesses that's very hard
19:01:05 <SamB> vixey: yes, but an attempt should be made ;-)
19:02:05 <MyCatVerbs> Gah.
19:02:32 <MyCatVerbs> Am I the only one to find it disconcerting to see a paper consistently using "we" to refer to the authors when there's only one?
19:02:42 <SamB> MyCatVerbs:
19:02:46 <SamB> I do that sometimes
19:02:52 <Zao> I find it reasonably sane.
19:02:55 <name_> the royal we
19:02:56 <vixey> we also do that
19:03:04 <Zao> We rule.
19:03:22 <MyCatVerbs> I mean, find, the ol' "academic we", but I always got the impression that that was meant to be academia's version of a Kipling-style "you and I, dear beloved".
19:03:25 <SamB> it's especially useful if we multiply in number during the writing of the paper, though this is unlikely to happen to us in the near future
19:03:25 <OceanSpray> Let us make man in our image.
19:03:37 <MyCatVerbs> *I mean, fine
19:04:08 <OceanSpray> SamB, why, because we're geeks?
19:04:18 <lispy> We disagree with you, precious.
19:04:26 <SamB> OceanSpray: well, I was actually referring only to myself in that sentence ;-)
19:04:31 <MyCatVerbs> Damn.
19:04:36 <OceanSpray> Oh wait, THAT multiply.
19:04:53 <MyCatVerbs> This conversation isn't headed in anything like the direction I was hoping for.
19:04:54 <SamB> OceanSpray: that would be a REALLY LONG PAPER
19:05:11 <SamB> or at least very highly polished
19:05:42 <MyCatVerbs> Ideally, I should've been inducing flashbacks to "Just So Stories" in the other denizens here, instead of causing schizophrenia and multiple personality disorder jokes.
19:06:20 <SamB> MyCatVerbs: what? who was joking about that?
19:06:27 <jamii> MyCatVerbs: You're not even on irc. We're all products of your imagination...
19:06:44 <SamB> okay, that makes jamii
19:06:46 <MyCatVerbs> SamB: me.
19:06:57 <MyCatVerbs> SamB: damn, so nobody got the "dearly beloved" thing?
19:07:14 <SamB> MyCatVerbs: I meant, who was joking about psychological disorders?
19:07:36 <lispy> It's not a disorder, just an alternative to the norm.
19:07:47 <lispy> You people can be so judgemental of us.
19:07:49 <jamii> Technically I only exist in MyCatVerbs head, so I am blameless in this
19:07:57 <SamB> MyCatVerbs: I was vaguely reminded of stories involving the origins of distinctive features of various types of animal
19:08:16 <MyCatVerbs> SamB: lispy, for starters.
19:08:22 <SamB> lispy: you have a disorder?
19:08:55 <SamB> oh, so what psychological disorder is golem supposed to have then?
19:09:05 <MyCatVerbs> SamB: no, it's a point of uniqueness that is looked down upon in society due to widespread bigotry, of course. ;P
19:09:09 * SamB doesn't mean to imply that golem does not have one, just that he doesn't know what it is
19:09:22 <MyCatVerbs> What? Who is golem?
19:09:26 <SamB> MyCatVerbs: a disorder doesn't have to be bad does it?
19:09:31 <SamB> did I misspell it?
19:09:41 <dons> ?users
19:09:42 <lambdabot> Maximum users seen in #haskell: 483, currently: 428 (88.6%), active: 17 (4.0%)
19:09:47 <jamii> SamB: gollum
19:10:00 <chrisdone> I think a golem is a creature of clay
19:10:05 <MyCatVerbs> Ah, heh. Smeagol, Gollum. Yes.
19:10:26 <SamB> oh, well, I do see the word golem a lot more than the word Gollum ...
19:11:09 <MyCatVerbs> A golem is, yeah, a gigantic enchanted lump of clay with a vaguely humanoid shape. Features in stories and legends where it (very much like a computer, come to think of it) severely inconveniences one or another owner by doing exactly what it is told, rather than what is desired.
19:11:34 <jamii> Like a computer
19:12:18 <dmwit> Golems are the inspiration for the first robot story, in fact.
19:12:46 <SamB> MyCatVerbs: more generally, of anything. typically animated with human souls.
19:12:56 <MyCatVerbs> You say to the golem, "Dig!" and go off to get some lunch. By the time you return, the golem is halfway to China.
19:13:12 <SamB> MyCatVerbs: wouldn't it have cracked?
19:14:00 <chrisdone> samb: cracked? âI don't mind 24 hour wiping duty, but diggingâ½ I've had it!â
19:14:37 <MyCatVerbs> You say to the computer, "strcpy()!" and go off to evaluate a thunk. By the time you come back, half your heap has been overwritten with nice poems about how adorably beautiful some girl called "Juliet" is, and there are witches cackling about the contents of their pots in your stack.
19:14:42 <SamB> chrisdone: isn't that the failure mode for clay objects in excessively hot surroundings?
19:14:49 <MyCatVerbs> SamB: no.
19:15:18 <MyCatVerbs> SamB: it's the failure mode for clay objects very rapid temperature changes.
19:15:19 <SamB> okay, so what actually happens if a clay object encounters magma?
19:15:23 <MyCatVerbs> *undergoing, even
19:15:32 <SamB> MyCatVerbs: oh, right.
19:15:59 <MyCatVerbs> SamB: goes gooey. Melts, I presume.
19:16:02 <jamii> SamB: It wears oven mits, of course
19:16:07 <jamii> *mitts
19:16:13 <chrisdone> jamii: good point
19:16:16 <SamB> jamii: do you mean magma mitts?
19:16:29 <lispy> So, the solution is to have a golem that uses lazy evaluation?
19:16:31 <MyCatVerbs> SamB: possibly for a little while, you'd find yourself with a metamorphic-skinned golem instead of a sedimentary golem. :)
19:16:38 <jamii> SamB: Where would you get magma mitts from at this time of day? You have to work with what youve got.
19:17:18 <jamii> lispy: At that point you might as well hire ordinary builders
19:17:32 <chrisdone> jamii: I suppose shard mitts would have to do. taking into acount golem owners' penchants for defestration
19:17:48 <MyCatVerbs> SamB: but since legends about golems talk about the thing being run according to instructions written on a scrap of paper inside its head, presumably it'd just shut down when the temperature got high enough to destroy the paper.
19:17:54 * jamii runs for a dictionary
19:18:05 <chrisdone> jamii: you'll like this one
19:18:30 <jamii> since when was OED subscription only?
19:18:31 <chrisdone> ah, I typo'd: defenestration
19:19:11 <jamii> Ah, ok, I know that one
19:19:33 <chylli> does haskell has libs about SIP protocol ?
19:19:42 <lispy> SIP?
19:19:53 <jamii> MyCatVerbs: The platinum model comes with an asbestos head
19:20:21 <hml> grepping -i wire on ":browse Graphics.Rendering.OpenGL" shows up nothing does Haskell's OpenGL mode not support wireframe rendering?
19:20:40 <dons> chylli: not that i know of.
19:20:46 <chylli> http://www.ietf.org/rfc/rfc3261.txt
19:20:56 <chylli> dons: ok,thanks
19:20:57 <jamii> chylli: http://directory.fsf.org/project/Python-SIP/ or http://en.wikipedia.org/wiki/Session_Initiation_Protocol
19:20:58 <lambdabot> Title: Python-SIP - Free Software Directory - Free Software Foundation
19:21:00 <dons> hml: i think its a fairly complete opengl binding. so whatever opengl provides.
19:21:10 <jamii> Which are you after?
19:21:20 <darrint> Is there a proper name for (:[]) ?
19:21:26 <dmwit> darrint: no
19:21:35 <dmwit> darrint: Some people call it "box".
19:21:40 <dmwit> darrint: "return" also does that.
19:21:45 <dmwit> > return 3 :: [Int]
19:21:48 <lambdabot>  [3]
19:22:08 <vixey> return = (:[])
19:22:18 <vixey> we also call it upside down robot ninja
19:22:32 <dmwit> angry monkey robot
19:23:51 <jorick> hgih
19:23:52 <MyCatVerbs> That's not upside down. S'merely sideways.
19:24:11 <jorick> (:
19:24:27 <dmwit> *That*'s upside down, and *then* sideways!
19:24:30 <MyCatVerbs> *That* is upside down, you weirdo. D:
19:24:44 <MyCatVerbs> S'not. S'sideways *then* upside down, silly.
19:24:56 <codacola> only 22 questions to go :(
19:25:34 <chrisdone> ._Â·
19:26:35 <lispy> yay type errors...
19:26:43 <codacola> yay
19:26:43 <lispy> This source file is about 1000 lines long
19:26:45 <codacola> theyre always fun
19:26:50 <MyCatVerbs> chrisdone: bloody Hell, get away!
19:27:00 <lispy> and I think there is a type error every 10 lines on average
19:27:04 <chrisdone> Â·_Â·
19:27:12 <MyCatVerbs> lispy: ow.
19:27:19 <codacola> lispy: ah well, only 100 errors
19:27:29 <vixey> how did this happen?
19:27:29 <MyCatVerbs> lispy: write less at a time, for sanity's sake.
19:27:40 <lispy> Hahah.  I didn't write this.
19:27:59 <codacola> am i the only person that tests after every function?
19:28:00 <jorick> wtf are you guys on
19:28:26 <dmwit> #haskell
19:28:37 <lispy> I'm converting the darcs source base...and unfortunately, the process means that GHC gives me a type error about every single function in the file at once
19:28:37 <jamii> and meth
19:28:48 <codacola> jamii: ?
19:29:02 <dmwit> lispy: Converting to what?
19:29:16 <jamii> codacola: Would hate to give a straight answer to a silly question.
19:29:22 <lispy> dmwit: type safe patch manipulations
19:29:35 <codacola> jamii: why do you say we're on meth?
19:29:38 <dolio> lispy: I'm curious, what do the functions look like?
19:29:43 <lispy> This is one of my all time favorites:
19:29:46 <MyCatVerbs> codacola: yeah. I keep writing until I run out of ideas, then I throw it at ghci until the trivial type errors go away, then I read the non-trivial type errors (if any) carefully in order to work out why my thinking is totally wrong. Then I correct it, and try again.
19:29:49 <lispy>     Inferred type is less polymorphic than expected
19:29:49 <lispy>       Quantified type variable `x' is mentioned in the environment:
19:29:50 <dolio> lispy: I know I've seen that GADT error before, but I can't remember when.
19:30:01 <MyCatVerbs> lispy: ARGH, PAINFUL MEMORIES
19:30:25 <jamii> codacola: Its 3am and I just got up. I wanted a witty answer but panicked under the pressure
19:30:26 <chrisdone> codacola: I actually load my file in ghci and try out each function I write
19:30:48 <lispy> dolio: Well, they look like Haskell code.  Some are short, 1 line + type sig, and others (usuall the IO monad ones) are long and hairy
19:31:05 <jorick> -- one day i took some dextro-amphetamines i could focus on ONE SINGLE TOPIC for *hours*
19:31:07 <MyCatVerbs> codacola: "trivial type errors" in this case refers, usually, to stupid crap like misspelt names, forgetting to write parameters in... I have a *very* common failure mode where I think of two different names for the same thunk, and use both. Oops. So I end up changing all of them to use one or the other.
19:31:37 <codacola> chrisdone: that was more of a joke, ive noticed a lot of people write a lot of code, and then test, whereas i tend to compiler (or whateever) after every function just so i dont get stuck fixing up a heap at once
19:31:42 <MyCatVerbs> dolio: you don't even need GADTs for that. Existential types alone suffice to cause that problem.
19:31:47 <lispy> dolio: but ths file is a bit of a nightmare because it's so huge
19:31:51 <dolio> lispy: I was thinking more like an example of one that gave that error (preferably a short one).
19:31:52 <jorick> that was months after droppin the acid tho
19:32:07 <lispy> dolio: sure, the one I'm on now is a good example
19:32:26 <dolio> MyCatVerbs: I'm actually talking about a different error he mentioned on the ghc-users mailing list.
19:32:33 <pchiusano> hello
19:32:46 <dolio> "GADT pattern match in non-rigid context"
19:32:46 <lispy> http://haskell.pastebin.com/d4be15420
19:32:48 <codacola> MyCatVerbs: type errors are one of the things i found annoying about haskell, but slowly i seem to be getting past them. kept assuming stuff like i can pass an integer as a float
19:32:49 <SamB> jorick: is that unusual?
19:33:07 <lispy> dolio: oh which error?
19:33:13 <MyCatVerbs> dolio: ah, yes.
19:33:17 <pchiusano> is there an operator equivalent to (flip ($))
19:33:18 <lispy> dolio: the one I emailed to glasgow haskell list?
19:33:28 <lispy> the one no one responded too
19:33:31 <jorick> SamB, what, to take LSD? or that i took amphetamines months later?
19:33:33 <SamB> ... I realize that I haven't been OFF amphetamines for a significant period of time for ... quite a while now ...
19:33:47 <dolio> lispy: Yeah. Which does the one you pasted throw? The 'inferred type ...' one?
19:33:49 <SamB> jorick: being able to focus on one thing for hours
19:33:55 <jorick> hahaha
19:33:56 <jorick> yes
19:33:58 <jorick> very
19:34:00 <jorick> ;)
19:34:07 <pchiusano> > head $ map (1+) [1,2,3,4]
19:34:08 <lambdabot>  2
19:34:12 <lispy> dolio: the one in the pastebin does the inferred blah
19:34:15 <SamB> of course, usually the thing I focus on for hours is NOT something I am SUPPOSED to be doing
19:34:17 <MyCatVerbs> codacola: oh I know. Like I said, 90% of the time I'm using them to pick up on all the stupid crap I do. The next 9% of the time, I'm using type checker's refusal to let something through to sanity-check my ideas for blatant confusion.
19:34:46 <jorick> SamB, meh ... it all depends i guess
19:35:02 <MyCatVerbs> codacola: it's just that when I get "Inferred type is less polymorphic than expected", I very rapidly start to hate the entire universe.
19:35:49 <jorick> SamB, it's not like a have a job or anything, i don't really care about focusing
19:36:00 <jorick> except when i want to write something big
19:36:23 <SamB> MyCatVerbs: I usually just curse at the bad interaction between typeclasses and higher-order polymorphism
19:36:30 <jorick> so ... in college they wanted me to write all this stupid fuckit shit yknow, like fuckit pacman n all
19:36:37 <dolio> lispy: Is C a macro or something?
19:36:38 <lispy> dolio: in this case, the fix seems to be just getting rid of the extra type signature on p
19:36:44 <jorick> so i didn't, i learned haskell instead :)
19:36:54 <SamB> jorick: eh, wait, those are mutually exclusive how?
19:37:05 <lispy> dolio: yeah, and right now, with type witnesses enabled it's an identity macro
19:37:06 <SamB> jorick: now go write pacman in Haskell!
19:37:11 <codacola> MyCatVerbs: yesterday i had no type errors. was sohappy. then i ran the "test program", spent 2 hours trying to find my little bug
19:37:16 <lispy> dolio: but when type witnesses are disabled, it emits nothing
19:37:20 <jorick> well ... they ARE if you HAVE to write pacman in Scheme
19:37:26 <dolio> Ah, I see.
19:38:00 <dmwit> pchiusano: No, there's no (flip ($)) in the Prelude.
19:38:09 <SamB> jorick: there isn't a Haskell interpreter written in Scheme yet?
19:38:19 <jorick> so, i didn't do it yknow ... didn't even Desire their fuckit paper ... a "degree" to tell me how good of a student i was. fuckit, if they wouldve been better Teachers .. maybe
19:38:26 <SamB> I guess it would be kinda slow though :-(
19:38:30 <MyCatVerbs> SamB: usually I find myself writing stuff that's very close to monomorphic. Meh.
19:38:32 <pchiusano> dmwit, thx
19:38:39 <pchiusano> I guess there is >>>
19:38:56 <dons> yale haskell used to exist, and was written in lisp.
19:38:59 <dmwit> pchiusano: That's (flip (.)), as far as I understand.
19:39:11 <pchiusano> dmwit, yeah
19:39:37 <lispy> lisp is dead, long live the lisp!
19:39:42 <chrisdone> :t flip (.)
19:39:43 <lambdabot> forall a b (f :: * -> *). (Functor f) => f a -> (a -> b) -> f b
19:39:47 <pchiusano> for some reason i thought |> used to be flip ($)
19:39:57 <dmwit> :t (|>)
19:39:57 <lambdabot> Not in scope: `|>'
19:40:05 <jorick> hehehe
19:40:06 <dmwit> ?index (|>)
19:40:07 <lambdabot> bzzt
19:40:22 <jamii> I think is |> is defined like that in F#...
19:40:38 <jorick> wait a min, what are we talking about here?
19:40:52 <hml> in ghci, can i get something similar to lambda bot's @src?
19:41:22 <ben_h> hi all
19:41:23 <SamB> hml: only if you can get GOA going again
19:41:28 <vixey> > let e |> a = a e in 1 |> (+1) |> (*2) |> (+1) |> (*2) |> (+1) |> (*2)
19:41:29 <lambdabot>  22
19:41:35 <hml> SamB: what's GOA ?
19:41:44 <lispy> ghci on acid
19:41:48 <dmwit> GHCi on Acid.
19:41:54 <lispy> it allows ghci to run lambdabot in the bg
19:41:55 <dmwit> hml: It's a fusion of GHCi and \bot.
19:41:58 <jamii> http://www.cse.unsw.edu.au/~dons/code/goa/
19:41:59 <lambdabot> Title: Index of /~dons/code/goa
19:42:43 <SamB> also, I must warn you that I was told that the database for @src was hand-made
19:42:43 <jamii> Last modified 2006. Might take a bit of doing up
19:43:01 <vixey> bugs added by hand of course
19:43:13 <SamB> jamii: yeah, that's why I said "going again" ;-)
19:43:31 <jamii> SamB: I know. Was just pointing out the date.
19:43:34 <chrisdone> > let e â a = a e in 1 â (+1) â (*2) â (+1)
19:43:34 <lambdabot>  Illegal character ''\8594''
19:43:34 <lambdabot>  at "" (column 7)
19:43:38 <chrisdone> ;_;
19:43:53 <jamii> It might be easier once the various summer of code projects on the GHC api are finished
19:44:27 <SamB> what does GOA have to do with GHCi on ACID?
19:44:33 <SamB> er.
19:44:36 <lispy> lol
19:44:37 <SamB> GHC API
19:44:40 <SamB> sorry
19:44:52 <SamB> ... would you believe me if I blamed that on tab completion?
19:45:03 <lispy> SamB: what does PETA have to do with people for the ethical treatment of animals anyway?
19:45:14 <SamB> (in my head ???)
19:45:45 <lispy> At the moment, GOA doesn't use GHCi API.  But, it's an interesting point.  maybe it should
19:45:53 <jamii> SamB: Good point. I assumed that there would be some reflection mechanism in the GHC api for examining loaded modules. Alas, I cant see anything
19:46:17 <SamB> jamii: that certainly isn't related to GOAs essential functions
19:47:08 <jamii> SamB: It would mean you wouldnt need a seperate, handmade database for things like @src
19:47:09 <SamB> last I heard, lambdabot was only available in statically linked form (well, that is, non-plugins form)
19:47:26 <SamB> jamii: I don't know how that would work
19:47:47 <SamB> does GHC actually store the source ranges you'd need ?
19:48:23 <jamii> SamB: Im not claiming I do either. It just seems like GHC should be doing some of the heavy lifting here. I mean, its already compiled everything in your package list, why couldnt it build src databases while its in there?
19:49:27 <lispy> sounds more like a job for Haddok actually
19:49:35 <SamB> yes, it definately does
19:49:42 <lispy> definitely*
19:50:05 <SamB> though of course haddock uses the GHC API nowadays, right?
19:50:21 <Saizan_> for parsing i think
19:50:39 <jorick> hml: it'ss NOT A PLACE, NOR A TIME ... (nor a music genre)
19:50:41 <MyCatVerbs> SamB: yep. Links against GHC's guts.
19:50:46 <lobo9> hello
19:50:49 <SamB> Saizan_: well, haddock doesn't really do much else with Haskell code, does it?
19:51:04 <SamB> MyCatVerbs: that's what ghc-api is ;-P
19:51:13 <MyCatVerbs> SamB: just making sure.
19:51:25 <MyCatVerbs> (Just making sure I wasn't under some or other misapprehension, I mean.)
19:51:33 <jamii> Ok. So the cabal installer could be set up to run Haddock over every package thats installed. And if haddock also matchs function definitions to sources while its at it we get a source database which includeds every installed package. Does this sound feasible?
19:51:34 <SamB> (I suppose that's why the interface keeps breaking?)
19:51:57 <jamii> *includes
19:52:06 <SamB> jamii: well, something similar is
19:52:33 <SamB> and actually I'd really love if cabal kept all sources around while the package was installed
19:52:59 <SamB> (at least, most of the time)
19:53:40 <jamii> That doesnt *sound* like too much work. Ill take a shot at it when I finish my summer of code stuff
19:53:55 <MyCatVerbs> SamB: mmmm. For bonus points, figure out how to get a gigantic libraries haddock listing *everything* installed, also saving line numbers+all for @src and friends, with embedded links to HsColour output... and maybe a pony, too.
19:53:57 <SamB> then there'd be hope of getting it to (mostly) automatically compile the profiling libraries on an as-needed basis
19:54:57 <jamii> MyCatVerbs: A pony *and* jump to definition
19:55:17 <Saizan_> MyCatVerbs: there's a ticket on Cabal's track for that, the discussion is mostly on where to keep it
19:55:17 <jamii> SamB: My god yes, thats incredibly frustrating
19:55:19 <SamB> "cabal install" already seems to cache sources, so it might actually not be that hard
19:55:31 <MyCatVerbs> jamii: oooh, ctags output so we can browse it with a tags/TAGS-aware editor! :)
19:55:38 <Saizan_> "trac"
19:55:48 <MyCatVerbs> Saizan_: huh.
19:56:10 <SamB> I want hsscope
19:56:30 <jamii> The really tricky thing would be hacking on cabal without breaking your own ghc install all the time
19:56:40 <MyCatVerbs> SamB: hsscope?
19:56:44 <SamB> jamii: how so?
19:56:46 <jamii> SamB: "" ?
19:56:59 <SamB> heard of cscope?
19:57:00 <shepheb> I'd love hsscope or hstags
19:57:13 <SamB> it would be kinda like that, only with the obvious difference
19:57:14 <jamii> SamB: If I test a modified cabal install and it has bug I can probably say goodbye to my package database
19:57:26 <MyCatVerbs> SamB: oooooooh.
19:57:26 <SamB> jamii: oh
19:57:34 <SamB> jamii: why?
19:57:44 <SamB> wouldn't that only be a very particular class of bugs?
19:57:54 <MyCatVerbs> jamii: cp -r ~/.cabal ~/cabalbkup
19:58:17 <MyCatVerbs> jamii: cp -r ~/.ghc ~/ghcbkup
19:58:35 <jamii> MyCatVerbs: Out here we program on the edge, living for the speed. I spit in the face of backups :-)
19:58:39 <MyCatVerbs> jamii: That's pretty much sorted then.
19:58:48 <SamB> jamii: I must point out that hosing ~/.cabal and parts of ~/.ghc would NOT actually hose your ghc installation
19:59:08 <MyCatVerbs> jamii: if you want to be *really* snooty, put the contents of your .cabal and .ghc directories into version control. :)
19:59:11 <SamB> only potentially make GHC unusable as $USER for a short time
19:59:24 <MyCatVerbs> SamB: not even that.
19:59:33 <SamB> jamii: I would suggest using git for versioning things like that
19:59:43 <MyCatVerbs> SamB: it'd just make you spontaneously lose the use of everything you've installed as --user. :)
19:59:54 <jamii> SamB: No. I guess I was speaking loosely. What it would do is force you to fix everything before the next test. Its not exactly an insurmountable problem, I was just saying it would be annoying
20:00:10 <jamii> SamB: git? heretic!
20:00:13 <SamB> I think it would probably waste the least space in lousy attempts at storing deltas
20:00:26 <MyCatVerbs> jamii: write a short shell script. rm -rf .ghc .cabal; cp -r ghcbkup .ghc; cp -r cabalbkup .cabal
20:00:34 <SamB> darcs would use more than double the space git would use, at BEST
20:01:06 <SamB> (assuming you uninstall everything at some point)
20:01:07 <jamii> SamB: But it would apologise so cutely...
20:01:07 <thetallguy> Anyone familiar with Design Patterns?
20:01:07 <lambdabot> thetallguy: You have 1 new message. '/msg lambdabot @messages' to read it.
20:01:33 <SamB> git is actually very clean at the core
20:01:40 <SamB> (conceptual core)
20:02:25 <jamii> I read about it. I thought it sounded like it would make a nice persistence layer for functional objects (the core, that is, not the filesystem layer)
20:02:32 <SamB> it's model is probably the simplest possible model for a DVCS-like-thing to have
20:02:48 <SamB> jamii: that's what it is
20:03:26 <jamii> Is there a haskell git binding anywhere?
20:04:23 <vixey> what would that do .. ?
20:04:40 <SamB> (of course, it really only supports storing directed graphs labeled with filetrees ...)
20:05:19 <SamB> (and also small amounts of other data)
20:05:27 <jamii> An adt is a directed graph labeled with types. Semantically at least
20:06:04 <jamii> Thats kind of the point of my current work, in fact
20:07:37 <SamB> you could definately use the same approach to persist any persistant datastructure -- of course, it'd probably complicate the implementation considerably unless you had language runtime support -- which in itself would most likely be complicated to implement ...
20:08:01 <sioraiocht> @seen dcoutts
20:08:02 <lambdabot> dcoutts is in #gentoo-haskell, #haskell-soc, #haskell-overflow, #ghc and #haskell. I last heard dcoutts speak 1h 35m 42s ago.
20:08:06 <sioraiocht> @seen dcoutts_
20:08:06 <lambdabot> dcoutts_ is in #gentoo-haskell, #haskell-overflow, #ghc and #haskell. I last heard dcoutts_ speak 5h 18m 43s ago.
20:08:08 <sioraiocht> @seen dcoutts__
20:08:09 <lambdabot> I haven't seen dcoutts__.
20:08:11 <vixey> I would like to put all the time and effort I spent learning to program into something more useful than <anything I can think of programming>
20:08:16 <sioraiocht> hrm, he's probably asleep
20:09:07 <jamii> I would think you could use template haskell to reify the adt into an actual tree. And then use show/read to convert the type tags. Would never be fast like that, though
20:11:46 <SamB> jamii: well, keeping track of what each object is called on disk would be critical to performance, and I suppose it could also be important to be able to look things up in reverse
20:12:28 <cjs> Grr. So ghc has some "silently exit the program" issues that are very annoying.
20:12:44 <SamB> cjs: which program?
20:12:46 <SamB> are you using threads?
20:12:59 <SamB> if so, be aware that it ALWAYS silently exits when the main thread exits...
20:13:08 <cjs> Yes, it's a thread issue.
20:13:32 <cjs> However, it's silently exiting when another thread fails, I believe. I run some threads with the runThread in that paste.
20:13:33 <SamB> so maybe you should just fork off and make the main thread wait forever?
20:13:48 <cjs> They do network I/O, and do little error checking at the moment.
20:14:06 <cjs> Everything works fine until the network connection those threads are handling is torn down, at which point my program exits.
20:14:23 <SamB> how low level are the functions you use?
20:14:38 <cjs> hReadLine, stuff like that.
20:14:54 <cjs> Oh, these are actually run from a separate listener thread, too.
20:14:57 <SamB> so you aren't getting any exception?
20:15:14 <cjs> So basically main thread forks listener, listener forks a pair of network reader/writer threads.
20:15:26 <SamB> what else does main thread do?
20:15:30 <cjs> No. At one point I was getting an exception from hReadLine, but that seems to have gone away.
20:16:28 <cjs> The main thread reads a file and, runs various calculations on the input data. One "calculation" is to feed commands to the reader/writer threads.
20:16:43 <cjs> Hm. Is it an error, perhaps, if one half of a channel goes away?
20:16:59 <cjs> That could be doing it.
20:18:46 <cjs> No, but it doesn't go away, because the listener thread always has one dup of that channel, though it never reads it.
20:18:55 <cjs> (Which I just realized could be a problem.)
20:19:26 <cjs> But if I make two connections, and kill one, the other is still running and reading from that channel.
20:19:55 <cjs> Oh, here's what I get from time to time: thread error: <socket: 5>: hGetLine: end of file
20:20:06 <cjs> So one of my catchErrors worked.
20:21:09 <cjs> Is there anything wrong with the way I'm using catchError?
20:21:15 <cjs> Oh, wait, the paste didn't show!
20:21:25 <cjs> http://hpaste.org/9130
20:21:35 <MyCatVerbs> Is it just me, or has the traffic level on haskell-cafe really dropped lately?
20:21:54 <jamii> I wouldnt know, I tend to mute most of it
20:22:00 <MyCatVerbs> Or is it maybe just a faulty mail daemon on my end?
20:22:26 <dolio> @hoogle quotRemInteger
20:22:27 <lambdabot> No matches found
20:22:38 <jamii> You could check the online archives?
20:22:46 <jamii> See if you have all the recent mails
20:22:58 <MyCatVerbs> Hrmn. Okay, nevermind. It isn't *that* low, I'm just not getting the messages at all for some reason.
20:23:20 <MyCatVerbs> Fooled for a minute there because I saw some messages with haskell-cafe@ in the To: line, but it seems those were just crossposts.
20:23:56 <lobo9> =]
20:29:01 * dolio is frequently baffled by the GHC internal libraries.
20:29:59 <jamii> Hopefully they will be neater soon
20:30:23 <dolio> So, I'm experimenting with a Show for byte strings...
20:30:32 <dolio> And the Integer showing code uses quotRemInteger.
20:30:42 <dolio> The code in GHC, that is.
20:31:01 <MyCatVerbs> dolio: what's the issue?
20:31:02 <dolio> Which presumably comes from GHC.Integer, which is imported in GHC.Num (where its Show instance is defined)...
20:31:12 <dolio> But when I try to import GHC.Integer, it doesn't exist. :)
20:31:19 <MyCatVerbs> dolio: *mindexplode*
20:31:21 <dolio> So, I imported GHC.Num instead, which exports GHC.Integer.
20:31:54 <dolio> And that gave me quotRemInteger, but in the GHC.Num code, it returns unboxed tuples, while in the version exported from GHC.Num, via GHC.Integer, it returns regular tuples.
20:33:18 <dolio> Actually, GHC.Num's module signature is bizarre, too.
20:33:32 <dolio> "module GHC.Num (module GHC.Num, module GHC.Integer) where"
20:33:42 <dolio> So it's exporting itself as a module?
20:34:33 <MyCatVerbs> dolio: quit worrying and click on this instead: http://www.wackyarchives.com/featured/bring-it-on.html
20:34:34 <lambdabot> Title: Bring It On!! : Wacky Archives
20:34:48 <MyCatVerbs> (SFW, inoffensive, etc.)
20:35:02 <MyCatVerbs> (Features mild breakdancing, frighteningly high-saturation colours.)
20:35:10 <MyCatVerbs> (Some hats.)
20:35:20 <dolio> Hah.
20:35:27 <dolio> That guy got served.
20:36:02 <MyCatVerbs> Quite.
20:36:36 <Elly> MyCatVerbs: I want "May contain hats" to be a movie-rating category
20:36:48 <Elly> "Rated PG for Violence and Adult Situations. May contain hats."
20:37:25 <dolio> That would have helped me back when I was watching Fear of a Black Hat.
20:42:18 <MyCatVerbs> Elly: I rather suspect it could've saved an awful lot of people (who weren't really of sufficiently robust consitution to cope with the film) from having mistakenly watched "A Clockwork Orange".
20:42:35 <Elly> you think the hats were the scariest part of the movie?
20:44:10 <MyCatVerbs> No, but nobody ever pays any attention to the warnings about rape and murder and beatings by police officers.
20:44:19 <Elly> touche
20:44:37 * Twey laughs.
20:45:32 <MyCatVerbs> I mean, you get those on *everything* nowadays (to heck with whoever came up with the idea of being "edgy"). The hats, though, man. Just the idea that there -might- be something sufficiently dangerous about the hats will, at least for the next few years, probably stay effective.
20:46:09 <codacola> it contains a cat, which will eat you with green eggs
20:46:49 <Elly> I should admit that as hats go, the ones in A Clockwork Orange were pretty scary
20:47:34 * codacola thinks any with a cat in it is scary
21:11:50 * bitrot notes that after 12 hours, reverse video can sometimes magically change colors...
21:13:22 <Elly> bitrot: 12 hours of staring at a screen?
21:13:57 <bitrot> Elly: staring, looking, however you call it
21:14:19 <Elly> yeah, that happens
21:15:14 <MyCatVerbs> bitrot: "glazing".
21:15:15 <bitrot> it's been a while since the last "episode"
21:15:28 <bitrot> MyCatVerbs: spot-on
21:15:58 * Elly yawns
21:16:07 <Elly> I'm in about my twelfth hour of LCD use today actually
21:16:15 <Elly> this is probably a bad habit
21:18:11 <mjrosenb> Elly: sounds like a normal morning for me.
21:18:34 <Elly> yeah
21:18:40 <Elly> 9 hours at work and three at home so far
21:19:49 <mjrosenb> @hoogle Bool -> MonadPlus a -> MonadPlus a
21:19:50 <lambdabot> No matches, try a more general search
21:20:08 <mjrosenb> @hoogle MonadPlus a -> Bool -> MonadPlus a
21:20:08 <lambdabot> No matches, try a more general search
21:20:27 <mjrosenb> i need to get irssi to use readline keybindings
21:21:44 <mjrosenb> wait, that was wrong...
21:22:09 <mjrosenb> @hoogle (MonadPlus m) => Bool -> m a -> m a
21:22:10 <lambdabot> GHC.Exts.breakpointCond :: Bool -> a -> a
21:22:10 <lambdabot> Control.Exception.assert :: Bool -> a -> a
21:22:20 <mjrosenb> or not...
21:23:15 <mjrosenb> now if only if were defined as a function
21:23:32 <mjrosenb> if True _ x _ _ = x
21:23:49 <mjrosenb> if False _ _ _ x = x
21:24:08 * Twey goes 'eh?'
21:25:37 <mjrosenb> so sans parsing, if can be defined as a function in haskell
21:26:08 <mjrosenb> which would make most things that involve the Bool type easier to write
21:26:21 <mjrosenb> since 'if' would theoretically be curryable
21:26:33 <Twey> Oh I see.
21:26:41 <Twey> Hmn.
21:27:55 <Twey> if True x _ = x; if False _ x = x
21:27:56 <Twey> No?
21:29:36 <cjs> Grr. I'm getting a 141 exit code from my ghc-compiled program, and it's not caught by `catchError`.
21:30:32 <dons> cjs: a fatal signal?
21:30:39 <cjs> Looks like it.
21:30:49 <cjs> Oh, hm. I wonder if I can get a SIGPIPE from a network connection?
21:32:25 <cjs> I guess I can find out with ktrace.
21:33:54 <mjrosenb> Twey: i added in the other bindings so you could say if foo then bar else baz
21:34:26 <mjrosenb> cjs: iirc, yes you can
21:34:30 <cjs> 6047      1 playback PSIG  SIGVTALRM caught handler=0x8367f74 mask=())
21:34:31 <cjs> ...
21:34:35 <cjs> 6047      1 playback PSIG  SIGPIPE SIG_DFL
21:34:41 <cjs> And that's the last line of the trace.
21:35:03 <mjrosenb> the default handler for SIGPIPE is to keel over dead
21:35:18 <cjs> After reading up on the new signal handling code, I now understand just what's going on here.
21:35:58 <cjs> mjrosenb: Right, at the "C" level, as it were. I had basically assumed that the runtime would catch all signals and turn them into exceptions or something like that.
21:40:23 <mjrosenb> well the OS does'n know what code is running; it just kills the process
21:40:36 <mjrosenb> erm
21:40:46 * mjrosenb was thinking of different signals
21:40:50 <cjs> Right. Thus, I should have been thinking like a C programmer, not a Haskell programmer. :-)
21:40:50 <mjrosenb> you are totally correct
21:41:24 <cjs> So basically, if I want this thing to run reliably, I need to make sure I'm correctly handling all of the signals I might receive. Fair enough.
21:50:53 <codacola> http://foo-projects.org/~sofar/art/dilbert-linux.gif
21:51:40 <Elly> :)
22:18:20 <codacola>     You may use the software for non-commercial purposes  <- does that typically mean for free software development as well?
22:22:40 <hml> the following code does not compile; does it mean that in haskell when I declare something to be of an array type; I have to speficy it's size statically?
22:22:43 <hml> import Data.Array
22:22:46 <hml> data Object = Object { vertex_arr :: Array }
22:22:46 <hml> (if not, how can i get around this)
22:23:08 <dons> hml: nope. you specify its index and element types.
22:23:18 <dons> data Object = Object { vertex_arr :: Array Int Bool }
22:23:27 <dons> would be an object containing Int-dexed booleans
22:28:30 <hml> dons: got it; thanks!
22:29:47 <vinc456> i think i might have found an error in a textbook. Before i e-mail the author i would like to make sure that it's not on my part
22:29:55 <vinc456> http://codepad.org/k8Ws4wpW
22:30:10 <cjs> codacola: Typically. But you want to be careful with that sort of thing; it's always best just to contact the owners if you're not sure.
22:30:13 <Trinithis> What would be a good way of defining a higher-order case function case'?
22:30:47 <Trinithis> Or would lambdas be the way to go?
22:30:50 <bos> Trinithis: a what?
22:30:58 <dolio> vinc456: The first line is backwards. It should be your second line instead.
22:31:12 <Trinithis> bos: a case equivalent to the if' function
22:31:17 <Trinithis> where if' is if as a func
22:31:27 <Elly> wait, how does that work?
22:31:31 <cjs> Trinithis: do you have an example of its use?
22:31:32 <bos> Trinithis: that doesn't really make any sense.
22:31:46 <Elly> oh, wait, thunks
22:32:05 <Trinithis> I was just wondering. I would think just using a lambda would be the easiest way though
22:33:17 <dolio> vinc456: You could keep the first line, but it's unlikely to add a lot of value.
22:34:29 <Elly> Trinithis: you could do: if' p i e = if p then i () else e ()
22:34:45 <Elly> although actually
22:35:08 <vinc456> dolio: well actually the third line is missing in the original code and i have problems running the functionwithout it. I didn't see this mentioned in the errata so i thought it might be an mistake
22:35:12 <Trinithis> Now that I think about it, what I was asking for doesn't really make sense because of pattern matching issues
22:35:23 <Elly> yeah, you can do: if' p i e = if p then i else e
22:35:30 <Elly> but I dunno how that helps you
22:35:53 <dolio> vinc456: Oh, it was only the first two lines?
22:36:03 <Trinithis> I already have a func like that. I was just asking about a case' just out of curiosity, not out of any real need
22:36:54 <vinc456> dolio: 1, 2 and 5 actually. it's page 51 of Programming in Haskell by Graham Hutton if you happen to have the book
22:37:07 <vinc456> i'll report it anyways, worst case scenario is i'm wrong and graham ignores me
22:37:38 <dolio> I don't. But, yeah, the match against [] and the match against (x:xs) should be on the same argument.
22:38:31 <catface> http://hpaste.org/9131
22:38:54 <dolio> vinc456: Oh, when I said 'first line' I meant first clause of the function, not the type signature. And so on.
22:39:55 <vinc456> dolio: ok. thanks for your help
22:40:08 * dobblego wonders if groupBy can be written across Traversable
22:41:04 <cjs> vinc456: I have Hutton, and his version is not what was in that paste. Here's what I have: http://hpaste.org/9132
22:43:07 <vinc456> i renamed the function because i was getting an ambiguous occurence error. do you get an exception when you try run the function?
22:44:11 <cjs> I've not tried to run it, but note that the second line of yours is not in Hutton's, and the third line of yours that you added is the second line of Hutton's.
22:44:28 <vinc456> i think it's because (++) is already defined. anyways the error is that I think you need the extra line "[] ++ ys     = ys"
22:44:30 <cjs> BTW, you can probably "import Prelude hiding ((++))" to get rid of the error.
22:44:48 <cjs> vinc456: That's not an extra line, that's the original line, in my copy.
22:45:33 <cjs> BTW, my copyright page says "First published 2007", so there's no indication that I have a corrected copy.
22:46:44 <Trinithis> Are there standard versions of uncurry that convert to n-tuples instead of only pairs?
22:47:29 <dolio> uncurry3 is coming whenever the libraries get bumped, I think (6.10).
22:47:44 <Trinithis> Ok
22:47:58 <Trinithis> So in the meantime, I should define them myself?
22:48:22 <dolio> Yeah.
22:48:39 <Trinithis> k
22:48:39 <dolio> There won't be uncurry4+, incidentally.
22:48:44 <Trinithis> huh
22:48:48 <dolio> At least, I don't think.
22:48:55 <Trinithis> :t uncurry . uncurry
22:48:56 <lambdabot> forall b c a b1. (a -> b1 -> b -> c) -> ((a, b1), b) -> c
22:49:19 <hml> why does haskell think the following is a data constructor (i'm trying to define a function)
22:49:22 <hml> SplitObject objectA objectB = NullObject
22:49:47 <Trinithis> Haskell is case sensitive
22:49:54 <Trinithis> SplitObject should be splitObject
22:50:03 <Trinithis> only constructors are uppercased
22:50:12 <hml> fixed it: thanks
22:50:16 <Deewiant> if it's capitalized, or an operator beginning with :, it's a data constructor
22:50:35 <newsham> http://hpaste.org/9133
22:50:46 <newsham> I'm getting a weird error when trying to use sockets
22:51:03 <Trinithis> Deewiant: Any user-defined operator beginning with ':' ?
22:51:13 <newsham> anyone seen this before?
22:51:19 <Deewiant> Trinithis: yes.
22:51:24 <Trinithis> huh
22:51:51 <Deewiant> > let x :! y = x + y in 1 :! 2
22:51:52 <lambdabot>   Not in scope: data constructor `:!'
22:52:33 <Trinithis> > data X a b = a %%% b
22:52:33 <lambdabot>  Parse error at "data" (column 1)
22:52:42 <Trinithis> > data X a b = a :%%% b
22:52:42 <lambdabot>  Parse error at "data" (column 1)
22:53:15 <vinc456> cjs: my bad, i was confused because "ys ++ []     = ys" and "ys ++ []     = ys" are not quite the same
22:53:40 <newsham> you cant do data decls in lambdabot
22:53:50 <Trinithis> mm
22:54:53 <codacola> they arent?
22:56:59 <cjs> codacola: I think he mistyped here, too.
22:57:13 <codacola> oh, thought it was just me
22:57:17 <cjs> The confusion is "[] ++ ys" and "ys ++ []".
22:57:20 <codacola> anyways, back to being confused
22:58:33 <vinc456> grrr that's what i meant. i'll shut up now
22:58:47 <codacola> i wonder if i should be deleting these comments
22:59:09 <codacola> theyve got "add error checking here" for this tutorial work, unsure if they want it left there or not
23:03:38 <hml> i have: data Boundary = Boundary { lower :: Float, upper :: Float } -- how can I assert in the type declaration that lower <= upper?
23:03:53 <bos> you can't.
23:04:28 <bos> you could do it with a considerable amount of work for integers, but not for floats.
23:04:45 <bos> i don't think anyone has developed floating point arithmetic in the type system yet.
23:04:54 <opqdonut> hml: make a smart constructor that checks it
23:04:59 <hml> is there a way to hide a constructor; (i.e. force it to construct via a function taht I can check on) ... yet still allow pattern matching of the constructor?
23:05:08 <opqdonut> no
23:05:12 <cjs> Yup. Put it in a separate module, and don't export the value constructor.
23:05:23 <cjs> Oh, pattern matching. Oops.
23:05:23 <hml> can I still pattern match it outide the module?
23:05:31 <cjs> Nope.
23:05:31 <bos> not yet.
23:05:40 <opqdonut> no, you can only pattern match on constructors that are available
23:05:41 <bos> you'll need to wait for view patterns to show up.
23:05:58 <cjs> Are we getting that? Cool! Let's go all the way and do pattern matching on arbitrary functions!
23:05:59 <hml> lol; haskell is a lnguage that is continuning to evolve?
23:06:03 <mauke> the next best thing is to export a function that encapsulates pattern matching
23:06:11 <hml> mauke: how do I do that?
23:06:20 <mauke> @src maybe
23:06:21 <hml> mauke: oh; n/m; I tyhink i see it
23:06:21 <lambdabot> maybe n _ Nothing  = n
23:06:21 <lambdabot> maybe _ f (Just x) = f x
23:06:37 <mauke> ^ that's the deconstructor for Maybe a
23:08:04 <codacola> "i hate the word procedure" <- kinda silly reason to not use a language
23:10:03 <name_> is there any reason to use preluds list functions instead of stream-fusion ones
23:21:11 <hml> if i declare a type/record like: data Boundary = Boundary { lower :: Float, upper :: Float } ... is there a way that i can construct an instance of Boundary w/o using upper/lower ?
23:21:35 <mauke> Boundary 0 1
23:29:47 <hml> how do I fix the following:
23:29:49 <hml> data Boundary = Boundary { lower :: Float, upper :: Float }
23:29:49 <hml> works = upper (Boundary 1.0 2.0)
23:29:49 <hml> broken = (Boundary 1.0 2.0).upper
23:30:08 <mauke> heh
23:30:20 <mauke> by removing the "broken =" line
23:30:32 <hml> i can\'t use dot notation for fields?
23:30:35 <mauke> no
23:30:43 <mauke> . is function composition
23:31:03 <hml> ywow; so records/templates 'names' really create functions ?
23:31:11 <hml> that take the data type and return the fiel
23:31:12 <hml> hmm
23:31:21 <mauke> yes
23:31:27 <hml> got it; good to know ; thanks
23:31:39 <koninkje> or by monkey patching to redefine (.) and drive everyone crazy
23:31:39 <koninkje> http://www.reddit.com/comments/6r64b/
23:31:40 <mauke> the only thing that's special about record selectors is that you can use them in patterns
23:31:40 <lambdabot> Title: Parallel map-reduce in one line of Haskell : "bump all your cores to 100% usage, ...
23:31:46 <koninkje> >;)
23:32:06 <mauke> foo (Boundary{ lower = x }) = x
23:35:02 <Trinithis> @src (<**>)
23:35:03 <lambdabot> (<**>) = liftA2 (flip ($))
23:35:15 <Trinithis> @src (<*>)
23:35:15 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
23:36:08 <rwbarton> How can I convert "2008-07-24" to an integer (like "days since whenever")?
23:37:07 <Pseudonym> @let rowlandSequence = let { as = as' 7 2; as' an1 n = an1 : as' (an1 + gcd n an1) (n+1)) in filter (/= 1) $ zipWith (-) (tail as) as
23:37:08 <lambdabot>  Parse error
23:37:13 <Pseudonym> @let rowlandSequence = let { as = as' 7 2; as' an1 n = an1 : as' (an1 + gcd n an1) (n+1)) } in filter (/= 1) $ zipWith (-) (tail as) as
23:37:13 <lambdabot>  Parse error
23:37:26 <Pseudonym> @let rowlandSequence = let { as = as' 7 2; as' an1 n = an1 : as' (an1 + gcd n an1) (n+1) } in filter (/= 1) $ zipWith (-) (tail as) as
23:37:29 <lambdabot> Defined.
23:37:32 <Pseudonym> > rowlandSequence
23:37:35 <lambdabot>  [5,3,11,3,23,3,47,3,5,3,101,3,7,11,3,13,233,3,467,3,5,3,941,3,7,1889,3,3779,...
23:39:54 <Pseudonym> Nice.
23:42:46 <bos> Pseudonym: is that the new recurrence formula for generating primes?
23:43:00 <bos> i assume yes, due to the frequency of 3s
23:43:10 <lucca> http://www.research.att.com/~njas/sequences/A137613 ya
23:43:10 <lambdabot> Title: id:A137613 - OEIS Search Results
23:43:20 <Pseudonym> Yes.
23:44:07 <lucca> so what is the 5001st term?
23:44:18 <Pseudonym> > rowlandSequence !! 5001
23:44:21 <lambdabot>  Tried to use too much memory
23:44:25 <Pseudonym> Dunno.
23:49:33 <catface> anyone know of a haskell interpreter written in scheme?
23:50:03 <lucca> ...lots of the other way around :p
23:51:02 <Elly> "Write Yourself Scheme in 48 Hours" is to blame for that
23:51:10 <Elly> I don't know of any the other way though
23:51:15 <bos> whew, two book chapters tech edited today.
23:55:27 <papermachine> bos, nice.
23:55:36 <papermachine> Wish I were that productive.
23:56:51 <gabbs> hi, is there a decent haskell runtime debugger out there?
23:57:22 * luqui wishes there were, but isn't even sure what that would look like
23:59:25 <hml> I want to have this class 'intersectable' which has the & operator defined on it; I also have a boundary type:
23:59:29 <hml> class Intersectable a where (&) :: a -> a -> a
23:59:31 <hml> data Boundary = Boundary { lower :: Float, upper :: Float }
23:59:39 <hml> however, I can't make the Boundary type of the Intersectable class; when I try:
23:59:49 <hml> instance Intersectable a => Intersectable Boundary where
23:59:54 <hml> I get an erorr about the 'a' not being used
