00:00:12 <kosmikus> dons: I understand that. It still all depends on having one person feeling responsible. If Janis is willing to switch to Wiki, perfect. But it really depends on him.
00:00:37 <dons> sjanssen: i think it has to be cheaper to get new contributions than that.
00:00:38 <kosmikus> I'm just saying that it is not a majority decision, because we're not the ones doing the editing work.
00:00:42 <dons> sjanssen: more like our FAQ for xmonad.
00:01:08 <dons> kosmikus: sure. somehow we need both a happy editor, and decent coverage of the community.
00:01:23 <kosmikus> and I know it was difficult for me to find a successor as an editor.
00:01:56 <kosmikus> and from my own time, I recall that it is easy to understand constructive criticism as if the work isn't appreciated.
00:02:05 <dons> maybe at the HW we can discuss the role of the HCAR, now that the surrounding infrastructure has built up.
00:02:30 <vegai> here's my TChan stresser: http://hpaste.org/12459
00:02:40 <vegai> changing that to Chan stresses is trivial
00:02:42 <ksf> if it wasn't appreciated, you wouldn't get any feedback.
00:02:43 <kosmikus> so I'd like to prevent a public email discussion where everyone starts bashing the current HCAR system ;)
00:02:54 <ksf> it's not trivial to get, though.
00:03:06 <dons> what is its role, given hackage, industry wiki, haskell reddit? its collecting information from particular groups , some of which we know about, some we don't.
00:03:10 <dons> kosmikus: oh, certainly.
00:03:32 <dons> preparation seems like a lot of work. is it still an effective use of time?
00:04:03 <dons> i suppose the overriding concern is still coverage and breadth of groups reporting.
00:04:14 <kosmikus> dons: yes, you're absolutely right to question that. that's why I think you should definitely suggest the change to Janis.
00:04:25 <kosmikus> it might actually make things easier.
00:04:50 <kosmikus> currently, the processing of the emails is the thing that takes up most of the time.
00:05:03 <dons> yes. that seems like a bottleneck we know how to solve.
00:05:10 <kosmikus> i.e., people sending in stuff in strange formats despite being told not to, and so forth.
00:05:32 <dons> its an old fashioned way of organising content :) pre web 2.0
00:05:38 <kosmikus> in my experience there is a very small minority (less than 5 contributions) that take up almost half of the time
00:05:43 <dons> huh
00:06:09 <dons> the other good things: broad coverage, and high quality/reliable content.
00:06:29 <dons> the former, I worry we're not getting everything, the latter we must preserve
00:06:40 <kosmikus> dons: yes. if I'd still be editor, my main worry would be the initial overhead of setting things up.
00:06:56 <kosmikus> from experience, I knew pretty much how much time the HCAR would cost me at what point in time.
00:07:15 <kosmikus> and I would have been reluctant to invest a large amount of time outside of these windows in order to set up a new system.
00:07:19 <dons> yep
00:07:38 <dons> it seems like the community should help. why have a single person as the sole worker. strange.
00:07:45 <kosmikus> if you can argue that that is simple, I think you have a good chance of convincing Janis as well :)
00:08:16 <dons> well, i'll probably just set up a demo. seems like the easiest way to convey the idea.
00:08:44 <dons> then, say, the 'collection wiki' goes live for a month or two before the HCAR release, collecting submissions. then editing, and publish.
00:09:04 <erikc> hrm, why is it that all haskell jobs require graduate degrees :)
00:09:07 <dons> depending on how much checking and how much help is received to clean up the edits, that could be simple or hard.
00:09:28 <dons> erikc: hmm.
00:09:39 <sbahra> dons, have you looked at proggy fonts before?
00:09:47 <dons> sbahra: no?
00:09:51 <sbahra> x11-fonts/proggy_fonts, The perfect monospaced bitmap programming fonts, http://www.proggyfonts.com/
00:09:52 <lambdabot> Title: Proggy Programming Fonts
00:09:56 <kosmikus> dons: sounds good.
00:10:03 <sbahra> dons, they're very nice.
00:10:15 <ksf> erikc, just send them code that your average lecturer doesn't stand a chance of understanding.
00:10:39 <ksf> might scare them off, might make them hunting for your head.
00:10:52 <dons> "1700 lines of Haskell code (including about 250 lines for the C API), is compiled to a DLL with ghc, and linked dynamically into C++ and Java applications"
00:10:59 <dons> huh. i wish they would tell us how they did that.
00:11:32 <dons> we could ship more ghc's if it was really obvious you could link haskell smarts into C++ and Java.
00:12:07 <ksf> sbahra, you're the hero of the day.
00:12:24 <erikc> what is this you're referring to dons
00:12:50 <dons> http://www.haskell.org/communities/11-2008/html/report.html#sect7.7
00:12:52 <lambdabot> Title: Haskell Communities and Activities Report, http://tinyurl.com/6f36nz
00:13:03 <sbahra> ksf, why?
00:13:04 <dons> that entry is why we have the HCAR
00:13:10 <ksf> I'm long sick of bitstream vera.
00:13:14 <sbahra> Ah :)
00:13:16 <dons> no one has heard of these guys. they did amazing things. in haskell. and well.
00:21:12 <erikc> well im working on the c++ one, we'll see how far i get, im pretty optimistic at this point
00:22:11 <ksf> argh
00:22:34 <ksf> why didn't the gentoo devs package the ttf versions?
00:22:37 <vegai> heh, http://sklofp.zju.edu.cn/icfp2009/
00:22:41 <lambdabot> Title: Homepage of ICFP2009
00:22:54 <mornfall> dons: I suspect they just use http://www.haskell.org/haskellwiki/GHC/Using_the_FFI#Callbacks_into_Haskell_from_foreign_code
00:22:57 <lambdabot> Title: GHC/Using the FFI - HaskellWiki, http://tinyurl.com/6xh6cr
00:24:57 <Axman6> are Chan's safe to use if you have multiple things adding to a chan, and one consumer? or would a TChan be better?
00:25:41 <Axman6> the order isn;t important, just need to make sure i get everything into the chan without issue
00:25:55 <mornfall> dons: Once you have a C library, it's just a matter of writing the right wrappers to pull it into C++ or Java.
00:26:06 * Axman6 pokes dons for advice, respectfully
00:26:42 <vegai> Axman6: that's pretty much what I tested in my Chan test. And yes, the messages seem to come out just fine
00:26:46 <vegai> I don't know if that's guaranteed, though
00:26:55 <Axman6> ok, thanks :)
00:27:56 <vegai> I would think that it is
00:30:02 <erikc> the hard about ffi is data representation, not control transfer (ignoring cross-language unwinding)
00:30:22 <erikc> hard part
00:31:04 <MikeMayer> might someone take a look at what I'm doing wrong for a sec? http://hpaste.org/12458#a1
00:31:23 <mornfall> erikc: Well, in the mentioned situation, it would seem that they just need to get the problem description in and error messages out, so it could be fairly straightforward.
00:31:31 <erikc> right
00:31:32 <opqdonut> MikeMayer: you don't need that [] case
00:31:41 <opqdonut> as concat (intersperse ", " a) isn't recursive
00:31:46 <erikc> their case seems straightforward
00:31:51 <MikeMayer> opqdonut: I didn't think so but I had it for good measure
00:31:54 <ksf> non-resizable fonts just don't work, i want to be able to read the console at distances between 30cm and 2m.
00:32:22 <erikc> the killer for c++ is discovering data representation requires template expansion
00:32:24 <MikeMayer> opqdonut: when I remove that case though it won't compile anymore
00:32:59 <opqdonut> with what error
00:33:05 <opqdonut> > let a = [] in concat (intersperse ", " a)
00:33:06 <lambdabot>   ""
00:33:09 <MikeMayer> Not in scope: `commaSeperate'
00:33:13 <mornfall> erikc: Well, that's the whole point of templates, sort of. : - )
00:33:26 <mornfall> Yes, powerful languages are hard to FFI.
00:33:30 <opqdonut> MikeMayer: you're doing something wrong. that code works
00:33:37 <opqdonut> > let a = ["foo", "bar"] in concat (intersperse ", " a)
00:33:38 <lambdabot>   "foo, bar"
00:33:43 <MikeMayer> hmm
00:33:45 <MikeMayer> ok
00:33:47 <ksf> did anyone ever have the idea to code hm type inference in templates?
00:33:58 <mornfall> ksf: I'd say that'd be quite silly.
00:34:04 <ksf> ...for templates, of course.
00:34:06 <MikeMayer> opqdonut: thanks :)
00:34:08 <mornfall> Ah.
00:34:09 <mornfall> : - )
00:34:16 <ksf> it'd safe me tons of typing work.
00:34:56 <mornfall> Well, C++ as a language doesn't work well with inference.
00:34:58 <ksf> also, it would make certain techniques feasible that now are just too...erm... bracketly.
00:35:23 <erikc> vc++ 2010 has auto keyword support :), wait 2 years
00:35:24 <ksf> i don't care for c, it's the template type insanity that buggers me.
00:35:39 <mornfall> erikc: That's not really inference, it's just "avoid stating the obvious".
00:35:54 <erikc> true, but it nails a large amount of use cases
00:36:14 <mornfall> erikc: #define AUTO(x,y) typeof(y) x = y ; - )
00:37:24 <erikc> hmm...im embarassed to say that trick never occurred to me, now which compilers have typeof...
00:37:38 <ksf> ghc has.
00:37:43 <ksf> it's called pattern matching.
00:38:18 <erikc> no vc++ support :\, sigh
00:38:26 <mornfall> Ah. Yeah, VC++ is a bitch.
00:38:32 * mornfall fortunately doesn't need to care.
00:39:09 * ksf sometimes even considers ddd to be overkill
00:39:41 <erikc> also bugs me that vc++ has no intention to ever support c99
00:39:51 <ksf> but then i can find my way around ed, too.
00:40:12 <MikeMayer> I get the same "not in scope" error with ghc or ghci
00:40:14 <ksf> we need an ed-mode for yi.
00:40:15 <opqdonut> ed is great
00:40:26 <opqdonut> tho ex has some nice extensions
00:40:35 <dancor> is there any kind of description of what O2 does that O doesn't do
00:40:44 <ksf> in case vty doesn't run on TERM.
00:40:50 <ksf> the solaris vi does the same.
00:40:52 <dancor> (besides ghc source :)
00:40:57 <ksf> it's the only sensible fallback.
00:41:04 <MikeMayer> > let a = ["apple", "banana", "carrot"] in concat(intersperse ", " a)
00:41:05 <lambdabot>   "apple, banana, carrot"
00:41:22 <MikeMayer> weird that it works here but not with ghc/gchi
00:41:38 <mornfall> MikeMayer: don't forget to import Data.List
00:41:41 <vegai> dancor: http://www.haskell.org/ghc/docs/latest/html/users_guide/options-optimise.html
00:41:48 <lambdabot> Title: 5.9.�Optimisation (code improvement), http://tinyurl.com/254c66
00:41:52 <MikeMayer> mornfall: sure have :/
00:41:53 <vegai> well, ok. That's not very specific
00:46:06 <MikeMayer> thanks everyone who helped me- I really appreciate it
01:11:44 <dancor> why is -fvia-C recommended (with -O2) for going-for-broke optimization
01:11:52 <dancor> or, what is compiling normally via?
01:12:46 <Lemmih> dancor: Native code.
01:13:09 <dancor> the idea is just that gcc may think of some things ghc did not?
01:13:36 <dancor> at 2x compile time or whatever
01:14:45 <luite_> dancor: the main idea is that gcc has better native code generation
01:14:57 <Lemmih> Going through C is more trouble than it's worth.
01:17:35 <povman> does that mean there are 2 different compilation paths that need to be maintained?
01:18:03 <ksf> not any more, now there's a third one ;)
01:18:17 <povman> what?
01:18:23 <ksf> new codegen.
01:18:37 <povman> another native one?
01:18:49 <ksf> dons posted some links yesterday, lemme grep through my history.
01:19:29 <povman> ooo i should find an excuse to use quasiquoting
01:19:53 <povman> or no
01:20:41 <ksf> http://hackage.haskell.org/trac/ghc/wiki/Commentary/Compiler/NewCodeGen
01:20:43 <lambdabot> Title: Commentary/Compiler/NewCodeGen - GHC - Trac, http://tinyurl.com/63hck7
01:21:11 <ksf> http://hackage.haskell.org/trac/ghc/wiki/Commentary/Compiler/IntegratedCodeGen
01:21:14 <lambdabot> Title: Commentary/Compiler/IntegratedCodeGen - GHC - Trac, http://tinyurl.com/6g4fqb
01:22:47 <ksf> I assume that all the ghc devs won't even start to be content until ghc outsmarts gcc on every scale.
01:23:19 <povman> interesting. i suggested that possible future last night and got yelled at :p
01:29:23 <quicksilver> dancor: it is no longer recommended, btw
01:29:26 <quicksilver> dancor: it once was.
01:29:43 <dancor> oh
01:30:05 <quicksilver> dancor: it might stil be a win for certain floating point code. GHC doesn't have much of an FP codegen, gcc does.
01:30:30 <pao> hi all
01:30:32 <quicksilver> but for typical branching algorithmic code, the native codegen should do better.
01:31:03 <pao> I remember I've seen dihomogeneus list implementation based on same haskell extensions... I think it was phantoms...
01:31:16 <pao> has anyone a pointer?
01:31:55 <quicksilver> what does "dihomogeneous" mean?
01:32:03 <Lemmih> List of Either's?
01:32:22 <pao> quicksilver: [1, "foo", ...]
01:32:31 <quicksilver> heterogeneous.
01:32:38 <pao> quicksilver: yep... sorry
01:32:42 <quicksilver> HList is the canonical one.
01:32:55 <pao> Lemmih: List of Either is h98 in fact :-)
01:33:02 <pao> quicksilver: thanks I'll give a look
01:33:09 <quicksilver> it's important to recognise that HList is really just nested tuples.
01:33:19 <quicksilver> with a load of type classes to help you manage them in interesting ways.
01:33:32 <quicksilver> [Dynamic] is a totally different approach.
01:35:20 <pao> quicksilver: thanks
01:36:09 <quicksilver> pao: In practice, I don't find I need either solution.
01:36:19 <quicksilver> I would tend to a custom existential or an ADT.
01:36:50 <pao> quicksilver: In fact I think existential was the non standard feature that I was looking for
01:36:58 <pao> http://en.wikibooks.org/wiki/Haskell/Existentially_quantified_types
01:37:10 <lambdabot> http://tinyurl.com/f9umb
01:37:37 <pao> quicksilver: It has an example for building heterogeneous lists... that was the doc I wasn't remembering
01:38:01 <pao> quicksilver: you helped me with "heterogeneous" :-)
01:38:42 <quicksilver> Dynamic is something of a catch-all existential.
01:38:54 <quicksilver> being a catch-all it should probably be seen as a last resort.
01:39:39 <pao> quicksilver: clear
01:39:41 <glguy> Data.Dynamic? You're doing it wrong :)
01:39:55 <pao> glguy: ? :-)
01:40:03 <pao> quicksilver: thank you very much... very helpful
01:40:25 <quicksilver> glguy: HELP I ACCIDENTALLY THE TYPE SYSTEM
01:40:47 <glguy> types are hard. let's go shopping
01:52:50 <JaffaCake> glguy: shopping is *much* harder than types, especially in offline shops
01:53:06 <povman> especially with women
01:53:32 <glguy> I didn't realize it was so hard... my wife handles most of it
01:53:40 <JaffaCake> exactly, mine too
01:54:26 <ksf> http://hackage.haskell.org/trac/haskell-prime/wiki/CompositionAsDot is rather pointless imo
01:54:27 <lambdabot> Title: CompositionAsDot - Haskell Prime - Trac, http://tinyurl.com/5wvoet
01:54:50 <JaffaCake> ksf: I think we've pretty much resolved that now anyway
01:55:06 <JaffaCake> with the new qualified operator syntax
01:55:48 <ksf> duh.
01:56:12 <ksf> I always wondered why it's Prelude.>==, anyway.
01:56:39 <JaffaCake> it made sense from a certain point of view
01:57:04 <JaffaCake> but Preluide.(>>=) makes more sense
01:57:05 <pao> can I consider phantom types extension being a subset of gadts and not worth mastering?
01:57:16 <ksf> so that you can say Foo.) as Foo.()) doesn't really work?
01:57:31 <JaffaCake> pao: phantom types is not an extension
01:57:48 <pao> JaffaCake: is it h98?
01:57:54 <JaffaCake> pao: yes
01:58:05 <pao> JaffaCake: clear
01:58:13 <ksf> it's a design pattern.
01:58:18 <JaffaCake> ksf: I don't follow
01:58:59 <ksf> it's a not-so-completely-obvious trick that you can apply to certain classes of problems.
01:59:43 <JaffaCake> ksf: sorry, what trick?
01:59:59 <povman> JaffaCake: http://en.wikibooks.org/wiki/Haskell/Phantom_types
02:00:33 <JaffaCake> oh right, I thought you were still talking about qualified operators :)
02:00:35 <povman> actually it sounds like something you should never need if you got the design right...
02:01:18 <flux> povman, how so?
02:01:39 <ksf> you're doing inference for the type inferer.
02:01:40 <flux> povman, with phantom types you can for example implement type-level access control
02:01:43 <povman> isn't it better to just name your function differently?
02:01:53 <quicksilver> no.
02:01:55 <povman> er
02:01:56 <pao> what I understand is that you have funcy type check requirements that can benefit from phantom, you can use GADT as well
02:02:02 <quicksilver> you can be polymorphic over the phantom
02:02:04 <quicksilver> that's the benefit.
02:02:12 <quicksilver> some functions will be polymorphic over the phantom
02:02:17 <povman> oh i see
02:02:20 <quicksilver> whilst others will depend on a particular value of the phantom
02:02:24 <povman> my bad
02:02:36 * povman learns
02:02:59 <quicksilver> in a funny sort of way the "a" and "b" in "a -> b" are like phantoms.
02:03:15 <quicksilver> after all, (->) isn't actually a data declaration which actually contains members of types a and b
02:03:22 <osfameron> quicksilver: btw, are you at LPW this weekend?
02:03:30 <quicksilver> osfameron: I hope to come along for a bit of it.
02:03:42 <osfameron> quicksilver: I'll be talking about monads :-)
02:03:46 <ksf> but then what stops you from matching on a TI inside concat, to stay at that site's example?
02:04:36 <ksf> I'd use something like Either Int String instead.
02:05:31 <quicksilver> ksf: it's not a good example.
02:05:42 <quicksilver> ksf: you'd have to hide the constructors, and export restricted versions.
02:05:51 <quicksilver> which amounts to doing GADTs the hard way.
02:05:59 <quicksilver> (losing the convenience of pattern matching)
02:07:34 <ksf> you have to have some code that gets utterly elegant to justify and weigh off that kludge.
02:07:55 <quicksilver> ksf: it's just a stupid example, honestly.
02:08:00 <quicksilver> not all uses of phantom types are like that ;)
02:08:24 * ksf remembers something inside the xmonad docs
02:08:43 <ksf> but i never actually wanted to do such a thing.
02:08:54 <quicksilver> I have also never needed them in anger.
02:09:10 <ksf> otoh, we _could_ use a haskell design patterns book
02:09:47 <ksf> that, more or less, explains all coding strategies you can use in haskell, starting with passing a function to a function.
02:10:48 <ksf> ppl will fall for the "design pattern" buzzword and leave c++ like rats a ship as soon as they realize what they're missing.
02:11:40 <ksf> hmmm....
02:12:01 <ksf> we got GADT syntax, we got record syntax, but no named function args.
02:12:03 <ksf> why's that?
02:13:12 <ksf> ...but then we got implicit args.
02:13:15 <pao> ksf: I can get a good example on the paper "the fun of programming"
02:13:20 <ksf> doesn't really match up.
02:13:27 <quicksilver> ksf: nobody seems to find them quite important enough (named function args) to spend the time implementing.
02:13:41 <pao> ksf: "Fun with phantom types" by Hinze
02:14:12 <pao> ksf: implict args?
02:14:40 <ksf> I'd prefer having putString with a named arg defaulting to stdout over the putString/hPutString duality.
02:15:01 <ksf> http://cvs.haskell.org/Hugs/pages/users_guide/implicit-parameters.html
02:15:03 <lambdabot> Title: Implicit parameters, http://tinyurl.com/35uxrh
02:15:14 <pao> ksf: by the way example in Hinze is a subset of the example in SPJ paper on gadts
02:15:43 <quicksilver> ksf: How would you distinguish a partially applied function from a missing defaulted arg?
02:16:05 <ksf> you'd have to name the arg to specify it.
02:16:19 <ksf> if missing, the default is taken.
02:16:24 <ksf> let me think of a syntax.
02:17:02 <ksf> putStLn (?handle = stderr) "Whoops"
02:17:14 * ksf smells dynamic scope
02:17:22 <quicksilver> ok, but let's suppose for the sake of the argument the args were in the other order
02:17:34 <quicksilver> putStrLn "Whoops" (?handle=stderr)
02:17:36 <quicksilver> now consider
02:17:40 <quicksilver> putStrLn "Whoops"
02:17:45 <quicksilver> is that partially applied?
02:17:49 <quicksilver> or defaulted to stdout?
02:17:50 <ksf> nope.
02:17:54 <ksf> it's stdout.
02:18:03 <quicksilver> ok, so how do I write the partially applied one?
02:18:16 <ksf> dynamic scope is really the key here.
02:18:18 <ksf> erm...
02:18:54 <quicksilver> implicit arguments already give a kind of dynamic scope. They're a bloody mess and no one uses them in new code.
02:18:57 <ksf> (\h -> putStrLn (?handle = h) "whoops")
02:19:11 <quicksilver> ksf: no, I deliberately wanted the handle argument to be second
02:19:13 <quicksilver> to make my point
02:19:18 <povman> sounds an awful lot like record syntax
02:19:26 <quicksilver> it would be hard to distinguish between a trailing defaulted argument
02:19:34 <ksf> (\s -> putStrLn s (?handle = stderr))
02:19:40 <quicksilver> let's make it worse
02:19:42 <Axman6> whoot, finally made this thing a hell of a lot faster!
02:19:51 <quicksilver> suppose the string also defaults to "Hello World"
02:19:55 <Axman6> my god i love how fun haskell + GHC makes playing with concurrency
02:20:06 <povman> putStrLn s (Args {handle = stderr})
02:20:08 <quicksilver> putStrLn (?handle = stderr) (?string = "Boo")
02:20:11 <ksf> that's a bloody great idea.
02:20:20 <quicksilver> now if I just write 'putStrLn'
02:20:24 <quicksilver> has that defaulted both arguments?
02:20:30 <quicksilver> or is it just not applied yet?
02:20:33 <ksf> one step closer to beating HQ9+ in source code length.
02:20:48 <mibbi> how to create random numbers?
02:21:02 <Axman6> @hoogle random
02:21:02 <lambdabot> package random
02:21:02 <lambdabot> System.Random random :: (Random a, RandomGen g) => g -> (a, g)
02:21:02 <lambdabot> module System.Random
02:21:10 <ksf> putStrLn (?handle = _) (?string = _)
02:21:34 <ksf> putStrLn (?string = _) (?handle = _)
02:21:43 <ksf> is the same with args flipped.
02:21:53 <ksf> that's undefaulting stuff.
02:22:12 <povman> mibbi: also try this file:///usr/local/share/doc/ghc/libraries/random/System-Random.html#v%3AgetStdRandom
02:22:13 <mibbi> and how to get the system's time?
02:22:17 <ksf> ...which is what you want to do, if you wanna curry.
02:22:31 <Axman6> @hoogle getCurrentTime
02:22:32 <lambdabot> Data.Time.Clock getCurrentTime :: IO UTCTime
02:22:32 <lambdabot> Data.Time.LocalTime getCurrentTimeZone :: IO TimeZone
02:22:46 <luite_> mibbi: you may want to install MonadRandom once you get tired of passing the RandomGen around :)
02:22:50 <Axman6> i'm using Data.Time.Clock
02:23:37 <quicksilver> ksf: this has nothing to do with curry.
02:23:51 <quicksilver> ksf: I'm talking about partial application and principle types.
02:23:54 <ksf> yes i know, my terminology differs.
02:24:05 <quicksilver> ksf: are you saying that 'putStrLn' would default both?
02:24:12 <quicksilver> so 'putStrLn' is a term of type IO ()?
02:24:16 <ksf> currying is partial application to me.
02:24:18 <quicksilver> there where is my term with arguments?
02:24:32 <quicksilver> ksf: currying is replacing tuples with multiple arguments.
02:24:41 <ksf> yes, but it could use a better name then.
02:24:54 <ksf> and no, i wouldn't ever default the string arg.
02:25:04 <ksf> ...but name it, so you _may_ default it.
02:25:10 <quicksilver> why wouldn't it default it?
02:25:18 <ksf> ...so that they can be partially applied.
02:25:26 <ksf> that's why it's the same in my head.
02:25:32 <quicksilver> yes, but I'm asking a theoretical question about how your extension works.
02:25:39 <quicksilver> I'm saying I have chosen to give both arguments defaults.
02:25:50 <quicksilver> or are you saying that is forbidden by the system?
02:26:20 <ksf> you can do it, but I'd have to physically hurt you if you don't call the function stdoutPutHelloWorld ;)
02:26:20 <quicksilver> perhaps you're saying the final arg can never be defaulted?
02:26:28 <quicksilver> that's not the point.
02:26:38 <quicksilver> I'm tring to show you why your extension is hard.
02:26:41 <povman> it might be valid if there were different syntax for such functions
02:26:44 <quicksilver> because it leads to ambiguity.
02:26:52 <quicksilver> "putStrLn" then, is totally applied
02:27:01 <povman> eg ?putStrLn or something
02:27:02 <quicksilver> (because both its arguments are defaulted)
02:27:12 <quicksilver> so how do I get back to the unapplied one?
02:27:18 <quicksilver> I'm forced to use a lambda perhaps?
02:27:43 <ksf> if you choose to default both, you can do putStrLn (?handle = _) (?string = _) and putStrLn (?string = _) (?handle = _) to get unapplied functions. and yes, putStrLn would be completely applied, that's the very reason for defaults.
02:28:06 <quicksilver> ah, OK. a special token _ to indicate not yet applied.
02:28:07 * quicksilver nods
02:28:09 <quicksilver> that could work.
02:28:21 <quicksilver> you have some strange behaviour, though
02:28:36 <quicksilver> you lose the equation "f a $ b" = "f a b"
02:28:38 <ksf> it's actually just sugar for wrapping it up inside a lambda.
02:28:46 <quicksilver> because I can no longer write
02:28:48 <povman> ksf: i can't see how your syntax is any better than passing a record structure
02:29:00 <quicksilver> putStrLn (?handle = stdout) $ (?string = "Hi")
02:29:11 <quicksilver> (or..?) putStrLn (?handle = stdout) $ "Hi"
02:29:11 <ksf> you can't partially apply records.
02:29:43 <ksf> hmmm....
02:29:46 <povman> ksf: putStrLn (pslargs {handle = stdout})
02:30:02 <ksf> semantically, the dynamic binding is outside of the fun to be called.
02:30:11 <ksf> that's a syntactic nightmare.
02:30:29 <flux> perhaps you can look at ocaml for inspiration. however, named arguments (and optional ones) don't come without some complications, esp. regarding currying and type compatibility
02:30:53 <povman> unless there were some special syntax indicating a default structure associated with the function you're calling
02:31:11 <quicksilver> ksf: I think it's quite hard to get elegant syntax, principle typing of terms, and partial application all working at once
02:31:22 <quicksilver> ksf: but I'd be interested to see a proposal which does.
02:31:22 <flux> for example a function taking only optional arguments will require a unit argument to be evaluated
02:31:28 <povman> eg putStrLn (~ {handle=stdout, string="blah"})
02:31:34 <flux> (and optional argument can never be after the last non-optional one)
02:31:46 <ksf> flux, nope it does'nt neet to.
02:31:51 <quicksilver> (I think the reason it hasn't been done, by the way, is that it's not obvious how to do it)
02:31:51 <povman> where ~ represents the default record attaached to putStrLn
02:31:56 <flux> ksf, I was referring to how O'Caml does it
02:32:02 <ksf> ah.
02:32:15 <ksf> never looked at it after i get fed up with / vs. /. .
02:32:18 <flux> :-)
02:32:43 <flux> otherwise I actually think that in whole the named/optional argument thing is mostly done right in it
02:32:53 <ksf> seemed like a restricted scheme to me, too.
02:32:59 <ksf> though usually faster.
02:33:13 <kig>  /. is the right thing to do
02:33:27 <ksf> it's pure b&d.
02:33:30 <kig> mixing number types = painnn
02:33:46 <ksf> but then ocaml == pascal, in too many senses.
02:35:23 <quicksilver> is / vs /. different from div vs / ?
02:35:28 <quicksilver> I don't remember my ocaml very well
02:35:48 <ksf> :t mod
02:35:49 <lambdabot> forall a. (Integral a) => a -> a -> a
02:35:54 <ksf> hmmm...
02:36:10 <ksf> shouldn't it work on floats, too?
02:36:24 <quicksilver> there is a mod' for floats, hidden away in Data.Fixed
02:37:39 <ksf> i can think of a thousand applications of using float mod 1 mod -1 arithmetic.
02:48:49 <ksf> haskell should just switch completely to s-expressions, life would be so much easier.
02:49:08 <ksf> (please don't point me to liskell, i know it exists)
02:50:44 <cads> why not simply use that?
02:51:07 <cads> it looks pretty interesting
02:51:37 <quicksilver> typed s-expressions might be fun.
02:52:13 <ksf> the desugaring is the wrong way round.
02:52:38 <ksf> the current haskell syntax should be sugar for the s-expr one.
02:53:22 <ksf> ...and we can include a runSugar while we're at it.
02:53:58 <quicksilver> unsafeDistillRum
02:54:02 <ksf> (runSugar haskellSyntax (main = putStrLn "Hello, World))
02:55:04 <ksf> ...in which case haskellSyntax returns main if there's a main and a nullop otherwise.
02:55:17 <ksf> or something more TH-ish.
02:55:34 <ksf> would utterly simplify th, too.
02:56:27 <BeelsebobWork> yay, pretty much done with time profiling now :) http://www.cs.kent.ac.uk/people/rpg/tatd2/Hsark.png
02:57:13 <povman> technically every syntax is sugar for another syntax from someone's perspective
02:57:53 <quicksilver> BeelsebobWork: purty colours!
02:58:03 <BeelsebobWork> quicksilver: :)
02:58:07 <BeelsebobWork> they're not perfect yet
02:58:20 <BeelsebobWork> I want it to be that the first part of the module path determines hue
02:58:23 <BeelsebobWork> the second part saturation
02:58:28 <BeelsebobWork> and the third part brightness
02:58:37 <flux> beelsebobwork, btw, have you taken a look at gprof2py for inspiration?
02:58:38 <BeelsebobWork> it only does the hue thing atm
02:58:46 <flux> uh, I mean gprof2dot.py
02:59:08 <flux> because that's something I've found useful
02:59:17 <BeelsebobWork> flux: you can get that kind of output from pretty-hat
02:59:33 <BeelsebobWork> there's not enough info in the simple profiling tools though
03:03:38 <roderyk> f <- Data.ByteString.readFile ..; followed by XML.Expat.parse gives me a type mismatch:
03:03:40 <roderyk> Couldn't match expected type `Data.ByteString.Lazy.Internal.ByteString' against inferred type `ByteString'
03:04:14 <roderyk> what is the correct way to read in ByteStrings to be able to work with them? :)
03:04:33 <roderyk> do I need to encode it as UTF8 first?
03:05:49 <quicksilver> roderyk: no, that's not the problem
03:05:58 <quicksilver> roderyk: the problem is that one of those is lazy and one is strict
03:06:05 <quicksilver> (bytestring)
03:06:10 <quicksilver> they are different types.
03:06:24 <quicksilver> it's likely you just need to change your import to import the other type.
03:09:02 <ksf> http://hackage.haskell.org/trac/haskell-prime/wiki/Tabs ftw.
03:09:02 <lambdabot> Title: Tabs - Haskell Prime - Trac
03:09:22 <twb> Explain this:
03:09:22 <twb> > let valid_pref_data = [("test", "a shell command that runs regression tests"),("predist", "a shell command to run before `darcs dist'"),("boringfile", "the path to a version-controlled boring file"),("binariesfile", "the path to a version-controlled binaries file")]
03:09:22 <twb> <interactive>:1:264: parse error on input `]'
03:09:23 <lambdabot>   <no location info>: parse error on input `;'
03:09:31 <twb> ...in GHCi
03:09:48 <ksf> Doing that was so utterly obvious as i wrote my first layout parser, it surprises me noone else did it like that.
03:09:58 <quicksilver> twb: works for me.
03:10:07 <quicksilver> twb: (in ghci)
03:10:16 <twb> Maybe it's a 6.8.3 problem?
03:10:24 <quicksilver> I'm running 6.8.3
03:10:25 <twb> If I delete the last entry in the list, it works
03:10:39 <twb> If I delete all *but* the last entry in the list, it works
03:10:47 <quicksilver> twb: broken pty implementation on your OS
03:10:55 <twb> If I delete "version-controlled" from the last string, it works
03:10:57 <quicksilver> twb: cutting off lines that emacs sends to only 256 chars
03:11:01 <quicksilver> twb: I bet ;)
03:11:07 <twb> quicksilver: Emacs does that?!
03:11:09 <twb> WTF
03:11:15 <quicksilver> no, the broken pty implementation does it
03:11:22 <twb> Ugh
03:11:23 <quicksilver> although emacs presumably could, but doesn't, work around it.
03:11:25 <twb> Who can I blame for this?
03:11:31 <quicksilver> I had this problem on OSX Tiger with emacs
03:11:37 <quicksilver> btu I note that I don't in leopard
03:11:38 <twb> I'm on Debian
03:11:49 <loriel> condolences
03:11:54 <quicksilver> that's odd. I never had it on linux that I recall.
03:11:55 <twb> Heehee
03:12:34 <quicksilver> twb: well I'm sure it's a 256 char limit of some kind, then. maybe it's a bug worked around by newer versions of comint, or something?
03:12:48 <twb> I'm running Emacs trunk
03:12:51 <roderyk> quicksilver: ah, you're right. Expat was using Lazy bytestrings. I keep hitting these silly string / bytestring / encoding issues and spend too much time hitting my head against brick walls. Cheers!
03:14:47 <hugo___> hello
03:15:01 <povman> whatyp
03:15:24 <fasta> How do I get Haskell mode 2.4 working on Windows in Emacs? After executing this: (load "~/elisp/haskell-mode-2.4/haskell-site-file.el") there is no M-x haskell-mode available.
03:16:21 <fasta> Already got it.
03:16:25 <quicksilver> twb: I'm unable ot locate whichever information I had on this last time. Possibly it is an emacs bug.
03:16:35 <twb> Shrug
03:16:37 <twb> I have moved on
03:16:45 <quicksilver> twb: certainly I no longer suffer from it, but I've changed so many many things on my system since last time I fell foul of it.
03:24:53 <twb> @pl f acc (x,y) = acc ++ "\n" ++ x ++ ":" ++ (take (14 - (length x)) (repeat ' ')) ++ y
03:24:53 <lambdabot> f = (`ap` snd) . (. fst) . (. ((('\n' :) .) . liftM2 (.) (++) (((':' :) .) . (++) . flip take (repeat ' ') . (-) 14 . length))) . (.) . (++)
03:24:59 <twb> Ew.
03:25:20 <twb> How can I make the above form less ugly?
03:25:57 <int-e> what is wrong with \acc (x,y) -> etc?
03:26:08 <twb> int-e: oh sure, I do that
03:26:12 <twb> But all those ++s are ugly
03:26:14 <Peaker> > take 10 (repeat ' ')
03:26:15 <lambdabot>   "          "
03:26:19 <Peaker> > replicate 10 ' '
03:26:21 <lambdabot>   "          "
03:26:50 <int-e> twb: f acc (x,y) = concat [acc, "\n", x, ":", replicate (14 - length x) ' ', y]
03:27:43 <Peaker> maybe   unlines [acc, columnStr [14] [x, y]]
03:27:56 <Peaker> (columnStr would be a generalization on the replication thing between columns)
03:28:22 <EvilTerran> printf?
03:28:43 <int-e> twb: hmm. actually accumulating on the left like that is a bad idea, performance wise.
03:28:57 <Peaker> could use shows
03:29:06 <twb> The list is only 4 entries wide
03:29:07 <Peaker> but it does seem like x and y are all small O(1) strings
03:29:41 <int-e> twb: still, you could use concatMap (if I'm guessing what the surrounding code looks like correctly)
03:30:24 <twb> Really I just have a list of options and their one-line descriptions, and I want to turn them into lines for the "help" string
03:30:28 <Peaker> I dislike the (14 - length x) part the most
03:31:08 <int-e> take 15 $ x ++ ":" ++ repeat ' '
03:31:13 * int-e shrugs
03:31:18 <int-e> not quite the same :)
03:31:33 <int-e> > replicate (-10) ' '
03:31:34 <lambdabot>   ""
03:32:01 <EvilTerran> > (\acc (x,y) -> printf "%s\n%-15s%s" acc (x++":") y) "abc" ("def","ghi") :: String
03:32:03 <lambdabot>   "abc\ndef:           ghi"
03:32:20 <EvilTerran> "%s\n%-15s%s"!
03:32:25 <EvilTerran> :D
03:34:12 <Peaker> > let columnStr [] [x] = x ; columnStr (c:cs) (x:xs) = x ++ replicate (c - length x) ' ' ++ columnStr cs xs in columnStr [4,3] ["x", "y", "z"]
03:34:13 <lambdabot>   "x   y  z"
03:35:09 <Peaker> > let columnStr [] [x] = x ; columnStr (c:cs) (x:xs) = x ++ replicate (c - length x) ' ' ++ columnStr cs xs in unlines ["hello", columnStr [14] ["this is x", "and y"]
03:35:10 <lambdabot>   <no location info>: parse error on input `;'
03:35:19 <EvilTerran> "The document (fill i x) renders document x. It than appends spaces until the width is equal to i."
03:35:23 <Peaker> > let columnStr [] [x] = x ; columnStr (c:cs) (x:xs) = x ++ replicate (c - length x) ' ' ++ columnStr cs xs in unlines ["hello", columnStr [14] ["this is x", "and y"]]
03:35:25 <lambdabot>   "hello\nthis is x     and y\n"
03:35:28 <EvilTerran> (looking at Text.PrettyPrint.Leijen)
03:35:35 <EvilTerran> looks suitable for formatting tables
03:35:59 <Peaker> rendering tables to a teletype is so 1973 :-)
03:36:26 <EvilTerran> true
03:36:58 * EvilTerran is tempted to make a haskell analogue of perl6's reports or whatever they're called
03:37:00 <EvilTerran> sometime
03:39:33 <p_l> Peaker: And still so damn useful
03:43:52 <ksf> http://hackage.haskell.org/trac/haskell-prime/ticket/58 ++
03:43:54 <lambdabot> Title: #58 (prelude re-organisation proposal) - Haskell Prime - Trac
03:44:40 <ksf> h' should feel like a shiny, new language when you unwrap it, not like a battered box of legacy.
03:46:27 <myname> anyone using xmonad here?
03:46:47 <ksf> sure, though you'll find more in #xmonad.
03:47:10 <myname> cool, I have been trying to run weka under xmonad
03:47:15 <ksf> or maybe exactly as many.
03:47:16 <ivanm> ksf: oh, is _that_ what that channel's for ;-)
03:47:35 <ivanm> myname: xmonad discussion belongs in #xmonad (which I think is what ksf was hinting at)
03:47:41 <myname> and when I run weka, I get a empty screen
03:48:16 <ivanm> myname: see the xmonad faq
03:48:18 <myname> ah ok, thx ivan
03:48:22 <Peaker> p_l: only because we don't yet have decent/usable graphical environments
03:49:51 <p_l> Peaker: No, because text is much more versatile
03:50:15 <EvilTerran> p_l, er, text is a subset of graphics, it's trivially no more versatile
03:50:23 <EvilTerran> but it's so much easier to manipulate
03:50:26 <Peaker> p_l: text is sort of a rendering system, weaker than a real graphical system
03:50:40 <Peaker> EvilTerran: It doesn't have to be easier..
03:50:47 <Peaker> (But I agree that it currently is)
03:50:50 <p_l> EvilTerran: I'm talking about the ability to manipulate and present
03:51:08 * EvilTerran is also tempted to try to make a typesetting combinator library, again "sometime"
03:51:14 <Peaker> p_l: FieldTrip, for instance, is already making manipulation of graphics much easier
03:51:21 <EvilTerran> something that'd generate EPS or something
03:51:33 <ksf> port tex to haskell?
03:51:42 <Peaker> p_l: but perhaps some combinators to display text (as in tables/etc) are still missing there
03:51:58 <EvilTerran> ksf, not port, that'd just be silly. more like provide an alternative.
03:52:01 <p_l> Peaker: I allow of graphics generation only at the end of the chain (for various reasons)
03:52:21 <Peaker> p_l: "end of the chain"? What do you mean?
03:52:29 <quicksilver> Peaker: text is more versatile than graphics, because it is a useful input rather than just output
03:52:44 <quicksilver> I use CLI tools very heavily in my day job even though I am aware of graphical ones
03:52:49 <quicksilver> because graphical ones can't "pipe to awk"
03:52:52 <quicksilver> or anything like that.
03:53:07 <ksf> quicksilver, have a look at conal's work.
03:53:07 <quicksilver> maybe that is similar to what p_l is getting at
03:53:11 * EvilTerran is of the opinion that the design of TeX is, TBH, completely outdated
03:53:12 <ksf> he does such stuff with gui's.
03:53:13 <quicksilver> ksf: I do, all the time.
03:53:26 <quicksilver> ksf: apple does something similar with Automator, in fact.
03:53:27 <EvilTerran> and i think a replacement is long overdue
03:53:40 <quicksilver> but, it's not good enough until it's good enough
03:53:53 <ksf> EvilTerran, shut up, order your pizza and get to work ;)
03:53:55 <quicksilver> until I can attach that to my server logs and process 500k lines in a fraction of a second.
03:54:09 <EvilTerran> i have nothing against the internal workings of TeX - they're very clever, but the TeX language _sucks_
03:54:19 <quicksilver> in a very cool way
03:54:33 <quicksilver> a little like a motorway bridge made of matchsticks, which is actually strong enough to carry cars
03:54:39 <quicksilver> nobody would built it like that now
03:54:44 <quicksilver> but you have to be impressed that it works.
03:54:47 <EvilTerran> yeah
03:54:48 <p_l> Also, Automator is still nothing compared for example to Plan9 ability to couple nearly anything together
03:55:06 <EvilTerran> the non-terminating aspect of it bugs me slightly, though
03:55:07 <quicksilver> p_l: so I have heard, but not actually experienced first-hand.
03:55:46 <Peaker> quicksilver: Text is not an input - keyboard keys and mouse movements are input. Their translation to text is straight forward, but who's to say there's no straightforward way to input other kinds of things, like graphic editing commands?
03:56:38 <quicksilver> Peaker: I don't say there is none (in the platonic sense)
03:56:47 <quicksilver> Peaker: I say there is none (here, now, on this computer I am using)
03:57:15 <quicksilver> Peaker: you're quite wrong about text not being an input.
03:57:22 <quicksilver> cat access_log | grep Peaker
03:57:27 <Peaker> quicksilver: yeah, and I agree that currently, non-textual systems suck so bad that mostly-textual systems are easier to write and usually easier to work with.  I think this is sad and ought to change
03:57:28 <p_l> Peaker: And graphics is a really poor transmission system, especially for humans - there's so much approximation that it's a miracle we get it right...
03:57:31 <quicksilver> ^^ access_log is a text file, it is input.
03:57:45 <Peaker> quicksilver: Text can be an input argument just like any other value.  Its not UI input, though
03:58:05 <quicksilver> no, but it *is* the answer to your question
03:58:08 <Peaker> quicksilver: A graphical image, reference, or gesture can also be an input value
03:58:11 <quicksilver> "why use text as output" ?
03:58:21 <quicksilver> "because text outputted by one thing is a useful input to other things"
03:58:30 <quicksilver> and graphics is not, typically, a useful input.
03:58:37 <ksf> quicksilver, text is untyped.
03:58:39 <quicksilver> It could be in principle but it is not in practice.
03:58:39 <ksf> that's the problem.
03:58:50 <quicksilver> that's true, but fortunately I deal with structured text
03:58:56 <Peaker> p_l: The concensus is that many things are best displayed by graphics. For example, 3d models, state machine diagrams, photos, emotive displays, ...
03:59:01 <quicksilver> so there is a type system even if it's not checked at compile time.
03:59:12 <Peaker> quicksilver: well, text VS graphics is a false dichotomy
03:59:29 <Peaker> quicksilver: You really want to input a table into some program, not text that represents a table via spaces and newlines
04:00:05 <p_l> Peaker: that's why we use a textual format for that (cause text is easy to recode) and put rendering as the last part
04:00:29 <Peaker> p_l: the unix way of serializing everything to text to communicate is pretty horrible.. Did you see conal's tech talk?
04:01:03 <p_l> Peaker: Not yet, but you know the old unix/plan9 mantra?
04:01:30 <twb> p_l: "don't" ?
04:01:38 <ksf> I can't see why files shouldn't be typed.
04:01:40 <p_l> "If you can't do something right, don't do it". Text is portable across anything (well, sometimes you have to put an EBCDIC translator in the way, but...)
04:02:02 <Zao> p_l: Provided you know the encoding and no-one mangles it along the way.
04:02:22 <Peaker> p_l: EBCDIC translator <==> Data.Binary serialization
04:02:33 <osfameron> Peaker: horrible but effective.  I do like the typed monadshell/powershell idea a lot though
04:02:36 <Peaker> p_l: other kinds of data types can also be serialized
04:02:56 <p_l> Peaker: Have ever tried recovering something autoserialized?
04:03:03 <ksf> http://www.matroska.org/technical/specs/rfc/index.html ftw.
04:03:08 <Peaker> osfameron, p_l: conal's Eros system tech talk is pretty cool: http://www.youtube.com/watch?v=faJ8N0giqzw
04:03:09 <lambdabot> Title: YouTube - Tangible Functional Programming
04:03:17 <lambdabot> Title: EBML & Matroska RFC Specifications
04:03:20 <Peaker> p_l: I don't recall, why would I "recover" it? I just "load" it
04:03:47 <kig> you could add a mimetype header to the things you pipe. like http
04:03:55 <p_l> Peaker: Nice thing you live in "no faults ever/no one ever mangles your data" environment :-)
04:04:45 <p_l> As for binary formats, EBML is quite nice (I don't recommend text for everything - but most data can be safely represented as it)
04:04:49 <Zao> p_l: La-la-la-land?
04:05:14 <fasta> When in Haskell mode in Windows and evaluating a simple function defined in a source file, I only get a blank line as a result. It should have returned a list. When I write down the literal value and then press enter it works. Does this sound familiar to anyone?
04:05:28 <ksf> generally ebml and xml are better for structured data than plain text.
04:05:34 <Zao> fasta: Haskell Mode means inside emacs?
04:05:36 <ksf> ...no matter whether it's a table or ast.
04:05:46 <fasta> Zao, yes
04:06:01 <ksf> you can always render an xml table as plain text in case you want to display it on a teletype.
04:07:03 <p_l> The thing is, if you want to make a transport format, don't "serialize". Write a f*cking translator from your datastructure to a sensibly *designed* format... otherwise we end up with Java's XML Hell
04:07:32 <ksf> i'd also prefer a decent ebml editor over struggling with xml syntax just because a plain-text editor can mess with it.
04:08:11 <fasta> Zao: it doesn't seem to work when the file I am loading is a Unix file.
04:08:28 <fasta> Zao: it does work with a new Windows file.
04:08:57 <p_l> ksf: If the data really benefits from being put in binary format (like multimedia) EBML is lifesaver :)
04:09:23 * p_l doesn't understand why some people try to cram graphics into XML files...
04:09:35 * EvilTerran concurs
04:09:59 <ksf> base64 encoding them and then gzipping the resulting xml is pure madness.
04:10:04 <EvilTerran> see SVG: they gave up and introduced a CFG to describe sequences of vertices
04:10:31 <p_l> EvilTerran: _raster_ graphics. See the proposed new format for Gimp ;_;
04:10:54 <loriel> I can use javascript and DOM manipulation to mess with svgs
04:11:09 <loriel> Try generating/manipulating pngs in javascript in the browser >:C
04:11:15 <scanz> hey all
04:11:40 <ksf> i once mangled png palettes under j2me.
04:16:50 <vegai> can HUnit report how long the testing took?
04:17:03 <scanz> i have some source code to scan, and replace identifier like variable names with Idf
04:17:21 <ksf> use template haskell.
04:17:31 <ksf> maybe together with haskell-src-exts
04:17:32 <scanz> but dont know how
04:17:33 <vegai> or sed :P
04:17:37 <scanz> i give you example
04:17:41 <ksf> depends on what you need to do.
04:18:03 <scanz> http://hpaste.org/12462 this code
04:18:43 <ksf> ah. not haskell source.
04:18:45 <scanz> http://hpaste.org/12463 and this is my code
04:19:00 <ksf> write a parser, a pretty printer, the rest is trivial.
04:19:15 <scanz> at first i need a scanner, later a parser
04:19:27 <ksf> what you need is parsec.
04:19:34 <EvilTerran> p_l, ouch :(
04:19:40 <scanz> but the replacement of Idfs wont work
04:21:11 <scanz> int ball_size = 10; <= after scan this should look like  => Int Idf Equal Number;
04:21:18 <ksf> believe me, you really, really want to use parsec, do an ast and everything and work on that.
04:21:41 <scanz> what is parsec?
04:21:47 <scanz> sorry, but i am a newbie ;)
04:22:01 <ksf> http://www.haskell.org/haskellwiki/Parsec
04:22:04 <lambdabot> Title: Parsec - HaskellWiki
04:22:50 <scanz> can you give me an example in my source code?
04:23:16 <ksf> i can give you an example of a parser using layout rules.
04:23:55 <EvilTerran> this seems like it's entirely lexing, though
04:24:04 <scanz> yeah
04:24:17 <ksf> parsec basically enables you to match on any structure and return any kind of thing you can interpret out of it.
04:25:14 * EvilTerran has written a lexer using ReadP (another of the parsing libraries that comes with ghc), if you're interested, scanz?
04:27:06 <Peaker> p_l: I don't think I've had to "recover" a document from some fault in the last 10 years. In any case, such recoverability merely speaks of using open/readable formats, and not of using textual serialization.  A binary serialization that has standard readers can also work (it merely requires the lowest layers not to corrupt the data format itself, but that is true of text as well)
04:28:20 <p_l> anyway, for most of the data (not everything, but most of the stuff that ends up in files, not in storages like database or something), I prefer formats I can edit with ed. Saved me many times.
04:28:32 <p_l> afk - coffee & snacks time
04:30:38 <EvilTerran> scanz, have a look at http://hpaste.org/12464
04:31:39 <EvilTerran> scanz, the documentation for ReadP is at http://www.haskell.org/ghc/docs/latest/html/libraries/base/Text-ParserCombinators-ReadP.html , btw
04:31:40 <lambdabot> Title: Text.ParserCombinators.ReadP, http://tinyurl.com/uo5wd
04:32:18 <scanz> i don't understand parsec.. i only need a string buffer, where i can save chars until i read for example a '\n' char, then i want to return this string in this buffer as a Idf String. What ca I use for this?
04:32:29 <scanz> Thanks EvilTerran i will have a look
04:33:22 <ksf> parsec looks like this (mathing on a token stream in this case): http://hpaste.org/12465
04:33:31 <ksf> let me know if you want to see the whole thing.
04:33:34 <EvilTerran> it occurs to me now that "tokens = skipSpaces >> (token `endBy` skipSpaces)
04:33:34 <EvilTerran> " would also work as a definition of "tokens"
04:33:53 <vixey> ksf, 'Lambda [String] Expr' is gonna bite you hard
04:34:21 <ksf> it works for what it's currently is.
04:34:33 <ksf> a layout-syntax to sexpr converter.
04:37:49 <ksf> do{ s <- manyTill '\n' char; return $ Ids s}
04:37:59 <ksf> :t manyTill
04:38:00 <lambdabot> Not in scope: `manyTill'
04:38:12 <ksf> modulo the type of manyTill, don't know it by hard.
04:38:31 <vixey> ksf, puzzle if you're bored: http://moonpatio.com:8080/fastcgi/hpaste.fcgi/view?id=379#a381
04:43:36 <Peaker> hmm, the syntax highlighter is broken by the "--" not being a separate token
04:43:57 <Peaker> (--> starts a comment)
04:44:32 <myname> thx ivan, the java problem is solved
04:47:59 <gio123> does somebody know list with ranks all usa math departments?
04:48:55 <monadwr> has anyone looked through the haskell state preprocessor?
04:49:23 <monadwr> i'm wondering how monadic if/case constructs are implemented with them
04:51:53 <quicksilver> HCAR++
04:54:19 <delYsid> Anyone remember this webproject where you could execute code?
04:54:28 <delYsid> I remember it supported haskell and C, and some others.
04:54:47 <vixey> @undo do x <- 1 ; if x == 3 then return () else fail "foo"
04:54:48 <lambdabot> 1 >>= \ x -> if x == 3 then return () else fail "foo"
05:03:55 <nohluhtC> delYsid: Codepad.org?
05:04:14 <Cthulhon> It only had Hugs, though.
05:05:29 <quicksilver> wow : http://www.informatik.uni-kiel.de/prog/mitarbeiter/fabian-reck/projekte/chd
05:05:36 <lambdabot> Title: Programmiersprachen und �bersetzerkonstruktion: CHD, http://tinyurl.com/6ysqbv
05:06:14 <ksf> omg uebersetzerkonstruktion
05:06:36 <EvilTerran> ... concurrent debugger? i thought that was meant to be zomgdifficult
05:07:08 <quicksilver> well, it is. and it only does some simple cases as far as I can
05:07:13 <quicksilver> however it is stil extremely cool
05:07:15 <EvilTerran> i guess it's a lot easier with some of haskell's high-level concurrency primatives, too
05:11:30 <BeelsebobWork> EvilTerran: it's dead easy... as long as you happen to use tracing rather than debugging directly
05:11:45 <BeelsebobWork> it's no harder than a non-concurrent one in fact
05:12:34 <BeelsebobWork> quicksilver: http://www.cs.kent.ac.uk/people/rpg/tatd2/Hsark.png <-- nearly there, just filtering to add, and the c.h.o project to wait on
05:13:25 <quicksilver> nice.
05:13:44 <BeelsebobWork> oh, and ofc figuring out why it crashes in the release build >.<
05:16:41 <necroforest> In haskell, can you have a type constructor that takes a value as  a parameter, not just a type ?
05:17:10 <vixey> necroforest, no, types and values are segregated
05:17:21 <necroforest> an example would be if you wanted to encode the ring Zn, you could have a constructor that took the n
05:17:44 <necroforest> Hmm
05:17:55 <vixey> you can do a type level encoding of 'n'
05:18:31 <vixey> data Zero ; data Succ x ; ... now  Succ (Succ (Succ Zero)) is a type   (but so is Succ String)
05:20:23 <quicksilver> HCAR++ (again)
05:20:56 <quicksilver> you can use GADTs to get a value-level rep and type-level rep mirroring each other.
05:21:24 <quicksilver> Z :: Nat Zero; S Z :: Nat (Succ Zero)
05:21:25 <quicksilver> etc
05:22:43 <necroforest> eh... that looks like a hack
05:23:27 <vixey> @quote tightrope
05:23:28 <lambdabot> mmorrow says: in langs with dependent types, you can just map numbers directly to types instead of having to ride a unicycle along a tightrope while battling an unruly gang of monkey with knives
05:23:44 <quicksilver> necroforest: yup, it's a hack.
05:23:51 <quicksilver> necroforest: haskell is not a dependently typed language :)
05:24:10 <quicksilver> although GADTs and type classes supply the tightrope and the monkeys.
05:24:16 <quicksilver> you have to bring your own unicycle.
05:25:53 <arw> btw is there a way to define constrained types? like "Angle is a Float between 0 and 6.28" or "Odd is an Integer x where (odd x) is true"?
05:26:05 <arnfred> where do cabal install programs to?
05:26:16 <arnfred> i can't seem to find a bin dir in ~/.cabal
05:27:07 <dcoutts> arnfred: by default, programs get installed to ~/.cabal/bin and libs to ~/.cabal/lib
05:27:09 <arnfred> and they aren't in my path either
05:27:32 <dcoutts> arnfred: no, ~/.cabal/bin would not be on your path, you'd have to change your path
05:27:53 <arnfred> and lib as well, I guess?
05:28:08 <dcoutts> arnfred: there's no problem with libs
05:28:14 <quicksilver> arw: using abstraction and smart constructors
05:28:36 <arnfred> but when I try to install yi, it complaints about depending on programs I've just installed with cabal
05:28:46 <arnfred> or libraries, that is
05:29:08 <dcoutts> arnfred: are you installing yi using "cabal" or  "runghc Setup" ?
05:29:25 <dcoutts> if the latter then you want to configure with the --user flag
05:29:35 <dcoutts> or just use the cabal program
05:29:44 <vixey> arw, no
05:30:11 <arnfred> I'm not using cabal to install yi, because I want to have the most current source code
05:30:25 <gio123> I need to collect 5 weakest math deps in usa, can somebody help me :)?
05:30:27 <arnfred> so I'm using runhaskell to install
05:30:38 <arnfred> I'll try runhaskell --user
05:30:38 <dcoutts> arnfred: that's no problem. You can use the cabal program there too.
05:30:46 <dcoutts> arnfred: cabal configure; cabal build
05:31:15 <arw> quicksilver, vixey: so i guess your answers in combination would mean "yes, if you reimplement all operators for those subtypes", right?
05:31:22 <dcoutts> arnfred: the cabal program should be a complete replacement for the runghc Setup command line interface
05:31:34 <arnfred> oh, neat!
05:31:53 <quicksilver> arw: yes, for abstract types you have to implement all the operators, although it's often not very hard
05:32:02 <vixey> arw, I just mean, you can't reflect computational properties into the type system with HM
05:32:18 <arnfred> dcoutts, thanks a lot for your help
05:32:21 <quicksilver> instance Num T where (T a) + (T b) = (a + b) `mod` 7
05:32:29 <dcoutts> arnfred: np
05:33:32 <arw> quicksilver, vixey: okay, thanks
05:36:10 <arnfred> is there any way I can make cabal install the newest package of parsec?
05:36:18 <arnfred> it's installing 2.x while I want 3.0
05:36:37 <arnfred> or will I have to do that manually?
05:36:40 <dcoutts> arnfred: cabal install 'parsec >= 3'
05:36:47 <dcoutts> arnfred: the default version is 2.x
05:37:14 <arnfred> damn, there's nothing this program wont do...
05:37:22 <arnfred> thanks again dcoutts
05:38:00 <Peaker> cabal make-me-some-pie
05:38:21 <Raevel> @faq can haskell make me some pie?
05:38:21 <lambdabot> The answer is: Yes! Haskell can do that.
05:38:25 <vixey> so anyone read that PEG parser paper?
05:38:39 <vixey> I'm not sure the proof technique they use is good..
05:39:01 <dcoutts> Peaker: hmm, try cabal install some-pie --reinstall
05:39:20 <vixey> they use induction of step counts, so that covers step counts 1, 2, 3, ... infinity, but it doesn't cover infinite computations -- and termination of the evaluation isn't guarenteed
05:39:39 <Peaker> dcoutts: Yummy! :-)
05:40:05 <vixey> so.. is this actually a good proof technique or not? I don't really see why it can be acceptable
05:40:46 <Fallen_Demon> Does anyone know how to catch an overflow error?
05:41:33 <osfameron> an overflow net?
05:41:54 <Fallen_Demon> Integer overflow
05:42:20 <necroforest> sorry, this channel is only for Catch & Release overflow errors
05:42:44 <Fallen_Demon> I'm googling it now, but I'm not turning up anything useful...
05:42:44 <arnfred> I have a peculiar problem:
05:43:24 <arnfred> Warning: This package indirectly depends on multiple versions of the same package. This is highly likely to cause a compile failure.   package regex-tdfa-0.95.2 requires parsec-2.1.0.1   package yi-0.5.1 requires parsec-3.0.0
05:43:34 <arnfred> can cabal solve this for me?
05:43:53 <dcoutts> arnfred: sometimes, try cabal install --dry-run
05:44:07 <dcoutts> it'll tell you what it'd install/reinstall to make it consitent
05:44:35 <dcoutts> on the other hand it may be impossible to make it consistent, and it may build ok anyway
05:46:34 <arnfred> dcoutts, thanks. It seemed to solve the problem, only to reveal a new one. This is turning into a longer quest than I imagined
05:47:08 <BeelsebobWork> GAH! Why am I writing C?
05:47:23 <quicksilver> BeelsebobWork: because HoC isn't good enough?
05:47:23 <lilac> BeelsebobWork: you believed it would be easier than fixing Hoc?
05:47:34 <Peaker> @where hoc
05:47:35 <lambdabot> http://hoc.sourceforge.net/
05:47:54 <BeelsebobWork> well, the problem now is... it appears the Obj-C 2 garbage collector is collecting my root object >.<
05:48:19 <vixey> oh well .. it's a valid proof technique for _terminating_ computations and since they are the only ones that matter..=
05:50:44 <Axman6> BeelsebobWork: report it to Apple
05:51:01 <BeelsebobWork> Axman6: yeh, I'm not yet convinced it's not my bug
05:51:13 <ksf> I just noticed that waaaay back, when I was staring at the BASIC screen only armed with a reference and no idea of programming, I used to reason about control flow in terms of continuations.
05:51:16 <Axman6> fair enough
05:51:20 <dcoutts> Fallen_Demon: so Int is a machine integer, like 32bit
05:51:33 <Fallen_Demon> Go on
05:51:38 <dcoutts> Fallen_Demon: so it overflows when you get a bigger number than 32bits can hold.
05:51:49 <vixey> ksf, makes sense, that's what control *is*
05:51:49 <Fallen_Demon> Yep
05:51:55 <dcoutts> Fallen_Demon: Integer is a "big int", it is only bounded by the size of memory
05:51:58 <ksf> it just didn't work as i had no idea how to return to the call site.
05:52:05 <dcoutts> > 2^(2^10) :: Integer
05:52:07 <lambdabot>   179769313486231590772930519078902473361797697894230657273430081157732675805...
05:52:07 <ksf> ...at least in the general case.
05:52:08 <Fallen_Demon> Oh, So like the python mechanism?
05:52:12 <dcoutts> Fallen_Demon: yep
05:52:21 <Fallen_Demon> Ok, thanks :)
05:53:12 <Peaker> the Python mechanism is basically only Integer (Python longs).  It does use ints (Haskell Ints) but that's an implementation detail because they overflow into Integer automatically
05:53:32 <quicksilver> the haskell Integer has a special case for small numbers, too
05:53:39 <quicksilver> so actually it's a very similar design.
05:53:56 <Axman6> quicksilver: small numbers being Int sized?
05:54:06 <quicksilver> @src Integer
05:54:07 <lambdabot> data Integer = S# Int#
05:54:07 <lambdabot>              | J# Int# ByteArray#
05:54:10 <quicksilver> yeah.
05:54:14 <Axman6> i see
05:54:17 <Axman6> interesting
05:54:21 <ksandstr> just curious -- what exactly is Integer's special case for small numbers? just one 32/64-bit limb? that'd not be at all special though
05:54:31 <Axman6> @src Int
05:54:31 <lambdabot> data Int = I# Int#
05:54:33 <quicksilver> ksandstr: an unboxed Int.
05:54:36 <Axman6> @src Int#
05:54:36 <lambdabot> Source not found. I've seen penguins that can type better than that.
05:54:50 <quicksilver> ksandstr: exactly the same rep as Int; not a gmp limb.
05:55:12 <Axman6> whats the Int# in the J# constructor for?
05:55:18 <ksf> Axman6, lambdabot won't undress and show you her circuits. She's a /nice/ girl.
05:55:24 <quicksilver> the length of the ByteArray#
05:55:30 <quicksilver> I believe.
05:55:31 <Axman6> thought so
05:55:36 <quicksilver> or the number of limbs in it, perhaps.
05:55:50 <Axman6> @src ByteArray
05:55:50 <lambdabot> Source not found. You type like i drive.
05:56:06 <quicksilver> you can't ask for the src of #-types
05:56:09 <quicksilver> that's meaningless.
05:56:12 <quicksilver> They just are.
05:56:16 <Fallen_Demon> dcoutts, thanks heaps, the idiots on the channel my bot was sitting on thought it was funny to keep crashing it
05:56:16 <quicksilver> Like giraffes.
05:56:19 <ksandstr> quicksilver: ah, ok. I guess that's worth it from a "not dereferencing another pointer" perspective
05:56:37 <quicksilver> ksandstr: and "not calling slow gmp routines when you can use an assembly ADD"
05:56:39 <luite_> @src Giraffe
05:56:40 <lambdabot> Source not found. Just what do you think you're doing Dave?
05:56:44 <luite_> hm, you seem to be right ;)
05:57:19 <Peaker> quicksilver (the program) is pretty cool (as Gnome do is pretty cool)
05:57:34 <Peaker> (quicksilver the person is also cool, if anything else was implied :-)
05:57:40 <quicksilver> i was here the first, too.
05:57:47 <dcoutts> Fallen_Demon: ah, you have a Haskell bot doing integer arithmetic? Well the next thing to watch out for is doing very large Integer calculations that take a long time and a lot of memory.
05:57:54 <Peaker> quicksilver: ah, I thought you nicked yourself based on the program everyone seems to love
05:58:02 <quicksilver> hell no.
05:58:13 <quicksilver> I've had this nickname before that program was even a glint in someone's eye
05:58:15 <dcoutts> Fallen_Demon: lambdabot uses a process mechanism to limit the cpu time and memory of requests from potentially malicious users.
05:58:17 <Peaker> where did your nick originate then?
05:58:20 <quicksilver> or indeed the operating system it runs on.
05:58:38 <ksf> Fallen_Demon, try mueval.
05:58:48 <ksf> saves you a lot of work.
05:58:56 <Fallen_Demon> dcoutts, it's a small channel, so it shouldn't get hammered to badly
05:59:20 <Fallen_Demon> @src mueval
05:59:20 <lambdabot> Source not found.
05:59:40 <ksf> cabal install mueval you want to type
05:59:52 <Peaker> quicksilver is like a pretty good interactive subset of hoogle, as it lets you incrementally search within the correctly typed argument space of actions
05:59:55 <ksf> it uses the source.
06:00:08 <ksf> so mueval with you will be
06:00:49 <Fallen_Demon> ksf, yeah,  wrote my own from scratch just to have a play with parsing... I'll look into it :)
06:00:54 * ksf train his joda mode has to
06:03:45 <ttt--> mueval doesn't compile yet on 6.10.1, i think
06:06:16 <ttt--> src/Hint/Parsers.hs:7:21: Module `GHC' does not export `Session'
06:06:48 <lilac> ttt--: yeah, that's pretty involved to fix
06:11:25 <scanz> cya
06:29:51 <Asgaroth> I'm trying to write a plugin for xmobar which uses Network.MPD, but it keeps complaining about libmpd being hidden although this is not the case, when I check with ghc-pkg list. How do I expose this package to xmobar?
06:31:19 <quicksilver> mark it as a dependency in your .cabal
06:32:30 <Asgaroth> quicksilver: Thanks, it works.
06:40:20 <shapr> Asgaroth: Where is network.mpd?
06:41:32 <shapr> oh libmpd
06:49:27 <monadwr> :t head
06:49:28 <lambdabot> forall a. [a] -> a
06:55:24 <angie^> kinda a noob
06:55:27 <angie^> can someone help pls
06:55:31 <loriel> Hi
06:55:39 <shapr> hiya angie^
06:55:42 <shapr> hiya loriel
06:55:53 <angie^> like with a function i want to make: say -- let abc = abc :: (Num a) => a -> String
06:55:54 <angie^> doesnt work
06:56:14 <monadwr> Doesn't work ...
06:56:18 <shapr> Are you writing in ghc interactive?
06:56:22 <angie^> ya, like i get errors
06:56:23 <angie^> ya shapr
06:56:38 <angie^> feel really stupid lol
06:56:56 <shapr> New things are confusing :-)
06:57:06 <angie^> lol
06:57:19 <shapr> Hold on, I'm trying it on my local ghci
06:57:26 <shapr> I know how to do it, I just want to get it right...
06:57:37 <angie^> uhm k
06:57:41 <Axman6> angie^: what are you trying to do?
06:57:53 <angie^> Axman6, make my own functions lol
06:57:56 <angie^> like
06:57:57 <angie^> let faktor = faktor :: (Num a) => a -> a
06:57:57 <angie^> <interactive>:1:13:
06:57:57 <angie^>     Inferred type is less polymorphic than expected
06:57:57 <angie^>       Quantified type variable `a' is mentioned in the environment:
06:57:57 <angie^>         faktor :: a -> a (bound at <interactive>:1:4)
06:58:00 <angie^>     In the expression: faktor :: (Num a) => a -> a
06:58:02 <angie^>     In the definition of `faktor': faktor = faktor :: (Num a) => a -> a
06:58:07 <angie^> :\
06:58:08 <Peaker> angie^: please paste at hpaste.org
06:58:12 <angie^> k
06:58:21 <angie^> Axman6, so
06:58:22 <Peaker> angie^: why are you defining an infinitely recursive function?
06:58:24 <shapr> > let faktor a = a / 2 in faktor 4
06:58:25 <lambdabot>   2.0
06:58:29 <angie^> im trying to make a factorial function
06:58:33 <shapr> oh
06:58:34 <Axman6> angie^: f = f :: c -> b doesn;t make any sense
06:58:36 <angie^> with uhm the type class thingy
06:58:53 <angie^> > :t faktor
06:58:54 <shapr> angie^: You don't need to describe the typeclass part most of the time.
06:58:54 <lambdabot>   <no location info>: parse error on input `:'
06:58:59 <angie^> :t faktor
06:59:01 <lambdabot> Not in scope: `faktor'
06:59:04 <angie^> uhh
06:59:10 <angie^> shapr, o
06:59:18 <angie^> i thought i needed to _all the time_
06:59:21 <Axman6> lambdabot isn't ghci, but acts a little like it
06:59:25 <angie^> o
06:59:25 <angie^> k
06:59:27 <shapr> angie^: It was a local definition, it disappeared when that line was done.
06:59:29 <Axman6> angie^: no
06:59:41 <shapr> GHC can guess the type 99.99% of the time.
06:59:46 <Axman6> :t let factor a = a / 2 in factor
06:59:48 <lambdabot> forall a. (Fractional a) => a -> a
06:59:54 <angie^> mmm k
07:00:02 <angie^> this lyah book is kinda ugh
07:00:04 <angie^> well thanks everyone
07:00:12 <shapr> bah
07:00:23 <shapr> I was going to suggest the free edition of RWH!
07:00:34 <Axman6> urgh
07:00:38 <Peaker> lyah starts out great. I didn't read a lot of it though
07:00:59 <monadwr> shapr: Have they gotten around to the pdf ver yet?
07:01:07 <shapr> You can order it online.
07:01:14 <shapr> from ora.com
07:01:20 <shapr> There's also a script that will build a pdf for you.
07:01:47 <monadwr> A script
07:01:54 <BeelsebobWork> gah, thank god for #haskell being a friendly channel -- the contents of #macdev are a bunch of twats >.<
07:02:14 <quicksilver> compared to #haskell, most places are.
07:02:26 <Axman6> #macdev more so though
07:02:26 <BeelsebobWork> yeh
07:02:39 <Axman6> there's a reason BeelsebobWork and I started a new mac development channel
07:03:04 <shapr> You're basing it on the social values of #haskell? :-)
07:03:04 <Axman6> speaking of which, anyone with a mac should come and join us in #macosxdev
07:03:14 <monadwr> I should fix that macbook sometime.
07:03:15 <BeelsebobWork> I asked about marking items as root objects in #macdev -- got the response "yes, you have to jump through hoops, yes I know what hoop you need to jump through, no I'm not going to tell you because I don't think you should use garbage collection"
07:03:19 <BeelsebobWork> >.<
07:03:23 <shapr> I acquired a macbook pro recently.
07:03:24 <monadwr> Axman6: Seems rather long to type.
07:03:33 <monadwr> shapr: new era?
07:03:37 <shapr> It's a g4
07:03:41 <Axman6> monadwr: what, #macosxdev?
07:03:43 <shapr> old era
07:03:50 <monadwr> Axman6: Yes
07:03:52 <BeelsebobWork> shapr: oh, a Powerbook then, not an MBP?
07:03:57 <shapr> oh is that it?
07:04:00 <Axman6> yes
07:04:02 <monadwr> shapr: That's about three-era's old.
07:04:06 <shapr> hah
07:04:07 <Axman6> should say powerbook on it
07:04:11 <BeelsebobWork> MBPs are all intel
07:04:13 <shapr> I'll go get it...
07:04:15 <BeelsebobWork> powerbooks are not
07:04:20 <monadwr> PPC afaik
07:04:27 <Axman6> yes
07:04:29 <BeelsebobWork> indeed
07:04:36 <monadwr> It's a wonder why they made the shift.
07:04:45 <BeelsebobWork> it is?
07:04:52 <Axman6> not really, IBM wouldn't deliver
07:04:57 <BeelsebobWork> the Core architecture was massively faster than the G4/G5
07:05:01 <BeelsebobWork> and the G5 was enormously hot
07:05:06 <BeelsebobWork> and couldn't go in laptops at all
07:05:11 <monadwr> Were the G4/G5 PPC-64 ?
07:05:18 <BeelsebobWork> no, only the G5
07:05:19 <Axman6> G5's were
07:05:23 <monadwr> Ah.
07:05:30 <quicksilver> even then, they weren't running in full 64bit mode
07:05:31 <quicksilver> AIUI.
07:05:34 <BeelsebobWork> the G5 was essentially an IBM Power4 with chunks taken off
07:05:36 <quicksilver> (just like my atholong doesn't)
07:05:40 <shapr> Yeah, it's a powerbook G4
07:05:42 <BeelsebobWork> so it was *really* hot
07:05:46 <Axman6> meaning we've owned a 64-bit machine since 2005 i think
07:05:59 <monadwr> Axman6: You're a pioneer.
07:06:01 <Axman6> no, must be before then
07:06:12 <Axman6> BeelsebobWork: know when the G5 iMacs came out?
07:06:20 <shapr> I wonder why they didn't use POWER chips?
07:06:21 <BeelsebobWork> 03 IIRC
07:06:30 <Axman6> well, since then
07:06:31 <BeelsebobWork> shapr: because they're enormous and very very hot
07:06:34 <shapr> hola araujo!
07:06:39 <shapr> BeelsebobWork: Oh.
07:06:47 * shapr throws sugar lambdas at araujo 
07:06:54 <BeelsebobWork> shapr: the G5 was a POWER4 with large chunks stripped off it
07:07:02 <BeelsebobWork> and it was *still* too hot
07:07:07 <monadwr> I should stop running this ubuntu.
07:07:10 <Axman6> BeelsebobWork: what do you reckon they'll do with P.A. semi?
07:07:11 <shapr> Oh I see. Is there a family tree somewhere? I wonder where the Cell fits into it.
07:07:29 <maxote> the ppc architecture is going to dead end, its popularity is a fallacy
07:07:34 <BeelsebobWork> shapr: the Cell is roughly a G3 with 8 of the G4's AltiVec units attached to it's arse
07:07:36 <Axman6> shapr: i believe i heard ages ago that sony reckoned they could get OS X running on the Cell
07:07:36 <monadwr> It's a small wonder why ghc in apt is still in 6.8
07:07:48 <Axman6> monadwr: the military use it a lot
07:07:50 <shapr> That would be nifty.
07:07:59 * araujo jumps and catches the sugar lambda 
07:08:04 <monadwr> Axman6: The military uses ghc 6.8 ?
07:08:05 <araujo> shapr, Hola!
07:08:07 <araujo> :-)
07:08:11 <shapr> como est as?
07:08:23 <daf> maxote: except for the millions of Xbox 360s, playstations and wiis that have ppcs, you mean
07:08:23 <Axman6> s/monadwr/maxote
07:08:25 <BeelsebobWork> maxote: really? All Playstations, XBoxes and Wiis is not popular?
07:08:27 <araujo> shapr, todo bien , y tu?
07:08:28 <Botje> are people throwing around sugar lambdas again? :D
07:08:35 <Axman6> daf: ha. yes, good point
07:08:40 <shapr> bien, obrigado
07:08:42 <maxote> daf, these consoles are crap
07:08:44 <daf> BeelsebobWork: o/\o
07:08:49 * shapr teases araujo by switching to portuguese halfway!
07:08:50 <maxote> they are not computers
07:08:50 <BeelsebobWork> daf: indeed
07:08:51 <araujo> Botje, always :-)
07:09:01 <araujo> shapr, haha
07:09:01 <maxote> i wanted a computer!
07:09:04 <Axman6> the PS3 is a pretty damn impressive machine
07:09:09 <BeelsebobWork> maxote: so BlueGene/L is not a computer?
07:09:26 <shapr> My PS3 is better than yours.
07:09:29 <Ferdirand> we have a PS3 cluster, it's working great
07:09:32 <monadwr> tanto quanto eu sei que o #haskell é um de língua inglesa canalize:)
07:09:44 <BeelsebobWork> actually, Roadrunner is Cell based too
07:09:45 <shapr> I have a Cell cluster too.
07:09:51 <shapr> But it's in an IBM BladeCenter.
07:09:52 <myname_> anyone using xmonad?
07:09:55 <shapr> ooh me me!
07:09:59 <maxote> i wanted a computer in home!
07:10:03 <shapr> Ferdirand: What do you do with your cell cluster?
07:10:06 <myname_> I am running xmonad on ubuntu and sometimes I see  that keyboard gets unresponsive
07:10:09 <shapr> maxote: My bladecenter is in my living room.
07:10:27 <Axman6> shapr: i keep mine in the kitchen
07:10:32 <shapr> smart
07:10:41 <Axman6> though we call them knife blocks here in aus
07:10:42 <Axman6> >_>
07:10:44 <shapr> haha
07:10:54 <Axman6> i
07:10:58 <shapr> I really do have a Cell cluster in my living room though: http://picasaweb.google.com/shae.erisson/BladeCenterEChassisArrives
07:10:59 <Axman6> i'll be here all week
07:11:00 <lambdabot> Title: Picasa Web Albums - shapr - BladeCenter E..., http://tinyurl.com/6xr3dm
07:11:08 <Ferdirand> shapr: various hash collisions, factoring
07:11:26 <shapr> Ferdirand: Ah, nifty. Got any interesting Haskell code tuned for the Cell?
07:11:27 <maltem> myname_: I'd recommend #xmonad, there are friendly people there too ;-)
07:11:52 <Ferdirand> shapr: i wish i had :)
07:11:59 <monadwr> shapr: Did you give the UPS guy a sixpack?
07:12:01 <shapr> Ferdirand: It's sort of hard to carry.
07:12:08 <shapr> monadwr: Nah, I don't drink beer.
07:12:14 <maxote> who have a ppc computer in home? nobody ...
07:12:22 <Axman6> i do
07:12:23 <monadwr> shapr: What ?
07:12:26 <Ferdirand> i do too
07:12:27 <Axman6> i have about 4 actually
07:12:50 <shapr> I do
07:13:05 <Axman6> iMac G3, iMac G5, powerbook 5300c (hahaha... aww) and a powermac 6400 or somethign
07:13:15 <quicksilver> maxote: I do.
07:13:18 <shapr> I think the point about xbox360, wii, and ps3 all using PowerPC is important.
07:13:36 <monadwr> shapr: Probably a valid remark
07:13:44 <monadwr> I should get that ps3.
07:14:14 <monadwr> The only game console I ever owned was the first nintendo/gameboy.
07:14:19 <shapr> All the current consoles and many of the recent consoles use PPC, it won't die soon.
07:14:27 <shapr> The GameCube used PPC
07:14:43 <maxote> if my prevision at 2009-2019 says me that not ppc computer will be in my home then i will do rm -fr *ppc* from my hard disk
07:14:51 <monadwr> Dreamcast used ppc as well, afaik
07:15:12 <monadwr> maxote: What?
07:15:23 <sbahra> Dreamcast doesn't use PPC
07:15:24 <shapr> maxote: The PS3 is okay, its only downside is the lack of memory.
07:15:25 <monadwr> 'i will do rm -fr *ppc* from my hard disk
07:15:26 <sbahra> It uses SH4
07:15:30 <Deewiant> monadwr: nope, it was some weird RISC CPU
07:15:35 <sbahra> Which is MIPS derived, iirc
07:15:38 <shapr> And lack of access to the NVidia graphics chip from Linux.
07:15:38 <Deewiant> SH4 sounds right
07:15:39 <Axman6> i know the millitary were a little edgy when Apple bought P.A. Semi because they use their PPC chips in things like missiles
07:15:40 <monadwr> Ah
07:15:41 <maxote> shapr, the downsides is part of their problems
07:15:45 <monadwr> sbahra: Ah, ok
07:16:29 <shapr> maxote: I agree with you, there aren't any good options for a Cell desktop.
07:16:56 <monadwr> Most symbian OS devices use MIPS as well ?
07:17:03 <monadwr> Nokia smartphones.
07:17:04 <maxote> then i will have my PC desktop clean from *ppc* contamination
07:17:13 <shapr> I wish the Cell had memory slots and cpu sockets.
07:17:40 <maxote> for me, now, *ppc* is a smoking thing
07:18:03 <Axman6> PPC is an excellent architecture
07:18:10 <BeelsebobWork> shapr: unfortunately on the PS3, you don't even get access to the SPUs from linux
07:18:18 <shapr> BeelsebobWork: You do.
07:18:20 <Ferdirand> BeelsebobWork: you do
07:18:24 <BeelsebobWork> really?
07:18:29 <shapr> You get access to six of them, with the hypervisor running on the seventh.
07:18:30 <Ferdirand> there even is a scheduler now I think
07:18:33 <BeelsebobWork> ah, oay
07:18:35 <BeelsebobWork> okay*
07:18:35 <luite_> hm, I thought there was some toshiba laptop with a cell?
07:18:42 <Ferdirand> and an ELF loader too
07:18:47 <thoughtpolice> generally speaking isn't PPC code much larger than x86 code? that can have a major effect on cache
07:18:48 <BeelsebobWork> there is -- you get a Core2Quad and an 8 core cell
07:18:51 <BeelsebobWork> which isn't bad at all
07:19:03 <BeelsebobWork> thoughtpolice: yes, but also PPC chips are smaller than intel ones
07:19:08 <BeelsebobWork> so the cache can take up more space
07:19:18 <monadwr> PPC code is much larger than 80x86 code?
07:19:19 <shapr> luite_: It only hase four of the SPEs.
07:19:21 <thoughtpolice> BeelsebobWork: yeah, there's an IBM article about cell programming and using a gcc-variant for compiling stuff onto the SPU
07:19:28 <maxote> i had an old question much time ago, why is not there "Cell Desktop"?
07:19:32 <shapr> luite_: I think it's the Quosimo or something.
07:19:45 <Axman6> maxote: because there's no OS to run on it really
07:19:46 <shapr> maxote: Because XDR memory is *expensive* and only recently have Cell systems started using DDR2.
07:19:48 <thoughtpolice> BeelsebobWork: but like shapr said it really sucks that when you use linux you're on a hypervisor restricted from the graphics card
07:19:49 <Axman6> nothing viable anyway
07:19:57 <thoughtpolice> but afaik, that's really the only thing you're restricted from
07:20:13 <BeelsebobWork> thoughtpolice: that does indeed suck -- I'm surprised no one has hacked it on yet
07:20:21 <monadwr> I've never owned a ppc
07:20:37 <maxote> until now, there were many Cell falacies that people didn't understand them
07:20:45 <maxote>  /falacies/fallacies
07:20:54 <thoughtpolice> the cell is a pretty exotic piece of SIMD hardware
07:21:00 <thoughtpolice> it's not exactly a perfect fit for a desktop
07:21:09 <Axman6> yeah
07:21:10 <thoughtpolice> in those toshiba laptops, the cell processor is only restricted to graphics work
07:21:14 <thoughtpolice> you can't run whatever you want on there
07:21:20 <shapr> You probably can...
07:21:31 <shapr> but the SPEs are tuned towards SIMD work.
07:21:58 <luite_> simd is not a problem, but it would get ugly if you have to access them through a graphics (opengl or dx?) layer
07:22:02 <Axman6> which... is where haskell's going, yay
07:22:25 <shapr> Axman6: Where, simd?
07:22:45 <Axman6> well, parallel stuff i guess
07:22:59 <Axman6> but, DPH is sort of along those lines right?
07:23:05 <shapr> I have six blades for my bladecenter that each have two Cell cores, and 1GB of XDR.
07:23:07 <BeelsebobWork> luite_: OpenCL to the rescue!
07:23:11 <thoughtpolice> i think haskell and the cell would be an excellent match together, in the sense of using haskell to generate code for the cell
07:23:12 <shapr> They will soon be available for Haskell development :-)
07:23:13 <thoughtpolice> :]
07:23:38 <thoughtpolice> like the Coconut project; they use haskell to generate fast SIMD code for cell processors
07:23:46 <shapr> Yeah Coconut is *really* awesome.
07:23:50 <thoughtpolice> according to their benchmarks, their code is regularly faster than optimized C code
07:23:54 <shapr> Anand's work is amazing.
07:24:12 <thoughtpolice> shapr: ooo, do you think I could get a shell on a fancy 'puter like that? :]
07:24:19 <shapr> It makes sense, principle single pass optimization is a great thing.
07:24:23 <Axman6> any relation to Anandtech?
07:24:35 <thoughtpolice> shapr: I've been wanting to play with a cell for a while, and I've had many thoughts about using haskell for making it easier to program
07:24:40 <maxote> my conclusion will be that if there are not Cell Desktops or Cell Laptops in the 2009-20019 roadmap then i will do rm -fr *ppc* now
07:24:46 <shapr> thoughtpolice: If you promise to write cool Haskell code using this computer, and you promise to release your cool code under some sort of open source license, then YES.
07:24:58 <Botje> maxote: what are people going to do with that many cores?
07:25:00 <thoughtpolice> shapr: well, duh. :)
07:25:05 <Axman6> maxote: you honestly don't know what you're talking about
07:25:18 <shapr> Axman6: Well, his choice :-)
07:25:20 <Botje> multi-core desk/laptops are already a stretch as it is
07:25:22 <Axman6> there's far more to the CPU world than desktops
07:25:27 <shapr> Botje: How so?
07:25:34 <monadwr> Hmm.
07:25:34 <thoughtpolice> like I said the cell isn't exactly a good fit for a desktop anyway
07:25:39 <Botje> what's grandma going to do with a quadcore?
07:25:49 <shapr> thoughtpolice: I don't agree with you yet, but I haven't investigated it enough.
07:25:53 <BeelsebobWork> Botje: what's grandma going to do with anything better than a Pentium II?
07:25:57 <shapr> Botje: I think the limitation is the existing software.
07:26:02 <thoughtpolice> Botje: play fucking unreal tournament 3
07:26:02 <thoughtpolice> duh
07:26:04 <Botje> BeelsebobWork: watch youtube, of course :P
07:26:17 <shapr> Grandma could do video editing, and that would work for her.
07:26:18 <BeelsebobWork> heh, and decoding complex video codecs isn't an easily parallelisable task?
07:26:21 <BeelsebobWork> wait... YES IT IS!
07:26:21 <BeelsebobWork> :P
07:26:21 <shapr> Right
07:26:25 <monadwr> Is Cabal is the ubuntu repositories?
07:26:33 <Botje> monadwr: cabal is installed with ghc
07:26:47 <thoughtpolice> shapr: when you get your box up, we'll settle whether it's a good fit. :)
07:26:50 <Botje> if you mean cabal-install, you can install it with a simple shell script
07:26:55 <dcoutts> monadwr: the Cabal lib is bundled with ghc. The cabal command line tool is separate. You can get it from hackage.
07:27:01 <luite_> BeelsebobWork: but for some reason most of them hardly use more than one core
07:27:08 <shapr> thoughtpolice: I like that plan!
07:27:08 <thoughtpolice> shapr: how expensive is your colo going to be btw? i ran across shae.lj.com yesterday
07:27:19 <shapr> Should be $250 a month or so.
07:27:20 <monadwr> cool
07:27:22 <BeelsebobWork> luite_: oh? you have crappy decoders :(
07:27:22 <thoughtpolice> sounds expensive as hell
07:27:23 <thoughtpolice> oh wow
07:27:29 <quicksilver> luite_: erm?
07:27:30 <thoughtpolice> that's really good
07:27:38 <BeelsebobWork> dcoutts: you have command over \bot, don't you? or is it only Cale that can reconfigure her?
07:27:47 <quicksilver> luite_: the good decoders all use multiple cores now
07:27:51 <dcoutts> BeelsebobWork: not I
07:27:54 <BeelsebobWork> :(
07:27:59 <shapr> thoughtpolice: Yes, it is :-) The biggest difference is that I'll be offering shell accounts, not serving up websites.
07:28:04 <quicksilver> luite_: ffmpeg was slow catching up, but MSes and Apple's proprietary ones have done for ages.
07:28:17 <shapr> The colo I chose gets expensive quickly if you use lots of bandwidth.
07:28:24 <BeelsebobWork> and x264 has always done it quicksilver
07:28:30 <shapr> So that'll be on the login banner "please be nice about bandwidth"
07:28:34 <BeelsebobWork> (and youtube now uses h264)
07:28:34 <thoughtpolice> shapr: nice. if you could let me use irssi (with ssl support) on there, you would be a *god*
07:28:35 <luite_> but x264 is only an encoder?
07:28:41 <BeelsebobWork> nope
07:28:47 <monadwr> dcoutts: I just use the bootstrap.sh
07:28:51 <monadwr> I suppose?
07:28:54 <BeelsebobWork> x264 is a full codec reference implementation for h264
07:28:55 <thoughtpolice> shapr: because I've been using mibbit for about 5 months now and I'm sick of it. screen + ssh is much more my thing.
07:28:56 <dcoutts> monadwr: right
07:29:03 <shapr> I think the biggest problem is that none of our existing software can transparently take advantage of lots of cores.
07:29:20 <quicksilver> BeelsebobWork: ffmpeg's x264 certainly did not always use two cores. I remember vividly when it didn't.
07:29:34 <shapr> thoughtpolice: Sure, that would be fine. No guarantees on uptime or reliability though, I'll be tuning it lots in the coming months.
07:29:35 <BeelsebobWork> quicksilver: oh, wierd -- at least the encoder half has done for *ages*
07:29:42 <BeelsebobWork> been using that in Handbrake for years
07:29:42 <thoughtpolice> shapr: that's cool.
07:30:05 <quicksilver> BeelsebobWork: when apple brought out its first dual core macs, linux people were sad that they couldn't play HD on the same low-spec chips.
07:30:07 <shapr> thoughtpolice: If you want to learn how to admin a bladecenter, you could be backup sysadmin.
07:30:17 <BeelsebobWork> quicksilver: oh, wierd
07:30:19 <luite_> I usually use vlc, how long has that had multithreaded h264 decoding?
07:30:24 <quicksilver> BeelsebobWork: with current ffmpeg you can, more or less. It still consumes more CPU than the quicktime implementation.
07:30:30 <quicksilver> luite_: vlc just uses ffmpeg under the hood
07:30:32 <BeelsebobWork> luite_: same length of time as x264
07:30:35 <thoughtpolice> shapr: hehe, awesome. :)
07:30:42 <BeelsebobWork> because x264 is developed by VideoLan
07:30:45 <quicksilver> but they probably sync library versions periodically rather than constantly.
07:30:59 <BeelsebobWork> quicksilver: VLC is made by the same people as make x264 though
07:31:37 <luite_> I remember not being able to play 1080p h264 without framedrops last year, in vlc, and didn't get 100% cpu usage for both cores
07:31:50 <thoughtpolice> shapr: i would be interested in helping with your bladeserver, if you're going to give out shells you'll need more than just you. and when it's up and we get ghc on there, we'll hack the cell and the fun will begin!
07:31:58 <shapr> Yes!
07:32:28 <BeelsebobWork> I don't get why people can't play 1080p, my little 1.8Ghz MacBook can manage it at only about 70% CPU
07:32:46 <sbahra> shapr, I'm about to pick up a PS3 :-P
07:32:53 <luite_> my new desktop can, but I guess it should be able to decode 1080p on a single core, at 1080p
07:32:54 <shapr> sbahra: Cool, putting yellowdog on it?
07:32:59 <luite_> I mean, at 3.4GHz
07:33:00 <sbahra> Of course.
07:33:13 <monadwr> sbahra: How much do they go for now
07:33:13 <shapr> Spiffy, I wonder if we need #haskell-ps
07:33:22 <sbahra> monadwr, too much :-( ~$400
07:33:24 <shapr> sbahra: ebay has ps3s for cheaper
07:33:40 <sbahra> shapr, I would rather not purchase one that cannot be guaranteed.
07:33:42 <luite_> BeelsebobWork: which program or decoder do you use?
07:33:43 <shapr> I got mine used for $350, but only because I didn't want to wait for shipping from ebay.
07:33:45 <monadwr> I once saw a man sell his soul on eBay.
07:33:51 <BeelsebobWork> luite_: VLC
07:33:55 <Axman6> BeelsebobWork: ew
07:34:00 <shapr> sbahra: I could get one off of ebay and try it out for you :-P
07:34:16 <sbahra> I also want one now :-P
07:34:17 <BeelsebobWork> Axman6: we had this argument already -- you lost, when I revealed VLC was using half the CPU of mPlayer
07:34:21 <shapr> oh
07:34:22 <sbahra> Compulsive purchases are fun.
07:34:31 <Raevel> 350 usd is cheap! i wonder what they go for here
07:34:35 <shapr> Yes they are, until they sit in your living room taking up space!
07:34:40 <sbahra> haha
07:34:42 <monadwr> You have to get the keyboard seperately, I suppose?
07:34:51 <monadwr> I wonder if it comes with one or two pads.
07:35:05 <BeelsebobWork> monadwr: 1
07:35:10 <Raevel> okay, i'd have to pay up 600 usd
07:35:15 <monadwr> Oh
07:35:28 * vixey hugs shapr, transmits freezing coldness
07:35:31 <shapr> I used my kinesis usb keyboard and a usb trackball to get yellow dog linux installed on my ps3, then I unplugged everything and it sits in a corner.
07:35:42 * shapr hugs vixey, transmits lots of heat
07:36:05 <quicksilver> BeelsebobWork: technically x264 is the encoder though?
07:36:17 <monadwr> shapr: So, in essense you own one, just to own one.
07:36:20 <shapr> vixey: You should show up, I keep my apartment warm ;-)
07:36:28 <BeelsebobWork> quicksilver: last I checked it decoded too
07:36:34 <shapr> monadwr: No, I ssh into it to teach myself cell assembly.
07:36:43 <monadwr> Oh, cool
07:36:50 <Axman6> shapr: is it funky?
07:36:52 <shapr> Then I can do dev on my 25" screen
07:37:10 <shapr> Axman6: It's interesting. I understand a lot more about the weird architecture, it's actually a really brilliant idea.
07:37:29 <Axman6> how so?
07:37:45 <Axman6> (== please elaborate because i'm curious)
07:37:57 <Peaker> downloading ftp://ftp.cs.york.ac.uk/pub/haskell/hat/hat-2.06.tar.gz at 460 bytes/sec, nice!
07:37:58 <sbahra> Well, the idea is nothing amazingly new.  The only weird thing is that it is heterogeneous.
07:38:02 <monadwr> what's the rwh pdf script?
07:38:18 <shapr> There aren't any hard numbers on the percentage of CPU powered burned by doing cache coherency, but the Cell completely skips out on cc by having separate cores with their own memory, instead of a single must-be-coherent view of main memory.
07:38:49 <shapr> I've read someplaces that 15% to 25% of the raw CPU power is burned by cache coherency with eight cores.
07:39:02 <sbahra> shapr, yes.
07:39:08 <sbahra> shapr, ~20% on AMD64 with MOESI
07:39:19 <sbahra> shapr, http://kerneled.org/site/?q=node/8
07:39:22 <lambdabot> Title: AMD64 | kerneled.org
07:39:25 <thoughtpolice> what's the size of the memory on each core again?
07:39:26 <Botje> Peaker: you can read it while it's downloading!
07:39:32 <sbahra> thoughtpolice, 256k
07:39:39 <thoughtpolice> that's what I thought
07:39:41 <sbahra> It's called a "scratch pad" or something
07:40:14 <quicksilver> sbahra: surely that would depend on the workload?
07:40:16 <shapr> Obviously, that number will go up as the number of cores goes up. The cell pushes that sort of work into 'userspace' by giving you the element interconnect bus that lets you send bits at great speed to your neighbors and to the strawboss CPU.
07:40:22 <quicksilver> (%power burnt in  coherency)
07:40:23 <sbahra> quicksilver, yes, it does.
07:40:48 <sbahra> quicksilver, cache friendly applications, in general, will perform at "peak".
07:41:04 <sbahra> quicksilver, but this excludes I/O-bound applications or any other kinds of applications which are not so cache friendly.
07:41:05 <shapr> thoughtpolice: Each core has 256k of local store, and its own dedicated DMA processor for getting stuff into and out of main memory.
07:41:35 <quicksilver> I remember when people said SMP would never scale past 4 cores
07:41:40 <quicksilver> and here we are with 8/16/24 machines.
07:41:43 <luite_> is it possible to run programs larger than 256k on the spe's?
07:42:02 <quicksilver> triumph of investment over architecture?
07:42:25 <sbahra> quicksilver, also consider models like http://kerneled.org/view/amd64/gettimeofday.png
07:42:54 <shapr> So the existing well known problem is that IBM/Intel/etc could produce CPUs that they could not possibly power and cool. The solution there is to make more cores running at a slower speed. The next problem is that as number of cores increases, coherency eats more of your power.
07:43:12 <quicksilver> sbahra: I don't understand the significance of that graph?
07:43:20 <shapr> luite_: As long as you swap into and out of main memory.
07:43:38 <sbahra> quicksilver, gettimeofday uses "shared" memory that is located on CPU 0.
07:44:13 <thoughtpolice> shapr: so you make cache a processor-local thing to avoid cc, and then you - the programmer - explicitly uses the DMA processor and bus to send things to your other spu's?
07:44:15 <quicksilver> sbahra: ah.
07:44:23 <thoughtpolice> (well, I say 'cache' but I think you catch my drift)
07:44:25 <shapr> thoughtpolice: That's right.
07:44:29 <sbahra> quicksilver, imagine the impact on any applications dealing with timestamped transactions, for example.
07:44:43 <quicksilver> sbahra: some of the AMD architectures use a non-symmetric model is that right?
07:44:59 <sbahra> shapr, how does communication work between SPUs? I heard it's non-trivial.
07:45:04 <Peaker> sbahra: what does the graph show there? gettimeofday() is being called on all the processors?
07:45:06 <thoughtpolice> shapr: ah, that reminds me I have a really good paper on scientific computing with PS3s
07:45:09 <p_l> quicksilver: All amd64 are NUMA
07:45:10 <sbahra> quicksilver, well, all of them are ccNUMA.
07:45:15 <shapr> I think the best future CPU architecture is no pipelines, no out-of-order execution, just cores and *really* smart compilers.
07:45:17 <p_l> *ccNUMA
07:45:27 <p_l> shapr: look up itanium
07:45:31 <sbahra> Peaker, yes. Line graph isn't the best, but it just allowed me to quickly see different from CPU to CPU.
07:45:34 <thoughtpolice> shapr: www.netlib.org/utk/people/JackDongarra/PAPERS/scop3.pdf
07:45:36 <shapr> pipelines and ooe are hacks to excuse insufficiently intelligent compilers, imho
07:45:51 <quicksilver> shapr: evolution is hard, though, because the driving force behind evolution is to make *this* thing we have *here* run faster
07:45:56 <Peaker> sbahra: what does the "speedup" mean? How many total gettimeofday() calls all the processors managed to make during the time?
07:46:01 <sbahra> shapr, how does communication work between SPUs? I heard it's non-trivial. <-
07:46:10 <quicksilver> shapr: seldome is evolution driven by making that thing in the future we might do one day.
07:46:17 <sbahra> shapr, must it go through the PPU?
07:46:22 <shapr> quicksilver: Yeah, and that's why the Cell is having so much trouble, it's not incremental at all from the x86 viewpoint. But it's a small increment from my larger viewpoint.
07:46:23 <quicksilver> shapr: this problem affects cpus, graphics hardware, motherboard design, etc.
07:46:31 <p_l> shapr: The approach of "intelligent" compilers was found to be failed
07:46:34 <sbahra> Peaker, normalized cost of a single gettimeofday.
07:46:35 <Peaker> p_l: Itanium probably fails to win over because of closed-source software... Open-source is gradually taking over, which will allow incompatible advancements in CPU technology
07:46:38 <p_l> at least for the time being
07:46:54 <shapr> p_l: I'm aware of Itanium's EPIC.
07:46:55 <sbahra> Peaker, CPU 1 gettimeofday time is reference point ("100% of lowest latency")
07:46:55 <p_l> Peaker: Itanium failed because of more things
07:46:57 <monadwar> Peaker: With emphasis on gradually.
07:47:07 <Peaker> p_l: what are those things?
07:47:11 <sbahra> Peaker, CPU 2 is ~95% compared to CPU 1, etc...
07:47:12 <shapr> thoughtpolice: Thanks, I'll check it out.
07:47:23 <Peaker> sbahra: ideally, you'd expect CPU2 to be 50%?
07:47:33 <sbahra> Ideally?
07:47:42 <sbahra> Ideally I expect CPU2 to be 100%.
07:47:59 <shapr> sbahra: Communication among the SPEs is straightforward, you can use mailboxes, or you can DMA it directly into the other SPEs memory.
07:48:03 <p_l> Peaker: Actually, everyone jumped on Itanium bandwagon, killing out multiple platforms. Basically lot of work had gone into it, and many closed-source vendors specifically supported a new architecture despite intel&hp being slow with releasing a working model
07:48:04 <Peaker> sbahra: Oh, I see
07:48:10 <sbahra> Topology isn't some traditional ring. I forget the name of it, but basically ring topology with an additional bidirectional link between 2 other CPUs.
07:48:19 <quicksilver> how does Sun's Niagara architecture fit into this picture?
07:48:26 <Axman6> shapr: mailboxes... like how erlang passes messages?
07:48:26 <sbahra> So, you have only 1 CPU that is 3 hops away.
07:48:32 <sbahra> Rest are 2, some are 1.
07:48:33 <shapr> sbahra: I'm not sure if communication is also that simple with the hardware security turned on (as it is in the PS3 with hypervisor?)
07:48:40 <sbahra> Actually, it is 2 more links.
07:48:43 <Peaker> p_l: well, that doesn't sound like an inherent flaw
07:48:46 <Axman6> > 2^44
07:48:48 <lambdabot>   17592186044416
07:48:49 <sbahra> Peaker, think of it as a ring with an X in the middle.
07:48:52 <quicksilver> sbahra: it's a cube if you squint isn't it?
07:48:54 <monadwar> !rwh
07:48:58 <monadwar> Eh.
07:48:58 <Peaker> p_l: surely for porting purposes, an emulator is enough?
07:49:16 <monadwar> What's the rwh-pdf-script ?
07:49:23 <sbahra> quicksilver, almost
07:49:26 <shapr> Oh, an amusing thing I discovered ... I've been saying for years on #haskell that there's no such thing as a purely strict language, I was wrong!
07:49:36 <sbahra> quicksilver, but some edges are taken for I/O, network, etc...
07:49:40 <quicksilver> sbahra: *nod*
07:49:41 <p_l> Peaker: Despite all that effort, Itanium failed to give any sensible result. In the meantime, AMD released K8 with a lot of stuff taken from Alpha and basically sent IA-64 to a coffin
07:50:09 <shapr> Purely strict is the most efficient way to get fast code on the Cell and Itanium, you don't branch on condition, you evaluate both paths of a conditional and then jump accordingly.
07:50:28 <Peaker> p_l: surely losing backwards compatibility with x86 can only help CPU's better themselves, so all of this is not inherent
07:50:48 <p_l> Peaker: The thing is, Itanium never delivered anything it promised
07:50:53 <znutar_> The first itanium revision had x86 compatibility, didn't it?
07:50:58 <p_l> znutar_: Yes, it had
07:50:59 <sbahra> p_l, sensible results in what way?
07:51:05 <sbahra> Doesn't it still have?
07:51:09 <shapr> Axman6: It is very much like erlang's message passing, yes.
07:51:12 <EmielRegis> but it was very slow
07:51:18 <p_l> sbahra: No longer, Itanium 2 doesn't have in-built emulator
07:51:20 <shapr> I've thought about trying to get erlang running on the SPEs, I wonder if that would work.
07:51:20 <sbahra> IA64 manual has no mention of no x86 support in later processors (but there is a cpuid feature flag for it).
07:51:20 <Axman6> shapr: sounds awesome :)
07:51:25 <sbahra> p_l, ah.
07:51:25 <Peaker> p_l: one project failing is probably not the doom of the entire idea/field
07:51:31 <znutar_> sbahra: I think they dropped it after the first generation of them
07:51:31 <Philippa> shapr: it's not actually purely strict though, you only evaluate so far ahead
07:51:33 <EmielRegis> however, its 64 bit was sure better than x86_64 which isnot truly 64 bit...
07:51:37 <Axman6> i'd like to do more erlang work, but it's far more boring than haskell
07:51:40 <shapr> Philippa: Yeah, but the whole idea amused me.
07:51:45 <shapr> Axman6: I have the same feeling.
07:51:51 <Peaker> EmielRegis: "truly 64 bit" meaning?
07:51:55 <sbahra> shapr, cool (regarding DMA to other SPEs)
07:51:57 <shapr> I keep trying to enjoy erlang, but... no.
07:51:57 <p_l> Peaker: Oh, we are using EPIC-style cpus - they are mostly called DSPs though :P
07:52:09 <Peaker> EmielRegis: the main 64-bit feature is being able to work with 64-bit offsets and virtual memory addresses
07:52:11 <monadwr> shapr: You're trying to learn erlang?
07:52:12 <EmielRegis> peaker, it internally translates 64 bit instructions into 2 32 bit
07:52:16 * sbahra is giving shapr an Itanium 2 box :-P
07:52:19 <EmielRegis> of course it has 64 bit registers
07:52:26 <EmielRegis> but it doesnt run near as fast as it should
07:52:27 <p_l> Peaker: That's more like Core2
07:52:34 <EmielRegis> again, due to x86 legacy
07:53:03 <sbahra> EmielRegis, yes.
07:53:09 <p_l> EmielRegis: What you described is the way 64-bit mode was enabled on NetBurst
07:53:12 <shapr> sbahra: I'm the exotic hardware collector.
07:53:17 <sbahra> EmielRegis, I don't know the details of this, but I dislike running in long mode on Intel processors :-P
07:53:18 <Peaker> EmielRegis: again, a 64-bit MMU and offsetting is the important part.. 4GB of RAM is no longer an insane amount...
07:53:21 <p_l> K8/K10 use 64bit instructions
07:53:26 <Axman6> they managed to drop a lot of the x86 crap that was there though didn't they?
07:53:29 <EmielRegis> '  EMT64 (Extended Memory Technology 64) chips allow a P4 chip to
07:53:29 <EmielRegis> use the same registers that a 64 bit chip accesses, so that they can use
07:53:29 <EmielRegis> more than the 4GB that a non-EMT64 P4 can access. As a side advantage of
07:53:29 <EmielRegis> this, the chip can "execute" the x86 code, but it does so through emulation
07:53:29 <EmielRegis> using a 32 bit thunking layer.  It does not run the 64 bit OS as a 64 bit
07:53:30 <EmielRegis> OS, but as a thunked OS.  This is slow and clumsy at best'
07:53:45 <sbahra> EM64T.
07:53:49 <EmielRegis> thats same
07:53:51 <shapr> monadwr: I've done some erlang before, it just doesn't seem to fit my head, or my interests or something.
07:53:57 <Peaker> I think 32/64 bit opcodes, with 128 bit addressing could be nicer still, so we could address disk storage of the future years to come, in a single level store
07:54:03 <EmielRegis> <p_l> K8/K10 use 64bit instructions
07:54:04 <EmielRegis> they do
07:54:08 <EmielRegis> but internally, its all 32bit...
07:54:15 <shapr> monadwr: Haskell fit me instantly. Haskell was hard to learn, but the whole time I knew it was what I wanted to do, it obviously fit my head.
07:54:18 <sbahra> EMT64 is wrong.
07:54:23 <p_l> EmielRegis: That's intel's NetBurst - it chained two ALUs together cause it couldn't really execute even 32bit code at sensible speed without that
07:54:24 <Peaker> 2^128 is more than the number of particles in the universe, or something, isn't it?
07:54:25 <sbahra> It is EM64T
07:54:36 <earthy> peaker: nah.
07:54:43 <EmielRegis> ah
07:54:44 <monadwr> shapr: So, why are you trying to learn erlang?
07:54:55 <monadwr> shapr: Do you have that rwh/pdf script
07:54:57 <Peaker> earthy: how many particles are there in the universe?
07:54:57 <shapr> monadwr: I learn stuff.
07:55:12 <shapr> monadwr: For the same reason I learned Joy, PostScript, etc
07:55:15 <earthy> there's about 8.87 * 10.49 atoms in the earth
07:55:16 <Peaker> My point was that 2^128 could really be enough for everybody, so why not skip the 64-bit part :-)
07:55:20 <shapr> hoi earthy! Long time no see.
07:55:28 <p_l> EmielRegis: AMD got DEC engineers to work on AMD64, intel had to scramble because they never wanted to release a 64bit cpu for the masses at that time
07:55:31 <earthy> 2^128 is about 3.4 * 10^38
07:55:41 <sbahra> p_l, why not?
07:55:47 <EmielRegis> so you think core 2 is internally 64 bit?
07:55:50 <earthy> peaker: so you're off by quite a few orders of magnitude
07:55:52 <sbahra> p_l, I don't see so many political/etc... reasons.
07:55:54 <quicksilver> > 2.0 ^^ 128
07:55:55 <lambdabot>   3.402823669209385e38
07:56:09 <earthy> shapr: indeed. I've been doing a lot of non-haskell lately.
07:56:10 <p_l> EmielRegis: Core2 can execute 64bit code directly, but still uses microcode emulation for some important stuff
07:56:14 <monadwr> shapr: That's nice
07:56:15 <Peaker> Well, wouldn't 128-bit offsets be enough for the next few centuries?
07:56:15 <vixey> > 8.87 * 10^49 :: Int32
07:56:17 <lambdabot>       No instance for (Fractional Int32)
07:56:17 <lambdabot>        arising from the literal `8.8...
07:56:19 <EmielRegis> ah alrite
07:56:24 <p_l> EmielRegis: AMD cpus all use 64bit internals
07:56:28 <quicksilver> shapr: Joy is pretty fun.
07:56:35 <shapr> quicksilver: Yeah, I really like it.
07:56:36 <quicksilver> shapr: I can't actually imagine writing programs in it.
07:56:39 <EmielRegis> p_l, so how do they run 32 bit instructions?
07:56:45 <vixey> Joy makes me feel physically ill
07:56:57 <p_l> EmielRegis: Simply use only 32bit part of registers?
07:57:00 <quicksilver> shapr: concatenativity sounds great, but I'm not convinced it's a *useful* form of compositionality.
07:57:03 <shapr> quicksilver: I can. It's really nice. I wish it included more ideas from PostScript, but whatever.
07:57:06 <monadwr> vixey: Like withdrawl symptoms.
07:57:11 <EmielRegis> p_l, heh probably :P
07:57:16 <quicksilver> shapr: poetry is concatenative but that's not a good way to write poems.
07:57:17 <quicksilver> ;)
07:57:19 <monadwr> What's the realworldhaskell-pdf script!
07:57:24 <sbahra> EmielRegis, no, it is how it is done.
07:57:25 <shapr> quicksilver: It's great for people with very small sized short term memory :-)
07:57:29 <ksf> setting 2^128 bits would require more energy than boiling the oceans.
07:57:41 <shapr> quicksilver: That's one of the pieces I'm experimenting with, what mental resources do different languages require?
07:57:42 <earthy> ksf: that is literally true.
07:57:45 <p_l> sbahra: Intel did not consider "PC market" to be worthy of a 64bit cpu for a few more years
07:57:46 <ksf> http://en.wikipedia.org/wiki/Zfs#Capacity
07:57:48 <lambdabot> Title: ZFS - Wikipedia, the free encyclopedia
07:58:00 <sbahra> p_l, I see
07:58:26 <shapr> quicksilver: Joy and concatenativity is good to know to get a view of how compositional something can be.
07:58:27 <monadwr> Eh.
07:58:30 <sbahra> Move to ccNUMA is the most important thing, imho
07:58:42 <sbahra> even intel will hop on this band wagon supposedly
07:58:48 <p_l> BTW, IBM's iOS (i.e. those business mini-computers) uses 128bit vm, only recompiling it to the cpu it runs on
07:58:53 <earthy> of course, given 128 bit in-machine addresses and 128 bit machine addresses (IPv6) gives you a bit of headroom. :)
07:59:09 <Axman6> p_l: yeah iOS looks pretty awesome
07:59:16 <shapr> I worked on my own fork of Joy for awhile, but it never went anywhere.
07:59:19 <shapr> Secret Joy :-)
07:59:26 <earthy> iOS, that's AS/400 's new name, right?
07:59:38 <monadwr> Thanks: http://hpaste.org/12060
07:59:56 <winniebambi> if "simple" is a function that that takes three inputs, what type would you assign to "(simple 1 2 3, simple)" ? It's an excersize in the school of expression book and im unsure how to answer it. Thanks.
08:00:15 <p_l> earthy: Yes
08:00:21 <p_l> I couldn't remember the name ^^;
08:00:30 <winniebambi> (Integer -> Integer -> Integer -> Integer, <now what!!>)
08:00:37 <earthy> yeah, that's cool stuff. virtual machine code and running for *ages* already.
08:00:40 <shapr> winniebambi: What type is a function?
08:00:49 <winniebambi> im not sure
08:01:07 <shapr> winniebambi: What type is the simplest function, something like add x y = x + y ?
08:01:08 <earthy> ofcourse, you can't get IBM's i for just toying around with
08:01:23 <sbahra> winniebambi, (b, (a -> a -> a -> b))
08:01:25 <winniebambi> operator?
08:01:42 <sbahra> Of course, it depends on the type of simple.
08:01:43 <shapr> winniebambi: Well, what's the type of "foo" ?
08:01:45 <p_l> shapr: If you want to see an architecture (hw one) that was designed to serve for over 20 years and did *not* fail, try reading about Alpha. Although it did a lot of what you consider bad :D
08:01:53 <shapr> p_l: I really liked the Alpha
08:02:00 <sbahra> I never learned Alpha architecture
08:02:18 <winniebambi> sbahra: That makes no sense to what i've covered so far
08:02:29 <winniebambi> shapr: isn't that just Char?
08:02:29 <earthy> Alpha was cool to hack on
08:02:33 <Axman6> OpenVMS is a pretty insane OS
08:02:39 <thoughtpolice> hehe, shapr, back at my parents house before I left for college I got a friend to give me a dual intel xeon at 3.0gHz - I'm not exactly sure of the exact specifics, I've never been able to install anything on it.
08:02:39 * p_l loves how nearly every Alpha instruction is followed by "in case of error, instruction pointer is not guaranteed to point at the instruction causing the error"
08:02:47 <sbahra> winniebambi, then you need to learn harder :-P
08:02:54 <shapr> The Cell also has some interesting long term features. It's designed to be able to add or remove SPEs, you can make 16 or 32 or 4 or whatever. The SPEs can have up to 4GB of local store each, lots of interesting scalability features like that.
08:03:00 <Axman6> and the machines are rediculous. designed for CPU upgrades without downtime, like holy crap
08:03:09 <shapr> winniebambi: 'a' is Char and "foo" is a list of Char, or [Char]
08:03:12 <p_l> Axman6: Normal stuff
08:03:13 <sbahra> shapr, I would like to see good management features from OS.
08:03:21 <shapr> sbahra: What do you mean?
08:03:24 <earthy> Axman6: you are aware of erlang and its design goals?
08:03:26 <sbahra> shapr, you can interrupt SPEs, or no?
08:03:31 <jberg> how is the support for calling c functions in linux? and using c libraries?
08:03:36 <winniebambi> sbahra: yes, but im following a book, throwing me something i've never encountered before and expecting me to know it after 8 pages of haskell is unhelpful
08:03:42 <Axman6> earthy: sure, i know quite a bit about erlang
08:03:50 <thoughtpolice> jberg: with haskell? easy!
08:03:52 <sbahra> shapr, well, for example. Migrate program in SPE 3 to SPE 2. Have the operating system provide a scheduler for the SPEs so applications can share them easily, etc...
08:03:54 <shapr> sbahra: Yes?
08:03:58 <winniebambi> obviously i should continue and all will be made clear
08:04:04 <shapr> Oh, that should work fine, but you get to write it yourself.
08:04:06 <winniebambi> thanks for your help
08:04:10 <sbahra> shapr, well, I just forget the instruction for it
08:04:10 <shapr> winniebambi: Would you like a few tips?
08:04:11 <shapr> bah
08:04:14 <sbahra> shapr, I don't believe you need to though
08:04:15 <jberg> thoughtpolice, ok cool. is there a standard lib?
08:04:22 <p_l> sbahra: As far as I know SPE's are long-term resources
08:04:23 <sbahra> shapr, you could have a very very thin kernel for the SPEs
08:04:31 <shapr> sbahra: Yeah, there have been a few of those written.
08:04:33 <sbahra> p_l, yes, but this would help share them
08:04:46 <sbahra> p_l, and map them as resources to offload work to in a more uniform manner
08:04:48 <Axman6> earthy: not sure where that question came from though...
08:04:52 * p_l wonders about the overhead
08:04:55 <thoughtpolice> jberg: the haskell FFI is an accepted addendum to haskell98
08:04:55 <earthy> Axman6: the telephone switches running erlang code have the same functionality
08:04:56 <shapr> I haven't tried any of them yet, but there's one from gatech, one from a school in .es, one from ibm.com, and some others.
08:05:02 <sbahra> p_l, it would help applications scale in a more transparent manner, etc...
08:05:04 <thoughtpolice> jberg: so if you just install GHC, you have ffi support already
08:05:09 <thoughtpolice> jberg: here's a good example - http://therning.org/magnus/archives/315
08:05:10 <earthy> swapping out of boards and even code without bringing the switch down
08:05:19 <Axman6> earthy: well that's more a hardware thing (that i didn't know about, cool)
08:05:21 <lambdabot> Title: therning.org/ magnus » Blog Archive » Haskell and C—structs
08:05:24 <Peaker> swapping out code and even boards, it should be, surely? :)
08:05:31 <jberg> thoughtpolice, thanks
08:05:39 <p_l> earthy: hw swapping is a common feature of many "big iron" systems
08:05:41 <shapr> Axman6: It's just as much a software thing, Erlang does that well, and it's the only language I know that does that well.
08:05:44 <earthy> Peaker: swapping hardware is easier given redundancy
08:05:58 <earthy> Erlang allows runtime updates of the entire software stack
08:06:05 <earthy> without bringing down services
08:06:11 <quicksilver> commodity SATA drives are hot-swappable.
08:06:16 <Peaker> earthy: depending on the kind of software changes, it can be easy or hard
08:06:17 <Axman6> shapr: well, from what i've read, VMS was designed along with the Alpha machines for that
08:06:18 <p_l> shapr: There were many systems before that did it right (down to runtime and OS)
08:06:22 <quicksilver> earthy: so does the GHC RTS, as far as I know
08:06:26 <p_l> Axman6: VMS is older than Alpha
08:06:29 <quicksilver> earthy: FSOV "entire stack"
08:06:34 <shapr> p_l: Worse is Better keeps getting in the way.
08:06:34 <quicksilver> (you can't swap out the RTS itself)
08:06:39 <Peaker> quicksilver: you can disconnect a SATA cable and reconnect it in runtime, without kernel oopses?
08:06:39 <p_l> Axman6: 1977
08:06:44 <earthy> quicksilver: you can with erlang, IIRC
08:06:45 <quicksilver> Peaker: yes.
08:06:55 <Axman6> earthy: not afaik
08:06:57 <Peaker> quicksilver: Linux/MacOSX/Windows generally support it?
08:06:57 <quicksilver> earthy: but I'm sure that's not the key feature.
08:06:58 <thoughtpolice> I've done several experiments with haskell + hot code loading
08:06:59 <thoughtpolice> and it works
08:07:04 <thoughtpolice> it actually works really well with haskell
08:07:05 <quicksilver> Peaker: Linux certainly does.
08:07:06 <p_l> Peaker: If your controller doesn't try to play "I'm only an IDE controller" then yes
08:07:07 <shapr> Peaker: Linux supports it.
08:07:10 <sbahra> hot code loading?
08:07:12 <thoughtpolice> although without hs-plugins, it's somewhat more cumbersome
08:07:18 <sbahra> ah, ok
08:07:20 <earthy> quicksilver: it was important
08:07:20 <Peaker> p_l, shapr, quicksilver: Cool, useful!
08:07:28 <quicksilver> earthy: being able to change the RTS? surely not.
08:07:31 <earthy> core telephone switches Should Not Go Down. :)
08:07:35 <quicksilver> surely the important thing is being able to change code.
08:07:37 <quicksilver> not the RTS itself.
08:07:39 <earthy> if there's a bug in the RTS...
08:07:40 <Axman6> earthy: you can think of the RTS as more of a kernel, which allows the processes running in it to be live updated
08:07:51 <thoughtpolice> sbahra: yeah, a while back I wrote an IRC bot kinda like lambdabot that used hs-plugins, and it could be on multiple servers, channels, with multiple plugins etc, and you could just say '@reboot' and everything would Just Work :]
08:07:52 <p_l> Peaker: But to get full functionality of it, you need fault-tolerant storage config and multi-path
08:07:52 <shapr> earthy: I want references...
08:07:55 <earthy> axman6: I understand the rts
08:07:56 <Axman6> i'll have to find out about the RTS though
08:07:59 * gwern always enjoys reading HCAR and hearing about new stuff
08:08:07 <maxote> i wanted to donate some to AMD buying a good X4 PC of their good micros+motherboards although Intel Quad Core is too evil
08:08:08 <quicksilver> gwern: yeah, it was great wasn't it.
08:08:11 <Peaker> p_l: why not umount and mount something else?
08:08:14 <shapr> thoughtpolice: Cool!
08:08:15 <gwern> like this 'HEAT: The Haskell Educational Advancement Tool'
08:08:23 <quicksilver> earthy: anyhow my point is that GHC supports an awesome amount of hot-pluggability.
08:08:25 <gwern> it's written in java, but it still looks interesting
08:08:27 <quicksilver> but nobody really uses it.
08:08:37 <quicksilver> (probably because it's not very documented and fiddly to use)
08:08:42 <p_l> Peaker: You can do that, but it's not like heavy-duty hot swap required by server systems :)
08:08:43 <quicksilver> whereas erlang made it a 'core feature'
08:08:46 <Valodim> written in java?
08:08:57 <Valodim> now what way to raise the children is that .V.
08:09:04 <shapr> So, how can I use GHC on six dual Cell blades that are each independent linux boxes connected by gigEthernet?
08:09:22 <shapr> 96 SPEs, 12 PPEs, one GHC to rule them all?
08:09:33 <p_l> shapr: I propose switching to message passing
08:09:52 <thoughtpolice> shapr: yeah, it was a really fun project
08:09:54 <shapr> rdma?
08:09:56 <p_l> shapr: OS will dynamically give you free SPEs
08:09:57 <thoughtpolice> one of my first that got my haskell-hands dirty
08:10:12 * Axman6 checks for his erlang book
08:10:13 <p_l> shapr: RDMA on GigEthernet? crazy?
08:10:19 <thoughtpolice> shapr: if you would like to see the code in all its horror, http://code.haskell.org/infinity/src/
08:10:19 <lambdabot> Title: Index of /infinity/src
08:10:30 <shapr> p_l: It's gigEthernet inside the bladecenter chassis :-)
08:10:35 <maxote> i seeing that the AMD participation on linux is good
08:10:40 <thoughtpolice> shapr: that's an old version; I rewrote it and the code is much better, but it doesn't share all the functionality; I never got rebooting the code fully working
08:10:47 <shapr> thoughtpolice: aww
08:10:59 <p_l> shapr: Oh, so it's emulated GigE
08:11:14 <p_l> shapr: Check if you can get into direct interface
08:11:22 <thoughtpolice> shapr: yeah, if either the GHC API would allow something like that easily *or* hs-plugins could be coaxed into working on ghc 6.10, I might finish it
08:11:33 <shapr> p_l: I guess so, I don't know how everything works inside the chassis.
08:11:43 <p_l> shapr: There's no real GigE inside
08:11:55 <thoughtpolice> shapr: but that link above should work just perfectly fine, provided you have ghc 6.6 and hs-plugins :]
08:11:59 <earthy> http://www.sauria.com/blog/2008/05/28/notes-on-a-history-of-erlang/
08:12:04 <shapr> What's the problem with hs-plugins on 6.10? Hint?
08:12:06 <earthy> Changing code on the fly was an initial key requirement
08:12:07 <lambdabot> Title: Notes on A History of Erlang at Ted Leung on the Air, http://tinyurl.com/5tqm6c
08:12:19 <p_l> shapr: The BladeCenter AFAIK runs a virtualisation software for IO, multiplexing it through the devices installed into it
08:12:19 <shapr> earthy: Sure, but the entire RTS?
08:12:31 <shapr> p_l: Where can I read about this?
08:12:32 <gwern> shapr: the ghc api changes every release; I'm not sure hs-plugins uses hint
08:12:38 <p_l> shapr: Similar to how LPARs are usually configured
08:12:47 <shapr> What's that?
08:12:57 <p_l> shapr: Logical PARtitions
08:13:01 <monadwr> Christ, realworldhaskell is pretty 'complete'.
08:13:03 <earthy> shapr: ISTR they do that using distributed erlang, where each pair of processors runs its own rts
08:13:14 <earthy> and then you can swap rts's 'on the fly' as it were
08:13:17 <p_l> shapr: partitioning by hardware
08:13:27 <quicksilver> I note that erlang's hotswapping is very dangerous in the sense that
08:13:28 <shapr> earthy: Oh, like Linux booting into another kernel at runtime?
08:13:38 <quicksilver> if you have a bug in your persistence code, you're really screwed.
08:13:46 <earthy> by killing parts of the distributed system and bringing it up with a different rts
08:13:57 <shapr> p_l: Where did you learn that? I want to know more!
08:13:58 <quicksilver> or you change your data structure assumptions in some little used code path.
08:14:02 <thoughtpolice> quicksilver: getting GHC-built code to support hotswapping isn't really hard, like I said it was one of my first 'big' haskell projects and took relatively minimal effort (with the way paved thanks to a paper by dons) but it's certainly more annoying than otherwise if you don't have hs-plugins
08:14:14 <shapr> quicksilver: We can into similar problems with HAppS.
08:14:17 <quicksilver> thoughtpolice: my word was "fiddly" rather than hard.
08:14:23 <quicksilver> shapr: can has verb pls?
08:14:24 <shapr> Upgrading from previous versions of the persistence code was hard.
08:14:28 <p_l> shapr: Unfortunately, I can't point you to any links - I simply observed an IBM engineer at work, setting one of our POWER5 clusters :D
08:14:33 <quicksilver> shapr: ah. "ran"
08:14:33 <shapr> quicksilver: s/can/ran
08:14:34 <quicksilver> shapr: *nod*
08:14:34 <shapr> sorry
08:14:45 <shapr> I can has code!
08:14:46 <quicksilver> I ACCIDENTALLY THE WHOLE VERB
08:14:47 <shapr> whee!
08:14:50 * shapr laughs
08:14:58 <thoughtpolice> quicksilver: it's way more fiddly without hs-plugins, I tried plenty but I could never find a way to load code into a program, unload it and then reload a new version
08:15:06 <quicksilver> thoughtpolice: *nod*
08:15:11 <shapr> p_l: You have a POWER5 cluster? Where do you work??
08:15:18 <thoughtpolice> quicksilver: with the GHC API, that is
08:15:21 <quicksilver> thoughtpolice: I think people went before you, found that, and then wrote hs-plugins ;)
08:15:25 <p_l> shapr: I *worked* for a big mobile phone operator :)
08:15:28 <quicksilver> thoughtpolice: where people =? dons
08:15:33 <shapr> p_l: oohhh
08:15:34 <thoughtpolice> quicksilver: yeah :)
08:15:44 <shapr> p_l: I'm doing all this on my own time and money.
08:15:55 <thoughtpolice> quicksilver: personally I think building a very high level API like hs-plugins into the GHC API would be worth it
08:15:59 <thoughtpolice> want plugins? use the simple interface: load, unload, eval, etc..
08:16:00 <shapr> @remember quicksilver I ACCIDENTALLY THE WHOLE VERB
08:16:00 <lambdabot> I will never forget.
08:16:11 <thoughtpolice> want the guts? you've got it too
08:16:41 <shapr> p_l: Still, I got 2.4 single precision teraflops worth of Cell hardware together for less than $2k usd.
08:17:44 <newsham> terrorflops
08:17:44 <thoughtpolice> shapr: re. so many cell systems that're separate linux boxes, I've thought of using network-bytestring + binary for a very lightweight form of distributed app communication
08:17:48 <p_l> shapr: Though we ran only x86 blades with Solaris on it. On POWER servers we had AIX, the rest was mostly SPARCs (rarely an AMD64) with Solaris 10, four or five Alphas (3x GS1280, 1xGS160 and there was some other I think), some vendor-specific stuff running linux, etc.
08:18:01 <Axman6> ok, can someone explain the 'i accidentally the x' meme? it makes no sense to me
08:18:40 <quicksilver> thoughtpolice: definitely.
08:18:42 <p_l> shapr: Lots of fun, but I moved to Scotland and can't get a job in IT anymore ;_;
08:18:52 <quicksilver> thoughtpolice: there are other plugins apis.
08:19:01 <gwern> whew. Yi is feeling much more usable with a better Home binding
08:19:18 <earthy> p_l: too many computer scientists or no jobs?
08:19:48 <p_l> earthy: HR depts throwing your CV away when they see the words "currently pursuing a degree in ..."
08:19:48 <gwern> Axman6: /b/; someone showed up asking for help, and their first line was something like 'I accidentally my 78megabyte RAR file! Please help etc.', and the rest of the thread was mocking his omitted verb
08:19:48 <maxote> no earthy, many non-computer scientists stealing the computer jobs
08:19:51 <blueonyx> hi
08:20:11 <Axman6> ha, i see
08:20:11 <earthy> p_l: that sucks
08:20:16 <maxote> wrong world
08:20:25 <earthy> maxote: that's everywhere in the whole wide worlf
08:20:29 <earthy> world
08:20:37 <gwern> Axman6: from there it changed into 'I accidentally the whole [thing]', spurred by a few good captions - like one photo of GWB shrugging with a sheepish look on his face was captioned 'Oops, I accidentally the whole economy!'
08:20:41 <quicksilver> thoughtpolice: I don't know if any of htem addresses the hotplug question.
08:20:44 <blueonyx> is there a standard function that gets a list and returns a list of pairs of an element and its follower?
08:20:48 <quicksilver> thoughtpolice: plugins? mueval?
08:21:06 * p_l would love to get a job where he could either work on IT infrastructure or write code...
08:21:10 <quicksilver> > zip`ap`tail "hello blueonyx"
08:21:12 <lambdabot>   Couldn't match expected type `[a] -> [b]'
08:21:12 <Lemmih> blueonyx: zip list (tail list)?
08:21:18 <quicksilver> > (zip`ap`tail) "hello blueonyx"
08:21:19 <idnar> Axman6: http://encyclopediadramatica.com/I_accidentally_X
08:21:19 <lambdabot>   [('h','e'),('e','l'),('l','l'),('l','o'),('o',' '),(' ','b'),('b','l'),('l'...
08:21:20 <lambdabot> Title: I accidentally X - Encyclopedia Dramatica
08:21:31 <quicksilver> Axman6: warning, NFSW
08:21:38 <earthy> quicksilver: that's probably not what he wanted.
08:21:40 <quicksilver> the article is fine, but E.D. is very NSFW.
08:21:51 <Axman6> heh, it's 3:21AM here and i'm home ;)
08:21:54 <quicksilver> earthy: are you sure? it sounded like what he wanted.
08:21:56 <idnar> encyclopædia dramatica is like wikipedia, but for the interwebs :P
08:22:04 <idnar> but yeah, I probably should have specified
08:22:07 <quicksilver> blueonyx: is that what you wanted?
08:22:20 <skorpan> <quicksilver> Axman6: warning, LOL -> NFSW <- LOL
08:22:22 <earthy> quicksilver: if you'd filter every second element from that list, then yes
08:22:27 <blueonyx> > zip "hello" (tail "hello")
08:22:29 <lambdabot>   [('h','e'),('e','l'),('l','l'),('l','o')]
08:22:41 <blueonyx> quicksilver: yea thats it :) thanks
08:22:45 <Axman6> skorpan: ?
08:22:54 <skorpan> Axman6: type
08:22:56 <skorpan> typo*
08:22:57 <Deewiant> > (zip<*>tail) "hello"
08:22:59 <lambdabot>   [('h','e'),('e','l'),('l','l'),('l','o')]
08:23:00 <skorpan> that was ironic
08:23:06 <quicksilver> > (zip`ap`tail) [1..]
08:23:08 <lambdabot>   [(1,2),(2,3),(3,4),(4,5),(5,6),(6,7),(7,8),(8,9),(9,10),(10,11),(11,12),(12...
08:23:13 <quicksilver> @quote axtec
08:23:14 <lambdabot> No quotes match. My brain just exploded
08:23:16 <quicksilver> @quote aztec
08:23:17 <earthy> hm. he was underspecified. :)
08:23:17 <lambdabot> quicksilver says: zip`ap`tail - the Aztec god of consecutive numbers
08:23:22 <jpcooper> :t (<*>)
08:23:23 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f (a -> b) -> f a -> f b
08:23:47 <monadwr> hm, who wrote rwh2pdf?
08:23:47 <idnar> not for safe work
08:24:02 <monadwr> !rwh2pdf
08:24:07 <monadwr> Eh.
08:24:17 <athos> @s zip
08:24:17 <lambdabot> Maybe you meant: seen shootout show slap smack source spell spell-all src . ? @ v
08:24:22 <athos> @source zip
08:24:22 <lambdabot> zip not available
08:24:31 <Axman6> monadwr: just buy the book or PDF
08:24:54 <earthy> time to get my son from daycare
08:24:55 <monadwr> Axman6: Word.
08:25:23 <nominolo|msr> @seen waern
08:25:24 <lambdabot> I saw waern leaving #haskell, #haskell.se and #ghc 1m 20d 18h 55m 23s ago, and .
08:25:46 <Axman6> long memory
08:26:17 <nominolo|msr> with long holes in it
08:33:07 <RayNbow> twanvl: have you already received RWH in your shoe from St. Nicolas? :p
08:35:24 <twanvl> RayNbow: not yet, and I doubt it would fit :)
08:35:52 <gwern> it could be rolled
08:36:32 <idnar> Rolled World Haskell
08:36:34 <luite_> the electronic edition would fit, on an sd card
08:37:24 <luite_> is there a sample of the electronic version somewhere?
08:37:38 <RayNbow> I doubt I will receive a copy of RWH from St. Nicolas... I haven't received a thing in years... :(
08:38:17 <Botje> RayNbow: i'll send you one if you send me one :P
08:38:49 <RayNbow> :p
08:40:19 <luite_> RayNbow: you probably have been behaving very well then. you're lucky he hasn't taken you in his bag to spain
08:40:25 <luite_> haven't
08:41:39 <BeelsebobWork> quicksilver: this actually some some interesting problems in it... http://www.cs.kent.ac.uk/people/rpg/tatd2/Hsark.png <-- finally found a good algorithm for determining the colour of the backgrounds
08:42:03 <BeelsebobWork> the hue is determined by xoring the characters before the dot, the saturation by xoring characters after the first dot
08:42:07 <Peaker> does anyone here use HAT or any other Haskell tracer? Does it work on large-scale things?  Will it be able to help understand what goes bad in Reactive?
08:42:24 <BeelsebobWork> Peaker: Hat works fine, on anything that is Haskell 98 -- this does not include Reactive :(
08:42:39 <Peaker> BeelsebobWork: oh.. how do you and conal debug Reactive?
08:42:48 <BeelsebobWork> Peaker: a lot of thought :(
08:42:56 <BeelsebobWork> the profiling tools are useful too
08:43:21 <BeelsebobWork> ideally, someone will extend the ghc runtime to include something that outputs a Hat (or similar) trace
08:43:24 <blueonyx> the QuickCheck manual says it is included in ghc but ghci cant import it? i got ghc v6.10.1
08:43:27 <Peaker> BeelsebobWork: it should be possible to show the incremental evaluation of a Haskell program...
08:43:34 <Peaker> BeelsebobWork: which would make debugging so much easier
08:43:39 <BeelsebobWork> Peaker: it doesn't actually
08:43:47 <BeelsebobWork> incremental evaluation is really horrible to see
08:44:10 <Philippa> a little like a cancer growing and shrinking? :-)
08:44:11 <BeelsebobWork> you write functional programs without thinking about evaluation order -- ideally, you want to debug independant of it as well
08:44:12 <RayNbow> luite_: but I haven't been taken to Spain in the previous years...
08:44:24 <BeelsebobWork> Philippa: that's a remarkably good description, yes
08:45:15 <monadwr> hi jj.
08:45:15 <Peaker> BeelsebobWork: not sure I can debug the kinds of problems I have (Mostly in IO) via a pure denotational debugger
08:45:21 <luite_> RayNbow: I would like to be there for some time, but I could think of more comfortable ways of travel than a bag
08:45:37 <BeelsebobWork> Peaker: yeh, IO is a special case as always
08:46:30 <quicksilver> printf-debugging works pretty well in IO though
08:46:35 <BeelsebobWork> indeed
08:46:38 <Peaker> BeelsebobWork: well, a denotational debugger could be great for certain kinds of bugs, but I suspect IO code is more often in need of a debugger :)
08:46:51 <quicksilver> I'm not sure that's true.
08:46:55 <Philippa> IO's certainly more likely to truly need one
08:46:58 <BeelsebobWork> nor am I
08:47:09 * gwern rolls a copy of RWH and smokes it. ah... mind-expanding
08:47:19 <BeelsebobWork> mostly because the IO code I write usually consists of main = adaptToIO (properlyFunctionalCode)
08:47:39 <monadwr> gwern: RWH-Smokers are liable to lambda young.
08:47:40 <Raevel> gwern: your addicted, get help?
08:47:52 <Raevel> </grammar>
08:47:56 <gwern> Raevel: don't force me, man! my bottom might blow
08:48:09 <Philippa> Beelsebob: well quite, that suggests you don't actually need to debug /IO/ usually
08:48:21 <monadwr> drugs make people better in their various areas of proficency.
08:48:37 <Peaker> BeelsebobWork, quicksilver: Would you suggest adding a lot of prints to Reactive's code to debug my Reactive bugs?
08:48:46 <gwern> monadwr: run fast, terminate young, and leave a pure-looking corpse, I always say
08:48:56 <quicksilver> Peaker: no, I would suggest that for IO bugs.
08:48:59 <quicksilver> not Reactive bugs.
08:49:00 <BeelsebobWork> Peaker: nope -- but I would bet heavily that the bug you have is not in IO
08:49:17 <BeelsebobWork> is this the event -> behavior -> event -> behavior bug?
08:49:19 <monadwr> gwern: You listen to way too much lilwayne/birdman.
08:49:33 <Peaker> quicksilver: I'm guessing the Reactive bugs are in its IO implementation, but I am not sure
08:49:39 <Peaker> BeelsebobWork: yeah
08:49:44 <gwern> monadwr: I never met the man!
08:50:45 <BeelsebobWork> Peaker: I *think* the IO stuff is now bug free, but I could well be wrong
08:51:00 <BeelsebobWork> I would bet that your bug is a not-enough-lazy bug
08:51:15 <BeelsebobWork> but that's just me
08:51:32 <Peaker> BeelsebobWork: surely a growing/shrinking cancer can help with that kind? :-)
08:52:13 <BeelsebobWork> Peaker: not usually, no -- all it does is destracts you with evaluation elsewhere
08:52:28 <BeelsebobWork> what most people don't realise is how big the cancer is
08:52:51 <Peaker> BeelsebobWork: Then there must be some way to visualize the truly relevant data to debug that kind of bug
08:53:15 <BeelsebobWork> while debugging a sort of a 4-5 element list, the intermediate expressions end up 4 times wider than a terminal the width of my 1920x1200 screen, with a really tiny font
08:53:26 <BeelsebobWork> Peaker: yep, declarative debugging ;)
08:54:05 <Peaker> BeelsebobWork: how would that work?
08:54:28 <BeelsebobWork> you'd terminate your program, and enter a debugging session
08:54:53 <BeelsebobWork> eventually it would say "someExpression (Event ...) =?= _|_"
08:54:58 <BeelsebobWork> and you would say "hey, that's not right"
08:55:51 <gwern> @pl insertArticle adb a = a:adb -- flip (:)?
08:55:52 <lambdabot> insertArticle = flip (:)
08:58:24 <haskellNewbie> Hi!
08:58:39 <BeelsebobWork> hello
08:59:36 <Axman6> haskellNewbie: identity crisis?
08:59:50 <haskellNewbie> Can anyone tell me whether it is possible - and if so: how - to split up my haskell source code into several files which can be "included" in other parts of my program, similar to the way one does in C/C++?
09:00:14 <haskellNewbie> No, I'm even more unused to IRC than to haskell :- )
09:00:19 <Riastradh> Use modules.  (`Inclusion' is a red herring.)
09:00:22 <gwern> oh, Soccer-Fun looks like a pretty cool program
09:00:51 <gwern> except.. aw, it's written in Clean
09:01:14 <quicksilver> gwern: yeah I must admit I don't really get why the clean stuff is in there
09:01:21 <quicksilver> except for the bits which are joint projects
09:01:30 <BeelsebobWork> haskellNewbie: module My.Module.Name where... and then import Some.Other.Module
09:01:36 <gwern> I guess people see clean and haskell as pretty much interchangeable
09:01:42 <Axman6> haskellNewbie: just make modules, and import them: module MyModule where <function defs>; (another file) module MyOtherThing where \n import MyModule
09:01:55 <gwern> which is sensible - things like the clean compiler compiling haskell certainly do seem to support that
09:02:04 <ksf> thunks are just continuations, why did no one tell me?
09:02:16 <osfameron> continuations are just thunks? ;-)
09:02:23 <haskellNewbie> Okay, thank you very much.
09:02:36 <dolio> Because thunks aren't continuations?
09:02:48 <ksf> or, taking whnf into account, coroutines.
09:03:10 <thoughtpolice> woo!
09:03:26 <quicksilver> ksf: a thunk may simply be an evaluated data object.
09:03:33 <quicksilver> Like "Just 'a'"
09:03:40 <quicksilver> is that a continuation?
09:03:55 <ksf> if you pass it around, sure.
09:03:55 <quicksilver> only in a fairly boring way.
09:04:02 <thoughtpolice> @tell Lemmih I just got an email back from niklas - he said he has been putting pragma support in haskell-src-exts off for a while in favor of fast and small fixes, but if LHC needs it, he said he'd spend some time in the next few days hacking pragma support in and releasing it!
09:04:03 <lambdabot> Consider it noted.
09:04:04 <quicksilver> if that's a continuation, everything is.
09:04:05 <ksf> it's a continuation that returns "Just 'a'"
09:04:27 <dolio> So they're delimited continuations?
09:04:42 <gwern> thoughtpolice: what a nice fellow. on the other hand, thanksgiving vacation is probably a good time to ask for features :)
09:05:18 <gwern> (objects are a poor man's closure; closures are objects for poor men, as the lispers say)
09:05:34 <ksf> ...or that passes "Just a" to the current continuation, I don't care.
09:05:38 <thoughtpolice> gwern: hehehe.
09:06:46 <gwern> 'Galois develops software under contract, and every project (bar three) that we have ever done has used Haskell. The exceptions used ACL2, Poly-ML, SML-NJ, and OCaml, respectively, so functional programming languages and formal methods are clearly our “secret sauce”.'
09:06:48 <thoughtpolice> gwern: using haskell-src-exts for LHC would be really really great tbh.
09:06:54 <bbs> hey all
09:06:59 <thoughtpolice> gwern: but it will be a long, tough conversion.
09:07:09 <bbs> Cale: schools oveer
09:07:14 <Axman6> whooo
09:07:55 <thoughtpolice> after haskell-src-exts I guess I'll have to get to reading some about region inference
09:07:58 <blueonyx> (zip`ap`tail) "hello blueonyx"
09:07:59 <thoughtpolice> and seeing if I can fix it inside LHC
09:08:01 <gwern> school's out - for summer. school's out - forever! (goes into power chords)
09:08:07 <blueonyx> > (zip`ap`tail) "hello blueonyx"
09:08:08 <lambdabot>   [('h','e'),('e','l'),('l','l'),('l','o'),('o',' '),(' ','b'),('b','l'),('l'...
09:08:16 <blueonyx> in which module is this ap?
09:08:16 <thoughtpolice> having an application immediately use 900mb of memory once you start it isn't too cool
09:08:19 <Deewiant> ?index ap
09:08:20 <lambdabot> Control.Monad, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont, Control.Monad.Error, Control.Monad.List, Data.Graph.
09:08:20 <lambdabot> Inductive.Query.ArtPoint, Data.Graph.Inductive.Query, Data.Graph.Inductive
09:08:25 <Peaker> @src ap
09:08:26 <lambdabot> ap = liftM2 id
09:08:30 <thoughtpolice> (see: shootout recursive benchmark which LHC does such things to)
09:08:35 <gwern> 'Report by:	Dan Popa
09:08:36 <gwern> This is to report some activities of the Ro/Haskell group. The Ro/Haskell page becomes more and more known. The numbers of students and teachers interested in Haskell is increasing.
09:08:39 <gwern> A new book, “The Practice Of Monadic Interpretation” by Dan Popa appears in November 2008. '
09:08:39 <Deewiant> ?src (->) (<*>)
09:08:40 <lambdabot> (<*>) f g x = f x (g x)
09:08:40 <Peaker> @src liftM2
09:08:41 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
09:08:43 <blueonyx> in my ghci i get No instance for (Monad ((->) [Char])) :/
09:08:45 <gwern> <- who knew haskell was popular in romania?
09:08:57 <mdmkolbe> Ro/Haskell = ?
09:09:01 <Deewiant> blueonyx: :m + Control.Monad.Instances
09:09:03 <gwern> 'Haskell products like Rodin (a small DSL a bit like C but written in Romanian) begin to spread, proving the power of the Haskell language. The Pseudocode Language Rodin is used as a tool for teaching basics of computer science in some high-schools from various cities. Some teachers from a high school have requested training concerning Rodin.'
09:09:09 <gwern> mdmkolbe: page on ha wiki
09:09:27 <gwern> 'There are some unsolved problems, too: PhD. Advisors (specialized in monads, languages engineering, and Haskell) are almost impossible to find. This fact seems to block somehow the hiring of good specialists in Haskell. There was even a funny case when somebody hired to teach Haskell was tested and interviewed by a LISP teacher. Of course, the exam was more or less about lists.'
09:09:46 <mdmkolbe> gwern: Ro = romainian? or Rodin?
09:10:07 <blueonyx> Deewiant: ah thanks
09:10:37 <Raevel> I have a value IO (String -> String) and a String, i essentially want a function IO (a -> b) -> a -> IO b, how should i do this?
09:11:03 <mdmkolbe> @hoogle [a] -> b -> [[a]]
09:11:04 <lambdabot> Data.List genericDrop :: Integral i => i -> [a] -> [a]
09:11:04 <lambdabot> Data.List genericTake :: Integral i => i -> [a] -> [a]
09:11:04 <lambdabot> Data.List intersperse :: a -> [a] -> [a]
09:11:06 <dolio> @type (<$)
09:11:06 <lambdabot> forall a (f :: * -> *) b. (Functor f) => a -> f b -> f a
09:11:18 <dolio> @type (<*)
09:11:19 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f a -> f b -> f a
09:11:25 <dolio> Hmm...
09:11:42 <quicksilver> :t \act val -> do f <- act; return (f val)
09:11:44 <lambdabot> forall t (t1 :: * -> *) t2. (Monad t1) => t1 (t -> t2) -> t -> t1 t2
09:11:53 <quicksilver> Raevel: like that, I believe.
09:12:00 <dolio> @type flip $ fmap . flip ($)
09:12:01 <lambdabot> forall (f :: * -> *) a b. (Functor f) => f (a -> b) -> a -> f b
09:12:05 <Deewiant> ?src (<*)
09:12:05 <lambdabot> (<*) = liftA2 const
09:12:11 <quicksilver> although it's a surprising type to have, I think.
09:12:31 <mdmkolbe> What is a good name (or existing library function) for a function (type :: [a] -> Integer -> [[a]]) that takes a list and chops it up into bits of a certain length?
09:12:44 <quicksilver> mdmkolbe: I call it 'groupsOf'
09:12:49 <quicksilver> (and I flip the parameters)
09:13:09 <quicksilver> :t let groupsOf n = map (take n) . takeWhile (not.null) . iterate (drop n)
09:13:10 <lambdabot> <no location info>:
09:13:10 <lambdabot>     not an expression: `let groupsOf n = map (take n) . takeWhile (not.null) . iterate (drop n)'
09:13:14 <dolio> We should establish a FAQ somewhere with that question.
09:13:14 <quicksilver> :t let groupsOf n = map (take n) . takeWhile (not.null) . iterate (drop n) in groupsOf
09:13:15 <lambdabot> forall a. Int -> [a] -> [[a]]
09:13:40 <Raevel> quicksilver: i may well be solving this in a bad way
09:14:04 <vixey> @faq How do I split a list into chunks of size n?
09:14:05 <lambdabot> The answer is: Yes! Haskell can do that.
09:14:05 <mdmkolbe> Raevel: you could do \f x -> f `ap` return x
09:14:15 <gwern> dolio: while we're at it, we can include definitions for stuff like 'split' that everyone wants but no one can agree on
09:14:24 <vixey> gwern, I disagree
09:14:27 <mdmkolbe> @hoogle groupsOf
09:14:28 <lambdabot> No results found
09:14:31 <dolio> Yeah.
09:14:51 <vixey> why not the haskell wiki?
09:15:14 <Raevel> okay, thanks everyone, see if i get this working
09:15:45 <dolio> > let stopAt p f x = guard (p x) >> return (f x) ; chunk n = unfoldr (stopAt null $ splitAt n) in chunk 3 [1..]
09:15:47 <lambdabot>   []
09:16:04 <dolio> > let stopAt p f x = guard (not $ p x) >> return (f x) ; chunk n = unfoldr (stopAt null $ splitAt n) in chunk 3 [1..]
09:16:05 <lambdabot>   [[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18],[19,20,21],[22,23...
09:17:48 <RayNbow> > unfoldUntil null (splitAt 4) [1..]
09:17:49 <lambdabot>   [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16],[17,18,19,20],[21,22,23,24]...
09:18:05 <dolio> I've always been a fan of splitsAt.
09:18:19 <dolio> Since you can then similarly define breaks and spans.
09:18:25 <Peaker> Didn't know of unfoldUntil, cool :-)
09:18:36 <RayNbow> Peaker: it is a user defined function
09:18:40 <Peaker> oh
09:18:42 <RayNbow> unfoldUntil p f = unfoldr (\x -> guard (not (p x)) >> return (f x))
09:18:45 <Peaker> @src unfoldUntil
09:18:46 <lambdabot> Source not found. Just what do you think you're doing Dave?
09:18:54 <mdmkolbe> @type splitAt
09:18:55 <lambdabot> forall a. Int -> [a] -> ([a], [a])
09:19:03 <Peaker> @type unfoldUntil
09:19:04 <lambdabot> forall b a. (b -> Bool) -> (b -> (a, b)) -> b -> [a]
09:19:17 <dolio> unfoldUntil is an alternate form of unfoldr you'll find in the literature sometimes.
09:19:46 <vixey> @let unfoldUntil p f = unfoldr (\x -> guard (not (p x)) >> return (f x))
09:19:47 <lambdabot>  <local>:2:0:
09:19:47 <lambdabot>      Warning: Pattern match(es) are overlapped
09:19:47 <lambdabot>               In...
09:19:56 <mdmkolbe> hmm, groupsOf is a really good name in haskell.  Unfortunately I need the name to harmonize with scheme so is there a name that would be like vectorSplitsAt (vector-functions in scheme conventionally begin with "vector")
09:20:00 <Peaker> foldr : list catamorphism   as to:   unfoldr : ?
09:20:17 <dolio> anamorphism
09:20:30 <vixey> @go anamorphism
09:20:33 <lambdabot> http://en.wikipedia.org/wiki/Anamorphism
09:20:34 <Peaker> what is the anamorphism of Maybe?
09:20:37 <RayNbow> I saw the definition of unfoldUntil for the first time here in #haskell  (from my logs: <newsham> ?let unfoldUntil p f = unfoldr (\x -> guard (not (p x)) >> return (f x)) )
09:22:00 <Peaker> @pl unfoldr (\x -> guard (not (p x)) >> return (f x)) )
09:22:00 <lambdabot> (line 1, column 51):
09:22:00 <lambdabot> unexpected ")"
09:22:00 <lambdabot> expecting variable, "(", operator or end of input
09:22:01 <dolio> Peaker: Well, it's kind of (b -> Maybe a) -> b -> Maybe a, which isn't great.
09:22:23 <Peaker> @pl unfoldr (\x -> guard (not (p x)) >> return (f x))
09:22:23 <lambdabot> unfoldr (ap ((>>) . guard . not . p) (return . f))
09:22:43 <dolio> Technically, the exact dual of unfoldr would be like: foldr :: (Maybe (a,b) -> b) -> [a] -> b
09:23:05 <vixey> where does the Maybe and (,) come from?
09:23:08 <dolio> Which would put maybe :: (Maybe a -> b) -> Maybe a -> b, which is similarly worthless.
09:23:12 <vixey> oh
09:23:14 <vixey> oh I see what you mean
09:23:51 <dolio> So I guess you could split it into something like: 'unmaybe :: (a -> Bool) -> (a -> b) -> a -> Maybe b'
09:24:00 <dolio> Which is similar to the predicate version of unfoldr.
09:24:11 <Peaker> I guess when you have data constructors as functions, you don't really need anamorphisms on non-recursive data structures
09:25:29 * shapr boings
09:27:15 <Peaker> data Tree a = Branch (Tree a) (Tree a) | Leaf a       ; what would the anamorphism of that?  Would it also use a Maybe to choose between the data constructors?
09:27:37 <dolio> Can it be just Leaf? That's easier.
09:28:02 <dolio> Oh, wait.
09:28:11 <dolio> That's leaf labeled only.
09:28:36 <Peaker> well, you could do a tree that has everything labelled: data Tree a = Branch a (Tree a) (Tree a) | Empty
09:28:45 <dolio> So it's: unfoldTree :: (b -> Either (b,b) a) -> b -> Tree a
09:29:21 <dolio> If it's node-labeled, it's: unfoldTree :: (b -> Maybe (a,b,b)) -> b -> Tree a
09:29:46 <Peaker> @type unfoldr
09:29:47 <lambdabot> forall b a. (b -> Maybe (a, b)) -> b -> [a]
09:30:04 <Peaker> aha, cool
09:30:07 <Peaker> dolio: Thanks
09:30:09 <RayNbow> @hoogle unfoldTree
09:30:09 <lambdabot> Data.Tree unfoldTree :: (b -> (a, [b])) -> b -> Tree a
09:30:09 <lambdabot> Data.Tree unfoldTreeM :: Monad m => (b -> m (a, [b])) -> b -> m (Tree a)
09:30:09 <lambdabot> Data.Tree unfoldTreeM_BF :: Monad m => (b -> m (a, [b])) -> b -> m (Tree a)
09:30:14 <dolio> No problem.
09:30:31 <dolio> Peaker: In general, you have to ask what the shape functor is.
09:30:56 <dolio> So, the shape of list (mu X. 1 + A*X) is F X = 1 + A*X.
09:31:39 <dolio> Then the anamorphism :: (B -> F B) -> B -> mu X. F X (or, nu, technically).
09:32:01 <dolio> And the catamorphism :: (F B -> B) -> mu X. F X -> B
09:32:58 <dolio> Where mu is the least fixed point operator, and nu is the greatest fixed point operator.
09:36:53 <dolio> (In one of those fancy total languages with distinctions between data and codata, there's an actual distinction between least and greatest fixed point, but there isn't in Haskell.)
09:47:24 <dolio> Oh, and Maybe A = 1 + A = mu X. 1 + A, so you can say cata :: (1 + A -> B) -> mu X. 1 + A -> B, but as we've already seen, that's useless.
09:48:13 <acidjnk> hello
09:48:20 <dolio> In that case, you gain more by finding isomorphic versions of 1 + A -> B through other techniques (which is what leads to maybe).
09:48:42 <acidjnk> I tried :type ord, but got "<interactive>:1:0: Not in scope: `ord'". How can I use ord?
09:48:51 <dolio> ord is in Data.Char
09:49:06 <dolio> So you need to import it.
09:49:14 <acidjnk> thanks
09:51:05 <blueonyx> mh my ghc-pkg lists QuickCheck-2.1.0.1 but i cant import QuickCheck, any ideas why?
09:51:34 <dolio> Isn't the module named Test.QuickCheck?
09:51:41 <lilac> @hoogle QuickCheck
09:51:42 <lambdabot> package QuickCheck
09:51:42 <lambdabot> module Debug.QuickCheck
09:51:42 <lambdabot> module Test.QuickCheck
09:51:53 <blueonyx> ahh
09:52:19 <dolio> Debug.QuickCheck was in old versions.
09:52:23 <blueonyx> thanks again
09:52:53 <blueonyx> but the quickcheck script i found does it wrong, too
09:57:18 <hugo___> anyone knows when will ghc for ubuntu be updated ?
09:57:30 <hugo___> im currently using version 6.8.2, which is fine by me :P
09:57:45 <dolio> Whenever their next release is.
09:57:50 <luite_> I guess there won't be a backport for 8.10
09:58:18 <hugo___> luite_: why ?
09:58:19 <Botje> hugo___: i made a ghc 6.10 .deb
09:58:31 <Botje> but i'm not sure how good / bad it is
09:58:44 <hugo___> im just thinking that it might blow my current setup :/
09:58:49 <Botje> yeah
09:58:58 <dolio> hugo___: They've never done it before.
09:59:17 <Botje> perhaps i'll spend this weekend on making some .debs
09:59:35 <hugo___> hmm yes
09:59:42 <lilac> Botje: last i looked there was a debian project which provided ghc 6.10
10:00:19 <luite_> hugo___: installing by hand, and using cabal for installing libraries isn't so bad, by the way
10:01:02 <hugo___> luite_: i've had my share of stresses with that :/
10:01:04 <luite_> or it means that I'm just too lazy to use the proper ubuntu/debian way ;)
10:01:12 <hugo___> in opensuse
10:01:37 <luite_> hugo___: oh, I just make sure that everything is installed in some place where it cannot interfere with packaged files
10:02:04 <hugo___> somehow happs insisted on not working..., i replaced all the libs, still the same, something about closing the descriptor and not being able to serve the files :/
10:02:41 <hugo___> that is something i dont like that much, some haskell packages just use too much different libs and dif versions of them... :/
10:02:45 <luite_> hm, I do have some problem with ghc forgetting that some package is installed, but a reinstall with cabal usually fixes things
10:02:51 <hugo___> there should be a "release" for a package of libs
10:03:04 <hugo___> that ensures compatibility across dependencies of the major packages
10:03:33 <Botje> lilac: hmm? i searched but couldn't find one
10:03:35 <hugo___> i had to run things in ghci with the -package option, to ensure no compatibility issues
10:04:35 <hugo___> i think it would be a great project for some of the haskell gurus with some spare time: a "haskell-dev" release, a package with all the main libraries...
10:05:04 <hugo___> so i would just make a "update haskell-dev" and it would merge the newest version without any stresses
10:05:46 <luite_> hugo___: hmm, that probably has more to do with the cabal files not specifying dependencies (versions) well enough.
10:05:50 <hugo___> i mean, why are some many packages still using parsec 2 ?
10:05:52 <lilac> Botje: i was thinking of http://haskell-unsafe.alioth.debian.org/haskell-unsafe.html but they only have 6.6 (!)
10:05:53 <lambdabot> Title: Haskell Unsafe
10:06:04 <Botje> :)
10:06:46 <lilac> conal: afternoon
10:07:24 <conal> lilac: hi there.
10:07:34 <hugo___> i vote for kicking out of hackage all of the packages that are still using parsec 2 or any other discontinued package version, and sending a proper email to the maintainers... :P
10:07:54 <Botje> perhaps something like haskell-janitors
10:07:59 <vixey> write a program that updates all the old code
10:08:10 <vixey> hugo___
10:08:20 <lilac> conal: how's the comonadic reactive coming along?
10:08:34 <conal> lilac: great! :)
10:08:44 <luqui> what's this about a comonadic reactive?
10:08:47 <conal> lilac: the latest release has most of the comonads.
10:08:57 <conal> luqui: i thought you'
10:09:05 <conal> luqui: d be interested.
10:09:15 <vixey> where is the code? :)
10:09:25 <conal> @hackage reactive
10:09:25 <lambdabot> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/reactive
10:09:54 <lilac> conal: the docs are failing to build again :)
10:09:57 <conal> luqui: see yesterday's #haskell log
10:10:05 <luqui> ok
10:10:10 <conal> lilac: hm.
10:10:42 <conal> oh, urg.  haddock failure.
10:10:58 <conal> i forgot to test the docs
10:10:59 <Botje> i wonder how much work it'd be to automatically debify cabalized libs
10:11:46 <lilac> Botje: i'd not be surprised if it's already been done :)
10:11:59 <Botje> that'd be cool
10:12:07 <luqui> conal, okay, so  Behavior a = (Time, Time -> a)  ?
10:12:11 <Botje> then i could build them with ghc 6.10 and publish my repository :)
10:12:22 <lilac> luqui: relative time. Behaviour a = Time -> a
10:12:37 <conal> luqui: just T->a
10:12:38 <luqui> lilac, well that's not a comonad
10:12:43 <lilac> counit f =sem f 0
10:12:45 <luqui> oh
10:12:51 <luqui> ah I see
10:13:05 <luqui> Time is the type of realtive time, so extract = ($ 0)
10:13:08 <conal> luqui: it is when T is a monoid
10:13:16 <conal> right
10:13:22 <conal> the Sum monoid
10:13:30 <luqui> hmm, that's neat
10:13:35 <conal> yeah!
10:13:46 <lilac> i wonder how practically useful it'll be :)
10:14:00 <conal> luqui: replacing the Max monoid by the Sum monoid changes Reactive from absolute time FRP to relative time FRP.
10:14:07 <conal> which, of course, is much more composable!
10:15:00 <conal> and eliminates programming awkwardness and space leaks
10:15:04 <luqui> sure.  well the thing that I see (just now) in relative time FRP is that it's local.
10:15:20 <luqui> functional programming is good at making local things efficient
10:15:47 <conal> luqui: i use "local" and "relative" interchangeably
10:16:10 <luqui> yeah...   I was referring more to the implementation side
10:16:19 <conal> oh.
10:16:21 <conal> yeah
10:16:30 <conal> T->a vs (T,T->a)
10:16:39 <conal> i think either could work.
10:16:54 <luqui> yeah, their isomorphic under a translation
10:16:55 <conal> the latter is like comonadic arrays
10:17:05 <conal> yep.
10:17:15 <conal> i want to do the same thing for imagery.
10:17:35 <conal> (infinite continuous images)
10:17:36 <quicksilver> conal: Eek. There's something very suspicious about this reactive demo of mine.
10:17:46 <luqui> conal, so what's the representation?
10:17:47 <conal> quicksilver: yeah?
10:17:50 <quicksilver> conal: it doesn't leak memory. Not even a little bit.
10:18:00 <idnar> haha
10:18:02 <quicksilver> conal: rock solid 24.8M memory, over many minutes.
10:18:12 <luqui> quicksilver, !! :-)
10:18:17 <conal> luqui: almost unchanged.  Mainly swap out one monoid for another  (s/Max/Sum/g)
10:18:18 <lilac> that seems implausible
10:18:22 <dons> pretty cool use of haskell, http://www.reddit.com/r/programming/comments/7g7uf/eu_bus_regulations_are_np_hard_so_they_use/
10:18:24 <lambdabot> Title: EU bus regulations are NP hard ... so they use Haskell to enforce bus timetable  ..., http://tinyurl.com/5edets
10:18:49 <conal> quicksilver: great.  that's what i'd hope.
10:18:50 <luqui> conal, and an Event is now relative to some given start time?
10:18:57 <conal> yeah
10:19:00 <acidjnk> Is there a function "lowers"? In my book they use "... where n = lowers xs"
10:19:02 <luqui> hmm
10:19:12 <ksandstr> map toLower?
10:19:19 <conal> btw, i do know a solution for reactive's space leak, using weak refs for external inputs.
10:19:49 <luqui> conal, haha.  remember when I was suggesting Waiter instead of Event?   Future in relative time is Waiter :-)
10:20:07 <conal> luqui: oh, cool. i thought Future == Waiter.
10:20:17 <conal> and i guess it does with that monoid switch
10:20:34 <conal> luqui: i always wondered why you didn't just call it Future
10:20:42 <luqui> well it wasn't.
10:20:48 <luqui> in absolute time.   Time -> (Time, a)
10:21:01 <acidjnk> got it, they forgot to define it or I did not see it.
10:21:20 <conal> luqui: sounds like our ideas are converging.
10:21:34 <conal> luqui: i found your old post mentioning comonadic frp.
10:21:51 <newsham> luqui: where's your new blog?
10:21:59 <luqui> newsham, lukepalmer.wordpress.com
10:22:08 <newsham> tysir
10:22:33 <dons> oh, nice benefit of the new Fedora support for haskell. The installer gives you the option of a Ruby ,, Java or Haskell dev environment
10:22:34 <BMeph> So, who's gonna start writing comonad tutorials, now? ;p
10:22:35 <luqui> conal, yeah, it didn't really make sense though.  or maybe it did, in eg. realtive time, but I wasn't thinking that way
10:23:14 <newsham> dons: but its still fedora :(
10:23:20 <dons> heh
10:23:38 <quicksilver> conal: well I have a known leaky combinator.
10:23:41 <conal> luqui: the aha for me this week was discovering how useful cojoin is on behaviors.
10:23:59 <quicksilver> history = accumE [] . fmap (:)
10:24:07 <conal> luqui: i'm building a layer above behaviors & events for space-time-modular interaction.
10:24:09 <quicksilver> conal: such a nice simple definition, but not sensible.
10:24:21 <luqui> conal, what do you mean by that?
10:24:23 <quicksilver> turns out it was leaking, just much much slower than I feared.
10:24:28 <shapr> Does cabal install generate haddocks automatically?
10:24:45 <dcoutts> shapr: yes, if you --enable-documentation
10:24:48 <shapr> ah
10:24:53 <dcoutts> see --help
10:24:59 <conal> luqui: i mean something that represents *interactive* animations, which behaviors don't.
10:25:10 <conal> luqui: as can be seen from the semantic domain.
10:25:13 <quicksilver> BMeph: comonad tutorials aren't interesting until there are interesting comonads which show interesting behaviour under polymorphic comonad combinators.
10:25:22 <luqui> conal, interesting.
10:25:32 <luqui> conal, semantics?
10:25:38 <newsham> heh "reduceronian world"
10:25:51 <luqui> I would expect Behavior Input -> Behavior a...
10:26:05 <conal> luqui: yeah, though generalized some.
10:26:20 <conal> luqui: roughly, signal transformers, B i -> B o, but not necessarily single behaviors.
10:26:35 <conal> single behaviors leads to the (apparently) inherent inefficiencies of yampa
10:26:38 <dons> dcoutts: http://tap.ethz.ch/2009/ strictcheck
10:26:41 <lambdabot> Title: TAP: Tests and Proofs
10:26:51 <dcoutts> dons: mmm
10:26:54 <conal> but yeah, it's back to the motivation described in  "genuinely functional user interfaces"
10:26:56 <dons> Submission deadline: 15 February 2009
10:27:22 <dons> strictcheck, some scenarios (even say, a galois project), hpc to check coverage. done.
10:27:56 <luqui> conal, I'm just pondering.  All of my problems with reactive and all the related frp implementations have been assuming absolute time.  I might have to break my head a bit to think in relative time.
10:27:57 <Raevel> scary, one of dons' messages just turned up in another channel
10:28:00 <Raevel> good job irssi
10:28:04 <dcoutts> dons: data.bytestring is a real world example of course, eg the foldr bug
10:28:10 <dons> dcoutts: exactly.
10:28:16 <dons> and in the wild for a long time.
10:28:17 <luqui> I hope it is as expressive as I wanted the relative time versions to be
10:28:20 <dcoutts> dons: aye
10:28:28 <luqui> s/relative/absolute/
10:28:28 <conal> luqui: good!
10:28:36 <newsham> raevel: is it a screen refresh issue (ie. does it go away if you ^L)?
10:28:51 <Raevel> ah, indeed it does
10:29:04 <conal> luqui: i think you'll really like the direction i'm following.
10:29:39 <luqui> conal, well I like it semantically.  My practical side is worried though (but unsure, since I'm not thinking there yet).
10:30:05 <luqui> I've been wanting to make games and UIs with FRP, and I hope it is easy to do the things I want to do :-)
10:30:20 * quicksilver hopes the same.
10:30:23 <BMeph> quicksilver: In other words, we need to use them more before we can write about them?
10:30:28 <conal> luqui: i think it'll be crucial.
10:30:35 <conal> luqui: that's why i'm doing it.
10:30:36 <shapr> dcoutts: Thanks, trying it.
10:30:45 <shapr> y0 jethr0, long time no see!
10:30:56 <newsham> when i'm reading about FRP I can't help but feel its a lot more like engineering (particular circuits in EE) than traditional programming.. and it makes me wonder if FRP might be a better fit for visual programming than some other types of programming where.
10:31:02 <jethr0>  yo shapr, how's it going
10:31:08 <shapr> life is exciting!
10:31:15 <shapr> newsham: dataflow!
10:31:17 <jethr0> where are you at right now?
10:31:17 <dons> this is really worth a read guys, http://www.reddit.com/r/programming/comments/7g7uf/eu_bus_regulations_are_np_hard_so_they_use/  we need to get an experience report on what infrastructure they used to deploy haskell + C++ + Java in one app.
10:31:19 <quicksilver> BMeph: they're only interesting - from a programmer's point of view - when there are general combinators.
10:31:19 <lambdabot> Title: EU bus regulations are NP hard ... so they use Haskell to enforce bus timetable  ..., http://tinyurl.com/5edets
10:31:27 <newsham> the pong-type game written w/ arrows in an earlier FRP paper comes to mind
10:31:59 <jethr0> "a problem is NP-hard => so they use haskell" ^_^
10:32:00 <newsham> s/where/were/
10:32:14 <shapr> jethr0: Boston, want to visit?
10:32:18 <dons> jethr0: yeah. awesome.
10:32:20 <jethr0> i tried writing pong with yampa. it was a hell of a learning curve
10:32:23 <newsham> jethr0: if its already "hard" whynot use a hard programming language? ;-)
10:32:29 <shapr> jethr0: You got it working?
10:32:35 <quicksilver> BMeph: monads are interesting because of mapM and ap
10:32:42 <jethr0> more or less. I kinda quit when I had it mostly working
10:32:48 <shapr> jethr0: Got sources?
10:32:59 <shapr> dons: That's really cool!
10:33:00 <jethr0> integrating a computer adversary in yampa was beyond my patience
10:33:03 <newsham> jethr0: have you seen this (or the paper its from)?  http://www.thenewsh.com/~newsham/x/machine/paddleball.hs
10:33:08 <dons> it makes a lot of sense though, there's a long tradition of writing solvers/ constraint solvers/ provers in FP languages
10:33:11 <jethr0> shapr, sure I got the source somewhere, but the code is pretty ugly.
10:33:13 <jethr0> let me have a look
10:33:19 <luqui> conal, oh, in my pondering, I've kind of come to the feeling that building reactives on top of behaviors (rather than 'tother way 'round) is a cleaner and more powerful representation if it can be done efficiently.
10:33:22 <shapr> jethr0: Got it under an OSS license? :-)
10:33:27 <dons> but they went the whole way, integrating it into C++ and Java, deploying it. and running across the EU
10:33:35 <jethr0> newsham: my attempt is over a year ago. that site probably didn't exist then
10:33:39 <jethr0> ;)
10:33:43 <conal> luqui: interesting.  i'd love to hear more.
10:33:44 <luqui> conal, i.e. Behavior a = [Time] -> [a], Reactive a = Behavior (a,Time)
10:33:50 <luqui> (just as an example)
10:33:57 <newsham> jethr0: its taken from a 2001 paper
10:34:10 <jethr0> k, didn't find it back then
10:34:20 <luqui> where the Time in the Reactive is the time of its next step.
10:34:32 <jethr0> it took me ages to figure out how to differentiate the mouse movement and integrate it back in :)
10:34:47 <conal> semantically, is a Reactive more than a step function?
10:34:51 <vixey> differentiate??
10:34:54 <conal> luqui: ^^
10:34:57 <vixey> ITYM subtract (?)
10:35:02 <shapr> thoughtpolice: Got any code for the network-bytestring + binary idea?
10:35:15 <conal> luqui: for instance, can we tell when a reactive "changes" from 6 to 6?
10:35:16 <shapr> thoughtpolice: It sounds like erlang-style communication.
10:35:32 <luqui> conal, oh I see what you mean.
10:35:41 <thoughtpolice> shapr: no, but I've been meaning to hack something together for a while now
10:36:00 <luqui> conal, continuous computable semantics seem to indicate that we should do it that way
10:36:02 <conal> luqui: also, that reactive representation can have lots of nonsense, right?
10:36:08 <thoughtpolice> shapr: I think it would be a nice lightweight solution for distributed communication, esp. because stuff serialized with data.binary is platform-agnostic
10:36:14 <jethr0> vixey: the way i figured it out back then you get the acceleration of the mouse (by differentiating it) and then integrating it into the position of the paddle. or some such.
10:36:18 <luqui> conal, yeah, it's a subtype of Behavior (a,Time)
10:36:20 <conal> e.g., \ t -> (sin t, 0)
10:36:23 <conal> oh, ok
10:36:24 <jethr0> i'm far from an expert on FRP. It nearly drove me nuts
10:36:29 <shapr> dcoutts: Um, where does cabal put the docs?
10:36:36 <shapr> dcoutts: When it's working from --user?
10:36:40 <thoughtpolice> shapr: in ~/.cabal/share/doc iirc
10:36:52 <conal> jethr0: that's it's purpose.  to free you from conventional sanity.
10:36:54 <shapr> aha!
10:36:56 <scoo4114> :t map
10:36:57 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
10:37:30 <shapr> thoughtpolice: thanks
10:37:34 <jethr0> where can i upload a file on the web these days?
10:37:35 <conal> lilac: i fixed the doc bugs.  uploaded 0.9.6.  i don't know how often hackage runs haddock.
10:37:47 <shapr> jethr0: gmail it to me?
10:37:54 <jethr0> shapr: sure
10:38:06 <thoughtpolice> conal: it runs it like once every 6 hours with the build process i think
10:38:19 <jethr0> but as i said the code is horrible. it was exploratory programming and i never did figure out whether to put yampa or opengl as the master loop
10:38:26 <conal> thoughtpolice: thx.  i was wondering.
10:38:27 <shapr> Sounds interesting to me.
10:38:32 <jethr0> shapr: not sure i have your mail address handy right now
10:38:37 <conal> i wonder if we could get that frequency increased.
10:38:37 <shapr> shae.erisson
10:38:39 <shapr> for gmail
10:39:11 <conal> ideally, i'd like packages to be compiled & haddock'd immediately on uploading
10:40:07 <conal> i also wonder: does hackage announce package uploads here when they get compiled & haddock'd?
10:40:28 <dons> just when they're uploaded
10:40:55 <jethr0> shapr: "erisson" without a "c"?
10:40:59 <conal> jethr0: i was only half-joking there.  frp is a radically different way to think about the questions answered by imperative programming.
10:41:53 <shapr> jethr0: That's me, I'm not Shane Ericsson, I'm Shae Erisson
10:41:56 <jethr0> conal: what i liked about it (and about functional programming in general) is that FRP describes the whole game state (in this case) totally.
10:42:26 <conal> jethr0: across its whole timeline
10:42:27 <jethr0> In imperative languages you always describe conditionals, but with FRP I had the feeling of defining a time-independent (or rather for all time) description of the logic
10:42:37 <jethr0> shapr: ^_^
10:42:49 <conal> shapr: yeah!  that's the idea.
10:43:48 <lament> haha, shane ericsson
10:44:16 <Beelsebob> lament: ?
10:44:53 <shapr> lament: That's how I get put into most systems, some combination of that.
10:45:18 <shapr> Also Errison, for whatever reason.
10:45:36 <shapr> I guess that's more like "harrison"
10:45:43 * shapr shrugs
10:45:47 <shapr> Anyway...
10:46:08 <jethr0> sorry for getting you all fired up about this
10:46:13 * shapr grins
10:46:30 <conal> jethr0: my last comment was meant for you.
10:46:53 <olsner> I want to play with this awesome FRP thing too!
10:46:53 <jethr0> conal: i figured as much. so, do you work with FRP much these days?
10:46:58 <shapr> heh
10:47:33 <conal> jethr0: that temporally completeness is what lets FRP behaviors be both *immutable* and *about change*
10:48:03 <conal> jethr0: yes.  i work on frp a lot.  in the form of the Reactive library
10:48:14 <ertai> I'm looking for an advice about choosing where to place a module in the hierarchy
10:48:16 <conal> @wiki reactive
10:48:16 <lambdabot> http://www.haskell.org/haskellwiki/reactive
10:48:19 <jethr0> right, so that WAS you...
10:48:21 <shapr> jethr0: Thanks!
10:48:36 <shapr> ertai: What is it?
10:48:36 <ertai> that's a module to handle the mbox format
10:48:40 <Peaker> conal: how would I go about debugging the Event -> Behavior -> Event -> Behavior  bug on my own?
10:48:44 <ertai> Codec.Mbox ?
10:48:57 <shapr> ertai: Nothing better jumps to my mind.
10:49:13 <conal> Peaker: oh yeah.  that one.  looking again...
10:49:36 <jethr0> conal: what i had the hardest time figuring out was how to interface this time-completeness with more imperative code (i.e. networking or AI). to get imperative code (i.e. open gl events) into the all-time-view was really hard to do mentally for me
10:49:53 <ertai> shapr: thanks, let's go for Codec.Mbox
10:50:02 <conal> Peaker: sry. i've been in a comonadic mania
10:50:04 <Peaker> jethr0: you mean GLUT events?  Or what events does OpenGL itself have?
10:50:11 <newsham> jethr0: the reactive library has separate concepts for events and time-dependant behaviors
10:50:19 <jethr0> may have been glut
10:51:16 <jethr0> well, for some reason I quit my yampa experiment (not least because it was hurting my brain so much). but I definitely liked the concept of describing logic this way.
10:51:22 <conal> Peaker: i'm confused.  works and doesntWork don't even have the same type
10:51:35 <newsham> jethr0: check out conal's Reactive paper, and this blog http://netsuperbrain.com/blog/
10:51:36 <lambdabot> Title: Less Sugar/More Meat
10:51:46 <jethr0> I hope reactive gui programming will become the norm, because the state of imperative gui logic is just aweful.
10:52:18 <newsham> (and conal's blog)
10:52:25 <conal> jethr0: agrees.  sequential imperative programming is such an awful fit for GUIs
10:52:32 <Peaker> conal: sec, let me look again
10:52:49 <ddarius> concurrent imperative programming fits much better
10:52:53 <Peaker> trac is so paranoid about logins, it remembers them for about 1 hour ..
10:53:01 <jethr0> you're so likely to get something wrong when having to handle all kinds of events manually and dispatching them to the correct gui elements.
10:53:15 <ddarius> jethr0: Use more concurrency.
10:53:20 <jethr0> fruit and the reactive guis solve this nicely and I hope to master them someday
10:53:23 <Peaker> conal: right, I only (FT.utext . show) on them
10:53:49 <Peaker> conal: so the type can be different, they're both behaviors though
10:54:34 <Peaker> conal: showing the original behavior that is built with accumB on the keyboard input works.  Showing a stepper of a snapshot of that behavior fails (doesn't show any change at all)
10:55:09 <jethr0> ddarius: maybe. but the idea of just wiring gui components is really nice. a much nicer paradigm then dispatching arbitrary events to the correct widget
10:55:37 <ddarius> jethr0: By concurrent, I mean threaded v. event-based.
10:55:55 <ddarius> Most GUI libraries are event-based.
10:56:42 <jethr0> ddarius: again, i am out of my depth. but how do threaded solutions work for connecting widgets with some logic? wouldn't it still be based on events?
10:56:54 <ertai> shapr: what about the package name, mboxlib, mbox, mbox-codec...
10:57:26 <jethr0> shapr: and yes, the code i just mailed to you is dual licensed under BSD and GPL license
10:57:27 <Peaker> ddarius: I always thought "concurrent" meant things that appear to happen simultaniously (event driven qualified) and parallel is actually running in parallel (e.g multi-core) and event-driven does not qualify
10:57:56 <Peaker> conal: is it still confusing?
10:58:00 <shapr> jethr0: spiffy
10:58:23 <jethr0> feel free to build a gaming empire with it
10:58:29 <ddarius> Peaker: In a general use of the word, yes, event-based concurrency is a form of concurrency.
10:58:36 <shapr> ertai: Some people would use libmbox (libmpd is an example),but mbox-codec is fine as well.
10:59:21 <ddarius> jethr0: There is still some notion of "event," that's a domain concept it can't go away, but FRP still has a notion of event.
10:59:49 <jethr0> ddarius: can you point me to any framework that take this approach?
11:00:01 <ertai> shapr: I going to use just mbox
11:00:20 <shapr> ertai: Ok
11:01:24 <ddarius> jethr0: Not a widely used one off the top of my head though I'm sure some exist, but luckily it is feasible (more reasonable in some languages than others) to build such a system over top of an event-based GUI.
11:01:33 <ddarius> @google "A Concurrent Windowing System"
11:01:35 <lambdabot> No Result Found.
11:01:38 <ddarius> @google "A Concurrent Window System"
11:01:43 <lambdabot> http://citeseer.ist.psu.edu/pike89concurrent.html
11:03:45 <dolio> > uncurry . curry . const 1 $ undefined
11:03:46 <lambdabot>       No instance for (Num ((a, b) -> c))
11:03:46 <lambdabot>        arising from the literal `1'...
11:04:44 <jethr0> @type undefined
11:04:45 <lambdabot> forall a. a
11:04:48 <dolio> > (uncurry . curry $ const 1) undefined
11:04:50 <lambdabot>   1
11:04:51 <conal> Peaker: i'm back.  got a phone call from my brother.  thx for the explanation.
11:04:52 <jethr0> @type ()
11:04:53 <lambdabot> ()
11:05:07 <dolio> > (uncurry . curry $ \(a,b) -> 1) undefined
11:05:08 <lambdabot>   1
11:06:03 <conal> i agree that concurrent imperative programming fits GUIs better.  however, it's also a semantic and pragmatic nightmare.
11:06:24 <conal> (catching up)
11:07:16 <ddarius> conal: Yeah, I'm not saying it is better than FRP (but I can't really draw a strong conclusion yet), but it's certainly much better than an event-loop based system.
11:08:47 <conal> discussions of "concurrent" and "parallel" usually address implementation issues.  there are also semantic issues.
11:09:10 <newsham> i think event-loop based and concurrent are inherently equivalent
11:09:25 <conal> newsham: as implementations?  as semantics?
11:09:37 <newsham> i guess i mean semantically
11:10:00 <conal> oh -- i forgot my bias again.  by semantically i mean denotationally.
11:10:01 * dolio mutters about 'threading is dual to event-based'.
11:10:09 <conal> not operationally
11:10:29 <Peaker> ddarius: in the threaded approach, what kind of synchronization takes place?  Do you mean using STM, MVars, or..?
11:10:31 <jethr0> newsham: you mean turing-equivalent? ;)
11:10:38 <newsham> i can trivially write a userland threads library to transform an event loop into a concurrent model
11:10:58 <ddarius> newsham: They're dual.
11:11:14 <ddarius> newsham: And yes, you can transform one to the other... using continuations.
11:11:26 * conal bows out of the implementation discussion
11:11:29 <hackage> Uploaded to hackage: reactive 0.9.6
11:11:38 <dolio> What was the name of that paper...
11:11:45 <ddarius> dolio: There is more than one.
11:11:49 <Peaker> ddarius: I think I prefer a solution based on single-threaded event loops over any lock-based (e.g MVar) solution, because there's so much less to worry about, and much more determinism
11:11:51 <dolio> Yeah, yeah.
11:12:15 <Peaker> ddarius: but a threaded solution which does not introduce non-determinism and deadlocks could be great (e.g some FRP implementations)
11:12:16 <ddarius> Peaker: Read the link I referenced above.
11:13:06 <ddarius> Peaker: Event loops definitely have some things to recommend them, but composability is not one of them.
11:13:31 <Peaker> ddarius: MVar-based code is even harder to compose..?
11:13:33 <newsham> peaker: if concurrency is your main enemy, sure.  but event-loop bsaed code can be complex in other ways... the code is often hard to follow and scattered all over the place
11:13:46 <ddarius> Peaker: I've never said anything about MVars or locks.
11:14:01 <Peaker> newsham: you know Twisted, right?
11:14:11 <newsham> peaker: thats exactly whta i had in mind when i said that
11:14:30 <Peaker> the "here's the PDF, reply to that please" approach is so much more fitting to email than IRC :-)
11:14:46 <Peaker> newsham: I don't think Twisted causes code to be scattered all over the place
11:14:48 <dolio> Evidently I didn't bother to put those papers in my "concurrency" papers folder...
11:14:56 <lilac> what's the best way to do time profiling?
11:15:03 <lilac> or at least, the simplest
11:15:31 <lilac> recompiling all of my deps with -prof looks to be a pain
11:15:42 <newsham> peaker: consider    read 5 bytes; process; send 5 bytes; change state; loop
11:16:13 <newsham> most programmers would write that in a linear fashion w/o a framework.  with a twisted-like framework you put those pieces in separate event handlers.
11:16:53 <newsham> it loses some of its linearity (in the reading sense)
11:17:23 <Peaker> newsham: "read 5 bytes" is not really a concurrent operation, how do you perform 2 of these at the same time?
11:17:43 <Peaker> newsham: In Twisted, you can do something like:  def dataReceived(self, data):  self._current_generator.send(data)     ; and then your code is linear just like that
11:17:47 <Peaker> newsham: (with some yields)
11:17:54 <dolio> You can perform it at the same time as "process".
11:18:18 <newsham> it can be concurrent in that you may have several clients that you are processing concurrently
11:19:05 <zeeeee> hi, in the following snippet, how can `sort` have the type being inferred by the compiler? http://gist.github.com/30056
11:19:06 <lambdabot> Title: gist: 30056 — GitHub
11:19:50 <Peaker> newsham: twisted code with python generators can be completely linear until it is no longer simple enough to represent linearly at all
11:19:56 <newsham> zee: what are the types of your other functions?
11:20:05 <Peaker> newsham: so I can't identify much with the non-linear disadvantage of that style
11:20:33 <newsham> peaker "(with some yields)"
11:20:55 <Peaker> newsham: yields are merely explicit context switches, not "code all over the place"
11:21:02 <newsham> ie. "we secretly replaced our event loop with coroutines, lets see if anyone notices"
11:21:14 <zeeeee> newsham, i didn't specify their types so they are what the compiler infers
11:21:33 <Peaker> newsham: well, event-callbacks VS coroutines is not a very significant difference beyond style, at least in a language with closures
11:21:34 <newsham> zee: ask the compiler what they are?
11:21:36 <ksandstr> zeeeee: from the way that the function deals with lists, and the contents of the lists are used with comparsion operators.
11:22:09 <newsham> peaker: events+coroutines == thread library
11:22:11 <ksandstr> zeeeee: the comparison operators are in the Ord class, thus Ord a => [a] -> [a]
11:22:25 <Peaker> newsham: not quite, because they don't yet introduce non-determinism
11:22:31 <filcab42> hi all
11:22:36 <zeeeee> newsham, oh, i knew what they were - merge :: (Ord t) => [t] -> [t] -> [t] and split :: [a] -> ([a], [a])
11:23:20 <zeeeee> ksandstr, i just don't understand how i can have [t] in and [a] out for sort
11:23:35 <zeeeee> i was expecting just a single type: (Ord t) => [t] -> [t]
11:23:38 <filcab42> I'm having a little problem installing array-0.1.0.0 in MacOSX, using cabal
11:24:12 <ksandstr> zeeeee: because split's constraints are looser than those of merge. this is because split doesn't do anything with the list elements, thus it has type [a] -> ([a], [a])
11:24:28 <filcab42> Duplicate instance declarations: instance Typeable2 IOArray@Data/Array/IO/Internals.hs--- and instance [overlap ok] Typeable2 IOArray@base:Data.Typeable
11:24:34 <filcab42> any clues on how to fix it?
11:24:43 <filcab42> btw, ghc 6.10.1
11:25:07 <zeeeee> ksandstr, yeah, but doesn't the fact that they're composed as functions mean that the more restrictive type of the two is used?
11:25:38 <zeeeee> perhaps another way to ask is, is there a simpler example of this kind of phenomenon than the one i gave?
11:25:40 <dolio> zeeeee: I bet your sort function never terminates.
11:25:58 <zeeeee> dolio, it indeed doesn't, but i was mainly wondering why the types are the way they are
11:26:01 <newsham> zee: your sort program does not terminate for all inputs
11:26:06 <dolio> zeeeee: The types are a clue to that.
11:26:20 <zeeeee> dolio, this was an example given in an oopsla talk, and i was just hung up on the types here; the infinite loop bug is clear
11:26:23 <zeeeee> tom e
11:26:24 <ksandstr> zeeeee: no, not really. the merge function just has tighter constraints than split.
11:26:25 <zeeeee> *to me
11:26:32 <dolio> zeeeee: It says that the output is unrelated to the input, more or less.
11:26:45 <dolio> At least, unrelated in a key way.
11:26:51 <newsham> zee: trace what happens when you sort "x"
11:26:56 <zeeeee> dolio, http://perl.plover.com/classes/OOPSLA/samples/slide069.html
11:27:04 <lambdabot> Title: sort [] = []
11:27:29 <zeeeee> the talk doesn't really explain the types though
11:28:41 <dolio> zeeeee: Since it's 'Ord a => [t] -> [a]', that tells you that none of the elements in the input list can be in the output list (otherwise they'd both be using the same variable).
11:29:38 <newsham> zee: do you see the problem?
11:30:20 <dons> ?users
11:30:20 <lambdabot> Maximum users seen in #haskell: 552, currently: 519 (94.0%), active: 19 (3.7%)
11:30:22 <zeeeee> dolio, ok... so i guess that this inference result is directly due to the infinite recursion
11:30:36 <lilac> zeeeee: it's a classic bug actually :)
11:30:49 <zeeeee> lilac, what do you mean? the split?
11:30:58 <lilac> no, your function doesn't work
11:31:10 <zeeeee> lilac, yeah the bug is in split
11:31:17 <newsham> the bug is in sort
11:31:19 <lilac> zeeeee: no, the bug is in sort.
11:31:25 <newsham> [09:21] < newsham> zee: trace what happens when you sort "x"
11:31:47 <ksandstr> or sort x, where length x is odd
11:31:52 <zeeeee> oops, i meant sort
11:31:53 <lilac> zeeeee: the type signature tells you that the only value that function can return other than bottom is []
11:32:06 <zeeeee> i think i see how the inference worked there now
11:32:08 <lilac> or arguably a list of bottoms
11:32:09 <dolio> Now the big question: is annotating your functions at the top-level a good idea, since in this case, not-annotating demonstrated that your code has a bug?
11:32:37 <ksandstr> dolio: annotating it would've displayed a contradiction between the annotation and the definition, right?
11:32:37 <lilac> dolio: perhaps a 'most general type' annotation might be handy?
11:32:41 <zeeeee> dolio, that is a good question :)
11:32:53 <ksandstr> so it sort of comes down to what kind of error you prefer
11:32:53 <lilac> ksandstr: no, the annotated type is compatible with the inferred one
11:33:01 <ksandstr> ah, drat.
11:33:12 <dolio> ksandstr: No. It would have been accepted, because Ord a => [a] -> [a] is a specialization of the type that's inferred.
11:33:50 <newsham> "attempting to prove any nontrivial theorem about your program will expose lots of bugs.  The particular choice of theorems makes little difference." -pierce
11:33:51 <thoughtpolice> on and dons, re. that whole bus-roster-NP-hard-java-C++-dll thing, I have taken a similar approach; I compiled my haskell code to a .so and loaded it from C code
11:34:07 <dons> thoughtpolice: very cool. do you want  to document that on thhe wiki?
11:34:11 <thoughtpolice> dons: it's not difficult to do, it's just fiddly and requires a little setup.
11:34:17 <dons> right
11:34:27 <thoughtpolice> mainly because you have to use gcc as the linker
11:34:30 <dons> http://haskell.org/haskellwiki/Calling_Haskell_from_C
11:34:31 <lambdabot> Title: Calling Haskell from C - HaskellWiki
11:34:33 <conal> Peaker: i'm in the midst of (happy) family chaos right now.  i'll have to look at that bug later.
11:34:36 <dons> we should build this stuff up here, imo.
11:34:44 <thoughtpolice> so you have to set up the lib/include paths and also link in all the proper 'libHS....a' libs
11:34:45 <dons> so we can point to simple rules for integrating haskell into other apps
11:34:47 <dons> yep
11:34:50 <thoughtpolice> dons: yeah I can probably put something together
11:35:03 <Peaker> conal: okay, but at least its clear what I was experiencing there?
11:35:16 <thoughtpolice> dons: I deleted the code that did that a long time ago; calling haskell code in a .so from C was literally like my 2nd haskell experiment
11:35:27 <thoughtpolice> but i could hack something up quick surely
11:36:02 <dons> i think its ridiculously important to show how to call haskell from C/C++/Java
11:36:11 <dons> since that's how we get people to write new components in better languages.
11:36:25 <thoughtpolice> yeah
11:36:35 <thoughtpolice> hopefully things like this will be tremendously easier
11:36:46 <thoughtpolice> once shared library support makes it into GHC and is actually stable
11:37:00 <thoughtpolice> the whole shared-lib thing has been going on since the 06 SoC hasn't it?
11:37:10 <dons> yep
11:37:20 <dons> i think its a matter of building demand now
11:37:47 <arw> there is demand. lots of it.
11:38:12 <thoughtpolice> there were other reasons behind why it was taking so long according to JaffaCake iirc
11:38:33 <dons> and just documenting what the current state is.
11:38:44 <dons> its a key enabling technology, which works *now*. we just have to train people
11:39:01 <arw> the only cause for C beeing lingua franca for writing libraries is that its awfully hard to link/call anything else written in c++, java or some scripting language
11:39:10 <dons> yup
11:40:20 <arw> the only other language i know of which really supports linking to anything very well is fortran. but maybe i got the wrong sample there as a physicist :)
11:40:45 <dons> well, it's easy enough to call haskell to and from C. which means anything else that can call C can also call Haskell
11:40:50 <ksandstr> i thought the killer app for shared libraries in haskell was the "helloworld in less than 250KiB"
11:40:53 <dons> but DLLs / .so's are not so well documented
11:41:11 <dons> ksandstr: no, not really. that's a nice thing, but not crucial
11:41:17 <dons> apparently disk space is cheap now.
11:41:23 <dons> so 250k for the runtime doesn't hurt too much
11:41:32 <ksandstr> there is that, yes.
11:41:42 <dons> i hear less about this now than 4 years ago, and expect to hear even less in 4 years time
11:41:48 <dolio> Isn't that the jhc killer ap?
11:41:55 <conal> Peaker: yes, thanks.
11:42:06 <Aviator> ok i want to pass a file descriptor to a c function through ffi, how do i initialize the file descriptor?
11:42:17 <Aviator> i don't know any c, this is painful
11:42:19 <thoughtpolice> dolio: well, jhc produces really small executables for other reasons
11:42:42 <thoughtpolice> notably because pretty much 100% of the code is subject to aggressive optimizations/dead code elimination
11:42:46 <dolio> Yeah.
11:42:59 <dolio> But, it gets harder to actually successfully build programs as they get larger.
11:43:00 <thoughtpolice> but I wouldn't say that's jhc's "killer app"
11:43:10 <dolio> But "hello world" is well within its abilities. :)
11:43:15 <thoughtpolice> i know
11:43:20 <thoughtpolice> i'm working on a fork of it :]
11:43:21 <olsner> disk space is cheap, disk *bandwidth* is kind of expensive
11:43:30 <thoughtpolice> dolio: me and Lemmih are trying to tackle that, fwiw.
11:43:34 <dolio> Sweet.
11:43:52 <thoughtpolice> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/lhc-0.6.20081127
11:43:58 <lambdabot> Title: HackageDB: lhc-0.6.20081127, http://tinyurl.com/6qwpom
11:44:16 <dolio> Someone was saying it's not actually all that fast anymore compared to ghc.
11:44:21 <dolio> Just small binaries.
11:44:26 <dolio> But I don't know how true that is.
11:44:29 <thoughtpolice> it can still produce some really damn fast code.
11:44:30 <arw> olsner: never assume that anything is cheap. "fast processors are cheap" killed the first years of java.
11:44:54 <dons> anyway, who didn't deploy their haskell program because it was n + 250k ?
11:45:02 <dolio> It may have to do with aggressive work in some areas of ghc that aren't addressed by things j/lhc does.
11:45:07 <dolio> Like IO performance.
11:45:34 <dolio> I don't know what they were actually using as a test program.
11:45:55 <arw> dons: i know somebody who thought of doing embedded development in haskell. embedded as in "16K RAM? how luxurious"
11:46:02 <thoughtpolice> dolio: e.x. http://thoughtpolice.stringsandints.com/code/lhc-tests/bench/ <- loop.hs is from nobench; if you compile with GHC (along with -O2 -funbox-strict-fields -fexcess-precision -ffast-math -optc-O3 -fvia-C etc.) and you run as './loop 100000000', the code takes about 3 seconds. for lhc, the same program with the same input only takes 0.2 seconds
11:46:07 <lambdabot> Title: Index of /code/lhc-tests/bench
11:46:08 <ksandstr> dons: it probably just turns old farts off a new language, nothing more
11:46:09 <newsham> dons: shapr, on his cell.
11:46:10 <thoughtpolice> dolio: I wanted to test it on recursive as well but uh,
11:46:16 <dons> arw: that needs custom tools though.
11:46:20 <thoughtpolice> jhc/lhc's region inference algorithm is currently broken
11:46:29 <dons> ksandstr: well, they're not using any high level language, so that's fine :)
11:46:33 <thoughtpolice> so if you don't compile with a flag to change the memory management
11:46:42 <thoughtpolice> recursive will start gobbling up 900mb+ of memory
11:46:44 <thoughtpolice> almost immediately
11:46:46 <dolio> thoughtpolice: From the shootout?
11:46:46 <thoughtpolice> which isn't cool
11:46:49 <arw> dons: yes, of course you need to be able to compile to that architecture.
11:46:50 <thoughtpolice> yeah
11:46:51 <newsham> arw: also 16k ram is pretty small these days even in embedded systems
11:46:56 <dolio> That would be interesting to see.
11:47:11 <dons> i'm more interesting in making sure we run on say, the iphone or android phones
11:47:15 <arw> dons: the idea was, that its very easy to write proofs about haskell, but not so much about C...
11:47:16 <dolio> GHC still lags a ways behind the top contenders in that one.
11:47:26 <dons> and that's fine. they run things like java there, so small footprints like ghc /haskell are no worries
11:47:36 <dons> arw: right. we do this for FPGAs.
11:47:40 <dolio> And, as Jon Harrop points out, you'd think functional languages would be better than they are at function application. :)
11:47:45 <dons> use haskell EDSL. prove it. generate code
11:48:05 <dons> arw: see also Eaton's work on hydraulic bus controllers generated from haskell
11:48:08 <dons> on the haskell wiki
11:48:24 <dons> so don't run haskell on the tiny device. use it as the language for specifying the code to run on the device
11:48:33 <arw> uh, sounds interesting, i need to look that up...
11:48:36 <thoughtpolice> dolio: also, more important than small bin. size, is lhc/jhc's ISO C output if you ask me
11:48:39 <thoughtpolice> which is awesome :]
11:48:47 <olsner> arw: I can easily buy enough disk space that it takes a day to even touch it all on standard hardware (and I can hook it up to a computer), if I want that to go faster there's not much I can do without getting special hardware that's a lot more expensive... ergo, disk space is currently much cheaper than disk bandwidth :)
11:48:52 <dolio> Certainly handy for cross compiling.
11:48:54 <dons> arw: http://cufp.galois.com/2008/abstracts.html#HawkinsTom
11:48:55 <lambdabot> Title: Commercial Users of Functional Programming 2008 Program
11:48:57 <arw> dons: thats what that person did before, with a java to c compiler.
11:49:10 <dolio> Or, bootstrapping on a new system, as it were.
11:49:45 <thoughtpolice> dolio: yeah, if we ever get to the stage of LHC being able to compile itself, well,
11:49:48 <dons> reddit's jumped the shark. we get what might possibly be one of the most interesting industrial uses of haskell, and no one cares. http://www.reddit.com/r/programming/comments/7g7uf/eu_bus_regulations_are_np_hard_so_they_use/
11:49:50 <thoughtpolice> haskell for everyone, everywhere!
11:49:50 <lambdabot> Title: EU bus regulations are NP hard ... so they use Haskell to enforce bus timetable  ..., http://tinyurl.com/5edets
11:49:56 <thoughtpolice> (or ghc becomes a cross compiler)
11:49:59 <thoughtpolice> (whatever happens first)
11:50:02 <dons> that would have been reddit crack 12 months ago
11:50:48 <Igloo> dons: Can you tell what rank an entry has from its page, BTW?
11:51:00 <thoughtpolice> dons: also I'll write something up about the haskell dll thing, blog and put some example on that wiki page
11:51:13 <dons> Igloo: from the front page.
11:51:21 <dons> thoughtpolice: wonderful!
11:51:44 <Igloo> dons: But that involves finding it, and it may not be in the first 25 (or whatever it is)
11:51:47 <dons> Igloo: can 'documented support for using Haskell DLLs" be a goal for 6.12?
11:51:52 <dons> Igloo: right
11:52:15 <newsham> dons: the biggest complaint I hear about whenever i try to pitch haskell to people is "where am I going to find developers who can write in haskell?"
11:52:19 <dons> btw, we have the haskell reddit now, which is much more focused, http://www.reddit.com/r/haskell/
11:52:20 <lambdabot> Title: Haskell
11:52:23 <dons> ?users
11:52:23 <lambdabot> Maximum users seen in #haskell: 552, currently: 522 (94.6%), active: 20 (3.8%)
11:52:23 <Igloo> dons: So the answer to my original question is "no"?
11:52:24 <dons> ^^ here
11:52:42 <newsham> dons: if you have good ideas for giving positive answers to that question, i think the pitch would be a lot easier
11:52:44 <dons> Igloo: to find the rank, visit the front page and scroll. yes
11:52:44 <Igloo> dons: There are already docs, aren't there?
11:52:53 <Igloo> dons: Patches to improve the docs would certainly be welcomed, though!
11:53:08 <dons> Igloo: well, how did these http://www.haskell.org/communities/11-2008/html/report.html#sect7.7 guys integrate haskell DLLs with Java and C++ ?
11:53:09 <lambdabot> Title: Haskell Communities and Activities Report, http://tinyurl.com/6f36nz
11:53:27 <dons> if we did a good job there, we'd massively improve our deployment options, and open up new users
11:53:47 <dons> i imagine C wrappers, foreign export as usual. and lots of linker flags?
11:53:58 <dons> so specifying precisely what you'd need to do would be an invaluable resource
11:54:11 <ddarius> Peaker: Incidentally, there is "less to worry about and more determinism" in event-loop systems compared to threaded systems only insofar as the former is coarser, which doesn't have to be the case at all.
11:54:16 <Igloo> Perhaps ask them to write something about it, then?
11:54:18 <dons> yes
11:56:47 <Peaker> ddarius: coarser-grained in context switches, you mean?
11:57:34 <ddarius> Peaker: Kind of, though that's lower level than necessary.
11:58:25 <Peaker> ddarius: I think the important difference is not how fine-grained it is, but the fact that it is explicit in event-based systems.. You can access shared state "atomically" without having to lock anything
11:59:15 <ddarius> Peaker: You can do that just as well in a cooperatively threaded system.  In fact better since you are limited to the granularity of the events.
11:59:42 <Peaker> ddarius: would you agree that cooperative threads are basically coroutines?
12:00:05 <ddarius> Peaker: You can easily implement them given coroutines.
12:00:24 <Peaker> ddarius: I'm not sure I understand what differences there are?
12:00:26 <arw> Peaker: that is only possible if you don't need parallelism for anything, which is getting less common given the trend towards multiple processors
12:01:01 <Peaker> ddarius: I think the differences between coroutines and event callbacks is pretty minor and superficial, especially when you have closures.. The real difference is between preemptive multitasking and cooperative multitasking
12:02:20 <filcab42> Hi
12:02:29 <ddarius> Peaker: The main difference between preemptive multitasking and cooperative multitasking is granularity.  Also, if you fired off events while others were still ongoing, corresponding to preemptive multitasking, you'd get the same problems as preemptive threading.
12:02:47 <BMeph> Peaker, ddarius: Lua programmers have been dealing with this stuff for fifteen years; there should be some good discussions to pick over in their info-space. :)
12:02:58 <BMeph> filcab42: Hi
12:03:15 <Peaker> ddarius: I disagree that the main difference is granularity, I'd say the main difference is explicitness/determinism
12:03:27 <Peaker> ddarius: and indeed firing the events as they occur is basically preemptive
12:03:32 <ddarius> BMeph: People have been dealing with stuff before Lua was a twinkle in anyone's eye.
12:03:32 <filcab42> I wanted to do something like: foldr (*) [1,2,3,4,5], but ghc complains that I need an instance declaration... It must know which of the Num instances it will use when compiling? So, I can't just define a factorial by folding (*) over an enumFromTo?
12:03:40 <Peaker> ddarius: Though maybe I was wrong to say preemptive, because there's also the truly-parallel case
12:03:59 <Deewiant> ?ty foldr (*) [1,2,3,4,5]
12:04:00 <lambdabot> forall t. (Num t, Num [t]) => [[t]] -> [t]
12:04:08 <Peaker> ddarius: Python-twisted style code can be event-callback based, and the code is still linear, you have the closures that handle the linear case one after another, and each registers the next.  The coroutine based solution just has a bit less syntactic callback registration noise
12:04:36 <filcab42> ah, damn!
12:04:39 <filcab42> forget it :$
12:04:40 <Deewiant> filcab42: you're giving [1,2,3,4,5] as the initial element: it expects to do [1,2,3,4,5] * (list !! 0) * ...
12:04:50 <filcab42> missed the second argument to fold... Sorry :P
12:04:53 <povman> may i ask what 'twisted style' means?
12:05:03 <Peaker> ddarius: IOW, a coroutine/cothread "blocking" on a result to make the continuation code wait, is pretty much equivalent to code that registers the continuation as a callback
12:05:11 <BMeph> ddarius: Well, yes, but mainly they've been dealing with it as a concept, as what-if. With Lua, it's an active concern. Not to say that there isn't lots of literature outside of Lua, just saying that it's an integral concern, and thus, concentrated on explicitly. :)
12:05:13 <ddarius> Peaker: It is equivalent.
12:05:50 <Peaker> ddarius: oh, wasn't sure we agree that event callbacks and coroutines are basically equivalent (not just turing-equivalent, but also in terms of ease/etc)
12:06:05 <filcab42> Yup... as always... PEBKAC :-)
12:06:36 <ddarius> Peaker: They're not really equivalent in terms of "ease/etc" unless you just implement coroutines on events which, as newsham said, is just implementing (cooperative) threaded concurrency.
12:06:56 <Peaker> ddarius: now if you fire up the events in parallel, or switch to other handlers preemptively, then suddenly shared state is hard, determinism is lost.  If you try to restore determinism with locks, you lose either modularity or you introduce deadlocks, etc
12:07:25 <ddarius> Peaker: Yes, and this is still the same thing that happens in event system, the locks are just not called "locks"
12:08:07 <ddarius> And even without preemptive switching, you still have the problem in event-based systems or overly fine-grained cooperative threaded systems.
12:09:23 <Peaker> ddarius: in the event system, there's just one big "lock", so there are no deadlocks or modularity issues
12:09:31 <flux> the problem in event-based systems is a lot smaller, because you always know when you lose your turn
12:10:02 <filcab42> ?ty enumDeltaToIntegerFB
12:10:03 <lambdabot> Not in scope: `enumDeltaToIntegerFB'
12:10:05 <Peaker> ddarius: and if something doesn't explicitly involve a scheduler yield, then its atomic, which is a very nice property
12:10:12 <Peaker> gtg
12:10:13 <ddarius> Peaker: Yes, I can only provide a "global lock" operation in a cooperative (or preemptive) threaded arrangement.  Using a global lock just increases granularity.
12:10:18 <thoughtpolice> @tell Lemmih is LHC using a darcs2 repository? if not I suggest we go ahead, switch it over to darcs 2, and then push it back to code.haskell.org
12:10:18 <lambdabot> Consider it noted.
12:10:24 <ddarius> Peaker: The problem is you may need to spread over multiple events.
12:10:25 <filcab42> damn... Where can I look for stuff about GHC's internal functions?
12:10:40 <ddarius> You are only as atomic as the events are coarse.
12:11:08 <Peaker> ddarius: importantly, the exact level of coarseness is visible through explicit control yields
12:11:29 <hackage> Uploaded to hackage: uniplate 1.2.0.2
12:11:54 <ddarius> Peaker: The -minimum- level of coarseness is visible.
12:12:22 <dolio> Oh snap, new uniplate.
12:12:30 <filcab42> ?ty and
12:12:31 <lambdabot> [Bool] -> Bool
12:13:02 <ddarius> Peaker: The problem is that you can't make larger blocks of coarseness without doing something that's essentially locking (and easily finer grained locking than globally)
12:17:51 <dons> anyone received any RWH copies here yet?
12:28:49 <RayNbow> dons: I haven't ordered RWH yet
12:30:17 <RayNbow> hmm... and of 3 Dutch webshops I tried, only 1 has it in its catalog
12:30:18 <mauke> force him!
12:32:08 <RayNbow> http://www.vanstockum.nl/product/10881858/Real-World-Haskell.html <-- heh, it says "not yet published"? :p
12:32:14 <lambdabot> Title: Real World Haskell, Goerzen, John - Van Stockum
12:32:29 <RayNbow> but it does offer a preview of the book (hosted by Google)
12:33:38 <C-Keen> no amazon.nl?
12:34:25 <RayNbow> C-Keen: nope
12:34:43 <RayNbow> International Sites:  Canada  |  United Kingdom  |  Germany  |  Japan  |  France  |  China  <-- Amazon hates the Dutchies :p
12:35:23 <C-Keen> :(
12:36:37 * BMeph goes to see if Michael Caine owns any Amazon stock...
12:36:44 <RayNbow> it's probably not interesting for Amazon to open a Dutch site... there are already several good bookshops here in the Netherlands :p
12:37:30 <Deewiant> You can buy it off a non-Dutch Amazon as well :-P
12:38:55 <RayNbow> Deewiant: I know, but then I'm probably getting limited in payment options
12:39:16 * RayNbow also needs to check the shipping rates
12:39:18 <Deewiant> Possibly—I've never ordered anything off Amazon myself so I wouldn't know
12:40:11 <RayNbow> credit cards are not very common here in the Netherlands
12:40:54 <Deewiant> Debit cards? Or is it all cash :-)
12:41:26 <RayNbow> debit cards, yes
12:41:30 * monochrom conceives a rude joke about how the Dutch pays back.
12:41:42 <BMeph> Bank transfers, isn't it? :)
12:42:06 <RayNbow> BMeph: yeah, that's also a possible payment option
12:42:47 <RayNbow> but increasingly more Dutch webshops are using the iDeal system
12:43:00 <Deewiant> Debit cards in Finland, at least, tend to work decently well for online purchasing purposes (most notably the Visa Electron)
12:43:13 * monochrom looks at the topic and considers: "Real World Haskell: in the real world now!"
12:43:40 <RayNbow> (iDeal = bank card + challenge response using a reader device, bank informs the webshop that the payment is done)
12:44:16 <Deewiant> I prefer Paypal myself
12:45:16 <RayNbow> most of my online orders are placed at shops that don't support Paypal
12:45:31 <RayNbow> (I do have a Paypal account though for eBay :p)
12:45:45 <monochrom> Isn't Paypal expensive?
12:46:07 <monochrom> Like it charges you 85% every transaction...
12:46:12 <RayNbow> monochrom: for buyers there is no fee when you link a credit card to your Paypal account, iirc
12:46:17 <povman> is anyone here an OpenGL expert?
12:46:28 <jpcooper> I saw a strange device in Holland at my work where one puts the card in, enters a number and it displays a number in order to execute a debit transaction
12:46:34 <jpcooper> I guess it's some kind of hashing
12:46:45 <RayNbow> http://www.arenabloemen.nl/assets/Image/help/iDEAL.jpg <-- this device or something similar, jpcooper? :)
12:46:48 <monochrom> Oh, that's better. (I exaggerated deliberately.) Do you know how it costs sellers?
12:47:00 <RayNbow> monochrom: I don't, but I don't sell stuff :p
12:47:06 <povman> my program runs stupidly slow for what it's doing - it's drawing about 60 lines and it chugs. runs faster with 30 or so
12:47:06 <jpcooper> RayNbow, yes, look like that
12:47:15 <jpcooper> I presume that it's the same type of device, what with Rabobank being Dutch
12:47:37 <monochrom> "te invder" = "the invader"? :)
12:47:47 <jpcooper> RayNbow, though is this system only apparent in Holland? I presume that it doesn't work with foreign sellers
12:47:53 <peter_12> I'm curious about how Haskell folks (and functional folks, in general) like to handle the same part of the application that a OOP ORM would handle. In particular, validating data, before attempting to persist, and error handling.
12:47:57 <peter_12> I don't like how an ORM like Rails' Active Record goes about doing its job
12:48:06 <jpcooper> what is ORM?
12:48:07 <monochrom> What is ORM?
12:48:11 <p_l> lol
12:48:13 <jpcooper> hah
12:48:14 <RayNbow> jpcooper: I don't know if any other countries offer this kind of e-banking
12:48:26 <Korollary> Object-Relational Mapping
12:48:51 <peter_12> Object Relational Model (in the case that was not rhetorical)
12:49:00 <peter_12> *Mapping
12:49:01 <monochrom> Since FP doesn't do objects usually, first of all there is no ORM.
12:49:02 <RayNbow> jpcooper: but the Dutch system only works between Dutch bank accounts
12:49:06 <jpcooper> okay
12:49:22 <povman> is arithmetic with Ratio meant to be slow?
12:49:32 <povman> or conversion from Ratio to Float
12:49:35 <peter_12> monochrom: that is why I ask "the same part of the application" but not how does it do ORM (given there are no objects)
12:49:37 <monochrom> Secondly I suppose we just compose (function composition) three stages: input, validate, store.
12:49:47 <peter_12> what happens if validation fails?
12:49:48 <Deewiant> Slower than int or floating point, certainly.
12:49:50 <Korollary> There's still a question of Record-Relational Mapping. Object-ness is not that critical.
12:49:55 <ddarius> Ratio isn't a type.  If you mean Rational (i.e. Ratio Integer) then it certainly isn't going to be fast.
12:50:17 <RayNbow> jpcooper: I'm not sure if it could easily get extended to international transfers... I think most banks in the world are mainly focusing on national transfers, not international transfers
12:50:27 <povman> ddarius: yes I meant Rational. what a pain.
12:50:40 <p_l> RayNbow: Some countries have special, internal transfer systems
12:50:43 <ddarius> There's also a problem with Rational numbers in general in that the denominator can become very large.
12:50:57 <monochrom> input, if valid then store else report
12:51:06 <jpcooper> RayNbow, I was just wondering whether you had to use the device somehow even if you were making a foreign transaction
12:51:31 <povman> well that would explain my slow opengl. thanks
12:52:18 <monochrom> If you can draw a data-flow diagram, you get a pretty much FP design.
12:53:05 <vixey> are type constructors injective?
12:53:09 <monochrom> record-relational mapping is more trivial since there is no subclassing subtyping etc.
12:53:20 <ddarius> vixey: Module associated types and such, yes.
12:53:46 <ddarius> vixey: Well, I guess type synonyms don't need to be if you count those.
12:54:02 <ddarius> s/Module/Modulo
12:54:15 <RayNbow> jpcooper: I just looked it up... I can use the Rabobank device to log into my Rabobank account and then transfer money to an international account if I know the IBAN number
12:54:37 <jpcooper> okay
12:55:17 <dolio> Pretty much modulo type synonyms altogether, if you count associated types as a certain variety of those.
12:55:44 <dolio> Which they kind of are.
12:56:57 <ddarius> Indeed.  Manuel had a point that type synonyms arguably shouldn't be uppercase.
13:01:57 <dolio> I suppose one could make a more compelling case for the reverse, since you could look at type synonyms as a type family with 0 indices.
13:02:04 <dolio> But that doesn't work perfectly, either.
13:03:22 <dolio> At least as far as the syntactic restrictions go.
13:07:47 <dons> just started doing an interview about haskell for 'on ruby'
13:08:10 <dons> there's a couple of other interesting interviews about haskell coming up. i hope everyone's ready to be welcoming to new users :)
13:08:32 <Corun> Hello new user. MONADS.
13:08:35 <luite_> users asking for a rails alternative?
13:11:15 <dons> yay, RWH ranked #2 in germany/amazon for 'software eng' and 'software dev' books
13:11:38 <povman> i can't wait until people are asking for a HTTP alternative
13:30:14 <dons> ooh yay. what language are you currently programming in? http://www.terminally-incoherent.com/blog/2008/11/28/two-programming-polls-for-the-weekend/
13:30:17 <dons> i vote for haskell
13:30:20 <lambdabot> Title: Terminally Incoherent » Blog Archive » Two Programming Polls for the Weekend, http://tinyurl.com/5j83fl
13:30:21 <dons> anyone else? :)
13:30:33 <thoughtpolice> duh :]
13:30:41 <xian> dons: btw, RWH is now ranked #1 for that category on amazon.de   i hope i will get my copy soon :)
13:31:11 <luite_> voted :)
13:31:17 <dons> xian: woo!!
13:31:18 <luite_> we need 2 more to beat php ;)
13:31:38 * ddarius is not currently programming...
13:32:14 <luite_> I am, but not terribly productive today :(
13:32:30 <dons> xian: do you have a link to the ranking?
13:32:34 <ddarius> What's this radio box nonsense?
13:32:48 <ddarius> er radio button (or whatever they're called)
13:33:14 * vixey is programming
13:33:36 <xian> dons: sure: http://www.amazon.de/gp/bestsellers/books-intl-de/63350011/ref=pd_zg_hrsr_eb_1_4_last  but somehow it's back to #2 again.. i swear it was listed first just a moment ago
13:33:44 <lambdabot> http://tinyurl.com/5fhxao
13:34:01 <dons> interesting. i wonder how often they update
13:34:11 <dons> stupid design patterns
13:34:53 <luite_> hm, I have to admit that I do have the design patterns book, but not the rwh
13:34:58 <luite_> sorry dons ;)
13:35:05 <dons> hehe
13:35:50 <ddarius> 32,75 EU v. 40,99 EU ...
13:36:01 <dons> woot woot,. new turbinado.org site, http://www.reddit.com/r/programming/comments/7g8vx/turbinado_an_easytouse_web_application_framework/
13:36:03 <lambdabot> Title: Turbinado: an easy-to-use web application framework for Haskell which is frickin ..., http://tinyurl.com/6grg33
13:37:35 <luite_> oh by the way, is it possible to download a sample of the electronic version of rwh? i want to see how it looks on my ebookreader
13:37:37 <dons> so #24 in world wide Computers&Internet/Programming  books
13:37:45 <dons> luite_: oh, interesting. hmm.
13:37:53 <dons> there's online browsable pages, not sure about ebook
13:38:02 <dons> ask on the blog. keith from oreilly, the ebook guy will comment
13:39:01 <ddarius> "frickin' fast" versus Ruby...
13:39:03 <dons> hehe
13:39:14 <dons> well, gee. if they don't wipe ruby off the map, i'm going home.
13:39:56 <luite_> lol, I bet ruby people will get annoyed when you start about the speed of the language ;)
13:40:09 <dons> hehe
13:40:15 <dolio> Ruby people don't care about speed, right?
13:40:30 <dolio> They're glad ruby is slow, because it encourages them to write better algorithms. :)
13:40:35 <luite_> I guess they would've chosen another language if they would
13:41:24 <luite_> but I heard the situation has improved a bit in the latest ruby versions
13:42:43 <thoughtpolice> is there not a strict version of MTL anywhere? I could have sworn I saw something on hackage...
13:43:00 <dolio> Strict version?
13:43:09 <dolio> It has modules for strict state and writer.
13:44:27 <thoughtpolice> ah here we go http://hackage.haskell.org/packages/archive/mtl/1.1.0.2/doc/html/Control-Monad-RWS-Strict.html
13:44:29 <lambdabot> Title: Control.Monad.RWS.Strict, http://tinyurl.com/6zglhp
13:44:56 <thoughtpolice> trying to replace bunches of stuff in lhc source, moving as much as possible out to libraries.
13:45:46 <loriel> What does the L stand for?
13:46:51 * BMeph checks out the M:tG joke entry...
13:46:59 <ehird> oh no I'm back :|
13:47:10 <dolio> Oh no!
13:47:16 <ehird> yeah. it's awful.
13:47:22 <dolio> @yow!
13:47:22 <lambdabot> I think I am an overnight sensation right now!!
13:47:32 <ehird> i was like, disappeared, and it was like, yay, and now I'm, like, back, and it's like, damnit!
13:47:44 <ehird> :-|
13:48:52 <thoughtpolice> loriel: originally Lemmih was going to call it the 'Large Haskell Compiler' but now it's recursive, so it's the "LHC Haskell Compiler"
13:49:29 <ddarius> Ugh, recursive acronyms
13:49:30 <Beelsebob> not the Large Hadron Colidor Haskell Compiler?????
13:49:31 <Beelsebob> :P
13:49:58 <loriel> I would have gone with Haskell Collider :|
13:50:02 <mauke> RMS Matthew Stallman
13:50:15 <Beelsebob> the Large Haskell Collidor
13:50:20 <Beelsebob> or the Large Hadron Compiler
13:50:20 <vixey> what's this LHC for?
13:50:54 <vixey> ?where LHC
13:50:54 <lambdabot> I know nothing about lhc.
13:51:01 <dolio> For working on jhc stuff that j wouldn't necessarily approve of.
13:51:11 <thoughtpolice> vixey: http://lhc.seize.it
13:51:19 <lambdabot> Title: Wiki - Front Page
13:51:26 <monochrom> Lazy Haskell Compiler
13:51:37 <thoughtpolice> Loving Haskell Compiler
13:51:44 <monochrom> Leaky Haskell Compiler
13:52:44 <vixey> doesn't really explain aims or anything
13:53:04 <thoughtpolice> vixey: the website hasn't been the biggest priority right now
13:53:24 <vixey> ok
13:53:30 <vixey> I still don't know what the point of LHC is :)
13:53:42 <RayNbow> hmm, the Type-driven testing video link (@ http://www.foomongers.org.uk/videos/spj-typedriventestinginhaskell.html ) is 404...
13:53:54 <lambdabot> http://tinyurl.com/2u2mtq
13:54:20 <monochrom> Lazy Haskell Compiler: "if you won't run the program, why would I compile it?" :)
13:54:37 <BrokenClockwork> Hey, if I have a list of lists ( [[a]] and I want to read out the length of one list in the list?
13:54:50 <vixey> which one?
13:55:18 <BrokenClockwork> well, actually I want to read the length of all elements
13:55:18 <vixey> length . takeTheOneYouWantedOut
13:55:24 <luite_> BrokenClockwork: you could use map length xs
13:55:29 <kpreid> > map length [[1],[2,3],[4,5,6]]
13:55:31 <lambdabot>   [1,2,3]
13:55:32 <BrokenClockwork> ah right :)
13:55:42 <BrokenClockwork> higher-order func ftw
13:55:49 <vixey> > map^-1 length [1,2,3]
13:55:50 <lambdabot>   Not in scope: `^-'
13:56:24 <thoughtpolice> vixey: me and Lemmih are working on the compiler itself more than anything, but it's a fork of jhc, and there are a few reasons why it exists. notaby: john didn't want to use cabal for JHC, and JHC wasn't seeing any active development
13:56:50 <vixey> john sounds wise :p
13:57:10 <RayNbow> hmm
13:57:27 <RayNbow> spj-typedriventestinginhaskell.h264.mp4 <-- I wonder if I'm allowed to upload this to Google
13:57:43 <thoughtpolice> so Lemmih forked it and here we are. right now my priorities are to destroy as much old code as possible in favor of stuff on hackage (and we've done plenty of this already)
13:58:24 <thoughtpolice> vixey: why do you say that?
13:58:24 <dolio> thoughtpolice: By the by, when I tried cabal installing it, it just kind of bombed out without doing anything...
13:59:00 <dolio> After "Processing: src/C/FFI.hs"
13:59:32 <thoughtpolice> dolio: yeah, that's because when Lemmih uploaded the original version it had a version of '20081121,' and I just uploaded a new (much better) version yesterday, and the version is at '0.6.20081127', so cabal sees it as 20081121 > 0.6.20081127 and installs the older version instead
13:59:35 <vixey> thoughtpolice, 'cabal' just knee-jerk reflex makes me think of weird compiling errors I can't be bothered to fix
13:59:41 <thoughtpolice> dolio: cabal install lhc-0.6.20081127
13:59:50 <dolio> Oh, okay.
14:00:00 <vixey> why hacking on JHC and not GHC?
14:00:10 <thoughtpolice> dolio: we'll have to talk to dcoutts about removing that old version
14:00:11 <vixey> like making --make good enough to replace cabal?
14:00:16 <dolio> Yeah.
14:00:20 <ehird> hmm, happs still seems to be stuck in monad land :(
14:00:34 <thoughtpolice> vixey: why not?
14:00:44 <dolio> Why not make cabal good enough to replace --make?
14:00:47 <vixey> oh I'm not saying you shouldn't
14:00:49 <dolio> (As is the plan, I think.)
14:01:27 <pumpkin_> someone's making a new haskell compiler? :o
14:01:30 <thoughtpolice> vixey: before Lemmih forked LHC I had plans for my own haskell compiler that I began to work on that had many significant similarities with JHC. when Lemmih forked, I decided to drop my project and go work on LHC instead
14:01:49 <vixey> ok
14:02:43 <pumpkin_> vixey: what would that inverse map you tried to call do? :P
14:03:01 <thoughtpolice> dolio: luckily with 0.6.20081127, I completely eliminated the need for DrIFT in favor of Data.Derive, so you shouldn't need any external programs to build
14:03:04 <vixey> [[1],[2,3],[4,5,6]]
14:03:11 <dolio> Cool.
14:03:18 <thoughtpolice> dolio: which is much better, because you can't tell cabal "this build needs this arbitrary executable named <foo>"
14:03:20 <pumpkin_> vixey: :o
14:03:30 <ehird> is there something similar to happs with a more purely-functional approach?
14:03:31 <dolio> Heh.
14:04:04 <dolio> Weren't you building a continuation-based web server or something?
14:04:25 <ehird> yeah, toying about with that sort of stuff
14:04:33 <ehird> decided to give happs another look
14:04:46 <thoughtpolice> dolio: unfortunately using data.derive's template haskell features - while *extremely* useful in practice - has a few drawbacks of its own
14:05:12 <dolio> Like having to make lhc support template haskell before it can compile itself? :)
14:05:40 <thoughtpolice> dolio: but IMO the benefits outweigh the costs, primarily because it makes building with cabal so much simpler
14:06:18 <thoughtpolice> dolio: actually that might happen sooner than expected, because I'm planning on switching LHC's home grown parser with haskell-src-exts
14:06:58 <thoughtpolice> niklas (the author) said he would hack pragma support into the code base for us, which is quite generous. that was the main thing holding us back (because e.g. the RULES pragma is pretty important)
14:07:06 <dolio> Hmm, interesting. I guess I really have no idea just how much effort it takes to make something like Template Haskell work.
14:08:18 <thoughtpolice> dolio: well, the way I see it, the hard work on things like that has been done *and* published, so we're well off
14:08:43 <dolio> Well, that's true enough.
14:09:15 <thoughtpolice> dolio: what would be great about haskell-src-exts is it would (almost immediately and assuredly) make lhc the 2nd most extension-supportive haskell compiler, next to GHC itself.
14:09:29 <dolio> I suppose in theory it's not *that* hard so long as you can interpret haskell inside your compiler somehow.
14:09:33 <thoughtpolice> of course, that requires A) moving the compiler to use HSE and B) to make LHC actually work on a larger amount of programs
14:09:58 <pumpkin_> large hadron collider?
14:10:11 <thoughtpolice> the 2nd one will be more tricky
14:10:11 <pumpkin_> giant hadron collider?
14:10:19 <thoughtpolice> because things like region inference need to be fixed first
14:10:31 <thoughtpolice> since region inference in particular is severely broken in the code base, it seems.
14:11:09 <dolio> Does it totally use region inference instead of a traditional garbage collector? Or is it some kind of hybrid?
14:11:19 <thoughtpolice> at least it can be mitigated by compiling apps with '-fboehm' (for some reason I get the sneaking suspicion john actually put that flag into the compiler for this exact reason...)
14:11:41 <dolio> I guess that kind of answers my question.
14:12:26 <thoughtpolice> dolio: it uses region inference almost entirely AFAICS, but if you compile with -fboehm, basically all it does is use CPP to make the RTS's allocation functions call GC_alloc instead
14:12:36 <mmorrow> from what i've gathered about template-haskell, it's essentially being able to interleave compilation (well, typechecking) and evaluation (of splices) while walking the AST
14:13:28 <dolio> Yeah, there's some kind of diagram about that in one of the TH papers. :)
14:13:34 <thoughtpolice> dolio: http://hpaste.org/12468
14:13:42 <thoughtpolice> i think that'll explain what I mean better
14:13:44 <mmorrow> err, by "it's essentially..." i meant that that's the capability one'd need to be able to make it work at all
14:13:50 * vixey doesn't find enough PEG enthusiasts
14:14:14 <mmorrow> once you have that, then it'd "just" be a matter of making it behave how you want
14:14:41 <BrokenClockwork> Do you think this is fine? http://hpaste.org/12469 (Task was to get the ceiled average length of lists in a list)
14:15:04 <vixey> BrokenClockwork, I wouldn't write it like that
14:15:06 <dolio> I had forgotten that jhc uses region-based allocation. That's another reason it's cool. :)
14:15:13 <mmorrow> i've starting to see some parallels between evaluation of splices during typechecking and the evaluation that dependently typed langs have to do /in order to/ typecheck
14:15:13 <BrokenClockwork> mh
14:15:31 <vixey> BrokenClockwork, I would write averageLength = ceil . average . map length
14:15:46 <thoughtpolice> dolio: yeah, it's really neat
14:16:19 <mmorrow> i'm not exactly clear on the relationship yet, but i'm starting to think that TH and (certain flavors of) dependent types are just the same thing by different names
14:16:41 <thoughtpolice> dolio: region inference + GRIN means that, like john said when he announced jhc so long ago, you could pretty much stick a backend onto the compiler for just about any architecture, since you don't need a GC to fiddle with, and GRIN is by design a whole-program intermediate language
14:16:43 <BrokenClockwork> vixey: not in scope with average and ceil ?
14:16:52 <vixey> BrokenClockwork, guess you gotta code them too ..
14:16:58 <mauke> ceiling
14:17:00 <thoughtpolice> (or any language, really)
14:17:07 * vixey turn 1 problem into 2
14:17:34 <dolio> mmorrow: TH is a lot like some of the more restricted types of dependently typed languages. Like Dependent ML (which got absorbed by ATS). And, arguably, C++ to an extent.
14:17:35 <mmorrow> ie you have to use beta equality on types in for dependent types, which amounts to evaluating that "splice" during typechecking
14:17:57 <sdfsf> anyone know of a very very simple raytracer written in haskell, i really mean the absolutely simplest possible
14:18:30 <thoughtpolice> dolio: yeah, dependent ML only allowed you to encode things like naturals at the type level didn't it?
14:18:57 <vixey> I think DML was _just_ naturals or maybe integers, and lots of automatic constraint solving
14:19:07 <dolio> Yeah. I think it was limited to integers.
14:19:09 <mmorrow> dolio: i've been trying to come what exactly a "non"-restricted dependently typed lang would allow that couldn't be done with template-haskell (i'm sure i'm just not seeing it yet)
14:19:25 <kpreid> > let averageLength xss = genericLength (concat xss) / genericLength xs in averageLength  [[1],[2,3],[4,5,6]]
14:19:26 <lambdabot>   Not in scope: `xs'
14:19:30 <dolio> But the real strict divide was that all the integers had to be in some sense statically known.
14:19:33 <kpreid> > let averageLength xss = genericLength (concat xss) / genericLength xss in averageLength  [[1],[2,3],[4,5,6]]
14:19:35 <lambdabot>   2.0
14:19:37 <mmorrow> like, for instance, printf in cayenne and printf in TH are pretty much identical
14:19:51 <kpreid> I think that's pretty...
14:19:52 <mmorrow> both in terms of how they're coded and their capabilities
14:19:53 <vixey> mmorrow, seems like TH still doesn't let you reflect values into types but freeze snapshots of values and put them in types (would you say?)
14:20:05 <ehird> cayenne is awesome!
14:20:07 <ehird> :)
14:20:09 <thoughtpolice> mmorrow: btw, ever solve your cayenne-cabal problems?
14:20:15 <vixey> kpried, that's really neat actually
14:20:18 <mmorrow> vixey: hmm, could you elaborate on that.
14:20:35 <thoughtpolice> mmorrow: because 'cabal install cayenne' would be f'ing awesome, btw. ;]
14:20:42 <mmorrow> thoughtpolice: i think i know how to do it now, i just have to do just that :)
14:20:47 <ehird> [[genericLength (concat xss) / genericLength xs]] <-- um, holy slow batman?
14:20:48 <kpreid> @pl \(a,b) -> (f a,f b)
14:20:48 <chrisdone> preflex: be poppavic
14:20:48 <lambdabot> f *** f
14:20:49 <preflex>  as a virgin, it's better to learn the C concept of true/false - and see the libc interfaces for pass/fail, true/false - and wonder "why?"
14:20:51 <mmorrow> thoughtpolice: yeah, it would be sweet
14:21:11 <ddarius> sdfsf: There are tons of them.  Check haskell.org.
14:21:12 <thoughtpolice> mmorrow: I've been wanting to try out cayenne since I stumbled upon ATS
14:21:13 <mmorrow> i'm motivated too by the lhc cabalization
14:21:14 <vixey> mmorrow, along which axis? :p
14:21:16 <kpreid> ehird: you can use length and `div` if you like...
14:21:20 <ehird> chrisdone: don't do that, i read that and got a faint horror of realization which grew and grew until i saw your line
14:21:38 <thoughtpolice> mmorrow: hehehe.
14:21:44 <kpreid> @pl \f -> f *** f
14:21:44 <lambdabot> join (***)
14:21:58 <thoughtpolice> mmorrow: well we still have more things to do, in particular I think it might be possible to use quasi-quoting to replace some of the perl scripts that generate the primop files, etc..
14:22:11 <mauke> ehird: what, did you think poppavic was here? :-)
14:22:11 <mmorrow> vixey: so "reflect values into types", what would be a concrete one-line example of this in some sort of pseudo-code (or just words)?
14:22:15 <thoughtpolice> mmorrow: but yes, i think cabalising lhc was win. easiest way to get it to the biggest amount of people
14:22:31 <ehird> mauke: well, I just started reading it and kind of got some kind of horror which I couldn't place.
14:22:42 <thoughtpolice> mmorrow: personally I think franchise is also really cool - if they get it into a cabal-compatible state, that would be *awesome* because franchise has some really neat features
14:22:48 <kpreid> > let averageLength = uncurry (/) . join (***) genericLength . (concat *** id) / genericLength in averageLength  [[1],[2,3],[4,5,6]]
14:22:49 <lambdabot>   Couldn't match expected type `([[a]], [a])'
14:22:52 <mauke> preflex: be PoppaVic
14:22:52 <preflex>  oh, I know how folks can irk.. The code doesn't care, but folks make a big stink of mickey-mouse issues.
14:22:57 <mmorrow> thoughtpolice: yeah, the whole libraries needing to be built by the just-built compiler part is the tricky part
14:23:03 <kpreid> dang
14:23:18 <chrisdone> can't underestimate mickey-mouse issues
14:23:29 <dolio> mmorrow: Suppose you want to write some kind of proof carrying code about sorted lists. So in a dependently typed language, you might have a type that's something like 'Sigma l:[a] Sorted l'. But what that l is may not be known until runtime.
14:23:49 <thoughtpolice> mmorrow: yeah, that's a problem we're having with lhc. we would like lhc's base library on hackage, so you could do 'cabal install base --lhc', but that might very well interfere with, uh, *everything* uploaded onto hackage
14:24:03 <mmorrow> ohhh. ok, so are we not assuming that all types are erased at compile-time then?
14:24:03 <thoughtpolice> mmorrow: otoh, we could name it lhc-base and upload it, but that's problematic for packages that just depend on 'base'
14:24:12 <vixey> mmorrow, say I wrote functions f and g, (f and g being values), I can reflect computational proerties about them into the type system, for example  inverse = <proof omitted> :: forall x. Equals (f (g x)) x
14:24:29 <dolio> mmorrow: Wheras in TH and the like, any 'value' that affects the type level has to be statically known at compile time.
14:24:33 <thoughtpolice> mmorrow: so if we want lhc's base installation automated we need to find a way around that, or tie lhc-base's build into lhc's build, which might be a little nasty.
14:24:45 <ehird> thoughtpolice: Solution:
14:24:51 <ehird> Cabal should borrow abstract packages from debian
14:24:55 <mmorrow> vixey, dolio: so you're talking about runtime checking or something?
14:24:59 <vixey> mmorrow, so from what you said about TH it seems like you could sort of compute f (g x) for _some_ x, and freeze a snapshot of that by converting the result, say 5 into a type level version of 5
14:25:01 <ehird> i.e. packages which just represent "one of these concrete packages, pick one"
14:25:10 <ehird> base <----> {ghc-base, lhc-base etc}
14:25:20 <sdfsf> ? can Haskell solve the halting problem?
14:25:20 <vixey> mmorrow, no typechecking need occur at runtime
14:25:35 <dolio> mmorrow: Actually, you may be able to erase the proofs about the sortedness of the list (if you have proof irrelevance). But the types must nevertheless refer to runtime values.
14:25:36 <ehird> sdfsf: "proof omitted"
14:25:40 <ehird> so you have to specify a proof
14:25:42 <mmorrow> vixey: so what is the algorithm they're using?
14:25:48 <sdfsf> faq? can Haskell solve the halting problem?
14:25:52 <sdfsf> ?faq can Haskell solve the halting problem?
14:25:53 <lambdabot> The answer is: Yes! Haskell can do that.
14:25:53 <ehird> @faq
14:25:53 <lambdabot> The answer is: Yes! Haskell can do that.
14:26:01 <mmorrow> @dolio too
14:26:01 <lambdabot> Unknown command, try @list
14:26:05 <vixey> mmorrow, I'm not sure what you are asking? How to typecheck dependent types?
14:26:10 <sdfsf> @faq can Haskell solve the halting problem?
14:26:11 <lambdabot> The answer is: Yes! Haskell can do that.
14:26:32 <ehird> @faq can Haskell solve the halting problem?
14:26:32 <lambdabot> The answer is: Yes! Haskell can do that.
14:26:35 <ehird> it's in vogu
14:26:35 <ehird> e
14:26:35 <povman> @quote russia
14:26:36 <lambdabot> vegai says: in Soviet Russia, YOU blow up GHC's brain!
14:26:54 <povman> how come it accepts ? and @
14:27:02 <mmorrow> sure, that would answer my question. for instance, i've read the cayenne type-checking rules + type erasure rules and i don't see what they give that can't be done in some metaprogramming thingy (eg TH)
14:27:15 <ehird> @quote ehird
14:27:15 <lambdabot> No quotes match.
14:27:20 <mmorrow> so i guess other newer langs are using a completely different method?
14:27:30 <vixey> mmorrow, well that example I just gave above.. I don't think that can be done in TH
14:27:38 <povman> @quote
14:27:39 <lambdabot> malig says: I have to admit I'm still stunned when "tying the knot" actually works. it's like I just performed the kind of magic that normally requires a lot more goat's blood
14:27:44 <ehird> :(
14:28:45 <vixey> mmorrow, but it seems possible for some _specific x_ by taking a snapshot (coverting values into types)
14:29:17 <vixey> mmorrow, (not having used TH, I'm wondering if this sounds about right)
14:29:30 <mmorrow> sure, but the thing i can't seem to understand is, if the compiler is only doing work /until the end of but not after/ compilation, how that could gain you anything over being able to do arbitrary computation at compile-time, because that's what the dep lang is doing?
14:30:07 <pumpkin_> going back to my question from yesterday, I'm trying to think of an effective way of doing a sliding window higher-order function
14:30:22 <filcab42> Hi. Where can I look for stuff about GHC's internal functions?
14:30:37 <jethr0> pumpkin_: "sliding window"?
14:30:42 <filcab42> like $wshowsPrec, State# RealWorld, and others
14:30:53 <ehird> filcab42: mordor
14:31:00 <vixey> mmorrow, if both languages were general recursive -- I don't think you'd really gain anything at all. But if you compared two strongly normalizing ones, the more expressive types let you write more (complex) functions
14:31:04 <mmorrow> TH lets you essentially "add arbitrary code to the compiler". so, imagine you implem cayenne's typechecker+type-eraser in TH. then, TH verifies it all and spits out a few hundred lines with every expression and subexpression wrapped in unsafeCoerce
14:31:04 <Cale> filcab42: The GHC source code.
14:31:11 <filcab42> ehird: isn't it written: mooorrrddooorrrr? ;-)
14:31:12 <thoughtpolice> mmorrow: hey, where did you get your copy of hbc that came with hbci? i installed hbc 0.9999.5b or something but it doesn't come with hbci
14:31:18 <dolio> mmorrow: Consider this code: http://hpaste.org/12470
14:31:23 <mmorrow> thoughtpolice: i'll find the link
14:31:34 <ehird> filcab42: unsafeWalkInto# !mordor
14:31:38 <filcab42> Cale: indeed... I was asking ig it was documented... To better understand the stuff ghc-core spits out ;-)
14:31:42 <thoughtpolice> mmorrow: because I guess to try and play around with cayenne i need LML
14:31:47 <thoughtpolice> mmorrow: which comes with hbc i saw
14:31:48 <pumpkin_> jethr0: sliding 3 [1..5] = [[1,2,3], [2,3,4], [3,4,5]] for example... eventually I'd make it apply a function to the generated n-element lists, and take an increment too
14:31:51 <filcab42> in before reading GHCs source :-)
14:32:00 <jethr0> I'd like to deepen my experience with theorem provers or dependent typing. what would be the best way to start? agda? epigram? ?
14:32:06 <ehird> filcab42: careful you'll never in after that
14:32:19 <filcab42> after what?
14:32:25 <mmorrow> thoughtpolice: i don't recall the link i got it from, but i have the same tarball(s) here: http://code.haskell.org/~morrow/hbc/
14:32:25 <ehird> reading GHCs source :P
14:32:26 <lambdabot> Title: Index of /~morrow/hbc
14:32:33 <mmorrow> those have hbi included
14:32:37 <thoughtpolice> jethr0: for a theorem prover, lots of people are fans of Coq; for dependently typed languages, ATS is just about the most practical one out there (and it has kick-ass speed)
14:32:40 <mmorrow> dolio: cool, /me looks
14:32:44 <jethr0> pumpkin_: and what kind of higher order function do you want to apply to those sliding windows?
14:32:56 <mmorrow> thoughtpolice: yeah, you'll have to build and install lml
14:33:11 <jethr0> thoughtpolice: yes, I saw ATS kick ass on the language shootout. have you done anything with ATS?
14:33:15 <pumpkin_> jethr0: a map, probably, but not necessarily
14:33:16 <mmorrow> i don't remember how i managed that, but iirc it wasn't too painful
14:33:51 <Cale> filcab42: Well, some of it is in the Hierarchical libraries documentation under GHC.*
14:33:52 <thoughtpolice> jethr0: i'm (gradually) working on an HTTP server when I have the time
14:33:52 <jethr0> I don't really want to learn a new programming language, I have been doing that for too long. but rather broaden my horizons re: theorem proving. What would be a hello world example for coq?
14:34:20 <vixey> jethr0, correctness of a compiler for arithmetic expressions to a stack evalutator
14:34:38 <dolio> mmorrow: That code involves a proof that a runtime list is sorted. However, provided that certain conditions on the use of the proof hold, you can erase the proof and retain correct code.
14:34:39 <filcab42> Cale: thanks... I'll look it up
14:35:09 <jethr0> thoughtpolice: what would you say the main difference to haskell is? I've had a look at epigram and found it a bit clunky. does ATS seem more real world?
14:35:18 <filcab42> This is weird... I'm having a function that gets compiled to Core, but it's never used... although main uses it
14:35:29 <filcab42> what's the URL for pastebot?
14:35:36 <dolio> mmorrow: (Namely, that the value of a proof never causes a branch, more or less, I think; proof irrelevance equates all values of a proof/requires that they have at most one value.)
14:35:47 <jethr0> vixey: so i"d define such an interpreter in coq and prove its correctness?
14:35:50 <jethr0> @paste
14:35:50 <lambdabot> Haskell pastebin: http://hpaste.org/new
14:36:05 <dolio> mmorrow: So, the types may refer to runtime values, but may not have to be around at runtime.
14:36:10 <filcab42> thanks
14:36:20 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/ghc-prim/GHC-Prim.html
14:36:26 <lambdabot> Title: GHC.Prim, http://tinyurl.com/562vsv
14:36:27 <vixey> mmorow, aha, dolios example is great. I can phase my question in terms of it -- You could typecheck that program with TH for a single fixed 'l' right? but never for getLine (arbitrary l)
14:36:40 <mmorrow> dolio: ahh, hmm. this is different than i thought. so what happens if i input "42,10000,0,-1999"? what does that gain me over checking it myself and making a newtype Sorted a = Sorted [a] with a smart constructor?
14:37:15 <mmorrow> vixey: but that program fails if you get a non-sorted list as input, no?
14:37:34 <vixey> jethr0, yeah define expressions interpreter, stack language interpreter, compiler for expression -> stack and show that they have equal interpretation
14:37:44 <dolio> mmorrow: Maybe you peek inside the proofs later, inside "doSomethingThatRequiresProvablySortedLists" to prove that in (pf, x:y:zs) x<=y holds.
14:38:00 <jethr0> @let sliding n = take n . iterate (map (+1))
14:38:01 <lambdabot>  <local>:3:0:
14:38:01 <lambdabot>      Warning: Pattern match(es) are overlapped
14:38:01 <lambdabot>               In...
14:38:02 <vixey> jethr0, There's a Epigram pearl example of it
14:38:07 <jethr0> > sliding 3 [1..5]
14:38:09 <vixey> paper on it*
14:38:09 <lambdabot>   [[1,2,3,4,5],[2,3,4,5,6],[3,4,5,6,7]]
14:38:23 <dolio> mmorrow: But, in any case, what's the advantage of proving your code correct with the language instead of checking by hand and hoping you don't make mistakes?
14:38:48 <vixey> mmorrow, exlaiming that the list isn't sorted doesn't mean it's failed
14:38:53 <scoo4114> :t sliding
14:38:55 <lambdabot> forall a. (Num a) => Int -> [a] -> [[a]]
14:39:09 <monochrom> . o O ( Strange question. The advantage is you will make mistakes? )
14:39:10 <mmorrow> dolio: none, i agree. but i just now realized that that's really all that's happening
14:39:19 <jethr0> hmm, I think i'll have a look at ATS and maybe find a beginners tutorial on Coq to get me started...
14:39:19 <filcab42> is f never called because GHC realizes that whatever result f returns, it's binary and with 1 is always the same?
14:39:53 <filcab42> Hmmm... it's not that... If I .&. the result with 7, it also never calls f
14:40:30 <jethr0> filcab42: your comments are very hard to follow...
14:40:33 <monochrom> http://groups.google.com/group/comp.lang.functional/msg/571a96f2fd6195b5 "let's not look down on buggy software" :)
14:40:35 <lambdabot> Title: FP is an excellent match for modern CPUs - comp.lang.functional | Google Groups, http://tinyurl.com/6j7nsk
14:40:48 <filcab42> jethr0: my comments? it's from ghc-core :$
14:40:51 <mmorrow> vixey: for some reason i had in my head that you got some sort of guarantee about something so that zero checks for "impossible"(ly-typed) situations wouldn't occur
14:41:11 <mmorrow> but i think i misunderstood something essential here
14:41:34 <jethr0> filcab42: i meant it's very hard for me to follow the meaning of your last two lines in this channel
14:41:35 <vixey> mmorrow, I don't really know what situation you mean there though
14:41:52 <filcab42> oh, sorry...
14:42:03 <thoughtpolice> jethr0: sorry I missed your message
14:42:15 <thoughtpolice> jethr0: yes, ATS does indeed seem to be the most 'real-world' dependently typed language I've come across
14:42:36 <mmorrow> getLine >>= \l -> if sorted l /= l then error "oops" else doSomethingWithMyVerifiablySortedList l
14:42:40 * ddarius hates how if he's logged into GMail he has to log into Google Groups, but if he isn't, he doesn't.
14:42:48 <filcab42> f only returns either 3 or 5. So, I should be able to substitute the expression (f <variable> .&. 1) to 1, because the .&. of either result with 1 is always 1
14:43:02 <jethr0> thoughtpolice: would you categorize it in the toy/experimental category or rather production level? what i've seen at first glance looked quite mature
14:43:22 <filcab42> but haskell is maybe inlining and making constant propagation... I should read something or use an unsafe variable, maybe
14:43:36 <filcab42> or is it possible to turn off inlining?
14:43:41 <mmorrow> i guess the main gain is being able to propogate that property (once it's been checked at runtime) through the types in your prog while coding it thus enabling better bookkeeping
14:43:51 <thoughtpolice> jethr0: it's still very much experimental, but it's very much possible to start writing real programs in it today
14:44:31 <jethr0> cool, I really love the idea of dependent typing since it's one of the features i'm starting to miss in haskell's type system. ATS, here I come ^_^
14:44:40 <thoughtpolice> jethr0: in particular there are almost *no* libraries available to anything but libc (which is provided by the compiler,) so you'll probably end up writing a large bit of C inside your ATS code for glue - IMO, if some libraries could get put out there, ATS would be way more practical already
14:44:56 <monochrom> ddarius: You could simplify your sentence to: /me hates he's logged into GMail iff he's logged into Google Groups :)
14:45:01 <dolio> mmorrow: Anyhow, in the right dependently typed language, you can replace many sorts of predicates P : T -> Bool with a type-level predicate P : T -> Set, where P t is the type of proofs that t satisfies P, and then a function p? : (t : T) -> P t + Not (P t), which tells you whether there is a proof of P t (or the negation thereof). Then you can (hopefully) write provably (in the language) correct code in the language where the proofs can be erased at
14:45:03 <dolio> runtime.
14:45:06 <dolio> At least, that's the idea.
14:45:29 <thoughtpolice> jethr0: the error messages also might scare you at first glance, and the docs on www.ats-lang.org are still not filled out, but for my basic experiments I was able to work all that out
14:45:30 * dolio goes to dinner.
14:45:36 <ddarius> monochrom: That's not what's happening though.  I'm not logged into Google Groups.
14:45:40 <mmorrow> dolio: oh, interesting.
14:46:11 <mmorrow> ahhh
14:46:12 <thoughtpolice> jethr0: but it is a very interesting and practical language, e.g. you can just start writing programs you can compile and have work. writing real programs you can compile and execute in agda is a little more troublesome
14:46:24 <jethr0> thoughtpolice: ok, so much for "mature". but the benchmarks at the shootout definitely looked good, and anything with dependent typing has my interest high
14:46:26 <ddarius> mmorrow: Yes.  Clearly at the program borders you have to do a run-time check, but once that's done the property is preserved.
14:46:29 <dolio> mmorrow: But the key is: you (presumably) want to prove that the right things happen to runtime values, not merely compile-time values.
14:46:32 <thoughtpolice> (because you have to call into haskell - agda has an FFI, but it is an FFI to haskell)
14:46:33 <mmorrow> vixey, dolio: i think i just got a crucial insight.
14:46:38 <thoughtpolice> but, I'm not entirely sure how powerful agda's FFI is
14:46:45 <thoughtpolice> I've only seen extremely limited examples of its usage
14:46:55 <thoughtpolice> (like binding to 'putStrLn')
14:47:27 <thoughtpolice> jethr0: OTOH, ATS has out of the box *extremely* simple interfacing to C code
14:47:55 <jethr0> thoughtpolice: any good tutorials for ATS, or should I just start on the homepage?
14:48:03 <thoughtpolice> jethr0: look through the home page
14:48:07 <thoughtpolice> there is also a manual on there somewhere
14:48:18 <jethr0> k, thx a lot
14:48:19 <thoughtpolice> that is useful and covers things more gradually
14:48:28 <thoughtpolice> also it's complete, parts of the documentation/tutorial on ats-lang.org are missing
14:48:52 <thoughtpolice> jethr0: you will also probably find this interesting - http://adam.chlipala.net/cpdt/
14:48:53 <lambdabot> Title: Certified Programming with Dependent Types
14:49:38 <thoughtpolice> brb
14:49:57 <Cale> filcab42: {-# NOINLINE f #-}
14:50:04 <Cale> filcab42: It is indeed inlining f
14:51:11 <filcab42> nice
14:51:13 <filcab42> thanks :D
14:51:54 <filcab42> it doesn't do a certain optimization that's (relatively) easy to implement... Maybe I'll learn a bit of GHC... Unfortunately I must write certain stuff first :$
14:52:10 <filcab42> *I must write some reports on other things
14:52:31 <Cale> which optimisation?
14:53:08 <filcab42> It could see that f only returns 3 or 5. the binary AND of any of those with 1 is always 1. So it could just use 1 for that ;-)
14:54:38 <Cale> I'm not sure how the Data.Bits library is implemented, but it seems like it would have to know that applying those functions at compile time is safe to do.
14:55:12 <filcab42> indeed
14:55:24 <filcab42> Yes, this optimization must be applied at a lower level
14:55:31 <jethr0> also a lot of hassle with runtime vs. compile time architecture (like little/big endian for advanced bit operations)
14:55:35 <filcab42> That's why I must research GHC.Prim first
14:55:44 <jethr0> for cross-compilation that is
14:56:36 <ryrunfrnf> why are C programs faster? because you can make them faster? ie manipulate on a lower level or because there is less overhead?
14:56:40 <jethr0> I read that this was a big issue with C compile-time optimizations because there sometimes is a mismatch between compile-time and run-time IEEE floating point precision
14:57:25 <jethr0> ryrunfrnf: very broad question. actually some haskell programs optimized by ghc and compiled by gcc can be faster than straight-forward C code
14:57:30 <ryrunfrnf> i mean obv you can maniulate ona lowlevel and make it faster. but the same program (as far as you can write the same program) in C or Haskell, does the C program have less overhead?
14:58:21 <ddarius> ryrunfrnf: It depends on whether you write try to raise the C to Haskell or lower the Haskell to C.
14:58:42 <jethr0> ryrunfrnf: depends on how smart you are. advanced optimizations that gcc does not do may make haskell programs faster. the more insight you put into the C program (like logical short-cuts) the faster your C program will run and the more optimized to the architecture you are using
14:59:04 <ryrunfrnf> one thing i dont get, you cant manipulate pointers in Python, but people say you can implement any turing-complete language in any turing-complete language so how would you implement C in python?
14:59:22 <ddarius> ryrunfrnf: You'd simulate pointers.
14:59:23 <mauke> ryrunfrnf: python has arrays and strings
14:59:27 <mauke> that's more than enough
14:59:36 <maxote> @go Helium Haskell   its speed is good
14:59:38 <lambdabot> No Result Found.
14:59:39 <ddarius> mauke: Does python have unbounded integers?
14:59:43 <maxote> @go Helium Haskell
14:59:44 <mauke> ddarius: yes
14:59:46 <lambdabot> http://www.cs.uu.nl/helium/
15:00:04 <ddarius> mauke: There you go.  Just Goedel encode everything and write a bit of arithmetic.
15:00:11 <jethr0> turing-completeness has nothing to do with speed. postscript is turing complete, as is brainf*ck, but you would probably never get a fast C interpreter/compiler with either
15:00:28 <ddarius> jethr0: Why not?
15:01:20 <maxote> @go Lindenmayer system
15:01:23 <lambdabot> http://en.wikipedia.org/wiki/L-system
15:01:23 <lambdabot> Title: L-system - Wikipedia, the free encyclopedia
15:01:27 <mmorrow> if you're /generating/ code, then it doesn't matter what turing-complete lang you choose to implem you compiler in
15:01:31 <jethr0> well, maybe you could. bad example. i was just trying to make the point that turing-completeness says nothing about efficiency. a turing machine implemented with real tape would be really slow, but still a universal interpreter
15:01:32 <ryrunfrnf> but python compiles to byte code not machiencode. also wouldnt such a C-implementation be much slower than a real one(i dont really know what area l one is though :) machinecode?)?
15:01:41 <jethr0> (with an infinite tape that is)
15:01:51 <mmorrow> look at harpy. beat C easy!
15:02:00 <mauke> ryrunfrnf: from C's point of view, (almost) everything is an array of bytes
15:02:01 <thoughtpolice> mmorrow: harpy ftw!
15:02:15 <vixey> mmorrow, (back) what's the insight? :)
15:02:34 <ddarius> ryrunfrnf: As jethr0 said, Turing-equivalence says nothing about efficiency.
15:02:39 <jethr0> it's like with assembly. a good C compiler will beat a mediocre assembly programmer any time. moving to the next level of abstraction just does the same step.
15:02:47 <jethr0> it's not as if C was pure machine language
15:03:33 <jethr0> except on the mythical C-machine that is ;)
15:04:51 <ddarius> @where+ characterizing http://alistair.cockburn.us/Characterizing+people+as+non-linear,+first-order+components+in+software+development
15:04:51 <loriel> Any other machine is just a trivial special case that is not worth consideration
15:04:51 <lambdabot> Nice!
15:05:11 <jethr0> take the turing tarpit languages for example (http://en.wikipedia.org/wiki/Turing_tarpit). They are all turing complete but some of them are terribly inefficient to implement.
15:05:13 <mmorrow> vixey: that you can begin by assuming certain base properties are true (eg sorted), then build proofs/properties of arbitrary complexity out of these base assumptions, then you can erase everything as long as you can prove the base assumptions in some way at runtime at as ddarius put it the "program edges"
15:05:16 <ryrunfrnf> so why is gcc-code so fast? it isnt? it is jsut that you can customize it to the hardware? could you write a c-compiler in python that was a s fast as gcc?
15:05:42 <thoughtpolice> ryrunfrnf: gcc's generated code is fast because GCC is a very optimizing compiler
15:06:01 <vixey> I don't think there's any proving at runtime
15:06:02 <jethr0> ryrunfrnf: you could write a compiler for C code in python that produced faster code than gcc
15:06:30 <mmorrow> heh, i love it when you just realize something and say it and while you're saying it it sounds so blindingly obvious but it wasn't until it was (or something)
15:06:30 <ddarius> There are quite a few compilers that are better than gcc.
15:06:43 <mmorrow> vixey: you have to "prove" that the input list is sorted
15:07:12 <jethr0> for a long time the intel compiler was much faster than gcc. not sure how it looks today
15:07:32 <mmorrow> then, once you have that, the arbitrarily complex proof you built upon that base assumption is proved also and no more checking need occur
15:07:53 <jethr0> especially, gcc/g++ is supposed to be terribly slow at compiling huge projects
15:07:57 <mmorrow> so you can erase all types/whatev
15:09:07 <thoughtpolice> jethr0: afaik, ICC still beats the crap out of just about any x86 compiler
15:09:37 <thoughtpolice> (in terms of generated code; in terms of compilation speed, you will probably want to look at e.g. tinyCC or something)
15:10:03 <thoughtpolice> or clang
15:10:33 <jethr0> *yeah* clang
15:21:36 <ryrunfrnf> but without gcc no linux probably!!!!
15:21:49 <ryrunfrnf> how long does it take to compile the linux kernel?
15:22:01 <vixey> so anyone read this PEG paper? :p
15:22:29 <vixey> (that one http://pdos.csail.mit.edu/~baford/packrat/popl04/ )
15:22:30 <lambdabot> Title: Parsing Expression Grammars: A Recognition-Based Syntactic Foundation
15:22:45 <vixey> just confused about the abstract evaluation part
15:23:00 <jethr0> ryrunfrnf: haven't done it for a while... probably 10 minutes or half an hour these days.
15:24:48 <_Dae_> took me about 1½ hour last time
15:25:11 <jethr0> well there are alternatives for gcc these days. and in the early days (as I wrote before) gcc used to be far less than perfect. even today it has quite a few shortcomings (especially speed when compiling huge projects)
15:26:07 <jethr0> _Dae_: really, i had expected processors to be faster than that these days. last time i did was 3 years ago and it wasn't so much more than 1.5 hours back then (if i recall correctly)
15:26:20 <jethr0> s/really,/really!?/
15:27:01 <jethr0> compiling KDE used to be a nightmare ;)
15:27:04 <_Dae_> jethr0: my computer is almost 3 years old...
15:27:11 <jethr0> hehe
15:27:57 <jethr0> _Dae_: as is mine
15:28:59 * _Dae_ hates the mozilla build system with a passion
15:29:36 <Beelsebob> _Dae_: so don't use it?
15:30:06 <_Dae_> Beelsebob: ahh, but people are paying me to....
15:30:16 <Beelsebob> oh, lame
15:30:27 <Beelsebob> make them switch to WebKit
15:30:55 <thoughtpolice> mmorrow: when you first built cayenne, did GHC give you utf8-decoding errors?
15:31:20 <_Dae_> Beelsebob. I would make them switch to haskell if I thought they would listen
15:31:25 <mmorrow> thoughtpolice: oh yeah, you have to fix that one string in there
15:31:39 <thoughtpolice> mmorrow: there are two iirc
15:31:46 <mmorrow> (it's the parser and or lexer, right?)
15:32:08 <Beelsebob> hehe
15:34:48 <mmorrow> thoughtpolice: here's a pretty graph of the (transitive reduction of the) module dep graph for Cayenne (i hierarch(ical)ized those mods but they have the same structure) http://code.haskell.org/~morrow/cayenne/cayenne.tred.png
15:34:58 <dons> mmorrow: is cayenne on hackage yet?
15:35:29 <thoughtpolice> mmorrow: neat
15:35:35 <ryrunfrnf> is it now allowed to do: let [x blah c x]?
15:35:39 <vixey> I don't get why these languages all compile to polymorphic typed languages
15:35:44 <mmorrow> dons: not yet, but soon (i just need to sit down and do it). all the problems i was having seem to be solved
15:35:49 <vixey> why not to untyped ?
15:36:48 <thoughtpolice> because typed intermediate languages help ensure transformation correctness; you can eliminate a large amount of errors that optimizations can cause in the generated code if you type check the intermediate language
15:37:33 <thoughtpolice> i believe that is addressed by SPJ in 'a history of haskell'
15:37:54 <mmorrow> thoughtpolice: and here are haddocks for cayenne http://code.haskell.org/~morrow/cayenne/haddock/
15:37:55 <lambdabot> Title: cayenne-0.0: Cayenne
15:37:57 <vixey> typed intermediate languages ??
15:38:08 <vixey> even if you used unsafeCoerce all over the place
15:39:17 <ddarius> vixey: Usually a typed intermediate language is richer (type-wise), i.e. System FC v. Haskell.
15:39:35 <vixey> I'm talking about Cayenna and Coq outputting Haskell
15:39:45 * pao is trying to learn monad transformers by "inference"... I'm exhausted
15:40:22 <ryrunfrnf> is it now allowed to do: let [x blah c x]?
15:40:31 <dons> this guy did a good job  http://infinitediary.blogspot.com/2008/11/haskell-mandelbrot3d.html
15:40:33 <lambdabot> http://tinyurl.com/6zmca3
15:40:34 <dons> Cale: ^
15:41:46 <acidjnk> Can I write this shorter? let pyth n = [(x,y,z)|x<-[1..n],y<-[1..n],z<-[1..n],x*x+y*y==z*z]
15:42:08 <dons> probably not.
15:42:20 <acidjnk> thanks
15:42:57 <dons> one char shorter...
15:42:58 <dons> let s=[1..n]in[(x,y,z)|x<-s,y<-s,z<-s,x*x+y*y==z*z]
15:43:08 <Anon_R> er
15:44:31 <Anon_R> not meaning to sound silly, but it's been about a year since i've touched haskell. Is there a function which turns a expression... say mod x y to a list (say [modxy])
15:44:49 <povman> that's exactly the function
15:44:52 <povman> [mod x y]
15:44:53 <Anon_R> ... [mod, x, y] probably.
15:45:00 <Anon_R> even
15:45:03 <mauke> Anon_R: huh?
15:45:20 <pao> I'm struggling with my own monad transformers based parser...
15:45:21 <pao> http://moonpatio.com:8080/fastcgi/hpaste.fcgi/view?id=513#a513
15:45:36 <pao> can anyone help me with consumeN implementation?
15:45:51 <vixey> pao, why use StateT s [] a?
15:46:08 <pao> vixey: why not? :-)
15:46:17 <Cale> Anon_R: [mod, x, y] would be a type error, most likely
15:46:20 <pao> vixey: I'd like to map many possibile valid outcomes
15:46:56 <ddarius> Rendering the Mandelbrot fractal as a texture onto a polygon seems pointless...
15:47:17 <pao> vixey: I really think I got the right signature for the problem
15:47:17 <vixey> ddarius, if it means you can render it in GLSL then you get a few thousand times speed boost
15:47:26 <mmorrow> pao: this is an excellent paper: http://www.cs.chalmers.se/~koen/pubs/entry-jfp04-parser.html
15:47:29 <ddarius> Or is it actually a heightmap ...
15:47:32 <lambdabot> Title: Koen Claessen - Publications
15:47:47 <mmorrow> (it's essentially  ReadP (by the ReadP author))
15:47:47 * vixey is reading more packrat parser papers
15:47:54 <pao> vixey: I'm struggling with monad transformer implementation
15:48:02 <Anon_R> Cale: yes - i'm trying to be lazy and not come up with a function to see whether two expressions are the same via a recursion and trying to let the list comprehension handle it all
15:48:12 <pao> mmorrow: thanks
15:48:18 <mmorrow> np
15:49:12 <erikc> when you use a binary function infix, does it default to left or right associative?
15:49:32 <mauke> > let (?) = (,) in 1 ? 2 ? 3
15:49:34 <lambdabot>   ((1,2),3)
15:49:54 <mauke> > let f = (,) in 1 `f` 2 `f` 3
15:49:55 <lambdabot>   ((1,2),3)
15:49:59 <mmorrow> also, it may be nice to have the ReadP src handy while reading that (i grabbed it from  http://darcs.haskell.org/libraries/base/Text/ParserCombinators/ReadP.hs  and un CPPed and cleaned it by hand according to my tastes, it's not that long)
15:50:01 <Beelsebob> can has infixr version?
15:50:05 <lambdabot> http://tinyurl.com/65rz3c
15:50:20 <mauke> > let infixr 1 `f`; f = (,) in 1 `f` 2 `f` 3
15:50:22 <lambdabot>   (1,(2,3))
15:50:24 <Anon_R> Cale: i'll just recursively define it, it's for a lambda calculus coursework and the onus is rather on the code working than it being particulary pretty
15:50:30 <Anon_R> Cale: thanks anyhow
15:50:50 <mauke> > let infix `f`; f = (,) in 1 `f` 2 `f` 3
15:50:51 <lambdabot>       precedence parsing error
15:50:51 <lambdabot>          cannot mix `f' [infix 9] and `f' [inf...
15:51:26 <vixey> Anon_R: you implement alpha equality?
15:51:46 <Anon_R> vixey: yessums
15:51:49 <Cale> Anon_R: You might define a fold for your expression type, but testing if two expressions are directly equal could be done using == if you've derived an Eq instance.
15:52:07 <vixey> Anon_R: I got somewhere in my code  alphaEqual = (==)
15:52:35 <vixey> Anon_R: if you use de bruijn indices you can just use the derived structural equality for alpha equivalence
15:53:17 <Anon_R> bruijn structures... hmmm my notes my call it something else... i've generated a binding diagram
15:53:30 <Anon_R> from that i can just check whether two diagrams are equal
15:53:50 <vixey> Anon_R: By de bruijn I mean something like  \x -> \y -> x  is notated as  Lam (Lam (Var 1))
15:53:50 <Anon_R> i suppose deriving equality here might work... sillycakes me
15:53:59 <Anon_R> yes... that's what i've got.
15:54:17 <Anon_R> BLam (BLam (BApp (BApp (Ptr 4) (BVar "z")) (Ptr 2))) as an example of my output
15:54:34 <mauke> BLAM BLAM BLAM
15:54:35 <Anon_R> righty o - i think i see how to proceed now
15:55:01 <Anon_R> vixey: thanks too
15:57:47 <Anon_R> yessums - it's giving me the right answers... i do tend to overcomplify things. Ta ta all
16:01:36 <dons> i don't understand people complaining about too many libraries. asking for the perfect one. that's why we're writing these libs -- to find the best one.
16:02:15 <Beelsebob> dons: I don't think they're really complaining about there being too many -- merely that it would be nice to have one that has all the best features of all of them
16:02:35 <Beelsebob> and that they'd like someone other than themselves to invest time in such an endevour
16:03:37 <ddarius> dons: I completely agree.
16:03:42 <Philippa> or alternatively, that they'd like to be told which to use as a "go-to" library
16:04:19 <ddarius> Beelsebob: If it was evident how to combine them all with the best features of each, someone would be doing it already.
16:04:37 <Beelsebob> ddarius: yep, what I said had a cheek full of tongue
16:05:09 <Beelsebob> that they're coming across to me as essentially saying "I don't like the situation, and I want you to do something about it for me"
16:06:33 <dons> there's a cultural gap between the post-hackage/cabal devs, and the email only crowd
16:06:49 <dons> we've moved so far, so fast, its hard for them to know what the state of the art is.
16:07:30 <dons> still waiting for bulat or andrew coppin to upload something to hackage. that'll be a fine day.
16:10:06 <thoughtpolice> man i hate this internet :(
16:10:18 <Philippa> dons: to be fair, one of these years I might too
16:10:32 <monochrom> I hate the other internet. :)
16:10:54 <dons> Philippa: yeah, what's up with that? :)
16:11:00 <ddarius> Philippa: Me too...
16:11:09 <dons> slackers!
16:11:19 <dons> you better make it into the first 1000 packages.
16:11:24 <monochrom> haha, dons, who is complaining about too many libraries? last I heard it was too few.
16:11:28 <dons> hah
16:11:39 <dons> 897 packages on hackage now.
16:11:45 <dons> so you've got about 2 months, imo.
16:11:50 <olsner> all my hackage libraries are still in the meditation state, not quite yet ready to be written down
16:11:52 <dons> unless we advertise a prize.
16:12:10 <dons> who's going to write the killer graph library?
16:12:15 <dons> or our first gpu programming library on hackage?
16:12:17 <monochrom> "the exact 1000th library will get a prize"?
16:12:24 <erikc> a 2 foot tall graphite lambda logo
16:12:30 <erikc> for your garden
16:12:30 <Beelsebob> dons: maybe you need to publish stats about the people with the most packages, and get a race going
16:12:31 <Beelsebob> :D
16:12:31 <dons> monochrom: i'm not sure how to do it...
16:12:42 <dons> Beelsebob: yeah.. i think that would do well to fire up things.
16:12:43 <lament> erikc: diamond, surely
16:12:55 <dons> Beelsebob: i'll have a go.
16:12:58 <dons> gwern will win i guess.
16:13:00 <ddarius> erikc: I don't have a garden.
16:13:04 <dons> so i'll need to check the maintainer field
16:13:23 <ddarius> Isn't there already a GPU programming library on Hackage?
16:13:40 <Beelsebob> dons: that or the uploader, but I guess that's unfair to people who maintain a lot, but aren't primary devs
16:13:41 <dons> well, the only two i know of are obsidian at chalmers, and dph-gpu at unsw, neither on hakcage
16:15:02 <Beelsebob> hmm, I need to upload 2 more packages and hit 1% of all hackages being mine >.>
16:16:31 <ddarius> I could try to figure out how to make my LADSPA binding trivial to build and upload that.
16:16:48 <dons> it would be interesting to let the -cafe@ know who's actually contributing all the code
16:16:58 <dons> the open source crowd is the key growth driver now
16:17:04 <dons> we should make sure people know that.
16:17:11 <ddarius> I should look at the Google Charts API thing on Hackage since I was developing another one when that one was put up.
16:17:41 <ddarius> And roconnor put up a Data.Color library, but he has a somewhat different emphasis than one that I'd like.
16:18:39 <ddarius> If I figure out how, maybe I'll put up some nonlinear controller design tools.
16:18:42 <thoughtpolice> i think i have a few up there
16:18:57 <thoughtpolice> of course most of them are defunct now; only built on ghc 6.6, etc.
16:19:24 <mm_freak> tryJust (\e -> if isEOFError e then Just () else Nothing)  -- very ugly code
16:19:28 <mm_freak> is there any way to write this nicer?
16:19:49 <ddarius> tryJust (guard . isEOFError)
16:19:58 <mm_freak> indeed, thanks
16:20:41 <mm_freak> is this actually the proper way to handle EOF?
16:21:01 <leimy> Got my copy o real world haskell
16:21:13 <ddarius> leimy: Emailed a picture to dons yet?
16:21:19 <leimy> not yet...
16:23:12 <thoughtpolice> dons: re. gpu stuff, I was thinking of writing a binding along the lines of pycuda - http://en.wikipedia.org/wiki/CUDA#Example (see the lower part)
16:23:14 <lambdabot> Title: CUDA - Wikipedia, the free encyclopedia
16:23:37 <thoughtpolice> since I installed cuda 2.0 on this mbp not too long ago
16:23:39 <Beelsebob> thoughtpolice: wait half a month for OpenCL to come out at least
16:23:42 <thoughtpolice> i have way to many ideas
16:23:43 * ddarius probably doesn't have a GPU to speak of anyway.
16:24:49 <dons> leimy: woo!
16:24:59 <dons> leimy: yeah, send a picture. where are you ?
16:25:04 <leimy> Seattle WA
16:25:09 <leimy> -ish :-)
16:25:18 <leimy> dons: email?
16:25:20 <dons> oh good. so amazon has made it to the west coast (ironically)
16:25:26 <dons> leimy: sure.
16:25:27 <leimy> I think I clobbered that thread
16:25:32 <leimy> so I don't know where to send it :-)
16:25:38 <dons> dons <> galois.com
16:25:43 <dons> just send me a link to a photo
16:25:46 <leimy> swee
16:25:49 <leimy> ok I can do that.
16:25:52 <dons> and i'll add it to the blog (to track where the books are making it to)
16:26:08 <Beelsebob> am I the only one who thinks of LCARS every time he sees a new HCAR
16:26:17 <leimy> nope
16:26:22 <dons> so we've had a few east coast and now a west coast delivery. waiting on canada, uk, germany...
16:27:06 <ddarius> HCAR always pops out people you've never heard of doing things you've never heard of.
16:27:25 <dons> you should also go into amazon and tag it as a 'haskell' book and rate it and so on. helps it appear in searches for programming books.
16:27:38 <dons> so instead of getting a ruby book, people might end up with a haskell book this xmas :)
16:27:54 <leimy> Heh
16:27:55 <leimy> yeah
16:28:18 <pumpkin_> dons: is there somewhere I can order the haskell book that makes you more money? or are all online retailers the same to you?
16:28:24 <pumpkin_> RWH that is
16:28:39 <pumpkin_> did I already ask that question? I have a feeling I did
16:28:51 * pumpkin_ is getting old
16:30:54 <dons> pumpkin_: i don't actually know. i imagine o'reilly has the least markup. probably you should just pick whatever is cheapest.
16:31:36 <haskellnoob> hello, i have a question, i need String for example "ABC" of ["A","B","C"] ... how do I do this?
16:31:57 <mauke> concat?
16:32:01 <dons> > map (:[]) "ABC"
16:32:02 <lambdabot>   ["A","B","C"]
16:32:07 <dons> > concat ["A","B","C"]
16:32:08 <lambdabot>   "ABC"
16:32:28 <leimy> dons
16:32:30 <leimy> oops
16:32:32 <leimy> dons: http://gallery.me.com/leimy2k#100008
16:32:33 <lambdabot> Title: MobileMe Gallery
16:32:57 <dons> yay!
16:33:04 <dons> leimy: seattle/wa ?
16:33:16 <leimy> Lynnwood, WA, approximately 15 miles north of Seattle
16:33:20 <dons> sweet.
16:33:28 <dons> thanks!
16:33:31 <leimy> I just reviewed on Amazon too
16:34:46 <dons> oh, exciting. is that the first review?
16:34:52 <leimy> Yes apparently :-)
16:35:28 <dons> awesome!
16:38:56 <profmakx> hm. 23 pounds from amazon.co.uk. perhaps i should just place my order
16:39:18 <profmakx> having books on dead trees is much better than on screen
16:39:44 <leimy> heh
16:39:48 <leimy> I like to have one for the bus.
16:40:54 <ehird> I should buy RWH.
16:40:55 <ehird> :)
16:40:55 <leimy> I'm also giving great consideration to writing some important and very critical system software with Haskell in the next 30 days using the FFI stuff to control CAN bus and other weird stuff :-)
16:41:03 <ehird> But I like the site design more than the book :(
16:41:06 <ehird> (design)
16:42:05 <leimy> then I'd have a system with a large Erlang piece talking to a Haskell piece talking to a really tiny C piece
16:43:30 <haskellnoob> http://hpaste.org/12472 ... I really cant find my the error :( the decode one is working good but in the encode
16:43:46 <haskellnoob> i hope somebody of you can tell me where the error is
16:44:50 <haskellnoob> actually i got it working when i put the output of encode to [String] but then it looks like ["A","B","...] what i need is "ABC" and the map (:[]) is not working
16:44:53 <mauke> the types don't match
16:45:33 <mauke> why are you using map (:[])?
16:46:04 <haskellnoob> I want to split the String to a List of strings then i can use map
16:46:25 <mauke> no
16:46:33 <mauke> you can just use map on the string
16:47:23 <haskellnoob> ok ive done that before
16:47:37 <mauke> good
16:47:53 <haskellnoob> on this version: http://hpaste.org/12473
16:48:10 <haskellnoob> with this its working but now it outputs the List of Strings
16:48:15 <haskellnoob> but i need only one String
16:48:25 <mauke> <mauke> concat
16:49:09 <Raevel> > concat ["a","b","c"]
16:49:10 <lambdabot>   "abc"
16:49:43 <gwern> mapConcat?
16:49:58 <gwern> or was it concatMap...
16:50:03 <gwern> @hoogle concatMap
16:50:04 <lambdabot> Prelude concatMap :: (a -> [b]) -> [a] -> [b]
16:50:04 <lambdabot> Data.ByteString concatMap :: (Word8 -> ByteString) -> ByteString -> ByteString
16:50:04 <lambdabot> Data.Foldable concatMap :: Foldable t => (a -> [b]) -> t a -> [b]
16:52:38 <haskellnoob> hmm sorry i dont understand concatmap
16:52:45 <haskellnoob> what does this function do?
16:53:03 <pumpkin_> @src concatMap
16:53:04 <lambdabot> concatMap f = foldr ((++) . f) []
16:53:27 <pumpkin_> apply the function, then concatenate its output to the list accumulator?
16:55:06 <Raevel> haskellnoob: the same as using concat (map f s) if f :: a -> String
16:57:48 <mm_freak> is there a standard about how 'lines' determines EOLs?
16:58:23 <skorpan> i'm guessing it matches differently on different systems
16:58:27 <mm_freak> haskellnoob: 'map' maps a function over a list, 'concatMap' maps a non-deterministic function
16:58:50 <mm_freak> haskellnoob: concatMap f = concat . map f
16:59:38 <mm_freak> skorpan: well, i'm needing it for a network protocol, so guessing is bad…  i think, i'll implement the splitter explicitly
17:00:19 <Raevel> mm_freak: why non-deterministic?
17:00:34 <mm_freak> Raevel: non-determinstic = having arbitarily many results
17:00:56 <mm_freak> deterministic = having exactly one result
17:01:05 <pao> which is the best doc explaining monad transformers?
17:01:40 <Raevel> oh, you meant it like that, alright
17:01:52 <mm_freak> pao: http://haskell.org/haskellwiki/Monad_Transformers_Explained
17:01:54 <lambdabot> Title: Monad Transformers Explained - HaskellWiki
17:02:11 <haskellnoob> yes its working now !!
17:02:20 <Raevel> haskellnoob: awesome
17:02:36 <pao> mm_freak: thanks
17:02:49 <haskellnoob> But what i need to do next is to seperate
17:02:59 <Raevel> separate how?
17:03:12 <mm_freak> pao: actually, there is nothing special about then…  while 'State s a' has a result type of 'a', 'StateT s m a' has a result type of 'm a'
17:03:31 <haskellnoob> so encode "ABC" => "... --- ..." with a free space
17:03:35 <mm_freak> you can use the 'lift' function to perform computations in 'm'
17:04:06 <pao> mm_freak: yep... I need to grasp the use cases... it's not so obvious for me
17:04:23 <mm_freak> pao: for example, implicit state in IO
17:04:28 <mm_freak> StateT s IO a
17:04:33 <Raevel> @hoogle [String] -> String -> String
17:04:33 <lambdabot> Distribution.Simple.PreProcess.Unlit plain :: String -> String -> String
17:04:33 <lambdabot> Distribution.Simple.Utils findFile :: [FilePath] -> FilePath -> IO FilePath
17:04:33 <lambdabot> Data.List intercalate :: [a] -> [[a]] -> [a]
17:04:48 <mm_freak> pao: here is an example: http://hpaste.org/11993
17:04:54 <pao> mm_freak: suppouse I'd like to implement a naive parser
17:04:57 <mauke> haskellnoob: you want 'unwords'
17:05:06 <pao> mm_freak: I used a simple State monad
17:05:27 <pao> mm_freak: suppouse I'd like to return multiple parse results
17:05:34 <haskellnoob> yes ive seen this function... but then i dont need concatMap anymore right?
17:05:43 <mauke> yeah, just plain map
17:05:55 <pao> mm_freak: I'd like something like (s -> [(a,s)])
17:06:01 <mauke> also, shouldn't you be in bed? :-)
17:06:07 <mm_freak> pao: yeah, that would be a use case:  ParserT [] a
17:06:09 <haskellnoob> hmm i think i tried this already and there were only errors.. i try this again
17:06:26 <mm_freak> actually a parser can be understood as:  State String a
17:06:27 <mauke> > unwords (map show [100, 200, 300])
17:06:29 <lambdabot>   "100 200 300"
17:06:37 <mm_freak> so a non-deterministic parser would be:  StateT String [] a
17:06:51 <mm_freak> to return multiple results, use the 'lift' function
17:07:03 <pao> mm_freak: type MyParser s a = StateT s [] a
17:07:36 <pao> mm_freak: as you can see I got the right signature...
17:07:47 <haskellnoob> yes !! then i think ive made a failure with the brackets
17:07:52 <haskellnoob> thanks
17:07:56 <mm_freak> pao: almost…  there is no reason to be polymorphic in the state type
17:07:57 <pao> mm_freak: I cannot understand how to use lift for returning multiple results
17:08:23 <mm_freak> :t lift
17:08:24 <lambdabot> forall (m :: * -> *) a (t :: (* -> *) -> * -> *). (Monad m, MonadTrans t) => m a -> t m a
17:08:26 <psygnisfive> anybody up for a simple CS-y reverse engineering puzzle? :3
17:08:38 <lament> sure. How much will you pay?
17:08:52 <psygnisfive> oh you.
17:08:53 <pumpkin_> psygnisfive: let's hear it!
17:09:06 <mm_freak> pao: you can use 'lift' to return something in the lower monad:  lift [1,2,3]
17:09:17 <psygnisfive> well its slightly verbose, so let me type it up and stick it on my server for you
17:09:49 <pao> mm_freak: let me try it
17:10:03 <pao> mm_freak: it's not so obvious :-) for me at least :-)
17:10:28 <mm_freak> yeah, the StateT s [] monad is a bit weird at first, particularly because of this:  get >>= \s -> …
17:10:46 <mm_freak> you'd expect 's' to be a single value, but it is non-deterministic, so there may be multiple 's' values
17:11:01 <mm_freak> you still handle it like there were only a single 's'
17:11:14 <mm_freak> just like in the list monad:  [1,2,3] >>= \x -> …
17:11:32 <mm_freak> there 'x' doesn't mean a specific value, but all values 1, 2 and 3
17:11:38 <MikeMayer> good evening gentlemen
17:12:05 <mm_freak> hello there
17:13:19 <pao> mm_freak: yep... in general I'd like to be able to infer the semantics of a monad stack ... that's what I miss... :-)
17:14:05 <Philippa> pao: there's a rule of thumb that works if you're used to the idea of rules with precedence
17:14:30 <pao> Philippa: can you elaborate?
17:14:49 <Philippa> which is that monads lower down the stack have precedence over monads above them. So with ErrorT State, the State will persist through exceptions, whereas with StateT Error, the State is subject to them
17:15:04 <Philippa> (and thus an exception will undo updates to it)
17:15:07 <pao> mm_freak: the problem of non-determinism is also with a simple put or get
17:15:31 <mm_freak> pao: that's not a problem, but a feature
17:16:08 <mm_freak> State s gives you implicit state, [] gives you implicit non-determinism, so StateT s [] gives you implicit stateful non-determinism
17:16:11 <pao> Philippa: it would be really useful if I understood ;-)
17:16:55 <mm_freak> it sucks that we don't have a working ListT =)
17:16:56 <dolio> The only problem with that rule is StateT s Cont, because that instance is crazy.
17:17:03 <pao> mm_freak: yep... I grasp perfectly the type signature... I've successfully designed it
17:17:06 <Philippa> pao: if I handed you, say, a board game with numbered rules, and told you that where the rules clashed, the lower numbers had priority, would you know what I meant?
17:17:07 <Saizan> jsn: how did it go with genericZip?
17:17:07 <dolio> Use LogicT.
17:17:16 <jsn> Saizan: it is no good
17:17:18 <pao> mm_freak: what I miss is the implementation strategy :-)
17:17:24 <jsn> Saizan: have to use lots of annotations
17:17:46 <Philippa> dolio: Cont on the bottom is generally confusing, no?
17:17:55 <psygnisfive> pumpkin_: wellnowwhat.net/puzzle.txt
17:18:01 <pao> Philippa: yep...
17:18:08 <Saizan> jsn: really?
17:18:12 <jsn> the core problem is i can't specify this:
17:18:17 <mm_freak> pao: you have a computation in some monad m, and you feel that you need implicit state, then StateT is for you
17:18:20 <mm_freak> or what do you mean?
17:18:25 <dolio> Philippa: Well, I'd expect it to undo state changes and such, like lists, but it doesn't.
17:18:27 <Philippa> pao: right. State effectively has rules that govern how state behaves, for example
17:18:31 <jsn> class Z f r | f -> r where
17:18:35 <dolio> Philippa: The one from monadLib does it right, I think.
17:18:35 <jsn> and then instances
17:18:57 <Philippa> whereas things like Error have 'control flow' rules
17:19:24 <jsn> instance Z ([a] -> [b]) [(a, b)] where zip :: [a] -> [b] ->  [(a, b)]
17:19:24 <Philippa> which may say things like "forget everything that happened since..." - if Error's below State then that affects the State
17:19:50 <Philippa> Error's idea of "everything" includes the state because state's built on top of it
17:19:53 <jsn> if i try    class Z f r | f -> r where zip :: f -> r
17:19:58 <jsn> of course that is all wrong
17:20:00 <pao> Philippa: I think I get it
17:20:01 <Philippa> whereas if it's the other way round, error doesn't know about state
17:20:16 <pao> mm_freak: just give me some more seconds to solve my own puzzle
17:20:34 <Philippa> (not that it needs to 'know about' it in the sense of being written with state in mind or even having a specific case for it somewhere)
17:20:44 <dolio> Philippa: As it is, StateT s (Cont r) is the same as ContT r (State s) (I think).
17:21:00 <mauke> @unmtl StateT s (Cont r) a
17:21:00 <lambdabot> s -> (a -> s -> r) -> r
17:21:10 <mauke> @unmtl ContT r (State s) a
17:21:10 <lambdabot> (a -> s -> (r, s)) -> s -> (r, s)
17:21:14 <Philippa> dolio: hrmm. That makes some sense actually: Cont is a really really /weird/ state machine, in that the state's a pile of stacks, no?
17:21:33 <Saizan> jsn: didn't you want the result to determine the function? http://hpaste.org/12309
17:21:40 <Philippa> and state (more generally, there's a specification in terms of monoids) commutes with other state
17:22:12 <Philippa> mind you, it partly makes sense in a "that's still the wrong result" kind of way :-)
17:22:22 <dolio> :)
17:22:37 <Philippa> but it's easy to see how you'd goof it if you squint at it that way, if you follow me?
17:23:01 <psygnisfive> pumpkin_: does that make sense? lol
17:23:18 <erikc> there we go, RWH and The Elements of Style ordered, thats gonna be some good christmas readings
17:23:32 <pumpkin_> psygnisfive: the uppercase parameters are odd to buildS
17:23:41 <pao> mm_freak: Philippa: ok... I give up
17:23:56 <psygnisfive> pumpkin_: its not a haskell function, its just lambda notation :P
17:24:01 <pumpkin_> oh fair enough :P
17:24:14 <pao> mm_freak: Philippa: consumeUpToN :: Int -> StateT String [] String
17:24:48 <jsn> Saizan: wow, it seems you have figured it out
17:24:54 <pao> that's my signature... the semantics should be obvious
17:24:56 <jsn> i will study these, thank you
17:25:16 <Philippa> pao: yeah, I'd expect to get a state with each item in the list
17:25:17 <pao> how do I implement it?
17:25:43 <mm_freak> pao: what do you want it to do?  consume [0..n] characters at once?
17:25:47 <Saizan> jsn: unfortunately the genericZip's typesign is not very pretty
17:25:53 <mm_freak> (i.e. giving multiple results?)
17:26:30 <pao> Philippa: mm_freak: runStateT (consumeUpTo 2) "paolo" == [("", "paolo"), ("p","aolo"), ("pa","olo")]
17:27:50 <haskellnoob> so what i want to do next is to put the morseCode as a datatype http://hpaste.org/12475 but the first line does not work when i replace [MorseTable] anybody can help because i have little experience with own datatypes
17:27:53 <Philippa> bearing in mind that I'm not feeding this into an interpreter or anything...
17:28:58 <jsn> Saizan: you have such high expectations for yourself :)
17:29:07 <Philippa> consumeUpTo 0 = do s <- get; return ("", s)
17:29:32 <mm_freak> pao: it looks like you'd need to swap state and list in the monad stack for that
17:29:33 <Philippa> er, that return's broken
17:29:40 <Philippa> so...
17:29:45 <Philippa> consumeUpTo 0 = return ""
17:30:21 <Philippa> ..hrmm, no, needs an accumulator
17:30:28 <mm_freak> yeah
17:30:35 <Philippa> gimme a moment to thrash this out in an editor and then we can see where it falls over?
17:30:36 <pao> mm_freak: I'm happy to see you use the term "looks like" :-) It doesn't really seem any obvious at all to me ;-)
17:30:54 <mm_freak> i think, you'd need ListT (State s) instead, but ListT is sometimes not a monad
17:30:57 <Philippa> the important part is to cons your alternatives together
17:31:08 <Philippa> mm_freak: nope, in fact we don't want that at all
17:31:28 <Botje> haskellnoob: if you change the type synonym for a data declaration, you have to add data constructors to the code
17:31:33 <mm_freak> pao: the problem with StateT s [] is that you can return multiple results, but you can't do multiple state changes
17:31:35 <Philippa> pao: do you have a nice name for non-deterministic or?
17:31:41 <mm_freak> the state is still deterministic
17:31:55 <Philippa> mm_freak: er, no, it's not. The state's affected by the list
17:31:56 <pao> Philippa: nope :-)
17:32:28 <mm_freak> Philippa: sure, and we need it the other way round =)
17:32:45 <pao> mm_freak: Philippa: my heart rejoices :-) I was fearing that I wasn't able to solve a naive problem
17:32:51 <Philippa> no, we specifically need it non-det and that's what "affected by the list" means
17:32:51 <mm_freak> so you'd need to pass some kind of accumulator along with the state
17:33:07 <Philippa> you need an accumulator in building your alternatives, yes
17:33:16 <mm_freak> that's my point
17:33:23 <Philippa> pao: actually I can solve it, but give me a moment
17:33:39 <Philippa> it's late and I've not written any code in a month or two :-)
17:33:41 <jsn> haskellnoob: please tell us more about the error you get from the compiler
17:33:53 <mm_freak> pao: doing multiple state changes can only be done through returning multiple results and changing the state _later_ accordingly
17:34:25 * erikc grumbles about gcc not generating dwarf3 yet
17:34:39 <mm_freak> so i'd go for something like this:  StateT (Int, String) []
17:34:58 <mm_freak> where the Int in the state specifies a number of characters to drop unconditionally
17:35:01 <pao> mm_freak: I'm wondering if, for this parser, is not easy to directly write an instance for Monad
17:35:08 <gwern> @hoogle [a] -> Maybe a
17:35:09 <lambdabot> Data.Maybe listToMaybe :: [a] -> Maybe a
17:35:09 <lambdabot> Data.List find :: (a -> Bool) -> [a] -> Maybe a
17:35:09 <lambdabot> Prelude head :: [a] -> a
17:35:22 <gwern> hm.
17:35:27 <gwern> @hoogle [a] -> a
17:35:28 <lambdabot> Prelude head :: [a] -> a
17:35:28 <lambdabot> Prelude last :: [a] -> a
17:35:28 <lambdabot> Data.List head :: [a] -> a
17:35:28 <mm_freak> pao: i think, that would be even crazier to implement
17:35:34 <_roconnor> @seen mib_ta2z31
17:35:34 <lambdabot> I saw mib_ta2z31 leaving #haskell 10m 19s ago, and .
17:35:41 <gwern> @hoogle init
17:35:42 <lambdabot> Prelude init :: [a] -> [a]
17:35:42 <lambdabot> Data.ByteString init :: ByteString -> ByteString
17:35:42 <lambdabot> Data.List init :: [a] -> [a]
17:35:43 <mm_freak> and monad transformers are the way to go here, so i'd use them
17:35:56 * gwern wants safe head
17:36:13 <Axman6> gwern: i think listToMaybe is safe
17:36:17 <Philippa> hrmm, what's wrong with:
17:36:17 <Philippa> upTo 0 = lift (return acc)
17:36:17 <Philippa> upTo n = lift (consume n) ++ upTo (n-1)
17:36:21 <Axman6> > listToMaybe []
17:36:21 <roconnor> who doesn't what safe head?
17:36:22 <lambdabot>   Nothing
17:36:28 <Philippa> given an appropriate consume
17:36:31 <gwern> roconnor: -_-
17:36:35 <mm_freak> > listToMaybe "abc"
17:36:36 <lambdabot>   Just 'a'
17:36:44 <gwern> > listToMaybe ""
17:36:45 <lambdabot>   Nothing
17:36:53 <Philippa> to be fair, I'm probably cheating horrendously re the StateT
17:37:01 <haskellnoob> Yes, what he tells me is that he now dont get (Char,String)- couldnt match  expected CodeTree against inferred type (Char, [Char])
17:37:03 <Philippa> and it's hardly efficient
17:37:14 <gwern> > ''
17:37:15 <lambdabot>   <no location info>:
17:37:16 <lambdabot>      lexical error in string/character literal at chara...
17:37:20 <mm_freak> Philippa: this doesn't make much sense to me:  lift (consume n) ++ upTo (n-1)
17:37:23 <haskellnoob> so i think i make errors in the syntax
17:37:23 <Axman6> haskellnoob: huh, that's an odd error
17:37:35 <Philippa> mm_freak: which bit doesn't?
17:37:42 <Axman6> considering String = [Char]
17:37:51 <mm_freak> consider that the type of this expression needs to be StateT s [] r, not [r]
17:37:56 <Philippa> the ++?
17:38:05 <mm_freak> :t (++)
17:38:06 <lambdabot> forall a. [a] -> [a] -> [a]
17:38:22 <Philippa> hrmm, yeah, it needs reboxing
17:38:32 <haskellnoob> yes i know that, its [Char] in the compiler... but i know its the same as String
17:38:55 <Philippa> d'oh, of course, it's ++ that needs lifting, no?
17:38:56 <Axman6> haskellnoob: whats the code you're having a problem with?
17:39:26 <gwern> @hoogle catchDyn
17:39:26 <lambdabot> Control.Exception catchDyn :: Typeable exception => IO a -> (exception -> IO a) -> IO a
17:39:31 * Axman6 guesses something like (a,"hello") ++ ('b',"world")
17:39:33 <haskellnoob> http://hpaste.org/12476 , thats the cod with the error
17:40:03 <Axman6> haskellnoob: and where's the error?
17:40:15 <haskellnoob> im trying to use the data declaration
17:40:16 <Axman6> could you append the error to that hpaste?
17:40:26 <BMeph> Hm, one behavior I've gotten used to in a hurry, from Google's browser:
17:40:37 <haskellnoob> of course
17:40:46 <BMeph> Pulling a tab away to make a new instance.
17:41:28 <Axman6> haskellnoob: for one, morseTree is not a CodeTree but you're using (dec1 morseTree)
17:41:30 <Philippa> mm_freak: okay, yeah, you're going to have to explicitly do a bunch of runStateT here, aren't you?
17:41:59 <Axman6> haskellnoob: i think you might want 'type CodeTree = [(Char,String)]'
17:42:29 <Philippa> your suggestion doesn't have the desired semantics though, we /want/ a state per item in the list
17:42:32 <haskellnoob> http://hpaste.org/12477
17:43:05 <mm_freak> Philippa: i'm trying to solve it
17:43:09 <haskellnoob> yes ok, but how do i define that morseTree is a CodeTree?
17:43:16 <Axman6> haskellnoob: do you see how an example of a CodeTree would be 'MorseTable ('a',"hello")'?
17:43:59 <Axman6> the type of MorseTable ('a',"hello") would be CodeTree. ('a',"hello") is just (Char,String)
17:44:17 <Axman6> and morseTree is [(Char,String)]
17:44:23 <gwern> the yi codebase sometimes make me cringe
17:44:30 <gwern> here's an example why: shift (Event k ms) = Event k $ nub $ sort (MShift:ms)
17:44:33 <gwern> ctrl (Event k ms) = Event k $ nub $ sort (MCtrl:ms)
17:44:36 <gwern> meta (Event k ms) = Event k $ nub $ sort (MMeta:ms)
17:44:39 <gwern> super (Event k ms) = Event k $ nub $ sort (MSuper:ms)
17:45:03 <Axman6> haskellnoob: so, if you define type CodeTree = [(Char,String)] you should be ok
17:45:54 <dons> gwern: ?
17:46:00 <dons> oh, just the nub / sort reuse?
17:46:03 <haskellnoob> hmm actually that ive done before
17:46:15 <haskellnoob> you see the commented line
17:46:52 <Axman6> haskellnoob: you see how CodeTree is not a list?
17:46:59 <gwern> dons: not just that, they're all exactly the same except for the MShift, MCtrl, MMeta, and MSuper tokens
17:47:22 <Axman6> and your morseTable has nothing to do with your CodeTree definition at all
17:48:03 <haskellnoob> yes its another version my working code is example: decode :: [MorseTable]...
17:48:25 <gwern> (hm, the new exception module is hitting Yi hard)
17:48:29 <Axman6> yes, that works
17:48:43 <haskellnoob> but i what i want to do is to create a data declaration
17:49:25 * Axman6 gets breakfast
17:52:03 <Philippa> mm_freak: yeah, by the time I add the runState calls I've got it solved
17:52:40 <Philippa> it really is just a boxing issue
17:52:41 <haskellnoob> hmm its ok i will try myself later but thank you very much for your help bye
17:52:44 <mm_freak> here is a dirty solution:  StateT String [] (Int, String)
17:53:39 <pao> mm_freak, Philippa: I eager to see the solution :-)
17:55:19 <pao> mm_freak: if we need to carry the state around explicitly maybe we can drop StateT...
17:56:18 <Philippa> pao: that's definitely an easier way of doing things for now
17:56:46 <mm_freak> then it wouldn't be a monadic parser anymore, but i think, the easiest way to do it is to write your own monad
17:56:47 <pao> Philippa: undeterminism with the list monad, explicit state
17:57:42 <pao> mm_freak: that's what I begin to suspect...
17:57:52 <BMeph> gwern: Doesn't it just make your fingertips itch to write a Functor decl for it? ;)
17:58:20 <mm_freak> well…  it seems, monad transformers aren't always the solution
17:58:42 <gwern> BMeph: it makes my fingers itch tremendously but I dunno if I itch for Functor decls
17:58:59 <pao> mm_freak: Philippa: I'll let you know if I can write my own monad instance
17:59:20 <BMeph> gwern: Well, sublimate the itch to press the Delete key... ;)
17:59:22 <pao> mm_freak: Philippa: thank you very much for your time... very helpful :-)
18:00:06 <gwern> @hoogle ioErrors
18:00:06 <lambdabot> Control.Exception ioErrors :: Exception -> Maybe IOError
18:00:29 <mm_freak> have fun =)
18:00:56 <Philippa> mm_freak: you can build a monadic wrapper around it when you're done, no problem there
18:01:41 <mm_freak> well, no problem here, no problem there…  up to now, there isn't a solution =)
18:01:52 <pao> mm_freak: LOL
18:13:56 <gwern> @hoogle a -> [a] -> Int
18:13:57 <lambdabot> Data.List elemIndex :: Eq a => a -> [a] -> Maybe Int
18:13:57 <lambdabot> Data.List elemIndices :: Eq a => a -> [a] -> [Int]
18:13:57 <lambdabot> Data.List intersperse :: a -> [a] -> [a]
18:14:07 <gwern> @hoogle [a] -> [a] -> Int
18:14:08 <lambdabot> Prelude (++) :: [a] -> [a] -> [a]
18:14:08 <lambdabot> Data.List (++) :: [a] -> [a] -> [a]
18:14:08 <lambdabot> Data.List deleteFirstsBy :: (a -> a -> Bool) -> [a] -> [a] -> [a]
18:15:04 * gwern needs foo "bar" "foo bar baz" ~> 8. what does data.list have to help me...
18:18:03 * BMeph wonders what gwerm wants foo "bar" "foo baz quux" to be...
18:19:25 <gwern> I figured it'd call 'unsafePerformIO fireMissiles'. that'll learn the user not to provide necessary input!
18:28:17 <monochrom> 「unsafePerformIO fireMissiles」 is referentially transparent if no one survives after the first launch to check for the second time.
18:28:55 <Axman6> i think unsafePerformIO launchMissiles should have the type Target ->
18:29:58 <Axman6> possibly because you hope it never returns
18:30:45 <scook0> at least it's idempotent
18:31:38 <acidjnk> What's the most elegant way to express "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"?
18:31:50 <acidjnk> concat [a..z] [A..Z]?
18:31:59 <acidjnk> concat [[a..z] [A..Z]]
18:32:37 <tromp> [a..z]++ [A..Z]
18:32:50 <shepheb> needs more single quotes
18:33:38 <acidjnk> thanks
18:38:29 <Lemmih> thoughtpolice: Hey.
18:38:54 <Lemmih> thoughtpolice: I'm not sure how to convert the repo to darcs-2.
18:39:36 <gwern> Lemmih: darcs help convert
18:40:06 <gwern> it goes something like 'darcs convert; mv new-repo ../; cd ../; rmd old-repo; mv new-repo old-repo'
18:40:08 <Lemmih> gwern: I don't understand the consequences of my action.
18:40:17 <gwern> :)
18:40:55 <gwern> well I've not yet heard of anything bad coming from converting to darcs-2 aside from a few people complaining that there's a small slowdown on normal operators
18:41:07 <gwern> @hoogle a -> [a] -> [Int]
18:41:08 <lambdabot> Data.List elemIndices :: Eq a => a -> [a] -> [Int]
18:41:08 <lambdabot> Data.List intersperse :: a -> [a] -> [a]
18:41:08 <lambdabot> Data.List insertBy :: (a -> a -> Ordering) -> a -> [a] -> [a]
18:41:18 <Lemmih> Heard anything good?
18:41:58 <gwern> Lemmih: well, I really really like the global cache, but that's technically a feature of the hashed repo format not darcs-2 itself
18:42:23 <gwern> and I've heard that the merge conflict could be really annoying but I rarely if ever ran into that, so darcs-2 fixing it is immaterial
18:42:31 <Saiz> darcs get should be much faster in the -2 format?
18:42:54 <gwern> Saiz: if the patches are in the cache yes , get is almost infinitely faster
18:43:10 <gwern> (if you follow me)
18:43:24 <thinkpo> grr
18:43:31 <thinkpo> damn internet
18:44:39 <gwern> hm. this yi function is proving tricky. move to one space before '>', but if there is no > in the line, move to the beginning
18:44:59 <gwern> but make it so calling it twice moves you to a > before the first >
18:45:00 <thoughtpolice> Lemmih: do 'darcs convert lhc lhc-darcs2'
18:45:08 <thoughtpolice> Lemmih: it'll give you a warning and you'll have to confirm
18:45:28 <Lemmih> thoughtpolice: On code.haskell.org?
18:45:33 <gwern> can't just 'move to previous '>'', because once you move to one space after it, you won't move again...
18:45:39 <gwern> Lemmih: yes this is a shell level task
18:45:56 <thoughtpolice> Lemmih: well, I was going to suggest do it on your box and then use 'darcs put' to put it up there
18:46:01 <thoughtpolice> but yeah you can do it on c.h.o
18:46:15 <thoughtpolice> Lemmih: actually, if you're doing it on c.h.o, just do 'darcs convert lhc'
18:46:29 <thoughtpolice> you probably won't have permission to write to another dir, and the last argument to that command specifies the output dir
18:46:33 <thoughtpolice> otherwise it does it in place iirc
18:46:53 <Lemmih> yi would be a lot better if it didn't leak like a sieve.
18:47:12 <thoughtpolice> Lemmih: yes, constant increasing memory usage is not attractive to say the least.
18:47:17 <thoughtpolice> :P
18:47:46 <gwern> can't say I've noticed the leak, but I have lots of ram and I rarely stay in yi for long since I'm hacking it
18:48:00 <thoughtpolice> it's not horrible or anything
18:48:10 <gwern> the use case in case you're wondering is the interactive ghci buffer
18:48:16 <thoughtpolice> for me yi starts off with about a 7mb footprint, but by just using it that will increase pretty constantly
18:48:30 <gwern> I want Home to move to just before the prompt, but I have to deal with user expressions that have > in them
18:48:50 <Lemmih> gwern: It gets quite slow after editing large files. I have 4G ram but it still requires me to restart it once in a while.
18:48:51 <gwern> since suppose it's 'Prelude> 4 > x', and I'm right after the x
18:49:14 <gwern> Lemmih: darcs yi or older yi? jpb is always tossing in little optimizations and things
18:49:32 <gwern> obviously you want Home to take you to the 4, not the x
18:49:47 <gwern> but writing this is tricky; I must be thinking about this wrong...
18:49:52 <Saiz> gwern: i'd kust start looking from the beginning of the line, rather than walking back from the end
18:50:30 <thoughtpolice> gwern: why don't you just jump to one spot after the first occurrence of '>' in that buffer, since you're pretty much guaranteed it's going to be after the list of loaded modules?
18:50:45 <thoughtpolice> (by one spot I mean one space)
18:51:00 <gwern> yeah... getFirstIndice '>', getFirstPosition '>', if currentPosition == getFirstPosition, go to SOL/Start of line else go to getFirstPosition
18:51:02 <thoughtpolice> er, first occurrence of '>' in that line, not buffer...
18:51:34 <Saiz> (btw, a yi ghc frontend using the ghc-api might be cleaner and allow more features than wrapping ghci)
18:51:37 <thoughtpolice> Lemmih: when you convert the repo let me know.
18:51:44 <gwern> thoughtpolice: well the convention is the first hit of Home does the smart thing and jumps to the start of the contents, and then if you're already at the start of the contents, then you go to colum 0
18:51:47 <thoughtpolice> Saiz: cabal install yi -fghcAPI
18:52:08 <gwern> I already have this function written for normal haskell code, it's just the format of the ghci buffer is different
18:52:22 <Saiz> thoughtpolice: does it work on 6.10?
18:52:32 <Lemmih> thoughtpolice: I can't push the darcs2 repo. Incompatibility with repository.
18:52:35 <thoughtpolice> Saiz: you'll need the darcs repository, but yes
18:52:42 <gwern> Saiz: let me try it
18:52:45 <thoughtpolice> Lemmih: hm. ok, I can convert and push if you would like.
18:52:55 <Lemmih> thoughtpolice: If you know how to do it, go ahea.
18:52:58 <Lemmih> *ahead
18:52:59 <gwern> hm. what a fascinating conflict
18:53:49 <thoughtpolice> heh, this conversion is going to take a while.
18:54:28 <thoughtpolice> Lemmih: note that converting to darcs 2 will require anybody with a darcs repository to remove it and check it out again
18:54:33 <thoughtpolice> since darcs1 and darcs2 formats are incompatible
18:54:48 <thoughtpolice> so you'll have to rm -r lhc; darcs get http://code.haskell.org/lhc after this
18:54:49 <lambdabot> Title: Index of /lhc
18:55:22 <thoughtpolice> but the darcs2 format is now the default and it's considered nice and stable to use.
19:04:52 <thoughtpolice> Lemmih: grrr, this internet connection is insanely frusterating
19:05:07 <thoughtpolice> Lemmih: ok anyway, I removed the stuff in http://code.haskell.org/lhc (as you can tell, it being empty)
19:05:09 <lambdabot> Title: Index of /lhc
19:05:45 <thoughtpolice> Lemmih: if you would convert the darcs1 repository to darcs2 using e.g. darcs convert lhc lhc-darcs2, and then doing 'cd lhc-darcs2; darcs put lemmih@code.haskell.org:/srv/code/lhc' that should handle it
19:06:11 <thoughtpolice> Lemmih: I'm literally probably getting about 8kb/s right now, so I really can't
19:06:33 <tanob> hello, anybody knows a haskell library that generates JVM bytecodes?
19:06:51 <Lemmih> Putting...
19:07:47 <thoughtpolice> Lemmih: when it's done tell me and I'll re-pull the repository
19:08:16 <Lemmih> thoughtpolice: The compiler pipeline is just two functions away from being pure, btw.
19:08:20 <Axman6> @help dice
19:08:21 <lambdabot> dice <expr>. Throw random dice. <expr> is of the form 3d6+2.
19:08:58 <thoughtpolice> Lemmih: yeah I noticed you lifted stuff in src/E out
19:09:03 <thoughtpolice> Lemmih: the typechecker is what's next?
19:09:28 <Axman6> @dice 3d6+2
19:09:29 <lambdabot> 3d6+2 => 11
19:09:33 <Axman6> @dice 3d6+2
19:09:34 <lambdabot> 3d6+2 => 11
19:09:35 <pumpkin_> lol
19:09:40 <Axman6> right...
19:09:51 <Lemmih> thoughtpolice: Yes, the typechecker and then E.LetFloat.floatOutward (it uses IO to generate unique names, yuk).
19:10:46 <scodil> on the type families wiki page there is an ominous sentence at the end: "NB: Equalities in superclass contexts are not fully implemented in the GHC 6.10 branch."   Does anyone know any more about that?
19:11:11 <Saiz> Lemmih: how do you generate them efficiently otherwise? or do you just hide that behind an unsafePerformIO?
19:11:16 <Lemmih> The naming situation is horrible. Changing it to something slightly more sane was what made the simplifier O(n) instead of O(n^2).
19:11:33 <thoughtpolice> god, i swear
19:11:49 <Lemmih> Saiz: We only locally unique names.
19:12:26 <Saiz> ah, i see
19:12:41 <Lemmih> *only need
19:13:16 <Lemmih> My keyboard accidentally the whole word.
19:13:16 <thoughtpolice> scodil: it means that doing things like 'class (F a ~ b) => C a b where ...' isn't supported yet
19:13:37 <Lemmih> thoughtpolice: Put successful.
19:14:10 <pumpkin_> has anyone used the matlab package on hackage?
19:14:17 <thoughtpolice> Lemmih: yay!
19:14:18 <athos> @dice 1d6
19:14:18 <lambdabot> 1d6 => 2
19:14:25 <athos> @dice 1d6+2
19:14:25 <lambdabot> 1d6+2 => 5
19:14:29 <athos> 8()
19:14:39 <athos> bad luck
19:15:33 <scodil> thoughtpolice: but I can use type equality constraints right now. Is there a page or mailing list thread somewhere talking about how unsupported it is?
19:15:34 <thoughtpolice> Lemmih: what'd you mean by the naming situation? the way the compiler internally handles symbols?
19:16:04 <thoughtpolice> scodil: yes, you can use type equality constraints regularly, it's just that the only place they aren't supported is in superclass contexts like the one above
19:16:18 <thoughtpolice> this is basically the last piece to the type family puzzle
19:16:19 <scodil> oh oh ok I get it
19:16:35 <scodil> but they're fine in instance constraints, right?
19:16:43 <thoughtpolice> yeah, you should be just fine
19:16:59 <thoughtpolice> Lemmih: perhaps this could be of use? http://hackage.haskell.org/cgi-bin/hackage-scripts/package/value-supply
19:17:06 <lambdabot> Title: HackageDB: value-supply-0.1, http://tinyurl.com/27ge84
19:17:27 <Lemmih> thoughtpolice: We have a good solution already. We just need to apply it consistently.
19:18:16 <pumpkin_> if I get something like matlab-0.1 failed during the configure step. The exception was:
19:18:16 <pumpkin_> exit: ExitFailure 1
19:18:26 <pumpkin_> is there some way to get a more meaningful message?
19:18:59 <thoughtpolice> Lemmih: what would that be? (i haven't looked into the patches for making e.g. some of the operations pure so you'll have to excuse me)
19:19:40 <Lemmih> thoughtpolice: Some of the code requires everything to be unique. Other code assumes shadowing is fine. This confusion requires a ton of unnecessary renaming.
19:20:25 <Lemmih> thoughtpolice: We thread around a map/set of the current scope and use that for generating locally unique names.
19:23:40 <thoughtpolice> Lemmih: ah ok
19:23:40 <thoughtpolice> Lemmih: I'll look into some of your patches then
19:24:03 <Axman6> @version
19:24:04 <lambdabot> lambdabot 4.2.2
19:24:04 <lambdabot> darcs get http://code.haskell.org/lambdabot
19:24:42 <drbean_> @hoogle [[a]] -> [a]
19:24:42 <lambdabot> Prelude concat :: [[a]] -> [a]
19:24:42 <lambdabot> Data.List concat :: [[a]] -> [a]
19:24:42 <lambdabot> Data.List intercalate :: [a] -> [[a]] -> [a]
19:25:21 <gwern> excellent, me rewritten Home seems to be working
19:25:38 <gwern> and it has the nice proprety of cycling between Sol and the > prompt too, which I didn't intend
19:28:35 <dolio> > runCont (runWriterT (callCC (\k -> tell "woo!" >> k ()))) id
19:28:36 <lambdabot>   ((),"")
19:30:28 <athos> good night everyone
19:32:54 <gwern> good night athos
19:33:03 <gwern> good night freenode, with #haskell in it
19:33:12 <gwern> good night lambdabot, in #haskell
19:33:54 <lambdabot> Good night, athos.
19:34:07 <gwern> good night, monads
19:36:11 <thoughtpolice> hehehe - http://www.cse.unsw.edu.au/~dons/images/commits/community/ghc-commits.png
19:36:15 <lambdabot> http://tinyurl.com/2yawtw
19:36:59 <thoughtpolice> how active :)
19:36:59 <thoughtpolice> nb: graph over the course of ~12 years ;)
19:37:22 <dons> yes, pretty solid development for the last few years
19:39:06 <gwern> 04 looked like a bad year
19:40:25 <gwern> wonder what happened in 98 and 01?
19:40:34 <thoughtpolice> Lemmih: btw, perhaps we could put a darcsweb interface up on lhc.seize.it ? also you got my message about niklas' adding pragma support to HSE, yes?
19:40:39 <pumpkin_> no matlab + haskell users around here? :P
19:40:43 <ddarius> gwern: It doesn't look like GHC has been at less than 1 commit per day since 98.  That's quite a few commits.
19:42:13 <gwern> ddarius: yes, but even with that baseline it's very spiky
19:43:41 <Lemmih> thoughtpolice: I did. Sounds great.
19:43:48 <Lemmih> thoughtpolice: I don't know much about darcsweb.
19:43:52 <dons> Lemmih: so you'll be pulling patches from jhc as they're done?
19:44:03 <Lemmih> dons: Say again?
19:44:21 <dons> if john fixes things in jhc, do you pull those patches into lhc?
19:44:58 <Axman6> dons: haven't touched your blog in a while
19:44:59 <Lemmih> dons: Sure, but I doubt John will be working jhc any time soon.
19:45:16 <dons> oh, he just said that 'jhc is still active'
19:45:21 <dons> on the mailing list.
19:45:33 <dons> Axman6: true. i've been doing things on the arch and rwh blogs
19:46:35 <Lemmih> dons: The last spike in patches were when I made jhc 6 times faster. Without that, jhc has flatlined for more than a year.
19:47:25 <dons> yep, certainly. i was just wondering if you still have the ability to pull patches from jhc's repo cleanly?
19:48:10 <thoughtpolice> Lemmih: seems darcsweb should pretty much 'just work' if you have CGI enabled - http://blitiri.com.ar/p/darcsweb/
19:48:17 <lambdabot> Title: darcsweb - A web interface for darcs
19:48:26 <Lemmih> Opening Main.hs takes 8megs. Scrolling to the bottom takes 56megs. Inserting a single space at the bottom takes 134megs. Sure looks like yi could be optimized a bit more.
19:48:43 <dons> wow. someone broke something.
19:48:55 <dons> that's not the yi i left :/
19:49:11 <dons> i should release 'classic-yi' on hackage.
19:49:11 <thoughtpolice> yeah, looks like
19:49:22 <thoughtpolice> Lemmih: have you been using yi while hacking lately? :]
19:49:34 <thoughtpolice> dons: re-release yi 0.1? that would be fun
19:49:41 <thoughtpolice> the 0.1 sources were minimal and clean
19:49:53 <dons> and fast.
19:50:02 <dons> but pretty low level. probably my first serious haskell project.
19:50:31 <Lemmih> dons: Pulling patches from jhc won't be easy. We've made quite a few structural changes and they'll only become more pronounced as time goes by.
19:50:37 <dons> ok.
19:50:49 <Lemmih> thoughtpolice: Yes, I've been using yi for the last couple of months.
19:51:20 <Lemmih> thoughtpolice: It has its problems but emacs is still ten times worse (:
19:51:34 <Axman6> Lemmih: any chance of a lhc hackage update anytime soon?
19:51:35 <thoughtpolice> yeah,
19:51:35 <thoughtpolice> notably, removing all the autoconf stuff
19:51:35 <thoughtpolice> and moving things into src/ will probably cause a lot of confusion
19:51:35 <thoughtpolice> Lemmih: hehe, I use emacs for everything
19:51:36 <thoughtpolice> although I have been trying to become a yi-convert
19:51:42 <thoughtpolice> Lemmih: I uploaded a new version yesterday
19:51:53 <thoughtpolice> Axman6: cabal update; cabal install lhc-0.6.20081127
19:52:01 <thoughtpolice> (you have to do it that way, btw. otherwise cabal install chooses the wrong version)
19:52:02 <Axman6> cheers
19:52:16 <dons> MikeMayer: how's the haskell hacking going?
19:52:16 <Lemmih> Axman6: I messed up the version name on the first release. Sorry 'bout that.
19:52:29 <thoughtpolice> Lemmih: speaking of that,
19:52:44 <MikeMayer> dons: just about complete with my assignment-- :)
19:53:20 <thoughtpolice> @tell dcoutts is there anyway you can remove http://hackage.haskell.org/cgi-bin/hackage-scripts/package/lhc-20081121 from hackage? it is an old version, but it technically has a higher version number than the version I uploaded, so 'cabal install lhc' defaults to the old version
19:53:20 <lambdabot> Consider it noted.
19:54:55 <dons> MikeMayer: hooray!
19:55:09 <Axman6> hmm, i need to get that ARM emulator on hackage now i've finished uni for the year
19:55:12 <dons> thoughtpolice: i think Ross can do that.
19:55:17 <Axman6> MikeMayer: what's the assignment?
19:55:19 <dons> Axman6: oh. huh. sounds interessting
19:55:26 <blackdog> is TH the only way to get code evaluated at compile time?
19:55:26 <pumpkin_> Axman6: ooh, that sounds awesome
19:55:47 <pumpkin_> Axman6: you gonna support arm disassembly too? you should release a separate package for that :P
19:55:57 <Axman6> i didn't write it, but i asked the author if i could stick it on there... just nee to ask if i can change the name from vARM to HARM ;)
19:55:59 <gwern> blackdog: well, there's type-level programming
19:56:11 <thoughtpolice> blackdog: you can pull an oleg and do some type-level stuff :]
19:56:12 <dons> blackdog: the only way? how many ways do you want?
19:56:35 <gwern> dons: one for each day of the week, pls, kthnx
19:57:16 <blackdog> dons: heh. ok, let me rephrase - if i want to do a significant amount of computation at compile time and package it into the binary, is TH a sensible way of doing that?
19:57:18 <Axman6> thoughtpolice: got an evample of how to use lhc?
19:57:25 <pumpkin_> does the mythical oleg come on irc?
19:57:37 <Axman6> i get: lhc: user error (LibraryMap: Library base not found!)
19:57:40 <blackdog> thoughtpolice: not nearly as smart as oleg :)
19:57:55 <Lemmih> Axman6: Excellent, that means it works (:
19:58:02 <gwern> pumpkin_: oleg is far too busy to idle here :)
19:58:02 <dons> TH is the sensible way to do that, yes.
19:58:13 <pumpkin_> what's he busy with? :) being awesome?
19:58:16 <dons> oleg asked for a code.haskell.org account today
19:58:16 <Axman6> Lemmih: but... where's my program? :(
19:58:36 <Axman6> dons: oh no... is that wise?
19:58:51 * Axman6 feels uneasy
19:58:57 <Lemmih> Axman6: Sorry, things aren't that easy. To actually compile anything you need the darcs repo (it contains the base library).
19:59:13 <Axman6> ah lame -_-
19:59:15 <Axman6> link?
19:59:42 <Lemmih> Axman6: http://code.haskell.org/lhc/
19:59:42 <lambdabot> Title: Index of /lhc
19:59:43 <thoughtpolice> code.haskell.org might explode because it can't handle oleg
20:00:08 <Lemmih> Axman6: Hopefully we'll get permission to upload the base package to hackage.
20:00:14 <thoughtpolice> Axman6: yeah, we would like to put lhc-base on hackage somehow so you can just do 'cabal install base --lhc'
20:00:32 <Axman6> i see... so it doesn't work atm?
20:01:06 <Lemmih> Axman6: We're afraid it'll have unforeseen consequences.
20:01:14 <dons> yes.
20:01:25 <dons> i think it should be called base-lhc or something. like ghc-prim
20:01:25 <thoughtpolice> Axman6: yeah, it could potentially stop every package uploaded to hackage from now on from building
20:01:36 <thoughtpolice> speaking of that dons I was thinking of that today
20:01:58 <thoughtpolice> perhaps an easy solution would just be to call it lhc-base and then hardwire the compiler to see occurrences of 'base' as 'lhc-base' and vice versa
20:02:16 <Lemmih> dons: But then we can't build anything that depends on base (which is everything).
20:02:37 <Lemmih> thoughtpolice: We'd have to hardwire cabal and cabal-install.
20:02:50 <thoughtpolice> Lemmih: ah, right.
20:02:56 <dons> Lemmih: ah
20:03:00 <gwern> 'base-lhc like ghc-prim' <-- how do you figure?
20:03:04 <dons> Lemmih: so best discuss with dcoutts
20:03:21 <dons> i'd imagine lhc should just provide base, the way ghc does.
20:03:26 <dons> it should be essentially wired in.
20:04:02 <Lemmih> dons: It's conceptually pretty to have base on hackage.
20:10:17 <jeffwheeler> dons: I'm sure you can't answer this, but I'll ask anyways. For things like Cryptol, are you modifying GHC's parser, or using something like Parsec to recreate the entire parser?
20:10:35 <jeffwheeler> (I'm reading some sample code from this page: http://www.galois.com/files/down/Cryptol_Whitepaper.pdf)
20:10:37 <lambdabot> Title: cache:http://www.galois.com/files/down/Cryptol_Whitepaper.pdf - Google Search
20:10:38 <scodil> lets play "help me name this function" :   f [1,2,3,4] = [ [2,3,4] , [1,3,4] , [1,2,4], [1,2,3] ]
20:11:14 <pumpkin_> dropOne ? :P
20:11:26 * pumpkin_ is terrible at naming
20:11:34 <scodil> dropOneEachInOrderAndCollect?
20:11:42 <pumpkin_> lol
20:11:48 <Axman6> ok, emailed the author of this ARM emulator, and i should be able to upload HARM, the haskell arm emulator
20:11:56 <pumpkin_> nice :D
20:12:00 <pumpkin_> what license?
20:12:13 <jeffwheeler> dropMovingTarget :P
20:12:21 <Axman6> dropOneEachInOrderAndCollectIntoAListSoTheyCanBeUsedLaterForOtherStuffMaybeHopfullyLazily
20:12:27 <papermachine> @djinn [a] -> [[a]]
20:12:27 <lambdabot> Error: Undefined type []
20:12:48 <Axman6> pumpkin_: MIT/X11
20:12:55 <pumpkin_> Axman6: *grin*
20:13:08 <jeffwheeler> dons: Or, I suppose, some derivative of quasiquotes.
20:13:19 <Axman6> it's not a full emulator, but it's fun to play with
20:16:16 <Axman6> dons: any chance you could clarify something in http://book.realworldhaskell.org/read/writing-a-library-working-with-json-data.html for me? i don't understand exactly what the exercises want
20:18:19 <Axman6> > sum . map (2^) $ [1..30]
20:18:21 <lambdabot>   2147483646
20:19:48 <cads> > 2^31 - 1
20:19:49 <lambdabot>   2147483647
20:20:43 <cads> > sum . map (2^) $ [0..30]
20:20:45 <lambdabot>   2147483647
20:22:50 <blackdog> ok. so i have some IO Foo action that i want to run at compile time. I'd like a variable "bar :: Foo" to be bound in my program. I can see runIO can get me to a Q Foo - how do i actually slot that in?
20:25:33 <newsham> maybe a Q Expr or Q Stmt or something?
20:26:39 <BMeph> blackdog: Are you a collector - you just like finding Foo items and giving them a home, or did you want to do something with the variable? :)
20:26:42 <dons> blackdog: don't you just $( ) the result?
20:27:31 <blackdog> BMeph: it takes forever to evaluate, so i want to stash it as a constant in the binary
20:27:52 <blackdog> dons: it tells me it expected IO Exp, and inferred IO Foo
20:28:20 <blackdog> BMeph: i promise i'm using it later :)
20:28:30 <sjanssen> @hoogle runIO
20:28:30 <lambdabot> Language.Haskell.TH runIO :: IO a -> Q a
20:28:30 <lambdabot> Language.Haskell.TH.Syntax runIO :: IO a -> Q a
20:28:30 <lambdabot> Language.Haskell.TH.Syntax qRunIO :: Quasi m => IO a -> m a
20:29:08 <newsham> blackdog: you need to make an Exp that constructs the Foo
20:29:27 <newsham> and then you can set  bar = $( ... )    your function that calculates it at compile time
20:29:54 <blackdog> newsham: does that mean i have translate my Foo-building code into the AST representation?
20:30:02 <newsham> yup
20:30:33 <newsham> (unless there's some way to have TH do that for you, but i dont know of one.. but i'm also no TH wiz)
20:30:33 <sjanssen> wait, there is supposed to be a way around that
20:30:57 <blackdog> newsham: ouch. that won't work, it's relatively complex code...
20:31:11 <newsham> is the constructor for Foo complex?
20:31:58 <blackdog> newsham: yeah
20:34:10 <newsham> you could always just use Show and write code to emit your data to a .hs file
20:34:25 <sjanssen> blackdog: you just need to use an [e| |] quotation
20:35:08 <sjanssen> blackdog: http://hpaste.org/12478
20:35:09 <Axman6> dons: i'd hate to be filling up the reddit homepage :P
20:36:45 <blackdog> sjanssen: thanks, that looks like exactly what i need. i'll go try it out :)
20:38:11 <BMeph> > map snd . oneOf $ [1,2,3,4]
20:38:13 <lambdabot>   [[2,3,4],[1,3,4],[1,2,4],[1,2,3]]
20:38:20 <BMeph> @bo
20:38:21 <lambdabot> :)
20:38:27 <Lemmih> dons: darcs-graph doesn't work with darcs-2?
20:38:55 <newsham> sjanssen: that will make a string literal of whatever you read, no?
20:39:54 <blackdog> sjanssen: annotated that hpaste - i have to implement an instance of ... something?
20:40:07 <newsham> http://hpaste.org/12478#a3
20:41:09 <newsham> oh, i'm dumb, nevermind
20:41:35 <sjanssen> blackdog: ah, hmm
20:41:55 <Axman6> src oneOf
20:41:58 <sjanssen> I guess Lift is just a tool to make the lifting automatic
20:41:58 <Axman6> @src oneOf
20:41:59 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
20:42:04 <Axman6> :t oneOf
20:42:06 <lambdabot> forall t. [t] -> [(t, [t])]
20:42:19 <Axman6> > oneOf [1..4]
20:42:21 <lambdabot>   [(1,[2,3,4]),(2,[1,3,4]),(3,[1,2,4]),(4,[1,2,3])]
20:42:27 <sjanssen> I hadn't tried this with a non-prelude type before
20:43:05 <blackdog> sjanssen: ah. so i'd have to lift it myself with anything more complex
20:44:22 <sjanssen> blackdog: yeah, but it should be fairly easy to write an instance
20:44:50 <sjanssen> http://www.haskell.org/ghc/docs/6.8.3/html/libraries/template-haskell/src/Language-Haskell-TH-Syntax.html has the source for all the instances, they're fairly mechanical
20:44:54 <lambdabot> Title: Haskell Code by HsColour, http://tinyurl.com/5funs2
20:45:03 <sjanssen> I think we need TH to generate Lift instances :)
20:45:38 <blackdog> heh. meta-super-hyper-recursive
20:46:56 <sjanssen> it would be a good thing for the derive package
20:48:55 <gwern> papermachine: djinn doesnt understand lists, although I doubt [a] -> [[a]] corresponds to a unique definition - [a] could be turned into [[a]], [[a], []], etc. couldn't it?
20:49:47 <thoughtpolice> sjanssen: mmorrow has a very modified version of igloo's original th-derivation tool somewhere...
20:50:37 <sjanssen> thoughtpolice: I think derive would be a really good place for that
20:50:49 <thoughtpolice> sjanssen: yeah, I really like derive.
20:51:46 <pumpkin_> can't get this damn matlab extension working in cabal
20:52:58 <dolio> @type ?m >> ?n
20:52:59 <lambdabot> forall (m :: * -> *) a b. (Monad m, ?n::m b, ?m::m a) => m b
20:53:07 <dons> Lemmih: hmm. the darcs 2 support seems to be broken.
20:53:20 <dons> probably not hard to fix.
20:58:40 <Lemmih__> thoughtpolice: Can the darcs conversion be undone?
21:00:01 <the_unmaker1> hey there enthusastc haskellers
21:00:03 <the_unmaker1> whats new
21:01:48 <dons> the_unmaker1: hmm. turbinado, real world haskell - the book - is shipping, `par` is getting faster, and we've almost reached 1000 packages
21:02:04 <Lemmih> dons: par is getting faster?
21:02:15 <dons> yeah, simon marlow's been doing cool things with it in the head.
21:04:24 <gwern> hm. I am running yi like thus 'yi +RTS -tfile -RTS Main.hs ' but when I close yi 'file' is empty
21:04:33 <gwern> is there a minimum time one must run to get statistics?
21:04:53 <Lemmih> gwern: yi just executes ~/.yi/yi-blah
21:05:07 <Lemmih> gwern: Run the executable in ~/.yi/ directly.
21:05:18 <dons> gwern: also, yi sleeps most of the time, so to get good stats, you probably need a finer scheduler (at least in the past, when it was fast :)
21:05:21 <gwern> annoying
21:05:46 <the_unmaker1> ah ha
21:05:55 <the_unmaker1> but how good is the web serving bits of haskell?
21:06:07 <the_unmaker1> I heard learn you a haskell is good too
21:06:20 <the_unmaker1> does strong typing hurt exploratory programming as paul graham claims or is it ok?
21:06:33 <Cale> It's fine.
21:06:44 <gwern> hm. I'm not seeing usage of 100s of megs: '<<ghc: 1602606480 bytes, 3064 GCs, 12834801/27964240 avg/max bytes residency (32 samples), 82M in use, 0.00 INIT (0.02 elapsed), 2.12 MUT (21.58 elapsed), 3.17 GC (3.42 elapsed) :ghc>>
21:06:47 <the_unmaker1> I remember having a bugger of a time getting happs going
21:07:10 <gwern> the_unmaker1: it is both a blessing and a curse in my experience. happs is perhaps not the best example
21:07:19 <gwern> I'll try yi again I guess
21:07:43 <Cale> In fact, I would be willing to claim that strong typing helps exploratory programming, by helping you think in the right way.
21:07:52 <solussd> i am reading in command line args into a haskell program... hwo can i check to see if an arg is a positive integer ?
21:08:08 <MikeMayer> Axman6: http://dl.getdropbox.com/u/59541/stauro_HOMEWORK%205.pdf
21:08:14 <lambdabot> Title: cache:http://dl.getdropbox.com/u/59541/stauro_HOMEWORK%205.pdf - Google Search
21:08:14 <sjanssen> the_unmaker1: one thing types are good at is helping exploratory refactoring
21:08:54 <sjanssen> you can change the type of one function, then just keep hacking until compilations succeeds.  At that point, your program is almost guaranteed to work
21:09:01 <Cale> solussd: perhaps something like all isDigit, or use 'reads' to parse an Integer, and then if the list of parses is nonempty, check the integer you got is nonnegative.
21:09:21 <solussd> thanks cale
21:09:23 <Cale> > reads "3328" :: [(Integer, String)]
21:09:25 <lambdabot>   [(3328,"")]
21:09:32 <Cale> > reads "hello" :: [(Integer, String)]
21:09:34 <lambdabot>   []
21:09:46 <gwern> solussd: getArgs, then i = read (head args) :: Int, if i >= 0... etc. you see what I mean
21:09:49 <Cale> > reads "3320 hello" :: [(Integer, String)]
21:09:51 <lambdabot>   [(3320," hello")]
21:10:24 <Cale> Probably best not to use head explicitly... unless you don't mind the program just dying when there's not enough args.
21:10:39 <gwern> Cale: it'll serve the user right
21:10:50 <gwern> 'give it the args it needs - or else!'
21:10:54 <solussd> i check for the number of args already
21:11:05 <the_unmaker1> hmmmm
21:11:17 <the_unmaker1> for web why is haskell cooler than say php?
21:12:09 <Axman6> > reads "123 456" :: [(Integer,String)]
21:12:11 <lambdabot>   [(123," 456")]
21:12:12 <jeffwheeler> Over PHP? It's not a mess. :P
21:12:13 * gwern suggests that it doesn't say 'hack me' in big neon letters
21:12:37 <jeffwheeler> Over something like Python/Django . . . well, not a whole lot at the moment, in my opinion. We're getting there, though.
21:13:48 <Axman6> :t reads
21:13:50 <lambdabot> forall a. (Read a) => String -> [(a, String)]
21:14:12 <Axman6> @src reads
21:14:12 <lambdabot> reads = readsPrec minPrec
21:15:00 <the_unmaker1> hack me hard!!!
21:15:15 <blackdog> it's something i've been thinking about a bit, actually. developing a decent web framework's pretty thankless work, and it takes a fair bit of work - we might be better served by getting seamless interoperability with something like python/php/whatever and just making it easy to call haskell functions
21:15:20 <Axman6> > (map reads . words) "123 456" :: [[(Int,String)]]
21:15:22 <lambdabot>   [[(123,"")],[(456,"")]]
21:15:33 <FunctorSalad> there has to be some existing tool to generate haskell types from a BNF ;) but I can't seem to find it
21:15:38 <Axman6> > (concatMap reads . words) "123 456" :: [[(Int,String)]]
21:15:39 <lambdabot>   Couldn't match expected type `[(Int, String)]'
21:15:42 <Axman6> > (concatMap reads . words) "123 456" :: [(Int,String)]
21:15:44 <lambdabot>   [(123,""),(456,"")]
21:16:28 <FunctorSalad> (and conversion functions)
21:16:43 <Axman6> > (map snd.concatMap reads . words) "123 456" :: [(Int,String)]
21:16:45 <lambdabot>   Couldn't match expected type `(Int, String)'
21:16:51 <Axman6> > (map snd.concatMap reads . words) "123 456" :: [Int]
21:16:53 <lambdabot>   Couldn't match expected type `Int' against inferred type `String'
21:17:07 <Axman6> > (map fst.concatMap reads . words) "123 456" :: [Int]
21:17:08 <lambdabot>   [123,456]
21:17:20 <gwern> Lemmih: I think you're right, there's some sort of blowup in yi
21:17:27 <Axman6> > (map fst.concatMap reads . words) "123,456" :: [Int]
21:17:29 <lambdabot>   [123]
21:18:12 <gwern> Lemmih: it stays below 100 megs for me when I deal with main.hs, or 2xmain.hs, but when I get to 6x or so, it jumps to 1gig
21:20:46 <Axman6> MikeMayer: looks kind of interesting... and annoying
21:20:51 <gwern> 3x is 338m
21:21:01 <MikeMayer> Axman6: for sure
21:21:50 <Lemmih> gwern: Do you know why it happens?
21:22:29 <gwern> Lemmih: no idea, honestly. one culprit in the past has been the syntax higlighting
21:22:53 <gwern> yeah, 6x the file and 10x the memory
21:27:05 <gwern> > 1077 / 63
21:27:07 <lambdabot>   17.095238095238095
21:27:25 <Lemmih> gwern: Hm, it /is/ the syntax highlighting. Renaming the file makes the problem go away.
21:28:03 <Lemmih> Why on earth is this the case? Lexer bases highlighting should be extremely fast.
21:28:11 <gwern> whoa
21:28:17 <gwern> I just tried a text file
21:28:19 <gwern> 4mb total usage
21:28:34 <gwern> and this text file is 10x the size of main.hs
21:32:14 <gwern> > 6*4
21:32:16 <lambdabot>   24
21:32:37 <pumpkin_> orly?
21:33:19 <gwern> YAH RLY
21:33:35 <pumpkin_> o ok
21:34:44 <gwern> http://www.geeklair.net/~pratzsch/blog/2008/11/initial-haskell-impressions.html <-- someone needs to set this poor fellow straight
21:34:50 <lambdabot> Title: Initial Haskell Impressions - You don't want to read this., http://tinyurl.com/6f3uqn
21:35:53 <pumpkin_> wow
21:36:13 <pumpkin_> So clearly the : primitive appends elements to the beginning of a list. I thought that perhaps [0,1]:x might produce [[0,1],[1,2]].
21:36:16 <sjanssen> gwern: but the title says I don't want to read it!
21:36:36 <Axman6> :t (:)
21:36:38 <lambdabot> forall a. a -> [a] -> [a]
21:36:53 <gwern> sjanssen: but you may. the title can't make your decisions for you
21:38:03 <sjanssen> gwern: just looks like some notes from someone who has spent 30 minutes with ghci
21:38:15 <sjanssen> I'm sure they'll correct their misunderstandings soon
21:38:24 <Axman6> :t let x = [1,2] in x
21:38:26 <lambdabot> forall t. (Num t) => [t]
21:39:27 <obk> While going through my just-delivered Real-World-Haskell book (great!) I started wondering if there is/will be a "Magic Haskell" book covering stuff like forall and existential types and the other advanced goodies that make my head ache every time I try to follow them in one of Oleg's papers...
21:39:54 <pumpkin_> forall doesn't sound like it's too voodooish
21:39:57 <pumpkin_> from what I've read about it
21:40:07 <sjanssen> obk: I would think RWH has at least some content on forall
21:40:08 <pumpkin_> maybe I just don't understand it enough to see the voodoo
21:40:24 <sjanssen> obk: look for "existential", "rank 2" or "rank n"
21:40:31 <obk> foral isn't in the index
21:40:53 <gwern> hm, yi has sloppy haddocks
21:40:57 <sjanssen> do they talk about the ST Monad?
21:41:00 <obk> Neither is rank, or existential
21:41:08 <pumpkin_> does anyone in here have matlab installed?
21:41:35 <obk> Anyway, forall and existential types are only the start of a slippery slope of concepts I admit I haven't really tracked to depth...
21:41:44 <sjanssen> obk: yeah
21:41:53 <gwern> 'haddock: Could not find module `HscTypes': it is a member of package ghc-6.10.1, which is hidden
21:41:57 <gwern> argh
21:42:02 <sjanssen> though you might need a big book to be able to approach all of Oleg's tricks :)
21:42:59 <erikc> i love the title for oleg's site
21:43:25 <erikc> its like hes throwing down the gauntlet
21:43:33 <gwern> which is?
21:43:38 <thoughtpolice> you're going to need more than a book for all of oleg's tricks
21:43:43 <erikc> "This FTP Site - That's what you can find here"
21:43:46 <obk> sjanssen: A very big book indeed. But I would *love* to read it nevertheless
21:43:54 <erikc> and then a wall of papers and articles on code
21:43:58 <erikc> http://okmij.org/ftp/
21:43:59 <lambdabot> Title: This FTP site
21:44:19 <erikc> throwing down the gauntlet, or whipping it out
21:44:29 <erikc> either way, its awesome :)
21:45:44 <erikc> his critique of OO is particularly astute
21:45:48 <obk> It occured to me that these tricks can be thought off as trying to achieve the elegance of dynamic languages in a static setting... most of the examples (e.g. universal traversal) are common in dynamic languages - of course unsafely. It would be very interesting if Haskell got to the point it would be practical to do the same tricks "safely"
21:46:28 <Axman6> gwern: i left a comment on that guys blog, to hopefully straighten things out
21:47:31 <pumpkin_> what's a good simple data format to dump something to to load in for extreme processing in haskell?
21:48:01 <Axman6> pumpkin_: eh?
21:48:07 <pumpkin_> I have lots of numeric data
21:48:19 <pumpkin_> basically a large matrix
21:48:27 <pumpkin_> it's in a matlab file and I'm trying to load it in
21:48:47 <pumpkin_> so I'm going to convert it to some other format because I can't get the matlab extension working
21:49:07 <obk> BTW, speaking of typing tricks, is there a Haskell equivalent to http://www.iam.unibe.ch/~scg/Research/Traits/ (Traits are a sort of structured way to do Mixins and seem to have a lot in common with Haskell typeclass, I think)
21:49:10 <lambdabot> Title: Traits
21:50:13 <obk> I think they may mesh well with Oleg's critique of OO
21:52:28 <Cale> obk: Well, that description of them seems to indicate they are basically exactly the same thing as typeclasses.
21:52:42 <pumpkin_> wow, Control.Monad.Omega is pretty sweet btw :P
21:52:44 <Cale> Well, there may be some differences...
21:52:49 <perspectival> Hi; is there a way to use a pattern guard with get in a state monad?
21:52:53 <obk> I am not clear on the ability to rename and drop methods
21:53:04 <obk> It does sound very close though
21:53:54 <Cale> Well, Haskell has no notion of inheritance.
21:54:40 <Cale> Though typeclasses can be defined as subclasses of other classes, which simply means that if you want to make a type an instance of the subclass, you must define an instance of the parent class as well.
21:55:09 <Axman6> perspectival: what do you mean? there isn't much inside the State monad except for the runState
21:55:19 <Axman6> @src State
21:55:19 <lambdabot> Source not found. Sorry about this, I know it's a bit silly.
21:55:23 <Axman6> bah
21:55:30 <Cale> perspectival: er, pattern guard?
21:55:32 <perspectival> Axman6: I mean I've got this:
21:55:32 <perspectival> blah ∷ String → State (Decision, String) String
21:55:32 <perspectival> blah (c:cs)
21:55:32 <perspectival> 	| (Accept, _) ← get
21:55:32 <perspectival> 	= do stuff
21:55:44 <perspectival> and I get this:  No instance for (MonadState s ((,) Decision))
21:55:44 <perspectival>       arising from a use of `get' at Errata.hs:191:17-19
21:55:50 <obk> And it is also easy to retrofit relationship between typeclasses with glue code (instance). Sounds like you basically get the same thing. Interesting.
21:55:52 <Cale> perspectival: oh, you don't want that.
21:56:15 <perspectival> no?
21:56:18 <pumpkin_> is there some super monad type that can accept constraints like those on Set?
21:56:19 <Cale> perspectival: blah is supposed to produce a State computation.
21:56:52 <Cale> perspectival: Guards might be used to determine which state computation it produces, but they're not part of the computation itself.
21:57:07 <Cale> (so they can't use actions like get)
21:57:23 <perspectival> Cale: OK, I think I understand that; which was the reason I was asking
21:57:29 <perspectival> Cale: thanks ;-)
21:57:41 <Cale> What you can write instead is:
21:57:50 <Cale> blah (c:cs) = do x <- get
21:58:03 <Cale>                  case x of (Accept, _) -> ...
21:58:25 <perspectival> Cale: yes, that's what I have, but I was wondering if i could simplify the function with a pattern guard using get
21:58:29 <Cale> pumpkin_: You could write an OrdMonad class, for monads on ordered types.
21:58:42 <pumpkin_> then I'd need to write all the monad functions again, right?
21:58:52 <Cale> pumpkin_: Unfortunately, yes.
21:58:55 <pumpkin_> boo hoo
21:59:22 <pumpkin_> so it isn't possible to write a sekrit monad, that encloses the constraints elegantly and hides them from the functions? :(
21:59:25 <pumpkin_> boo hoo hoo
21:59:52 <Cale> pumpkin_: Well, return is usually a problem.
22:00:26 <Cale> pumpkin_: Because in the type of return, it's supposed to be able to take any type of value whatsoever (might not have an Ord instance), and produce a monadic computation.
22:00:34 <pumpkin_> ah, yeah
22:00:54 <Cale> It might even do so polymorphically, giving you something of type  (Monad m) => m (Int -> String), say.
22:01:09 <adu> why does Set have an Ord restriction anyways?
22:01:21 <pumpkin_> it's represented as a tree internally?
22:01:24 <Cale> adu: Because it's really a binary balanced tree.
22:01:34 <pumpkin_> not sure why it should expose that to the outside world, honestly
22:01:39 <warren_> h
22:01:45 <pumpkin_> but I can see why it would
22:01:46 <Cale> adu: And in general, you need ordering to implement a Set datatype efficiently.
22:02:02 <wkh> what's the best way of doing ssh/sftp in haskell?
22:02:11 <pumpkin_> but abstractly, there's nothing about a set that implies an ordering
22:02:12 <Cale> Eq doesn't really cut it, because with just Eq, you end up with many operations being O(n^2)
22:02:23 <adu> right, but if we can't use Set Monads, then its also not very efficient
22:02:37 <Cale> Eq has the same problem though.
22:02:44 <perspectival> it seems obvious in hindsight now... ;-)
22:02:53 <pumpkin_> I guess Eq is absolutely necessary for a set
22:02:55 <Cale> and you need a notion of equality to even discuss Sets.
22:02:56 <pumpkin_> Ord shouldn't be
22:02:57 <pumpkin_> yeah
22:03:14 <pumpkin_> so the limitation is that whoever came up with unrestricted monads at the beginning of time
22:03:20 <pumpkin_> didn't foresee neding restrictions later on?
22:03:24 <wkh> SSH in Haskell. how do you do it.
22:03:36 <Cale> pumpkin_: It's just a limitation of how typeclasses work.
22:04:00 <adu> i think the more fundamental problem is that people in computer science think of every datatype imaginable, except sets
22:04:06 <Cale> wkh: I don't know... if there's nothing on hackage, you might have to write a binding using the FFI.
22:04:57 <adu> ppl are drifting away from mathematical truth...
22:05:07 <pumpkin_> adu: I'm in computer science and love sets
22:05:09 <pumpkin_> :P
22:05:14 <Cale> adu: I don't think that's the case.
22:05:31 <Cale> It's just that how mathematics does things is often unsuitable for computation.
22:05:52 <roconnor> Damn Dedekind!
22:06:15 <Cale> In mathematics, we sort of glibly use equality all over the place, and that's fine, but determining if two things are equal can be arbitrarily hard.
22:06:39 <roconnor> undecidably hard.
22:06:40 <Cale> So definitions which are equational can be problematic for real computation.
22:06:47 <roconnor> and that is easy compared to how hard it can get.
22:07:03 <adu> compsci == math :)
22:07:23 <roconnor> math /= set theory :)
22:08:01 <adu> lisp >= scheme
22:08:04 <Cale> I actually really like set theory as a foundation, it's just not an appropriate foundation for directly computational work.
22:08:27 <Cale> Or it doesn't seem to be, anyway.
22:09:12 <roconnor> Cale, you are such an enigma.  You certainly know enough that I'd think you'd come around to rejecting set theory as a foundation.
22:09:33 <Cale> As a foundation for mathematics?
22:09:48 <roconnor> yes
22:09:48 <Cale> It's proven itself quite admirably in many regards there.
22:10:17 <Cale> Most of mathematics is quite unconcerned with what's computable and what isn't.
22:10:33 <dolio> Category theory is clearly a way cooler foundation.
22:10:42 <roconnor> if by admirably, you mean, is unconcerend with what's computable.
22:10:47 <roconnor> and what isn't.
22:10:56 <Cale> dolio: It's not bad, but you still need a notion of sets if you're going to proceed.
22:11:26 <Cale> roconnor: Most of the time when I'm doing mathematics, I don't want to be involved in such petty things :)
22:12:11 <roconnor> so bizarre.
22:12:21 <adu> i like functors
22:12:28 <Cale> Most things aren't computable. I wouldn't expect them to be, anyway.
22:14:12 <roconnor> I find it odd that you are so curious about "objects" that are unobservable.
22:14:33 <Cale> 'unobservable'?
22:14:44 <Cale> They're basically as observable as everything else.
22:14:57 <roconnor> Like trying to figure out what an uncomputable Julia set looks like.
22:15:00 <Cale> Well, there are functions which are not definable, for example.
22:15:06 <roconnor> or wondering what the digits of Omega are.
22:15:32 <Cale> Well, the whole business of proving theorems is such a thing.
22:15:42 <adu> roconnor: isn't that just W(1)?
22:15:50 <Cale> Some theorems aren't going to be decidable from your axioms.
22:16:04 <roconnor> adu:  Chartin(sp?)'s Omega
22:16:53 <Cale> roconnor: I'm a bit of a formalist, so it doesn't bother me if the axioms correspond to anything in the "real world", whatever that is.
22:17:07 <roconnor> Cale: it is software
22:17:13 <Cale> Not for me :)
22:18:21 <roconnor> It is more than that, some of these things cannot correspond to anything in the real world.
22:18:25 <adu> roconnor: its Chaitin, actually
22:18:27 <Cale> I don't really believe in objective reality. I'm willing to make use of it within particular physical models, but I see no reason to assume that there's one explanation that captures everything.
22:18:38 <roconnor> adu: thanks.
22:19:01 <Cale> As such, the notion of a 'real world' doesn't mean a whole lot to me ;)
22:19:19 <roconnor> _can_ _not_ :)
22:19:22 <adu> Cale: may the force be with you
22:19:27 <roconnor> _period_
22:19:34 <roconnor> but anyways
22:20:05 <Cale> Let's take a particular example of something I think you wouldn't like... say, an everywhere dense function on R.
22:20:20 <Cale> (the image of every open set is dense in R)
22:20:46 <roconnor> sounds discontinuous.
22:20:47 <Cale> I have no problem working with that. It's actually a rather nice property which can be appreciated for what it is.
22:20:54 <Cale> Oh, incredibly discontinuous.
22:21:14 <roconnor> I'm okay working with it, so long as I don't ever have to evaluate it at an arbitrary point.
22:21:20 <roconnor> that would just be wrong.
22:21:35 <Cale> If you try to draw the graph of such a function, you're forced to black in the whole plane, at any scale, because every neighbourhood in R^2 will contain a point of the graph
22:21:35 <roconnor> like a type error
22:22:04 <roconnor> it sounds like the graph isn't compact.
22:22:09 <roconnor> so I don't know what it means to draw it.
22:22:17 <roconnor> (or locally compact)
22:22:18 <ksf> @quote+ oleg It is known, albeit not so well, that following the OOP letter and practice may lead to insidious errors.
22:22:18 <lambdabot> No quotes for this person. Your mind just hasn't been the same since the electro-shock, has it?
22:22:24 <Cale> Well, you'd only draw a portion of it.
22:22:26 <ksf> @remember oleg It is known, albeit not so well, that following the OOP letter and practice may lead to insidious errors.
22:22:27 <lambdabot> I will remember.
22:22:41 <roconnor> but it isn't localy compact.
22:22:44 <roconnor> I presume
22:22:45 <Cale> (like we do when we plot functions normally)
22:22:49 <roconnor> oh
22:22:55 <roconnor> but you and I have different definition of compact
22:22:58 <roconnor> sorry
22:23:10 <ksf> @quote OOP
22:23:10 <lambdabot> Spark says: "oops, we proved the wrong property"
22:23:16 <roconnor> it isn't constructively locally compact.
22:23:17 <ksf> grrr
22:23:18 <ksf> @quote OOP
22:23:18 <lambdabot> Spark says: "oops, we proved the wrong property"
22:23:33 <ksf> it's a great koan, though.
22:24:05 <roconnor> or in your words, the graph isn't computable (for the suitable definition of computability).
22:24:11 <Cale> Moreover, as far as normal mathematics is concerned, there's such a function which is additive :)
22:24:11 <adu> my favorite property is bijectivity
22:24:18 <roconnor> so the notion of "drawing it" is nonsensical.
22:24:29 * adu <3 bijectivity
22:24:31 <ksf> OOPS is an abbrev for "Object-oriented programming semantics"
22:24:51 <roconnor> Cale: presumably there is one such function for every well-ordering of the reals?
22:25:13 <Cale> roconnor: Here's a suitable notion of drawing. Pick some epsilon, and break (a finite piece of) R^2 into a grid of squares of width epsilon.
22:25:33 <Cale> roconnor: If there's a point of the graph in a given square, colour it black.
22:26:16 <Cale> In that sense, this function is computably drawable, because you can tell for each square whether or not there is a point of the graph in that square. (There is, always)
22:26:57 <BMeph> ksf: Really? I thought it was an abbrev for "Oh no, I just did something wrong, so now I have to stop what I was doing and go fix the wrong thing..." ;p
22:27:15 <roconnor> Cale: that works well for compact sets.
22:27:29 <roconnor> but if the set isn't compact, that two different sets can have the same drawing
22:27:37 <roconnor> which is just wrong.
22:27:41 <roconnor> (localy compact)
22:28:00 <ksf> Simply see that as practical teaching of continuations ;)
22:28:01 <Cale> roconnor: Well, you're picking a resolution and discretising, so sure, lots of sets will have the same drawing.
22:28:32 <roconnor> right but two unequal (at least one non compact) sets can have the same drawing at all resolutions.
22:28:37 <Cale> Of course, lots of sets will have the same drawing at every scale as well.
22:28:45 <roconnor> that's dumb.
22:28:51 <BMeph> BRB - setting up VMWare. Wish me luck, it crashed my system the last time I tried...
22:28:57 <roconnor> you shouldn't draw non-compact sets.
22:28:59 <Cale> That's not a problem. This notion of drawing is topological.
22:29:16 <Cale> and sets in R^2 might not behave particularly nice topologically.
22:29:53 <Lemmih> dons: Why chance darcs-graph can be upgraded to work with darcs2?
22:29:56 <Cale> roconnor: That sounds like a value judgement. "shouldn't"
22:30:02 <roconnor> yep
22:30:21 <Cale> You *can* draw non-compact sets, in my sense, so I see no reason to restrict it.
22:30:22 <roconnor> because you just end up drawing the completion of the set.
22:30:31 <Cale> Sure.
22:30:41 <roconnor> sorry
22:30:49 <roconnor> it isn't a judement on value
22:30:59 <Cale> Another way to say what I said about the graph of my everywhere dense function is that its completion is R^2.
22:31:00 <roconnor> it is a judgement on the meaning we want to assign "draw"
22:31:12 <roconnor> if you said "let's draw the completion of the graph"
22:31:19 <roconnor> then you can fill your paper black.
22:31:31 <roconnor> but don't pretend you drawing is of the set.
22:31:45 <Cale> Well, of course, there's a lot lost in any drawing.
22:32:25 <roconnor> and you failed to convey that loss with your classical mathematics mumble jumble.
22:32:31 <wkh> i thought i could learn haskell by writing a simple static blog generator
22:32:38 <wkh> kind of like perl's ikiwiki.
22:32:39 <roconnor> Cale: compact sets have no such loss
22:32:44 <Cale> For example, look at, say, the function x^2. Given any epsilon, there will be a portion of the drawing where we're forced to fill in two boxes vertically, which makes it look non-functional.
22:32:56 <roconnor> two compact sets are equal if they have the same drawing at every resolution.
22:33:19 <roconnor> (again locally compact as well)
22:33:37 <Cale> I'm not sure that I understand what you mean.
22:33:47 <Cale> Of course if you apply a function to something, you might lose information.
22:34:02 <Cale> This function which produces the drawing is no exception.
22:34:14 <roconnor> The notion of drawing a compact set makes sense, because two compact sets are equal if they have the same drawing at every resolution.
22:34:21 <Cale> And yes, it's nice that for compact sets, there's always an epsilon which will distinguish them.
22:34:33 <Cale> But it doesn't mean that the function's domain is compact sets.
22:35:42 <Cale> I could say something silly like... the remainder after division by 2 only makes sense for the integers 0 and 1, because if you allow other numbers then you can no longer tell them apart after taking the remainder.
22:35:46 <roconnor> But how can you consider it drawing something if two different things are drawn the same.
22:35:55 <roconnor> obviously you are not drawing the object, only it's "shadow"
22:35:55 <Cale> Drawing isn't perfect.
22:36:04 <wkh> here's a summary of trying to use haskell for a real-world task:
22:36:11 <wkh> me: i want to use haskell for <common task>.
22:36:12 <roconnor> I'm arguing that is a bad definition of drawing
22:36:19 <Cale> I never said that this drawing was an exact representation of the set.
22:36:21 <wkh> haskell people: nothing for doing that exists. write your own, starting with FFI C code.
22:36:27 <wkh> haskell people: isn't haskell awesome?
22:36:57 <Cale> wkh: If you write a library, make sure to stick it on hackage.
22:37:13 <roconnor> Cale: you don't see your defintion as misleading?
22:37:20 <Cale> roconnor: not in the least.
22:37:36 <Cale> wkh: Apparently you're the first person to want to do that.
22:38:12 <roconnor> how do you feel about show functions that return the same string for morally different values?
22:38:12 <lament> Apparently you're the first person to want to use haskell for a real-world task.
22:38:44 <Cale> roconnor: Depends. Sometimes you don't want to show everything.
22:39:00 <Cale> roconnor: Like, show functions for functions.
22:39:12 <roconnor> show isn't defined for functions.
22:39:16 <Cale> It can be.
22:39:22 <lament> > id
22:39:23 <lambdabot>       Overlapping instances for Show (a -> a)
22:39:23 <lambdabot>        arising from a use of `s...
22:39:34 <lament> it can be.. in several ways!
22:39:40 <Cale> In fact, annoyingly, in multiple ways, yes :)
22:40:05 <conal> i'd like some help nailing down an algebraic notion.  one special case is non-negative numbers with addition and a sort of partial subtraction a - b that's used only when a > b.
22:40:06 <roconnor> how do you feel about show functions that return different string for the same value. :P
22:40:20 <Cale> roconnor: Those would not be functions.
22:40:25 <roconnor> :P
22:40:41 <Cale> They might be relations ;)
22:40:43 <conal> it's for behaviors with duration.
22:40:58 <Korollary> conal: a + b when a < b, and a - b when a >= b ?
22:41:00 <roconnor> conal: semi-groups?
22:41:05 <roconnor> no
22:41:06 <roconnor> hmm
22:41:07 <Cale> conal: natural numbers?
22:41:33 <conal> Korollary: a + b for any a,b, and a - b when a >= b .
22:42:00 <conal> Cale: usually reals.
22:42:05 <Cale> conal: I would usually denote that with a subscript +
22:42:10 <Cale> Like R_+
22:42:22 <roconnor> Cale: really?
22:42:29 * roconnor has a supsercript in his thesis
22:42:36 <Cale> Or superscript, sure.
22:42:50 <conal> i have a nice comonadic definition for functions with duration.  and it looks like a special case of something  much more general.
22:42:53 <conal> and fairly simple.
22:43:13 <Cale> conal: Is it the functions on a monoid domain comonad?
22:43:27 <maxote> ~category construction
22:43:38 <maxote> @go category construction
22:43:41 <lambdabot> http://en.wikipedia.org/wiki/Category:Construction
22:43:45 <conal> i know the 0 and (+) part generalize to a monoid, since that's how the pair comonad works.
22:44:01 <conal> but there's also a subtraction, which only gets used when the difference is non-negative.
22:44:28 <conal> Cale: i couldn't parse "monoid domain comonad". i know the words, but not how they're strung together.
22:44:44 <Cale> (functions on a monoid domain) comonad
22:44:58 <conal> oh!  yes.
22:45:21 <conal> F a = (T, T -> a)
22:45:27 <conal> where T is a monoid
22:45:35 <Cale> hmm...
22:45:41 <Cale> What's the first T there?
22:45:46 <conal> time
22:45:50 <conal> no
22:45:52 <conal> duration
22:46:02 <Cale> hmm, all right
22:46:03 <dolio> That looks more like state-in-context.
22:46:04 <conal> (length of time)
22:46:15 <the_unmaker1> I wana make a on of money in software
22:46:21 <the_unmaker1> is haskell  a good tool for that?
22:46:32 <roconnor> the_unmaker1: yep
22:46:41 <Axman6> ?faq can haskell make you a crapload of cash quick?
22:46:42 <lambdabot> The answer is: Yes! Haskell can do that.
22:46:50 <Axman6> yep, its in the faq
22:47:03 <Cale> conal: okay, so what does duplicate look like in this comonad?
22:47:05 <conal> dolio: thx.  i'll look at that one.  i wonder if it gives me the comonad i want.
22:47:18 <Cale> conal: Just copy the T value?
22:47:29 <centrinia> ?faq how can haskell make you a crapload of cash quick?
22:47:29 <lambdabot> The answer is: Yes! Haskell can do that.
22:47:32 <conal> Cale: in part.  i'll write it out.
22:47:43 <Cale> conal: I know what it would be for T -> a
22:47:45 <centrinia> That's not very informative.
22:47:54 <Cale> It's just that extra T which I'm wondering about :)
22:47:59 <conal> duplicate (d,f) = (d, \ t -> (d - t, \ t' -> f (t + t')))
22:48:16 <conal> which uses the duplicate of pairing and of function.
22:48:18 <Cale> aha, okay
22:48:19 <roconnor> centrinia: 1. write quant software 2. ??? 3. profit
22:48:22 <dolio> Oh. That's not state-in-context.
22:48:28 <conal> dolio: thx.
22:48:52 <conal> the (+) is from the Sum monoid
22:49:26 <conal> extract (d,f) = extract f = f 0
22:49:31 <conal> since 0 = mempty
22:49:54 <wkh> what would be a good project for someone who codes all day long in a crappy blub language but is new to haskell
22:50:16 <conal> so that duplicate looks like it wants to generalize to something that has a little more stucture than a monoid.  but not a group.
22:50:17 <centrinia> What is a crappy blub language?
22:50:51 <wkh> centrinia: Java and PHP.
22:51:03 <conal> what this duplicate does is "age" the function-with-duration.
22:51:11 <roconnor> conal: why is d < t?
22:51:13 <ksf> wkh, try an interpreter.
22:51:18 <roconnor> er
22:51:26 <roconnor> why is t < d ?
22:51:32 <centrinia> ?google Make Yourself a PHP in Fixnum Hours.
22:51:34 <lambdabot> No Result Found.
22:51:40 <conal> roconnor: because the function f has duration d
22:51:50 <aleator> wkh: Command line todo-list manager? Gives you bit of monads(IO), interpreter (which haskell is good at) and some datastructures?
22:51:59 <conal> that's why the duplicate has duration d also
22:52:22 <ksf> start of with a simple calculator, then do a parser, then get adventurous and implement lambdas.
22:52:27 <centrinia> wkh: You can write the tutorial "Make Yourself a PHP in Fixnum Hours" using Haskell. :)
22:52:36 <conal> the function-segment gets shifted left until there's none left.
22:53:36 <the_unmaker1> so why do lisp people and haskell people say java is crappy and php is crappy?
22:53:51 <the_unmaker1> can great websites be made without bothering? just do it in lisp or java?
22:53:55 <the_unmaker1> er lisp or haskell
22:53:55 <ksf> java isn't actually completely borked.
22:53:57 <the_unmaker1> sorry
22:54:04 <ksf> it's just mostly borked.
22:54:13 <ksf> php, on the other hand, it a hacked cat.
22:54:20 <the_unmaker1> so when you use a non borked language what can you do easier?
22:54:24 <Cale> the_unmaker1: Because they're terribly designed languages, not because they're impractical for every task.
22:54:36 <the_unmaker1> so when a lang has good design
22:54:40 <the_unmaker1> where does one see it?
22:54:50 <the_unmaker1> are programs faster and better?
22:54:51 <ksf> mainly, composability.
22:54:52 <the_unmaker1> less code?
22:54:56 <the_unmaker1> easier to maintian?
22:54:59 <Axman6> the_unmaker1: thats one thing
22:55:00 <roconnor> conal: so (d, \t -> f (d*t)) would also work where t ranges from 0 to 1?
22:55:07 <Axman6> readability is high up there too
22:55:17 <Cale> the_unmaker1: If your task includes wanting to be reasonably sure that your program is correct, or as maintainable and flexible as possible, then those languages tend to do a poor job.
22:55:37 <centrinia> The ease of reasoning about your code is another.
22:55:39 <roconnor> conal: hmm, maybe not
22:55:40 <the_unmaker1> ok now lisp has a reputation for having a good design
22:55:44 <roconnor> conal: scratch that.
22:55:48 <conal> k
22:55:54 <Axman6> the_unmaker1: lisp is quite hard to read imo
22:55:56 <blackdog> the_unmaker1: there's a strong panda's thumb principle in play here. I tend to use Perl at work, not because i think it's a wonderfully designed language, but because there's a huge amount of useful code available for it i don't have to write.
22:55:59 <Cale> the_unmaker1: Some lisps are better than others.
22:55:59 <the_unmaker1> why would soeone go with haskell over say lisp? and why do many look at me as crazy to even talk about lisp?
22:56:02 <Axman6> from what i've seen, very hard to follow
22:56:24 <Axman6> Cale: i think the fact there's just one haskell is a big plus...
22:56:29 <the_unmaker1> common lisp is the good one I hear
22:56:36 <Cale> the_unmaker1: I'd disagree with that.
22:56:48 <Cale> the_unmaker1: Common lisp is a pain in the ass for functional programming.
22:56:55 <the_unmaker1> steel bank common lisp and clisp seem to be 2 good ones
22:56:56 <Cale> the_unmaker1: Scheme is nicer.
22:57:06 <the_unmaker1> doesnt scheme not have macros?
22:57:11 <the_unmaker1> or "true" macores
22:57:13 <ksf> the_unmaker1, http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/
22:57:17 <Adamant> Scheme has both kinds of macros
22:57:25 <lambdabot> Title: Structure and Interpretation of Computer Programs, Video Lectures, http://tinyurl.com/6q4ut7
22:57:28 <Axman6> the_unmaker1: haskell also has very good performance, up there with C
22:57:36 <ksf> iirc the first lecture says a good deal about what makes a language good.
22:57:37 <Adamant> it implements hygenic macros on top of a unsafe (CL-style) macro system
22:57:39 <conal> is there some theory on composing comonads?  my example is (,) T :. (->) T
22:57:51 <the_unmaker1> I thought c was fastest above assembler
22:57:58 <the_unmaker1> except for fortran for numbers
22:58:08 <Adamant> Axman6: Lisp isn't really that hard to read once you're experienced with it IMO
22:58:09 <Axman6> no
22:58:13 <Adamant> yes
22:58:15 <the_unmaker1> although I have read that forth can be fast as well
22:58:20 <Cale> conal: Well... I'm willing to bet that the distributive law trick works.
22:58:24 <centrinia> Uh, it is not a good idea to talk about "language speed"
22:58:25 <Axman6> C++ is often faster than C
22:58:34 <Axman6> but yeah, centrinia is right
22:58:34 * Cale agrees with centrinia 
22:58:35 <Adamant> Axman6: for what?
22:58:42 <roconnor> http://zestyping.livejournal.com/233348.html
22:58:43 <lambdabot> Title: zestyping: Why PHP should never be taught, Part II.
22:58:46 <Axman6> Adamant: language shootouts >_>
22:58:46 <conal> Cale: maybe so.
22:58:46 <Adamant> I half agree with her
22:58:48 <Axman6> :)
22:58:49 <Cale> You can only talk about the performance of a language implementation, not of a language.
22:58:54 <the_unmaker1> seem most adult sites use php
22:59:00 <conal> Cale: i'll try it.
22:59:16 <the_unmaker1> I tried learning lisp and scheme and the books kinda threw me
22:59:20 <the_unmaker1> maybe I didnt try hard enough
22:59:28 <Adamant> Cale: some languages have properties that make them more or less amenable to fast implementation
22:59:29 <Cale> conal: The question will be what your distributive law is :)
22:59:30 <Axman6> the_unmaker1: that's just because there's a pretty standard set of things people use on OSS OS's
22:59:41 <Adamant> the_unmaker1: try The Little Schemer
22:59:44 <Axman6> or, unixish OSs
22:59:50 <roconnor> everyone uses PHP because it is easy to quickly make and distribute a crappy language.
22:59:59 <conal> Cale: i don't think i can go from (T -> (T, a)) to (T, (T -> a))
23:00:00 <roconnor> and then you get lots of users
23:00:27 <Adamant> everyone uses PHP because it fit the problem domain of allowing unskilled programmers to knock out sites quickly well
23:00:27 <Cale> conal: Well, not in a way which agrees with your existing meaning...
23:00:36 <Adamant> *fits
23:00:36 <the_unmaker1> I have that book right here on myshelf
23:00:40 <the_unmaker1> its kinda annoying
23:00:44 <the_unmaker1> like for 4 year olds
23:00:47 <the_unmaker1> but ok
23:00:50 <the_unmaker1> say I learn scheme
23:00:53 <Adamant> ah, too simple?
23:00:55 <the_unmaker1> can i egt it to do web stuff?
23:01:00 <monochrom> Hai, I heard that Chinese is faster than English, is that true?
23:01:02 <the_unmaker1> Im only a bash coder sofar
23:01:04 <conal> Cale: yeah.  i can only think of using 0 (mempty) for that outer T
23:01:10 <conal> which is sure not what i want.
23:01:14 <the_unmaker1> with a bit of tcl lisp and haskell
23:01:19 <monochrom> I have heard people speaking Chinese extremely quickly. It must be a fast language.
23:01:20 <centrinia> Chinese is only faster than English by a constant factor.
23:01:21 <Korollary> the_unmaker1: PLT Scheme has a continuation-based webserver, which you may find interesting.
23:01:34 <Adamant> monochrom: obviously not for computer use
23:01:49 <Cale> conal: So it might be that this comonad just doesn't break down like that...
23:01:55 <Axman6> the_unmaker1: you'll probably find haskell the easiest to understand, and the most fun... though this is just my opinion
23:02:02 <ksf> the_unmaker1, a couple of years back drscheme was the fastest cgi server available.
23:02:11 <the_unmaker1> really?
23:02:12 <the_unmaker1> wow
23:02:12 <ksf> now it should be hAppS.
23:02:27 <the_unmaker1> now there is "fastCGI" which apparently rocks
23:02:33 <conal> Cale: yeah.  okay.  well i guess i'll make up a structure that subclasses monoid and define my composition via that structure.
23:02:39 <Axman6> i wish HAppS has some decent documentation
23:02:46 <ksf> there's no multiple copying of results like apache does, even with fastcgi.
23:02:50 <the_unmaker1> and I have aolserver installed on my linux box here [archlinux is a gift from another plane]
23:02:52 * centrinia agrees with Axman6
23:02:59 <conal> then make a blog post and ask if there's already a notion/name i can use instead.
23:03:09 <erikc> if you are gonna use scheme, check out mzscheme/pltscheme and the stuff they have going on at planet.plt-scheme.org, their version of hackage
23:03:11 <the_unmaker1> aolserver is threaded adn supposedly running scripts in the server threaded process is REALLY fast
23:03:24 <ksf> http://happstutorial.com/
23:03:29 <lambdabot> Title: Real World HAppS: The Cabalized, Self-Demoing HAppS Tutorial
23:03:35 <the_unmaker1> is happs working?
23:03:36 <Axman6> aolserver? eh?
23:03:43 <the_unmaker1> I had a devil of a time isntalling it a year ago
23:03:51 <Axman6> ksf: yeah i've seen it, it doesn't help much
23:04:02 <Axman6> why ot use apache like everyone else?
23:04:05 <the_unmaker1> yeah I know aol scares piss outa people but philip greenspun wrte about how aolserver kiks ass
23:04:10 <Axman6> or lighttpd like the smart people do? :)
23:04:23 <the_unmaker1> aolserver is aupposed to be fater than lighty etc.
23:04:26 <the_unmaker1> even nginx
23:04:34 <pumpkin-> ksf: is that you?
23:04:35 <conal> oh -- "groupoid" came to mind.  so i looked: http://en.wikipedia.org/wiki/Groupoid
23:04:35 <the_unmaker1> and lighty you need one per cpu since its event
23:04:41 <conal> looks like a fit
23:04:43 <the_unmaker1> so get N logs
23:04:47 <ksf> pumpkin, me is who?
23:04:52 <pumpkin-> happstutorial
23:04:54 <Cale> the_unmaker1: If you're interested in this stuff, though, I would highly recommend picking up at least a bit of a lot of different languages (as different as possible). Haskell is particularly well-suited for introducing you to quite a lot of ideas however.
23:05:21 <ksf> nope, i don't do web-stuff, at least not seriously.
23:05:32 <pumpkin-> ah :)
23:05:52 <Cale> (By 'this stuff', I mean functional programming, or programming in general.)
23:05:52 <roconnor> conal: -oid means a typed version of thing :)
23:05:54 <conal> maybe just almost a groupoid, since i wouldn't expect to use -a + a
23:06:12 <conal> roconnor: does it in this context?
23:06:27 <erikc> i would have loved to have been a fly on the wall for the executive meetings about playstation home, how was this trainwreck greenlit
23:06:27 <abbe> hi all
23:06:33 * Cale wonders which definition of Groupoid wikipedia went with.
23:06:48 <ksf> the_unmaker1, also have a look at http://www.nondot.org/sabre/Mirrored/AdvProgLangDesign/
23:06:49 <lambdabot> Title: Index of /sabre/Mirrored/AdvProgLangDesign
23:06:58 <ksf> should blow your mind.
23:07:03 <abbe> is there any advantage of moving to ghc-6.10.1 from ghc-6.8.2 ?
23:07:32 <ksf> yes, you get opportunities to fix old code that doesn't use the new exceptions yet ;)
23:07:35 <Cale> ah, good, the category theory one :)
23:07:43 <centrinia> conal, how isn't natural number addition total?
23:07:56 <abbe> ksf, for me ?
23:08:25 <conal> centrinia: i don't think the question fits
23:08:29 <ksf> well, have a look at the release notes.
23:08:38 <ksf> chances are that you don't really care.
23:08:45 <the_unmaker1> ksf: interesting
23:08:54 <abbe> ksf, okay, thanks
23:08:57 <the_unmaker1> I actually installed io
23:09:07 <the_unmaker1> seems like good thing
23:09:17 <the_unmaker1> godel hm gota go look that one up
23:09:38 <ksf> the io mentioned in that book isn't the io that's out on the web
23:09:50 <centrinia> The Wikipedia entry says that Groupoids are groups without totality (the binary operation isn't always defined for all pairs of elements).
23:09:58 <Axman6> the_unmaker1: i think you should pick a language to start learning and see how you like it. i would recommend haskell because its easy to learn and fun, but you choose what you want
23:10:03 <conal> centrinia: and also an inverse.
23:10:25 <abbe> and last question is ghc 6.10.1 going to take more time to build than ghc 6.8.2 ?
23:10:27 <ksf> there's an implementation out there, though: http://www.guldheden.com/~sandin/amalthea.html
23:10:28 <roconnor> conal: I would be tempted to call your structure an ordered monoid.
23:10:33 <conal> i wasn't looking for the style of definition used on the Groupoid wiki page.  but it's pretty close in implication.
23:10:39 <lambdabot> Title: vague's - amalthea
23:11:20 <conal> roconnor: yeah.  Ord and Monoid are the two requirements i've had on time so far.
23:11:28 <conal> roconnor: but now there's more.  this partial difference function.
23:11:40 <the_unmaker1> Axman6: ok
23:11:51 <conal> and i like the look of the Identity law for groupoids.
23:11:53 <roconnor> I would argue that a partiall difference function would be implied by how I would define an ordered monoid.
23:11:54 <Axman6> @where lyah
23:11:54 <lambdabot> www.learnyouahaskell.com
23:12:03 <Axman6> the_unmaker1: check out that tutorial ^^
23:12:16 <Axman6> and stick around here, imo this is the best place to learn haskell
23:12:32 * roconnor thinks about that
23:12:34 <conal> roconnor: sounds like more structure than i'd expect from combining monoid & ord.  that's all.
23:12:46 <ksf> it's definitely the place to go if you want to know how to generate fibonacci series in haskell.
23:12:57 <the_unmaker1> lol
23:13:08 <the_unmaker1> are fib and factorials liek super ez in functional languages
23:13:22 <conal> roconnor: there's the piece that says that b-a is defined whenever b > a
23:13:25 <ksf> :t product
23:13:26 <lambdabot> forall a. (Num a) => [a] -> a
23:13:26 <the_unmaker1> its file input and parsing and web that are hard in functional langs right?
23:14:01 <ksf> > let fak n = product [1..n] in fak 20
23:14:02 <lambdabot>   2432902008176640000
23:14:07 <conal> roconnor: roconnor and perhaps also that a + b >= a
23:14:19 <ksf> @src product
23:14:19 <lambdabot> product = foldl (*) 1
23:14:22 <the_unmaker1> http://learnyouahaskell.com/chapters this tutorial?
23:14:23 <ksf> @src foldl
23:14:24 <lambdabot> foldl f z []     = z
23:14:24 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
23:14:27 <lambdabot> Title: Learn You a Haskell for Great Good! - Chapters
23:14:30 <centrinia> It is actually very easy to write parsers in Haskell.
23:14:34 <the_unmaker1> lisp does seem to have less syntax for lists at least
23:14:39 <roconnor> conal: see http://en.wikipedia.org/wiki/Semiring
23:14:41 <lambdabot> Title: Semiring - Wikipedia, the free encyclopedia
23:14:48 * conal looks
23:14:50 <roconnor> conal: ``One can define a partial order ≤ on an idempotent semiring by setting a ≤ b whenever a + b = b (or, equivalently, if there exists an x such that a + x = b).
23:14:51 <ksf> lisp _only_ has syntax for lists.
23:14:54 <conal> roconnor: and i'm not sure the Ord part is necessary for this definition.
23:15:11 <conal> roconnor: hey that sounds good.
23:15:38 <conal> roconnor: hey: a + a = a.  i don't want that piece.
23:16:00 <roconnor> conal: every monoid as an associated partial order (althought it may be undecidable)
23:16:09 <roconnor> conal: where is a + a = a?
23:16:23 <conal> roconnor: it's a quote from that page.
23:16:32 <conal> "An idempotent semiring (also known as a dioid) is one whose addition is idempotent: a + a = a, that is, (R, +) is a band."
23:16:42 <roconnor> conal: oh crap
23:16:58 <roconnor> hmm
23:17:16 <centrinia> Not all semirings are idempotent. ;)
23:18:06 <centrinia> The ring of integers with addition and multiplication is not idempotent. ;)
23:18:07 <ddarius> monoid action or an action of some sort?
23:18:15 <conal> roconnor: however, parts of that definition fit very well.
23:18:51 <conal> roconnor: when i said t <= d i could have that t+t' == d for some t'
23:19:13 <conal> for a *unique* t'
23:19:36 <conal> so that d - t  is defined
23:20:11 <ddarius> @google torsor
23:20:14 <lambdabot> http://en.wikipedia.org/wiki/Principal_homogeneous_space
23:20:14 <lambdabot> Title: Principal homogeneous space - Wikipedia, the free encyclopedia
23:20:30 <the_unmaker1> what is this science fiction stuff?
23:20:46 <centrinia> Science fiction stuff?
23:20:48 <centrinia> Where?
23:22:48 <roconnor> conal: that is what I was initially thinking
23:23:00 <roconnor> would be part of the definition of an ordered monoid
23:23:02 <conal> torsor?
23:23:05 <roconnor> if I were to make a definition
23:23:31 <roconnor> conal: torsor : group :: affine space : vector space
23:23:45 <conal> roconnor: that looks really good.
23:23:51 <pumpkin-> what's a good math course to take to get a grasp of all the crazy language you guys use on a regular basis?
23:23:57 <conal> my durations are time deltas, i.e., vectors.
23:24:06 <ddarius> pumpkin: Most of this stuff is abstract algebra.
23:24:16 <pumpkin-> I guess I need to take more of it then :P
23:24:25 <pumpkin-> I know the basic structures
23:24:31 <pumpkin-> but have never heard of a torsor
23:24:32 <conal> roconnor: although i don't think i'll have any negative durations
23:24:45 <dolio> John Meacham seems a bit miffed about lhc.
23:24:47 <conal> pumpkin-: me too
23:24:52 <ddarius> pumpkin: The only reason I've heard of a torsor is because of John Baez.
23:24:57 <roconnor> dolio: why do you say that?
23:25:14 <ddarius> It's a really natural concept though.
23:25:23 <pumpkin-> I thought you said Joan Baez
23:25:23 <dolio> roconnor: He seemed that way in his mail on haskell-cafe.
23:25:25 <pumpkin-> I was confused :P
23:25:31 <roconnor> sadly great stuff like torsors aren't covered in undergrad math.
23:25:49 <pumpkin-> roconnor: graduate math is an option
23:26:00 <roconnor> conal: I keep thinking "convex" but I don't know how to fit that word in.
23:27:29 <conal> i'd be unhappy also in john's situation.
23:27:39 <dolio> I don't really understand his argument, though. He says the fork is silly, but he also doesn't want to be bugged about cabalizing jhc (which the fork solves).
23:28:00 <pumpkin-> what license is jhc under?
23:28:13 <dolio> Not sure.
23:28:13 <Lemmih> pumpkin-: GPL.
23:28:17 <conal> dolio: maybe he doesn't want jhc contribution energy going into a version different from the one he believes in.
23:28:39 <conal> put positively: maybe he wants jhc contribution energy going into the version he believes in.
23:29:17 <pumpkin-> dolio: wouldn't it be easier to just have someone else cabalize it for him, instead of forking the thing?
23:29:28 <conal> i wonder also.
23:29:29 <centrinia> There is a set of functions f_d that are defined only for inputs less than d.
23:29:33 <dolio> And if he won't accept the patches for that?
23:29:43 <pumpkin-> dolio: he won't?
23:29:46 <ddarius> At least part of his rational for not supporting cabal is silly
23:29:53 <dolio> I thought that was the point (among other things).
23:30:17 <conal> centrinia: that's what i'm talking about.  inputs between 0 and d.
23:30:37 <conal> centrinia: do you know of some relevant theory?
23:30:47 <centrinia> It isn't really an algebra.
23:30:58 <centrinia> You will have a lot of functions.
23:31:10 <conal> centrinia: what do you mean it's not an algebra?
23:31:15 <ddarius> Martingales might be relevant but that's too far out there.
23:31:16 <Lemmih> pumpkin-: He's very much against cabalization. Due to the nature of distributed version control, jhc was forked the instance John refused to apply my patches.
23:31:20 <dons> i'm not sure what to do. the packaged/cabal-installable version is so much more likely to be used, imo.
23:31:21 <ddarius> And not very simple.
23:32:00 <pumpkin-> Lemmih: makes sense to fork it then, I guess :) why is he so against it?
23:32:06 <pumpkin-> (cabalization)
23:32:33 <dons> you'll have to read his arguments. mostly the usual ones: make is common, and more flexible.
23:32:52 <sjanssen> pumpkin-: also philosophical differences with Cabal's approach
23:33:01 <pumpkin-> ah
23:33:02 <conal> maybe he wants something functional
23:33:06 <conal> i do
23:33:31 <dons> i think the its really lopsided now though. there's simply too much code using cabal/hackage, to the point that its much more difficult to contribute to something not in that infrastructures
23:33:41 <sjanssen> conal: as in "working", or the usual meaning?
23:33:45 <dons> using cabal /is/ how we get reuse/sharing/collaboration now
23:33:50 <conal> sjanssen: as in functional programming
23:34:03 <ddarius> conal: franchise should be a good reflection of what he wants.  You can see if it's "functional" if you'd like.
23:34:12 <dons> so cabalise or perish.
23:34:20 <conal> ddarius: what's franchise
23:34:22 <centrinia> This is the Wikipedia entry for an algebra over a set: http://en.wikipedia.org/wiki/Algebra_over_a_set
23:34:25 <sjanssen> conal: I'm curious what sort of features make a build/package system functional
23:34:35 <centrinia> I don't think what I just described is an algebra over a set.
23:34:36 <dons> conal: a setup.hs-like build system.
23:34:55 <roconnor> There is no problem as far as I see.  John won't get any complaints about cabal problems, and Lemmih will pull in John's changes.  Everyone should be happy.
23:35:13 <dons> people will work on Lemmih's repo though.
23:35:14 <roconnor> If anything is wrong it is that "fork" has a bad rap.
23:35:16 <ddarius> http://www.mail-archive.com/haskell-cafe@haskell.org/msg40088.html
23:35:19 <dons> roconnor: that's true.
23:35:26 <lambdabot> Title: [Haskell-cafe] announcing franchise 0.0, http://tinyurl.com/5bykmw
23:35:34 <dons> its just the market of ideas at work. its a healthy thing.
23:35:44 <dons> it is how projects are rewewned
23:35:47 <dons> and new ideas can be tried out.
23:36:03 <roconnor> dons: only that tiny fraction of users using Cabal will work on lhc ;)
23:36:21 <dons> yeah, so that's everyone with ghc installed.
23:36:27 <roconnor> :P
23:36:43 <centrinia> The Large Hadron Collider?
23:36:49 <pumpkin-> lol
23:37:00 <pumpkin-> I wonder how many times that joke will be made
23:37:10 <dons> pretty awesome name.
23:37:24 <dons> aka Large Heap Collider
23:37:31 <dons> little jhc joke ther.e
23:38:43 <dons> it's nice that with cabal we can package up anyone's code for native distros with ease. e.g http://aur.archlinux.org/packages.php?ID=21749
23:38:49 <lambdabot> Title: AUR (en) - lhc
23:38:53 <dons> something that wasn't done ever to jhc.
23:39:26 <ddarius> dons: Not everyone has apt, emerge, or dpkg, or ... installed.
23:39:52 <the_unmaker1> archlinux rules
23:39:55 <the_unmaker1> in fact
23:39:57 <dons> I'm not sure what your point is , or if it is not a joke.
23:40:01 <the_unmaker1> im switch to my arch box now
23:40:10 <dons> the_unmaker1: how's the haskell hacking coming along?
23:40:22 <pumpkin-> anyone tried Control.Monad.Omega here? it's fun!
23:40:28 <dons> pumpkin-: yikes.
23:40:36 <dolio> But it's not a monad!
23:40:38 <pumpkin-> is that bad?
23:40:44 <dons> scared the_unmaker1 off? did he have a stack overflow?
23:40:54 <pumpkin-> lol
23:40:58 <pumpkin-> dolio: it isn't?
23:41:02 <dons> oh. he really did intend to switch his machine over.
23:41:22 <dolio> pumpkin-: It fails the associativity law due to producing different ordering in the output.
23:41:27 <pumpkin-> :o
23:41:39 <pumpkin-> then it's a poser!
23:41:46 <dolio> It's a monad up to not caring what order the result is in.
23:43:01 <pumpkin-> how do you mean?
23:44:12 <the_unmaker> oh yeah
23:44:19 <the_unmaker> archlinux powered baby
23:44:25 <the_unmaker> leme update my whole box:
23:44:28 <the_unmaker> pacman -Syu
23:44:35 <dolio> I mean that when you do 'runOmega whatever' if you decide that [1,2,3] is the same as [2,1,3], and so on, then it's a monad.
23:45:16 <sjanssen> John Meacham makes some comments about avoiding "hegemony".  However, I wonder if having a single ruling build system is actually a good thing
23:45:25 <centrinia> Why not have runOmega :: Omega a -> Data.Set.Set a  ?
23:46:06 <dolio> Because the point of Omega is to have working operations over products of infinite lists, which rules out Set.
23:46:21 <ddarius> and Set would add an Ord constraint
23:46:30 <centrinia> Oh.
23:46:32 <dolio> Yeah, that too.
23:46:47 <roconnor> sjanssen: how ironic
23:46:48 <Giraffe> sjanssen, it does provide consistency
23:46:59 <pumpkin-> it's still handy if you ever find yourself needing to generate all fractions and such
23:47:01 <Giraffe> but if that build system is problematic (autotools, anyone?) then you run into trouble
23:47:03 <sjanssen> Giraffe: exactly
23:47:09 <dolio> You could have it be 'Omega a -> IO [a]' and say "Hey, IO is nondeterministic" but that's not very useful.
23:47:19 <sjanssen> Giraffe: Cabal has pretty much the opposite problems of autotools
23:47:25 <Giraffe> sjanssen, how so?
23:47:33 <ryrunfrnf> can you gus write parsers faster than i write regexps?
23:47:36 <sjanssen> autotools are excessively extensible, Cabal is fairly rigid
23:48:03 <centrinia> We can write regexps faster than we can write parsers in many cases. ;)
23:48:16 <Giraffe> gotcha
23:48:43 <Axman6> the_unmaker: dons who's one of the more influencial people in the haskell world these days is a big arch user too
23:48:46 <Giraffe> the other problem is...if a developer (or team) doesn't like how things work with cabal or any similar system, they get ostracized unintentionally
23:49:00 <pumpkin-> ryrunfrnf: I'll write you a parser for haskell before you write me a regex that can recognize it ;)
23:49:07 * ddarius just found out what a "heap" is.
23:49:12 <sjanssen> Giraffe: yeah, I think the community needs to work on that
23:49:21 <pumpkin-> ddarius: in the programming sense or the datastructure sense?
23:49:22 <ryrunfrnf> and how about writing a programming language with regexps for parsing?
23:49:24 <roconnor> > let f = 1:[[1/(1/x+1),x+1]|x<-f] in f
23:49:25 <lambdabot>       Occurs check: cannot construct the infinite type: t = [t]
23:49:25 <lambdabot>        Expect...
23:49:35 <roconnor> > let f = 1:concat [[1/(1/x+1),x+1]|x<-f] in f
23:49:36 <lambdabot>   [1.0,0.5,2.0,0.3333333333333333,1.5,0.6666666666666666,3.0,0.25,1.333333333...
23:49:37 <ddarius> pumpkin: In the equivalent-to-a-torsor sense.
23:49:42 <roconnor> > let f = 1:concat [[1/(1/x+1),x+1]|x<-f] in f::[Rational]
23:49:44 <lambdabot>   [1%1,1%2,2%1,1%3,3%2,2%3,3%1,1%4,4%3,3%5,5%2,2%5,5%3,3%4,4%1,1%5,5%4,4%7,7%...
23:49:45 <pumpkin-> ryrunfrnf: that's sort of the idea of PEGs
23:49:55 <sjanssen> Giraffe: we ought to incorporate and address concerns rather than ignore or refute them
23:49:57 <ryrunfrnf> PEG=?
23:50:00 <pumpkin-> ddarius: oh shit, my head just exploded again... I'd just finished putting it back together from last time you mentioned those things
23:50:07 <pumpkin-> ryrunfrnf: parsing expressing grammars
23:50:10 <Giraffe> sjanssen, exactly.  the other issue is when it does come to dissent...
23:50:13 <pumpkin-> not quite the same thing, but similar
23:50:20 <Giraffe> well, positive reinforcement is better than nothing
23:50:44 <Giraffe> people should be encouraged to use cabal, not punished for not using it (not that i'm pointing fingers or anything, i'm just saying as a general rule)
23:52:10 <Axman6> > map (\x -> 1/(1/x+1)) [1..10]
23:52:12 <lambdabot>   [0.5,0.6666666666666666,0.75,0.8,0.8333333333333334,0.8571428571428571,0.87...
23:52:24 <pumpkin-> :o
23:52:35 <Axman6> > map (\x -> 1/(1/x+1)) [1..5] :: [CReal]
23:52:37 <lambdabot>   [0.5,0.6666666666666666666666666666666666666667,0.75,0.8,0.8333333333333333...
23:53:09 <thoughtpolice> re. john m. and lhc, I got that impression from the mailing list too.
23:53:26 <ddarius> > map (recip . succ . recip) [1..5]
23:53:27 <lambdabot>   [0.5,0.6666666666666666,0.75,0.8,0.8333333333333334]
23:53:33 <thoughtpolice> it's not unsurprising - he should very much have an attachment to jhc, it being written and designed completely by him.
23:53:56 <thoughtpolice> i only hope that won't hamper future collaboration efforts in the future
23:54:11 <dolio> > fix$\l -> 1:l>>=\x->[x/(x+1),x+1]
23:54:12 <lambdabot>   <no location info>: parse error on input `->'
23:54:13 <thoughtpolice> because if we can get things like region inference etc. working in LHC, I would very much be interested in porting those enhancements back to JHC
23:54:50 <dolio> > fix$\l->1:(l>>=\x->[x/(x+1),x+1])
23:54:51 <lambdabot>   <no location info>: parse error on input `->'
23:55:10 <ddarius> dolio: Removing whitespace isn't going to help anything.
23:55:19 <sjanssen> what is the feasibility of making LHC just a patchset on top of JHC that only adds Cabal support?
23:55:26 * ddarius waits to see how long it takes dolio to figure out what is going on.
23:56:04 <the_unmaker> dons: like don corleone?
23:56:12 <the_unmaker> the don of haskell
23:56:25 <sjanssen> > let ($\) = (+) in 1 $\ 2
23:56:27 <lambdabot>   3
23:56:45 <ddarius> > let (>>=\) = (-) in 1 >>=\ 2
23:56:47 <dolio> > fix$ \l->1:(l>>= \x->[x/(x+1),x+1])
23:56:47 <lambdabot>   -1
23:56:48 <lambdabot>   [1.0,0.5,2.0,0.3333333333333333,1.5,0.6666666666666666,3.0,0.25,1.333333333...
23:56:52 <Lemmih> sjanssen: Cabalizatoin isn't the only change John is against.
23:56:55 <dolio> > fix$ \l->1:(l>>= \x->[x/(x+1),x+1]) :: [Rational]
23:56:57 <lambdabot>   [1%1,1%2,2%1,1%3,3%2,2%3,3%1,1%4,4%3,3%5,5%2,2%5,5%3,3%4,4%1,1%5,5%4,4%7,7%...
23:57:14 <thoughtpolice> sjanssen: there are more fundamental things that've already happened
23:57:23 <thoughtpolice> for one, lhc already depends on a much larger amount of external libraries
23:57:31 <roconnor> @pl \x->[x/(x+1),x+1]
23:57:31 <lambdabot> ap ((:) . ap (/) (1 +)) (return . (1 +))
23:57:49 <roconnor> bah
23:58:09 <ddarius> @pl \u -> [u/u,u]
23:58:10 <lambdabot> ap ((:) . join (/)) return
23:58:12 <roconnor> @type sequence [recip . (+1) . recip, (+1)]
23:58:15 <lambdabot> forall a. (Fractional a) => a -> [a]
23:58:16 <thoughtpolice> me and Lemmih have been tearing things down and bringing things like utf8-string, stringtable-atom, Data.Derive, ansi-wl-pprint into the code base already
23:58:23 <thoughtpolice> (which has cleaned things up A LOT, mind you)
23:59:19 <sjanssen> thoughtpolice: all of those features were previously baked in to JHC?
23:59:33 <dolio> > fix$ \l->1:l>>= \x->[x/(x+1),x+1] :: [Rational]
23:59:34 <lambdabot>   [1%2,2%1,1%3,3%2,2%3,3%1,1%4,4%3,3%5,5%2,2%5,5%3,3%4,4%1,1%5,5%4,4%7,7%3,3%...
