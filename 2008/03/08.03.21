00:09:50 <dmwit> Huh, I have the binary distribution of 6.8 lying around, but not installed.
00:10:09 <dmwit> I wonder if there was a reason I didn't install it.
00:10:25 * dmwit decides to try it and hope for the best
00:11:35 <dmwit> Aw man, Ubuntu doesn't have libreadline4.
00:11:42 <solrize> man there really seems to be no way to do low level i/o without going through ffi pain
00:11:59 <dmwit> How low level are we talking about here?
00:12:17 <solrize> well i just want to copy a file to /dev/null to see how fast i can do it
00:12:36 <dmwit> You shouldn't need FFI for *that*.
00:12:49 <solrize> i.e. read 4096 bytes at a time or something
00:12:55 <glguy> you don't need ffi for that
00:13:04 <dmwit> If you want fast, use Data.ByteString.
00:13:10 <glguy> ?index hPutBuf
00:13:10 <lambdabot> System.IO
00:13:13 <glguy> ?index hGetBuf
00:13:14 <lambdabot> System.IO
00:13:14 <solrize> oh system.posix.io
00:13:18 <solrize> system.io didn't have it
00:13:19 <dmwit> Otherwise, System.IO should have everything you need.
00:13:25 <solrize> it had stuff like getLine
00:13:29 <glguy> :t System.IO.hGetBuf
00:13:31 <lambdabot> forall a. GHC.IOBase.Handle -> GHC.Ptr.Ptr a -> Int -> IO Int
00:13:36 <solrize> but the function for reading a binary block used Foreign.ptr
00:13:39 <solrize> yeah
00:13:53 <solrize> oh ptr
00:13:55 <solrize> that's different
00:14:00 <solrize> i clicked on something and it went to foreign
00:14:13 <solrize> that went to foreign.ptr too
00:15:07 <solrize> i tried data.bytestring and it was a lot slower than python
00:15:23 <solrize> though faster than regular haskell string io
00:15:37 <glguy> You are avoiding things in Foreign on principle?
00:15:47 <glguy> not interested in Haskell 98 based code?
00:15:47 <solrize> glguy well i want to stay typesafe if possible
00:15:55 <dmwit> *blink*
00:15:57 <solrize> i guess foreign is ok
00:16:06 <dmwit> Do you not see the 'a' at the end of Ptr?
00:16:09 <solrize> i remember seeing there was some malloc like routine i'd have to get the buffer from
00:16:53 <glguy> alloca is the fastest way to get memory
00:16:56 <dmwit> Sorry, that sounded really aggressive, but it wasn't meant to.
00:17:02 <solrize> dmwit it's ok
00:17:26 <solrize> i see there are a bunch of unsafe cast operations but i'd have to go out of my way to use them
00:17:30 <solrize> so this is certainly an improvement over c
00:17:56 * glguy imagine you can still run off the end of the array with hPutBuf and hGetBuf
00:17:59 <glguy> images*
00:18:14 <solrize> also i think the bottleneck in that text sort program was data.list.sort and i'm wondering if there is something better around
00:18:16 <dolio> Third time's the charm.
00:18:21 <Carolyna_> Hello, play online with me ,
00:18:21 <Carolyna_> http.//jugar-online.blogspot.com/
00:18:26 <solrize> i gotta say that the python sorting func is carefully tuned
00:18:41 <glguy> Carolyna_: Did you have some Haskell questions?
00:18:42 <Carolyna_> Carolina Cerezuela
00:18:44 <Carolyna_> http://carolina-cerezuela.blogspot.com/
00:18:45 <dmwit> solrize: timosrt, right?
00:18:45 <lambdabot> Title: Carolina Cerezuela
00:18:49 <solrize> dmwit yeah
00:18:51 --- mode: ChanServ set +o glguy
00:18:54 --- mode: glguy set +b Carolyna_!*@*
00:18:54 --- kick: Carolyna_ was kicked by glguy (glguy)
00:19:01 <solrize> heh
00:19:58 <solrize> it's just not nice when ghc -O gives a prog that runs 7x slower than the same python prog :(
00:20:36 --- mode: glguy set -o glguy
00:21:22 <glguy> solrize: how much data are you trying to move into /dev/null?
00:21:29 <solrize> let's say 1gb
00:21:37 <glguy> which bytestring did you use?
00:22:04 <solrize> i didn't try bytestring on a 1gb file, i only ran it on that 2mb(?) text file from that usenet post
00:22:21 <solrize> i guess i can try it on the 1gb file
00:22:29 <glguy> which bytestring did you use?
00:22:45 <solrize> data.bytestring.char8 iirc
00:22:49 <glguy> use the lazy one
00:22:54 <glguy> for the 1gig test
00:22:56 <solrize> ok
00:23:54 <glguy> the bytestring file io was the fastest on the shootout until they changed the rules
00:25:07 <dolio> Did they change the rule after the Haskell submission?
00:25:20 <solrize> glguy the lazy one is a little faster for the 2gb file
00:25:28 <solrize> actually 4gb :)
00:25:35 <glguy> wow... Clean is beating C on the shootout
00:25:59 <solrize> but still slower than python
00:26:06 <solrize> glguy wow
00:26:22 <solrize> wonder if they used --no-pointer-aliasing for the c test
00:26:52 <taruti> shootout seems to have a habit of 1) add a new test, 2) haskell is too good, 3) change rules until that is fixed, 4) be happy with a more "balanced" test :)
00:27:07 <solrize> hehe
00:27:18 <solrize> haskell seems to do amazingly well with computational code but not so good with i/o
00:27:40 <taruti> solrize: the standard libraries are not very well optimized for some IO tasks.
00:27:47 <solrize> taruti yeah
00:27:56 <taruti> which is usually not a problem with real code.
00:28:06 <solrize> well, for real code that's i/o intensive...
00:28:10 <taruti> and things *can* be optimized, it just takes more lines.
00:28:35 <solrize> i just wonder what the obstacle is to making the library fast
00:28:41 <taruti> usually the io-intensive part is localized and has to be tuned for different OSs in any case.
00:29:06 <solrize> i don't have the impression that python is carefully tuned for linux.  perl might be but i think perl is faster than python
00:29:14 <taruti> one size fits it all buffering + staying portable.
00:29:44 <solrize> yeah i guess it's like doing read/write systems calls in c instead of using stdio
00:29:59 <solrize> a pain in the neck but necessary for real speed
00:30:09 <solrize> maybe i can use mmap
00:30:23 <dcoutts> I don't think lazy bytestring IO is a bottleneck
00:30:28 <dolio> It shouldn't be difficult to get quite good speed with one of the bytestring modules.
00:30:32 <dcoutts> it doesn't go via the handle buffer
00:30:34 <dolio> Considering it's highly optimized for that.
00:30:42 <taruti> bytestrings in general are very nice.
00:31:02 <solrize> also i have to handle unicode
00:31:09 <taruti> shootout has lots of line based things - maybe that is the problem?
00:31:09 <solrize> there's a module for that related to bytestring iirc
00:31:52 <taruti> at least at some point they had some rules how the input lines must be read.
00:32:07 <dolio> Yeah, that killed one of the tests.
00:32:35 <dolio> dons had written a loop that read in a lazy byte string, and then worked with the lazy list of chunks directly for optimum speed.
00:32:53 <dolio> But since the test required the use of the standard getLine function, or whatever, that was illegal.
00:33:05 <solrize> oh sheesh
00:34:43 <solrize> maybe that was before bytestring got into the standard library ?
00:35:53 <solrize> 1gb test running now, if bytestring was REALLY lazy it would detect that its stdout was pointed at /dev/null and not write antying :)
00:36:39 <dcoutts> dolio: I think we could reinstate the sumfile test using lazy bytestring and get approximately the same speed
00:37:01 <dcoutts> dolio: the main problem was reading the file all in one go, rather than in standard buffer sized chunks
00:37:19 <dcoutts> if we were using lazy io and the lines function I don't think they could complain
00:37:23 <solrize> man that seemed to go nuts i think my prog has a space leak
00:37:27 <dolio> It'd be as fast without explicitly dealing with the chunks?
00:37:40 <dcoutts> dolio: I think it could be
00:37:59 <dcoutts> I changed the lazy bytestring representation partly for that reason
00:38:23 <dolio> Ah, interesting.
00:38:36 <dcoutts> it ought to work better with constructor specialisation now
00:38:53 <solrize> oh i guess it really did have to slurp the file into memory and this is just a 1gb machine...
00:39:05 <dcoutts> which could in theory allow everything to get unboxed, like it does already with dons's strict sumfile program
00:39:27 <solrize> ok now i have it just counting lines and the process is nice and small, but not getting much cpu
00:39:31 <solrize> i/o bound i guess
00:39:42 <dcoutts> solrize: you're using lazy bytestring right?
00:39:51 <solrize> yes running again
00:40:12 <solrize> getting more cpu now due to kernel file cache
00:40:19 <dcoutts> if you're careful with the strictness of your code then using lazy bytestring allows streaming IO in constant heap
00:40:26 <solrize> same approx total speed
00:41:10 <solrize> trying with dd, bs=1M
00:41:26 <dcoutts> try 64k for a better comparison
00:41:29 <solrize> wow, dd used slightly more wall clock time, though much less cpu
00:41:41 <solrize> trying 64k
00:42:03 <solrize> not much change
00:42:05 <dcoutts> lazy bytestring defaults to 64k chunks when reading files
00:42:34 <solrize> ok i guess i should use lazy bytestring, i can't complain about that speed at all
00:42:56 <solrize> need to figure out what to do about sorting
00:43:23 <solrize> what does ghc core look like?  any reasonable control structures, or all registers and gotos and stuff ?
00:43:47 <glguy> cases
00:44:26 <solrize> hmm, not sure what to picture from that
00:45:21 <glguy> imagine Haskell code with machine mangled variable names
00:45:32 <solrize> hmm
00:45:44 <solrize> is there some godawful system f type annotation on every term, or anything like that?
00:49:24 <solrize> what's a good way to implement memoization, with something like an lru cache?
00:49:46 <solrize> i'm looking at the weak pointer docs but it looks like they get gc'd unpredictably and in no particular order
00:50:03 <dolio> Oh, hey.
00:50:30 <Cale> solrize: Take a program and compile it with ghc using the flag --ddump-simpl and you'll see :)
00:50:38 <Cale> (what Core looks like)
00:50:52 <dolio> dcoutts: Haskell already has a lazy IO program for sum-file, it seems.
00:51:14 <solrize> ghc-6.8.2: unrecognised flags: --ddump-simpl
00:51:14 <solrize> Usage: For basic information, try the `--help' option.
00:51:17 <dolio> More than one, actually.
00:54:49 <solrize> holy cow.  i guess sequoia voting machines are not programmed in haskell.  http://www.freedom-to-tinker.com/
00:54:50 <lambdabot> Title: Freedom to Tinker
00:59:18 <dolio> Clean is still the king, though.
00:59:57 <solrize> king of what?  is that about sum-file shootout?
01:00:13 <lispy> solrize: it makes me sick that aren't using open source hardware/software for voting machines
01:00:15 <dolio> Yeah.
01:01:26 <dolio> Clean is almost twice as fast as the fastest accepted Haskell entry.
01:01:49 <Cale> solrize: er, -ddump-simpl rather
01:02:20 <lispy> solrize: I don't want to sound like I know better than you how to solve your problem.  But, seriously, what type of data sets are you working on?  You're concerned with crazy low level details these days.  It's worry some :)  Have you tried a niave implementation to check the performance?
01:02:30 <solrize> proposed entry 2 looks nice for that shootout
01:03:15 <dolio> Yeah, that's dons' entry that got disqualified for explicitly operating on chunks.
01:03:34 <solrize> lispy yeah i'll try shelling out to unix sort first, that's the easiest
01:03:37 <solrize> but i like to make things go fast
01:04:04 <solrize> and i think if haskell progs have the goal of running within a factor of 2 of c programs in speed
01:04:16 <solrize> i.e. with tuning
01:04:29 <solrize> it should be equally desirable to get memory consumption to within a similar ratio
01:04:34 <solrize> and i'm not terribly short of cpu cycles
01:04:39 <solrize> but am limited to these 4gb machines
01:05:02 <dolio> #2 is, of course, embarassingly long compared to the Clean entry.
01:05:17 <solrize> do they have the sample data around and is there a python timing?
01:05:18 <taruti> solrize: usually it makes sense to first create a solution and then profile it.
01:05:23 <taruti> not the reverse.
01:05:34 <lispy> solrize: your approach might be suboptimal.  It sounds like you are building the high performance version from the ground up but can't really test it yet.  You may have better overall sucess if you build it end-to-end and then optimize way mercilessly until you get the best performance.
01:06:15 <taruti> usually just a small fraction of code is important for performance
01:06:25 <solrize> lispy to some extent that is true, but you've got to have a sound technical plan about how you're going to end up with something fast.  i'm trying to replace a big java application that's a pig
01:06:38 <taruti> for the rest of it being clean, modular and easy to refactor is important.
01:07:09 <taruti> solrize: so what do you think will be too slow?
01:07:15 <solrize> and if i'm trying to make a fast airplane it makes no sense to first build it with a steam engine and then think about putting in a jet
01:07:37 <lispy> solrize: yeah, again, I don't want sound like I know more about your problem than you do.  Just trying to give some advice based on my experiences.  Good luck eitherway.
01:07:37 <solrize> taruti, for one thing i just saw that data.list.sort is something like 7x slower than python's sort function
01:07:56 <taruti> solrize: when designing airplanes one typically makes models *tests* them, and then refines the design.
01:08:11 <solrize> another thing is the standard representation of strings with 1 cons node per character is a nonstarter, but bytestring probably fixes that
01:08:16 <taruti> solrize: data.list.sort is probably not something that you will need for performance in real world.
01:08:27 <taruti> bytestring fixes it.
01:08:41 <solrize> well i can probably find or write another sorting routine
01:09:01 <taruti> solrize: large lists are usually not the right solution. and if the lists are small then sort is probably not a large issue.
01:09:53 <solrize> right that's why i was asking about resizeable arrays earlier
01:11:09 <lispy> solrize: bytestring has been heavily optimized.  If you do find a case where the performance is poor I'm sure dons would love to see it.  It may be an already know bad case where they can't fix it, or it may be a new place to tweak performance.  Either way, bytestring is probably the fastest you'll get strings to be in haskell anytime soon.
01:11:17 <solrize> other than the above i don't see any real obstacles to using haskell, i'm impressed
01:11:37 <solrize> actually don put in a huge speedup recently because of an edge case that i found, using bytestrings as keys in data.map
01:11:50 <lispy> cool
01:12:20 <lispy> what oleg does for type hackery, dons does for optimizations :)
01:12:25 <solrize> :)
01:12:40 <dolio> Data.Map is dead, long live Data.GeneralizedTrie. :)
01:12:47 <thoughtpolice> except oleg's stuff makes me cry sometimes. :(
01:13:03 <lispy> ?quote oleg.*explode
01:13:04 <lambdabot> bos says: 00:24 < bos> it seems that quite often people will have a poke at oleg's code, their heads will explode, and they'll find some other way to do their thing.
01:13:07 <solrize> i need a ph.d. pill to read oleg's site :)
01:13:44 <lispy> And, actually that happened to me with OOHaskell.
01:13:46 <solrize> there's really data.generalizedtrie?
01:13:46 <dolio> I'm not sure that'd help. Oleg scares even PhDs.
01:13:53 <solrize> heh dolio
01:14:12 <dolio> No, there isn't. But maybe once type families get going for real in 6.10, there will be.
01:14:29 <thoughtpolice> i've gotten through some of the stuff he's published; it's all fantastic work (notably I got through a bit of his stuff on static capabilities and monadic regions.)
01:14:47 * glguy prefers his takusen library for database work
01:14:49 <solrize> taruti i'm also concerned about the space overhead of having a lot of small bytestrings (someone told me that was substantial) but again i might do some hack to shove them all in a contiguous array and just juggle pointers to them
01:15:24 <dolio> He occasionally writes stuff that normal humans can understand reasonably, too.
01:15:42 <dolio> His delimited continuations for operating systems paper was really good that way, I thought.
01:15:56 <thoughtpolice> heh, I almost opted to use some oleg hackery in a problem I had with existentials in some of my code. i instead just read the abstract of the issue and came up with my own solution eventually.
01:15:59 <solrize> oh i wanted to read that one
01:16:44 <solrize> btw can someone give a 1 sentence explanation of generic zippers?  i.e. do they rely on calling an outside continuation from inside the traverse combinator?
01:17:08 <taruti> solrize: yes. but localizing the problem first makes sense. performance issues with haskell can be non-predictable - so premature optimization rarely makes sense.
01:17:30 <thoughtpolice> probably the most incredibly insane thing I've ever seen was his simple lambda calculus implemented in the type system.
01:17:40 <lispy> I went to one HW, when it was in Portland and I remember Oleg giving this 10 minute demostration about how the type system was turing complete.  His example was to write a lambda calc evaluator in the types and then implement factorial.  It was tiny, short, genious and over my head all at the same time :)
01:17:52 <solrize> what language?
01:18:05 <thoughtpolice> he embedded a lambda calculus evaluator into haskell's type system
01:18:09 <solrize> zomg
01:18:13 <solrize> i thought you couldn't do that
01:18:16 <lispy> thoughtpolice: yeah, that was at the HW right?
01:18:19 <solrize> what's HW?
01:18:24 <thoughtpolice> lispy: not sure.
01:18:24 <dolio> solrize: They rely on constructing a monadic traversal for a data structure where at each step, you can specify what direction to go next in the traversal.
01:18:24 <lispy> haskell workshop
01:18:34 <thoughtpolice> lispy: i normally just read what's on his site
01:18:52 <thoughtpolice> there's also the type level logarithm
01:19:08 <solrize> dolio i guess the zipper has to remember everythign that it's seen
01:19:10 <solrize> ?
01:19:20 <dolio> solrize: Then, you run that traversal with a function that, at each step, captures the rest of the traversal, and presents an object with the current element, and that continuation.
01:19:49 <lispy> solrize: basically type classes work in a constraint logic sort of way.  It's very similar to something like prolog.  From that realization you can get to the lambda calc evaluator without too much fuss.
01:20:21 <solrize> but but but sputter, i thought that haskell type inference was decidable
01:21:17 <dolio> solrize: So, if you think about lists, your traversal is like: 'traverse :: Monad m => (a -> m (b, Direction)) -> [a] -> m [b]'.
01:21:18 <glguy> h98 is
01:21:51 <solrize> taruti, you're making good points, i'm still in a conceptual phase for this program and am mainly trying to check whether haskell has enough technical features to really use up the machine
01:22:25 <lispy> http://www.haskell.org/haskellwiki/Type_arithmetic <-- look at #5, I can't recall if this was oleg's example, it does use fundeps
01:22:26 <lambdabot> Title: Type arithmetic - HaskellWiki
01:22:34 <dolio> solrize: And then your zipper is something like: 'zip l = reset (\p -> Done `liftM` traverse (\a -> shift p (\k -> Stop a k)))'
01:22:47 <dolio> Oops, forgot to use the l in that, but you get the idea.
01:23:12 <thoughtpolice> there's also this:
01:23:13 <thoughtpolice> http://okmij.org/ftp/Haskell/types.html#peano-arithm
01:23:15 <lambdabot> Title: Haskell Programming: Types
01:23:16 <solrize> hmm i don't understand that at all but one of these days i'll read the paper carefully.  my officemate is also interested in it
01:23:25 <dolio> Of course, his traversal has a more complicated type, because he wants to share as much of the data structure as possible and such.
01:24:03 <solrize> i've seen a bunch of the arithmetic examples
01:24:10 <thoughtpolice> solrize: prepare yourself for the oleg.
01:24:22 <thoughtpolice> for when you think you understand you will only be struck down (generally speaking.)
01:24:37 <solrize> thoughtpolice yeah :)  i was up late last night looking at his stuff
01:24:41 <solrize> omg i'm up late AGAIN
01:25:39 <dolio> Actually, I suppose the traversal can't change the type of the elements, either, since you might not visit the entire list.
01:25:43 <dolio> But anyhow.
01:27:05 <solrize> so let's see: 1) fast io: bytestrings probably suffice.  2) fast sorting: write some code, doable.  3) efficient memory usage: biggest data structures are simple enough to manage through some STUarray or FFI hack if necessary.  4) internal state management (caches and so forth): might be a bit ugly but can use regular haskell types, requirements are not too demanding
01:27:37 <taruti> caches are not a problem.
01:27:41 <lispy> http://www.haskell.org/pipermail/haskell/2006-September/018486.html
01:27:43 <lambdabot> Title: [Haskell] On computable types. I. Typed lambda and type closures, http://tinyurl.com/2x8mvd
01:27:50 <lispy> I think that's what he presented at HW
01:27:55 <lispy> I found it via HWN
01:27:58 <lispy> so that makes sense
01:28:03 <lispy> based on the date and description
01:28:22 <thoughtpolice> there're also some other cool examples like the type-level quicksort and type-level fizzbuzz
01:28:23 <solrize> Incidentally, the present code constitutes what seems to be the
01:28:24 <solrize> shortest proof that the type system of Haskell with the undecidable
01:28:24 <solrize> instances extension is indeed Turing-complete.
01:28:27 <taruti> Data.LRU (from hackage) is quite simple to use and if you need more performance using a custom thing also works.
01:28:33 <solrize> yeah i saw the fizzbuzz and think i sort of understood it
01:28:39 <solrize> aha, data.LRU, thanks
01:28:46 <solrize> also i saw something about a heap structure
01:29:00 <solrize> what's the difference between big step and small step ?
01:29:31 <solrize> oh yeah i wanted a gzip continuation i wonder if that's ever been done
01:30:32 <solrize> :t spawn
01:30:35 <lambdabot> Not in scope: `spawn'
01:31:32 <solrize>     *  hashtable performance is poor. A simple binding to a basic C hashtable would be very useful
01:31:44 <solrize> yeah i've been wondering about that data.map thing :(
01:32:46 <solrize> when i try to write a fast c program the first thing i think about is the machine code for the innermost loops, and sometimes the program's whole high level design flows from that
01:33:45 <wli> When I write C, I'm more concerned about API structure and modularity than speed.
01:33:58 <solrize> if you're not concerned about C why do such a crazy thing as write in C?  :)
01:34:03 <solrize> about speed
01:34:22 <wli> solrize: Maybe I work on C code.
01:34:51 <solrize> yeah there's still a lot around, it should all be thrown out :)
01:35:26 <solrize> some of the doc links from that shootout page are broken
01:35:31 <wli> Something like C is needed for systems programming. Granted, one could do much better wrt. language design even for such a low level.
01:36:17 <solrize> yeah i wrote some c code the other day for the first time in a while, and i made a dumb type safety error that the compiler didn't notice
01:36:19 <wli> (I daresay Ada.)
01:36:43 <solrize> wli yeah i have more respect for ada now than i used to
01:36:51 <solrize> my officemate used it at his last job (aerospace)
01:37:05 <solrize> i looked at a book about it, it looks a bit clutzy but basically saner than c
01:37:25 <solrize> cyclone is pretty interesting, a c dialect with type safety
01:37:40 <solrize> you can port c code to it fairly straightforwardly, they converted some linux device drivers to it
01:37:46 <wli> I'd call it more of a derivate than a dialect.
01:38:04 <solrize> fair enough
01:38:26 <solrize> so when is the right time to use weak pointers?  seems like it would take good understanding of how and when the gc runs
01:40:20 <luqui> weak pointers are good for caches and other things that are semantics preserving
01:40:28 <luqui> i.e. you have to make sure your code works correctly even if the gc never runs
01:41:16 <solrize> yeah, what i basically want to do is keep a few thousand items cached and age them out if they're not re-used
01:41:28 <solrize> data.LRU as taruti suggested
01:41:51 <solrize> i just mean that if gc behavior is totally unknown then weak pointers don't sound worthwhile
01:42:23 <solrize> the idea is they should stay around long enough to be useful but not long enough to occupy memory uselessly
01:42:42 <solrize> and there doesn't seem to be any way of making some of them fresher than others
01:43:11 <solrize> like with a multigenerational gc, moving them on reference
01:44:19 <luqui> yeah, I'm pretty sure you can't do that purely
01:44:33 <luqui> you could do it if you accessed the data through a monad or something
01:44:56 <solrize> well if the compiler knew about them and generated the right code
01:45:13 <solrize> it already has to do far more impure things for `par`
01:46:32 <luqui> fair enough.  it might be a bad idea since it would either be a highly experimental module or lock down implementation decisions that we don't want to lock down... but yes the compiler could of course do it
01:47:37 <solrize> yeah it's almost certainly a bad idea
01:47:44 <solrize> but still possible :)
01:51:04 <solrize> oh cool, there's a SoC project for unicode bytestrings
01:51:11 <solrize> last modified 2 days ago
01:51:49 <solrize> no wait not soc, someone's masters' project
02:09:11 * solrize nails arthurclemens to the channel floor :)
02:19:40 <solrize> http://groups.google.se/group/fa.haskell/msg/ceb6edf250fd069f
02:19:41 <lambdabot> Title: The Proliferation of List-Like Types - fa.haskell | Google-grupper
02:39:53 <Eulex> hello
02:40:15 <desegnis> be greeted
02:41:53 <Eulex> I'm trying to pass a list of functions to call next to a function, but it appears that at least the way I am trying to do it is not allowed by haskell: http://hpaste.org/6539 -- I get an infinite type error. can this be done and if so, how?
02:44:51 <desegnis> Eulex: Your code has essentially the same problem as in (\x -> x x)
02:45:18 <desegnis> Because you are passing fs to f
02:46:09 <Eulex> sorry, I'm very new to haskell, I don't really understand why it is wrong
02:46:42 <desegnis> Hm... maybe you could first explain detailed, in words, what you're trying to do?
02:47:15 <desegnis> Better to first solve your problem, and then explain why your code fails
02:47:42 <solrize> eulex, try writing explicit type annotations for those functions.  if you can't figure out what they should be, the compiler can't either.
02:48:01 <Eulex> solrize, ok
02:53:02 <Eulex> well, I read about CPS the other day, and now I was going to write a parser (for propositional logic wffs) so I thought that I could try it out. turned out to be very hard. basically, I was missing a way of telling it what to do after the continuation has been called (often didn't suffice to have the continuation decide) so I thought that I could perhaps use a stack of functions, which some functions just passed on and others added to b
02:53:02 <Eulex> efore passing on etc.
02:55:08 <desegnis> Eulex: Is it ok if I first explain (\x -> x x)?
02:55:30 <Eulex> desegnis, sure :)
02:56:28 <desegnis> First, (\x -> x x) is perfectly valid in the untyped lambda calculus, but it is a type error in Haskell (as well as the various typed lambda calcui, fwiw)
02:56:42 <desegnis> Let's try to determine its type.
02:57:02 <Eulex> not possible, I think?
02:57:16 <desegnis> right :)
02:57:56 <desegnis> x has some type T, and since it is applied to another value (namely x) it is clear that T = A -> B for some types A and B
02:58:25 <desegnis> Now since x is applied to x, what does that mean for A?
02:58:46 <dolio> @type ((\x -> x x) :: (forall a. a -> b) -> b)
02:58:47 <lambdabot> forall b. (forall a. a -> b) -> b
02:59:15 <desegnis> ah... I'm not informed about higher-rank types :)
03:00:34 <desegnis> Eulex: That is, dolio made it work by means of a GHC extension
03:00:54 <Eulex> ok
03:01:04 <desegnis> Anyway, A = T
03:01:34 <desegnis> Thus T = T -> B = (T -> B) -> T = etc.
03:01:43 <desegnis> er
03:01:49 <desegnis> (T -> B) -> B, rather
03:02:12 <desegnis> Which explains why ghc complains about an infinite type.
03:02:41 <dolio> @type ((\x -> x x) :: (forall a. a -> b) -> b) (const 5)
03:02:42 <lambdabot> forall b. (Num b) => b
03:03:15 <scook0> μX. X -> B
03:03:17 <desegnis> And since infinite types are not allowed... you see?
03:03:41 <dolio> In other words, giving it that higher ranked type means you can't do anything very interesting with that a.
03:03:53 <Eulex> yes
03:04:16 <Eulex> anyway, the core problem I have when parsing is that if you begin a sub-expression within parantheses, you'll have to store in some way that after this expression is parsed I will have to make it call parseClosingParen or a similar function. passing a fixed number of functions to the function that parses the sub-expression would not be enough. for example, if I have a parser that just can parse expressions like ((())) when I've parsed s
03:04:16 <Eulex> o much so that I'm in the middle of it, I'll have to store that the next function to be called will be parseClosingParen, then parseClosingParen, parseClosingParen and finally parseEnd. so I figured I needed a stack, but perhaps there's some other solution?
03:04:29 <Eulex> woops, sorry for the flood...
03:04:50 <dolio> Higher ranked types don't let you type Y or Omega, for instance (I think).
03:05:21 <dolio> Or, all the subterms of those, that is. You can, of course, type Y as a whole in Haskell.
03:05:42 <desegnis> Eulex: Now, you have something very similar in your definition: If f has type T, and f _ _ :: [A] -> B, we have T = A.
03:09:10 <dmwit> Eulex: How about calling the function as you work your way back up the call stack?
03:09:26 <dmwit> In parsec, for example, you could do something like:
03:10:03 <dmwit> parseParens = do { char '('; parseParens; char ')' }
03:10:15 <dmwit> (But with a little extra work to recognize when we're in the middle.
03:10:53 <dmwit> Notice that parseParens doesn't really take any parameters; it knows how many ')'s to parse just by how deeply the final call was nested.
03:11:37 <Eulex> dmwit, however, wouldn't this require me to return the remaining string to parse?
03:11:55 <Eulex> desegnis, so, basically the approach is flawed?
03:11:58 <dmwit> No, why?
03:12:30 <dmwit> Oh, well; Parsec handles keeping track of what's left to parse for you.
03:13:13 <desegnis> Eulex: Basically that means that your function does not work in Haskell. But again, I'm not into CPS
03:14:02 <Eulex> ok, thank you
03:14:18 <Heffalump> you can generally do things that have infinite types normally by wrapping them in a datatype
03:14:22 <dmwit> Ah, I've read a bit more of the scrollback.
03:14:24 <Heffalump> whether that's actually advisable is a different question
03:15:00 <dmwit> Eulex: What you can do for CPS is, rather than passing an array of functions, just pass the composition of the old continuation with the new "extra" computation.
03:15:17 <dmwit> I don't know if this applies; I may still be misunderstanding what you're trying to do.
03:15:28 <Eulex> dmwit, ah, that's smart
03:17:07 <Eulex> I'll try it out :)
03:17:08 <Heffalump> also, you can represent a list of functions that you intend to compose in a GADT
03:17:59 <Heffalump> data F a b where Id :: F a a ; Single :: (a -> b) -> F a b ; Comp :: F a b -> F b c -> F a c
03:19:22 <dmwit> Hold up half a tick, those constructors don't return "F a b"s!
03:19:29 <dmwit> Is that allowed?
03:20:04 <Heffalump> that's what a GADT does
03:20:11 <Heffalump> the G bit means you are allowed to do that
03:20:30 <Heffalump> (G for generalised)
03:20:49 <dmwit> I see.  Are the a's and b's the same in that whole line?
03:20:56 <dmwit> Or: where can I find out more?
03:21:01 <dmwit> ?where gadt
03:21:02 <lambdabot> http://www.haskell.org/ghc/docs/latest/html/users_guide/gadt.html
03:21:11 <dmwit> 404'd
03:21:15 <dmwit> ?go haskell gadt
03:21:17 <lambdabot> http://en.wikibooks.org/wiki/Haskell/GADT
03:21:21 <solrize> oh man, dmwit that stuff is awesome, look for the article about how darcs uses them
03:22:24 <solrize> later
03:24:00 <Eulex> is there a way of representing a function that 'should not be called' in haskell and will yield an error if you do? like (if you excuse the C-ism) in C if you pass a NULL pointer as a function pointer?
03:24:12 <dmwit> error
03:24:27 <byorgey> Eulex: badFunc x = error "You... you didn't!!"
03:24:33 <AndreWe> @type error
03:24:34 <lambdabot> forall a. [Char] -> a
03:24:43 <Eulex> thank you :)
03:25:24 <scook0> though unlike NULL, you can't really distinguish it from a real function
03:25:43 <AndreWe> That's referential transparency, isn't it?
03:35:07 <Baughn> Eulex: If you just want a placeholder for a function you haven't implemented yet, use 'undefined'
03:35:23 <AndreWe> @type undefined
03:35:24 <lambdabot> forall a. a
03:35:43 <Baughn> AndreWe: No, it's just that functions are opaque. You can't tell what they'll do without calling them.
03:36:28 <AndreWe> Isn't that what referential transparency is about?
03:37:10 <Baughn> Nope. Referential transparency, at least the way it's defined here, means that the value of a function depends solely on its parameters - and there are no side-effects
03:37:29 <Baughn> So, "foo 2 42" is always the same value no matter when and where you use it
03:37:46 <thoughtpolice> AndreWe: referential transparency says that f(x) will *always* equal f(x) for the same 'x'
03:37:47 <AndreWe> I think it's getting clearer to me.
03:38:21 <Baughn> AndreWe: Basically, referential transparency means "This works the same as in math." ;)
03:38:29 <AndreWe> thoughtpolice: But that is only one consequence of referential transparency, right?
03:38:36 <thoughtpolice> you can always be assured that the result f(1) will be the same every time you call f(1). there are no exceptions.
03:39:09 <Baughn> AndreWe: That /is/ referential transparency. It's the definition, not a consequence.
03:39:18 <thoughtpolice> AndreWe: it's basically all referential transparency is, not really a consequence. a consequence however, is that it makes it a lot easier to reason about programs and functions
03:40:36 <thoughtpolice> the function does not care about what time it is, where it's being executed or for what reason. it only knows how to give output, given input. that's all.
03:40:56 <Baughn> AndreWe: Combined with lazy evaluation, this is also why you absolutely can't do I/O in pure functions, even if it wouldn't affect its value - there's no telling what order it'd be evaluated in
03:41:16 <AndreWe> thoughtpolice: It's not a consequence then, but only the definition for referential transparency when using Haskell, opposed to referential transparency in logic.
03:41:52 <Baughn> AndreWe: ..yeah, this isn't #linguistics. :P
03:42:08 <thoughtpolice> it's the definition of referential transparency in computer science, entirely. you can have referentially transparent functions in any language.
03:42:09 <AndreWe> :)
03:42:27 <thoughtpolice> but yes :>. i'm not much on linguistics
03:42:34 <Baughn> AndreWe: The CS term is derived from the linguistics term, though
03:42:59 <AndreWe> thoughtpolice: Although you're the police, I don't think you're right here. ;-) I would say that logic is part of CS as well.
03:43:05 <thoughtpolice> referential transparency is really nice though. the ability to reason about what f(x) will produce is greatly eased when there can be no side effects.
03:43:24 <Baughn> AndreWe: Ie. it's the /values/ of a variable (which don't exist, but..) that matters, not the identity of the variable
03:43:27 <AndreWe> I really like RP as well.
03:43:48 <Lycurgus> scientific terms are by necessity natural language bound
03:44:30 <Lycurgus> presumably nothing scientific won't translate from one "sufficiently rich" NL to another
03:44:31 <thoughtpolice> i suppose it depends on how broad your definition of CS is; I'm inclined to side with you as I have no idea, I'm not a CS student or anything of the sort (yet)
03:45:36 <Lycurgus> at least until a NL well founded on UG appears (whence said binding might cease to be a necessity)
03:45:59 <AndreWe> What's UG?
03:46:14 <Baughn> Universal grammar? Only if that actually /exists/. :P
03:46:36 <Baughn> (If it does, wouldn't every language by definition already be based on it?)
03:46:59 <opqdonut> no, only polynomially reducible to it :P
03:47:26 <Lycurgus> yes, every human (and some appropriate extension) language
03:48:01 <Baughn> Lycurgus: Now, as I understand, UG must be based on details of human brain architecture
03:48:19 <Baughn> Leaving aside the detail that not all brains are identical.. what happens once we start deliberately altering it?
03:48:28 <seafood__> How do I show the locally installed packages using the cabal utility?
03:48:35 <Baughn> seafood__: ghc-pkg -l
03:48:41 <seafood__> really?
03:48:43 <seafood__> Wow.
03:48:55 <seafood__> I suppose that's very obvious now that I think about it.
03:49:04 <Lycurgus> you mean post-singularity?
03:49:29 <Heffalump> dmwit: sorry, was away. In each clause of the definition variables are the same. But not in the whole line.
03:49:36 <Baughn> Lycurgus: Whatever /that/ is. I don't believe there will be any noticable discontinuity, except for people who stay behind
03:49:55 <Baughn> Lycurgus: But, yes. It'd have to be post-.
03:49:56 <Lycurgus> i don't like to speculate on post singularity stuff unless it's certain from first principles
03:50:18 <Baughn> Okay. How about primitive AIs?
03:50:32 <Lycurgus> i.e. unless we can infer it now pre-singularity
03:50:50 <Baughn> Meh. You're no fun. ^_^
03:51:38 <Lycurgus> <- on guard against crackpots, creeps, suckers, usw.
03:52:28 <Baughn> <- Nervous about the likelihood of brute-force AI. Time for lunch, though..
03:54:48 <Lycurgus> though I do believe the technological sigularity Kurweil describes is immanent. I suppose between 30 and a 100 years depending on events. Less of course if one can't discount external and prior singularities in that timeframe.
03:57:32 <Lycurgus> *kurzweil
03:59:15 <Peaker> do you believe that technological singularity will be the end of the human race? :-)
04:00:37 <Peaker> by obseleting humans by smarter computers - humans may lose power completely, and become subjects of the computer's will, which will hopefully have been defined well enough by the humans before that
04:01:52 <Lycurgus> I haven't fully digested Kurzweils book. Have detected one major flaw in his thinking and that naturally colors judgement as it was also accompanied by a moment of class consciousness.
04:02:22 <Baughn> Peaker: Not to worry. Ideally, we'll become one with the computers.
04:02:23 <Lycurgus> However, I presume both his and my understanding imply a merger of human and AI.
04:02:41 <Baughn> It's the best outcome
04:02:59 <Peaker> Why is a merger "good"?
04:03:15 <Lycurgus> though practical immortality and not computer power would be the reason for the merger.
04:03:15 <Lycurgus> *compute
04:03:49 <NatLWalker> what is the best free haskell compiler?
04:03:55 <Baughn> NatLWalker: GHC
04:04:01 <NatLWalker> kk
04:04:07 <Peaker> Lycurgus, an increase in the life-time constant, not immortality..  Heat-death, cold-death, etc :-)
04:04:30 <Baughn> Peaker: Removal of human flaws, practical immortality, vast intelligence increases..
04:04:56 <Peaker> Baughn, I am not sure all of those are "good" things
04:05:01 <Lycurgus> right, I don't even believe in concrete infinities so immortality as such is a non or common sense locution
04:05:08 <Peaker> Baughn, as in, aligned with typical humans' real goals
04:05:11 <Baughn> Peaker: I don't imagine anyone will be /forcing/ you
04:05:28 <Baughn> Peaker: ..typical humans' real goals often horrify me. That could be a problem, yes.
04:06:39 <Peaker> Baughn, they are quite directly stemming from biological programming, I think
04:07:43 <Baughn> Peaker: Extrapolating from that, we could end up in a scenario where /humans/ are the berserkers
04:07:59 <Baughn> I really hate evolution sometimes
04:08:33 <Lycurgus> berserkers is from waht?
04:09:18 <Baughn> I don't know who invented the term, but what they are is.. robots, originally, whose sole purpose in existence is to be bountiful and multiply. Oh, and kill everything else for resources to do so.
04:09:30 <Baughn> More or less what you'd expect from uncontrolled evolution
04:09:44 <Peaker> Baughn, I remember I used to chuckle at the absurdity of movies like Terminator, I Robot or many others where computers rise up to fight the humans -  but I've grown to believe it to be a very likely result of tech signularity
04:09:56 <Lycurgus> i see. I think there are other more common uses of that term.
04:10:05 <Baughn> Peaker: And I've come to realize that the robots may very well be on the right side
04:10:20 <Peaker> Baughn, define "right side"
04:10:29 <Baughn> Peaker: The one I'd be on
04:10:33 <Peaker> Baughn, heh
04:10:52 <Peaker> Baughn, you'd be useless for the robots - human intelligence will be obselete
04:11:17 <Peaker> I think those movies are optimistic - in that they think humans will still be able to outsmart the computers
04:12:02 <Baughn> Peaker: If they're the sort of robots I'd want to be on the side of, they probably wouldn't mind bootstrapping me
04:12:05 <Eulex> if I have f (a :: Int) b c = (a, b, c), why is f.f invalid? If I simplify it to not specify any type for a, it works.
04:12:30 <Baughn> Peaker: What I've realized (to my horror) is that I can very easily see a scenario where the bulk of humanity is opposed to my own goals. Call me a mad scientist, I guess.
04:12:41 <sieni> Peaker: what makes you think that a technological singularity happens?
04:12:41 <Peaker> Baughn, what are your goals?
04:12:49 <quicksilver> Eulex: remember that, really, all haskell functions have only one parameter.
04:13:02 <quicksilver> Eulex: so f's parameter (aka first parameter) is an Int
04:13:10 <Baughn> Peaker: To begin with, "Don't eat the universe just so you can have uninteresting kids"
04:13:10 <quicksilver> Eulex: you can't call that with a tuple. (a,b,c)
04:13:14 <Peaker> sieni, well, I believe human intelligence is nothing "special", and that computers will eventually outsmart humans. They will thus be able to design even smarter computers, leaving human intelligence far behind
04:13:28 <Peaker> Baughn, the universe is very big
04:13:29 <Baughn> Peaker: I believe that children should be designed to bring something new into the world, not just more of the same
04:13:31 <sieni> Peaker: perhaps
04:13:51 <Spark> Baughn: is it not enough to compensate for all the death
04:14:12 <Peaker> Baughn, children are "designed" to bring happiness to their parents
04:14:26 <Baughn> Peaker: No, parents are designed to be irrationally happy about children
04:14:31 <Eulex> quicksilver, ah, ok. well, how would I return 'several parameters' to put onto f from f?
04:14:42 <Baughn> Spark: That would be good. It's a start. But don't take it as an excuse to fork-bomb.
04:14:46 <Peaker> Baughn, There is no set of goals you could call "rational" - goals are irrational/arbitrary by definition
04:14:55 <Peaker> Baughn, "fork-bomb" :-)
04:14:59 <Baughn> Peaker: I am aware, yes
04:15:05 <quicksilver> Eulex: the simplest way to make f self composable is to make its argument also a three-tuple
04:15:11 <Baughn> Peaker: The problem is that lots of people /aren't/. ;)
04:15:12 <quicksilver> f (a,b,c) = (a,b,c)
04:15:16 <quicksilver> Eulex: you can self compose that.
04:15:23 <Baughn> Peaker: ..let's stop jamming the channel.
04:15:38 <ac> or you could make it just a little more interesting: f (a,b,c) = (b,c,a)
04:15:38 <byorgey> > let f (a,b,c) = (a+1,b,c) in f . f $ (1,4,5)
04:15:40 <lambdabot>  (3,4,5)
04:15:41 <Eulex> quicksilver, ah, wonderful :)
04:16:04 * Eulex converts all his functions into taking a three-tuple
04:16:57 <ac> iterate (1,2,3) f where f (a,b,c) = (b,c,a)
04:17:01 <ac> > iterate (1,2,3) f where f (a,b,c) = (b,c,a)
04:17:01 <lambdabot>  Parse error at "where" (column 19)
04:17:06 <ac> bah
04:17:33 <quicksilver> > let f (a,b,c) = (b,c,a) in iterate f (1,2,3)
04:17:34 <lambdabot>  [(1,2,3),(2,3,1),(3,1,2),(1,2,3),(2,3,1),(3,1,2),(1,2,3),(2,3,1),(3,1,2),(1,...
04:17:58 <luqui> let f (a,b,c) = (b,c,a) in nub $ iterate f (1,2,3)
04:18:29 <luqui> > let f (a,b,c) = (b,c,a) in nub $ iterate f (1,2,3)
04:18:33 <lambdabot> Terminated
04:18:39 <luqui> aww, no printing lists with 3+_|_ elements?
04:18:58 <Peaker> why isn't there a real symbol for _|_ ?
04:19:07 <luqui> there is, it's just not in ascii
04:19:12 <Baughn> Peaker: What would you do with it?
04:19:26 <Peaker> Baughn, wipe it? :)
04:19:40 <mauke> ⊥
04:19:43 <luqui> ahh, answering the wrong question I was
04:19:51 <quicksilver> luqui: what LB is effectively doing is take 80 . show
04:20:03 <quicksilver> luqui: so you need the first 80 chars to be produced lazily
04:20:12 <quicksilver> just producing "some" chars lazily is not enough.
04:20:16 <luqui> ah
04:20:57 <quicksilver> this is slightly different from ghci
04:21:07 <quicksilver> ghci would have displayed the 3 elts and then hung
04:21:42 <ac> take 3 works fine
04:21:50 <quicksilver> yup
04:22:14 <luqui> I can imagine a solution in lambdabot that would reproduce ghci's behavior (for an appropriate definition of "hang" of course)
04:22:19 <luqui> but it's friggin ugly
04:24:29 <Baughn> The program is actually run in a separate process. Couldn't that be set to unbuffered printing?
04:25:40 <quicksilver> yup
04:25:47 <quicksilver> it could, but it isn't :)
04:25:56 <quicksilver> it would need to be more than unbuffered printing, though
04:26:08 <quicksilver> it would need to be unsafe-interleaved
04:26:08 <Spark> i'm looking at code that is like this:
04:26:14 <Spark> palin [] = True
04:26:46 <Spark> palin (x:xs) | (x:xs)!!((length (x:xs))-1) /= x  = False
04:27:07 <Spark>  | (x:xs)!!((length (x:xs))-1) == x  = palin (drop xs)
04:27:20 <Spark> where drop yields a list without its last element
04:27:28 <Spark> why does this need another case for a singleton list?
04:27:48 <mauke> oh god wtf
04:28:00 <scook0> palin xs = xs == reverse xs
04:28:01 <scook0> :)
04:28:06 <quicksilver> list withouth its last element is called "init"
04:28:09 <Spark> i'm not interested in the quality of the code
04:28:10 <quicksilver> not "drop", nomrally :)
04:28:19 <Spark> it's an assignment that i have to mark
04:28:23 <quicksilver> the answer to your question is that that code assumes "xs" has at least one element.
04:28:26 <Baughn> quicksilver: Actually.. nope. :)
04:28:32 <Spark> ah yes true
04:28:38 <Spark> so we need a version that doesn't call drop in the case of a singleton
04:28:41 <quicksilver> which means (x:xs) is at least too.
04:28:44 <quicksilver> erm two.
04:28:46 <quicksilver> damn homonyms
04:28:51 <Baughn> er..
04:29:20 <Spark> = if xs = [] then True else palin (drop xs)
04:29:22 <mauke> palin xss@(x : xs) | xss !! (length xss) /= x = False
04:29:24 <Spark> that would work would it not?
04:29:29 <Lycurgus>  mauke: are you referring to your blank line (that's what I see in irssi).
04:29:29 <Spark> or just palin [x] = True
04:29:30 <mauke>  | otherwise = palin (drop xs)
04:30:07 <mauke> Lycurgus: you can't see unicode?
04:30:20 <Spark> mauke: you just replaced the inverse with "otherwise", right?
04:30:38 <mauke> yes, and used xss@ to bind the whole thing
04:31:01 <byorgey> Spark: "otherwise" is defined to be True, so it's useful as a last fall-through case
04:31:14 <Lycurgus> No. Have in the past though. Have seen chinese characters, presume they are unicode. Dunno if I've seen running on this host though.
04:31:27 <Spark> the students have to prove properties about programs that they are given
04:31:36 <Spark> unfortunately sometimes these programs are incredibly ugly and boring
04:31:48 <Spark> maybe this is intentional, who knows :)
04:32:08 <Spark> proving correctness of "palin xs = xs == reverse xs" is a lot easier
04:32:10 <byorgey> Spark, wait, that code you showed is code given to students on an assignment?
04:32:17 <Spark> assuming you have a lemma about revers
04:32:22 <Spark> yep
04:32:41 <byorgey> wow, yuck
04:32:42 <scook0> that's ... cruel
04:32:43 <Spark> and then it's given to phd students to mark
04:32:52 <Spark> so it is hated from all angles and perspectives
04:33:35 <Baughn> > [2,3,undefined]
04:33:35 <lambdabot>  Undefined
04:33:36 <Cheiron>  [2,3,Exception: Prelude.undefined
04:33:37 <Lycurgus> looks like I need to install UTF-8
04:33:39 <sieni> I wonder why computer scientists have such a preference for _really_ verbose proofs
04:34:03 <mauke> U+00F6 (c3 b6): LATIN SMALL LETTER O WITH DIAERESIS [ö]; U+20AC (e2 82 ac): EURO SIGN [€]
04:34:11 <sieni> that's what bugged be with TAPL
04:34:35 <Lycurgus> the o umlaut showed fine
04:34:45 <sieni> but perhaps there is an educational point in it or something
04:34:48 <Lycurgus> euro didn't
04:34:50 <Baughn> quicksilver: Not an unsafeInterleaveIO in sight. Want the patch?
04:35:49 <scook0> "Spin̈al Tap"
04:36:08 <scook0> yeesh, even my client messed that up
04:36:15 <mauke> I can sort of see it
04:36:27 <mauke> but the glyph for the dots is semi-broken
04:36:40 <scook0> oddly enough it was fine in the input field, but broken in the channel window
04:37:05 <therp> sieni: hm yes, tapl is pretty verbose. I would have preferred a more mechanical/formal/concise way of proofing
04:37:13 <quicksilver> Baughn: erm, undefined is cheating
04:37:17 <quicksilver> Baughn: that might work anyway
04:37:25 <quicksilver> Baughn: show me with a real non-terminating thing
04:37:49 <sieni> therp: it's a bit annoying to read through 2.5 pages of proofs that are plain obvious
04:37:57 <quicksilver> > nub $ cycle [1,2,3]
04:38:02 <sieni> "by induction" would have been a sufficient proof
04:38:02 <lambdabot> Terminated
04:38:14 <quicksilver> Baughn: like that one
04:39:33 <luqui> well, tapl is kind of a textbook introducing formal CS in a way
04:39:44 <luqui> so what is obvious to you is less obvious to others
04:40:12 <luqui> (I'm sitting in on a class right now with people to whom "by induction" would not at all be sufficient)
04:40:24 <luqui> (because they're scared of the word "proof")
04:40:33 <Lycurgus2> mathematical induction?
04:40:55 <luqui> but then again, I guess a proof of any length wouldn't really work, because they're not used to thinking that way
04:40:58 <luqui> so... point taken
04:41:35 <therp> sieni: in the first few chapters, showing how proofs are done is ok imho. but I usually feel overwhelmed by the flood of words used in the proof.
04:43:00 <Lycurgus> actually I think the only thing I've seen work in irssi is that people with xchat clients seem to be able to send anything and irssi renders the proper glyphs
04:43:31 <sieni> Lycurgus: only thing? :-o
04:43:52 <sieni> irssi just works and isn't a pain in the ass except for a few misfeatures
04:44:07 <Lycurgus> well in terms of being able to handle unicode/non core ascii charsets
04:44:10 <sieni> like really stupid reconnection logic
04:44:59 <mauke> I'm using ☃irssi☃ and it seems to handle utf8 fine
04:45:09 <Lycurgus> sieni: what client do you use?
04:45:47 <Lycurgus> mauke: if you go to #ubuntu-cn do you see chinese characters?
04:45:53 <dolio> Oh, it's a snowman.
04:46:09 <mauke> Lycurgus: in the topic, yes
04:46:42 <sieni> Lycurgus: irssi :-)
04:47:10 <sieni> irssi is one of the few pieces of software that doesn't annoy me constantly
04:47:23 <sieni> well of those pieces of software that I use
04:47:25 <Lycurgus> OK. so I probably just need to configure something.
04:47:35 <Baughn> > nub $ cycle [1,2,3] -- Unfortunately, Eval.hs uses the empty string to detect a timeout..
04:47:39 <Cheiron>  [1,2,3
04:47:41 <lambdabot> Terminated
04:47:58 <Lycurgus> because I've definitely seen hanzi in the past.
04:48:01 <quicksilver> Baughn: nice
04:48:46 <Baughn> quicksilver: Still no unsafeInterleaveIO. As I suspected, the only thing that had to be done was to remove all buffering
04:49:03 <MarcWeber> Do you know to which library ParsecPos belongs?
04:49:11 <MarcWeber> It's used in hsffig
04:49:30 <taruti> parsec?
04:49:38 <quicksilver> Baughn: nice
04:49:59 <taruti> hmm. no.
04:50:12 <taruti> parsec defines SourcePos
04:53:15 <Lycurgus2> yeah this host handles hanzi fine so it's just the environment missing the fonts on the other hosts.
05:28:49 <Peaker> @src Identity
05:28:49 <lambdabot> newtype Identity a = Identity { runIdentity :: a }
05:29:13 <Peaker> @src runIdentity
05:29:13 <lambdabot> Source not found. Do you think like you type?
05:30:28 <mauke> that is the source
05:31:23 <Peaker> how do I see the instance declarations of Identity?
05:31:43 <Peaker> @instances Identity
05:31:51 <lambdabot> Couldn't find class `Identity'. Try @instances-importing
05:32:10 <allbery_b> there aren't asny
05:32:30 <Peaker> oh, I thought that Identity was a monad
05:32:32 <quicksilver> :info Identity , in ghci
05:32:39 <quicksilver> it is a monad and a functor
05:32:41 <quicksilver> at least
05:32:45 <allbery_b> it is.  that means it is an instance, noit that it has instances
05:32:53 <quicksilver> lambdabot can't searching in that direction
05:32:55 <allbery_b> Monad has instances
05:33:37 <Peaker> allbery_b, yeah, I wanted to know if lambdabot can tell me what Identity is an instance of, not the other way around, but :info does the trick
05:33:54 <allbery_b> yeh, it'd be nice if LB did that, oh well
05:34:24 <allbery_b> every so often :info is discussd but the consensus is that it would be spammy.  although maybe it could respond via /privmsg
05:36:47 <OWNER> 
05:36:56 <hallongrottan> is that so
05:37:11 <mauke> os ʎlpǝpıɔǝp sı ʇı
05:39:03 <Peaker> :info shows me that Identity is a Monad, but not how it implements return / >>=
05:39:07 <Peaker> any way to see that?
05:40:01 <Heffalump> @src (>>=)
05:40:01 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
05:40:11 <Heffalump> @src (return :: a -> Identity a)
05:40:11 <lambdabot> Source not found. Maybe you made a typo?
05:40:19 <Heffalump> guess not :-(
05:40:28 <allbery_b> @src Identity (>>=)
05:40:28 <lambdabot> m >>= k  = k (runIdentity m)
05:40:43 <Heffalump> oh :-)
05:42:41 <Peaker> is runIdentity a function or a data constructor?  I read the above src of identity as though Identity is the data constructor
05:42:55 <Heffalump> Identity is the constructor, runIdentity is the field selector
05:43:00 <Heffalump> it can be used as a function
05:43:11 <mauke> it starts with a lowercase letter, so not a constructor
05:43:22 <Heffalump> but it can also be used for record update - though for a single constructor, single argument datatype that's not particularly useful.
05:44:16 <Peaker> so (runIdentity m)  extracts the data from an Identity value.  so the above could be written as:   (Identity x) >>= k = k x ?
05:45:57 <luqui> Peaker, yes
05:46:01 <Peaker> luqui, thanks
05:48:05 <Peaker> Is the "Identity" monad useful to use stuff that's written for monads on simple values?
05:49:10 <luqui> I've seldom used it
05:49:50 <xerox> Peaker: a cute use is to define your monad as transformer, and plug in Identity to get the actual base monad.
05:49:53 <luqui> because usually there is a pure alternative already written
05:50:15 <Peaker> luqui, yeah it sounds like doing what I suggested is backwards
05:50:33 <Peaker> xerox, so its primarily as a neutral value for monad transformers?
05:50:57 <luqui> and of educational value; it was the first, eh, monad I ever wrote
05:51:20 <luqui> without knowing it was in the libraries
05:53:53 <pjd> you could think of Identity as the functor/monad of 1-tuples
05:57:23 <Peaker> Where is callCC useful in Haskell? Is it a convenience thing, instead of just using the right-hand-side of a >>= expression twice?
06:01:21 <allbery_b> check the haskell-cafe mailing list archives; while callCC is rarely necessary because laziness handles most of its potential uses, CPS can be used as an optimization
06:01:40 <Peaker> CPS?
06:01:52 <allbery_b> continuation-passing style
06:02:17 <allbery_b> (the "pattern" of code that uses call-cc)
06:02:24 <Peaker> oh
06:08:19 <Baughn> > [1,2,3] ++ [last [1..]] -- This works..
06:08:23 <lambdabot>  Terminated
06:08:52 <Baughn> ..I said.... oh, never mind. Seems I've got a heisenbug.
06:09:45 <Baughn> > [1,2,3] ++ [last [1..]] -- Then again, I may just have forgotten to make it join
06:09:48 <lambdabot> Terminated
06:09:49 <Cheiron>  [1,2,3,Timeout
06:10:09 <Baughn> > nub $ cycle [1..3] -- But this fails. I think it just never catches the signal - any idea why?
06:10:14 <Cheiron>  [1,2,3
06:10:15 <lambdabot> Terminated
06:11:58 <Saizan> > take 3 $ nub $ cycle [1..3]
06:11:59 <lambdabot>  [1,2,3]
06:12:23 <Peaker> the compiler isn't smart enough to see that everything will be filtered out?
06:12:45 <Baughn> Nope
06:15:29 <haraldk> They said python's itertools would let me do lazy programming just like haskell
06:15:35 <haraldk> so I tried this:
06:15:47 <haraldk> l[0:20] = itertools.repeat(None)
06:16:19 <Peaker> haraldk, itertools.islice(itertools.repeat(None), 20)
06:16:42 <haraldk> thanks for the tip, Peaker :-)
06:17:03 <haraldk> I did manage to kill it eventually
06:18:12 <pjd> haraldk: Haskell would do the same given that, of course
06:18:29 <haraldk> what would be the eqiv. haskell?
06:18:35 <Saizan> "just like Haskell" is an overstatement, they are limited to lists, and can you have circular definitions?
06:18:59 <Saizan> haraldk: let l = repeat () in take 20 l
06:19:14 <Saizan> or just take 20 (repeat ())
06:20:18 <pjd> haraldk: something like repeat Nothing ++ (drop 20 l)
06:20:26 <haraldk> Saizan: but those work
06:20:46 <haraldk> ah, the former two I mean
06:21:08 <pjd> haraldk: you'd end up with an infinite list of the repeated element, in other words
06:23:17 <pjd> haraldk: if the Python l is a plain list, it corresponds to ++ being strict
06:24:37 <pjd> there are various lazy list implementations for Python, though, that would give behavior more like the Haskell
06:29:51 <Peaker> When designing a mainloop for a game or such in Haskell, I am confronted with the question of how to have "inner" actions "decide" things that have global effects, such as an inner-event handler who decides to "quit" the mainloop - how is it most elegant to send this decision to the main loop?  An IORef state can be passed down to all actions (yuck?), or everyone can return these global decisions (awkward), any other choice?
06:31:57 <Peaker> or a Monad can be layered on top of IO with a Transformer to allow this extra state to be implicit...
06:32:06 <Heffalump> Peaker: that's what I was about to suggest.
06:32:24 <Peaker> but that just "hides" these global effects, not sure that's a good idea
06:32:53 <Saizan> but they are made explicit and limited by the type
06:33:02 <Peaker> passing down an IORef does explicitly pass down the "authority" to exit the program, in an obj-cap sense, which has some appeal
06:33:23 <Heffalump> the same could be said of the monad transformer
06:33:23 <bd_> you could also use ContT
06:33:31 <Peaker> bd_, what's that?
06:33:36 <Heffalump> things with the relevant type have the authority, things without don't
06:33:39 <bd_> It adds continuations - callCC
06:33:50 <Heffalump> by calling something with that type, you grant the authority
06:33:51 <bd_> the idea being you do: mainloop = callCC $ \exitMainLoop -> ...
06:34:13 <bd_> when you want to exit, call exitMainLoop () in the monad, and it'll skip right out of mainloop
06:34:32 <Heffalump> continuations are very cool, but confusing until you get your head round them (which I haven't)
06:35:01 <Peaker> I have just read about Monad Transformers now, and it seems that explicitly lift'ing N levels for the monad I want is a bit ad-hoc/kludgy, isn't it?
06:35:18 <Heffalump> yeah, sadly.
06:35:23 <Heffalump> But you can also have class-based lifting.
06:35:25 <astrolabe> Is there a way of moving the quit decision to the outside of the loop?
06:35:28 <Peaker> Heffalump, how?
06:35:33 <Heffalump> e.g. liftIO always finds the IO monad
06:35:37 <Heffalump> cos of the MonadIO instances
06:35:44 <bd_> Peaker: If you have a StateT SomeState (ReaderT SomeContext IO)
06:35:56 <bd_> you can just use  'ask' without needing to lift
06:35:59 <Peaker> bd_, calling exitMainloop would run stuff after the main loop, but wouldn't it do that in addition to continuing the run inside the main loop?
06:36:01 <Heffalump> but that gets a bit messy when you have the same monad repeatedly inside the stack
06:36:18 <bd_> Peaker: nope, it'll skip right out
06:36:26 <bd_> Heffalump: yeah, this is where newtype encapsulation is nice
06:36:27 <Peaker> Heffalump, bd_ : How does the lift-by-type thing work?
06:36:42 <Heffalump> Peaker: by having instances like MonadIO m => MonadIO (StateT s m)
06:37:29 <Heffalump> so the MonadIO IO instance actually implements liftIO
06:37:34 <Heffalump> and the other ones just pass it up
06:37:42 <Heffalump> it's very clean with IO, cos that can't be a transformer
06:37:53 <Peaker> oh, so its not that IO's automatically lift, but liftIO "finds" the IO monad?
06:37:58 <Heffalump> right.
06:38:16 <Peaker> what about using "ask" without needing to lift, how does that work?
06:38:22 <Heffalump> same thing
06:38:27 <Spark> how efficient is the fib = 1:1:(zip (+) fib (last fib)) execution
06:38:27 <Heffalump> ask is in a class MonadReader
06:38:28 <bd_> There's a similar MonadReader env instance
06:38:39 <Heffalump> instance MonadReader (ReaderT ..) implements ask
06:38:42 <Heffalump> the other instances push it up
06:38:48 <bd_> like this: instance MonadReader env b => MonadReader env (StateT s b) where ask = lift ask
06:38:54 <mauke> Spark: zipWith, tail
06:38:55 <bd_> etc
06:39:11 <Spark> mauke: not what i asked :)
06:39:20 <Spark> is it the same as the iterative approach
06:39:21 <Heffalump> the problem being that you can't write MonadReader env b => MonadReader env (ReaderT env' b)
06:39:25 <mauke> Spark: finding the n'th element takes O(n) time
06:39:33 <Peaker> oh. I hope all this doesn't mean that I have a lot of boilerplate in my code (need to create a blahT for each blahM, and then a newtype for lifting, and then funcs that work on this new type?)
06:39:35 <Spark> and you'd do that with fib !! n
06:39:41 <mauke> right
06:39:49 <Spark> what about memory?
06:39:56 <Spark> does it use constant memory as it executes
06:39:59 <Heffalump> Peaker: well, you can use the standard ones.
06:40:09 <mauke> depends on how you use it
06:40:13 <Peaker> Heffalump, well, I need to use this once or twice so it all settles in my head :)
06:40:14 <Spark> fib !! n
06:40:16 <Heffalump> Or you can use newtypes of your own which require the boilerplate, but help reduce the ambiguity.
06:40:30 <mauke> if you make it a global var, it will probably be kept around
06:40:38 <Peaker> Heffalump, my practical Haskell experience consists of ghci toy examples and writing a little SDL mainloop
06:40:45 <Peaker> Heffalump, (and a lot of reading)
06:41:38 <Heffalump> Peaker: sure. You have to play with this stuff to get familiar with it.
06:41:45 <Heffalump> we're just laying out the summary :-)
06:45:38 <Spark> right so the "keeping around" is the memoisation
06:45:40 <Spark> if you like
06:45:46 <Spark> without that, it can't be O(n)
06:45:53 <Spark> time, for fib !! n
06:45:57 <mauke> sure it can
06:46:24 <Spark> ah yes i'm on crack
06:46:27 <mauke> you allocate a new fib for each request and fuse !! with zip
06:47:04 <Spark> it's kept around for the duration of the !! though
06:47:07 <Spark> then it can be destroyed again?
06:47:19 <Spark> it builds the list all the way to n, right?
06:47:35 <Saizan> if it fuses the list never exist
06:47:36 <bd_> Has anyone checked -ddump-stg to see what ghc actually does for that? I don't know how to read it :/
06:48:20 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in map fib [1..20]
06:48:22 <lambdabot>  [1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946]
06:48:30 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in map fib [0..20]
06:48:30 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946]
06:49:09 <Spark> dolio: that's the traditional method, right?
06:49:20 <bd_> Heffalump: wrt newtypes, they don't need much boilerplate. newtype it to death :)
06:49:22 <Spark> that exploits tail call optimisation to stop a state explosion
06:50:18 <dolio> More or less. You can think of it as a deforested version of 'fib n = let fibs = ... in fibs !! n'.
06:50:59 <Spark> so they are executed equivalently?
06:51:06 <dolio> > let fib n = fix ((1:) . scanl (+) 1) !! n in map fib [0..20]
06:51:07 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946]
06:52:27 <dolio> Well, I don't know if they get compiled to the same thing, but they're roughly equivalent.
06:53:12 <Spark> what's the precedence of . there
06:53:27 <dolio> (1:) . (scanl (+) 1)
06:53:39 <Spark> ah right
06:53:55 <Saizan> however in both cases we need help from the strictness analyzer or strictness annotations to avoid building a big lazy (+) tree, right?
06:54:39 <dolio> Oh, well, that may be true.
06:54:50 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in map fib 1000
06:54:50 <lambdabot>   add an instance declaration for (Num [a])
06:54:55 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in fib 1000
06:54:56 <lambdabot>  7033036771142281582183525487718354977018126983635873274260490508715453711819...
06:54:58 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in fib 10000
06:54:59 <lambdabot>  5443837311356528133873426099375038013538918455469596702624771584120858286562...
06:55:02 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in fib 1000000
06:55:08 <lambdabot> Terminated
06:55:54 <dolio> I guess lambdabot compiles with -O2, so it probably catches that.
06:56:06 <Saizan> yes, it does
06:56:24 <Japsu> @help dice
06:56:24 <lambdabot> dice <expr>. Throw random dice. <expr> is of the form 3d6+2.
06:57:03 <haraldk> > dice 1d7
06:57:03 <jekor> Can someone please help sort me out wrt MVars? http://hpaste.org/6540#a1
06:57:03 <lambdabot>   Not in scope: `d7'
06:57:07 <haraldk> > dice "1d7"
06:57:08 <lambdabot>   Not in scope: `dice'
06:57:09 <dolio> The one with fix is slower, though, it seems, so it obviously isn't getting optimized into as nice a loop.
06:57:15 <Saizan> @dice 1d7
06:57:15 <lambdabot> 1d7 => 5
06:57:57 <mauke> jekor: missing initial value
06:58:26 <dolio> > let fib n = fix ((1:) . scanl (+) 1) !! n in fib 100000
06:58:28 <lambdabot> Terminated
06:58:31 <Saizan> ?type newMVar
06:58:32 <lambdabot> Not in scope: `newMVar'
06:58:36 <dolio> > let fib' (m,_) 0 = m ; fib' (m,n) k = fib' (n,m+n) (pred k) ; fib = fib' (1,1) in fib 100000
06:58:38 <lambdabot>  4202692702995154386319005101293915131773915702632234503304716087198335731457...
06:59:14 <mauke> :t Control.Concurrent.MVar.newMVar
06:59:15 <lambdabot> forall a. a -> IO (GHC.IOBase.MVar a)
06:59:19 <jekor> mauke: Thanks. I just realized that I should have looked up newMVar. I was looking at the concurrency paper which has a different type signature!
06:59:32 <mauke> :t Control.Concurrent.MVar.newEmptyMVar
06:59:33 <lambdabot> forall a. IO (GHC.IOBase.MVar a)
06:59:37 <dolio> > let fib n = fix ((1:) . (1:) . ap (zipWith (+)) tail) !! n in fib 100000
06:59:39 <lambdabot> Terminated
06:59:50 <jekor> Works with newEmptyMVar.
07:00:38 <mauke> hah, newMVar is just newEmptyMVar + putMVar
07:00:51 <jekor> :)
07:01:22 <jekor> It compiles, but I still don't have the synchronization right on this.
07:01:44 <mauke> do you know about do-notation?
07:02:25 <jekor> Yes. But I was following the "do notation considered harmful" article :)
07:02:37 <jekor> At least until I understand monads better.
07:04:37 <jekor> redo (passThru (return stdin) o) >> putMVar wait ()
07:04:58 <EvilTerran> ?redo passThru (return stdin) o >> putMVar wait ()
07:04:58 <lambdabot> do { passThru (return stdin) o; putMVar wait ()}
07:05:08 <EvilTerran> yeah, that one's not very interesting ;)
07:05:39 <mauke> @redo newEmptyMVar >>= \wait -> forkIO ((passThru (return stdin) o) >> putMVar wait ()) >> passThru i (return stdout) >> takeMVar wait
07:05:39 <lambdabot> do { wait <- newEmptyMVar; do { forkIO (do { (passThru (return stdin) o); putMVar wait ()}); passThru i (return stdout)}; takeMVar wait}
07:05:47 <jekor> Was testing first :)
07:06:07 <mauke> why did it add another do block in the middle?
07:06:20 <EvilTerran> because it's chronically silly
07:06:22 <jekor> heh
07:06:40 <EvilTerran> i think it's because of the associativity of >>
07:06:45 <EvilTerran> ?redo a >> (b >> c)
07:06:45 <lambdabot> do { a; (do { b; c})}
07:06:51 <EvilTerran> ?redo (a >> b) >> c
07:06:51 <lambdabot> do { (do { a; b}); c}
07:07:04 <EvilTerran> well, kinda
07:07:07 <EvilTerran> ?redo a >> b >> c
07:07:08 <lambdabot> do { do { a; b}; c}
07:07:28 <EvilTerran> that could do with some optimising
07:08:11 <dolio> A separate do block for the stuff in the forkIO call is 'legitimate'.
07:08:19 <dolio> Though it doesn't look any better.
07:08:54 <dolio> Oh, wait, I'm looking in the wrong spot.
07:10:15 <anandrd_> I am trying to use runProcess and runCommand, but when I run my code, I get a whole bunch of <defunct> processes.
07:10:30 <anandrd_> processes that should have stopped
07:10:46 <mauke> they're dead
07:11:13 <mauke> did you call waitForProcess?
07:11:17 <anandrd_> no
07:11:44 <gbacon> why do I have to wait if I want the result RIGHT NOW?!
07:12:08 <anandrd_> my processes are external scripts that print to stdout and return.
07:12:29 <anandrd_> I retrieve the stdout (through runInteractiveProcess)
07:12:41 <anandrd_> however, the processes don't die. they become <defunct>
07:12:51 <mauke> er, that means they're dead
07:13:33 <Peaker> I am kind of disappointed by http://www.haskell.org/haskellwiki/Sudoku -- almost all these solutions are bigger compared with an efficient Python one I wrote a while ago
07:13:34 <lambdabot> Title: Sudoku - HaskellWiki
07:14:25 <mauke> anandrd_: after a process exits, its PID isn't freed immediately
07:14:44 <anandrd_> ok
07:14:51 <mauke> it still occupies an entry in the process table, storing the exit status of the process
07:14:55 <Peaker> for reference: http://rafb.net/p/ZVRZP835.html
07:14:56 <lambdabot> Title: Nopaste - Python soduko solver
07:15:15 <mauke> the parent process needs to call waitForProcess to retrieve the status/free the slot
07:15:24 <Spark> prolog is clearly the language for suduko solvers
07:15:41 <anandrd_> ok.
07:15:43 <jekor> OK, I'm doing something wrong. I get no errors, but one of the files isn't copied correctly. http://hpaste.org/6540#a2 (sorry for the totally random example)
07:15:43 <mauke> or the parent process could just exit
07:16:03 <anandrd_> but the parent process is my haskell program
07:16:11 <anandrd_> which is not supposed to exit
07:16:26 <Peaker> Spark, why isn't there a Prolog layered on top of Haskell then? :)  Prolog does not specify an exact algorithm, just what to search for, too - so its complexity varies
07:16:36 <jekor> I suspect I'm misinterpreting how hGetContents works.
07:16:40 <mauke> yeah, then you either need to call waitForProcess or use the double-fork trick
07:16:54 <anandrd_> yeah, that's what I was thinking of -- forking
07:17:34 <Spark> Peaker: i thought it does specify an algorithm, at least for the basics
07:17:41 <Spark> you don't need anything complicated for suduko
07:18:39 <Spark> if you start parameterising it by the board size, maybe then...
07:18:52 <Peaker> Spark, for soduko, you want to try putting in the slots that have the least possibilities, it seems the simpler Haskell solvers don't do that
07:19:48 <Peaker> I was hoping Haskell solvers would be much shorter/nicer than the one I wrote - and I still believe there should be one (maybe undiscovered general purpose primitives make it possible? :)
07:21:38 <Spark> true
07:23:21 <Spark> it doesn't seem like it should be too hard, you can throw an exception to track back to the last place where there was a choice
07:23:32 <Spark> and if there are no more choices, this would propogate it
07:24:18 <Spark> that optimisation you speak of seems like it should manifest itself as just sorting a list at some point in the algorithm
07:24:24 <Peaker> Spark, no need to throw it upwards - in each solve call, it can try to fill any slot - instead of the naive "fill first empty slot" it should fill the one which has the fewest valid possibilities
07:24:32 <Peaker> Spark, indeed
07:24:49 <Spark> i mean if you have no choices, you want to backtrack
07:24:56 <Peaker> actually, not sort, just a min call
07:25:09 <Peaker> http://rafb.net/p/ZVRZP835.html  line 33
07:25:10 <lambdabot> Title: Nopaste - Python soduko solver
07:25:15 <Spark> you should back track to the last place where you had a choice, so that's where the exception is useful
07:25:43 <EvilTerran> ?where yhc
07:25:43 <lambdabot> http://www.cs.york.ac.uk/~ndm/yhc
07:26:02 <Peaker> Spark, you can just return an (empty) list of solutions rather than raise an exception, though
07:26:14 <Spark> but then you have to propogate it manually
07:26:50 <replica> has anyone ever gotten the HsOpenSSL bindings to work? i've had no luck with 4.1.0 from hackage or current darcs, it's completely hosed
07:26:56 <Peaker> Spark, solve already manually calls recursive solve's and handles its result
07:27:09 <replica> sorry, 0.4.1
07:47:19 <anandrd_> :q
07:59:15 <Peaker> does hSDL support font rendering?
08:01:52 <Peaker> ok, found SDL-ttf
08:04:51 <Peaker> @src fail Identity
08:04:51 <lambdabot> Source not found. Wrong!  You cheating scum!
08:04:57 <Peaker> @src (>>=) Identity
08:04:57 <lambdabot> Source not found. You untyped fool!
08:05:00 <Peaker> @src Identity fail
08:05:00 <lambdabot> Source not found. I've seen penguins that can type better than that.
08:05:20 <hallongrottan> haha
08:05:51 <Peaker> how come Identity is a monad but only has >>= but not return or fail?
08:06:10 <Twey> Eh
08:06:10 <dolio> @src Identity return
08:06:10 <lambdabot> Source not found. Where did you learn to type?
08:06:21 <dolio> return = Identity
08:06:54 <dolio> fail is the default, error.
08:07:24 <Peaker> oh, ok, thanks
08:17:43 <dbueno> I am able to crash my GHC-6.8.2-compiled program (as in EXC_BAD_INSTRUCTION) when I use unsafeFreeze, even if the array is never referenced, and even with optimisations turned on.
08:18:08 <dbueno> Should I try to boil down to reasonable size test case?
08:18:28 <Saizan> turned on?
08:18:37 * Heffalump would say you should, but is not certain.
08:18:55 <dbueno> Saizan: I mean with -O1 enabled.  I shouldn't have said "even".
08:19:34 <dbueno> I mentioned that because I thought maybe optimisations would remove an unused binding; however, I'm in the ST monad, so, presumably not (as there might be a side effect).
08:19:46 <Peaker> any standard thing like bracket for when finalizer code does not need the init result?
08:19:59 <Peaker> (other than: bracket init \_ -> fini $ do ...)
08:20:14 <dbueno> Peaker: the function const?
08:20:16 <Heffalump> if the array is the only output from the ST and is unused, I'd expect the entire ST to be removed
08:20:24 <Heffalump> or do you mean that you are freezing it inside ST?
08:20:47 <Peaker> dbueno, oh, thanks
08:20:47 <Heffalump> (and continuing to do stuff)
08:20:47 <dbueno> Heffalump: freezing it inside ST in order to read from it conveniently.
08:21:09 <Heffalump> dbueno: I'd still expect a dead code remover to be able to get rid of that.
08:21:15 <Heffalump> but I don't know what GHC's one does.
08:21:59 <dbueno> I'm unsafeFreezing an STArray into an Array.
08:22:27 <dancor> http://hpaste.org/6542   why do these threads with subprocess redirect hang
08:22:40 <dbueno> My program already uses a bunch of unsafeFreezing from STUArray -> UArray, but this is the first boxed  array I'm using.
08:26:58 <Peaker> Why does my blitSurface in http://hpaste.org/6543 not seem to do anything?
08:27:23 <Peaker> oh, nm, the argument order is reversed
08:27:39 <Peaker> I got a gruesome yellow Hello World rendered now :)
08:34:57 <Peaker> how do I get a surface's size in hSDL?
08:37:45 <Peaker> hmm, seems impossible..
08:38:02 <Lemmih> Peaker: How is it done from C?
08:39:32 <Peaker> Lemmih, maybe accessing struct members directly
08:40:18 <Peaker> Lemmih, can't see any API to do it
08:41:31 <Peaker> oh.. its all there, I wonder why googling didn't find any of it
08:42:53 <Peaker> I wish there was an editor feature showing me all functions available to deal with a type I have
08:43:16 <Peaker> (The "." opening a method list in OO editors thing)
08:44:48 <kpreid> hmm, hoogle could be the backend for that
08:47:27 <Peaker> easy way to check if Num is in range between two numbers?
08:47:39 <mauke> Peaker: impossible
08:47:53 <Peaker> (shorter than ((x > start) && (x < end))  )
08:48:13 <mauke> oh, you can assume Ord?
08:48:16 <Peaker> yeah
08:48:24 <Saizan> ?src Num
08:48:24 <lambdabot> class  (Eq a, Show a) => Num a  where
08:48:24 <lambdabot>     (+), (-), (*)           :: a -> a -> a
08:48:24 <lambdabot>     negate, abs, signum     :: a -> a
08:48:24 <lambdabot>     fromInteger             :: Integer -> a
08:48:45 <Peaker> for some reason I thought Nums were ord, but assuming Ord is ok
08:49:15 <kpreid> range a b x = a < x && x < b
08:49:23 <mauke> :t inRange
08:49:25 <lambdabot> forall a. (Ix a) => (a, a) -> a -> Bool
08:50:30 <kpreid> > let a <. x = \b -> a < x && x < b; (.<) = id in 1 <. 5 .< 10
08:50:30 <lambdabot>  True
08:50:35 <kpreid> > let a <. x = \b -> a < x && x < b; (.<) = id in 1 <. 20 .< 10
08:50:36 <lambdabot>  False
08:50:39 <kpreid> > let a <. x = \b -> a < x && x < b; (.<) = id in 1 <. 0 .< 10
08:50:40 <lambdabot>  False
08:50:49 <kpreid> Peaker: how's that? :)
08:53:06 <Peaker> kpreid, that's great, I used that (inclusive/exclusive though), thanks
08:53:29 <Peaker> used inRange from above, that is
08:53:40 <kpreid> one could consider it a horrible abuse of the language though
08:53:57 <Peaker> no no I meant I use: inRange x start end = (start <= x && x < end)
08:54:33 <mauke> > inRange ('a', 'k') 'j'
08:54:34 <lambdabot>  True
08:55:21 * EvilTerran thinks something could be done with Maybes
08:57:05 <Peaker> EvilTerran, for in-range checking?
08:57:18 <EvilTerran> for chaining comparisons together in general
08:58:11 <EvilTerran> have x .< y | x < y = Just y | otherwise = Nothing, say
08:58:25 <dancor> is it possible to allocate a tty to run subprocess on, so you could run like 'zsh -i'
08:58:41 <EvilTerran> Nothing .<. y = Nothing; Just x .<. y | x < y = Just y | otherwise = Nothing
08:59:03 <EvilTerran> Nothing <. y = False; Just x <. y = x < y
08:59:12 <Peaker> Lemmih, surfaceGetWidth and surfaceGetHeight seem to return garbage
08:59:21 <EvilTerran> then you could do "x .< y .<. z .<. p <. q" or whatever
08:59:27 <byorgey> EvilTerran: oh, cool
08:59:40 <EvilTerran> (with everything infixl)
08:59:59 <byorgey> kind of annoying to have to remember the different . forms though
09:00:05 <EvilTerran> probably swapping the names of <. and .< would look better
09:00:14 <byorgey> true
09:00:24 <EvilTerran> yeah. see, if we were in a language with no static checking... :P
09:00:49 * EvilTerran has experimented with something similar in perl, returning the RHS of a comparison if the comparison passes and null if it doesn't
09:00:57 <EvilTerran> and "0 but true" if it passes but the RHS is zero :P
09:01:15 <mauke> "0 but true" is hax
09:01:30 <mauke> why couldn't they just use "0.0" or something :/
09:01:50 <Peaker> 0 == 0.0 In Perl?
09:02:00 <mauke> yes
09:02:16 <mauke> in fact, 0 eq 0.0 :-)
09:02:23 <mauke> but "0" ne "0.0"
09:02:23 <EvilTerran> but 0, 0.0, and "0" are false, and "0.0" is true
09:02:49 <EvilTerran> indeed, any string other than "" and "0" are true
09:03:17 <EvilTerran> and converting a string to a number ignores trailing characters
09:03:17 <Peaker> I don't like perl :P
09:03:21 <EvilTerran> (with a warning)
09:03:36 <EvilTerran> so they special cased "0 but true" to not produce a warning
09:03:51 <snhmib> hello! i'm reading the paper on zippers but i don't really know the language it is in (OCaml), it says: type path = Top | Node of tree list * path * tree list;; is that: data Path a = Top | Nods [Tree a] (Path a) [Tree a]   in haskell??
09:04:34 <mauke> data Path = Top | Node [Tree] Path [Tree]
09:05:14 <Peaker> hmm, surfaceGetWidth/surfaceGetHeight on my correctly-rendering text surface return 176093659350 -- (happens to be 0x29000000d6) -- seems like an FFI/64-bit bug
09:05:22 <snhmib> ah yea.. i added the a myself :) thanks!
09:05:47 <skorpan> is there any function which takes an integer N and returns 0 if N < 0 and X if N > X?
09:05:49 <dancor> weird, that's a binary zipper holding no data in its leaves?
09:06:08 <mauke> max 0 . min x
09:06:13 <Peaker> is "hsc" an FFI thing that's compiled to an .hs file?
09:06:23 <skorpan> > (max 0 . min 7) 8
09:06:24 <lambdabot>  7
09:06:29 <skorpan> > (max 0 . min 7) -5
09:06:29 <lambdabot>   add an instance declaration for (Num (t -> t))
09:06:32 <snhmib> dancor: i have no idea -- it's right at the beginning :P
09:06:33 <mauke> Peaker: it's a hsc2hs source file
09:06:38 <skorpan> > (max 0 . min 7) (-5)
09:06:39 <lambdabot>  0
09:06:44 <EvilTerran> dancor, looks to me like the Trees have Paths on them, hard-coded instead of parameterised
09:06:46 <Peaker> mauke, any known bugs regarding 64-bit systems?
09:06:54 <mauke> Peaker: I don't know
09:07:11 <mauke> manual is at http://haskell.org/ghc/docs/latest/html/users_guide/hsc2hs.html
09:07:13 <lambdabot> Title: 11.3. Writing Haskell interfaces to C code: hsc2hs
09:07:15 <EvilTerran> (guessing here)
09:07:18 <Peaker> thanks
09:07:26 <snhmib> dancor: the trees hold a item though
09:08:06 <Peaker> @src peekByteOff
09:08:06 <lambdabot> Source not found. Sorry.
09:08:30 <mauke> http://haskell.org/ghc/docs/latest/html/libraries/base/Foreign-Storable.html
09:10:04 <ttt--> > max 0 $ min 7 $ 5
09:10:05 <lambdabot>  5
09:13:28 <ttt--> :t ($) ($) ($)
09:13:31 <lambdabot> forall a b. (a -> b) -> a -> b
09:13:48 <mauke> :t id id id
09:13:49 <lambdabot> forall a. a -> a
09:14:04 <ttt--> :t ($) 1 ($) ($)
09:14:05 <lambdabot> forall a b a1 b1 t. (Num (((a -> b) -> a -> b) -> ((a1 -> b1) -> a1 -> b1) -> t)) => t
09:14:09 <ttt--> :t ($) 1 ($) ($) ($)
09:14:10 <lambdabot> forall a b a1 b1 a2 b2 t. (Num (((a -> b) -> a -> b) -> ((a1 -> b1) -> a1 -> b1) -> ((a2 -> b2) -> a2 -> b2) -> t)) => t
09:14:36 <ttt--> :t ($) 1 ($) ($) ($) ($) ($) ($) ($)
09:14:37 <lambdabot> forall a b a1 b1 a2 b2 a3 b3 a4 b4 a5 b5 a6 b6 t. (Num (((a -> b) -> a -> b) -> ((a1 -> b1) -> a1 -> b1) -> ((a2 -> b2) -> a2 -> b2) -> ((a3 -> b3) -> a3 -> b3) -> ((a4 -> b4) -> a4 -> b4) -> ((a5 ->
09:14:37 <lambdabot>  b5) -> a5 -> b5) -> ((a6 -> b6) -> a6 -> b6) -> t)) => t
09:15:31 <byorgey> ttt--: ?
09:16:06 <dancor> anyone know of any binding to openpty
09:16:30 <Peaker> on x86-64, is ghc's Int 32-bit or 64-bit?
09:16:44 <lispy> Peaker: iirc, it's allowed to expand
09:16:56 <lispy> Peaker: So Ithink it is 64bit
09:17:12 <lispy> Prelude> maxBound :: Int
09:17:12 <lispy> 9223372036854775807
09:17:21 <Peaker> lispy, well, SDL_Surface is a struct with "int w,h", but the Foreign peek of those fields as "Int" yields a 64-bit value (with top 32-bit being garbage ofcourse)
09:17:22 <lispy> that's on an x86_64 machine
09:17:41 <Peaker> So "int" is not "Int" in x86-64, so the FFI is broken
09:17:44 <lispy> Peaker: there is Int32
09:17:55 <Peaker> Ah, will try to fix the hSDL wrapper
09:18:10 <roconnor> isn't int usually 32 bit for 64 bit processors?
09:18:13 <roconnor> in C
09:18:28 <roconnor> lispy: how abou CInt?
09:18:57 <dancor> > maxBound :: CInt
09:18:57 <lambdabot>   Not in scope: type constructor or class `CInt'
09:18:59 <Peaker> It could be nice to have a CInt that is platform-dependent, depending on the local C compiler's default configuration,  because hard-coding Int32 in a foreign wrapper for a C "int" sucks
09:19:01 <skorpan> Use `+RTS -Ksize' to increase it. <- where do i type that?
09:19:13 <Peaker> @hoogle CInt
09:19:13 <lambdabot> Foreign.C.Types.CInt :: data CInt
09:19:13 <lambdabot> Foreign.C.Types.CIntPtr :: data CIntPtr
09:19:13 <lambdabot> Foreign.C.Types.CIntMax :: data CIntMax
09:19:20 <Peaker> hehe, nice!
09:19:20 <skorpan> oh, i found out
09:19:37 <skorpan> it uses quite some memory :/
09:20:05 <mauke> > maxBound :: Foreign.C.Types.CInt
09:20:05 <lambdabot>      Not in scope: type constructor or class `Foreign.C.Types.CInt'
09:20:07 <Peaker> if I installed SDL from cabal, how do I modify it for my own compilation? It stores it as a tarball
09:20:15 <skorpan> i think i have some infinite loop in my code and i can't figure out where
09:20:20 <skorpan> i've been doing this for two hours straight
09:20:35 <dons> Peaker: use CInt !
09:21:07 <joricj> i'm using ubuntu/ghci6.6.1 and i get the error "Could not find module `Control.Monad.Writer'", that shouldnt happen ... no?
09:21:20 <allbery_b> mtl is unbundled
09:21:21 <mauke> joricj: sounds like you didn't get the extralibs
09:21:30 <allbery_b> libghc6-mtl-dev?
09:21:40 <dbueno> skorpan: There is an "infinite loops" section of this page: http://haskell.org/haskellwiki/Debugging which might help
09:21:41 <lambdabot> Title: Debugging - HaskellWiki
09:21:42 <Peaker> dons, Yep, figured that out now (its the SDL wrapper, not me). not sure how to edit a cabal-installed source of a package
09:21:44 <allbery_b> something like that
09:21:53 <lispy> roconnor: yeah, CInt is 32bits here
09:22:42 <Peaker> how do I edit/compile/install stuff that was downloaded into ~/.cabal/ so it plays nice with the cabal package system?
09:23:08 <joricj> oh it works now, thanks
09:23:19 <skorpan> i think i just found out where the infinite loop is...
09:23:24 <dancor> Peaker: i'm curious are you using ghc 6.8.2 (i couldn't get cabal-install to like me)
09:23:33 <Peaker> Could be nice if an auto-wrapper of structs was created to avoid such bugs in the future
09:23:47 <Peaker> dancor, nope, the 6.6 one in Gutsy Gibbon
09:23:47 <skorpan> through like four function calls
09:24:17 <skorpan> actually six function calls.
09:27:23 <lispy> Peaker: there are tools to do automated (or is it semi-automated) binding to C apis.  Maybe you could convince hSDL to use one
09:28:10 <skorpan> @pl \p -> validMove (fst p) pos (snd p) game
09:28:10 <lambdabot> flip (uncurry (flip validMove pos)) game
09:28:27 <EvilTerran> lispy, i think they're semi-automated, generally
09:28:35 <EvilTerran> if you're thinking of chs and c2hs
09:30:49 <Peaker> how do I convert a CInt into an Int?
09:31:13 <byorgey> Peaker: fromIntegral, perhaps?
09:31:15 <lispy> ?hoogle CInt -> Int
09:31:16 <lambdabot> No matches, try a more general search
09:31:22 <skorpan> > fromIntegral (CInt 5) :: int
09:31:22 <lambdabot>   Not in scope: data constructor `CInt'
09:31:24 <skorpan> :/
09:31:28 <skorpan> worth at ry
09:31:42 <EvilTerran> ?index CInt
09:31:42 <lambdabot> Foreign.C.Types, Foreign.C
09:31:54 <EvilTerran> > fromIntegral (Foreign.C.CInt 5) :: Int
09:31:54 <lambdabot>   Not in scope: data constructor `Foreign.C.CInt'
09:32:08 <EvilTerran> ?type fromIntegral :: Foreign.C.CInt -> Int
09:32:09 <lambdabot> Foreign.C.Types.CInt -> Int
09:32:15 <EvilTerran> ?type fromEnum :: Foreign.C.CInt -> Int
09:32:16 <lambdabot> Foreign.C.Types.CInt -> Int
09:32:42 <Peaker> yep, fromIntegral works, thanks
09:32:50 <Peaker> bug fixed. now how do I send patches?
09:34:02 <dcoutts_> @seen Cale
09:34:03 <lambdabot> Cale is in #haskell, #haskell-overflow and #ghc. I last heard Cale speak 8h 32m 13s ago.
09:34:57 <dcoutts_> @ask Cale is it possible to arrange for a locked/immutable page on the haskell wiki? I'll explain why I need it
09:34:58 <lambdabot> Consider it noted.
09:35:27 <dcoutts_> @tell Cale or at least why it seems like a good idea from my pov :-)
09:35:27 <lambdabot> Consider it noted.
09:35:47 <Peaker> @ask Lemmih You use Int in your .hsc files where CInt should be used. This causes a problem on x86-64 systems. Please use Foreign.C.Types.CInt instead.
09:35:47 <lambdabot> Consider it noted.
09:38:01 <olsner> you can't @ask non-questions! you @ask questions and @tell statements :P
09:39:46 <byorgey> maybe @ask makes it more polite when you are telling someone to do something.
09:41:52 <joricj> @src const
09:41:53 <lambdabot> const x _ = x
09:45:26 <jgrimes> how might one reduce the amount of memory used during linking?
09:45:57 <roconnor> @go 1 CAD in USD
09:45:58 <lambdabot> 1 Canadian dollar = 1.003915 U.S. dollars
09:46:07 <EvilTerran> @go 1 GBP in USD
09:46:08 <lambdabot> No Result Found.
09:46:14 <EvilTerran> huh
09:46:20 <resiak> it's not proper money
09:46:22 <EvilTerran> @go £1 in USD
09:46:22 <lambdabot> UK 1 = 2.0016 U.S. dollars
09:46:25 <Peaker> @hoogle (Num a) => Float -> a
09:46:25 <lambdabot> No matches, try a more general search
09:46:30 <Peaker> @hoogle Float -> a
09:46:30 <lambdabot> No matches, try a more general search
09:46:32 <EvilTerran> yay still >2 :D
09:46:42 <skorpan> @go 1 SEK in USD
09:46:42 <lambdabot> 1 Swedish krona = 0.166597 U.S. dollars
09:46:49 <skorpan> @go 1 USD in SEK
09:46:49 <lambdabot> 1 U.S. dollar = 6.00250905 Swedish kronor
09:46:57 <skorpan> the us dollar is going down the drain
09:47:12 <byte-> hola
09:47:13 <skorpan> i sense 1929 all over again
09:47:39 <Peaker> nice, I have a little bouncing "Hello World!" screen saver
09:47:52 <wli> skorpan: As does everyone else.
09:48:33 <skorpan> 1929 will cause 1939...
09:48:48 <skorpan> which in turn will probably cause 1984
09:49:17 <skorpan> i should really fix this bug now.
09:49:37 <wli> skorpan: One for #haskell-blah
09:49:55 <Peaker> now I need to sync to vblank so it looks nice...
09:59:47 <AndreWe> Hi, did anybody try xmonad? I'm trying to follow the "A taste of Haskell" video, but do not know how to start xmonad with Xnest.
10:00:17 <mauke> me neither, I run it as my primary WM
10:00:39 <Saizan> AndreWe: you can try on #xmonad
10:01:22 <AndreWe> Sorry, I will do that, didn't know it existed.
10:11:20 <sclv> Anyone have any experience using weak pointers in conjunction with STM?
10:11:26 <sclv> Are there any issues to worry about?
10:13:14 <sclv> I can't think of any reason weak pointers and STM wouldn't play well, but the question seems tricky and I'd hate to code a bunch before running into an obvious gotcha.
10:14:52 <jgrimes> How might one reduce the amount of memory used during linking?
10:15:41 <jgrimes> I am compiling happs and ld uses all of my ram and swap
10:22:29 <quicksilver> sclv: I can't think why.
10:22:46 <quicksilver> sclv: I don't think STM uses pointers in any particularly special way.
10:24:26 <sclv> Yeah -- the more I think about it, the less I'm worried. concurrency and garbage collection tricks together always feel a bit scary to me though.
10:25:57 <bd_> GHC uses a stop the world collector, so there shouldn't be anything particular worrying, I hope :)
10:26:24 <bd_> particularly*
10:37:33 <delYsid> Anyone played with HaXML and the MusicXML DTD yet?  DtdToHaskell fails with some kind of name clash I cant seem to resolve.
10:37:54 <delYsid> Are there other nice haskell extensions to deal with complex xml files?
10:38:34 <dons> there's hxt, and an xquery compiler for haskell
10:38:38 <dons> tagsoup also
10:38:43 <dons> look about on hackage.haskell.org
10:41:53 <snhmib> is there something like lefty, but then in haskell?
10:45:49 <byorgey> snhmib: what's lefty?
10:46:06 <dons> ?uptime
10:46:06 <lambdabot> uptime: 5d 9h 14m 22s, longest uptime: 1m 10d 23h 44m 29s
10:47:34 <snhmib> oh, it's a graphics editor that comes with graphviz
10:47:55 <snhmib> you can make litle scripts for it to edit stuff, but not in haskell :P
10:48:17 <byorgey> snhmib: oh, I see
10:48:20 <Cale> dcoutts_: You'll have to ask Ashley Yakeley
10:48:20 <lambdabot> Cale: You have 3 new messages. '/msg lambdabot @messages' to read them.
10:48:26 <dons> snhmib: like 'sed', but graphical?
10:48:31 <dcoutts_> Cale: oh right, ok thanks
10:48:32 <byorgey> I'm not aware of anything like that for Haskell, but it sounds like a cool project =)
10:48:40 <dons> morning dcoutts_
10:48:44 <dcoutts_> hia dons
10:48:52 <Cale> gbacon: yeah, sure
10:48:56 <dons> dcoutts_: i was looking at your readInt function in ByteString -- surprisingly subtle
10:49:02 <dcoutts_> dons: :-)
10:49:07 <dons> obvious variants, to me anyway, were all worse
10:49:11 <gbacon> Cale: on the way
10:49:15 <dcoutts_> dons: can you make a faster one?
10:49:18 <snhmib> well if you consider lists and mouseclicks and io to be regular expressions then yes :P
10:49:25 <dons> dcoutts_: i want to find the source to Clean's freadi function
10:49:36 <dons> that currently beats us on the sum-file shootout program
10:49:44 <dcoutts_> dons: well I'm glad there's nothing blindingly obvious that's faster :-)
10:49:46 <dons> but yeah, i suspect we can do better. not sure how yet though
10:50:02 <dons> dcoutts_: well, i'm surprised doing manual spec constr doesn't help :)
10:50:09 <dons> ghc's smarter than the average bear
10:50:13 <dcoutts_> heh
10:50:39 <dcoutts_> dons: btw, I think we should look again at doing a sumfile with directly lazy bytestring
10:50:47 <dons> oh, we do now.
10:50:52 <dcoutts_> I think we should be able to get it as fast as your strict bytestring version
10:50:58 <dons> ah right
10:51:12 <dons> the naive code is almost there, since ptr tagging landed
10:51:13 <dcoutts_> using spec constr to get complete unboxing
10:51:23 <dcoutts_> but the strict one unboxed completely
10:51:28 <dons> right
10:51:33 <dcoutts_> where the lazy one didn't with the old representation
10:51:38 <dons> http://shootout.alioth.debian.org/gp4/benchmark.php?test=sumcol&lang=ghc&id=6
10:51:40 <lambdabot> Title: sum-file Haskell GHC #6 program | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Comp ..., http://tinyurl.com/ys3ony
10:51:44 <dons> is quite similar to the clean program, now.
10:51:54 <dcoutts_> I think we should be able to get spec constr to do it for us
10:51:56 <dons> but about 2x slower
10:51:59 <dcoutts_> for the lazy bs
10:52:06 <dons> http://shootout.alioth.debian.org/gp4/benchmark.php?test=sumcol&lang=clean&id=0
10:52:07 <lambdabot> Title: sum-file Clean program | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Computer Lang ..., http://tinyurl.com/37h63e
10:52:30 <dcoutts_> the difficulty with the lazy bs sumfile is the Empty | Chunk distinction
10:52:39 <dcoutts_> that prevents unboxing of the Chunk constructor
10:52:40 <Peaker> If I want to build a "language", on top of Haskell, in which there are "computations", which are similar to functions in their use but do not compute the entire result, but instead they get differentials on their inputs, and output differentials about their output. How would I go about this?
10:52:43 <dcoutts_> unless...
10:53:06 <dcoutts_> unless specconstr can spot that we have a loop that passes a Chunk back in the common case and specialise on that
10:53:17 <dons> hmm
10:53:19 <dcoutts_> which it really ought
10:53:23 <dons> yes, that's what' it needs to do
10:53:28 <dcoutts_> it's a classic use case
10:53:29 <dons> the old magic fast sum-file did that manually
10:53:31 <gbacon> Cale: sent
10:54:05 <Peaker> Sort would be a computation that looks as though its input is a list, but actually its input is list-differentials (such as element-add, element-remove, and perhaps higher-level manipulations as well), and its output seems like a list but is actually (list-insert-at, list-delete-at, etc)
10:54:14 <Cale> gbacon: great, I have to wake up and get some breakfast, but I'll apply it after that :)
10:54:22 <gbacon> whee!
10:54:43 <bd_> Peaker: presumably your function would be something like mySort :: [ListMutator] -> [ListMutator] or something?
10:54:56 <bd_> your sort function would need to actually construct the list to sort it, of course
10:55:06 <Peaker> bd_, Yeah, something like that, I'm not sure yet
10:55:11 <bd_> unless you're just going to output a static sort program to execute in your target language
10:55:38 <Peaker> bd_, the idea is that differential handling would be more efficient than re-sorting the whole thing
10:56:03 <Peaker> bd_, and that you can use many such "differential primitives" to build "differential functions" as though they were normal functions
10:56:25 <Peaker> Ideally you wouldn't be aware of the fact its actually differential when you're building it, that its somehow hidden behind the types
10:56:44 <bd_> Peaker: well, the thing is, if you need to sort it, it'll need to inspect every element in the list. So you'll need to construct the list anyway
10:56:58 <bd_> Sure, you could write a sort function which emits a series of mutation operations though
10:57:03 <Peaker> bd_, Yeah, a differential-sort would have to hold the entire result, true.
10:57:19 <Peaker> bd_, but when it takes a differential it can output a differential in O(lg n)
10:57:21 <bd_> but I suspect that it wouldn't be helpful if it's all happening in-process
10:57:35 <bd_> eh? O(n lg n) surely
10:58:07 <Peaker> bd_, If a differential is a single element, knowing where to place it in the list takes just lg n (in-place updating its own list would be O(n) though, unless its doing something fancy)
10:58:40 <Peaker> actually, if it holds a binary search tree (e.g redblack) it can get an element-insertion and handle it in O(lgn) and output which index to do element-insertion at
10:58:42 <bd_> Peaker: oh, you mean taking a stream of elements and emitting operations placing them into sorted order?
10:58:46 <bd_> yeah
10:59:04 <Peaker> bd_, A differential function of inputs takes a "stream" of changes on those inputs and itself outputs a stream of changes, yes
10:59:14 <bd_> ahh now I see
10:59:30 <bd_> I'm not entirely sure how to generalize it well though
11:00:18 <Peaker> I want to build this  "Differential Computing" language  so that a user can connect differential components in a GUI and have updates in "source values" propagate efficiently through his created chain and animate nicely the result (animation without a heuristic diff of what happened)
11:01:22 <Peaker> (Consider an "inbox" (a message list), a user can connect it to a "Sorted" function, and connect the result of "Sorted" to a display widget. If a message is added in the box, the widget will get a diff event - making it easy for it to animate it
11:01:34 <bd_> You could have [(a -> a)], but that's hard to do any useful high-level operations on
11:01:48 <Peaker> yeah, I think I'm going to need to define some rich types
11:01:55 <bd_> eg, an operation "add after element 2" passed into a sort function, if it can't toss out the location info...
11:02:17 <Peaker> you a function is too opaque
11:02:21 <Peaker> s/you/yea
11:02:55 <Peaker> also, another more complicated feature this system should support is "Reversible computing". The user presses "Delete" in the Widget that's displaying the Sorted result
11:02:56 <bd_> [forall a. ListType a => (a -> a)] ? :D
11:03:25 <Peaker> The "Delete" should propagate back into the input, converted by the "Sorted" in the chain to a deletion on the right place in the input list
11:03:59 <Peaker> ListType a  is [a] ?
11:04:11 <byorgey> Peaker: now you're talking about the "view update problem" =)
11:04:36 <bos> @seen augustss
11:04:36 <lambdabot> augustss is in #haskell. I don't know when augustss last spoke.
11:04:39 <bd_> Peaker: ListType is any ListType
11:04:46 <bd_> the function has to generalize to all ListTypes
11:04:48 <byorgey> Peaker: see the recent work of e.g. B. Pierce et al on languages for bidirectional data transformation/update
11:04:49 <bd_> then the caller can pick one later
11:04:50 <Peaker> bd_, oh
11:04:53 <augustss> hey bos
11:05:06 <bos> hi augustss - did you get my message about the llvm repo missing a file?
11:05:16 <bd_> Peaker: these are called GADTs - Generalized Algebraic Data Types, I believe
11:05:18 <augustss> bos: yes, and I've added it
11:05:30 <bos> ok, thanks
11:05:50 <bos> got it.
11:06:49 <augustss> bos: maybe I'll even have time to fix the phi nodes soon
11:07:05 <bos> augustss: :-)
11:08:11 <Peaker> so its not clear how all this maps to Haskell?
11:14:03 <Baughn> Peaker: Haskell doesn't /directly/ support it, nope. I'd still claim that it should be easier to implement than in most other languages
11:16:56 <Baughn> Peaker: Actually, what with backpropagation and all, it seems to me that what you're trying to write is a logic programming language
11:16:59 <Peaker> Baughn, Maybe that's true - I wish someone more experienced in Haskell can short cut me through years of experimenting with Haskell in order to figure out how to do just that :)
11:17:14 <Peaker> Baughn, there's no "search" involved as in e.g Prolog
11:17:22 <Baughn> Peaker: No, so it's simpler
11:17:37 <Baughn> You could still learn something from the way prolog is implemented in haskell
11:18:02 <Peaker> I want to be able to "modify" source values and have their modifications propagate to those computations that depend on them - not sure how to represent that at all
11:18:16 <Peaker> I could learn a lot from reading any piece of Haskell source code at this point, indeed
11:18:47 <Heffalump> there's a lot online, surely?
11:19:01 <Heffalump> oh, I see what you mean.
11:19:20 <Heffalump> I initially thought you were saying you couldn't find any to read :-)
11:19:47 <Peaker> Baughn, in fact "back propagation" is just a way to say "write to a source value" just through a chain of computations
11:21:04 <Baughn> Peaker: Right. A systematic way.
11:23:56 <bd_> hmmm
11:24:03 * bd_ wonders if arrows are related somehow
11:24:50 <Heffalump> Peaker: have you seen the paper on arrows for reversible computation
11:24:53 <Heffalump> HW 05, IIRC
11:25:20 <Peaker> nope, where do I find papers frmo "HW 05"?
11:25:40 <Heffalump> HW = Haskell Workshop
11:25:43 <Heffalump> hangon, I'll find it
11:26:32 <Heffalump> http://www.st.cs.ru.nl/papers/2005/alia2005-biarrowsHaskellWorkshop.pdf
11:26:34 <lambdabot> http://tinyurl.com/36rlyl
11:28:39 <marshmallows> much nicer invertible language, Inv
11:28:40 <skorpan> could anyone help me solve this? http://hpaste.org/6545
11:28:59 <marshmallows> used in an editor for invertible XML tranformations
11:29:07 <marshmallows> (written in haskell ..)
11:29:22 <Heffalump> skorpan: that's an incorrect description of the laws of chess (IIRC)
11:29:27 <skorpan> Heffalump: really?
11:29:30 <skorpan> please, do tell me more
11:30:04 <marshmallows> skorpan: What do you actually want to compute?
11:30:05 <Heffalump> being in check means directly in the line of fire of another piece according to its normal movement rules, whether or not that move would be illegal for other reasons.
11:30:37 <skorpan> Heffalump: *really*? that helps me a lot!
11:30:41 <Heffalump> the logic is that you immediately lose the game if your king is captured
11:31:09 <Heffalump> so your opponent could in theory still win the game even if they themselves in check by doing so, so that bit doesn't matter.
11:31:15 <Heffalump> because they'd get your king before you got theirs.
11:31:18 <wli> What are we doing with chess here?
11:31:34 <Heffalump> wli: skorpan's paste asked for help with implementing it in Haskell.
11:31:49 <marshmallows> implementing what?
11:31:49 <Heffalump> well, I presume that was the idea, it didn't mention Haskell explicitly
11:31:50 <skorpan> yes, i'm writing a chess game in haskell and have been struggling with infinite loops for infinity.
11:32:14 <skorpan> marshmallows: currently refining movement rules.
11:33:02 <Heffalump> also, you don't need to worry about weird movement rules like castling and en passant, because none of them is relevant
11:33:03 <Igloo> The king can't move through a position that would put it in check when castling, either
11:33:07 <Heffalump> (from the point of view of check)
11:33:23 <skorpan> Heffalump: uhh, what? how are they not relevant?
11:33:26 <Heffalump> (and yes, what Igloo said)
11:33:27 <skorpan> oh, right, not in check
11:33:33 <wli> There are some nasties there.
11:33:35 <Heffalump> skorpan: they're not relevant to placing a piece in check.
11:33:50 <Philippa> they are relevant to blocking moves though
11:34:03 <Heffalump> Philippa: what are?
11:34:21 <marshmallows> skorpan: You probably write this in a generate and test way, given some peice on the board, you can list every square it goes to
11:34:42 <skorpan> marshmallows: yes
11:34:42 <marshmallows> skorpan: then you can remove from that list any move that is putting the peice ontop of one of the same color
11:34:44 <Philippa> Heffalump: things like the king not being able to move through a position that'd put it in check when castling
11:34:52 <marshmallows> skorpan: then you can remove from that list any move that put the king in check
11:34:56 <Heffalump> Philippa: right, yeah. But there's nothing else like that, AFAIK.
11:35:03 <marshmallows> skorpan: that should be fine for checking if a move is valid
11:36:21 <wli> You need three move repetition checking even where you don't need transpositions for efficiency, so you're stuck doing what's essentially a graph.
11:37:05 <Heffalump> repetition checking can be achieved by remembering all positions since the last piece capture or pawn move
11:37:13 <Heffalump> you also need a count of those positions for the 50-move rule
11:38:18 <wli> You also need to track whether kingside or queenside castling is still valid on account of having moved either kings or rooks, and (of course) en passant tracking.
11:38:35 <Heffalump> though en passant is nice as it's transient
11:38:58 <Igloo> en passant tracking doesn't actually need any tracking
11:39:12 <Heffalump> not long-term. You just need a flag for one move.
11:39:20 <Igloo> Oh, true
11:39:27 <wli> Yeah, the true nasties are the 50-move rule and three move repetition.
11:39:48 <wli> Three move repetition being the worst of the lot.
11:40:05 <Heffalump> how many bits does a reasonably naive encoding of a position need?
11:40:25 <marshmallows> log_2(8*8) ?
11:40:26 <Heffalump> no more than 6*32, anyway.
11:40:36 <Heffalump> I meant an entire board.
11:40:58 <Heffalump> well, 6*32 + a bit extra for castling and en passant state.
11:41:06 <wli> Heffalump: A fair amount. Positions are counted as different if e.g. en passant is possible in one and not another, or castling possible in one and not another, or if it's a different player's move.
11:41:27 <Heffalump> not much, anyway. You could just keep a map from positions to number of visits.
11:41:41 <Heffalump> Flush the map on every pawn move and piece capture.
11:41:52 <Heffalump> And that gives you a cheap way to do both three-fold repetition and 50-move rule.
11:42:13 <roconnor> What if a pawn turn into a new piece, and then the board is repeated?
11:42:19 <Heffalump> roconnor: it can't be.
11:42:31 <roconnor> oh, because the pawn is gone.
11:42:35 <Heffalump> indeed.
11:42:42 <wli> Heffalump: It sounds so simple until you try to use it for strategy, at which point drawn conclusions of the game show up in minimax and/or other strategies.
11:42:44 <Heffalump> promotion doesn't add to the count of pieces
11:42:50 <Heffalump> wli: sure.
11:42:57 <int-e> pawn promotions make the 6*32 number problematic though.
11:43:10 <wli> Heffalump: Now, worst of all, add in clocks. You now have a schedule to follow.
11:43:24 <Heffalump> wli: cool.
11:43:52 <Heffalump> int-e: yeah, ok. No more than 2 more bits per pawn, though (=32 more bits)
11:43:57 <roconnor> This complexity sounds like fun to program ...
11:44:01 <Heffalump> I think it can comfortably be done in 256 bits, anyway.
11:44:02 <roconnor> in a theorem prover :P
11:44:32 <marshmallows> Has anyone read Concepts, Techniques, and Models of Computer Programming?
11:44:38 <marshmallows> I'm wondering if I should get it..
11:45:05 <wli> Heffalump: I'm all ears as to how lazily unfolded move graphs can be incrementally computed in such a fashion as to stop the computation at particular points in time and then use what's been computed thus far for decision-making.
11:45:45 <Heffalump> wli: presumably some kind of CPS would help.
11:45:49 <Heffalump> but I'm just speculating.
11:46:03 <lament> wli: "take 10 moves" :)
11:46:03 <skorpan> thanks a LOT Heffalump this actually fixed the problem! i can't tell you how grateful i am
11:46:38 <wli> lament: Will not fly.
11:46:52 <bos> marshmallows: it's a brilliant book.
11:47:19 <marshmallows> thanks bos
11:47:31 <glguy> Your move graph could be lazy and pure, and your traversal function could be in IO and support time based aborting
11:47:47 <glguy> (not arguing that would provide maximal performance)
11:48:29 <wli> glguy: Sounds like a good start.
11:48:43 <Heffalump> how do you get partial results, though?
11:48:58 <Heffalump> that's the real challenge, structuring the computation in an appropriate way
11:49:35 <wli> You have to fail the "get next" operation in the event that it blows past the time limit.
11:50:02 <glguy> you have the traversal write it's current favorite to an IORef
11:50:04 <roconnor> presumably you can write an IO function to take as much of a list it can in a given amount of time.
11:50:10 <glguy> and have a timer kill the thread whhen it's done
11:50:41 <glguy> (a samplevar would probably be most appropriate over ioref)
11:50:51 <Heffalump> you also need to be able to reuse the work done for the next move
11:50:59 <wli> You even have to fail things like database lookups attempting to check 3-move repetition or even legality, but maybe that's not a big issue.
11:51:11 <Heffalump> perhaps a lazily evaluated game tree is all you need
11:51:17 <wli> Heffalump: And to discard things that have since become irrelevant.
11:51:24 <glguy> a lazily evaluation should get you part of the way there on computation reuse
11:51:30 <Heffalump> wli: sure, but GC will handle that
11:51:32 <glguy> (might blow your memory though)
11:51:44 <Heffalump> if you just move your state to be a subtree
11:52:21 <wli> Heffalump: It can't be a tree; it's a graph of positions with edges being moves and gameplay as path traversal.
11:52:24 <Heffalump> of course, getting sharing for sets of moves that could be done in any order is harder.
11:52:38 <Heffalump> it *can* be a tree, but you lose some useful sharing.
11:52:48 <Heffalump> do inductive graphs work?
11:53:27 <wli> Heffalump: Position sharing is absolutely required for 3-move repetition, or you can't even do legality checking. Without sharing the game can be forced to be over and your engine has no idea.
11:53:56 <Heffalump> wli: you can put the history in the state at each node
11:54:25 <wli> Heffalump: Each node of what? There's more than one data structure here.
11:54:41 <Heffalump> I am considering a game tree, where the nodes are positions and the moves are edges.
11:55:25 <Heffalump> the nodes can also include the bag of board history up to the last pawn move or piece capture
11:55:44 <Heffalump> that's all you need to evaluate all the laws
11:57:01 <wli> I'm pretty sure game trees fall down at the very least in terms of code complexity. Checking legality from that sounds awkward at best.
11:57:52 <Peaker> can anyone give me feedback about how to beautify my first Haskell program: http://hpaste.org/6546 ?
11:58:10 <Heffalump> I described how to check legality a bit earlier. Just count.
11:58:28 <bd_> wli: whenM exists in Control.Monad as when
11:58:31 <bd_> :t Control.Monad.when
11:58:34 <lambdabot> forall (m :: * -> *). (Monad m) => Bool -> m () -> m ()
11:58:41 <Peaker> bd_, thanks
11:58:43 <Heffalump> I don't think they fall down in complexity, but they might well do so in efficiency.
11:58:44 <bd_> oh, not quite
11:58:54 <bd_> you take a monad argument, nevermind
11:59:12 <bd_> s/wli/Peaker/ above too
11:59:32 <Peaker> yeah its not the same, I now tried :)
11:59:57 <Peaker> did you run this silly program? :)
12:00:06 <bd_> nah, I'm actually theoretically busy atm XD
12:00:17 <Peaker> ;-)
12:00:28 <bd_> :t (>>= when)
12:00:29 <lambdabot> forall (m :: * -> *). (Monad m) => (m () -> Bool) -> m () -> m ()
12:00:33 <bd_> :t join . (>>= when)
12:00:34 <lambdabot>     Occurs check: cannot construct the infinite type: m = (->) (m ())
12:00:34 <lambdabot>     Probable cause: `>>=' is applied to too many arguments
12:00:34 <lambdabot>     In the second argument of `(.)', namely `(>>= when)'
12:01:13 <bd_> @pl \m a -> m >>= \r -> when r a
12:01:13 <lambdabot> (. flip when) . (>>=)
12:01:44 <lament> kinda sad that this entire program does not contain a single pure function :)
12:01:55 <Peaker> lament, :-)
12:02:09 <Peaker> lament, It is my first Haskell program :-)
12:02:19 <Peaker> My first Python programs were actually C :)
12:02:31 <bd_> lament: Sure it does, instantiate whenM in Identity
12:02:36 <bd_> or Reader
12:02:41 <sclv> what's the purpose of using the index functions of Data.Map?
12:02:57 <mauke> :t Data.Map.index
12:02:58 <lambdabot> Not in scope: `Data.Map.index'
12:03:35 <Heffalump> most monads are pure
12:03:39 <sclv> they're all log(n) time, right? which is what you get if you just operate on keys directly?
12:03:58 <sclv> I suppose if key comparison is expensive...
12:04:00 <lament> Peaker: you could calculate position and speed as a function of time and put them in an infinite list. That would be a pure function. Then you don't need to keep them in iorefs
12:04:13 <Peaker> lament, good idea, thanks
12:04:20 <bd_> sclv: To find the index of a key otherwise you'd have to turn it into a list and count
12:04:34 <bd_> which is O(n)
12:04:36 <sclv> right... but what's the purpose of getting an index?
12:04:39 <lament> Peaker: i meant you could calculate them as a function of the previous value
12:04:57 <Peaker> well, mutually-recursively, yes
12:05:15 <sclv> since all you can do with it is the same stuff you can do with the key directly...
12:05:15 <bd_> sclv: Well, if you need to treat the map as an indexable array that just happens to be kept sorted...
12:05:23 <bd_> sclv: ah, no, it's not the key, it the /index/
12:05:28 <bd_> ie, 0 is the lowest key
12:05:51 <bd_> So if you have key "foo", this way you can easily query to find it it's, say, the 30th smallest key
12:06:09 <sclv> oh, ok... that makes sense -- it provides order information.
12:06:42 <sclv> that wasn't apparent from the documentation.
12:07:00 <bd_> submit a doc patch? :)
12:23:21 <Peaker> is it considered good style to use: x <- return [expression]   in a do block, instead of "let" which adds annoying nest levels?
12:23:42 <skorpan> i would frown upon it, but on the other hand, i'm no haskell wiz
12:23:50 <resiak> it doesn't add nest levels
12:24:04 <byorgey> Peaker: in a do-block, you don't need to do  let foo = blah in ...
12:24:05 <resiak> do { foo; bar; let x = expression; baz }
12:24:21 <Peaker> oh, thanks
12:24:22 <byorgey> you can do what resiak showed
12:24:24 <marshmallows> Peaker: let does not add nesting levels ni a do block
12:24:38 <daf> do/let is not non-do/let
12:25:38 <mauke> x <- return ... is useful if x is not a simple variable :-)
12:25:38 <Peaker> daf, is do/let blah=V   like   blah<-return V  ?
12:26:00 <Peaker> can't pat-match in a let?
12:26:06 <mauke> do { let p = e; X } === let p = e in do { X }
12:26:07 <smg> http://de.youtube.com/watch?v=xaoLbKWMwoU <-- haha :)
12:26:07 <lambdabot> Title: YouTube - Haskell music 2
12:27:35 <Peaker> I hate emacs's haskell-mode auto-indent
12:27:52 <smg> no one likes emacs
12:28:20 <skorpan> i like emacs
12:28:26 <smg> :]
12:28:54 <wli> skorpan: Are you familiar with chess problems?
12:29:00 <wagle_home> sometimes (?) you can convince the emacs haskell mode to cycle through possible tab points by repeatedly hitting tab
12:29:04 <skorpan> wli: no, i suck at chess
12:29:38 <Peaker> I currently have: "whileM (liftM not $ (readIORef stop))" and I want to instead have a similar while-loop but that iterates an infinite position list, what would be a good way to combine the conditional with such iteration?
12:29:43 <wli> skorpan: It's where a chess position is printed in a newspaper, and they say "white to move, checkmate in 3 moves."
12:30:18 <skorpan> wli: yeah?
12:31:04 <wli> skorpan: Your task is to basically come up with a move and responses to everything black could do so that checkmate happens in 3 moves no matter what (basically a game tree showing that white can force checkmate in that number of moves).
12:31:35 <wli> skorpan: There are no time limits or anything nasty like that on chess problems, so you could do a lot of work for chess problem solving vs. chess playing.
12:32:03 <Heffalump> mate in 3 must be trivially solvable by a reasonable computer program though
12:32:08 <Heffalump> good test case, I guess.
12:32:46 <Peaker> I suppose those newspapers use a computer program, as to not miss stuff
12:33:08 <wli> Heffalump: It's good to get an engine started. The horrendous issues raised by the clocks and time limits and heuristic search strategies can be put off until the plain old chess problem solving is done.
12:33:41 <wli> Heffalump: There are also chess problems like helpmate (both players cooperate to achieve checkmate in a certain number of moves) and so on.
12:34:13 <Heffalump> that doesn't sound like much of a problem
12:34:46 <Heffalump> IM, with two bishops + king vs king it might be tricky to do quickly, but it seems rather contrived and silly.
12:35:05 <wli> Heffalump: It's the same sort of issue as the rest of the chess problems. It can be awkward enough to make checkmate happen that even with cooperation it takes some search.
12:35:40 <Heffalump> sure
12:36:26 <wli> Heffalump: Minimax as for the usual mate-in-three problems is as useless for real gameplay as the helpmate search strategies, so these are all nothing but legality checker exercises as they apply to a real chess program anyway.
12:37:34 <Peaker> minimax is good when you're searching an entire tree. When you have to search partial trees, iteratively deepening is better
12:37:35 <wli> s/legality checker/move generation/ if you want.
12:37:35 <Heffalump> true. Though mate-in-three isn't really minimax except in the 0-1 sense.
12:37:50 <Peaker> Heffalump, why isn't it minimax?
12:38:10 <Peaker> Heffalump, set with a depth of 3, lose,tie,win possible results
12:38:30 <Heffalump> and "no result"
12:38:40 <wli> Heffalump: Well, you can also declare white's strategy a failure if it fails to achieve checkmate in 3 moves.
12:38:48 <Heffalump> but all you actually care about is checkmate and no-checkmate.
12:39:05 <Heffalump> at some level its minimax, but it's a pretty degenerate case of it
12:39:17 <Peaker> Heffalump, that's a "tie", not "no result"
12:39:27 <Heffalump> well, then there's "draw".
12:39:56 <wli> For chess problems, if you arrive at the move limit without checkmate it's a failure.
12:40:02 <Peaker> you could define a draw as a loss for white, so its just "win"/"lose", and you negate the value as it propagates back in the recursion
12:40:04 <Heffalump> right
12:40:13 <wli> So it's even easier than that.
12:40:38 <Peaker> have you guys implemented iteratively deepening game searches?
12:41:06 <Heffalump> I can't remember. Probably not. Isn't it just breadth-first search?
12:41:31 <Peaker> nope, its a DFS search to depth 0, and then to depth 1, up to depth N
12:41:37 <Peaker> (restarting the search each time)
12:41:49 <wli> Heffalump: It's basically alternating breadth-first and a depth-limited depth-first search.
12:41:52 <Heffalump> oh, why wouldn't you reuse the partial results?
12:41:53 <Peaker> the idea is to use the previous search results to know which subtrees to search
12:42:04 <Heffalump> ah, I see
12:42:20 <Heffalump> what criteria do you use to rule out subtrees?
12:42:23 <Peaker> The previous search (to depth N-1) is of negligible time compared to depth N, so you can even throw its partial results away
12:42:49 <wli> Heffalump: So you queue tree nodes to search, and upon dequeueing, do depth-first search to some depth limit and enqueue the deepest results found there.
12:43:30 <Peaker> well, you can think of it as a generalization of a normal board-evaluation heuristic.  Instead of a heuristic that looks at the board now and determines which moves are best to try, you have a heuristic that scans to N-1 to know which moves to try. And for the N-1 one, you have one that does so to N-2. Its sort of a meta-recursion
12:44:04 <Heffalump> ah, so you prune based on a heuristic
12:44:17 <Peaker> yeah, but the heuristic also recurses
12:44:37 <Peaker> and to make that recursion better focused, an even smaller recursion is used to prune for that, and so on
12:44:38 <Heffalump> but when you scan to N-1, presumably you just value the position?
12:45:12 <Peaker> the result of scan to N-1 will tell you which branches are worth scanning to depth N (which is a lot bigger than depth N-1)
12:45:22 <Heffalump> sure.
12:45:30 <Heffalump> it sounds like breadth-first search with pruning to me.
12:46:11 <Peaker> You can scan the entire sub-tree to depth 0, almost the entire tree to depth 1, less so to depth 2, and narrow/lengthen the scan as you progress
12:47:18 <Heffalump> proper chess engines do selective deepening too, right? Things like going a bit deeper for more "interesting" lines, and for positions which aren't "stable".
12:47:49 <Eulex> is there any good debugger for haskell? providing stuff like (partial) stack traces, stepping through instructions etc
12:48:18 <Peaker> Heffalump, that is a natural result of iteratively deepening, but maybe they go to a dynamic depth in each single DFS scan too, I don't know
12:49:54 <Heffalump> Peaker: the positions that you don't go deeper on are still considered as candidates, though
12:50:45 <Peaker> Heffalump, only if the board evaluation at the bottom of their DFS decided they are worthwhile
12:54:04 <sclv> Eulex: modern ghcis come with a debugger built in.
12:55:02 <Peaker> ok, I converted the size/position computation to be a pure infinite list, mutually recursive: http://hpaste.org/6547
12:55:08 <Peaker> Now its become really really really slow
12:55:16 <Peaker> (initially fast, then very quickly very slow)
12:55:44 <bd_> Peaker: +RTS -Sstderr should tell you if it's using too much memory
12:56:16 <bd_> oh, I see
12:56:31 <bd_> Peaker: pos and speed are referenced from the top level, so they'll never be GC'd
12:56:44 <bd_> I think you can avoid this by putting them in a where clause
12:56:53 <bd_> but not sure
12:56:54 <Peaker> bd_, so what's to be done?
12:57:04 <Eulex> sclv, then I guess my question is how to use it :) I know of :t, but that's not really enough now...
12:57:08 <bd_> you could definitely avoid it by creating a data dependency on their first element
12:57:16 <bd_>  pos :: (Int, Int) -> [(Int, Int)]
12:57:17 <bd_> er
12:57:38 <bd_> ... wait, it's not referenced from toplevel is it
12:57:39 <bd_> I need sleep
12:58:09 <Peaker> me too :-) But I want a pure part in my program, or its not really Haskell is it :)
12:58:39 <bd_> Peaker: I'm a little worried about how you invoke pos and speed with a size parameter in the zip in speed
12:58:41 <sclv> Eulex: http://www.haskell.org/ghc/docs/latest/html/users_guide/ghci-debugger.html
12:58:42 <lambdabot> Title: 3.5. The GHCi Debugger, http://tinyurl.com/2orwlb
12:58:43 <bd_> that could prevent memoization
12:59:05 <bd_> Peaker: one solution would be to make pos size = pos' where pos' = ...  speed = ...
12:59:05 <Peaker> bd_, how do I avoid it? I only know size later on.. I could define them within that lexical scope I guess
12:59:11 <Eulex> sclv, already found it, thank you :)
12:59:22 <Peaker> bd_, oh, nice
12:59:39 <Eulex> oddly enough those commands aren't listed in :h...
13:01:06 <Eulex> ah, my ghc version is too old
13:01:19 <Peaker> bd_, that fixes it, thanks
13:02:05 <Peaker> bd_, I wonder why ghc couldn't see the equivalence here - Isn't it a superficial difference whether a bunch of functions get a shared arg, or whether they share that arg as a lexical scope?
13:03:31 <sclv> Peaker: are you compiling with -O2 ?
13:03:44 <Peaker> sclv, nope
13:04:03 <sclv> as i recall, ghc does quite a bit of aggressive let floating, but only with optimizations on.
13:04:08 <Peaker> hmm.. I am too lazy to change it back to the way it was to see if -O2 would optimize that out now
13:04:18 <bd_> Peaker: it might just not be smart enough to figure it out, but I don't know :)
13:04:22 <Peaker> as its more elegant this way anyhow
13:04:25 <bd_> GHC doesn't do anything like hashing on the argument
13:04:42 <bd_> so either it finds it statically
13:04:51 <bd_> or it will end up calling multiple times
13:04:53 <bd_> afk
13:05:22 <Peaker> the stuff defined in the "where' clause under the pos (sx, sy) = ... where      definition will not be accessible, right?  (How would they get their lexical scope if they were accessible?)
13:08:04 <Peaker> so now I have a:  forM (pos size) $ \(x, y) -> do   and I have an  IORef Bool  called "stopped" that I want to terminate the forM loop. Elegant way?
13:10:01 <dmwit> Don't you have a takeWhileM for just that purpose?
13:10:52 <Heffalump> oh, another way you could take care of exiting, throw an exception
13:11:10 <Peaker> takeWhileM  binds a monad again and again until an action returns monadic False,  forM iterates a pure-list..?
13:11:22 <dmwit> Yeah, not quite the same, sorry.
13:11:56 <Peaker> its a bit mind boggling :) I hope it becomes simpler later..
13:12:48 <Peaker> how do I throw an exception?
13:13:37 <Heffalump> lots of different ways, sadly.
13:13:38 <Peaker> fail ".." ?
13:13:53 <Heffalump> either use the IO native exceptions, like fail
13:13:59 <Peaker> why should there be sad things in Haskell? :-)   backwards compatibility?
13:14:01 <Heffalump> or use an exception monad transformer on top
13:14:30 <Heffalump> well, they have different properties. The really nasty bit is that the builtin exceptions come in two forms for backwards compatibility reasons.
13:14:38 <dibblego> ?type takeWhileM
13:14:39 <lambdabot> Not in scope: `takeWhileM'
13:14:47 <Heffalump> But exception monad transformer versus exception-in-IO is a reasonable distinction.
13:15:05 <Heffalump> like state monad transformer versus IORefs
13:19:35 <Peaker> dibblego, its in http://hpaste.org/6547
13:19:45 <dibblego> ah cheers
13:19:47 <Peaker>  takeWhileM :: Monad m => (a -> m Bool) -> m a -> m [a]
13:20:04 <Peaker> how is throwIO used?
13:20:10 <Peaker> How do I make an "Exception" value?
13:21:33 <wli> Peaker: It might be more natural to do DFS with a yet-smaller max depth (e.g. 2-4 plies) repetitively until some number of nodes has been blown past.
13:22:54 <Peaker> wli, plies?
13:25:21 <Peaker> Hmm, what if division returned a Maybe instead of "errors"?
13:27:23 <wli> Peaker: It would be much nicer. Perhaps nicer still if division were e.g. div :: (MonadZero m, Integral t) => t -> t -> m (t, t) (here MonadZero is the component of MonadPlus properly separated so mzero and mplus are separate methods).
13:28:34 <piojo> hi, everyone. what is the proper way to read values from strings (like with "read") and catch bad parses (bad input) and clean up?
13:28:52 <dibblego> ?where Parsec
13:28:52 <lambdabot> http://www.cs.ruu.nl/~daan/parsec.html
13:29:01 <piojo> isn't there anything simpler?
13:29:18 <piojo> i want the functionality of "read", but with the ability to do something besides "error" on bad input
13:29:23 <sclv> you can use reads
13:29:26 <sclv> ?hoogle reads
13:29:27 <lambdabot> Prelude.reads :: Read a => ReadS a
13:29:27 <lambdabot> Text.Read.reads :: Read a => ReadS a
13:29:27 <lambdabot> Prelude.ReadS :: type ReadS a
13:29:44 <piojo> okay, i'll read up on that. thanks
13:30:07 <gbacon> piojo: see readM in http://cgi.cse.unsw.edu.au/~dons/blog/2007/03/10#programmable-semicolons
13:30:09 <lambdabot> Title: Haskell hacking, http://tinyurl.com/ywdjsr
13:30:54 <piojo> gbacon: thanks, i'll read that, too
13:37:29 <Peaker> ((->) r) is a Monad, example use of that?
13:39:19 <Peaker> @src ((->) r) return
13:39:19 <lambdabot> Source not found. My brain just exploded
13:39:39 <gbacon> @src (->) return
13:39:39 <lambdabot> return = const
13:39:43 <gbacon> @src (->) >>=
13:39:43 <lambdabot> Source not found. Maybe if you used more than just two fingers...
13:39:57 <Peaker> @src (->) (>>=)
13:39:57 <lambdabot> f >>= k = \ r -> k (f r) r
13:41:56 <byorgey> > liftM2 (*) length sum $ [1,2,3]
13:41:58 <lambdabot>  18
13:42:00 <Peaker> but k is a function of 1 argument, supposedly?
13:42:15 <byorgey> Peaker: k is of type (a -> m b)
13:42:26 <byorgey> and in this case m is (-> r)
13:42:32 <byorgey> so it's (a -> r -> b)
13:42:59 <byorgey> Peaker: also, note that all functions are functions of one argument =)
13:43:08 <Peaker> ah, I see. But how come the "r" argument gets fed to two functions? Does that make sense?
13:43:11 <byorgey> it's just that some happen to also return a function.
13:43:24 <byorgey> Peaker: yes, that's the semantics of the (-> r) monad.
13:43:46 <gbacon> > let f = (+1); k = (*) in (f >>= k) 3
13:43:46 <lambdabot>  12
13:44:08 <byorgey> Peaker: in the (-> r) monad, a computation (m a) represents a computation which needs an input of type r to produce an output
13:44:27 <gbacon> > ((+1) >>= (*)) 3
13:44:27 <lambdabot>  12
13:44:49 <Peaker> what's happening here?
13:44:52 <gbacon> why doesn't ghci like that?
13:45:10 <gbacon> I get No instance for (Monad ((->) a))
13:45:18 <byorgey> gbacon: you need Control.Monad.Instances
13:45:20 <mauke> :m + Control.Monad.Reader
13:45:23 <Peaker> what computation does ((+1) >>= (*)) represent?
13:45:25 <byorgey> or that
13:45:42 <mauke> > ((+1) >>= (*)) x
13:45:42 <lambdabot>  (x + 1) * x
13:46:37 <Peaker> any place where that kind of behavior is useful?
13:46:51 <mauke> liftM2 is semi-common
13:47:04 <daf> @type (+1) >>= (*)
13:47:05 <lambdabot> forall a. (Num a) => a -> a
13:47:16 <mauke> > liftM2 f g h x
13:47:17 <lambdabot>  Add a type signature
13:47:21 <daf> @type ((+1) >>=)
13:47:22 <lambdabot> forall a b. (Num a) => (a -> a -> b) -> a -> b
13:47:49 <mauke> Peaker: liftM2 c f g x === f x `c` g x
13:47:55 <AndreWe_> What is MaybeS good for?
13:48:09 <Peaker> mauke, that's confusing :)
13:48:29 <byorgey> AndreWe_: what's MaybeS?
13:48:34 <gbacon> > ((:[]) >>= (flip (:))) [1,2,3]
13:48:34 <lambdabot>  [[1,2,3],[1,2,3]]
13:48:41 <mauke> well, it would make more sense if I could draw pictures over IRC
13:49:07 <AndreWe_> data MaybeS = NothingS | JustS !a
13:49:18 <AndreWe_> I wonder what the exclamation mark does?
13:49:30 <dibblego> strictness annotation
13:49:40 <byorgey> AndreWe_: oh, that's a strict version of Maybe
13:49:50 <dibblego> where does MaybeS come from?
13:49:56 <gbacon> MaybeStrict
13:50:06 <dibblego> @index MaybeStrict
13:50:06 <lambdabot> bzzt
13:50:13 <dibblego> @index MaybeS
13:50:13 <lambdabot> bzzt
13:50:33 <AndreWe_> Does it mean that it's components are evaluated always?
13:50:56 <byorgey> AndreWe_: sort of =)
13:51:16 <AndreWe_> ok, I don't wanna know more ;-)
13:51:32 <Saizan> AndreWe_: it means that when you force the JustS constructor the value inside is evaluated until its first contructor
13:51:43 <gbacon> @do \l -> ((:[]) >>= (flip (:))) l
13:51:44 <lambdabot> \l -> ((:[]) >>= (flip (:))) l not available
13:51:44 <byorgey> AndreWe_: essentially, it prevents you from getting 'Just' followed by a huge unevaluated expression =)
13:51:52 <gbacon> @redo \l -> ((:[]) >>= (flip (:))) l
13:51:52 <lambdabot> \ l -> (do { a <- (: []); (flip (:)) a}) l
13:52:03 <AndreWe_> byorgey: Is that useful?
13:52:58 <byorgey> AndreWe_: it could be. depends on what you're using Maybe for.
13:53:01 <byorgey> AndreWe_: I've never needed it.
13:54:00 <AndreWe_> That calms me down.
13:55:17 <byorgey> AndreWe_: where did you see this?
13:55:38 <Peaker> byorgey, mauke is "return" commonly used in the (->) monad? is the monad used in generic monadic functions?  Its use of "const" that discards the input seems to make it unsuitable?
13:55:50 <marshmallows> I just gave my mom grahams paper on the universality and expressiveness of fold :P
13:55:59 <CSlime> Help eradicate poverty, war and racism by joining our campaign!!!!!Help eradicate poverty, war and racism by joining our campaign!!!!!Help eradicate poverty, war and racism by joining our campaign!!!!!Help eradicate poverty, war and racism by joining our campaign!!!!!  Barack the Magic Negro will end all injustice! Barack the Magic Negro will end all injustice!Barack the Magic Negro will end all injustic
13:56:06 <CSlime> e! Barack the Magic Negro will end all injustice! Barack the Magic Negro will end all injustice!Barack the Magic Negro will end all injustice! Barack the Magic Negro will end all injustice! Barack the Magic Negro will end all injustice!
13:56:07 --- mode: ChanServ set +o Cale
13:56:12 --- mode: Cale set +b *!*@201.160.161.86.cable.dyn.cableonline.com.mx
13:56:13 <gbacon> oh snap
13:57:18 <AndreWe_> byorgey: I was trying to use Data.Graph which uses GHC.Arr.Array which contains a signature with a data constructor that uses strict components (!).
13:57:18 <RayNbow> CSlime on #ruby-lang #haskell #mysql ##c ##php ##linux #politics  <-- oh boy
13:58:04 <\z> looking over the definitions, Monoid, MonadPlus and Control.Alternative all look very similar
13:58:08 <\z> how similar are they?
13:58:17 <dmhouse> If he returns and I'm around, drop me a ping.
13:58:36 <Saizan> \z: Alternative could subsume MonadPlus
13:58:59 <dmhouse> (Or any of the other people on /msg chanserv access #haskell list.)
13:59:15 <byorgey> Peaker: (1) sure, "return" is commonly used in any monad.  (2) are you asking if the (->) monad used in generic monadic functions?  I'm not sure I understand the question.  (3) I'm not sure what you mean about being unsuitable due to const.
13:59:37 <Saizan> \z: but Monoid is quite different since a type to be an instance of Monoid must be of kind *, instead of * -> * for Alternative
13:59:45 <\z> Saizan: so something that's MonadPlus could be Alternative if it defines mzero = empty and mplus = <|> ?
14:00:10 <sclv_> Monoid makes sense, Alternative makes sense, MonadPlus is sort of maddening...
14:00:27 <Peaker> byorgey, well, binding func-monads to each other is useful, but a func monad created with "return" loses its input, which seems to be problematic, isn't it?
14:01:04 <Cale> Peaker: You're misusing the word "monad".
14:01:09 <sclv_> see here: http://www.haskell.org/haskellwiki/MonadPlus
14:01:10 <lambdabot> Title: MonadPlus - HaskellWiki
14:01:10 <Saizan> \z: yes, but you've inverted the order, you'd define empty = mzero, (<|>) = mplus
14:01:18 <marshmallows> Why is #functional empty?
14:01:26 <marshmallows> but haskell is so full
14:01:26 <Cale> Peaker: Essentially, return is const in the (->) e monad.
14:01:29 <\z> Saizan: Thanks!
14:01:41 <Peaker> Cale: Yeah, that seems weird to me, I don't understand how that would make much sense
14:01:50 <Cale> Peaker: That's not a problem, it's a consequence of the type.
14:01:56 <Cale> return :: a -> m a
14:02:02 <Cale> When m = (->) e,
14:02:06 <Cale> return :: a -> (e -> a)
14:02:27 <Saizan> \z: you've to define Applicative too, but that's also easy (<*>) = ap, pure = return
14:02:35 <\z> So if I have a type that's both a Monad and a MonadPlus, it's necessarily both an Applicative and Alternative as well
14:02:35 <mauke> Peaker: 'return' wraps a value in some monad, with no side effects
14:02:42 <Peaker> Cale, yeah, it means that if you bind stuff to (return X) you lose their result?
14:02:50 <Cale> hm?
14:02:50 <Peaker> (in this monad)
14:02:51 <byorgey> Peaker: in any monad, (return x) is a monadic computation which ignores the monad context and just returns the value x.
14:02:57 <mauke> Peaker: the "side effect" of -> is the ability to see the hidden function argument
14:03:02 <Cale> y <- return x   will result in y being equal to x
14:03:15 <\z> where does it make sense to start using the applicative and alternative operations within the monad?
14:03:51 <sclv_> <|> seems to make sense for Left Catch always, no...?
14:03:51 <byorgey> Peaker: note, in the (r ->) monad, the 'r' is NOT the result of the previous monadic computation, if you bind two of them with >>=
14:03:54 <Peaker> byorgey, If I bind an (IO Integer) to a (Integer -> IO ()) which was created via (return ..) it doesn't lose all the work done by the (IO Integer)
14:04:04 <byorgey> Peaker: no.
14:04:19 <Cale> Peaker: sorry?
14:04:30 <Cale> Peaker: This is in the IO monad?
14:04:30 <sclv_> which I guess means that a haskell refactoring could choose monadplus always be Left Distribution instead.
14:04:49 <byorgey> Peaker: well, in that specific case, yes.
14:05:03 <byorgey> Peaker: I think I see your confusion.
14:05:11 <Saizan> \z: well, the Applicative interface is less expressive, but gives more guarantees, essentially how the effects compose is statically determined
14:05:11 <mauke> I have done an art: http://img220.imageshack.us/img220/6120/readerdj1.png
14:05:13 <Peaker> Cale, no no, I was saying that in the IO Monad, binding to "return"  continues the monadic computation.  In the (->) monad, binding to return "loses" everything?
14:05:26 <mauke> can anyone recommend a program better than paint for creating this type of diagrams?
14:05:28 <Cale> I don't understand what you mean by "loses everything"
14:05:42 <Cale> x >>= return  is always the same as  x
14:05:46 <Cale> In any monad.
14:05:46 <flux> mauke, graphviz!
14:06:12 <flux> zero need for drawing edges or placing nodes
14:06:18 <Peaker> Cale, (x >>= \_ -> return 5)  Compare this in the IO Monad and the (->) monad
14:06:27 <flux> however, if you want to integrate some explanative texts, well, then maybe it's not perfect
14:06:38 <byorgey> Peaker: note, you can always say something like  m >>= \x -> return foo ... something else involving x ...  so you don't have to "lose" the x
14:06:43 <Cale> Peaker: x won't need to be computed in the ((->) e) monad
14:06:52 <Cale> Peaker: you're throwing away its result.
14:07:04 <Cale> (and indeed, it won't be computed)
14:07:05 <dons> ops, Cale?
14:07:09 <Peaker> Cale, byorgey : Ok, I think I see my confusion now
14:07:10 --- mode: Cale set -o Cale
14:07:11 <dons> ?uptime
14:07:11 <lambdabot> uptime: 5d 12h 35m 27s, longest uptime: 1m 10d 23h 44m 29s
14:07:16 <dons> good stuff, btw ^^ :)
14:07:49 <gbacon> mauke: dia
14:07:54 <\z> Saizan: I think I see that.  But it all seems a little handwavy with Alternative/MonadPlus, if <|> === mplus
14:08:08 <Peaker> Cale, byorgey : The monad represents the value that's being moved into the rhs of >>=, AND it also represents some extra internal state that may be contained within it (or not). In the case of IO monad, that extra state exists, in the case of the (->) monad there's no such extra state.  Would that be more accurate?
14:08:28 <Cale> Peaker: I suppose, yes
14:08:53 <Peaker> Cale, byorgey : When the monad only has the contained value, its unclear why its a monad, and not a simple composition?
14:09:08 <Cale> Peaker: At the end of the day, a monad is just a type constructor, and some operations that satisfy some laws.
14:09:26 <Peaker> I don't understand why it makes sense to make (->) an instance of Monad, though
14:09:26 <Cale> Peaker: Some monads represent the maintenance of state, some don't.
14:09:36 <Peaker> Why do you need ones that don't?
14:09:42 <Jaak> > join (*) 5
14:09:43 <lambdabot>  25
14:09:43 <Cale> Because with the given definitions of return and bind, it is a monad.
14:10:01 <Cale> And hence you get all kinds of useful operations from Control.Monad for free.
14:10:06 <Peaker> with some work, I can probably make any type a monad :-)
14:10:11 <Cale> Which is really the *only* reason to declare anything at all a monad.
14:10:18 <Cale> No, you can't :)
14:10:25 <Peaker> (any type constructor)
14:10:31 <Cale> Some types don't have suitable operations making them into monads.
14:10:37 <Heffalump> you'd also be expected to satisfy the monad laws if you did so
14:10:39 <Peaker> Cale, I can artificially define them
14:10:42 <marshmallows> why is there no declarative functional or procedural channels on freenode?
14:10:44 <Saizan> \z: the point is that with a monad you can decide the next action to use at "runtime" i.e. after seeing the result of the previous action, with an applicative you can't, and (a <|> b) respect this, it's not like the result of a is passed to b
14:10:58 <Cale> For instance,  newtype Foo a = F (Integer -> a)
14:11:06 <Jaak> aah, stream
14:11:24 <Jaak> excellent comonad tho'
14:11:40 <Peaker> Cale, I can define functions suitable to serve as return/(>>=) on that, can't I?
14:11:51 <Cale> Peaker: Will they satisfy the laws?
14:12:02 <clanehin> It might be worth pointing out that (->) is obviously an arrow, and from there there's an obvious definition of ArrowApply, which makes it obviously a monad by baby steps.
14:12:02 <Peaker> Cale, I think so
14:12:29 <Cale> That *may* be a poor example. A better example might be  newtype Foo e a = F (e -> a)
14:12:31 <Peaker> Cale, I am slow with this, being a beginner :) I'd have to try defining that as an instance of Monad and see
14:12:51 <Cale> I'm pretty sure that can't be made into a monad.
14:13:05 <Peaker> I'll take the challenge :)
14:13:10 <Cale> er
14:13:25 <Heffalump> umm, aren't both your examples reader monads?
14:13:25 <Cale> d'oh
14:13:29 <Cale> yes
14:13:34 <Cale> I have it backwards :)
14:13:43 <Cale> newtype Foo e a = F (a -> e)
14:13:48 <Cale> There we go :)
14:14:02 <Peaker> more challenging :)
14:14:15 <Cale> So now you have to define things so that  join :: ((a -> e) -> e) -> (a -> e)
14:14:17 <Heffalump> to the point of impossible :-)
14:14:21 <\z> Saizan: but if <|> is exactly the same as mplus, how are they any different, runtime or otherwise?
14:14:26 <Heffalump> return will be rather hard..
14:14:29 <Cale> and yeah,
14:14:37 <Cale> return :: a -> (a -> e)
14:14:41 <Twey> @src (<|>)
14:14:41 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
14:14:48 <Peaker> question is whether I can "store" a value of type "a" in  (a -> e), I guess I can't
14:14:48 <Twey> :-\
14:15:04 <sclv_> Twey: <|> has no particular source. its a classmethod of Alternative
14:15:08 <Peaker> especially as functions are opaque that way
14:15:13 <Heffalump> more importantly you can't invent any e except undefined
14:15:39 <Twey> sclv_: Oh
14:16:04 <Peaker> okay - so everything that can be made a monad is made a monad, because it can? :)
14:16:09 <sclv_> as <|> and mplus are both class methods, its quite possible to give them different behaviors.
14:16:13 <Saizan> \z: why should they be different if we're just using them for the same Monad/Applicative? the Applicative interface is a subset of the Monad one
14:16:43 <sclv_> (and indeed, mplus has no clear "right" behavior -- see my link above, e.g.)
14:16:43 <Heffalump> Peaker: well, the reader monad is independently useful
14:16:55 <Peaker> Cale, any useful way to use functions that operate on Monads are useful on the (->) monad?
14:16:57 <Heffalump> though people typically do it explicitly with Reader/ReaderT, not the (a->) instance.
14:17:02 <Peaker> I am trying to figure out the usefulness of (->) being a monad
14:17:15 <Heffalump> environments
14:17:16 <agcorona> I just added a new proposal to th Google Summer of Code :  "intelligent mobile Haskell code"
14:17:18 <Cale> It's really that ((->) e) is a monad for any e
14:17:27 <oerjan> > sequence [(+1), sin, cos] 1.0
14:17:28 <lambdabot>  [2.0,0.8414709848078965,0.5403023058681398]
14:17:29 <Heffalump> it gives you implicit access to some context value
14:17:31 <Cale> > sequence [id, (+2), (*2), (^2), (2^)] 5
14:17:31 <lambdabot>  [5,7,10,25,32]
14:17:55 <Cale> > (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z)) "hello"
14:17:56 <lambdabot>  ("hello","olleh","HELLO")
14:18:09 <Cale> > liftM2 (==) nub (take 1) [1,1,2]
14:18:09 <lambdabot>  False
14:18:12 <Cale> > liftM2 (==) nub (take 1) [1,1,1,1]
14:18:13 <lambdabot>  True
14:18:29 <Cale> > map (ap (,) (^2)) [1..10]
14:18:30 <lambdabot>  [(1,1),(2,4),(3,9),(4,16),(5,25),(6,36),(7,49),(8,64),(9,81),(10,100)]
14:19:13 <Peaker> Cale, Ah, indeed useful
14:19:16 <Peaker> Cale, thanks
14:19:29 <mauke> also, @pl
14:19:35 <oerjan> Peaker: other than that, (->) e allows you to make much code point-free, which is what @pl does
14:19:41 <Peaker> the liftM2 examples of the (->) are too advanced for me to understand easily
14:19:44 <skorpan> let's say that i have a value which i know is "Just p". how do i actually extract the "p" without using case?
14:19:49 <Peaker> @pl?
14:19:49 <lambdabot> (line 1, column 1):
14:19:49 <lambdabot> unexpected end of input
14:19:49 <lambdabot> expecting white space, "()", natural, identifier, lambda abstraction or expression
14:19:52 <Cale> Peaker: look at the types :)
14:19:55 <Cale> :t liftM2
14:19:56 <lambdabot> forall a1 a2 r (m :: * -> *). (Monad m) => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
14:20:02 <Peaker> skorpan, pattern-match (Just p) =>
14:20:04 <mauke> Peaker: http://img220.imageshack.us/img220/6120/readerdj1.png
14:20:08 <Peaker> skorpan, in the function itself or the where clause
14:20:09 <Cale> (a -> b -> r) -> m a -> m b -> m r
14:20:12 <Cale> So...
14:20:20 <skorpan> Peaker: uh yeah, but without "case", as i said
14:20:23 <daf> skorpan: fromJust?
14:20:24 <Cale> (a -> b -> r) -> (e -> a) -> (e -> b) -> (e -> r)
14:20:26 <Saizan> skorpan: maybe undefined id == fromJust
14:20:30 <Heffalump> skorpan: fromJust
14:20:31 <\z> sclv_: thanks.  this page clarifies it a little further: http://www.haskell.org/haskellwiki/MonadPlus_reform_proposal
14:20:32 <lambdabot> Title: MonadPlus reform proposal - HaskellWiki
14:20:34 <Peaker> skorpan, pattern matching happens for functions too, not just cases
14:20:42 <Cale> liftM2 (==) f g x
14:20:53 <Cale> = f x == g x
14:21:03 <skorpan> Peaker: i'm not sure what you mean, but i do know that it doesn't work in my case
14:21:05 <daf> skorpan: but fromJust is what you use when you can't possibly pattern match
14:21:14 <daf> and usually you can pattern match
14:21:32 <daf> you want to have the "is this a Just or a maybe" combined with the "extract from the Just"
14:21:37 <skorpan> daf: i can pattern match, but i *know* that the value is Just _, and there is not really anything to do if it's not "Just _"
14:21:39 <daf> * or a Nothing
14:21:55 <sclv_> has anyone written any code that uses mplus for lists anyway as opposed to monoid ops??
14:22:00 <daf> if you know it's a just, that suggests you should have an a rather than a Maybe a
14:22:28 <Cale> join (++) "hello"
14:22:32 <Cale> > join (++) "hello"
14:22:33 <lambdabot>  "hellohello"
14:22:34 <skorpan> daf: problem is that i don't have an a instead of Maybe a. i don't even have a Maybe a, it's being returned from a function call
14:22:55 <oerjan> skorpan: it may still be nice to have an error message if the impossible happened, makes it easier to track down
14:23:07 <Cale> (another consequence of the ((->) e) monad)
14:23:08 <skorpan> oerjan: such as "error "hello""?
14:23:18 <oerjan> skorpan: fromMaybe (error "Impossible here")
14:23:21 <Peaker> skorpan, myfunc (func_returning_just x) blah  where myfunc (Just x) = ... use x ...
14:23:45 <Peaker> Cale, I don't understand why that makes sense thoguh
14:24:02 <Cale> Peaker: join :: m (m a) -> m a
14:24:10 <Cale> (Monad m) => of course
14:24:16 <Cale> So in this case,
14:24:23 <Heffalump> that is a particularly useless example of the reader monad, IMO
14:24:24 <Cale> join :: (e -> (e -> a)) -> (e -> a)
14:24:34 <Cale> It's sometimes handy.
14:25:03 <Heffalump> I'd be interested to see a real example where it actually was easy to understand what's going on.
14:25:10 <Cale> It lets you take a function of two parameters and turn it into a function which takes only one parameter
14:25:18 <oerjan> :t join.($)
14:25:19 <lambdabot> forall a a1. (a1 -> a1 -> a) -> a1 -> a
14:25:26 <ddarius> Heffalump: liftM2 ?
14:25:43 <Peaker> Cale, what does join do in the general case? I don't understand what m (m a)  typically represents
14:25:51 <byorgey> > liftM2 (*) length sum [2,3,4]
14:25:51 <lambdabot>  27
14:25:52 <Peaker> Cale, what would IO (IO a) be?
14:26:01 <byorgey> the length times the sum of [2,3,4].
14:26:03 <Heffalump> Peaker: join m = m >>= id
14:26:05 <mauke> an IO action returning an IO action
14:26:11 <Cale> That would be an IO action that when executed, produced another IO action as a result.
14:26:14 <Heffalump> it just flattens out stuff.
14:26:21 <ddarius> The Reader liftM2 is useful for quickcheck properties.
14:26:42 <Heffalump> ddarius: I meant an example of join in the reader monad being useful. Or is that what you mean too?
14:26:44 <Cale> join would remove the layer of indirection, producing the action which would run the first, then run its result
14:27:22 <mauke> takeWhile ((<= n) . join (*))
14:27:52 <ddarius> mauke: Those diagrams are impressively crappy, though you could easily connect them to J hooks and forks.
14:28:01 <Cale> Peaker: Does that make sense?
14:28:22 <Peaker> Cale, yeah, but I'm still digesting it. Its so abstract its crazy :)
14:28:23 <ddarius> Heffalump: join is probably more obfuscatory than clarifying unless you are expecting your audience to know that particular trick
14:28:30 <Heffalump> ddarius: right.
14:28:39 <AndreWe_> Has someone used Data.Graph?
14:28:50 <Heffalump> I wish Cale would stop foisting it on newbies :-)
14:28:52 <AndreWe_> I just want to create a graph.
14:29:09 <oerjan> @undo join a
14:29:10 <lambdabot> join a
14:29:14 <Cale> Heffalump: Why? It's one of the simplest examples of a monad.
14:29:21 <mauke> @redo join a
14:29:21 <lambdabot> join a
14:29:27 <Cale> Heffalump: Or do you mean join?
14:29:27 <oerjan> oh
14:29:30 <Heffalump> not the reader monad, the example of using join in the reader monad
14:29:31 <Peaker> mauke, that drawing is specific to the (->) monad right?
14:29:39 <mauke> Peaker: yes
14:29:41 <Cale> Heffalump: join is one of the simplest examples of a monad combinator :)
14:29:48 <Heffalump> the reader monad is useful, join is useful, but only rarely together except in an obfuscating fashion
14:29:51 <oerjan> @src join
14:29:51 <lambdabot> join x =  x >>= id
14:29:52 <Cale> So it's worth looking at as a beginner :)
14:29:59 <Heffalump> yes, on a different monad
14:30:00 <oerjan> @redo x >>= id
14:30:00 <lambdabot> do { a <- x; id a}
14:30:07 <ddarius> I don't think the Reader monad can be fully motivated with small examples.
14:30:07 <Cale> Nah, even on this monad :)
14:30:36 <Heffalump> no, it's just confusing.
14:30:50 <Peaker> mauke, Your 'g' varies a lot :-)
14:30:54 <Cale> Heh, I disagree, but whatever :)
14:30:59 <TheRoot> how do I manipulate the types of numbers in haskell?
14:31:12 <oerjan> @quote fromIntegral
14:31:13 <lambdabot> monochrom says: You've got an Int / But you want Double / Who do you call? / "fromIntegral!"
14:31:15 <Cale> TheRoot: fromIntegral
14:31:17 <Heffalump> even experienced Haskellers don't know what join (+) does without either having seen it before or thinking for a bit. It's not a good expository example.
14:31:22 <Cale> TheRoot: and realToFrac
14:31:30 <Cale> TheRoot: and round/floor/ceiling
14:31:34 <oerjan> TheRoot: or sometimes realToFrac
14:31:46 <Cale> Heffalump: It's a good exercise, and not very hard.
14:32:23 <Heffalump> once you've really got the hang of monads, yes
14:32:34 <sclv_> I've only seen the unwrapped reader used for small things though -- for big things using the wrapped one seems the way to go.
14:32:39 <mauke> even newbies understand what join (+) does after seeing a few examples, even if they don't know anything about monads
14:32:40 <Heffalump> but if you're still trying to understand why the reader monad is any use, it's not :-)
14:32:44 <Cale> sclv_: This is generally true :)
14:32:52 <Heffalump> sclv_: agreed.
14:33:07 <Cale> Oh, it's not a great example of why the unwrapped reader monad is useful.
14:33:08 <sclv_> the one really cool thing with the unwrapped reader is sequence, I think...
14:33:09 <ddarius> sclv_: Except for tricks like that, usually using lexical scoping rather than a reader monad is the way to go for small examples.
14:33:15 <Heffalump> I wish that Haskell had a disappearing Identity type.
14:33:23 <Cale> But it's still handy to know that there's a function in the libraries which does that.
14:33:59 <ddarius> :t let dup = join (,) in dup
14:33:59 <joricj> @src forever
14:34:00 <lambdabot> Source not found. You type like i drive.
14:34:01 <lambdabot> forall a. a -> (a, a)
14:34:06 <TheRoot> augh. why are there so many number types!?
14:34:09 <gbacon> darcs record -m 'Implement BourneIdentity monad.' ...
14:34:11 <Heffalump> I would argue against using join just as a convenience combinator to duplicate an argument. The overloaded type would make for poor errors.
14:34:22 <mauke> forever = fix . (>>)
14:34:31 <sclv_> TheRoot: because they're all different, most languages just lie about it :-)
14:34:32 <oerjan> @unpl forever = fix . (>>)
14:34:32 <lambdabot> forever c = fix ((>>) c)
14:34:36 <Peaker> You didn't all hear my question about building a "Differential computing" language/platform on top of Haskell before, right?
14:34:40 <oerjan> bah
14:34:47 <TheRoot> haskell doesn't tell me anything about it.
14:34:53 <ddarius> "C# has more than 10 integer types [none of them arbitrary precision]"
14:34:59 <mauke> TheRoot: you only need 2.5 of them
14:35:01 <Heffalump> Peaker: it's very likely, as the active population in here changes quite fast.
14:35:15 <TheRoot> I want to do something relatively simple and I'm going to have to do about three numeric type casts.
14:35:21 <TheRoot> but I don't know which ones.
14:35:22 <sclv_> use Integers and Doubles unless you need something specialized...
14:35:24 <mauke> there are no type casts
14:35:40 <Cale> TheRoot: If you're going from an Integer-like value to anything else, use fromIntegral
14:35:43 <TheRoot> mauke: which is why I'm here. to figure out what to do instead.
14:35:52 <sclv_> ?paste for us
14:35:52 <lambdabot> Haskell pastebin: http://hpaste.org/new
14:35:55 <TheRoot> I want to get TO an integer, I think.
14:35:58 <Cale> TheRoot: If you're going between fractional types, generally realToFrac is what you want
14:36:00 <Peaker> I want to create a "language" where I build a function invocation graph, much like a normal one - except that the leaves in this graph are called "source values" and they "change" in-place. These changes are sent (as changes) to computations based on them - which do not generate a whole new value, but instead generate a change too, which continues to propagate over the computation
14:36:05 <mauke> TheRoot: from what?
14:36:08 <ddarius> @src Real
14:36:08 <lambdabot> class  (Num a, Ord a) => Real a  where
14:36:08 <lambdabot>     toRational      ::  a -> Rational
14:36:08 <gbacon> @ty join (,)
14:36:09 <lambdabot> forall a. a -> (a, a)
14:36:13 <ddarius> @src RealFrac
14:36:14 <lambdabot> class  (Real a, Fractional a) => RealFrac a  where
14:36:14 <lambdabot>     properFraction                   :: (Integral b) => a -> (b,a)
14:36:14 <lambdabot>     truncate, round, ceiling, floor  :: (Integral b) => a -> b
14:36:15 <Cale> TheRoot: If you're going from a fractional type to an integer-like type, round/ceiling/floor
14:36:36 <TheRoot> the types those are returning aren't quite right either.
14:36:39 <TheRoot> it's a bit confusing.
14:36:44 <TheRoot> hang on and I'll explain better.
14:36:50 <Peaker> in other words: Computations are seemingly of inputs, but in actuality they compute differentials on their values based on differentials they receive from the inputs
14:37:00 <gbacon> is forall a. a -> (a, a) a wordy way to say _|_?
14:37:05 <sclv_> seriously -- if its relatively small, go ahead and paste the code. :-)
14:37:06 <Peaker> how would I go about designing such a language on top of Haskell?
14:37:07 <ddarius> gbacon: No
14:37:10 <Cale> gbacon: no
14:37:11 <ddarius> @djinn a -> (a,a)
14:37:12 <lambdabot> f a = (a, a)
14:37:16 <Cale> > join (,)
14:37:16 <lambdabot>  Add a type signature
14:37:21 <Cale> :t join (,)
14:37:22 <lambdabot> forall a. a -> (a, a)
14:37:25 <Cale> ;)
14:37:29 <gbacon> why does it need the existential?
14:37:37 <Heffalump> Peaker: do you actually mean numeric differentials?
14:37:38 <gbacon> *universal?
14:37:39 <Peaker> what's "@djinn"?
14:37:39 <Cale> gbacon: existential?
14:37:45 <ddarius> @help djinn
14:37:45 <lambdabot> djinn <type>.
14:37:45 <lambdabot> Generates Haskell code from a type.
14:37:45 <lambdabot> http://darcs.augustsson.net/Darcs/Djinn
14:37:49 <Cale> gbacon: Oh, that's normally implicit in all Haskell types
14:37:59 <ddarius> Peaker: Technically, it's a theorem prover.
14:38:04 <Cale> gbacon: But if you use -fglasgow-exts, GHC will print it explicitly
14:38:17 <Peaker> Heffalump, numerics are more difficult to explain -  I like the "sort" example -  it takes a "list" and returns a "list" but actually it runs on  list modifications and sends out list modifications
14:38:27 <gbacon> @ty id
14:38:29 <lambdabot> forall a. a -> a
14:38:56 <Peaker> ddarius, ah, cool, though why wouldn't a -> (a,a)  be:  f a = (a*2,a*2) ?  Because that would require the class containing * ?
14:38:57 <Heffalump> hmm. Invertible stuff isn't so hard (e.g. see that paper I pointed you at). But propagating differences is tricky.
14:38:58 <TheRoot> let's say I have a list, x. I want to split x into two lists of equal parts. x is guaranteed to have length evenly divisible by 2.
14:38:59 <gbacon> I hadn't noticed lambdabot throwing those in
14:39:14 <TheRoot> I want something like splitAt((length x / 2) x)
14:39:21 <ddarius> Peaker: Yes
14:39:25 <Heffalump> I'd guess you should implement an "Edit" type for each datatype you want to work with.
14:39:26 <TheRoot> but the problem's in the length x / 2 bit.
14:39:27 <mauke> TheRoot: length x `div` 2
14:39:35 <gbacon> TheRoot: do you care about ordering?
14:39:36 <mauke> div is integer division
14:39:39 <Heffalump> (this would be a neat application of associated type synonyms, but they're not released yet)
14:39:48 <TheRoot> gbacon: yes.
14:39:52 <Peaker> Heffalump, the in-place changes to source-values and those should trigger the differentials flowing through the computations, that's tricky, I guess
14:39:58 <Heffalump> actually associated datatypes is all you'd need and those are in 6.8. But perhaps they're a bit advanced for a relative newbie like you.
14:40:07 <gbacon> so [a,b,c,d] -> [[a,b],[c,d]] ?
14:40:18 <TheRoot> mauke: that doesn't work.
14:40:21 <gbacon> and not [[a,c],[b,d]]?
14:40:35 <Peaker> Heffalump, Well, I'll try to work at my Haskell to un-newbie myself :)
14:40:39 <mauke> > let foo x = splitAt (length x `div` 2) x in foo [a,b,c,d]
14:40:40 <lambdabot>  ([a,b],[c,d])
14:40:41 <TheRoot> http://hpaste.org/6550
14:40:46 <mauke> TheRoot: does too
14:40:54 <Heffalump> fundamentally your problem is algorithmic, and Haskell won't be much active help to you, IMO. It won't hinder either, though, and the pure nature will help provide assurance that changes can only be propagated in the ways you specify explicitly.
14:41:31 <gbacon> @ty 3
14:41:32 <lambdabot> forall t. (Num t) => t
14:42:16 <TheRoot> `div` returns the 31 bit integer and splitAt is looking for the arbitrary Integer, right?
14:42:24 <Peaker> Heffalump, well, I had a working model in Python - but then I realized this differential-computing language is a half-arsed FP language too, and I better learn FP
14:42:30 <TheRoot> am I reading my error message correctly?
14:42:46 <Heffalump> right, so Haskell will do a good job of the functional part. But you'll need to sort the differential part yourself :-)
14:43:01 <Heffalump> but I think defining an associated datatype Edit would be a nice way of doing it.
14:43:03 <mauke> TheRoot: your error message is that length returns a number, not a function
14:43:06 <Cale> TheRoot: you're applying the result of (length test `div` 2) to test
14:43:20 <Cale> TheRoot: you just have to remove a pair of parens
14:43:25 <Cale> (the outer ones)
14:43:39 <Heffalump> class Editable t where data Edit t ; diff :: t -> t -> Edit t ; patch :: Edit t -> t -> t
14:43:41 <TheRoot> ah. gotcha.
14:43:57 <mauke> > let foo x = splitAt (length x `div` 2) x in foo [a,b,c,d]
14:43:58 <lambdabot>  ([a,b],[c,d])
14:44:01 <TheRoot> I take it that haskell supports lisp-like function calls then?
14:44:19 <Peaker> how do I create an GHC.IOBase.Exception?
14:44:21 <Heffalump> (/me is just thinking out loud, what you need may well be very different)
14:44:25 <Cale> TheRoot: f x y z really means  ((f x) y) z)
14:44:37 <Cale> er, (((f x) y) z)
14:44:45 <marshmallows> TheRoot: No it doesn't
14:45:06 <marshmallows> TheRoot: then again, lisp-like might mean something totally different to you and me :S
14:45:28 <marshmallows> (what exactly did you mean?)
14:45:34 <TheRoot> marshmallows: no, it seems we interpret that phrase the same way.
14:45:56 <TheRoot> I should have said lisp-like syntax, I think.
14:46:12 <marshmallows> ah ok, you can kind of do lisp-syntax
14:47:01 <gbacon> > a
14:47:01 <lambdabot>  a
14:47:12 <gbacon> @ty a
14:47:13 <lambdabot> Expr
14:47:46 <Peaker> Heffalump, well, I've done some more thinking about my problem, and I think that descriptions of differentials should themselves be "functions" that can be "extracted" into lower functions - this will allow optimizations such as:  A) Apply clear-elements on source list  B) "Sorted" knows clear-elements and uses O(1) diff as an optimization for this case OR "Sorted" does not know this higher-order function, so "extracts" it into many small
14:47:47 <Peaker> "remove element" functions which it handles.
14:48:06 * wli might do something like half [] = Nothing ; half [x] = Just $ Left x ; half (x:x':xs) = case half xs of { Nothing -> Just $ Right ([x], [x']) ; Just (Left x'') -> Just $ Right ([x, x''], [x']) ; Just (Right (ys, zs)) -> Just $ Right (x:ys, x':zs) } ; crush op x xs = case half xs of Nothing -> x ; Just (Left x') -> x `op` x' ; Just (Right (ys, zs)) -> crush op x ys `op` crush op x zs
14:48:15 <marshmallows> constructors are prefix applied, so when you write code as data it looks like lisp.. (Lambda "x" ((Atom "f") :$: (Atom "x"))) ..
14:48:38 <marshmallows> if you squint .. and ignore infix constructors
14:48:40 <Peaker> Heffalump, As in - whatever changes are being made can themselves be described in a "higher-order" in which case optimizations may take place, or if the computation receives a "higher-order" change it does not know, it can view the same change as a bunch of lower-order changes
14:48:46 <Heffalump> peaker: ok, so explicitly constructed functions, not Haskell ones
14:48:52 <Peaker> Heffalump, yeah
14:49:03 <Heffalump> sounds reasonable
14:49:31 <TheRoot> can someone point me to a good explanation of statements like: functionName :: Num a => a -> a -> a -> a
14:49:47 <Cale> TheRoot: that's a type declaration
14:50:00 <marshmallows> TheRoot: -> is right associative, so it's the same as :: Num a => (a -> (a -> (a -> a)))
14:50:09 <Cale> TheRoot: it says that for any type of Numbers a, the function functionName takes three values of type a and produces an a
14:50:30 <TheRoot> Cale: oh.
14:50:42 <Cale> Yes, and -> is right associative, so if you just pass functionName a single value of type a, then you get a function which will take two more and produce an a
14:50:46 <gbacon> @ty \a b c -> a + b + c
14:50:47 <lambdabot> forall a. (Num a) => a -> a -> a -> a
14:51:15 <Peaker> why does lambdabot prepend the "forall a." ? Is that in order to describe the kinds?
14:51:42 <Cale> Peaker: It's because -fglasgow-exts is turned on, so you can quantify the type variables elsewhere too
14:51:49 <Cale> for instance...
14:52:39 <Cale> > let f :: (forall a. [a] -> [a]) -> (String, [Integer]); f g = (g "hello", g [1,2,3]) in f reverse
14:52:39 <lambdabot>  Parse error at "." (column 19)
14:52:44 <Cale> er...
14:52:48 <Cale> heh
14:53:05 <Cale> :t let f :: (forall a. [a] -> [a]) -> (String, [Integer]); f g = (g "hello", g [1,2,3]) in f
14:53:06 <lambdabot> (forall a. [a] -> [a]) -> (String, [Integer])
14:53:14 <TheRoot> so if I wanted to say that a function takes a list of Nums and returns a list of Nums, that would look like Num a => [a] -> [a]
14:53:23 <Cale> I suppose the evaluation plugin doesn't have that option turned on
14:53:32 <Cale> TheRoot: yeah
14:53:37 <dons> there's  a flag to turn that off now
14:53:46 <dons> -fno-print-foralls or something
14:54:02 <Peaker> Cale, isn't any type variable already "forall'd"?
14:54:10 <dons> Prelude> :set -fno-print-explicit-foralls
14:54:10 <dons> Prelude> :t []
14:54:10 <dons> [] :: [a]
14:54:10 <dons> Prelude> :set -fprint-explicit-foralls
14:54:10 <dons> Prelude> :t []
14:54:11 <Cale> Peaker: yes.
14:54:12 <dons> [] :: forall a. [a]
14:54:22 <dons> Cale, maybe turn it on, or off, as you see fit, in Plugin.Type ?
14:54:40 <Peaker> Cale, so what information does it add?
14:54:43 <Cale> Peaker: Type variables are implicitly forall'd at the outermost point in the type signature if you don't specify.
14:54:48 <wli> Some people prefer foldb op x (y:y':ys) = (y `op` y') `op` foldb op x ys ; foldb op x [y] = x `op` y ; foldb _ x [] = x
14:55:10 <Cale> Peaker: Not much. GHC just likes to print them. dons just pointed out that there's now an option to turn that off.
14:55:32 <Cale> Peaker: It would add information if the forall didn't occur right at the beginning
14:55:47 <Peaker> Cale, why would it add information in that case?
14:55:54 <Peaker> what's the difference where the forall is put?
14:56:13 <Cale> Peaker: Because it lets you say, for instance, that a parameter to some function *must* be polymorphic.
14:56:18 <Cale> If I write:
14:56:20 <oerjan> fortunately it was recovered
14:56:32 <Cale> f :: ([a] -> [a]) -> String
14:56:47 * oerjan wonders why the active window changed by itself
14:56:52 <Cale> Then, for example, it must be okay for a = Integer
14:57:11 <Cale> So that function won't likely be so useful in the body of f
14:57:18 <Cale> However, if I write:
14:57:24 <Cale> f :: (forall a. [a] -> [a]) -> String
14:57:27 <ddarius> Peaker: The different scoping of the forall has different meanings just like it does in logic.
14:57:35 <Cale> Then the function passed to f is *forced* to be polymorphic.
14:57:50 <Cale> For example, you can't pass in something of type [Integer] -> [Integer]
14:58:01 <Cale> But you could pass in reverse
14:58:07 <Cale> or  take 5
14:59:26 <Peaker> so if the forall is outside, it is as if the entire "f" signature exists for every polymorphic type. If the "forall" is inside, its as if there is just one "f" but the type it takes must be polymorphic, right?
14:59:30 <Peaker> that's why the scoping has that effect
14:59:43 <Cale> I suppose, yes.
15:00:04 <Peaker> well, I had to justify to myself why the scoping had that effect :)
15:00:37 <TheRoot> well, thanks for your help guys.
15:00:43 <ddarius> "if all the lights are out you won't be able to see" is not the same as "for each light, if it is out you won't be able to see"
15:00:52 <TheRoot> I still have a ways to go to learn this puppy, so I'll be back over the next week or several. :P
15:01:10 <igel> could someone please help me with a c-binding problem?
15:01:31 <Cale> igel: we can certainly try :)
15:01:38 <igel> i've got  helper.{c, h} files in the project direcotry
15:01:39 <Peaker> ddarius, yeah, I see
15:02:00 <igel> loading my program with ghci -L... -l... works
15:02:13 <igel> but ghc --make produces a binary that is not properly linked
15:02:25 <igel> when invoking the binary i get the error:
15:02:34 <ddarius> (The latter statement being equivalent to "if any light is out you won't be able to see", and indeed (forall light. Out light -> Not See) <=> (exists light. Out light) -> Not See and different from (forall light. Out light) -> Not See
15:03:00 <igel> ./test: error while loading shared libraries: libhelper.so: cannot oben shared object file: no such file or directory
15:03:01 <Peaker> ddarius, yep
15:03:18 <Peaker> well, gotta go. I really appreciate all the help, guys. Thanks!
15:03:32 <igel> long story short: my helper.so is loaded in ghci, but not in the compiled binary
15:05:04 <Saizan> igel: do you pass the same -L -l flags to ghc too?
15:05:17 <igel> i do
15:05:20 <Cale> igel: Perhaps do something like  ldconfig -p | grep libhelper.so  to ensure that ld knows about it?
15:06:19 <igel> Cale: it doesn't
15:06:58 <Cale> If it doesn't show up, then perhaps making sure that the .so is in a path which is in /etc/ld.so.conf or in /lib or /usr/lib
15:07:04 <Cale> will help.
15:07:29 <Cale> Otherwise, you might just have to set LD_LIBRARY_PATH (If I'm recalling that name correctly)
15:07:33 <igel> well i don't have root access to this machine
15:08:03 <igel> there is $LDPATH
15:08:09 <igel> but i already set it to .
15:08:38 <Cale> Try LD_LIBRARY_PATH
15:08:48 <Cale> export LD_LIBRARY_PATH=.
15:09:14 <igel> yay! :)
15:09:19 <igel> this works :)
15:09:20 <igel> thanks
15:09:24 <Cale> okay, good :)
15:27:35 <igel> hmm
15:27:52 <igel> should a function finding out the endianess of a system be IO or not?
15:28:59 <Cale> igel: I suppose that depends on how it works.
15:29:42 <igel> int i = 1; char *array = (char*) &i; return array[0] == 0
15:29:42 <Cale> It probably should be IO, as I don't really see a way to compute it unless Data.Bits exposes something...
15:30:20 <mauke> that looks safely unsafePerformIOable
15:30:22 <Heffalump> it depends what you think about getArgs, really.
15:30:33 <igel> well it has no side effect and always returns the same result
15:30:36 <Heffalump> if you think getArgs should be in IO, then an endianness function should be too
15:30:40 <Heffalump> if not, then not.
15:30:42 <marshmallows> igel: You should use ntohs
15:30:55 <igel> n?
15:30:59 <Heffalump> network
15:31:03 <marshmallows> 0xDEADBEEF == ntohs(0xDEADBEEF);
15:31:05 <mauke> ntohs has the wrong type :(
15:32:34 <oerjan> Cale: Data.Binary.(Put|Get) should be able to do it?
15:32:43 <dmwit> Glorious GHC 6.8.2!
15:33:11 <igel> well this is not about endian, this is my first step to learn how to write c-bindings ;)
15:33:22 <Heffalump> I hope that those are cross-platform!
15:34:05 <nano> hi
15:34:20 <nano> I'm looking for a SoC project and I'm interested in the project desribed in ticket 40. I mailed the interested mentor an learned that he is away until the 31st. Does anyone know if there is someone else I could get in touch with for that project ?
15:34:34 <mauke> igel: you don't need C bindings; you can write the above code in haskell
15:34:52 <igel> but i want to learn to :)
15:35:09 <Cale> igel: In that case, try both ways :)
15:35:16 <igel> :)
15:35:21 <dmwit> nano: http://hackage.haskell.org/trac/summer-of-code/wiki/StudApply2008 ?
15:35:22 <lambdabot> Title: StudApply2008 - Haskell.org Google Summer of Code - Trac
15:36:37 <joricj> Couldn't match expected type `StateT ServerState IO t' against inferred type `IO ClientEvent'
15:36:50 <dmwit> joricj: liftIO, or just lift
15:37:21 <joricj> i have something like "a <- readChan c", ok ill try "a <- lift readChan c"
15:37:26 <Heffalump> lift $ readChan c
15:37:41 <oerjan> joricj: liftIO is better if you might ever change the monad
15:37:54 <joricj> okay it works
15:38:05 <joricj> well, i made a "monad" for my server state
15:38:17 <oerjan> lift will only go one level down
15:38:19 <joricj> but i don't really know how it works ... i mean i have
15:38:33 <oerjan> so will break if you add more transformers
15:38:35 <Cale> lift isn't really something that should show up in applications, it's something which should appear a limited number of times inside a library
15:39:25 <joricj> okay
15:39:29 <nano> dmwit: I thought it would be better to talk to someone who knows the project before applying, is it ?
15:39:38 <Cale> liftIO on the other hand is just fine
15:39:50 <dmwit> nano: yeah, maybe
15:39:55 <Heffalump> nano: it'd be better, but if you can't..
15:40:05 <joricj> i mean i kinda understand simple monads but the transformers and "lifting" o_O
15:40:42 <Cale> joricj: Monad transformers are a way of constructing the monad you're interested in. You should always wrap the result in a newtype, so that it's just a simple monad and becomes less of a hassle to use.
15:41:07 <Cale> joricj: Then you use some combination of lifts and the newtype constructor to build up the primitive computations in your new monad.
15:41:14 <Cale> (and maybe some combinators as well)
15:42:27 <Cale> Monad transformers are something for library designers to worry about. You shouldn't expose them in application code, because that leaves you with a mess. It becomes hard to change the implementation of the monad you're using if you have lots of explicit lifting hanging around.
15:42:41 <Cale> (which means that it becomes hard to add features to that monad if needs be later)
15:42:42 <joricj> i'm sorry but that's beyond me
15:42:47 <joricj> i mean i try to understand
15:42:50 <Cale> okay...
15:43:04 <igel> ok thanks & good night!
15:43:12 <Cale> Well, it's just a sort of engineering detail... :)
15:43:16 <joricj> wait
15:43:28 <joricj> do i have to put 'liftIO $' in front of ALL my code now?
15:43:48 <Cale> Just in front of IO actions which you want to run in your new monad.
15:43:52 <joricj> none of the putStrLns work anymore
15:43:59 <joricj> ok
15:43:59 <Cale> liftIO turns an IO action into an action in your new monad.
15:44:06 <Cale> You may want to write somewhere:
15:44:08 <joricj> can i wrap em the other way around?
15:44:08 <Cale> io = liftIO
15:44:15 <Vulpyne> You could also define a helper function if you don't want to do liftIO $ putStrLn all the time.
15:44:29 <joricj> Vulpyne: yeah i think i'm going to go with that
15:44:37 <Cale> joricj: Well, if your monad has a run function.
15:44:42 <Cale> (which it probably does)
15:45:10 <Cale> runMyMonad foo <other inputs>  might produce an IO computation
15:45:22 <Cale> (from foo, which is a MyMonad computation)
15:45:38 <joricj> i only need to "run" it once so i just use "runStateT (processClientEvents chan) emptyServer"
15:46:24 <Cale> joricj: Okay, then you absolutely must do the lifting from IO up to StateT ServerState IO
15:46:56 <Cale> But you probably should wrap that StateT in a newtype
15:47:19 <Cale> newtype Server a = Server (StateT ServerState IO a)
15:47:48 <Cale> Then you'd derive Functor and Monad using newtype deriving
15:47:56 <Cale> and possibly MonadState ServerState
15:48:09 <Cale> I have to go to dinner, bbiab
15:49:01 <joricj> i should really start adding some type signatures to my code too
15:49:08 <oerjan> joricj: if you do several IO actions in a row you can combine them with liftIO $ do ...
15:49:34 <Vulpyne> I think adding type signatures helps a lot if you're still learning.
15:49:50 <Vulpyne> Because you find out right away if you views for the type of some function are incorrect.
15:50:20 <noecksit> hello, what is the best way that everyone on here installs haskell applications on his comp?
15:50:50 <noecksit> i use gentoo and it has an overlay but it seems really buggy, last time i upgraded it broke my dependencies
15:51:01 <bd_> I use APT :)
15:51:05 <joricj> apt
15:51:18 <noecksit> id like to put happs on my server but am worried it might break some stuff
15:51:22 <noecksit> apt-get?
15:51:46 <bd_> well, debian and ubuntu seem to keep reasonably up-to-date with haskell stuff... when they're not in freeze anyway
15:51:52 <joricj> its not for gentoo i think
15:53:52 <noecksit> for gentoo, some stuff like xmonad, happs, & ghc 6.8.2 is not in the stable releases
15:54:46 <noecksit> i was thinking about doing it all from source too
15:57:02 <jsnx_> :t eof
15:57:03 <lambdabot> Not in scope: `eof'
15:57:55 <jsnx> :t eof
15:57:56 <lambdabot> Not in scope: `eof'
15:59:45 <oerjan> :t isEOF
15:59:45 <lambdabot> Not in scope: `isEOF'
15:59:51 <oerjan> :t System.IO.isEOF
15:59:52 <lambdabot> IO Bool
16:00:10 <jsnx> i'm trying to make a parser that consumes a newline and fails
16:00:18 <jsnx> or consumes EOF and fails
16:00:29 <jsnx> (parsec EOF, not ^D)
16:00:33 <oerjan> um if it fails it cannot consume, at least in Parsec
16:00:44 <jsnx> oerjan: well, okay
16:01:13 <jsnx> hmm
16:02:05 <oerjan> notFollowedBy
16:02:20 <jsnx> oerjan: yeah
16:02:24 <jsnx> does not eat!
16:02:41 <jsnx> maybe i am not think about this problem
16:02:45 <jsnx> the right way
16:03:10 <jsnx> oerjan: also, 'notFollowedBy newline; notFollowedBy eof' doesn't work
16:03:19 <jsnx> it's not typable, apparently
16:03:24 <oerjan> you probably need a try around the newline
16:03:34 <mauke> yes, because notFollowedBy is actually broken and has the wrong type
16:03:44 <jsnx> mauke: what type should it have?
16:04:00 <mauke> Parser a -> Parser ()
16:04:06 <oerjan> it does
16:04:11 <oerjan> at least in the manual
16:04:25 <mauke> :t notFollowedBy
16:04:26 <lambdabot> Not in scope: `notFollowedBy'
16:04:45 <oerjan> :t Text.ParserCombinators.Parsec.notFollowedBy
16:04:46 <lambdabot> forall tok st. (Show tok) => Text.ParserCombinators.Parsec.Prim.GenParser tok st tok -> Text.ParserCombinators.Parsec.Prim.GenParser tok st ()
16:04:58 <mauke> that's Parser Char -> Parser ()
16:05:16 <nibro> @where hpaste
16:05:16 <lambdabot> I know nothing about hpaste.
16:05:21 <nibro> @where hspaste
16:05:21 <lambdabot> I know nothing about hspaste.
16:05:29 <nibro> bah, what am I looking for? :)
16:05:31 <oerjan> tok it says
16:05:37 <nibro> @where paste
16:05:37 <lambdabot> http://hpaste.org/new
16:05:40 <nibro> ah
16:05:44 <jsnx> :t Text.ParserCombinators.Parsec.notFollowedBy Text.ParserCombinators.Parsec.eof
16:05:46 <lambdabot> forall st. Text.ParserCombinators.Parsec.Prim.GenParser () st ()
16:05:52 <jsnx> :t Text.ParserCombinators.Parsec.notFollowedBy Text.ParserCombinators.Parsec.newline
16:05:54 <lambdabot> forall st. Text.ParserCombinators.Parsec.Prim.GenParser Char st ()
16:05:59 <oerjan> @where+ hpaste http://hpaste.org/new
16:05:59 <lambdabot> Okay.
16:06:22 <oerjan> oh dear
16:06:47 <jsnx> oerjan: ?
16:06:50 <oerjan> i see it can only do single-char lookahead
16:06:58 <oerjan> jsnx: mauke was right
16:07:21 <jsnx> what is `Parser` ?
16:07:34 <jsnx> all i see are these `GenParser`s
16:07:58 <newsham> "Parser a" is a parser for type a
16:08:02 <mauke> type Parser a = GenParser Char () a  or something like that
16:08:43 <jsnx> yeah, found it
16:09:05 <jsnx> so, how to fix notFollowedBy...
16:09:06 <oerjan> jsnx: the point is that tok occurs twice in the type of notFollowedBy's first argument - it is forced to parse the same as the terminal token type
16:09:15 <oerjan> it should work fine with newline
16:09:22 <jsnx> oerjan: but not eof
16:09:39 <oerjan> nevertheless
16:09:52 <jsnx> oerjan: so, i can make a new one, i guess
16:09:52 <mauke> eof = notFollowedBy anyChar, so not eof == followedBy anyChar
16:09:59 <mauke> which I don't think exists
16:10:28 <oerjan> never mind
16:10:45 <oerjan> followedBy (noneOf "\n")
16:10:54 <oerjan> i think that should combine both
16:13:07 <oerjan> :t Text.ParserCombinators.Parsec.followedBy (Text.ParserCombinators.Parsec.noneOf "\n")
16:13:08 <lambdabot>     Not in scope: `Text.ParserCombinators.Parsec.followedBy'
16:13:24 <oerjan> :t Text.ParserCombinators.Parsec.notFollowedBy (Text.ParserCombinators.Parsec.noneOf "\n")
16:13:25 <lambdabot> forall st. Text.ParserCombinators.Parsec.Prim.GenParser Char st ()
16:13:46 <oerjan> *notFollowedBy (noneOf "\n")
16:13:56 <oerjan> er wait
16:14:00 <oerjan> sheesh
16:16:44 <mofmog> can i consider a zipper a monad?
16:17:07 <Baughn> mofmog: You could certainly make it one
16:17:12 <Cale> mofmog: Usually not, but every zipper has an associated monad.
16:17:18 <mofmog> more importantly
16:17:29 <mofmog> is a monad the data, the function, bind/return or all of the above?
16:17:32 <mofmog> which part is the "monad"
16:17:42 <Cale> mofmog: The type constructor
16:17:57 <Cale> (but it must have return and bind implemented satisfying the laws of course)
16:18:20 <Cale> The type constructor is the name of the monad though.
16:18:24 <Cale> So Maybe is a monad
16:18:27 <mofmog> and then... a comonad is like a monad but it follows the rules backwards
16:18:27 <Cale> Just 5 is not a monad
16:18:40 <Cale> Yeah, it has its own flipped over rules.
16:19:12 <mofmog> ok, so far i've been thinking of monads as some piece of data and a bunch of stuff you don't -really- care about but you sort of do latched onto it
16:19:36 <mofmog> and then bind can slice off the baggage or do what it wants with it and then feeds the function some clean data it can work with
16:19:52 <Cale> getLine isn't a monad
16:20:03 <Cale> IO is a monad, and getLine is a computation typed in that monad.
16:20:24 <mofmog> ok, so any computation within the monad
16:20:31 <mofmog> latches stuff onto some sort of data
16:20:49 <Cale> Sort of.
16:21:35 <Cale> Well, it's kind of odd to look at it that way in many cases.
16:21:39 <mofmog> ?
16:21:48 <Cale> For example, getLine is a computation which produces a String
16:22:00 <mofmog> yes
16:22:02 <mofmog> hmm
16:22:36 <Cale> You could think of that as being a huge array of Strings which are indexed by possible states of the world (and include new states of the world along with them), but it's a little strange to look at it like that
16:22:53 <mofmog> so...
16:23:19 <mofmog> @t getLine
16:23:19 <lambdabot> Maybe you meant: tell temp thank you thanks thx time tiny-url todo todo-add todo-delete topic-cons topic-init topic-null topic-snoc topic-tail topic-tell type . ? @ ft v
16:23:28 <Cale> :t getLine
16:23:29 <lambdabot> IO String
16:23:45 <Baughn> Cale: That's the sort of metaphysics people who ponder dovetail algorithms get into. I never expected to see it in #haskell..
16:24:03 <mofmog> could you say it's type is ???? -> IO String
16:24:08 <Cale> dovetail algorithms?
16:24:32 <mofmog> ???? meaning "mysterious stateful input from the user"
16:24:44 <oerjan> Baughn: it follows pretty swiftly from ghc's IO definition...
16:24:44 <Baughn> Cale: Running every possible turing machine simultaneously (by interleaving). Forever.
16:24:46 <oerjan> @src IO
16:24:46 <lambdabot> newtype IO a = IO (State# RealWorld -> (# State# RealWorld, a #))
16:25:12 <Cale> Of course, the implementation suggested by @src is a total cheat.
16:25:37 <Trinithis> why
16:25:45 <Trinithis> the # signs?
16:25:50 <Cale> But yeah, if you want, you could use that as a mental model, at least until you get to dealing with concurrency.
16:25:59 <Cale> The # signs just indicate unboxing
16:26:15 <nibro> it's a cheat because there is no such thing as a RealWorld :)
16:26:21 <Cale> Right.
16:26:28 <Trinithis> :D
16:26:41 <Philippa> RealWorld = void :-)
16:26:53 <Cale> and so what really happens is that a RealWorld token is passed along to get the data dependencies straight in the compiler
16:27:01 <Cale> But side effects are put into the ->
16:27:09 <Cale> Very hadky.
16:27:11 <Cale> hacky*
16:27:22 <mofmog> alright, so getLine returns a string in some container called "IO"
16:27:26 <Cale> There could be a pure implementation of the IO monad using GADTs though
16:27:31 <Cale> It would look something like:
16:27:37 <Cale> data IO a where
16:27:43 <Cale>    ReturnIO :: a -> IO a
16:27:54 <Cale>    BindIO :: IO a -> (a -> IO b) -> IO b
16:28:02 <Cale>    GetChar :: IO Char
16:28:14 <Cale>    PutStr :: String -> IO ()
16:28:27 <Cale>    ForkIO :: IO a -> IO ThreadId
16:28:28 <nibro> mofmog: RealWorld is the real world, i.e. everything outside your program, and that's where getLine takes the string from
16:28:29 <Cale>    ...
16:28:47 <Cale> and the Haskell runtime would just take apart this data structure and carry out the actions
16:29:05 <nibro> the magic IO type is just there to make the ugliness of the real world implicit so you don't have to see it
16:29:07 <Cale> That is, the primitive IO actions are just values
16:29:11 <Trinithis> Cale, you say that GADTs can create pure IO ... but don't monads already solve that?
16:29:19 <Cale> Trinithis: hm?
16:29:20 <mofmog> wait
16:29:25 <mofmog> isnt that already a monad?
16:29:41 <Cale> mofmog: Trivially so, yes, up to a certain equivalence.
16:29:52 <Baughn> mofmog: Whatever you do, don't ever use unsafe functions on RealWorld. Haskell's normal type-checking prevents you from corrupting it, which is fine, but you don't want to see the consequences if someone alters Beijing and forgets to set it back.
16:29:53 <Trinithis> Cale: Isn;t IO already pure so to speak because it is implemented as a monad
16:29:56 <Cale> So return and bind would just be constructors of the data type.
16:30:06 <Cale> Trinithis: The implementation of the IO monad in GHC is not pure.
16:30:21 <Cale> Trinithis: it involves side-effecting functions
16:30:44 <Trinithis> Cale: to the programmers perspective does it matter? or am I missing somethign
16:31:07 <Cale> Trinithis: It doesn't really matter to the user of IO so much, no.
16:31:21 <svalkii> http://www.svalki.info/index.php
16:31:22 <lambdabot> Title: Свалки
16:31:23 <svalkii> http://www.svalki.info/index.php
16:31:23 <lambdabot> Title: Свалки
16:31:25 <svalkii> http://www.svalki.info/index.php
16:31:25 <lambdabot> Title: Свалки
16:31:26 <Cale> But it would be nice to have a real pure IO monad, because then IO computations could be inspected.
16:31:27 <svalkii> http://www.svalki.info/index.php
16:31:28 <lambdabot> Title: Свалки
16:31:29 --- mode: ChanServ set +o Cale
16:31:29 <jsnx> so, when i think about what i'm doing, `notFollowedBy eof` is a little vague
16:31:29 <svalkii> http://www.svalki.info/index.php
16:31:30 <lambdabot> Title: Свалки
16:31:31 <mofmog> can we kick him?
16:31:33 --- mode: Cale set +b svalkii!*@*
16:31:35 <mofmog> wtf was that
16:31:44 <Cale> damn, wrong menu item
16:31:59 --- mode: Cale set +b *!*@78.154.5.144
16:32:09 --- mode: Cale set -b svalkii!*@*
16:32:30 <jsnx> so, what i want to say is something like `eof && fail` (if this were shell programming)
16:32:34 --- mode: Cale set -o Cale
16:34:44 <jaj> Cale: but isn't IO unpure by definition?
16:35:01 <Cale> jaj: No. The carrying out of IO actions is impure.
16:35:19 <Cale> IO actions themselves need not be implemented using impure values.
16:36:03 <Cale> They could even be implemented internally as strings representing C programs (sort of)
16:36:50 <Cale> (I say sort of because there may be some issues with laziness in that case, but basically, you could)
16:37:52 <dibblego> newtype U = U T -- is it possible to somehow automatically inherit all type-class instances over T?
16:38:02 <oerjan> ah
16:38:16 <Cale> dibblego: Not quite, but using newtype deriving, you can get any individual ones you want.
16:38:33 <dibblego> Cale, isn't deriving restricted to certain type-classes?
16:38:48 <dibblego> hmm, I guess not, cheers
16:38:57 <Cale> Normally, but GHC has an extension called newtype deriving which lets you do almost any class.
16:39:04 <dibblego> ok thanks
16:40:16 <jsnx> so basically, `notFollowedBy` is supposed to be a 'parser negator'
16:40:23 <Cale> jsnx: yeah
16:40:29 <jsnx> but it doesn't quite work
16:40:35 <Cale> jsnx: How so?
16:41:00 <jsnx> `do{ notFollowedBy newline; notFollowedBy eof }`
16:41:04 <jsnx> is not typable
16:41:13 <Cale> :t notFollowedBy
16:41:14 <lambdabot> Not in scope: `notFollowedBy'
16:41:26 <Cale> :t Text.ParserCombinators.Parsec.notFollowedBy
16:41:27 <lambdabot> forall tok st. (Show tok) => Text.ParserCombinators.Parsec.Prim.GenParser tok st tok -> Text.ParserCombinators.Parsec.Prim.GenParser tok st ()
16:41:33 <darrint> Is there an algorithm which will take a large number of permutations of different symbols and select a small number optimized for "diversity"?
16:41:50 <Cale> jsnx: why not?
16:42:08 <mofmog> small number of symbols or permutations?
16:42:15 <jsnx> :t Text.ParserCombinators.Parsec.notFollowedBy Text.ParserCombinators.Parsec.eof
16:42:16 <lambdabot> forall st. Text.ParserCombinators.Parsec.Prim.GenParser () st ()
16:42:22 <jsnx> :t Text.ParserCombinators.Parsec.notFollowedBy Text.ParserCombinators.Parsec.newline
16:42:23 <lambdabot> forall st. Text.ParserCombinators.Parsec.Prim.GenParser Char st ()
16:42:28 <darrint> mofmog: permutations
16:42:45 <jsnx> Cale: for some reason, `notFollowedBy eof` is not a char parser
16:43:08 <jsnx> it is a `()` parser!
16:43:10 <dibblego> is there a way of determining which pragma to use given a GHC option?
16:43:16 <mofmog> well if you had some way of defining how different something is on a certain dimension
16:43:19 <Cale> uh, that looks like GHC's extended defaulting
16:43:32 <Cale> :t Text.ParserCombinators.Parsec.notFollowedBy Text.ParserCombinators.Parsec.eof >>  Text.ParserCombinators.Parsec.notFollowedBy Text.ParserCombinators.Parsec.newline
16:43:33 <lambdabot>     Couldn't match expected type `()' against inferred type `Char'
16:43:33 <lambdabot>       Expected type: Text.ParserCombinators.Parsec.Prim.GenParser
16:43:33 <lambdabot>                        () st ()
16:43:38 <Cale> odd
16:43:43 <mofmog> you could group them together, figure out natural breaks through some sort logic and then take one from each group
16:43:44 <Cale> :t Text.ParserCombinators.Parsec.eof
16:43:45 <lambdabot> forall tok st. (Show tok) => Text.ParserCombinators.Parsec.Prim.GenParser tok st ()
16:43:59 <Cale> hmm
16:44:08 <darrint> mofmog: I'm dealing with symbols like i386 vs. x86_64 and some other symbols for operating systems and other parameters.
16:44:38 <Cale> really strange...
16:44:47 <darrint> mofmog: I could describe this as I'm narrowing down test configurations from an impossible amount to a smaller amount that it still "good".
16:45:24 <jsnx> Cale: so, i am trying to rewrite it
16:45:47 <jsnx> but it's a little weird to write something for Parsec that says if i succeed, fail
16:45:56 <jsnx> because the `if` part is hard to do
16:46:05 <Cale> oh!
16:46:09 <Cale> I see why
16:46:16 <Cale> notFollowedBy :: forall tok st.
16:46:16 <Cale>                  (Show tok) =>
16:46:16 <Cale>                  GenParser tok st tok -> GenParser tok st ()
16:47:26 <jsnx> Cale: right
16:47:46 <Cale> That's a bug.
16:47:52 <jsnx> Cale: aye
16:47:56 <Cale> The type signature for notFollowedBy in the library is wrong.
16:48:06 <Cale> (explicit and wrong)
16:48:14 <Cale>  notFollowedBy p = try (do{ c <- p; unexpected (show [c]) } <|> return ())
16:48:27 <Cale> If you write that, it'll get a more general type.
16:48:57 <jsnx> Cale: so the error is *just* in the type signature?
16:49:01 <Cale> yep
16:49:51 <mofmog> alright, i've decided tiling window managers aren't all that nifty
16:50:27 <oerjan> Cale: there is a problem with that though.  your version will show a representation of the _result_ rather than the actual parsed text
16:50:32 <Cale> mofmog: It seems you've decided the same as me. xmonad is really cool apart from that fact.
16:50:51 <mofmog> Cale: yeah. I like the extensibility in haskell part. But tiling just feels overly restrictive
16:50:56 <Cale> oerjan: It's the same implementation.
16:51:06 <mofmog> if they had floating windows say, i wonder if that would inflate the code
16:51:19 <mofmog> because it seems as if .5k lines is a selling point
16:51:29 <oerjan> Cale: i think it is restricted because otherwise the error messages won't be sensible
16:51:32 <esteth> mofog: There are floating windows
16:51:36 <Cale> mofmog: Well, they do have floating windows, but not window borders
16:51:36 <esteth> right click and drag a window
16:51:45 <Cale> and poor EWMH support.
16:51:58 <mofmog> esteth: that's like saying Haskell has support for state
16:51:59 <esteth> erm sorry, that was misinformation. Hold the mod key and left click drag
16:52:11 <mofmog> while true in a practical and technical sense
16:52:11 <jsnx> oerjan: well, i'm going to try it out now
16:52:14 <mofmog> that's not what i meant
16:52:21 <esteth> oh, ok.
16:52:52 <kjdf> it is possible to deduce necessary type of a function given a "format string"
16:52:58 <kjdf> an example of this is Text.Printf
16:53:06 <kjdf> is it possible the other way around?
16:53:29 <Cale> kjdf: Actually Text.Printf doesn't look at the format string at all
16:53:43 <Cale> kjdf: It's just incredibly polymorphic and not typesafe.
16:53:59 <kjdf> hm
16:54:04 <ddarius> It should be type safe, albeit not statically.
16:54:11 <Cale> oh, I suppose yeah
16:54:23 <Cale> It's "type safe" in the dynamic types sense.
16:54:36 <Cale> I just don't consider those to be types ;)
16:54:36 <jsnx> so in fact, this new one type checks
16:54:38 <kjdf> hm
16:54:44 <kjdf> actually that might answer my question
16:54:49 <jsnx> but of course it does not do anything in the eof case
16:54:57 <kjdf> or am I wrong? :)
16:55:02 <Cale> kjdf: Types are purely a compile time thing.
16:55:10 <jsnx> because that always drops through to `return ()`
16:55:11 <ddarius> kjdf: The answer to your question is "no" (in Haskell)
16:55:15 <Cale> kjdf: They're stripped away by compilation.
16:56:59 <jsnx> Guitar Hero is not about music -- any more than Call Of Duty 4 is about infantry tactics
16:57:19 <ddarius> jsnx: Now try it again in the right channel.
16:57:41 <jsnx> ddarius: i do that every so often
16:57:55 <ddarius> I think I've done that once... ever.
16:58:16 <wkh> CoD 4 is about being a one-man arab/slav genocide machine
16:58:20 <Cale> I've typed shell commands into IRC :)
16:58:28 <jsnx> ddarius: on mac, the keys are different for switching windows -- and i move between mac and linux erratically
16:58:39 <marshmallows> kjdf: Sage, Omega, Epigram(?), Agda 2, Coq let you do this
16:58:55 <marshmallows> I think Charity, DML .. can maybe
16:59:19 <Cale> Is Charity dependently typed?
16:59:23 <Cale> I didn't think so...
16:59:40 <marshmallows> double checking..
17:00:14 <marshmallows> ok yeah, I think I imagined a printf example for that but there isn't one, sorry
17:00:40 <jsnx> so, it looks like i will have to do some monad wrapping/unwrapping stuff to write `parserNegate`
17:00:53 <Cale> jsnx: hm?
17:01:03 <Cale> doesn't that notFollowedBy work okay?
17:01:12 <jsnx> Cale: it does not fail on `eof`
17:01:28 <jsnx> because it always falls through to `return ()`
17:01:35 <marshmallows> s/Charity/Cayanne/ !
17:01:39 <marshmallows> that's what I meant
17:01:46 <jsnx> we need a `<!>` operator :)
17:02:36 <Cale> jsnx: But if the eof parser succeeds, then it should throw an error
17:02:42 <Cale> shouldn't it?
17:03:10 <Cale> hmm
17:03:49 <Cale> jsnx: I think what you're looking for is  lookAhead anyToken
17:03:55 <Cale> (in any event)
17:04:44 <jsnx> Cale: well, that does not generalize
17:04:59 <Cale> wha?
17:05:08 <Cale> It's pretty general...
17:05:13 <jsnx> Cale: doesn't work for newline, &c.
17:05:25 <Cale> lookAhead anyToken :: forall tok st. (Show tok) => GenParser tok st tok
17:06:04 <Cale> after all, eof = notFollowedBy anyToken
17:06:04 <jsnx> Cale: okay, i will try it
17:06:31 <oerjan> Cale: darn yet another one not mentioned in daan's manual
17:14:05 <fophillips> Are there any existing pseudo-terminal bindings?
17:16:05 <qebab> if you've got some time to kill, and you're interested in education, you might want to check out: http://www.maa.org/devlin/LockhartsLament.pdf :) I rarely find essays that I agree so much with
17:17:08 <jsnx> Cale: so, i could go along with your suggestion -- but wouldn't it be much cooler to have a general parser negater?
17:17:09 <Cale> qebab: Yeah, I read that last week and sent it to a bunch of my friends.
17:17:25 <Cale> jsnx: sure
17:17:54 <qebab> Cale: I was lucky enough to have a real teacher for a few years in school, I doubt I'd be anywhere near as curious as I am without that
17:18:08 <qebab> so it was easy to agree with it :)
17:19:15 <Cale> qebab: I read Gödel, Escher, Bach by Hofstadter and ended up going to university for pure mathematics as a result :)
17:19:23 <qebab> cool
17:19:28 <qebab> I haven't gotten to reading that yet
17:19:34 <qebab> I meant to, at some point
17:19:54 <ddarius> GEB would never have made me want to go into pure mathematics.
17:20:00 <Cale> and of course, once I went, I found out just how cheated out of 8 years of my life I'd been
17:20:01 <dibblego> me neither :)
17:20:36 <qebab> we had a really awesome lecturer in our first year of maths at university
17:21:12 <qebab> I learnt more maths the first 2 months than I had after 12-13 years of school
17:22:33 <Cale> Er, I suppose I'd meant to count the 4 years of highschool. I was well aware that the 8 years of elementary school before that were a complete waste of time at the time.
17:23:13 <Cale> Highschool was actually a bit better for most subjects than it was for math. I don't blame my teachers though, it's just that the curriculum sucks and they have no control over it.
17:24:14 <Cale> The examples given at the start of Lockhart's Lament are ones which I've used quite often (well before seeing it)
17:24:26 <Cale> In music class, we actually played and listened to music.
17:24:39 <Cale> In art class, we actually painted pictures and sculpted clay.
17:25:16 <ddarius> Cale: The problem is that the courses are simply misnamed.  "Calculation class"
17:25:43 <Cale> Indeed. "How to be a calculator" or "Calculator ownership" would be much better titles.
17:25:47 <Twey> A class on how to push buttons on a calculator, obviously.
17:26:55 <thoughtpolice> i need to finish reading GEB. it's a fascinating book. i think my math teacher when I was a junior in hs (last year) had the right idea. she didn't let us use calculators until after chapter exams and tests.
17:27:08 <thoughtpolice> she was also very eloquent when it came to math so that is also a plus.
17:27:29 <thoughtpolice> or i should say explaining it.
17:27:58 <Cale> thoughtpolice: Mathematics and the explanation of mathematics are one and the same :)
17:28:54 <jsnx> Cale: would Gauss have agreed ? :)
17:29:01 <lament> for what it's worth, GEB kinda sucks in its portrayal of Bach.
17:30:53 <ddarius> We should resurrect Gauss
17:31:02 <roconnor> Zombie Gauss
17:31:33 <Cale> jsnx: Possibly not, but he didn't have the benefit of late 19th century/early 20th century logicians
17:31:49 <lament> resurrect Gauss and Hitler as zombies, and make them fight!
17:32:36 <fophillips> Hitler lives in a red bus on the Moon, no need to resurrect him.
17:32:43 <wkh> zombie gauss would build a giant tesla coil and blow zombie hitler to bits
17:32:59 <lament> that kinda sounds like something zombie tesla would do
17:33:36 <wli> No need to resurrect him. His side won the Cold War.
17:34:04 <opqdonut> :P
17:36:02 <SimonRC> argh not again
17:36:20 <ddarius> Every night, same old "resurrecting Gauss" conversation
17:36:36 <SimonRC> #haskell is talking about random stuff and #haskell-blah is talking about HAskell
17:36:41 <EvilTerran> yeah, well, someone keeps resurrecting "resurrecting Gauss"
17:36:46 <SimonRC> I do beleive you are the wrong way round
17:36:52 <lament> "what are we doing today, brain?"
17:37:02 <wli> Ut nihil amplius desiderandum relictam sit?
17:37:08 <oerjan> @brain -- also relevant to zombies?
17:37:08 <lambdabot> Umm, I think so, Brain, but what if the chicken won't wear the nylons?
17:37:13 <SimonRC> hehehe
17:37:23 <olsner> you guys are making oklofok seem sane
17:37:28 <Cale> #haskell is only for discussion of zombies
17:37:43 <mauke> @keal
17:37:43 <lambdabot> can haskell compile flash animations and java apps?
17:37:50 <Cale> @keal
17:37:50 <lambdabot> obviously you never heard of Tier. theoretically it would work using nanobots
17:37:56 <Cale> @keal
17:37:57 <lambdabot> i cant think anymore
17:38:01 <Cale> Keal was the best
17:38:02 <Cale> @keal
17:38:02 <lambdabot> when i put what i dat recoved from that tile into a ti92. the damn thing blew up
17:38:14 <SimonRC> where do these qoutes come from
17:38:15 <Cale> @keal
17:38:15 <lambdabot> today's 24hour project was supposed to be logical overloading using plegm method
17:38:20 <Japsu> @faq can haskell compile flash animations and java apps?
17:38:20 <lambdabot> The answer is: Yes! Haskell can do that.
17:38:20 <SimonRC> who compiled them and how?
17:38:23 <Cale> SimonRC: A real guy who used to come here
17:38:44 <Cale> SimonRC: Apparently he has schizophrenia and when he was off his meds, he liked to IRC.
17:38:56 <Japsu> @remember SimonRC where do these quotes come from
17:38:56 <lambdabot> It is forever etched in my memory.
17:39:05 <Japsu> ^__^
17:39:30 <Japsu> that's where
17:39:32 <Cale> (at least, this is his story from when he was apparently a bit saner)
17:39:33 <EvilTerran> Cale, seriously?! O.o
17:39:37 <Cale> EvilTerran: apparently
17:39:41 <Cale> @kean
17:39:41 <lambdabot> i changed my user od
17:39:42 <Cale> @keal
17:39:42 <lambdabot> i dont really eat vegetables unless cheese is a vegetable
17:39:49 <EvilTerran> huh. takes all sorts, eh.
17:39:55 <Cale> @keal
17:39:55 <lambdabot> i dont really eat vegetables unless cheese is a vegetable
17:39:56 <Cale> @keal
17:39:56 <lambdabot> can haskell pipe the raw irrational megaequation into an analog device
17:40:07 <EvilTerran> ... what
17:40:11 <Cale> @faq can haskell pipe the raw irrational megaequation into an analog device
17:40:11 <lambdabot> The answer is: Yes! Haskell can do that.
17:40:17 <EvilTerran> @cale
17:40:17 <ddarius> Someone has added more
17:40:17 <lambdabot> Unknown command, try @list
17:40:27 <SimonRC> @quote SimonRC
17:40:27 <lambdabot> SimonRC says:  if performance was that important, people would be using perl, python, or the JVM
17:40:31 <thoughtpolice> @ghc
17:40:31 <lambdabot> ghc says: All the type patterns for a generic type constructor must be identical
17:40:39 <SimonRC> huh, that quote is backwards
17:40:40 <Cale> @keal
17:40:40 <lambdabot> bot seems useless
17:40:42 <Cale> @keal
17:40:42 <lambdabot> ithink has to do with hardcased government failsafe in chip
17:40:43 <SimonRC> @quote SimonRC
17:40:44 <lambdabot> SimonRC says:  if performance was that important, people would be using perl, python, or the JVM
17:40:49 <Cale> @keal
17:40:49 <lambdabot> 99% of my book has been erased by faulty hdd's
17:40:55 <Cale> @keal
17:40:56 <lambdabot> are you saying i am MegaMonad?
17:40:59 <Cale> @keal
17:40:59 <lambdabot> nsa prevent me from returning to math on efnet
17:41:16 <roconnor> *L*
17:41:20 <roconnor> damn hdds
17:41:57 <thoughtpolice> hah. i want actual logs of this person.
17:42:17 <EvilTerran> ?where logs
17:42:17 <lambdabot> http://tunes.org/~nef/logs/haskell/ http://meme.b9.com/cdates.html?channel=haskell
17:42:18 <Cale> @protontorpedo
17:42:18 <lambdabot> how does haskell compare to c++?
17:42:20 <Cale> @protontorpedo
17:42:20 <lambdabot> lazy makes macro not needed?
17:42:23 <Cale> @protontorpedo
17:42:23 <lambdabot> how would haskell solve the following gnarley problem: many client distributed accross the usa, transfers must take palce in the form of file transfer, and data must be read from files, and recorded,
17:42:23 <lambdabot>  then other partners who apply taxes to this data and then give abck new files with taxes aded, then last transers to 4th parties who get us paid for the phone calls that are the product
17:42:25 <EvilTerran> knock yourself out
17:42:42 <Cale> @protontorpedo
17:42:42 <lambdabot> hakell is not lisp or ml right?
17:42:47 <Cale> hehe
17:43:19 <Cale> In the amount of time protontorpedo spent asking questions like that, he could have become a master Haskell programmer.
17:43:58 <Twey> Haha
17:44:19 <mauke> g.schuett is an ancient troll
17:44:27 <Valodim_> seeing his questions - I doubt that
17:44:33 <marshmallows> maybe protontorpedo is one of the GHC implementors
17:44:35 <mauke> IIRC he's been doing this for 10+ years
17:44:46 * EvilTerran blinks
17:45:00 <EvilTerran> even #haskell's trolls are of the finest quality, apparently
17:45:20 <oerjan> @remember EvilTerran even #haskell's trolls are of the finest quality, apparently
17:45:20 <lambdabot> Done.
17:45:25 <EvilTerran> :D
17:45:56 <marshmallows> how are protontorpedos questions not reasonable?
17:46:04 <olsner> haskell seems to attract both genius and insanity
17:46:09 <marshmallows> it just sounds like a curious person wanting to get into haskell to me...
17:46:20 <Cale> marshmallows: They're not reasonable because he had no intention whatsoever to learn the language.
17:46:56 <Cale> marshmallows: He just asked questions like that for a few years without actually asking a single question about Haskell itself.
17:47:02 <thoughtpolice> http://code.haskell.org/lambdabot/Plugin/Quote/Text.hs
17:47:57 <olsner> hmm, why doesn't the ircbrowse search page actually have a search function?
17:48:01 <thoughtpolice> look there. it's fairly evident that it's just random questions, nothing -really- to do with haskell.
17:48:46 <Valodim_> "so if I learn haskell i can make cool interactive websites and get rich right?" <- sounds like the legitimate curious question of a ten year old to me
17:49:34 <Cale> Valodim_: That's the idea.
17:49:51 <Cale> Valodim_: When it goes on for a year, you start to wonder ;)
17:50:09 <TomMD> Valodim_: Thats what I ask my self every day about almost every Haskell library.
17:50:23 <Cale> TomMD: hehe
17:50:25 <Valodim_> what?
17:50:31 <Valodim_> the quote?
17:50:33 <ddarius> @faq Can Haskell make me rich?
17:50:33 <lambdabot> The answer is: Yes! Haskell can do that.
17:50:56 <oerjan> > cycle "This is the song that never ends, yes it goes on and on my friend. Some people started singing it, not knowing what it was, and they'll continue singing it forever just because... "
17:51:00 <TomMD> @faq Will Haskell inspire the FringeDC goers?
17:51:01 <lambdabot>  "This is the song that never ends, yes it goes on and on my friend. Some peo...
17:51:01 <lambdabot> The answer is: Yes! Haskell can do that.
17:51:07 <lispy> ?faq Can Haskell create a thunk so big even Haskell can't evaluate it?
17:51:08 <lambdabot> The answer is: Yes! Haskell can do that.
17:51:22 <Cale> ...If your name is John Launchbury ;)
17:51:31 <ddarius> lispy: Quite easily too.
17:51:33 <Cale> (re: Can Haskell make me rich :)
17:52:53 <oerjan> > foldl (flip (:)) [] [1..1000000] -- hm or this might actually work
17:52:54 <lambdabot>  [1000000,999999,999998,999997,999996,999995,999994,999993,999992,999991,9999...
17:53:16 <Cale> > foldl (+) 0 [1..1000000]
17:53:17 <lambdabot>  500000500000
17:53:18 <roconnor> @src reverse
17:53:19 <lambdabot> reverse = foldl (flip (:)) []
17:53:25 <Cale> Compiles with -O :)
17:53:31 <Cale> Or perhaps -O2
17:53:34 <Cale> I forget
17:53:43 <oerjan> does that work with Integer nowadays?
17:53:51 <lispy> roconnor: I love that definition of reverse
17:54:05 <roconnor> lispy: is it efficent?
17:54:14 <roconnor> I'm used to there being an accumulator.
17:54:26 <lispy> roconnor: I think so, not sure, but it's cool because it's saying you just flip the conses
17:54:32 <oerjan> @src foldl
17:54:32 <lambdabot> foldl f z []     = z
17:54:32 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
17:54:54 <kjdf> actually Text.printf does exactly what I wanted to do
17:54:58 <oerjan> there is an accumulator there
17:55:07 <kjdf> constructs a list of concrete representation of types
17:55:15 <kjdf> (and then does its own thing)
17:55:20 <roconnor> oerjan: the z?
17:55:24 <jsnx> http://www.cse.ogi.edu/~jl/Haskell/poem.html
17:55:25 <oerjan> yeah
17:55:25 <lambdabot> Title: A Haskell Lover's Plea
17:55:33 <lispy> Cale: H98 type system is not turing complete, right?
17:55:41 <Cale> lispy: right
17:55:46 <Cale> but GHC's is
17:55:54 <lament> so GHC can hang during compilation?
17:56:01 <lispy> lament: yeah
17:56:03 <ddarius> Cale: Only in a pretty well-defined case (plus bugs)
17:56:14 <ddarius> lament: It can do that without extensions due to its inliner.
17:56:19 <lispy> lament: a friend of mine who got his PhD last year had it hang on him a couple times :)
17:56:31 <TSC> It only hangs for PhDs (:
17:57:07 <lispy> "How I too wish to mutate memory with thoughts born of von Neumann earthiness! "
17:58:24 <lispy> jsnx: that's clever
17:58:44 <kjdf> can someone tell me in a few words what Data.Typeable does and what can it be used for?
17:59:06 <mauke> reflects types as values
17:59:09 <kjdf> or where I can learn more about it
17:59:18 <mauke> :t cast
17:59:18 <oerjan> @src Typeable
17:59:18 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
17:59:20 <lambdabot> forall a b. (Typeable b, Typeable a) => a -> Maybe b
17:59:57 <oerjan>  @src, may a thousand flees descend upon your camels
18:00:02 <kjdf> and what can I do with these values?
18:00:10 <oerjan> *fleas
18:00:30 <thoughtpolice> kjdf: iirc, the 'scrap your boilerplate' papers had some examples of using typeable for generics
18:00:42 <lispy> http://www.haskell.org/ghc/docs/latest/html/libraries/base/Data-Typeable.html
18:00:43 <lambdabot> http://tinyurl.com/ynu4qa
18:00:53 <thoughtpolice> http://www.cs.vu.nl/boilerplate/#papers
18:00:54 <lambdabot> Title: Scrap your boilerplate ... in Haskell
18:00:56 <mauke> @let (===) :: (Eq a, Typeable a, Typeable b) => a -> b -> Bool; x === y = Just a == cast b
18:00:57 <lambdabot> Defined.
18:01:04 <mauke> php-style
18:01:13 <mauke> > True === '?'
18:01:14 <lambdabot>  False
18:01:17 <mauke> > '?' === '?'
18:01:18 <lambdabot>  False
18:01:28 <mauke> what
18:01:31 <kjdf> :)
18:01:44 <mauke> why you do this :(
18:01:45 <oerjan> mauke: i don't think you want a and b there :)
18:01:50 <mauke> argh
18:01:56 <mauke> @define
18:01:58 <lambdabot> Undefined.
18:02:06 <mauke> @let (===) :: (Eq a, Typeable a, Typeable b) => a -> b -> Bool; x === y = Just x == cast y
18:02:07 <lambdabot> Defined.
18:02:11 <mauke> > '?' === '?'
18:02:12 <lambdabot>  True
18:02:26 <mauke> > a === 42
18:02:27 <lambdabot>  False
18:02:39 <lispy> > f === x
18:02:40 <lambdabot>  Add a type signature
18:03:00 <oerjan> f is polymorphic
18:03:17 <lispy> > x === x
18:03:18 <lambdabot>  True
18:03:25 <ddarius> :t f
18:03:25 <lispy> > f === f
18:03:26 <lambdabot>  Add a type signature
18:03:26 <lambdabot> forall a. (SimpleReflect.FromExpr a) => a
18:03:47 <kjdf> what is that?
18:04:13 <oerjan> @where simplereflect
18:04:13 <lambdabot> http://twan.home.fmf.nl/blog/haskell/simple-reflection-of-expressions.details
18:04:58 <mauke> > map f [a,b,c,d]
18:04:58 <lambdabot>  Add a type signature
18:05:04 <oerjan> the letters a..z have been defined so they can be used to demonstrate how haskell builds up expressions.  f g and h are additionally functions
18:05:06 <ddarius> Speaking of resurrection, we need to resurrect the hey-day of lambdabot when people added extensions constantly.
18:05:14 <mauke> > map f [a,b,c,d] :: [Expr]
18:05:15 <lambdabot>  [f a,f b,f c,f d]
18:05:41 <mauke> ddarius: just write a @fresh-extension extension
18:05:45 <kjdf> hm, now I remember that I've seen cast in xmonad to get back a value hidden in an existential type
18:05:46 <lispy> > foldl1 f [a,b,c,d]
18:05:47 <lambdabot>  f (f (f a b) c) d
18:05:52 <lispy> > fold1 f [a,b,c,d]
18:05:52 <lambdabot>   Not in scope: `fold1'
18:05:55 <lispy> > foldr1 f [a,b,c,d]
18:05:56 <lambdabot>  f a (f b (f c d))
18:06:00 <kjdf> are there other cirucmstances where the type information can be lost?
18:06:25 <kjdf> (because other than that I still don't see how cast is useful)
18:06:40 <lispy> > (foldl1 f [a,b,c,d], foldr1 f [a,b,c,d]) -- cool example to show to beginners
18:06:41 <lambdabot>  (f (f (f a b) c) d,f a (f b (f c d)))
18:06:51 <bd_> :t f
18:06:52 <lambdabot> forall a. (SimpleReflect.FromExpr a) => a
18:07:03 <bd_> :t f a b
18:07:04 <lambdabot> forall t. (SimpleReflect.FromExpr (Expr -> t)) => t
18:07:30 <lispy> :t unfoldr
18:07:31 <lambdabot> forall b a. (b -> Maybe (a, b)) -> b -> [a]
18:07:56 <lispy> > unfoldr f b [a,b,c,d]
18:07:56 <lambdabot>  Couldn't match expected type `[Expr] -> t'
18:08:01 <marshmallows> > ( foldr (flip f) z [a,b,c,d,e] , foldl f z (reverse [a,b,c,d,e]) )
18:08:02 <lambdabot>  (f (f (f (f (f z e) d) c) b) a,f (f (f (f (f z e) d) c) b) a)
18:08:30 <oerjan> lispy: unfoldr doesn't take a list, it builds one
18:08:50 <lispy> oerjan: you're right
18:09:14 <lispy> > unfoldr f b
18:09:15 <lambdabot>        add an instance declaration for
18:09:15 <lambdabot>       (SimpleReflect.FromExpr (Maybe (...
18:09:55 <oerjan> lispy: Expr only supports a few numerical operations
18:10:16 <mauke> > x^8
18:10:16 <lambdabot>  x * x * (x * x) * (x * x * (x * x))
18:10:27 <bd_> > sin x
18:10:27 <lambdabot>  sin x
18:10:37 <bd_> > sum [a,b,c,d]
18:10:37 <lambdabot>  0 + a + b + c + d
18:10:38 <oerjan> since it is added to haskell's type system it cannot do much with functions that demand a fixed type
18:11:13 <oerjan> hm lessee
18:11:32 <marshmallows> > x `mod` y
18:11:33 <lambdabot>  x `mod` y
18:11:40 <marshmallows> > 345 `mod` 142
18:11:41 <lambdabot>  61
18:11:45 <marshmallows> > x `mod` 142
18:11:45 <lambdabot>  x `mod` 142
18:11:50 <marshmallows> > x `gcd` 142
18:11:51 <oerjan> > unfoldr (\n -> Just (var ('x':show n), n+1)) 0
18:11:53 <lambdabot>  [x0,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x...
18:11:56 <lambdabot> Terminated
18:11:57 <marshmallows> > x `gcd` y
18:12:04 <lambdabot> Terminated
18:12:09 <marshmallows> > 345 `mod` 142 :: Expr
18:12:10 <lambdabot>  345 `mod` 142
18:12:13 <marshmallows> :/
18:12:23 <marshmallows> I can't get it to work
18:12:35 <Botje> Expr is powerful, awesome, dangerous stuff
18:12:39 <Botje> mostly awesome.
18:12:47 <ddarius> Botje: Mostly a cheap hack
18:13:08 <marshmallows> What do you mean cheap?
18:13:20 <Botje> to the untrained mind, any amount of type hackery is indistinguishable from magic
18:13:24 <ddarius> It's certainly not an expensive hack
18:13:40 <Botje> I can handle about 30 milli-olegs at the moment
18:13:49 <ddarius> It's mostly just a type class
18:14:25 <ddarius> And a data type Expr that is an instance of a bunch of standard classes
18:14:52 <ddarius> It's really the genericity of (most of) the Haskell standard libraries showing through.
18:14:59 <oerjan> marshmallows: gcd requires that mod actually ends up with 0 at some point, which Expr's version doesn't do
18:15:24 <olsner> what happens to Oleg the unit when Oleg the person learns new tricks?
18:15:28 <ddarius> Expr is not a Euclidean division ring, oh noes!
18:15:40 <Botje> inflation.
18:15:41 <ddarius> olsner: It increases.
18:16:41 <thoughtpolice> the oleg is a rapidly increasing unit, no doubt.
18:24:26 <lekro> @pl g (x, y, z) = f x y z
18:24:27 <lambdabot> (line 1, column 13):
18:24:27 <lambdabot> unexpected "="
18:24:27 <lambdabot> expecting variable, "(", operator or end of input
18:24:33 <lekro> what's wrong with that?
18:24:59 <mauke> pl
18:25:01 <marshmallows> ?djinn ((a , b , c) -> x) -> (a -> b -> c -> x)
18:25:02 <lambdabot> f a b c d = a (b, c, d)
18:25:19 <mauke> in general, you can't pl pattern matches
18:25:32 <marshmallows> ?djinn (a -> b -> c -> x) -> ((a , b , c) -> x)
18:25:32 <lambdabot> f a (b, c, d) = a b c d
18:25:50 <mauke> @pl g (x, (y,z)) = f x y z
18:25:50 <lambdabot> g = uncurry ((`ap` snd) . (. fst) . f)
18:26:09 <mauke> 2-tuples are special cased
18:26:45 <lekro> I see
18:27:10 <lekro> so I guess there is no uncurry for triples in prelude?
18:27:20 <mauke> no
18:27:45 <mauke> http://4chanarchive.org/images/g/1021226/1202313464429.jpg -- quite but not entirely unrelated
18:40:33 <lispy> :t (,x)
18:40:34 <lambdabot> parse error on input `x'
18:40:45 <lispy> :t (,1)
18:40:46 <lambdabot> parse error on input `1'
18:40:59 <oerjan> nope, no tuple sections
18:41:06 <oerjan> :t flip (,) 1
18:41:06 <lambdabot> forall a b. (Num b) => a -> (a, b)
18:41:08 <lispy> it's too bad, you could get some very lispish looking things :)
18:41:39 <oerjan> :t flip (,) x
18:41:40 <lambdabot> forall a. a -> (a, Expr)
18:42:10 <lispy> ?pl flip (,) x
18:42:10 <lambdabot> flip (,) x
18:42:22 <lispy> I was hoping it would think of something even simpler :)
18:42:36 <oerjan> ?pl \a -> (a,x)
18:42:36 <lambdabot> flip (,) x
18:42:50 <marshmallows> swap . ((,) x)
18:42:58 <lispy> :t swap
18:42:59 <lambdabot> Not in scope: `swap'
18:43:10 <marshmallows> ?djinn (a,b) -> (b,a)
18:43:10 <lambdabot> f (a, b) = (b, a)
18:44:37 <lispy> ?djinn (a,b) -> Maybe (b,a)
18:44:37 <lambdabot> f (a, b) = Just (b, a)
18:44:45 * lispy expected f _ = Nothing
18:45:22 <marshmallows> ?djinn a -> Maybe b
18:45:22 <lambdabot> f _ = Nothing
18:45:27 <oerjan>  @djinn tries to use all parameters
18:45:41 <lispy> ?free (a,b) -> (b,a)
18:45:41 <lambdabot> Pattern match failure in do expression at Plugin/Free/FreeTheorem.hs:54:20-34
18:45:50 <marshmallows> @free map
18:45:51 <lambdabot> g . h = k . f => $map g . map h = map k . $map f
18:45:57 <oklofok> 1@2
18:45:59 <lispy> Can free not handle tuples?
18:46:02 <oklofok> @die 1d2
18:46:02 <lambdabot> 1d2 => 1
18:46:05 <oklofok> @die 1d2
18:46:05 <lambdabot> 1d2 => 1
18:46:08 <oklofok> darn
18:46:10 <oerjan> something has become buggy in @free lately
18:46:12 <marshmallows> lispy: (a,b) -> (b,a) looks like a type
18:46:22 <lispy> marshmallows: free works on types
18:46:28 <lispy> ?free m :: (a,b) -> (b,a)
18:46:28 <lambdabot> $map_Pair g f . m = m . $map_Pair f g
18:46:37 <marshmallows> no it doesn't...
18:46:39 <lispy> ah, but only named types
18:47:34 * oerjan notes oklofok is still out of coins
18:48:44 <lispy> ?free m :: (a,b) -> Maybe (b,a)
18:48:45 <lambdabot> $map_Maybe ($map_Pair g f) . m = m . $map_Pair f g
18:49:30 <lispy> ?instance Functor Maybe
18:49:30 <lambdabot> Maybe you meant: instances instances-importing
18:49:40 <lispy> ?src fmap Maybe
18:49:40 <lambdabot> Source not found. :(
18:49:49 <oerjan> ?src Maybe fmap
18:49:49 <lambdabot> fmap _ Nothing       = Nothing
18:49:49 <lambdabot> fmap f (Just a)      = Just (f a)
18:49:55 <lispy> ah
18:50:02 <lispy> I was backwards
18:50:04 <Twey> > let x = \ (y, z) -> (z, y) in x ("Hi", 5)
18:50:05 <lambdabot>  (5,"Hi")
18:50:11 <oerjan> ?instance Functor
18:50:11 <lambdabot> Maybe you meant: instances instances-importing
18:50:16 <oerjan> ?instances Functor
18:50:16 <lambdabot> ((,) a), ((->) r), Cont r, ContT r m, Either a, ErrorT e m, IO, Maybe, RWS r w s, RWST r w s m, Reader r, ReaderT r m, ST s, State s, StateT s m, Writer w, WriterT w m, []
18:50:17 <Twey> > let x = flip (,) in x ("Hi", 5)
18:50:18 <lambdabot>  Add a type signature
18:50:34 <Twey> Oh, that's not going to work anyway is it
18:50:44 <Twey> @pl x = \ (y, z) -> (z, y)
18:50:45 <lambdabot> x = uncurry (flip (,))
18:50:47 <Twey> Ah
18:50:53 <Twey> @src uncurry
18:50:53 <lambdabot> uncurry f p = f (fst p) (snd p)
18:51:15 <lispy> why is fst and snd? is it lazier?
18:51:22 <oerjan> yeah
18:51:55 <oerjan> could have been uncurry f ~(p,q) = f p q
18:52:03 <lispy> yeah, I was just typing that to ask :)
18:52:06 <lispy> okay
18:52:25 <Twey> What's ~?
18:52:28 <lispy> so, can you always replace a strict pattern match with that then?
18:52:31 <oerjan> lazy pattern
18:52:42 <Twey> Ah
18:52:58 <oerjan> it doesn't evaluate the tuple unless a parameter is used
18:53:04 <lispy> > do { ~(Just x) <- return 1; return x } :: Maybe Int
18:53:04 <lambdabot>   add an instance declaration for (Num (Maybe Int))
18:54:14 <lispy> > do { ~(Just x) <- return (Just 1); return x } :: Maybe Int
18:54:14 <lambdabot>  Just 1
18:54:18 <oerjan> > case Nothing of ~(Just x) -> show x; Nothing -> "Nope"
18:54:18 <lambdabot>      Warning: Pattern match(es) are overlapped
18:54:18 <lambdabot>              In a case alterna...
18:54:23 <lispy> Cool, so it works in do-notation too
18:54:57 <lispy> > do { ~(Just x) <- return undefined; return 2 } :: Maybe Int
18:54:58 <lambdabot>  Just 2
18:57:55 <oerjan> it's implicit on the top-level of where and let patterns
18:58:43 <oerjan> er that's ambiguous
18:59:36 <oerjan> it's implicit on the outermost level of pattern bindings in where and let blocks
19:03:41 <lispy> oerjan: please explain more.  I don't think I understand yet.
19:04:08 <lispy> (examples would help)
19:05:36 <oerjan> a ~ on a pattern means there is no check of whether that pattern matches unless and until an identifier bound in that pattern is itself used and evaluated
19:06:28 <lispy> but, you said it's implicit sometimes
19:06:33 <oerjan> this can be good for laziness.  otoh if there is a chance that the pattern _won't_ match then it is not what you want
19:06:36 <oerjan> oh right
19:06:46 <oerjan> > let 5 = 4 in 3
19:06:47 <lambdabot>  3
19:07:17 <ddarius> It can still be what you want if there is a chance that the pattern won't match.
19:07:21 <oerjan> you can have pattern bindings in let and where blocks.  those are always done lazily in this way
19:07:51 <oerjan> well yeah, but it's not as safe then
19:07:54 * li
19:08:22 <glen_quagmire> > let { a = b ; b = a ; } in a
19:08:23 <lambdabot>  Exception: <<loop>>
19:08:43 <glen_quagmire> how woudl lambdabot detect <<loop>> ?
19:08:54 <ddarius> glen_quagmire: By solving the Halting Problem.
19:09:02 <lispy> glen_quagmire: it uses a halting problem solver built into the type system
19:09:05 <ddarius> @faq Can Haskell solve the halting problem?
19:09:05 <lambdabot> The answer is: Yes! Haskell can do that.
19:09:09 <glen_quagmire> i knew lambdabot would be awarded turing award
19:09:27 <ddarius> That would be ironic.
19:09:41 <lispy> was it oleg that created that after implementing lambda calculus in the type level?
19:09:49 <oerjan> glen_quagmire: in some optimization settings, whenever ghc starts evaluating a thunk it puts a "black hole" in it so that if the thunk is reached _again_ before being finished, it errors out
19:10:19 <glen_quagmire> recursive let is so hard to implement
19:10:23 <olsner> #haskell - where your questions are answered with Halting Problem jokes, delivered in majestic stereo
19:10:36 <lispy> ?quote fuge
19:10:36 <lambdabot> No quotes match. Have you considered trying to match wits with a rutabaga?
19:10:39 <nkmrl> hi, anyone knows how  ghci can do auto-completion in emacs ?   (sorry for off topics)
19:10:39 <lispy> ?quote fuege
19:10:39 <lambdabot> No quotes match. Do you think like you type?
19:10:44 <olsner> @quote fugue
19:10:44 <lambdabot> monochron says:  "Welcome to #haskell, where your questions are answered in contrapuntal fugues."
19:10:45 <oerjan> ?quote fugue
19:10:45 <lambdabot> monochron says:  "Welcome to #haskell, where your questions are answered in contrapuntal fugues."
19:10:48 <lispy> olsner: thanks
19:10:58 <glen_quagmire> nkmrl: windows?
19:11:11 <nkmrl> freebsd
19:11:23 <glen_quagmire> it doesn't have tab completion?
19:11:31 <nkmrl> yes
19:11:32 <lispy> nkmrl: hmm...maybe M-/
19:11:33 * glen_quagmire doesn't use emacs
19:11:43 <lispy> nkmrl: but then that's using emacs's completions
19:11:49 <taruti> nkmrl: normal emacs completion does not work?
19:11:55 <glen_quagmire> ghci does have tab completion here
19:11:56 <taruti> M-/ or somesuch
19:12:01 <nkmrl> ok, i go try it
19:12:08 <ddarius> Incidentally, blackholing is done for space reasons, it just conveniently detects some loops as well.
19:12:14 <nkmrl> thank you
19:13:11 <lispy> nkmrl: I haven't found much utility in using ghci from emacs.  ghci has :r to re-load a file and other cool things, plus you can make your own bindings, use readline and even install plugins to make ghci to even more stuff.  You might try ghci on acid.  Bottom line, I prefer my ghci to be outside of emacs.
19:14:09 * taruti likes emacs + ghci, nicer cut-paste etc
19:14:30 <taruti> but depends probably on the workflow
19:14:32 * marshmallows would like emacs to actually launch :/
19:14:55 <ddarius> marshmallows: Did you set it as your boot loader?
19:15:07 <marshmallows> no
19:15:16 <lispy> M-x install-emacs-grub
19:16:31 <nkmrl> M-/ really works nicely :>
19:24:50 <jaj> I'm also on FreeBSD and I also have tab completition in ghci
19:25:38 * oerjan suddenly gets a strange association to an AA meeting
19:26:06 <olsner> "Hi, my name is X and I use emacs"?
19:26:19 <olsner> (I don't use emacs)
19:26:21 <oerjan> indeed
19:26:36 <oerjan> neither do i, although that is irrelevant
19:26:56 <olsner> (btw, being in denial is hard to successfully deny)
19:27:19 <roconnor> olsner: You sound like a lemon.
19:27:37 <olsner> lemons make sounds?
19:27:43 <lispy> Tell me, roconnor, what do the lemons say to you?
19:28:00 <lispy> we're all friends here, no one will laugh
19:28:02 <roconnor> lispy: they say ``lemons make sounds?''
19:28:19 * SimonRC reads some lolpresidents.com and goes.
19:28:39 <lispy> what is it about haskell and the name simon :)
19:28:58 <nkmrl> i stick to emacs because :browse can't  ":browse | less"  or  ":browse | grep foo"
19:29:11 <roconnor> ... sorry, olsner was supposed to deny he was a lemon, and I was supposed to say that is what  a lemon would say.
19:29:13 <oerjan> it was made by the secret conspiracy of Simons
19:29:30 <roconnor> apparently this doesn't work as well as I was lead to beleive.
19:30:18 <oerjan> roconnor: the lemons have had PR training
19:33:07 <roconnor> they are sneaky
19:33:35 <olsner> indeed we are
19:33:36 <olsner> *they
19:34:36 <oerjan> they've also been known to hire other people to claim they aren't lemons
19:36:16 <olsner> this is where I would ssh somewhere else, join #haskell under a different name and back myself up... and when challenged, I would deny being a sock puppet
19:36:34 <dancor> is there anything like hasktags for gnu global, so i can see e.g. all the places a given function is called
19:39:11 <oerjan> olsner: lemons would be far more sneaky than that, they would hire a regular.  this proves that you cannot be a lemon.
19:41:43 <roconnor> oerjan: is clearly the lemon.
19:42:20 <oerjan> it's just like a lemon to say that.
19:42:46 <roconnor> crap!
19:43:07 <dmwit> But what about lemon... demons!
19:45:35 <oerjan> beware the acid stare
19:50:07 <nkmrl> can anyone give me an one line example that  "cast :: (Typeable b, Typeable a) => a -> Maybe b"  produces something other than Nothing ...?
19:50:34 <marshmallows> Just undefined
19:50:41 <dolio> > (cast (5 :: Int)) :: Maybe Int
19:50:44 <lambdabot>  Just 5
19:51:16 <dolio> cast isn't for converting between types.
19:51:42 <nkmrl> dolio:  that's what i expect ...
19:52:30 <nkmrl> dolio:  i want to something like casting between Char and Word8 ...
19:53:12 <marshmallows> @instances Integral
19:53:13 <lambdabot> Int, Integer
19:53:35 <marshmallows> :t toEnum.fromEnum :: Char -> Word8
19:53:39 <dolio> > (toEnum (fromEnum 'c')) :: Word8
19:53:40 <lambdabot>  99
19:53:40 <lambdabot> Char -> Word8
19:53:54 <marshmallows> nkmr1: "casting" is the wrong word though
19:53:59 <Zao> Isn't there ord and chr for that?
19:54:14 <dmwit> Zao: Yes, but ord just returns Int.
19:54:21 <dmwit> (ord = fromEnum)
19:54:29 <dmwit> And of course, chr = toEnum.
19:56:29 <olsner> roconnor: hah, who's the lemon now :P
19:58:11 <dolio> > let fooInt :: Int -> String ; fooInt n = "I got an int: " ++ show n ; fooString :: String -> String ; fooString s = "I got a string: " ++ s ; fooErr = "Unexpected type." ; foo x = case cast x of Just i -> fooInt i ; Nothing -> case cast x of Just s -> fooString s ; Nothing -> fooErr in (foo (6 :: Int), foo "string", foo 'c')
19:58:12 <lambdabot>  ("I got an int: 6","I got a string: string","Unexpected type.")
19:58:53 <marshmallows> How are people finding this strict haskell dialect?
19:59:02 <lament> DDC?
19:59:16 <lament> "strict" is hardly its main property
19:59:35 <marshmallows> lament: how are you finding it?
19:59:45 <lament> it seems interesting
19:59:49 <marshmallows> yes...
19:59:50 <lament> it has practically nothing to do with haskell
20:00:09 <lament> but i hate monads, so...
20:00:53 <dolio> http://hpaste.org/6555
20:01:06 <dolio> There's the casting example with layout.
20:01:15 <dolio> So it's not just a wall of text.
20:02:23 <lament> wow, that's evil
20:02:39 <dolio> cast lets you build 'polymorphic' functions that inspect the type of the polymorphic value.
20:03:00 <lament> painful
20:03:37 <dolio> There's a maybe monad in there, but I'm lazy.
20:03:47 <jaj> I have some trouble building HaskellDB. First I had a lot of hidden package errors. after adding the different packages to the dependency list I get a build error.
20:04:27 <nkmrl>  dolio : thank you. i think i should start from a tutorial to figure out what they are.
20:04:42 <dolio> fromMaybe fooErr (fmap fooInt (cast x) `mplus` fmap fooString (cast x)) or something like that
20:05:11 <jaj> http://hpaste.org/6556 don't know why lambdabot doesn't announce it
20:05:43 <dolio> nkmrl: If you've used Java, you can think of cast like a combination of 'instanceof' and casting from Object.
20:05:50 <Cale> lambdabot never annouces hpastes
20:06:01 <Cale> It's the hpaste bot which does that, and it seems to be down.
20:06:02 <Zao> hpaste does, however.
20:06:25 <jaj> oh ok :)
20:06:30 <Cale> (announces*)
20:06:58 <dolio> nkmrl: But in general, you probably won't see most Haskell programmers using Typeable related stuff like cast.
20:10:59 <jeffz> jaj, the error seems pretty self explanatory to me, it even tells you how to fix it
20:11:33 <jaj> jeffz: I get another error when I use -XPatternSignatures
20:11:36 <marshmallows> any other remarks about DCC?
20:12:04 <marshmallows> just polling for thoughts..
20:12:37 <dolio> An effect system where map and mapm are the same is somewhat appealing.
20:12:43 <dolio> mapM, even.
20:12:55 <jaj> jeffz: http://hpaste.org/6557
20:13:45 <dolio> Although, I don't know how much effect typing subsumes monads.
20:13:56 <jeffz> jaj: http://www.haskell.org/pipermail/haskell-cafe/2008-January/037660.html
20:13:57 <lambdabot> Title: [Haskell-cafe] Cabal and DB packages, http://tinyurl.com/35zfsa
20:14:52 <jeffz> someone will probably fix those things and re-upload it to hackage with any luck
20:15:42 <jaj> jeffz: thanks -fglasgow-exts did the trick!
20:15:46 <Cale> dolio: My problem with that sort of thing is that the specification of map doesn't really specify an order in which the elements are to be computed, whereas mapM *does* specify an order in which things are to be carried out.
20:16:15 <dolio> Well, it does in DDC, because it's strict.
20:16:20 <dolio> Unless you make it explicitly lazy.
20:16:51 <dolio> Although, I'm not sure I'm wild about that.
20:17:00 <Cale> I rather like the idea that the compiler should have control over that. Haskell isn't *really* a lazy language, it's a nonstrict one :)
20:17:43 <dolio> Well, I don't know if the annotations make something lazy or just nonstrict.
20:18:40 <Cale> I suppose you could say that the implicit ordering is the lazy evaluation one, but just saying that it's any nonstrict ordering would not be well-defined.
20:18:49 <Cale> (once you introduce effects)
20:19:32 <dolio> Yeah. Making something explicitly non-strict might force it to have an effect free type, I'm not sure.
20:19:53 <roconnor> reverse . map . reverse = map
20:20:10 <roconnor> reverse . map f . reverse = map f
20:20:20 <Cale> Oh, you're talking about a specific system? I don't really know anything about DDC.
20:20:36 <roconnor> at least for inductive lists.
20:20:40 <dolio> I don't think I see anything specific on that issue.
20:20:41 <Cale> > reverse . map (*2) . reverse $ [1..]
20:20:43 <lambdabot>  Terminated
20:21:14 <Cale> If it's strict, then it can just specify that it uses the strict ordering.
20:21:28 <roconnor> reverse . map f = map f . reverse
20:21:34 <dolio> Oh, yes: http://www.haskell.org/haskellwiki/DDC/ClassSystem
20:21:35 <lambdabot> Title: DDC/ClassSystem - HaskellWiki
20:21:38 <Cale> (but I rather like the property of Haskell that the ordering is something which the compiler takes care of)
20:21:44 <oerjan> @free reverse
20:21:50 <lambdabot> $map f . reverse = reverse . $map f
20:21:58 <roconnor> :D
20:22:14 <dolio> Lazy expressions/functions are forced to have effects in the class 'Pure' or something like that.
20:22:26 <marshmallows> g = h -> f . g = f . h -- ?
20:22:36 <_cjs> The compiler doesn't take care of it; it's too lazy!
20:22:58 <Cale> Yeah, they're really explicit about the evaluation order.
20:23:59 <Cale> I'm more interested by the possibility of having a runtime/compiler which figures out when to optimistically evaluate things and improves the execution of a program over time :)
20:24:04 <oerjan> although @free may be sloppy around bottoms
20:24:33 <marshmallows> Cale: Have you heard of Elephant?
20:25:09 <Cale> marshmallows: I'm not sure.
20:25:11 <marshmallows> John McCarthy was talking about it.. the language should remember everything that happened, you just reminded me of it
20:25:18 <marshmallows> seems like that might be one use
20:25:38 <marshmallows> (that kind of runtime optimization, I am just guessing though)
20:25:46 <Cale> There has been some research in that direction.
20:27:21 <lament> the language should remember everything? sounds like reversible computing
20:27:26 <_cjs> It doesn't seem to me that it would be so hard to figure out where things are used more than once and start doing some memoization on some of that stuff.
20:27:30 <nkmrl> how can I turn off the output of ghci temporarily? because when I load a .bmp file...overwhilming \XX\XX...    thanks
20:28:18 <dolio> Personally, I think I'd rather have non-strict by default, and have effects impose strictness, but I don't know if you can do that with an effect system.
20:29:00 <dancor> what would be the correct way to do like runInteractiveProcess and replace the process's stdin with the client-side of a pty i've allocated and just have the CInt fd for
20:29:30 <dancor> Handle doesn't have a just-a-bare-file-descriptor constructor
20:30:14 <dancor> and i guess i couldn't swapout Handle's anyway
20:30:35 <dolio> I don't see any information on how to create your own effects, either. So, can I make a nondeterminism effect like a list/logic monad?
20:32:34 <dancor> ah looks like i can reuse c_runInteractiveProcess
20:32:41 <dancor> that runInteractiveProcess uses
20:33:24 <dancor> except that it doesn't expose that func of course
20:35:59 <_cjs> Hey, what's the "rts" code? Run time system?
20:36:40 <allbery_b> yes
20:38:43 <_cjs> Hm. Ok, so it's a compiler thing.
20:39:04 <_cjs> Oh, wait, a linker thing? Or linking into the RTS?
20:39:25 <_cjs> I'm trying to figure out why I keep getting this when I link an executable: /usr/pkg/lib/ghc-6.8.2/lib/base-3.0.1.0/libHSbase-3.0.1.0.a(Internals.o): In function `base_SystemziPosixziInternals_zdwccall16_info':
20:39:26 <_cjs> : warning: warning: reference to compatibility opendir(); include <dirent.h> for correct reference
20:40:29 <allbery_b> that would indicate that when ghc's runtime was built, it called opendir() without #include-ing <dirent.h> (and got a 4.2BSD backward compatibility stub which might or might not do the right thing)
20:40:57 <_cjs> Right. I got that far. But where the heck do I fix this is what I want to know.
20:41:11 <_cjs> I do believe that it's in some generated code.
20:41:19 <allbery_b> no
20:42:31 <_cjs> No? I had a grep for opendir and didn't hit any obvious results.
20:42:39 <allbery_b> it's somewhere in System.Posix.Internals, which is the internal implementation code for System.Posix.  It lives in the "unix" package
20:43:09 <allbery_b> (so, unless you have ghc+extralibs source, you want to get the unix package from hackage and dig at its source
20:43:54 <_cjs> I'm actually trying to tweak the NetBSD ghc package.
20:44:05 <_cjs> You mean like ghc-6.8.2/libraries/unix?
20:44:48 <allbery_b> yes
20:44:59 <allbery_b> I find it in System/Posix/Directory.hsc
20:45:40 <_cjs> Right. But this is what I'm saying about "generated" code; it's not a C file to which I can simply add a #include.
20:45:47 <allbery_b> hm, actually that's c_opendir which is presumably the wrapper for the raw C function, but I missed it somewhere in my quick grep
20:46:05 <_cjs> (Sorry about my very relaxed terminology.)
20:46:11 <allbery_b> no, but you can specify #include files to use to find things in .hsc files
20:46:15 <allbery_b> hold on, lemme dig
20:46:39 <_cjs> So is that c_opendir calling the opendir library function directly, or is it linking to a C function in the ghc source somewhere?
20:46:53 <_cjs> BTW, thanks for the help.
20:47:43 <allbery_b> I can't say for certain just yet but I think c_opendir is the FFI wrapper for C opendir()
20:47:56 <dolio> I guess looking closely, it doesn't look like you'd create your own new effects.
20:48:24 <dolio> Effects are primitive, provided by the compiler for tracking impurities.
20:48:32 <allbery_b> System.Posix.Internals is actually in base, it turns out, not unix
20:49:02 <allbery_b> the rest of System.Posix lives in the unix package
20:49:03 <dolio> So you could add a callCC primitive to the compiler and an associated effect, but you wouldn't be writing it in user code.
20:49:08 <dolio> Or something like that.
20:50:16 <allbery_b> here we go.  libraries/base/System/Posix/Internals.hs:foreign import ccall unsafe "HsBase.h opendir"
20:50:24 <dolio> Maybe I'm off, though.
20:50:34 <allbery_b> so you should be able to add your #include to HsBase.h
20:50:47 <dancor> what is more ridiculous: modifying process in ghc, or copying c_runInteractiveProcess
20:51:18 <allbery_b> which is in the top level include directory for the ghc distribution
20:51:44 <allbery_b> hm, it's there.  with an #if.  I suggest you have a problem with configure
20:51:57 <allbery_b> check config.log to see why the test for <dirent.h> failed
21:11:55 <_cjs> configure:6664: checking for dirent.h
21:11:56 <_cjs> configure:6671: result: yes
21:14:49 <_cjs> mk/config.h has: #define HAVE_DIRENT_H 1
21:17:36 <_cjs> Ooo. rts/Linker.c calls opendir. That would be my guess at the culprit.
21:18:16 <_cjs> And ha ha, what's this? #if defined(cygwin32_HOST_OS)
21:18:16 <_cjs> #ifdef HAVE_DIRENT_H
21:18:16 <_cjs> #include <dirent.h>
21:18:16 <_cjs> #endif
21:18:52 <_cjs> (And other stuff beyond.) Now why would that be only for cygwin32_HOST_OS?
21:26:37 <allbery_b> huh.  no idea, you need ghc folks now :)
21:27:15 <EvilTerran> would this be one for #ghc?
21:27:39 <TomMD> I seem to remember bit operations on bytestrings from somewhere, but not sure which library - does this actually exist?
21:29:17 <dons> Data.Binary ?
21:30:21 <TomMD> yeah, I figured I might resort to that - just, I thought there was another library more geared to my operation.
21:31:50 <dons> current code coverage of xmonad, for those interesting, http://galois.com/~dons/tmp/hpc_index.html
21:32:03 <dons> ( quickchecks with -fhpc )
21:32:56 <dons> glguy: hah, Typhoon is on the tv, after the blazers game.
21:33:12 <_cjs> Is there a #ghc?
21:33:24 <dons> yep
21:33:26 <allbery_b> yes
21:33:26 <_cjs> Cool, there is.
21:33:53 <allbery_b> however I dont' promise anyone is paying attention there (or will be until Monday...)
21:34:52 <_cjs> Is there a lambdabot there? What's the thing to find out recently active users?
21:35:14 <idnar> @bot
21:35:14 <lambdabot> :)
21:35:26 <idnar> oops, read "here"
21:35:30 <dons> ?users #ghc
21:35:30 <lambdabot> Maximum users seen in #ghc: 42, currently: 30 (71.4%), active: 3 (10.0%)
21:35:33 <_cjs> Crud. I was hoping to have it fixed by Monday morning my time, which is Sunday evening in the western world.
21:35:37 <dons> ?users #xmonad
21:35:37 <lambdabot> Maximum users seen in #xmonad: 127, currently: 94 (74.0%), active: 5 (5.3%)
21:35:40 <dons> mega woot
21:37:07 <oerjan> @users
21:37:07 <lambdabot> Maximum users seen in #haskell: 473, currently: 395 (83.5%), active: 11 (2.8%)
21:37:17 <dons> ok, haskell wins
21:37:25 <dons> ?users #darcs
21:37:25 <lambdabot> Maximum users seen in #darcs: 45, currently: 36 (80.0%), active: 2 (5.6%)
21:37:27 <dons> ?users #perl6
21:37:28 <lambdabot> Maximum users seen in #perl6: 141, currently: 122 (86.5%), active: 1 (0.8%)
21:37:37 <dons> ooh. xmonad's almost more popular than perl6.
21:37:45 <dons> what a day, calloo callay
21:37:46 <TomMD> dons: I just noticed lambdabot doesn't @seen #someRoom and give me good results
21:37:57 <dons> it gives unusual default results :)
21:38:01 <TomMD> Sounds like I have a reason to learn lambdabot - unless you know this is already done.
21:38:15 <dons> fix away, its a long outstanding wibble
21:38:31 <dancor> ?users #xmonad1
21:38:31 <lambdabot> Maximum users seen in #xmonad1: 1, currently: 0 (0.0%), active: 0 (NaN%)
21:38:54 <dancor> @vixen why would you lie and say max of 1
21:38:54 <lambdabot> good question, why did i say that?
21:39:32 <dons> @vixen you are a bot of mystery.
21:39:32 <lambdabot> a bot? what is that?
21:40:55 <noecksit> hello, i have a question about minimax if someone in here knows smthing about it
21:47:20 <lekro> noecksit: just ask. if someone knows something about it you'll notice
21:48:43 <noecksit> ok, my thing works fine, however with maximise I only get the final value, i dont get a move that tells me where i should go next
21:49:29 <noecksit> is there some kind of easier way to find the next value of the tree im supposed to use?
21:50:11 <entropie> hi
21:50:15 <noecksit> right now, im thinking about making a tree that is a tuple with (valueOfMove,actualMove) and then somehow returning the final move
21:50:41 <lekro> you could return the move together with the value, or if you want to just return the value, you need to compute the value for all possible moves and select the best
21:50:42 <noecksit> but then i would have to parse the actual move to get to the next move
21:51:04 <entropie> in the YAHT tutorial, there is in "Type Basics" an example: data Pair a b = Pair a b — but it does not work?
21:52:06 <noecksit> lekro: i dont want to return the value only since that doesnt give me much info
21:52:53 <lekro> noecksit: what is the problem with returning (valueOfMove, actualMove)?
21:53:03 <oerjan> entropie: you need to put data declarations in a file and load them.  they cannot be typed into the interpreter directly
21:53:19 <entropie> oerjan: ah okay. thank you
21:56:29 <noecksit> lekro: no problem, i just thought there was an easier way
22:02:22 * dancor is unsure why process's c_runInteractiveProcess would bother to use (Ptr FD) instead of FD
22:03:52 <lispy> dancor: does the FD need to be mutated?
22:04:27 <glguy> ?index c_runInteractiveProcess
22:04:27 <lambdabot> bzzt
22:04:47 <dancor>   *pfdStdInput  = fdStdInput[1];
22:04:57 <dancor> i guess so
22:05:01 <glguy> that's an output parameter
22:05:17 <dancor> ya there's no real mutation that i can see
22:05:48 <dancor> well i will just try changing it and see what happens
22:05:54 <glguy> no no
22:06:01 <dancor> it's the only way to learn
22:06:04 <glguy> it is a pointer, you need to read it to file the file descriptor
22:06:20 <glguy> if it took an FD, then you'd be passing the FD in
22:06:23 <glguy> instead of getting one out
22:08:11 <dancor> oh right, i know what i want now
22:21:17 <biouser> http://sequence.complete.org/node/157
22:21:18 <lambdabot> Title: First Post: Cellular Automata Simulator | The Haskell Sequence
22:22:02 <biouser> anyone know how to use this code for cellular automata.. maybe know of a good resource for cellular automata/mathematical biology...?
22:28:34 <cjb> biouser: put it in foo.hs, ghc -o foo.hs, ./foo
22:30:23 <_cjs> Jeffrey Sampson: _Biological Information Processing_ and, err, ...
22:31:01 <biouser> bio@bio-bushi:~/math/4490$ ghc -o cell.hs
22:31:01 <biouser> ghc-6.6.1: no input files
22:31:01 <biouser> Usage: For basic information, try the `--help' option.
22:32:39 <_cjs> Ah, _Adaptive Information Processing_. That's the one that's really got all of the cellular automata stuff in it.
22:34:18 <cjb> biouser: Sorry, my fault.  ghc -o cell cell.hs
22:34:25 <cjb> (just like gcc)
22:36:10 <cjb> huh, looks like a pascal/sierpinski triangle to me
22:39:18 <biouser> ty cjb, yeah, not quite what I was hoping for... hehe...
22:40:35 <biouser> http://arxiv.org/pdf/0801.0357 I want to work with some difference equations and make some automata
22:58:25 <marshmallows> hi mae
23:06:02 <Enzo> How might one go about adding an instance declaration for (Enum (Complex Double))  ?
23:06:24 <roconnor> @src Enum
23:06:24 <lambdabot> class  Enum a   where
23:06:24 <lambdabot>     succ                     :: a -> a
23:06:24 <lambdabot>     pred                     :: a -> a
23:06:24 <lambdabot>     toEnum                   :: Int -> a
23:06:24 <lambdabot>     fromEnum                 :: a -> Int
23:06:26 <lambdabot> [3 @more lines]
23:06:48 <roconnor> Enzo: it can be done, but I strongly recommend against it.
23:09:06 <Enzo> roconnor: If I don't add an instance for it than I can zip [1..] with a list of complex numbers, right?
23:09:36 <roconnor> yep, you can zip a list of anything with a list of anything else.
23:10:07 <roconnor> actually, I tone down my wording, and only moderately recommend you don't make it an instance of Enum.
23:16:11 <oerjan> the *To methods would probably require a bit of work just to find out what you want them to be, when the start, increment and end don't line up
23:16:54 <oerjan> and toEnum and fromEnum are a bit hairy but that's the case for Float and Double too
23:17:04 <oerjan> @more
23:17:04 <lambdabot>     enumFrom                 :: a -> [a]
23:17:04 <lambdabot>     enumFromThen, enumFromTo :: a -> a -> [a]
23:17:04 <lambdabot>     enumFromThenTo           :: a -> a -> a -> [a]
23:17:40 <dmwit> Enzo: Out of curiosity, why did you want that instance?
23:19:08 <Enzo> dmwit: http://hpaste.org/6558
23:20:18 <oerjan> Enzo: oh, just put xx+fromIntegral y
23:20:36 <dmwit> yup
23:20:58 <Enzo> ooh! hahha thanks =]
23:33:03 <dmwit> ?remember newsham <lispy> Oh shoot, I need 6.6 not 6.8 <newsham> uninstall 0.2?
23:33:03 <lambdabot> It is forever etched in my memory.
23:33:27 <dmwit> lispy: GHC 6.6 and 6.8 coexist peacefully, for the most part.
23:33:41 <lispy> dmwit: how?
23:33:55 <dmwit> lispy: They install into, e.g., /usr/local/ghc-6.8/...
23:34:15 <dmwit> lispy: Then ghc, runghc, etc are just symlinks.
23:34:24 <lispy> I see
23:34:27 <lispy> so I can call them by name
23:34:31 <dmwit> righc
23:34:34 <dmwit> *right
23:34:38 <lispy> call by name vs. call by value?
23:35:57 <Enzo> Dmwit, I noticed that you have a stanford.edu email account. Are you a student there?
23:36:08 <dmwit> For a few more months!
23:36:18 <Enzo> How funny, I live about a minute from campus! I've been thinking about organizing a Haskell intrest group and meeting somewhere on campus. Would you like to attend?
23:36:27 <dmwit> I'd love to!
23:36:38 <dmwit> Do you know about the Bay Area Functional Programming group?
23:36:44 <Enzo> excellent
23:36:51 <Enzo> I do not
23:37:15 <TomMD> Control.Monad.Reader++
23:39:29 <dons> Enzo: oh, at stanford?
23:39:38 <dons> Enzo: you might want to ask the BayFP guys
23:40:12 <Enzo> I'm not exactly sure when the first meeting will be..   probably at the Green library in about 2 and a half weeks or so.
23:40:27 <dons> i'd definitely advertise to the BayFP guys
23:40:50 <Enzo> I'll most likely announce it on the haskell.org mailing list
23:41:13 <dons> yep, go for it
23:41:18 <dons> and add it to the Events page on haskell.org
23:42:24 <Enzo> dons, i haven't looked into advertising with BayFP but that sounds like a good idea
23:43:52 <Enzo> I'll be adding it to the events page within a few days.. keep your eyes pealed
23:50:02 <lispy> I downloaded GNUreadline-framework.zip (this is for ghc6.6.1 on osx) now what do I do with that file so that GHC can find the framework at runtime?
23:50:22 * BMeph had a bad cold, where his eyes pealed, and his ears shone...
23:53:01 <solrize_> bayfp?
23:53:06 <solrize_> i'v been going to that
23:55:42 <lispy> oh, I figured it out
