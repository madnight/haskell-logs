00:01:19 <evancz`> Oh, as in ($!!) will force a crawl over the list whether it is needed or not?
00:01:46 <Saizan> yeah
00:01:47 <ddarius> It has to go to all the elements to force them.  It has no way of knowing that they've already been reduced.
00:02:13 <ddarius> At any rate, rnf is usually -way- too eager.
00:02:30 <evancz`> I see.
00:04:11 <ddarius> If you -really- want to reduce things to normal form, the correct thing to do would be to convert to a data structure that is necessarily fully reduced.  This will take not much more work than a deepseq but will make it manifestly obvious no further work is required and that the data is in normal form.
00:04:41 <ddarius> Also, in practice, you usually don't care to reduce things completely to normal form, so you can convert to less eager data structures, e.g. head strict lists.
00:08:15 <Saizan> hah, we could convert Strategy's into datatype declarations
00:17:42 <evancz`> I think laziness is a really bad fit for concurrency so far
00:18:05 <evancz`> correction, as far as I have seen so far
00:18:31 <evancz`> WHNF allows computations to escape threads
00:18:48 <evancz`> NF forces extra traversal of data structures
00:19:08 <evancz`> normal laziness allows everything to escape threads
00:20:12 <evancz`> Every option seems to be undesirable from the perspective of concurrency
00:20:28 <pnielsen> evancz`: for parallelism
00:20:56 <pnielsen> lazy concurrency is fine
00:22:32 <evancz`> regardless of whether threads operate concurrently
00:22:38 <pnielsen> you could probably structure the application in a way that you'd only need to deepseq once
00:22:47 <pnielsen> per thread/worker
00:23:18 <evancz`> as an abstraction for concurrency
00:23:35 <pnielsen> evancz`: http://ghcmutterings.wordpress.com/2009/10/06/parallelism-concurrency/
00:23:56 <Raynos> Other then here, what's a good place to ask "what would this function be called?"
00:24:08 <Raynos> and by function I mean abstract functional programming building blocks
00:24:31 <evancz`> I am familiar with the distinciton
00:25:04 <evancz`> the point I am making is that Haskell has these abstractions for concurrency, namely threads
00:25:24 <evancz`> and there is no nice easy way to ensure that computations do not escape a thread
00:25:33 <pnielsen> or rather, concurrency is composing independently executing process, and parallelism as simultaneously executing computations
00:25:36 <evancz`> defeating the purpose of the thread!
00:25:47 <pnielsen> the lazy evaluation wouldn't be a problem if the application weren't parallel
00:26:11 <evancz`> ok, what term do you want me to use?
00:26:19 <evancz`> and does this undermine the point I am making?
00:26:24 <pnielsen> sorry, I'm just being pedantic :)
00:26:58 <evancz`> no worries, it is important to be clear with terminology like this
00:27:07 <evancz`> but I think the larger point still stands
00:27:46 <Jafet> What do you think is the purpose of threads?
00:28:26 <evancz`> breaking work up into independent chunks
00:28:39 <pnielsen> evancz`: I would usually do work in a thread, deepseq, then send back the result. I wouldn't need to repeatedly deepseq the same value
00:29:11 <Jafet> That's not the purpose of threads.
00:29:13 <pnielsen> or par and pseq
00:29:36 <evancz`> My trouble is that I have a network of threads (non-cyclical graph, input on one side, output on the other)
00:29:40 <Jafet> Threads are used to have concurrent semantics.
00:30:19 <evancz`> so if I call deepseq after each thread finishes its work, i may be calling deepseq a ton of times
00:30:34 <evancz`> if the network is 10 nodes deep, i'll call it 10 times
00:31:09 <Jafet> If only the thread that creates a value deepseqs its value, then the value will only be evaluated once.
00:31:41 <evancz`> Someone mentioned the case of a list getting deepseq'd
00:31:54 <evancz`> in this case, they said, deepseq needs to crawl the entire list
00:32:04 <evancz`> so if every node just computes `id`
00:32:04 <Jafet> You misunderstood what ddarius said.
00:32:26 <Jafet> If every thread deepseqs every value that passes through it, then values get deepseqed multiple times.
00:32:44 <evancz`> ok
00:32:46 <Jafet> That's why adding deepseq to the concurrent library is bad.
00:33:04 <Jafet> Instead, you should use it in a way that it gets applied once to every result.
00:33:04 <evancz`> shit dude, that defeats the purpose of a thread
00:33:16 <Jafet> Yo momma
00:33:20 * Jafet wanders off
00:34:05 <evancz`> I guess I am missing how laziness+concurrency/parallelism is a good idea
00:34:18 <pnielsen> laziness+parallelism
00:34:24 <pnielsen> :)
00:34:37 <evancz`> lol, okay
00:35:27 <pnielsen> the words aren't interchangeable. It's not just pendantics--there's an important difference: you can have millions of threads executing concurrently on the same processor, but you can't have more than one thread execute in parallel on the same processor
00:35:34 <evancz`> so the answer in this case is "use it in a way that it gets applied once to every result"
00:35:47 <evancz`> I get it!
00:35:50 <pnielsen> the problem you are facing is because of parallelism, because one processor (the one running the collecting thread) is the one that ends up doing the computation
00:35:59 <pnielsen> alright
00:36:10 <evancz`> yes!
00:36:15 <evancz`> that is a nice way to put it
00:36:17 <pnielsen>  \o/
00:36:28 <evancz`> lol
00:36:36 <evancz`> double meaning "lol"
00:37:45 <pnielsen> evancz`: if you are skeptical about Haskell and parallelism, and you're working with collections, check out Data Parallel Haskell. It'll almost certainly make you hot for lazy.
00:38:21 <evancz`> In this case though, parallel execution of threads, it seems bad
00:38:39 <evancz`> i actually haven't tried out data parallelism yet in haskell
00:38:42 <evancz`> it seems cool :)
00:38:43 <pnielsen> I don't know of a language where you can enable parallelism so transparently/easily
00:38:52 <Jafet> > [1..] `par` ()
00:38:53 <lambdabot>   ()
00:38:59 <Jafet> Parallelism in haskell.
00:39:02 <evancz`> Concurrent ML!
00:39:15 <evancz`> although, getting Concurrent ML running is another problem
00:39:25 <Jafet> ML ain't even pure, fo shizzle
00:39:43 <evancz`> unsafePerformIO
00:39:58 <pnielsen> purity is the key IMO
00:39:59 <evancz`> it is culturally pure :)
00:40:57 <pdxleif_> Isn't repa a simple version of data parallel haskell?
00:41:34 <evancz`> ok, but for the specific problem (acyclic network of threads, ideally getting some benefits of parallelism) is there a nice way to localize computation to a specific thread?
00:42:10 <evancz`> it seems like everything needs to be seq'd to avoid the over-crawling of deepseq
00:45:02 <Saizan> one way is to use datatypes with strict fields
00:45:35 <Saizan> e.g. data StrictPair a b = Pair !a !b
00:49:33 <evancz`> the point I was trying to make earlier (which I don't want to get back into) is this: with concurrent semantics (whether it is running on a single processor or not) you are saying these computations can happen in an order independent way. If one thread takes a really long time, it does not need to block any other thread. But if the system ultimately puts all of the computation into a single thread, you lose the order
00:49:33 <evancz`> independence. Something that does not need to block stuff suddenly does!
00:49:35 <evancz`> ok
00:49:53 <evancz`> i will mess around with getting strictness right in my case
00:50:14 <pnielsen> yes
00:50:18 <evancz`> hopefully it will not be too crazy to figure out
00:50:54 <evancz`> That is why I said that laziness+concurrency is a bad idea
00:50:57 <evancz`> so far
00:50:59 <pnielsen> I guess GHC's name is a little misleading. It's probably easier to think of threads (forkIO) as coroutines that are multiplexed onto OS threads
00:51:01 <evancz`> but maybe i am wrong
00:51:26 <merijn> pnielsen: "you can't have more than one thread execute in parallel on the same processor" <-- hyperthreading? :P
00:51:27 <pnielsen> your program wouldn't have any problem if it only ran on one processor
00:51:34 <pnielsen> heh
00:51:42 <pnielsen> logical processor :)
00:51:46 <evancz`> false!
00:51:56 <pnielsen> evancz`: not as big of a problem, anyway
00:51:57 <evancz`> assume one processor
00:52:06 <evancz`> we have three threads
00:52:08 <pnielsen> evancz`: but what you said was concurrency/parallelism - slash
00:52:13 <pnielsen> that's why I corrected you
00:52:16 <Jafet> merijn: don't use AMD, your module will only run on one module
00:52:17 <pnielsen> they're not interechangable
00:52:44 <evancz`> i said it that way because you gave me a hard time for saying concurrency+laziness in the first place
00:52:47 <pnielsen> but you're right that concurrency and parallelism both have issues, parallelism being the major one
00:52:52 <evancz`> ok, on processor
00:53:07 <evancz`> three threads, two feeding into one that prints the results from each
00:53:33 <evancz`> `feed1` and `feed2` go to the `printer` thread
00:53:42 <evancz`> if feed1 takes a long time
00:53:49 <evancz`> feed2 should not be blocked
00:53:54 <evancz`> they are concurrent
00:54:04 <evancz`> they may be running on a single processor
00:54:13 <evancz`> but they still should not block eachother
00:54:15 <Saizan> you get the same effect by scheduling
00:54:16 <pnielsen> depending on whether you have cooperative or preemptive scheduling
00:54:22 <evancz`> at least not in a pre-emptive system
00:54:31 <merijn> Saizan: PREEMPTIVE scheduling
00:54:37 <evancz`> in this case, we have pre-emptive
00:54:38 <Saizan> even a pre-emptive system doesn't need to be fair
00:55:02 <merijn> Saizan: No, but he was implying fairness, and that is hard to do on a non-preemptive system
00:55:03 <pnielsen> evancz`: following so far
00:55:10 <evancz`> this one, the one in Haskell, the one directly relevant, pre-epmts frequently
00:55:10 <Jafet> With GHC's concurrency implementation, they do not block each other.
00:55:18 <pnielsen> evancz`: or was that all?
00:55:27 <Jafet> Unless you do something silly or unusual
00:55:33 <evancz`> so with laziness
00:55:38 <Saizan> assuming computing feed1 allocates :)
00:55:48 <evancz`> yes...
00:55:55 <evancz`> the computations on feed1 and feed2 can escape to the printer thread
00:55:57 <merijn> btw
00:56:08 <Saizan> so yeah, there are a lot of assumptions to make to make this point
00:56:09 <evancz`> in which case, the computations DO block eachother
00:56:12 <evancz`> no
00:56:15 <evancz`> not at all
00:56:23 <evancz`> these are all how Haskell works!
00:56:29 <Jafet> It doesn't matter if the printer thread evaluates a huge thunk from feed1. All threads still get scheduled unless they are waiting on IO or an MVar.
00:56:30 <evancz`> that is whayt I have been here learning today
00:56:33 <merijn> Can a forkIO thread executing FFI code be moved to another OS thread?
00:56:57 <pnielsen> evancz`: that only matters if you are sleeping/waiting for I/O in the feeders
00:57:09 <evancz`> ?
00:57:19 <merijn> (If yes, can I safely assume that will have involved a full memory barrier?)
00:57:21 <evancz`> sorry info is passing through these threads
00:57:25 <Jafet> feed1, feed2 and printer still get scheduled. They just don't get to do anything because printer is locked up.
00:57:28 <pnielsen> if you are, then sure, you are doing a lot of computation at once instead of some computation over a longer preiod of time
00:57:31 <evancz`> yes
00:57:32 <Saizan> Jafet: he means that if feed1 was evaluated in the worker thread before getting to the printer than feed2 would ge to the printer first
00:57:43 <evancz`> yes!
00:57:52 <Jafet> Wat
00:57:55 <Saizan> *then
00:58:04 <Saizan> Jafet: feed1 and feed2 aren't names of threads
00:58:23 <Saizan> Jafet: they are values produced by different worker threads, sent to printer
00:58:34 <Jafet> This is why I hate concurrency, it enables other people to confuse me
00:58:34 <pnielsen> evancz`: that is laziness, though
00:58:55 <evancz`> that is why i am saying that laziness+concurrency is not so good
00:58:57 <maukd> "though"?
00:59:06 <maukd> I thought that was the entire point of the discussion
00:59:07 <pnielsen> evancz`: you can solve most of this by using strict fields and seq
00:59:14 <evancz`> I can design a concurrent system and then lose all of the benefits
00:59:20 <pnielsen> maukd: I'm just emphasizing that that's pretty much the point of lazy evaluation
00:59:22 <Jafet> Concurrency is implemented in IO, which is strict
00:59:34 <maukd> Jafet: except when it isn't
00:59:43 <shachaf> Concurrency concurrendo.
00:59:52 <maukd> I'm pretty sure the whole spark system isn't in IO
00:59:56 <Jafet> Concurryency
01:00:02 <maukd> and values passing through IO aren't strict either
01:00:21 <Jafet> And I thought your complaint was about interleaveIO
01:00:27 <shachaf> The whole spark system isn't really concurrency.
01:00:41 <maukd> ah
01:00:45 <evancz`> pnielsen: you are suggesting I use a strict semantics
01:00:48 <Jafet> Because normal IO is strict, you can use it to strictify whatever you want in the thread, evan
01:00:53 <maukd> :t evaluate
01:00:55 <lambdabot> Not in scope: `evaluate'
01:00:59 <maukd> @hoogle evaluate
01:00:59 <lambdabot> Control.Exception.Base evaluate :: a -> IO a
01:00:59 <lambdabot> Control.Exception evaluate :: a -> IO a
01:00:59 <lambdabot> Control.OldException evaluate :: a -> IO a
01:01:16 <Jafet> worker box x = do evaluate (deepseq x); putMVar box x
01:01:17 <evancz`> the problem is with deepseq running over the whole datastructure
01:01:25 <shachaf> You probably shouldn't use deepseq.
01:01:34 <Jafet> Then use a smaller seq.
01:01:37 <maukd> evancz`: why is that a problem?
01:01:53 <evancz`> the example i gave here was 2 level deep
01:01:59 <evancz`> lets say it is 10 level deep
01:02:04 <evancz`> if each level does a deepseq
01:02:14 <evancz`> on the values coming through
01:02:18 <Jafet> So don't deepseq at every level.
01:02:19 <evancz`> say a list of length 1000
01:02:23 <Jafet> I don't understand what the problem is.
01:02:29 <Jafet> deepseq at the right level.
01:02:48 <maukd> does deepseq allocate?
01:02:52 <evancz`> my network is generated programatically
01:03:09 <Jafet> In lieu of actually designing your program properly, you can even create a wrapper type to remember whether you have deepseqed results or not.
01:03:16 <evancz`> deepseq needs to run over the entire datastructure to see if it is all evaluated
01:03:31 <Jafet> data Future a = Future Bool a
01:03:35 <evancz`> lol, passive-aggresive
01:03:36 <shachaf> maukd: Certainly it might.
01:03:38 <maukd> ah, my thinking is faulty
01:03:40 <evancz`> but that is a good idea!
01:03:49 <Jafet> deepseq' (Future False a) = Future True (force a)
01:03:50 <maukd> or rather, backwards
01:03:55 <shachaf> Who's deepseqing and why?
01:04:08 <evancz`> lol, long discussion!
01:04:18 <maukd> shachaf: the why is to make sure computation happens in the producer thread AFAIU
01:04:46 <maukd> (seqing, fuck yeah)
01:04:50 <shachaf> Is this related to bgamari's thing?
01:05:04 <Jafet> I hope not. That's too many levels of confusion for one channel.
01:05:11 <shachaf> You probably shouldn't deepseq.
01:05:21 <Saizan> shachaf: we know!
01:05:23 <Jafet> I do, proudly and in public.
01:05:31 <shachaf> Jafet is like that.
01:05:44 <evancz`> it sounds like i just need to deal with it!
01:05:52 <evancz`> thanks for talking me through this stuff!
01:05:58 <evancz`> I need to get some sleep though
01:06:07 <maukd> @localtiem evancz`
01:06:08 <lambdabot> Local time for evancz` is Sat Sep 29 04:05:45 2012
01:06:18 <evancz`> yeah :)
01:06:36 <maukd> that reminds me, I need to load my lambdatime script
01:06:50 <pnielsen> @localtime pnielsen
01:06:50 <lambdabot> Local time for pnielsen is Sat Sep 29 04:06:30 2012
01:06:52 <maukd> @localtime
01:06:56 <lambdabot> Local time for maukd is Sat Sep 29 09:55:56 2012
01:07:00 <pnielsen> heh, wrong suckers
01:07:02 <evancz`> if anyone can figure out how to make concurrency+laziness work in a general way, please blog about it or something!
01:07:04 <pnielsen> it's 3:06
01:07:11 <evancz`> anyway, later folks!
01:07:22 <pnielsen> oh wait, I'm connected through a server in NJ. I digress.
01:07:32 <maukd> @localtime
01:07:36 <lambdabot> Local time for maukd is Boomtime, the 53rd of Bureaucracy in the YOLD 3178.
01:07:40 <shachaf> I don't think there's a known solution that doesn't involve thinking, unfortunately. :-(
01:07:41 <maukd> great success
01:07:53 <benmachine> maukd: is it ALWAYS lambdatime?
01:08:05 <shachaf> Unnecessary thinking considered harmful.
01:08:08 <maukd> evidently
01:08:19 <maukd> @localtime maukd
01:08:22 <lambdabot> Local time for maukd is none of your concern
01:08:51 <maukd> ah, another missing script
01:09:01 <Saizan> shachaf: you can make your thread products have strict types
01:09:35 <shachaf> Saizan: Laziness is often desirable in the context of concurrency.
01:09:39 <shachaf> It's also often undesirable.
01:09:54 <Saizan> well, we have to decide
01:09:56 <maukd> shachaf: did that work?
01:10:16 <Saizan> do we want a producer to evaluate its results or not?
01:10:34 <shachaf> maukd: Yep.
01:10:38 <Saizan> the answer can be yes and keep laziness within that thread
01:10:51 <Saizan> but have a strict type as final result
01:11:56 <shachaf> Saizan: Certainly you can reason about it in a specific case.
01:12:20 <Saizan> if you want half of it evaluated in the producer and half later then the thinking seems pretty necessary
01:14:29 * hackagebot aeson-pretty 0.6.3 - JSON pretty-printing library and command-line tool.  http://hackage.haskell.org/package/aeson-pretty-0.6.3 (FalkoPeters)
01:22:58 <theplanet> does ghc run on whatever os macbook pros use?
01:23:38 <merijn> theplanet: Well, it runs (at least) on anything since Tiger (10.4)
01:24:30 * hackagebot libmpd 0.8.0.1 - An MPD client library.  http://hackage.haskell.org/package/libmpd-0.8.0.1 (SimonHengel)
01:26:24 <merijn> theplanet: Anything specific you're worried about?
01:29:37 <theplanet> no merijn
01:38:07 <merijn> theplanet: Then it's just a matter of checking you have xcode installed (for the commandline tools), running the Haskell Platform installer and things should Just Work(TM)
01:52:17 <hiptobecubic> @src [] gaurd
01:52:17 <lambdabot> Source not found. My brain just exploded
01:52:20 <hiptobecubic> @src guard []
01:52:21 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
01:52:22 <hiptobecubic> rats
01:52:55 <maukd> @src guard
01:52:55 <lambdabot> guard True  =  return ()
01:52:55 <lambdabot> guard False =  mzero
01:53:11 <maukd> @src [] mzero
01:53:11 <lambdabot> mzero = []
01:53:24 <sheriff_> Given a type constructor like :+:    Foo a :+: Foo a
01:53:31 <sheriff_> There's nothing magic about the ::'s, right?
01:53:46 <shachaf> Right.
01:54:04 <sheriff_> And I could as happily have written :++
01:54:13 <sheriff_> I'm not getting any free functionality for using :?
01:54:38 <maukd> well.
01:54:49 <maukd> in older ghcs, : is the only uppercase symbol
01:54:59 <maukd> i.e. all operatory constructors must start with :
01:55:15 <hiptobecubic> why would they do that
01:55:18 <maukd> in the latest ghc, all operators are constructors, not variables
01:55:39 <sheriff_> maukd: Oh, that's interesting
01:55:57 <sheriff_> maukd: And explains its use
01:56:01 <benmachine> maukd: only in types
01:56:22 <benmachine> maukd: operator data constructors still need to start with :, of course
01:56:26 <shachaf> Value-level constructors still must start with :
01:56:31 <benmachine> right
01:56:37 <maukd> oh, right
01:56:45 <benmachine> that's the version of what I said that uses less confusing punctuation
01:58:55 <dmwit> Agda syntax for lambdas is also "\x -> e", right?
02:00:09 <maukd> .oO( lambada calculus )
02:00:22 <theplanet> what's thst
02:00:38 <Robdgreat> haha
02:00:38 <shachaf> dmwit: More like λ x → e
02:00:58 <shachaf> (I think the space is important.)
02:01:00 <theplanet> how do you type those characters
02:01:10 <maukd> like this: λ →
02:01:28 <shachaf> theplanet: Using the λ and → keys on my keyboard.
02:01:28 <theplanet> are they on your keyboard
02:01:34 <notdan> lol
02:01:37 <maukd> I use my compose key
02:01:42 <maukd> and a custom compose map
02:01:45 <theplanet> what are the compose keys
02:01:52 <theplanet> you do?
02:01:52 <maukd> theplanet: what OS are you on?
02:01:59 <theplanet> 1linux
02:02:06 <maukd> good start
02:02:15 <theplanet> yeah but debian
02:02:19 <maukd> so am I
02:02:23 <sheriff_> I am having a great deal of trouble deciding when to use the term 'expression' and the term 'value' in my Haskell homework
02:02:26 <theplanet> actually im on windows SSH
02:02:33 <maukd> that makes it harder
02:02:45 <maukd> using putty?
02:02:47 <theplanet> i write all syntactic stuff over SSH
02:02:54 <theplanet> no, using cygwin
02:02:57 <maukd> ah
02:03:06 <Jafet> Expressions are syntactic objects. A semantics gives them values.
02:03:10 <maukd> well, I have no idea how to do that in windows
02:03:25 <maukd> short of creating your own keyboard layout (which I have, but without greek letters on it)
02:03:36 <Jafet> They should not be interchangeable (except in some weird languages)
02:03:44 <theplanet> how did you create it on debian ?
02:04:04 <sheriff_> Jafet: OK
02:04:10 <sheriff_> Jafet: thanks
02:04:43 <shachaf> In Windows you can just memorize codepoints.
02:04:50 <maukd> theplanet: there's a menu in System > Preferences > Keyboard > Layouts > Options ...
02:04:54 <theplanet> never heard of codepoints
02:04:59 <theplanet> but i dont intend to use windows for ever
02:05:12 <maukd> theplanet: Compose key position
02:05:12 <theplanet> hmm let me book centos from this usb stick
02:05:18 <Jafet> Back in the day, you had to memorize code pages!
02:05:22 <theplanet> bbut just explain it further please
02:05:25 <maukd> I've mapped it to the "menu" key
02:05:55 <maukd> now I can press (and release) <menu> ' a and get á
02:06:11 <maukd> (that is, I don't have to hold down anything, just press keys in sequence)
02:06:27 <maukd> <menu> " a gives me ä
02:06:47 <maukd> those combinations are there by default
02:07:08 <shachaf> <menu> C C C P gives me ☭
02:07:27 <maukd> I can give you my ~/.XCompose file, which defines things like <compose> - > turning into → and <compose> g l turning into λ
02:07:41 <maukd> ☭
02:07:41 <maukd> nice
02:08:15 <merijn> ∃k∈ComposeKeys . NeverUsed(k)
02:08:37 <merijn> I'd prefer to have an input method using latex for math codepoints, though :p
02:08:58 <maukd> I can do that, but only in irssi
02:09:21 <maukd> haven't tried to script it in vim yet
02:09:23 <shachaf> I don't have a binding for ∃, I think. :-(
02:09:30 <merijn> shachaf: n00b
02:09:35 <maukd> want mine? <Compose> E E here
02:09:38 <merijn> maukd: Someone here was working on it for vim
02:09:58 <sheriff_> What's the name for using ()'s to 'de-infix' an infix constructor/operator? /me was thinking it was sectioning, but it's not
02:10:03 <shachaf> merijn: Hey, I know the code point by heart!
02:10:10 <shachaf> I just type ctrl-shift-u 2203
02:10:18 <maukd> shachaf: http://hpaste.org/75473
02:10:24 <theplanet> the windows DE is actually better than gnome
02:10:28 <merijn> sheriff_: Not sure it really has a name
02:10:35 <theplanet> u?
02:10:36 <sheriff_> merijn: That might explain why I can't find one :-)
02:10:49 <theplanet> rrs
02:10:53 * shachaf is too lazy to set up a custom Xcompose file.
02:11:03 <maukd> oh damn, the unicode is all messed up
02:11:04 <merijn> sheriff_: It's just a disambiguation trick for the parser, not really any dark voodoo :p
02:11:07 <Jafet> merijn: there is one
02:11:10 <theplanet> you shouldnt be coding if you are that lazy
02:11:13 <merijn> Jafet: There is?
02:11:25 <shachaf> maukd: Is that hpaste messing it up?
02:11:34 <Jafet> Or rather, it's a bunch of latex definitions for an IME program.
02:11:54 <theplanet> maukd, can i map it to the windows-logo key
02:12:05 <theplanet> finally have use for it on non-windows os's
02:12:09 <theplanet> ;)
02:12:12 <merijn> Jafet: Oh, latex input method. I thought you were referring to my answer to sheriff_ :p
02:12:31 <merijn> Jafet: I know, but I haven't found a really nice input method program for OSX yet
02:12:46 <merijn> I guess I should ask my Chinese colleagues :p
02:13:03 <maukd> shachaf: http://hpaste.org/75475 #fixed
02:13:12 <maukd> bug in my paste script
02:13:24 <maukd> theplanet: yes
02:14:41 <shachaf> _∘_ : {A : Set}{B : A → Set}{C : (x : A) → B x → Set} → (f : {x : A} (y : B x) → C x y) → (g : (x : A) → B x) → (x : A) → C x (g x)
02:14:44 <shachaf> What a great type.
02:14:52 <theplanet> what the hell is that
02:15:11 <theplanet> →
02:15:13 <shachaf> Function composition.
02:15:19 <theplanet> is → used for haskell coding?
02:15:28 <maukd> theplanet: not normally
02:16:01 <maukd> heh, <Compose> q e d
02:16:04 <maukd> I forgot about that
02:16:04 <shachaf> That's not Haskell.
02:16:17 <hvr> shachaf: ...so what is it?
02:16:19 <ion> My Compose table doesn’t seem to have that.
02:16:20 <shachaf> maukd: U+220e?
02:16:36 <maukd> shachaf: yes
02:16:37 <shachaf> hvr: Agda.
02:16:45 <maukd> ion: see my hpaste
02:16:50 <maukd> it's a custom definition
02:17:00 <pordan30> ibus is really convenient: Ctrl+Space \rightarrow instead of remembering unicode
02:17:18 <maukd> \rightarrow? do you think I'm made of typing?
02:17:39 <shachaf> ¦
02:17:46 <ion> maukd: Ah, thanks. Are you going to update it in the future? In that case, would you mind putting it to a public VCS repo somewhere?
02:18:12 <shachaf> ion: kmc had a nice post about his custom xcompose file.
02:18:13 <pordan30> if you read math in latex by force of habit it's convenient, i mean :/
02:18:29 <shachaf> I think it's also on Github.
02:18:38 <maukd> ion: ah, right. I should probably upload it to github
02:18:43 <maukd> next week maybe
02:19:18 <shachaf> You should get U+261D
02:19:20 <maukd> but I haven't changed it in a while
02:19:27 <maukd> heh
02:19:43 <maukd> I don't think I've ever needed that
02:20:10 <maukd> and when I do, I'm probably not going to remember whatever combination I set for it
02:20:13 <shachaf> It's useful for pointing to something someone else said.
02:20:14 <ion> Is there a way to reload .XCompose without restarting X?
02:20:17 * shachaf is boycotting "^".
02:20:26 <efie> where is defined that [a] is the same as [ ] a?
02:20:33 <maukd> ion: compose tables are in userspace. just restart whatever application
02:20:42 <ion> maukd: Oh, ok. Thanks.
02:20:52 <pordan30> why doesn't ∘ have type ∀ (A B C : Set), (B → C) → ((A → B) → (A → C))? What is being encoded in the types of the function arguments?
02:21:04 <shachaf> ion: http://mainisusuallyafunction.blogspot.com/2010/10/typing-mathematical-characters-in-x.html
02:21:13 <ion> shachaf: Thanks, already looking at it.
02:21:40 <maukd> shachaf: heh, maybe I'll try that
02:21:45 <shachaf> pordan30: Dependent types.
02:21:46 <maukd> map it to ^ ^, etc
02:22:01 <merijn> pordan30: You lose out the ability to compose dependent functions in your type :p
02:22:10 <bitonic> is there a simple way to get a UNIX timestamp without old-time?
02:22:41 <pordan30> oh, i see - that's neat
02:22:59 <bitonic> do I have to get the diff between the UTCTime and 1 Jan. 1970?
02:23:26 <merijn> efie: In what sense?
02:25:04 <typoclass> bitonic: Data.Time.Clock.POSIX, i think
02:25:06 <maukd> bitonic: getPOSIXTime
02:25:22 <bitonic> oh, thanks
02:25:38 <efie> merijn: I can do [3] :: [Int] as well as [3] :: [] Int... I was reading the chapter at LYAHFGG and in the definition of fmap it says "... f a .. " and for lists that would be "[] a" - is this the correct one whereas [a] is just syntactic sugar? If so, where is this suggar written down?
02:26:10 <shachaf> efie: It's part of the language standard.
02:26:17 <shachaf> There's a special case just for []
02:26:27 <hiptobecubic> > [3] :: [] Int
02:26:28 <lambdabot>   [3]
02:26:36 <maukd> what do you mean by "written down"?
02:26:43 <hiptobecubic> documented?
02:26:48 <maukd> the report
02:26:50 <hiptobecubic> > 3 :: IO Int
02:26:51 <lambdabot>   No instance for (GHC.Num.Num (GHC.Types.IO GHC.Types.Int))
02:26:51 <lambdabot>    arising from ...
02:26:55 <efie> yes, documented
02:27:19 <hiptobecubic> > return 3 :: IO Int
02:27:21 <lambdabot>   <IO Int>
02:27:30 <shachaf> R6RH
02:32:18 <maukd> efie: http://www.haskell.org/onlinereport/haskell2010/haskellch4.html#x10-650004.1.2
02:32:20 <bitonic> shachaf: lol.  thank got it's not like that.
02:36:56 <efie> maukd: "A list type has the form [t], which is equivalent to the type [] t" - thanks
02:37:54 <ion> “Though my use of Haskell here may seem gratuitous, …” wat?
02:40:04 <merijn> ion: Where'd you read that?
02:41:11 <sheriff_> Let's say I have: Foo f
02:41:19 <sheriff_> Which is a polymorphic type
02:41:39 <ion> merijn: http://mainisusuallyafunction.blogspot.fi/2010/10/typing-mathematical-characters-in-x.html
02:41:51 <sheriff_> And I use an associated data constructor to create a value of type: Foo Int
02:42:06 <sheriff_> What's the term to describe the new 'specialized' type. I've been using 'specialized' and I think it's the wrong word
02:42:39 <maukd> you mean like data Foo f = Bar f and you use Bar 42?
02:42:55 <maukd> I don't see Foo Int as a "new" type
02:43:11 <maukd> hmm, you could call it an instance
02:43:40 <sheriff_> So it's a recursive type, and I'm trying to make the point
02:43:54 <merijn> I'd go with instance, yes. specialisation usually has a different meaning in a compiler context
02:43:55 <sheriff_> That while I can append other values to a 'specialized' type that are still in their polymprophic state
02:44:12 <sheriff_> If I have a value that's 'specialized' differently, I can't then append it
02:44:15 <sheriff_> (if that makes sense)
02:44:15 <maukd> "monomorphic"?
02:44:35 <sheriff_> I think as long as there isn't a regular term, I'll just make the words up as I go :-)
02:46:56 <merijn> sheriff_: Usually you would note that given "data Tree a = Branch (Tree a) (Tree a) | Leaf a" and "bar :: Tree X; baz :: Tree Y" that the types in "Tree bar baz" don't unify
02:47:53 <sheriff_> That's what I've noted in my homework, without using the word 'unify'
02:48:00 <sheriff_> I think I'll avoid using that word so I don't have to cite it :-P
02:48:13 <maukd> but it's the right word!
02:48:26 <sheriff_> maukd: Sure, but I'm being scrupulously honest in my citations
02:48:39 <maukd> http://en.wikipedia.org/wiki/Unification_(computer_science)#Type_inference
02:48:39 <sheriff_> maukd: And so far all work is my own doing. If I take that word, I have to explain I got it from somewhere :-P
02:48:46 <hiptobecubic> serban, look it up and then cite it :)
02:48:46 <merijn> sheriff_: The way the type checker works is that it tries to unify any type variables in combined expressions and if the variables can't unify then the expression doesn't type check
02:52:52 <sheriff_> Is the correct name for a data constructor's "type signature" simply "type signature"?
02:56:12 <bitonic> sheriff_: definitely
02:57:04 <maukd> or just "type"
02:57:18 <maukd> like, 'Just' has the type a -> Maybe a
03:00:43 <merijn> Math/logic question: What's the correct way to "assert" that a condition holds in given scenario?
03:00:59 <merijn> Or rather, write down that assertion
03:01:22 <sheriff_> Are you trying to say that "x is true where assertion"
03:01:33 <sheriff_> Or are you trying to say "is assertion true"?
03:02:26 <merijn> I'm describing an abstract machine for my algorithm and I need to say that a given transition is only when condition X holds
03:02:38 <merijn> s/is only/is only allowed
03:03:09 <sheriff_> So conceptually your assertion is the left-side of a Haskell guard
03:03:31 <McChousuke> @quote Kukkua
03:03:32 <lambdabot> Kukkua says: They say there are two things, once mastered, you will harness boundless strength from the cosmos itself, continuations and monads.
03:03:46 <Maxdamantus> @quote Kakka
03:03:47 <lambdabot> No quotes match. I've seen penguins that can type better than that.
03:05:02 <merijn> sheriff_: Not really, more like a type restriction on an expression that doesn't typecheck if the guard doesn't hold :p
03:07:00 <merijn> I guess I want something like "D ⊧X" where D is my machine state and X my condition?
03:07:05 <sheriff_> Sure. But your assertion here has a hypothesis, which means it's either the antecedent of implication, or the left-side of &&
03:07:50 <sheriff_> In Z-Notation, then, you either want: D => X   or D ∧ X
03:07:53 <merijn> What do you mean by "your assertion has a hypothesis"
03:08:09 <sheriff_> Sorry, I meant /is/ a hypothesis
03:08:34 <sheriff_> By which all I really mean is it has a truth value
03:09:03 <sheriff_> Is there also a condition where the assertion fails/
03:09:27 <merijn> I'm trying to say "the valid transitions in the abstract machine are: <list of transitions here>" and for one transition T from S_1 to S_2 I want to say that T(S_1, S_2) is only a valid transition iff X holds in S_1
03:13:03 <sheriff_> Either choose a format that allows expression of this sort of thing (like Z-Notation), or just write it out long hand
03:14:33 * sheriff_ & back to homework
03:16:23 <Maxdamantus> merijn: in S_1 or S_2?
03:17:21 <merijn> Maxdamantus: In S_1
03:17:23 <Maxdamantus> merijn: write a function that maps from states to sets of potential to states.
03:18:37 <merijn> Maxdamantus: That's essentially what my transitions *are*, I just want to assert a precondition for some of them
03:18:43 <Maxdamantus> transitions(s) = { t | T(s, t), X(s) }
03:20:33 <Maxdamantus> or maybe T(s, t) \land X(s) → transition(s, t)
03:20:55 <merijn> I think I'll just stick to my current approach with ⊦
03:20:56 <merijn> http://hpaste.org/75477
03:23:11 <Maxdamantus> What's the ⇒ notation?
03:23:48 <sheriff_> Maxdamantus: Implication operator
03:23:55 <sheriff_> in Z Notation
03:24:04 <Maxdamantus> No, his use of it.
03:24:07 <sheriff_> ah, sorry
03:24:15 <Maxdamantus> (just wondering)
03:24:17 * merijn hasn't even heard the term Z notation
03:24:47 * Maxdamantus has only heard of it.
03:25:15 <merijn> Maxdamantus: In this case it denotes transition from state D_1 to D_2 via the transition in the middle. I just stole that use from an earlier paper I'm citing
03:25:53 <Maxdamantus> Ah. I could see what it was representing. Was just wondering where it came from/if it had a name.
03:26:07 <Maxdamantus> (or if you'd defined it yourself)
03:28:49 <bitonic> if I have a `Foo {-# UNPACK #-} !Word8 !Word8 !Word8 !Word8', will the 4 Word8 be packed together
03:36:29 <tuttlem> Hi all, I'm stuck. I've defined a data type like this (Person String Int)... when using this data type, I have no idea how to get the string or the integer out of it as it's referenced as Person.
03:37:00 <tuttlem> I know it's a pretty "entry level" question -- I'm just stuck!
03:37:22 <merijn> tuttlem: You mean you have "data Person = Person String Int"?
03:37:23 <cark> myFun (Person s i) = workWithString s
03:37:46 <tdammers> pattern matching
03:38:00 <merijn> What cark just wrote should work :)
03:38:04 <tuttlem> merijn: yep, just like that.
03:38:06 <tdammers> let Person s i = p
03:38:24 <tuttlem> cark: awesome. I'll try that now.
03:38:28 <Jafet> bitonic: no, because you didn't ask to unpack all of them.
03:38:29 <Maxdamantus> > let Person s i = p
03:38:30 <lambdabot>   not an expression: `let Person s i = p'
03:38:42 <tdammers> you obviously have to have an 'in' part, too
03:38:43 <Jafet> And if you did, they would be packed together as four words.
03:38:57 <tdammers> e.g. let Person s i = p in putStrLn s
03:39:00 <Maxdamantus> > let Person s i = p in s
03:39:01 <lambdabot>   Not in scope: data constructor `Person'
03:39:02 <bitonic> Jafet: right, I meant to unpack them all.  thanks.
03:39:06 <Jafet> If you actually want four bytes, use Word32 or a ByteArray.
03:39:10 <Maxdamantus> Oh, nvm .. I see it now.
03:39:32 <merijn> "toString :: Person -> String; toString (Person s i) = "Person " ++ s ++ " " ++ show i"
03:40:03 <Jafet> (On amd64, I'm not sure if ghc allows four bytes.)
03:40:03 <bitonic> Jafet: no, I have four bytes that are independent, I don't want to pack/unpack them if I canb
03:40:19 <merijn> tuttlem: Does that function make sense to you? (++ being string concatenation and show turning an Int into a String)
03:40:28 <bitonic> Jafet: Word32 surely works on 64bit, but I don't think that's what you meant
03:40:48 <tuttlem> merijn: that' fantastic.. I've got that part building now. Thanks for your help (everybody!)
03:41:05 <Jafet> bitonic: Word8 uses the same amount of space as Word.
03:41:09 <merijn> tuttlem: Out of curiosity: What are you reading to learn haskell?
03:41:12 <efie> tuttlem: you might also check out the record syntax: http://learnyouahaskell.com/making-our-own-types-and-typeclasses#record-syntax
03:41:24 <bitonic> Jafet: yes, which is why I want them to be packed :)
03:41:43 <Jafet> What does "packed" mean, then?
03:41:43 * merijn was going to recommend LYAH if you weren't already reading it :p
03:41:44 <tuttlem> merijn: I'm being very impatient with LearnYouAHaskell.. I should just read more, but I'm so keen to actually "do something".
03:41:51 <merijn> tuttlem: :p
03:42:17 <bitonic> Jafet: that they won't occupy a word each
03:42:20 <tuttlem> Bet you guys get chumps like me in here all the time then. :)
03:42:22 <merijn> tuttlem: Well, if you want to see some stuff happening quickly you could also try http://tryhaskell.com/
03:42:33 <Jafet> UNPACK probably doesn't do that.
03:42:37 <merijn> Although I'd recommend going over LYAH as well afterwards
03:42:44 <tuttlem> Sweet. Thanks merijn, I'll check it out now.
03:43:03 <bitonic> Jafet: OK, that's what I was asking.
03:43:41 <bitonic> sorry for the confusion, the terminology is a bit poor - I meant "packed together"
03:43:41 <merijn> hmm, tryhaskell seems a bit...unresponsive atm
03:44:33 * hackagebot hedis 0.6.2 - Client library for the Redis datastore: supports full command set,  pipelining.  http://hackage.haskell.org/package/hedis-0.6.2 (FalkoPeters)
03:44:34 <tuttlem> It's going alright for me.
03:44:48 <merijn> ok, maybe just me then :)
03:45:15 <PatrixCR> .
03:45:34 <Jafet> If it's important to you, you will want to use a ByteArray# or something.
03:45:54 <bitonic> Jafet: or Word32 as you said.  I just wanted to avoid bit fiddling.
03:46:21 <Jafet> Well, think about what The Hardware does.
03:47:13 <bitonic> having it in a 64bit word (so I'm wasting 4 bytes) is not that much of a problem
03:47:25 <bitonic> but having 4 words in any case is much worse
03:48:30 <Jafet> Also, strict array libraries have the correct instances for these types.
03:50:03 <mysticc> @src foldl
03:50:03 <lambdabot> foldl f z []     = z
03:50:04 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
03:50:13 <bitonic> that's true.  I could simply have an unboxed vector
04:01:49 <efie> is Either String a type or a type constructor? I thought I would be the latter, but LYAH says "Either String is a type that takes one type and produces a concrete type, like Either String Int"
04:02:28 <maukd> looks like LYAH calls everything a "type"
04:03:04 <merijn> efie: It's not a difference I'd personally worry about
04:03:55 <merijn> I think the definition of type constructor is just "something that takes one or more types as arguments and returns a type"
04:04:27 <merijn> Whether that something is a type or a type constructor or both seems unimportant to worry about as long as you get what people are talking about
04:04:55 <efie> hm ok
04:05:24 <SLi> ... given enough arguments? Wouldn't it make more sense to say that Either is a type constructor that, given a type, returns a type constructor that takes a type and returns a type.
04:06:28 <merijn> SLi: Depends, given "data Bar a = Foo a a a a" would you call "Foo" a constructor taking a value and returning a constructor?
04:06:46 <SLi> Hmm. :)
04:07:12 <maukd> just use OCaml; they don't allow Foo
04:07:13 <SLi> Hm, in value-land, functions (and thus constructors) are values too, but in type-land, type constructors are not themselves types?
04:07:38 <efie> Foo is a value/data constructor, not a type constructor
04:07:59 <efie> I think for type constructors it would make sense
04:08:13 <merijn> SLi: Well, I think they are and so does LYAH (hence why they call "Either String" and "Either" types, rather than type constructors
04:09:34 <maukd> type constructors ⊂ types
04:10:47 <SLi> Hmm, and all inhabitants of unary types are values, while all inhabitants of type constructors (= non-unary types) are types themselves?
04:12:16 <merijn> To start an entirely different line of questions: Can forkIO threads be moved to another OS thread in the middle of execution of a FFI function?
04:12:16 <maukd> what's a unary type?
04:12:42 <SLi> Um, nullary, I should have said.
04:12:59 <maukd> type constructors don't have inhabitants
04:13:34 <SLi> But they are also different from a non-constructor type that does not have inhabitants (the nullary type).
04:13:53 <SLi> As you cannot even construct a function that would hypothetically take a value of that type.
04:14:17 <SLi> Or give a bottom of that type.
04:15:17 <SLi> So I think it's more like the inhabitants relation is not defined for type constructors, but is defined for all non-constructor types.
04:15:59 <maukd> τ :: *
04:17:26 <SLi> It seems to me that you would more often like to talk about the kind of types that can have inhabitants (at least I find myself talking more about things in the value-land than in the type-land), and therefore it would make sense to give the name "type" to the beings for which the inhabitant relation is defined, and to call type constructors something else.
04:17:59 <SLi> But, it's not such an important distinction in practice, maybe. Usually it's clear from the context which kind of type you mean. :)
04:18:06 <efie> LYAH says: "Type constructors take other types as parameters to eventually produce concrete types." So for example Maybe is a type constructor which can take >type< Int and produces >concret type< Maybe Int. As I guess Int is also a >concret type<. Maybe can also take just >types<? That would be, not a concret type ... for example what? I don't get the distinction between "concret type" and "type"
04:18:14 <maukd> excellent use of "kind"
04:18:27 <SLi> maukd, I noticed that too after typing that line :D
04:18:42 <SLi> Concrete type. That's nice.
04:19:10 <maukd> efie: looks like LYAH partitions "type" into "type constructor" and "concrete type"
04:19:13 <SLi> Though I don't think Maybe can take non-concrete types?
04:19:40 <maukd> efie: a bit more formally, "concrete types" are those of kind * while "type constructors" are everything else
04:19:48 <maukd> Maybe has kind * -> *
04:19:55 <maukd> @kind Maybe
04:19:57 <lambdabot> * -> *
04:20:00 <maukd> @kind Int
04:20:01 <lambdabot> *
04:20:04 <maukd> @kind Maybe Int
04:20:05 <lambdabot> *
04:20:07 <maukd> @kind Int Int
04:20:09 <lambdabot>     `Int' is applied to too many type arguments
04:20:09 <lambdabot>     In the type `Int Int'
04:20:13 <maukd> @kind Maybe Maybe
04:20:15 <lambdabot>     `Maybe' is not applied to enough type arguments
04:20:15 <lambdabot>     The first argument of `Maybe' should have kind `*',
04:20:15 <lambdabot>     but `Maybe' has kind `* -> *'
04:20:18 <SLi> But LYAH is imprecise in not saying that "Maybe is a type constructor which can take >a concrete type<"?
04:20:24 <maukd> yes
04:20:26 <SLi> Because you cannot say something like Maybe Maybe
04:20:29 <SLi> :kind Maybe Maybe
04:20:34 <SLi> @kind Maybe Maybe
04:20:36 <lambdabot>     `Maybe' is not applied to enough type arguments
04:20:36 <lambdabot>     The first argument of `Maybe' should have kind `*',
04:20:36 <lambdabot>     but `Maybe' has kind `* -> *'
04:21:07 <maukd> @kind ReaderT
04:21:09 <lambdabot> * -> (* -> *) -> * -> *
04:21:37 <efie> ah, that's clearer now
04:21:48 <maukd> @kind ReaderT Char Maybe String
04:21:49 <lambdabot> *
04:22:51 <maukd> @kind ReaderT Char (ReaderT () ((->) Int)) String
04:22:52 <lambdabot> *
04:23:13 <ZsoL> is it possible for a function (f :: a -> b -> c) to have a different definition (or work in a different way) when the type of a and b are the same?
04:23:43 <ZsoL> I guess this would mean some kind of runtime type inspection
04:24:28 <maukd> not with that exact type
04:25:19 <ZsoL> you mean not with f's type?
04:25:22 <merijn> ZsoL: If you want to decide behaviour on the values of a and b you'll most likely need a typeclass or something similar
04:25:25 <maukd> @let isChar x = typeOf x == typeOf 'a'
04:25:26 <lambdabot>  Defined.
04:25:28 <maukd> :t isChar
04:25:30 <lambdabot> forall a. (Typeable a) => a -> Bool
04:25:30 <merijn> ZsoL: Can you explain what you want to do?
04:25:34 <ZsoL> aha so this is what Typeable is for
04:25:42 <maukd> > isChar '.'
04:25:44 <lambdabot>   True
04:25:48 <maukd> > isChar 42
04:25:50 <lambdabot>   False
04:25:51 <ZsoL> gotcha
04:26:07 <maukd> @let a === b = cast a == Just b
04:26:09 <lambdabot>  Defined.
04:26:14 <merijn> Ah, yeah. I guess that'd do it
04:26:15 <ZsoL> sure i can explain it if you're still interested :)
04:26:41 <merijn> ZsoL: Yes, because for many scenario's there might be smarter solutions than Typeable :p
04:26:50 <ZsoL> quite possible
04:26:52 <ZsoL> hang on
04:27:23 <tdammers> maukd: that smells of Acme.PHP
04:29:14 <maukd> > "Haskell" === "PHP"
04:29:16 <lambdabot>   False
04:29:29 <maukd> > "Haskell" === sqrt 42
04:29:31 <lambdabot>   False
04:29:50 <ZsoL> https://gist.github.com/fc98801b36de7685f1a7
04:29:56 <ZsoL> i have something like this
04:29:59 <sipa> :t cast
04:30:00 <lambdabot> forall a b. (Typeable a, Typeable b) => a -> Maybe b
04:30:44 <ZsoL> oh wait i left out the most important part
04:34:04 <ZsoL> ok
04:34:09 <ZsoL> so, https://gist.github.com/fc98801b36de7685f1a7
04:34:46 <ZsoL> the root of the problem is that I have to be able to create instances of Combine
04:34:50 <ZsoL> from a configuration
04:35:25 <efie> Type constructors cannot be instances of typclasses, can they?
04:35:48 <PatrickRobotham> efie: Yes they can, Functor is a type class.
04:36:26 <efie> PatrickRobotham: uh oh, yeah :)
04:36:54 <maukd> constructor classes, fuck yeah
04:37:16 <PatrixCR> let sqr x = x * x
04:37:18 <ZsoL> ok so is my problem clear?
04:37:45 <merijn> ZsoL: I think the type on your combineAndShow is wrong?
04:37:52 <ZsoL> possibly
04:38:03 <ZsoL> yeah
04:38:04 <merijn> ZsoL: Shouldn't that be "AnyCombine -> AnyCombine -> String"?
04:38:05 <ZsoL> there's two arguments
04:38:06 <ZsoL> yep
04:38:32 <maukd> then the definition is wrong
04:38:33 <ion> let sqr = (^2)
04:38:42 <merijn> I think this looks like a case for GADTs and Rank2Types :p
04:39:16 <maukd> this code is so java
04:39:41 <merijn> ZsoL: Is the number of combinable things big?
04:39:47 <ZsoL> not right now
04:39:49 <merijn> (Say, more than 5?)
04:40:20 <ZsoL> but potentially there will be more than 5
04:41:24 <merijn> ZsoL: What are you combining in actual reality?
04:41:57 <ZsoL> arbitrarily complex algebraic data types usually
04:42:10 <ZsoL> they repesesent some sort of intermediate state
04:42:44 <ZsoL> when a new input comes in it produces another state and i want to merge it in
04:43:02 <efie> is there a type constructor which takes another type constructor (and maybe more concret types) to produce a concret type? could you give me an example?
04:43:23 <merijn> ZsoL: Isn't Combine just a reinvention of Monoid?
04:43:53 <maukd> efie: I did, see above
04:44:15 <ZsoL> merijn: my god you are right :P
04:44:26 <Phil_> Very stupid question: when trying to load a module with ghci I get told to "Use -XMultiParamTypeClasses to....". Where do I specify this options? The :load command doesn't seem to allow options to be specified
04:44:31 <ZsoL> i could possibly come up with an identity
04:44:43 <maukd> Phil_: either in the file itself, or with :set
04:45:14 <ion> merijn: Or semigroup?
04:45:19 <efie> maukd: you mean ReaderT Char Maybe String? As I didn't know ReaderT I just ignored this :x
04:45:28 <Phil_> @maukd how do I set it in the file?
04:45:28 <benmachine> Phil_: you can pass -X options to GHC, or use LANGUAGE pragmas in the source file, or use :set
04:45:28 <lambdabot> Unknown command, try @list
04:45:45 <benmachine> Phil_: {-# LANGUAGE MultiParamTypeClasses #-}
04:45:57 <merijn> Pet peeve: loading a file with pragmas in ghci doesn't enable said flags for the entire session with that file...
04:46:04 <ZsoL> merijn: but this doesn't help me, does it?
04:46:07 <benmachine> merijn: yeah, that annoys me too
04:46:12 <Phil_> @benmachine Thanks
04:46:12 <lambdabot> Unknown command, try @list
04:46:20 <merijn> ZsoL: Not really, that's just one think I just realised :p
04:46:23 <benmachine> Phil_: try not to start messages with @, it confuses lambdabot :)
04:46:23 <ZsoL> ah ok
04:46:33 <ZsoL> good to know anyway
04:46:52 <benmachine> merijn: I reckon if you submitted a feature request around that it might be accepted
04:46:55 <benmachine> merijn: alternatively, .ghci
04:47:01 <ZsoL> so you're saying i should read up on rank2types and gadts?
04:47:02 <maukd> efie: oh, you wanted something you can understand? :-)
04:47:17 <maukd> @src ReaderT
04:47:17 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
04:47:20 <maukd> :-(
04:47:25 <maukd> @unmtl ReaderT e m a
04:47:25 <lambdabot> e -> m a
04:48:40 <merijn> ZsoL: I'm not sure those will actually help your case
04:48:57 <maukd> data OfInt f = C (f Int)
04:49:05 <maukd> OfInt :: (* -> *) -> *
04:49:10 <merijn> ZsoL: The main problem is that "createCombineFromConfig" doesn't encode which type of state it is in the type
04:49:21 <merijn> ZsoL: So it is hard to do something smart based on the states
04:52:58 <efie> maukd: ah, I think I get the last one
04:53:00 <Morgawr> This might be a stupid question but.. is there a way to implement something like global data in a Haskell application? Maybe using State monads or something? For example I have a program that interacts with two GUI elements and I need to call several functions on events and each function may want to access some global data, where would I store such things?
04:53:33 <Morgawr> I know I could pass everything around but I don't think having a thousand parameters for each function is really useful...
04:53:54 <maukd> you could use a single parameter containing a struct
04:54:11 <maukd> and you could call that parameter "this"
04:54:25 <Morgawr> yes but the parameter itself isn't per se relevant to the function.. it's just "global data" that I may request if needed
04:55:02 <ZsoL> merijn: the other option i'm considering is to use template haskell to define createCombineFromConfig
04:55:48 <ion> I had a problem. I thought i’d solve it with Template Haskell. Now i have two problems.
04:55:57 <merijn> Morgawr: You could store the data in an MVar and pass that MVar to any functions that need it
04:56:22 <ZsoL> ion: i've used it successfully so far
04:56:25 <merijn> Morgawr: Although that forces you into IO, but so will any other scheme (unless it's read only data)
04:56:33 <maukd> merijn: or IORef
04:56:37 <merijn> That too
04:56:48 <merijn> STM is another option
04:57:15 <merijn> Morgawr: If you have read only data than you might be able to stay out of IO
04:57:18 <ZsoL> thanks for the help anyway :]
04:58:16 <Morgawr> well, I am already operating in IO mostly.. I will check that, thanks
05:00:01 <bitonic> is there the reverse of IsString anywhere?  not something like Show, but something that says "this is a list of characters".  something that String and Text would be instances of
05:01:13 <merijn> Morgawr: Oh, then IORef/MVar's are by far the easiest. You can use State to transport them to the places you need them and then use IO operations to get info in and out whenever you need it
05:02:02 <maukd> did you mean: Reader
05:02:12 <ion> bitonic: This isn’t what you asked for, but perhaps it’s useful anyway: http://hackage.haskell.org/packages/archive/lens/3.0/doc/html/Data-Text-Lens.html
05:02:23 <Morgawr> merijn: thank you :)
05:02:55 <bitonic> ion: well, I could also use `ListLike a Char'.  but I was wondering if something more specific existed
05:14:35 * hackagebot usb-id-database 0.4.0.8 - A database of USB identifiers  http://hackage.haskell.org/package/usb-id-database-0.4.0.8 (RoelVanDijk)
05:14:37 * hackagebot ls-usb 0.1.0.12 - List USB devices  http://hackage.haskell.org/package/ls-usb-0.1.0.12 (RoelVanDijk)
05:19:35 * hackagebot roman-numerals 0.5.1.2 - Parsing and pretty printing of Roman numerals  http://hackage.haskell.org/package/roman-numerals-0.5.1.2 (RoelVanDijk)
05:28:26 <ClaudiusMaximus> roman-numeral eh, i remember some computing contest in school where that was a task, i was deducted points because i used if+goto instead of (whatever the bbc/acorn basic syntax for while loops was)
05:28:59 <maukd> pfft, just hardcode all combinations
05:39:36 * hackagebot terminal-progress-bar 0.0.1.1 - A simple progress bar in the terminal  http://hackage.haskell.org/package/terminal-progress-bar-0.0.1.1 (RoelVanDijk)
05:44:22 <Philonous> Is there a library for managing groups/hierarchies of threads?
06:28:49 <lazylemur> hello
06:30:42 <lazylemur> how do data structures/ADTs work in a purely functional language like Haskell?
06:31:22 <lazylemur> I guess haskell has bitwise operations like C does (but maybe with different operators)
06:31:58 <sheriff_> ok
06:32:12 <akamaus> is there an easy way to rebuild all the installed libraries to include profiling support?
06:32:18 <sheriff_> lazylemur: ... on integers?
06:32:48 <lazylemur> yes
06:33:04 <sheriff_> lazylemur: First Google result for "haskell integer bitwise" looks promising
06:34:59 <merijn> lazylemur: What do you mean with "how do data structures work"? Do you mean semantics, implementation or...?
06:37:32 <lazylemur> http://rosettacode.org/wiki/Bitwise_operations#Haskell
06:37:50 <lazylemur> implementation
06:39:56 <merijn> lazylemur: They're just pointers to values (their contents) plus a tag to indicate which constructor
06:46:46 <pordan30> lazylemur: A classic paper is Mitchell and Plotkin's "Abstract Types Have Existential Type." Also, Okasaki's PHD thesis is the de facto standard on purely functional data structures.
06:49:37 * hackagebot doctest-prop 0.1.0.0 - Allow QuickCheck-style property testing within doctest.  http://hackage.haskell.org/package/doctest-prop-0.1.0.0 (TakayukiMuranushi)
06:53:38 <merijn> There's no way to have "IO a" values magically replaced with "MonadIO m => m a" without manually liftIO-ing everything, right?
06:54:30 <mikeplus64> right
06:58:58 <merijn> Bah
07:04:38 * hackagebot doctest-prop 0.1.0.1 - Allow QuickCheck-style property testing within doctest.  http://hackage.haskell.org/package/doctest-prop-0.1.0.1 (TakayukiMuranushi)
07:04:40 * hackagebot doctest-prop 0.2 - Allow QuickCheck-style property testing within doctest.  http://hackage.haskell.org/package/doctest-prop-0.2 (TakayukiMuranushi)
07:05:49 <ozgura> what does ghc "ExitFailure 11" mean?
07:06:32 <ClaudiusMaximus> ozgura:        SIGSEGV      11       Core    Invalid memory reference
07:06:38 <ClaudiusMaximus> probably
07:07:04 <ClaudiusMaximus> but it could be anything, depending on the command that failed
07:07:40 <ozgura> compiling something via cabal, it gives me an ExitFailure 11 the first time, after compiling 7 modules
07:07:48 <ozgura> (a total of 43 modules is to be compiled)
07:07:59 <dcoutts> ozgura: low memory?
07:07:59 <rwbarton> could be running out of memory
07:08:06 <ozgura> then I 'cabal install' again, and it goes through this time
07:08:33 <ozgura> I tried passing --ghc-options="-H2G +RTS -M1G" but doesn't seem to help
07:08:45 <ozgura> my first guess was low memory too
07:08:51 <rwbarton> or bad memory :)
07:09:05 <ozgura> rwbarton: that doesn't sound too good
07:09:07 <dcoutts> ozgura: check if it's ghc that's getting killed, or ld
07:09:22 <ozgura> dcoutts: hmm good point
07:09:38 * hackagebot cmaes 0.1.0.0 - CMA-ES wrapper in Haskell  http://hackage.haskell.org/package/cmaes-0.1.0.0 (TakayukiMuranushi)
07:09:40 * hackagebot cmaes 0.1.0.1 - CMA-ES wrapper in Haskell  http://hackage.haskell.org/package/cmaes-0.1.0.1 (TakayukiMuranushi)
07:09:41 <ozgura> this is before linking though
07:09:52 <ozgura> always while compiling 7th module
07:09:59 <ozgura> (which is quite a big one)
07:10:07 <ClaudiusMaximus> are you using -O2 and/or template haskell
07:10:22 <ClaudiusMaximus> because big modules with lots of data and ghc -O2 did give me big memory troubles once
07:10:36 <ClaudiusMaximus> think it was graphviz
07:10:39 <ozgura> ClaudiusMaximus: I am using both, yes.
07:10:55 <ClaudiusMaximus> bbiab, lunch
07:12:13 <ozgura> was using --ghc-options="+RTS -M1G" before, tried -M2G now and seems to work without the ExitFailure 11.
07:12:26 <ozgura> 1G wasn't enough then
07:12:31 <rwbarton> wouldn't no --ghc-options be best? isn't the heap size unbounded by default?
07:12:49 <ozgura> rwbarton: is it? let me try.
07:13:31 <ozgura> the docs (http://www.haskell.org/ghc/docs/latest/html/users_guide/runtime-control.html#rts-opts-cmdline) say it is unlimited afterall
07:13:49 <ozgura> i don't remember why i added that ghc option in my build script now
07:14:16 <ozgura> that is a non-problem solved now. thanks :)
07:15:21 <ClaudiusMaximus> ozgura: except when ghc eats all your ram sufficiently slowly that you can't do anything at all http://claudiusmaximus.goto10.org/g/tech/oops.gif
07:15:48 <rwbarton> right, "best" in the sense of "attempt to compile at all costs" :)
07:15:57 <ozgura> ClaudiusMaximus: maybe I should add an upper bound then :)
07:16:01 <ClaudiusMaximus> (running with disk-based swap would have let me spot it before it started paging out X11 etc)
07:16:27 <ClaudiusMaximus> probably best to set it system wide to "whole memory - 512MB
07:16:44 * ClaudiusMaximus resumes lunch
07:26:25 <efie> http://hackage.haskell.org/package/terminal-progress-bar-0.0.1.1 says "or build the package with the -fexample flag for a small example program", so I did "cabal install terminal-progress-bar -fexample". Do you know how can I access this example program?
07:27:19 <ClaudiusMaximus> efie: `http://hackage.haskell.org/packages/archive/terminal-progress-bar/0.0.1.1/terminal-progress-bar.cabal has the stanza commented out, so it doesn't exist
07:27:59 <ClaudiusMaximus> efie: cabal unpack && bump version && uncomment executable && cabal install -fexample   -- maybe
07:45:00 <merijn> If I plan to provide an alternative interface (using monad transformers) for a module Foo, should I put the new one under Foo (i.e. Foo.Trans) or at the same level (i.e. FooTrans)
07:46:08 <nand`> since there's no distinction between levels I think Foo.Trans would be more sensible than FooTrans
07:46:23 <nand`> simply because it looks cleaner
08:10:56 <bookerz> Say I've got pure functions f_1..f_n such that f_i calls f_{i+1} some number of times.  And say that I discover f_n to be actually kind of expensive and that I'd like all calls to it from f_1 on down to share the same cache.
08:11:04 <bookerz> So I wrap it in the State monad.
08:11:10 <bookerz> Do I then have to go back through f_1..f_{n-1} and lift all their logic into State, too?
08:19:40 <monochrom> don't use State. use a lookup table. f_n simply looks up.
08:23:11 <bookerz> Could I do that without adding that lookup table to each f_i's inputs and outputs?
08:23:25 <joeyh> like Data.MemoTrie?
08:24:12 <monochrom> only f_n needs to know about the table. implementation detail
08:24:52 <monochrom> "myfunc x = a ! x"
08:24:53 <bookerz> How does f_n remember the table from one call to the next?
08:25:07 <monochrom> to the user, myfunc is a function. to me the author, a is an array
08:26:30 <bookerz> huh
08:26:54 <bookerz> An array of function calls, more or less?
08:27:09 <bookerz> Could such a scheme work with a Map, too?
08:27:19 <bookerz> array of thunks?
08:31:29 <benmachine> bookerz: a Map could also work, and may be easier depending on what your input types are
08:32:56 <hpaste> joeyh pasted “MemoTrie example” at http://hpaste.org/75481
08:33:04 <monochrom> I am not sure that "array of function calls" is accurate. and I am not convinced that "thunk" is an informative word
08:33:19 <bookerz> I could fromList a list of thunks into a Data.Map.Lazy, for example...
08:33:20 <bookerz> interesting
08:33:24 <bookerz> :-)
08:33:35 <bookerz> What would be better terminology?
08:33:52 <monochrom> data. value.
08:35:35 <bookerz> It could be done in such a way that I don't need to know all the parameters f_n would take in the lifetime of the program?
08:35:58 <bookerz> joeyh: thanks -- I'm playing around with that in ghci
08:36:29 <monochrom> replace "array" by "trie" for that
08:37:14 <joeyh> I'm glad you brought it up, I remember being symied by how to memoize pure functions a few years ago, but it makes sense now :)
08:37:45 <monochrom> I start with array because it takes away all the mystique and vain glory
08:37:52 <joeyh> +1
08:38:52 <bookerz> so say f_n :: Int -> Foo so we can apply arrays
08:39:00 <monochrom> it is also why I still haven't said "memoize". it's just table lookup.
08:41:17 <bookerz> Then I just define f_n' = array (1,m) ([(i, f_n i) | i <- [1..m]])
08:42:05 <bookerz> or maybe f_n' = (!) array (1,m) ([(i, f_n i) | i <- [1..m]])
08:42:19 <monochrom> yes that's one way
08:42:35 <bookerz> Could I do that over a domain that I can't enumerate?
08:43:40 <monochrom> I am not sure what you can't enumerate. array is very flexible about its index type
08:43:54 <bookerz> if f_n :: Double -> Foo
08:44:03 <cark> you can't enumerate reals
08:44:22 <monochrom> replace "array" by "map" for Double
08:44:36 <bookerz> nod
08:44:43 <cark> right but he's "precalculating"
08:44:45 <bookerz> But in that case I'm not sure how to construct it
08:45:21 <bookerz> I can't construct the list to fromList that Map
08:45:55 <cark> i would go for proper memoisation, with mutable state and unsafeperformio
08:45:55 <bookerz> cark: So long as evaluation stays lazy, I'm not sure if there'd be any precalculating
08:46:05 <monochrom> I see. then go "trie" and what joeyh says about memotrie. it has that much flexibility
08:46:16 <cark> yes, that's why there are quotes around precalculating =P
08:46:19 <bookerz> :-)
08:47:04 <bookerz> cark: Is using state possible without putting all my f_1..f_n functions into State?
08:47:37 <cark> yes, but it's not recommanded
08:47:51 <bookerz> what do you mean by that?
08:48:12 <bookerz> and how ugly/dangerous are we talking?
08:48:25 <bookerz> (still trying to figure out how to use the Data.Trie...)
08:48:36 <rwbarton> if you use State there is some lifetime for the lookup table
08:48:36 <cark> it is possible to do referentially transparent stuff, but realying on mutable state on the inside o fit
08:48:45 <cark> relying*
08:48:49 <rwbarton> unless you cheat with unsafePerformIO, yes
08:49:42 <cark> there is much literature on the web about how ugly and dangerous unsafePerformIO is
08:49:47 <bookerz> well... maybe I'll learn how unsafePerformIO works, then.  It'd be just such a headache to have to lift all the logic in all those functions into State just to test out the performance of this memoization
08:49:52 <bookerz> word
08:50:02 <cark> but there are some uses of it in the standard library
08:50:56 <monochrom> joeyh posted an example
08:52:37 <monochrom> it looks like f_n' = untrie (trie f_n)
08:54:18 <monochrom> hrm? it wants enumeration
08:57:21 <bookerz> Ah -- I see that, too
08:59:30 <cark> last answer on this post has an implementation of memoize http://stackoverflow.com/questions/10529284/is-there-ever-a-good-reason-to-use-unsafeperformio
09:01:17 <bookerz> awesome, awesome
09:01:22 <bookerz> that looks highly manageable
09:03:00 <bookerz> Thanks, all y'all
09:03:07 <bookerz> This is totally enough to get me working again
09:10:20 <nooodl_> http://hpaste.org/75484 is the indentation on this code right? something feels wrong
09:11:49 <monochrom> looks right
09:15:49 <hpaste> d pasted “d” at http://hpaste.org/75487
09:34:49 <sheriff_> I wonder how long it's gonna take me to convert LHS written with Markdown in to something pretty
09:37:37 <astry_> wow
09:37:42 <astry_> that's gotta look terrible
09:37:50 <sheriff_> astry_: I dunno
09:37:50 <astry_> can you show a paste?
09:37:57 <astry_> paste it!
09:37:58 <astry_> :)
09:38:13 <sheriff_> hahaha, it's homework. Let me find a bit that's not too controversial to post
09:38:27 <astry_> why would homework be controversial
09:38:33 <astry_> are you schooling with the hitler jugend
09:39:18 <sheriff_> You know, it doesn't look very interesting at all. It's just like writing LHS with text comments
09:39:27 <sheriff_> Only I escpate some stuff with `foo`
09:39:37 <sheriff_> And occasional _emphasis_
09:39:45 <ClaudiusMaximus> looked at pandoc, of course?
09:39:54 <sheriff_> ClaudiusMaximus: No, but I will.
09:40:08 <sheriff_> ClaudiusMaximus: I might be more effective hacking it up with Perl
09:40:11 <sheriff_> as I am a Perl ninja
09:40:26 <sheriff_> And this only needs to work once
09:40:29 <hpaste> d pasted “g” at http://hpaste.org/75488
09:40:31 <ClaudiusMaximus> sheriff_: pandoc -f markdown+lhs -t html+lhs
09:40:43 <ClaudiusMaximus> sheriff_: from its fine manual
09:40:43 * sheriff_ tries 
09:41:17 <ClaudiusMaximus> cabal install pandoc takes an age because of a zillion dependencies, so get a binary from your distribution if possible
09:41:27 <sheriff_> it's in apt
09:42:16 <sheriff_> That looks not bad
09:42:39 <sheriff_> I want to add syntax highlighting for the Haskell, but I will look at pandoc's docs for some hints
10:03:34 <vikt0r0> If i want to use an abstract datatype (supporting some operations) as part of another datatype, should I make it instance of a typeclass?
10:03:39 <vikt0r0> If that question makes sense.
10:06:07 <Saizan> not necessarily
10:06:29 <Saizan> i mean the usual thing to do is just use it
10:06:57 <vikt0r0> But it's abstract, so it's not exported in the module that i am using.
10:07:29 <Saizan> abstract usually means the type is exported but not its internals
10:07:50 <Saizan> is this your case? or you don't even have access to the type?
10:07:55 <vikt0r0> Oh. Sorry about that, it's obviously the other way around then.
10:08:30 <Saizan> vikt0r0: it's be better if you could show some code to explain the situation
10:08:33 <vikt0r0> I don't have access to the type, but I have access to functions that will create data that is an instance of it.
10:08:47 <vikt0r0> Sure, should I use HPaste?
10:08:51 <Saizan> yes
10:09:23 <vikt0r0> Okay, just 1 sec.
10:11:07 <hpaste> Viktor pasted “Code” at http://hpaste.org/75489
10:11:17 <vikt0r0> There.
10:11:32 <vikt0r0> I seperated the two files with a comment.
10:12:51 <rwbarton> the first module should just export Maze
10:12:54 <vikt0r0> Saizan: I tried making maze an instance of a a class i defined called RobotMaze with functions fromList, validMove and goalPos.
10:13:07 <vikt0r0> But the assignment does not allow me to.
10:13:19 <vikt0r0> rwbarton: ^^^
10:13:21 <rwbarton> if you just add 'Maze' to the export list it will export Maze but not its constructors
10:13:24 <rwbarton> what
10:13:43 <rwbarton> well there are various more annoying things you could try
10:13:51 <vikt0r0> It says: "This type should be abstract and not exported from the module"
10:14:39 <monochrom> let me ask you this question. does abstract type mean: the user is not allowed to write type sigs that mention the type name "Maze"?
10:15:51 <vikt0r0> monochrom: It's the first time I encountered the word ADT, so I am not sure. But that's how I understood it.
10:16:02 <vikt0r0> monochrom: interpreted it*
10:16:29 <rwbarton> I am sure the assignment intends "this type should be abstract and its definition not exported from the module"
10:16:50 <monochrom> ok, then you may like to read more about abstract types. from books and/or the internet and/or whatever you can get your hands on
10:17:13 <vikt0r0> monochrom: Is my interpretation wrong then?
10:17:29 <monochrom> I'm pretty sure in all instances of using abstract types by other people, users are allowed to say the type name
10:17:56 <vikt0r0> rwbarton: So I export the type, but not the constructor?
10:17:59 <rwbarton> yes
10:18:10 <vikt0r0> rwbarton: I could do that, yes :)
10:18:23 <vikt0r0> monochrom: Yes, that makes more sense.
10:18:35 <rwbarton> if you don't export the type then you can still do data World maze = World { wMaze :: maze, wRobot :: Robot } ... and never write a type signature anywhere
10:18:46 <rwbarton> that seems like a silly thing tod o
10:19:02 <rwbarton> all that exporting the type Maze does is allow a client to talk about the type Maze in a type signature
10:19:11 <vikt0r0> Also, we are implementing a monadic interpreter that queries the maze, but is not allowed to change it… It makes sense that way.
10:19:57 <vikt0r0> rwbarton monochrom: Thanks guys! :)
10:35:39 <hpaste> d pasted “;” at http://hpaste.org/75490
10:43:02 <efie> what is wrong with "map (\i -> return i :: IO Int) [1..5]"? "Not in scope: `return'"
10:44:19 <centrinia> :t map (\i -> return i ::IO Int) [1..5]
10:44:20 <lambdabot> [IO Int]
10:45:08 <centrinia> :t sequence $ map (\i -> return i ::IO Int) [1..5]
10:45:09 <lambdabot> IO [Int]
10:45:13 <centrinia> > sequence $ map (\i -> return i ::IO Int) [1..5]
10:45:14 <lambdabot>   <IO [Int]>
10:46:05 <efie> it still says that it does not know return
10:46:23 <Nimatek> efie: import Control.Monad ?
10:47:03 <efie> oh.. thanks, it was restricted to a few functions (...)
10:49:39 <centrinia> :t return
10:49:40 <lambdabot> forall a (m :: * -> *). (Monad m) => a -> m a
10:49:55 <nicoo> efie: IIRC, lambdabot refuses to evaluate stuff in IO
10:50:12 <centrinia> For your own protection.
10:50:21 <jmcarthur> i think it's happy to evaluate it, just not execute it
10:50:33 <jmcarthur> > putStrLn "Hello" `pseq` 5
10:50:34 <lambdabot>   5
10:50:51 <centrinia> > putStrLn "I am doing IO!"
10:50:53 <lambdabot>   <IO ()>
10:51:26 <jmcarthur> hmm
10:51:31 <jmcarthur> > putStrLn undefined `pseq` 5
10:51:32 <lambdabot>   5
10:51:39 <jmcarthur> wasn't sure what to expect there
10:51:48 <jmcarthur> i guess i shoudl have guessed
10:51:59 <jmcarthur> since print [1..] is lazy
10:52:07 <jmcarthur> well, lazily evaluates the list, that is
10:52:21 <jmcarthur> i keep saying that wrong
10:52:32 <jmcarthur> evaluates the list on demand
10:53:56 <monochrom> in "putStrLn x", x is not evaluated until "putStrLn x" is executed
11:00:59 <HairyDude> @instances ByteString
11:01:00 <lambdabot> Couldn't find class `ByteString'. Try @instances-importing
11:01:06 <HairyDude> @instance ByteString
11:01:06 <lambdabot> Maybe you meant: instances instances-importing
11:01:15 <atriq> @info ByteString
11:01:15 <lambdabot> ByteString
11:01:20 <atriq> :)
11:01:22 <atriq> Heh
11:01:24 <atriq> Useful
11:01:38 <HairyDude> what I want to know is: where is the IsString instance for ByteString?
11:02:19 <HairyDude> @instances-importing ByteString
11:02:20 <lambdabot> Couldn't find class `ByteString'. Try @instances-importing
11:02:27 <HairyDude> @instances IsString
11:02:27 <lambdabot> Couldn't find class `IsString'. Try @instances-importing
11:02:35 * HairyDude sighs
11:02:42 <HairyDude> @instances-importing IsString
11:02:43 <lambdabot> Couldn't find class `IsString'. Try @instances-importing
11:04:07 <geekosaur> @help instances-importing
11:04:07 <lambdabot> instances-importing [<module> [<module> [<module...]]] <typeclass>. Fetch the instances of a typeclass, importing specified modules first.
11:04:24 <HairyDude> I am assuming here that ByteString even has an IsString instance
11:04:36 <HairyDude> @instances-importing Data.ByteString IsString
11:04:37 <lambdabot> Couldn't find class `IsString'. Try @instances-importing
11:04:43 <HairyDude> @instances-importing Data.String Data.ByteString IsString
11:04:44 <lambdabot> [Char]
11:04:55 <HairyDude> @instances-importing Data.String Data.ByteString.Lazy IsString
11:04:56 <lambdabot> [Char]
11:05:38 <HairyDude> @instances-importing Data.String Data.ByteString.Internal
11:05:39 <lambdabot> Couldn't find class `Data.ByteString.Internal'. Try @instances-importing
11:06:07 <HairyDude> @instances-importing Data.String Data.ByteString.Char8 Data.ByteString.UTF8
11:06:08 <lambdabot> Couldn't find class `Data.ByteString.UTF8'. Try @instances-importing
11:06:10 <HairyDude> @instances-importing Data.String Data.ByteString.Char8
11:06:11 <lambdabot> Couldn't find class `Data.ByteString.Char8'. Try @instances-importing
11:07:12 <geekosaur> why are you expecting Data.String to have it?
11:07:41 <geekosaur> @instances-importing Data.ByteString IsString
11:07:41 <lambdabot> Couldn't find class `IsString'. Try @instances-importing
11:08:30 <geekosaur> @instances-importing Data.ByteString.Char8 IsString
11:08:31 <lambdabot> Couldn't find class `IsString'. Try @instances-importing
11:08:52 <geekosaur> hm, is that a shortcoming of @instances-importing or is it buried deeper?
11:09:01 <bfig> what does V a ~ R2 mean in the context of constraints?
11:09:49 <sipa> bfig: if means that (V a) and R2 are identical
11:09:56 <sipa> *it
11:10:24 <bfig> sipa, where can i read about this?
11:11:04 <HairyDude> turns out there's one in Data.ByteString.Char8
11:11:20 <sipa> bfig: http://www.haskell.org/haskellwiki/GHC/Type_families#Equality_constraints
11:11:30 <geekosaur> yes, which us what I asked it and it said no (I checked first)
11:14:49 * hackagebot bindings-gobject 0.4 - Low level bindings supporting GObject and derived libraries.  http://hackage.haskell.org/package/bindings-gobject-0.4 (YurasShumovich)
11:18:29 <Quantumplation> Here's the rough outline of my data model as it exists currently: http://hpaste.org/75492  I have the two functions at the bottom written, but i've removed their implementation for clarity.  I'm trying to implement, now, transferring resources between stars.  Anyone have suggestions one how to model it?
11:18:59 <Quantumplation> I was going to use a queue between stars, but I can't seem to wrap my head around how to create these queues, add to and remove from them, and make sure everything is pointing to the correct "version" of things when it gets updated by the tick.
11:21:16 <noviceprogrammer> how do I have optional parameters in Haskell?
11:21:32 <c_wraith> How do you express the type of that?
11:21:40 <noviceprogrammer> I don't know :(
11:21:52 <ion> @src Maybe
11:21:52 <lambdabot> data Maybe a = Nothing | Just a
11:21:57 <noviceprogrammer> atm I've been doing function, and then function',
11:23:45 <geekosaur> there are ways you can express such things, under some circumstances, but generally you want to use Maybe
11:24:43 <hiptobecubic> noviceprogrammer, you mean default values?
11:24:51 <noviceprogrammer> hiptobecubic: something like that
11:25:41 <noviceprogrammer> http://ideone.com/S7X6O
11:25:43 <hiptobecubic> noviceprogrammer, what i usually see is that some function will take some kind of "args" type which is defined with record syntax. Then the defaults args will be defined and named something like stdargs
11:26:19 <hiptobecubic> then you can do   foo (stdargs {bar = newval}) if you only want to change the value of bar, for example
11:26:39 <hiptobecubic> ah ok i see
11:26:47 <hiptobecubic> Maybe then
11:27:00 <noviceprogrammer> how would I do that?
11:27:02 <hiptobecubic> but you must include it
11:27:10 <hiptobecubic> prompt "What is your name?" Nothing
11:27:27 <hiptobecubic> if it's a common usage, then make a wrapper
11:27:42 <hiptobecubic> defaultPrompt str = prompt str Nothing
11:30:36 <YayMe> Haskell is not reflexive is it?
11:30:44 <noviceprogrammer> what's reflexive?
11:31:09 <YayMe> capable of inspecting itself, or so I understand it to be
11:31:26 <hiptobecubic> YayMe, in what sense?
11:31:43 <hiptobecubic> You already know all the types of all expressions at compile time, there is nothing to discover
11:32:17 <YayMe> hiptobecubic: I guess on 2 fronts: Is haskell at run time have an image format available to it that it could even inspect? And if so, are there any facilities available for haskell to do so?
11:32:45 <noviceprogrammer> http://ideone.com/wX9YE how do I make my program catch EOF and repeat the prompt?
11:32:58 <YayMe> > :type map
11:32:59 <lambdabot>   <no location info>: parse error on input `:'
11:33:17 <hiptobecubic> YayMe, image in what sense? What are you trying to determine about the program
11:33:19 <YayMe> hrmm since ghci gives :type i guess it must have it huh
11:33:25 <merijn> :t map
11:33:26 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
11:33:39 <hiptobecubic> the types are inferred before the code is compiled
11:33:49 <hiptobecubic> which is *before* anything is running
11:33:51 <merijn> YayMe: :t and @type work on lambdabot, just not when evaluating expressions (i.e. the > prefix)
11:33:52 <rwbarton> ghci is a haskell interpreter so naturally it can tell you the type of stuff
11:34:08 <monochrom> I am not convinced of the value in asking again after EOF. you get EOF, there is no further input, even if you ask for it
11:34:18 <YayMe> hiptobecubic: common things people use reflection in other languages for are to for instance iterate the properties of an object. In haskell it would be like iterating the parts of an ADT perhaps
11:34:24 <nwf> YayMe: There are some "dynamic" type facilities available, by, e.g., combining the use of existentials and Data.Typeable.
11:34:29 <monochrom> but see Control.Exception for catching EOF as an exception
11:34:51 <YayMe> data Wha = Wha String Int String Char String Num
11:35:01 <nwf> YayMe: There's also Data.Data for generics.
11:36:00 <jmcarthur> Typeable and Data both just use normal Haskell values there. there is nothing really special about their runtime representations, afaik.
11:36:12 <jmcarthur> *though.
11:36:18 <YayMe> nwf: reflection though is specifically about inspecting your running code. usually the binary will have metadata in it that you would be inspecting to tell your code about itself
11:36:52 <hpaste> merijn pasted “repeating prompt” at http://hpaste.org/75493
11:37:10 <merijn> noviceprogrammer: Look at that paste, that should show how to repeat the prompt
11:37:15 <joeyh> I'm seeing something weird with CPP if I #ifdef a import line. Is there a way to get ghc to dump what it sees after cpping the file?
11:38:20 <nwf> YayMe: I understand?  Data.Typeable and Data.Data (and others) essentially are that "metadata"
11:38:24 <noviceprogrammer> the 'hFlush stdout' seems ugly, but otherwise the prompt string wont show up at the same time as getLine :( what IO functions flush the buffer automatically?
11:38:44 <YayMe> nwf: ah ok, cool
11:38:47 <merijn> noviceprogrammer: You can turn off buffering for stdout
11:38:48 <copumpkin> ski: do you have your fancy zipWith using inverted lists code handy?
11:38:51 <nwf> noviceprogrammer: Typically the streams are newline-buffered, which is to say that any newline causes flushing.
11:38:57 <noviceprogrammer> ah
11:39:04 <merijn> noviceprogrammer: Look for hSetBuffering in the System library
11:39:38 <merijn> (of course, turning off buffering will slow down your program. But for these toy example you won't even notice the difference)
11:39:50 * hackagebot yaml 0.8.1 - Low-level binding to the libyaml C library.  http://hackage.haskell.org/package/yaml-0.8.1 (MichaelSnoyman)
11:39:59 * monochrom is not happy that the written question talks about EOF whereas the real question has nothing to do with EOF
11:40:24 <rwbarton> it was always pretty unlikely that the real question was about reading after reaching EOF
11:40:42 <noviceprogrammer> :t forever
11:40:43 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b
11:41:09 <merijn> noviceprogrammer: forever does just what it says. It takes a monadic action and repeat it forever :)
11:41:37 <hiptobecubic> :t forever sequence ["abc"]
11:41:38 <lambdabot> forall b. b
11:41:43 <hiptobecubic> > forever sequence ["abc"]
11:41:46 <hiptobecubic> :D
11:41:46 <lambdabot>   mueval-core: Time limit exceeded
11:42:11 <hiptobecubic> i guess forall b. b, can only be bottom?
11:42:16 <merijn> hiptobecubic: Yes
11:42:35 <hiptobecubic> :t id
11:42:37 <lambdabot> forall a. a -> a
11:42:41 <merijn> hiptobecubic: Although, if your value is in IO it can at least be an interesting bottom :p
11:42:43 <fmap> > forever Nothing
11:42:44 <lambdabot>   Nothing
11:43:03 <hiptobecubic> > forever []
11:43:05 <lambdabot>   []
11:43:18 <stew> i like interesting bottoms
11:43:31 <ben> rude
11:43:42 <hiptobecubic> > forever return ()
11:43:43 <lambdabot>   Ambiguous type variable `m' in the constraint:
11:43:44 <lambdabot>    `GHC.Base.Monad m'
11:43:44 <lambdabot>      a...
11:43:52 <hiptobecubic> :t  forever return ()
11:43:53 <lambdabot>     Ambiguous type variable `m' in the constraint:
11:43:54 <lambdabot>       `Monad m' arising from a use of `return' at <interactive>:1:8-13
11:43:54 <lambdabot>     Probable fix: add a type signature that fixes these type variable(s)
11:44:04 <monochrom> don't you need more parentheses?
11:44:07 <hiptobecubic> > forever return () :: IO ()
11:44:08 <lambdabot>   Ambiguous type variable `m' in the constraint:
11:44:08 <lambdabot>    `GHC.Base.Monad m'
11:44:08 <lambdabot>      a...
11:44:19 <hiptobecubic> :t forever
11:44:20 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b
11:44:45 <hiptobecubic> > forever (return ()) :: IO ()
11:44:46 <lambdabot>   <IO ()>
11:45:02 <monochrom> because I was looking at "forever sequence ["abc"]" which is "(forever sequence) ["abc"]" and its type has an unexpected explanation
11:45:22 <hiptobecubic> :t forever sequence
11:45:24 <lambdabot> forall (m :: * -> *) a b. (Monad m) => [m a] -> b
11:45:39 <rwbarton> @type forever f
11:45:40 <lambdabot>     Ambiguous occurrence `f'
11:45:40 <lambdabot>     It could refer to either `L.f', defined at <local>:5:0
11:45:40 <lambdabot>                           or `SimpleReflect.f', imported from SimpleReflect at State/L.hs:74:0-32
11:45:56 <monochrom> @undefine
11:45:57 <monochrom> there
11:46:05 <rwbarton> probably it would still not work
11:46:06 <rwbarton> @type forever f
11:46:07 <lambdabot> forall (m :: * -> *) a b. (SimpleReflect.FromExpr (m a), Monad m) => m b
11:46:17 <rwbarton> @type f
11:46:18 <lambdabot> forall a. (SimpleReflect.FromExpr a) => a
11:46:49 <hiptobecubic> > f x
11:46:50 <lambdabot>   Ambiguous type variable `a' in the constraints:
11:46:50 <lambdabot>    `GHC.Show.Show a'
11:46:50 <lambdabot>      a...
11:47:04 <rwbarton> @type f x
11:47:05 <lambdabot> forall t. (SimpleReflect.FromExpr (Expr -> t)) => t
11:47:20 <rwbarton> > f x :: Expr
11:47:21 <lambdabot>   f x
11:47:26 <hiptobecubic> yes
11:47:34 <hiptobecubic> Always missing some type annotations :/
11:48:22 <noviceprogrammer> How do I write a Haskell program that emulates the `echo` system utility/shell builtin?
11:48:37 <noviceprogrammer> i.e. a program that echoes the arguments it was passed
11:48:56 <monochrom> look into System.Environment
11:49:00 <noviceprogrammer> right
11:49:14 <Cale> main = do xs <- getArgs; putStrLn (unwords xs)
11:52:09 <YayMe> :type unwords
11:52:15 <noviceprogrammer> :t getArgs
11:52:16 <lambdabot> Not in scope: `getArgs'
11:52:19 <noviceprogrammer> :(
11:52:22 <YayMe> :t unwords
11:52:23 <lambdabot> [String] -> String
11:52:39 <noviceprogrammer> I guess getargs has type String
11:52:44 <noviceprogrammer> or is it [Char]?
11:52:50 <YayMe> [String]
11:52:54 <pnielsen> getArgs is [String]
11:53:03 <noviceprogrammer> ah right
11:53:07 <rwbarton> IO [String]
11:53:29 <pnielsen> indeed
11:53:45 <monochrom> > unwords  ["dinosaur", "is", "better"]
11:53:46 <lambdabot>   "dinosaur is better"
11:53:53 <monochrom> that's what unwords does
11:56:39 <noviceprogrammer> (reverse . unwords) "avoid success at all costs"
11:56:43 <noviceprogrammer> > (reverse . unwords) "avoid success at all costs"
11:56:44 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
11:56:44 <lambdabot>         against inferred ty...
11:56:53 <noviceprogrammer> :(
11:57:01 <YayMe> are list comprehensions pervasive or not so much in real world haskell?
11:58:09 <noviceprogrammer> was wondering that myself ^^ I use listcomps a lot due to my python background :)
11:59:23 <YayMe> I've no experience with them before haskell, but I find myself going to them everytime I want nested looping (or whatever you call it?)
11:59:32 <noviceprogrammer> listcomps make things so much concise than (map . filter) foo
12:00:54 <danharaj> edwardk: I bumped into an issue with traversals and using fold combinators on them. If I have a `Traversal a b c d` and I have a constraint on b or d, GHC complains when I use it with something that takes a `Getting r a b c d`.
12:01:14 <edwardk> such as?
12:01:22 <edwardk> oh
12:01:25 <edwardk> ick
12:01:31 <edwardk> i see what you mean, ambiguous instance?
12:01:38 <danharaj> ambigious type variable in the constraint
12:01:41 <edwardk> yah
12:02:07 <danharaj> Solution is not too painful: for every traverse I have like that I define a fold that throws out those types, and thus the constraint.
12:02:12 <danharaj> But I was wondering if there's a nicer way?
12:02:13 <edwardk> so i have a dilemma. in the classic sense. that no matter which way i move users get speared by one of the horns
12:02:38 <edwardk> one way, users have to take two traversals if they want to both read from something and them change it
12:02:47 <edwardk> the other way you occasionally get this issue
12:02:47 <YayMe> edwardk: spear them with both horns and it's not a dilemma
12:02:54 <edwardk> maybe if i made a 'simple' combinator?
12:03:01 <edwardk> something like
12:03:08 <Cale> YayMe: List comprehensions have their place and are sometimes nicer than other options, but there are a lot of cases which get edged out by the Monad instance for lists and the other stuff in the list library.
12:03:21 <alpounet> edwardk, do you plan on releasing some of your AI stuffs at some point? (just read your comment on reddit)
12:03:27 <edwardk> simple :: ((b -> f b) -> a -> f a) -> (b -> f b) -> a -> f a
12:03:46 <edwardk> alpounet: probably. i have a little 'ai' package i've been kicking around locally for a while
12:03:56 <edwardk> mostly just boring SVM stuff
12:03:56 <alpounet> oh.
12:04:23 <edwardk> danharaj: then you can just call simple (yourLens) whenever you'd run afoul of those constraints
12:04:42 <alpounet> one of my missions this year is to work on getting us in a better shape for AI
12:04:50 <danharaj> edwardk: It's all good. Usually when type errors bite me it's my fault, so I wanted to check that I could do something about it. It's not terribly painful to have a foldFoo for every traverseFoo
12:05:05 <edwardk> well, i'd rather not force that on you, ergo simple ;)
12:05:07 <alpounet> 'cause the SVM binding we have for example now is... well, not what i'd expect
12:05:38 <danharaj> edwardk: Thanks :P Could the type system in theory be able to throw out the constraint by concluding they are dummies?
12:05:55 <thirsteh> can I derive an Eq on all constructors of a datatype?
12:06:19 <edwardk> sadly, no. defaulting would have to be able to fire on the constraint, so it'd have to have ExtendedDefaultingRules turned on, and the constraint would have to be unary and contain Show, Eq, Ord, or something numeric
12:06:19 <danharaj> Eq is a typeclass, you derive instances of it for types. Constructors are functions.
12:07:07 <thirsteh> danharaj: what I meant was I wanted to derive an instance of Eq that returned true if all constructors of a datatype were equal, but I just realized that's a silly question. That's what it does
12:07:21 <danharaj> Indeed.
12:08:05 <thirsteh> or rather, that's what deriving Eq does :)
12:08:20 <edwardk> simple :: SimpleLensLike f a b -> SimpleLensLike f a b
12:08:20 <edwardk> simple l = l
12:14:26 <idnar> what's the easiest way to generate pseudorandom bytes?
12:14:57 <hiptobecubic> System.Random  to make Word8s maybe?
12:15:01 <idnar> I already wrote this in python, but I thought I'd try a haskell version for comparison (and I can't believe there's no standard utility for outputting a stream of pseudorandom data)
12:15:12 <rwbarton> @type randoms
12:15:13 <lambdabot> forall g a. (Random a, RandomGen g) => g -> [a]
12:15:15 <pnielsen> idnar: there is
12:15:22 <rwbarton> > randoms (mkStdGen 17) :: [Word8]
12:15:24 <lambdabot>   [49,220,93,232,188,117,111,254,230,211,21,179,122,83,155,63,124,223,75,14,5...
12:16:06 <idnar> pnielsen: what's it called?
12:16:15 <hiptobecubic> idnar, you just saw it
12:16:29 <idnar> hiptobecubic: that's a snippet of Haskell code, not a standard utility
12:16:44 <hiptobecubic> idnar, what do you want the "standard utility" to do
12:16:44 <shachaf> @ty BSL.readFile "/dev/urandom"
12:16:45 <lambdabot> IO BSLC.ByteString
12:16:56 <pnielsen> idnar: read more here: http://hackage.haskell.org/packages/archive/random/1.0.1.1/doc/html/System-Random.html
12:17:01 <monochrom> what does "standard utility" mean?
12:17:17 <idnar> by "utility" I mean something that would live in /usr/bin
12:17:26 <pnielsen> idnar: what does that have to do with Haskell?
12:17:34 <rwbarton> cat /dev/urandom, but yeah ...
12:17:38 <pnielsen> idnar: you can read from /dev/random or /dev/urandom if you want
12:17:43 <pnielsen> idnar: nobody's stopping you from doing that
12:17:50 <idnar> pnielsen: nothing, it was just an aside comment because I can't believe I have to write this myself
12:17:52 <pnielsen> idnar: that's how Python's os.urandom works
12:17:55 <hiptobecubic> idnar, i'm curious now what your python implementation was
12:17:57 <idnar>  /dev/urandom is too slow
12:18:08 <pnielsen> idnar: /dev/urandom is a CSPRG, not a normal PRG
12:18:12 <pnielsen> so yeah
12:18:21 <idnar> the python 3 implementation is http://hastebin.com/lihaqifiha.py
12:18:41 <rwbarton> so really you "can't believe there's no standard utility for outputting a stream of pseudorandom data that doesn't meet other unstated demands" :P
12:18:55 <pnielsen> idnar: I fail to understand how that is a Python utility, but what rwbarton wrote isn't a "Haskell utility"
12:19:31 <rwbarton> anyways System.Random is not very good by any measure aside from convenience
12:20:02 <hiptobecubic> System.Random.MWC does fine for me, but I think the gsl wrappers will be fastest
12:20:44 <edwardk> danharaj: i pushed 3.0.1 with simple in it
12:20:44 <idnar> pnielsen: what rwbarton wrote isn't a complete implementation, of course, but the point is that all of this code is some stuff that just got written, it's not in some Debian/whatever package that I can install and use
12:20:51 <idnar> anyway, whatever, that was just an unimportant aside
12:21:05 <pnielsen> idnar: how is your snippet different?
12:21:15 <idnar> pnielsen: it's not. that's the point.
12:21:34 <hiptobecubic> it's just a function call. what more do you want?   it's no more than writing  "from random import getrandbits" and then "getrandbits(N).to_bytes"
12:21:43 <pnielsen> idnar: I don't understand your point then
12:21:43 <monochrom> "randoms (mkStdGen 17) :: [Word8]" is not a lot of code.
12:22:09 <idnar> pnielsen: I am surprised that there isn't an existing tool that I can just use, instead of having to write the tool myself, that's all; it seems like somebody would have needed a fast source of pseudorandom data before
12:22:10 <pnielsen> idnar: I hope you don't mean that because "it is some code that just got written" it isn't good, or production-quality
12:22:20 <pnielsen> a lot of Haskell code just gets written and works very well
12:22:39 <monochrom> but I agree that there is a place for Prelude.Twitter: a package that contains every function definable in 140 characters or less
12:22:53 <pnielsen> idnar: I don't understand what you mean by tool. Launching a binary in /usr/bin would have significantly higher overhead than calling a function
12:23:46 <scri> monochrom: does lambdabot have a twitter?
12:23:49 <pnielsen> I'm not trying to be difficult, but I really don't understand what you are looking for that exists in Python and not Haskell
12:23:52 <monochrom> no
12:24:03 <idnar> pnielsen: okay, let me start over, I think I was unclear
12:24:05 <pnielsen> if there were a binary that existed in /usr/bin that you use in Python, you would be able to use it in Haskell, too
12:24:51 * hackagebot lens 3.0.1 - Lenses, Folds and Traversals  http://hackage.haskell.org/package/lens-3.0.1 (EdwardKmett)
12:24:53 * hackagebot machines 0.2.1 - Networked stream transducers  http://hackage.haskell.org/package/machines-0.2.1 (EdwardKmett)
12:25:14 <idnar> pnielsen: I needed to pipe some random data into another program; /dev/zero was fast, but not random enough, and /dev/urandom was too slow, so I looked for an existing tool; when I didn't find one, I wrote that python script; then I decided to write a similar tool in Haskell to see how it would compare performance-wise
12:25:42 <idnar> the comment about being surprised it didn't already exist didn't have anything particularly to do with Haskell or Python, it was just an aside
12:25:57 <pnielsen> idnar: oh, so you aren't looking for a function to generate random data, but rather some application written in Haskell that outputs random data
12:26:07 <pnielsen> I don't know whether something like that exists
12:26:15 <pnielsen> but it would be trivial to write, as rwbarton demonstrated
12:26:25 <rwbarton> well also you asked for the "easiest" way, System.Random is easy but not very fast
12:26:44 <parcs`> /dev/urandom is slow?
12:26:54 <pnielsen> parcs`: all cryptographically secure pseudo-random generators are slow
12:27:08 <pnielsen> parcs`: although it is significantly faster than /dev/random
12:27:27 <idnar> parcs`: I get 1.69GB/sec from /dev/zero, 2.4MB/sec from /dev/urandom, and about 20MB/sec from that python script
12:27:33 <parcs`> ah
12:27:39 <pnielsen>  /dev/urandom seeds itself with high-entropy output from /dev/random rather than waiting for the required entropy from device timings, etc.
12:27:55 <idnar> the python script uses the `random` module from Python, which is a Mersenne Twister PRNG
12:28:17 <danharaj> Mersenne Twister isn't cryptographically secure so no surprise there.
12:28:26 <pnielsen> MT is completely deterministic, so it is a lot faster. You can predict all iterations of it given only a few observations
12:28:44 <rwbarton> @hackage mersenne-random
12:28:44 <lambdabot> http://hackage.haskell.org/package/mersenne-random
12:28:45 <shachaf> pnielsen: The former doesn't imply the latter.
12:29:28 <pnielsen> shachaf: what's your point?
12:29:39 <idnar> anyhow, I asked about "the easiest way" initially because I thought I'd try the simplest possible thing, and then go from there
12:29:43 <parcs`> i'm not sure whether a haskell implementation will be any faster. the random module in python is likely implemented in c
12:30:32 <pnielsen> idnar: http://hackage.haskell.org/packages/archive/mersenne-random/1.0.0.1/doc/html/System-Random-Mersenne.html
12:31:10 <pnielsen> almost the same API as System.Random
12:31:11 <idnar> parcs`: the core PRNG algorithm is implemented in C, but between the random module itself (written in python) and my code, there's a lot more python overhead than I'd like
12:31:20 <parcs`> in any case mwc-random is the recommended rng package i think
12:31:34 <pnielsen> idnar: if the only thing you want is a binary that spits out output from MT, then you might as well just write it in C
12:31:37 <hiptobecubic> idnar, so write it in C?
12:32:19 <idnar> my C is rusty enough that figuring that out will likely take more effort than I care to invest in this session of golf :P
12:32:28 <parcs`> idnar: well aren't you just printing the random bytes to stdout?
12:33:14 <YayMe> Are there any haskell packages for executing assembly through FFI? Like how C can inline assembly, haskell can't do that but are there any FFI packages that would let you toss over some assembly? (No I do not want to do this, I don't even know assembly, just curious)
12:33:20 <idnar> parcs`: yes
12:33:21 <pnielsen> shachaf: Sorry if my sentence was misleading. Mersenne Twister is completely deterministic, and you can predict all iterations of it given only a few observations.
12:34:01 <rwbarton> YayMe:
12:34:04 <rwbarton> @hackage Harpy
12:34:04 <lambdabot> http://hackage.haskell.org/package/Harpy
12:34:08 <Ralith> pnielsen: I should certainly hope that it's deterministic.
12:34:10 <rwbarton> uh
12:34:15 <rwbarton> @hackage harpy
12:34:15 <lambdabot> http://hackage.haskell.org/package/harpy
12:34:24 <YayMe> try harder?
12:34:37 <YayMe> oh i see
12:34:48 <monochrom> there is no need for a package for FFI-ing to assembly code. just ensure the assembly code follows the C calling convention, then use it through Haskell FFI as usual
12:35:21 <YayMe> monochrom: That was going to be my next question was if FFI could do that
12:35:23 <shachaf> pnielsen: OK. :-)
12:35:57 <parcs`> idnar: have you measured the python overhead? because it seems like it would be insignificant
12:36:19 <hiptobecubic> run it in pypy
12:36:22 <idnar> parcs`: I don't really have a good way of measuring, I'm just guessing
12:36:25 <Ralith> YayMe: the FFI doesn't do anything differently for that, that's the point
12:36:42 <idnar> parcs`: the problem is that the output of the PRNG iteration is a float
12:37:07 <idnar> parcs`: so there's a bunch of contortions to turn those floats into an integer of the requested size, and then some more contortions to turn that integer into a packed string
12:38:21 <hiptobecubic> idnar, cast to char* :)
12:38:29 <pnielsen> shachaf, Ralith: what I meant is that the output is deterministic, whereas output from a CSPRG using some entropy pool is nondeterministic, not that the algorithms are or aren't. Sorry, I realize you can't see what I'm thinking if I don't type it
12:38:41 <Ralith> hiptobecubic: if the float is uniformly distributed, the char won't be.
12:39:23 <hiptobecubic> sure, it's not a good suggestion. but all of this seems pretty useless anyway :)
12:39:34 <Ralith> idnar: an rng which only outputs floats is pretty useless; get a better one
12:40:39 <idnar> Ralith: I don't see how a prng could output more than one type
12:41:03 <idnar> Ralith: your prng state has to be determined by a set of values of particular types
12:41:08 <pnielsen> idnar: an RNG which doesn't support representing its output in other types than floats
12:41:33 <idnar> well, the random module supports lots of different things, but all of those are implemented in terms of the underlying generator
12:42:06 <pnielsen> MT19937AR.c does not output floats, for example
12:42:12 <hiptobecubic> idnar, yes and? it's just a source of bits
12:42:42 <pnielsen> idnar: it really is trivial to use MT from C
12:42:57 <idnar> hiptobecubic: the conversion from the output of the generator to an integer of the requested size is implemented in Python code, not C code
12:44:01 <pnielsen> idnar: and that was Ralith's point. If that's all the generator supports, get a better one
12:44:18 <pnielsen> a CSPRG does not output a specific type
12:44:29 <pnielsen> PRG*
12:44:40 <idnar> okay, are you offering to implement it for me?
12:44:41 <scaphe> hello
12:44:55 <idnar> I don't really understand what your point is
12:45:39 <hiptobecubic> idnar, no one understands your point either i think
12:45:43 <idnar> I'm just saying that I suspect the throughput of the Python version is much lower than the theoretical optimum
12:45:46 <Ralith> 12:36:54 < idnar> parcs`: the problem is that the output of the PRNG iteration is a float
12:45:55 <Ralith> if this is your problem, the cause of your problem is using a bad rng.
12:46:39 <idnar> I was responding to this: <parcs`> i'm not sure whether a haskell implementation will be any faster. the random module in python is likely implemented in c
12:47:42 <hiptobecubic> idnar, what version of python is this anyway? your code doesn't run in 2.7
12:47:50 <Ralith> parcs` didn't say anything about floats, or your problem.
12:48:02 <pnielsen> hiptobecubic: py3k
12:48:18 <idnar> hiptobecubic: that's the python 3 version; the python version is http://hastebin.com/xiwecoriwi.py (which is more awkward and a little slower)
12:48:59 <efie> I tried to make haskellmode under vim work, but I have 2 problems: when I open a .hs file with vim, I get a quick error which says: "error dected while processing  /home/name/.vim/ftplugin/haskell_doc.vim". Furthermore, if I try "gf" when the cursor is over "Control.Monad.State" I get "Can't find file "Control/Monad/State." in path". Did someone come across this?
12:49:33 <idnar> Ralith: I was trying to explain why my guess is that there's a lot of Python-level overhead, despite the MT algorithm itself being implemented in C code instead of Python code
12:49:40 <idnar> (although admittedly I don't have any proof of that)
12:49:58 <Ralith> idnar: it sounds like the answer is "because the python code is written incorrectly"
12:51:07 <idnar> Ralith: I'm not going to claim that there's absolutely no way to improve it, but I couldn't find a way (at least, one that doesn't involve writing more C code)
12:52:21 <Ralith> idnar: don't take the output as a float, for starters.
12:53:41 <idnar> it looks like I may have misread the code slightly, getrandbits() only uses random() if you've overridden it, otherwise it calls some C function directly
12:55:18 <idnar> so there may be no floats involved at all
13:01:01 <dolio> ddarius: Ping.
13:04:42 <pnielsen> idnar: crude, but here you go: http://pastebin.com/raw.php?i=9fEzD568
13:04:45 <maukd> The paste 9fEzD568 has been copied to http://hpaste.org/75495
13:04:56 <pnielsen> idnar: gcc -o mtrand mtrand.c
13:06:30 <idnar> pnielsen: I don't think that quite does what you wanted
13:06:48 <pnielsen> idnar: change main
13:06:56 <pnielsen> I just wanted to demonstrate how easy it is to use MT from C
13:07:08 <hiptobecubic> i got a bunch of crap and a segfault :D
13:07:13 <idnar> yeah, it writes out 4 bytes of random data followed by the contents of the stack until you hit a NUL :)
13:07:24 <BMeph_> hiptobecubic: Welcome to C. ;)
13:07:29 <hiptobecubic> idnar, sounds like your C isn't so rusty at all :)
13:07:31 <idnar> (or until you get a segfault, or a garbage printf formatting code, whichever happens first)
13:07:48 <idnar> I'm actually playing around with MT19937AR.c myself now despite my protestations to the contrary
13:08:12 <idnar> but so far I can't get something that's as fast as the python version, I suspect I'm not writing enough data at a time
13:08:25 <pnielsen> buffering / fwrite
13:09:40 <pnielsen> idnar: so why do you need this in the first place?
13:11:54 <Ralith> better would be to generate like 8kB buffers of random data and write them all at once
13:11:56 <pnielsen> idnar: that is to say, why do you need a binary that spits out random data in the first place?
13:11:57 <idnar> pnielsen: somebody else needed it, actually, I just ended up golfing it because I'm easily distracted like that
13:12:10 <Ralith> I/O will slow you down if you do it this way
13:12:12 <Nafai> idnar: wooo haskell. :)
13:12:13 <pnielsen> Ralith: yeah
13:14:06 <idnar> looks like the highest I can get is about 76MB/sec
13:14:30 <idnar> pretty decent improvement over the python version
13:14:39 <hiptobecubic> which got what?
13:14:49 <idnar> 20MB/sec on this box
13:17:26 <pnielsen> and a much smaller binary ;)
13:17:55 <idnar> http://hastebin.com/qerugiloxa.c is what I ended up with (I assume tuning "mult" may give different results on different systems)
13:20:17 <pnielsen> might wanna seed it with the time of day and PID or something
13:20:42 <pnielsen> or /dev/urandom :)
13:21:17 <idnar> yeah, probably
13:21:57 <Ralith> idnar: that's still pretty far from optimal
13:24:14 <hpaste> alanz pasted “Data.Data.Lens for GHC.ParsedSource” at http://hpaste.org/75496
13:24:49 <alanz> Any GHC API and Lens boffins our there?
13:25:04 <hiptobecubic> idnar, that's const void*, not char*
13:25:09 <edwardk> i know lens pretty well, and am at least loosely familiar with the GHC API
13:25:34 <alanz> edwardk: I actually cast the bait for you
13:25:39 <edwardk> i figured ;)
13:25:50 <edwardk> so what are you trying to do?
13:26:14 <alanz> I am trying to traverse a GHC ParsedSource, and avoid the holes before renaming/typechecking
13:26:38 <alanz> (And learn Lenses on the way)
13:26:55 <edwardk> hrmm
13:27:31 <edwardk> now i need to learn how they handle holes ;)
13:27:37 <alanz> something like what the GHC SYB utils do with the Staged strategies
13:28:12 <alanz> They pass in a constant/function to be used in place of the hole when detected
13:28:17 <edwardk> so what is this k parameter?
13:28:23 <edwardk> ah
13:28:26 <alanz> That is my question :)
13:28:51 <idnar> Ralith: looks like the fastest I can call genrand_int32() on this box is ~43708204 times/sec, so that gives about 166MB/sec maximum
13:28:55 <alanz> k is intended to fill the hole, in a way that makes sense to the surrounding traversal
13:28:57 <edwardk> i would usually expect you can just use something like 'pure' to ignore that field
13:29:14 <idnar> Ralith: not sure how to improve the I/O overhead beyond what I've already done
13:29:18 <alanz> I tried that, but tripped up on the type signatures
13:29:29 <edwardk> *nods*
13:29:38 <edwardk> you may have to reduce the generality of your traversal then
13:29:52 * hackagebot heist-async 0.5.0.0 - Adding support for asynchronous updates ("AJAX") with heist  http://hackage.haskell.org/package/heist-async-0.5.0.0 (DanielPatterson)
13:29:59 <alanz> Any ideas?
13:29:59 <edwardk> Do you need the ability to go from a to b?
13:30:02 <pnielsen> idnar: you can generate random numbers while printing to the screen
13:30:07 <Ralith> idnar: you're still triggering undefined behavior in the print; you'd reduce over head and resolve that just by calling write
13:30:35 <idnar> I'm not using printf, I'm using fwrite
13:30:52 <Ralith> I didn't say that you were using printf :P
13:31:12 <alanz> I think I do for queries, and from a to a for transformations. I will need both
13:31:15 <idnar> well, okay, what do you mean by "the print"?
13:31:20 <jmcarthur> when using finalizers, what measures do i need to take to make sure that the box the finalizer is attached to is not optimized away. alternatively, is it always meaningful to attach a finalizer to an unboxed value using mkWeak# ?
13:31:24 <Ralith> the call which causes text to be printed.
13:31:48 <idnar> how would I use write in a way that doesn't trigger undefined behaviour?
13:32:15 <Ralith> not use pointer casts, mainly
13:32:18 <idnar> it takes a void * the same as fwrite
13:32:34 <Ralith> yes.
13:33:13 <Ralith> the actual slowdown at this point is going to be in that you're generating a mere 4 bytes at a time, though.
13:33:19 <alanz> edwardk: Context, porting HaRe to use the GHC API, investigating Lens as the underlying abstraction instead of SYB/Strafunski
13:33:21 <Ralith> or so I expect; get a profiler up if you really want to know
13:33:57 <Ralith> idnar: out of curiosity, what CPU do you have?
13:34:09 <idnar> Ralith: the box I'm running it on is "Intel(R) Atom(TM) CPU N270   @ 1.60GHz"
13:34:16 <idnar> so pretty slow
13:34:18 <Ralith> ah, unfortunate
13:34:29 <Ralith> the latest intel desktop CPUs have hardware RNG
13:34:49 <Ralith> well, not even 'desktop'
13:34:50 <edwardk> alanz: ah
13:34:51 <Ralith> just not atom.
13:35:12 <idnar> are they really that fast?
13:35:46 <pnielsen> yes. TPM RNGs aren't
13:36:13 <edwardk> alanz: there is probably a good way to do this, but i'm having a hard time getting my head around the types in a library i don't use for a tool i don't use to understand this in a useful way ;)
13:36:16 <idnar> okay what the heck
13:36:20 <alanz> And I am hoping to come up with some kind of interface that makes defining refactorings straightforward
13:36:39 <idnar> oh oops, I accidentally left in both fwrite and write calls, no wonder it was twice as fast :P
13:37:01 <edwardk> makes sense
13:37:02 <alanz> no problem, I am learning a lot as I wrestle with it
13:37:16 <idnar> and I was passing the wrong pointer anyway :(
13:37:22 <idnar> (this is why I shouldn't be writing C code)
13:38:00 <Ralith> what I'd do next would be modify the RNG to fill in arbitrarily large byte arrays in one pass
13:38:08 <Ralith> (no, I don't actually know how to do that)
13:38:51 <edwardk> i have some (much simpler) code in Control.Lens.TH.Lens that also does traversals but in that case over TH
13:38:56 <idnar> I'm pretty sure I don't either; but I suspect there might be a way to use vector ops and operate N different generators in parallel or something like that
13:39:03 <edwardk> you might be able to draw inspiration from that
13:39:38 <alanz> ok, I will have a look, thanks
13:40:03 <pnielsen> idnar: take a look at their more recent revisions
13:40:13 <edwardk> the fact that you are using a (b -> f b) for the traversal leads me to think you should be able to get away with using something like the actual template combinator rather than the less efficient tinplate approach as well
13:41:05 <edwardk> also the type of stepghc weirds me out
13:41:24 <edwardk> i realize its for analogy to the type i use for step
13:41:33 <edwardk> but it still weirds me out
13:42:48 <edwardk> wait, i just paged in enough of this to maybe be useful
13:42:50 <idnar> pnielsen: heh, I found a CUDA implementation
13:43:14 <alanz> I started with tinplate as the simplest version
13:43:15 <pnielsen> idnar: heh, nice
13:43:19 <edwardk> | isGhcHole d = ($d) <$> w   -- is the stuff you want to ignore
13:43:26 <edwardk> wouldn't that just work?
13:43:39 <alanz> hold on
13:45:04 <alanz> edwardk: yep, works. I knew it had to be something simple
13:45:09 <alanz> Thanks
13:45:11 <edwardk> np
13:45:27 <edwardk> took me a minute to understand the problem =)
13:45:43 <alanz> Well, thanks for spending the minute
13:46:02 <edwardk> happy to help
13:46:19 <edwardk> kind of frustrating that i can't come up with a way to make that use the more efficient traversal though =P
13:47:02 <hpaste> alanz annotated “Data.Data.Lens for GHC.ParsedSource” with “Data.Data.Lens for GHC.ParsedSource (annotation)” at http://hpaste.org/75496#a75497
13:47:51 <alanz> Well, my motto is first make it work, then make it fast. Will worry about performance when it becomes a problem
13:48:04 <edwardk> =)
13:48:38 <nand`> my motto is ‘start with the simplest possible solution’
13:49:15 <edwardk> my motto is 'abstract abstract abstract abstract and implement the only thing that remains possible'
13:49:42 <edwardk> that tends to lead to a nice solution in haskell ;)
13:51:10 <luite> hm does anyone know if it's possible to have a jmacro quasiquote inside an antiquote in a jmacro quasiquote?
13:51:11 <nand`> to perhaps clarify, ‘simple’ in my model does not exclude abstraction. On the contrary, if you can abstract it / transfer to an existing model, the solution may become very very simple
13:51:27 <alanz> I don't have enough knowledge for that yet
13:51:44 <edwardk> luite: it should just work
13:51:57 <edwardk> luite: thats the nice thing about jmacro
13:52:36 <edwardk> luite: you may have to stage it a bit, e.g. do it outside of the quasiquote and just reference variables that are in scope
13:53:20 <eyebloom> Is there a way in haskell to dispatch a polymorphic function based on the kind of it's parameter?
13:54:17 <nand`> for example, if tasked to implement ‘concat’, a very complex solution would be ‘concat [] = []; concat (x:xs) = x ++ concat xs’; a simpler solution would be ‘concat = foldr (++) []’; and the simplest solution I can come up with would be ‘concat = msum’
13:54:48 <rwbarton> you can do kind-based poly-kinded type family instance selection
13:54:53 * hackagebot keter 0.2.0.3 - Web application deployment manager, focusing on Haskell web frameworks  http://hackage.haskell.org/package/keter-0.2.0.3 (MichaelSnoyman)
13:55:07 <edwardk> eyebloom: you can make typeclasses in 7.6 that are parametric and which can dispatch on kinds
13:55:48 <pnielsen> nand`: ironically, to a newcomer, each iteration was harder to understand
13:55:56 <luite> edwardk: hm, that's a bit tricky, i have for example a `(traceGc $ "roots " +| [jmacroE| JSON.stringify(roots) |])`; where roots is a local variable, i could make a stringify :: JExpr -> JExpr for that, but it gets trickier when i want to trace x.y[z] or something, with x and z local vars
13:56:16 <luite> oh +| should be |+ and it's just JExpr -> JExpr -> JExpr
13:56:20 <luite> javascript plus
13:56:24 <nand`> pnielsen: I value simplicity (the minimalism of the expression) far more greatly than easiness to understand
13:56:43 <eyebloom> edwardk: what is the term for that?
13:56:46 <edwardk> luite: well, you can always just name the local variables and pass them to a method introduced either as a top level thing or in a surrounding let
13:56:59 <edwardk> eyebloom: google 'giving haskell a promotion'
13:57:09 <viorel> hi all
13:57:09 <nand`> being easy to understand might make the code more accessible, but may also make it harder to maintain and more error-prone, to a person that can understand the alternatives
13:57:19 <viorel> i have an error message that is very cryptic to me
13:57:22 <pnielsen> nand`: yeah, agree
13:57:51 <viorel> I see there is something called "hpaste.org/new/haskell"
13:57:52 <pnielsen> nand`: it becomes easier to reason about at the cost of requiring a deeper understanding
13:58:11 <viorel> what happens if I submit my error message there ?
13:58:50 <nand`> exactly. I don't think it's important for code to be very accessible either, it is my assumption that any programmer worth his salt should be capable of learning the necessary requisites - you don't have to be a math genius either to understand them in Haskell terms
13:58:50 <rwbarton> try it and find out
13:59:42 <pnielsen> nand`: agree. It becomes problematic when working in normal teams/when you can't guarantee that every programmer is worth their salt
14:00:18 <pnielsen> but, like edwardk said (I think), rather work in a team of 5 good programmers than 30 bad ones, if you have the choice
14:00:27 <nand`> definitely
14:00:40 <rwbarton> nand`, why msum rather than join or mconcat or asum or ...
14:00:50 <nand`> I've never worked professionally in teams, only IRC-based collaboration where you have the freedom of choice of who to collaborate with
14:01:02 <nand`> rwbarton: oh, I was thinking of mconcat
14:01:06 <nand`> I always mix those up
14:01:07 <rwbarton> heh :P
14:01:18 <nand`> basically foldr mappend mempty
14:01:20 <luite> edwardk: hm, not sure what you mean. Something like var x = JSON.stringify(roots); `(traceGc $ .... x)`;  ?
14:01:21 <rwbarton> concat = concat is the best imo :)
14:01:30 <jmcarthur> i didn't have luck with this question a short while ago, but i'll try again. i've been aware for some time that finalizers added to boxes might run early if the boxes are optimized away. is the only way to get around this to add the finalizer to an unboxed value?
14:01:49 <jmcarthur> and does adding a finalizer to an unboxed value always make sense?
14:03:39 <edwardk> luite: i meant something like outside of the jmacro quasiquoter, foo = [$jmacro|… `(bar x y z)` |] where bar x y z = … [$jmacro| … |] …;
14:04:14 <edwardk> then the antiquote doesn't have a quasiquote directly in it
14:05:02 <luite> edwardk: oh right, problem is that gets a bit unreadable for debug messages
14:05:35 <luite> perhaps is hould use lens combinators to generate the x.y[z] complex accessors wihtout using other quasiquoters ;)
14:06:30 <edwardk> heh
14:06:59 <luite> hm, but a few simple ad hoc combinators will do most of the things i need
14:08:02 <alpounet> jmcarthur, might want to try in #ghc?
14:08:31 <jmcarthur> alpounet: was thinking about doing that
14:09:49 <hpaste> viorel pasted “error when trying to compile code in "Write yourself a scheme"” at http://hpaste.org/75498
14:13:34 <geekosaur> viorel, at a guess your ghc requires --make to resolve those
14:15:38 <viorel> awesome
14:15:40 <viorel> it works
14:16:00 <viorel> thanks geekosaur
14:31:54 <pnielsen> when _don't_ I want to do return $! f x ?
14:32:20 <Cale> pnielsen: most of the time?
14:35:25 <HairyDude> is it possible to do pattern splices? say, have a template that takes the name of a constructor and match on it
14:35:59 <pnielsen> Cale: http://www.haskell.org/haskellwiki/Performance/Strictness suggests always writing it that way, since it is "very rare to actually need laziness in the argument of return." I think I understand why--since it's in a monad, something will probably evaluate it eventually. However, it goes on to say, "Warning: Using any kind of strictness annotations as above can have unexpected impact on program semantics, in particular when certain
14:35:59 <pnielsen> optimizations are performed by the compiler."
14:36:07 <rwbarton> HairyDude: yes
14:36:36 <pnielsen> Cale: e.g. in IO, whatever I'm returning will probably be seq'ed in any case
14:36:46 <pnielsen> Cale: given your comment, and the footnote, though, I find the rule-of-thumb quite confusing
14:36:47 <HairyDude> rwbarton: how? I just keep getting "parse error in pattern: $name" (this being a quasiquote)
14:37:49 <Cale> pnielsen: The article says "it is very rare to actually need laziness in the argument of return here", but the opposite is also true -- it's very rare to need strictness there as well.
14:37:53 <rwbarton> I forget :) it was a long time since I tried
14:38:18 <pnielsen> Cale: but I suppose what the article means is that in 99% of cases, you're going to make a chunk that will get evaluated anyway, so you might as well just evaluate it
14:38:31 <pnielsen> s/chunk/thunk/
14:38:46 <Cale> Yeah, but if it was going to be evaluated immediately anyway, there's no need to put the $!
14:39:15 <Cale> The only case you need the $! is when you know it'll be needed, but much later, and the thing that it evaluates to is smaller than the thunk itself.
14:39:26 <pnielsen> Cale: so in conclusion, it's silly to worry about the creation of one thunk? Is it optimized away (the footnote seems to suggest something like it, but is deliciously vague)
14:39:41 <Cale> It might be optimised away too
14:40:26 <Cale> There's also a strictness analyser which means that lazy evaluation isn't really what's going on in the first place -- some things will automatically get evaluated sooner anyway.
14:40:33 <lacrymology> hello. This seems to be very basic, but I'm getting <interactive>:1:1: Not in scope: data constructor `Int'
14:41:25 <lacrymology> what I'm actually trying to do is this, within a module: type DNI       = Int and then get a not in scope DNI
14:42:00 <rwbarton> Int is (likely) in fact not a data constructor
14:42:07 <Cale> lacrymology: uhhh, what are you typing that the ghci prompt?
14:42:08 <Cale> at*
14:42:22 <rwbarton> Int is a type (constructor)
14:42:26 <pnielsen> Cale: Interesting
14:43:09 <tgeeky> @type Int
14:43:10 <lambdabot> Not in scope: data constructor `Int'
14:43:12 <tgeeky> @type 2 :: Int
14:43:13 <lambdabot> Int
14:43:16 <tgeeky> @kind Int
14:43:17 <lambdabot> *
14:43:41 <Cale> pnielsen: Here's the real rule of thumb, imo. You want strictness when you're collapsing a "large" datastructure or number of terms down to something which is "small" in the sense of not having many separately-evaluatable parts.
14:43:45 <lacrymology> Cale: "Int" and "DNI", what I'm actually trying to do is load a module that loads this module, and fails because this DNI thing is not defined
14:44:10 <rwbarton> shouldn't you be getting an error message that refers to a line in that module then
14:44:13 <Cale> lacrymology: the error message suggests that you've used "Int" somewhere that a value was expected.
14:44:40 <rwbarton> what is the actual error message and what are you actually typing into ghci(?)?
14:44:51 <pnielsen> Cale: thanks. That makes more sense.
14:44:53 * hackagebot hs-pkpass 0.1.0.0 - A library for Passbook pass creation & signing  http://hackage.haskell.org/package/hs-pkpass-0.1.0.0 (VincentAmbo)
14:44:55 * hackagebot BNFC-meta 0.3.0.4 - Deriving Quasi-Quoters from BNF Grammars  http://hackage.haskell.org/package/BNFC-meta-0.3.0.4 (JonasDuregard)
14:45:30 <Cale> pnielsen: frequently that can be handled as a foldl'
14:45:41 <lacrymology> rwbarton, Cale: ok, when I load the module, the one that USES the DNI type, it says <module name>:<line> Not in scope, data constructor DNI
14:45:59 <Cale> lacrymology: You're using DNI as a data constructor, which it is not.
14:46:10 <lacrymology> Cale: it's supposed to be
14:46:14 <Cale> nope
14:46:17 <rwbarton> in other words you are using DNI in an expression rather than in a type (roughly)
14:46:23 <Cale> it's a type constructor (which is a synonym for Int
14:46:24 <Cale> )
14:46:28 <rwbarton> or as an expression
14:46:47 <rwbarton> presumably on the line indicated by the error message
14:46:48 <Cale> DNI as you've defined it lives in the world of types, on the right hand side of the ::
14:47:10 <lacrymology> would you care to look at it, and explain? It's like 40 lines of code, all data definitions
14:47:15 <Cale> sure
14:47:50 <Cale> hpaste.org
14:47:57 <lacrymology> http://pastebin.com/4LGa99pt
14:47:59 <maukd> The paste 4LGa99pt has been copied to http://hpaste.org/75499
14:48:07 <lacrymology> ok, there :)
14:48:15 <Cale> documentoR R DNI _ _ _ _ = DNI
14:48:19 <Cale> ^^ that's the problem
14:48:31 <Cale> DNI cannot be pattern matched against, because it's a type, not a value
14:48:41 <Cale> and it can't be produced as the result of a function for the same reason
14:48:55 <rwbarton> and DNI isn't a variable here because it begins with a capital letter
14:49:06 <rwbarton> it has to be a data constructor, but there is no data constructor DNI
14:49:15 <lacrymology> Cale: ah, so the error is at L51, it should be a var name
14:49:21 <Cale> yeah
14:49:26 <lacrymology> great, thanks
14:49:29 <lacrymology> it's been a while
14:50:06 <Cale> also, you will want parens around (R dni _ _ _ _)
14:50:32 <Cale> because otherwise, that looks like 6 parameters to documentoR
14:51:05 <lacrymology> yeah, it complained about that :)
14:52:32 <HairyDude> it would seem pattern splices are not supported...
14:53:06 <applicative> lacrymology: you can use a record to define Reserva, then you woulnt need a separate definition for documentoR
14:53:53 <rwbarton> HairyDude: you have to use a quasiquoter apparently. you said you did but then you wrote $name which doesn't look like a quasiquotation to me
14:54:28 <lacrymology> applicative: I'm sure I have no clue what you're talking about :) But this needs to be an ADT
14:55:40 <applicative> oh it's homework of some sort, lacrymology
14:56:11 <Cale> lacrymology: Records are just algebraic datatypes with a slightly modified syntax which lets you give names to the fields.
14:56:17 <HairyDude> rwbarton: name :: Name, intended to be a data constructor (for a specific data type). So how do I define a pattern that matches on the constructor represented by name? I guessed $name but that's a parse error.
14:56:45 <applicative> lacrymology: data Reserva = R {documentoR :: DNI , fechaDesdeR :: Fecha, tipoR :: TipoHabitacion, confirmadaR :: Bool } deriving (Show, Eq)
14:56:54 <schellsan> hi all - anyone here a vim user?
14:56:54 <rwbarton> I don't really know how to do that
14:57:19 <applicative> lacrymology: the only difference is that you get a functioni to extract each field, eg. documentoR:: Reserva -> DNI
14:57:29 <rwbarton> I only know you can splice in patterns like [myQQ|some text here|]
14:57:45 <rwbarton> or whatever the syntax is today
14:59:01 <Cale> schellsan: I use vim
14:59:28 <schellsan> Cale:cool - i'm having a problem with haskellmode-vim
14:59:34 <Cale> I've never used that
14:59:50 <schellsan> hmm - it may just be a vim prob in general
15:00:14 <Cale> what's going on?
15:00:34 <schellsan> i can't seem to execute a certain number of commands that have underscores as the first character...
15:02:06 <Cale> huh, I didn't even know vim had commands with underscores as their first character
15:02:09 <schellsan> for instance, in the plugin's help i see this command:
15:02:11 <schellsan> |_t|                  show type for id under cursor
15:02:23 <Cale> hmm
15:03:00 <schellsan> it doesn't have : so i guess it must be a sequence, but i can't work it out
15:03:20 <hpc> have you tried :_t?
15:03:48 <schellsan> yeah - E492: Not an editor command: _t
15:04:28 <schellsan> if i run :script names it shows that the plugin is loaded, so i know it's there
15:04:52 <takemitsu> schellsan: I can use _t with no problems. What happens if you try?
15:05:04 <schellsan> nothing
15:05:40 <schellsan> usually you can see the sequence build up but the _ disappears after i type the t
15:06:10 <schellsan> then i get a beep :(
15:07:15 <takemitsu> Do you do it fast enough? If i pause too long after I press _, it disappears.
15:07:16 <schellsan> i must have some plugin conflict or something...
15:08:13 * HairyDude gives in to boilerplate
15:08:13 <schellsan> it doesn't seem to be a timing issue
15:08:38 <typoclass> schellsan: i think it's a configuration issue. double-check all the steps in the install instructions of haskellmode. also check if it correctly knows the path of your ghc and so on
15:09:14 <takemitsu> Is :messages showing you some errors?
15:10:39 <schellsan> just the 'not an editor command' errors
15:12:05 <schellsan> i'm using haskim, a vim distribution based off of spf-13, which has a buttload of plugins, so it's probably some config issue that is buried in one (of the many) .vimrc files
15:12:20 <shapr> :t src
15:12:22 <lambdabot> Not in scope: `src'
15:13:02 <shapr> :t edwardk
15:13:03 <lambdabot> Not in scope: `edwardk'
15:14:17 <shapr> I know I've asked this several times, but is there a tutorial on writing QuickCheck properties and generators?
15:14:32 <shapr> Wasn't there some recent tool that did the QC stuff without requiring custom Arbitrary instances?
15:15:25 <typoclass> schellsan: if all else fails, you could map the "show the type" command to some other key, alt-t or whatever. you'd have to find out what the "show the type" function is called, but that's either documented or you can find it out easily from the haskellmode's vim script source code
15:15:34 <shapr> Cale: oh great fount of Haskell knowledge, I ask for QuickCheck knowledge!
15:15:56 <Cale> hehe
15:16:15 <Cale> I dunno, I usually just write the Arbitrary instances by hand
15:16:26 <schellsan> thanks, i'm going to spend the day reinstalling vim - i should learn it the hard way anyway...
15:16:43 <Cale> but it would certainly be reasonable to imagine a TH program to generate them
15:29:07 <timthelion> colah_: Are you there?  I'm trying to get rotate3 in ImplicitCAD to work to no avail :(
15:34:59 <KirinDave> Where is the definition of the instance of Monoid for Monoid a => Maybe a?
15:35:23 <KirinDave> I thought I'd find it in the source for Data.Maybe, but I don't think I see it htere?
15:35:27 <hpc> > Nothing ++ Just "one"
15:35:29 <lambdabot>   Just "one"
15:35:36 <shachaf> KirinDave: :i tells you where an instance is defined.
15:35:37 <hpc> > Just "one" ++ Just "two"
15:35:39 <lambdabot>   Just "onetwo"
15:35:43 <hpc> > mempty :: Maybe String
15:35:44 <lambdabot>   Nothing
15:35:52 <hpc> KirinDave: that should be enough to get an implementation out
15:35:56 <KirinDave> hpc: I know the definition, I just wanted a hyperlink
15:35:58 <shachaf> KirinDave: It's kind of a silly instance -- it should be Semigroup a => Monoid (Maybe a)
15:36:01 <hpc> oh
15:36:10 <shachaf> Anyway, it's in Data.Monoid
15:36:23 <shachaf> (Says :i)
15:37:19 <KirinDave> shachaf: Like in http://www.haskell.org/ghc/docs/6.10.2/html/libraries/base/src/Data-Monoid.html
15:37:23 <KirinDave> I just want a hyperlink.
15:38:42 <KirinDave> Okay http://www.haskell.org/ghc/docs/7.4.1/html/libraries/base/src/Data-Monoid.html does have it.
15:38:44 <KirinDave> Just tricky to find.
15:39:23 <monochrom> "6.10.2" should mean that it's very old
15:39:53 <shachaf> KirinDave: 6.10.2 has it too.
15:40:21 <monochrom> also, there are no links pointing at instances
15:41:01 <drchaos> How do I learn functional programming?
15:41:15 <KirinDave> drchaos: Start by doing it, I guess. ;)
15:41:16 <jmcarthur> slowly
15:41:30 <monochrom> same way you learn anything
15:41:33 <drchaos> I want to write a function that deletes each character in string1 which matches any character in the string s2
15:41:53 <drchaos> where should I begin to learn haskell at?
15:42:02 <barrucadu> @where lyah
15:42:02 <lambdabot> http://www.learnyouahaskell.com/
15:42:04 <barrucadu> Here.
15:42:06 <drchaos> I've dabbled in Learn You A Haskell...
15:42:13 <KirinDave> That's a good start.
15:42:14 <shachaf> See also the FAQ
15:42:16 <shachaf> @where faq
15:42:16 <lambdabot> http://www.haskell.org/haskellwiki/FAQ
15:42:59 <monochrom> you can write a recursion. it's induction over string1
15:43:45 <monochrom> perhaps s/over/on/
15:45:35 <timthelion> > "Eachcharacter in string1 which matches any character in" "string2"
15:45:36 <lambdabot>   Couldn't match expected type `t1 -> t'
15:45:36 <lambdabot>         against inferred type `[GHC....
15:45:39 <timthelion> > nub "Eachcharacter in string1 which matches any character in" "string2"
15:45:41 <lambdabot>   Couldn't match expected type `[GHC.Types.Char] -> t'
15:45:41 <lambdabot>         against inferr...
15:45:59 * timthelion goes to bed
15:47:55 <typoclass> drchaos: your solution for the deleting will most likely involve the 'map' function. there's examples and explanation on this page http://ww2.cs.mu.oz.au/172/Haskell/tourofprelude.html#map
15:48:19 <barrucadu> > let filterList as bs = [x | x <- as, not $ x `elem` bs] in filterList "hello" "world"
15:48:20 <lambdabot>   "he"
15:48:41 <barrucadu> Wait, I just reimplemented `filter`
15:48:47 * barrucadu hangs his head in shame
15:49:55 * hackagebot test-framework-golden 1.0 - Golden tests support for test-framework  http://hackage.haskell.org/package/test-framework-golden-1.0 (RomanCheplyaka)
15:49:57 * hackagebot test-framework-golden 1.0.1 - Golden tests support for test-framework  http://hackage.haskell.org/package/test-framework-golden-1.0.1 (RomanCheplyaka)
15:49:59 * hackagebot quickcheck-instances 0.3.1 - Common quickcheck instances  http://hackage.haskell.org/package/quickcheck-instances-0.3.1 (AntoineLatter)
15:50:14 <shapr> ooh, really?
15:50:20 <shapr> Do want!
15:50:52 <timthelion> shapr: you can have!
15:50:58 * shapr installs
15:51:06 <timthelion> shapr: you do have!
15:51:34 <drchaos> ghci> take 12 (cycle "LOL ")  
15:51:36 <drchaos> "LOL LOL LOL "   
15:51:52 <drchaos> I assume you only get 3 LOLs because 3*4 = 12
15:52:08 <monochrom> yes
15:52:32 <timthelion> > take 12 (cycle ["LOL "])
15:52:33 <typoclass> drchaos: yes, it takes 12 Chars (letters). a String is a list of Char, written as [Char]
15:52:34 <lambdabot>   ["LOL ","LOL ","LOL ","LOL ","LOL ","LOL ","LOL ","LOL ","LOL ","LOL ","LOL...
15:52:49 <parcs`> @check (== Right ())
15:52:51 <lambdabot>   "Falsifiable, after 4 tests:\nLeft ()\n"
15:53:11 <drchaos> oh wow
15:58:43 <jmcarthur> @check \a b c -> a * (b * c) == (a * b) * (c :: Double)
15:58:44 <lambdabot>   "Falsifiable, after 15 tests:\n-0.5714285714285714\n-3.0\n-1.6\n"
15:59:14 <atriq> Huh
15:59:26 <parcs`> why hasn't anybody written generics support for quickcheck yet?!
15:59:37 <jmcarthur> there is some commented out in the quickcheck package
15:59:53 <jmcarthur> i suspect the main thing is that it's hard to get the sizes right
16:00:55 <parcs`> sizes?
16:01:22 * typoclass would have thought the reason is that floats are some very sneaky bastards
16:01:51 <jmcarthur> typoclass: float multiplication is known to not be associative
16:02:44 <typoclass> jmcarthur: that's what i'm saying. a lot of things about floats are known to be sneaky
16:02:45 <jmcarthur> parcs`: it's pretty hard to guarantee in a generic way that generating a random tree terminates. not impossible, but still hard
16:02:58 <jmcarthur> typoclass: it's pretty well defined
16:03:21 <shapr> QuickCheck instances for floats is one of my fun "gotcha" examples when I'm showing someone the awesome things they can do with Haskell.
16:03:25 <jmcarthur> floats are just well defined in such a way as to not satisfy a lot of nice algebraic properties
16:03:46 <jmcarthur> they satisfy a lot of nice properties about precision, though
16:03:55 <jmcarthur> (believe it or not)
16:04:46 <shapr> Well, I asked for a tutorial writing QuickCheck properties and generators, this is pretty good!
16:04:51 <jmcarthur> shapr: it's a shame, though, because i want to check code that is denotationally over the real numbers sometimes
16:05:45 <shapr> jmcarthur: Does that mean your code is designed for real number properties, but has to use floats?
16:06:05 <jmcarthur> yeah
16:06:29 <shapr> Ah, I see. Why not QuickCheck it with Haskell's Ratio numbers?
16:06:44 <jmcarthur> doesn't have all the instances that Double does
16:06:47 <shapr> oh
16:06:51 <shapr> And can't be added?
16:06:54 <jmcarthur> nope
16:07:04 <jmcarthur> can't represent sqrt 2 in Rational, for example
16:07:09 <parcs`> jmcarthur: ah right
16:07:16 <dreixel> parcs`: it's kind of done
16:07:48 <shapr> well that's too bad
16:07:53 <parcs`> dreixel: kind of?
16:08:03 <dreixel> I don't think it's been "ported" to GHC.Generics
16:08:25 <dreixel> but it should be very easy
16:08:27 <dreixel> https://github.com/dreixel/regular-extras/blob/master/src/Generics/Regular/Functions/Arbitrary.hs
16:09:00 <dreixel> that implementation is cool, it lets you specify the desired frequency for each constructor.
16:09:01 <rwbarton> could use CReal and its approximate (==)
16:10:10 <rwbarton> I guess that's not really any better than a Double with a custom Eq instance
16:10:12 <parcs`> dreixel: neat!
16:10:34 <dreixel> parcs`: wanna port it?
16:12:07 <jmcarthur> rwbarton: it's a little better, but still not a guarantee of not getting bogus tests :\
16:12:16 <jmcarthur> *bogus test results
16:13:31 <jfischoff> I noticed vector has unsafeFreeze/Thaw and it has the comment. I would like to use these functions but I'm not sure what the comment "The (im)mutable vector may not be used after this operation" means?
16:13:55 <hpc> jfischoff: the immutable vector is made mutable in-place
16:14:14 <hpc> it's like a const conversion in C or something
16:15:22 <jfischoff> hpc: right, let me explain my example, and maybe you can help understand if the unsafe functions would work
16:16:49 <jmcarthur> hmm... now that we have DataKinds, it should be possible to make closed type classes...
16:16:50 <rwbarton> if you use only Num you could use a SimpleReflect-sort of technique and feed the equality to be tested to a solver for real arithmetic
16:17:36 <jmcarthur> huh, i said that because i didn't expect it to work...
16:19:23 <jfischoff> So I want to pass around an immutable vector and that is used as a piece of accumulated state for a parallel fold. The fold itself would not be in ST monad, but the fold function would use runST on the vector and unsafely thaw, mutate it, and unsafely freesze it each loop iteration.
16:19:42 <jfischoff> Does that sound reasonable?
16:19:59 <shachaf> That doesn't sound like a very immutable vector to me...
16:20:16 <jfischoff> no it not
16:20:22 <jfischoff> s /it/its
16:20:34 * BMeph_ passes on the quasi-mutable vector...
16:21:00 <jfischoff> I just don't want the fold to be the ST monad, just the inner function
16:21:31 <rwbarton> it might happen to work but it is not really reasonable
16:21:31 * Polarina wonders why people would want mutable data.
16:21:45 <rwbarton> Polarina, really?
16:21:58 <Polarina> rwbarton, really.
16:22:06 <rwbarton> interesting
16:22:10 <jfischoff> rwbarton: could you elaborate?
16:22:41 <rwbarton> jfischoff: well as long as nothing else tries to use the "old" vector after you mutate it then it might happen to work
16:23:14 * BMeph_ finds Actors and pi-calc interesting, but Hates the concept of other people changing "his" data's "internal state"
16:23:15 <jfischoff> rwbarton: okay great, you've answered my first question
16:23:44 <rwbarton> basically an immutable vector is a pointer to a bunch of memory which by convention is not mutated
16:24:05 <dolio> vector has (as I recall) some black magic that sometimes represent immutable vectors as 'Build exp', where exp is an ST expression that produces a mutable vector, and then operations on it will be fused into the mutable version.
16:24:12 <rwbarton> oh yeah
16:24:22 <dolio> You might want to check if that will automatically work for your use case.
16:24:54 <rwbarton> vector has a lot of black magic :/
16:24:58 <dolio> Yes.
16:24:59 <jfischoff> dolio: interesting
16:25:10 <OscarZ> is there an easy way to expain how STM works ?
16:25:19 <shapr> database transactions on memory
16:25:20 <jfischoff> I would like to "not" have to understand the internals of vector
16:25:21 <shachaf> "the way you expect"
16:25:24 <shapr> OscarZ: tada! that's it!
16:25:31 <shachaf> Which is pretty great, where concurrency is concerned.
16:25:59 <dolio> jfischoff: If all the loop is doing is writing to the vector, I'd say it might work.
16:26:05 <dolio> If it has to read from the vector, probably not.
16:26:36 <jfischoff> dolio: it has to read from it (one value to be precise)
16:26:41 <OscarZ> lets say we have some shared resource that is being bombed by change requests... lets say they are http requests by some very popular web page..
16:26:43 <shapr> OscarZ: You have state, and a bunch of stuff you want to do to transform that state. You have a bunch of cores hanging around. You give processes to these cores. When they return, THEN you check to see if they're using the correct 'version' of memory. If yes, apply change, if no, dump work and restart.
16:26:46 <dolio> But if it has to read and write, your version is risky, too.
16:27:20 <rwbarton> jfischoff: what I said applies to UArrays or repa arrays that have a manifest representation but not necessarily vectors
16:27:22 <jfischoff> I have a feeling it is too risky.
16:27:43 <chrisb> manatee!
16:27:59 <shapr> chrisb: where? I haven't seen him in forever!
16:28:16 <rwbarton> if you didn't have to read from the vector, then probably just using the immutable vector interface would be efficient due to all that black magic
16:28:51 <shapr> OscarZ: If your state is only one chunk, then spawning off optimistic processes is a waste. If you have lots of chunks, then it's great. Makes sense, right?
16:29:08 <jfischoff> I'm not convinced I even need to use the vector this way
16:29:11 <jfischoff> Maybe you guys can help at a higher level
16:30:19 <rwbarton> I like the repa 3 approach, though I only have a little bit of experience working with it so far. The magic is much less black.
16:30:23 <OscarZ> shapr: it is typically some object with multiple fields and some collections related to it
16:31:22 <OscarZ> shapr: I would like the first one to be able to modify the state.. and the rest would get some error message about the situation.. that the state has been changed after youve loaded the page
16:31:23 <shapr> OscarZ: If you're using Yesod, you get to define the state however you like, and you can chunk it into STM-friendly pieces.
16:31:28 <bos> mmm, SipHash in haskell
16:31:44 <jfischoff> I'm trying to understand how to do parallel scans in repa
16:31:52 <rwbarton> aha! me too
16:31:54 <jfischoff> so my description before was not accurate
16:31:58 <rwbarton> well, I don't care too much about parallel
16:32:01 <jfischoff> I meant map not fold
16:32:02 <danharaj> rwbarton: The fact that the intermediate representations are explicit is enormously helpful.
16:32:06 <rwbarton> yes
16:32:15 <rwbarton> I had real headaches trying to understand repa's runtime warnings in repa 2
16:32:18 <jfischoff> rwbarton: have you made any progress
16:32:19 <shapr> OscarZ: I'm not sure STM applies directly to serving up state in a web server... but perhaps it could? I really don't know.
16:32:19 <jfischoff> ?
16:32:32 <rwbarton> uh, I turned my repa array into a mutable vector to do scans on it. :P
16:32:46 <danharaj> rwbarton: my strategy was to intersperse the forcing functions until they went away.
16:32:49 <rwbarton> and didn't bother making them parallel
16:33:07 <rwbarton> I wish there were some built-in scans though
16:33:15 <jfischoff> rwbarton: right I want to make them parallel, and it is looking like I will need to scheduling by hand I guess
16:33:30 <rwbarton> what kind of scan?
16:33:36 <shapr> OscarZ: That might actually work, I'd suggest you ask someone like luite who understand this better than I do.
16:33:38 <Eduard_Munteanu> Speaking of that stuff... what's the state of DPH lately?
16:33:44 <rwbarton> or what kind of parallelism, like scanning each row of an image independently?
16:33:47 <shapr> Yah, I'd love to use more DPH!
16:33:47 <jfischoff> its a sliding dft
16:33:54 <rwbarton> ah
16:33:55 <jfischoff> no
16:34:07 <dolio> shapr: You need to port GHC to your parallella.
16:34:13 <shapr> I wish :_)
16:34:18 <jfischoff> I can just split up the array into n parts and I will be fine
16:34:43 <jfischoff> where n is the number of threads and I bet it work fine
16:35:00 <rwbarton> probably
16:35:37 <jfischoff> so is there an easy way to get at the underlying representation for a repa array?
16:35:42 <danharaj> yes
16:35:47 <jfischoff> cool
16:35:47 <rwbarton> you have a window size which is small compared to (size of array)/(number of threads)?
16:35:57 <jfischoff> yes
16:36:06 <jfischoff> err
16:36:11 <jfischoff> yes
16:36:14 <rwbarton> yeah, {from,to}Unboxed
16:36:43 <rwbarton> which is just an O(1) operation if you already have a U array
16:36:44 <OscarZ> shapr: but how do you express this requirement in Haskell.. that the first request will define the state and the rest of the request will get a message "sorry, but you were a bit too slow" ?
16:37:00 <jfischoff> I actually have a F array
16:37:05 <jfischoff> but I could change that
16:37:23 <shapr> OscarZ: http://www.haskell.org/haskellwiki/Simple_STM_example ?
16:37:29 <rwbarton> might need to copy it then, not sure.
16:37:38 <jfischoff> currently I wrote a small C program to load a Wave file into memory, and I ffi to it
16:37:42 <shapr> OscarZ: more goodies here: http://www.haskell.org/haskellwiki/Software_transactional_memory
16:37:52 <jfischoff> yeah I'd rather not
16:37:59 <OscarZ> thanks, I'll check those...
16:38:08 <jfischoff> but it's not the end of the world
16:38:17 <shapr> OscarZ: This may be the sort of thing you want: http://computationalthoughts.blogspot.com/2008/03/some-examples-of-software-transactional.html
16:38:27 <danharaj> you can grab the rep of an Array F too.
16:38:35 <danharaj> {to, from}ForeignPtr
16:38:47 <jfischoff> oh yeah of course
16:39:05 <augur> whats the unsigned int type??
16:39:07 <danharaj> there is also computeInto{S,P} if that is relevant to you.
16:39:19 <jfischoff> I wonder how hard it would be for ben to add scans to repa?
16:39:26 <jfischoff> danharaj: I'll take a look
16:40:28 <jfischoff> ah interesting
16:40:30 <OscarZ> thanks shapr for the links..
16:40:34 <ClaudiusMaximus> jfischoff: i'd like scans too, so if there's a ticket i can cc me on...
16:41:32 <danharaj> jfischoff: I think a lot of combinators in Repa are implemented via `traverse`.
16:41:37 <jfischoff> I saw he comment about it on stack overflow. Apparently accelerate has a scan primitive ;p
16:41:53 <jfischoff> ah
16:41:56 <rwbarton> yeah i was about to paste that link
16:42:14 <danharaj> hmm, Repa totally needs edwardk lenses :P
16:42:59 <typoclass> augur: i think it's Word normally
16:42:59 <jfischoff> What about ST monadic version of lenses?
16:43:14 <danharaj> Those sort of don't exist afaik.
16:43:18 <timthelion> jfischoff: isn't that just C#?
16:43:19 <ClaudiusMaximus> > "edwardk" \\ "repa"
16:43:20 <lambdabot>   "dwdk"
16:44:01 <jfischoff> yeah I'm currently interested in how well I program imperatively with Haskell ;o
16:44:51 <jfischoff> which brings me back to parallel scan, lets just say map.
16:44:56 * hackagebot gluturtle 0.0.5 - turtle like LOGO with glut  http://hackage.haskell.org/package/gluturtle-0.0.5 (YoshikuniJujo)
16:46:05 <jfischoff> so if I wanted to do the scheduling my self, basically there are functions for offsetting foreign pointers (right) I would use to make n starting places on n threads. Does that sound reasonable?
16:46:21 <danharaj> sure
16:46:21 <jfischoff> and can
16:46:30 <HairyDude> why can you derive things with a standalone deriving clause that you can't derive with a non-standalone deriving? (other than orphans, obviously)
16:46:54 <HairyDude> better: why can't you use a non-standalone deriving clause to derive some things that work with standalone clauses?
16:46:59 <maukd> can you?
16:47:15 <jfischoff> okay let me see how far I can get
16:47:29 <danharaj> iirc you can standalone derive GADTs but not normally.
16:47:37 <geekosaur> HairyDude, afaik the only thing you can do with standalone that you can't with integrated is derive for something that is in a library and doesn't already derive what you want
16:47:50 <juliohm> What do you think of Haskell for large projects? My impression is that it doesn't scale at all.
16:47:58 <pnielsen> I find it more enjoyable programming imperatively with STM than most other languages with "good" concurrency support
16:47:58 <pnielsen> STM in Haskell that is
16:47:58 <pnielsen> > 9223372036854775807.0 == 9223372036854775808
16:47:59 <lambdabot>   True
16:48:09 <HairyDude> throwing together an example
16:48:34 <augur> Cale: how can i get lambdabot to show newlines as newlines?
16:48:43 <augur> as opposed to just as \n
16:48:48 <pnielsen> augur: I'm guessing you can't. That'd be annoying
16:48:49 <centrinia> > 9223372036854775807.0 :: CReal == 9223372036854775808
16:48:50 <lambdabot>   Only unit numeric type pattern is valid
16:48:58 <geekosaur> juliohm, could you explain where you got this impression from?
16:49:10 <typoclass> > text "lol\ncat" -- augur
16:49:11 <lambdabot>   lol
16:49:11 <lambdabot>  cat
16:49:16 <augur> aha
16:49:16 <juliohm> geekosaur, from my head.
16:49:17 <pnielsen> I'm mistaken
16:49:30 <geekosaur> there are large projects that use haskell, whichh would appear to demonstrate otherwise
16:49:44 <geekosaur> ah, so you are the fount of all wisdom, then?  or just spewing noise?
16:49:53 <benmachine> geekosaur: hey, no need to be sarky
16:50:04 <danharaj> or even snarky
16:50:12 <benmachine> danharaj: neither
16:50:19 <augur> oh well. lambabot wont show it all
16:50:20 <augur> :(
16:50:23 <geekosaur> benmachine, the way it was stated sure sounded like it had some reason behind it, yet here there turns out to be none
16:50:27 <juliohm> I don't see extremely large projects like complete Engineering systems being built in Haskell. It's out of control to maintain all that, i think.
16:50:38 <pnielsen> juliohm: I think it scales very well. The problem is scaling it to larger groups (of programmers), not scaling the codebase, IMO
16:50:42 <maukd> what's an engineering systems?
16:50:52 <augur> let k = 15 ; mns :: [[Int]] ; mns = [ [ abs (complement (m .&. n)) | m <- [0..k] ] | n <- [0..k] ] in intercalate "\n" $ map (concat . map (\n -> if 1 == n then "X" else " ")) mns
16:50:54 <danharaj> I don't think anyone here wants to answer your completely insubstantiated ideas. There's not much to gain.
16:50:57 <pnielsen> juliohm: all languages with even a moderate amount of complexity have that problem
16:51:11 <augur> everyone should check out that expression there
16:51:14 <augur> its pretty great
16:51:23 <augur> make k bigger for more fun!
16:52:00 <ddarius> You could tell that the Parallella people are computer people just from the number of donor slots they have for each price point in their KickStarter project.
16:52:40 <juliohm> Object-oriented programming is the way to go, IMO, how do you keep things self contained so that everyone can contribute locally and achieve global effects? In other words, in C++ we have all the methods encapsulated in a class, and the objects play around. In Haskell, seems all the things are being passed to successive function calls.
16:53:13 <typoclass> juliohm: interesting, i've had no trouble messing around with xmonad (which is kinda large, given all the contrib modules). i've had different experience with, say, c. you just can't tell where state is being changed. to make any kind of modification, you'd have to read huge amounts of code, and hope that you didn't misread anything, and hope that nothing sneaky is going one, etc.
16:53:16 <maukd> troll alert
16:53:22 <shapr> maukd: mebbe not
16:53:24 <danharaj> boring discussion alert, at least
16:53:33 <gfredericks> can I define types within ghci?
16:53:37 <danharaj> yes
16:53:39 <maukd> gfredericks: depends
16:54:09 <hpaste> HairyDude pasted “can derive Show with standalone clause, but not non-stsandalone” at http://hpaste.org/75504
16:54:12 <shapr> juliohm: It's been my experience that the state abstraction in OOP is not as orthogonal as the monadic state abstraction.
16:54:20 <typoclass> danharaj: it's not like you have to participate in the discussion. people discuss all kinds of math all the time, which is boring to me, but it's perfectly fine
16:54:28 <gfredericks> well certainly `data Foo = Bar | Baz` doesn't work
16:54:30 <danharaj> it takes up window space :|
16:54:31 <juliohm> It's kinda of boring discussion, you're right, but i don't see how Haskell can deal with such large scenarios yet.
16:54:45 <danharaj> gfredericks: It does. I just did it to double check :P
16:54:55 <maukd> gfredericks: then your ghci isn't new enough
16:54:57 <pnielsen> juliohm: Have you used Haskell?
16:54:59 <shapr> juliohm: It actually works fine. My Google Summer of Code project handles synchronized javascript editor widgets and backend compilation state all with no trouble.
16:55:24 <hpaste> HairyDude annotated “can derive Show with standalone clause, but not non-stsandalone” with “fixed obvious error” at http://hpaste.org/75504#a75505
16:55:31 <monochrom> if you haven't used haskell in anger, you don't see a lot of things. this should be self-evident
16:55:32 <gfredericks> maukd: ah ha; thanks
16:56:00 <pnielsen> juliohm: there is no reason something has to be OO to enable collaboration
16:56:17 <juliohm> Do you have any proof of concept that Haskell can scale to the size of, let's say, AutoCAD?
16:56:22 <pnielsen> juliohm: in fact OO in large projects often hurts collaboration since the internals are so far removed from what you're looking at that you don't really know what effects your changes will have
16:56:23 <danharaj> yes
16:56:25 <juliohm> I'm talking about really large projects
16:56:35 <danharaj> GHC
16:56:47 <shapr> juliohm: I'm now learning C++ after years of using Haskell. To me, it seems that the object oriented abstraction is significantly less granular (and thus less flexible/useful) than the monadic state abstraction.
16:56:49 <pnielsen> Darcs is fairly large
16:56:54 <juliohm> pnielsen, OO is intended to hide only the unnecessary parts.
16:56:57 <typoclass> juliohm: in my opinion, mutable state (which the oo languages seem to love) makes programming in the large difficult
16:57:08 <HairyDude> geekosaur: see my paste for a counterexample
16:57:17 <shapr> I know Xilinx and Intel have used Haskell for hardware verification projects. While the source is not available, I bet it's also not small.
16:57:21 <typoclass> juliohm: in principle, anything can be written in any language. the issue is how much effort it takes
16:57:27 <monochrom> if you invest cdn$1M in me, I can produce a proof of concept.
16:57:50 <juliohm> hehehe
16:58:03 <pnielsen> juliohm: It hides much more than the unnecessary parts. Either way, there is no way you can't present "modules" with interfaces and work independently on different modules. OOP/multiple inheritance/Java-style class waterfalls aren't necessary for big projects
16:58:22 <Quantumplation> http://hpaste.org/75492 so here's the simplified version of my current data model.  Does anyone have any better ideas to structure this? I'm having trouble threading state modification through this while trying to implement shipping resources between stars.
16:58:35 <pnielsen> juliohm: OOP is popular mostly by accident, not because it is the only (or even the best) method to enable collaboration
16:58:58 <juliohm> pnielsen, OOP born as a solution to large scale projects, really.
16:59:08 <shapr> Er, really?
16:59:11 <maukd> juliohm: that doesn't mean it's a good solution
16:59:13 <juliohm> Before it, we had imperative programming, but all becomes a mess in large scale
16:59:22 <maukd> juliohm: OOP is still imperative
16:59:27 <gfredericks> and still messy
16:59:40 <juliohm> i agree, it still messy
16:59:42 <maukd> and I can do encapsulation and all that stuff in plain C
16:59:44 <HairyDude> Haskell, of course, is the world's best imperative language.
16:59:44 <ddarius> OOP was definitely not born as a solution to large scale projects.
17:00:13 <gfredericks> juliohm: immutability makes code a lot easier to reason about
17:00:16 <danharaj> Quantumplation: an OctTree is good for spatial query, but for links between nodes you want another way to index them.
17:00:19 <maukd> in fact, if we're only talking C vs. C++, then C is better at encapsulation in some sense
17:00:23 <juliohm> What do you mean by imperative language?
17:00:27 <typoclass> juliohm: i don't think that oop is quite as good at solving programming in the large as you make it sound. there's plenty of problems left. to me, it's not even clear oop is the right approach to start with
17:00:30 <pnielsen> juliohm: You don't seem to understand the differences between e.g. Haskell and OOP. I really encourage you to read Learn You a Haskell, or one of the tutorials, then make a qualified judgement
17:00:45 <pnielsen> juliohm: right now you are only fuelled by your (IMO, false) misconceptions
17:00:50 <maukd> juliohm: something that has the concept of an instruction pointer and sequences of statements
17:00:52 <juliohm> gfredericks, i think in small scale your statement is true.
17:01:03 <shapr> Also, I don't think there's a clear and small definition of OOP.
17:01:09 <juliohm> pnielsen, i read Learn you Haskell twice. :)
17:01:26 <typoclass> shapr: sure, there's lots of variants
17:01:35 <gfredericks> juliohm: the larger-scale your project is the harder it is to verify that your data structures and objects aren't being secretly mutated
17:01:36 <shapr> juliohm: So, what do you think is the difference between Haskell and OOP?
17:01:46 <ddarius> typoclass: "Variants" is extremely optimistic.
17:01:49 <pnielsen> juliohm: Then you should have no trouble understanding that there are easy mechanisms for separating modules and APIs in Haskell, and enabling the same kind of loose coupling (oftentimes superior) as in other languages
17:01:57 <danharaj> Quantumplation: I would keep a Map of Stars and have the Galaxy index into that array. I would also keep a graph structure to keep track of connections between Stars.
17:02:15 <Quantumplation> Danharaj: stars can send resources to any star within some range.
17:02:48 <HairyDude> the meaning of the term "object" depends on your language and/or programming culture.
17:03:12 <danharaj> Quantumplation: In that case you do not need that graph, and actually don't need a Map since you're only indexing by position, it seems.
17:03:22 * ddarius thinks he'll donate to the Parallella project.
17:03:23 <maukd> hrhr, I choose C++'s definition of "object"
17:03:34 <pnielsen> HairyDude: when people say it they usually mean "multiple inheritance"
17:03:44 <pnielsen> HairyDude: that teams have their own little batch of subclasses that they work on
17:03:50 <danharaj> I'm not entirely sure what the best way is to have multiple data structures indexing the same set of data. Does anyone have better ideas?
17:03:56 <HairyDude> pnielsen: I don't think so... Python people certainly don't
17:04:03 <jmcarthur> Eduard_Munteanu, shapr: an update on SIMD and DPH here http://www.youtube.com/watch?v=2Pucbf8_hGQ&t=10m35s (link should start at right point, but it's at 10:35 if that doesn't work)
17:04:07 <pnielsen> HairyDude: Sure they do. Look at Twisted.
17:04:09 * ddarius has no idea wtf pnielsen is talking about or responding to.
17:04:14 <dolio> ddarius: You interested in hanging with some Dans tomorrow?
17:04:31 <maukd> pnielsen: you've lost me
17:04:34 <juliohm> pnielsen, i see the Haskell data types, abstract constructs, but the program flow is not that clear, in Haskell we describe what things are, not how they are created and destructed, nor the program workflow.
17:04:36 <ddarius> dolio: Brand new Dans or those old dusty ones?
17:04:40 <HairyDude> pnielsen: also Java
17:04:44 <pnielsen> ddarius: what's your problem?
17:04:47 <dolio> Old and dusty, I'm afraid.
17:05:04 <Quantumplation> danharaj: *nods* I'm just not sure on the proper idioms for state in haskell.  everything I seem to do requires me to bend over backwards to make sure that everything is still pointing to the correct "version" of an object (since each mutation returns a new object)
17:05:04 <juliohm> Maybe it's my C++ background who is telling me this will not work for large scale.
17:05:09 <ddarius> dolio: Sure.
17:05:11 <HairyDude> hurm. I thought python didn't have multple inheritance.
17:05:18 <shapr> ddarius: if I had the money, I'd certainly order the affordable 16-core option.
17:05:20 <juliohm> I'm just asking to share my fears about the language. :)
17:05:41 <shapr> juliohm: Could you describe what you perceive to be the difference between Haskell and OOP?
17:05:50 <maukd> juliohm: I've read The C++ Programming Language and it's obvious the language is a joke
17:05:51 <rwbarton> why do you think we want your fears
17:06:02 <maukd> C++ can't be used for actual programs. have you seen how complex it is?
17:06:03 <shapr> c'mon guys, be nice to the newbie :-P
17:06:06 <Cyan6> shapr: haskell is functional. oop is oop
17:06:11 <ddarius> juliohm: You planning on financing hundreds of programmers over multiple years to build 10,000KLOC projects in the near future?
17:06:19 <maukd> Cyan6: OCaml is functional OOP
17:06:23 <maukd> where is your god now
17:06:25 <Quantumplation> for example, if I keep a list of queue's for ships in transit between two stars in the galaxy, then adding anything to the queue causes a whole new galaxy to be created, AND the stars can't also point to these queues because if I update them I have to create new stars as well
17:06:29 <shapr> Cyan6: Yah, but that has no details or descriptions that can be used for establishing a conversation :-P
17:06:39 <Cyan6> maukd: i'm atheist so nowhere?
17:06:43 <schellsan> hey vim guys - do haskellmode and ghcmod occupy the same use-space? do i need them both?
17:06:52 <Quantumplation> it just seems to grow out of control really quickly.  I'm sure the problem is just me thinking imperatively, so that's why I came here to see if there's some common pattern or idiom i'm missing.
17:06:56 <pnielsen> ddarius: Really, what are you having difficulty understanding?
17:07:09 <shapr> I think you meant juliohm
17:07:13 * HairyDude really isn't an advanced vim user
17:07:28 <Cyan6> hairydude: get sublimetext
17:07:41 <HairyDude> Cyan6: which is?
17:07:46 <Cyan6> text editor
17:07:47 <danharaj> Quantumplation: the new Galaxy would share almost everything with the old one.
17:07:53 <benmachine> oh man, term has started again, it's probably time to quit #haskell for another few months
17:07:56 <Cyan6> the best text editor for people who can't vim
17:07:57 <danharaj> There is a lot of sharing between peristent data structures.
17:07:59 <HairyDude> Cyan6: no thanks
17:08:01 <ddarius> pnielsen: I thought I made it clear.  Your response to HairyDude seems completely disconnected from anything he said, and your response on its own is completely disconnected from my experience as a professional developer using languages like C#.
17:08:04 <juliohm> maukd, C++ is a mess, we all know, but it works in large scale, that's a fact.
17:08:11 <pnielsen> ddarius: I was responding to juliohm
17:08:12 <maukd> juliohm: I don't believe you
17:08:14 <HairyDude> Cyan6: did I say I couldn't handle vim? I can handle it pretty well
17:08:20 <HairyDude> Cyan6: I just don't use all its advanced features
17:08:29 <Cyan6> i didn't say can't handle vim, i said who can't vim.
17:08:31 <shapr> juliohm: After writing C++ for a year now, it feels too complicated to be really usable :-(
17:08:37 <Cyan6> as in... can't use vim to it's full potential
17:08:40 <shapr> But I'm certainly not an expert.
17:08:44 <Cyan6> or at least, don't
17:08:52 <typoclass1> juliohm: i've seen enough oop code with lots of methods that are very short, perhaps even 1-line getters and setters. i don't think the program flow is any more apparent than in typical haskell code
17:08:53 <juliohm> If you enumerate 10 software, i think 50% is written in C++
17:08:54 <ddarius> '[20:03] <pnielsen> HairyDude: when people say it they usually mean "multiple inheritance"' sure doesn't sound like a response to juliohm.
17:08:55 <Quantumplation> danharaj: Right.  but if, for example, stars want to keep a list of incoming and outgoing shipments, suddenly sending a new shipment is a big hassle
17:08:57 <pnielsen> ddarius: or rather the conversation about why "OOP" languages are better.
17:09:04 <maukd> juliohm: how many of those are bug free?
17:09:16 <Eduard_Munteanu> jmcarthur: I see, thanks.
17:09:20 <Cyan6> but at the same time sublime has vim mode... so you could use it to vim
17:09:38 <juliohm> maukd, bug free is a dream, Haskell is not bug free.
17:09:42 <shapr> juliohm: Perhaps program flow would be easier to see if you grabbed the source of some small real-world programs and read through them?
17:09:58 <maukd> juliohm: Haskell is a language. what do you mean by "bug" in this context?
17:10:03 <imeredith> hi, im trying to install eclipsefp - but the update site doesnt seem to be working - anyone know anything about this?
17:10:09 <pnielsen> ddarius: I don't see how that is difficult to understand. When people say "OOP" they often mean, or are mainly talking about, inheritance and multiple inheritance, and how extending more and more classes enable team collaboration
17:10:13 <Cyan6> maukd: buggy compilation
17:10:28 <HairyDude> not sure "program flow" is very well defined in lazy functional parts of haskell :)
17:10:31 <maukd> juliohm: linux, gcc, perl, ghc, vim, bash, tmux, git, xmonad, firefox
17:10:32 <pnielsen> ddarius: I don't see how that is detached from anything. That's how virtually all Java teams work
17:10:32 <juliohm> maukd, i mean bug in Haskell programs exists the same way in C++
17:10:38 <maukd> juliohm: ^ my 10 programs
17:10:46 <maukd> juliohm: I don't believe that either
17:11:16 <juliohm> linux, gcc, vim, tmux, git, firefox  ? are the ones implemented in C/C++?
17:11:18 <HairyDude> maukd: I think one of those is C++ (firefox)
17:11:22 <maukd> juliohm: wrong
17:11:25 <pnielsen> ddarius: I am not talking about the definition of object-oriented programming. I am talking about what juliohm claimed Haskell doesn't have/what he claims is what makes it easier to make big projects that several people collaborate on
17:11:31 <shapr> juliohm: Have you considered browsing github for Haskell repositories and finding something that interests you?
17:11:33 <HairyDude> juliohm: dunno about tmux but the rest of them are C
17:11:34 <maukd> juliohm: only gcc and firefox are C++ programs
17:11:45 <maukd> juliohm: none of them are in C/C++
17:11:51 <typoclass1> juliohm: again, it is possible to write some large thing in an ill-suited language. the question you should be asking is how much effort it is. after some change somewhere in your c++ program, do you have a lot of confidence that it will work? or will it take weeks of testing? i'd argue, in haskell the situation is better
17:12:05 <maukd> juliohm: linux, perl, vim, bash, tmux, git are in C; ghc and xmonad are in haskell
17:12:21 <HairyDude> juliohm: btw, if you think C and C++ are basically the same language, you have a *lot* to learn :)
17:12:24 <monochrom> this is a stupid "debate"
17:12:25 <ddarius> pnielsen: That wasn't even the one that was really weird.  "Inheritance" is fine.  When people say "OOP", most don't mean multiple inheritance because that's rarely (well) supported.  I think what you are actually trying to say is that OO programmers often use the Template Pattern.
17:12:31 <juliohm> monochrom, +1
17:13:17 <monochrom> good, so please end the stupid debate that you started
17:13:19 <shapr> juliohm: So, what sort of answers do you want? Examples of abstraction in larger Haskell programs?
17:13:25 <HairyDude> I find the practice of applying arbitrary proper nouns to code smells pretty bogus.
17:13:25 <shapr> monochrom: Be nice
17:13:40 <juliohm> maukd, the point here is that the world largest programs are written in C/C++, C can get very close C++, the same ideas to encapsulate data inside structs instead of classes, in fact C++ is a "big wrapper" on top of a raw C code.
17:13:49 <Puffton> Are there "map comprehensions" the way there are list comprehensions?
17:13:55 <maukd> juliohm: again, wrong. C/C++ is a completely different language
17:14:05 <Puffton> Hm
17:14:07 <maukd> juliohm: C can't get close to C++
17:14:13 <Eduard_Munteanu> Puffton: what do you mean?
17:14:17 <monochrom> no, there isn't a map comprehension yet
17:14:17 <juliohm> maukd, why not?
17:14:22 <maukd> juliohm: C++ is not a big wrapper on top of C
17:14:33 <maukd> juliohm: C++ doesn't really have structs in the C sense
17:14:45 <pnielsen> ddarius: Correct. I apologize profusely. What I meant was multiple levels of inheritance, not multiple inheritance.
17:14:55 <pnielsen> ddarius: No need to be such a dick about it
17:15:05 <juliohm> maukd, C++ classes are basically a pretty way to point to resources in the stack/heap.
17:15:07 <HairyDude> Puffton: no, but you can do the same things using functions in Data.Map (assuming that's what you're talking about)
17:15:09 <maukd> juliohm: wrong
17:15:17 <juliohm> it nothing more than C pointers
17:15:20 <maukd> juliohm: C has no stack or heap and I bet C++ doesn't either
17:15:25 <pnielsen> maukd: I meant multiple levels of inheritance, not multiple inheritance.
17:15:27 <maukd> classes aren't pointers
17:15:28 <juliohm> o.O
17:15:30 <Ralith> maukd: perhaps juliohm means that C++ can be compiled down to C, and doesn't realize how trivially true this is.
17:15:56 <juliohm> Ralith, i know exactly how a C++ class can be down to C
17:16:05 <Ralith> see?
17:16:12 <juliohm> that's what i'm trying to say, it's all pointers
17:16:26 <maukd> juliohm: then everything is "all pointers"
17:16:34 <HairyDude> pointers all the way down!
17:16:39 <juliohm> the resource is allocated and each member function, field is an offset from the top of the class in the stack
17:16:42 <Ralith> juliohm: the wikipedia page on turing completeness may be of interest.
17:16:46 <maukd> I can compile C to javascript
17:17:11 <typoclass1> juliohm: c and c++ are popular ("proven"), but there's nothing wrong with trying to push the envelope. (without pushing the envelope, there'd never have been any technical progress)
17:17:13 <Puffton> HairyDude, I would like to do something like this: min [myFunc x y | x <- a, y <- a, x /= y]
17:17:17 <maukd> juliohm: that doesn't even make sense
17:17:22 <juliohm> Ralith, you're really off-topic.
17:17:30 <Puffton> where a is a map
17:17:30 <shapr> juliohm: Do you actually want to understand abstraction in Haskell, or do you really want to have an off-topic discussion about C++?
17:17:48 <Eduard_Munteanu> Puffton: there are generalized monad comprehensions
17:17:48 <HairyDude> Puffton: min of what? key or value?
17:17:57 <HairyDude> Eduard_Munteanu: note that Map is not a monad.
17:18:02 <rwbarton> Puffton: just insert M.toList as appropriate
17:18:05 <Ralith> juliohm: you're not one to talk about topicality :P
17:18:14 <rwbarton> or I guess you can use Foldable
17:18:19 <Puffton> HairyDude, of the value
17:18:22 <typoclass1> > minimum [5,3,9] -- Puffton, is this what you're asking for?
17:18:23 <Puffton> rwbarton, but that feels a bit ugly, no? :S
17:18:23 <lambdabot>   3
17:18:30 <rwbarton> not really?
17:18:32 <Ralith> juliohm: anyway, if you're not interested in haskell, this probably isn't the channel for you.
17:18:53 <Puffton> I am doing it in another place now with "elems"
17:18:55 <juliohm> shapr, i really interested in understand beforehand how Haskell scales, as i said, i read the Learn you Haskell twice, but reading it doesn't get me a feeling that the language is capable of produce codes like SolidWorks, AutoCAD, Linux, etc.
17:18:56 <Puffton> which should be the same thing
17:19:07 <maukd> http://images.4channel.org/f/src/dancingstreetguys.swf
17:19:08 <rwbarton> oh sorry, that's probably what it's called
17:19:34 <rwbarton> or rather, that gives you just the elements
17:19:38 <pnielsen> juliohm: what is your concern, really?
17:19:42 <rwbarton> the values rather than the (key, value) pairs
17:19:51 <Eduard_Munteanu> There's something wrong with that enumeration of software.
17:19:54 <typoclass1> juliohm: i think the abstraction of the function is more powerful than you think
17:19:58 <pnielsen> juliohm: like, specifically, what are you worried about?
17:19:59 <shapr> juliohm: I agree. I would strongly suggest you try to write a Haskell program that does something simple.
17:21:02 <geekosaur> could you explain why your vague feeling with nothing behind it should be trusted by anyone?
17:21:48 <juliohm> pnielsen, can you imagine a Haskell program with thousands or million objects instantiated and communicating each other asynchronously? How do you debug it?
17:21:49 <HairyDude> Puffton: I guess you want something like deleteFindMin (fromList [(x,y) | x <- a, y <- a, x /= y])
17:21:57 <HairyDude> Puffton: where a is a list?
17:22:09 <shapr> juliohm: Perhaps reading the source to an actual CAD program written in Haskell would help? https://github.com/colah/ImplicitCAD
17:22:16 <juliohm> In C/C++ we can try to follow the program workflow and put break points to see what is happening.
17:22:25 <Jafet> @protontorpedo
17:22:25 <lambdabot> is there a decent scheduler in haskell? how about a netwrok monitor?
17:22:26 * ddarius has made Haskell programs with thousands of concurrenc processes communicating.
17:22:43 <maukd> juliohm: show me a C++ program with a million objects communicating asynchronously
17:22:44 <HairyDude> ddarius: by "process" you mean "lightweight thread", I guess?
17:22:44 <pnielsen> juliohm: yes, I can. Haskell has excellent concurrency mechanisms. GUI programs usually aren't heavily concurrent though, so I don't understand what your real concern is
17:22:46 <rwbarton> why on earth would anyone think an introductory language text would give the reader an idea of what writing operating systems or other large systems in the language is like...
17:22:53 <rwbarton> this is ridiculous
17:22:56 <monochrom> I know Chris Olah. he and I are about the only two regular members of the Toronto haskell user group
17:23:12 <Puffton> HairyDude, how did you know I wanted to delete it too? :p
17:23:18 <juliohm> shapr, thanks for the link. :)
17:23:31 <maukd> juliohm: also show me how you're going to follow a million threads with "break points"
17:23:32 <alpounet> shapr, hah! awesome, i didn't know abotu this one
17:23:49 <HairyDude> Puffton: well, that's the only function I can see that finds the minimum... it happens to give you back the map without that element too, but you can ignore it if you don't want it
17:23:49 <shapr> alpounet: It looks nifty, though I still haven't had time to play with it.
17:23:57 <HairyDude> Puffton: minimum element, that is
17:24:04 <juliohm> maukd, AutoCAD, SolidWorks, etc. All those have lots of objects playing around.
17:24:14 <juliohm> And of course, million is just a way to say.
17:24:23 <pnielsen> shapr: impossible!
17:24:30 <juliohm> maukd, how do you debug your haskell app?
17:24:30 <rwbarton> you can of course conclude that *you* do not know how to go about designing large systems in that language, yet, but that is a statement about you, not the language
17:24:32 <maukd> juliohm: how are those asynchronous?
17:24:57 <juliohm> maukd, or you're saying Haskell programs don't have bugs because we can prove it correctness? :(
17:25:16 <monochrom> http://www.iij.ad.jp/en/company/development/tech/mighttpd/ is an introduction to mighttpd, a high-speed web server written in haskell. it uses thousands of threads, and they communicate asynchronously
17:25:29 <pnielsen> juliohm: like rwbarton said, it seems like the real problem is you don't understand Haskell well enough to understand how you can write programs. You mistakenly take this to mean that Haskell is a bad language for writing large programs
17:25:32 <gwern> > 7 * 60
17:25:34 <lambdabot>   420
17:25:38 <maukd> juliohm: no, I'm saying: show me those millions of asynchronously communicating objects
17:26:07 <meiji11> hey
17:26:10 <monochrom> while a web server is not "large scale" in terms of program size, it is certainly "large scale" in terms of run-time structure
17:26:10 <juliohm> maukd, if i had the SolidWorks source code, i could show you.
17:26:17 <typoclass1> juliohm: i think this whole discussion needs a clearer focus. perhaps you could find some haskell program (github, hackage) and then identify 1 or 2 specific problems that you're having with it. ("i've noticed it has X modules/functions/lines of code/..., that seems like too many/too few/..., what could be done to improve that")
17:26:18 <juliohm> or the AutoCAD one
17:26:39 <meiji11> is there a nice way to do a lisp-like map function in haskell, which maps a single, two-input function over two lists for example?
17:26:41 <juliohm> typoclass1, i'll take a look at the link shapr gave me. :)
17:26:46 <pnielsen> juliohm: but you have no idea how those applications are implemented
17:26:50 <ddarius> "I notice this functioning code has too few lines of code.  Please add more."
17:26:52 <BMeph_> meiji11: Hi! Don't mind the rage-spam, it's a work-in-progress... ;)
17:26:52 <Jafet> :t zipWith
17:26:53 <lambdabot> forall a b c. (a -> b -> c) -> [a] -> [b] -> [c]
17:27:02 <Jafet> :t zipWith3
17:27:03 <lambdabot> forall a b c d. (a -> b -> c -> d) -> [a] -> [b] -> [c] -> [d]
17:27:06 <juliohm> pnielsen, of course i have an idea, based on the tasks i can do with them.
17:27:21 <maukd> juliohm: what's your source for claiming AutoCAD is written in C++?
17:27:26 <pnielsen> juliohm: that tells you nothing about whether the program is written with concurrent semantics
17:27:26 <HairyDude> :t map *** map
17:27:27 <lambdabot> forall a b a1 b1. (a -> b, a1 -> b1) -> ([a] -> [b], [a1] -> [b1])
17:27:34 <typoclass1> ddarius: well do it yourself, send patches plz ;)
17:27:34 <meiji11> BMeph_, rage spam?
17:27:44 <juliohm> in AutoCAD i can manipulate lots of objects at the same time, do processing at different levels, simulate while reshaping another experiments, ...
17:27:54 <HairyDude> nah, zipWith is probably what meiji11 wants
17:28:00 <pnielsen> juliohm: that has nothing to do with coroutines or asynchronous communication
17:28:02 <juliohm> this is parallel processing, period.
17:28:15 <pnielsen> juliohm: parallelism is not concurrency
17:28:19 <meiji11> HairyDude, zipWith will do, thanks
17:28:20 <pnielsen> juliohm: you are misguided
17:28:39 <HairyDude> parallelism /= concurrency
17:28:40 <Jafet> @protontorpedo
17:28:40 <lambdabot> how does haskell compare to say java?
17:28:51 <juliohm> pnielsen, there are many types of parallelism, i know, shared memory, distributed memory...
17:28:51 <HairyDude> @botsnack
17:28:51 <lambdabot> :)
17:29:02 <rwbarton> that's two for two for protontorpedo
17:29:03 <ddarius> @botsnack
17:29:03 <lambdabot> :)
17:29:09 <pnielsen> juliohm: That's concurrency
17:29:11 <monochrom> I don't know how haskell compares to java or c++ etc. but I know how haskell compares to scala.
17:29:12 <juliohm> but AutoCAD runs on a single machine with no MPI environment or any other alternative
17:29:31 <juliohm> pnielsen, and what is parallelism?
17:29:33 <pnielsen> juliohm: Concurrency is interleaving actions; Parallelism is simultaneously executing actions
17:29:50 <maukd> juliohm: what's your source for claiming AutoCAD is written in C++?
17:29:51 <monochrom> Chris Okassaki did not need help understanding haskell, but needs help understanding scala. that's how they compare, from my perspective
17:29:52 <applicative> @protontorpedo
17:29:52 <lambdabot> so with 100s of users adn different daabases haskell does fine?
17:29:54 <shachaf> You can implement parallelism with concurrency.
17:29:56 <shachaf> Similarly, can implement concurrency with parallelism.
17:30:07 <shachaf> (Well, OK, not similarly.)
17:30:08 <Eduard_Munteanu> Heh, monochrom
17:30:18 <Jafet> monochrom: proving the inferiority of haskell
17:30:19 <pnielsen> juliohm: A concurrent program can run 1,000,000 workers on the same CPU; you can only run one worker/thread at the same time on one CPU
17:30:30 <pnielsen> juliohm: Synchronization is required for concurrency
17:30:31 * ddarius awaits shachaf's implementation of forkIO and MVar with par.
17:30:48 <pnielsen> juliohm: Concurrency enables parallelism, but they're not equivalent
17:30:53 <shachaf> ddarius: The GHC RTS runs multiple Haskell threads at the same time on multiple CPUs.
17:30:59 <monochrom> but I guess you could say, he learned haskell first, there is much unlearning to do before learning scala as a second language...
17:31:12 <shachaf> That seems like an implementation of concurrency with parallelism.
17:31:16 <juliohm> pnielsen, in my language concurrency and parallelism are words used for the same purpose. But in the programming world people often use this definition you said. Not that useful, but it's used.
17:31:23 <pnielsen> shachaf, ddarius: That is parallelism enabled by concurrency
17:31:26 <Eduard_Munteanu> So that's the raison d'etre for @protontorpedo, hm...
17:31:32 * HairyDude decides to ignore all trolls.
17:31:32 <ddarius> shachaf: That seems like an implementation of concurrency -having- parallelism.
17:31:33 <juliohm> Hence, a single machine can only achieve interlieving actions
17:31:41 <applicative> @protontorpedo
17:31:41 <lambdabot> does huge or ghc have more stuff?
17:31:57 <maukd> juliohm: hello?
17:32:03 <pnielsen> juliohm: It's very useful. They mean two different things.
17:32:07 * Eduard_Munteanu awaits the day @yarr will fit in just as well
17:32:11 <monochrom> and I also hate stupid "debates" on concurrency vs parallelism
17:32:11 <Eduard_Munteanu> @yarr
17:32:11 <lambdabot> Avast!
17:32:13 <shachaf> ddarius: If you want to implement a system with two concurrent threads, you can either context-switch between them or run them in parallel.
17:32:19 <juliohm> monochrom, +1
17:32:20 <pnielsen> juliohm: http://ghcmutterings.wordpress.com/2009/10/06/parallelism-concurrency/
17:32:30 <pnielsen> juliohm: http://concur.rspace.googlecode.com/hg/talk/concur.html#title-slide
17:32:36 <rwbarton> Eduard_Munteanu: talk like a pirate day was a week ago
17:32:47 <Eduard_Munteanu> Dang :)
17:33:09 <shachaf> rwbarton: And Don't Talk Like A Pirate Day is in ~6 months.
17:33:13 <shachaf> Until then we can talk however we like.
17:33:23 <rwbarton> I did not know that, thanks for the heads up.
17:33:33 <juliohm> pnielsen, i'll read the links, thanks.
17:33:39 <HairyDude> I didn't know there was a Don't Talk Like A Pirate Day
17:33:55 <applicative> this new paper of oleg simon pj et al. is a complete chamber of horrors
17:33:56 <pnielsen> shachaf: concurrency does not imply parallelism; it enables it
17:33:57 <tsou> maukd: i don't think he has a source for that, it's in C with a simple googling :P
17:34:09 <shachaf> pnielsen: "enables it"?
17:34:28 <HairyDude> applicative: it kills you in amusing and spectacular ways with no warning?
17:34:31 <pnielsen> shachaf: it makes parallelization easy
17:34:44 <applicative> HairyDude: the types are torture
17:34:48 <shachaf> You're mixing things up.
17:34:50 <pnielsen> shachaf: Your last sentence was an excellent example of concurrency enabling parallelism. A program that is concurrent is trivial to make parallel.
17:35:06 <shachaf> (I was too. But I was doing it on purpose.)
17:35:52 <pnielsen> shachaf: How so? :)
17:36:03 <maukd> do you even liftM?
17:36:39 <ddarius> Actually, there are concurrent programs that have no parallelism, e.g. the power series implementation in NewSqueak.
17:36:54 <pnielsen> shachaf: You seem to imply that concurrency is a biproduct of parallelism, but it is perfectly possible to write concurrent programs that are not parallell
17:37:06 <pnielsen> ddarius: Which is exactly what I'm saying.
17:37:19 <shachaf> pnielsen: I said you can implement concurrency in terms of parallelism.
17:37:25 <pnielsen> Concurrency enables parallelization, but concurrency and parallelism are not the same thing
17:37:32 <shachaf> pnielsen: That seems to be the exact opposite of "A program that is concurrent is trivial to make parallel."
17:37:33 <pnielsen> shachaf: You implement parallelism in terms of concurrency
17:37:33 <ddarius> pnielsen: How is this consistent with "A program that is concurrent is trivial to make parallel."
17:37:37 <hpaste> meretrix pasted “IOUnsafe” at http://hpaste.org/75507
17:37:49 <pnielsen> shachaf: or, it is easy to do so
17:37:52 <shachaf> pnielsen: My whole joke-thing was that both statements are valid.
17:38:11 <shachaf> ddarius: There exists a program that is concurrent such that it's trivial to make parallel.
17:38:24 <pnielsen> ddarius, shachaf: I don't know if you are just having a laugh trying to make me look like an idiot, but the presentation I just linked has Rob Pike, the author of Newsqueak, saying the same thing
17:38:47 <maukd> (rob pike)--
17:39:10 <ddarius> pnielsen: Yes, I (mostly) agree with the links you are providing.  I think you are saying some things consistent with them and some things inconsistent with them.
17:39:24 <danharaj> ddarius: seems consistent with the rest of human behavior.
17:39:35 <pnielsen> shachaf: I'm sorry if I'm giving another impression, but I was agreeing with you the whole time
17:39:45 <jfischoff> rwh builds a thread manager to wait for child threads to complete. Is there something on hackage to accomplish the same thing?
17:39:45 <pnielsen> ddarius: What is inconsistent?
17:40:18 <shachaf> pnielsen: I have no idea what's even going on, man.
17:40:23 <jfischoff> okay I found something
17:40:24 <shachaf> I may be having a laugh but it's not at anybody's expense.
17:40:32 <pnielsen> shachaf: haha
17:40:37 <meretrix> Hi, when I make multiple calls to a function that uses IOUnsafe, I am only prompted for input once. Why is this? (I know I shouldn't be using IOUnsafe, but I'm just using it has a hack in a more complex case). Sample code: http://hpaste.org/75507
17:41:25 <meretrix> And is there a workaround besides handeling IO correctly?
17:41:40 <maukd> meretrix: what do you mean, "just using it as a hack"? that's exactly why you shouldn't use it
17:41:48 <maukd> meretrix: also, what function?
17:42:01 <Jafet> I think the workaround is {-# NOINLINE f #-}
17:42:14 <geekosaur> there might be a workaround for that example, but not at all reliably for all possible uses.
17:42:16 <Jafet> Well, f needs to be a function
17:42:20 <danharaj> that is the workaround that is guaranteed to maybe work.
17:42:26 <monochrom> it's ok to use IOUnsafe, but not ok to ask for input inside
17:42:55 <meretrix> Jafet: I did try the NOINLINE, but it didn't help.
17:42:58 <pnielsen> ddarius: I guess we're disagreeing about the meaning of "enable." By enable I mean it makes parallelization easy. I don't mean that a concurrent program has to be parallel.
17:43:23 <meretrix> monochrom: So, simple putting the getLine outside will solve it?
17:43:29 <Jafet> You need to make f a function, otherwise NOINLINE doesn't mean anything.
17:43:37 <pnielsen> ddarius: that's the reason I clarified juliohm's statement in the first place
17:43:47 <Puffton> http://hpaste.org/75510
17:43:50 <ddarius> pnielsen: Concurrency is not interleaving actions either in the "time slicing" interpretation, or even at a higher level.  Depending on the level you are working at, there are (usually) concurrent executions that can't be explained as an interleaving of operations.  The (almost) key thing is the non-determinism (there's an narrow exception for declarative concurrency.)
17:43:57 <Jafet> Then you need to understand the operational semantics of GHC. But after that you're done.
17:43:58 <Puffton> looking at s and minS, is this really how to work with lists, maps and sets in Haskell?
17:44:05 <Puffton> it feels like I'm using them in a roundabout way
17:45:36 <ddarius> (Really, concurrency is, as Simon Marlow said, about multiple threads of control.)
17:45:58 <rwbarton> Puffton: well this M.findMin . M.fromList stuff is way overkill, but otherwise it looks fine
17:46:12 <Puffton> rwbarton, how would you do it?
17:46:16 <rwbarton> what's wrong with just... minimum
17:47:30 <applicative> meretrix: it already knows what f is after it gets a line, I don't see why it should figure out what string f is again.
17:47:42 <Jafet> Puffton: List is usually never imported qualified.
17:47:44 <rwbarton> I guess it might give a different answer if there is a repeated minimum "s fi di x y" value, but it looks like you don't care about that
17:47:55 <Puffton> how will it know which value to use then?
17:47:58 <Puffton> since it's a tuple
17:48:08 <Jafet> :t minimumBy
17:48:09 <lambdabot> forall a. (a -> a -> Ordering) -> [a] -> a
17:48:17 <rwbarton> tuples are ordered lexicographically
17:48:17 <ddarius> A parallel program does not need a notion of multiple threads of control to be understood unless it is also a concurrent (trivially by "definition").
17:48:39 <Puffton> oh, so it will minimize on the key, even if it's a list on tuples?
17:48:43 <Puffton> of*
17:48:57 <ddarius> At any rate, the real issue is not that "concurrency enables parallelism", but, traditionally, parallelism has almost always required concurrency which is rather undesirable.
17:48:58 <pnielsen> ddarius: I don't understand what you mean. Perhaps we have different interpretations of the word interleave
17:49:02 <Jafet> > (1,2) `compare` (2,1)
17:49:03 <lambdabot>   LT
17:49:05 <rwbarton> it will take the one with minimum "key" (or just first component really) and among those the one with minimum "value" (or second component)
17:49:31 <Puffton> yeah seems to work
17:49:33 <Puffton> cool
17:49:40 <pnielsen> ddarius: I was never talking about an issue, though. The only thing I've been trying to say is that concurrency makes parallelism easy
17:49:52 <hpaste> “Jonathan Fischoff” pasted “Imperative Haskell” at http://hpaste.org/75511
17:49:57 <rwbarton> you can also rewrite the whole thing as a minimumBy
17:50:09 <pnielsen> ddarius: And that the difference between concurrency and parallelism is that parallelism executes operations simultaneously
17:50:12 <jfischoff> I haven't tried to run that code ^ but I was wondering if I was on the right track
17:50:15 <Jafet> The only real problem I can see with that program is that it seems to use a terrible algorithm
17:50:18 <rwbarton> though actually that is somewhat worse since you'll recompute s
17:50:42 <jfischoff> I
17:51:00 <jfischoff> I'm trying to make an efficient parallel map. http://hpaste.org/75511
17:51:31 <ddarius> pnielsen: Parallism is easier without concurrency.
17:51:34 <Jafet> jfischoff: I thought we'd agreed that C was offtopic here!
17:51:37 <maukd> :t parMap
17:51:38 <lambdabot> forall b a. Strategy b -> (a -> b) -> [a] -> [b]
17:51:53 <pnielsen> ddarius: The discussion has been about concurrency from the start
17:52:02 <pnielsen> ddarius: What I was pointing out was a misunderstanding of the words concurrency and parallelism
17:52:07 <jfischoff> maukd: can I mutate an foreign buffer in place there?
17:52:17 <pnielsen> ddarius: juliohm suggested AutoCAD was a program with millions of concurrent threads, and took that to mean it was a parallel program
17:52:31 <Jafet> jfischoff: there is probably a mutable parallel vector library somewhere
17:52:41 <juliohm> shapr, the this is what i'm saying, this is far from large scale: https://github.com/colah/ImplicitCAD
17:52:47 <Jafet> (That's way too many adjectives)
17:52:56 <pnielsen> ddarius: I don't disagree that parallelism is easier without concurrency. This and the statement that concurrency makes parallelism easy aren't mutually exclusive :)
17:53:02 <geekosaur> and that proves that nothing can ever be large scale?
17:53:32 <juliohm> pnielsen, parallelism is just a word to describe things being done at the "same" time.
17:53:33 <jfischoff> Jafet: I would not be surprised to find that function lurking somewhere, err a better version
17:53:48 <rwbarton> jfischoff, can't you process each chunk in ST and split up the work with par or parMap or something? that might be more pleasant
17:53:48 <ddarius> juliohm: You'd be correct if you remove the quotes.
17:53:52 <monochrom> those who keep preaching how concurrency /= parallelism should, for practising what they preach, go to haskell mailing lists and advocate for renaming "par" to "conc" or something. For all "par" does is creating concurrent sparks, which enables but does not enforce parallelism.
17:53:56 <pnielsen> juliohm: Literally, not figuratively
17:53:59 <hpaste> applicative annotated “IOUnsafe” with “IOUnsafe (annotation)” at http://hpaste.org/75507#a75512
17:54:03 <mikeplus64> jfischoff: repa (that parallel vector library Jafet mentioned)
17:54:16 <jfischoff> repa is off the list
17:54:17 <juliohm> ddarius, i would remove the quotes myself, but people on this channel generally takes statements too seriously.
17:54:19 <ddarius> monochrom: Uh, par definitely does NOT create concurrency.
17:54:21 <applicative> meretrix: ^^^ this might do what you want
17:54:31 <Jafet> I think repa has immutable arrays.
17:54:46 <juliohm> for me concurrency and pararelism stills the same. they are just words, no matter what the programmers uses as convention
17:54:47 <monochrom> well, it does not create parallelism either
17:54:50 <ddarius> juliohm: Um, if you have a time-slicing implementation, you don't have parallelism.
17:54:56 <Jafet> Though you might want to consider if you really need in-place update.
17:55:06 <ddarius> monochrom: Yes, but it allows parallelism.  It doesn't allow concurrency.
17:55:13 <jfischoff> rwbarton: I think I see what you are saying. Got to run to dinner, I'll take a crack at that
17:55:33 <applicative> can I store some of this in @protontorpedo?   "for me concurrency and pararelism stills the same. they are just words, no matter what the programmers uses as convention"
17:55:36 <pnielsen> juliohm: they are not the same
17:55:41 <shapr> juliohm: I think ImplicitCAD may be sufficiently large scale to demonstrate how abstraction works in Haskell. Lines of Code in Haskell count for far more than in most languages.
17:55:59 <shapr> applicative: lambdabot's source (or at least state file) should include those.
17:56:01 <ddarius> That's kind of the point I'm trying to make.  If you can -tell-, you are executing in parallel (from within the language), then you have concurrency.  Adding parallelism may also add concurrency.  Concurrency is the thing that you can see.  You can't see parallelism.
17:56:27 <juliohm> shapr, ImplicitCAD doesn't have an GUI at all, right?
17:56:34 <ddarius> applicative: You -could-, but @protontorpedo refers to a particular person.
17:56:37 <pnielsen> ddarius: That's a good explanation
17:56:40 <applicative> ddarius: I know
17:56:52 <ddarius> applicative: If you want, you can create a new command.
17:57:02 <juliohm> the GUI contains a lot of the objects i mentioned in the "thousand objects ..."
17:57:05 <applicative> photontorpedo
17:57:12 <Jafet> @remember juliohm for me concurrency and pararelism stills the same. they are just words, no matter what the programmers uses as convention
17:57:13 <lambdabot> Good to know.
17:57:18 <nwf> I have a stupid question -- I have an expression which checks on every _tuple_ type, but not on every type.  I have added a constraint which ought to close the set of admissible types to just tuples, but GHC does not reach the correct conclusion.  Is there any way to do what I want or is it hopeless?
17:57:19 <shapr> Jafet: be nice
17:57:37 <juliohm> Jafet, thank you. :)
17:57:50 <maukd> nwf: what is that expression?
17:57:53 <Jafet> I am nice, just not to everyone.
17:58:05 <shapr> Jafet: heh, ok
17:58:05 <ddarius> I am nice, just not to anyone.
17:58:08 <applicative> nwf, you can enumerate the tuple types?
17:58:36 <shapr> juliohm: Is a GUI necessary to understand how Haskell builds abstractions?
17:58:56 <nwf> applicative: I've tried creative uses of TH and DataKinds both to generate the closed universes I want to quantify over.
17:59:17 <juliohm> Jafet, one more, for me array has a clear definition, in C++ we talk about arrays and know what they mean, in Haskell an array can be a lot of different things and Haskell programmers don't care about a precise vocabulary in this circunstamces. :)
17:59:22 <applicative> nwf I see you really are going at it
17:59:44 <nwf> maukd: Let me collect my work in progress to hpaste; just a moment.
17:59:49 <Jafet> nwf: most people realize the futility early on and make about ten instances for tuples.
17:59:49 <juliohm> shapr, no, i'm just arguing that i don't see a large scale app in Haskell yet.
17:59:55 <ddarius> Oh, it's this guy.
18:00:01 <shapr> juliohm: How would you recognize a large scale app?
18:00:17 <pnielsen> GUI is a strange example to use for a concurrent program
18:00:27 <applicative> nwf isn't hlist basically tuples with as many elements as you please?
18:00:28 <maukd> oh shit, the @official one?
18:00:32 <ddarius> pnielsen: It's a completely natural example.
18:00:33 <mikeplus64> nwf: mind posting the code (just out of interest)
18:00:41 <mikeplus64> oops
18:00:50 <juliohm> shapr, one that has the around the same number of features than AutoCAD for example.
18:00:50 <nwf> applicative: Yes, but I couldn't get HList to do what I wanted either.
18:01:11 <juliohm> SolidWorks is large, Linux is very large, ...
18:01:16 <juliohm> Google Chrome is large
18:01:16 <nwf> I'm working on an EDSL and would like to use Haskell tuples for DSL tuples, and this requires that I be able to shuffle some type constructors.
18:01:17 <typoclass1> juliohm: i think haskellers are overall pretty clear on the terminology. the random-access sequence is called array. the most-used data structure in haskell (with some syntactic support) is called a list
18:01:20 <nwf> Just a moment.
18:01:36 <maukd> juliohm: Linux isn't written in C++
18:01:49 <ddarius> typoclass1: You are wasting your time.  This conversation has been had before.  You should be able to predict how useful it was.
18:02:04 <juliohm> maukd, but it's written in C which is very close. I don't see why you're talking about C++ yet.
18:02:06 <Jafet> typoclass: unlike in python
18:02:15 <juliohm> C/C++ any major language
18:02:18 <juliohm> doesn't matter
18:02:32 <pnielsen> ddarius: certainly, in theory. Certainly not my experience with most GUI frameworks
18:02:33 <Eduard_Munteanu> Oh, boy, kmc should be in here.
18:02:54 <geekosaur> juliohm, you're still blowing smoke
18:02:55 <ddarius> Eduard_Munteanu: We already have mauke.
18:03:00 <Jafet> nwf: since nobody uses longer than sextuples or so, most DSLs only bother with instances up to that.
18:03:07 <maukd> juliohm: C/C++ is not a major language. C is not C++. C/C++ is not C++. C/C++ is not C.
18:03:12 <geekosaur> come up with something based in reality
18:03:14 <shapr> juliohm: Your question as I understand it: "How to do abstraction in Haskell?" My answer: "monad transformers". Tada! This conversation is done!
18:03:18 <maukd> juliohm: C is not very close to C++.
18:03:21 <Eduard_Munteanu> True, but kmc has a particular disdain for the phrase "C/C++"
18:03:25 <pnielsen> maukd: imagine if you could have C/C++ with concurrency/parallelism
18:03:27 <Jafet> Even the Prelude only bothers with a finite length of tuples
18:03:31 <ddarius> Eduard_Munteanu: As does mauke.
18:03:33 <maukd> pnielsen: hah
18:03:34 <juliohm> shapr, hehehe, i laugh with the "Tada!" part
18:03:35 <juliohm> hehehehe
18:03:38 <hpaste> nwf pasted “Quantification over tuples” at http://hpaste.org/75513
18:03:40 <typoclass1> juliohm: you keep bringing up things like linux, but that requires enormous discipline, strong oversight, a lot of testing, and still there's plenty of mistakes being made (buffer overflows, security issues, inexplicable crashes, etc.)
18:04:01 <nwf> Jafet: That's fine, but I don't want my class to have separate "tuple2, tuple3, tuple4, ..." combinators.
18:04:01 <ddarius> pnielsen: Just because they don't use threads, doesn't mean they aren't concurrent.
18:04:14 <maukd> pnielsen: that would be hard to add, I think
18:04:16 <pnielsen> ddarius: I mean that they aren't concurrenct
18:04:24 <nwf> maukd: applicative: mikeplus64: http://hpaste.org/75513
18:04:32 <shapr> juliohm: The thing is, your description of a large scale app allows you to disqualify any Haskell codebase that can be suggested. Thus I feel that is not a useful question/request.
18:04:32 <pnielsen> but I admit I'm not a GUI programmer
18:04:33 <mikeplus64> nwf: sweet
18:04:43 <mikeplus64> (also scary)
18:04:45 <mikeplus64> :)
18:04:55 <Jafet> nwf: ok. I've not seen a DSL that bothers with that.
18:04:56 <shapr> juliohm: So, I suggest you will learn the most about abstraction in Haskell by actually *writing* Haskell code yourself.
18:04:57 <juliohm> shapr, ok, let me put it more clear, any Haskell program with a GUI?
18:05:01 <pnielsen> juliohm: You still haven't given an example of a real problem that Haskell has that makes it unsuitable for developing large applications
18:05:02 <shapr> juliohm: Sure, lots.
18:05:19 <mikeplus64> juliohm: xmonad, leksah, plenty of games
18:05:20 <juliohm> shapr, i need only one completely written in Haskell
18:05:32 <maukd> (also, I'm pretty sure no one here knows C/C++)
18:05:33 <juliohm> no wrappers for external C/C++ libraries
18:05:42 <maukd> juliohm: there are no C/C++ libraries
18:05:43 <shapr> And what does completely mean? No use of Qt, wxWindows, or gtk?
18:05:45 <juliohm> (graphical libraries)
18:05:49 <juliohm> yep
18:05:54 <maukd> haha, what
18:05:56 <shapr> juliohm: That's a very silly request.
18:06:01 <mikeplus64> no xlib, xcb or whatever? juliohm
18:06:08 <nwf> juliohm: xmonad is completely Haskell using the FFI for libX11.  There would be no theoretical obstacle, just inconvenience, to make it use the X wire format directly.
18:06:11 <maukd> no X11, no libc
18:06:15 <pnielsen> this conversation just descended into room-temperature IQ
18:06:20 <shapr> Oh WAIT! I know of one!
18:06:22 <shapr> LightHouse!
18:06:23 <juliohm> X11 and libc is ok, of course.
18:06:24 <BMeph_> ddarius: Did that guy who claimed to know C and D ever actually look at E? ;)
18:06:27 <maukd> juliohm: why?
18:06:32 <ddarius> BMeph_: I don't know.
18:06:43 <applicative> nwf: I'm worried about the error messages your users are going to be reading ... :)
18:06:49 <BMeph_> ddarius: Pity.
18:07:03 <nwf> Jafet: Yeah, I might give up and use TH to derive the equations each of my classes are going to need.
18:07:09 <Jafet> nwf: does the expression "work" if you add more type signatures?
18:07:11 <nwf> applicative: Well, fortunately, the user is just me. :)
18:07:11 <maukd> juliohm: btw, why did you ignore my questions before?
18:07:17 <juliohm> maukd, because if someone touches the X11 library, it explodes, it's the messy thing i ever saw.
18:07:23 <nwf> Jafet: I have never figured out which signatures I would need to add.
18:07:31 <juliohm> maukd, what questions?
18:07:32 <juliohm> sorry
18:07:39 <Jafet> You don't need to. The error message will contain the word "ambiguous"
18:07:47 <maukd> <maukd> juliohm: what's your source for claiming AutoCAD is written in C++?
18:08:05 <applicative> wikipedia says it's c
18:08:06 <nwf> Jafet: The errors that GHC (HEAD) gives are also sort of worrying: "Could not deduce (r ~ RTR (RTER ty r))"
18:08:28 <Jafet> Well, or that.
18:08:29 <juliohm> thanks applicative, i just guessed because again, C/C++ is the language for large scale apps
18:08:32 <nwf> And "Could not deduce (ty ~ RTE (RTER ty r))"
18:08:38 <juliohm> maukd, ^
18:08:39 <maukd> juliohm: stop saying "C/C++"
18:08:50 <maukd> juliohm: you have no idea what you're talking about
18:08:52 <applicative> what does C++ have to do with C?
18:08:54 <shapr> juliohm: Check out Haskell running on the bare metal as its own operating system: http://lingrok.org/xref/lighthouse/
18:08:57 <shapr> That includes a GUI
18:08:59 <Jafet> nwf: "I can't figure out which instance to use"
18:08:59 <ddarius> pnielsen: Let's say I have a timeout event scheduled and a button.  When the event handlers for each fires they will set the contents of a label to different strings, say "Timeout" and "Button".  Assuming both the button is clicked and the timeout expires, what is the label displaying?
18:09:04 <nwf> shapr: That's _awesome_.
18:09:12 <juliohm> is just a shortcut, i know very precisely these are different languages with different idioms
18:09:12 <nwf> Jafet: I am aware that that's what it means. :)
18:09:28 <typoclass1> juliohm: "because if someone touches the X11 library, it explodes, it's the messy thing i ever saw" -- what do you mean by that?
18:09:34 <juliohm> maukd, you really thinks makes difference to write C and C++, C/C++ ?
18:09:56 <rwbarton> nwf: what you are trying to do on line 62 doesn't seem to make sense, you want something like (Univ a, Univ b, Univ c) -> Univ (a, b, c), right? but the Univs might be hiding different Lang types
18:10:04 <maukd> juliohm: do you really think it makes a difference whether you write "java" or "javascript"?
18:10:05 * applicative writes C/Java for the hell of it
18:10:05 <pnielsen> ddarius: oh I understand that it's hard in parallel. I mean that I haven't found GUI toolkits to be very concurrent
18:10:07 <Jafet> Well then, adding sufficiently many type signatures should solve the problem
18:10:10 <nwf> rwbarton: They're universal, not existential, so.
18:10:11 <shapr> juliohm: It still sounds like you want to argue about C++ more than you want to learn about Haskell abstractions.
18:10:15 <rwbarton> oh sorry
18:10:23 <rwbarton> so they are
18:10:25 <applicative> everything important is written with curly brackets
18:10:27 <nwf> They can and are mapped to the same Lang by the RTupled equality constraints.
18:10:45 <nwf> (I got that part working in GHCi, at least. ;)  The problem is the U constructor.)
18:10:47 <applicative> juliohm: you can use curly brackets in haskell!
18:10:51 <pnielsen> juliohm: Please come up with an example of a problem that Haskell has that makes it unsuitable for writing large applications
18:10:58 <juliohm> maukd, hehehe, java javacript is not comparable to C C++, i'm not writing java/script
18:10:59 <ddarius> pnielsen: Huh?  Parallelism has nothing to do with what I said, and again, I think you are attributing things to concurrency that aren't part of concurrency.
18:11:09 <juliohm> applicative, hehehehe
18:11:11 <rwbarton> nwf: can you annotate the paste with the error messages?
18:11:12 <pnielsen> ddarius: Then I don't understand what you are suggesting
18:11:13 <maukd> juliohm: so when I asked you for examples of programs using millions of asynchonously communicating objects, you said AutoCAD because ... you guessed it should be written in C++ because it's a "large scale app" and you guessed it should be using millions of objects because ... ?
18:11:17 <zomg> juliohm: java is not comparable to javascript :P
18:11:19 <nwf> rwbarton: Absolutely.
18:11:31 <ddarius> pnielsen: I wasn't suggesting anything, I asked you a question about a hypothetical program.
18:11:36 <maukd> juliohm: C/C++ has about as much to do with C++ as java has to do with javascript
18:11:43 <juliohm> shapr, i just want a huge haskell code that implements a GUI API
18:11:48 * applicative was afraid of this, java/script c/++
18:11:57 <applicative> @protontorpedo
18:11:57 <lambdabot> is haskell better than APL or perl or clisp?
18:11:57 <dabblego> juliohm: you have been given several examples, bye now
18:11:59 <zomg> applicative: php/python/perl!
18:12:00 <shachaf> maukd: C/C++ is a language based on C/C
18:12:01 <geekosaur> juliohm, the only reltionship java has with javascript is a marketer at netscape
18:12:09 <maukd> shachaf: [citation needed]
18:12:28 <rwbarton> I hear C/C is a very good language
18:12:30 <rwbarton> @karma C/C
18:12:30 <lambdabot> C/C has a karma of 298
18:12:38 <shachaf> @karma haskell
18:12:38 <lambdabot> haskell has a karma of 7
18:12:45 <hpaste> nwf annotated “Quantification over tuples” with “Quantification over tuples (annotation)” at http://hpaste.org/75513#a75514
18:12:47 <Jafet> Pfft, it's just popular.
18:12:49 <applicative> haskell++
18:12:50 <pnielsen> ddarius: you've lost me, sorry
18:12:51 <geekosaur> so, thank you for confirming that you have nothing useful to say
18:12:53 <juliohm> Let me ask again, just to maintain the focus of the question. Any huge Haskell code implementing a GUI API?
18:13:04 <juliohm> applicative, is more like hakell--
18:13:07 * BMeph_ resolves to work "C/Java" into more programming conversations at work
18:13:08 <juliohm> lol
18:13:08 <dabblego> juliohm: No, there are none — all those you have been given so far were ghosts
18:13:12 <ddarius> pnielsen: I'm just asking you what the label shows in the scenario I described.
18:13:17 <nwf> Whoop, I seem to have screwed that up.  In any case, I took the liberty of adding the language pragmas I used, too.
18:13:26 <shapr> juliohm: Perhaps manateecat's browser? http://patch-tag.com/r/AndyStewart/manatee-browser
18:13:31 <geekosaur> troll circling around to the beginning again, I see
18:13:47 <maukd> juliohm: no, I won't let you ask again
18:13:58 <pnielsen> ddarius: depends on whether firing one of them prevents firing the other
18:14:03 <zomg> geekosaur: yeah that's a common pattern isn't it
18:14:23 <shapr> juliohm: You are being perceived as more interested in arguing than learning.
18:14:25 <pnielsen> ddarius: most GUI toolkits I've used have been reactors
18:14:26 <ddarius> pnielsen: It doesn't.  Why would it?  Even if it does, what does the label show?
18:14:47 <juliohm> shapr, you're saying i'm more interested in arguing than learning, but i'm not.
18:14:52 <typoclass1> juliohm: it seems like a weird standard to demand a gui api. would you say python is a language suited for the large? afaik there's no major gui toolkit written in python
18:15:08 <maukd> juliohm: show me a C++ program with a million objects communicating asynchronously
18:15:20 <maukd> you still haven't done that
18:15:42 <Eduard_Munteanu> Um, there's gtk2hs? (I know, I know, C)
18:15:46 <shapr> juliohm: No, I'm saying you are being perceived that way. It's not the same thing at all.
18:15:48 <pnielsen> ddarius: Why wouldn't it? I have no idea how your hypothetical program works
18:16:04 <pnielsen> ddarius: there are many applications that let you click different buttons repeatedly
18:16:13 <pnielsen> ddarius: I'd like you to explain what you are trying to say, instead of this
18:16:15 <juliohm> typoclass1, i know python can for example produce an alternative to MathCAD: http://sourceforge.net/projects/miramath/?source=directory
18:16:29 <ddarius> pnielsen: How about this?  Would the label show "Cat"?
18:16:45 <juliohm> It's enough to me conclude Python is good for this intermediate scale
18:16:53 <pnielsen> ddarius: are you arguing that it's deterministic?
18:17:03 <ddarius> pnielsen: That was a yes or no question.
18:17:06 <juliohm> because it's not that big as MathCAD, but it's good.
18:17:10 <pnielsen> ddarius: just get to the point
18:17:27 <pnielsen> ddarius: have you used GTK, Qt, WinForms, Cocoa, etc.?
18:17:30 <shapr> juliohm: Have you looked at ManateeCat's browser? It's a web browser written in Haskell. It uses Haskell's gtk2hs wrapper of the gtk libraries.
18:17:32 <jmcarthur> juliohm: that uses qt, so it's not all written in python
18:17:43 <ddarius> pnielsen: I'm arguing that it is non-deteriministic and thus concurrent.
18:17:51 <juliohm> shapr, all the source code of the manatee browser are three files?
18:17:55 <typoclass1> juliohm: okay, but that page says it uses qt for the gui, which isn't implemented in python. that's why i'm saying your standard of wanting a gui api implemented in haskell seems weird to me
18:17:57 <jmcarthur> juliohm: your criterion that a qualifying haskell app must be completely in haskell is ridiculous. very few languages go all the way down like C
18:18:08 <ddarius> pnielsen: I don't know about Cocoa, but all of the others have button events and timeout events.
18:18:45 <shapr> juliohm: It also imports manateecat's DBus bindings library, and his gtk extensions, etc. The actual source is spread across quite a few modules. But in essence, yes.
18:18:52 <juliohm> jmcarthur, i'm just saying Python has good support for dealing with low level API's, not saying it needs to rewrite the entire thing
18:18:54 <jmcarthur> juliohm: we have bindings for qt, gtk, wxwidgets
18:19:02 <pnielsen> ddarius: all I said was that I thought GUI was a strange example of somewhere where concurrent semantics are powerful
18:19:13 <ddarius> pnielsen: Have you read Rob Pike's work?
18:19:14 <shapr> Haskell can do an amazing amount of work with very few lines.
18:19:17 <juliohm> jmcarthur, i'll take a look at them...
18:19:19 <dabblego> juliohm: please go and look at all the examples you have been given now, thanks
18:19:33 <pnielsen> ddarius: wonderfully vague again, but yes, some of it
18:19:42 <ddarius> @google "Concurrent Windowing System"
18:19:43 <lambdabot> http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.9465
18:19:43 <lambdabot> Title: CiteSeerX — BriX - A Deterministic Concurrent Functional X Windows System
18:19:55 <pnielsen> ddarius: most windowing systems AREN'T, that's my point
18:19:56 <ddarius> @google Concurrent Windowing System rob pike
18:19:58 <lambdabot> http://doc.cat-v.org/bell_labs/concurrent_window_system/
18:19:58 <lambdabot> Title: A Concurrent Window System
18:20:04 <pnielsen> ddarius: I'm NOT arguing that it's not a good fit in theory
18:20:15 <pnielsen> ddarius: I'm arguing that it's a strange example to bring up for something like AutoCAD
18:20:28 <ddarius> pnielsen: Most windowing systems aren't -theaded-, but that doesn't mean they aren't -concurrent-.
18:20:30 <applicative> juliohm: here's a nice import of Control.Concurrent http://shootout.alioth.debian.org/u64q/benchmark.php?test=threadring&lang=all    http://shootout.alioth.debian.org/u64q/program.php?test=threadring&lang=ghc&id=1
18:20:53 <ion> preflex: seen ManateeLazyCat
18:20:54 <preflex>  ManateeLazyCat was last seen on #haskell 77 days, 8 hours, 21 minutes and 27 seconds ago, saying: How about OCaml? I want to try it.
18:21:00 <pnielsen> ddarius: I'm arguing that they aren't a good example of somewhere where concurrent semantics are useful
18:21:02 <jmcarthur> woah what's f# doing there
18:21:17 <shapr> ion: and he probably did
18:21:17 <pnielsen> ddarius: Again, the frameworks in popular use now: not the ones in the papers above
18:21:20 <jmcarthur> 1/3 the time as ghc. that's impressive
18:21:21 <applicative> it's probably harrop
18:21:28 <shapr> oh no! not jdh!
18:21:44 <applicative> he did some other ones, maybe ocaml
18:21:47 <jmcarthur> it's impressive regardless of who wrote it
18:21:48 <pnielsen> ddarius: I am not arguing about whether GUI toolkits and concurrency are a good fit. I am arguing that most popular GUI toolkits aren't a good example
18:21:49 <applicative> not that one
18:22:00 <jmcarthur> it looks pretty straightforward
18:22:16 <shachaf> Wow, that F# code isn't even trying.
18:22:45 <shachaf> Is "async" preëmptive?
18:22:50 <juliohm> manatee-browser is not on Ubuntu repos?
18:23:07 <juliohm> i'm curious to try it.
18:23:19 <Eduard_Munteanu> juliohm: you can probably get it through cabal
18:23:32 <Eduard_Munteanu> cabal install, even
18:23:33 <pnielsen> ddarius: you seem to be intent on disputing a claim I never made
18:23:36 <pnielsen> ddarius: I don't disagree with you
18:23:40 <jmcarthur> shachaf: that would certainly explain it if it's not
18:23:55 <shachaf> jmcarthur: To be fair, GHC threads aren't really "preëmptive" either.
18:24:03 <ddarius> pnielsen: Popular GUI toolkits aren't a good example of what?
18:24:04 <shachaf> The whole thread-ring benchmark is a joke.
18:24:13 * pnielsen sighs
18:24:16 <pnielsen> ddarius: I'm done :)
18:24:35 <juliohm> Eduard_Munteanu, i'll try using darcs...
18:24:35 <jmcarthur> shachaf: well, they sort of are... in that the semantics is not any more precise than that
18:24:44 <juliohm> and cabal
18:25:21 <Eduard_Munteanu> juliohm: apart from those examples, you might want to look up hackage or http://www.haskell.org/haskellwiki/Applications_and_libraries
18:25:22 <shachaf> jmcarthur: Concurrent Haskell doesn't give you any preëmption guarantees.
18:25:43 <shachaf> jmcarthur: The GHC implementation of it makes it possible, though tricky, to write code that can't be preëmpted.
18:26:06 <Eduard_Munteanu> shachaf: what's with the French? :P
18:26:09 <jmcarthur> shachaf: right
18:26:33 <jmcarthur> shachaf: i just mean there are no guarantees either way. no guarantee of being preempted or of not being preempted
18:26:36 <Eduard_Munteanu> ("preëmpted", that is)
18:26:49 <shachaf> «Programs may use pre-emptive kernel threads or pre-emptive lightweight threads; but programs that use non pre-emptive threads (coroutines, cooperative threads) and any programs that use custom schedulers, will be listed as interesting alternative implementations.»
18:26:51 <typoclass1> Eduard_Munteanu: i think it's andorians, with their eyes or whatever on antennas
18:26:53 <jmcarthur> apart from atomic operations of course
18:27:18 <shachaf> Eduard_Munteanu: That's English, not French.
18:27:21 <shachaf> Easy to confuse.
18:27:40 <juliohm> People use Darcs because it may someday be more close to the Haskell needs?
18:27:56 <juliohm> It's just another VCS, right?
18:28:13 <pnielsen> shachaf: and naïve and naive are both valid
18:28:45 <nwf> juliohm: It's a fundamentally different model from Monotone/Mercurial/Git which tries to be closer to semantics of edits.
18:28:55 <nwf> One hopes it will be closer to all of our needs, not just Haskell's.
18:29:05 <mikeplus64> juliohm: dvcs, there is a bit of dogfooding involved
18:29:06 <nwf> Haskell has no particular needs of a VCS -- I use both darcs and git.
18:29:31 <jmcarthur> juliohm: darcs is the only version control system i know of that has the particular model it has
18:29:52 <juliohm> What is the model you're talking about?
18:30:02 <Eduard_Munteanu> Also, the patch theory behind it might be appealing to certain audiences.
18:30:05 <juliohm> nwf, closer to semantics of edits?
18:30:09 <jmcarthur> juliohm: the main benefit it gives you is that you can cherrypick without changing the commit identity. it sounds small, but it pretty pervasively changes the way you work with it
18:30:44 <typoclass1> juliohm: i like darcs because its command line interface is clear. i've given up on git because i found it too complicated
18:30:56 <rwbarton> is there some way to get the type variables in the type of a polymorphic class method into scope in the definition of the method in an instance? ghc won't let me repeat the signature
18:31:11 <juliohm> typoclass1, have you tried Mercurial? It's nice.
18:31:25 <jmcarthur> juliohm: for example, say you and i both have clones of the same repo with various extra patches in it. if i pull from you, i get to say which patches i want, even if i want something you've written more recent and not something you'd written earlier. i can then continue to develop with just what i wanted, you can pull from me similarly, i can get the patches i skipped later, etc.
18:31:27 <shachaf> rwbarton: I think 7.6 has an extension for that?
18:31:33 <nwf> juliohm: Git's model is one of snapshots -- it records exact states of whole trees; it incidentally stitches these together with commit messages and has some DAG management at this layer.
18:31:58 <typoclass1> juliohm: yeah, hg is cool. i think it's pretty much the same level as darcs regarding the command-line interface
18:32:00 <mikeplus64> juliohm: instead of a repository having a history of commits with a definite sequence, darcs represents it as patches, so if you commit A, B, then C, you can reverse B without reversing C
18:32:12 <jmcarthur> typoclass1: i think hg's interface is the worst of any i've used...
18:32:26 <rwbarton> unfortunately I only have ghc 7.4
18:32:48 <jmcarthur> typoclass1: hg makes it easy to make irreversible mistakes, in particular
18:32:58 <jmcarthur> and the command flags are inconsistent
18:33:03 <ion> It’s actually not acyclic, you just have to come up with something that refers to its own SHA1 sum. ;-)
18:33:18 <mikeplus64> juliohm: that approach has problems in that the patch "tree" can grow very large after a while, but many people seem to like/prefer it
18:33:18 <juliohm> mikeplus64, interesting, now i understood.
18:33:45 <shachaf> rwbarton: Hmm, yes, looks like -XInstanceSigs is new in 7.6.
18:33:56 <typoclass1> jmcarthur: not sure, i've worked with hg only for a while
18:33:59 <jmcarthur> mikeplus64: if you use tags they have the effect of linearizing the history at points
18:34:15 <shachaf> rwbarton: Are these variables that appear only in the method's signature?
18:34:28 <shachaf> You can always give it its own name, presumably...
18:34:31 <jmcarthur> mikeplus64: err, more accurately, they have the effect of creating sync points, since they depend on all patches in the repo at the time they were created
18:34:34 <shachaf> foo = bar where bar :: ...; bar = ...
18:34:45 <jmcarthur> mikeplus64: so they end up making it a bit more manageable, history-wise
18:35:35 <mikeplus64> jmcarthur: yeah (juliohm listen to this guy he knows more than me :))
18:36:08 <jmcarthur> mikeplus64: you don't know that!
18:36:14 <rwbarton> shachaf: yes, that's what I ended up doing
18:36:18 <rwbarton> seems to work
18:37:34 <shachaf> Hmm, are type variables in "expr :: type" scoped inside "expr"?
18:38:34 <rwbarton> I assumed that wouldn't work
18:38:44 <zuserm> Good evening.
18:38:51 <rwbarton> but if I tested it, I accidentally did so without ScopedTypeVariables
18:39:01 <shapr> oh hai zuserm
18:39:21 <jmcarthur> shachaf: they might be with ScopedTypeVariables. they probably aren't without
18:39:37 <shachaf> jmcarthur: I don't expect any type variables to be scoped without ScopedTypeVariables...
18:40:23 <shachaf> Looks like it works with the extension.
18:40:37 <zuserm> I have a program I'm trying to optimize, and I have two versions of a function. Is it normal that using one version is significantly better with profiling enables, and the other is significantly better with profiling disabled?
18:40:53 <shachaf> zuserm: I don't think that's very normal.
18:40:56 <shachaf> What are the functions?
18:41:13 <zuserm> I can hpaste them, one sec.
18:42:28 <shachaf> shachaf@carbon:~$ grep ghci .bash_history | wc -l
18:42:28 <shachaf> 514
18:42:47 <hpaste> zuserm pasted “mapOneToOne” at http://hpaste.org/75515
18:42:50 <shachaf> (The whole file is <2000 lines.)
18:43:31 <typoclass1> shachaf: y u no use xmonad shortcut to launch a terminal with ghci in it? mine is next to the shortcut to launch a terminal with a shell in it
18:44:09 <shachaf> typoclass1: Often it's ghci on a file...
18:44:17 <shachaf> Well, not *that* often, I guess. Maybe it's worth it.
18:44:29 <typoclass1> shachaf: ah i see. i do :l in those cases
18:46:07 <juliohm> Good night everyone! (or good morning, good afternoon, don't be so pedantic ;))
18:47:08 <shachaf> zuserm: And one of those is much faster with profiling, and the other is much faster without?
18:48:32 <zuserm> When I'm using mapOneToOne, my program goes 20% faster with profiling on, than with mapOneToOne'. With profiling off the swing is 16% the other way.
18:48:52 <danharaj> I wonder how much I should contribute to Parallella.
18:50:30 * typoclass1 wonders if zuserm should file a trac ticket for the ghc developers
18:51:25 <imeredith> if someone has time, please can you take a look at my L02 answers and see if ive done them the best way? https://github.com/hadashi/course/blob/master/src/L02/List.hs
18:51:27 <zuserm> I guess I should probably try it out on 7.6.1. I'm currently on 7.4.2
18:52:40 <imeredith> it compiles, but given that it is one of my first things in haskell i doubt its as good as can be :)
18:57:27 <typoclass1> imeredith: from skimming, it doesn't look half-bad to me :) congratulations
18:58:03 <imeredith> thanks
18:59:27 <typoclass1> imeredith: recall that ' is a valid character in function names, so if you find it a little goofy to have "fiilter" and that, you could do filter' instead. also, you can hide functions from prelude by doing "import Prelude hiding (filter, head, this, that)"
19:00:09 <imeredith> typoclass1: yeah, well this was something that dabblego had set of for examples, so all the naming is from him, but i was aware :)
19:01:13 <imeredith> if i have
19:01:15 <imeredith> data Parser a = P {
19:01:15 <imeredith>   parse :: String -> Maybe a
19:01:16 <imeredith> }
19:01:26 <imeredith> how do i construct  P ?
19:01:51 <imeredith> struggling to find syntax on that
19:01:52 <shachaf> With "P".
19:02:00 <rwbarton> P :: (String -> Maybe a) -> Parser a
19:02:12 <typoclass1> imeredith: normally by "P somefunction"
19:02:49 <imeredith> typoclass1: ah i was trying to do it inline, just found somthing they shows the use of an anonymous fn when used inline
19:03:20 <zuserm> ex: parseDigi = P (\(c:cs) -> if isDigit c then Just (read "c" :: Int) else Nothing
19:03:33 <imeredith> shachaf: yeah I got the P part, it was just how to define the fn heh
19:03:40 <zuserm> whoops, [c]
19:04:35 <shachaf> imeredith: The same way you always define things.
19:05:46 <typoclass1> imeredith: you can use the anonymous "\... -> ..." pretty much anywhere you can use a function name ("map succ ..." vs. "map (\... -> ...) ..."). you often need parens around it.
19:06:00 <shachaf> It doesn't have to be anonymous.
19:06:24 <shachaf> But this is probably a part of Haskell you should have a pretty good grasp on before defining "data Parser".
19:06:41 <Jafet> Clandestine functions
19:08:56 <zuserm> How do I get two version of GHC to play nice together?
19:09:06 <rwbarton> there isn't a way to say "class C t where type M t a; {- M t is a Monad for every a -}" is there?
19:09:14 <rwbarton> *for every t
19:10:35 <shachaf> You mean provide a Monad instance?
19:10:54 <rwbarton> no, I want to require that in any instance t of C, M t is a monad
19:11:05 <rwbarton> or maybe that's a yes
19:11:18 <rwbarton> wait
19:11:25 <shachaf> Oh.
19:11:27 <rwbarton> this is not an example
19:11:36 <rwbarton> ugh
19:11:46 <rwbarton> "class C t where type M t a :: * -> *; {- M t a is a Monad for every a -}"
19:12:19 <rwbarton> the other one I can do, class (Monad (M t)) => C t where type M t a
19:12:58 <shachaf> Ah. I don't know.
19:17:37 <rwbarton> nwf: I don't know how helpful this is but I convinced myself that GHC's error messages are correct
19:17:53 <Jafet> zuserm: "let not thy left hand know what thy right hand doeth"
19:17:56 <nwf> rwbarton: I believe they are, too; that's the unhappy part. :)
19:18:12 <zuserm> the answer was that I needed to cabal update
19:18:19 <shachaf> hi nwf
19:18:40 <nwf> I believe that if I could peruade GHC that the domain of quantification was not kind * but the subkind "Tuples", it would work fine.
19:18:44 <nwf> shachaf: Y EHLO THAR
19:21:36 <rwbarton> is there a standard Product/Tuple type constructor :: [*] -> * in the ConstraintKinds world?
19:21:54 <nwf> Not as far as I know
19:22:03 <nwf> TemplateHaskell has such a thing
19:22:18 <rwbarton> seems like something that really ought to exist
19:22:24 <rwbarton> I mean it's easy enough to write one
19:22:27 <rwbarton> but it should be standardized
19:23:02 <nwf> I think DataKinds only went as far as promoting '(,) and friends.
19:23:49 <shachaf> nwf: What are you trying to do?
19:24:20 <nwf> shachaf: be polymorphic in tuple length for my EDSL.
19:24:33 <nwf> Here's my current stab at it: http://hpaste.org/75513
19:25:36 <nwf> I think that I cannot get what I want, and so will have (possibly TH-produced) wads of code where "tuple2" "tuple3" and so on have identical definitions.
19:25:37 <shachaf> Polymorphism in tuple length sounds worrying.
19:26:19 <nwf> shachaf: Well, in particular, I want to be able to take (r a, ..., r z) -> r (a, ..., z), where r is my EDSL type constructor.
19:27:46 <nwf> (Though sometimes, like for pretty-printing, I need the also-easy-to-define "(forall a . r a -> xx) -> (r a, ..., r z) -> [xx]")
19:28:05 <nwf> (Well, want; not need, I suppose.)
19:28:08 <rwbarton> is this Univ thing the same as data Univ where Base :: Int -> Univ Int; Recombine :: TupleAll Univ ty sty => sty -> Univ ty
19:28:39 <rwbarton> just trying to think about how you could produce Univ values
19:29:31 <nwf> rwbarton: I tend to produce them on the command line as "base 3 :: Univ Int" or similar, FWIW?
19:30:44 <nwf> I hadn't thought to give the universal an initial encoding as well as the class...
19:32:41 <Puffton> Is there an easy way to make a set containing a string "hello"? ideally something like { "hello" } rather than S.fromList ["hello"]
19:33:12 <shachaf> S.singleton "hello"
19:33:39 <Puffton> ah, very nice
19:33:40 <Puffton> thanks
19:34:14 <mikeplus64> Puffton: if there is a set monad, you may be able to use return "hello" as well (but singleton "hello" is probably more helpful to someone reading it)
19:34:31 <shachaf> There is no such Monad instance.
19:35:13 <latro`a> sets form a monad; Sets don't, because of the Ord constraint
19:35:45 <shachaf> (a -> Bool) is also not a Monad.
19:35:50 <shachaf> s/a//
19:36:34 <Puffton> mikeplus64, I was using it in the context someSet `S.union` S.fromList [element]
19:36:51 <Puffton> in which case I think S.singleton element looks a lot better
19:36:55 <Puffton> than what I had before :)
19:37:03 <shachaf> S.insert?
19:37:04 <rwbarton> S.insert element someSet
19:37:06 <zuserm> woo, GHC 7.6.1 gives me a 3.5x performance regression
19:37:08 <smartviking> I'm reading LYAH and in it it says "One big difference between the two types of folds is that right folds work on infinite lists, whereas left ones don't!". How is that possible? What I'm thinking is that infinite lists don't have a rightmost element which means foldr wouldn't work either, what am I missing?
19:37:26 <shachaf> > foldr f z [a,b,c,d]
19:37:27 <lambdabot>   f a (f b (f c (f d z)))
19:37:28 <shachaf> > foldl f z [a,b,c,d]
19:37:29 <lambdabot>   f (f (f (f z a) b) c) d
19:37:37 <shachaf> smartviking: Think about what happens there with an infinite list.
19:37:42 <nwf> rwbarton: And, tragically, while the initial form of the universal does admit a class construction, it does not admit an interpreter -- attempting to write "iui :: (Lang r) => UnivI a -> r a
19:37:53 <jmcarthur> shachaf: i now believe that that F# threadring implementation is breaking the rules
19:37:54 <nwf> " yields identical errors in the recombine case.
19:38:03 <shachaf> jmcarthur: I do too.
19:38:14 <shachaf> jmcarthur: And I'm suspicious of the Haskell implementation too.
19:38:37 <smartviking> shachaf: Ok I'll think about it
19:38:51 <latro`a> smartviking, consider:
19:38:52 <mikeplus64> zuserm: wrt what?
19:39:00 <latro`a> > foldr (const 1) 2 [3..]
19:39:01 <lambdabot>   1
19:39:01 <Puffton> I think I will stick with the words for now (union, difference etc.)
19:39:11 <shachaf> Note that the GHC code is a good deal slower with -threaded on a multicore machine.
19:39:11 <latro`a> now expand it out and see why that should be the case
19:39:14 <Puffton> it makes it easier to follow (I'm implementing an algorithm from a mathematical definition)
19:39:32 <Puffton> so I can pretty much read it just like I read the mathematical implementation
19:39:34 <jmcarthur> shachaf: it's slower with -threaded due to the parallel gc, i'm pretty sure
19:39:46 <jmcarthur> i have never seen the parallel gc give an improvement
19:39:55 <shachaf> jmcarthur: I assume it's due to communication overhead between cores and such.
19:40:03 <shachaf> Given that only one thread is ever running at a time and all.
19:40:10 <shachaf> This is really a terrible benchmark of concurrency...
19:40:16 <jmcarthur> shachaf: no, in fact, forkOnIO prevents the threads from running on different capabilities
19:40:52 <shachaf> jmcarthur: Oh, hmm.
19:41:14 <shachaf> That's even sillier, then.
19:41:44 <jmcarthur> shachaf: i got a reasonable improvement by adding a line to set the capabilities to 1 at the beginning of the program (which just has the effect of not parallelizing the gc)
19:42:07 <zuserm> mikeplus64: true story
19:45:12 <jmcarthur> shachaf: anyway, the F# code is basically doing what in haskell would be an array of IO actions where each one indexes the next one to run
19:47:43 <rwbarton> a mutable global token?
19:48:29 <rwbarton> isn't it a stretch to interpret "pass a token from thread to thread N times" that way?
19:52:23 <rwbarton> what does return! do anyways
19:54:46 <jmcarthur> i think it's basically an async tail call. "my result is the result of this next action"
19:54:58 <rwbarton> and is there no way to pass an argument to that action?
19:55:24 <jmcarthur> sure there is
19:55:28 <jmcarthur> i think it's basically just an IO action
19:55:56 <jmcarthur> it is in fact an IO action that is looked up from an array
19:56:09 <rwbarton> oh, so it should be (Int -> Async<unit>)[] or something
19:56:25 <rwbarton> I mean if it was passing the token as an argument to a function it would be at least a little more respectable
19:56:25 <jmcarthur> not sure i follow
19:56:59 <rwbarton> trying to claim that a mutable global variable is a "token passed from thread to thread" is a little over the top
19:57:00 <jmcarthur> i don't think there's anything wrong with the one mutable global variable. i think the problem is that it's cooperative concurrency, not preemptive
19:57:59 <jmcarthur> i think the global may be justifiable because only one "thread" runs at a time anyway
19:58:34 <jmcarthur> eh, i take that back
19:59:04 <jmcarthur> "create 503 linked pre-emptive threads" is violated, and so is "pass a token"
20:02:20 <shachaf> It's a silly benchmark.
20:02:26 <ddarius> They are all silly benchmarks.
20:02:48 <shachaf> Some are sillier than others.
20:02:51 <rwbarton> yeah
20:02:51 <ddarius> True.
20:02:57 <zuserm> my profiling peculiarity is still there in 7.6, but it's not as pronounced, probably because 7.6 murders my program
20:03:03 <smartviking> shachaf: I still don't get it, because foldr will never reach the last element
20:03:30 <mikeplus64> shachaf: ddarius: where are these silly benchmarks? :)
20:03:35 <ddarius> smartviking: Use the definitions of foldr and foldl and reduce them by hand using normal order evaluation (call-by-name).
20:04:11 <smartviking> ddarius: Where are the definitions?
20:04:18 <ddarius> @src foldr
20:04:18 <lambdabot> foldr f z []     = z
20:04:18 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
20:04:20 <ddarius> @src foldl
20:04:20 <lambdabot> foldl f z []     = z
20:04:20 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
20:04:27 <rwbarton> stuff like pidigits is less silly because the program actually computes something nontrivial, but pidigits in particular is pretty silly since it just benchmarks the large integer library your language environment comes with
20:05:57 <jmcarthur> all the shootout benchmarks are silly, really
20:06:14 <shachaf> @where pi
20:06:14 <lambdabot> I know nothing about pi.
20:06:16 <shachaf> @where pi_10
20:06:17 <lambdabot> (!!3)<$>transpose[show$foldr(\k a->2*10^2^n+a*k`div`(2*k+1))0[1..2^n]|n<-[0..]]
20:06:26 <shachaf> There should be a golf shootout.
20:06:36 <smartviking> ddarius: Ok I'll do that. I think it the exact part where I got stuck last time I read LYAH a year ago or so
20:06:36 <mikeplus64> lies, damned lies and benchmarks?
20:07:10 <mikeplus64> > transpose[show$foldr(\k a->2*10^2^n+a*k`div`(2*k+1))0[1..2^n]|n<-[0..]]
20:07:14 <lambdabot>   mueval-core: Time limit exceeded
20:07:24 <ddarius> smartviking: Learning how to execute Haskell by hand is crucial and will allow you to answer a lot of these questions in the future as well as understand what is actually happening for, e.g. performance purposes.
20:07:35 <smartviking> s/k\ it/this\ is/
20:07:36 <mikeplus64> :t transpose[show$foldr(\k a->2*10^2^n+a*k`div`(2*k+1))0[1..2^n]|n<-[0..]]
20:07:38 <lambdabot> [[Char]]
20:08:03 <mikeplus64> > transpose[show$foldr(\k a->2*10^2^n+a*k`div`(2*k+1))0[1..2^n]|n<-[0..]] !! 3
20:08:06 <lambdabot>   mueval-core: Time limit exceeded
20:08:14 <jmcarthur> i was thinking it would be nice to have a slightly more realistic shootout, which somewhat larger programs. for example, fully featured implementations of wc
20:08:19 <jmcarthur> *with somewhat
20:09:49 * ddarius is not sure why Firefox's bookmarks drop-down is so horrible.
20:15:01 * hackagebot gentlemark 1.0.0 - Gentle markup language  http://hackage.haskell.org/package/gentlemark-1.0.0 (AndriyPolishchuk)
20:15:03 * hackagebot cmaes 0.1.1 - CMA-ES wrapper in Haskell  http://hackage.haskell.org/package/cmaes-0.1.1 (TakayukiMuranushi)
20:20:25 <edwardk> preflex: xseen alanz
20:20:25 <preflex>  alanz was last seen on freenode/#haskell 6 hours, 29 minutes and 14 seconds ago, saying: I don't have enough knowledge for that yet
20:35:01 * hackagebot lojbanParser 0.1.3 - lojban parser  http://hackage.haskell.org/package/lojbanParser-0.1.3 (YoshikuniJujo)
20:36:33 <djahandarie> Oh nice, Lojban + Haskell
20:36:40 * Polarina likes Lojban.
20:39:39 <donri> ui mi selcme lo jbovla
20:41:41 <shapr> donri: mi'e capr .i mi djica lenu mi gunka
20:42:24 <geisthaus> que
20:42:24 * bos reinvents duff's device using continuations
20:42:42 <geisthaus> is lojban potentially useful for anything?
20:43:00 <sheriff_> geisthaus: Keeping linguists from doing anything truly reprehensible with their time
20:43:06 <hpaste> bos pasted “whee” at http://hpaste.org/75516
20:43:33 <bos> geisthaus: it's one of the most powerful prophylactics known
20:43:58 <sheriff_> bos: That looks more like Church Numerals to me
20:44:22 <bos> sheriff_: it's hard to get a good translation, alas
20:46:26 <bos> sheriff_: nevertheless, this compiles down to branch-free code
20:47:16 <mm_freak_> are there any RULE-based optimizations on Maybe or Either in the base library?
20:47:31 <mm_freak_> relatedly is there a strict Either somewhere?
20:48:12 <gwern> @quote either
20:48:12 <lambdabot> jack-nicholson says: You only lie to two people in your life, Linux fanboys and the police. Neither can handle the truth.
20:48:36 <mm_freak_> @quote maybe
20:48:36 <lambdabot> Twey says: Maybe Bool: the Haskell equivalent to True/False/FileNotFound
20:50:02 * hackagebot vty-ui 1.5.1 - An interactive terminal user interface library for Vty  http://hackage.haskell.org/package/vty-ui-1.5.1 (JonathanDaugherty)
20:50:26 <ddarius> I don't think there are, but there are a bunch of random things.  It doesn't seem worthwhile to do though.  Normal compiler optimizations should catch most cases.
20:50:55 <ddarius> mm_freak_: There's probably a strict Either somewhere, but you probably don't want to pull in the dependency just for that.
20:51:43 <lpvb> smartviking: The 'r' and 'l' in folds doesn't indicate the starting position of a fold, it indicates the direction
20:51:56 <lpvb> foldr really starts at the left and goes right
20:53:57 <lpvb> foldl starts at the right and goes left, that's why it doesn't work on infinite lists
20:55:10 <mm_freak_> ddarius: that's my impression…  thanks
20:55:44 <Nereid> exercise: implement foldl using foldr
20:56:47 <ddarius> Both foldr and foldl "start" at the left.  That's just how lists are arranged.
20:58:45 <latro`a> ehh...
20:58:47 <latro`a> if f is strict
20:58:58 <latro`a> then I *think* foldr is actually the same as foldl on a reversed list
21:00:14 <ddarius> > foldr (flip f) z $ reverse [a,b,c]
21:00:16 <lambdabot>   f (f (f z a) b) c
21:00:20 <ddarius> > foldl f z [a,b,c]
21:00:21 <lambdabot>   f (f (f z a) b) c
21:00:45 <Nereid> latro`a: nope
21:00:57 <Nereid> yeah you have to fliip f I guess.
21:00:58 <latro`a> are you sure?
21:01:01 <latro`a> yeah
21:01:03 <latro`a> that's what I meant
21:01:10 <latro`a> well
21:01:10 <latro`a> no
21:01:19 <latro`a> because you are working on the rightmost two, in order
21:01:31 <latro`a> where the actual rightmost is the initial value
21:01:37 <latro`a> then you move left
21:01:56 <latro`a> anyway yeah, if f is strict this is accurate, I'm fairly sure
21:02:17 <ddarius> latro`a: No need to guess.
21:02:26 <ddarius> > foldl (flip f) z $ reverse [a,b,c]
21:02:28 <lambdabot>   f a (f b (f c z))
21:02:32 <ddarius> > foldr f z [a,b,c]
21:02:33 <lambdabot>   f a (f b (f c z))
21:02:43 <latro`a> ah
21:02:43 <latro`a> k
21:02:51 <latro`a> then yeah, with flipping+strictness they are the same
21:03:18 <latro`a> so "foldr starts at the right" is only deceptive if f isn't strict
21:03:41 <latro`a> eh...deceptive of return semantics, not operational semantics
21:03:45 <latro`a> it's always deceptive of operational semantics
21:03:53 <ddarius> I don't think it's particularly useful to think of them as "proceeding" a particular direction.
21:04:32 <latro`a> foldl definitely "proceeds" left to right
21:04:34 <ddarius> If I cared to give meaning to the l and r, I would simply say that foldr produces a right associated value and foldl a left.
21:04:44 <ddarius> They both definitely proceed left to right.
21:05:01 <latro`a> but with foldr, in the presence of strictness, you have an ambiguity depending on how you focus
21:05:25 <latro`a> because with strictness you *could* write it as proceeding right to left
21:05:48 <latro`a> i.e. there's a function which operationally proceeds right to left and has the same semantics as foldr, assuming the function argument is strict
21:05:58 <latro`a> *return semantics
21:06:09 <ddarius> What are "return semantics"?
21:06:09 <latro`a> we don't use it because it's slower
21:06:12 <latro`a> but it exists
21:06:19 <cmccann> lists proceed left to right. folds don't have much say in the matter.
21:06:21 <latro`a> evaluation semantics might be clearer
21:06:34 <cmccann> short of reversing the list first, implicitly or otherwise.
21:06:39 <latro`a> denotational semantics is probably a different term
21:06:40 <ddarius> latro`a: I think(?) you want "operational semantics" or something.
21:06:43 <latro`a> no
21:06:47 <latro`a> that's the term I'm actively avoiding
21:07:00 <latro`a> because the operational semantics of those two are different
21:07:41 <lpvb> the evaluation for foldl still proceeds from right to left, no?
21:07:50 <ddarius> Okay, I mixed what you were referring to up.  So you want "denotational semantics"?
21:08:05 <latro`a> I think so, yeah, though that gets used in type theory too -_-
21:08:21 <latro`a> they are equal in the sense that they return the same value given the same input
21:08:25 <mm_freak_> lpvb: from outer to inner (foldl) or from inner to outer (foldl')
21:08:27 <latro`a> even though the procedure by which they do so is different
21:08:39 <lpvb> lazy foldl
21:08:41 <mm_freak_> lpvb: ((a + b) + c) + d
21:08:52 <ddarius> latro`a: Another possibility is "observational behavior".
21:09:20 <latro`a> that's a good one
21:09:22 <latro`a> (no sarcasm)
21:09:35 * ddarius thinks he'll use "observationally equal" more than he already does because there's nothing about operational and denotational semantics that requires one to be lower or higher level or more or less discriminating.
21:09:51 <mm_freak_> lpvb: the direction is orthogonal to the way you read the expression
21:10:04 <mm_freak_> so "left to right"/"right to left" don't really make sense
21:10:37 <ddarius> Operational semantics just have a natural notion of "step" whereas denotational semantics typically does not.
21:10:50 <mm_freak_> it's just that foldr has a different idea of "inner" than foldl, and for both evaluation can happen in both directions depending on the strictness of your fold
21:12:05 <ddarius> Though, a denotational semantics is a fold over the syntax and you could say the algebra for that fold specifies a notion of step.
21:12:21 <Polarina> mm_freak_, I saw a mail from on haskell-beginners about not sending in multiple SDL events at once. What would you recommend I do when I want my wire to run with a constant delta of 1/20 rather than "whenever"? I have my timedeltas fixed to get my physics calculations be more predictable and consistent.
21:13:35 <mm_freak_> Polarina: use counterSession
21:13:54 <mm_freak_> (instead of clockSession)
21:14:10 * Polarina is using stepWire directly.
21:14:24 <mm_freak_> in that case just pass 1/20 as dt
21:15:01 <Polarina> I already have my deltas fixed. I currently collect events into a list and have that as a wire input. You suggested to do otherwise. Just wanted to know how I could do that in my situation.
21:15:16 <mm_freak_> if your wire is actually stepped at 20 times per second, then that should even be close to real time, but you can make simulations using your own clock…  there is no need to adhere to real time
21:15:37 <mm_freak_> in that case that's more difficult
21:15:50 <mm_freak_> my initial suggestion would be to step the wire as many times as there are events
21:16:10 <mm_freak_> (netwire can deal with dt = 0, btw)
21:16:17 <Polarina> Hmm...
21:16:44 <Polarina> I hadn't thought of that.
21:17:27 <mm_freak_> yeah…  the only possible implication i see here is that you might get some NaNs or Infinities if you use avgFps
21:17:35 <mm_freak_> but you won't need that wire anyway, if your FPS is fixed =)
21:17:47 <Polarina> I got a separate wire for rendering. :)
21:18:00 <mm_freak_> ah =)
21:18:20 <Polarina> I collect all the state iinto a data GameOutput. Then pass that to the renderer.
21:18:30 <mm_freak_> i see
21:18:36 <mm_freak_> what's the use of the wire for rendering then?
21:19:18 <Polarina> mm_freak_, mostly executing OpenGL calls. I use it as well to track shader, textures, state, etc.
21:19:20 <cmccann> mm_freak_, so what would it take to convince you to finally register a proper user account on Stack Overflow? >:[
21:19:51 <Polarina> I wouldn't want to upload the same texture on each frame. :)
21:19:57 <mm_freak_> Polarina: i mean, why is your rendering itself reactive?  just to save some typing or are you doing something clever there?
21:20:04 <cmccann> rather than having a bunch of interesting answers distributed among 15 different unregistered accounts. :P
21:20:23 <mm_freak_> cmccann: let me quote a mail i wrote to someone who has asked me the same question =)
21:21:31 <Polarina> mm_freak_, nothing clever really. Just tracking OpenGL resources.
21:21:44 <Polarina> I find wires to be better that a state monad.
21:21:58 <hpaste> “Ertugrul Söylemez” pasted “Why I don't register on StackOverflow” at http://hpaste.org/75518
21:22:00 <geisthaus> wires??
21:22:20 <mm_freak_> Polarina: yeah, that's true
21:22:26 <mm_freak_> geisthaus: see the netwire library
21:22:40 <Polarina> geisthaus, http://hackage.haskell.org/package/netwire
21:22:49 <mm_freak_> geisthaus: darcs get http://darcs.ertes.de/netwire/
21:22:58 * Polarina was just going to link that. :)
21:23:01 <mm_freak_> hehe
21:23:14 <mm_freak_> hackage still has netwire 3, because i want to finish the manager wire before release
21:24:47 * shapr hugs johnw 
21:25:23 <cmccann> mm_freak_, a reasonable position, with which I sympathize (somewhat. as you can tell from my own total "reputation"...)
21:26:09 <johnw> hey shapr!
21:26:12 <johnw> how's it going?
21:26:32 <Polarina> mm_freak_, out of curiosity, will the manager wire be anything similar to the one in netwire 1? That is, MgrAdd and friends, or will the wire user have control over the set of wires?
21:27:01 <shapr> johnw: Life is good, I'm trying to figure out how to use hledger.query to project my expenses for the next month.
21:27:02 <cmccann> mm_freak_, it's just that it's sort of annoying not having all your answers connected to a single account. I often look through answers on a user's profile page if it's someone who I think has an interesting perspective for some reason
21:27:20 <cmccann> so it sort of does reduce the value to the Haskell community as a whole, even if only slightly
21:27:53 <johnw> shapr: I'm working on my gitlib project
21:27:55 <shapr> Er, could someone else try to cabal install lojbanParser? My ghc 7.6.1 has been trying to compile the tests for the past five minutes.
21:28:13 * shapr looks at the sources
21:28:15 <johnw> i'm waiting on 7.6.1 until the next cabal-install comes out
21:28:19 <cmccann> I've flagged a few examples of duplicate accounts for moderator merging specifically for that reason.
21:28:24 <johnw> and hsenv isn't working for me for whatever reason
21:29:03 <cmccann> particularly conor mcbride, who had two or three older accounts floating around.
21:29:19 <shapr> Wow, lojbanParser takes eight minutes to build, and most of it is in Test.Pappy, what the heck?
21:30:23 <mm_freak_> cmccann: yeah, but still i'm not going to register
21:30:29 <shapr> Oh, no wonder it takes eight minutes to build.
21:30:34 <mm_freak_> Polarina: similar, but more powerful
21:30:36 <johnw> why?
21:30:47 <Polarina> mm_freak_, looking forward to see that. :)
21:30:55 <cmccann> mm_freak_, fair enough. just wanted to register my dissatisfaction on the subject. :P
21:31:01 <shachaf> mm_freak_: You should join #haskell-blah, too!
21:31:29 <mm_freak_> Polarina: or let me call it flexible…  in particular it will give you the ability to disconnect the wire collection management from the actual signal processing
21:31:55 <johnw> is there a ghc flag to turn *off* profiling?
21:32:20 <mm_freak_> cmccann: i understand your dissatisfaction…  sorry for that =)
21:32:21 <shapr> TestPappy.pappy is 3000 lines of parser generator code?
21:32:23 <mm_freak_> shachaf: why?
21:32:38 <shachaf> mm_freak_: So people can blahther at you.
21:32:42 <shapr> Wow, this is an epic module.
21:33:37 <mm_freak_> shachaf: i don't mind people /querying me =)
21:34:51 <Polarina> I somehow prefer to poke people in channels rather than /querying them.
21:35:08 <mm_freak_> feel free =)
21:35:24 <Polarina> I'll do that next time then. :)
21:38:49 * Polarina has this shiny wire now :: Wire () (Kleisli Implvz) PhysicalInput (GameOutput, [PhysicalOutput])
21:40:26 <mm_freak_> Polarina: you're lucky i renamed 'now' to 'once' =P
21:41:12 * Ralith had a shiny wire once
21:41:54 <Polarina> mm_freak_, what happened to 'once' then?
21:42:34 <mm_freak_> Polarina: Control.Wire.Prefab.Event.once is the event that happens once immediately and then never again
21:43:12 <Polarina> I saw that. :)
21:43:23 <mm_freak_> yampa calls it 'now'
21:44:49 <Polarina> Ah. I hadn't used Yampa much. I was starting to begin to look seriously into it, then saw the netwire-1.0.0 announcement on the mailing list. I lost it there.
21:45:06 <mm_freak_> =)
21:45:27 <shapr> Huh, so lojbanParser includes its own PackRat parser, and it uses that to turn 8000 lines of a lojban grammar mixed with inline Haskell into some sort of binary. Compilation takes about eight minutes on my dual-core Athlon with 6GB of RAM.
21:46:02 <latermuse> What do you guys feel about the current research of compiling haskell to javascript?
21:46:03 <ddarius> shapr: If only you had your Cells handy.
21:46:11 <shapr> ddarius: They're here, just not plugged in :-P
21:46:17 <Polarina> shapr, lojban's grammar is so simple, yet so complex at the same time. :)
21:46:24 <mm_freak_> latermuse: you can pretty much summarize it as "look into UHC and GHCJS"
21:46:34 <shapr> Wow, it produces a 25MB library in ~/.cabal/lib
21:46:49 <johnw> if I pass --enable-executable-profiling to Cabal, can I tell it to *not* generate executable profiling for one of my tests?
21:47:15 <latermuse> mm_freak: Do you think its going to be an area that will exponentially gain popularity?
21:47:49 <shapr> mm_freak_: Have you seen the results of the haste compiler? http://jshaskell.blogspot.de/2012/09/breakout.html
21:47:52 <mm_freak_> latermuse: it gets a lot of attention, so intuitively i'd say yes
21:47:54 <Polarina> latermuse, I say it has a lot of potential. What'll exactly happens, I have no idea.
21:48:08 <mm_freak_> shapr: oh yeah, i forgot haste
21:48:12 <shapr> latermuse: Have you see haste compiling a breakout game to JavaScript? http://jshaskell.blogspot.de/2012/09/breakout.html
21:49:07 <latermuse> with html5 on the horizon and javascript's stranglehold on the browser, I feel it would be good if more people become interested in haskell by writing code with the purpose of compiling to javascript and deploying to the web
21:49:29 <latermuse> shapr: ive seen it. it looks very interesting
21:50:04 <pnielsen> latermuse: check out Fay
21:50:59 <bos> ooh, my SipHash implementation is 9x to 63x faster than the siphash package. booyah!
21:51:02 <latermuse> pnielsen: thanks, i hadnt seen that yet
21:51:09 <pnielsen> latermuse: http://fay-lang.org/
21:51:11 <Polarina> latermuse, I've always liked the idea of compiling/translating one language into another. The end result is that when it comes to debugging / profiling, one has to know both environments well, in this case, Haskell and Javascript.
21:51:13 <pnielsen> it's pretty cool
21:51:14 <ddarius> @hackage siphash
21:51:15 <lambdabot> http://hackage.haskell.org/package/siphash
21:51:43 <Polarina> latermuse, I don't think it will ever happen that someone can "program" javascript only knowing haskell.
21:52:05 <Polarina> Which makes the barrier of entry a bit higher.
21:52:24 <pnielsen> Polarina: I'm already doing so with Fay
21:52:24 <pnielsen> its support is far from comprehensive, but totally usable
21:52:27 <Polarina> It's like database ORMs. Oh, the nightmares working with those...
21:53:23 <pnielsen> agree about ORMs. Kind of agree about transcompiling to JS -- can be a pain to debug
21:53:44 <mm_freak_> Polarina: i think it's very well possible for that to happen…  you can program haxe and compile to javascript without knowing javascript
21:53:57 <mm_freak_> but you need to understand its surroundings like the DOM
21:55:26 <pnielsen> CoffeeScript apparently has its own "debugger" now, although I have very little experience with it
21:56:03 <pnielsen> what makes ORMs stand out, IMO, is that they life such of a pain at scale that you might as well just throw them out
21:56:04 <Polarina> mm_freak_, not saying that it isn't possible. It's just, from what I've seen, usually not so pretty when it comes to something more complex than simple examples.
21:56:06 <ddarius> bos: I don't think you are competing against a terribly optimized example, though it is interesting that there is that much slack.  There seem like a few things wrong, and maybe some crucial things I didn't notice, but those don't seem to be 63x differences.
21:56:13 <hamishmack> You can run webkitgtk DOM apps in ghci then compile them with ghcjs
21:56:18 <ddarius> bos: Some loop unrolling and such, though, could easily add a lot of performance.
21:57:14 <bos> ddarius: sure, i'm certain that implementation could be improved
21:57:40 <ddarius> bos: Clearly.  You've done so.
21:57:46 <ddarius> bos: I'm curious what you did differently.
21:58:13 <bos> ddarius: i use CPS extensively, and i examined the generated Core minutely at every step
21:59:06 <bos> ddarius: so in my code, there are no boxed values, and very few branches
21:59:46 <bos> ddarius: https://github.com/bos/hashable/blob/sip/Data/Hashable/SipHash.hs
22:00:09 <bos> also, i do big fat reads when i ca
22:00:10 <bos> can
22:02:25 <ddarius> bos: How do you compare against straightforward C and unrolled C?
22:03:04 <bos> ddarius: haven't tried those yet. there are C implementations that use SSE4.1 - which i'd expect to be rather faster.
22:03:35 <cmccann> ddarius, do you know of anything written about inherent (non-)strictness for linear logic connectives? I seem to recall reading something but don't remember clearly.
22:03:40 <bos> compiling via -fllvm gives an extra 35% speed boost
22:04:20 <cmccann> it seems to me (based on my own implementation, at least) that either strictness or non-strictness is required based on polarity
22:05:29 <cmccann> well, maybe not outright required, but strongly suggested at least
22:05:47 <ddarius> cmccann: I can't think of a reference off the top of my head, but I also vaguely remember things like that.  Clearly some aspects bias things one way or the other based on polarity.  E.g. with a(x)b, there's no value in not evaluating b, say, because you will always have to use both.
22:05:58 <Cale> bos: I love how there are just these specifically applied bang patterns :)
22:06:14 <ddarius> Cale: In sipRound?
22:06:17 <Cale> yeah
22:06:36 <bos> Cale: i think i've found a way to get rid of them
22:06:48 <ddarius> Yeah.  I was wondering if that made a difference (i.e. having a different pattern led to a slower program.)
22:06:52 <ddarius> I wouldn't expect it to.
22:07:03 <Cale> (They're just on the things going into the application of k, I realise, it just looks a bit crazy at first)
22:07:07 <bos> it does, because GHC doesn't notice enough strictness
22:07:12 <cmccann> ddarius, right--if the tensor connective is forced, there's no reason not to force the two components. likewise for plus, I think.
22:07:39 <cmccann> whereas with and par seem to possibly require a degree of non-strictness to make sense
22:07:47 <ddarius> bos: What if you put ! on all though?
22:08:01 <bos> ddarius: why bother?
22:08:26 <ddarius> bos: Because then you don't have to think.  I mean now there's no point, but in the beginning you could have just slapped ! on everything in that function.
22:08:45 <bos> i kind of hate slapdash bang patterns
22:08:51 <ddarius> Me too.
22:09:02 <ddarius> But when it's a sequence of calculations, it seems fine.
22:09:25 <ddarius> For my Kalman filter code, all the (flat) intermediates are banged.
22:09:38 <Cale> In my head, there's a small cost to applying seq to an already-evaluated term which I realise is probably not actually there
22:09:56 <ddarius> Cale: There is, but presumably GHC would see it as superfluous in this case.
22:12:26 <Cale> Those bang patterns are also interesting, in that they would do nothing if my preferred translation of the sugar were used.
22:12:38 <johnw> edwardk: can I make my own set of functions into lenses for a given record type?
22:13:02 <johnw> i mean, i'll have record fields, but then I also want "virtual fields" that can be accessed via getter/setters of their own
22:13:04 <edwardk> johnw: you can do anything you want =P
22:13:07 <johnw> haha
22:13:14 <edwardk> johnw: but yes, that works fine
22:13:33 <cmccann> you can do anything at zombo.com
22:13:33 <johnw> do I just make a SimpleLens (a -> b) (a -> b -> c)
22:13:34 <johnw> ?
22:14:04 <edwardk> you mean something like: SimpleLens (a,b,c) (a,b)   ?
22:14:06 * ddarius can't believe zombo.com is still there.
22:14:14 <cmccann> it's a classic.
22:14:25 <Cale> the only limit is yourself
22:14:31 <cmccann> kinda like time cube.
22:14:56 <ddarius> cmccann: Time cube is powered by crankery.
22:14:58 <cmccann> the internet just wouldn't be the same without zombo.com
22:15:03 * hackagebot hsshellscript 3.3.0 - Haskell for Unix shell scripting tasks  http://hackage.haskell.org/package/hsshellscript-3.3.0 (VolkerWysk)
22:15:05 * hackagebot gluturtle 0.0.6 - turtle like LOGO with glut  http://hackage.haskell.org/package/gluturtle-0.0.6 (YoshikuniJujo)
22:15:46 <Cale> So hang on, does this mean zombo.com is actually more successful than many of the businesses it was designed as a mockery of?
22:15:48 <ddarius> cmccann: Maybe in 20 years your children will find zombo.com and it will have a popularity rebirth.
22:15:56 <cmccann> ddarius, yes and zombo.com is basically a parody of bullshit advertising. the only real difference is that the time cube guy is sincere about it.
22:15:59 <ddarius> Cale: Well, it's still here...
22:16:03 <Cale> indeed!
22:16:50 <Cale> johnw: You can generally just apply 'lens' to whatever getter and setter you want, and if it typechecks, it ought to work :)
22:17:03 <johnw> what do you mean by "just apply 'lens'"?
22:17:17 <edwardk> johnw: there is a combinator named lens that takes the getter and setter directly
22:17:21 <Cale> lens :: Functor f => (a -> c) -> (a -> d -> b) -> (c -> f d) -> a -> f b
22:17:36 <edwardk> its not as efficient as doing it yourself, but its pretty easy
22:19:54 <Cale> edwardk: So it's intuitively "obvious" that every lens satisfying the laws is in the range of 'lens', but has anyone attempted a proof? (e.g. by showing that lens (view l) (set l) = l?)
22:20:32 <edwardk> maybe roconnor has, not sure'
22:21:00 <edwardk> shouldn't be hard, you have the strength to lift it
22:22:18 <Cale> Also, I noticed that you have the traversal laws listed for lenses, in addition to the three lens laws. Are there implications in either direction?
22:22:59 <edwardk> i believe that the traversal laws plus the laws of a getter + parametricity imply the traditional lens laws
22:23:57 <edwardk> and the traditional lens laws should give you the traversal laws
22:24:24 <johnw> Cale: excellent, thank you
22:25:59 <Cale> edwardk: I haven't managed to find any mathematicians yet who have seen anything of this shape before. (Though one of my friends who I thought would be likely if anyone has, hasn't got back to me yet.)
22:29:21 <Cale> It just seems so tantalising that the definition is expressible in nearly any category (you need constant maps to define 'set' though)
22:30:02 <jfischoff> what are the optimizations that GHC cannot make with polymorphic datatypes? Is it that it cannot create unboxed versions? I can't remember...
22:30:37 <Cale> jfischoff: Well, that's almost certainly true. Boxing is necessary for polymorphism to work.
22:31:14 <jfischoff> how about inlining?
22:31:28 <bos> inlining with polymorphic types generally helps
22:31:45 <edwardk> heya bos
22:31:49 <bos> though it's not guaranteed to
22:31:52 <bos> yo edwardk
22:32:07 <Cale> There are things like unboxing strict fields which obviously are meaningless if the fields are polymorphic.
22:32:47 <jfischoff> Cale: these things are less obvious to me :)
22:32:49 <mikeplus64> it would be very neat if GHC were able to optimize polymorphic types that are given unboxable types, so you don't have to create a specialised type e.g. IntMap
22:33:10 <bos> that is known to be a lot of work
22:33:48 <edwardk> bos: i had a question. someone asked me how to instantiate a class of mine for attoparsec the other day and i found myself at a loss. one of the methods is 'lookAhead :: m a -> m a' which tries the parsing action, but rewinds afterwards not consuming. Is there a way to provide that using the existing attoparsec api? and if not would it be possible to add it?
22:34:20 <ddarius> edwardk: Is this the parsers package?
22:34:23 <bos> edwardk: i believe i've bounced off that several times
22:34:25 <edwardk> ddarius: yes
22:34:44 <edwardk> ddarius: alec pinged me wanting to write an instance of parsers for attoparsec
22:34:50 <edwardk> bos: =(
22:34:52 <bos> edwardk: i haven't been able to find an easy way to do that
22:35:03 <bos> or a non-easy way
22:35:22 <edwardk> bos: that one combinator is the thing keeping basically the entire parsers package from working with attoparsec out of the box =/
22:35:30 <ddarius> lookAhead = throw UnsupportedOperationException
22:35:37 <edwardk> ddarius: =P
22:36:04 <bos> edwardk: the internals of attoparsec are very simple. if you're feeling like it, please be welcome to throw yourself at that problem, as it's a feature i've wanted umpteem times.
22:36:17 <edwardk> bos: k. i may just do so
22:36:32 <edwardk> at least now i know you are open to the idea ;)
22:36:38 <bos> (i think the backtracking that attoparsec does is subtly broken, too, so watch out for that.)
22:38:07 <edwardk> i added an issue to the parsers bugtracker to remind me to go try fixing up attoparsec
22:38:15 <ddarius> edwardk: Maybe you can throw Alec at it...
22:38:19 <bos> cool
22:38:51 <Cale> jfischoff: Ah, okay, so whenever you write code in which there's a type variable 'a', say, the compiler is only going to compile one version of that code normally. The reason it doesn't have to compile a separate version for a = Int and a = (Int, Int), and a = (Int, (Int, Int)), and a = (Int, (Int, (Int, Int))), and so on, is that all values are represented by objects of the same size in memory.
22:38:58 <edwardk> it'd be nice for folks to be able to use attoparsec rather than trifecta through that when they don't need the diagnostic support
22:39:02 <Cale> jfischoff: That's what the "box" is :)
22:39:20 <Cale> Specifically, in GHC, all values are pointers to code.
22:39:46 <jfischoff> ah interesting. I guess I assumed it worked like c++ templates.
22:39:47 <edwardk> ddarius: i think he just switched to parsers + parsec =P
22:39:54 <ddarius> edwardk: Attoparsec seems like a bigger jump from trifecta than someone who just didn't need diagnostic support would go.
22:40:14 <Cale> jfischoff: You can write code which would fall flat on its face if it were:
22:40:25 <edwardk> ddarius: well, the goal with parsers was to be able to support attoparsec, trifecta, parsec and most anything else someone came up with
22:40:27 <jfischoff> how so
22:40:28 <jfischoff> ?
22:40:45 <ddarius> edwardk: So perhaps you need to refactor the classes in parsers?
22:40:49 <edwardk> so it was very much in my mind as one of the initial targets
22:40:51 <edwardk> possibly
22:41:02 <Cale> > let f x 0 = show x; f x n = f (x,x) (n-1) in map (f ()) [0..]
22:41:03 <lambdabot>   Occurs check: cannot construct the infinite type: a = (a, a)
22:41:04 <edwardk> given my druthers i'd rather fix attoparsec to support lookAhead
22:41:06 <Cale> oops
22:41:12 <edwardk> otherwise i have to make uglier grammars for some things
22:41:17 <Cale> > let f :: (Show a) => Integer -> a -> String; f x 0 = show x; f x n = f (x,x) (n-1) in map (f ()) [0..]
22:41:18 <lambdabot>   Couldn't match expected type `GHC.Integer.Type.Integer'
22:41:18 <lambdabot>         against inf...
22:41:22 <ddarius> edwardk: Well yes, but that may be the nature of attoparsec.
22:41:31 <edwardk> it may be
22:41:36 <Cale> (I just woke up :)
22:41:42 <jfischoff> lol
22:41:44 <edwardk> i'll beat my head against it before giving up first though ;)
22:41:56 <edwardk> i want to understand why it is the nature of attoparsec if it is
22:41:56 <shachaf> sagelywizard: Beep
22:42:02 <cmccann> Cale, this is clearly the best explanation of boxed values: http://spl.smugmug.com/Humor/Lambdacats/boxed-cat-has-a-uniform/960526161_yXhEz-O-1.jpg
22:42:04 <Cale> oh
22:42:10 <Cale> > let f :: (Show a) => a -> Integer -> String; f x 0 = show x; f x n = f (x,x) (n-1) in map (f ()) [0..]
22:42:11 <lambdabot>   ["()","((),())","(((),()),((),()))","((((),()),((),())),(((),()),((),())))"...
22:42:15 <Cale> yeah, there we go
22:42:17 <Cale> :)
22:42:17 <edwardk> attoparsec is very very close to the internals of trifecta though, so i think it can work
22:42:39 <Cale> jfischoff: Okay, so this f clearly needs to be applied at infinitely many types 'a' to work
22:42:53 <jfischoff> aye
22:43:01 <Cale> cmccann: :)
22:43:05 <thoughtpolice> edwardk: you should release trifecta 0.90 while you're at it :)
22:43:17 <ddarius> Boxing is the extra level of indirection that solves all problems.
22:43:38 <edwardk> thoughtpolice: 0.90 needs me to spend more time porting stuff forward
22:43:51 <cmccann> ddarius, except the problem of too many levels of indirection, of course.
22:43:56 <jfischoff> Well I am very glad that ghc can unbox some things
22:44:15 <ddarius> cmccann: Just indirect your indirections then you can collapse chains of indirections.
22:44:55 <ddarius> Cale: What's with the x parameter?
22:45:11 <ddarius> Er, never mind.
22:45:47 * ddarius for some reason remembered that function having only one parameter even though that makes no sense.
22:46:07 <ddarius> I don't even have the excuse of having just gotten up.
22:46:14 <johnw> is boxing all about manufacturing isomorphisms?
22:47:20 <Cale> johnw: In a weird way, for infinitely many definitions of "isomorphism", perhaps.
22:47:33 <johnw> as long as those definitions are isomorphism :)
22:47:35 <johnw> phic
22:48:51 * cmccann still enjoys having "uptoisomorphism.net" as his email domain
23:05:29 <hpaste> Matt pasted “axiomatic definitions” at http://hpaste.org/75522
23:10:26 <johnw> edwardk: what does this mean?  `x is not a (visible) method of class `Y'?
23:10:37 <johnw> i can't see what I'm doing wrong, it's very simple code
23:11:05 <edwardk> johnw: is this in an instance declaration?
23:11:28 <hpaste> johnw pasted “lens problem” at http://hpaste.org/75523
23:12:01 <edwardk> hmm
23:12:02 <shachaf> That paste doesn't mention x or Y....
23:12:04 <shachaf> s/.$//
23:12:20 <edwardk> what is the actual 'x' it says?
23:12:30 <johnw> `refName' is not a (visible) method of class `HasReference'
23:12:46 <edwardk> interesting
23:12:47 <shachaf> Is the class HasReference defined elsewhere?
23:12:52 <johnw> makeClassy creates it
23:12:57 <edwardk> gets built by makeClassy
23:13:05 <shachaf> Right, but is there anything else that's also defining it?
23:13:19 <edwardk> just to be sure, refName isn't a method provided by one of those modules is it?
23:13:37 <johnw> oh, I'm sorry
23:13:42 <johnw> I had two functions much further down with the same names
23:13:46 <edwardk> ah
23:13:53 <johnw> i knew it had to be something stupid
23:14:04 <edwardk> happy to help ;)
23:14:18 <shachaf> It's much easier to ask questions like that if you @paste the full code with the full original error. :-)
23:14:55 <johnw> granted
23:27:53 <johnw> i find myself liking =<< more than >>= recently
23:28:05 <johnw> guess I'm too used to reading (.) from right to left
23:28:20 <johnw> putStrLn =<< arg just reads easier than arg >>= putStrLn
23:29:19 <pnielsen> especially when the next step is a composition
23:30:18 <pnielsen> writeTVar t . (x :) =<< readTVar t
23:31:52 <johnw> yeah, and <=< is more consistent too
23:31:53 <pnielsen> feels more natural with f $ g x as well
23:32:44 * Ralith likes >>= because the lexical order is consistent with the monadic sequencing
23:32:51 <johnw> well, there's that
23:33:06 <johnw> i still use both
23:33:07 <pnielsen> I like it for getArg >>= putStrLn
23:33:28 <pnielsen> but given . or $ it looks weird to me
23:33:37 <pnielsen> zig-zaggy
23:33:49 <johnw> something I think of an action as an "argument", and sometimes as an action that follows from the preceding
23:36:42 <Cale> If only Newton had written x f rather than f(x), we wouldn't be in all this mess.
23:37:16 <McChousuke> You can choose to not use it you know
23:37:37 <McChousuke> It always boggles my mind that they actually consciously decided to propagate the godawful atrocity that is mathematical textbook notation with Haskell.
23:38:23 <McChousuke> If you're going to learn Haskell you most likely have to unlearn a lot of tings anyway, so why not just come up with an actual proper syntax intead of trying to force somethng as awful as mathematical textbook notation into something parsable
23:39:49 <johnw> on the other hand, Haskell is the first reason I've had to learn higher math in my entire life
23:40:07 <Cale> McChousuke: Because there are millions of papers written in mathematical notation.
23:40:29 <Cale> McChousuke: and being able to translate things from common mathematical notation into programs is definitely an advantage.
23:40:42 <McChousuke> Cale, irrelevant, a machine is never going to translate that to Haskell, humans are going to read those and express the logic in that in haskell code.
23:41:01 <Cale> McChousuke: Yes, but humans are worse than machines at doing things consistently.
23:41:03 <McChousuke> Cale, if you're just copying the symbols in those papers without understanding them it will go wrong anyway.
23:41:13 <Cale> They make mistakes, and if you make the work harder for them, they make more.
23:41:24 <McChousuke> mathematical textbook notation _encourages_ mistakes.
23:41:38 <Cale> If it *were* machines doing the work of translation, then it wouldn't be an issue.
23:41:38 <johnw> McChousuke: it does make it easier to leverage some of the mathematical research being done
23:41:40 <McChousuke> Tell me, how many type errors have you had due to operator praecedence?
23:41:55 <Cale> McChousuke: The fact that they were type errors meant that it was no big deal.
23:42:11 <McChousuke> Mathematical textbook notation is hard to read and undertand for both humans and machines and terribly inefficient.
23:42:28 <Cale> The real question is how many runtime bugs I've had because of operator precedence, and that's probably about 1/year.
23:42:29 <McChousuke> No, haskell catches your mistakes for you, it still makes mathematical textbook notation a very iinefficient and bad way of writing exact logic in.
23:42:41 <Cale> That's not true though
23:43:03 <Cale> Mathematical textbook notation is much better designed than people give it credit for.
23:43:09 <McChousuke> I'm pretty sure that if you wrote Haskell in the most convulted and bad syntax as long as it was decidable haskell would still capture your errors, it doesn't make the logic you're trying to express easy to read for humans.
23:43:12 <McChousuke> "designed"?
23:43:18 <Cale> yes, designed.
23:43:43 <McChousuke> It is not designed, it is something that evolved by piling features atop of features until consistency was thrown out of the window, it's ambiguous even and ridden with abuse of notation.
23:43:51 <Cale> It wasn't handed down to us on golden plates from the grand council of mathematics gnomes :)
23:44:01 <Cale> It is designed and redesigned continuously.
23:44:17 <Cale> Mostly by graduate students :D
23:44:51 <McChousuke> It was never designed, it just gradually evolved and it's inefficient. And eve HAskell recognizes this, there's a reason you don't do map(f)(list) in Haskell.
23:45:08 <McChousuke> The notation f(x) is silly anyway, it' ambiguous and bad.
23:45:11 <Cale> Not everyone writes the parens for function application in mathematics either.
23:45:28 <McChousuke> a(x+y), is that a applied to x+y or is that a distributing over x and y?
23:45:58 <McChousuke> Yap, and without it in mathematical notation it suddenly becomes ambiguous with f * x, which it already is.
23:46:03 <Cale> answer: multiplication is a homomorphism, so it doesn't matter
23:46:09 <McChousuke> Mathematical textbook notation is a complete and utter mess.
23:46:38 <McChousuke> Which is probably also why Hasell doesn't take it over in full as it would become ambiguous.
23:46:45 <McChousuke> Or -5 in Haskell
23:46:53 <Cale> I thoroughly disagree. *Some* notation by *some* mathematicians is messy.
23:46:54 <McChousuke> apparently that is 0-5
23:46:59 <johnw> McChousuke: you know we don't have the power to fix this here, right?
23:47:07 <McChousuke> Of course.
23:47:17 <Cale> But by and large, mathematical notation is highly polished.
23:47:29 <Cale> To do the job it needs to do for mathematicians.
23:47:44 <McChousuke> No it's not, if we were to start from scratch to make a language to define exact mathematics in it would be infinitely better
23:47:45 <johnw> I'd have more luck convincing academia that James Joyce's Ulysses is a giant piece of crap
23:47:49 <Cale> and any bit of notation which doesn't work well enough is typically replaced
23:48:07 <McChousuke> I beg to differ, I am willing to bet everyone here has had a 'proof by notation' slipped under the radar from a lecturer.
23:48:09 <johnw> once a group of people large enough thinks that something is good and worth maintaining, it will be called good and maintained
23:48:14 <Cale> and indeed, in some contexts where there's a lot of composition of arrows going on, people flip things around
23:48:36 <Cale> But you have to understand that notation isn't just for local expression of ideas. It's for communication.
23:48:36 <McChousuke> I can recall many a times that a student from the room just said 'Yeah, but your proof assumes that the '=' in the notation is actually the identity relation, which it isn't
23:49:06 <McChousuke> Cale, and it communicates badly, it takes a long time to learn to read it, and it reads slowly by humans
23:49:10 <Cale> Who uses = as something other than the identity relation?
23:49:15 <McChousuke> slower than something specifically designed to communicate these ideas.
23:49:24 <McChousuke> Limits? big O notation?
23:49:48 <McChousuke> I've seen many garbled proofs which used '=' in """limits""" which 'go to infinity'
23:49:49 <Cale> Okay, if you're using = for big O notation, that's bad.
23:50:09 <pnielsen> for some reason Excel came to mind :)
23:50:13 <McChousuke> Or infiite series, but those are limits as well I guess.
23:51:00 <Cale> For limits, you're usually working in a topological space which is sequentially complete, so it's okay to talk of "the limit"
23:51:35 <Cale> (or just plain complete)
23:51:44 <McChousuke> Well, I have definitely seen proofs where the transitivity of '=' was applied to that in a case where purely by chance it ended up going okay, but I could produce examples where just applying that transitivity went to madness.
23:51:45 <Cale> Things don't have more than one limit
23:51:57 <McChousuke> If the limit goes to infinity, there is no limit.
23:52:04 <McChousuke> It's just a special case of no limit at all.
23:52:36 <Cale> Well, sure. Whenever you write limit as x -> a of f(x), you must have the condition that said limit exists.
23:52:44 <McChousuke> But anyway, mathematical textbook notation is honestly like the empirial system, people just use it because they are used to it, but the metric system saves everyone time.
23:52:55 <Cale> Similarly to whenever you write x/y, you require that y is nonzero.
23:52:58 <McChousuke> Well, it is actually a proper = if the limit does exist.
23:53:05 <pnielsen> McChousuke: Americans use the imperial system*
23:53:07 <pnielsen> :)
23:53:15 <McChousuke> But lim = \infty is very common notation that gets abused a lot.
23:53:28 <Cale> I don't see it being abused.
23:53:34 <McChousuke> They do, and it's obviously inferior to the metric syste and it would save them time and money if they completed the switch
23:53:37 <pnielsen> even the British have largely discarded it
23:53:38 <McChousuke> but making the switch is an investment
23:53:43 <Cale> Maybe people use notation in a more horrible fashion where you live :P
23:53:49 <Cale> Or I dunno.
23:53:56 <Cale> There are some people who just have bad taste in notation
23:53:57 <McChousuke> Just like learning to use a good ytem of mathematical notation is an investement, but after that point it will become easier to read and to write for you.
23:54:06 <Cale> But by and large, mathematical notation is pretty good.
23:54:13 <McChousuke> No, it's terrible
23:54:15 <McChousuke> x + y + z
23:54:17 <McChousuke> is TERRIBLE
23:54:20 <Cale> oh?
23:54:37 <johnw> also, let's not assume that a "new" Haskell notation created by primarily mathematicians would per force be a vast improvement :)
23:54:37 <McChousuke> Of course, in this case it just happesn to go already because (x + y) + z is the same as x + (y + z)
23:54:38 <Cale> That notation makes the associativity of addition implicit.
23:54:42 <McChousuke> But what about x / y / z
23:54:53 <McChousuke> Is that (x / y) / z or x / (y / z)?
23:54:56 <Cale> Now that would be bad notation, but nobody writes that
23:55:05 <pnielsen> McChousuke: what isn't terrible? + x y z ?
23:55:08 <johnw> never in my life have I needed x / y / z
23:55:16 <johnw> i've wanted a == b == c
23:55:24 <McChousuke> a == b == c is also terrible
23:55:29 <pnielsen> a < b < c is nice
23:55:33 <McChousuke> Is that (a == b) == c or a == (b == c) or neiter
23:55:39 <Cale> neither
23:55:43 <McChousuke> no, a < b < c is terrible
23:55:44 <McChousuke> exactly.
23:55:46 <Cale> It's a == b and b == c
23:55:49 <pnielsen> or < a b c
23:55:49 <McChousuke> Indeed
23:55:58 <McChousuke> which is seomthing you have to memorize specifically for ==
23:56:02 <Cale> No
23:56:04 <McChousuke> Yes
23:56:07 <pnielsen> McChousuke: what would you suggest? (Honestly curious)
23:56:14 <McChousuke> It doesn't work that way in x + y + z
23:56:16 <Cale> It's something that you memorise once for all transitive relations
23:56:26 <McChousuke> pnielsen, I would have to design something for that specifically if I wanted to replace that
23:56:34 <McChousuke> Cale, indeed, memorize for every single case
23:56:36 <Cale> Any transitive relation makes that notation morally correct
23:57:03 <McChousuke> Cale, I'm pretty sure it does not apply to all transitive relations
23:57:07 <McChousuke> Wat about x -> y -> z
23:57:13 <McChousuke> Does that mean x -> y ad y -> z
23:57:17 <pnielsen> I'm personally intrigued by PN/RPN, but have never really used it
23:57:24 <Cale> In my head, what you're really doing is providing a diagram of arrows in a particular category described by the relation :)
23:57:27 <McChousuke> No, in general that either mean (x ->y) ->z or x -> (y -> z)
23:57:29 <johnw> a == b == c does actually work in some languages, as a special hack
23:57:30 <pnielsen> aside from lisp
23:57:59 <McChousuke> Well, I feel S-expressions or something in that vein are a really good start honestly, together with shortands
23:58:09 <ddarius> If (~>) was "reduces to", then x ~> y ~> z would indeed mean x ~> y and y ~> z.
23:58:16 <McChousuke> For intance, ( wouldn't mind (a b c; d e ;f) to be short for (((a b c) d e) f)
23:58:19 <johnw> i miss sexprs
23:58:25 <johnw> they are so easy to manipulate in my editor
23:58:32 <johnw> something refactoring Haskell code is a nightmare
23:58:36 <johnw> sometimes
23:59:05 <McChousuke> Cale, anyway, the point is, if you encounter x -> y -> z, depending on the author it wil mean (x -> y) -> z or x -> (y -> z) or even indeed x -> y and y  -> z
23:59:28 <McChousuke> Again, soemthing that costs you time and money every time you read literature that contains that because you have to read the appendix, the appendix needs to be printed etc.
23:59:43 <ddarius> So clearly the solution is yet another notation.
23:59:52 <McChousuke> Also, if you have a long expression containing a lot of infixes it might not be immediately clear what the 'top level' operator is.
