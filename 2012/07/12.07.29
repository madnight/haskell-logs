00:00:59 <ddarius> edwardk: It would be a good exercise for an intermediate Haskeller to figure out how to use List when defined as Free Monoid.
00:01:09 <edwardk> *nods*
00:01:27 <donri> it seems people target either haskell 98 or ghc haskell, rarely haskell 2010 specifically
00:01:40 <donri> i guess there isn't enough useful additions from h98?
00:01:42 <edwardk> it was fun figuring out the ForallT, ForallF tricks necessary to make the Monad once and for all
00:01:59 <ddarius> donri: They removed n+k patterns and added pattern guards.
00:02:13 <donri> ddarius: empty data decls :)
00:02:13 <ddarius> Pattern guards are sort of important but not commonly use.
00:02:32 <edwardk> donri: i target the intersection of 98 and 2010
00:02:37 <donri> heh
00:02:47 <ddarius> At any rate, I think it's more terminological inertia.  The vast majority of Haskell 2010 code would also be Haskell 98 code and vice versa.
00:02:48 <edwardk> i sometimes use pattern guards when i write code at first
00:02:50 <edwardk> but most of the time i rip them out by the time i ship
00:03:10 <donri> ddarius: well my point is, if your code is h2010, it's probably easy to make it h98?
00:03:11 <edwardk> they rarely add much clarity once i've had time to refine the code
00:03:19 <edwardk> donri: yeah
00:03:27 <edwardk> pattern guards are nice though
00:03:37 <donri> so either you don't care = ghc haskell, or you probably end up targetting h98 anyway
00:03:46 <dolio> Just add some n+k patterns.
00:03:46 <ddarius> Pattern guards can be very valuable in some cases, but those cases don't come up all the time.
00:03:50 <dolio> Then it's compliant.
00:03:54 <donri> :)
00:04:13 <ddarius> I believe view patterns have a desugaring into pattern guards.
00:04:27 <edwardk> jfischoff: i'll probably release a 'lens98' package or 'lens-core' that contains the LensLike type and pretty much all the combinators
00:05:01 <dolio> Because one module uses liberal type synonyms?
00:05:09 <edwardk> no
00:05:14 <edwardk> because of the rank n types
00:05:20 <edwardk> just to make the few sticklers happy
00:05:35 <dolio> Who are these sticklers?
00:05:38 <dolio> Besides you.
00:05:41 <edwardk> =)
00:05:52 <Dodek> hey, so few days ago someone here recommended a paper about applicative functors to me
00:05:55 <edwardk> roconnor likes to complain ;)
00:06:07 <Dodek> i finally found time to read it, and it was very nic
00:06:09 <Dodek> nice
00:06:15 <Dodek> do you have more like that one?
00:06:57 <donri> papers, we've got loads of those
00:07:00 <ddarius> Dodek: A perhaps more productive route is to state which paper you read and then ask your question.
00:07:28 <ddarius> Or perhaps I should say "state the title of the paper you read"
00:07:44 <donri> i think the point is they want moar interesting papers in general?
00:08:09 <dolio> What about the sticklers who think that dividing every package into two or three packages is worse than having a package that isn't strictly Haskell 98?
00:08:23 <edwardk> dolio: i'm coming around to that view myself
00:08:25 <Dodek> ddarius: it wasmcbride, patterson "applicative programming with effects"
00:08:53 <jfischoff> edwardk: that's my feeling right now, but what do I know
00:09:16 <donri> i don't mind many packages until i need to package something for fedora
00:09:27 <jfischoff> I'm interested to see where roconnor takes things too :)
00:10:16 <edwardk> there isn't much room left in the design space. you can add, say, partial-lenses, which i have a toy module for, but they kinda suck without Pointed as a superclass of Applicativ
00:10:22 <ddarius> donri: "more like that one" suggests they want more papers like the one they read, which is hard to resolve from "that paper someone referred me to the other day"
00:10:35 <edwardk> you can also add 'non-empty traversals' but they suck without Apply as a superclass of Applicative
00:10:41 <donri> ddarius: ah true
00:10:44 <Dodek> ddarius: nah, i don't want like that one
00:10:50 <Dodek> ddarius: i just want some cool ideas
00:10:51 <edwardk> the former are useful because you can know the lens targets at most one thing
00:11:03 <edwardk> the latter is useful because you know the traversal targets at least one thing
00:11:03 <ddarius> Dodek: Trust me.  I have tons of interesting papers not like that one.
00:11:13 <donri> Dodek: not a paper per se but maybe read http://www.haskell.org/haskellwiki/Typeclassopedia
00:11:16 <Dodek> ddarius: go ahead than, i'm all open
00:11:22 <jfischoff> edwardk: what are the partial lens laws?
00:11:33 <donri> that should at least give you a starting point to peak interest in various type classes
00:11:36 <jfischoff> have they been articulated?
00:11:38 <edwardk> jfischoff: you lose the first one in my list
00:11:38 <donri> peek?
00:11:56 <jfischoff> yeah
00:12:17 <edwardk> jfischoff: usually with a lens you have the fact that getting what you put is what you put, that goes away.
00:12:23 <ddarius> pique
00:12:32 <ddarius> @wn pique
00:12:34 <lambdabot> *** "pique" wn "WordNet (r) 3.0 (2006)"
00:12:34 <lambdabot> pique
00:12:34 <lambdabot>     n 1: tightly woven fabric with raised cords
00:12:35 <lambdabot>     2: a sudden outburst of anger; "his temper sparked like damp
00:12:35 <lambdabot>        firewood" [syn: {pique}, {temper}, {irritation}]
00:12:36 <lambdabot>     v 1: cause to feel resentment or indignation; "Her tactless
00:12:38 <jfischoff> yeah I'm looking at your list now
00:12:38 <lambdabot>          remark offended me" [syn: {pique}, {offend}]
00:12:50 <donri> english, y u suck
00:13:10 <edwardk> anyways, i use multilenses for many things that are nominally a partial lens
00:13:17 <Dodek> donri: that's nice, but i already know most of that
00:13:26 <donri> ah ok
00:13:28 <dolio> You need linear lenses, too.
00:13:32 <edwardk> traverseHead for instance is actually a partial lens in disguise
00:13:36 <Franciman> hi all
00:13:41 <ddarius> donri: Because pique isn't an English word.
00:13:43 <jfischoff> edwardk: I've been avoided partial lens for now, which is actually working out well
00:13:43 <edwardk> if they have to target exactly one element, that is a Lens ;)
00:13:49 <dolio> Wait, that's a normal lens.
00:13:56 <jfischoff> ah
00:14:02 <edwardk> the ones that can be anything are Traversals
00:14:10 <Dodek> donri: basically i'm a mathematician, and i've seen lots of category theory in mathematical setting
00:14:17 <donri> aha
00:14:44 <dolio> Ordered lenses.
00:14:51 <edwardk> hahaha
00:15:11 <ddarius> edwardk: I await the gray-lenses package.
00:15:25 <edwardk> clearly we need disposable and contact lenses as well
00:15:33 <Taneb> And coloured
00:15:40 <Franciman> by using zippers on a binary tree, what's the asymptotic complexity of changing a node's value?
00:15:40 <dolio> Uniqueness lenses.
00:15:50 <Dodek> so now i see people talking about some lenses thing and i wonder what it is and how it is useful
00:15:58 <donri> Dodek: http://www.haskell.org/haskellwiki/Research_papers ;)
00:15:59 <help2man> is haskell by default compiled or interperted
00:16:00 <jfischoff> maybe restricted lenses is a better word. They're lenses only when the domain is restricted
00:16:01 <edwardk> of course, now i kind of want to go reread the lensman books
00:16:08 <edwardk> help2man: the major implementation is compiled
00:16:14 <Taneb> Ooh, reading material
00:16:16 <donri> help2man: there is no default, but it's typically compiled
00:16:21 <edwardk> jfischoff: i call them 'LensLike' rather than lenses
00:16:27 <jfischoff> yeah
00:16:33 <ddarius> There's not just no default, the question makes no sense.
00:16:37 <edwardk> hence why 'Fold' and 'Traversal' rather than 'PartialLens' or 'MultiLens'
00:16:47 <edwardk> er
00:16:53 <edwardk> 'Fold' was 'MultiGetter'
00:16:57 <help2man> for ubuntu linux is there any freely available haskell compilers or tools for developing haskell that you recommend
00:17:07 * ddarius typically executes Haskell in his head.  I'm not sure if that counts as compiled or interpreted.
00:17:07 <help2man> something i can apt-get install
00:17:18 <mikeplus64> help2man: apt-get install haskell-platform
00:17:21 <ddarius> help2man: Go to haskell.org.
00:17:28 <Dodek> donri: hah, that's what i was looking for, thank you!
00:17:31 <donri> Dodek: http://www.scs.stanford.edu/11au-cs240h/notes/zipper.html
00:18:19 <edwardk> i'm actually tempted to put together a functional pearl on lenses, folds, and traversals
00:18:33 <mikeplus64> help2man: (that installs ghc, the most standard and widely used (by far) haskell compiler, and various libraries)
00:18:39 <edwardk> it might do more to foster adoption than anything else i could do
00:19:09 <jfischoff> yeah I'd love it, but I've already adopted :)
00:19:19 <edwardk> ddarius: i think you jit it to forth
00:24:25 <ddarius> Free Monoid may, in many ways, actually be a better representation of lists than [].
00:24:48 <Taneb> Free Monoid?
00:25:13 <ddarius> @hackage free-functors
00:25:14 <lambdabot> http://hackage.haskell.org/package/free-functors
00:26:15 <levi> edwardk: Data Lenses aren't actually related to the usage of lens brackets for anamorphisms, are they?
00:26:25 <ddarius> levi: No.
00:27:54 <levi> They didn't seem related, but I figured I may have overlooked something.
00:28:36 <jfischoff> Did Pierce come up with the term lenses?
00:29:25 <levi> A good bit of the 'Functional Programming with Bananas, Lenses, etc.' paper went over my head.
00:29:44 <Taneb> What's a Banana in this context?
00:30:17 <levi> In that paper, banana brackets are used for catamorphisms
00:31:22 <edwardk> levi: if it helps, i'm not a huge fan of the crazier foomorphisms myself
00:31:40 <edwardk> and i think i've used them as much as anyone
00:32:58 <jfischoff> what's not to like?
00:33:24 <levi> The gist of it was that you can describe many kinds of recursive algorithms in terms of general operators that capture different patterns of recursion. I pretty much followed the cata/anamorphisms, the paramorphisms and hylomorphisms and whatnot started to lose me, and by the time it got to discussing fusion laws I was off in the weeds.
00:34:33 <edwardk> jfischoff: whats to like? you get all the benefits of terribly baroque and scary names to scare off anyone from learning them, and all that metatheory that never really panned out into any really usefully automatable fusion models, and all the pain of writing code in an unnatural style. its amazing ;)
00:34:42 <ddarius> hylo is easy if you understand cata and ana.  hylo = cata . ana
00:35:23 <edwardk> ddarius: and hylo is pretty much where they stop being interesting, after that its just the fact that you can use a distributive law to push a monad or comonad out of sight where it can't get in your way
00:35:35 <edwardk> and all the others are applications of that theme
00:36:01 <ddarius> Hylo is already uninteresting because the language of hylomorphisms on reasonable data types is Turing-complete.
00:36:24 <edwardk> good point
00:36:48 <edwardk> thats a large part of why the hylo-fusion guys never got off the ground -- they could never figure out how to automate the rewriting
00:38:46 <jfischoff> Okay so recursion schemes are not all they were cracked up to be, so what should I be trying to grok then?
00:38:52 <ddarius> Yep.  Basically, there are several ways of solving a problem using hylos and you are only going to get useful fusion if you write it in just the right way(s), which is basically the antithesis of what that approach was trying to accomplish.
00:39:26 <ddarius> jfischoff: You should definitely understand fold/unfold (cata/ana) as they are of fundamental importance.
00:39:41 <jfischoff> fair enough
00:40:05 <jfischoff> what else
00:40:09 <levi> I think I followed what hylomorphisms were pretty well, but the name didn't really stick. All the abstract math terminology is slowly sinking in to my brain as I read more, but I need to do something with it if I'm going to retain any of it.
00:40:47 <ddarius> levi: Most of the *morphism terminology, certainly the *morphism names themselves aren't mathematical terms.  Heck, they are defunct terms entirely.
00:41:03 <weirdo> hello
00:41:09 <ddarius> Though it varies depending on who you're reading.
00:41:14 <weirdo> i've been reading LYAH some time ago
00:41:19 <weirdo> but now i plan to go back to it
00:41:37 <levi> Aren't the 'morphism' terms from category theory?
00:41:38 <weirdo> the question is, how much ghc conses thunks during normal operation?
00:41:49 <ddarius> jfischoff: Jeremy Gibbons chapter "Calculating Functional Programs" is something you should be able to read fairly easily.
00:41:53 <ddarius> levi: No.
00:42:17 <weirdo> how is deforestation working in practice? how is GC doing with all the thunks?
00:43:13 <ddarius> levi: Pretty much no categorist would have any clue what you were talking about if you started saying "catamorphism this" and "anamorphism that".
00:43:15 <jfischoff> ddarius: thanks
00:43:21 <ddarius> levi: The concepts are from category theory though.
00:43:35 <edwardk> levi: 'morphism' comes from category theory. all the greek and latin crap on the front comes from lambert meertens
00:44:09 <ddarius> "Morphism", "isomorphism", and "homomorphism" are general mathematical terms.
00:44:13 <edwardk> levi: a few others chipped into the insanity, uustalu and vene, etc.
00:44:20 <levi> OK, that makes sense then.
00:44:30 <edwardk> but uustalu later recanted ;)
00:45:01 <edwardk> and most of the early papers were by meertens' students who had a vested interest in using his vocabulary
00:45:04 <ddarius> levi: The thing I referred jfischoff to goes over the category theory behind those things.  Gibbons uses the more common terms fold/unfold.
00:45:23 <edwardk> fold/unfold/refold supplies a nice intuition
00:46:29 <geekosaur> ...was actially working on an answer for them...
00:46:31 <edwardk> levi: in  http://hackage.haskell.org/packages/archive/recursion-schemes/2.1/doc/html/Data-Functor-Foldable.html i provide a whole menagerie of them
00:47:59 <levi> I'm pretty comfortable with fold, anyway.
00:47:59 <Taneb> How does unsafeCoerce get on with the garbage collector?
00:47:59 <edwardk> though, parts of that menagerie dates back further to category-extras, where it was started by dave menendez
00:47:59 <edwardk> Taneb: just fine
00:47:59 <ddarius> Taneb: Fine as long as you use it only in the ways allowed by the documentation.
00:48:35 <Taneb> Heh, that's exactly how I'm not using it
00:48:39 <ddarius> That said, unsafeCoerce has no operational effect and GHC's garbage collector effectively doesn't use type information, so unsafeCoerce can never directly cause problems for the GC.
00:49:18 <Taneb> Actually, what does it mean by Any?
00:49:41 <edwardk> Taneb: there is a type GHC.Prim.Any
00:50:04 <ddarius> Taneb: I believe Any is treated more carefully by the optimizer so as to not have the optimizer break your evil programs.
00:50:21 <ddarius> The optimizer quite definitely -does- use type information at times.
00:50:51 <Taneb> Nah, that's not what I want
00:50:58 <Taneb> My program is an evil bunch of evil
00:51:22 <Taneb> Quite deliberately, though, and it seems to work
00:52:20 <Taneb> Maybe you've seen it
00:52:32 <Taneb> It uses unsafeCoerce <*> unsafeCoerce for recursion
00:57:41 <donri> edwardk: i must say %~ is a rather ugly operator though :(
00:57:55 <edwardk> donri: %= is the motivation
00:58:01 <edwardk> 'mod' =
00:58:09 <edwardk> that one is pretty handy
00:58:19 <donri> yea i get it, just ugly :)
00:58:23 <edwardk> +=  +~
00:58:33 <edwardk> keeps the same length and ~ and = are at least kinda related
00:58:51 <donri> sure
00:59:05 <edwardk> couldn't find another symbol that didn't collide with everything on the planet
00:59:11 <edwardk> when put next to something else
00:59:29 <donri> how about # :D it's like = but twice and once flipped
00:59:34 <donri> %# so pretty!
00:59:37 <donri> not really!
00:59:39 <edwardk> i really don't like # =P
00:59:50 * ddarius waits for +≅
00:59:58 <edwardk> ddarius: =)
01:00:22 <Franciman> hey people, is every time you call a constructor a new value created? Or sometimes calling a constructor won't create something new?
01:00:49 <ddarius> Franciman: It depends on the constructor, though really the implementation can do whatever it wants.
01:01:15 <Franciman> what do you mean by depends on the constructor?
01:01:28 <edwardk> anyways, you can always just call 'adjust
01:01:36 <ddarius> Nullary constructors are shared.
01:01:39 <ddarius> In GHC.
01:02:03 <ddarius> In practice, a constructor will lead to memory allocation.
01:02:19 <ddarius> Though fusion makes that not always true eithe.
01:02:20 <edwardk> Franciman: for instance 'Nothing' takes no arguments, so there isn't a point in constructing multiples in memory
01:02:28 <ddarius> As well as other optimizations.
01:02:42 <Franciman> oh yes
01:08:26 * levi puts the Gibbons Calculating Functional Programs chapter on his iPad and heads to bed
01:14:12 * elegantWay . o O ( iPaid )
01:19:16 <quintessence> Does GHC allocate a new value if you pattern match a value and put the same value back together with a different type?  (think `fmap length (Left ())`)
01:20:08 <edwardk> quintessence: most of the time, sadly, yes
01:22:49 <ddarius> The killer is that I'm pretty sure it does that for phantom types.
01:22:49 * hackagebot lens 1.0.1 - Families of Lenses, Folds and Traversals (EdwardKmett)
01:22:56 <amatsu> Does anybody know much about the state of the Lambdabot package on Hackage? Namely, the state of a few dependency issues?
01:23:33 <edwardk> i've build code that uses unsafeCoerce for those which pathetically gained me a few percent performance wise
01:23:37 <amatsu> (I'm talking about how the Eval plugin calls ShowIO instead of ShowFun, the former seems to have been deprecated in show-0.4)
01:56:14 <donri> edwardk: hm was that really pvp? :)
01:56:24 <edwardk> 1.0.1?
01:56:32 <edwardk> i only added stuff
01:56:46 <edwardk> no new instances for old types
01:56:49 <edwardk> so it should comply
01:57:27 <donri> oh yea i keep forgetting that A.B count as major version together
01:57:34 <donri> so increase in minor doesn't imply 1.1
01:57:52 <edwardk> yeah
01:58:25 <donri> i think most other versioning scheme call them A=major B=minor C=patch-level
01:58:37 <edwardk> i tend to bump the second minor number when i just bump dependency bounds or docs, the first minor number when i add stuff
01:59:26 <shachaf> And the major number when you break compatibility?
01:59:35 <edwardk> so a doc goes to 1.0.0.1, a minor addition 1.0.1.0 and any pvp-breaking change to 1.1.0.0, which keeps me in line with the pvp
01:59:49 <shachaf> Oh, four digits.
01:59:54 <shachaf> s/digit/number/
02:00:02 <edwardk> but i only put the digits on the version as i need them
02:00:25 <edwardk> technically the pvp is kind of silent on whether 1.0 is ok, because they talk about versions always in the form A.B.C
02:00:27 <donri> major is increased when changes could break code that's even using explicit/qualified imports
02:00:34 <edwardk> yeah
02:01:37 <donri> 1.0 is tricky if you're not using proper imports, because then you're supposed to depend on 1.0.0.*
02:01:57 <donri> so it makes writing the version harder harder
02:02:37 <donri> >= 1.0 && < 1.0.1, something like that?
02:03:29 <donri> which is so hard i had to say harder twice, apparently
02:04:16 <edwardk> well, you should just use 1.0.*, because thats a full major version spread
02:04:52 <edwardk> in general the breakages from minor version bumps even with unqualified imports are few and far btween
02:05:11 <donri> yes but if you're not using proper imports you're supposed to depend on the *minor* version
02:05:35 <donri> you could do == 1.0, but then you don't get patch releases for that minor version
02:05:41 <donri> 1.0.0.1 :)
02:06:12 <edwardk> well, the pvp doesn't actually require that of you, just says you are on the safe side if you do that ;)
02:06:20 <donri> but yea this is the strict interpretation of pvp
02:06:30 <donri> yea
02:06:31 <edwardk> " However, note that this approach is slightly risky: when a package exports more things than before, there is a chance that your code will fail to compile due to new name-clash errors. The risk from new name clashes may be small, but you are on the safe side if you import identifiers explicitly or using qualification."
02:06:43 <edwardk> i've had one problem with that in 5 years
02:07:09 <edwardk> so i don't really worry about it any more
02:07:18 <donri> yea, i think the only times i've had problems is when a dependency has no version constraint at all
02:07:27 <donri> e.g. blaze-html since 0.5
02:08:08 <edwardk> yeah i have enough dependencies i use that have things like mtl <3 as bounds that i'm comparatively a relatively compliant little fish ;)
02:08:37 <donri> well you're the mtl maintainer so ;)
02:09:18 <Taneb> edwardk, I hope you break everything in mtl 3
02:09:25 <edwardk> Taneb: mauahaha
02:09:41 <edwardk> ive been able to do comparatively little with the mtl
02:10:03 <edwardk> mostly because all the stuff you need to do anything major is in transformers, and ross kept control of that
02:10:05 <donri> everything will be free monads in mtl 3.0 right
02:10:33 <edwardk> donri: of course
02:10:37 <Taneb> You can do an awful lot with Free, Cofree, and Const
02:10:47 <donri> \o/
02:11:06 <Taneb> Maybe ~ Free (Const ())
02:11:17 <edwardk> Maybe = Free Default ;)
02:11:20 <Taneb> (a, b) ~ Cofree (Const a) b
02:11:21 <edwardk> using the prettier Free
02:11:44 <edwardk> List = Free Monoid
02:12:16 <edwardk> TheOtherFree f = Free (Algebra f)
02:12:29 <Taneb> Not sure where you are getting Default and Monoid?
02:12:31 <shachaf> What's the prettier Free?
02:12:38 <edwardk> Data.Default, and Data.Monoid
02:13:00 <edwardk> newtype Free p a = Free { runFree :: forall r. p r => (a -> r) -> r }
02:13:19 <edwardk> when p = Monoid thats 'given any monoid and a function from a to that monoid, i'll give you a monoidal result
02:13:34 <Taneb> You can use classes as arguments to newtypes?
02:13:43 <edwardk> Taneb: ConstraintKinds
02:13:53 <ddarius> @hackage free-functors
02:13:53 <lambdabot> http://hackage.haskell.org/package/free-functors
02:13:55 <edwardk> Eq :: * -> Constraint
02:14:46 <edwardk> he's done some more since then. let me see if i still have the gist
02:15:22 <ddarius> This was published yesterday.
02:16:12 <edwardk> well, he has some more complicated stuff he hasn't published then ;)
02:16:35 <Taneb> Where's algebra taken from?
02:16:42 <Taneb> *Algebra
02:17:05 <ddarius> class Algebra f a where algebra :: f a -> a presumably.
02:19:24 <edwardk> ddarius: https://gist.github.com/3101791
02:19:36 <donri> is that copointed or something like that+
02:19:37 <donri> ?
02:19:40 <donri> algebra
02:20:25 <ddarius> donri: No.  It's not parametric in a.
02:20:56 <donri> oh i see
02:21:37 <edwardk> donri: implement Algebra f (Free (Algebra f) a) -- and it becomes fairly obvious why thats the old free monad
02:22:57 <ddarius> edwardk: That gist doesn't really have anything new/interesting as far as I can see, except I'm not sure why Exp is defined the way it is.
02:24:55 <simon_> Hi, Im tring to teach myself some haskell by write a brainfuck compiler, with llvm as backend. And since every character matches a few lines of assembly I run map on the brainfuck code. This works greate except that i have to step up the values of temps(since llvm requires SSA) and maintain a stack of labels that have been created. In a OO language i would have saved this counter and stack in the object. But how do i solve this in haske
02:25:21 <ddarius> edwardk: I guess it's supposed to be a mechanical instance of the pattern.
02:25:28 <edwardk> yeah
02:25:46 <edwardk> i think one of the earlier versions of that gist had more but i can't find it
02:32:35 <ddarius> Presumably we can get a cottage industry started with people trying to figure out what Free Eq is and Cofree Ord etc.
02:32:59 <edwardk> yeah
02:33:34 <edwardk> i've actually used something like Free Ord
02:33:58 <edwardk> it lets you supply a scoring metric basically
02:34:26 <edwardk> forall r. Ord r => (a -> r) -> a  -- is more interesting though of course
02:34:39 <edwardk> thats just a variant on J
02:34:43 * BMeph is not trying to think of an excuse for a class named Willy... >;)
02:35:05 <edwardk> =P
02:35:07 * BMeph is not thinking of such a class...very poorly, though.
02:35:41 <ddarius> Cofree WLI
02:36:05 <edwardk> just take a comonad w, a lens l, and an index i.
02:36:11 <edwardk> Cofree w l i
02:36:23 <edwardk> doesn't quite work
02:40:48 <ddarius> "I do not think that the wireless waves I have discovered will have any practical application." -- Heinrich Hertz
02:41:35 <edwardk> "Radio has no future." "X-rays will prove to be a hoax."
02:43:10 <ddarius> EPS or extracellular polymeric substance
02:52:51 * hackagebot order-statistics 0.1.0.4 - L-Estimators for robust statistics (EdwardKmett)
02:56:13 <Taneb> HLint is telling me to use the import/export shortcut
02:56:15 <Taneb> What is that?
02:56:40 <danr> simon_: I would suggest using the State monad
03:00:43 <simon_> danr: i have looked a bit on that, but wouldnt that be a global variable more or less? which from what i have read i considered "bad design" i Haskell?
03:02:51 * hackagebot liblastfm 0.0.3.4 - Wrapper to Lastfm API (MatveyAksenov)
03:03:10 <Adeon> depends on the problem you are solving
03:04:01 <danr> simon_: when using the State monad, you are explicit that you are using this state along with these computations, so it is ok
03:04:46 <k0ral> hi
03:05:02 <simon_> danr: OK, thank you, then i will take a closer look on that
03:05:25 <danr> simon_: State s a is really only a newtype around s -> (a,s), so it is not a magical thing. it just means that the state parameter is threaded around in the computation
03:05:35 <k0ral> how can I catch an error that is raised using the dreadful fail monad function ?
03:06:29 <danr> simon_: one bad thing with global variables is that it can be hard to track which parts of your program poke at them, and now you are being explicit about it (in the type system)
03:11:30 <simon_> danr: ok, i will need to study how the state monad works. I might get back with more questinones when i have tried it myself
03:16:21 <pharakesh> Is there a simple or recommended way to terminate a stateful computation with the state monad
03:16:36 <simon> simon_, you could also skip the state monad and use a recursive function that calls itself with a state as its parameter. this is what the State monad corresponds to, with added syntactic sugar and library helper functions.
03:16:56 <edwardk> hrmm, anyoe have a bunch of the standard ops like scanr, foldl, etc. implemented as foldr handy?
03:17:08 <edwardk> i really just need to go rederive all the scans
03:18:01 <pharakesh> Sure but its a lot easier to construct with the,monad, is there any easy way of telling there is no state lft
03:19:24 <srhb> Is there really no :pwd-equivalent in ghci, or am I just being blind?
03:20:01 <simon> pharakesh, terminate a stateful computation? besides having one or more states which signify that it has terminated?
03:20:09 <srhb> Ah, :!pwd works
03:20:16 <srhb> (At least on Unix, but how about Windows?)
03:20:26 <simon> good morning srhb. you're up "early" :)
03:20:55 <srhb> simon: I just hard my appartment returned from renovation, and I have no curtains. I must say I don't feel very fresh :P
03:20:58 <srhb> had*
03:21:06 <srhb> Stupid sunlight.
03:21:26 <simon> srhb, I prefer to sleep with my curtains up. I did wake from the radio going off, though, and I had a nightmare.
03:21:55 <srhb> Sleeping in is a must for me. I need my curtains :P
03:22:48 <pharakesh> Simon, for example when recursively passing the state I can just use a pattern that returns, say nothing, when the state has run out ie [] but such pattern matching is not possible to my knowledge in the state monad so how can I achieve something similar?
03:24:52 <simon> pharakesh, I don't understand. if your state is a list, and the empty list is equivalent to having run out of transitions to new states, will that not be the value to check against?
03:26:40 <pharakesh> State is within the state monad, I get errors if I try to pattern match a function in the state monad
03:27:07 <k0ral> anyone would be so kind as to tell me how to catch an IO fail (like in monad's fail function) ?
03:28:51 <bitonic> @hoogle catch
03:28:51 <lambdabot> Prelude catch :: IO a -> (IOError -> IO a) -> IO a
03:28:51 <lambdabot> System.IO.Error catch :: IO a -> (IOError -> IO a) -> IO a
03:28:51 <lambdabot> Control.OldException catch :: IO a -> (Exception -> IO a) -> IO a
03:29:02 <bitonic> wow, none of those is the right one.
03:29:29 <bitonic> @hoogle Control.Exception.catch
03:29:29 <lambdabot> Control.Exception.Base catch :: Exception e => IO a -> (e -> IO a) -> IO a
03:29:29 <lambdabot> Control.Exception catch :: Exception e => IO a -> (e -> IO a) -> IO a
03:29:29 <lambdabot> Control.Exception catches :: IO a -> [Handler a] -> IO a
03:30:24 <k0ral> bitonic: right, now how do you do the same for a MonadIO m rather than IO itself ?
03:30:40 <bitonic> @hoogle liftIO
03:30:40 <lambdabot> Network.CGI liftIO :: MonadIO m => IO a -> m a
03:30:40 <lambdabot> Control.Monad.IO.Class liftIO :: MonadIO m => IO a -> m a
03:30:40 <lambdabot> Network.CGI liftIO :: MonadIO m => forall a. IO a -> m a
03:30:54 <k0ral> basically, I'm trying to catch errors from Network.Browser.request
03:31:59 <k0ral> you're telling me how to go from IO to MonadIO m, but I need the other way around: catch needs an IO, and all I have is a MonadIO ù
03:32:03 <k0ral> MonadIO m*
03:32:24 <bitonic> k0ral: oh.  you have to run whatever stack you have to get IO then
03:34:20 <danr> where is the (Semigroup (Identity a),Semigroup (Compose f f a)) => Comonad f instance defined?
03:35:25 <danr> found it, Data.Functor.Free
03:35:51 <quintessence> k0ral: there's also some tangle of MonadBaseControl stuff for lifting things that take IO a, I'm not sure which package in that family is recommended if any
03:37:01 <k0ral> bitonic, quintessence: thank you
03:37:36 <k0ral> I wish every library used the same error handling system
03:37:44 <k0ral> I'm struggling to merge them all in MonadError
03:38:27 <bitonic> k0ral: well IO exceptions and MonadError are different things for different purposes
03:38:36 <bitonic> but yes the situation is kinda messy
03:39:28 <k0ral> bitonic: what's the purpose of IO exceptions that wouldn't be already taken care of by MonadError ?
03:40:19 <bitonic> k0ral: to fail harder, MonadError is more when you expect that things might go wrong
03:42:27 <k0ral> bitonic: isn't that quite subjective ? I mean, when writing a library, how could you possibly know if the error you're about to raise will be considered as a hard one for your user ?
03:42:52 <quintessence> k0ral: part of it is that some IO exceptions are raised by the RTS or thrown at you from other threads
03:43:11 <quintessence> and you don't want those popping up in pure implementations of MonadError
03:43:37 <bitonic> k0ral: IO exceptions are much nastier to "handle", so I personally throw them when I expect them not to be handled at all
03:45:32 <k0ral> bitonic: well, the maintainer of Network.Browser probably expected me not to handle his error, in the end he has just made my life harder
03:46:53 <bitonic> k0ral: yeah but on the other hand he made the lives of the people that do not want to handle them easier
03:47:46 <bitonic> so I think there is a point to IO exceptions
03:48:26 <bitonic> but they should be used sparingly
03:48:53 <k0ral> fair enough
03:52:24 <absence> mm_freak: i'm toying with making an audio synthesizer using netwire. is this the "right" way to schedule events into the future? theEventWire . edge . arr (> eventTime) . integral 0
04:30:43 <simon_> simon: would that work together with map? or maybe i should do the complete operation on the list reqursive? let it call itself with tail list (everything but the processed element), and pass the state.  or will that cause haskell to copy the complete list for every call?
04:32:58 * hackagebot yesod-platform 1.0.6 - Meta package for Yesod (MichaelSnoyman)
04:33:00 * hackagebot really-simple-xml-parser 0.2.0.0 - A really simple XML parser (KashyapChatamballi)
04:37:30 <danr> simon_: can you reprase what you want to do? are you looking for a function like mapM?
04:37:33 <danr> @hoogle mapM
04:37:34 <lambdabot> Prelude mapM :: Monad m => (a -> m b) -> [a] -> m [b]
04:37:34 <lambdabot> Control.Monad mapM :: Monad m => (a -> m b) -> [a] -> m [b]
04:37:34 <lambdabot> Prelude mapM_ :: Monad m => (a -> m b) -> [a] -> m ()
04:41:07 <ski> simon_ : no, just passing the tail of the list onward will not copy it
04:49:51 <simon_> danr: i will take a look on mapM, what i try to do is from a list of brainfuck code i want to map each char to a few lines of assembly, when i do this i have to use a new id on every temp variable i create, so for every characher i do map on, i also want to know what was the latest id i used so i can continue to create them from that value
04:55:06 <simon_> danr: i dont complety understand what mapM do, but from what i found on google its not what I try/want to do
04:57:09 <simon> simon_, have you tried to translate every brainfuck-instruction into C code?
04:57:10 <jel> Could someone explain 4 in x * x?   Obviously it applies 4 as x, but why's it called "in"?  What's the logic of assigning it to x vs. y in 4 in x * y?
04:57:19 <ski> @type Control.Exception.catchJust (\e -> guard (isUserError e) >> Just (ioeGetErrorString e))
04:57:20 <lambdabot> Not in scope: `isUserError'
04:57:20 <lambdabot> Not in scope: `ioeGetErrorString'
04:57:26 <ski> er
04:57:29 <ski> @type Control.Exception.catchJust (\e -> guard (System.IO.Error.isUserError e) >> Just (System.IO.Error.ioeGetErrorString e))
04:57:30 <lambdabot> forall a. IO a -> (String -> IO a) -> IO a
04:57:33 <ski> k0ral ^
04:57:44 <jel> Ahh, I see, let x = 4 sets it, then in x*x is expr 2?
04:57:47 <simon> simon_, maybe finding an assembly-code equivalent to that C code makes sense.
04:58:09 <Borgvall> simon_: you are maybe looking for zipWith in combination with iterate.
04:58:16 <simon> simon_, although if you compiled the C code with clang, you'd get LLVM bytecode anyway. ;-)
04:58:28 <Borgvall> something like: zipWith idBftoAssembler (iterate nextID foo) brainfuck
04:58:35 <jel> So let x=4 in x*x is like setting x for the duration of the next expression, like shell's X=4 somecommand
04:58:36 <jel> ?
04:58:40 <k0ral> ski: looking at that
04:59:03 <srhb> jel: Yes, consider x an alias of 4
04:59:04 <ski> k0ral : if you're just wanting to catch `error' calls from `Network.Browser.request', then it might be even better to figure out the main shape of the error string in that case, and add another guard to the above, so that it doesn't catch other calls to `error' (as it currently does)
04:59:22 <k0ral> ski: it's IOError
04:59:34 <ski> @type System.IO.Error.isUserError
04:59:35 <lambdabot> IOError -> Bool
04:59:40 <ski> @type System.IO.Error.ioeGetErrorString
04:59:41 <lambdabot> IOError -> String
04:59:45 <simon_> simon: generating the llvm assembly is easy, its just to inc. the id of temps due to SSA that is a problem now
05:00:06 <ski> k0ral : yes, so `e' has type `IOError', so it's ll only catch exceptions of that type
05:00:32 <mapreduce> jel: The shell's variables are dynamically instead of lexically scoped.  In Haskell you're not changing anything, you have a new variable called x that only exists during that expression.
05:01:07 <mapreduce> jel: In the shell you're temporarily changing X.
05:01:09 <ski> k0ral : but not every exception of that type is generated by a call to `error', there are also other kinds of `IOError'/`IOException's -- `System.IO.Error.isUserError' guards for those that actually are generated from a call to `error'
05:01:52 <ski> (k0ral : in case the `IOError' is not generated from `error', `System.IO.Error.ioeGetErrorString' appears to just give a string describing the error type `IOErrorType' -- but you don't want that here)
05:02:00 <k0ral> ski: ok I you suggest I specify which kind of IOError is to be catched
05:02:01 <jel> mapreduce: right, makes sense.  So if x is already set, does haskell complain, or silently shadow the previous definition?
05:02:53 <ski> k0ral : yes, i already did that above, but if you know how the string that `Network.Browser.request' passes to `error' is shaped, you can check for that, getting an even more accurate catch
05:03:12 <k0ral> ski: understood, thank you
05:03:29 <ski> yw
05:04:10 <srhb> jel: It shadows the definition in most cases. :)
05:04:15 <ski> k0ral : if the predicate passed to `catchJust' (or `handleJust' or `tryJust', if you prefer) returns `Nothing', then the exception isn't caught, after all
05:05:25 <k0ral> ski: at the moment, my biggest problem is to catch *only* the request errors
05:05:33 <ski> if it returns `Just x' for any value `x' (above the error string, but you might be able to split that down to smaller pieces of information put there by `Network.Browser.request'), then that `x' is passed to the "handler"
05:05:42 <k0ral> ski: I mean, catch is supposed to work on IO, but request isn't
05:05:44 <ski> @type Control.Exception.catch
05:05:45 <lambdabot> forall a e. (GHC.Exception.Exception e) => IO a -> (e -> IO a) -> IO a
05:05:47 <ski> @type Control.Exception.handle
05:05:48 <lambdabot> forall e a. (GHC.Exception.Exception e) => (e -> IO a) -> IO a -> IO a
05:05:48 <jel> Another question :)    If : is for constructing lists from its operands, how come 'a' : 'b' doesn't work?  Why does it need to be 'a' : 'b' : []   ?   I get that there's some sort of type inference and the array type wins, but what's 'a': 'b' trying to do?
05:05:50 <ski> @type Control.Exception.try
05:05:51 <lambdabot> forall a e. (GHC.Exception.Exception e) => IO a -> IO (Either e a)
05:05:52 <ski> @type Control.Exception.catchJust
05:05:53 <lambdabot> forall e b a. (GHC.Exception.Exception e) => (e -> Maybe b) -> IO a -> (b -> IO a) -> IO a
05:05:54 <ski> @type Control.Exception.handleJust
05:05:55 <lambdabot> forall e b a. (GHC.Exception.Exception e) => (e -> Maybe b) -> (b -> IO a) -> IO a -> IO a
05:05:55 <k0ral> ski: so I have to wrap catch on the whole browse function
05:05:56 <ski> @type Control.Exception.tryJust
05:05:56 <lambdabot> forall e b a. (GHC.Exception.Exception e) => (e -> Maybe b) -> IO a -> IO (Either b a)
05:06:08 <Athas> What's the status on adding bang patterns to Haskell Prime?
05:06:27 <mm_freak> absence: check out 'after'
05:06:42 <k0ral> ski: that sucks because then my errorHandler's signature depends on the last action performed on browse, which isn't generic
05:06:48 <jel> : is just like .append, I assume?  So it finds whichever of 'a' : 'b' : [] supports append and then applies the rest?
05:06:57 <mm_freak> absence: Control.Wire.Prefab.Event
05:07:17 <ski> jel : `:' always combines a single list element on the left with a list on the right. it's not append, it's "put an element at the front"
05:07:31 <ski> jel :  'a' : 'b' : []  means  'a' : ('b' : [])
05:07:35 <jel> ski: ahh, thanks
05:07:42 <ski> `++' is append
05:07:58 <ski> > 'a' ++ 'b'  -- error, `++' takes lists on both sides
05:07:59 <lambdabot>   No instance for (Data.Monoid.Monoid GHC.Types.Char)
05:07:59 <lambdabot>    arising from a use o...
05:08:12 <ski> > ['a','b'] ++ ['c','d','e']  -- ok
05:08:14 <lambdabot>   "abcde"
05:08:51 <ski> > ([0] ++ [1,2,3]) ++ ([] ++ [4,5])  -- also ok
05:08:53 <lambdabot>   [0,1,2,3,4,5]
05:09:03 <ski> > [0] ++ ([1,2,3]) ++ ([] ++ [4,5]))  -- is more efficient, though
05:09:04 <lambdabot>   <no location info>: parse error on input `)'
05:09:19 <ski> > [0] ++ [1,2,3] ++ [] ++ [4,5]  -- means the same as the one just above
05:09:21 <lambdabot>   [0,1,2,3,4,5]
05:11:10 <ski> k0ral : "catch is supposed to work on IO, but request isn't" -- meaning ?
05:11:27 <ski> @type Network.Browser.request
05:11:28 <lambdabot> forall ty. (Network.TCP.HStream ty) => Network.HTTP.Base.Request ty -> Network.Browser.BrowserAction (Network.TCP.HandleStream ty) (Network.URI.URI, Network.HTTP.Base.Response ty)
05:13:09 <ski> k0ral : i'm not sure i understand "so I have to wrap catch on the whole browse function" nor "that sucks because then my errorHandler's signature depends on the last action performed on browse, which isn't generic" either ..
05:13:44 <k0ral> ski: request isn't IO
05:13:52 <k0ral> ski: it's BrowserAction
05:14:34 <k0ral> ski: so I have to write catch errorhandler $ browse ... rather than browse $ do ... ... catch errorhandler request ...
05:19:08 <ski> @hoogle Request a -> IO a
05:19:08 <lambdabot> Network.HTTP.Base rqBody :: Request a -> a
05:19:08 <lambdabot> Control.Exception.Base evaluate :: a -> IO a
05:19:08 <lambdabot> Control.Exception evaluate :: a -> IO a
05:19:22 <hpaste> srhb pasted “Why does this work? (Lazy IO)” at http://hpaste.org/72295
05:19:23 <ski> what's `browse' ?
05:19:47 <ski> (e.g. what's the type of it ?)
05:20:40 <simon_> Borgvall: you might be onto someting, if i understand i correct, zipwith applys an operation on every element list1.N and list2.N.  If I then have one method that calculate how many temps i create for every operation i will get a list like [1,2,2,3,1]. that list then have to be transformed to absolute value of the temps. like this [1,3,5,8,9] (I dont know how to this step). the function generating the assembly will then get 2 parameter 
05:21:27 <srhb> Can anyone tell me why the above paste seems to work as intended despite the fact that I think I am hClosing before I use any of the (lazy?) data.
05:21:38 <srhb> The issue is in grabdata, grabdata is used in getSecret
05:23:03 <Athas> srhb: no, because hGetLine is strict, in a way.
05:23:26 <srhb> "in a way" ?
05:23:36 <Athas> It needs to check whether it has to fail with an error.
05:23:57 <quintessence> simon_: do you have to use 1...N as your temp ids, or can you skip some?
05:23:59 <geekosaur> you may have confused hGetLine with hGetContents
05:24:06 <Athas> Yes, hGetContents is the evil one.
05:24:23 <Athas> All other file-IO functions work pretty much as you'd see in an imperative language.
05:25:19 <srhb> Hmm.
05:27:04 <Athas> srhb: that said, your code is unsafe because it will neglect to close the handle if an exception is thrown.
05:27:28 <srhb> Yes, I was merely testing around, I'll throw a finally somewhere afterwards.
05:27:42 <hpc> @hoogle [a] -> [a -> b] -> b
05:27:43 <lambdabot> Control.Applicative (<**>) :: Applicative f => f a -> f (a -> b) -> f b
05:27:43 <lambdabot> Control.Applicative (<*>) :: Applicative f => f (a -> b) -> f a -> f b
05:27:43 <lambdabot> Prelude map :: (a -> b) -> [a] -> [b]
05:27:47 <hpc> oh, duh
05:28:05 <geekosaur> also, I think the withSocketsDo is needed only in grabData?
05:28:51 <covi> @hoogle when
05:28:52 <lambdabot> Control.Monad when :: Monad m => Bool -> m () -> m ()
05:28:52 <lambdabot> System.Posix.Terminal WhenDrained :: TerminalState
05:28:52 <lambdabot> Test.QuickCheck.Property whenFail :: Testable prop => IO () -> prop -> Property
05:29:23 <srhb> geekosaur: Uh, yes, a leftover from restructuring - thanks.
05:29:51 <simon_> quintessence: did a test when i skiped some, and its not allowed by llvm
05:30:39 <covi> LYAH meantions a 'tell' function when talking about Monads, however:
05:30:42 <covi> @hoogle tell
05:30:42 <lambdabot> Control.Monad.Trans.RWS.Lazy tell :: (Monoid w, Monad m) => w -> RWST r w s m ()
05:30:42 <lambdabot> Control.Monad.Trans.RWS.Strict tell :: (Monoid w, Monad m) => w -> RWST r w s m ()
05:30:42 <lambdabot> Control.Monad.Trans.Writer.Lazy tell :: (Monoid w, Monad m) => w -> WriterT w m ()
05:30:51 <covi> WHich looks daunting to me
05:31:38 <covi> @unodo do { x <- action; x }
05:31:38 <lambdabot> action >>= \ x -> x
05:31:58 <covi> @undo do { x <- action; x }
05:31:58 <lambdabot> action >>= \ x -> x
05:32:05 <covi> @undo { action }
05:32:05 <lambdabot>  Parse error at "{" (column 1)
05:32:22 <covi> @undo { x <- action }
05:32:22 <lambdabot>  Parse error at "{" (column 1)
05:33:04 <ski> srhb : defining `hReadLn :: Read a => Handle -> IO a; hReadLn = readIO <=< hGetLine', you can replace  read `fmap` hGetLine h  with `hReadLn h' (which is not quite the same, but probably better) -- also i think you can replace `return . map snd . toList $ newmap' by `return (elems newmap)'
05:35:00 <ski> srhb : re "Shouldn't this cause problems because of hClose before I actually using packetNum, maxPackets and datum?" the monadic calls to `hGetLine',`hGetChar' are strict in the `IO' state, meaning that they don't monadically return before they've actually extracted the data they monadically return from the I/O state -- so you already have those values "in your hand" at the point of the `hClose' call
05:35:32 <covi> Which prime, below one-million, can be written as the sum of the most consecutive primes?
05:35:35 <ski> (srhb : if you had wrapped any of the three calls before `hClose' in `unsafeInterleaveIO', the situation would have been different)
05:35:44 <covi> What's the functional way to solveing this problem ^?
05:36:11 <srhb> ski: Hang on, does that last bit mean that when I rewrap them in IO, I'm sure that I have the data? But I do that after hClose
05:37:03 <ski> srhb : it seems slightly strange that you get a new `maxPackets' value each time `getSecret' loops around -- is that intended ?
05:37:26 <srhb> ski: No, it isn't, I just had issues abstracting it out because it seems wasteful to do one entire initial call to get maxPackets.
05:37:41 <ski> srhb : no, already after the `packetNum  <- ...',`maxPackets <- ',`datum      <- ...' do you have the data
05:37:43 <srhb> (Of course, I could also seed the map with that initial call)
05:38:01 <ski> why would that be wasteful ?
05:38:03 <srhb> ski: Can you explain once more why it is that I have the data after that?
05:38:11 <srhb> How do you _know_ that?
05:38:40 <ski> (to me, reading a new `maxPackets' each time would seem more wasteful -- and possibly leading to bugs if you're not careful -- i wouldn't do this, though)
05:39:07 <srhb> I agree, it probably is, although I have to get past that line anyway once reading, but I could just throw the data away of course.
05:39:12 <ski> srhb : because, as Athas said, those operations are strict in the I/O state
05:39:19 <srhb> Alright.
05:39:38 <geekosaur> srhb, you are confusing hGetLine, which is strict, with hGetContents
05:42:35 <srhb> ski: Ideally I guess I'd like to remove the recursion from getSecret and use until somehow..
05:42:51 <srhb> ski: And thanks a lot for the feedback :)
05:43:24 <ski> to read a line of character, it has to make sure there is no error occuring before the newline (or end-of-file)
05:44:03 <ski> and by doing that, it reads the characters in the line from the handle into memory, so then it doesn't matter if you close the handle
05:44:21 <srhb> But this shouldn't be the case for hGetChar, should it?
05:44:34 <Athas> It's the case for anything else than hGetContents.
05:44:39 <srhb> Alright, got it.
05:44:40 <srhb> :)
05:44:47 <Athas> Even if you read a single character, you still have to check whether it exists.
05:44:51 <srhb> Right.
05:47:41 <covi> Can I use record syntax with algebraic data types (ones that have several value constructors)?
05:49:16 <Athas> covi: yes.
05:49:58 <Athas> The accessor functions for fields not present for all constructors will be partial, though.
05:50:02 <ski> srhb : i think it would be better if you defined `main' something like `main = print =<< withSocketsDo (getSecret (empty :: Map Int Char))', removing every other call to `withSocketsDo', so that you only call it once
05:50:21 <srhb> ski: Thanks, I had not thought about that.
05:50:55 <ski> srhb : then i think it would also be good to have only one call to `connectTo', or at least call it seldom, instead of recalling it over and over, once for each `datum' (and `packetNum' and `maxPackets')
05:51:42 <srhb> ski: The server closes the connection once those three lines have been sent, so that isn't possible.
05:51:43 <Athas> covi: consider 'data F = A { a :: Int} | B', and the expression 'let x = B in x { a = 2 }'.
05:52:01 <ski> Athas,srhb : s/hGetContents/stuff using `unsafeInterleaveIO'/ :)
05:52:43 <Athas> ski: shh, better not to tell anyone about that possibility at all.
05:54:08 <ski> covi : normally, if you use record syntax at all with multiple data constructors, you'd not use the record-update syntax with a field, unless you *know* it has a data constructor which has that field -- (the best would be to not have to use record-update syntax at all, for those fields)
05:54:28 <ski> srhb : ok, i see. not much to do, then
05:54:41 <srhb> I'm not sure how to deal with the maxPackets.. Should I just grab that first and let getSecret take is as a second argument?
05:54:58 <covi> ski: record-update syntax? what 'record syntax' is short for?
05:55:20 <ski> srhb : but why is the server resending `maxPackets' over and over ? -- is it possible that next time it might send a different `maxPackets' (assuming the size of `newmap' is not `maxPackets' yet) ?
05:55:55 <srhb> It shouldn't send a different amount (or if it did I ought to abort completely, because the secret must have changed)
05:56:12 <srhb> On the other hand the secret can change in a more subtle way, eg. an equal number of packets but a different secret.
05:57:24 <ski> covi : given
05:57:29 <ski>   data F = A {a :: Int   ,c :: String}
05:57:34 <ski>          | B {b :: Double,c :: String}
05:57:55 <srhb> (It's a toy program, so these things don't really matter, I'm more interested in the structure, but I think you gave me a lot to go on. :))
05:58:03 <ski> you can think of `x { a = aValNew }' as being defined as :
05:58:13 <mmaruseacph2> hello, what is i ~ o in a type signature error?
05:58:48 <ski>   (A { a = aValOld , c = cVal }) { a = aValNew } = A { a = aValNew , c = cVal }
05:59:11 <Athas> mmaruseacph2: 'i ~ o' means 'i is o'.  What is the entire error?
05:59:22 <ski> i.e. with no case for the `B' data constructor, so sending such a value as `x' in `x { a = aValNew }' will give you (basically) a pattern-match failure
05:59:43 <ski> otoh, `x { c = cValNew }' would behave as if defined by
05:59:54 <mmaruseacph2> Could not deduce (i ~ o) from the context (Monad m)
06:00:05 <mmaruseacph2> I'll add it there
06:00:16 <mmaruseacph2> but I was interested in a documentation link, if possible:)
06:00:19 <ski>   (A { a = aVal , c = cValOld }) { c = cValNew } = A { a = aVal , c = cValNew }
06:00:19 <ski>   (B { b = bVal , c = cValOld }) { c = cValNew } = B { b = bVal , c = cValNew }
06:00:26 <ski> covi : ok ?
06:01:00 <mmaruseacph2> found it, Type Families
06:01:03 <mmaruseacph2> thanks
06:01:04 <covi> Sorry I don't understand what's going on...
06:01:16 <covi> data JValue = JString { getString :: String } | JNumber { getDouble :: Double } | JBool   { getBool :: Bool }
06:01:29 <covi> See this is what I new end up writing
06:01:51 <covi> and expressions like  getString $ JString "1" works fine
06:02:13 <Saizan> mmaruseacph2: http://www.haskell.org/ghc/docs/7.0.3/html/users_guide/type-families.html#id636192 in particular
06:02:38 <ski> srhb : Should I just grab that first and let getSecret take is as a second argument? -- that's what i would do -- at least if i either could change the server to not pass `maxPackets' each time (only initially, say before the first `packetNum' and `datum); *or* i was sure the server always sent the same `maxPackets' (until that many `datum's has been received, at which point you let the `getSecret' loop terminate anyway)
06:02:57 <mmaruseacph2> thanks Saizan
06:03:33 <srhb> ski: OK, thank you again. :)
06:03:53 <ski> covi : try `getString (JNumber 14)' or 'getDouble (JBool False)' or `getBool (JString "1")', or ...
06:04:35 <covi> ski: "*** Exception: No match in record selector getString
06:04:51 * ski still thinks that the "server closes the connection once those three lines have been sent" is strange
06:04:58 <ski> covi : indeed, and you don't want that
06:05:21 <covi> ski: Couldn't I just avoid this by writing correct code?
06:05:38 <Athas> covi: sure, but the correctness would not be checked by the compiler.
06:05:59 <ski> covi : i would probably just skip the record syntax and the fields there, and just pattern-match (e.g. using `case' if i don't want to define a new function which can pattern-match on argument) to get the `String', the `Double', resp. the `Bool' contents
06:06:00 <srhb> ski: I will rewrite the server. It is a bit stupid. :-)
06:07:30 <covi> ski: a single pattern-match function?
06:07:39 <covi> ski: JValue -> ??
06:11:48 <ski> covi : `case myJValue of JString s -> ..s..; JNumber d -> ..d..; JBool b -> ..b..'
06:11:59 <ski> or, indented on multiple lines :
06:12:03 <ski>   case myJValue of
06:12:07 <ski>     JString s -> ..s..
06:12:15 <ski>     JNumber d -> ..d..
06:12:20 <ski>     JBool   b -> ..b..
06:12:42 <ski> this is the same as calling
06:12:50 <covi> But how do I specify the type of such function's result?
06:12:57 <ski>   myHelper myJValue, if you define
06:13:03 <ski>   myHelper (JString s) = ..s..
06:13:04 <Athas> covi: think of it this way: whenever you want to use your getString/getDouble/etc functions, you first have to pattern-match to detect the value constructor anyway (so you can use the proper function).  Why not use the pattern matching to extract the value you want directly?
06:13:07 <covi> It could be a String, Double, Bool, or others
06:13:08 <ski>   myHelper (JDouble s) = ..d..
06:13:15 <ski>   myHelper (JBool   b) = ..b..
06:13:24 <ski> (sorry, s/JDouble s/JDouble d/)
06:13:56 <covi> Athas: Good reason. Record syntax is now frowned upon?
06:14:19 <Athas> covi: no, it's not.  But record syntax that leads to partial functions (as in your example) is brittle.
06:14:20 <ski> covi : it's frowned upon when one's usign record-update partially
06:14:26 <covi> ski: What is the type of myHelper? myHelper :: JValue -> ?? (I don't know what this is. Or can I just ignore this line?)
06:14:45 <Qtr> Context-free grammar, what does this actually mean(wikipedia doeasnt help). Like 'dry'/logic grammer? Always consistent? Doesnt depend on the 'context' (LDO) it is said but just what is said? So programming languages are context free grammar and nat lang is not?
06:14:46 <ski> (well, as well as field-selection, i.e.)
06:15:10 <ski> covi : and since all your fields in `JValue' are partial -- i would say there's not much point of having those fields there
06:15:22 <Athas> Qtr: it means that a push-down automaton can determine whether a string belongs to the language.
06:15:25 <ski> and removing them, there's no fields left, so you might as well skip record syntax in this case
06:15:50 <Athas> That is, you can process it with a finite amount of states and a stack where only the topmost element is readable.
06:16:16 <Athas> Er, the finite states is not considering stack contents, of course.
06:17:45 <Athas> Many programming languages have context-free grammars, but many do not.
06:17:49 <covi> ski: I see. Thanks. Do you have a github? I'd like to see good practice of record syntax
06:18:02 * hackagebot derive 2.5.10 - A program and library to derive instances for data types (NeilMitchell)
06:18:02 * ski doesn't
06:18:05 <Athas> Haskell doesn't, for example, due to user-defined operator precedence.
06:18:32 <Qtr> I see. C is context free?
06:18:36 <Athas> Nope.
06:18:43 <Qtr> One that is?
06:18:52 <ski> Scheme
06:18:54 <Athas> Lisp.
06:18:55 <Athas> Yeah.
06:19:13 <Athas> Fortran and Pascal too, I think.
06:19:15 <ski> maybe Pascal ?
06:19:17 <ski> ok
06:19:37 <Athas> Python?
06:20:39 <Athas> Really, most languages are very close to being context-free, so you can sort of pretend they are and do some post-processing after the primary parsing step.
06:21:15 <Athas> User-defined operators in Haskell and SML can be more or less ignored in the context-free parser, then dealt with in post-processing.
06:21:47 <mun> hi
06:21:54 <covi> mun: hi
06:22:00 <mun> i have a slightly logic related question: is a first-order function a second-order term?
06:23:05 <Franciman> guess so
06:23:48 <nule> hrm, anybody know how to work around the outdated version of cabal in fedora 17?
06:26:26 <otters> anybody know of a haskell indentation plugin for vim
06:27:23 <Franciman> mun, what's a second-order term specifically?
06:27:57 <mun> Franciman, i guess a second-order expression is one in which no function variable need have functinos as arguments
06:28:02 * hackagebot fay 0.3.1.1 - A compiler for Fay, a Haskell subset that compiles to JavaScript. (ChrisDone)
06:30:35 <mun> i know that the quantification in FOL is limited to atomic terms. but does 'first-order' refer to the highest order of terms quantifiable in the logic or the highest-order of expressions allowed in the logic?
06:31:12 <absence> mm_freak: ah, thanks :)
06:31:33 <Franciman> mun think so
06:32:28 <Qtr> What is a 'glass house for plants' called in english, garden house?
06:32:51 <Clint> greenhouse
06:33:51 <Qtr> ty. Are greenhouses ever opened tp let rain in?
06:34:39 <Franciman> it depends I think, as the owner may also give water to plants by himself
06:35:30 <Franciman> oh english is so cutie: as the owner may also water plants by himself
06:36:40 <confusing> Franciman: milk the cow, water the horse ...
06:37:16 <Franciman> confusing, yeah that's great
06:40:13 <Franciman> confusing, for instance latins thought about it differently
06:40:27 <Franciman> and so in italian water and to water are completely different
06:45:41 <Qtr> in swedish the verb water is different from the noun water
06:45:49 <Qtr> so now you know that!
06:46:21 <donri> waterify
06:46:39 <confusing> wettify
06:47:20 <mapreduce> mojar / agua (Spanish, and somewhat guessing at the verb; mojar just means to make wet, not specifically for plants)
06:47:40 <Qtr> Yo muje mujeres!
06:48:04 <Qtr> (Uh, nevermind)(
06:48:22 <mapreduce> You wom women? (wom isn't a word but then I doubt muje is either)
06:48:52 <Franciman> agua .. lol
06:49:00 <Franciman> acqua
06:49:08 <ski> mun : hm, not sure -- possibly both
06:49:09 <Franciman> ( because we italians like to be poetic )
06:49:24 <Franciman> spanish is a great language
06:49:36 <Franciman> respect to spanish
06:49:55 <mapreduce> acqua would be pronounced as 'aka' in Spanish, so the spelling has to change to keep a similar pronunciation to Italian.
06:50:11 <mun> ski, but what exactly is a 'first-order term'? is it a term of type 'A' or 'A => B'?
06:50:34 <mapreduce> actually that could be wrong, sorry
06:50:45 <Franciman> I don't really know why acqua it's written in this way: acua and aqua ( like in latin ) would sound the same
06:51:03 <Franciman> and in fact it's the only italian word written that way ( along with its derivations )
06:52:04 <Qtr> Can cable-length be a problem for data transmission? Like if i have 30 copper wire instead of what is porbably intended to be 5?
06:52:14 <Qtr> 30meter instead of 5m
06:53:12 <donri> Qtr ski hundskatt donri this channel is being overrun by swedes
06:53:17 <geekosaur> that depends on a number of factors.  like, what kind of cable and what kind of signal (voltage, modulation, etc.)  also to some extent on connectors, which can introduce loss or noise via impedance mismatch
06:53:56 <confusing> geekosaur: i suspect he means ethernet cables
06:54:49 <geekosaur> ah, but which ethernet?  answer is different for 10baseT vs. 10gig copper ethernet ;}
06:54:53 <geekosaur> which was kinda my point
06:58:48 <ski> @type Data.ByteString.Char8.concatMap
06:58:48 <lambdabot> (Char -> BSC.ByteString) -> BSC.ByteString -> BSC.ByteString
06:59:07 <ski> mun : we call that ^ a second-order function/term
06:59:51 <ski> mun : so then `not :: Bool -> Bool' would be first-order, and `False :: Bool' be zeroeth-order
07:00:03 <mun> ski, but isn't a function a second-order term? so doesn't a second-order function mean that it's a function that takes second-order terms as arguments, thus a third-order term?
07:00:36 <confusing> geekosaur: ah i see :) it's just that it sounded so general that it could have meant anything from pots wires to sata cables
07:00:57 <mun> ski, i'm reading http://arxiv.org/pdf/cs/9301104.pdf it says in section 6 that 'For representing first-order logic, second-order expressions suffice...'
07:01:01 <ski> mun : hm, i'm not sure, but i suspect not
07:01:01 <geekosaur> well, it could have indeed.  I thught the query sounded somewhat odd if related to commodity Ethernet
07:01:15 <confusing> agreed
07:01:37 <Eduard_Munteanu> Sounds like the order is going to be the number of arguments, since  e.g.  a -> b -> c == a -> (b -> c)
07:01:50 <mun> ski, so "f::A" is a zeroth order term?
07:02:06 <geekosaur> so the widened response was in part to inidcate that the question was slightly wrong or at least somewhat suspect
07:04:41 <mun> Eduard_Munteanu, but (a->b->c->d) == a -> (b -> (c -> d)). ternary functions are allowed in FOL though.
07:04:51 <neutrino2000> hi
07:05:25 <neutrino2000> is it possible to declare a type in such a way, that i create the instances by processing a literal String, and initial empty lines are purged?
07:05:56 <geekosaur> > read "\n\n  5" :: Int
07:05:57 <lambdabot>   5
07:06:16 <Eduard_Munteanu> Hrm.
07:06:24 <geekosaur> derive Read (and Show for the other direction)
07:06:26 <neutrino2000> for example: i want to have a type Linelen = [Int], and i want each line of the passed string to be counted for characters
07:06:36 <Athas> neutrino2000: that's not really a question of the type, but a question of the function.
07:06:52 <Athas> neutrino2000: map length . map (dropWhile isSpace) . lines
07:07:01 <Athas> Wait, no, that's wrong, I misread.
07:07:08 <Athas> map length . dropWhile null . lines
07:07:12 <neutrino2000> well i want initial empty lines dropped
07:07:15 <neutrino2000> athas yeah
07:07:16 <ski> mun : i was using
07:07:17 <ski>   order `a -> b' = max (order `a' + 1) (order `b')
07:07:21 <ski> with
07:07:36 <ski>   order `a' | baseType `a' = 0
07:07:39 <neutrino2000> i would use that combination for the derivation of Read, yes?
07:07:51 <mun> ski, right. i was thinking order `a' | baseType `a' = 1
07:07:58 <geekosaur> neutrino2000, I thought you were asking a different question, my response is not helpfiul, sorry
07:08:17 <Athas> neutrino2000: I'd advise you to look at the read typeclass.  It's a bit more complex than that, unfortunately.
07:08:18 <mun> ski, so a first-order function is a first-order term to you?
07:08:25 <neutrino2000> ok
07:08:26 <geekosaur> Haskell is not object oriented; types do not have logic built into them, you cannot embed that kind of logic into the type itself
07:08:29 <ski> mun : well, we already call functions like `Data.ByteString.Char8.concatMap :: (Char -> ByteString) -> ByteString -> ByteString' second-order functions
07:08:35 <neutrino2000> gotcha
07:08:37 <confusing> neutrino2000: tell us a little more about what you're planning, folks can give you better advice then
07:09:06 <neutrino2000> i'm not sure what i'm planning yet
07:09:08 <ski> mun : the question then is how the terms `n'th-order *function* and `n'th-order *term* are related
07:09:25 <neutrino2000> but i think you guys helped me figure out what not to do
07:09:28 <neutrino2000> thx
07:09:53 <ski> mun : "a first-order function is a first-order term to you?" -- i'm not sure, but with (afaik) lack of any other convention, saying that might make sense
07:10:48 <mun> ski, so do you disagree with Paulson's "For representing first-order logic, second-order expressions suffice"? it seems if you define baseType `a' = 0, then representing FOL requires only first-order expressions.
07:10:50 <Athas> neutrino2000: the Read typeclass adds complexity in that you have to return the unused remainder of the string (which is probably "" here), as well as deal with operator precedence (which you can ignore).
07:11:16 <Athas> For some reason, Read feels like a half-hearted parser framework.  I'm not really sure what the plan was.
07:11:35 <ski> mun : anyway, if we have `forall x :: a. ..x..' where `a' has order `n' according to the definition above, then i hope you agree that this whole proposition has order at least `n + 1'
07:12:14 <ski> mun : e.g. `forall x :: |N. x > S (S Z)' is first-order
07:13:32 <ski> mun : in fact, possibly
07:13:33 <ski>   order `forall x :: a. ..x..' = max (order `a' + 1) (order `..x..')
07:13:35 <Athas> Actually, does anyone know the history behind the design of Read?
07:13:45 <mun> ski, sure. but S is a first-order term to you, right?
07:13:53 <ski> btw, note that we have two different `order' functions here, one defined on types/sorts, and another defined on propositions
07:14:06 <Soultaker> is there a nice way to write something like: do input :: [Int] <- readLine; that doesn't require enabling a GHC extension
07:14:19 <Soultaker> s/ReadLine/ReadLn/
07:14:30 <ski> mun : it is a first order function -- not sure about the order as a term -- but i'm also not sure whether it matters here
07:14:49 <geekosaur> Athas, it is a halfhearted parser framework.  ReadS is the more detailed version of it.  for practical parsing, monadic and then applicative parsers superseded the ReadS style parser some time bacjk
07:14:59 <ski> mun : what is the order of `s = t' ?
07:15:19 <mun> ski, right. well i'm just trying to understand Paulson's statement there.
07:15:21 <ski> mun : always `0' ? the maximum of the "term order" of `s' and `t' ? one more than that ?
07:15:43 <Athas> geekosaur: it must be really old.  I've been reading about monadic parsers in some of the earliest papers on monads in Haskell.  I know very little about pre-monadic Haskell, though.
07:15:45 <mun> ski, well = is a first-order function.
07:15:56 <geekosaur> Athas, Haskell predates monads
07:16:15 <geekosaur> the earliest versions of Haskell used main :: [Response] -> [Request] -- or some such
07:17:10 <mroman> You mean [Request] -> [Response]?
07:17:38 <mun> ski, actually paulson's statement is: For representing first-order logic, second-order expressions suffice: no function variables need have functions as arguments.
07:18:32 <mun> ski, so he seems to suggest that functions taking functions as arguments are 3rd-order expressions
07:18:45 <geekosaur> oddly enough, no.
07:18:56 <confusing> Soultaker: you could move the ":: [Int]" to one of the following lines, e.g. "print (input :: [Int])". i'm pretty sure that doesn't need ScopedTypeVariables or whatever extension
07:18:57 <geekosaur> mroman:  the Requests are requests to the old I/O engine
07:19:27 <geekosaur> responses come from that.  so the initial input is an unsolicited Response
07:19:28 <geekosaur> see "tackling the Awkward Squad"
07:20:45 <mroman> Ic.
07:21:25 <Soultaker> confusing: what if I don't actually use the value anywhere?
07:22:07 <Soultaker> I guess I could write a function discard :: [Int] -> () or something but that seems so ugly...
07:23:04 <confusing> Soultaker: hm, then you could do "input <- readLn :: IO [Int]". it's a little longer because you have to state the entire type of the readLn function. fortunately it doesn't take arguments
07:23:06 <ski> mun : `=' is a predicate symbol, not a function symbol
07:23:26 <confusing> Soultaker: by the way, if you don't use a value, you can make that clear by saying "_" instead of "input"
07:23:33 <mun> ski, yes, i meant first-order predicate
07:23:35 <Soultaker> confusing: that seems like a reasonable solution to me. Thanks.
07:23:40 <ski> mun : "so he seems to suggest that functions taking functions as arguments are 3rd-order expressions" -- i don't think that follows
07:23:45 <confusing> Soultaker: you're welcome :)
07:24:02 <Soultaker> confusing: true, but using a variable name helps 'documenting' what I've just read.
07:24:21 <Soultaker> ('input' isn't a very descriptive name, of course, but that was just an example)
07:24:43 <geekosaur> Soultaker, a convention we use oin that case is a leading underscore, suggesting the _ anonymous wildcard
07:24:45 <geekosaur> so _input
07:24:54 <Soultaker> ah, that's not a bad idea either.
07:25:18 <confusing> geekosaur: how about the -Wall warnings that say "unused variable"? that's what you can avoid with "_"
07:25:19 <mun> ski, well we know FOL doesn't have functions taking functions as arguments and he says second-order expressions is sufficient to represent FOL. so functions taking functions as arguments are not 'second-order' terms -- so at least 3rd order?
07:25:20 <ski> mun : by "second-order expressions suffice", i think he there possibly meant "second-order proposition" -- and all the quantifiers in a second-order proposition must quantify over at most *first*-order variables (i.e. "no function variables need have functions as arguments")
07:25:47 <geekosaur> GHC actually knows tht convention and suppresses the warning
07:25:54 <geekosaur> (the leading _, that is)
07:26:50 <confusing> geekosaur: oh nice. interesting
07:27:08 <Soultaker> I didn't get a warning before. Do I need to turn those on somehow?
07:27:09 <ski> mun : you're still confusing the order of the proposition/expression with the order of the (quantified) variables in it, i think
07:28:43 <geekosaur> Soultaker, you get it with -Wall or -fwarn-unused-matches
07:28:57 <geekosaur> (there are other kinds of unused variables, -matches is the one that knows about leading underscores)
07:29:39 <Soultaker> I should probably use -Wall.
07:29:47 <geekosaur> typically we just use -Wall instead of turning on individual warnings, and maybe use the inverted -f forms to disable specific warnings (-fno-warn-...)
07:33:47 <ski> mun : consider `forall f : |N -> |N. (exists n : |N. exists p : |N. forall i : |N. f (n + i + p + S Z) = f (n + i)) \/ (forall m : |N. forall n : |N. f m = f n -> m = n)'
07:35:02 <ski> mun : i would say this proposition is second-order *because* it only quantifies over a first-order variable (i.e. having first-order type), but not over any variables of higher order
07:35:02 <ski> mun : do you agree/disagree ?
07:37:02 <ski> mun : how about the following proposition : `forall f : |N -> |N. (exists n : |N. f n = Z) -> f (Search f) = Z' -- where `Search' is a function symbol (not a function variable)
07:37:13 <mun> hmm
07:37:24 <ski> mun : what order would you say this proposition has +
07:37:24 <ski> s/+/?/
07:37:51 <mun> i'd say the first is second-order
07:38:00 <ski> ok. and why ?
07:38:09 <mun> so is the second.
07:38:19 <ski> ok, that's interesting
07:38:34 <mun> ski, because it quantifies over variables of type |N -> |N
07:38:56 <ski> would your opinion on the order of the latter proposition change, if i instead said that `Search' is a function variable ?
07:39:48 <ski> (note that in either case, `Search : (|N -> |N) -> |N', so the type of `Search' has order two)
07:40:21 <ski> mun : so, you seem to (a) not count the order of function *symbols* (and presumably neither that of predicate *symbols*) used in the propostion
07:40:49 <ski> and possibly you also don't count the order of function (or predicate) *variables*, as long as they're not bound in the proposition
07:40:55 <ski> i suppose the latter makes sense, since :
07:41:21 <ski> consider `forall n : |N. n = Z', which has `n = Z' as a subproposition
07:41:30 <ski> the order of the type of `n' is zero
07:41:56 <mun> ski, but going back to paulson's, he suggests that you'd need second-order expressions to represent FOL
07:42:19 <ski> hm, no, that's not a good example
07:42:21 <ski> say instead
07:42:51 <mun> ski, so what elements of FOL actually require second-order expressions?
07:43:02 * ski ponders
07:43:17 <mun> ski, are quantifiers themselves second-order functions?
07:43:37 <ski> mun : i suspect Paulson translate the quantifiers to two second-order function symbols, yes
07:43:55 <ski> mun : does the target language have function abstraction terms ?
07:44:01 <mun> ski, as quantifiers take a FO-term as an argument (body)?
07:44:40 <mun> ski, yes i believe so
07:45:28 <mun> ski, but then, unification for FOL is actually second-order unification, right?
07:46:52 <ski> mun : ok, so then if the translation of `P[x]' is `E[x]', then the translation of `forall x : a. P[x]' would probably be `Pi_a (\x : a. E[x])'
07:47:14 <neutrino2000> is there something which can take a finite list of finite types, and make sure there's only one copy of each?
07:47:32 <ski> with `Pi_a : (a -> O) -> O' being a function symbol in the target language, and `O' being the type that corresponds to propositions
07:47:36 <mun> ski, but then Pi_a would take a function as an argument.
07:47:58 <ski> of course
07:48:27 <ski> `\x : a. E[x]' would be the function that maps any value `x' of type `a' to the value of the expression `E[x]'
07:48:54 <mun> ski, ok. so in a second-order expression, function *symbols* can take functions as arguments but function *variables* cannot?
07:48:54 <geekosaur> :t nub
07:48:55 <lambdabot> forall a. (Eq a) => [a] -> [a]
07:49:02 <neutrino2000> kind of like the unix "uniq" util
07:49:06 <geekosaur> I *think* that's what you mean...
07:49:15 <ski> mun : i'm not sure. but i suspect so
07:49:51 <ski> > nub "mississippi"
07:49:52 <lambdabot>   "misp"
07:50:38 <ski> > group "mississippi"
07:50:39 <lambdabot>   ["m","i","ss","i","ss","i","pp","i"]
07:50:39 <neutrino2000> oh nub thanks
07:50:39 <ski> > (map head . group) "mississippi"
07:50:39 <lambdabot>   "misisipi"
07:50:39 <neutrino2000> i forget you can use hoogle
07:50:51 <neutrino2000> :t head
07:50:53 <lambdabot> forall a. [a] -> a
07:51:22 <ski> `group' gives a list of non-empty lists, so it's safe to use `head', there
07:51:26 <ski> @src head
07:51:26 <lambdabot> head (x:_) = x
07:51:26 <lambdabot> head []    = undefined
07:52:56 <mun> ski, so when unifying expressions in FOL, is first-order unification sufficient? or is the order of unification required n+1 where n is the order of the target logic?
07:54:30 <hpc> > group ::
07:54:30 <lambdabot>   <no location info>: parse error (possibly incorrect indentation)
07:54:30 <hpc> > group ""
07:54:30 <lambdabot>   []
07:54:38 <hpc> oh, in (map head)
07:55:12 <ski> mun : well, at least normally in FOL, there are no variables of type with order greater than zero (iow no function variables) -- specifically neither bound (quantified) nor *free* such variables
07:55:34 <ski> mun : and if there's no such variables, then unification is first-order
07:57:32 <ski> e.g. `x + S y' and `(a + b) + b' (assuming `a',`b',`x',`y' are variables) can unify as `x = a + S y /\ b = S y'
07:58:55 <mun> right
07:59:15 <ski> and `S x + Z' and `Z + z' would not unify at all (unless you're unifying in arithmetic, using arithmetic laws, in which case you'd get `z = S x' as unification solution)
08:02:19 <ski> mun : however, if you e.g. want to unify `f Z' with `Z + S Z' (`f' being a variable, we assume that we don't allow using arithmetic laws in the unification, so pure term unification), then we need to assign a value to the variable `f' which is a (first-order) function, so this is second-order unification, yielding `f = \x : |N. Z + S Z \/ f = \x : |N. x + S Z \/ f = \x : |N. Z + S x \/ f = \x : |N. x + S x' as the four solutions
08:02:31 <ski> (did that get cut off at the end ?)
08:03:54 <mun> um
08:04:48 <mun> that has shown up fine
08:04:55 <mun> ski, how come that's second-order unification
08:05:05 <mun> f is only a first order function
08:05:28 <ski> well, in the `x + S y' vs. `(a + b) + b' example, the variables `x',`y',`a',`b' were all zeroeth-order variables
08:05:37 <ski> and therefore it was first-order unification
08:06:20 <ski> in the `f Z' vs. `Z + S Z' case, the highest order of the variables was one, and so it was second-order unification
08:06:31 <ski> mayhaps there's a better way to think of it, i'm not sure
08:07:24 <mun> ski, so the order of unification is n+1 where n is the highest order of the meta-variables?
08:07:43 <ski> mun : that's how the terminology i've seen appears to me, yes
08:08:24 <ski> (whether there's any deep point to adding one here, or whether it's just an accident of the history of the terminology, i don't know)
08:08:56 <mun> ski, is it n+1 because the order of unification is virtually the order of the unification function?
08:08:58 <BestDeal> Best Deal Ever! Check it out and start making money!  http://cantinhofaro.zeekrewards.com            http://cantinhofaro.zeekler.com
08:09:14 <mun> ski, as in, since the variables are of n, then the unification function takes terms of order n as arguments?
08:09:25 <ski> maybe
08:16:06 <mun> ski, hmm i'm not sure if the terminology is right: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.6700&rep=rep1&type=pdf
08:16:12 * ski tittar frågande på hundskatt
08:16:34 <mun> ski, it says that "We prove in this paper that third order matching is decidable i.e. we give an algorithm that decides if a matching problem, in which all the variables are at most third order, has a solution.
08:16:50 <mun> so the author seems to suggest that the order of unification is simply the highest order of the variables
08:16:56 <mun> without +1
08:17:15 <ski> sounds like that, yes
08:17:38 <ski> maybe they define `x', having type `|N' as being first-order instead of zeroth-order ?
08:18:00 * ski isn't too sure of the terminology here
08:18:10 * hackagebot wai-eventsource 1.2.1 - WAI support for server-sent events (FelipeLessa)
08:18:24 <mun> ski, possibly. that goes all the way back to what we talked about earlier...
08:19:17 * ski is quite tired, needs to sleep ..
08:19:28 <mun> ski, thanks for your time
08:19:32 <ski> yw
08:42:07 <neutrino2000> can i have a function which returns Array's of various bounds and dimensions?
08:42:16 <neutrino2000> i'm not talking about using unions
08:43:03 <parcs`> sure
08:44:53 <parcs`> use an existential type
08:45:02 <neutrino2000> i have no idea what that means
08:45:10 <neutrino2000> but i guess i can make the arrays always three-dimensional
08:45:54 <Athas> neutrino2000: that is simplest, yes.
08:46:01 <merijn> Simple question: data-lens or lens-family?
08:46:08 <Athas> But note that the bounds of an array is not part of the type, so only the dimensionality matters here.
08:46:30 <neutrino2000> yeah i just noticed that
08:46:50 <parcs`> merijn: haven't you been around lately? 'lens' is the hot new lens package
08:47:24 <neutrino2000> is it made by the yesod people
08:47:28 <merijn> parcs`: Yeah, but why? :p
08:48:28 <c_wraith> merijn: because it generalizes to approximately everything.  ask edwardk about it.  Or wait for his series of blog posts on it.
08:48:34 <parcs`> merijn: 'lens' uses the same underlying lens representation as 'lens-family' but the package provides more combinators and is more complete
08:48:40 <neutrino2000> is there some cool literal syntax for arrays of Bool?
08:48:46 <neutrino2000> or of Char?
08:50:38 <merijn> neutrino2000: If you feel horrible you could make them instances of IsString and use the OverloadedStrings extension to use your fancy string serialisation as literal syntax :p
08:50:50 <merijn> neutrino2000: Be warned that other programmers may murder you for this
08:51:20 <neutrino2000> @hoogle [[[a]]] -> Array (Integer, Integer, Integer) a
08:51:20 <lambdabot> No results found
08:51:31 <neutrino2000> @hoogle [[a]] -> Array (Integer, Integer) a
08:51:32 <lambdabot> No results found
08:51:39 <neutrino2000> @hoogle [a] -> Array Integer a
08:51:40 <lambdabot> Data.Array listArray :: Ix i => (i, i) -> [e] -> Array i e
08:51:40 <lambdabot> Data.Graph.Inductive.Graph delNodes :: Graph gr => [Node] -> gr a b -> gr a b
08:51:40 <lambdabot> Data.Array.IArray listArray :: (IArray a e, Ix i) => (i, i) -> [e] -> a i e
08:52:14 <parcs`> merijn: anyway 'lens' and 'lens-family' are cool because you can do polymorphic updates with the lenses and you compose lenses with (.)
08:52:37 <c_wraith> Prelude (.), rather than Category (.)
08:52:44 <neutrino2000> i think i'm looking for listArray
08:52:49 <merijn> parcs`: Please say that I don't have to relearn all the operators I learned for data-lens :p
08:53:28 <parcs`> merijn: lens provides all the combinators from data-lens and more
08:53:58 <merijn> Ah, that's good :)
08:54:04 <neutrino2000> @hoogle i -> [e] -> Array i e
08:54:05 <lambdabot> Data.Graph.Inductive.NodeMap delMapNodes :: (Ord a, DynGraph g) => NodeMap a -> [a] -> g a b -> g a b
08:54:05 <lambdabot> Data.Graph.Inductive.NodeMap insMapNodes_ :: (Ord a, DynGraph g) => NodeMap a -> [a] -> g a b -> g a b
08:54:05 <lambdabot> Data.Graph.Inductive.NodeMap delMapNode :: (Ord a, DynGraph g) => NodeMap a -> a -> g a b -> g a b
08:54:14 <neutrino2000> hrm.
08:54:17 <parcs`> check out http://comonad.com/reader/2012/mirrored-lenses/ for more information
08:55:21 <neutrino2000> parcs`: that's just smoke and lenses!
08:56:14 <c_wraith> the big thing about lens is that it generalizes its combinators to so many more things than just record updates
08:56:19 <ParahSailin> so a lens is just fancier getter and setter?
08:56:38 <confusing> ParahSailin: yes
08:57:04 <c_wraith> like, it contains combinators that create a lens for a particular index in a list, for instance
08:57:35 <ceti331> setters in haskel? how does that work... create copy and modify?
08:57:47 <hpc> c_wraith: sounds like semantic editor combinators
08:57:57 <c_wraith> ceti331: yes, create a new value based on an old one with slight modifications
08:58:15 <ceti331> perhaps there are ways of batching up all the modifications to do at once
08:58:29 <hpc> ceti331: suppose you had "data Foo = Foo {a :: Int, b :: Bool}"
08:58:47 <hpc> and let x = Foo {a = 5, b = False}
08:58:56 <hpc> really, x is (Foo 5 False)
08:59:04 <hpc> now you do a record update
08:59:10 <hpc> let y = x {b = True}
08:59:23 <hpc> what you are really doing is
08:59:24 <jmcarthur> ParahSailin: basically. a lens is basically a pointer into a data structure that allows you to get and set the bit that it points to, and lenses can be composed. so if you have a lens that points to a Bar in a Foo, and a lens that points to a Baz in a Bar, you can compose them to get a lens that points to a Baz in a Foo via a Bar
08:59:27 <hpc> let (Foo a b) = x in Foo a True
08:59:40 <ceti331> is that the actual syntax ... let y = x {b=True}
08:59:51 <hpc> yes
09:00:06 <ceti331> sugar?
09:00:09 <hpc> yes
09:00:36 <hpc> though slightly lower-level than say, do-notation sugar
09:01:18 <hpc> in addition to the record updating you get accessor functions
09:01:24 <hpc> a :: Foo -> Int
09:01:34 <hpc> a (Foo x y) = x
09:01:54 <hpc> a _ = error "something about record field not existing for other constructors if you have any"
09:02:07 <ceti331> ah, one problem i was finding with my limtited haskel from c knowledge is,  when declearingmultiple "records",its not letting me use the same member names
09:02:10 <merijn> ParahSailin: Fancier, *composable* getter and setter :p
09:02:24 <hpc> ceti331: yeah, and this is why
09:02:30 <hpc> you don't end up with one single type for 'a'
09:02:30 <merijn> ceti331: Yes, that's an often bikeshedded issue
09:02:38 <ceti331> bikeshedded?
09:02:51 <hpc> ceti331: everyone has their own solution, basically
09:03:11 <merijn> ceti331: You can google the origin of the term, but in short: No one argues about the design of thermonuclear reactors, but everyone has an opinion on the colour of its bikeshed.
09:03:16 <ceti331> doesn't lisp qualify getters with record name Foo-get-a Bar-get-a etc
09:03:37 <ParahSailin> merijn, thanks learned a new word today
09:03:40 <merijn> ceti331: If you define your records in a separate module you could use qualified imports to get that effect
09:03:49 <hpc> lisp isn't a single language, and many of them implement OOP with macros
09:03:51 <ceti331> ah
09:03:56 <hpc> so really, it's whatever the macro does
09:04:00 <ceti331> thats not SO baad
09:04:27 <ceti331> but from C++ i was expecting overloading to handle it :)
09:04:29 <confusing> ceti331: there's various proposals how to solve that, but no consensus yet
09:04:49 <ceti331> this is possibly what people mean when they say "records in haskell aren't great"
09:04:55 <merijn> ceti331: Yeah
09:05:02 <hpc> the proposals range from hackish things like type-directed name resolution
09:05:17 <hpc> to huge sweeping changes to the type system, like using Ur's row types
09:05:28 <ceti331> well i did used to code in asm where i didn't really have classes, just pointers and equates for offsets i guess ...
09:07:19 <ceti331> so trying to setup vec maths, i found how to make a Vector3<T> { T x,y,z;} equivalent but was still struggling to make general purpose operators
09:07:37 <ceti331> that i would have donewith templated helper functions or methods in c++
09:07:54 <hpc> well
09:07:59 <hpc> assuming something like
09:08:10 <hpc> data Vector3 a = Vector3 a a a
09:08:16 <merijn> ceti331: Vectors would be a good candidate to get an instance of the Num typeclass
09:08:18 <ceti331> i was trying to make class based "Point" (3 elem vector with implicit W=1) and "vector" 3 elem vector with implicit W=0) ,the W carried as compile time type information
09:08:18 <hpc> you would do stuff like
09:08:34 <hpc> magnatiude :: Num a => Vector3 a -> a
09:08:35 <ceti331> of course when i say Vector i mean as in 3d math not as in collection
09:08:45 <merijn> instance Num a => Num (Vector3 a) where...
09:09:02 <ceti331> although another good way in c++ to do a 'maths vector' is an std::array :)
09:09:24 <ceti331> a "Num" is a builtin/standard typeclass ?
09:09:28 <hpc> merijn: does that follow enough algebraic laws to make sense as an instance?
09:09:29 <merijn> Or maybe a slightly less broad typeclass, but that'd allow you to overload all operation in that typeclass
09:09:45 <ceti331> hpc: the problem is Vector3 * Vector3 ..
09:09:47 <hpc> ceti331: it's not built-in, but it's part of the spec and special things get done with it
09:09:49 <ceti331> i dont wnt that
09:09:58 <hpc> ceti331: cross product :P
09:10:11 <ceti331> i want 'dot' and 'cross' functions, not *
09:10:15 <merijn> ceti331: There's a bunch of numeric typeclasses in the prelude. Num, floating, complex, integral, etc.
09:10:31 <ceti331> i want * undefined...or i usually use Vector *Scalar for componentwise scaling
09:10:47 <hpc> ceti331: the latter doesn't work, sadly
09:10:49 <hpc> :t (*)
09:10:51 <lambdabot> forall a. (Num a) => a -> a -> a
09:10:57 <ceti331> oh also... i like having a vector class that maps onto SIMD instructions
09:11:02 <hpc> gotta have two arguments of the same type, then produce an element of that type
09:11:03 <ceti331> i mean a float4 type
09:11:16 <ceti331> that wraps the hardware __mm128 intrinsics
09:11:25 <merijn> ceti331: Alternatively, you can define functions as follows: "cross :: Num a => Vector3 a -> Vector3 a -> a"? (at least, I guess you want a as a return value there?)
09:11:35 <hpc> merijn: that's dot
09:11:51 <merijn> It's been a while since linear algebra, ok? ;)
09:11:51 <ceti331> in C++ you can make classes to do fancy things like AOSOA .. batches of 4 .. for effieicnt SIMD
09:11:55 <hpc> ;)
09:12:23 <ceti331> cross :: Num a => Vector3  a-> Vector3  a-> Vector3 a
09:12:35 <ceti331> dot :: Num a => Vector3 a -> Vector3 a -> a
09:12:38 <ceti331> ok
09:12:39 <merijn> That should work, yes\
09:12:43 <ceti331> let me try that now...
09:13:11 <hpc> then when you want to use cross/dot, there's backtick notation
09:13:11 * hackagebot wai-eventsource 1.2.1.1 - WAI support for server-sent events (FelipeLessa)
09:13:13 * hackagebot cmdargs 0.9.6 - Command line argument processing (NeilMitchell)
09:13:15 <hpc> @src subtract
09:13:15 <lambdabot> subtract x y = y - x
09:13:21 <hpc> > 5 `subtract` 1
09:13:22 <lambdabot>   -4
09:13:38 <merijn> Subtract might be a bad example, with its reverse order ;)
09:13:41 <hpc> (translates to subtract 5 1)
09:13:43 <hpc> heh, yeah
09:13:49 <hpc> @let add x y = x + y
09:13:51 <lambdabot>  Defined.
09:13:51 <merijn> > 1 `elem` [1..10]
09:13:52 <lambdabot>   True
09:13:54 <hpc> 5 `add` 5
09:13:56 <ceti331> just to check:  :: Num a =>  specifies that 'a' must satisfy conditions defined by 'Num' ?
09:13:57 <shapr> Good Morning #haskell!
09:13:57 <hpc> > 5 `add` 7
09:14:00 <lambdabot>   12
09:14:01 <merijn> ceti331: Yes
09:14:03 <ceti331> type restricttiono?
09:14:22 <hpc> ceti331: in haskell terms, specifies that 'a' is an instance of 'Num'
09:14:28 <merijn> ceti331: It says your function is defined for all a's which provide implementation of them Num functions
09:14:51 <merijn> You'll see that for example (+) and (-) are defined in terms of Num
09:14:53 <merijn> :t (+)
09:14:53 <hpc> (don't confuse it with say, java's definition of "instance")
09:14:54 <lambdabot> forall a. (Num a) => a -> a -> a
09:14:57 <merijn> :t (-)
09:14:58 <lambdabot> forall a. (Num a) => a -> a -> a
09:15:04 <hpc> @src Num
09:15:04 <lambdabot> class  (Eq a, Show a) => Num a  where
09:15:04 <lambdabot>     (+), (-), (*)           :: a -> a -> a
09:15:04 <lambdabot>     negate, abs, signum     :: a -> a
09:15:04 <lambdabot>     fromInteger             :: Integer -> a
09:17:00 <merijn> Fun fact, you could define a Num instance for something like String (silly, but you could) and immediately your vector operations would support cross product and dot product of vectors of Strings without modification :)
09:18:54 <ceti331> ok that worked thanks
09:19:23 <hpc> more fun fact: you can define a Num instance for functions
09:19:32 <hpc> @let one = sin**2 + cos**2
09:19:33 <lambdabot>  Defined.
09:19:38 <hpc> > map one [1..10]
09:19:40 <lambdabot>   [1.0,NaN,NaN,NaN,NaN,NaN,0.9999999999999999,NaN,NaN,NaN]
09:19:49 <hpc> o.O
09:20:11 <hpc> oh, probably defaulted to Float or something
09:21:11 <ion> @type one
09:21:12 <lambdabot> forall a. (Floating a) => a -> a
09:21:30 <ion> > typeOf (map one [1..10])
09:21:32 <lambdabot>   [Double]
09:22:18 <hpc> > map one [1..10] :: [Rational]
09:22:20 <lambdabot>   No instance for (GHC.Float.Floating GHC.Real.Rational)
09:22:20 <lambdabot>    arising from a us...
09:22:20 <hpc> > map one [1..10] :: [CReal]
09:22:20 <ion> > map one [1..10] :: [CReal]
09:22:20 <lambdabot>   [1.0,*Exception: log of negative number
09:22:20 <lambdabot>   [1.0,*Exception: log of negative number
09:22:20 <hpc> heh
09:22:20 <hpc> ooooh
09:22:24 <ceti331> is [1,2,2,3] an array supporting array indexing
09:22:30 <hpc> no
09:22:32 <hpc> it's a linked list
09:22:36 <Athas> > sin
09:22:37 <lambdabot>   Overlapping instances for GHC.Show.Show (a -> a)
09:22:37 <lambdabot>    arising from a use of `...
09:22:42 <DMcGill> and the index operator is !!
09:22:46 <ceti331> is that [a] too
09:22:53 <DMcGill> > [0,1,2,3] !! 2
09:22:54 <lambdabot>   2
09:22:58 <hpc> (!!) is O(n) though, so you don't want to go crazy with it
09:23:01 <ceti331> ouch
09:23:04 <hpc> > [1..] !! 1000000000
09:23:07 <merijn> ceti331: Yes, [a] is a linked list. There are proper arrays too, though if you need them
09:23:08 <lambdabot>   mueval-core: Time limit exceeded
09:23:23 <hpc> arrays tend to be indexed with (!)
09:23:26 <ceti331> is it possible for haskell's compile time analysis to figure out when it can be an array :)
09:23:35 <DMcGill> also Sets have log(n) insertion and access
09:23:39 <ceti331> linklists are horendous on modern cpus
09:23:49 <hpc> ceti331: no - there's much you can do with linked lists that depends on their linkiness
09:23:54 <Athas> ceti331: it can always be an array.  No Haskell compiler does any optimisation like that to my knowledge, though.
09:23:57 <ksf> what was the name of that filepath package that doesn't use strings?
09:24:05 <DMcGill> bytestring?
09:24:09 <DMcGill> ah, sorry
09:24:12 <hpc> for instance, infinite list!
09:24:13 <DMcGill> no idea
09:24:14 <hpc> > [1..]
09:24:15 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
09:24:23 <ceti331> linklists and parallelism dont mix
09:24:37 <ceti331> linklists and caches dont mix either
09:24:46 <DMcGill> note too that the linked lists are immutable
09:24:48 <ksf> ah, system-filepath
09:25:30 <merijn> ceti331: That's mostly micro-optimisation though
09:25:30 <c_wraith> on the plus side, linked lists in haskell don't always require links.
09:25:31 <hpc> ceti331: at least with GHC, the operational details of a given piece of code will be /wildly/ different from what you are used to
09:25:31 <DMcGill> and that lazy evaluation means you can traverse a linked list without calculating every element
09:25:31 <Athas> merijn: no, the problems with linked lists with respect to parallel programming are deep and significant.
09:25:47 <ceti331> i figure its more like templated coding but on steroids
09:25:48 <ksf> in my case, I'm spending lots of time in compare and ==
09:25:49 <merijn> Athas: I disagree, what would the problem be?
09:25:50 <hpc> Athas: they're not that deep
09:25:53 <Athas> You can't even do a parallel scan on a linked list, which is the building block of much parallel functional programming.
09:26:03 <hpc> "data parallelism bottlenecks on traversing the list"
09:26:04 <hpc> there, done
09:26:21 <Athas> hpc: alright, but it affects a lot of the techniques we have available.
09:26:22 <c_wraith> it's true, lists are not the one true data structure.
09:26:26 <Athas> That's what I meant by "deep".
09:26:28 <merijn> Athas: You're just saying "lists are a bad data parallel access", in which case, use arrays
09:26:35 <ceti331> arrays are much better for data-parallelism; however i can see that you can express an algorithm and leave it up to implementation to choose
09:26:39 <c_wraith> But they're really, really good control flow structures.
09:26:43 <hpc> Athas: with plain old multithreading, you have to traverse the list anyway to spawn threads
09:26:44 <c_wraith> lists are loops
09:27:03 <merijn> ceti331: There's Data.Array for arrays and also a vector package that's highly optimised for data parallelism, afaik
09:27:22 <hpc> i heard vector was still quite rough?
09:27:30 <ceti331> 'vector' as in collection?
09:27:35 <ceti331> (i hate that name in c++..)
09:27:41 <DMcGill> the repa array library is also designed for parallelism
09:27:44 <ceti331> (i learned 3d maths before c++ :) )
09:28:03 <DMcGill> no, the vector package is arrays too
09:28:05 <merijn> In short, don't use lists for things that lists aren't good for and everyone will be fine :)
09:28:15 <DMcGill> those are the three array packages in Haskell: Data.Array, vector and repa
09:28:18 <hpc> c_wraith summed it up nicely
09:28:18 <Athas> ceti331: lists and arrays have very different performance characteristics.  It is unlikely that you would express an algorithm without being very clear on what the underlying structure is like.
09:28:21 <hpc> "lists are loops"
09:28:23 <ceti331> in c++ there is std::array<T,3> which makes a good basis for a 'maths vector' e.g. array<float,3>
09:28:27 <DMcGill> all contain mutable and immutable, boxed and unboxed arrays
09:28:38 <ceti331> and there's std::vector<T> which is what i call a "Dynamic Array" :)
09:28:42 <ceti331> i hate that naming
09:29:07 <ksf> binary instances for text?
09:29:12 <merijn> ceti331: Well, in haskell it can't be dynamic, so that part is out :p
09:29:16 <ceti331> Athas: with templates you can express an algorithm and ask for an array implementatin or a list implementation
09:29:19 <hpc> ceti331: there's a somewhat mathematical motivation behind it, if you squint
09:29:34 <hpc> in that a vector is a collection of n items, for some n
09:29:46 <Athas> ceti331: yes, and in most cases, one of those two choices is always the best.  So why have the choice?
09:29:47 <hpc> for instance, in Agda, you can have types that depend on values
09:30:02 <ceti331> merijn: dynamic can also mean non-compile time constant size which haskell can do i presume.
09:30:05 <hpc> which lets you say "here's a vector of 3 elements, here's a vector of 4, here's a vector of (n + 1) elements"
09:30:48 <ceti331> merijn: when doing my own nonstandard c++ collection classes, i ususally have "FixedArray<T,N>", "DynamicArray<T>" (opt for resizing..) and "Array<T>" (opt for setting size on create, but not resizing)
09:30:59 <Athas> ceti331: that said, there are some generic algorithms that work on a wide variety of data structures, and Haskell supports that as well.  Look at the Functor and Traversable typeclasses, for example.
09:31:01 <ceti331> "FixedArray<T,N>" is std::array<T,N>
09:31:03 <hpc> linear algebra, et al overload the term "vector" to mean "3-vector"
09:31:48 <ceti331> i much prefer using the term 'vector' for linear algebra sense (compile time size) and 'array' for collections
09:32:06 <ceti331> but c++ std:: is exactly backwards :(
09:33:01 <ceti331> what does instantiating arrays look like in haskell
09:33:14 * hackagebot imm 0.3.0.0 - RSS-to-maildir tool (koral)
09:33:23 <c_wraith> there's no syntax for it.  it looks like function calls
09:33:23 <DMcGill> listArray (0,5) [0..4]
09:33:33 <ceti331> lets say i want equiv of sepples'  class Mesh { vector<Point> points; vector<Triangle> triangles; }
09:33:38 <DMcGill> for example, this is the Data.Array library
09:34:07 <ceti331> how do i express 'Mesh'  in haskell
09:34:39 <ceti331> data Mesh = ?
09:35:35 <hpaste> DMcGill pasted “Mesh” at http://hpaste.org/72299
09:35:47 <Athas> The best part about Haskell arrays is that you can use interesting types for its indices.
09:35:50 <Athas> listArray (ReadMode,ReadWriteMode) [0..]
09:35:52 <DMcGill> that's one dimensional, to increase just replace the "Int" with, say, "(Int, Int")
09:35:59 <ceti331> thanks
09:36:22 <DMcGill> I really recommend you read LYAH
09:36:22 <ceti331> point :: Array Int Point, nice
09:36:29 <DMcGill> Algebraic Data Types like that are pretty basic Haskell
09:36:54 <ceti331> is that Array INDEXTYPE ELEMENTTYPE
09:37:00 <DMcGill> note too that the name of the type "Mesh" and the constructor "Mesh" are in different name spaces
09:37:03 <DMcGill> yes
09:37:14 <DMcGill> the index type must be a member of the Ix typeclass
09:37:24 <ceti331> in 'sepples' my custom collectionclasses would have ooptional index type.. default =int
09:37:26 <DMcGill> see http://hackage.haskell.org/packages/archive/base/latest/doc/html/Data-Ix.html
09:37:46 <DMcGill> there isn't that in Haskell, but it's no great hardship to be explicit
09:37:48 <ceti331> becomes more important with 64bit machines... want to specifiy when 32bit indices are enough
09:38:12 <DMcGill> the vector package can only use Int I believe, it's faster though
09:38:33 <merijn> ceti331: There's Word8,Word16,Word32,Word64 for that kind of precision, if you want it. Although whether that's worth it is another question
09:38:55 <Athas> Those are still lifted, aren
09:38:57 <Athas> Those are still lifted, aren't they?
09:39:03 <ceti331> Int=32bit?
09:39:05 <Athas> The space savings are going to be small, if they're there at all.
09:39:05 <DMcGill> so you'd have "points :: Vector Point"
09:39:12 <Athas> ceti331: implementation-defined.
09:39:21 <ion> ceti331: and potentially less than 32 bits
09:39:22 <Athas> I think it's 30 bits on GHC 32-bit.
09:39:30 <Athas> Maybe 31 bits...
09:39:32 <hpc> no, 30 is the minimum
09:39:40 <hpc> GHC does 32
09:40:06 <DMcGill> > (maxBound :: Int) `logBase` 2
09:40:06 <Athas> Oh, right, since it's lifted anyway...
09:40:06 <lambdabot>   No instance for (GHC.Float.Floating GHC.Types.Int)
09:40:06 <lambdabot>    arising from a use of...
09:40:06 <ion> > (logBase 2 . fromIntegral) (maxBound :: Int)
09:40:06 <monochrom> GHC Int gives you the full word length by using two words
09:40:06 <merijn> Easy to check
09:40:07 <lambdabot>   63.0
09:40:29 <merijn> > (maxBound :: Word32) > (maxBound :: Int)
09:40:29 <lambdabot>   Couldn't match expected type `GHC.Word.Word32'
09:40:29 <lambdabot>         against inferred typ...
09:40:44 <DMcGill> of course, that's only for the compiler that lambdabot is using
09:40:49 <ceti331> 30,31,32bit ints ... is there a bit reserved for compile time type info or something
09:40:49 <merijn> > fromIntegral (maxBound :: Word32) > fromIntegral (maxBound :: Int)
09:40:49 <lambdabot>   False
09:40:58 <ion> merijn: lambdabot is running on a 64-bit system.
09:41:12 <ceti331> is there a guide "Haskell for C++ coders"
09:41:13 <merijn> ceti331: That is allowed by the standard, yes
09:41:16 <Athas> ceti331: it's somewhat common to reserve a bit for the mark bit when doing garbage collection, and possibly another bit for type-tagging.
09:41:23 <DMcGill> @where lyah
09:41:33 <lambdabot> http://www.learnyouahaskell.com/
09:41:33 <ion> ceti331: Yes: “forget everything about C++”
09:41:33 <ion> ceti331: “and then read LYAH”
09:41:35 <DMcGill> it's not strictly for C++ coders
09:41:40 <ceti331> ion: haha
09:41:49 <Athas> I prefer Real World Haskell.
09:42:13 <ceti331> ion: i really mean... a guide written that assumes you've been coding c++ all your life, and explains everything in c++ analogies and "how this is different inC++"
09:42:33 <monochrom> I have a guide for "Haskell for C++ programmers" too, but people have problem executing it. set up a virtual machine in your brain. learn haskell there.
09:42:34 <DMcGill> try lyah, do the exercises
09:42:36 <DMcGill> you'll be fine
09:43:03 <monochrom> it is also for PHP programmers
09:43:04 <ion> ceti331: Something like that probably doesn’t exist, but feel free to ask on this channel whenever you feel like that kind of a comparison for something would be helpful.
09:43:28 <EmilyS> I found LYAH to be severly lacking in real programs, it was very hard to piece together the bread crumbs into something meaningful
09:43:42 <ceti331> seems like the fine granulairy of information possible on the web would suit how to explain X for someone familiar with Y :)
09:44:03 <merijn> EmilyS: RWH should help with that
09:44:20 <merijn> EmilyS: But RWH skips some over the finer details, which often causes confusion for people
09:44:30 <monochrom> I know how to write a table of C++-Haskell analogies. it's pretty easy actually
09:44:33 <merijn> I usually recommend reading LYAH first, RWH second
09:44:38 <Athas> ceti331: it's not too useful to explain Haskell in terms of C++, since the languages are so very different.
09:45:04 <monochrom> C++ int is not like Haskell Int. C++ function is not like Haskell function. C++ void is not like Haskell (). C++ class is not like Haskell class.
09:45:29 <hpc> in conclusion, C++ is not like Haskell
09:45:39 <nurpax> Anyone know if there are good sqlite bindings that'd have a nicer high-level API like postgresql-simple?  I'm not very happy with hdbc-sqlite or sqlite packages
09:45:44 <ceti331> ultimately haskell must produce ASM - and C++ is shorthand for C, is shorthand for ASM
09:46:02 <Athas> ceti331: no, that is wrong.
09:46:04 <nurpax> feels like sqlite would be the first choice for many programs needing to persist data, but seems like that's the hardest to use in Haskell
09:46:17 <monochrom> anyway we were through this just a few days ago
09:46:21 <merijn> ceti331: I disagree that C++ is shorthand for C (also with C being shorthand for ASM, btw :p)
09:46:26 <hpc> nurpax: check out acid-state
09:46:31 <Athas> And it would not be useful to explain Haskell in terms of how it is compiled.
09:46:38 <ceti331> merijn: thats definitely how i've learned them
09:47:09 <Athas> C is more or less analogous to an early 70s minicomputer.  Modern machines are very different.
09:47:12 <ceti331> merijn: i coded ASM in my formative years - when i coded in C, initially it was with void*'s  and casting and raw datastructures :)
09:47:15 <monochrom> you don't write C code to do stack smashing. but GHC generates stack-smashing code
09:47:18 <nurpax> hpc: I have checked it out - but I'd like to use sqlite.  I need the data to be accessible from multiple languages.. and I found acid-state to be quite scarcely documented.
09:47:20 <Athas> C doesn't even have an intrinsic concept of SIMD!
09:47:29 <ceti331> then i learned the convininent ways C has for expressing what ASM can do.
09:47:37 <BMeph> ceti331: "<ceti331> ultimately haskell must produce ASM - and C++ is shorthand for C, is shorthand for ASM" - these statements alone are a good argument for you not to learn things about any other PL in terms of C++. :/
09:47:46 <Athas> C is more like the machine language of the modern Unix virtual machine.  It reflects the memory model, sort of, and that's it.
09:48:04 <DMcGill> I've always thought that C (and ASM) is about expressing our ideas in terms of what the computer can do while Haskell is about doing what we want to and letting the compiler sort it out
09:48:11 <ceti331> Athas: C is used in contexts very closely with ASM  , with intrinsics
09:48:27 <hpc> ceti331: everything is run on a CPU, therefore Skype == Firefox
09:48:29 <ceti331> C coders have tricks like __restrict to control the asm produced
09:48:31 <DMcGill> rather than evolving from need, the commitee took a step back and designed a language
09:48:31 <hpc> :P
09:48:32 <merijn> Athas: Not if you do dirty things with mmap, TLBs and caches :D
09:48:36 <monochrom> hpc++
09:48:37 <ion> C++ return is not like Haskell return
09:48:40 <ceti331> hpc: thats very far from what i'm saying.
09:48:57 <monochrom> it's very close
09:48:58 <ceti331> hpc: the point is, i can know how i want to do something in ASM - then write it more concisely in C++
09:49:07 <ceti331> monochrom its miles off.
09:49:14 <monochrom> such as stack smashing?
09:49:15 <ceti331> now i'm not saying Haskell is C++...
09:49:33 <DMcGill> if you really want, copy some examples from LYAH and then look at the ASM produced
09:49:37 <ceti331> i'm saying.. you should be able to explain what datastructures are producted and explain in terms familiar to an ASM->C->C++ coder
09:49:50 <ParahSailin> thats kinda what bugs me about haskell, is that i have no idea how well it's gonna optimize given code for performance
09:49:51 <DMcGill> it's even compiled into a C like language, you could have a look at that too
09:50:03 <ceti331> thats more like it...
09:50:05 <Athas> merijn: C doesn't reflect those things at all.  That's all through extensions, like the Unix system call interface.
09:50:07 <monochrom> I'm fine with the ASM part. I have seen the ASM code generated
09:50:16 <BMeph> Athas: Specifically, a virtual PDP. Whether it's -7 or -11, I'm not sure anymore.
09:50:21 <DMcGill> ceti133: you seem to be missing the point of a high level abstract language
09:50:22 <ceti331> if its a metaprogramming language..you want to be able to reason about the code it will produce
09:50:42 <ParahSailin> on an imperative language, i have a general idea of what declarations are gonna translate to in machine code
09:50:44 <ceti331> DMcGill: i dealt with games programming, low level mattered.
09:50:49 <monochrom> the ASM code generated cannot be done in C, emphatically
09:51:07 <Athas> ceti331: if you want to understand Haskell at that level, you should read the paper about the Spineless Tagless G-machine.
09:51:13 <ceti331> monochom: i find that hard to beleive...
09:51:13 <monochrom> even setjmp and longjmp don't come close to what GHC generates
09:51:20 <parcs`> nurpax: i agree that a good sqlite binding is lacking, but there are decent postrgres and mysql bindings -- see postgresql-simple and mysql-simple
09:51:25 <hpc> ceti331: perhaps you would be better off finding a language that compiles to C++ as an intermediate language?
09:51:33 <Athas> ceti331: how?  If GHC uses a SIMD instruction, you're already past what C can do.
09:51:38 <ceti331> monochom: show me a haskel program genearet some ASM that C cannot
09:51:46 <ceti331> Athas: C can use SIMD
09:51:56 <Athas> ceti331: only because the compilers have a huge back of tricks.
09:51:59 <jmcarthur> ceti331: look into the stg machine. it's quite a different execution model from C
09:52:01 <Athas> Or if you use inline assembly.
09:52:15 <monochrom> I have seen the code. you haven't. I find it obvious what to beleive.
09:52:17 <ceti331> Athas: yes, inline assembly.
09:52:23 <Athas> ceti331: that's not really C, then.
09:52:37 <ceti331> Athas: sorry - *intrinsics*
09:52:46 <ion> ceti331: Many C compilers don’t support tail calls. (Not that Haskell even does them quite like a C compiler would.)
09:52:56 <ion> s/Haskell/GHC/
09:53:00 <ParahSailin> whats spineless tagless g machine
09:53:00 <nurpax> parcs`: yes, it was exactly postgresql-simple that made me want something better for sqlite.  for my use-cases, I really prefer to have the data stored in a local file without a server.  it's so much handier for small programs that just save some data (as opposed to web apps or similar).  I wonder how much work it'd be to layer a nicer api on top of the 'sqlite' package
09:53:05 <ceti331> ion: gotos... :)
09:53:08 <jmcarthur> ceti331: you could probably write C code that basically does what the stg machine does, but you could not write it in such a way as to emit anything much like the assembly generated by ghc
09:53:32 <ceti331> jmcarthur: if you can do  it in ASM, you can do it in C
09:53:40 <jmcarthur> that's a pretty crazy claim
09:53:51 <monochrom> that's just Turing tarpit
09:54:09 <jmcarthur> ah, yeah, in the Turing tarpit sense, it's true
09:54:21 <ceti331> ok - someone show me some ASM that Haskel can generate that C can't.
09:54:42 <ceti331> it may be more elegant in haskell - sure - but..
09:54:45 <jmcarthur> compile basically any haskell program and you probably have i
09:54:45 <monochrom> "ghc -O2 -ddump-asm yourfile.hs"
09:54:46 <jmcarthur> *it
09:55:05 <ceti331> i do not beleive that.
09:55:05 <Athas> ceti331: if you accept extensions to C (like intrinsics), then that's not possible.  But then, why not just assume a C extension that accepts Haskell code?
09:55:10 <jmcarthur> ceti331: read the stg paper
09:55:12 <ceti331> someone show me a minimal example designed to illustrate the point
09:55:12 <jmcarthur> @where stg
09:55:13 <lambdabot> http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.3729
09:55:20 <Athas> ceti331: Haskell uses self-modifying code to represent thunks.
09:55:26 <Athas> That's not possible in standard C.
09:55:27 <merijn> Athas: You said it just provides some form of memory model, I was trying to point out even that isn't provided once you start mucking around with C code :)
09:55:32 <jmcarthur> ceti331: it's hard to come up with a minimal example because in order to explain it we would have to explain the stg machine
09:55:34 <ceti331> Athas: becuase Haskell wasn't ready on the platforms of interest..
09:56:10 <Athas> Also, as suggested, read the papers on the STG machine.  It's worthwhile, and very interesting, to understand Haskell's execution model, but a very difficult way to learn the language.
09:56:19 <ceti331> Athas: not all machines suit self-modifying code
09:56:22 <ParahSailin> does ghc target mips?
09:56:39 <hpc> ParahSailin: it can target llvm
09:56:40 <jmcarthur> Athas: as far as the self-modifying code thing, isn't it normally just function pointer and closure twiddling?
09:56:41 <merijn> ParahSailin: Spineless Tagless g machine is the execution model for the code generated by GHC
09:56:42 <ceti331> self-modifying code is terrible on machines with harvard cache
09:57:02 <jmcarthur> ceti331: we don't actually support that many architectures
09:57:06 <Athas> ceti331: presumably a Haskell implementation for those would use a different technique.  Which is the point; Haskell does not have an easy mapping to any machine the way C does.
09:57:19 <monochrom> no, GHC doesn't use that much self-modifying code
09:57:22 <Athas> jmcarthur: pretty much, yeah.
09:57:25 <ceti331> good..
09:57:34 <monochrom> I think StablePtr is the only place
09:57:39 <ion> *Haskell* doesn’t use self-modifying code; an implementation of a compiler could choose to.
09:59:03 <jmcarthur> monochrom: wait... how does stableptr use self-modifying code?
09:59:18 <Athas> Related to ion's comment, it's pointless to say that Haskell can generate Haskell that C can't.  It all depends on the compiler.
09:59:19 <ceti331> "explain the stg machine" ... what is that
09:59:37 <Athas> ceti331: the STG, or Spineless Tagless G-machine, is the machine model used by GHC to compile Haskell.
09:59:39 <jmcarthur> @where stg
09:59:40 <lambdabot> http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.3729
09:59:44 <jmcarthur> ceti331: ^^ read that paper
10:00:29 <monochrom> it's a rather long and complicated story. I don't remember the details, but give me a moment
10:00:44 <jmcarthur> monochrom: i could just look into it myself if it's not handy for you
10:02:09 <ceti331> if it existed, this would be the first page of "haskellfor c++ coders". here's a peice of ASM haskell can make that C can't. now here's how to make it..
10:02:50 <ion> That sounds like a horrible way to learn Haskell. :-P
10:02:55 <jmcarthur> ceti331: your demands betray a misunderstanding about what we're saying. please just read the stg paper.
10:03:03 <jmcarthur> it will make more sense after
10:03:12 <jmcarthur> ceti331: ghc'
10:03:14 <jmcarthur> oops
10:03:26 <jmcarthur> ceti331: ghc's calling conventions, etc. just don't make any sense in C
10:04:47 <jmcarthur> ceti331: heck, just compile something like  foldr (++) []  and see what comes out... there's a lot of fun stuff that happens in there due to laziness
10:05:46 <ceti331> jmcarthur, are you telling me that generates a program i can't express another way in C? if you tell me "it expresses it in 1/10th the lines of code" i might beleive you
10:06:12 <ksf> you know, sometimes I *really* want duck typing.
10:06:24 <ksf> like when porting things to Data.Text
10:06:40 <DMcGill> ksf: did you see the simple prelude?
10:06:46 <shapr> ceti331: How would you express [1..] in C?
10:06:47 <jmcarthur> ceti331: in the turing tarpit sense it's all the same, but there is no way to structure the C code that generates assembly of the same structure
10:07:12 <ksf> DMcGill, that won't help me much, the stuff I'm calling isn't prelude stuff.
10:07:13 <ceti331> shapr: i wouldn't, its a tool to generate some C i think?
10:07:17 <DMcGill> it had loads of type-classes to allow you to not care if you had String or Text or what have you.
10:08:15 * hackagebot splot 0.3.4 - A tool for visualizing the lifecycle of many concurrent multi-staged processes. (EugeneKirpichov)
10:08:23 <jmcarthur> ceti331: implement thunks in C. it's doable, but it won't be especially efficient or pretty in any way
10:08:39 <DMcGill> ksf: http://www.yesodweb.com/blog/2012/07/classy-prelude
10:08:43 <ion> shapr: gen_t gen = gen_enum_from_to(1, INT_MAX); int i = gen_next(gen), j = gen_next(gen);
10:08:51 <ceti331> now you're getting somewhere, "its doable, but it wont be pretty"
10:08:59 <jmcarthur> ceti331: ... or efficient
10:09:01 <DMcGill> it's not prelude only stuff, more an alternate (modern) prelude
10:09:06 <jmcarthur> it's the efficiency i'm getting at
10:10:21 <jmcarthur> ceti331: you still seem to be attached to the whole turing completeness thing (implicitly), whereas I'm merely trying to argue that you can't just make a C compiler spit out whatever assembly is best for the problem at hand, such as this one
10:11:24 <ceti331> thunks.. what do these do that isn't possible with function pointers
10:11:42 <ceti331> also, optimmizing C for caches is about simplifying the flow
10:11:55 <DMcGill> ceti, all your questions would be much better formed if you read LYAH
10:12:20 <DMcGill> arguing in IRC about turing completness isn't going to do anything
10:12:33 <shapr> ceti331: It does sound like you want to understand Haskell in terms of C++. While I'm sure that's possible, it will take much longer to do than learning Haskell on its own.
10:12:33 <jmcarthur> ceti331: a thunk is really more of a closure than a function, and it destructively replaces itself with code that returns its result when you evaluate it.
10:12:46 <jmcarthur> ceti331: it's already hard just to get closures, let alone closures that can modify themselves transparently
10:12:51 <ceti331> isn;t that just a datastructure with a function pointer
10:12:55 <jmcarthur> ceti331: at least, efficiently
10:13:03 <monochrom> at the beginning, you are clearly not appealing to Turing completeness. you said things like C is high-level ASM, which is a claim on bit-by-bit internal correspondence, not just "write an alternative program that gives the same answer"
10:13:04 <ceti331> i mean its loong winded in C.. but ..
10:13:30 <ceti331> i can think how i'd do something in ASM - and modify C to produce that result
10:13:32 <jmcarthur> ceti331: the assembly generated by that long winded C will be far less than ideal, too
10:14:02 <jmcarthur> i'm done. just read the paper
10:14:03 <ceti331> can you show me a small illustrative example, give you have this knowledge and i dont, i can't search for it...
10:14:14 <DMcGill> you can't think "this is some C++ I would write, now let's translate it into haskell"
10:14:24 <ceti331> as far as i know closures are a 'shortcut' for returning a datastructure and a function pointer...
10:14:24 <jmcarthur> ceti331: any example would require an explanation of the stg machine, as i've already said several times
10:14:26 <monochrom> at the end, you see that the internal correspondence is untenable, so you shift to Turing completeness
10:14:28 <DMcGill> (well you could, but it would be horrendous)
10:14:42 <ceti331> jmcarthur, how many lines of ASM are required to show this
10:14:48 <merijn> Can I alias specific function on import? i.e. import foo' as foo?
10:15:03 <jmcarthur> ceti331: it must include bits of runtime, so hundreds at least
10:15:08 <bitonic> merijn: no
10:15:11 <jmcarthur> maybe thousands? dunno
10:15:14 <merijn> bitonic: Aww :(
10:15:24 <monochrom> http://blog.ezyang.com/2011/04/tracing-the-compilation-of-hello-factorial/
10:15:31 <jmcarthur> ceti331: most of those lines are reused throughout the program, of course
10:15:31 <bitonic> merijn: just import the module as qualified
10:15:38 <ion> import qualified Foo; foo' = Foo.foo  -- modulo MonomorphismRestriction probably
10:16:12 <ParahSailin> monochrom, thanks that looks like something i was looking for
10:16:15 <ceti331> lets ask another question... closures - if i understand correctly, are a shortcut for returning a datastructure  (variable capture)?
10:16:26 <ceti331> along with a function-pointer?
10:16:40 <shapr> ceti331: It sounds like you aren't willing to read the paper to try to teach yourself.
10:16:54 <bitonic> ion: the monomorphism restr. is only for `where' declaration, isn't it?
10:17:11 <Adeon> it's annoying to argue with someone who doesn't bother to educate themselves on the relevant material to discussion
10:17:13 <ceti331> shapr: if you already know this you can explain this quicker.
10:17:16 <absence> mm_freak: if i want to "deschedule" the event even later, will i have to make my own wire for that, or will a prefab one do the trick? e.g. "theEventWire . require . arr (\t -> t >= t1 && t < t2) . integral 0" for saying that an event will start at t1 and stop at t2
10:17:17 <Adeon> and possibly disrespectful
10:17:50 <shapr> ceti331: Yes, but if you get into the habit of getting me to teach you rather than reading papers, you can only learn what I know, and I won't get other useful code written.
10:17:56 <jmcarthur> ceti331: no. nobody can explain it more quickly than just reading the paper. there is all sorts of helpful stuff, like code and diagrams. it would take a really long time for a person to write up a good enough explanation
10:18:10 <edwardk> hrmm i need to come up with a name for scanr, etc. that don't include the initial seed in the result. ideas?
10:18:11 <jmcarthur> that's why we have papers
10:18:23 <DMcGill> scanr1?
10:18:26 <ion> bitonic: printf '%s\n' 'foo = 42' >Foo.hs; ghc Foo.hs -e ':t foo'
10:18:26 <edwardk> that can be applied to Traversables or Traversals, but scanr can't
10:18:29 <DMcGill> that's what the folds do
10:18:31 <edwardk> no, scanr1 is taken sadly
10:18:39 <edwardk> by the non-empty scan
10:18:42 <bitonic> ion: OK, I wasn't sure
10:19:19 <shapr> ceti331: http://en.wikipedia.org/wiki/Closure_%28computer_science%29
10:19:20 <jmcarthur> ceti331: you have the gist of closures. a closure is a bit of code that has free variables, packed up with data to fill in those free variables.
10:19:33 <edwardk> scanr (+) 5 [1,2,3,4]   => [15,14,12,9,5]     whateverr (+) 5 [1,2,3,4] => [15,14,12,9]
10:19:47 <edwardk> the latter has the same shape as the original so it can be done on a traversable
10:20:27 <edwardk> its like init . scan, so initScanr might work
10:20:41 <ion> edwardk: scanr卐
10:20:42 <edwardk> er init . scan f z
10:20:49 <edwardk> hah
10:21:13 <ceti331> Callbacks (C)
10:21:13 <ceti331> In C, libraries that support callbacks sometimes allow a callback to be registered using two values: a function pointer and a separate void* pointer to arbitrary data of the user's choice. Each time the library executes the callback function, it passes in the data pointer. This allows the callback to maintain state and to refer to information captured at the time it was registered. The idiom is similar to closures in func
10:21:13 <ceti331> tionality, but not in syntax.
10:21:13 <ceti331> [edit]
10:21:35 <merijn> There's really now nice way to have a top level IORef/MVar without unsafePerformIO, right? I guess I should just create a StateT to pass my state along from main?
10:21:44 <ceti331> can a closure do anything you can't do in C with datastructures and function callbacks. you can tell me "it does it more elegantly" and i'll beleive you
10:21:59 <confusing> merijn: how about implicit params?
10:22:23 <bitonic> merijn: if you need global state for some reason (e.g. FFI with libraries that do) you can
10:23:26 <bitonic> well, you probably need unsafePerformIO at some point, but there are libraries: http://hackage.haskell.org/package/safe-globals
10:23:29 <ceti331> and of course it is something i've wanted in C. it would be great to have syntactic sugar for the creation of the temporary structure.
10:23:46 <ceti331> but C programmers are very used to using structures to group , share , defer the use of data...
10:24:11 <ceti331> its a suitable model for what you'd have done in raw ASM..
10:24:25 <edwardk> i guess i can just start with scanr1, and do the rest later when i have a name
10:24:30 <merijn> bitonic: Naah, I just wanted to avoid passing my global variable through to every function. But then I might as well shove it in StateT, I guess
10:25:05 <hpc> merijn: you end up with lots of foo = do {s <- get; ...}
10:25:27 * confusing1 . o O ( why is scanl/r called scan anyway? )
10:25:55 <edwardk> it gives you insight into what foldr would give you at each step. you can scan the result of the fold
10:25:58 <merijn> hpc: Yeah, but else you'd end up with a lot of takeMVar, I guess?
10:26:14 <edwardk> > scanr1 (+) [1,2,3,4]
10:26:15 <lambdabot>   [10,9,7,4]
10:26:18 <DMcGill> merijn: if you do use StateT, don't forget the function gets to make things a little more point free
10:26:21 <merijn> And in case of StateT I can write more convenient wrappers around get
10:26:23 <edwardk> > foldr1 (+) [1,2,3,4]
10:26:24 <lambdabot>   10
10:27:14 <merijn> DMcGill: I'd probably use lenses rather than get/put anyway
10:27:15 <ceti331> "a bit for marking garbage collectino" - does it do the same for floats sometimes too
10:27:15 <ddarius> "A scanr Darkly"
10:27:15 <confusing> edwardk: yeah, i know the relation between foldr and scanr. it's just that i always read it as "scan as in determining the meter in a poem", and wondered about it ...
10:27:15 <merijn> StateT + lenses is nice, I've found :)
10:27:32 <edwardk> merijn: =)
10:27:36 <DMcGill> I'll have to try that, got a blog post about it?
10:27:40 <edwardk> merijn: have you seen the new package?
10:28:12 <merijn> edwardk: Control.Lens you mean? Yes, I've been informed Data.Lens is now soooooo 2012 :p
10:28:21 <edwardk> =)
10:28:31 <merijn> (I think the blog post is also waiting in my RSS reader until I'm sober enough to read it)
10:29:01 <edwardk> i need to blog up the new traversal stuff, its pretty much 'anything can compose with anything' and do something meaningful
10:29:59 <merijn> edwardk: At your current rate all my programs turn into a handful of variables names and unreadable combinators from your libraries :p
10:30:00 <heatsink> Does GHC specialize polymorphic functions with class constraints to the types they're used at?
10:30:27 <edwardk> they aren't already? man. i've failed to do my job
10:30:46 <edwardk> heatsink: 'sometimes'
10:30:57 <heatsink> Thanks for clearing that up.
10:31:05 <edwardk> depends on the size of the function and whats known at the call site, so it really is sometimes
10:31:32 <edwardk> if its across module boundaries, it is less likely to be able to see into it to do so, if its big it probably won't bother, etc
10:31:36 <edwardk> hey, its a hard question
10:31:44 <heatsink> Yeah, I know
10:32:01 <edwardk> you can use INLINE and SPECIALIZE pragmas to help
10:32:28 <heatsink> It seems like a useful transformation because it can simplify code, yet be more conservative about code bloat than inlining
10:32:49 <heatsink> Actually, I was hoping for a link to a paper about it
10:32:56 <heatsink> to see how they decide what to specialize
10:33:06 <heatsink> I found the constructor specialization paper, but that's something different
10:34:10 <aristid> edwardk: you do have the monopoly on package names that sound like algebra class, it seems :)
10:34:25 <edwardk> aristid: hah
10:35:02 <edwardk> heatsink: look for neil mitchell's superspecialization stuff, unfortunately with polymorphic recursion what you ask for can't be done in general
10:35:26 <edwardk> er supercompilation
10:35:47 <heatsink> Ah, a partial evaluation approach
10:37:26 <heatsink> Well, this paper looks interesting
10:37:33 <heatsink> I'll give it a read
10:38:22 <ParahSailin> very useful.. so pattern matching translates to case statements directly
10:39:12 <ceti331> stg machine: a graph of expressions to evaluate
10:39:13 <ceti331> ?
10:39:21 <ceti331> and the runtime figures out which parts are needed ?
10:39:58 <ceti331> is that what it is? (g for "graph")
10:40:09 <heatsink> Spineless Tagless Graph
10:41:13 <Rotaerk> it's a coward
10:42:49 <ceti331> i've seen people implement all sorts of data-driven graph evalulation in C
10:43:16 <ceti331> ... and nothing late binding can be implemented fast; you always need to rework it
10:43:31 <ceti331> for high performance code. for convinience its ok
10:43:51 <ceti331> the point with C is refactoring things to suit the I-Cache..
10:43:58 <ceti331> batching *when* things are called.
10:44:15 <ceti331> any sort of callback mechanism is doomed to create cache misses
10:44:37 <heatsink> A good compiler can figure out that lots of things are constant and generate specialized code
10:44:43 <ceti331> although its very *convinient* (programming time vs execution timme tradeoff)
10:44:57 <ceti331> heatsink: ok sure
10:45:10 <ceti331> heatsink: i can certainly see the value in having the language aware of a graph
10:45:21 <ceti331> but mostly for compile-time
10:46:25 <heatsink> The graph is really an implementation thing.  The langauge isn't aware of it.
10:46:27 <tbelaire> \join #python
10:46:34 <heatsink> blasphemy!
10:46:40 <tbelaire> oops
10:46:47 <ceti331> what i just read is that haskell is building a graph not a tree
10:46:55 <ceti331> which does make sense
10:50:26 <edwardk> ok, scanr1Of, and scanl1Of are in. -- i left off their more generalized cousins
10:50:33 <ceti331> is the STG machine a 'graph of closures'
10:50:39 <edwardk> now to skim Data.List to see if i missed any
10:51:22 <heatsink> I never took a close look at the STG, to be honest.  I know a bit more about how GHC implements Haskell.
10:52:32 <c_wraith> hmm.  Where's an example of scanr being useful?
10:52:51 <ceti331> is there a lower-level interface to the "stg"...like an assembler for it
10:54:03 <edwardk> c_wraith: postfix sum ;)
10:54:21 <heatsink> I don't think there's an STG machine assembler.
10:54:28 <edwardk> > scanl1 (+) [1,2,3,4]
10:54:28 <lambdabot>   [1,3,6,10]
10:55:16 <edwardk> heatsink: ? the STG is just an intermediate stop on the way to one of the backends, it gets compiled all the way down
10:55:24 <ceti331> heatsink: or dissasembler perhaps - for debugging or reasoning purposes... perhaps something to show nice graphical output explaining how & why a haskell progam works..
10:55:48 <edwardk> or do you mean something that can take it and evaluate/compile it?
10:56:00 <heatsink> I think ceti331 was asking about a way to write STG code directly
10:56:09 <edwardk> dylukes was playing around with some STG compiler, but i don't think he finished it
10:56:15 <edwardk> google winchester STG
10:56:17 <ceti331> i'm not even 100% sure its a valid question
10:56:31 <heatsink> ceti331, GHC takes some flags to dump out intermediate code at various stages
10:56:49 <ParahSailin> ceti331, http://blog.ezyang.com/2011/04/tracing-the-compilation-of-hello-factorial/
10:56:50 <ceti331> right, i can't imagine someone developing something as complex as GHC eithout shit loads of that...
10:57:02 <heatsink> http://www.haskell.org/ghc/docs/latest/html/users_guide/options-debugging.html#dumping-output
10:57:15 <ceti331> nice link, thanks
10:57:30 <heatsink> Useful ones are -ddump-simpl, -ddump-stg, -ddump-cmm
10:57:37 <edwardk> anyone have an implementation of take and drop handy as a foldr?
10:58:30 <edwardk> ceti331: well, you can --ddump-stg or whatever to see the stg from your code, there are a whole host of other dump options
10:59:30 <elegantWay> either Left Right == id, right?
10:59:38 <ddarius> elegantWay: Mostly.
10:59:44 <ddarius> either Left Right <= id
11:00:01 <elegantWay> yea, the type is more specific…
11:01:27 <ddarius> elegantWay: That wasn't what I meant, but I was wrong any way, it's the other way that isn't equal.
11:01:53 <elegantWay> okay… =)
11:02:07 <redscare> i have several functions in different modules that require state, is there a standard way of passing them only the relevant state? right now i'm just using a state monad with a Map as the state, and have each external function read that
11:02:28 <DMcGill> I think it would be more accurate to say "either Left Right x === x"
11:02:51 <elegantWay> fine.
11:02:57 <DMcGill> either a) make a prop and ask quickcheck or b) look at the source for either and prove it
11:03:17 * hackagebot data-lens 2.10.2 - Haskell 98 Lenses (RussellOConnor)
11:03:23 <ceti331> does the STG runtime implement the parallelism..
11:03:29 <elegantWay> DMcGill: i chose c) ask the channel :P
11:03:30 <DMcGill> does lambdabot have quickCheck?
11:03:32 <ddarius> DMcGill: QuickCheck will fail to find the counter-examples in some cases.
11:03:35 <elegantWay> DMcGill: yes
11:03:41 <ddarius> Smallcheck or lazycheck should though.
11:03:50 <DMcGill> ddarius: true, hence why I also suggested proving it
11:03:54 <elegantWay> DMcGill: @test, i think.
11:04:18 <DMcGill> @test propEither x = either Left Right x == x
11:04:18 <lambdabot> Maybe you meant: let list tell
11:04:31 <DMcGill> @list
11:04:31 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
11:04:38 <ddarius> DMcGill: Also, Djinn can prove this, albeit with similar limitations as quickcheck.
11:05:19 <DMcGill> @djinn either Left Right
11:05:20 <lambdabot> Error: Undefined type Left
11:05:37 <DMcGill> how would I give djinn the source as opposed to a type?
11:06:07 <ddarius> Well, you'd need to apply some meta-analysis with the output of djinn to finish it.
11:06:18 <DMcGill> @src either
11:06:18 <lambdabot> either f _ (Left x)     =  f x
11:06:18 <lambdabot> either _ g (Right y)    =  g y
11:06:21 <byorgey> DMcGill: that doesn't make sense. what would you want djinn to do with the source?
11:06:47 <DMcGill> either Left _ (Left x) = Left x; either _ Right (Right x) = Right x
11:06:59 <DMcGill> I don't know, ddarius said you could use djinn
11:07:23 <ceti331> if haskell interfaces with C, does it need to have a way of representing types like 32-bit int that really is 32bit... someone said earlier haskell Int might be 30,31bits (tagging, GC)
11:07:34 <byorgey> ceti331: yes, it does
11:07:34 <ddarius> @hoogle CInt
11:07:35 <lambdabot> Foreign.C.Types data CInt
11:07:35 <lambdabot> Foreign.C.Types data CIntMax
11:07:35 <lambdabot> Foreign.C.Types data CIntPtr
11:07:43 <danr> @djinn (a -> c) -> (b -> c) -> Either a b -> c
11:07:43 <lambdabot> f a b c =
11:07:44 <lambdabot>     case c of
11:07:44 <lambdabot>     Left d -> a d
11:07:44 <lambdabot>     Right e -> b e
11:08:30 <neothemachine> hey guys, just a quick one: how can I import *** from Control.Arrow? using 'import Control.Arrow (***)' makes the compiler cry
11:08:34 <ceti331> is the "STG" a mid-level unit that could be used as a back-end for other functional languages
11:08:41 <DMcGill> import Control.Arrow ((***))
11:08:51 <neothemachine> thanks! :)
11:08:52 <hpc> neothemachine: "import <module> (<import list>)"
11:09:08 <ParahSailin> :t return
11:09:09 <lambdabot> forall a (m :: * -> *). (Monad m) => a -> m a
11:09:18 <heatsink> CMM was originally designed to be a backend for many languages, but it didn't get very far
11:09:23 <hpc> => "(<symbol>)" => ((***), (&&&), arr, etc)
11:09:30 <ceti331> whilst i'm finding haskell intersting, reading "Int might be 30bits" is a bit scary
11:09:45 <heatsink> It's probably to allow tag-based implementations
11:09:47 <ddarius> heatsink: C--.  Cmm is somewhat different from C-- and it got somewhere but then Norman ran out of grad students.
11:09:49 <byorgey> ceti331: why is it scary?
11:09:51 <hpc> heatsink: it is
11:10:06 <ceti331> byorgey i grew up on bits and bytes and alignment..
11:10:15 <hpc> it allows 2 bits of information for the Int# constructor or something similar
11:10:18 <ddarius> ceti331: C is far worse than Haskell in that regard.
11:10:25 <heatsink> ceti331, in some LISP compilers, all even numbers were pointers and all odd numbers were integers
11:10:30 <ceti331> C is very natural for me
11:10:37 <hpc> C only specifies the relative sizes of things
11:10:44 <heatsink> Essentially, the low bit says it's an int, and the upper bits are the int value
11:10:51 <hpc> with special cases for when an int is smaller than 8 or whatever
11:10:57 <ceti331> formative years was BBC basic -> 68k asm. C was very easy.
11:11:35 <ddarius> ceti331: C doesn't guarantee int is 32 bits or 64 bits.
11:11:37 <heatsink> ddarius, Cmm is a fork of C-- incorporated into GHC?
11:11:51 <ddarius> heatsink: Something like that.
11:11:55 <heatsink> ok
11:11:58 <redscare> i have several functions in different modules that require state, is there a standard way of passing them only the relevant state? right now i'm just using a state monad with a Map as the state, and have each external function read that
11:12:08 <ceti331> ddarius: when i encounter an implementation that doesn't have a 32 or 64bit type, i'll freak out.
11:12:25 <ddarius> ceti331: Why doesn't the same logic apply to Haskell then?
11:12:44 <ceti331> i understand its not defined.. but a C where int is 30 bits? i dont thinkso
11:12:45 <ceti331> obscure DSPs maybe
11:12:50 <ddarius> There are no doubt C's with 36 bit ints.
11:12:58 <ceti331> but you wont write or port large programs to that
11:14:08 <neothemachine> one more thing... hlint tells me "use ***" on "(mk (fst inp), mk (snd inp))" where mk turns a list into an array and inp is (string,string)
11:14:13 <ceti331> ddarius: i've worked with about 5 cpus and never seen one
11:14:14 * hackagebot data-lens-fd 2.0.3 - Lenses (RussellOConnor)
11:14:14 <byorgey> ceti331: well, you'll need to temporarily stop thinking that way when learning Haskell.  Because Haskell encourages programming at a higher level where it simply doesn't matter.
11:14:14 <byorgey> ceti331: use Integer instead of Int, which is arbitrarily sized.
11:14:14 <heatsink> Also, as I recall, the C standard doesn't require signed integers to be in two's complement form
11:14:14 <ceti331> 6502 68k 80486 MIPS 3000  VU DSP SH4 PowerPC Cell modern x86
11:14:14 <ceti331> ARM
11:14:14 <hpc> haskell doesn't even specify lazy evaluation
11:14:14 <ceti331> i've worked with a lot of CPUs and have some safe assumptions about sizes
11:14:30 <hpc> it only mentions semantics with respect to bottom
11:14:30 <byorgey> neothemachine: (mk *** mk) inp
11:14:40 <ddarius> ceti331: I think you meant to say you have some unsafe assumptions.
11:15:33 <ceti331> ddarius, i can always get a mainstream type (not "foreign type") that is 32bit... when my program can't be ported.. well.. i'll worry about it then
11:15:35 <neothemachine> byorgey: whoops, that's magic :D I recently read up on arrows, interesting things!
11:16:03 * shapr throws a spear at lambdabot 
11:16:04 <ddarius> There also is an Int32 type in Data.Int which is guaranteed to be 32-bits (and I believe 2's complement)
11:16:32 <ceti331> ddarius: will Int32 clash with GC (e.g. do something silly like force it to use extra tags)
11:16:39 <ssbr-> clearly haskell needs inttypes.h
11:16:46 <ssbr-> where's my int_fast32_t ?
11:17:08 <ddarius> ceti331: The GHC doesn't "tag" numbers.  There is no reason to.
11:17:13 <ParahSailin> i dont understand this monad law "return a >>= k  =  k a"
11:17:20 <hpc> ssbr-: you want uint_fast32_t
11:17:20 <hpc> ;)
11:17:23 <ddarius> GHC GC
11:17:24 <ceti331> ddarius: lets say you want to reason about compression algorithms - you need to know absolute sizees
11:17:37 <ParahSailin> oh, nevermind, got it
11:17:46 <ParahSailin> still hard for me to read currying of functions
11:17:50 <ssbr-> hpc: maybe. :(
11:17:52 <ceti331> ddarius: optimizing code is sometimes about compressing for cache efficiency..
11:17:59 <hpc> ParahSailin: that one is really easy in do-notation form
11:18:06 <ceti331> reasoniing about data-layout..
11:18:06 <ddarius> ceti331: I don't know why you are saying this.
11:18:16 <hpc> do {x <- return a; k x} == k a
11:18:24 <ceti331> well someone said "Int is 30bits"
11:18:40 * roconnor finds a 3rd lens package he maintains
11:18:40 <ddarius> ceti331: You said that the Report said that Int may be 30bits.
11:18:45 <ceti331> what does that look like when i serialize it..
11:19:08 <ssbr-> ceti331: that would depend entirely on the serialization algorithm
11:19:29 <ParahSailin> because my brain is used to seeing return as a statement and not as (return a) >>= k
11:19:41 <ddarius> ceti331: If you want to do data layout optimizations, you'll need to know the details of the implementation you are using, not of the standard.
11:19:47 <heatsink> ceti331: When passing an Int32 to polymorphic code, it is a pointer to an int.  In monomorphic code, after optimization, Int32 variables are usually kept in registers.
11:19:53 <hpc> ParahSailin: ah; yeah that's a tough mindset to get out of
11:20:04 <ssbr-> ParahSailin: I know the feeling. I made a point of understanding everything in >>/>>= form first, and do notation second
11:20:07 <hpc> it helps to constantly see "return" be unhighlighted in vim or whatever
11:20:10 <ssbr-> ParahSailin: that helped me. Maybe it'll help you?
11:20:28 <ParahSailin> yeah im trying to avoid do notation because it looks too much like imperative
11:20:51 <ssbr-> I like >>. It reads a lot like bash ;)
11:20:53 <heatsink> BTW, the report guarantees that Int is at least 30 bits.  It permits 32-bit or 64-bit integers.
11:20:55 <ceti331> whats return in haskell..
11:20:56 <hpc> ParahSailin: you can also mentally replace "return" with "pure"
11:21:08 <ddarius> ceti331: A function.
11:21:13 <hpc> for all monads that define sane instances, pure = return
11:21:36 <ceti331> i'm thinking you're going to tell me its absolutely nothing like return in c
11:21:36 <ssbr-> hpc: woah, pure?
11:21:43 <ssbr-> ceti331: Well, it isn't.
11:21:44 <hpc> @src Applicative
11:21:56 <lambdabot> class Functor f => Applicative f where
11:21:56 <lambdabot>     pure  :: a -> f a
11:21:56 <lambdabot>     (<*>) :: f (a -> b) -> f a -> f b
11:21:56 <ssbr-> ceti331: it has no control flow connotations at all
11:22:09 <ssbr-> ceti331: "return" says "push this through the pipeline"
11:22:14 <ddarius> The Report says nothing about how anything is laid out in memory.  It just says that you have to provide the semantics given.  I can implement Int as a string of characters as long as all the operations behave correctly.
11:22:42 <ddarius> ssbr-: I would not describe return like that at all.
11:23:03 <ssbr-> ddarius: Man, I don't know how to explain things to people
11:23:13 <ceti331> is it like a single statement return slotting in as a function, a bit like when using 'return' in gcc extended macros
11:23:31 <hpc> ssbr-: "return lifts a value to a monadic action"
11:23:43 <ssbr-> hpc: that doesn't explain anything at all.
11:23:43 <ddarius> ceti331: It's nothing like C's return.
11:24:06 <confusing> ssbr-: fwiw, i thought your explanation wasn't half bad
11:24:13 <heatsink> ceti331, the meaning of "return" is closely related to monads.  Haskell novices usually take some time to understand monads.
11:24:17 <ceti331> "lifts a value to a monadic action" - a function 'returning'the value passed in, wrapped with monad-?????
11:24:30 <ssbr-> hpc: or, I guess the point is, the only people that understand what you said, are the people that already know what return does
11:24:35 <hpc> ceti331: seriously, learning haskell will go a lot more smoothly if you pretend no other programming languages exist
11:24:38 <ssbr-> hpc: at least, that's how I'd estimate the reaction
11:24:50 <ddarius> confusing: Can you explain what "pipeline" return is "pushing things through" and what "pushing things through" means?
11:24:56 <neothemachine> htc: haha :D there's truth in it
11:25:25 <ceti331> hpc: can you provide a couple of single line examples to explain what haskell return does
11:25:26 <hpc> ssbr-: it's something you can build an explanation on
11:25:41 <hpc> ceti331: (return >=> k) == k
11:25:46 <ddarius> ceti331: It's an overloaded function.  It does different things at different types.
11:25:46 <ssbr-> hpc: is that the plan? if he really wants to learn monads he should read a tutorial
11:25:47 <hpc> k >=> return == k
11:26:04 <hpc> that's the grand total of what return is required to do
11:26:12 <ddarius> ssbr-: If he really wants to learn monads in Haskell, he should read a tutorial on Haskell.
11:26:21 <ssbr-> ddarius: has he not even done that yet?
11:26:25 <ssbr-> what are we doing then
11:26:26 <ddarius> hpc: It needs to be a left identity as well.
11:26:47 <heatsink> hpc, I don't think these examples will be useful on their own.  He'll need to understand the idea of monads as computations.
11:26:50 <ddarius> hpc: Oh, I missed the other line.
11:26:52 <ParahSailin> @src return
11:26:53 <lambdabot> Source not found. My pet ferret can type better than you!
11:27:04 <ParahSailin> :t return
11:27:05 <ReinH> Athas: so I think I understand boolean blindness now, and I think I understand type strictnes, but I'm not sure what (if anything) boolean blindness has to do with type strictness
11:27:05 <lambdabot> forall a (m :: * -> *). (Monad m) => a -> m a
11:27:06 <hpc> heatsink: that's my point
11:27:13 <ParahSailin> why no sauce?
11:27:30 <hpc> you can't ask for a few one-liners and magically understand a fundamentally different approach to programming
11:27:30 <ssbr-> ceti331: you should definitely read a tutorial, they help a lot. Plus it feels less goofy, because you don't make mistakes in public :P  So you get to go through a slow, private transformation from not knowing to knowing. Tutorials are great. And if you get stuck, you can always ask for help!
11:27:46 <ddarius> ParahSailin: return is an overloaded function.  It has a different definition for different types.
11:28:05 <ParahSailin> @hoogle return
11:28:05 <lambdabot> Prelude return :: Monad m => a -> m a
11:28:06 <lambdabot> Control.Monad return :: Monad m => a -> m a
11:28:06 <lambdabot> Control.Monad.Instances return :: Monad m => a -> m a
11:28:14 <heatsink> Can you ask for @src for a specific class instance?
11:28:20 <ddarius> heatsink: Yes.
11:28:27 <hpc> @src [] (<*>)
11:28:27 <lambdabot> (<*>) = ap
11:28:29 <smithw> What would be the simplest way to construct a State IO arrow in Haskell? I've been reading HXT's source and it seems very elaborate. Is the way they do it the simplest way to do it?
11:28:34 <heatsink> Cool
11:28:36 <ParahSailin> @src [] return
11:28:37 <lambdabot> return x    = [x]
11:28:40 <ReinH> > return 'c' :: String
11:28:41 <ParahSailin> wow thats cool
11:28:41 <lambdabot>   "c"
11:28:47 <neothemachine> can I express "length (fst inp) == length (snd inp)" somehow shorter? inp is a 2-tuple
11:28:49 <ParahSailin> @src IO return
11:28:49 <lambdabot> return x    = returnIO x
11:28:50 <hpc> smithw: arrow as in Arrow?
11:28:56 <hpc> stick it in a Kleisli
11:28:57 <ParahSailin> @src returnIO
11:28:58 <lambdabot> Source not found. Do you think like you type?
11:29:00 <smithw> hpc, yes
11:29:00 <ddarius> Kleisli (StateT IO) done
11:29:01 <heatsink> neothemachine, (==) `on` length
11:29:09 <ParahSailin> @hoogle returnIO
11:29:09 <lambdabot> No results found
11:29:15 <neothemachine> heatsink: cool, thanks :)
11:29:23 <heatsink> Uh, you need fst and snd in there somewhere too
11:29:37 <ParahSailin> @src IO returnIO
11:29:37 <lambdabot> Source not found. You speak an infinite deal of nothing
11:29:51 <heatsink> :t let lengthEq = (==) `on` length in \x y -> lengthEq (fst x) (snd y)
11:29:53 <lambdabot> forall b a a1. ([a], b) -> (a1, [a]) -> Bool
11:30:03 <ddarius> :t uncurry (==) . (length *** length)
11:30:04 <heatsink> :t let lengthEq = (==) `on` length in \x -> lengthEq (fst x) (snd x)
11:30:05 <lambdabot> forall a a1. ([a], [a1]) -> Bool
11:30:05 <lambdabot> forall a. ([a], [a]) -> Bool
11:30:06 <ParahSailin> @src State return
11:30:07 <lambdabot> Source not found. My mind is going. I can feel it.
11:30:43 <ddarius> ParahSailin: @src is extremely ad-hoc.
11:30:47 <heatsink> :t uncurry $ (==) `on` length
11:30:48 <lambdabot>     Precedence parsing error
11:30:48 <lambdabot>         cannot mix `$' [infixr 0] and `on' [infixl 0] in the same infix expression
11:30:56 <heatsink> :t uncurry ((==) `on` length)
11:30:58 <lambdabot> forall a. ([a], [a]) -> Bool
11:31:01 <heatsink> There
11:31:08 <ddarius> heatsink: That forces the types to be the same.
11:31:09 <ParahSailin> im noticing that i cant often get what im looking for out of it
11:31:13 <smithw> ddarius, hpc, thanks. That seems the simplest way to do it. I was trying to construct an state arrow transformer from nothing, but that is actually not that simple.
11:31:29 <neothemachine> heatsink: ok I'll try it
11:31:39 <heatsink> Oh, I didn't think of that
11:31:40 <merijn> ParahSailin: Out of @src you mean? That's because it's a handwritten lookup table
11:31:46 <ceti331> one problem here is you can't google ">=>"  WTF is >=>
11:31:51 <neothemachine> in my case they're the same
11:31:54 <ssbr-> ceti331: use hoogle
11:31:56 <merijn> ceti331: You can Hoogle, though
11:32:00 <merijn> @hoogle (>=>)
11:32:01 <lambdabot> Control.Monad (>=>) :: Monad m => (a -> m b) -> (b -> m c) -> (a -> m c)
11:32:04 <ssbr-> ceti331: hoogle is a search engine for haskell syntax. It is a lifesaver
11:32:12 <hpc> ssbr-: not just syntax
11:32:19 <ssbr-> syntax and type signatures, sure
11:32:19 <ReinH> neothemachine: do you want shorter or clearer?
11:32:21 <edwardk> roconnor: heya
11:32:35 <roconnor> hi
11:32:41 <ssbr-> ceti331: >=> is closely related to >>=, which is more fundamental
11:32:50 <ParahSailin> why's hoogle not have returnIO
11:33:03 <ssbr-> ceti331: or at least, there are more explanations for >>= than for >=> ;)
11:33:05 <neothemachine> ReinH: both :p
11:33:15 <merijn> ParahSailin: I suspect it is a GHC/compiler builtin
11:33:18 * hackagebot lens-family-core 0.0.1 - Haskell 98 Lens Families (RussellOConnor)
11:33:18 <edwardk> almost to the point of saturation on adding combinators to lens ;)
11:33:21 <ddarius> ssbr-: That's better.  Arguably (>=>) is more fundamental.
11:33:22 <ssbr-> ceti331: but you can't really understand these in isolation
11:33:27 <ReinH> neothemachine: good luck :)
11:33:28 <ssbr-> ddarius: yeah
11:33:40 <roconnor> edwardk: that doesn't necessarily sound good
11:33:45 <edwardk> its good =)
11:33:49 <roconnor> ok
11:33:50 <ssbr-> ceti331: if you want to understand >=>, you have to understand monads as a whole
11:33:52 <hpaste> Nolrai24 pasted “revertIfFailed” at http://hpaste.org/72301
11:33:52 <ceti331> >> >=> >>= pass monads along? >> without a value  >>= with a value, but >=>  (did i even get those wrong)
11:34:05 <edwardk> pull 1.0.2 and take a look around
11:34:15 <ddarius> ceti331: Monads are not values.
11:34:18 <ParahSailin> :t (>=>)
11:34:20 <lambdabot> forall a (m :: * -> *) b c. (Monad m) => (a -> m b) -> (b -> m c) -> a -> m c
11:34:24 <roconnor> edwardk: what was it called again?
11:34:28 <edwardk> 'lens'
11:34:28 <ceti331> wrappers for values ?
11:34:36 <merijn> ceti331: Wrappers for actions
11:34:47 <hpc> they aren't wrappers, even
11:34:48 <ddarius> Monads are not wrappers.
11:34:50 <merijn> Well, potentially
11:34:50 <hpc> actions are values
11:34:55 <hpc> a monad is a TYPE
11:34:59 <hpc> that is an instance of Monad
11:35:07 <ddarius> Monads are type constructors that are instances of the Monad class (and, arguably, satisfy the monad laws.)
11:35:20 <hpc> ddarius: not necessarily type constructors
11:35:29 * hpc pedants
11:35:41 <ddarius> hpc: More an issue with differing terminology.
11:35:44 <edwardk> i'm getting pretty happy with the level of polish it is reaching, the signatures aren't scary any more
11:35:56 <ddarius> I'll use the Report's terminology: "types of kind * -> *"
11:36:06 <roconnor> _2 ?
11:36:15 <heatsink> ddarius, what do you usually call a monadic value?  A computation?
11:36:20 <edwardk> yes, fstL was an eyesore
11:36:25 <edwardk> traverse._2 largely vanishes
11:36:31 * roconnor is reading https://gist.github.com/3190574
11:36:34 <ceti331> is a monad a node in an STG graph..
11:36:37 <ddarius> heatsink: Sometimes, or monadic computation, or monadic value.
11:36:41 <roconnor> ._2 is kinda distrubing ... in a good way
11:36:49 <Nolrai244> Is this doing what I want it to? I basicly want to run a state action, if it fails revert, and log the error.
11:36:50 <edwardk> =)
11:36:58 <ddarius> Smacks of ML
11:37:04 <heatsink> ceti331, Monads are not related to the STG.  You can make monads in any programming language.
11:37:05 <edwardk> its the name scala uses
11:37:08 <Nolrai244> ceti331: STG? thats low leve stuff.
11:37:13 <edwardk> for once i stole something back from there ;)
11:37:15 <ceti331> Monads in C?
11:37:28 <heatsink> ceti331, you can.  It's very inconvenient though.
11:37:39 <edwardk> the names are now all completely unmangled, and the ones you use a lot are a lot shorter
11:37:40 <ParahSailin> @src IO fail
11:37:40 <lambdabot> fail s  = failIO s
11:37:40 <roconnor> I see you've come around on multilenses
11:37:46 <edwardk> just a bit ;)
11:37:48 <ParahSailin> @src [] fail
11:37:48 <lambdabot> fail _      = []
11:37:52 <ssbr-> monads in a language without ad-hoc polymorphism sound like they'd be a little odd
11:37:56 <confusing> ParahSailin: lambdabot is also available privately
11:38:01 <edwardk> i don't like the multilens name, but i like the concept of them
11:38:10 <edwardk> as a 'Traversal' they aren't offensive to me
11:38:18 * hackagebot lens 1.0.2 - Families of Lenses, Folds and Traversals (EdwardKmett)
11:38:18 <edwardk> and they are merely 'LensLike' when used
11:38:19 <merijn> edwardk: What is the concept of a multilens?
11:38:21 * hackagebot lens-family 0.0.1 - Lens Families (RussellOConnor)
11:38:29 <edwardk> merijn: take the signature traverse
11:38:31 <ceti331> monads in C++ ?
11:38:33 <roconnor> edwardk: why not call them Biplates :D
11:38:37 <edwardk> (a -> f b) -> t a -> f (t a)
11:38:48 <edwardk> er Applicative f => (a -> f b) -> t a -> f (t b)
11:38:58 <edwardk> then generalize it to monomorphic containers
11:39:07 <edwardk> Applicative f => (c -> f d) -> a -> f b
11:39:08 <ssbr-> ceti331: http://www.reddit.com/r/programming/tb/1761q
11:39:13 <ParahSailin> why is there a fail function for monad instances
11:39:18 <edwardk> that is a 'multilens' or 'traversal'
11:39:28 <edwardk> roconnor: because that is an equally crappy name =P
11:39:36 <merijn> edwardk: Not sure if that helped, let me meditate on the types for a while :p
11:39:42 <Nolrai244> cieti331: Sure, just define a fmap, a join, and a return.
11:39:44 <roconnor> edwardk: it's the "original" name :P
11:39:46 <merijn> ParahSailin: Historical wart
11:39:47 <edwardk> traverse :: Traversabe t => Traversal (f a) (f b) a b
11:39:56 <Nolrai244> (or a fmap , a bind and return)
11:40:00 <merijn> ParahSailin: IMO (and that of many others)
11:40:13 <edwardk> yes, i have a shocking disregard for precedent when there is something that will actually help gain adoption/traction
11:40:27 <roconnor> edwardk: do you have (Bool -> k) -> SimpleTraversal (k,v) v ?
11:40:33 <ParahSailin> so left in for backwards compatibility?
11:40:44 <edwardk> i didn't get around to adding that one
11:40:53 <roconnor> hmm
11:40:58 <edwardk> keyValue or something
11:41:03 <roconnor> I think it is kinda important
11:41:07 <ddarius> ParahSailin: No.
11:41:10 <dolio> I'd bet some money that someone referred to '(a -> f b) -> t a -> f (t b)' as a traversal before you called it a biplate. :)
11:41:15 <roconnor> though I'm often tempted to use k :-> v instead of (k,v)
11:41:24 <ddarius> dolio: Not some bitcoins?
11:41:31 <dolio> I don't have any bitcoins.
11:41:39 <ddarius> dolio: I know a good dealer.
11:41:43 <dolio> And copumpkin's rates are too high to borrow.
11:41:50 <Nolrai244> ddarius: "ParahSailin: No" huh?
11:41:53 <ceti331> "do" is purely sugar for sequences of >> >>= >=> ?
11:41:59 <heatsink> yes ceti331
11:42:09 <heatsink> Actually just >> and >>=
11:42:32 <ion> ceti331: and some pattern matching along with “fail”
11:42:32 <ceti331> >> when an action returns nothing, >>= when an action returns something passed into the next? (??)
11:42:43 <heatsink> right
11:42:49 <hpc> almost right
11:42:56 <hpc> (>>) when the result of an action is ignored
11:42:58 <roconnor> edwardk: why do you have clone?
11:43:02 <ion> @undo do foo; bar
11:43:02 <lambdabot> foo >> bar
11:43:04 <ion> @undo do a <- foo; bar
11:43:04 <lambdabot> foo >>= \ a -> bar
11:43:09 <hpc> all actions return something, even if it's a value of the unit type ()
11:43:10 <ion> @undo do (Foo a) <- foo; bar
11:43:10 <lambdabot> foo >>= \ b -> case b of { (Foo a) -> bar; _ -> fail ""}
11:43:21 <edwardk> because you may want to pass a lens non-polymorphically for container reasons, and it can be used to sanity check a lens
11:43:22 <hpc> or undefined, of some indeterminate type
11:43:24 <ddarius> return Nothing
11:43:29 <heatsink> @undo do _ <- foo; bar
11:43:29 <lambdabot> foo >>= \ _ -> bar
11:43:40 <ReinH> edwardk: which lens lib are you working on?
11:43:45 <roconnor> edwardk: container reasons?
11:43:48 <edwardk> ReinH: 'lens'
11:43:49 <heatsink> _ <- m is not equivalent to m?
11:43:49 <hpc> (>>) is defined in terms of (>>=)
11:43:52 <hpc> @src (>>)
11:43:52 <lambdabot> m >> k      = m >>= \_ -> k
11:43:53 <ddarius> @undo do Just _ <- foo; bar
11:43:53 <lambdabot> foo >>= \ a -> case a of { Just _ -> bar; _ -> fail ""}
11:43:58 <hpc> heatsink: it is
11:44:03 <ReinH> edwardk: oh, "the" lens lib :)
11:44:17 <ceti331> i've seen the "imperative part of a haskel program is the "do" ... presumably you can make imperative "procedures" called from mains 'do' ... would that be with monads in signatures
11:44:19 <ReinH> edwardk: I'm writing a chess engine for a tutorial and I thought I might use a lense on the board matrix
11:44:19 <ion> edwardk: I don’t remember if i asked about this before. I wonder if these functions would be useful in the tagged package? (I understand if they wouldn’t.) http://heh.fi/tmp/tagged-0001-Add-Proxy-based-versions-of-base-functions-with-dumm.patch.text
11:44:26 <ReinH> *lens
11:44:30 <edwardk> impredicative polymorphism is a flaky beast. if you need to toss around a 'f (Simple Lens a b)' you sometimes can't
11:44:51 <ReinH> edwardk: to implement updateBoard and move, etc
11:44:58 <jmcarthur> ceti331: and the funny thing is do notation is just syntax notation for a certain class of functional code
11:44:59 <Nolrai244> ceti331: that is the IO monad.
11:45:00 <dolio> GHC is a flaky beast, you mean. :)
11:45:02 <jmcarthur> *syntax sugar
11:45:10 <Nolrai244> (other monads do other things.)
11:45:10 <ion> ceti331: No, that’s not the “imperative” part. IO is “the” imperative EDSL in Haskell and it’s just coincidental it happens to be a monad and therefore can take advantage of the “do” sugar.
11:45:17 <edwardk> ion: bookmarked to touch next time i look at tagged
11:45:23 <smithw> @src State get
11:45:24 <lambdabot> Source not found.
11:45:32 <ddarius> ion: I would not describe it as "coincidental."
11:45:35 <hpc> ceti331: historical note: IO was not always monadic
11:45:51 <ion> ddarius: Fair enough. :-)
11:45:51 <hpc> it used to be treated as a lazy infinite stream of inputs and outputs
11:46:05 <ceti331> so monads can do more than IO ; (?)   ; or were monads developped for IO and found to be more general ?
11:46:21 <ReinH> edwardk: I'm sorry, do you have a link to the haddock for your lib? I'm not sure which it is. :(
11:46:21 <hpc> monads were discovered long before haskell existed
11:46:22 <dolio> Monads were definitely not developed for IO.
11:46:34 <ddarius> hpc: Not -that- long.  Category theory is pretty young.
11:46:43 <edwardk> http://hackage.haskell.org/package/lens-1.0.1
11:46:45 <hpc> ddarius: long in "CT-years"
11:46:49 <ceti331> "IO was not always monadic" ... monads were added to haskel as a better way to do IO ?
11:46:51 <Ralith> CT?
11:46:52 <ReinH> ceti331: it's essentially the other way around: monads were found to be a reasonable way to do IO
11:46:56 <hpc> (one CT year == 3.27 internet years)
11:47:02 <ssbr-> hpc: neutral terminology would say "described", you evil idealist
11:47:12 <jmcarthur> ceti331: monads are not a language feature. they are just a thing from math
11:47:41 <ReinH> ceti331: they're part of the category theoretical basis of haskell
11:47:47 <dolio> Does internet time have years? I thought it was beats.
11:47:48 <heatsink> Haha, monads are old in cat years :)
11:47:49 <jmcarthur> ceti331: that is, all languages have monads. it just so happens that in haskell monads are much more convenient than they are in most other languages
11:47:54 <smithw> ceti331, although not strictly formal, this is the best (in the sense of "easier to understand") monad explanation I've ever seen: http://cdsmith.wordpress.com/2012/04/18/why-do-monads-matter/
11:48:34 <ReinH> smithw: after reading about two dozen "a monad is a burrito full of stars" blog posts, the only way I really grokked them was to just write and read a bunch of monadic code
11:48:45 <hpc> ^
11:48:51 <jmcarthur> what ReinH said
11:49:18 <ReinH> all the analogies leak terribly
11:49:18 <ssbr-> ReinH speaks wonderful truth
11:49:20 <Athas> I understood monads by reading the type signatures.
11:49:23 <hpc> i used StateT as part of an IRC bot when i was learning
11:49:35 <Athas> Really, you have two methods, and they have trivial types.
11:49:40 <hpc> didn't know how it worked, just knew i could get state with "get" and put it with "put"
11:49:47 <ceti331> i thought all this could start with a differentiation between "functions" and "procedures".
11:49:50 <roconnor> edwardk: where is the JustLens?
11:49:55 <smithw> ReinH, true, but I only consider I "understand" something if I'm able to explain them to someone else. After I read that explanation, I realized that was the way I would explain monads to someone who have never heard of them.
11:49:58 <hpc> and that this magical incantation let you run the stateful stuff
11:50:00 <edwardk> its 'traverse'
11:50:03 <ceti331> i had that in BBC basic in 1984
11:50:06 <edwardk> no need for it
11:50:06 <roconnor> edwardk: gah
11:50:08 <ddarius> Athas: It's unlikely you understood the application of monads to modelling effects from just reading the type signatures, which is really where people get hung up.
11:50:13 <hpc> then i learned "how it knew what the state was"
11:50:13 <ReinH> Athas: many people, myself included, are not at the point yet where they can always intuit such things from type signatures
11:50:15 <roconnor> edwardk: this is like using the ssreflect library
11:50:18 <edwardk> i want to encourage the use of 'traverse' as a traversal a lot
11:50:30 <ReinH> it's definitely an acquired skill
11:50:37 <roconnor> edwardk: definitely a tutorial is in order
11:50:40 <edwardk> traverseRight is there because Either b isn't traversable yet
11:50:42 <edwardk> yes
11:50:44 <roconnor> maybe even a short book :D
11:50:48 <jmcarthur> ceti331: in haskell, you can't even execute a procedure. you can create them (IO actions), but never cause them execute by way of evaluation
11:50:50 <edwardk> i'm planning on writing a blog series on it
11:50:51 <ion> “Why *do* monads matter? (See what i did there?)”
11:50:56 <edwardk> and maybe a functional pearl
11:50:57 <Athas> ddarius: well, after that, it's just reading the implementation of a state monad, and it should click.  My point is that monads are most easily understood as concrete things, rather than an abstract concept.
11:50:58 <ReinH> edwardk: yes, tutoriol! we demand it
11:51:03 <ReinH> s/ol/al
11:51:11 <jmcarthur> (ignoring unsafePerformIO, which is obviously considered unsafe)
11:51:17 <ceti331> jmcarthur , i thought the final "main" ultimately triggers what must really be 'procedures'
11:51:19 <ReinH> Athas: we certainly agree on that
11:51:26 <roconnor> edwardk: I sort of think <>= should be added :)
11:51:29 <hpc> Athas: specific monads
11:51:31 <jmcarthur> ceti331: right.
11:51:33 <srhb> ReinH: You end up in a position where you have to unlearn what (nonsense) you heard up until that point.
11:51:36 <edwardk> i have no dependencies outside of base
11:51:40 <hpc> Monad itself should not be taught concretely, because it is not concrete
11:51:41 <ceti331> jmcarthur: i would much prefer if C called its things 'procedures' :)
11:51:43 <edwardk> and i'm trying to keep it that way ;)
11:51:46 <ReinH> srhb: ?
11:51:46 <jmcarthur> ceti331: but you can't trigger execution of a procedure yourself
11:51:50 <roconnor> edwardk: isn't <> in base?
11:51:56 <edwardk> the one for Monoid?
11:51:59 <roconnor> ya
11:52:00 <edwardk> oh that one
11:52:02 <srhb> Hmm, I think my client had a hiccup and some of what I wrote got lost. ._.
11:52:06 <edwardk> i thought you meant the semigroup one
11:52:10 <ReinH> edwardk: sorry to ask again, but do you have a handy link to the lens library?
11:52:14 <edwardk> http://hackage.haskell.org/package/lens-1.0.1
11:52:17 <ReinH> thanks much
11:52:19 <ion> edwardk: I’m looking forward to that.
11:52:20 <ceti331> jmcarthur: but the 'monads' (that i'm still not sure what they are) in signatures are used to describe how procedures should be triggered ?
11:52:25 <edwardk> i pasted it above =)
11:52:34 <hpc> i would like to see (<=>) brought in as an alias for compare, while we are asking for infix operators
11:52:36 <Nolrai244> ceti331: I think what you are calling procedures are IO values in haskell.
11:52:37 <neutrino3000> hi
11:52:39 <jmcarthur> ceti331: don't focus on monads. just pay attention to the IO type constructor
11:52:42 <edwardk> i can add the one for mappend, sure
11:52:43 <monochrom> actually you can't trigger execution yourself in C either. main is magically executed
11:52:46 <ceti331> jmcarthur: or is it all coming down to building an STG graph
11:52:51 <jmcarthur> ceti331: the label "monad" can come later
11:52:54 <ion> edwardk: Whoops, i hadn’t scrolled all the way down. I was referring to what you said about the blog series.
11:52:57 <ReinH> edwardk: and do you think it would be useful to handle get/sets on a 2d matrix for a chess engine?
11:53:06 <neutrino3000> i have [[[[a]]]]. I want to get the max len in each dimension. how do i do that best?
11:53:08 <edwardk> sure
11:53:12 <heatsink> ceti331,  Think of IO actions as Haskell bindings to a non-Haskell library
11:53:17 <jmcarthur> ceti331: i don't think i would try to use STG as a way of explaining IO
11:53:19 <edwardk> i use it to access matrices for matrix multiplications, etc.
11:53:29 <edwardk> m^.i.j is a nice way to talk about parts of a matrix
11:53:39 <ceti331> jmcarthur: initially i thought that IO in haskell was some state variable e.g. newOutsideWorldIOState = SomeFunctionDoingIO(OldOutsideWorldIOState, ParametersForIO) but i know this is wrong now...
11:53:43 <Athas> neutrino3000: use map and maximum functions.
11:53:59 <heatsink> ceti331, Some Haskell implementations use that method, but it's hidden
11:54:01 <heatsink> internally
11:54:03 <alpounet> ceti331, monads are just some kind of pattern that many (parametrized) data types happen to follow. just try to forget about them when you work on understanding IO
11:54:04 <ReinH> edwardk: I think after I switch the list of lists to a matrix (possibly repa?), I may also switch the board modification code to use a lens then
11:54:09 <neutrino3000> i thought about using map but couldn't figure it out
11:54:11 <roconnor> edwardk: what are the types for i and j, or did you sneak in a crazy num instance?
11:54:12 <neutrino3000> let me think some more
11:54:12 <hpc> ceti331: internally, the GHC code for IO looks like that
11:54:14 <ReinH> edwardk: I hope your tutorial exists before then ;)
11:54:22 <hpc> but the RealWorld type is fake, and the whole module is a lie
11:54:28 <ceti331> hpc: ahh. perhaps all the monad stuff is sugar for generating that
11:54:31 <jmcarthur> ceti331: my usual explanation of IO is that you can think of a haskell program as a kind of macro language for building imperative programs, but with the additional power than it can create the imperative program dynamically, based on dynamic information
11:54:33 <hpc> ceti331: no
11:54:33 <edwardk> roconnor: using Control.Lens.Representable
11:54:41 <hpc> well yes
11:54:43 <ceti331> hpc: what i just typed looks very easy to understand ..
11:54:43 <edwardk> they are obtained from rep
11:54:44 <hpc> but not specifically that
11:54:55 <jmcarthur> ceti331: ghc's "implementation" of IO is a lie, though
11:54:57 <roconnor> edwardk: I'll wait for the tutorial
11:55:02 <jmcarthur> ceti331: it doesn't explain concurrency, for example
11:55:03 <Nolrai244> For IO, (a >>= b) just means do action a, and the do the action that results from applying b to a's result.
11:55:06 <ceti331> jmcarthur: "macro language" ok now you're making sense
11:55:15 <ceti331> jmcarthur: it can explain a dependancy graph
11:55:25 <edwardk> roconnor: check Physics.Quaternion and its use of 'Representable' in github.com/ekmett/physics
11:55:35 <jmcarthur> ceti331: yes, that's a pretty good direction of thought
11:55:35 <edwardk> rep f = Quaternion (f e) (f i) (f j) (f k)
11:55:45 <edwardk> using the lenses e i j and k
11:55:50 <Athas> neutrino3000: maxs xs = (length xs, maximum (map length xs), maximum (map (maximum . map length) xs), maximum (map (maximum . map (maximum . map length)) xs))
11:55:54 <edwardk> then (>>=) = bindRep follows for free
11:55:56 <ceti331> 'this action can't proceed until this is completed'
11:55:59 <Athas> It's not particularly pretty.
11:56:07 <ReinH> edwardk: physics in haskell... mind blown. thanks for that
11:56:08 <heatsink> Hey, we just came up with a new monad analogy!  The IO monad is like a cake containing values.  The cake is actually a lie, but it's frosted with delicious syntactic sugar.
11:56:14 <ceti331> because it relies on the outside world having been updated.
11:56:16 <ReinH> heatsink: +1
11:56:24 <monochrom> haha
11:56:26 <edwardk> bindRep f m = rep $ \i -> f (m^. i) ^. i
11:56:27 <monochrom> heatsink++
11:56:40 <edwardk> notice the use of lenses to make a monad there
11:57:09 <ceti331> could someone recomend me somehting to *write* that will teach me wtf monads are
11:57:13 <monochrom> is it a monad or a functor? it's both! http://www.vex.net/~trebla/photo/unorganized/burrito-salad.jpg
11:57:15 <ParahSailin> oh god, lenses and monads at the same time
11:57:16 <edwardk> Representable combos very nicely with makeLenses
11:57:18 <smithw> maybe I'm wrong, but my idea of what a monad is is this: is this function a -> b a strictly mathematical function? does it map from exactly one element of type a to exactly one element of tybe b, every time I run it? No? Then the set of elements of type b must be modified by some monad.
11:57:22 <ksf> what's ARR_WORDS in a heap profile? bytestrings? the backbone of Text?
11:57:23 <ion> monochrom: :-D
11:57:23 <ceti331> so far i've got haskell to print some vector maths results
11:57:24 <jmcarthur> ceti331: i think you should just ignore monads for now, honestly
11:57:45 <identity> ceti331: I recommend a pint of guinness followed by several more, after which you take a look at monads.
11:57:46 <ion> TIL functors are like salads.
11:57:48 <identity> it worked for me.
11:57:57 <ceti331> jmcarthur: if they're how actions are structured... how can i ignore them
11:58:03 <jmcarthur> ceti331: once you get familiar with using a lot of different types that happen to be monads, you will start to notice some common patterns
11:58:04 <bartavelle> ceti331, and when you feel like you mean something (error handling, state, stuff) just use them
11:58:15 <bartavelle> s/mean/need/
11:58:16 <identity> If you are so inclined, you can smoke some weed and get high and take a look after that, but I wouldn't dare myself. I think I'd cry because haskell was so beautiful
11:58:16 <ion> Also, ignore monads before you understand applicative functors and ignore them before you understand functors.
11:58:20 <roconnor> edwardk: your monad instance for Quanterions seems like nonsense from a mathematical perspective.
11:58:37 <jmcarthur> ceti331: just pretend for now that in the context of IO, Monad and do notation do what they do for IO. for other types, they do something else. don't worry too much about associating them yet
11:58:42 <edwardk> its more useful for other vectors of course
11:58:51 <dolio> I recommend getting out of here, so you don't have 18 people giving you conflicting, anecdotal methodologies for 'getting' monads.
11:59:11 <ceti331> jmcarthur: i'd be typing shit without knowing what it means, and that is bad..
11:59:15 <Athas> A monad is like a salad in a transparent container, but a functor is a salad in an opaque container.
11:59:23 <jmcarthur> ceti331: it doesn't work like that
11:59:38 <neutrino3000> Athas: that's not simple
11:59:44 <jmcarthur> ceti331: you can write perfectly good code without knowing what a monad is. you've been doing it in C all along, haven't you?
11:59:59 <ksf> c is an arrowchoice, not a monad.
12:00:09 <neutrino3000> Athas: there's a pattern to it, though
12:00:15 <ceti331> what's a monad in C ..
12:00:18 <jmcarthur> ksf: there are other monads in C
12:00:21 * geekosaur really likes http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html ... monads really are something quite simple and you probably have been using them without knowing it
12:00:28 <geekosaur> ceti331, ^^
12:00:53 <BMeph_> ceti331: Can you ride a bus? Can you describe how a bus is built?
12:00:54 <jmcarthur> ceti331: error handling code has a monadic flavor to it. you run some procedure, get some return code, check it, if it failed your current procedure fails, otherwise you continue, rinse and repeat
12:00:55 <ReinH> I liked that one as well
12:01:10 <ceti331> BMeph_: i wouldn't call myself a bus expert unless i did
12:01:20 <ReinH> Maybe and List are the two monadic types that were easiest for me to understand
12:01:21 <ParahSailin> wxhaskell is the "standard" gui lib for haskell?
12:01:24 <jmcarthur> ceti331: seeing it as a monad can save you some work in haskell, but doesn't help much in C
12:01:36 <ddarius> ParahSailin: No.  Why would you think that?
12:01:37 <roconnor> I guess indexing by lenses instead of numbers is a good thing
12:01:40 <jmcarthur> ceti331: but regardless, you are used to working with that kind of abstraction, whether you realize it or not
12:01:42 <edwardk> added (<>~) and (<>=) and traverseValue
12:01:56 <jmcarthur> s/abstraction/thing/
12:02:07 <ParahSailin> ok, what is the common consensus gui framework for haskell
12:02:10 <ceti331> in C one is used to the "no globals" idea for controlling side effects.. just pass pointers and use const to differentiate inputs from outputs
12:02:16 <ddarius> ParahSailin: Why do you think one exists?
12:02:17 <neutrino3000> ParahSailin: wx
12:02:17 <geekosaur> C is incapable of the level of abstraction necessary.  People have done monads in C++ templates but the abstracton doesn't quite work out there eitger
12:02:18 * monochrom is the standard "there is no standard" guy
12:02:21 <ceti331> then the "prototypes" tell you whats going on
12:02:26 <jmcarthur> ceti331: monads are not just for side effects
12:02:39 <jmcarthur> ceti331: for example, the error handling stuff i just mentioned
12:02:40 <ParahSailin> if im going to use something for gui, what should i pick?
12:02:50 <ceti331> i would love an extention to C which says "this function can't use globals"
12:02:50 <ddarius> ParahSailin: That would depend on you and the problem.
12:02:55 <ski> jmcarthur : .. which is a kind of effect :)
12:02:57 <jmcarthur> ceti331: checking for null, etc.   in haskell, Maybe is a kind of monad
12:03:07 <jmcarthur> ski: note the word "just"
12:03:17 <jmcarthur> ceti331: D has pure functions!
12:03:27 <ceti331> jmcarthur: do i want to skip haskell and learn D
12:03:28 <neutrino3000> @hoogle liftM
12:03:29 <lambdabot> Control.Monad liftM :: Monad m => (a1 -> r) -> m a1 -> m r
12:03:29 <lambdabot> Control.Monad liftM2 :: Monad m => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
12:03:29 <lambdabot> Control.Monad liftM3 :: Monad m => (a1 -> a2 -> a3 -> r) -> m a1 -> m a2 -> m a3 -> m r
12:03:29 <jmcarthur> ceti331: i think gcc has an attribute for that, too
12:03:34 <ParahSailin> neutrino3000, wx is the most developed and documented?
12:03:37 <neutrino3000> @hoogle liftM_
12:03:37 <lambdabot> No results found
12:03:39 <jmcarthur> but i don't know how safe it is
12:03:42 <ReinH> the other thing that helped was comparing the list monad to list comprehensions, which I was already familiar with from python, erlang, etc
12:03:48 <neutrino3000> ParahSailin: it's well developed and documented.
12:03:58 <BMeph_> ceti331: This isn't about being a bus expert. This is about using something without having to know how it "really" works inside.
12:04:01 <jmcarthur> ceti331: nah, you want to learn haskell, i'm sure ;)
12:04:02 <ceti331> i think i'll be satisfied when i can explain to someone else what a monad is
12:04:12 <ddarius> ParahSailin: wxHaskell and gtk2hs and maybe one other are fairly well supported and comprehensive.
12:04:23 <Athas> neutrino3000: maxs xs = let g f = maximum . map f in (length xs, g length xs, g (g length) xs, g (g (g length)) xs)
12:04:24 <roconnor> edwardk: okay, so a Traversable type constructor is a type constructor with a canonical multilens?
12:04:26 <ceti331> BMeph_: i need to know how it works...
12:04:28 <jmcarthur> ceti331: you are more likely to learn more by just writing some code than by asking us to give poor explanations
12:04:40 <Athas> neutrino3000: it's hard to simplify because it involves cutting layers off a type.
12:04:40 <jmcarthur> ceti331: and i promise, these *are* poor explanations
12:04:40 <ceti331> jmcarthur: sure.
12:04:41 <edwardk> roconnor: yes
12:04:51 <ddarius> BMeph_: It's not even that, it's about using something without knowing that it is a special instance of something more general.
12:04:52 <ParahSailin> ddarius, that's what i was looking for, not the "mathematically correct" answer
12:05:08 <roconnor> edwardk: and Foldable is?
12:05:09 <neutrino3000> Athas: well, i see a recursive way to do it
12:05:13 <edwardk> notice to mix your original terminology with mine what I call a Traversal is a multilens family ;)
12:05:15 <edwardk> a 'Fold'
12:05:17 <ddarius> ParahSailin: You should ask for what you want rather than for other things.
12:05:30 <roconnor> edwardk: canonical read-only multilens?
12:05:30 <edwardk> that was a 'multigetter' before
12:05:33 <neutrino3000> ParahSailin: ask for money
12:05:34 <edwardk> yes
12:05:41 <identity> ceti331: Yeah, I'd agree with jmcarthur here. Writing code that used monads worked best for me. Then everything else made sense
12:05:48 <roconnor> @type Data.Foldable.fold
12:05:50 <lambdabot> forall (t :: * -> *) m. (Data.Foldable.Foldable t, Monoid m) => t m -> m
12:05:52 <edwardk> toList = toListOf folded
12:05:57 <roconnor> @type Data.Foldable.mapFold
12:05:59 <lambdabot> Not in scope: `Data.Foldable.mapFold'
12:06:02 <identity> same with the State monad and the transformers. I learned to use them and then understood how they worked behind the scenes.
12:06:02 <ddarius> BMeph_: It would be like knowing about buses but not knowing about the term "vehicle"
12:06:03 <roconnor> @type Data.Foldable.foldMap
12:06:04 <lambdabot> forall a m (t :: * -> *). (Data.Foldable.Foldable t, Monoid m) => (a -> m) -> t a -> m
12:06:09 <edwardk> foldMap = foldMapOf folded
12:06:10 <edwardk> etc.
12:06:24 <edwardk> folded :: Foldable f => Fold (f c) a c d
12:06:32 <roconnor> so foldMap is multilens instantiated at the constant monoid functor
12:06:59 <edwardk> i smash a 'Const' in there to make it line up, but ye
12:07:10 <roconnor> okay
12:07:24 <edwardk> folded g = Const . foldMap (getConst . g)
12:07:27 <roconnor> I'm not sure how to diseminate this knowledge to the broader community
12:07:34 <edwardk> i'm working on it =)
12:07:35 <roconnor> but it feels important
12:07:43 <BMeph_> ddarius: Wouldn't it be like demanding to know what a vehicle is before riding a bus?
12:07:45 <edwardk> part of it has been building a whole laundry list of examples in the docs
12:07:56 <ReinH> roconnor: I feel like lens is just sitting there waiting to completely blow my mind
12:08:06 <monochrom> great, now monad is a bus
12:08:08 <edwardk> partial lenses kind of suck because Pointed isn't a superclass of Applicative
12:08:18 <ReinH> monochrom: and Maybe is the short bus?
12:08:25 <roconnor> I think Conor's applicative article said that his work on Applicative was the tip of the iceburg  (not in those words)
12:08:28 <edwardk> and non-empty multi-lenses suck because Apply isn't a superclass of Applicative
12:08:42 <monochrom> or perhaps monad is vehicle, Maybe is a bus, [] is a train
12:08:52 <ddarius> BMeph_: Well that is the situation that people common do, yes, but jmcarthur was talking about understanding buses and cars and trains individually and then, later, capturing their commonality with vehicle.
12:08:59 <roconnor> edwardk: that is why we have WrappedApplicative (WrappedMonad m) !
12:09:01 <edwardk> the former of course admits knowledge that you target at most one element, while the latter lets you know you target at least one, and so foldr1Of, etc. are safe
12:09:07 <roconnor> edwardk: for the Apply and Pointed classes
12:09:12 <identity> monochrom: no. a monad is clearly a burrito.
12:09:15 <mapreduce> Is it a plane?  Is it a bird?  Dunno, but whatever it is, it's a monad.
12:09:24 <edwardk> the problem is that doesn't let you transparenty use a multilens as a partial lens
12:09:29 <monochrom> it's Supermonad
12:09:51 <roconnor> edwardk: ya
12:10:07 <BMeph_> ddarius: Aren't we advocating just riding in a bus, car, truck or plane, without worrying how a "vehicle" "really" works?
12:10:07 <edwardk> now, if i wanted to be pedantic i could use
12:10:13 <ReinH> monochrom: speedMovie :: Bus -> Maybe Bus
12:10:20 <monochrom> hahahaha
12:10:26 <monochrom> ReinH++
12:10:32 <roconnor> my data-accessor-monadLib package is out of date
12:10:37 <ReinH> speedMovie = return
12:10:40 <edwardk> type MultiLens a b c d = forall f. (Applicative f, Pointed f, Apply f) => (c -> f d) -> a -> f b
12:10:43 <roconnor> mostly because I didn't remember it existed
12:10:56 <ReinH> or Just
12:11:04 <ddarius> BMeph_: No, we're advocating learning about bus, car, truck, or plane before worrying about how they are all special cases of an abstract notion "vehicle".  You are quite free to learn how each individual "really" works, or not.
12:11:05 <edwardk> then you could pass it to a partial lens or non-empty multilens
12:11:29 <BMeph_> ddarius: At first, anyway.
12:12:06 <redscare> i have several functions in different modules that require state, is there a standard way of passing them only the relevant state? right now i'm just using a state monad with a Map as the state, and have each external function read that
12:12:07 <startling> meh, I sort of wish there was a do notation for parallel composition
12:12:24 <ddarius> startling: There are.
12:12:31 <startling> ddarius, tell me more
12:12:35 <edwardk> redscare: define lenses to view the parts of your state you want to pass and use 'focus'
12:12:45 <ddarius> @google "monad comprehensions" ghc
12:12:47 <lambdabot> http://hackage.haskell.org/trac/ghc/wiki/MonadComprehensions
12:12:47 <lambdabot> Title: MonadComprehensions – GHC
12:13:07 <startling> ddarius: thanks!
12:13:47 <ceti331> whats the difference between do x<-y  <more>  and do let x=y <more>  ... having just read "its sugar for y>>= .... and (..more) y
12:13:49 <startling> that's close to what I want, but not really.
12:13:55 <edwardk> redscare: the idea is you have, say, data MyState = MyState { _localizationState :: LocalizationState, _configurationState :: ConfigurationState, … }; makeLenses ''MyState
12:14:08 <startling> ceti331, let just names a thing
12:14:33 <heatsink> ceti331, in the context of the IO monad, "x <- y" runs the computation, "y"
12:14:35 <edwardk> and then focus configurationState ::  StateT ConfigurationState m a -> StateT MyState m a
12:14:36 <applicative> ceti331: with let x = y you haven't 'extracted the value', so to say.  suppose it's IO and you say let x = readFile "a.txt"
12:14:50 <startling> ceti331: a <- someMonadicAction runs someMonadicAction and names the result `a`
12:14:52 <heatsink> while "let x = y" just evaluates the side effect free expression "y"
12:15:04 <edwardk> redscare: you can of course define these as one-off combinators instead of importing 'lens'
12:15:22 <startling> ceti331, so if I did "let a = readFile "/etc/passwd", a has type IO String
12:15:32 <applicative> let x = readFile "a.txt" names the action, x <- readFile "a.txt" names the text
12:15:45 <startling> ceti331: if I did a <- readFile "/etc/passwd", a has type String
12:16:18 <redscare> edwardk: It's non-obvious to me how i'd use what you wrote. i guess i'm not familiar enough with haskell. Is there somewhere i can read about this stuff?
12:16:24 <ceti331> ah so <- is sugar for extracting a wrapped value
12:16:30 <ddarius> redscare: Snap uses this pattern.
12:16:34 <heatsink> ceti331, consider this code: do {let read_it = readFile "/etc/passwd"; x <- read_it; return x}
12:16:43 <heatsink> First statement makes a computation but doesn't execute it
12:16:44 <startling> ceti331, "wrapped" is a bit problematic, but yeah
12:16:52 <heatsink> Second statement executes it and reads the text
12:17:02 <ceti331> mathced... tagged...
12:17:03 <edwardk> redscare: http://hackage.haskell.org/packages/archive/lens/1.0.1/doc/html/Control-Lens.html has the haddock for focus, but yeah the snap framework documentation talks about lenses a _lot_
12:17:04 <heatsink> Third statement executes a do-nothing computation that returns x
12:17:17 <ceti331> oh the let just defines an action
12:17:26 <heatsink> It defines anything
12:17:31 <heatsink> I can write "let x = 3"
12:17:33 <startling> ceti331, yep. it can define any other thing too, though
12:17:53 <startling> it's just for giving things names so you can use them later or more than once or whatever
12:17:55 <ceti331> so if you define something with an IO monad, its an action, and the <- forces it to run
12:18:04 <ceti331> by asking for the actual value insude
12:18:07 <heatsink> ceti331, that's a good way of thinking about it
12:18:08 <startling> ceti331, right
12:18:13 <jmcarthur> ceti331: but only if the context you're using <- in is forced to run
12:18:24 <startling> ^ also important
12:18:39 <startling> ceti331, by using <-, you're defining an action that uses another action
12:18:55 <ceti331> so let is more like a very powerful #define , or template definition... wheras <- is an action itself..
12:19:18 <startling> ceti331, it's more like an assignment operator
12:19:19 <ceti331> let builds nodes in a dependancy graph
12:19:38 <ParahSailin> so the <- in list comprehension is the same <- in monadic do notation
12:20:22 <ceti331> from what i know of list compreshensions they're one of the reasons i want to learn haskell..
12:20:54 <roconnor> edwardk: funny how all this will be standard in upper year CS in a few years :D
12:20:57 <raek> >>= composes two actions. when the compund action is executed the left one is executed and the result is passed to a function (the right operand) that returns the other action to execute
12:21:03 <edwardk> one can hope
12:21:05 * roconnor wishes
12:21:09 <bartavelle> is there a key/value container (like HashMap) that is designed to use as little memory as possible ?
12:21:36 <c_wraith> bartavelle: that was one of the primary considerations in unordered-containers
12:21:46 <edwardk> ParahSailin: yep
12:21:46 <bartavelle> another question, is this possible to ask the runtime how much real memory a container (and contained items) is taking ?
12:21:50 <bartavelle> c_wraith, thanks
12:22:00 <ParahSailin> there's probably an unsafe mutable one that has better performance?
12:22:02 <edwardk> bartavelle: not really
12:22:10 <heatsink> bartavelle, if you're in IO, Data.HashTable is fairly memory efficient
12:22:46 <bartavelle> ok I'll test Data.HashTable and that of unordered-containers
12:22:50 <ceti331> <- action;  = definition
12:22:52 <ceti331> ?
12:23:01 <ParahSailin> edwardk, so how would you write a list comprehension without the sugar <-
12:23:18 <edwardk> ParahSailin: i'd just write it with do
12:23:19 * hackagebot cabal-meta 0.2.3 - build multiple packages at once (GregWeber)
12:23:25 <heatsink> <- executes a value (which must be an action) and assigns the result
12:23:27 <heatsink> = assigns a value
12:23:28 <edwardk> and then you can translate from that to >>=
12:23:46 <edwardk> ceti331: yes
12:23:47 <roconnor> edwardk: what is a modify-only multilens ... a functor?
12:24:02 <edwardk> roconnor: a Setter, and yeah 'mapped' is the canonical Setter
12:24:06 <hpaste> neutrino pasted “why doesn't this recursive length function work?” at http://hpaste.org/72302
12:24:16 <edwardk> fmap = adjust mapped
12:24:18 <neutrino3000> i have a problem with this
12:24:23 <edwardk> (<$) = set mapped
12:24:30 <neutrino3000> am i doing something that cannot be done in haskell
12:24:43 <neutrino3000> because this function sure does seem like it'll terminate
12:24:44 <edwardk> overall the relationship to Functor, Foldable and Traversable is very nice
12:24:53 <ceti331> > >>=
12:24:54 <lambdabot>   <no location info>: parse error on input `>>='
12:24:57 <edwardk> since those are kind of the gold standard for useful classes in haskell
12:25:00 <raek> ceti331: do you you have intuition for what "getLine >>= putStrLn" means?
12:25:01 <ceti331> > (>>=)
12:25:02 <lambdabot>   Overlapping instances for GHC.Show.Show (m a -> (a -> m b) -> m b)
12:25:02 <lambdabot>    arisi...
12:25:26 <roconnor> edwardk: I was about to say that Traversable was missing a superclass beside Foldable
12:25:30 <roconnor> edwardk: but it is Functor!
12:25:32 <ceti331> raek: i'm thinking its forcing getLine to run first, and passing the return as input to putStrLn
12:25:32 <startling> should my readSomething function be "IO (Maybe Something)/MaybeT IO Something" or should it be just "IO Something"?
12:25:34 <heatsink> neutrino3000, you probably want a different solution.  What are you using this for?
12:25:34 <edwardk> yep =)
12:25:40 <ceti331> but there's some monad matching going on too....
12:25:41 <roconnor> which is why the setting laws are the functor laws
12:25:44 <ceti331> which i'm hazy on
12:25:45 <roconnor> it all fits together
12:25:46 <edwardk> exactly
12:25:54 <Athas> neutrino3000: indeed, it is impossible to assign a type to this function.
12:25:56 <neutrino3000> heatsink, do you see the list at the top? it has multiple levels
12:26:03 <edwardk> once that connection came clear the rest of the api fell together
12:26:13 <neutrino3000> i want a function which can tell me the max length at a specific level
12:26:21 <roconnor> so the Foldable, Functor, Traversable heirarchy is simply the canonical versions of mirrored multilenses
12:26:28 <edwardk> yep
12:26:39 <neutrino3000> can this not even be done with the new dependent types extensions?
12:26:40 <Athas> neutrino3000: you'd need dependent types for that function to be typable, and you don't have that in Haskell.
12:26:42 <edwardk> and with that insight you can do things like
12:26:42 <startling> ceti331, nope, that's pretty much it.
12:26:42 <raek> ceti331: the expression itself isn't what causes the actions to be executed (binding it to the name "main" does that)
12:26:51 <roconnor> well, now I feel more confident about stating the Setter laws
12:26:51 <neutrino3000> i thought we had naturals in the newest ghc
12:26:52 <heatsink> neutrino3000, do you want to check the list depth at run time or compile time?
12:26:55 <ceti331> startling: did i explain it right?
12:27:00 <neutrino3000> at run time heatsink
12:27:02 <edwardk> anyOf traverseText (=='c') -- so work with 'any' on a 'monomorphic' container
12:27:22 <neutrino3000> well
12:27:24 <roconnor> what are the types of anyOf and traverseText?
12:27:24 <neutrino3000> to correct you
12:27:27 <startling> ceti331, "nope" was to your self-doubt.
12:27:32 <neutrino3000> i want to check the list size
12:27:43 <neutrino3000> and i want to define the depth i'm checking at, at runtime
12:27:57 <edwardk> anyOf :: Getting Any a b c d -> (c -> Bool) -> a -> Bool
12:28:05 <ceti331> i mean now thats making sense.... run this, pass a value along..
12:28:05 <Athas> neutrino3000: there is no way to express "arbitrarily deeply nested lists" in Haskell.
12:28:15 <edwardk> traverseText :: Simple Traversal Text Char -- (actually its in a class so it can work with strict and lazy Text)
12:28:21 * hackagebot lens 1.0.3 - Families of Lenses, Folds and Traversals (EdwardKmett)
12:28:25 <neutrino3000> what about expressing "lists nested n levels deep for any n"
12:28:37 <heatsink> neutrino3000, okay.  For run time checks you should define a new data type that contains either a list or a value
12:28:45 <raek> ceti331: getLine is an action and putStrLn is a function from string to action. "getLine >>= putStrLn" is also an action that when executed will run getLine first, pass the result to putStrLn and then execute the returned action
12:28:46 <heatsink> You can express fixed-depth list nesting
12:28:52 <roconnor> edwardk: what is Text?
12:28:55 <edwardk> if you could only 'fold' text then that would be fine too
12:28:57 <edwardk> Data.Text
12:29:05 <Athas> neutrino3000: you have to define your own list type, no matter what.
12:29:17 * roconnor isn't familiar with data.text
12:29:20 <edwardk> its a bytestring like container of utf-16 encoded characters
12:29:24 <neutrino3000> why do i need to
12:29:39 <edwardk> then use traverseByteString :: Simple Traversal ByteString Word8
12:29:48 <edwardk> anyOf traverseByteString (==0x80)
12:29:48 <ceti331> raek: ah. so >>= composes actions  ... and still needs to be put in a "do" or something else to actually run?
12:29:56 <ceti331> (and passes values along)
12:29:59 <startling> ceti331, no, do isn't the key
12:30:13 <Athas> neutrino3000: because the list type must have a statically determined depth.
12:30:24 <startling> ceti331, the idea is that a >>= b doesn't *run* a and then b, it creates a new monadic action that does those things
12:30:40 <roconnor> edwardk: oh it is Bytestring for strings?
12:30:40 <heatsink> neutrino3000, there needs to be a way to do one of two things: either check at run time whether you have a list or something else; or prove at compile time that you have a list or something else
12:30:41 <startling> ceti331, it's sort of similar to function composition in this respect
12:30:44 <ceti331> ok that i think i get, "creates nodes in a dependancy graph".. ?
12:30:56 <heatsink> neutrino3000, To do run time checks, you define a data type and pattern match on teh data type
12:30:57 <roconnor> edwardk: ah that is what you said
12:31:03 <Athas> neutrino3000: well, you can do it with runtime type casting, but it's ugly.
12:31:03 <startling> ceti331, well, the entry point to everything is `main`.
12:31:18 <ceti331> so really main .... will always perform that action?
12:31:18 <startling> ceti331, and `main` naturally depends on whatever you put on it
12:31:22 <ceti331> and 'do' is just composing actions?
12:31:31 <roconnor> edwardk: oh neat.  Bytestring cannot be traversable because it isn't polymorphic, hence the need for a multilens
12:31:32 <startling> ceti331, something like that
12:31:43 <raek> ceti331: the do notation lets you write do { x <- a; y <- b; return (x + y) } instead of a >>= (\x -> b >>= (\y -> (return x + y)))
12:31:46 <edwardk> toListOf traverseText :: Text -> String
12:31:46 <edwardk> yep
12:31:48 <ceti331> and 'procedures' would just be more composed actions?
12:31:56 <ion> ceti331: In the context of IO only, you get an IO action to run by assigning it to “main” (e.g. main = print "foo"). Operators like (>>=) can be used to combine IO actions into new, bigger actions (e.g. main = getLine >>= print). Anything not assigned to main won’t be executed (e.g. main = [ print "foo", print "bar", print "baz" ] !! 2 only prints "baz").
12:31:58 <ceti331> (that main links into its dependancy graph)
12:31:58 <edwardk> and you can use things like lengthOf traverseText to get a very inefficient length on Text ;)
12:32:10 <edwardk> anyways gotta run. bbiab in an hour or so
12:32:13 <ceti331> ok
12:32:26 <neutrino3000> heatsink: how can i do it at compile time?
12:32:54 <ceti331> it is perhaps a shame we have the baggage of the word "function" instead of "procedure"
12:33:05 <ceti331> in c
12:33:14 <neutrino3000> why
12:33:19 * hackagebot cabal-meta 0.2.3.1 - build multiple packages at once (GregWeber)
12:33:23 <neutrino3000> C is purely functional
12:33:28 <heatsink> neutrino3000, it requires some relatively sophisticated use of types.
12:33:28 <ceti331> procedural
12:33:29 <jmcarthur> ugh this
12:33:34 <ceti331> C is procedural
12:33:43 <jmcarthur> reference to this http://conal.net/blog/posts/the-c-language-is-purely-functional
12:33:59 <neutrino3000> C has no side effects outside of the well established operations on the state machine that it performs
12:34:06 <neutrino3000> it's just that there are very many states
12:34:19 <jmcarthur> well there's that attempt at an explanation, too
12:34:28 <heatsink> You can express the list depth with two types, ListOf and Id, so that depth 0 = Id, depth 1 = ListOf Id, depth 2 = ListOf (ListOf Id), and so forth
12:34:32 <ceti331> that sounds like stretching definitions
12:34:37 <jmcarthur> i think C is more of an automata, in that sense :P
12:34:42 <neutrino3000> it's not an attempt, in architectures C was developed for you could map out the whole state space on a piece of paper
12:35:01 <dolio> Define "purely functional."
12:35:03 <neutrino3000> it's not C's fault you use it for things it wasn't meant for
12:35:08 <roconnor> Data.Traversable should have the laws that traverse Identity === Identity and that composeCoalgebroid law
12:35:08 <ceti331> mathematics has functions. computers have procedures (and somethimes they return values..)
12:35:40 <ceti331> it doesn't seem helpful to start claiming c is purely functional
12:35:46 <neutrino3000> heatsink: what sophisticated use of types would that be?
12:35:52 <neutrino3000> heatsink: you got me intrigued
12:36:05 <heatsink> neutrino3000, I'll annotate it on pastebin
12:36:20 <neutrino3000> heatsink: thanks. mind explaining it to me after that?
12:36:46 <intrigue> took me a minute to figure out why my terminal beeped neutrino3000
12:36:49 <intrigue> :)
12:37:00 <ddarius> @google "What is a purely functional language"
12:37:01 <startling> jmcarthur, that's an interesting read, thanks
12:37:02 <lambdabot> https://www.cs.indiana.edu/~sabry/papers/purelyFunctional.ps
12:37:10 <neutrino3000> :)
12:37:34 <ddarius> intrigue: You should adjust your regex.
12:37:43 <intrigue> indeed :)
12:38:10 <intrigue> I was like "Oh, hey someones talki... Oh.. Nevermind =("
12:38:25 <neutrino3000> owwww
12:38:27 <startling> intrigue, seems pretty common in this channel
12:38:38 <ddarius> intrigue: I have always recommended using a UUID as a nick.
12:38:58 <Athas> isomorphic is a particularly tragic example.
12:39:13 <startling> as are fmap and applicative and ski
12:39:24 <neutrino3000> that's just as startling as it makes me intrigued
12:39:44 <ski> @where purely-functional
12:39:44 <lambdabot> "What is a Purely Functional Language?" by Amr Sabry in 1993-01 at <https://www.cs.indiana.edu/~sabry/papers/purelyFunctional.ps>
12:40:20 <startling> funnily enough, people don't say "startling" very often
12:40:30 <ddarius> No one named monad.
12:40:48 <ski> neutrino3000,Athas : `data ArbitrarilyNestedList a = Element a | ListLevel [ArbitrarilyNestedList a]' vs. `data UniformlyNestedList a = Element a | NestAllLists (UniformlyNestedList [a])' -- try to figure out how these two differs ?
12:40:51 <neutrino3000> monad would be one popular guy
12:40:52 <ski> roconnor : s/because it isn't polymorphic/because it isn't parametric/ :)
12:41:32 <roconnor> ski: okay
12:41:38 <neutrino3000> ski: i see the difference in constructors but i don't know what to make of it
12:41:58 <Athas> ski: it's a rather easy problem if you define your own list type.
12:42:04 <roconnor> ski: I'm not entirely sure what the difference is
12:42:05 <ddarius> neutrino3000: Unfold the recursion.
12:42:22 <ski> neutrino3000 : let's abbreviate the data constructors as `E',`LL' in the first case, and `E',`NAL' in the second case
12:42:24 <roconnor> ski: since in Haskell-land polymorphic is shorthand for "parametric polymorphic"
12:42:48 <neutrino3000> ski: ok
12:43:19 <ski> neutrino3000 : now, in the first case, we can have values like `E 0',`LL [E 0,LL [LL [],E 1 LL [E 2]],E 3]',`LL [LL [E 0,E 1,E 2],LL [],LL [E 3,E 4]]'
12:43:39 <neutrino3000> ski: yes
12:43:50 <ion> 148c7920-5791-49ac-8fd6-d5625046bb1f: Your idea about using a UUID as a nick is excellent.
12:44:37 <ski> neutrino3000 : while in the second case we can only have ones like `E 0',`NAL (E [0,1,2])',`NAL (NAL (E [[0,1,2],[],[3,4]]))',`NAL (NAL (NAL (E [[[0,1],[2]],[],[[3,4,5]]])))'
12:44:37 <neutrino3000> ion: you'd need to go on a crash diet in order to become neutrino
12:45:15 <ddarius> data UniformlyNestedList a = Zero a | Succ (UniformlyNestedList [a])
12:45:25 <ski> neutrino3000 : so, in the first case, we can have arbitrary distance from the root to the `E'-leaves -- while in the second case, the distance to the leaves has to be the same for all the leaves in a single tree / nested-list
12:45:55 * heatsink is still figuring out how to compute nested list length
12:46:09 <neutrino3000> ski: right, i just understood why
12:46:22 <neutrino3000> ski: it's because every time we nest in the second one we get a new set of braces
12:46:27 <neutrino3000> whereas the first one is more like a tree
12:46:34 <ski> neutrino3000 : the second data type is known as a "non-regular datatype", because, defining `UniformlyNestedList a', recursive occurances are not just exactly `UniformlyNestedList a' (in fact `UniformlyNestedList [a]' in this case, with `[a]' instead of `a')
12:46:37 <neutrino3000> oo-ary tree
12:46:57 <ddarius> neutrino3000: The typical name is a rose tree.
12:47:01 <ion> heatsink: Are you sure you want to use nested lists instead of a tree of some kind?
12:47:02 <ski> neutrino3000 : usually, to be able to work usefully with non-regular data types, you need to use "polymorphic recursion"
12:47:18 <neutrino3000> how do you use polymorphic recursion?
12:48:08 <osa1> this function stucks in infinite loop when I enable commented lines and comment out the rest, can anyone help? http://hpaste.org/72303
12:48:34 <ski> neutrino3000 : a variant of the second is `data PerfectlyBalancedBinaryTree a = Elements a | Double (PerfectlyBalancedBinaryTree (a,a))' -- a (total) tree of type `PerfectlyBalancedBinaryTree a' contains exactly `2 ^ n' elements of type `a', for some natural number `n'
12:48:45 <Athas> neutrino3000: you just do.  But in some languages, the type system requires that a recursive call has the same type as the current call.
12:48:55 <ceti331> can haskell itself implement pointers to specific blocks of memory (locked for GC) with monads.. perhaps peek and poke 'actions'..
12:49:01 <ddarius> Athas: In most languages.
12:49:05 <ski> neutrino3000 : "how do you use polymorphic recursion?" -- just by writing the recursion you want, *and* writing a type signature (the type signature can't be inferred in this case)
12:49:11 <startling> osa1, dunno, but the idiomatic way to do \_ -> x is "const x"
12:50:11 <neutrino3000> ski: can i apply this uniformly nested list in order to solve my problem?
12:50:17 <Athas> ceti331: there are IO actions for manual memory management, yes.
12:50:32 <ddarius> > return 3 4
12:50:33 <lambdabot>   3
12:50:36 <neutrino3000> i think i can
12:50:45 <neutrino3000> i can match against the NAL constructor
12:50:58 <heatsink> neutriono3000, does it matter whether all lists have exactly the same nesting depth?  If not, the tree solution is simpler.
12:51:06 <ski> neutrino3000 : e.g. to define `sumPBBT :: Num n => PerfectlyBalancedBinaryTree n => n' you can say `sumPBBT = mergePBBTWith (+)'
12:51:28 <neutrino3000> heatsink: well, they *do* all have the same depth of nesting, so it seems the more natural data type?
12:51:32 <ceti331> could you implement something like zlib decompression with that (not link to zlib library)
12:51:51 <neutrino3000> ski: don't get it?
12:51:54 <Athas> ceti331: why would you need manual memory management to implement zlib decompression?
12:52:11 <ceti331> manual pointers for stepping through and decoding blobs
12:52:24 <ceti331> or would it be done as a stream
12:52:26 <Athas> Manual memory management is usually only used when you need to interact with C libraries.
12:52:39 <heatsink> neutrino3000, it is a closer fit.  But keeping track of the nesting statically makes things harder, like in the perfect tree example above.
12:52:41 <Athas> Probably.  I'm not familiar with zlib specifically.
12:52:46 <ceti331> ok so you can read a 'blob' bymanually extracting from a byte array
12:52:49 <neutrino3000> ski: oh i get it now
12:52:56 <AJ__> hey there
12:52:56 <neutrino3000> pbbt = that binary tree you mentioned
12:53:00 <ski> neutrino3000 : and then `mergePBBTWith :: (a -> a -> a) -> (PerfectlyBalancedBinaryTree a -> a)' is defined by polymorphic recursion as `mergePBBTWith merge (Elements a) = a; mergePBBTWith merge (Double taa) = merge a0 a1 where (a0,a1) = mergePBBTWith (\(l0,r0) (l1,r1) -> (l0 + l1,r0 + r1)) taa'
12:53:01 <AJ__> i have a question
12:53:01 <ceti331> in C , i would build data structures as blobs, with relative pointer links..
12:53:08 <Athas> Yeah, you'd just use a byte array.
12:53:13 <AJ__> why should i use haskell ? and where ?
12:53:17 <Athas> This isn't C, you shouldn't do too many memory tricks.
12:53:42 <ceti331> Athas: what about writing a new type of compression algorithm
12:53:47 <ddarius> AJ__: Maybe you shouldn't.
12:53:50 <Athas> AJ__: to obtain more correct programs, and on lambdabot, of course!
12:54:04 <ski> neutrino3000 : "can i apply this uniformly nested list in order to solve my problem?" -- no idea what your problem is, so dunno
12:54:10 <Athas> ceti331: I don't understand what that has to do with details about memory management.
12:54:35 <ceti331> not so much memory management, but parsing custom datastructures that didn't come from the langauge's own syntax
12:54:38 <neutrino3000> ski itym (\(l0,r0) (l1,r1) -> (merge l0 l1, merge r0 r1))
12:54:47 <ski> er, sorry, right
12:55:16 <neutrino3000> ski my problem is: i have a uniformly nested list (however not like you mentioned, it's just a haskell list for now)
12:55:18 <Athas> ceti331: you'd write a parser, like in any other language.
12:55:19 <ceti331> i'm trying to think what it would look like in haskell: building a blob with relative pointer links
12:55:46 <roconnor> @type traverse
12:55:47 <lambdabot> Not in scope: `traverse'
12:55:48 <Athas> You can't do memory tricks, like how C allows you to cast some random memory address to a structure pointer, no.
12:55:58 <roconnor> @type Data.Traversable.traverse
12:55:59 <lambdabot> forall a (f :: * -> *) b (t :: * -> *). (Data.Traversable.Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
12:56:08 <ceti331> Athas: perhaps you could make functions to assemble bytes into values
12:56:14 <ddarius> Athas: C doesn't allow that.
12:56:25 <ceti331> it does
12:56:29 <ski> neutrino3000 : exercise : given `(Double . Double . Double . Elements) (((0,1),(2,3)),((4,5),(6,7)))', figure out in what order (and nesting) these numbers gets added
12:56:30 <neutrino3000> ski: i look at it as an n-dimensional construct, which fits into a minimal n-dimensional hypercube of sorts (what do you call a cube with differing dimensions?)
12:56:33 <Athas> ddarius: alright, but C programmers do it.
12:56:33 <ceti331> C can treat any memory as anything
12:56:36 <jmcarthur> ceti331: no it doesn't
12:56:42 <ceti331> it most certainly does
12:56:45 <jmcarthur> ceti331: it's illegal. compilers just allow it to happen
12:56:46 <ion> ceti331: ByteString is the “standard” type for blobs.
12:56:49 <Athas> ceti331: technically, the C *language* doesn't permit it.
12:56:51 <ceti331> wtf.
12:56:53 <ceti331> its very legal
12:56:54 <Athas> It's implementation-defined behaviour.
12:57:08 <ceti331> its very much what C is for
12:57:11 <jmcarthur> lol
12:57:35 <jmcarthur> i bet this is the core of why you think C compilers can emit the assembly that ghc does
12:57:35 <Athas> Yes, it's what C is in principles for, but it's not actually part of the language, because it has such machine-specific semantics.
12:57:41 <ski> ceti331 : it's undefined behaviour
12:57:44 <ceti331> lmao
12:57:49 <Athas> It's not even portable across compilers, because structure padding isn't standardised.
12:57:56 <ddarius> Athas: And compiler specific.
12:57:58 <neutrino3000> ski my guess is 04 15 26 37
12:58:12 <ceti331> oh of course a structure will look different
12:58:13 <neutrino3000> but i might be wrong
12:58:14 * BMeph is strangely reminded of US drug laws: just as illegal, just as tolerated; granted, maybe slightly more off-topic, but still...
12:58:16 <neutrino3000> anyways
12:58:20 <neutrino3000> going back to my problem
12:58:27 <ceti331> but you can make wrappers to extract vaues from memory any way you like
12:58:28 <Athas> That said, let's not get into this debate again.  ceti331 is obviously arguing from the point of view of a C programmer, not a language lawyer.
12:58:30 <jmcarthur> ceti331: technically when you do that the compiler is allowed to emit whatever crap it wants
12:58:55 <startling> it can even start nethack!
12:59:04 <ceti331> #ifdef ...#else #error I_HAVEN'T_PORTED_MY_CODE_TO_THIS_COMPILER_YET
12:59:30 <ceti331> #error BUT_IT_WORKS_ON_THE_MAJOR_PLATFORMS_IVE_USED
12:59:34 <ddarius> ceti331: You are free to write in "GCC C for x86-64" and use any guarantees it provides.
12:59:56 <Athas> Out of curiosity, does Haskell have any implementation-defined semantics, rather than small things like the size of Ints?
13:00:03 <Athas> I don't recall any from the Haskell Report.
13:00:15 <ceti331> sure you are right - you have to be mindful of struct padding. but fundemendally, you are free to assemble and reason about data in any way you see fit
13:00:16 <jmcarthur> ceti331: some examples: http://en.wikipedia.org/wiki/Undefined_behavior#Examples_in_C_and_C.2B.2B
13:00:22 <neutrino3000> ski: i have [[[a]]], nested 3 times. i look at it as inhabiting a^n, for example R^n, and each value of type [[[a]]] fits in a 3-dimensional box (hyperrectangle)
13:00:30 <shachaf> Athas: "rather than"?
13:00:35 <neutrino3000> ski: i want to figure out the dimensions of that minimal box
13:00:37 <hpaste> heatsink annotated “why doesn't this recursive length function work?” with “why doesn't this recursive length function work? (annotation)” at http://hpaste.org/72302#a72305
13:00:44 <Athas> shachaf: sorry, I mean "apart from".
13:00:59 <ceti331> i've dealt with alignment , padding, endian issues just fine...
13:00:59 <heatsink> Well, I gave up on the more elegant solution and made this one
13:01:07 <neutrino3000> ski: to do this, i need to figure out the max lengths at the level [hole], [[hole]], and [[[hole]]], and [[[a]]]
13:01:22 <neutrino3000> well i guess i don't need the last one
13:01:30 <ddarius> Athas: I don't think it is spelled out, but what is passed to fail when you fail a pattern match in do-notation isn't specified.
13:01:48 <jmcarthur> ceti331: i think it's even illegal to add an offset to a pointer that's greater that overflows the array it points to, even if you never dereference it, and even if you later subtract from it to obtain what might in some compilers be a valid pointer again
13:01:55 <neutrino3000> heatsink: looking
13:01:56 <neutrino3000> thanks
13:01:56 <jmcarthur> s/that's greater//
13:02:01 <startling> ddarius: oh man, that sucks
13:02:01 <ddarius> > do Nothing <- return (Just 3); return 1 :: Either String Int
13:02:03 <lambdabot>   *Exception: Pattern match failure in do expression at <interactive>:3:3-9
13:02:05 <ski> ceti331 : see John Regehr's "Compilers and Termination Revisited" in 2010-06-07 at <http://blog.regehr.org/archives/161>, "A Guide to Undefined Behavior in C and C++, Part 1" in 2010-07-09 at <http://blog.regehr.org/archives/213> (and part 2 in 2010-07-23, part 3 in 2010-07-30), and " Contest: Craziest Compiler Output due to Undefined Behavior" in 2012-07-12 at <http://blog.regehr.org/archives/759>
13:02:15 <ceti331> jmcarthur: i guess i better throw my million+ selling programs away then
13:02:26 <jmcarthur> by no means
13:02:29 <startling> ceti331, not what he's saying at all
13:02:31 <jmcarthur> i'm just saying, these are illegal
13:02:36 <jmcarthur> by the language spec
13:02:44 <jmcarthur> you are simply relying on compiler-dependent behavior
13:02:45 <ceti331> ok
13:02:49 <ceti331> sure i am
13:02:50 <jmcarthur> nothing wrong with that as long as you realize it
13:02:50 <ceti331> and i do test
13:03:11 <startling> C is a "get away with doing the least amount of evil" type language, anyway
13:03:17 <ddarius> Does Either not have an appropriate fail instance?
13:03:28 <jmcarthur> > fail "foo" :: Either String Int
13:03:29 <lambdabot>   *Exception: foo
13:03:38 <shachaf> ddarius: Nope, it's defined for arbitrary (Either e)
13:03:46 <Athas> When C programmers say "C", they mean "the C implementation on my platform", just like when Haskell programmers say "Haskell" and actually mean "Haskell with a kilobyte of LANGUAGE pragmas prepended".
13:03:56 <jmcarthur> no fail implementation is "appropriate" ;)
13:04:19 <heatsink> Also, this blog post about undefined behavior problems that compiler authors have seen in practice http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html
13:04:30 <ceti331> i had this on another channel.
13:04:41 <ceti331> supposedly i can't assume 'char' goes from -128->+127
13:04:49 <ceti331> well every CPU i've used, it does.
13:05:11 <shachaf> ceti331: Those statements are both correct.
13:05:12 <startling> ceti331, you can't assume integers use two's complement either
13:05:21 <heatsink> neutrino3000, does it need an explanation?
13:05:22 <ceti331> and i've used quite a lot of CPUs
13:05:23 <bartavelle> capitalizing the first letter of a Text by doing "cons (toUpper $ T.head x) (T.tail x)" would cost O(length(x)), is there a O(1) way ?
13:05:23 <ski> jmcarthur : it's legal to have a pointer to the (nonexisting) "element" just past the last element of an array
13:05:35 <ceti331> since 1984
13:05:36 <bartavelle> T.con
13:05:45 <ddarius> ceti331: 5 is not "quite a lot."
13:05:47 <startling> ceti331, oh, definitely. it's a flaw in C that the language wasn't designed to handle these cases
13:05:49 <shachaf> bartavelle: No, because a (strict) Text is contiguous in memory.
13:06:08 <bartavelle> ok
13:06:25 <startling> ceti331: nevertheless, compiler writers have come up with fairly standards ways to handle them
13:06:34 <ski> ddarius : someone suggested `fail = Left . error'
13:07:13 <ceti331>  6502 68000 80486 r3000 more x86 sh4 r5600 vu  powerpc arm.  i'm inthe habit of assuming amongst other things, cha goes from -128->+127 :) its a safe assumption.
13:07:28 <Athas> ceti331: to return to your original question: in Haskell, as in most higher-level languages, you have to explicitly parse binary data and construct a Haskell value.  There's no memory tricks that can help you.
13:07:29 <ceti331> if char didn't do that - chances are it would be a machine that can't run that program anyway
13:07:42 <ddarius> > runIdentity (runErrorT (do Nothing <- return (Just 1); return 1))
13:07:43 <lambdabot>   Ambiguous type variable `e' in the constraints:
13:07:43 <lambdabot>    `Control.Monad.Trans.Err...
13:07:44 <Athas> ceti331: that said, Haskell has powerful parser combinator libraries that can make such parsing very efficient and succint.
13:07:51 <ddarius> > runIdentity (runErrorT (do Nothing <- return (Just 1); return 1)) :: Either String Int
13:07:52 <startling> ceti331, you continue to spectacularly miss the point
13:07:52 <lambdabot>   Left "Pattern match failure in do expression at <interactive>:3:27-33"
13:07:56 <ddarius> There we go.
13:07:58 <ceti331> cell
13:07:59 <ski> (so that `do Nothing <- Right (Just ()); Right ()' would definitely return something of shape `Left ...')
13:08:01 <ceti331> 10 cpus
13:08:06 <ceti331> 11 counting SPU
13:08:08 <ion> bartavelle: Btw, that implementation doesn’t take combining characters into account.
13:09:13 <bartavelle> ion what do you mean ?
13:09:42 <shapr> ceti331: Er, nine cores on the Cell actually.
13:09:44 <shachaf> bartavelle: Capitalization is tricky business.
13:09:55 <ceti331> shapr: i'm counting ISA's
13:09:58 <ceti331> that i've used
13:09:58 <ski> ceti331 : iirc, there were platforms with `CHAR_BIT' being `36'
13:10:14 <bartavelle> shachaf, yes, I am only handle pure ascii here
13:10:15 <ceti331> ski: maybe but having encountered 11 ISA's i've never seen one.
13:10:18 <ddarius> ski: Probably PDP-10 etc.
13:10:22 <Athas> ski: I think ZETA-C was like that.
13:10:29 <geekosaur> PDP10 used CHAR_BIT == 9
13:10:30 <bartavelle> handling
13:11:15 <ceti331> i'm aware that C is used for microcontrollers and DSPs' but you dont port whole desktop programs to those
13:11:24 <Athas> Hm, no, ZETA-C had 8 bit chars, but on the other hand it was unsigned.
13:11:30 <jmcarthur> ski: okay, that's familiar, but no farther than that, right?
13:12:04 <shachaf> ceti331: What exactly are you arguing?
13:12:04 * bartavelle wishes "cabal install xx -p" would try to compile the profiling version FIRST
13:12:06 <ski> jmcarthur : right (e.g. not before the element at index `0')
13:12:19 <Athas> ceti331: all of this is a question of semantics (literally!).  It won't expand your Haskell knowledge.
13:12:45 <ceti331> shachaf: that assumptions like char goes from -128->127 are safe for a C programmer
13:13:23 <ceti331> because after working with 11 ISA's since 1984 years i've never seen otherwise
13:13:24 <shapr> ceti331: What do you think Char does in Haskell?
13:13:38 <ceti331> no idea at this point, if Int is 30 bits :)
13:13:43 <shachaf> shapr: Char in Haskell has nothing to do with char in C, other than the name.
13:13:46 <ski> jmcarthur : so e.g. `for (p = start + len - 1; p >= start; p--) ...' is UB
13:13:47 <ceti331> ok
13:13:49 <shapr> shachaf: Yes, I agree.
13:14:07 <confusing> > "char" == "Char" -- lambdabot confirms it
13:14:09 <lambdabot>   False
13:14:16 <t7> are there any imperative languages with type classes based generics like haskell?
13:14:33 <ion> t7: Haskell for one.
13:14:36 <ddarius> t7: What are "type classes based generics"?
13:14:38 <startling> t7, I'm thinking about writing one
13:14:53 <startling> I have a parser going, at least
13:15:32 <Athas> @type ord
13:15:33 <lambdabot> Char -> Int
13:15:46 <ski> @google how to make ad-hoc polymorphism less wadler
13:15:47 <lambdabot> http://homepages.inf.ed.ac.uk/wadler/topics/type-classes.html
13:15:47 <lambdabot> Title: Wadler: Type classes
13:15:58 <Athas> So I guess the only restriction on Char is that it can't have more distinct values than Int.
13:16:19 <hape01-> @type (.)
13:16:20 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
13:16:21 <shachaf> Char represents a Unicode character, doesn't it?
13:16:25 <heatsink> yeah
13:16:27 <ski> @type (Prelude..)
13:16:27 <shachaf> And Unicode is limited to, what, 21 bits?
13:16:27 <lambdabot> forall b c a. (b -> c) -> (a -> b) -> a -> c
13:16:39 <shachaf> And Int is required to be 29 bits.
13:16:40 <Athas> You never know with those Unicode folks, they're adding all sorts of strange things...
13:16:51 <ion> > logBase 2 (fromIntegral (maxBound :: Char))
13:16:51 <lambdabot>   No instance for (GHC.Real.Integral GHC.Types.Char)
13:16:52 <lambdabot>    arising from a use of...
13:16:58 <ion> err
13:17:00 <t7> ddarius: type safe templates
13:17:01 <jmcarthur> i think Char is a unicode "codepoint", whatever that means
13:17:01 <Athas> One day you'll wake up, and Unicode will be a 128 bit charset.
13:17:05 <t7> with sub types
13:17:06 <ion> > logBase 2 (ord maxBound)
13:17:06 <lambdabot>   No instance for (GHC.Float.Floating GHC.Types.Int)
13:17:07 <lambdabot>    arising from a use of...
13:17:08 <shachaf> jmcarthur: Er, right.
13:17:11 <ion> err²
13:17:20 <ion> > (logBase 2 . fromIntegral) (ord maxBound)
13:17:22 <lambdabot>   20.087461546321563
13:17:24 <hape01-> @ 1+1
13:17:44 <ceti331> so basically if you want to encode say colour values or "half-floats" for openGL you've got to use foreign types
13:17:45 <ddarius> Athas: And then it will take 128 bits to represent Char and Int will still need only 30 bits at least.
13:17:47 <ski> hape01- : try `> 1 + 1'
13:18:09 <heatsink> ddarius, then the Enum class will have to be redefined :)
13:18:10 <ddarius> ceti331: OpenGL is a foreign library.
13:18:15 <Athas> ddarius: isn't 'chr . ord' defined to be an identity?
13:18:16 <hape01-> >1+1
13:18:24 <ddarius> Athas: I don't think so.
13:18:24 <jmcarthur> ceti331: for what it's worth, Int is the native machine int, in GHC
13:18:48 <hape01-> > 1+1
13:18:48 <jmcarthur> the main difference is that it's boxed
13:18:50 <lambdabot>   2
13:19:22 <ski> > reverse "-10epah olleh"
13:19:23 <lambdabot>   "hello hape01-"
13:19:32 <mausch> Hi all, what would be a good, simple, English name for the Monoid a => Applicative ((,) a) instance? "Pair with monoid"? Is it hopeless?
13:19:40 <heatsink> GHC has a pretty good interface for byte-level data manipulation
13:19:41 <shachaf> mausch: Writer?
13:19:45 <startling> is there a bifunctor-like thing whose bimap takes two arguments?
13:19:46 <jmcarthur> ceti331: but if you ever find yourself depending on that, you should just use Int32 or Int64 or whatever you need
13:19:54 <ceti331> Int32 ok
13:19:59 <startling> err, whose bimap takes a function that takes two arguments
13:20:01 <ddarius> @hoogle bifunctor
13:20:02 <lambdabot> package bifunctors
13:20:04 <heatsink> It's easier to use than C's interface for byte-level data manipulation, IMO
13:20:07 <ski> mausch : output ?
13:20:10 <jmcarthur> ceti331: rarely should you be depending on that, though, IMO
13:20:19 <hape01-> ski: :-)
13:20:22 <mausch> shachaf: good one
13:20:32 <shachaf> I think "Writer" is the standard name, except for the newtype and tuple order.
13:20:46 <ion> Erlang’s bitstrings are the best thing i’ve seen so far for bit/byte-level data parsing and generation so far.
13:20:49 <startling> ddarius, not what I want
13:21:02 * ski always thinks of it as "output(/logging) and environment monad" in his head, not "writer and reader monad"
13:21:24 <ddarius> Yeah, I don't like the "Reader"/"Writer" names either.
13:21:25 <ski> (many of the papers uses the former terms instead of the latter)
13:21:51 <identity> Reader/Writer definitely confused me a whole lot in the beginning. I also recently saw someone thinking he had to use the Reader monad to read files in Haskell.
13:21:55 <ceti331> can you get haskell onto an iphone (e.g. generating C?)
13:21:57 <identity> I think it was on SO, even.
13:22:15 <ceti331> i guess getting into google NaCl would be easier
13:22:20 <jmcarthur> ceti331: these guys have ghc working for the iphone http://ipwnstudios.com/
13:22:26 <ceti331> ah nice
13:22:36 <heatsink> I thought Apple had a rule that you had to write iphone code in approved languages
13:22:37 <joeyh> now if there were only android ..
13:22:44 <jmcarthur> ceti331: not much support though
13:22:44 <ceti331> ah JNI
13:22:49 <shachaf> Someone got GHC generating Android code too.
13:22:50 <ion> It might also be good if Functor was named Mappable or something.
13:22:54 * ski . o O ( "SO" ~ "Significant Other" )
13:23:00 <jmcarthur> ion: why?
13:23:04 <startling> heatsink, they're loosening up about that
13:23:10 <heatsink> Oh, that's nice
13:23:11 <joeyh> shachaf: any urls?
13:23:18 <startling> heatsink, people have used lua and python recently with no trouble, I hear
13:23:24 <identity> ski: Are you implying that I'm in a relationship with stack overflow?
13:23:25 <ion> jmcarthur: For the same reason Environment might be a better name for Reader.
13:23:30 <shachaf> joeyh: No, it's not released. But it was also for http://ipwnstudios.com/
13:23:32 <identity> I know I don't have a life, but it's not nice to point it out :(
13:23:36 <neutrino3000> heatsink: still looking. sorry, got distracted.
13:23:46 <jmcarthur> ion: the difference is that Functor has a well-defined meaning from category theory already
13:23:51 <joeyh> shachaf:  ok. I need to do t withn the next 6 months if possible..
13:23:58 <ion> jmcarthur: That’s not disputed.
13:24:14 <jmcarthur> i do think Environment makes more sense than Reader
13:24:16 <shachaf> joeyh: Ask the ipwnstudios people about it, I guess.
13:24:49 <ceti331> there's a lot in graphics programming that can be expressed as dependancy graphics
13:25:32 <ski> identity : i'm saying that's what "SO" automatically expands to, in my mind
13:25:33 <startling> can anyone think of a catchy name for a function that takes a list of [a -> b] and an a, applies all the functions to the a, and then uses some function on the output to get a single b?
13:25:34 <ceti331> graphs
13:25:55 <confusing> ion: but if it was called Mappable or something, it couldn't cause frenzies of math babble anymore
13:26:00 <neutrino3000> heatsink: your Nest is like the NestAllLists from ski's example with uniformly nested lists, right?
13:26:08 <startling> @hoogle [a -> b] -> ([b] -> b) -> a -> b
13:26:08 <lambdabot> Data.Generics.Aliases ext1Q :: (Data d, Typeable1 t) => (d -> q) -> (forall e. Data e => t e -> q) -> d -> q
13:26:11 <ion> jmcarthur: I’d be fine with Haskellers interested of CT (myself included) having to learn Mappable is the same as functor instead of all newbie Haskellers having to learn Functor is anything mappable.
13:26:18 <ski> identity : "environment" was used before the "reader" name, when talking about the concept in papers
13:26:21 <shachaf> startling: That sounds like a composition of two unrelated functions.
13:26:22 <ski> er
13:26:25 <ski> ion ^
13:26:54 <startling> shachaf, between a ([a -> b] -> a -> [b]) and a ([b] -> b), you mean?
13:27:00 <ski> ion : and it already has a traditional meaning in interpreters, which is the right meaning here
13:27:13 <shachaf> @ty sequence :: [a -> b] -> a -> [b]
13:27:14 <lambdabot> forall a b. [a -> b] -> a -> [b]
13:27:16 <confusing> ion++, that's thoroughly sensible
13:27:27 <shachaf> Or, alternatively, map ($ x) list
13:27:38 <ski> ion : also "environment variables" in shells is basically the same idea (though they're also mutable within a process)
13:27:41 <shachaf> And [b] -> b is probably a fold or something, I don't know.
13:27:50 <ion> ski: aye
13:27:58 <startling> shachaf, yep, I use sequence and folds in this definition
13:28:02 <ddarius> :t \f -> f . sequence
13:28:03 <lambdabot> forall b (m :: * -> *) a. (Monad m) => (m [a] -> b) -> [m a] -> b
13:28:06 <startling> shachaf, I still need a catchy name for it. :)
13:28:20 <shachaf> startling: Do you really need a name for it?
13:28:26 <ddarius> :t (.: sequence)
13:28:27 <lambdabot> forall b (g :: * -> *) a. (Monad g, Functor g) => ([a] -> b) -> [g a] -> g b
13:28:31 <Nolrai24> How do I figure out If I need Monad, or if Aplicative is good enough?
13:28:53 <startling> shachaf, yes. I want a dsl-like high-level api
13:29:05 <startling> Nolrai24, do you use <*> or >>=?
13:29:10 <ski> ion : "I’d be fine with Haskellers interested of CT (myself included) having to learn Mappable is the same as functor instead of all newbie Haskellers having to learn Functor is anything mappable." -- they (probably) have to learn the concept (more or less) from scratch anyway, why not learn it under the right name to start with ?
13:29:48 <ski> ion : they'd need more info than just the name `Mappable'/`Functor' in any case, to understand what is meant
13:29:49 <Nolrai24> startling: Well right now I am using >>=, but do I need to is my question.
13:30:18 <ion> nolrai24: Well, can you rewrite it using <*>? If you can, then you don’t need Monad.
13:30:34 <mausch> Nolrai24: have you seen http://www.haskell.org/haskellwiki/Applicative_functor#How_to_switch_from_monads ? I think it's a pretty good guide to start getting used to applicatives
13:30:37 <ddarius> My experience is that most people don't have trouble with Functor, name or concept.
13:30:49 <ski> > flip [(^ 2),(^ 3)] 5  -- startling
13:30:50 <confusing> startling: perhaps "each"? each [f, g, h] 42 combiner ...
13:30:51 <lambdabot>   [25,125]
13:31:19 <heatsink> neutrino3000, it's similar
13:31:43 <heatsink> neutrino3000, the types carry different information and the run-time tags are in different places
13:31:55 <startling> ski, how does that work?
13:32:04 <startling> confusing, hm, yeah, that's an interesting idea
13:32:05 <ski> startling : it's a generalization of the ordinary
13:32:08 <yitz> personally, "Mappable" wouldn't have said much to me before I learned Haskell anyway
13:32:22 <yitz> and Functor has been what it's called since the 1940's
13:32:31 <ski>   flip :: (e -> (a -> b)) -> (a -> (e -> b))
13:32:33 <shachaf> When did "-able" become popular for typeclasses?
13:32:55 <yitz> shachaf: ok then. "Mappative"
13:32:57 <ski> startling : set `f' to be `(e ->)', and then generalize to any `Functor f', so you get
13:33:07 <ski>   flip :: Functor f => f (a -> b) -> (a -> f b)
13:33:40 <ski> startling : i.e. you recover the original by setting `f' to `(e ->)' (which is a functor)
13:33:49 <startling> ski, oh, is this not the Prelude `flip`?
13:34:18 <ski> right, this is one which Cale defined in lambdabot (on my request, as a companion to his `(.) = fmap')
13:34:38 <ski> the deail with `(.) = fmap' is :
13:34:47 <startling> ski: makes sense now.
13:34:55 <startling> ski, yeah, functions are functors, I know
13:35:05 <ski>   (.) :: (a -> b) -> ((e -> a) -> (e -> b))
13:35:18 <ski> as before, generalize `(e ->)' to any functor `f', and we get
13:35:21 <startling> which is part of the reason I don't think Mappable covers what functors are
13:35:29 <ski>   (.) :: Functor f => (a -> b) -> (f a -> f b)
13:35:33 <ski> which is just `fmap'
13:35:42 <startling> ski: yep
13:35:50 <Cale> What is Mappable?
13:36:03 <startling> Cale, people are saying Functor should be "Mappable"
13:36:08 <Cale> er
13:36:13 <yitz> Cale: they decided to rename Functor
13:36:20 <Cale> Who decided?
13:36:22 <ski>   flip f_ab a = fmap ($ a) f_ab  -- startling, this is the definition of the generalized `flip'
13:36:35 <Cale> Functor is a fine name
13:36:37 <yitz> Cale: our gang on #haskell
13:36:44 <Cale> and it's possible to look up what it means
13:36:45 * heatsink renames Monad to Doable
13:36:46 <ski> startling : and btw, i didn't invent it, i saw it in some paper somewhere, i think
13:37:09 <ciaranm> monad should be WarmFuzzyThing
13:37:12 <Nolrai24> Okay which opperator combines two error actions giving you the first that doesn't fail.
13:37:23 <neutrino3000> heatsink: wait, what other information do they carry?
13:37:35 <ddarius> Nolrai24: <|>
13:37:36 * ski is in the "keep the `Functor' name" camp
13:37:38 <startling> ski, wow neat
13:37:44 * startling too.
13:37:50 <Cale> Is this a discussion on one of the mailing lists?
13:38:03 <Cale> I should really start paying attention to the mailing lists again
13:38:12 <Nolrai24> @find (<|>)
13:38:13 <lambdabot> Not in scope: type variable `<|>'
13:38:20 <heatsink> neutrino3000: In my version, each list node contains a tag that says whether it's a list or not
13:38:22 <Nolrai24> >_<
13:38:23 <ski> (i don't see what would really be improved by having it called `Mappable', even if we disregard the history of it not being called that in the past)
13:38:26 <startling> Nolrai24, it's in Control.Applicative
13:38:31 <Nolrai24> Thanks!
13:38:40 <startling> Nolrai24: it's a method of Alternative
13:38:44 <heatsink> neutrino3000, in ski's version, there is only one tag per nesting level, total
13:39:01 <Nolrai24> startling++
13:39:04 <heatsink> neutrino3000, I started with a version more like ski's, but couldn't figure out how to write the function
13:39:04 <ciaranm> i want a magic "lift" thing that's like "do" except that it work with functors, applicatives etc too
13:39:09 <ski> Cale : no idea -- i think ion (and possibly others ?) suggested `Mappable' above
13:39:21 <startling> LiftToAble
13:39:37 <ski> @index <|>
13:39:38 <lambdabot> Text.ParserCombinators.Parsec.Prim, Text.ParserCombinators.Parsec
13:39:46 <ski> @hoogle (<|>)
13:39:46 <lambdabot> Control.Applicative (<|>) :: Alternative f => f a -> f a -> f a
13:39:46 <lambdabot> Text.Parsec.Prim (<|>) :: (ParsecT s u m a) -> (ParsecT s u m a) -> (ParsecT s u m a)
13:39:46 <lambdabot> Text.ParserCombinators.Parsec.Prim (<|>) :: (ParsecT s u m a) -> (ParsecT s u m a) -> (ParsecT s u m a)
13:39:51 <ski> @hoogle+
13:39:53 <ion> ciaranm: What would the syntax look like?
13:40:02 <ski> oh, i suppose it's the first one there
13:40:06 <ski> Nolrai24 ^
13:40:18 <ciaranm> ion: magic
13:40:23 <neutrino3000> heatsink: hmm ok
13:40:38 <heatsink> neutrino3000, Also, in my version, an N-deep list has a different type from an N-1 deep list.  In ski's, they have the same type.
13:40:40 <ciaranm> really, i'm just sick of writing liftA6 etc, which the compiler can obviously work out for me
13:40:41 <Nolrai24> @hoogle noMsg
13:40:41 <lambdabot> Control.Monad.Trans.Error noMsg :: Error a => a
13:40:41 <lambdabot> Control.Monad.Error.Class noMsg :: Error a => a
13:40:41 <lambdabot> Control.Monad.Error noMsg :: Error a => a
13:40:54 <neutrino3000> oh, let me look at that again
13:40:59 <startling> ciaranm, use <$> and <*>
13:41:05 <ion> ciaranm: Ah, you might be thinking of banana brackets.
13:41:15 <ciaranm> startling: i know, i know, but i mean in general
13:41:18 <ciaranm> ion: pretty much
13:41:26 <startling> ciaranm: yeah, understood
13:41:41 <startling> the somethingXN functions are kind of ridiculous
13:41:42 <confusing> ski: names like "Functor" encourage into the notion that before learning haskell, you need full understanding of a thousand complicated math concepts. i think that notion is unfortunate and not accurate
13:41:52 <ciaranm> oh boo frickin' hoo
13:41:57 <confusing> s/into//
13:42:13 <ciaranm> you don't hear java programmers moaning that they have to know what inheritance is before they can write java code
13:42:17 <neutrino3000> heatsink: right, you use the peano number parameter as part of the type
13:42:19 <Nolrai24> Why is ghc saying noMsg is not a visible method of Error?
13:42:31 <ddarius> ciaranm: And sure enough, most Java programmer's don't understand inheritance.
13:42:32 <startling> confusing, I don't think that'll change if you changed it to Mappable
13:42:42 <startling> ddarius: heh
13:42:53 <ciaranm> ddarius: well to be fair, neither did the people who wrote the java standard library
13:43:00 <ciaranm> see UnsupportedOperationException
13:43:00 <Nolrai24> I can see confusing's point.
13:43:16 <ddarius> ciaranm: I suspect those people were Java programmers.
13:43:16 <startling> @src flip
13:43:17 <lambdabot> flip f x y = f y x
13:43:19 <ciaranm> also haskell should stop using the term "Int"
13:43:22 <startling> oh right
13:43:27 <heatsink> haha
13:44:01 <ddarius> type Int = Free Group ()
13:44:11 <ddarius> Well, that would be Integer.
13:44:55 <ciaranm> yeah, and who needs []?
13:45:08 <ciaranm> type [a] = Free Monoid a
13:45:19 <ddarius> type Natural = Free Monoid ()
13:45:24 <avpx> Heh.
13:45:25 <Nolrai24> We really do need a Nat and Natural types too.
13:45:32 <avpx> ddarius: That does not sound very efficient.
13:45:52 <ciaranm> avpx: your compiler is free to substitute in an isomorphic type
13:45:53 <ddarius> Nolrai24: We have Word types.
13:46:01 <avpx> ciaranm: Like church numerals :p
13:46:08 <ion> Word, yo
13:46:25 <ddarius> But having a GMP backed Natural would make a lot of sense for GHC.
13:46:29 <ciaranm> church numerals are silly.
13:46:30 <neutrino3000> heatsink, ski, Athas thanks guys, you have really helped me
13:46:33 <Nolrai24> ddarius: eh..but word types are all machine level stuff.
13:46:39 <avpx> ciaranm: Yes, thus the :p
13:46:42 <heatsink> Glad to be helpful.
13:46:43 <avpx> ciaranm: It is meant to convey silliness
13:46:46 <ddarius> The problem is the numeric hierarchy.
13:46:58 <ciaranm> i mean, you're guaranteed a natural numbers object in Hask anyway
13:47:04 <Nolrai24> Hmm. You mean the Num class?
13:47:15 <ciaranm> it's one of the axioms of the elementary theory of the category of Hask
13:47:27 <avpx> ddarius: Indeed. The fact that Float implements Num is problematic, for instance.
13:47:30 <startling> I'm pretty fond of "data Nat = Zero | Succ Nat" myself
13:47:36 <ski> confusing : "names like \"Functor\" encourage into the notion that before learning haskell, you need full understanding of a thousand complicated math concepts" -- i don't agree. it's just a new language-specific term, which are pretty common
13:47:38 <avpx> It seems to me that Num should really be a Field
13:47:40 <ciaranm> startling: you need to learn some category theory
13:47:45 <Nolrai24> Num is too big. Needs to be broken up.
13:47:48 <ddarius> ciaranm: Hask isn't a category (at least in the naive way of defining it).
13:47:49 <startling> ciaranm, working on it. :)
13:48:10 <ion> avpx: Hmm. What’s the issue with Float being an instance of Num?
13:48:28 <avpx> ion: Floating point numbers behave badly.
13:48:32 <ciaranm> ddarius: eh, we just make our axioms say it is, and then call haskell a model of Hask
13:48:39 <startling> it's a good demonstration of haskell's power, though
13:48:58 <startling> same as "data List a = Nil | Cons a (List a)
13:48:58 <avpx> ion: They don't even form a group under addition, so to put them in the same class as the integral types seems wrong to me.
13:49:10 <ddarius> 16GB to represent maxBound :: Int32, yay!
13:49:12 <Nolrai24> @hoogle Error
13:49:13 <lambdabot> Prelude error :: [Char] -> a
13:49:13 <lambdabot> Control.Exception.Base ErrorCall :: String -> ErrorCall
13:49:13 <lambdabot> Control.Exception ErrorCall :: String -> ErrorCall
13:49:13 <heatsink> > let x = recip 0 in let y = x - x in y == y
13:49:14 <lambdabot>   False
13:49:22 <ciaranm> startling: oh boy. you're going to have such a happy when you learn about free algebras.
13:49:43 <avpx> It seems like free algebras are the new hotness in this channel
13:49:54 <startling> ciaranm, I've used Free actually! I don't think I fully grok it though
13:49:54 <ceti331> changing float to not be "Num"
13:50:20 <ddarius> There are several different notions of "Free" floating around.
13:50:21 <ReinH> Athas: I'm about to start recording my first haskell live coding video!
13:50:35 <avpx> It seems to me that there should be classes for additive groups, rings, and fields that all guarantee certain axioms.
13:50:57 <ReinH> Athas: I have a question about boolean blindness if/when you have a moment
13:51:26 <Nolrai24> I almost though think (+) and (*) should be in classes that don't say anthing other then this type uses this symbol.
13:51:44 <heatsink> ceti331, the Set library behaves weirdly when used with Float, because it assume that (x == x) for any x, but (per the IEEE standard) NaN is not equal to NaN.
13:51:51 <startling> Nolrai24: indeed
13:51:55 <heatsink> > x `member` Data.Set.fromList [x]
13:51:57 <lambdabot>   Not in scope: `Data.Set.fromList'Not in scope: `member'
13:52:08 <startling> heatsink, that bugs me a lot
13:52:10 <startling> I don't get it
13:52:36 <startling> wouldn't (== NaN) be useful for checking whether a thing is NaN?
13:52:47 <ddarius> There's isNaN.
13:52:48 <ion> class Plus a b c | a b -> c where (+) :: a -> b -> c  -- ;-)
13:52:51 <startling> I suppose it probably also defines an isNaN
13:52:51 <startling> yeah
13:53:14 <avpx> I guess NaN is a lot like the IEEE-754 equivalent of _|_
13:53:24 <ddarius> startling: The idea is two NaN could be arrived at in different ways and thus should not be considered equal.
13:53:29 <avpx> > undefined == undefined
13:53:30 <lambdabot>   *Exception: Prelude.undefined
13:53:33 <heatsink> The rationale is probably that NaN is like (exists x. x), and two such values are probably not equal
13:54:03 <startling> meh. haskell should just use Maybe Float and have Nothing be equivalent to NaN
13:54:09 <ion> (NaN == NaN) == FileNotFound
13:54:13 <heatsink> ^
13:54:14 <ddarius> Most of the rules in IEEE are designed so that common numerical algorithms can be written without cases.
13:55:24 <ion> That’s why they don’t support denormal floats.
13:56:20 <Nolrai24> Is there more then one Error class?
13:56:58 <ceti331> nice legs up together :)
13:58:22 * hackagebot fay 0.4.0.1 - A compiler for Fay, a Haskell subset that compiles to JavaScript. (ChrisDone)
13:58:41 <Nolrai24> wow.
13:58:50 <Nolrai24> Thats somewhat impresive.
13:59:09 <avpx> Fay?
14:00:56 <avpx> I've played around with it. Works pretty intuitively, though I've had trouble doing anything nontrivial with the FFI.
14:01:01 <ski> Nolrai24 : you mean like e.g. `class (+) infixl 6 a :: a a -> a' at <http://clean.cs.ru.nl/download/html_report/CleanRep.2.2_8.htm#_Toc311798063> in Clean ?
14:01:23 <joeyh> it's quite cool :)
14:01:41 <Nolrai24> Yep.
14:01:54 <ski> avpx : except that `NaN' is detectable
14:02:18 <Nolrai24> Though if you required (+) to be assositive you wouldn't piss me off.
14:02:20 <joeyh> I like how the js it generates is so clear you can see eg, the thunks and forces and currying, and maybe learn something about the input haskell :)
14:02:54 <joeyh> avpx: its FFI is just a way to run arbitrary js methods, right?
14:03:00 <avpx> joeyh: Basically.
14:03:12 <joeyh> seems like something a pile of libraries will cure nicely
14:03:25 <ski> Nolrai24 : then `StdClass' defines `class PlusMin a | + , - , zero a' subclassing those three classes, and also `class MultDiv a | * , / , one a', and then `class Arith a | PlusMin , MultDiv , abs , sign , ~ a'
14:03:38 <avpx> joeyh: What might be nice is a set of jQuery bindings
14:03:48 <joeyh> yes, that was my same thought today
14:04:03 <joeyh> wonder if jquery has a machine parsable API
14:04:06 <luite> Nolrai24: there are actually already far more full-featured haskell->js compilers, but it's difficult to get the right mix of easy to use, small code size, features, and performance
14:04:22 <ski> Nolrai24 : presumably `PlusMin' would come with the laws for a commutative(?) group ..
14:04:38 <avpx> What I like about Fay is that it interoperates well with existing JavaScript code
14:05:06 <takemitsu> I am wondering: Is the future of JavaScript to become the C of Web programming into which other languages compile to?
14:05:08 <luite> fay is easy to use and generates small code, but i think it can overflow the javascript stack easily (not 100% sure)
14:05:08 <Nolrai24> You need a Ring class below Arith.
14:05:32 <luite> avpx: ghcjs also supports the haskell ffi for javascript interaction
14:05:42 <Nolrai24> Lots of things have plus minus and mult, but not div, abs, or sign
14:05:44 <joeyh> hmm, he added tail call optimisation, dunno how good
14:05:46 <avpx> luite: Oh, that's good
14:05:53 <luite> joeyh: oh in that case i'm probably wrong
14:06:31 <ddarius> > (0.00000005 + (0.00000005 + 1) :: Float) == ((0.00000005 + 0.00000005) + 1 :: Float)
14:06:33 <lambdabot>   False
14:06:43 <luite> avpx: ghcjs is a bit more difficult to call, callhs(haskellFunction,args,callbackNormal,callbackException)
14:06:49 <luite> something like that
14:07:16 <ddarius> takemitsu: That's already happened.
14:07:17 <Nolrai24> (and Rings with out addive inversis pop up in CS a fair bit. Types for instances.)
14:07:34 <luite> it's like that because ghcjs has haskell threads and asynchronous IO in the rts
14:07:45 <ddarius> Nolrai24: Those are typically called Rigs.
14:08:05 <Nolrai24> Really? Good to know.
14:08:22 * hackagebot shelly 0.13.2.1 - shell-like (systems) programming in Haskell (GregWeber)
14:08:24 * hackagebot shelly 0.13.3 - shell-like (systems) programming in Haskell (GregWeber)
14:08:54 <joeyh> so much good stuff, so little time..
14:09:13 <ddarius> Nolrai24: Semiring is another name for them.
14:10:02 <takemitsu> ddarius: Really? I don't know much about Web programming. Aren't there still people who use pure JavaScript framworks? Or is their number dwindling?
14:10:24 <Nolrai24> Theres still people who use C.
14:10:24 <ddarius> takemitsu: There are a lot of people who still use C.
14:11:10 <Nolrai24> Hell most of whats on this computer I am using was writen in C.
14:11:22 <startling> yeah, isn't it terrible?
14:12:34 <avpx> Could be worse.
14:12:52 <luite> takemitsu: unfortunately javascript is a pretty bad compilation target :(
14:13:11 <ddarius> luite: So is C.
14:13:15 <broombs> I've just installed Cabal on my ubuntu box.  Now how do I make sure it's the latest version?
14:13:25 <ddarius> cabal install cabal-install
14:13:51 <broombs> ddarius: when I do that, I get warnings that other packages will break.
14:13:57 <broombs> ddarius: strike that.
14:14:08 <broombs> ddarius: when I try that, I'm told I'll need to use the 'reinstall' flag.
14:14:28 <gwern> http://news.ycombinator.com/item?id=4309727 dependency hell
14:14:36 <ddarius> Then, if you've done a cabal update recently, you probably have the latest version.
14:14:38 <avpx> luite: Yeah, and then you throw thunks into the mix... My conjecture is that Fay is very slow.
14:14:43 <luite> ddarius: C is still a whole lot better if you know a few things about your platform, especially if you can use some compiler extensions or inline asm
14:14:52 <avpx> Then again, most JavaScript stuff is event handling, not exactly CPU-intensive stuff
14:15:05 <startling> is Fay lazy?
14:15:09 <luite> startling: yes
14:15:11 <avpx> Yes.
14:15:13 <startling> weird
14:15:29 <luite> startling: why?
14:15:41 <broombs> ddarius: after doing a cabal update, 'cabal install cabal-install' warns me that several other packages will be broken if I proceed.
14:15:42 <avpx> The laziness is handled in a pretty intuitive / naive way.
14:15:50 <startling> I was under the impression most functional language -> js compilers were strict
14:16:07 <luite> avpx: yeah probalby. i'm experimenting a bit with code generators for ghcjs, hopefully getting something a bit faster
14:16:11 <ddarius> Most functional languages are strict.
14:16:25 <sm> broombs: adding --avoid can sometimes fix that
14:16:34 <luite> avpx: but it looks a whole bunch more low-level than what fay spits out
14:17:15 <luite> still i don't really care that much about how the javascript looks, as long as it's fast and not too big
14:17:20 <ddarius> broombs: Why do you need the latest cabal (also Cabal is the name of a library).
14:17:29 <broombs> ddarius: why not??
14:17:32 <luite> and it's possible to implement MVar and scheduler on top of it
14:17:53 <broombs> ddarius: I thought we should always use the latest versions of *any* package.  And besides, I'll have to 'upgrade' it sooner or later, no?
14:18:10 <avpx> luite: ghcjs seems like a more sensible solution, TBH
14:19:14 <luite> avpx: it's quite heavyweight though, fortunately it removes unused functions from its output. i thnk it would be nice if someone could write a nice standard library for javascript and page interaction that only depends on a limited amount of haskell (so not too many packages, not too much of base)
14:20:06 <luite> the text package gets you around 3 megabyte of javascript :)
14:20:11 <broombs> ddarius: let me put it another way.  Suppose several months from now, I need to upgrade my cabal.  How should I do that?
14:20:23 <startling> so is there a typeclass somewhere that implements mapWithKey like Data.Map has?
14:20:26 <Saizan> broombs: cabal --version ?
14:20:47 <broombs> Saizan: that does not perform an upgrade :-)
14:20:55 <Saizan> broombs: no, it was a question
14:21:08 <ddarius> broombs: You would do it by cabal install cabal-install or by upgrading whatever you installed to get cabal-install.
14:21:22 <broombs> ddarius: yes, but that throws warnings.
14:21:23 <Saizan> broombs: can you tell me the output of that command on your system?
14:21:33 <parcs`> broombs: you wait for your distro to update the cabal-install package
14:21:36 <broombs> cabal-install version 0.14.0
14:21:36 <broombs> using version 1.14.0 of the Cabal library
14:21:42 <ddarius> broombs: Yes, because upgrading can break things which is why everyone doesn't use the latest version of everything all the time.
14:21:45 <avpx> luite: Compiling a hello world program in ghc produces a 1 MB executable on my machine.
14:21:49 <Saizan> broombs: you have the latest cabal-install version.
14:22:00 <avpx> luite: It seems like compiled Haskell programs are generally very very large.
14:22:11 <luite> avpx: yeah well for native executables that's acceptable
14:22:21 <startling> javascript is plaintext, though
14:22:47 <luite> startling: right, the output compresses well, but it's still not difficult to end up with something that's well over a megabyte gzipped
14:22:49 <startling> whereas executables pack more semantics into any given byte
14:23:02 <avpx> You think so?
14:23:17 <luite> avpx: yeah i tried :p
14:23:28 <avpx> luite: I was talking to startling :p
14:23:31 <luite> oh
14:23:32 <luite> hehe
14:23:37 <avpx> startling: A byte of x86 output is not very expressive.
14:23:38 <ddarius> startling: If that were true on average, source files would always be larger than object files.
14:24:04 <ddarius> That said, disassembling machine code will almost never make it smaller.
14:24:10 <startling> ddarius, but you're linking to other source files presumably, yeah?
14:24:29 <startling> meh, I dunno
14:24:45 <joeyh> does ghc strip unused functions when linking in pre-compiled cabal libraries statically?
14:25:07 <ddarius> joeyh: No, ld does.
14:25:08 <joeyh> I've been wondering about this as my binary grows towards 20 mb (stripped) after adding yesod
14:25:10 <broombs> Saizan: that's encouraging news.  But, out of curiosity, why does 'cabal install cabal-install' say that, if I supply the --force-reinstalls flag, then it will (re)install a bunch of new packages or new versions of old packages?
14:25:14 <joeyh> well, same diff.
14:25:38 <luite> avpx: you can use cabal with ghcjs btw, it has its own cabal db
14:25:41 <broombs> That just makes it seem (to me) like I don't have the most up-to-date version.
14:25:50 <Saizan> broombs: because it's trying to install the previous version, actually
14:26:01 <broombs> Saizan: ??
14:26:01 <joeyh> ddarius: even when linking in a .a file?
14:26:23 <broombs> Do I understand correctly?  It would try to install an *older* version of cabal-install?
14:26:50 <Saizan> broombs: yeah, because it's the preferred one at the moment, according to hackage
14:27:28 <Saizan> broombs: but it doesn't easily build on ghc-7.4.1
14:27:50 <broombs> OK, this is really complicated for me. :-(
14:28:02 <luite> oh ghcjs currently fails to install with the latest shelly and http-conduit, i need to push my changes, but have messed them up a bit in a separate branch
14:28:15 <broombs> I suppose the best thing to do at this point is not to try to understand too much and just move forward without an update...
14:28:38 <Saizan> ..you already have the newest cabal, there's nothing you could update to
14:28:50 <broombs> Saizan: right, sorry.
14:29:04 <broombs> Anyway, many thanks for your help.  This whole business has made me quite anxious.
14:29:21 <Saizan> and anyhow it's better to be not so update hungry
14:29:33 <broombs> OK.
14:29:50 <broombs> These problems actually began when I tried to install snaplets.
14:30:21 <broombs> I then completely uninstalled snap and even ghc, and reinstalled.  And I want to make sure I take the right steps from here on.
14:31:23 <avpx> luite: Well, it's an interesting project and I think a more promising direction when it comes to compiling Haskell to JS
14:31:55 <avpx> Fay is nice in that it produces readable output but I'd rather have a compiler with all the power of GHC.
14:32:22 <k0001> I'm trying to understand why this doesn't work http://ideone.com/2IOw9 Can someone give me any hints?
14:33:50 <Saizan> k0001: "foo :: forall a. Bool -> Foo a" means that the caller of foo can decide what 'a' is, not the implementation of foo
14:34:34 <luite> avpx: there's also the haste compiler, which is similar to ghcjs in approach, maybe a bit more stable and faster, but doesn't implement threading
14:34:52 <scooty-puff> k0001, perhaps you mean foo :: Bool -> (forall a . Foo a -> b) -> b?
14:35:13 <luite> avpx: and it also doesn't support bytestrings and finalizers and the like
14:36:24 <luite> avpx: but it has its own non-threaded frp framework
14:37:31 <Obfuscate> You're really forced to make some tradeoffs when compiling (just about anything) to javascript, since the language is a somewhat odd target.
14:38:23 <luite> yeah that's why there are at least 4 different approaches now :)
14:39:32 <avpx> Definitely.
14:40:18 <scientes> http://www.yesodweb.com/book/shakespearean-templates
14:40:24 <scientes> why don't you guys just use haml?
14:41:23 <sm> broombs: you've already done the right thing by running cabal 0.14, it will keep you on track
14:41:36 <haskcat> I have a type class like class Ref r where ref :: (a -> b) -> (b -> a -> a) -> r a b and a type synonym type Lens a b = forall f. Functor f => (b -> f b) -> a -> f a. Why can't I do instance Ref Lens where ref = lens?
14:41:38 <k0001> Saizan: I tried your suggestion but it yields the same error. scooty-puff: Well, your suggestion certainly works, but it is not what I was looking for.
14:42:20 <Saizan> k0001: mine wasn't a suggestion, was an explanation of why you get the error
14:42:27 <haskcat> error: type synonym Lens should have 2 arguments, but has been given none in the instance declaration for Ref Lens
14:42:33 <sm> broombs: and if you have projects whose dependencies just can't coexist, turn to virthualenv
14:42:55 <ReinH> does maybe have an inverse?
14:43:06 <geekosaur> k0001, I did not see a suggestion from Saizan, I saw an explanation of why what you are trying to do makes no sense
14:43:07 <Saizan> k0001: the forall a. was only to emphasize the role of 'a', the type is equivalent to the one in your paste
14:43:14 <haskcat> yet instance Ref (->) where ref = const works fine
14:43:16 <pozic_> sm: how does that work?
14:43:24 <haskcat> any ideas?
14:43:46 <geekosaur> oh, I',m slow
14:44:14 <ddarius> haskcat: You can't make instances out of type synonyms.
14:44:38 <haskcat> I am using -XTypeSynonymInstances
14:44:57 <haskcat> (and -XRank2Types)
14:44:59 <ddarius> haskcat: All that does is fully expand the type synonym.
14:44:59 <sm> pozic_: it makes a nearly completely independent local cabal package set in ./.virthualenv
14:45:10 <ski> haskcat : type synonyms must be fully applied in instances
14:45:17 <k0001> Saizan geekosaur ohh, now I see. Well, thanks then.
14:45:17 <haskcat> oh :(
14:45:32 <ski> haskcat : `TypeSynonymInstances
14:45:33 <ReinH> for instance: let showSquare:: Char -> Maybe Piece; showSquare = maybe ' ' showPiece; let readSquare = ? (assume I have readPiece)
14:45:42 <haskcat> is there a workaround, or is it pretty much impossible to do this then?
14:45:42 <ski> ' really only buys you some convenient shorthand
14:45:53 <ddarius> haskcat: What you are trying to write is equivalent to instance Ref (/\a b. forall f. Functor f => (b -> f b) -> a -> f a)
14:46:25 <haskcat> right
14:46:32 * ski would write `\a b.' rather than `/\a b.' there, reserving the latter for terms taking types
14:46:39 <haskcat> is that a limitation of haskell's type system?
14:46:49 <pozic_> sm: it doesn't solve the problem where one library wants to depend on two different versions of a package?
14:46:51 <ddarius> haskcat: Yes.  There are not type lambdas.
14:47:03 <ski> haskcat : it is a limitation that is imposed to guarantee the termination of the type-checker
14:47:04 <ddarius> Also, it would make instance resolution somewhat difficult and/or ambiguous.
14:47:29 <haskcat> is there a way to do it with UndecidableInstances?
14:47:34 <ski> haskcat : possibly it could be lifted somewhat, at the cost of complicating the rules of what is and what isn't allowed / supported
14:47:41 <ddarius> haskcat: No.  Certainly not in any sane way.
14:47:41 <ski> haskcat : i don't think so
14:47:48 <ddarius> haskcat: Just make a wrapper newtype.
14:47:50 <haskcat> :(
14:48:01 <pozic_> You always hear how Haskell is so compositional with its functions, but having composable packages apparently was too much work.
14:48:08 <sm> pozic_: no, it wouldn't solve that. By two versions, you mean two differently-depending builds of a package, with the same version number, ie the old cabal problem which 0.14 prevents, right ?
14:48:25 <ddarius> ski: Yes, we could support higher order pattern unification, though that would add a -lot- of complexity to the implementation and probably to the semantics as well.
14:48:53 <ski> perhaps it might be nice to distinguish more between first-class type functions, and ones which must always be fully applied, possibly giving them different kinds (maybe with a subkinding relation relating them)
14:49:00 <haskcat> ddarius, it won't work in this case. the idea with the ref class is to allow one to use a ref as a lens or a regular function automatically
14:49:12 <ski> then one could possibly declare a class (or a type) which took such a second-class type function (only) as argument
14:49:43 * ski ponders away
14:49:45 <haskcat> if I stick a newtype in there then I need to unwrap it, breaking the illusion
14:50:04 <ski> ddarius : is that the same as "L-lambda unification" ?
14:50:12 <ddarius> ski: Yes.
14:50:17 <ski> ok
14:50:21 <pozic_> sm: I am just talking about any composition of packages.
14:50:37 <ddarius> There are a lot of things you can add to superficially go beyond higher order pattern unification.
14:51:00 <ddarius> pozic_: The packaging system is not part of the language.
14:51:08 <pozic_> sm: so, if I want to depend on a library which compiles library foo with options a, b and c and on another library which depends on library foo with options d, e,f, it should still work.
14:51:34 <sm> ah
14:52:32 <pozic_> ddarius: is that your serious answer?
14:53:04 <pozic_> ddarius: because, honestly, I think it's hilarious.
14:53:12 <sm> I suppose you can do that with ocaml, racket and such.. is it done in the C world ?
14:54:11 <ddarius> pozic_: Haskell being compositional or not says nothing about a system around it.  In fact, I think the only languages that do have a packaging system that truly is compositional do have packages as part of the language, typically in a first-class manner.
14:54:52 <pozic_> ddarius: still as funny as it was before.
14:55:04 <ddarius> pozic_: I await your solution.
14:55:09 <ski> mun mentioned "Third Order Matching is Decidable" by Gilles Dowek in 1999 at <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.6700> before
14:55:28 <pozic_> ddarius: sm already listed a few solutions.
14:55:35 <pozic_> ddarius: it's not like this is a research problem.
14:56:21 <geekosaur> so when do all these self-appointed packaging experts with their already solved problms present their solutions instead of just demanding everyone worship?
14:56:51 <ski> ddarius : i'm curious about which (if any) languages you were thinking about
14:56:53 <ddarius> ski: I'm pretty sure we'd need higher order unification and not matching for this to be usable.
14:57:05 <ddarius> ski: AliceML comes to mind.
14:57:16 <ski> ah, ok
14:57:39 * ski should look more at how packages the work, ty for the reminder
15:05:14 <Guest62319> is there a difference between hPutStr h (x ++ y) and hPutStr h x >> hPutStr h y
15:05:31 <Guest62319> rather whats the difference and is it important
15:05:55 <alexandrus> missing definition of h, x, y
15:05:56 <Guest62319> do i have to worry about concurrent writers
15:06:20 <alexandrus> for me these two things are totally different...with an arbitrary h
15:06:21 <Guest62319> youre lucky i didnt just put send (x++y) and send x >> send y
15:06:41 <Saizan> Guest62319: yeah, you have to worry about concurrent writers
15:06:43 <Guest62319> h is a Handle
15:06:51 <Guest62319> Saizan: hmm
15:07:10 <ddarius> Admittedly, you arguably have to worry about that in either case.  I don't think hPutStr is guaranteed to be atomic.
15:07:19 <Guest62319> i was about to say
15:07:24 <ddarius> @hoogle hPutStr
15:07:25 <lambdabot> System.IO hPutStr :: Handle -> String -> IO ()
15:07:25 <lambdabot> GHC.IO.Handle hPutStr :: Handle -> String -> IO ()
15:07:25 <lambdabot> System.IO hPutStrLn :: Handle -> String -> IO ()
15:07:49 <Guest62319> even if i have one write command it might get garbled
15:07:54 <Guest62319> by another thread
15:08:11 <Cale> It is not, so those are the same
15:08:21 <Saizan> one tends to delegate all the writing for a(some) Handle to a single thread for this reason, and have others send messages to this one if needed
15:08:55 * stepkut wonders why you can't extend the 'deriving' mechanism with template haskell
15:10:29 <ddarius> stepkut: Why would you be able to?
15:10:55 <stepkut> ddarius: because people get bent out of shape when they see things like $(deriveFoo ''SomeType)
15:10:58 <ddarius> stepkut: You can just as well just write a top-level call to TH to do the same thing, so why update the deriving syntax?
15:11:07 <ddarius> stepkut: Those people should be ignored.
15:11:20 <stepkut> but if they could write, deriving Foo, then they would be fine
15:11:50 <ddarius> stepkut: If that's true, then see my earlier statement.  If that's false, and what they are really complaining about is the highly non-portable, non-stable extension, then this would not help.
15:11:53 * Guest62319 imagines a rage face with stepkut's complaint
15:12:14 <ddarius> Also, you can write just: deriveFoo ''SomeType now.
15:12:32 <ddarius> (Which I'm a bit ambivalent about.)
15:12:38 <alexandrus> hmm...i am pretty new here...any reasons against the Existentially qunatified types as well?
15:13:16 <stepkut> ddarius: still more typing and less pretty
15:15:45 <Guest62319> rather than a thread dedicated to write to each handle can you just put it in a MVar
15:17:32 <ddarius> Guest62319: A bounded channel would probably work better as then things would usually not block, or, if you don't care about potentially overrunning the output capacity, an unbounded channel.
15:17:46 <startling> so what's the difference between Data.ByteString.ByteString and Data.ByteString.Lazy.ByteString
15:17:49 <startling> ?
15:17:54 <Guest62319> how would a bounded channel work
15:18:16 <ddarius> You'd block when it was full.  MVar is a bounded channel with capacity 1.
15:18:25 <ion> startling: A lazy ByteString is essentially a list of strict ByteStrings.
15:18:36 <Guest62319> well ill slippery slope to an MVar
15:18:37 <startling> ion, oh, huh
15:19:23 <startling> so if I use Data.ByteString.readFile, does it read the whole thing into memory?
15:19:51 <JoeyA> Yes.  Data.ByteString.Lazy.readFile does not.
15:20:04 <startling> understood. thanks!
15:20:04 <ddarius> Guest62319: If there were to be a slippery slope, it would go to a channel, not an MVar.
15:20:23 <Guest62319> i slide both ways if you know what i mean
15:20:43 <Guest62319> Chan makes me nervous
15:20:48 <ddarius> A bounded channel of any length would have the same good properties as an MVar but with higher capacity you'd get less contention.
15:20:58 <Guest62319> blocking is what i want
15:21:08 <ddarius> Guest62319: You could use a TChan.  It would actually be better in this case.
15:21:15 <ddarius> Guest62319: Why?
15:21:23 <Guest62319> i cant imagine how a worker would continue without finishing its send
15:21:30 <Guest62319> havent considered it
15:22:02 <ddarius> Guest62319: Everything still gets sent in order (for any particular thread), it can just get to the next send sooner.
15:22:19 <ion> Someone really needs to implement some kind of a channel and call it JackieChan.
15:22:20 <Guest62319> but ... to what end
15:22:37 <Guest62319> your output speed isnt not increased
15:22:43 <ddarius> Guest62319: So that your program isn't blocked waiting for an IO buffer when it could be doing calculations.
15:22:54 <Guest62319> is not*
15:23:36 <Guest62319> if i didnt care whether the msg was ever sent, it would make sense to continue
15:23:49 <Guest62319> but i cant guarantee it gets there
15:23:56 <Guest62319> so maybe thats how i should think of it
15:24:09 <ddarius> Guest62319: You'd need a two-way communication if you need acknowledgement that the message was actually sent.
15:24:30 <Guest62319> s/sent/received/
15:25:02 <Guest62319> well is there a Chan with a bound
15:25:04 <JoeyA> stm-2.4 has a bounded channel type (TBQueue)
15:26:02 <ddarius> Guest62319: The only way to know if a message was successfully received by the recipient is via an acknowledgement which would require two-way communication and then you'd block on a receive, which may still be beneficial to separate from the sedn.
15:26:18 <Guest62319> im not doing that
15:26:32 <JoeyA> What's a good pattern for managing access to a resource that can come and go, for a long-running program?
15:26:42 <startling> funny how Html isn't all caps in pandoc, RST is, and LaTeX is mixed-case
15:27:02 <ddarius> Guest62319: Then it sounds like you don't care if the message was successfully received.
15:27:43 <ddarius> JoeyA: What do you want to happen when someone tries to use the resource and it isn't there?
15:27:47 <Guest62319> heres a question, getting more inane, can we be sure that the other end knows that we know it was received ;)
15:28:11 <ddarius> Guest62319: No, but usually you don't care.  If you do, then you can acknowledge the acknowledgement.
15:28:26 <JoeyA> ddarius: It doesn't talk to the server in that case, but tries to reconnect.
15:28:34 <ddarius> Usually that will be handled by the next message you send implicitly anyway.
15:28:46 <JoeyA> The 'send' function will return failure, if we know the resource is missing.
15:29:01 <JoeyA> So the program can react accordingly
15:29:04 <Guest62319> the 'next message' might not come for a while and in a real time thing youd want to signal an error as soon as possible if you get out of sync
15:29:08 <Guest62319> anyway
15:29:15 <JoeyA> data ConnectionStatus = Connecting | Connected | Disconnected
15:29:20 <Guest62319> need to rethinking my sending
15:29:28 <JoeyA> I have a good idea about how I plan to manage the resource itself.
15:29:35 <JoeyA> I'm just wondering what a good API would be.
15:29:53 <ddarius> JoeyA: So far it sounds like you just want a send that can return a failure message.  What's the problem with that API?
15:29:58 <JoeyA> Should I make all interaction with the connection manager STM, so it's easier to think about it w.r.t exceptions?
15:31:10 <JoeyA> For example, consider the thread that receives messages.
15:31:20 <JoeyA> We could either put the messages in a queue for the application to pick up.
15:31:27 <JoeyA> Or we could invoke a callback.
15:31:42 <JoeyA> But if the connection hangs, we may have to kill the receiving thread.
15:32:09 <JoeyA> The issue with making the callback IO is that it might receive that exception.
15:32:45 <JoeyA> So I'm considering having a TBQueue for sending, and an STM callback invoked when the manager generates an "event".
15:33:08 <JoeyA> The types of "event" are: 1) message from server, and 2) connectivity status changed
15:33:22 <JoeyA> Is it time for me to learn FRP yet?
15:33:38 <ddarius> JoeyA: Why would you kill the receiving thread?  Why wouldn't the receive just return an error indicator?
15:34:15 <JoeyA> ddarius: The receive operation is doing a network operation
15:34:32 <ddarius> Which typically will return a timeout error if the connection fails.
15:34:36 <JoeyA> And the receive might hang indefinitely.
15:34:46 <JoeyA> And it almost always will, when connectivity is lost.
15:34:59 <JoeyA> ddarius: Good point
15:36:24 <JoeyA> Maybe I should just use System.Timeout, paired with socket timeouts for Windows.
15:37:22 <JoeyA> ddarius: Maybe I was thinking of the other case: what if my application wishes to close the connection?
15:37:27 <JoeyA> Then we have to kill the receive thread.
15:38:21 <JoeyA> And make the application callback STM so we don't have to worry about what will happen if it's killed.
15:38:23 <ddarius> I'm pretty sure if you close the connection the receives will fail too.
15:38:56 <JoeyA> Mm, not sure.  IO on Windows is pretty stupid.
15:39:22 <ddarius> You should typically avoid solutions that involve asynchronously killing threads.
15:39:44 <JoeyA> ddarius: Actually, I remember now.
15:39:54 <JoeyA> If you try to hClose a handle when another thread is waiting to read
15:39:58 <JoeyA> The thread that called hClose will block.
15:40:02 <ddarius> However, you can use an orElse on some kind of notification channel for that situation (if necessary) and then the receive thread can terminate itself gracefully notifying whomever.
15:40:39 <JoeyA> Because hGet... and hClose both take the duplex handle's read-end MVar.
15:41:26 <sw20> how are pattern bindings desugared? for example: " let (Just x) = f in e "
15:41:31 <JoeyA> I just want to avoid doing something like this again: http://hackage.haskell.org/packages/archive/stm-channelize/latest/doc/html/Control-Concurrent-STM-Channelize.html
15:42:20 <JoeyA> Look at the source of the 'channelize' function if you have no further use for your eyes.
15:43:10 <JoeyA> > let (x:xs) = [] in "Nope, not forced"
15:43:11 <lambdabot>   "Nope, not forced"
15:44:06 <ddarius> Modulo some differences with types, let pat = e in body is equivalent to case e of ~(pat) -> body
15:44:32 <ddarius> Though BangPatterns muddy this slightly.
15:45:02 <JoeyA> > let !(~(x:xs)) = [] in "Bang lazy"
15:45:03 <lambdabot>   "*Exception: <interactive>:3:4-18: Non-exhaustive patterns in pattern binding
15:45:18 <JoeyA> > let ~(!(x:xs)) = [] in "Lazy bang"
15:45:19 <lambdabot>   "Lazy bang"
15:46:35 <JoeyA> > let ~(!(x:xs), x) = ([], "Lazy bang pow") in x
15:46:37 <lambdabot>   Conflicting definitions for `x'
15:46:37 <lambdabot>  Bound at: <interactive>:1:8
15:46:37 <lambdabot>            <in...
15:46:44 <JoeyA> > let ~(!(x:xs), y) = ([], "Lazy bang pow") in y
15:46:45 <lambdabot>   "*Exception: <interactive>:3:4-40: Irrefutable pattern failed for pattern (...
15:49:27 <mun> when writing a paper, what's a good notation to use to represent that type V is in the type hierarchy of type U?
15:50:39 <sw20> what is the order of cases? e.g. in " let {p1 = e1;p2=e2} in body " ? case e1 of ~p1 -> case e2 of ~p2 -> body?
15:51:07 <sw20> dependency?
15:51:27 <JoeyA> mun: That question's out of my league, but: is V a subtype of U?
15:51:37 <mun> JoeyA, yeah
15:51:41 <JoeyA> e.g. in C++: class Foo {...}; class Bar : Foo {...}
15:51:46 <JoeyA> Here, Bar is a subtype of Foo.
15:51:56 <ddarius> It would be case (e1, e2) of (~(p1), ~(p2)) -> body
15:52:02 <Gracenotes> mun: V < U?
15:52:05 <JoeyA> mun: You could say V < U to mean "V is a subtype of U".
15:52:18 <Gracenotes> if you're writing the paper, you can use whatever notation you like :P
15:52:21 <mun> JoeyA, but strictly speaking, a type hierarchy is different to a type class, right
15:52:40 <Gracenotes> (said half-jokingly...)
15:52:43 <JoeyA> Well, type classes have hierarchy, too.
15:52:58 <ddarius> If this were actually a subtyping relationship, which I don't think it is, the common notation is <:
15:53:25 <ddarius> I don't know what mun means by "type hierarchy" here.
15:53:50 <Gracenotes> type classes can be cyclic, though, yeah?
15:54:20 <ion> let { p1 = e1 p2; p2 = e2 p1 } in body → case fix (\(~p1, ~p2) -> (e1 p2, e2 p1)) of (~p1, ~p2) -> body?
15:54:30 <mun> ddarius, like subtyping
15:56:12 <Gracenotes> not sure what sort of question that was I asked. am tirred.
15:56:22 <ion> Whoops, the fix pattern will try to force the tuple. fix (\ ~(p1, p2) -> …)?
15:56:33 <mietek> http://pastie.textmate.org/private/od6wrjeyjysp0u2xii3ujq
15:56:40 <mun> how do i define that S and T are subtypes of U in haskell?
15:56:41 <mietek> Can someone explain to me why is this happening?
15:56:50 <ddarius> Haskell doesn't have subtyping.
15:56:51 <mietek> Fresh HP install, cabal update, cabal install cabal-dev
15:57:15 <ion> > case fix (\ ~(p1, p2) -> ('a':p2, 'b':p1)) of (~p1, ~p2) -> p2
15:57:16 <lambdabot>   "bababababababababababababababababababababababababababababababababababababa...
15:57:54 <ddarius> ion: That should be a correct translation modulo the same kinds of type issues I mentioned above.
15:58:12 <JoeyA> abal?
15:58:56 <JoeyA> mietek: I would just say, go ahead and use --force-reinstalls .  But I'm not happy about your mtl getting downgraded.
15:59:12 <JoeyA> I don't understand why HTTP is being reinstalled, though.  It's not listed as a dependency of cabal-dev.
15:59:22 <JoeyA> nor of cabal
16:00:33 <JoeyA> Yeah, that output seems bogus to me.  HTTP-4000.2.3 doesn't need to downgrade mtl to install.
16:00:52 <mietek> I wonder if this is OS X-specific
16:00:52 <mietek> Are you on OS X?
16:01:01 <JoeyA> But nonetheless, I get that here on Linux, too.
16:01:04 <mietek> Ah.
16:01:37 <JoeyA> Fresh HP with GHC 7.4.1?
16:01:53 <mietek> Yep
16:02:05 <mietek> Wiped all traces of Haskell before reinstalling just now
16:02:25 <mietek> As I had to move to 32-bit
16:02:26 <JoeyA> Did you cabal update?
16:02:35 <mietek> Yes
16:02:38 <mietek> Come on
16:03:12 <sw20> what would be the translation of: "let {Just x = Just y; Just y = Just 1} in  x " ? no dependency graph checks?
16:04:14 <ion> > case fix (\ ~(Just x, Just y) -> (Just y, Just 1)) of (~x, ~y) -> x
16:04:15 <lambdabot>   Just 1
16:04:16 <burbul> @hoogle (.:)
16:04:16 <lambdabot> No results found
16:04:22 <burbul> @hoogle (:.)
16:04:22 <lambdabot> No results found
16:04:26 <ion> burbul: (.:) = (.).(.)
16:04:30 <JoeyA> Ah, it is cabal-dev pulling down your dependencies.
16:04:32 <burbul> thanks!
16:04:36 <JoeyA> The package description file says it al
16:04:38 <JoeyA> all*
16:04:44 <JoeyA> Hackage has the wrong summary.
16:05:08 <JoeyA> mietek: For now, just say --force-reinstalls, and let it downgrade your stuff.
16:05:23 <JoeyA> This is why I hate when packages have unnecessary upper bounds.
16:05:32 <JoeyA> There should be a cabal option to ignore them.
16:07:06 <mietek> I know I can do --force-reinstalls, I'm interested in learning what's the reason
16:07:18 <JoeyA> http://hackage.haskell.org/packages/archive/cabal-dev/0.9.1/cabal-dev.cabal
16:07:19 <mietek> So cabal-dev has an upper bound on MTL?
16:07:26 <JoeyA> mtl >= 1.1 && < 2.1
16:07:32 <mietek> Right
16:07:39 <JoeyA> It's in the cabal file
16:11:07 <mun> just a check on terminology: are all polymorphic functions overloaded?
16:11:15 <mietek> JoeyA: well, I don't know
16:11:19 <EvanR> haskelling at the clothing optional pool bar
16:11:34 <mietek> JoeyA: I unpacked cabal-dev-0.9.1, changed the upper bound on mtl to < 2.2, and still the same
16:11:50 <JoeyA> You did cabal install and not cabal install cabal-dev, right?
16:11:53 <mietek> I also note the cabal message says "HTTP-4000.2.3 (reinstall)"
16:12:13 <mietek> And so it seems to me that HTTP-4000.2.3 is causing the mtl downgrade
16:12:24 <Eduard_Munteanu> mun: overloaded how? Overloading usually refers to ad-hoc polymorphism, or overloading like in C++.
16:12:34 <JoeyA> transformers >= 0.2 && < 0.3,
16:12:39 <JoeyA> That brings mtl to < 2.1
16:12:49 <JoeyA> Err
16:12:53 <JoeyA> nevermind
16:13:00 <Eduard_Munteanu> mun: but in Haskell, polymorphism usually refers to parametric polymorphism
16:13:09 <mietek> This is hell
16:13:15 <JoeyA> Err, yes it does.  That dependency constrains mtl.
16:13:28 <JoeyA> mietek: Just nuke the upper bounds and see what happens :-)
16:13:45 <mietek> JoeyA: how did you come to this conclusion?
16:13:50 <JoeyA> Which conclusion?
16:13:58 <mietek> That transformers constraints mtl
16:14:14 <JoeyA> mtl 2.1 requires transformers 0.3.*
16:14:23 <mietek> Ah
16:14:31 <JoeyA> So if transformers < 0.3, then you can't use mtl 2.1
16:15:57 <mietek> Indeed
16:16:09 <mietek> I really wish this was somehow less painful
16:16:43 <mun> Eduard_Munteanu, right. can a function be overloaded in haskell though? is there a workaround?
16:17:27 <EvanR> mun: why thats so popuar in c++ type languages i never understood
16:17:33 <mietek> Looks like there already is a patch for this, https://github.com/creswick/cabal-dev/pull/55/files
16:17:42 <EvanR> mun: it just lets you call different functions by the same name
16:17:46 <EvanR> it doesnt let you write more general code
16:18:02 <mun> EvanR, basically i want a function to behave according to the type of its input
16:18:08 <JoeyA> Type class
16:18:20 <EvanR> mun: well, its more than that in c++
16:18:39 <EvanR> foo(int x) can act different from foo(int x, int y)
16:19:57 <EvanR> a type class with one method can sort of pull that off
16:20:03 <EvanR> but a type class does more than that
16:20:08 <EvanR> so its two orthogonal features
16:20:53 <mun> right
16:21:23 <EvanR> another way you can do it is with a new data type
16:21:53 <EvanR> data Foo = A A0 | B B0 | C C0
16:21:59 <EvanR> and the function takes Foo as input
16:36:46 <edwardk> :t (.)(.)(.)
16:36:46 <lambdabot> forall (f :: * -> *) a b (f1 :: * -> *). (Functor f, Functor f1) => (a -> b) -> f (f1 a) -> f (f1 b)
16:37:37 <edwardk> I'd like to propose that as the total recall operator.
16:37:44 <Obfuscate> EvanR: It's useful/convenient in some cases. Two that come to mind are default arguments and "natural" math operators for different types: both can be made to work in haskell, but it's messier.
16:38:12 <monochrom> haha total recall
16:39:01 <EvanR> Obfuscate: 'messier'
16:39:17 <gwern> edwardk: it took me a moment to get that. damn you!
16:39:25 <EvanR> Obfuscate: 'default arguments' are easy to do by calling the function something else, and its easier to get right
16:39:31 <edwardk> gwern: =)
16:39:38 <Wibowit> i'm on ubuntu 12.10 and i have ghc and libraries installed from ubuntu repository. how to view documentation and/ or source code? i've found only *.hi files which are precompiled sources i think. for example i would want to view the source of filterM function
16:39:40 * gwern had almost forgotten
16:39:53 <EvanR> and thanks to partial application you can 'default' the arguments to whatever you wanted
16:40:07 <monochrom> 12.10 already!
16:40:10 <edwardk> gwern: only thought of it because there was a trailer for some godawful hollywood remake when I went to see batman the other day
16:40:23 <gwern> monochrom: gosh, I'd better turn into bed
16:40:25 <EvanR> Obfuscate: natural math operators? i mean + and * work pretty well in haskell
16:40:34 <monochrom> doesn't ubuntu have *-doc packages for docs?
16:40:49 <gwern> EvanR: sure, but those allow negative numbers!
16:41:30 <Obfuscate> EvanR: For default arguments, I really mean that it is just a convenience matter, especially since those languages typically do not have implicit partial application.
16:41:46 <Obfuscate> EvanR: For the math operators, see http://www.haskell.org/haskellwiki/Functional_dependencies
16:42:41 <Wibowit> monochrom: yes, it has, but how to quickly show documentation and source code for a particular function?
16:42:55 <EvanR> i tend to make a function with a new name instead of making the arguments exponentially more configurable in like javascript and php
16:44:23 <Wibowit> when asking for documentation about posix function i can do 'man function' eg 'man pipe' and documentation shows up. is there something like this for haskell? and mainly i'm curious how to show source code for a function as i want to study it
16:44:37 <monochrom> the doc are html files for web browsers. /usr/share/doc/something
16:46:19 <Wibowit> ok, i've found them. where are sorces then?
16:47:42 <ddarius> edwardk: I wonder if it is remotely related to the original story the first one was supposed to based on.
16:47:46 <Obfuscate> EvanR: I'm just saying that there is an advantage to having that style of adhoc overloading... whether it's worth giving up partial application for is a debate I'd rather not have. :)
16:48:26 <EvanR> Obfuscate: oh, i didnt understand thats what you were referring to. default arguments sounds like a crazy use for c++ type 'polymorphism'
16:49:52 <monochrom> it is possible that sources are not included
16:50:30 * monochrom not a fan of either "read implementation details" or "get ghc from ubuntu"
16:51:03 <mauke> Wibowit: http://www.haskell.org/ghc/docs/latest/html/libraries/base-4.5.1.0/Control-Monad.html#v:filterM
16:51:35 <Obfuscate> EvanR: It's a pretty common use (although I'd be hesitant to call it polymorphism).
16:52:16 <EvanR> its definitely not in haskell context
16:52:44 <BrianHV> does chrisdone IRC? I'm messing around with Fay and am confused about how modules work.
16:52:57 <Clint> he certainly does
16:53:23 <BrianHV> in this channel?
16:53:26 <monochrom> preflex: seen chrisdone
16:53:26 <preflex>  chrisdone was last seen on #haskell 1 day, 1 hour, 28 minutes and 56 seconds ago, saying: and roll
16:53:31 <BrianHV> guess so. :)
16:53:36 <edwardk> BrianHV: every once in a while, yes
16:53:50 <monochrom> not so easy to catch. maybe email him
16:54:23 <BrianHV> all right. thanks.
16:55:34 <mun> if one says 'F is a polymorphic function', which variety of polymorphism does it implement? parametric?
16:56:59 <Nolrai24> So I want to convert a Char to a Word64, there is a function for that right?
16:57:09 <mauke> fromIntegral . ord
16:57:11 <azaq23> mun: usually parametric
16:57:30 <Nolrai24> mauke: duh, thanks!
16:57:35 <mauke> > (fromIntegral . ord) '€' :: Word64
16:57:37 <lambdabot>   8364
16:57:51 <mun> azaq23, right. but the distinction matters, right? as in, specifically indicating whether a function is ad-hoc polymorphic or parametric polymorphic.
16:57:51 <EvanR> > 'EUR'
16:57:53 <lambdabot>   <no location info>:
16:57:53 <lambdabot>      lexical error in string/character literal at chara...
16:58:04 <EvanR> hax
16:58:36 <ddarius> mun: It's best just to not use the unadorned term "polymorphic".
16:58:43 <mauke> if this was Perl, you could use "\N{EURO SIGN}"
16:59:20 <mun> ddarius, right. so what's a better way to put it?
16:59:36 <ddarius> mun: It depends on what you mean.
16:59:49 <ddarius> If you mean a parametrically polymorphic function, simply say that.
17:00:39 <mun> right
17:02:33 <Cale> Also, please don't refer to typeclass polymorphism as ad-hoc polymorphism.
17:02:49 <ddarius> Also please don't refer to type classes as typeclasses.
17:03:17 <Cale> disagree!
17:03:53 <Nolrai24> > maxBound :: Word64
17:03:54 <lambdabot>   18446744073709551615
17:04:20 <monochrom> please don't refer to parametric polymorphism as parametricpolymorphism :)
17:04:47 <Cale> Aww, English could be agglutinative too, if we only gave it a chance.
17:05:36 <monochrom> we are certainly going from "oh noes" to "onoes"
17:12:34 <BrianHV> hah. I had to reinstall my virthualenv and chris released a new version of fay since this afternoon. broken code ensues.
17:13:14 <monochrom> I see now. when he releases software, he hides from the channel!
17:14:33 <BrianHV> turns out that my module confusion doesn't have to do with the new release though... I'll still have to track him down. ;)
17:21:12 <edwardk> ooh, neat
17:21:18 <edwardk> parTraversal :: LensLike Eval a a b b -> Strategy b -> Strategy a; parTraversal l strat = l (rparWith strat)
17:21:35 <edwardk> you can use lenses to automate most of Control.Parallel.Strategies
17:21:46 <edwardk> evalTraversal = id ;)
17:22:13 <edwardk> evalTraversal :: SimpleLensLike Eval a b -> Strategy b -> Strategy a
17:29:59 <Nolrai24> @hoogle STArray
17:30:00 <lambdabot> Data.Array.ST data STArray s i e :: * -> * -> * -> *
17:30:00 <lambdabot> Data.Array.IArray listArray :: (IArray a e, Ix i) => (i, i) -> [e] -> a i e
17:30:00 <lambdabot> Data.Array listArray :: Ix i => (i, i) -> [e] -> Array i e
17:31:07 <gwern> hm. I wonder how I would make hakyll/pandoc generate HTML <img> links which include the image's dimensions (for more accurate rendering before the images download)
17:31:49 <ddarius> > liftA2 (^) [x,y] [0..2]
17:31:50 <lambdabot>   [1,x,x * x,1,y,y * y]
17:33:17 <ddarius> > liftA2 (\i j -> x^i * y^j) [0..2] [0..2]
17:33:18 <lambdabot>   [1 * 1,1 * y,1 * (y * y),x * 1,x * y,x * (y * y),x * x * 1,x * x * y,x * x ...
17:34:02 <centrinia> > liftA2 (^) [x,y,z] [0..4]
17:34:02 <lambdabot>   [1,x,x * x,x * x * x,x * x * (x * x),1,y,y * y,y * y * y,y * y * (y * y),1,...
17:34:22 <centrinia> > liftA2 (^) [x,y,z] [0..1]
17:34:23 <lambdabot>   [1,x,1,y,1,z]
17:37:57 <edwardk> ix :: (IArray a e, Ix i) => i -> Simple Lens (a i e) e -- is kind of nice
17:38:10 <edwardk> arr^.ix 2   == arr ! 2
17:38:26 <edwardk> ix 2 += 5 $ arr
17:39:04 <ddarius> @hoogle zipWith
17:39:04 <lambdabot> Prelude zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
17:39:04 <lambdabot> Data.List zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
17:39:04 <lambdabot> Prelude zipWith3 :: (a -> b -> c -> d) -> [a] -> [b] -> [c] -> [d]
17:39:10 <byorgey> gwern: modify pandoc's HTML generation?
17:39:14 <ddarius> @hoogle product
17:39:14 <lambdabot> Prelude product :: Num a => [a] -> a
17:39:15 <lambdabot> Data.List product :: Num a => [a] -> a
17:39:15 <lambdabot> Data.Monoid Product :: a -> Product a
17:39:18 <gwern> byorgey: well, I'd rather not!
17:39:27 <ddarius> @hoogle sequence
17:39:27 <lambdabot> Prelude sequence :: Monad m => [m a] -> m [a]
17:39:27 <lambdabot> Control.Monad sequence :: Monad m => [m a] -> m [a]
17:39:27 <lambdabot> Prelude sequence_ :: Monad m => [m a] -> m ()
17:40:45 <gwern> byorgey: I'm not sure how I would... the obvious way is to change the Image AST to include a tuple for x-y dimensions and then have a hakyll Pandoc->Pandoc plugin which does file IO and sets the tuple
17:41:25 <byorgey> gwern: oh, well, you wouldn't have to change the image AST ... just make the Pandoc->Pandoc plugin change any Images to a RawBlock "html"
17:41:29 <gwern> but John hates changing the AST, for obvious reasons
17:41:32 <byorgey> and generate the HTML yourself
17:41:47 <gwern> hm. that's so ugly and such a hack that I'd never think of it and it just might work
17:41:52 <byorgey> hehehe
17:58:05 <redscare> in learning haskell, i wrote some dumb, short code to find the Nth prime number: http://hpaste.org/72311. It just finds all the prime numbers up to the Nth tail-recursively, using previous results to find the next one. It's not the best way of doing it, but just an exercise. The problem is that the compiled version runs much slower than an equivalent python implementation. What am I doing wrong?
17:58:33 * hackagebot graph-rewriting-ski 0.6.2 - Two implementations of the SKI combinators as interactive graph rewrite systems (JanRochel)
18:00:14 <redscare> here i added only to check primes up to the square root of the number being tested, but it's still slower than equivalent python: http://hpaste.org/72312
18:02:05 <latro`a> you sure the python is equivalent?
18:02:13 <latro`a> it's not hard to think it is
18:02:19 <latro`a> and find out that it isn't
18:02:19 <byorgey> redscare: do you know that !! takes O(n) time to extract the nth element?
18:02:27 <latro`a> but yes, it does, which is different from python
18:02:27 <byorgey> because it has to traverse the entire list
18:02:31 <startling> hi, what's the best way to apply an argument to a function in a maybe?
18:02:44 <latro`a> fmap ($)?
18:02:46 <ddarius> Similarly for (++[x])
18:02:51 <byorgey> startling: fmap ($ arg)
18:02:52 <ddarius> And length
18:02:53 <latro`a> er
18:02:56 <latro`a> ($ arg), yeah
18:03:01 <ddarius> And last
18:03:10 <redscare> but !! is only done once?
18:03:15 <ddarius> redscare: Practically ever list operation you have is O(n)
18:03:39 <byorgey> oh, true, the !! is not the problem
18:03:53 <byorgey> the ++ [c] is a problem though
18:03:54 <redscare> ddarius: but they're all done relatively unoften? most numbers aren't prime
18:04:07 <redscare> byorgey: i thought that would be ok because most numbers aren't prime
18:04:08 <latro`a> try changing the primes ++ [c]
18:04:10 <startling> byorgey, latro`a: lovely, thanks
18:04:16 <latro`a> to c:primes with reverse at the end
18:04:40 <latro`a> reverse is O(n); using (++) every single time is overall O(n^2)
18:04:57 <redscare> so if i do reverse $ c:primes that should actually help?
18:05:02 <latro`a> not reversing every time
18:05:04 <redscare> why isn't (++) defined that way?
18:05:06 <latro`a> reverse at the very vend
18:05:28 <latro`a> for a single ++ call, ++ is fast
18:05:38 <latro`a> that is, as fast as linked list concatenation can be
18:05:54 <latro`a> when you are appending many many elements, however, it has to do traverse the left list repeatedly
18:06:04 <redscare> latro`a: well the way the algorithm works I need to divide by smaller numbers first
18:06:09 <latro`a> so you're traversing a k element list for each k from 1 to the number of primes
18:06:15 <latro`a> hm
18:06:20 <latro`a> that is an issue, yeah
18:06:22 <redscare> latro`a: because i only divide up to the sqrt of the number in question
18:06:54 <latro`a> there are prime sieve algorithms that are more idiomatic than this one in haskell
18:07:03 <latro`a> including several that generate infinite lists of primes
18:07:22 <redscare> latro`a: i know, this is a really stupid algorithm, but i just wanted to have something simple where i could experiment with performance
18:07:23 <ddarius> length nprimes is called each time through the loop and is O(length nprimes) each time.
18:07:30 <latro`a> yeah
18:07:37 <latro`a> a faster way would be to use an accumulator
18:07:39 <latro`a> for the length
18:07:51 <redscare> latro`a: and what should I use for the ++?
18:08:05 <ddarius> Also, rem is faster than mod and has the same result if both numbers are positive.
18:08:15 <latro`a> you can't do much better than ++ in this context
18:08:32 <latro`a> the idea I was talking about was for if you can generate a list without back-referencing the list itself
18:08:48 <ddarius> It would also help if helper was strict in c.
18:08:50 <latro`a> but the generation happens in the order that you want the elements (for some other reason)
18:09:19 <redscare> i'm surprised length is slow. it works really quick in python
18:09:23 <redscare> ddarius: how would i make it strict?
18:09:32 <ddarius> redscare: "Lists" in Python are arrays.
18:09:38 <ddarius> Lists in Haskell are linked lists.
18:09:43 <latro`a> helper c primes = seq c (helper' c primes)
18:09:47 <latro`a> where helper' is what you wrote
18:09:53 <latro`a> will make helper strict in c
18:10:21 <latro`a> but yes, that's a big difference between arrays in python and haskell
18:10:22 <latro`a> er
18:10:24 <latro`a> lists
18:10:34 <latro`a> python lists aren't *exactly* arrays, afaik
18:11:02 <redscare> is doing unpacking through pattern matching also slow?
18:11:10 <latro`a> no
18:11:32 <ddarius> redscare: There is no alternative.  There is no other way to get at the components of a data type.
18:11:37 <ddarius> @src head
18:11:37 <lambdabot> head (x:_) = x
18:11:38 <lambdabot> head []    = undefined
18:11:50 <latro`a> well, nothing that is truly different
18:12:02 <latro`a> technically pattern matching is sugar for case
18:14:19 <Veinor> pattern matching for newtypes is even faster!
18:20:49 <redscare> i made the changes you guys suggested, it did get faster, but now I get a stack space overflow for big numbers. code here: http://hpaste.org/72313
18:24:22 <ddarius> redscare: You did not do what latro`a suggested.
18:25:51 <redscare> ddarius: i thought i did. I could be wrong but i think the only thing i'm missing is i'm still doing (++) but we agreed that was needed?
18:28:35 <ddarius> helper calls helper so the strictness annotation on helper' makes no difference in any of the recursive calls.
18:29:09 <redscare> ddarius: ok, i see, thanks, i'll try that
18:29:36 <ddarius> Also, the new l parameter has a worse problem than the c parameter.
18:30:58 <ddarius> Actually, I think that will be fine enough.
18:31:47 <vodik> can anyone point me to a good example to learn how to properly use attoparsecs incremental parsing abilities?
18:32:12 <vodik> i've been playing around wrapping it in a StateT but I'm sure someone has done this before
18:32:27 <ddarius> redscare: Also, how big is "big"?
18:33:24 <redscare> ddarius: the 1,000,000th prime
18:36:29 <redscare> ddarius: still doesn't work. changed code here: http://hpaste.org/72315
18:36:40 <mm_freak> absence: first of all a side note:  Wire is a family of profunctors, so you really don't need Arrow at all
18:36:59 <mm_freak> absence: instead of "require . arr p" you can simply write "lmap p require"
18:37:09 <mm_freak> this is not only more concise, but also faster
18:38:40 <mm_freak> absence: another side note…  just in case the input to 'integral 0' is a constant 1 you can simply use the 'time' wire for that…  same semantics, but again slightly faster and less to type
18:39:23 <mm_freak> absence: now to your actual question:  see the 'asSoonAs' and 'while' wires, which correspond to dropWhile and takeWhile respectively
18:40:09 <mm_freak> netwire 3 is a bit unfortunate about the event wires…  the next version will have more sensible types
18:40:34 <ddarius> redscare: I didn't expect that to fix it, that change was more related to helping the compiler unbox things which will only give a constant factor improvement.
18:40:48 <ddarius> redscare: Also, have you verified that it is giving correct answers for lower numbers.
18:40:49 <mm_freak> absence: asSoonAs :: (Reactive (>~)) => (a -> Bool) -> Wire e (>~) a a  -- this will be the new type
18:41:08 <redscare> ddarius: yep, definitely correct
18:43:25 <mm_freak> absence: btw, if you have any complaints about netwire right now, tell me…  now is the opportunity to influence the next major version, which is close to its release =)
18:44:51 <redscare> ddarius: so any ideas?
18:46:06 <JoeyA> Obscure exception safety question: is this interruptible?  atomically (retry `orElse` return ())
18:46:24 <JoeyA> I put together a quick test case, and found that it is not interruptible (which is good, imho)
18:47:12 <dysinger> Does anyone know an easy way to derive/generate/anything Binary instances for my data types?  I've tried the binary-generic package (fails to install).
18:47:33 <mm_freak> JoeyA: it is not interruptible, because it doesn't access any shared resources
18:47:51 <dysinger> This has to be a common need (re: easy generic Binary instances)
18:47:59 <JoeyA> mm_freak: "atomically retry" *is* interruptible, but does not access shared resources.
18:48:57 <JoeyA> (except internally, perhaps)
18:53:04 <mm_freak> JoeyA: "atomically retry" is interruptible?  are we talking about the same kind of interrupt?
18:53:34 <JoeyA> I'm talking about, inside of Control.Exception.mask, whether another thread can interrupt you.
18:53:58 <mm_freak> an STM transaction can well be interrupted by an exception, but not necessarily by another transaction
18:54:01 <JoeyA> Take a look at the source of writeChan, for example: http://hackage.haskell.org/packages/archive/base/latest/doc/html/src/Control-Concurrent-Chan.html#writeChan
18:54:15 <JoeyA> It depends on takeMVar and putMVar not being interruptible.
18:54:31 <JoeyA> (when it is known in advance that the MVar is full/empty)
18:54:56 <JoeyA> mm_freak: Inside of mask_, atomically (return ()) is not interrupted by async exceptions.
18:55:22 <JoeyA> http://hackage.haskell.org/packages/archive/base/latest/doc/html/Control-Exception.html#g:14
18:55:38 <JoeyA> "The following operations are guaranteed not to be interruptible: ... STM transactions that do not use retry"
18:56:03 <JoeyA> atomically (retry `orElse` return ()) is a transaction that uses retry, but appears to be interruptible.
18:59:28 <mietek> http://news.ycombinator.com/item?id=4309727
19:00:55 <JoeyA> Sigh indeed.  Fedora 17 doesn't come with the latest Haskell Platform.
19:01:16 <JoeyA> I remember when Fedora used to be one step ahead of Ubuntu regarding versions of things.  Now it seems it's the other way around.
19:01:23 <geekosaur> the error message there is horrible but what it is telling you is the package says it doesn;t work with your installed ghc
19:01:33 <JoeyA> (Ubuntu 12.04 adopted GHC 7.4.1 before HP 2012 was released)
19:01:56 <mietek> JoeyA: aha, so that's why I didn't get the same failure there.
19:02:04 <mietek> BTW this Fedora issue isn't me
19:02:39 <mietek> Is anyone working on making Cabal nicer, or is this just something that nobody wants to work on?
19:04:08 <luite> mietek: ugh, still problems with yesod-platform 1.0.6?
19:04:20 <mietek> luite: that's yet another one, yes
19:04:21 <mietek> ;)
19:05:04 <luite> i guess michael needs to add more stuff to the blacklist
19:05:23 <mietek> ( FYI https://github.com/yesodweb/yesod/issues/392 )
19:05:42 <mietek> Same workaround applies
19:06:11 <luite> hehe i guess he'll release 1.0.7 tomorrow with binary added to the blacklist
19:06:30 <mietek> I hope he actually tries it before releasing this time
19:06:51 <Cale> That error message could possibly be clearer, but personally, I like the fact that it's at least fairly detailed about the things which it tried.
19:06:53 <luite> yeah he probably uses a plain ghc install
19:07:28 <mietek> Cale: the error message in the yesod issue is fine
19:07:34 <mietek> Cale: the error message in the HN post is pretty bad
19:07:55 <luite> that's the older cabal-install isn't it?
19:08:13 <mietek> Probably, as JoeyA said
19:08:15 <Cale> I think the error message in the HN post could perhaps be clearer, but I don't personally mind the noise of it.
19:08:48 <mietek> Cale: the problem with it is that it's not clear what needs to be done for it to work
19:09:06 <Cale> Well, sure. You need to know that base is a package which is tied to the GHC version.
19:10:44 <mietek> For the dependency on base >=4.4 && <5 there are these packages: base-4.4.0.0, base-4.4.1.0, base-4.5.0.0 and base-4.5.1.0. However none of them are available. base-4.4.0.0 was excluded because base-4.3.1.0 was selected instead base-4.4.0.0 was excluded because of the top level dependency base -any
19:10:49 <mietek> Are you serious?
19:11:13 <mietek> "top level dependency base -any"
19:11:47 <redscare> i have a simple, dumb prime number finding function that I'm using to try to learn about how to use haskell for performance, numerical code: http://hpaste.org/72315. It works pretty quick as of now (still far slower than the c version of the same algorithm), but when i try to find the 1,000,000th prime it gives a stack space overflow error. do i really have to just increase the stack size?
19:11:57 <shopt> ldd can help with low level issues :)
19:12:30 <Cale> redscare: Stack overflow means that you're building up large expressions in memory which are being evaluated later
19:12:36 <Cale> (typically)
19:13:07 <mm_freak> JoeyA: have you tried -threaded?  because otherwise async exceptions can only be received at certain spots like garbage collection
19:13:22 <JoeyA> That's the case even with -threaded.
19:13:48 <redscare> Cale: that's probably the reason. if you look at the code, the helper function isn't tail-recursive anymore because i changed helper to be strict in one of its arguments
19:14:10 <mauke> ¯\(°_o)/¯
19:14:22 <redscare> Cale: but i had to do that to make the code run faster. can i get around this?
19:14:43 <hpaste> “Joey Adams” pasted “atomically (retry `orElse` return ()) is not interruptible” at http://hpaste.org/72316
19:14:49 <redscare> Cale: actually, would haskell be able to handle a list of 1,000,000 elements?
19:14:56 <JoeyA> mm_freak: But I tried it with -threaded, and got the same result.
19:15:10 <Cale> redscare: of course it can :)
19:15:15 <shopt> depends on how you implemented the prime number finding function if it is a simple one then perhaps yes. Unless of course you create simple quadratic sieve or more general number sieve which is very hard :) and is the bases of the quantum proof on why some encryption algorithms will fall prey :)
19:15:22 <mm_freak> JoeyA: then i'm not sure
19:16:31 <redscare> shopt: it's really simple, the code at http://hpaste.org/72315 is really clear, but what it does is build up N prime numbers, testing the Nth prime number with all prime numbers found before it
19:16:38 <mm_freak> redscare: the main problem i see in your code is appending to a list
19:16:45 <Cale> here's how I'd do it:
19:16:54 <Cale> primes = 2 : filter isPrime [3,5..]
19:17:14 <Cale> isPrime n = all (\p -> n `mod` p /= 0) (takeWhile (\p -> p*p <= n) primes)
19:17:32 <redscare> mm_freak: for the algorithm to work efficiently i have to test smaller numbers first
19:17:34 <Cale> this is seemingly about as fast as your program, and a good bit simpler
19:17:56 <Cale> actually, it seems it's a bit faster
19:18:05 <mm_freak> redscare: as far as i see your algorithm is an O(n) space algorithm anyway, so you can use a much simpler, likely faster algorithm
19:18:18 <mm_freak> i just wanted to write it, but Cale was faster =)
19:18:53 <shopt> ya , I don't know haskell yet or maybe never have to decide. But 100000000... gets to be an overflow issue in some language the way to get around it is uses big int or another algorithm which doesn't uses spaces
19:18:59 <shopt> just guessing though
19:19:16 <Cale> The important thing to understand about stack overflows is that there is no call stack
19:19:17 <mm_freak> Int will hardly overflow for that algorithm
19:19:18 <mauke> shopt: what do bigints have to do with this?
19:19:33 <Cale> So your intuition about stack overflows does not apply
19:19:38 <redscare> Cale, mm_freak: oh i know that the algorithm is terrible, I just wanted to try to see how i'd tweak other, more complicated projects should these problems arise. i have the same thing implemented in C and python so i can compare relative speeds
19:19:56 <Cale> The stack being referred to is more or less a pattern match stack
19:20:18 <mm_freak> redscare: the algorithm is actually a somewhat complicated case…  normally in haskell it is customary to generate and then traverse a list
19:20:31 <Cale> A stack of case expressions (or other pattern matches which get compiled into them) waiting for their scrutinee to be sufficiently evaluated to pattern match
19:20:38 <Cale> Consider something like this:
19:20:50 <Cale> foldl (+) 0 [1,2,3,4]
19:20:55 <Cale> @src foldl
19:20:55 <lambdabot> foldl f z []     = z
19:20:55 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
19:21:05 <Cale> foldl (+) 0 [1,2,3,4]
19:21:11 <Cale> -> foldl (+) (0+1) [2,3,4]
19:21:17 <Cale> -> foldl (+) ((0+1)+2) [3,4]
19:21:23 <Cale> -> foldl (+) (((0+1)+2)+3) [4]
19:21:24 <mm_freak> foldl shouldn't stack-overflow…  it's more likely to heap-overflow
19:21:30 <Cale> -> foldl (+) ((((0+1)+2)+3)+4) []
19:21:35 <redscare>  mm_freak: as opposed to doing what?
19:21:36 <Cale> -> (((0+1)+2)+3)+4
19:21:37 <mauke> mm_freak: wat
19:21:41 <luite> heap overflow?
19:21:44 <Cale> *foldl* doesn't stack overflow :)
19:21:52 <Cale> the expression which it creates might
19:22:00 <mm_freak> yeah
19:22:12 <ddarius> redscare: The seq doesn't make helper not tail recursive any more than the use of && makes isPrime not tail recursive.
19:22:24 <ddarius> redscare: You can verify this by removing the seq.
19:22:24 <Cale> So we get to this point here without having used any stack at all (well, one stack spot, to evaluate the list)
19:22:36 <mm_freak> redscare: whenever you are compelled to write a loop for a numeric iterative algorithm, the haskell solution is very likely a (usually infinite) list, which you then traverse
19:22:39 <mm_freak> produce, then consume
19:22:45 <mm_freak> laziness makes this work nicely
19:23:15 <ddarius> redscare: In fact you already verified this.
19:23:17 <redscare> Cale, mm_freak, ddarius: thanks for your help so far. I know that the algorithm is bad, but do you guys see any way to make this code work, or is it not worth it because i won't *ever* run into problems like the one i'm having if i program 'haskell-like'?
19:23:40 <Cale> redscare: oksy
19:23:43 <mm_freak> redscare: you will eventually run into this problem, and Cale has written a nice solution already
19:23:44 <redscare> ddarius: then where would the stack overflow come from?
19:23:53 <mauke> redscare: "make this code work" involves changing the code, at which point it's no longer "this code"
19:24:10 <Cale> So, let's look at what's going on in this program
19:24:49 <Cale> hmm
19:24:56 <Cale> where does l get used in helper?
19:25:01 <mm_freak> of course since it's already an O(n) space algorithm, i would have used a sieve instead, but that doesn't answer your question =)
19:25:23 <mm_freak> however, a sieve shows the strengths of haskell as an imperative language =)
19:25:25 <ddarius> redscare: Cale already described how stack overflows have other causes in Haskell, but it actually isn't clear where the issue is.
19:25:34 <redscare> Cale: l is the accumulated length of the list, i use it because ddarius pointed out that length is slow
19:25:45 <ddarius> > nubBy((<1).:gcd)[2]
19:25:47 <lambdabot>   [2]
19:25:53 <ddarius> > nubBy((<1).:gcd)[2..]
19:25:55 <lambdabot>   [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,2...
19:26:01 <Cale> okay, it'll be evaluated because either l+1 or l will be bound to nl and then the if will force its evaluation before helper' is applied
19:26:04 <Cale> So that's not it
19:26:20 <ddarius> > nubBy((>1).:gcd)[2..]
19:26:22 <lambdabot>   [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101...
19:28:24 <lambdanaut> I've got a module "Extra" that shares the function "head" with Prelude. How can I make calls to "head" default to Prelude's head rather than Extra's head
19:28:40 <lambdanaut> so that calling head won't give me ambiguous function errors
19:28:44 <mm_freak> lambdanaut: import qualified Extra
19:28:45 <redscare> Cale: and i think c has to get evaluated because it's strict in c. maybe it's the (++)?
19:28:49 <mauke> lambdanaut: don't import Extra
19:29:05 <lambdanaut> thanks mm_freak (:
19:29:14 <ddarius> > length $ replicate 10000000 () ++ [()]
19:29:17 <lambdabot>   10000001
19:29:23 <mm_freak> lambdanaut: you can also import Extra twice:  import Extra hiding (head); import qualified Extra as E
19:30:13 <redscare> ddarius: but what could be happening is building up lots of (++) applications as lots of the primes won't be accessed
19:30:28 <redscare> ddarius: just to try it, how would i force ++ to be evaluated?
19:31:31 <mm_freak> btw, IMO the 'qualified' keyword should come after the module name
19:31:58 <mm_freak> this would make double imports more readable
19:32:43 <luite> that's why many people align the module names
19:34:52 <mm_freak> i don't really like that
19:35:00 <mm_freak> i just put the qualified modules at the top
19:35:01 <redscare> Cale, mm_freak, ddarius: i might be asking too much, but any ideas? or i can just give up and change the algorithm :)
19:35:14 <mm_freak> redscare: my suggestion is to start with a simpler algorithm first
19:35:25 <mm_freak> get your hands wet with producing and consuming lists
19:35:52 <mm_freak> redscare: my suggestion is to start with the lucas lehmer primality test for mersenne numbers
19:36:12 <mm_freak> it is a simple algorithm, with which you can practice using lists
19:37:02 <mm_freak> first produce the sequence, then traverse it…  for now do it with as few predefined helper functions as possible
19:37:14 <Cale> I'm still trying to sort out exactly what's going on, but this isn't in an easy form to figure out.
19:37:18 <redscare> mm_freak: definitely, but i'm still bothered by the stack overflow, if you could possibly shed some light on that?
19:37:35 <Cale> okay, hand execution time :)
19:37:47 <redscare> Cale: i figured this form is something that would occur frequently? :) i guess not. thanks very much btw
19:37:50 <mm_freak> redscare: i think Cale already gave a good explanation there, but i'm afraid as a beginner it won't be helpful yet
19:38:10 <mm_freak> to summarize:  case x of …
19:38:22 <mm_freak> now x is evaluated, which may again require pattern matches
19:38:40 <mm_freak> each nested 'case' will push on the stack
19:38:56 <mm_freak> not nested syntactically, but by dependency
19:39:10 <mm_freak> case (… case …) of …
19:40:01 <mm_freak> case … of { … case … }  -- this is no problem
19:40:05 <ddarius> Hmm is fusion foiling me.
19:41:14 <ddarius> > let xs = replicate 1000000 () in length xs `seq` length (xs ++ [()])
19:41:16 <lambdabot>   1000001
19:42:11 <mm_freak> > let stackOverflow = case stackOverflow of True -> "yes" in stackOverflow
19:42:12 <lambdabot>   Couldn't match expected type `GHC.Bool.Bool'
19:42:12 <lambdabot>         against inferred type ...
19:42:19 <mm_freak> > let stackOverflow = case stackOverflow of True -> True in stackOverflow
19:42:23 <lambdabot>   mueval-core: Time limit exceeded
19:45:37 <mm_freak> somehow i'm failing to produce a stack overflow
19:45:46 <mm_freak> the one time i actually want it =)
19:46:11 <latro`a> the effect should be different in ghci than lambdabot I think
19:46:37 <mm_freak> i just tried a compiled version…  still heap overflow
19:46:54 <mauke> > foldl (+) 0 [0, 0 ..]
19:46:58 <lambdabot>   mueval-core: Time limit exceeded
19:47:04 <mauke> interesting
19:47:12 <mauke> mm_freak: what does a heap overflow look like?
19:47:38 <mm_freak> mauke: Heap exhausted;
19:47:57 <mauke> that looks like it's out of memory, not an overflow
19:49:35 <mm_freak> if you fill a glass with water, you will run out of capacity, or put differently you will cause an overflow
19:49:53 <mauke> http://en.wikipedia.org/wiki/Heap_overflow
19:50:36 <mm_freak> ok, i see your point
19:50:50 <mm_freak> but then we also don't have "stack overflows"
19:50:59 <mm_freak> we run out of stack memory
19:51:17 <mauke> http://en.wikipedia.org/wiki/Stack_overflow
19:51:41 <mm_freak> ok, then the terminology is inconsistent
19:51:50 <mauke> yeah
19:52:23 <mauke> I just noticed that something about "heap overflow" looked wrong to me, so I looked it up on wikipedia
19:53:04 <ddarius> Ironically, I believe the length of nprimes was what was saving redscare before.
19:55:19 <Cale> Yeah, it looks like because he's not necessarily evaluating the whole list of primes on each iteration, eventually the later parts of the list end up with a large number of (++)'s in front of them
19:55:39 <ddarius> Cale: Yep.  I'm working on a reduction sequence to spell that out.
19:57:33 <Cale> redscare: In general something to be suspicious of is any case where you're adding to the end of a list with ++
19:57:51 <Cale> redscare: xs ++ ys takes O(length xs) steps to reduce fully
19:58:24 <Cale> redscare: and so if you're recursively adding one element to the end of a list over and over, the cost of evaluating the whole list is quadratic
19:58:47 <redscare> Cale: i think i asked whether the ++ was avoidable, but i only want to test up to the sqrt of the number being tested, so i think i have to have it there
19:59:04 <ddarius> Let's say isPrime only needed to look at 1 cons cell.  Then isPrime c (([a,b,c]++[d])++[e]) ~> isPrime c ((a:([b,c]++[d]))++[e]) ~> isPrime c (a:([b,c]++[d])++[e]).  Then next time around with f you get isPrime c' ((a:([b,c]++[d])++[e])++[f] ~> isPrime c' (a:((([b,c]++[d])++[e])++[f]).  And then when isPrime decides to go 1 step further, it now has a tower of (++) expressions to evaluate to get to the head.
19:59:48 <Cale> redscare: Did you look at the program I wrote?
20:00:42 <redscare> ddarius: i probably wasn't being clear, but i actually asked a while ago how to force the ++'s to evaluate?
20:00:49 <BMeph> redscare: Heck, did you look at the program ddarius (eventually) wrote? ;)
20:01:21 <ddarius> redscare: The right solution is to avoid this problem entirely.
20:01:33 <redscare> Cale: i'm sorry i must have missed it. the sieve?
20:01:53 <mauke> yeah, any problem that starts with "so I have a lot of calls to (++) ..." is already wrong
20:02:13 <Cale> > let primes = 2 : filter isPrime [3,5..]; isPrime n = all (\p -> n `mod` p /= 0) (takeWhile (\p -> p*p <= n) primes) in primes
20:02:14 <lambdabot>   [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101...
20:02:14 <redscare> ddarius mauke: is the solution to use a different data structure?
20:02:19 <Cale> ^^ that one
20:02:28 <Cale> this only tests primes up to the square root of n
20:02:42 <Cale> and it avoids the problem of adding over and over to a list, by simply defining the list of all primes at once
20:03:12 <redscare> Cale: oh of course. i said right away you had a better algorithm, this was just an exercise to see how to work around these problems if such an algorithm is unavoidable.
20:03:49 <startling> why is :t error :: [Char] -> a ? does it become whatever type it needs to be for typechecking? or what?
20:04:16 <mauke> startling: what else would it be?
20:04:42 <Cale> startling: yes -- it's treated in the same way as nontermination, basically
20:05:14 <ddarius> redscare: That's one option.
20:05:45 <Cale> I wonder if we could use the (++) -> (.) trick productively...
20:05:59 <ddarius> A strict append avoids the stack overflow, though of course it's slow as heck.
20:06:07 <edwardk> cale: ?
20:06:10 <edwardk> what trick
20:06:14 <edwardk> oh
20:06:17 <edwardk> the difference list thing
20:06:39 <Cale> [] -> id; (++) -> (.); [x] -> (x:)
20:06:40 <Cale> yeah
20:06:45 <ddarius> It's easy enough to try.
20:06:47 <redscare> ddarius: well it's "only" being done 1,000,000 times :)
20:08:02 <Cale> I can't imagine that this will be very efficient, but it might avoid the stack overflow...
20:08:31 <Cale> I'm not getting a stack overflow now, but it's taking a long time.
20:09:03 <monocell> redscare: I think the algorithms are the same, the only difference is that you manually try to keep track of how much of the prime list you've generated?
20:09:45 <redscare> Cale: well it's a really stupid algorithm, 1,000,000 is probably going to take a while :)
20:09:54 <ddarius> Well 1,000,000^2 is only a trillion.  With a 1GHz processor and going through the loop in one cycle means it will only take about 16 minutes.
20:10:07 <Cale> redscare: if you'd like to try this too, instead of passing the list drop 1 knownPrimes to helper, pass the function (drop 1 knownPrimes ++)
20:10:28 <Cale> redscare: and instead of (primes ++ [c], l + 1) use (primes . (c:), l + 1)
20:10:28 <redscare> Cale: that's all?
20:10:44 <Cale> redscare: and then when you call isPrime, change that to  isPrime c (primes [])
20:10:47 <edwardk> heya roconnor_
20:10:55 <Cale> (and that's all)
20:11:11 <ddarius> There are three ways to resolve the stack overflow, all of them emphasizing the quadratic nature of the algorithm.
20:11:15 <Cale> It avoids the problem which was causing the stack overflow
20:11:20 <ddarius> As well as the memory hungry nature.
20:11:25 <Cale> but the cost of the algorithm is bad
20:11:40 <Cale> So it takes a long time anyway
20:11:58 <ddarius> The simplest thing would be to add length nprimes `seq` ... before the if.  Another alternative is to use an eager append.  Cale's option is a third alternative.
20:12:34 <ddarius> > nubBy((>1).:gcd)[2..]!!1000000
20:12:38 <lambdabot>   mueval-core: Time limit exceeded
20:12:48 <edwardk> debating about breaking up the lens api like this: http://imgur.com/MNkew or as Control.Lens.Array, Control.Lens.Bits, Control.Lens.Strategies, etc.
20:13:06 <Cale> redscare: This trick of replacing lists with functions that add elements to the beginning of a list and (++) with (.) is often good for improving the performance of algorithms though
20:13:35 <Cale> redscare: Unlike how (xs ++ ys) costs O(length xs) steps to evaluate, (f . g) takes only one.
20:14:01 <Cale> redscare: for example, consider the problem of reversing a list
20:14:06 <Cale> reverse [] = []
20:14:10 <edwardk> and the listing on cabal is a lot shorter because you don't have the module name path changing all over, but then it makes a bit of a weird placement for folks who make their own later
20:14:14 <Cale> reverse (x:xs) = reverse xs ++ [x]
20:14:24 <Cale> this is correct, but costs quadratic time
20:14:38 <ddarius> And linear stack...
20:14:44 <Cale> To fix it, we can make those replacements I mentioned:
20:14:49 <Cale> reverse' [] = id
20:14:59 <Cale> reverse' (x:xs) = reverse' xs . (x:)
20:15:11 <Cale> and then apply the result to an empty list to get an ordinary list back
20:15:21 <Cale> reverse xs = reverse' xs []
20:15:28 <Cale> this is now linear time
20:16:05 <Cale> redscare: make sense? :)
20:16:20 <Cale> (I get that this can be quite mindbending the first time you see it :)
20:16:25 <redscare> Cale: tried some stuff in the interpreter, yep :) thanks, that's an interesting way of doing it
20:18:13 <Cale> redscare: This is similarly useful when defining traversals over tree structures:
20:18:28 <Cale> data Tree a = Tip | Branch a (Tree a) (Tree a)
20:18:39 <Cale> inorder' Tip = id; inorder
20:18:41 <Cale> oops
20:18:50 * ddarius grumbles at regularization.
20:18:54 <Cale> inorder' Tip = id; inorder' (Branch x l r) = inorder' l . (x:) . inorder' r
20:19:04 <redscare> Cale: it's REALLY slow now though :) i'll look into another data structure i guess
20:19:43 <ddarius> redscare: If you were to stick with this data structure, what you'd really want to do is share the work rather than recomputing it each time.
20:20:31 <ddarius> redscare: If you pursue that, you are naturally led to a solution where you produce all the primes and then just pick out the one you want.
20:21:38 <Cale> Yeah, the main difference between the little program I wrote and the one which you have here is that the little program maintains a single fixed list of primes which will be shared throughout the whole computation, rather than making new datastructures containing primes constantly.
20:26:41 <Cale> redscare: another thing you can do to speed it up is to use Data.Sequence
20:26:57 <Cale> redscare: which is a sequence datastructure that has fast access to both ends
20:27:10 <redscare> Cale: would it be possible to use data.sequence with your algorithm?
20:27:14 <Cale> (so it can operate as a queue, like you're using your list of primes)
20:27:33 <Cale> No, because Data.Sequence doesn't allow for infinite sequences.
20:28:16 <redscare> Cale: ok. even your algorithm doesn't beat my 'dumb' one written in C, but i guess that's why C exists :)
20:28:51 <Cale> redscare: My algorithm is still bad
20:29:51 <redscare> Cale: well it's better than mine :) and i wish haskell was faster. it's more than 10 times slower than my horribly stupid c version
20:29:52 <Cale> redscare: http://www.cs.hmc.edu/~oneill/papers/Sieve-JFP.pdf
20:30:09 <Cale> Well, you're using linked lists :P
20:30:40 <Cale> You could use mutable arrays in Haskell too
20:31:01 <Cale> (Unless your C version also uses linked lists, in which case, nevermind :)
20:31:11 <ddarius> I'd be impressed if that was the case.
20:31:46 <Cale> Lists are a really nice datastructure, but not for just anything you'd consider a sequence of items.
20:32:11 <Cale> They're more analogous to loops in imperative languages than anything else.
20:32:16 <redscare> Cale: but i can't do anything as elegant as your example with sequences or arrays?
20:32:41 <Cale> redscare: mmm... probably not as short
20:32:58 <Cale> redscare: I'm not really sure. :)
20:33:10 <hpaste> ddarius annotated “GetNthPrime v4” with “GetNthPrime v4 (annotation)” at http://hpaste.org/72315#a72318
20:33:19 <Cale> You could actually get pretty close using a lazy array
20:33:23 <ddarius> That is a version where the constant appending is not done.
20:33:44 <ddarius> Cale: Yes, you could use a dynamic programming-like technique.
20:34:08 <ddarius> dp
20:34:09 <ddarius> > dp
20:34:11 <lambdabot>   Not in scope: `dp'
20:36:33 <ddarius> @let dp n f = let a = array (0,n) (zipWith f [0..] (elems a)) in a
20:36:35 <lambdabot>  Defined.
20:37:17 <ddarius> @undefine
20:37:39 <ddarius> @let dp n f = let a = array (0,n) (map (f a) [0..]) in a
20:37:40 <lambdabot>  Defined.
20:40:48 <slack1256> it's there an option for ghci to export all the functions of a module (not just the ones exposed?)
20:41:20 <parcs`> :m + Module
20:43:44 <slack1256> and if it is a non exported module? (something like Data.Text.Internal
20:45:32 <Cale> slack1256: Download the source code of text
20:45:36 <parcs`> then you're out of luck
20:48:17 <slack1256> Cale: I did that, and loaded 'ghci Data/Attoparsec/Text/Internal.hs' then it asks me for 'Data/Attoparsec/Text/Fastset.hs' which is also non-exported
20:48:54 <slack1256> oh i could specify more modules inthe command line
20:52:42 <mm_freak> an immutable vector version of the sieve of eratosthenes is surprisingly fast
20:53:41 * hackagebot metadata 0.1.0.1 - metadata library for semantic web. (KatsutoshiItoh)
20:54:39 <mm_freak> primes below 10^7 in 1.8 seconds
20:54:51 <slack1256> mm_freak: really? I thought vector should be used as reference datatype (only ask but don't change anything)
20:55:24 <Cale> That's presumably how he's using it?
20:56:07 <mm_freak> slack1256: that's how i'm using it
20:56:25 <mm_freak> let me optimize a bit, then i'll post the code
20:56:31 <slack1256> mm_freak: could you hpaste it?
20:57:26 <slack1256> kthxbai ;-)
20:58:33 <hpaste> “Ertugrul Söylemez” pasted “Sieve of Eratosthenes (immutable vector implementation)” at http://hpaste.org/72319
20:58:40 <mm_freak> slack1256: see paste
20:59:25 <Veinor> @hoogle [a] -> (a -> m b) -> m [b]
20:59:26 <lambdabot> Control.Monad forM :: Monad m => [a] -> (a -> m b) -> m [b]
20:59:26 <lambdabot> Prelude mapM :: Monad m => (a -> m b) -> [a] -> m [b]
20:59:26 <lambdabot> Control.Monad mapM :: Monad m => (a -> m b) -> [a] -> m [b]
21:02:02 <mm_freak> i wonder if repa would make a difference there
21:02:36 <mm_freak> but i doubt it
21:02:36 <ddarius> @undefine
21:03:04 <ddarius> @let dp n f = let a = array (0,n) (map (\i -> (i, f a)) [0..n]) in a
21:03:05 <lambdabot>  Defined.
21:03:51 <ddarius> @undefine
21:03:54 <ddarius> @let dp n f = let a = array (0,n) (map (\i -> (i, f a i)) [0..n]) in a
21:03:55 <lambdabot>  Defined.
21:04:13 <slack1256> mm_freak: doubt it, this code is pretty much sequential
21:04:33 <slack1256> although one can always try and shut up the critics >:D
21:08:22 <jimi_hendrix> is there a function that maps a predicate to a list and returns true if the predicate is ever true? i guess i could do it with a foldl', but that would evaluate the whole list even after the predicate is true, and i only need to know if the predicate was true at least once.
21:08:43 <Veinor> > any odd [2..]
21:08:44 <lambdabot>   True
21:09:05 <mm_freak> slack1256: the code can be parallelized
21:09:16 <mm_freak> the Vu.// step is parallel
21:09:28 <mm_freak> but repa doesn't seem to have a parallel primitive for that
21:10:01 <jimi_hendrix> Veinor, thanks
21:13:04 <slack1256> mm_freak: are you sure about that? by the example it seems that "<5,9,2,7> // [(2,1),(0,3),(2,8)] = <3,9,8,7>" implies that the order of the list affect the result (order of application
21:13:32 <slack1256> also Data.Vector.Generic (//) give a reference of being fused but not executed in parallel
21:13:56 <slack1256> but this is me speaking in a terrain which I don't dominate
21:16:27 <ddarius> My dp function has a problem and I don't know how best to solve it.
21:18:04 <dncr> is there a fork of Yampa that is currently more active than Yampa?
21:18:04 <lambdabot> dncr: You have 1 new message. '/msg lambdabot @messages' to read it.
21:20:38 <mm_freak> slack1256: you're right…  but if the indices are unique, then this can be parallelized
21:21:22 <mm_freak> dncr: animas is a fork of yampa that has at least shown /some/ activity…  for a yampa-like library that is actively developed (by me =)) see netwire
21:21:35 <dncr> nice
21:27:36 <mm_freak> dncr: see <http://www.haskell.org/haskellwiki/Netwire> for a short tutorial…  it should give you the basic idea
21:27:43 <dncr> ok
21:46:16 <redscare> is there a built-in function for unboxed vectors that allows 'sorted' insertion? i.e. if a list is already sorted, insertion of an element occurs to keep it sorted?
21:47:26 <shachaf> Vectors or lists or what?
21:47:29 <Kaidelong> mmm? and it makes a copy of the vector with the element added?
21:47:35 <shachaf> You're still going to have to cpy the whole thing, unless it's mutable.
21:47:42 <shachaf> (If you're talking about vectors.)
21:47:47 <redscare> oh a mutable unboxed vector
21:48:08 <Kaidelong> wouldn't you still have to copy the whole thing even if it is mutable?
21:48:20 <shachaf> Kaidelong: No, you might just have to copy part of the thing.
21:48:22 <Kaidelong> or does the vector implementation work with powers of two under the covers or something
21:48:37 <shachaf> Well, I guess that depends on what you mean by "vector".
21:49:48 <Kaidelong> redscare: It shouldn't be too hard to find such a function on hackage if it is there but are you sure you need to do this with a vector?
21:49:53 <redscare> shachaf: i mean Data.Vector.Unboxed
21:50:04 <Kaidelong> for another data type that implements foldable you could turn it into a vector after you're done with it
21:50:06 <applicative> there's no reason why it would have to be copied if its really a stream youre building as with vector
21:50:08 <Kaidelong> like sy, a Map
21:51:09 <redscare> Kaidelong: well i definitly don't want to use a list. the use-case is i want to insert values to keep the thing sorted, and pop them off the front when needed
21:51:28 <Kaidelong> oh, like a heap?
21:51:36 <Kaidelong> mutation actually won't win you much there
21:51:51 <Kaidelong> you might just want to use a Map or Set
21:51:59 <redscare> Kaidelong: i thought it would with the insertion
21:52:00 <applicative> do you need a giant vector it sounds like Set
21:52:19 <Kaidelong> redscare: inserting into arrays is not efficient
21:52:21 <Kaidelong> but
21:52:33 <Kaidelong> with a Map it's logarithmic
21:52:38 <mauke> classic priority queue
21:53:14 <Kaidelong> redscare: you want to use mutable vectors when A) indexes are important, B) you want to overwrite things at certain indexes
21:54:00 <Kaidelong> in this case an immutable data structure is probably better due to the fact that it can be "copied" for a pittance by just referencing it
21:54:18 <applicative> deleteFindMin :: Set a -> (a, Set a) ; insert :: Ord a => a -> Set a -> Set a
21:54:21 <redscare> Kaidelong: isn't copying slow? :)
21:54:36 <mm_freak> the vectors from the 'vector' library can do many things without copying, as long as they are part of a composition
21:54:44 <mm_freak> note that the 'vector' library performs stream fusion
21:54:44 <applicative> not if it isn;t copying
21:54:48 <Kaidelong> the stream-fusion stuff?
21:54:58 <Kaidelong> mmm although
21:55:19 <Kaidelong> I thought it could only do stream fusion on stuff that are hylomorphisms over other foldables
21:55:21 <mm_freak> but this isn't what's happening in my prime sieve code…  it likely actually performs the copying
21:55:46 <redscare> is Data.Set a complete priority queue?
21:55:46 <mm_freak> it's really the full copying thing, and yet it manages to calculate the first 10 million primes in less than two seconds here
21:55:51 <Kaidelong> redscare: to "copy" a map you just pass a reference to the map
21:56:02 <mm_freak> redscare: yes…  every element gets a unique priority
21:56:28 <mm_freak> the priority is determined by the Ord instance of the element type
21:56:31 <Kaidelong> what kind of implementation does Glasgow Haskell use for Set?
21:56:38 <Kaidelong> just an AVL tree?
21:56:44 <mm_freak> Kaidelong: see the 'containers' library source code
21:56:51 <mm_freak> it's not part of GHC
21:56:57 <ddarius> Data.Set is a compiler-independent library.
21:57:11 <Kaidelong> thanks
21:58:04 <redscare> mm_freak: just wondering, why did you chose to use vector.unboxed as opposed to set in your seive?
21:58:22 <mm_freak> redscare: how would you use Set as a bit field?
21:58:30 <ddarius> A long, long time ago Hugs, GHC, and NHC shared a source tree for all the "core" libraries.  The good ole fptools repository.
21:58:30 <mm_freak> redscare: presence/absence of indices?
21:59:20 <ddarius> Does vector do bit packing?
21:59:24 <mm_freak> redscare: a vector stores this presence/absence by a single indexed bit and query is O(1), but it would be interesting to try Data.Set
21:59:27 <mm_freak> ddarius: yes
21:59:57 <Kaidelong> there is IntSet
22:00:57 <mm_freak> let's see how well IntSet performs
22:01:30 <ddarius> Bitpacking makes a big, positive difference for sieve algorithms.
22:04:01 <mm_freak> IntSet seems to be much slower
22:06:27 <Veinor> hm, that's unfortunate
22:06:54 <Veinor> it looks like using RandT from Control.Monad.Random, if i stack it on top of a tree, then when i run a monadic action over all leaves of a tree using >>=, they get the same state in each generator
22:08:16 <mm_freak> while Vector Bool required only 1.6 secs, IntSet required 19.9 secs
22:08:30 <mm_freak> for all primes <= 10^7
22:08:53 <mm_freak> but it's not surprising…  IntSet does heavy thunk work for every single change
22:10:55 <mm_freak> i have two methods for bulk deletion from an IntSet
22:11:04 <mm_freak>     deletes = flip (foldl' (flip Si.delete))
22:11:05 <mm_freak>     deletes ds xs = xs Si.\\ Si.fromList ds
22:11:09 <mm_freak> the former is faster
22:11:55 <ddarius> That's not surprising.
22:12:58 <mm_freak> yeah…  with access to the underlying data structure i could probably write a much faster deletion algorithm, but IntSet is exported opaque
22:13:35 <mm_freak> but wait
22:14:49 <mm_freak> ok, the \\ version is now faster and the whole algorithm runs in 19.0 secs
22:15:41 <hpaste> “Ertugrul Söylemez” pasted “Sieve of Eratosthenes (IntSet implementation)” at http://hpaste.org/72321
22:15:44 <edwardk> ok, i'm at the limits of my haddock-fu, i was hoping i could get some help
22:16:05 <mm_freak> see the paste…  this is the IntSet-based sieve
22:16:20 <mm_freak> it's still much slower than the immutable vector version
22:16:22 <edwardk> haddock craps out on this line https://github.com/ekmett/lens/blob/master/lens.cabal#L130   and i have no idea how to make it not do that
22:16:35 <mm_freak> and of course needs loads of memory
22:16:56 <edwardk> i get haddock: failed to parse haddock prologue from file: dist/doc/html/lens/haddock-prolog24524.txt
22:17:09 <edwardk> it took forever for me to isolate the line that was the culprit
22:17:19 <edwardk> but nothing i do to the line seems to help
22:18:12 <edwardk> anyone?
22:18:13 <mm_freak> is that really a haddock issue?  it could be a hackage issue
22:18:22 <redscare> is there a funtion that "lifts" functions of multiple arguments to apply to the first element of pairs? i.e. (a -> b -> c) -> ((a, _) -> (b, _) -> c)?
22:18:24 <edwardk> i haven't uploaded it to hackage
22:18:26 <edwardk> its local
22:18:35 <edwardk> just when i cabal install haddock
22:18:39 <edwardk> er cabal haddock
22:18:41 <mm_freak> redscare: 'first' from Control.Arrow
22:18:51 <mm_freak> > first succ (3, 5)
22:18:52 <lambdabot>   (4,5)
22:19:07 <mm_freak> is that what you wanted?
22:19:27 <mm_freak> oh, no, it probably isn't, but you can use it to do what you want =)
22:19:40 <edwardk> bah. _1 %= succ $ (3,5) ;)
22:19:52 <edwardk> or: adjust _1 succ (3,5)
22:19:56 <edwardk> =)
22:19:58 <latro`a> oh dear
22:20:02 <mm_freak> _1?
22:20:06 <mm_freak> is that fstLens?
22:20:13 <edwardk> yeah
22:20:18 <mm_freak> ugly!
22:20:26 <edwardk> it grows on you =)
22:20:35 <mm_freak> gimme back my fstLens =)
22:20:55 <edwardk> 2 characters, and it vanishes nicely when composed
22:21:01 <edwardk> traverse._2._2
22:21:12 <mm_freak> you actually use it like that?
22:21:15 <edwardk> yep
22:21:20 <mm_freak> without spaces?
22:21:28 <edwardk> horrible, eh?
22:21:31 <mm_freak> ugly!
22:21:32 <edwardk> m^.i.j
22:21:54 <edwardk> it would be, … if it was as big and nasty as fstLens
22:22:01 <mm_freak> seems like with lenses we are approaching C++ =)
22:22:03 <edwardk> traverse.fstLens.fstLens looks awful ;)
22:22:27 <edwardk> well, they DO give you += =)
22:22:36 <mm_freak> i'm quite used to "fstLens . fieldX . repY"
22:22:53 <hpaste> jimi_hendrix pasted “syntax error” at http://hpaste.org/72322
22:23:05 <edwardk> i've slowly switched my style around to the few spaces and small lens name style
22:23:15 <edwardk> (1, 2 :+ 3)^._2.to magnitude
22:23:58 <mm_freak> that is unintelligible at a first glance
22:23:58 <solrize> that's almost a reinvention of haskell
22:24:01 <jimi_hendrix> stupid noob question: why am i getting a syntax error on line 23? it just says 'parser error on input newCoef'.
22:24:07 <solrize> i wonder how much ghc can fuse all those lenses
22:24:19 <edwardk> (1, [2 :+ 3, 4 :+ 5])^._2.traverse.to magnitude
22:24:27 <edwardk> solrize: surprisingly well
22:24:37 <edwardk> they are all monomorphic, being used in monomorphic contexts, etc.
22:24:45 <edwardk> everything is INLINE marked
22:24:49 <solrize> jimi_hendrix, the "else" part is not optional in an if
22:25:13 <solrize> i.e. line 19 is an if with no else
22:25:14 <edwardk> er that last one actually won't work the types don't check
22:25:23 <edwardk> but its a technicality ;)
22:25:48 <mm_freak> jimi_hendrix: if that's the complete function definition the whole thing is a syntax error =)
22:26:03 <mm_freak> jimi_hendrix: the last thing in a 'do' block must be an expression
22:26:08 <edwardk> anyOf (traverse._2.traverseByteString) (==0x80)  is perhaps a better example
22:26:54 <edwardk> Traversable f => f (a, ByteString) -> Bool
22:27:12 <solrize> jimi_hendrix, i dont see why you have do's there
22:27:14 <edwardk> traverse puts the f' on, the _2 puts the (a,) on and traverseByteString fills in the ByteString
22:27:25 <solrize> do is syntax sugar for a monad bind chain
22:27:28 <solrize> that is a pure function
22:27:34 <solrize> you should read LYAH or something
22:27:41 <jimi_hendrix> solrize, i forgot to remove that
22:28:02 <edwardk> to takes a function and makes a getter out of it, so you can chain it with these other things
22:28:41 <edwardk> mm_freak: you don't have to smash everything together of course if you don't want to =P
22:29:03 <mm_freak> jimi_hendrix: if you remove it, then you end up with an unfinished 'let'
22:29:19 <mm_freak> outside of 'do' and list comprehensions there is no 'let' without 'in'
22:29:20 <edwardk> nobody have any idea about that haddock error?
22:29:34 <mm_freak> jimi_hendrix: i second solrize's suggestion to read LYAH
22:30:27 <mm_freak> jimi_hendrix: you seem to be trying to write C in haskell, which simply won't work =)
22:30:32 <jimi_hendrix> mm_freak, i did. my brain is starting to go to sleep though. i must have just missed the in somewhere.
22:30:35 <solrize> you don't need all those "let", "where" is probably cleaner.  because of lazy evaluation those expressions aren't computed unless you actually use them
22:30:38 <ddarius> edwardk: I would worry about the TH stuff, e.g ''Foo but nothing seems wrong with that line.
22:30:40 <jimi_hendrix> mm_freak, old habits die hard
22:30:54 <solrize> so you can write the equation without having to check whether you need it
22:31:00 <edwardk> i removed that TH line and it still crapped out
22:31:05 <mm_freak> jimi_hendrix: of course…  better take a break and revisit LYAH later, possibly after getting some sleep =)
22:31:11 <edwardk> in fact if that line is the only thing in there it dies
22:31:33 <edwardk> so i'm pretty sure its the data Foo a line. but i have no idea what it is trying to parse out of that line
22:31:33 <solrize> edwark what error?
22:31:48 <solrize> *edwardk
22:31:56 <mm_freak> solrize: this actually isn't because of lazy evaluation
22:32:02 <ddarius> You didn't accidentally spew some crazy non-ASCII character in there somehow?
22:32:13 <edwardk> https://github.com/ekmett/lens/blob/master/lens.cabal#L130 the highlighted line causes haddock to crap out
22:32:38 <solrize> mm_freak, i'm looking at, say, line 15
22:32:44 <edwardk> i just gave up and rephrased the problem away, but i'd like to know what the hell i was doing wrong
22:32:45 <jimi_hendrix> mm_freak, which let is missing the in?
22:33:03 <edwardk> losing an hour to chasing down a documentation problem is why i don't haddock stuff in the first place
22:33:18 <ddarius> edwardk: Haddock is very annoying about that.
22:33:41 <ddarius> It would be nice if it either gave better error messages or was more forgiving.
22:33:43 <mm_freak> jimi_hendrix: the outermost after removing the 'do'
22:33:59 <edwardk> giving up and pushing the version that works
22:34:48 <jimi_hendrix> mm_freak, it has one, see line 4 of the paste
22:34:51 <edwardk> ok, then on a documentation related note, can someone proof read through https://github.com/ekmett/lens/blob/master/lens.cabal#L15 and let me know what you think?
22:35:05 <mm_freak> jimi_hendrix: oh, indeed
22:35:25 <mm_freak> the code is really hard to read
22:35:31 <latro`a> I'm kind of a newb with lenses, so slightly silly question:
22:35:35 <ddarius> edwardk: Feedback 1.  Delete "So what are they?"
22:35:37 <latro`a> what is the point of the Const in that file?
22:35:47 <edwardk> ddarius: =P
22:35:49 <latro`a> that is what does Const a b get you that a doesn't?
22:36:11 <edwardk> ok, maybe that is a bit bloggy ;)
22:36:15 <jimi_hendrix> mm_freak, indentation weird?
22:36:25 <edwardk> latro`a: a 'Functor' ;)
22:36:32 <latro`a> why is that a good thing
22:36:42 <latro`a> OK, another way of putting it
22:36:45 <mm_freak> jimi_hendrix: indentation and placement of supplemental keywords like 'in'
22:36:48 <latro`a> what does Const a b get you that Identity a doesn't
22:36:49 <edwardk> because the shapes line up when i align it with everything else in there
22:36:54 <latro`a> shapes?
22:36:55 <mm_freak> jimi_hendrix: if you wouldn't indent after the 'in' it would be clear
22:36:58 <solrize> line 29 every 'Getter',    extra comma
22:36:58 <hpaste> jimi_hendrix annotated “syntax error” with “syntax error (annotation)” at http://hpaste.org/72322#a72323
22:37:25 <edwardk> every function i describe in that doc has the form (c -> f d) -> a -> f b   -- for some functor f
22:37:39 <latro`a> so why Const and not Identity
22:37:45 <edwardk> I get it by carefully choosing by choice of 'f' to get the right behavior
22:37:54 <edwardk> I use 'Identity' below
22:37:56 <edwardk> for 'Setter'
22:38:01 <edwardk> but it has the wrong semantics for a Getter =)
22:38:05 <latro`a> um
22:38:08 <latro`a> how are its semantics different
22:38:32 <latro`a> seems like Const a b has an a in it, Identity a has an a in it, neither of them have any other structure, no?
22:39:25 <edwardk> when you go to compose a Fold with a 'Getter' and the 'Getter' uses Identity, the types don't match
22:39:30 <hpaste> jimi_hendrix annotated “syntax error” with “syntax error (annotation) (annotation)” at http://hpaste.org/72322#a72325
22:39:43 <edwardk> if you made everything use Identity for Fold and Getter, then the types won't match when you go to line it up with Traversal
22:40:02 <jimi_hendrix> mm_freak, like the last annotation there?
22:40:08 <edwardk> you'll get a mishmash of behaviors.
22:40:12 <hpaste> “Ertugrul Söylemez” annotated “syntax error” with “Style suggestion” at http://hpaste.org/72322#a72326
22:40:34 <edwardk> when I first did this i just use (c -> r) -> a -> r  directly
22:40:36 <edwardk> for getter
22:41:02 <jimi_hendrix> i see
22:41:05 <edwardk> latro`a: the key thing is that the Functors do very different things for Const a and Identity
22:41:09 <mm_freak> jimi_hendrix: see my annotation
22:41:13 <latro`a> oh wait
22:41:18 <latro`a> Const a is the Functor
22:41:18 <applicative> jimi_hendrix: I put one in the middle there with more or less standard style
22:41:25 <latro`a> even though the value is an a
22:41:25 <edwardk> in the functor for Const fmap doesn't touch the value you pass through
22:41:27 <latro`a> ohh, right
22:41:29 <latro`a> yes
22:41:29 <latro`a> that
22:41:32 <latro`a> I forgot about that
22:41:37 <mm_freak> jimi_hendrix: this is how i do it
22:41:38 <latro`a> because the value that's in there is the first parameter
22:41:41 <latro`a> riiight, ok
22:41:42 <latro`a> nvm
22:42:02 <edwardk> so we can read from (c -> Const c d) -> a -> Const c b    by passing 'Const' as the function, and an a, and getConsting the answer
22:42:22 <edwardk> view l = getConst . l Const     reads from a lens
22:42:34 <mm_freak> jimi_hendrix: so far applicative's style is much easier to read, but the code can still be improved a lot
22:42:44 <ddarius> edwardk: Is there supposed to more in the Lens Families section?
22:42:45 <mm_freak> try factoring things out and don't nest too much
22:43:02 <mm_freak> if you're compelled to nest a lot you probably want to write a small helper function instead
22:43:14 <edwardk> it was intended to just be a link to my post on the topic, since i was already pretty longwinded for a package description ;)
22:43:39 <edwardk> my main goal was to motivate the combination of Lens, Fold, Getter, Setter, Traversal as generalizations of things you use all the time
22:43:41 <ddarius> edwardk: Okay, then maybe don't say "For a longer description" when no description has or will be provided.
22:43:46 <edwardk> just put in a form where they compose
22:43:51 <edwardk> fair nuff
22:44:01 <applicative> jimi_hendrix: what is the Scene type like ( I was just trying to figure it out)
22:45:16 <ddarius> edwardk: It might help to show an example of turning a function into a Getter in the first section.
22:45:29 <edwardk> yeah
22:45:30 <jimi_hendrix> applicative, data Scene = Scene { objects :: [Sphere], lights :: [Light] }
22:46:12 <edwardk> er and it should be a function a -> c
22:46:30 <ddarius> Yeah that was weird.
22:46:53 <mm_freak> btw, "Getter" and "Setter" are really awkward names…  they will make people write C++ in haskell without ever seeing the full power of lenses
22:46:54 <edwardk> the usual tool for it is 'to'
22:47:12 <applicative> ah. jimi_hendrix when you define newCol in the middle, the left fold doesn't have a list or seed? or am I missing it...
22:47:14 <edwardk> 'to fst' :: (a -> r) -> (a,b) -> r
22:47:21 <ddarius> edwardk: I think the final thing I'll say is that you should go through and evaluate all the uses of "so" and decide if they really need to be there.
22:47:35 <edwardk> so you think i should eh?
22:47:37 <edwardk> =)
22:47:54 <ddarius> edwardk: For example, I would remove both of the instances of "so" in the Fold section.
22:48:04 <jimi_hendrix> applicative, it should be "initialColor (lights scene)"
22:48:16 <edwardk> yeah
22:48:22 <applicative> oh wait I was wondering where they came from ...
22:48:22 <hpaste> jimi_hendrix annotated “syntax error” with “syntax error (annotation) (annotation) (annotation)” at http://hpaste.org/72322#a72327
22:48:29 <jimi_hendrix> mm_freak, how is that?
22:48:34 <edwardk> i confess i tend to go nuts with connectives
22:49:06 <ddarius> edwardk: It's possible that using a b a' b' or something like that may be slightly clearer for type variable names.
22:49:13 <jimi_hendrix> oh wait...the last 3 lines are one space out of alignment :/
22:49:24 <edwardk> not going to go change 4000 lines of code for that ;)
22:49:28 <tertl4> hi
22:49:46 <edwardk> and i prefer the shorter types i get from c and d
22:49:56 <mm_freak> jimi_hendrix: much better in any case
22:49:59 <mm_freak> tertl4: hi there
22:50:15 <edwardk> the variable names i chose here were so they lined up with all the examples in Control.Lens
22:50:22 <hpaste> jimi_hendrix annotated “syntax error” with “syntax error (annotation) (annotation) (annotation) (annotation)” at http://hpaste.org/72322#a72328
22:50:57 <hpaste> applicative annotated “syntax error” with “syntax error ” at http://hpaste.org/72322#a72329
22:51:16 <jimi_hendrix> mm_freak, that fixes that little bit out of alignment, but i still get a syntax error. parse error on newCoef in line 27
22:51:40 <latro`a> ....so much indentation
22:51:41 <latro`a> wtf
22:51:54 <applicative> jimi_hendrix: I moved the monster operation you were folding to another line in the sequence of lets
22:52:08 <edwardk> basically i wanted some kind of preamble to help hint to people where to look now that there are so many modules, and to help motivate why they should care about the library
22:54:20 <jimi_hendrix> applicative, i see. good idea
22:55:14 <ddarius> So I have a matrix expression parameterized by a point that's used for interpolation.  So I know what the values are at certain points, but the matrix expression is undefined at those points unless I regularize it.  This regularization appears to require a decent amount of work and is local to each point.
22:55:55 <edwardk> i figure i'll take that writeup and use it as the skeleton to hang a blog post on
22:56:19 <ddarius> Furthermore, I don't think it's necessary if I'm not actually on the point which would be the case I'd care about most seeing as it's an interpolation function, but I wouldn't want to have to worry about these undefined points.
22:58:18 <latro`a> isn't there a missing else now?
22:58:23 <latro`a> in #72329
23:00:15 <hpaste> jimi_hendrix annotated “syntax error” with “syntax error  (annotation)” at http://hpaste.org/72322#a72330
23:00:17 <applicative> latro`a: yes that's  where we started
23:00:59 <jimi_hendrix> well i still have a syntax error because the type line of my next function has a syntax error (possible incorrect indentation) and i know it does not
23:01:07 <edwardk> ddarius: afraid i'm probably not going to be much help =/
23:01:14 <latro`a> jimi_hendrix, that is usually a missing closed paren
23:01:22 <latro`a> which you have
23:01:26 <latro`a> in the raytrace line
23:01:38 <hpaste> solrize annotated “syntax error” with “syntax error  (annotation) (annotation)” at http://hpaste.org/72322#a72331
23:01:39 <latro`a> not sure where it should be, but you have 4 left and 3 right
23:01:49 <jimi_hendrix> latro`a, aha thanks
23:02:00 <solrize> i annotated to get rid of a bunch of nested lets though there are other errors i didn't see how to remove
23:02:47 <latro`a> there has gotta be some way to move most of those lets into a where
23:02:50 <jimi_hendrix> solrize, what other errors?
23:03:17 <latro`a> keep in mind that the where doesn't get evaluated anywhere near all the way if that branch doesn't return
23:03:27 <latro`a> erm, if that branch's condition isn't satisfied
23:03:30 <solrize> lr, lg, lb are undefined
23:03:53 <jimi_hendrix> solrize, yeah i just noticed that
23:03:55 <solrize> oh i thought there was still an if missing an else
23:04:25 <solrize> i messed it up
23:04:37 <solrize> what i was mostly showing in that paste is you can lift out most of the nested lets
23:04:47 <solrize> without triggering errors or doing extra computation
23:04:48 <ddarius> edwardk: It wasn't very coherent and I never got to an actual question.
23:04:51 <solrize> because it's lazy
23:05:06 <latro`a> you can do the same thing with a giant where
23:05:11 <latro`a> again, because it's lazy
23:05:47 <latro`a> like, I'd probably do (Just s,Just dist) -> functionInTheWhereBlock s dist
23:05:52 <latro`a> and then start the where block
23:06:17 <solrize> also it's kind of bad style to have a case on Just dist, with no case for Nothing
23:06:19 <jimi_hendrix> this is my second day of writing non-trivial haskell code so i am still getting used to things
23:06:29 <applicative> jimi_hendrix: it should be calcLighting c l = ...  I think
23:06:36 <solrize> why do you return a pair of Maybes instead of Maybe of a pair
23:06:52 <solrize> i.e. why (Maybe a, Maybe b)  instead of Maybe (a,b)  ?
23:06:56 <latro`a> given the matching pattern, Maybe pair would be better, agreed
23:07:04 <jimi_hendrix> applicative, oh yeah missed that.
23:07:06 <latro`a> if he were separately matching, like
23:07:11 <latro`a> (Nothing, _) and then (_, Nothing)
23:07:16 <latro`a> then this would be appropriate
23:07:19 <solrize> yeah
23:08:09 <latro`a> it is ofc possible that other calls to findNearestIntersection match like that, but it sounds like s is the point and dist is the distance from the input to that point
23:08:20 <latro`a> so you either have both or neither
23:08:24 <solrize> the total amount of nested if/else seems like an antipattern but i'm not sure what to do instead
23:08:44 <latro`a> there has to be a way to name some of these functions
23:08:48 <latro`a> eh, "functions"
23:08:50 <latro`a> and split them
23:08:59 <jimi_hendrix> solrize, because the function that returns that pair gets the pair from the result of a foldl', whose initial value is something like (Nothing, Just someNumber)
23:09:26 <latro`a> can't you then change it
23:09:28 <latro`a> after
23:09:35 <jimi_hendrix> latro`a, yeah, i will get nothing or both
23:09:49 <ReinH> I finished the first live coding video!
23:09:50 <latro`a> like
23:10:01 <latro`a> f (Nothing,Nothing) = Nothing
23:10:06 <latro`a> f (Just x,Just y) = Just (x,y)
23:10:18 <latro`a> just write that and do f $ inside findNearestIntersection
23:10:26 <jimi_hendrix> latro`a, that is a good idea
23:10:33 <latro`a> it's irrefutable, which is still not wonderful
23:10:35 <latro`a> but
23:10:37 <latro`a> that's not so bad
23:11:26 <latro`a> I guess since (Nothing,Just x) and (Just x,Nothing) are garbled
23:11:27 <latro`a> you could just do
23:11:31 <latro`a> f (Just x,Just y) = Just (x,y)
23:11:33 <latro`a> f _ = Nothing
23:12:03 <edwardk> f = liftA2 (,)
23:12:13 <latro`a> +1
23:12:15 <applicative> latro`a: why are you thinking it matters here?
23:12:20 <edwardk> f x y = (,) <$> x <*> y
23:12:23 <latro`a> that it's irrefutable?
23:12:27 <latro`a> or what
23:12:43 <solrize> any (\s -> Nothing /= intersect lightRay s)     could be    any (isJust . intersect lightRay)
23:12:53 <applicative> that its (Maybe a,Maybe b) not Maybe (a,b)
23:13:06 <latro`a> it's not a huge deal, but his matching style is the latter, not the former
23:13:26 <latro`a> since there is no case for only one failing
23:13:46 * hackagebot hTensor 0.8.1 - Multidimensional arrays and simple tensor computations. (AlbertoRuiz)
23:13:50 <solrize> :t isJust . intersect lightRay
23:13:52 <lambdabot> Not in scope: `lightRay'
23:14:12 <solrize> prob should have said    any (isJust . (intersect lightRay))
23:14:28 <latro`a> extra parens not needed
23:18:13 <jimi_hendrix> also, if i declare two types with record syntax and they have properties with the same names, there is a name clash error. what is the common way around that? create a typeclass or something?
23:19:41 <latro`a> there is
23:19:44 <latro`a> I forget the name
23:19:47 <latro`a> but there is an extension
23:19:55 <latro`a> that just lets you do that directly
23:21:53 <latro`a> internally it makes a typeclass though
23:23:47 <applicative> http://www.haskell.org/ghc/docs/7.0.1/html/users_guide/syntax-extns.html lists the cranky  record extensions
23:23:47 * hackagebot really-simple-xml-parser 0.3.0.0 - A really simple XML parser (KashyapChatamballi)
23:23:47 <jimi_hendrix> latro`a, -XDisambiguateRecordFields perhaps
23:24:00 <latro`a> that might've been it
23:24:21 <jimi_hendrix> i will do it manually
23:24:24 <jimi_hendrix> it will be a good exercise
23:24:34 <latro`a> it's pretty straightforward to do manually tbh
23:24:48 <jimi_hendrix> yeah
23:24:55 <jimi_hendrix> just a bit of extra typing
23:25:02 <jimi_hendrix> and i havent made my own typeclass yet :P
23:26:09 <Veinor> DisambiguateRecordFields doesn't create a typeclass
23:26:50 <Veinor> what it does instead is make it so that if you have multiple datatypes with a 'name' field, then greet (Person {name = pName}) = "Hello, " ++ name
23:26:52 <Veinor> will work
23:28:12 <latro`a> the extension I have in mind does something that is basically a typeclass, iirc
23:28:41 <Veinor> i don't think that exists
23:28:51 <latro`a> sure? I was sure I read that :/
23:28:59 <Veinor> i'm not positive
23:29:02 * ddarius should abuse TH and Haskell to make it's latent first-class module support viable.
23:29:15 <latro`a> if there isn't, it would be pretty easy using TH to write such a thing
23:29:21 <latro`a> I think
23:29:23 <ddarius> latro`a: You are probably thinking about one of the many, many proposals recently.
23:29:26 <Veinor> yeah
23:29:28 <latro`a> sounds likely
23:29:36 <Veinor> anyway
23:30:10 <Veinor> i'm trying to build a binary space partition tree generator in haskell, so i'm using Data.Tree and stacking RandT from Control.Monad.Random (which uses a StateT internally) on top of that
23:30:28 <ddarius> Veinor: Why not use an existing library?
23:30:33 <Veinor> does one exist?
23:30:57 <Veinor> the problem is, when i recursively generate the BSP tree, each child of a node gets the same RNG state, so they wind up looking homogenous.
23:31:21 <ddarius> There's a kdtree library, a useless sounding space partitioning library, and I think some other specific space partitioning data structure libraries.
23:31:25 <orzo> hey, i'm trying to find scalar-vector multiplication in the Data.Vec docs.  I don't really imagine they'd leave that out.  Anybody know?
23:32:33 <Veinor> orzo: it looks like Data.Vec.map will do what you want
23:32:38 <Veinor> just map scalar multiplication over the vector
23:32:47 <applicative> map (*3) myvector ?
23:32:52 <orzo> hm
23:32:54 <applicative> what Veinor said
23:32:54 <jimi_hendrix> i assume i am still not allowed to use the name for the getter function that i am resolving via the typeclass method in the record syntax definition for the type then?
23:32:59 <orzo> okay
23:33:56 <orzo> i'm a little surprised they didn't make an operator or name a function for it
23:34:00 <Veinor> ddarius: kdtree doesn't help with the problem of randomly generating the tree
23:34:09 <Veinor> @pl \vec n -> map (*n) vec
23:34:10 <lambdabot> flip (map . (*))
23:34:16 <Veinor> @pl \n vec -> map (*n) vec
23:34:17 <lambdabot> map . (*)
23:34:20 <ddarius> jimi_hendrix: You can if you put them in different modules.
23:34:57 <jimi_hendrix> grr
23:36:07 <Veinor> ddarius: (the context is generating a map for a roguelike)
23:36:59 <ddarius> Veinor: Why are you using Data.Tree?
23:37:03 <jimi_hendrix> i am a little surprised that this name conflict issue is a thing. i mean, if you are going to do syntax sugar, add this to the sugar?
23:37:15 <jimi_hendrix> Veinor, bsp maps are cool
23:38:20 <Veinor> ddarius: because it seemed like a natural fit? i'm using http://doryen.eptalys.net/articles/bsp-dungeon-generation/
23:39:04 <ddarius> Veinor: Wouldn't a binary tree be more natural?
23:39:22 <Veinor> well, yeah
23:39:38 <Veinor> but i don't really gain anything from that, and Data.Tree was already there
23:41:05 <ddarius> Veinor: I would think you would gain a lot of clarity and Data.Tree is mostly useless.
23:41:57 <Veinor> so, write my own datatype data BSPTree = Split [BSPTree] | BSPNode Bounds ?
23:42:44 <ddarius> That's not a binary tree.
23:42:54 <Veinor> er, yeah
23:43:07 <Veinor> data BSPTree = Split BSPTree BSPTree | BSPNode Bounds
23:43:44 <ddarius> data BspTree a = Split !Axis !Double BspTree BspTree | Node a
23:43:54 <Veinor> actually, parameterize over Bounds, yeah
23:44:17 <Veinor> i think the strictness is unnecessary here though
23:44:49 <ddarius> You probably aren't making big enough maps to care, but I think laziness in the attribute fields is even less necessary.
23:46:16 <Veinor> eh, the final representation is going to wind up being a 2d vector anyway, since i'm eventually going to add generators other than BSP
23:48:47 * hackagebot hmatrix 0.14.1.0 - Linear algebra and numerical computation (AlbertoRuiz)
23:48:53 <Veinor> but yeah, i think writing BspTree a and defining a couple useful instances (Traversable and Functor, I think)
23:48:59 <Veinor> will definitely wind up better
23:49:27 <ddarius> Incidentally, data BspF x = Split !Axis !Double x x, type BspTree = Free BspF.  Now you have Functor, Applicative, and Monad for your type.
23:50:12 <edwardk> or you can just make it a monad manually
23:50:20 <edwardk> so as not to have all the newtype noise
23:50:25 <ddarius> But then it isn't Free!
23:50:36 <Veinor> see, i'd do that, but i have no clue how Free works... and you know what they say about writing code as clever as you can
23:50:58 * mikeplus64 paints blue on his face
23:51:01 <mikeplus64> freeeeedommm!
23:51:33 <edwardk> Veinor: instance Monad BspTree where return = Node; Split axis d l r >>= f = Split axis d (l >>= f) (r >>= f)
23:51:45 <ddarius> Veinor: You can derive the definition of Free just by comparing the two definitions of BspTree.  You can easily figure out the definitions of the monad operations by following the types.
23:52:02 <edwardk> Veinor: with instance Functor BspTree where fmap = liftM -- you can then use >>= to insert more leaves
23:52:38 <edwardk> and when you define the Traversable instance you can use folds over the nodes
23:53:16 <Veinor> i'm still not sure what this gains me over just using Data.Tree
23:53:28 <shachaf> Do people actually use Free that way in practice?
23:53:43 <shachaf> I've always seen things like "yes, this is a free monad, but we're defining it here explicitly anyway".
23:53:49 * hackagebot hmatrix-tests 0.3 - Tests for hmatrix (AlbertoRuiz)
23:54:13 <Veinor> well, it does get me correctness guarantees
23:54:27 <ddarius> And efficiency, and Monad instances.
23:54:33 <Veinor> Data.Tree has a Monad instance.
23:55:26 <ddarius> Ah yes, it was the MonadPlus that couldn't be defined because there aren't empty trees.
23:57:28 <edwardk> shachaf: there are benefits to using the variants of 'Free' (apfelmus's operational type or my church encoded Free), so once you spot that something is free, that opens you up to optimization opportunities that aren't obvious
23:57:57 <edwardk> Veinor: do you use the multiple children support?
23:58:17 <Veinor> nope
23:58:21 <edwardk> e.g. for your structure, is having 3 children well defined?
23:58:28 <edwardk> thats what it buys you over Tree ;)
23:58:34 <edwardk> because its correct ;)
23:58:34 <Veinor> haha
23:58:45 <Veinor> i mean it's not ill-defined it's just not going to happen in my model
23:58:51 <edwardk> i can pass around tuples in my code using [a,b] too!
23:58:55 <Veinor> haha
23:59:34 <Veinor> yeah, i think i'm just going to wind up defining my own tree
23:59:45 <edwardk> its 15 lines of code, and its worth it
23:59:59 <ddarius> It's usually better in every way.  It's extremely easy to define new tree types in Haskell.
