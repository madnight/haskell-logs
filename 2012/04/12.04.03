00:07:14 <osa1> hmm I happened to make ping threads working, but now I can't handle exceptions throwed when trying to write closed sockets..
00:21:02 <db81> Is there a function to wait for an IO action to complete for a set amount of time and terminate it if it times out?
00:21:40 <shachaf> @hoogle timeout
00:21:40 <lambdabot> System.Timeout module System.Timeout
00:21:40 <lambdabot> System.Timeout timeout :: Int -> IO a -> IO (Maybe a)
00:21:40 <lambdabot> System.Event type TimeoutCallback = IO ()
00:22:41 <db81> thank you
00:23:09 * hackagebot hakyll 3.2.7.1 - A static website compiler library  http://hackage.haskell.org/package/hakyll-3.2.7.1 (JasperVanDerJeugt)
00:48:09 * hackagebot hyakko 0.3.0 - Literate-style Documentation Generator  http://hackage.haskell.org/package/hyakko-0.3.0 (JeremyHull)
01:04:24 <osager> hi all why when i type singleton 1 "foo" i get fromList
01:04:39 <osager> where is there always fromList ?
01:05:32 <danr> osager: that is how Sets and Maps are printed, in terms of their fromList
01:05:54 <danr> you can also view them with showtree
01:05:56 <danr> @hoogle showtree
01:05:56 <lambdabot> Data.IntSet showTree :: IntSet -> String
01:05:56 <lambdabot> Data.Map showTree :: (Show k, Show a) => Map k a -> String
01:05:56 <lambdabot> Data.IntMap showTree :: Show a => IntMap a -> String
01:06:15 <osager> @hoogle fromList
01:06:16 <lambdabot> Data.HashTable fromList :: Eq key => (key -> Int32) -> [(key, val)] -> IO (HashTable key val)
01:06:16 <lambdabot> Data.IntMap fromList :: [(Key, a)] -> IntMap a
01:06:16 <lambdabot> Data.IntSet fromList :: [Int] -> IntSet
01:06:21 <osager> wow this is cool
01:06:35 <danr> @where hoogle
01:06:35 <lambdabot> http://haskell.org/hoogle
01:06:42 <danr> you can also use that webpage :)
01:07:01 <osager> so you mean fromList is called when i call singleton ?
01:07:08 <osager> i read the source code
01:07:15 <osager> it didnt call fromList
01:07:20 <osager> is it a ghci thing ?
01:07:30 <danr> osager: no, it is called when the Map is show-n
01:07:46 <danr> osager: yes in a way, ghci will print values with their show-function
01:08:28 <osager> danr, but you do agree that singleton doesn't call fromList
01:08:46 <osager> it's just that when showing it , fromList is automatically called
01:09:22 <danr> osager: yes indeed. singleton does not call it (see source http://hackage.haskell.org/packages/archive/containers/latest/doc/html/src/Data-Map.html#singleton)
01:09:30 <osager> ok
01:09:33 <danr> it just constructs a singleton map
01:09:35 <osager> one more question
01:09:46 <osager> in singleton source code, i see Bin
01:09:50 <osager> a lot of Bin
01:09:53 <osager> what is it ?
01:10:22 <osager> ok sorry, iget it
01:10:31 <danr> osager: It's part of the implementation, it's a constructor for Map
01:10:32 <osager> it's not a haskell reserved name
01:10:42 <osager> just some name
01:10:47 <osager> thanks danr
01:10:49 <danr> nope, the constructors are defined a bit further up in the file ( see http://hackage.haskell.org/packages/archive/containers/latest/doc/html/src/Data-Map.html#Map )
01:11:10 <danr> osager: you're welcome
01:11:23 <koala_man> osager: also see the instance for Show in that same source file, to see why it shows fromList
01:11:35 <danr> koala_man: good point
01:11:41 <osager> ok
01:12:36 <koala_man> it just prepends "fromList" to the list of items so that you can copy-paste the output and have it evaluate to the same map
01:13:09 <osager> thank you, now i see that part of code
01:14:37 <t7>  has anyone ever seen a C-like language with parametric polymorphism and type classes?
01:14:55 <t7> like C with forall over functions and structs
01:17:28 <Ptival> type classes would be complicated
01:21:31 <zhulikas> @hoogle [a] -> a -> [a]
01:21:32 <lambdabot> Data.List intersperse :: a -> [a] -> [a]
01:21:32 <lambdabot> Data.List insertBy :: (a -> a -> Ordering) -> a -> [a] -> [a]
01:21:32 <lambdabot> Data.List deleteBy :: (a -> a -> Bool) -> a -> [a] -> [a]
01:21:51 <zhulikas> > intersperse "a" ["asd","dsa"]
01:21:52 <lambdabot>   ["asd","a","dsa"]
01:25:48 <cheater> > intercalate "-" ["hi", "there"]
01:25:49 <lambdabot>   "hi-there"
01:27:37 <earthy> t7: you might want to look into BitC
01:28:04 <t7> earthy: didnt that die a few years ago?
01:29:11 <earthy> well, yeah. but it's the only one I've heard of. :)
01:29:22 <jfischoff> poor bitc
01:29:32 <earthy> plus, the docs are still available
01:29:45 <jfischoff> I really feel for those guys
01:29:55 <earthy> (and, to be honest, people can still learn things from Algol 68, and that's not been a going concern for decades ;))
01:30:35 <t7> then we could add sum types to c
01:30:40 <t7> then currying
01:30:44 <t7> and lazy evaluation
01:30:49 <t7> get rid of the parens
01:30:55 <t7> call it haskell
01:30:57 <jfischoff> are unions not sum types?
01:31:06 <earthy> jfischoff: they are
01:31:07 <t7> yeah but there not tagged
01:31:13 <earthy> they're just not discriminated by default
01:31:28 <jfischoff> t7: true, I just add an enum
01:31:38 <earthy> (some 2 decades ago I wrote a data type preprocessor that gave me adt's in C)
01:31:56 <jfischoff> ha, I did the same thing
01:32:07 <earthy> very simple, very powerful
01:32:17 <joshuatly> hello #haskell!
01:32:27 <jfischoff> yep, trying to cabalize my code as we speak
01:32:53 <joshuatly> hey im new to haskel, got some question to ask. what does the symbol ' means when added to something like if' ?
01:33:24 <t7> its just another identifier
01:33:29 <jfischoff> joshuatly: its a naming convention
01:33:33 <danbst> joshuatly: it's just a symbol
01:33:44 <danbst> like any other letter
01:34:04 <joshuatly> can haskell do nested if else?
01:34:18 <Ptival> why wouldn't it?
01:34:45 <joshuatly> hmm... means something wrong with my code :D
01:34:59 <t7> > if if True then False else True then 1 else 2
01:34:59 <Ptival> @where hpaste
01:35:00 <lambdabot> http://hpaste.org/
01:35:00 <lambdabot>   2
01:35:08 <jfischoff> joshuatly: probably identation
01:35:17 <geekosaur> possibly the real question is whether they nest "nicely"... "else if" + layout probably doesn;t do what you would like
01:35:32 <geekosaur> especially inside a do/let
01:35:55 <t7> joshuatly: if you have alot of ifs you can use a case with gaurds
01:35:58 <t7> looks a bit nicer
01:36:01 <joshuatly> ok
01:36:09 <joshuatly> let me try
01:36:14 <geekosaur> that's my solution as well
01:36:17 * quicksilver doesn't see how "else if" is any worse than a plain if; it doesn't require any *extra* indentation.
01:36:22 <danr> in monadic code, unless and when look pretty nice (but not really when nesting)
01:36:49 <danbst> Guys, I'm looking for function "onlyWhen". Is it somewhere? Here is how I define it and use http://hpaste.org/66378
01:36:56 <t7> omg you dont get points for upvoted comment on stackoverflow :|
01:37:23 <t7> impossible type danbst
01:37:29 <Ptival> omg my life is devoid of meaning because of that
01:37:31 <geekosaur> quicksilver, what I've seen is that "then" and "else" must be indented beyond "if" inside of "do"/"let", and that means chained if/then/else does generally require extra indentation
01:37:50 <t7> id a :: a
01:37:51 <osa1> does anyone here know a websocket server written in haskell? I'm having trouble catching disconnections
01:37:54 <quicksilver> geekosaur: yes, "then" and "else" must be indented slightly more because htey're part of the same expression.
01:38:01 <quicksilver> geekosaur: however it doesn't get any worse.
01:38:02 <danr> danbst: yeah, your type is too general, but curiously, me and quicksilver where discussing this function yesterday, but with arguments flipped and named (?)
01:38:02 <joshuatly> when winhugs giving me Syntax error in expression (unexpected `<-') what does it mean?
01:38:03 <t7> :: type of a *
01:38:11 * hackagebot digestive-functors 0.3.0.1 - A practical formlet library  http://hackage.haskell.org/package/digestive-functors-0.3.0.1 (JasperVanDerJeugt)
01:38:13 * hackagebot digestive-functors-blaze 0.3.0.1 - Blaze frontend for the digestive-functors library  http://hackage.haskell.org/package/digestive-functors-blaze-0.3.0.1 (JasperVanDerJeugt)
01:38:23 <quicksilver> geekosaur: "else if" doesn't require any *more* indentation - it's still the same expression.
01:38:32 <danr> danbst: (from yesterday: http://hpaste.org/66356 )
01:38:58 <danbst> danr: oh thanks
01:39:06 <geekosaur> joshuatly, <- only works in "do"
01:39:13 <Ptival> you can't "change the type only if" :d
01:39:16 <joshuatly> Oh.
01:39:17 <danr> danbst: let me know if you find this combinator in some library
01:39:37 <geekosaur> as for that onlyWhen, note that "id" only works for a ~ b
01:39:40 <danbst> danr: i'll try =)
01:41:16 <geekosaur> there are monadic versions of it which rely on m () or mzero being acceptable; similarly you could do a Monoid-based one with mempty as the False leg
01:42:07 <joshuatly> which means i need to use getLine if I dont use do right?
01:42:51 <geekosaur> joshuatly, what are you really trying to do?
01:43:11 * hackagebot digestive-functors-heist 0.3.0.0 - Heist frontend for the digestive-functors library  http://hackage.haskell.org/package/digestive-functors-heist-0.3.0.0 (JasperVanDerJeugt)
01:43:51 <quicksilver> geekosaur: indeed 'id' is the mempty of one particular Monoid...
01:44:12 <geekosaur> joshuatly, I do not see what getLine has to do with using/not using do notation; except insofar as it is in IO and therefore do notation can be easier for working with it (but is not essential)
01:44:33 <joshuatly> hold on, i hpaste it, its my first code, so it will look terrible
01:44:44 <hpaste> joshuatly pasted “login” at http://hpaste.org/66379
01:45:13 <joshuatly> many mistakes there... try to figure out one by one
01:45:23 <quicksilver> you need another "do" inside the "then", joshuatly
01:45:34 <joshuatly> oh let me try
01:45:56 <quicksilver> and your else will need to be indented another couple of spaces.
01:46:10 <quicksilver> I recommend not using tabs in haskell, personally.
01:48:02 <joshuatly> what does this error mean: Syntax error in expression (unexpected `;', possibly due to bad layout)
01:48:10 <joshuatly> i got no ; in my code
01:49:09 <quicksilver> joshuatly: it is because of my second comment.
01:49:17 <quicksilver> "your else will need to be indented another couple of spaces"
01:49:22 <quicksilver> the ; is how layout works
01:49:45 <quicksilver> it inserts ; after each line which is the same indentation, loosely
01:50:11 <sabrehagen> hey guys :) i want to aviod recursion and use higher order functions to apply a function to all elements in a list. however, i want to apply the function to all elements with it's first parameter being the first element in the list and the second being the rest of the list, then the first parameter being the second element and the second being the rest of the list, and so on for the entire list. how would i do this?
01:50:24 <joshuatly> Oh... i think i got it quicksilver
01:50:31 <quicksilver> joshuatly: http://en.wikibooks.org/wiki/Haskell/Indentation#do_within_if
01:50:59 <jfischoff> why does haskell only allow sum types at the top level? Is a generic sum type problematic for type inference? Or is it just not interesting.
01:51:04 <joshuatly> thanks :D I think i got my login working. so happy :D
01:51:19 <quicksilver> jfischoff: "top level" ?
01:51:30 <jfischoff> only with constructors
01:51:38 <mandaya> sabrehagen: does map not do what you want?
01:51:51 <jfischoff> there is not sum type equivalent of a tuple
01:52:01 <quicksilver> jfischoff: yes there is, "Either"
01:52:12 <jfischoff> which is what I am say
01:52:14 <jfischoff> ing
01:52:19 <earthy> sabrehagen:  applyForSabre [] f z = z; applyForSabre (x:xs) f z = applyForSabre xs f (f x xs)
01:52:21 <quicksilver> jfischoff: and what are you saying?
01:52:23 <sabrehagen> mandaya, i believe map is what i want, but it maps a function to all elements, i want to map that function to all elements, but do it N times, with each element in the list being passed in one time
01:52:35 <quicksilver> earthy: that does not avoid recursion.
01:52:46 <quicksilver> sabrehagen: take a look at "zip xs (tails xs)"
01:52:52 <mandaya> sabrehagen: you want one of the fold varients then
01:52:53 <earthy> oh, right. :)
01:52:54 <quicksilver> although it is not quite what you wanted.
01:53:03 <jfischoff> look at the template haskell Type. There is a TupleT there, you can make a generic product type. But there is no SumT
01:53:07 <quicksilver> it is fairly close, perhaps you can see how to fix it.
01:53:08 <earthy> fold, or scan, or somesuch. :)
01:53:13 <mandaya> sabrehagen: try foldr and see if it works for you
01:53:19 <sabrehagen> quicksilver, okay, i'll look into that
01:53:28 <sabrehagen> mandaya, i'll look at foldr too
01:53:32 <mandaya> :t foldr
01:53:33 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
01:53:50 <sabrehagen> thanks guys :) i'll be back soon with more clarifications soon i'm sure!
01:54:19 <quicksilver> jfischoff: it's not really significant or deep
01:54:43 <quicksilver> jfischoff: it just happens there are an infinite family of tuple types and TupleT exists as a convenient way to construct them.
01:54:45 <roconnor> lambdabot: @time dibblego
01:54:46 <lambdabot> Local time for dibblego is Tue Apr  3 18:54:24
01:54:58 <roconnor> dibblego: I'm in Paris now.
01:55:00 <quicksilver> "Either" is a perfectly reasonable generic sum.
01:55:14 <sabrehagen> mandaya, okay, can we start with that function definition? i'm still trying to get my head around them. what is the part (a -> b -> b) saying? (i've only been doing haskell a little over a week)
01:55:25 <mux> roconnor: are there any conferences right now in Paris?
01:55:36 <roconnor> mux: not that I'm aware of
01:55:45 <mux> roconnor: ok, I live here so I thought I'd ask :-)
01:55:55 <jfischoff> quicksliver: no way. Either is annoying to work with when you have many options
01:55:56 <roconnor> yay, a Haskeller!
01:56:10 <jfischoff> tuples are way easier
01:56:22 <mux> tuples are not sum but product types, that made no sense
01:56:44 <jfischoff> mux: I know. What I am saying is I want a sum type
01:56:46 <mandaya> sabrehagen: how much experience you do you have with functional languages?
01:56:46 <jfischoff> like a tuple
01:56:51 <mandaya> is haskell your first?
01:57:05 <sabrehagen> mandaya, yep
01:57:13 <jfischoff> in the sense that I don't want to have to write isomorphisms between binary trees and general trees all the time
01:57:26 <sabrehagen> mandaya, but i have done functional mathematics before
01:57:31 <mandaya> sabrehagen: ok
01:57:33 <jfischoff> which is what using a Either for multiple options means you have to do
01:58:16 <mandaya> sabrehagen: ok
01:58:21 <quicksilver> jfischoff: what you're saying is you want a generic syntax for writing n-ary sums?
01:58:31 <sabrehagen> mandaya, i understand it's saying things like 'take a and b and return b' (i think) but i don't understand why it's in brackets
01:58:33 <mandaya> sabrehagen: foldr and foldr are two of the basic operations of functional programming
01:58:49 <jfischoff> exactly, and I am wondering if there is reason why we don't have one
01:58:54 <mandaya> sabrehagen: the brackets mean lists
01:58:54 <quicksilver> jfischoff: no reason.
01:59:09 <quicksilver> jfischoff: I could never have understood that from your initial choice of words "why does haskell only allow sum types at the top level" though!
01:59:12 <t7> are type classes OOP?
01:59:23 <quicksilver> t7: no, absolutely not.
01:59:35 <jfischoff> yeah, my bad :)
01:59:36 <mandaya> sabrehagen: so they take functions of two arguments: the "sum" type and the list type
01:59:49 <mandaya> an initial value of the list type
02:00:00 <mandaya> and a list
02:00:02 <quicksilver> jfischoff: I've occasionally wanted them although the problem you're talking about (isomorphisms to n-ary sums) is basically solved by the new generics stuff.
02:00:07 <sabrehagen> okay let me review that...
02:00:09 <sabrehagen> :t foldr
02:00:09 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
02:00:35 <mandaya> sabrehagen: no problem.
02:00:35 <mandaya> :t foldl
02:00:36 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
02:00:42 <quicksilver> jfischoff: I have suggested the syntax (Int|Bool|Char) for an anonymous sum in the past.
02:00:48 <sabrehagen> mandaya, i'm not following you when you say the sum type and the list type
02:01:04 <mandaya> sabrehagen: in the case of the type signatures
02:01:16 <mandaya> sabrehagen: for foldr, b is the sum type
02:01:18 <sabrehagen> mandaya, to take the stress off you, i might go away and read an article about foldr and come back to you
02:01:32 <mandaya> sabrehagen: no stress :)
02:02:03 <mandaya> sabrehagen: try and figure out what the following does
02:02:09 <sabrehagen> mandaya, okay, well, i'm really not following what you mean by b is the sum type. also, you just did :t foldl. what's the difference between foldr and foldl
02:02:15 <sabrehagen> mandaya, fire away
02:02:34 <quicksilver> jfischoff: then you'd write "case x of (a||) -> "Int :" ++ show a; (|b|) -> "Bool : " ++ show b; ....
02:02:49 <mandaya> sabrehagen: foldr (+) 0 ls
02:03:02 <mandaya> sabrehagen: foldr and foldl are very similar functions
02:03:20 <jfischoff> quicksliver: I like that syntax. But now you have brought up another thorn in my side. The new generics stuff is good, but requires, atleast if you copy the aeson way, so much type level programming. It is very difficult to debug.
02:03:21 <mandaya> sabrehagen: don't worry about the difference quite yet
02:03:30 <mandaya> sabrehagen: just notice that they're very similar
02:03:48 <sabrehagen> mandaya, i can see that. i'd be interested in figuring out that code...
02:04:44 <mandaya> sabrehagen: yep, I think there's a wikipedia article that covers that :P
02:05:13 <sabrehagen> mandaya, alright, i'll do some reading and get back to you, thanks for the push in the right direction :)
02:05:25 <quicksilver> jfischoff: well I think the idea is that you only have to do it once.
02:05:27 <mandaya> sabrehagen: no problem
02:05:43 <quicksilver> jfischoff: I mean the generic part of your code is a small part, and you get it working and then move on
02:05:48 <mandaya> sabrehagen: don't be afraid to ask questions if you get stuck. you're very close.
02:05:53 <quicksilver> jfischoff: but, yes, new features tend to lack reasonable debugging support :-/
02:06:11 <sabrehagen> mandaya, alright, will do! cheers :)
02:06:37 <jfischoff> quicksliver: once you get it work, its great, and for simple stuff its easy. But the difference between a 15 minute job and 2 day one, is very subtle
02:07:01 <mandaya> sabrehagen: also, no guarantees I can successfully relate the answer. I started drinking about two hours ago.
02:07:08 <jfischoff> I am struggling with it write now, if you are familar, I'll hpaste it
02:07:20 <mandaya> sabrehagen: I'm very happy we got this far in this discussion :P
02:07:54 <sabrehagen> mandaya, you're quite coherent at the moment. just don't go over 0.01337 BAC okay? :P
02:07:57 <quicksilver> jfischoff: unfortunately I'm only familiar in theory, I'm not sure I'd be much use in practice. Keep meaning to have a proper play.
02:08:11 * hackagebot process-extras 0.1.0 - Process extras  http://hackage.haskell.org/package/process-extras-0.1.0 (DavidLazar)
02:08:32 <mandaya> sabrehagen: you mean 0.1337, right? :D
02:08:41 <jfischoff> here is my advice, make sure you understand how this works first. http://www.haskell.org/haskellwiki/GHC/AdvancedOverlap . I am finding it essential
02:08:45 <sabrehagen> mandaya, i think you may be dead at that level!
02:08:58 <gregATio> ll
02:09:00 <jfischoff> then read the aeson code
02:09:01 <sabrehagen> mandaya, 0.01337 for coherence :P
02:09:13 <mandaya> nah, the legal limit is what, 0.08?
02:09:37 <mandaya> 0.1337 is well within survivable, if not rememberable
02:09:45 <gregATio> hey , i just screwed up my ghc installation, keeps saying that it cant find Text.Regex.Posix, and cabal keeps installing to ~/.ghc
02:09:52 <gregATio> does anyone know how to fix
02:19:29 <t7> rm -rf /
02:20:08 <db81> gregATio: try disabling user-install
02:20:38 <egomes> Hi guys! is it possible to use "cabal build" with "--flags" options?
02:21:09 <gregATio> ah is that in the cabal config
02:21:13 <gregATio> thanks db81
02:22:54 <jabirali> t7: I actually tried that once, since I was gonna reinstall anyway. Apparently you stop deleting stuff when /lib is gone.
02:23:16 <t7> i did it once when i was new and using ubuntu
02:23:36 <t7> i cant remember what i meant to delete
02:25:29 <merijn> jabirali: Depends
02:25:42 <egomes> gregATio: Do you know which tag in the cabal config?
02:25:54 <merijn> jabirali: If your basic tools are statically linked I think you can go much further
02:30:18 <jabirali> merijn: Do you know if any files are actually required to keep the system running? If you have a statically linked `rm', can you actually clear everything before stopping?
02:30:40 <merijn> You might be able to, I think
02:30:43 <shachaf> Why would it have to do with static linking?
02:30:56 <shachaf> Unlinking a file doesn't do anything if it's opened.
02:31:06 <shachaf> (Well, other than unlink it. But the file is still around.)
02:31:48 <merijn> shachaf: Nothing, I would say. But it's the first semi coherent things I can think off for someone claiming it stops at /lib. Alternately, the people saying that it stopped are /lib (which I admit considered a more likely explanation, but when I call people wrong on a hunch I get yelled at for being rude :p)
02:37:52 <jabirali> I remember the system freezing, and when I tried mounting the partition later, I remember e.g. /usr still being around. I believe the folder /lib still was around, but it's 8 years since I tried it, so my memory might be getting blurry :P
02:40:06 <mandaya> sabrehagen: any luck?
02:48:52 <Geralt> Hi, I have a haskell program which I cannot compile because the haskell98 package is hidden by default. The problematic import is "import IO", is there an easy way to fix that program?
02:49:46 <Geralt> oh, I'm talking about compiling with GHC
02:51:27 <quicksilver> well you can use haskell98
02:51:36 <quicksilver> or you can "fix" the code to use more modern imports
02:51:40 <quicksilver> import System.IO
02:53:16 <Saizan> Geralt: to use the haskell98 package you can ghc-pkg expose it or pass -package haskell98 to GHC when compiling
02:53:38 <Geralt> quicksilver: Saizan: thanks, replacing import IO with System.IO fixed it :)
02:54:02 <quicksilver> Saizan: isn't it supposed to be sufficient to add {-# LANGUAGE haskell98 #-} to the top?
02:54:31 <quicksilver> or -Xhaskell98
02:54:32 <Saizan> quicksilver: ah, it might
02:56:15 <Saizan> not in ghci-7.2.1 though
02:59:26 <quicksilver> Saizan: -Xhaskell98 doesn't appear to be documented :-(
03:02:05 <statusfailed> I want to make a very simple CPU model, but i'm not sure how to store the "RAM"
03:02:32 <statusfailed> What's the best functional data structure to use? is it IntMap?
03:04:06 <Peaker> statusfailed: you might want to use a mutable array?
03:04:43 <statusfailed> Peaker: as in MArray?
03:13:51 <Cale> statusfailed: depends on how fast you want it to run
03:13:51 <preflex>  Cale: you have 1 new message. '/msg preflex messages' to read it.
03:14:05 <Cale> @bot
03:14:05 <lambdabot> :)
03:18:16 * hackagebot wai-extra 1.2.0.1 - Provides some basic WAI handlers and middleware.  http://hackage.haskell.org/package/wai-extra-1.2.0.1 (MichaelSnoyman)
03:18:18 * hackagebot http-enumerator 0.7.3.2 - HTTP client package with enumerator interface and HTTPS support.  http://hackage.haskell.org/package/http-enumerator-0.7.3.2 (MichaelSnoyman)
03:21:09 <t7> Compute φ(n) = (p – 1)(q – 1), where φ is Euler's totient function.
03:21:24 <t7> how the hell do i do that
03:22:28 <t7> im defining a funtion?
03:22:57 <Elemir> Heh
03:23:21 <sipa> In number theory, Euler's totient or phi function, φ(n) is an arithmetic function that counts the number of positive integers less than or equal to n that are relatively prime to n.
03:23:25 <Elemir> You trying to find easy hack of RSA?
03:23:26 <sipa>  -- wikipedia
03:23:29 <t7>  is this on hackage?
03:23:59 <statusfailed> Cale: What's the fastest option? :)
03:23:59 <sipa> t7: the point is that since you know you are working with a number n with two prime factors, φ(n) = (p – 1)(q – 1)
03:24:06 <t7> Elemir: maybe :3
03:24:39 <sipa> t7: so forget about it being a totient function, and just compure (p-1)*(q-1)
03:25:23 <t7> ah
03:25:39 <t7> they could have made that clearer
03:28:17 * hackagebot mime-mail-ses 0.2.0 - Send mime-mail messages via Amazon SES  http://hackage.haskell.org/package/mime-mail-ses-0.2.0 (MichaelSnoyman)
03:33:18 * hackagebot wai-handler-webkit 1.2.0 - Turn WAI applications into standalone GUIs using QtWebkit.  http://hackage.haskell.org/package/wai-handler-webkit-1.2.0 (MichaelSnoyman)
03:34:40 <Cale> statusfailed: Using mutable arrays or references.
03:35:10 <Cale> statusfailed: But using an IntMap or something else which is pure is much nicer for testing and debugging
03:36:43 <t7> what does (a, b) mean in number theory
03:36:49 <t7> how can (a, b) = 1 ?
03:37:23 <t7> oh its just notation for gcd (a, b) = 1
03:42:34 <t7> @pl \e -> gcd e tn == 1
03:42:34 <lambdabot> (1 ==) . flip gcd tn
03:55:07 <jonkri> thanks for your messages yesterday, Philonous
03:55:15 <jonkri> :)
03:55:57 <Philonous> jonkri:  snoyman has pushed a fix for the xml-conduit problem, I'll try it out later
03:56:48 <Philonous> jonkri:  snoyberg* Oops
03:58:25 <t7> d is the multiplicative inverse of e mod φ(n).    but  1 < e < φ(n)..... e mod φ(n) is allways going to be e ... ?
03:58:37 <t7> or am i missing parens
04:06:06 <int-e> t7: d is the multiplicative inverse of e, in arithmetic modulo phi(n).
04:06:28 <int-e> t7: is what it means, that is, d*e = 1 (mod phi(n)).
04:06:38 <merijn> Since we're talking number theory and RSA...
04:08:07 <merijn> Can anyone explain to me why, given p is prime forall a. a in Z mod p "a^(p-1) == 1" (or was it a^p? I forget...)
04:08:38 <merijn> That part of RSA has always remained voodoo to me
04:09:12 <int-e> Little Fermat. a^p = a (mod p), and a^(p-1) = 1 (mod p) if a != 0 (mod p).
04:10:39 <merijn> int-e: Is it just that a^(p-1) = 1 follows from a^p = a (mod p)?
04:11:07 <int-e> sure, by division by a.
04:11:23 <merijn> No, wait. That doesn't help me, because why does "a^p = a (mod p)" hold?
04:11:32 <int-e> ... that is, multiplication by the inverse of a, which exists if a and p are coprime.
04:13:02 <int-e> There are many proofs for this fact. one that I like counts necklaces of p beads with a colors: There are a^p ways to arrange such beads on a string in a row. When you connect the two ends, you produce a necklace. Two necklaces are equivalent if you can obtain one from the other by rotation. Now every necklace is equivalent to p different strings, except when the beads are all of the same color. Therefore, p divides a^p-a.
04:14:00 <int-e> the last "is equivalent" should be replaced by "can be obtained from".
04:14:06 <merijn> Wait, I think I may have it
04:14:56 <merijn> The only way to end up with a*b = 0 (mod p) is if either a or b is not prime relative to p, right?
04:15:08 <t7> why does modulo only take 1 arguement :S
04:15:26 <merijn> (Does coprime mean the same thing as "relatively prime?)
04:15:28 <sipa> t7: it's mathematical notation, not a function
04:15:33 <sipa> merijn: yes, afaik
04:15:46 <sipa> a and b are coprime if their gcd is 1
04:15:56 <merijn> t7: Math notation has mod as infix
04:15:57 <sipa> iff, even
04:16:12 <merijn> Ok, so a*b = 0 mod p only happens if either a or b is coprime with p
04:16:16 <merijn> Eh
04:16:18 <albel727> merijn: http://en.wikipedia.org/wiki/Fermat's_little_theorem
04:16:25 <merijn> Both are *not* coprime with p
04:16:43 <sipa> no, when either is a multiple of p
04:16:51 <int-e> t7: a = b (mod c) means that c divides (a-b).
04:18:01 <merijn> sipa: Ok, lemme rephrase correctly a*b != 0 (mod p) if both are coprime with p (since multiplying two p coprimes results in a new p coprime)
04:18:28 <sipa> merijn: indeed
04:18:31 <ivanm> is there a function like unfoldr that only applies the function a specified number of times, and returns the final  ::b value ?
04:18:34 <int-e> t7: http://en.wikipedia.org/wiki/Modular_arithmetic explains that and lists a lot of properties that justify this equation-like notation.
04:18:53 <roconnor> lambdabot: @time dibblego
04:18:54 <lambdabot> Local time for dibblego is Tue Apr  3 21:18:32
04:18:56 * int-e wonders why he is discussing math topics on #haskell rather than ##math.
04:19:26 <roconnor> int-e: In my experience, ##math thinks everything is about homework
04:19:36 <t7> because ##math only talk phd level math
04:19:43 <int-e> lol
04:20:00 <sipa> 13:19:04 < roconnor> int-e: In my experience, ##math thinks everything is about homework
04:20:03 <sipa> 13:19:14 < t7> because ##math only talk phd level math
04:20:06 <sipa> those are quite conflicting statements
04:20:10 <roconnor> indeed
04:20:23 <merijn> a being coprime with p means a^n also has to be coprime with p. So repeatedly multiplying results in a cycle (since Z mod p is finite), the only question is why you don't get stuck in a smaller cycle. Which I think I knew at some point, but seem to have forgotten
04:20:25 <roconnor> I was about to say that t7 and I have had very different experiences
04:20:31 <int-e> it's funny because both are true at times.
04:20:49 <Saizan> i guess if a topic is clearly phd material they won't think it's homework
04:21:41 <quicksilver> maybe it's phd homework.
04:21:52 <ivanm> I could write something unfoldr-like that will do the job, but would rather use a pre-defined function if it exists (strangely enough...)
04:21:53 <quicksilver> pls write thesis on algebraic cohomotopy. kthx.
04:22:13 <t7> are so this equation is just like a constraint
04:22:20 <t7> find d where all this crap is true :)
04:22:40 <quicksilver> ivanm: I don't quite understand but perhaps just taking the n'th item of a "scan" is what you need?
04:22:59 <osa1> I want to install leksah but I have ghc 7.04 installed and I don't want to mess with my installed packages, is there a way to install a different verison of ghc in a isolated environment(like python's virtualenv)
04:23:34 <quicksilver> > (scanl (+) 1 [1..]) !! 7
04:23:34 <lambdabot>   29
04:23:40 <merijn> hmm, got a bit closer but I still haven't grokked the reason why a^n ends up in a cycle that's exactly p multiplications...time to hit the books when I get home again
04:23:45 <ivanm> quicksilver: not really, as I don't have a list to apply it to
04:23:58 <quicksilver> merijn: there are no cycles of any other length, if p is prime.
04:24:21 <ivanm> quicksilver: e.g. say I have an unwrapped supply Monad (Supply a -> (a, Supply)) and I want to get n values
04:24:33 <merijn> quicksilver: I know, but why?! (Imagine whiny voice here)
04:24:50 <quicksilver> merijn: how deep an answer do you need?
04:24:58 <Saizan> osa1: different ghc versions keep their packages separate by default
04:25:09 <quicksilver> merijn: a cycle of a shorter length would define a subgroup, and subgroups have to divide the size of the whole group.
04:25:28 <quicksilver> merijn: ... but are you already comfortable with the second half of that as being a fact?
04:25:28 <merijn> quicksilver: Deep enough, it's the only piece that's missing in my understanding of how RSA works :p
04:25:33 <osa1> Saizan: ok, but how can I install different ghc without replacing current one
04:25:49 <merijn> quicksilver: No, I remember that being stated. But I don't remember the proof
04:25:51 <Saizan> osa1: which OS are you on?
04:25:55 <osa1> Saizan: suse 12.1
04:25:59 <osa1> opensuse*
04:26:01 <quicksilver> ivanm: wrap it back up and use replicateM :)
04:26:29 <quicksilver> merijn: that's the problem with maths, the turtles go round and round.
04:27:01 <merijn> quicksilver: Well, most of the stuff just discussed I knew at some point, but forgot and I just go reminded of that open question :p
04:27:07 <ivanm> quicksilver: this is one small thing, I'd rather not use an actual Monad
04:27:14 <quicksilver> there will be a way to rewrite this proof in a purely number theoretic setting without appealing to group theory but off-hand I don't know an attractive way to do so.
04:27:20 <ivanm> but it looks like I have to write my own function :(
04:27:23 <merijn> quicksilver: I remember that subgroup sizes had to divide the group cardinality but I didn't understand why
04:28:06 <quicksilver> ivanm: well, replicateM is not scary. "Using a monad" is not something which has independent merit.
04:28:22 <Saizan> osa1: on linux each version also installs versioned executables, e.g. ghc-7.0.4, ghci-7.0.4 .. and the rest of the installation won't be overwritten
04:28:30 <Saizan> osa1: except for docs i think
04:28:39 <ivanm> quicksilver: I know replicateM isn't scary :)
04:28:46 <quicksilver> merijn: consider the cosets of the subgroup; convince yourself that each coset must either *be* the subgroup, or be another set of the same size.
04:29:10 <quicksilver> merijn: every element must be in some coset, so the size of the group is a multiple of the size of the subgroup.
04:30:20 <Saizan> osa1: though on hackage there are some virtualenv-like tools you might prefer
04:31:15 <quicksilver> @type runState . replicateM 5 . State
04:31:16 <lambdabot> Not in scope: data constructor `State'
04:31:22 * quicksilver slaps lambdabot 
04:31:37 <quicksilver> runState . replicateM 5 . State :: (s -> (a, s)) -> s -> ([a], s)
04:31:43 <quicksilver> ^^ ivanm
04:32:03 <merijn> quicksilver: I think I just have to back to learning more math, as I'm not familiar with cosets
04:32:24 <quicksilver> merijn: well as I say, there will be a elementary way of rewording this factr
04:32:31 <quicksilver> if you don't want to appeal to group theory.
04:32:33 <Saizan> @type runState . replicateM 5 . state
04:32:34 <lambdabot> forall s a. (s -> (a, s)) -> s -> ([a], s)
04:32:38 <ClaudiusMaximus> :t unfoldr
04:32:39 <lambdabot> forall b a. (b -> Maybe (a, b)) -> b -> [a]
04:32:40 <quicksilver> thanks Saizan.
04:33:05 <ivanm> quicksilver: sure, but that requires I bring in transformers for one small function in a data structure library
04:33:57 <Saizan> how dare you write haskell code without a monads library?
04:34:37 <quicksilver> merijn: OK, here goes. Consider an orbit of a length less than 'p' - say its length is 'o'. Then you have an element 'a' and an interval 'b', such that a + o * b = a (mod p), agreed?
04:36:01 <merijn> Yes, if o or b is 0 or o*b is a multiple of p
04:38:19 <quicksilver> merijn: but now we have o*b = 0 (mod p) which means that o and b divide p.
04:38:27 <ivanm> Saizan: quite easily actually
04:38:29 <ivanm> :)
04:38:45 <quicksilver> merijn: ...but p is prime, so one of o and b is 1.
04:38:53 <quicksilver> and the other is p.
04:39:05 <quicksilver> so your cycle wasn't really of a length less than p and greater than 1.
04:40:36 <hpaste> keep_learning pasted “multiple executables from single cabal file” at http://hpaste.org/66381
04:40:46 <keep_learning> Hello all
04:41:22 <keep_learning> I have implemented a algorithm using data parallel haskell and without dph ( sequential ) .
04:41:25 <merijn> quicksilver: Well, that or a multiple of p, but since Z mod p doesn't have more than p elements you can't have a cycle longer than that, right?
04:42:02 <keep_learning> Both are same so is it possible to generate two executable from single test file
04:42:11 <keep_learning> some thing like this
04:42:20 <keep_learning> http://hpaste.org/66381
04:42:21 <quicksilver> merijn: yes.
04:42:27 <quicksilver> merijn: your cycle must have repeated before then.
04:42:37 <quicksilver> merijn: make sense?
04:42:46 <merijn> Unless you're cycle size is 1, which only makes sense for 0 mod p
04:43:22 * hackagebot crypto-conduit 0.3.0.1 - Conduit interface for cryptographic operations (from crypto-api).  http://hackage.haskell.org/package/crypto-conduit-0.3.0.1 (MichaelSnoyman)
04:43:23 <Saizan> keep_learning: yes, it should work
04:43:24 <merijn> quicksilver: Yeah, I need to meditate on this a bit to grok it, but at least I'm a bit further now :)
04:44:37 <keep_learning> Saizan: thanks
04:44:43 <quicksilver> merijn: well if your cycle size is 1, then your cycle step was 'p'.
04:44:51 <quicksilver> merijn: there are indeed cycles of size 1 :)
04:45:25 <quicksilver> observe that 4+13 = 4 (mod 13), so [4] is a cycle of length 1 and step 13.
04:49:47 <keep_learning> Saizan: Its giving me error for my common interface function
04:50:46 <hpaste> keep_learning annotated “multiple executables from single cabal file” with “multiple executables from single cabal file (annotation)” at http://hpaste.org/66381#a66382
04:58:30 <joshuatly> hello! Want to ask abit, if i want to do if else with to multiple condition, like if (a=="aaa" or a=="bbb"), how do i do that in haskell?
04:58:47 <roconnor> preflex: seen dmwit
04:58:47 <preflex>  dmwit was last seen on #haskell 8 hours, 31 minutes and 36 seconds ago, saying: That's what e.g. Boomerang does.
04:58:54 <merijn> joshuatly: Usually you use guards
04:59:15 <joshuatly> oh okay, i will check that out
05:01:12 <quicksilver> well, let's start with the simpler answers first?
05:01:26 <quicksilver> joshuatly: if (a=="aaa" || a=="bbb")
05:01:33 <quicksilver> is one reasonable approach.
05:01:37 <joshuatly> ok.
05:01:43 <quicksilver> if (a `elem` ["aaa","bbb")
05:01:47 <hpaste> merijn pasted “guards” at http://hpaste.org/66383
05:01:49 <quicksilver> is another. If you fix the missing ]
05:02:05 <quicksilver> guards are another syntax which, sometimes, looks nicer than if.
05:02:31 <quicksilver> merijn's paste has two more options
05:02:46 <joshuatly> thanks :D
05:04:12 <merijn> quicksilver: Ah, I sorta glossed over his example and assumed he meant "if/elif/elif/else", that's what I get for not reading properly :p
05:08:06 <t7> whats a quick way to get a prime number between 0 and n?
05:08:14 <ClaudiusMaximus> 2
05:08:18 <merijn> ClaudiusMaximus: Damn you
05:08:22 <t7> mine is super slow :(
05:08:24 <merijn> I was about to say that :(
05:08:58 <joshuatly> lol
05:09:33 <quicksilver> t7: that is a question which only has complicated answers, as far as I know.
05:09:49 <quicksilver> there are a variety of well-known algorithms to general "probable primes" of particular sizes
05:09:54 <quicksilver> you then have to check they really are prime.
05:10:15 <t7> someone should make a package :)
05:10:30 <quicksilver> if n is quite small you might prefer the simple approachs of (1) pick random number, check if it's prime or (2) make list of all primes, pick one at random.
05:11:17 <t7> n will be 512 bits or something
05:11:23 <t7> so big
05:11:38 <keep_learning> t7: Try this http://www.haskell.org/haskellwiki/Prime_numbers
05:11:50 <quicksilver> t7: they did make a package.
05:12:36 <quicksilver> at least there is some code in http://hackage.haskell.org/packages/archive/cryptocipher/0.3.0/doc/html/src/Number-Prime.html
05:12:42 <merijn> If I want a top level TVar do I just do "unsafePerformIO $ newTVarIO foo"?
05:12:53 <quicksilver> and some more in http://hackage.haskell.org/packages/archive/Crypto/4.2.4/doc/html/src/Codec-Encryption-RSA-NumberTheory.html
05:12:59 <quicksilver> merijn: don't do it. You will go to hell.
05:13:13 <merijn> quicksilver: Why?
05:13:52 <ChristianS> t7: you could also use the form on http://www.rsok.com/~jrm/printprimes.html and then parse the result :-P
05:14:02 <t7> haha
05:14:42 <quicksilver> t7: there is some background in the comments of http://stackoverflow.com/questions/2882147/generating-exactly-prime-number-with-java
05:14:56 <quicksilver> merijn: it's just a hideous thing to want to do.
05:15:24 <merijn> quicksilver: The toplevel TVar, the unsafePerformIO or both?
05:16:49 <t7> aha
05:17:03 <t7> i can pinch the RSA one for now
05:17:50 <quicksilver> merijn: toplevel TVar, although the fact you need unsafePerformIO to do it is not unrelated to why it's a mess.
05:18:34 <quicksilver> merijn: there have been long and bloody flamewards on the haskell-cafe on this topic :)
05:18:49 <bitonic> merijn: unsafePerformIO $ newTVarIO foo is a great way to break the type system
05:19:07 <merijn> bitonic: Explain
05:19:44 <quicksilver> merijn: http://www.haskell.org/haskellwiki/Top_level_mutable_state has a rundown of some of the issues
05:19:51 <bitonic> merijn: you can have a polymorphic value in that tvar and then put things with different types in it
05:20:33 <quicksilver> http://www.haskell.org/pipermail/haskell-cafe/2008-August/046520.html is one of the many discussions on it.
05:20:46 <merijn> Yeah, those people can all go suck it
05:21:12 <merijn> I'm hacking together a quick simulation and I need a mostly (but not completely) read-only map available from multiple places
05:21:32 <merijn> And now I can either design really nice complicated modular code or I can just stuff it in a top level IORef/TVar
05:21:33 <quicksilver> and the reason you can't do it properly is?
05:21:40 <hpaste> ClaudiusMaximus annotated “multiple executables from single cabal file” with “multiple executables from single cabal file (minimal test case with common packages)” at http://hpaste.org/66381#a66384
05:21:40 <quicksilver> stupidity, laziness, or a bad attitude?
05:21:42 <quicksilver> ;P
05:21:42 <hpaste> bitonic pasted “unsafePerformIO to break the type system” at http://hpaste.org/66385
05:21:45 <merijn> quicksilver: Because I can't be arsed and don't care :)
05:21:48 <bitonic> merijn: ^^^ this will typecheck
05:21:59 <bitonic> the same applies for the IO TVars
05:23:07 <merijn> quicksilver: The only reason I'm using haskell for this anyway is because I'm to lazy to figure out the locking in Go/Python otherwise I'd do it in either with global state and be finished in no time :p
05:23:35 <quicksilver> it doesn't take any time to create a TVar and pass it around.
05:23:42 <Saizan> tbf, adding a monomorphic type signature is a simple local fix to the "break the type system" problem
05:23:58 <quicksilver> if the program as a whole is as simple as you claim you could have done that by now.
05:24:08 <bitonic> yeah, really. the only reason why you might want to do that is because you're writing bindings to some poorly designed C library
05:24:16 <merijn> It isn't as simple as that, only the state is as simple as that
05:24:51 <bitonic> Saizan: yes it's just a warning, since most people don't know that you can do that
05:25:32 <Philippa> even then it might be better to type it as Crap and make blatant coerceCrap calls
05:34:32 <hpaste> ClaudiusMaximus annotated “multiple executables from single cabal file” with “multiple executables from single cabal file (solution using flags))” at http://hpaste.org/66381#a66386
05:34:50 <ClaudiusMaximus> keep_learning: ^^
05:35:23 <t7> how can i calculate d in   d = e^(-1) (mod phi(n))  using extended Euclidea algorythm ?
05:35:56 <dcoutts_> ClaudiusMaximus: if you wanted all of them you could make multiple executable sections
05:36:17 <dcoutts_> but what you have is ok for being able to make any one of a number of variations
05:37:19 <ClaudiusMaximus> dcoutts_: not sure i follow
05:37:31 <Igloo> dcoutts_: I think the previous paste is showing that that doesn't work, but I think it would if there was a higher Cabal-version bound?
05:45:32 <yasar> Hi, is there any online document that you could suggest that mentions using indentations as grammar elements in a parser? (sorry for my English if that sounds absurd.)
05:45:40 <Bytter> hey, can someone help me out in a doubt here.. is a monad a category too?
05:46:03 <Bytter> the same way a Lense is a category
05:46:11 <Bytter> or a Function is a category
05:47:51 <osager> can people install glade-0.12.1 ?
05:48:00 <osager> i always gets cabal error
05:48:00 <Philippa> Bytter: I think you're having some terminology trouble? It might help to think of monads as functors-and-more though - functors are like functions from one category to another, and haskell Functors are endofunctors - from and to the category of haskell types
05:48:12 <osager> gtk2hsC2hs: UName: root name supply used after saving
05:48:12 <osager> cabal: Error: some packages failed to install:
05:48:12 <osager> glade-0.12.1 failed during the building phase. The exception was:
05:48:12 <osager> ExitFailure 1
05:48:26 * hackagebot repa 3.0.0.1 - High performance, regular, shape polymorphic parallel arrays.  http://hackage.haskell.org/package/repa-3.0.0.1 (BenLippmeier)
05:48:28 * hackagebot repa-algorithms 3.0.0.1 - Algorithms using the Repa array library.  http://hackage.haskell.org/package/repa-algorithms-3.0.0.1 (BenLippmeier)
05:48:30 * hackagebot isohunt 0.1.3 - Bindings to the isoHunt torrent search API  http://hackage.haskell.org/package/isohunt-0.1.3 (ReinerPope)
05:48:32 * hackagebot repa-io 3.0.0.1 - Read and write Repa arrays in various formats.  http://hackage.haskell.org/package/repa-io-3.0.0.1 (BenLippmeier)
05:48:37 <Philippa> (so monads will get you at a new category, just as functions over haskell types form a category)
05:49:22 <Bytter> Philippa: ah, it makes sense... so a Monad is not a Category per se, it acts as a functor in the same category
05:49:27 <Bytter> Philippa: hence, and endofunctor
05:49:55 <Philippa> right. A monad is a functor and two natural transformations
05:50:11 <Bytter> Philippa: also known as morphisms, right? return and bind?
05:50:59 <Philippa> morphisms are arrows - natural transformations are also arrows (in the category of functors), but not all arrows are natural transformations
05:51:09 <keep_learning> ClaudiusMaximus:  Hi
05:51:13 <Philippa> I was thinking of return and join - bind is defined in terms of join and the functor
05:51:36 <yasar> Is this haskell you are talking about, or categoty theory?
05:51:40 <keep_learning> ClaudiusMaximus: Sorry  I was not at the desk. Thanks for solution
05:51:40 <Philippa> "yes"
05:52:10 <Bytter> Philippa: an arrow in the caregory of functors is always a natural transformation?
05:52:24 <Philippa> in category theory, the operation we call bind is still definable in terms of the operations that haskellers call return and join
05:52:32 <Philippa> Bytter: by definition, IIRC
05:53:05 <Bytter> hmmmm
05:53:28 <Bytter> This channel is a nice complement to the "Conceptual Mathematics" book :P
05:53:34 * hackagebot repa-examples 3.0.0.1 - Examples using the Repa array library.  http://hackage.haskell.org/package/repa-examples-3.0.0.1 (BenLippmeier)
05:53:36 * hackagebot repa-bytestring 3.0.0.1 - (deprecated)  http://hackage.haskell.org/package/repa-bytestring-3.0.0.1 (BenLippmeier)
05:53:38 * hackagebot repa-examples 3.0.0.2 - Examples using the Repa array library.  http://hackage.haskell.org/package/repa-examples-3.0.0.2 (BenLippmeier)
05:54:10 <Bytter> Philippa: thank you... I think I cleared up some things in my head..
05:54:53 <Philippa> yeah, CM takes a while to get on to natural transformations but it's a good book
05:55:04 <ciaranm> it's an awful, annoying, horrible book!
05:56:06 <Bytter> Philippa: my problem is maping categoric notions to programming
05:57:25 <keep_learning> Igloo: Hi
05:57:46 <ciaranm> Bytter: there's Pierce's book, except it was written just before all the stuff we actually care about in category theory was discovered
05:58:26 <hpaste> merijn pasted “IO loop” at http://hpaste.org/66387
05:58:27 * hackagebot couchdb-conduit 0.8.0 - Couch DB client library using http-conduit and aeson  http://hackage.haskell.org/package/couchdb-conduit-0.8.0 (AlexanderDorofeev)
05:58:50 <merijn> Is there a nice way to rephrase that loop without the explicit recursion? Something forever like?
05:59:19 <Bytter> ciaranm: what book?
05:59:34 <ciaranm> Bytter: uh, "Basic Category Theory for Computer Science" iirc
06:01:44 <keep_learning> Igloo: Thanks  :)
06:02:25 <quicksilver> merijn: not a really simple built-in way, no.
06:02:37 <emcc> pierce's book is about the best intro there is
06:02:56 <quicksilver> merijn: your problem is that that loop needs to terminate and there aren't any simple standard loop combinators which allow you to terminate.
06:03:09 * mux is waiting for Learn You a Category Theory with cute drawings ;-)
06:03:10 <t7> what is key size for rsa
06:03:14 <t7> size of p and q ?
06:03:18 <t7> or size of d?
06:03:23 <quicksilver> merijn: you could use IO exceptions (ick!) or you could move to a monad with termination like ExitT IO or ErrorT IO (a bit of a pain)
06:03:27 * hackagebot conduit 0.4.0.1 - Streaming data processing library.  http://hackage.haskell.org/package/conduit-0.4.0.1 (MichaelSnoyman)
06:03:38 <bitonic> ciaranm: I'm reading the Awodey book and it tries to hard to make CT interesting
06:03:41 <quicksilver> merijn: or you could wish there was a combinator for this ;)
06:03:46 <copumpkin> t7: modulus aize
06:03:55 <quicksilver> merijn: I must admit I generally just write explicit recursion for stuff like that.
06:04:56 <emcc> pierce's is geared towards getting you to understand domain theoretic semantics
06:05:07 <dcoutts> ClaudiusMaximus: yes, Igloo is right. You hit a bug in the semantics of Cabal pre-1.8.
06:05:12 <ClaudiusMaximus> osager: there's a workaround, something like cabal unpack && cabal install && cabal install
06:05:33 <ClaudiusMaximus> keep_learning: ^^   dcoutts: aha, good to know
06:05:44 <dcoutts> ClaudiusMaximus: Multiple executables work fine, but previously for multiple components the deps of all components were unioned together.
06:05:56 <merijn> quicksilver: Yeah, I was considering doing the exception thing, but was to lazy :p
06:05:57 <quicksilver> merijn: there is http://hackage.haskell.org/packages/archive/monad-loops/0.3.0.2/doc/html/Control-Monad-Loops.html but amazing none of them seems well suited to your example.
06:06:08 <t7> copumpkin: i mod against phi ...
06:06:18 <dcoutts> ClaudiusMaximus: to opt-in to the sensible semantics, you just need to specify:  cabal-version: >=1.8
06:06:49 <dcoutts> ClaudiusMaximus: we couldn't just change it because it'd have broken lots of older packages that accidentally relied on the odd behaviour
06:06:54 <quicksilver> merijn: I was expecting something like whileM_ :: m Bool -> m (); -- keep executing this block until it returns false.
06:07:11 <hpaste> t7 pasted “key gen” at http://hpaste.org/66388
06:07:16 <quicksilver> merijn: but all the variants of while in monad-loops seem to have a separate condition parameter rather than using the return value of the main thing.
06:07:55 <quicksilver> merijn: ah, you could use "iterateUntil" from monad-loops, in fact
06:08:06 <quicksilver> you probably don't want a dependency on a package for that though
06:08:07 <ClaudiusMaximus> dcoutts: groovy
06:08:17 <ciaranm> i'd like to see a "Category Theory and Algebra and Lattices using Haskell" book
06:08:43 <ciaranm> something that starts where your typical "the bare minimum of maths you need for a programming course" course leaves off
06:08:46 <emcc> that... would be an excellent intro, I think
06:09:16 <ciaranm> could probably get some parts of topology in there too
06:10:00 <ciaranm> afaik most places do topology via metric spaces, and after analysis, which is fine if you need to know analysis but not necessarily the most efficient way of learning it for compsci
06:10:14 <t7> copumpkin: how could you tell key size from my paste above?
06:10:36 <emcc> Munkres (topology 2nd ed) does a good job of introducing topology w/o getting stuck in obscure math topics
06:11:12 <ciaranm> Munkres is still mostly looking at it with examples that look suspiciously like metric spaces
06:11:22 <emcc> most category theory books, on the other hand, seem to assume you have a master's in pure math before you start
06:11:40 <ciaranm> Awodey's not quite that bad
06:11:53 <ciaranm> it just assumes half of an undergrad degree in pure maths
06:12:19 <emcc> there's a parallel branch of PL semantics based on (ultra)metric spaces
06:12:40 <quicksilver> I certainly didn't do topology via metric spaces
06:12:56 <quicksilver> although plenty of the examples looked like metric spaces (does that matter?)
06:13:14 <ciaranm> i'm not saying analysis, metric spaces etc are useless. just that if you're looking at CS, they're probably not the most important topics if you only have however much you can fit in a three or four year progra,
06:14:10 <sabrehagen> hi, i'm looking for an n^2 algorithm to apply a function to all elements in a list, but using each element as one of the inputs to that function. map seems to do what i want, but only as a once off thing, not repeatedly. i've drawn a diagram of the algorithm here: http://oi40.tinypic.com/2sbab93.jpg
06:14:13 <quicksilver> sure.
06:14:39 <quicksilver> I would argue topology itself is not that important in a 3-year CS course.
06:14:57 <sabrehagen> is there a way to do this just using higher order functions, not recursion?
06:15:05 <quicksilver> sabrehagen: you want to apply the function to every possible pair of elements in the list?
06:15:09 <ciaranm> sabrehagen: your picture looks like a spider
06:15:15 <ciaranm> a deformed spider
06:15:50 <bitonic> I don't have half a maths degree (I'm 3rd year computing) and I can read Awodey... it doesn't assume much
06:16:00 <sabrehagen> quicksilver, yes, it applies a function taking the value circled, and the value at the end of the line, and stores the result in the position of the value at the end of the line
06:16:16 <sabrehagen> it then does this for each element
06:16:57 <quicksilver> sabrehagen: that doesn't make sense.
06:16:59 <ciaranm> so in conclusion, we should kidnap Cale or edwardk or that dan guy, and make them write a book covering monoids, groups, categories, lattices, domain theory, topologies and a bit of number theory, using haskell
06:17:18 <quicksilver> sabrehagen: you've then stored multiple things in each position!
06:17:28 <quicksilver> sabrehagen: how many arguments does the function take?
06:17:35 <quicksilver> sabrehagen: can you give an actual example?
06:17:49 <emcc> Hausdorf spaces are pretty common in algorithms, actually.  Particularly anything involving a fixed point.
06:18:11 <bitonic> ciaranm: the problem is that you can't express/prove properties of those things in Haskell :P
06:18:46 <danr> emcc: hmmm. with the order topology?
06:18:49 <emcc> but you could give examples
06:18:56 <bitonic> you can just express the abstractions with typeclasses
06:19:02 <bitonic> (which is already something)
06:19:07 <bitonic> but you have to write the rules in the comments ehe
06:19:23 <ciaranm> bitonic: sure, but you can use haskell to illustrate it, and to explain why things are interesting for compsci
06:19:24 <sabrehagen> quicksilver, sure! haha. each element is a particle, and i want to calculate it's effect on each other particle in the list. you take the circled particle, and the particle at the end of the line, calculate the gravitational effect of the circled particle on the one at the end of the line, and then update the one at the end of the line
06:19:29 <bitonic> and edwardk has largely done that, even if there isn't a book
06:19:42 <bitonic> ciaranm: that might not be so easy, apart from 3 or 4 things
06:20:03 <`Jake`> sabrehagen: The function takes two arguments?
06:20:04 <bitonic> well, they are interesting to compsci yes
06:20:07 <quicksilver> sabrehagen: OK, so it's really a multiple step and *mutable* process.
06:20:14 <ciaranm> the material's all out there, scattered around hundreds of blog posts, papers using weird notation, and so on. i want it all in one place, on a dead tree!
06:20:17 <sabrehagen> quicksilver, you then need to calculate this gravitational effect on every particle in the list. so how each particle effects each other particle. yes, it takes two arguements.
06:20:18 <quicksilver> sabrehagen: remember that haskell values are immutable.
06:20:26 <bitonic> ciaranm: yeah I'd love that too :)
06:20:44 <quicksilver> sabrehagen: so, you could instead produce a new list after each iteration you describe
06:20:56 <sabrehagen> quicksilver, each X in the list is a data type that has sub variables, and i believe i have to do the update in place
06:21:10 <quicksilver> sabrehagen: there is no in-place update.
06:21:15 <bitonic> something like "Type Theory for Functional Programming" (which could be better) but for CT
06:21:23 <quicksilver> sabrehagen: haskell data values are immutable.
06:21:36 <quicksilver> sabrehagen: record update syntax produces a new value based on the old.
06:21:43 <ciaranm> not just category theory. i reckon you could get some abstract algebra in there too.
06:21:46 <sabrehagen> quicksilver, hmm...okay...so i would need to generate a whole new list and return that?
06:21:57 <sabrehagen> quicksilver, n times?
06:22:19 <quicksilver> well personally when I model particle systems I do it in one pass
06:22:28 <bitonic> ciaranm: yeah you can start from asbstract algebra and then build up to CT I guess
06:22:33 <quicksilver> I update every particle individually based on the "old" locations of all of them
06:22:39 <quicksilver> so it's just a single map.
06:22:56 <quicksilver> new_particles = map (\x -> updateParticle x old_particles) old_particles
06:23:05 <emcc> if you're doing physics in Haskell, I'd look into some of the data parallel stuff
06:23:18 <quicksilver> I would suggest you do not follow emcc's advice.
06:23:47 <quicksilver> that is definitely "running before your can walk" if I have correctly judged your level of haskell ;)
06:24:12 <sabrehagen> quicksilver, it's probably less than you have judged :P
06:24:21 <Bytter> I'm trying to define a time-series data-structure (called Timeline), parameterized in two types (T, V), the first one representing the series, and the second one the value
06:25:12 <t7> > 2 ^ 32 / 700,000,000
06:25:13 <lambdabot>   <no location info>: parse error on input `,'
06:25:17 <t7> > 2 ^ 32 / 700000000
06:25:18 <lambdabot>   6.135667565714286
06:25:22 <Bytter> based on typical manipulations, I can see that a timeline may be regarded as a Functor
06:25:28 <Bytter> manipulating the values
06:25:43 <osa1> I have two type synonyms that are same types(ie type a = x; type b = x), how good is the idea of using data constructors instead of type synonyms(ie data a = a x, data b = b x) just to prevent bugs? ie. bugs caused by using one of them in place of other one
06:25:55 <sabrehagen> quicksilver, just to clarify the syntax of your last statement, does "\x -> updateParticle x old_particles" say for each x in old_particles, pass in x and old_particles to the update particle function?
06:26:44 <emcc> true, if you're a beginner, probably not a good idea
06:27:29 <quicksilver> sabrehagen: yes, and then the updateParticles function still has a list as its second parameter.
06:27:42 <quicksilver> sabrehagen: so it still has to update the particle 'x' based on *all* the particles in old_particles
06:27:54 <quicksilver> which, normally would be a fold
06:28:07 <sabrehagen> quicksilver, ahh okay. far out this is tough to get my head around...
06:28:28 * hackagebot alex-meta 0.3.0.3 - Quasi-quoter for Alex lexers  http://hackage.haskell.org/package/alex-meta-0.3.0.3 (JonasDuregard)
06:28:30 * hackagebot happy-meta 0.2.0.4 - Quasi-quoter for Happy parsers  http://hackage.haskell.org/package/happy-meta-0.2.0.4 (JonasDuregard)
06:28:32 * hackagebot BNFC-meta 0.3.0.1 - Deriving Quasi-Quoters from BNF Grammars  http://hackage.haskell.org/package/BNFC-meta-0.3.0.1 (JonasDuregard)
06:29:52 <quicksilver> updateParticle x other_parts = foldl' (\x y -> x { accel = accel x + mass_y / (distance x y)^2 }) other_parts
06:30:24 <quicksilver> sabrehagen: ^^ something like that, although that's not real gravitational attraction
06:30:33 <quicksilver> and it assumes the function 'distance' exists
06:30:43 <quicksilver> and "mass_y" is a typo for "mass y"
06:31:25 <sabrehagen> quicksilver, jeez...okay. i'll try to manipulate what you've given me. thanks a lot :)
06:33:49 <quicksilver> sabrehagen: well probably I'd start by writing the code for just two particles x and y, and test it
06:33:58 <quicksilver> then combine that with a whole list using foldl
06:34:08 <quicksilver> and then apply that to everything with a map (or another fold, in fact)
06:36:06 <t7> No instance for (Data.String.IsString [Word8])   :(
06:38:03 <t7> ah Char8
06:40:18 <t7> can i encode (Byte)String as hex string somehow?
06:40:40 <joshuatly> hey, in a function, is there a way to add two variable (integer) without creating another function again?
06:41:10 <Entroacceptor> joshuatly: what?
06:41:20 <quicksilver> t7: http://stackoverflow.com/questions/8412398/pretty-print-bytestring-to-hex-nibble-wise
06:42:10 <joshuatly> how do i add two variable?
06:42:10 <t7> nice
06:42:25 <Entroacceptor> :t (+)
06:42:25 <lambdabot> forall a. (Num a) => a -> a -> a
06:42:32 <quicksilver> joshuatly: a + b ?
06:42:38 <joshuatly> yea
06:42:42 <quicksilver> joshuatly: can't quite follow what you're asking ;)
06:42:44 <ClaudiusMaximus> > joshuatly a b = let d = abs (a - b) in d * d in joshuatly 5 8 -- completely random guess based on almost complete lack of context
06:42:44 <lambdabot>   <no location info>: parse error on input `='
06:43:00 <sabrehagen> quicksilver, just wondering, how come you model particle systems? what application does it have?
06:43:07 <joshuatly> hmm let me think about how should i ask the question
06:43:11 <quicksilver> sabrehagen: messing around with graphics and computer games
06:43:31 <sabrehagen> quicksilver, interesting. have you ever written any games in haskell?
06:43:44 <quicksilver> not complete ones, no
06:43:53 <quicksilver> just toys I work on until I get distracted by something else shiney
06:44:05 <sabrehagen> quicksilver, i know the feeling...
06:44:25 <hpaste> joshuatly pasted “question add2” at http://hpaste.org/66390
06:44:37 <joshuatly> i hpaste my unfinished code. dont know how to continue
06:45:00 <quicksilver> joshuatly: to add those two numbers you just write "a + ins"
06:45:14 <quicksilver> well, except x is a string
06:45:23 <quicksilver> so at some point you have to do
06:45:38 <quicksilver> let x_as_number = (read x) :: Integer
06:45:47 <joshuatly> ok all is integer.
06:45:51 <joshuatly> wait i try
06:45:56 <quicksilver> but what do you want to do with the number you get? print it out maybe?
06:46:39 <joshuatly> yea i would like to print it out and save back to the file, overwrite the old value
06:47:37 <joshuatly> how do i do that quicksilver?
06:49:47 <quicksilver> well writeFile is part of your answer
06:50:14 <joshuatly> yea but how do i add the two the only write to the file?
06:50:25 <joshuatly> *then only
06:50:26 <ciaranm> i think you need to read a book
06:51:05 <joshuatly> i didnt manage to borrow one from my library sorry
06:51:35 <quicksilver> joshuatly: well I've already told you that you add two numbers with +
06:51:39 <quicksilver> a + b
06:51:42 <joshuatly> ok
06:51:45 <joshuatly> i try
06:51:46 <ciaranm> joshuatly: "learn you a haskell" is free online
06:51:51 <quicksilver> joshuatly: I think you need to actually try something and explain where your problems are
06:51:59 <quicksilver> it seems to me like I have answered all your questions
06:52:57 <joshuatly> does it mean i do writeFile "file1.txt" x + ins? cos i got error
06:53:45 <Entroacceptor> @where lyah
06:53:46 <lambdabot> http://www.learnyouahaskell.com/
06:53:46 <quicksilver> well yes, there are two things wrong with that.
06:53:57 <quicksilver> firstly, x and ins are strings, so you can't add them
06:54:05 <quicksilver> secondly, even if you could, you'd need parens
06:54:12 <quicksilver> writeFile "file1.txt" (x + ins)
06:54:21 <joshuatly> i see
06:54:22 <quicksilver> and, thirdly, writeFile needs a string, so you'd need to show it.
06:54:38 <quicksilver> would definitely recommending reading some of learn you a haskell
06:55:14 <Entroacceptor> is it homework?
06:56:29 <joshuatly> yea, im doing part of it. sorry and thanks for all the trouble
06:57:19 <Entroacceptor> the problem is, #haskell has a different opinion on what to teach first from a lot of teachers :)
06:57:22 <ion> Too bad Haskell doesn’t have weak typing, writeFile "foo" (x + y) would work. In fact, writeFile "foo" x + y could work as well!
06:57:39 <ciaranm> why would you want weak typing when you have typeclasses?
06:58:13 <merijn> ciaranm: Why would you want weak typing ever?
06:58:30 <merijn> Even python doesn't do implicit conversion
06:58:44 <int-e> @type print
06:58:45 <lambdabot> forall a. (Show a) => a -> IO ()
06:58:45 <ion> Except between number types.
06:58:54 <ciaranm> merijn: if your choice is weak typing or strong typing with nothing resembling generics, i'm not sure i'd want strong typing...
06:59:06 <int-e> you could implement a printFile that allows printFile "foo" (x + y)
06:59:32 <ion> In case it was lost on someone, i don’t *really* want weak typing in Haskell. :-P
06:59:33 <int-e> the point is, type classes carry us a very long way.
06:59:53 <ciaranm> someone should fix typeclasses so a type can implement a typeclass in more than one way
07:00:17 <quicksilver> for values of "fix" approaching "break".
07:00:43 <ciaranm> wrapper types are a horrible hack
07:01:01 <ion> lim_{fix→break} fix typeclasses
07:01:04 <int-e> > fix error
07:01:05 <lambdabot>   "*Exception: *Exception: *Exception: *Exception: *Exception: *Exception: *E...
07:01:38 <int-e> ciaranm: they're not a hack
07:01:38 <quicksilver> ciaranm: typeclasses of which types can be members in more than one way are no longer type classes.
07:01:43 <quicksilver> they're something els.e
07:01:57 <quicksilver> and it's not remotely clear they have any advantage over simple higher order programming
07:01:58 <ion> ciaranm: In what way are they a hack?
07:02:01 <emcc> problem is, how do you indicate which implementation of a given class you want to use
07:02:05 <ciaranm> lots of things are monoids in lots of ways
07:02:08 <quicksilver> (that is, passing around functions or polymorphic bundles)
07:02:39 <emcc> it would get nasty
07:02:47 <ciaranm> i want to be able to say "for the purposes of this expression, i want to use the additive version of monoid for this type"
07:03:28 <quicksilver> ciaranm: understood, but it doesn't work.
07:03:39 <quicksilver> typeclasses are used to guarantee invariants.
07:03:53 <quicksilver> either lexical or dynamic selection of instances will give you ways to break those invariants
07:03:55 <int-e> ciaranm: I understand the pain, but "hack" is simply the wrong word for inconvenience.
07:04:11 <quicksilver> consider "Ord" and how it's used for Data.Maps, or "Binary" and how it's used to build ByteStrings.
07:04:22 <quicksilver> and also, what's the point anyway?
07:04:34 <quicksilver> the entire point of typeclasses is that the compiler can select the right one automatically
07:04:46 <quicksilver> if the compiler can't - if you have to tell it which one - then why use a typeclass?
07:04:56 <ciaranm> i'd like to be able to say something like "mconcat [1, 2, 3] using Num.Sum"
07:05:06 <ciaranm> or "mconcat [1, 2, 3] using Num.Product"
07:05:08 <quicksilver> why not use a simpler mechanism to pass the right one around
07:05:22 <quicksilver> foldl1 (+) [1,2,3]
07:05:26 <quicksilver> fold1 (*) [1,2,3]
07:05:27 <ion> > ala Sum foldMap [1..3]
07:05:28 <lambdabot>   Not in scope: `foldMap'
07:05:35 <ion> > ala Sum Data.Foldable.foldMap [1..3]
07:05:35 <lambdabot>   6
07:05:43 <quicksilver> by the magic of "passing a function" you choose the instance... ^^
07:05:48 <ciaranm> that only works for simple examples
07:05:55 <quicksilver> no, it works for every example.
07:06:01 <ciaranm> in a very verbose way
07:06:12 <int-e> everything only works for simple examples. the trick is to make things simple ;)
07:06:23 <quicksilver> "foldl1 (+) [1,2,3]" is less verbose than "mconcat [1, 2, 3] using Num.Sum"
07:06:27 <hpc> @type Data.Foldable.foldMap
07:06:28 <lambdabot> forall a m (t :: * -> *). (Data.Foldable.Foldable t, Monoid m) => (a -> m) -> t a -> m
07:06:38 <ciaranm> replace mconcat with a less trivial function
07:06:47 * quicksilver shrugs
07:06:48 <ciaranm> replace product and sum with less trivial instances
07:06:56 <quicksilver> then it looks like this:
07:07:07 <quicksilver> mconcat' sum' [1,2,3]
07:07:16 <quicksilver> the second parameter is your "instance"
07:07:27 <ciaranm> then you end up reimplementing your function, which goes against the entire point of parametricity
07:07:32 <quicksilver> no you don't
07:07:34 <quicksilver> not at all
07:07:34 <ciaranm> or you use wrapper types, which are icky
07:07:39 <quicksilver> mconcat' is just as generic
07:07:43 <quicksilver> and there are no wrapper types.
07:08:00 <quicksilver> mconcat' gets the type (a -> a -> a) -> [a] -> a
07:08:04 <quicksilver> or, if you prefer
07:08:11 <quicksilver> Monoid a -> [a] -> a
07:08:21 <quicksilver> no wrapper types, full parametricity
07:08:24 <quicksilver> and no type-classes.
07:08:26 <ciaranm> and when a typeclass consists of three or four functions, not one?
07:08:37 <quicksilver> "Monoid a" is a type
07:08:38 <ciaranm> or two here, really
07:08:52 <ciaranm> your type for mconcat' is wrong anyway
07:08:58 <quicksilver> data Monoid a = Monoid { mempty :: a, mappend :: a -> a -> a }
07:09:01 <ciaranm> you also have to pass in the identity
07:09:08 <quicksilver> ^^ can contain as many functions as you want.
07:09:13 <quicksilver> or non-functions, indeed.
07:09:14 <ciaranm> so it's (a -> a -> a) -> a -> [a] -> a
07:09:23 <quicksilver> yes, that's right.
07:09:49 <ciaranm> and that's just for a really easy typeclass and instance
07:10:38 <Saizan> once you replace it with the record the number of methods doesn't matter
07:11:01 <ciaranm> you're reimplementing type classes, in effect
07:11:06 <Saizan> nope
07:11:10 <quicksilver> no, you're not
07:11:17 <quicksilver> you're learning that typeclasses are not what you're looking for
07:11:26 <quicksilver> you're using the *simpler* concepts of higher order functions
07:11:33 <quicksilver> and passing data around
07:11:55 <quicksilver> the only wrinkle here - not visible in the simple Monad example - is that more complex cases do use higher-rank types.
07:12:01 <merijn> "type Foo = Bar -> Bar; xyzzy :: Foo -> Baz", does the type of xyzzy get parsed as being "(Bar -> Bar) -> Baz"?
07:12:09 <quicksilver> In this surprising sense, typeclasses "smuggle in" higher rank types into haskell 98
07:12:10 <ciaranm> it's not simpler when you have to explicitly say how you're implementing a concept in lots of places
07:12:12 <Saizan> it would be nice if you could project functions with a typeclass context down to the HOF version though
07:12:32 <yitz> merijn: yes
07:12:33 <quicksilver> ciaranm: it's exactly the same amount of "explicitness" as your "using" syntax, surely?
07:12:38 <quicksilver> you mention it in the same places.
07:12:40 <merijn> yitz: ok, thanks :)
07:12:42 <quicksilver> except it's not broken
07:12:52 <quicksilver> and it doesn't ruin the actual, useful, features of typeclasses.
07:13:01 <quicksilver> Saizan: it would, yes.
07:13:45 <quicksilver> ^^ "in the simple Monad example" - I mean "in the simple Monoid example"; actually "Monad" is one of the cases which is higher-rank, which is what I was trying to say but my fingers missed out a sentence.
07:14:31 <ciaranm> if you don't like the "using" syntax, think let/where, with the same scope possibilities
07:14:48 <Saizan> quicksilver: if you have code like (a `mappend` b `mappend` c) then "using" would be more convenient than passing the dictionary twice
07:15:22 <Saizan> and opening the dictionary locally is a bit of a pain too..
07:15:26 <snhmib> hey if i want a bitvector could i use an Integer or would it be better to use a bytestring or some thing else?
07:16:11 <ciaranm> anyway. i'm going to implement my own functional language. with subtypes. and laziness as a functor. and blackjack. and hookers.
07:17:04 <merijn> ciaranm: In fact, screw the subtypes and laziness? :p
07:17:18 <ciaranm> exactly
07:17:27 <quicksilver> ciaranm: yes, and if you use let/where and either dynamic or lexical scope you break the use of typeclasses as invariants.
07:17:27 <merijn> Was that Bender in Futurama?
07:17:36 <quicksilver> which is a pretty important feature.
07:18:23 <quicksilver> Saizan: well, it's only slightly different to say "let mappend' = mappend sum in (a `mappend'` b `mappend'` c) isn't it?
07:18:49 <quicksilver> Saizan: it doesn't feel "asymptotically different" although it does involve choosing a local name for the partially applied version.
07:19:03 <ciaranm> merijn: http://www.youtube.com/watch?v=z5tZMDBXTRQ
07:19:51 <merijn> \o/ I remembered correctly
07:20:17 <ciaranm> quicksilver: i think you're thinking i'm trying to do something more than what i really am
07:21:09 <quicksilver> ciaranm: you haven't really addressed the 'typeclasses for invariants' part, and it's actually really important.
07:21:21 <osa1> which one is better for being used as keys in Data.Map, String or Data.Text?
07:21:40 <ciaranm> quicksilver: it doesn't change the behaviour of type classes at all
07:21:41 <Saizan> quicksilver: it got a bit tedious when i tried to program like that in Agda, especially if you have more than one Monoid around, though better features for handling namespaces could help, e.g. bulk renaming of "method" names by appending a suffix
07:22:23 <ciaranm> quicksilver: the entire thing could be syntactic sugar for wrapper types
07:22:52 <djahandarie> Hmm, this State monad is causing me issues
07:22:58 <emcc> that's how I do it, if I were creating a language
07:22:59 <djahandarie> It doesn't seem to be strict enough, or something
07:23:50 <quicksilver> ciaranm: if it really was sugar for wrapper types then it would work, yes.
07:24:13 <quicksilver> well it would and and it wouldn't
07:24:17 <djahandarie> I have a  StateT SomeState Parser , and I'm trying to make it interleave the parsing and state modification, but it seems to delay the state modification until after all the parsing is finished.
07:24:20 <quicksilver> would still be a problem for Binary/ByteString
07:24:23 <quicksilver> because there is no type to tag.
07:24:37 <quicksilver> but at least with Data.Map you'd get a type error if you used the wrong one
07:24:44 <djahandarie> And I've seqd/$! everything I can see to no avail
07:25:04 <quicksilver> (but that type error might seem suprising if you didn't realise the wrapper type was being used under the hood)
07:25:16 <quicksilver> having said, that "ala" is a pretty good attempt at sugar for wrapper types
07:25:36 <quicksilver> we can probably get quite a long way with tools like 'ala' although they tend to work for expressions of certain form only.
07:26:18 <Saizan> djahandarie: can you show the code?
07:26:51 <djahandarie> Hmm, yeah, let me see if I can
07:27:08 <djahandarie> It's messy as hell right now since I'm forcing every value possible :p
07:27:48 <Saizan> that often ends up not forcing where it matters :)
07:28:02 <djahandarie> Yeah, so it seems.
07:28:30 <ciaranm> anyway, i'm more interested in laziness as a functor than anything else when it comes to language design issues
07:28:53 <hpaste> djahandarie pasted “.” at http://hpaste.org/66391
07:28:55 <quicksilver> I sometimes wonder things like State a should take, on construction a "Strategy a" parameter
07:28:59 <djahandarie> Saizan, ^
07:29:07 <quicksilver> and use that to force the state "to that extent" after every command.
07:29:14 <quicksilver> not sure if the overhead would be too high.
07:29:25 <djahandarie> Saizan, the  return $! cs  at the very end successfully forces it
07:29:28 <djahandarie> But that's too late
07:29:40 <djahandarie> I want the  RT.insert  call to happen during the parsing
07:30:06 <Saizan> well, it's not much use forcing the function
07:30:11 <djahandarie> And interestingly, the trace "i" does show up during the parsing, but it doesn't make the RT.insert call no matter what I do
07:30:30 <quicksilver> yes because you attached the trace to the evaluation of the function itself
07:30:36 <quicksilver> not its application to its argument.
07:30:44 <djahandarie> Ah, right.
07:31:04 <Saizan> modify' f = do s <- get; let s' = f s; s' `seq` put s'
07:31:08 <Saizan> use that
07:31:21 <quicksilver> is there any laziness inside "IPRTable IPv4 Coord"
07:31:30 <quicksilver> is seqqing that at the top level enough?
07:31:41 <djahandarie> Nope, that's fully strict
07:32:12 <quicksilver> that's good.
07:32:20 <Saizan> and i guess the strict StateT, though that might not matter when transforming Parsec
07:32:40 <djahandarie> Saizan, bang, that did it
07:32:50 <djahandarie> I had a feeling it had to do with the State monad not being strict enough
07:32:58 <djahandarie> And nice, much much faster now
07:33:00 <quicksilver> is that an honorific for people who solve strictness problems?
07:33:05 <quicksilver> Welcome, Saizan bang.
07:33:14 <Saizan> lol
07:33:58 <djahandarie> Okay, now I can remove all this useless forcing, excellent.
07:34:43 <Saizan> modify' should probably go into the mtl or even replace modify
07:35:33 <quicksilver> Saizan: or something cleverer with Strategy, if that's not too inefficient.
07:36:02 <Saizan> quicksilver: ah, true
07:36:58 <quicksilver> Saizan: same thing with "Event a" and similar types in FRP-like systems.
07:37:11 <quicksilver> Saizan: in general, you want them implicit forced according to some strategy every time they are updated.
07:37:19 <quicksilver> Saizan: you don't want lack of observaton to cause thunk blow-up.
07:38:16 <Saizan> quicksilver: yep, and same for most container types too
07:38:42 <quicksilver> yup.
07:44:51 <Saizan> then we can have a typeclass with the default strategy for each type and argue on how to best override that locally :)
07:46:37 <DoctorSmaug> Hi guys, I have a function which produces an infinite list and I want to work out how many items in the list are less than 4 chars long.  I've tried this: length [x | x <- genIDList, length x < 4] but it never ends because it doesn't stop checking the IDList when things are over 3 chars long.
07:46:42 <DoctorSmaug> Any help?
07:47:51 <quicksilver> Saizan: hahaha :)
07:48:01 <osa1> is there a way to call forM_ on Data.Map?
07:48:12 <quicksilver> DoctorSmaug: how could you expect it to stop?
07:48:27 <quicksilver> DoctorSmaug: how is it supposed to know at which point there will never be anything shorter?
07:48:33 <osa1> or do I have to call toList ?
07:48:42 <quicksilver> osa1: calling toList or something similar is the way.
07:48:54 <osa1> ok, thanks
07:48:57 <DoctorSmaug> the list is in order from shortest to longest.  Once it finds the first thing longer than 3, they will all be longer
07:49:07 <merijn> DoctorSmaug: takeWhile
07:49:10 <merijn> :t takeWhile
07:49:11 <DoctorSmaug> so it needs to stop the moment it finds the first one of length 4
07:49:11 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
07:49:20 <quicksilver> merijn has your answer then.
07:49:36 <DoctorSmaug> yes, thank you
07:49:38 <merijn> :t takeWhile ((<4) . length)
07:49:39 <lambdabot> forall a. [[a]] -> [[a]]
07:49:50 <quicksilver> > takeWhile (\xs -> length xs < 3) ["a","aa","aaa","aaaa"]
07:49:51 <lambdabot>   ["a","aa"]
07:50:18 <DoctorSmaug> merijn: Perfect, I had thought of takeWhile already but couldn't work the syntax out. Cheers
07:51:23 <esiwmas> hey, what's a good tuorial on sparks?
07:51:27 <esiwmas> tutorial*
07:53:11 <yitz> esiwmas: http://stackoverflow.com/questions/555077/sparc-assembly-tutorial
07:53:21 <yitz> esiwmas: just joking
07:53:23 <Saizan> esiwmas: http://community.haskell.org/~simonmar/par-tutorial.pdf
07:53:36 <t7> how does generating shares work?
07:53:41 <yitz> esiwmas: use the one Saizan said
07:53:51 <t7> how do i know if i generated a share or a block... if my hash meets the difficulty
07:55:00 <koala_man> > let memoized_fib = (map fib [0 ..] !!) where fib 0 = 0; fib 1 = 1; fib n = memoized_fib (n-2) + memoized_fib(n-1)  in memoized_fib 40
07:55:01 <lambdabot>   102334155
07:55:08 <koala_man> > let memoized_fib x = (map fib [0 ..] !! x) where fib 0 = 0; fib 1 = 1; fib n = memoized_fib (n-2) + memoized_fib(n-1)  in memoized_fib 40
07:55:12 <lambdabot>   mueval-core: Time limit exceeded
07:55:14 <koala_man> why is this?
07:55:16 <Saizan> esiwmas: some more here http://research.microsoft.com/en-us/people/simonmar/
07:55:17 <yitz> t7: what are you trying to do?
07:55:26 <t7> wrong channel lolol
07:55:30 <t7> :3
07:55:41 <yitz> t7: ok :)
07:57:04 <yitz> koala_man: probaly because lambdabot is not using -O.
07:57:11 <yitz> *probably
07:58:27 <Saizan> > let memoized_fib = (map fib [0 ..] !!) where fib 0 = 0; fib 1 = 1; fib n = memoized_fib (n-2) + memoized_fib(n-1)  in  memoized_fib 40
07:58:28 <lambdabot>   102334155
07:58:32 <Saizan> koala_man: ^^^
07:58:49 <clintm> t7/yitz: interesting that it make some sense in either channel.
07:58:54 <koala_man> Saizan: yes, I pasted that too
07:59:06 <Saizan> koala_man: ah, sorry
07:59:32 <Saizan> koala_man: well, ghc only shares bindings with no explicit arguments
08:00:14 <koala_man> but memoized_fib = \x -> ... doesn't memoize either
08:00:34 <quicksilver> it shares the function
08:00:40 <quicksilver> but that doesn't help you much
08:00:46 <quicksilver> since you want to share the list.
08:02:23 <Saizan> if you put the lambda there GHC won't create a single thunk with map fib [0 ..] which memoized_fib refers to, it creates a new thunk each time you apply it instead
08:02:33 <koala_man> quicksilver: and that happens in the working case because the list is one of the parameters to !! ?
08:03:37 <bobry> Where can I find the definitions of built-in quoters (e, d etc)?
08:12:47 <quicksilver> koala_man: no.
08:13:00 <quicksilver> koala_man: it happens in the working case because memoized_fib *is* a list in that case.
08:13:22 <quicksilver> oh no it's not.
08:13:23 <quicksilver> erm
08:13:40 <quicksilver> I don't know why that works, koala_man :)
08:13:55 <quicksilver> I think it's a fluke of a floating optimisation which GHC chose to perform but you can't rely on
08:14:03 <koala_man> neat
08:14:19 <quicksilver> it chose to float that nameless array (the left parameter to !!) out to the top-level
08:14:23 <quicksilver> whereupon it got shared
08:14:35 <quicksilver> but nothing promises that will happen
08:15:03 <quicksilver> the fact that memoized_fib had no parameters must have been relevant.
08:19:06 <Saizan> isn't the thunk for memoized_fib something like (PartialApplication (!!) xs) where xs is another thunk for map fib [0..] ?
08:19:28 <Saizan> that seems to explain the sharing to me
08:21:40 <ique> Is it possible to run a list of IO functions concurrently? I have like mapM run mongoDBinsertActions where the actions are IO (Action IO()) and run is IO() i want to just split them up on different threads, there's no communication between the actions or anything
08:22:06 <copumpkin> :t mapM_ forkIO
08:22:07 <lambdabot> Not in scope: `forkIO'
08:22:13 <roconnor> @faq s it possible to run a list of IO functions concurrently? I have like mapM run mongoDBinsertActions where the actions are IO (Action IO()) and run is IO() i want to just split them up on different threads, there's no communication between the actions or anything
08:22:13 <lambdabot> The answer is: Yes! Haskell can do that.
08:22:15 <copumpkin> that's the most naive way of doing it, anyway
08:23:05 <roconnor> @type mapM_
08:23:06 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m ()
08:23:18 <hpc> @hoogle forkIO
08:23:19 <lambdabot> Control.Concurrent forkIO :: IO () -> IO ThreadId
08:23:19 <lambdabot> GHC.Conc.Sync forkIO :: IO () -> IO ThreadId
08:23:19 <lambdabot> GHC.Conc forkIO :: IO () -> IO ThreadId
08:23:22 <ique> copumpkin: I see.. does that spawn a thread for every action then?
08:23:32 <copumpkin> depends what you mean by that
08:23:34 <copumpkin> but probably not
08:23:45 <copumpkin> GHC has lightweight threads
08:23:53 <copumpkin> so no new OS threads are spawned
08:23:54 <ique> yeah that's what I meant, not OS thread
08:23:54 <hpc> it spawns a "thread" for every action
08:23:56 <roconnor> ique: it spawns GHC threads but not necessarily OS threads
08:30:49 <ozataman> is there a way to pass flags to build dependencies in .cabal files?
08:31:03 <dcoutts> ozataman: no, by design
08:31:47 <dcoutts> ozataman: since flags should not affect the interface, then packages do not need to specify that dependencies get built with particular flags
08:32:06 <ozataman> dcoutts: I have a problem where I need to do "cabal install snap -fhint", but doing cabal install to a much larger project re-installs snap without the flag in order to satisfy some other dependencies upper bound on a different dependency (if that makes sense ;) )
08:32:28 <ozataman> I am in fact using cabal-dev, but that's irrelevant, I think
08:33:21 <ozataman> since my stand-alone cabal install snap -fhint is done by itself and does not consider the larger project, it just uses highest bounds on all of its dependencies
08:34:03 <dcoutts> ozataman: when you install the top level thing, you can specify -fhint there I think, or the dev version of cabal-install has flag constraints, e.g. --constraint='snap +hint'
08:34:40 <ozataman> right, but then I have to know which library is causing the problem. and do cabal-dev install snap -fhint --constrain='blahblah"
08:34:55 <dcoutts> ozataman: if snap is changing it's interface based on that flag, then it is being naughty
08:34:57 <ozataman> the offending package changes every week or so - given the rapid pace at which Haskell env evolves-
08:35:08 <ozataman> and cabal-dev install -fhint does *not* pass the -fhint to underlying dependencies
08:35:30 <dcoutts> ozataman: right, there's currently no sensible way to make the flag persistent
08:35:33 <ozataman> dcoutts: it doesn't change the API, but adds dynamic recompilation capability if you pass in the -fhint flag
08:35:55 <dcoutts> ozataman: but what you can do is tell cabal you want to use an installed instance of snap
08:36:14 <ozataman> hmm. what's a good way to do that?
08:36:15 <dcoutts> then it'll use the existing instance (or fail if the deps conflict)
08:36:22 <dcoutts> --constraint='snap installed'
08:36:28 <ozataman> ah! didn't know that.
08:36:31 <ozataman> let me try
08:36:39 <dcoutts> again, iirc this is with the dev version of cabal-install I think
08:36:53 <_mpu> Hi, is there a way to tell cabal to build a specific module.
08:37:06 <ozataman> I think cabal-dev now supports everything cabal supports, so should work
08:37:30 <dcoutts> ozataman: the workaround for the released version would be to bump the snap version locally and say you want to use that version (for which there is only the installed instance available)
08:37:35 <_mpu> I am adding a new feature to a program in a new module, but it is not yet needed as a dependency, yet I would like to compile it.
08:38:03 <dcoutts> _mpu: no, not yet, I'm just getting round to adding 'cabal build <component-name>'
08:38:32 <dcoutts> _mpu: the problem with a module that does not belong to any component would be that cabal would not know which environment to use
08:38:48 <ozataman> dcoutts: yeah, or I could add-source a customized version of snap that has the -fhint flag by default
08:39:00 <_mpu> dcoutts, I added it to an executable section of my cabal file.
08:39:14 <_mpu> dcoutts, in "other-modules".
08:39:38 <dcoutts> _mpu: ok, but as I say, that feature isn't available yet
08:42:40 <_mpu> Is there a temporary fix?
08:43:16 <dcoutts> _mpu: import the module
08:43:22 <dcoutts> so that the main exe depends on it
08:43:33 * hackagebot wai-extra 1.2.0.2 - Provides some basic WAI handlers and middleware.  http://hackage.haskell.org/package/wai-extra-1.2.0.2 (MichaelSnoyman)
08:43:56 <yrlnry> mauke:  okmij had a tutorial on delimited continuations that was exactly what I needed, so thanks for the reference.
08:57:43 <mizu_no_oto> What's the term for assigning the type of the righthand side of a declaration to the right?  i.e. what C# does when you say "val foo = 0.0".  Is it also called type inference, or is there another term for this anemic level of support for inferring types?
08:58:07 <koeien> type inference, yes
08:58:47 <ciaranm> it's worth noting that c# and c++ do it "the wrong way round"
08:59:05 <mizu_no_oto> In what way?
08:59:47 <ciaranm> inside-out rather than outside-in. or if you prefer, they work out the type on the right.
08:59:54 <mizu_no_oto> ah
09:00:06 <ciaranm> :t 2 + 2
09:00:07 <lambdabot> forall t. (Num t) => t
09:00:44 <ciaranm> if you did that in c# or c++ it would use the 2 + 2 to decide that the type is an int
09:01:16 <ciaranm> in haskell it doesn't decide that it's an Int or whatever until you do something with it that needs it to be that
09:02:12 <mizu_no_oto> Isn't that because numeric literals in haskell have the type (Num t) => t?
09:02:18 <quicksilver> is that a fair comparison, ciaranm ?
09:02:19 <koeien> no
09:02:20 <ciaranm> not specifically
09:02:26 <koeien> that's a coincidence of this example
09:02:34 <quicksilver> if you say "True == False"
09:02:39 <koeien> :t mempty `mappend` mempty
09:02:40 <bitonic> I agree with quicksilver
09:02:40 <lambdabot> forall a. (Monoid a) => a
09:02:48 <quicksilver> then haskell decides that is Bool straightaway
09:02:50 <quicksilver> doesn't it?
09:02:53 <bitonic> the problem in that case is that number literals are not polymorphic in C++/C#
09:02:54 <ciaranm> because == requires it
09:03:04 <quicksilver> also because True,False require it.
09:03:07 <bitonic> not something about C++/C# inference engine itself
09:03:41 <quicksilver> "2" being very polymorphic in haskell seems to be muddying the water, at least
09:03:53 <quicksilver> can you give an example that doesn't rely on polymorphic literals?
09:04:10 <bitonic> but if there was an abstract class "Number" and + "(Number, Number) -> Number" it'd probably work (I don't know the details of C++ auto)
09:04:54 <ciaranm> > let f = mempty in "foo" ++ f
09:04:56 <lambdabot>   "foo"
09:05:02 <ciaranm> you can't really do that in c++
09:05:17 <ciaranm> c++ overloading rules hate you if you have overloads that differ only by their return type
09:05:31 <wheely_mc> @pl (\f g x y -> f $ g x y)
09:05:31 <lambdabot> (.) . (.)
09:05:49 <hpc> wheely_mc: also known as fmap . fmap, also known as (.:)
09:06:07 <hpc> :t (.:)
09:06:08 <lambdabot> forall a b (f :: * -> *) (g :: * -> *). (Functor f, Functor g) => (a -> b) -> f (g a) -> f (g b)
09:06:08 <wheely_mc> haha oh wow
09:06:15 <hpc> > (f .: g) x y
09:06:15 <ciaranm> c++ uses the type of parameters to decide which overload to select. haskell uses the expected type to decide.
09:06:16 <lambdabot>   Ambiguous type variable `a' in the constraints:
09:06:16 <lambdabot>    `GHC.Show.Show a'
09:06:16 <lambdabot>      a...
09:06:20 <hpc> > (f .: g) x y :: Expr
09:06:21 <lambdabot>   Ambiguous type variable `a' in the constraints:
09:06:21 <lambdabot>    `SimpleReflect.FromExpr ...
09:06:23 <hpc> :(
09:06:23 <wheely_mc> I was wondering whether to make up a name for it and (.:) was my first idea
09:06:45 <byorgey> wheely_mc: heh, nice =)
09:06:50 <hpc> :t (.:) . (.:)
09:06:51 <lambdabot> forall (f :: * -> *) (g :: * -> *) a b (f1 :: * -> *) (g1 :: * -> *). (Functor f, Functor g, Functor f1, Functor g1) => (a -> b) -> f (g (f1 (g1 a))) -> f (g (f1 (g1 b)))
09:06:53 <quicksilver> ciaranm: you're talking about overload resolution, not type inference.
09:06:57 <hpc> :t (.:) . fmap
09:06:58 <lambdabot> forall (f :: * -> *) (g :: * -> *) a b (f1 :: * -> *). (Functor f, Functor g, Functor f1) => (a -> b) -> f (g (f1 a)) -> f (g (f1 b))
09:07:05 <quicksilver> in my (very very limited) understanding of C++ those are totally different things.
09:07:17 <hpc> wheely_mc: for extra fun, each level deeper adds another ':' to the name
09:07:21 <quicksilver> overload resolution has been in C++ forever, it was a core feature.
09:07:23 <ciaranm> quicksilver: c++11 has "type inference" now
09:07:28 <quicksilver> type inference in C++ is brand new.
09:07:39 <zhulikas> :t (...)
09:07:40 <lambdabot> Not in scope: `...'
09:07:41 <quicksilver> I thought we were talking about a difference in type inference.
09:08:21 <bitonic> ciaranm: well without type inference there is nothing to compare :P
09:08:23 <shergill> c++/c# infer types only in a very limited sense. if you define variables you have to give it their type
09:08:56 <ciaranm> shergill: not in c++11
09:09:09 <ciaranm> c++11 lets you do "auto foo = expr;"
09:09:10 <shergill> yeah i don't know about that beast
09:09:35 <sap> how can i debug a program with ghci when ghci won't stop or react to ^C any more?
09:09:46 <ciaranm> the point is, c++ works out the type "on the right". haskell knows what it expects "on the left", and works out how to get the thing on the right into that type
09:10:23 <ciaranm> hence c++ having a clusterfuck of weird conversion rules for integerish things
09:10:37 <bitonic> ciaranm: I don't get what you're saying
09:11:09 <bitonic> well yeah the problems with numbers and coercions are involved but unrelated to the concepts behind type inference
09:11:15 <elliott> sap: try holding Ctrl+C
09:11:21 <elliott> failing that, Ctrl+Z, kill -9 %%
09:11:26 <elliott> then restart ghci
09:11:36 <bitonic> I'd imagine that C++ tries to figure out types in a similar way (with auto)
09:11:52 <sap> elliott: holding won't help, i can kill it, but then i still don't know where the program loops infinitely
09:12:06 <ciaranm> bitonic: c++ does it from the inside out. haskell does it from the outside in.
09:12:11 <elliott> sap: divide and conquer -- test smaller parts until you find the smallest bit that loops
09:12:21 <elliott> sap: or try the ghci debugger with breakpoints and stuff (I've never used it, see the manual)
09:12:24 <bitonic> ciaranm: that is vague. I still don't get the difference.
09:12:24 <shergill> ciaranm: could you give an example? the first one seemed to rely on polymorphic numbers, and with the second i'm not sure what the corresponding thing in c++ would be, since i didn't know it had a mappend
09:12:37 <ciaranm> ok, maybe 'read' is a better example
09:12:58 <ciaranm> you can't do "auto x = read();" or something similar in c++11
09:13:25 <bitonic> ciaranm: something like Read is not expressible in C++ type system in the first place
09:13:35 <sap> elliott: ok, i thought i could get around that, because it is a lot of code to check. does the fact that it won't react to ^C imply that the loop does not do any memory allocations?
09:13:36 <ciaranm> you also can't have a "read()" that would let you do "int x = read();" and "string x = read();" without doing a very sneaky trick
09:13:51 <parcs`> templates are sneaky?
09:14:02 <ciaranm> parcs`: not a template. a template with an implicit conversion.
09:14:19 <ciaranm> you'd have to specify int x = read<int>();
09:14:22 <bitonic> ciaranm: what's the type of 'read()' in C++?
09:14:26 <elliott> sap: well, you can do a binary search from small to big parts, can't be that slow :) and yes, I think so, but I'm not sure
09:14:32 <elliott> since it's an async exception
09:14:33 <ciaranm> bitonic: template <typename T> T read();
09:14:35 <elliott> and those are handled on allocation
09:14:50 <bitonic> ciaranm: exactly, it's not expressible in the type systems, and you have to resort to templates
09:15:01 <ciaranm> bitonic: templates are part of the type system
09:15:21 <bitonic> ciaranm: no, templates are just macros, afaiu :P
09:15:30 <quicksilver> ciaranm: what you're talking about is being unable to successfully overload on return values
09:15:37 <quicksilver> I still don't see how that's related to type inference
09:16:02 <quicksilver> it's a widely understood shortcoming of C++ but not particularly related to whether C++'s (limited) type inference is in a different order to haskell's
09:16:04 <ciaranm> the reason you can't overload on return values, via templates or anything else in c++, is because types are calculated from the inside out
09:16:20 <bitonic> ciaranm: "types are calculated from inside out" doesn't mean anything...
09:16:40 <bitonic> if you're asking C++ to figure out what to put as 'T' in that C++ generic function, that is a different thing
09:16:40 <sap> ciaranm: "bottom up"?
09:16:42 <elliott> ciaranm: I think you're trying to say "C++ doesn't have Hindley-Milner", which is true
09:16:43 <ciaranm> given an expression, you determine its type in c++ by looking at the bottom of the parse tree, and working upwards
09:16:46 <elliott> but it still has type inference, it's just limited
09:16:59 <sap> elliott: ok, i'll start digging then. thanks
09:17:25 <elliott> sap: but you might find the ghci debugger helpful.
09:18:13 <quicksilver> elliott: also, "overload resolution" and "type inference" are different things in C++, although part of the same process in haskell.
09:18:22 <bitonic> ciaranm: the fact that you do inference like that doesn't have anything to do with the fact that it doesn't fill in template parameters
09:18:58 <ciaranm> bitonic: c++ does "fill in template parameters". just not on return types.
09:19:53 <ciaranm> and the reason it doesn't fill them in on return types is because the algorithm for working out the type of an expression starts at the bottom right of the parse tree
09:19:56 <bitonic> ciaranm: ok, I get what you're saying now, it has to know the type of something immediately
09:20:12 <ciaranm> yes, that
09:20:25 <bitonic> it doesn't do unification it just gets the type of the function and infers that - I suppose
09:20:39 <bitonic> in which case yes, it sucks, but C++ type systems is completely different to begin with
09:21:27 <bitonic> I mean even if it "looked ahead", that template parameters could only be intantiated once, so it couldn't be truly polymorphic anyways
09:21:47 <ciaranm> well yes. i wasn't saying it was a good idea. just that mizu_no_oto's question when answered in haskell terms isn't representative of how c++ or c# work.
09:24:18 <bitonic> I still wouldn't say it works "opposite" to Haskell type systems. It's just geared to the fact that C++ is not polymorphic
09:24:24 <bitonic> *type inference.
09:39:18 <mm_freak> what's the EitherT you would normally use?  mtl only has a very ugly ErrorT
09:39:56 <elliott> mm_freak: there's http://hackage.haskell.org/package/EitherT
09:40:21 <elliott> mm_freak: maybe you could ask edwardk to smuggle one in :P
09:40:44 <edwardk> mm_freak: check 'either'
09:40:57 <mm_freak> i'm checking 'either' right now
09:41:00 <bitonic> mm_freak: what's wrong with ErrorT?
09:41:14 <mm_freak> how do you throw an error?  return . Left?
09:41:17 <edwardk> bitonic: the largely unnecessary error constraint on Left
09:41:23 <mm_freak> bitonic: the Error constraint
09:41:37 <edwardk> bitonic: it mucks up lots of perfectly good uses of the monad
09:41:46 <bitonic> the error constraint has nothing to do with ErrorT itself eh.
09:41:48 <parcs`> i take it EitherT has the default fail implementation
09:41:51 <parcs`> ?
09:41:52 <mm_freak> edwardk: am i missing an instance for throwing errors?
09:42:01 <bitonic> mm_freak: MonadError
09:42:13 <bitonic> of which ErrorT is an instance
09:42:13 <edwardk> bitonic: it infects the normal Monad instance because of 'fail'
09:42:20 <mm_freak> bitonic: EitherT from 'either' doesn't have a MonadError instance
09:42:23 <edwardk> parcs: yes
09:42:33 <bitonic> edwardk: that's true
09:42:53 <bitonic> I thought you were complaining about the data type itself
09:43:12 <bitonic> mm_freak: sorry, I thought you were still talking about ErrorT
09:43:26 <edwardk> bitonic: this means that you can't make generalized apomorphism with ErrorT that are dual to zygomorphisms, etc.
09:43:47 <edwardk> all in the interest of supporting a rather misguided feature
09:43:47 <bitonic> damn, I won't sleep tonight :D
09:43:47 <elliott> mm_freak: hoistEither?
09:43:53 <elliott> hoistEither . Left would work
09:44:03 * bitonic goes to look what an apomorphism and a zygomorphism is
09:44:22 <mm_freak> elliott: yeah, seems to be the best way
09:44:44 <edwardk> an apomorphism is dual to the notion of a paramorphism ;)
09:44:49 <bitonic> edwardk: ahhhh, that
09:45:01 <mm_freak> ok, i'll go with 'either'
09:45:02 <mm_freak> thanks
09:45:03 <edwardk> inparticular its a way to unfold a structure where you are free to say 'and this is the rest' all at once
09:45:21 <bitonic> edwardk: anyways, I can see why that constraint is annoying without resorting to CT :)
09:46:08 <shergill> hmm excuse me if this is a dumb question, but i never understood the reason behind 'fail'. is there one? from what i understand of monads they can do without a fail
09:46:16 <shergill> monads in the general sense
09:46:28 <bitonic> shergill: absolutely
09:46:31 <edwardk> shergill: it exists because the commitee had a bout of insanity in 98
09:46:34 <bitonic> 'fail' is a big mistake
09:46:36 <elliott> shergill: do { pattern <- m; ... }
09:46:50 <elliott> shergill: if pattern is refutable (e.g. x:xs), then it'll translate to
09:46:55 <elliott> @undo do { pattern <- m; blah }
09:46:55 <lambdabot> m >>= \ pattern -> blah
09:46:58 <elliott> ugh!
09:47:01 <shergill> right the case of thingy
09:47:03 <elliott> @undo do { x:xs <- m; blah }
09:47:03 <lambdabot> m >>= \ a -> case a of { x : xs -> blah; _ -> fail ""}
09:47:06 <elliott> except it's actually
09:47:08 <bitonic> elliott: that's still not a good reason :P
09:47:11 <elliott> fail "an error message with line/column info"
09:47:18 <elliott> bitonic: actually it's very useful when working in MaybeT
09:47:21 <edwardk> shergill: the main reason was that they removed the notion of unfailable patterns in 98. and they didn't want do (x,y) <- …   vs do pair<- …   to change the resulting type
09:47:25 <elliott> you can short-circuit w/ failed pattern matches
09:47:27 <elliott> Just foo <- ...
09:47:32 <elliott> however
09:47:33 <bitonic> elliott: ofc, but we should have a MonadFail
09:47:38 <elliott> yes
09:47:43 <elliott> of course :)
09:47:50 <elliott> but it's actually useful, just not as part of Monad
09:48:01 <bitonic> elliott: I don't think shergill was questioning that ehe
09:48:16 <elliott> well, i thought shergill might not know why it's there
09:48:24 <elliott> as in, at all
09:48:27 <elliott> which is what their question was, after all :)
09:48:40 <edwardk> shergill: anyways, its not theoretically part of a monad in the proper sense, but we're stuck with it
09:49:22 <bitonic> shergill: as we're stuck with Monad m not having an Applicative m constraint
09:50:07 <shergill> yeah i don't get that either. would it really be complicated to just have a conversion script which adds those constraints?
09:50:11 <elliott> we just need someone with haskell.org access to move fail into MonadFail and add an Applicative constraint to Monad in the master copy of the spec right before they release it
09:50:27 <elliott> shergill: writing such a script makes such a change more likely, I would think
09:50:33 <elliott> plenty of people have said it's trivial, nobody has bothered to actually do it
09:50:37 <edwardk> shergill: the problem is you require everyone who has a monad they defined themselves to add the missing instances. it should be done, but inertia is strong ;)
09:51:13 <elliott> that's what the script would do
09:51:14 <shergill> well i guess there's a project for my free time
09:51:39 <elliott> shergill: it shouldn't be overly difficult but you will have to be careful
09:51:50 <elliott> for instance haskell-src-exts is probably not viable because it'd reformat the entire codebase
09:52:01 <c_wraith> edwardk: I really can't believe that'd be more work than the Num change was...
09:52:05 <elliott> but just doing textual stuff makes handling all the details of the syntax hard
09:52:13 <edwardk> c_wraith: the num change broke surprisingly little code
09:52:22 <bitonic> c_wraith: it will in terms of amount of characters to delete/add
09:52:33 <luite> haskell-src-exts can preserve layout
09:52:38 <edwardk> c_wraith: and there seems to be general consensus on making the applicative change
09:52:44 <elliott> luite: perfectly? including extraneous newlines and the like?
09:52:53 <edwardk> though there were some surprising holdouts, like oleg piped up
09:53:10 <edwardk> which was funny because he made a rather fundamental misunderstanding of haskell in his post ;)
09:53:12 <luite> elliott: yes, though with a few bugs I think
09:53:16 <elliott> honestly I think we should just rip the plaster off and get it over with
09:53:21 <elliott> edwardk: heh, what was that?
09:53:27 <edwardk> digging it up
09:53:38 <shergill> heh
09:53:53 <bitonic> no. no.
09:53:54 <luite> elliott: but it's really annoying having to update all position info in the ast if you change something in the code
09:53:56 <edwardk> we all have off days ;)
09:53:56 <bitonic> oleg can't be wrong.
09:54:23 <hpc> bitonic: he can, but only in universes with incoherent axioms
09:54:29 <elliott> luite: exactly, but it's very important that such a conversion script not disturb any formatting
09:54:45 <elliott> hpc: that means he's right too, though
09:54:56 <luite> elliott: as long as the converted values are never longer than the original ones it's simple :)
09:54:57 <shergill> ok, now to play the devil's advocate. is there stuff which can't be done currently, or is harder atm because of fail being a part of Monad, and there being no Applicative constraint?
09:55:25 <bitonic> shergill: of course not, it's just annoying
09:55:45 <shergill> bitonic: it's annoying because it's inelegant?
09:55:50 <hpc> you can always get an Applicative instance out of a Monad
09:55:55 <hpc> and you can always let fail = error
09:55:56 <bitonic> shergill: it's annoying to add constraints that are not needed.
09:56:08 <bitonic> if I want to use <$> and I already have Monad, I have to add Applicative.
09:56:14 <hpc> bitonic: just Functor
09:56:21 <hpc> but that's missing too :P
09:56:24 <bitonic> fail is even more annoying, since you can easily pepper your code with partiality without realising.
09:56:49 <k0ral> hi, is there a Boolean class or something similar, that would make it possible to evaluate instances of a type as True or False ?
09:57:20 <hpc> :t filter
09:57:21 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
09:57:26 <elliott> <luite> elliott: as long as the converted values are never longer than the original ones it's simple :)
09:57:26 <hpc> just pass predicates
09:57:31 <elliott> luite: no values to convert
09:57:45 <ion> hpc: Wow. I had trouble parsing the question.
09:57:59 <elliott> luite: in fact the only thing that needs to be done is adding { instance $ctx => Applicative $m where pure = return; (<*>) = ap } whenever you see { instance $ctx => Monad $m where ... }
09:58:11 <elliott> luite: (and an { import Control.Applicative (Applicative) } as appropriate)
09:58:49 <elliott> hpc: I... don't understand the question, but I don't think your answer answers it :P
09:58:55 <luite> ah, that should be doable
09:59:47 <bitonic> elliott: no, that won't work (if we have Applicative m => Monad m)... or maybe I'm misunderstanding what you wawnt to do?
10:00:06 <bitonic> wawnt!
10:00:14 <luite> although I've been using haskell-src-exts to rename modules and I stopped doing that (using some GHC API code instead now) because it was so annoying :)
10:00:21 <hpc> k0ral: there's no class pre-made, and such a class wouldn't be particularly useful
10:00:27 <elliott> bitonic: huh? yes it will.
10:00:42 <elliott> that kind of "circularity" (not actually circular, really) is perfectly permissible
10:00:50 <elliott> bitonic: if you don't believe me, write an Applicative instance, and do
10:00:59 <hpc> k0ral: compare "class IsBool a where predicate :: a -> Bool" with "predicate :: YourType -> Bool"
10:01:00 <elliott> instance Functor F where fmap = (<*>) . pure
10:01:01 <bitonic> elliott: really? whoa
10:01:02 <elliott> it'll work perfectly
10:01:06 <bitonic> elliott: my bad then, sorry
10:01:17 <elliott> hehe, no problem, it's a bit unintuitive
10:01:22 <elliott> but it's really convenient
10:01:27 <bitonic> well it is intuitive, but it's great
10:01:33 <bitonic> you'd think that it wouldn't be smart enough
10:01:55 <elliott> well, if (>>=) can use (>>=) (which of course it has to be able to) then it's easier to allow that then to deny it
10:02:02 <elliott> you just do it "globally" rather than per-instance
10:02:09 <k0ral> hpc: I have to call predicate with different names for each "boolean" type in the second case
10:02:33 <elliott> k0ral: why do you have types isomorphic to booleans?
10:02:34 <k0ral> hpc: the first case makes it possible to use the symbol "predicate" for any of them
10:02:55 <elliott> if there is no meaning to the predicate other than a trivial conversion, then your type is useless, it's just Bool!
10:03:01 <elliott> if there is meaning, it deserves a proper name
10:03:12 <k0ral> elliott: first, because I want to manipulate meaningful-named types, rather than bare Bool
10:03:40 * hackagebot http-conduit 1.4.0.1 - HTTP client package with conduit interface and HTTPS support.  http://hackage.haskell.org/package/http-conduit-1.4.0.1 (MichaelSnoyman)
10:03:44 <k0ral> elliott: second, because there are things one can evaluate to True or False, and such things are of various types
10:04:39 <enu> @reduce
10:04:39 <lambdabot> Unknown command, try @list
10:04:42 <enu> @list
10:04:43 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
10:04:47 <k0ral> for the first example, it's because I want to wrap an API that works with Bool
10:04:57 <elliott> if they're meaningful, then "predicate" isn't
10:05:08 <elliott> data FileStatus = FileFound | FileNotFound
10:05:12 <elliott> isFound :: FileStatus -> Bool
10:05:15 <enu> @pointful (((last.splitDirectories) path)++)
10:05:16 <lambdabot> (\ a -> (last (splitDirectories path)) ++ a)
10:05:24 <elliott> that's much more readable than "predicate", which offers no clue as to what its return value represents
10:05:25 <enu> @pointfree (((last.splitDirectories) path)++)
10:05:25 <lambdabot> Unknown command, try @list
10:05:25 <k0ral> I'm using f :: Bool -> Bool -> Bool -> Result
10:05:32 <elliott> which is why you made a new type in the first place
10:05:40 <enu> @pointless (((last.splitDirectories) path)++)
10:05:40 <lambdabot> (last (splitDirectories path) ++)
10:06:15 <k0ral> I want to wrap f to get meaningful types: f' :: IsItPropertyA -> IsItPropertyB -> IsItPropertyC -> Result
10:06:24 <k0ral> (arbitrary example of course)
10:06:57 <enu> @pl (((last.splitDirectories) path)++)
10:06:58 <lambdabot> (last (splitDirectories path) ++)
10:07:32 <k0ral> I want to call f' propertyA noPropertyB noPropertyC instead of f True False False which isn't understandable without looking at the function definition
10:07:32 <enu> @pl f path = (((last.splitDirectories) path)++)
10:07:33 <lambdabot> f = (++) . last . splitDirectories
10:08:53 <k0ral> elliott: well, maybe I should simply do like this, indeed
10:10:16 <Zedrikov> Hi, is there some generalisation «gen» of «words» and «lines», such that «words == gen ' '» and «lines == gen '\n'», or do I have to define one?
10:10:49 <elliott> <k0ral> I want to call f' propertyA noPropertyB noPropertyC instead of f True False False which isn't understandable without looking at the function definition
10:10:53 <elliott> why not write f' directly, and skip f?
10:11:17 <c_wraith> Zedrikov: that's not actually how words works.
10:11:21 <elliott> but. e.g., I think f' = f <$> isAmazing <*> isFound <*> isEnabled looks fine
10:11:29 <c_wraith> > words "foo bar\tbaz"
10:11:29 <lambdabot>   ["foo","bar","baz"]
10:12:05 <c_wraith> @hoogle a -> [a] -> [[a]]
10:12:05 <lambdabot> Data.List intersperse :: a -> [a] -> [a]
10:12:06 <lambdabot> Data.List insertBy :: (a -> a -> Ordering) -> a -> [a] -> [a]
10:12:06 <lambdabot> Data.List deleteBy :: (a -> a -> Bool) -> a -> [a] -> [a]
10:12:14 <c_wraith> @hoogle splitOn
10:12:14 <lambdabot> Data.Text splitOn :: Text -> Text -> [Text]
10:12:14 <lambdabot> Data.Text.Lazy splitOn :: Text -> Text -> [Text]
10:12:18 <magicman> @hackage split
10:12:18 <lambdabot> http://hackage.haskell.org/package/split
10:13:41 <Zedrikov> c_wraith: Thanks
10:15:49 <k0ral> @hoogle <*>
10:15:50 <lambdabot> Control.Applicative (<*>) :: Applicative f => f (a -> b) -> f a -> f b
10:17:28 <elliott> k0ral: it's applicative notation
10:17:29 <killy9999> is there a way to remove temporary files created by cabal-install? Except for doing it manually of course
10:17:30 <elliott> that's equivalent to:
10:17:35 <killy9999> ?
10:17:40 <elliott> k0ral: ...wait, no
10:17:41 <c_wraith> killy9999: cabal clean ?
10:17:46 <elliott> k0ral: sorry: i am an idiot, my code exmple wouldn't work
10:18:18 <k0ral> elliott: I wish it did, would have been really elegant
10:18:49 <killy9999> c_wraith: I mean after installing packages from Hackage using cabal install --global some_package
10:19:06 <killy9999> cabal clean seems to refer to cleaning after building my own package
10:19:16 <Luke> is there a strict version of mapM_?
10:19:38 <killy9999> I just discovered that my / partition is almost full and that's due to installoing GHC and packages from Hackage
10:20:23 <Luke> I'm trying to use copyFile but it's not doing anything I think because of lazyness
10:20:40 <c_wraith> killy9999: ah.  there's nothing tool-assisted then.
10:20:46 <elliott> k0ral: i think it might be possible to define combinators such that that does work :) but i'm not sure
10:20:59 <c_wraith> Luke: mapM_ is strict if (>>=) is.  Which it is, for IO.
10:21:01 <killy9999> crap...
10:21:22 <dcoutts_> killy9999: there's not that much in the way of temp files, there's the downloaded source .tar.gz files, other than that it's just the actual installed packages
10:21:58 <dcoutts_> killy9999: of course if you've got lots of packages installed for old ghc versions you don't need anymore, then you can unregister and delete those
10:22:32 <killy9999> I only have one version of GHC and I don't think I have that many packages
10:22:51 <elliott> killy9999: how much space is GHC+pkgs taking?
10:22:53 <killy9999> 126 packages
10:22:56 <Luke> c_wraith: thanks - not quite sure why my app doesn't do anything but hang then
10:23:18 <killy9999> hard to judge, it's spread in different directories (linux)
10:23:19 <c_wraith> Luke: post the code on hpaste and someone will probably take a look at it for you, if you'd like
10:23:36 <Luke> thanks
10:23:37 <dcoutts_> killy9999: du -sh ~/.cabal ~/.ghc
10:23:41 <killy9999> give me a moment, I'll try to make precise estimation
10:23:44 <k0ral> elliott: I'll spend some time in getting in touch with Functor and Applicative, I have the feeling this can simplify my code a lot :)
10:24:00 <killy9999> dcoutts_: I'm installing globaly, not in user directory
10:24:33 <dcoutts_> killy9999: ah, then it's in /usr/local/$pkgname
10:24:51 <dcoutts_> erm, /usr/local/lib
10:25:00 <killy9999> /usr/local as a whole is 4.2 GB
10:25:10 <killy9999> so GHC+pkg takes about 3GB'
10:25:32 <hpaste> Luke pasted “Script 1” at http://hpaste.org/66396
10:25:40 <Luke> c_wraith: ^
10:26:12 <elliott> k0ral: yeah, alas it won't help for that :)
10:26:46 <elliott> killy9999: btw, you should generally install as user unless you have a good reason not to
10:26:47 <killy9999> in /usr/locah/lib/PKG_NAME/ghc-7.0.4 I can see *.o and *.a file which are probably left from the compilation process
10:26:59 <killy9999> elliott: why?
10:27:06 <Luke> c_wraith: the pasted code just hangs - not consuming CPU or mem
10:27:13 <killy9999> I mean I'm the only user of my laptop
10:27:25 <c_wraith> Luke: a hang like that usually means you have a recursive definition you didn't expect
10:27:31 <killy9999> and I preffer to have software installed system-wide then in ~
10:27:35 <dcoutts_> killy9999: they're not left overs, they're the installed package files
10:27:38 <killy9999> s/then/than
10:27:50 <killy9999> dcoutts_: OK
10:28:06 <dcoutts_> killy9999: if you deleted those you would not be able to compile packages that depend on those packages
10:28:18 <elliott> killy9999: well, running as root gives cabal strictly more privileges -- unless you have a multiuser machine (or a complex partitioning scheme), it has no benefits
10:28:18 <c_wraith> Luke: and you do.  line 17
10:28:33 <Luke> c_wraith: thanks
10:28:34 <c_wraith> Luke: the files referred to at the end of the line is the same one you're defining
10:28:45 <Luke> oh damn - good catch
10:28:51 <Luke> meant to have a '
10:29:01 <killy9999> elliott: to me it's a matter of keeping software on one partition and user setting on the another
10:29:18 <killy9999> but I think it's a matter of personal preference
10:29:24 <elliott> well, that's whay i meant by complex partitioning scheme
10:29:27 <elliott> *what
10:29:32 <elliott> most people just use one partition nowadays, in which case it's pointless
10:29:36 <ClaudiusMaximus> what's the best way to parallelize something like this?   head . dropWhile f . transpose . map (iterate g)
10:30:05 <killy9999> I don't think that's very complex, for the moment I was thinking you mean LVM based partitions or something like that
10:31:04 <elliott> killy9999: eh, Ubuntu's installer can't do it without manual tweaking, so it's complex ;)
10:31:30 <killy9999> I don't think Ubuntu is a good example :)
10:36:12 <killy9999> I'm trying to construct a binary Tree using Maybe construction
10:36:12 <killy9999> data Tree a = Maybe (a (Tree a) (Tree a))
10:36:36 <dmwit> data Tree a = Tree (Maybe (a, Tree a, Tree a)) -- perhaps?
10:36:39 <killy9999> this compiles - whoch suggests it valid code -- but I don't know how to create a value
10:36:51 <dmwit> killy9999: It compiles, but doesn't do what you think it does. =)
10:37:20 <dmwit> killy9999: For one thing, it defines a new value-constructor named "Maybe"; for another, your type variable "a" has kind * -> * -> *
10:38:05 <killy9999> yeah, ghci complains about kind when I try to create a value
10:38:30 <dmwit> killy9999: Do you want an explanation of what the code you wrote does? Or can you work it out from these hints?
10:38:42 * hackagebot crypto-api 0.10 - A generic interface for cryptographic operations  http://hackage.haskell.org/package/crypto-api-0.10 (ThomasDuBuisson)
10:38:54 * Clint squints.
10:39:42 <killy9999> I'll try to work it out, give me a moment
10:41:16 <dmwit> You could try "fix (\x -> Maybe (x, x))" as a value of the type you wrote.
10:41:35 <dmwit> Also written as "let funnyValue = Maybe (funnyValue, funnyValue)".
10:42:00 <killy9999> dmwit: OK, I give up
10:42:13 <dmwit> right, so, one piece at a time
10:42:15 <killy9999> I mean i understand that a has type *->*->*
10:42:19 <killy9999> OK
10:42:23 <killy9999> I'm listening
10:42:28 <killy9999> reading
10:42:31 <dmwit> data Tree f -- declare a new type constructor Tree
10:42:40 <dmwit> = Maybe -- declare a new value constructor Maybe
10:42:49 <killy9999> overriding the existing one?
10:42:55 <dmwit> There is no existing one.
10:43:02 <dmwit> (Though there *is* a *type* constructor named Maybe.)
10:43:18 <killy9999> argh
10:43:21 <killy9999> right
10:43:22 <dmwit> yeah =)
10:43:35 <killy9999> I confused type constructor and value constructor...
10:43:50 <dmwit> (f (Tree f) (Tree f)) -- this value constructor takes a single value, whose type is "f (Tree f) (Tree f)"
10:44:35 <dmwit> So, for example, you could have a value of type "Tree (,)", and then the constructor would need a tuple of type "(Tree (,), Tree (,))"
10:45:01 <elliott> (Because (,) (Tree (,)) (Tree (,)) = (Tree (,), Tree (,)))
10:45:05 <dmwit> yes
10:45:08 <killy9999> wait a moment
10:45:13 <elliott> (May be easier to see with Tree Either: constructor would take Either (Tree Either) (Tree Either). Infix muddles it there)
10:45:18 <elliott> (Because f = Either.)
10:45:34 <dmwit> Or, given suitable instances, you could have a value of type "Tree Map", and then the constructor would need a Map of type "Map (Tree Map) (Tree Map)"
10:46:16 <dmwit> (It's a bit unusual, but certainly not nonsensical, to have maps whose keys and values are the same type.)
10:46:31 * dmwit tries to think of other type constructors of kind * -> * -> *
10:46:50 <dmwit> ?hoogle * -> * -> *
10:46:50 <lambdabot> No results found
10:47:00 <dmwit> I didn't think that would work. =P
10:47:07 <elliott> dmwit: State?
10:47:13 <dmwit> Cool, yes!
10:47:15 <elliott> Just to be *really* confusing!
10:47:17 * killy9999 knows only Either
10:47:24 <dmwit> Ah, Either is a good one.
10:47:30 <elliott> I already did Either. :(
10:47:40 <dmwit> You could have a "Tree Either", whose constructor would expect something of type "Either (Tree Either) (Tree Either)".
10:47:45 <killy9999> yeah, you did :)
10:47:48 <dmwit> ooo, I missed that.
10:48:16 <dmwit> leftBiasedEitherTree = Maybe (Left leftBiasedEitherTree)
10:48:28 * elliott thinks this is a very funny sort of "tree".
10:48:38 <dmwit> leftFirstTree = Maybe (Left rightFirstTree); rightFirstTree = Maybe (Right leftFirstTree)
10:48:40 <killy9999> how should I create a value of my type?
10:48:52 <elliott> Actually Tree Either ~ Stream Bool.
10:48:55 <dmwit> killy9999: Well, I've been giving examples. =)
10:48:56 <elliott> That's kind of neat.
10:49:07 <dmwit> killy9999: But really you should just fix your data declaration to do what you meant. =)
10:49:17 <elliott> killy9999: In case it isn't clear, your type is really weird, and probably not what you want :P
10:49:39 <elliott> killy9999: For a start, you forgot commas in between a, (Tree a) and (Tree a).
10:49:49 <killy9999> elliott: yes, dmwit already gave me the correct version, now I'm trying to understand what i actually wrote
10:49:49 <elliott> Which is why you can plug in a = Either, because you're actually *applying* a there.
10:49:53 <elliott> Ah, ok.
10:49:59 <dmwit> 13:36 < dmwit> data Tree a = Tree (Maybe (a, Tree a, Tree a)) -- perhaps?
10:50:06 <elliott> Right. Missed that, sorry.
10:50:28 <killy9999> elliott: yes, I was wondering about the commas
10:50:39 <dmwit> Let's see... State (Tree State) (Tree State)...
10:50:52 <dmwit> statefulTree = Maybe get -- ?
10:51:14 <dmwit> First non-recursive one in here. Or is the recursion hiding in there somewhere?
10:51:26 <elliott> nope
10:51:34 <elliott> State a b doesn't have to contain an a or a b
10:51:36 <elliott> so you don't need to recurse
10:51:43 <elliott> wait
10:51:48 <elliott> that was meant to be a question for killy9999 :)
10:51:55 * elliott shuts up
10:52:02 <dmwit> No, I was genuinely thinking aloud.
10:52:06 <dmwit> I agree, no recursion in that one.
10:52:09 <elliott> oh... good, then :P
10:52:35 <elliott> I wonder if that State tree is good for anything.
10:52:44 * killy9999 tries to undestand value examples given by dmwit
10:53:28 <dmwit> Anyway, you may enjoy this type as a next piece of exploration:
10:53:30 <dmwit> ?src Mu
10:53:30 <lambdabot> newtype Mu f = In { out :: f (Mu f) }
10:54:28 <c_wraith> > fix $ In . Just
10:54:28 * killy9999 doesn't know newtype yet :(
10:54:29 <lambdabot>   In (Just (In (Just (In (Just (In (Just (In (Just (In (Just (In (Just (In (J...
10:54:42 <elliott> killy9999: You can think of "newtype" like "data" there.
10:54:55 <elliott> There's a difference, but it doesn't matter much to your thinking about Mu.
10:55:00 <dmwit> killy9999: That's alright, read it as "data" for now. That's subtly wrong... but the subtlety isn't so important here.
10:55:03 <killy9999> it's the Y-combinator?
10:55:25 <killy9999> that's the first impression of looking at it as an equation...
10:55:31 <dmwit> No, the Y-combinator is a value-level thing. It's the corresponding type-level base point for forming recursive types.
10:55:32 <killy9999> Y f = f (Y f)
10:55:58 <dmwit> ...I suppose you might as well think of it as a type-level Y combinator. Y not?
10:56:11 <elliott> it's exactly that
10:56:29 <dmwit> I retract my "No".
10:57:37 <killy9999> hm... does this recursion ever end?
10:57:53 <c_wraith> killy9999: sure, depending on the constructor
10:57:55 <killy9999> I mean in the Y-combinator it obviously depends on the function
10:58:08 <killy9999> I can;t imageing how a type coudl contain a stop condition...
10:58:10 <parcs`> :t In Nothing
10:58:11 <lambdabot> Mu Maybe
10:58:20 <c_wraith> :t In (Just (In Nothing))
10:58:21 <lambdabot> Mu Maybe
10:58:33 <parcs`> Mu Maybe is like a [()]
10:58:57 <killy9999> is Mu defined somewhere in the libs? I can't hoogle it
10:59:15 <parcs`> not in the standard libs at least
10:59:17 <elliott> not in base
10:59:20 <killy9999> ok
10:59:24 <elliott> <killy9999> I can;t imageing how a type coudl contain a stop condition...
10:59:30 <elliott> by not containing a value of the type it gets given
10:59:31 <elliott> for example
10:59:34 <elliott> data Maybe a = Nothing | Just a
10:59:41 <elliott> In Nothing :: Mu Maybe
10:59:47 <elliott> because Nothing :: Maybe a, and so Nothing :: Maybe (Mu Maybe)
10:59:48 <killy9999> OK
11:00:05 <elliott> but for In (Just x), x has to be a Mu Maybe again... so it can be In Nothing, or In (Just y), where y is a Mu Maybe... etc. :)
11:01:00 <killy9999> why does lambdabot know about Mu if it's not in the libs? :)
11:01:14 <wieczyk> Hi, could someone give me good paper/points about higher order polymorphism in programming languages? I am preparing seminar on my university about this. We have already lectures for system F, we are basing on Pierce's book.
11:01:18 <elliott> killy9999: lambdabot has some wild ideas
11:01:19 <wieczyk> But for Fomega Pierce is only giving small intuitions and a lot of meta theory. I would like to tell also about some usage of Fomega, or some subset of Fomega, or sth like this.
11:01:19 <elliott> :t (.)
11:01:19 <ezyang> Did someone right a semantic editor combinator library?
11:01:19 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
11:01:24 <ezyang> *write
11:01:26 <elliott> :t (.:)
11:01:26 <lambdabot> forall a b (f :: * -> *) (g :: * -> *). (Functor f, Functor g) => (a -> b) -> f (g a) -> f (g b)
11:01:29 <elliott> it's not the most standard of things :)
11:01:44 <elliott> ezyang: http://hackage.haskell.org/package/sec?
11:02:08 <ezyang> Fancy.
11:02:26 <ezyang> I'm not quite sure this is what I want. My access pattern is more like I want multiple fingers into a tree.
11:02:57 <elliott> ezyang: Sounds like you want a multi-zipper.
11:03:00 <elliott> Oleg has some stuff on that.
11:03:23 <elliott> I find his presentation quite ugly though. I've played around with multi-zipper constructions for a tree. It's quite possible but rather hairy to code up.
11:03:34 <killy9999> wieczyk: what university are you on?
11:03:52 <ezyang> Yeah, I don't actually want all the hair, and the structures aren't going to be that big.
11:04:01 <ezyang> But a nice elegant way of doing it would be kind of nice :-)
11:04:21 <c_wraith> conal also had some zipper ideas
11:04:29 <wieczyk> killy9999: of Wroclaw, Poland
11:04:36 <c_wraith> writing them in terms of themselves, for instance
11:04:53 <elliott> ezyang: Well, you can always just store a bunch of paths, and recreate the zipper every time you want to go to another part.
11:05:00 <elliott> ezyang: That'll be slow as heck, but....
11:05:10 <ezyang> bleh
11:05:13 <elliott> ezyang: This is pretty easy with mutable references ;)
11:05:23 <killy9999> wieczyk: I'm from Poland, so I'm curious which Uni does that kind of stuff
11:05:25 <ezyang> I actually do need persistence here.
11:05:25 <elliott> Note that a multi-zipper construction... probably isn't that fast either.
11:05:38 <elliott> My way involves a lot of tree-splitting and splicing and reorganising. I forget how Oleg's works.
11:05:43 <ezyang> I mean, if the trees are small probably just doing a path copy is pretty zippy.
11:05:51 <killy9999> wieczyk: Politechnika Łódzka, BTW :)
11:05:52 <elliott> ezyang: But see http://okmij.org/ftp/continuations/zipper.html#zipper2.
11:07:02 <wieczyk> killy9999: Warsaw, Wroclaw, and Krakow are doing loing logic, so on each of those universities you can find type-theory and functional stuff.
11:07:10 <wieczyk> remove "loing"
11:10:54 <ezyang> I know! I'll use higher-order abstract syntax for the holes.
11:11:21 <ezyang> Hmm, but that doesn't really work if I have multiple holes.
11:12:15 <elliott> ezyang: Are you sure you can't use mutable refs + copying?
11:12:57 <ezyang> Mutable refs are annoying in Haskell.
11:13:39 <c_wraith> honestly, they're annoying everywhere.  Haskell just makes you regret using them even before anything goes wrong. :)
11:13:47 <dmwit> ezyang: Lenses. =)
11:14:20 <emcc> haskell makes them hard enough that you don't use them gratuitously
11:15:02 <dmwit> Haskell makes immutable references so convenient that you find mutable references inconvenient.
11:15:08 <Mathnerd314> is () -> a isomorphic to a?
11:15:19 <dmwit> Mathnerd314: Depends. How do you feel about bottom?
11:15:32 <alpounet> if you don't include bottom, it is
11:16:18 <emcc> Lenses are based on Pierce's work, yes?  Bidirectional programming languages?  Or is it something else?
11:17:34 <dmwit> the same
11:17:46 <Mathnerd314> ah. I guess (const a) and (\() -> a) are distinguishable
11:17:50 <sclv> I don't know if I'd say Pierce invented 'em though.
11:17:57 <elliott> Mathnerd314: as is _|_ and (const a)
11:17:58 <ezyang> They have some recent work there though
11:18:02 <sclv> he did a lot of work on one type of them, and I think is the origin of the term "lenses"
11:18:04 <dmwit> sclv: Right.
11:18:16 <sclv> but they've been independently discovered/created a few difft ways.
11:18:17 <elliott> emcc: http://stackoverflow.com/questions/5767129/lenses-fclabels-data-accessor-which-library-for-structure-access-and-mutatio is a short intro to the specific definition of lenses being talked about here
11:18:29 <elliott> or, well, many specific definitions i suppose :)
11:19:14 <Mathnerd314> elliott: but those are distinguished when you map them back to a
11:19:50 <elliott> Mathnerd314: Erm
11:19:53 <elliott> Mathnerd314: _|_ and (const _|_) rather
11:19:54 <elliott> (By seq)
11:20:20 <Mathnerd314> @src seq
11:20:21 <lambdabot> Source not found. :(
11:20:31 <c_wraith> now...
11:20:40 <c_wraith> Void -> a is indistinguishable from a
11:20:54 <c_wraith> (well, not really, but you need seq - pattern matching doesn't suffice)
11:21:44 <Mathnerd314> c_wraith: and you do ($undefined) to get back to a?
11:21:57 <dmwit> Mathnerd314: seq is a magical primitive which evaluates its first argument to WHNF, whether that can be done by the API exposed by that datatype or not.
11:21:58 <roconnor_> ezyang: multiplate!
11:22:09 <mm_freak> edwardk: could you please update 'either' to use the latest data-default package?  when using it in a yesod project i get a warning:
11:22:12 <mm_freak> Warning: This package indirectly depends on multiple versions of the same
11:22:14 <mm_freak> package. This is highly likely to cause a compile failure.
11:22:16 <edwardk> sure
11:22:20 <mm_freak> thanks =)
11:22:54 <c_wraith> Mathnerd314: or any other value of the type void.  like fix Void
11:23:23 <Mathnerd314> Void :: ?
11:23:24 <bscarlet> edwardk: Is there anything upcoming for the Boston Haskell Users Group?
11:23:37 <edwardk> bscarlet: i need someone else who wants to give a talk
11:23:42 <roconnor_> Default Double!!
11:23:48 <roconnor_> that's a bit of a stretch
11:24:03 <elliott> Mathnerd314: data Void
11:24:08 <elliott> Mathnerd314: or newtype Void = Void Void
11:24:12 <elliott> the uninhabited modulo _|_ type
11:24:21 <roconnor_> morally uninhabited
11:24:44 <edwardk> bscarlet: i've kind of forced my coworkers to talk a fe too many times, so i need to reach out and expand the pool ;)
11:25:06 <Mathnerd314> I'm not certain fix Void == _|_... it's more like ()
11:25:19 <c_wraith> fix Void is certainly bottom
11:25:30 <c_wraith> newtype constructors are id
11:25:32 <mm_freak> fix Void is a type error
11:25:47 <c_wraith> mm_freak: not with newtype Void = Void Void
11:25:50 <mm_freak> might work with the newtype version though
11:26:23 <c_wraith> > fix id
11:26:27 <lambdabot>   mueval-core: Time limit exceeded
11:26:27 <dmwit> Mathnerd314: pop quiz! "newtype Weird = Weird Weird"; what does "case undefined of Weird _ -> 3" evaluate to (if anything)?
11:26:43 <bscarlet> edwardk: Ah. Thanks. Unfortunately I don't have anything right now, but I'll keep it in mind in case I get anything far enough.
11:26:48 <ezyang> I wonder how Agda represents its holes...
11:27:04 <roconnor_> fix Void isn't a type error with data Void ; it is a sort error. :)
11:28:38 <Mathnerd314> dmwit: undefined?
11:28:40 <roconnor_> edwardk: think Partial lenses should use data-default?  (Default d) => PLens a b -> (b -> d) -> (a -> d)
11:29:19 <edwardk> i don't really like the quotienting by default, i suppose it might make sense as a set of combinators
11:29:39 <Mathnerd314> @let newtype Weird = Weird Weird
11:29:40 <lambdabot>  Invalid declaration
11:30:32 <roconnor_> ezyang: multiplate is like lens except you can have many references
11:30:44 <elliott> <Mathnerd314> I'm not certain fix Void == _|_... it's more like ()
11:30:44 <elliott> it is _|_
11:30:47 <elliott> because newtype, not data
11:30:56 <elliott> anyway, that definition is "obsolete"
11:30:59 <elliott> "data Void" is valid haskell 2010
11:31:26 <dmwit> Mathnerd314: BZZZT! Actually, it evaluates to 3. Surprised? I was!
11:31:40 <Mathnerd314> ok...
11:31:40 <dmwit> Mathnerd314: Turns out pattern matches on newtype constructors always succeed instantly.
11:31:47 <elliott> dmwit: you know, that should really be fixed.
11:31:49 <dmwit> Since they're a figment of the type-checker's imagination anyway.
11:31:56 <dmwit> elliott: wut
11:32:02 <dmwit> elliott: "fixed"?
11:32:06 <elliott> dmwit: it'd be nice if "case foo of Weird _ -> 3" === "foo `seq` 3".
11:32:17 <elliott> it's silly that a single-constructor single-strict-field data behaves differently to newtype, imo
11:32:22 <elliott> and it's obviously very surprising to people who find it out
11:32:45 <elliott> it'd be nice if newtype was a simple optimisation of that rather than having a weird additional semantic quirk based on the operational details
11:33:49 <dmwit> ...but data Weird = Weird !Weird and newtype Weird = Weird Weird are represented differently in memory.
11:34:28 <dmwit> hm
11:34:56 <Mathnerd314> you could go the other way and require case y of { Left _ -> x ; Right _ -> x } = \y -> x
11:35:12 <elliott> dmwit: So?
11:35:16 <elliott> Haskell doesn't say anything about memory.
11:35:43 <elliott> If I wanted the meaning of the language to depend on details of the memory layout of common implementations, I'd... not use Haskell, anyway.
11:35:49 <elliott> s/depend on/be based on/
11:35:55 <dmwit> yes, hence the "hm" afterwards
11:36:01 <dmwit> I'm not convinced by my own argument. =)
11:36:17 <elliott> hehe
11:36:26 <ezyang> Man, this was easier when I didn't need it to be persistent.
11:36:53 <elliott> ezyang: Did I ask whether mutable + copying is really out of the question?
11:36:59 <ezyang> Yep!
11:37:46 <ezyang> I guuess I owe you guys some context: I'm building a front-end to Coq, so I need a proof representation for proofs in progress.
11:38:10 <elliott> ezyang: What about DiffArray-style tricks?
11:38:29 <elliott> Anyway, it's Coq. Just store multiple paths. There's no way your frontend can be slower than Coq itself.
11:38:30 <ezyang> Efficiency is not actually the problem here.
11:38:34 <ezyang> I just want the code as simple as possible.
11:38:38 <elliott> See above, then ;)
11:38:47 <elliott> Trivial tree zipper + storing paths + reconstructing each time.
11:38:58 <roconnor_> ezyang: are all the holes the same type as far as you are concerned?
11:39:04 <ezyang> Yep.
11:39:06 <emcc> the Coq guys published a paper about a theorem proving monad
11:39:10 <emcc> I forget the title
11:39:17 <roconnor_> ezyang: maybe you can use Biplates from Uniplate
11:39:46 <ezyang> roconnor_: I still get really worried about Uniplate when I hear it mentioned :-)
11:39:49 <roconnor_> ezyang: or my yet to be published multi-lens library
11:40:01 <roconnor_> which is the same thingish
11:40:07 <roconnor_> but safer
11:40:12 <roconnor_> and probably slower
11:40:30 <ezyang> Actually, I think variable naming might be a bigger problem here.
11:41:32 <monochrom> I think I can prove "case foo of Weird _ -> 3" === "foo `seq` 3". (if Weird is as in data W = Weird ...)
11:42:13 <dmwit> newtype Weird = Weird Weird -- was the thing elliott was complaining about
11:42:26 <monochrom> right, doesn't work for newtype, I agree
11:43:28 <dmwit> elliott: Okay, I think I have a better understanding of why I like the current behavior.
11:43:49 <dmwit> elliott: One common use case for newtype is to separate two conceptually different types which happen to have the same representation.
11:44:13 <dmwit> elliott: It would be super frustrating if you took code that used the same type for this, added newtypes to differentiate them, and then it behaved differently.
11:44:48 <elliott> dmwit: Ah! But if you make the _minimum_ necessary change, that won't happen.
11:44:56 <elliott> You don't need to transform _ into (C _) to make it work with a newtype.
11:45:09 <elliott> And, of course, _ wouldn't evaluate.
11:45:13 <dmwit> elliott: Forget the minimum change, I want the mechanical change.
11:45:26 <dmwit> Change "case foo of bar" into "case foo of (C bar)".
11:45:31 <dmwit> Everywhere.
11:45:34 <dmwit> So I don't have to think.
11:45:42 <elliott> Well, sure.
11:45:59 <elliott> You deserve what you get if you play with _|_s and don't want to think ;)
11:46:27 <dmwit> I *already* thought about _|_s.
11:46:41 <dmwit> Now you're telling me I have to do it again, and potentially about code somebody else wrote, just because I'm using newtype?
11:47:18 <elliott> I was kidding. I see your point. But I think it's an academic complaint either way, since nobody should use _|_s ever,* and so the more theoretically-pleasing option should be chosen.
11:47:22 <elliott> *Except sometimes. But you should feel bad about it.
11:47:29 <dmwit> lol
11:48:04 <elliott> Anyway, if Haskell were total...
11:48:16 <tgeeky_> elliott: yes. what if?
11:48:47 * hackagebot RSA 1.2.0.0 - Implementation of RSA, using the padding schemes of PKCS#1 v2.1.  http://hackage.haskell.org/package/RSA-1.2.0.0 (AdamWick)
11:49:18 <elliott> tgeeky_: Well, then all these ugly problems about newtypes and _|_ vs. const _|_ and seq being able to change semantics and strictness analysis having to be raelly careful wouldn't exist!
11:49:47 <elliott> *really. I do not believe Raël (http://en.wikipedia.org/wiki/Ra%C3%ABlism) has ever analysed strictness.
11:49:58 <tgeeky_> a naive (related?) question -- when you "total" functions, does this exclude the situation where you've used partial functions (like partial isomorphisms), but have adjoined all necessary elements to act like a total function?
11:50:48 <tgeeky_> elliott: in my last guess, Prelude exported ~ 470 functions or types. How many are partial? A dozen?
11:51:00 <elliott> Well, you could use GADTy-esque type trickery to encode what parts you need to "fill in" to make a function total, with the "empty" case being convertable to a plain function, perhaps...
11:51:30 <elliott> I advocate the addition of unsafePerformPartial, anyway (where Partial is a monad), for when you want to write something the totality checker isn't convinced is OK.
11:51:35 <elliott> tgeeky_: More than that, surely.
11:51:47 <elliott> Many, many instances are partial, esp. of numeric typeclasses and Enum.
11:51:53 <elliott> fix has to go. etc.
11:52:03 <elliott> Really I don't think Haskell should be partial, it's far too major a change.
11:52:10 <elliott> But a language aspiring to be like Haskell but better should consider it.
11:52:16 <tgeeky_> elliott: you mean total?
11:52:19 <elliott> Erm, yes :)
11:52:35 <elliott> (Oh, and I don't want to eliminate partiality entirely -- the IO monad should be able to do everything the partiality monad can.)
11:52:54 <elliott> (Just like Haskell can do IO, but is pure: we control dangerous effects by localising them.)
11:53:37 <tgeeky_> elliott: how many of the ~470 which are pure, are partial? any guesses?
11:53:46 <ezyang> Here's a question: which parser library is best for /simplicity of code you have to write/?
11:53:47 <tgeeky_> is this something that code analysis could understand?
11:53:58 <elliott> ezyang: attoparsec? Or maybe uu-parsing.
11:54:04 <elliott> Both don't have "try" :P
11:54:24 <elliott> tgeeky_: Well, it's trivially undecidable, but you need to change more than the Prelude.
11:54:25 <ezyang> Does attoparsec even work on String?
11:54:28 <elliott> General recursion leads to partiality.
11:54:31 <elliott> ezyang: No, but Text.
11:54:52 <ezyang> "See, as simple as possible code == using String"
11:55:11 <elliott> ezyang: What? Text has a bunch of useful functions String doesn't!
11:55:18 <elliott> But fine :p
11:55:36 * ezyang applies the ASCII assumption, and the performance-doesn't-matter assumption 
11:55:36 <tgeeky_> ezyang: are you repeating someone else's words? why the // and ""?
11:56:09 <ezyang> They're scare quotes.
11:56:31 <monochrom> SQL is the go-to total language
11:56:36 <tgeeky_> oh, those things you put in corn fields to get rid of birds?
11:56:42 <elliott> ezyang: String is ASCII now?
11:56:44 <hpaste> bobajett pasted “simple zip” at http://hpaste.org/66397
11:56:59 <ezyang> It's not, but it does mean I don't need Text's bits and bobs.
11:57:09 <elliott> bobajett: You claim your function works on all "a"s in the type signature: zip1 :: [a] -> [a] -> [a]
11:57:19 <elliott> bobajett: But it only works on "a"s which can be divided, which means "a"s that are instances of the Integral typeclass.
11:57:27 <elliott> bobajett: Thus: zip1 :: (Integral a) => [a] -> [a] -> [a]
11:57:33 <elliott> *integer-divided, to be precise.
11:57:44 <elliott> Read: "For all integral types a, this function works as [a] -> [a] -> [a]".
11:58:06 <elliott> bobajett: Or, specialise it to a single type you want to use, if there is one: zip1 :: [Integer] -> [Integer] -> [Integer]
11:58:13 <ezyang> Maybe I'll just turn on overloaded strings
11:58:20 <bobajett> awesome!! damn that was fast! thanks elliott
11:58:29 <qnikst> hello, I have next problem I want to use polymorphic data-type that should have two operations (+) and *const
11:59:08 <tgeeky_> qnikst: that sounds like a monoid
11:59:09 <qnikst> so in that type I want to use Num, Vector Num, and maybe types or so
11:59:11 <elliott> bobajett: yw :)
11:59:26 <monochrom> what is "*const"?
11:59:36 <qnikst> tgeeky_: yep (+) is exaclty a monoid
11:59:46 <qnikst> monochrom: multiply by a constant
11:59:49 <tgeeky_> qnikst: well, you need a unit (which also must be a constant)
11:59:59 <bobajett> elliott: so the compiler is saying something like "Im looking at your function and it looks like you want to be able to `div`ide two of the "a" together, but I don't have a general notion of `div` for any "a" type?"
12:00:06 <qnikst> i.e. for vector map (*c) f , for Num *c
12:00:18 <elliott> qnikst: Perhaps you want http://hackage.haskell.org/package/vector-space.
12:00:25 <elliott> http://hackage.haskell.org/packages/archive/vector-space/0.8.0/doc/html/Data-VectorSpace.html
12:00:34 <elliott> (*^) is your (*const) (except it's "scalar" not constant).
12:00:45 <elliott> (But it also has negation: http://hackage.haskell.org/packages/archive/vector-space/0.8.0/doc/html/Data-AdditiveGroup.html#t:AdditiveGroup)
12:01:11 <qnikst> will check
12:01:23 <tgeeky_> elliott: I don't think (+) and ((*) const) form a automatically?
12:01:42 <tgeeky_> elliott: oh, yes they do.
12:01:44 <mm_freak> thinking about acid-state:  deserialization can cause the database to take much more memory than before, because when originally created sharing may be involved
12:01:45 <tgeeky_> I see.
12:01:55 <elliott> tgeeky_: Well, you need zeroV and (^+^) too.
12:02:03 <elliott> But it's the closest thing I can parse qnikst's statements into.
12:02:04 <qnikst> elliott: it seems it will be overkill for num types that should be used as vector of one dimesion
12:02:13 <tgeeky_> elliott: you have (+) automatically, by extensionality I think
12:02:24 <elliott> mm_freak: acid-state really wants a serialisation interface that uses observable sharing
12:02:35 <elliott> tgeeky_: oh, wait, (^+^) is the (+) being talked about, yes
12:02:36 <tgeeky_> elliott: maybe you need a distributive and other laws of (+) over/under (*)
12:02:39 <elliott> so it's just zeroV and negateV you need
12:02:48 <elliott> qnikst: I wouldn't call the vector-space package overkill.
12:02:53 <elliott> It's very simple, and preferable to reimplementing it yourself.
12:02:59 <qnikst> ok
12:03:28 <qnikst> why it's preferrable to reimplement, just to understand how it works?
12:03:38 <elliott> No, I said it's best not to.
12:03:38 <tgeeky_> qnikst: when is it, and yes
12:03:43 <elliott> I meant that using the package is preferable to reimplementing it yourself.
12:04:02 <tgeeky_> how does one add a quote?
12:04:11 <tgeeky_> remember, right?
12:04:13 <qnikst> aa
12:04:14 <qnikst> ok
12:04:25 <mm_freak> elliott: i agree, but on the other hand i wouldn't know what that would look like
12:04:33 <mm_freak> seems like a very impure thing to begin with
12:04:59 <elliott> mm_freak: Well, you can just pass the result of running data-reify on it.
12:05:01 <elliott> Which is a simple graph structure.
12:05:25 <tgeeky_> @remember "What I cannot create, I do not understand." -- Richard Feynman, on his blackboard when he died in 1988.
12:05:25 <lambdabot> Okay.
12:06:54 <parcs`> @quote "What
12:06:54 <lambdabot> "What says: I cannot create, I do not understand." -- Richard Feynman, on his blackboard when he died in 1988.
12:07:44 <elliott> "I cannot create, I do not understand." --Feynman
12:07:47 <elliott> -- "What
12:07:55 <elliott> @forget "What I cannot create, I do not understand." -- Richard Feynman, on his blackboard when he died in 1988.
12:07:55 <lambdabot> Done.
12:08:04 <elliott> @remember RichardFeynman What I cannot create, I do not understand. (on his blackboard when he died in 1988)
12:08:05 <lambdabot> I will remember.
12:08:31 <tgeeky_> ugh. it just uses the first word?
12:08:39 <monochrom> yes
12:08:45 * tgeeky_ is disappointed in her
12:08:51 <elliott> no, it uses highly advanced natural language techniques to determine who you wanted to attribute the quote to
12:08:54 <monochrom> (I would answer differently on April 1st)
12:09:08 <monochrom> "it automatically guesses where the name is!"
12:09:10 <tgeeky_> elliott: just fulltextsearch
12:09:20 <tgeeky_> @quote feynman
12:09:20 <lambdabot> No quotes match. I can't hear you -- I'm using the scrambler.
12:09:23 <elliott> tgeeky_: it's for attribution, not search
12:09:27 <elliott> @quote blackboard
12:09:27 <lambdabot> Cale says: I swear that most of higher-dimensional category theory must have been arrived at by some guys sitting around in a room with a blackboard and saying "What if a drew a diagram like *THIS*!?
12:09:27 <lambdabot> " and drawing some insane scribble up on the blackboard, and then everyone tries to figure out how to turn it into meaningful mathematics.
12:09:37 <monochrom> it's for retribution :)
12:10:46 <dixie> I'm not able to compile wxcore on ghc 7.4.1 on archlinux... machine starts swapping
12:11:02 <dixie> ghc grows
12:11:34 <dixie> what can be a cause ? I can not imagine anything.
12:11:46 <elliott> how much ram do you have
12:11:54 <elliott> and is it when linking
12:11:55 <dixie> 1 GB
12:12:04 <elliott> buy more
12:12:13 <elliott> and try the gold linker
12:12:18 <elliott> but first buy more ram
12:12:51 <dixie> elliott: I have been able to compile it in the past. I just reinstaled machine on 64bit linux (I have been using 32bit) and nows this
12:13:17 <elliott> don't use 64-bit linux if you only have 1 gig of ram
12:13:18 <c_wraith> dixie: well, 64-bit *does* mean programs use more memory
12:13:22 <elliott> all the pointers and integers take up twice as much space
12:13:37 <elliott> go back to 32-bit... or buy more ram :)
12:14:11 <dixie> yes, I know it uses more memory... but
12:14:16 <dixie> ok :)
12:14:38 <geekosaur> dixie, it used to be well known that you didn't attempt 64-bit on 1GB systems
12:14:41 <dixie> anyway, I'm surprised :) I didn't take into account that simple fact about twice size of pointers :)
12:14:44 <c_wraith> Yeah, until you have 4 GB, 64-bit is *only* bad.  It's still not great until you have a lot more.
12:15:16 <geekosaur> of course these days everyone "knowsn better", and then winders why it doesn't work.  much like they wnder why 7.4.1 isn't compatible with so many packages that were tested against 7.0.4
12:15:35 <dixie> that was reason why I used the 32bit in the first place. but later my system becomes laggy... after instalation of gnom3
12:16:02 <geekosaur> I think 1GB has more to do with *that* too
12:16:06 <dixie> hence I applied cargo cult science - 64bit must solve my problems :) thanks for helps anyway. I will go back to 32bit
12:16:08 <geekosaur> gnome3 is fairly large
12:16:32 <elliott> dixie: you'll have to buy more ram sooner or later, anyway :p
12:16:40 <elliott> at least if you're going to keep installing and upgrading things
12:16:56 <bobajett> trying to multiple two lists, but can't get my types right. e.g. let amount = [1000,2000] and let percentage = [50,60] and formula is  amount * (percentage/100)
12:16:59 <bscarlet> 64 bit allows a larger _virtual_ address space, regardless of how much RAM you've got.
12:17:03 <dixie> ooop, it seems I have 2 GB
12:17:36 <qnikst> how can I convert Double to current numeric type
12:17:45 <monochrom> use the gold linker nonetheless
12:17:46 <geekosaur> I have a 2GB netbook, it's painful with gnome3.
12:17:48 <edwardk> c_wraith: its not a purely bad thing, the reduced register pressure helps an insane amount
12:17:59 <elliott> bobajett: Amount is a list, not an integer.
12:18:09 <monochrom> qnikst: try realToFrac
12:18:13 <monochrom> example:
12:18:25 <monochrom> > realToFrac (0.3 :: Double) :: Complex Float
12:18:26 <lambdabot>   0.3 :+ 0.0
12:18:42 <geekosaur> real question might be "what are you really trying to do?"
12:18:45 <elliott> bobajett: (Or a float, or any integral type.)
12:18:49 <qnikst> thanks
12:18:54 <elliott> bobajett: Perhaps you want zipWith and map?
12:18:57 <monochrom> no, not integral type
12:19:01 <monochrom> > realToFrac (0.3 :: Double) :: Integer
12:19:02 <lambdabot>   No instance for (GHC.Real.Fractional GHC.Integer.Type.Integer)
12:19:02 <lambdabot>    arising f...
12:19:22 <monochrom> oh nevermind, cross-talk
12:19:34 <edwardk> c_wraith: also, you might want to look at the new x32 abi stuff, running code with 32 bit pointers with the 64 bit extensions turned on, or the hotspot jvm's 'compressed OOPs' which let you address 32 gigs, but use 32 bit pointers
12:20:11 <hpaste> bobajett pasted “trying to multiply two lists” at http://hpaste.org/66398
12:20:17 <elliott> (Ahem. More like compressed oops because it's Java ha ha ha. Sorry.)
12:20:24 <edwardk> elliott: =P
12:20:36 <edwardk> 'object-to-object pointer' ;)
12:20:42 <luite> Trace/BPT trap: 5  <- what does this usually mean?
12:20:49 <elliott> edwardk: Oh, it doesn't even stand for object-oriented programming?
12:20:54 <elliott> They sure like confusion.
12:21:29 <geekosaur> luite: there is no "usually" for that one
12:21:30 <edwardk> basically you can use [base + ptr * 8 + offset] addressing to address a 32 gigabyte region of memory using 32 bit pointers, since that is a builtin addressing mode
12:21:56 <edwardk> as long as everything is aligned on 8 byte boundaries
12:22:34 <luite> geekosaur: hehe it's the first time I see it
12:22:47 <shachaf> When *I* write a program, it uses about 20GB of address space before it even gets going.
12:23:14 <edwardk> note to self, don't hire shachaf for embedded systems work
12:23:42 <bscarlet> shachaf: Wow, when you _write_ it? That's a lot of code. What the heck happens when you _run_ it?
12:23:49 <shachaf> edwardk: Pft. I refuse to program on anything with pointers smaller than 128 bits.
12:24:03 <Enigmagic> i need 68 bit pointers
12:24:03 <elliott> bscarlet: You can't "run" shachaf's code.
12:24:13 <elliott> At best you can admire it.
12:24:14 <iFire> Send me a prototype of your 128bit word machine today!
12:24:22 <iFire> shachaf: :(
12:24:30 <qnikst> another basic question, can I do f :: (VectorSpace (Fractional) a) => a -> a
12:24:30 <qnikst> ?
12:24:35 <geekosaur> luite: getting that signal means either (a) you have a buggy debugger (b) you have a program which expectes to be run under a debugger but isn't (this has not been common since the 1960s or thenabouts) (c) some program is doing raise(SIGTRAP) to indicate an internal error
12:24:41 <shachaf> qnikst: What would that mean?
12:25:09 <luite> geekosaur: hmm, I'd guess (c), and that that program is ghc :)
12:25:15 <qnikst> I need to say that type a should be an instance of VectorSpace a, there a is Fractional
12:25:16 <geekosaur> luite: which is strange but possible, and you would need to find out exactly what library is doing it and why; there is no standard meaning
12:25:25 <elliott> qnikst: (VectorSpace a, Fractional a)
12:25:29 <geekosaur> that's ghc doing it?  huh
12:25:32 <elliott> qnikst: But a VectorSpace probably isn't Fractional.
12:25:35 <elliott> To be Fractional it would have to be Num.
12:25:37 <luite> geekosaur: it happens when loading packages with the ghc api
12:25:41 <elliott> To be Num it would have to have (*) :: a -> a -> a.
12:26:13 <elliott> qnikst: What type do you want division to have in this context?
12:26:25 <bscarlet> shachaf, iFire: 128bit word machines ought to be mainstream in about (128 - 64) * 18 months = 96 years, according to Moore's law, right?
12:26:26 <qnikst> I have: explicitEuler f = \h y -> y ^+^ ((realToFrac h) *^ (f y))
12:26:27 * geekosaur does a search for SIGTRAP in (somewhat dated) source tree
12:26:37 <byorgey> elliott: Double is an instance of both VectorSpace and Fractional.
12:26:44 <shachaf> bscarlet: Seems logical enough!
12:26:48 <byorgey> Rational is too.
12:26:51 <elliott> byorgey: By "probably" I meant something like "almost all VectorSpaces aren't Fractional".
12:26:55 <elliott> Obviously the scalar instances are :)
12:27:03 <elliott> But if you're OK with just scalars, then you don't need VectorSpace.
12:27:14 <elliott> qnikst: Ah, I see.
12:27:19 <elliott> qnikst: What should realToFrac do on vectors?
12:27:41 <elliott> You said you wanted to support vectors as input. I'm not sure how you intend to convert [pi, 123, -4] to, e.g. a Double.
12:27:47 <qnikst> it's on a Double
12:28:03 <elliott> Then just say f :: Double -> Double. You don't need typeclasses at all.
12:28:13 <geekosaur> luite, hm, actually ghc, or maybe ld?  or, if you're using -fllvm, some llvm components might get involved at some point...
12:28:13 <qnikst> explicitEuler :: (VectorSpace a, Fractional  a ) => (a -> a) -> Integrator a
12:28:29 <byorgey> elliott: perhaps qnikst has other instances in mind as well.
12:28:56 <qnikst> a should be at least vector of doubles or complex
12:29:42 <byorgey> sure, you can make a Fractional instance for e.g. pairs of Doubles just by doing the division pointwise.
12:29:44 <Enigmagic> geekosaur: llvm is driven using command line tools not the API
12:29:47 <elliott> byorgey: "it's on a Double" as a reply to my qusetion about a vector instance would seem to contradict that...
12:29:57 <Enigmagic> with -fllvm
12:30:11 <elliott> But yes, I did suggest (VectorSpace, Fractional a) before, I was just warning that it might not be what you want.
12:30:29 <qnikst> elliott: sorry, I should copy function type as well as code itself
12:30:40 <geekosaur> Enigmagic, not really relevant (actually I was assuming command line tools, but not clear it would matter one way or the other)
12:30:50 <byorgey> elliott: I guess my point is just that perhaps you didn't need to warn so vehemently =)
12:30:56 <geekosaur> either way I wouldn't find it in the ghc source tree
12:31:04 <geekosaur> and I would have to look in the llvm source tree
12:31:18 <byorgey> elliott: at least without having a better understanding of exactly what qnikst is trying to accomplish
12:31:34 <luite> geekosaur: oh could well be ld
12:31:34 <geekosaur> ghc -v might be helpful to narrow down where it's happening if nothing else
12:31:46 <hpaste> bobajett pasted “trying to multiply two lists” at http://hpaste.org/66399
12:31:50 <bobajett> whooo I think I got it, elliott does this look ok?
12:32:34 <hpc> :t (/)
12:32:35 <lambdabot> forall a. (Fractional a) => a -> a -> a
12:32:45 <bobajett> I was trying to wrap my arguments in fromIntegral() but looks like I just needed to specify (Fractional) in my type signature
12:33:07 <hpc> bobajett: it's just fromIntegral, not fromIntegral()
12:33:10 <luite> geekosaur: I don't have a ghc executable since it happens in the api, but I'll increase the verbosity in the dynflags
12:33:13 <hpc> :t fromIntegral
12:33:14 <lambdabot> forall a b. (Integral a, Num b) => a -> b
12:33:15 <hpc> :t fromIntegral()
12:33:16 <lambdabot>     No instance for (Integral ())
12:33:16 <lambdabot>       arising from a use of `fromIntegral' at <interactive>:1:0-13
12:33:16 <lambdabot>     Possible fix: add an instance declaration for (Integral ())
12:33:18 <hpc> :t ()
12:33:19 <lambdabot> ()
12:33:24 <qnikst> ghc suggested to add Fractional (Scalar a)
12:33:35 <qnikst> and it works now, thanks
12:33:38 <bobajett> hpc gotcha
12:33:45 <byorgey> bobajett: looks good to me.  you may also want to take a look at the zipWith function from the Prelude.
12:33:52 <geekosaur> oh, that does make it harder.  I also have no idea what's involved there, but I suspect neither llvm nor necessarily ld
12:34:03 <geekosaur> (also, what ghc version is this?)
12:34:11 <bobajett> byorgey <nod> checking it out
12:34:15 <luite> geekosaur: 7.4.1
12:34:34 <geekosaur> hrm.
12:34:37 <luite> geekosaur: I think it's still just loading packages, ld is usually invoked only after compiling I guess
12:34:39 <qnikst> another question is what type should I use for generic float point type?
12:34:59 <tgeeky_> qnikst: there is no such thing. You can choose Float or Double
12:35:11 <byorgey> qnikst: it depends what operations you need.
12:35:17 <geekosaur> ok, I don't have 7.4.1 source locally to poke at and network here is iffy.  think I'll suggest you ask in #ghc or on the ghc list
12:35:53 <geekosaur> it is very probably something inside ghc tghat is doing it, and I have no clue what they might mean by it; it probably indicates ghc-lib found some severe internal inconsistency though
12:36:03 <byorgey> qnikst: but perhaps  Floating a => a ?
12:36:22 <byorgey> or  Fractional a => a  if you just need division and not actually floating point
12:36:35 <qnikst> I need to do numerical integration
12:36:35 <byorgey> Floating gives you stuff like pi, sin, cos, sqrt...
12:36:47 <qnikst> on Complex or Real field
12:37:07 <qnikst> depend on a concrete task
12:37:08 <tgeeky_> qnikst: that's Floating
12:37:41 <bobajett> let scaleByPercent x y = x * y/100
12:37:45 <elliott> If I interpret the question directly: You probably want Double unless you know you want Float.
12:37:46 <qnikst> ok, thanks
12:37:48 <bobajett> scaleByPercent
12:37:57 <tgeeky_> byorgey: there isn't a varaible precision Real type is there?
12:38:05 <tgeeky_> byorgey: i mean, is it even possible?
12:38:06 <byorgey> tgeeky_: there's CReal
12:38:11 <bobajett> > let scaleByPercent x y = x * y/100
12:38:13 <lambdabot>   not an expression: `let scaleByPercent x y = x * y/100'
12:38:18 <byorgey> tgeeky_: which is infinite precision
12:38:55 <mm_freak> wow, i didn't notice the Monoid instance on Ordering before
12:38:58 <tgeeky_> byorgey: I mean something which just scales the cutoff
12:39:03 <mm_freak> it's amazingly useful
12:39:29 <tgeeky_> byorgey: like something which would use a Float, then a Double, then a DoubleDouble, then a DoubleDoubleDouble, as "necessary"
12:39:37 <tgeeky_> byorgey: I presume CReal is untolerably slow?
12:39:43 <byorgey> tgeeky_: probably. dunno.
12:40:15 <elliott> tgeeky_: Never mind how fast it is.
12:40:19 <elliott> (==) doesn't terminate for equal arguments.
12:40:30 <elliott> There's a reason people don't use computable reals for actual computation.
12:41:07 <byorgey> hehe, why would you not use *computable* reals for *computation*?  ;)
12:41:24 <c_wraith> because many operations on computable reals are not computable :)
12:41:24 <tgeeky_> is that what the C in CBlah is in numeric-prelude et al?
12:41:40 <elliott> tgeeky_: I doubt it, but I can't say for sure.
12:41:47 <elliott> (Mostly because I don't know much about numeric-prelude.)
12:41:56 <tgeeky_> c_wraith: that's becuase the reals are morally bankrupt. -- Dirichlet
12:42:01 <elliott> Oh!
12:42:03 <tgeeky_> Dedekind, even.
12:42:12 <elliott> numeric-prelude is a Thielemann production.
12:42:14 <qnikst> elliott: people don't use computable reals for actual computation. ? what do you mean?
12:42:16 <elliott> No, the C stands for "Class".
12:42:25 <byorgey> I don't think numeric-prelude has computable reals
12:42:35 <elliott> qnikst: Well, it's true. Nobody uses computable reals to do actual computation. They use approximations of the rationals, mostly (like Float and Double).
12:42:39 <c_wraith> qnikst: people don't use the construction known as "computable reals". That's a very specific statement
12:42:56 <monochrom> people surely use computable reals. just not all of computable reals.
12:43:02 <elliott> Certainly Float is a subset of the computable reals... with infinities... and NaN.
12:43:03 <elliott> OK, a sideset.
12:43:15 <qnikst> elliott: but it's a lie, or there some missunderstanding
12:43:19 <copumpkin> finite floats are a subset of the ratioanls, even
12:43:27 <elliott> qnikst: I didn't lie.
12:43:31 <elliott> I suspect there is a misunderstanding.
12:43:36 <elliott> What evidence do you have against my claim?
12:43:36 <ClaudiusMaximus> elliott: http://holumbus.fh-wedel.de/hayoo/hayoo.html?query=%22C%22 http://holumbus.fh-wedel.de/hayoo/hayoo.html?query=%22T%22 what's not to love??
12:43:47 <qnikst> ok
12:43:49 <c_wraith> qnikst: there is a *very specific* construction called the "computable reals".  *that construction* is not used for computation
12:43:53 <elliott> ClaudiusMaximus: Useful!
12:44:16 <elliott> ClaudiusMaximus: "Tensor.	T	:: T [Tensor]"
12:44:24 <elliott> ClaudiusMaximus: Haddock was not designed with Henning in mind...
12:44:33 <elliott> T :: T T -> T [T] T
12:44:37 <c_wraith> qnikst: instead, people use smaller constructions that allow efficiency, and even things like computable equality
12:44:38 <qnikst> c_wraith: ok
12:45:20 <elliott> c_wraith: hey, (x ==) is computable for almost all arguments
12:46:03 <c_wraith> elliott: you could just approximate it to "const False"
12:46:33 <elliott> c_wraith: that's too computable!!!
12:46:46 <monochrom> too total, too
12:47:16 <copumpkin> sclv: so what is the type of aaaa aaaaa a aa = aaaaa{a = a, aaa = aa} ?
12:47:23 <monochrom> hahaha
12:48:17 <DMcGill> :t aaaa aaaaa a aa = aaaaa{a = a, aaa = aa}
12:48:18 <lambdabot> parse error on input `='
12:48:23 <DMcGill> well, I'm stumped
12:49:16 <elliott> copumpkin: Q Decl
12:49:35 <hpc> elliott: lawl
12:49:47 <elliott> Oh, it's Dec, isn't it?
12:49:50 <elliott> How embarrassing.
12:50:14 <shergill> isn't that the renowned AstleyR?
12:50:16 <hpc> @seen sclv
12:50:17 <lambdabot> Unknown command, try @list
12:50:25 <hpc> preflex: seen sclv
12:50:25 <preflex>  sclv was last seen on #haskell 1 hour, 32 minutes and 9 seconds ago, saying: but they've been independently discovered/created a few difft ways.
12:51:08 <DMcGill> preflex: help
12:51:08 <preflex>  try 'help help' or see 'list' for available commands
12:51:14 <DMcGill> preflex: list
12:51:14 <preflex>  Botsnack: [botsnack]; Cdecl: [cdecl]; 8ball: [8ball]; Factoid: [+, -, ., ?, delete, get, store]; Help: [help, list]; Karma: [++, --, karma, karmabot, karmatop]; Nickometer: [nickometer]; Nickr: [nickr]; PlokiRE: [re]; Seen: [seen]; Sixst: [6st]; Tell: [ask, clear-messages, messages, tell]; Rot13: [rot13]; Quote: [be, quote, remember]; WCalc: [calc, wcalc]; Version: [version]; XSeen: [xseen];
12:51:15 <preflex>  ZCode: [zdec, zenc]
12:51:25 <DMcGill> just how many bots do we have?
12:51:38 <tgeeky_> DMcGill: about 700
12:51:39 <monochrom> that's uncomputable :)
12:51:46 * Clint beeps.
12:52:02 <tgeeky_> ignore him, he's (not a very good) bot
12:52:13 <tgeeky_> can't even count to 700
12:52:14 <c_wraith> preflex: cdecl array of pointers to unsigned int
12:52:14 <preflex>  trailing garbage
12:52:18 * tgeeky_ turns monochrom off
12:52:22 <geekosaur> two bots, lots of _|_s?
12:52:26 <monochrom> https://plus.google.com/102208456519922110915/posts/RdfEqPNZgwT
12:52:29 <c_wraith> Never did learn how to use cdecl
12:52:41 <geekosaur> try "explain"
12:52:55 <geekosaur> actually, no.  that direction is "declare"
12:53:28 <c_wraith> preflex: cdecl declare array of pointers to unsigned int
12:53:28 <preflex>  trailing garbage
12:53:34 <elliott> monochrom: YOU RUINED MY DAY :'(
12:53:40 <c_wraith> geekosaur: I'm afraid I just don't get it :)
12:53:42 <monochrom> preflex: cdecl void f(void *())
12:53:43 <preflex>  f: function(pointer to function() returning pointer to void) returning void
12:53:58 <bobajett> another noob type question, let scaleByPercent amount percent = amount * percent/100   works fine in gchi if I do scaleByPercent 100 50, but when I try to do zipWith (scaleByPercent) [100,200] [50,50] I get a type error
12:54:14 <geekosaur> ah, so "cdecl" there does the explain part, there is no declare part
12:54:15 <elliott> that's because you can't do [50,50]/100
12:54:28 <qnikst> hm Data.Vector has no instance of Vector-Space :/
12:54:30 <bobajett> oh!
12:55:02 <c_wraith> geekosaur: which may be why my current spare-time project, written in C, is in collaboration with someone who knows C and keeps fixing all my dumb mistakes while I forge ahead with my main idea. :)
12:55:11 <geekosaur> heh
12:55:16 <monochrom> preflex: cdecl void f(void *())()
12:55:16 <preflex>  trailing garbage
12:55:54 <byorgey> qnikst: Data.Vector doesn't represent vectors in the mathematical sense.
12:56:02 <geekosaur> I haven't done C in anger for many years, and do tend to make basic mistakes writing it from scratch these days.  can usually hack on existing code okay though.  (still try to avoid; ew)
12:56:35 <qnikst> byorgey: so it seems I should add such locally for my task
12:56:43 <bscarlet> elliott: I don't understand your answer to bobajett: it looks like his code should work to me, and for me it does.
12:56:55 <byorgey> qnikst: What exactly do you need?
12:57:08 <byorgey> I don't think it makes sense to create a VectorSpace instance for Data.Vector.
12:57:08 <bobajett> scarlet sorry my question was incorrect
12:57:12 <qnikst> I hoped that smb will say, you are wrong, there is such in foo package
12:57:18 <bobajett> what I was trying to say was
12:57:20 <bobajett> *Main> let scale x y = x * 100/y
12:57:20 <bobajett> *Main> zipWith (scale) [100,200] [50,50]
12:57:20 <bobajett> [200.0,400.0]
12:57:24 <monochrom> Data.Vector is quite orthogonal to vector-space
12:57:24 <bobajett> this works
12:57:27 <byorgey> because there is no guarantee that two different Data.Vector structures have the same length.
12:57:31 <bobajett> but if I do let amount = [100,200]
12:57:33 <bobajett> and try to do
12:57:43 <bobajett> zipWith (scale) amount [50,50]
12:57:43 <qnikst> byorgey: I need no make numerical computation on data vector
12:57:46 <bobajett> then I get a type error
12:57:59 <hpc> ah, the dreaded monomorphism restriction
12:58:09 <qnikst> simplies case: explicitEuler :: (VectorSpace a, Floating a, Floating (Scalar a)) => (a -> a) -> Integrator a
12:58:09 <qnikst> explicitEuler f = \h y -> y ^+^ ((realToFrac h) *^ (f y))
12:58:15 <hpc> bobajett: try ":t amount" in ghci
12:58:22 <byorgey> qnikst: of a certain length? of any length?
12:58:41 <qnikst> certain length
12:58:45 <bobajett> *Main> :t amount
12:58:45 <bobajett> amount :: [Integer]
12:58:56 <elliott> <bscarlet> elliott: I don't understand your answer to bobajett: it looks like his code should work to me, and for me it does.
12:59:00 <elliott> "but when I try to do zipWith (scaleByPercent) [100,200] [50,50] I get a type error"
12:59:03 <byorgey> qnikst: what length?
12:59:10 <elliott> If [50,50]/100 works for you you have nonstandar dinstances
12:59:26 <hpc> bobajett: yeah, ghci decides that to avoid some recalculation, it should specialize the type
12:59:34 <bscarlet> elliot: Where would [50,50]/100 happen with his code? He's using zipWith.
12:59:52 <hpc> the fix is to turn it off (ugly) or give a type signature (also ugly)
12:59:58 <elliott> bscarlet: The bit where bobajett divides percent by an integer literal.
13:00:12 <hpc> or define amount in a file and load it, and give a type signature there
13:00:18 <hpc> (less ugly)
13:00:19 <bobajett> hpc ah ok that clarifies it a bit
13:00:20 <elliott> Oh, agh.
13:00:24 <elliott> I completely missed the zipWith.
13:00:28 <bobajett> :-)
13:00:32 <elliott> I'm not doing well today :)
13:00:34 <elliott> Sorry.
13:00:45 <qnikst> byorgey: lenght depending on task, i.e. I have a function from R^n -> R^n
13:00:54 <bobajett> elliot you were doing so well earlier ;-) now your internal haskell parser is not functioning well
13:02:05 <byorgey> qnikst: oh, I see.  Well, if I were you I would just make a VectorSpace instance for lists
13:02:11 <qnikst> I'm using vector space just for ^+^ and ^*
13:02:12 <luite> geekosaur: Program received signal EXC_BAD_ACCESS, Could not access memory. <- when running in gdb
13:02:36 <qnikst> byorgey: starting from some n it will be very inefficient
13:03:04 <qnikst> and I'm returning a result as a Vector of a, with lists it will be Vector (List a)
13:03:46 <bscarlet> bobajett: a debatably less weird option would be to write your code in a file and use runhaskell or compile with ghc, rather than ghci. ghci's handy, but it adds an additional layer of heuristics - like this one where it decided the [100,200] was specifically [Integer].
13:03:56 <byorgey> qnikst: why would it be inefficient?
13:04:44 <qnikst> list is a linked list so it consumes more memory and search is O(n)
13:04:46 <bscarlet> bobajett: Personally, I think those heuristics make life harder, not easier.
13:05:04 <byorgey> qnikst: and how big could n be?
13:05:14 <monochrom> n = 4.3
13:05:16 <elliott> bscarlet: Er?
13:05:21 <elliott> Defaulting applies to GHC too
13:05:29 <elliott> GHCi just adds the () fallback
13:05:50 <monochrom> lambdabot does the same defaulting to (). observe:
13:05:52 <qnikst> for each computation 4-6 for current task and returning result about millions or so
13:05:55 <monochrom> @check (==)
13:05:55 <lambdabot>   "OK, passed 500 tests."
13:06:05 <monochrom> "all animals are equal"
13:06:08 <qnikst> i.e. millions of list of length 4-6
13:06:14 <bscarlet> elliott: Er? right back at you. I tried the code w/ runhaskell before I spoke, and it worked there.
13:06:31 <qnikst> it seems I can drop vector space and use just vector a
13:06:45 <elliott> bscarlet: Well, I might not be understanding the specific defaulting going on.
13:06:49 <qnikst> but I'll loose generality
13:06:55 <elliott> But GHC will certainly pick [Integer] for (NumericTypeClasses a) => [a].
13:07:01 <elliott> And I don't think GHCi changes that.
13:07:05 <bobajett> bscarlet: so if I understand this correctly, when I do amount = [100] ghci specifies it to [Integer] but won't GHC do the same?
13:07:06 <elliott> The DMR might be relevant, though.
13:07:22 <elliott> Of course, if you add a type signature to the file, that changes things.
13:07:25 <elliott> But you can add a type signature in GHCi to.
13:07:26 <bscarlet> bobajett: empirically, GHC doesn't do the same for me.
13:07:32 <bobajett> ah interesting
13:07:37 <byorgey> qnikst: well, maybe you really do want a vector-space instance for Data.Vector.
13:07:37 <bscarlet> elliott: I didn't add any type signatures.
13:07:54 <elliott> weird
13:08:07 <byorgey> it's just a bit odd because when implementing ^+^ you have no guarantee that the two vectors are the same length
13:08:14 <byorgey> even though in your particular application they always will be.
13:08:49 <elliott> I think just using zipWith will obey the laws there
13:08:52 <elliott> though I might be wrong
13:09:02 <byorgey> looks like Data.Vector supports zipWith though, so implementing it should be easy
13:09:16 <byorgey> oh, the problem is zeroV
13:09:21 <bscarlet> elliott: My understanding, based on some guessing I grant you, was that ghci was fully evaluating each line, so it was forced to pick a type with less context (not yet having seen the use of amount), but that ghc was free to do its type inference only after it had seen all the code.
13:09:30 <byorgey> to obey the laws you'd need zeroV to be an infinite sequence of zeros
13:09:31 <elliott> oh, right
13:09:34 <elliott> with lists you can use repeat 0
13:09:37 <byorgey> but qnikst isn't using zeroV
13:09:47 <byorgey> so it will work even though it is icky.
13:09:48 <elliott> bscarlet: Ah, right, yes, GHCi will commit earlier.
13:10:13 <elliott> bscarlet: But technically you can recreate that behaviour with GHC, it'll just mean a looot of files :)
13:10:18 <monochrom> zeroV dim = replicate dim 0
13:10:39 <qnikst> seems I should do zeroV = empty
13:10:50 <elliott> bscarlet: Turning off the DMR in GHCi fixes that, since it doesn't have to default.
13:10:55 <elliott> monochrom: zeroV can't have that type.
13:10:57 <byorgey> qnikst: no, because then zeroV ^+^ x == zeroV
13:11:02 <qnikst> and for ^+^ if dimention not match use zeros
13:11:07 <elliott> you could define (^+^) to pad with zeroes
13:11:10 <elliott> yeah
13:11:11 <qnikst> zeroV + x = x
13:11:11 <elliott> (ew)
13:11:20 <elliott> why not just use tuples?
13:11:21 <byorgey> qnikst: you should do  zeroV = error "oh noes! zeroV! abort!"
13:11:27 <elliott> do you have really huge vectors?
13:11:35 <qnikst> elliott: no
13:11:41 <elliott> how big?
13:11:44 <byorgey> qnikst: oh, I see, if you implement ^+^ by padding with zeros instead of zipWith... yes, that sounds good
13:11:50 <qnikst> 4-6 for current task
13:11:57 <elliott> I'd just use tuples, or define your own strict tuple equivalent
13:12:05 <elliott> likely smaller/maybe faster than Vector for such small sizes
13:12:10 <elliott> and you get static guarantees
13:12:18 <dzhus> Is (//) part of standard Prelude?
13:12:19 <byorgey> yeah, I don't know what the performance would be like of millions of tiny Vectors
13:12:30 <qnikst> it seems I shouldn't think about generality
13:12:30 <dzhus> * \\
13:12:33 <monochrom> hoogle //
13:12:38 <monochrom> @hoogle //
13:12:38 <lambdabot> Data.Array.IArray (//) :: (IArray a e, Ix i) => a i e -> [(i, e)] -> a i e
13:12:38 <lambdabot> Data.Array (//) :: Ix i => Array i e -> [(i, e)] -> Array i e
13:12:40 <qnikst> elliott: thatnks
13:12:43 <qnikst> thanks
13:12:58 <byorgey> dzhus: it is not exported by the Prelude, to use it you must import Data.List
13:12:58 <qnikst> and thanks to all, will use tuples
13:13:07 <monochrom> wait, \\ doesn't look like a legal operator name
13:13:14 <elliott> qnikst: well, no, I mean
13:13:17 <elliott> qnikst: Use VectorSpace
13:13:26 <elliott> the thing is that you can define VectorSpace instances on explicitly-sized tuple/tuple-ish types
13:13:29 <elliott> rather than using Data.Vector
13:13:31 <byorgey> monochrom: it doesn't, does it?
13:13:36 <byorgey> > "abc" \\ "b"
13:13:37 <lambdabot>   "ac"
13:13:39 <DMcGill> > let (\\) = id in (\\) 3
13:13:40 <lambdabot>   3
13:13:40 <byorgey> but it is!
13:13:52 <qnikst> elliott: tuples + vectorspace?
13:13:54 <monochrom> alright good
13:13:55 <elliott> @hoogle (\\)
13:13:56 <lambdabot> Data.List (\\) :: Eq a => [a] -> [a] -> [a]
13:13:56 <lambdabot> Data.IntMap (\\) :: IntMap a -> IntMap b -> IntMap a
13:13:56 <lambdabot> Data.IntSet (\\) :: IntSet -> IntSet -> IntSet
13:14:04 <elliott> I never use (\\) because I never consider that might be an operator :)
13:14:11 <elliott> qnikst: sure, or rather I would say tuple-alikes
13:14:22 <elliott> qnikst: e.g. data T4 = T4 !Double !Double !Double !Double
13:14:23 <monochrom> (\\) is in Data.List but not in Prelude
13:14:27 <elliott> and instance VectorSpace T4
13:14:33 <qnikst> ok
13:15:32 <bobajett> so if I have
13:15:33 <bobajett> scale :: (Fractional a) => a -> a -> a
13:15:35 <bobajett> scale x y = x * y/100
13:15:52 <bobajett> and ghci is turning my amount into [Integer]
13:16:13 <bobajett> how should I call (scale) in my zipWith ?
13:16:16 <monochrom> then you need to prevent [Integer]
13:16:38 <geekosaur> bobajett, sounds ot me like you're letting the monomorphism restriction creep in somewhere
13:16:52 <qnikst> @hoogle on
13:16:53 <lambdabot> Data.Function on :: (b -> b -> c) -> (a -> b) -> a -> a -> c
13:16:53 <lambdabot> Control.Exception.Base onException :: IO a -> IO b -> IO a
13:16:53 <lambdabot> Control.Exception onException :: IO a -> IO b -> IO a
13:17:13 <geekosaur> ":set -XNoMonomorphismRestriction", or give a type signature so it won't default to Integer
13:17:22 <qnikst> zipWith (on fromIntegral scale) [100,200] [50,50]
13:17:27 <qnikst> > zipWith (on fromIntegral scale) [100,200] [50,50]
13:17:28 <lambdabot>   Not in scope: `scale'
13:17:52 <qnikst> > zipWith (on fromIntegral (\x y -> x * y/100)) [100,200] [50,50]
13:17:53 <lambdabot>   No instance for (GHC.Real.Integral (a -> a))
13:17:53 <lambdabot>    arising from a use of `GHC....
13:18:08 <qnikst> ops
13:18:19 <qnikst> > zipWith (on (\x y -> x * y/100) fromIntegral) [100,200] [50,50]
13:18:20 <lambdabot>   [50.0,100.0]
13:18:38 <bobajett> <interactive>:1:10: Not in scope: `on'
13:18:39 <tgeeky_> edwardk: pringles
13:18:52 <qnikst> use Data.Function
13:18:55 <bobajett> ah ok.
13:19:00 <geekosaur> Data.Function.on, yeh
13:19:17 <edwardk> tgeeky_: i still have yet to pop
13:19:26 <bobajett> wohoo! thanks qnikst!
13:19:47 <tgeeky_> edwardk: does a pringles can who refuses to pop make a sound? The world doesn't give a shit.
13:20:11 <tgeeky_> edwardk: you have any burning internal desire to create an authoritative tensor library?
13:20:29 <edwardk> i have a notion of tensors in my ad package
13:20:36 <edwardk> well, technically its a Jet, I just haven't renamed it
13:21:23 <tgeeky_> edwardk: I have this book in front of me that says 2009-2010 developed techniques make tensors of d > 3 computationaly feasible, and even some extreme cases data sets n^d (1000^1000) are computable
13:22:19 <edwardk> ah
13:22:31 <tgeeky_> "alltogether ... problems of size h^d can be reduce to O(d log(n)) = O(log(n^d))
13:22:34 <tgeeky_> "
13:22:36 <edwardk> well depending on how sparse they are you could always use them
13:23:07 <edwardk> i generate zipped up tensors of arbitrary dimension using grads in 'ad' ;)
13:23:17 <tgeeky_> edwardk: isn't that almost the naive case?
13:23:21 <edwardk> but there i have a BOATLOAD of symmetries
13:23:27 <qnikst> is it a right syntax? instance AdditiveGroup a => AdditiveGroup (a,a) where
13:23:49 <monochrom> yes
13:24:03 <edwardk> qnikst: it is, though you probably want instance (AdditiveGroup a, AdditiveGroup b) => AdditiveGroup (a,b)
13:24:09 <whittle> Holy crap! I’m teaching myself about Data.ByteString.Lazy, and in my own little micro-benchmark I saw a speedup of two orders of magnitude over String. Is that typical?
13:24:24 <qnikst> edwardk: yes, thanks
13:24:25 <edwardk> whittle: depends on the problem, but often, yes
13:25:39 <elliott> qnikst: btw, i would recommend defining your own type, since tuples are lazy
13:25:50 <elliott> but it might not matter for your purpose
13:26:01 <qnikst> elliott: I've seen
13:26:14 <qnikst> it's just for prototyping
13:26:39 <qnikst> to test if all other parst of project works as needed
13:28:47 <elliott> right
13:33:48 <xil> hey everyone, I could use some advice on how to code something. I am writing a function of type (a,a)->StdGen->([[a]],StdGen) that, given bounds and a generator, returns a new generator and an infinite list of infinite lists of random values within the bounds.
13:33:52 <xil> The part I'd like a suggestion on is generating the list. I was thinking something like "map fst $ iterate (\(_,g) -> let (h,i) = split g in (randomRs bnds h, i)) stdgen" but I feel like the whole map fst thing is a bit ugly. What do y'all think?
13:36:58 <monochrom> @type unfoldr
13:36:59 <lambdabot> forall b a. (b -> Maybe (a, b)) -> b -> [a]
13:37:50 <monochrom> you can use unfoldr, or write your own that intends to never stop: my'unfoldr :: (b -> (a, b)) -> b -> [a]
13:37:57 <qnikst> elliott: edwardk bobajett, thanks I've got working code
13:38:15 <qnikst> at least it computes things that I need
13:38:43 <monochrom> then you can use my'unfoldr (\g -> (h,i) = split g in (randomRs bnds h, i)) stdgen
13:38:52 <xil> monochrom: ah that's a nice fix, in a way
13:39:06 <xil> I'll play around with writing an unfoldr
13:40:08 <elliott> qnikst: \o/
13:40:18 <elliott> hmm
13:40:18 <elliott> @type unfoldl
13:40:19 <lambdabot> Not in scope: `unfoldl'
13:40:22 <elliott> oh! huh.
13:40:24 <elliott> @hoogle unfoldl
13:40:25 <lambdabot> Data.Sequence unfoldl :: (b -> Maybe (b, a)) -> b -> Seq a
13:40:47 <elliott> oh, right
13:40:51 <elliott> unfoldl would be slow on lists
13:42:03 <qnikst> can I ask a help to rewrite more efficienlty next code:
13:42:28 <xil> is this a reasonable solution for myunfoldr: myunfoldr f b = let ( a, b' ) = f b in a : myunfoldr f b'
13:42:30 <qnikst> http://paste.pocoo.org/show/575741/ (fixedPoint function)
13:44:38 <edwardk> qiknst: using integration for learning or for practical code?
13:45:30 <qnikst> currently for learning, but then there will be some real-world tasks
13:45:59 <edwardk> qnikst: if you just want a usable numeric integrator http://hackage.haskell.org/packages/archive/integration/0.1/doc/html/Numeric-Integration-TanhSinh.html does tanh-sinh quadrature, which makes it about as fast as possible for anything in any hardy space H^p
13:46:22 <qnikst> I need  structure-preserving integrators
13:46:31 <edwardk> *nods*
13:46:38 <qnikst> that preserve high order firest integrals
13:47:39 <edwardk> just figured i'd mention it as its pretty handy for low dimension integrals
13:48:09 <edwardk> i need to package up a bunch of hamiltonian monte carlo integration code i have for higher dimensional integrals
13:48:14 <qnikst> i.e. 3-4-6 polynomial in angular momentum, and that will leave me on manifold
13:48:30 <qnikst> edwardk: ok, will check
13:48:54 * hackagebot vector-strategies 0.3 - A parallel evaluation strategy for boxed vectors  http://hackage.haskell.org/package/vector-strategies-0.3 (ThomasDuBuisson)
13:49:06 <qnikst> ops.. it seems I should go to bed ^), I'm making ODE solver
13:50:31 <edwardk> qnikst: k. we'll talk later
13:50:49 <edwardk> qnikst: sclv has a nice library of lazy splines thare are useful for differential equations as well
13:52:34 <iFire> link?
13:58:55 * hackagebot cblrepo 0.6 - Tool to maintain a database of CABAL packages and their dependencies  http://hackage.haskell.org/package/cblrepo-0.6 (MagnusTherning)
14:02:46 <jfischoff> what is a good way trace based on a debug flag?
14:03:55 * hackagebot vector-conduit 0.4.0.0 - Conduit utilities for vectors  http://hackage.haskell.org/package/vector-conduit-0.4.0.0 (JaredHance)
14:03:58 <xil> so does this function look good, or is there a better way to do it?
14:04:00 <hpaste> xil pasted “random lists” at http://hpaste.org/66402
14:04:56 <danr> @last bitonic
14:04:56 <lambdabot> No module "bitonic" loaded
14:05:32 <elliott> preflex: xseen bitonic
14:05:32 <preflex>  bitonic was last seen on freenode/#haskell 4 hours, 3 minutes and 59 seconds ago, saying: you'd think that it wouldn't be smart enough
14:05:58 <monochrom> xil: I think it's good
14:08:35 <xil> monochrom: thanks =]. I'm still a relative haskell beginning so I'm trying to take opportunities to learn how to write well. Coming from languages like Java and c++ has been a challenge. My latest big project is disastrously written
14:23:10 <luite> does waitForProcess completely block all threads with the nonthreaded runtime?
14:23:33 <Elemir> In linux — yes
14:23:40 <luite> whoops it even says so in the docs
14:24:03 <luite> crap, I must use the nonthreaded runtime, and must wait for a proces, any alternatives?
14:26:15 <Elemir> luite: Try to create thread throw forkOS and wait process at it
14:26:33 <Elemir> Crutches.png
14:27:07 <roaldfre> Is Glasgow parallel Haskell (GpH) still alive? [I'm looking for a High Performance Computing language that can run on clusters]
14:28:35 <luite> Elemir:does forkOS work at all in the nonthreaded runtime?
14:29:24 <Elemir> AFAIK it works at single kernel thread
14:30:13 <Elemir> forkOS is a really a crutch for FFI functions that can't support haskell thread runtime
14:30:25 <qnikst> you can use createProcess from process package
14:30:44 <Elemir> qnikst: createProcess can create a thread?
14:30:57 <Elemir> Thread as kernel thread
14:31:02 <qnikst> ops, seems I'm wrong
14:31:35 <qnikst> yep, forkOS is a guaranteed method on spawning an OS thread
14:31:43 <c_wraith> no, it is not
14:31:50 <c_wraith> forkOS is almost exactly the same as forkIO
14:32:04 <c_wraith> the only difference is guarantees it makes available for doing FFI calls
14:32:04 <Elemir> Am.
14:32:13 <shachaf> c_wraith: Every practical implementation of the guarantees of forkOS will spawn an OS thread, I think.
14:32:16 <shachaf> Sadly.
14:32:17 <qnikst> =(
14:32:29 <shachaf> At least GHC's implementation does.
14:32:45 <c_wraith> shachaf: that thread won't run any haskell code, though.  it will only be used by native calls.
14:32:46 <shachaf> But it's not something you should rely on, nor something you should use it for.
14:32:54 <shachaf> c_wraith: No, it runs Haskell code too.
14:32:54 <Elemir> As I understand it spawns OS thread for ffi guarantees
14:33:19 <c_wraith> shachaf: that isn't what any of the papers on the topic describe it as doing...
14:33:22 <shachaf> c_wraith: It wouldn't necessarily *need* to, but GHC's implementation does.
14:33:55 <shachaf> Unless I'm sorely misunderstanding, anyway. I think JaffaCake said something along those lines in this channel before. :-)
14:37:40 <monochrom> my http://www.vex.net/~trebla/haskell/ghc-conc-ffi.xhtml explains why every forkOS must bind to a fresh OS thread. this is not just GHC; this is implied by the general specification
14:38:21 <shachaf> c_wraith: Maybe I'm wrong.
14:38:33 <monochrom> "Why does forkOS always create a fresh OS thread for the association? For concurrency: two forkOS'ed Haskell threads calling C at the same time necessitates two OS threads."
14:39:53 <shachaf> monochrom: Right. You *could* implement forkOS without spawning an OS thread per bound thread, but then a bound thread could starve another bound thread.
14:40:00 <monochrom> however, this still doesn't imply "injection from bound Haskell threads to OS threads they bind to". see the last section for how to get sharing
14:42:07 <dpratt71>  /msg lambdabot @pl runStep u rn rs cs ds = GameState u rn rs cs (runStep (u + 1) (rn + 1) rs cs)
14:42:18 <dpratt71> oops
14:42:46 <dpratt71> oh, wow, that's scary
14:43:09 <elliott> dpratt71: you do not use "ds"
14:44:10 <dpratt71> elliott: good observation, I shall have to try to remember why that's there
14:50:07 <Clint> why might i not want to use a Sequence?
14:50:34 <elliott> it's strict, and the constant factors are a bit worse
14:50:47 <elliott> (worse compared to what is another question entirely)
14:51:16 <Clint> well, Seq a vs. [a]
14:51:34 <Clint> thanks
14:52:00 <elliott> Clint: [a] is more of a control structure than a data structure.
14:52:20 <elliott> Other languages have loops; we transform (possibly-infinite, incrementally-created-and-consumed, lazy) lists.
14:53:59 <Clint> how would i make a newtype wrapper for []?
14:54:44 <hpc> newtype FancyFrenchListWithSerifsOnTheCorners a = Fancy {unFancy :: [a]}
14:55:17 <hpc> Clint: ^
14:55:19 <Clint> thanks
14:57:13 <elliott> Clint: (That said, people often misuse [] in a way that would better suit another structure like Seq or IntMap.)
14:58:18 <monochrom> project euler beginners abuse []
14:58:45 <Clint> elliott: i want to represent a stream of packets
15:00:22 <elliott> Clint: depends where the stream is coming from and how you're processing it
15:02:47 <Clint> elliott: possibly a conduit source if i can figure out cereal-conduit
15:03:09 <elliott> Clint: then you probably want Conduit ByteString IO Packet or such
15:04:43 <Clint> hmm
15:50:05 <kaitocracy> what's the best way to do like a reverse map on a list?
15:50:18 <kaitocracy> that is I need a function
15:50:25 <kaitocracy> [a -> b] -> a -> [b]
15:51:03 <c_wraith> :t \x xs -> map ($ x) xs
15:51:04 <lambdabot> forall a b. a -> [a -> b] -> [b]
15:51:26 <c_wraith> flip the args around, then :)
15:51:31 <kaitocracy> ahh thanks forgot that function composition was a function
15:51:39 <c_wraith> that's function application, not composition
15:51:41 <c_wraith> But yes
15:51:45 <kaitocracy> or yeah that's what I meant
15:52:27 <parcs`> :t map (flip id)
15:52:28 <lambdabot> forall a b. [a] -> [(a -> b) -> b]
15:52:48 <parcs`> that has sort of an elegance to it
15:52:55 <magicman> :t map . flip id -- ftfy
15:52:55 <lambdabot> forall b a. a -> [a -> b] -> [b]
15:53:50 <magicman> :t sequence
15:53:51 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
15:53:59 <parcs`> magicman: o right
15:54:08 <magicman> > sequence [(+1),(*2)] 5
15:54:09 <lambdabot>   [6,10]
15:54:21 <copumpkin> > flip [(+1),(*2)] 5
15:54:23 <lambdabot>   [6,10]
15:56:00 <magicman> :t flip
15:56:01 <lambdabot> forall (f :: * -> *) a b. (Functor f) => f (a -> b) -> a -> f b
15:56:18 <magicman> :t sequenceA
15:56:19 <lambdabot> Not in scope: `sequenceA'
15:56:26 <magicman> :t Data.Traversable.sequenceA
15:56:27 <lambdabot> forall (t :: * -> *) (f :: * -> *) a. (Data.Traversable.Traversable t, Applicative f) => t (f a) -> f (t a)
15:57:35 <dpratt71> copumpkin, I gather that only works in Caleskill?
15:57:58 <dpratt71> err...Caleskell
15:58:44 <copumpkin> yep
15:58:52 <magicman> flip, yes. sequence works with Control.Monad.Instances. map ($ a) works always.
16:00:12 <dpratt71> copumpkin: I see; neat trick just the same
16:18:56 <tgeeky_> @remember elliott ... [a] is more of a control structure than a data structure.
16:18:56 <lambdabot> Nice!
16:19:21 <elliott> I'm not the first to make that observation :)
16:19:35 <tgeeky_> elliott: like that ever counts anyway
16:19:59 <tgeeky_> good science is littered with things named after 2nd or 3rd inventors/discoverers
16:23:31 <whittle> @pl isMachFile path = readFile path >>= (return . hasMachMagic)"
16:23:32 <lambdabot> (line 1, column 60):
16:23:32 <lambdabot> unexpected "\""
16:23:32 <lambdabot> expecting variable, "(", operator, ">>", ">>=", "=<<", ">>>", "^>>", "^<<" or end of input
16:23:56 <whittle> @ps isMachFile path = readFile path >>= (return . hasMachMagic)
16:23:56 <lambdabot> isMachFile = (hasMachMagic `fmap`) . readFile
16:24:42 <whittle> @t fmap
16:24:42 <lambdabot> Maybe you meant: tell thank you thanks thx ticker time todo todo-add todo-delete topic-cons topic-init topic-null topic-snoc topic-tail topic-tell type . ? @ ft v
16:25:43 <whittle> @type fmap
16:25:44 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
16:25:58 <whittle> @type liftM
16:25:59 <lambdabot> forall a1 r (m :: * -> *). (Monad m) => (a1 -> r) -> m a1 -> m r
16:27:48 <whittle> Is Functor a Monad?
16:28:19 <Elemir> No
16:28:31 <c_wraith> IO is a Functor, though
16:28:55 <Elemir> Theoretically Monad is a Functor
16:28:59 <alpounet> a monad gives rise to a functor, though, in theory
16:29:20 <Elemir> But in haskell it doesn't
16:32:26 <whittle> I’m just learning monads. Should I be worried about functors now or later?
16:33:33 <td123> whittle: lyah introduces functors then applicatives then monads
16:33:41 <c_wraith> functor is strictly less complex
16:33:59 <whittle> td123: Good to know. I’m working my way through RWH.
16:35:47 <whittle> c_wraith: When you say “strictly less complex,” are you talking about strictness vs. lazyness?
16:36:13 <elliott> No.
16:36:57 <luite> what's the easiest way to find the ar and ld programs that cabal and ghc use for compiling stuffs?
16:37:16 <luite> (programmatically, so not cabal -v please)
16:37:20 <dcoutts> luite: they're usually on the $PATH
16:37:27 <luite> dcoutts: not on windows
16:37:51 <dcoutts> luite: cabal finds them either on the $PATH or for windows it looks at where ghc lives and finds them relative to that
16:38:34 <luite> dcoutts: would configureProgram be the right way to find them?
16:38:35 <dcoutts> luite: the logic is in the configureToolchain function in D.S.GHC in Cabal lib
16:39:10 <luite> thanks
16:39:30 <dcoutts> luite: if you're using the Cabal lib, I think if you just run the configureCompiler then for ghc it'll adjust the program database appropriately
16:39:58 <luite> ok, will try that
16:42:06 <Axman6> whittle: do you understand map on lists?
16:42:13 <luite> dcoutts: wait, there's no configureCompiler?
16:42:38 <dcoutts> luite: it's called something like that, from the Configure module
16:43:17 <luite> ah configCompiler
16:44:29 <monochrom> functor is way easier than monad, and related. you should learn functor first.
16:52:47 <whittle> Axman6: Yes. Mapping over lists is something I am very familiar with.
16:53:11 <Axman6> whittle: well, the Functor class just generalises that idea
16:53:13 <Axman6> :t map
16:53:14 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
16:53:15 <Axman6> :t fmap
16:53:16 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
16:53:29 <Axman6> @instances Functor
16:53:30 <lambdabot> ((,) a), ((->) r), ContT r m, Either a, ErrorT e m, IO, Maybe, RWST r w s m, ReaderT r m, ST s, StateT s m, WriterT w m, []
16:53:41 <Axman6> fmap (*2) [1..10]
16:53:55 <Axman6> > fmap (*2) [1..10]
16:53:56 <lambdabot>   [2,4,6,8,10,12,14,16,18,20]
16:54:00 <Axman6> > fmap (*2) (Just 7)
16:54:01 <lambdabot>   Just 14
16:54:10 <Axman6> > fmap (*2) (Right 3)
16:54:11 <lambdabot>   Right 6
16:54:48 <elliott> (Another example is mapping the result of an IO computation.)
16:55:06 <whittle> elliott: That’s where I first ran into it.
16:55:23 <Axman6> aye, something like fmap read getLine isn't too uncommon
16:55:40 <elliott> (Though it should be, since readLn exists!)
16:55:44 <monochrom> "fmap length getLine" is a safer example
16:55:52 <Axman6> yes
16:56:40 <whittle> I keep hearing whispers about “lifting.” Is that what fmap does?
16:56:42 <elliott> whittle: You can also think of fmap as a kind of "lift": lifting an ordinary function (a -> b) to work on (f a -> f b).
16:56:45 <elliott> Ha!
16:56:46 <elliott> Snap.
16:56:50 <elliott> "lifting" doesn't really mean anything though.
16:56:56 <elliott> It's just an evocative word we like to use a lot.
16:57:27 <geekagent> :t lift
16:57:27 <lambdabot> forall (m :: * -> *) a (t :: (* -> *) -> * -> *). (MonadTrans t, Monad m) => m a -> t m a
16:57:48 <whittle> Okay. Between the examples and the explanation, I think I’m coming around on this one.
16:57:52 <whittle> Thank you all.
16:58:00 <Orclev_> you see it most commonly with liftIO
16:58:09 <elliott> >_<
16:58:11 <elliott> not the same kind of lifting.
16:58:17 <elliott> (@ geekagent, Orclev_)
16:59:22 <magicman> I see what you did there.
16:59:26 <Orclev_> it seems fairly similar
17:00:21 <whittle> Thank you especially, elliott and Axman6. I’m going to go back to de-pointing example code for practice.
17:00:37 <Orclev_> ok, would liftM be a more apt comparison?
17:00:41 <elliott> whittle: hehe, have fun :)
17:00:49 <elliott> Orclev_: liftM is actually just fmap for Monads (due to the unfortunate typeclass situation)
17:00:57 <elliott> it's true that lift is similar in that they're both lifts of a kind
17:01:16 <elliott> but fmap is a more obvious example of lifting than lift IMO, despite the name
17:01:40 <Axman6> whittle: pointfree code should not be a goal when writing haskell. it often reduces clarity to the point where it can take you 10 minutes to figure out even simple pieces of code. clarity is much more important than cute code
17:02:39 <elliott> well, if it's a learning exercise, does it matter?
17:02:51 <elliott> it helps you get more familiar with the composition operators etc. which is certainly a noble goal
17:02:52 <whittle> Thanks for the warning, Axman6. I’m really just doing it to cement my understanding of function application and types.
17:03:10 <elliott> anyway, I disagree with "pointfree code should not be a goal"... perhaps not pointfree code, but pointlesser code
17:03:20 <djahandarie> In fact, as an exercise it'll only drive home the point that usually doing point-free code just muddles stuff most of the time. :)
17:04:42 <Axman6> elliott: clear code. sometimes pointfree code is clearer, sometimes it's not. use it when it adds clarity
17:05:09 <Orclev_> I generally only use it if I'm writing something like: foo x = a $ b $ c $ d x
17:05:45 <elliott> @quote platitude
17:05:45 <lambdabot> ddarius says: "use the right platitude for the job"
17:05:59 <elliott> I can't disagree that making your code less clear is worse, obviously :)
17:06:08 <elliott> Orclev_: foo = a . b . c . d  -- actually much more readable
17:06:13 <elliott> in fact, your first example wasn't point-free :)
17:06:41 <Orclev_> yes, that was my point, statements like that are more readable point-free
17:06:50 <elliott> ah, right
17:22:33 <hpaste> tsuraan pasted “traceback causing "thread killed"” at http://hpaste.org/66406
17:23:18 <tsuraan> so in that traceback I just pasted in, the line using nState reads something like "let nState = UploadState { ... }"
17:23:53 <tsuraan> that { ... } has some function calls in it, but since the trace stops with nState, the error causing my "thread killed" death probably isn't in any of those functions, right?
17:24:03 <geekosaur> does nState happen to get used anywhere inside the { ... }?
17:24:36 <tsuraan> not directly
17:25:01 <tsuraan> but the function using it is recursive, and calculates the next nState using the value stored in a previous nState
17:27:22 <tsuraan> this is a function that often works, but about 1 time in 200 it will die with "thread killed"
17:28:18 <tsuraan> and it's an Iteratee being tied to a Snap handler, so the call stack is actually 42 lines deep
17:37:57 <NemesisD> hi all. i'm just learning about TMChans and i wanted to know if they were the right choice for what i'm doing
17:38:55 <NemesisD> so i've got a main thread that's going to fill a TMChan queue full of data. i'll spawn a gang of threads that will read from that queue until it closes. i need the main thread to gather their results
17:39:54 <NemesisD> i can have each thread spawn return a TMChan back to the main thread but then i'd have to try to pull from those TMChans sequentially wouldn't I?
17:41:19 <teneen> Is there an irc channel for frege?
17:41:52 <elliott> If there is, it's not #frege.
17:45:34 <Enigmagic> NemesisD: you can use the Alternative instance for STM to read in data as it becomes available from any channel
17:47:18 <NemesisD> Enigmagic: where does one learn about these instances? i see that stm is an instance of alternative but theres no documentation for what that instance entails
17:47:38 <JoeyA> In Haddock, click on Applicative.
17:47:42 <JoeyA> Oh
17:47:48 <JoeyA> You want to know how it's implemented?
17:48:11 <Enigmagic> NemesisD: i don't know if there is a good tutorial or anything for STM alternative, but Alternative is commonly used for parsers
17:48:14 <NemesisD> JoeyA: not really, just what it means, because alternative is pretty general, isn't it?
17:48:42 <NemesisD> its just a binary operation i think. never actually used alternatives except in attoparsec, and i didn't know what i was doing really
17:48:43 <JoeyA> For STM, (<|>) = orElse, and empty = retry.
17:49:07 <JoeyA> <|> lets you compose STM transactions from left to right.
17:49:23 <JoeyA> readTChan a <|> readTChan b reads from either a or b.
17:49:37 <JoeyA> If both channels have an item at the moment, a is preferred.
17:49:52 <teneen> Does frege perform tco?
17:51:47 <NemesisD> JoeyA: i suppose that would work, except if all the stmchans produce data at roughly the same rate, then the queueing won't be "fair"
17:53:34 <c_wraith> NemesisD: then rotate the order you read from them
17:55:55 <NemesisD> c_wraith: fair enough. i don't actually need it to be fair in my case thankfully
18:23:56 <hpaste> oml pasted “probably simple patter-matching-error” at http://hpaste.org/66407
18:24:10 <fetter_oml> wow, thats a useful skript :)
18:24:23 <dstcruz> is it possible to define multi-line data types in ghci?
18:24:54 <fetter_oml> multi-line data-types?
18:24:54 <ByronJohnson> dstcruz: Yep; :{ :}
18:25:16 <fetter_oml> i wrote the CODE-stuff in a file, and tried to load it, if thats what you mean
18:26:08 <ByronJohnson> dstcruz: In ghci, type :{ to begin the multiline command, and then type :} to terminate it
18:26:12 <fetter_oml> well, and what i want to absorb are those (a,b), where a == b
18:26:15 <dstcruz> ByronJohnson: Ah! Excellent. Thanks!
18:26:43 <dstcruz> ByronJohnson: I assume that indentation still matters inside that block?
18:26:45 <fetter_oml> dstcruz: oh, sry, thought you throwed that complain at me
18:27:13 <ByronJohnson> dstcruz: Right.  The alternative to layout is, oaf course, to use braces and semicolons
18:27:13 <dstcruz> fetter_oml: np
18:27:34 <dstcruz> aluink: you awake?
18:29:16 * hackagebot yjtools 0.9.16 - some tools for Monad, List, Tuple and so on.  http://hackage.haskell.org/package/yjtools-0.9.16 (YoshikuniJujo)
18:30:02 <magicman> fetter_oml: Use guards. factorialInverse (a,b) | a == b = (your code here)
18:31:03 <fetter_oml> ah, ok, i thought it would work directly with the given pattern. thank you very much :)
18:31:23 <magicman> Nope, variables in patterns have to be unique.
18:32:42 <fetter_oml> mhm, i was following the learnyouahaskell.com tutorial, and it gave me the impression
18:33:15 <fetter_oml> but i have to say, its quite great
18:33:31 <fetter_oml> im actually vomiting rainbows all over the keyboard
18:33:42 <NemesisD> Enigmagic: is there a better way to do apply Alternative over a list?, like if i have a list of tmchans, maybe foldl' (<|>) tchans ?
18:34:19 * hackagebot ekg 0.3.0.4 - Remote monitoring of processes  http://hackage.haskell.org/package/ekg-0.3.0.4 (JohanTibell)
18:34:49 <dmwit> ?hoogle Alternative f => [f a] -> f b
18:35:28 <dmwit> ?botsnack
18:36:17 <NemesisD> hhm?
18:36:27 <NihilistDandy> Lamdabot's not talking :(
18:36:32 <NihilistDandy> I tried earlier
18:37:01 <dmwit> Cale: \bot seems to be down
18:37:33 <elliott> @unquit
18:38:05 <fetter_oml> a more general question: does haskell have anything like the usual array? the list seems to be more of a classic linked list to me, given the information provided by mentioned tutorial
18:38:46 <fetter_oml> its not like i miss the array, but cs-class teached me that linked list tend to be a bit slow
18:39:12 <dstcruz> arrays tend to be mutable
18:39:30 <ByronJohnson> fetter_oml: Yes, and there have been several approaches throughout Haskell's history
18:39:32 <dstcruz> haskell does have them, but they won't be introduced in the first few chapters of a tutorial for the language
18:39:36 <ByronJohnson> fetter_oml: These days, the most common approach seems to be vector
18:39:36 <NihilistDandy> http://www.haskell.org/ghc/docs/latest/html/libraries/haskell98-2.0.0.1/Array.html
18:39:45 <ByronJohnson> fetter_oml: Theer's also the array package
18:40:36 <ByronJohnson> fetter_oml: Now, theoretically, let's say vector isn't all that great.  The lack of a proper approach doesn't necessarily imply that such an approach is impossible in Haskell
18:40:45 <fetter_oml> nah, i really dont miss it, i was just wondering how the list is implemented, given that its a very basic, and probably often used feature
18:41:22 <fetter_oml> mhm
18:41:55 <ByronJohnson> fetter_oml: It's pretty general and can be used in a lot of cases, but often there's a more efficient data structure.  For small things, it usually doesn't matter much
18:42:12 <fetter_oml> ah, ok
18:42:31 <dibblego> "linked list is slow" is a furfy
18:42:52 <ByronJohnson> fetter_oml: Besides what I've already mentioned, "containers" contains some commonly used data structures: http://hackage.haskell.org/package/containers-0.4.2.1 ; there are, of course, more than what this package provides
18:42:53 <zachk> whats a furfy?
18:43:10 <dibblego> furfy n. That which does not coincide with reality.
18:43:14 <fetter_oml> furfy? im sry, dont understand that (german is my mother tongue)
18:43:28 <fetter_oml> also implies im a bit slow with typing :)
18:43:30 <mauke> @dict furfy
18:43:36 <lambdabot> Supported dictionary-lookup commands:
18:43:42 <lambdabot>   all-dicts devils easton elements foldoc gazetteer hitchcock jargon lojban vera web1913 wn world02
18:43:51 <ByronJohnson> dibblego: The optimal structure really depends on context
18:43:52 <lambdabot> Plugin `dict' failed with: thread killed
18:44:01 <dibblego> *furphy
18:44:14 <ByronJohnson> In some applications, Set, for instance, would be more efficient
18:44:19 * hackagebot simple-sendfile 0.2.2 - Cross platform library for the sendfile system call  http://hackage.haskell.org/package/simple-sendfile-0.2.2 (KazuYamamoto)
18:44:35 <zachk> why would I want immutable arrays over mutable arrays?
18:44:51 <mauke> purity
18:45:18 <tsuraan> is "thread killed" something that can happen due to mis-use of unsafePerformIO, especially with the FFI?
18:45:35 <tsuraan> I keep getting that exception, and it seems to be coming from the "update" function of Crypto.Hash.Tiger
18:45:57 <tsuraan> which is an entirely freaky looking function, but mostly because it's all FFI stuff
18:46:00 <ByronJohnson> zachk: Generally purity and simplicity.  Mutable arrayrs also exist in Haskell, and they can even be manipulated purely, so long as you maintain referential transparency, by using ST
18:46:14 <fetter_oml> ByronJohnson: ok, thx :)
18:46:14 <fetter_oml> im glad it doesnt have to concern me yet
18:46:37 <elliott> fetter_oml: It's also not really a "classic" linked list.
18:46:48 <elliott> To shamelessly use the quote that just got added,
18:46:51 <elliott> @quote more of a control
18:46:54 <elliott> Wait.
18:46:57 <lambdabot> No quotes for this person. BOB says:  You seem to have forgotten your passwd, enter another!
18:46:57 <elliott> lambdabot is gone.
18:47:02 <elliott> My plain is foiled. Oh, now it's here. Argh.
18:47:04 <elliott> @quote elliott control
18:47:09 <lambdabot> elliott says: ... [a] is more of a control structure than a data structure.
18:47:53 <elliott> fetter_oml: Laziness means that you can process lists without the whole list actually existing: i.e. if you traverse it properly, then it'll be incremental, cells getting reclaimed as you go along it.
18:48:00 <ByronJohnson> zachk: (Conceptually, you can think of ST as a purely / non-primitively defined State monad; when a compiler compiles your code's representation to low-level machine code, though, it can optimize ST actions to code that mutates state in-place, and that's what it does)
18:48:06 <elliott> So the full list structure never even really exists in memory at once, it's just evaluating more tails and losing the previous cells.
18:48:15 <elliott> That just so happens to be what a loop looks like :)
18:48:20 <fetter_oml> elliott: jep, i got that, awesome feature
18:48:51 <fetter_oml> im fealing quite powerfull to create an endless list and using it :D
18:49:00 <elliott> It's true that [] is often not good when you want, uh... a data structure. But even then, an array isn't usually what you want, if you plan to modify it a lot (and don't want the ugliness of mutable arrays).
18:49:05 <elliott> Tree structures like Map do much better.
18:50:15 <fetter_oml> as i said, i dont miss arrays. i just wondered if every haskell-programm builds on lists as data structures, and the answer seems to be no.
18:50:56 <NemesisD> dmwit: you lost me
18:50:58 <elliott> Right, then no :)
18:52:14 <fetter_oml> another one, and i dont want to troll: do you use haskell to actually write software you want to actually use? im learning it cause someone said to me it would heal the scars ive got from java
18:52:28 <clsmith> why do some [hp]ackages not provide access to its module docs?
18:52:37 <fetter_oml> (im also a mathematician and most of the syntax is really awesome, i have to admit)
18:52:58 <JoeyA> clsmith: Are you talking about the 404 page you get when you try to look at the docs for, say, Data.ByteString.Internal ?
18:53:05 <ByronJohnson> fetter_oml: I regularly find Haskell much more pleasant to work with than any other language
18:53:07 <fetter_oml> but couldnt imagine building a tiling-wm, at least yet
18:53:13 <rasfar> clsmith: module docs are only generated automatically for "libraries"
18:53:23 <clsmith> no, just how on some packages - like http://hackage.haskell.org/package/weighted-regexp - the docs aren't accessible
18:53:38 <ByronJohnson> fetter_oml: (Haskell isn't the only language in which I have experience, nor is it the first)
18:53:40 <rasfar> hmm.
18:53:54 <JoeyA> clsmith: That's because of: Build failure	ghc-7.4 (log)
18:54:03 <clsmith> oh, hmm
18:54:16 <rasfar> fetter_oml: i've just come back to Haskell after a hiatus, and I have to agree with ByronJohnson it is a joy!
18:54:20 <fetter_oml> ByronJohnson: that i can imagine, it is pleasing me to tears. but for most practical programming (which i dont do at all, i hate hacking) i would c/java/bash
18:54:22 <JoeyA> They need to update their code to deal with the Eq/Num split introduced by GHC 7.4.
18:54:23 <fetter_oml> (yet)
18:54:24 <clsmith> well, i downloaded it and it's ok locally at least. i only use 7.0.4 though
18:54:51 <clsmith> i guess i'll just work with that until they update. i know they've done some things to do with that upstream
18:54:51 <rasfar> fetter_oml: pretty much why i go on hiatuses :)
18:55:33 <rasfar> but if you're willing to learn to use the optimised libs/datastructures (or FFI for the crunch if necessary) I think you can have the best of both worlds.
18:55:38 <Modius> Any good articles/thoughts on haskell handling high number of incoming connections?
18:55:53 <Modius> Old article here:  http://www.haskell.org/haskellwiki/Simple_Servers  Anything newer/definitive?
18:55:57 <rasfar> although that's still hypothetical for me, all my code is still lists combinators and pattern-matching <blush>
18:56:06 <clsmith> i find haskell a little difficult to use in certain situations, but for the most part when i use it i just feel less frustrated when i'm programming. all the state and IO and exceptions flying everywhere in procedural languages give me shellshock
18:56:23 <clsmith> i'm not a mathematician though, so i sometimes struggle with that side of things ;p
18:56:27 <elliott> <fetter_oml> another one, and i dont want to troll: do you use haskell to actually write software you want to actually use? im learning it cause someone said to me it would heal the scars ive got from java
18:56:39 <elliott> fetter_oml: Yes, Haskell is my go-to language; I suspect it is for many people here.
18:57:06 <fetter_oml> go-to-language?
18:57:20 <fetter_oml> the one you earn your money with? dont understand that term
18:57:28 <NemesisD> wouldn't basic be a goto language
18:57:44 <elliott> As in, the language I generally consider/use first when writing new code.
18:57:53 <fetter_oml> ah, k
18:57:55 <Cale> fetter_oml: I use Haskell pretty much exclusively these days
18:57:57 <Enigmagic> i thought BASIC was written in haskell?
18:58:00 <Enigmagic> @package BASIC
18:58:00 <lambdabot> http://hackage.haskell.org/package/BASIC
18:58:08 <JoeyA> The idiom "x is my go-to T" means that when I need a T, I usually choose x by default.
18:58:21 <NemesisD> i use haskell for experimental stuff, high performance, stuff that needs concurrency
18:58:23 <elliott> IMO it would be hard to restrict yourself to only using Haskell for the "joy" and not for actual tasks (of course, those can be joyful to write too) once you've really used it.
18:58:25 <elliott> It's too pleasant.
18:58:26 <Cale> fetter_oml: I use it in my job (working on a game/engine for iPhones and other mobile devices), and for all kinds of random tasks
18:58:41 <NemesisD> i use  ruby for web stuff and larger programs
18:58:43 <elliott> And, thankfully, it's not such a niche language that the library support isn't there.
18:58:48 <clsmith> mine really depends on the problem. i tend to use python for more IO-centric and quick-hack things, haskell for more involved stuff
18:59:10 <elliott> NemesisD: you pick Ruby for larger programs? like, programs that need *more* support and static checks from the computer to avoid going wrong due to the increasd complexity?
18:59:13 <fetter_oml> meh, im impressed. i thought of it mainly as a cure for pissed of programmers :)
18:59:44 <elliott> fetter_oml: You don't get thousands of library packages unless someone is using your language ;)
19:00:05 <NemesisD> elliott: most of my large programs do happen to be web apps, now that i think of it
19:00:23 <ByronJohnson> fetter_oml: In my experience, I've found it to work quite nicely for game and web development
19:00:28 <clsmith> yeah, i do the opposite: python for quick hacks; once you get large projects with dynamically typed languages i find i sort of hit a point at which i break down and fight back the tears
19:00:31 <NemesisD> elliott: lots of the med to large stuff i do require a lot of libraries that just aren't there in haskell yet
19:00:57 <Cale> fetter_oml: I still think of myself as a mathematician, and still not 100% completely invested in the notion that I have to be a computer programmer to make my living, so I feel confident in refusing to program in any language without first class functions and a powerful static type system.
19:00:57 <NemesisD> if im doing the project on my own time, i'm not going to write all the components from scratch, ill quickly lose steam that way
19:01:44 <ByronJohnson> fetter_oml: (Before I was introduced to Haskell, I indepedently wrote an open source game with 40,000 lines of C, C++, and Lua, for example)
19:02:03 <fetter_oml> jay, so static it doesnt even automatically cast int to float :D
19:02:17 <fetter_oml> quite satisfacting after the first shock
19:02:29 <clsmith> when i first saw that i thought it was insane
19:02:44 <clsmith> but i've grown to like the explicit conversions
19:03:12 <fetter_oml> at least better than java with its millions of possible static-dynamic-type combinations
19:03:24 <Cale> fetter_oml: Basically, we've known how to implement first class functions efficiently for 20 or 30 years now, and we've known about their importance to abstraction in programming since before the advent of electronic computers. There's no excuse to still be writing new programs in languages without them.
19:03:44 <Cale> At least, that's how I see it
19:04:01 <clsmith> i think that's true except when it comes to the plumbing
19:04:09 <clsmith> low level software still needs something close to the metal
19:04:12 <fetter_oml> im still on the way of grapsing what a HO-function is
19:04:44 <rasfar> floor $ sqrt $ fromIntegral $ length $ fst $ unNetwork net (re. explicit conversions) just earlier in my code) is a bit drole though
19:05:05 <clsmith> a higher-order function is just a function that takes another function and does something with it. like 'filter' takes another function and, for each element in the list you give it, calls that function on the element to see if it should be filtered out or not
19:05:07 <dibblego> new Func<A, B>() { public B apply(A a) { ... } }  // one of these
19:05:27 <fetter_oml> easy to write down, hard to fully grasp
19:05:36 <djahandarie> dibblego, that's not a higher-order function, that's an ugly contraption! You lier!
19:05:42 <djahandarie> > map (\x -> x*2) [1,2,3,4,5,6]
19:05:42 <lambdabot>   [2,4,6,8,10,12]
19:05:47 <djahandarie> Now that's what I'm talking about
19:05:50 <ByronJohnson> @remember < Cale> fetter_oml: Basically, we've known how to implement first class functions efficiently for 20 or 30 years now, and we've known about their importance to abstraction in  programming since before the advent of electronic computers. There's no excuse to still be writing new programs in languages without them.
19:05:51 <lambdabot> Done.
19:05:51 <Cale> fetter_oml: Okay, well, have you ever written two pieces of code which textually looked similar, but which you couldn't make a parameter to distinguish between them, because some inner bit of code was different, and not just some (e.g. integer) parameter was able to explain the difference?
19:05:59 <NemesisD> rasfar: to me composition reads much nicer. floor . sqrt . fromIntegral . length . fs . unNetwork $ net
19:06:20 <NemesisD> rasfar: easier to take chunks out of that huge function pipeline into separate functions with better names
19:06:35 <rasfar> yeah, i am gradually getting more used to composition, but for some reason $ was easier for me to get right at first.
19:07:08 <clsmith> i kinda prefer chains of $ tbh. it's more obvious at a glance what is applying to hwat
19:07:09 <fetter_oml> Cale: may be. i dont write that much, i actually hate writing code (it might change with haskell. its so goddamn beautiful)
19:07:10 <Cale> fetter_oml: (resulting in what looks a bit like annoying copypasta)
19:07:11 <clsmith> *what
19:07:21 <rasfar> well, that would be single-use at this point -- sqrt(nNodes) is all I'm trying to express!
19:07:44 <Cale> fetter_oml: Okay, well, that's where you get higher-order functions from, essentially.
19:07:48 <NemesisD> clsmith: yeah but you have to at least admit that that many $'s is a code smell
19:07:58 <clsmith> NemesisD: why?
19:08:11 <elliott> @forget < Cale> fetter_oml: Basically, we've known how to implement first class functions efficiently for 20 or 30 years now, and we've known about their importance to abstraction in  programming since before the advent of electronic computers. There's no excuse to still be writing new programs in languages without them.
19:08:11 <lambdabot> Done.
19:08:17 <elliott> @remember Cale Basically, we've known how to implement first class functions efficiently for 20 or 30 years now, and we've known about their importance to abstraction in  programming since before the advent of electronic computers. There's no excuse to still be writing new programs in languages without them.
19:08:17 <lambdabot> It is stored.
19:08:18 <NemesisD> because you should strive to write functions with good names that are composable/reusable
19:08:21 <rasfar> i don't mind doing it because, to be honest, it just doesn't happen that often in the kind of code I write
19:08:23 <elliott> lambdabot is picky about syntax :)
19:08:58 <NemesisD> sqrtLen = floor . sqrt . fromIntegral . length
19:09:25 <parcs`> isqrtLen ;)
19:09:31 <rasfar> okay NemesisD! give me a break i hacked this together in a few days and i'm more interested in seeing if it will work at all...
19:09:44 <ByronJohnson> elliott: je'e
19:09:44 <rasfar> :) btw
19:09:58 <NemesisD> i like code that has nice readable names up top and then puts all the nasty composition chains further down in "when"s or helper functions if you're interested
19:09:58 <Cale> fetter_oml: I don't know how far along you are with Haskell, but perhaps you've seen how to implement the sum and product of a list of numbers recursively?
19:10:06 <Cale> sum [] = 0
19:10:07 <fetter_oml> yep
19:10:11 <Cale> sum (x:xs) = x + sum xs
19:10:14 <Cale> product [] = 1
19:10:19 <Cale> product (x:xs) = x * product xs
19:10:20 <rasfar> that is in a where clause i'm pretty sure (probably nested)
19:10:27 <NemesisD> rasfar: lol totally understand, don't want to give the impression i follow my own rules 100% of the time
19:10:50 <Cale> fetter_oml: These two pieces of code are extremely similar in structure. The definition of product just replaces 0 with 1, and + with *
19:10:55 <fetter_oml> you mean, sum and factorial are very much the same except for * and +
19:10:58 <fetter_oml> mhm, jep
19:11:00 <Cale> yeah
19:11:14 <Cale> and many other functions fit into this pattern
19:11:23 <Cale> for example, concatenating a list of lists
19:11:33 <fetter_oml> and you could write one HO, which does it all?
19:11:34 <Cale> So we'd like to be able to abstract over it
19:11:35 <Cale> yeah
19:11:39 <clsmith> nice example with sum / product btw
19:11:47 <pqmodn> any [] = True; any (x:xs) = x || any xs
19:12:07 <Cale> That would be 'or' in the prelude
19:12:09 <Cale> but yeah
19:12:09 <fetter_oml> could you dig up an example how it would look for sum/factorial ?
19:12:16 <Cale> okay, so
19:12:26 <Cale> we're going to define a function  foldr f z
19:12:34 <Cale> where f is our abstraction over (+)
19:12:39 <Cale> and z is our abstraction over 0
19:12:44 <Cale> So:
19:12:50 <Cale> foldr f z [] = z
19:12:59 <Cale> foldr f z (x:xs) = f x (foldr f z xs)
19:13:09 <Cale> and then we can write:
19:13:13 <Cale> sum = foldr (+) 0
19:13:18 <Cale> product = foldr (*) 1
19:13:24 <Cale> concat = foldr (++) []
19:13:51 <Cale> or = foldr (||) False
19:14:01 <Cale> and = foldr (&&) True
19:14:04 <Cale> and so on :)
19:14:51 <NemesisD> so any of you guys know about TMChan and Alternative? trying to write something like takeUntilEmpty :: [TMChan a] -> [a]
19:15:42 <fetter_oml> ok, thats abstraction taken serious
19:15:48 <fetter_oml> but not impossible to understand
19:16:06 <fetter_oml> i think you managed to demystify it quite a bit :)
19:16:17 <JoeyA> NemesisD: Note that you'll have to read the entire list strictly.  STM doesn't support laziness (at least not last time I checked)
19:16:28 <NemesisD> JoeyA: thats fine with me
19:16:29 <JoeyA> That is, there's no lazy STM like there is lazy IO.
19:16:50 <romildo> Does a function similar to the following one already exists in some library?
19:16:52 <romildo> prompt msg = putStr msg >> readLn
19:16:59 <NemesisD> i'm trying to figure out if i could use "some" here
19:17:15 <JoeyA> NemesisD: Did you mean [TMChan a] -> STM [a] ?
19:17:25 <NemesisD> JoeyA: oh, yes i did
19:17:33 <JoeyA> And you want to consume all available items from all lists?
19:17:37 <JoeyA> err, all channels.
19:17:52 <NemesisD> JoeyA: yeah
19:18:08 <parcs`> romildo: don't think so
19:18:18 <JoeyA> NemesisD: Well, you can start by writing getTMChanContents :: TMChan a -> STM [a]
19:18:25 <elliott> romildo: You need an hFlush stdout in there
19:18:31 <elliott> putStr msg >> hFlush stdout >> readLn
19:18:39 <parcs`> romildo: though the 'haskeline' library provides stuff like that
19:18:39 <JoeyA> Which calls tryReadTMChan over and over until it returns Nothing.
19:19:12 <JoeyA> err
19:19:24 <JoeyA> "A version of readTMChan which does not retry. Instead it returns Just Nothing if the channel is open but no value is available; it still returns Nothing if the channel is closed and empty. "
19:19:39 <Cale> fetter_oml: as a simpler example, consider all the cases where we want to apply a function to each element of a list
19:19:45 <Cale> fetter_oml: or other datastructure
19:19:48 <JoeyA> That's rather confusing.
19:20:14 <NemesisD> yeah it is
19:20:29 <fetter_oml> mhm
19:20:30 <elliott> JoeyA: better:
19:20:39 <kaitocracy> okay one thing I still don't get, well one of many things, but what are applicative functors good for?
19:20:43 <elliott> ((:) <$> readTMChan blah <*> getTMChanContents blah) <|> return []
19:20:45 <Cale> fetter_oml: that sort of operation is a very common thing, and having to write a loop or recursive something-or-other where you can easily screw up the loop bounds or base case is rather unhappy
19:20:56 <kaitocracy> I find myself using monads quite a bit but not really ever applicatives
19:20:58 <elliott> kaitocracy: writing effectful code in an applicative style
19:21:00 <elliott> for instance
19:21:06 <Cale> fetter_oml: Not to mention being needlessly verbose
19:21:06 <elliott> do { x <- blah blah blah; xs <- blah blah blah; return (x:xs) }
19:21:08 <elliott> is much nicer as
19:21:12 <elliott> (:) <$> blah blah blah <*> blah blah blah
19:21:16 <Cale> fetter_oml: So instead, we write a higher order function like map
19:21:21 <Cale> map f [] = []
19:21:21 <JoeyA> The source for tryReadTMChan is even more confusing.
19:21:26 <Cale> map f (x:xs) = f x : map f xs
19:21:35 <JoeyA> If I were a Haskell compiler, I would throw a type error.
19:21:36 <elliott> kaitocracy: it's a more "direct" style -- just like you can write "f x" instead of "let myF = f; myX = x in myF myX"
19:21:45 <NemesisD> JoeyA: i was playing around with something more like foldl (<|>) chans
19:21:52 <kaitocracy> but okay how are they like Monads then?
19:21:55 <elliott> judicious and frequent use of applicative style can really clean up a big tangle of monadic code
19:21:58 <kaitocracy> for example can I have Writer as an applicative?
19:22:03 <elliott> kaitocracy: yes, all monads are applicatives
19:22:11 <elliott> Haskell doesn't enforce that but all the common monads have Applicative instances
19:22:19 <elliott> pure is just return, and (<*>) is just ap
19:22:29 <elliott> ap mf mx = do { f <- mf; x <- mx; return (f x) }
19:22:31 <NemesisD> JoeyA: the type on that makes me think this is not a safe thing to do
19:22:35 <elliott> kaitocracy: however, not all applicatives are monads, though most are
19:22:44 <elliott> kaitocracy: with the applicative interface, the structure of the computation is fixed
19:22:54 <elliott> kaitocracy: for instance, you can't write "read a line, then print it" in applicative style
19:23:04 <elliott> because the structure of the computation (putStrLn theLine) depends on a previous computation (getLine)
19:23:09 <elliott> that's what monads add to applicatives
19:23:30 <elliott> when you don't need that, applicative style is more concise, and often more readable
19:23:46 <elliott> basically, any time you see yourself doing a bunch of actions, then running a pure function over the results -- use applicative style
19:24:14 <fetter_oml> Cale: ok ... i dont see myself using them anytime soon, but i think i begin to understand
19:24:14 <kaitocracy> so okay for example I'm writing a little form validation library, now my idea is that I'll have a series of 'validators', and each one will run in the Writer monad, it will inspect a ValidationField, add something to the Writer if there is an error, possibly modify the ValidationField, then return the ValidationField so that it can be passed to the next validator
19:24:20 <kaitocracy> would this be more effective using an applicative?
19:24:51 <JoeyA> Yes.
19:25:01 <JoeyA> I do that for reading my program's configuration file.
19:25:15 <kaitocracy> but I can't figure out how to do it as an applicative
19:25:19 <elliott> kaitocracy: There's not really "using an applicative".
19:25:22 <elliott> You have a monad, right?
19:25:30 <kaitocracy> well I'm using the Writer monad
19:25:31 <elliott> Then you're done. You can mix applicative and monadic style freely.
19:25:33 <elliott> And you should.
19:25:44 <fetter_oml> Cale: without being disrespectful, i would like to get some sleep now - your explanations would be much less wasted if it wasnt 4:30 am around here :)
19:25:56 <elliott> You don't have to commit to doing everything applicatively, since that isn't even always possible. It simplifies a certain, very very common pattern in monadic code.
19:26:18 <kaitocracy> wait but how do I use 'tell' in applicative code?
19:26:19 <JoeyA> NemesisD: Going by common sense, there are two possible outcomes of tryReadTMChan: 1) No items are available *yet*, and 2) The channel is closed.
19:26:25 <JoeyA> Hence the Maybe (Maybe a))
19:26:49 <elliott> kaitocracy: Erm. You just use it.
19:26:51 <elliott> tell x
19:26:59 <elliott> All the actions are the same! An applicative is not a different type.
19:27:06 <elliott> It is just another set of glue combinators to tie actions together.
19:27:08 <fetter_oml> but my gratitude for eplaining it, you seed a seed :)
19:27:27 <kaitocracy> I'm so confused, so here's basically what I have write now
19:27:31 <JoeyA> NemesisD: But when the channel is closed, there may still be pending items.
19:27:43 <kaitocracy> require =<< isValidDate =<< getSomeField
19:28:05 <elliott> kaitocracy: That uses (>>=).
19:28:09 <elliott> That's what applicatives don't do.
19:28:17 <elliott> And that's perfectly fine.
19:28:20 <kaitocracy> oh okay
19:28:46 <elliott> This is a red flag, you want to rewrite it in applicative style: (a >>= \blah -> b >>= \bleh -> return (f blah 42 bleh)) as (f <$> a <*> pure 42 <*> bleh).
19:28:49 <kaitocracy> so if I find that I have to use >>= then I should use a Monad rather than an applicative?
19:28:53 <elliott> But (>>=), in general, can't be rewritten that way.
19:28:59 <elliott> No, you can rewrite certain cases of it.
19:29:20 <elliott> But "use a Monad rather than an Applicative" is still misleading.
19:29:21 * hackagebot texmath 0.6.0.4 - Conversion of LaTeX math formulas to MathML or OMML.  http://hackage.haskell.org/package/texmath-0.6.0.4 (JohnMacFarlane)
19:29:24 <NemesisD> JoeyA: was just hoping this wasn't going to get ugly but i think it will
19:29:25 <kaitocracy> I see I see but there's nothing wrong with what I'm doing where I'm building a pipeline of validators with =<<?
19:29:38 <elliott> Writer doesn't "become Applicative" rather than Monad just because you use (<$>) and (<*>); it's just a certain style that you can, like I said, mix freely.
19:29:41 <elliott> kaitocracy: Nothing wrong, no.
19:29:56 <kaitocracy> got it okay thanks
19:30:34 <Philippa> elliott: that usage can be correct though, especially in a more mathematical context
19:31:10 <Philippa> it's just that type classes encourage us to pun between type[ constructor]s and types+instances
19:31:53 <kaitocracy> wait so as a general rule, if I have some side effect (liking writing to a Writer) in addition to my computation, then monadic style is more appropriate than applicative style?
19:32:11 <fetter_oml> goodnight to you, till tomorrow
19:32:30 <byorgey> kaitocracy: no, applicative can encompass "side effects" as well.
19:32:54 <JoeyA> NemesisD: I imagine that takeAvailable :: TMChan a -> STM [a] will read items from the channel until it is empty, or until no items are available.
19:32:59 <byorgey> kaitocracy: the distinction is that if you need to use intermediate values in order to decide which computations to run next, you need Monad
19:33:14 <byorgey> kaitocracy: otherwise, if the structure of your computation is fixed up front, you can use Applicative
19:33:25 <kaitocracy> argh I don't get it, so in my case where I have
19:33:26 <Philippa> and really you'll get a feel for style. What's more important is when you need to do something that doesn't support a Monad, or when you might need to make the Monad instance available to some parameter you take
19:33:40 <JoeyA> It is easy to apply takeAvailable to a list of chans: concat <$> mapM takeAvailable chans
19:33:45 <kaitocracy> validator1 =<< validator2 =<< validator3 =<< someValue
19:34:01 <kaitocracy> and each one of those validators is effectful in that it might log an error to my Writer
19:34:01 <JoeyA> But for takeAvailable, I would write a recursive loop.
19:34:06 <kaitocracy> how would I do that in applicative style?
19:34:22 <Philippa> you wouldn't: the "might" rules it out
19:34:53 <byorgey> right, presumably those need to know the value of the previous one in order to *decide* whether to write or not.  That requires Monad.
19:34:53 <kaitocracy> hmm I kind of get it, okay
19:35:03 <kaitocracy> ahh got it
19:35:30 <JoeyA> kaitocracy: Well, you'd do things a little differently with Applicative.  In particular, you can extract values, rather than just validating.
19:35:56 <kaitocracy> well I can extract values with my monadic solution also
19:36:27 <Philippa> JoeyA: as in runFoo-style functions? Yeah, you can do that but it's not a good thing for polymorphism
19:36:47 <Philippa> (join is arguably a better-behaved run function!)
19:36:50 <JoeyA> Philippa: I'm not sure what you mean.  I'll post a simple example.
19:37:20 <Philippa> if you're about to pattern-match on list or Maybe or similar, that's equivalent too
19:38:05 <elliott> Philippa: yes, that's true
19:38:16 <elliott> Philippa: but I think if there's a perception of a dichotomy "using a Monad"/"using an Applicative", that's a misconception
19:38:38 <Philippa> there is one, but you only care if you care about polymorphism
19:38:50 <Philippa> (or, y'know, don't have a Monad instance handy)
19:38:55 <elliott> true, but i think the example was unambiguously monomorphic to Writer :)
19:39:31 <Philippa> yeah. But if you're going to be picky about language it's a good idea not to stomp on neighbouring usages that're correct if you can avoid it
19:40:59 <Philippa> if nothing else, it leads to people stomping on genuinely correct usages by mistake - sometimes leaving no way to talk about a distinction without a full-blown definition of terms as you go
19:41:54 <kaitocracy> wait I just realized that I have a lot of code that looks likedo a <- some1; b <- some2; c <- some3; return SomeRecord { a' = a, b' = b, c' = c }
19:41:59 <elliott> I was trying to emphasise the point using a direct quote, since I'd phrased it more precisely earlier. But, okay.
19:42:05 <kaitocracy> can I do that in applicative style?
19:42:49 <Philippa> yes. Might need to write a tedious lambda, but otherwise it fits pretty simply
19:43:26 <kaitocracy> is the tedious lambda because I'm using a record?
19:43:29 <Philippa> (\a b c -> SomeRecord { a' = a, b' = b, c' = c }) <$> some1 <*> some2 <*> some3 , unless I'm even more tired than I think I am
19:43:55 <elliott> SomeRecord <$> some1 <*> some2 <*> some3 will work if you're lucky with parameter orders.
19:43:57 <Philippa> partly that and partly trying to maintain connotations, yeah
19:44:11 <kaitocracy> ahh, I kind of wish that records were easier to use with accessors and stuff
19:44:12 <elliott> With idiom brackets it'd be slicker: (| SomeRecord { a' = some1, b' = some2, c' = some3 } |)
19:44:16 <elliott> dunno if she can do that
19:44:20 <elliott> kaitocracy: you might want lenses
19:44:32 <NemesisD> JoeyA: well the types check but guh is this thing ugly and probably wrong
19:44:33 <Philippa> that'd need an extension of idiom brackets, technically
19:44:40 <kaitocracy> I looked into those but they look really complicated
19:44:42 <aavogt> I think it's also possible to use the same name for the variable and the field label:    SomeRecord { a = a, b = b, c = c }
19:44:45 <hpaste> “Joey Adams” pasted “Simple configuration file parsing with Applicative” at http://hpaste.org/66408
19:44:45 <elliott> kaitocracy: nope, really simple
19:44:47 <Philippa> (but it's a sensible one)
19:44:48 <kaitocracy> what are idiom brackets and where can I find more about them?
19:44:55 <elliott> kaitocracy: take a look at http://stackoverflow.com/a/5769285/1097181 for a simple introduction to lenses
19:45:01 <elliott> idiom brackets are the original notation for applicatives
19:45:05 <elliott> see https://personal.cis.strath.ac.uk/~conor/pub/she/idiom.html
19:45:12 <aavogt> but maybe that's a ghc extension
19:45:13 <elliott> basically (| f a b c |) -> f <$> a <*> b <*> c
19:45:23 <hpaste> NemesisD pasted “drainTMChans” at http://hpaste.org/66409
19:46:15 <elliott> kaitocracy: as far as lenses go, they're basically just a bundling of getter and setter -- so you can imagine myFieldLens = (\record -> myField record, \record value -> record { myField = value })
19:46:29 <NemesisD> this code does benefit a from applicative
19:46:35 <elliott> that's basically it; it means you can use "record fields" as first-class values, since they know how to set too, rather than just getting
19:46:59 <elliott> so you can write things like modify :: Lens a b -> (b -> b) -> a -> a -- "given a field, and a function to update it, turn that into an updater for the record"
19:47:10 <JoeyA> NemesisD: It looks like you're making it more complicated than it is.  What are you trying to do besides simply drain all available items from each chan?
19:48:25 <kaitocracy> ahh I'll have to study these lenses some more
19:48:29 <NemesisD> JoeyA: that is what i'm trying to do, i keep iterating over the list and pulling elements that are (Just (Just a)) until there are none
19:48:52 <JoeyA> Does it matter what order you do it?
19:49:17 <JoeyA> Why not gulp each list one at a time?
19:49:21 * hackagebot fast-tags 0.0.3 - Fast incremental vi tags.  http://hackage.haskell.org/package/fast-tags-0.0.3 (EvanLaforge)
19:49:38 <elliott> kaitocracy: I recommend the data-lens library for them -- http://hackage.haskell.org/package/data-lens -- there's also a convenience library for using them with a state monad (http://hackage.haskell.org/package/data-lens-fd) and a package that lets you automatically derive lenses for your record fields with template haskell (http://hackage.haskell.org/package/data-lens-template) which makes it a lot less tedious... but yeah, the SO answer I linked
19:49:39 <elliott>  goes into more detail
19:50:12 <JoeyA> NemesisD: Let's say you have three channels, whose currently available items can be represented as: [[1,2],[3],[4,5,6]]
19:50:33 <JoeyA> Where [1,2] is the items available in the first chan, [3] is the items available in the second chan, and [4,5,6] is the items available in the third chan.
19:50:59 <JoeyA> You can read the items by gulping each channel one at a time.
19:51:01 <dibblego> we are hoping to do a data-lens-2.9.0 release soon
19:51:07 <dibblego> !seen roconnor
19:51:32 <JoeyA> If you want to make it more "fair" and round-robin, you can just use transpose (I think):
19:51:38 <JoeyA> > transpose [[1,2],[3],[4,5,6]]
19:51:38 <lambdabot>   [[1,3,4],[2,5],[6]]
19:52:36 <Philippa> elliott: is there a good library for using TH to 'delegate' [bits of] instances to some other structure yet?
19:53:21 <elliott> Philippa: hmm, what would that mean? From your description the only thing I can think of is derive, which presumably isn't what you mean
19:53:22 <Philippa> (that is, such that you could couple it to something that does convention-over-configuration mapping of names to the structure in question?)
19:53:29 <elliott> dibblego: "preflex: xseen roconnor"
19:53:32 <elliott> preflex: xseen roconnor
19:53:32 <preflex>  roconnor was last seen on freenode/#haskell 11 hours, 29 minutes and 36 seconds ago, saying: ique: it spawns GHC threads but not necessarily OS threads
19:53:39 <NemesisD> JoeyA: i'm not sure if i want it fair
19:53:40 <Philippa> (though there's some overlap with delegation in the OO sense too)
19:53:45 <dibblego> ta
19:54:03 <elliott> Philippa: data-lens-template lets you pass it a function to map field name -> lens name, but I get the feeling I'm still misunderstanding :)
19:54:09 <NemesisD> JoeyA: i guess the only reason for it to be fair is if you're don't need *all* the results at once right?
19:54:25 <Philippa> that would probably suffice, yeah
19:54:29 <clsmith> hey. is there a typeclass for viewl-ing?
19:54:36 <JoeyA> NemesisD: If that's the case, then don't read all of the items in a single transaction.
19:54:58 <JoeyA> Pick off the first item of each (if available), and handle it in IO or whatever.
19:55:10 <Philippa> probably for all the use cases I have in mind, in fact. At least, by the time you've thrown the lens names into a typeclass!
19:55:24 <magicman> clsmith: Foldable? Or... that's viewr-ing, isn't it?
19:56:30 <Philippa> hmm. Yeah, it's starting to sound like I should try hacking up something other than type checkers and interpreters again sometime
19:56:45 <dolio> What else is there?
19:56:55 <Philippa> partial evaluators? :p
19:57:00 <clsmith> magicman: Foldable doesn't offer a function :: f a -> (a, f a)
19:57:01 <dolio> Yeah, that's true.
19:57:14 <clsmith> or, i suppose, Maybe (a, f a)
19:58:03 <dolio> Only if you're expecting the original 'f a' to go back in the right spot.
19:58:23 <hpaste> NemesisD annotated “drainTMChans” with “drainTMChans (annotation)” at http://hpaste.org/66409#a66411
19:58:37 <NemesisD> JoeyA: a little cleaner, something is blowing up my stack though :P
19:58:38 <Philippa> but... well, I did a lot of thinking about what enterprise-but-not-in-the-stupid-sense Haskell code might look like when hs-plugins was new, for example, and it'd probably be useful-to-me to at least think through some of that again. And I should definitely relearn doing 'real' IO
19:58:47 <NemesisD> whoops
19:59:30 <hpaste> NemesisD annotated “drainTMChans” with “drainTMChans (annotation)” at http://hpaste.org/66409#a66412
20:02:48 <hpaste> “Joey Adams” annotated “drainTMChans” with “drainTMChans (annotation) (annotation)” at http://hpaste.org/66409#a66413
20:02:57 <JoeyA> There's how I might do it.
20:03:38 <JoeyA> Since an STM transaction will not observe changes from other threads, it hardly matters what order you read the items if you read all available items.
20:04:50 <rasfar> does anyone know where to find a collection of "standard test graphs", or have ideas how to web search for that?  no luck so far...
20:05:03 <NemesisD> ah yeah i see why i wouldn't want to use readTMChan in that case since it would block on that first channel
20:06:50 <NemesisD> JoeyA: what is dl supposed to stand for?
20:06:56 <JoeyA> NemesisD: "difference list"
20:07:01 <JoeyA> http://www.haskell.org/haskellwiki/Difference_list
20:07:28 <JoeyA> It's a technique for building a list of items that supports efficient append.
20:08:20 <magicman> clsmith: Hrm, yes, you're right. I had hoped to hack up something elaborate, but you need an (insert :: a -> f a -> f a) or something for that.
20:10:47 <NemesisD> JoeyA: hmm, i thought ghc now made it so you didn't have to specify the number of native threads to run
20:11:18 <JoeyA> NemesisD: What is that in reference to?
20:12:11 <hpaste> NemesisD pasted “TMChans Testing” at http://hpaste.org/66414
20:12:39 <NemesisD> that code is really good at pinning 1 cpu core
20:14:00 <JoeyA> NemesisD: STM doesn't do huge transactions well.
20:14:15 <JoeyA> (e.g. reading a million items from a channel)
20:14:27 <JoeyA> At least as far as I can tell.
20:14:37 <NemesisD> what tool should i have chosen instead
20:14:48 <JoeyA> When are you going to run into that in practice, though?
20:15:46 <NemesisD> so the actual code i'm thinking about using this in will spawn a bunch of threads with mysql conns, they will get pumped data to query against and as the results come in they will be processed
20:16:07 <JoeyA> Why not write all the results to a single TChan ?
20:16:36 <JoeyA> Use a TVar Int to track the number of worker threads still running.
20:16:40 <NemesisD> JoeyA: how will the main thread know when to stop reading in my toy case?
20:17:05 <JoeyA> So the first thing your transaction would do is... class?
20:17:20 <JoeyA> (this is sort of a trick question)
20:17:46 <JoeyA> Assuming you have TVar Int and TChan Result
20:18:35 <JoeyA> Where the TVar Int is the number of workers still running, and the TChan Result is a single channel to which all of the worker threads write their results.
20:19:46 <NemesisD> so it would spawn threads each with a reference to the threadCount and resultQueue, then each loop i guess it would try read and check the counter
20:19:58 <NemesisD> each thread decrementing the counter
20:22:13 <NemesisD> i guess not even try, it could just readTMChan since there's only 1
20:22:20 <JoeyA> But here's where it's easy to mess up: do you check the counter first, or do you get available items first?
20:22:37 <JoeyA> Don't need TMChan, since nobody's going to close the channel.
20:22:55 <JoeyA> If you have multiple writers writing to a shared channel, you don't want a writer closing it.
20:23:14 <NemesisD> id check the chan first then the thread count. a thread could have finished but still left something in the chan
20:23:17 <JoeyA> (as that will cause items from other channels to be discarded, too)
20:23:21 <JoeyA> NemesisD: Bingo
20:24:25 <NemesisD> JoeyA: and whats the relevant difference here between chan and tchan
20:25:11 <JoeyA> You mean TChan and TMChan?
20:26:02 <NemesisD> JoeyA: Control.Concurrent.Chan
20:26:10 <JoeyA> Chan doesn't use STM.
20:26:22 <NemesisD> so not threadsafe then?
20:26:58 <JoeyA> No, it's thread-safe, as it's based on MVars underneath.
20:27:23 <NemesisD> so what's the practical difference to me?
20:27:33 <JoeyA> STM provides a nicer interface.
20:27:38 <monochrom> it doesn't fit your STM usage
20:28:11 <JoeyA> Chan *might* be faster, but a) The difference should be negligible, if you plan on having workers talk to a friggin database server, and b) Chan might even be slower.
20:29:04 <NemesisD> i see
20:30:31 <JoeyA> If your application does other stuff with STM, throwing a non-STM Chan into the mix might make things hard.
20:31:51 <JoeyA> For a simple application, Chan might be more convenient, since you can use getChanContents to read the channel lazily.
20:33:37 <NemesisD> oh, i didn't know it was just an interface issue, i thought they had widely different performance characteristics
20:34:47 <JoeyA> Well, they do have different performance characteristics.
20:36:14 <elliott> They have different semantics.
20:43:29 <NemesisD> JoeyA: in your idea for using a thread counter, you'd still need a TMChan for the input queue right?
20:43:42 <NemesisD> since the workers have to know when the queue is done
20:44:18 <JoeyA> That would make sense, assuming all workers read from the same queue.
20:45:28 <scooty-puff> does anyone know a paper that illustrates rules for record subtyping that do not require explicit coercion?
20:46:38 <scooty-puff> basically: x = if ... then { x: ... } else { x: ...; y: ... } would have type { x: ... }
20:47:09 <scooty-puff> but the way i've written in, the type environment is part of a reader monad that is only local'ly updated
20:47:23 <scooty-puff> would it have to be made part of the state?
20:47:41 <scooty-puff> (which also would worry me..)
20:49:02 <NemesisD> hmm kind of annoying there's no modifyTMVar
20:49:29 <NemesisD> JoeyA: would the counter make more sense as an IORef?
20:50:42 <JoeyA> What are you doing with TMVar?
20:50:59 <JoeyA> Versus just TVar
20:51:23 <JoeyA> NemesisD: You could use IORef, but you'd have to do the counter check outside of STM.
20:52:12 <NemesisD> oh tvar
20:52:17 <NemesisD> gah these names are confusing
20:52:19 <JoeyA> STM has modifyTVar', as of version 2.3
20:52:56 <JoeyA> (which was released a little over a month ago)
20:59:56 <Enigmagic> NemesisD: what would modifyTMVar look like? you could easily code one up yourself
21:01:00 <Enigmagic> unlike IORefs or MVars you can pack multiple TVar/TMVar reads/writes into a transaction
21:03:17 <JoeyA> NemesisD: When dealing with counters, get in the habit of forcing the accumulator.
21:04:17 <JoeyA> modifyTVar' does this for you.  If you wrote it by hand using readTVar and writeTVar, you'd throw a $! or seq in there.
21:05:40 <JoeyA> If you keep incrementing the counter over and over and never force evaluation of the value, you'll get a space leak.  When you do finally evaluate it, you'll get a stack overflow if enough (+1) computations piled up.
21:19:24 * hackagebot http-conduit 1.4.0.2 - HTTP client package with conduit interface and HTTPS support.  http://hackage.haskell.org/package/http-conduit-1.4.0.2 (MichaelSnoyman)
21:23:10 <hpaste> NemesisD pasted “New TChan Test” at http://hpaste.org/66418
21:23:14 <NemesisD> JoeyA: i think i botched the diff list. this code runs for a few seconds then outputs a singleton list of 0
21:23:46 <JoeyA> return $! [x]
21:23:48 <JoeyA> There's your singleton
21:24:34 <JoeyA> NemesisD: Why don't you make drainResults more polymorphic?  TChan a -> TVar Int -> STM [a]
21:26:00 <NemesisD> JoeyA: because this is just throwaway code to learn how it works
21:26:29 <NemesisD> JoeyA: do i want to do return $! x:(dl id) ?
21:26:59 <JoeyA> Well, first of all, drainResults blocks when the channel exhausted, for one thing.
21:27:14 <JoeyA> More precisely, readTChan retries when the channel is empty.
21:27:31 <monochrom> @tell copumpkin do you know who is behind the "haskell page" on google plus? that is, https://plus.google.com/102374556577483081270/about
21:27:31 <lambdabot> Consider it noted.
21:27:45 <JoeyA> So drainResults never returns anything except when count /= 0.
21:28:10 <JoeyA> When count /= 0, it returns that singleton, and doesn't see any of the other items.
21:28:34 <copumpkin> monochrom: nope, sorry :/
21:28:34 <lambdabot> copumpkin: You have 1 new message. '/msg lambdabot @messages' to read it.
21:28:52 <JoeyA> NemesisD: If you're gulping all available items, use tryReadTChan so your transaction won't retry when you've reached the end.
21:29:26 <JoeyA> Second, get that threadCounter check out of drainResults.  That can be done separately.
21:30:07 <JoeyA> Finally, your transaction as a whole will need to 'retry' if no items are available and worker threads are still working.
21:30:43 <JoeyA> NemesisD: It might be better to have your consumer read only one item at a time, rather than reading all available items.
21:31:03 <NemesisD> JoeyA: it isn't
21:31:14 <NemesisD> my consumer IRL will need all the data
21:31:43 <JoeyA> At once?
21:32:12 <NemesisD> essentially
21:32:18 <JoeyA> Might be better to set a limit on the number of items to gulp.
21:32:37 <JoeyA> Otherwise, I imagine you'll get a lot of retry overhead.
21:32:54 <clsmith> edwardk: hey. i've been thinking of using your rope package for an experimental text editor. for regexes, do you think it would be efficient enough to just toList, or do you think i should write a regexer specifically for ropes' chunks?
21:33:29 <edwardk> clsmith: not sure, i haven't touched that package in a while. you might want to look at the ropes that are used in trifecta
21:33:52 <dibblego> edwardk: your comment on the (non-)existence of (|||) on Lens/PartialLens would be great https://github.com/roconnor/data-lens/commit/8f0158c89290271799d2c4cc1d6fd5193ed3da2a
21:33:53 <JoeyA> NemesisD: Before an STM transaction commits, it checks to make sure none of the values it read changed.
21:34:00 <Philippa_> hell, probably at trifecta in general?
21:34:16 <Philippa_> it'd be great to have an editor that used trifecta to do syntax highlighting
21:34:36 <JoeyA> If the tail of the TChan changes between getting the last item and committing the transaction, drainResults will have to start all over.
21:34:43 <NemesisD> ok so in the actual app it divides a list of dbs up amongst a gang of threads. it then feeds an id, for example, to each thread and needs to get the result of the query from *each* database
21:35:08 <NemesisD> aaand i'm thorughly lost
21:35:16 <JoeyA> Meaning each thread needs an id?
21:35:26 <JoeyA> If you have a single shared TChan, the items will be divvied up.
21:35:37 <JoeyA> Which, if I understand correctly, is not what you want.
21:35:40 <edwardk> dibblego: i talked with roconnor about it here in channel for a while
21:35:50 <dibblego> edwardk: ok cool
21:36:27 <NemesisD> each thread will get one id (probably more like a chunk, but forget that for simplicity), the same id in fact, and will require the threads to query all their databases with that same id
21:36:38 <edwardk> dibblego: scalaz has ||| for lenses too
21:36:46 <NemesisD> they push their results back to the main thread which then supplies them with the next id and processes what they gave it
21:36:56 <edwardk> its +++ and &&& that fail
21:37:02 <dibblego> edwardk: right, and for partial lenses, but roconnor doesn't like its properties
21:37:04 <dibblego> right
21:37:08 <dibblego> (and left/right)
21:37:33 <JoeyA> NemesisD: Two options: 1) Give each thread its own TChan, and write each id to all of the TChans.  2) Write rows to a single TChan, and use dupTChan to duplicate it for each worker thread.
21:37:59 <JoeyA> Note that for option 2, you have to ensure every TChan you create gets read; otherwise, you'll get a memory leak.
21:38:41 <edwardk> dibblego: i didn't realize he was removing it in that commit
21:38:47 <edwardk> we'd talked about him adding one
21:39:12 <dibblego> edwardk: he has removed it and we will probably do a 2.9.0 release until we sort out that issue
21:39:25 <JoeyA> Unfortunately, this is hard to do unless you create all of your workers up front.  See http://hackage.haskell.org/trac/ghc/ticket/5911
21:39:28 <edwardk> ah well
21:39:49 <edwardk> i definitely would like to have the operator
21:39:54 <edwardk> i don't care what its called
21:39:59 <dibblego> me too, perhaps names something elsre
21:40:07 <dibblego> and on a type-class for both Lens/PartialLens
21:40:13 <NemesisD> JoeyA: what is the most likely outcome is that i'll leave my code the hell alone and not introduce chans to it at all
21:40:20 <dibblego> (and (->) and Kleisli f...)
21:40:40 <elliott> edwardk: what is an actual use-case for the operator?
21:40:58 <edwardk> elliott: its there because it can exist ;)
21:41:00 <elliott> i considered it ugly because I couldn't think of a useful way to use it without fromLeft/fromRight at all
21:41:02 <elliott> asserting the invariant
21:41:07 <NemesisD> it runs well enough now i just wanted to learn about tchans/stm, but it seems like i'm getting stuck in implementation details
21:41:09 <elliott> edwardk: that's what i was afraid of :(
21:41:27 <edwardk> elliott: we actually use the scalaz version somewhere in our compiler i just don't remember where
21:41:36 <dibblego> "can exist" is pretty compelling
21:41:39 <elliott> if there's really no way to usefully use it without that unsafe forcing of the invariants I don't see why you'd want it
21:41:53 <edwardk> what unsafe forcing of the invariants?
21:42:07 <JoeyA> NemesisD: I've felt that way a lot dealing with concurrency and IO in Haskell :(
21:42:08 <elliott> edwardk: enforcing that it gives you back the same constructor you fed in when setting
21:42:09 <edwardk> you can't implement it wrongly for lenses or it won't type check
21:42:20 <NemesisD> the heart of what i'm doing is dividing work amongst a pool of threads and gathering the results. i'm starting to think i've chosen the wrong tool
21:42:25 <elliott> this is Lens a c -> Lens b c -> Lens (Either a b) c, right?
21:42:34 <elliott> so if you set it with (Left x), you always get a (Left y) out
21:42:34 <edwardk> yep
21:42:37 <dibblego> elliott: correct
21:42:43 <elliott> I don't see any useful way to use that lens without fromLefting it in that case
21:42:47 <elliott> hmm
21:43:05 <elliott> actually, if you have Either SomeType SomeRelatedTypeWithDifferentExtraStuffOrSomething
21:43:09 <edwardk> um, you have an either, and you have a way to get something out of either half, so you can get it out of the whole either.
21:43:12 <elliott> then you could use it to modify it "transparently" through the EIther
21:43:16 <edwardk> yes
21:43:20 <elliott> edwardk: yes, I know it's implemented :)
21:43:28 <elliott> I just couldn't think of any uses where you wouldn't immediately fromLeft or fromRight it
21:43:33 <elliott> *implementable
21:43:36 <elliott> ok, fair enough
21:44:11 <edwardk> lets say you have an 'Either' in a container. its a way to drill down into a member of the either that is available from either side
21:44:14 <JoeyA> Haskell can be a surprisingly productive language (as I discovered writing my recursive-line-count program).  But dealing with the perils of concurrency, IO, and exceptions kills it.
21:44:19 <edwardk> or some equivalent notion
21:44:24 <elliott> edwardk: I do understand how it works :P
21:44:27 <JoeyA> @hackage recursive-line-count
21:44:27 <lambdabot> http://hackage.haskell.org/package/recursive-line-count
21:44:46 <elliott> the perils being that concurrency and IO is nicer in Haskell than most other languages?
21:44:55 <edwardk> JoeyA: that can be said of every language, and i'd argue that haskell makes concurrency IO and exceptions a hell of a lot more palatable than languages in which their semantics are almost completely undefined
21:44:55 <elliott> I've run into those!
21:45:04 <JoeyA> elliott: Nicer, maybe, but it's still hard.
21:45:10 <edwardk> i'm sorry. it can't be said of every language
21:45:21 <edwardk> there are languages like python where the concurrency thing isn't an issue because its not available
21:45:36 <elliott> "Haskell makes concurrency, IO and exceptions nicer than other languages -- that's why dealing with the perils of concurrency, IO, and exceptions kills it"?
21:45:38 <NemesisD> JoeyA: save for this endeavor i've found the concurrency tools in haskell a lot more performant than my native language, ruby
21:45:48 <elliott> that... doesn't make much sense, except as a blanket "programming sucks because of concurrency, IO and exceptions"
21:45:55 <elliott> which isn't really a statement about haskell :P
21:46:11 <edwardk> joeya: as a general rule if concurrency is hard for you in haskell you are living far too much in the IO monad
21:46:21 <NemesisD> doing hard work on multiple cores in ruby is essentially a joke for now unless you use JRuby. it has native threds but with a global interpreter lock :(
21:46:37 <monochrom> unless you are a pure mathematician, there is something unproductive about considering IO to be perilous
21:46:40 <dibblego> if IO is hard for you in Haskell, you have never used Scala, Java, C#, Python and friends
21:47:06 <NemesisD> dibblego: i think you're mistaking hard with error-prone
21:47:10 <edwardk> monochrom: i don't consider it perilous, but i also try to keep large swathes of code pure because its easier to sprinkle par than forkIO
21:47:15 <dibblego> NemesisD: I mean both
21:47:21 <edwardk> monochrom: and far easier to prove that that code is safe when i do
21:47:37 <JoeyA> Well, an example of a practical peril is: should I bother making foo async exception safe?
21:47:40 <NemesisD> ruby is close to python. i cannot fathom how one could think IO was difficult in ruby
21:48:12 <monochrom> oh, I agree with keeping IO out of data crunching
21:48:13 <edwardk> joeyA: what is a typical example of something foo would be doing for you?
21:48:14 <JoeyA> And if foo needs to be exception safe, can I count on the functions I'm calling being async exception-safe, too?
21:48:16 <dibblego> the absence of first-class IO programs is pretty non-productive, resulting in difficulty, just to get started
21:48:31 <NemesisD> first-class io programs?
21:48:39 <JoeyA> edwardk: Something I would need to interrupt, like performing a download or talking to a client.
21:48:44 <dibblego> yes, an interpreter for the IO programming language that is built into haskell
21:49:03 <elliott> JoeyA: if it wants to be interrupted, then just let async exceptions happen...
21:49:05 <elliott> that's what they're for
21:49:19 <Orclev_> dibblego: something seems profoundly wrong abut that statement
21:49:20 <JoeyA> Yes, but it's easy to leak sockets that way.
21:49:20 <dibblego> we wrote one for Scala by the way -- an improvement, but nowhere near as useful as haskell
21:49:29 <edwardk> joeya: thats what bracket is for
21:49:45 <elliott> yeah, that's why you allocate resources properlyt :P
21:49:46 <NemesisD> what you're saying is going way over my head
21:49:50 <JoeyA> If you use http-conduit or http-enumerator and kill the thread right before the download can start, you'll leak a socket.
21:50:00 <elliott> in http-conduit? really?
21:50:04 <elliott> ResourceT is meant to prevent that, no?
21:50:23 <edwardk> thats what yelling at snoyman is for ;)
21:50:30 <monochrom> first-class IO programs means you can have forever :: IO a -> IO ()  (see the IO a parameter there?) and some other goodies
21:50:48 <JoeyA> Take a look at the source.  withSocketConn creates a socket, and returns it to a caller which puts it where it belongs.
21:50:54 <elliott> to be fair, many other languages have first-class IO programs too, they're represented as impure functions with a dummy parameter
21:50:59 <elliott> it's a pain to work that way though :p
21:51:06 <elliott> JoeyA: yes, but that's in ResourceT
21:51:10 <lispy> hi
21:51:11 <elliott> which handles cleanup itself
21:51:23 <JoeyA> And there's no async exception mask between creating the socket and establishing the cleanup.
21:51:30 <dibblego> yes, other languages have it -- but often it is so difficult, that it is not worth using
21:51:59 <monochrom> some other goodies means you can have: join $ atomically $ (readTChan c1 >> return (putStrLn "first channel")) `orElse` (readTChan c2 >> return (putStrLn "second channel"))  which is like a select on c1 and c2
21:52:05 <elliott> JoeyA: well, that's a ResourceT bug then
21:52:15 <elliott> it should tie resource allocation to finaliser registration
21:52:16 <JoeyA> No, it's an http-conduit bug.
21:52:19 <JoeyA> err
21:52:28 <elliott> no, ResourceT is meant to manage this stuff
21:52:33 <elliott> so if it doesn't handle it correctly, then it's broken
21:52:36 <Veinor> is there a way to build a hoogle database for everything in the current cabal-dev install?
21:52:36 <JoeyA> Well, resource allocation takes an IO action.
21:52:41 <Veinor> i'd like to be able to hoogle yesod
21:52:49 <elliott> JoeyA: yes, but it can happen before finalisers are registered
21:53:09 <JoeyA> You could just as easily make an IO action that does: do {socket ...; allowInterrupt}
21:53:26 <JoeyA> (in which case, finalizers won't be registered)
21:53:52 <elliott> yes, and ResourceT is meant to solve the problem "finalisers in IO are hard"
21:54:30 <strager> @pl \p -> braces (many p) >>= return . Ast.Body
21:54:30 <lambdabot> (Ast.Body `fmap`) . braces . many
21:54:41 <strager> ick.
21:54:44 <JoeyA> Hmm, maybe the bug I speak of doesn't exist.
21:54:49 <elliott> strager: Ast.Body <$> braces (many p)
21:55:02 <JoeyA> If allocate is used, then there's an exception mask to keep the socket from leaking.
21:55:09 <elliott> strager: m >>= return . f === fmap f m
21:55:12 <elliott> === f <$> m
21:55:23 <Enigmagic> JoeyA: looks like it's masked here ? https://github.com/snoyberg/http-conduit/blob/master/Network/HTTP/Conduit/Manager.hs#L317
21:55:30 <strager> elliott: Yes, I know that.  I was trying to remove the point.
21:55:39 <strager> So I wrote the expression out in long form.
21:55:49 <JoeyA> Enigmagic: restore $ liftIO open
21:55:55 <JoeyA> So much for that.
21:56:14 <JoeyA> My point is, making code async exception safe is difficult.  There are cases where it's needed, and there are cases where it's a waste of time.
21:56:27 <elliott> @pl \p -> fmap Ast.Body (braces (many p))
21:56:27 <lambdabot> fmap Ast.Body . braces . many
21:56:33 <elliott> strager: you defeated your own goal :P
21:57:01 <ivanm> how to make haddock bitch: comment out a guard...
21:57:59 <JoeyA> heh
21:59:16 <JoeyA> But knowing when you need async exception safety versus when you don't means knowing what you plan to do with the module in question.  That hurts being able to build programs piecemeal.
21:59:20 <Enigmagic> JoeyA: can a user of the library provide their own open? it seems like normally open would have to throw an exception if the socket failed to open
21:59:29 <JoeyA> Enigmagic: Nope,.
21:59:31 * hackagebot aeson 0.6.0.2 - Fast JSON parsing and encoding  http://hackage.haskell.org/package/aeson-0.6.0.2 (BryanOSullivan)
22:00:16 <JoeyA> An async exception mask doesn't prevent exceptions arising from the current thread.
22:00:25 <monochrom> on programmer-caused async exceptions such as array out of bounds, fromJust Nothing, etc., I hold this view: it is better to have never loved than to have loved and heart-broken
22:00:37 <JoeyA> Those aren't asynchronous...
22:00:46 <edwardk> joeya: so guard the crap out of your io subsystems and insulate the rest of your program from that as much as possible ;)
22:01:01 <monochrom> those aren't asynchronous in C, sure
22:01:02 <JoeyA> Easier said than done.
22:01:29 <JoeyA> An asynchronous exception is an exception thrown using throwTo
22:02:33 <edwardk> when someone throws an exception at you, duck.
22:02:53 <JoeyA> @quote edwardk When someone throws an exception at you, duck.
22:02:53 <lambdabot> No quotes match. Your mind just hasn't been the same since the electro-shock, has it?
22:03:03 <JoeyA> @remember edwardk When someone throws an exception at you, duck.
22:03:03 <lambdabot> Done.
22:03:22 <monochrom> with Haskell where "fromJust Nothing" may or may not throw an exception, and if it does it happens at a time not determinable lexically, that is so close to async exceptions that SPJ just calls it one of them
22:03:42 <JoeyA> I see
22:04:14 <JoeyA> Where a pure value goes "surprise" and rears its ugly bottom?
22:04:32 <monochrom> yeah
22:04:53 <monochrom> you can arrange it so it happens to a thread not lexically determinable, too
22:04:59 <Philippa_> pretty much. Also, AIUI they're async in the sense of Hope & Hutton's work?
22:04:59 <edwardk> then you were meant to die a horrible death. sorry, better luck in the next life er.. process
22:05:52 <strager> Can I partially apply a constructor using the record syntax?
22:05:55 <strager> http://hpaste.org/66420
22:06:05 <strager> (If that makes sense ...  kinda new to Haskell)
22:07:01 <edwardk> i have finally decided on how to handle the annoying import qualified Foreign.ForeignPtr.Unsafe as Unsafe problem since Unsafe.unsafeForeignPtrToPtr was kinda redundantly redundant
22:07:12 <edwardk> import qualified Foreign.ForeignPtr.Unsafe as Really
22:07:39 <monochrom> I haven't known of Hope & Hutton on async exceptions. (I have only known counting lazy evaluation steps)
22:07:45 <edwardk>  describe a = Really.unsafeDupablePerformIO $ do ...
22:08:10 <strager> I think Unsafe.unsafe is fine.  =D
22:08:18 <JoeyA> withForeignPtr is unsafe, to...
22:08:34 <JoeyA> For example: http://codereview.stackexchange.com/a/10079/2672
22:08:35 <elliott> edwardk: import qualified Foreign.ForeignPtr.Unsafe as Thing
22:08:38 <Philippa_> monochrom: yeah, I just went and double-checked. I'd definitely misremembered something - can't remember if it's whether Hope worked on any of that stuff at all and just didn't get to the point of publishing, or just didn't work on it
22:08:56 <Philippa_> (I was an undergrad at UoN at the time)
22:08:58 <edwardk> strager: sadly no, record syntax when you haven't supplied all the arguments just puts in undefineds for the missing parts
22:09:04 <JoeyA> Here, someone passed a pointer from withForeignPtr to a continuation that gets called outside of withForeignPtr's runtime scope.
22:09:07 <edwardk> strager: so you are stuck with the lambda
22:09:13 <edwardk> (or learning lenses)
22:09:49 <strager> Something like lenses are too heavy-weight IMO =]
22:09:57 <strager> I don't abuse records (yet).
22:10:06 <copumpkin> they're not just for abusing records
22:10:11 <copumpkin> they're useful in all sorts of places
22:11:36 * elliott wonders how anything can be less heavy-weight than (a -> (b, b -> a))
22:11:46 <strager> Using the built-ins?  =]
22:12:05 <elliott> that's more heavy-weight
22:12:07 <elliott> special syntax built in
22:14:24 <strager> Requires less dependencies, known to work pretty well and efficiently, won't conflict with anything, less mental overhead
22:15:44 <elliott> i think you vastly overestimate data-lens' dependencies :)
22:15:58 <strager> Requires less dependency =]
22:16:02 <elliott> ...and there's hardly much "unknown" about lenses, since they're in wide production use and there isn't exactly many performance opportunities for them to go wrong
22:16:42 <copumpkin> in the time spent arguing about how heavyweight lenses are, you could've learnt how to use them (they're that easy) and started using them in your program
22:16:57 <monochrom> all you mean is that lenses is not covered in LYAH
22:16:58 <strager> Well why would I use them?
22:17:14 <Enigmagic> elliott: though data-lens does have a lot of dependencies (large or not) that i don't currently have installed
22:17:16 <strager> I mean, I know there are reasons to use them, but I haven't yet needed them.
22:17:18 <edwardk> i'm not trying to sell lenses here more than that one tongue-in-cheek comment
22:17:27 <copumpkin> MUALL
22:17:34 <edwardk> hah
22:17:52 <edwardk> great, now that acronym will be used to bludgeon people into the cult of lenses ;)
22:17:54 <monochrom> lenses just mean getters and setters
22:18:00 <strager> I know that.
22:18:29 <monochrom> what is MUALL?
22:18:50 <edwardk> monochrom: http://comonad.com/reader/2012/wadlers-law-revisited/
22:19:54 <monochrom> oh God, Wadler's law is already facing a revision!
22:20:03 <edwardk> this would be its second revision
22:20:16 <edwardk> it was updated from the original 1992 definition by wadler himself in 96
22:20:27 <edwardk> the original just talked about the fervor of debate in relative terms
22:20:29 <monochrom> but I also see a further revision. it's so elegantly cyclic:
22:20:38 <edwardk> the 1996 adaptation was extended to give the actual power law
22:21:23 <monochrom> 0. semantics; 1. syntax; 2. lexical syntax; 3. lexical syntax of comments; 4. semantics of records; 5. syntax of records; 6. lexical syntax of records; 7. lexical syntax of comments of records
22:21:35 <edwardk> in many ways the strong record conjecture can also be seen as both a generalization and a return to the original thrust of the 1992 version, being about the fervor of opinions rather than durations
22:21:36 <edwardk> yeah
22:21:49 <edwardk> i omitted that one but commented about it on reddit ;)
22:21:59 <edwardk> if that one is added then you can shift the powers down
22:22:07 <edwardk> and it all becomes wadler's original law
22:22:11 <edwardk> just a special case
22:22:11 <monochrom> oh, I see it when I scroll down. good job!
22:22:26 <edwardk> the only one i omitted was the comments part
22:23:20 <edwardk> Consequently, and in the name of science, I plan to check in again on the record debate in 3 years. ;)
22:23:50 <monochrom> Wadler would be pleased that his law is parametrically polymorphic
22:24:25 <monochrom> God, we just missed April 1st, didn't we? "Wadler's Laws for Free!" would be so apt
22:26:08 <edwardk> i deliberately stated it the day after april 1st, because i wanted it to be clear i wasn't really joking
22:26:38 <edwardk> i'm really rather disgusted with the current state of that discussion
22:28:10 <Philippa_> edwardk: yeah, that came through. You're not the only one, either
22:28:59 <Philippa_> hell, the main reason I didn't make more concrete proposals myself is I really couldn't be arsed to deal with the syntax bikeshedding
22:29:28 <Philippa_> (and the proposals I did have in mind were aimed at being 'unifying enough' at any given moment)
22:30:45 <edwardk> my main problem is every single one of those proposals breaks polymorphic updates to a greater or lesser degree.
22:31:05 <edwardk> and they aren't worth enough to me to be worth that cost
22:31:38 <Philippa_> mmm. Mine was approximately "fuck it, can we figure out enough sugar to make experimenting with solutions something that more users can tolerate doing?"
22:32:45 <Philippa_> I mean, no doubt you would've had cause to be scathing had it been sufficiently-concrete, but still :-)
22:34:15 <c_wraith> I wonder how much pain would go away if we had a pointless syntax for record update.
22:36:54 <Philippa_> hmm, you'd be able to leave most of the TH you might need to the modules that define your new records at least
22:37:53 <augur> edwardk :|
22:38:08 <augur> just tell me we're breaking up T_T
22:38:10 <augur> GOSH
22:42:24 * edwardk didn't realize he was dating augur
22:42:30 <augur> edwardk: :p
22:42:42 <augur> intellectually
22:42:45 <augur> well its more stalking
22:42:47 <augur> BUT THATS NOT THE POINT
22:42:55 <edwardk> I apparently have sent mixed signals. I must ask someone for a native coder judgment
22:43:41 <augur> im going to play some wipeout. edwardk, i expect explanations of the type error in that equation >|
22:43:42 <augur> |<
22:43:43 <augur> >|
22:44:04 <edwardk> i'm going to go get work done and i may eventually take a look at this equation =P
22:54:37 * hackagebot fast-tags 0.0.4 - Fast incremental vi tags.  http://hackage.haskell.org/package/fast-tags-0.0.4 (EvanLaforge)
22:58:10 <strager> ^ cool
22:58:54 <strager> I don't understand: > Like hasktags, it uses its own parser rather than haskell-src or haskell-src-exts, so it's fast.
22:59:02 <strager> Are those packages known to have slow parser implementations?
22:59:31 <Veinor> ok cabal-dev is throwing errors everywhere now for some reason
22:59:31 <cadabra> Suppose I have a class ToString a where toString :: a -> String. If a is an instance of Show, I can provide a default toString, but I don't want to require Show. Is there a way to do something like that using type classes?
23:00:32 <strager> cadabra: Maybe:  instance (Show a) => ToString a where { toString = show } ?
23:04:25 <cadabra> strager: Illegal instance declaration
23:05:24 <mraxilus_> does anyone know how I can go about making an infinite list which doesn't include powers of 2, e.g., 2, 4, 8, 16...
23:06:04 <cadabra> filter (not . isPowerOf 2) [1..]
23:07:12 <mraxilus_> thanks
23:07:53 <cadabra> strager: Adding FlexibleInstances gives: Constraint is no smaller than the instance head in the constraint
23:09:02 <mraxilus_> it failed to recognize isPowerOf
23:09:11 <cadabra> and adding UndecidableInstances gives all sorts of errors in seemingly correct code
23:09:59 <cadabra> mraxilus_: you'll need to implement isPowerOf 2 or isPowerOf2 yourself
23:10:44 <strager> cadabra: Dunno; I'm a newb =]
23:11:09 <edwardk> cadabra: there is a (new) way
23:11:31 <edwardk> cadabra: you can use DefaultSignatures
23:12:12 <edwardk> class ToString a where toString :: a -> String; default toString :: Show a => a -> String; toString = show
23:12:18 <edwardk> notice the 'default toString' there
23:12:23 <edwardk> this requires a pretty current ghc though
23:13:01 <edwardk> strager: instance (Show a) => ToString a where { toString = show } ?  is almost _never_ what you want
23:13:27 <edwardk> strager: in general importing that is going to say that every ToString is supplied by Show, in the absence of OverlappingInstanes
23:13:29 <cadabra> I do have a current GHC! Let me try that.
23:13:44 <edwardk> strager: and in the _presence_ of OverlappingInstances it may not even work!
23:14:02 <edwardk> because it's only likely to work if that instance and the things you wanted it to overlap were defined in the same module!
23:14:28 <edwardk> and beyond that lots of newer extensions break overlapping instances worse and worse
23:16:07 <edwardk> cadabra: you'll still need to say instance ToString Int -- but you'll be able to leave off the definition of the method
23:16:30 <kaitocracy> this might be the wrong channel to ask but I'll do it anyway: okay the fundamental problem I'm having with web development right now is that, say on a couple of pages I have an element that has the current logged in user's username; I require a database lookup to fetch that username; so I see two strategies: 1. perform the db fetch, then render an HTML template based on that result; 2. have
23:16:30 <kaitocracy> my HTML template perform the db fetch. Option 1 means I have to add the db fetch to every page I need to contain that element, option 2 means that I pollute my templates with IO, is there any sort of abstraction that can help me?
23:16:52 <strager> edwardk: I see, okay
23:18:04 <strager> kaitocracy: MVC patterns tend toward option 1.
23:18:45 <kaitocracy> strager: yeah that's what I'd do in Rails but it's kind of a shitty solution
23:18:54 <strager> Though most MVC frameworks have hierarchies or views or something to help you with the common code.
23:19:38 * hackagebot simple-c-value 0.0.0.1 - A simple C value type  http://hackage.haskell.org/package/simple-c-value-0.0.0.1 (JonathanFischoff)
23:20:22 <kaitocracy> maybe there's some abstraction that lets a piece of pure code say, register this IO action so that it always runs before me?
23:25:58 <gnoi> Is there some isJust . find analog like :: (a -> Bool) -> [a] -> Bool?
23:26:16 <copumpkin> :t any
23:26:17 <lambdabot> forall a. (a -> Bool) -> [a] -> Bool
23:27:54 <gnoi> And what about not . null ?
23:28:35 <edwardk> :t notNull
23:28:36 <lambdabot> Not in scope: `notNull'
23:29:06 <gnoi> :hoogle [a] -> Bool
23:29:11 <gnoi> @hoogle [a] -> Bool
23:29:11 <lambdabot> Prelude null :: [a] -> Bool
23:29:12 <lambdabot> Data.List null :: [a] -> Bool
23:29:12 <lambdabot> Prelude all :: (a -> Bool) -> [a] -> Bool
23:29:19 <edwardk> :t any
23:29:20 <lambdabot> forall a. (a -> Bool) -> [a] -> Bool
23:29:36 <edwardk> as opposed to
23:29:37 <edwardk> :t all
23:29:38 <lambdabot> forall a. (a -> Bool) -> [a] -> Bool
23:31:47 <qnikst> gnoi: why not  'not . null'?
23:32:32 <gnoi> qnikst: dunno :3
23:33:44 <gnoi> And the last one. length . filter
23:34:31 <qnikst> same here
23:35:36 <gnoi> I saw that pattern very often. (> n) . length . filter $ (...)
23:37:12 <qnikst> don't thinks it's a bad thing
23:37:15 <edwardk> gnoi no standard name, its  composition of a series of standard operators
23:37:49 <gnoi> edwardk: bigger part of Data.List function is a series of standard operators
23:38:27 <edwardk> gnoi: there is a notion often used, called the Fairbairn threshold. where you weigh the overhead of remembering a new name and teaching it against the benefits of teaching people to compose operators when considering what to add
23:38:29 <gnoi> I have some paranoia that all that kind of stuff is already written for me
23:38:37 <edwardk> this falls somewhat under that threshold
23:38:57 <edwardk> understandable
23:39:12 <edwardk> as you go you'll find more and more of what you wrote by hand already in the prelude
23:39:16 <edwardk> but thats a good thing. ;)
23:39:39 <gnoi> Btw, why hoogle don't tell me about `any`?
23:39:44 <edwardk> funny
23:39:47 <edwardk> @hoogle any
23:39:47 <lambdabot> Prelude any :: (a -> Bool) -> [a] -> Bool
23:39:47 <lambdabot> Data.List any :: (a -> Bool) -> [a] -> Bool
23:39:48 <lambdabot> Data.Monoid Any :: Bool -> Any
23:39:48 <gnoi> @hoogle (a -> Bool) -> [a] -> Bool
23:39:49 <lambdabot> Prelude all :: (a -> Bool) -> [a] -> Bool
23:39:49 <lambdabot> Data.List all :: (a -> Bool) -> [a] -> Bool
23:39:49 <lambdabot> Prelude any :: (a -> Bool) -> [a] -> Bool
23:39:58 <edwardk> there ya go
23:39:59 <gnoi> O, it did ;_;
