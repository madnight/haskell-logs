00:00:19 <startling> efie, reinstall the haskell platform
00:00:49 <startling> efie: I don't know of a command like that. would certainly be convenient, though
00:01:47 <zhulikas> yea... cabal upgrade would be awesome
00:02:13 <zhulikas> "upgrade all the packages and solve whole dependency hell"
00:03:38 <efie> hm ok
00:03:43 <efie> is there a reinstall command..?
00:03:57 <startling> efie: no
00:04:04 <startling> efie: reinstall it the same way you installed it
00:06:05 <efie> startling: Should I delete it before?
00:06:19 <hpaste> scri pasted ‚Äúroutes ocaml‚Äù at http://hpaste.org/73096
00:06:44 <hpaste> scri pasted ‚Äúroutes haskell‚Äù at http://hpaste.org/73097
00:07:15 <startling> efie: I don't think so
00:07:31 <efie> ok, thanks
00:07:52 <scri> Hi all. so, i have programs in OCaml and Haskell to solve this http://projecteuler.net/problem=15
00:08:06 <scri> http://hpaste.org/73096 http://hpaste.org/73097
00:08:35 <scri> so i'm using a simple memo to avoid recomputing paths. my question is,
00:08:56 <avpx> The suspense is killing me
00:09:24 <scri> i was sort of under the impression that due to Haskell's laziness, and the fact that reduced thunks are not recomputed
00:09:37 <scri> the memo thing would be going on without having to do it explicitly
00:09:55 <scri> by the performance of the haskell version shows that couldn't be the case
00:10:09 <scri> or if it is, something else is drastically slowing things down
00:10:59 <scri> mind, i'm cheating a bit in the Ocaml by storing the same values in fin[m,n] and fin[n,m] since they're the same
00:11:27 <scri> but that alone couldn't account for the difference
00:11:30 <zhulikas> I believe this algorithm works effectively until grid size of 14-15, right?
00:11:39 <startling> scri, nope, haskell doesn't memoize
00:11:41 <zhulikas> my solution was to take first 14 members and figure out the progression
00:11:44 <startling> (automatically)
00:12:12 <scri> zhulikas: yeah, but it gets worse and worse
00:12:25 <zhulikas> it does
00:12:31 <zhulikas> with every +1 time increases twise
00:12:34 <zhulikas> twice
00:12:56 <zhulikas> I don't know how this can be #15 problem
00:12:56 <scri> yes, thats about right
00:13:11 <zhulikas> some of the problems >100 were easier for me
00:13:27 <scri> startling: so how can i accomplish memoization?
00:13:40 * zhulikas is also interested 
00:13:48 <avpx> startling: Okay, just curious, let's say you have a conventional recursive Fibonacci implementation fib n = (fib (n - 1)) + (fib (n-2)). And let's say you apply this a lot, like using map fib [2..]. Does GHC's implementation remember previous calls?
00:13:58 <scri> also, it _is_ true that identical thunks are reduced only once, right?
00:14:19 <scri> or am i seriously misunderstanding laziness
00:14:36 <avpx> For instance, if you ask for "fib 3" and then "fib 4", they both depend on "fib 2". Does this get recomputed?
00:14:46 <startling> avpx: I don't know. I don't think so
00:14:48 <scri> avpx: exactly my question
00:15:05 <qtplatypus> avpx: In general no.
00:15:13 <avpx> Isn't that memoization?
00:15:33 <qtplatypus> avpx: Yes
00:16:15 <Quantumplation> o/ Morning everyone
00:16:24 <avpx> So it is a bit curious that scri is having this problem, supposing that he is using pure functions and is relating the performance bottleneck correctly
00:17:49 <avpx> scri: If you want, you can try explicit memoization. I would recommend Data.Map
00:18:05 <startling> hmmm, you can probably use the state monad
00:18:06 <avpx> Essentially, have your function look up the input in the map, and if it's not there, compute the value
00:18:13 <avpx> startling: Yeah, that's a fine idea.
00:18:53 <scri> could do that, but if i use destructive updates, i have to ask, what's the point of using a pure f. language?
00:19:08 <avpx> Destructive updates?
00:19:24 <scri> it's not?
00:19:36 <scri> i'll check it out
00:19:47 <startling> scri, the state monad is like a state argument that gets passed around
00:19:47 <avpx> Data.Map is a pure functional data structure. The operations are like insert :: k -> v -> Map k v -> Map k v, IIRC
00:20:03 <avpx> And yeah, you can write the State monad yourself in pure Haskell, it's really just for plumbing.
00:20:07 <startling> scri: it's computationally the same as passing a map explicitly
00:20:31 <avpx> It lets you easily compose computations of the type s -> (a, s), where s is some internal state that you don't want to have to look at all the time.
00:20:32 <startling> you just get cleaner code (sometimes ?) and nicer type signatures
00:21:44 <scri> interesting, i'll have to try that
00:22:17 <startling> @src state
00:22:18 <lambdabot> Source not found. Just what do you think you're doing Dave?
00:22:19 <startling> err
00:22:22 <startling> @src ST
00:22:23 <lambdabot> newtype ST s a = ST (STRep s a)
00:22:26 <avpx> scri: https://github.com/nvanderw/NumberTheory/blob/master/NumberTheory/MillerRabin.hs
00:22:28 <startling> @src STRep
00:22:28 <lambdabot> type STRep s a = State# s -> (# State# s, a #)
00:22:35 <startling> okay that's complicated
00:22:37 <startling> never mind
00:22:52 <avpx> scri: That's my implementation of the Miller-Rabin primality test using the State monad with random numbers.
00:24:07 <scri> avpx, startling, thanks
00:24:14 <scri> but also though, i really want to understand this better
00:24:37 <avpx> The memoization thing?
00:24:40 <scri> yes!
00:24:48 <scri> why can't we have that?
00:25:01 <startling> scri: more unpredictable memory usage
00:25:04 <avpx> My guess is that it is doing some memoization
00:25:20 <avpx> But it's probably not keeping very many of the mappings around
00:25:35 <avpx> Think about it: there are a lot of paths. If it kept the output for every input that would take much RAM.
00:25:43 <latro`a> I feel like that little randomCoprime thing isn't actually cleaner than the explicit version
00:25:44 <latro`a> :/
00:25:46 <startling> also, the things would need to be Eq
00:25:56 <startling> welll
00:26:02 <avpx> latro`a: Hmm.
00:26:04 <startling> they could probably fake it
00:26:06 <latro`a> oh wait
00:26:16 <latro`a> erm, -oh wait
00:26:25 <avpx> latro`a: What am I waiting for?
00:26:32 <latro`a> I deleted the oh wait
00:26:39 <latro`a> hence the minus sign
00:26:42 <avpx> So I'm not waiting. Phew.
00:26:46 <Ralith> startling: ST and State are different
00:26:57 <scri> startling: but if we're talking about ASTs, what does Eq mean?
00:26:58 <Ralith> it sounds like you were thinking of State, not ST
00:27:02 <Ralith> @src State
00:27:03 <lambdabot> Source not found.
00:27:05 <Ralith> hm.
00:27:10 <Ralith> guess it doesn't have it
00:27:14 <avpx> lambdabot: What do you mean by "the explicit version?"
00:27:21 <avpx> Erm
00:27:25 <avpx> latro`a: ^^
00:27:34 <latro`a> writing it now
00:27:38 <latro`a> it's two lines -_-
00:27:38 <startling> Ralith: oh! I've never actually used state, just Reader, but i thought it was named ST for some reason
00:27:43 <Ralith> but it really is trivial
00:27:49 <avpx> latro`a: You mean without do notation?
00:27:50 <hpaste> latro`a pasted ‚ÄúrandomCoprime, no State‚Äù at http://hpaste.org/73098
00:28:17 <startling> what is ST?
00:28:22 <avpx> latro`a: How does it return the new state?
00:28:35 <latro`a> does it need to?
00:28:43 <startling> oh, is it like State + IO ?
00:28:51 <avpx> latro`a: Yes, that's quite an important part of this
00:28:51 <latro`a> if it does you can do (n,gen')
00:28:59 <c_wraith> startling: ST is IO...  but in a very limited form
00:29:02 <latro`a> wait
00:29:05 <latro`a> return it to what
00:29:06 <avpx> latro`a: The reason I used the State monad at all is because randomCoprime gets called a lot
00:29:10 <latro`a> um
00:29:13 <latro`a> it's two-parameter
00:29:17 <c_wraith> startling: it is limited to mutable data only, no other things you can do with IO
00:29:18 <startling> c_wraith: mhm. I imagine just some mutable block of memory?
00:29:22 <latro`a> the recurrence uses gen'
00:29:23 <latro`a> not gen
00:29:24 <startling> yeah
00:29:48 <startling> interesting
00:29:52 <c_wraith> startling: and it uses some type trickery to encapsulate mutation such that it can be run in a pure context
00:29:57 <avpx> latro`a: Right, but when the function is done, it never gives back another generator. You could do it with a tuple but then you're in State monad territory again
00:30:09 <latro`a> are you using the RNG afterward?
00:30:12 <avpx> latro`a: The reason I use the State monad is because I want the random generator state to be persistent
00:30:14 <avpx> Yes!
00:30:24 <startling> c_wraith: very cool
00:30:27 <latro`a> oh wait, you're doing this over multiple inputs
00:30:35 <latro`a> I didn't read the very last function
00:30:39 <avpx> It's not even that
00:30:40 <latro`a> which makes everything worthwhile
00:30:45 <avpx> You need many coprimes to do Miller-Rabin
00:30:53 <avpx> One lonesome coprime won't do
00:30:59 <latro`a> right
00:31:07 <avpx> So yeah, thus the State monad. I think it works out cleanly.
00:31:18 <latro`a> the actual randomCoprime really doesn't need it
00:31:43 <latro`a> it's when you start using the *Ms that you're getting power out, I think
00:32:00 <latro`a> (fwiw isPrime is an fmap)
00:32:14 <avpx> Well, otherwise what would randomCoprime's signature be? I need to get a new generator from it every time, so it ends up looking like g -> (a, g)
00:32:26 <avpx> But if I want to compose that kind of function, I end up using the State monad
00:32:39 <latro`a> I meant that getting a random coprime doesn't require it
00:32:44 <avpx> Oh, sure.
00:33:03 <latro`a> but chaining randomCoprime calls together, passing the generator *those* return
00:33:08 <latro`a> makes it more worthwhile
00:33:19 <avpx> For sure, that's why I did it that way :)
00:33:53 <latro`a> that said, I'm not sure whether just writing randomCoprime m = state $ \gen -> randomCoprime' m gen, with that definition
00:33:54 <latro`a> might be cleaner
00:33:55 <latro`a> :p
00:34:05 <latro`a> (I don't much like get/put in small functions, basically)
00:34:15 <avpx> latro`a: I struggle with this sort of thing daily
00:34:41 <avpx> I think in a large way Haskell code has a reputation of being inaccessible/unreadable and I went in this case with more verbose code.
00:34:48 <latro`a> true
00:36:03 <avpx> No doubt it could be shorter, but I think it shows the power of the State monad reasonably well
00:36:17 <latro`a> when I first griped I had only looked at randomCoprime
00:36:19 <latro`a> not the rest of it
00:36:26 <avpx> Although one issue I ran into is that it's completely impossible to parallelize, because every random value is dependent on the previous
00:36:27 <startling> any of you folks use shime? no tab completion in the ghci window? :(
00:36:42 <latro`a> in isolation I think randomCoprime is actually rather kludgy
00:36:50 <avpx> latro`a: You're probably right
00:37:11 <Lamen> Someone please give me a hint why "join (+) 100" results in 200? I am a bit confused. :)
00:37:21 <latro`a> lamen: join f = \x -> f x x
00:37:46 <avpx> Is this join from Control.Monad?
00:37:47 <latro`a> that's how it gets defined; if you'd like we can explain why it should be defined that way in the first place
00:38:00 <startling> Lamen: it's the same as (+) 100 100
00:38:23 <startling> latro`a: I'll bite; why is it a lambda?
00:38:36 <latro`a> it doesn't have to be
00:38:42 <latro`a> join f x = f x x works fine
00:38:44 <avpx> Bah, the monomorphism restriction
00:38:46 <avpx> It comes for us all!
00:38:47 <latro`a> but depends on currying to make sense
00:38:57 <latro`a> but yes, MR messes with the lambda version :(
00:39:10 <startling> psh
00:39:14 <latro`a> "join f x = f x x" is like using "const id"
00:39:32 <Lamen> I was trying to simplify map (\x->(x,x,x)) [1..],  @pl outputs map (join (join (,,))) [1..], Just wondering what is 'join' on functions
00:39:33 <latro`a> it's entirely functional, but if someone's already confused it will probably confuse them more :p
00:40:08 <latro`a> Lamen, you can look at Control.Monad.Instances
00:40:33 <latro`a> for the source
00:40:37 <Lamen> I did, but only got a functor instance (?) or was I wrong?
00:40:50 <latro`a> there should be a monad instance for ((->) r) around
00:41:11 <avpx> Ah yes. The lovable old ((->) r) functor.
00:41:18 <Lamen> oh, yes it isÖI was trying to look for a instance for (,) a
00:41:35 <Lamen> my bad.
00:41:41 <mekeor> what is ıÄãπ ?
00:41:44 <mekeor> can't see it...
00:41:50 <latro`a> avpx--shouldn't you actually be able to use Rand?
00:41:56 <latro`a> for this purpose?
00:42:06 <avpx> latro`a: Eh?
00:42:28 <latro`a> Rand is a specialization of State for pseudorandom number generation
00:42:37 <avpx> Oh, neat
00:42:56 <Lamen> latro`a: care to explain why it's defined that way? I am curious :)
00:42:57 <avpx> You can use it to do, like, parallel Monte Carlo simulations and whatnot?
00:43:07 <latro`a> I think so
00:43:13 <latro`a> and sure, Lamen
00:43:22 <latro`a> are you at least acquainted with monads already?
00:43:35 <latro`a> if not I may have to retract that "sure"
00:43:40 <Lamen> I think so, latro`a
00:43:48 <latro`a> alright
00:43:58 <zzing_> :t unlines
00:44:00 <lambdabot> [String] -> String
00:44:05 <latro`a> a monad m has a function join :: m (m a) -> m a
00:44:31 <latro`a> if you substitute in m = ((->) r, you get join :: (r->(r->a)) -> (r->a)
00:44:51 <latro`a> since -> is right associative, that's the same as join :: (r->r->a) -> (r->a)
00:45:01 <avpx> Ah, it's worth noting that an equivalent definition of the monad uses return / fmap / join
00:45:06 <avpx> Rather than return / bind
00:45:12 <latro`a> *nod*
00:45:29 <latro`a> so what we're doing is taking a function that takes two arguments of the same type, and turning it into a function that takes one argument of that type
00:45:52 <latro`a> if you can come up with any other generic way to do this besides join f = \x -> f x x, I'm impressed
00:46:56 <latro`a> does that help?
00:47:28 <avpx> Solid explanation. Would read again.
00:47:43 <avpx> (I know I'm not the target of the explanation but I just wanted to note)
00:47:59 <Lamen> latro`a: sure! It's really helpful! :) glad to have you around
00:48:03 <latro`a> :)
00:48:48 <Lamen> ..and it just "collapsed" the monad one layer down, right?
00:48:57 <latro`a> correct
00:49:01 <latro`a> also I missed a paren
00:49:08 <latro`a> *m = ((->) r) is what I meant
00:49:23 <shachaf> Not "the monad".
00:49:59 <latro`a> not "the monad", true, but you've "peeled off" a layer of the type constructor in the same way that return adds one
00:50:28 <latro`a> "in the same way" is actually made precise by the statement: fmap return . join = id
00:51:39 <shachaf> fmap return . join is not = id
00:52:03 <shachaf> (join . fmap return) is, as is (join . return)
00:52:04 <avpx> Wouldn't it just be return . join?
00:52:15 <shachaf> return . join is also not id.
00:52:15 <latro`a> must be tired, sorry
00:52:29 <avpx> I am definitely tired, and will apologize for nothing.
00:52:31 <shachaf> join loses information, usually.
00:52:43 <Twey> > fmap return . join $ Just Nothing
00:52:45 <shachaf> But return also "adds no information" in a similar sense.
00:52:45 <lambdabot>   No instance for (GHC.Show.Show (m a))
00:52:45 <lambdabot>    arising from a use of `M2093810793...
00:53:38 <mekeor> > fmap return . join $ Just Nothing :: Maybe Integer
00:53:40 <lambdabot>   Couldn't match expected type `GHC.Integer.Type.Integer'
00:53:40 <lambdabot>         against inf...
00:53:49 <mekeor> bummer! :/ :D
00:54:00 <latro`a> @type fmap return . join
00:54:01 <lambdabot> forall a (m :: * -> *) (f :: * -> *). (Monad m, Functor f, Monad f) => f (f a) -> f (m a)
00:54:13 <mekeor> > fmap return . join $ Just Nothing :: Maybe (Maybe Integer) -- last try
00:54:13 <latro`a> ah, that's why they're different
00:54:15 <lambdabot>   Nothing
00:54:19 <mekeor> yeah!!! :D
00:54:37 <latro`a> ahh right
00:54:39 <latro`a> of course
00:54:41 <latro`a> silly me
00:54:49 <mekeor> intelligent me
00:54:52 <mekeor> :P :D
00:54:55 <latro`a> heh
00:55:02 <latro`a> anyway
00:55:34 <latro`a> avpx, Control.Monad.Random may interest you
00:55:46 <avpx> Cool, I will add it to my reading list
00:56:08 <latro`a> in particular that whole get/randomR/put is just getRandomR
00:56:13 <latro`a> in MonadRandom
00:56:32 * hackagebot pqc 0.5.1.1 - Parallel batch driver for QuickCheck (KidoTakahiro)
00:56:35 <avpx> Neat.
00:56:55 <Lamen> Thanks everybody for the informative discussion.
00:57:20 <mekeor> Lamen: no problem :D
00:58:43 <latro`a> also, using the IO MonadRandom opens up parallelization
00:58:53 <latro`a> (though it taxes your system entropy more, obviously)
00:59:00 <avpx> Well yeah :p
00:59:15 <avpx> But that's great. I was wondering what solutions people had to that problem.
01:06:53 <edsko> the channel header says 'hackage new IP' but doesn't tell me which -- anyone?
01:07:06 <shachaf> edsko: It should've propagated by now.
01:07:33 <edsko> shachaf: hackage is still timing out for me :-/
01:07:42 <shachaf> What IP is it resolving to?
01:07:55 <shachaf> The right one is 66.193.37.204.
01:07:57 <edsko> 69.30.63.204
01:08:02 <shachaf> Oh.
01:08:05 <shachaf> I guess not, then. :-)
01:08:11 <edsko> so it seems :)
01:08:14 * edsko tries new IP
01:10:41 <yitz> anecdotally: i found i had to reboot by adsl to update its dns cache.
01:21:33 * hackagebot blaze-builder-enumerator 0.2.0.5 - Enumeratees for the incremental conversion of builders to  bytestrings. (SimonMeier)
01:23:16 <edsko> yitz: indeed, that helped
01:29:56 <Targen> Is it possible for type family arguments to have kinds such as ¬´* -> *¬ª?
01:30:36 <shachaf> Try it!
01:30:50 <Targen> Well, I‚Äôm having a hard time telling GHC what I want.
01:31:05 <shachaf> type family Foo (a :: * -> *)
01:31:10 <Targen> oh!
01:31:15 <Targen> Wonderful, thanks!
01:32:49 <startling> in haskell mode (in the interpreter you get with C-c C-l), pressing up doesn't get the previous thing. in ghci it does. halp
01:32:53 <startling> ?
01:33:15 <Botje> have you tried ctrl-n or ctrl-p?
01:33:37 <scri> startling: C-<up> should work
01:33:46 <sopvop> more like M-n, M-p
01:33:52 <scri> yeah that
01:34:04 <scri> C-up and down are usually also bound
01:34:27 <adnam> or go to the line edit it and press RET
01:34:31 <startling> oh I think evil-mode is conflicting. :/
01:34:52 <startling> ah well, I'll figure it out later
01:34:56 <adnam> but that's bound to be confusing :(
01:34:56 <sopvop> Relevant qustion, how to get autocomplete from ghci in haskell-mode?
01:35:29 <adnam> i know of scion, but not if it's an active project
01:35:33 <scri> ghc-mod?
01:36:14 <sopvop> the usual TAB and list of options from ghci would be nice :)
01:36:30 <shachaf> If you want ghci, you could use ghci.
01:36:39 <adnam> I actually never found a need anything other than the regular dumb auto complete
01:36:49 <sopvop> I want ghci inside emacs
01:37:11 <Ralith> you can probably get emacs to forward the TAB
01:37:18 <adnam> scion was looking fantastic, if only someone would make it easy to install :)
01:37:56 <sopvop> Probably, but my emacs-fu is weak.
01:39:24 <adnam> my favorite feature was C-c C-t to get type information
01:41:28 <scri> if you do C-u C-c C-t you can insert the type sig automatically
01:41:53 <srhb> Keep wondering why there isn't a "do ALL the type sigs" functionality.
01:43:13 <hpaste> Targen pasted ‚ÄúType-level map hackery?‚Äù at http://hpaste.org/73099
01:43:42 <adnam> hmm something's up my configuration...
01:44:37 <Targen> I suppose the issue is that AsServer/AsClient should be type constructors for this to work, and not just type functions ‚Äî but what I want is to substitute one constructor for another, not just to apply one.
01:44:38 <adnam> my haskell-mode is probably horribly outdated
01:44:52 <Targen> What might be the proper way to do this?
01:46:34 * hackagebot lens 2.1 - Lenses, Folds and Traversals (EdwardKmett)
01:46:52 <danr> Targen: why don't you make them a data family instead?
01:47:26 <Targen> danr: I‚Äôll try that; thanks!
01:50:02 <Targen> I have a feeling this task would be better suited for TH, heh.
02:12:04 <XexonixXexillion> Is there any more lightweight RTS for Haskell than the one GHC uses?
02:15:04 <Botje> you can't run a ferrari on bicycle wheels
02:15:15 <latro`a> lol
02:15:25 <latro`a> that would actually be kinda hilarious
02:15:27 <MostAwesomeDude> Depends on how many wheels you have.
02:15:28 <latro`a> if you just had endless money
02:15:32 <MostAwesomeDude> XexonixXexillion: What's the problem?
02:15:33 <latro`a> hook up 4 bicycle wheels to a ferrari
02:16:44 <XexonixXexillion> No problem, I'm just curious
02:17:25 <latro`a> as far as I know the other haskell environments are lighter than GHC, but I don't know how much of GHC is actually the RTS
02:17:54 <Botje> if you had a really good strictness analyzer you could compile some programs without the laziness part of the RTS
02:20:45 <Jurily> the RTS itself is 430 kilobytes over here
02:21:38 <XexonixXexillion> What I really want it something about half the size of the current RTS, with more explicit memory control
02:22:32 <quicksilver> well there is the hugs RTS, the JHC RTS, the UHC RTS and the EHC RTS.
02:23:00 <quicksilver> as well as any RTSes that might be embedded in the various hs->js projects running around at the moment
02:27:28 <merijn> XexonixXexillion: What you plan to use it for?
02:27:41 <Botje> DOS programs!
02:28:55 <XexonixXexillion> merijn: Haskell programs I can reason about the run time for
02:29:11 <merijn> XexonixXexillion: If you don't mind vaporware you might interested in Habit?
02:29:39 <merijn> XexonixXexillion: They're working on a strict haskell dialect for systems programming, including stuff like memory safe pointers, etc.
02:30:59 <XexonixXexillion> merijn: It looks nice, but for now I'll just stick to writing my important things in spark :p
02:31:30 <hiptobecubic> Are there any tools that can give you things like type information when the file *doesn't* compile properly yet?
02:31:59 <hiptobecubic> ghc-mod is nice, but it only seems to work after i've figured out my problems and then i don't need it
02:32:17 <quicksilver> I don't think so hiptobecubic although I've seen people talk about it quite often
02:32:28 <quicksilver> (construct a maximal fragment of the file which *does* compile and compiler than...)
02:32:33 <quicksilver> compile that.
02:33:06 <efie> I have ghc-7.0.4 and ghc-7.4.2 installed, but when I say "ghci" ghci 7.0.4 is started, how can I fix this?
02:33:42 <efie> so that ghci 7.4.2 is started
02:33:51 <arkx> efie: make sure the newer GHC comes first in your $PATH
02:36:35 * hackagebot PortFusion 1.2.0.1 - high-performance distributed reverse / forward proxy & tunneling for TCP (CetinSert)
02:38:56 <efie> arkx: both the ghc-7.0.4 and the ghc-7.4.2 folder are not in my $PATH... but at /usr/local/bin (which is in my path) there is a ghc-7.0.4 and ghc-7.4.2 file, should I delete the 7.0.4 file there?
02:40:01 <lizzin> why doesn't 'data Point = Point Float Float
02:40:03 <srhb> I am confused. For one of my functions, ghc derives the type MonadState World m => Coord -> m Char -- but I can't annotate it with this type myself without FlexibleContexts -- why?
02:40:07 <lizzin> ' work in ghci?
02:40:18 <hiptobecubic> can't start with '  i think?
02:40:34 <shachaf> srhb: Sometimes that happens.
02:40:40 <srhb> lizzin: Because you have an old ghci, probably
02:40:46 <arkx> efie: is the ghci in your /usr/local/bin a symlink? If so, make it point to the newer ghci.
02:40:58 <srhb> shachaf: Hm :P
02:41:16 <srhb> shachaf: So I should just choose a more specialized type.
02:41:26 <lizzin> shachaf: 6.10.4
02:41:41 <srhb> lizzin: Too old for top level data types in ghci, you need I think 7.2 or 7.4 for that.
02:41:45 <shachaf> srhb: Or just turn on FlexibleContexts.
02:41:51 <srhb> shachaf: Right, thanks.
02:42:05 <lizzin> srhb: ok, thanks
02:43:26 <arkx> efie: helpful commands to sort this out: 'which ghci' tells you what your shell uses for invoking ghci, 'ls -l <whaterver which told you>' shows you where that symlink points to.
02:46:17 <efie> arkx: thanks! the ghci file pointed to the ghc-7.0.4 executable, I changed it and now it works . :)
02:50:18 <efie> With the newest ghc version, I wanted to install the newest Haskell Platform, but it fails with: "Configuring parallel-3.2.0.2...Setup: At least the following dependencies are missing:deepseq >=1.1 && <1.4"
02:51:57 <efie> does anyone know how to fix this? How can I install this deepseq version?
02:53:53 <Jurily> cabal install deepseq-1.3.0.0 --dry-run
02:54:29 <Jurily> --dry-run won't actually install the packages, just show you what it would do
02:55:54 <efie> Jurily: thanks! I'll try installing Haskell Platform again
02:58:34 <Jurily> btw, are you talking about the 7.6 release candidate?
02:59:24 <lizzin> is :: read as 'has a' or 'is a'?
02:59:57 <adnam> "has type" i'd say
03:00:13 <lizzin> that works
03:01:02 <Scheisselstadt> I proudly announce that Snardbafulator was doxed
03:01:05 <Scheisselstadt> and has left Freenode
03:01:12 <Scheisselstadt> United Mexican Trolls declare victory
03:01:19 <efie> Jurily: I don't think so, I installed GHC 7.4.1
03:01:23 --- mode: ChanServ set +o quicksilver
03:01:24 <Scheisselstadt> let Snardbafulator be an example of what happens to pushy commies and leftists on Freenode
03:01:26 --- mode: quicksilver set +b *!*cheissels@204.12.223.*
03:01:26 --- kick: Scheisselstadt was kicked by quicksilver (Scheisselstadt)
03:01:58 <lizzin> should haskell be faster than java in parsing a 100mb+ json file?
03:03:00 <adnam> lol what was that
03:03:04 <osfameron> lizzin: it probably depends more on how the code is written than the languages themselves
03:03:06 <XexonixXexillion> lizzin: That would depend more heavily on the actual code and the machine doing it than on the implementation language
03:03:14 <osfameron> XexonixXexillion: ^5!
03:03:18 <srhb> lizzin: I think it would be easier to write a very optimized JSON parser in Haskell than in Java, that;s about the closest answer you can get..
03:03:20 <srhb> Then again...
03:03:35 <osfameron> try both, and see which is fastere!
03:03:44 <adnam> @faq Can haskell parse a 100mb+ json file faster than java?
03:03:45 <lambdabot> The answer is: Yes! Haskell can do that.
03:03:55 <lizzin> ha
03:04:06 <barometz> I have to say that if you've got a 100MB+ json file something probably went wrong in an earlier stage :P
03:04:11 <lizzin> osfameron: true, think i'll try that
03:04:21 <efie> I just saw that cabal install deepseq-1.3.0.0 installed deppseq into deepseq-1.3.0.0/ghc-7.0.4 .. .probably it has to be deepseq-1.3.0.0/ghc-7.4.2? (because it failed again)... if so, how can it be fixed .. ?
03:04:28 <lizzin> barometz: city data...
03:04:29 <Targen> @faq Can haskell make unicorns?
03:04:30 <lambdabot> The answer is: Yes! Haskell can do that.
03:04:34 <Targen> Wonderful.
03:04:36 <hiptobecubic> lizzin, you're parsing lots of these or what?
03:04:51 <osfameron> @faq can haskell do things that haskell can't do?
03:04:52 <lambdabot> The answer is: Yes! Haskell can do that.
03:04:53 <lizzin> hiptobecubic: once a week
03:04:59 <Jurily> efie: did you change your PATH?
03:05:13 <sipa> @faq can Haskell do infinite loops in 5 seconds?
03:05:13 <lambdabot> The answer is: Yes! Haskell can do that.
03:05:27 <hiptobecubic> lizzin, my point is will 8 seconds vs 12 seconds matter anyway?
03:05:36 <XexonixXexillion> I'd be more inclined to say Haskell is going to be faster, simply because it's not running in a vm
03:05:47 <Jurily> Haskell is too lazy to do infinite loops.
03:05:48 <Targen> Indeed.
03:06:04 <hiptobecubic> XexonixXexillion, it's not like the jvm can't be very fast
03:06:05 <lizzin> XexonixXexillion: that's what i was wondering/thinking
03:06:11 <Jurily> XexonixXexillion: jit
03:06:14 <hiptobecubic> The problem with java is java.
03:06:52 <osfameron> in the language shootouts (hahahahaha) Haskell tends to place around the same area as Java, fwiw
03:06:56 <srhb> lizzin, XexonixXexillion: I don't think that's a reasonable assumption. Have you seen the language shootout recently?
03:06:57 <lizzin> hiptobecubic: probably not in the long run. but i'm just getting started on this and would rather not lose the time while still trying to verify that everything works as expected
03:07:08 <Targen> Jurily: JIT, sure, but Java bytecode is still a stack-based machine with no registers.  A Haskell compiler can optimize much more.
03:07:32 <Targen> If the code is optimization-friendly, at least.
03:07:52 <Jurily> Targen: if the JIT manages to pick up the actual parser, over 100 megabytes that will dwarf everything else
03:08:42 <hiptobecubic> lizzin, then whats most important is that you have the libraries and interop with other stuff that you need. It will be easier to write a correct parser in haskell i think, but you can usually trust a library to work fine so i don't see your argument
03:09:13 <Jurily> the main drawback of a Java parser is that you would write Java
03:09:18 <srhb> Jurily++
03:09:21 <hiptobecubic> yes, that's my point as well
03:09:23 <osfameron> surely it depends more on what you and your dev team know, and can support, and what libraries exist that you need to work with?
03:09:42 <osfameron> If I had a competent Java team, and needed to interact with Java libraries, I wouldn't even *think* about using Haskell
03:09:43 <srhb> lizzin: The speed difference will be negligible given good code in either language -- the whole point is that Haskell is much nicer
03:09:52 <efie> Jurily: my PATH contains to usr/local/bin where are a lot of haskell files like this ghci-file: http://hpaste.org/73100 probably I need to replace ghc-7.0.4 with 7.4.2 in these files?
03:10:30 <lizzin> srhb: alright
03:11:08 <Jurily> efie: I would recommend taking /usr/local/* out of your PATH for the time being, and install the new platform somewhere else
03:11:12 <XexonixXexillion> srhb: Fair enough; most of my code is half Haskell and half Ada. That tends to run very quickly
03:11:38 <srhb> XexonixXexillion: The secret lies in the word negligible (fsvo of it)
03:11:39 <Targen> Jurily: No matter ‚Äî the generated code for that parser, whether bytecode or JIT-compiled to machine code, is going to have missed out on many opportunities for optimization due to the design of the JVM itself.  JIT optimizations could make up for it to some degree, but never as far as a Haskell compiler could in theory get.
03:13:01 <XexonixXexillion> Just write it in ada. The gnat compiler is amazing at optimising things. *ducks*
03:13:33 <Targen> I don‚Äôt know how good the optimization pipeline may be for a JIT-compiling JVM, and perhaps it‚Äôs actually better in practice than the current state of GHC optimization, but there‚Äôs a limit to how good they can be, and the limit is quite lower for Java.  It‚Äôs an unavoidable consequence of its design.
03:14:03 <srhb> XexonixXexillion: Give me dependently typed Haskell, please. :-)
03:15:05 <Jurily> Targen: don't forget you have more information at runtime than you have at compile time
03:15:46 <XexonixXexillion> srhb: I'm talking about ada, not agda :p but I would like dependently typed haskell
03:15:57 <srhb> XexonixXexillion: Oh dear, fail me. :(
03:16:27 <Jurily> for example, most of the time, compilers are not allowed to take the cache sizes into account
03:16:59 <XexonixXexillion> srhb: every time I mention ada on this channel someone assumes I meant agda, or misreads it as agda. I'm used to it.
03:17:45 <osfameron> ah, people still use Ada?  I've heard good things about it, but assumed it was mostly dead
03:17:46 <Targen> Jurily: I would venture that extra information wouldn‚Äôt help much.  There simply isn‚Äôt much to be done in the way of optimizing stack code.
03:18:09 <srhb> XexonixXexillion: I shouldn't make that mistake, I'm quite a fan of the historical person. :-)
03:19:54 <XexonixXexillion> Ada itself is falling out of popular use. Spark (a subset of ada) is still quite popular for formally verified systems
03:21:50 <XexonixXexillion> One of these days I'll upload my haskell libraries for interacting with ada to hackage, but I doubt there's really any demand for them
03:23:09 <merijn> osfameron: Well, it seems to be a rather niche language
03:23:33 <merijn> C is (obviously) right out for any project needing verification and most other languages aren't much better
03:24:23 <merijn> Haskell might be nice for safety/verification, but I wouldn't use it in a real-time environment
03:24:52 <merijn> And of course many fields interested in safety/verification are at least semi-real-time
03:25:05 <Jurily> well, NASA thought C is fine for Curiosity
03:25:51 <companion_cube> a very restricted C, without malloc, recursion and lots of stuff
03:25:59 <srhb> I think Galois uses Haskell to generate some real time language
03:26:06 <srhb> Or was it some other company...
03:26:31 <srhb> Anyway, the idea is to get correctness from Haskell and real-time from the output language. Seems like a sane approach.
03:28:54 <XexonixXexillion> I just find it amusing that people talk about a language as being "as fast as c" when often my ada code will often compile to something faster than what the same code in c will
03:30:20 <quicksilver> I think what they really mean by that is "compiling to native code"
03:30:31 <quicksilver> since most other popular languages do not
03:30:53 <shachaf> @quote monochrom einstein
03:30:54 <lambdabot> monochrom says: einstein's theory implies that haskell cannot be faster than c
03:31:39 <typoclass> Jurily: i don't know if they did use c on the mars rover, but from what i know about the avionics industry, code sizes are tiny, documentation is a huge topic, testing and verification is huge, development cycles are long. what nasa or boeing or airbus do can't be compared at all to some random open source guy messing around
03:31:42 <sipa> @quote neutrino
03:31:43 <lambdabot> No quotes match. Maybe if you used more than just two fingers...
03:31:52 <sipa> sorry, i only use 2 fingers
03:34:16 <m3ga> typoclass: yes, curiosity was coded in C. the JPL coding guidelines were released recently.
03:34:41 <Jurily> http://programmers.stackexchange.com/a/159638/4894
03:35:49 <m3ga> typoclass: http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf
03:37:38 <nus> what's hackage status atm?
03:37:53 <srhb> nus: Seems to work fine.
03:38:08 <srhb> nus: Some dns servers might not have refreshed yet though.
03:38:30 <nus> at which ip address?
03:38:52 <typoclass> nus: channel topic claims hackage has a new ip
03:40:02 <Jurily> oooh, Ariane 5 and Ada: http://www.leshatton.org/wp-content/uploads/2012/01/Ariane5_STQE499.pdf
03:40:47 <nus> typoclass, YMMV sounds like a new addressing scheme, though
03:44:04 <shachaf> Roman Numeral IP.
03:46:03 <nus> could an op put 66.193.37.204 in the topic?
03:47:30 <srhb> @ops
03:47:31 <lambdabot> Maybe you meant: docs oeis pl
03:47:35 <srhb> Oh.
03:47:49 <srhb> Not lambdabot :~
03:47:58 <typoclass> nus, what's wrong with using the domain name? an ip address seems brittle
03:48:03 <srhb> Why can't lambdabot do _everything_
03:48:11 <srhb> typoclass: The IP just changed, some dns have not updated yet
03:54:25 <quicksilver> typoclass: the DNS hasn't propogated to all DNS servers I suppose
03:54:53 <SebastienGllmt> If Haskell98 is a hidden package, does that mean I'm not supposed to be using it and there's a new better way to do something?
03:55:08 <quicksilver> to use the IP directly you'd need to understand how to set up a hosts file or equivalent way to locally fudge it
03:55:17 <quicksilver> so it might be unhelpful advice in general?
03:57:37 <typoclass> SebastienGllmt: yes, haskell98 has been replaced by the package 'base' and a few others. they are recommended instead of the old haskell98 stuff. it's usually not much of a change; e.g. Char is replaced by Data.Char
03:58:06 <SebastienGllmt> Well I'm trying to find out how to do system "pause" or whatever that would be now
03:59:44 <typoclass> SebastienGllmt: maybe you mean threadDelay
03:59:48 <typoclass> @hoogle threadDelay
03:59:49 <lambdabot> Control.Concurrent threadDelay :: Int -> IO ()
03:59:49 <lambdabot> GHC.Conc.IO threadDelay :: Int -> IO ()
03:59:49 <lambdabot> GHC.Conc threadDelay :: Int -> IO ()
04:00:03 <typoclass> (it's a little weird, it uses microseconds, not milliseconds)
04:00:22 <SebastienGllmt> there's no way to pause it forever or do some "press any key" thing?
04:00:27 <shachaf> I think SebastienGllmt might be after getLine.
04:00:44 <SebastienGllmt> Well I want to put this after the getLine
04:00:59 <shachaf> Oh, you actually want to use "system".
04:01:02 <SebastienGllmt> because it prints what you put in the line put the program closes as soon as it happens
04:01:09 <shachaf> You should probably not do that because it's evil and unportable. :-(
04:01:23 <shachaf> But you can do it with base just the same as with haskell98.
04:01:25 <shachaf> @hoogle system
04:01:26 <lambdabot> System.Process system :: String -> IO ExitCode
04:01:26 <lambdabot> System.Cmd system :: String -> IO ExitCode
04:01:26 <lambdabot> package system-argv0
04:01:27 <srhb> I am confused. Should I be able to get this error at runtime: Couldn't match expected type `Identity` with actual type `IO` ?
04:01:55 <barrucadu> SebastienGllmt: So, you want to get a line and then wait for the user to press any key? how about getChar?
04:02:15 <typoclass> srhb: if you get it at compile time, fine. if you get it at runtime, that's ... uh ... interesting
04:02:20 <SebastienGllmt> Well I don't /want/ to do anything I'm just trying to learn how to do stuff
04:02:23 <shachaf> srhb: Not unless you're using the GHC API.
04:02:29 <srhb> shachaf: I am not.
04:02:34 <srhb> typoclass: It compiles fine.
04:02:40 <shachaf> srhb: I suspect it's not happening at runtime, then?
04:02:45 <shachaf> Unless you count "runghc" as runtime.
04:02:48 <shachaf> Context?
04:02:49 <srhb> Oh, I did.
04:02:55 <srhb> Hang on, let me test some more
04:03:16 <shachaf> "oops, I accidentally embedded the GHC API into my program"
04:03:37 <srhb> Haha.
04:03:55 <Swizec> hello everyone
04:03:58 <quicksilver> HALP I ACCIDENTALLY THE WHOLE GHC
04:04:30 <srhb> Right, my mistake. runghc is not runtime. :-)
04:04:49 <typoclass> SebastienGllmt: if you want to wait some number of seconds, use threadDelay. if you want to wai forever, use "forever $ threadDelay ...". if you want to wait until the user presses a key, use getChar, or getLine to wait until he has hit enter
04:05:12 <shachaf> It's not quite that simple because of buffering.
04:05:15 <quicksilver> (getChar will also wait until he presses enter, probably, unless you changed the buffering)
04:05:17 <merijn> SebastienGllmt: Can you be a little clearer about the reason you want to wait?
04:05:42 <SebastienGllmt> @Merijn nope, but Typoclass told me all I wanted to know, I think
04:05:43 <lambdabot> Unknown command, try @list
04:11:58 <Swizec> I need a judgement check on this blogpost: http://swizec.com/blog/an-elegant-way-to-randomly-change-every-list-member-in-haskell/swizec/5060
04:12:19 <Swizec> did I stumble on something remotely interesting, or something everyone knows already and I'm just that far behind?
04:13:14 <quicksilver> Swizec: yes, that's fairly well known
04:13:26 <Botje> I've never used mapAccumL before, so it's helpful for me
04:13:32 <quicksilver> although a more haskellish solution is to put the RandomGen into a state monad
04:13:42 <quicksilver> mapAccumL is precisely mapM for the state monad
04:13:44 <Botje> Swizec: although I had this nagging 'but that's just zipWith (+) randoms' feeling :)
04:13:48 <quicksilver> with its type "unwrapped"
04:14:25 <Swizec> quicksilver interesting, well this discovery has helped me a lot anyway :)
04:14:43 <Swizec> Botje that's example specific, the case where I'm using this the zip approach wouldn't work
04:15:00 <habyss> if I have: data Foo = Foo { bar :: Int }, is there any way I can export bar as an accessor, so that it can only be used to access fields of type Foo but not construct new Foo values?
04:15:28 <quicksilver> 'bar', in fact, can't be used to construct new values
04:15:40 <quicksilver> what you need to construct new values is the constructor Foo
04:16:03 <quicksilver> I think you can export bar and not Foo although, I"m not quite sure of the syntax.
04:16:06 <quicksilver> Foo(bar), I think.
04:16:19 <quicksilver> (as opposed to Foo(Foo,bar) or Foo(..))
04:16:29 <habyss> quicksilver: I can still 'construct' new values of Foo by modifying an existing value: x { bar = 42 }
04:16:35 <shachaf> Or you could export a lens! :-)
04:16:42 <quicksilver> I didn't think you could, habyss
04:16:47 <shachaf> Even a read-only lens.
04:16:47 <quicksilver> but maybe I'm wrong :)
04:16:59 <habyss> quicksilver: I just tried it and it seems I can
04:17:03 <quicksilver> hmm
04:17:26 <quicksilver> I've never thought about how record notation interacts with export/import of individual selector names
04:17:33 <Botje> Swizec: random*s* generates an infinite list of random numbers
04:17:37 <quicksilver> your best bet is probably to write your own selector and export that
04:17:48 <quicksilver> Foo { _bar :: Int }
04:17:55 <quicksilver> bar :: Foo -> Int; bar = _bar
04:18:08 <habyss> alright, I was hoping there was something simpler :\
04:18:59 <SebastienGllmt> Hmm. I'm trying the getChar method then printing it out with putStrLn "Hey there, " ++ [name] but I get an error with string concatenation
04:19:19 <SebastienGllmt> I understand name is only 1 char by the way, I'm just trying stuff
04:19:29 <Swizec> Botje yes, that would work in the example I used to write the blog, but not in the real world problem where I discovered mapAccumL (but wasn't able to reduce to a good example)
04:20:05 <m3ga> SebastienGllmt: use : putStrLn ("Hey there, " ++ [name])
04:20:37 <quicksilver> SebastienGllmt: function application binds tightest so what you wrote got read as (putStrl
04:20:46 <quicksilver> Ln "hey there") ++ [name]
04:20:55 <quicksilver> apologise for unexpected linebreak :)
04:20:57 <edsko> anyone ever see syntaxerror in the generated postscript file from hp2ps when using retainer profiling?
04:21:00 --- mode: quicksilver set -o quicksilver
04:29:50 <Botje> Swizec: yep, fair enough
04:30:23 <Swizec> Botje the real world problem is an EA algorithm dealing with strings
04:30:41 <Swizec> Botje more specifically, randomly mutating and breeding them
04:33:00 <srhb> In the signature StateT s m a, s is the state, m is the inner monad, and a can be described as... What? The type of the final result?
04:34:24 <squidz_> does anybody know why cabal doesnt detect happy even though i installed it with cabal install?
04:34:35 <typoclass> srhb: yo. it's the same as State s a, but with the m stuck in the middle. see http://hackage.haskell.org/packages/archive/mtl/1.1.0.2/doc/html/Control-Monad-State-Lazy.html#t:State
04:34:56 <srhb> typoclass: So "yes" :-)
04:35:00 <edsko> squidz_: make sure it's in your path
04:35:00 <mekeor> squidz_: what does "cabal does not detect" mean?
04:35:09 <typoclass> squidz_: is it in the PATH? when you do "where happy", does it show up?
04:35:13 <typoclass> srhb: yo
04:35:32 <mekeor> in general (Either Error Value) should be preffered over (Either Value Error), right?
04:35:39 <squidz_> okay so cabal doesnt add it to the path?
04:35:50 <srhb> typoclass: Sorry, I didn't realize yo is the same thing as yes, I thought it was a greeting :P
04:36:33 <fmap> squidz_: no
04:36:34 <typoclass> mekeor: yes, absolutely. mnemonic: "Right" also means correct. therefore Left is for the error
04:36:53 <mekeor> typoclass: thanks
04:36:56 <srhb> mekeor: Also Left gives you short-circuiting.
04:37:15 <mekeor> squidz_: what is the problem? can't you start `happy'? then, you have to make sure that your $PATH variable includes ~/.cabal/bin/
04:37:24 <mekeor> srhb: huh?
04:37:55 <srhb> > foldr (liftM2 (+)) (Right 0) [Right 2, Right 4, Left 0]
04:37:57 <lambdabot>   Left 0
04:38:00 <srhb> > foldr (liftM2 (+)) (Right 0) [Right 2, Right 4]
04:38:02 <lambdabot>   Right 6
04:38:02 <squidz_> mekeor: i am trying to install ghc-mod but am getting this error http://hpaste.org/73102
04:38:11 <srhb> (I should have stuck the Left in earlier to show it)
04:38:24 <typoclass> mekeor: if you're in the Either monad. when a function in the middle of the do block gives Left, the rest of the do block is not evaluated
04:38:39 <mekeor> typoclass: yeah, i was just about to mention the monad... :)
04:38:39 <JaggetD> !help
04:39:14 <srhb> JaggetD: :o What happen
04:39:14 <mekeor> typoclass: in fact, the monad was the reason for me to think that Right should be the result... :)
04:40:33 <mekeor> squidz_: i can't help you because you're using zsh. :/
04:40:50 <JaggetD> srhb: sorry, wrong window ) I just forgot how to login in IRC
04:40:58 <srhb> JaggetD: :)
04:41:17 <squidz_> mekeor: okay, but do you suppose that as soon as i fix my path with zsh, it should install fine?
04:41:41 <mekeor> squidz_: yeah, you probably have to re-start you shell afterwards but yeah.
04:41:57 <squidz_> mekeor: okay thanks, ill give it a try and let you know how it works
04:43:00 <mekeor> squidz_: this is how it works in bash: (put this in ~/.bashrc) PATH="$PATH:~/.cabal/bin"
04:56:38 * hackagebot nat 0.3 - Lazy binary natural numbers (JanChristiansen)
04:59:29 <mekeor> is mod or div more efficient?
04:59:55 <srhb> mekeor: rem and quot are more efficient.
05:00:24 <mekeor> oh, yeah, that's what i wanted to ask :D thanks :)
05:00:31 <srhb> mekeor: ;)
05:01:40 * hackagebot sloth 0.0.2 - Testing for minimal strictness (JanChristiansen)
05:01:42 * hackagebot cabal-uninstall 0.1 - Uninstall cabal packages (JanChristiansen)
05:02:26 <dabblego> Can I use Control.Compose.Flip to take a type constructor :: * -> (* -> *) -> * -> * to one :: (* -> *) -> * -> * -> * ?
05:04:08 <hpc> dabblego: don't think so; is Flip kind-polymorphic?
05:04:18 <dabblego> No, but is there something like it perhaps?
05:04:24 <hpc> you could make your own
05:04:30 <dabblego> yeah I guess :(
05:04:45 <mekeor> type Flip f a b = f b a
05:05:19 <hpc> that works if you don't want to partially apply Flip
05:05:35 <mekeor> hm
05:05:55 <dabblego> yeah I have essentially EitherT f a b and I want to keep it in that order so I can bimap, but I also want MonadTrans
05:30:35 <bartavelle> is there a pcre library other than regexpr that includes the "substitute" functions
05:30:37 <bartavelle> ?
05:32:15 <jimi_hendrix> is anyone aware of a library that lets me output basic sounds, like specific notes or chords?
05:34:17 <bitonic> jimi_hendrix: haskore?
05:36:06 <bartavelle> also it is claimed it is "like Perl/Ruby's regular expressions", but it doesn't seem compatible at all
05:41:37 <quicksilver> bartavelle: regex-pcre?
05:44:29 <jimi_hendrix> bitonic, that will probably work
05:46:22 <bartavelle> quicksilver, doesn't have substitute, or I missed it
05:46:26 <bartavelle> I'm writing it right now
05:46:31 <quicksilver> bartavelle: what is "substitute"?
05:46:39 <dabblego> how do I use symbols in code such as [ and <*> in haddock/
05:46:40 <dabblego> ?
05:47:21 <t7> is 'Translatable' allready a type class?
05:47:35 <quicksilver> bartavelle: (e.g. is it "subRegex" ? http://hackage.haskell.org/packages/archive/regex-compat/0.92/doc/html/Text-Regex.html )
05:47:51 <bartavelle> yes
05:48:32 <quicksilver> then, there it is :)
05:48:37 <bartavelle> ;)
05:48:38 <bartavelle> cool
05:48:43 <bartavelle> but
05:48:46 <bartavelle> it's POSIX
05:48:57 <quicksilver> regex-pcre is just a backend
05:49:13 <quicksilver> it should support the same API as the other regex family packages
05:49:59 <quicksilver> http://www.haskell.org/haskellwiki/Regular_expressions
05:50:06 <quicksilver> rather old page but I think it's still true
05:50:08 <bartavelle> ah
05:59:23 <phil_____> mm_freak: are you planning on finishing your arrow / wire tutorial?
06:02:12 <bitonic> is anybody going to the haskell exchange thing?
06:02:23 <bitonic> http://skillsmatter.com/event/home/haskell-exchange-2012/te-4960 the "early bird" price is quite good
06:02:39 <bitonic> I probably won't learn anything new, but meeting those people might still be interesting...
06:03:14 <philll> hope they record the talks, looks interesting
06:03:46 <bitonic> well living in London I'm quite tempted :P
06:04:24 <philll> id go if i was in london :)
06:05:14 <bitonic> why are these things expensive :(
06:05:21 <_flow_> hmm when writing a programm that parses data from a network socket, should I read the data 1. from the socket 2. from a handle 3. from a bytestream?
06:05:43 <srhb> _flow_: Yes.
06:06:16 <srhb> _flow_: Get a handle from the socket and read a ByteString.
06:06:43 <_flow_> the problem i am facing now is that i get sometimes a bytestream with the length 0 from a bytestring from handle (which comes from a socket)
06:07:16 <srhb> _flow_: Why is that a problem?
06:07:41 <_flow_> well because I need some method to ask if there is more data in the bytestring and then wait until there is new data
06:08:52 <srhb> _flow_: recv and company will block until there's the specified number of bytes to read, and stop if the socket is closed
06:09:27 <_flow_> recv will block until there is the specified number or less bytes to read iirc
06:09:58 <srhb> Hm, you are right. That is silly. But then you can just count the bytes that you've received.
06:10:14 <quicksilver> hWaitForInput
06:10:19 <_flow_> problem is the commands are not a fixed length
06:10:19 <quicksilver> hGetNonBlocking
06:10:20 <quicksilver> etc.
06:10:42 <quicksilver> there are quite a few approachs you can take
06:10:45 <_flow_> so i could come into a situation where i get only the first 256 bytes of a command that is 512 bytes long
06:10:53 <quicksilver> perhaps you can read an initial fixed length header first?
06:11:00 <quicksilver> and that tells you how much more to read?
06:11:03 <srhb> _flow_: Then you can just get the remaining bytes.
06:11:30 <quicksilver> you will almost certainly want to separate the part of your code which reads commands (and may do several reads in a row to get a 'whole' command)
06:11:36 <quicksilver> from the part which processes whole commands.
06:12:10 <_flow_> quicksilver: that is what i am doing atm, but i think i need a blocking bs from a handle
06:12:19 <_flow_> thanks for pointing me into the direction
06:15:22 <_flow_> ahh and if i use socketToHandle, how can i query the handle if the other side has closed the tcp connection?
06:17:30 <fmap> you should get exception on read/write
06:18:27 <Expez> If I have type Foo = Foo Baz Bar and then have a function which takes in such a Foo. Is there another way to do f (Foo baz bar) which lets me pattern match in an opening "let" instead? So I can do f foo = let ... and still get to baz and bar.
06:19:01 <plat0> Are you looking for "case foo of ..."?
06:20:09 <Expez> I might be. Is that the easiest way to just get all the fields of foo?
06:20:19 <fmap> `f foo = let Foo ... = foo in ...' ?
06:20:58 <Expez> that last one seems like exactly what I want. Thanks :)
06:21:40 <fmap> i don't see how it's more convenient that `f (Foo ...) = ...' though
06:21:50 * hackagebot chuchu 0.0.0.1 - Behaviour Driven Development like Cucumber for Haskell (MarcoSilva)
06:21:51 <fmap> s/that/than/
06:22:18 <Expez> fmap: It's not, but Foo has 5 elements, and I thought the function definition got too long. It looked ugly.
06:24:55 <squidz> can somebody tell my why i am getting this error? This is the first time i am writing haskell, so it will probably be apparant to the more experienced fellows http://hpaste.org/73108
06:26:18 <Botje> squidz: you probably meant ("-a" : file : []
06:26:27 <Botje> squidz: or ["-a", file]
06:26:57 <Botje> squidz: as ("-a" : file) will put the rest teh result of getArgs ( :: [String] ) into file
06:26:59 <srhb> :t getArgs
06:27:01 <lambdabot> Not in scope: `getArgs'
06:27:40 <squidz> Botje: ah okay, that did the trick
06:28:05 <srhb> squidz: getArgs returns a list of each argument understood as every element that is whitespace seperated. Perhaps that clears things up.
06:30:13 <Botje> srhb: * as provided by the operating system. It's the shell's job to split on whitespace.
06:30:43 <squidz> Botje: i still dont understand why appending an empty list changes anything though
06:31:22 <Botje> > let ("-a" : file) = ["-a", "foo", "-other", "option"] in file
06:31:23 <lambdabot>   ["foo","-other","option"]
06:31:30 <Botje> > let ("-a" : file : _ ) = ["-a", "foo", "-other", "option"] in file
06:31:31 <lambdabot>   "foo"
06:32:03 <Botje> (knowing that ["foo", ...] is actually "foo" : "-other" : "option" : [] )
06:32:49 <Botje> so file was matching the rest of the list, rather than the second element of the list as you intended
06:32:55 <dgpratt> I remember when I was first learning Haskell, I often got tripped up with pattern matching with ':'
06:33:47 <squidz> Botje: ah okay, thanks for clearing it up for me. I know it is basic stuff, but i have to work my way through it nontheless if im to go anywhere with haskell
06:34:23 <Botje> squidz: no problem, GHC errors aren't always the best :)
06:34:48 <squidz> Botje: i keep hearing that, is that going to be improved in the future?
06:34:59 <Botje> not unless they add telepathy.
06:35:43 <squidz> so it is inherent
06:35:51 <Botje> although sometimes adding explicit type annotations clears things up.
06:36:25 <Botje> if you said addFileToProgram (file :: String) I think you'd have gotten a better type error
06:36:42 <Botje> something like 'expected type String, inferred type [String]'
06:37:16 <squidz> so we need parenthesis as soon as we explicitly list the type?
06:37:41 <Botje> otherwise you're assigning a type to the entire right hand side of the <-
06:38:03 <Botje> and since your problem was with the input types, it wouldn't have changed much I think.
06:38:31 <tdammers> in my experience, splitting things up into tiny functions and explicitly typing them all pretty much solves the error message problem
06:38:38 <tdammers> also makes for more maintainable code
06:38:42 <Yiq> so any news about haskell on heroku or where do you host?
06:38:44 <Botje> yep.
06:49:34 <Axman6> Yiq: worth talking to blackdog when he's online. he's put a lot of effort in getting Haskell working on Heroku, but there are some fundamental limitations
07:00:52 <heatsink> What is an synonym of "type" in english that doesn't already have a mathematical meaning?
07:03:28 <kaos_> Hi, I'm currently working on a some code that does a lot of counting. An easy example is just data Count = Count Int. I would like the counter to be abstracted so the user can supplement his own method of storing the counts, eg. database (IO) . Is there a nice approach for this problem?
07:04:01 <DT``> heatsink, brand, sort, genre.
07:04:13 <edsko> sort is taken :)
07:04:25 <DT``> true.
07:04:39 <heatsink> Ooh, so there are unused names
07:04:42 <heatsink> brand and genre...
07:05:44 <heatsink> kaos_, what operation is abstracted exactly?
07:06:10 <heatsink> It's different if you want to do something different on every counter update, or save the final counter
07:07:22 <kaos_> headsink: In the simplest of case I just want two operations, increment and decrement - and the user would then define these functions (my idea is to use a typeclass). So the user can use an IORef, or an Int or whatever to store the counts
07:08:13 <heatsink> Defining a type class sounds appropriate
07:09:23 <heatsink> The class should be parameterized over a monad and a counter reference type
07:09:39 <mikeplus64> kaos_: (eg class Counter a where increment :: a -> m a or something)
07:09:40 <EvanR> meh, you can just use functions and partial application
07:10:59 <kaos_> Is there any issue with using MultiParamTypeClasses?
07:11:15 <Cale> kaos_: It might be good to actually see what code you have, and what you're trying to abstract out.
07:12:50 <Cale> The sort of incrementation which is encoded by (\x -> x + 1) :: Int -> Int is quite different in nature from (\r -> do v <- readIORef r; writeIORef r (v+1)) :: IORef Int -> IO ()
07:13:08 <kaos_> Cale: not so important - I have a in-memory counter that I want to move to a Redis database. But I thought it would be nice to avoid injecting IO all over my code...
07:13:24 <EvanR> yeah, typeclasses arent necessary to goto feature
07:13:26 <kaos_> ofc it's different :P
07:13:49 <Cale> The former sort of incrementation, it doesn't matter when it occurs
07:14:17 <Cale> (whereas the latter, that's almost the only thing which matters)
07:15:04 <heatsink> kaos_, do you increment counters in non-monadic code?
07:15:22 <Cale> So in order to use something like that, the rest of your program has to be structured around it to provide the context of *when* the increment happens. So it's not quite so trivial a change to make.
07:16:03 <Cale> (Same holds for going from pure counter to database counter, though of course, if the thing is already IO, the DB counter and IORef counter might not be so different)
07:16:51 * hackagebot Chart-gtk 0.16.1 - Utility functions for using the chart library with GTK (TimDocker)
07:18:16 <kaos_> heatsink: Yeah, atm its just a inc :: Counter a -> Counter a (non-monadic)
07:19:25 <heatsink> they passed
07:21:52 * hackagebot chuchu 0.1.0.0 - Behaviour Driven Development like Cucumber for Haskell (MarcoSilva)
07:22:27 <bartavelle> the regexp-compat library uses unsafePerformIO and fail in seemingly "pure" code, can I catch these exceptions ?
07:24:19 <heatsink> bartavelle, it's not easy to catch them outside of IO
07:25:02 <EvanR> ffi libs are tricky like that
07:25:19 <EvanR> unsafePerformIO is tricky like that
07:26:48 <bartavelle> ok then I have to use another library
07:27:32 <EvanR> sorry i dont know which regex lib is the nicest
07:27:40 <EvanR> try not to use too much regex
07:27:50 <EvanR> it causes cancer
07:28:09 <quicksilver> bartavelle: if it uses fail in things which you might want to catch then it sounds quite broken :(
07:28:15 <quicksilver> are you sure there isn't a way around it?
07:28:18 <quicksilver> when does it fail?
07:30:30 <bartavelle> quicksilver, when trying to compile broken regexps
07:30:57 <bartavelle> Text.Regex.Posix.String died: (ReturnCode 7,"Unmatched [ or [^")
07:31:52 * hackagebot astrds 0.1.1 - an incomplete 2d space game (AndresLoeh)
07:32:53 <bartavelle> the problem is that the interface is "mkRegex :: String -> Regex"
07:33:22 <bartavelle> i'll just use pcre-builtin, it lives in IO
07:33:32 <Cale> bartavelle: Is it a hard requirement that you use regular expressions at all?
07:33:40 <bartavelle> yes
07:33:44 <Cale> (Or is your goal just to parse something?)
07:33:49 <bartavelle> it will not be compatible with puppet otherwise
07:34:00 <bartavelle> nope, it's for my language-puppet library
07:34:08 <bartavelle> users are allowed to use arbitrary regexps
07:34:09 <Cale> okay, just checking :)
07:34:38 <quicksilver> bartavelle: that does seem very daft
07:34:56 <quicksilver> (no way to discover that a regexp is ill-formed)
07:35:05 <EvanR> :t evaluate
07:35:07 <lambdabot> Not in scope: `evaluate'
07:35:16 <EvanR> :t Control.Exception.evaluate
07:35:18 <lambdabot> forall a. a -> IO a
07:35:20 <EvanR> hmm
07:35:20 <bartavelle> indeed
07:35:22 <quicksilver> since the *only* reasonable use of a regexp library is to execute regexps from an external source
07:35:28 <bartavelle> exactly
07:35:39 <quicksilver> then it's incomprehensible not to have a way of signalling illformedness.
07:35:40 <EvanR> quicksilver: or to use your own hard coded regex
07:35:42 <xraycat> hello, I'm going to implement some graph algorithms and I'm currently working on a possible graph representation atm it's just type Graph = M.Map Node (S.Set Node) (with type Node = B.ByteString) in the end it'll probably be IntMap, but my current concern is that the representation is inefficient for my purpose: I have to constantly build subgraphs and evaluate them (see http://hpaste.org/73117)
07:35:45 <quicksilver> EvanR: no.
07:35:57 <quicksilver> EvanR: that is a very unreasonable use :)
07:35:58 <xraycat> (its a naive implementation)
07:36:02 <Cale> EvanR: That's not reasonable ;)
07:36:04 <bartavelle> you usually want to implement your own parsing system without regexps
07:36:18 <frerich> @hoogle a -> (a -> b) -> b
07:36:19 <lambdabot> Prelude ($) :: (a -> b) -> a -> b
07:36:19 <lambdabot> Data.Function ($) :: (a -> b) -> a -> b
07:36:20 <lambdabot> Prelude ($!) :: (a -> b) -> a -> b
07:36:39 <frerich> err...
07:37:17 <shirt> Should I use Rank2Types or RankNTypes? This seems to indicate that Rank2Types is going to be deprecated... http://hackage.haskell.org/trac/ghc/ticket/6032#comment:3
07:37:30 <frerich> Is there a conventional name for 'x :- f = f x'? I took that function name :- from LYAH but I wonder whether there's something like that in the libraries.
07:38:04 <ParahSailin__> @pl x :- f = f x
07:38:05 <lambdabot> (line 1, column 8):
07:38:05 <lambdabot> unexpected "="
07:38:05 <lambdabot> expecting variable, "(", "`", "!!", ".", operator or end of input
07:38:27 <frerich> I think it would be 'flip ($)'?
07:39:28 <quicksilver> frerich: surely that's not legal? :- is a constructor
07:39:52 <EvanR> Cale: quicksilver: yeah in haskell i guess, but thats where all regexes come from anyway
07:40:54 <heatsink> xraycat, What do you want to accomplish by writing the graph algorithm?
07:41:09 <heatsink> If you just want to use a graph algorithm, there are good libraries
07:43:37 <xraycat> heatsink: I don't think it has been implemented yet
07:43:52 <frerich> quicksilveR: sorry, I meant '-:'
07:44:45 <heatsink> xraycat, the FGL library has efficient functional graphs (http://hackage.haskell.org/package/fgl)
07:44:46 <xraycat> heatsink: I took a look at fgl and Data.Graph, but I don't know whether they are a good match
07:45:48 <heatsink> That depends on what algorithms you want to use
07:47:11 <heatsink> Is computing induced graphs the only algorithm you're going to write?
07:48:24 <xraycat> probably not, but the first algorithms make heavy use of induced graphs (they have a runtime of O(4^k*‚Ä¶) k is <= n (no of nodes))
07:49:57 <parcs`> frerich: F# uses <| or |> or something
07:50:42 <heatsink> If you have imperative graph algorithms, it may be easier to write them imperatively instead of converting them to functional algorithms
07:52:37 <heatsink> An imperative graph can be written as an Array NodeID Node, where Node contains edge lists
07:53:16 <heatsink> Of course, that means that you have to allocate node IDs and keep edge lists consistent
07:57:25 <xraycat> hm‚Ä¶ I'll look into it, ty, might have to do some experiments, my graphs are mostly sparse
07:59:44 * heatsink wants a functional giraffe library.
08:12:13 <nand`> giraffe library?
08:13:29 <geekosaur> would have to be something about lenses for graphs...
08:25:49 <shapr> Isn't there a way to list visible instances of a class in ghci?
08:26:10 <quicksilver> :info <classname>
08:26:45 <shapr> thanks
08:38:02 <sopvop> what happened to haskelldb? was it abandoned?
08:42:16 <Cale> sopvop: I don't think it's abandoned so much as not very actively contributed to?
08:42:50 <sopvop> No updates for more than a year, It's some serious lack of contribution.
08:57:00 * hackagebot hdevtools 0.1.0.3 - Persistent GHC powered background server for FAST haskell development tools (BitConnor)
09:04:19 <augur> where can i read about implementations of the IO monad?
09:04:42 <augur> or about laws relating to IO
09:05:45 <Axman6> "In the expression a >>= b, the universe changes between the execution of a and b"
09:05:48 <Axman6> >_>
09:06:08 <EvanR> >>= isnt about execution
09:07:21 <srhb> augur: >>= does what you'd expect it to from looking at its type.
09:07:39 <augur> srhb: yes i know that.
09:08:06 <srhb> augur: Alright, sorry. :-) You're talking about the monad laws then?
09:08:13 <augur> no
09:10:18 <EvanR> i havent heard of any IO laws
09:10:40 <srhb> No, I'm not sure what's being asked either. augur: Can you specify?
09:11:19 * geekosaur thought the only IO law was that it's the sewer system....
09:11:20 <augur> there is nothing to specify
09:11:43 <augur> all im looking for is a discussion of different ways the IO monad could be implemented
09:11:50 <quicksilver> you could only give useful laws w.r.t to specific IO primitives
09:12:04 <quicksilver> for example putStr "a" >> putStr "b" === putStr "ab"
09:12:09 <augur> and also what sorts of expectations one might reasonably have about how IO actions work
09:12:11 <quicksilver> is a law I would expect IO to obey.
09:12:49 <quicksilver> and you could write down some laws about readIORef and writeIORef, etc.
09:12:55 <quicksilver> I'm not aware that anyone has done so, though.
09:14:18 <danil> augur: as far as implementation goes, http://blog.ezyang.com/2011/05/unraveling-the-mystery-of-the-io-monad/ is a good outline
09:14:57 <quicksilver> it's an interesting description
09:15:03 <quicksilver> I don't like it though
09:15:10 <quicksilver> because it really doesn't make it clear that that *isn't* haskell
09:15:19 <quicksilver> and you *CANNOT* implement the IO monad that way in haskell
09:17:10 <quicksilver> Conal's comments highlight why this is a seductive but confusing explanation
09:17:28 <quicksilver> but they don't seem to highlight the thing which I think is most important... which is that that language there is not haskell.
09:19:42 <augur> also, what is the denotation of IO actions?
09:20:15 <NeonJesus> Snardbafulator has been defeated! United Mexican Trolls managed to dox him and use the information to demonstrate to Robert McKeown in person the power of the UMT.  Freenode has been liberated from the nefarious Marxist propaganda machine that plagued ##philosophy.   Let that be an example for anybody on Freenode who thinks of spreading left wing commie dribble!  You can incur the wrath of the United Mexican Trolls and suffer S
09:20:16 <NeonJesus> nardbafulator's fate!  Snardbafulator, AKA Robert McKeown, knows what will happen to him if he returns to Freenode with his claptrap.  Let that be a warning!  Praise United Mexican Trolls!  Snardbafulator is gone from Freenode!
09:20:27 --- mode: ChanServ set +o mauke
09:20:28 --- mode: mauke set +b $a:NeonJesus
09:20:49 <quicksilver> augur: if only we knew :)
09:20:58 <quicksilver> augur: you have to devise something.
09:21:34 <quicksilver> augur: fairly easy to put something together for certain particular sets of primitives, especially ones which don't include forkIO.
09:22:12 <quicksilver> otherwise, well... the whole literature on giving denotational semantics to conventional (that is, side-effectful) programming languages is generally applicable to haskell/IO
09:22:56 --- mode: mauke set -o mauke
09:23:42 <conal> although -- see my "toxic avenger" remarks at http://conal.net/blog/posts/notions-of-purity-in-haskell/#comment-22829
09:23:42 <lambdabot> conal: You have 1 new message. '/msg lambdabot @messages' to read it.
09:24:40 <quicksilver> conal: you mean http://conal.net/blog/posts/notions-of-purity-in-haskell#comment-22829
09:24:44 <quicksilver> (no / before the #)
09:24:54 <augur> conal! :o
09:25:27 <conal> quicksilver: both URLs work for me. what about you?
09:25:32 <srhb> Both work for me
09:25:51 <quicksilver> conal: when I visited the first, your web host redirected me to the version without the /
09:25:55 <quicksilver> which lost the anchor
09:26:04 <quicksilver> which meant I jumped to the top of the page
09:26:09 <srhb> quicksilver: That's odd, that doesn't happen in Chrome.
09:26:13 <quicksilver> instead of the comment you presumably intended.
09:26:23 <conal> quicksilver: thx. what browser?
09:26:29 <quicksilver> safari
09:26:46 * quicksilver suspects some nasty wordpress browser sniffery
09:26:57 <srhb> Yep, broken in Safari here as well.
09:27:00 <conal> quicksilver: glad to know. i'll switch to the more dependable URL.
09:27:02 <augur> conal: whats the denotational semantics for IO :D
09:27:33 <conal> augur: see that URL (^^) for my answer.
09:27:46 * EvanR denotes some quantum mechanics
09:27:55 <augur> conal: :o
09:29:26 <quicksilver> conal: I have, incidentlly, been complaining about the type of System.Info.os for many, many years
09:29:29 <quicksilver> :)
09:29:41 <conal> quicksilver: i'm glad to hear it! :)
09:29:50 <conal> quicksilver: please keep complaining.
09:30:25 <quicksilver> and the int overflow behaviour too although I'm slightly more sympathetic to the argument that it's genuinely important to have a performant (hardware-backed) integer type available.
09:32:19 <augur> conal: hm. ok so i gess what i should ask instead is
09:32:35 <augur> conal: forget haskell, how can some simple IO-like interactions be modelled
09:32:36 <conal> quicksilver: i'm a little more sympathetic to the Int thing also. both betray a principle i care about deeply. bigger payoff (more pieces of silver?) with Int.
09:33:13 <quicksilver> augur: as I said before, it's perfectly simple for a variety of simple cases.
09:33:33 <quicksilver> independent stream IO (putStr/getLine) is easy enough
09:33:44 <quicksilver> IORefs (in the absence of concurrency) is easy enough
09:33:57 <EvanR> concurrency is the heart of IO
09:33:59 <quicksilver> you just use the same techniques used to give semantics to (for example) algol
09:34:04 <quicksilver> nothing new under the sun.
09:34:27 <conal> quicksilver: in all such cases, however, i'd like the haskell community to keep reminding ourselves that these compromises are temporary until we can figure out how program denotatively ("genuinely functional" as Landin said).
09:34:40 <augur> yes well, saying that there's nothing new under the sun is not the same thing as "here's what it is"
09:35:27 <quicksilver> augur: I'm saying that these are solved problems.
09:35:36 <augur> quicksilver: and i know that
09:35:44 <quicksilver> there are 100s of papers on denotational semantics for simple stored-memory variables
09:35:54 <augur> i was asking what a good place is to read about the solutions
09:36:01 <quicksilver> and fewer, but still some simplified systems of file IO
09:36:02 <augur> not asking for you to tell me there are solutions
09:36:11 <quicksilver> ok but now we're not talking about haskell any more
09:36:14 <quicksilver> and that's my point :)
09:36:24 <quicksilver> as far as I know nothing has been published specificaly about haskell IO in this way
09:36:45 <quicksilver> augur: http://www.eecs.qmul.ac.uk/~ohearn/Algol/intro.html
09:36:52 <levi> There's always the source code of the various Haskell implementations.
09:37:03 <quicksilver> has an extensive bibliography in denotational semantics and relation stuff
09:37:13 <conal> augur: i like your question. forget haskell. forget IO (imperative thinking). think about the essence of interaction and play with some denotational models. this process is where denotative continuous-time programming (FRP) came from. there are probably other wonderful possibilities.
09:37:32 <quicksilver> and O'Hearn understands this area pretty much as well as any living person I suspect, so that should be a reliable starting point.
09:38:17 <augur> conal: my real interest is to try and maybe understand questions in a way similar to IO.
09:38:33 <augur> conal: ive heard that there are some ways to implement IO as just fancy instruction-building
09:38:37 <quicksilver> Landin / Abramsky / Reynolds are good authors to look out for.
09:38:43 <mysticc> Why reads has list in its type .. ?
09:38:53 <augur> which seems very intuitive, especially for a model of questions -- questions could be just instructions of one sort instead of another
09:39:47 <conal> augur: if you want to understand questions, don't emulate IO, since no one understands IO (denotationally).
09:40:11 <augur> ;p
09:40:20 <augur> i was really just looking for a starting point
09:40:28 <danil> mysticc: it returns a list of possible parses.
09:41:03 <augur> conal: some really popular models of questions are really weird. like, a question is a set of propositions that could answer it
09:41:39 <conal> augur: cool.
09:41:54 <augur> conal: its a weird idea tho, because the propositions are just sets of worlds where they're true, right
09:42:27 <augur> and i honestly have no idea how to even think of that sort of model of questions
09:42:38 <augur> its just so .. weird, i guess.
09:42:53 <augur> i want a more BHK model of questions
09:47:31 <squidz> I'm not sure if i understand this well enough. Can the IO monad be a more general case for other Monads. I am trying to use Shelly which has the ShIO monad but think i might have to somehow recognize it as a general IO monad. Do I have this all wrong? Here is my code http://hpaste.org/73128
09:49:40 <geekosaur> IO's a specific case, not a general one
09:50:20 <adnam> squidz: type ShIO a = ReaderT (IORef State) IO a
09:50:44 <danil> squidz: Sh (the ShIO name is deprecated) is an instance of MonadIO, so you can use liftIO to turn IO actions into Sh actions.  To run your Sh action in main, use the 'shelly' function.
09:51:46 <squidz> danil: okay thank you. I'll take a look at liftIO to learn a little about it. Never programmed anything in haskell so this is a big learning experience
09:54:32 <adnam> return/lift has always seemed a little backwards to me, am I thinking about it wrong?
09:54:54 <mauke> how are you thinking about it?
09:55:08 <monochrom> you mean you want to write "lift 5" and "return (putStrLn "hello")"?
09:55:47 <adnam> yes, like lifting a value into the monad
09:55:52 <conal> squidz: if you want to understand Monad, I recommend not starting with IO, which is very unlike other monads.
09:56:11 <squidz> conal: okay, which monads would be better
09:56:11 <monochrom> and "return (putStrLn "hello")"?
09:56:34 <adnam> hmm i'm not so sure about that one :)
09:56:43 <conal> squidz: and if you want to understand haskell, i recommend not starting with imperative programming (IO).
09:57:09 <conal> squidz: Maybe, pair, function, list.
09:57:10 <conal> s
09:57:47 <adnam> I'm not sure about anything anymore
09:57:53 <EvanR> haha
09:58:00 <conal> squidz: and i suggest warming up to Monad. start with Monoid, then Functor, then Applicative.
09:58:20 <danil> adnam: maybe pure is a better name than return, but lift seems pretty good for monad transformers
09:58:21 <squidz> conal: i would like to try writing up a small program that has some use, and im not sure if i would be able to with those monads. Unless you have an idea
09:58:22 <adnam> it's perhaps just that i will forever associate return with escaping from something
09:58:26 <conal> squidz: then you'll see through the haze surrounding Monad.
09:59:07 <MostAwesomeDude> adnam: You'll get used to it. How many other languages do you know?
09:59:11 <adnam> yeah pure does make more sense
09:59:12 <jfischoff> conal: Maybe pure intros to programming should "Goodbye World" ;)
09:59:19 <danil> adnam: they would both be lift if regular values were in Identity and all monad transformers had Identity at the bottom, though
09:59:22 <conal> jfischoff: good one! :)
09:59:31 <jfischoff> :)
09:59:44 <monochrom> return doesn't escape, so you're still sane
10:00:06 <monochrom> do { return (); putStrLn "hello" }  does not escape.
10:00:08 <conal> squidz: you'll inevitably use monads such as the ones i mentioned above (pair etc). and you'll use other type classes beside Monad (Monoid, ...).
10:00:29 <monochrom> oh nevermind, you said "forever", I misread "never"
10:00:37 <adnam> danil: what does it mean to be "in Identity"?
10:01:19 <MostAwesomeDude> adnam: There's a Monad called Identity that does nothing except hold whatever was put into it.
10:01:24 <adnam> ah
10:01:47 <EvanR> adnam: return is just a function, like any other
10:01:57 <adnam> yes that I know
10:02:01 <EvanR> its not a keyword or control thingie
10:02:08 <EvanR> so youre set
10:02:14 <conal> squidz: if you want short-term usefulness, maybe use a language you already know. if you want to learn a different way to think about programming, then I expect that a short-term usefulness focus would be counterproductive. my 2 cents. in any case, have fun!
10:02:15 <adnam> :)
10:02:33 <squidz> conal: okay, so ill try to play around with some examples, but there isnt really a way i could interact with my code since that involves IO usually. Is there any other way I would see results of what im doing. Maybe tests or something?
10:02:55 <adnam> oh well it's not like i accidentally switch them out when coding
10:02:55 <jfischoff> MostAwesomeDude: In response to Multiplate vs. Biplate, after reading more about Biplate and playing with it, I think there is very little that Multiplate can do that Biplate can't. For all practical purposes I would recommend Biplate.
10:03:30 <EvanR> squidz: you dont need to eliminate all IO to concentrate on some other techniques
10:03:41 <MostAwesomeDude> jfischoff: Okay. That's not a surprising result; I looked at Multiplate and I found it hard to imagine when it would be a better call than Biplate.
10:03:58 <EvanR> and you dont need to get into far out psychadelic denotational semantics of IO to use IO
10:04:07 <conal> squidz: keep your IO code as small and isolated as you can. keep coming here to ask for help with making that separation.
10:04:30 <jfischoff> MostAwesomeDude: unfortunately I did not have such foresight and had to discover it the hard way :p
10:04:41 <squidz> conal: EvanR okay guys, thanks for the advice, ill try hacking something up, and if i need help or advice ill return. Thanks for being so helpful
10:04:53 <conal> squidz: :)
10:06:07 <danil> adnam: the Identity monad is just newtype Identity a = Identity { runIdentity :: a }.  Identity a is isomorphic to a -- you can wrap and unwrap things whenever you want.
10:07:14 <adnam> right
10:09:51 <danil> so if you think of pure values as being in the identity monad (rather than no monad at all), return becomes lift
10:10:38 <danil> (this is not particularly deep or useful, but it does explain how the two are related)
10:11:18 <MostAwesomeDude> Hm. Does lift have any combinator friends?
10:12:15 <MostAwesomeDude> In particular, (MonadTrans t, Monad m) => (b -> m a) -> b -> t m a or similar.
10:13:10 <edwardk> danil: its actually quite useful , as another property a monad transformer should be able to give you is something where hoist :: (MonadTrans t, Monad m, Monad n) => (forall a. m a -> n a) -> t m a -> t n a  -- alas the type of that is rank 2
10:13:31 <edwardk> danil: then 'state' in MonadState would be the use of hoist from Identity
10:14:00 <edwardk> (and the natural transformation the user supplies actually has to be a monad homomorphism)
10:17:11 <cobbe> I'm looking for suggestions on how to debug a Parsec parser -- it's rejecting input that should be valid, and I need to find out why.
10:17:19 <end3rW> Are there LLVM bindings for Haskell for LLVM 3.1? The internet says no, but it couldn't hurt to ask.
10:17:36 <cobbe> In particular, I think one of the parsing functions is unexpectedly consuming input on failure.
10:18:01 <cobbe> I'd like to be able to print out or otherwise capture the remaining input after the failure, but I can't find a way to do that
10:18:44 <cobbe> once the original function fails, the rest of the parser computation doesn't run -- unless there's a trick I'm overlooking.
10:19:07 <cobbe> Any suggestions?
10:19:17 <johnw> question: what generic algorithms in Haskell that take a Functor, require the Functor identity law in order to return correct results?
10:23:57 <Cale> cobbe: You can get the remainder of the input... one sec let me look in the documentation :)
10:24:25 <Cale> johnw: I would expect almost all of them?
10:24:25 <cobbe> Cale: yeah, I saw getInput in Text.Parsec.Prim
10:24:35 <johnw> Cale: I just need one concrete example
10:24:37 <Cale> cobbe: yeah, that sounds like it
10:24:48 <johnw> Cale: where if I create a homomorphism breaking functor, the algorithm returns incorrect results
10:25:09 <cobbe> but if the thing I parse right before calling getInput fails, I don't call getInput.  Hang on a sec, let me find an example
10:26:15 <hpaste> cobbe pasted ‚Äúparsec problem‚Äù at http://hpaste.org/73129
10:26:27 <cobbe> Cale: ^
10:26:28 <danil> edwardk: I meant "not deep or useful" to apply just to writing return_{t Identity} as lift_{t} return_{Identity} (which is just a specialization of one of the monad transformer laws).  There are certainly cases where wrapping things in Identity is useful (e.g. to write a monad homomorphism into or out of it).
10:26:30 <Cale> johnw: Of course, a tricky bit about that will be defining "correct results"
10:26:40 <johnw> Cale: for example: a sort which returns unsorted results
10:26:58 <cobbe> so if actualParser fails, the whole do block aborts with a parse error, and I never see the results of either call to getInput
10:27:12 <Cale> cobbe: right, of course
10:27:40 <johnw> I get that "functors are a homomorphism between categories", and so I see that the first functor law is necessary to make that statement true.  I'm just wondering why the restriction exists, other than satisfying that definition from category theory.  There has to be a compelling reason for the law to be there, which makes algorithms possible that would not be otherwise
10:28:05 <cobbe> If there were some way to catch the parse error & continue parsing, then I could profitably use getInput here, but I haven't seen such a facility in the Parsec docs -- though I may just have missed it
10:28:26 <Cale> johnw: Okay, so from the programming side of things there's an intuition that when you fmap some function over a computation, you don't change what that computation "does", you just apply the function to its result
10:28:54 <Cale> johnw: So for example, you still want  fmap lines getContents  to get the contents of the standard input.
10:29:12 <johnw> yes
10:29:12 <Cale> johnw: and if   fmap id getContents  is not the same action as  getContents
10:29:34 <Cale> then there is an intuitive problem with that
10:29:44 <johnw> but "helping intuition" isn't sufficient cause for a fundamental law
10:29:53 <johnw> there must be a category of propositions whose truth depends on the law
10:30:06 <johnw> otherwise, the law is self-justifying
10:30:13 <johnw> "it's there because if it weren't there, it wouldn't be there"
10:30:29 <Cale> Well, if it weren't there, then fmap would not mean what we want it to mean.
10:30:48 <Cale> It's not called a Functor axiom for nothing ;)
10:30:55 <johnw> for example, in the C++ STL, the comparator function for a sort is required to have a "strict weak ordering".  I can write code that shows how sorts will fail if this requirement is not met
10:31:16 <johnw> now I want to write Haskell code that shows that algorithm X will fail if the id law is not met
10:31:29 <Cale> Pick an algorithm
10:31:42 <Cale> (anything generalised over Functor)
10:31:49 <johnw> do you know a simple algorithm in Haskell that depends on functors?
10:31:50 <Cale> and we'll see what happens when the law fails
10:32:03 * hackagebot hamlet 1.1.0.2 - Haml-like template files that are compile-time checked (MichaelSnoyman)
10:32:05 <MostAwesomeDude> johnw: instance Functor [] where fmap f [] = []; fmap f (x:xs) = x:x:fmap f xs
10:32:05 * hackagebot shakespeare 1.0.1.1 - A toolkit for making compile-time interpolated templates (MichaelSnoyman)
10:32:07 * hackagebot shakespeare-css 1.0.1.4 - Stick your haskell variables into css at compile time. (MichaelSnoyman)
10:32:24 <johnw> an algorithm that *uses* functors
10:32:31 <johnw> not a simple use of fmap by the user
10:32:36 <MostAwesomeDude> Anything that uses map; map is the fmap for lists.
10:33:03 <Cale> MostAwesomeDude: well, presumably it also needs to not do anything list-specific aside from calling map
10:33:07 <johnw> i can't think of one, I'm a relative newcomer to haskell
10:33:16 <johnw> what haskell algorithms require fmap?
10:33:20 <Cale> There's not a lot you can do with *only* the assumption that something is a Functor
10:33:27 <Cale> because all you can do is call fmap with some functions
10:33:30 <danil> johnw: any algorithm generalized over a Functor can be normalized to just be fmap, if you assume the Functor laws
10:33:48 <Cale> and so the only way it will fail is it will fail your expectation that the thing is a Functor.
10:33:54 <johnw> danil: hmm, that is very interesting
10:33:58 <danil> (er, to just be fmap f for appropriate f)
10:34:00 <johnw> now you're getting at my question
10:34:49 <Cale> However, once you add some more assumptions about what the functor is, perhaps a broken Functor instance could cause a bug.
10:35:31 <Cale> Like, as MostAwesomeDude mentioned, just take any list function which calls map, and replace map with something that duplicates elements of the list
10:35:39 <Cale> or always gives an empty list
10:35:49 <Cale> (which even satisfies the functor laws, lol)
10:35:51 <johnw> so far I've heard that "normalization breaks if the functor laws are not met", but I'm still looking for "algorithm X is provably broken if the first law is not met"
10:36:47 <johnw> i'm grepping the ghc libraries sources for "fmap" now
10:37:09 * hackagebot shakespeare-js 1.0.0.5 - Stick your haskell variables into javascript/coffeescript at compile time. (MichaelSnoyman)
10:37:11 * hackagebot shakespeare-text 1.0.0.4 - Interpolation with quasi-quotation: put variables strings (MichaelSnoyman)
10:37:27 <Cale> johnw: Okay, suppose I have the following datatype:
10:37:31 <levi> Looking at deforestation algorithms might be fruitful.
10:37:38 <Cale> data Tree a = Tip | Branch a (Tree a) (Tree a)
10:37:55 <Cale> and I have:
10:38:08 <johnw> Cale: that is actually the sample data structure that I have
10:38:15 <johnw> https://gist.github.com/3342568
10:38:24 <Cale> foldTree tip branch = f where f Tip = tip; f (Branch x l r) = branch x (f l) (f r)
10:38:26 <johnw> Traversable depends on fmap
10:38:49 <johnw> Cale: ok
10:39:48 <Cale> johnw: Okay
10:40:17 <Cale> and let's say I have some silly Functor instance which duplicates nodes
10:41:07 <Cale> fmap f Tip = Tip; fmap f (Branch x l r) = Branch (f x) (Branch (f x) (fmap f r) (fmap f l)) (Branch (f x) (fmap f l) (fmap f r))
10:41:19 <Cale> and now someone comes along and writes
10:41:44 <Cale> size = foldTree 0 (\x l r -> x + l + r) . fmap (const 1)
10:42:04 * hackagebot zlib-bindings 0.1.1 - Low-level bindings to the zlib package. (MichaelSnoyman)
10:45:49 <johnw> what would the correct fmap look like?
10:46:13 <johnw> swap l and r in the first Branch constructor call?
10:46:53 <johnw> weird, size always returns 15, no matter the values of my nodes
10:47:04 * hackagebot yesod-auth 1.1.0.1 - Authentication for Yesod. (MichaelSnoyman)
10:47:06 * hackagebot yesod-core 1.1.0.1 - Creation of type-safe, RESTful web applications. (MichaelSnoyman)
10:51:18 <johnw> ah, I see now
10:52:08 * hackagebot yesod-form 1.1.0.1 - Form handling support for Yesod Web Framework (MichaelSnoyman)
10:52:16 <ReinH> we're talking about the shape preserving property of fmap right?
10:52:21 <johnw> yes, exactly
10:52:29 <johnw> and what algorithms depend upon it
10:53:00 <ReinH> johnw: imagine if I wrote fmap for List like this: fmap f x:xs = f x:f x:fmap f xs
10:53:18 <ReinH> fmap _ [] = [] -- ofc
10:53:48 <ReinH> all algorithms that depend on the shape of the instance would be broken if fmap does not preserve the shape of the instance
10:54:07 <johnw> can you name me an algorithm?
10:54:19 <ReinH> Sum
10:54:33 <ReinH> any sort
10:54:38 <ReinH> (+1)
10:54:42 <ReinH> almost anything
10:54:44 <johnw> what about something like LYAH's CMaybe
10:54:48 <johnw> Sum wouldn't be broken in that case
10:54:56 <ReinH> johnw: it would double the sum
10:55:01 <ReinH> since fmap doubles the list
10:55:51 <lamefun> looks like I'll have to use integer ids a lot
10:55:59 <ReinH> but let's ignore sum since it's not as easy to derive from fmap as, say, (+1)
10:56:21 <lamefun> how is resource management usually implemented in Haskell games?
10:56:52 <ReinH> lamefun: unboxing, unpacking, inlining and leveraging the gc?
10:57:10 <ReinH> careful use of strict types?
10:58:21 <ReinH> lamefun: disclaimer: I haven't written any Haskell games, these are just general resource management suggestions.
10:58:36 <lamefun> loading for example
10:59:13 <cobbe> Cale: the parsec bug turned out to be an operator precedence problem (<|> vs >>=) -- so crisis averted.  It's deeply frustrating how hard it is to debug this stuff, though.
10:59:17 <lamefun> my game in haskell is   State -> [InputEvent] -> (State, [OutputEvent])
10:59:41 <dmwit> Strange. Why does your type allow multiple input events?
10:59:47 <ReinH> cobbe: multiple levels of user-definable operator precedence seems like a recipe for such things
11:00:00 <lamefun> so, add output event TextureLoadRequest?
11:00:06 <Cale> cobbe: The best thing for it is just to test things in pieces as you write them.
11:00:10 <lamefun> and TextureLoaded input event?
11:00:40 <cobbe> Actually, I slightly misspoke--the >>= is implicit in a do block.  But either way.
11:01:05 <cobbe> ReinH: agreed, but in this case >>=/do comes from the Prelude, and <!> comes from Parsec, so I kinda have to live with it  :-)
11:01:48 <cobbe> Cale: That's more or less what I was attempting to do, but there's a really thorny mutual-recursion in my grammar, so there's only so much I can do along those lines.
11:02:09 <mysticc> I have n threads and I want to have some notification in another thread when all these n threads have done some work .. So what I could think of is 1. have mvars for all n thread and wait the main thread until all the n threads have written to their mvars or 2. Increase value of mvar by 1 each time and in the main thread keep on checking until it becomes n.. Which one is better. Is there any other better way ?
11:02:34 <dmwit> Why not have them all write to the same mvar?
11:02:35 <EvanR> yes, wait on all the mvars
11:02:39 <dmwit> Just read from it n times.
11:02:47 <EvanR> ah
11:03:10 <mysticc> dmwit: Read from it n times ?? what do you mean ..
11:03:22 <dmwit> I mean replicateM_ n takeMVar
11:03:25 <monochrom> takeMVar n times
11:03:51 <mysticc> oh .. yes .. thanks ..
11:05:05 <mysticc> but would'n then n threads will get blocked ?
11:05:37 <monochrom> not if the waiting thread takeMVars fast enough
11:06:19 <lamefun> dmwit: right, it's better to handle them one by one
11:06:50 <dmwit> lamefun: I don't really have anything helpful to tell you though, so sorry about that. =P
11:07:15 <dmwit> I've written pieces of a game, but performance was far from my mind.
11:09:57 <mysticc> monochrom: Other problem is my threads are performing the work recursively ... so it can happen that one thread calls putMVar several times before other thread gets a chance ..?
11:10:22 <pepijndevos> how do I shuffle a list? Just the simplest way, using an IO monad.
11:10:34 <mysticc> I means same function is called again and again in the threads ..
11:11:01 <mysticc> I somehow want to count when every n thread calls the function 1 time each then do something ...
11:11:10 <monochrom> so don't call putMVar from that function. call putMVar from an outer function
11:11:26 <mysticc> monochrom: read my last comment.
11:12:26 <monochrom> forkIO (f 5 `finally` putMVar v)
11:13:30 <dmwit> pepijndevos: random-fu has a high-quality list shuffle
11:13:32 <dmwit> http://hackage.haskell.org/packages/archive/random-fu/0.2.3.0/doc/html/Data-Random-List.html
11:14:17 <mysticc> I have function f in n threads and this is called repeatedly.. and my problem is when f is called 1 time in all n threads then do something .. I want to somehow synchronize on the number of calls to function f .. so then block all other threads untill everybody call f one time then do something .. this is repeated when f gets called 2nd time and so on ..
11:14:45 <mysticc> monochrom: ^^
11:14:51 <n-dolio> How were you going to solve this with the counting mvar?
11:15:29 <mysticc> I thought using n mvars was what I needed ..
11:24:13 <danil> mysticc: you can use one mvar to have the main thread wait for the workers, and then one per worker that the main thread uses to tell that worker to continue.  Just have the end of the worker loop put on the "I'm done" mvar and take on the "can I go again?" mvar.
11:25:27 <monochrom> I can reduce that further to 2 mvars. one for "done". one for "go".
11:26:07 <danil> right, just say "go" as many times as there are threads
11:26:09 <monochrom> main_thread = replicateM_ n (takeMVar done) >> replicateM_ n (putMVar go ())
11:26:43 <monochrom> f = ... putMVar done () >> takeMVar go >> f
11:27:10 <dmwit> This seems silly.
11:27:15 <dmwit> I think he just wants n Chan's.
11:27:33 <dmwit> Write to the Chan's as fast as you can, and have the main thread read from them in sequence.
11:27:52 <ReinH> }/redraw
11:27:57 <ReinH> sorry
11:28:56 <monochrom> 2 mvars is simpler than n chans if the amount of communication and the bottleneck are the same
11:31:10 <dmwit> Well, part of the problem is that I have no idea what he's actually trying to accomplish.
11:33:19 <ghorn_> i wonder if it's possible to write a type signature and a bunch of properties, use djinn to generate a bunch of candidate implementations, then filter them with quickcheck until only the correct one remains
11:33:41 <mysticc> dmwit: Well its an hw problem .. there are n players and server is monitoring some kind of game between them .. In each round of game players send some number to server and depending on that players are kicked out. In each round atleast half players are kicked out . .. This is repeated until only one player is left..
11:34:40 <danil> ghorn_: djinn doesn't work with recursive types, so you're unlikely to be able to produce very interesting functions that way
11:34:56 <dmwit> ghorn_: I think there's a fair amount of work on inventing code that conforms to a spec. The keyword to use when searching is "synthesis".
11:36:25 <dmwit> ...and "program specification", I guess
11:37:05 <veldskoen> sup guys! lets say I have a function which returns something like Just [1,2] How do I get that 1 or 2 out of there? e.g. say I want to sum the contents of that just?
11:37:05 * hackagebot zip-conduit 0.1 - Working with zip archives via conduits. (TimCherganov)
11:37:45 <MostAwesomeDude> :t \ma x -> do { lift $ ma x }
11:37:46 <lambdabot> forall t (m :: * -> *) a (t1 :: (* -> *) -> * -> *). (MonadTrans t1, Monad m) => (t -> m a) -> t -> t1 m a
11:38:05 <MostAwesomeDude> Does this combinator have a name? ^^
11:38:31 <ghorn_> veldskoen: what do you want to happen when you pass that function Nothing?
11:38:37 <danil> :t liftM lift
11:38:39 <lambdabot> forall (m :: * -> *) a (t :: (* -> *) -> * -> *) (m1 :: * -> *). (MonadTrans t, Monad m, Monad m1) => m1 (m a) -> m1 (t m a)
11:38:48 <dmwit> veldskoen: You don't; you lift the sum function into one that knows how to handle Maybe values.
11:38:54 <dmwit> > fmap sum $ Just [1,2]
11:38:56 <lambdabot>   Just 3
11:39:05 <dmwit> fmap goes by many names
11:39:22 <dmwit> > (liftM sum $ Just [1,2], liftA sum $ Just [1,2], sum <$> Just [1,2])
11:39:24 <lambdabot>   (Just 3,Just 3,Just 3)
11:39:58 <dmwit> :t (lift .)
11:39:59 <lambdabot> forall (m :: * -> *) a (t :: (* -> *) -> * -> *) (f :: * -> *). (MonadTrans t, Monad m, Functor f) => f (m a) -> f (t m a)
11:40:22 <dmwit> MostAwesomeDude: I don't think so. It hardly needs one.
11:40:43 <dmwit> I can't think of a name that's shorter than "lift ." and still usable.
11:41:10 <veldskoen> ghorn: hmmm forgot about Nothing... Seems I have more to think about... thanks!
11:41:28 <veldskoen> dmwit: cool thanks! will probably use that eventually
11:41:44 <ghorn_> np
11:41:47 <MostAwesomeDude> dmwit: Hmm, so that's using (->) as the functor?
11:42:00 <MostAwesomeDude> Er, (->) e for some e.
11:42:04 <mmos> what's wrong with (space >> return ()) <|> eof ?   (I get "no instance for Stream s m Char")
11:42:18 <MostAwesomeDude> @unpl lift .
11:42:19 <lambdabot> (\ a d -> lift (a d))
11:42:24 <mmos> :t Char
11:42:26 <lambdabot> Not in scope: data constructor `Char'
11:42:32 <dmwit> MostAwesomeDude: Well, yes, but it works fine with Prelude's (.).
11:42:33 <mmos> :t String
11:42:34 <lambdabot> Not in scope: data constructor `String'
11:42:37 <dmwit> :t (lift Prelude..)
11:42:39 <lambdabot> forall (m :: * -> *) a (t :: (* -> *) -> * -> *) a1. (MonadTrans t, Monad m) => (a1 -> m a) -> a1 -> t m a
11:42:41 <mmos> :t 'x'
11:42:43 <lambdabot> Char
11:42:49 <mmos> :t eof
11:42:51 <lambdabot> Not in scope: `eof'
11:42:57 <MostAwesomeDude> @pl \ma x y -> lift (ma x y)
11:42:57 <lambdabot> ((lift .) .)
11:43:02 <monochrom> import Text.Parsec.String
11:43:10 <MostAwesomeDude> Okay, I'm convinced. That's a pretty pleasant way of doing things.
11:43:10 <mmos> :t eof
11:43:12 <lambdabot> Not in scope: `eof'
11:43:18 <mmos> import Text.Parsec.String
11:43:27 <mmos> :t eof
11:43:29 <lambdabot> Not in scope: `eof'
11:43:39 <mmos> import Text.Parsec
11:43:49 <mmos> :t eof
11:43:50 <lambdabot> Not in scope: `eof'
11:43:51 * dmwit facepalms
11:43:51 <monochrom> I mean do it in your file. lambdabot does not know import
11:44:14 <monochrom> lambdabot is not ghci. when will people understand this?
11:44:19 <mmos> import Text.Parsec.Combinator
11:44:25 <mmos> :t eof
11:44:27 <lambdabot> Not in scope: `eof'
11:44:28 <dmwit> ...
11:45:38 <monochrom> I have an idea. I can just +q lambdabot :)
11:45:51 <dmwit> heh
11:45:58 <johnw> i'm still having trouble finding a standard library algorithm whose implementation uses fmap and depends on the functor laws
11:46:11 <johnw> I can write my own functions that depend on the functor laws
11:46:19 <johnw> but I want to find an existing stdlib algo that needs them
11:46:33 <n-dolio> Why?
11:46:38 <johnw> call it educational
11:46:48 <dmwit> Define "depends on".
11:46:57 <johnw> if the law is violated, the results change
11:47:18 <dmwit> For example, I observe that length . fmap f = length; does length "depend on" the functor laws?
11:47:21 <n-dolio> There are no algorithms that must be written to use fmap for a particular type, and there are few algorithms that generalize to arbitrary functors.
11:47:54 <n-dolio> But fmap is a handy function to have.
11:47:58 <johnw> ah, that's what I want; an algorithm that generalizes to arbitrary functors
11:48:07 <n-dolio> And what it does is charaterized by the two axioms.
11:48:18 <johnw> i get htat
11:48:36 <mmos> okay what is the proper way to write a Parsec expression that parses either a space or eof?
11:48:36 <johnw> but I'm trying to distinguish between arbitrary axiom that define its character, and necessary axioms that functional code currently depends on
11:48:50 <johnw> the former control how *I* use fmap, the latter governs requirements made by the library to be "correct"
11:49:20 <mmos> oh all I had to do was add a type declaration. it works now. huh.
11:49:59 <MostAwesomeDude> johnw: Why does it have to be in the base?
11:50:01 <dmwit> "if the law is violated, the results change" is not much of a definition.
11:50:10 <johnw> MostAwesomeDude: in the base, or on Hackage
11:50:13 <dmwit> If you change the definition of fmap, the output of any function that calls fmap will change.
11:50:18 <johnw> I just don't want to be an artificial example of my own creation
11:50:25 <dmwit> That has nothing to do with whether there are laws or not.
11:50:27 <MostAwesomeDude> johnw: Well, I'm sure there's craploads of stuff on Hackage that depends on Functor to work correctly.
11:50:28 <johnw> otherwise, I'm just manufacturing evidence
11:51:05 <dmwit> I don't think the question is precise enough yet to have a meaningful answer.
11:51:06 <johnw> dmwit: I mean, is there a use of Functor (say, on Hackage) where the validity of the first law is central to its correctness
11:51:17 <monochrom> every programmer manufactures existential evidence, by definition
11:51:26 <johnw> take LYAH's CMaybe value for example
11:51:40 <johnw> there are tons of uses of fmap that still work just fine, even though CMaybe violates the first law
11:51:51 <johnw> the first law in those cases just doesn't matte
11:51:52 <johnw> r
11:52:40 <MostAwesomeDude> johnw: It's been pointed out that there is either zero or one correct fmap for any given type.
11:52:51 <johnw> I want a compelling demonstration of the need for the first law, other than "helps intuition", or "makes this sample code I just wrote to demonstrate breakage, break"
11:53:14 <levi> It's not intuition that it helps, it's the formal reasoning process.
11:53:23 <danil> johnw: what do you mean "work just fine"? The results change, you've just decided you don't care about that kind of change.
11:53:29 <n-dolio> I don't think you understand how general functors are, that you want some algorithms to be generalized to arbitrary functors.
11:53:55 <johnw> i know that I can change fmap to break any use of fmap
11:54:06 <johnw> I mean, if my fmap only breaks the first law
11:54:10 <johnw> like with LYAH's CMaybe
11:54:30 <johnw> CMaybe will seem to be valid in most cases
11:54:51 <johnw> foldr (:) [] (CMaybe 0 "foo") will return ["foo"], just as you'd expect
11:54:56 <danil> johnw: CMaybe also breaks the composition law
11:55:01 <johnw> and yet, behind the scenes, it's breaking the first law
11:55:01 <levi> You can write such a thing, but you can't treat it like a real Functor.  It's just something else with a functor-like interface.
11:55:11 <johnw> danil: yeah; are those two laws really just expressing one law?
11:55:19 <MostAwesomeDude> For example, instance Functor CMaybe where fmap f CNothing = CNothing; fmap f (CJust counter x) = CJust counter (f x)
11:55:27 <MostAwesomeDude> That's the correct fmap for CMaybe.
11:55:34 <johnw> levi: exactly.  so what algorithms demonstrably require "a real Functor" to operate?
11:55:59 <danil> johnw: parametricity gets you the second from the first, but not the other way--for instance, the second holds for fmap f xs = [], but not the first
11:56:02 <dmwit> johnw: The refactoring algorithm requires it. =)
11:56:05 <levi> It's not about algorithms, it's about the meaning of things.
11:56:22 <MostAwesomeDude> johnw: Demonstrably? How about every Applicative or Monad that uses its Applicative or Monad instance to define its Functor instance?
11:56:52 <johnw> no one can name me just one function from the standard library or Hackage?
11:56:56 <johnw> that would clear all this up, real fast
11:56:57 <dmwit> johnw: The one where you're looking at a piece of code that goes "f . g . h" and you realize that "f = fmap f'" and "g = fmap g'" and "h = fmap h'", and so you realize you can optimize that to "fmap (f' . g' . h')" instead.
11:57:07 <johnw> otherwise, we're just dancing in circles here
11:57:07 <MostAwesomeDude> johnw: Well, you already rejected Foldable and Traversable.
11:57:14 <levi> johnw: This is left as an exercise for the interested reader. :P
11:57:21 <johnw> Foldable uses the Monoid, not the Functor
11:57:26 <johnw> Traversable is compelling
11:57:32 <MostAwesomeDude> How about lens? >:3
11:57:46 <johnw> levi: and the interested (and newbie) reader was hoping you'd help point him in the right direction :)
11:57:48 <johnw> hmmm
11:57:49 <MostAwesomeDude> http://comonad.com/reader/2012/mirrored-lenses/ makes use of forallf. Functor f
11:57:49 <johnw> lens..
11:57:53 <johnw> ok, I'll look there
11:57:53 <ergot> is there any simple binary tree implementation with BFS in haskell?
11:58:06 <parcs`> can't 'fmap id = id' be derived from 'fmap (f . g) = fmap f . fmap g'?
11:58:18 <dmwit> I think the other way around.
11:58:26 <monochrom> n-dolio cleared it up real fast, 10 minutes ago. you continued to dance
11:58:27 <levi> johnw: Sometimes, it's best to put questions aside until you learn enough background information to answer them yourself.
11:58:44 <monochrom> <n-dolio> There are no algorithms that must be written to use fmap for a particular type, and there are few algorithms that generalize to arbitrary functors.
11:58:57 <danil> johnw: how about implementing >>= with join and fmap?  That implementation won't satisfy the monad laws if your fmap is wrong
11:59:19 <dmwit> The force of the Functor laws is that all algorithms that generalize to arbitrary functors *are* applications of fmap and nothing else.
11:59:20 <johnw> danil: but then I'm just using one set of laws to justify another set of laws
11:59:31 <johnw> I want _code that always breaks_ if the law is not upheld
11:59:40 <ergot> the only thing I found with BFS is with ListT, and is too much for my head
11:59:43 <MostAwesomeDude> johnw: Lenses as implemented by the lens package.
11:59:46 <MostAwesomeDude> Go read. Now.
11:59:47 <johnw> like the way that sorting breaks in the C++ STL if your comparator doesn't support strict weak ordering
11:59:52 <johnw> MostAwesomeDude: am reading
12:00:02 <danil> johnw: what does "breaks" mean if not "fails to satisfy the spec"?
12:00:06 <prototrout> parcs`: I think from 'fmap (f . g) = fmap f . fmap g' you can say 'fmap id = fmap id . fmap id' (so fmap is idempotent) but not necessarily that 'fmap id = id'. You can say that one or more 'fmap id's are equivalent, but not that it's the same as zero.
12:00:07 <dmwit> johnw: The following code breaks if the Functor laws do: {-# REWRITE fmap f . fmap g = fmap (f . g) #-}.
12:00:09 <levi> johnw: This is like defining something to be of class Eq and implementing Eq in a non-standard way that doesn't correspond to what equality is supposed to mean.
12:00:11 <johnw> danil: meaning your sort is not a sort
12:00:23 <dmwit> johnw: (likewise for the id law)
12:00:25 <prototrout> fmap id is idempotent*
12:00:31 <monochrom> order laws are way more stronger than functor laws
12:00:32 <prototrout> hrm, maybe that's enough to say fmap id = id
12:01:15 <monochrom> stronger laws means you can write useful algorithms. weaker laws means useless algorithms
12:01:16 <danil> johnw: "your sort is not a sort" and "your monad is not a monad" sound the same to me, it's just different specs you're violating
12:01:27 <dmwit> prototrout: No, f . f = f does not imply f = id.
12:01:35 <dmwit> prototrout: consider f = const ()
12:01:55 <parcs`> prototrout: if fmap (f . g) = fmap f . fmap g then 'fmap (id . g) = fmap id . fmap g' AND 'fmap (id . g) = fmap g = id . fmap g'
12:02:02 <dmwit> or const False, I guess
12:02:05 <n-dolio> A better try would be 'fmap f = fmap (f . id) = fmap f . fmap id', but that still doesn't require that fmap id = id.
12:02:06 <prototrout> dmwit: Right, just throught of that as well.
12:02:10 <nand`> prototrout: isn't that exactly what he said?
12:02:16 <nand`> oh
12:02:33 <nand`> double fail on my part; I meant to talk to dmwit and didn't see ‚Äúmaybe that's enough to say fmap id = id‚Äù
12:02:38 <levi> johnw: There are a bunch of papers and wiki articles and blog posts about 'calculating programs' and exploiting the algebraic properties of the standard type classes in order to do interesting things.
12:02:48 <sipa> prototrout: idempotence means that the data is "projected" on some subset; within that subset, the function is just the identity
12:03:13 <monochrom> monad laws are just a wee bit stronger than functor laws. breaking monad laws just means breaking a few refactorings in practice, not really breaking a few useful algorithms
12:03:31 <johnw> monochrom: hmm
12:03:40 <parcs`> so 'fmap id . fmap g = fmap g' doesn't imply fmap id = id?
12:03:46 <n-dolio> No.
12:04:03 <n-dolio> fmap f = const V, const V . const V = const V.
12:04:14 <monochrom> and so breaking functor laws means breaking even fewer refactorings
12:04:48 <monochrom> so yes, therefore it's too hard to observe functor law breakage in practice
12:05:03 <johnw> so far, the refactoring case is the only compelling case I can find for functor laws
12:05:11 <parcs`> n-dolio: sneaky
12:05:46 <johnw> which is valuable and all, but that's more about conventions than making categories of solutions possible
12:06:01 <parcs`> that makes sense, though. thanks
12:06:39 <monochrom> the most compelling reason for "fmap id = id" is that I can't find anything to replace the RHS and still preserve parameteric polymorphism
12:07:05 <n-dolio> What happens if you write a Monoid instance that doesn't follow the axioms?
12:07:46 <MostAwesomeDude> johnw: Lenses.
12:07:56 <dmwit> MostAwesomeDude: Stop saying that. It's not helpful.
12:08:07 <MostAwesomeDude> dmwit: Fine.
12:08:09 <dmwit> Lenses do not make critical use of the functor laws.
12:08:09 <monochrom> oh monoid laws are stronger. if matrix multiplication were not associative, then that algorithm about "finding the best bracketting" would be bunk
12:08:27 <MostAwesomeDude> The new ones do.
12:08:32 <dmwit> Not really.
12:08:36 <MostAwesomeDude> 'k.
12:08:38 <edwardk>  dmwit: actually the functor laws do play an important rule in the lens package
12:08:46 <edwardk> i motivated them using the laws from traversable and functor
12:08:51 <srhb> :t wWorker -- wWorker :: Functor f => (Coord -> f Coord) -> World -> f World
12:08:51 <srhb>  
12:08:53 <lambdabot> Not in scope: `wWorker'
12:08:54 <srhb> Looks critical!
12:08:55 <srhb> oops
12:08:59 <edwardk> rather than off the get/set laws
12:09:00 <srhb> paste from ghci :-)
12:09:05 <dmwit> I mean, you never rewrite an "fmap f . fmap g" into an "fmap (f . g)".
12:09:14 <dmwit> And you never rewrite an "fmap id" into an "id".
12:09:27 <n-dolio> It only matters if you want lenses to follow certain rules, and then you have to say why you wan that.
12:09:29 <edwardk> dmwit: that is a setter law ;)
12:09:32 * roconnor prays that GHC rewrites fmap id into id
12:09:41 <edwardk> roconnor: it doesnt
12:09:45 <roconnor> edwardk: what
12:10:00 <roconnor> edwardk: what about all my fmapping newtype wrappers
12:10:02 <edwardk> dmwit: http://hackage.haskell.org/packages/archive/lens/2.1/doc/html/Control-Lens-Setter.html#g:1
12:10:04 * dmwit == n-dolio
12:10:06 <edwardk> roconnor: you pay for it
12:10:10 <parcs`> fmap from = unsafeCoerce
12:10:10 <roconnor> fUUUUUUUUUUUUUUUUUUUUUUUUUUU
12:10:11 <n-dolio> roconnor: I don't think it operates on anything general enough to make that useful.
12:10:17 <n-dolio> Like 'fmap (\x -> x)' sorry.
12:10:25 <edwardk> roconnor: hence why i want Control.Newtype to add cheap coercions using unsafeCoerce
12:10:38 <roconnor> edwardk: screw Control.Newtype, just add the rewrite rules
12:10:46 <n-dolio> roconnor: You could only make it specifically rewrite 'fmap id', which no one writes.
12:10:50 <edwardk> roconnor: you can also use the iso hack
12:10:58 <EvanR> statements of the form 'if the ___ laws werent true, then ___' are funny to me
12:11:08 <roconnor> n-dolio: I write fmap getSum all the time
12:11:17 <roconnor> n-dolio: which compiles to fmap id
12:11:17 <EvanR> its like contradictory
12:11:23 <roconnor> which souldl compile to id
12:11:25 <edwardk> class Iso a b where iso :: f a -> f b; osi :: f b -> f a; instance Iso a a where iso = id; osi = id; and use newtype deriving for Iso (the contents of your newtype) for your newtype
12:11:26 <roconnor> and then disappear
12:11:30 <edwardk> then you can use iso to coerce
12:11:40 <edwardk> its of course an unsafeCoerce
12:11:43 <n-dolio> dmwit: Actually, there are reasons why you want lenses to follow certain rules, but it's 'just convention'.
12:12:40 <n-dolio> roconnor: Also, for eliminating newtype stuff, you need to work at a level below where rewrite rules fire, I think.
12:12:47 <roconnor> n-dolio: oh you are saying there are no rewrite rules that operate on core after newtypes have been removed?
12:12:53 <roconnor> ah
12:12:56 <n-dolio> Not as far as I know.
12:13:04 * roconnor cries himself to sleep
12:13:06 <edwardk> roconnor: yes
12:17:59 <dmwit> To defend myself, even though the moment has past: what I mean by "lens doesn't really use the Functor laws" is "you can define any old instance of Functor and it won't change anything, because all the functions in the lens library instantiate things at particular functors that already happen to obey the laws".
12:18:38 <edwardk> that much is true
12:19:11 <roconnor> unless you make a monoid that isn't a monoid
12:19:40 <edwardk> 'garbage in, garbage out' ;)
12:22:07 * hackagebot swish 0.8.0.0 - A semantic web toolkit. (DouglasBurke)
12:23:24 <Peaker> edwardk, hey -- it appears in the new lens, you're late binding some TH names again, causing the need for imports of indirectly used names at the user side
12:29:59 <EvanR> i have mwc-random, how do i take a random element from a list
12:30:29 <roconnor> EvanR: ah, the old take a random element from a lazy list problem.
12:30:40 <EvanR> hah didnt think of that
12:30:54 <roconnor> it's tricky.
12:31:10 <roconnor> you start with the head of the list
12:31:26 <hughfdjackson> 3
12:31:29 <hughfdjackson> oops
12:31:29 <roconnor> then with 1/2 chance you drop it and take the next element of the list
12:31:45 <roconnor> otherwise you keep the head and skip the second element of the list
12:31:52 <EvanR> so its an exponential decay distribution
12:32:09 <roconnor> now with 1/3 chance you drop what you are holding and take the third element of the list
12:32:13 <EvanR> oh
12:32:31 <roconnor> otherwise keep what you are holding
12:32:34 <roconnor> then 1/4
12:32:46 <roconnor> until you reach the end of the list when you produce what you are holding
12:33:05 <roconnor> (please take note of the error case when the list is empty to begin with)
12:33:14 <EvanR> ive seen that algorithm before
12:33:20 <EvanR> it still amazes me that it works
12:33:53 <EvanR> related question
12:34:21 <EvanR> how do i get a random yes or no with probably p and 1-p
12:34:37 * roconnor doesn't know
12:34:57 <EvanR> hmm
12:35:08 <roconnor> wait I do know
12:35:10 <Jeanne-Kamikaze> I remember that was on the wikipedia
12:35:17 <roconnor> you take an infinite stream of binary flips
12:35:24 <roconnor> and do a lazy comparision with p
12:35:31 <roconnor> rather
12:35:50 <roconnor> you take an infinite stream of binary flips and consider it as a binary expantion of a number between 0 and 1
12:36:00 <roconnor> and you do a lazy comparision with p
12:36:10 <roconnor> will terminate with probability 1
12:36:38 <EvanR> haha
12:36:41 <n-dolio> What kind of thing is p?
12:36:50 <EvanR> p is a real number ;)
12:37:01 <roconnor> n-dolio: I assume a creal between 0 and 1.
12:37:20 <n-dolio> You don't need to do it for real numbers to implement the random select algorithm, so that isn't related.
12:37:33 <EvanR> rational
12:37:54 <roconnor> n-dolio: well can can use it to implement the random select algorithm, so it is related
12:37:58 <roconnor> *you can
12:38:10 <EvanR> ill settle for rationals right now
12:38:14 <n-dolio> You can. Is there no better way to do it if you know the number is rational?
12:38:39 <EvanR> rationals of the form 1/n
12:38:41 <n-dolio> Also, the random select algorithm only uses numbers of the form 1/n.
12:39:06 <plat0> Is this in the standard library somewhere: join s ss = foldr (++) "" (intersperse s ss)
12:39:09 <EvanR> so pick a number from 0 to n-1, 0 is yes, otherwise no
12:39:11 <roconnor> n-dolio: I'm not aware of a way to turn binary flips into a choice with rational probability in a bounded number of flips
12:39:11 <janne`> hi!  I'm working some code that deals with utf-8 strings going in and out of a database.  I'd like to add some unit tests for this code, and would need utf-8 input strings for these tests.  I wonder if it's a good idea to simply type in utf-8 strings in Emacs?  or will other people editing my source be in trouble, and I'd be better off encoding this in some other way into the source?
12:39:30 <EvanR> thx for yer help ;)
12:39:34 <roconnor> n-dolio: I'm not aware of a way to turn binary flips into a choice with (1/3) in a bounded number of flips
12:40:03 <roconnor> Seems almost certainly impossible.
12:40:09 <EvanR> roconnor: true, to get a random 0 1 or 2 with normal rngs, you have to reroll and you have an vanishing probability to go into an infinite loop
12:40:19 <EvanR> ;)
12:40:44 <roconnor> the best method I can think of degenerates into the real number comparision method I started with
12:40:47 <parcs`> :t intercalate
12:40:48 <lambdabot> forall a. [a] -> [[a]] -> [a]
12:41:25 <EvanR> luckily i have primitives which are not limited to binary flips ;)
12:41:58 <Peaker> @src intercalate
12:41:59 <lambdabot> intercalate xs xss = concat (intersperse xs xss)
12:42:03 <t7> roconnor: are you still en france?
12:42:15 <roconnor> t7: I'm back in canada now
12:42:26 <parcs`> :t ""
12:42:27 <lambdabot> [Char]
12:42:37 <parcs`> bah, should have type [a]
12:42:40 <t7> how did you like it?
12:43:07 <roconnor> It isn't raining as much
12:43:09 <EvanR> IsString a => a
12:43:11 <roconnor> though it still rains
12:43:14 <roconnor> just not every day
12:43:50 <roconnor> EvanR: I find it hard to believe that you have primitive that are not limited to binary flips
12:44:06 <roconnor> well maybe you do
12:44:34 <roconnor> some sort of mersenne twister give results in multiples of 1/p for some huge prime p?
12:44:58 <roconnor> not exactly random though :D
12:45:28 <obiwahn> i want a something like sum(f(i),i=0..m)
12:45:39 <obiwahn> what haskell functions would i use?
12:45:44 <roconnor> obiwahn: sum [f i | i <- [0..m]]
12:47:15 <n-dolio> The beginning of the conversation established that we were talking about mwc-random, I thought.
12:47:30 <n-dolio> Which claims to give you (a, a) -> Gen a or something.
12:47:45 <n-dolio> Something more complicated than that, probably.
12:48:15 <roconnor> oh
12:48:18 <n-dolio> So if you take it at its word, then you give it (1, n), and use (==1) or something.
12:48:27 <roconnor> n-dolio++
12:48:49 <n-dolio> It's probably lying, though.
12:48:56 <roconnor> ^_^
12:49:10 <EvanR> it doesnt claim that the running time is bounded
12:49:15 <roconnor> hah
12:49:32 <EvanR> but it almost certainly is ;)
12:52:44 <roconnor> EvanR: is it pseudo-random?
12:53:35 <EvanR> mwc is deterministic
12:54:11 <Peaker> edwardk, sent a pull request to fix TH user code name dependency
12:54:18 <edwardk> ?
12:54:24 <EvanR> i assume it uses IO for performance
12:54:25 <edwardk> whats wrong?
12:54:31 <EvanR> mutable arrays
12:54:45 <edwardk> oh
12:54:48 <edwardk> definitely
12:55:13 <edwardk> peaker: thanks!
12:55:39 <Peaker> edwardk, sure :)
12:56:34 <danharaj> does anyone have a favorite priority queue package?
12:57:00 * roconnor uses PSQueue a lot
12:57:50 <danharaj> A good enough endorsement for me.
12:59:29 <obiwahn> > foldl (+) 0 $ map (+2) [0..3] ... roconnor is there a way to rewrite this shorter?
12:59:31 <lambdabot>   <no location info>: parse error (possibly incorrect indentation)
13:00:00 <zhulikas> sum $ map (+2) [0..3]
13:00:24 <n-dolio> Yes, there is a way.
13:00:28 <dmwit> sum [2..5]
13:00:33 <zhulikas> :DD
13:00:35 <zhulikas> or that
13:00:53 <fmap> why not 14?
13:00:56 <zhulikas> yea
13:00:58 <statusfailed> Huh.. you can use undefined as a type
13:01:04 <danharaj> undefined is not a type
13:01:12 <EvanR> :t undefined
13:01:13 <lambdabot> forall a. a
13:01:19 <danharaj> :k undefined
13:01:20 <lambdabot> Not in scope: type variable `undefined'
13:01:32 <statusfailed> > mempty :: [undefined]
13:01:33 <lambdabot>   []
13:01:38 <statusfailed> What did I do ??
13:01:39 <EvanR> :k Maybe undefined
13:01:39 <statusfailed> :D
13:01:41 <lambdabot> Not in scope: type variable `undefined'
13:01:52 <danharaj> You binded undefined as a type variable.
13:01:53 <zhulikas> :k Just undefined
13:01:54 <lambdabot> Not in scope: type constructor or class `Just'
13:01:55 <lambdabot> Not in scope: type variable `undefined'
13:01:55 <statusfailed> ooooh
13:01:55 <statusfailed> hahaha
13:02:11 <roconnor> danharaj: be ware that PSQueue is a priority *search* queue, so I guess it might not be as fast as the fasted prioirity queue.
13:02:13 <statusfailed> My bad :)
13:02:17 <roconnor> *aware
13:02:22 <EvanR> > mempty :: [a]
13:02:24 <lambdabot>   []
13:02:29 <n-dolio> Also it presumaby requires your payloads to be orderable or something.
13:02:38 <n-dolio> If that matters.
13:03:14 <statusfailed> Huh, so I can create a generic empty list?
13:03:15 <danharaj> Fair points. If I need speed or a pqueue of things without Ord I'll shop around.
13:03:19 <statusfailed> I guess that's not entirely surprising
13:03:32 <danharaj> Is there a priority queue package in the platform? Seems like a basic data structure.
13:03:42 <danharaj> :t []
13:03:43 <lambdabot> forall a. [a]
13:04:01 <statusfailed> seems odd that mempty complains without the annotation
13:04:11 <EvanR> > mempty
13:04:12 <lambdabot>   ()
13:04:16 <EvanR> hah
13:04:16 <danharaj> monomorphism restriction
13:04:23 <danharaj> (possibly)
13:04:54 <EvanR> statusfailed: mempty isnt always the empty list
13:05:05 <EvanR> > mempty :: Maybe a
13:05:06 <statusfailed> EvanR: I just realisd that... I am asking some duuuumb questions :D
13:05:06 <lambdabot>   Could not deduce (Data.Monoid.Monoid a) from the context ()
13:05:07 <lambdabot>    arising from...
13:05:15 <EvanR> > mempty :: Monoid a => Maybe a
13:05:17 <lambdabot>   Nothing
13:07:12 <n-dolio> Monoid is not something that can be defaulted normally.
13:07:17 <n-dolio> You need extended defaulting, I believe.
13:08:11 <frerich_> Does anybody have some hints as to how implement a recursive algorithm which recurses "multiple times"? I'm not sure what the correct term is - I'm thinking of functions which don't just call themselves once, but multiple times. Think of a flood fill algorithm, which invokes itself recursively four times (for each direction). I can't seem to find a nice way to implement such functions.
13:08:18 <frerich_> Maybe the State monad?
13:08:33 <EvanR> thats easy
13:09:08 <EvanR> four x = [four x, four x, four x, four x]
13:09:20 <EvanR> not well typed, i know ;)
13:09:32 <copumpkin> now make it well typed
13:09:35 <EvanR> ok
13:09:58 <EvanR> four x = Four (four x) (four x) (four x) (four x)
13:10:07 <edwardk> Peaker: waiting for travis to check it the merged code and then i'll shove it to hackage
13:10:13 <copumpkin> :t four x = In [four x, four x, four x, four x]
13:10:14 <lambdabot> parse error on input `='
13:10:18 <copumpkin> :t let four x = In [four x, four x, four x, four x] in four
13:10:18 <frerich_> EvanR: Hm, but the thing is - with a flood fill algorithm, each recursive call serves as input to the next. With 'straight' recursion (the function calls itself just once) I basically did a fold. But if a function calls itself multiple times, it gets a bit ugly somehow.
13:10:19 <lambdabot> forall t. t -> Mu []
13:10:23 <copumpkin> not very exciting, though
13:10:27 <copumpkin> might as well kill the x
13:11:52 <roconnor> @let ack m n = if m == 0 then n+1 else if n == 0 then ack (m-1) 1 else ack (m-1) (ack m (n-1))
13:11:53 <lambdabot>  Defined.
13:11:58 <roconnor> > ack 2 2
13:12:01 <lambdabot>   7
13:12:02 <obiwahn> how can i express the following: p is a vector/array of tupels  now i want to calculate f(n) = sum(p[i]+f(i),i=0..n)
13:12:11 <roconnor> frerich_: no problem nesting recursive calls
13:12:13 <pxlas> > ack 5 5
13:12:17 <lambdabot>   mueval-core: Time limit exceeded
13:12:19 <obiwahn> i do not see how to access the right position:(
13:12:21 <roconnor> frerich_: you can use the state monad if you think it helps
13:12:41 <obiwahn> do i need my own version of fold that tracks the i?
13:12:49 <frerich_> roconnor: Not sure it does, I never used it :-) I  just found http://www.markhneedham.com/blog/2012/04/07/algorithms-flood-fill-in-haskell/ and somebody in the comments suggestet the State monad as well. So I think I'll give that a try.
13:13:05 <EvanR> :k Mu
13:13:06 <latro`a> obiwahn, you can just use map
13:13:06 <lambdabot> (* -> *) -> *
13:13:08 <roconnor> obiwahn: what is the precise type of p?
13:13:37 <latro`a> if your indexing function is !!!, you're looking at sum $ map (\i -> p !!! i + f i) [0..n]
13:13:42 <Reaga> hey buddy
13:13:52 <Reaga> why is it hard to model relations in haskell
13:13:59 * roconnor wonders what he did when he implemented floodfill
13:14:00 <obiwahn> i am not sure what i should take it is a list of float tuples
13:14:39 <latro`a> if it's an actual list you can do better than I just said: sum $ zipWith (\x i -> x + f i) xs [0..n]
13:14:52 <obiwahn> f is a function that takes the value of 1 in one instance and 0 otherwise
13:15:47 <EvanR> Reaga: it isnt
13:16:22 <hpaste> roconnor pasted ‚Äúfloodfill‚Äù at http://hpaste.org/73137
13:16:36 <n-dolio> obiwahn: f(0) = p[0] + f(0)?
13:16:36 <Reaga> oh, i heard it was
13:16:37 <Reaga> thats all.
13:16:53 <roconnor> frerich_: this is what I wrote in 2007 FWIW: http://hpaste.org/73137
13:17:09 * hackagebot ad 3.0.1 - Automatic Differentiation (EdwardKmett)
13:17:09 <obiwahn> p[i] * f(i)
13:17:11 * hackagebot lens 2.2 - Lenses, Folds and Traversals (EdwardKmett)
13:17:47 <frerich_> roconnor: Hmm, What is RNAMonad? I suppose it automagically passes the result of one 'fill' to the next?
13:17:50 <statusfailed> Where's the "liftA2" function (A as in Arrow) as defined here: http://www.haskell.org/haskellwiki/Arrow_tutorial ?
13:17:54 <statusfailed> Has it been renamed?
13:18:05 <latro`a> statusfailed, that's in Control.Applicative as I recall
13:18:10 <n-dolio> That doesn't really change my question.
13:18:12 <MostAwesomeDude> @hoogle liftA2
13:18:13 <lambdabot> Control.Applicative liftA2 :: Applicative f => (a -> b -> c) -> f a -> f b -> f c
13:18:16 <n-dolio> f(0) = p[0] * f(0)?
13:18:30 <roconnor> type RNAMonad a = forall s. ReaderT (RNAStateST s) (ST s) a
13:18:37 <obiwahn> uhm better vecMultSca (selectitem [list] i) (f i)
13:19:02 <statusfailed> oh, Arrow is Applicative?
13:19:15 <roconnor> frerich_: it is just a souped up state monad
13:19:31 <obiwahn> hope that describes a bit what i want ...
13:19:31 <latro`a> statusfailed, they define liftA2 for arrows on that page
13:19:47 <statusfailed> latro`a: Oh... I thought it was just for demonstrating how it worked in the library
13:19:50 <statusfailed> haha
13:19:59 <latro`a> I'm not sure if it's in the library, hoogle doesn't seem to find it
13:20:04 <geekosaur> hrm.  if cabal-dev only depends on base and Cabal, why does cabal install cabal-dev think it wants to reinstall a bunch of stuff and "probably break ... haskell-platform-2012.2.0.0 ..."?
13:20:19 <statusfailed> Yeah, I hoogled the type signature but got nothing
13:21:07 <statusfailed> It seems odd that it's not in Control.Arrow...
13:21:33 <EvanR> Reaga: besides the obvious association list, check out ixset
13:21:36 <latro`a> not every little clever function that applies to all arrows is gonna be there, but I do see your point
13:22:14 <hpaste> roconnor annotated ‚Äúfloodfill‚Äù with ‚Äúfloodfill (annotation)‚Äù at http://hpaste.org/73137#a73138
13:22:34 <statusfailed> latro`a: That's dangerously close to saying liftM2 shouldn't be in Control.Monad, right? :P
13:22:46 <latro`a> "I do see your point" :p
13:22:52 <statusfailed> ":P" :P
13:22:52 <EvanR> ive seen people say liftM2 shouldnt exist
13:22:57 <EvanR> er, or that was liftA2
13:23:09 <statusfailed> as in the applicative one? :D
13:23:14 <EvanR> :t liftA2
13:23:16 <lambdabot> forall a b c (f :: * -> *). (Applicative f) => (a -> b -> c) -> f a -> f b -> f c
13:23:32 <latro`a> neither of them really make *that* much sense
13:23:42 <statusfailed> liftM2 makes sense!
13:24:04 <latro`a> it's another one of those "we can only go up so high because type system" things
13:24:20 <statusfailed> How do you mean?
13:24:26 * roconnor uses liftM2/liftA2 for binary operators
13:24:27 <EvanR> :t liftA3
13:24:28 <lambdabot> forall a b c d (f :: * -> *). (Applicative f) => (a -> b -> c -> d) -> f a -> f b -> f c -> f d
13:24:31 <latro`a> it'd be elegant to have an arbitrary arity lift
13:24:33 <EvanR> :t liftA4
13:24:35 <lambdabot> Not in scope: `liftA4'
13:24:37 <statusfailed> latro`a: sequence?
13:24:38 <latro`a> but you can only go so high
13:24:42 <roconnor> latro`a: we use <*> for arbitrary lifts
13:24:45 <latro`a> yes
13:24:55 <obiwahn> when i fold a list is there a way to easily access the number of the current element?
13:24:57 <latro`a> that's why I was saying liftA was a little silly, because <*> does that already
13:25:01 <EvanR> statusfailed: a list can only have elements all of the same type
13:25:13 <statusfailed> oh, true
13:25:15 <EvanR> obiwahn: not with the normal fold
13:25:18 <latro`a> obiwahn--you can store the index in the accumulator
13:25:25 <latro`a> if you're doing a foldl
13:25:32 <roconnor> latro`a: in those rare cases where you want to eta-contract a lifted term, liftMn is nice.
13:25:39 <obiwahn> how would i do that?
13:25:54 <obiwahn> or is there a special version of flodl that i can use?
13:26:10 <EvanR> indexed traversal
13:26:18 <roconnor> obiwahn: use a schwartizan tranform if you want to do that
13:26:19 <latro`a> if you were doing foldl f init xs, you can do foldl (\acc x -> (1+init,f acc x)) (0,init) xs
13:26:26 <latro`a> erm
13:26:29 <latro`a> bah
13:26:32 <latro`a> lemme fix that
13:26:36 <parcs`> :t zip [0..]
13:26:37 <lambdabot> forall t b. (Num t, Enum t) => [b] -> [(t, b)]
13:26:39 <roconnor> *transform
13:27:09 * hackagebot snaplet-fay 0.1.0.0 - Fay integration for Snap with automatic (re)compilation during development (AdamBergmark)
13:27:11 * hackagebot snaplet-postgresql-simple 0.2 - postgresql-simple snaplet for the Snap Framework (DougBeardsley)
13:27:13 <latro`a> foldl (\(n,acc) x -> (1+n,f acc x)) (0,init) xs
13:27:21 <latro`a> works, but there are again better ways to do it
13:27:34 <adnam> free ads \o/
13:27:37 <EvanR> postgresq-simple sweet jesus
13:27:57 * roconnor is tired of paying for ads
13:28:04 <micahjohnston> does anyone know why Parsec would be complaining about this?
13:28:04 <micahjohnston>     No instance for (Stream s m Char)
13:28:05 <micahjohnston>       arising from a use of `noneOf' at Parser.hs:4:14-31
13:28:20 <identity> micahjohnston: Very hard to say without any context at all.
13:28:21 <identity> hpaste.org
13:28:40 <micahjohnston> it happens when I use any Parsec functions
13:28:59 <micahjohnston> so I'm trying to load a module with only this line
13:29:00 <micahjohnston> name = many1 (noneOf " \n\t{}()")
13:30:43 <micahjohnston> identity: there isn't really more context to give than that, because the most trivial of things won't compile
13:30:46 <micahjohnston> :/
13:31:01 <identity> micahjohnston: what are you importing?
13:31:16 <micahjohnston> Text.Parsec
13:31:50 <identity> micahjohnston: Seems you need to explicitly specify the type signature
13:32:01 <identity> try: name :: Parser String .. etc.
13:32:07 <micahjohnston> ok
13:32:23 <micahjohnston> Parser seems not to be in scope
13:33:27 <identity> Hmm. I'm not too familiar with Parsec, but when I import "Text.ParserCombinators.Parsec", Parser is in scope, while it isn't with Text.Parsec.
13:33:55 <micahjohnston> ok, that worked
13:33:55 <micahjohnston> thanks
13:33:56 <identity> I'm not entirely sure which one is the "right one" -- IIRC the former is the backwards compatible layer or something like that.
13:34:07 <identity> (For the old Parsec, that is)
13:34:12 <micahjohnston> yeah, that sounds right
13:34:21 <micahjohnston> wish I knew the Right way to use the new Parsec
13:34:47 <kgzm> I've a query. I know this is invalid 'data Line = [[Int,Int],[Int,Int]' is it clear what I intend and is it possible to do something like that without using tuples? I started with tuples then I realized that it's much better if I can do list comprehensions on these types.
13:35:23 <latro`a> you want two lists of two ints?
13:35:29 <latro`a> "lists"*
13:35:35 <identity> micahjohnston: Maybe someone else in here can shed some light on that. Last time I used Parsec, I just used T.PC.Parsec
13:35:45 <EvanR> ([(Int,Int)],[(Int,Int)])
13:35:46 <micahjohnston> identity: ok, thanks for your help
13:35:49 <Cale> kgzm: [[Int]] ?
13:35:52 <identity> micahjohnston: No problem.
13:35:56 <kgzm> latro: Yeah.
13:36:11 <Cale> kgzm: Lists don't constrain their length at compile time.
13:36:16 <latro`a> EvanR's idea works; using a constructor is a bit cleaner
13:36:27 <latro`a> data Line = Line [(Int,Int)] [(Int,Int)]
13:36:39 <EvanR> data Pair a = Pair a a
13:36:48 <EvanR> Line [Pair Int] [Pair Int]
13:36:49 <latro`a> that helps too
13:36:52 <kgzm> I used tuples initially but they became unwiedly quickly.
13:37:15 <EvanR> Pair (Pair Int) ;)
13:37:32 <EvanR> Pair [Pair Int] ;)
13:37:37 <kgzm> I'm defining some geometric functions for operating on rectangles, lines and points.
13:37:39 <Cale> I think possibly what kgzm means is that he wants a type which only contains lists matching the pattern [[x,y],[z,w]] where x,y,z,w :: Int
13:37:53 <kgzm> Cale: Exactly.
13:37:55 <Cale> but yeah, that's not possible
13:38:01 <Cale> Not with lists
13:38:11 <Cale> You want something like
13:38:24 <Cale> data Point = P Int Int
13:38:32 <Cale> data Rect = R Point Point
13:38:38 <kgzm> I think I'll just go without it. I started with tuples but then I found it unwiedly to switch axes.
13:38:52 <Cale> Use proper datatypes
13:39:07 <Cale> rather than tuples
13:39:51 <EvanR> you can do anything with one infinite tape of mutable cells containing values of type X ;)
13:40:11 <latro`a> ...lol
13:40:14 <EvanR> you dont even need multiple tapes!
13:40:31 <latro`a> you can also remove "of type X"
13:40:32 <latro`a> :p
13:40:40 <latro`a> we don't need no types in our turing machine
13:40:49 <EvanR> well you have to write something there
13:41:02 <EvanR> unless its tapes all the way down
13:41:03 <latro`a> doesn't much matter what it is though
13:41:08 <micahjohnston> you don't have to write anything
13:41:10 <EvanR> thats why i put X
13:41:12 <micahjohnston> encode state in the position of the tape
13:41:12 <latro`a> it could just be another tape
13:41:26 <kgzm> I mean as the actual container. Doing something like data Line = Line Point Point is that I'm not really clear on an easy way to flip axes without specifying it specifically, it's basically the same problem with using a tuple. I think a point as a list of coordinates is probaly the way to go, and building up from there to make lists of points. It doesn't feel that safe though.
13:41:29 <latro`a> tapeception
13:41:33 <EvanR> lol
13:41:45 <micahjohnston> use G√∂del encoding with the position of the tape
13:41:48 <kgzm> typesafe that is.
13:41:55 <EvanR> Tape (Tape (Tape (Tape ...
13:41:59 <latro`a> lists are really not the way to go at all if you know what you meant
13:42:01 <latro`a> erm
13:42:02 <latro`a> know the size
13:42:12 <latro`a> flipping axes can be done with just a helper function if need be
13:45:03 <osa1> so System.INotify's event handler needs functions with type Event -> IO () but I want to use StateT because I need to handle some state while handling events, how can I do that?
13:45:27 <kgzm> Hm. I was thinking that I don't want to have to do deep pattern matching to get to the internals, for example if a rectangle is four points. Would I not need a very specialized pattern to get at the innards of the points? I mean if data Point = Point Int Int and data Rect = Rect Point Point Point Point ..?
13:47:06 <micahjohnston> kgzm: you only need two Points for a Rect, right?
13:47:50 <kgzm> Well, yes.
13:47:52 <parcs`> osa1: handleEvent (\event -> evalStateT (handler event) initial_state)
13:47:58 <kgzm> Can I show you what I have now?
13:48:02 <EvanR> osa1: also, IO has state stuff
13:48:20 <osa1> parcs`: doesn't that create a new state every time event handler called?
13:48:43 <EvanR> kgzm: you can make functions to do the particular pattern matches you want, if you just want field accessors, use a record type
13:48:53 <osa1> EvanR: do you mean IORef ?
13:48:54 <kgzm> https://gist.github.com/0f57361c3093c619beb1
13:48:59 <latro`a> kgzm: starting to sound like you want lenses, heh
13:49:01 <EvanR> osa1: yeah or MVar or whatever
13:49:04 <kgzm> It's really messy.
13:49:07 <kgzm> latro: Lenses?
13:49:10 <Nereid> osa1: if you need to do IO stuff inside a StateT IO monad, you use liftIO
13:49:21 <latro`a> you can look it up
13:49:28 <osa1> Nereid: yeah I'm not asking that
13:49:29 <latro`a> it's a pretty rich subject
13:49:31 <Nereid> ok
13:49:38 <Nereid> or you can use stuff like IORef/MVar
13:50:01 <EvanR> osa1: i seem to be using ReaderT with IO a lot for this
13:50:15 <EvanR> to have access to the IORefs
13:51:20 <kgzm> latro: I'll check it out. I don't want to complicated this too much. I just started writing a functiont o slice a rectangle by a line and realized that there's a general solution that would be easier to write if I can flip axes easily enough.
13:51:30 <kgzm> This is my first outting with Haskell.
13:51:35 <latro`a> ah
13:54:50 <kgzm> latro: I'd appreciate it if you'd have a gander at what I've got so far.
13:55:16 <latro`a> sure
13:55:27 <kgzm> latro: https://gist.github.com/0f57361c3093c619beb1
13:57:11 <adnam> is it new that hackage turns /x/ into italics? hadn't noticed all the malformed urls before
13:58:11 <geekosaur> isn't that normal haddock behavior?
13:58:42 <adnam> couldn't tell you :) how do you escape it?
13:58:56 <t7> more interesting topic: i just sold my first thing on ebay
13:59:01 <t7> ordered collection online
13:59:12 <t7> used paypal (yuck) but it worked nice
14:00:26 <monochrom> use \/ for / in haddock
14:00:49 <t7> is hackage a package on hackage?
14:00:58 <monochrom> /x/ being italics has been in haddock since the dawn of time
14:01:57 <monochrom> use <http://google.com/> for url in haddock
14:02:27 <adnam> I see, thanks
14:03:09 <EvanR> paypal is so gross
14:03:09 <latro`a> kgzm: I'm writing some fairly minor comments
14:03:18 <kgzm> latro: Thanks.
14:03:23 <latro`a> but don't really have enough context to make an assessment on your type choices
14:04:13 <monochrom> you probably have haddock manual in your hard disk. prefix/share/doc/ghc/html/haddock/index.html
14:04:17 <EvanR> a positioned rectangle type which can be divided vertically or horizontally...
14:04:36 <latro`a> http://pastebin.com/iHNQN247
14:04:38 <mauke> The paste iHNQN247 has been copied to http://hpaste.org/73139
14:04:43 <t7> whoops i thought this was haskell blah, excuse me
14:05:15 <kgzm> latro: Well, there's not really much context to be had I'm trying to solve a bunch of simple geometric problems for a random map generator based on rectangles of unit sizes expanding and slicing the rectangles they overlap and adding the resultant rectangles back to the pool.
14:05:20 <kgzm> Or what EvenR said.
14:05:55 <latro`a> so when you do the division you get two new rectangles?
14:06:41 <EvanR> so you start with a grid of unit rectangles
14:06:46 <latro`a> if so, it sounds like it'd be easiest to do the division one way without changing orientation, and then do the other one by changing orientation, calling the old cut, and then changing back
14:06:47 <EvanR> and you subdivide them into smaller pieces
14:06:49 <latro`a> but I may be misunderstanding
14:07:10 * hackagebot monadIO 0.10.1.3 - Overloading of concurrency variables (TrevorElliott)
14:07:54 <kgzm> I start with a grid of unit rectangles, then I grow them and use their edges to cut their neighbors into small pieces or remove the neighbors that are completely encompassed.
14:08:28 <EvanR> so combining unit rectangles into bigger structures
14:08:52 <kgzm> latro: THat's what I was thinking but it's not clear to me how to do that. I'm still thinking imperatively.
14:09:16 <kgzm> And I don't know the best way to use Haskell's type system for this.
14:09:24 <kgzm> EvarR: Yeah.
14:09:47 <EvanR> id start by modelling the grid itself
14:10:03 <EvanR> since these rectangles cant exist independently in a sensible way
14:12:10 * hackagebot orc 1.2.1.2 - Orchestration-style co-ordination EDSL (TrevorElliott)
14:12:38 <veldskoen> good night
14:13:51 <kgzm> EvanR: Hrm, I wasn't actually plannnig to make a grid. I was just going to generate a list of rectangles then operate on it. Since they're positioned within boundaries that are known.
14:19:58 <kgzm> Ah, I think I'm onto something. I might've been complicating this too much. Thanks for your help and comments, you all.
14:21:40 <zzing_> Is there any nice way of doing multiline strings? I want to be able to start the string, produce the text as if it were a dump from a text file and ending it.
14:22:16 <latro`a> kgzm: have you gotten any chance to play with monads?
14:22:37 <latro`a> if not, ignore me, if so, you should probably check out MonadRandom if you're going to be doing much randomization
14:23:03 <kgzm> I've played with the IO monad a bit but I haven't wrapped my head all the way around them yet.
14:23:34 <latro`a> basic use of MonadRandom instances isn't much different from basic use of the IO monad
14:23:44 <latro`a> (indeed one of the MonadRandom instances *IS* the IO monad)
14:23:55 <kgzm> System.Random seems pretty good though. What's the advantage of MonadRandom?
14:24:23 <latro`a> you can avoid having to pass around generators, basically
14:24:46 <latro`a> it's in Control.Monad.Random (you'll need to install the package with cabal, but that's not hard)
14:24:47 <kgzm> Is it still deterministic? Do I have to do anything special to my code that uses random values?
14:24:51 <nobdraisentone> How can I define such class, that user could create instance of it's element and then tests is it a valid one? In other words, how can I make something workable from that - http://hpaste.org/73140 ?
14:24:53 <latro`a> it can be deterministic or not
14:25:10 <latro`a> the usual way is to get a seed from the IO monad and then thread it through deterministically
14:25:39 <latro`a> that said, you wouldn't have to do much to your code but it would change some things here and there
14:25:44 <latro`a> for one thing you'd never take a generator as an argument
14:25:58 <latro`a> you'd take in the random number, and then you'd do something along the lines of
14:26:03 <latro`a> n <- getRandom
14:26:09 <latro`a> somefunction n
14:26:18 <kgzm> Ah. I was planning to make a list of random numbers with System.Random and then pick from that and use a counter in my list operations to pick a value from it.
14:26:45 <latro`a> you mean with randomRs?
14:27:00 <latro`a> because that works too, but all the splitting would probably get cumbersome after a while
14:28:00 <EvanR_> kgzm: a counter to sequentially pick from a list?
14:28:09 <EvanR_> sound borken
14:28:27 <kgzm> Hm. You're probably right. How about an array?
14:28:40 <Reaga> Man, haskell rocks :D
14:28:48 <EvanR_> no wa
14:28:59 <latro`a> I wouldn't use an array either :p
14:29:09 <EvanR_> kgzm: to sequentially pull from a list, you just pop
14:29:10 <latro`a> I mean, you just want a "new RNG" at certain stages, right
14:29:23 <latro`a> and yeah, popping is basically the splitting I was talking about
14:29:29 <latro`a> avoids indexing, but is still kinda kludgy
14:29:36 <EvanR_> you can hide it
14:29:39 <latro`a> true
14:29:40 <latro`a> but
14:29:43 <latro`a> MonadRandom already does
14:29:44 <latro`a> so why bother
14:29:44 <latro`a> :p
14:29:48 <EvanR_> you cant rng split it throuhg, if you need to do that
14:30:09 <EvanR_> and you wouldnt want to split every time to get a new random number
14:30:14 <EvanR_> thats counterproductive
14:30:15 <latro`a> I meant splitting the list
14:30:18 <kgzm> And it will be the same 'random number' everytime?
14:30:29 <latro`a> that depends on how you set it up
14:30:35 <EvanR_> no, if you have a list of random numbers, its probably a different one each time
14:30:39 <zhulikas> kgzm, why would you pick a random number if you can generate a random number instead?
14:30:42 <latro`a> EvanR_, no
14:30:45 <latro`a> you can use mkStdGen
14:30:47 <latro`a> with a hardcoded seed
14:31:00 <zhulikas> @hoogle randomRIO
14:31:01 <lambdabot> System.Random randomRIO :: Random a => (a, a) -> IO a
14:31:04 <EvanR_> i figured he asked if it would be 4,4,4,4,4,4,4,4,4,4
14:31:08 <latro`a> oh
14:31:17 <zhulikas> > randomRIO (1, 10)
14:31:18 <latro`a> no, I don't think that's what he meant, but it might've been
14:31:18 <lambdabot>   <IO Integer>
14:31:18 <EvanR_> i guess obviously that wouldnt make sense
14:31:23 <zhulikas> O.o
14:31:27 <kgzm> No, I mean will it be deterministic.
14:31:29 <hpaste> da-x pasted ‚ÄúDatabase.PostgreSQL.Simple broken..‚Äù at http://hpaste.org/73142
14:31:34 <EvanR_> depends on how you seed it
14:31:34 <latro`a> you can make it deterministic, yes
14:31:39 <latro`a> it depends on how the seeding is done
14:32:08 <zzing_> Does anyone have any examples of major programming bugs that have occured because of lack of type safety?
14:32:10 <kgzm> Currently I have mkStdGen and I'm generating a list of values.
14:32:24 <latro`a> most of the time you want to get one seed from the IO monad and then thread the generator through afterwards
14:32:25 <EvanR_> zzing_: null pointer exception
14:32:33 <zhulikas> :D
14:32:37 <zhulikas> nice one
14:32:43 <zhulikas> and indeed a fine example
14:32:50 <koala_man> zzing_: you mean specific examples, or classes of errors?
14:32:58 <kgzm> Doesn't the generator have to carry state for that?
14:32:59 <latro`a> if you always want the same sequence, you pick an integer blindly and then thread the generator through afterwards
14:33:05 <latro`a> hm?
14:33:07 <EvanR_> kgzm: no
14:33:13 <da-x> (only followed the docs: http://hackage.haskell.org/packages/archive/postgresql-simple/0.2.3.0/doc/html/Database-PostgreSQL-Simple.html )
14:33:15 <latro`a> the generator *is* the RNG state, if that's what you meant
14:33:28 <zzing_> koala_man: I mean specific examples, preferably documented that can be read. i.e. can convince a perl programmer that type safety is worth it
14:33:33 <EvanR_> kgzm: you made an infinite list of random numbers? that doesnt need a generator
14:33:48 <latro`a> it does at first, but you don't have to thread it through if you do that
14:34:03 <zzing_> EvanR_: I am talking about the kind of things articles describe the failure of something - the bigger the better
14:34:05 <kgzm> EvarR It's not infinite. I mean I was jsut planning to generate a list in advance. It doesn't need to be infinite.
14:34:06 <EvanR_> instead you have to thread the tail of the list through
14:34:16 <EvanR_> kgzm: ... then youll run out
14:34:31 <kanedank`> hey, can someone help me figure out this sample code from real world haskell?: https://gist.github.com/3344241
14:34:40 <kanedank`> I don't get what the 'otherwise' keyword means
14:34:44 <latro`a> otherwise = True
14:34:52 <latro`a> it's just a synonym used to make guard notation look pretty
14:34:58 <kgzm> EvanR: I was planning to just make more.
14:35:06 <kanedank`> ah, okay. Thanks!
14:35:16 <koala_man> zzing_: there was that military ship that got stuck for hours after dividing by zero, but that's a type error haskell doesn't prevent
14:36:16 <EvanR_> kgzm: ... thats a pretty complex way to accomplish that
14:36:32 <koala_man> nearly all bugs are type safety bugs, if you take type safety far enough
14:36:32 <EvanR_> koala_man: that was a blue screen of death
14:36:58 <EvanR_> otherwise is not a keyword
14:37:04 <zhulikas> I want to live in a bug-free world
14:37:08 * zhulikas hates insects
14:37:08 <kgzm> I was just going to put a list of random numbers in at the same time as I took user input.
14:37:23 <kgzm> 'random' numbers.
14:37:24 <EvanR_> kgzm: and if you run out?
14:37:26 <zzing_> koala_man: I am mainly interested in good examples of it
14:37:28 <koala_man> "a crew member entered a zero into a database field causing a divide by zero error in the ship's Remote Data Base Manager which brought down all the machines on the network, causing the ship's propulsion system to fail."
14:37:52 <EvanR_> koala_man: interesting, maybe this ship problem happens a lot
14:38:03 <kgzm> EvanR: then I reuse.
14:38:12 <EvanR_> kgzm: repeat?
14:38:30 <EvanR_> > cycle [6,2,7,4,2,3,4,5]
14:38:32 <lambdabot>   [6,2,7,4,2,3,4,5,6,2,7,4,2,3,4,5,6,2,7,4,2,3,4,5,6,2,7,4,2,3,4,5,6,2,7,4,2,...
14:38:51 <EvanR_> this is just what i was saying, only not explicitly cyclic
14:38:54 <zhulikas> looks random to me
14:38:54 <zhulikas> :D
14:39:34 <EvanR_> kgzm: generally you want to avoid reseeding your generator that often, the point of a rng is to begin and never be reset
14:39:35 <kgzm> Well, they're really big numbers. And when I get them I apply modulo to constrain them to a range so I was thinking it'd be random enough.
14:39:50 <EvanR_> dont use modulo to constrain them to a range
14:39:56 <EvanR_> use randomR
14:40:11 <MagneticDuck> hey, I have a question
14:40:23 <zhulikas> > sequence $ map ($(1,10)) $ replicate 10 randomRIO
14:40:25 <lambdabot>   <IO [Integer]>
14:40:29 <zhulikas> awww man
14:40:30 <zhulikas> what's wrong?
14:40:40 <EvanR_> lambdabot cant do IO
14:40:42 <zhulikas> second time it happened to me today
14:40:45 <zhulikas> oh, ok
14:41:13 <zhulikas> basically it's a IO [Integer] of random numbers
14:41:56 <EvanR_> :t forever
14:41:57 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b
14:42:09 <EvanR_> :t replicateM
14:42:10 <lambdabot> forall (m :: * -> *) a. (Monad m) => Int -> m a -> m [a]
14:42:14 * hackagebot tamarin-prover-utils 0.8.1.0 - Utility library for the tamarin prover. (SimonMeier)
14:42:15 <kgzm> Hmm.
14:42:15 <sipa> MagneticDuck: any reason not to ask it?
14:42:21 <zhulikas> oh, right
14:42:23 <zhulikas> replicateM
14:42:25 <EvanR_> whats m a -> m [a] ?
14:42:29 <zhulikas> sequence
14:42:33 <EvanR_> :t sequence
14:42:35 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
14:42:38 <EvanR_> wrong
14:42:45 <zhulikas> :t sequence . replicate
14:42:46 <lambdabot>     Couldn't match expected type `[m a]'
14:42:46 <lambdabot>            against inferred type `a1 -> [a1]'
14:42:46 <lambdabot>     Probable cause: `replicate' is applied to too few arguments
14:42:53 <EvanR_> ah
14:42:57 <zhulikas> I thought replicateM is sequence . replicate
14:42:59 <sipa> > fmap replicate
14:43:01 <lambdabot>   Overlapping instances for GHC.Show.Show
14:43:01 <lambdabot>                              (f GHC...
14:43:02 <EvanR_> :t sequence . repeat
14:43:03 <lambdabot> forall (m :: * -> *) a. (Monad m) => m a -> m [a]
14:43:06 <sipa> :t fmap replicate
14:43:08 <lambdabot> forall a (f :: * -> *). (Functor f) => f Int -> f (a -> [a])
14:43:35 <EvanR_> i was looking for sequence . repeat
14:43:37 <ion> @type fmap pure
14:43:38 <lambdabot> forall a (f :: * -> *) (f1 :: * -> *). (Applicative f, Functor f1) => f1 a -> f1 (f a)
14:43:45 <ion> @type fmap (:[])
14:43:46 <lambdabot> forall a (f :: * -> *). (Functor f) => f a -> f [a]
14:45:00 <sipa> :t fmap repeat
14:45:02 <lambdabot> forall a (f :: * -> *). (Functor f) => f a -> f [a]
14:45:21 <EvanR_> >_>
14:45:25 <EvanR_> which fmap is this, list?
14:45:31 <sipa> any fmap
14:45:42 <EvanR_> :t repeat
14:45:43 <sipa> if f were $
14:45:43 <lambdabot> forall a. a -> [a]
14:45:58 <EvanR_> head exploding
14:46:04 <sipa> if f were [], fmap list :: [a] -> [[a]]
14:46:38 <EvanR_> if f were >> ?
14:47:16 <sipa> no f is a type, not a value
14:47:16 * hackagebot tamarin-prover-term 0.8.1.0 - Term manipulation library for the tamarin prover. (SimonMeier)
14:47:18 * hackagebot tamarin-prover 0.8.1.0 - The Tamarin prover for security protocol analysis. (SimonMeier)
14:47:31 <EvanR_> f were a monad
14:47:43 <ion> Then‚Ä¶ it would be a monad. :-P
14:47:54 <sipa> "monad" is not a type either
14:47:57 <EvanR_> so fmap is (sequence .)
14:48:02 <singpoly1a> If I want a where clause that works across multiple pattern matches... I can't do that, right?  I need a new toplevel?
14:48:08 <ion> No, fmap is
14:48:09 <ion> @type fmap
14:48:11 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
14:48:44 <shachaf> singpoly1a: Well, it doesn't need to be top-level. But it needs to be higher-level than those pattern matches.
14:48:47 <EvanR_> fmap repeat == sequence . repeat for monads
14:48:55 <singpoly1a> shachaf: right. ox
14:48:56 <EvanR_> so fmap == (sequence .) ;)
14:49:01 <EvanR_> for monads
14:49:01 <singpoly1a> s/ox/ok
14:49:03 <zhulikas> singpoly1a, you can define it outside your function
14:49:07 <zhulikas> as in top level function
14:49:15 <shachaf> E.g. foo n = foo' n where { blah = f n; foo' ... = ... }
14:49:17 <EvanR_> divide both sides by repeat
14:49:29 <shachaf> Or foo n = case n of ... -> ... where blah = f n
14:49:29 <ion> > fmap repeat (Just 42)
14:49:30 <lambdabot>   Just [42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,...
14:49:34 <ion> > (sequence . repeat) (Just 42)
14:49:36 <lambdabot>   *Exception: stack overflow
14:53:17 <EvanR_> o_O
15:00:50 <ReinH> ion: laziness
15:02:00 <ReinH> ion: sequence in Prelude uses foldr
15:02:19 <tgeeky> @src sequence
15:02:20 <lambdabot> sequence []     = return []
15:02:20 <lambdabot> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs)
15:02:20 <lambdabot> -- OR: sequence = foldr (liftM2 (:)) (return [])
15:03:17 <ReinH> whereas fmap is recursive and thus lazy
15:03:29 <zhulikas> sequence doesn't look tail recursive
15:04:24 <ReinH> I'm not sure if we should trust lambdabot
15:04:33 <ReinH> http://hackage.haskell.org/packages/archive/base/latest/doc/html/src/Control-Monad.html#sequence
15:07:41 <Twey> ReinH: lambdabot's definition comes from the standard, which is used to specify behaviour.  Implementations may be more complicated for performance reasons.
15:08:11 <ReinH> Twey: iirc lambdabot's been messed with a bit
15:08:13 <ReinH> :t (.)
15:08:15 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
15:08:28 <Twey> ReinH: But, in that case, k = liftM2 (:)
15:08:41 <ReinH> Twey: yes, but the point is that foldr can't handle infinite lists
15:08:42 <Twey> ReinH: Yes, but that's different and unrelated.
15:08:55 <latro`a> uh
15:09:02 <latro`a> "foldr can't handle infinite lists" uh...
15:09:11 <Twey> Yeah, foldr can quite easily handle infinite lists
15:09:21 <Twey> So long as the provided function is productive
15:09:28 <latro`a> if the function is non-strict and you hit one of its non-strict cases
15:09:36 <latro`a> or if you lazily use the result
15:09:39 <latro`a> (for example map is a foldr)
15:09:47 <ReinH> right, sorry: if it's evaluated
15:09:49 <typoclass> anyway, _is_ sequence tail-recursive, as quoted above? it looks like it to me, but i have no clue
15:09:52 <latro`a> even if it isn't
15:09:53 <Twey> > take 10 $ foldr (:) [] [1 ..]
15:09:55 <lambdabot>   [1,2,3,4,5,6,7,8,9,10]
15:10:09 <ReinH> I'm saying it canb't handle lazy lists if it's evaluated
15:10:17 <ReinH> > foldr (:) [] [1..]
15:10:18 <lambdabot>   [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28...
15:10:20 <Twey> ReinH: But you're wrong
15:10:22 <ReinH> apparently
15:10:39 <ReinH> foldr (+) 0 [1..]
15:10:42 <ReinH> > foldr (+) 0 [1..]
15:10:44 <lambdabot>   *Exception: stack overflow
15:10:49 <Twey> That won't do anything because it needs to get to the end
15:11:02 <Twey> Like I said, so long as the function is productive, it's fine.
15:11:05 <ReinH> ok
15:11:35 <ReinH> but sequence isn't productive
15:11:37 <Twey> typoclass: No, sequence isn't tail-recursive
15:12:23 <latro`a> > foldr (const 1) 0 [1..]
15:12:23 <latro`a> ermm..derp
15:12:23 <latro`a> > foldr const 0 [1..]
15:12:23 <latro`a> ....?
15:12:23 <latro`a> that should return 1
15:12:23 <latro`a> why does it not
15:12:23 <latro`a> ghci does
15:12:24 <lambdabot>   1
15:12:25 <lambdabot>   can't find file: L.hs
15:12:41 <Twey> latro`a: Because you just lagged hugely.
15:12:45 <Twey> latro`a: There's your 1 ‚ò∫
15:12:48 <latro`a> oh
15:12:52 <latro`a> yay apparently
15:12:59 <sipa> hehe
15:13:01 <nexx> isn't this an important reason to use foldr instead of foldl?
15:13:21 <latro`a> sometimes, yeah
15:13:29 <typoclass> twey: hm. do you have any links about how to determine that?
15:14:03 <Twey> typoclass: You can just look at it
15:14:20 <applicative> @src foldr
15:14:21 <lambdabot> foldr f z []     = z
15:14:21 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
15:14:25 <applicative> @src foldl
15:14:26 <lambdabot> foldl f z []     = z
15:14:26 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
15:14:51 <Twey> typoclass: Remember that all of Haskell is lazy.  If it produces something that you can get out without evaluating the infinite thunk, it's productive.
15:14:52 <latro`a> foldl will always call itself if the list is nonempty, foldr may or may not depending on the semantics of f
15:14:54 <applicative> foldl is tail recursive, but is only desirable as foldl'
15:15:36 <latro`a> eh
15:15:37 <latro`a> ish
15:15:48 <latro`a> that depends on other semantics of f
15:16:03 <latro`a> foldl can do stuff to finite lists that have undefined in them, for example
15:16:13 <latro`a> foldl' can't
15:16:16 <sipa> hehe
15:16:17 <latro`a> but those usages are very rare
15:16:27 <zhulikas> @src foldl'
15:16:27 <lambdabot> foldl' f a []     = a
15:16:28 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
15:16:55 <applicative> foldl' is desirable when you are accumulating something strictly, e.g. adding to a seed
15:16:58 <zhulikas> :t seq
15:16:59 <ReinH> foldl' is a strict foldl
15:16:59 <lambdabot> forall a t. a -> t -> t
15:17:27 * zhulikas finally gets how seq needs to be used
15:17:41 <zhulikas> so I force evaluation of it and then use it later in algorithm
15:17:48 <zhulikas> because according to type it looks like it disappears
15:17:59 <applicative> otherewise, typoclass, you tend to want foldr
15:18:05 <zhulikas> :t par
15:18:06 <lambdabot> forall a b. a -> b -> b
15:18:12 <zhulikas> same goes here I believe
15:18:18 <zhulikas> right?
15:18:46 <typoclass> twey: you mean, it's not tail-recursive because the (:) operation needs both operands? i.e. before (:) can proceed, we need the 2nd operand (produced by the recursive call)? that doesn't sound right to me, i thought (:) was lazy ... sorry if i'm being dense here :-/
15:18:49 <nexx> So only in rare cases one want to use foldl?
15:19:02 <Twey> typoclass: Tail-recursion isn't that important in Haskell because of laziness
15:19:07 <applicative> nexx, that is the received wisdom
15:19:20 <danil> zhulikas: (a `seq` b), when evaluated, evaluates a and returns the result of evaluating b
15:19:20 <zhulikas> :t par 1 (par 1 (1, 1))
15:19:21 <lambdabot> forall t t1. (Num t, Num t1) => (t, t1)
15:19:52 <zhulikas> oh, except instead of 1s there needs to be some value/function
15:19:53 <ReinH> Twey: I'm not quite sure what you mean by "productive", but (+) is strict in both of its args, which is why foldr (+) doesn't work, right?
15:19:57 <applicative> tail recursion is the bees knees when you are dealing with e.g. the usual strict operations on numbers.
15:20:09 <Eduard_Munteanu> ReinH: yeah
15:20:29 <Eduard_Munteanu> ReinH: you could use it if you had lazy numbers
15:20:35 <zhulikas> danil, "returns the result of evaluating b" <- I don't get that
15:20:54 <Eduard_Munteanu> ReinH: e.g. (+) on Peanos
15:20:58 <ReinH> right
15:21:06 <ReinH> or church
15:21:23 <danil> zhulikas: so, if you do "case (a `seq` b) of ...", this is the same as "case b of ..." except a also gets forced (to WHNF)
15:21:34 <Twey> typoclass: Recursion in other languages is important because you can't get anything out until the whole operation has completed, so you end up with a huge value that overflows the stack.  However, because Haskell is lazy, you get two effects with regard to TCO: one, that if you're not careful you can build up a huge *thunk* even with a tail-recursive operation, and two, that it doesn't matter how big a value you build up so long as you're also consuming‚Ä¶
15:21:37 <Eduard_Munteanu> IDK how Church fits there.
15:21:38 <zhulikas> I get that
15:21:40 <Twey> ‚Ä¶ it as you go along
15:21:46 <Twey> s/Recursion/tail-recursion/
15:22:12 <typoclass> twey: hm, yeah ...
15:22:33 <ReinH> Eduard_Munteanu: church encoded numbers?
15:22:35 <Twey> typoclass: So, in practice, applying strictness and laziness in the right places is much more important than making things tail-recursive
15:22:40 <zhulikas> "case (a `par` b) of ... -> return a" <- can I expect here a to be calculated in parallel and then available for return?
15:23:12 <zhulikas> I think I just accidently understood parallelization O.o
15:23:22 * Twey laughs.
15:23:37 <ReinH> foldl' works because it reduces the inner expressions first, right?
15:23:39 <danil> zhulikas: (a `par` b), when evaluated, "sparks" a (puts it in a queue to be evaluated by threads without work to do) and evaluates b
15:23:43 <typoclass> zhulikas: ;-)
15:23:46 <Twey> zhulikas: Yes, probably
15:24:04 <Twey> ReinH: No, strict evaluation is still out-to-in
15:24:14 <danil> zhulikas: there's no guarantee that a will have been evaluated by the time you return it, but that's the hope
15:24:23 <ReinH> Twey: doesn't a `seq` b reduce a before b?
15:24:42 <ReinH> sorry reduce a and return b
15:25:01 <ReinH> @src foldl'
15:25:02 <lambdabot> foldl' f a []     = a
15:25:02 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
15:25:06 <hpaste> Mandarin pasted ‚ÄúMagical square transdigit validation‚Äù at http://hpaste.org/73143
15:25:09 <zhulikas> so... if it's not evaluated and returned, it just means that if current thread wants to evaluate the final result it has to wait for parallel threads to make an evaluation on a first?
15:25:09 <ReinH> so a' is reduced first, right?
15:25:34 <latro`a> yeah
15:25:37 <Mandarin> I'm having a trouble with typeclasses, see paste: http://hpaste.org/73143
15:25:47 <zhulikas> yeah to what?
15:25:58 <latro`a> @ ReinH
15:26:01 <ReinH> zhulikas: maybe just yeah in general :p
15:26:01 <zhulikas> ok:(
15:26:02 <latro`a> also
15:26:03 <Twey> ReinH: Yes?
15:26:05 <latro`a> Mandarin
15:26:07 <parcs`> ReinH: nope http://hackage.haskell.org/packages/archive/parallel/3.2.0.3/doc/html/Control-Parallel.html#v:pseq
15:26:09 <latro`a> at the top of your file
15:26:13 <Mandarin> latro`a: Yeah?
15:26:18 <latro`a> put {-# LANGUAGE NoMonomorphismRestriction #-}
15:26:20 <latro`a> erm
15:26:24 <ReinH> Twey: so f a x is reduced before foldl' f (f a x) xs, right?
15:26:25 <danil> zhulikas: if no thread has started evaluating the sparked computation yet, forcing it just makes you start evaluating it as normal
15:26:27 <latro`a> {#- and -#}
15:26:34 <Twey> ReinH: Yes
15:26:36 <Mandarin> Thanks!
15:26:39 <latro`a> I think I wrote it right, always forget which of the # and - comes first
15:26:45 <danil> zhulikas: if someone else has started but not finished I think you do wait for them though
15:26:48 <ReinH> Twey: so the inner expression is reduced before the outer expession, right?
15:26:50 <monochrom> {-# is right
15:26:53 <zhulikas> awesome!
15:26:55 <latro`a> thanks
15:27:03 <Twey> ReinH: Oh, I see what you mean.  Yes.
15:27:05 <latro`a> that said, you will need an Ord constraint
15:27:11 <zhulikas> so in the worst case scenario, if you parallelize - you will end up evaluating things in main thread
15:27:13 <ReinH> parcs`: why am I looking at par and pseq?
15:27:19 <latro`a> in addition to an Eq constraint
15:27:24 <latro`a> @ Mandarin
15:27:26 <zhulikas> thanks guys :)
15:27:41 <ReinH> Twey: ok I'm not crazy; just bad at explaining things. :)
15:27:53 <parcs`> ReinH: seq does not specify an evaluation order
15:27:57 <Twey> ReinH: *nod*  Sorry I didn't understand before ‚ò∫
15:28:14 <parcs`> ReinH: read the description under pseq
15:28:14 <ReinH> parcs`: and the docs for pseq and par are supposed to show me that how?
15:28:25 <latro`a> in fact you actually don't need Eq
15:28:26 <latro`a> just Ord
15:28:35 <ReinH> parcs`: I thought the entire point of seq was to specify an evaluation order o_O
15:28:43 <applicative> Mandarin: length returns an Int so only an int can satisfy (>(height * height))
15:28:46 <shachaf> "you actually don't need Eq, just Ord"
15:28:47 <ReinH> The docs for seq say: "Evaluates its first argument to head normal form, and then returns its second argument as the result."
15:28:55 <latro`a> ah yeah, applicative is right
15:29:01 <ReinH> what else would seq be for if it didn't specify evaluation order?
15:29:02 * shachaf looks for context.
15:29:05 <monochrom> seq is a suggestion. pseq is an order. I would put it that way
15:29:14 <latro`a> if you want a generic number, you want to use fromIntegral height
15:29:28 <latro`a> or else use genericLength (in Data.List)
15:29:33 <shachaf> monochrom: seq is more than a suggestion.
15:29:40 <shachaf> It's just not about evaluation order.
15:29:40 <Mandarin> latro`a: Thanks! That helped :)
15:29:43 <sipa> :t pseq
15:29:44 <shachaf> (Oh, I get it. "an order".)
15:29:45 <lambdabot> forall a b. a -> b -> b
15:29:48 <typoclass> a sequestion
15:29:52 <Mandarin> You'll forever be in my hall of fame <3
15:30:13 <ReinH> shachaf: then why do the docs say it is about evaluation order and why is it used to specify evaluation order?
15:30:17 <latro`a> actually...you want both, otherwise the square element has to be Integral
15:30:27 <ReinH> the docs very clearly state that it sequences evaluation
15:30:35 <monochrom> hehe shachaf, yes, pun intended hehe
15:30:40 <ReinH> monochrom: yes very good ;)
15:31:02 <shachaf> ReinH: seq is about strictness, in the denotational sense.
15:31:13 <monochrom> anyway, pseq is compulsory, seq is softer
15:31:20 <hpaste> latro`a annotated ‚ÄúMagical square transdigit validation‚Äù with ‚ÄúMagical square transdigit validation (annotation)‚Äù at http://hpaste.org/73143#a73144
15:31:26 <Mandarin> latro`a: do you mean both fromIntegral and genericLength?
15:31:41 <latro`a> what I just wrote will work as long as square is small enough (which it almost certainly is)
15:31:43 <shachaf> @remember monochrom seq is a suggestion. pseq is an order.
15:31:43 <lambdabot> It is stored.
15:32:01 <latro`a> oh wait nvm
15:32:02 <ReinH> shachaf: right, it makes the first argument strict
15:32:02 <shachaf> seq does force *some* ordering.
15:32:03 <latro`a> my mistake
15:32:08 <latro`a> genericLength returns any Num, not Integral
15:32:16 <Eduard_Munteanu> ReinH: right, but do you get a productive (+) for Church numbers?
15:32:21 <shachaf> In the same way that strictness always forces ordering.
15:32:37 <Mandarin> latro`a: Ord a works but not Eq a
15:32:41 <shachaf> But (seq a b) forces both a and b, without a guarantee about which order it'll force them in.
15:32:50 <hpaste> latro`a annotated ‚ÄúMagical square transdigit validation‚Äù with ‚ÄúMagical square transdigit validation (annotation) (annotation)‚Äù at http://hpaste.org/73143#a73145
15:32:53 <latro`a> ^that's what I meant
15:33:13 <monochrom> yeah "seq x y" leads to both x and y being evaluated. usually x first, but sometimes not.
15:33:20 <Mandarin> haha okay ^^ you're a nice guy
15:33:29 <ReinH> Eduard_Munteanu: I think they're equivalent? Zero | Succ Peano vs 0 = x; 1 = f x; 2 = (f.f) x etc?
15:33:41 <latro`a> you should probably look up the monomorphism restriction
15:33:48 <latro`a> so you have some intuition as to why you need that flag here
15:34:12 <parcs`> > error "a" `seq` error "b"
15:34:13 <lambdabot>   *Exception: a
15:34:15 <latro`a> ...wait...my bad, you don't
15:34:24 <latro`a> bah, I'm silly
15:34:28 <Mandarin> Yeah, my bookmark tab is full since I started with haskell. Don't think I've ever studied this much :)
15:34:30 <ReinH> Eduard_Munteanu: 3 = (Succ.Succ.Succ) Zero vs 3 = (f.f.f) x right?
15:34:31 <Eduard_Munteanu> ReinH: Church numbers are lambdas like \f x -> f (f x)
15:34:33 <latro`a> somehow I thought hasOverflow was eta reduced
15:34:40 <latro`a> i.e. had an argument omitted
15:34:43 <latro`a> but I was mistaken
15:35:07 <Peaker> under what conditions will seq behave differently from pseq?
15:35:34 <monochrom> what Simon Marlow says on seq and pseq for GHC: http://article.gmane.org/gmane.comp.lang.haskell.glasgow.user/11144/
15:35:43 <shachaf> Peaker: Even if it always behaves the same, there's no guarantee of it behaving the same in the future.
15:36:28 <danil> Peaker: optimization could change which kind of bottom you get from seq, or whether a spark gets spawned before or after a long computation
15:37:29 <monochrom> I think it's fair to say: in the early days, seq was about evaluation order, that's why they called it seq, and the order is important if you want to change memory usage. but after a while, they decided to shy away from operational semantics altogether. so now you can't talk about order
15:38:15 <monochrom> after another long while, parallelism came up, and now you have to talk about order afterall
15:42:00 <Peaker> so "seq" basically gives the compiler more freedom to _|_ due to more reasons
15:42:07 <Peaker> which can lead to some optimizations
15:42:25 <Peaker> and "pseq" controls evaluation order... that's the way it seems after reading the above
15:44:13 <monochrom> my reading: pseq means you are smarter than the compiler, so you dictate; seq means you and the compiler work together, you help with strictness analysis and the compiler finds a better order
15:44:47 <Eduard_Munteanu> What does 'p' stand for? It surely isn't "please". :)
15:45:01 <monochrom> http://article.gmane.org/gmane.comp.lang.haskell.cafe/88120/ is a fun experiment :)
15:45:04 <shachaf> Eduard_Munteanu: I think it has to do with "par".
15:45:08 <shachaf> Since that's the main use of pseq.
15:45:17 <Eduard_Munteanu> Yeah, that'd make sense.
15:45:25 <monochrom> yeah, par and pseq, the p relates to the parallelism scheme
15:46:41 <monochrom> oh, Peaker's reading is the same as mine
15:57:35 <latro`a> is there a way to find instance declaration source on hackage?
15:58:09 <latro`a> for example, hackage.haskell.org/packages/archive/MonadRandom/0.1.1/doc/html/Control-Monad-Random-Class.html shows a bunch of instances of MonadRandom, but the source for them isn't in the same file
16:00:39 <edwardk> instances could really use [Source] links in haddock
16:01:21 <nand`> agree
16:02:18 * hackagebot semigroups 0.8.4 - Haskell 98 semigroups (EdwardKmett)
16:26:17 <ion> reinh: Those two functions wouldn‚Äôt have the same behavior no matter what the implementation details are.
16:36:17 <notdan> Is it possible to define top and bottom types in Haskell?
16:36:26 <Nereid> what are those?
16:36:27 <Mandarin> bottom = bottom
16:36:44 <Mandarin> http://www.haskell.org/haskellwiki/Bottom
16:36:52 <Nereid> I know what bottom is.
16:36:56 <Nereid> but what is a bottom *type*?
16:38:41 <Nereid> or top type
16:39:43 <mm_freak> probably bottom on the type level
16:40:08 <ion> ‚ÄúVoid‚Äù and ‚Äúa‚Äù perhaps?
16:40:30 <ion> that is, ‚Äúforall a. a‚Äù
16:40:41 <mm_freak> any type is fine for a value level bottom
16:40:52 <mm_freak> and a type level bottom is impossible without extensions
16:40:55 <Saizan> forall a. a is mostly the same as Void
16:41:02 <Nereid> ion: those are pretty much the same
16:41:17 <notdan> it's a type without any members
16:41:17 <notdan> Mandarin: I think that's something different
16:41:30 <ReinH> notdan: what would you do with a "bottom type"?
16:41:30 <Nereid> notdan: yes, there is a Void type.
16:41:36 <Saizan> exists a. a, which is like () is called the top type sometimes
16:41:59 <ion> Indeed, sorry.
16:42:16 <Mandarin> notdan: Ah my bad, just felt that I could answer a question for the first time in #haskell ^^'
16:42:20 <notdan> ReinH: I was going to try to abuse Haskell's type system
16:42:39 <mm_freak> notdan: that's easy
16:42:39 <Saizan> notdan: so you can defined data Top = Top; and data Bot; with {-# LANGUAGE EmptyDataDecls #-} for Bot
16:42:41 <Nereid> obviously Void isn't useful by itself.
16:43:00 <notdan> Mandarin: that's ok, I actually didn't know about the bottom that you linked to either, it is an interesting read
16:43:01 <mm_freak> Saizan: no need for EmptyDataDecls since haskell 2010
16:43:02 <Nereid> but it's nice to be able to use it, say, in other type constructors.
16:43:20 <ion> ‚Äúdata Top where Top :: a -> Top  -- since we don‚Äôt have exists‚Äù?
16:43:45 <mm_freak> anyway, you're still referring to value level bottoms and give them some sensible types
16:44:12 <ion> or ‚Äúdata Top = forall a. Top a‚Äù
16:44:14 <mm_freak> a "bottom type" doesn't sound to me like "a possible type of value-level bottom"
16:44:20 <Saizan> what's called Top usually doesn't have the 'a' part
16:44:26 <mm_freak> but rather something like this:  type instance F x = F x
16:44:37 <Nereid> what properties are Bottom and Top supposed to have?
16:44:37 <Saizan> so i guess my line above was misleading
16:45:08 <mm_freak> a "bottom type" sounds like something that shoots the type checker into an infinite recursion
16:45:43 <Nereid> ^
16:45:53 <signalsea> Hi all, question.. what GHC features or extensions allow me to do double/multiple dispatch? Are MPTCs typically the preferred way?
16:45:58 <mm_freak> type family F :: * -> *
16:46:00 <Saizan> they are the bottom and top of the implication lattice
16:46:01 <mm_freak> type instance F x = F x
16:46:05 <ion> nereid: I understood that you can‚Äôt have a value that is a witness to the bottom type and every value can be a witness to the top type. Or something. But i‚Äôve probably misunderstood it.
16:46:24 <Mandarin> Is there a way to skip the 640000000 first mutations of the permutations function without having to compute them?
16:46:34 <Saizan> (or initial and terminal objects of Hask, if you want)
16:47:02 <Nereid> Saizan: initial and terminal objects of Hask are both Void.
16:47:06 <mm_freak> signalsea: could you give an example?  OOP isn't well supported by GHC/haskell
16:47:06 <luite> Mandarin: if that's what you want, you
16:47:12 <Nereid> unless you like being total, then Void and (), respectively.
16:47:24 <luite> Mandarin: 're probably looking for an unranking algorithm for permutations
16:47:29 <Saizan> i like being total :)
16:48:23 <mm_freak> bottom types don't have bottom values actually‚Ä¶  those are the only types that are not inhabitated
16:48:29 <Mandarin> luite: thanks will look it up :)
16:48:58 <luite> Mandarin: efficient ones will probably force a different order on the permutations
16:49:05 <signalsea> mm_freak: give me a moment, I will make up an example
16:49:17 <mm_freak> signalsea: it suffices to describe it
16:49:24 <carharttjimmy> Could someone please go into a little more depth in how curried functions work?
16:49:53 <mm_freak> carharttjimmy: f x y = (f x) y
16:49:59 <notdan> so, how it is possible to define/use bottom type with those extensions?
16:50:01 <mm_freak> carharttjimmy: a -> b -> c = a -> (b -> c)
16:50:05 <latro`a> O.o the lag
16:50:12 <mm_freak> carharttjimmy: that's currying
16:50:48 <mm_freak> carharttjimmy: all functions take a single argument‚Ä¶  multi-argument functions are actually single-argument functions that return functions
16:51:10 <mm_freak> "(f x) y" means to apply 'y' to the function returned by 'f x'
16:51:14 <latro`a> speaking of which
16:51:14 <carharttjimmy> so multi-argument functions pass on parameters to the function ?
16:51:20 <latro`a> with the MR off
16:51:44 <latro`a> are "f x = \y -> g x y" and "f x y = g x y" the same?
16:51:44 <mm_freak> notdan: again, i don't think there is an agreed upon notion of "bottom types"
16:51:52 <mm_freak> notdan: if you're using my notion, just look at my example
16:51:58 <Nereid> latro`a: yeah
16:52:01 <mm_freak> you need TypeFamilies and UndecidableInstances for it
16:52:25 <mm_freak> latro`a: after optimization probably
16:52:35 <latro`a> I mean semantically identical
16:52:38 <latro`a> again given that the MR is off
16:52:38 <mm_freak> latro`a: semantically they are the same, yes
16:53:02 <Mandarin> mm_freak: you gave me a real a-ha moment ! Now I understand multi-argument functions, thanks ^^
16:53:15 <carharttjimmy> Ohhh
16:53:16 <carharttjimmy> Ohhh
16:53:22 * carharttjimmy gets it now
16:53:57 <notdan> mm_freak: no, Bottom type is just uninhabited
16:53:58 <Nereid> isn't the monomorphism restriction involved here or something
16:54:04 <Nereid> between f x = \y -> g x y, f x y = g x y
16:54:10 <mm_freak> notdan: that's just the void type
16:54:19 <notdan> mm_freak: basically, what I wanted to do is some primitive constructive logic proofs
16:54:25 <notdan> and I needed Bot for the negation
16:54:56 <mm_freak> notdan: in logic you would usually call that 'Absurd'
16:55:01 <mm_freak> data Absurd
16:55:01 <Nereid> notdan: the Void type, then.
16:55:09 <mm_freak> or newtype Absurd = Absurd Absurd
16:55:17 <mm_freak> the former is h2010, the latter is h98
16:55:19 <signalsea> mm_freak: I have a record Meeting, with fields mtg_attendees (Meeting -> [Attendee]) and mtg_topics (Meeting -> [Topic]) and I want a function "append" that selects the mtg_attendees field when appending (Attendee)s and the mth_topics field when appending (Topic)s
16:55:40 <Nereid> X -> Void is uninhabited if X is inhabited.
16:55:43 <danil> Nereid: no, the MR only gets involved with non-function bindings, and both of those have at least one parameter on the LHS
16:55:44 <Nereid> and is inhabited if X = Void.
16:55:52 <mm_freak> signalsea: sounds like a Monoid to me
16:55:52 <Nereid> danil: oh ok.
16:55:52 <signalsea> mm_freak: but I will want to have an append for types not involving Meeting)s at all
16:55:55 <signalsea> Ok
16:56:08 <mm_freak> signalsea: see Data.Monoid
16:56:46 <kanedank`> the only difference between tuples and arrays is that tuples are immutable, right?
16:56:54 <mm_freak> signalsea: i'm assuming that your Meeting type has only a single constructor
16:57:01 <Nereid> kanedank`: what do you mean by "arrays"?
16:57:05 <Nereid> kanedank`: also, everything is immutable
16:57:07 <kanedank`> []
16:57:17 <carharttjimmy> [] denote lists in haskell
16:57:17 <kanedank`> list, sorry
16:57:27 <mm_freak> kanedank`: tuples are unboxed, heterogenous and don't have an assumed memory layout
16:57:29 <carharttjimmy> a tuple can have different types
16:57:35 <carharttjimmy> a [] can only have one type
16:57:36 <Nereid> mm_freak: tuples are quite boxed.
16:57:41 <mm_freak> uhm
16:57:45 <mm_freak> i meant to say /not/ unboxed
16:57:46 <carharttjimmy> its possible to create multiple tuple types
16:57:50 <Nereid> lists are also not unboxed.
16:58:12 <mm_freak> kanedank`: again‚Ä¶  tuples are not unboxed, heterogenous and don't have an assumed memory layout
16:58:13 <signalsea> mm_freak: yes, Meeting only has a single constructor. I recall looking into Monoids but thinking they were unsuitable for some reason... let me see if i can jog my memory
16:58:44 <latro`a> Nereid, yes MR is relevant, that is why I specified that it was off
16:58:49 <mm_freak> signalsea: a monoid is a set with an associative closed binary operation and a neutral element wrt that operation
16:59:42 <mm_freak> signalsea: meetings with combining attendees and topics form a monoid
17:00:01 <mm_freak> the neutral element (mempty) is the empty meeting
17:00:02 <Nereid> mm_freak: "closed" is always redundant.
17:00:11 <Nereid> it's implied by "binary operation".
17:00:15 <mm_freak> Nereid: no
17:00:23 <danil> latro`a: it's not, those are both function bindings.  The MR would only matter if you go all the way to f = \x -> \y -> g x y .
17:00:39 <signalsea> mm_freak. oh ok i remember... I saw the signature of mappend (a -> a -> a) and wondered how I could use that for several types
17:00:43 <Nereid> or f = \x y -> g x y
17:00:54 <mm_freak> Nereid: given the set {0 ‚Ä¶ 9} the binary operation '+' is not closed
17:01:01 <Nereid> then it's not a binary operation on that set
17:01:20 <latro`a> nereid is correct
17:01:31 <latro`a> 8+7, on {0,..,9}, is nonsense
17:01:37 <latro`a> it's not 15 and not in the set, it's just absurdity
17:01:53 <latro`a> this is somewhat of a technical distinction in practice, however
17:02:09 <Nereid> well
17:02:29 <mm_freak> ok, the terminology seems to be that a binary operation is a closed binary relation
17:02:36 <Nereid> to me a "binary operation on X" is a "function X x X -> X"
17:02:42 <Nereid> certainly not a relation.
17:02:44 <signalsea> yeah
17:02:50 <mm_freak> Nereid: every function is a relation
17:03:22 <Nereid> and every number is a set.
17:03:31 <Nereid> poor way of thinking about functions.
17:04:03 <Nereid> and certainly not every relation is a function.
17:04:06 <mm_freak> no, actually a sensible way‚Ä¶  thinking in terms of the set formed by the mapping allows you to analyze the structure of a function
17:05:03 <mm_freak> and i didn't say that every relation is a function, but every function is a relation
17:05:12 <Nereid> "a binary operation is a closed binary relation"
17:05:32 <mm_freak> yes
17:05:36 <mm_freak> what's untrue about that?
17:05:47 <Rotaerk> no
17:05:47 <Rotaerk> numbers aren't sets
17:05:47 <Rotaerk> a relation is a mapping from elements of one set to another; a function is a relation such that every element in the domain has at most one mapping
17:05:47 <Rotaerk> to put it informally...
17:05:53 <mm_freak> every binary operation is a function, and every function is a relation
17:06:02 <Nereid> Rotaerk: if numbers aren't sets, what are they?
17:06:03 <mm_freak> by transitivity every binary operation is a relation
17:06:21 <Nereid> mm_freak: it does not serve as a definition or characterization of binary operations
17:06:35 <mm_freak> Nereid: so?
17:06:45 <mm_freak> it's a true statement and useful on the group theory level
17:06:51 <Nereid> your wording made it look like a definition.
17:06:56 <Nereid> this is silly.
17:07:04 <Rotaerk> Nereid, numbers
17:07:15 <mm_freak> Nereid: that's your interpretation
17:07:25 <signalsea> mm_freak: How can I use Monoids to combine several types while restricting nonsense cases?  I cant append an Attendee to a Topic
17:07:39 <Nereid> mm_freak: this is silly and off topic.
17:07:40 <monochrom> a relation is a function. a function is a relation.
17:08:16 <mm_freak> signalsea: Meeting atts1 topics1 `mappend` Meeting atts2 topics2 = Meeting (atts1 `mappend` atts2) (topics1 `mappend` topics2)
17:08:24 <mm_freak> signalsea: mempty = Meeting mempty mempty
17:08:46 <Rotaerk> Nereid, numbers can be *encoded* as sets, but that doesn't mean they *are* sets
17:08:54 <Rotaerk> i.e. {} {{}} {{{}}} etc
17:09:00 <mm_freak> monochrom: a relation is a subset of a cartesian product betwee two sets
17:09:11 <signalsea> so I should just construct a Meeting for every append?
17:09:12 <monochrom> @type (==)
17:09:13 <lambdabot> forall a. (Eq a) => a -> a -> Bool
17:09:24 <monochrom> the (==) relation is a function. the type says so.
17:09:24 <mm_freak> not every relation is a function
17:09:55 <monochrom> a subset is a function
17:09:58 <Nereid> ^
17:10:10 <Nereid> subsets of X naturally correspond to functions X -> {0,1}
17:10:17 <mm_freak> Nereid: it's off-topic, but certainly not silly, otherwise you're calling all people who subscribe to the idea of group-theoretic relations silly
17:10:26 <Mandarin> luite: Thanks for pointing me to the right resources. I found out a better solution to my problem :)
17:10:42 <Rotaerk> Nereid, eh?
17:10:53 <Nereid> Rotaerk: eh?
17:10:57 <Rotaerk> EH?
17:11:03 <Nereid> http://en.wikipedia.org/wiki/Subobject_classifier
17:11:05 <n00b6502> this might sound far fetched, but has anyone heard of tools to convert a SUBSET of haskell into c++  ; type inference -> templates, and iterators on vectors..
17:11:12 * monochrom pokes fun at every attempt at basing everything on sets
17:11:16 <mm_freak> a partial order on A is also a relation‚Ä¶  it's a subset of A¬≤
17:11:22 <Nereid> no
17:11:24 <Nereid> no one said that
17:11:27 <luite> Mandarin: np :)
17:11:35 <mm_freak> but a partial order is not (necessarily) a function
17:12:09 <monochrom> a partial order on A is a function A -> A -> Bool. you can also use (A,A) -> Bool if you like
17:12:37 <mm_freak> monochrom: you're thinking in haskell
17:12:42 <mm_freak> right now i'm thinking in group theory
17:12:51 <monochrom> not true. I already thought that before I met haskell
17:12:52 <Nereid> we can use the same notation with sets
17:13:04 <monochrom> hol.sf.net
17:13:12 <mm_freak> monochrom: may be, but still there is the group-theoretical approach
17:13:14 <Nereid> and it largely has nothing to do with groups anyway
17:13:22 <Nereid> anyway, my point is that
17:13:30 <Rotaerk> when you said "a subset is a function" did you mean subsetOf is a function?
17:13:32 <Nereid> instead of thinking of functions as particular kinds of relations,
17:13:39 <mm_freak> Rotaerk: no
17:13:43 <monochrom> there is almost no relation (other than equality) in group theory
17:13:46 <Nereid> I prefer thinking that every function gives rise to a relation.
17:13:58 <Rotaerk> all sets are subsets
17:14:04 <Rotaerk> therefore all sets are functions
17:14:09 <mm_freak> Rotaerk: a function A ‚Üí B is a subset of A√óB
17:14:12 <monochrom> a subset of A is a function A->Bool
17:14:19 <Nereid> a function A -> B induces a subset of A x B, yes.
17:14:35 <mm_freak> every subset of a cartesian product is a relation, and some of them are functions
17:14:54 <carharttjimmy> whats group theory ?
17:14:56 <Nereid> think more category-theoretically.
17:15:02 <Nereid> carharttjimmy: an area of math.
17:15:04 <carharttjimmy> oh wait
17:15:08 <carharttjimmy> off to google
17:15:09 <monochrom> perhaps your group theory course is the first time you see everything done based on sets, and so you think that "everything is a set" comes from group theory
17:15:37 <mm_freak> monochrom: well, "everything is a set" is not my mindset
17:15:40 <Nereid> anyway I have better things to be doing, bbl.
17:15:49 <mm_freak> but "every relation is a subset of a cartesian product" is
17:16:05 <Rotaerk> carharttjimmy, it's mathematical theory... about groups
17:16:11 <Rotaerk> I think it falls under abstract algebra
17:16:20 <Rotaerk> at least, I first learned about it in my abstract algebra course
17:16:28 <carharttjimmy> it so appears with two main cats, lie groups and linear alg groups ?
17:17:05 <monochrom> and what is a cartesian product? I bet it's another set for you again
17:17:19 <carharttjimmy> cartesian product is x*y ?
17:17:31 <Rotaerk> "everything is a set" is simply wrong
17:17:34 <mm_freak> yeah, of course it's a set
17:17:46 <carharttjimmy> or (x1,y1)*(x2,y2) ?
17:17:46 <latro`a> rotaerk--...not really
17:17:47 <mm_freak> seems like i have to give the literal definition
17:17:51 <monochrom> well there you go. a relation is, eventually, a set again
17:17:56 <Rotaerk> but maybe "everything can be encoded as a set" is correct
17:18:06 <monochrom> I know the literal definition. I took several set theory courses.
17:18:07 <latro`a> the distinction is splitting hairs really
17:18:11 <Rotaerk> no it isn't
17:18:12 <latro`a> given that you care about the structure
17:18:14 <latro`a> not the content
17:18:15 <mm_freak> a relation between A and B is a subset of A√óB
17:18:18 <latro`a> for mathematical purposes
17:18:32 <latro`a> that said Godel issues make not everything that can be thought of as "mathematics" a set anyway
17:18:49 <monochrom> you are admitting that A√óB is yet another set
17:18:56 <mm_freak> i'm not admitting it
17:18:59 <mm_freak> i'm saying it
17:19:13 <mm_freak> that doesn't make me think "everything is a set"
17:19:26 <monochrom> alright, fine, but you're saying "a relation is a set"
17:19:27 <Rotaerk> a dog isn't a set
17:19:39 <carharttjimmy> a dog is a set
17:19:46 <latro`a> if you can encode its quantum state into numbers, then you can represent a dog as a set
17:19:48 <monochrom> and then you also say "a function is a relation", so therefore "a function is a set", too
17:19:49 <mm_freak> monochrom: as a statement i'd be saying that, but as a definition that's wrong
17:19:59 <Rotaerk> carharttjimmy, no it's not...
17:20:03 <monochrom> I'm after true statements, yes
17:20:12 <latro`a> it's silly and unhelpful to do this, but it's *plausible*, modulo physics issues
17:20:15 <mm_freak> then yes, i'm happy with the statement
17:20:18 <Rotaerk> although you could encode a dog as a set of cells, or as a set of body parts
17:20:30 <carharttjimmy> if you smoke enough mary jane anything can be a set.
17:20:41 <latro`a> but you can encode a dog as a set all the way down
17:20:41 <monochrom> also we agree that "is-a" is not a reflexive relation. it is a "<special case> is a <general case>" relation
17:20:46 <latro`a> using enough quantum mechanics
17:20:54 <mm_freak> monochrom: yeah
17:20:56 <latro`a> and yeah, copulae are stupid
17:21:06 <latro`a> they don't behave like they should
17:21:10 <mm_freak> monochrom: i know where you're going
17:21:44 <mm_freak> a set can be represented by a function, so set = function
17:21:52 <mm_freak> uhm, no
17:21:59 <mm_freak> every set is a function and every function is a set
17:22:12 <latro`a> "every set is a function" requires assumptions on the background set theory
17:22:32 <latro`a> and is invalid in Z, ZF, and ZFC
17:22:38 <latro`a> as well as NF
17:22:44 * carharttjimmy is soo lost
17:22:48 <mm_freak> but anyway, (true) statements like that are not very informative
17:22:56 <monochrom> hol.sf.net uses functions as primitives and builds sets on top of them (that is, if you care about sets at all)
17:23:08 <latro`a> "every set is isomorphic to a function" is true, however
17:23:15 <mm_freak> what is useful is a /definition/ of relations in terms of sets
17:23:22 <mm_freak> and that's what i'm doing
17:23:48 <mm_freak> carharttjimmy: don't worry‚Ä¶  such discussions come up here from time to time =)
17:24:05 <carharttjimmy> what is Z, ZF and ZFC ?
17:24:07 <mm_freak> carharttjimmy: it's off-topic btw
17:24:14 <monochrom> no, the most useful thing is a complete list of properties of relations. the API. leave the implementation abstract. do not expose the implementation by sets
17:24:18 <mm_freak> carharttjimmy: sets of set theory axioms =P
17:24:29 <carharttjimmy> You know what nvm.
17:24:42 <carharttjimmy> one day I will go read it.
17:24:48 <carharttjimmy> then I will be more confused
17:25:37 <mm_freak> monochrom: i agree, but you can use the set-theoretic implementation to create some useful categorizations and derive some proofs
17:26:06 <mm_freak> (easily that is)
17:27:15 <latro`a> carharttjimmy, ZF is the most commonly used collection of axioms for set theory
17:27:20 <Nereid> ZFC.
17:27:30 <latro`a> no, I intentionally said ZF
17:27:38 <Nereid> and I intentionally said ZFC.
17:27:56 <DT``> a new old flamewar arises.
17:28:00 <latro`a> C is an additional axiom, called the axiom of choice, which is more often than not added to ZF; the result is called ZFC
17:28:13 <latro`a> I shouldn't have said "most commonly used", fair enough
17:28:18 <Nereid> no one uses Z.
17:28:23 <latro`a> I didn't say anyone did
17:28:29 <Nereid> I'm answering what Z is.
17:28:29 <latro`a> was just pointing it out for emphasis
17:28:39 <carharttjimmy> why is set theory usefuk?
17:28:41 <c_wraith> I can't find a mathematician who wants to say the axiom of choice makes sense - just that it's too handy to not use.
17:28:43 <carharttjimmy> useful*
17:28:51 <Nereid> c_wraith: indeed.
17:29:13 <Nereid> carharttjimmy: because mathematicians have recognized that they can do all of their mathematics in set theory.
17:29:18 <mm_freak> carharttjimmy: it's a theoretical framework for collections of objects
17:29:28 <DT``> c_wraith, why? it makes plenty of sense to me but some fo the results are quite odd.
17:29:31 <Nereid> I would simply say "objects"
17:29:41 <jyc> I installed leksah using cabal, and now I want to uninstall it (so I can install it w/ apt) - I can't find what argument to give to ghc-pkg unregister. would anyone know?
17:29:47 <Nereid> DT``: some consequences of denying choice are also odd
17:30:07 <mm_freak> carharttjimmy: for example every collection of numbers forms a set, and set theory is the fundamental concept around that
17:30:12 <carharttjimmy> ahh
17:30:16 <Nereid> wikipedia copypaste. "The Axiom of Choice is obviously true, the well-ordering principle obviously false, and who can tell about Zorn's lemma?" ‚Äî Jerry Bona
17:30:26 <c_wraith> DT``: does it really makes sense that you can pick an element from R \ CR (computable reals)?  That assertion makes no sense to me.
17:30:30 <monochrom> hehe
17:30:46 <Nereid> I am comfortable with using the axiom of choice.
17:31:02 <DT``> c_wraith, for me, at least, it does.
17:31:15 <Nereid> I think the main interest in set theory without choice, or logic without excluded middle, is when you are working in some internal logic.
17:31:18 <Nereid> (like haskell!)
17:31:19 <danil> c_wraith: you probably want to substitute definable for computable there--Chaitin's constant is a perfectly good number to me
17:31:29 <DT``> I concur, Nereid.
17:31:33 <c_wraith> DT``: not me.  If you need infinite information to pick an element, it seems like nonsense.
17:31:48 <c_wraith> and yeah, I should go with defineable.
17:32:45 <DT``> c_wraith, if I have uncountably infinite objects and I have to pick one, I'd close my eyes and pick one.
17:33:10 <c_wraith> DT``: but how would you describe your choice such that others can repeat it?
17:33:34 <DT``> I can't.
17:33:59 <c_wraith> seems like a problem to me.
17:34:24 <parcs`> jyc: cabal/ghc doesn't keep track of executables
17:34:45 <mm_freak> what is R \ CR?
17:35:03 <DT``> c_wraith, I'm fine with it.
17:35:07 <mm_freak> something the busy beaver may feel comfortable in?
17:35:07 <monochrom> yeah, nothing to unregister, just go ahead delete the exe
17:35:37 <monochrom> the uncomputable reals
17:36:05 <mm_freak> ah, that's from computer science
17:36:14 <jyc> hm, so the binary is the only thing it's installed?
17:36:24 <monochrom> part computer science, part real analysis
17:36:29 <monochrom> yes
17:36:36 <jyc> thanks!
17:37:08 <mm_freak> could you give me an example of an uncomputable number? =P
17:37:22 <c_wraith> chaitin's constant, as was pointed out earlier
17:37:23 <monochrom> I don't know the exact definition, so I can't
17:37:25 <Nisstyre> mm_freak: any chaitin constant
17:38:19 <c_wraith> but simpler...  BB(10)
17:38:45 <danil> all integers are computable
17:38:58 <c_wraith> hmm, yes, it's BB that's non-computable
17:39:25 <c_wraith> You'll never be able to prove any particular integer is BB(10)...  But that's not the same thing.
17:39:55 <Nereid> hmm, there was some discussion about this elsewhere, a while ago.
17:40:00 <Nereid> I forget how it went.
17:40:06 <Nereid> let me find my logs.
17:40:21 <monochrom> do you accept that BB(10) is an integer? since you don't know which one it is...
17:40:53 <monochrom> it is related to: do you accept choice? since you don't know which to choose
17:42:09 <m3ga> which version of cabal-install understands the -j option?
17:42:58 <monochrom> what does -j do?
17:43:00 <Nereid> ah right, that's what it was about.
17:43:06 <c_wraith> yeah, I touch on the edge of that.  I don't go as far as the people who reject exponentiation...  But I have to admit sympathy with denying the ability to prove any properties of numbers you can't fully characterize
17:43:24 <parcs`> m3ga: no actual version i don't think
17:43:37 <danil> monochrom: you don't need choice to prove that the maximum of a countable set of integers is an integer
17:43:41 <m3ga> monochrom: its like -j with makem ie use all the cpu cores
17:43:42 <monochrom> I decided to accept both. that is, "can" does not have to be constructive
17:43:58 <monochrom> I don't think cabal-install has -j yet.
17:44:14 <m3ga> parcs`: i thought i saw an announcement just recently
17:44:26 <m3ga> probably from tibbe
17:44:31 <Nereid> there exists a turing machine that doesn't halt, but there is no proof that it doesn't halt.
17:44:34 <Nereid> that's what it was.
17:44:49 <monochrom> a countable set of integers may or may not have a maximum
17:45:19 <Nisstyre> you don't need to construct a mathematical object to prove stuff about it
17:45:30 <parcs`> m3ga: perhaps there will be a cabal release in sync with the next ghc release
17:45:39 <parcs`> m3ga: but if you really want -j you can install cabal from git
17:45:52 <danil> monochrom: (*headbonk*) right, yeah.
17:46:19 <monochrom> hehe
17:46:33 <kfish> m3ga, https://plus.google.com/116396165393082006231/posts
17:46:51 <erjiang> Hi all, any recommendations for a simple HTTP server library?
17:47:35 <Nereid> relatedly, there exists n such that for all N, BB(n) <= N is not provable.
17:48:55 <Nereid> for all N, (BB(n) <= N is not provable)
17:49:05 <mm_freak> erjiang: snap or WAI
17:49:28 <mm_freak> erjiang: snap is more convenient, WAI is lower level
17:49:39 <AfC> erjiang: Snap is pretty easy to use
17:49:58 <kfish> erjiang, http://hackage.haskell.org/package/webserver is lightweight
17:50:25 <erjiang> thanks for all the suggestions
17:50:42 <erjiang> I'm looking for something similar to Go's net/http
17:50:56 <erjiang> kfish: webserver looks pretty simple
17:50:56 <mm_freak> erjiang: what do you want to implement?
17:51:07 <luite> erjiang: wai is the underlying lib for yesod and some other frameworks like scotty
17:51:42 <luite> hoogle also uses it for its embedded server
17:52:27 <erjiang> mm_freak: I'm looking to build an api endpoint that'll serve json
17:52:49 <mm_freak> erjiang: in that case you should go with a web framework instead of a simple HTTP library
17:52:56 <mm_freak> there are happstack, snap and yesod
17:53:14 <erjiang> mm_freak: what's your reasoning behind that?
17:53:28 <mm_freak> erjiang: you'll be reinventing what they provide for free
17:53:38 <erjiang> mm_freak: which are... ?
17:53:46 <mm_freak> think about parsing requests, formatting responses, etc.
17:53:50 <luite> erjiang: all the frameworks are basically web server libraries with some stuff on top to make it easier to use
17:54:01 <mm_freak> luite put it better than me
17:54:13 <sm> scotty looks like the quickest way to get going
17:55:01 <m3ga> parcs`: the cabal install -j flag was commited to git 4 days ago :-)
17:55:09 <luite> what does the -j flag do?
17:55:19 <kfish> erjiang, we use webserver for what is basically a json+websockets app
17:55:22 <m3ga> luite: it uses more than one core
17:55:31 <luite> whoah!
17:55:41 <erjiang> kfish: I think I'm shooting for something similar too
17:55:45 <mm_freak> probably the same as make's -j
17:55:49 <mm_freak> i.e. concurrent builds
17:55:52 <m3ga> mm_freak: yes
17:55:54 <luite> m3ga: does it compile files in parallel, or only packages?
17:56:09 <mm_freak> i don't think you can compile files in parallel much
17:56:09 <m3ga> luite: packages in parallel where possible.
17:56:15 <parcs`> m3ga: well the standalone -j flag was committed recently, but -jN was committed a while ago
17:56:24 <m3ga> oh really?
17:56:28 <m3ga> let me try
17:56:45 <luite> that will finally let me install yesod in under an hour ;)
17:57:00 <kfish> hi conal :)
17:57:07 <mm_freak> luite: it usually takes around 10 minutes for me
17:57:09 <erjiang> kfish: do you have any tips or pointers to documentation?
17:57:11 <carharttjimmy> http://www.youtube.com/watch?v=vQA2eB8LJ7U&feature=related
17:57:15 <carharttjimmy> whoops
17:57:17 <carharttjimmy> wrong channel
17:57:18 <carharttjimmy> sorry
17:57:33 <erjiang> kfish: I basically need to be able to query a db and serve up json efficiently
17:57:50 <mm_freak> erjiang: definitely a web framework
17:58:03 <luite> mm_freak: hehe yeah i was joking, but it's still a long time if want to test something quickly on a different ghc version or from a different yesod development branch
17:58:26 <erjiang> mm_freak: I'm not sure why you keep pushing a web framework. I don't need session handling, auth, or templating
17:58:31 <mm_freak> luite: despite my love for static checks that's one of the reasons i switched from yesod =)
17:58:34 <kfish> erjiang, i can't give you advice about querying a db, we use [a hacked up version, with added Typeable instances] of Takusen, and I'd advise against that
17:58:51 <mm_freak> erjiang: a haskell web framework doesn't give you that‚Ä¶  it's all optional
17:59:40 <kfish> erjiang, but, aeson is pretty straightforward, you'll be using that no matter what web server you use
17:59:53 <mm_freak> erjiang: again, please don't compare to web frameworks in other languages, which do everything for you and you have to /get rid/ of features to have something lightweight
17:59:58 <luite> erjiang: you don't need to use any of those. even yesod, which is said to be the most heavyweight framework, lets you use only the very basics (although sessions are enabled in a default instance, it's one line to disable them)
18:00:39 <mm_freak> erjiang: let me state it this way:  what is 10 lines using snap will be 200 lines using WAI
18:01:12 <erjiang> mm_freak: do you think snap-core is enough?
18:01:55 <mm_freak> erjiang: probably, if you can live without snaplets (modularity)
18:02:22 <luite> mm_freak: you use snap now?
18:02:27 <mm_freak> luite: yeah
18:03:08 <luite> mm_freak: was it mostly the installation time, or the reload time for development?
18:03:36 <mm_freak> luite: neither‚Ä¶  i wanted something more transparent
18:04:05 <mm_freak> yesod is great, as long as you do what it wants you to do‚Ä¶  everything else is a pain
18:05:16 <luite> mm_freak: oh i thought you mentioned it at one of the reasons for switching, after i mentioned the installation time
18:05:25 <tswett> Ahoy.
18:05:29 <mm_freak> luite: only a minor reason
18:05:32 <luite> ah ok
18:05:41 <luite> mm_freak: anything in particular that was difficult to achieve with yesod?
18:05:59 <tswett> So, Data.Unique lets a person generate unique identifiers in the IO monad.
18:06:00 <mm_freak> luite: modularity
18:06:12 <tswett> Is there a similar thing that works in the ST monads?
18:06:42 <mm_freak> tswett: it would only be unique within the ST session, so you can just as well use an STRef
18:07:13 <luite> mm_freak: because of the local state in snaplets, whereas the yesod model is stuffing everything in the foundation type?
18:07:25 <tswett> Use an STRef s () as a unique identifier... yeah, that would work.
18:07:26 <tswett> Thanks.
18:08:14 <mm_freak> luite: that's one of the reasons‚Ä¶  the other one is that it's hard to make components in separate packages, much harder than snaplets at least
18:08:17 <tswett> And now I can implement Lua in Haskell.  Muahaha...
18:08:38 <mm_freak> there are subsites, but at the time they were terribly documented and inconvenient to implement
18:08:52 <mm_freak> tswett: btw, i'd use StateT
18:08:58 <luite> right, and they come with routing, which you don't always need
18:09:49 <tswett> But Lua translates to the ST monads so nicely!  A table is simply, uh... an infinite collection of STRefs.
18:10:04 <mm_freak> luite: yeah, subsites are pretty much individual parts of an application‚Ä¶  in particular they can't interact without ugly hacks
18:10:11 <mm_freak> luite: snaplets can interact very naturally
18:10:21 <AfC> You can use Snap without Snaplets; the core Snap functionality is more than sufficient for many things.
18:10:37 <mm_freak> i use snaplets even for simplest applications
18:10:54 <mm_freak> it makes using heist so much simpler
18:11:33 <AfC> mm_freak: (just saying for erjiang there that you can get on with what it sounds like they need to do without having to climb a steep learning curve)
18:11:53 <mm_freak> yeah, erjiang needs only snap-core and snap-server
18:12:14 <mm_freak> that's for simple HTTP servers
18:14:13 <mm_freak> luite: as a side note i used type classes in yesod for what i do with snaplets now‚Ä¶  think of YesodPersist or YesodBreadcrumbs
18:14:39 <mm_freak> that makes it somewhat modular, but snaplets are still easier to deal with
18:15:44 <luite> mm_freak: yeah that what i meant in the first question by "stuffing everything in the foundation type", since these instances don't have extra state or anything
18:21:42 <tswett> Is there an associative array type where the keys can be STRefs?
18:22:11 <monochrom> I think not
18:22:19 <tswett> I'm trying to have fun, and preferably implement Lua along the way.
18:23:15 <monochrom> it doesn't have Ord or Hashable. it just has Eq. if you don't mind linear search, something can be done :)
18:23:25 <tswett> I suppose that although STRefs aren't ordered, I can *make* them be ordered...
18:23:32 <mm_freak> tswett: [(STRef k, STRef a)]
18:23:53 <mm_freak> or Seq ((STRef k), (STRef a))
18:24:00 <mm_freak> but you're not going to enjoy that =)
18:24:18 <mm_freak> and you can't make them ordered
18:24:25 <mm_freak> runST's 'forall' will be in your way
18:25:31 <tswett> data OSTRef s a = OSTRef Integer (STRef s a); data OST s a = OST (STRef s Integer) (ST s a)
18:25:44 <tswett> That'll give me STRefs with Integers attached, aye?
18:26:28 <mm_freak> i wonder why you're working in ST anyway
18:26:55 <tswett> Something tells me State would, in fact, be nicer.
18:30:20 <mm_freak> tswett: something tells me that a free monad would be best
18:31:29 <Nafai> I want to do some computer generated abstract 2D art. Is gtk2hs/cairo the best option or is there something better?
18:31:35 <tswett> mm_freak: what would that do?
18:32:18 <ion> nafai: There are higher-level libraries you might want to use. I don‚Äôt remember their names.
18:32:39 <latro`a> the top level header of the graphical libs is Graphics
18:32:44 <ion> nafai: The Pong example in lens seems to use Gloss.
18:32:45 <latro`a> you might find some stuff under that header on hackage
18:32:46 <mm_freak> Nafai: have a look at the 'diagrams' library
18:33:23 <Nafai> thanks for the pointers, I've heard of both and had forgotten them
18:33:26 <mm_freak> Nafai: here is a gallery:  http://projects.haskell.org/diagrams/gallery.html
18:33:46 <mm_freak> gloss is also fine, but not as powerful
18:33:55 <mm_freak> gloss on the other hand does real-time rendering
18:34:02 <latro`a> that sierpinski is pretty awesome
18:34:28 <latro`a> the code I mean, not the image
18:34:33 <latro`a> the image is just fine, but not awesome
18:36:15 <mm_freak> hehe indeed
18:38:37 <mkCurry> There's absolutely no way to define a conversion from one type to another that's global and automatic, right? E.g., say, Int -> Float... such that if I referenced an int and tried to use it where a float's needed that conversion would be automatically invoked.
18:39:21 <Twey> mkCurry: No
18:39:30 <mkCurry> Twey: Didn't think so.
18:39:37 <Twey> (and thank goodness for that :√æ)
18:40:16 <mkCurry> Twey: I have a valid use case. I have one special class that I'd like automatically converted just because the code because unreadable otherwise.
18:40:34 <Twey> mkCurry: That indicates that you're probably doing it wrong
18:40:49 <Twey> mkCurry: Consider taking some sort of typeclass instead of a concrete Float
18:41:22 <mkCurry> Twey: In this case, it's a class that can hold any type.
18:41:56 <mm_freak> mkCurry: implicit conversion is not possible in haskell
18:42:37 <mm_freak> there are simple solutions for polymorphic conversions like the 'convertible' package, but there is no way to do this /implicitly/
18:42:51 <latro`a> ime you actually get a bit surprised as you start fiddling with numbers a bit in haskell
18:42:58 <Twey> mkCurry: So you want your function to take *any type* and automatically convert it to a Float?
18:43:01 <latro`a> because the literals are polymorphic but have a concrete type in context
18:43:03 <latro`a> erm
18:43:08 <latro`a> *but numbers have a concrete type in context
18:43:12 <mm_freak> i guess mkCurry is sick of "x + fromIntegral y"
18:43:13 <mkCurry> Twey: No, a specific type to a specific type.
18:43:19 <latro`a> so it looks really really nice at first
18:43:23 <latro`a> and then fromIntegrals pop up
18:43:27 <Twey> mkCurry: So it's not any type at all?
18:43:36 <mkCurry> Basically, it's a type that holds a value, and within a monad, when read it adds an edge to a directed graph.
18:43:51 <mkCurry> It's to assure all reads occur after writes.
18:44:04 <Twey> mkCurry: I think you'd probably have to sketch us some code
18:44:05 <latro`a> why would that need a cast
18:44:26 <Twey> Yeah, I can't see any use for a cast there, either
18:44:26 <mm_freak> mkCurry: i don't see the conversion there‚Ä¶  some code would be useful
18:44:52 <mkCurry> Twey: If I knew how to code it I wouldn't be asking :) Point taken though... let me think about it.
18:45:27 <mm_freak> mkCurry: the problem is that we couldn't make sense of your description‚Ä¶  please try to describe it without using haskell terms
18:45:28 <mkCurry> mm_freak: Currently I call a function read on the class instance... I just don't want to have to read all over, I want the opposite, a function I call to NOT read.
18:45:54 <mm_freak> that made even less sense =)
18:45:58 <mm_freak> (to me)
18:45:58 <ion> ‡≤†_‡≤†
18:46:09 <ion> @type show  -- ? :-P
18:46:10 <lambdabot> forall a. (Show a) => a -> String
18:46:15 <mkCurry> mm_freak: I'm attempting to create a rule based system where each rule is scheduled based on which variables it reads, like Atom'
18:46:34 <mm_freak> mkCurry: what kind of rules?
18:46:46 <mm_freak> i'm not familiar with Atom'
18:47:08 <mkCurry> mm_freak: Synchronous? All rules are run in some order, and then repeated again.
18:47:08 <mm_freak> mkCurry: could you describe the application?  again without haskell terms
18:47:19 <mkCurry> mm_freak: Circuit design.
18:47:27 <mm_freak> ah, now we're getting somewhere
18:47:48 <mm_freak> so a "rule" is an action?
18:48:03 <mkCurry> mm_freak: Yes. And it's scheduled in some order amongst all other actions.
18:48:30 <mm_freak> ok, and the rule accesses some variables, and depending on which variable you want to give it a priority?
18:48:33 <mkCurry> mm_freak: That part is easy, the hard part is making it look nice :)
18:49:00 <mkCurry> mm_freak: I just need to make sure that all rules that read a variable are scheduled after rules that read it.
18:49:10 <mkCurry> Err, write it
18:49:19 <mm_freak> i see
18:49:37 <mm_freak> i'm afraid a monad can't do that at all
18:49:39 <mkCurry> mm_freak: But I don't want to have to type "read var" everywhere, because it's so common
18:50:29 <mm_freak> so it's like a little programming language with actions and mutable variables‚Ä¶  a program is a sequence of actions, where the actions themselves run in a specific order
18:50:37 <mm_freak> the order depends on the structure of the actions
18:50:41 <mkCurry> mm_freak: I figured I could grow a DAG.
18:50:42 <mm_freak> did i get that right?
18:50:48 <mkCurry> Yea.
18:51:11 <mkCurry> mm_freak: Though mutable might not be the right way to think about it.
18:51:26 <mm_freak> write-once, read later
18:51:27 <mkCurry> mm_freak: Since it can act a lot like bind.
18:51:35 <mkCurry> mm_freak: Yes.
18:51:58 <mm_freak> but the actions themselves can appear in any order?
18:52:09 <mm_freak> and must be reordered by your application?
18:52:18 <mkCurry> mm_freak: YEs. The plan is to build up the DAG and process it once the description is complete.
18:52:25 <mm_freak> ok, i see
18:52:27 <mkCurry> The reordering is trivial.
18:52:32 <zzing_> Is there a good clean way of having a multiline string?
18:52:34 <mm_freak> then my design would be this:
18:52:41 <mkCurry> *listening*
18:52:43 <mm_freak> the language for the actions would form an arrow
18:52:54 <mm_freak> and there would be a function to actually order and perform the actions
18:53:15 <mm_freak> zzing_: "x\ny"?
18:53:41 <zzing_> mm_freak, not really clean. I want it to appear as if I pasted the text file in my source code
18:54:26 <mkCurry> mm_freak: I've been trying to understand arrows, and how I could apply them here, over the weekend. I had given up.
18:54:31 <zzing_> I found some code online that used quasiquotes but it didn't work
18:54:47 <mkCurry> mm_freak: It seems as if there need to be two functions to schedule - read & write.
18:55:08 <mm_freak> mkCurry: monads can't encode static informations about a computations
18:55:12 <mm_freak> (>>=) is in your way
18:55:24 <mkCurry> Hmmm.
18:55:29 <mm_freak> arrows can
18:55:47 <mm_freak> mkCurry: my unfinished arrows tutorial:  http://ertes.de/new/tutorials/arrows.html
18:56:06 <mm_freak> zzing_: quasiquotes are your only way
18:56:09 <mkCurry> Reading...
18:56:14 <mm_freak> zzing_: or read the actual file using TH
18:56:40 <zzing_> mm_freak, might be just better for me to read the file in, just have to figure out how packaging works with cabal
18:57:19 <mm_freak> zzing_: there are two options‚Ä¶  one assumes that the files will be needed online, the other only requires the files during compilation
18:57:30 <mm_freak> i think Data-files vs. Other-files, but i'm not sure
18:57:34 <mm_freak> read the cabal docs
18:57:41 <zzing_> Looking now
18:58:44 <mm_freak> zzing_: if the file is very long, i recommend turning it into an object and then use the FFI to turn it into a ByteString
18:58:58 <zzing_> mm_freak, these are shaders
18:59:01 <zzing_> very small
18:59:46 <mm_freak> ok, then QQ/TH seem to be your best options‚Ä¶  with TH you can have separate files, but you will run into a problem
18:59:55 <mm_freak> GHC won't recognize when the shaders have changed
19:01:32 <shirt> why can't i do this: data Foo = Foo (a -> a)
19:01:42 <mm_freak> shirt: because 'a' is not in scope
19:01:48 <mm_freak> data Foo a = Foo (a -> a)
19:02:15 <shachaf> Or data Foo a = forall a. Foo (a -> a), or data Foo a = Foo (forall a. a -> a)
19:02:19 <shirt> mm_freak: right, but that's not what i want. i want a datatype that can hold any function of type (a -> a)
19:02:21 <shachaf> Although it's likely that neither of those is what you want.
19:02:26 <shachaf> Oh.
19:02:31 <shachaf> Then the latter is what you want.
19:02:35 <mm_freak> shirt: that function will be useless, because you can't apply it
19:02:42 <shachaf> (But there's only one such total function.)
19:02:52 <shachaf> Or maybe the former is what you want, depending on what you mean. :-)
19:03:03 <mm_freak> shirt: or rather:  with the existential version (the first option by shachaf) you can't apply it
19:03:12 <mm_freak> with the second option the only possible function is 'id'
19:03:27 <shachaf> id or undefined or const undefined. But that's not very useful.
19:03:37 <mm_freak> in either case it won't be useful =)
19:03:59 <shachaf> shirt: I think the point is that you probably don't want what you think you want.
19:04:05 <mm_freak> shirt: also you have a leftover type variable =)
19:04:11 <mm_freak> data Foo = forall a. Foo (a -> a)
19:04:26 <mm_freak> uhm, that was for shachaf
19:04:26 <shachaf> This is easier to see with a GADT.
19:04:36 <shachaf> mm_freak: Oh, I do.
19:04:42 <shachaf> mm_freak: I was confused by your version!
19:04:52 <shirt> hm.... maybe existentials are what i am looking for...
19:04:59 <shachaf> shirt: No, they probably aren't.
19:05:22 <shachaf> Most of the time, when beginners ask a question in here whose answer is "existentials", they're asking the wrong question.
19:05:24 <mm_freak> shirt: then you want something like:  data Foo = forall a. Foo a (a -> a) (a -> Int)
19:05:32 <mm_freak> otherwise it's a useless type
19:06:05 <shachaf> Note that there are other ways of expressing (exists a. (a,(a -> a),(a -> Int)))
19:06:15 <shachaf> Like (Nat -> Int) :-)
19:06:41 <mm_freak> it can also expressed using universal quantification, but then you have to express it slightly differently
19:07:08 <mm_freak> newtype Foo b = Foo (forall a. a -> (a -> a) -> (a -> Int) -> b)
19:07:23 <shachaf> I think the main question should be: What are you actually trying to do?
19:07:31 <mm_freak> yeah =)
19:07:33 <shirt> i'll try to explain what i'm trying to do...
19:08:53 <shachaf> mm_freak: I think (Nat -> Int) is the nicest way of expressing that type. :-)
19:09:20 <shirt> I have a monad that is: ReaderT Config IO
19:09:30 <mm_freak> shachaf: note that the function could be 'id'
19:09:49 <mm_freak> shirt: wait
19:09:55 <shachaf> mm_freak: What function?
19:10:00 <mm_freak> shirt: try to express it without haskell terms
19:10:11 <shirt> mm_freak: ok:) ...
19:10:14 <zzing_> :t (<<=)
19:10:16 <mm_freak> i.e. explain /what/ you want to achieve, not /how/ ;)
19:10:16 <lambdabot> Not in scope: `<<='
19:10:21 <zzing_> :t (=<<)
19:10:23 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> m a -> m b
19:10:41 <mm_freak> shachaf: data Foo = Foo a (a -> a) -> (a -> Int)
19:10:48 <mm_freak> shachaf: the second argument can be 'id'
19:10:58 <shachaf> You mean forall a. Foo ...?
19:11:04 <mm_freak> uh yeah, of course
19:11:14 <shachaf> Right, it can be id, or it can be (+1) or anything else.
19:11:22 <mm_freak> for 'Foo x f g' you're assuming that f x /= x
19:11:22 <shachaf> But the only thing you can do with it is apply it zero-or-more times.
19:11:32 <shachaf> I am?
19:11:56 <mm_freak> yeah, you're proposing the fixed (!) succ function in place of the variable (!) constructor argument
19:12:12 <shirt> (well, i've already done this in haskell terms, and it works well)l, but anyway, here's what i want: a framework/DSL to be able to write "scripts" that can create/set variables, and do perform a limited set of IO operations
19:12:17 <shachaf> mm_freak: What do you mean?
19:12:30 <mm_freak> shirt: sounds like a free monad
19:12:57 <shachaf> The equivalent of (Foo x id somethingThatTurnsXTo5) is (\_ -> 5)
19:13:07 <mm_freak> shachaf: Foo -> X is more flexible than Nat -> (Nat -> Int) -> X
19:13:17 <shirt> mm_freak: I have this working using a monad that "wraps" IO and restricts the actions, but now i'd like to make an alternative implementation that doesn't use IO and instead uses "mock" actions instead of the IO actions, for testing
19:13:26 <zzing_> My shader compiled. This is definitely a good example of haskell giving you grief at compile time, but just working when it compiles
19:13:39 <shachaf> mm_freak: What's Foo -> X?
19:13:48 <mm_freak> shachaf: nope, it's not‚Ä¶  i can apply the second function a number of times before applying the third
19:14:02 <mm_freak> if it's id, then it's like i never applied it
19:14:03 <shachaf> Oh, and save the thunks?
19:14:13 <mm_freak> this is about semantics, not operation
19:14:23 <shachaf> OK, so that's what the Nat is.
19:14:30 <shachaf> The number of times that you apply the (a -> a) function.
19:14:43 <mm_freak> shirt: yeah, still sounds like a free monad =)
19:14:45 <shachaf> If that function is id, then the (Nat -> Int) function ignores its argument.
19:15:01 <Digit> anyone use hbro?  i just tried it in debian sid, but got segfault.
19:15:14 <shirt> mm_freak: ok thanks i'll read about free monads
19:15:43 <mm_freak> shachaf: i mean think of passing a Foo around as opposed to passing (Nat -> Int) around
19:16:03 <shachaf> mm_freak: I must be missing something.
19:16:06 <mm_freak> shachaf: a function Foo -> Foo can turn the second function f into id or f . f
19:16:36 <shachaf> OK, and a function :: (Nat -> Int) -> (Nat -> Int) can manipulate the Nat.
19:16:47 <shachaf> For example, by always passing 0, or by doubling.
19:16:57 <mm_freak> hmm
19:17:14 <mm_freak> might be true actually
19:17:37 <shachaf> mm_freak: For any Foo, you can construct a (Nat -> Int), and for any (Nat -> Int), you can construct a Foo.
19:17:38 <mm_freak> what about manipulating the actual value?
19:17:50 <shachaf> What can you do with the actual value?
19:17:51 <mm_freak> a Foo -> Foo could turn x into f x
19:18:02 <shachaf> All that means is applying the (a -> a) one more time.
19:18:05 <shachaf> So (+1) on the Nat.
19:18:36 <mm_freak> true
19:19:10 <mm_freak> indeed, i can write conversion functions between the two
19:19:34 <shachaf> There you go. So I can do any Foo-manipulation that you propose by converting a (Nat -> Int) into a Foo first.
19:20:20 <mm_freak> yeah‚Ä¶  that's actually how i found out that LS is equivalent to Auto =)
19:20:31 <mm_freak> data LS a b = LS s ((a, s) -> (b, s))
19:20:36 <mm_freak> uhm
19:20:40 <mm_freak> data LS a b = forall s. LS s ((a, s) -> (b, s))
19:22:02 <shachaf> What's Auto?
19:22:53 <Digit> k0ral: hi, just tried hbro.  got a segfault.  aw.  was really looking forward to it.  likely some pesky debian sid issue.
19:23:48 <mm_freak> shachaf: data Auto a b = Auto (a -> (b, Auto a b))
19:23:49 <\rs> row polymorphism?
19:23:59 <mm_freak> shachaf: a generalized ZipStream basically that forms an arrow
19:24:17 <shachaf> mm_freak: Ah. Makes sense.
19:24:30 <mm_freak> both can be used for continuous computations with local state
19:24:38 <mm_freak> composable that is
19:24:59 <\rs> data Auto a b = Auto (a -> (b, Auto a b)) is a mechanism to encode [a](length==x) -> [b](length==x) ?
19:25:30 <mm_freak> did i write data?  newtype of course
19:30:25 <monochrom> a class that can hold any type, is a class that can't use any type
19:30:55 <shachaf> Unless that class is Seq!
19:33:27 <Durgesh> hi Sir/Madam
19:36:24 <mkCurry> mm_freak: I've seen a lot of Arrow tutorials in the last few days - yours is the best.
19:36:53 <mkCurry> mm_freak: It may help that I've seen others, but yours motivates where as the others don't.
19:36:58 <Durgesh> I am just learning the tutorials
19:37:12 <Durgesh> its quite imperasive
19:37:53 <mm_freak> mkCurry: thanks for the feedback =)
19:38:13 <mkCurry> mm_freak: Thanks for the tutorial :) Not done yet, still more to read.
19:38:22 <mm_freak> mkCurry: now the variables used form the static information of a computation much like the boolean forms the static information in the StateA in the tutorial
19:38:35 <mkCurry> *nods*
19:38:41 <mm_freak> and that's why your action type can't be a monad
19:38:41 <ion> Yeah, that tutorial is great. I look forward to you continuing it.
19:39:09 <mkCurry> Yea, I think one point that particularly helped was pointing out that a monad is just a result, and an arrow is an argument and result. I'd seen that, but didn't pay much attention to the importance.
19:39:48 <mm_freak> mkCurry: you can have that with monads as well‚Ä¶  the main problem is that in c >>= f the 'f' is a function
19:39:58 <mkCurry> mm_freak: Your tutorial combined with the graphics in the Wikibook on Arrows seem to be a great combo.
19:40:14 <mkCurry> Yea.
19:40:37 <mkCurry> mm_freak: Gonna go back into the tutorial... I'll be back again.
19:43:07 <n00b6502> may sound far fetched, but has anyone heard of something for converting a suitable subset of  pure functional code such as haskell into c++
19:44:25 <mauke> like, a compiler?
19:45:38 <ion> No, a decompiler from GHC-generated binaries into C++.
19:45:55 <n00b6502> a translator perhaps
19:46:22 <mkCurry> n00b6502: C++ or is C ok?
19:46:29 <n00b6502> haskell -> internal representaion -> c/c++ -> binary    instead of haskell -> binary -> decompiler
19:46:31 <n00b6502> yes C is ok
19:46:44 <mkCurry> n00b6502: Because GHC can generate C as an intermediate language
19:47:09 <mkCurry> http://www.haskell.org/ghc/
19:47:11 <n00b6502> this might sound balmy but the quetsion crossed my mind whilst writing functional styled templates in c++ (map , filter across vectors, with lazy eval to chain them together)
19:47:27 <n00b6502> ah, ghc CAN create C?
19:47:31 <mkCurry> n00b6502: Yup.
19:47:33 <luite> the C generated by GHC doesn't look like the C you'd expect
19:47:43 <mkCurry> What he said.
19:47:50 <mkCurry> *points at luite*
19:47:50 <n00b6502> but i read something about a C- not exactly C
19:47:51 <luite> it's low level C that implements the STG machine
19:48:05 <luite> Cmm isn't C
19:48:11 <luite> it's much lower level
19:48:17 <n00b6502> like LLVM i think
19:48:18 <luite> a portable assembly language
19:49:21 <luite> (Although Cmm is translated to C in one of the backends)
19:49:32 <mkCurry> n00b6502: It's not a great idea to mix C/++ generated from Haskell with your C++, but there's great support for interop.
19:49:38 <n00b6502> i think i have something of a franken-language in my head
19:50:05 <mkCurry> n00b6502: Look at FFI before trying what you're thinking of trying.
19:50:05 <n00b6502> where this is coming from is trying to write functional style code in c++ ...
19:50:49 <mkCurry> n00b6502: Ahhh. Well, Haskell provides a lot of sugar. You could implement anything you can in Haskell using BF.
19:50:58 <n00b6502> resultVector = someVector.map(somefunc).filter(somethingelse).eval()  ... that sort of thing.. with messy c++ lambdas, and C macros for declaring partial functions on C++ functions
19:51:19 <luite> n00b6502: GHC generates code that doesn't use the C call stack, it manages its own little stacks
19:51:33 <n00b6502> heh ok
19:51:40 <luite> and just jumps back and forth between code fragments, with JMP, not CALL/RET
19:51:41 <scshunt> cactus stacks are fun
19:51:42 <n00b6502> so it can traverse lazy ?
19:51:45 <mkCurry> luite: Didn't know that. Hey - any chance GHC will get growing stacks like Go?
19:52:10 <luite> mkCurry: not sure what those are, but ghc stacks automatically grow as needed
19:52:13 <mkCurry> luite
19:52:17 <luite> there is still a limit though
19:52:18 <n00b6502> is there any visualization of haskell intermediate..
19:52:25 <mkCurry> luite: In Go, the stack is a resizable vector.
19:52:35 <n00b6502> dammit :)
19:52:36 <luite> n00b6502: ghc -c -ddump-stg blah.hs
19:52:41 <luite> n00b6502: or -ddump-cmm
19:52:47 <mkCurry> luite: It grows automatically when it runs out of space. that's how you can have a Go program with a million threads.
19:52:49 <n00b6502> i'm a C++ programmer but just writing a little haskell i'm hooked on its elegance
19:53:03 <luite> mkCurry: yeah ghc does that too
19:53:04 <shachaf> mkCurry: GHC doesn't exactly have "a stack" in the C sense.
19:53:09 <n00b6502> partial function currying  and the mentality of map etc
19:53:13 <mkCurry> kuite: Ahhh, ok.
19:53:22 <luite> mkCurry: stacks start really small, each thread has a stack
19:53:48 <mkCurry> shachaf, luite: Got it.
19:54:52 <mkCurry> n00b6502: Just don't try to convert your co-workers. They'll turn on you ;)
19:55:02 <luite> mkCurry: not quite a C style stack like shachaf said, it contains function arguments and functions, doesn't necessarily get deeper when you call (enter) something
19:55:23 <n00b6502> mkCurry, i've had big arguments on #C++ already
19:55:34 <mkCurry> luite: Do you mean tail-recursion, or something else?
19:55:44 <n00b6502> i dont know enough haskell to drop C++ any time soon... but i'm hooked i think
19:56:01 <luite> mkCurry: something like that, the whole STG machine is implemented in a CPS way, everything is a tail call
19:56:33 <n00b6502> i know haskells way of working is VERY differnt to C++ , but imagine something 'half way between' ... with haskell syntax, a subset of haskell
19:56:39 <mkCurry> luite: Interesting.
19:56:56 <luite> mkCurry: if you pattern match on a thunk (thus force its evaluation), you first push the function that does the case pattern match on the stack, then jump to the thunk
19:57:21 <luite> one the thunk is back to data it loads the patthern match from the stack and jumps to that
19:59:25 <Durgesh> after step 13
19:59:26 <mkCurry> luite: Back to data == generates data?
19:59:38 <Durgesh> its not going to the next lesson ??
19:59:43 <luite> mkCurry: nah i mean if the thunk is reduced to whnf
19:59:55 <luite> mkCurry: so then you have a data constructor, or perhaps a function
20:00:52 <mkCurry> luite: I see.
20:01:07 <mkCurry> luite: It's amazing that with all this going on that Haskell is so performant.
20:01:37 <luite> there are some tricks to make things faster, ghc uses pointer tagging on data constructors and functions
20:02:04 <luite> where the lower bits of the pointer indicate the constructor tag, or the arity of the function
20:02:11 <Durgesh> ohh I got it....hheeh the last step should be typed as it is :P
20:02:22 <n00b6502> mkCurry: is it possible that GHC might emit readable functions where inlinging from composition happens...
20:03:20 <luite> mkCurry: also allocating heap objects is really cheap, just incrementing the heap pointer
20:03:45 <n00b6502> in my C++ "wannabe functional" templates, i made it so you can do result=something.map(f1).filter(f2).eval();  and you get a loop that says if (f2) { result.push_back(f1(src))} .. that sort of thing
20:03:53 <luite> (and a check if the heap pointer is not incremented past the limit)
20:04:16 <mkCurry> n00b6502: I'm one of the least knowledgable people in this room. I'd bet no though.
20:04:18 <n00b6502> i like writing templates but i really like the way type inference seems to work in haskell
20:04:26 <luite> n00b6502: haskell functions will look nothing like that
20:04:58 <n00b6502> i'm thinking i can't be the only one in the world with this going through my mind;
20:05:07 <mkCurry> n00b6502: https://github.com/jaredhoberock/hindley_milner
20:05:08 <luite> Cmm uses registers explicitly to pass function arguments
20:05:34 <mkCurry> n00b6502: Proof that you're not ;)
20:05:35 <luite> or at least the ghc-generated cmm
20:05:53 <n00b6502> does GHC output use GOTO's?
20:06:01 <luite> yes, the Cmm output does
20:06:30 <mkCurry> n00b6502: Don't know the goto. It's better than the comefrom.
20:06:38 <mkCurry> s/know/knock
20:07:04 <luite> STG is still functional, that has just pattern matches with case
20:07:16 <n00b6502> well i can see why you'd use it if you were implementing your own stacks certainly :)
20:07:24 <n00b6502> i'm all for trickery
20:07:38 <mkCurry> n00b6502: Did you see the github link?
20:07:44 <n00b6502> yes i'm reading now..
20:09:05 <n00b6502> i've always wondered if type-inference in a dynamic language could be used to spit out C (instead of using C++ templates..)
20:09:23 <n00b6502> sorry type *tracking*
20:10:01 <n00b6502> build a call-graph from a dynamic (typeless) language, track what types are used at each point, and spit out alternate C code for specific types..
20:10:14 <mkCurry> n00b6502: Not when the types aren't known until runtime. It might depend on data.
20:10:23 <n00b6502> subset that precludes that
20:10:33 <mkCurry> n00b6502: Oh, then sure :)
20:11:15 <mkCurry> n00b6502: Of course the great thing about Haskell is that it's statically typed.
20:11:23 <mkCurry> One of the great things...
20:11:36 <n00b6502> but the type inference is SO good , it feels halfway between templates and dynamic language sometimes
20:12:15 <mkCurry> n00b6502: Yup. FYI, the type inference is also used in ML and OCaml, but Haskell rounds that out with a lot of other nice features.
20:13:17 <n00b6502> i really do like tuples, and partial function applicatoin - these seem to eliminate so much of the declaring, intializing temporary structs that you do in C
20:14:30 <mkCurry> n00b6502: Not just C - any language that doesn't have currying.
20:14:55 <mkCurry> n00b6502: That's why many languages have been adding it, e.g. Python has a library for it now.
20:15:27 <mkCurry> I'm fairly partial to currying myself.
20:15:32 <johnw> is there any handing utility for Haskell that will desugar a function?
20:15:43 <johnw> I'm thinking of something like how I can unmacroize CL code in Emacs
20:15:45 <n00b6502> i've just done some messy #defines in C++ to do it
20:16:13 <n00b6502> #define DEF_PARTIAL3(myFunc, type0,type1,type2) /* declares lots of functor constructors*/
20:16:46 <n00b6502> now just imaging  using a subset of Haskell to write my C++ instead of having messy #defines :)
20:17:04 <mm_freak> n00b6502: why not just use haskell?
20:17:15 <n00b6502> i dont trust GC
20:17:22 <mm_freak> why not?
20:17:27 <ion> ‡≤†_‡≤†
20:17:33 <luite> n00b6502: ghc does something like that
20:17:53 <n00b6502> i would prefer to infer by whole program analysis where stack and single alloc/dealloc can be done, and see where its fallen back to GC (or reference counting perhaps)
20:18:04 <ion> ‚Äú<mkCurry> I'm fairly partial to currying myself.‚Äù I see what you did there.
20:18:12 <mkCurry> ;)
20:18:12 <mm_freak> n00b6502: compiled haskell code will run faster than hand-crafted currying
20:18:16 <luite> it compiles functions with multiple arguments (instead of a fully curried version), and constructs partial applications on the heap if you don't have enough arguments
20:18:49 <n00b6502> are you one of these people claiming haskell can match C++
20:18:53 <n00b6502> for speed
20:19:02 <mm_freak> i am, because i do it
20:19:02 <johnw> n00b6502: can't you just do currying with std::bind?
20:19:11 <n00b6502> i prefer my macros now
20:19:14 <johnw> like bind1st and bind2nd?
20:19:16 <n00b6502> because it looks more like haskelly code
20:19:29 <roconnor_> @type mapAccumL
20:19:31 <lambdabot> forall acc x y. (acc -> x -> (acc, y)) -> acc -> [x] -> (acc, [y])
20:19:33 <mkCurry> n00b6502: I'm reminded of a case study where NASA used garbage collection in a space probe because their deallocation was causing large tail latencies.
20:19:39 <n00b6502> I want a franken language
20:19:54 <mkCurry> n00b6502: Garbage collection introduced less predicatable, but smaller tail latencies.
20:19:56 <roconnor_> @type flip . mapAccumL . flip
20:19:58 <lambdabot> forall acc x y. (x -> acc -> (acc, y)) -> [x] -> acc -> (acc, [y])
20:20:02 <johnw> n00b6502: can't your macros use std::bind?
20:20:10 <johnw> i mean, this is a solved problem
20:20:14 <n00b6502> oh  maybe they'll clean it up a bit
20:20:48 <n00b6502> but the thing is i really did have myfunc(arg1, arg2, arg3) {}  .....    myvector.map(myfunc(a0,a1))
20:20:59 <roconnor_> @type runState . traverse . state
20:21:01 <lambdabot> Not in scope: `traverse'
20:21:06 <roconnor_> @type runState . Data.Traverse.traverse . state
20:21:08 <lambdabot> Couldn't find qualified module.
20:21:09 <n00b6502> insted of myvector.map(bind(myfunc,a0,a1))
20:21:14 <roconnor_> @type runState . Data.Traversable.traverse . state
20:21:15 <lambdabot>     Couldn't match expected type `State s a'
20:21:16 <lambdabot>            against inferred type `t a1 -> f (t b)'
20:21:16 <lambdabot>     In the first argument of `(.)', namely `Data.Traversable.traverse'
20:21:20 <roconnor_> hmm
20:22:59 <n00b6502> GC vs manual management: isn't this just where a program hasn't been re-ordered for memory efficiency
20:23:23 <n00b6502> with lazy-functional rather than imperative description of a program, perhaps you'd actually have more scope to re-order things
20:23:27 <n00b6502> example:-
20:24:28 <mkCurry> n00b6502: I once designed an embedded system that abandoned GC when an interrupt occured.
20:24:29 <n00b6502> vector.filter(pred).map(func) .. could have an implementation where it traverses 'pred' to count the output size, then when 'map' is done it just has one allocation operation and fills in the results
20:24:50 <mkCurry> n00b6502: It had to start over, but we needed hyper low latency.
20:24:56 <n00b6502> i have difficulty visualizing GC being suitable for games
20:25:16 <mkCurry> n00b6502: Games only care about throughput.
20:25:35 <argiopeweb_> I need to apply zipSinks (http://hackage.haskell.org/packages/archive/conduit/0.5.2.3/doc/html/Data-Conduit-Util.html#g:5) on an arbitrary number of sinks. I'm not even sure it's possible with the way the types are set up. Anyone mind throwing some knowledge at me?
20:25:49 <n00b6502> games need predictability
20:26:11 <mkCurry> n00b6502: No - games need predicatability in tens of millisecond units.
20:26:37 <n00b6502> games can be written with minimal use of heap ... just stack within the frame updates
20:27:06 <n00b6502> by re-ordering everything compared to the smallest *code*
20:28:45 <n00b6502> but haskell seems to open up possibilities for re-odering..
20:29:01 <Ralith> n00b6502: many games use GC just fine.
20:29:22 <mkCurry> n00b6502: Haskell has a gotcha, if a lazy evaluation is needed when you don't expect it.
20:29:46 * argiopeweb_ starts counting games written in C# and Java
20:29:56 <n00b6502> any AAA
20:30:04 <n00b6502> on consoles
20:30:37 <n00b6502> games might use C# but with an underlying C++ engine for physics etc
20:31:00 <n00b6502> of course i know many games use LUA
20:31:18 <argiopeweb_> And this is where we argue C++ vs. C vs. Fortran vs. Assembly for the underlying physics engine.
20:31:21 <mkCurry> n00b6502: One could argue they use C++ as a wrapper with an underlying shader engine :)
20:31:33 <n00b6502> heh ok
20:32:21 <n00b6502> physics / collision system is the biggy that jumps out interms of calcuation & use of complex memory layout. pathfinding aswell perhaps
20:32:46 <n00b6502> but haskell has me thinking ...
20:33:33 <Ralith> n00b6502: suddenly we're only considering embedded platforms?
20:33:36 <Ralith> moving goalposts much? :P
20:33:37 <n00b6502> perhaps haskell champions have tried to write such things IN haskell to prove a point :)
20:33:56 <Ralith> I implemented A* with ST the other day, it was fun
20:34:06 <mkCurry> n00b6502: People *clears his through* design circuits in Haskell.
20:34:07 <argiopeweb_> https://www.google.com/search?q=haskell+physics
20:34:23 <mkCurry> s/through/throat (what's up with my brain tonight)
20:36:46 <n00b6502> my perfect franken-language will probably never exist hehe
20:37:54 <mm_freak> in any case performance can't be a reason one would want to prefer C++ over haskell
20:38:09 <mm_freak> haskell is usually as fast as C++ and sometimes faster
20:38:29 <mm_freak> in particular when it comes to concurrency no languages beat erlang and haskell
20:38:30 <mkCurry> mm_freak: Unless performance is a function of programmer agility, e.g. finance.
20:39:02 <mkCurry> What he said *points at mm_freak*
20:39:21 <n00b6502> well one thing i can certainly beleive is Haskell might write a faster program *for a given amount of programmer time*
20:39:22 <luite> hm i kinda disagree with mm_freak here
20:39:34 <mkCurry> luite: Oh?
20:40:00 <mkCurry> luite: Reminds me of a debate at work. Would you prefer to have the algorithms of today and computers of 20 years ago, or vice versa.
20:40:27 <mkCurry> luite: Algorithms of today almost always wins in that argument.
20:40:32 <luite> hm that's an even more pointless debate :p
20:40:42 <n00b6502> correct me if i'm wrong. C++ (including tricks like SIMD intrinsics) can't be beat for speed. The issue is how long it takes to write the program. the other tools we have produce good solutions for finite amounts of programmer time
20:41:07 <mkCurry> n00b6502: Not true. FPGAs :)
20:41:15 <n00b6502> the thing about C++ is, the work is in re-working algorithms for size/speed tradeoffs
20:41:26 <n00b6502> which is why it works especailly well in embedded
20:41:55 <n00b6502> but - it seems haskell might be capable of representing what you later turn into a C++ program
20:42:25 * hackagebot Validation 0.2.0 - A data-type like Either but with an accumulating Applicative (TonyMorris)
20:43:51 <mm_freak> luite: C is better at number crunching, so by extension C++ is better there
20:43:57 <mm_freak> for everything else i found haskell to be faster
20:44:09 <mm_freak> and even for number crunching the difference isn't large
20:44:14 <johnw> and faster with bugs is hard to compare against slower with no bugs
20:44:27 <n00b6502> shouldn't haskell be able to reduce itself to traversing arrays with inlined code just like C
20:44:32 <mkCurry> mm_freak: The shootout website has Haskell running at half speed against C++
20:44:38 <n00b6502> imaybe the compilers arent there yet
20:44:45 <mm_freak> johnw: oh, there is some potential for bugs in numeric code even in haskell, unless you make a DSL for the domain
20:44:56 <johnw> mkCurry: which version of GHC?  and did they try -fllvm?
20:44:59 <argiopeweb_> mkCurry: As far as I know, nobody has given the Haskell code there any love in awhile.
20:45:03 <johnw> plus, Haskell can be easier to parallelize
20:45:11 <mkCurry> johnw: Not likely. And agreed.
20:45:13 <luite> n00b6502: if you count the stack and heap as arrays, and you count everything not using call/ret as inlined, then yes it already does that :p
20:45:15 <n00b6502> parMap is rather nice
20:45:36 <n00b6502> i mean arrays as in collections :)
20:46:25 <mm_freak> also i think they are using an old GHC version for the shootout
20:46:40 <dolio> I wouldn't claim that Haskell is usually as fast or faster than C++, but the shootout isn't going to answer the question.
20:46:41 <mm_freak> GHC-produced code improves noticably with every new minor version
20:46:41 <mkCurry> http://shootout.alioth.debian.org/u64q/which-programming-languages-are-fastest.php
20:46:43 <luite> n00b6502: haskell data doesn't really map well to arrays
20:46:46 <n00b6502> well.. i didn't realize GHC emits C. this is encouraging
20:47:05 <mm_freak> n00b6502: it doesn't
20:47:08 <argiopeweb_> n00b6502: It doesn't any more.
20:47:13 <mm_freak> that's a few versions ago
20:47:17 <n00b6502> ah thats where i was confused
20:47:18 <n00b6502> oh no
20:47:31 <mm_freak> now GHC emits (better) native code
20:47:33 <n00b6502> is there still an optioin for it a mkCUrry mentioned
20:47:33 <argiopeweb_> n00b6502: You'd have a bear of a time modifying it even if it did.
20:48:18 <n00b6502> isn't there a datastructure called 'fingertree' that provides a good halfway house between linklist and flat arrays
20:48:31 <n00b6502> scala peeps were telling me about a 32-ary tree
20:48:42 <luite> mm_freak: looks like it used 7.4.2?
20:49:13 <mm_freak> luite: ok then‚Ä¶  the last time i checked it was GHC 6, while we have been at GHC 7 already
20:49:49 <mm_freak> anyway, my point is:  there are only very few applications, where speed would be the reason to use C++ over haskell
20:49:52 <Rotaerk> hmm, the wikipedia page on finger trees is way too sparse
20:50:07 <argiopeweb_> n00b6502: If you feel it incredibly necessary to have flat arrays, why not use the Data.Array and Data.Vectors of the world?
20:50:39 <mkCurry> mm_freak: And that's where FFI and unsafe IO come in.
20:50:41 <argiopeweb_> mm_freak: And this is why the FFI exists, yes?
20:51:00 <n00b6502> are those ones designed with mutability in mind
20:51:04 <mm_freak> well, i don't think it's /the/ reason for the FFI, but definitely /a/ reason =)
20:51:17 <argiopeweb_> n00b6502: They both provide mutable interfaces.
20:51:26 <Rotaerk> hmm, do you ever *need* to use mutability to improve performance in haskell
20:51:35 <n00b6502> i like the immutable idea.
20:51:35 <argiopeweb_> mm_freak: Valid point.
20:51:38 <Rotaerk> or are there usually purely functional alternatives that perform just as nicely
20:52:05 <mkCurry> Rotaerk: Constant time needs, e.g. hash tables?
20:52:18 <mm_freak> n00b6502: you seem to be very obsessed with arrays‚Ä¶  in haskell array usage is rare, and mostly not the way you would use them in C++
20:52:25 <n00b6502> game update: the bulk of data is immutable. there is a lot workspace. the permanent state is very small so its ok to copy "nextframe=Update(prev_frame, inputs)" IMO
20:52:26 <mm_freak> i do use immutable (!) arrays
20:52:29 <shachaf> "constant time" :-(
20:52:51 <mkCurry> shachaf: Expected constat, see Cuckoo Hashing ;)
20:52:55 <n00b6502> mm_freak i have difficulty visualizing how you could work, say, with efficient polygon meshes without arrays
20:53:12 <mm_freak> n00b6502: what kind of access?
20:53:24 <n00b6502> eg meshes brokwn up into sets that can be indexed with 16bits
20:53:33 <n00b6502> instead of full pointers everywhere
20:53:35 <luite> immutable arrays work fine in haskell
20:53:39 <n00b6502> ok
20:53:44 <mm_freak> yes, but do you actually use the indexing or are you in reality just traversing?
20:54:16 <n00b6502> traversing and indexing
20:54:34 <mm_freak> so when you update a mesh it depends on other meshes?  like CSG?
20:55:00 <n00b6502> its more like immutable mesh stored with acceleration structure for raytraces (KD tree?)
20:55:13 <n00b6502> but trees implemented pointerless.. with indices
20:55:35 <mm_freak> i see‚Ä¶  i would have to start developing before i can choose a data structure =)
20:55:43 <mm_freak> but what you say sounds a lot like IntMap
20:55:45 <n00b6502> i've just come back from arguments on #C++ where thye're convinced you can do everythingwith STDLIB lmao :)
20:56:21 <n00b6502> there's all sorts of compressed representations of cache-coherent trees
20:56:58 <n00b6502> when its working right, compression and cache-coherency have synnergy - small chunks with smaller local references
20:57:28 <n00b6502> what whats intersting is what this might look like ina functional language, e.g. inserting encoder/decoder neatly ..
20:57:38 <mm_freak> in any case the 'vector' library can do that
20:57:46 <adu> aloha help
20:57:46 <adu>  /aloha
20:57:46 <adu> aloha: ?
20:57:53 <n00b6502> result = dosomthing(data)    result=dosomething(decompress(comprseseddata))
20:58:04 <mm_freak> uh
20:58:06 <mm_freak> please
20:58:12 <mm_freak> dosomething data
20:58:20 <n00b6502> hhaahaha
20:58:22 <mm_freak> dosomething (decompress compresseddata)
20:58:26 <n00b6502> {{}{}{}{}{}}}}}{{{}}
20:58:35 <shachaf> Better yet, "something data"
20:58:44 <mm_freak> yeah
20:59:12 <mm_freak> to learn haskell the first thing you need to free your mind of is thinking in terms of actions =)
20:59:16 <n00b6502> its a funny one because i can see the use of brackets NOT for function application is more consistent, in haskell brakcets only ever mean one thing
20:59:27 <shachaf> n00b6502: If only!
20:59:32 <n00b6502> oh
21:00:13 <n00b6502> what does the "vector" library do
21:00:22 <mm_freak> n00b6502: arrays
21:00:28 <argiopeweb_> http://hackage.haskell.org/package/vector
21:00:48 <mkCurry> n00b6502: And if you haven't seen hoogle yet, google it :)
21:01:49 <n00b6502> result=something data       result = something.decompress compressedData             compressedData = compress data
21:02:00 <n00b6502> sizeo of 'data' is important
21:02:12 <mm_freak> n00b6502: btw, that's a syntax error
21:02:19 <mm_freak> "data" is a reserved word in haskell =)
21:02:25 <n00b6502> oh of course
21:02:38 <mm_freak> also the second example is likely a type error
21:02:43 <mm_freak> (f . g) x
21:02:47 <mm_freak> or f . g $ x
21:03:00 <n00b6502> result = something$decompress compressedData ???
21:03:11 <mm_freak> that would work, but it's ugly
21:03:22 <n00b6502> easy to type ugly to read
21:03:54 <mm_freak> also add some more space for readability
21:04:12 <mm_freak> something $ decompress compressedData
21:04:20 <luite> n00b6502: haskell also does streaming processing in small chunks. if it's pure it's very simple function application, if you interleave with IO, the relevant libraries are conduit, pipes and enumerator (a little older)
21:04:25 <n00b6502> some functional langauges has $ but the other way round , right? like a unix pipe ?    decompress compressedData |> dosomething
21:04:57 <mm_freak> ($) is just function application, n00b6502
21:05:00 <mm_freak> f $ x = f x
21:05:10 <argiopeweb_> ($) :: (a -> b) -> a -> b
21:05:11 <n00b6502> isn't it a bracket-saver
21:05:19 <mm_freak> it is =)
21:05:22 <mm_freak> it's both
21:05:22 <n00b6502> f $ g $ x = f(g(x))
21:05:39 <mm_freak> the ($) operator has a low priority
21:05:52 <n00b6502> is there a backwards one , e.g. x | g | f
21:06:00 <mm_freak> as such it binds weaker than (.), so you can write:  f . g $ x
21:06:04 <mm_freak> instead of (f . g) x
21:06:15 <luite> n00b6502: diagrams uses # for that
21:06:25 <n00b6502> ah i 'm not balmy
21:06:26 <luite> but there is not a standard one in Prelude
21:06:30 <n00b6502> i did that aswell
21:06:39 <mm_freak> if you import Control.Category you also get (>>>), which is flipped (.)
21:06:49 <mm_freak> but get used to the right-to-left flow style =)
21:06:53 <n00b6502> x#g#f  = f$g$x ??
21:07:05 <n00b6502> if i do this i'm not being insane ?
21:07:49 <mm_freak> n00b6502: i recommend not trying to write C++ syntax in haskell‚Ä¶  you will eventually find that the way things are written in haskell makes a lot of sense
21:08:06 <mm_freak> just go with the right-to-left style for now‚Ä¶  you get used to it
21:08:07 <shachaf> == mm_freak
21:08:14 <n00b6502> x#g#f is just nice because you're writing it in the order it happens
21:08:19 <n00b6502> even if its lazy
21:08:37 <mm_freak> there is no order‚Ä¶  there is now an inverted dependency
21:08:42 <shachaf> There's some justification to the reversed $ operator.
21:08:47 <mm_freak> but that won't make sense to you right now
21:08:49 <n00b6502> yes
21:08:51 <shachaf> But you shouldn't do C++ in Haskell.
21:08:59 <n00b6502> its a dependancy graph  i get that
21:09:38 <mm_freak> n00b6502: you may find it surprising that f . g can well mean that the effect of 'f' is applied first =)
21:09:49 <n00b6502> how can that be
21:10:00 <shachaf> mm_freak: Pah, f has no effects!
21:10:05 <n00b6502> f.g x = f (g x )  right?
21:10:05 <mm_freak> continuation passing style
21:10:16 <mm_freak> the lens library makes use of that
21:10:25 <n00b6502> ok the 'result' ... the 'dependancy' the 'equation'
21:10:28 <mm_freak> shachaf: not "effect" as in side effect, but the mapping effect
21:10:37 <shachaf> Yes, that's true.
21:10:42 <shachaf> But that mixes everything up.
21:10:46 <n00b6502> ahhh if its a High order function
21:10:50 <n00b6502> with lifting and so on going on
21:11:01 <mm_freak> n00b6502: without lifting, but yes, higher order is the key word =)
21:11:46 <n00b6502> if f x =  x (something else)
21:12:26 * hackagebot Pup-Events-Server 1.1.5 - A networked event handling framework for hooking  into other programs. (DanielWilson)
21:12:46 <n00b6502> what about using the imperative subset of haskell to generate C++ ... like a better template language
21:13:08 <mm_freak> n00b6502: that's not going to work‚Ä¶  you need an expression DSL to do that
21:13:34 <n00b6502> perhaps I want to  use a subset of haskell as an expression DSL
21:14:00 <mm_freak> you would express the DSL in haskell, unless you want to write a haskell compiler =)
21:14:00 <n00b6502> garbage collection is the sticking point for me
21:14:19 <n00b6502> subset of haskell compiler
21:14:20 <mm_freak> don't worry about the garbage collection‚Ä¶  it mostly does exactly what you would have done manually in C++
21:14:39 <n00b6502> let me cut paste that in #c++ and see what they say...
21:15:00 <mm_freak> whatever they say, make sure that they know haskell first
21:15:20 <argiopeweb_> And have preferably hacked on the reference compiler.
21:15:29 <mm_freak> unlike in most languages like C# the GC in haskell is not an addon feature or something like that‚Ä¶  it's an integral feature of the way your code executes
21:15:30 <n00b6502> i had a long argument on #c++ based on this idea:-
21:15:38 <luite> still it's often possible to write inner loops in C++ that do no dynamic allocation, while it's usually impossible to do the same in haskell, except really trivial cases
21:15:44 <n00b6502> if you were to start language again, you wouldn't write C++. you'd stop at C, and write something else
21:16:18 <n00b6502> luite: of course. fast inner loops would never have memory operations
21:16:19 <argiopeweb_> n00b6502: I would have been fine with Lisp.
21:16:39 <n00b6502> thats what i'm getting at ... i would like to see if haskell can generate the same
21:16:46 <mm_freak> luite: haskell uses the heap, but other than that it does the same thing‚Ä¶  what is the stack in C++ is the heap in haskell, and they are used in a very similar style
21:16:57 <mm_freak> again, don't compare how C++ code executes to haskell
21:17:05 <mm_freak> haskell programs don't even have a call stack!
21:17:14 <mm_freak> much less a stack for local variables
21:17:20 <mm_freak> the whole concept does not make sense in haskell
21:17:25 <n00b6502> ah, now i recall Haskell has synergy between GC and immutability doesn't it
21:17:28 * hackagebot Pup-Events-Client 1.1.3 - A networked event handling framework for hooking  into other programs. (DanielWilson)
21:17:41 <n00b6502> immutabiltiy lets it make some assumptions in tracing that other langauges can't ?
21:17:43 <luite> mm_freak: no it's not the same, heap allocations are dynamic, heap objects are only deallocated when the garbage collector runs
21:18:07 <mm_freak> luite: heap allocations may not happen at all
21:18:18 <mm_freak> you should check out the STG paper
21:18:24 <luite> mm_freak: only in really trivial situations they don't happen at all
21:18:25 <n00b6502> inner loops will not consult memory managemetn datastructures
21:18:33 <n00b6502> when a program is working right
21:18:43 <luite> mm_freak: they happen often enough for ghc to make thread scheduling dependent on heap allocation
21:18:57 <luite> if the allocation area is never filled, other threads never get scheduled
21:19:20 <mm_freak> n00b6502: GHC is not working with assumptions other than that your code is pure‚Ä¶  the produced could would scare you away, because it doesn't look anything like C
21:19:27 <mm_freak> no functions, not even returns
21:19:48 <luite> sometimes people report problems there, but they usually have a really tight loop, forever (return ()) or something
21:20:03 <mm_freak> luite: that's why i always compile with -threaded
21:20:31 <ion> System.IO.sleepReallyHard = forever (return ())
21:20:37 <Guest90348> @src forever
21:20:37 <lambdabot> Source not found.
21:20:43 <ion> forever a = a >> forever a
21:21:19 <luite> mm_freak: hm i'm not sure that really helps
21:21:31 <mm_freak> luite: the cases where it happens may be simple, but far from trivial‚Ä¶  also the usage of the word "trivial" is very wrong
21:21:58 <mm_freak> trivial would be something like x = x
21:21:58 <luite> should i have said degenerate?
21:21:58 <Guest90348> ion: so if i have a forever loop, and at some point it 'executes' an IO action that goes into an infinite loop, will that >> forever a ever be reclaimed?
21:22:02 <mm_freak> and that one would <<loop>>
21:22:22 <mm_freak> Guest90348: no
21:22:36 <Guest90348> so if the actions continue to 'exit' by calling other loops
21:22:44 <n00b6502> mm_freak i do remember coding in ASM, non-idiomatic C wont scare me away
21:22:55 <Guest90348> ill get an expanding memory leak
21:23:19 <mm_freak> Guest90348: a better implementation looks like this:  forever c = let fc = c >> fc in fc
21:23:41 <Rotaerk> n00b6502, but it should digust you
21:23:43 <mm_freak> that has one additional thunk that lives in memory, until an exception is raised
21:24:01 <n00b6502> no crazy non-idiomatic tricks do not disgust me, they facscinate me
21:24:14 <n00b6502> idomatic, by the rules disgusts me :)
21:24:33 <Guest90348> mm_freak: how is this better
21:24:43 <mm_freak> n00b6502: that's true for other languages‚Ä¶  in haskell actually the idiomatic fascinates me =)
21:24:56 <n00b6502> heh ok
21:25:07 <mm_freak> Guest90348: less memory, faster
21:25:42 <Rotaerk> well I do tend to break idioms a lot in C#
21:25:47 <Rotaerk> for instance I mostly use structs
21:25:49 <ion> It‚Äôs important for forever (return ()) to be as fast as possible.
21:26:06 <mm_freak> when would you use that?
21:26:41 <Guest90348> mm_freak: im trying to make an interpreter that can change states, by getting a command, casing on the it, then either repeating or entering a different look (which might in turn return to this loop by simply executing it)
21:26:54 <Guest90348> but now im wondering how to avoid memory leaks
21:27:02 <Guest90348> i figured laziness would automatically save me but maybe not
21:27:36 <mm_freak> Guest90348: it will =)
21:27:49 <mm_freak> you can make a DSL that has the exact semantics you want
21:27:54 <nand`> isn't laziness usually detrimental to memory usage rather than beneficial? unevaluated thunks etc.
21:28:22 <mm_freak> no, i make heavy use of lazy evaluation
21:28:23 <Guest90348> im not trying to reduce memory usage, im trying to not leak memory
21:28:32 <mm_freak> Guest90348: you won't
21:29:00 <Guest90348> but if i use forever, wont that lead to unevaluated >> forever a, or >> fc
21:29:08 <Guest90348> dangling
21:29:17 <mm_freak> Guest90348: it can't
21:29:32 <Guest90348> implementation cant know that it will never complete the loop
21:29:33 <mm_freak> either there is exactly one unevaluated thunk or the forever has been left
21:29:54 <mm_freak> anyway, what you want to do sounds like coroutines to me
21:29:55 <n00b6502> will GHC emitted   C show how much inlining is being done
21:30:01 <mm_freak> see the monad-coroutine package
21:30:05 <mm_freak> @hackage monad-coroutine
21:30:06 <lambdabot> http://hackage.haskell.org/package/monad-coroutine
21:30:24 <Guest90348> no, im not interested in returning to a previous action
21:30:26 <mm_freak> n00b6502: you don't need to look at the C code to figure that out (because it will be hard to find out there anyway)
21:30:32 <mm_freak> n00b6502: look at the core output
21:30:36 <mm_freak> @hackage ghc-core
21:30:37 <lambdabot> http://hackage.haskell.org/package/ghc-core
21:30:52 <mm_freak> Guest90348: so whenever the loop is changed, the old one is forgotten?
21:31:12 <Twey> nand`: Laziness is beneficial to memory usage so long as you consume what's produced
21:31:13 <Guest90348> mm_freak: yes
21:31:17 <n00b6502> could you build an AAA style game engine in haskell
21:31:23 <Guest90348> hopefully
21:31:28 <Twey> nand`: Strictness is one way to consume ‚ò∫
21:31:32 <mm_freak> Guest90348: so effectively it's a language with a 'goto' instruction that allows you to enter another loop, correct?
21:31:41 <luite> n00b6502: not without a lot of groundbreaking work
21:31:41 <Twey> @faq Could you build an AAA style game engine in Haskell?
21:31:41 <Guest90348> yes
21:31:42 <lambdabot> The answer is: Yes! Haskell can do that.
21:31:50 <mm_freak> Guest90348: then it still sounds like coroutines to me
21:32:01 <Twey> What is an ‚ÄòAAA‚Äô game engine?
21:32:09 <mm_freak> Guest90348: you may have a very specialized idea of coroutines
21:32:18 <nand`> Twey: I think he means stuff like Unreal Engine, CryEngine, etc.
21:32:20 <shachaf> Coroutines are pretty expressive.
21:32:21 <n00b6502> yes
21:32:25 <Guest90348> im sure, but i think IO works fine, as long as calling a new loop from existing loop wont keep recursing into a expanding thunk
21:32:36 <Twey> nand`: So‚Ä¶ a game engine?
21:33:03 <Twey> Guest90348: It doesn't
21:33:05 <n00b6502> yes. scene management, animation evalutaion, 3d world collision
21:33:06 <nand`> one with lots of bells and whistles, yes
21:33:07 <mm_freak> Guest90348: another option is to use ContT
21:33:15 <Guest90348> yeah i thought about continuations
21:33:15 <shachaf> I'm afraid Haskell is limited to AA games or less.
21:33:24 <Guest90348> then i ran away scared
21:33:24 <mm_freak> Guest90348: when a 'goto' is found, just ignore the continuation and switch to something else
21:33:30 <Twey> Guest90348: The runtime consumes your IO value as it's executed
21:33:36 <mm_freak> coroutines also use CPS
21:33:47 <shachaf> mm_freak: One implementation of them does, anyway.
21:33:52 <mm_freak> true
21:33:57 <mm_freak> monad-coroutine uses CPS
21:34:09 <Guest90348> Twey: in particular i was asking about the implementation of forever as forever a = a >> forever a
21:34:14 <mm_freak> anyway, CPS is very natural for both coroutines and Guest90348's application
21:34:17 <Guest90348> if a happens to never complete
21:34:18 <Guest90348> ...
21:34:33 <Twey> Guest90348: I know
21:34:49 <Twey> Guest90348: If a never completes then the thunk ‚Äòforever a‚Äô remains unevaluated
21:34:50 <Guest90348> what happens to the >> forever a
21:34:55 <n00b6502> i think at this point i would even like a c like language with haskell style type inference instead of macros/templates; + tuples, partialfunctions :)
21:35:05 <mm_freak> Guest90348: as said, it stays in memory
21:35:05 <Twey> Guest90348: It hangs around, as a single thunk in small constant space
21:35:17 <Guest90348> yeah but if a is forever b
21:35:24 <Guest90348> which may eventually do forever c
21:35:27 <Rotaerk> n00b6502, C and type inference? C doesn't even have types...
21:35:27 <ion> twey: An ‚ÄúAAA game‚Äù refers to one of those huge-budget blockbuster games.
21:35:29 <mm_freak> perhaps some day GHC will solve the halting problem, but until then the thunk remains there =)
21:35:34 * Twey chuckles.
21:35:35 <Rotaerk> well not many
21:35:35 <n00b6502> c/c++
21:35:36 <nand`> n00b6502: program Haskell for a few months and reevaluate :)
21:35:50 <Twey> Guest90348: If you have an infinite number of loops then your program will take an infinite amount of memory, yes ‚ò∫
21:35:51 <Guest90348> so this implementation of forever is not good
21:35:57 <mm_freak> n00b6502: in other words, you want haskell =)
21:35:59 <Guest90348> ah bad
21:36:11 <n00b6502> no i want manual memory management
21:36:30 <mm_freak> n00b6502: a C-like language with strong static typing, type inference and tuples and partial function application sounds like the IO monad ;)
21:36:35 <Twey> Guest90348: You can't have an implementation that doesn't
21:36:37 <n00b6502> but functional style instead of iterators now
21:36:44 <mm_freak> n00b6502: there is Foreign.Marshal if you insist on manual memory management
21:36:56 <Guest90348> Twey: meh. so manual recursion it is
21:37:00 <n00b6502> hah ok. "the imperative subset of haskell"
21:37:03 <Twey> Guest90348: If you didn't keep the thunk around, then if a *did* complete it wouldn't know what to do next
21:37:10 <Guest90348> right
21:37:12 <Twey> Guest90348: Manual recursion won't be any better
21:37:26 <Guest90348> ... then i need continuations
21:37:32 <Twey> ‚Ä¶ no?
21:37:36 <Guest90348> god dammit
21:37:42 <mm_freak> Twey: manual recursion sounds fine to me
21:37:50 <mm_freak> it's a valid way to do it, just not very convenient
21:37:51 <Guest90348> confuzzled
21:37:58 <mm_freak> i think coroutines are the most convenient way to do it
21:38:06 <Twey> mm_freak: Implementing forever by using manual recursion won't solve any problems that forever might have
21:38:17 <mm_freak> have a small switcher enveloping the actual interpreter
21:38:32 <mm_freak> Twey: ah, i was talking about Guest90348's application
21:38:32 <Twey> Coroutines are surely an option
21:38:45 <Guest90348> loopA = case c of X -> loopA, Y -> loopA, Z -> loopB
21:39:22 <mm_freak> Guest90348: with monad-coroutine you would have a function 'switchTo', which takes an alternative interpreter as argument
21:39:33 <Guest90348> interesting
21:39:37 <mm_freak> that's about as convenient as you can get =)
21:39:48 <n00b6502> how is haskell for boilerplate in serialization.
21:39:55 <Guest90348> did what i type avoid a memory leak
21:39:56 <Twey> n00b6502: You might want to have a look at ATS
21:40:14 <mm_freak> n00b6502: there are several good libraries
21:40:18 <mm_freak> i like cereal most
21:40:20 <n00b6502> i know haskell 'records' are limited
21:40:36 <n00b6502> what i really like is the idea of lisp macros
21:40:42 <mm_freak> n00b6502: they aren't limited‚Ä¶  it's just that advanced features are not language features in haskell =)
21:40:47 <n00b6502> declare a schema and expand out various bits of code and data from that
21:41:05 <mm_freak> Guest90348: yes
21:41:07 <Twey> n00b6502: ATS has Lisp-style macros.
21:41:18 <n00b6502> ah.. now i'm intereste
21:41:37 <Twey> (albeit not on a Lisp-style syntax)
21:41:37 <mm_freak> ATS has about the ugliest syntax i've ever seen
21:41:39 <Twey> Haskell does, too.
21:41:44 <Twey> mm_freak: I know, right :-D
21:41:59 <Guest90348> k i think i understand now
21:42:05 <Twey> viewt@ype!
21:42:18 * Guest90348 wonders about using ContT with IO instead ;)
21:42:19 <mm_freak> Guest90348: note that switchTo can be implemented using ContT, too
21:43:23 <Guest90348> yep thats the plan
21:43:35 * Guest90348 descends into CPS
21:43:50 <n00b6502> so with GC and lazy eval   something which consumes one immutable collection to produce another can basically build the result while freeing up the source ?
21:44:01 <mm_freak> Guest90348: might look something like:  switchTo (ContT f) = ContT (\_ -> f return)
21:44:30 <mm_freak> note that the final continuation (the one you pass to runContT) is ignored
21:44:38 <mm_freak> so don't do cleanup there =)
21:44:44 <Guest90348> heh
21:45:05 <argiopeweb_> n00b6502: Assuming you aren't using the original immutable collection elsewhere, generally yes.
21:45:42 <n00b6502> and there might be some structures (like fingertrees?) that can do that and have reasonable indexing too?
21:46:00 <Guest90348> mm_freak: so forever in a ContT wont leak?
21:46:14 <Enigmagic> n00b6502: Data.Sequence.Seq in the containers package is a type of fingertree
21:46:17 <mm_freak> Guest90348: it has the potential not to leak
21:46:50 <mm_freak> Guest90348: if you use the side exit by ignoring the continuation, then the 'forever' is left and thus garbage-collected
21:46:51 <n00b6502> is Seq suitable as a 'default' datastructure.. if in doubt use that
21:47:05 <mm_freak> n00b6502: you're still thinking in C++
21:47:08 <mm_freak> n00b6502: read LYAH
21:47:10 <mm_freak> @where lyah
21:47:10 <Guest90348> i love it
21:47:11 <lambdabot> http://www.learnyouahaskell.com/
21:47:12 <Enigmagic> n00b6502: no
21:47:16 <n00b6502> will it have less pointeroverhead than lists
21:47:38 <ion> If that‚Äôs significant for your data, use neither.
21:47:56 <mm_freak> n00b6502: haskell doesn't fall for the fallacy that there can be /any/ suitable "default" data structure
21:48:04 <argiopeweb_> n00b6502: Of course, though I generally seldom find myself needing to index a data structure when writing idiomatic Haskell.
21:48:07 <Guest90348> php arrays of course
21:48:24 <mm_freak> yeah, idiomatic haskell seldomly requires indexing
21:48:45 <mm_freak> even if you would use indexing in equivalent C++ code
21:48:53 <n00b6502> again i find it difficult to imageine polygon meshes without indexing :)
21:49:14 <argiopeweb_> n00b6502: Then use IntSet or Vector.
21:49:20 <n00b6502> ok
21:49:26 <argiopeweb_> Just because you don't generally need it doesn't mean you can't use it.
21:49:52 <n00b6502> can you also map/ filter on that.. or was it "fmap" or something, the generalized version..
21:50:10 <mm_freak> n00b6502: haskell programming bends your mind enough that you will find entirely new ways of approaching problems
21:51:08 <mm_freak> n00b6502: you may find yourself surprised how many problems can be solved much more easily and elegantly using folds and unfolds
21:51:21 <n00b6502> oh i'm totally sold on high order functinos
21:51:34 <n00b6502> i never want to write another iteration again :)
21:51:46 <mm_freak> hehe yeah, i can understand that =)
21:51:58 <n00b6502> iteration is clunky and ugly
21:52:05 <mm_freak> and error-prone
21:52:22 <n00b6502> and precludes parallelism
21:52:50 <n00b6502> haskell has a "tree like fold " doesn't it on that note,
21:53:20 <n00b6502> (((A +B)+(C+D))+((E+F)+(G+H)))
21:53:23 <mm_freak> folds are concept applicable to any data type‚Ä¶  and they are not a language feature of course
21:53:36 <n00b6502> i dont mean fold on tree- i mean tree-like fold
21:53:42 <mm_freak> in fact combinators like 'maybe' and 'either' are folds for their respective types
21:53:56 <mm_freak> what is a tree-like fold?  a fold is a particular operation on a data structure
21:53:57 <n00b6502> ah now i remember - thats why i want fingertree as default datastructure
21:54:11 <n00b6502> a tree-like fold is that i posted above
21:54:28 <n00b6502> e.g. find the min of A B C D E F G H
21:54:45 <n00b6502> (min (min (min A B)  (min C D)...etc
21:54:57 <mm_freak> what's the data structure?
21:55:03 <n00b6502> anything
21:55:09 <mm_freak> folds are tightly bound to their data structure
21:55:13 <n00b6502> the core concept is the dependanciy is treelike
21:55:19 <mm_freak> Maybe is folded with 'maybe'
21:55:24 <mm_freak> Either is folded with 'either'
21:55:28 <mm_freak> [] is folded with foldr
21:55:32 <mm_freak> etc.
21:55:41 <n00b6502> i'll try again to explain:-
21:55:48 <mm_freak> perhaps what you want is not a fold =)
21:55:52 <n00b6502> given A B C D;
21:55:56 <mm_freak> but rather some divide/conquer algorithm
21:56:16 <n00b6502> if you want to find the min eement  - instead of computing min(A,min(B,min(C,D)))
21:56:25 <n00b6502> computing min(min(A,B),min(C,D))
21:56:28 <n00b6502> has more parallelism
21:56:43 <n00b6502> in the first example each calculation wats for the result
21:56:53 <mm_freak> a fold on a tree can do that
21:56:55 <n00b6502> of the prev. whereas in the second example, 2 can go in parallel
21:57:09 <n00b6502> but what i want is a tree-like-fold on a flat datastructure :)
21:57:22 <mm_freak> you may be interested in 'repa'
21:57:30 <mm_freak> transparently parallelized arrays in haskell
21:58:07 <n00b6502> ah this is another case where "nice default datatructure" in mind
21:58:18 <n00b6502> list sort of implies serial traversal
21:58:45 * liyang thinks n00b6502 is after Foldable (fold)
21:58:47 <n00b6502> arrays are easier to parallelise
21:58:59 <mm_freak> you do this very often in haskell‚Ä¶  so often in fact that an optimization called deforestation gets rid of actual in-memory lists as far as possible
21:59:09 <n00b6502> i have the word "tree like fold" in mind after reading it in haskel guide somewhere i think
21:59:15 <mm_freak> a list operation is likely compiled to a tight loop in haskell
21:59:35 <n00b6502> ah "deforestation" - ... turns lists into arrays where possible, transparently?
21:59:45 <n00b6502> removes pointeres by placing them sequentially?
22:00:48 <mm_freak> n00b6502: no, deforestation removes the data structure entirely
22:01:24 <n00b6502> ah thats very interesting
22:02:01 <mm_freak> n00b6502: for example:  head . filter f . iterate g $ x0
22:02:07 <mm_freak> the list is compiled away entirely
22:02:13 <mm_freak> what remains is a tight C-like loop
22:02:30 <n00b6502> ok will isee that in the GHC output :)
22:02:49 <n00b6502> whats x0, a list ?
22:02:57 <n00b6502> whats 'iterate g'
22:02:59 <latro`a> @type iterate
22:03:00 <lambdabot> forall a. (a -> a) -> a -> [a]
22:03:02 <mm_freak> a value
22:03:11 <mm_freak> > iterate (2*) 1
22:03:13 <lambdabot>   [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,...
22:03:21 <latro`a> iterate f x = x:iterate f (f x)
22:03:32 <n00b6502> ah nie
22:03:33 <n00b6502> nice
22:03:40 <latro`a> so that's probably something like
22:03:51 <latro`a> while not f(x0): x0 = g(x0)
22:03:53 <latro`a> ?
22:04:14 <n00b6502> i was thinking that, where you have  a [1..] in haskell it should really signify generating a loop somwhere
22:04:30 <MostAwesomeDude> .tell edwardk Wait, so there's no "focus" in lens? Or did I miss it somewhere?
22:04:36 <latro`a> mm_freak,
22:04:43 <latro`a> did you mean a loop like that one?
22:04:46 <MostAwesomeDude> Oh, whatever, I'll ping him tomorrow.
22:05:03 <mm_freak> latro`a: with a break condition, yes
22:05:07 <n00b6502> [1..] = iterate (1+) 1?
22:05:10 <n00b6502> >iterate (1+) 1
22:05:13 <latro`a> um
22:05:25 <latro`a> I already have the break condition no?
22:05:37 <latro`a> or do you mean a test for the case f(x0)
22:05:49 <latro`a> erm no that case is there too
22:06:01 <luite> mm_freak: it doesn't optimize away the list with -O2 in ghc 7.4.2
22:06:17 <mm_freak> head . filter f . iterate g
22:06:21 <mm_freak> that's the code
22:06:32 <luite> something f g x0 = head . filter f . iterate g $ x0
22:06:36 <luite> this is what i compiled
22:06:46 <latro`a> you mean
22:06:55 <latro`a> h f g = head . filter f . iterate g
22:06:59 <latro`a> ^is what you meant
22:07:12 <mm_freak> latro`a: that's the same thing
22:07:15 <mm_freak> i wonder why it doesn't
22:07:37 <mm_freak> perhaps 'head' is the problem‚Ä¶  try 'find' instead of head . filter f
22:08:14 <n00b6502> it is a shame haskell can't use . for record acess. just using another symbol for composition would have been nice
22:08:25 <mm_freak> n00b6502: it can =)
22:08:30 <nand`> n00b6502: you mean like foo^.bar.bat.baz ?
22:08:35 <mm_freak> hehe
22:08:37 <n00b6502> ah can you override it :)
22:08:45 <mm_freak> n00b6502: it's not overridden ;)
22:08:49 <n00b6502> is . defined in library code
22:08:53 <mm_freak> yes
22:08:57 <nand`> . is from base
22:09:09 <mm_freak> (.) is defined like this:  (f . g) x = f (g x)
22:09:14 <mm_freak> and that's the one nand` used =)
22:10:06 <nand`> to demystify: n00b6502: See Control.Lens from package ‚Äòlens‚Äô
22:10:37 <n00b6502> when i was messing with haskell i defined   a # b = b a
22:10:54 <n00b6502> for that purpose
22:11:05 <n00b6502> perhaps i needed to mess with infix precedence
22:12:36 <luite> mm_freak: find doesn't seem to help
22:12:46 <mm_freak> weird
22:13:38 <n00b6502> scala's retrofit of partial application to clike syntax was interesting,  foo(a)(b)
22:13:40 <luite> this is from the Cmm output, the NCG can still optimize after that, but i don't think it can do anything like deforestation :)
22:14:00 <n00b6502> i could live with that in my perfect language
22:14:24 <nand`> seems needlessly verbose compared to foo a b
22:14:53 <luite> n00b6502: keep in mind that ghc doesn't actually compile to foo(a)(b), in such a case it would just compile foo as an arity 2 function
22:14:55 <mm_freak> i wonder where deforestation is done then, and why the code is just as fast as a recursive function for me
22:15:11 <luite> mm_freak: in core
22:15:21 <mm_freak> perhaps the STG optimizes the constructors away, so deforestation is not actually needed
22:15:31 <mm_freak> after all you never have more than the head of the list
22:15:31 <luite> Cmm is after STG
22:15:36 <n00b6502> can haskell spit out ARM asm
22:15:38 <mm_freak> hmm
22:15:41 <mm_freak> n00b6502: yes
22:15:44 <mm_freak> GHC can
22:16:08 <n00b6502> nice
22:16:26 <mm_freak> just recently there was a success story on reddit about GHC on the raspberry pie
22:16:29 <mm_freak> pi
22:16:57 <n00b6502> i guess haskell's inliner will work better when it can reason about register use directly rather than going through C
22:17:11 <n00b6502> if its that advanced
22:17:39 <mm_freak> the inliner doesn't have to rely on that i think‚Ä¶  again, STG produces code that looks nothing like well-separated functions
22:18:06 <n00b6502> a perfect compiler will be making inlining decisions based on that sort of thing
22:18:19 <mm_freak> and size
22:18:31 <n00b6502> eg boundary between where to touch memory with temporaries.
22:18:45 <n00b6502> stick functions together so long as locals stay in registers
22:19:00 <mm_freak> anyway, inlining doesn't make much of a difference in haskell, because it really just saves a JMP
22:19:13 <n00b6502> what i just said above is why it should
22:19:20 <mm_freak> functions are extremely lightweight in haskell
22:19:36 <n00b6502> can haskell use the full register file...
22:20:18 <n00b6502> "<mm_freak> anyway, inlining doesn't make much of a difference in haskell, because it really just saves a JMP"
22:20:52 <n00b6502> in C like compiling you can get 'leaf' functions called by 'branch' functions with no memory useage,
22:20:53 <luite> inlining makes a lot of difference since it can often specialize functions. it's also required for deforestation in vector
22:21:09 <luite> and inlining can make a lot of unknown calls known
22:21:14 <n00b6502> i.e. leaf functions use half the registers, branch functions use the other half
22:21:20 <mm_freak> luite: you don't need inlining for the specialization
22:21:22 <luite> for example the find/filter in the previous iterate example is inlined
22:21:31 <n00b6502> branch calling branch has to save registers, whereas branch calling leaf does not
22:21:34 <mm_freak> the inlining itself is really a simple thing in haskell
22:21:38 <luite> in which case the function you filter on is known
22:21:39 <ion> I‚Äôd guess inlining can help with polymorphic values.
22:21:49 <n00b6502> inlining can help with all sorts
22:21:53 <mm_freak> n00b6502: you're still thinking in C-like separate functions
22:21:56 <luite> oh i guess in this case that's not true, since f is supplied by the user again
22:22:10 <n00b6502> mm_freak, i'm thinking in terms of mapping algorithms to  machine code now...
22:22:23 <mm_freak> n00b6502: yes, but then you should really first read the STG paper
22:22:33 <luite> but if you do an inline of filter f xs, with a known f, then you can make a faster call to f
22:22:39 <luite> since you know its arity statically
22:22:45 <n00b6502> when temporaries are in registers the compiler (and possibly OOO hardware) has an easier time parallelizing
22:23:11 <n00b6502> when temporaries go through memory, more work is being done to figure out if they're independant
22:23:12 <luite> this is not in the STG paper btw, but in the later push/enter vs eval/apply paper
22:23:32 <mm_freak> yeah, but the STG paper introduces the basic idea
22:23:52 <mm_freak> and the reason why you really should think very differently in haskell
22:24:04 <n00b6502> i'm  going to think in ASM first and foremost :)
22:24:08 <mm_freak> for example it tells you why GHC does /not/ do TCO =)
22:24:12 <n00b6502> C is shortcut for ASM and C+++ shortcut for C
22:24:18 <luite> right, but if you don't eval/apply (which is what ghc uses now), you lose that benefit of inlining
22:24:18 <n00b6502> you can build lazy-eval systems in C
22:24:46 <n00b6502> ok example:-
22:24:48 <luite> if you inline a function so that more function calls are known, you skip a few checks for thunk type and function arity, so it's a lot faster
22:25:03 <n00b6502> map (+3).(*2) src
22:25:07 <mm_freak> i see
22:25:19 <n00b6502> between all the thunks and inining, you want the constants '3' and '2' to stay in registers
22:25:20 <latro`a> that doesn't typecheck
22:25:24 <mm_freak> luite: but that's only in the presence of type classes, right?
22:25:32 <latro`a> unless List is apparently Num
22:25:33 <luite> mm_freak: no polymorphism in general
22:25:57 <n00b6502> map ((3+).(2*)) src perhaps
22:26:25 <mm_freak> for compositions there really should be prefix variants of (+), (*), etc.
22:26:42 <n00b6502> i'm happy to make 'add' 'mul' functions
22:26:48 <mm_freak> map (plus 3 . times 2) src
22:27:31 <n00b6502> i'm also happy with functions like le, gt , lt , ge , eq, ne   for comparison operators
22:27:45 <n00b6502> i still write those in C to this day due to having coded asm as a kid
22:28:04 <n00b6502> those abreviations
22:28:09 <mm_freak> i'm happy with the infix variants of those, because you seldomly compose them directly
22:28:13 <luite> mm_freak: if you generate polymorphic code for map f xs, you don't know the arity of f statically, the result might be a list of functions. so you cannot just load one list element in a register and apply f. you have to check the arity first, and possibly construct a partial application
22:28:29 <mm_freak> rather something like this:  liftA2 (&&) (> 3) (<= 10)
22:28:38 <mm_freak> > liftA2 (&&) (> 3) (<= 10) 9
22:28:39 <lambdabot>   True
22:28:55 <mm_freak> luite: i see
22:29:15 <n00b6502> hahah you haskellers have me seeing <= as something different now its an arrow not a comparison
22:29:25 <latro`a> lol
22:29:35 <n00b6502> it freaks me out when i look at c++ now
22:29:47 <mm_freak> n00b6502: that one is actually an operator =)
22:29:48 <n00b6502> for ( i=0; i<=10; i++) { /* WTF!!! */
22:29:52 <mm_freak> but => is an arrow
22:30:03 <mm_freak> and >= is an operator
22:30:28 <n00b6502> then there's >>= isn't there , at least thats unique
22:30:56 <mm_freak> > let (#!~#) = (+) in 3 #!~# 4
22:30:58 <lambdabot>   7
22:30:58 <latro`a> shame on you for using <= in a for loop anyways
22:30:59 <latro`a> :p
22:31:09 <n00b6502> < ok
22:31:35 <mm_freak> shame on you for using a for-loop =)
22:31:40 <latro`a> lol
22:32:21 <n00b6502> c++ range based for is still very new
22:32:30 * hackagebot tardis 0.3.0.0 - Bidirectional state monad transformer (DanBurton)
22:33:02 <latro`a> is that a new or an old version of tardis?
22:33:23 <latro`a> (really lame joke)
22:35:24 <mm_freak> RState hurts my brain
22:35:46 <ion> Did you see Tardis?
22:35:54 <mm_freak> yes, that's why i'm bringing it up =)
22:36:01 <latro`a> mm_freak, it's just corecursion :p
22:36:10 <ion> Ah, i missed hackagebot‚Äôs line above.
22:36:13 <latro`a> the new value corecurses with the old state, basically
22:36:24 <n00b6502> to permute an array... that would be    map (\i -> vertices!!i )  indices    ... is there a nicer way to write it.
22:36:35 <mm_freak> latro`a: perhaps i'd need an actual use case, where RState is really a nice option
22:36:40 <n00b6502> is that even right
22:36:51 <mm_freak> n00b6502: 'vector' gives you the 'backpermute' combinator
22:36:53 <shachaf> mm_freak: I doubt there is such a use case.
22:37:02 <latro`a> I'm not sure if there is one, yeah
22:37:06 <n00b6502> 'combinator' = ?
22:37:26 <shachaf> @google what is a combinator in haskell
22:37:28 <lambdabot> http://www.haskell.org/haskellwiki/Combinator
22:37:28 <lambdabot> Title: Combinator - HaskellWiki
22:37:38 <n00b6502> map (vertices!!) indices ... would taht work
22:38:03 <mm_freak> n00b6502: there is no agreed upon definition of "combinator"‚Ä¶  just think of it as a function
22:38:07 <mm_freak> usually it's higher order
22:38:07 <shachaf> (foo!!) is the same as (\i -> foo!!i), if that's what you're asking.
22:38:07 <n00b6502> > map ([10,20,30,40,50]!!) [1,3,4]
22:38:08 <lambdabot>   [20,40,50]
22:38:17 <shachaf> mm_freak: There isn't?
22:38:53 <ion> > let go xs len = do { (d, m) <- (`divMod` len) <$> get; put d; tell [xs !! m]; when (d /= 0) (go xs len) } in execWriter (runStateT (go "0123456789" 10) 31337)
22:38:54 <lambdabot>   "73313"
22:38:55 <mm_freak> shachaf: would you call (<*>) a combinator?
22:38:58 <ion> RState would result in "31337" ;-)
22:39:56 <n00b6502> heh haskell can sometimes get hard to read.. even if it feels elegant to write
22:41:24 <mm_freak> shachaf: better example:  would you call 'map' a combinator?
22:41:43 <apeschel> The more I use bash and haskell, the more that I realize good bash and good haskell have a lot more overlap than might be expected
22:43:07 <mm_freak> n00b6502: only when you're a beginner‚Ä¶  nowadays i find strange haskell code much easier to read than strange code in any other language
22:43:17 <mm_freak> even if the coding style is very different from mine
22:43:27 <SebastienGllmt> http://ideone.com/O2g4u could anybody tell me what the issue(s) with this code is? I'm trying to get it to print out the last item in a list
22:43:28 <shachaf> mm_freak: That's because all Haskell code is strange.
22:43:32 <shachaf> So you get used to it quickly.
22:43:44 <mm_freak> "strange" as in "not by you"
22:43:50 <shachaf> SebastienGllmt: [] isn't a type.
22:43:51 <mm_freak> s/you/yourself/
22:44:03 <shachaf> SebastienGllmt: You should probably @paste the error along with the code when you ask a question like this.
22:44:19 <shachaf> SebastienGllmt: Also, you shouldn't use length to write this function.
22:44:20 <SebastienGllmt> well the error is under the code
22:44:28 <shachaf> Oh, wait, it is. :-)
22:44:33 <ion> sebastiengllmt: Function application has the highest precedence. That‚Äôs parsed as (drop (length x)) - (1 x)
22:44:44 <shachaf> Also, the precedence is messed up.
22:45:01 <n00b6502> how would you express a *sort* that also spits out a list of indices of the permutation done by the sort
22:45:06 <shachaf> What ion said.
22:45:08 <mm_freak> SebastienGllmt: you probably get a kind error, which is basically what n00b6502 said
22:45:12 <mm_freak> [] isn't a type
22:45:21 <mm_freak> uhm
22:45:24 <mm_freak> what shachaf said =)
22:45:28 <shachaf> SebastienGllmt: Oh, and your indentation is messed up.
22:45:35 <shachaf> Everything in a do block must be indented the same amount.
22:45:46 <mm_freak> n00b6502: sort . flip zip [0..]
22:45:54 <SebastienGllmt> but I thought you had to use drop that way because it pseudo takes two arguments
22:46:01 <shachaf> SebastienGllmt: You should start with a small working program and add little tiny pieces to it at a time.
22:46:04 <mm_freak> > sort . flip zip [0..] $ "baced"
22:46:06 <lambdabot>   [('a',1),('b',0),('c',2),('d',4),('e',3)]
22:46:12 <shachaf> And run ghci on it right away after every little change, so you can see what breaks it.
22:46:23 <n00b6502> ok then its simple to extract the index list
22:46:42 <SebastienGllmt> This was supposed to be my small working program
22:46:43 <mm_freak> > map snd . sort . flip zip [0..] $ "baced"
22:46:45 <lambdabot>   [1,0,2,4,3]
22:46:50 <shachaf> flip zip :-9
22:46:53 <shachaf> s/9/(/
22:46:55 <mm_freak> hehe
22:47:05 <shachaf> I think use of flip is almost never justified.
22:47:10 <mm_freak> flip zip (strip nip)
22:47:12 <n00b6502> haskell is insanely concise
22:47:14 <shachaf> (`zip`[0..]) would probably be OK.
22:47:35 <sp3ctum> n00b6502, yes it is
22:47:43 <sp3ctum> it gets some getting used to
22:48:07 <n00b6502> its like you're writing one statement that does the job of loops ...
22:48:16 <n00b6502> one statement that does the job of several loops
22:48:33 <ion> > flip (Just succ) 42
22:48:35 <lambdabot>   Just 43
22:48:41 <apeschel> Is chaining with the dot operator more efficient than chaining with the dollar operator?
22:48:58 <dmwit> No.
22:48:59 <n00b6502> different purpose if i've understood
22:49:05 <BMeph> > unzip . sort . (`zip`[0..]) $ "based"
22:49:07 <lambdabot>   ("abdes",[1,0,4,3,2])
22:49:15 <sp3ctum> :t unzip
22:49:17 <shachaf> Yes.
22:49:17 <lambdabot> forall a b. [(a, b)] -> ([a], [b])
22:49:26 <dmwit> If (.) or ($) are the bottlenecks in your code, you are doing something very wrong.
22:49:27 <shachaf> I'm not talking about runtime efficiency, though, but refactoring efficiency.
22:49:41 <ion> Chaining with the dollar operator is (almost?) always wrong.
22:49:50 <latro`a> ehh
22:49:57 <latro`a> depends
22:50:09 <latro`a> more often than not, though, sure
22:50:13 <apeschel> dmwit: It seems like you could parallelize with the dot operator but not with the dollar operator
22:50:20 <latro`a> wat
22:50:23 <shachaf> apeschel: Nope.
22:50:24 <ion> apeschel: no
22:50:27 <mm_freak> apeschel: that makes no sense
22:50:27 <latro`a> how would you do that
22:50:30 <n00b6502> no they're both sequential
22:50:35 <shachaf> apeschel: $ and . probably both just get inlined.
22:50:37 <latro`a> g needs f to do anything at all
22:50:42 <n00b6502> no forget what i said
22:50:47 <Twey> I suppose you could actually
22:51:03 <mm_freak> n00b6502: there are linear data dependencies is a better way of saying that
22:51:03 <apeschel> . operator chains outputs to inputs, while $ operator evaluates the argument before passing, no?
22:51:16 <apeschel> If you chain outputs to inputs, you can parallelize
22:51:16 <mm_freak> apeschel: no
22:51:29 <Twey> In f . g $ x, if the *value* of g x is not needed for f, you could use a future
22:51:41 <n00b6502> will the haskell inliner figure out...   map a (map b c)    =  map a.b  c
22:51:45 <ion> f $ x = f x
22:51:47 <mm_freak> apeschel: semantically there is no difference between "f . g . h $ x" or "(f . g . h) x" or "f $ g $ h $ x" or "f (g (h x))"
22:51:51 <Twey> E.G. if f = (: []) you could parallelize execution of f and g
22:51:51 <ion> (f . g) x = f (g x)
22:51:52 <shachaf> n00b6502: That has nothing to do with inlining.
22:51:53 <mm_freak> they are all semantically the same
22:51:55 <Twey> Not that you'd get much for it, I guess
22:52:06 <shachaf> n00b6502: But fusion will probably figure it out.
22:52:19 <shachaf> (With the correct syntax, even! :-) )
22:52:22 <mm_freak> n00b6502: deforestation will
22:52:26 <n00b6502> if one is drawing a result ... you'd hope it could inline like that
22:52:30 <mm_freak> (this time i promise it will) =)
22:52:50 <apeschel> To me it seems that f $ g $ h $ x would imply sequential ordering and f. g . h $ x would not
22:52:59 <mm_freak> apeschel: nope
22:53:06 <shachaf> apeschel: Just inline the functions.
22:53:09 <mm_freak> > const 1 $ const undefined $ undefined
22:53:10 <ion> apeschel: Try evaluating the $s and .s manually and see what comes out.
22:53:11 <lambdabot>   1
22:53:12 <shachaf> They reduce to the same thing.
22:53:15 <mm_freak> @ apeschel
22:53:55 <mm_freak> apeschel: in haskell an argument is /never/ evaluated before the application unless you tell it explicitly to do that
22:54:09 <mm_freak> f $! x
22:54:21 <mm_freak> or x `seq` f x
22:54:26 * shachaf wonders whether .! makes any sense.
22:54:27 <apeschel> I didn't think that in f . g that g was an operator
22:54:31 <apeschel> *argument
22:54:37 <mm_freak> shachaf: it could, yeah
22:54:37 <shachaf> "f . g" == "(.) f g"
22:54:45 <shachaf> (.) f g = \x -> f (g x)
22:55:18 <mm_freak> apeschel: "f . g" means to apply g, then f
22:55:18 <sp3ctum> i feel weird since that makes perfect sense to me
22:55:26 <sp3ctum> feels like i just learned to read perl or something
22:55:38 <mm_freak> apeschel: both are functions‚Ä¶  look at the type
22:55:45 <mm_freak> :t (Prelude..)
22:55:46 <lambdabot> forall b c a. (b -> c) -> (a -> b) -> a -> c
22:56:02 <apeschel> mm_freak: I see from shachaf's example as well
22:56:17 <mm_freak> apeschel: yeah, but it's always useful to look at types
22:56:28 <apeschel> It still seems odd to me, since if f and g have no side effects, there is no reason no to run them in parallel if you want
22:56:30 <mm_freak> the types often tell you what a function does
22:56:44 <mm_freak> apeschel: how would you run them in parallel?
22:56:50 <mm_freak> f depends on the result of g
22:56:59 <quicksilver> apeschel: it may be hard for f to "get very far" without g, since it works on the result of g.
22:57:14 <quicksilver> to the extent that f can do some work without inspecting its argument at all then sure.
22:57:29 <apeschel> mm_freak quicksilver That is true if the function only deals with one element, but for a list of any subtiantial size it would make a huge difference
22:57:42 <quicksilver> (and to the extent that g can produce some partial result that f can start working on before g finishes, sure)
22:58:00 <mm_freak> apeschel: the problem is that (.) has no semantic information about the functions, so it can't make any educated decisions about when to parallelize
22:58:04 <quicksilver> but autoparallization of code is hard.
22:58:19 <apeschel> That is why I like the low hanging fruit
22:58:35 <quicksilver> on the other hand, fusion plus modern CPU design (fast L1 caches) is like a poor man's parallelization.
22:58:46 <mm_freak> apeschel: there are nice ways to parallelize your computations in haskell‚Ä¶  did you check them out?
22:59:04 <apeschel> mm_freak Not yet, I'm still exploring
22:59:12 <mm_freak> like the 'par' combinator or the Control.Parallel.Strategies module
22:59:16 <mm_freak> apeschel: you should
22:59:19 <quicksilver> if you already have some elements of (g x) on memory then running f on them straight away may actually be free.
22:59:24 <mm_freak> x `par` y `pseq` x + y
22:59:31 <mm_freak> says that x and y can be computed in parallel
22:59:35 <quicksilver> (because it may be able to run at the same time as fetching the next values of x from memory)
22:59:43 <quicksilver> and that's what fusion gives you.
23:00:48 <mikeplus64> @pl (\(x, _) (y, _) -> x == y)
23:00:48 <lambdabot> (`ap` snd) . (. fst) . (const .) . (==) . fst
23:01:12 <quicksilver> in fact, fusion is not even required for that to work. it just saves some allocations and makes it more likely everything stays in cache and pipelined.
23:02:36 <dmwit> Man, when will hardware designers start designing hardware with optimizations built for us superior functional programmers instead of those mere imperative programmers.
23:02:43 <latro`a> lol
23:03:15 * ion rubs his Lisp machine.
23:03:35 <mm_freak> give it a few years
23:03:37 <ion> (I don‚Äôt really have one.)
23:03:56 <mm_freak> people start to realize that (de facto) OOP sucks and functional programming is superior
23:04:02 <danharaj> I'm not sure if that would help GHC very much.
23:04:26 <apeschel> mm_freak: Modern computer architecture is kind of bad for OOP too
23:04:30 <arcatan> then comes the era of enterprise Haskell
23:05:23 <mm_freak> that era is already reached, but yet only on a small scale
23:05:45 <ion> Com.Microsoft.Research.SimonPJ.Prelude
23:06:03 <arcatan> with AbstractMonadTransformerTransformers
23:06:28 <ion> and more XML
23:06:35 <sp3ctum> apeschel, can you elaborate / point to reference why Modern computer architecture is kind of bad for OOP too
23:06:43 <ion> packagename-cabal.xml
23:06:47 <BMeph> mikeplus64: equating fst
23:06:51 <sp3ctum> last part is a quote from you..
23:07:14 <mikeplus64> BMeph: (==) `on` fst
23:07:17 <apeschel> sp3ctum: It has no features to help with OOP. There was fancy hardware designed with things like dirty bits for objects in memory, but it was deemed to expensive and impractical
23:07:40 <n00b6502> dmwit : its called GPU's
23:07:41 * BMeph nods
23:08:47 <sp3ctum> apeschel, when you say "no features to help with OOP", does it have features to help with FP then?
23:08:59 <n00b6502> SIMD also
23:09:07 <apeschel> sp3ctum: The stack maybe? I didn't really claim it did though
23:09:23 <n00b6502> you can't make hardware for OOP
23:09:39 <apeschel> n00b6502: There was hardware designed for OOP in the 70s and 80s
23:09:42 <apeschel> It was pretty cool
23:10:05 <n00b6502> OOP is just various things including polymorphism which is functioon pointers which is for functional progrmming too :)
23:10:25 <apeschel> True OOP is about encapsulation and message passing
23:10:38 <apeschel> The hardware designed for OOP supported these things directly
23:10:39 <n00b6502> ah then thres' that too where it  makes sense
23:10:49 <n00b6502> messaging system in the CELL
23:11:38 <n00b6502> but message passing is just data going through queues really which is just regular computation as far as i can tell
23:11:58 <apeschel> In the 90s, CPU manufacturers decided that making specialty hardware was too difficult, and decided to shove the problem onto software developers
23:12:38 <n00b6502> you want a good general purpose cpu then you make hardware for things it finds slow
23:13:35 <apeschel> n00b6502: RISC in the 90s taught us the opposite
23:13:46 <apeschel> If you want a fast CPU, you strip it down
23:13:52 <n00b6502> or rather make hardware for repetitive tasks that take up a lot of time
23:14:00 <n00b6502> RISC *is* a good general purpose CPU
23:14:23 <dmwit> RISC architectures followed exactly the path n00b6502 suggested. First you make a good CPU, then you add whistles that detect slow sequences of instructions and fix them.
23:14:47 <n00b6502> what i've got in my head more things like dedicated graphics cards, sound cards, video decompression
23:14:49 <apeschel> Yes, my mistake
23:15:49 <apeschel> Sound cards and video decompression have been superceded by more general cpus
23:16:08 <n00b6502> .. with SIMD units
23:16:46 <apeschel> I think sound decompression is usually done by the chipset now? Or am I mistaken?
23:16:57 <n00b6502> sometimes its a mixture
23:17:00 <apeschel> *sound processing and video decompression
23:18:17 <n00b6502> 2 things that got me interested in FP are.. [1] parallelism [2] the experience of working with other coders on imperative, pointerbased programs :)
23:19:22 <apeschel> I've heard complaints from people in scientific computing that FP doesn't have enough fine grain control
23:19:26 <dmwit> My graphics card does video decompression for some formats, but sound is still done in software for a lot of computers.
23:19:37 <apeschel> But I like that you can get easy parallelism with FP
23:19:59 <apeschel> And I'm not sure how valid their complaints are anyway, since that is not what I do
23:20:01 <n00b6502> yes you need to reason about memory for parallelism
23:21:12 <n00b6502> you need to reason about the granulariry jobs for parallelism , size of  intermediate datastructures relating to caches & potentially other types of local memories like in GPGPU
23:21:21 <n00b6502> granularity of^
23:21:58 <n00b6502> whilst FP lets you express what you want to do perfectly concisely , from what i've seen its difficult to visualize how its actually going to be exectuted
23:22:18 <n00b6502> this is why i'm after something that converts FP to C/C++
23:22:42 <apeschel> You can do FP kind of easy in C++11x
23:22:44 <sp3ctum> n00b6502, yeah i read somewhere that one problem with haskell is that it might be hard to see potential performance degrades
23:23:26 <apeschel> FP in C++11 is definately not terse though
23:23:30 <n00b6502> the notion i have though... it would be nice to express a program in its pure form - THEN put in hints perhaps in a seperate file that change how it maps onto hardware
23:24:36 <n00b6502> i definitely want a syntax that suits lambdas & FP by default now
23:24:46 <n00b6502> with c++ its a bolt on
23:24:55 <mm_freak> also FP without laziness is really not that great
23:25:08 <mm_freak> that's one of the reasons i never liked scheme
23:25:08 <n00b6502> i was just experimenting with templates for lazy eval
23:25:20 <sp3ctum> laziness is very cool
23:25:26 <n00b6502> result = src.map(f1).filter(f2).eval()
23:25:31 <apeschel> mm_freak: You can get laziness in C++ with Boost
23:25:32 <SebastienGllmt> ok I got my code working if I use head $ reverse x but if I use the dot notation like so: http://ideone.com/BKR0g I get an error. Any idea why?
23:25:46 <mm_freak> apeschel: that's not the same
23:25:53 <mm_freak> i mean laziness by default
23:25:54 <n00b6502> with class LazyMap -> class LazyMapFilter -> then eval() actually does something
23:25:58 <dmwit> SebastienGllmt: myLast = head . reverse
23:26:06 <mm_freak> because with boost the laziness stuff would be all over my code
23:26:11 <mm_freak> and that would be really ugly
23:26:12 <dmwit> SebastienGllmt: or, if you really want to bind to the list, myLast x = (head . reverse) x
23:27:22 <dmwit> SebastienGllmt: That error message is actually one of the more confusing ones I've seen with that template.
23:27:38 <dmwit> SebastienGllmt: But if you read it slowly *after* you know what's wrong, hopefully it should make sense.
23:27:42 <dmwit> (complain loudly if it doesn't)
23:27:51 <SebastienGllmt> I don't understand Haskell error messages half the time
23:28:11 <shachaf> I don't read error messages half the time.
23:28:17 <shachaf> Beyond the line number, that is.
23:28:21 <SebastienGllmt> unless I'm passing the wrong argument, returning the wrong type, etc. the meaning of the error message is a mystery to me
23:28:40 <dmwit> Well, they're often very helpful. So it might not be a bad exercise to make sure you understand every error message for a while.
23:28:57 <dmwit> As with shachaf, I often don't read them. But when I do need to read them, they are darn specific and helpful.
23:29:59 <shachaf> ==dmwit
23:30:57 <sp3ctum> i think they are messy. one of the biggest problems i had when starting out
23:31:41 <sp3ctum> my problem commonly was that i left out a parameter to a function, the error message i got:
23:31:46 <sp3ctum> No instance for (Show ([[b0]] -> [b0]))
23:32:17 <mm_freak> shachaf: now that you say it‚Ä¶  i also don't read the actual error messages much
23:32:23 <sp3ctum> it makes sense now that i understand the error, and it's true that it is helpful. just a little rough for beginners
23:32:36 <dolio> So you were trying to print everything?
23:33:00 <dmwit> GHC is not designed for beginners, that's true.
23:33:16 <dmwit> I don't feel that's a mark against GHC, but rather a call to action for a spin-off.
23:33:23 <sp3ctum> dolio, no actually i used ghci which tries to :)
23:33:34 <ion> ghc -fbeginner
23:33:48 <dmwit> (And I think there actually have been a few attempts to make something more newb-friendly.)
23:34:01 <mm_freak> sp3ctum: that's why helium doesn't have type classes
23:34:14 <n00b6502>  whats helium, another FP language
23:34:17 <dmwit> There we go, that's the name I couldn't think of.
23:34:18 <dmwit> helium
23:34:50 <mm_freak> because you can't really improve the error message without standing in the way of advanced programmers‚Ä¶  but i suppose you could add some hints for specific errors and have a flag that enables them
23:35:00 <mm_freak> n00b6502: a haskell-like language for beginners
23:35:59 <mm_freak> if you're trying to use Show on a function that's probably a missing application
23:36:09 <mm_freak> and GHC could add a notice about that
23:36:23 <mm_freak> unless you're lambdabot
23:36:25 <mm_freak> > show id
23:36:27 <lambdabot>   Overlapping instances for GHC.Show.Show (a -> a)
23:36:27 <lambdabot>    arising from a use of `...
23:37:04 <shachaf> > show (id::Int->Int)
23:37:06 <lambdabot>   Overlapping instances for GHC.Show.Show
23:37:06 <lambdabot>                              (GHC.T...
23:37:06 <mm_freak> hmm‚Ä¶  that's actually a smart way to prevent one from using a dummy type class
23:37:20 <mm_freak> or instance
23:37:53 <ion> FSVO smart
23:38:09 <mm_freak> let's say clever
23:38:16 <mm_freak> not that smart
23:39:01 <n00b6502> someone mentioned some GHC output that might shed more light on how it actually executes
23:39:03 <dmwit> Wasn't there a push by Microsoft to do some machine learning on errors and their fixes to suggest likely fixes to common errors?
23:39:16 <n00b6502> notC output, not asm, but somethhing else
23:39:26 <dmwit> -ddump-core ?
23:39:32 <shachaf> dmwit: That sounds neat.
23:39:43 <dmwit> and in general the -ddump-* flags give GHC some introspection powers
23:40:15 <dmwit> shachaf: I can't find any mention of it now, but I'm like... 77% certain I'm not just making shit up.
23:40:36 <mm_freak> n00b6502: there is C--
23:40:43 <mm_freak> that's the lowest level before assembler
23:40:58 <dolio> I don't think C-- is going to help a lot.
23:41:03 <dolio> But that's me.
23:41:13 <mm_freak> C-- sheds light on how the code executes
23:41:22 <mm_freak> it's basically a high level cross platform assembler
23:42:15 <dolio> Reading a paper on STG is more likely to be helpful, I think, because it gives an operational model for executing the Haskell core language.
23:42:29 <dolio> More or less.
23:42:38 <mm_freak> i suggested that to n00b6502 already, but i have a feeling he refuses to do that =)
23:43:17 <n00b6502> haven;t got round to it :)
23:44:00 <mm_freak> SPJ's book from 1987 is available online‚Ä¶  it introduces STG very well
23:44:12 <n00b6502> what i have in my head: efficient code is straightforward loops - which should be possible to visualize in C; perhpas its possible for a haskell compiler to generate such loops from its dependancy-graph
23:44:33 <mm_freak> n00b6502: no
23:44:39 <n00b6502> efficient code is a series of simple loops, inside those loops everything is inlined, tempoaries are in registers
23:44:52 <mm_freak> neither is that what you get, nor is that what you really want
23:45:04 <n00b6502> inefficient code branches and jumps allover the place :)
23:45:06 <mm_freak> haskell produces code that is procedures and jumps
23:45:23 <mm_freak> indeed, not CALL, but JMP =)
23:45:35 <mm_freak> haskell programs don't have a call stack
23:45:47 <apeschel> n00b6502: A loop is a jump and branch by definition
23:45:50 <n00b6502> if a loop should still be visualized as a block of code with a lable and a jump at the end
23:46:02 <n00b6502> yes i have written them in ASM :)
23:46:14 <mm_freak> n00b6502: that's only for the most straightforward recursions
23:46:21 <mm_freak> everything else will look like spaghetti
23:46:58 <n00b6502> optimization is refactoring algorithms until it *is* straightforward recursions with predictable memory acess patterns
23:47:05 <n00b6502> refactoring algorithms and data
23:47:12 <mm_freak> you still have C++ in mind
23:47:20 <n00b6502> no i have modern computers in mind
23:47:29 <n00b6502> SIMD hardware and pipelines and caches
23:47:52 <mm_freak> whatever, you have compilation of common imperative languages in mind
23:48:08 <yitz> n00b6502: predictable memory access patterns is what you need. for c++ you get that with straightforward recursions. not with haskell.
23:48:16 <n00b6502> computers are imperative. the FP part comes in with parallelism - which is needed for pipelines, and SIMD :)
23:48:55 <yitz> well, straightforward loops, anyway.
23:49:03 <mm_freak> n00b6502: http://research.microsoft.com/en-us/um/people/simonpj/papers/slpj-book-1987/index.htm
23:49:06 <mm_freak> read this
23:49:06 <dolio> Are you sure he has compilation of imperative languages in mind?
23:49:19 <dolio> I thought they compiled things to single static assignment and so forth.
23:49:30 <dolio> Not loops.
23:49:31 <n00b6502> what i'm trying to get at is, if the compiler is doing its job, it starts with an elegant description of an algorithm from which it can generate these nice loops
23:49:38 <dolio> And mutation.
23:49:52 <n00b6502> exactly
23:49:54 <mm_freak> in any case, he doesn't have compiling a non-strict functional language in mind
23:49:57 <ion> Aww, he should have named the book ‚ÄúThe Structure and Implementation of Functional Programming Languages‚Äù.
23:50:03 <n00b6502> optimization in imperative langauges involves a lot of functional thinking
23:50:20 <n00b6502> SSA as mentioned, in order to do instruction scheduling
23:50:45 <n00b6502> instruction scheduling requires grouping instructions together that have been proven to be independant
23:51:10 <mm_freak> n00b6502: that's low level optimization, but that doesn't change the general structure of the code
23:51:11 <yitz> n00b6502: it could be that jhc compiles haskell in a way that is more like what you are thinking
23:51:30 <apeschel> n00b6502: Loops are not so nice for a processor when branch prediction fails
23:51:30 <n00b6502> mm_freak: optimizing is: changing the general structure of the code, to allow good mapping to low level hardware
23:51:53 <n00b6502> apeschel: sure - thats why you have SIMPLE loops
23:51:58 <n00b6502> and not SPAGHETTI loops
23:52:20 <mm_freak> n00b6502: yeah, and because GCC is so good at that the GHC developers switched to a native code generator that produces better code =)
23:52:28 <ion> Yes, my code never has conditional branching.
23:52:30 <n00b6502> what i have been trying to say is, optimizing a program IS turrning it into SIMPLE loops so that branch prediction works, and pipelining works ..
23:52:32 <mm_freak> n00b6502: again, please read the paper i just linked
23:53:16 <n00b6502> mm_freak: if haskell is doing its job it will spit out simple loops :) they might be a label and a  branch but you'll still be able to see it as a simple loop... with no jumps in the middle- blocks of code that fill registers
23:53:24 <mm_freak> n00b6502: if the loops aren't good, GHC did its job bad at a higher level
23:53:30 <apeschel> n00b6502: Branch prediction doesn't really care if your loop is simple. It just uses heuristics to guess.
23:54:19 <n00b6502> simple loops are cache coherent. whatever predictors you have, the simpler the loop the better the algorithm will perform on a wider variety of CPUs
23:54:22 <mm_freak> n00b6502: after the code is translated from the STG language the structure of the produced code is pretty much fixed
23:54:30 <shachaf> n00b6502: You should read that paper mm_freak just linked.
23:54:31 <n00b6502> also three's GPGPU which is the biggest application of these ideas
23:54:37 <sp3ctum> what is a simple loop in this context?
23:54:38 <shachaf> Oh, or the STG paper.
23:54:40 <shachaf> @where stg
23:54:40 <lambdabot> http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.3729
23:54:52 <mm_freak> n00b6502: you're talking about stuff that doesn't apply to haskell
23:55:02 <mm_freak> at least not in the way you think
23:55:04 <n00b6502> i'm talking about things which apply to how computers work
23:55:19 <lucca> The STG paper really helped me with understanding how it is all possible, at least.  Highly recommended.
23:55:21 <n00b6502> efficient code is not always idomatic C++
23:55:27 <yitz> n00b6502: ghc works really well and it doesn't do what you are saying. so read the paper. if you can then improve on it, that's great.
23:55:45 <n00b6502> does it work with GPGPU
23:56:23 <n00b6502> GPGPU is only physically capable of executing simple loops. so if you want to use the most powerful processors, you need to be able to generate these :)
23:56:45 <n00b6502> well not simple loops - more like mapping a big inlined function
23:56:54 <mm_freak> i'm done
23:56:59 <n00b6502> but very simiilar to a simple loop in C
23:57:02 <yitz> n00b6502: there have been several research projects that compile haskell to run on gpus. not via gpgpu.
23:57:18 <ion> mm_freak: Congratulations for having persevered this far.
23:57:21 <n00b6502> these will then spit out the type of code i talk about
23:57:31 <n00b6502> because GPU's are physically incapable of executing anything else
23:57:35 <n00b6502> they have limited program store
23:57:45 <dolio> No, they spit out GPU code.
23:57:55 <yitz> n00b6502: people spent years researching this. read what they did.
23:57:56 <n00b6502> right, which will be simple "inner loops"
23:58:11 <n00b6502> you take the inner loop and stick it on the GPU
23:58:17 <ion> How about reverse psychology? n00b6502: Nooo, don‚Äôt read the online book mm_freak linked!
23:58:21 <mm_freak> n00b6502: you know, you always say, "will", "does", "must", "is", ‚Ä¶
23:58:34 <mm_freak> because you know everything about computers and compilers
23:58:35 <shachaf> n00b6502: What ion said. And definitely don't read the STG paper.
23:58:39 <apeschel> n00b6502: GPUs don't really use loops, they're vector processors
23:58:47 <n00b6502> yes i know
23:58:49 <dolio> No, you take loops, which are an abstraction, and compile them to code that the GPU can execute.
23:58:50 <Ralith> n00b6502: you are definitely the first person to think about these problems.
23:59:06 <mm_freak> hehe
23:59:18 * shachaf wonders why @where stg links to citeseer.
23:59:19 <n00b6502> for (i in array) do_something() <<<< THATS WHAT I CALL A SIMPLE LOOP    ----> do_something() on gpu
23:59:32 <shachaf> Oh, because it has a .pdf instead of a .ps.gz
23:59:35 <n00b6502> do_something() = kernel
23:59:52 <ion> Data Parallel Haskell, anyone?
