00:03:03 <tomberek> can't do equality on undefined because of halting problem?
00:04:38 <Cale> tomberek: right
00:05:14 <Cale> tomberek: At least, in the large sense of "undefined"
00:05:25 <Cale> Which includes nonterminating computations of all sorts
00:05:39 <tomberek> Cale: so I'm writing that instance,, and it's a bunch of bar (Foo a b) = Foo a (bar b)   is that right? and isn't there a lift or something that does that?
00:06:35 <tomberek> becaue b is already an instance of the typeclass
00:09:16 <Zeiris_> Is the Data.Tree naming scheme and method for trees typical? IE not having an "Empty"
00:09:37 <Zeiris_> Well, having an empty, but calling it a forest.
00:10:32 <Cale> tomberek: you could invent a Foo-specific higher-order function, perhaps
00:10:45 <Cale> Zeiris_: I don't like Data.Tree, myself
00:11:10 <Cale> Zeiris_: I'm usually more content just to invent my own tree type, write a fold over it, and then use that to get everything I need.
00:11:41 <Zeiris_> I can see why, although I really need to start making my code far more general. And a part of that would be, ideally, not re-inventing the wheel :(
00:11:55 <tomberek> ah!  like promote op (Foo a b) = Foo a (op b)  ?
00:12:03 <Cale> tomberek: yeah
00:12:12 <Cale> tomberek: Whatever pattern you see a lot of.
00:12:30 <Cale> tomberek: If Foo were a parametric type, then that would be an implementation of fmap
00:12:38 <tomberek> what is the traditional term for that? promote? lift? hoist? elevate? launch?
00:12:40 <Cale> data Foo a = Foo Integer a
00:12:45 <enthymene> lift?
00:12:51 <Cale> instance Functor Foo where
00:13:11 <Cale>   fmap f (Foo n x) = Foo n (f x)
00:13:58 <Cale> Yeah, it's a type of lifting.
00:14:05 <dolio> Does GHC derive Functor yet?
00:14:05 <tomberek> Cale: thanks, i didn't see that,, that helps me out later
00:14:13 <Saizan> dolio: yes
00:14:27 <Saizan> and Foldable and Traversable too
00:23:22 <enthymene> g'night all
00:23:43 <enthymene> lifting is awesome btw.  I'll have to use it extensively for math stuff this semester
00:23:54 <enthymene> because I stubbornly refuse to use Mathematica
00:27:13 <Cale> Mathematica is actually pretty nice, though its evaluation model is strange, and it's rather untyped.
00:27:31 <enthymene> fascist syntax
00:27:39 <enthymene> "oh, did you not mean to put a space there?"
00:27:57 <Cale> The syntax doesn't bother me, though I don't know what you mean about spaces.
00:28:17 <enthymene> I've had ridiculous amounts of trouble getting things to work
00:28:25 <enthymene> simple things, like graphs of a function
00:28:30 <enthymene> or even the functions themselves
00:28:58 <enthymene> Haskell on the other hand, I can understand, and if needs be I can just export my data in gnuplot-readable form
00:28:59 <Gracenotes> W|A rephrases math input in mathematica form
00:29:09 <enthymene> I used to do the same thing with scheme, but that was some time ago
00:30:30 <Lycurgus> yeah, I bought when the got a reasonable price for the home edition
00:30:36 <Lycurgus> *they
00:30:49 <enthymene> mmm
00:30:52 <enthymene> yeah, I'm poor
00:31:06 <Lycurgus> the hard drive failed a few days later and after biz opened I was able to get authorization to reinstall
00:32:05 <enthymene> :o
00:32:12 <enthymene> yeah that's another nightmare scenario
00:32:14 <Lycurgus> I wouldn't use it for anything other than personal
00:32:20 <enthymene> g'night all
00:33:00 <Lycurgus> actually it wasn't the hard drive it was the power supply, the hard drive is new in that machine so if I replace the power supply I'll have two running copies
00:33:37 <TR2N> <enthymene> I've had ridiculous amounts of trouble getting things to work <- I've had the same experience with Mathematica. The convoluted syntax rules are annoying at best.
00:34:15 <Lycurgus> that doesn't seem like a valid criticism to me
00:36:06 <Lycurgus> if stuff actually didn't work, or could be shown to be purposefully misdesigned as far as human factors are concerned that would be one thing
00:36:41 <Cale> I don't really understand how the syntax of mathematica is all that complicated...
00:37:03 <Cale> I guess if you write things in 2D-layout form, it's a bit involved, but there's only so much of that.
00:37:22 <Cale> It's mostly pretty lispish, but with M-expressions rather than S-expressions.
00:40:59 <TR2N> The wonderful side of Mathematica is really mathematics. The programming side is very ill designed imho. The only thing about it that I liked was the concept of hierarchical cells and the mix of text with active code.
00:41:39 <Lycurgus> and actually I didn't have to wait to biz opened, they gave me a temp auth immediatedly then a permanent one after biz opened
00:41:42 <Cale> It supports functional programming reasonably well, though it could do better at that.
00:42:14 <Cale> The semantics are a bit strange -- particularly upvalues.
00:42:55 <Cale> You can define Cos[a] ^= 2, and that becomes part of the definition of a, rather than the definition of Cos (which is protected anyway)
00:42:58 <Lycurgus> iirc there was talk of a haskell i/f at one point
00:43:10 <Cale> There is a Haskell binding for MathLink
00:43:17 <Cale> I haven't really tried it much
00:44:43 <Lycurgus> where?
00:45:06 <Cale> http://hackage.haskell.org/package/mathlink
00:45:41 <Lycurgus> yeah had it by time i turned back here
00:46:08 <Lycurgus> looks reasonably current too
00:54:22 <MaciejP> Hey! What's the problem with ``The fixity signature for `>>' lacks an accompanying binding''? (>>) is defined
00:55:02 <tensorpudding> you need to declare its fixity
00:55:28 <Cale> Er, hmm
00:55:55 <Cale> MaciejP: I'm not sure, but (>>) is taken in the Prelude.
00:57:01 <MaciejP> Cale: Dammit, I defined (<<) not (>>) :-)
00:57:09 <Cale> ah
00:57:37 <tomberek> a type synonym cannot be made an instance of a typeclass?
00:57:43 <Cale> tomberek: right
00:57:51 <tensorpudding> there's an extension for that
00:57:59 <tomberek> but if you right out the original (non synonym) it's ok?
00:58:00 <tensorpudding> TypeSynonymInstances or something
00:58:03 <Cale> Or you can just expand the type synonym by hand.
00:58:14 <tomberek> roger roger... see, i'm getting the hang of it
00:59:30 <SubStack> I could sure go for a good algorithm for polynomial expansion and reduction
00:59:42 <SubStack> the one I wrote is so ad-hoc and fragile
01:01:01 <SubStack> I should probably just play with MathObj.Polynomial more, since it probably could be made to do what I want
01:01:31 <Cale> MathObj?
01:01:52 <SubStack> in the numeric-prelude
01:02:34 <Cale> Oh, Henning Thielemann's madness.
01:03:11 <Cale> It's too bad about him. He writes so much of what would be good code, except that he sabotages it with insane naming conventions.
01:03:55 <SubStack> I wrote a pretty swell interface for expression construction
01:07:07 <copumpkin> is there a nice library for generating haskell code?
01:12:06 <dons> template-haskell ?
01:12:24 <Cale> copumpkin: haskell-src-exts?
01:25:21 <monadic_kid> does anyone know how i can make keys such as home work correctly in ghci?
01:29:10 <hotaru2k3> fix your terminal settings?
01:30:01 <monadic_kid> it's not broken, i can use them fine outside of ghci
01:32:36 <hotaru2k3> the fact that your shell manages to make things work doesn't mean it's not broken
01:33:47 <monadic_kid> it does not mean that is broken either
01:35:38 <hotaru2k3> monadic_kid: sure, but the fact that it doesn't work in ghci indicates that it probably is
01:35:46 <hotaru2k3> maybe take a look at http://www.ibb.net/~anne/keyboard/keyboard.html
02:21:51 <tomberek> @djinn (a,b)->(b,a)
02:21:51 <lambdabot> f (a, b) = (b, a)
02:21:54 <tomberek> hehe
02:21:59 <tomberek> i like that
02:22:29 <nonowarn> @djinn ((a -> (b->r)->r) -> (a->r)->r) -> (a->r)->r
02:22:29 <lambdabot> f a b = a (\ c _ -> b c) b
02:22:33 <Zao> @type flip (,)
02:22:34 <lambdabot> forall a a1. a1 -> a -> (a, a1)
02:32:30 <OscZA> hi, im trying to create a simple tuple type: data MyType a = MyType a a, and then adding a show implementation for it: instance Show MyType where show (MyType x y) = show x ++ " and " ++ show y
02:33:02 <OscZA> getting error 'MyType' is not applied to enough type arguments
02:33:34 <OscZA> can you help me out a bit to get started?
02:35:09 <OscZA> i dont understand whats the error
02:38:02 <mreh> OscZA: Show a => show (MyType a)
02:38:25 <mreh> sorry
02:38:32 <mreh> that second show is supposed to be capitalised
02:38:52 <mreh> do you know about type calsses?
02:39:16 <OscZA> not much, no
02:39:20 <Beelsebob> OscZA: that's read by the way as "if you can Show type a, then you can Show MyType of a too"
02:39:22 <mreh> OscZA paste your full code and i'll show you
02:39:28 <mreh> @paste
02:39:29 <lambdabot> Haskell pastebin: http://moonpatio.com/fastcgi/hpaste.fcgi/
02:39:46 <OscZA> thats the whole code.. theres two lines hehe
02:40:12 <mreh> oh, I didn't read it properly
02:41:26 <mreh> instance Show a => Show MyType a where show (MyType x y)  = show x ++ " and " ++ show y
02:41:28 <mreh> try that
02:42:17 <Beelsebob> of note though OscZA, this is not the correct use for Show
02:42:41 <Beelsebob> Show is meant for producing haskell representations of values
02:43:24 <mreh> instance Show a => Show MyType a where show (MyType x y)  = intercalate ' ' ["MyType ", show x, show y]
02:43:32 <mreh> instance Show a => Show MyType a where show (MyType x y)  = intercalate ' ' ["MyType", show x, show y]
02:43:35 <mreh> that would do it
02:43:53 * Beelsebob prefers unwords over intercalate ' '
02:44:13 <mreh> oh, you learn something new every day
02:44:44 <OscZA> Beelsebob: I thought I was doing that.. defining how to show my tuple type
02:44:48 <mreh> > unwords . replicateM 6 $ "abc"
02:44:49 <lambdabot>   "aaaaaa aaaaab aaaaac aaaaba aaaabb aaaabc aaaaca aaaacb aaaacc aaabaa aaab...
02:45:13 <Beelsebob> OscZA: yes, but your output is not Haskell code
02:45:19 <OscZA> mref: why do i need that intercalate ?
02:45:46 <mreh> > intercalate ' ' ["hello","OscZA"]
02:45:47 <lambdabot>   Couldn't match expected type `[a]'
02:45:47 <lambdabot>         against inferred type `GHC.Types...
02:46:06 <mreh> > intercalate " " ["hello","OscZA"]
02:46:07 <lambdabot>   "hello OscZA"
02:46:21 <mreh> :t intercalate
02:46:22 <lambdabot> forall a. [a] -> [[a]] -> [a]
02:46:34 <mreh> intercalate "9" [1..3]
02:46:38 <mreh> > intercalate "9" [1..3]
02:46:39 <lambdabot>   No instance for (GHC.Num.Num [GHC.Types.Char])
02:46:40 <lambdabot>    arising from the literal ...
02:46:44 <mreh> > intercalate 9 [1..3]
02:46:45 <lambdabot>   No instance for (GHC.Enum.Enum [a])
02:46:45 <lambdabot>    arising from the arithmetic sequence...
02:46:52 <mreh> oh man, what a morning
02:47:09 <OscZA> Beelsebob: do you mean the " and " part? I was just fooling around, not trying to produce any expressions
02:47:17 <Beelsebob> ah, I see
02:48:29 <OscZA> how would i add such constraint that those tuple elements must be Ord class ?
02:48:31 <mreh> OscZA: the point of "show" is to do things like write haskell data structures out to a file and read them back in again
02:48:48 <mreh> OscZA deriving (Ord)
02:49:00 <mreh> you do show automatically do
02:49:07 <mreh> deriving (Show, Ord)
02:49:11 <OscZA> mreh: ok.. i was adding it so that I could "see" its value in ghci interpreter when i evaluate it
02:49:30 <mreh> OscZA: you can still use Show for that :)
02:49:41 <mreh> most people just derive the typeclass automatically
02:50:05 <OscZA> i mean something like data MyType Ord = Range Ord Ord ...
02:50:37 <mreh> OscZA: Ord is a typeclass, not a type
02:50:55 <mreh> data Ord a => MyType a = Range a a
02:51:03 <mreh> i think that's valid Haskell
02:51:18 <OscZA> ok.. I think thats what i want
02:51:20 <mreh> you use a "type context", which is the bit to the left of the =>
02:52:06 <OscZA> with that i can define what "a" stands for, right?
02:52:36 <mreh> OscZA: what you're doing is restricting the things that it can be
02:52:53 <mreh> in this case, only a type that implements the type class Ord
02:52:56 <mreh> @instances Ord
02:52:57 <lambdabot> (), (a, b), (a, b, c), (a, b, c, d), (a, b, c, d, e), All, Any, Bool, Char, Double, Dual a, Either a b, First a, Float, Int, Integer, Last a, Maybe a, Ordering, Product a, Sum a, [a]
02:52:58 <manjunaths> if I had an array of say hundred floats and I wanted to walk through the array and "update" the float values based on some input (what would be the most efficient
02:52:58 <OscZA> ok, thats exactly what i want
02:53:06 <manjunaths> way to do this ?
02:53:19 <mreh> manjunaths, map?
02:53:32 <mreh> you're not "updating" per-say
02:54:16 <manjunaths> mreh, I have to do this as fast as possible atleast 30 fps
02:54:25 <c_wraith> map is fast.
02:54:36 <manjunaths> 30 times per second, but doesn't it create a new list ?
02:54:38 <c_wraith> 30 fps is SLOW
02:54:53 <mreh> manjunaths, on a modern processor, easy :)
02:55:05 <manjunaths> mreh, ok
02:55:06 <c_wraith> for a computer?  updating only 30 times per second is moving quite slowly
02:56:59 <manju__> sorry
02:57:04 <manju__> got disconnected
02:57:31 <mreh> @src Any
02:57:32 <lambdabot> Source not found. Maybe if you used more than just two fingers...
03:01:51 <OscZA> intercalate is not in scope, i guess i need to "include" something
03:01:54 * ski wonders if there's any inverse to `intercalate sep' (for given `sep') floating around ..
03:01:58 <ski> @index intercalate
03:01:59 <lambdabot> bzzt
03:02:09 <ski> @slap lambdabot
03:02:09 * lambdabot activates her slap-o-matic...
03:02:31 <ski> @type Data.List.intercalate
03:02:32 <lambdabot> forall a. [a] -> [[a]] -> [a]
03:02:34 <ziman> it's in baughn's Data.List.Split, iirc
03:02:37 <Twey> Crazeh
03:02:46 <Baughn> ziman: That's not mine.
03:02:52 <Twey> ziman: It's in standard Data.List, and I don't think Baughn wrote that
03:03:22 <ski> OscZA : so you need `import Data.List', yes
03:03:40 <ziman> ah, it's byorgey, sorry to both
03:04:09 <OscZA> i dont understand why i need such a "special" stuff for this.. could I somehow constraint it more so that my original definion of show x ++ " and " ++ show y would work
03:05:18 <ski> OscZA : sure you can use plain `++' instead of `intercalate' .. but note that your original code for `show' isn't what `show' is meant for
03:06:38 <OscZA> if i want to turn MyTuple to something more human readable in the interpreter, i should define some other function for that ?
03:06:55 <OscZA> of type MyTuple -> String
03:07:14 <ski> (and if you want a proper `Show' instance, you should define
03:07:19 <ski>    showsPrec p (MyType x) = showParen (..p..) $ showString "MyType " . showsPrec ? x . showChar ' ' . showsPrec ? y
03:07:39 <ski>  (for some values of `..p..' and `?' which i can never recall)
03:07:44 <ski>  instead of defining `show'
03:07:45 <ski> )
03:08:25 <ski> OscZA : yes. `show' is for turning it into a Haskell-readable string
03:09:10 <OscZA> ski: ok.. i finally understand what you mean.. and why Beelsebob said its not proper haskell
03:09:16 <ski> (since that is what it is used for in many places, it seems bad to break that expectation, when you could just as easily conform to it)
03:10:06 <OscZA> ski: ok.. ill just define a function to turn it to string
03:10:14 <OscZA> and then use that in interpreter
03:17:00 <tomberek> hi ski
03:17:52 <ski> ehlo
03:18:40 <tomberek> I'm trying to use Text.Pretty print to print two docs next to each other, but not getting the result I expect.
03:25:16 <SubStack> hooray I fixed my polynomial expansion by removing it
03:25:32 <SubStack> and playing tricks with the instances
03:30:03 <Twey> 11:25:22 < SubStack> hooray I fixed my polynomial expansion by removing it
03:30:15 <Twey> Damn, I wish that were acceptable mathematical practice… :þ
03:32:55 <SubStack> if only!
03:33:12 <SubStack> good thing I am not a mathematician then!
03:52:18 <mreh> could someone explain to me how to read the .prof output
03:52:24 <mreh> is it outlined in RWH?
03:57:28 <jlouis> mreh: what is your question?
03:57:43 <jlouis> Personally, I think it is rather straightforward
03:58:33 <mreh> jlouis: It's alright, I was just a little confused about what kind of data was displayed in the cost centre summary at the top
03:58:48 <mreh> I just cross referenced with the full table
03:59:26 <jlouis> yeah, whats in the CCS are the main culprits
03:59:32 * hackagebot darcs 2.4 - a distributed, interactive, smart revision control system  http://hackage.haskell.org/package/darcs-2.4 (ReinierLamers)
04:00:51 <SubStack> new darcs :o
04:01:14 <jlouis> \o/
04:06:57 <chrisdone> there are a lot of japanese visitors to tryhaskell. I think we are getting some of the ruby community?
04:07:10 <medfly> uh...
04:07:20 <medfly> I'm sure the Japanese do more than just Ruby.
04:08:05 <jlouis> I envy them for their IPv6
04:08:27 <Twey> Haha
04:08:43 <chrisdone> medfly: http://twitter.com/#search?q=tryhaskell
04:08:56 <SubStack> and their hundreds of megabits per second
04:10:08 <jlouis> I also ponder how you get a RSS of 500Mb in haskell-torrent while the heap is some 4Mb in size
04:10:10 * ski stares at a blank page
04:18:32 <mreh> what If I really really can't be bothered to use template haskell and want to define something functionally but have it static at runtime?
04:18:43 * mreh breaks out the unsafePerformIO
04:19:55 <SubStack> you could also write a haskell program to write haskell programs
04:20:34 * mreh is confused by what this could mean
04:20:55 <Twey> That's what Template Haskell is for
04:21:04 <SubStack> or is it?
04:21:25 <mreh> oooh... it makes you think doesn't it? :)
04:21:34 <mreh> no, I think that's what template haskell is for
04:22:18 <SubStack> or so it would seem
04:22:37 <Twey> Well, there's a difference
04:22:50 <Twey> TH if you want it to be calculated at compile-time
04:23:02 <chrisdone> Twey: could you write a japanese translation of tryhaskell?
04:23:09 <Heffalump> mreh: what do you mean by static at runtime?
04:23:11 <Twey> unsafePerformIO + eval if you need it to be calculated at runtime
04:23:22 <Twey> chrisdone: Yes I could
04:23:25 <Heffalump> if it's a pure value you wouldn't need unsafePerformIO
04:23:28 <mreh> Heffalump: a fully reduced expression, not evaluation required
04:23:44 <mreh> a pure value?
04:23:46 <Heffalump> then you absolutely need Template Haskell
04:23:48 <Heffalump> not an IO value
04:23:48 <chrisdone> Twey: would it be worth it?
04:23:53 <Twey> chrisdone: Probably not
04:24:04 <Heffalump> otherwise it'll always be evaluated at runtime (unless the compiler happens to do some constant folding)
04:24:07 <chrisdone> ah well
04:24:14 <mreh> Heffalump: I was thinking evaluate once, and store it with unsafePerformIO
04:24:16 <Twey> chrisdone: Anybody in computer science has a decent grasp of English anyway, these days
04:24:18 <mreh> memoization
04:24:26 <Heffalump> mreh: what is the value?
04:24:31 <Twey> Might be a nice thing to have, but it's certainly not necessary
04:24:38 <mreh> Heffalump: a list of UArrays
04:24:46 <Heffalump> and how are the contents calculated?
04:25:28 <mreh> > replicateM 11 [False, True] -- Heffalump like so
04:25:29 <lambdabot>   [[False,False,False,False,False,False,False,False,False,False,False],[False...
04:25:46 <Heffalump> then why not just define it as a top level value?
04:25:46 <SubStack> I love that trick
04:25:51 <Heffalump> no unsafePerformIO etc.
04:25:53 <Berengal> What can be done by TH can always be done by hand
04:26:00 <mreh> Heffalump: it's a massive list
04:26:07 <Heffalump> so?
04:26:15 <Heffalump> I don't understand what unsafePerformIO buys you.
04:26:36 <mreh> Heffalump: if I were to parameterise that as a function
04:26:48 <mreh> > (\x -> replicate x [False,True]) 11
04:26:49 <lambdabot>   [[False,True],[False,True],[False,True],[False,True],[False,True],[False,Tr...
04:26:57 <mreh> > (\x -> replicateM x [False,True]) 11
04:26:57 <chrisdone> Twey: yeah, just thinking about the effect. I imagine it's nice to see something in your own language. also, it would just look cool :d
04:26:58 <lambdabot>   [[False,False,False,False,False,False,False,False,False,False,False],[False...
04:27:09 <Heffalump> ok, so you don't want all the possible values computed ahead of time
04:27:15 <Heffalump> how about using data-memocombinators?
04:27:26 <Twey> chrisdone: Yeah, but that's not sufficient motive for me to spend a significant amount of my recently-quite-limited time on it :þ
04:27:50 <mreh> Heffalump: I do need them computed ahead of time, but there's no way it is possible at compile time
04:28:06 <chrisdone> Twey: I know =)
04:28:18 <mreh> I've never got far with memo-combinators, there's not much documentation
04:28:20 <mreh> IIRC
04:29:06 <Heffalump> what are the arguments to your function?
04:29:11 <mreh> they're like Maps, aren't they?
04:29:21 <mreh> Heffalump: exactly what I just showed you
04:29:38 <Heffalump> so then foo = Memo.integral foo' where foo' x = replicate x [False, True]
04:29:46 <Berengal> mreh: What's the type?
04:29:48 <Heffalump> cribbed straight from the haddock
04:30:00 <chrisdone> Twey: wait, why's it limited? jibgu'a?
04:30:37 <mreh> Berengal: they type of the function? Int -> [Bool]
04:30:43 <Twey> chrisdone: ckule .ui-ru'e
04:30:48 <mreh> bzzt
04:30:53 <Heffalump> btw, what do you actually plan to do with these lists?
04:30:55 <mreh> Berengal: they type of the function? Int -> [UArray Int Bool]
04:31:15 <mreh> Heffalump: evaluate very large boolean expressions
04:31:20 <Berengal> mreh: Then what Heffalump said. No need for unsafePerformIO
04:31:32 <Berengal> In fact, unsafePerformIO would only make it harder
04:31:33 <mreh> they represent all the possible evaluations of a truth table for a boolean expression
04:31:33 <chrisdone> Twey: milxe ua nai cinmo
04:31:39 <Heffalump> is it really worth memoising them at all?
04:31:52 <Heffalump> they'll be generated lazily otherwise, and the data is trivial
04:32:05 <Heffalump> so you won't waste memory and will probably get similar or better performance
04:32:30 <mreh> Heffalump: I'm evaluating several hundred boolean expressions
04:32:42 <manjunaths> hello
04:32:46 <mreh> with 11 variables, each need binding with each truth evaluation
04:32:51 <Heffalump> I'm just asking if the cost of looking up this data is actually cheaper than the cost of regenerating it.
04:32:53 * ski . o O ( `(Memo.integral -> foo) x = replicateM x [False,True]' ? )
04:32:54 <nus> mreh, how frequently your runtime is going to be restarted/reexecuted?
04:32:55 <mreh> manjunaths, hello again, did it work?
04:33:04 <Heffalump> which is the assumption behind your desire to memoise here
04:33:08 <manjunaths> mreh, did what work ?
04:33:18 <mreh> manjunaths, you were here earlier
04:33:34 <manjunaths> mreh, ah...that one, I am still getting there
04:33:45 <manjunaths> I have more fundamental problems
04:34:08 <mreh> Heffalump, I wont know until I try it :)
04:34:27 <Heffalump> fair enough
04:34:31 <Heffalump> will that ViewPattern actually work?
04:34:33 <manjunaths> Vector3 is defined as data Vector3 = Vector3 a! a! a!, I wrote a function getX x y z = x
04:34:35 <manjunaths> this works
04:34:54 <nus> mreh, do you expect short runtimes?
04:34:55 <mreh> Heffalump: I'll regenerate it first, and profile
04:34:57 <Heffalump> it doesn't even look syntactically correct to me
04:35:03 <manjunaths> but returns Vector3 Double
04:35:14 <manjunaths> how do I unVector3 it ?
04:35:28 <manjunaths> make a function that directly returns the Double ?
04:35:57 <manjunaths> I want something like getX::Vector3 a b c => a -> b -> c -> Double a
04:36:25 <ski> manjunaths : you have not defined a type class `Vector3', so i doubt you really want that type signature
04:36:25 <Beelsebob> Double has the wrong kind
04:36:37 <ski> are you sure you reall don't want
04:36:40 <Beelsebob> Double :: *
04:36:44 <ski>   getX :: Vector3 a -> a
04:36:45 <Beelsebob> so you can't apply it to type arguments
04:36:46 <ski> instead ?
04:37:02 <manjunaths> hmmm...
04:37:22 <manjunaths> ah...
04:37:55 <manjunaths> ok...but now I don't know how to write the function :-)
04:37:57 <ski> manjunaths : it might be easier not to confuse things, if you define `data Vector3 a = MkVector3 !a !a !a', instead
04:38:23 <manjunaths> ski, it is part of standard library
04:38:25 <ski> `Vector3' is the type constructor, so e.g. `Vector Double' is a valid type of values that can then be used
04:39:04 <ski> and `MkVector3' then is a data constructor that takes three values of type `a' (e.g. `Double') and constructs a value of type `Vector3 a' (`Vector3 Double' in the specific case)
04:39:49 <manjunaths> ski, ok
04:39:52 <ski> so then you use `Vector3' in the type signatures of your functions, and you use `MkVector3' in the patterns and bodies of your functions
04:41:05 <ski> any value of type `Vector3 a' may then be of form `MkVector3 x y z', (with `x',`y',`z' all having type `a'), so you can extract those parts by pattern-matching on that common form
04:41:30 <ski> preflex: seen mmorrow
04:41:30 <preflex>  mmorrow was last seen on #ghc 40 days, 9 hours, 43 minutes and 45 seconds ago, saying: * mmorrow is rtfm'ing
04:41:38 <manjunaths> ski, ok
04:42:01 <ski> Heffalump : i'm not sure .. but i think it ought to :)
04:42:30 <Heffalump> think what ought to?
04:42:42 <ski> it ought to work
04:43:15 <ski> `Memo.integral -> foo' would be matched with the value `\x -> ...', passing that to `Memo.integral', finally matching the result with `foo', whose binding is exported by the whole equation
04:43:18 <Heffalump> oh, the ViewPattern. Sorry.
04:43:34 <Heffalump> I missed that it was you that suggested it and not mreh, so was getting very lost :-)
04:44:07 <Heffalump> but you're writing a pattern in place of the function, not the argument
04:44:42 <ski> indeed
04:44:49 <Heffalump> is that legal at all?
04:44:55 <ski> sure
04:45:02 <ski>   f (x,y) = ..x..y..
04:45:05 <ski> is legal
04:45:06 <ski> and
04:45:10 <ski>   (x,y) = ...
04:45:13 <ski> is also legal
04:45:15 <Heffalump> yes, but (x,y) v = ... isn't
04:45:26 <Heffalump> which is sort of what you've written
04:45:43 <ski> in the former case, `x',`y' is provided to the body; in the latter case, the declaration exports `x' and `y'
04:46:05 <Heffalump> I agree, but neither of those is equivalent to what you wrote, IMO
04:46:27 <ski> well, the type of `(x,y)' must be a pair type, so it can't be applied to anything
04:46:42 <ski> but the type of `f -> p' can be any type, e.g. a function type
04:46:43 <Heffalump> ok, (\x -> f x) v = ...
04:46:55 <Heffalump> I don't think that's legal either even if technically it could bind f
04:47:31 <ski> (i think that could too be legal, with some restrictions on the body of the lambda-expression)
04:47:40 <Heffalump> *could be*, not *is* :-)
04:47:45 <ski> (but i'm not sure how useful that example would be)
04:47:47 <ski> right
04:47:52 <ski> but
04:48:02 <ski>   (Memo.integral -> foo) x = ..x..
04:48:16 <ski> appears to me to be a useful way to use view patterns
04:48:23 <Heffalump> perhaps
04:49:05 <ski> (for that matter, sometimes i've wanted `f@(g x) y = ...', too)
04:49:22 <Heffalump> what would that mean?
04:49:36 <ski> `f' would be bound in the body to `g x'
04:49:37 <Heffalump> f wouldn't have a value for x
04:49:45 <Heffalump> oh, just in the body
04:50:35 <ski> (in case that's the only equation for `g', one can instead write `g x = fix $ \f y -> ...')
05:01:21 <Berengal> Heffalump: It does work
05:01:54 <Berengal> (memo -> fib) = \n -> if n < 2 then 1 else fib (n-1) + fib (n-2)
05:02:12 <Berengal> import Data.MemoTrie, and compare that with the unmemoized version.
05:04:15 <ski> nice :)
05:04:44 <ski> i suppose `(memo -> fib) n = ...' doesn't work, though ?
05:05:15 <Berengal> No
05:05:23 <ski> a pity
05:05:32 <Berengal> A bit, yes, but understandable
05:06:01 <ski> it would probably require some extra work and sanity checking, i suppose
05:06:21 <ski> (i.e., what to do with multiple equations ?)
05:06:36 <Berengal> Indeed. I don't think there's a clear semantics for that
05:07:27 <Berengal> You could just do (memo -> fib) = f where f <rest of regular function definition goes here>
05:08:09 <ski> well, then you might as well do `fib = memo f where f <rest of regular function definition goes here>'
05:08:16 <Berengal> Then you've got all the multiple equations, pattern matchings and guards you'd ever want
05:08:28 <Berengal> Indeed
05:41:00 <SubStack> Hooray I can now do: subs Z (Var "C.z" - T * Var "D.z") $ subs Y (Var "C.y" - T * Var "D.y") $ subs X (Var "C.x" - T * Var "D.x") $ 3*X^2 + 0.5*(Y^2+X) + Z^2
05:41:21 <SubStack> which expands to an even hairier looking polynomial
05:42:19 <ski> why those strings in there ?
05:43:24 <SubStack> produces output closer to the glsl code I'll be generating
05:45:29 <ski> i was thinking it might be nicer with something like `Proj (Var "C") Z' instead of `Var "C.z"'
05:45:42 <ski> but maybe your code don't need to analyze that, anyway ..
05:49:47 <SubStack> you can put whatever you want in the string
05:50:56 * ski isn't doubting it
05:51:20 <SubStack> http://github.com/substack/hs-polynomial-builder/blob/master/lib/MathObj/Polynomial/Builder.hs
06:07:59 <gwern> huh. Jon Meachem now works at google
06:08:06 <gwern> should be very good for jhc
06:24:18 <merijn> Is there like an "FRP for dummies" explanation somewhere?
06:26:56 * nus suspects FRP isn't for dummies
06:29:21 <merijn> I know that, but I can't find any introductions on what exactly it is. Only papers referring to it which assume you already have a basic understanding what they mean by FRP
06:31:59 <MissPiggy> yeah FRP doesn't make any sense
06:32:40 <Berengal> There functions, and then something reacts, and you program with it...
06:32:42 <merijn> Well, what I gather from it it sounds like the paradigm I've been dreaming off, but I'm not sure I'm actually understanding it right :p
06:33:07 <nus> it makes sense to those who buy a notion of "continuous time"
06:34:07 <tensorpudding> it's a convenient illusion sometimes
06:34:49 <MissPiggy> do you think 'continuous time' is not reality?
06:35:10 <nus> merijn, the closest thing you get is Hudak's FRP from first principles.
06:35:28 <Twey> MissPiggy: Zeno's paradox says no
06:35:29 <helpseeker> hello
06:35:36 <helpseeker> is anyone around?
06:35:40 <Twey> But FRP doesn't give us continuous time, anyway
06:35:55 <Twey> Only to the precision supported by the underlying time representation
06:35:55 <merijn> Continuous time vs discrete time sounds like a Von Neumann-catastrophe tar pit
06:36:05 <Twey> helpseeker: Nope, nobody at all
06:36:17 <helpseeker> haha
06:36:22 <ski> Twey : you're wrong. anyone is around
06:36:31 <helpseeker> I was in loads of chat rooms saying hi and there was no response
06:36:36 <Berengal> preflex: seen anyone
06:36:36 <preflex>  Sorry, I haven't seen anyone
06:36:43 <helpseeker> Does anyone here know Java - i know this is the haskell room.
06:36:53 <burp> lol
06:36:57 <ski> helpseeker : tried ##java ?
06:37:08 <helpseeker> yeah, i went to all the java room
06:37:14 <helpseeker> no one seems to be responding
06:37:17 <ski> on this network ?
06:37:29 <mauke> helpseeker: have you tried #metallica?
06:37:31 <helpseeker> this had a high amount of ppl in so i was trying my luck
06:37:31 <Twey> Hm, we're seeing a resurgence of Java-related questions lately.
06:37:38 <Twey> Homework season again?
06:37:40 <tensorpudding> if you have a specific question, try Stack Overflow
06:37:58 <helpseeker> it's a little more pressure than homework season, lol
06:38:05 <MissPiggy> oh what is it?
06:38:34 * jlouis happily forgot most of Java
06:38:36 <helpseeker> basically a group project in school
06:38:40 <mauke> #haskell-blah
06:38:44 <Berengal> aka. homework
06:38:46 <ski> helpseeker : maybe you're hired to do some Java job, but hasn't really learned the language, yet ?
06:38:48 <MissPiggy> group theory?
06:39:05 <helpseeker> a software development project that is given out to all student groups
06:39:06 <Twey> helpseeker: Which school?
06:39:33 <burp> yup homework ;-)
06:39:34 <helpseeker> hmm, i might be volunteering information there
06:39:48 * Berengal programs haskell in java
06:40:00 * MissPiggy wonders if it's possible to build a quotient ring without zerop or abelianness
06:40:30 <ve> @let ndmap f [] = []; ndmap f (x:xs) = (f x : xs) : (map (x:) (ndmap f xs))
06:40:31 <tensorpudding> every ring has zero
06:40:32 <lambdabot>  Defined.
06:40:44 <MissPiggy> homwork is the work done by an arrow ?
06:40:45 <ve> is there some elegant monadic way to define 'ndmap' ?
06:40:53 <MissPiggy> :t ndmap
06:40:54 <lambdabot> forall a. (a -> a) -> [a] -> [[a]]
06:41:01 <merijn> MissPiggy: Isn't the existence of a zero and abelianness part of the definition of a ring?
06:41:06 <mmaruseacph2> where can i find Hudak's article?
06:41:09 <MissPiggy> > ndmap (+1) [0,1,2]
06:41:10 <lambdabot>   [[1,1,2],[0,2,2],[0,1,3]]
06:41:10 <mauke> > ndmap f [x,y,z]
06:41:11 <lambdabot>   [[f x,y,z],[x,f y,z],[x,y,f z]]
06:41:35 <merijn> mmaruseacph2: I found it in the ACM library, but that requires you have membership access to it: http://portal.acm.org/citation.cfm?id=349331
06:41:40 <tensorpudding> if you mean abelianness to mean what is meant by a commutative ring, that is not necessary for making a quotient ring out of it and one of its ideas
06:41:42 <tensorpudding> ideals*
06:41:42 <MissPiggy> merijn, by zerop I mean decidible zero test
06:42:04 <helpseeker> is there anyone in here i could pm that knows java. the main window suddenly got very busy
06:42:08 <MissPiggy> merijn, basically it is needed every number is zero or not zero.. but that is not possible constructive
06:42:32 <MissPiggy> tensorpudding: oh I mean the Quot(R) construction -- field of fractions
06:42:53 <MissPiggy> maybe I could somehow compute an ideal from R.. such that R/I ~ Quot(R)...
06:42:55 <tensorpudding> well, all fields are commutative rings
06:42:55 <mauke> helpseeker: you can try #haskell-blah, but java is off-topic here
06:43:13 <MissPiggy> really? damn I should have known that..
06:43:56 <mmaruseacph2> i found it here: Functional reactive programming from first principles
06:44:15 <mmaruseacph2> www.haskell.org/frp/frp-1st.pdf
06:44:22 <mmaruseacph2> bad copy-paste buffer
06:45:14 <merijn> Ah, nice. (I have a university subscription to the ACM anyhoo so I can get it for free from there via an SSH tunnel :p)
06:45:36 <mmaruseacph2> i'd do that too:)
06:45:48 <ski> > do (a,a_as) <- element [x,y,z]; return (a_as (f a)) :: [[Expr]]
06:45:49 <lambdabot>   [[f x,y,z],[x,f y,z],[x,y,f z]]
06:46:25 <ski> > map (\(a,a_as) -> a_as (f a)) (element [x,y,z])
06:46:26 <lambdabot>   [[f x,y,z],[x,f y,z],[x,y,f z]]
06:46:54 <ski> ve : does that look ok ?
06:50:04 <ski> @type \f -> map (uncurry (flip (. f))) . element
06:50:05 <lambdabot> forall a. (a -> a) -> [a] -> [[a]]
06:50:11 <ski> @type \f -> fmap (uncurry (flip (. f))) . element
06:50:12 <lambdabot> forall a (f :: * -> *). (Functor f, MonadPlus f) => (a -> a) -> [a] -> f [a]
06:50:39 <chrissbx> Is there a shorter way to write "\x->case x of "?
06:50:51 <ski> no :(
06:51:09 <chrissbx> k
06:52:02 <ve> ski: yeah, thanks
06:52:22 <ski> ve : probably, you'll want my definition of `element', though ..
06:52:41 <ve> oh, it's not in Prelude then
06:52:59 <ski> no, i defined in on the spot, in lambdabot
06:53:19 <ski> (it might be part of a functional reference library, though)
06:53:52 <ski> it's up to you to decide whether your original definition is nicer / more useful than the one via `element'
06:54:18 <ski> the definition is basically
06:54:45 <Berengal> chrissbx: let f 0 = ..; f 1 = ... in f
06:55:00 <ski>   type FRefM m a b = a -> m (b,b -> a)
06:55:18 <ski>   element :: MonadPlus m => FRefM [a] a
06:55:25 <ski>   element [    ] = mzero
06:55:35 <ski>   element (a:as) = return (a,(: as))
06:56:02 <ski>            `mplus` do (a',f) <- element as
06:56:11 <ski>                       return (a',\a' -> a:f a')
06:56:30 <ski> (you would fix `m' to `[]', if you prefer ..)
06:56:49 <ski> `element' is basically a (nondeterministic) functional reference to any element in a list
06:56:57 <etpace> I have a getLine, but things such as backspace don't actually backspace but print a weird character, any ideas?
06:57:20 <Berengal> etpace: Use a better terminal
06:57:39 <ski> (if one were making a library out of this, then `FRefM' would probably be a `newtype' rather than a type synonym)
06:58:14 <etpace> im using urxvt Berengal, which seems pretty good?
06:58:29 <Berengal> etpace: Well, yes. What buffering are you using?
06:59:53 <etpace> default I guess
07:00:38 <Berengal> Try setting it to line buffered, see if that helps
07:00:46 <nus> etpace, use a better termcap :-P (-;
07:01:04 <nus> etpace, i.e. ^? vs ^H
07:02:00 <etpace> yeah, it's ^?
07:02:03 <etpace> how do I change it?
07:02:28 <mauke> etpace: is this in ghci?
07:02:36 <etpace> yeah
07:02:44 <mauke> ghci changes your terminal settings
07:02:47 <mauke> you're not in default mode
07:03:36 <appamatto> have there been major developments since the STG machine?
07:03:36 <etpace> what mode should I uh, change it to
07:04:16 * mauke wouldn't bother
07:24:43 <yaru1022> How do I get the n-th element from n-tuple?
07:25:01 <mauke> there are no n-tuples, and the answer is pattern matching
07:25:01 <Zao> There's fst/snd for 2-tuples.
07:25:04 <Zao> For others, match.
07:25:14 <Zao> Some libraries define fst3/snd3/etc.
07:25:16 <Zao> But that's silly.
07:25:19 <yaru1022> hm.. so if n is fairly large, patternmatching is still the solution?
07:25:26 <mauke> svn9
07:25:34 <Zao> Pattern matching or define helper functions.
07:25:36 <mauke> yaru1022: why do you have fairly large tuples?
07:25:41 <Zao> Or define data types like sane people.
07:26:08 <yaru1022> mauke, I'm just curious how else I can deal with it...
07:26:22 <mauke> nested tuples, or custom data types
07:26:28 <Twey> Type-lists!
07:26:34 <mauke> or plain lists
07:26:55 <yaru1022> I see...
07:54:30 <mreh> are there any strict functors?
07:55:06 <jmcarthur> define "strict functor"
07:56:07 <jmcarthur> fmap is strict according to the laws, if that's what you mean, so in that sense all Functors are strict
07:56:24 <jmcarthur> fmap f _|_ = _|_
07:56:33 <jmcarthur> err
07:56:36 <jmcarthur> fmap id _|_ = _|_
07:56:47 <jmcarthur> but i think that applies to any lifted function too
08:08:34 <mreh> how do I expand "sequence 11 [False,True]" with TH?
08:08:54 <MissPiggy> mreh why don't you just put
08:09:02 <MissPiggy> module Bits (bits) where
08:09:04 <MissPiggy> bits = sequence 11 [False,True]
08:09:12 <MissPiggy> then compile that file with optimization
08:09:19 <mauke> :t sequence
08:09:20 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
08:11:46 <mreh> not sequence, replicateM 11 [False, True]
08:14:00 <mreh> MissPiggy: why wouldn't that binding be optimising in the module it's in currently?
08:14:12 <mreh> s/optimising/optimised/
08:14:43 <MissPiggy> mreh not sure what you mean
08:14:45 <benmachine> > replicateM 11 [False, True]
08:14:46 <lambdabot>   [[False,False,False,False,False,False,False,False,False,False,False],[False...
08:15:01 <benmachine> you realise that would be a list like 2000 long?
08:15:37 <mreh> benmachine: yes, 2048 long
08:15:44 <mreh> but not too large to fit in memory
08:15:47 <benmachine> 2048 is like 2000
08:15:51 <benmachine> <_<
08:18:56 <mreh> > 2^11
08:18:57 <lambdabot>   2048
08:18:59 <mreh> :D
08:19:21 <gwern> @hoogle map
08:19:21 <lambdabot> Prelude map :: (a -> b) -> [a] -> [b]
08:19:21 <lambdabot> Data.ByteString map :: (Word8 -> Word8) -> ByteString -> ByteString
08:19:21 <lambdabot> Data.IntMap map :: (a -> b) -> IntMap a -> IntMap b
08:19:40 <benmachine> mreh: I'm not an expert in TH so I can't tell you the best way
08:19:44 <benmachine> but this seems to work for me:
08:19:56 <benmachine> bits = $(return . ListE . map ListE . replicateM 11 $ [ConE (mkName "False"), ConE (mkName "True")])
08:20:20 <benmachine> (with import Language.Haskell.TH)
08:21:49 <benmachine> bits = $(return . ListE . map ListE . replicateM 11 . map (ConE . mkName) $ ["False", "True"])
08:21:59 * benmachine wonders if that can be fused somehow
08:22:04 <mreh> can't you construct the abstract syntax tree directly from haskell source?
08:22:08 * benmachine wonders if the return can be deleted
08:22:17 <benmachine> mreh: like I said, I can't tell you the best way
08:22:19 <mreh> isn't there a function that compiles haskell and returns an Expr
08:22:26 <benmachine> probably you can but I don't know how
08:22:37 <mreh> benmachine: you need the return to lift it into the Quotation monad, from what I am aware
08:22:55 <MissPiggy> mreh what's wrong with doing what I said?
08:23:18 <mreh> MissPiggy: Optimisation doesn't work like that
08:23:55 <mreh> what if you tried to optimise an infinitely recursive function by expanding it?
08:25:03 <mreh> aaah benmachine: [| ... |] takes haskell code and returns an Expr
08:25:23 <MissPiggy> mreh I don't really what you mean by that
08:25:39 <MissPiggy> mreh is your real example (which this is a simplified version of) an infinite stream?
08:25:54 <mreh> > let ones = 1 : ones in ones
08:25:55 <lambdabot>   [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...
08:26:34 <MissPiggy> lets assume that I know what an infinite stream is for the purpose of this discussion
08:27:16 <mreh> if you think what I just created is an infinite stream, I would agree with you
08:27:26 <mreh> that's what I would call that
08:27:43 <mreh> or that's how I know the term "infinite stream"
08:27:46 <merijn> mreh: Cyclical and infinite amount to the same thing in most useful discussions
08:27:52 <MissPiggy> okay this isn't working I guess, because you have your heart set on TH for some (possibly bad) reason
08:29:52 <mreh> MissPiggy: I'm doing what I think works, I'm not convinced that simply running compiler optimisations would do it
08:30:05 <mreh> i'm about to empirically test that
08:30:15 <mreh> so i'll tell you how it goes :)
08:30:20 <MissPiggy> mreh oh you are guessing that what I said doesn't work
08:30:34 <MissPiggy> mreh I thought you had some kind of objective reason why it didn't solve the problem
08:31:21 <mreh> MissPiggy: it's nothing personal
08:31:45 <mreh> please explain what you meant, you might convince me :)
08:34:32 <mreh> MissPiggy: it is faster using template Haskell, I wanted the expression fully expanded at compile time, optimisation doesn't appear to do that in this case
08:34:56 <MissPiggy> okay
08:36:08 <mreh> expanding a function like that isn't something that is decidable I would suspect, so it's not the kind of optimisation you could do safely
08:36:21 <MissPiggy> yes that's true
08:43:55 * bos fiddles with continuations-as-monoids
08:46:45 <MissPiggy> bos that is an interesting concept is the operation composition?
08:47:00 <MissPiggy> @src Cont
08:47:00 <lambdabot> newtype Cont r a = Cont { runCont :: (a -> r) -> r }
08:47:03 <bos> MissPiggy: trying to figure that out, sans answer
08:47:28 <MissPiggy> bos is this for  Cont m m  ? or  Cont r a ?
08:47:33 <MissPiggy> hmm
08:47:52 <MissPiggy> wait a min Cont is a monad can't we get a monoid out of a monad for free?
08:47:54 <bos> MissPiggy: my observation was that the type S String String is isomorphic to the continuation String -> String -> a
08:48:12 <MissPiggy> is that different lists?
08:48:37 <bos> it's trivial to turn S String String into a monoid (there are obviously several possible monoids that fit), but turning the continuation form into a comparable monoid is messier
08:57:31 <ski> bos : `S' being ?
08:58:02 <bos> ski: doesn't really matter
08:58:42 <ddarius> I think he meant (String, String) (?)
08:58:47 <bos> Right
08:58:57 <bos> "some product type"
08:59:06 <sm> morning all
08:59:35 <sm> How can I construct a tuple with similar elements, like (sumPostings realPostings t, sumPostings virtualPostings t, sumPostings balancedVirtualPostings t) in a more concise way ?
09:00:51 <ddarius> :t (,,) <$> ($ ?realPostings) <*> ($ ?virtualPostings) <*> ($ ?balancedVirtualPostings)
09:00:52 <lambdabot> forall a b. (?realPostings::a, ?virtualPostings::a, ?balancedVirtualPostings::a) => (a -> b) -> (b, b, b)
09:01:13 <ddarius> :t ((,,) <$> ($ ?realPostings) <*> ($ ?virtualPostings) <*> ($ ?balancedVirtualPostings)) ?sumPostings ?t
09:01:14 <lambdabot>     Couldn't match expected type `t1 -> t'
09:01:14 <lambdabot>            against inferred type `(a, a1, a2)'
09:01:14 <lambdabot>     In the first argument of `(<$>)', namely `(,,)'
09:01:17 <ddarius> Curses.
09:01:20 <ski> @djinn (string,string) -> ((string -> string -> a) -> a)
09:01:20 <lambdabot> f (a, b) c = c b a
09:01:32 <Alpounet> heh
09:01:33 <ski> (NCurses ?)
09:01:49 <Twey> ‘string’?
09:01:55 <ski> yes
09:02:42 <sm> ddarius: thanks. Did your example work, or not ? I can't tell :)
09:02:42 <Twey> Looks like… f = flip . uncurry $ flip id
09:02:45 <bos> fascinating. pulling apart my product type and using it as function arguments made no difference to performance.
09:02:49 <ski> (writing a type variable `string' there makes djinn treat it abstractly, which was good enough here (and even what i wanted))
09:02:50 <sm> also what are those leading $'s for ?
09:03:15 <ddarius> sm: I didn't quite get what I wanted, but you can use the same technique to pull out the t or the sumPostings.
09:03:44 <Twey> Err, no
09:04:15 <ddarius> :t (,,) <$> ?sumPostings ?realPostings <*> ?sumPostings ?virtualPostings <*> ?sumPostings ?balancedVirtualPostings
09:04:16 <lambdabot> forall a t (f :: * -> *). (?balancedVirtualPostings::t, ?sumPostings::t -> f a, ?virtualPostings::t, Applicative f, ?realPostings::t) => f (a, a, a)
09:04:32 <ddarius> :t ((,,) <$> ?sumPostings ?realPostings <*> ?sumPostings ?virtualPostings <*> ?sumPostings ?balancedVirtualPostings) ?t
09:04:33 <lambdabot> forall a t t1. (?t::t1, ?balancedVirtualPostings::t, ?sumPostings::t -> t1 -> a, ?virtualPostings::t, Applicative ((->) t1), ?realPostings::t) => (a, a, a)
09:04:54 <sm> ok, I get it. The ? are something for lambdabot eh
09:05:07 <ski> no, it's implicit parameters
09:05:13 <ddarius> sm: No, they are the implicit parameters extension, but it is handy for lambdabot.
09:05:25 <sm> yikes. Ok, a new thing
09:05:38 <ddarius> I dislike implicit parameters.
09:05:54 <sm> and when I see <$> and <*> I should be thinking which english words.. functor ? mappend ?
09:05:59 <ddarius> They are not a very popular extension.
09:06:09 <ddarius> (<$>) = fmap
09:06:35 <ddarius> And (<*>) is a generalization of Monad's ap which is a monadic version of application.
09:06:35 <Alpounet> <*> is pretty simple too
09:06:40 <monadic_kid> <$> application, <*> give each argument
09:06:41 <Alpounet> :t (<*>)
09:06:42 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f (a -> b) -> f a -> f b
09:06:49 <sm> thanks
09:07:35 <monadic_kid> if you don't give enough <*> for each arg you'll get a partially applied (lifted) function
09:08:41 <ski> @type undefined `asTypeIn` \(sumPostings,realPostings,virtualPostings,balancedVirtualPostings,t) -> ((,,) <$> sumPostings realPostings <*> sumPostings virtualPostings <*> sumPostings balancedVirtualPostings) t
09:08:42 <lambdabot> forall t t1 a. (t -> t1 -> a, t, t, t, t1)
09:09:23 <ski> (possibly not really better, in this case)
09:09:31 <ddarius> Probably not.
09:09:49 <ddarius> Though, it does avoid naming whatever expression t is bound to.
09:11:16 <ddarius> If the types are all the same, you can just use map and pattern matching, though that is a bit ugly.
09:12:13 <benmachine> :t asTypeIn
09:12:14 <lambdabot> forall a b. a -> (a -> b) -> a
09:12:52 <blueonyx> hi, when using ghc as a lib it throughs a panic defaultDynFlags: No filesToClean at me, but the simple example from wiki work, any ideas?
09:16:37 <sm> (,,) <$> sumPostings.realPostings <*> sumPostings.virtualPostings <*> sumPostings.balancedVirtualPostings
09:16:52 <sm> but yes it seems hard to extract the sumPostings
09:17:11 <sm> yes, I was inclined to use a list and convert to tuple somehow
09:17:42 <sm> but I've probably chased this enough. Thanks for helping me upgrade my fmap/ap skills
09:19:13 <zygoloid> @type (,,) <$> ($ ?realPostings) <*> ($ ?virtualPostings) <*> ($ ?balancedVirtualPostings) $ flip ?sumPostings ?t
09:19:14 <lambdabot> forall a b a1. (?realPostings::a, ?virtualPostings::a, ?balancedVirtualPostings::a, ?sumPostings::a -> a1 -> b, ?t::a1) => (b, b, b)
09:20:01 * ski wonders what "extract" means, here
09:21:42 <ddarius> Good call zygoloid
09:23:50 <ddarius> > ((,) <$> f <*> g) x
09:23:51 <lambdabot>   Ambiguous type variable `a' in the constraints:
09:23:51 <lambdabot>    `GHC.Show.Show a'
09:23:51 <lambdabot>      a...
09:24:05 <ddarius> > ((,) <$> f <*> g) x :: (Expr, Expr)
09:24:06 <lambdabot>   (f x,g x)
09:24:47 <monadic_kid> if I used a guard function (MonadPlus) inside a ErrorT IOError IO what exception is thrown userError?
09:25:01 <ddarius> @src guard
09:25:01 <lambdabot> guard True  =  return ()
09:25:01 <lambdabot> guard False =  mzero
09:25:09 <ddarius> Whatever mzero is defined as.
09:25:59 <ddarius> > fromLeft (mzero :: ErrorT IOError IO ())
09:26:00 <lambdabot>   Not in scope: `fromLeft'
09:26:19 <ddarius> Wouldn't have worked anyway.
09:26:20 <choffstein> anyone using the zeromq binding?
09:26:23 <ddarius> @src ErrorT mzero
09:26:24 <lambdabot> mzero       = ErrorT $ return (Left noMsg)
09:26:36 <ddarius> @src IOError Error
09:26:37 <choffstein> I am having a wee bit of trouble getting the cabal package installed
09:26:37 <lambdabot> Source not found. You untyped fool!
09:28:19 <monadic_kid> i can find instance declarations but not definitions
09:28:44 <monadic_kid> okay it gives a userError
09:29:11 <monadic_kid> okay it gives a: userError "mzero" lol
09:29:24 <wagle> where do you go for the current haskell-platform?  http://hackage.haskell.org/platform/ is bit-rotted
09:29:50 <benmachine> ghci> runErrorT (mzero :: (ErrorT IOError IO ()))
09:29:50 <benmachine> Left user error
09:30:29 <benmachine> wagle: what makes you think it's rotted?
09:30:58 <wagle> doesnt actually work?  has same bugs from 6 months ago
09:31:18 <wagle> wont upgrade
09:32:28 <benmachine> won't upgrade?
09:33:54 <wagle> go do if from the 2.0.2 tarball, then put me through the wringer
09:34:01 <wagle> go do it from the 2.0.2 tarball, then put me through the wringer
09:34:06 <wagle> on a debian system
09:34:23 <benmachine> don't have a debian system :P
09:34:52 <benmachine> in conclusion I am entirely useless to you
09:34:56 <benmachine> but maybe someone else won't be
09:35:08 <wagle> the timestamp on the website is Fri Jul 31 15:11:11 PDT 2009
09:35:26 <benmachine> the haskell platform is meant to be stable
09:35:35 <benmachine> there will be a new release in the not too distant future
09:35:37 <wagle> all i asked is if that was the most uptodate version of the website
09:35:41 <benmachine> oh
09:35:51 <benmachine> as far as I know yes
09:35:55 <wagle> if it is, then i have my work cutout for me
09:36:05 * benmachine just uses cabal to install stuff
09:36:42 <wagle> i tried to upgrade yesterday, and today gitit (pandoc) is b0rk)
09:38:43 <monadic_kid> I guess there is no point i n using ErrorT with IOError if I change the guard predicate to just throw an exception
09:39:38 <monadic_kid> that's the only reason I started to use ErrorT, because I was using a guard predicate
09:39:50 <monadic_kid> changed from using MaybeT
09:40:52 <gwern> @hoogle fmap
09:40:52 <lambdabot> Prelude fmap :: Functor f => (a -> b) -> f a -> f b
09:40:53 <lambdabot> Control.Monad fmap :: Functor f => (a -> b) -> f a -> f b
09:40:53 <lambdabot> Control.Monad.Instances fmap :: Functor f => (a -> b) -> f a -> f b
09:40:55 <serhalp> Is there any way to... err, pretty print a function?  Say I have f "a" = 1, f "b" = 2, f "c" = 3, is there any way I can do (show f) and see all the definitions?
09:41:54 <mauke> no
09:42:24 <serhalp> At all?
09:42:29 <MissPiggy> serhalp, the thing is...
09:42:29 <medfly> > show f
09:42:35 <lambdabot>   Ambiguous type variable `a' in the constraints:
09:42:36 <lambdabot>    `GHC.Show.Show a'
09:42:36 <lambdabot>      a...
09:42:40 <medfly> :/
09:42:53 <MissPiggy> serhalp, this COULD be possible for basic functions (i.e. the ones you write in a file),  but what would the show instance do for compositions and such?
09:43:16 <ddarius> MissPiggy: See J.
09:44:26 <serhalp> I... don't know.  Beginner here.
09:46:10 <benmachine> serhalp: there is no way to tell the difference between f "blah" = 3; f _ = 2 and g _ = 2 except by giving "blah" to it and getting 3
09:46:34 <benmachine> thus it is possible to show a function if and only if you can conduct an exhaustive search of its entire possible input
09:46:43 <etpace> @hoogle -> ((a,b) -> (a, m b)) -> [(a, b)] -> m [(a, b)]
09:46:43 <lambdabot> Parse error:
09:46:43 <lambdabot>   --count=20 "-> ((a,b) -> (a, m b)) -> [(a, b)] -> m [(a, b)]"
09:46:44 <lambdabot>              ^
09:46:47 <etpace> @hoogle ((a,b) -> (a, m b)) -> [(a, b)] -> m [(a, b)]
09:46:47 <lambdabot> No results found
09:47:00 <etpace> any ideas on that?
09:47:27 <benmachine> :t \(a, b) -> fmap ((,) a) b
09:47:28 <lambdabot> forall t a (f :: * -> *). (Functor f) => (t, f a) -> f (t, a)
09:47:38 <benmachine> :t sequence . (\(a, b) -> fmap ((,) a) b)
09:47:39 <lambdabot> forall t a. (Monad ((,) t)) => (t, [a]) -> (t, [a])
09:47:47 <benmachine> erm
09:47:59 <manjunaths> hello
09:48:07 <benmachine> :t mapM . (\(a, b) -> fmap ((,) a) b)
09:48:08 <lambdabot> forall a t a1. (Monad ((,) t)) => (t, a -> a1) -> [a] -> (t, [a1])
09:48:14 <benmachine> ugh
09:48:24 <serhalp> Alright, thank you.
09:49:01 <manjunaths> I have a list of Vector3 objects, where Vector3 is defined as data Vector3 = Vector3 !a !a !a
09:49:20 <manjunaths> I defined a function as addForce m (Vector3 x y z) = Vector3 (x/m) (y/m) (z/m)
09:49:24 <ddarius> > let f (a, m) = do b <- m; return (a,b) in mapM . (f .)
09:49:25 <lambdabot>   No instances for (Test.SmallCheck.Serial (m t1),
09:49:25 <lambdabot>                    GHC.Sho...
09:49:32 <ddarius> :t let f (a, m) = do b <- m; return (a,b) in mapM . (f .)
09:49:33 <lambdabot> forall a (m :: * -> *) t t1. (Monad m) => (a -> (t, m t1)) -> [a] -> m [(t, t1)]
09:49:44 <manjunaths> which is this not working ? [ (addForce 3.0) x | x <- particles]
09:49:56 <benmachine> :t \f -> mapM ((\(a, b) -> (,) a <$> b) . f)
09:49:57 <lambdabot> forall t a (m :: * -> *) a1. (Functor m, Monad m) => (a1 -> (t, m a)) -> [a1] -> m [(t, a)]
09:49:58 <manjunaths> s/which/why
09:50:11 <benmachine> let a1 = (t, a)
09:50:26 <dankna> manjunaths: what error message do you get, or what incorrect result?
09:50:36 <etpace> cheerss fella
09:50:58 <manjunaths> No instance for (Fractional Integer) arising from a use of `addForce' at <interactive>:1:2-15
09:51:15 <dankna> oh, yeah.
09:51:30 <gwern> anyone know when ghc 6.14 is scheduled for release?
09:51:41 <dankna> you defined your vector type to contain ANY content type
09:51:49 <dankna> in this case you have created your array containing integers
09:52:00 <dankna> but you're trying to divide them by floats
09:52:07 <dankna> Haskell doesn't have automatic promotion for numeric types
09:52:09 <benmachine> manjunaths: is it actually data Vector3 a = Vector3 !a !a !a
09:52:31 <benmachine> dankna: I wouldn't call Integer -> Double a "promotion" :P
09:52:34 <dankna> haha, well, yeah
09:52:39 <dankna> anyway Haskell doesn't do it
09:52:42 <benmachine> yes
09:52:58 <benmachine> (addForce 3) should work fine
09:53:19 <benmachine> if you actually want to work with vectors of integers
09:53:22 <benmachine> which you probably don't
09:53:30 <benmachine> (also depends on what addForce is/does)
09:53:39 <benmachine> oh wait
09:53:40 <benmachine> you said
09:53:41 <dankna> yeah, you probably meant to create it as vectors of floats, but it's hard for us to know that
09:53:49 <benmachine> ok (addForce 3) won't work
09:54:09 <manjunaths> it is addForce of 3.0
09:54:21 <manjunaths> hmm...you are right
09:54:25 <manjunaths> it is integers
09:55:02 <mauke> <benmachine> (addForce 3) should work fine  <- not it shouldn't
09:55:04 <dankna> there are a few possible solutions.  if you want your vector type to only ever hold floats, you could define it as data Vector3 = Vector3 !Float !Float !Float
09:55:09 <dankna> (or Double instead of Float)
09:55:34 <mauke> s/not/no,/
09:55:40 <dankna> or if you do want it generic, you need to at the very least add a context that ensures that the content type is numerical:
09:55:40 <manjunaths> dankna, I can't because it is part of Graphics.Rendering.OpenGL
09:55:51 <dankna> oh, right, okay
09:55:58 <dankna> well, then I'll skip that example
09:56:04 <wagle> benmachine: thanks anyway..  i'm trying the default debian install this time..  last time i had to install bleeding edge ghc
09:56:05 <benmachine> mauke: < manjunaths> it is addForce of 3.0
09:56:13 <benmachine> err
09:56:16 <benmachine> that is the wrong past
09:56:17 <benmachine> that is the wrong paste
09:56:21 <manjunaths> I'll paste to reduce confusion
09:56:29 <benmachine> mauke: < benmachine> ok (addForce 3) won't work
09:56:30 <benmachine> :P
09:56:37 <benmachine> manjunaths: try -fwarn-type-defaults
09:56:39 <benmachine> when compiling
09:56:43 <benmachine> see if it says something interesting
09:56:59 <manjunaths> benmachine, ok
09:57:16 <dankna> that flag should help you locate where you're creating your vectors
09:57:25 <dankna> the fix is probably to do something like
09:57:34 <benmachine> an explicit type signature
09:57:47 <dankna> Vector3 = (fromIntegral x) (fromIntegral y) (fromIntegral z) :: Vector3 GLfloat
09:57:50 <manjunaths> http://moonpatio.net/fastcgi/hpaste.fcgi/view?id=8124#a8124
09:58:01 <manjunaths> dankna, ah
10:00:26 <manjunaths> ok...this is confusing
10:01:47 <manjunaths> I still don't know what to do ?
10:02:11 <wagle> wow..  haskell-platform isnt just a package, its an adventure!
10:03:10 <wagle> (refuses to run with the debian ghc, which comes in 162 packages)
10:03:14 <benmachine> sarcasm makes computers go faster
10:03:27 <wagle> yup
10:04:39 <wagle> you try to get instructions to install ghc on debian, it says to go to debian packages..  which dont actually work..  hence the adventure isn't completely sarcasm
10:05:30 <wagle> part of this is that nothing has changes in over 6 months
10:05:35 <wagle> changed
10:05:39 <Heffalump> in what Debian?
10:05:45 <Heffalump> I thought unstable is quite up to date
10:08:38 <ccasin> if my cabal file has multiple "cpp-options:" lines, will these be combined?
10:12:56 <wagle> Heffalump: not sure, which mens, probably not unstable
10:13:09 <wagle> means
10:15:52 <manjunaths> how do I do nothing in main, that is just call a function which does stuff and print some junk.
10:15:58 <manjunaths> both are unrelated
10:16:29 <Lemmih> manjunaths: What?
10:18:02 <manjunaths> I want to time how much time something takes
10:18:14 <manjunaths> but in main it asks for IO, I don't want to do IO
10:18:46 <chrissbx> Isn't taking the time IO already?
10:18:59 <manjunaths> oh
10:19:07 <manjunaths> well I was taking time outside
10:19:17 <chrissbx> aha.
10:19:18 <manjunaths> like /usr/bin/time clothsim
10:19:25 <mreh> @pl (\x y -> pred y * x)
10:19:25 <lambdabot> (. pred) . (*)
10:19:34 <tensorpudding> running /usr/bin/time counts as IO too
10:20:11 <Lemmih> manjunaths: Write your main function to evaluate what you want to evaluate.
10:20:59 <manjunaths> main = do
10:21:00 <manjunaths>   map (addForce 3.0) particles
10:21:04 <manjunaths> I did it doesn't compile
10:21:13 <manjunaths> is there something like
10:21:20 <manjunaths> main = do
10:21:22 <manjunaths> is there something like
10:21:24 <manjunaths> main = do
10:21:27 <manjunaths>   map (addForce 3.0) particles
10:21:27 <chrissbx> manjunaths: the problem is that if you want the code to *do* something it is with regards to the outside world, it is IO
10:21:37 <Lemmih> @type Control.Exception.evaluate
10:21:38 <lambdabot> forall a. a -> IO a
10:21:39 <Zao> manjunaths: You need to have an IO action that in the end results in forcing the whole computation.
10:22:02 <Zao> manjunaths: If you do not touch any of the results of your computation, much of it will never run, thanks to lazyness.
10:22:13 <philo> hi
10:22:14 <manjunaths> Zao, then how do I time only the above function ?
10:22:18 <Lemmih> manjunaths: You're best off printing some kind of result.
10:22:18 <Zao> > let x = map (+1) [0..] in 3
10:22:19 <lambdabot>   3
10:22:23 <philo> does bounds for IOarray exist ?
10:22:34 <manjunaths> Zao, ah
10:22:38 <philo> "bounds"
10:22:45 <Lemmih> philo: getBounds
10:22:53 <philo> Lemmih: thanks
10:23:02 <Zao> manjunaths: It depends on what you want to measure and in what context.
10:23:26 <Zao> manjunaths: Just because you have a tunk representing a computation doesn't mean the computation will actually be done.
10:23:35 <philo> so "http://cvs.haskell.org/Hugs/pages/libraries/base/Data-Array-MArray.html#v%3Abounds" is wrong ?
10:23:43 <Zao> > take 3 [0..]
10:23:44 <lambdabot>   [0,1,2]
10:23:54 <sm> manjunaths: in other words, you can often force it by prepending putStr $ show $  to it in main
10:24:03 <Zao> There only the computations needed to give me the first three elements of the list was done, nothing more.
10:24:13 <Zao> sm: But would skew results due to formatting and outputting.
10:24:20 <manjunaths> sm, I did, but then show and putStr also come into the timing
10:24:44 <chrissbx> manjunaths: but starting the binary takes time too
10:24:45 <Lemmih> philo: Yes, http://www.haskell.org/ghc/docs/latest/html/libraries/array-0.3.0.0/Data-Array-MArray.html
10:24:58 <Zao> sm: Of course, you assume it's Show too.
10:24:59 <sm> indeed, well I would show the length for a big list, but if you are getting into fine precision use criterion
10:25:13 <tensorpudding> take 5 [1,2,3,4,5,undefined]
10:25:20 <tensorpudding> > take 5 [1,2,3,4,5,undefined]
10:25:21 <lambdabot>   [1,2,3,4,5]
10:25:31 <tensorpudding> > take 6 [1,2,3,4,5,undefined]
10:25:32 <lambdabot>   [1,2,3,4,5,* Exception: Prelude.undefined
10:25:33 <wagle> which version of cabal should i find for ghc 6.12.1 on a mac?
10:25:41 <Zao> wagle: 0.8.x?
10:26:38 <wagle> 1.6.0.2 cant parse the ghc-pkg dump
10:26:52 <philo> Lemmih:  thanks
10:27:19 <philo> the hugs things is the first result google give
10:27:24 <philo> that dangerous
10:30:05 <wagle> shouldn't ghc 6.12.1 install image for mac/intel come with cabal?
10:30:38 <c_wraith> wagle: that's haskell-platform's job, and it hasn't been finished for 6.12 yet
10:31:34 <Draconx|Laptop> GHC 6.12 comes with cabal 1.8.
10:31:37 <c_wraith> wagle: anyway, installing cabal-install is pretty painless
10:34:13 <tomberek> trying to use Text.PrettyPrint....  doesn't <> place two docs next to each other?
10:39:40 <wagle> c_wraith: technically, this all started when i tried to cabal-install on my several month old version..  refused to run, AND apparently broke my gitit server
10:40:01 <wagle> but hey, time to do it all over again
10:44:12 <bos> nice, i now have attoparsec parsing 102,000 HTTP requests per second
10:45:03 <copumpkin> not too shabby
10:45:20 <dons> so the parser isn't going to be the bottleneck.
10:46:40 <MaciejP> bos: Can you do the same things with attoparsec you can do with parsec?
10:50:40 <kw317> I am thinking of writing a simple binary classifier in haskell, and I wonder if anyone is aware of some ML notes / examples / slides using haskell as implementation language
10:51:21 <mreh> kw317: I find most of ML is taught in mathematica, becaue the practitioners are all Math grads :)
10:51:48 <mreh> kw317: i've written a Neural Network in haskell
10:51:59 * ski would think ML being taught in either SML or O'Caml ..
10:52:15 <mreh> Machine Learning
10:52:25 <ski> .. oh
10:52:33 <kw317> yeah, I forget the possiblity of confusion here ;-)
10:52:52 <tomberek> mreh: which one?
10:52:55 * ski has read a little on inductive logic programming
10:52:58 <tomberek> mreh: what package?
10:54:02 <mreh> tomberek: I wrote it just by composing functions in a on-line learning algorithm
10:54:28 <tomberek> can i see the code?
10:54:45 <mreh> tomberek: possibly, let me see if I have it with me
10:54:51 <Saizan> isn't inductive logic programming just logic programming?
10:55:12 <tomberek> Saizan: trying to use Text.PrettyPrint....  doesn't <> place two docs next to each other?
10:55:14 <mreh> not on this machine, can you ping me tomorrow? I'll send it to you then
10:55:21 <ski> Saizan : aiui, it's a kind of Machine Learning (of sorts)
10:55:32 <kw317> mreh: can I get a copy too?
10:55:38 <Saizan> tomberek: i've never used it
10:55:57 <tomberek> erg..
10:56:09 <tomberek> mreh: i'll try to remember
10:56:34 <Saizan> ski: ah
10:57:38 <mreh> tomberek: write a note :)
10:57:44 <MissPiggy> Saizan: it means to implement induction in the sense of educated guess, I think
10:57:56 <MissPiggy> or program with.. rather than implement
10:58:03 <tomberek> anyone have any experience with Text.PrettyPrint?
10:58:27 <tomberek> or a simple way to get two columns of text, lined up.
10:58:42 <shepheb> tomberek: printf :P
10:58:57 <Saizan> ah, yeah, it infers the hypothesis from the observations, much like philosophical induction
10:59:28 <tomberek> shepheb, printf doesn't line up columns
10:59:53 <ski> @hoogle prettyPrintf
10:59:53 <lambdabot> No results found
11:00:03 <shepheb> tomberek: it does if you specify field widths appropriately
11:00:28 <shepheb> or do you mean two paragraphs, with word wrapping?
11:01:09 <tomberek> shepheb: i have two blocks of text that I want to be printed next to each other, not above below
11:01:21 <shepheb> word-wrap to 37 columns, then zipWith (\x y -> x ++ "      " ++ y)?
11:05:00 <Hiato> Hey all, I have yet another newb-type problem and I was wondering if someone could explain what was going wrong in: max [x*y|x<-[10..99],y<-[10..99], show (x*y) == reverse $ show (x*y)]? It moans about the show type from [t] -> [t], which I cant see as an issue as the show (bleh) is never returned
11:05:20 <mauke> :t max
11:05:21 <lambdabot> forall a. (Ord a) => a -> a -> a
11:05:33 <mauke> Hiato: you're trying to print a function, which is impossible
11:05:41 <tomberek> shepheb,,,I know that it's possible that way,, it just seems like there should be a more elegant way,, i though PrettyPrint did it for you
11:06:04 <Hiato> Ah, right. So what, max $ [ .. ] ?
11:06:11 <ski> @type maximum
11:06:11 <mauke> that's still a function
11:06:12 <lambdabot> forall a. (Ord a) => [a] -> a
11:06:12 <c_wraith> :t maximum
11:06:13 <lambdabot> forall a. (Ord a) => [a] -> a
11:06:21 * ski grins
11:06:25 <Hiato> or do I need to use the do or something to get that to be evaluated
11:06:26 <MissPiggy> > max [x*y|x<-[10..99],y<-[10..99], show (x*y) == reverse $ show (x*y)]
11:06:27 <lambdabot>   Couldn't match expected type `GHC.Base.String'
11:06:28 <lambdabot>         against inferred typ...
11:06:54 <ski> Hiato : see that other function, just mentioned above ..
11:06:58 <MissPiggy> > [x*y|x<-[10..99],y<-[10..99], show (x*y) == reverse $ show (x*y)]
11:06:59 <mauke> Hiato: it is evaluated
11:06:59 <lambdabot>   Couldn't match expected type `GHC.Base.String'
11:06:59 <lambdabot>         against inferred typ...
11:07:05 <MissPiggy> > [x*y|x<-[10..99],y<-[10..99]]
11:07:06 <lambdabot>   [100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,28...
11:07:11 <MissPiggy> > [x*y|x<-[10..99],y<-[10..99],True]
11:07:12 <lambdabot>   [100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,28...
11:07:23 <ski> > show 0 == reverse $ show 0
11:07:24 <lambdabot>   Couldn't match expected type `GHC.Base.String'
11:07:24 <lambdabot>         against inferred typ...
11:07:28 <ski> > show 0 == reverse (show 0)
11:07:29 <lambdabot>   True
11:07:45 <ski> > (show 0 == reverse) show 0
11:07:46 <lambdabot>   Couldn't match expected type `GHC.Base.String'
11:07:46 <lambdabot>         against inferred typ...
11:07:52 <Hiato> so i need to use maximum vs max? I thought they had the same type signature
11:07:54 <MissPiggy> ahh show 0 == reverse $ show 0 is read asa (show 0 == reverse) (show 0)
11:08:00 <ski> Hiato : that last was what you were doing
11:08:01 <MissPiggy> > max [x*y|x<-[10..99],y<-[10..99], show (x*y) == reverse (show (x*y))]
11:08:01 <mauke> obviously they don't
11:08:02 <lambdabot>   []->
11:08:02 <lambdabot>    [121,242,363,484,616,737,858,979,1001,252,444,636,696,828,888,494,5...
11:08:08 <MissPiggy> > maximum [x*y|x<-[10..99],y<-[10..99], show (x*y) == reverse (show (x*y))]
11:08:09 <lambdabot>   9009
11:08:22 <Hiato> Ah, right. Ok, cool. But why is that?
11:08:26 <mauke> why is what?
11:08:43 <ski> one is for taking the maximum of two things
11:08:51 <Hiato> that max fails where maximum works. I realise that this is probably quite annoying to go through
11:08:55 <ski> the other is for taking the maximum of a (non-empty) list of things
11:09:04 <mauke> Hiato: because you don't understand what max does
11:09:05 <Hiato> Aha, right. Great. Thanks, problem solved :)
11:09:13 <mauke> max didn't fail
11:09:16 <Hiato> yep mauke, but now I do :)
11:09:27 <mauke> and if you give it another list, it will return the maximum of its two input lists
11:09:52 <Hiato> right, a different function for another time
11:10:10 <ski> > max (fail "") (fail "max (fail \"\")") :: Either String ()
11:10:11 <lambdabot>   Left "max (fail \"\")"
11:10:39 <Hiato> right, right
11:10:45 <mauke> > max 2 3
11:10:46 <lambdabot>   3
11:11:01 <mauke> > max [4, 5, 6] [3, 99, 4]
11:11:02 <lambdabot>   [4,5,6]
11:11:05 <Hiato> but maximum [1,2,3] ==> 3
11:11:15 <mauke> > maximum [ [4, 5, 6] [3, 99, 4] ]
11:11:16 <lambdabot>   Couldn't match expected type `t -> a' against inferred type `[a1]'
11:11:18 <mauke> > maximum [ [4, 5, 6], [3, 99, 4] ]
11:11:19 <lambdabot>   [4,5,6]
11:11:42 <Hiato> aha, right. Element by element comparison, right?
11:11:54 <Hiato> which is why [4,5,6] > [3,99,4]
11:11:58 <mauke> yes
11:11:59 <ski> lexicographic ordering
11:12:04 <Hiato> got it
11:13:41 --- mode: ChanServ set +b *!*@*.bb.dnainternet.fi
11:13:41 --- kick: saul1x was kicked by ChanServ (Banned: offender)
11:14:44 <hasenov> hello what function may I use that is similar to map that however breaks on some condition and does not go further in the list? I want to use takeWhile however I want to output the last value on while the break occured
11:15:46 <hasenov> so something like "takeWhile' (< 2) [1,2,3]' should output 3
11:16:11 <olsner> sounds like you want dropWhile
11:16:14 <mauke> > dropWhile (< 2) [1, 2, 3]
11:16:15 <lambdabot>   [2,3]
11:16:16 <BONUS> > find (not . (< 2)) [1,2,3]
11:16:18 <lambdabot>   Just 2
11:16:25 <mauke> > head $ dropWhile (< 2) [1, 2, 3]
11:16:26 <lambdabot>   2
11:16:50 <ski> > (fmap tail . span (<= 2)) [1,2,3]
11:16:51 <lambdabot>   ([1,2],[])
11:16:56 <ski> erm
11:16:57 <BONUS> or yeah, span
11:16:59 <ski> > (fmap head . span (<= 2)) [1,2,3]
11:17:00 <lambdabot>   ([1,2],3)
11:17:09 <mauke> head . snd
11:17:29 <sinelaw_> Happy Purim!
11:17:33 <hasenov> oh sorry for the typo, I meant "takeWhile' (< 3) [1,2,3]"
11:17:38 <ski> (or `dropWhile' as mauke said, if you don't want the initial part)
11:18:24 <sinelaw_> someone kick wulansari
11:18:33 <sinelaw_> sending me ads through pm
11:19:13 --- mode: ChanServ set +o mauke
11:19:13 --- kick: wulansari was kicked by mauke (/msg me if you aren't a bot)
11:19:20 <sinelaw_> heh
11:19:52 <sinelaw_> bbl
11:20:34 <hasenov> i think that will work though, since dropWhile doesn't evaluate the rest of the list it just returns the first occurance down
11:21:20 <ski> > (head . dropWhile (< 3)) [0,1,2,3,4]
11:21:22 <lambdabot>   3
11:21:24 <ski> > (head . dropWhile (< 3)) [0,1,2]
11:21:24 --- mode: mauke set -o mauke
11:21:25 <lambdabot>   * Exception: Prelude.head: empty list
11:21:56 <hasenov> thanks, I need to make a condition if there is no occurance
11:22:48 <int-e> > listToMaybe . dropWhile (< 3) $ [0..2]
11:22:49 <lambdabot>   Nothing
11:22:51 <int-e> > listToMaybe . dropWhile (< 3) $ [0..3]
11:22:52 <lambdabot>   Just 3
11:24:37 <int-e> @type msum . map return
11:24:38 <lambdabot> forall (m :: * -> *) a. (MonadPlus m) => [a] -> m a
11:26:35 <sm> yay, http://www.reddit.com/r/haskell/comments/b76bc/darcs_24_the_latest_and_greatest_in_easy_version/
11:35:01 <Vq> sm: yay indeed :)
11:49:57 <Stalafin> i have a function foo, which gives me True or False; what is the correct representation of not(foo(x))? not.foo x or not $ foo x ?
11:50:00 <Stalafin> i am confused with this
11:50:36 <bos> MaciejP: yes you can
11:50:46 <Lemmih> Stalafin: not (foo x)?
11:50:46 <bos> MaciejP: and more, quite often
11:50:52 <Stalafin> Lemmih: yeah, that one
11:50:53 <hasenov> Stalafin: both should work
11:50:54 <Stalafin> Lemmih: sry
11:51:23 <hasenov> though i think (not.foo) x would compile
11:51:33 <imc> hello!
11:51:38 <aavogt> also   not . foo $ x
11:51:54 <Stalafin> i see.... confusing stuff
11:52:27 <imc> how do I use Text.PrettyPrint.HughesPJ ? I have some data and would like to pretty print it (writing a "stripped down XML" parser)
11:53:16 <imc> normally I should make my data instance of Doc if I'm correct
11:54:51 <imc> maybe something like "instance Show MyData where show d = render (myDataToDoc d)" ?
11:56:46 <imc> some clue: http://lstephen.wordpress.com/2007/07/29/parsec-parser-testing-with-quickcheck/
11:59:17 <hasenov> Is there a way to pass a list along with another list in a foldr without using monads?
11:59:53 <Botje> i don't fully understand your question, what are you trying to do?
11:59:54 <jlouis> hasenov: where is the difference compared to using a zip?
12:00:29 <hasenov> what i mean is that I have a list [1..20] and I want to sum up all values that are not sum of two abundants
12:01:36 <aavogt> @type \p -> sum . filter p
12:01:37 <lambdabot> forall a. (Num a) => (a -> Bool) -> [a] -> a
12:01:48 <hasenov> if I see that the value is not a sum of two abundants based on a predefined list, I want to check if the number itself is an abundant and if it is add it to the list
12:02:13 <aavogt> lists are inefficient for querying membership
12:02:21 * ddarius is only familiar with the word "abundant" as an adjective.
12:02:34 <hasenov> then I want to pass the list of abundants along with the next number to check for in the next round of foldr
12:02:40 <Botje> ddarius: it's a project euler question, something to do with the number of divisors iirc
12:02:46 <aavogt> but there's elem if you want to check
12:03:28 <hasenov> aavogt: yeah, i am already using elem
12:03:48 <aavogt> then I don't understand what you're trying to do then
12:03:57 <Botje> hasenov: so you want something like foldr (\(result, abundants) x -> if (x `elem` abundants) then ... else ...) ([], set_of_abundants) [1..20]
12:04:05 <Botje> i guess?
12:04:52 <wagle> any ideas why i'd be getting stuff like this:
12:04:55 <wagle> Text/Feed/Import.hs:32:7:
12:04:55 <wagle>     Could not find module `System.IO.UTF8':
12:04:55 <wagle>       There are files missing in the `utf8-string-0.3.5' package,
12:05:39 <wagle> fresh install of 6.10.4 then haskell-platform
12:05:56 <wagle> 2009.2.0.2
12:06:02 <jlouis> system, distribution?
12:06:07 <wagle> debian
12:06:13 <wagle> lenny
12:06:25 <byorgey> wagle: not sure what would cause that, but haskell-platform includes ghc, so no need to install ghc 6.10.4 first
12:06:39 <wagle> it claims it does
12:06:53 <wagle> but i'll try again to get the error message
12:07:07 <jlouis> wagle: ghc-pkg check shows anything odd?
12:07:25 <wagle> shows all sorts of horror
12:07:43 <bos> dons: i got attoparsec performance about 2.5x better
12:08:13 <jlouis> bos: how?
12:08:30 <bos> careful tuning, and fixing the app that was calling into it too.
12:08:30 <dons> bos: this is on bytestrings, no texts, right?
12:08:35 <bos> dons: right.
12:08:53 <bos> dons: but i can parse more than 102,000 http requests per second, which is not embarrassing.
12:09:05 <dons> that seems rather high, in my limited experience
12:09:10 <bos> it's still slower than i'd like, but better than before.
12:09:12 <wagle>   This installer for the Haskell Platform requires ghc to be installed first
12:09:12 <wagle> ...
12:09:26 <dons> wagle: the linux installer?
12:09:28 <MaciejP> imc: Doc isn't a type class, you just build a Doc an then call render.
12:09:38 <bos> dons: the current bottleneck is ByteString.findIndexOrEnd which i really can't see a way to improve
12:09:45 <dons> mmm
12:09:46 <copumpkin> ByteString seems more appropriate than Text anyway, for this task
12:09:53 <tomberek> MaciejP : are you talking about PrettyPrint?
12:09:54 <dons> yep
12:09:54 <bos> 22% of time, 31% of allocations
12:10:03 <wagle> 2009-08-30 10:56 haskell-platform-2009.2.0.2.tar.gz
12:10:08 <MaciejP> tomberek: Yes
12:10:14 <wagle> dons ^^^
12:10:15 <tomberek> MaciejP: I'm trying to use it now as well, bu I can't get it to do what I want
12:10:18 <dons> bos: specializing it i guess
12:10:21 <bos> after that, the next most expensive thing is my parser's (>>=) implementation
12:10:28 <dons> check that the 'k' inlines
12:10:49 <dons> i've seen speedups in the past by hand specializing bytestring functions -- but that was in 2006
12:11:11 <dons> the function itself looks fine
12:11:21 <MaciejP> tomberek: What's the problem?
12:11:27 <tomberek> MaciejP :  I want to have two columns of text, each left aligned.
12:11:34 <dons> bos: careful to inline >>= et al?
12:11:36 <wagle> anyone have anything for me to try?
12:11:44 <bos> dons: of course! :-)
12:11:47 <dons> :)
12:11:54 <tomberek> MaciejP: i thought paragraph1 <> paragraph2 would do it, but I was wrong
12:12:08 <Botje> wagle: can you try reinstalling utf8-string with cabal?
12:12:14 <copumpkin> bos: you could almost parse http requests without even a real parser combinator, couldn't you? is HTTP even context-free (and nothing less powerful)?
12:12:22 <wagle> Botje: trying to install cabal
12:12:27 <bos> dons: the findIndexOrEnd code is being inlined for sure.
12:12:33 <bos> copumpkin: oh sure.
12:12:36 <Botje> cabal should come with the haskell platform
12:12:40 <hasenov>  Botje: so it is foldr (\(result, abundants) x -> if (isSumOfTwoAbundants x) then if isAbundant x then (result, x:abundants) else (result, abundants) else (x+result, abundants)) (0, set_of_abundants) [1..20]
12:12:44 <dons> and the function argument is inlined too?
12:12:54 <dons> i.e. not an indirect call to 'k', but the body of k in a case?
12:12:59 <wagle> Botje: the haskell-platform isnt really installing
12:13:01 <copumpkin> I guess it'd be nicer not to have a hand-coded parser :)
12:13:09 <dons> bos: i could try with the llvm backend too, if you want ... :)
12:13:12 <dons> i wonder if that helps any
12:13:16 <dons> (if the benchmark is easy to run)
12:13:19 <Botje> wagle: oh, i thought you got that _after_ installation. that's weird :(
12:13:32 * dons plans a weekend of llvm haxoring
12:13:46 <jlouis> :P
12:14:06 <jlouis> that llvm backend will definitely be fairly neat to have access to
12:14:09 <Botje> hasenov: roughly. I'd factor out that lambda to a function with guards to make it more readable
12:14:22 <Botje> and probably use Set instead of lists :)
12:14:42 <jlouis> Or perhaps IntSet in this circumstance
12:14:58 <bos> dons: hard to see in the generated core
12:15:00 <wagle> any reason not to use 6.10.4 to bootstrap haskell-platform on debian x86_64?
12:15:02 <bos> dons: it's super-easy
12:15:17 <dons> got a repo?
12:16:12 <tomberek> MaciejP: any ideas?
12:16:44 <MaciejP> tomberek: Hhm, I never used it myself, but I think you need a combination with nest
12:17:17 <bos> dons: http://bitbucket.org/bos/attoparsec/
12:17:28 <jlouis> wagle: it should be fine. I think something is confused in your install, but I can't really put a finger on what
12:17:36 <copumpkin> omg bitbucket
12:17:43 <bos> copumpkin: ?
12:18:10 <dons> Arse.hs or Arselet.hs ? :)
12:18:25 <bos> dons: examples/TestRFC2616.hs
12:19:18 <hasenov> Botje: thanks
12:19:23 <dons> are you funboxing those strict fields in the Header?
12:19:39 <bos> no, it doesn't help to do so for this benchmark.
12:19:42 <dons> interesting
12:19:55 <dons> nice high level code
12:20:30 <bos> dons: sample data at http://www.serpentine.com/bos/files/big.txt.bz2
12:20:39 <bos> yeah, the code is really clean.
12:22:04 <dons> ok. i'll have a poke around
12:22:42 <bos> oh, and dons: the external API is really nice, if i say so. notice that i feed the parser data in 4KB chunks?
12:22:42 <ibid> xerox: why is the whole dnainternet.fi on AKICK?  my log says you started it on the 12th
12:23:13 <xerox> ibid: I can lift it, I remeber adding it, it was something quite annoying
12:23:15 <ccasin> how can I get cabal to pass cpp options to c2hs?  I tried cpp-options, but they don't get sent to c2hs
12:23:41 <bos> dons: so i can take input incrementally, and produce results incrementally via parseWith too.
12:23:41 <ibid> xerox: yeah, i can see the issue in my log.  just the wide ban looked a bit weird
12:23:51 <xerox> sorry for the inconvenience
12:23:54 <MaciejP> tomberek: It seems it's not suitable for what you want.
12:23:58 <bos> dons: meaning that the parser can run in very little space and retain very little data.
12:24:19 <tomberek> MaciejP : i would think that it was a basic combinator,,, maybe another package?
12:24:20 -ChanServ(ChanServ@services.)- xerox removed *!*@*.bb.dnainternet.fi from the AKICK list.
12:24:38 <dons> mmm
12:24:49 <ibid> xerox: thanks
12:24:50 <MaciejP> tomberek: I would expect `render $ (text "a1" $$ text "a2") <+> (text "b1" $$ text "b2")' to render something else than the result it produces.
12:25:14 <tomberek> agreed, it puts one below the other, instead of next to
12:25:24 <dons> builds with ghc head, btw. good stuff.
12:25:46 <tomberek> MaciejP : what are the other popular/standard printing libraries?  or perhaps some of the sages on here know how to do it in a cryptic one-liner?
12:25:46 <bos> dons: i can successfully run the program with -M640K, i.e. a 640Kbyte heap
12:26:05 <dons> huh
12:26:16 <wagle> one problem is that its randomly switching between /usr/local and ~/.cabal
12:26:17 <bos> which i find rather spiffy.
12:26:18 <dons> i don't think i've ever seen someone try that
12:26:31 <dons> 640k should be enough for anyone
12:26:48 <bos> of course it should!
12:27:13 <MaciejP> tomberek: Sorry, I'm not familiar with the printing libraries.
12:27:34 <dons> $ time ./TestRFC2616 /tmp/big.txt
12:27:34 <dons> 45668
12:27:35 <dons> ./TestRFC2616 /tmp/big.txt  0.77s user 0.02s system 99% cpu 0.788 total
12:27:38 <dons> does that mean anything to you?
12:27:45 <tomberek> perhaps Text.PrettyPrint.Boxes .. i'm reading up on it now
12:27:46 <dons> (that's with 6.13 and -fllvm -O2)
12:28:11 <bos> the minimal heap size i can run in is 568KB
12:28:26 <bos> dons: that's about 40% slower than on my X200
12:28:33 <bos> dons: i assume you're still running on an X200?
12:28:47 <bos> dons: i'm using 6.10.4 still
12:28:51 <dons> no, an x61
12:29:05 <bos> ok, slightly different hardware.
12:29:05 <dons> i'll try with 6.10.4
12:30:17 <dons> ah, better with 6.10.4
12:30:17 <dons> $ time ./TestRFC2616 /tmp/big.txt
12:30:18 <dons> 45668
12:30:18 <dons> ./TestRFC2616 /tmp/big.txt  0.50s user 0.01s system 99% cpu 0.514 total
12:30:23 <dons> interesting!
12:31:38 <ibid> xerox: hmm, AKICK removed, but the +b remains.  any ideas?
12:31:59 <MaciejP> tomberek: Yeah, that's probably what you want.
12:32:02 --- mode: ChanServ set +o xerox
12:32:05 <bos> dons: neat.
12:32:06 <copumpkin> :O
12:32:15 --- mode: xerox set -b *!*@*.bb.dnainternet.fi
12:32:38 <ibid> xerox: thanks, and sorry for the trouble
12:32:39 <tomberek> MaciejP : yeah, i get exactly the behavior i expect... wierd behavior from that other one,, thanks
12:32:44 <xerox> ibid: no problem
12:32:48 --- mode: xerox set -o xerox
12:33:23 <dons> bos: i notice isDigitOrDot is floated out to the top
12:33:45 <marko1> hi, I'm new in haskell and I have one question about configuration cabal. I'm using win 7 and debian testing, ghc 6.12.1 (last version) and I download cabal.exe for windows.
12:33:46 <marko1> when run cabal --help then work.
12:33:48 <marko1> when run cabal install somepackage then I get errors:
12:33:50 <marko1> "cabal: failed to parsse output of 'ghc-pkg dump' "
12:33:51 <marko1> I try with this version of ghc on linux debian but the errors is the same. if somebody  can help me?
12:33:52 <marko1> thanks
12:33:56 <wagle> anyone recommend a good wiki for haskell code, tex + category theory?
12:34:02 <bos> dons: hm
12:34:06 <marko1> win 7 and debian is 64 bit
12:34:08 <bos> dons: i want to benchmark against http://github.com/ry/http-parser/
12:34:32 <copumpkin> wagle: you mean something to run? or something with content?
12:34:43 <copumpkin> wagle: ncatlab has lots of stuff on category theory
12:34:46 <burp> marko1: did you try ghc-pkg recache?
12:35:04 <marko1> I don't know how
12:35:09 <burp> um and do you use a proxy where cabal downloads through?
12:35:18 <marko1> yes
12:35:22 <burp> that's the problem
12:35:51 <burp> I think ;)
12:36:43 <burp> try it without using the proxy
12:36:46 <wagle> copumpkin: to run
12:37:13 <wagle> been using gitit, but i can even install it now
12:37:19 <wagle> cant
12:37:40 <geheimdienst> guys, i'm trying to fix some FFI code. i could use a haskell equivalent of memset, but i found only memcpy and memmove in Foreign.Marshal.Utils. any ideas?
12:37:56 <marko1> old version 6.8 ghc on debian work, but then I can't install new packages, because I then get errors about wrong version of base and other packages
12:38:57 <marko1> how I can use without proxy? I'm new in this
12:39:13 <marko1> I mean ih haskell and cabal
12:39:15 <wagle> marko1: i was just where you are a couple hours ago..  i'm trying 6.10.4, but its not working for me
12:39:25 <burp> if you don't know how to use it without it, are you sure you used it with a proxy?
12:39:36 <marko1> I don't know
12:39:55 <burp> then you don't and it's not the problem I was thinking of
12:39:56 <marko1> I'm download cabal .exe and put in bin directory
12:40:21 <wagle> marko1: .exe is for windows
12:40:37 <marko1> using windows
12:41:07 <wagle> marko1: oh..  you said something about debian..  i know nothing about windows install
12:41:16 <marko1> ok
12:41:40 <marko1> I have windows 7 64 bit and debian on vmware
12:41:50 <marko1> vmware is install on win 7
12:42:33 <marko1> i try on debian because on win don't work, but I found this to don't work on debian
12:42:53 <marko1> sory for english
12:43:06 <wagle> i tried macosx, and that didnt work either..  i should go back to bed
12:43:16 <marko1> on win xp work all
12:43:30 <enthymene> hrm, so "class (Num a, Num b) => Function (a -> b) where ..." doesn't work
12:43:58 <Botje> geheimdienst: Data.ByteString.Internal has a memset implementation you can use (or steal)
12:45:00 <bos> memset is trivial. what's the issue?
12:46:00 * hackagebot hMollom 0.1.1 - Library to interact with the Mollom anti-spam service  http://hackage.haskell.org/package/hMollom-0.1.1 (AndyGeorges)
12:52:03 <geheimdienst> bos, well, the issue is that my knowledge of FFI is tiny. the geheimdienst of a few hours ago barely knew the term FFI ;-) now i'm trying to fix System.Fuse, which is pretty crashy on my box
12:52:15 <bos> ah
12:53:11 <geheimdienst> i thought, do i really have to do plusPtr a lot and set each byte to 0 individually? that can't be right
12:54:43 <geheimdienst> thanks botje, i'm trying out bytestring.internal
12:58:25 <wagle> why would qls
12:58:27 <marko1> this is my problem http://comments.gmane.org/gmane.comp.lang.haskell.cafe/69703
12:59:17 <bos> dons: wow, inlining takeWhile wasn't winning me anything earlier, but it now gets me 15% better performance
13:01:34 <MaciejP> Can you specify multiple patterns in case branch like `case x of 1;2;3 -> y'?
13:01:50 <Botje> no
13:01:53 <aavogt> no, you have to write y' 3 times
13:02:51 <Botje> if your scrutinee is an instance of Eq you can do case x of _ | x `elem` [1,2,3] -> ...
13:05:07 <byorgey> marko1: you need to upgrade to cabal-install 0.8.  version 0.6 does not work with ghc 6.12.1.
13:05:20 <wagle> brand new macmini running 10.6.2, trying to install cabal-install:
13:05:21 <NielsOlson> hi, n00b here. Installed ghc and hugs in FreeBSD and the ghci has a tendency to return output to the same line as the prompt. eg, "prelude>"hello"" becomes "hellode>" Any suggestions?
13:05:22 <wagle> error: CPU you selected does not support x86-64 instruction set
13:06:06 <bos> wagle: use 6.12.1
13:06:23 <arw> NielsOlson: wrong terminal type? try fiddling with TERM=
13:06:29 <byorgey> marko1: oh, sorry, you already figured that out.
13:06:42 <geheimdienst> yay memset worked! thanks a lot, guys
13:07:23 <MaciejP> Botje: So this fails if x is not in the list and I can use the same pattern in the next branch?
13:07:46 <Botje> yes
13:07:46 <marko1> @byorgey: where is cabal.exe 0.8 version for download?  http://www.haskell.org/cabal/download.html on list is only 0.6
13:07:47 <lambdabot> Unknown command, try @list
13:07:57 <benmachine> MaciejP: quite often what I do is move the entire RHS of the case branch to a function in a where
13:08:15 <benmachine> and then you just have 1 -> rhs; 2 -> rhs; 3 -> rhs where rhs = blah blah
13:08:15 * wagle 's head implodes
13:08:21 <byorgey> marko1: I don't know, sorry
13:08:27 <NielsOlson> arw: from bash "echo $TERM" gives me cons25
13:08:32 <geheimdienst> so, would it be correct to say: with things like allocaBytes (#size struct something), it's good practice to first of all do memset 0 (#size struct something)
13:08:58 <wagle> bos trying to install cabal by installing haskell-platform, which installes 6.10.4..  what do you suggest>
13:08:59 <MaciejP> benmachine: That's what I have now but it's too long. ;-)
13:09:20 <arw> NielsOlson: hm. try TERM=xterm or xterm-color for example
13:09:37 <benmachine> wouldn't you have to export that?
13:09:43 <arcatan> With ghc --make, can I call the main module something else than Main?
13:09:44 <benmachine> or TERM=blah ghci I suppose
13:09:50 <arw> benmachine: yes
13:09:52 <benmachine> arcatan: there is an option for it
13:09:53 <bos> wagle: it doesn't work well on 10.6.2
13:10:03 <bos> wagle: install ghc 6.12.1 and bootstrap cabal-install by hand
13:10:14 <benmachine> arcatan: I think it's -main-is but not sure
13:10:23 <arw> NielsOlson: 'TERM=xterm ghci' or 'export TERM=xterm; ghci'
13:10:33 <arw> the export makes it permanent.
13:10:35 <wagle> doesnt want to bootstrap anywhere (debian or macosx, but ok)
13:10:35 <NielsOlson> arw: had the same idea, checked my Mac's term. xterm-color. Works like a champ
13:10:40 <benmachine> arcatan: you can give it foo and it uses Main.foo, or Bar and it uses Bar.main, or Baz.quux and etc.
13:11:36 <arcatan> benmachine: it works! thank you.
13:13:47 <wagle> wacky..  at least half the haskell programmers on the planet run 10.6.2
13:14:00 <Twey> Hehe
13:14:27 <NielsOlson> arw: got it, thanks.
13:15:06 <marko1> I found  cabal 0.8 in list packages , how I can build from source package?
13:15:40 <wagle> bos: i should use haskell-platform-2009.2.0.2.tar.gz?
13:15:56 <benmachine> that supplies 6.10.4
13:15:59 <bos> wagle: no. install ghc 6.12.1 by hand.
13:16:17 <doserj> marko1: download the .tar.gz, unpack it, run bootstrap.sh
13:16:25 <wagle> ghc 6.12.1 is installed, but cabal cant parse ghc-pkg dump
13:16:32 <benmachine> which version of cabal?
13:16:34 <Heffalump> upgrade cabal with the old GHC
13:16:43 <arw> NielsOlson: np. but take care, some other (n)curses apps could behave weird. i don't quite know what *bsd does with its terminal stuff...
13:16:46 <benmachine> Heffalump: there isn't an old GHC I don't think :P
13:16:57 <marko1> I'am on win now
13:17:28 <benmachine> wagle: if cabal --version says 0.6 you need to be using 0.8
13:17:34 <benmachine> I think
13:17:56 <wagle> me and marko1 have similar problems, please tag messages
13:18:12 <jeffwheeler> What's the function in an interation called? Iteree?
13:18:47 <benmachine> do you mean iteration
13:18:50 <jeffwheeler> iterand?
13:18:51 <benmachine> if so then I still don't know
13:19:02 <jeffwheeler> benmachine, oh, yes
13:19:09 <benmachine> but I thought I would clarify that because I kept reading it as interaction and it confused me
13:19:28 <wagle> benmachine: how do i get 0.8?
13:19:32 <jeffwheeler> benmachine: yeah, I saw the underline but assumed my spell-checker sucked
13:21:22 <benmachine> wagle: good question
13:21:29 <wagle> can i get a newer version of haskell-platform than 2.0.2?
13:21:36 <benmachine> http://hackage.haskell.org/packages/archive/cabal-install/0.8.0/ you could try this
13:22:09 <benmachine> there is not currently any version of the platform that is designed for 6.12 as far as I know
13:22:50 <marko1> here is for building and cabal needs yet 2 packages
13:22:51 * alama waves at lambdabot 
13:22:51 <marko1> http://www.haskell.org/ghc/docs/latest/html/Cabal/builders.html
13:23:04 <benmachine> OS X isn't the best-supported platform, especially not 10.6
13:23:12 <benmachine> but there are people who use itr
13:23:14 <benmachine> -r
13:23:41 <Heffalump> if I want to mess around with GPGPU stuff (not necessarily get raw performance, just experiment with the coding etc), should I aim for nVidia or are things like Intel's on-chip GPUs a reasonable target too?
13:24:12 <Phyx-> bleh, usb 2.0 is dog slow
13:25:40 <p_l> Heffalump: intel's is a No-No
13:27:31 <p_l> Heffalump: the only real options you have are nVidia and ATi, at least as far as I checked it out there's no real support for GPGPU on intel's hw - you can of course do it, but it'd be similar to how it was done before nVidia CUDA or ATi Stream/CTM
13:29:10 <Heffalump> ok, ta
13:34:40 <wagle> fresh install of ghc 6.12.1 on macosx 10.6.2..  how do i repair this:
13:34:59 <wagle> Distribution/Client/Types.hs:28:7:
13:35:00 <wagle>     Could not find module `Network.URI':
13:35:00 <wagle>       There are files missing in the `network-2.2.1.5' package,
13:35:00 <wagle> Distribution/Client/Types.hs:28:7:
13:35:00 <wagle>     Could not find module `Network.URI':
13:35:01 <wagle>       There are files missing in the `network-2.2.1.5' package,
13:35:03 <wagle> Distribution/Client/Types.hs:28:7:
13:35:05 <wagle>     Could not find module `Network.URI':
13:35:07 <wagle>       There are files missing in the `network-2.2.1.5' package,
13:35:12 <wagle> oops
13:35:16 <wagle> didnt loook like it was pasting
13:35:19 * hackagebot glpk-hs 0.0.4 - Comprehensive GLPK linear programming bindings  http://hackage.haskell.org/package/glpk-hs-0.0.4 (LouisWasserman)
13:35:24 <wagle> sorry
13:36:51 <marko1> when run runhaskell Setup.hs install, i got: setup.hs permission denied, i don't how
13:37:09 <marko1> i don't kniw how
13:37:12 <wagle> cotuple:cabal-install-0.8.0 wagle$ ghc-pkg check 2>&1 | wc -l
13:37:12 <wagle>       88
13:37:13 <marko1> know
13:37:20 * hackagebot redis 0.1 - A driver for Redis key-value database  http://hackage.haskell.org/package/redis-0.1 (AlexanderBogdanov)
13:37:43 <temoto> Yay, Redis!
13:38:03 <geheimdienst> wagle, i just did "cabal update" and it tells me that network-2.2.1.7 is current. do you have the same problem with 2.2.1.7?
13:39:05 <wagle> geheimdienst: i dont get that far..  i'm just trying a fresh install of ghc and cabal on macosx since I cant get it to work on debian
13:39:32 <wagle> my wiki server is dead, so i gotta get SOMETHING to work..  sigh
13:40:45 <chrissbx> How can you parametrize a type with itself? (Sort of a fix combinator for types)
13:41:13 <Heffalump> do you mean the result of applying itself to something, or actually itself?
13:41:25 <Heffalump> T T could never be well kinded
13:42:04 <chrissbx> Like:  data Foo a = Bar String | Baz a;  now I want to write "instance Show (Foo Foo) ..."
13:42:22 <donpdonp> im looking at a haskell cheat sheat and the most basic fuction definitions arent working for me. a function bob that always return 3: "bob x = 3" parse error on input `=
13:42:47 <Twey> You're executing them in an interactive shell
13:42:52 <donpdonp> is that bad?
13:43:05 <progo> prefix your stuff with "let"
13:43:06 <Twey> No, but it means you must preface  definitions with ‘let’
13:43:12 <donpdonp> oh!
13:43:22 <monadic_kid> donpdonp: you need to use let binding in ghci
13:43:29 <donpdonp> it works now. yea! thx :)
13:44:06 <monadic_kid> heh
13:44:16 <Heffalump> chrissbx: that can't be kind correct
13:49:39 <chrissbx> Heffalump: how do you mean? "data Foo = Bar String | Baz Foo; instance Show Foo where  show x = "Hm"  works just fine after all.
13:52:21 <Heffalump> right, but when you add the parameter, you change the kind of Foo
13:52:25 <monadic_kid> chrissbx: you can't make (Foo Foo) an instance because you still need to apply a type to the second Foo
13:52:29 <Heffalump> you can't write data Foo a = Bar String | Baz Foo
13:53:23 <chrissbx> monadic_kid: exactly, that's where I got the idea of "I need a fix combinator" from.
13:54:17 <Heffalump> data Fix f = Fix (f (Fix f))
13:54:18 <Heffalump> works fine
13:54:20 <chrissbx> Hm I'll go on and see.
13:55:11 <pastorn> Heffalump: so Fix can only hold a container for something?
13:55:33 <pastorn> (i'm thinking f == Maybe)
13:55:40 <Heffalump> it's not polykinded, if that's what you mean.
13:55:41 * ddarius hates this "container" terminology.
13:56:33 <pastorn> ddarius: functor then
13:57:08 <Heffalump> pastorn: Fix Maybe ~= List
13:58:37 <ddarius> Heffalump: Not quite.
13:58:50 <ddarius> Fix Maybe = Nat
13:59:06 <MissPiggy> Mu (\x -> (a,x)) = List a
13:59:13 <Heffalump> oh, sorry
13:59:16 <Heffalump> yeah
13:59:21 <MissPiggy> yes I just use lambda in the type level.
13:59:27 <MissPiggy> and im not ashamed
13:59:37 <ddarius> :k Fix ((,) a)
13:59:38 <lambdabot> Not in scope: type constructor or class `Fix'
13:59:38 <lambdabot> Not in scope: type variable `a'
13:59:46 <ddarius> :k Mu ((,) a)
13:59:47 <lambdabot> Not in scope: type variable `a'
13:59:47 <Heffalump> MissPiggy: Mu (\x -> Maybe (a, x)) = List a
13:59:51 <ddarius> :k Mu ((,) Int)
13:59:52 <lambdabot> *
13:59:59 <MissPiggy> oh yeah good point
14:00:01 <MissPiggy> I forgot that
14:01:28 <pastorn> Heffalump: i'm not seeing it
14:01:43 <pastorn> could you write [1,2,3] as Fix Maybe?
14:01:52 <pastorn> or maybe just [1..]
14:02:03 <pastorn> (i'm guessing there's no real 'nil' here
14:02:46 <MissPiggy> @src Mu
14:02:46 <lambdabot> newtype Mu f = In { out :: f (Mu f) }
14:03:08 <MissPiggy> :t In (Just (1, In (Just (2, Int (Just (3, Nothing))))))
14:03:09 <lambdabot> Not in scope: data constructor `Int'
14:03:13 <MissPiggy> :t In (Just (1, In (Just (2, In (Just (3, Nothing))))))
14:03:14 <lambdabot>     Couldn't match expected type `Mu f'
14:03:14 <lambdabot>            against inferred type `(t, Maybe a)'
14:03:14 <lambdabot>     In the first argument of `Just', namely `(3, Nothing)'
14:03:16 <Heffalump> pastorn: as ddarius said, I got it wrong. Fix Maybe = Nat
14:03:18 <MissPiggy> :t In (Just (1, In (Just (2, In (Just (3, InNothing))))))
14:03:19 <lambdabot> Not in scope: data constructor `InNothing'
14:03:20 <MissPiggy> :t In (Just (1, In (Just (2, In (Just (3, In Nothing))))))
14:03:21 <lambdabot>     Couldn't match expected type `Mu f'
14:03:22 <lambdabot>            against inferred type `(t, Mu Maybe)'
14:03:22 <lambdabot>     In the first argument of `Just', namely `(3, In Nothing)'
14:03:46 <MissPiggy> ah
14:03:59 <MissPiggy> I'm not allowed to form this because it can't solve the equation
14:04:29 <MissPiggy> I think this lead to a reason why djinn on recursive is not solvable
14:05:15 <ddarius> MissPiggy: It's not able to solve the equation because it doesn't use higher order unification.
14:05:25 <MissPiggy> yes!
14:05:42 <MissPiggy> djinn on recursive types*
14:07:10 <ddarius> Heffalump: Did you do any significant work on higher order matching after your thesis or did you move on to other things?
14:11:58 <wagle> how do i override a QuickCheck version check on a cabal install?
14:12:35 <Heffalump> ddarius: moved on
14:17:15 <wagle> what wiki software do people use for haskell literate source and latex/category theory
14:20:27 <JoshTriplett> In Template Haskell, how can I most easily get from [Q [Dec]] to Q [Dec]?  I wrote a list comprehension with a [d| |] in it.
14:20:53 <copumpkin> is Q a monad?
14:20:57 <twink> head
14:20:59 <copumpkin> fmap join . sequence
14:21:13 <ddarius> copumpkin: Yes.
14:21:19 <JoshTriplett> copumpkin: That much crossed my mind already; I just wondered if some more elegant way existed. :)
14:21:35 <copumpkin> it's barely 20 characters, how can you get more elegant? :P
14:21:42 <ddarius> Four tokens is not elegant!
14:21:44 <tensorpudding> 0 characters
14:21:45 <JoshTriplett> copumpkin: (and I'd probably write join as concat for clarity)
14:21:46 <copumpkin> true
14:21:47 <jmcarthur> :t fmap join . sequence
14:21:48 <lambdabot> forall a (f :: * -> *). (Functor f, Monad f) => [f [a]] -> f [a]
14:22:01 <copumpkin> eww
14:22:04 <copumpkin> Functor f, Monad f
14:22:04 <JoshTriplett> :t liftM concat . sequence
14:22:05 <lambdabot> forall a (m :: * -> *). (Monad m) => [m [a]] -> m [a]
14:22:36 <copumpkin> I think twink's suggestion is best though
14:22:49 <JoshTriplett> :t liftM head . sequence
14:22:50 <lambdabot> forall a (m :: * -> *). (Monad m) => [m a] -> m a
14:22:53 <JoshTriplett> Yeah, probably sensible.
14:23:02 <jmcarthur> :t liftM join
14:23:03 <lambdabot> forall (m :: * -> *) a (m1 :: * -> *). (Monad m, Monad m1) => m1 (m (m a)) -> m1 (m a)
14:23:04 <JoshTriplett> Given that I know each [d| |] will produce exactly one Dec.
14:23:20 <twink> Not liftM head . sequence, just head
14:23:25 <copumpkin> :P
14:23:33 <JoshTriplett> twink: Heh.  That will definitely do the *wrong* thing. :)
14:23:39 <JoshTriplett> twink: Right type, wrong function. :)
14:23:43 <copumpkin> pff
14:23:47 <copumpkin> the type is all that matters
14:23:56 <copumpkin> if more matters, write a tighter type
14:24:24 <copumpkin> :t join . liftM join
14:24:25 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m (m a)) -> m a
14:24:26 <JoshTriplett> copumpkin: As often as Haskell has led me to say "it compiles, it must be correct", this case does provide an effective counterexample. :)
14:24:35 <sarah93> wow you should check this http://bit.ly/bFi9I4
14:24:44 <copumpkin> :t liftM2 (==) (join . liftM join) (liftM join . join)
14:24:45 <lambdabot> forall (m :: * -> *) a. (Eq (m (m a)), Monad m) => m (m (m (m a))) -> Bool
14:24:48 <copumpkin> zomg
14:24:59 <copumpkin> :t liftM2 (==) (join . liftM join) (join . join)
14:25:00 <lambdabot> forall (m :: * -> *) a. (Eq (m a), Monad m) => m (m (m a)) -> Bool
14:25:14 <copumpkin> so deep
14:25:34 <dons> "Do not emit code that uses the red zone.
14:25:35 <copumpkin> sarah93: go away
14:25:35 <dons> "
14:25:47 <JoshTriplett> Does an equivalent to @pl exist which simplifies expressions?
14:25:48 --- mode: ChanServ set +o dons
14:26:02 --- mode: ChanServ set -o dons
14:26:04 <ddarius> "red zone" ?
14:26:10 <dons> some llvm thing
14:26:21 <p_l> ddarius: red zone is part of x86-64 SysV ABI
14:26:42 <p_l> 128 bytes on stack preallocated for usage in current frame
14:26:46 <sm> wagle: gitit has a lot of haskell and latex users using it
14:27:14 <dons> ah
14:30:00 <sarah93> wow you should check this http://bit.ly/bFi9I4
14:30:28 <enthymene> what'cha floggin here sarah93?
14:30:56 <enthymene> seeing as how you also said the same thing in #perl within the minute.
14:31:32 <p_l> dons: red zone is basically a safe, always allocated space that can be addressed with single-byte displacement from framepointer
14:31:55 <sarah93> wow you should check this http://bit.ly/bFi9I4
14:32:01 --- mode: ChanServ set +o mauke
14:32:01 --- kick: sarah93 was kicked by mauke (sarah93)
14:32:01 --- mode: mauke set +b *!*@BSN-176-138-210.dial-up.dsl.siol.net
14:32:30 <enthymene> "Hey listen!" >.>
14:34:01 --- mode: mauke set -o mauke
14:38:10 <pheaver> i'm trying to handle the UserInterrupt exception (Control-C) in a really simple read-eval-print-loop.  it always catches the first exception.  but the second one always goes uncaught and the program quits.  am i missing something?  http://haskell.pastebin.com/nG5HnrW4
14:39:41 <pheaver> note that if i try to catch ANY exception (SomeException) on the second Control-C, that it still doesn't catch anything
14:41:02 <wagle> sm i cant get gitit to reinstall
14:47:47 <ksf> pheaver, you want to trash all your code and use haskellline
14:48:03 <pheaver> ksf: that's the whole idea :)
14:48:26 <pheaver> i am planning on doing that, yes
14:48:29 <Twey> C-c is a signal, not an exception, surely?
14:48:34 <pheaver> but i have this problem regardless of haskeline
14:48:56 <pheaver> uh, well the new Control.Exception in base-4 treats C-c as an exception (UserInterrupt)
14:49:02 <bos> dons: have you looked at the new attoparsec internals at all?
14:49:06 <int-e> The rts has extra code for this. The intention is probably to make irresponsive programs killable with ^C - now how do you distinguish between an irresponsible program and one that deliberately ignores the exception?
14:49:39 <pheaver> ksf: i'm not quite sure what you mean by "all my code" anyway.  do you mean my trivial little example that demonstrates this problem? :)
14:49:51 <pheaver> int-e: ah, that makes sense
14:50:16 <ksf> I thought you'd be doing line editing yourself
14:50:24 <ksf> ...and that haskellline would handle the situation
14:50:30 <pheaver> ksf: no, and that's really beside the point
14:50:36 <ksf> but it should.
14:50:38 <pheaver> but yes, i am using haskeline
14:51:13 * int-e wonders how ghci deals with this
14:51:23 <pheaver> heh me too
14:51:39 <pheaver> in one scenario, i was able to get the behavior to stop
14:51:53 <pheaver> i had called out to a shell command, and then each Control-C was actually caught after that
14:51:58 <pheaver> but it has been hard to reproduce :p
14:54:04 <pheaver> long story is i am actually porting some old code from using readline to haskeline.  in that old code, we actually use System.Posix.Signals to install a sigInt handler to *ignore* C-c alltogether
14:54:17 <pheaver> which was a little disturbing when i first saw it
14:54:56 <int-e> pheaver: oi. ghc installs custom signal handlers for SIGINT among others. ( ghc/utils/Panic.lhs )
14:55:07 <pheaver> int-e: oh, thanks!
14:56:21 <Cale> Hmm, weirdly enough, I can't seem to get GHC 6.10.4 to throw a UserInterrupt exception.
14:56:26 <int-e> eh. s=ghc=compiler=
14:57:05 <int-e> Cale: are you using ghci?
14:57:07 <mreh> is there an easy way to memoize a function without having to pass it up and down the call stack of a program? I thought this would be a nice candidate for an unsafePerformIO?
14:57:24 <Cale> int-e: At first I was, but I just tried it in a compiled program as well.
14:57:33 <pheaver> Cale: using base-4 Control.Exception?
14:57:37 <Cale> yeah
14:57:40 <pheaver> interesting
14:57:49 <pheaver> can you share the code
14:58:17 <int-e> Cale: do you have a non-productive loop?
14:58:31 <Cale> I'm just doing  catch getLine f
14:58:56 <Cale> where f will catch the UserInterrupt and re-throw other AsyncExceptions
14:59:50 <pheaver> Cale: yeah sounds just like what i did
15:00:04 <Cale> I wonder if things are any different in 6.12
15:00:29 <dons> got my GA breeding LLVM opt flags.
15:00:35 <dons> lots of combinations seem to lead to segfaults :)
15:00:49 <jmcarthur> ew
15:00:52 <pheaver> Cale: yeah that's quite possible
15:00:58 <dons> i bet no one has tried these in all the mad combinations
15:01:03 <copumpkin> dons: sounds kind of disconcerting :P
15:01:11 <dons> i might be doing it wrong
15:01:24 <dons> like using some flag that's guaranteed to break others
15:01:26 <copumpkin> dons: wait, you have a simple system to pass flags from ghc's command line straight through to llvm?
15:01:34 <Cale> Well, those genomes are obviously unfit ;)
15:01:47 <dons> well, yes. -optlo -optlc, but also a "simple system" to measure the fitness and breed the next round
15:02:01 <copumpkin> dons: so you could ask it to generate code for other architectures? :o
15:02:08 <dons> yes. i already generated arm code
15:02:11 <copumpkin> ooh!
15:02:17 <dons> which obviously won't link - we don't have a cross compiler yet
15:02:22 <copumpkin> yeah :)
15:02:26 <copumpkin> still neat
15:02:27 <dons> but we probably could with enough ld magics
15:02:31 <bos> hmm, ghc 6.12.1 is slower than 6.10.4 on my attoparsec benchmark
15:02:37 <dons> bos: same here.
15:02:53 <dons> oh, i had 6.13
15:03:41 <dons> so first gen, runtime 0.22132s, second gen, 0.16048s
15:03:43 <dons> it's getting better
15:03:51 <dons> (i know that -O3 is 0.05s though).
15:03:56 <bos> dons: what are you timing the performance of?
15:04:04 <dons> one of the fusion benchmarks
15:04:17 <mreh> dons: you can expect diminishing returns :)
15:04:20 <mreh> almost certainly
15:04:28 <jmcarthur> dons: what's the difference between -O2 and -O3?
15:04:38 <dons> well, if i can convince llvm that the loop is actually a constant...
15:04:39 <djahandarie> jmcarthur, O3 is a bigger number!
15:04:40 <copumpkin> mreh: ORLY? I thought he could just optimizing it down until he hit O(0), myself
15:04:49 <dons> these are llvm -O3
15:04:56 <jmcarthur> dons: oh i see. n/m
15:04:56 <dons> which trigger some of the 100 or so opt passes
15:05:00 <bos> how does llvm affect compilation time?
15:05:02 <dons> 3rd gen, 0.1538
15:05:13 <dons> bos: about the same as gcc under the current model (3 external processes called)
15:05:24 <bos> dons: i see.
15:05:37 <dons> i also want to use criterion to report the fitness
15:05:38 <Heffalump> would using the direct binding be much better?
15:05:42 <dons> yes, i think so
15:05:42 <bos> sounds like it has a way to go before being usable in production.
15:05:58 <dons> i'd prob. not use it in productoin yet, but it seems to compile everything i throw at it.
15:06:02 <p_l> dons: does it use straight llvm assembly or does it go through C?
15:06:11 <mreh> do you understand the fitness landscape well enough to be able to use a GA here?
15:06:12 <dons> C-- to LLVM bytecode
15:06:27 <dons> mreh: fitness is total runtime
15:06:34 <dons> and the variables are llvm flags
15:06:40 <int-e> Cale: oh well. you have to compile the program.
15:06:41 <dons> ooh 0.06
15:06:48 <dons> 4th gen found a breakthrough :)
15:06:59 <mreh> punctuated equalibria
15:07:00 <int-e> Cale: but then it works for me with  main = forever $ (getLine >>= putStrLn) `E.catch` \(e :: E.AsyncException) -> print (e,())
15:07:03 <bos> dons: with runtimes that short, you can easily be seeing noise variations far bigger than the signal
15:07:13 <dons> 60ms ?
15:07:17 <dons> yes, i guess so.
15:07:22 <copumpkin> is there a way of removing packages from hackage?
15:07:23 <int-e> Cale: "work" meaning it catches the first ^C
15:07:26 <copumpkin> probably not
15:07:26 <dons> the runtime ranges from 1.2s to 60ms
15:07:37 <dons> bos: hence i'd like criterion to do the reporting
15:07:48 <dons> so each run would actually be criterion doing multiple samples
15:07:50 <dons> then reporting the mean
15:08:02 <dons> i'll just have to hack the criterion driver to print only the final mean to stdout
15:08:06 <dons> and nothing else
15:08:20 <bos> i need to do some refactoring of the internals to make that sort of thing easier.
15:08:29 <merijn> Can someone explain to me why this doesn't work? "fib = [x+y | x <- [1, 1] ++ fib, y <- [1] ++ fib]"
15:08:33 <dons>                          -fasm: **************************************************    (0.099)
15:08:37 <dons>      Acovea's Best-of-the-Best: ************************                              (0.049)
15:08:51 <wagle> [14 of 20] Compiling Happstack.Crypto.MD5 ( src/Happstack/Crypto/MD5.hs, dist/build/Happstack/Crypto/MD5.o )
15:08:51 <wagle> cc1: error: unrecognized command line option "-fno-toplevel-reorder"
15:08:51 <wagle> ...  how to get rid of this?
15:08:51 <dons> so it found a llvm flag set about twice as good as -fasm
15:09:01 <dons> bos: i'll just hack the no verbose flag
15:09:04 <dons> for now anyway
15:09:07 <mreh> what is an llvm flag?
15:09:11 <Twey> > let fib = [x+y | x <- [1, 1] ++ fib, y <- [1] ++ fib] in fib
15:09:12 <lambdabot>   [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,2...
15:09:23 <mreh> and how many are there?
15:09:29 <merijn> Twey: Well, it works. But it doesn't do what I'd expect it to do
15:09:33 <Twey> merijn: You're taking those 1s *for each item*, not in parallel
15:09:36 <p_l> mreh: an option to compiler
15:09:54 <dons> we have a simple -fasm code generator, and a new llvm code gen.
15:09:58 <merijn> Twey: Oh, duh
15:09:59 <dons> the llvm code gen has many flags, http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23087#a23087
15:10:08 <merijn> Twey: Thanks, I think I know how to solve it :)
15:10:18 <Twey> merijn: (hint: zipWith :þ)
15:10:40 <mreh> non-deterministic polynomial time then
15:10:52 <mreh> hence the GA
15:10:55 <jlouis> dons: in MLton we used genetic programming to choose the order and which optimizations at the low-level to use
15:11:07 <int-e> Cale: oh and I tested with bothj 6.10.4 and 6.12.1
15:11:44 <twink> > let fib = [1, 1] ++ [x + y | x <- fib, y <- tail fib] in fib
15:11:45 <lambdabot>   [1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,...
15:11:45 <Heffalump> can you control ordering of passes too?
15:11:53 <Heffalump> (with llvm)
15:12:23 <twink> > let fib = [1, 1] ++ [x + y | x : y : _ <- fib] in fib
15:12:24 <lambdabot>   Occurs check: cannot construct the infinite type: t = [t]
15:12:25 <dons> jlouis: that's essentially what i want to do here too.
15:12:30 <dons> Heffalump: there is some control i believe.
15:12:33 <Cale> > let fib = [1, 1] ++ [x + y | x <- fib | y <- tail fib] in fib
15:12:34 <lambdabot>   [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,1...
15:13:29 <jlouis> dons: IIRC we won quite some on doing that
15:13:31 <twink> Cale got it.
15:13:57 <dons> jlouis: fwiw, i did that with inlining flags last year, and found some 15% speedups in shootout code. the search space is just so big here you have to automate it.
15:14:36 <jlouis> dons: exactly!
15:14:50 <Heffalump> has anyone done it for nofib?
15:14:56 <Heffalump> i.e. figured out the right defaults
15:15:07 * copumpkin kind of wants to recall vector-static from hackage
15:15:11 <copumpkin> dolio was right
15:15:58 <wagle> in src/ghc/ghc-6.10.4/extra-gcc-opts on a debian system, what should i replace "-fno-toplevel-reorder" with?
15:16:08 <merijn> Cale: Ooh, nice one. That works too :)
15:16:19 <mreh> dons: how did you tune your GA parameters?
15:16:34 <mreh> you're getting incredible results
15:17:41 <decker> UAE: what's with the spam jerk?
15:17:57 <dons> mreh: i'm using a library for this.
15:18:13 <dons> someone else did all the thinking, http://donsbot.wordpress.com/2009/03/09/evolving-faster-haskell-programs/
15:18:16 --- mode: ChanServ set +o Heffalump
15:18:20 <dons> i'm just porting it to other parameters
15:18:55 <dons> so far i'm not getting results better than llvm -O3 would give me though.
15:19:00 <dons> i'm hoping to find a combination better than -O3
15:19:34 <copumpkin> he'll msg you with spam if he is :)
15:20:03 <olsner> dons: what if you start with -O3 and only search over the parameters not included in O3?
15:20:40 <Alpounet> copumpkin, what was dolio right about ?
15:20:50 <copumpkin> vector-static not being a good idea
15:20:57 <MissPiggy> why not?
15:21:10 <copumpkin> because it's close to impossible to write anything meaningful with it
15:21:15 <decker> so I ran ":load foo.hs" in ghci, and it seemed to work.  but when I try and use a function from that file it's telling me "not in scope".
15:21:28 <copumpkin> proofs are not pleasant in haskell
15:21:49 <MissPiggy> what about erasing the proofs
15:21:57 <ksf> decker, most likely it got optimized away
15:22:16 <copumpkin> MissPiggy: writing them in the first place is hard, not even sure how I'd get them erased (maybe rewrite rules?)
15:22:18 <Alpounet> copumpkin, to be handy to use, it may need some syntactic sugar which would be sort of preprocessed, or transformated through some TH magic
15:22:20 <ksf> you can either rm *.hi *.o and try again (without -O) or export the function
15:22:33 <copumpkin> Alpounet: well, you do need to prove things, which can make it quite hard
15:22:40 <Alpounet> yeah, hmm
15:22:51 <MissPiggy> copumpkin I mean like write the thing in full on paper or Coq or something, then translate to haskell -- erasing the bits that are not expressible
15:22:51 <copumpkin> and you really don't want your proofs to survive until runtime
15:22:59 <MissPiggy> not computational
15:23:03 <Alpounet> dons, what's the best flag set you've come upon so far ?
15:23:09 <copumpkin> MissPiggy: oh, I was thinking of something similar, yeah
15:23:15 <ddarius> MissPiggy: End result = vector
15:23:17 <copumpkin> MissPiggy: but vector-static itself is pretty hopeless, I think
15:23:21 <dons> bos: i think i could wrap this up to have a similar interface to criterion. main = Evolution.defaultMain [ code ]
15:23:22 <decker> ksf: I see no .hi file or object file.  again, I'm just trying this via ghci.
15:23:32 <dons> bos: and it would print   the flags you should use at the end.
15:23:33 <bos> dons: that would be neat!
15:23:37 <MissPiggy> ddarius yeah but that's far too low level to program with directly :P
15:23:44 <dons> yeah, i think that's the way forward
15:23:56 <dons> criterion -> progression -> evolution
15:24:12 <copumpkin> I'm currently thinking about a specialized DSL in a dependently typed language that generates vector (or dph) code
15:24:14 <dons> Alpounet: llvm-opt -O3
15:24:19 <ksf> ghci uses pre-compiled modules, though.
15:24:20 <Alpounet> ok
15:24:25 <MissPiggy> that sounds fun
15:24:34 <copumpkin> by specializing it I can build things like a ring solver into it
15:24:40 <copumpkin> so you don't need to write "trivial" proofs
15:24:45 <ksf> decker, if your module has an export list, the function you want to call has to be in it
15:24:52 <copumpkin> but I need to think about it a bit more before diving in
15:25:15 <copumpkin> (mostly semirings actually)
15:25:45 <ksf> oh yes I wanted to try out llvm
15:25:45 <wagle> how do i get Crypto/MD5.hs to not use -fno-toplevel-reorder?
15:26:36 <MissPiggy> copumpkin *confused*
15:26:40 <decker> ksf: here's what I'm going with:  http://book.realworldhaskell.org/read/types-and-functions.html#funcstypes.srcfile  It mentions none of that.
15:26:49 <copumpkin> MissPiggy: about what?
15:26:57 <copumpkin> MissPiggy: I don't have anything concrete yet :P
15:28:35 <decker> ha, my prompt changed at least
15:32:43 <krey> hello
15:32:50 <krey> can anyone help me with monads?
15:33:00 <MissPiggy> yes
15:33:00 <Heffalump> google "monad tutorial" ;-)
15:33:04 <krey> haha
15:33:08 <krey> been there
15:33:28 <MissPiggy> I can help you with monad
15:33:35 <krey> great
15:33:36 <krey> so
15:33:44 <krey> ive read all i could about them
15:33:56 <krey> and im looking for some practical use
15:34:00 <copumpkin> krey: how much haskell experience do you have?
15:34:13 <krey> i've done basic haskell
15:34:14 <copumpkin> (just curious)
15:34:19 <krey> and im comfortable with folds
15:34:22 <copumpkin> like, days, weeks, months?
15:34:26 <copumpkin> hours? :P
15:34:31 <MissPiggy> krey, I use them to implement various types of programming languages
15:34:31 <krey> haha :)
15:34:48 <Cale> Let the practical uses find you. If something happens to be a monad, then that's great, but forcing a library you're writing to be a monadic one can sometimes produce unnatural results.
15:34:49 <MissPiggy> krey, and some operations of compilers are expressible in a very elegant way with monads
15:35:06 <krey> hmm
15:35:15 <krey> i am trying to implement finite state machines
15:35:15 <MissPiggy> krey, a different application is: Do you know hoare triples? There is a way to use monad in a similar fashion -- to prove correctness of programs
15:35:17 <krey> in haskell
15:35:18 <copumpkin> I'm just trying to figure out at what point people decide they want to learn about monads. I get the impression most people try it prematurely, but don't have too much supporting evidence
15:35:26 <copumpkin> krey: MissPiggy called you a hoare
15:35:35 <krey> haha
15:35:37 <copumpkin> I wouldn't let that slide
15:35:42 <MissPiggy> krey, sure you can do finite state mahcines -- this is the style I first mentioned, using them to implement an interpreter
15:35:45 <mreh> mmm, my 11-multiplexer boolean expression evolved to have 904 nodes
15:35:46 <krey> tony hoare, quicksort man
15:35:49 <Heffalump> surely she called hoare a hoare?
15:35:52 <lpsmith> krey:   data DFA ab st = DFA (st -> ab -> st) st (st -> Bool)     ;-)
15:35:57 <copumpkin> hoare was a hoare
15:35:58 <Cale> I'm probably not bother with a monad.
15:36:01 <MissPiggy> wow there is so much noise here
15:36:03 <Heffalump> he still is a hoare
15:36:06 <MissPiggy> I can't even see what people are saying
15:36:10 <krey> me neither
15:36:12 <benmachine> is quicksort man his superhero identity
15:36:19 <ddarius> I, too, would not use monads for an FSM.
15:36:25 <tensorpudding> hoare is a son of a hoare too
15:36:28 <krey> well
15:36:29 <MissPiggy> Flying Spagetti Monad?
15:36:30 <copumpkin> Cofree ((->) a)
15:36:30 <krey> i tried to
15:36:37 <krey> but it didnt work out...
15:36:37 <dons> llvm -die
15:36:39 <lpsmith> Cale, I agree,  monads are not particularly useful for state machines
15:36:39 <BONUS> a DFA is a five tuple :)
15:36:51 <krey> i kind of did it with 2
15:36:52 <enthymene> theFSM :: (Untouched a -> Touched a)
15:36:58 <MissPiggy> krey well I hope some of what I said reached you
15:36:59 <krey> i mean, i did it as a pair
15:37:11 <krey> you said something about spaghetti
15:37:13 <tensorpudding> a monad is a triple
15:37:16 <krey> love italian
15:37:28 <krey> soo
15:37:36 <krey> can you give me some kind of simple task
15:37:38 <Cale> I would probably just use Data.Map to encode the finite state machine's graph.
15:37:39 <lpsmith> BONUS, true,  but you might consider the type parameters ab and st to be part of the five tuple :)
15:37:45 <krey> that is easily/nicely done with monads
15:37:53 <Alpounet> dons, huh ?
15:38:00 <Cale> and then implement various operations for combining FSM's in various ways
15:38:03 <dons> dead instruction elimination :)
15:38:10 <dons> nice flag name
15:38:11 <copumpkin> Cofree (Map k)
15:38:11 <BONUS> lpsmith, hmm, one might do that yeah
15:38:19 <MissPiggy> krey, make an interpreter for WHILE
15:38:23 <Alpounet> haha, indeed
15:38:27 <krey> ?
15:38:34 <Cale> krey: Certain sorts of parsers are naturally monadic
15:38:37 * copumpkin shuts up
15:38:46 <krey> ok
15:38:51 <krey> can you send me a link on this
15:38:52 <Cale> krey: Consider the type  data Parser a = P (String -> [(String,a)])
15:39:04 <krey> or describe it in further detail
15:39:27 <Cale> So a parser is a function from strings, to lists of possible parses, where each parse consists of a depleted string, and a parsed result.
15:40:00 <ddarius> copumpkin: You can consider the Map to be the entire graph and not just an adjancency list.
15:40:19 <lpsmith> krey, BONUS:  http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.7711
15:40:19 <copumpkin> ddarius: yeah, was just trying to be obscure and newbie-unfriendly
15:40:25 <Cale> So, for instance, if we had the parser corresponding to the regular expression a*, one which matches zero or more a's producing, say, the number of a's that it matched as a result...
15:40:35 <Cale> and we were to run it on the string "aardvark"
15:40:46 <BONUS> lpsmith: cheers, i'll czech that out
15:40:56 <copumpkin> why the hate against the slovaks?
15:41:06 <Cale> We should get the result [("rdvark",2),("ardvark",1),("aardvark",0)]
15:41:11 <MissPiggy> krey WHILE? It's a basic imperative programming language -- a lot of like say GCL
15:41:13 <Cale> clear?
15:41:24 <krey> cale: processing
15:41:52 <krey> why cant it just return the first pair
15:41:54 <krey> ?
15:42:12 <Cale> krey: It could, except that we want to compose these parsers, and we might need to backtract
15:42:16 <Cale> backtrack*
15:42:24 <krey> ooh
15:42:32 <krey> so
15:42:36 <krey> these are possible matches
15:42:43 <BONUS> type parameters that consist of more than just one letter always freak me out
15:42:43 <lpsmith> Heffalump, thanks for the interactive diff editing,  it's a pretty cool feature
15:42:58 <Cale> So, for instance if we wanted to construct the parser for a*a from this, and we tried matching a* and it ate both the a's, the following a would have nothing left to match
15:43:01 <Cale> yeah
15:43:19 <krey> ok
15:43:28 <krey> why do you need the number?
15:43:33 <Cale> Well, that was arbitrary
15:43:34 <krey> (in the pair)
15:43:41 <Cale> Every parser will produce some sort of result
15:43:51 <Cale> Usually in real scenarios, the parser will construct a tree
15:44:01 <lpsmith> BONUS, why?  :)
15:44:03 <Cale> Or some useful value that we're after
15:44:08 <krey> ok
15:44:12 <BONUS> i guess i'm just so used to one-letter ones
15:44:42 <BONUS> idea: DFAs and monads seem kind of orthogonal but you can make good use of the list monad when implementing NFAs
15:44:48 <ddarius> Because BONUS doesn't know how to multiply type variables.
15:44:49 <Cale> If we only care about whether some string belongs to a language or not, we can use Parser () values, but that's less interesting.
15:44:55 <BONUS> haha
15:44:55 <Alpounet> nice, I have 100.5% of battery left
15:45:06 <krey> BONUS: i am doing NFAs
15:45:10 <Alpounet> haskell is *that* powerful
15:45:20 <Cale> We also want the parsers to have a result if we want the thing to be monadic, of course.
15:45:34 <NathanRoys> New Programming Forums - http://www.hackersrus.info/ - Join!:)
15:45:43 <Cale> Otherwise, there's no monad to be had -- maybe a monoid or two, but no monad.
15:45:53 <krey> ooh
15:45:59 <krey> not sure what that means
15:46:10 <krey> for me monad = haskell,  monoid = maths
15:46:19 <benmachine> monoids are in haskell too
15:46:20 <MissPiggy> monad = haskell is wrong
15:46:26 <Cale> Well, they're both used in mathematics and Haskell.
15:46:27 <benmachine> (and monads in maths)
15:46:33 <benmachine> :t mappend
15:46:34 <lambdabot> forall a. (Monoid a) => a -> a -> a
15:46:39 <Cale> Monads are originally a concept from category theory.
15:46:43 <MissPiggy> also I think the mathematical idea of a monad is much more general than the haskell one
15:46:49 <Cale> yes, it is
15:47:02 <MissPiggy> but I am not sure about monoiod
15:47:09 <Cale> The monads in Haskell are only monads on Hask, the category of Haskell types and functions.
15:47:14 <copumpkin> there are at least two things called monoids out there
15:47:15 <pikhq> Yes, category theory is more general than morphisms on Hask.
15:47:18 <copumpkin> related
15:47:22 <krey> all i know is, associative binary operator with identities
15:47:39 <Cale> krey: Right, that's a monoid, we mean the same thing in Haskell. :)
15:47:58 <copumpkin> unless someone's trying to scare you away about monads
15:48:01 <Cale> So parsers without results have a few natural monoids.
15:48:02 <krey> so how will this help me write a parser?
15:48:22 <NathanRoys> New Programing Forums, Help, Support and exclusive downloads! http://www.hackersrus.info/ REGISTER!
15:48:23 <krey> can you be a bit more concrete?
15:48:30 <Cale> One being the concatenation of parsers, with the parser which always succeeds, eating no characters, as the identity.
15:48:30 <Gracenotes> o.o
15:48:35 <lpsmith> @google "Monadic Parsing Combinators"
15:48:38 <lambdabot> http://eprints.nottingham.ac.uk/archive/00000223/01/pearl.pdf
15:48:38 <lambdabot> Title: FUNCTIONAL PEARLS Monadic Parsing in Haskell
15:48:39 <copumpkin> NathanRoys: go away
15:48:48 <BONUS> lol
15:48:50 <Cale> The other being the disjunction (OR) of parsers, with the parser that always fails being the identity
15:49:00 <oxamus> this is funny
15:49:02 <oxamus> http://www.reddit.com/r/programming/comments/b7bn6/why_do_i_read_all_these_blogs_about_lisp_and/
15:49:24 <krey> ok
15:49:29 * benmachine always thinks the "requested" in those part messages is a bit of a
15:49:32 <krey> methinks ima read this pdf
15:49:35 <benmachine> euphemism?
15:49:37 <krey> and then come back
15:49:43 <ksf> parsers are largely applicative, though.
15:49:43 <benmachine> reading pdfs is overrated
15:49:49 <Cale> krey: Are you feeling lost?
15:49:51 <krey> :D
15:50:00 <krey> with monads always :)
15:50:04 <ksf> I'm always surprised what you can do with applicatives by making parsers yield functions
15:50:13 <wagle> can anyone get gitit to cabal install on a macosx or debian system?  which version of ghc/cabal?
15:50:30 <krey> i can do maths, i can do basic haskell, but i can't seem to get a grip with monads
15:50:48 <dobblego> do we have a channel for monad tutorials? I recall it was once discussed
15:50:53 <MissPiggy> krey, did my examples make sense?
15:51:02 <bos> #burrito?
15:51:04 <ksf> though ($) <$> foo <*> bar might not look particularily intuitive.
15:51:05 <pikhq> krey: Here's what you need to know about monads: they are types with (>>=) and return defined.
15:51:11 <krey> yep
15:51:12 <MissPiggy> krey, if the concept is clear, then the implementation stuff would just come about naturally
15:51:16 <BONUS> krey: do you get applicatives?
15:51:23 <Botje> krey: the trick to "getting" monads is simply to start using them. Once you no longer get type errors all the time, you get them :P
15:51:26 <twink> Monad tutorials are Cale's specialty.
15:51:35 <krey> applicatives?
15:51:45 <ksf> @where typeclassopedia
15:51:45 <lambdabot> http://www.haskell.org/haskellwiki/Typeclassopedia
15:51:46 <Cale> krey: Okay, no need to be afraid. If you have your programmer's hat on, "monad" is just a particular sort of API -- it means that your type has a particular shape, and it supports some particular functions.
15:51:46 <BONUS> often it's easier to "get" applicatives and then see that monads are just applicatives with >>=
15:51:53 <ksf> krey, read that one
15:52:12 <Cale> krey: So, let's look at this parser type, and think about what it needs to become a monad.
15:52:17 <BONUS> also i like this one: http://www.haskell.org/haskellwiki/Monads_as_Containers
15:52:22 <krey> ok
15:52:26 <benmachine> ksf: isn't ($) <$> f <*> g the same as f <*> g
15:52:27 <Cale> krey: First of all, we need an implementation of  return :: a -> Parser a
15:52:28 <krey> thanks for all these links
15:52:32 <krey> im going to read them
15:52:34 <krey> and then return
15:52:37 <ddarius> benmachine: Reading PDFs is underrated.
15:52:40 <benmachine> krey: noo listen to Cale
15:52:41 <Cale> krey: oh, okay...
15:52:43 <benmachine> it's more didactic
15:52:43 <Cale> er
15:52:47 <benmachine> ddarius: both
15:52:49 <ksf> benmachine, yep, it is. but flip ($) <$> ... isn't.
15:52:54 <copumpkin> oxamus: I just responded
15:53:02 <krey> you have been most helpful, thank you
15:53:05 <benmachine> ksf: mm, fair enough
15:53:09 <Cale> I also have a bunch of stuff that I've written about monads.
15:53:15 <krey> oooh
15:53:19 <Cale> http://www.haskell.org/haskellwiki/Monads_as_Computation
15:53:21 <monadic_kid> to me a monad is a meta-pattern, pattern of patterns. You can implement various abstraction with one abstraction
15:53:37 <Cale> http://www.haskell.org/haskellwiki/Monads_as_Containers
15:53:37 <krey> ima be really clever wheni read all this :D
15:53:39 <monadic_kid> *various abstractions with one
15:53:49 <Cale> krey: But you could also just try to follow along with this example :)
15:53:54 <krey> okay
15:53:58 <krey> lets do that
15:54:10 <krey> where were we?
15:54:22 <jjohnsson> Hello! I'm trying to use the Data.Vector stuff, using an example where I want to calculate the sum of the squares of the differences between a vector and all vectors in a "database" array (a vector of vectors).
15:54:29 <jjohnsson> The type signature of the main function is sumSquaresDiffs :: U.Vector Double -> V.Vector (U.Vector Double) -> V.Vector Double (V is Data.Vector and U is Data.Vector.Unboxed).
15:54:42 <jjohnsson> The implementation is sumSquaresDiffs a b = V.map (sumSquaresDiff a) b, where sumSquaresDiff just takes two unboxed vectors and calculates its result. It's half the speed of corresponding Matlab code on my computer, compiled with ghc --make -Odph, so I just wonder if this is the proper way to do it. It seems that the "array" cannot be made using unboxed vectors, and the V.map above produces a boxed vector, so maybe there is some room 
15:54:43 <jjohnsson> improvement?
15:54:43 <ksf> krey, don't listen to cale, he is trying to block out the fact that he just doesn't get zygohistomorphic prepromorphisms by giving exhaustive monad tutorials.
15:54:49 <Cale> So, a monad in Haskell consists of 3 things: a type constructor M (which is what we usually are referring to when we say "the monad")
15:54:59 <Cale> an implementation of return :: a -> M a
15:55:09 <jjohnsson> quite complete haskell newbie, by the way.
15:55:18 <krey> and bind >>= (a -> m b)
15:55:20 <Cale> and an implementation of (>>=) :: M a -> (a -> M b) -> M b
15:55:29 <krey> yeah, something like that :)
15:55:30 <MissPiggy> "But why is Haskell so great when everyone just put everything in the IO Monad all the time?
15:55:33 <Cale> right
15:55:33 <MissPiggy> hahaha
15:55:42 <Cale> So we have our type constructor Parser
15:55:48 <dobblego> MissPiggy, ?
15:55:53 <Cale> and we want  return :: a -> Parser a
15:55:54 <MissPiggy> dobblego it's from that reddit link
15:55:55 <ksf> jjohnsson, isn't dph meant to be used with [: :] thigies?
15:55:59 <MissPiggy> http://www.reddit.com/r/programming/comments/b7bn6/why_do_i_read_all_these_blogs_about_lisp_and/
15:56:05 <MissPiggy> someone just linked that a moment ago
15:56:20 <jjohnsson> I just used some advice from some blog post by dons, let me see...
15:56:25 <ksf> jjohnsson, try -O3 and -O3 -fvia-C
15:56:27 <Cale> Normally, return v will be the "computation" which when run "does nothing" (whatever that means), and produces the value v as its "result"
15:56:31 <MissPiggy> I think they but be fooling around, nobody really thinks all haskell is in IO monad.. do they?
15:56:33 <ddarius> benmachine: (($) <$>) = (id <$>) = fmap id = id
15:56:33 <Alpounet> jjohnsson, x4 speedups ? :p
15:56:45 <ksf> er -O2 . -O3 doesn't exist.
15:56:45 <monadic_kid> these kind of reddit posts are dumb, it's like these people haven't even attempted to google
15:56:46 <Cale> I'm using quotes, because what these words mean in various monads is somewhat different.
15:56:57 <jjohnsson> ksf: thanks, I'll try it
15:57:17 <jjohnsson> Alpounet: Matlab was twice as fast. may not be a very rigorous benchmark though.
15:57:25 <Cale> But in the case of parsers, return v will naturally be the parser which doesn't eat any characters, but succeeds, producing the result v
15:57:43 <Cale> So:  return v = P (\s -> [(s,v)])
15:58:05 <krey> ok, wait a minute, processing
15:58:37 <chrissbx> I've got the problem of having a type like "data Foo a = Bar | Baz a" and wanting to write generic code for that type that works for any a. How?
15:58:40 <krey> the definition of parser is a bit strange
15:58:43 <Cale> Okay
15:58:48 <Alpounet> jjohnsson, you may want to see how things go with the (still experimental) llvm backend
15:58:49 <krey> i mean
15:58:58 <benmachine> chrissbx: what do you want the code to do?
15:59:03 <Cale> "A parser for things is a function from strings to lists of pairs of strings and things." :)
15:59:06 <Alpounet> it performs quite well on numerical code
15:59:12 <krey> yep
15:59:20 <krey> but id just do it with "type"
15:59:34 <Cale> Yeah, we need at least newtype to be able to define an instance of Monad though
15:59:35 <krey> but i guess you need to data for some reason...
15:59:48 <krey> ok
15:59:48 <Cale> I went with data in case you're unfamiliar with newtype
15:59:51 <copumpkin> wow, my comment on that reddit thread was controversial
15:59:51 <jjohnsson> Alpounet: well, I don't feel that bleeding edge right now, I'll try it when it's easily accessible. but thanks for the advice
16:00:00 <dons> Heffalump: yes, order of passes on the command line is order they are run in
16:00:00 <krey> i am, good choice :)
16:00:04 <dons> making the search space rather larger
16:00:10 <krey> sooo
16:00:29 <Heffalump> dons: fun :-)
16:00:31 <Alpounet> jjohnsson, btw, before reading don's post, I dare asking if you have already read the performance/optimization sections of GHC's manual and haskellwiki ?
16:00:32 <krey> return v = P (\s -> [(s,v)])
16:00:34 <Heffalump> are you getting anywhere with beating -O3?
16:00:38 <aavogt> if it has to work for any a your data Foo might as well be   data Foo = Bar | Baz, chrissbx
16:00:40 <chrissbx> benmachine: I'm implementing a lisp; it's a s-expression parser that I'd like to keep separate from knowhow about what other things s-expressions can contain than s-expressions.
16:00:57 <Cale> So P is a data constructor which turns a function of type  String -> [(String, a)]  into a value of type  Parser a
16:01:06 <krey> yep
16:01:08 <dons> Heffalump: i think we might have to use the GA properly and let it slowly search over night
16:01:11 <Cale> Oh, we'll also want a way to 'run' these parsers
16:01:12 <Alpounet> jjohnsson, and hp2any, criterion, progression and all may be of help
16:01:15 <jjohnsson> Alpounet: :) well... I've skimmed through it. Maybe I should re-read it.
16:01:22 <Cale> runParser :: Parser a -> String -> [(String,a)]
16:01:30 <Cale> runParser (P f) s = f s
16:01:32 <Alpounet> these are all hot topics in the blogosphere, you will find some informations there
16:01:33 <Cale> yeah?
16:01:41 <krey> yep
16:01:42 <dons> Heffalump: oh, and you can run them multiple times
16:01:44 <dons> crikey
16:01:50 <Alpounet> (mostly profiling & benchmarking tools)
16:02:03 <benmachine> chrissbx: hmm, you probably know what you are doing better than I do >_> also I am hungry
16:02:09 <chrissbx> benmachine: to clarify: I need to extend the s-expression type for internal purposes, but the parser code should remain clean from that extension
16:02:09 <benmachine> it is midnight but I am hungry
16:02:10 <benmachine> so there
16:02:15 <Heffalump> jjohnsson: I didn't follow which bit of your code couldn't use unboxed vectors
16:02:28 <Heffalump> it's midnight and I probably have to get up in 6 or 7 hours :-(
16:02:45 <jjohnsson> with -O2 -fvia-C it takes 1.8 seconds, with -Odph it takes 1.6.
16:03:04 <ksf>     Ambiguous module name `SrcLoc':
16:03:05 <ksf>       it was found in multiple packages: hdirect-0.21.0 ghc-6.13
16:03:21 <chrissbx> aavogt: no, Baz a isn't the same as Baz; with a, Foo types can contain random other types, without it it can't.
16:03:22 <ksf> ouch. now I know what cabal really does for me with --hide-all-packages
16:03:25 <Cale> krey: It might help, before we continue, to get comfortable with this sort of parser by defining some primitive parsers we'll need to make the thing usable anyway
16:03:30 <benmachine> if you have -fvia-C aren't you also supposed to have -optc-O3 and something to do with fast-math
16:03:44 <krey> ok
16:03:44 <Cale> krey: For instance, the parser which tries to match a particular character.
16:03:57 <krey> lemme try
16:03:57 <pikhq> jjohnsson: -optc-O3 should help; passes -O3 to the C compiler.
16:04:08 <Cale> and if it succeeds, it produces that character as a result, depleting the string, and if it fails, gives an empty list of parses
16:04:10 <ksf> -optc-ffast-math
16:04:17 <jjohnsson> Heffalump: I put a bunch of unboxed vectors within a boxed vector. then I want to compare an unboxed vector to those within the boxed vector, for which I used the map function for the boxed vector. however, this produces a boxed vector as a result. I guess this could be made in a better way.
16:04:21 <ksf> -optc-fomit-framepointer
16:04:22 <krey> so
16:04:25 <Alpounet> jjohnsson, have you read that : http://www.haskell.org/haskellwiki/Performance ?
16:04:32 <ksf> -optc-fimagentooricerbreakmycode
16:04:33 <aavogt> chrissbx: what I mean is that a (function :: Foo a -> Int) can't do anything practical with any values of type a
16:04:34 <krey> just check head of string?
16:04:37 <krey> or anywhere?
16:04:42 <Heffalump> jjohnsson: ah, got it
16:04:46 <Cale> Yeah, just the head of the string
16:04:51 <pikhq> ksf: That's -optc-funroll-loops
16:04:56 <Cale> Of course, in the empty string case, we also fail.
16:05:01 <chrissbx> aavogt: but it can use all other constructors; or even return a
16:05:07 <pikhq> ksf: -optc-fomit-framepointer is default on not-x86. ;)
16:05:13 <aavogt> chrissbx: but is this 'a'  supposed to be some set of known types?
16:05:19 <Cale> So,  char :: Parser Char
16:05:26 <jjohnsson> pikhq: just that or in combination with something else?
16:05:35 <MaciejP> chrissbx: Maybe you want Baz to store a Dynamic value?
16:05:38 <pikhq> jjohnsson: In combination with -fvia-c -O2
16:05:42 <chrissbx> aavogt: known outside of the parser; it is known in the interpreter. But I don't want to code this type into the parser.
16:05:46 <aavogt> or say you additionally know:    (function :: (String -> a) -> Foo a -> Int)
16:05:50 <krey> (\s -> if head s == x then [(x,tail s)] else [])
16:05:52 <pikhq> jjohnsson: -fvia-c makes GHC actually compile to C.
16:05:53 <krey> something like this?
16:05:59 <Heffalump> jjohnsson: what you really want is for fusion to kick in.
16:06:00 <krey> for some x
16:06:07 <chrissbx> aavogt: because I'm going to use the parser for several different interpreters
16:06:09 <wagle> how do i get cabal to ignore a dependency?
16:06:11 <Cale> krey: close...
16:06:19 <aavogt> chrissbx: do you know how read resolves types?
16:06:25 <Cale> krey: But we need to handle the empty string too.
16:06:26 <krey> :S
16:06:28 <chrissbx> aavogt: no
16:06:29 <krey> ooh
16:06:35 <Heffalump> hmm, perhaps it can't.
16:06:36 <chrissbx> aavogt: which read?
16:06:41 <aavogt> @type read
16:06:42 <lambdabot> forall a. (Read a) => String -> a
16:06:42 <Cale> So, probably best to use case and pattern match
16:06:47 <krey> ok
16:06:53 <Cale> Or define a helper function with pattern matching
16:07:03 <jjohnsson> oh, I should add that I'm on 6.10.4. So maybe I don't get all the performance benefits? Waiting for the Haskell Platform to catch up.
16:07:16 <krey> so i have this parser
16:07:18 <krey> what now?
16:07:18 <Cale> er, oops
16:07:26 <Cale> I gave a bad type signature for char above.
16:07:35 <Cale> char :: Char -> Parser Char
16:07:36 <aavogt> as in leave those types parameterized, but require passing some helper function (possibly implicitly by a typeclass) that can generate those values
16:07:40 <jjohnsson> pikhq: no difference adding that option
16:07:53 <krey> so
16:08:00 <krey> char takes a character
16:08:10 <krey> and returns a parser for that particular character
16:08:12 <krey> right?
16:08:17 <pikhq> jjohnsson: Hrm.
16:08:18 <Cale> yeah
16:08:38 <Heffalump> I think the Vector API may need to be improved for this use case.
16:08:38 <krey> i think i can manage that, yep
16:08:55 <Heffalump> oh, unless it fuses conversion of boxed to unboxed with a map?
16:08:56 <copumpkin> Heffalump: what use case?
16:09:01 <Cale> char c = P f where f [] = ...; f (x:xs) | x == c = ...  | otherwise = ...
16:09:13 <aavogt> chrissbx: so your    parseExpr :: Parser a -> Foo a -> Parser (Foo a)
16:09:19 <jjohnsson> pikhq: I guess I should reiterate that I'm a newbie, and may very well have done some stupid mistake. Just today starting to get the hang of how to do simple things.
16:09:30 <aavogt> or if there's only one parser per result type:
16:09:31 <Heffalump> copumpkin: mapping a function over a boxed vector, giving an unboxed vector
16:09:40 <Heffalump> jjohnsson: try making your eventual return type be an unboxed vector
16:09:48 <Heffalump> (just by adding a final conversion step)
16:09:57 <copumpkin> Heffalump: ah, I see. You could probably do that with unstream . stream
16:09:59 <Heffalump> if we're really lucky, fusion will kick in and the intermediate boxed one will vanish
16:10:03 <Alpounet> jjohnsson, the performance section of the haskell wiki may be of help
16:10:23 <aavogt> *parseExpr :: Parser a -> Parser (Foo a)
16:10:23 <Heffalump> Alpounet: jjohnsson has a fairly specific problem with boxed vectors here, I think.
16:10:31 <Alpounet> oh
16:10:51 <Alpounet> if it's just a "tiny" boxed vector centered program, yeah, ok
16:11:45 <jjohnsson> Alpounet: I hear you, and I am interested in how to make code perform in general, but in this case I just wanted to know if I did this particular way of implementation the right way. I guess I could just use som binding to fortran and get speed immediately, but what's the fun in that? ;)
16:11:58 <jjohnsson> it is really tiny.
16:12:09 <Heffalump> jjohnsson: try what I said about converting to an unboxed vector at the end
16:12:17 <jjohnsson> yes, looking into it.
16:12:29 <jjohnsson> just don't know how to convert yet.
16:12:41 <krey> Cale?
16:12:46 <Cale> krey: yep?
16:12:50 <Alpounet> ok
16:12:59 <Cale> krey: okay
16:13:04 <krey> are you going to carry on explaining then?
16:13:08 <Cale> So I can finish that if you like :)
16:13:21 <Cale> char c = P f where f [] = []; f (x:xs) | x == c = (xs,x) | otherwise = []
16:13:44 <Cale> (obviously a little funny when squished onto one line, but not so bad)
16:13:58 <Cale> er, oops
16:14:00 <krey> (also missing a pair of brackets, but i get it)
16:14:01 <Cale> char c = P f where f [] = []; f (x:xs) | x == c = [(xs,x)] | otherwise = []
16:14:03 <Cale> yeah
16:14:13 * hackagebot glpk-hs 0.1.0 - Comprehensive GLPK linear programming bindings  http://hackage.haskell.org/package/glpk-hs-0.1.0 (LouisWasserman)
16:14:21 <Cale> all right, good, now, let's have a look at >>=
16:14:33 <Cale> >>='s type can be daunting at first, but the idea is not really so bad
16:14:45 <Cale> (>>=) :: Parser a -> (a -> Parser b) -> Parser b
16:14:57 <Cale> >>= takes a parser whose results have type a
16:15:11 <Cale> and a function from values of type a, to further parsers whose results have type b
16:15:19 <krey> yep, but why?
16:15:23 <krey> if i write a parser
16:15:27 <Cale> and somehow glues those together into a parser whose results have type b
16:15:32 <krey> doesn't it generally parse things to the same type?
16:15:40 <pikhq> krey: No.
16:15:47 <Cale> So, the idea is that how we continue to parse the string can depend on what we parsed initially
16:16:06 <Heffalump> jjohnsson: I think either toList and fromList, or stream and unstream. Try the latter first.
16:16:14 <Cale> and we represent that by using a function from the result of the parser which eats the beginning of the string, to a parser which eats whatever's left over
16:16:55 <Cale> That is,
16:16:57 <jjohnsson> Heffalump: so I convert from boxed to list and then back to unboxed? sounds inefficient to me, but I'll try.
16:16:59 <Cale> x >>= f
16:17:05 <Cale> will be the parser which
16:17:38 <Cale> runs x against the initial string s, and for each depleted string s' and result v
16:17:51 <Cale>   it runs the parser f v on the depleted string s'
16:18:42 <Heffalump> jjohnsson: the hope is it'll all get fused.
16:18:54 <Cale> If this is too complicated, we can take a step back and implement (>>) :: Parser a -> Parser b -> Parser b, which ignores the result of the first parser, and is just simple concatenation
16:18:55 <Heffalump> try the stream/unstream first, it's more likely to work out
16:19:06 <wagle> puzzle me this: both datetime and happstack-util are (cabal) installed, yet i cannot install gitit because they cant both be installed because they want different versions of QuickCheck..  how do i install anyway?
16:19:07 <Cale> But (>>=) will give us (>>) for free
16:19:13 <krey> sooo
16:19:19 <krey> x >>= f
16:19:27 <krey> hmm
16:19:28 <krey> lemme think
16:20:17 <krey> so the function f
16:20:27 <krey> takes a result of a previous parser
16:20:37 <Cale> yeah, the parser x there
16:20:51 <Cale> and it's going to decide how to continue parsing the string
16:21:04 <krey> okay
16:21:14 <Cale> It might just do the same thing regardless, but that's a special case.
16:21:37 <Cale> The point being that we're allowed to decide how to continue based on what we've already seen
16:22:04 <Cale> Are you comfortable with list comprehensions?
16:22:11 <krey> oooh monads again :D
16:22:13 <krey> yep
16:22:15 <Cale> okay
16:22:38 <Cale> So, we'll have it do exactly what I described. I'll write it piece by piece.
16:22:44 <Cale> x >>= f = ...
16:23:07 <Cale> Well, at this point, we know we want to produce a Parser, and we don't have too many too many ways to do that yet, so we'll use the data constructor P
16:23:13 <Cale> x >>= f = P (...)
16:23:28 <Cale> and P takes a function, so it might as well be a lambda
16:23:32 <Cale> x >>= f = P (\s -> ...)
16:23:57 <Cale> So now we have our initial string s, we want to run x on the initial string...
16:24:09 <Cale> x >>= f = P (\s -> ... runParser x s ...)
16:24:39 <Cale> and for each of the depleted strings s' and results v, we want to continue with something else, so we'll use a list comprehension...
16:24:51 <Cale> x >>= f = P (\s -> [... | (s',v) <- runParser x s, ...])
16:25:35 <Cale> and what do we want to do? We want to run (f v) with s', and each of its depleted strings and results will be a depleted string/result of our combined parser
16:25:48 <Cale> x >>= f = P (\s -> [... | (s',v) <- runParser x s, (s'',w) <- runParser (f v) s'])
16:25:53 <aksionov> mm_freak: Thanks for writing http://ertes.de/articles/monads.html :)
16:26:02 <Cale> So we run the parser f v on s'
16:26:21 <Cale> capturing the final depleted string s'' and result w
16:26:29 <Cale> and we just want to return those...
16:26:35 <Cale> x >>= f = P (\s -> [(s'',w) | (s',v) <- runParser x s, (s'',w) <- runParser (f v) s'])
16:26:45 <krey> hmm
16:26:51 <krey> i donno
16:26:55 <krey> why do we need this?
16:27:00 <krey> why cant we just use map?
16:27:09 <Cale> We could use map and concat
16:27:28 <krey> oo
16:27:40 <krey> cause our new parser could return multiple values...
16:27:45 <Cale> But the list comprehension provides us with nice syntax for saying how we want to proceed with each of the results
16:27:47 <Cale> right
16:28:13 <Cale> So it's for each (s',v) and each (s'',w) after that
16:28:58 <Cale> Now, we can take our definitions of return and (>>=) and write the proper instance of Monad
16:29:02 <Cale> instance Monad Parser where
16:29:10 <Cale>   return v = ...
16:29:15 <Cale>   x >>= f = ...
16:29:32 <wagle> can anyone get gitit to install via cabal on their machine?  what machine/os?
16:29:56 <Cale> and with this, we automatically get do-notation
16:30:20 <Cale> do { v <- x; <stmts> } = x >>= \v -> do { <stmts> }
16:30:24 <krey> arent we supposed to check monad laws and such?
16:30:28 <Cale> Oh, well, yes
16:31:16 <Cale> It's a little involved, checking the associative law particularly.
16:31:42 <Cale> But if you'd like to do it...
16:31:50 <krey> :D
16:32:02 <krey> not this time of night
16:32:06 <Cale> okay
16:32:23 <Cale> Now let's suppose we want to write a parser which does matched parens
16:32:44 <Cale> oh, actually we need one more thing
16:33:01 <Cale> We need an operation  (+++) :: Parser a -> Parser a -> Parser a
16:33:15 <Cale> which has the union of the results of the two parsers you give it
16:33:29 <Cale> So, if one or the other matches, you get a result.
16:33:46 <Cale> This is pretty simple, we just concatenate the lists of results:
16:34:00 <krey> what about repetitions??
16:34:01 <Cale> x +++ y = P (\s -> runParser x s ++ runParser y s)
16:34:19 <chrissbx> I'm unavoidably running into import cycles; moving all code into the same file would supposedly help; is there another solution (short of removing the cyclic data dependency that leads me to needing the cyclic imports)?
16:34:24 <Cale> Well, we'll preserve the number of occurrences, because it's easiest that way.
16:34:52 <Cale> This isn't a particularly *efficient* parsing library we're writing, but it's probably as simple as we can manage :)
16:35:02 <krey> ok
16:35:12 <Cale> chrissbx: Usually moving types out into their own module helps.
16:35:33 <ddarius> With the proper definition for Parser, Parser x `mappend` Parser y = Parser (x `mappend` y)
16:35:52 <Cale> Yeah, we could have made this a Monoid instance
16:35:53 <chrissbx> Cale: I did this, but because I have a show instance, which I need, I have to import the instance declaration too, and that needs both types
16:35:55 <mauke> chrissbx: are the cycles a problem?
16:36:27 <jjohnsson> Heffalump: No difference in speed using toList and fromList, unfortunately, at least with ghc. With ghci it got a lot slower, I didn't have the patience to wait it out. But now I really need to sleep.
16:36:33 <jjohnsson> thanks for all the help! :)
16:36:35 <chrissbx> mauke: the problem is the imports. GHC complains about cyclic imports. Moving everything to 1 file should help. But that'd be suboptimal, which is why I'm asking
16:36:46 <mauke> chrissbx: you could write a .hs-boot file
16:36:51 <Cale> krey: Okay, so now we could write a parser which matches strings of parens which are balanced
16:37:17 <Cale> parens = (do char '('; parens; char ')'; parens) +++ return ()
16:37:53 <Cale> Of course, that's not using the full power of our >>=, because we're ignoring the results of our parsers
16:38:02 <mauke> chrissbx: http://haskell.org/ghc/docs/latest/html/users_guide/separate-compilation.html#mutual-recursion
16:38:19 <Cale> We could also extract the largest nesting depth as we parse, which is more fun
16:38:22 <ddarius> s/parser/recognizer
16:38:23 <Heffalump> jjohnsson: pity. I guess you need dons' ninja core-reading skills to figure it out.
16:38:35 <krey> ooh, getting confused
16:38:52 <Cale> parens = (do char '('; n <- parens; char ')'; m <- parens; return (max (n+1) m)) +++ return 0
16:39:18 <Cale> It's good to get comfortable with the translation between do-notation and the >>= operation we wrote
16:39:26 <Cale> do { x } = x -- base case
16:40:14 <Cale> do { x ; <stmts> } = x >> do { <stmts> }  -- where x >> y = x >>= \k -> y
16:40:27 <Cale> do { v <- x ; <stmts> } = x >>= \v -> do { <stmts> }
16:40:50 <Cale> do { let { <decls> } ; <stmts> } = let { <decls> } in do { <stmts> }
16:41:27 <Cale> So, do-blocks are mostly just convenient sugar for chains of >>=
16:41:55 <krey> ok
16:42:04 <krey> but i don't understand the previous parser
16:42:05 <Cale> parens = (char '(' >> parens >>= \n -> char ')' >> parens >>= \m -> return (max (n+1) m)) +++ return 0
16:42:10 <Cale> okay
16:42:30 <ddarius> Cale: Provide an example of input it recognizes.
16:42:43 <Cale> the basic idea is that a balanced string of parens is either the empty string (which we handle with the "+++ return 0" on the end)
16:43:18 <Cale> or it is a nonempty string which starts with an open paren, has some balanced string of parens, then a closed paren, and some other balanced string of parens
16:43:30 <Cale> For example...
16:43:38 <Cale> (())()
16:43:52 <krey> ok
16:43:56 <krey> ima sleep on this
16:44:14 <krey> and read
16:44:15 <Cale> Starts with a (, followed by () which is a balanced string of parens, then a ) and finally () which is another balanced string
16:44:40 <krey> but i've saved everything you told me
16:44:43 <Cale> cool
16:44:47 <krey> and shall return with questions
16:44:52 <Cale> sure
16:45:03 <krey> thank you very much!
16:45:05 <krey> nnight!
16:45:07 <jjohnsson> Heffalump: yeah, maybe. But I still have some idea of doing the comparison "explicitly", by "looping" through the vector of vectors and comparing, and thus not needing the boxed vectors. Maybe I'll try it tomorrow.
16:45:08 <Cale> night
16:45:15 <jjohnsson> night all!
16:45:39 <ksf> Failed: llc -tailcallopt /tmp/ghc30967_0/ghc30967_0.bc -o /tmp/ghc30967_0/ghc30967_0.s getProcessExitCode: interrupted (Interrupted system call)
16:45:43 <ksf> now that's strange
16:45:50 <Heffalump> jjohnsson_: makes sense, though that's what fusion should do for you
16:49:08 <m3ga> is there a way to tell the platform's pointer size (ie 32 vs 64 bit) from haskell code?
16:50:08 <pikhq> m3ga: Not sure of the way to do it, but probably somewhere in the C FFI.
16:50:09 <mauke> sizeof (undefined :: Ptr CChar)
16:50:15 <mauke> sizeOf
16:50:25 <m3ga> mauke: thanks
16:50:26 <pikhq> That'd be the way, yeah.
16:51:20 <m3ga> a little ugly, but should work.
16:52:05 <ksf> ...stuff is working fine if I call llc without -tailcallopt
16:54:51 <alex404> Does anyone here use vim for haskell coding?
16:55:56 <mauke> yes
16:58:05 <pardus> alex404, and yes again
16:58:49 * ksf only uses head, tail and cat.
16:59:22 <gwern> as if anyone needed anything but cat and >>!
17:00:24 * pikhq speaks at exactly the right frequency to modify the kernel's drive queue so that the right data gets written
17:01:43 <adu> ksf: have you tried 'only'?
17:02:07 <adu> ksf: http://hackage.haskell.org/package/only
17:02:44 <JoshTriplett> Why can I not use record selectors with existentially quantified types?
17:03:00 <adu> JoshTriplett: what exactly do you mean?
17:03:13 <Saizan> because there's no way to express their type in haskell.
17:04:32 <JoshTriplett> Specifically, I have a type "data D = forall a . C a => D { d_field :: a }", and a class "class C a where c :: a -> T", and I want the function "c . d_field :: D -> T".
17:04:44 <alex404> mauke: Hey, sorry for dissapearing. I'm finding that the indent script for haskell indents under keywords like 'if/case/let' even in comments, which is dreadfully annoying. Do you know anyway around this?
17:04:56 <mauke> oh, no idea
17:05:13 <alex404> dang, it's very frustrating
17:05:27 <ksf> esc^i
17:05:43 <adu> JoshTriplett: and you have "instance C D"?
17:06:04 <JoshTriplett> Saizan: What do you mean by "no way to express their type"?  Seems like they have a fairly obvious type: they take a D, and return some instance of class C.
17:06:10 <ksf> ESCc^?
17:06:11 <Saizan> instance C D where c (D x) = c x
17:06:15 <ksf> I'm not sure, but it should work.
17:06:19 <JoshTriplett> adu, Saizan: Yes, why?
17:06:19 <mauke> JoshTriplett: how do you say "some instance of class C"?
17:06:30 <alex404> pardus: Hey, do you have any issues with the haskell indent script indenting inside comments?
17:06:53 <JoshTriplett> mauke: Existentially quantified types?
17:07:02 <JoshTriplett> Saizan: Why would that cause a problem?
17:07:07 <mauke> JoshTriplett: yes. how do you say that in haskell?
17:07:12 <Saizan> JoshTriplett: there's no exists quantifier in haskell
17:07:26 <adu> c (D (x :: D)) should force it
17:07:45 <Saizan> JoshTriplett: the type of d_field should be "D -> exists a. C a *> a"
17:07:58 <Saizan> JoshTriplett: but there's nothing like exists in haskell
17:08:06 <JoshTriplett> I see.  But I can do something like "case dvar of D x -> c x"?
17:08:12 <Saizan> yes, you can
17:08:14 <ksf> there is in uhc
17:08:24 <JoshTriplett> Saizan: Simply because GHC never has to think about the type of x?
17:08:38 <Saizan> ksf: uhc's exists doesn't work with typeclasses afaik
17:09:19 <JoshTriplett> OK.  Time for some fun and exciting adventures in Template Haskell. :)
17:09:24 <adu> JoshTriplett: I bet you $1M that what you're doing can be done better with type families
17:09:46 <JoshTriplett> adu: No bet. :)  Happy to explain what I want to do, though.
17:09:58 <mauke> d_field :: D -> (forall a. (C a) => a -> b) -> b
17:10:32 <JoshTriplett> Currently using Text.HTML.Chunks: http://hackage.haskell.org/packages/archive/chunks/2007.4.18/doc/html/Text-HTML-Chunks.html
17:10:54 <JoshTriplett> It turns templates into "data Chunk_foo = Chunk_foo { foo_a :: String, ... }"
17:11:40 <pardus> alex404, yep
17:11:45 <JoshTriplett> With instances of the class "class Chunk c where format :: c -> String".
17:12:23 <JoshTriplett> I wanted to make a framework that avoids the need to manually HTML-escape strings, while still allowing nested template expansions.
17:12:45 <JoshTriplett> So, I made a wrapper: "newtype HTML = HTML { unHTML :: String }".
17:13:02 <JoshTriplett> And a class: "class Escape e where esc :: e -> HTML".
17:14:01 <JoshTriplett> esc for String does HTML escaping; esc for Chunk_foo just formats the chunk, trusting the template to not have malicious HTML.  I've used Template Haskell to rewrite the chunks to have existential type, with each field having some escapable type.
17:14:38 <JoshTriplett> And then I just want to rewrite the format functions in the Chunk instances to use "unHTML . esc . foo_a" instead of foo_a, and then re-wrap in an HTML.
17:14:54 <JoshTriplett> Which I've now done, except I get the warning that started this line of questioning.
17:15:07 <JoshTriplett> adu: So, how can I do this better with type families? ;)
17:15:49 <JoshTriplett> I want to write things like: Chunk_foo 5 "<script src="dangerous"></script>" Chunk_bar
17:15:53 <JoshTriplett> and then call esc on them.
17:16:07 <JoshTriplett> Without having to call esc on the arguments.
17:19:28 <aavogt> preflex: seen dcoutts
17:19:28 <preflex>  dcoutts was last seen on #ghc 20 days, 5 hours, 57 minutes and 25 seconds ago, saying: ok, ta
17:19:45 <aavogt> preflex: seen dcoutts_
17:19:46 <preflex>  dcoutts_ was last seen on #haskell 4 days, 2 hours, 45 minutes and 48 seconds ago, saying: gwern: ask Igloo for old repos that needs moving elsewhere
17:20:38 <aavogt> has anybody used the cabal-1.8 feature that enables you to have executables that depend on modules from a library in the same package?
17:21:21 <aavogt> I'm running into problems where cabal seems to pass   -package-id myPackageName-version, which doesn't match because -package-id is supposed to include some kind of hash
17:32:02 --- mode: ChanServ set +o mauke
17:32:02 --- mode: mauke set -b *!*@BSN-176-138-210.dial-up.dsl.siol.net
17:33:06 <dons> mm. seem to have found a faster combination of flags.
17:33:07 <dons> yay
17:33:18 <copumpkin> :o
17:33:38 <enth|walk> hehe
17:33:49 <enth|walk> love the name Muad_Dibber
17:34:02 --- mode: mauke set -o mauke
17:34:15 <enth|walk> mmmmm... shai'hulud...
17:41:48 <Zeiris_> Is there a filter that's generalized to functors?
17:42:05 <MissPiggy> Zeiries_, I don't believe that such a thing is possible
17:42:24 <dons> :t filter
17:42:25 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
17:43:20 <copumpkin> new class, Filterable :P
17:43:27 <camio> How would filter apply to a pair?
17:43:32 <Berengal> It's just a foldable, isn't it?
17:43:35 <copumpkin> it wouldn't
17:43:37 <copumpkin> Berengal: nope
17:43:52 <copumpkin> and even Traversable doesn't let you change the "shape" of the structure
17:43:52 <Berengal> Traversible then?
17:43:57 <Berengal> Bah
17:44:19 <Berengal> Applicative?
17:44:34 <Berengal> I guess not even that
17:45:29 <c_wraith> No, Filterable would be quite a lot less general.  It would almost certainly imply a structure that can contain variable numbers of elements.
17:45:29 <Berengal> You could do it if there was an Unfoldable class
17:45:53 <aavogt> use   Functor f => f (Maybe a) instead?
17:46:22 <camio> That's interesting. Although, I can see how to unfold a list, but not a tree. Where I can see filtering both a tree and a list.
17:46:32 <c_wraith> aavogt: I don't want a CatMaybeable class.  :P
17:47:22 <Berengal> We need to not call our classes -able
17:47:38 <MissPiggy> GoooGooGaaGaaable
17:47:38 <aavogt> Fmappable
17:47:45 <copumpkin> camio: an unfold for a tree is different from one for a list
17:48:33 <Berengal> We should instead append -ism to all class names
17:48:43 <c_wraith> FMapism
17:49:05 <Berengal> Or -or, or -orfism, to combine them
17:49:11 <Berengal> Monadorfism
17:49:26 <c_wraith> Monadorphismable
17:49:33 <c_wraith> ...  Ok, time for me to leave
17:49:50 <Berengal> Monadableorfism
17:50:25 <camio> :t unfold
17:50:26 <lambdabot> Not in scope: `unfold'
17:50:31 <Berengal> It's an ism that is an object that can do something that turns stuff into monads
17:50:34 <c_wraith> :t unfoldr
17:50:35 <lambdabot> forall b a. (b -> Maybe (a, b)) -> b -> [a]
17:51:18 <Berengal> And also, let's not forget -TRON
17:51:57 <copumpkin> camio: you need to look at the "underlying" functor of the structure you're unfolding over
17:52:10 <copumpkin> camio: the usual list is composed of not one but two functors!!!
17:52:20 <copumpkin> one is secret
17:52:21 <Berengal> Monad -> MONATRON, Functor -> FUNCTRON, Eq -> EQUITRON, Foldable -> FOLTRON
17:52:27 <camio> So unfoldr for a binary tree might be. forall b a. (b -> Maybe (a,Bool,b)) -> b -> [a]
17:52:35 <copumpkin> MonadFix -> CYCLOTRON
17:52:44 <copumpkin> camio: why Bool?
17:52:59 <camio> hrm, that's not it. I was thinking of choosing which side of the binary tree to continue on.
17:53:35 <copumpkin> anyway, it depends :) Maybe (x, y) is the underlying functor of lists
17:53:58 <camio> underlying functor?
17:54:05 <copumpkin> its fixed point is a list
17:54:10 <camio> oh
17:54:18 <copumpkin> type ListF a b = Maybe (a, b)
17:54:29 <copumpkin> type List a = Fix (ListF a)
17:54:42 <Berengal> So they would be associated types then?
17:54:45 <camio> So to generalize an unfoldable structure, maybe we can use it's underlying functor then?
17:54:52 <copumpkin> camio: yep
17:55:03 <copumpkin> so the answer depends on how you structure your tree
17:55:14 <copumpkin> do you have data on inner nodes or just on leaves?
17:55:36 <camio> Lets say just on leaves for instance.
17:55:45 <camio> Or, whichever is easier.
17:55:52 <camio> for our context
17:55:54 <copumpkin> either works, just show me a data Tree a = ...
17:55:56 <copumpkin> :)
17:56:26 <Berengal> Leaf | Branch a (Tree a) (Tree a)
17:56:27 <camio> data Tree a = Leaf a | Branch (Tree a) (Tree a)
17:57:11 <copumpkin> for the first one, it's data TreeF a b = Leaf | Branch a b b
17:57:23 <copumpkin> the second is data TreeF a b = Leaf a | Branch b b
17:57:36 <copumpkin> so your unfold will want to generate values of one of those types
17:57:50 <camio> facinating
17:57:51 <copumpkin> (a fold would take those in)
17:58:11 <copumpkin> if you've played with fix, it's the same exact process, at the type level
17:59:22 <Berengal> Foldables usually concern themselves with monoids though
18:01:34 <dons> mm. this code's getting really fast now. exciting.
18:02:18 <copumpkin> how real is really?
18:02:35 <ddarius> 79.2% real.
18:02:41 <Berengal> <- this real ->
18:02:42 <copumpkin> nice!
18:02:49 <copumpkin> ddarius hacked dons computer and is watching his performance gains
18:02:58 <dons> well, -fasm is about 90ms, -fllvm -O3 is 60ms but currently i have 27ms
18:03:09 <copumpkin> nice
18:03:10 <dons> so its finding the right phases to run in llvm
18:03:23 <dons> i'm hoping it folds my loop down to a constant
18:04:05 <copumpkin> what is your loop?
18:04:08 <Berengal> Wait, you're running some things through -fast and some through -fllvm?
18:04:17 <pikhq> Berengal: -fasm
18:04:28 * pikhq wonders what an -fast would do.
18:04:47 <copumpkin> walks the AST
18:04:49 <copumpkin> ruby style
18:05:03 * Berengal wonders if the AST is a monad
18:05:41 <Berengal> I suspect it is
18:06:12 <MissPiggy> syntax is monadic yes
18:16:28 <dons> ah ha: 8ms. i think llvm has removed my loop :)
18:17:28 <copumpkin> ooh
18:18:58 * p_l loves cases where compiler simplifies a program to exit(0) ;-)
18:19:25 <Saizan> no loop for you
18:19:44 <stevenmarky> dons> It's like I'm accidentally stalking you today, I saw a blog post you wrote, then a stack overflow post, and now you're here.
18:20:00 <dons> hey stevenmarky :)
18:22:59 <pikhq> p_l: Aren't those wonderful?
18:37:04 <MaciejP> Is it possible to see the generated Haskell code for a TH splice?
18:38:24 <chrissbx> Is there a way to extend a type by inheritance instead of containment (is-a instead of has-a relationship)?
18:39:05 <choffstein> Anyone been able to effectively use zeromq with haskell?  I am getting an error with the latest bindings.
18:39:15 <copumpkin> chirssno
18:39:28 <copumpkin> chrissbx: no :P
18:39:34 <chrissbx> hm.
18:39:56 <dark> does haskell has a kind of 'duck typing'?
18:40:02 <copumpkin> typeclasses
18:40:07 <dolio> No.
18:40:18 <copumpkin> Data.Map of methods :P
18:40:54 <dolio> copumpkin: That sounds like a good way to simulate Ruby's performance.
18:40:54 <Saizan> HList + craftmanship
18:41:11 <copumpkin> dolio: I'm an expert at that kind of slowness
18:42:48 <MissPiggy> dark: what do you mean though?
18:42:50 <dolio> Wow, darcs 2.4 requires base 3?
18:43:27 <chrissbx> Is there a way to create type aliases (rename a type to another one, to avoid having to adapt a code base and to leave the original intention in the code)?
18:43:55 <chrissbx> something like a "data Foo = ...;  alias Foo2 = Foo;"
18:44:17 <copumpkin> you can make an alias, but they won't help you much
18:44:22 <copumpkin> type Moo = Baa
18:44:23 <MissPiggy> type Foo2 = Foo
18:45:20 <dons> dolio: they be old school
18:46:05 <dolio> Looks like they'll have to change that before 6.14.
18:46:24 <dark> MissPiggy, if some value can be used as X, it's X
18:46:59 <MissPiggy> dark hmm that seems to be true of haskell, but not in the sense you mean - I think
18:47:26 <dark> you probably is right, it was just a random question ^^
18:47:40 <MissPiggy> I think it's a good question
18:50:00 <dark> some OO 'dynamic' languages has duck typing, eg. python or ruby. ocaml has a row typing that is just the same: there is the "type of objects that has method X that receives an int and returns an int". a class, there, is just a shorthand to the signature of a definition, so I think this is like a duck typing too. but maybe this doesn't apply to haskell, because haskell isn't specifially OO (or is it?)
18:50:28 <MissPiggy> ;is
18:50:30 <MissPiggy> yes*
18:50:33 <copumpkin> definitely not OO
18:50:40 <twink> What's duck typing?
18:50:42 <enthymene> what's Object Orientedness anyway?
18:50:44 <MissPiggy> but like Saizan said, it can be done (in a scary way)
18:50:47 <enthymene> I mean, isn't a closure an object?
18:50:54 <MissPiggy> enthymene hehe
18:50:58 <MissPiggy> enthymene no and object is a closure
18:51:14 <enthymene> ?
18:51:16 <enthymene> no and?
18:51:27 <enthymene> oh s/and/an/
18:51:34 <enthymene> k thens
18:51:35 <MissPiggy> sorry it's a famous koan
18:51:42 <enthymene> I see
18:51:45 <enthymene> or not.
18:51:47 <MissPiggy> in computing
18:52:21 <enthymene> anyway, I've written functions that take messages and return functions or values.  Basically objects in any way that I've been taught them.
18:52:40 <enthymene> haven't done it in haskell, of course.  The class system is too nice.
18:52:54 <MissPiggy> OHhhh
18:53:05 <MissPiggy> Classes in haskell is completely unrelated to object oriented classes...
18:53:09 <enthymene> I know
18:53:15 <MissPiggy> @dark
18:53:15 <lambdabot> Maybe you meant: arr ask part yarr
18:53:20 <dark> yeah, MissPiggy ^^
18:53:23 <MissPiggy> just incase
18:53:25 <twink> Hmm. Duck typing sounds bad.
18:53:33 <enthymene> classes in teh same way as character classes in regular expressions
18:53:41 <pikhq> Duck typing is an abomination to strict typing.
18:53:42 <dark> hmm
18:53:46 <enthymene> not as in the definition of a stateful object type.
18:53:53 <dark> but there is duck strict typing
18:54:01 <dark> just like the row typing i described
18:54:01 <enthymene> it just waddles a bit
18:54:12 <carnieri> there is strict duct taping
18:54:36 <enthymene> duct tape is very strict
18:54:42 <enthymene> however, you can do lots with it.
18:54:47 <dark> lol
18:55:13 <dark> duck typing is: don't bother how it is implemented, how the code was derived or generated or inherited etc: if the interface of two things are the same, their types are the same
18:55:13 <enthymene> duct tape is like dakka.  When in doubt, you need more of it.
18:55:21 <enthymene> yeah, I know
18:55:24 <enthymene> I've used ruby.
18:55:39 <dark> i like the general idea. i dislike C++ / java OO
18:55:42 * ddarius is pretty sure the term "duck typing" precedes the existence of ruby.
18:55:54 <enthymene> not for anything serious, but when you have a book written for C++, ruby is a helluva lot faster than hashing out C++ code.
18:56:01 <dark> my code rarely fit in an hierarchy of types.. o.o
18:56:13 <pikhq> ddarius: It's a Python thing.
18:56:20 <MissPiggy> it's from before python no?
18:56:30 <ddarius> pikhq: Python isn't much older than Ruby if I'm not mistaken.
18:56:31 <carnieri> dark: what do you mean by hierarchy of types?
18:57:10 <dark> carnieri, types A and B are contained inside C that is contained inside D..
18:58:01 <carnieri> dark: how is a type "inside" another?
18:58:03 <dark> inheritance, etc (but in C++ if A inherits from B, it can't always be used as B, the code is inherited but not always the interface.. that's even worse)
18:58:08 <dark> hmm
18:58:10 <copumpkin> it's a subset
18:58:14 <copumpkin> but haskell doesn't do subtyping
18:58:21 <dark> hmm
18:58:52 <Saizan> in haskell you tend to use parametric polymorphism
18:59:26 <Saizan> there isn't so much need for nesting
18:59:41 <enthymene> well you have type constraints sometimes
19:00:14 <enthymene> like "class (Function a) => Differentiable a where ..." right?
19:00:50 <Saizan> yeah, but making a new type class is not that common.
19:00:51 <copumpkin> that's subclassing, but it's nothing like subtyping
19:01:11 <copumpkin> it means that if you want to make an instance of Differentiable, you need to have an instance of Function first
19:01:14 <enthymene> Saizan: really, it's not?  I've been toying with it a lot; seems useful
19:01:34 <enthymene> copumpkin: yeah, in my own code I'm trying to capture the notion of differentiable functions
19:01:55 <copumpkin> note that it's saying a _type_ is differentiable
19:02:44 <enthymene> for instance, if you have a numeric function that you can evaluate numerically, and get its derivative, but can't manipulate directly, you can reconstruct it with things like newton's method
19:02:54 <chrisdone> interactive tutorial! http://tryhaskell.org/ comments, bugs, suggestions, welcome
19:03:00 <enthymene> that's not a particularly useful one, though
19:03:15 <enthymene> anyway.  Game night tonight, time to go get food
19:03:18 <copumpkin> chrisdone: omg, you have a starburst
19:03:25 <chrisdone> haha
19:03:44 <aavogt> chrisdone: so no luck with pretty printing the results?
19:03:57 <stevenmarky> nice, you fixed the scrolling issue.
19:04:08 <chrisdone> aavogt: haven't got round to pretty printing errors yet =)
19:04:27 <chrisdone> stevenmarky: mhm ^_^
19:04:37 <aavogt> I mean like  [1..100] should be allowed to take a couple lines
19:04:39 <Saizan> enthymene: typeclasses are indeed useful for some things, they just aren't as needed as one coming from OO would think
19:04:51 <chrisdone> aavogt: ahh, sorry. yeah, that's on my list
19:05:06 <copumpkin> chrisdone: I like it, but the whole thing tends to extend fairly far vertically. On my 1280x800 macbook air I pretty much always have a scrollbar
19:06:04 <chrisdone> copumpkin: I could reduce the console size and the line spacing, hang on
19:06:11 <copumpkin> chrisdone: you have a typo about your nemesis: http://snapplr.com/afc8
19:06:17 <copumpkin> it's pretty nice though
19:06:27 <chrisdone> copumpkin: you're not reading properly :p
19:06:34 <chrisdone> copumpkin: the nemesis is the reverse "yourname"
19:06:35 <chrisdone> :D
19:06:40 <copumpkin> oh, yeah
19:06:48 <copumpkin> :)
19:06:49 <chrisdone> your evil twin!! :o
19:07:00 <copumpkin> damn!
19:08:04 <Saizan> aw, no import?
19:08:08 <Saizan> nor let
19:08:35 <chrisdone> not yet. I've conveniently stepped around that in the tutorial :p
19:08:43 <copumpkin> it would need to maintain session state per connection
19:08:45 <copumpkin> for that
19:08:51 <chrisdone> indeed
19:08:51 <copumpkin> sounds like it'd make things a lot more complicated
19:09:36 <chrisdone> more complicated server side yeah, but not hard
19:09:47 <carnieri> chrisdone: great job! how many hits have you been getting?
19:10:40 <chrisdone> carnieri: had about.. 1,039 individual hits in four days
19:11:20 <chrisdone> ^_^
19:17:26 <stevenmarky> chrisdone> I think pressing up should repeat the previous command
19:18:14 <chrisdone> stevenmarky: it does!
19:18:23 <chrisdone> stevenmarky: what browser are you using?
19:18:53 <stevenmarky> oh it does in IE, but not chrome
19:18:59 <copumpkin> pressing the down arrow takes me to the last command too
19:19:02 <copumpkin> which is weird
19:19:16 <stevenmarky> in chrome it lists a command but not the previous one
19:20:07 <gwern> chrisdone: how are you safely evaluating?
19:21:17 <copumpkin> coweval
19:21:36 <chrisdone> gwern: it uses mueval but keeps the interpreter session open in a forever loop
19:21:58 <gwern> chrisdone: hm. interesting. that lets you build up state I take it?
19:22:15 <gwern> or are you just trying to avoid the startup cost?
19:22:34 <chrisdone> gwern: just trying to avoid start-up cost. it would take 500ms on my machine per mueval invocation
19:22:40 <MaciejP> Can you force GHCi to reload all modules, even if unchanged?
19:22:57 <gwern> yeah, I know it's pretty slow. but ghc just isn't trustworthy with jsut one process
19:23:45 <chrisdone> yeah. so I just let it start up and do its thing once, and when it dies from error restart it
19:23:51 <gwern> unfortunately
19:24:08 <gwern> chrisdone: restart it?
19:24:35 <chrisdone> gwern: like from sigkill, I mean start a new one (from the web service point of view)
19:24:46 <gwern> I was about to say, unless you've hacked mueval a fair bit, the one-shot eval is pretty buitl in
19:26:41 * gwern is impressed by how much better 7zip is than gzip
19:27:32 <lament> i'm impressed by how gzip is still used despite being inferior to pretty much everything
19:27:54 <gwern> nah, bzip is even worse
19:27:58 <Draconx|Laptop> depends on how you define inferior.
19:29:07 <gwern> of course it does
19:31:02 <dark> lament, gzip *is* better when you want to do on-the-fly decompression
19:31:11 <dark> or, at least, in my machine :t
19:31:34 <djahandarie> I used quantum compression algorithms
19:32:02 <dark> hmm? :)
19:32:52 <djahandarie> It is exponentially faster than any other algorithm!
19:33:10 * copumpkin uses kolmogorov compression!
19:33:15 <chrisdone> exponentially faster?
19:33:26 <copumpkin> factorially faster!!!
19:33:30 <MissPiggy> uncomputable awesome
19:33:35 <MissPiggy> ly*
19:33:42 <copumpkin> yep
19:35:32 <p_l> ... some more and someone might dig up "backup into network traffic" scheme
19:35:33 <gwern> wait, is factorial faster than exponentially?
19:35:36 <gwern> that doesn't suond right
19:35:47 <p_l> gwern: factorial is faster, iirc
19:35:56 <copumpkin> yep
19:36:03 <MissPiggy> O(n!) = O(n^n) doesn't it?
19:36:11 <p_l> MissPiggy: no
19:36:43 <pikhq> n! = n*(n-1)*(n-2)*...*3*2
19:36:45 <gwern> n^n would be larger, no? because it'd be, n*n*n*n... vs. n*n-1*n-2*n-3...
19:37:02 <MissPiggy> gwern but in terms of asymptotic behavior?
19:37:18 <p_l> gwern: exponential is constant^n iirc
19:37:22 * gwern shrugs. asymptotes are hard
19:37:36 <ddarius> One could calculate from the definition...
19:37:51 <copumpkin> by stirling's approximation it is closest to n^n, I think
19:37:53 <gwern> one couldnae be fashed.
19:38:04 <copumpkin> it's obviously smaller at any given point, but grows at the same rate
19:38:30 <djahandarie> I like how I can say any little thing about any computer science related topic in here and it explodes into some giant conversation.
19:38:48 <copumpkin> djahandarie: we're a bunch of CS and math nerds, what do you expect?
19:38:52 <aavogt> are there any Cabal hackers around? I've made some changes but I can't convince my current ghc to use the updated Cabal
19:38:57 <aavogt> do I have to recompile ghc?
19:39:01 * MissPiggy like show people come in here and mention interesting things
19:39:22 <copumpkin> djahandarie: not only do we like talking about this stuff, but we're all secretly trying to prove that we know what the others are talking about by introducing new (if only partially relevant) information
19:39:38 <copumpkin> oh crap, maybe that's just me
19:40:22 <djahandarie> The Law of Factorially Increasing Discussion and Proportionality to Social Status
19:40:23 <gwern> aavogt: need moar detail
19:40:44 <chrisdone> would adding quickcheck to tryhaskell freak newbies out?
19:40:44 <chrisdone> like, "give me a function that doubles all the numbers in a list" and then it runs quickcheck on it and tells them if their implementation is good
19:40:49 <gwern> copumpkin: secretly? I've never made any bones of being a dilettante
19:41:31 <gwern> chrisdone: sounds good to me - shouldn't you be checking solutions for correctness anyway? but for simple numeric/list problems might be better to use smallcheck so you really get the smallest counterexample
19:41:39 <aavogt> gwern: I've done something to Distribution.Simple.GHC which may address this: http://hackage.haskell.org/trac/hackage/ticket/89#comment:26
19:42:06 <gwern> chrisdone: plus smallcheck would fail faster
19:42:09 <aavogt> but installing the new cabal doesn't seem to be enough
19:42:12 <gwern> I assume turnaround is important
19:42:34 <chrisdone> gwern: indeed that's true. thanks I hadn't heard of smallcheck
19:43:07 <gwern> the properties testing triumvirate: quickcheck, smallcheck, and lazy smallcheck. not that people use the latter 2 very much
19:43:08 <aavogt> gwern: can you help me?
19:43:31 * gwern points up. what part of 'dilettante' don't you understand? SPEAK ENGLISH
19:43:41 <chrisdone> try ruby doesn't test your implementations. so I guess if I add this I'll actually be doing something original :p
19:44:26 <dolio> If you try to expand out that factorial, you get something like: O(n^n - n^(n-1) + n^(n-2) - ...)
19:44:38 <dolio> Then you have to decide whether you throw away those lesser terms.
19:45:29 <gwern> (see, the joke is 'dilettante' is etymologically foreign - latin)
19:46:07 <mm_freak> aksionov: you're welcome…  thanks for the feedback =)
19:46:13 <mm_freak> aksionov: you're welcome…  thanks for the feedback =)
19:46:21 <aksionov> mm_freak: :)
19:46:32 <mm_freak> uhm, yeah…  one time should be enough =)
19:46:41 <djahandarie> gwern, looks like you are actually a lingustics fanatic
19:46:48 <MissPiggy> dolio interesting!
19:47:38 <gwern> djahandarie: I is proud of my vocab
19:47:44 <aavogt> so the problem could be seen as proving the existence of:  lim n->inf (n! / n^n)
19:48:14 <aavogt> err, flip the fraction
19:48:29 <djahandarie> aavogt, by definition, in fact.
19:49:04 <dolio> Well, Stirling's approximation says that ln (n!) = n ln n - n + O(n).
19:49:23 <djahandarie> Oh shit, haven't gotten this far in my math courses yet LOL
19:50:00 <dolio> Which implies that ln (lim n -> inf (n^n / n!)) exists, I think.
19:50:27 <cads> n!  = 1*2*...*n, while n^n, n*n*n*...*n, so that limit should be zero, I think
19:50:53 <djahandarie> I don't know why I'm so bad at math anyways while I excel with computer science.
19:51:07 <necroforest> you won't see sterling's approx in a math class
19:51:12 <necroforest> i've only seen it in CS classes
19:51:20 <necroforest> data structures/algorithms
19:51:28 <aavogt> I've seen it in stats
19:51:30 <necroforest> well, i take that back, i think i did see it in a probability course
19:52:07 <aavogt> gwern: do you need yet moar details?
19:52:08 <p_l> btw, exponential growth is k^x, not n^x, where k - constant; x - x axis value;
19:52:47 <gwern> aavogt: I've read through it. I don't see any obvious easy solution. seems to involve fiddling inside cabal
19:53:37 <aavogt> gwern: well my problem is that I can't test my change (which should fix it)
19:54:23 <cads> you can write  n!/n^n = (n-1)!/n^(n-1) = (n-2)!/n^(n-2) * (n-1)/n, and the second factor of that product clearly diverges, and you can get the other parts by induction
19:54:57 <MissPiggy> diverges??
19:55:00 <cads> doh
19:55:22 <cads> converges*
19:55:37 <MissPiggy> oh okay
19:55:46 * MissPiggy worried
19:56:09 <MissPiggy> so then it is the case that O(n!) is the same as O(n^n)?
19:56:44 <dolio> ln (lim n->oo (n^n / n!)) = lim n->oo (n ln n / (n ln n - n + O(n))) =l'hopital= lim n->oo ((ln n + 1) / (ln n - 1)) = 1.
19:56:48 <cads> I'm not too clear on big oh, I think O(n!) = O(n log n)
19:57:33 <dolio> Wait, that's not right.
19:57:47 <MissPiggy> cads, see I thought quicksort was n log n :P
19:57:54 <MissPiggy> cads, but permutation sort would be n!?
19:57:56 <aavogt> what's the derivative of O(n)? O(1)?
19:58:28 <MissPiggy> woah
19:58:33 <MissPiggy> you can take derivatives of O(-)?
19:59:19 <aavogt> well the notation means a fixed arbitrary constant times the term on the inside
19:59:58 <dolio> ln (lim n->oo (n^n / n!)) = lim n->oo (n ln n - (n ln n - n + O(n))) = lim n->oo (n - O(n)).
20:00:03 <copumpkin> aavogt: not just that
20:00:04 <dolio> Which looks inconclusive.
20:00:14 <aavogt> copumpkin: what else?
20:00:28 <copumpkin> aavogt: O(n^2) might be 5n^2 + 3n - 1
20:00:38 <copumpkin> not just a constant coefficient
20:01:12 <copumpkin> it also may be log n
20:01:36 <cads> big o means that a function is eventually bound above by some element of a class of functions, I don't think you'd be able to say much about the derivative of the original function, plus the function's derivative can easily be unbounded, no?
20:02:53 <dolio> I guess the more relevant approximation is: lim n->oo n!/(sqrt(2*pi*n)*(n/e)^n) = 1.
20:03:06 * copumpkin wishes he had a latex IRC client
20:03:12 * MissPiggy too!
20:03:17 <augur> copumpkin: ditto
20:03:21 * cads would worry about viruses
20:03:21 <augur> maybe you should write it!
20:03:24 <augur> in haskell! :D
20:03:27 <copumpkin> hah
20:03:39 <aavogt> at least pidgin has a plugin
20:03:43 <cads> using sandboxing techniques from miss lambabot!
20:04:14 <augur> Adium presumably has a plugin
20:04:17 <augur> but it doesnt work right
20:04:23 <augur> adium is a fucking mess, it really is
20:04:33 <cads> The third equation here shows us why n! is actually Big-Theta(n log n): http://en.wikipedia.org/wiki/Factorial#Rate_of_growth
20:04:34 <aavogt> copumpkin: hmm, I think since we're talking about the asymptotes I don't think that still matters
20:04:54 <copumpkin> aavogt: it doesn't! I was just pointing out an issue with your definition :)
20:05:20 <copumpkin> cads: nope
20:05:29 <copumpkin> it shows us why log n! is big-theta(n log n)
20:05:31 <aavogt> if we can trust [22:48:09]  djahandarie | aavogt, by definition, in fact.,  then I think my statement is equivalent to l'Hopital's rule
20:06:00 <copumpkin> aavogt: ?
20:06:08 <cads> ph
20:06:10 <djahandarie> aavogt, you can't trust anything I say!
20:06:21 <cads> log n! is O(n log n)
20:06:34 <MissPiggy> n! is actually Big-Theta(n log n)??
20:06:39 <copumpkin> no
20:06:42 <djahandarie> log n!
20:06:50 <cads> sorry for the misinformation!
20:06:54 <copumpkin> :)
20:07:35 <copumpkin> one thing I've wondered: http://snapplr.com/w3k8
20:07:46 <djahandarie> aavogt, only reason I said that is because BigO is an asymptotic analysis towards infinity, so I suppose that would be the definition
20:07:52 <copumpkin> oh wait, nothing
20:08:08 <cads> MissPiggy, I was working on a problem a while back which involved log_2 (n!) and I confused the result
20:08:59 <aavogt> copumpkin: as in saying   g(n) = O(f(n))  is that this exists: lim (n -> inf) ( g(n) / f(n) )
20:09:24 <copumpkin> sure,
20:09:25 <djahandarie> Hmmm
20:09:36 <copumpkin> I was just saying that your definition that it's a constant times what's inside the O(-) wasn't right :P
20:09:37 * aavogt should probably think about stuff before saying it though
20:10:06 <aavogt> anyways, I want to test cabal and nobody is helping me!
20:10:34 <djahandarie> aavogt, little did you know that we have been trying to move the conversation away from helping you this whole time!
20:10:48 <djahandarie> It's all a conspiracy!
20:11:38 * aavogt is also guilty
20:13:51 <copumpkin> does the caption on http://snapplr.com/50gc look strange to anyone?
20:15:52 <FauxFaux> Sounds like scary maths, copumpkin.
20:16:22 <MissPiggy> is that gamma?
20:16:42 <MissPiggy> I heard you can "analytically" by the factorial recurrence extend i to negatives ?
20:16:56 <copumpkin> it's gamma shifted by 1
20:17:02 <copumpkin> to coincide with factorial
20:17:08 <MissPiggy> sure
20:17:22 <copumpkin> my issue was with the caption saying "complex numbers"
20:17:40 <copumpkin> since that's just plotting the those on the real line
20:17:40 * MissPiggy didn\t really read it XD
20:21:19 <dons> :D
20:21:22 <dons> llvm is smart :)
20:21:26 <copumpkin> yeah?
20:21:34 <dons> yeah, and pretty easy in the end.
20:21:43 <dons> it says i just need:
20:21:44 <dons> -fllvm -optlo-O2 -optlo-globalopt -optlo-mem2reg -optlo-prune-eh
20:21:53 <dons> and that's enough to fold the loop to a constant
20:21:58 <dons> yay for SCIENCE!
20:22:03 * dons looks at the asm
20:22:30 <dons> i was concerned when the fitness no. fell to 0.00
20:22:31 <dolio> The 'sum [1..1billion]' one?
20:22:34 <dons> yeah
20:22:40 <dons> llvm got it!
20:22:47 <copumpkin> :)
20:22:47 <dolio> Nice.
20:24:26 <dons> it removed the loop
20:24:49 <dons> it drops the limit value into a register, and multiplies and shifts it a couple of times
20:24:51 <dolio> That'll make our very unrealistic programs much faster.
20:24:54 * dons ponders
20:25:07 <dons> dolio: well it means that ghc -O2 + llvm -X -Y can match gcc -O3
20:25:13 <dons> on C code.
20:25:38 <dons> and llvm in general is a) fun  b) viable
20:25:55 <dolio> Yeah, that's good news.
20:26:02 <cads> dons: does it automatically figure out the formula for that sum?
20:26:16 <dons> btw, it says the best combination of flags is: -Odph -O2 -funbox-strict-fields -fllvm -optlo-O2 -optlo-disable-inlining -optlo-enable-load-pre -optlo-basicaa -optlo-domfrontier -optlo-instcount -optlo-codegenprepare -optlo-abcd -optlo-die -optlo-dse -optlo-globaldce -optlo-globalopt -optlo-indvars -optlo-inline -optlo-instcombine -optlo-internalize -optlo-ipconstprop -optlo-lcssa -optlo-loop-rotate -optlo-loop-unswitch -optlo-mem2reg -optlo-memcpyopt 
20:26:28 <dolio> Wow.
20:26:31 <dons> cads: basically, yes.
20:26:37 <FauxFaux> I assume that got cut off by irc. :p
20:26:42 <dons> dolio: there's no-ops in there though. i need to run it longer to remove extras
20:26:49 <dons> FauxFaux: no, that's it.
20:27:05 <dons> so now to derive what passes i *actually need* to get the loop to dissolve
20:27:30 <pikhq> So, doesn't get flags automatically passed to "opt"?
20:27:42 <dons> ?
20:28:30 <dons> this is weird code. it didn't reduce it to a constant
20:28:43 <pikhq> Looks like you're having to do a lot of "telling LLVM to do sane optimisations".
20:28:46 <dons> it reduced it to an expression of straight line shifts and multilies
20:29:14 <dons> pikhq: right
20:29:24 <dons> pikhq: but in this case: i had a program work out what flags to pass
20:29:56 <pikhq> Mmm.
20:30:45 <dons> llvm is good, but its got such a large optimization surface, it will be hard to find optimal settings
20:31:57 <dolio> That's one thing that I wonder about. Yes, they work on all sorts of optimizations, but do they work on identifying the right opportunities for optimizations of code generated from a Haskell-like language?
20:32:11 <pikhq> Probably not yet.
20:32:30 <dons> it definitely found flags for my haskell program that are better than the defaults.
20:33:07 <dons> i'd like to first have an llvm binding for writing plugins in haskell, and b) adding plugins for the kind of llvm code we get from C--.
20:33:40 <pikhq> There's an LLVM binding for writing functions in Haskell.
20:34:47 <dons> right, but not for writing llvm optimization plugins
20:34:58 <Saizan> then there's also the problem of running the optimizations in the right order, i guess?
20:35:01 <dons> we should be able to write our own llvm *passes* in haskell.
20:35:05 <dons> Saizan: yes!
20:35:16 <djahandarie> LLVM is cool
20:35:20 <dons> my little app only tries each pass once
20:35:59 <dons> so the flags it found that helps are: -loop-unswitch -mem2reg -globalopt
20:36:39 <dons> which are: "transforms loops that contain branches on loop-invariant conditions to have multiple loops"
20:37:03 <dons> "promotes memory references to be register references."
20:37:16 <dons> "transforms simple global variables that never have their address taken."
20:37:29 <dons> ah, that might help with the loop constants
20:38:08 <carnieri> dons: how did you find out which ones of all those flags were actually helping?
20:38:38 <dons> well, i have a genetic algorithm library that's searching.
20:38:41 <dons> and the results are:
20:38:41 <dons>        Acovea's Common Options:                                                       (0)
20:38:45 <dons>            -optlo-O3 -optlc-O3: ********************                                  (0.048)
20:38:48 <dons>                          -fasm: **************************************************    (0.118)
20:38:54 <dons> so -fasm took 118 ms, while the default llvm flags took 48ms
20:39:03 <dons> but with enough llvm flags, it turned into a constant function
20:39:11 <dons> 0ms :)
20:39:24 <dons> took 4.5 hrs to find
20:39:28 <pikhq> Mmm, Acovea.
20:39:45 <copumpkin> how about a more complicated function? dot product, or maybe a matrix mult?
20:39:50 <copumpkin> maybe in DPH :o
20:39:54 <dons> yeah, now i know it works, i'll try some more things
20:40:07 <djahandarie> dons, what is this thing that you are using?
20:40:18 <dons> i hope to find a better set of flags to use by default in ghc's llvm backend, than just -O3
20:40:40 <dons> djahandarie: same approach as this, http://donsbot.wordpress.com/2009/03/09/evolving-faster-haskell-programs/
20:40:48 <dons> but for llvm flags, not inlining flags
20:40:56 <djahandarie> Ooh, interesting.
20:42:31 <dons> looks like -optlo-globalopt is enough, in fact.
20:43:14 <copumpkin> enough for everything?
20:43:21 <dons> to clean up the loop
20:43:32 <dons> so ghc -Odph -fllvm -optlo-O2 -optlo-globalopt
20:43:53 <dons> ultimately, i need to try this on all of nofib, and let it work out the best set for all programs
20:43:55 <djahandarie> Think that could cause any degradation?
20:44:07 <dons> http://llvm.org/docs/Passes.html#globalopt
20:44:25 <dons> probably a good thiing for haskell code: lots of global constants
20:44:47 <dons> ghc just imported 20 years of imperative compiler research
20:45:19 <djahandarie> Yeah, the stuff they have in here is actually pretty interesting.
20:46:12 <dons> all the low level optimizations we needed
20:46:18 <djahandarie> dons, do you think hooking into LLVM is the better path to take?
20:46:28 <dons> well, we've done it now
20:46:33 <dons> i think it's a good idea.
20:47:21 <edwardk> the llvm back end for ghc is a ridiculously good idea
20:49:15 <ddarius> Hopefully the LLVM folk will take the equality saturation ideas.
20:49:33 <ddarius> Otherwise, I still think Hoopl and co. have more potential.
20:50:39 <dons> we've basically bet on LLVM over C-- now,  (literally translating C-- to LLVM)
20:50:51 <dons> after the cmm compilers were outmatched by llc
20:52:07 <pikhq> Yeah, LLVM is really quite impressive.
20:52:31 * MissPiggy dosen't undesrtand LLVM enough to be impressed by it
20:52:39 <MissPiggy> it's like the best complier or something?
20:52:51 <Gracenotes> things like LLVM are kind of rare
20:53:13 * ddarius wishes LLVM was LLer.
20:53:20 <dons> MissPiggy: lots of reusable compiler components for low level optimizations
20:53:32 <Gracenotes> if you're going to spend all the time to write a great code generator, why not just go out and write a compiler?
20:53:48 <pikhq> MissPiggy: LLVM is a virtual machine designed to be used as a compiler backend.
20:53:50 <dons> basically, an implementation of Muchnick's book, as a library.
20:54:03 <Gracenotes> but LLVM stops at great code generator
20:54:05 <pikhq> It functions as a really good code generator that any compiler can just plug into.
20:54:08 <dons> we don't use it as a vm though. but as a suite of C--_level compiler optimizations
20:54:25 <dons> and turns out it does a better job on ghc's code than gcc ever did
20:54:30 <dons> as well as being more programmable
20:54:48 <MissPiggy> and it's the best optimizer?
20:55:15 <Gracenotes> yeah, there's a formal proof somewhere that it's the best optimizer anywhere in the history of everywhere
20:55:22 <pikhq> It appears to be one of the best free code generators out there ATM.
20:55:55 <dons> yep. that's been proven, MissPiggy
20:55:58 <pikhq> And unlike GCC, anything can use it quite readily.
20:57:53 * MissPiggy scowls at Gracenotes
20:58:10 <Gracenotes> @slap Gracenotes
20:58:10 * lambdabot puts on her slapping gloves, and slaps Gracenotes
20:58:21 <ddarius> -,
20:58:26 <edwardk> dons: heh i never made the connection to muchnik's book. nice observation
20:58:53 <MissPiggy> so how about something really trivial like a lambda calculus to LLVM
20:59:08 <edwardk> MissPiggy: i think lennart might have blogged something like that
20:59:19 <MissPiggy> and how does that differ from haskell to LLVM?
20:59:32 <edwardk> http://augustss.blogspot.com/
20:59:43 <luqui> Was "non-stop Haskell" ever implemented; i.e. an incremental GC that doesn't have to stop the world?
20:59:54 <MissPiggy> lol I did cabal install LLVM and is says:
20:59:54 <MissPiggy> Generating and compiling a zillion numerical type aliases, this might take a while
21:00:22 <ddarius> luqui: Yes.
21:00:34 <MissPiggy> can we make non-stop haskell using LLVM?
21:00:41 <luqui> ddarius, huh, does it have to be enabled?  I'm getting weird pauses...
21:00:43 <bos> hey dons, interesting stuff here.
21:00:51 <Gracenotes> @hackage LLVM
21:00:52 <lambdabot> http://hackage.haskell.org/package/LLVM
21:00:54 <ddarius> luqui: It was a branch that was never merged into the trunk.
21:01:05 <Gracenotes> okay, needs lower case
21:01:12 <bos> dons: the crazy hand-bummed C HTTP parser at http://github.com/ry/http-parser/ is only a little over 2x faster than my combinator-based one
21:01:13 <luqui> aww, too slow or something?
21:01:22 <ddarius> luqui: More or less.
21:01:28 <edwardk> luqui: seems to be the fate of most things that are too invasive =/
21:01:36 * bos is mildly blown away by this
21:01:49 <copumpkin> bos: very nice!
21:02:02 <pikhq> bos: And yours is probably *readable*.
21:02:04 <djahandarie> It's cool when Haskell makes everything fast
21:02:07 <copumpkin> is that one known for being fast?
21:02:17 <djahandarie> You don't even need to ask!
21:02:23 <copumpkin> I mean, the c one
21:02:37 <edwardk> copumpkin: its main claim to fame was that it had a very tight bound on space usage so it could be used embedded
21:02:37 <luqui> well they are just minor skips for now... i really hope it doesn't get worse.  that would be a showstopper for a game :-(
21:02:46 <copumpkin> ah, I see
21:02:48 <copumpkin> wow, http://snapplr.com/62h7
21:02:56 <copumpkin> gotta love lookup tables
21:03:01 <djahandarie> haha copumpkin
21:03:21 <djahandarie> Do you have some screen grabbing thing that automatically uploads to snapplr? :P
21:03:28 <copumpkin> that's what snapplr is :)
21:03:34 <djahandarie> Oh. 8-)
21:03:39 <bos> pikhq: yeah, mine is 54 lines long, vs 1650 for the C version
21:03:43 <edwardk> luqui: i wound up giving up on using haskell for game stuff, because i couldn't deal with random starts and stops from GC. ryan trinkle is using haskell in some stuff, but they are just using it for logic/ai, and run their rendering and ui in c/c++.
21:03:50 <copumpkin> press a key combo, get a cursor to draw the region you want to snapshot, it puts url into clipboard
21:03:51 <bos> pikhq: granted, the other one does a bit more than mine right now
21:03:52 <pikhq> bos: Hah.
21:03:54 <djahandarie> OS X. ~.~
21:03:55 <Gracenotes> memory lookup probably faster than bounds check+arithmetic, really
21:04:00 <bos> pikhq: but only a bit
21:04:09 <Gracenotes> by a few nanoseconds
21:04:23 <edwardk> bos: yeah, but how is your memory usage?
21:04:44 <bos> i believe that jaffacake has plans for a proper concurrent/incremental GC at some point
21:04:55 <bos> edwardk: i can parse a 200MB file in 500KB of heap
21:05:01 <djahandarie> Parallel GC! >=D
21:05:04 <copumpkin> 200MB of HTTP?!?
21:05:16 <bos> copumpkin: 200MB of HTTP requests
21:05:16 <MissPiggy> that doesn't seem that much these days
21:05:17 <luqui> edwardk, huh.  well giving up early due to an unsubstantiated fear is one of the antigoals of this project.
21:05:21 <copumpkin> ah
21:05:27 <luqui> I wonder what could be done to remedy the situation
21:05:46 <edwardk> bos: marlow popped up (on haskell_proposals i think?) asking if someone would want to implement immix gc.
21:06:12 <edwardk> luqui: well, in their case they started entirely in haskell, but gave up because the gc pauses just shut down their gameplay.
21:06:16 <Gracenotes> bos: just requests? does that include multipart/form-data of really large files?
21:06:22 <bos> Gracenotes: not yet
21:06:32 <Gracenotes> 200MB of requests o_o
21:06:45 <bos> Gracenotes: goal #1 was to bum the holy heck out of what i have right now, without losing focus.
21:06:50 <djahandarie> Ooh, immix looks cool
21:06:52 <luqui> edwardk, my first instinct would be to do what they did.  but I wonder how to minimize the amount of non-haskell...
21:06:57 <luqui> maybe a DSL to generate gameloop code?
21:07:02 <edwardk> bos: ok, so 500k is a bit more than 136 bytes ;)
21:07:21 <luqui> if it could be sufficiently specified and we don't just end up creating "the C generation DSL" which would not really be a win...
21:07:27 <edwardk> luqui: a game-dev oriented equivalent of "atom"?
21:07:37 <luqui> yeah something like that
21:08:12 <Gracenotes> hm - http://www.mail-archive.com/cvs-ghc@haskell.org/msg13418.html .. that was for last summer
21:08:14 <luqui> the thing is that we certainly want *some* of the runtime to be in Haskell... otherwise we are just using Haskell syntax in C.
21:08:28 <Gracenotes> heh, exactly a year+3 days ago in fact
21:08:35 <Gracenotes> regarding the immix gc
21:09:11 <MissPiggy> can I compile a standalone binary using llvm?
21:09:11 <edwardk> luqui: i've been looking at using haskell to automatically generate shader combinations for a toy 3d engine which uses deferred shading. building the uber-shader by hand is tedious.
21:09:22 <MissPiggy> like write a compiler in haskell which turns the input into a binary
21:09:23 <bos> edwardk: yeah, but 500K is the entire haskell runtime heap, not just my little narrow thing.
21:09:46 <edwardk> bos: fair nuff
21:09:54 <copumpkin> what is the fixed memory overhead of the haskell runtime?
21:09:54 <bos> edwardk: i'm sure i'm above 136 bytes, but i also don't have a shitty API :-)
21:10:08 <edwardk> bos: =)
21:10:13 <jkingkong> hi, i am trying to figure out the levmar package (nonlinear curve fitting)
21:10:28 <jkingkong> but my haskell's not good enough to understand some of the typing going on
21:10:32 <edwardk> MissPiggy: yes.
21:10:40 <edwardk> MissPiggy: there is an llvm standalone assembler
21:10:43 <bos> copumpkin: i don't know.
21:10:48 <MissPiggy> cool
21:10:50 <luqui> this is really annoying... i wish that incremental gc branch would have been optionally in there.  I could take a speed hit (I have made games in pygame, after all), but pauses suck
21:11:07 <jkingkong> http://hackage.haskell.org/packages/archive/levmar/0.2.1/doc/html/LevMar-Fitting.html#t%3AModel
21:11:17 <luqui> given the date on that paper, the divergence is probably too high.  i guess I could look.
21:11:18 <jkingkong> what do 3 colons in succession mean?
21:11:23 <jkingkong> ':::'
21:11:34 <MissPiggy> jkingkong it's just a type level operator
21:11:38 <edwardk> luqui: you could always manually call into System.Mem.performGC every frame to force it to take smallish steps
21:11:54 <bos> if your heap is big enough, you'll lose.
21:11:56 <MissPiggy> jkingkong so it could be caleed x :&: y of x ::: y instead of With x y, but they chose to use :::
21:12:02 <luqui> edwardk, does that work?  eventually it will have to do a generation 0 collection
21:12:06 <bos> calling performGC often is a great way to do nothing but GC.
21:12:18 <edwardk> luqui: depends on the size of your overall heap.
21:12:21 <aavogt> MissPiggy: looks like a regular constructor to me
21:12:41 <edwardk> bos: true nuff
21:13:01 <jkingkong> type level operator ok i'll do some reading
21:13:10 <tomberek> so, i've got a Foo a b... I want both Foo a AND Foo b to be comonads...  though in reality, i just want (i think) a dependency a->b so Foo by itself can be the comonad.
21:13:12 <MissPiggy> jkingkong oh no it's a value lvel operator
21:13:21 <bos> if you turn on GC in criterion via -g, for instance, you get much smoother runs with much less GC-induced noise, but runs take about 20x as long to perform.
21:13:25 <copumpkin> it could be either (or both), I think
21:13:26 <tomberek> thoughts?
21:13:32 <jkingkong> misspiggy ok thanks
21:13:41 <edwardk> tomberek: what is the comonad in question?
21:13:41 <luqui> tomberek, very hard to say without more info
21:14:08 <tomberek> Pointer
21:14:19 <tomberek> rather, copointed
21:14:23 <Gracenotes> 20x... that's a constant we can take, right? o-o
21:14:24 <jkingkong> misspiggy hmm i'm not familiar with the term and it isn't on zvon http://www.zvon.org/other/haskell/Outputglobal/index.html
21:14:45 <edwardk> So, the Pointer i a comonad from sigfpe's blog/category-extras?
21:15:12 <edwardk> and you want to be able to 'extract' the index?
21:15:36 <edwardk> as well as the currently targeted value?
21:15:39 <aavogt> jkingkong: you know how you can create and take appart lists with : ?
21:15:51 <tomberek> edwardk: sort of,, the index is parametric with both a and b
21:15:56 <jkingkong> aavogt yea it pulls the head of the list out
21:16:10 <tomberek> basically, i have no problem with the functions, it's the kinds that are giving me issues
21:16:22 <aavogt> in this case the library has defined a constructor `:::' for some other data type
21:16:23 <edwardk> tomberek: the problem is that Pointer i a isn't a Hask Comonad in i. the index i is subject to a constraint.
21:16:39 <jkingkong> aavogt oh i see it's not a standard operator
21:16:48 <edwardk> the only valid types i can take on are instances of Ix
21:17:09 <tomberek> well, it's not exactly Pointer
21:17:16 <edwardk> so at best Pointer i a is a restricted comonad in i. you can't map it.
21:17:38 * MissPiggy wants to do a compiler with llvm but not sure what language
21:17:41 <jkingkong> aavogt gosh this library is the hardest i've tried to use ever
21:17:47 <jkingkong> :P
21:18:10 <MissPiggy> jkingkong -- I know the feeling I had this with a libaraly other day..
21:18:11 <edwardk> tomberek: how does yours differ then?
21:18:33 <tomberek> simplified:: data Foo a b = Foo [(a,b)]
21:19:11 <tomberek> because I need Foo to be of kind *->*->*... but then comonads need it to be *->*
21:19:25 <edwardk> well, you'll need at least something like newtype Flip f a b = Flip { unFlip :: f b a } to define the second comonad.
21:19:26 <jkingkong> misspiggy haha thanks i'll plug through tonight and all tomorrow probably
21:19:43 <jkingkong> misspiggy i have some data that's the superposition of three poisson distributions and a constand
21:19:51 <edwardk> and you can then define an instance Comonad (Foo a), and an instance Comonad (Flip Foo a)
21:19:57 <MissPiggy> jkingkong: I wish you good luck it's all I can do :)
21:19:58 <jkingkong> misspiggy and i'm trying to extract a parameter with this nonlinear fit
21:20:05 <jkingkong> misspiggy thanks!
21:20:17 <tomberek> edwardk:  yeah,, that way I can make Foo a and Foo b 'comonad-able'
21:20:30 <MissPiggy> jkingkong, one thing that migh be useful is check if the library comes with examples or tests sometimes they can explain how to use it
21:20:38 <edwardk> another option is to use Control.Comonad.Parameterized
21:20:47 <dons> bos: excellent.
21:20:51 <tomberek> edwardk: let me read up on that.. one sec
21:20:52 <dons> we can find a 2x factor somewhere.
21:20:55 <edwardk> and define Foo to be both a "PComonad" and a Comonad
21:21:00 <edwardk> http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/Control-Comonad-Parameterized.html
21:21:04 <jkingkong> misspiggy i'm trying to read their demo file
21:21:25 <edwardk> tomberek: i defined it a long time ago, but it doesn't get much use except as a way to build up the cofree comonad in a way that scares the hell out of people
21:21:33 <jkingkong> misspiggy it seems more like a demonstration of its capability that a tutorial unfortunately
21:22:03 <tomberek> edwardk: close, it might work
21:22:13 <edwardk> with that you can define Foo quite naturally as a Bifunctor, define it as a comonad in its right hand argument, a pcomonad so you can pextract its left hand argument
21:22:23 <edwardk> and you can pextend or extend as needed
21:22:30 <MissPiggy> jkingkong sometimes it almost feels like revers engineering to use a libarrly
21:22:33 <edwardk> ideally you'd rather have a more robust extension
21:22:37 <tomberek> edwardk: is there something like, pextract :: f a c -> a c  ?
21:23:07 <copumpkin> f (a c) -> a c ?
21:23:11 <edwardk> tomberek: a higher order extract: http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/Control-Comonad-HigherOrder.html
21:23:24 <edwardk> check out hextract from there
21:23:56 <tomberek> edwardk: ah, i like it!  so you wrote the category-extras?
21:24:01 <edwardk> tomberek: yeah
21:24:31 <tomberek> edwardk: i'm using comonads for neural network evaluation
21:24:49 <edwardk> dave menendez had a few fragments of code for dealing with recursion schemes and a comonad definition, and i er, had a bout of OCD and ran with it for a few hundred modules.
21:24:57 <edwardk> tomberek: a pretty good fit
21:25:08 <tomberek> edwardk: each node is updated in the context of it's neighborhood
21:25:29 <edwardk> yep, the shape of the network doesn't change so its a reasonable comonad
21:25:42 <tomberek> edwardk: except for the problem that the fgl package defines graphs as gr a b (*->*->*) giving me issues
21:25:48 <edwardk> then you can run your backpropagation function as a comonadic action
21:26:43 <tomberek> exactly my thoughts... this is my first foray into haskell, and sometimes the type/kind system gives me problems
21:26:55 <Saizan> so you want to update both the edge and node labels with the comonad?
21:26:56 <edwardk> you may want to look at the hcomonad instances for Yoneda as an example
21:27:20 <edwardk> i'll warn you hextract is pretty deep for a first foray ;)
21:27:26 <Saizan> since you can still write instance Graph gr => Comonad (gr a) where -- acting on 'b'
21:27:29 <tomberek> Saizan: at the moment, just the node label, then the edge labels seperately.... but eventually both
21:27:50 <tomberek> Saizan: yes,, my previous draft did that
21:28:53 <tomberek> Saizan: or rather i flipped them with a new data type so essentially it was Comonad (gr b) acting on a
21:29:10 <edwardk> tomberek: and if you decide to stick with the simpler 'comonad in one parameter at a time' approach. Flip is already defined in category-extras: http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/Control-Functor-Combinators-Flip.html
21:29:54 * ddarius hugs parameterized representability.
21:30:01 <Saizan> i'm not sure if fgl's graph representation works so well as a comonad, since it stores the incoming and outgoing edges in the same map as the node labels
21:30:01 <tomberek> edwardk: but now i'm trying to get Graph gr => Comonad gr  in some way
21:30:26 <tomberek> edwardk: i didn't see the Flip, i just did it myself...oops
21:30:48 <edwardk> tomberek: no worries, its easy to miss
21:31:18 <tomberek> Saizan: perhaps you are right, but a graph can also be seen as a collection of 'Context a b'
21:31:38 <tomberek> that's the whole point of the fgl implementation
21:32:07 <tomberek> So i'd like to have a Comonad where the extract goes from Gr a b to Context a b
21:32:28 <Saizan> yeah, but for a comonad you don't want =>> to wonder if it has to change the structure of the graph
21:33:09 <tomberek> Saizan: hm... certain algorithms need it to
21:33:35 <edwardk> tomberek: i think that will fail here. that type you just gave isn't going to match any comonadic extract
21:33:36 <tomberek> Saizan: running some pruning via genetic algorithms will remove edges
21:34:13 <Saizan> tomberek: but those algorithms can't really be expressed with =>>, afaiu
21:35:48 <tomberek> can I make a newtype Context a b=... ? er, or something?
21:35:54 <edwardk> type Context a b = (Adj b, Node, a, Adj b) = ([(b, Node)], Node, a, [(b,Node)]) -- extract won't yield anything like that
21:36:35 <edwardk> not unless you are dealing with Foo (Context a b) -- but then you should be able to instantiate Foo Int -- as well, and extract an Int. -- otherwise what you're dealing with isn;t quite a comonad.
21:36:54 <Saizan> i think the laws say that in duplicate :: w a -> w (w a) the outer w wrapping has to have the same shape as the original, so to speak
21:37:22 <ezyang> yo
21:37:28 <tomberek> my attempt was to make a data NN a b = NN (Context a b) (Gr a b)
21:37:29 <edwardk> Saizan: that works as a good way to show the construction blowing up
21:38:29 <Saizan> blowing up?
21:38:47 <edwardk> tomberek: but now, instance Comonad (NN a) -- can at best extract a value of type b, not the Context a b you're looking for
21:39:17 <tomberek> then make instance Graph NN where  op (NN _ net)= op net... my plan was extract would be extract (NN node _)=node
21:39:56 <Saizan> tomberek: that extract won't match the types
21:40:14 <MissPiggy> Fib: user error (Unable to find target for this triple (no targets are registered))
21:40:17 <MissPiggy> :(
21:40:28 <tomberek> yeah... and hence I ran into problems that I figured the o-so-great-sages of #haskell could help me
21:40:42 <edwardk> if your types were reversed you can get farther
21:40:53 <edwardk> data NN a b = NN (Context b a) (Gr b a)
21:41:18 <tomberek> edwardk: oops, yeah, it is... i have it in GADT notation now:  NN :: Context a b -> Gr a b -> NN a b
21:41:30 <edwardk> then instance Copointed (NN a) where extract (NN (_,_,a,_) _) = a
21:42:43 <tomberek> edwardk: there's a contraint or something there no?
21:42:45 <edwardk> but you can't always extract a 'b' from the Context, because at most you have two lists of [(b,Node)] from the Adj b components of Context a b and those could both be empty
21:42:52 <MissPiggy> I cant use haskell llm
21:42:53 <MissPiggy> I cant use haskell llvm
21:43:14 <edwardk> tomberek: is there? i just mechanically took apart the type of Context, looking for a bare a.
21:43:58 <tomberek> you can get the label, but not an edge label,, but that would be a 'floating' node, not attached,, (i think that would be rejected during construction of the graph)
21:45:02 <Saizan> the intuition of the Pointer comonad is that extract gives you the value stored at the location pointed to, not the whole structure around it
21:45:42 <Saizan> you usually have other primitives specific to your comonad to look in the neighborhood
21:45:48 <tomberek> Saizan: yes,,, so hence my first draft where extract would only get the "Axon" or "Dendrite", not the whole "Neuron"/Context
21:47:13 <edwardk> tomberek: it seems to me like you'd have something like two versions of the pointer comonad. one where the 'index' references an edge and the other where it references a node.
21:47:25 <edwardk> these would be different comonads for processing the edges or the nodes of a given graph
21:48:00 <tomberek> edwardk: yes, that's what Saizan was saying, that's what my last draft did
21:48:28 <edwardk> you could cheat and avoid separating them by defining them using comonad and pcomonad, but you'd still only be able to extend on one or the other at a time.
21:49:17 <tomberek> edwaedk: hm... so no way to combine functions of type :: Context a b -> Context a b  ?
21:49:46 <edwardk> tomberek: you're looking for some kind of restricted comonad, but there aren't many useful combinators of that sort
21:50:14 <edwardk> ultimately, whenever you find yourself needing a restricted comonad or restricted monad one should question if you're choosing the right abstraction. =/
21:50:46 <edwardk> plus, Context isn't even a newtype, so you can't really even define instances around it
21:50:52 <luqui> edwardk++
21:51:24 <copumpkin> edwardk: what if I'd like a nice Set monad :(
21:52:02 <edwardk> now, you can take your comonad apart, and build a generalized pointer that has two 'pointers', one for the 'currently selected edge and one for the currently selected node, which can be extended on each separately.
21:52:14 <edwardk> you get something like
21:52:56 <edwardk> newtype NN graph a b = NN Edge Node (graph a b)
21:53:15 <tomberek> edwardk: hm... can i make that an instance of Graph as well
21:54:40 <edwardk> tonberek: _almost_, instance Graph gr => Graph (Node gr) -- works except for the fact that empty :: ... doesn't yield a well defined value.
21:54:56 <edwardk> Graphs are allowed to be empty, but an NN graph can never be empty
21:56:18 <edwardk> of course, you could define a constructor for it that just takes a non-empty graph and a pair of selections within the graph, so its not all thatr damning.
21:57:35 <tomberek> ok... i'm almost caught up to ya... i understand conceptually, but i'm not seeing the code
21:58:27 <edwardk> the other problem with that NN graph a b -- is that the graph api is biased, there is a match :: Node -> gr a b -> Decomp gr a b -- which gives you information on the currently selected node, but there is no matchEdge :: Edge -> gr a b -> EdgeDecomp gr a b -- since there is no notion of a selected edge
21:59:26 <tomberek> edwardk: true,,, that's why i like that Decomp,, it has a currently selected Context
21:59:40 <edwardk> you can of course take the slow path of defining it by using labEdges to generate a list of all edges and hunting that list for your currently selected edge
21:59:42 <tomberek> and that's where I began my attempt
21:59:55 <edwardk> but i'd not recommend that for anything that had to be remotely fast
22:00:01 <tomberek> edwardk: agreed
22:01:19 <edwardk> the more i look at the fgl graph api the more it seems to me that you're screwed ;)
22:01:36 <tomberek> nooo!!!
22:02:06 <edwardk> you really need a more symmetric api than this provides
22:02:27 <tomberek> edwardk: i liked the fgl package (except for this *->*->* business), it seemed fast in early tests.... can you recommend another approach?
22:03:02 <edwardk> this api lets you ask about what is around your node, but you have no equivalent way to ask about an edge at first glance
22:03:11 <copumpkin> ezyang: that samlee dude on reddit is just a troll who spends his time semi-seriously advocating buzzwordy enterprise-ready things
22:03:38 <ezyang> ha
22:03:39 <edwardk> it needs a matchEdge :: Edge -> gr a b -> LEdge b -- or something similar
22:03:46 <ezyang> I sort of suspected so :-)
22:04:01 <MissPiggy> copumpkin, samlee used to hang around here didn'\t he? (also: trolling on my reddit??)
22:04:12 <copumpkin> or if not a full-time troll, someone who loves to post things about everything being better when you move to cloud computing etc.
22:04:20 <copumpkin> MissPiggy: not sure, if he did I missed him (or wasn't here yet)
22:04:23 <copumpkin> :P
22:04:28 <MissPiggy> ISTR a saml doing a lot of CSish homework problems into this channel
22:04:29 <ezyang> oh wait, he was being seroius?
22:04:30 <ezyang> lol
22:04:34 <ezyang> *serious
22:04:43 <copumpkin> preflex: seen saml
22:04:43 <preflex>  saml was last seen on ##javascript 1 day, 8 hours, 50 minutes and 21 seconds ago, saying: js> var result = function() { result = 5; return result; };   result()
22:04:53 <copumpkin> saml does sound familiar
22:04:55 <copumpkin> not sure if it's samlee
22:05:14 <edwardk> and it basically provides bupkis when it comes to extracting edges from the graph without extracting all edges
22:05:24 <tomberek> edwardk: but there's no quickfix like extending the Graph or DynGraph typeclass... getting edge info should be somewhat fast with something like lpre
22:05:29 <tomberek> ?
22:06:28 <ezyang> edwardk: ...goat droppings?
22:06:32 <edwardk> well, you could build class EdgyGraph gr where matchEdge :: Edge -> gr a b -> Maybe (LEdge a b)
22:06:36 <copumpkin> :O
22:06:40 <edwardk> er
22:06:51 <edwardk> class Graph gr => EdgyGraph gr where ...
22:06:54 <ezyang> oh, "absolutely nothing of value"
22:07:07 <copumpkin> :P
22:07:27 <edwardk> ezyang: used in the colloquial sense of 'nothing of value'
22:08:02 <copumpkin> goat droppings are very valuable, to me
22:08:10 <copumpkin> er, maybe I shouldn't be telling people that
22:08:51 <edwardk> copumpkin: must be some strange side-effect from your bizarre upbringing.
22:08:57 <copumpkin> probably :)
22:08:59 <tomberek> edwardk: yeah, that way i can still use all the graph algorithms like dfs, etc... is that a worthwhile approach?  at this point, i'm a bit beyond my skills
22:09:10 <edwardk> tomberek: probably
22:10:46 <edwardk> tomberek: trick is taking the Gr datatype from Data.Graph.Inductive.PatriciaTree and figuring out a way to select an edge in it.
22:11:05 <copumpkin> edwardk: oh, I had a question for you
22:11:10 <copumpkin> I'll wait until you're done with this though
22:11:26 <tomberek> edwardk: won't a (Node,Node) work?
22:11:55 <edwardk> tomberek: there is no fast (Node,Node) selection. i suppose you could cheat a bit
22:12:06 <edwardk> you could just look up one of those, and use inn' or out'
22:12:20 <edwardk> and walk that potentially much smaller list to find your edge
22:12:34 <tomberek> that could come from lpre?  hm..
22:12:48 <edwardk> then in that case i'd refactor a bit and you'd probably have something like
22:13:14 <edwardk> data NN gr a b = NN Node Node (gr a b)
22:14:43 <edwardk> which presumes you have at most a  single edge between two nodes (the graph api seems not to prevent multigraphs) and takes the convention that you are selecting the edge, and the node you have selected for pextract purposes is one or the other (you choose the convention, it doesn't matter to me)
22:14:58 <tomberek> ok, i've copied this stuff to redigest later..... anything else o-Wise-One?
22:15:43 <edwardk> dunno, hadn't thought about this problem prior to an hour ago ;)
22:15:57 <edwardk> copumpkin: whats the question?
22:17:11 <tomberek> thanks for the help Edward.  It's amazing that I can find the author of different libraries and talk to them.
22:17:30 <edwardk> tomberek: that is one of the best things about this community. =)
22:17:51 <copumpkin> edwardk: I was thinking of what else we could cram into fingertrees beyond the common applications, and am pretty sure an r-tree is possible, but I was wondering about two other cases and thought you might be able to think of suitable monoids (I have a hunch it's not possible though): structures for finding all strings within a certain levenshtein(-damerau) distance from a query string, or structures for finding all strings that mat
22:17:51 <copumpkin> given regular expression (in sublinear time with respect to the number of strings)
22:18:25 <copumpkin> those two seem quite different though
22:18:37 <copumpkin> both seem like they'd need some sort of trie-like thing
22:18:37 <edwardk> the r-tree function is key-calculation for it as a GiST?
22:18:55 <edwardk> er no that doesn't work
22:19:02 <edwardk> hrmm, it needs to be calculation of the whole r-tree
22:19:18 <tomberek> edwardk, thanks again
22:19:19 <edwardk> ok, i buy it. that is a lot of redundant calculation though
22:19:24 <edwardk> tomberek: happy to help
22:19:47 <copumpkin> edwardk: to do an r-tree my idea was the following: extend the interval tree example to give you n-dimensional intervals, and then do something dealing with "load factors" of individual intervals, expanding or shrinking them as described in regular r-trees
22:19:51 <edwardk> so you have the r-tree itself as the value of the monoid, merging two monoids its merging the r-trees
22:20:39 <edwardk> so you wind up with an r-tree that indexes by pointing down to the individual source leaves, inserting into the finger-tree would add the node to the r-tree, so you could find it quickly by asking the r-tree of the fingertree
22:20:44 <copumpkin> I already wrote a 2-dimensional interval tree using fingertree and it was fairly trivial
22:21:00 <copumpkin> hmm, I don't understand how you're talking about it
22:21:11 <copumpkin> I'm basically encoding an r-tree in a fingertree
22:21:22 <edwardk> well, i presume your interval tree just used the (Min,Max) monoid?
22:21:31 <copumpkin> yeah
22:21:42 <edwardk> you can do the same thing for an r-tree but its about useless
22:21:48 <copumpkin> how come?
22:22:11 <edwardk> the power of an r-tree comes from the linear or quadratic splitting algorithms used to balance it
22:22:20 <edwardk> lemme see if i can dig up a paper for you
22:22:22 <copumpkin> yeah, and that's independent of the fingertree
22:22:32 <edwardk> unless you make that part of the monoid =)
22:23:08 <copumpkin> well my idea was to get around that by doing the splitting manually
22:23:09 <edwardk> so the monoid isn't just a min and a max over 2 or more dimensions
22:23:23 <edwardk> it is the whole tree
22:23:49 <edwardk> with an additional indexing operation to go find the leaves that match a given gist-like query
22:24:09 <edwardk> the monoid then represents the operation of merging databases
22:24:14 <copumpkin> hm
22:24:33 <edwardk> replete with the r-tree construction/balancing
22:24:35 <copumpkin> I still don't see why what I was thinking of wouldn't work :)
22:27:05 <edwardk> you can do it, its just kinda easy =)
22:27:23 <copumpkin> that's a bad thing? :P
22:27:27 <edwardk> you just need to replace Min/Max with Meet/Join
22:28:07 <edwardk> well, the problem comes down to the fact that attempting to search by key will be walking a lot of the fingertree
22:28:18 <edwardk> it isn't as efficient as it could be
22:28:56 <copumpkin> as far as I could figure out, it'd be similar to the original r-tree. The fingertree would store 2-dimensional rectangles that had fixed load capacities, and if they filled up too much they'd get split
22:29:25 <copumpkin> the original r-tree makes no claims about optimality either
22:29:26 <edwardk> perhaps i'm not understanding your version
22:29:40 <edwardk> what is the monoid?
22:29:49 <edwardk> give me an example data type for it
22:30:05 <edwardk> is it a tree or list of rectangles? or a single rectangle?
22:30:20 <edwardk> which summarizes its contents
22:30:25 <copumpkin> I made it by mechanically modifying the interval tree example :) it's min-max on 2d points
22:30:36 <copumpkin> so it stores a bunch of rectangles, conceptually
22:30:52 <copumpkin> and provides efficient query from (x, y) to the set of rectangles that contain that
22:30:58 <edwardk> yes, but the problem there is that an r-tree handles insertion more intelligently than your naive tree
22:31:12 <edwardk> it tries to insert it into the rectangle it would expand the least
22:31:13 <copumpkin> hm
22:31:18 <edwardk> the finger-tree isn't that smart
22:31:21 <copumpkin> yeah, that's what I'd do
22:31:37 <copumpkin> I guess you mean I can't find out which that is until I see them all?
22:31:54 <copumpkin> so say I want to insert (5,6), I get three rectangles that fit that
22:32:17 <copumpkin> I'd look at all three and then decide to insert into the one of those that would expand the least
22:32:41 <edwardk> i guess i mean that you can't just throw to node on the left or right most edge of the fingertree, and you can't even insert it in the middle of a fingertree, and rely on the monoid doing the right thing as you go 'up the tree', because the tree will slowly rebalance and slop over different rectangles as you insert in the middle of it
22:32:58 <copumpkin> hm
22:33:09 <copumpkin> well, it's immutable :P
22:33:34 <copumpkin> so obviously it's not going to be as efficient as a real r-tree
22:33:35 <edwardk> the point of a fingertree is the ability to add to it =)
22:33:55 <copumpkin> but that's what I'd be doing
22:33:59 <copumpkin> hm
22:34:05 <edwardk> the problem i have is that you don't get any benefit out of the 'fingertree-ness' of it, in fact it actively works against correct insertion in the naive example
22:34:21 <edwardk> that was why i was advocating a more complicated monoid
22:34:33 <copumpkin> it gives me a cheap way to get easy lookup of regions
22:34:44 <copumpkin> it doesn't do all the work, but it's pretty easy :P
22:34:56 <edwardk> there is no reason to believe that in the limit as you grow your tree that each branch won't cover nearly the entire space
22:35:15 <copumpkin> but that's what the logic on top of it would be doing, hmm
22:35:28 <copumpkin> I have direct control over the size of each rectangle
22:35:29 <edwardk> and no way to choose a good insertion order in order to prevent that
22:35:36 <edwardk> how?
22:35:52 <copumpkin> my API user is inserting points, not rectangles
22:35:55 <copumpkin> I decide on the rectangles
22:36:04 <edwardk> i insert 5 elements into a tree, i can shuffle them, now i insert 4 more, i can shuffle them, but the result will be that i now have different branches potentially covering the original 5.
22:36:16 <aavogt> @hoogle temporary
22:36:16 <lambdabot> System.Directory getTemporaryDirectory :: IO FilePath
22:36:25 <aavogt> @hoogle tmp
22:36:25 <lambdabot> Network.Socket AF_ATMPVC :: Family
22:36:25 <lambdabot> Network.Socket.Internal AF_ATMPVC :: Family
22:36:25 <lambdabot> Data.Generics.Aliases extMp :: (MonadPlus m, Typeable a, Typeable b) => (a -> m a) -> (b -> m b) -> a -> m a
22:36:49 <copumpkin> edwardk: yeah, but the original r-tree can have multiple regions covering the same areas too
22:36:57 <edwardk> thats not the problem
22:37:23 <copumpkin> hmm :)
22:37:24 <edwardk> the problem is that a real r-tree consists of points in regions, but adding points to a different region won't affect any other region
22:37:37 <edwardk> but a finger-tree rebalances itself
22:37:45 <edwardk> irrespective of the ideal r-tree balancing
22:38:12 <copumpkin> ah, I see what you mean. But is that necessarily a problem in practice?
22:38:18 <edwardk> yes
22:38:18 <edwardk> a HUGE problem
22:38:23 <copumpkin> hmm
22:38:41 <ezyang> whoa, dons is a programming reddit moderator
22:38:44 <edwardk> you don't have a natural 'order' limit the interval tree to figure out where to drop your nodes
22:38:52 <edwardk> ezyang: happened a few months ago
22:39:04 <ezyang> I just unsubscribed, meself
22:39:32 <edwardk> copumpkin: you might have a better chance using the hilbert ordering, that at least gives you a reasonably spatially coherent query mechanism
22:39:47 <edwardk> that is suited to a fingertree
22:39:52 <copumpkin> hmm
22:40:17 <copumpkin> to project it into a lower dimension?
22:40:18 <edwardk> http://www.dcs.bbk.ac.uk/TriStarp/pubs/bncod17.pdf
22:41:04 <edwardk> project from n dimensions down to a 1d space filling curve. now you have a single coordinate. that you can order. insert into the fingertree at a location based on your 1d coordinate.
22:41:09 <ezyang> whoa, that's really cool
22:41:33 <copumpkin> edwardk: so the ordering is fundamental for a fingertree?
22:42:04 <edwardk> query based on rectangles by projecting the rectangle into the space of your space filling curve, and test all points on the curve between the min and max value touched by your rectangle in hilbert space.
22:42:11 <edwardk> er hilbert curve space
22:42:18 <edwardk> its damn useful ;)
22:42:59 <copumpkin> but that seems like it would degrade in performance the "lower down" you went (just looking at fig 4)
22:43:39 <edwardk> it works reasonably well, and doesn't involve tree balancing, which the finger-tree would just screw up anyways
22:43:44 <copumpkin> if my query region was the bottom cm (full width) of that figure
22:43:55 <copumpkin> it seems like it'd need to query the entire curve?
22:44:04 <edwardk> there are degenerate cases, yes.
22:44:42 <edwardk> but for 'well-shaped' queries the hilbert curve provides a nice heuristic approach to get 2+d spatial coherency out of a projection onto a 1d number line.
22:44:51 <copumpkin> yeah, makes sense
22:45:13 <copumpkin> any thoughts about the other two things?
22:45:21 <copumpkin> the string structures
22:45:36 <edwardk> well, to me it seems the better monoid is to make the monoid the construction of the r-tree itself.
22:45:45 <copumpkin> hm
22:46:01 <edwardk> the monoidal values look like an entire r-tree rather than one branch of it
22:46:12 <copumpkin> but then I'd need to do a lot more of the work :P
22:46:17 <edwardk> that way you can properly handle splitting, etc.
22:46:18 <edwardk> sure
22:46:22 <copumpkin> boo
22:46:31 <edwardk> but if you take a step back and DON'T implement r-trees to start its much more general.
22:46:36 <edwardk> implement GiSTs ;)
22:46:54 <edwardk> then you derive a whole family of related structures, x-trees, russian doll trees, etc.
22:47:04 <edwardk> http://gist.cs.berkeley.edu/
22:47:08 <copumpkin> so GiST is more general than monoids? as far as I could tell, GiST was talking about anything that could be represented as nested sets
22:47:14 <copumpkin> which seemed to form a monoid anyway
22:47:42 <edwardk> A GiST is a way to talk about nested set-like things that also have a notion of how to split those sets
22:47:56 <edwardk> that latter part is important
22:47:57 <copumpkin> ah, so you have more control over the splitting process than fingertree
22:48:02 <edwardk> yep
22:48:20 <edwardk> now, you can then choose to make a monoid out of merging those trees
22:48:25 <copumpkin> Last modified: $Date: 1999/08/17 02:13:24 $ by $Author: jmh $
22:48:28 <copumpkin> not very encouraging :P
22:48:30 <edwardk> and use a fingertree over that monoid
22:48:35 <copumpkin> I see
22:48:38 <edwardk> its in active use in postgresql
22:48:45 <copumpkin> yeah, I know :) been using it recently
22:48:48 <edwardk> i've also used gists in my own research
22:48:56 <copumpkin> I get the gist ;)
22:49:03 <copumpkin> :)
22:49:53 <edwardk> also, joe hellerstein pretty much wrote the book on advanced query techniques. ;) rather literally. pick up 'Readings in Database Systems' which is edited by him and Stonebraker. ;)
22:50:07 <copumpkin> ah, cool
22:50:18 <copumpkin> I have the big book on spatial datastructures and have leafed through it a bit
22:50:22 <copumpkin> but it's dauntingly large
22:50:46 <edwardk> the handbook of discrete and computational geometry?
22:50:51 <copumpkin> hm, nope
22:50:55 <copumpkin> hanan samet is the author's name i think
22:51:07 <copumpkin> too lazy to get up and look for it :)
22:51:21 <copumpkin> http://www.amazon.com/Foundations-Multidimensional-Structures-Kaufmann-Computer/dp/0123694469/ref=cm_cr_pr_product_top
22:51:23 <edwardk> design and analysis of spatial data structures?
22:51:33 <edwardk> ah
22:51:48 <copumpkin> 2^10 pages!
22:52:25 <edwardk> http://books.google.com/books?id=QS6vnl8WlnQC&dq=handbook+of+discrete+and+computational+geometry&printsec=frontcover&source=bn&hl=en&ei=hRKKS63mDtCWtgeA09G4Dw&sa=X&oi=book_result&ct=result&resnum=4&ved=0CBwQ6AEwAw#v=onepage&q=&f=false 1558 pages ;)
22:52:33 <copumpkin> pff
22:52:42 <copumpkin> smaller book
22:52:45 <copumpkin> this one is huge!!
22:52:47 <edwardk> also has just a few more contributors ;)
22:53:18 <copumpkin> :P
22:53:34 <copumpkin> anyway, about those string structures :)
22:53:38 <copumpkin> any ideas there?
22:53:46 <edwardk> i bring that one out whenever i start to get uppity and think i understand computational geometry. I can open it to a random page and am instantly reduced to newbie status
22:53:55 <edwardk> same idea i suppose
22:53:55 <copumpkin> hah
22:54:32 <ezyang> @remember edwardk i bring that one out whenever i start to get uppity and think i understand computational geometry. I can open it to a random page and am instantly reduced to newbie status
22:54:32 <lambdabot> It is forever etched in my memory.
22:55:51 <copumpkin> hmm
22:56:06 <edwardk> I'm obviously in the wrong line of work at Raytheon. http://rtncyberjobs.com/ I could be a cyber gladiator ;)
22:56:21 <copumpkin> :o
22:56:33 <copumpkin> they're talking to me!
22:56:41 * ezyang lifts eyebrow 
22:56:43 <edwardk> the 'logic' puzzle on there was actually quite enjoyable.
22:57:12 <edwardk> would have been nicer had it actually looked like something
22:57:12 <copumpkin> oh wow, the job titles are actually cyber warrior
22:57:18 <copumpkin> not sure I could take myself seriously with a job title like that
22:57:32 <edwardk> yeah, cyber gladiator vi was actually on the list ;)
22:57:33 <copumpkin> my macbook air overheats with all that flash :(
22:57:47 <edwardk> best part is they are looking for folks with 8-10 years of experience to take the job..
22:57:51 <copumpkin> oh, that logic puzzle has a name
22:57:59 <edwardk> how you can get 8-10 years of experience and still have no pride is beyond me
22:58:40 <copumpkin> lol
22:58:44 <copumpkin> fat salaries?
22:58:52 <copumpkin> I'd imagine that takes second place to pride for many
22:59:00 <Niccus> aaaa the logic puzzle has no way to mark off numbers or guaranteed empty spaces
22:59:18 <edwardk> niccus: graph paper ;)
22:59:24 <copumpkin> lol
22:59:37 <edwardk> copumpkin: you laugh. i have a sheet of paper next to me with it ;)
22:59:53 <Jafet> How many security experts run flash plugins
22:59:56 <copumpkin> I just saw a wikipedia page about that kind of puzzle the other day
22:59:59 <edwardk> copumpkin: my wife teased me about it
23:00:11 <ezyang> I'd prolly just write a program to solve it...
23:00:13 <edwardk> Jafet: haha, the ability to see the content of the site should instantly disqualify you from the job!
23:00:25 <copumpkin> I agree :P
23:00:34 <copumpkin> ezyang: it's np-complete iirc from the wikipedia page
23:00:37 <copumpkin> but I can't remember what that was :P
23:00:42 <edwardk> ezyang: it has 2 solutions. it is underdetermined
23:00:43 <ezyang> it's small enough.
23:01:11 <ezyang> with judicious use of constraint programming and all
23:01:14 <luqui> not that np-completeness means that a human could solve it faster than a computer
23:01:42 <copumpkin> nope
23:01:47 <luqui> in fact the only place humans seem to be better than computers as far as well-defined problems is at proving theorems
23:01:58 <ezyang> well, of course
23:02:02 <Jafet> Not necessarily.
23:02:11 <Jafet> Sokoban, but that's pspace
23:02:12 <Gracenotes> with NP-complete a human could possibly approximate in fewer steps than a computer
23:02:13 <ezyang> because once you start proving theorems, you start trekking into the uncomputable realm >:-)
23:02:29 <Gracenotes> er. depends on what you mean by "step". But yeah. We can do something okay.
23:02:37 <luqui> ezyang, uncomputable means as much to humans as it does to computers
23:02:53 <MissPiggy> ?
23:03:03 <ezyang> luqui: I have this weird conception that, in theory, humans should be able to calculate busy beaver numbers
23:03:08 <Niccus> uncomputable as in intractable or unprovable
23:03:19 <MissPiggy> what computable matter? most things that are 'computable' can never be computed in reality
23:03:26 <edwardk> copumpkin: re your levenshtein distance monoid, that starts to sound like a phylogenetic tree
23:03:28 <ezyang> It doesn't :-)
23:03:40 <Jafet> @djinn a -> b -> (b -> c -> d) -> c -> (a -> b) -> d
23:03:40 <lambdabot> f a _ b c d = b (d a) c
23:03:45 <luqui> ezyang, we have only the ability to propose new "reasonable" axioms that can permit the computation of more BB numbers
23:04:09 <copumpkin> edwardk: that's something I haven't come across :)
23:04:15 <luqui> which has instantly disqualified it from being a well-defined problem.  The ill-defined ones are the ones we are best at :-)
23:05:17 * copumpkin looks up
23:05:25 <luqui> Jafet, sokoban is in P?  cool, didn't know that.
23:05:34 <copumpkin> edwardk: it looks like a trie, but outside of CS :P
23:05:36 <Jafet> No? It's in pspace.
23:05:46 <edwardk> copumpkin: they come up when you have a bunch of genomes and you're trying to figure out how they evolved. what is closer to the root of the tree, what common ancestors likely existed but aren't present any more?
23:06:04 <ezyang> "I bought me a cat, my cat pleased me. I fed my cat by the yonder trie."
23:06:20 <copumpkin> lol
23:06:22 <Gracenotes> these are trieing times
23:06:31 * copumpkin punches Gracenotes 
23:06:46 <edwardk> Apparently you trie copumpkin's patience.
23:06:52 * copumpkin punches edwardk 
23:07:02 <edwardk> If at first you don't succeed....
23:07:10 * copumpkin screams
23:07:16 <Niccus> it's like our old values are in a junk heap
23:07:21 <Gracenotes> I dropped the trie at the cafeteria
23:07:33 <copumpkin> by the way, has anyone ever come across soft heaps?
23:07:37 <copumpkin> they're pretty neat
23:07:41 * ezyang wonders if he's been mispronouncing trie... 
23:07:43 <Gracenotes> hm, what's that? We can't just use any vowel we want?
23:07:44 <edwardk> Fortunately, trie is pronounced 'tree' unfortunately, when you pronounce it that way, no one knows what you're talking about.
23:07:55 <copumpkin> it's a really bad name, in my opinion
23:08:08 <Niccus> screw that, tries and deeks all the way
23:08:09 <ezyang> 'parently everyone else pronounces it "try"
23:08:09 <copumpkin> the only way to get people to get it is to say "prefix/suffix trie" or mention trish
23:08:13 <edwardk> i gave up pronouncing them correctly years ago
23:08:16 <Jafet> It's a reified directed acyclic degree-constrained search graph
23:08:18 <copumpkin> ezyang: nope, I pronounce it tree
23:09:27 <Gracenotes> prefix free is clearer
23:09:36 <edwardk> i usually go into a short shpiel about how its tree spelled 'trie' and that i'm going to intentionally mispronounce it for the remainder of the discussion so you can hear the distinction
23:09:43 <Gracenotes> prefix tree. prefix-free is a different thing entirely.
23:09:45 <Jafet> Anyway, soft heaps are kind of niche
23:09:57 <copumpkin> Jafet: yeah, but I think it's a neat idea
23:11:05 * ezyang goes to look up 
23:11:47 <edwardk> in any event, imputing phylogenetic trees is a bit of a black art with lots of heuristics
23:12:18 <ezyang> that's... so funky
23:12:20 <copumpkin> I don't really see how you'd apply those to levenshtein
23:12:38 <copumpkin> it seems almost like another spatial search problem, but the space isn't "cartesian"
23:12:40 <edwardk> its one of those areas where i started trying to borrow research from bioinformatics for tackling generation of linguistic hypotheses
23:12:47 <copumpkin> or whatever else you'd want to call it
23:13:26 <MissPiggy> edwardk is the best person
23:13:33 <edwardk> well, if you have a bunch of strings, what is the ideal way to group them into stuff that has low mutual levenshtein distance
23:13:50 <copumpkin> edwardk: ah, I see what you mean
23:13:54 <Jafet> Does levenshtein define a valid metric?
23:14:10 <copumpkin> I think so
23:14:41 <Jafet> (For arbitrary mutation costs)
23:14:51 <Gracenotes> hm, does it satisfy the triangle inequality? taking the strings aa aba aa, for instance
23:15:21 <Gracenotes> hm, 2 > 0, so yes there.
23:15:23 <edwardk> Gracenotes: yes
23:15:23 <copumpkin> I'm pretty sure it does
23:16:24 <edwardk> for those who are interested: http://multitree.linguistlist.org/search was the result of the aforementioned research. it mostly turned towards how to visualize linguistic hypotheses, which is tricky because you can have several thousand languages in the tree
23:16:54 <Gracenotes> if you have moving characters from one part of the string to another, though, that fails to become a metric, says wikipedia
23:17:10 <copumpkin> the damerau variant?
23:17:19 <copumpkin> makes sense
23:18:40 <ezyang> doesn't work in my browser...
23:18:46 <ezyang> :-(
23:18:59 <copumpkin> edwardk: how about the hardest one of all? the regex matching :)
23:19:17 <ezyang> but proved Turing-recognizability is closed under concatenation! yaay
23:19:57 <edwardk> ezyang: sorry man, we wound up needing a java library to visualize the trees, used the poincare projection of a hyperbolic half-plane, to enable you to mouse over the entire tree in one motion.
23:20:12 <edwardk> nowadays, i'd probably use 'thejit' or something
23:20:21 <ezyang> blah
23:21:25 <edwardk> http://thejit.org/demos/ look at the hypertree demos (assuming you have canvas)
23:21:49 <copumpkin> oh that's pretty nice
23:22:17 <copumpkin> I might use something like that for what I'm working on right now
23:22:35 <edwardk> warning, there is a patent minefield thrown up by xerox parc that is still good for another 2 years or so
23:22:43 <copumpkin> screw them :P
23:22:52 <Gracenotes> pretty.
23:22:54 <ezyang> pretty
23:22:59 <edwardk> i don't know that they've enforced it, but there is a company: inxight that has licensed it
23:22:59 <ezyang> jinx
23:24:18 <copumpkin> I'm pretty impressed by this stuff
23:24:28 <copumpkin> it probably dies with very large graphs though
23:24:53 <edwardk> given linguist list's nature they found it better to license the official version than to risk getting called out on our homegrown version, since we had NSF funding
23:25:01 <edwardk> copumpkin: nah, it scales to astronomically large graphs
23:25:03 * copumpkin coughs http://dl.dropbox.com/u/361503/copumpkin_sfdp_transparentedges.png [warning, huge]
23:25:08 <copumpkin> oh, nice
23:25:21 <ezyang> it's... a hairy fuzzball
23:25:22 <copumpkin> edwardk: I have a graph with about 600 million edges right now
23:25:23 <edwardk> thats fine
23:25:51 <copumpkin> hmm, maybe I'll hook this up to my data source
23:25:54 <edwardk> the trick is you can only deal with a spanning-tree =/ in-degree at most 1
23:26:23 <copumpkin> edwardk, ezyang: can you find yourselves on that graph btw? :P
23:26:32 <copumpkin> you're both on there but probably not very visibly :)
23:26:44 <ezyang> wait what
23:26:45 <luqui> copumpkin, that's all the better graphviz can do?
23:26:53 <copumpkin> luqui: sadly
23:27:00 <ezyang> GraphViz needs to be revamped
23:27:04 <copumpkin> luqui: that's after I "tweaked" it, too
23:27:05 <ezyang> also, the website is down :-/
23:27:21 <uorygl> Your Mom's Law of Efficiency and Real-Time Scheduling: "If you keep putting things off hoping that you'll never have to do them, they'll just keep piling up until you have to do them all at once."
23:27:29 <copumpkin> ezyang: that's my twitter neighborhood, and you're on it, obviously :P
23:27:35 <ezyang> aha!
23:27:55 <luqui> copumpkin, i suspect it's dense?  N =~= E ?
23:28:04 <luqui> or even E >> N ?
23:28:11 <copumpkin> twitter? definitely not
23:28:16 <copumpkin> E >>>>>> N :P
23:28:22 <copumpkin> but not so much that I'd call it dense
23:28:26 <luqui> :P
23:28:39 <luqui> huh?
23:28:42 <copumpkin> N ~ 50M, E is way in excess of 1B
23:29:05 <luqui> oh yeah, N =~= E  is the definition of *sparse*...
23:29:26 <copumpkin> I think most people are probably connected to a few dozen other people
23:29:30 <luqui> dense is N = O(E^2) ?
23:29:36 <copumpkin> yeah
23:29:41 <copumpkin> oh wait, vice versa
23:29:44 <edwardk> copumpkin: of course since the tree can be loaded lazily you can allow for the tree to span outwards indefinitely, by ignoring redudnant links just subtending the angle further or there is the 'mostly hierarchical' approach used by thejit which allows for redundant links.
23:29:53 <luqui> copumpkin, oh right, that's what I meant ;-)
23:30:04 <copumpkin> edwardk: sounds neat, I'll hook it up to my twitter network data
23:30:21 <copumpkin> and tell people to stay away from the likes of ashton kutcher
23:30:28 <copumpkin> since they have fairly high indegrees :P
23:30:41 <edwardk> copumpkin: hah, i think i have barackobama on my list. be warned ;)
23:30:58 <copumpkin> edwardk: hah
23:31:04 <copumpkin> anyway, what I liked about that sfdp output from graphviz
23:31:11 <copumpkin> was that it correctly bunched things together
23:31:28 <copumpkin> all the haskellers form a fairly tight bunch on the left
23:32:04 <copumpkin> the regular fdp output didn't do that (and took an hour to compute)
23:33:29 <edwardk> i'm not a fan of fdp/sfdp. springs can only handle so much. the whole point of the poincare projection is that it doesn't matter the size of the tree. you merely subtend the angle locally in a hyperbolic space, so as you go farther out into the halfplane you have more angle available to you to split.
23:33:52 <edwardk> that way when you have a 10000 node tree, you don't have to space the 10 items 1 level away from the root 1000 labels apart.
23:33:54 <copumpkin> edwardk: hmm, I used sfdp because it's all I knew about :)
23:34:04 <copumpkin> and it was the only tool of the graphviz suite that could handle that graph
23:34:11 <copumpkin> where can I find better?
23:34:11 <edwardk> copumpkin: yeah
23:34:25 <edwardk> copumpkin: try loading your dataset into thejit
23:34:36 <edwardk> i've not tried it on a large dataset though, so be warned
23:34:42 <djahandarie> That's going to be a beast JSON file
23:34:46 <edwardk> it'll at least take you into hyperbolic space
23:34:52 <copumpkin> any nice way to convert dot to it?
23:35:46 <copumpkin> I guess I can write a quick script to spit out json
23:36:08 <edwardk> copumpkin: no idea. i just found it a couple of weeks ago, when i was explaining the poincare projection stuff to a friend who was writing some mind mapping software
23:36:15 <copumpkin> ah
23:36:34 <copumpkin> this isn't actually doing any real graph layout though
23:36:54 <copumpkin> it's just placing it on concentric circles based on distance from some specified node
23:36:55 <edwardk> its not going to be laid out in euclidean space in the end, no
23:37:10 <edwardk> you looked at the hypertree version, right?
23:37:13 <copumpkin> yeah
23:37:26 <copumpkin> I guess it is laying it out
23:37:36 <edwardk> did you see the multitree example?
23:37:44 <copumpkin> I'll see if it can "find" the haskellers in my neighborhood :)
23:37:44 <edwardk> not thejit, the one using inxight startree?
23:37:58 <copumpkin> hm, not thejit?
23:38:02 <copumpkin> that's the only site I have here
23:38:09 <edwardk> http://multitree.linguistlist.org/search
23:38:12 <lpsmith> Argh,  Data.Map needs some kind of lookupFloor :: Ord k => Map k v -> k -> Maybe (k,v)  that finds the greatest element less than a given element
23:38:14 <copumpkin> oh that :)
23:38:20 <copumpkin> let me try
23:38:29 <lpsmith> err, s/element/key/,  but yeah
23:39:16 <copumpkin> edwardk: that's quite pretty, yep :)
23:39:18 <copumpkin> but it's a tree
23:39:21 <copumpkin> I have an arbitrary graph
23:39:22 <luqui> lpsmith, findMin + split ?
23:39:30 <edwardk> copumpkin: go to, say, Africa, Niger-Congo, Composite 2008 to get a dense dataset.
23:39:41 <ezyang> sleepy
23:39:43 <ezyang> g'night all
23:39:50 <copumpkin> g'night!
23:39:53 <edwardk> so there is a way to make it handle 'mostly hierarchical data
23:40:35 <copumpkin> I definitely like the hyperbolic (?) layout
23:40:36 <edwardk> you basically wind up with the tree, with edges that go to the node nearest the center of the tree when they link 'upwards'. no force swapping things around
23:40:54 <lpsmith> luqui:  that might be good enough for my purposes, actually,   but still that strikes me as sub-optimal
23:40:54 <copumpkin> but my data isn't even nearly a tree
23:41:02 <luqui> lpsmith, why?
23:41:05 <lpsmith> lookupFloor shouldn't need to allocate new structures
23:41:20 <luqui> lpsmith, yeah maybe Map is too strict for that to be efficient
23:41:26 <luqui> i am not sure
23:41:32 <edwardk> well, if you're looking to extract clusters, etc. that isn't the right tool. if you're looking to start at you and browse your way outward though?
23:41:43 <copumpkin> edwardk: that's a pretty neat project btw :) you need to put the pretty trees more visible up front though!
23:41:56 <edwardk> copumpkin: i'm not involved any more. ;)
23:42:00 <lpsmith> luqui, point taken, I didn't consider that laziness might help a bit here
23:42:01 <copumpkin> boo
23:42:28 <copumpkin> edwardk: well, what edges would I include? what if one of my twitter friends follows another of my twitter friends? should I just omit that?
23:42:36 <edwardk> i just designed the data, chose the technologies, etc. but they cut scope when i left, thats why all the neat stuff which allowed it to compare linguistic hypotheses, etc. isn't there.
23:42:47 <copumpkin> aw
23:43:37 <edwardk> one option is to omit it. one is to draw the arrow back upwards to the guy closer to the root, another option is to just fan out. the tree can be infinitely large. you have more space in hyperbolic space than on the euclidean plane, so if you fan to 40 who fan to 40 who fan to 40, etc. you never run out of space.
23:43:50 <lpsmith> :t Data.Map.lookup
23:43:51 <lambdabot> forall k a. (Ord k) => k -> M.Map k a -> Maybe a
23:43:58 <copumpkin> yeah
23:44:12 <lpsmith> that also annoys me a bit.  But whatever
23:44:31 <copumpkin> well my main goal at the moment is to look at groupings of users
23:44:37 <JoshTriplett> A question on generalization: data Maybe a = Nothing | Just a, and maybe :: b -> (a -> b) -> Maybe a -> b .  Similar for either, with its two constructors.  If you generalize that, it works for any number of data constructors with any number of variables.  For a single unary constructor, that equals fmap; for a single nullary constructor, that equals const.
23:45:01 <copumpkin> JoshTriplett: catamorphism?
23:45:13 <JoshTriplett> copumpkin: Is *that* what that means? :)
23:45:29 <copumpkin> not sure if it's a catamorphism if you don't have the fixed point of a functor
23:45:49 <edwardk> JoshTriplett: yeah, 'foldr' is the catamorphism for lists for instance.
23:45:50 <copumpkin> I'm sure edwardk can comment :) but if not, it's a "destructor", probably
23:45:52 <edwardk> @type foldr
23:45:53 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
23:46:07 <edwardk> because lists are recursive.
23:46:09 <copumpkin> cata = destruct anyway
23:46:20 <JoshTriplett> Nice.
23:46:29 <edwardk> cata = downward
23:46:37 <copumpkin> I attach more negativity
23:47:26 <edwardk> as in 'tearing down' in this case, or in the context of catastrophe. the word that usually imparts the negative connotation to kata-
23:47:55 <copumpkin> I love that you can compose these thejit graphs
23:48:07 <edwardk> its a nice library
23:48:42 <lpsmith> JoshTriplett, you might enjoy looking at "The essence of the iterator pattern" by Jeremy Gibbons and Bruno Oliveria
23:48:44 <edwardk> i think it would be better if it separated the two kinds of animations into a 'viewport'/panning animation and an opening/mutating kind of action
23:48:56 <edwardk> that would let you get the instant mousable pan and zoon even in hyperbolic space
23:49:09 <copumpkin> omg the author does ocaml
23:49:22 <copumpkin> we must bring him to our haskelly ways
23:49:27 <JoshTriplett> lpsmith: Looks interesting, thanks.
23:49:33 <edwardk> hah
23:49:48 * copumpkin follows him on twitter, just to be more 2.0ish
23:49:57 <edwardk> clearly there needs to be a hyperbolic version of vacuum ;)
23:50:05 <copumpkin> I was just thinking :)
23:50:11 <copumpkin> speaking of vacuum, mmorrow has disappeared
23:50:23 <edwardk> hrmm. what happened to him?
23:50:31 <copumpkin> no clue, he got buried in a manual
23:50:33 <copumpkin> preflex: seen mmorrow
23:50:33 <preflex>  mmorrow was last seen on #ghc 41 days, 4 hours, 52 minutes and 48 seconds ago, saying: * mmorrow is rtfm'ing
23:50:37 <edwardk> yeow
23:50:52 <edwardk> i think i still have his number, i should give him a call and see how he's doing
23:50:58 <copumpkin> he fixed up hpaste.org I think recently
23:51:02 <copumpkin> cause it was dead and then reappeared
23:51:07 <copumpkin> but I sent him an email and he hasn't responded
23:51:47 <JoshTriplett> So, a different pattern: what about the function which does this: f :: b -> ([a] -> b) -> [a] -> b , with f z _ [] = z ; f _ func l = func l
23:52:00 <JoshTriplett> Do one thing if you have an empty list, and run a function on the list if you have another.
23:52:19 <edwardk> JoshTriplett: it has no name ;)
23:52:23 <copumpkin> special case of the same thing as before
23:52:33 <JoshTriplett> edwardk: Not a pattern, and not any particular standard function?
23:52:49 <copumpkin> :t fromMaybe
23:52:50 <lambdabot> forall a. a -> Maybe a -> a
23:52:55 <JoshTriplett> @pl \z f l -> if l == [] then z else f l
23:52:55 <lambdabot> ap . flip (if' . ([] ==))
23:53:09 <copumpkin> I guess that isn't what you want either
23:53:13 <edwardk> JoshTriplett: i mean, why bother with the b? you could always just define f :: ([a] -> b) -> [a] -> b; f = id; -- the 'z' case is redundant, since your function from ([a] -> b) could always be used
23:53:16 <JoshTriplett> fromEmptyList. :)
23:53:36 <copumpkin> and then it just becomes id :)
23:53:39 <JoshTriplett> edwardk: Well, sure, but the pattern of doing something different with an empty list seems fairly common.
23:53:53 <edwardk> plus since it takes a list, it isn't unambiguous how it uses the function. it could reshuffle the input list however it wants, or apply it to some subset of the elements
23:53:56 <JoshTriplett> Effectively, I want to pull out the "please substitute this value for the empty list" case from a function.
23:54:17 <copumpkin> you do something fundamentally different for empty lists than you do for non-empty ones?
23:54:31 <copumpkin> that doesn't seem that common to m
23:54:36 <edwardk> @pl \z f l -> if l == mempty then z else f l
23:54:36 <lambdabot> ap . flip (if' . (mempty ==))
23:54:51 <JoshTriplett> copumpkin: Yes, and I don't do that to the last nil in a non-empty list.
23:54:55 <JoshTriplett> copumpkin: My use case: templating.
23:55:00 <copumpkin> :o
23:55:01 <edwardk> personally i think you probably would be better off doing the same thing and establishing a proper base case
23:55:13 <copumpkin> JoshTriplett: can I see more of the use case?
23:55:36 <JoshTriplett> copumpkin: If I have a non-empty list, run each of these items through the item template, and substitute the result into the list template.
23:55:48 <JoshTriplett> copumpkin: If I have an empty list, do something else entirely.
23:55:52 <copumpkin> hmmm
23:56:02 <copumpkin> sounds like you'd want a Maybe?
23:56:10 <copumpkin> or something else
23:56:10 <JoshTriplett> copumpkin: (For instance, don't emit <ul></ul>, but do emit <ul><li>...</li></ul>.)
23:56:26 <copumpkin> I see
23:56:52 <JoshTriplett> In fact, I can make the pattern more specific quite easily.
23:56:56 <Jafet> (<ul></ul> can be different from nothing, though)
23:57:07 <JoshTriplett> Jafet: Indeed, precisely why I don't want to have it. :)
23:58:52 <JoshTriplett> copumpkin: I never do anything to the non-empty list except concatMap.
23:59:09 <edwardk> in any event, it doesn't have a name as such, you can always build it out of foldr and some post processing
23:59:19 <JoshTriplett> edwardk: Yeah, true.  Just wondered.
