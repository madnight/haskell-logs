00:00:42 <ndxtg> :t func :: (Eq a, Show a, Show b) => [a] -> [b]
00:00:43 <lambdabot> Not in scope: `func'
00:01:48 <ndxtg> :t func :: (Eq a, Ord b) => [a] -> [b]
00:01:49 <lambdabot> Not in scope: `func'
00:02:19 <Veinor> you told it the type already
00:02:26 <Veinor> (Eq a, Ord b) => [a] -> [b]
00:02:34 <kmc> ndxtg, :t takes expressions, not top-level declarations
00:02:43 <kmc> :t let func :: (Eq a, Show a, Show b) => [a] -> [b]; func = undefined in func
00:02:43 <lambdabot> forall a b. (Show b, Show a, Eq a) => [a] -> [b]
00:02:49 <kmc> «let ... in ...» is an expression
00:05:44 <ndxtg> right... 
00:06:39 <kmc> what's a convenient way to repeat an IO action until a file handle isEOF
00:06:59 <elaforge> is it possible to put a superclass constraint on a type family?
00:07:15 <elaforge> so that e.g. all the type instantiations are required to be in a certain class?
00:07:39 <elaforge> I can write class (Show (Element derived)) => Derived derived where type Element derived :: *
00:07:59 <elaforge> but my Element instances are still not apparently in Show
00:09:16 <elaforge> kmc, I don't know about stdlib, but I just wrote a while function
00:09:22 <kmc> yeah
00:09:29 <Jafet> :t while
00:09:30 <lambdabot> Not in scope: `while'
00:09:32 <elaforge> while_ :: (Monad m) => m Bool -> m a -> m ()
00:13:26 <elaforge> oh, interesting, it does work, but I have to put a class context on a data declaration
00:13:38 <elaforge> I thought that was supposed to be always a mistake
00:14:31 <kmc> grr i'm getting: Exception: logs/06.02.27: hGetContents: invalid argument (Invalid or incomplete multibyte or wide character)
00:14:35 <kmc> and can't seem to catch it
00:14:55 <elaforge> it's the lazy hGetContents from System.IO?
00:15:17 <kmc> oh never mind, very dumb mistake
00:15:17 <FunctorSalad> elaforge: is this in a stdlib?
00:15:29 <elaforge> not to my knowledge but it's trivial to define
00:15:30 <FunctorSalad> thought there was something similar but couldn't find it recently
00:15:36 <FunctorSalad> sure
00:15:40 <elaforge> while_ cond op = do
00:15:40 <elaforge>     b <- cond
00:15:40 <elaforge>     if b then op >> while_ cond op else return ()
00:16:33 <elaforge> it's probably in MissingH or something
00:18:08 <kmc> grr now how do i go past the invalid character
00:18:12 <kmc> hSeek won't seek past it
00:18:23 <kmc> even though the offset is allegedly in bytes not chars
00:18:50 <elaforge> isn't there usually a mode to replace decode errors with ?s or something?
00:19:14 <kmc> do you know how to do that in Haskell?
00:19:33 <kmc> ah very tricky
00:19:40 <kmc> if i open in binary mode, seeking works
00:19:44 <elaforge> nope, but maybe there are some settings in the new encoding modules
00:21:05 <elaforge> you're decoding multibyte data to a String?
00:23:18 <kmc> just using hGetLine
00:23:20 <kmc> but yes, it would do that
00:41:54 <ivan_m> robertmassaioli: I notice you're joining us at AusHac! \o/
00:49:37 <robertmassaioli> ivanm: yes I hope to. I just want to come and check it out. Even if I only manage one day. :D
00:49:46 <ivanm> cool
00:49:54 <ivanm> any idea about what you want to hack on?
00:50:50 <robertmassaioli> not really. I'm still very new to haskell. Any suggestions are good to me. I pick out of the suggested projects right?
00:51:25 <robertmassaioli> I only have about six months experience and I am almost done with real world haskell :)
00:52:39 <c_wraith> what sort of things are you interested in?  It always helps to contribute to a project in an area you're already interested in
00:52:46 <ivanm> robertmassaioli: you can pick your own as well
00:53:00 <ivanm> c_wraith: he's referring to the projects at http://www.haskell.org/haskellwiki/AusHac2010
00:54:00 <c_wraith> unrelated to this conversation, but vexing me at the moment..  Aside from doing something to SIGINT handlers, why else might a haskell program quit responding to ctrl-c?
00:54:45 <ivanm> because it's ignoring the keyboard completely?
00:54:56 * ivanm has no idea tbh
00:57:09 <robertmassaioli> ivanm, c_wraith: Well. I saw the need for a library that implements iCalendars properly so maybe that? It would help my (parsec) parsing skills. I'm not really sure; but I want to try and start with something reasonable. I don't want to make the mistake of trying to make a 'mmo on my first attempt' sort of thing. I'm open to suggestions basically.
00:57:38 <ivanm> I have no idea what the iCal format is like, but it sounds like a reasonable goal
00:57:51 <c_wraith> I can easily reproduce the state, but I don't know what to look for as the underlying cause.  It doesn't appear to be doing anything to the signal handler, from my scan of the dtruss output.
00:58:36 <ivanm> you just wanting something to parse + print iCal?
00:59:00 <c_wraith> Also, my attempts to create a minimal case showing this behavior failed.  So it's an interaction between multiple parts of the system.
00:59:52 <ivanm> robertmassaioli: there already appears to be one:
00:59:53 <robertmassaioli> ivanm: yeah basically, maybe even make it more intuiative to use as a hackage library, turn it into a calendar app if the spec alone proves to be too easy. ect. ect.
00:59:55 <ivanm> @hackage iCalendar
00:59:56 <lambdabot> http://hackage.haskell.org/package/iCalendar
01:00:04 <ivanm> no idea how good it is though
01:00:10 <robertmassaioli> yeah, it's not complete, I spoke to the author
01:00:22 <robertmassaioli> I could try and extend it?
01:00:30 <ivanm> sure
01:00:40 <ivanm> maybe upgrade it to parsec 3 if you want
01:00:45 <ivanm> do pretty-printing as well
01:01:03 <ivanm> the docs say things are missing, so you can add them in as well
01:01:35 <ivanm> yeah, there's no pretty-printer (as in to print the calendar
01:01:50 <ivanm> so even if you leave the parsing alone there should be enough stuff you can do there
01:01:52 <robertmassaioli> sounds like a plan to me. I thought it would make a nice first project. pretty_printer would be very cool for it
01:02:00 <robertmassaioli> I like it. 
01:02:05 <ivanm> good-o
01:02:09 <ivanm> preflex: seen eelco
01:02:10 <preflex>  eelco was last seen on #haskell 1 year, 150 days, 16 hours, 34 minutes and 50 seconds ago, saying: bling, because [2..2-1] is []
01:02:31 <robertmassaioli> ...yeah that was a while ago
01:03:07 <ivanm> hmmmm, he was apparently on IRC on 29 March this year
01:03:17 <ivanm> mustn't have said anything though
01:03:44 <robertmassaioli> The spec that is was based on has changed too and been obsoleted, I might look at the changes document. And really, huh?
01:03:58 <ivanm> /msg nickserv info eelco
01:04:08 <ivanm> ^^ will give you info on when that nick was last seen, etc.
01:04:30 <robertmassaioli> ivanm: right you are
01:29:17 <danharaj> :t ()
01:29:19 <lambdabot> ()
01:29:25 <danharaj> :k ()
01:29:26 <lambdabot> *
01:32:22 <krainboltgreene_> :( ()
01:32:45 <kmc> silly finite sort hierarchy
01:33:54 <Baughn> Ye~es. We need more kinds.
01:33:57 <Baughn> Integer kinds.
01:34:48 <kmc> http://strictlypositive.org/winging-jpgs/
01:35:30 <kmc> also http://web.cecs.pdx.edu/~sheard/Omega/index.html
01:36:01 <kmc> Omega is at a very interesting point in type system design space
01:36:29 <danharaj> What is that point?
01:36:44 <danharaj> Their page is not very... informative.
01:36:47 <kmc> http://web.cecs.pdx.edu/~sheard/Omega/OmegaManual.ps
01:36:51 <kmc> had to find it through wikipedia :/
01:37:12 <danharaj> Good thing website design has no correlation with theoretical prowess.
01:37:13 <danharaj> :p
01:37:14 <kmc> danharaj, it does not have dependent types, but has an infinite hierarchy where Haskell has only value :: type :: kind
01:37:21 <kmc> and you can declare GADT-ish things at any level of the hierarchy
01:38:11 <danharaj> does it have only one hierarchy or can the user define new sorts independent of it?
01:38:22 <kmc> don't know
01:38:45 <danharaj> 'cause it sounds almost like a sandbox for pure type systems
01:39:27 <kmc> yeah
01:40:01 <kmc> anyway i like this idea because i think Haskell could go in this direction
01:40:07 <kmc> much more easily than it could acquire dependent types
01:40:19 <kmc> it is also similar to She
01:41:04 <kmc> well they both have datakinds, anyway
01:41:12 <kmc> not similar in other ways ;P
01:42:02 <kmc> are there any programming languages actually based on PTS?
01:43:11 <danharaj> Does the calculus of constructions count as a programming language? :p
01:43:23 <kmc> Coq and Agda do
01:44:46 <kmc> isn't CoC merely one of the systems described by PTS in the same way STLC or F is?
01:45:13 <danharaj> oh, I thought you meant an example of a PTS used in programming languages.
01:45:25 <kmc> Haskell would be such an example, no?
01:45:39 <kmc> i mean depends how you define things
01:46:54 <danharaj> I wonder how the agda people parse their mixfix operators.
01:47:13 <danharaj> Must be quite a bit harder than just dealing with infix
01:47:50 <kmc> yes
01:47:56 <kmc> i read a paper on that but can't recall the name
01:48:47 <kmc> iirc agda has the property that 1) operator-parts are always delimited by whitespace, 2) operator-parts are unique
01:49:05 <kmc> without that it sounds way the hell harder, maybe undecidable
01:49:27 <danharaj> undecidable syntax might be undesirable
01:49:35 <kmc> it works fine for C++ and Perl
01:49:55 <danharaj> C++ parsing is undecidable? I know compilation is because of template recursion.
01:50:03 <kmc> yeah, but that's a silly complaint
01:50:07 <kmc> when people make that complaint
01:50:25 <kmc> C++ parsing is difficult.  i'm not sure if it's actually undecidable, but there is significant context-dependence
01:50:56 <danharaj> I can believe parsing perl is undecidable.
01:51:06 <kmc> you should believe it; it's been proven
01:51:16 <kmc> of course you can argue around this
01:51:32 <flux> but it was via trickery, using eval in BEGIN or something
01:51:36 <kmc> nah
01:52:19 <kmc> i say, Perl has very simple syntax -- the AST is just a sequence of characters!
01:52:22 <kmc> nothing could be easier to parse
01:52:35 <kmc> now, the *semantics* of Perl... don't want to write sequent calculus for that
01:52:51 <kmc> anyway the example is
01:52:55 <kmc> whatever  / 25 ; # / ; die "this dies!";
01:53:01 <danharaj> you totally just googled that :p
01:53:02 <kmc> "Schwartz's Snippet can parse two different ways: if whatever is nullary (that is, takes no arguments), the first statement is a division in void context, and the rest of the line is a comment. If whatever takes an argument, Schwartz's Snippet parses as a call to the whatever function with the result of a match operator, then a call to the die() function."
01:53:06 <kmc> you think? ;P
01:53:25 <danharaj> I dunno, I have an embedding of the lambda calculus into C++ templates in my bookmarks.
01:54:42 <thoughtpolice> even parts of the C grammar aren't context free, because the lex 'a * b' could be an expression i.e. multiplication, or a variable declaration where a is a type
01:54:51 <kmc> yeah
01:54:54 <kmc> good point
01:54:56 <thoughtpolice> C++ requires a boatload of semantic analysis to parse correctly
01:55:10 <kmc> yes
01:55:13 <kmc> a boat filled with shit
01:55:36 <danharaj> I think C++ would have a lot healthier toolchains if parsing it wasn't as hard as screwing in a lightbulb with machineguns for arms.
01:55:42 <kmc> yeah
01:56:07 <robertmassaioli> danharaj: that should be your IRC quote
01:56:21 <kmc> languages which lack abstraction of the usual sort are much more tolerable when you can do real metaprogramming
01:56:29 <danharaj> @quote danharaj
01:56:29 <lambdabot> danharaj says: unsafeCoerce should be renamed to badPun
01:56:30 <kmc> C++ templates are about as bad as a metalanguage can be and still be useful
01:56:35 <kmc> :D
01:56:37 <kmc> i love that quote
01:56:55 <danharaj> I admit I may have peaked at that point :p
01:56:59 <thoughtpolice> it's arguable that the lack of high quality, free C++ analysis tools is a result of how complicated the language semantics are
01:57:04 <robertmassaioli> danharaj: lol actually that one is better :D
01:57:06 <thoughtpolice> clang at least is designed with this in mind
01:57:08 <kmc> anyway, it would be easy to fix this externally, except for syntactic woes
01:57:12 <thoughtpolice> i welcome our new compiler overlord in that area
01:57:20 <thoughtpolice> and hope IDEs/refactoring tools begin adopting it
01:57:35 <kmc> yeah
01:57:35 <danharaj> clang sounds good
01:57:39 <danharaj> LLVM ftw
01:57:44 <thoughtpolice> even microsoft abandoned their own C++ frontend in visual studio 2010
01:57:51 <kmc> haha
01:57:53 <thoughtpolice> they went to using an online EDG-based parser
01:58:08 <thoughtpolice> apparently EDG is really awesome, so it was probably worth it though
01:58:23 <danharaj> I can't imagine how complicated their intellisense algorithms are.
01:58:53 <kmc> what is EDG?
01:59:03 <thoughtpolice> a commercial compiler frontend
01:59:13 <kmc> oh right
01:59:19 <danharaj> they have a three letter domain name
01:59:23 <danharaj> edg.com
01:59:25 <thoughtpolice> technically I think EDG, aside from the comeau compiler, is the *only* C++ frontend out there that fully supports the C++ spec in every form
01:59:34 <thoughtpolice> in that they both support template 'export'
01:59:37 <danharaj> to be fair, export is a broken language feature
01:59:39 <thoughtpolice> which pretty much nobody else supports
01:59:43 <thoughtpolice> yes
01:59:44 <kmc> http://cacm.acm.org/magazines/2010/2/69354-a-few-billion-lines-of-code-later/fulltext
01:59:53 <kmc> great article
02:00:00 <kmc> EDG is mentioned in it
02:00:21 <thoughtpolice> most people estimate that the amount of effort required to build support for export is roughly as hard as implementing as 80% of C++ itself
02:00:36 <thoughtpolice> well, most people, more like 'people Ive heard from at comeau and online'
02:00:53 <thoughtpolice> so it's a very broken language feature indeed
02:00:54 <danharaj> I wonder how much of that is because of traditional compiler structure.
02:01:03 <thoughtpolice> EDG actually pushed the proposal to remove export from C++0x
02:01:07 <kmc> haha
02:01:19 <thoughtpolice> not deprecate, actually *remove*, because deprecation implies they still have to support it
02:01:22 <thoughtpolice> and they don't want to do that
02:01:40 <kmc> they want to disappear the feature
02:01:42 <kmc> in the dead of night
02:01:52 <danharaj> take it out back with a shotgun
02:01:55 <kmc> chase down all printed copies of the C++ spec and remove the offending pages
02:01:59 <kmc> edit it out of photos
02:02:02 <thoughtpolice> which tbh is very nice on their part, since it's arguable that destroys a bit of marketability for their product, especially considering how hard it must be to monetize compiler frontends
02:02:02 <danharaj> C++0x is in some ways welcome
02:02:12 <danharaj> but in other ways you just realize that C/++ is the new COBOL
02:02:19 <kmc> C++0x brings C++ into the 1970's
02:02:23 <danharaj> There are going to be two different ways of writing a function type signature.
02:02:33 <kmc> well, almost -- their type inference isn't nearly as clever as HM
02:02:35 <danharaj> Now to be fair, the new way is more sane, but still.
02:02:46 * thoughtpolice has essentially inherited a large C++ project at work from his coworker who moved to EA
02:02:58 <thoughtpolice> where large = ~50 kLOC
02:03:09 <kmc> rewrite it in haskell
02:03:17 <danharaj> that's like 1000 lines in Haskell </set phasers to troll>
02:03:17 <thoughtpolice> because basically I'm the only person who's willing to write C++ and competent enough to do it, they've found
02:03:29 <fasta> thoughtpolice, the language is not really that important. What matters is whether it was written to be understood by someone else.
02:03:29 <kmc> danharaj, i was going to shoot lower
02:03:35 <thoughtpolice> would if I could, there are bigger problems there than just the code challenges
02:03:38 <thoughtpolice> namely, deployment
02:03:51 <kmc> NEVER admit to knowing anything you don't want to do
02:04:15 <danharaj> fasta: It matters whether the language was designed for writing code to be understood by someone else :p
02:04:16 <thoughtpolice> well, I said I could do it, and I can
02:04:18 <kmc> woe to he who admits to knowing SQL
02:04:27 <fasta> thoughtpolice, my personal favorites are undocumented buggy floating point geometrical algorithms ;)
02:04:59 <thoughtpolice> fasta: you're correct. some parts of our software are ridiculously complicated and my coworker did a good job of explaining major, important parts of the project to me
02:05:10 <fasta> danharaj, C++ has certain nice semantics, but it also has some things which are quite annoying. Not everything about it is bad.
02:05:18 <kmc> "oh, you know what a SELECT statement is? great, it's your job to install and maintain and replicate our MySQL cluster and also design the schemas and write frontend tools"
02:05:42 <danharaj> fasta: Don't get me wrong, I like C++, I just think that for every nice point there is a mountain of shit and heavy syntax.
02:05:46 <thoughtpolice> of course, I'm also roughly willing to say that despite that, I would feel more productive and confident with higher amounts of abstraction and type safety, e.g. haskell
02:06:08 <kmc> don't get me wrong, i hate C++
02:06:09 <fasta> I think you can write with the same safety in C++, just with more effort. 
02:06:14 <kmc> i admit that it's the best extant language for a certain niche
02:06:24 <thoughtpolice> namely more confident in the ability to change code. code entanglement and smell happens to all projects, I just happen to think in haskell it's easier to get rid of and be confident about the changes :)
02:06:29 <kmc> but not all of its flaws are due to fitting that niche, as its apologists will claim
02:06:33 <Baughn> kmc: ..well, creating schemas isn't /that/ hard....
02:06:51 <thoughtpolice> fasta: indeed, I just don't like the extra effort :)
02:07:03 <thoughtpolice> but I don't think our choice of C++ at work is broken or anything
02:07:15 <thoughtpolice> I think it's actually a fairly reasonable choice, it just has its consequences
02:07:18 <kmc> Baughn, sure, none of it's *that* hard.  but a lot of medium-size organizations see "the database" as a little side thing and don't recognize how quickly it can take up all of one full-time worker's time
02:07:33 <danharaj> C++ should be succeeded by a new language
02:07:44 <thoughtpolice> it's funny because I spend a lot of time @ work talking with some of my coworkers about haskell
02:07:46 <kmc> yes, one which is not backwards compatible
02:07:51 <kmc> D tried to be this
02:08:04 <thoughtpolice> they are constantly mind blown when they challenge me to do something and I write it in about 2 lines of code and explain it abstractly
02:08:24 <kmc> thoughtpolice, that's better than refusing to believe that it's a real language
02:08:34 <thoughtpolice> and many of these things we talk about have very similar correspondences to what we do at work
02:08:51 <danharaj> You need to be able to trivially bind C++ libraries though
02:08:55 <thoughtpolice> kmc: i've never heard anybody at work seriously shit-talk haskell for being impractical, not even my boss
02:08:57 <danharaj> or it wouldn't catch on.
02:09:04 <kmc> thoughtpolice, i'm impressed
02:09:20 <kmc> though what i meant is not "it's impractical" but literally refusing to believe that the code is compilable
02:09:33 <kmc> there's some old paper which is an experience report from a design competition
02:09:36 <thoughtpolice> at my interview my boss was more like "could you write this in C please, not haskell lol. i just need to be sure you won't pull a fast one"
02:09:42 <kmc> and they said that a lot of the judges thought the Haskell code was non-executable specification
02:10:09 <kmc> anyway this claim is easy to refute if you have a computer ;)
02:10:24 <danharaj> or lambdabot :p
02:10:25 <thoughtpolice> kmc: one of my favorites @ work was something about needing to do network protocol parsing, but have the parser be resumable so if the socket blocks it can pick up where it left off
02:10:44 <thoughtpolice> my solution: 10 minutes later, using attoparsec. result: 3 lines of code, 1 of which was a type declaration :P
02:10:50 <kmc> nice
02:11:09 <kmc> isn't that the sort of problem which is solved automatically by having non-shitty threads?
02:11:26 <kmc> C and C++ programs are full of weird control-flow inversions when they could just fire off threads and let them block
02:11:45 <kmc> (except that this is both hard and slow typically)
02:11:48 <Baughn> Pretty much. You could even use non-shitty threads in C...
02:12:19 <Baughn> There *are* lightweight thread libraries around for it.. not quite as lightweight as GHC's, but usually still good enough
02:12:23 <kmc> yeah
02:12:27 <kmc> they're not popular though
02:12:29 <thoughtpolice> I actually think I have haskell to thank for my job, now that It hink about it
02:12:44 <danharaj> thoughtpolice: Because it's like a badge of intelligence?
02:12:46 <kmc> people think "threads = slow" to the extent that Go had to invent a ridiculous new term for them, for marketing reasons
02:12:57 <kmc> i have Haskell to thank for quitting my last job
02:12:58 <kmc> partially
02:13:04 <danharaj> Go threads are heavier than Haskell aren't they?
02:13:12 <kmc> heavier than GHC?
02:13:16 <danharaj> well yeah
02:13:20 <danharaj> that's what I meant
02:13:20 <thoughtpolice> danharaj: nope, my coworker who praised me prior to my interview and recommended my resume etc. found me @ school one day, because he was looking into haskell work as a part of his masters thesis
02:13:23 <kmc> also going from "work whenever you want" to "come in 08:30 sharp", that sucked
02:13:32 <thoughtpolice> so he came and found me one day because I do work on LHC occasionally
02:13:53 <thoughtpolice> several months later I gave him my resume and I was hired the next day
02:14:03 <kmc> danharaj, i don't know
02:14:23 <danharaj> then let us assume in our arrogance that the GHC people are totally better than the Go people.
02:14:34 <kmc> yes
02:14:35 <kmc> totally
02:14:43 <kmc> what did the Go people ever accomplish anyway
02:14:46 <thoughtpolice> so somewhat indirectly, yes, haskell is directly responsible for me having a very nice job right now :)
02:14:55 <danharaj> Go is just an Algol dialect anyway.
02:14:56 <thoughtpolice> Go has some very strange semantics
02:15:15 <thoughtpolice> the good thing is they probably have time left to change lots of these things if they wish
02:15:22 <thoughtpolice> whether or not they will, well, jury's out on that one
02:16:12 <thoughtpolice> here's a perplexing example: you cannot copy a container (even if it's a built in generic container like map.) there is no copy semantics for containers, why? because types like map are a built in reference type
02:16:22 <fasta> thoughtpolice, where do you work now?
02:16:23 <thoughtpolice> want to copy that map? write a loop and construct a new map from it
02:16:39 <danharaj> It's like the language is trying to be a dick to you
02:17:12 <thoughtpolice> fasta: I work @ a small company (~8 engineers, 40 people total maybe) writing data backup software
02:17:27 <roconnor> thoughtpolice: do you work in Haskell?
02:17:33 <thoughtpolice> nope
02:17:54 <fasta> thoughtpolice, what's wrong with rsync or unison? Or is this for certified backup or something like that? 
02:17:56 <thoughtpolice> me & my other coworker (haskell afficianado) pretty much yell out at work every day about why/how C++/Java totally suck though
02:18:14 <roconnor> :)
02:18:26 <thoughtpolice> fasta: we do backups at the block level on volumes
02:18:38 <roconnor> do you use -Weff-c++ or whatever that flag is called?
02:18:58 <thoughtpolice> i like to think that stands for 'fuck C++' myself
02:19:05 <fasta> thoughtpolice, what's a "volume" (tape)?
02:19:08 <thoughtpolice> but I think so, i'd need to look at our build system
02:19:16 <thoughtpolice> fasta: basically just any device with a filesystem on it
02:19:32 <roconnor> I've been told that that flag makes c++ more usable, though i haven't used c++ since learning this
02:19:45 <roconnor> others have said the flag gives too many warnings
02:19:47 <thoughtpolice> fasta: there are somewhat more complicated scenarios, but essentially block level backups on any regular filesystem
02:19:58 <fasta> thoughtpolice, ah, so it is much faster than using the FS api.
02:20:12 <roconnor> since I'm a retarded programmer, I need as many errors as possible
02:20:15 <thoughtpolice> yes, it's basically just reading a ton of data from one file
02:20:18 <roconnor> that's why I like Haskell!
02:20:24 <roconnor> I even get big hard to read errors :P
02:20:38 <danharaj> ghc has terrible type errors
02:20:54 <danharaj> I pity the fool who gets a 'type less polymorphic than expected' error
02:20:58 <thoughtpolice> fasta: practical implications - a) with some work, we can do block-level diffing and make backups very small. also, b) because we have a consistent view of the FS at the time of backup, we can do things like analyze NTFS files, and restore file ACLs when you choose to restore files, etc
02:21:40 <thoughtpolice> even though typically you can't do this if you just backup with a copy of a file, because security descriptors for NTFS reside on a very special part of the filesystem that is not visible to the user or average developer
02:21:50 <thoughtpolice> and totally undocumented, btw
02:21:56 <thoughtpolice> that took a couple months to hammer out all those bugs
02:22:09 <fasta> thoughtpolice, ah, I can see that could be useful. It is basically just solving the "how to do large backups"-problem. 
02:22:18 <thoughtpolice> yep
02:22:50 <thoughtpolice> work is very challenging at least, goes from kernel drivers -> network protocols -> web interfaces and everywhere inbetween
02:22:59 <thoughtpolice> there are some monotonous parts however, naturally
02:23:41 <kmc> GHC has some hilariously bad advice in its errors
02:23:50 <kmc> "Probable fix: add an instance for (Num (a -> b))"
02:24:05 <thoughtpolice> "my brain just exploded"
02:24:21 <ski> @ghc
02:24:22 <lambdabot> ghc says: ARGH! Jump uses %esi or %edi with -monly-2-regs
02:24:49 <Jafet> Serves you right for only using two regs.
02:25:08 <kmc> serves you right for using a computer with only six regs
02:25:13 <thoughtpolice> god help the register starved
02:25:17 <Baughn> Serves you right for using a computer
02:26:29 <thoughtpolice> computers = ultimate hate machine
02:26:46 <soupdragon> haskell = internet coffee phone
02:27:00 <fasta> Why aren't there consumer machines with a few 100 registers on the market? 
02:27:18 <fasta> I don't see why it would cost that much more to produce them. 
02:27:26 <kmc> that's not the issue
02:27:28 <danharaj> All hail the x86
02:27:35 <kmc> your average x86 implementation has hundreds of registers behind the scenes
02:27:39 <kmc> and maps onto them dynamically
02:27:46 <fasta> There are millions of people that don't care about x86 anymore. 
02:27:56 <kmc> it's just that the ISA is retarded and we're all stuck with it
02:27:59 <kmc> for compatibility
02:28:04 <kmc> fortunately x86_64 is less retarded
02:28:11 <Baughn> Only one bit less retarded
02:28:12 <danharaj> Maybe if you went to Intel and AMD and went
02:28:19 <danharaj> "Come on" a lot
02:28:20 <Baughn> ..why didn't they make it 64 registers?
02:28:22 <danharaj> they would cave.
02:28:32 <kmc> physically i think there's not much difference between registers and L1 cache
02:28:37 <kmc> and we have lots of L1 cache now
02:28:47 <kmc> it's just a question of who manages that memory
02:29:04 <danharaj> I thought registers were even faster than L1 cache
02:29:12 <kmc> and whether they're shared between threads
02:29:16 <kmc> yeah i don't know really
02:29:17 <fasta> kmc, so all the register allocator algorithms are basically worthless according to you. 
02:29:22 <kmc> but they're all on-chip SRAM
02:29:23 <kmc> fasta, ?
02:29:45 <danharaj> yeah, but I dunno how much room you have for memory fast enough to be registers.
02:30:02 <kmc> is fast memory bigger on-die?
02:30:08 <kmc> given that it's already SRAM?
02:30:14 <fasta> kmc, algorithms that decide whether a certain variable needs to be kept in a register or not. 
02:30:20 <kmc> fasta, i know what register allocators are
02:30:26 <danharaj> kmc: I have no idea, I just assume registers are faster because they are closer to the logic
02:30:33 <danharaj> I know most of a die is usually taken up by L1 cache.
02:30:34 <kmc> i've no idea where your claim comes from
02:30:47 <kmc> ah
02:30:55 <danharaj> honestly
02:31:03 <danharaj> I just want a reduceron that runs at 2 ghz
02:31:08 <danharaj> just to see how awesome it is
02:31:21 <fasta> kmc, you basically say that L1 and registers are about as fast. That would imply it doesn't matter whether or not you allocate registers in a sane way. 
02:31:24 <danharaj> maybe we can convince Intel to add it as a coprocessor :p
02:32:12 <danharaj> fasta: I think the issue has reduced in importance over the decades. Accessing L1 cache takes like 15 cycles on a Core2Duo
02:32:15 <kmc> fasta, under some unrealistic assumptions about cache structure, yes
02:32:28 <kmc> it's all fucking satanic dark magick anyway
02:32:33 <kmc> drawing patterns on stones to make them think
02:32:39 <fasta> I like Forth CPUs. 
02:32:40 <danharaj> yeah really
02:32:41 <Cthulhon|> L1 cache usually takes between four and ten cycles in modern CPUs.
02:32:45 <Cthulhon|> Just FYI.
02:32:54 <danharaj> Cthulhon: Whatever
02:32:56 <Cthulhon|> Compare with memory at a few hundred cycles.
02:32:58 <kmc> using potions and casting patterns of light
02:33:02 <danharaj> what about Register latency?
02:33:02 <kmc> Cthulhon|, why does it take so long?
02:33:45 <danharaj> keep in mind the last time I was curious about processor architectures was like two years ago.
02:33:46 <Cthulhon|> It's not really that L1 cache is slow so much as it is that everything else can be faster.
02:33:59 <Baughn> Cthulhon|: What're the numbers for L2 and L3 cache, then?
02:34:07 <Cthulhon|> So the logical thing to do is to let things like the execution units run faster.
02:34:20 <Cthulhon|> Because data is often in registers anyway.
02:34:32 <ville> That Java dude with a funny name, I think Click, had a pretty good presentation about what happens on a modern CPU.
02:34:35 <Baughn> And thus, we need more registers. ;)
02:34:41 <Cthulhon|> I don't know about L3 offhand.  L2 is usually tends of cycles.
02:34:44 <danharaj> 400 hundred registers
02:34:47 <Cthulhon|> *tens
02:34:54 <chrisdone> anyone ever got "user error (FCGX_PutStr failed with error code: -1)" with the FastCGI library?
02:35:13 <Cthulhon|> You're thinking of Cliff Click, ville.
02:35:15 <danharaj> that
02:35:18 <danharaj> hundred is redundant >_<
02:35:24 <Cthulhon|> It was an InfoQ presentation, IIRC.
02:35:44 <kmc> so what is the cache logic doing that requires cycles?
02:35:45 <Baughn> danharaj: No.. no it's not
02:35:53 <kmc> address comparison and output latching?
02:35:56 <chrisdone> it seems that after X requests per second, lighttpd silently cuts the connection to the FastCGI process because FCGX_PutStr only fails with EOF
02:36:13 <Baughn> danharaj: If you remove the "hundred", I'd get the impression there are just 400 registers, when there are /actually/ 40,000.
02:36:41 <Cthulhon|> kmc: That and the cache memory is just physically further away.  Even at the scale of a CPU the distance can matter when going at many billions of cycles per second.
02:36:52 <danharaj> Baughn: I think ~40,000 registers might be a bit excessive, unless we're doing some serious SIMD crunching.
02:36:55 <kmc> or does "everything else can be faster" imply that there's a physical switching speed issue, and therefore effectively that cache runs on a clock divider?
02:37:08 <danharaj> kmc: the speed of light is a bitch.
02:37:14 * roconnor was promised clockless cpus by now
02:37:20 <kmc> a light-nanosecond is like a foot though
02:37:27 <Cthulhon|> It's a combination of factors, and physical speed is definitely one of them.
02:37:33 <ville> http://www.infoq.com/presentations/click-crash-course-modern-hardware here is Cliff Click's representation, it talks what happens on x86.
02:37:45 <kmc> almost exactly a foot
02:37:50 <danharaj> kmc: I don't think electrons flow through a silicon chip as fast as the speed of light though, just saying there is a physical limitation.
02:37:54 <Cthulhon|> That presentation mostly talks about how x86 deals with complete ache misses, IIRC.
02:37:55 <kmc> it's true
02:38:07 <Cthulhon|> *cache
02:38:20 <Cthulhon|> Which is an interesting subject.
02:38:26 <kmc> a crash course in modern hardware, for java programmers
02:38:29 <ville> Cthulhon|: yes that comes towards the end but it also highlights the part that you can't really tell what happens.
02:38:30 * kmc could make so many mean comments
02:38:34 <ville> kmc: it isn't Java specific at all.
02:39:08 <Cthulhon|> Anyway, CPUs already have tons of registers aside from the GPRs you see.
02:39:30 <Cthulhon|> Even within x86, which is notoriously register starved, there are tons of background state registers.
02:39:42 <Cthulhon|> Throwing in more GPRs is not a problem, from a chip design point of view.
02:40:08 <Cthulhon|> But AMD barely managed to fit 8 more in x64 with the crazy encoding x86 has.
02:40:39 <Baughn> Why would they want to stick with that encoding?
02:40:55 <fasta> Isn't it  a trade-secret to know how specific brand CPUs work internally? 
02:41:12 <Cthulhon|> Because no one wants to invest in another Itanium, I guess.
02:41:48 <Cthulhon|> Itanium even had emulated compatibility and failed.
02:42:02 <fasta> Itanium was a failure because there was no reason for a consumer to buy one.
02:42:17 <kmc> there were specific technical problems too
02:42:18 <fasta> And consumers had to do extra effort to do so.
02:42:32 <kmc> not sure which consumers you mean
02:42:39 <kmc> i don't think they ever targetted joe pc
02:42:46 <danharaj> We await the coming of the reduceron's sucessor.
02:42:46 <kmc> it was for HPC and for replacing pa-risc on HP's workstations
02:43:15 <danharaj> All hail the savior who will emancipate us from the Von Neumann prison.
02:43:17 <fasta> kmc, I am pretty sure I could order them too via a webshop. 
02:43:35 <kmc> yeah but that's not what they were counting on for success
02:43:46 <Cthulhon|> In a perverse sense, I am glad that x86 refuses to die.  It's a lot more interesting than some boring RISC ISA.
02:43:53 <kmc> hehe
02:44:07 <fasta> kmc, an entire architecture for a relatively small market seems to be a bad idea, anyway. 
02:44:16 <kmc> yeah well, it was
02:45:52 <Cthulhon|> Anyway, with x64, AMD appropriated the opcode for DEC for a prefix byte, of which the lower four bits are extensions to the existing instruction encoding's Mod/RM byte for register specifications.  Specifically, that byte is extended by one bit, which is why the register count basically doubled.
02:46:08 <Cthulhon|> There are a few other issues with the Mod/RM encoding, but that's the big picture.
02:46:25 <danharaj> I find Intel and AMD's instruction set wars amusing.
02:46:29 <Cthulhon|> If someone would knock off another one byte opcode, we could have 32 GPRs.
02:46:53 <Jafet> But the STG only needs... four!
02:46:57 <Jafet> (Right?)
02:47:10 <danharaj> STG?
02:47:12 <Jafet> As usual, we are ahead of the curve
02:47:18 <danharaj> G machine?
02:49:23 <MigoMipo> @pl \a b c d e -> (d a b, e c)
02:49:24 <lambdabot> flip flip (flip id) . (((.) . flip . (((.) . (,)) .)) .) . flip . flip id
02:51:32 <kmc> why didn't they just make a new mode for the processor with a totally different encoding?
02:52:22 <Itkovian> nobench (http://code.haskell.org/nobench/) still features Data.ByteString.Base. Are these function now available through Data.ByteString?
02:53:14 <Cthulhon|> kmc: x64 is a totally new mode.
02:53:17 <Cthulhon|> Long mode.
02:53:27 <kmc> 's what i thought
02:53:28 <Cthulhon|> As opposed to protected mode being the standard mode with x86.
02:53:43 <Cthulhon|> And the encoding is changed, just not much.
02:53:43 <kmc> so why the contortions to make a new prefix byte?
02:54:36 <Cthulhon|> Presumably because most x86 tools like compilers could be updated very easily.
02:54:54 <Cthulhon|> You just have to avoid using DEC in the instructions you emit and everything else just works.
02:55:06 <Cthulhon|> And DEC still has two-byte encodings.
02:55:13 <Cthulhon|> So again, not much work.
02:55:23 <theorbtwo> ...and it's not like there's not a half-million ways to subtract one from a register.
02:55:27 <Cthulhon|> As opposed to something like Itanium where you have to write a whole new backend.
02:56:42 <kmc> sure but that's because itanium is way the hell different semantically
02:56:42 <Cthulhon|> True.
02:56:43 <kmc> encoding is basically the syntax of machine code, and should be a pretty simple no matter what
02:56:47 <Cthulhon|> But even a similar ISA with a whole new encoding would need a new backend.
02:56:53 <Cthulhon|> A backend written from scratch.
02:57:14 <kmc> it would need a new table in an existing multiplatform assembler
02:57:26 <danharaj> surely using LLVM would make writing such a backend much easier.
02:57:53 <kmc> it seems that modifying the thing generating assembly to take advantage of x64
02:57:53 <Cthulhon|> Well, LLVM didn't exist when x64 was designed.
02:58:00 <danharaj> True.
02:58:02 <Cthulhon|> or if it did it had barely started.
02:58:09 <kmc> and modifying the assembler to understand x64 assembly
02:58:21 <kmc> is way the hell harder than making the assembler output bytes which are a lot different as opposed to a little different
02:59:35 <fasta> http://www.nicta.com.au/education/scholarships/sydney_research_lab/scholarship_opportunities_at_the_university_of_sydney
02:59:35 <Cthulhon|> We can only speculate as to what the AMD engineers were thinking.
03:00:07 <Cthulhon|> The encoding for x64 is pretty terrible, even compared to x86.
03:00:14 <danharaj> I am convinced Intel and AMD are in a contest of who can make x86 worse.
03:01:06 <Cthulhon|> You need the REX prefix everywhere to access the new GPRs, and with 8 byte immediate addresses, instructions tend to be huge.
03:01:22 <kmc> which makes I-cache less effective
03:01:48 <Cthulhon|> It used to be hard to hit the 15 byte instruction size limit, but not anymore.
03:01:49 * hackagebot hakyll 2.2.1 - A simple static site generator library.  http://hackage.haskell.org/package/hakyll-2.2.1 (JasperVanDerJeugt)
03:02:05 <danharaj> 15 bytes for an instruction? O_O
03:02:29 <kmc> how big is a typical 64-bit RISC instruction?
03:02:34 <Cthulhon|> You can write longer ones, but they cause an exception.
03:02:36 <kmc> 10 bytes?
03:02:47 <Cthulhon|> I believe the longest x86 instruction that still makes some amount of sense (i.e. no redundant prefixes) is 17 bytes, though.
03:03:04 <Cthulhon|> It can never be executed, but it is a valid instruction in the x86 encoding.
03:03:18 <kmc> is the 15-byte limit a documented part of the ISA?
03:03:19 <danharaj> That thing better do my taxes
03:03:21 <Cthulhon|> Yes.
03:03:23 <kmc> haha
03:04:13 <Cthulhon|> Not only do larger instructions hurt the i-cache, but they also hurt the i-TLB.
03:04:52 <Cthulhon|> x64 is not always faster than x86 because of the huge instructions and the effect they can have on a program.
03:05:04 <kmc> yeah
03:05:09 <kmc> but it's often faster, due to decreased register pressure
03:05:15 <kmc> much more often than sparc64 is faster than sparc
03:05:52 * hackagebot web-routes-quasi 0.4.0 - Define data types and parse/build functions for web-routes via a quasi-quoted DSL  http://hackage.haskell.org/package/web-routes-quasi-0.4.0 (MichaelSnoyman)
03:06:08 <Cthulhon|> Intel is still jamming new instructions into the ISA too.
03:06:17 <Cthulhon|> SSE5 has a CRC32 instruction.
03:06:23 <danharaj> wtf
03:06:24 <Cthulhon|> And they have various AES instructions planned.
03:06:30 <danharaj> does that really need to be an instruction?
03:06:46 <cozachk> doesnt hurt :( 
03:07:07 <danharaj> except it does :|
03:07:29 <cozachk> how does it hurt? 
03:07:40 <danharaj> too many instructions adds more overhead
03:07:46 <Cthulhon|> When you get to things like SSE5, the encoding becomes even more crazy because of the prefixes required.
03:08:13 <danharaj> I imagine them as elaborate as those really long moves in Street Fighter
03:08:15 <Cthulhon|> So not only do you have a totally crazy way of encoding the registers, and the memory used, but you have crazy ways of even specifying the basic opcode.
03:08:26 <cozachk> the encoding for the opcodes? 
03:09:35 <cozachk> cisc killed da risc  
03:09:43 <danharaj> Sup dawg, we heard you liked complicated processors, so we put encodings on your encoding so you can decode while you decode.
03:10:40 <cozachk> so its kinda like segmented memory all over again just with segmented instruction sets? 
03:10:46 <kmc> they're doing it all wrong
03:11:00 <kmc> they should have the ALU communicate with the instruction decoder over JSON RPC
03:11:00 <Cthulhon|> I'm not sure I see the analogy, cozachk.
03:11:17 <kmc> they need to use, nay, /leverage/ Web standards
03:11:48 * cozachk has had lil sleep so he really doesnt make too much sense right now 
03:11:59 <Cthulhon|> I suppose the argument for CRC32 is that if you offload the NIC processing to the CPU in something like a netbook, you're going to want to do CRC32 very fast.
03:12:11 <Cthulhon|> You need to CRC32 every Ethernet packet.
03:12:35 <danharaj> fair enough
03:12:38 <kmc> winmodems all over again
03:12:43 <theorbtwo> ...or you can keep using dirt cheap ethernet chips.
03:12:49 <kmc> i can't imagine ethernet silicon is that expensive now
03:12:56 <Cthulhon|> Although, you an do the CRC32 as a running calculation while you shove the bits to the actual Ethernet interface.
03:13:07 <Cthulhon|> So it's not a great justifcation.
03:13:16 <theorbtwo> I think a bigger thing is for use in https and the like.
03:13:20 <Cthulhon|> *can
03:13:26 <theorbtwo> Lots of things use crc32 for lots of reasons.
03:13:26 <Cthulhon|> Could be.
03:13:50 <kmc> Welcome to Sun Microsystems, can I take your order please?
03:13:54 <kmc> Would you like fries with that?
03:14:07 <cozachk> SUPERsize m3!!!
03:14:18 <Cthulhon|> Well, Ethernet is the only mainstream protocol between layers 1 and 6 that uses CRC32, AFAIK.
03:14:32 <Cthulhon|> IP, TCP, and UDP all use the 'internet checksum'.
03:15:04 <Jafet> Is there a checksum instruction, then?
03:15:05 <Cthulhon|> Which is just adding up all the 4-byte wide words in the packet.
03:15:13 <Cthulhon|> Not that I'm aware of, Jafet.
03:15:25 <Cthulhon|> There is an add instruction.
03:15:30 <Cthulhon|> maybe they thought that sufficed.
03:16:17 <Jafet> Also, via c7 has had AES for a while now, probably as a gimmick
03:16:27 <Cthulhon|> I'd actually be surprised if HTTPS used CRC32, given how useless it is cryptographically.
03:16:58 <danharaj> So how many instructions is SSE5 adding anyway/
03:17:15 <Cthulhon|> I think it was like twenty, but I'd have to pull out the manuals.
03:17:28 <kmc> i think my favorite instruction ever is "Halt and Catch Fire"
03:18:07 <Cthulhon|> I've written x86/x64 disassemblers before, but that was before SSE5, and I haven't had the occasion to update them or look much at SSE5 other than taking note of the CRC32 instruction.
03:18:20 <Jafet> HCF is so meta
03:18:41 <kmc> oh?
03:19:09 <danharaj> In comparison to x86, the reduceron has 5 instructions :p
03:19:35 <kmc> 1) compute factorial
03:19:40 <kmc> 2) interpret untyped lambda calculus
03:19:55 <kmc> 3) argue with Lisp users
03:20:12 <kmc> what are the other two?
03:20:23 <danharaj> 4) unsafeCoerce
03:20:32 <kmc> 5) monad tutorial
03:20:34 <theorbtwo> 5) Halt.
03:20:56 <Jafet> Halt is only found on the German "von Neuman" models.
03:20:57 <theorbtwo> Every processor needs a halt instruction.  Otherwise, you might be able to solve the halting problem.
03:21:26 <danharaj> but srsly
03:21:51 <Jafet> I just had the idea for a modal processor
03:22:17 <Cthulhon|> x86 is already modal.
03:22:22 <theorbtwo> Jafet: Er, different from ARM's arm mode / thumb mode?
03:22:36 <Cthulhon|> Long mode, real mode, protected mode, virtual 8086 mode...
03:23:03 <Cthulhon|> SMM mode.
03:23:28 <danharaj> If something like the reduceron were fabricated instead of programmed into a FPGA, who knows how fast Haskell would be compared to C
03:23:36 <danharaj> (on that platform)
03:24:26 <cozachk> you would still have the memory bottleneck though wouldnt you? 
03:24:27 <Jafet> Something more like rewritable microcode
03:24:40 <kmc> i think the way to go is memristor computers
03:24:44 <kmc> memory and computation unified
03:24:52 <kmc> then run your massively parallel haskell program
03:25:01 <Jafet> But how would you upgrade ram
03:25:03 <kmc> when you create a spark, that chunk of memory just reconfigures itself to a processor
03:26:29 * cozachk kmc get out of my head 
03:27:46 <Cthulhon|> That idea is reminds me of Henry Massalin's Synthesis OS, Jafet.
03:27:57 <Cthulhon|> Which would rewrite itself on the fly for speed.
03:28:14 <Jafet> A security disaster.
03:28:22 <Cthulhon|> E.g. it would generate a custom read function after an open of a file.
03:28:30 <Cthulhon|> To make it as fast as possible.
03:28:45 <Cthulhon|> A security playground. :D
03:29:21 <danharaj> pff
03:29:28 <danharaj> we just need to start using verified code
03:29:30 <Cthulhon|> Things will be boring once we have perfect security, just like things would be boring if we had a perfect ISA.
03:29:44 <cozachk> isa?
03:29:55 <Cthulhon|> Instruction set.
03:30:13 <fasta> Isn't it instruction set architecture?
03:30:21 <Cthulhon|> Yes.
03:30:29 <Cthulhon|> I was eliding the last word for simplicity.
03:30:42 <Jafet> We're all simple here
03:30:58 <Cthulhon|> Anyway, I could be biased about the security thing since I'm a security person.
03:31:08 <Cthulhon|> But I will still be sad once nothing can be pwned.
03:31:14 <Jafet> danharaj, http://raw.cs.berkeley.edu/pcc.html
03:31:23 <Jafet> Humans can be pwned, as always
03:33:20 <Sadache> do anyone here know of an API that would go through Text.Html structure and change/remove/add some elements?
03:34:11 <Sadache> something like JQuery for Text.Html?
03:35:14 <kmc> Sadache, might be something you could do with Scrap Your Boilerplate
03:35:16 <kmc> @where syb
03:35:17 <lambdabot> http://www.cs.vu.nl/boilerplate
03:35:23 <kmc> err dead link
03:35:25 <kmc> but it can be googled
03:35:50 <kmc> Uniplate is another generic programming library
03:37:04 <Cthulhon|> A fun fact related to x86 and Henry Massalin is that Henry Massalin invented the superoptimizer (not to be confused with supercompilation), which tries to generate the most efficient sequence of instructions for a function by brute force.
03:37:37 <Cthulhon|> It found a two instruction encoding for abs(), for example.
03:37:50 <danharaj> haha what
03:37:51 <Cthulhon|> Which GCC now uses, in fact.
03:38:08 <Cthulhon|> Hm, actually, that might have been a two instruction encoding for signum.
03:38:15 <Cthulhon|> I'd have to check the paper.
03:39:09 <Cthulhon|> Henry Massalin is a very interesting person.
03:39:23 <Cthulhon|> There's a Wired profile of him which is interesting reading.
03:41:29 <Cthulhon|> Well, the original paper has signum in three instructions.
03:41:47 <Cthulhon|> cwd / neg ax / adc dx, dx
03:41:51 <fasta> Cthulhon|, in what year did he do that?
03:42:14 <fasta> Cthulhon|, he might have written the program, it probably was not a new idea or the first implementation. 
03:42:20 <Cthulhon|> ACM says copyright 1987.
03:42:36 <Cthulhon|> So I assume the research was done a year or two prior.
03:43:10 <ndxtg> http://codepad.org/wPP6R6cY <---- is there any better solution for this function??? I think monad may do the trick but I dont know how to
03:43:16 <Cthulhon|> fasta: Do you know of work earlier than that?
03:43:30 <fasta> Cthulhon|, heuristics to do that (program search already existed at the time), it seems that brute-force was kind of obvious for those people.
03:43:52 <fasta> Cthulhon|, Levin search was also earlier, I think.
03:44:06 <kmc> ndxtg, use a real html combinator library
03:44:14 <kmc> there are several; i don't know which is good
03:44:21 <fasta> Cthulhon|,  (1973, 1984) according to Wikipedia.
03:44:26 <Cthulhon|> Interesting.
03:44:37 <kmc> ndxtg, just by looking at this code visually you can see a pattern
03:44:47 <kmc> so how about defining a new function
03:44:52 <kmc> f n Nothing = ""
03:44:53 * fasta believes everything has already been invented in a certain sense ;)
03:45:07 <kmc> f n (Just x) = n ++ "=" ++ x
03:45:18 <kmc> you can also define that in terms of:
03:45:19 <kmc> :t maybe
03:45:24 <lambdabot> forall b a. b -> (a -> b) -> Maybe a -> b
03:45:37 <kmc> :t maybe "" ("foo="++)
03:45:40 <lambdabot> Maybe [Char] -> [Char]
03:45:46 <kmc> then you can do such as
03:46:06 <kmc> unwords $ zipWith f ["name","size"] [name, show size]
03:46:26 <kmc> (probably want to pick a better name than 'f' but i'm lazy)
03:47:24 <ndxtg> kmc: so monad cannot be used in this case?
03:48:01 <fasta> Cthulhon|, a super computer running Levin search day and night probably runs at the NSA ;)
03:48:10 <Cthulhon|> It seems that Massalin used a novel method for pruning the tree of all possible programs, making the use of his superoptimizer more practical.  Whereas Wikipedia seems to suggest that Levin search was not a practical thing to do until later researchers provided refined implementations of the idea, post-dating Massalin's work.
03:48:31 <fasta> Cthulhon|, I doubt they do the same thing. 
03:48:45 <Cthulhon|> No, probably not.
03:49:24 <fasta> Cthulhon|, Levin search can come up with algorithms who's correctness cannot be showed.
03:49:37 <kmc> ndxtg, i won't say it can't, it doesn't seem natural to me
03:49:43 <kmc> ndxtg, you mean the Monad instance for Maybe?
03:50:24 <kmc> ndxtg, that's useful when you want to propagate Nothings, as if you were propagating errors
03:50:28 <kmc> that's not the case here
03:50:29 <fasta> Cthulhon|, that is, it happens to return the right answer every single time, but there is no way using mathematics to show this unless you are talking about finitely sized inputs. 
03:50:36 <kmc> you want to turn Nothing into a string, and Just into a different string
03:50:42 <kmc> but you can still abstract this pattern, with a helper function
03:50:46 <ndxtg> kmc: oh i see
03:50:53 <Cthulhon|> Yes, I inferred as much, fasta.
03:51:18 <kmc> ndxtg, a good hint is that you're looking for a function of type (Maybe String -> String), but there's no function which does that for *all* monads
03:51:26 <kmc> i.e. there's no function of type (Monad m) => m a -> a
03:51:37 <kmc> it's a common misconception that this means all monads are "one-way"
03:51:38 <Cthulhon|> I'm not sure I can quite see the proof of that, though.
03:51:52 <Cthulhon|> I can imagine the start of an approach to a proof, I guess.
03:51:54 <SailorReality> anyone know why I cant use function name in quotes between arguments like 5 'mod' 2 doesnt work says lex error
03:52:01 <kmc> SailorReality, you need backticks
03:52:02 <kmc> `
03:52:06 <kmc> > 5 `mod` 2
03:52:12 <lambdabot>   mueval-core: Time limit exceeded
03:52:16 <kmc> oh what the fuck
03:52:21 <kmc> @slap lambdabot
03:52:22 * lambdabot places her fist firmly on lambdabot's jaw
03:52:46 <SailorReality> backticks?
03:52:55 <kmc> ndxtg, but what it tells you is that you can't extract values from a monadic type using *only* the Monad interface.  you have to use some function specific to your particular monad
03:52:56 <kmc> yes SailorReality
03:53:08 <kmc> the character `
03:53:12 <kmc> which is not the same as
03:53:13 <kmc> the character '
03:53:25 * ski wonders whether ndxtg wants `catMaybes'
03:53:26 * SailorReality searches keyboard
03:53:31 <kmc> upper left corner
03:53:32 <SailorReality> oh found it
03:53:33 <kmc> usually
03:53:33 <SailorReality> nice
03:53:53 <SailorReality> how have i been on the computer for 10 years straight and am still this computer illeterate
03:55:09 <fasta> illeterate? 
03:55:13 * fasta ducks
03:56:06 <kmc> > 5 `mod` 2
03:56:09 <lambdabot>   1
03:56:18 <kmc> lambdabot is a bit sluggish this morning
03:56:35 <kmc> somebody's got a case of the mondays
03:56:49 <Botje> except it's tuesday
03:56:55 <Botje> which is /worse/ than a monday!
03:57:43 <kmc> yeah tuesday is actually the worst
04:03:56 <alpha_> I need help with the following: At the section "A simple program" from here (http://book.realworldhaskell.org/read/getting-started.html) I am trying to run the code but I get the following errors: http://pastebin.com/3AJfFyye
04:04:20 <kmc> alpha_, that's a command for the system command line
04:04:21 <kmc> not for ghci
04:05:32 * hackagebot persistent 0.0.0 - Type-safe, non-relational, multi-backend persistence.  http://hackage.haskell.org/package/persistent-0.0.0 (MichaelSnoyman)
04:05:34 * hackagebot persistent-postgresql 0.0.0 - Backend for the persistent library using postgresql.  http://hackage.haskell.org/package/persistent-postgresql-0.0.0 (MichaelSnoyman)
04:06:32 * hackagebot persistent-sqlite 0.0.0 - Backend for the persistent library using sqlite3.  http://hackage.haskell.org/package/persistent-sqlite-0.0.0 (MichaelSnoyman)
04:07:04 <ketil> Anybody using CmdArgs here? 
04:07:07 <ketil> @seen ndm
04:07:09 <lambdabot> Unknown command, try @list
04:07:17 <ketil> preflex: @seen ndm
04:07:17 <preflex>  ndm was last seen on #haskell 1 year, 44 days, 48 minutes and 36 seconds ago, saying: plus with current compiler technology, it would be slower
04:07:31 <ketil> Okay... I guess it's no use waiting around...
04:08:03 <ketil> Why can't I use a value of Maybe String?  Is there some inherent limitation of Data or Typeable?
04:08:21 <ketil> (and if so, why do I get a run-time error?)
04:12:33 * hackagebot yesod 0.3.0 - Creation of type-safe, RESTful web applications.  http://hackage.haskell.org/package/yesod-0.3.0 (MichaelSnoyman)
04:13:59 <byorgey> alpha_: runghc WC < quux.txt  is meant to be typed at a command line prompt, not the ghci prompt
04:15:36 <alpha_> byorgey, oh, thanks. I guess this is a bit embarrassing hehe
04:16:44 <SailorReality> is there an extension of fst and snd to n-tuples like thd and fth etc
04:16:52 <soupdragon> byorgey, what's an infinite number of variables in a power series for?
04:16:52 <Botje> nope :(
04:17:11 <kmc> SailorReality, in the "tuple" library on Hackage
04:17:16 <kmc> but it probably means you're doing something wrong
04:17:26 <SailorReality> i want to make a dot product function
04:17:28 <kmc> you can take apart tuples with pattern-matching instead
04:17:42 <kmc> > sum $ zipWith (*) [1,2,3] [4,5,6]
04:17:46 <lambdabot>   32
04:17:46 <fasta> SailorReality, unless it is homework, you don't want that. 
04:17:48 <kmc> ^^^ lists, not tuples
04:17:51 <SailorReality> thanks
04:28:17 <Itkovian> Any idea how to fixor this: Control.Exception.handle (const $ return []) so that it typechecks?
04:28:31 <trin_cz> Hi all! I just realized I can prevent unintended loops by using an Identity monad (instead of let/where). Now, can I get rid of the ubiquitous returns?
04:29:38 <soupdragon> trin_cz, I don't know the answer to your question but how what are you using the identity monad for that souds really neat
04:31:17 <trin_cz> soupdragon: yes, I'm also excited ... I never thought it can be useful.
04:33:27 <roconnor> trin_cz: you can get unintended loops back if you use mdo :P
04:34:08 <roconnor> trin_cz: anyhow, to answer your question, use the applicative functor interface perhaps.
04:35:26 * trin_cz is reading control.applicative ... again
04:36:29 * roconnor is sort of guessing here
04:37:31 <roconnor> trin_cz: maybe if you posted an example
04:39:16 <trin_cz> roconnor: here goes ...
04:39:24 <trin_cz> result :: Identity Int
04:39:26 <trin_cz> result = do
04:39:27 <trin_cz>     a'' <- return $ a' + 1
04:39:29 <trin_cz>     a'  <- return 1
04:39:30 <trin_cz>     return a''
04:39:42 <ketil> Hm.  You're using the identity monad's do as an non-recursive let?
04:39:55 <trin_cz> ketil: yes
04:40:07 <trin_cz> but I want the returns to go away
04:40:47 <ketil> Use Ocaml?  Or some other language with both let and letrec.
04:41:04 <ketil> :-)
04:41:55 <trin_cz> ketil: ok, I didn't make it clear ... I want the returns to go away in haskell ;-)
04:42:18 <roconnor> ketil: better that ocaml, you can use nested lets
04:42:31 <roconnor> well, maybe not better than ocaml
04:43:01 <roconnor> trin_cz: that is an example of something illegal?
04:43:05 <Jafet> Haskell macros!
04:43:31 <trin_cz>  roconnor: yes, this is supposed to fail.
04:44:02 <trin_cz> roconnor: but it would pass with using let instead of <-
04:44:45 <roconnor> > let result = do { let a'' = a' + 1; let a' = 1; return a''} :: [Int]
04:44:49 <lambdabot>   <no location info>: parse error on input `}'
04:46:35 <roconnor> > let result = do { let {a'' = a' + 1}; let {a' = 1}; return a''} :: [Int]
04:46:41 <lambdabot>   mueval-core: Time limit exceeded
04:46:54 <roconnor> huh?
04:47:14 <roconnor> anyhow
04:47:30 <roconnor> trin_cz: do { let {a'' = a' + 1}; let {a' = 1}; return a''}
04:47:33 <roconnor> this is not legal
04:47:37 <roconnor> and has less returns
04:48:07 <roconnor> trin_cz: do { let {a'' = a' + 1}; let {a' = 1}; pure a''}
04:48:14 <roconnor> pure is a little shorter than return
04:48:17 <roconnor> :)
04:49:14 <trin_cz> roconnor: so different blocks of lets are sequential ... good to know.
04:49:19 <roconnor> You could make you own Identity monad whose constructor is called In
04:49:24 <roconnor> then you could write
04:49:36 <roconnor> trin_cz: do { let {a' = 1}; let {a'' = a' + 1}; In a''}
04:49:57 <roconnor> which looks a bit better written on multiple lines
04:50:33 <roconnor> and think of an equally clever name for the destructor
04:50:35 <trin_cz> the lets on separate lines would certainly look a lot better
04:50:51 <roconnor> ya, I just can't do it with lambdabot
04:51:16 <roconnor> result = nonRecursively do
04:51:20 <roconnor>   let a' = 1
04:51:26 <roconnor>    let a'' = a' + 1
04:51:32 <roconnor>   In a''
04:51:42 <roconnor> where
04:51:45 <trin_cz> the destructor is only once before the do, that is not a problem
04:52:05 <roconnor> newType MyIdenityMonad a = In { nonRecursively :: a }
04:52:06 <trin_cz> also the final return is not
04:52:35 <roconnor> I kinda like this
04:53:44 <roconnor> I might actually start using this
04:54:35 <roconnor> though maybe I'd rename nonRecursively to out.
04:54:35 <illissius_> can you reencode any functional code into the identity monad and have it be semantically the same? (and is ghc smart enough to optimize it away?)
04:54:45 <roconnor> illissius_: yes
04:55:01 <roconnor> ang ghc will optimize most of it away
04:55:38 <illissius_> that's pretty nice.
04:56:21 <benmachine> @undo do { let {a' = 1}; let {a'' = a' + 1}; In a''}
04:56:23 <lambdabot> let { a' = 1} in let { a'' = a' + 1} in In a''
04:57:18 <benmachine> roconnor: for non-obvious and irritating reasons I think it'd have to be nonRecursively $ do
04:59:05 <roconnor> ah
04:59:09 <roconnor> I can live with that
04:59:20 <roconnor> out $ do also has a nice ring to it
04:59:34 <roconnor> though less semantics
04:59:41 <roconnor> kinda
05:00:48 * hackagebot vhdl 0.1.2.1 - VHDL AST and pretty printer  http://hackage.haskell.org/package/vhdl-0.1.2.1 (ChristiaanBaaij)
05:12:53 * hackagebot fullstop 0.1.1 - Simple sentence segmenter  http://hackage.haskell.org/package/fullstop-0.1.1 (EricKow)
05:16:04 <soupdragon> what's the fourth dimension
05:16:43 <Veinor> time
05:23:42 <tafryn> Is there a convenient way to list the type classes that a given type is a member of?
05:24:28 <Botje> :info Type
05:24:39 <Botje> that gives a list of typeclasses at the end
05:24:52 <tafryn> Botje: Thanks
05:39:44 <ksf> @pl (\f g t -> f t <|> g t)
05:39:46 <lambdabot> liftM2 (<|>)
05:40:09 <ksf> that's monad -> isn't it?
05:40:23 <Botje> r->
05:40:27 <ksf> If so, I refuse to even consider changing my suerce.
05:40:29 <Botje> but yes
05:40:51 <Botje> why? it's pretty enough, no? :P
05:54:44 <slaye> Ke: plop :)
06:01:48 <Ke> slaye: hi
06:03:08 <vitka> Anyone else had trouble with fgl when graph nodes are indexed from 1 as opposed to 0?
06:07:14 <fasta> vitka, that is a personal question. 
06:07:29 <fasta> vitka, there is no right answer. 
06:07:43 <fasta> That said, FGL has the wrong answer ;)
06:07:52 <soupdragon> fasta, it's reasonable to assume the question is asked in order that someone who has resolved the problem would have insight
06:08:40 <fasta> soupdragon, I cannot see any reason for a problem being caused by that. FGL worked fine years ago. I don't see why it suddenly would work worse.
06:09:52 <fasta> vitka, if you want a more specific answer, build a test case.
06:12:08 <soupdragon> now /that/ is a good idea
06:13:47 <ksf> huh
06:13:58 <ksf> http:/foo.bar/baz is actually a valid url
06:14:12 <ksf> ...but foo.bar is a path, not the server.
06:14:50 <Jafet> Looks like one of those funky windows special paths
06:15:31 <ksf> http:foo.bar/baz is valid, too
06:15:40 <ksf> ...it's a relative path
06:16:02 <Jafet> Not very universal, I'd think
06:16:43 <illissius_> hmm
06:16:50 <mafs> Especially when Chrome adds the // for you 
06:16:59 <ksf> one might even see how that's sensible if you have a document rooted at say http://foo.com/bar/ with a relative link to ftp:baz , which would resolve to ftp://foo.com/bar/baz
06:17:28 <mafs> Ah, I get what you're saying now
06:17:55 <Itkovian> To whom should I send patches for nobench? dons?
06:18:14 <ksf> "//" is net path, "/" is absolute path and "" is relative path, no matter whether there's a schema present or not.
06:19:15 <ksf> which _also_ means that file:/// is quite nonsensical. file:/ is the same (if the default authority resolves to localhost, that is)
06:19:23 <ksf> (which file: should do)
06:22:01 <illissius_> is there any way you can reference type variables from the context of a class instance declaration which don't occur in the head when defining an associated type for the instance? :/ (e.g. instance (Foo a, b ~ AssocTypeFromFoo a) => Bar b where type AssocType b = (Int,a) or so)
06:22:13 <illissius_> ScopedTypeVariables doesn't seem to do it so I'm guessing the answer is 'no.'
06:22:21 <illissius_> and I should switch over to fundeps :\
06:22:57 <ksf> illissius_, that's Foo a => Bar (AssocTypeFromFoo a)
06:23:26 <ksf> ...at least that's how I would write it, it might not work either...
06:23:38 <illissius_> ksf: can't put type function applications in the instance head
06:24:14 <illissius_> I was pleasantly surprised the ~ way worked as a substitute :)
06:24:49 <ksf> introduce a phantom constraint on b?
06:25:09 <ksf> undecibaleInstances?
06:25:12 <illissius_> hmmm
06:25:19 <illissius_> what do you mean by phantom constraint?
06:25:24 <illissius_> UndecidableInstances is on
06:25:45 <ksf> class Unimportant a; instance Unimportant (Int, a)
06:26:13 <ksf> oh wait the problem is a not being mentioned on the rhs
06:26:37 <illissius_> the problem is it won't let me put the 'a' in (Int,a) because it's not in scope
06:26:47 <illissius_> or so it says
06:27:41 <illissius_> maybe it has a good reason for this, but thinking it through is hard so in the meantime I'll try fundeps
06:28:39 <illissius_> (by good reason i mean maybe something to do with the instances-are-matched-by-their-heads-not-their-contexts thing)
06:34:29 <chrisdone> is the fastcgi-direct author in here
06:35:15 <chrisdone> show your face!
06:35:36 <chrisdone> class MonadIO m => MonadFastCGI m where
06:35:39 <chrisdone> excuse me wtf r u doin
06:37:35 <Jafet> Such beautiful generality
06:38:24 <edwardk> chrisdone: well, does he need to do IO in there? if so what is the problem?
06:38:45 * ksf does indeed think that 'a' <= x <= 'z' is quite clear, but I've got no idea what '&' <= x <= '\\'' and  '(' <= x <= ')' mean
06:39:20 <opqdonut> unicode code point value comparison, of course :)
06:39:39 <chrisdone> edwardk: i don't think IO is necessary
06:39:40 <ksf> I'm not even at unicode, yet.
06:39:50 <chrisdone> edwardk: implementationThrowFastCGI :: (Exception.Exception e) => e  -> m a
06:39:55 <ksf> it's still all 7-bit ascii but getting towards not blowing up with a bigger set.
06:40:18 <chrisdone> that could be implemented with ErrorT Exception 
06:40:22 <chrisdone> http://hackage.haskell.org/packages/archive/direct-fastcgi/1.0.1.1/doc/html/src/Network-FastCGI.html#MonadFastCGI
06:40:41 <chrisdone> i prefer the cgi library's definition: class Monad m => MonadCGI m where
06:41:39 <edwardk> yeah but its not 'fast' ;)
06:41:44 <chrisdone> though i'd like class CGI f where foo :: .. f a so i can implement a monad or applicative or functor or w/e
06:42:01 <chrisdone> edwardk: the fastcgi package is based on the cgi and has the same monad
06:42:16 <edwardk> chrisdone: that was intended as humor ;)
06:43:02 <chrisdone> i know but you could still be making a claim
06:43:07 <edwardk> besides when was the last time fastcgi was touched? 2006 or so? applicative wasn't even on the radar =)
06:43:32 <chrisdone> march 2010
06:43:57 <chrisdone> oh, fastcgi was nov 2008
06:44:17 <edwardk> yeah but all minor updates since the original release
06:44:24 <chrisdone> Snap has a nice Applicative and Alternative instance
06:44:28 <edwardk> so ping bjorn and take it over ;)
06:44:31 <chrisdone> tryThisPage <|> tryAnotherPage
06:45:11 <chrisdone> tryThisPage = do in' <- loggedIn; if in' then ... else pass
06:45:11 <chrisdone> (where pass = empty)
06:45:19 <chrisdone> could do something like that
06:45:21 <edwardk> *nods*
06:45:28 <chrisdone> though it might be confusing to maintain, i don't know
06:46:12 <chrisdone> yeah i've been a user of it for a few years. i've discovered a serious bug in the fastcgi package so i'm trying to fix ~_Z 
06:46:18 <edwardk> the alternative is it'll continue to bitrot. unless i miss my mark i think bjorn moved on a couple of years ago
06:46:30 <chrisdone> yeah he did
06:46:56 <chrisdone> basically said feel free to take over the gd project, and i presume same goes for the rest
06:47:50 <Eduard_Munteanu> Hi.
06:48:02 <chrisdone> hey
06:48:22 <Eduard_Munteanu> I'm seeing this in the xmonad config, and I can't wrap my head around it: (f, m) <- [(W.greedyView, 0), (W.shift, shiftMask)]
06:48:43 <edwardk> Eduard_Munteanu: is that in a 'do' statement?
06:48:53 <edwardk> or in a [ ... | .... ] ?
06:49:14 <chrisdone> edwardk: same thing right? :D
06:49:21 <Eduard_Munteanu> edwardk: AFAICT, no.
06:49:31 <edwardk> chrisdone: sorta. i was looking to get more context. =)
06:49:38 <byorgey> it's in a [ ... | ... ]
06:49:43 <edwardk> Eduard_Munteanu: can you paste it to hpaste.org
06:49:47 <Eduard_Munteanu> Sure.
06:50:12 <byorgey> Eduard_Munteanu: that means to let 'f' and 'm' first be bound to 'W.greedyView' and 0 respecively, and then to W.shift and shiftMask respectively
06:50:18 <edwardk> Eduard_Munteanu: f and m are bound in turn to each tuple in the list
06:51:33 <Eduard_Munteanu> edwardk: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26456#a26456
06:52:06 <byorgey> > [ f m | (f,m) <- [(succ, 5), ((^2), 6), (abs, (-99))] ]
06:52:10 <lambdabot>   [6,36,99]
06:52:15 <Eduard_Munteanu> Oh it's a list comprehension?
06:52:19 <byorgey> yep
06:52:21 <edwardk> Eduard_Munteanu: yeah
06:52:24 <Eduard_Munteanu> Damn, I didn't see it as such.
06:52:26 <Eduard_Munteanu> Thanks.
06:52:32 <byorgey> a big multi-line one =)
06:52:34 <edwardk> the | is on the second line
06:52:54 <edwardk> byorgey: how is the wrong cambridge treating you?
06:53:15 <byorgey> edwardk: it's pretty fantastic despite being the wrong cambridge ;)
06:53:58 <byorgey> today it is 22 and sunny, maybe have a picnic dinner when I get off work =)
06:54:22 <edwardk> byorgey: hah. fair nuff.
06:54:51 <Eduard_Munteanu> Any idea how to map over a WindowSet in xmonad? I'm struggling to get toggleBorder to work on all windows, not just the current workspace.
06:55:05 <Eduard_Munteanu> FWIW, it's for a keybinding.
06:55:18 <byorgey> the research is fun too.  a bit of hacking on GHC, and we're trying to nail down the details of a change to GHC's core language to allow *typed* type-level programming
06:56:12 * Eduard_Munteanu thinks soon people are going to do kind-level arithmetic :P
06:56:31 <ksf> byorgey, any chances of contexts on type families?
06:57:41 <ksf> Eduard_Munteanu, have a look at how the fadeInactive loghook does it
06:57:43 <byorgey> Eduard_Munteanu: a WindowSet is a collection of workspaces, you probably want to map over a WindowSpace instead
06:58:05 <ksf> and while you're at it, remove that border and replace it with transparency.
06:58:07 <byorgey> ksf: can you give me an example?
06:58:27 <Eduard_Munteanu> Thanks.
06:58:41 <ksf> type instance Enum a => Mapof a = EnumMap a
06:58:51 <byorgey> Eduard_Munteanu: well, with this extension we'll be essentially collapsing the type and kind levels, so it will be no harder to do kind-level arithmetic than type-level arithmetic =)
06:59:29 <byorgey> ksf: and what would be the semantics of that?  It's just an error to apply Mapof to anything that doesn't have an Enum instance?
06:59:48 <byorgey> oh, never mind, I think I see -- 
06:59:52 <ksf> there's other mays to go along
07:00:11 <byorgey> Mapof a should evaluate to EnumMap a for any a which is an instance of Enum?
07:00:14 <ksf> but it'd be an error to write MapOf Char = CharMap
07:00:28 <ksf> ...at least without OverlappingInstances or something.
07:00:37 <byorgey> ksf: what do you do about the fact that type classes are open?
07:00:40 <ksf> byorgey, exactly
07:00:51 <ksf> error out?
07:01:01 <ksf> also, arguing that we should have closed ones, too.
07:01:28 <byorgey> yeah, closed type classes could be useful too
07:01:50 <byorgey> ksf: well, I think the answer to your question is, "not yet"
07:01:58 <ksf> or possibly semi-open ones, that is, everything you add doesn't get exported or something.
07:02:16 <wli> Restrictions on qualified names in instance decls can prevent new instances.
07:02:23 <ksf> (which could be useful for classes too, btw)
07:03:10 <byorgey> wli: yes, but not in a way the compiler can take advantage of when doing instance search.
07:04:00 <wli> Hmm. That could hurt.
07:05:46 <wli> I've often wished for some kind of disciplined, scoped affair with classes and instances.
07:08:10 <ksf> "open class", "closed class", "private instance", "public instance", where private is default for closed and vica versa and only public ones are visible outside of the defining module.
07:08:25 <Jafet> Sounds like java
07:08:54 <ksf> well s/private/closed s/public/open works
07:10:34 <ksf> plus "nonviral class", which doesn't export itself automatically from modules importing it.
07:14:08 <tromp_> :t clearBit
07:14:14 <ksf> btw, to safe interested people those ages of googling I did to find it: there are no unicode URIs, ever, at all, they're always 7-bit ascii. the unicode ones are called IRIs and are defined in RFC 3987
07:14:16 <lambdabot> forall a. (Bits a) => a -> Int -> a
07:14:34 <wavewave> I have a question.
07:14:47 <koala_man> ksf: neat
07:14:52 <wavewave> Can I zip two streams with Iteratee ?
07:15:03 <ksf> wavewave, yes.
07:15:25 <wavewave> ksf: I am using iteratee package but I cannot find the function. 
07:15:33 <ksf> ...at least in principle, and I think there's even a function to do that in the package
07:16:31 <ksf> enumPair?
07:16:54 <ksf> that's not what you want.
07:16:59 <wavewave> enumPair is doing opposite things. zip two iteratee for one stream. 
07:17:23 <wavewave> I want to make one zipped stream from two streams. 
07:18:17 <igstan> hi guys, is there some predefined function that will apply a certain function over the elements of a list, BUT will supply the callback function not only with the current element of the list, but also its index?
07:18:53 <roconnor> igstan: flip zipWith [0..]
07:19:12 <roconnor> @type flip zipWith [0..]
07:19:15 <lambdabot> forall a b c. (Num a, Enum a) => (a -> b -> c) -> [b] -> [c]
07:19:17 <ksf> wavewave, the main problem with such a function is that chunk boundaries don't line up and everything quickly becomes inefficient
07:19:46 <ksf> I think oleg used a seeking file enumerator inside an iteratee do do such things.
07:19:49 <igstan> roconnor, looks like what I need, thanks
07:20:20 <MigoMipo> @kind (->)
07:20:23 <lambdabot> ?? -> ? -> *
07:20:24 <alexyk> did anybody use: http://donsbot.wordpress.com/2009/09/26/very-fast-scalable-mutable-maps-and-hashes-for-haskell/
07:20:41 <MigoMipo> Why ?? instead of * 
07:20:45 <wavewave> ksf: hmm 
07:20:55 <Saizan_> MigoMipo: GHC extension to handle unboxed types
07:21:23 <Gracenotes> there was a recent stackoverflow question about it.. http://stackoverflow.com/questions/3034264/haskell-weird-kinds
07:22:12 <wavewave> ksf, What is the main difference between Data.Iteratee and Data.Stream, by the way?
07:22:39 <Gracenotes> we don't have subtyping of record types, but we have sub-kinding.
07:23:25 <Gracenotes> Data.Stream is just a pure infinite list, no?
07:23:33 <Gracenotes> with some interesting typeclass instances
07:23:50 <Gracenotes> but not suitable for IO like Iteratee is
07:23:55 <roconnor> does it have a comonad instance?
07:24:25 <Gracenotes> well, in spirit
07:24:37 <wavewave> I look at stream fusion paper and Iteratee, inside they look pretty similar. 
07:24:40 <Gracenotes> but I don't think the stream package depends on any crazy category theory packages
07:25:06 <ksf> non-monadic iteratees, yes.
07:25:18 <wavewave> I like the idea of composable fold.
07:25:24 <ksf> iteratees also come with error control
07:25:25 <Gracenotes> "Note that this package has (almost) nothing to do with the work on Stream Fusion by Duncan Coutts, Roman Leshchinskiy, and Don Stewart."
07:25:39 <ksf> ...forwards and backwards flowing exceptions so to speak.
07:26:23 <Gracenotes> also, embarrassingly trivial thought of the day: (SomeType -> Type) -> Type is a perfectly normal type signature to have when Type is a monad with a reader component. not like fix at all.
07:26:32 <wavewave> 'fold to iteratee' transform is related to comonad?
07:26:49 <alexyk> "subkindness".  Be subkind to each other.
07:27:15 <wavewave> hmm. too difficult.. 
07:27:33 <wavewave> anyway I want to make some zipping iteratee..
07:27:57 <ksf> I'd recommend against it if you haven't fully grokked them yet
07:28:07 <ksf> which usually means having implemented them.
07:28:13 <tromp_> :t foldl
07:28:15 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
07:29:25 <wavewave> ksf: yeah.. I see. 
07:29:43 <ksf> one of those typical web-situations is there being no http rfc referencing up-to-date uri rfc's.
07:29:48 <zygoloid> @type ($ ?a) -- Gracenotes
07:29:52 <lambdabot> forall a b. (?a::a) => (a -> b) -> b
07:29:57 <wavewave> ksf: Currently what I have to do is to treat very big files. 
07:30:05 <tromp_> :t scanl
07:30:07 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> [a]
07:30:15 <wavewave> and do the same thing again and again. 
07:30:31 <Gracenotes> zygoloid: that's sort of a reader too, if an implicit partially applied argument :)
07:30:34 <wavewave> but combine some info from two files.
07:30:35 <Gracenotes> *of
07:30:51 <ksf> if you don't have many files to deal with, stream fusion might be the better way to go
07:31:05 <wavewave> ksf: I see.
07:31:20 <ksf> as the reason for iteratees is ressource management, ressources like file descriptors, that is.
07:31:21 <wavewave> But it is not clear that I can have zipping folds.. 
07:31:45 <zygoloid> Gracenotes: if you consider a closure to be sort of a reader, then sure, i guess
07:32:10 <wavewave> I mean.. If I have length operation and sum operation.. (both are fold.. )  
07:32:29 <ksf> you can write a function that takes two enumerators and drives an iteratee
07:32:39 <ksf> that is, it has the same type as .>
07:32:46 <alexyk> so, who tried judy?  you abstract people?
07:32:46 <wavewave> ksf: I found that if I use iteratee, I can just compose to one. 
07:32:48 <Gracenotes> it just somewhat surprised me writing a top-level declaration that looked sorta like fix. small thing, yeah..
07:32:51 <wavewave> ksf: yes. 
07:33:09 <ksf> that function would have to drive the enumerators, though.
07:33:25 <wavewave> ksf: is it possible using stream package? ( I superficially think so. )  
07:33:33 <ksf> if it has to be by forkIO'ing them and blocking.
07:33:36 <ksf> yes
07:33:52 <ksf> stream-fusion implements everything lists do.
07:34:25 <wavewave> ksf: hmm. but what I said was things list cannot do. 
07:35:05 <ksf> not in the standard interface, no
07:35:14 <wavewave> length `enumPair` fold (+) 0 
07:35:27 <ksf> ...but you can write a recursion on two different streams
07:35:48 <ksf> you can't do that with iteratees, because they don't recurse on enumerators, enumerators recurse them.
07:36:12 <ksf> @src zipWith
07:36:13 <lambdabot> zipWith f (a:as) (b:bs) = f a b : zipWith f as bs
07:36:14 <lambdabot> zipWith _ _      _      = []
07:36:21 <ksf> ...that's a fold.
07:37:11 <wavewave> hmm in fact I do not understand the concept of iteratee and enumerator..
07:38:23 <wavewave> anyway, I have to look at stream package first..
07:39:00 <wavewave> ksf: thanks
07:40:22 <edwardk> Gracenotes: i'm in the process of putting my crazy category theory packages on a diet ;)
07:41:45 <Gracenotes> noooo, hackage needs more crazy
07:42:23 <gwern> hackage needs more crazy like cat ladies need more dogs
07:42:59 <absentia> ?
07:45:10 <silver> crazy enough
07:47:37 <soupdragon> does anyone have code that loads a bitmap and renders it as a 3D hegihtmap with a camera that can mover around it
07:48:09 <soupdragon> :( my program is completely described there ^ but how many lines of haskell code to wirte it... -_-
07:48:25 <ksf> hmmm I think I should change String to (String,[Word8])
07:52:29 <Axman6> rarg! how are you supposed to use mutable Vectors >_<
07:53:12 <tromp_> wonder if there's a better way to write  [prom ps ic|(ic@(_,Black):_)<-[idxcols]]
07:53:23 <soupdragon> I need free haskell code
07:53:28 <tromp_> idxcols is a list of pairs
07:54:02 <chrisdone> i've noticed this odd thing where cabal will keep re-building certain dependency packages whenever i build a package
07:54:17 <chrisdone> used to happen and then it stopped thought it was fixed. is this an intended behaviour that i don't get?
07:56:16 <Axman6> dons: i don't suppose you're around are you?
07:56:21 <chrisdone> i have project X, with dependency Y. if i re-install dependency Y, then when i install project X, it rebuilds a bunch of dependencies
08:03:24 <byorgey> tromp_: why not just  if ((==Black) . snd) idxcols then [prom ps idxcols] else []  ?
08:03:37 <byorgey> it's not too much longer and much, much clearer
08:04:23 <Axman6> ffs, the vector's mutable interface is completely useless. i have no idea how to use it
08:04:28 <byorgey> oh, I guess I mean  ((==Black) . snd . head)
08:04:33 <tromp_> but idxcols is a list, not a pair
08:04:42 <tromp_> because that fails on empty list
08:04:43 <byorgey> hmm, could idxcols be empty?
08:04:47 <byorgey> I see =P
08:04:48 <tromp_> yes
08:04:57 <ksf> "Publishers should avoid confusing users with "br0ken" or "1ame" identifiers."
08:05:34 <tromp_> i think alternative is  case idxcols of (_,Black):_ -> [...]; [] -> []
08:05:42 <tromp_> which is kinda ugly too
08:06:51 <byorgey> tromp_: you could use pattern guards, like  foo | ic@(_,Black):_ <- idxcols = [prom ps ic] | otherwise = []
08:07:26 <byorgey> that at least removes the arbitrary need to stuff things in a list to get the nice pattern-matching semantics of list comprehensions
08:08:43 <tromp_> i don't like making the empty case expliocit though:(
08:10:05 <Eduard_Munteanu> @hoogle [a -> a] -> a -> [a]
08:10:12 <tromp_> i want that to emerge as monadic behavior
08:10:19 <lambdabot> Prelude iterate :: (a -> a) -> a -> [a]
08:10:19 <lambdabot> Data.List iterate :: (a -> a) -> a -> [a]
08:10:19 <lambdabot> Data.Generics.Schemes everywhere :: (a -> a) -> a -> a
08:12:24 <ClaudiusMaximus> :t foldr (.) id
08:12:58 <soupdragon> [a -> a] -> a -> a
08:13:18 <lambdabot> thread killed
08:14:12 <Eduard_Munteanu> Hm, not really what I was looking for :)
08:15:02 <ClaudiusMaximus> :t \fs x -> map ($ x) fs
08:15:14 <Eduard_Munteanu> My fault...
08:15:20 <Eduard_Munteanu> @hoogle [a -> a] -> [a -> [a]]
08:15:27 <lambdabot> Data.Generics.Schemes listify :: Typeable r => (r -> Bool) -> GenericQ [r]
08:15:37 <lambdabot> thread killed
08:15:47 <Eduard_Munteanu> Meh.
08:16:13 <Eduard_Munteanu> :t XMonad.StackSet.curent
08:16:16 <Eduard_Munteanu> :t XMonad.StackSet.current
08:16:31 <lambdabot> thread killed
08:16:39 <lambdabot> thread killed
08:16:46 <Axman6> :t (+)
08:16:47 <Eduard_Munteanu> > fix lambdabot
08:16:48 <Eduard_Munteanu> :P
08:17:45 <Axman6> RRRRRRAAAAAAAAAAAGGGGGGGGGGGGGEEEEEEEEEEEE!
08:17:50 <Axman6> frigging vector!
08:18:00 <opqdonut> ?
08:18:01 <Axman6> there is such thing as being too generic >_<
08:18:22 <lambdabot>   mueval: ExitFailure 1
08:18:24 <Axman6> why make things generic if it makes them completely impossible to understand and use
08:18:29 <lambdabot> thread killed
08:18:38 <Axman6> > 1 + 1
08:18:46 <lambdabot>   mueval: ExitFailure 1
08:18:59 <jmcarthur> vector is too generic?
08:19:01 <Eduard_Munteanu> lambdabot is sick :(
08:19:21 <Axman6> the mutable parts are
08:19:39 <jmcarthur> personally i think they are not generic enough
08:19:53 <Axman6> it's all using this PrimState stuff from the primitive package, and the types are completely lost on me
08:19:58 <jmcarthur> having wanted to be able to write a couple instances of MVector before but being unable to (efficiently, at least)
08:20:11 <jmcarthur> oh i don't find that too difficult
08:20:19 <Axman6> all i want to do is have a data type which contains a mutable vefore
08:20:23 <jmcarthur> you have a PrimMonad class, and an associated type
08:20:24 <Axman6> vector*
08:20:40 <jmcarthur> the associated type is what you would normal parameterize ST with
08:20:44 <jmcarthur> *normally
08:21:12 <jmcarthur> as long as you know that parameterized ST with RealWorld effectively gives you IO then you can understand with PrimMonad is doing (not a whole lot besides genericity, of course)
08:21:22 <jmcarthur> *understand what
08:21:41 <Axman6> everything you just said, meant basically nothing to me
08:21:51 <jmcarthur> do you understand ST?
08:21:59 <jmcarthur> do you understand associated type synonyms?
08:22:00 <Axman6> yes
08:22:06 <Axman6> i've used it numerous times
08:22:08 <Axman6> no
08:22:14 <jmcarthur> okay there's the problem
08:22:21 <Eduard_Munteanu> Mmm... say you have a function that takes something and outputs a list of results. I want to turn it into a list of functions that each output a single result.
08:22:50 <Eduard_Munteanu> Is this something already known?
08:23:18 <jmcarthur> Eduard_Munteanu: like this type?   (a -> [b]) -> [a -> b]
08:23:29 <Eduard_Munteanu> jmcarthur: yes.
08:23:56 <Axman6> jmcarthur: this is my data type at the moment: data (G.Vector vec v) =>FastMap vec k v =  F (KMap k) (vec v) (don't worry about what KMap is)
08:24:14 <Axman6> though, i'm not even sure if i should be using the generic interface
08:24:45 <jmcarthur> Axman6: i'd learn associated type synonyms before continuing
08:25:16 <jmcarthur> Eduard_Munteanu: i don't think that is possible. how many elements is the result list supposed to have?
08:25:17 <Axman6> does it basically choose the best implementation foer the type being stored? (ie, unboxed for things like Int, and boxed for non-unboxable tpyes)
08:25:24 <Axman6> jmcarthur: anywhere i should start looking?
08:25:34 <jmcarthur> Axman6: search for TypeFamilies
08:25:42 <zygoloid> Axman6: incidentally, contexts on data types are basically useless...
08:26:00 <zygoloid> hmm, actually, maybe this is a case where you need one? :)
08:26:02 <Axman6> i'm already using type families
08:26:14 <jmcarthur> Axman6: but you don't understand them
08:26:29 <zygoloid> is KMap an associated type in the Vector type class, by any chance?
08:26:33 <Axman6> i understand them somewhat
08:26:39 <Eduard_Munteanu> jmcarthur: it should completely describe the a -> [b] part
08:27:08 <ksf> how do I input character constants in hex-notation?
08:27:09 <jmcarthur> Eduard_Munteanu: what if one value of type a returns an empty list but another returns an infinite list? how long should this list be in the result of your function?
08:27:16 <Axman6> KMap is a type family (i think) in my MapKey class
08:27:23 <Eduard_Munteanu> jmcarthur: the lists are all finite.
08:27:27 <jmcarthur> when that (a -> [b]) function is applied to it, that is
08:27:36 <jmcarthur> ah, so this is infinite lists only
08:27:37 <Axman6> class MapKey a where data KMap a ...
08:27:40 <jmcarthur> that's different
08:27:49 <Eduard_Munteanu> No, they're finite.
08:27:56 <jmcarthur> oh
08:27:59 <jmcarthur> nevermind
08:28:01 <Eduard_Munteanu> a -> [b] --- [b] is finite.
08:28:42 <ksf> ah '\xNNN'
08:28:54 <jmcarthur> Eduard_Munteanu: okay, here's a concrete example. what if you have f 0 = []; f x = replicate x x. what should the length of the result of (yourFunc f) be?
08:29:05 <jmcarthur> oops
08:29:13 <jmcarthur> ignore the f 0 = [] part. it's redundant
08:29:20 <jmcarthur> f x = replicate x x
08:30:12 <Botje> Eduard_Munteanu: you could have f g = map (\x -> \a -> g a !! x) [0..]
08:30:27 <zygoloid> quick straw poll: what features would people want from a haskell debugger?
08:30:31 <Eduard_Munteanu> Hm, yeah, I guess it's not really doable.
08:30:33 <Botje> Eduard_Munteanu: but that still gives you an infinite list
08:31:34 <Axman6> jmcarthur: so, where should i look to find out about type families?
08:31:38 <jmcarthur> zygoloid: a visualizer of all structures and thunks in the program, vacuum style but applicable to data held on to by thunks as well. a bit difficult i guess :)
08:31:44 <jmcarthur> Axman6: google it
08:31:45 <Eduard_Munteanu> This is actually an XMonad-related question. I have this...
08:31:45 <Eduard_Munteanu> withAllEverywhere f = forM_ ([W.current] ++ W.visible) (\cat -> withWindowSet $ g cat) where g s c = mapM_ f (integrate' . stack . workspace . c $ s)
08:32:03 <ksf> we don't have overloaded character constants, do we?
08:32:07 <jmcarthur> zygoloid: which you can use whenever the program is paused, of course
08:32:07 <Eduard_Munteanu> And I'd like it to work not only for W.current, but for W.visible.
08:32:49 <Eduard_Munteanu> W.current is SomeType -> OtherType, W.visible is SomeType -> [OtherType]. :/
08:34:20 <tromp_> :t any
08:34:34 <zygoloid> jmcarthur: that's already on my list (or at least providing interfaces to allow other people to visualize in whatever way they like)
08:34:38 <lambdabot> thread killed
08:35:26 <jmcarthur> zygoloid: i mean something that can give me a way to locate things like thunk chains. would that be possible with what you are planning?
08:35:27 <zygoloid> jmcarthur: it's not /that/ hard. no more difficult than the pointer traversal that GC does. the tricky bit is figuring out the memory layout of everything, and finding the heap roots in the first place :)
08:35:40 <jmcarthur> ah yeah, sounds right to me :)
08:35:42 <jmcarthur> awesome
08:36:20 <zygoloid> it's a pain to be honest; there are about 12 different memory layouts per GHC release
08:36:46 * zygoloid has a bit of Language.C to scrape the headers to find the layout
08:36:56 <jmcarthur> bonus points for being able to watch a data structure grow and thunks evaluate as you step through a program :D
08:37:33 <zygoloid> just getting a pointer into the target process which survives a GC will be hard enough :)
08:41:11 * zygoloid idly contemplates allocating a StablePtr in a remote process :)
08:45:21 <Saizan_> zygoloid: if in your journey through GHC's heap you see a way to [de]serialize thunks/closures let me know :)
08:45:50 <wli> Use lockless algorithms.
08:50:12 <zygoloid> Saizan_: do you want it to work across rebuilds of the same code?
08:50:52 <Saizan_> zygoloid: nah, i'm fine if they can only be reloaded by the same build
08:51:40 <zygoloid> well, my plan is to provide a library of primitives, and allow people to build whatever they want on top of that (along with a haskell interpreter as a gdb-like shell)
08:52:28 <zygoloid> i /think/ it should be possible to make a serialization system, if symbols are present in the binary
08:52:47 <zygoloid> but creating a correct heap on restore would be distinctly unpleasant
08:53:17 <wli> I have doubts much of anyone locks symbol tables.
08:53:26 <Saizan_> what do you mean by correct?
08:54:31 <zygoloid> Saizan_: good enough that the RTS can't tell the difference :)
08:55:01 <Saizan_> heh
08:55:39 <chrisdone> how do you guys manage upgrading packages on which other packages depend?
08:56:16 <chrisdone> do you have some script to unregister everything, update the versions in their requirements and reinstall?
08:56:20 <Saizan_> maybe rebuilding them? assuming they aren't "core" packages
08:56:29 <chrisdone> or just avoid cabal-install entirely
08:58:14 <Saizan_> if you only ever do user installs and don't upgrade core packages it should just work, no need to unregister first
09:02:05 <chrisdone> ah well ghc-pkg check help
09:02:06 <chrisdone> s
09:03:22 <chrisdone> seems to work okay
09:05:48 <chrisdone> chris@cn-done:~$ ghc-pkg check
09:05:48 <chrisdone> chris@cn-done:~$ 
09:05:52 <chrisdone> yay, the sin is washed away
09:06:57 <chrisdone> i'll sort my broken packages out on hackage
09:07:12 <chrisdone> could do with removing some as they are bollocks and/or i'm not maintaining them anymore
09:08:14 <chrisdone> what happened to that "Let's Keep Hackage Tidy" movement? do we have some data about broken packages on Hackage that need fixing?
09:08:48 <geheimdienst> i have traveled here from the year 1983 to ask this:
09:09:27 <chrisdone> terminator II will be good
09:09:28 <geheimdienst> what's the haskellish way of testing? for a few inputs, verify that the function produces the expected output, which i guess you could call unit testing
09:09:41 <chrisdone> HUnit and QuickCheck
09:10:05 <geheimdienst> i've heard the name quickcheck various times, but 1) the version is like "0.2 DRAFT 000014" and 2) it's mostly undocumented
09:10:14 <geheimdienst> so that didn't inspire confidence
09:10:15 <chrisdone> what???
09:10:31 <chrisdone> QuickCheck is well-documented and stable
09:10:33 <Lor> tests can only verify the presence of errors, not their absence
09:10:40 <Lor> (unless the input domain is finite)
09:10:51 <chrisdone> or are we pretending we're in 1983
09:11:06 <chrisdone> Lor: thanks, Captain Obvious
09:11:09 <zygoloid> geheimdienst: here in 2010, we have quickcheck 1.2.0.0 on hackage
09:11:21 <zygoloid> hackage is pretty cool, by the way, but you'll have to wait a long time for that
09:12:46 <geheimdienst> wait a minute
09:13:09 <geheimdienst> uh, i just found out that when i said "cabal install quickcheck" it pulled this: http://hackage.haskell.org/packages/archive/QuickCheck/1.2.0.0/doc/html/Test-QuickCheck.html
09:13:28 <geheimdienst> not this: http://hackage.haskell.org/package/QuickCheck-2.1.1.1
09:13:33 * geheimdienst is confused
09:14:31 <geheimdienst> when i said "undocumented", i was obviously referring to the first link. which is what cabal put on my disk when installing
09:15:14 <chrisdone> geheimdienst: have you done a cabal update since 1983?
09:16:16 <geheimdienst> yes, i do them every few days
09:16:23 <geheimdienst> lemme double-check
09:18:03 <geheimdienst> (also, since the 1983 thing seems to confuse people, see this: http://xkcd.com/630/ )
09:19:01 <geheimdienst> $ l .cabal/packages/hackage.haskell.org/0*
09:19:01 <geheimdienst> -rw-r--r-- 1 hk  1735 19 jun 21:42 .cabal/packages/hackage.haskell.org/00-index.tar.gz
09:19:35 <geheimdienst> so i guess that's current enough. but why did i get some bloody old version? i just said install quickcheck
09:21:44 <gwern> geheimdienst: possibly because of the blacklisting of qc-2? I'm not really sure how the specialcasing for qc-2 works out
09:21:45 <zygoloid> geheimdienst: i see that too
09:22:02 <zygoloid> geheimdienst: which ghc version are you using?
09:22:24 <geheimdienst> zygoloid, The Glorious Glasgow Haskell Compilation System, version 6.12.1
09:22:27 <Gracenotes> > case Nothing of Nothing {} -> "..."
09:22:41 <lambdabot>   mueval: ExitFailure 1
09:23:02 <Gracenotes> o_O  I'll file {} on nullary constructors as "distinct possibility"
09:23:21 <zygoloid> Gracenotes: yes, you can do that.
09:23:22 <geheimdienst> gwern, how do you mean "blacklisting"?
09:23:55 <gwern> geheimdienst: because of the diamond dep problem and that people refused to use parsec-3 and qc-2 because it broke stuff, half of hackage was breaking 
09:24:28 <Saizan_> gwern: that's not why parsec-2 is preferred.
09:24:45 <zygoloid> how do i update cabal when "cabal install" says "cabal: failed to parse output of 'ghc-pkg dump'"
09:24:46 <gwern> Saizan_: and was slower
09:24:58 <gwern> it is singular, and I was referring to qc-2, which definitely did break qc users
09:24:59 <zygoloid> i thought parsec-3 was source-compatible with parsec-2?
09:25:12 <Saizan_> geheimdienst: together with the package index cabal-install also downloads a set of preferred versions, which usually are just the ones deemed most stable by their authors
09:26:12 <Saizan_> zygoloid: not that sense of breaking anyway
09:26:52 <Saizan_> geheimdienst: anyhow, for QuickCheck-1 there are also non-haddock docs, there's a fine manual/tutorial actually if you google
09:27:17 <Saizan_> but most people would recommend QuickCheck-2 these days
09:27:28 <c_wraith> hmm..  Seems the IO manager's select loop makes a couple calls in rapid succession:  "rt_sigprocmask(SIG_BLOCK, [INT], [], 8) = 0/rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0".  Anyone know what the purpose of blocking SIGINT momentarily is?
09:27:56 <Saizan_> (i guess you can port most of QC-1 knowledge to QC-2 via the haddock though)
09:28:10 <zygoloid> c_wraith: well, when a SIGINT arrives, it's passed over a pipe to the io manager. presumably it goes through some stuff where it'd rather that didn't happen?
09:29:20 <triyo> Using parsec manyTill, how would I define my 'end' param to be eof? I saw parsec has eof combinator but the type is not relevant. Any ideas pls?
09:29:48 <c_wraith> zygoloid, that sounds reasonable.  I'm trying to track down a problem where a certain set of actions causes my program to no longer respond to SIGINT.  Right now, I'm just trying to get a baseline behavior profile, of how it's supposed to work.
09:30:14 <Saizan_> ?type Text.Parsec.manyTill
09:30:24 <Saizan_> no bot?
09:30:27 <triyo> I have something like this: manyTill anyChar (try (string "::") <|> eof) , but eof doesn't have the right type, so need something similar I gurss
09:30:38 <triyo> *guess
09:30:57 <zygoloid> c_wraith: here's a good place to look: http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/Signals
09:31:10 <geheimdienst> okay, so i extracted the hackage index tar, and the preferred-versions file says QuickCheck < 2
09:31:17 <zygoloid> (it looks like the default SIGINT behaviour might be different from what i described fwiw)
09:31:28 <lambdabot> thread killed
09:31:33 <geheimdienst> is that a bug or a feature?
09:31:37 <Saizan_> triyo: s/eof/(eof >> return "")/ ?
09:32:11 <ddarius> geheimdienst: "Feature"
09:32:25 <aristid> > text "I'm back (hopefully)"
09:32:41 <aristid> :(
09:33:11 <lambdabot>   thread killed
09:33:51 <int80_h> hey guys. I'm trying to set up archlinux as a domU. I know this is haskell only. But I'm doing this to set up a haskell enviroment. I'm figuring someone here has done the same thing. I would like a url to help me with my task.
09:34:04 <Saizan_> triyo: actually, since the value is discarded, i'd use  "manyTill anyChar (try (string "::" >> return ()) <|> eof)"
09:34:24 <int80_h> the archlinux channel wasn't very helpful.
09:35:20 <triyo_> Saizan_: thank you very much. That worked. I see what you did, the return "" magic. :) (Sorry, I'm still new to haskell, but I'm getting there...)
09:35:38 <geheimdienst> ok thanks for your help guys
09:35:58 * geheimdienst charges onward, attacking the bugs of the world with his shiny new quickcheck-2
09:36:09 <zygoloid> > text " thread killed"
09:36:16 <lambdabot>   mueval: ExitFailure 1
09:36:19 <zygoloid> :(
09:36:28 <zygoloid> > text " mueval: ExitFailure 1"
09:36:34 <lambdabot>   mueval: ExitFailure 1
09:36:37 <zygoloid> yay
09:37:15 <Saizan_> triyo_: cheers :)
09:37:36 <Saizan_> > ()
09:37:41 <lambdabot>   mueval-core: Time limit exceeded
09:37:48 <djahandarie> lol Lambdabot
09:37:54 <Saizan_> poor thing
09:38:00 <Saizan_> @bot
09:38:01 <lambdabot> :)
09:38:05 <Saizan_> ?type id
09:38:18 <lambdabot> forall a. a -> a
09:38:39 <Saizan_> the machine must be under heavy load, hopefully not from lambdabot itself
09:58:04 <peterNovice> Is is obvious from the definition of the ST monad that a "newWith 3 0 :: ST s (STVector s Double)"-vector is not escapable with runST? Sorry I am just starting to use the ST monad. I know it works with Vector.create, or with runST, if I replicate the ST vector into a regular vector and return it in the monad at the end. 
09:59:44 <Saizan_> the type of runST prevents you from extracting that vector as it is
10:01:14 <Saizan_> because runST expects something of type ST s a for some 'a' that doesn't mention the respective 's'
10:02:03 <peterNovice> Does the "a" (vector for me) mention the hidden s in some way?
10:02:24 <Saizan_> (STVector s Double) mentions 's', doesn't it?
10:03:30 <Saizan_> it's not a problem of mentioning a particular concrete type used also for the first parameter of ST
10:04:01 <Saizan_> using the same variable in both places is what screws you up
10:04:14 <Saizan_> IOW keeps it safe
10:04:34 <peterNovice> Ok thanks I feel that there is something I am missing in my understanding of the ST monad, the http://www.haskell.org/haskellwiki/Monad/ST does not say so much. 
10:05:27 <Saizan_> the key is to understand higher-rank polymorphism
10:06:32 <peterNovice> But how come if I create a regular vector with say "Vector.replicateM n (v.read v 0)" in the ST monad, where v is the unescapable mutable-vector, this one can be escaped with runST?
10:07:18 <Saizan_> what's the type of that expression?
10:10:30 <peterNovice> I thought the type of v.read v 0 was ST s Double, I am not really sure what I am saying.
10:10:54 <Saizan_> that makes sense
10:11:17 <Saizan_> so "Vector.replicateM n (v.read v 0)" is probably of type ST s (Vector Double) ?
10:11:51 <Saizan_> in which case we can see how (Vector Double) doesn't mention the 's' used as first argument to ST there, so it satisfies the requirement of runST
10:12:53 <peterNovice> OK so it is the second s in "ST s (STVector s Double)" that is trying to escape with "STVector s Double" in the runST. 
10:14:02 <Saizan_> exactly
10:14:04 <Saizan_> the type of runST essentially says "if you can pick a type to use for the 'a' variable that will work for any possible type i could pick for 's' then i'll let you go"
10:15:46 <peterNovice> Ok, that sounds familiar with something I read in the wiki once. And basically all meaningful objects created in the ST monad have some reference to s in their state thread.
10:15:47 <Saizan_> mh, that description is not so clear without an explanations of the scoping rules and unification though :\
10:16:06 <illissius_> hmm... next fun question... is it possible to write a varargs function which returns its arguments as a stack of right-leaning nested tuples?
10:16:17 <peterNovice> No your explanation seems to make sense. Thanks alot!
10:16:41 <Saizan_> ah ok, cheers :)
10:17:23 <Saizan_> illissius_: yes
10:17:29 <illissius_> ok
10:17:35 <illissius_> in that case i'll keep trying =)
10:17:57 <Baughn> Does fromjust . gfindtype end up being resolved at compile-time?
10:20:48 <Saizan_> illissius_: i can link you my roundabout solution if you want :)
10:22:08 <illissius_> Saizan_: I think I want to see if I can figure it out first
10:22:21 <illissius_> just wanted to make sure I wasn't trying to do something impossible
10:22:41 <Saizan_> 'k
10:24:02 <Saizan_> i've found that it requires a bit of olegy sophistication, but there could be simpler ways
10:24:35 <Baughn> @quote olegy
10:24:38 <lambdabot> No quotes match. :(
10:24:52 <aristid> @remember Saizan_ i've found that it requires a bit of olegy sophistication, but there could be simpler ways
10:25:04 <aristid> @quote olegy
10:25:25 * sproingie pokes lambdabot 
10:25:58 <lambdabot> It is stored.
10:26:01 <lambdabot> Saizan_ says: i've found that it requires a bit of olegy sophistication, but there could be simpler ways
10:26:30 <Saizan_> it's not really that memorable..
10:26:46 <sproingie> @remember Saizan_ it's not really that memorable.
10:26:47 <lambdabot> Okay.
10:27:02 <Philonous> Is it possible that class instances are in scope even though I didn't import the according Module directly and the modules that I import don't reexport it?
10:27:21 <aavogt> Philonous: instances are always exported
10:28:13 <Saizan> you get all the instances defined in the transitive closure of your imports, and no more
10:30:08 <duairc> Hey, I have a query that required some code to explain fully, so I've just posted the whole question (with code) here: https://gist.github.com/0cff576eecce261c3bea
10:30:28 <Philonous> Oh dear. Both Control.Monad.Error and Control.Monad.Trans.Error define a Monad instance for Either e and ghc complains that the instances overlapp. Is there a way to solve that?
10:30:53 <aristid> got a small style question: http://codepad.org/aLrrDf2T
10:30:58 <aavogt> duairc: you can add another parameter to foo
10:31:21 <sproingie> hide the one you don't use
10:31:27 <sproingie> arg
10:31:29 <aavogt>  foo witness = length . show . (`asTypeOf` witness) . read
10:31:30 <sproingie> Philonous: hide the one you don't use
10:31:36 <aavogt> sproingie: how do you do that?
10:31:37 * hackagebot srec 0.0.0 - Reading S-Record files.  http://hackage.haskell.org/package/srec-0.0.0 (TomHawkins)
10:31:57 <geheimdienst> philonous, may be related: i had an issue a few days ago where i said import Control.Monad.Error and ghc complained that both "mtl" and "monads-tf" exported that. i solved it by adding a cabal file and specifying a dependency to mtl (not monads-tf)
10:32:20 <aristid> somehow the second variant (with <$>) appeals most to me
10:32:38 <sproingie> import Control.Monad.Error hiding (Either).  but if you indirectly use both then you're still basically screwed.
10:32:47 <duairc> aavogt: How would you do that? I want to parameterise it by a type value, not a data value... and there isn't really a place in the type signature to force a type, and you can't pass a type value as a data value
10:32:59 <sproingie> actually might be hiding Either(..) 
10:33:06 <aavogt> but you can pass a data value with a given type
10:33:17 <aavogt> @src asTypeOf
10:33:26 <aavogt>  asTypeOf x y = x
10:33:49 <aavogt> but it has a type that tells the typechecker that x and y have the same type
10:33:55 <aristid> :t asTypeOf
10:33:57 <lambdabot> asTypeOf = const
10:34:21 <aristid> why's lambdabot so slow today?
10:34:22 <lambdabot> thread killed
10:34:26 <duairc> Hah
10:35:15 <Baughn> Saizan: You know, you should comment your ixset code and use it as a tutorial of some kind
10:35:20 <Baughn> Because I can't make head or tails of it. :P
10:35:37 <Baughn> (I'm happily writing my own version.. requires lots of learning)
10:35:48 <duairc> aavogt: Ah, so I could do (foo (undefined :: Int) "43453"), that would work
10:37:06 <aavogt> exactly
10:37:16 <duairc> Thanks!
10:37:33 <Saizan> Baughn: that must be why while i've linked it to others in the past they never ended up packaging it :)
10:37:50 <aavogt> duairc: sometimes people define     data Proxy a = Proxy, so that you're a bit more explicit about data that's only there to restrict a type somewhere else
10:38:16 <aavogt> since it's a bit risky to throw undefined around
10:38:36 <aavogt> as it will typecheck almost anywhere
10:38:37 <Baughn> Saizan: I can imagine.
10:38:52 <Baughn> Saizan: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26461#a26461 <-- Like, say, /how do I extract a B from the FooDB/?
10:39:02 <Baughn> Or am I going entirely the wrong way here?
10:39:06 <Saizan> Baughn: i guess not everyone has read HList
10:39:29 <Baughn> Saizan: ...HList is not light reading, you maniac.
10:39:37 <aavogt> Saizan: your type-safe ixset is a HList of Map?
10:40:37 <Baughn> Saizan: You know what? I'll just use TH for all of this.
10:40:41 <Saizan> aavogt: roughly, though at the time i was quite deep in GADTs and took the opportunity abstract a bit: http://github.com/Saizan/TypedIxSet/blob/master/IxSetTyped.hs
10:40:53 <Saizan> Baughn: you need something like my Get class
10:41:09 * geheimdienst would like to, apropos of nothing, congratulate the guys who did the "cabal init" feature. the .cabal file generated feels a tiny little bit verbose, but the cabal init process is completely without pain or learning about monoidal endoallegories. it's refreshingly simple. kudos, people.
10:41:14 * edwardk looks up at the mention of ixset.
10:41:16 <Baughn> Saizan: Ooh
10:41:17 * aavogt hasn't actually used GADTs yet
10:41:29 <Baughn> edwinb: http://github.com/Baughn/IxSet/blob/master/IxSetTyped.hs
10:41:32 <Baughn> *edwardk
10:41:55 <edwardk> nice. i was just putting one together for use in a datalog implementation
10:41:55 <aavogt> whose branch is better?
10:42:07 <Baughn> aavogt: They're currently identical.
10:42:11 <edwardk> bit different though
10:42:23 <Baughn> alexyk: And I'm starting with a complete reimplementation, which makes the "fork" bit a bit.. dubious
10:42:39 <Saizan> Baughn: "class Get l a where get :: l -> a" instance Get (a :+: l) a where get (a :+: _) = a; instance Get l a => Get (b :+: l) a where get (_ :+: l) = get l
10:42:54 <Baughn> Saizan: Yep, found it already. It makes sense.
10:42:57 <edwardk> Saizan, Baughn: hey you could exploit the trick i use in fixed-precision to get calls to ix:
10:43:06 <Baughn> Saizan: I only hope it all gets done at compile-time
10:43:36 <Saizan> Baughn: if the type is known and there's enough inlining..
10:43:42 <Baughn> Mm.
10:43:47 <Baughn> I hear GHC likes inlining.
10:43:59 <soupdragon> so how did the ICFP go
10:44:00 <jmcarthur> yes indeedy
10:44:02 <soupdragon> ?
10:44:04 <edwardk> baughn, saizan: http://github.com/ekmett/intervals/blob/master/Numeric/Interval.hs check out certainly or possibly
10:44:09 <soupdragon> I didn't do it because it sounded boring
10:44:16 <edwardk> Baughn: and then reparse in the context of 'ix'
10:44:17 <zygoloid> Saizan: does that need IncoherentInstances?
10:44:36 <aristid> soupdragon: we gave up early :/
10:45:05 <Philonous> How do I hide an instance? 
10:45:07 <Baughn> edwardk: Nope, just undecidable ones
10:45:10 <Baughn> Philonous: You don't
10:45:18 <Saizan> edwardk: ooh, shiny
10:45:24 <zygoloid> Philonous: with a newtype
10:45:31 <edwardk> Saizan: there are only 8 such functions, so you can solve it exactly =)
10:45:36 <Baughn> edwardk: Also, the code you linked broke my mind.
10:45:58 <lispy> Cale: ping
10:45:59 <edwardk> Baughn: given (forall a. Ord a => a -> a -> Bool) -- there are only 8 things it can be. 
10:46:12 <lispy> ?botsnack
10:46:13 <lambdabot> :)
10:46:15 <lispy> hmm
10:46:30 <zygoloid> edwardk: as few as that, really?
10:46:31 <lispy> Cale: Has anything weird been going on with lambdabot that you know of?
10:46:32 <Saizan> zygoloid: Undecidable and Overlapping
10:46:33 <edwardk> Baughn: and you can test that by trying out the function on 3 sets of inputs.
10:46:33 <Baughn> edwardk: It might be more correct to say that I don't understand its purpose
10:46:36 <edwardk> zygoloid: yep.
10:46:39 <zygoloid> edwardk: is that including seq?
10:46:43 <edwardk> Baughn: it'd let you call ix (<=)
10:46:45 <lispy> Cale: I got some notices about high CPU and disk usage
10:46:46 <edwardk> zygoloid: no
10:46:53 <edwardk> zygoloid: i'm ignoring bottoms in that statement
10:47:00 <Saizan> lispy: it's quite slow in fact
10:47:31 <geheimdienst> > ()
10:47:35 <Saizan> lispy: maybe you should kill it, since it's almost useless in this state
10:47:37 <lambdabot>   mueval: ExitFailure 1
10:47:38 <lispy> Well, she's using 100% cpu at the moment
10:47:39 <zygoloid> edwardk: and you're assuming that, for instance, not (a < b) => max a b == a?
10:47:42 <edwardk> Baughn: which would let you kill your funny constructors
10:47:50 <lispy> and 80% memory, heh
10:47:59 <edwardk> zygoloid: nah, any use of max/min will turn into one of those other functions ;)
10:47:59 <zygoloid> (that is, a is not Double...)
10:48:07 * lispy wonders what is broken
10:48:13 <Philonous> Baughn: Now I'm utterly confused. As I said earlier, Both Control.Monad.Error and Control.Monad.Trans.Error define a Monad instance for (Either e), does that mean I can never include two modules where each of them uses one of those and retain a Monad instance for "Either e" ?
10:48:14 <edwardk> zygoloid: so yeah
10:48:22 <Baughn> Philonous: Yes
10:48:24 <lispy> ?botsnack
10:48:26 <edwardk> zygoloid: sorry misparsed your statement slightly
10:48:34 <geheimdienst> > "im in ur servr noming ur resurces"
10:48:45 <lispy> Bummer, it didn't restart
10:48:55 <zygoloid> edwardk: assuming a reasonable-but-not-met-by-Double set of Ord laws i could believe there are only 8
10:49:03 <edwardk> zygoloid: and no, not (a < b) doesn't imply max a b == a because in floating point land not (NaN < 123) = True
10:49:13 <Baughn> edwardk: I don't even understand the code *I'm* writing, don't ask me to understand someone else's. ;)
10:49:16 <zygoloid> edwardk: exactly, that's what i was worried about
10:49:18 <Baughn> edwardk: Type hackery is new to me.
10:49:28 <edwardk> zygoloid: yeah but i'm safe in assumptions about Double in that code
10:49:28 <Philonous> Baughn: That's... disillusioning. 
10:49:32 <lispy> ?tell Cale sorry, I killed lambdabot because she was using 100% CPU and 80% memory for quite a long time and being generally very unresponsive due to it.
10:49:37 <Baughn> Philonous: Ain't that right
10:49:38 <lispy> doh!
10:49:45 * lispy facepalms
10:49:58 <lispy> Can't use ?tell when lambdabot is down :)
10:50:08 <Saizan> preflex: help tell
10:50:08 <preflex>  tell NICK MESSAGE - when NICK shows activity, tell them MESSAGE
10:50:17 <edwardk> zygoloid: because even in the presence of NaN I can reason as long as I don't negate a conditional.
10:50:23 <lispy> preflex: tell Cale sorry, I killed lambdabot because she was using 100% CPU and 80% memory for quite a long time and being generally very unresponsive due to it.
10:50:23 <preflex>  Consider it noted.
10:50:36 <k23z> lispy: did you just face-palmed ?
10:50:37 <zygoloid> edwardk: clearly there's (<), (<=), (>), (>=), (==), (/=) and their complements. and for Double, i think they are all different...
10:50:45 <mreh> lispy: how do you know that?
10:50:58 <lispy> mreh: how do I know what?
10:51:02 <lispy> k23z: indeed
10:51:10 <mreh> about lambdabot
10:51:19 <lispy> mreh: oh, I have root on the server she's on
10:51:38 <mreh> start her up!
10:51:39 <Saizan> lispy: so it was the lambdabot process itself that used that much CPU?
10:51:47 <lispy> Saizan: yeah
10:51:53 <Philonous> Baughn: Do you know whether there is a ticket for that? Because that seems indefensible to me. 
10:52:10 <edwardk> zygoloid: hrmm. ok, so to be fully pedantic i should enlarge the set to encompass the extra 6. so that brings us to 14 observable members. i just need to make a broken instance ;)
10:52:12 <Baughn> Philonous: Probably several. Also years of discussions.
10:52:19 <lispy> mreh: Cale uses a script to run lambdabot and I don't really know his environment
10:52:22 * Saizan wonders if it's the @pl bug again, i thought i had fidex that!
10:52:23 <zygoloid> edwardk: further, for Double, there's NaN-detectors (like a < a) -- and there's as many of those as there are (Bool -> Bool -> Bool)
10:52:25 <Baughn> Philonous: Nobody is quite sure how to fix it.
10:52:38 <zygoloid> a <= a, rather
10:52:52 <lispy> mreh: and Cale will be back soon generally
10:52:55 <Baughn> Philonous: The people who would best be able to do so yell "But it only happens with orphan instances! So ban orphan instances!" instead, or so it feels.
10:52:58 <lispy> he's probably just sleeping
10:53:00 <portnov> @pl \a -> a < a
10:53:07 <zygoloid> join (<)
10:53:12 <edwardk> zygoloid: a < a = False -- regardless of NaN ;)
10:53:15 <portnov> @bot
10:53:17 <edwardk> zygoloid: but i get the idea ;)
10:53:23 <zygoloid> edwardk: < zygoloid> a <= a, rather
10:53:57 <edwardk> zygoloid: well then in a correct ord instance there are only 8 such functions ;)
10:54:22 <edwardk> and i take care of preserving the semantics of the stated operator for possibly, etc.
10:54:38 <edwardk> to avoid passing in arbitrary constructors
10:55:08 <Philonous> Baughn: Banning orphan instances is throwing out the baby with the bath water
10:55:11 <edwardk> so just use not (possibly (<=) ... ...) rather than possibly (not . (<=)) ... ... and you'll be all set ;)
10:55:21 <mreh> lispy: okay :)
10:55:24 <Baughn> Philonous: I know. It would kill hackage.
10:55:36 <Baughn> And, well, haskell.
10:55:45 <Saizan> newtypes for everyone.
10:55:56 <Philonous> Baughn: Ah, well, sorry to bother you with that. I guess it's all been said. 
10:55:57 * lispy passes out newtypes and a brochure
10:56:26 <Saizan> Baughn: actually, the real solution is to only make orphan instances in their own modules, and not import them from other libraries
10:56:30 * Baughn burns the NewType in effigy
10:56:53 <edwardk> Baughn: sadly we cannot bad orphan instances without completely redesigning the way we work with namespaces and retain a usable language i think ;)
10:56:53 <zygoloid> edwardk: presumably a 'correct' ord means one deducible from a strict weak ordering (<)?
10:57:02 <Saizan> it's safe to pick your orphans in applications
10:57:03 <Baughn> Saizan: Which would require being able to avoid exporting them
10:57:22 <Saizan> Baughn: why? if it's a different module you just avoid importing it
10:57:39 <gwern> > 1584 - 1621
10:57:47 <Baughn> Saizan: It's reasonable to want to define an orphan instance, then use it in multiple modules of your own program.
10:58:02 <Saizan> Baughn: right, program is fine, not libs.
10:58:11 <Baughn> Saizan: For libraries too.
10:58:14 <zygoloid> edwardk: in which case, given X = a<b and Y = b<a, we have either ¬X¬Y or X¬Y or Y¬X, so 8 functions. agreed!
10:58:24 <Baughn> Saizan: It's then reasonable to then /not/ want to export it to /users/ of the library. Export it from an internal module, sure, but not from one of the exported ones.
10:58:53 <Saizan> Baughn: i think libraries should only be allowed to define them isolately, but not to use them. leaving the user of the library the freedom of picking the one they like.
10:58:54 <Baughn> Saizan: I see no reason to force library writers to avoid orphan instances.
10:59:20 <Baughn> Really, all I want is the ability to /not export the bloody things/
10:59:26 <Baughn> ..and to hide them when importing, too
10:59:42 <Baughn> It could be done without changing the language much.
10:59:50 <Baughn> Add an instance keyword to export/import llists.
11:00:00 <edwardk> zygoloid: yeah. all i compute is cmp LT EQ, cmp EQ EQ, cmp GT EQ -- and use those three booleans, 2^3 = 8. const True, const False, and the 6 obvious comparisons
11:00:04 <Saizan> the fundamental reason is keeping the nice property that your program will only use one instance for type, not several in different pieces of code.
11:00:37 <Saizan> if you don't like that property don't use typeclasses
11:00:50 <Baughn> I like that property, but I don't think it's doable
11:00:56 <Baughn> Not across all of hackage.
11:01:12 <Baughn> Orphan instances are *useful*, and people *will* end up defining instances twice, in different libraries.
11:01:23 <Baughn> So what's so wrong about wanting to be able to prevent exporting them?
11:01:36 <edwardk> zygoloid: but since instances for Ord are free to do whatever they want in compare and (<=) as evidenced by Double, etc. this is a bit of a pleasant fiction ;)
11:01:41 <Saizan> hackage just needs to be disciplined enough that you're free to pick that one instance you want in your program.
11:02:01 <Baughn> It isn't.
11:02:07 * zygoloid quite likes the local-instances-via-existentials thing in the Oleg paper on implicit configurations
11:02:14 <Baughn> ..I'd prefer more fine-grained control over instances in general. Lexical instances,etc.
11:02:36 <edwardk> zygoloid: it works quite well. have you seen reflection on hackage?
11:03:01 <heiz> Hi! Is it possible to change list of reserved words using Language.Haskell.Preprocessor or Template Haskell?
11:03:37 <Baughn> heiz: No. What are you trying, exactly?
11:03:39 <edwardk> heiz: definitely not through TH. i don't know the preprocessor package though
11:03:48 <Eduard_Munteanu> heiz: you can hide stuff from Prelude.
11:04:01 <Saizan> (btw, i hate transformers! but i can see why it's like that.)
11:04:29 <zygoloid> edwardk: awesome. did you use the same StablePtr trick as in the paper?
11:04:41 <Eduard_Munteanu> Yeah, that transformers was a bad movie :P
11:05:02 <edwardk> zygoloid: yeah. the only difference is the use of Tagged instead of passing undefineds around
11:05:02 <zygoloid> it was pretty obvious how to do it with arbitrary byte streams, but the StablePtr thing was a great a-ha moment i thought
11:05:08 <edwardk> zygoloid: yep
11:05:28 <edwardk> zygoloid: i even use the fairly dangerous version at the end of the paper that relies on the fact that the effect happens once.
11:05:31 <zygoloid> i thought of Tagged when i read the 'we'd like to avoid undefined but can't' bit in the paper
11:05:58 <edwardk> zygoloid: i recently added a Proxy data type to Tagged to make it a bit nicer to use when you really do want to use ScopedTypeVariables
11:06:24 <edwardk> i may retrofit it back into reflection, since it is often what you really want
11:09:36 <edwardk> Saizan: the variant on the ixset that i was playing with just used fclabels
11:10:50 <zygoloid> edwardk: i find it pretty amusing that "Reifies s a => Tagged s" is now almost just a weirder way of writing "MonadReader r m => m" ;)
11:11:03 <edwardk> zygoloid: yeah =)
11:11:19 <Saizan> edwardk: ah, so you build an empty ixset by passing it the labels? and some Ord contexts i guess..
11:11:39 <Saizan> edwardk: do you still use a list of Maps?
11:12:24 <edwardk> Saizan: for now. i was looking at a way that i could use the indexes themselves as keys to find the appropriate map, using something like my stable-maps
11:12:36 <edwardk> that way i could get one out with appropriate type.
11:13:13 <edwardk> Saizan: http://github.com/ekmett/stable-maps/blob/master/System/Mem/StableName/Map.hs
11:14:02 <Philonous> Baughn: Lexicaly scoped instances would indeed be nice. Maybe add a feature to provide named instance and you could write stuff like withInstance (additiveIntegers) (mconcat [1..10] )
11:14:27 <edwardk> zygoloid: i suppose i could just define a MonadReader instance for Tagged and be done with it ;)
11:14:37 <edwardk> but it'd be orphan in reflection
11:14:48 <Baughn> Philonous: Or, not to beat around the bush, first-class instances and modules. :P
11:15:33 <Philonous> Baughn: First-class modules make classes sort of obsolete, don't they? 
11:16:11 <edwardk> Saizan: i do prefer the hlist though
11:16:19 <Baughn> Philonous: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26462#a26462 <-- Call me once you can do this with a module.
11:17:20 <Saizan> edwardk: i was mostly wondering if there were something algorithmically more efficient than rebuilding all the indexes on every projection :)
11:17:32 <Saizan> s/were/was/
11:18:05 <edwardk> Saizan: ah. well, theoretically, if you knew what fields an accessor modified you could skip updating the unmodified fields on mutation, etc.
11:19:08 <edwardk> Saizan: you could play very evil games like building a structure full of errors built using each accessor and see which errors you received back to figure out a conflict table
11:19:37 <mreh> why can't John Harrop use a Haskell Map rather than whine about HashMaps?
11:19:56 <edwardk> mreh: brain damage in childhood. we try not to talk about it
11:20:49 <Philonous> Baughn: Well ok, that would be a job for dependent types, I guess
11:25:42 <edwardk> Saizan: i'd also like things like bitindices, etc. but i'll take what i can get ;)
11:25:46 <Saizan> edwardk: i wasn't even thinking of updates, just that currently "getOrd o1 k1 . getOrd o1 k2" will cause the building of a Map from scratch (assuming optimal laziness) which gets immediately thrown away too
11:27:02 <edwardk> Saizan: hrmm, i should upload my data-ixset lib to github so i can point to the more or less raw dump of the happs ixset i have =/
11:27:30 <dons> alexyk: i'd be interested in hearing about how you used haskell-judy
11:27:32 <Eduard_Munteanu> heiz: there's an extension you can use not to import Prelude by default. Then you can can import Prelude hiding those definitions.
11:27:36 <zygoloid> edwardk: it'd have non-orphan context, so it'd be in scope iff it could apply. i'm not sure if that makes it an orphan or not...
11:27:42 <dons> alexyk: my little benchmarks showed that it scaled very well
11:27:42 <Eduard_Munteanu> import Prelude hiding (...)
11:28:13 <dons> mreh: because he's not interested in solving the problem, more in attacking communities he doesn't sell books to
11:28:20 <edwardk> zygoloid: nah still an orphan because someone could come along and define an instance of MonadReader for Tagged with a different environment
11:28:31 <Saizan> edwardk: my getOrd is taken from happs ixset and it's still quite faithful to it i believe 
11:28:35 <edwardk> zygoloid: its even the worst kind of orphan, the non-obvious orphan ;)
11:28:56 <Eduard_Munteanu> heiz: look here http://www.haskell.org/haskellwiki/No_import_of_Prelude
11:28:58 <zygoloid> it's only an orphan with -XOverlappingInstances :)
11:29:10 <mreh> Hashtables are rather the antithesis of haskell. But it would take an informed person to realise that, which I think he realises
11:30:05 <c_wraith> ok...  I think I need to dig into the ghc-api source to figure out what's going on here.  But I don't see where to find it. >_>
11:30:05 <Saizan> heiz, Eduard_Munteanu: you can import Prelude hiding (..) without any extension, the extension is needed to rebind the syntactic sugar
11:30:08 <zygoloid> it's not so much hashtables as referencing GC'd objects from mutable arrays. and it's strictly speaking a GHC problem not a haskell one...
11:30:19 <edwardk> zygoloid: nah, even then you're screwed you just don't know it until you go to link against the library that uses reflection internally
11:30:50 <Eduard_Munteanu> I see.
11:31:23 <zygoloid> edwardk: i think we have differing ideas of what orphan instances are.
11:31:57 <Eduard_Munteanu> Um, what's the problem with hashtables? I mean we've got stuff like DiffArray which hides impurities quite well.
11:32:19 <edwardk> zygoloid: perchance. an orphan instance for me is one that you can ever go to use, fail to find, then define yourself and have your code blow up when you link against other code that had the same problem.
11:32:44 <zygoloid> edwardk: an orphan instance for me is one where the compiler has to search all transitively-imported modules looking for it
11:33:18 <zygoloid> (rather than applying its usual speed hack of looking for only those modules referenced in the instance it's looking for)
11:33:26 <edwardk> zygoloid: if you define the instance in the module that defines the class or a data type in the head of the instance, that is never the case. if you only control a class in the body of the instance (like the cheesy Error class involved in the Monad instance for Either) then you're asking for trouble
11:33:45 <dons> edwardk: there's no problem. we have lots of great libraries with fine performance
11:33:49 <dons> Eduard_Munteanu: ^^
11:34:04 <zygoloid> edwardk: then we disagree on terminology, but not the result. either way the instance is an orphan. :)
11:34:11 <edwardk> zygoloid: hah =)
11:34:40 <Eduard_Munteanu> Ah.
11:36:24 * hackagebot JSONb 1.0.1 - JSON parser that uses byte strings.  http://hackage.haskell.org/package/JSONb-1.0.1 (JasonDusek)
11:36:50 <sclv> So any off-the-cuff advice if I have M.fromListWith dominating my performance profile?
11:37:35 <Saizan> there's a M.fromListWith' i believe?
11:37:47 <Saizan> not sure when that's preferable though
11:38:00 <alexyk> dons: in fact I wonder why didn't you suggest it earlier!
11:38:08 <edwardk> M = Data.Map?
11:38:27 <dons> alexyk: hmm good point.
11:38:35 <illissius_> [20:13:39] <Philonous> Baughn: Lexicaly scoped instances would indeed be nice. Maybe add a feature to provide named instance and you could write stuff like withInstance (additiveIntegers) (mconcat [1..10] ) -- this is possible, I can't remember where I read it but someone implemented more or less exactly this
11:38:36 <edwardk> sclv: what is the shape of the index? i.e. is it flat enough to move into an array and use runSTArray?
11:38:37 <dons> alexyk: i guess because i was more concerned by the other issues
11:38:44 <edwardk> or runSTUArray?
11:38:48 <sclv> edwardk: always :-)
11:38:48 <alexyk> dons: btw, ocaml is surprisingly slow with imperative Hashtbl!
11:39:06 <dons> alexyk: i think ghc's been generally outperforming ocaml for a few years now (at least going by the shootout) 
11:39:13 <sclv> judy is sort of the nuclear option, I think :-)
11:39:15 <dons> alexyk: and you're  working with simon on the big GC issues?
11:39:18 <dons> sclv: yeah
11:39:33 <dons> sclv: though i did manage to insert 1B keys into a judy map. pretty sweet
11:39:36 <alexyk> dons: yeah, he got the assertion failure firmly in the palm of his hand
11:39:42 <dons> alexyk: awesome.
11:39:55 <dons> alexyk: should be relatively easy to switch over to try judy. 
11:39:59 <sclv> edwardk: the index is an expression tree, but 90% of the time it will be a structure containing a Map String Double
11:40:06 <dons> it has a similar interface to IntMap, but is in IO, obviously
11:40:07 <alexyk> dons: is its usage  monadic?
11:40:13 <_Cactus_> hi
11:40:17 <dons> yup. there's one, and you destructively update it.
11:40:19 <c_wraith> Can anyone point me to the source for the ghc package?
11:40:30 <dons> c_wraith: ghc??
11:40:43 <jmcarthur> package?
11:40:46 <c_wraith> the thing used by ghc.  contains the ghc api.
11:40:48 <dons> c_wraith: http://darcs.haskell.org/ghc/
11:40:51 <dons> c_wraith: that is ghc.
11:40:51 <edwardk> sclv: ah. perhaps replace the Map String with a trie?
11:40:51 <illissius_> c_wraith: http://hackage.haskell.org/trac/ghc/wiki/Building/GettingTheSources
11:40:58 <c_wraith> I'm already browsing that.
11:41:06 <monochrom> Like this? http://www.haskell.org/ghc/docs/6.12.2/html/libraries/ghc-6.12.2/src/GHC.html
11:41:11 <c_wraith> really, I want to figure out where the GHC module is located in there.
11:41:13 <dons> alexyk: and how's progress so far? you're writing a comparative survey or something?
11:41:18 <_Cactus_> last time I was here, someone asked me to write some TH for creating HasSet instances for FFI for flag-like enums
11:41:24 <c_wraith> monochrom, that works
11:41:27 <_Cactus_> who could that have been?
11:42:20 <sclv> edwardk: well sure, but the map generally holds 3-10 things each keyed by 1-3 characters
11:42:32 <sclv> the comparisons aren't slow.
11:42:39 <edwardk> sclv: sclv fair enough
11:42:46 <sclv> They barely show up on the performance profile at all.
11:42:55 <sclv> It's the fromListWith itself
11:43:03 <_Cactus_> ksf: hi, are you here?
11:43:47 <alexyk> dons: I've reimplemented in ocaml and it doesn't crash but is very slow.  so far, only clojure works fully; haskell is faster until it dies/gets stuck.  I will create a functional graph shootout eventually (pretty soon).
11:43:48 <edwardk> sclv: hrmm, well if the comparisons are slow, what about just building a map of strings to indices, and then blasting into an array all the values before sucking them back into your map with an fmap?
11:43:56 <edwardk> er i mean if the comparisons are not slow
11:44:06 <Saizan> c_wraith: http://darcs.haskell.org/ghc/compiler/main/GHC.hs -- btw :)
11:44:22 <alexyk> dons: Twitter released my graphs, so all will be provided.  Let the best minds of FP collide!
11:44:41 <sclv> edwardk: not sure I follow?
11:45:02 <alexyk> I'll probably make a few smaller graphs so folks with boxes under 64 GB RAM don't need enlargement
11:45:03 <c_wraith> Saizan: thanks.
11:45:08 <edwardk> sclv: well, for some reason it seems that you're paying a lot to build the map and seal it back up behind you over and over for the fromListWith
11:45:11 <sclv> I'll hpaste
11:45:51 <alexyk> dons: the beauty of implementing in Haskell is that it's rather easy to translate to OCaml if desired :)
11:46:05 <edwardk> sclv: i just wonder if you'd do better to build the shape of the Map once in one traversal over your data, then blast the data into an ST(U)Array, and suck it out of there into the map when you're done to get the Map you wanted.
11:46:28 <alexyk> but didn't get me speedup and imperative Hashtbl and .iter now feels just nasty
11:46:41 <alexyk> OCaml is more careful with RAM though
11:47:00 <alexyk> (and is slow perhaps of that growing slowly)
11:47:03 <sclv> edwardk: here's where the problem comes up: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26465#a26465
11:47:54 <edwardk> sclv: hrmm.
11:48:29 <sclv> so the Es are expressions, which are generally going to be products, and the Vs are the constant coefficients to them. So we're basically storing multivariate polynomials in a sum of products form.
11:48:39 <edwardk> sclv: that should be fairly cheap over all. do you use this a lot? i.e. does it build up a lot of those (++)'s?
11:48:51 <sclv> This particular function, in my use case, is eating 22% of my time/alloc
11:49:03 <dons> alexyk: will you try the judy library too?
11:49:04 <edwardk> and is this AD? =)
11:49:24 <dons> alexyk: i  think a public site would be great. that way we would have something to work to improve
11:49:29 <edwardk> ah
11:49:33 <sclv> edwardk: a computer algebra layer for my differential solver, to do some partial evaluation
11:49:42 <dons> alexyk: already it seems like it is helping simon with the GC
11:49:44 <Botje> sclv: are you sure it's not the lazy tuples?
11:50:14 <sclv> Botje: the tuples get forced by the fromList
11:50:20 <alexyk> dons: yep, in a couple days will try judy.  Has to do something besides playing with my favorite FP things.  :)  Scala will be added eventually too.  But Haskell seems the nicest, its APIs the phattest!
11:50:30 <sclv> In any case, my problem isn't a leak, its just that this is more expensive than I'd like
11:50:48 <Botje> sclv: not their contents :)
11:51:10 <Philonous> illissius_: Oh, nice. I guess one could do it with some TH.
11:51:14 <Botje> but the expressions are too small to make a differnece i guess
11:51:26 <sclv> edwardk: I can lift splines to algebraic splines, construct algebraic splines with arbitrary unknowns, substitute in and partially evaluate, then reduce them back to pure numeric splines again.
11:51:39 <sclv> So theoretically a big performance win, but some of the algebraic code crawls.
11:51:52 <edwardk> ick
11:51:59 <sclv> ick ?
11:52:23 <illissius_> Philonous: no, it was completely TH-less
11:52:33 <illissius_> just type hackery, and not even very hackish at all iirc
11:52:37 <edwardk> ick that it crawls =)
11:52:40 <alexyk> dons: how can I suggest adding strict versions of Data.Map.fold* ?
11:52:44 <dons> alexyk: oh, your saying we tend to have richer libraries?
11:52:53 <edwardk> overall i don't see an obvious way to speed up your fromListWith
11:52:55 <Philonous> illissius_: Even better! I'd love to see that. 
11:53:14 <dons> alexyk: oh, i would say if you can demonstrate you need it, and maybe provide an implementation, we could add it very easily
11:53:27 <gwern> maybe we ought to just write a Data.Map.Strict
11:53:28 <dons> alexyk: did you modify Data.Map to support a strict fold already?
11:53:38 <sclv> the problem is I end up with MaxPower (I trim) `choose` MaxVariables terms in each slice, eventually. If this were all known statically, it would be a good use case for matrices
11:53:39 <alexyk> dons: not just rich, overflowing! :)  after Haskell OCaml has to be padded with a small Utils.ml with additions in every project or centrally.
11:53:43 <gwern> the current Data.Map apparently just isn't working for alexyk 
11:53:49 <ksf> _Cactus_, yes, I am
11:54:04 <sclv> but since the number of variables can vary arbitrarily over these things, then that doesn't work.
11:54:06 <dons> alexyk: ah i see.
11:54:07 <_Cactus_> ksf: hi
11:54:10 <ksf> is that unicode data Chars cary normalised?
11:54:13 <edwardk> sclv: my core multiplication routine in http://github.com/ekmett/ad/blob/master/Numeric/AD/Internal/Sparse.hs is faced with a similar bottleneck
11:54:19 <alexyk> dons: not there yet for implementation, but my project is clearly a case for stricter map folds, there's a hack via foldl' . toList
11:54:24 <_Cactus_> ksf: so are you still interested in generating HasSet with TH?
11:54:25 <dons> hmm.
11:54:36 <sclv> I just don't know why fromListWith is so slow?
11:54:40 <_Cactus_> ksf: I've pasted my code to http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26375#a26464
11:54:46 <sclv> do you think fromAscListWith . sort might be faster?
11:54:51 <dons> alexyk: well, i can't wait to see your test data. that will be a good case for benchmarking some container library i'm working on.
11:54:53 * sclv runs off to test
11:54:57 <edwardk> sclv: i'd doubt it
11:54:58 <illissius_> Philonous: what I remember is they defined an explicit dictionary type containing functions for mempty and mappend, and then somehow made it so you could run arbitrary Monoid calculations using that dictionary, with very-close-to-or-exactly the syntax you describe
11:55:01 <edwardk> sclv: but good luck
11:55:21 <dons> alexyk: modifying Data.Map directly wouldn't be too hard though, either.
11:55:22 <Botje> sclv: a tiny optimization could be addtl ++ crossProd
11:55:25 <edwardk> sclv: can you just union 3 maps together?
11:55:31 * dons runs off to get some work done.
11:55:43 <edwardk> sclv: that'd get you hedgeunions
11:55:44 <djahandarie> Work, who needs it anyways
11:56:09 <sclv> hmm... which three maps?
11:56:28 <edwardk> times (Sparse a as) n (Sparse b bs) = Sparse (a * b) $ unionWith (<+>) (fmap (^* b) (dropMap n as)) (fmap (a *^) (dropMap n bs)) -- is how i multiply in that Sparse module i linked
11:56:41 <Botje> the one in crossProd and the two in addtl
11:57:22 <edwardk> of course i have an easier time of it
11:57:37 <sclv> hmm.. I'll look at that more closely.
11:57:39 <Botje> that way you avoid building all those tuples
11:59:09 <dons> alexyk: if you want a super easy strict Data.Map, cabal unpack containers; edit Data/Map.hs ; and change the definition of Map to:
11:59:12 <dons> data Map k a  = Tip  | Bin {-# UNPACK #-} !Size !k !a !(Map k a) !(Map k a) 
11:59:17 <dons> that is, add a single ! to the 'a'
11:59:31 <alexyk> ok :)
11:59:31 <sclv> I've got dropMap factored out as a seperate pass. I'm sure folding it in, while reducing orthagonality, might be a good performance win though...
11:59:54 <illissius_> Philonous: found it! http://comonad.com/reader/2009/clearer-reflection/ apparently it's an edwardk invention :)
11:59:58 <dons> you probably should change the version number in the cabal file too.
12:00:07 <dons> to avoid clashes, and make it easier to uninstall
12:00:07 <edwardk> illissius_: happy to help.
12:00:41 <Cale> alexyk: Another way to acheive that: just make sure to seq elements before you insert them into the Map :)
12:00:41 <preflex>  Cale: you have 1 new message. '/msg preflex messages' to read it.
12:01:18 <edwardk> sclv: theoretically the machinery i use in sparse is basically the same stuff you need
12:01:55 <edwardk> sclv: so if you come up with great insights into how to make it faster, i'd welcome feedback ;)
12:01:57 <ksf> _Cactus_, thanks!
12:02:16 <Cale> You shouldn't really need a stricter version of Data.Map, because the API for Data.Map allows for strictness already.
12:03:20 <dons> Cale: i think just some of the combinators don't. e.g fold
12:03:25 <dons> so insertWith' works fine.
12:03:44 <Cale> yeah, and the fold won't be helped by making the elements strict anyway
12:04:00 <Cale> It might be nice to add a strict fold though...
12:04:06 <ksf> works flawlessly, as far as I can tell right now.
12:04:16 <edwardk> dons: import Data.Foldable (foldr') ;)
12:04:28 <Cale> It looks like foldrWithKey and foldlWithKey are both written in a tail recursive style, but aren't strict.
12:04:47 <Cale> which is problematic, though you could always just convert to a list and use foldl'
12:04:47 <ksf> _Cactus_, what shall I write into the copyright header?
12:05:03 <edwardk> (or foldl')
12:06:06 <dons> Cale: but converting to a list is not going to be good for performance..
12:06:10 <Cale> oh?
12:07:21 <ksf> everyone, how would you call a package and module with these contents: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26375#a26464  ?
12:07:37 <ksf> (modulo the actual O_CREAT c2hs stuff)
12:07:42 <ksf> Data.BitFooSet?
12:07:44 <Cale> Ah, toAscList is written using foldrWithKey anyway, so if your Map is so large that foldrWithKey is problematic, then perhaps that's a problem.
12:07:47 <ksf> Foreign.C.Set?
12:07:52 <ksf> Foreign.C.BitSet?
12:08:10 <Cale> Though I wouldn't expect the *log* of the size of your Map to be so large that this could create a stack overflow :P
12:08:52 <Cale> Maybe toAscList should be written using build
12:10:25 <Cale> toAscList t = build (foldrWithKey (\k x xs -> (\cons nil -> cons (k,x) xs)) (\cons nil -> nil) t)
12:10:51 <Cale> Then it'd fuse.
12:12:04 * Cale wonders if he got that quite right...
12:14:05 <alexyk> Cale: think 10 GB Map.  Think 20 GB.  Thnk BIG! :)  Think the Web.  Think Twitter.
12:15:14 <Cale> alexyk: Even with 10 billion elements, the depth of your map will be at most 30 or so.
12:15:26 <Cale> That's not going to create a stack overflow.
12:15:46 <dons> alexyk: did you get heap profiles? i don't think i ever saw any graphs?
12:15:54 * dons is intersted to see what a 20G heap looks like
12:16:54 <Cale> tsk, it kind of sucks being stuck back on GHC 6.10 :P
12:17:44 <gwern> it does?
12:18:05 <Cale> yes
12:18:32 <Cale> I need GHC 6.10.4, because GHC iPhone doesn't exist for newer GHCs yet.
12:19:11 <alexyk> dons: they are there in raw form, I can add .ps's
12:19:18 <dons> alexyk: url?
12:20:17 <monochrom> Think Pad. Think iPad.
12:20:42 <gwern> Cale: oh right, that game company thingy
12:20:50 <dons> alexyk: oh,, on github
12:20:57 <alexyk> yep
12:21:16 <alexyk> those are for an older tag cafe2, but performance didn't really change
12:21:25 <dons> nice.
12:21:39 <dons> the husky repo?
12:22:01 <Cale> I'll have to bug Stephen about it at some point :)
12:22:06 * dons loves getting 1.4MB/s from github
12:22:21 * gwern read a long blog post on how iphone apps are a fool's game
12:23:25 <Cale> toAscList' t = build (M.foldWithKey (\k x xs -> (\cons nil -> cons (k,x) (xs cons nil)))
12:23:25 <Cale>                                     (\cons nil -> nil)
12:23:25 <Cale>                                     t)
12:23:25 <edwardk> Cale: yeah unfortunately the build system changed right after that no? so it'd be a fair bit of work to update the current system to handle the ghc iphone build machinery
12:23:29 <Cale> there, better :)
12:23:55 <Cale> edwardk: Yeah, I'm not sure about the details :)
12:24:30 <Cale> Let's see if I can get it to fuse :)
12:25:04 <dons> alexyk: http://i.imgur.com/MIQnR.png
12:25:16 <dons> that doesn't look like a space leak, fwiw.
12:25:23 <dons> looks like you're just allocating a lot in a Map
12:25:37 <dons> the stg_app_upd might be a bit of laziness
12:25:42 <dons> but it seems stable
12:26:00 <dons> Float is interesting. that'd benefit from unboxing.
12:26:06 <alexyk> dons: that's before dafis strictified the bang out of it
12:26:15 <dons> oh, is there a graph for that?
12:26:24 <alexyk> dons: nope, need to do :)
12:26:27 <dons> ah ok.
12:26:39 <dons> are you finding the heap profile tools useful?
12:26:51 * dons will have time next week to help, btw.
12:27:42 <_Cactus_> ksf: I don't even know what you need this for
12:27:44 <alexyk> dons: for now I don't see where's the catch.  The main finding by dafis and me was long lookup of ByteString in a regular Map, so now it's all interned and IntMap rules
12:27:49 <_Cactus_> ksf (sorry for the late reply, got in a bit of a fight here)
12:28:09 <dons> alexyk: yeah, the Ord instance for Map can be a performance issue. I rememember issues with that in the past.
12:28:12 <_Cactus_> ksf: anyway, my name is Gergo Erdi, gergo@erdi.hu
12:28:23 <dons> alexyk: so you're getting better results with IntMap?
12:28:24 <Cale> yep, it fuses
12:28:25 <dons> its a better structure.
12:28:38 <dons> judy should do well too. since it really has   been tested on very large scale data sets
12:28:50 <alexyk> dons: 1000000 users really made it perkier; tripling them killed ghc runtime.  So maybe it's GC flaking.
12:28:53 <dons> a sort of monadic IntMap. very similar design.
12:29:00 <alexyk> 1 million works, 3 millions kill it
12:29:09 <dons> alexyk: ok. and that's what you're working on with Simon?
12:29:27 <Cale> So if you're afraid of the big bad intermediate list which is just going to be GC'd immediately anyway, you can use my buildified version of toAscList and the construction of that list will fuse away
12:29:37 <alexyk> dons: he got a tag where it got into a loop or dies; we'll solve that first.
12:29:47 <dons> alexyk: ok. all is in hand then. good work.
12:30:15 <alexyk> the recent one also segfaults, and my feeling is the same thing prevents it from scaling which kills it
12:30:15 <alexyk> \
12:30:28 <Cale> However, you'll need a lot of memory to fit the map in the first place :P
12:30:31 <alexyk> so fixing runtime must improve it :)
12:30:38 <alexyk> Cale: yeah
12:30:42 <Cale> You could do the very same trick with IntMap though
12:31:20 <alexyk> Cale: which one?
12:31:25 <dons> alexyk: one interesting point is that the judy library is outside of the ghc heap
12:31:30 <Cale> defining toAscList in terms of build
12:31:34 <alexyk> ah yeah
12:31:34 <dons> so will not stress the GC. you might be able to make faster progress that way
12:31:34 <Cale> toAscList' t = build (M.foldWithKey (\k x xs -> (\cons nil -> cons (k,x) (xs cons nil)))
12:31:34 <Cale>                                     (\cons nil -> nil)
12:31:34 <Cale>                                     t)
12:31:48 <Cale> ^^ this will cause the intermediate list to be fused away
12:32:01 <Cale> When you consume it with something like foldr or foldl'
12:32:06 <dons> tibbe: have you been following alexyk's work? good test for container specialization
12:32:26 <alexyk> dons: for now have to go back to grant-writing a bit.  Will resume Thu :)
12:32:42 <Cale> main = print (foldl' (\xs (k,v) -> v + xs) 0 (toAscList' bigMap))
12:32:45 <Cale> ^^ for example
12:33:00 <dons> alexyk: ok. talk to you later.
12:33:08 <alexyk> kk
12:33:17 <dons> Cale: just need to grab a sample data set from alexyk and his code and get hacking
12:33:31 <Cale> Well, I have actual work that I should work on. ;)
12:33:37 <dons> shapr: ping
12:33:49 <alexyk> sample is on github, I'd be happy to help setup if unclear (README is there :))
12:33:58 <Cale> But try that anyway
12:34:02 <dons> i'll play around with it next week. should be fun.
12:34:14 <alexyk> kk!
12:34:30 <Cale> I wonder if there's a way to get even deeper fusion.
12:34:41 <Cale> Fusable finite map structures :)
12:35:30 <dons> Cale: we hint at a design for that at the end of the stream fusion paper
12:35:36 <Cale> Probably adding RULES for M.fromList would help to begin with ;)
12:35:44 <dons> its definitely doable, though there's a paper waiting to be published. possibly dcoutts has it in his thesis
12:35:48 <Cale> But that's sort of lame on its own.
12:35:55 * ksf wants to bsd3 that code but he read in the cecil faq that the disclaimer is null and void in at least france if the user is a non-professional
12:36:32 <Cale> ksf: Are you in France?
12:36:34 <ksf> _Cactus_, it's useful for each and every binding to C that needs to deal with flags
12:36:41 <ksf> nope.
12:36:44 <ksf> I'm in germany.
12:36:55 <_Cactus_> ksf: I understand that, I'm asking specifically about where it'll end up
12:37:03 <_Cactus_> what module of what package
12:37:07 <Cale> So you're worries about the disclaimer of warranty not applying to you?
12:37:11 <Cale> worried*
12:37:14 <ksf> I was asking here, but nobody told me
12:37:30 <ksf> right now I'm planning to release it as package BitFuSet as Data.BitFuSet
12:37:33 <Cale> Software licenses annoy me.
12:37:43 <arw_> in germany any "i'm not responsible for anything"-disclaimer is also null and void. but don't worry, if you don't collect money for the software, usually nothing will happen except if you intentionally introduced bugs
12:37:47 <shapr>  dons: pong
12:37:50 <Cale> I just BSD things without thinking about it so much.
12:38:10 <shapr> dons: wassup?
12:38:37 <ksf> I've got no problems adding THIS SOFTWARE IS NOT AN END-USER PRODUCT   USE OF THIS SOFTWARE BY NON-PROFESSIONALS IS STRONGLY DISCOURAGED or something, but then I'd be other-license.
12:39:13 <_Cactus_> THIS SOFTWARE IS KNOWN TO CAUSE CANCER IN LAB RATS
12:40:00 <ksf> otoh, there's of coures CeCILL-B
12:40:01 <p_l> _Cactus_: that would encourage people
12:40:02 <Eduard_Munteanu> :))
12:40:55 <cwb> I'd like to try out hmatrix on Mac OS X Snow Leopard with Haskell Platform 2010.1.0.1. After installing hmatrix (0.9.3.0) using cabal, I get the following error message trying to use it in ghci: Lading package hmatrix-0.9.3.0 ... can't load .so/.DLL for: gsl (dlopen(/opt/local/lib/libgsl.dylib, 9): no suitable    image found.  Did find: /opt/local/lib/libgsl.dylib: mach-o, but wrong architecture) 
12:41:02 <_Cactus_> p_l: then how about "this software is NOT known to cause cancer in lab rats... or IS IT?"
12:41:06 <cwb> Anyone know how I might fix that?
12:41:51 <p_l> _Cactus_: even worse
12:41:58 <cwb> Or perhaps explain what the error message might mean.. ?
12:42:38 <cwb> (I figure it's got something to do with the Haskell Platform being compiled differently from what cabal does somewhow..)
12:43:12 <ksf> _Cactus_, you ok with CeCILL-B?
12:43:20 <ksf> it's BSD with better legalese
12:43:30 <_Cactus_> never heard of it
12:43:49 <_Cactus_> let me skim through it
12:43:57 <ksf> http://en.wikipedia.org/wiki/CeCILL 
12:44:07 <_Cactus_> not that my 5-minute work is so awesome and valuable that it needs the best license ever:)
12:44:27 <ksf> the inria created those to have bsd- and gpl-like licenses that are adapted to european(ish) law
12:48:12 <_Cactus_> ksf: the cecill-b license is a go for me
12:48:22 <ksf> hmmmm wait
12:48:28 <ksf> I don't grok the attribution clause
12:48:40 <ksf> it looks like BSD4
12:49:00 <chrisdone> ^-^
12:49:27 <ksf> and I don't really like bsd4 except when attribution would go to something like "The Haskell Community" and it's GPL-dual-licensed
12:49:50 <ksf> which, btw, is the way enlightment and freetype license their stuff
12:50:13 <chrisdone> i usually have a "BSD0"
12:50:27 <Baughn> sahazel: Well, my hlist-like Getter compiled down to.. no op-codes, near as I can tell.
12:50:39 <Baughn> Saizan: Well, my hlist-like Getter compiled down to.. no op-codes, near as I can tell.
12:50:55 <Baughn> Saizan: Works out nicely, even if it /does/ threaten my sanity.
12:51:01 <ksf> the enlightenment license states in clear, nice terms "give us attribution, unless you don't close the code"
12:51:11 * Baughn is incidentally listening to "A Shoggoth on the Roof"
12:51:36 <chrisdone> a shoggoth is a kind of steed, or sex slave, right?
12:51:46 <p_l> chrisdone: ... nope
12:51:52 <Gracenotes> or both?
12:51:54 <chrisdone> (they are essentially interchangeable, after all)
12:51:56 <p_l> ... shoggoth sex slave... urk
12:51:58 <Saizan> Baughn: hey, you're just writing something like find (==a) at the type level :P
12:52:03 <ksf> http://wiki.enlightenment.org/index.php/Enlightened_License
12:52:33 <Baughn> chrisdone: A shoggoth is essentially a semi-sentient mass of hypertech/nanotech blue goo
12:52:42 <chrisdone> "It was a terrible, indescribable thing vaster than any subway train—a shapeless congeries of protoplasmic bubbles, faintly self-luminous, and with myriads of temporary eyes forming and un-forming ..."
12:52:49 <chrisdone> okay, so not exactly a sex slave, unless you're into that
12:52:53 <Baughn> chrisdone: Oh, and in stealth mode it looks like a biosphere. Ours, coincidentally.
12:53:22 <monochrom> gross
12:53:25 <ksf> what's the general sentiment on such a attribution-if-code-gets-closed-otherwise-do-what-you-want license?
12:53:32 <Baughn> Saizan: ...now I want to write something like M.lookup a at the type level.
12:53:48 <chrisdone> i love a bit of HP Ludecraft
12:54:12 <Saizan> Baughn: getting an Ord context there requires too much boilerplate for my tastes
12:54:26 <gwern> chrisdone: as morphing protoplasm it could shape itself into a sex slave
12:54:31 <Baughn> Saizan: Pity that.
12:54:32 <gwern> some chicks dig tentacle porn I hear
12:54:43 <Baughn> gwern: People tend to overlook the fact that humans are shoggoths.
12:54:46 <chrisdone> gwern: i think the most interesting porn i've ever seen is melting porn
12:54:52 <cwb> Anyone got any experience with root finding in Haskell?
12:55:00 <gwern> chrisdone: what
12:55:00 <Baughn> gwern: ..well, stealth frontends to shoggoths, anyway.
12:55:07 <gwern> chrisdone: is that like guro?
12:55:14 <p_l> gwern: no
12:55:15 <dons>  is  this haskell-blah ??
12:55:27 <gwern> dons: no. this is #sparta!
12:55:33 <dons> think of people's sensibilities.
12:55:35 <djahandarie> Wow, beat me to it gwern :P
12:55:51 <mux> this looked like #haskell-4chan
12:56:15 * chrisdone cowers in shame
12:56:27 <chrisdone> now i'll go talk about the haskell code i was working on in #haskell-blah
12:57:08 <djahandarie> lol
12:57:28 * ksf decides not to push the issue and wait until he wrote a lucid inquiry to at least haskell-cafe and got some decent answers
12:59:11 <ksf> ...none of my code that uses it is ready for release, anyway, and you guys don't seem to be begging for it.
12:59:36 * Baughn realizes that he just causally wrote "flip id" as the answer to a type challenge. I'm doomed, aren't I?
12:59:48 <ksf> definitely.
12:59:51 <monochrom> @type flip id
12:59:55 <lambdabot> forall a b. a -> (a -> b) -> b
13:00:18 <ksf> it's a serious brain-twister.
13:00:32 <Baughn> But actually, I had the type signature backwards. It should clearly be just id.
13:00:56 <robinhoode> Hey guys.. I'm trying to follow these instructions: http://substack.net/posts/ea85c2/Happstack-on-Dreamhost-Notes and I'm running into some problems: http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=26466#a26466
13:00:57 <djahandarie> @type id
13:00:58 <lambdabot> forall a. a -> a
13:01:00 <nolrai_fg> Hi all, so I am in an open sorce project class, and we are supposed to start an project. I was wondering if there are any Haskelly things that could use some focused attention. Like a proposed language feature or something? Any ideas, places to look?
13:01:14 <sclv> @type flip ($)
13:01:15 <lambdabot> forall a b. a -> (a -> b) -> b
13:01:19 <sclv> same thing :-)
13:01:32 <djahandarie> @type ($)
13:01:33 <lambdabot> forall a b. (a -> b) -> a -> b
13:01:43 <robinhoode> Google is not much of a help for such a generic error like "Error 9" or "Error 2"
13:01:45 <sclv> $ is really just id with a restrictive type signature
13:01:49 <Baughn> nolrai_fg: http://hackage.haskell.org/trac/summer-of-code/wiki/Soc2010 <- You might find some useful ideas here
13:01:56 <ksf> nolrai_fg, http://www.reddit.com/r/haskell_proposals/
13:02:10 <sclv> Which leads me to wonder if we could obfuscate haskell by using `id` everywhere in place of $.
13:02:20 <ksf> or rather http://www.reddit.com/r/haskell_proposals/top/
13:02:49 <nolrai_fg> Baughn, sclv thanks!
13:03:28 <djahandarie> > (+1) `id` 10
13:03:30 <lambdabot>   11
13:03:35 <gwern> > (+1)`id`10
13:03:35 <Cale> It doesn't hurt readability that much to use `id` instead of ($), but the precedence is wrong
13:03:36 <lambdabot>   11
13:03:43 <gwern> djahandarie: even better, no need for spaces
13:03:45 <Cale> So you could do sneaky things
13:03:51 <Cale> > log `id` 2 + 3
13:03:52 <lambdabot>   3.6931471805599454
13:03:54 <Cale> > log $ 2 + 3
13:03:55 <lambdabot>   1.6094379124341003
13:03:59 <djahandarie> Haha
13:04:01 <lispy> Cale: I got another email about 23 minutes ago about excessive disk usage
13:04:07 <Cale> lispy: oh...
13:04:07 <lispy> Cale: probably swapping?
13:04:17 <Cale> lispy: Maybe /tmp filled up again?
13:04:19 <djahandarie> Someone should write a Haskell transformer that just obfuscates everything that it can find
13:04:26 <kmc> it's called @pl
13:04:28 <Cale> mueval stupidly doesn't clean up its temp files
13:04:30 <djahandarie> Hahaha
13:04:31 <lispy> Cale: oh!  Has that happened?
13:04:46 <sclv> @pl \x y -> x `id` y
13:04:46 <lambdabot> id
13:04:56 <sclv> oh, right. 
13:04:58 <Obfuscate> I find these obfuscation discussions quite boring.
13:05:09 <Cale> It's only 22MB of temporaries at the moment
13:05:10 <gwern> Obfuscate: old hat, even?
13:05:13 <lispy> Cale: Well, when I've seen this warning before it was when gnu ld needed 1GB of ram to link anything and so the swap was going crazy
13:05:14 <Cale> but lots of inodes
13:05:47 * ksf gently nugdes nolrai_fg to http://www.reddit.com/r/haskell_proposals/comments/b7gt2/a_native_glfwglutsdl_thingie/
13:05:50 <lispy> Cale: /me thinks it's because some command is using too much memory
13:06:19 <lispy> Cale: memory usage seems reasonable, so I don't
13:06:24 <Cale> I don't see anything...
13:06:36 <lispy> Cale: I'll let you know if I continue to get notifications
13:06:39 <Cale> okay
13:06:40 <djahandarie> You can use rLimits to make sure no commands make the bot go out of control
13:06:48 <Cale> We do
13:06:54 <gwern> I wonder if hint is strict in 'eval'
13:07:02 <Cale> But occasionally weird things happen :)
13:07:37 <Cale> I already have a command which looks for stray muevals and cleans them up periodically, even though lambdabot is supposed to do that itself :)
13:07:42 <c_wraith> wow, how fun.  the ghc api install a signal handler that stores the current ThreadId, and throws an exception to it.
13:08:15 <c_wraith> If the thread that started it completes...  that signal handler doesn't do anything
13:08:32 <kmc> it's called @pl
13:08:36 <kmc> whoops
13:08:42 <c_wraith> hence ctrl-c failing in my use case.
13:09:13 <djahandarie> Eh, the thread that started it can't complete without its children completing, can it?
13:09:27 <djahandarie> s/it //
13:09:37 <kmc> generally Haskell threads can
13:09:40 <ksf> there's a thread hierarchy?
13:09:48 <djahandarie> Oh
13:09:53 <kmc> (GHC-Haskell threads I mean)
13:09:55 <djahandarie> Was thinking process->threads
13:10:13 <kmc> you can make them wait if you like
13:10:43 <ksf> I once successfully wrote a no-op program by spawning threads in the main thread and not explicitely waiting for any of them to finish
13:10:50 <kmc> :)
13:10:59 <c_wraith> djahandarie, also, the ghc api doesn't *remove* that handler after it finishes.
13:11:08 <c_wraith> That's the real bug.
13:11:28 <c_wraith> But I finally was able to explain the symptoms.
13:11:39 <mreh> uh, how does GHC interpret a tab? as a single whitespace?
13:11:49 <c_wraith> 8 spaces, I think
13:11:53 <ksf> yep
13:11:57 <ksf> don't use them.
13:12:00 <lispy> mreh: you really don't want to use tabs in haskell source :)
13:12:03 <ksf> they're going to be outlawed completely.
13:12:06 <lispy> mreh: ghc has a warning for them even
13:12:12 <kmc> mreh, the spec says a tab is 8 spaces
13:12:16 * gwern emails daniel asking where hint is strict about loading L.hs
13:12:18 <edwardk> lispy: i should definitely turn that warning on
13:12:18 <mreh> I'm not :)
13:12:19 <kmc> you really don't want to use tabs
13:12:29 <mreh> it's Henrik Nilsson
13:12:34 <ksf> the warning should be on by default.
13:12:49 <ksf> for say 6.14 and 6.16
13:12:55 <mreh> I'll preprocess the source now i know
13:12:57 <ksf> ...and then be an error in 6.18
13:13:07 <kmc> ksf, then GHC won't be Haskell 98 compatible anymore
13:13:18 <ksf> well then add -fallow-tabs
13:13:20 <c_wraith> GHC already isn't H98 compatible
13:13:30 <kmc> in 6.14 we'll have a flag to set the standard to H2010
13:13:31 <lispy> kmc: Haskell 2010 has been released.  Who cares about H98 :)
13:13:38 <c_wraith> 6.12 intentionally broke compatibility in one spot
13:13:41 <kmc> which?
13:13:53 <c_wraith> I don't recall which.  Something to do with IO exceptions
13:13:57 <ksf> I argued to outlaw them in 2010, but only the wrong people listened.
13:14:10 <ksf> CLDouble
13:14:13 <mreh> lispy: is that the same as Haskell'?
13:14:21 <ksf> haskell' is a process
13:14:25 <lispy> mreh: they overlap
13:14:44 <lispy> Haskell' is always the HEAD of the Haskell standard (if you think of it like version control)
13:14:44 <kmc> Haskell' is an infinite list of language specs
13:14:44 <c_wraith> "Lazy I/O now throws an exception if an error is encountered, in a divergence from the Haskell 98 spec which requires that errors are discarded (see Section 21.2.2 of the Haskell 98 report). The exception thrown is the usual IO exception that would be thrown if the failing IO operation was performed in the IO monad, and can be caught by System.IO.Error.catch  or Control.Exception.catch. "
13:14:55 <kmc> Haskell 2010 is the first element of that list
13:15:21 <ksf> no it isn't.
13:15:30 <ksf> it's been specced, and thus has been popped off the list.
13:15:39 <kmc> nonsense, that'd be mutation
13:15:56 <ksf> no it isn't.
13:16:05 <ksf> you confuse time and mutation.
13:16:15 <sclv> we have the whole list defined, it just so happens that inspecting further elements blocks :-)
13:16:26 <sclv> that's just an operational issue though.
13:16:27 <Igloo> Perhaps Haskell' is a partial function from year to langauge definition
13:16:47 <Saizan> and instead of a black hole you get commitee
13:17:13 <ksf> termination of language design is undecidable.
13:17:21 <ksf> we can't say whether the list is infinite.
13:18:53 <burp> @bot
13:18:53 <lambdabot> :)
13:19:05 <kmc> given that new versions of FORTRAN, COBOL, C++, and Java are still being developed
13:19:11 <kmc> i think it's safe to say that it will never halt
13:22:07 <burp> > take 1 $ filter (\[a,b,c,d,e] -> a^2 + b^2 + c^2 == d^2 + e^2 ) $ map (\x -> take 5 $ scanr (\a b -> a+x) 0 [1,2,3,4,5]) [1..]
13:22:08 <lambdabot>   [[10,11,12,13,14]]
13:23:38 <burp> that last piece is quite ugly :|
13:24:22 <Blkt> good evening everyone
13:25:58 <kmc> hi Blkt 
13:28:31 <Blkt> hi kmc 
13:30:13 <_Cactus_> ksf: just please drop me an email if/when it gets into a published package
13:31:18 <BMeph> codexon.com -  creepy? :\
13:34:55 <seric> dancor: you're here and got a minute?
13:35:52 <dancor> seric: yes
13:36:06 <ksf> _Cactus_, will do
13:36:13 <seric> dancor: may I query?
13:36:26 <alexyk> Cale: what does build do?
13:45:41 <soupdragon> Does anyone have a haskell program that:   Reads a bitmap file - Draws it as a 3D heightmap - Lets you move a camera aorund it?
13:45:44 <burp> http://www.codexon.com/posts/debunking-the-erlang-and-haskell-hype-for-servers
13:45:45 <soupdragon> I need that
13:45:46 <burp> um wtf
13:45:54 <burp> "Will you update the graphs to use the bytestring version?" "@Don Im not sure it would be fair to Erlang to do so."
13:45:55 <burp> not fair?
13:46:19 <aristid> burp: yeah that's rather weird
13:46:19 <kmc> this is old
13:46:50 <tibbe> Did someone mention my name? Colloquy says yes but I can't see anything in the chat log.
13:47:11 <kmc> news flash: if you don't know what you're doing you will write slow Haskell code
13:47:13 <djahandarie> tibbe, dons did. < dons> tibbe: have you been following alexyk's work? good test for container specialization
13:47:18 <edwardk> tibbe: great paper btw
13:47:23 <ksf> soupdragon, voxel graphics? olschool!
13:47:25 <djahandarie> tibbe, and yeah, nice paper ;-)
13:47:45 <edwardk> ksf: bah, heightmap /= voxel ;)
13:47:49 <soupdragon> I'm starting ot think that I have to wriet i myself ;(
13:48:08 <alexyk> tibbe: you got to follow my project reading in twitter graph!  and speed it up if possible! :) github/alexy/husky, branch mapfold
13:48:11 <edwardk> despite the misappropriation of the name by novalogic ;)
13:48:51 <edwardk> gotta run
13:48:52 <djahandarie> tibbe, also, c_wraith apparently found a typo in that paper
13:48:53 <tibbe> edwardk: thanks, I have something like 10% left on the GHC integration but the last 10% is a PITA (lots of concurrency stuff)
13:48:57 <dons> soupdragon: haskell-gnuplot ?
13:49:06 <c_wraith> hehe.  the typo was really minor. :)
13:49:12 <tibbe> alexyk: link?
13:49:15 <dons> burp: stupid post is stupid. 
13:49:30 <tibbe> alexyk: I was working on more memory efficient Maps the other day, with your project in mind.
13:49:37 <c_wraith> in section 8.1:  When the event manager is notified that data is available on this pipe, it issues a single read system call to gather all currently buffere buffered wakeups.
13:49:43 <alexyk> tibbe: http://github.com/alexy/husky
13:49:58 <alexyk> IntMap explodes the current runtime
13:49:58 <kmc> "The conclusion of this web server shootout is about as useful as racing a jetski against a tugboat, declaring the jetskis to be faster since the jetski won the race, and then deciding to pull barges into the harbour with jetskis from now on since they’re so much faster."
13:50:12 <tibbe> alexyk: unfortunately I'm insanely busy and I don't want to get distracted form my I/O manager work
13:50:24 <tibbe> alexyk: so I want to UNPACK values as well as keys
13:50:27 <lispy> kmc: haha
13:50:51 <tibbe> alexyk: but I haven't had time to thoroughly understand the problem you're trying to solve
13:50:56 <lispy> kmc: But, what does a jetski or tugboat really compare to with web servers?
13:50:57 <alexyk> kmc: mongrels on jetskis can pull a barge, if there's like a 100 of them
13:51:07 <alexyk> and a barge is a toyone
13:51:09 <kmc> yup
13:51:17 <tibbe> alexyk: I got a bit nervous with the Maps of Maps stuff, I don't know if that gives you the most memory efficient layout
13:51:30 <alexyk> tibbe: it's discussed in the readme, and there will be more.
13:51:48 <monochrom> That is a lengthy analogy.
13:52:00 <c_wraith> Does anyone have any experience with saving/restoring signal handlers cross-platform?
13:52:05 <alexyk> tibbe: a graph is a map of maps here.  Some kind of map, but map of maps for now.
13:52:14 <proq> looks like someone spreading python propaganda (debunking-the-erlang-and-haskell-hype-for-servers)
13:52:14 <dons> tibbe: using the adaptive type families approach?
13:52:20 <tibbe> dons: yes
13:52:29 <tibbe> dons: unfortunately I get O(n^2) instances
13:52:30 <dons> tibbe: we should collaborate then, since i'm writing a paper on that.
13:52:33 <tibbe> dons: for keys/values
13:52:33 <alexyk> later...
13:52:34 <dons> tibbe: indeed.
13:52:40 <tibbe> dons: I'd love to
13:52:52 <dons> ok. i'll be free after next tuesday. i will get in touch.
13:53:16 <dons> i want really good benchmarks :)
13:53:19 <tibbe> dons: great, thanks
13:53:25 <tibbe> dons: I have use cases I think
13:53:26 <dons> purely functional, auto-specializing data types
13:53:36 <dons> nice. maybe we can use alexyk's benchmark too
13:53:37 <tibbe> dons: large maps is very common in MapReduces (think joins)
13:53:44 <tibbe> dons: yes!
13:53:51 <tibbe> dons: same great interface, better performance
13:54:04 <dons> ok. good. i'll add some notes and we can work on this during the summer :)
13:54:14 <tibbe> alexyk: right, you could have a single map with a tuple key
13:54:23 <tibbe> alexyk: should give you less indirections
13:54:32 <tibbe> dons: great
13:55:44 <alexyk> tibbe: I currently implement the same algorithm across 3 FP languages and there will be more.  So long as a tupled key simulates map of maps map/reduces, fine.
13:56:04 <Itkovian> dons: ping
13:56:08 <dons> Itkovian: pong
13:56:09 <tibbe> alexyk: they do
13:56:09 <alexyk> but I'll consider anything for a separate superfast run
13:56:15 <dons> Itkovian: only for a little while. quick!
13:56:23 <Itkovian> dons: Are you the preferred recipient for nobench patches?
13:56:25 <tibbe> alexyk: it'd be useful with some stats, like friends per users, etc
13:56:29 <dons> ah nno, that's malcolmw now
13:56:31 * ManateeLazyCat pasted "haskell-cafe error." at http://paste2.org/get/888326
13:56:32 <ManateeLazyCat> I always got above error, and send mail to haskell-cafe-owner nothing help, any administror help me?
13:56:33 <Itkovian> ok thx
13:56:38 <tibbe> alexyk: so I can calculate the average overhead per value etc
13:56:39 <dons> no worries.
13:56:43 * dons -> out for a bit
13:56:53 <alexyk> tibbe: average like 10, but you do get 10000 or more 
13:56:58 <Itkovian> dons: any chance of a repky on my split compilation proposal? you'd like to be in, or out?
13:57:08 <Itkovian> either way is fine for me
13:57:20 <tibbe> alexyk: it'd be great if you could dump some numbers in the readme (so I can context switch to it some time in the future)
13:57:32 <alexyk> tibbe: I'll compute the exact stats Thu and update README
13:57:39 <tibbe> alexyk: so distributions of values would be great
13:57:43 <tibbe> alexyk: thanks!
13:58:06 <ManateeLazyCat> dons: Can you help me fix error at http://paste2.org/get/888326 ? I can create article at haskell-cafe, my mail always reject by haskell-cafe when i reply myself article.
13:58:38 <ManateeLazyCat> dons: I have send mail to haskell-cafe-owner@haskell.org, but no response.
13:58:45 <ManateeLazyCat> dons: Thanks!
13:59:20 <Igloo> ManateeLazyCat: Are you sending from the address you are subscribed as?
14:00:17 <monochrom> do you use thunderbird? do you filter haskell-cafe to a local folder? do you have many identities in thunderbird?
14:00:45 <ManateeLazyCat> Igloo: Yes, i can create article at haskell-cafe, but when i *follow*, my mail will reject.
14:00:56 <ManateeLazyCat> monochrom: I use gnus.
14:01:14 <ManateeLazyCat> monochrom: But i think my mail is reject by haskell-cafe somehow.
14:01:50 <ManateeLazyCat> monochrom: I haven't did special setup for haskell-cafe.
14:02:04 <ManateeLazyCat> monochrom: I have use gnus with many other mail-list, works fine.
14:02:27 <ManateeLazyCat> I don't why haskell-cafe will reject my mail?....
14:02:36 <Igloo> ManateeLazyCat: Does your mail program keep a copy of mails you send?
14:02:50 <ManateeLazyCat> Igloo: Yes.
14:03:23 <Igloo> ManateeLazyCat: Can you hpaste the headers of one that worked, and one that didn't, please?
14:03:39 <ManateeLazyCat> Igloo: Ok, wait a sec.
14:04:14 * ManateeLazyCat pasted "The one can work." at http://paste2.org/get/888336
14:04:56 * ManateeLazyCat pasted "The one can't work." at http://paste2.org/get/888339
14:05:04 <ManateeLazyCat> Igloo: Above ^^
14:05:11 <tibbe> alexyk: I see you hang in both #haskell and #clojure ;)
14:05:38 <Igloo> ManateeLazyCat: The second one is the failure message, not the message you sent
14:05:40 <alexyk> why doesn't ghc warn "you imported Control.Monad five times, you dog!"
14:06:16 * alexyk found repeated imports in dons' examples
14:06:30 * ManateeLazyCat pasted "The mail that reject by haskell-cafe." at http://paste2.org/get/888340
14:06:31 <alexyk> tibbe: and in #ocaml and #scala
14:06:34 <Igloo> alexyk: It does, if the imports are redundant
14:06:38 <tibbe> alexyk: :)
14:06:42 <c_wraith> Igloo, only in 6.12+
14:06:43 <ddarius> alexyk: It could come up legitimately, but, yeah, a warning for completely identical imports wouldn't hurt.
14:06:48 <ManateeLazyCat> Igloo: Sorry, http://paste2.org/get/888340 is my mail that reject by haskell-cafe.
14:07:30 <alexyk> tibbe: among the 3, only clojure does the job so far, rather quick and in small RAM.  Surprise!
14:07:40 <alexyk> JVM with compressed oops
14:07:48 <monochrom> Hmm, Cc: haskell-cafe@haskell.org? That's unusual.
14:07:56 <tibbe> alexyk: I would expect both clojure and java to do well given the stable/optimized JVM underneath
14:08:14 <tibbe> alexyk: what data structure do you use in clojure? a HAMT?
14:08:15 <sclv> I just used thrift to do some simple ipc between haskell and clojure -- super easy!
14:08:37 * sclv really wants hamts in haskell
14:08:52 <Igloo> ManateeLazyCat: lazycat.manatee@gmail.com isn't subscribed to the list. It looks like the first message was sent via gmane, which is presumably why it worked
14:08:54 <alexyk> tibbe: a regular immutable map, which can become magically transient for large updates and then back immutable! tada!
14:08:58 <tibbe> sclv: me too, if I had some time I would investigate if they could be made fast
14:09:06 <tibbe> alexyk: right
14:09:15 <Itkovian> Now, to figure out malcolmw's email address. Help.
14:09:17 <tibbe> alexyk: so a hashed array mapped trie then
14:09:33 <ManateeLazyCat> Igloo: Yes, i through gmane.org send mail to haskell-cafe@haskell.org
14:09:34 <sclv> being able to use thrift/clojure effectively gives me a very low cost java ffi :-)
14:09:34 <tibbe> alexyk: which probably works well in this case as it's quite compact
14:09:50 <ManateeLazyCat> Igloo: I must subscribed to the list with my mail?
14:09:56 <alexyk> tibbe: something new every day! 
14:10:13 <monochrom> or you must consistently use gmane, including follow-ups.
14:10:31 <Igloo> ManateeLazyCat: Yes. You can set your subscription settings so that the mailing list doesn't send you mail, if you would prefer to read it on gmane
14:10:32 <monochrom> perhaps you haven't configured gnus to use gmane when you reply.
14:10:38 <tibbe> alexyk: so once we know your actual data size we can do some memory consumption calculations by hand and see what the expected data size is
14:11:00 <Igloo> ManateeLazyCat: I can add your address if you like?
14:11:16 <ManateeLazyCat> Igloo: Oh, thank you very much! :)
14:11:37 <alexyk> tibbe: okok
14:11:49 <alexyk> bbl
14:12:38 <Igloo> ManateeLazyCat: OK, done. Let me know if it still doesn't work for you.
14:12:47 <tibbe> alexyk: The IntMap overhead is a bit tricky to calculate
14:12:56 <ManateeLazyCat> Igloo: Ok, i will send mail to test, thanks again. :)
14:14:48 <tibbe> alexyk: normal Maps have 7 words overhead per key/value I believe
14:15:22 <tibbe> data Map k a  = Tip 
14:15:23 <tibbe>               | Bin {-# UNPACK #-} !Size !k a !(Map k a) !(Map k a) 
14:16:02 <tibbe> so 1 word (8 bytes on 64-bit) for Size, two for the pointer to k and it's constructor, two more for the value and two for the child pointers
14:16:40 <tibbe> dcoutts: do you have the bytestring report handy?
14:17:05 <ManateeLazyCat> Igloo: I have test, works now. Thanks! :)
14:17:18 <Igloo> Cool
14:21:17 <Corey> I'm using GHCi and I did :module +Data.List but isInfixOf isn't in scope.  where is it?
14:21:29 <geheimdienst> @hoogle isInfixOf
14:21:29 <lambdabot> Data.ByteString isInfixOf :: ByteString -> ByteString -> Bool
14:21:30 <lambdabot> Data.List isInfixOf :: Eq a => [a] -> [a] -> Bool
14:21:30 <lambdabot> Data.ByteString.Char8 isInfixOf :: ByteString -> ByteString -> Bool
14:21:45 <illissius_> Saizan: it works! :]
14:21:49 <illissius_> it's also ugly as fuck
14:22:02 <geheimdienst> hm ... how exactly are you using isInfixOf? post the line of code maybe
14:22:09 <illissius_> and I cribbed 'how to write an instance for not-a-function' from The Oleg
14:22:57 <Corey> [2,6] `isInfixOf` [3,1,4,1,5,9,2,6,5,3,5,8,9,7,9]
14:23:10 <geheimdienst> > [2,6] `isInfixOf` [3,1,4,1,5,9,2,6,5,3,5,8,9,7,9]
14:23:11 <lambdabot>   True
14:24:10 <Corey> I get not in scope... but isPrefixOf and isSuffixOf work
14:24:11 <Gracenotes> Corey: hm... works here.
14:24:20 <Gracenotes> oh
14:24:35 <geheimdienst> i just checked in ghci, i get no errors after i did :module +Data.List
14:24:44 <Gracenotes> maybe you have a version of Haskell that doesn't have it?
14:24:54 <Gracenotes> if you do have it, :browse Data.List should list it
14:25:09 <Saizan> illissius_: heh, that's what i used too :)
14:25:35 <Corey> :browse shows suffix and prefix but no infix
14:26:15 <Gracenotes> what does 'ghc --version' say?
14:26:16 <Corey> weird
14:26:27 <Corey> 6.4.2
14:26:33 <mreh> if I have f :: a -> (b -> c), can I do "f a b"?
14:26:33 <sclv> that's ancient
14:26:40 <Gracenotes> I have 6.10.4, and it's there.. the latest version is 6.12 actually
14:26:45 <mreh> seems alright to me
14:26:52 <mreh> heh, FAB Scott
14:26:57 <geheimdienst> corey, so it seems to be a version issue
14:27:10 <Corey> alrighty, thanks
14:27:29 <Gracenotes> the latest versions are at http://hackage.haskell.org/platform/
14:27:32 <mreh> what I've written is a definition of curried notation isn't it
14:27:34 <illissius_> Saizan: http://haskell.pastebin.com/i1Trjb6w -- is this at all similar to yours?
14:27:46 <geheimdienst> corey, no problem. that will be $67.50, please
14:27:50 <mreh> a -> b -> c == a -> (b -> c)
14:27:52 <Corey> haha
14:27:55 <illissius_> a bunch of the predicates in the contexts are probably superfluous but i don't really feel like figuring out which ones atm
14:28:07 <geheimdienst> payable to the Cult of Curry
14:28:15 <Corey> I have no idea why my version of ghc is so old though... I just downloaded it a couple months ago but apparently 6.10 was released in 2008 lol
14:28:29 <Gracenotes> mreh: well, (a, b) -> c == a -> (b -> c). sorta.
14:29:06 <Gracenotes> isomorphic up to bottoms
14:31:07 * geheimdienst believes it's bottoms all the way down. "up to bottoms" doesn't make sense
14:31:56 <mreh> (_|_) *parp*
14:31:57 <Saizan> illissius_: sort of, i actually used the typeclass machinery only to build up a gadts that witnesses the arity and type of arguments of the function, so that i can write a few functions by recursing over it
14:32:30 <noeff> a -> b -> c == a -> (b -> c) is syntactically true , (a, b) -> c == a -> (b -> c). only isomorphic 
14:32:53 <monochrom> isomorphic down to bottoms. happy? :)
14:33:09 <Saizan> illissius_: your zipArgs would be "curry' reify id" here: http://code.haskell.org/~Saizan/Uncurry.hs
14:33:49 <Apocalisp> What's the fixed point of a functor like: Foo a = Bar a | Baz [a] ?
14:34:06 <Gracenotes> noeff: but currying usually means the latter.. the former more evokes partial application
14:34:26 <ddarius> Apocalisp: A tree like thing.
14:34:52 <mreh> :t curry
14:34:53 <lambdabot> forall a b c. ((a, b) -> c) -> a -> b -> c
14:34:54 <ddarius> Apocalisp: You have straight paths labelled Bar and branches labelled Baz. 
14:35:06 <monochrom> calamarie
14:35:15 <monochrom> err, s/e//
14:35:21 <mauke> data T = C1 T | C2 [T]
14:35:22 <ddarius> calamity
14:37:39 <roconnor> what are the ArrowLoop laws
14:37:42 <noeff> i prefer chinese food anyway
14:38:53 <illissius_> Saizan: hmm, yeah. I used GADTs in a similar way for type-level naturals when i couldn't figure out how to do equality-proving with just typeclasses (though some considerable time later I figured that out too)
14:39:14 <illissius_> is there any way to estimate the runtime performance of this kind of hackery other than benchmarking it?
14:39:25 <Saizan> illissius_: oh, how do you prove equalities with just typeclasses?
14:39:32 <Saizan> illissius_: looking at the core?:)
14:40:02 <illissius_> Saizan: hmm, let me find it for you
14:40:12 <illissius_> and oh yeah, I guess. looking at core is another thing I have yet to do
14:43:38 <illissius_> Saizan: oh, what I meant was the Nat itself was typeclass-based (as opposed to the other version which was itself a GADT), the equality-proving uses a GADT in either case
14:43:52 <Saizan> illissius_: ah, ok :)
14:46:48 <ksf> @src many
14:46:48 <lambdabot> Source not found. Just what do you think you're doing Dave?
14:46:53 <ksf> bah
14:49:06 <ksf> gragh minimizing  many (toks "abc") <|> many (toks "xy") still boggles me
14:49:18 <ksf> ...when using explicit kleene stars, that is.
14:50:17 <ksf> ...minimising in the sense of never looking ahead and never backtracking
14:51:38 <_Cactus_> so I wrote this Brainfuck interpreter. Two interpreters, in fact: one uses a zipper'd list for memory, the other one an IOUArray and an IORef Word8 (memory+ptr). And both are horribly slow
14:51:58 <_Cactus_> http://github.com/gergoerdi/brainfuck has the code
14:52:19 <_Cactus_> both are written in as simple way as I could manage
14:52:32 <_Cactus_> and I'm looking for insights on why it has performance problems
14:52:47 <dschoepe> What happened to haskell.org? Why is the old logo back on the front page?
14:53:08 <tromp_> i wrote one which appears on http://en.wikipedia.org/wiki/Binary_lambda_calculus#Brainfuck
14:53:32 <geheimdienst> isn't that because they haven't restored it completely after the recent snafu ... the wiki also seems to be missing its proper css files, etc.
14:53:43 <dschoepe> Ah, okay
14:54:06 <geheimdienst> at least that's what i heard. and yes, it is ugly :-/
14:55:13 <Saizan> _Cactus_: tried profiling?
14:55:33 <illissius_> @pl \f -> foo f . bar
14:55:33 <lambdabot> (. bar) . foo
14:56:10 <_Cactus_> Saizan: no
14:56:31 <_Cactus_> Saizan: when I think of profiling, it conjures up images of when I do it at my day job
14:56:59 <_Cactus_> Saizan: and let's just say its totem animal should be the Red Herring
14:57:00 <proq> _Cactus_: how do you expect to speed it up if you don't first profile?
14:57:32 <Saizan> _Cactus_: ghc has a very nice automatic profiling support
14:57:38 <proq> _Cactus_: aside from asking someone or here who already has, that is  :)
14:57:42 <proq> *on here
14:58:31 <Saizan> http://www.haskell.org/ghc/docs/6.12.2/html/users_guide/profiling.html , http://book.realworldhaskell.org/read/profiling-and-optimization.html
14:58:43 <_Cactus_> tromp_: JFYI, your interpreter crashes with a stack overflow on http://github.com/gergoerdi/brainfuck/blob/master/samples/9digits.bf
14:59:31 <_Cactus_> Saizan: thanks, I'll read these. I wrote the interpreter to learn something new, and if this something new turns out to be profiling, then that's great!
14:59:51 <ksf> profiling haskell is fun
14:59:58 <ksf> most importantly, it's not much work
15:00:44 <Saizan> _Cactus_: one reason why it might be slow is that your interpretation of while is suboptimal, since you reinterpret from the syntax tree for every step in the loop
15:01:54 <Saizan> you could instead have a function that transforms [Stmt] into Memory -> IO Memory, and paying a bit of attention to sharing you'd have to interpret the instructions in the loop only once
15:02:15 <_Cactus_> i see
15:03:14 <geheimdienst> ksf, haven't done profiling yet. does "not much work" mean easy for mortals? (often in haskell things are "not much work" only if you already understand theosophical disymmetric coexofunctors)
15:03:26 <tromp_> i only tested it on smallish BF programs:(
15:04:16 <dons> geheimdienst: profiling is easy. ghc -prof -auto-all ; ./a.out +RTS -p
15:04:19 <dons> read the prof file.
15:04:39 <Saizan> geheimdienst: well, in some cases it can get hard to spot the actual problem, the tools are very easy to use and give a lot of info though, if you skim the RWH chapter you'll see that
15:04:40 <danharaj> then again the prof file (heh) reads like it is writtin in hieroglyphics
15:04:56 <dons> Itkovian: haven't had a chance to look at it. thesis due in a few days. should have much more free time after that.
15:05:11 <mietek> dons: so you probably haven't taken part in the ICFP contest?
15:05:16 <Itkovian> dons: Ah. Good luck! Submission or defense?
15:05:24 <soupdragon> Who was disappointed with ICFP?
15:05:32 <_Cactus_> i know i was
15:05:35 <soupdragon> me too
15:05:41 <k23z> y ?
15:05:44 <dons> submission.
15:05:55 <dons> defense is before the submission in .au
15:06:04 <dons> you have to suceed before they let you write up
15:06:05 <dons> :)
15:06:08 <k23z> ground submission ?
15:06:18 <BMeph> Go, dons, go! \o/
15:06:28 <c_wraith> k23z: negative.  standing guillotine
15:06:40 <_Cactus_> soupdragon: we looked at last year's problems to get ourselves up to speed
15:06:46 <mietek> soupdragon: I was disappointed with the time-based scoring
15:06:52 <mietek> soupdragon: and the server problems
15:06:56 <soupdragon> yeah
15:06:57 <mietek> soupdragon: I enjoyed the reversing
15:07:01 <_Cactus_> soupdragon: and then when the real contest started, we were so disappointed that we wished we had partaken last year instead:)
15:07:16 <k23z> c_wraith watchin UFC/MMA ?
15:07:16 <geheimdienst> thanks for the pointers, guys
15:07:37 <BMeph> I liked the concept of trinary encoding, but the implementation left much to be desired... (only semi-joking...)
15:07:39 <soupdragon> I was hoping I could really throw myself into it, but I didn't even get started
15:07:42 <mietek> Is it possible to dynamically generate/compile/load Haskell code, without going through a text representation?
15:07:47 <c_wraith> k23z: not in a while.
15:08:02 <dons> mietek: yeah, see e.g. hint or plugins.
15:08:18 <dons> mietek: you can use TH to build an AST which you pass to the compiler/or bytecode interpreter
15:08:45 <mietek> Cool, this is exactly what I need.  Thanks
15:08:50 <Itkovian> dons: weird. we have to submit, a defend the submission before the jury and then have the final (public) defense.
15:09:14 <mietek> dons: this is desp, btw; you may remember me from the 2007 ICFP, or not ;)
15:09:24 <dons> so we do 3 talks, then you're allowed to write up, then the jury reviews. 
15:09:54 <dons> mietek: hey desp!!
15:14:25 <c_wraith> Is there any writeup out there on profiling TH code?
15:14:49 <aavogt> c_wraith: are compile-times getting that slow?
15:14:59 <roconnor> @type mapAccumL
15:15:00 <lambdabot> forall acc x y. (acc -> x -> (acc, y)) -> acc -> [x] -> (acc, [y])
15:15:10 <Itkovian> dons: and that's it? no more defense after that? or a public defense?
15:15:12 <roconnor> @index mapAccumL
15:15:12 <lambdabot> Data.List
15:15:30 <roconnor> I didn't know about this function
15:16:06 <dons> Itkovian: and that's it. they can either ask to revise some sections, or accept it.
15:16:16 <c_wraith> aavogt, yes, and I don't even know if the problem is my code for generating splice content or not.
15:16:28 <Itkovian> dons: cool. So in two days, it'll be dr. dons.
15:16:36 <aavogt> c_wraith: I'd imagine you might be able to compile ghc with profiling, then   ghc +RTS -p -RTS  ... other flags ...
15:16:40 <dons> well, not till they accept the thesis. :) 
15:16:47 <dons> and presumably not till the actual ceremony?
15:16:55 <Itkovian> ok, but if they allow you to write and submit, that should be ok, no?
15:16:57 <dons> but yes, hard work is done.
15:17:03 <c_wraith> ack, did you just suggest recompiling ghc?  ewww.  :P
15:17:06 <dons> Itkovian: indeed. only something like 1/100 aren't accepted
15:17:10 <Itkovian> here, once you;re allowed to the public defense, it's done
15:17:16 <aavogt> c_wraith: I don't understand your problem
15:17:18 * geheimdienst has always thought that things are not really official until you get a hat
15:17:22 <Itkovian> that's only for the engineering faculty though
15:17:26 <dons> geheimdienst: yeah, seems right
15:17:28 <Itkovian> the science faculty only has a single defense
15:17:34 <Itkovian> so you can still fail there :-)
15:17:39 * dons -> bcak to writing final chapter.
15:17:45 <Itkovian> we fail in private, they fail (possibly) in public
15:18:05 <geheimdienst> good luck, dons
15:18:14 <c_wraith> aavogt, I don't need to profile the TH engine, just figure out what I'm doing wrong in my TH code to result in splices taking so long.
15:18:30 * Botje puts on Aqua - Dr Jones
15:18:38 <aavogt> have you looked at the output with -ddump-splices?
15:18:40 <Botje> sounds much better if you make it Dr Dons >:)
15:18:44 * geheimdienst puts on Aqua - Dr Dons
15:19:00 <k23z> and I have a puppet wit "dons" written on it
15:19:23 * k23z just kidding
15:19:45 <Itkovian> OK, good luck. That'll counter at least one argument from a troll who shall remain unnamed 
15:19:55 <geheimdienst> you know, a puppet is actually a valuable debug tool for many people
15:20:08 <geheimdienst> it's called rubberducking
15:20:27 <k23z> geheimdienst: yes I was rubberducking when I was small and took a bath ..
15:21:02 <gwern> geheimdienst: is that actually a common term?
15:21:15 <gwern> I saw a blog once but didn't think it was anything but idiosynratic
15:21:26 <ksf> geheimdienst, to make it short, it's very, very easy to get started
15:21:41 <napping> It must be folklore by now, because I don't remember where I saw it
15:21:56 <ksf> it gets harder along the way, but nothing you can't tackle if you were able to start out with haskell in the first place :)
15:22:12 <dons> Itkovian: thanks :)
15:22:16 <geheimdienst> uh, i googled it to be sure, and there's quite a few hits. the first is a wiki page on c2.com
15:23:00 <ksf> geheimdienst, and it's cloaks, not hats.
15:23:19 <geheimdienst> ksf, thanks a lot. i just invested a few minutes trying profiling for the first time
15:23:54 * geheimdienst is not sure if there's an established term already for "rubberducking with a puppet called dons"
15:24:17 <napping> Did you make a cute little name tag?
15:24:24 * ksf has SCC's scattered over every case of every Applicative and Alternative function in his parser
15:25:08 <ksf> nothing beat actually being able to identify the closures that take up time.
15:25:43 <gwern> ksf: maybe you should write a tool to insert sccs on every line
15:26:08 <ksf> I'd rather have a tool that reliably prohibits open recursion
15:26:36 <ksf> hmmm well I could use data-reify and just ask fgl whether it sees loops
15:26:47 <napping> doesn't neil mitchell have something like that?
15:27:00 <ksf> actually, that's perfect.
15:27:03 <gwern> catch
15:27:07 <jedai> What's the problem with open recursion ?
15:27:11 <gwern> I'm not sure catch even works anymore. it was based on yhc iirc
15:27:16 <gwern> which isn't well maintained
15:27:24 <ksf> you quickly get grammars that aren't regular.
15:27:27 <napping> wait, what do you mean by open recursion? Isn't that usually to do with objects?
15:27:59 <ksf> open recursion is the recursion you do by saying foo = foo
15:28:00 <gwern> @wn eulexic
15:28:01 <lambdabot> No match for "eulexic".
15:28:14 <jedai> napping: What I know as open recursion is a version of a function that calls a function passed in parameter rather than itself
15:28:17 <mauke> that looks pretty closed to me
15:28:18 <ksf> as opposed to using something like fix, or, in my case, a kleene star.
15:28:43 <napping> you mean nontermination? or more general things like foo = ... foo ...
15:28:45 <jedai> but is clearly intended to use itself or a functional equivalent
15:28:56 <ksf> put differently, if you follow the pointers from the top expression, the subexpressions must form a tree, not a graph.
15:29:26 <napping> I'd call that cyclic definitions - and walking it with that expression reifier sounds like a good solution
15:29:35 <ksf> erm no the graph must not contain loops but that amounts to the same thing in practice I think
15:29:39 <napping> Catch doesn't do that, I think
15:29:52 <djahandarie> ksf, well the cover tree of a graph with loops would be infinite, I think
15:30:08 <kmc> c_wraith, you can run the splice as ordinary Haskell code using runQ
15:30:12 <kmc> and profile it in the ordinary way
15:30:32 <c_wraith> oh, I missed runQ.  That's handy.
15:31:39 <kmc> yes, for testing as well, e.g.: pprint <$> runQ [| 2 + 3 |]
15:31:46 <kmc> see what your splices actually generate
15:36:11 <c_wraith> ok...  generating the splice is fast.  it's actually doing the splice that's slow.  yikes.  These splices are creating huge string constants.  Should I assume that's a bad thing?
15:37:06 * ksf vaguely remembers a bug involving large constants, but thinks it has been fixed
15:37:15 <_Cactus_> Saizan: I tried to memoize the interpretation of the loop body
15:37:17 <_Cactus_> Saizan: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26470#a26470
15:37:29 <_Cactus_> Saizan: but the profiler still shows that evalStep is called a huge number of times
15:37:36 <ksf> if you generate much data, it might be a better idea to generate a data file
15:37:38 <c_wraith> Hmm.  I'm using 6.10.4  If if's the large object fix, that wasn't until 6.12
15:38:02 <_Cactus_> Saizan: got any ideas?
15:38:04 <c_wraith> though the large object bug caused crashes, as I recall
15:38:12 <c_wraith> And I'm not seeing crashes, just slow compiles
15:38:28 <napping> are you constructing your string in an O(n^2) way?
15:38:31 <ksf> maybe they're not large enough
15:38:45 <c_wraith> napping, no, the string construction is fast.  It's splicing that's slow.
15:38:50 <napping> and is it any slower than compiling a literal file with the same strings?
15:40:26 <c_wraith> Hmm.  ksf, is there a way to create a data file when a package is installed, and then get an easy reference to its location at runtime?
15:40:38 <c_wraith> and do all this in a manner supported by cabal?
15:40:47 <ksf> there's an even better way
15:40:59 <ksf> ...generate a .o file, either through gcc or gas
15:41:35 <Philonous> Why is it, that ghc complains about overlapping instances, But when I remove the transformers package, my code suddenly compiles? Could I possibly include a module without ghc complaining when I remove it? 
15:41:47 <ksf> cabal does some [/usr|~/.cabal]/share stuff, too.
15:42:11 <djahandarie> `either (error.show) id`   is kinda nice
15:42:35 <Botje> _Cactus_: if your function /didn't/ pass memory around you could bind "eval p" to a value and simply run it as much as necessary, i think
15:43:04 <_Cactus_> Botje: but isn't this what evalStep (While p) does?
15:43:59 <Botje> you're creating a new action each time and you can't lift it out because it depends on m
15:45:03 <Botje> okay, and now sleeptime
15:45:12 <Botje> getting up in 7 hours. whee!
15:46:26 <dancor> @pl \ x -> f x `h` g x
15:46:27 <lambdabot> liftM2 h f g
15:46:29 <Philonous> Ah, I see, monads-fd was the culprit, it's module names clash with mtl and I must have hidden mtl instead of monads-fd, which lead to the curious overlapping instance situation. 
15:47:28 * geheimdienst thinks monads-fd and monads-tf have been developed to expose innocent newbies to curious errors
15:47:51 <geheimdienst> as in, broadening their knowledge of ghc error messages
15:47:55 <Cale> heh
15:48:18 <geheimdienst> i had the same thing just a few days ago with monads-tf and mtl, whatever these things are
15:48:22 <orlandu63> dancor: why is it called liftM2?
15:48:23 <Cale> The thing which annoys me is that neither of them actually fixes any of the problems with mtl, while being incompatible with it.
15:49:08 <geheimdienst> cale, so monads-tf was a developed in reaction to mtl. what's monads-fd? some complementary thing to -tf?
15:49:08 <Cale> orlandu63: It lifts a plain function of two parameters to have monadic parameters and result
15:49:34 <Cale> geheimdienst: Yes, it's essentially mtl all over again.
15:49:39 <napping> lift - M - 2
15:49:43 <Cale> geheimdienst: with things split up a bit differently
15:49:55 <Cale> :t liftM2
15:49:56 <lambdabot> forall a1 a2 r (m :: * -> *). (Monad m) => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
15:50:01 <geheimdienst> and mtl is some mature-ish base-ish thing, but people are unhappy with it?
15:50:09 <Cale> Yeah.
15:50:24 <arnihermann> do you know where cabal installs on a mac (latest haskell platform) ?
15:50:28 <napping> orlandu63: lots of stuff gets the M suffix when it goes to monads - mapM, zipM, etc
15:50:47 <c_wraith> hmm.  It's not the length of the string constants that's making it slow.  I don't know what it is.
15:50:49 <geheimdienst> arnihermann, have you checked if there's a directory ".cabal" in your home dir?
15:50:52 <aavogt> they implicitly put a 'sequence' function there
15:50:56 <c_wraith> Maybe I'll just ignore it
15:51:00 <Cale> mtl contains ListT, which is broken, rather than a real nondeterminism monad transformer (those exist), and these other packages copy that
15:51:05 <Philonous> geheimdienst: This situation could easily resolved by mandating that Module on hackage names start with the package's name they are shipped in. But I guess it is actually a scheme to avoid success. 
15:51:28 <kmc> let's adopt the Java solution
15:51:31 <arnihermann> geheimdienst: yes, there is none
15:51:32 <Cale> and then there's the silly thing about Either's instance of Monad being a bit screwy
15:51:37 <kmc> org.haskell.Data.Map
15:51:46 <ksf> is there any _existing_ applicative syntax?
15:51:54 <monochrom> import "monads-tf" Control.Monad.State
15:52:06 <Cale> and then there's the minor style issue that the result value should always be second in a pair, because (,) t is a functor for any type t
15:52:14 <Cale> But in mtl, it's always first
15:52:14 <aavogt> that won't fix the duplicate/overlapping instances problem
15:52:15 <kmc> ksf, she has some
15:52:17 <geheimdienst> philonous, there's some merit to that idea. a drawback is however that you couldn't make packages that are a "drop-in" api-compatible replacement for something else
15:52:29 <kmc> http://personal.cis.strath.ac.uk/~conor/pub/she/idiom.html
15:52:46 <ksf> zomg
15:52:54 <ksf> I spelled strathclyde right the first time.
15:53:45 <arnihermann> geheimdienst: I can see haddock on path, but not cabal
15:54:23 <Philonous> monochrom: Yes, right. That would work, too, but it involves a language extension that wouldn't sctrictly be necessary otherwise. But I guess I can't have my cake and eat it, too. 
15:54:49 <ksf> kmc, I don't think that does what I want
15:54:56 <kmc> what do you want?
15:55:15 <geheimdienst> arnihermann, i guess you could look at the output of "ghc-pkg list". however a ghc package is not quite the same as a cabal package ...
15:55:48 <ksf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26471#a26471   without the monad
15:56:19 <ksf> that is, take the pure something line and put in a lambda in front of the preceding stuff
15:56:42 <arnihermann> geheimdienst: right, cabal is there, just no binary
15:58:24 <kmc> ksf, i don't understand you
15:58:49 <arnihermann> geheimdienst: sounds like a bug in the mac build... unless someone else can step forward with a cabal binary coming from the 2010.1 platform on mac
15:59:00 <Apocalisp> In general, how do you find the fixed point of a functor like: F a = a | F (G a)
15:59:16 <ksf> that is, I want a do-like syntax with only a single "statement" and the <- bindings are visible only there.
15:59:30 <gwern> you simply take the zygomorphic histomorphism
15:59:34 <kmc> something like this?  «ado { x <- a; y <- b; pure (f x y) }» === «liftA2 f a b»
15:59:36 <kmc> yeah ok
15:59:37 <ksf> otherwise, applicative is just utterly pointless.
15:59:45 <kmc> hehe
16:00:16 <kmc> i think it might look more natural if it were more like a comprehension
16:00:19 <geheimdienst> arnihermann, could you elaborate a little on your problem? cabal can't install packages ...?
16:00:21 * hackagebot tagsoup-parsec 0.0.7 - Tokenizes Tag, so [ Tag ] can be used as parser input.  http://hackage.haskell.org/package/tagsoup-parsec-0.0.7 (JohnnyMorrice)
16:00:32 <kmc> list comprehensions already have an implicit "return"
16:00:38 <ksf> sounds good
16:00:53 <ksf> ...there's been a lot of bikeshedding, but afaict no implementation
16:00:55 <kmc> you could write a little TH to quote a list compr and generate applicative code
16:01:00 <kmc> if you want to prototype this
16:01:03 <napping> Does anyone here use Lava?
16:01:34 <napping> kmc: the type checking on the quote will probably stop you
16:01:48 <kmc> hmm that's rude
16:02:03 <kmc> quotes are type-checked?
16:02:09 <napping> yep. Well - I guess it might work for anything in an otherwise free applicative type
16:02:51 <arnihermann> geheimdienst: I just installed haskell platform on mac, there is no cabal binary (although there are binaries for ghc, ghci, ...)
16:03:20 <kmc> well you could do it with haskell-src-meta then
16:03:28 <kmc> sounds like a pita though
16:03:34 <napping> yeah, it is
16:03:40 <arnihermann> geheimdienst: oh there are 2 .pkg files
16:04:03 <ksf> runQ [| [x | x <- pure 1 ] |]
16:04:07 <ksf> that works in ghci
16:04:09 <ksf> well...
16:04:19 <napping> yeah, cause pure 1 :: [Int]
16:04:25 <napping> (among other types)
16:04:28 <arnihermann> geheimdienst: sorry, in the installer, there are 2 pkg files, which need to be installed, the second one (hidden by scroll) contained the cabal binary
16:04:33 <ksf> CompE [BindS (VarP x_2) (AppE (VarE Control.Applicative.pure) (LitE (IntegerL 1))),NoBindS (VarE x_2)]
16:04:45 <kmc> it seems that type checking inside a splice does not resolve instances
16:05:03 <napping> Hmm? You get untyped syntax, it just typechecks it first
16:05:09 <kmc> yeah i know
16:05:20 <ksf> runQ [| [x <|> y | x <- pure 1, y <- 2 ] |]  works fine.
16:05:29 <napping> sure.
16:05:44 <kmc> but it doesn't do instance resolution during that typechecking phase
16:05:47 <kmc> [| 2 3 |] works fine
16:05:58 <napping> hmm, that's interesting
16:06:03 <geheimdienst> arnihermann, sounds kinda strange :-) i have no idea what the guys did there with the mac release
16:06:05 <kmc> doesn't care that there's no instance for Num (a -> b)
16:06:09 <djahandarie> > 2 3
16:06:10 <lambdabot>   Ambiguous type variable `t' in the constraint:
16:06:10 <lambdabot>    `GHC.Num.Num t' arising f...
16:06:10 <kmc> TH is very odd
16:06:10 <djahandarie> OR IS THERE
16:06:12 <djahandarie> Oh
16:06:14 <napping> that helps a bit I guess
16:06:14 <djahandarie> Damnit
16:06:18 <kmc> nice djahandarie
16:06:27 <napping> still, [| [ x | x <- Just 1 ] |]
16:06:29 <napping> fails
16:06:53 <kmc> you could quote a "do" instead
16:07:15 <napping> that might actually work
16:07:29 <napping> applicatives have to be * -> * anyway, right?
16:07:42 <ksf> but I really, really like the comprehension idea
16:08:08 <ksf> no room for multiple pures and order is apperant and natural, too.
16:08:14 <napping> Like I said, it will work as long as you stay to class methods list satisfies
16:09:44 <napping> Hi conal. Anything interesting in FRP these days?
16:10:27 <gwern> the otehr day I ran into an anon on Wikipedia who suggests that [[functional reactive programming]] and [[reactive programming]] be merged
16:10:37 <gwern> since they were just duplicates after all
16:10:43 <Eduard_Munteanu> Hm, I didn't check Grapefruit in awhile...
16:10:57 <kmc> how hard is it to implement new sugar in GHC itself?
16:11:21 <napping> I had a notion to do discrete time streams that only allow the semantics direct access to one unit of history. I haven't checked how for it works out, though
16:11:27 <conal> napping: there are a few threads of frp exploration going on, i think by luqui, sinelaw, and jmcarthur.  maybe others.  i'll get back into it at some point.
16:11:39 <napping> kmc: probably easier to rip out the type checking from TH
16:11:46 <kmc> yeah
16:11:49 <gwern> napping: sounds like lineartypes. 'the latest one is free, but you pay to go back in time'
16:11:50 <kmc> it'd be nice to be able to disable that
16:11:52 <kmc> maybe there is some flag
16:12:25 <ksf> wait shouldn't I be fine in any case as list obviously has an applicative instance and what I care about are applicatives?
16:12:36 <napping> conal: Now for a real blast from the past - there was some talk on here a while ago about higher order pattern matching. Is your thesis still a decent starting point for tracking down references to the various tractable special cases?
16:12:57 <Saizan> kmc: you could make a quasiquoter with haskell-src-exts
16:13:00 <proq> are there any implementations of haskell written in javascript?
16:13:12 <gwern> proq: no
16:13:14 <napping> proq: yhc can target javascript, kind of
16:13:31 <napping> don't think it can bootstrap itself - or that a browser survives even if it can
16:13:45 <djahandarie> Would be nice to have a Javascript Prelude
16:13:49 <djahandarie> Minus infinite list stuff
16:13:58 <napping> I imagine  cross compiling is more likely to have practical applications
16:14:09 <FauxFaux> Aww http://darcs.haskell.org/yhc/web/jsdemos/HsWTKDemo.html is broken.
16:14:13 <Eduard_Munteanu> Um, why even bother?
16:14:34 <napping> ksf: that's what I've been saying - but it won't work if you want code to work at a specific type
16:14:39 <geheimdienst> eduard, dude, javascript is the most-deployed language on the planet
16:14:40 <conal> napping: do you want a full decision procedure for unifiability?  an complete enumerator of unifiers?
16:14:50 <kmc> ksf, presumably you care about specific applicatives, not just writing code that works for every applicative
16:14:53 <aavogt> Saizan: quasiquoters don't get to know exactly which name you use, right?
16:15:10 <proq> Eduard_Munteanu: so you can tinker with haskell when you are offline on an iPad. (apple has a rule about interpreted languages on it)
16:15:13 <Saizan> aavogt: name?
16:15:19 <aavogt> Saizan: Name
16:15:29 <kmc> don't buy an iPad then
16:15:32 <Saizan> aavogt: of what?
16:15:36 <aavogt> of variables
16:15:52 <conal> the no-interpreters rule has softened recently
16:15:53 <Saizan> ah, no, a QQ just sees String, actually
16:15:55 <napping> conal: A precise definition of "higher order matching" to start with - then probably enumeration. I'm interesting in using it for the sort of things Agda uses it for
16:15:56 <aavogt> so that the macros are hygenic
16:15:58 <Eduard_Munteanu> geheimdienst: still, Javascript isn't generally used for this kind of stuff. And a Haskell compiler isn't trivial nor short to write
16:15:58 <proq> kmc: it's not about *me*  :P
16:16:07 <Eduard_Munteanu> proq: ah, I see.
16:16:09 <napping> proq: jailbreak?
16:16:24 <kmc> let's be clear about "write a compiler in JavaScript" versus "write a compiler which produces JavaScript"
16:16:26 <proq> napping: no, I'm writing an app
16:16:30 <conal> napping: is (one-way) matching enough, or do you want (two-way) unification?
16:16:34 <kmc> perhaps you need both for your app
16:16:36 <gwern> napping: if you're targeting hardcore geeks, just go with android
16:16:37 <Saizan> aavogt: i don't think that'd be a problem here
16:17:05 <aavogt> but in general it's a problem, no?
16:17:14 <napping> gwern: if you say "so you can tinker with Haskell" I don't think that's in question
16:17:33 <conal> napping as for a definition, "higher-order" means that the term language is a lambda calculus, and that matching or unification finds substitutions that makes terms be alpha-beta-eta convertible.
16:17:34 <ksf> yep runQ [| [x | x <- range 'a' 'b' ] |] won't work
16:17:37 <napping> conal: I'm not quite sure, but I think it's more like mapping
16:17:39 <djahandarie> kmc, well, once you have a compiler which produces JavaScript you could just compile the compiler
16:18:10 <geheimdienst> hm, sometimes it is used. i think e.g. that google GWT thing lets you write java, then compiles it to javascript. i mean, if you want to run inside a browser, there's not many options. javascript, flash, and that's about it ...
16:18:13 <kmc> presuming the compiler is written in the language you're compiling
16:18:16 <aavogt> ksf: if range is in scope...
16:18:25 <napping> conal: yeah, that part is fine - but definitions of the tractable special cases seem hard to find. I've heard "miller", but not been able to find references to his papers.
16:18:35 <ksf> it, indeed, is, and is a parser, not a list.
16:18:44 <aavogt> or this is not about using a quasiquoter instead of [| |]
16:18:49 <kmc> i think the simplest solution, as others mentioned, would be to implement YHC's bytecode interpreter in JavaScript
16:18:52 <conal> napping: dale miller.  look up his name and lambda-prolog, and you'll find some hits.
16:19:04 <kmc> which may already exist
16:19:05 <napping> Dale? hmm, that could be the problem.
16:19:09 * Eduard_Munteanu looks up this "rule", he
16:19:11 <proq> kmc: ok, I'll take a look
16:19:13 <kmc> then modify YHC to be self-hosting, if it's not already
16:19:14 <ksf> aavogt, the idea was to write an applicative-syntax in template haskell
16:19:17 <Eduard_Munteanu> 's obviously out of it.
16:19:42 <conal> napping: he had something i think he called L-lambda unification that was non-branching (no search).
16:19:45 <napping> conal: It's higher order *pattern matching* I'm not sure about - I think that just means the pattern is a closed term
16:20:12 <conal> napping: matching means one of the two terms is closed
16:20:19 <napping> proq: I've got hugs on my ipod
16:20:33 * geheimdienst uses the c backend of ghc, then uses regexes to make the c look more like javascript. needs some work but won't be long now ...
16:20:41 <kmc> haha
16:20:45 <proq> napping: that's cool, but I can't ship hugs with my app
16:20:56 <proq> napping: apple would never approve it
16:20:58 <napping> proq: oh, you want it for an app?
16:21:02 <Saizan> aavogt: i thought hygienicity(?) was more of a problem with variables generated by the macro rather than those given to it, but my macro-fu is quite weak
16:21:04 <kmc> proq, did you see http://projects.haskell.org/ghc-iphone/ also?
16:21:07 <kmc> it's not self-hosting
16:21:10 <proq> <proq> napping: no, I'm writing an app
16:21:27 <proq> it's a text editor basically
16:21:28 <napping> proq: there are some guys making games. cross-compiling is a different question
16:21:37 <Eduard_Munteanu> Right... it runs only software written by them.
16:22:01 <conal> napping: so that only one term gets specialized rather than both (as in unification)
16:22:36 <napping> conal: oh, right - no variables to instantiate.
16:22:45 <proq> napping: I'm aiming to have a haskell REPL, so it has to be javascript based or get rejected
16:22:51 <Saizan> aavogt: since i assume GHC respects the variable names given in the source, i.e. i'd expect "id :: a -> a; id x = $(Var (mkName "x"))" tp work
16:22:56 <Saizan> *to
16:23:13 <Saizan> s/Var/varE/
16:23:16 <Eduard_Munteanu> Well, can you find a C-to-Javascript compiler?
16:23:18 <proq> napping: either that or convince apple that it's not a threat
16:23:23 <gwern> proq: that sounds hopeless. just use a web interface to mueval like tryhaskell.org
16:23:28 <gwern> or whatever
16:23:31 <Eduard_Munteanu> jhc and ghc can output C(--) code.
16:23:32 <napping> I don't expect to learn it all now, I just remembered your thesis was on that. I think I might have implemented something from one of your papers once
16:23:49 <aavogt> kmc: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=26472#a26472
16:23:57 <napping> Now that I think about it, I should check Ulf's refernces more closely
16:24:18 <kmc> cool aavogt 
16:24:47 <kmc> i'm not sure ghc can output C-- actually
16:24:54 <kmc> or that it'd be particularly useful
16:24:58 <proq> gwern: if the user has an internet connection they won't need it.  they can just ssh to a machine with haskell on it
16:24:59 <kmc> it uses its own dialect of C-- named Cmm
16:24:59 <napping> conal: thanks. I'll let you know if I come up with interesting FRP stuff - I've also been trying to figure out if talk of sheaves gives you nicer ways of talking about history-respecting functions.
16:24:59 <aavogt> Saizan: it's also about which 'x' appears when you use:      let x = 1; q = [| \y -> x + y |] in let x = 2 in $q 0
16:25:11 <kmc> much more useful to output LLVM
16:25:20 <conal> napping: cool!
16:25:23 <Eduard_Munteanu> kmc: I'm not sure either. Though I hear it used to compile Haskell to C-- as intermediary in the past.
16:25:29 <aavogt> Saizan: though maybe those declarations must bu split across a couple modules
16:25:38 <gwern> proq: so all users with internet connections have ssh installed, know how to use it, and have ssh access to a machine with haskell?
16:25:43 <gwern> proq: interesting beliefs you have
16:25:59 <proq> gwern: the ones that know how to program haskell, yes
16:26:07 <gwern> I guess lamdabot's > is useless because we all have access to machines with haskell
16:26:12 <gwern> or we can easily install haskell
16:26:16 <kmc> GHC's last internal language is named Cmm and is a dialect of the independently spec'd language named C--
16:26:18 <napping> conal: I'm pretty sure you can define history-respecting functions as a certain kind of presheaf-valued-presheaf, but not that this gives you a nicer way of talking about anything :)
16:26:23 <Eduard_Munteanu> And as far as I've seen, C-- is pretty much compatible with C compilers.
16:26:29 <kmc> Eduard_Munteanu, not even close
16:26:40 <kmc> maybe you mean something different by C--
16:26:45 <aavogt> are we talking about unregisterized ghc builds?
16:26:49 <proq> gwern: the help document in the app will make it very clear that they should do this to have access to their language of choice
16:27:06 <Eduard_Munteanu> kmc: perhaps I'm mistaken, I thought it was mostly a subset of C with similar syntax.
16:27:12 <kmc> it's not
16:27:15 <napping> proq: honestly, Haskell doesn't seem like a very nice language for doing editor extensions
16:27:27 <kmc> it has similar syntax to C, but is not a subset and is not even close to standard C
16:27:29 <proq> gwern: this is of course to help improve the user experience where they have *no interpreted languages* but want to learn some in the text editor
16:27:42 <napping> proq: at a minimum, you'd need to write a bunch of framework for exposing hooks for scripts
16:27:49 <kmc> it seems that cminusminus.org has expired
16:27:54 <proq> gwern: none but javascript, I mean
16:28:18 <Eduard_Munteanu> http://web.archive.org/web/20080822062234/http://www.cminusminus.org/ from Wikipedia
16:28:35 <proq> napping: it's not for editor extensions, just for allowing the user to learn haskell
16:28:49 <kmc> thanks Eduard_Munteanu 
16:28:52 <kmc> look at http://web.archive.org/web/20080822062234/http://www.cminusminus.org/extern/man2.pdf
16:28:57 <proq> napping: while they are offline, etc.  when they are online, I could rig something like gwern mentioned maybe
16:29:01 <napping> oh, so it is specifically as a Haskell shell
16:29:22 <proq> napping: yes
16:29:28 <kmc> why do you want to jump through hoops to program for a hostile platform?
16:29:46 <napping> kmc: nice portable hardware
16:29:57 <conal> napping: keep tinkering with a eye on elegance, and you may find something beautiful & useful.
16:30:05 <proq> kmc: that's a very good question, to which I have no answer  :'(
16:30:14 <Eduard_Munteanu> kmc: hm, yes, it seems rather not trivial to make a C compiler grok that code.
16:30:29 <kmc> Eduard_Munteanu, yeah.  GHC can compile it,  though (modulo the difference between Cmm and C--)
16:30:43 <napping> conal: thanks for the advice. I'm worried the presheaf-value-presheaf bit is already getting a bit heavy elegance.
16:30:45 <kmc> at this point I think C-- is effectively dead, except as the basis for one of GHC's stages
16:30:55 <kmc> LLVM seems to have beat it as a general-purpose backend
16:31:19 <gwern> llvm does seem to be quite successful
16:31:25 <kmc> yes
16:31:31 <kmc> i'm quite pleased
16:31:34 <gwern> not that I understand what exactly llvm is. it seems to be a lot of things
16:31:40 <kmc> it is
16:31:41 <Eduard_Munteanu> Yeah, who would've thought that about an university research project :P
16:31:58 <napping> proq: are you sure you have a market? If it's for yourself you don't need to worry about approval, and there's hugs in the shell for those willing to jailbreak
16:32:08 <kmc> it's
16:32:15 <gwern> its
16:32:21 <kmc> (monty python's flying circus?)
16:32:36 <proq> napping: I think so.  I guess I'll find out when I submit it
16:32:44 <kmc> - a programming language with an SSA, assembly-ish feel, but relatively platform agnostic and e.g. having an infinite number of registers
16:32:53 <Eduard_Munteanu> Well, the LLVM name is rather confusing at first.
16:32:56 <kmc> - three concrete syntaxes for that language (one textual, two binary)
16:32:59 <proq> napping: but yes, I will make my own personal version with hugs in it  :D
16:33:04 <kmc> - a C++ library for manipulating those languages
16:33:23 <kmc> - a set of command-line tools implemented with that library
16:33:26 <napping> multiple backends
16:33:29 <napping> a jit
16:33:32 <napping> optimization passes
16:33:39 <napping> and a partridge in a pear tree
16:33:39 <kmc> yeah
16:33:46 <Eduard_Munteanu> Basically it's a JIT/AOT compiler (the right approach in my mind is not to separate these two) with an invented machine spec you use for portable assembly
16:33:55 <kmc> AOT?
16:34:00 <geheimdienst> ahead-of-time
16:34:05 <kmc> yeah
16:34:06 <geheimdienst> (normal compiler)
16:34:08 <Eduard_Munteanu> Yeah, like ordinary compilers.
16:34:12 <Saizan> aavogt: ah, true, though a quasiquoted expression gets spliced on the spot, so that case won't apply, unless you do something tricky like making a quasiquoter that produces a th macro to splice later
16:34:13 <kmc> well you can also interpret LLVM code without any compilation
16:34:30 <kmc> the dream is that one day your compiler is just a shell script which invokes a frontend, one or more pluggable optimizations, and a backend
16:35:00 <kmc> it's also nice for generating, compiling, and linking code on the fly
16:35:00 <aavogt> Saizan: yeah, if you add one more lift to the output of the QQ
16:35:05 <Eduard_Munteanu> Well yes.
16:35:07 <kmc> for compiling DSLs and the like
16:35:10 <geheimdienst> i guess the main selling point of llvm is that if you can somehow transmorify $your_language into llvm bytecode, then you get a whole lot of aggressive optimizations
16:35:15 <geheimdienst> is that right?
16:35:26 <kmc> geheimdienst, yes, and you get working backends for many architectures
16:35:41 <kmc> it saves you the trouble of writing the part of a compiler that is a) very hard to get right, and b) mostly a solved problem
16:35:49 <ksf> wasn't what's missing from platform independence endianess-obliviousness?
16:35:58 <kmc> maybe
16:36:03 <gwern> what major platforms are big-endian?
16:36:09 <Eduard_Munteanu> PPC
16:36:12 <napping> ARM
16:36:16 <kmc> mips and arm sometimes
16:36:16 <ksf> that was what some people were worried about wrt. nacl
16:36:19 <Eduard_Munteanu> MIPS (if you select it)
16:36:29 <Eduard_Munteanu> it's bi-endian though
16:36:52 <napping> is mips the only selectable one?
16:36:57 <kmc> PPC is too i think
16:37:15 <kmc> of course LLVM is only useful for certain types of optimization
16:37:18 <ksf> well, it's a matter of using "give me the high byte" instead of "do those and those shifts"
16:37:27 <Eduard_Munteanu> Usually biendianness isn't cheap.
16:37:28 <geheimdienst> so you could say: java = vm + runtime + language + standard library. llvm = vm. right?
16:37:34 <kmc> fortunately a compiler writer is probably more interested in cool high-level optimizations for her fancy new language
16:37:35 <Eduard_Munteanu> So it's not worth unless you have a use for it.
16:37:45 <kmc> than in knowing how many cycles this vs. that instruction takes on this obscure cpu
16:37:49 <geheimdienst> (by runtime i mean services like GC)
16:37:53 <ksf> llvm isn't a vm
16:38:07 <kmc> yes it is
16:38:09 <kmc> every language is a vm
16:38:20 <geheimdienst> lol
16:38:21 <ksf> does it even come with an interpreter?
16:38:23 <kmc> yes
16:38:28 <ksf> ok, then it is.
16:38:28 <geheimdienst> i'm not entirely following you
16:38:29 <Eduard_Munteanu> ksf: it is in the sense it provides a machine with its own instructions.
16:38:49 <kmc> a "virtual machine" is an operational semantics
16:39:04 <kmc> probably implying that it's not intended that anyone ever implement these semantics "directly in hardware"
16:39:20 <ksf> infinite registers would be nice
16:39:21 * Dashkal wants a ghc runtime in llvm...
16:39:22 <kmc> but a) it's not clear what "directly in hardware" means, and b) people will do it anyway (see: Java)
16:39:30 <geheimdienst> i mean: vm = something that takes a defined instruction set and translates it for $native_instruction_set_1, $native_instruction_set_2, ...
16:39:31 <kmc> Dashkal, you can compile all of GHC's RTS to LLVM
16:39:36 <ksf> well at least maxBound Int registers
16:39:37 <Eduard_Munteanu> Similarly, I hear there were implementations of Java CPUs, despite the "virtual" in its name.
16:39:42 <kmc> yes
16:39:53 * Dashkal blinks
16:39:54 <Apocalisp> If I've something like... data Foo a = One a | Many (Foo [a])
16:39:54 <Apocalisp> What is the functor of which Foo a is a fixed point?
16:40:23 <Eduard_Munteanu> Actually VM is meant as an environment, not neccessarily limited to the CPU.
16:40:24 <kmc> data FooF a self = One a | Many (self [a])
16:40:24 <ksf> but then we should try and make cpus dumber, at least not make x86 any smarter
16:40:39 <Dashkal> Then what exactly is making targeting ARM so difficult?  ghc will output portable C, you can get the RTS for LLVM (which can run on arm...)
16:40:42 <ksf> it's wasting way too much transistors on runtime code analysis, already.
16:40:46 <Eduard_Munteanu> Hence various semantical differences between VM, bytecode, vcpu, JIT etc.
16:40:50 <kmc> Dashkal, what makes you think it is difficult?
16:40:57 <Dashkal> I've asked about it before
16:41:02 <ksf> it's already been done.
16:41:14 <Apocalisp> kmc: Oh yeah :)
16:41:16 <Eduard_Munteanu> I'm curious if a functional-style assembly code is possible.
16:41:21 <ksf> ...a bit hakish and with the c backend
16:41:43 <kmc> Dashkal, Debian for arm linux ships with ghc
16:41:47 <kmc> you can apt-get install it
16:41:54 <ksf> assembly is a dfa, isn't it?
16:41:59 <Dashkal> hmm, when I get my hands on a jailbroken smartphone I'll be asking about this again...
16:42:03 <Eduard_Munteanu> I mean an actual CPU implementation of an instruction set.
16:42:12 <Eduard_Munteanu> DFA?
16:42:14 <aristid> ksf: assembly is a discrete finite automaton?
16:42:18 <kmc> (that's the armel architecture, not to be confused with the arm architecture... both are little-endian, long story)
16:42:19 <Eduard_Munteanu> Oh.
16:42:22 <napping> man, JVM is obviously not designed for hardware implementation
16:42:24 <ksf> Eduard_Munteanu, google "reduceron"
16:42:28 <Draconx|Laptop> kmc, yeah, but ghci doesn't work if you use the debian package. (rather, it didn't last time I tried).
16:42:33 <Eduard_Munteanu> ksf: ah, I know about that.
16:42:34 <kmc> Draconx|Laptop, correct
16:42:42 <kmc> Dashkal, as for smartphones, ghc-iphone already exists, and i'm working on ghc-android
16:42:43 <Eduard_Munteanu> ksf: but it's Lispy
16:42:44 <kmc> with good progress
16:42:46 <geheimdienst> well surely you don't need a haskell compiler on your phone. it should be enough that on the laptop you can cross-compile haskell and put it on the phone
16:42:47 <Eduard_Munteanu> *Lispish
16:42:51 <ksf> aristid, well, you have a finite number of states, and every input transforms it.
16:42:59 <napping> there's just gratuitious things like having + - / * etc all defined for int, long, float, object in a big cycle - and not starting the bytecodes at a multiple of four
16:43:01 <ksf> turing completeness is an illusion.
16:43:01 <Eduard_Munteanu> And it's only meant to speed up working with lists.
16:43:03 <Dashkal> kmc: android is the one I'm looking for.  I won't start on apple's developer policies
16:43:03 <aristid> ksf: isn't every computer a DFA in that sense?
16:43:10 <ksf> yes
16:43:10 <Eduard_Munteanu> No.
16:43:19 <aristid> kmc: ghc for android? cool
16:43:25 <kmc> Dashkal, all three currently use unregisterised via-C builds
16:43:46 <Eduard_Munteanu> AFAIK a DTM is more powerful and distinct to a DFA.
16:43:47 <kmc> LLVM is a good idea but currently GHC's LLVM output is not ABI-compatible with its C output
16:43:51 <napping> Did they guys who assigned java bytecode numbers hate the guys going the instruction decoding circuitry or what?
16:43:51 <ksf> geheimdienst, that doesn't mean there aren't arms that should have a ghc
16:43:57 <ksf> like e.g. pandoras.
16:44:00 <kmc> so it'd be an all-or-nothing switch
16:44:08 <Eduard_Munteanu> (Deterministic Turing Machine)
16:44:09 <kmc> also, making GHC via-C on ARM registerised might not be too hard
16:44:12 <Draconx|Laptop> kmc, is that a problem?  Doesn't the GHC ABI break with every release as it stands?
16:44:15 <geheimdienst> kmc, when you say ghc-android, you are referring to a compiler that produces code that can run on the phone ... right? not the compiler running on the phone
16:44:20 <kmc> geheimdienst, correct
16:44:26 <kmc> though since GHC is self-hosting
16:44:29 <kmc> the latter is a possibility
16:44:31 <FauxFaux> I'd be suprised if debian adn co didn't already build it.
16:44:40 <kmc> Draconx|Laptop, it means we'd need to be sure that LLVM will work for everything
16:44:42 <FauxFaux> (They do)
16:44:44 <aristid> kmc: do you use java or the native stuff?
16:44:48 <kmc> native
16:44:51 <Dashkal> I'd be perfectly happy with the former, so long as there are bindings to gui libraries
16:44:56 <kmc> but apps have to be Java
16:45:02 <kmc> so you need a Java wrapper to call the Haskell code by JNI
16:45:07 * geheimdienst still is of the opinion that who the fuck would want to compile things with their phone
16:45:11 <kmc> API bindings forthcoming :)
16:45:12 <Dashkal> ahh, or that I suppose
16:45:21 <ksf> geheimdienst, not all arms are phones
16:45:26 <Dashkal> doing the UI in java would be less painful anyway.  Not fond of haskell ui work.
16:45:29 <kmc> at least for ARM Linux, and for ARM Android probably (because it's similar), I expect we could do registerised via-C without too much trouble
16:45:31 <aristid> kmc: but you can embed native code in apps that are in the market?
16:45:31 <ksf> in fact, arms will replace x86
16:45:34 <kmc> aristid, yes
16:45:35 <FauxFaux> geheimdienst: I have build-essential on my 'phone just in case I fancy doing some c/++ development.  Eclipse works well, too.
16:45:38 <ksf> </prophet>
16:45:45 <Dashkal> geheimdienst: I would.  I used to play with a lua editor environment on my palm 3
16:45:49 <kmc> Dashkal, isn't UI desgin mostly done in declarative specification languages
16:45:52 <napping> geheimdienst: a new phone is faster than my second-newest laptop (old G4 mac)
16:45:52 <Eduard_Munteanu> x86 is a goddamn mess.
16:45:53 <geheimdienst> ksf, yes i agree, it's just that the discussion went so far in the direction of android and so on
16:46:08 <FauxFaux> Yeah, faster than my netbook.
16:46:26 <ksf> it'd be hard not to run on android, it's a linux, after all
16:46:27 <Dashkal> kmc: I'm not (yet) that familiar with android.  If I made no sense, disregard.  Problem 1 is the cashflow issue.  A new android is NOT cheap for someone not willling to bind to a 2-3yr contract
16:46:28 <kmc> Dashkal, what's wrong with haskell UI work
16:46:34 <Eduard_Munteanu> I've been looking with interest towards NISC CPUs (those which have no instruction decoder)
16:46:39 <ksf> also if the userspace is nothing like what one's used to.
16:46:42 <ksf> *even
16:46:50 <napping> Eduard_Munteanu: umm, how does that work?
16:46:50 <Dashkal> kmc: Inherently, nothing.  The problem is all my previous UI experience is in Java.
16:46:55 <kmc> Dashkal, get the chinese knockoff ipad that runs android and costs like $150
16:47:00 <napping> Eduard_Munteanu: surely you have an opcode mux if nothing else
16:47:10 <Eduard_Munteanu> napping: not really.
16:47:21 <gwern> napping: maybe it only has one instruction
16:47:28 <gwern> like 'subtract and branch if negative'
16:47:31 <Eduard_Munteanu> napping: normally the instruction decoder sets some internal signals. In NISC they're exposed.
16:47:38 <Eduard_Munteanu> gwern: no.
16:47:39 <geheimdienst> dashkal, i got my motorola droid for around €370 (unlocked without contract). i'd expect to pay the same if e.g. i wanted a netbook or something
16:47:41 <Dashkal> Java/Swing -> Haskell/GTK is not exactly a smooth transition.  ANd on a related note, I'm more interested in the new QT stuff
16:48:03 <Eduard_Munteanu> napping: so your opcode is made of all those control lines values you want for that execution cycle.
16:48:07 <geheimdienst> so it's not really _that_ expensive considering you basically get a kinda netbook shrunk to pocket-size
16:48:20 <zakwilson> Has anybody written a compiler (for a language other than JVM bytecode) that emits Dalvik VM bytecode?
16:48:20 <geheimdienst> (with calling capability)
16:48:21 <gwern> 'NISC is a statically-scheduled horizontal nanocoded architecture (SSHNA). The term "statically scheduled" means that the operation scheduling and hazard handling are done by a compiler. The term "horizontal nanocoded" means that NISC does not have any predefined instruction set or microcode. The compiler generates nanocodes which directly control functional units, registers and multiplexers of a given datapath. Giving low-level control to compiler ...
16:48:21 <Dashkal> geheimdienst: That sounds approximently right.  I also have to tack on approx $100 to pay for my existing phone (not quite a contract, I can leave, but I have to pay off the phone).
16:48:28 <gwern> ... enables better utilization of datapath resources, which ultimately result in better performance. '
16:48:34 <gwern> wow. that sounds pretty weird
16:48:41 <ndxtg> New definition of map: map' f xs = foldr ( ( : ).f) [] xs    <---- what exactly is (: ) . f  ? I know ":" is to concat but what is the dot "." ?
16:48:42 <kmc> zakwilson, not to my knowledge.  but you can compile many languages to JVM and then to Dalvik
16:48:59 <kmc> it'd only make sense if your language can run efficiently on Dalvik and not on JVM
16:49:01 <gwern> maybe we can run our exokernels on our nisc computers
16:49:06 <kmc> but that's possible, since they have pretty different designs
16:49:18 <geheimdienst> gwern, what are you smoking?
16:49:28 <zakwilson> kmc: I know. It was more a curiousity than a question of whether a given language can target Android.
16:49:29 <Eduard_Munteanu> gwern: think that your instruction is 10010010, where the 1st bit says "increment PC", the second selects the destination register lower/upper half etc.
16:49:32 <napping> sounds pretty unstable. I bet you'll figure out which combinations are sensible and compress that to a smaller code
16:49:44 <kmc> ndxtg, (:) is just the function \x xs -> x:xs
16:49:47 <kmc> like any other infix operator
16:49:55 <Eduard_Munteanu> The real problem is the really large pseudoinstruction length
16:49:57 <kmc> when you put it in parens, you get something usable as an ordinary function name
16:50:07 <kmc> just like (+) or (++)
16:50:16 <kmc> (.) is function composition
16:50:18 <kmc> @src (.)
16:50:19 <lambdabot> (f . g) x = f (g x)
16:50:19 <lambdabot> NB: In lambdabot,  (.) = fmap
16:50:36 <Gracenotes> zakwilson: I've considered a compiler that emits Dalvik VM bytecode
16:50:53 <Gracenotes> zakwilson: it's certainly possible, and Dalvik is an interesting bytecode
16:50:54 <napping> Gracenotes: how is the Dalvik bytecode?
16:51:16 <geheimdienst> pretty much java bytecode, right?
16:51:28 <kmc> > (:) 2 [3,4,5]
16:51:29 <lambdabot>   [2,3,4,5]
16:51:31 <Eduard_Munteanu> napping: normally you won't even touch assembly code on that, you'll write/use a compiler.
16:51:32 <Gracenotes> interesting because of the modifications made to fit in a mobile device
16:51:34 <ndxtg> kmc: right.. all clear
16:51:34 <napping> the numbering and constant coding for the JVM bytecode are a huge pain
16:51:34 <kmc> > ((:) . succ) 2 [3,4,5]
16:51:38 <lambdabot>   mueval-core: Time limit exceeded
16:51:40 <kmc> uh
16:51:40 <Gracenotes> zakwilson: unfortunately the main, and rather large, deterrent is that you have to integrate closely with the android toolchain
16:51:47 <Gracenotes> that's what put me off from doing it
16:51:59 <Gracenotes> because I'm not totally familiar with it, and it's changing all the time anyway
16:52:09 <napping> Eduard_Munteanu: sure, but even just to minimize instruction fetch bandwidth I doubt having a full range of signals pays off
16:52:19 <zakwilson> Gracenotes: What larguage were you going to compile? Haskell?
16:52:42 <geheimdienst> gracenotes: what, really? but when the bytecode standard changes, you can't run old apps anymore
16:52:44 <Gracenotes> well, that would be the plan, but as I said I'm not doing it. it's on a high-up shelf at least
16:53:04 <Eduard_Munteanu> napping: yeah, that's a problem. Some say it pays off at least partly because you can schedule multiple operations at the same time.
16:53:24 <Eduard_Munteanu> *explicitly schedule
16:53:33 <Gracenotes> geheimdienst: that's not that big of a problem.. it'll still run on old phones :)
16:53:35 <napping> oh, interesting. I guess you would explicitly schedule pipelining
16:53:43 <Gracenotes> and more instructions = better
16:53:44 <Eduard_Munteanu> You also don't need any smarts in the CPU to do pipelining.
16:53:49 <geheimdienst> so it's mostly additions, not changes
16:54:07 <Eduard_Munteanu> napping: yes.
16:54:26 <Gracenotes> it's whatever they think matches up with ARM best, since I don't think they have JIT yet in any significant way
16:54:41 <Gracenotes> but will be adding it, if they haven't done piles of development already
16:54:47 * kmc wonders if SMT is effective for mobile / low-end / low-power devices
16:55:00 <kmc> Atom dropped OOE from x86; can you get the performance back at less cost with SMT?
16:55:14 <kmc> right Atom has SMT ;)
16:55:22 <kmc> makes sense
16:56:04 <napping> Eduard_Munteanu: how do conditional jumps work?
16:56:40 <Eduard_Munteanu> napping: naturally they'd work just like in a normal CPU, except they're directly under control of opcodes instead of the insn decoder.
16:56:43 <napping> I guess pipeline squash goes at the jump targets
16:57:21 <napping> hmm, I guess it's not quite as crazy
16:57:24 <Eduard_Munteanu> napping: I guess you can set cache prefetch control lines yourself if you do scheduling.
16:57:59 <napping> no, I was talking about abandoning speculatively executed instructions that start in the pipeline after the conditional jump but before it resolves
16:58:26 <Eduard_Munteanu> napping: well, you wouldn't do speculative execution at all, it's all written in the instruction :)
16:58:42 <napping> sure you would
16:59:05 <napping> You might not call it speculation, but you'd start units working on stuff from the statically predicted branch
16:59:16 <Eduard_Munteanu> napping: yeah, that's what I mean.
16:59:33 <Eduard_Munteanu> It's explicit in the instruction.
17:00:07 <napping> sounds very much like a design for domains where out of order execution isn't a big win - and I'm not sure those can tolerate the code size
17:00:13 <Eduard_Munteanu> OTOH, I think larger instruction sizes can be compensated by the ability to put more cache on-die.
17:00:38 <napping> it would be interesting to see what combinations are actually used, though
17:00:56 <napping> perhaps you could recompress to something very unlike a standard instruction set
17:01:18 <Eduard_Munteanu> napping: sure, but then you'd miss on the advantages while being subjected to its disadvantages.
17:01:52 <napping> no, I'm thinking of running a nice big corpus through their compiler, and seeing how often stuff is actually used
17:02:01 <Eduard_Munteanu> Ah.
17:03:23 * geheimdienst uses a vm to watch programs run, counting how often instructions are used, then makes lolcats about it
17:03:38 <napping> pics or it didn't happen
17:03:43 <Eduard_Munteanu> :)
17:04:09 <mun_> hi
17:04:23 <Eduard_Munteanu> mun_: hi
17:04:24 <mun_> is \lambda x y.y an unary or binary function?
17:04:42 <monochrom> I would call it binary in practice
17:04:56 <gwern> that's what NISC sounds like to me - like exokernels. because they let you roll your own OS/instruction set, in theory they're better than monolithic OS/RISC-CISC
17:05:04 <gwern> I would guess it will be as popular in practice
17:05:25 <napping> I made a little processor in Lava. It's trick was always sending some blocks of bits to the two read ports on the register file - some instructions used the results, some ignored them and supplied other interpretations
17:05:49 <geheimdienst> i mean, i have no clue about these things, but i believe if you are a vm and can actually watch programs run, that could enable cool optimizations in the future (lolcats or no). you don't need to "predict" branches and things, you can actually count. tracing js compilers are maybe a step in that direction
17:05:59 <geheimdienst> </uninformed-rambling>
17:06:18 <mun_> monochrom, but there's no x in the body of the expression.
17:06:27 <monochrom> That does not matter.
17:06:31 <gwern> </foolish objection that betrays the fact that I skimmed everything>
17:06:55 <geheimdienst> what is an exokernel anyway
17:06:59 <Eduard_Munteanu> It's some sort of projection.
17:07:01 <mun_> monochrom, would \lambda x y. c be a binary function?
17:07:06 <monochrom> Yes.
17:07:08 * geheimdienst is reminded of endofunctors and shudders
17:07:24 <Eduard_Munteanu> (x, y) |-> y, mathematically speaking
17:07:52 <proq> </ignorant off-the-cuff addition to uninformed rambling>
17:08:03 <gwern> geheimdienst: an exokernel is like a microkernel
17:08:05 <gwern> but much more so
17:08:15 <Eduard_Munteanu> You can't really rip off part of its domain.
17:08:22 <mun_> Eduard_Munteanu, right. how about \lambda x y. c? (x,y) |-> c?
17:08:32 <sproingie> exokernel is basically a multiplexing HAL
17:08:33 <geheimdienst> ... nanokernel ...
17:08:34 <Eduard_Munteanu> mun_: sure.
17:08:59 <geheimdienst> so it routes messages and does a little hardware abstraction? sounds microkernelish
17:09:01 <Eduard_Munteanu> There are constant functions you know, and they're not considered 0-ary operators.
17:09:07 <Philonous> geheimdienst: Isn't that what the java vm does already and why jit supposedly makes execution sometimes faster than statically compiled code?
17:09:08 <sproingie> it doesn't so much even route messages
17:09:13 <sproingie> it just multiplexes the hardware
17:09:21 <gwern> geheimdienst: well, it's not easy to securely multiplex hard drives
17:09:44 <arw_> Philonous: yes, its called runtime profiling
17:09:50 <mun_> Eduard_Munteanu, if x and y are of type T, what type would c take?
17:10:02 <arw_> Philonous: modern cpus also do some very simple variant of that.
17:10:14 <Eduard_Munteanu> mun_: normal lambda calculus isn't typed.
17:10:19 <gwern> geheimdienst: but exokernels are interesting, you should read the papers
17:10:25 <Eduard_Munteanu> normal == in Haskell
17:10:30 <mun_> right
17:11:21 <geheimdienst> philonous, yes, that's what i mean. now add a few decades of research to today's vm, switch to some better languages maybe, and who knows how cool the future of optimizations at runtime could be
17:11:31 <Eduard_Munteanu> mun_: in practice writing \x y -> c yields something depending on c's type in question.
17:11:43 <Eduard_Munteanu> Which can be explicit or inferred.
17:12:07 <geheimdienst> so it's like a hypervisor that some ibm big irons use to multiplex (= run) multiple real os's onto one hardware
17:12:26 <gwern> one day, we may even catch up with Synthesis
17:12:59 <Philonous> geheimdienst: Btw. exokernel provides security features (like access controll) but leaves abstraction to userland libraries. So you can for example have a database that is optimised for your hardware
17:13:16 <Eduard_Munteanu> geheimdienst: that would be rather difficult and expensive to achieve on reasonable hardware.
17:13:58 <Eduard_Munteanu> unless the underlying stuff is paravirtualized.
17:14:19 <proq> Eduard_Munteanu: isn't that what amazon ec2 does though?
17:14:22 <Eduard_Munteanu> or you don't share it.
17:14:40 <Eduard_Munteanu> proq: I'm not familiar with that, *has a look*
17:15:16 <proq> Eduard_Munteanu: they were using xen last time I checked
17:15:42 <Eduard_Munteanu> Ah, well, that's not what geheimdienst meant.
17:16:08 <Eduard_Munteanu> Or that's not what I'm referring to by "hw multiplexing"
17:16:17 <geheimdienst> Eduard_Munteanu, i don't know if the os's need to be paravirtualized for the ibm thing, however i am sure that they actually do that. it's also called partitioning ... http://en.wikipedia.org/wiki/Hypervisor
17:16:44 <geheimdienst> no, i didn't mean ec2. although that's a damn interesting thing, too
17:17:03 <Eduard_Munteanu> Hm, I misunderstood you. I thought you meant letting the OS access the same piece of hardware as another OS.
17:17:09 <geheimdienst> philonous, how would a database optimized for my hardware look like?
17:17:55 <gwern> geheimdienst: very different paging strategies, for starters
17:17:59 <Eduard_Munteanu> Well, virtualization isn't really "only for big business" anymore.
17:18:03 <Eduard_Munteanu> Look at KVM, Xen etc.
17:18:14 <p_l> geheimdienst: don't mix VM and LPARs
17:18:20 <gwern> geheimdienst: databases and web servers are the exampels used in the exokernels fortheir benchmarks
17:18:29 <Philonous> geheimdienst: I don't know. But having acces to the bare metal of your hard drive agruably gives you more space to optimize for your access patterns than some set-in-stone abstraction provided by your OS?
17:18:29 <gwern> have I suggested you read the exokernel papers?
17:19:03 <Cthulhon|> The thing that I didn't like about the original Exokernel is that the original paper proposed 'downloading' semi-arbitrary code from userland into the kernel for performance (to avoid context switches), using SFI or some unspecified verification technique for security.
17:19:11 <geheimdienst> yes, thank you, i just opened the wikipedia article as a starting point :-)
17:19:28 <p_l> LPAR - hw-level partitioning, IBM VM - and old software hypervisor-like thing (more like a kernel with multiple single-process OSes running on it as processes)
17:19:48 <gwern> Cthulhon|: I thought that was cool - in line with the extensible OSs like SPIn using static checks
17:19:55 <gwern> what was that for, the packet filter?
17:20:18 <geheimdienst> so i guess the database thing is about removing the os's virtual memory layer, which probably isn't doing the optimal thing
17:20:21 <Eduard_Munteanu> Actually the upcoming AMD IOMMUs are going to be very interesting for moving stuff to userspace.
17:20:28 <Cthulhon|> Demuxing TCP and filtering, I think.
17:20:38 <Eduard_Munteanu> and microkernels and all that.
17:20:59 <Eduard_Munteanu> Plus you can export complete physical devices to VMs.
17:21:04 <p_l> geheimdienst: not like they don't dump virtual memory already
17:22:18 <p_l> geheimdienst: btw, have you seen L4? It has hierarchical Address Spaces so you can easily set up one that is managed exactly like you want
17:22:28 * p_l would really like userland swapping
17:22:51 <geheimdienst> i've never heard of L4
17:22:54 * geheimdienst is googling
17:23:17 <Eduard_Munteanu> L4 got away with such stuff because they took a whole lot of time getting message passing fast.
17:23:34 <Eduard_Munteanu> on a single arch and questionable portability.
17:23:47 <p_l> Eduard_Munteanu: And succeeded to show that its viable
17:23:56 <arw_> L4 was intentionally non-portable because they used every arch-specific optimization they could find
17:24:04 <p_l> it's source-level portable for client apps, though
17:24:15 <p_l> *userland apps
17:24:22 <arw_> their theory was that microkernels should be unportable, only the services running ontop of the kernel API should be ported.
17:24:29 <Eduard_Munteanu> Well yes, but I'm not sure it's really viable overall as an OS.
17:24:32 <gwern> what OS is really portable, with no assembler or anything?
17:24:42 <gwern> even netbsd needs OS-specific sections
17:24:43 <proq> gwern: so the exokernel developers first steps were emacs, gcc, then ... *perl*?  O_o
17:24:46 <Eduard_Munteanu> Look at Linux fastpaths and look at L4.
17:25:00 <gwern> the question is, is l4 so unportable that it's unportable?
17:25:05 <sproingie> l4 is about the size of linux's fastpaths
17:25:06 <p_l> Eduard_Munteanu: it is, because the "unportable" part is usually a 4K blob of assembly (in original L4 style)
17:25:25 <gwern> proq: well, most of this research was in the late 90s early 00s. perl was still very big there
17:25:40 <proq> gwern: oh, I see
17:26:05 <p_l> So you can have very small message passing kernel, small set of semi-portable services (which would have portable and unportable parts) and portable code
17:26:07 <gwern> proq: they're not going to port Firefox, I mean
17:26:21 <Eduard_Munteanu> p_l: yes, I don't disagree with that.
17:26:51 <p_l> Eduard_Munteanu: yes, but you made it sound like its a bad strategy :)
17:26:57 <Eduard_Munteanu> However, I'm yet to see how these OSes deal with workloads handled by common OSes.
17:27:11 <Eduard_Munteanu> p_l: well yes, I'm a bit skeptical ^
17:27:12 <gwern> dang academia, not being the real world
17:27:49 <p_l> Eduard_Munteanu: Well, L4 is just for context switching and passing messages around, how you structure the rest is up to you - L4/Linux is quite common platform
17:27:52 <arw_> p_l: in theory its a great strategy. but even for stuff like L4, message passing overhead kills the performance compared to traditional makrokernels.
17:27:55 <gwern> perhaps you coul ask the linux-on-l4 guys
17:28:09 <p_l> arw_: L4/Linux has faster syscalls than native :D
17:28:19 <kmc> is the idea of handling privilege separation statically with proof-carrying code the essential idea of an exokernel?
17:28:20 <p_l> despite twice the number of switches
17:28:22 <Eduard_Munteanu> p_l: yeah, though just putting Linux on L4 isn't useful all by itself :)
17:28:38 <napping> I'm working on a little microkernel with some people, and planning to use shared memory stuff to get speed
17:28:46 <gwern> kmc: I'm not sure the proof-carrying code is all that important
17:28:54 <arw_> p_l: that was a single measurement on a single architecture where the linux guys forgot to optimize iirc.
17:29:03 <p_l> Eduard_Munteanu: the usual use is NICTA-derived OKL4 + Linux (with userland) + real time software runnign straight on L4
17:29:05 <Eduard_Munteanu> It's not only the measured overhead that matters.
17:29:17 <gwern> the overhead is a mere constant factor
17:29:17 <napping> We think you can avoid "syscall" in the sense of flushing your TLB and loading a kernel one for message sends
17:29:39 <Eduard_Munteanu> When you have a fast interrupt source for example, you're going to get into lots of other trouble than the smallish L4 overhead.
17:29:57 <kmc> so what's the essential idea?
17:30:12 <Eduard_Munteanu> kmc: we need better hardware :P
17:30:15 <p_l> Eduard_Munteanu: macrokernels deal with that usually by disabling the interrupt and going for polling, apparently
17:30:18 <napping> Eduard_Munteanu: when you have tha kind of load it's time to switch to polling
17:30:27 <napping> p_l: any decent implementation does that
17:30:37 <p_l> napping: I know :)
17:30:41 <gwern> kmc: handling just resource separation, and doing this even for unobvious resources like hard drives. nothing else
17:30:59 <Eduard_Munteanu> And if you're missing too many interrupts, it won't be a good idea.
17:31:02 <Eduard_Munteanu> E.g. network card.
17:31:26 <sproingie> how's l4 do with multiple cores?
17:31:49 <napping> Eduard_Munteanu: you especially have to switch to polling for network cards.
17:32:01 <gwern> dunno. that's kind of like asking how l4 handles my camera
17:32:06 <arw_> p_l: http://wwwcip.cs.fau.de/~snalwuer/slashdot.png <- i've used that one in some presentation
17:32:15 <napping> napping: no way can you do 10G with an interrupt per packet
17:32:18 <Eduard_Munteanu> Because when you look at Linux's fast paths and you see they're considered crucial even regarding 0.1% overhead, you'll see that L4 tops that a lot.
17:32:23 <sproingie> i don't consider multiple cores to be a peripheral
17:32:44 <Eduard_Munteanu> napping: that's not the issue. You have to empty those buffers, and fast.
17:32:45 <arw_> http://linux.slashdot.org/story/06/05/31/0641207/Virtualized-Linux-Faster-Than-Native?art_pos=1 <- thats the original article
17:32:53 <p_l> Eduard_Munteanu: OpenBSD recommends dumping multiple NICs on a single interrupt, iirc, then you go for polling
17:32:55 <napping> Eduard_Munteanu: exactly, so you can't afford the interrupt load
17:33:28 <p_l> interrupts are for slow devices :)
17:33:29 <gwern> sproingie: if l4 isn't worthwhile on a singlecore, as we're debating here, then multicore is moot
17:33:36 <gwern> so yes, it is a peripheral concern
17:33:46 <Eduard_Munteanu> Doing that in a very small micro/nanokernel is naturally slower.
17:34:13 <napping> gwern: I'm not sure that's true - switching immediately into a kernel to get work done makes sense on a single processor
17:34:21 <Eduard_Munteanu> p_l: I mentioned fast interrupts because that implies huge amounts of data you have to transfer routinely.
17:34:46 <napping> gwern: while sending a message to a service on another core might be reasonable if you actually have multiple cores
17:35:06 <p_l> gwern: not necessarily - the very basis for the old push for microkernels was that they can run various tasks simultaneusly that normally would be locked traditional macrokernels... Linux afaik deals with it by becoming rather similar to Mach 4
17:35:37 <sproingie> looks like there's a flavor that runs on multicore ARM cpus
17:35:59 <p_l> gwern: one of the research OSes built on L4 was a SSI cluster on IA-64, where network-connected machines were accessible like different cores
17:36:15 <napping> that's just silly
17:36:27 <gwern> single cores are going to be important for a long time
17:36:31 <p_l> sproingie: that's what NICTA was working on, it got commercialized later as OKL4 - most smartphones you might encounter nowadays run it :)
17:36:38 <proq> p_l: sounds similar to HURD concepts
17:36:56 <Eduard_Munteanu> arw_: hm, that's interesting.
17:36:58 <sproingie> p_l: ahhhh, ive heard of OKL4
17:37:03 <sproingie> p_l: so hard to keep track of the names
17:37:07 <p_l> proq: Hurd just copy-pasted microkernel propaganda :)
17:37:11 <Eduard_Munteanu> I agree context switches could be better on Linux.
17:37:49 <p_l> Eduard_Munteanu: to get really fast switches one would have to put fire under cpu manufacturers to make more platform support similar TLB to EV6 one :)
17:37:57 <gwern> hurd switched microkernels like microkernels switch processes like your mom switches lovers
17:38:11 <Eduard_Munteanu> p_l: I agree, hardware isn't helping either.
17:38:12 <sproingie> hurd switched microkernels like duke nukem forever switched engines
17:38:51 <p_l> Eduard_Munteanu: EV6 had a TLB that really helped with switches, since instead of flushing TLB on syscall, you changed a byte in a register :)
17:38:57 <proq> gwern: someone here's mom is madonna?
17:39:16 <Eduard_Munteanu> p_l: hm, I'll look that up.
17:39:19 <geheimdienst> hurd switched microkernels sometimes multiple times without a reboot
17:39:28 <arw_> p_l: sensible cpu design is secondary to either cost or compatibility. intel won't change x86 and embedded manufacturers won't do anything complex.
17:39:36 <p_l> (it had indexed TLB, where each entry had 8bit address-space identifier, and a register was available to select which id was current)
17:39:38 <gwern> proq: er, which madonna? there are a lot
17:39:41 <Eduard_Munteanu> I'm not a fan of x86 for many reasons.
17:39:46 <proq> gwern: the singer
17:39:53 <danharaj> No one is a fan of x86
17:39:58 <gwern> I wonder what the Hollywood Madonna looks like underneath her woman-suit
17:39:58 <p_l> arw_: TLB manipulation isn't part of x86 spec - it's model-specific stuff
17:40:07 <gwern> proq: I wouldn't know
17:40:15 <napping> arw_: nobody really cares about the systems programming stuff. look how many syscall interfaces they've gone through
17:40:22 <sproingie> gwern: helen thomas
17:40:25 <Eduard_Munteanu> p_l: ah, so you could keep TLB entries but mark them inactive.
17:40:31 <arw_> napping: on linux. but not on windows.
17:40:33 <sproingie> gwern: have some pleasant dreams tonight
17:40:34 <p_l> arw_: and K8/K10 actually added 1-bit id to TLB entries, to represent which ones belong to hypervisor
17:40:38 <gwern> sproingie: ouch
17:40:49 <napping> arw_: I mean int vs. syscall vs. sysenter
17:41:10 <napping> oh, and the ancient call gate stuff
17:41:13 <Eduard_Munteanu> First generation SVM sucked.
17:41:17 <arw_> p_l: yes. but for some non-braindead tlb on intel one would need to clean up some of the more weird features of its mmu.
17:41:21 <Eduard_Munteanu> Especially due to TLB thrashing.
17:41:28 <p_l> arw_: on windows nobody knows because you don't call syscalls directly but call mapped functions that actually do the calls
17:41:37 <napping> same on linux
17:41:44 <Eduard_Munteanu> Intel continued to suck.
17:41:58 <arw_> napping: the point is, each and every one of those ancient methods still has to work...
17:42:13 <gwern> isn't that what the interrupt vector table is for?
17:42:23 <sproingie> they tried to go legacy-free with ia64
17:42:23 <arw_> gwern: on some architectures, yes
17:42:35 <Eduard_Munteanu> sproingie: that should be applauded
17:43:00 <napping> arw_: and my point is intel doesn't really seem to avoid inventing that kind of stuff, and operating systems can get away with not supporting t
17:43:03 <sproingie> unfortunately the world is still not ready for EPIC
17:43:11 <p_l> sproingie: HAHAHAHAHA
17:43:15 <napping> cause no user programs screw around with the TLB directly or anything
17:43:17 <Eduard_Munteanu> E-PIC :))
17:43:27 <arw_> napping: yes. because intel does not dare to remove the old stuff.
17:43:35 <sproingie> EPIC fail :p
17:43:42 <arw_> napping: right
17:43:48 <p_l> EPIC itself isn't bad, many architectures use it either directly or internally, it was the lack of branch prediction that was worse, IMHO :)
17:44:07 <arw_> and the lack of decent compilers.
17:44:36 <p_l> arw_: because due to lack of branch prediction compilers have to be semi-sentient and play prophet ;-)
17:45:55 <gwern> p_l: is it any better for the processors to play prophet?
17:46:20 <Philippa> gwern: yes, they've got access to the program's running history
17:46:26 <sproingie> my intuition is that this would be something a JIT would be good at
17:46:28 <p_l> gwern: the difference is that compiler does pure guesswork, cpu might actually get some extra data relevant to execution time
17:46:30 <gwern> Philippa: so that's what JITs are for
17:46:31 <arw_> gwern: yes. because the compiler won't know which processor the code would be running on.
17:46:34 <sproingie> of course my intuition is often wrong
17:46:37 <Philippa> gwern: no, it's not
17:46:44 <Philippa> at least, not the same way
17:46:57 * Eduard_Munteanu cringes anytime people attribute such things to JIT compilers
17:47:12 <p_l> JIT not, but runtime recompilation based on profiling data (to change branch prediction flags, duh!) would help
17:47:24 <sproingie> or profile guided optimization in general
17:47:32 <Philippa> profile guided is good, yeah
17:47:35 <geheimdienst> now, suppose you have the compiler running at runtime, making it a jit ...
17:47:43 <Eduard_Munteanu> Which all existed before JIT most likely :)
17:48:30 <Philippa> Eduard_Munteanu: and that's a problem with people saying JIT can do it too how?
17:48:44 * p_l points to Lisps that often are incremental compilers
17:48:45 <Philippa> hell, I'd /love/ to have JIT inlining in GHC
17:49:12 <arw_> all the magical "JITs are fast" propaganda rumours are mostly from Sun marketing guys telling you that java isn't slow.
17:49:17 <Philippa> even if I have to use pragmas to tell it where to profile
17:49:26 <Eduard_Munteanu> Philippa: that's not a problem, however I used to hear some people saying that's something JIT-specific.
17:49:35 <arw_> what they don't tell you is, its only fast if the program was already running for some time.
17:49:42 * geheimdienst thinks jit compilation is a special case of meta-programming
17:49:49 <gwern> arw_: from my pouint of view, JIT is just a general name for runtime optimizing, which subsumes things like branch prediction
17:49:59 <geheimdienst> ... or a special case of staged compilation
17:50:09 <gwern> @wn shylock
17:50:10 <lambdabot> *** "shylock" wn "WordNet (r) 2.0"
17:50:10 <lambdabot> shylock
17:50:10 <lambdabot>      n 1: someone who lends money at excessive rates of interest [syn:
17:50:10 <lambdabot>            {usurer}, {loan shark}, {moneylender}]
17:50:10 <lambdabot>      2: a merciless usurer in a play by Shakespeare
17:50:19 * Eduard_Munteanu likes to think of JIT compilers as nicely integrated profiling and progressively aggressive recompilation
17:50:22 <geheimdienst> gwern, right on
17:51:11 <Eduard_Munteanu> Other than that, claiming JIT is somehow better than AOT is a bunch of crap.
17:51:20 <Eduard_Munteanu> s/better/faster/
17:52:09 <Eduard_Munteanu> Because they're basically the same thing.
17:52:40 <geheimdienst> well not entirely the same. at runtime, you know more than at compile time
17:53:07 <Eduard_Munteanu> geheimdienst: profiling has been in use since AOT days.
17:53:17 <Eduard_Munteanu> It's just that it wasn't automated.
17:53:26 <Eduard_Munteanu> s/profiling/profiling-based optimisation
17:54:29 <Eduard_Munteanu> Don't get me wrong, I'd love it to have GCC do some of those neat things.
17:54:50 <geheimdienst> yes, but that's the point. shipping a runtime environment that includes a jit compiler is not a big issue. shipping a binary with some kind of profiling mechanism, and aot compiler and your sources is often impractical
17:54:58 <sproingie> gcc does have pgo
17:55:15 * Eduard_Munteanu switches to bashing proprietary software then :)
17:55:29 <arw_> geheimdienst: you don't ship a binary with profiling enabled. you profile and optimize before shipping
17:55:46 <Eduard_Munteanu> sproingie: profiling-based optimisation? Yes. But not really comfy to use.
17:55:50 <proq> geheimdienst: it works for the SBCL folks
17:55:54 <geheimdienst> okay, but that's the difference with jit then ... right?
17:55:57 <sproingie> Eduard_Munteanu: i dont think it ever is
17:56:18 <sproingie> it doesnt seem that hard tho.  -fprofile-generate and -fprofile-use
17:56:25 <geheimdienst> (that was to arw_)
17:56:37 <kmc> err many uses of JIT are much more sophisticated than this two-step process
17:56:38 <Eduard_Munteanu> sproingie: I meant integrated at runtime.
17:56:44 <kmc> tracing JIT for example
17:56:50 <p_l> proq: well, SBCL is kind of special case... there's some work necessary to make it run *without* compiler
17:56:58 <kmc> and yes tracing JIT can be useful even for languages which can be compiled AOT
17:57:37 <Eduard_Munteanu> sproingie: because generally, recompiling will be a huge waste of time in itself.
17:57:43 <kmc> you can do tracing JIT on bare machine code even
17:57:48 <arw_> geheimdienst: in a way, yes. one big problem with JIT in this scenario is the overhead that runtime-profiling and compilation generates.
17:57:50 <kmc> runtime constant folding and inlining
17:57:57 <Eduard_Munteanu> Unless they find a way to get that working in an economical fashion, it's not really nice.
17:58:09 <kmc> specialize your printf call at runtime based on the probably unchanging read-only format string
17:58:21 <Eduard_Munteanu> arw_: right.
17:58:26 <arw_> geheimdienst: its a tradeoff, if you have long-running programs that are rarely called and are fed very different kinds of input, JIT has its advantages.
17:58:49 <Eduard_Munteanu> Plus profiling introduces a tad bit of uncertainty wrt what happens when you remove it.
17:59:03 <sproingie> heisenbugs?
17:59:16 <Eduard_Munteanu> Heisenperformancebugs :)
17:59:23 <arw_> yes. and heisen-performance-problems...
17:59:28 <arw_> and heisen-timing...
17:59:32 <gwern> the synthesis kernel found that many jits of arbitrary code to be worthwhile
17:59:39 <proq> arw_: yes.  the achilles' heel of that technique would be needing to start up lots of short-running programs
17:59:54 <Eduard_Munteanu> Profiling really needs brains.
18:00:08 <Eduard_Munteanu> Doing good optimisation is not really a decidable problem.
18:00:39 <arw_> Eduard_Munteanu: but usually its not worth a humans valuable time.
18:00:40 <sproingie> i suspect we mostly just needed a decent compiler for ia64
18:00:48 <sproingie> handwavery about JIT and PGO aside
18:01:01 <Eduard_Munteanu> arw_: yes, there are benefits in gathering data and performing automated optimization.
18:01:21 <geheimdienst> i guess we could say that compilation is a process starting at compile-time and going all the way through run-time. today more so than 10 years ago, and 10 years in the future more than today
18:01:40 <Eduard_Munteanu> Um, we rather needed it to be cost effective for multiple markets.
18:02:24 <Eduard_Munteanu> That's why we're stuck with x86.
18:02:31 <geheimdienst> sproingie, a guy who knows a great deal about processors essentially said the same thing to me. ia64 was killed mostly by smart compilers that never materialized
18:03:08 <sproingie> it also doesn't help to release a product that needs millions or billions of $$ in research so that it can graduate to ... competing with your own product
18:03:33 <Eduard_Munteanu> I'd go on to say that CPU arches really need to be open, to stay awhile in academia and research and then to be implemented.
18:03:44 <sproingie> sparc is still open isnt it?
18:03:59 <Eduard_Munteanu> Yes. AFAIK, there still is OpenSPARC.
18:04:35 <arw_> and sparc is a nice arch to program for, register window madness aside.
18:04:53 <sproingie> i thought people liked register windows
18:05:21 <Pseudonym> No.
18:05:32 <kmc> UltraSPARC T2 is GPL'd
18:05:36 <Pseudonym> Think of a context switch.
18:05:54 <Eduard_Munteanu> Now SPARC ain't cost effective either.
18:05:54 <kmc> and is a damn cool processor
18:05:57 <Pseudonym> Register windows sound kinda nice right up to the point where you need to do a context switch.
18:06:06 <geheimdienst> Eduard_Munteanu, i think academia could help with purity of the design, but certainly not with market adoption. all the marketing power of intel couldn't replace x86 with ia64. i think if ia64 had come out of academia, that wouldn't have helped
18:06:35 <kmc> MIPS and SPARC both came out of academia and they had good market share for a long while
18:06:44 <sproingie> i've never programmed asm for sparc, so i only know what i've read about register windows
18:06:50 <Eduard_Munteanu> geheimdienst: well, you're probably right too. Cost-effectiveness is still goverened at least partly by economies of scale.
18:06:54 <Pseudonym> Much like how modern Intel chips are RISC machines which interpret a CISC instruction set, modern Sparcs don't really have register windows as you might expect.  They just expose that virtual machine to the assembler programmer.
18:08:02 <geheimdienst> pseudonym, exactly. we haven't talked about that all night. the step to translate instructions to micro-ops means cpus essentially have a little compiler built in
18:08:06 <geheimdienst> i think.
18:08:11 <Eduard_Munteanu> I think that if Intel/AMD CPUs were not widely adopted, they'd most certainly be a lot more expensive.
18:08:17 <Pseudonym> Interpreter, really.
18:08:35 <Eduard_Munteanu> geheimdienst: well, that's rather trivial.
18:08:40 <arw_> no, its a compiler. it compiles from cisc to micro-ops.
18:08:41 <Eduard_Munteanu> It's a lookup table.
18:08:41 <geheimdienst> yes, what's the difference really ... :-)
18:09:08 <geheimdienst> confucius said an interpreter is a compiler that happens at runtime
18:09:08 <arw_> Eduard_Munteanu: thats an implementation detail and not totally true.
18:09:14 <Pseudonym> arw_: Well, it's a bit of both in reality.
18:09:24 <Pseudonym> The trace cache is effectively a storage unit for compiled code.
18:09:27 <arw_> geheimdienst: some interpreters are compilers.
18:09:28 <Eduard_Munteanu> arw_: yeah.
18:09:38 <Pseudonym> But there's also the microcode for some of the CISC ops.
18:10:03 <Eduard_Munteanu> Something is a compiler when it delegates execution of code to another processing unit.
18:10:08 <kmc> confucius = futamura?
18:10:48 <Pseudonym> So interpreters can contain compilers as an implementation detail.
18:10:49 <Eduard_Munteanu> delegates = generates and delegates.
18:10:55 <geheimdienst> futamura sounds like something that came out of the depths of 4chan's hentai boards. i'm sure i don't want to google for futamura.
18:11:16 <Eduard_Munteanu> Futamura sounds indecent here :)
18:11:17 <Pseudonym> Eduard_Munteanu: The least fixpoint of that equation is delegates = generates and (generates and (generates and (...)))
18:11:35 <Eduard_Munteanu> Pseudonym: bottom :P
18:11:37 <Pseudonym> Turtles all the way down.
18:11:45 <geheimdienst> bottoms all the way down
18:11:49 <geheimdienst> i've said it before
18:11:51 <Eduard_Munteanu> Bottoms up :)
18:12:18 <danharaj> it's categories all the way down
18:12:19 <kmc> geheimdienst, http://blog.sigfpe.com/2009/05/three-projections-of-doctor-futamura.html
18:12:43 <kmc> and http://www.cubiclemuses.com/cm/blog/archives/000419.html/
18:12:58 <geheimdienst> kmc, http://images.google.com/images?um=1&hl=de&client=opera&rls=da&q=futanari
18:13:06 <gwern> @hoogle good.news
18:13:06 <gwern> @quote good.news
18:13:07 <lambdabot> No results found
18:13:07 <lambdabot> gwern says: good news everyone! we heard you like interpreters so we used the 3rd futamura projection to interpret your compiler so you can compile while you interpret!
18:13:15 <kmc> thanks for that geheimdienst 
18:13:34 <Eduard_Munteanu> Now that sounds like Futurama.
18:13:44 <geheimdienst> thanks for the links, i'm looking at it now
18:14:03 <kmc> geheimdienst, you set my google to german :O
18:14:20 <geheimdienst> sorry dude :)
18:14:33 <arw_> google went bad when it tried to be too smart...
18:14:40 <gwern> Eduard_Munteanu: yes, futamura/futurama is part of the joke. they're anagrams
18:14:49 <Eduard_Munteanu> Aaah :)
18:15:24 * Eduard_Munteanu remembers to go look for new episodes :D
18:15:35 <Eduard_Munteanu> Are they out yet?
18:15:42 * geheimdienst thinks a compiler is something that does computation and defers other computation to the future
18:17:19 <kmc> imo an important property of a compiler is that it halts even when compiling programs which don't
18:17:35 <kmc> which fundamentally limits the analysis you can do
18:17:38 <geheimdienst> omg compilers solved the halting problem
18:18:00 <kmc> yup
18:18:20 <danharaj> some languages have undecidable compilation
18:18:46 <arw_> .oO( c++ )
18:19:04 <danharaj> hell Haskell with undecidable instances :p
18:19:35 <geheimdienst> i thought c++ sends programs to the future to have them compiled by skynet. i mean, sure that's undecidable
18:19:58 <kmc> yeah danharaj
18:20:10 <kmc> that's a separate issue though
18:22:10 <geheimdienst> compilers don't evaluate my program completely. they keep putting off all kinds of things to runtime. compilers are fucking procrastinators.
18:22:35 <Eduard_Munteanu> I've hit that while playing with type-level arithmetic.
18:22:43 <Eduard_Munteanu> Though I'm not sure if it was a bug or not.
18:22:53 <arw_> hm. compilers are procrastinating interpreters. 
18:24:01 <Eduard_Munteanu> The line between compilers and interpreters is kinda thin though.
18:24:52 <Eduard_Munteanu> e.g. consider _emitting_ a jump to compiler/runtime code.
18:25:40 <mpiechotka> Hello. How to rewrite into type famillies class Ord b => MyClass a b | a -> b where ?
18:25:43 <geheimdienst> the buddha said that all computation happens at runtime, it's just that some of it was cached
18:26:36 <Cale> mpiechotka:  class (Foo b) => MyClass a where type Foo ...
18:26:46 <Cale> er
18:26:54 <Cale> mpiechotka:  class (Foo a) => MyClass a where type Foo a = ...
18:26:56 <Cale> sorry
18:27:31 <mpiechotka> Cale: You mean class (Ord (Foo a)) => MyClass a where type Foo a :: * ?
18:27:46 * Eduard_Munteanu thinks whether there are any good Haskell topics for his B/Eng thesis next year...
18:28:36 <Cale> ... right :)
18:28:39 <Eduard_Munteanu> Though the fun stuff is too researchish for B/Eng.
18:29:10 <Cale> mpiechotka: though, you don't need the explicit kind signature if you don't want it
18:29:31 <mpiechotka> Cale: I prefer everything explicit
18:29:39 <mpiechotka> Cale:  It helps tracking type errors
18:29:55 <Eduard_Munteanu> I doubt you'll meet kind errors too commonly.
18:30:27 <Eduard_Munteanu> Especially given the count of different kinds.
18:30:57 <c_wraith> more importantly, type inference can give unexpected results sometimes.  kind inference, that almost never happens
18:31:16 <Eduard_Munteanu> Anyway, it doesn't help in thinking the problem.
18:31:30 <Eduard_Munteanu> I don't think there's an equivalent for "Theorems for free" wrt kinds :)
18:35:22 <sproingie> * for *
18:37:44 <aavogt> > $(stringE "123")
18:37:45 <lambdabot>   <no location info>: parse error on input `$'
18:37:53 <aavogt> Cale: done thinking about TH?
18:43:29 <Pseudonym> Is there a standard typeclass for the Word* types which returns the number of bits in the word?
18:44:01 <aavogt> @hoogle log
18:44:02 <lambdabot> Prelude log :: Floating a => a -> a
18:44:02 <lambdabot> Prelude logBase :: Floating a => a -> a -> a
18:44:02 <lambdabot> Network.CGI logCGI :: MonadIO m => String -> m ()
18:44:20 <Pseudonym> What I want is this, more or less:
18:44:22 <pastorn> Pseudonym: look in Data.Bits
18:44:22 <aavogt> and those word types are all integral?
18:44:26 <Pseudonym> I did.
18:44:33 <Pseudonym> Yes, all integral.
18:44:34 <aavogt> @type logBase 2 . fromIntegral
18:44:35 <lambdabot> forall t a. (Floating t, Integral a) => a -> t
18:44:40 <Pseudonym> Data.Bits works on unbounded bit strings, too.
18:44:43 <Pseudonym> class (Integral word) => Word word where
18:44:43 <Pseudonym>     wordBits :: word -> Int
18:44:43 <Pseudonym> instance Word Word8 where
18:44:43 <Pseudonym>     wordBits _ = 8
18:44:50 <Pseudonym> That's What I Want(tm).
18:45:14 <aavogt> @type logBase 2 . fromIntegral . (maxBound `asTypeOf`)
18:45:15 <lambdabot> forall t a. (Floating t, Integral a, Bounded a) => a -> t
18:45:16 <pastorn> Pseudonym: 8 * sizeOf
18:45:29 <Pseudonym> :t sizeOf
18:45:30 <lambdabot> Not in scope: `sizeOf'
18:45:34 <pastorn> @hoogle sizeO
18:45:34 <lambdabot> Foreign.Storable sizeOf :: Storable a => a -> Int
18:45:34 <lambdabot> Network.Socket.Internal sizeOfSockAddr :: SockAddr -> Int
18:45:34 <lambdabot> Network.Socket.Internal sizeOfSockAddrByFamily :: Family -> Int
18:45:38 <Pseudonym> Oush.
18:45:39 <pastorn> @hoogle size_of
18:45:39 <lambdabot> No results found
18:45:40 <Pseudonym> Ouch, too.
18:45:41 <aavogt> @let bitsOf = round . logBase 2 . fromIntegral . (maxBound `asTypeOf`)
18:45:43 <lambdabot>  Defined.
18:45:43 <pastorn> @hoogle sizeOf
18:45:43 <lambdabot> Foreign.Storable sizeOf :: Storable a => a -> Int
18:45:43 <lambdabot> Network.Socket.Internal sizeOfSockAddr :: SockAddr -> Int
18:45:43 <lambdabot> Network.Socket.Internal sizeOfSockAddrByFamily :: Family -> Int
18:45:52 <pastorn> Pseudonym: it's the first
18:45:52 <aavogt> > bitsOf (undefined :: Word8)
18:45:53 <lambdabot>   8
18:45:56 <aavogt> > bitsOf (undefined :: Word16)
18:45:57 <lambdabot>   16
18:46:01 <aavogt> > bitsOf (undefined :: Word64)
18:46:02 <lambdabot>   64
18:46:07 <Pseudonym> @hoogle btisOf
18:46:07 <lambdabot> No results found
18:46:10 <Pseudonym> @hoogle bitsOf
18:46:10 <lambdabot> No results found
18:46:18 <aavogt> Pseudonym: I just defined it :)
18:46:21 <Pseudonym> I don't like bitsOf.
18:46:29 <aavogt> it seems to work though
18:46:45 <aavogt> it's likely to be slow though
18:46:46 <pastorn> bitsOf (1 :: Int64)
18:46:49 <tommd> Thats just sizeOf * 8
18:46:53 <pastorn> > bitsOf (1 :: Int64)
18:46:54 <lambdabot>   63
18:46:54 <Pseudonym> > bitsOf (undefined :: CUShort)
18:46:55 <lambdabot>   Not in scope: type constructor or class `CUShort'
18:46:58 <Pseudonym> > bitsOf (undefined :: IntPtr)
18:46:59 <lambdabot>   Not in scope: type constructor or class `IntPtr'
18:47:03 <pastorn> aavogt: yay!
18:47:18 <geheimdienst> > sizeOf (undefined :: Int64)
18:47:19 <lambdabot>   Not in scope: `sizeOf'
18:47:20 <pastorn> > sizeOf (1 :: Int64)
18:47:21 <lambdabot>   Not in scope: `sizeOf'
18:47:23 <tommd> > 8 * sizeOf (undefined :: Int64)
18:47:24 <lambdabot>   Not in scope: `sizeOf'
18:47:25 <geheimdienst> @hoogle sizeOf
18:47:25 <lambdabot> Foreign.Storable sizeOf :: Storable a => a -> Int
18:47:25 <lambdabot> Network.Socket.Internal sizeOfSockAddr :: SockAddr -> Int
18:47:25 <lambdabot> Network.Socket.Internal sizeOfSockAddrByFamily :: Family -> Int
18:47:34 <tommd> > 8 * Foreign.Storable.sizeOf (undefined :: Int64)
18:47:35 <lambdabot>   Not in scope: `Foreign.Storable.sizeOf'
18:47:47 <Pseudonym> For my purposes, I'll define it myself, but it's probably time to revisit the traits typeclasses.
18:47:52 <aavogt> pastorn: it could consider minbound too...
18:48:15 <tommd> Why avoid sizeOf?  This is a great use.
18:48:16 <geheimdienst> > minBound :: Int
18:48:17 <lambdabot>   -9223372036854775808
18:48:35 <aavogt> I avoid sizeOf because I don't know about it
18:48:45 <pastorn> aavogt: hehe :)
18:48:50 <Pseudonym> sizeOf returns the physical size, not the logical size.
18:49:00 <geheimdienst> lambdabot doesn't know about sizeOf
18:49:10 <Pseudonym> A Word128 built out of two Word64s might take more than two words to externalise.
18:49:11 <tommd> Pseudonym: yes, but for the data discussed they are the same.
18:49:42 <Pseudonym> tommd: Remind me never to hire you on the next Ariane project.
18:49:43 <Eduard_Munteanu> Physical as in the underlying boxed value?
18:49:57 <pastorn> can modern x86 hardware operate on 128 bit integrals?
18:50:17 <pastorn> (without hackery)
18:50:19 <Pseudonym> pastorn: Sure.  I have a modern x86, and I even have a working Integer!
18:50:20 <Eduard_Munteanu> pastorn: I think so.
18:50:21 <tommd> Pseudonym: Lol, it all depends what you are doing and IRC is a poor place for discussions relating to specification.
18:50:36 <Eduard_Munteanu> pastorn: lemme check a bit.
18:50:36 <Pseudonym> Actually, #haskell is an excellent place for such discussions.
18:50:42 <pastorn> Pseudonym: so there are ASM instructions for that?
18:50:46 <geheimdienst> > let bitsOf x = round . logBase 2 . fromIntegral . ((maxBound `asTypeOf` x) - (minBound `asTypeOf` x)) in bitsOf (undefined :: Word64)
18:50:46 <tommd> pastorn: If you mean in a single instruction I'd look at MMX
18:50:46 <lambdabot>   Couldn't match expected type `f a'
18:50:47 <lambdabot>         against inferred type `GHC.Word....
18:51:02 <geheimdienst> > let bitsOf x = round $ logBase 2 $ fromIntegral $ ((maxBound `asTypeOf` x) - (minBound `asTypeOf` x)) in bitsOf (undefined :: Word64)
18:51:02 <Eduard_Munteanu> Wait no need to check.
18:51:03 <lambdabot>   64
18:51:09 <pastorn> geheimdienst: that's just nasty :/
18:51:10 <Pseudonym> pastorn: Let me put it this way.  On a 32-bit x86, you have uint64_t available in a typical C compiler.
18:51:14 <Eduard_Munteanu> pastorn: you know CMPXCHG8B?
18:51:29 <pastorn> Eduard_Munteanu: haha... no clue :D
18:51:30 <Draconx|Laptop> tommd, mmx does 64-bit operations.
18:51:33 <Eduard_Munteanu> That's one of them. Then there's the 128-bit media instructins.
18:51:36 <Pseudonym> It might be more than one assembler instruction, but yes.
18:51:42 * geheimdienst succeeds with his proven newbie technique of randomly replacing .'s with $'s
18:51:45 <Eduard_Munteanu> Those I have to check to be sure.
18:51:47 <tommd> I ment SSE, but not sure the size there either tbh.
18:51:52 <Pseudonym> And yes, the SIMD instructions occurred to me too.
18:51:56 <pastorn> Eduard_Munteanu: media instructions? sounds float-y
18:52:00 <aavogt> @let bitsOf' x = let n = round . logBase 2 . fromIntegral $ maxBound `asTypeOf` x in if minBound < (0 `asTypeOf` x) then n+1 else n
18:52:01 <geheimdienst> > bitsOf (undefined :: Word64)
18:52:02 <lambdabot>  Defined.
18:52:03 <lambdabot>   64
18:52:15 <geheimdienst> > bitsOf (undefined :: Int64)
18:52:16 <aavogt> > bitsOf (1::Double)
18:52:16 <lambdabot>   63
18:52:16 <Eduard_Munteanu> pastorn: not really, MMX is integer.
18:52:17 <lambdabot>   No instances for (GHC.Enum.Bounded GHC.Types.Double,
18:52:17 <lambdabot>                    GHC...
18:52:22 <aavogt> > bitsOf (1::Int)
18:52:23 <lambdabot>   63
18:52:26 <Pseudonym> But this is beside the point.  For bit hackery, it seems wrong to use floating point log, even if the compiler does optimise it.
18:52:29 <aavogt> > bitsOf' (1::Int)
18:52:30 <lambdabot>   64
18:52:36 <geheimdienst> > let bitsOf x = round $ logBase 2 $ fromIntegral $ ((maxBound `asTypeOf` x) - (minBound `asTypeOf` x)) in bitsOf (undefined :: Int64)
18:52:37 <lambdabot>   269653970229347386159395778618353710042696546841345985910145121736599013708...
18:52:43 <geheimdienst> uh, sure
18:52:49 <aavogt> haha
18:52:59 <geheimdienst> an int64 seems to need a great deal of memory
18:52:59 <pastorn> Eduard_Munteanu: i've only workid with graphics in GL etc. where everything is floats
18:53:07 <aavogt> > bitsOf' (1::Int64)
18:53:08 <lambdabot>   64
18:53:16 <pastorn> (so i just assumed...)
18:53:17 <geheimdienst> > minBound :: Int64
18:53:18 <aavogt> geheimdienst: you're overflowing!
18:53:18 <lambdabot>   -9223372036854775808
18:53:23 <geheimdienst> > minBound :: Word64
18:53:24 <lambdabot>   0
18:53:33 <tommd> Anything that uses floating point seems rather hackjob ish.
18:53:36 <aavogt> > maxBound - minBound :: Int64
18:53:37 <lambdabot>   -1
18:53:47 <aavogt> hmm, or not
18:53:57 <pastorn> tommd: IEEE :)
18:54:07 <Pseudonym> > fromIntegral (maxBound :: Int64) - fromIntegral (minBound :: Int64) :: Integer
18:54:08 <lambdabot>   18446744073709551615
18:54:29 <geheimdienst> > logBase 2 18446744073709551615
18:54:29 <lambdabot>   64.0
18:54:49 <Eduard_Munteanu> pastorn: well, what do you need it for?
18:55:14 <Pseudonym> tommd: I've used floating point in integer programs before.
18:55:27 <Pseudonym> Did you know that you can store a 32-bit integer in an IEEE Double losslessly?
18:55:31 <Eduard_Munteanu> I mentioned the CMPXCHG stuff because you need it to do 128-bit atomic ops. 
18:55:33 <pastorn> Eduard_Munteanu: what do i need what for?
18:55:36 <tommd> As have I.  Not being alone in that doesn't make me feel better. 
18:55:36 <geheimdienst> so let me get this straight. bitsOf looks only at maxBound, which for Int64 should be half of what it is for Word64. why does bitsOf say 64 for both Int64 and Word64
18:55:57 <geheimdienst> does bitsOf work only by accident?
18:55:58 <aavogt> geheimdienst: uh, look at the definitions
18:56:18 <aavogt> > (bitsOf (1::Int64), bitsOf' (1::Int64))
18:56:19 <lambdabot>   (63,64)
18:56:20 <Eduard_Munteanu> pastorn: yeah. You're sure you can't do it using two 64-bit operations? Like addition is trivial using carry.
18:56:29 <geheimdienst> oic, thanks
18:56:41 <aavogt> I assume you have one sign bit
18:56:44 <aavogt> if 
18:56:49 <pastorn> Eduard_Munteanu: i was just curious as to how big numbers modern can handle :)
18:56:49 <aavogt> minbound is negative
18:57:23 * geheimdienst stores the sign as an ascii char. the sign takes 7 bits in the geheimdienst86 architecture
18:57:32 <pastorn> Eduard_Munteanu: sure, there's always BigNum implementations, but i was just curios as what the biggest number single op arithmetics were defined for :)
18:57:35 <Eduard_Munteanu> pastorn: long long on x86-64 is still 64-bit so I guess, there isn't a general purpose solution to it.
18:58:01 <aavogt> > cycle "long "
18:58:02 <lambdabot>   "long long long long long long long long long long long long long long long...
18:58:12 <Eduard_Munteanu> pastorn: there are a few _conversions_ you can do from integers to 128-bit SSE registers.
18:58:18 <pastorn> > cycle "OM! N"
18:58:18 <lambdabot>   "OM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! NOM! ...
18:58:21 <Eduard_Munteanu> (though there can be rounding errors)
18:58:29 <geheimdienst> > (take 3 $ cycle "long ") ++ "cat"
18:58:30 <lambdabot>   "loncat"
18:58:31 <aavogt> Eduard_Munteanu: are there short longs and long shorts and long long shorts and ...
18:58:33 <pastorn> Eduard_Munteanu: hehe
18:58:45 <geheimdienst> > concat (take 3 $ iterate "long ") ++ "cat"
18:58:45 <lambdabot>   Couldn't match expected type `a -> a'
18:58:46 <lambdabot>         against inferred type `[GHC.T...
18:58:47 <tommd> pastorn: If you are willing to stray from x86, I'm fairly sure Cell has 128 bit instructions on the SPEs.
18:58:59 <geheimdienst> lambdabot, you're bitchy today
18:59:09 <pastorn> tommd: but GHC isn't ported :(
18:59:10 <Eduard_Munteanu> Well, I agree, that is some C/C++ mishap.
18:59:22 <tommd> pastorn: Sounds like a summer project!
18:59:33 <tommd> ... otoh, that architecture seems to be dying.
18:59:33 <pastorn> tommd: i heard about Cell getting scrapped...
18:59:33 <aavogt> > concat (replicate 3 "long ") ++ "cat"
18:59:34 <lambdabot>   "long long long cat"
18:59:43 <tommd> pastorn: I heard the same thing
18:59:47 <pastorn> :(
19:00:01 <pastorn> it seemed like a pretty awesome processor
19:00:04 <Eduard_Munteanu> > fix ("cat" ++)
19:00:05 <lambdabot>   "catcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatca...
19:00:24 <pastorn> i'm moving to ARM for my main platform as soon as there is sufficient hardware for it...
19:00:24 <tommd> pastorn: LLVM can do cell...
19:00:30 <pastorn> tommd: hehe
19:00:37 <dancor> > cycle "cat"
19:00:38 <lambdabot>   "catcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatcatca...
19:00:44 <tommd> pastorn: I had the same thought - that's why I have an ARM netbook now.
19:01:00 <tommd> Wanted something more full featured than a beagleboard to play with.
19:01:00 <pastorn> tommd: cool! linky?
19:01:02 <Eduard_Munteanu> pastorn: well, you have bigger floats.
19:01:20 <pastorn> Eduard_Munteanu: yes, my floats are always bigger
19:01:44 <geheimdienst> > length ("concat (replicate 3 \"long \") ++ \"cat\"") - length (concat (replicate 3 "long ") ++ "cat")
19:01:45 <lambdabot>   19
19:02:05 <geheimdienst> so the programmatic version is 19 chars longer than just hardcoding it
19:02:13 <pastorn> >  ("concat (replicate 3 \"long \") ++ \"cat\"") - length (concat (replicate 3 "long ") ++ "cat")
19:02:13 <tommd> pastorn: Take note I don't suggest you get one right now - its open and does what I want (has screen, is ARM, runs Linux, has keyboard).  The bad part is the case is cheap, screen is cheap, and nothing is upstreamed yet (ex: Kernel support).
19:02:13 <tommd> http://www.alwaysinnovating.com/touchbook/
19:02:14 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
19:02:14 <lambdabot>         against inferred ty...
19:02:33 <Eduard_Munteanu> pastorn: :))
19:02:58 <pastorn> tommd: i think i'll wait for one with trackpoint
19:03:00 <geheimdienst> > fromIntegral $ length ("concat (replicate 3 \"long \") ++ \"cat\"") / fromIntegrl $ length (concat (replicate 3 "long ") ++ "cat")
19:03:01 <lambdabot>   Not in scope: `fromIntegrl'
19:03:05 * pastorn can't do without
19:03:08 <geheimdienst> > fromIntegral $ length ("concat (replicate 3 \"long \") ++ \"cat\"") / fromIntegral $ length (concat (replicate 3 "long ") ++ "cat")
19:03:09 <lambdabot>   Couldn't match expected type `GHC.Types.Int'
19:03:09 <lambdabot>         against inferred type ...
19:03:15 <geheimdienst> i hate you
19:03:38 <pastorn> tommd: 1024x600 :(
19:03:39 <tommd> pastorn: Does anyone besides Lenovo build those in anymore?
19:03:41 <geheimdienst> > (length ("concat (replicate 3 \"long \") ++ \"cat\""), length (concat (replicate 3 "long ") ++ "cat"))
19:03:42 <pastorn> i need way more than that
19:03:43 <lambdabot>   (37,18)
19:03:53 <tommd> pastorn: Not a problem for me - xmonad + xterm + vim cope fine ;-)
19:03:55 <pastorn> tommd: some dells and some HPs has them
19:04:27 <pastorn> heh, i like my pwetty fonts with anti-aliasing
19:04:34 <Eduard_Munteanu> Aye... add some Mutt in there though.
19:04:40 <pastorn> tommd: but the GHC ARM port works fine+
19:04:42 <pastorn> ?
19:04:52 <tommd> In Ubuntu? Yes, fine.
19:04:56 <pastorn> or is there even one?
19:05:00 <tommd> Yep
19:05:05 <pastorn> cool
19:05:30 <tommd> Debian ported GHC and ubuntu ports pulled that in.  GHC HQ doesn't support ARM if that's what you wanted to know.
19:05:53 <pastorn> tommd: ah, ok...
19:06:37 <pastorn> tommd: http://lenovoblogs.com/designmatters/?p=3204
19:06:54 <pastorn> no trackpoint, though :(
19:14:13 <Philippa> it'd be nice if someone got ghci working on ARM though
19:17:50 <pastorn> wait...
19:17:55 <napping> pastorn: did you want 128 bit operations?
19:17:59 <pastorn> only ghc, not ghci?
19:18:07 <pastorn> napping: well, i'm just curious
19:18:24 <napping> dunno what GHC uses, but SSE certainly gives you bitwise operations
19:18:28 <pastorn> napping: i'm guessing there are already ops for floats, i was curious about integral ops
19:18:57 <napping> SSE has plenty of permutation, bitwise, and packed integer stuff
19:20:21 <pastorn> napping: i was more thinking about basic arithmetic support, addition, subtraction and multipliction
19:21:13 <napping> I don't think it does many full width things, but plain only addc is already plenty to synthesize a 64-bit add
19:23:29 <napping> and either imul or some sse thing will let you get a 128-bit product from two 64-bit numbers
19:24:39 <pastorn> ah, ok
19:24:57 <pastorn> napping: thanks for knowing stuff :) i'm off to bed
19:25:18 <interferon> silly question: once i run "make" in ghc, where do the binaries end up?
19:26:18 <c_wraith> you mean ghc --make?  the current directory, if you provide no other options
19:26:20 <napping> if you run ghc --make from the same directory as the target the binary will end up there
19:26:26 <adfasa> divisors n = [ x | x<-[1..(n 'div' 2)], n 'mod' x ==0]; divisors 10
19:26:39 <napping> I don't think I've ever actually called it from a different directory
19:26:41 <interferon> no, sorry.  if i run "make" on the ghc source
19:26:49 <interferon> misleading question
19:26:56 <kmc> find -name \*.o
19:26:57 <napping> hmm, build/stage<N>
19:27:02 <kmc> they go all over, basically
19:27:10 <kmc> your usable binaries are in inplace/bin
19:27:22 <napping> oh, right
19:27:45 <napping> that's the usable ones, yes
19:27:55 <interferon> inplace/bin, thanks
19:28:01 <napping> why not install?
19:28:21 <kmc> it's easier to test this way
19:28:23 <interferon> i want to understand ghc's internals, so i want to be able to build from darcs
19:28:42 <interferon> ghc is a monster
19:28:54 <kmc> @ghc
19:28:54 <lambdabot> ghc says: internal error: Invalid object in processHeapClosureForDead
19:28:58 <kmc> @ghc
19:28:59 <lambdabot> ghc says: Malformed context in instance header
19:29:05 <kmc> @ghc
19:29:06 <lambdabot> ghc says: scavenge: unimplemented/strange closure type
19:29:08 <napping> yeah, that sounds best then. Installing into $HOME works fine once you actually want to keep a version
19:29:26 * kmc is lately doing weird things with/to ghc
19:29:37 <napping> the TH stuff? or other stuff besides?
19:29:42 <interferon> 427k lines of haskell, 117k lines of C
19:29:46 <interferon> :D
19:30:17 <kmc> me?
19:30:20 <napping> yeah
19:30:23 <kmc> i'm working on ghc-android
19:30:34 <napping> taking a proper fixpoint in the quasiquote stuff would be nice
19:30:53 <kmc> i can now compute 6 factorial on android
19:31:15 <interferon> kmc: awesome
19:31:56 <napping> oh, factorial.
19:32:04 <napping> What about a fibbonacci number?
19:32:16 <kmc> who knows
19:34:19 <napping> Well, I just computed fib 6 on a simple processor of my own devising
19:34:34 <napping> it is 8!
19:34:55 <c_wraith> hahaha
19:37:28 <napping> factorial would be easier if it had a multiplier
19:38:17 <kmc> cool
19:39:10 <napping> too bad we don't have a Xilinx board. I wonder if I can get the Lava output to build for Altera
19:40:18 <danharaj> What would you guys suggest as a first tutorial for someone who is new to programming.
19:40:32 <danharaj> A fresh mind ready to indoctrinate into the fold :p
19:40:44 <dons> kmc: via the Arm backend? or ??
19:41:36 <kmc> err, what arm backend?
19:41:39 <kmc> it's unregisterised via-C
19:41:40 <Eduard_Munteanu> What's that Lava thingy? As far as Wikipedia tells, seems to be some sort of LabView-like programming environment.
19:41:47 <kmc> as on ARM Linux, as on iPhone
19:42:01 <kmc> Eduard_Munteanu, there's a Haskell-embedded hardware design language named Lava
19:42:01 <dons> yeah, the unregisterised arm port (e.g. debian's)
19:42:39 <kmc> actually a family of such things, chalmers lava and kansas lava?
19:43:07 <Eduard_Munteanu> kmc: so it's not this one? http://en.wikipedia.org/wiki/Lava_(programming_language)
19:43:23 <kmc> right
19:43:40 <kmc> dons, i'm interested in making registerised via-C and/or LLVM work for ARM Linux and Android both
19:43:45 <adfasa> digits 100 pi
19:43:50 <adfasa> compute
19:43:52 <kmc> but it may wait a bit
19:44:19 <Eduard_Munteanu> kmc: ok, thanks, I'll google Chalmers and Lava.
19:44:28 <kmc> Eduard_Munteanu, http://www.ittc.ku.edu/csdl/fpg/Tools/KansasLava
19:44:35 <kmc> @google haskell lava
19:44:37 <lambdabot> http://raintown.org/lava/
19:44:37 <lambdabot> Title: The Lava Hardware Description Language
19:44:53 <Eduard_Munteanu> Thanks.
19:48:50 <dons> kmc: you should let people know you're working on this via a blog post
19:49:21 <kmc> yeah
19:49:27 <kmc> lazy
19:49:40 <ivanm> what are you working on?
19:49:49 <monochrom> @type foldl'
19:49:49 <kmc> RyanT5000, iPwn Studios blog?
19:49:50 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
19:50:06 <kmc> ivanm, ghc targeting android
19:50:10 <ivanm> ahhh
19:50:11 <ivanm> cool
19:50:32 <napping> Eduard_Munteanu: I've been using york lava, without using layout stuff.
19:51:05 <napping> Eduard_Munteanu: it doesn't actually seem to have the layout stuff
19:56:47 <Eduard_Munteanu> napping: I see.
19:56:55 <Eduard_Munteanu> Well, I have to go, bye everyone.
20:11:52 <sshc> How do I compare two functions to determine whether they're equal (by address)?
20:11:57 * hackagebot bloomfilter 1.2.6.1 - Pure and impure Bloom Filter implementations.  http://hackage.haskell.org/package/bloomfilter-1.2.6.1 (BryanOSullivan)
20:12:32 <BMeph> sshc: First, boot up Visual Studio... ;
20:13:20 <kmc> sshc, you don't, really
20:13:25 <kmc> but http://www.haskell.org/ghc/docs/6.10-latest/html/libraries/base/System-Mem-StableName.html is an approximation
20:13:35 <kmc> or you can do wretched hacks with GHC's internals
20:13:59 <kmc> note that the contractual guarantees on StableNames are quite weak
20:14:18 <kmc> data StableName a = StableName; instance Eq (StableName a) where { _ == _ = False }
20:14:21 <kmc> a conforming implementation ;)
20:15:50 <napping> there are even worse things you can do by unsafeCoercing from carefully constructed types to Ptr
20:16:02 <napping> why do you care if functions share an address?
20:16:16 <sshc> I should probably rewrite this mess instead of hacking it further
20:17:52 <napping> how do you use implication in separation logic?
20:18:01 <sshc> But the concept is still interesting.  Is (a modified) GHC capable of testing whether two functions are defined identically?
20:18:16 <napping> that's a different question entirely
20:18:20 <blackdog> that's not what you asked for
20:18:34 <sshc> blackdog: Of course it's not
20:18:55 <kmc> yes, that's extensional equality vs. intensional equality
20:19:03 <blackdog> you could probably get to an implementation that will never say two things are the same when they're not
20:19:07 <kmc> note that the by-ptr comparison is affected by arbitrary decisions in the optimizer
20:19:12 <napping> intensional is easy enough
20:19:14 <blackdog> like the StableName impl above:)
20:19:32 <gwern> I know, let's compile functions to graphs and then compare the graphs for equality!
20:20:07 <kmc> somewhere on Hackage there's essentially «instance (Bounded a, Enum a, Eq b) => Eq (a -> b)»
20:20:10 <kmc> forgot the package name
20:20:12 <napping> you just have to modify GHC so functions you consider equal retain some certificate you can check
20:20:30 <kmc> you just have to modify GHC so you have dependent types ;)
20:20:55 <napping> perhaps the assembly, if you turn off cross-module inlining or separate compilation
20:21:00 <kmc> sshc, you may be interested in www.ittc.ku.edu/~andygill/papers/reifyGraph.pdf
20:21:10 <gwern> of course, perfect function comparison is turing-complete, I suppose
20:21:11 <monochrom> In Soviet Russia, GHC writes code for you.
20:21:27 <napping> gwern: that's why we introduce intensional equality
20:21:38 <napping> and maybe spice it up a bit with eta-long forms and stuff
20:25:41 <kmc> yeah
20:25:46 <kmc> extensional equality of programs is undecidable
20:25:58 <kmc> this is why equality of real numbers is undecidable
20:26:13 <kmc> and part of why "real number" is such an absurdly inappropriate name
20:26:43 <monochrom> it's pretty real to abstract mathematicians
20:27:01 <danharaj> all mathematicians are concrete
20:27:03 <danharaj> :p
20:27:30 <napping> where do you find an abstract mathematician?
20:27:40 <kmc> floating in the platonic realm
20:29:15 <Cale> kmc: It's not like "natural number" is any better
20:29:26 <monochrom> Oh God XD
20:29:51 <Cale> They're just names for certain abstractions. :P
20:30:26 <kmc> they seem pretty natural to me
20:30:39 <kmc> of course they're names for abstractions
20:30:54 <kmc> but some abstractions are close to modeling things we actually encounter
20:31:10 <Cale> Well, they're certainly not *natural* in the sense of being part of nature
20:31:17 <kmc> and real numbers are not
20:31:25 <Cale> Oh?
20:31:25 <danharaj> hey, natural numbers are everywhere
20:31:36 <Cale> Classical physics would like to disagree with you ;)
20:31:40 <kmc> in that almost every real number contains an infinite amount of information
20:31:43 <monochrom> real numbers are almost everywhere XD
20:31:46 <danharaj> Good thing classical physics is bunk :p
20:31:57 <Cale> It works
20:32:01 <Cale> That's all that matters
20:32:06 <danharaj> to engineers maybe
20:32:15 <Cale> To scientists as well
20:32:33 <danharaj> us mathematicians don't care bout them
20:33:09 <gwern> wait, don't we have complex numbers in quantum stuff, which are as bad as real numbers?
20:33:10 <Cale> Yeah, but mathematicians also shouldn't care about what's fake or not.
20:33:28 <Cale> gwern: There're plenty of real numbers in QM too.
20:33:42 <Cale> Complex numbers are just pairs of reals with an appropriate multiplication and addition anyway
20:33:50 <gwern> Cale: well, then I don't see any reason to feel superior to classical mechanics. aside from our better predictions anyway
20:33:56 <danharaj> Cale: But we always take oppurtunities to troll
20:34:10 <gwern> isaac newton has a posse
20:34:14 <Cale> gwern: I meant to include QM in "classical physics"
20:34:46 <monochrom> "romantic physics" comes after "classical physics"
20:34:48 <kmc> if physicists had any balls whatsoever, they'd work explicitly with computable numbers
20:34:52 <Cale> Non-classical here being the funny discrete toy models.
20:34:54 <kmc> also constructive logic
20:35:05 <kmc> </troll>
20:35:08 <gwern> monochrom: is that based on the power of Love? (and hate)
20:35:12 <Cale> (which haven't yet managed to produce anything remotely as useful)
20:35:25 <ptrf> kmc: what a lovely troll :)
20:35:59 <kmc> thank you ptrf
20:36:12 <danharaj> Hasn't Lattice QCD produced good predictions
20:38:02 <Cale> Doesn't lattice QCD treat itself as a discrete approximation of other continuous models?
20:38:17 <napping> That's just numerical methods
20:38:29 <danharaj> Cale: That's just philosophy :p
20:38:37 <napping> It's hardly an attempt at a lorentz invariant discrete model
20:39:44 <napping> why is bos l33t today?
20:40:13 <Cale> danharaj: I suppose, but see napping's point :)
20:40:24 <Axman6> he's always 1337, he's just modest most of the time too
20:40:34 <kmc> i like that this channel collectively has strong opinions about everything from microprocessor architecture to discrete models of physics
20:41:09 <napping> Axman6: sure, but why less modest today?
20:41:17 <gwern> kmc: what we don't have strong opinions about is purple plaid
20:41:17 * gwern is weakly in favor
20:41:42 <wli> Loop Quantum Gravity?
20:43:00 <kmc> purple plaid makes me almost as angry as real numbers and C++
20:43:43 <napping> wli: does that even work?
20:43:54 <gwern> kmc: aw, you're just saying that
20:43:56 <Cale> http://pix.crash.net/motorsport/360/344395.jpg -- the first google images hit for "Glasgow tartan"
20:44:16 <napping> not purple
20:44:49 <napping> Glasgow Academy Tartan, however: http://en.wikipedia.org/wiki/File:The_Glasgow_Academy_Tartan.jpg
20:46:09 <napping> hmm, but that is not the university
20:47:09 <Cale> http://www.gbutlermovies.com/Tartantrivia/UOGTartan.jpg
20:47:36 <Cale> for some reason, the wikipedia page is being slow to load for me.
20:49:05 <napping> for the 550th anniversary
20:49:54 <kmc> "In general, the small limit that select imposes on the number of concurrently managed resources prevents us from seeing any interesting changes in the behaviour of the original I/O manager at scale, because applications fall over long before any curves have an opportunity to change shape. We find this disappointing, as we were looking forward to a fair fight."
20:51:25 <Cale> hehe
20:52:01 <Cale> Appears to be a quote from http://www.serpentine.com/bos/files/ghc-event-manager.pdf
20:52:05 <kmc> yes
20:52:06 <kmc> § 10.2 "By the way, screw Windows"
20:53:16 <gwern> he doesn't actually say that does he?
20:53:17 <gwern> so far I think my favorite footnote in a serious academic paper goes, 'Such a cheat!'
20:53:37 <kmc> heh
20:53:40 <kmc> where's that from?
20:54:10 <Pseudonym> Seriously, though, this is a serious misdesign in Unix.
20:54:19 <Pseudonym> The lack of a unified event handling mechanism.
20:54:20 * gwern forgets
20:54:34 <kmc> there's more than a couple serious misdesigns in Unix
20:55:11 <Pseudonym> You should be able to wait on a condition variable, a file descriptor, a file lock, a signal _and_ an IPC semaphore all at the same time.
20:55:23 <Pseudonym> OK, maybe not the IPC semaphore.
20:55:31 <Pseudonym> That one is probably best forgotten.
20:56:29 <ivanm> kmc: yeah, but people tend to bitch when you say "whoops, people, we did that wrong; we're now going to re-write the whole thing and you should use the new & improved version!!!"
20:56:46 <kmc> it might have been a bigger problem before
20:56:52 <kmc> now there are only a few Unix platforms anyone cares about
20:57:06 <Pseudonym> Solaris, Linux and BSD.
20:57:07 <kmc> certainly from the GHC perspective
20:57:07 <ivanm> since a lot of those things are probably things that they never thought about when designing Unix
20:57:08 <Pseudonym> Three.
20:57:08 <aavogt> @remember <ivanm> people tend to bitch
20:57:09 <lambdabot> Good to know.
20:57:19 <ivanm> aavogt: talk about a quote taken out of context...
20:57:47 <ivanm> Pseudonym: some people argue that OSX is a Unix
20:57:49 <kmc> Solaris is even marginal for a lot of stuff
20:57:54 <Pseudonym> It is.  It's BSD.
20:57:59 <kmc> it's Tier 2 for GHC
20:58:04 <ivanm> oh? I thought it was its own classification...
20:58:19 <kmc> it's based on a BSD kernel running on top of Mach
20:58:24 <kmc> but of course differs from other BSDs in various ways
20:58:31 <Pseudonym> Yes.
20:58:42 <kmc> hard to draw the lines when you're talking about complex assemblies of hundreds of programs
20:58:52 <kmc> if you want to stretch
20:58:59 <ivanm> then again, technically Linux /= Unix
20:59:03 <ivanm> it's just Unix-like
20:59:12 <kmc> Solaris, Linux, BSD, OS X, Cygwin
20:59:23 <kmc> ivanm, technically Linux is just a kernel ;P
20:59:32 <Pseudonym> Cygwin isn't a Unix.
20:59:34 <ivanm> true
20:59:38 <kmc> I think Unix is now effectively a synonym for Unix-like
20:59:40 <Warrigal> Yeah, I think OS X and Solaris are officially Unix, and Linux, BSD and Cygwin are Unix-like.
20:59:43 <ivanm> Pseudonym: what is it, just a POSIX compat layer for windows?
20:59:47 <kmc> people stopped caring a long time ago where the source is actually from
20:59:49 <ivanm> Warrigal: nah, BSD is Unix
20:59:52 <Pseudonym> ivanm: Kinda.
21:00:02 <Pseudonym> Yeah, BSD really _is_ Unix, unlike GNU.
21:00:10 <Warrigal> "Unix" is a trademark; an operating system is Unix if and only if the Unix guys say so.
21:00:14 <kmc> SCO?
21:00:17 <thoughtpolice> OSX just exposes a BSD API, but a large part of the underlying kernel is mach based, such as the scheduling and virtual memory iirc
21:00:22 <ivanm> IIRC, UNIX is the trademark
21:00:34 <kmc> Cygwin is an implementation of the POSIX APIs on Windows
21:00:35 <Pseudonym> kmc: The Open Group
21:00:39 <thoughtpolice> imo OS X is quite a nice version of unix if there ever was one
21:00:47 <kmc> GNU is an implementation of the POSIX APIs on Linux
21:00:58 <ivanm> you mean GNU coreutils?
21:01:07 <ivanm> since GNU is just an umbrella project...
21:01:11 <kmc> various bits of GNU, yes
21:01:25 <Pseudonym> The Open Group says whether or not it's UNIX, POSIX or CORBA.
21:01:42 <kmc> wouldn't OMG be in charge of CORBA
21:01:43 <aavogt> @forget <ivanm> people tend to bitch
21:01:43 <lambdabot> Done.
21:01:48 <ivanm> heh
21:01:51 <aavogt> ivanm: umbrellas?
21:01:52 <kmc> not kidding, that's the name
21:01:59 <ivanm> kmc: lol
21:02:00 <kmc> omg.org
21:02:01 <aavogt> there's a song for that
21:02:04 <Warrigal> Oh My Group!
21:02:26 <Pseudonym> Interesting.  The only things that are officially UNIX 03 are Mac OS X, Solaris, HP-UX and AIX.
21:02:46 <Pseudonym> You heard that right.  SVR4 is _not_ UNIX.
21:02:51 <Warrigal> Hm?  Wikipedia lists...
21:02:58 <kmc> that website consists almost entirely of bad logos for acronyms
21:03:01 <Pseudonym> http://www.opengroup.org/openbrand/register/
21:03:20 <Pseudonym> Well, it's not UNIX 03.
21:03:23 <Warrigal> AIX, HP/UX, OS X, UnixWare, Solaris, Tru64, z/OS, NCR, and some other thingies.
21:03:49 <Warrigal> So essentially, OS X and Solaris.  :P
21:04:04 <danharaj> I hate the gnu logo
21:04:29 * hackagebot bloomfilter 1.2.6.2 - Pure and impure Bloom Filter implementations.  http://hackage.haskell.org/package/bloomfilter-1.2.6.2 (BryanOSullivan)
21:04:38 <ivanm> Cale: any ideas how to visualise this in 3D? http://en.wikipedia.org/wiki/File:Graph_of_20-fullerene_w-nodes.svg
21:04:51 <ivanm> bos: any chance of you applying that patch to criterion?
21:05:09 * ivanm should probably check to see if that patch needs updating due to cabalised gtk
21:05:21 <bos> ivanm: i think i did
21:05:32 <ivanm> oh? did you make a release then? don't recall seeing one...
21:05:50 <ivanm> nope, no new release
21:05:58 <bos> ivanm: not yet, got a few more changes to go
21:06:02 <ivanm> fair enough
21:06:21 <bos> i'm about 5 months behind on replying to patchjes
21:06:25 <ivanm> heh
21:06:51 <Pseudonym> bos: If it compiles, ship it.
21:08:12 <ivanm> yeah, isn't that the Haskell Way? ;p
21:12:23 * BMeph always thought the Haskell Way was a combo of "Soft Shoulder", "No Turn on Red" and "Approaching Circle"...
21:15:14 <kmc> objects in mirror are closer than they appear
21:16:01 * BMeph plays some Meat Loaf...
21:16:40 <kmc> meat loaf aday keeps the doctor away
21:17:37 * BMeph gives kmc a rimshot of appreciation!
21:17:47 <kmc> thank you
21:33:17 <kmc> "These pages assume a good understanding of Xilinx's Virtex FPGA architecture and of the Haskell lazy functional programming language. The number of people that know about both can easily fit inside a medium sized elevator."
21:33:48 <mpiechotka> @source ap
21:33:49 <lambdabot> ap not available
21:35:45 <Saizan> @src ap
21:35:46 <lambdabot> ap = liftM2 id
21:36:08 <adfasa> > initiate pwnage | haskell.pwnt.channel 
21:36:09 <lambdabot>   <no location info>: parse error on input `|'
21:39:02 <kmc> yr. kung foo no good
21:39:53 <alexyk> I've tweaked OCaml runtime options and now it does the Twitter graph allright.  So clojure and ocaml are out the door, haskell be next.
21:40:17 <ptrf> twitter graph?
21:40:52 <alexyk> ptrf: a derivative of it
21:40:53 <kmc> which door is this?
21:41:04 <alexyk> kmc: the FP paradise
21:41:14 <kmc> will there be 72 virgins there?
21:41:25 <alexyk> kmc: pure ones
21:41:30 <ptrf> alexyk: oh, what kind of graph is it? what is the output of your program?
21:42:00 <alexyk> ptrf: there will be a writeup :)
21:42:06 <alexyk> and a shootout of the ages
21:42:28 <ptrf> oh, but I'm assuming that is a sort of pet learning project?
21:43:15 <alexyk> ptrf: no, it's a big-ass research project (TM) :) I actually do social capital simulation on a complete gardenhose for 35 days
21:43:49 <kmc> social capital
21:43:52 <kmc> twitter-backed securities
21:43:57 <alexyk> I did learn clojure and haskell with it; ocaml was translated back from haskell and did do speedup
21:44:10 <alexyk> ocaml is 2x+ faster than clojure
21:44:13 <Veinor> "I'd like to buy 200 shares of Justin Bieber"
21:44:42 <alexyk> haskell dies a valiant death, cursing in British-Aussie accent and remembering Nelson and Wellington
21:44:43 <ptrf> some of my friends have projects that they like to work on in perticular. so whenever they learn a new langauge they work on that project
21:45:05 <ptrf> one of my friends always do an irc bot.. or used too
21:45:06 <ptrf> to
21:45:17 <alexyk> Veinor: you have no idea how close you are.  Justin Bieber's ecosystem was a major discovery.
21:45:27 <ptrf> now he's doing ircds instead :P
21:45:28 <alexyk> before the world knew, clojure found him
21:45:46 <ptrf> another one who might be a bit well known in here does torrent clients
21:45:46 * hackagebot bloomfilter 1.2.6.3 - Pure and impure Bloom Filter implementations.  http://hackage.haskell.org/package/bloomfilter-1.2.6.3 (BryanOSullivan)
21:46:01 <kmc> cool alexyk
21:46:04 <alexyk> kmc: well al3x went into banking from twitter, so much for backing
21:46:53 <alexyk> the problem with haskell, imperativeness becomes disgusting.  All those List.iter and Hashtbl in ocaml now look so dirty.
21:47:03 <ivanm> as they should :p
21:47:08 <alexyk> I hide imperative code in folds
21:47:32 <sshc> "data RealFloat a => Complex a = !a :+ !a"  I don't understand the syntax of ":+"
21:47:40 <ptrf> alexyk: well good for you. I havent really advanced from SML/OCaml yet.
21:47:44 <sshc> Is there any documentation for this?
21:47:53 <ptrf> did a small virtual machine in haskell last year, was good
21:47:56 <aavogt> sshc: the haskell report
21:47:58 <alexyk> ptrf: very easy, just try 3 times over 4 years :)
21:48:19 <ptrf> it taught me some good stuff. I got to think differently
21:48:24 <ivanm> sshc: it's an infix constructor (hence the : at the beginning)
21:48:31 <kmc> sshc, it's an infix type constructor
21:48:37 <kmc> basically, : counts as an upper-case letter ;)
21:48:46 <aavogt> it's a data constructor
21:48:48 <ivanm> kmc: isn't the Complex the type constructor?
21:48:53 <kmc> sorry yes
21:48:54 <kmc> data constructor
21:48:57 <ivanm> *tsk, tsk*
21:49:03 <kmc> it's like data RealFloat a => Complex a = MkComplex !a !a
21:49:04 <kmc> but infix
21:49:16 <kmc> (in GHC you can have infix type constructors as well)
21:49:16 <aavogt>  `MkComplex` is infix
21:49:23 <ptrf> I would love to be better at functional programming, but I've been clinging on to imperative programming in a way. like it would sneak it's way into the code I'm writing
21:49:29 <ivanm> infix type/data constructors have to start with a colon
21:49:46 <sshc> kmc: I see.  Is it not standard (in 2010)?
21:49:52 <kmc> don't recall
21:49:54 <kmc> i think it's in 2010
21:50:03 <aavogt> which other languages have such flexible fixities as haskell?
21:50:08 <kmc> Agda
21:50:33 <ptrf> thing is, I feel it's a lot more easy to begin with. but when you add to it, and your code base grows, it just get too incomprehensible, at least compared to a functional design
21:50:57 <kmc> ptrf, do you know why you feel imperative code is easier to start with?
21:51:11 <ptrf> dunno. I was kinda brought up with it.
21:51:21 <ptrf> plus, I guess it's just less abstract
21:51:26 <sshc> kmc: Can infix functions start with ':' as well?
21:51:29 <kmc> sshc, no
21:51:38 <kmc> just as prefix functions can't start with an upper-case letter
21:51:49 <kmc> (but a constructor is a lot like a function)
21:52:03 <sshc> I see
21:52:05 <kmc> yeah, it takes time to learn the FP way of doing things
21:52:11 <ptrf> especially when you have state. then I can distinguish more easily among the... ehh
21:52:20 <kmc> it might be easier to learn it without learning the Haskell way of doing things at the same time
21:52:36 <kmc> Haskell sort of became the poster child for functional programming, but it's really strange among functional languages
21:52:56 <kmc> i think the core of what i'd call FP is only a small part of what beginners to Haskell have trouble assimilating
21:53:04 <ptrf> I cant really find the expression I'm looking for
21:53:46 <ptrf> kmc: well when it comes to syntax, I think haskell is very terse
21:53:51 <aavogt> kmc: but what of all these languages which "pragmatically" include unrestricted side-effects?
21:54:12 <p_l> I think most FP languages aren't pure nor lazy by default, so that's a big difference (which is hard to assimilate)
21:54:25 <kmc> yes
21:54:29 <kmc> and purity is often misunderstood by beginners
21:54:33 <kmc> aavogt, what of them?
21:55:18 <aavogt> whether they encourage this "FP" you have not yet defined
21:55:37 <kmc> well i tend to take the loose definition
21:55:41 <ptrf> I must disagree. I see most FP languages to strive for purity
21:55:43 <kmc> "programming with functions/actions as values"
21:55:56 <kmc> a function is more useful as a value if it's not confused with an action
21:56:07 <kmc> but i don't think it's an absolute prerequisite
21:56:13 <ptrf> but haskell has a great way of encapsulating impurity
21:56:24 <ptrf> that's what makes the difference from my POV
21:56:50 <napping> purity is quite common in theorem provers and related languages
21:57:03 <kmc> right, in most languages, functions do three unrelated things
21:57:03 <aavogt> encapsulating sounds like you treat side-effecting and pure computations as if they are the same
21:57:08 <napping> laziness is a little hard to tell when you have strong normalization
21:57:08 <kmc> in Haskell these three roles are separate
21:57:29 <kmc> it's not that effects are "encapsulated", they're a totally different unrelated sort of thing
21:57:34 <aavogt> while you can't because they have different types (unless you somehow manage to have everything in IO)
21:58:03 <ptrf> I'm kind of a newcomer to haskell
21:59:03 <kmc> ptrf, welcome :)
21:59:03 <ptrf> it wasn't meant as a quantizing 
21:59:08 <ptrf> thanks
21:59:31 <aavogt> kmc: besides agda with infix decls?
21:59:44 <aavogt> (I mean something you can use practically)
22:00:02 <kmc> other languages with custom infix operators?
22:00:05 <kmc> i'm sure there are some
22:00:12 <aavogt> ones with custom fixities
22:00:18 <kmc> i don't know
22:00:23 <kmc> Coq too ;)
22:00:43 <aavogt> the tendency seems to be to choose fixities based on first or last chars in the operator you define
22:00:54 <aavogt> (if you get to define your own ones at all)
22:02:10 <kmc> let's just hardcode a small set of operators and fixities and make the user shoehorn their problem into that syntax
22:03:15 <wavewave> hello, what package should I use for runtime haskell code compilation?
22:03:24 <aavogt> well user-fixities make parsing code more difficult
22:03:25 <kmc> hint
22:03:26 <emilmeln> wavewave: hs-plugins
22:03:32 <kmc> hs-plugins is muy deprecado
22:03:52 <emilmeln> kmc: Why?
22:03:57 <kmc> it doesn't work with recent ghc
22:04:17 <emilmeln> Is it abandoned?
22:04:24 <Axman6> i think i saw dons talking about working on it recently
22:04:25 <kmc> don't think it has worked since 6.6
22:04:27 <aavogt> so dons is writing a thesis about code that's already bitrotten?
22:04:28 <wavewave> hint is the package name?
22:04:33 <kmc> yes
22:04:40 <kmc> hs-plugins predates ghc-api iirc
22:04:40 <aavogt> kmc: perhaps it's been renamed to just plugins?
22:04:45 <aavogt> @hackage plugins
22:04:45 <lambdabot> http://hackage.haskell.org/package/plugins
22:04:45 <napping> aavogt, kmc: you should see what you can do with syntax in Coq
22:04:49 <kmc> no, i refer to the plugins package on hackage
22:05:16 <kmc> Configuring plugins-1.4.1... cabal-setup: At least the following dependencies are missing: base >=4 && <4
22:05:18 <kmc> awkward
22:05:20 <napping> they do the full extensible grammar
22:05:54 <wavewave> I failed to install plugins. 
22:06:00 <wavewave> I am using GHC 6.12.1
22:06:05 <ivanm> kmc: lol
22:07:00 <kmc> at this point i think your choices are hint or ghc-api directly
22:07:12 <kmc> and, for a different meaning of "runtime compilation", dyre
22:07:33 <BMeph> Maude has plenty of language oddity. :)
22:07:37 <kmc> oh and mueval
22:07:43 <BMeph> Hmm, Maude + Clean...
22:07:44 <wavewave> hint is an interpreter and ghc-api is JIT compilation?
22:08:09 <kmc> hint call ghc-api
22:08:14 <kmc> calls*
22:08:16 <kmc> it is a friendlier interface to ghc-api
22:08:32 <kmc> they both do the same thing as ghci
22:08:36 <kmc> compilation to bytecode, interpret that
22:08:39 <c_wraith> ghc api mangles your sigint handler, by the way.  I finally tracked that down today.
22:08:53 <kmc> though i am sure there's a way to use ghc-api to do native compilation, if you have the guts to go digging
22:09:06 <kmc> you can also just spit out Haskell code into a file and call ghc...
22:09:11 <emilmeln> kmc: can hint load dynamic libraries?
22:09:32 <kmc> do you mean .so specifically?
22:09:41 <kmc> or do you just mean loading a native-compiled haskell library at runtime?
22:09:46 <kmc> because it can do the latter, same as ghci
22:09:48 <emilmeln> kmc: Haskell .so's.
22:09:59 <kmc> i don't know about that; they're new and uncommon
22:10:15 <kmc> hint and ghci both will load an import of a native compiled library just fine
22:10:22 <kmc> but the code you pass in as a string is bytecode-compiled
22:10:56 <wavewave> kmc: i see. Thanks for the detail info. 
22:11:01 <kmc> no problem :)
22:11:03 <c_wraith> It will also load source files, the same way ghci does with :load
22:11:08 <wavewave> I will try to use hint. 
22:11:49 <kmc> if you are curious how ghci manages to dynamically link a plain .o file
22:12:13 <kmc> the answer is that rts/Linker.c contains the source to a dynamic linker for ELF and PE formats
22:12:21 <kmc> and is about 5000 lines of C
22:12:58 <kmc> with lots of preprocessor directives ;P
22:13:25 * kmc wonders why they didn't use bfd
22:13:26 <napping> is there a way to manipulate environments directly with the ghc-api?
22:13:53 <c_wraith> what environments?
22:13:57 <napping> I've tried to figure out how GHCi is implemented, but never found where the environment was maintained
22:14:38 <aavogt> ghci itself isn't much code
22:15:06 <emilmeln> i think it's in Ghc monad.
22:15:12 <napping> pointers would be appreciated
22:15:29 <napping> I have no idea how they evaluate new expressions / bindings in the scope of the existing environment
22:15:48 <aavogt> so ghci runs in it's own monad, which keeps track of what your imports etc. are
22:15:59 <kmc> i am glad that the ghc developers thought a REPL was worth this much effort
22:16:15 <kmc> it seems some compilers entirely overlook the possibility of a REPL
22:16:23 <c_wraith> GhcMonad is actually a typeclass
22:16:26 <aavogt> then whenever you :reload, it calls some functions from the ghc-api to load whatever modules you have
22:16:33 <napping> that's all the easy part
22:16:34 <c_wraith> http://darcs.haskell.org/ghc/compiler/main/GHC.hs
22:16:34 <Axman6> needs moar C REPL
22:16:46 <kmc> gdb is the poor man's C REPL
22:16:52 <kmc> what's fun is that you can attach it to any running process
22:16:55 <napping> what I couldn't find was how to extend a context with new bindings
22:16:57 <kmc> and make syscalls on that process's behalf
22:17:10 <aavogt> the definitions etc. are ghc-api stuff
22:17:38 <kmc> this is useful if your window manager's cwd is a stale nfs handle, or if you forgot to launch a long-running process in screen
22:17:40 <emilmeln> Still Haskell REPL is not good enough...
22:18:17 <Axman6> ?
22:19:18 <emilmeln> Frequently I want to load just one function.
22:20:05 * hackagebot haxr 3000.7 - XML-RPC client and server library.  http://hackage.haskell.org/package/haxr-3000.7 (GracjanPolak)
22:20:25 <napping> why do all these foundational verification strategies seem to rely on heap typings?
22:21:32 <ivanm> Axman6: there is a C REPL available IIRC...
22:21:38 <Axman6> yeah i
22:21:47 <Axman6> i've heard of them before too
22:22:01 <cncl> are there examples of long-running haskell programs that do not actually leak
22:22:26 <Axman6> sure
22:22:32 <Axman6> main = getChar
22:22:39 <cncl> :(
22:22:46 <blackh>   cncl: Do you want help with a leak?
22:22:52 <cncl> not in particular
22:22:56 <ivanm> @type getChar
22:22:57 <lambdabot> IO Char
22:23:10 <ivanm> Axman6: that isn't long-running though, is it? doesn't it just get one character and then stop?
22:23:18 <napping> most of the serious programs I know of seem to do fine - the web servers, xmonad
22:23:23 <cncl> i just feel like anything that is long living and written in haskell, i will end up spending time aimlessly wandering around trying to squash leaks
22:23:28 <Axman6> it's long running if you never give it a character ;)
22:23:42 <blackh> cncl: Well, yes - I have a commercial video game here that doesn't leak, so it is possible.
22:23:58 <cncl> i see
22:24:00 <napping> It's simple - don't keep references to data you no longer need
22:24:04 <Axman6> Xmonad is a good example
22:24:05 <cncl> maybe i do not have a good enough intuition of where to add strictness
22:24:08 <kmc> i've never had a leak problem with xmonad, to my knowledge
22:24:11 <ivanm> Axman6: heh
22:24:21 <cncl> yeah xmonad is a good example
22:24:26 <cncl> but i do not think it does much allocation?
22:24:34 <kmc> obviously a lot of work has gone into xmonad
22:24:35 <blackh> cncl: Leaks _are_ an issue in Haskell, but it is possible to deal with them.  Unfortunately you can't avoid the issue.
22:24:36 <napping> cncl: oh, leaks in a accumulators are a bit different
22:24:38 <kmc> every Haskell program does a ton of allocation
22:24:51 <kmc> also, i think we're confusing two uses of the word "leak"
22:24:57 <cncl> space leak, sorry
22:25:00 <kmc> one meaning that you're retaining garbage
22:25:10 <kmc> another meaning that your heap usage is asymptotically worse than it would be under strict evaluation
22:25:14 <kmc> (but those thunks are not garbage)
22:25:24 <cncl> right
22:25:27 <cncl> that is what i meant
22:25:38 <napping> the latter?
22:25:40 <cncl> yes
22:25:57 <napping> yeah, that is a function of your data structures
22:26:03 <cncl> yes it is
22:26:05 <kmc> cncl, there's no magic bullet -- strictness annotations on data, bang patterns on functions, strict folds, heap profiling are all tools to use
22:26:13 <Saizan> it's not so obvious in which case you are at a first glance though, unless you've an explicit tail recursive lazy loop.
22:26:34 <napping> and the advice there is pretty much just to always strictly evaluate things that go into a mutable reference cell
22:26:45 <napping> or something used in an imperative way, like a map you keep updating
22:26:47 <Saizan> throwing strictness around blindly can cause even more memory usage.
22:26:55 <cncl> right
22:26:58 <kmc> Saizan, interesting, do you have a good example?
22:27:09 <Axman6> strict trees
22:27:30 <cncl> what is the best tool for profiling heap usage and space leaks at the moment?
22:27:40 <cncl> i am not well-versed in debugging haskell programs
22:27:41 <Axman6> ghc's profiling features...
22:27:56 <Axman6> and cost center annotations
22:28:07 <Saizan> kmc: anything you've some stream or tree that can be GC'ed as you consume it lazyness is saving you memory
22:28:09 <kmc> cncl, did you read http://book.realworldhaskell.org/read/profiling-and-optimization.html
22:28:15 <cncl> yes
22:28:22 <napping> I haven
22:28:28 <Saizan> *anytime
22:28:35 <kmc> Saizan, makes sense
22:28:44 <cncl> i was wondering if that is still one of the better ways, and not just something that would be primarily used by beginners (that was the last time i actually used profiling in haskell)
22:28:48 <napping> I haven't had issues with leaks since I learned to force Ints when I was folding them
22:29:06 <napping> (or modifying a Map entry, or an IORef, or whatever)
22:29:19 <kmc> if you expose that right, it can unbox them too
22:29:25 <cncl> most of the haskell programs i write have been oriented towards symbol manipulation and stuff that is not long-running, so performance hasn't been an issue, but it will be for an upcoming project where i intend to use haskell
22:30:02 <kmc> cncl, well i think it's doable, but it sounds like you know what you're getting into
22:30:10 <kmc> in what sense is performance an issue for this new project?
22:30:54 <cncl> a few things. i will likely need to write C code for the most performance-critical sections (soft real-time low latency audio) to avoid GC pauses
22:31:14 <blackh> cncl: The way to deal with it is to look at what state you are retaining, and treat the strictness of it as a design issue.  Then run your profiling early in development and you should find that it will stay well-behaved.
22:31:27 <cncl> i see
22:31:34 <BMeph> Someone (by which I mean someone ELSE) should code up a cheap little TH splice to imitate loading a single function from a module. THat'd be sweet...
22:32:02 <c_wraith> haha.  I guess what I've done is *slightly* more than that.
22:32:06 <blackh> cncl: In the video game we are using some C for that reason.
22:32:15 <cncl> yup
22:32:36 <napping> threads running in C are not stopped for GC?
22:32:37 <cncl> i was expecting to do that either way (and probably prefer it, C is sort of ideal for that kind of immediate bit munging)
22:32:47 <blackh> napping: Correct
22:33:34 <blackh> napping: Another way to put it is that the GC pause is done co-operatively, so if your C thread doesn't go into Haskell, it'll never stop for GC.
22:33:50 <kmc> does that mean the GC will never happen?
22:33:58 <kmc> you could always spawn a new OS thread on the C side, of course
22:34:06 <blackh> kmc: No - it happens on all the Haskell threads, but the C thread keeps on truckin'
22:34:11 <kmc> ok
22:34:33 <kmc> right, because GC affects the Haskell-evaluating MUT threads, and non-"unsafe" FFI calls are made from a separate pool of FFI worker threads
22:34:37 <kmc> i think....
22:34:49 <cncl> blackh: do you use simple abstract representations of things like sound effects and music and pass them from haskell to c, which does the appropriate mixing and handles audio callbacks?
22:34:55 <napping> It's been a while since I read about the threaded runtime - isn't there a separate pool of threads that runs foreign calls?
22:35:29 <blackh> cnci: The Haskell gives instructions ahead of time, and the C code plays through them.
22:35:43 <cncl> ah ok
22:36:00 <cncl> so you have a second buffer, and use C to keep it steady and avoid GC hangs
22:36:40 <blackh> Yes - We delegate the instructions to the C thread through a queue (written in C).
22:37:03 <cncl> cool
22:37:04 <napping> have you measured GC time?
22:37:19 <cncl> though i won't be doing that, since i must maintain as little buffer as possible
22:37:45 <blackh> Yes - on the iPhone it ranges from 1 to 500 milliseconds, with the shorter delays being much more common.
22:37:56 <napping> ok, 500 is getting up there
22:37:58 <blackh> 500 ms delays are only once every minute or so
22:38:05 <cncl> haha
22:38:11 <blackh> This is on the iPhone.  The CPU is about 1/50th of the speed of a Core 2 Duo.
22:38:26 <emilmeln> Is Haskell popular in the game development?
22:38:32 <cncl> no
22:38:39 <napping> mostly C++
22:38:45 <Axman6> not yet
22:38:46 <cncl> c++ is overwhelming popular for game development, for better or worse (probably mostly worse)
22:38:50 <blackh> It's popular with us (iPwn Studios) but no other commercial games are done in Haskell.
22:39:00 <kmc> yes, this will be the first one
22:39:06 <kmc> also the first commercial mobile app in Haskell?
22:39:09 <blackh> There are a lot of open source games in Haskell, though
22:39:13 <cncl> since you can just model your game as a bunch of mutations between objects
22:39:19 <emilmeln> blackh: You're developing for iPhone?
22:39:29 <cncl> kmc there have been a couple of others, a newreader i think?
22:39:33 <cncl> though maybe they were free
22:39:33 <blackh> emilmeln: Yes
22:39:42 <kmc> yes we've heard of the new Apple license ;)
22:39:54 <blackh> Storm in a teacup.
22:39:58 <cncl> i have doubts apple will reject a haskell app
22:40:04 <kmc> the new rule is that Apple can reject your app for any or no reason
22:40:10 <kmc> the old rule is that Apple could reject your app for any or no reason
22:40:13 <cncl> simply on the grounds of it being in haskell, anyway.
22:40:31 <kmc> cncl, right, the best defense is to make it a good program
22:40:33 <kmc> that they'll want to have
22:40:50 <BMeph> HStorm should be your next project! :)
22:41:09 <cncl> if they were serious about enforcing those clauses they would be rejecting games left and right, or things that look like they're doing too much dynamic programming
22:41:33 <cncl> looks mostly like a scare tactic to make adobe and others not try to commoditize the platform
22:41:36 <napping> blackh: have you released anything?
22:41:42 <kmc> yeah, they will get no good games if devs aren't allowed to script game logic using something like Lua
22:42:21 <blackh> napping: No, nothing released yet
22:42:33 <cncl> blackh: are you using the LLVM backend to build for iphone, or gcc?
22:43:04 <blackh> cncl: We intend to, but we haven't done anything on it yet.
22:43:39 <cncl> i've written several obj-c applications and i have to admit i loathe it
22:43:54 <cncl> though i think os x/iOS is a nice platform with sensible libraries
22:44:11 <cncl> thankfully mostly C where necessary
22:47:06 <cncl> blackh: do you manually invoke GC as part of your program?
22:47:40 <blackh> cncl: No, we don't do anything special like that.  The RTS knows when to invoke it.
22:47:47 <cncl> cool
22:49:41 <cncl> does your game model use an imperative style? or is it something more like FRP
22:50:03 <cncl> since nearly all games i see use discrete frames to model game state
22:53:10 <gilbertleung> hi, I'm sure this has been asked a 100 times, but as it is hard to Google, I'll ask again:
22:53:20 <gilbertleung> what does :{ and :} do in haskell ?
22:53:24 <gilbertleung> * : }
22:53:45 <Axman6> what does { and } do? or :{ and :}?
22:53:56 <gilbertleung> latter
22:54:16 <Axman6> afaik, they're only used in GHCi for multi line definitions
22:54:24 <gilbertleung> ahh, okay
22:54:24 <gilbertleung> makes sense
22:54:26 <kmc> it's not part of Haskell; it's part of the command syntax for GHCi
22:54:34 <gilbertleung> i'm following a short tutorial that's using GHCi
22:54:35 <gilbertleung> thanks
22:56:03 <emilmeln> Hmm, I would like to see coloured GHCi output :)
22:56:18 <cncl> blackh: is there good info on getting haskell working with cocoa and/or uikit? (this is interesting to me since i will be targeting os x with my application)
22:56:30 <emilmeln> Especially error messages.
22:56:34 <cncl> i current use 6.12 but wouldn't mind using a newer version
22:56:53 <cncl> emilmeln: haskell inferior mode in emacs can do that
22:57:36 <blackh> cncl: I don't know much.  We're doing our own bindings but only for the bits we need.
22:57:45 <emilmeln> cncl: Not that much...
22:57:55 <cncl> i see
22:57:59 <cncl> HOC looked heavyweight and old
22:58:06 <cncl> and i am mostly interesting in just using C
22:58:19 <kmc> well, there are plenty of documents about making C bindings
22:58:25 <cncl> yup
22:58:38 <cncl> but i will still have to talk to obj-c stuff, which involves runtime stuff
23:00:16 <Axman6> what's the easiest way to get cabal-install installed? (without the plstform, i'm on FreeBSD)
23:00:20 <Axman6> platform*
23:00:59 <Axman6> isn't there a script somewhere that will download all the needed packages?
23:01:33 <Saizan> yes, in the tarball
23:01:37 <Saizan> bootstrap.sh
23:01:56 <Axman6> ah, ok
23:02:20 <dobblego> what is the format of lambdabot's passwd.rc file for authenticating to services?
23:03:29 <ddarius> It might be sent unaltered to the IRC server
23:03:44 <dobblego> ok so raw IRC
23:04:56 <dobblego> thanks
23:05:28 <Jafet> Isn't that the IRC default
23:08:52 <Cale> Oops, that's wrong. It's just a normal lambdabot .rc file, which means that it contains lambdabot commands
23:09:01 <Cale> msg freenode:nickserv identify <password>
23:09:12 <Cale> But dobblego is gone :P
23:13:36 <cncl> theoretically, let's say i'm working on a music sequencing application. most of it will be written in haskell. what are the best choices for persistence/serialization? files would contain chunks of cached binary data (audio waveforms) and musical sequences, which could be represented any number of ways
23:13:54 <cncl> i've used stuff like just binary in the past
23:14:08 <kmc> "binary" and "cereal" are popular
23:14:31 <cncl> yeah i have been doing instances of Get and Put for most of my persisting needs up until now
23:15:12 <cncl> with C i would probably use something like sqlite
23:15:22 <kmc> you can use that from Haskell
23:16:30 <cncl> is it worth doing? one motivation for using it in C is that it greatly lessons the burden on managing memory yourself
23:16:51 <cncl> in haskell this is not as much of a problem, though i am interested in gaining ways to easily stream data to and from the disk
23:17:00 <cncl> instead of having to spool up the entire thing into memory and write it all back out at once
23:18:02 <Jafet> Someone hasn't done their sequencer file format homework
23:18:29 <cncl> what am i missing :)
23:19:10 <Jafet> Why not use an existing format?
23:19:30 <cncl> they cannot represent all that i need
23:19:48 <cncl> (i am very familiar with all of them, i have been using general midi/smf since the early 90s for example)
23:20:05 <cncl> omf, all the tracker formats
23:20:35 <Jafet> Obviously, MIDI is not going to represent what you need
23:22:10 <cncl> open to suggestions if you know some format that is powerful
23:23:57 <Jafet> One based on sqlite sounds suspect, at any rate
23:24:21 <cncl> is there any reason in particular?
23:24:40 <Jafet> A common symptom of golden hammer syndrome.
23:25:11 <cncl> can you elaborate, i'm not sure what you mean in this case
23:25:34 <Jafet> SQL is a model for relational databases.
23:25:50 <Jafet> Is that a good model for sequencing?
23:26:10 <cncl> i don't see why not, sequences are just data
23:26:25 <Jafet> If you say so then, good luck
23:26:58 <cncl> if you have a reason why you think that would be a bad idea, i am definitely interested to hear it
23:29:21 <Axman6> there are plenty of cases where people use sqlite databases as their app's file format
23:30:24 <emilmeln> Maybe databases are too complex for just storing and retrieving files.
23:30:27 <cncl> i believe that is actually the primary purpose of sqlite
23:30:30 <kmc> "are just data" is uselessly broad
23:30:50 <cncl> kmc well so was his accusation that it might not be appropriate :)
23:30:55 <kmc> yeah
23:31:08 <kmc> i'm not sure you'll get anything out of it being relational
23:31:14 <kmc> but it might still be worth using as a serialization layer
23:31:18 <cncl> yes
23:31:28 <cncl> it would likely not be highly relational
23:31:50 <cncl> but it would be moreso than existing formats, which are mainly just dumb streams of events
23:32:01 <kmc> the question then is, is SQL too cumbersome for only serialization
23:32:02 <cncl> 'dumb' as in entirely local
23:32:12 <kmc> but it's probably not, since in Haskell you can abstract it nicely
23:32:33 <cncl> in C it's definitely not cumbersome compared to many alternatives :)
23:32:47 <Jafet> Note that sqlite is not SQL either
23:32:53 <cncl> if you consider that a sequence might also be enormous, then it is also helpful to not have to worry about seeking and such
23:33:20 <cncl> sql allows you to use most of the primary and important features of sql
23:33:22 <cncl> er sqlite
23:33:30 <Jafet> You do have to worry. Abstraction layers like sqlite just allow you to pretend, for the time being, that you don't.
23:33:32 <cncl> (sqlite allows)
23:33:46 <cncl> can you elaborate? i'm not sure what you mean
23:33:57 <Jafet> For example, the actual layout of data on the disk is unspecified; it is abstracted away.
23:34:03 <Jafet> Now do low-latency playback.
23:34:20 <cncl> it is trivial to pre-load sequence data as necessary
23:34:32 <Jafet> But you don't know the seek cost.
23:34:35 <cncl> you would not be reading from the disk in a low-latency fashion either way
23:34:38 <kmc> i think the amount of data involved here is small
23:34:44 <cncl> you don't either way
23:34:56 <kmc> how many kBps is a typical sequence file?
23:34:59 <Jafet> You can predict the seek cost if you know the layout.
23:35:09 <Jafet> kmc, he is combining it with samples, as mentioned previously
23:35:15 <Jafet> Otherwise MIDI would have sufficed
23:35:17 <kmc> i know
23:35:31 <kmc> i'm just interested in the average
23:35:36 <kmc> size of file divided by play time, that's all
23:35:41 <cncl> it depends. in a modern DAW with lots of automation data, you can get anywhere between 500kb through a few dozen mb depending on the efficiency of the sequencer and the song (assuming roughly 3 minutes, in my experience)
23:35:54 <cncl> this is excluding rendered waves and audio samples, etc
23:35:59 <cncl> just the sequence data
23:36:10 <kmc> dozens of MB for a 3 minute song?
23:36:13 <kmc> without samples?
23:36:14 <cncl> nothing heavyweight
23:36:16 <cncl> yes
23:36:22 <kmc> wow
23:36:39 <kmc> isn't that close to lossless 44.1 kHz audio?
23:36:42 <kmc> what's all that data doing?
23:37:02 <cncl> modern workstation sequencers like reaper can position events in time with sub-sample accuracy
23:37:22 <cncl> if you have a few thousand events it adds up quick
23:37:24 <Jafet> Sounds plausible. It might have numbers with ridiculous bitrate as well (48 bits?)
23:37:42 <Jafet> 192 kHz sequencing isn't unheard of, either
23:37:49 <kmc> mm
23:37:56 <cncl> in a modern daw, the frequency is not tangled with the sequencing
23:38:01 <cncl> you can switch between playback frequencies on the fly
23:38:42 <Jafet> You are working on one of these "modern DAW", cncl?
23:38:54 <cncl> yeah
23:39:21 <kmc> digital audio workstation?
23:39:25 <cncl> yes
23:40:32 <Jafet> Well then, researching and adapting from existing formats sounds even more pertinent
23:40:49 <cncl> not really, none of them are open, and i cannot stand existing DAWs
23:40:53 <cncl> they are almost uniformly terrible
23:41:05 <kmc> it sounds like you have done the research
23:41:12 <Jafet> The usual reason to make yet another one
23:41:23 <cncl> well i'm a professional in this field, so yeah, it would be weird if i wasn't familiar :)
23:41:39 <kmc> starting over might turn out to be the wrong decision, but it won't be an uninformed decision
23:41:48 <cncl> there is nothing to start with, though
23:41:56 <cncl> there are no open modern sequencer formats
23:41:58 <kmc> where would we be if Linux devs adapted from existing version control systems ;)
23:42:02 <cncl> none that are supported by any other DAWs, anyway
23:42:09 <kmc> @quote cvs
23:42:09 <lambdabot> LinusTorvalds says: The slogan of Subversion for a while was 'CVS done right', or something like that, and if you start with that kind of slogan, there's nowhere you can go. There is no way to do
23:42:09 <lambdabot> CVS right.
23:42:35 <cncl> yes i guess that is how i feel
23:42:43 <cncl> most DAWs are all the same, but with superficial differences
23:43:04 <kmc> most programming languages are the same, but with superficial differences ;)
23:43:04 <Jafet> Note that if you use sqlite, any other tools that work with your format in even the most trivial ways would likely need to use sqlite as well
23:43:22 <Jafet> Not a big licensing problem, but those programmers will hate you for it
23:43:36 <Jafet> Also, you are dependent on the sqlite internal storage format.
23:43:42 <kmc> any other tools that work with your format will need to include a widely-distributed public-domain library which has bindings to every language
23:44:13 <kmc> it's not even "copyleft" or "open source".  it's public domain do-whatever-the-hell-you-want
23:44:21 <Jafet> As opposed to a tool working with a specially designed format like MIDI, which only needs to know the details of what it does.
23:44:47 <kmc> a tool for working with MIDI depends on the MIDI internal storage format
23:45:03 <cncl> you cannot represent modern sequencer features (and even less so what i would like to do) in SMF (what people call midi files)
23:45:17 <cncl> again, i am open to suggestions if you have any
23:46:00 <Jafet> I have been suggesting to think about what your sequencer does, how it works, and design a format that fits that function.
23:46:03 <emilmeln> cncl: maybe you can extend existing format with new fetures?
23:46:22 <Jafet> Piggybacking on sqlite is a recipe for future hassle.
23:46:25 <cncl> that is what the sqlite databases (one per project) would represent
23:46:35 <cncl> do you have anything to back up that assertion? so far you have not offered any
23:46:42 <kmc> Jafet, a minute ago you were saying "researching and adapting from existing formats", now you're saying don't even use existing serialization libraries?
23:46:55 <Jafet> sqlite isn't a serialization library. What are you on about?
23:47:02 <kmc> it is, inter alia, a serialization library
23:47:11 <Jafet> Yeah, throw latin phrases around
23:47:12 <Jafet> I'm out
23:47:19 <kmc> ttyl
23:47:29 <cncl> emilmeln: there are no existing formats that have been created within the last 20 years that are open (non-proprietary) other than perhaps ardour's, but it is not a sequencer, only a multi-tracker
23:47:52 <kmc> cncl, fwiw i don't think you're crazy for wanting to use sqlite -- i think it could turn out well, or poorly, but that probably none of us can predict with confidence
23:48:09 <cncl> actually i know it will turn out fine since one other person has already done it and it works :)
23:48:12 <kmc> haha
23:48:18 <kmc> can you use their schema?
23:48:18 <cncl> the buze project
23:48:26 <cncl> nah it models sequences differently than i would
23:48:30 <kmc> ah
23:48:46 <kmc> sql seems like a good bet for reasonable extensibility -- new tools can add new tables that reference the existing ones
23:48:50 <kmc> without getting in the way
23:49:21 <cncl> yes
23:49:34 <cncl> he uses it quite extensively internally though -- almost all of the editor commands are just wrappers around queries
23:49:42 <kmc> interesting
23:49:48 <cncl> which allows it to operate ad-hoc over very large data sets
23:49:55 <cncl> without much work on his part
23:50:14 <cncl> i probably would not do that myself, though.
23:50:30 <cncl> maybe if i did most of the project in C
23:50:35 <cncl> but probably not if it were in haskell
23:51:46 <kmc> because in C you'd be using sqlite as the missing C data structures and memory management library?
23:52:00 <Saizan> there aren't really good abstractions for keeping a conceptually single value partially in memory and partially on disk yet, though
23:53:28 <cncl> yes
23:54:07 <Saizan> http://community.haskell.org/~ndm/binarydefer/ <- there's this but it once data gets loaded it will be kept in memory
23:55:04 <kmc> i imagine you could build something based on weak references?
23:55:36 <Saizan> yeah, but i'm not sure how nice it'd be to work with those
23:55:40 <Jafet> That doesn't sound like an abstraction I would want to make
23:55:56 <kmc> does the GC care about weak refs at all? if a value has a bunch of weak refs but no real refs is it less likely to get collected?
23:56:00 <Jafet> What happens when accessing something that isn't there anymore? Exception? Bottom?
23:56:11 <kmc> Jafet, http://www.haskell.org/ghc/docs/6.10-latest/html/libraries/base/System-Mem-Weak.html
23:56:31 <kmc> what i mean is that you'd use these internally
23:56:36 <kmc> and re-load from disk when they go away
23:57:16 <Jafet> I thought you were proposing using that as the abstraction
23:57:50 <kmc> the question is whether your whole file will get unloaded at every GC
23:58:05 <kmc> maybe you do some trickery where references switch between strong and weak adaptively
23:58:19 <Jafet> A practical system will inevitably involve internal magic
23:58:44 <kmc> i'm continually surprised by what people manage to do with GHC Haskell using a relatively small amount of internal magic
23:58:54 <kmc> Weak seems like one of those libraries providing a little magic that goes a long way
23:59:03 <Jafet> How would you tell (the user) if a reference is strong or weak?
23:59:10 <kmc> you wouldn't
23:59:11 <kmc> that's the point
23:59:18 <kmc> you just access the data, and either it's already there, or it gets loaded
23:59:25 <kmc> if it gets loaded, the GC might unload it later
23:59:30 <emilmeln> Does ![a] mean only strict head?
23:59:32 <kmc> but if it hasn't, subsequent accesses will be quick
23:59:34 <kmc> emilmeln, yes
23:59:49 <Jafet> That indeed sounds like an abstraction I would not make.
