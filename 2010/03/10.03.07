00:00:24 <c_wraith> Sometimes it loses laziness.  Sometimes it doesn't.
00:00:34 <c_wraith> Compare Control.Monad.State and Control.Monad.State.Lazy
00:00:55 <c_wraith> IO is non-lazy.
00:00:55 <blueonyx> but the action it forms is lazy
00:01:01 <Cale> rajeshsr: It doesn't really have anything to do with evaluation order.
00:01:21 <tensorpudding> > undefined >>= return (const 5) :: [Int]
00:01:22 <lambdabot>   Couldn't match expected type `[GHC.Types.Int]'
00:01:23 <lambdabot>         against inferred typ...
00:01:23 <Cale> rajeshsr: Instead it expresses the order of a sort of abstract "execution" whose meaning depends on the monad in question.
00:01:26 <tensorpudding> err
00:01:33 <Cale> For example, consider in the list monad, something like:
00:01:37 <tensorpudding> > undefined >>= return . const 5 :: [Int]
00:01:38 <lambdabot>   * Exception: Prelude.undefined
00:02:08 <Cale> > map (*10) [1..10] >>= \x -> [1..5] >>= \y -> return (x+y)
00:02:09 <lambdabot>   [11,12,13,14,15,21,22,23,24,25,31,32,33,34,35,41,42,43,44,45,51,52,53,54,55...
00:02:17 <tensorpudding> > undefined >>= return . const 5 :: Maybe Int
00:02:18 <lambdabot>   * Exception: Prelude.undefined
00:02:31 <tensorpudding> hmm
00:02:36 <Cale> The order in which the evaluation proceeds jumps back and forth between the lists involved there
00:02:57 <Cale> but there's a sort of ordering on the choices being made, and that's what >>= is really expressing
00:05:53 <rajeshsr> Cale, hmm, so it is not breaking the semantics of laziness. But it is just making the dependency between action explicit enough, right?
00:05:58 <blueonyx> > map (*10) [1..] >>= \x -> [1..5] >>= \y -> return (x+y)
00:05:59 <lambdabot>   [11,12,13,14,15,21,22,23,24,25,31,32,33,34,35,41,42,43,44,45,51,52,53,54,55...
00:06:27 <Cale> rajeshsr: yeah
00:06:34 <blueonyx> > map (*10) [1..] >>= \x -> [1..2] >>= \y -> return (x+y)
00:06:35 <lambdabot>   [11,12,21,22,31,32,41,42,51,52,61,62,71,72,81,82,91,92,101,102,111,112,121,...
00:09:29 <rajeshsr> Cale, great! But can you explain your example? that map (*10). I seem to be making nothing out of it!
00:09:52 <ezyang> rajeshsr: Do you know what a map does?
00:10:01 <rajeshsr> i mean, the whole expression and the final return. what it does?
00:10:53 <ezyang> it takes a list of natural numbers, multiplies them all by 10
00:11:20 <ezyang> then it assigns to x that value, then assigns to y either 1 or 2, and then adds x and y together
00:11:27 <ezyang> and the result is all concatenated into a final string
00:11:37 <ezyang> blueonyx is being slightly mean :-)
00:11:43 <ezyang> the code uses the list monad
00:14:22 <rajeshsr> ezyang, uh! ok!! I think I have to see list monad behaves with >>=. All I know is just I/O monad. Seems it is extracting individual elements or something like that..
00:14:54 <rajeshsr> ezyang, thanks for your explanation
00:15:35 <ezyang> yup
00:22:20 <ddarius> rajeshsr: (>>=) is just a normal function, it can't "break the semantics of laziness."
00:23:34 <psykotic> even if you have something like a state monad that threads a state value throughout, it only serializes those parts that actually depend on and modify the state
00:23:37 <rajeshsr> ddarius, yeah! i seem to be getting it! Just that it is expressing the dependency between actions clearly, and that sort of enforces the evaluation order, because of the dependency involved, right?
00:24:02 <c_wraith> exactly.  execution order is defined by data dependency
00:25:15 <psykotic> which is only a partial order
00:25:49 <psykotic> execution order is a total order consistent with the partial order of data dependency
00:25:55 <rajeshsr> cool! It is always interesting to know that, a means for expression of dependency has revolutionized functional programming! So what did people do before monads?
00:26:40 <ezyang> "it was the dark ages"
00:26:46 <ezyang> I think IO streams were what people were using?
00:26:58 <psykotic> and continuation-based IO
00:27:22 <psykotic> for non-IO things, people just did things manually.
00:27:40 <rajeshsr> psykotic, interesting interpretation about partial ordering. Is it possible to have some example about the need for a partial order while total ordering doesn't matter?
00:28:11 <rajeshsr> i mean in terms of some simple haskell code.
00:28:26 <psykotic> actually, the interesting thing about non-strictness is that you don't have a simple interpretation of 'input must be computed before output can be computed'
00:28:53 <psykotic> total ordering not mattering--well, think of adding the values of two subexpressions
00:29:11 <psykotic> you can evaluate the first, then the second; or the second, then the first; or you can even do them in parallel
00:29:58 <rajeshsr> psykotic, hmm, yeah But is there any partial ordering there at all?
00:30:15 <psykotic> well, if addition is strict, then the subexpressions must be evaluated before the addition itself
00:30:32 <Cale> Uh, sorry, that description of how the expression was evaluated was actually a bit off
00:30:47 <Cale> the map (*10) [1..10] isn't evaluated all at once, but one element at a time, as they're needed
00:31:34 <ezyang> "with implicit laziness on everything"
00:32:35 <rajeshsr> psykotic, don't get you! No matter what happnes in order to evaluate "a+b" a and b need to be evaluated first though the order of evaulating as (a, b) or (b, a) doesn't matter..
00:32:37 <psykotic> so that's a partial order between e1, e2 and e1 + e2. it says e1 < e1 + e2 and e2 < e1 + e2, but it does not stipulate a relation either way between e1 and e2, hence it is partial
00:33:01 <psykotic> i should probably not use < here as it has a normal numeric meaning :)
00:33:05 <rajeshsr> oh! with respect to e1+e2! ok!
00:35:10 <rajeshsr> psykotic, though that idea is interesting, i don't see if monads will realize such a partial ordering?
00:35:47 <rajeshsr> Cale, actually monads express a sort of linear data dependency only, right?
00:36:07 <psykotic> no
00:36:21 <Cale> rajeshsr: Well, >>= almost always expresses *some* kind of data dependency, but that's not its primary purpose.
00:36:40 <Cale> Except in a sort of abstract way.
00:36:57 <rajeshsr> Cale, hmm! So. what is the prime motivation then?
00:37:01 <Cale> I suppose it's just important to keep evaluation and execution separate.
00:37:04 <psykotic> this is one of those things where you have to think both 'inside' and 'outside' the monad's computational world
00:37:14 <psykotic> from inside the world, you can think of it as a simple linear data dependency
00:37:27 <ezyang> "plumbing" versus the actual computation
00:38:35 <Cale> If x is some computation, and f is a function from results of that computation to further computations, then (x >>= f) is the computation which, when executed, will "run x" (whatever that means) capturing its result (say v), and "then", it will "run (f v)", again, whatever that means in the monad in question.
00:39:05 <copumpkin> zomg
00:39:07 <Cale> However, the way that the result of that execution is actually determined, that is, the actual evaluation, might be in a completely different order.
00:39:35 <psykotic> copumpkin: FULL STEAM AHEAD!
00:39:39 <copumpkin> lol
00:39:49 <copumpkin> I'm famous!
00:39:49 <Cale> Almost completely different, anyway. Obviously you have to have at least some result v from x before you can make any use of the function f.
00:39:59 <ezyang> copumpkin: oh?
00:40:04 <planetbeing> Hahaha. copumpkin: that should be your comment on Reddit.
00:40:11 <copumpkin> ezyang: my abysmal AI made proggit
00:40:13 <Cale> But in some monads, for example, x might have multiple results, in which case, the evaluation will keep coming back to x
00:40:46 <psykotic> copumpkin: reading that made me tempted to make a bot that commits suicide in the fastest possible time
00:40:57 <ezyang> copumpkin: I thought it had been on proggit for some time now ;-)
00:40:58 <Cale> Or there might be even stranger loopy things, like with the backwards-in-time state monad :)
00:41:00 <rajeshsr> Cale, oh! Ok, any example of such monads?
00:41:13 <copumpkin> psykotic: I wanted to do that, but ended up getting lazy
00:41:15 <ezyang> rajeshsr: List monad. Logic monad.
00:41:15 <Cale> The list monad is an example of one where each computation can have multiple (or no) results.
00:41:30 <copumpkin> even Maybe
00:41:35 <copumpkin> gives you 0 or 1
00:41:51 <ddarius> psykotic: That should be pretty easy as in the worst case it should only take four steps and it would be easy to make a strategy to handle the remaining cases.
00:42:09 <psykotic> ddarius: right, i didn't mean it would be hard, but it would be a fun gag
00:42:24 <psykotic> i want that bottom spot!
00:42:39 * ezyang thinks blogging about teaching is kind of enjoyable 
00:42:41 <copumpkin> no bottom for you! it's mine
00:42:51 <rajeshsr> Cale, thank!! I think i get a lot clarified now!
00:43:21 <rajeshsr> ezyang, yeah, after seeing about list monads now, i seem to be getting it! Thank you so much!
00:43:30 <Cale> rajeshsr: So evaluation will return to the first list in my example up there many times, to obtain another element
00:44:25 <rajeshsr> Cale, yeah! take 5 $ map (*10) [1..] ... makes it more obvious, that full evaluation is not done!
00:44:29 <Cale> rajeshsr: The >>= doesn't really say how the evaluation goes, but imposes an ordering on how the choices are made. (It operates a little bit like nested loops in an imperative language)
00:45:37 <ezyang> rajeshsr: Fast learner ;-)
00:45:52 <ezyang> took me a week of puzzling to figure it out. partially.
00:46:48 <Cale> It's usually best to ignore the real evaluation order, but occasionally it's important.
00:47:25 <rajeshsr> Cale, haha! thanks! Anyway, so all i understood now is that order of evaluation is not what monads are for though in most cases they do! Still, am a bit fuzzy about monads though! :)
00:48:13 <copumpkin> monads take a while, don't push it :)
00:48:28 <Cale> rajeshsr: Monads are just a style of library really. Many libraries have this particular similarity in their API, and we pick it out and generalise over it so that we can write some functions that work in all those libraries.
00:48:32 <rajeshsr> So, how would you describe and interpret monads in a more intuitive way to see their usage and applications without really chewing all those formal descriptions!
00:48:55 <Cale> :t sequence
00:48:58 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
00:49:05 <Cale> (Monad m) => [m a] -> m [a]
00:49:39 <psykotic> > filterM (const [False, True]) [1..4]
00:49:40 <lambdabot>   [[],[4],[3],[3,4],[2],[2,4],[2,3],[2,3,4],[1],[1,4],[1,3],[1,3,4],[1,2],[1,...
00:49:43 <Cale> In the IO monad, this takes a list of IO actions, and glues them together into a single IO action which, when executed, runs each of the actions from the list, and collects a list of their results.
00:50:07 <Cale> In the list monad, sequence gives the Cartesian product -- all ways to pick one element from each of the list of lists.
00:50:18 <Cale> In a parsing monad, it would give the concatenation of parsers.
00:51:01 <Cale> > sequence [[1,2,3],[4,5],[6,7,8]]
00:51:02 <lambdabot>   [[1,4,6],[1,4,7],[1,4,8],[1,5,6],[1,5,7],[1,5,8],[2,4,6],[2,4,7],[2,4,8],[2...
00:51:17 <Cale> > do x <- [1,2,3]; y <- [4,5]; z <- [6,7,8]; return [x,y,z]
00:51:18 <lambdabot>   [[1,4,6],[1,4,7],[1,4,8],[1,5,6],[1,5,7],[1,5,8],[2,4,6],[2,4,7],[2,4,8],[2...
00:52:29 <Cale> rajeshsr: I go into some more detail about that view of things here: http://www.haskell.org/haskellwiki/Monads_as_Computation
00:53:11 <ddarius> If you were writing a denotational semantics for a (potentially) effectful programming language, the semantics of non-recursive let would be (>>=), i.e. eval [[let x = M in N]] = eval [[M]] >>= \x -> eval [[N]].  This is why (>>=) is called "bind."
00:53:31 <rajeshsr> Cale, ok, thanks!
00:54:05 <Cale> rajeshsr: Let us know if you still have questions. At a certain point, you just have to play around, and you'll get the idea pretty quickly.
00:54:34 <rajeshsr> Cale, sure! Thanks!
00:55:00 <mjrosenb> does ghc have a tracing mode rather than a polling mode for profiling?
00:55:00 <lambdabot> mjrosenb: You have 1 new message. '/msg lambdabot @messages' to read it.
00:56:38 <rajeshsr> One question i have is related to seq. So, when I was reading about monads and viewing it as imposing order of evaluation (which was a misconception and got corrected only now) I began to think of monads as a sort of "seq".
00:56:56 <copumpkin> ah, nope
00:57:02 <rajeshsr> But I found that my understanding of seq is flawed too!
00:57:08 <ezyang> seq is a much lower level operation
00:57:10 <copumpkin> seq is a misnomer
00:57:11 <rajeshsr> Foex example, on trying: seq (map (*10) [1..])  (1)
00:57:37 <copumpkin> that will only evaluate the first cons cell :) it won't even multiply 1 * 10
00:58:05 <rajeshsr> I thought it will go into infinite loop, but it isn't! So, what it means by evaluating the first argument?
00:58:13 <rajeshsr> copumpkin, cons cell?!
00:58:24 <copumpkin> lists are built up out of two bits
00:58:26 <copumpkin> (:) and []
00:58:34 <rajeshsr> do we have any sort of abstract machine architecture for haskell?
00:58:34 <copumpkin> [1,2,3] === 1 : 2 : 3 : []
00:58:48 <copumpkin> 1 : 2 : 3 : [] === 1 : (2 : (3 : []))
00:58:50 <rajeshsr> yeah, that i know...
00:59:05 <copumpkin> that seq is evaluating the : between 1 and ( :)
01:00:07 <copumpkin> what kind of abstract machine?
01:00:36 <olsner> the sequencing induced from seq and the sequencing you get from (some!) monads are completely different things, really
01:00:55 <rajeshsr> copumpkin, well, i don't see what has consing to do here...
01:01:08 <rajeshsr> olsner, yeah i get that. My question is: http://www.zvon.org/other/haskell/Outputprelude/seq_f.html
01:01:17 <rajeshsr> says the first argument is evaluated
01:01:18 <copumpkin> your map (*10) [1..] is building a list, no?
01:01:27 <rajeshsr> but nothing like that happens..
01:01:33 <rajeshsr> copumpkin, yeah
01:01:39 <copumpkin> it's evaluated to something called weak head normal form
01:01:48 <copumpkin> from the point of view of haskell
01:02:02 <copumpkin> when you pattern match on that [1..], you'd write (x:xs), right?
01:02:06 <rajeshsr> copumpkin, oh! So where can I read about that?
01:02:11 <mjrosenb> copumpkin: hnf, not whnf?
01:02:13 <rajeshsr> yeah
01:02:26 <copumpkin> mjrosenb: it can't see through lambdas?
01:02:33 <olsner> rajeshsr: oh, I think that's a bit unclear writing on that link really... it should at least point to some more docs about exactly what seq evaluates
01:02:54 <copumpkin> rajeshsr: so as far as evaluation is concerned, it's pattern matched on the main constructor, and doesn't care about x or xs
01:02:58 <copumpkin> rajeshsr: that's all seq does
01:03:22 <mjrosenb> copumpkin: (\x -> 1+ trace "foobar" 2) should not print anything
01:03:53 <copumpkin> hmm
01:03:53 <olsner> http://haskell.org/ghc/docs/latest/html/libraries/base-4.2.0.0/Prelude.html#v:seq says "evaluates to hnf"
01:04:33 <rajeshsr> olsner, thanks!
01:04:46 <rajeshsr> so where can i read about haed normal form?
01:05:12 <rajeshsr> i guess what copumpkin has said is a lot to do with such a representation..
01:05:40 <mjrosenb> Prelude Debug.Trace> (\x -> 1+trace "foo" 2) `seq` 5
01:05:40 <mjrosenb> 5
01:05:42 <lilrayray> hey all, Im new to haskell (and functional programming in general) I am trying to do a little practice by writing a prime-number checker... I am getting an error that complains about types ("Could not deduce (RealFrac a) from the context (Integral a)").  Ive tried changing the function type declaration, but that didnt help. Here's my code: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23298#a23298
01:05:51 <copumpkin> mjrosenb: and that makes it weak, doesn't it?
01:06:05 <mjrosenb> i believe so.
01:06:08 <olsner> hmm, wikibooks says something like haskell only really having weak hnf
01:06:14 <copumpkin> mjrosenb: so what's the objection? :P
01:06:46 <copumpkin> olsner: I'd agree with that
01:06:55 <olsner> http://en.wikibooks.org/wiki/Haskell/Laziness#Thunks_and_Weak_head_normal_form looks useful
01:06:58 <copumpkin> (about hnf not existing in haskell)
01:07:24 <rajeshsr> copumpkin, olsner, thanks!
01:07:28 <mjrosenb> right, so is there anything that will profile by tracing, not by polling?
01:07:31 <copumpkin> np :)
01:07:45 <arw_> > round (5 / 2)
01:07:46 <lambdabot>   2
01:08:27 <damd> :t round
01:08:28 <lambdabot> forall a b. (RealFrac a, Integral b) => a -> b
01:09:14 <arw_> :t fromRealFrac
01:09:15 <lambdabot> Not in scope: `fromRealFrac'
01:10:57 <ivanm> preflex: seen sinelaw
01:10:58 <preflex>  sinelaw was last seen on #haskell 11 hours, 53 minutes and 19 seconds ago, saying: ....problem :D
01:11:08 <copumpkin> ivanm: heh
01:11:16 <ivanm> @slap copumpkin
01:11:16 <lambdabot> *SMACK*, *SLAM*, take that copumpkin!
01:11:18 <arw_> > 5 `div` 2
01:11:19 <lambdabot>   2
01:11:31 <ivanm> @ask sinelaw hmmm... I wonder if it's possible to use gloss to render graphs that have been augmented via graphviz... >_>
01:11:31 <lambdabot> Consider it noted.
01:11:33 <arw_> :t div
01:11:34 <lambdabot> forall a. (Integral a) => a -> a -> a
01:11:39 <arw_> lilrayray: try div :)
01:12:31 <lilrayray> arw_: ahhh thanks... that doesnt seem very logical/"pretty"... why was it implemented this way?
01:12:46 <copumpkin> sure it does
01:13:10 <arw_> lilrayray: integer division is simply a totally different operation from real/rational division
01:13:54 <copumpkin> psykotic: you there?
01:14:02 <psykotic> copumpkin: yup
01:14:19 <lilrayray> arw_: ahh, ok... I guess I am still in imperative-land =/
01:14:40 <copumpkin> psykotic: sorry to bug, but you posted two things I found fascinating to reddit and I was wondering if you'd developed either of them any more... the matrix zipper and the bayes' law as relation inversion over a topos
01:14:51 <copumpkin> (a while ago)
01:14:57 <psykotic> copumpkin: oh right that
01:15:16 <psykotic> i finished the zipper stuff to my satisfaction, but i need to spend more time on the bayes topos
01:15:19 <arw_> lilrayray: but you are somewhat right, i also did not see the problem at first, many languages just take 'div' to be the same as '/', only doing magic things with different types of arguments.
01:15:39 <psykotic> although i recently found another use of a matrix-like zipper...
01:15:40 <arw_> lilrayray: but that does really lead to bugs sometimes.
01:16:00 <copumpkin> psykotic: is there anything else you know of out there dealing with anything related to the bayes topos? I'd love to see some deeper treatment of probablity as logic in CT
01:16:21 <olsner> basic did iirc use \ for integer division (or divide-and-truncate for floats) and / for floating-point division (converting arguments to floats)
01:16:39 <damd> basic also used goto
01:16:40 <psykotic> copumpkin: voevodsky (the guy who got the fields medal for his development of homotopy theory in algebraic geometry, etc) has been working on practical categorical foundations for probability theory, iirc
01:17:01 <psykotic> i saw some slides from last year that looked similar in some ways
01:17:03 <olsner> damd: pretty sure goto has been done in haskell too :P
01:17:08 <copumpkin> oh, interesting
01:17:10 <copumpkin> I'll look him up
01:17:15 <psykotic> but i couldn't find anything else written own by more in greater detail, alas
01:17:18 <psykotic> *down
01:17:24 <damd> olsner: only emulated though :P
01:18:05 <olsner> hmm, yeah, but in some sense it's always emulated, except sometimes it's emulated by lower-level gotos
01:18:30 <Jafet> Would goto be a monad...?
01:18:43 <copumpkin> you could build it with Cont
01:18:50 <copumpkin> goto itself wouldn't be a monad though
01:19:13 <damd> olsner: i wouldn't be at all surprised if basic compiled GOTO to some really simple sort of JSR
01:19:39 <olsner> sounds like something you could do nicely with a recursive monad
01:19:46 <Jafet> How about come from?
01:20:16 <olsner> hmm, might not be any harder than goto
01:20:28 <olsner> just flip the meaning of "create label" and "goto" :P
01:20:58 <Jafet> It might be nondeterministic, depending on how you define the semantics.
01:21:13 <olsner> yeah, or parallel
01:21:23 <olsner> intercal has explored this area to some depth, I believe :P
01:21:50 <pastorn> @pl \x -> when (p x) (f x)
01:21:50 <lambdabot> liftM2 when p f
01:21:55 <pastorn> right...
01:22:02 <copumpkin> psykotic: what was the other use for the matrix-like zipper by the way?
01:22:14 <Jafet> If all else fails, you could implement it by running it in gdb and setting break points.
01:22:15 <ddarius> pastorn: Or when <$> p <*> f
01:22:28 <pastorn> ddarius: who needs applicative?
01:22:34 <pastorn> DO NOT WANT
01:23:08 <ddarius> pastorn: Fine, when <$> p `ap` f
01:23:18 <copumpkin> lol
01:23:22 <pastorn> @type (<$>)
01:23:23 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
01:23:32 <copumpkin> when `liftM` p `ap` f
01:23:34 <pastorn> but it's fmap!
01:23:34 <copumpkin> now STFU
01:23:49 <copumpkin> :P
01:24:17 <pastorn> :~(
01:24:46 <pastorn> copumpkin: i finished an awesome feauter for my bot :0
01:24:46 <copumpkin> :)
01:24:47 <olsner> copumpkin: hehe, wrong precedences
01:24:48 <pastorn> :)
01:25:00 <pastorn> copumpkin: come to #bottest @ efnet and i'll show you :)
01:25:01 <copumpkin> olsner: then set better ones in your file :P
01:25:01 <olsner> you need a paren around p`ap`f
01:25:13 <copumpkin> pastorn: ugh, too lazy to connect to another network
01:25:29 <copumpkin> you gonna kick me?
01:25:44 <pastorn> nonono
01:31:52 <mjrosenb> also, their definition of CAF is odd to say the least.
01:32:37 <olsner> mjrosenb: whose?
01:34:27 <damd> copumpkin: are you a cop named umpkin
01:34:54 <copumpkin> nah I lost my BL and like cops
01:35:19 <rumpelstiltskin`> 10:34 *** 433 rumpelstiltskin Nickname is already in use.
01:35:22 <rumpelstiltskin`> ...
01:35:45 <mjrosenb> olsner: ghc's
01:36:55 <Veinor> damd: are you registered with nickserv?
01:37:03 <Veinor> oh wait, nevermind
01:37:05 <Veinor> I'm silly.
01:37:07 <damd> hehe
01:42:39 <pastorn> Jonno_FTW: yo!
01:46:17 <copumpkin> sleep time!
01:47:03 <Jonno_FTW> yo pastorn
01:47:22 <Jonno_FTW> i totally got side tracked with sleep and didn't finish reading that article
01:47:55 <pastorn> hehe
01:48:48 <Jonno_FTW> good thing it's a long weekend, we get a public holiday for a horse race,
01:48:55 <pastorn> whut?
01:49:01 <pastorn> where do you live?
01:49:29 <Jonno_FTW> adelaide, australia
01:49:44 <pastorn> what's the horse race about?
01:49:54 <Jonno_FTW> it's the adelaide cup
01:50:05 <damd> any relation to camptown?
01:50:11 <Jonno_FTW> nope
01:50:42 <Jonno_FTW> today i was trying some CGI stuff
01:50:50 <pastorn> ok?
01:51:00 <Jonno_FTW> is all good
01:51:13 <pastorn> cool
01:51:27 <Jonno_FTW> you can expect a new IRC bot in 2-3 weeks
01:51:38 <pastorn> Jonno_FTW: dude... read that paper
01:51:50 <pastorn> then you can write a parser in parsec
01:51:52 <adu> IRC bot?
01:52:00 <pastorn> and then you can have it ready in a few days :)
01:52:55 <Jonno_FTW> but i totally have university now
01:53:42 <Jonno_FTW> and my first computer science practical on tuesday
01:56:05 <malosh> Hi. This was missing, am I right ? http://www.lama.univ-savoie.fr/~meunier/darcs/Data-Rope/dist/doc/html/Data-Rope/Data-Rope.html
02:02:36 <Cale> malosh: Interesting. Might it have a fast implementation of splitAt as well?
02:05:55 <malosh> Cale : give me five minutes ;-)
02:08:58 <Zeiris_> Can I initialize a bytestring via s = "abcd"?
02:09:13 <damd> All of us have seen symptoms of the violation of this requirement. For instance, the vi editor on most UNIX(TM) systems is unusable on many text files due to a line length limit.
02:09:50 <ulfdoz> no problem, cmd.exe's line-length-limit ist harder.
02:11:36 <Veinor> Zeiris_: you need s = pack "abcd"
02:11:59 <Zeiris_> Thanks!
02:12:22 <Veinor> no problem.
02:12:57 <malosh> Cale : you got it !
02:13:04 <Cale> malosh: :)
02:13:39 <malosh> damd : now it is up to you to write an editor that uses ropes !
02:13:58 <malosh> Challenge : how to do it using the incremental parsing used in yi ?
02:13:59 <damd> malosh: maybe yi has done it
02:14:31 <Saizan> malosh: what's i0?
02:14:56 <malosh> a trick for referential transparency
02:15:11 <damd> tricks are for kids
02:15:23 <malosh> but referential transparency is not
02:15:37 <damd> referential transparency is serious business
02:16:19 <malosh> Zeiris_ : btw, you can use -XOverloadedStrings in ghc. Data.ByteString.Char8 has an instance of IsString
02:16:27 <malosh> Zeiris_ : and Data.Rope too :-)
02:17:17 <malosh> damd : for having used it, I really do not believe that yi has got this kind of structure
02:18:08 <damd> malosh: for having written code for it, i have no idea really
02:18:24 <damd> it seems to have Data.Rope as a dependency at least
02:18:55 <damd> actually, it seems they have their own version of Data.Rope in the yi repo
02:19:02 <damd> and also something called ByteRope
02:19:25 <malosh> It's quite weird then that it is so slow
02:19:40 <damd> much of it depends on the mode
02:19:56 <damd> e.g. the javascript mode which is now not even included by default
02:20:03 <damd> coincidentally, i wrote that one
02:21:39 <Saizan> the repo is still http://code.haskell.org/yi ?
02:21:51 <damd> looks like it
02:23:45 <rajeshsr> getChar >>= \x -> return 1 why is getChar evaluated, when its results is not going to be used at all? An explanation based on thunks will be good!
02:24:05 <damd> getChar has side effects
02:24:27 <malosh> rajeshr : have a look at http://www.haskell.org/ghc/docs/latest/html/libraries/base-4.2.0.0/System-IO-Unsafe.html#v%3AunsafeInterleaveIO
02:26:16 <sepp2k> rajeshsr: For the same reason that putStrLn will be evaluated even if its result is never used (which it will never be as its result is unit)
02:26:54 <Twey> rajeshsr: Evaluation ≠ execution
02:27:13 <Twey> Both sides of that expression are evaluated, because ‘main’ is evaluated
02:27:28 <rajeshsr> malosh, you mean that getChar is a sort of safe I/O? Well, am looking at an explanation in terms of this: http://en.wikibooks.org/wiki/Haskell/Laziness#Thunks_and_Weak_head_normal_form
02:27:30 <Twey> And the result of the bind is executed, because it's part of main
02:27:41 <Twey> rajeshsr: Laziness applies only to evaluation, not execution
02:27:58 <malosh> rajeshsr : it is not safe at all, it _is_ a side effect
02:28:04 <Saizan> rajeshsr: >>= chains the side effects of the two arguments ensuring the order, evaluation of the results is unrelated to this
02:28:26 <Saizan> it's safe in the sense that it doesn't break referential transparency
02:28:41 <rajeshsr> yeah, I get it all! Am simple looking to see how getChar fits into the semantics of lazy evaluation as defined in the links over there..
02:29:14 <Saizan> the side effects of getChar are unrelated to evaluation
02:29:47 <rajeshsr> Saizan, you mean? how it is unrelated?
02:29:53 <Saizan> when you evaluate getChar you just evaluate it as the description of some side-effectful computation
02:30:13 <malosh> IO actions are not "evaluated" in the same sense as pure values. It is necessarily chained in the IO monad of your main function
02:30:29 <Saizan> rajeshsr: you could think of the value of getChar as the code for some program in C
02:30:42 <Twey> > getChar
02:30:43 <lambdabot>   <IO Char>
02:30:47 <Twey> ^ evaluation of getChar
02:31:07 <Saizan> rajeshsr: producing a piece of code is different from executing that piece of code
02:32:00 <Saizan> you glue this pieces with >>= and other combinators, to form a main, which you give to the runtime system
02:32:21 <Saizan> which at that point will execute the given code
02:32:59 <rajeshsr> yeah, i can get all of that. My question is how this behavior fits into lazy evaluation and thunks as defined here: http://en.wikibooks.org/wiki/Haskell/Laziness#Thunks_and_Weak_head_normal_form
02:33:16 <Twey> rajeshsr: It doesn't.  It's not even relevant.
02:33:22 <rajeshsr> something should force getChar to get evaluated which in turn triggers its execution.
02:33:28 <Twey> Lazy evaluation applies to *evaluation*, not *execution*.
02:33:29 <Saizan> no
02:33:33 <Twey> Evaluation does not trigger execution
02:33:34 <Saizan> it's the other way around
02:34:01 <Saizan> the runtime system has to evaluate the IO action you give it before it can execute it
02:35:45 <rajeshsr> hmm, well the line between evaluation and execution in this context isn't clear. getChar executes some I/O action and evaluates to some value which is IO Char.
02:35:58 <rajeshsr> what is wrong with this statement?
02:36:04 <Saizan> the first part
02:36:17 <Saizan> "getChar executes some I/O action"
02:36:29 <olsner> getChar doesn't execute anything, something else executes it
02:36:30 <rajeshsr> Saizan, ok, then how will you call that?
02:36:54 <Saizan> getChar is an inhert description of the I/O effects that will be executed
02:36:57 <Saizan> it's a recipe
02:37:13 <dons> its pretty simple. to evaluate getChar we perform a side effect and return a Char. that's it. you're over-thinking this.
02:37:34 <rajeshsr> dons, yeah! thats waht even i said i think..
02:37:34 <Saizan> argh, dons, you're ruining it :\
02:37:57 <dons> read the awkward squad.
02:38:02 <Zeiris_> Argh, is there a way to get Data.Char functions to work on Word8 as well?
02:38:09 <Saizan> dons: if we use that model then there's no referential transparency
02:38:13 <dons> http://research.microsoft.com/en-us/um/people/simonpj/papers/marktoberdorf/mark.pdf
02:38:26 <dons> Saizan: effect are part of the semantics
02:38:46 <dons> you can also use the 'construct a model and pass to the rts' semantics
02:38:48 <Saizan> yeah, the problem is where you put them :)
02:38:51 <dons> that getChar describes an action
02:39:05 <dons> that is, the effect to do, and how to get  the result back
02:39:18 <dons> but that's level 2 understanding, imo.
02:39:49 <Saizan> if you say that "to evaluate getChar we perform a side effect and return a Char"
02:39:56 <dons> rajeshsr: btw, this is the same in any language. this is how you understand what a "statement" is in any language
02:40:15 <dons>  getChar -?-> return Char
02:40:28 <Saizan> then why "main = getChar `seq` return ()" doesn't get a char from stdin?
02:40:49 <dons> getChar :: World -> (Char, World)
02:40:57 <dons> and seq doesn't having meaning on functions
02:41:03 <dons> hence the -?-> arrow
02:41:13 <rajeshsr> dons, i have no problem with this description. My question is: getChar >>= \x -> return 1 results in getChar getting executed. All I want to know is why? Does it violate the semantics of lazy evaluation? If not, then why?
02:41:30 <dons> the World is being passed as an argument
02:41:36 <dons> and you get a new World as the result.
02:41:52 <dons> that's how we preserve the correct data dependencies, and all the same semantics work
02:42:14 <rajeshsr> dons, ha! yes, so we still use the return value in the form of Worlds!
02:42:16 <rajeshsr> right!
02:42:27 <dons> yep
02:42:32 <malosh> if you declare a=getChar>>= \x->return 1 as a toplevel value, and never use it, it won't be evaluated. That's what you'd call lazy. To use this value you must chain it in other IO actions
02:42:48 <dons> you have to give it a World argument to run it
02:42:52 <dons> since its a function
02:43:14 <dons> IO a == World -> (World, a), literally
02:43:42 <Saizan> we're using an implementation hack to describe a semantic
02:44:17 <dons> i find the world passing idea very simple and *easy to explain*, to describe how all the right ordering is preserved
02:44:27 <dons> but maybe i'm outside the mainstream here.
02:45:02 <dons> the 'construct a model and pass to the rts' is a bit abstract for easy explanation, i think
02:45:46 <Saizan> it's an encoding, and assumes there's a magical World type
02:46:02 <dons> yes, of course. its a particular implementation of the required semantics
02:46:15 <dons> a way to instantiate getChar -?-> return Char
02:46:54 <dons> bed time.
02:46:56 <dons> night all!
02:48:19 <rajeshsr> Saizan, so how will you decribe this in a more generic way?
02:53:18 <Saizan> how i tried to do before :)
02:53:23 <olsner> a different way to see it is that a full program (i.e. main :: IO ()) is really a function World -> ((),World) (or World -> World, if you ignore the value) - to see what the final World value is, you need to evaluate all the IO actions in the right sequence
02:54:53 <Saizan> a major problem with that is "how come we can observe all the intermediate World states?"
02:55:36 <Saizan> how can you fit concurrency into this?
02:56:39 <Saizan> though maybe it's fine for a starting point
02:56:56 <Saizan> but the distinction between execution and evaluation is useful for other monads too
02:57:37 <olsner> feels a bit like just stringing a bunch of unsafePerformIO's together with seq, rather than a proper model of IO
02:58:38 <Saizan> yeah
02:59:35 <Saizan> another example is that "loop = loop" and "loop = getChar >> loop" are extensionally the same function but they are quite different
02:59:59 <rajeshsr> Saizan, am interested to know about the difference between execution and evaluation. May be you can use a list monad as an example for that..
03:01:51 <Veinor> Saizan: well, the former has type a, while the latter has type IO a :P
03:02:05 <Saizan> Veinor: add a type annotation :P
03:06:16 <olsner> Saizan: wouldn't the World part of the first expression be bottom, while the second would be the fixpoint of getChar's "world transformation"?
03:07:04 <Saizan> olsner: assuming getChar is strict in the World argument it's still bottom
03:09:03 <Orphi> @seen dcoutts
03:09:03 <lambdabot> Unknown command, try @list
03:09:18 <Orphi> @list
03:09:19 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
03:09:22 <Saizan> rajeshsr: even in this IO a == World -> (World, a) there's a difference between evaluation and execution btw, evaluation is when you reduce a term of that type to an actual function value, execution is when you give it an argument of type World
03:09:29 <Saizan> preflex: seen dcoutts
03:09:30 <preflex>  dcoutts was last seen on #ghc 27 days, 15 hours, 47 minutes and 27 seconds ago, saying: ok, ta
03:09:30 <Orphi> ...
03:10:21 <Saizan> rajeshsr: the weird thing is that applying a function to an argument or even forcing its result, shouldn't produce any side-effects
03:10:24 <Orphi> I can't get gtk2hs to build with GHC 6.12.1. Is that normal?
03:10:32 <olsner> it's weird how applying a function to World makes stuff magically happen in the real world though
03:10:43 <ivanm> Orphi: known bug
03:10:48 <ivanm> fixed in repo, not in a release
03:10:54 <Orphi> ah, ok.
03:11:00 <rajeshsr> Saizan, hmm! ok, going by that definition execution precedes evaluation.
03:11:00 <Orphi> so long as it's not just me then :)
03:11:11 <ivanm> Orphi: 6.12's package format changed; whilst cabal takes care of this for most packages gtk2hs is as yet un-cabalisable
03:11:15 <Saizan> rajeshsr: not really
03:11:23 <rajeshsr> So, how does that understanding affects monads and explain about getChar?
03:11:28 <ivanm> and thus it has to do this manually, which menas tweaking for every new release of ghc
03:11:33 <Orphi> ivanm: so where's the repo?
03:11:51 <Saizan> rajeshsr: before you can force the result of a function application you've to evaluate the function.
03:11:58 <ivanm> @where gtk2hs
03:11:58 <lambdabot> http://haskell.org/gtk2hs/
03:12:08 <olsner> maybe you're supposed to pretend that the RTS actually feeds the entire universe into your haskell function, replacing it when the new universe is known
03:12:42 <Saizan> evaluate (f $ x) = apply (evaluate f) (evaluate x)
03:12:53 <Saizan> in an hypotetical interpreter :)
03:13:00 <Orphi> so darcs get http://code.haskell.org/ghc2hs/ should do it?
03:13:04 <olsner> maybe you just see the result of the code having been optimized into in-place mutation on the world
03:13:19 * hackagebot hmk 0.9.6 - A make alternative based on Plan9's mk.  http://hackage.haskell.org/package/hmk-0.9.6 (MathieuBoespflug)
03:13:24 <krey> does anyone feel competent with reduction trees/graphs?
03:14:07 <Phyx-> can you define your own unirary operators in Haskell?
03:14:22 <rajeshsr> Saizan, hmm, ok!
03:14:22 <Orphi> Phyx: I believe the answer is no.
03:14:57 <Phyx-> Orphi: ok, thanks
03:16:05 <Saizan> rajeshsr: using this IO a == World -> (World, a) the explanation of your getChar example is still that getChar side effects get performed because getChar gets executed, it's just that execution means something fairly weird here
03:16:24 <Saizan> tied back to evaluation
03:17:44 <Saizan> i'm not doing so much of a good job at explaining this, the right way would be to build a simple interpreter
03:17:51 <mjrosenb> Phyx-: what do you mean by unary operator?
03:18:13 <mjrosenb> Phyx-: and how would this be different from a function/
03:18:20 <mjrosenb> s:/:?:
03:18:32 <rajeshsr> Saizan, build an interpreter? you mean a haskell interpreter for understanding things under hoods?
03:18:55 <Saizan> no, to understand over the hood :)
03:19:09 * mjrosenb is currently working on an interpreter for a language that looks sort of like haskell
03:19:13 <olsner> this is why I like the building-a-model concept of IO, you can separate the magic from the purity much easier then, IMO
03:19:34 <Saizan> interpreters in a functional style are a very clean way to give semantics
03:20:26 <rajeshsr> haha! :) Would love to! Well, I guess haskell is really very complicated language! Am yet to write some non-trivial program in haskell, so many advanced concepts to understand!!
03:20:35 * Orphi is still waiting for the OpenSUSE VM to finish the bootstrap sequence...
03:21:05 <olsner> I think a lot of the complexity in haskell is just very cleverly hidden simplicity :P
03:21:10 <mjrosenb> Saizan: until you attempt to have call by name evaluation semantics
03:21:29 <mjrosenb> err
03:21:38 <mjrosenb> call by name is not the phrase i am looking for
03:21:47 <Saizan> call by need?
03:22:02 <mjrosenb> that sounds more correct
03:22:02 <rajeshsr> olsner, yeah! but haskell is worth leraning purely for the intellectual pleasure it offers, at least for me! :)
03:22:17 <Saizan> rajeshsr: in the end it's mostly that haskell is fairly more explicit about that's going on :)
03:22:43 <mjrosenb> (\(x,y) -> (x+x)) (1+2,3+4)
03:22:55 <mjrosenb> Saizan: the method that will evaluate 1+2 once and 3+4 0 times
03:22:56 <Saizan> while being less about _how_ it is going on :D
03:23:07 <olsner> rajeshsr: very true :) it's an enlightening experience
03:23:07 <Saizan> mjrosenb: yeah, call by need
03:23:35 <mjrosenb> updating references in haskell is kind of annoying
03:23:41 <rajeshsr> hmm, yeah! when writing purely mathematical or simple things it is so clear, but when doing something a bit more complicated like parse input, change states, it gets a lot complicated!
03:23:50 <mjrosenb> and i refuse to let haskell's laziness do the job for me :-p
03:23:53 <Saizan> mjrosenb: seen this paper? http://web.cecs.pdx.edu/~mpj/pubs/modinterp.html
03:24:16 <mjrosenb> Saizan: not yet.
03:24:29 <mjrosenb> Saizan: right now, i am fighting with the parser
03:24:41 <olsner> rajeshsr: at the very least it gets *different*, it's harder to judge the complicatedness
03:25:05 <mjrosenb> olsner: complicatedness is a rather complex word.
03:25:56 <McManiaC> what easy-to-use configuration format do you guys prefer? json? yaml?
03:26:36 <mjrosenb> McManiaC: text.
03:26:46 <arw_> McManiaC: json or apache-like. yaml sucks big time.
03:27:05 <McManiaC> mjrosenb: well text is not exactly easy to use ;)
03:27:18 <mjrosenb> McManiaC: it is for me (the end user)
03:27:27 <rajeshsr> olsner, hmm, yeah, it can be called different! But I guess complicated is also correct! Look at the number of concepts and codes involved in writing a simple sudoku solver (given in haskell wiki) you could code it in < 25 lines in C++ or python..
03:27:47 <arw_> McManiaC: yaml generates tons of headaches because of the significant and brain-damaged whitespace rules which end-users never understand.
03:28:06 <McManiaC> okay
03:28:26 <Cale> rajeshsr: If you're referring to the one at the top, I wrote it mostly to illustrate concepts rather than to solve Sudoku :)
03:29:23 <Orphi> I take it everybody hates XML then?
03:29:52 <McManiaC> yup
03:30:08 <mjrosenb> rajeshsr: i would argue that you could write a sudoku solver in haskell much more concisely than in C++ (and most likely python)
03:30:23 <Orphi> why's that then?
03:30:27 <Orphi> because it's easy to parse?
03:30:33 <Orphi> because many libraries already support it?
03:30:40 <Orphi> because there's lots of tool support?
03:30:46 <olsner> yeah, too successful, gotta be killed
03:31:04 <Orphi> heh. this from the language that vowed to "avoid success at all costs" ;)
03:31:17 <McManiaC> arw_: which package do you use? hjson? or json-b?
03:31:39 <Orphi> this proves it; you gotta have a sense of humour to do FP :)
03:31:43 <olsner> Orphi: yep, it's the new thing, we're extending it beyond haskell now :)
03:32:06 <Orphi> olsner: So when do we kill C?
03:33:05 <arw_> McManiaC: Text.JSON. but i really don't care, both do what i want.
03:33:07 <olsner> Orphi: killing C would be a success for haskell, so we can't do that
03:33:23 * Orphi lols
03:33:25 <pastorn> @pl \xs ys f -> zipWithM f xs ys
03:33:25 <lambdabot> flip . flip zipWithM
03:33:52 <Saizan> Orphi: XML is too horrible to be used by humans
03:34:03 <Saizan> Orphi: and for machines it's too slow to parse
03:34:19 <McManiaC> arw_: okay thx
03:34:20 * mjrosenb is of the opinion that C is not and should not die
03:34:26 <Orphi> Saizan: Well, I write HTML by hand, so...
03:34:56 <Orphi> I will conceed, however, that MathML is horrid.
03:35:22 <mjrosenb> Orphi: yes, but 1,000 lines of plain text is much nice than 10,000 lines of XML.
03:36:00 <Orphi> it could be worse - it could be TeX! :P
03:36:30 <McManiaC> theres no reason to write html by hand
03:36:38 <arw_> xml is ok for some things. if you really have a dtd and if you really exchange data between diverse software packages.
03:36:38 <McManiaC> pandoc <3
03:36:52 <arw_> but as a config file format, xml is not really a good idea
03:36:55 <mjrosenb> <3 latex
03:37:01 <Orphi> McManiaC: Last time I checked, you can't do very much with Pandoc.
03:37:17 <McManiaC> and I never saw any program using latex in their config file :>
03:37:31 <Saizan> nor html
03:37:34 <Orphi> McManiaC: You haven't seen initex then? ;)
03:37:44 <McManiaC> nope?
03:40:00 <Orphi> XML is quite verbose, but some programs apparently use Lisp... That's gotta be pretty scary.
03:41:32 <Orphi> What does JSON look like anyway?
03:41:47 <Saizan> a lisp-like with keyword arguments and optional layout would be nice spot
03:42:01 <Saizan> oh, json is not that far from that..
03:42:09 <arw_> http://json.org/
03:43:06 <Saizan> meh, there isn't a single example on that page :)
03:43:16 <stevenmarky> JSON looks like [ "hello", "pies", { "one" : 1232, "two" : "three" } ]
03:43:18 <Orphi> exactly.
03:44:11 <Orphi> and what does that *mean*, exactly?
03:44:59 <Saizan> an array, containing 3 values, the third being a dictionary with two entries
03:45:11 <Orphi> uh, ok.
03:45:38 <Orphi> so it encodes data, but doesn't it provide some way to label what the data is?
03:45:54 <voker57> label?
03:45:59 <Saizan> dictionary keys can be used for that
03:46:02 * maltem wonders whether a configuration format should optimally be typed or untyped
03:46:16 <Saizan> http://en.wikipedia.org/wiki/JSON#Data_types.2C_syntax_and_example <- e.g.
03:46:32 <arw_> Orphi: there are no types in that sense. usually one uses the key/value syntax for that.
03:46:36 <Orphi> right. so a config file would be a dictionary, with setting names as keys, and some appropriate structure as values.
03:46:58 <arw_> Orphi: like {"user" : "orphi", "password" : "12345"}
03:47:28 <Orphi> right. but the values can be of any suitable type?
03:47:46 <arw_> correct.
03:47:56 <Saizan> yeah, coming from javascript
03:48:09 <arw_> writing "user" : [1, 2, 3, 4, 5] would be valid
03:49:11 <Saizan> typechecking is often done while you transform the parsed json to a more native datatype
03:49:39 <Orphi> so you can do something like {"login" : {"user" : "orphi", password : "teadybear"}, "port" : 75, "encryption" : {"algorithm" : "RC6", "key" : "5834728"}}
03:49:50 <Saizan> yup
03:49:58 <Orphi> OK, that doesn't sound too bad.
03:50:27 <Orphi> damnit, I can't compile darcs :(
03:50:34 <arw_> you can do anything. that is good in that it gives you lots of freedom, and its bad because you will need to do some kind of typechecking yourself.
03:51:03 <arw_> like checking that your username is really a string and the port is really an int16.
03:51:26 <Saizan> it shouldn't be hard to provide a convenient haskell library for that
03:52:20 <Orphi> configure: error: curses headers could not be found, so this package cannot be built
03:52:21 <Saizan> where you give a declarative description of the configuration and you can use it to parse from json to a more typed representation
03:52:34 <Orphi> curses, indeed!
03:52:45 <Saizan> Orphi: do you have the C library installed?
03:52:53 <Orphi> Saizan: No idea.
03:53:45 <Orphi> is curses related to ncurses, or is that unrelated?
03:53:59 <Saizan> it is related i think
03:54:18 <Saizan> btw, how are you trying to compile it?
03:54:41 <Orphi> I have package ncurses-devel installed.
03:54:59 <Orphi> I did cabal install darcs, but it's tripping over terminfo.
03:56:18 <Orphi> stupidly enough, SUSE doesn't have a package for Darcs. :(
03:56:27 <Saizan> you could try -f-terminfo
03:56:34 <tensorpudding> people still use SUSE?
03:57:07 <Orphi> OK, I installed cdk-devel, and now it's happy...
03:57:34 <Orphi> tensorpudding: Why, what's wrong with SUSE?
03:59:26 <Orphi> ...and compiling Darcs crashed out due to missing Curl headers. >_<
03:59:38 <Orphi> Isn't it supposed to check that in the configure stage?
04:01:21 <Saizan> it is
04:01:57 <Orphi> ah, I think the compiler messages were for compiling Setup.lhs
04:02:02 <Orphi> (why you'd do that I'm not sure.)
04:02:40 <Saizan> to allow custom build systems, which usually are just hooking into the default one
04:02:43 <Orphi> 139 modules? man, this is big...
04:02:58 <Orphi> Usually I use runhaskell to run Setup.lhs
04:03:44 <Saizan> that works less well if it has to load other modules from the source tree
04:04:00 <Orphi> mmm, ok.
04:04:30 <Orphi> then again, I only ever build trivial packages from source; the big/useful ones usually don't work on Windows.
04:05:21 <Saizan> for packages that use the Simple build system cabal-install skips the Setup.lhs script completely :)
04:05:35 <Orphi> heh, right.
04:05:56 <Orphi> it's kind of redundant having all these multiple ways to do the same thing, eh?
04:06:43 <Orphi> OK, eating time.
04:06:51 <Orphi> I wonder if there's a way of setting this thing as away?
04:06:59 * Orphi prods it.
04:11:58 <McManiaC> arw_: what the Bool used for in the JSRational?
04:12:13 <McManiaC> 's
04:13:57 <Veinor> Haskell lists are linked lists, right?
04:14:39 <Twey> Singly-, yes
04:14:56 <Veinor> right, that makes sense
04:15:12 <Jonno_FTW> you know linked lists are patented?
04:15:42 <Twey> Veinor: data [a] = [] | a : [a]
04:16:08 <Twey> Jonno_FTW: Another good argument against software patents ;)
04:16:11 <Veinor> right.
04:16:16 <Jonno_FTW> a very good one
04:17:09 <Veinor> if you want fast random access, what type do you want?
04:17:50 <nagnatron> arrays?
04:17:56 <Veinor> oh yeah.
04:18:25 <pastorn> Veinor: note that in haskell is writing to arrays O(n)
04:19:18 <Veinor> immutability strikes me as being space-efficient at the cost of time, correct?
04:19:30 <Veinor> generally.
04:19:35 <pastorn> yeah...
04:19:53 <pastorn> well... maybe not space efficient... depends on the context
04:19:54 <Jonno_FTW> what is the difference between immutable and mutable?
04:20:21 <pastorn> Jonno_FTW: if you have something that is mutabel you can do
04:20:23 <pastorn> x = 3
04:20:24 <McManiaC> > [1..] !! 5
04:20:25 <pastorn> x = 4
04:20:25 <lambdabot>   6
04:20:30 <McManiaC> > [1] !! 5
04:20:31 <lambdabot>   * Exception: Prelude.(!!): index too large
04:20:54 <pastorn> Jonno_FTW: writing over old values
04:21:01 <Jonno_FTW> ok
04:21:08 <McManiaC> ja Map for "arrays"
04:21:10 <McManiaC> *use
04:21:44 <Jonno_FTW> so I assume you can't overwrite other values with immutable data types? as in haskell?
04:21:50 <McManiaC> > fromList [("foo", 5),("bar", 10)] ! "foo"
04:21:51 <lambdabot>   No instance for (Control.Monad.Random.Class.MonadRandom
04:21:52 <lambdabot>                    ...
04:22:04 <McManiaC> huh
04:22:04 <McManiaC> ^^
04:22:35 <Veinor> bizarre, that works in my ghci
04:22:45 <Veinor> > (fromList [("foo", 5)]) ! "foo"
04:22:45 <pastorn> Veinor: what McManiaC said... except if you're solving problems like this: http://projecteuler.net/index.php?section=problems&id=11
04:22:46 <lambdabot>   No instance for (Control.Monad.Random.Class.MonadRandom
04:22:46 <lambdabot>                    ...
04:22:56 <pastorn> Veinor: then you might want to use Data.Array
04:23:11 <McManiaC> Jonno_FTW: Map also has "alter" and "update"
04:23:12 <Veinor> why?
04:23:15 <McManiaC> @hoogle Map
04:23:16 <lambdabot> module Data.Map
04:23:16 <lambdabot> Data.Map data Map k a
04:23:16 <lambdabot> Prelude map :: (a -> b) -> [a] -> [b]
04:23:31 <McManiaC> ok, no haddock link =(
04:23:37 <Jonno_FTW> interesting
04:23:43 <Jonno_FTW> @hackage MAp
04:23:43 <lambdabot> http://hackage.haskell.org/package/MAp
04:23:56 <McManiaC> http://hackage.haskell.org/packages/archive/containers/0.2.0.1/doc/html/Data-Map.html ;)
04:24:02 <pastorn> Jonno_FTW: in haskell if you write 'do { x <- "hello"; y <- take 3 x; return (x,y) }'
04:24:19 <pastorn> on the last line, x and y are different, right?
04:24:23 <arw_> McManiaC: the bool is to indicate wether its a float.
04:24:24 <Jonno_FTW> yes
04:24:34 <pastorn> that's immutability
04:24:37 <arw_> McManiaC: the logic is a little weird...
04:24:41 <Zao> pastorn: The middle expression looks invalid.
04:24:50 <McManiaC> arw_: okay…
04:24:59 <pastorn> when you compute (take 3) on x it doesn't change x
04:25:15 <Jonno_FTW> oh right yep
04:25:15 <pastorn> and Zao is right, it's supposed to be "return" in front of the first two lines
04:25:20 <Jonno_FTW> got it
04:25:49 <Veinor> pastorn: why would you want to use Array instead of Map for those?
04:25:54 <arw_> McManiaC: you unfortunately have to read the source to see what it does, its not really documented afaik
04:26:06 <McManiaC> > let x = "hello"; y = take 3 x; in (x,y)
04:26:07 <lambdabot>   ("hello","hel")
04:26:54 <sepp2k> Can I somehow express  foo bar = case baz bar of ... (where bar does not appear in ...) without spelling out bar?
04:27:20 <Jonno_FTW> use a lambda?
04:27:24 <McManiaC> no
04:27:41 <McManiaC> @pl \x -> case x of _ -> Nothing
04:27:41 <lambdabot> (line 1, column 17):
04:27:41 <lambdabot> unexpected "_"
04:27:41 <lambdabot> expecting variable, "(", operator or end of input
04:28:09 <McManiaC> @pl \x -> case x of 5 -> Nothing
04:28:09 <lambdabot> (line 1, column 19):
04:28:10 <lambdabot> unexpected ">" or "-"
04:28:10 <lambdabot> expecting variable, "(", operator or end of input
04:28:15 <McManiaC> hm ^^
04:29:29 <trzkril> @pl \x -> case x of; _ -> Nothing;
04:29:30 <lambdabot> (line 1, column 16):
04:29:30 <lambdabot> unexpected ";"
04:29:30 <lambdabot> expecting variable, "(", operator or end of input
04:29:36 <trzkril> @type \x -> case x of; _ -> Nothing;
04:29:37 <lambdabot> forall t a. t -> Maybe a
04:29:47 <trzkril> @type \x -> case x of _ -> Nothing
04:29:48 <lambdabot> forall t a. t -> Maybe a
04:29:49 <Twey> sepp2k: No.  There's a proposed extension to allow it, though (‘foo = (case of ...) . baz’)
04:29:56 <trzkril> pl does not like case i guess
04:30:06 <Twey> You could also use view patterns and multiple equations
04:30:08 <maltem> sepp2k, view patterns would be another extension to address this I think
04:30:18 <Twey> Snap ☺
04:30:28 <sepp2k> McManiaC: Twey: maltem: Thanks.
04:30:29 <Veinor> view patterns are pretty great.
04:30:56 <Twey> foo (baz -> Bar) = …; foo (baz -> Quux) = …
04:32:17 <McManiaC> hmmm what are view patterns?
04:32:53 <Twey> McManiaC: They let you apply a transformation to a pattern before matching on it
04:33:27 <Twey> ‘foo x | x + 1 == 3 = bar’ can become ‘foo (succ -> 3) = bar’, for example
04:33:52 <Twey> (okay, == isn't quite the same as pattern-matching, so that's probably a bad example, though it works here)
04:34:09 <McManiaC> oh
04:34:10 <McManiaC> cool
04:34:39 <Twey> The syntax is (function -> result)
04:35:02 <Twey> You need -XViewPatterns or {-# LANGUAGE ViewPatterns #-}
04:35:07 <McManiaC> > let foo (find (5 ==) -> Just a) = a; foo _ = Nothing in foo [1..10]
04:35:08 <lambdabot>   Illegal view pattern:  (find (5 ==) -> Just a)
04:35:08 <lambdabot>  Use -XViewPatterns to enabl...
04:35:13 <Twey> No view patterns in \b ☹
04:35:14 <McManiaC> oh hehe
04:35:36 <McManiaC> thats cool
04:35:54 <Twey> Especially in ‘read’.
04:36:26 <sepp2k> Does lambdabot understand LANGUAGE-pragmas?
04:36:30 <Twey> No
04:36:40 <Twey> I don't think so
04:36:55 <sepp2k> > {-# LANGUAGE ViewPatterns #-} let foo (find (5 ==) -> Just a) = a; foo _ = Nothing in foo [1..10]
04:36:56 <Twey> > {-# LANGUAGE ViewPatterns #-} let foo (succ -> x) = x in foo 3
04:36:56 <lambdabot>   Illegal view pattern:  (find (5 ==) -> Just a)
04:36:56 <lambdabot>  Use -XViewPatterns to enabl...
04:36:57 <lambdabot>   Illegal view pattern:  (succ -> x)
04:36:57 <lambdabot>  Use -XViewPatterns to enable view patte...
04:36:58 <Twey> No ☺
04:37:26 <McManiaC> sepp2k: my example wouldnt even work :P a :: Num, Nothing :: Maybe a
04:37:55 <Twey> Heh, aye
04:38:14 <Twey> Also, it boils down to ‘foo = find (5 ==)’ ;)
04:38:40 <McManiaC> foo = fromMaybe 0 . find (5 ==)
04:38:48 <Orphi> I can't believe I'm running 3 OSes right now...
04:38:48 <McManiaC> :D
04:39:00 <Twey> 's better
04:39:34 <McManiaC> > succ `fmap` find (5 ==) [1..10]
04:39:35 <lambdabot>   Just 6
04:39:36 <McManiaC> :>
04:39:42 <Orphi> So does anybody else think the Prelude is too big?
04:39:57 <McManiaC> prelude is pretty small
04:40:00 <McManiaC> base is big ;)
04:41:12 <Orphi> yeah, but Prelude includes all the basic types, all the list functions, all the function functions, all the standard classes...
04:41:30 <Orphi> if you want to replace, say, just the list type, you have to manually import a bazillion symbols from Prelude.
04:41:40 <Orphi> there's no easy way to just not import the list stuff, for example.
04:41:58 <McManiaC> why would you do that? :O
04:42:09 <Veinor> I assume you want the various components of prelude to all autoimport as well.
04:42:42 <Orphi> It would be nice if the stuff in Prelude could be grouped into smaller chunks, and you could import chunks of stuff.
04:42:43 <McManiaC> import Prelude hiding ((:))
04:42:57 <McManiaC> although I think thats depreciated with ghc 6.12 (?)
04:43:05 <Orphi> McManiaC: yeah, but if you want to (say) replace all the standard list functions with a new implementation...
04:43:18 <McManiaC> then dont use lists
04:43:35 <McManiaC> newtype MyList a = MyList [a]
04:43:45 <McManiaC> myFind = ...
04:44:06 <McManiaC> list should behave as lists do imo
04:44:26 <Orphi> sure, but if you want to change the *implementation*, not the observable behaviour...
04:44:48 <Orphi> or if you're writing a module that uses ByteString and doesn't require lists, but you still want the other Prelude stuff...
04:46:15 <Saizan> it is a bit unfortunate
04:46:40 <Saizan> though you can solve this without really changing the Prelude
04:47:20 <Orphi> I just think it would be nicer if Prelude was just an empty module that imports a bunch of other modules.
04:47:39 <Orphi> then if you want, you can not import Prelude, and manually import just the bits you want.
04:47:51 <Orphi> I doubt I'm the first person to voice this idea...
04:48:08 <Saizan> it's actually defined like that in the haskell report, iirc
04:48:21 <Orphi> yes, I believe it is actually.
04:48:52 <McManiaC> isnt there a NoPrelude pragma?
04:49:37 <Saizan> http://hackage.haskell.org/packages/archive/base/4.2.0.0/doc/html/src/Prelude.html <- the only defined things are $! and seq :)
04:49:53 <Saizan> not even seq, actually
04:50:00 <Saizan> so it's already like that!
04:50:07 <Zao> McManiaC: NoImplicitPrelude or something.
04:50:21 <Saizan> McManiaC: NoImplictPrelude is needed only to override the way syntax gets desugared
04:50:24 <danderson> what does the ! do in "return $! Fail (I.input st) stk msg" ?
04:50:41 <McManiaC> strict notation
04:50:47 <danderson> oh, it's the function ($!)
04:50:56 <danderson> thanks.
04:50:56 <McManiaC> $! is the same as $ but uses strict evalutation
04:50:59 <Saizan> you can "import Prelude ()" to avoid importing symbols from it
04:51:07 <Saizan> @src $1
04:51:07 <lambdabot> Source not found. :(
04:51:10 <Saizan> @src $!
04:51:10 <lambdabot> f $! x = x `seq` f x
04:51:17 <danderson> @src $
04:51:18 <lambdabot> f $ x = f x
04:51:26 <danderson> right.
04:51:32 <Orphi> but what if you *want* to import from the Prelude, but only certain bunches of stuff?
04:51:42 <Orphi> currently you have to specify each symbol individually.
04:51:59 <Zao> import Prelude (doWhatIMeanCorrectly)
04:52:09 <Saizan> Orphi: you've to import each of the modules that you actually need separately
04:52:20 <Zao> Unfortunatly, mind reading will not be in until Haskell'
04:52:34 <McManiaC> hehe
04:53:06 <Saizan> yeah, there's no other way to do this with the current module system
04:53:34 <Orphi> well, if you wanted, say, all the list stuff, you could import Prelude (), import Data.List.
04:53:54 <Saizan> yeah, you can do like that for every part
04:53:56 <Orphi> but if you only wanted, say, the standard number types, number classes, function operators, but not lists... um... yeah.
04:54:19 <McManiaC> import GHC.Num ?
04:54:30 <Orphi> Doesn't that make the code GHC-specific?
04:54:31 <Saizan> import Prelude (); import GHC.Num
04:54:36 <Saizan> yes
04:54:48 * hackagebot Data-Rope 0 - Ropes, an alternative to (Byte)Strings.  http://hackage.haskell.org/package/Data-Rope-0 (PierreEtienneMeunier)
04:55:05 <Orphi> ...hackage...bot...?
04:55:13 <Orphi> that's new!
04:56:57 <Saizan> http://hackage.haskell.org/package/haskell98 <- maybe you could use this, though i don't see which module should export Num
04:58:40 <Orphi> Maybe I should just sit down and make a bunch of modules that import Prelude and export just one particular part of it.
04:58:52 <Orphi> do the effort use, reuse later.
04:59:04 <Orphi> do the effort once, reuse later.
05:00:04 <Orphi> Does anybody know the current status of DHP?
05:00:12 <Orphi> I mean, is it still alpha or what?
05:00:20 <Zao> DPH?
05:00:21 <Orphi> DPH
05:01:41 <Orphi> it's one of those features that sounds great, but most people are like "yeah, call me back when it's actually finished and working" :)
05:02:19 <Saizan> the vector package is a recent by-product, and it seems to work well
05:02:40 <McManiaC> > do Right foo <- Just (Left 5); return foo
05:02:41 <lambdabot>   Nothing
05:02:46 <McManiaC> cool
05:03:01 <Veinor> wait... what?
05:03:29 <Orphi> sure, but the last thing I heard was that the crucial vectorisation transformation that makes actual parallel processing work isn't done yet or something...
05:04:13 * Saizan doesn't know
05:04:16 <dantheman99> Hey, I'm having some trouble building/installing gtk2hs, is there anyone around here who might be able to help?
05:04:33 <Orphi> heh, I did that yesterday and I'm about to do it again today ;)
05:04:35 <Orphi> what's up?
05:05:20 <dantheman99> Basically, I do ./configure --disable-split-objs --disable-deprecated, then call make...
05:05:40 <sepp2k> Design question: When writing a parser is it preferable for it to fail as early as possible on invalid input or to be usable on partial input. In other words: should I check all the input first, to make sure it is valid, or should I only read as much of the input as is necessary to create the parts of the parse tree that have been requested (i.e. embrace laziness).
05:06:08 <dantheman99> However, make fails with an error saying something like 'failed to load interface Graphics.UI.GTK.General.General'
05:06:28 <Orphi> dantheman99: which OS, GHC version?
05:06:40 <sepp2k> Specifically I'm trying to decide whether parse should return Maybe ParseTree or (ParseTree, Success/Failure)
05:06:47 <Zao> sepp2k: Is this parser supposed to be continuable?
05:07:10 <dantheman99> Hey, sorry ya... windows, ghc 6.10.4
05:08:07 <Orphi> you got make to work on Windows? that's impressive...
05:08:19 <Orphi> have you seen this? http://www.mail-archive.com/gtk2hs-devel@lists.sourceforge.net/msg00340.html
05:08:22 <dantheman99> Hmmm.. no, not really, that's the problem!
05:09:27 <sepp2k> Zao: Well, at the moment it's not supposed to be anything. Meaning: I'm only writing it to write it, not because I'm actually planning on using it for anything (read: I'm bored).
05:09:55 <Orphi> sepp2k: Try writing it both ways. ;)
05:10:27 <dantheman99> Orphi, I think I did, but I don't think it includes glade, which I need...
05:10:31 <Zao> sepp2k: Excellent motivation.
05:10:47 <Orphi> dantheman99: ah, OK.
05:11:12 <dantheman99> actually, I was thinking of uninstalling ghc6.10.4 and going back to 6.10.3, as there is a windows installer for that.
05:11:20 <Orphi> dantheman99: In that case... I'm honestly out of my depth here. If you put the exact build error on hpaste, somebody else might know...
05:11:41 <Alpounet> gtk2hs on windows ?
05:11:42 <dantheman99> However, I don't know whether there is  a haskell platform that uses 6.10.3?
05:11:44 <Orphi> dantheman99: Yeah, that's what I end up doing. It's a pain, isn't it?
05:11:46 <Alpounet> haha, looks fun to make it work...
05:11:59 <dantheman99> Tell me about it, I've already spent 3 days!
05:12:06 <Orphi> Alpounet: If you use the pre-built one, it's quite easy.
05:12:14 <dantheman99> Really?
05:12:47 <sepp2k> Orphi: Good point. The Maybe version is trivial to define based on the tuple version, now that I think of it. (i.e. parseMaybe = case parseTuple of (parseTree, Success) -> Some parseTree; _ -> None )
05:12:48 <dantheman99> I looked on the haskell website but I couldn't figure out how to get the platform with a particular version of ghc?
05:13:24 <sepp2k> Zao: Orphi: Thanks.
05:14:07 <Orphi> dantheman99: The HP guys really aren't very helpful about with versions of HP contain what.
05:14:21 <Orphi> the *current* version has lots of description, but the older ones? not really described.
05:14:25 <jgh> How do you do, uh, complete induction? I want to define Catalan numbers by the obvious recurrence relation that seeing them as ways to bracketing an expression suggests.
05:14:55 <jgh> i.e. C_{n+1} = sum(C_k C_{n-k}, k = 1..n)
05:14:57 <dantheman99> Did you manage to find one yourself?
05:15:09 * Orphi is waiting for > 1,000 Darcs patches to download. o_O
05:15:42 <Veinor> JordiGH: I'm not sure what your question is.
05:15:53 <Orphi> dantheman99: I don't think I've ever got gtk2hs to work with HP - but I don't think I tried very hard...
05:16:30 <JordiGH> Veinor: How do I write in Haskell the definition I wrote for C_{n+1}.
05:16:31 <JordiGH> ?
05:16:31 <Saizan> dantheman99: the compiler error you got above might be cause by using the "wrong" version of the C gtk libs
05:17:22 <JordiGH> Huh, probably just as a function, eh?
05:17:42 <Saizan> JordiGH: c (n+1) = sum [ c k * c (n-k) | k <- [1..n]]
05:17:52 <Alpounet> Orphi, huh ? what for ?
05:17:56 <dantheman99> saizan, ah really?
05:17:58 <Saizan> assuming justaposition is multiplication
05:18:05 <dantheman99> what would you need to confirm that?
05:18:18 <dantheman99> My config.log file?
05:18:23 <Orphi> Alpounet: ...?
05:18:36 <JordiGH> Saizan: Does the compiler automatically do dynamic programming? That definition is inefficient without it.
05:18:37 <Saizan> dantheman99: i wouldn't know how to confirm that :)
05:18:44 <dantheman99> haha
05:18:46 <Saizan> JordiGH: it doesn't
05:18:50 <Alpounet> * Orphi is waiting for > 1,000 Darcs patches to download. o_O
05:19:07 <Orphi> Alpounet: Oh, right. Apparently I need the Darcs version of gtk2hs.
05:19:15 <Alpounet> oh
05:19:20 <Alpounet> good luck
05:19:27 <Orphi> thanks :S
05:19:42 <Orphi> 30 patches to go...
05:20:05 <JordiGH> Saizan: Hm, how can I see how the compiler decides to evaluate c(20)?
05:20:08 * JordiGH looks for debuggers.
05:20:15 <dantheman99> saizan, what would you suggest as a next step then?
05:20:26 <Alpounet> JordiGH, ghci has an integrated debugger
05:20:30 <Orphi> ...and now it's "applying" those patches...
05:20:35 <Alpounet> http://www.haskell.org/ghc/docs/latest/html/users_guide/ghci-debugger.html
05:21:08 <Orphi> It's nice that GHCi has a debugger now, but I find it very hard to use...
05:21:26 <Alpounet> compared to ?
05:21:29 <Saizan> dantheman99: mh, i'll search for what version of gtk they use to build their installers
05:21:31 <JordiGH> Hm, Emacs seems to have a mode for it.
05:21:58 <Orphi> Well, I don't know, maybe it's just because it's CLI; something graphical would maybe be better.
05:22:09 <Orphi> Praise the Lord, Darcs has finished!
05:22:10 <dantheman99> ah, ok. I'll check that out, thanks
05:22:12 <tensorpudding> there is is a Monad.Reader article about the GHCi debugger
05:22:18 <Veinor> is gtk2hs actually that hard to use? >_>
05:22:25 <Alpounet> to use no
05:22:32 <Veinor> I mean, to get working
05:22:33 <Alpounet> to make work under windows, heh ...
05:22:34 <JordiGH> Ah, ghc has a profiler, even better.
05:22:35 <dantheman99> to set up on windows... yes
05:22:38 <Saizan> JordiGH: see memo-combinators on hackage for a very easy way to do dynamic programming
05:22:44 <Alpounet> s/under/on/
05:22:52 <Orphi> on Windows, if you use the pre-built installer binary, it's trivial.
05:22:55 <Veinor> ah.
05:23:04 <Orphi> oh, wait - you cannot have any other stuff that uses GTK installed!
05:23:11 <Orphi> it doesn't like it.
05:23:12 <Saizan> everything is hard on windows
05:23:24 <Orphi> Saizan: And what makes you think that?
05:23:32 <Saizan> the people that come here :)
05:23:33 <Veinor> JordiGH: yeah, you want memo-combinators or memotrie
05:23:45 <Saizan> fsvo everything, at least
05:23:48 <Alpounet> Windows is definitely not the handiest platform for developers
05:23:52 <JordiGH> !memo-combinators
05:24:00 <JordiGH> Gah, force of habit.
05:24:03 <Saizan> @hackage memo-combinators
05:24:03 <lambdabot> http://hackage.haskell.org/package/memo-combinators
05:24:07 <Orphi> Windows is definitely not the handiest platform for CROSS-PLATFORM developers. ;)
05:24:22 <Orphi> If you develop exclusively for Windows, it's fairly easy.
05:24:28 <Orphi> (Guess what Microsoft wants you to do...)
05:24:36 <Alpounet> well, indeed
05:24:45 <Saizan> http://hackage.haskell.org/package/data-memocombinators <- here it is
05:24:54 <JordiGH> Saizan: Quoth the server...
05:24:59 <Orphi> In fairness, it seems to me that every platform that isn't Windows is essentially Unix.
05:25:19 <tensorpudding> desktop platforms
05:25:25 <JordiGH> Ah, you fixed the URL.
05:25:47 * Orphi stares at the gtk2hs source tree and feels awfully lost.
05:26:01 <JordiGH> Orphi: If you're going to be that essentialist, everything is essentialy x86.
05:26:41 <nostrand> JordiGH: actually, i use more sparc computers than x86
05:26:44 <Saizan> Orphi: i think your problem with other gtk apps installed has to be fixed by placing the gtk .dlls in the right place
05:26:45 <Orphi> JordiGH: It just seems to me that apart from Windows, everything is a Unix clone. I guess because it gives you instant access to all the Unix software already out there...
05:26:51 <JordiGH> nostrand: You are not essential.
05:26:54 <Saizan> Orphi: wrt of your %Path% too
05:27:06 <nostrand> JordiGH: :D
05:27:14 <tensorpudding> ARM is the future
05:27:57 <Orphi> over Intel's dead body ;)
05:28:21 <JordiGH> Orphi: That claim is broad enough to be almost meaningless, "Unix" is so diverse and varied to make most of your statement valid only after undue difficulty. I challenge you to get Apple software running on FreeBSD. :-/
05:28:24 <Orphi> Saizan: Actually, installing Gtk2hs *first*, and installing other GTK software *after* seems to work just fine...
05:28:47 <Veinor> JordiGH: at least they're both BSDs :P
05:28:55 <psychicist_> It will be found InHell :)
05:29:01 <JordiGH> Veinor: Yeah, tenously so.
05:29:10 <tensorpudding> oh crap, arguing about what Unix is
05:29:17 <JordiGH> tenuously
05:29:19 <Orphi> JordiGH: Well, all these OS have things like cp and ls, use /dev, and so forth.
05:29:34 <Orphi> Whereas Windows does something totally different.
05:29:39 <tensorpudding> they don't need them though
05:29:43 <JordiGH> Orphi: Yeah, they have processors that understand a very similar assembly language too.
05:29:47 <Orphi> I remember a time when *every* OS was totally different ;)
05:29:48 <tensorpudding> they would still be unix without them
05:30:03 <JordiGH> tensorpudding: Well, they wouldn't be POSIX.
05:30:12 <tensorpudding> POSIX isn't Unix though
05:30:22 <JordiGH> True.
05:30:32 <Alpounet> are the project mailing lists having some trouble again ?
05:30:52 <JordiGH> Anyways, where's the docs for this data-memocombinators thingamijig?
05:31:22 <Saizan> JordiGH: on the page i linked to you
05:31:22 <tensorpudding> @hackage data-memocombinators
05:31:23 <lambdabot> http://hackage.haskell.org/package/data-memocombinators
05:32:08 <tensorpudding> click on the link under Modules
05:32:12 <Veinor> click the "Data.Memo"... yeah that
05:32:30 <rajeshsr> what is the difference between "newtype" and "type"? or may be "newtype" and "data". I didn't find wiki entry useful.
05:32:34 <JordiGH> tensorpudding: Oh, thanks.
05:32:36 <Orphi> I think processors understand machine code, not assembly language ;)
05:32:57 <Saizan> rajeshsr: newtype, type and data are 3 different things
05:32:59 <JordiGH> I bet Windows is gonna apply for POSIX status one of these days too... all it needs is a few syscalls and a few aliases for copy -> cp, del -> rm.
05:33:10 <Twey> JordiGH: It's already POSIX-certified
05:33:17 <JordiGH> Well, there you go.
05:33:18 <Orphi> I think there is an (optional) POSIX layer you can install if you want POSIX.
05:33:22 <JordiGH> Orphi: Windows is Unix too.
05:33:23 <rajeshsr> Saizan, I know about type and data. But not about newtype.
05:33:24 <Saizan> rajeshsr: type just defines a transparent alias
05:33:41 <tensorpudding> Windows is POSIX and Linux isn't last I heard
05:33:45 <Orphi> But you just said Unix /= POSIX ;)
05:33:51 <Twey> There are several levels of POSIX-compliance
05:34:01 <benmachine> newtype works like data except you can only use it where you have exactly one constructor
05:34:01 <zygoloid> rajeshsr: newtype and data are quite similar
05:34:07 <Saizan> rajeshsr: ok, "newtype" is a restricted form of "data", which doesn't have runtime overhead
05:34:09 <JordiGH> tensorpudding: I forget why Linux didn't try to get the POSIX seal of approval.
05:34:29 <rajeshsr> Saizan, zygoloid oh, ok! thanks!
05:34:31 <tensorpudding> probably doesn't implement some obscure bit
05:34:34 * JordiGH wonders if GNU/kFreeBSD has the POSIX-nature.
05:34:36 <tensorpudding> or maybe something conflicts
05:34:42 <danderson> so, if I throw an exception in a ForkIO'd thread and don't plan on machinery to throw it back out to another thread, the exception will just cause that thread to die silently? Is that right?
05:34:52 <benmachine> if you do newtype MyInt = MkInt Integer, you have a type which looks different from Integer to the type system but behaves exactly the same once compiled
05:35:06 <tensorpudding> Linux is just a kernel
05:35:13 <benmachine> err, doesn't behave exactly the same
05:35:21 <JordiGH> Orphi: No, Unix isn't POSIX, but POSIX is Unix.
05:35:23 <Saizan> danderson: right
05:35:35 <benmachine> because behaviour is sometimes determined by the type system (e.g. class instances)
05:35:45 <benmachine> but it will use the same amount of space etc.
05:35:50 <Saizan> danderson: well, it'd get caught by the toplevel exception handler i think
05:35:56 <Alpounet> no space overhead compared to Integer
05:36:11 <Saizan> danderson: which will just print the message on stderr, though it can happen at any time
05:36:17 <danderson> hmm
05:36:39 <danderson> okay, so I should add some machinery to swallow exceptions if I don't want them displayed
05:36:50 <danderson> thanks.
05:37:25 <Saizan> forkIO (catch foo (\(SomeException _) -> return ()))
05:37:31 <JordiGH> Aw, man... codepad doesn't have Memo. ;_;
05:37:54 <danderson> Saizan: right, that's what I just did :)
05:38:17 * JordiGH will have to actually install stuff.
05:38:56 <Saizan> catalan numbers have a closed form, though
05:39:13 <JordiGH> Saizan: Yeah, it was just an illustrative example.
05:40:23 <JordiGH> Saizan: Coming from C++, it feels awkward to have a language where I'm not actively encouraged to think about how bytes are getting pushed around in memory. :P
05:41:12 <Orphi> I guess that's why I find C++ hard. ;)
05:41:14 <danderson> you are eventually in haskell
05:41:38 <danderson> when you run your network server and see that it adds 2 seconds of latency to everything because the laziness is thrashing all over the place :)
05:44:58 <Orphi> damnit, configure can't find happy, even though it's there. great.
05:45:17 <Orphi> ...also, that sentence sounds really weird. o_O
05:46:33 <JordiGH> Finding happy is a difficult task for many of us. :-0
05:46:35 <JordiGH> :-)
05:46:51 <Orphi> tell me about it...
05:46:54 <Twey> Heh.
05:47:02 <Orphi> it's not something you can just compile from source.
05:47:16 <Orphi> hell, where *is* the source?! :)
05:47:32 <Alpounet> @where happy
05:47:33 <lambdabot> http://www.haskell.org/happy/
05:47:41 <Orphi> yeah, I was joking.
05:47:48 <Alpounet> me too :)
05:47:55 <JordiGH> Orphi: http://3.bp.blogspot.com/_J5Ribm2Pk0w/Sd8LbxgSqRI/AAAAAAAAAMg/cET4jlTKK7w/s400/Philosoraptor_human_or_dancers.jpg
05:48:22 <Orphi> I don't know about you, but *I* am a dancer. :P
05:49:03 <Orphi> OK, so anybody know how I tell configure where Happy is?
05:50:30 <JordiGH> Is this a question about a GNU configure script?
05:50:42 <Orphi> yeah.
05:50:59 * Orphi looks at configure script.
05:51:01 <JordiGH> Is its help string helpful?
05:51:12 * Orphi notices that it's over 11,000 lines long, and quits.
05:51:15 <JordiGH> Or its output? It often says where it's looking.
05:51:24 <JordiGH> No, don't look at the script, it's automatically generated anyways.
05:52:44 <Orphi> OK, --help gives me several pages of stuff...
05:52:51 <JordiGH> grep for happy
05:53:01 <Orphi> what's grep?
05:53:01 <JordiGH> (Now we're on our way to finding happy)
05:53:07 <JordiGH> Uh...
05:53:37 <JordiGH> Okay, do configure --help | less (what OS are you on?)
05:53:47 <JordiGH> and if that worked, hit / (slash) and type "happy"
05:54:12 <JordiGH> configure --help | less
05:54:13 <heatsink> and then press return
05:54:34 <Orphi> OK, it says HADDOCK=path should tell it where to find Haddock.
05:54:40 <Orphi> Let's see if that works for Happy...
05:55:36 <Orphi> ...yes, it does.
05:55:40 <Orphi> Now it can't find Alex.
05:55:46 <Orphi> *facepalm*
05:55:54 * Orphi builds Alex.
05:56:35 <JordiGH> Orphi: btw: http://platinum.linux.pl/~jordi/piccies/grep.png
05:57:21 <Orphi> ah, OK.
05:57:28 <Orphi> I've always wondered WTF grep is supposed to do...
05:58:16 <Orphi> ...and it can't *find* Alex, so I guess I have to tell it...
05:58:27 <JordiGH> Globally search Regular Expression and Print
05:58:30 <JordiGH> i.e. search :-)
05:58:43 <Orphi> regular expressions?
05:58:45 * Orphi shivers
05:58:56 <JordiGH> Well, "happy" is also a regular expression.
05:59:44 <Orphi> Wooo! I survived the configure script! :D
05:59:50 <Orphi> I wonder if I get a hiscore for that?
06:00:12 <Orphi> OK, mike-alpha-kilo-echo...
06:01:29 <Orphi> Ah yes, my favourit thing about Unix: command strings too large to fit on a single page. :P
06:01:42 <JordiGH> You're not supposed to read the output of make.
06:01:52 <JordiGH> Those were commands generated by the configure script.
06:02:00 <JordiGH> Nor are you supposed to *write* those commands.
06:02:15 <heatsink> ...unless something doesn't work automatically.
06:02:16 <benmachine> autoconf is evil there I said it
06:02:39 <Orphi> autoconf is not evil - the fact that autoconf is needed in the first place is evil ;)
06:02:40 <JordiGH> benmachine: It still solves a problem no other build system solves (which might not be a problem you have).
06:02:42 <heatsink> It's like a crooked small-town cop.  It keeps its job because nobody better wants to move to such an awful place.
06:02:54 <benmachine> JordiGH: oh, sure, but it solves it evilly
06:02:58 <JordiGH> Yeah, what heatsink said.
06:03:30 * Orphi watches giant GHC invocations scroll past
06:03:47 <benmachine> imo if your build system is complicated enough to need automating, you need to make your build system simpler >_>
06:03:49 <Orphi> damn, this thing needs a syntax hilighter or something..
06:04:04 <benmachine> or at least devise some kind of tool that doesn't leave you utterly helpless when it goes wrong
06:04:09 <benmachine> (when, not if)
06:04:16 <Orphi> woo, now we get to the 25,000 warnings per source file part...
06:05:01 <benmachine> is this 6.12
06:05:08 <JordiGH> Orphi: CMake kinda colourises make output... sort of.
06:05:18 <benmachine> 6.12 has a tendency to go warnings-crazy on some old code
06:05:26 <JordiGH> Orphi: But it's an entirely different build system with its own shortcomings.
06:05:30 <benmachine> because of the base3 issue
06:05:55 <Orphi> I'm just waiting for some smart guy to say "actually, there's an Emacs mode for that..."
06:06:03 <benmachine> hah
06:06:08 <JordiGH> Orphi: Yeah, there is, compilation-mode.
06:06:20 <Orphi> gah! >_<
06:06:32 <benmachine> don't pretend you are surprised :P
06:06:33 <Orphi> Emacs, the nerd's favourit OS.
06:06:40 <JordiGH> It's not an OS.
06:06:45 <JordiGH> It's a lifestyle, man.
06:06:49 <Twey> Haha
06:06:51 <Orphi> Apparently some people think it's a *text editor*
06:06:52 <rajeshsr> > read "aaa"::String
06:06:52 * JordiGH sings the praises of GNU.
06:06:53 <lambdabot>   "* Exception: Prelude.read: no parse
06:07:01 <rajeshsr> why doesn't that work?
06:07:10 <benmachine> because you are reading aaa
06:07:14 <Orphi> > read "\"aaa\"" :: String
06:07:14 <benmachine> a string that contains aaa
06:07:15 <lambdabot>   "aaa"
06:07:23 <benmachine> but yes, you want a string that contains "aa"
06:07:34 <benmachine> > show "aaa"
06:07:35 <lambdabot>   "\"aaa\""
06:07:43 * Twey chuckles.
06:07:50 <rajeshsr> too subtle! So how I make it read "aaa" to a String?
06:07:51 <benmachine> > fix show
06:07:52 <lambdabot>   "\"\\\"\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\...
06:08:02 <benmachine> rajeshsr: the function "id" will do that for you
06:08:02 <Orphi> > fix haskell98
06:08:03 <lambdabot>   Not in scope: `haskell98'
06:08:25 <Orphi> ...so fixing Haskell 98 is beyond the scope of Lambdabot?
06:08:39 <Orphi> what the heck is c2hs anyway?
06:08:48 <Saizan> she uses haskell2010
06:08:57 <burp> > read "\"\\\"aaa\\\"\"" :: String
06:08:58 <lambdabot>   "\"aaa\""
06:09:04 <Saizan> c2hs is a preprocessor
06:09:13 <Saizan> it helps with binding to C libs
06:09:26 <Orphi> well, it sure is processing my pre's!
06:09:49 <Orphi> oh, no, now it's hsc2hs...
06:10:03 <rajeshsr> >lines "1 23\n4\n" >>= words >>= (return.(read::(String -> Int)))
06:10:17 <rajeshsr> > lines "1 23\n4\n" >>= words >>= (return.(read::(String -> Int)))
06:10:18 <lambdabot>   [1,23,4]
06:10:33 <rajeshsr> is there any way to simplify this?
06:10:55 <rajeshsr> the last part is really ugly! :) return.read etc..
06:11:10 <rajeshsr> anyway, am starting to enjoy monads! :)
06:11:15 <Orphi> > lines "1 23\n4\n" >>= words >>= (return . read) :: [Int]
06:11:16 <lambdabot>   [1,23,4]
06:11:52 <benmachine> a >>= return . f = fmap f a
06:11:55 <heatsink> >t fmap read
06:11:56 <JordiGH> So what's GUI coding in Haskell like?
06:11:58 <heatsink> :t fmap read
06:11:59 <lambdabot> forall a (f :: * -> *). (Read a, Functor f) => f String -> f a
06:11:59 <rajeshsr> Orphi, hmm, I tried something like that first! But forgot return! :)
06:12:05 <JordiGH> Are there bindings for Qt?
06:12:07 <rajeshsr> Orphi, thanks!
06:12:15 <benmachine> > lines "1 23\n4\n" >>= map read . words
06:12:16 <lambdabot>   [* Exception: Prelude.read: no parse
06:12:23 <benmachine> > lines "1 23\n4\n" >>= map read . words :: [Int]
06:12:24 <lambdabot>   [1,23,4]
06:12:28 <JordiGH> Ah, there is, qtHaskell.
06:12:56 <Orphi> I'm still dissapointed that I can't write native Win32 GUI code in Haskell. :(
06:13:05 <Orphi> (Well, OK, you *can*... but you won't survive long!)
06:13:07 <rajeshsr> benmachine, thats interesting!
06:14:15 <JordiGH> Orphi: Native? You mean, the Windows C API?
06:14:27 <Orphi> JordiGH: Yeah.
06:14:39 <Orphi> I mean, there's a GTK binding, there's a Qt binding, there's a wxWidgets binding...
06:14:48 <Orphi> ...but nothing for easily using Win32.
06:15:06 <Saizan> the Win32 doesn't bind those?
06:15:25 <Orphi> Programming Win32 directly is a nightmare.
06:15:33 <Orphi> You need some kind of library to make it bareable.
06:15:42 <JordiGH> I think I know a few Windows coders who in fact prefer the Qt API.
06:15:59 <JordiGH> Oh, I thought you were saying you preferred the Windows API.
06:16:08 <Orphi> no no ;)
06:16:25 <Orphi> I just prefer not having to install the entire GTK runtime just to run my Haskell application which happens to have a GUI.
06:16:42 <Orphi> Windows doesn't usually have GTK installed already, after all.
06:17:08 <JordiGH> I solved that problem in a different way.
06:17:16 <JordiGH> Defenestrated the computer.
06:17:32 <JordiGH> Throw the Windows out the computer, or if that fails, the computer out the Window.
06:17:50 <Orphi> heh, yeah, well, if I actually knew how to work Linux...
06:17:54 <Twey> Orphi: wxWidgets *is* a way to easily use the Win32 API.
06:18:02 <Twey> A library to, in fact.
06:18:12 <Orphi> sure, but you have to install wxWidgets to use it.
06:18:17 <burp> you will always need to install a runtime library
06:18:27 <Orphi> And also, I can't get wxHaskell to compile...
06:18:42 <Twey> Yeah… you're always going to need to install a library to use a library :þ
06:18:46 <JordiGH> Qt doesn't need that, does it?
06:19:02 <JordiGH> I think I would have heard more complaints from Windows Skype users.
06:19:08 <Twey> What, a runtime?
06:19:09 <Twey> Yeah
06:19:12 <Twey> It just comes bundled
06:19:49 <Orphi> the amusing this is, wxHaskell is instructions especially for Windows users.
06:19:54 <burp> you can bloat your binary and link statically
06:19:54 <Orphi> and I still can't make it work.
06:20:10 <Saizan> the usual strategy on windows seems to be "pack the .dlls into your installer"
06:20:31 <JordiGH> Saizan: i.e. static linking :P
06:20:46 <JordiGH> (well, not sure how Windows looks up symbols, maybe it is "dynamic")
06:20:48 <Orphi> not precisely; you can not install the DLLs if they already exist.
06:20:54 <arw_> shipping a runtime is no that bad...
06:21:18 <arw_> many windows programs ship stuff like msvc*.dll anyways.
06:21:30 <JordiGH> arw_: Is that legal?
06:21:30 <arw_> so a gtk*.dll should not be a problem imho.
06:21:32 * Orphi had forgotten just how long gtk2hs takes to compile.
06:21:43 <JordiGH> Orphi: Btw, why are you compiling?
06:21:51 <arw_> JordiGH: yes, afaik the license for doing that comes with the visual studio license.
06:21:57 <JordiGH> Orphi: It's not very environmentally-friendly.
06:22:05 <Orphi> what, gtk2hs?
06:22:07 <JordiGH> arw_: Developers, developers, developers, I see.
06:22:13 <JordiGH> Orphi: Yeah.
06:22:17 <Orphi> there's no pre-built binary for SUSE.
06:22:33 <JordiGH> Oh, SuSE. Is there one for RedHat or Fedora?
06:22:42 <JordiGH> You might be able to use those.
06:22:44 <Orphi> uh... possibly.
06:23:22 <Orphi> I've set up several Linux VMs, but the SUSE one is the easiest to use.
06:23:33 <Orphi> unfortunately it also seems to be the one with the least stuff prepackaged for it.
06:24:21 <Orphi> arw_: do you have any idea how big all the GTK DLLs are?
06:24:27 <JordiGH> Setup a GNU/kFreeBSD vm :P
06:24:44 <Orphi> is there a difference?
06:25:01 <JordiGH> Don't know. Been meaning to try it for some time.
06:25:16 <Orphi> well, I guess I am already in my pyjamas...
06:25:29 * JordiGH is in skin.
06:25:38 <benmachine> keeps your insides in?
06:25:49 <JordiGH> benmachine: It's great insulation too.
06:26:01 <benmachine> handy
06:26:04 <benmachine> thanks, skin!
06:26:07 <Orphi> I'm sitting on the skin of a dead cow.
06:27:01 <Orphi> ...I've got that song stuck in my head now :(
06:27:52 <tensorpudding> freebsd is fun times
06:28:04 <tensorpudding> in a vm
06:29:01 <Saizan> mh, can you setup a vm without rebooting?
06:29:19 <JordiGH> Huh?
06:29:21 <Orphi> once the VM software is installed... sure.
06:29:31 <JordiGH> Oh, right.
06:29:48 <Orphi> I used to use QEMU, which doesn't require being "installed".
06:29:53 <JordiGH> Hm, depends on the VM software, I reckon.
06:29:54 <Orphi> but it's slower than a glacier...
06:29:55 <tensorpudding> maybe if you're installing a host in xen or something
06:30:10 <tensorpudding> it would require a reboot
06:30:13 <ulfdoz> qemu gets damn fast with kvm.
06:30:22 <Orphi> ...which would require installing ;)
06:30:26 <ulfdoz> However, that requires Hardware-Support.
06:30:36 <McManiaC> is it possible to load content dynamicly into you main function without restarting it?
06:30:42 <tensorpudding> yeah, i use qemu without kvm
06:30:48 <Orphi> I wanted to put Linux onto a USB stick and use it anywhere.
06:30:49 <JordiGH> ulfdoz: If you have a processor that supports.
06:30:55 <Orphi> and you *can*, but... you won't. ever.
06:31:09 <McManiaC> hehe
06:31:23 <Orphi> I use VMware Workstation at work. It's quite nice.
06:31:30 <Orphi> I'm using VirtualBox at home. It's less nice.
06:31:46 <JordiGH> VMware is non-free ;_;
06:31:54 <JordiGH> inb4 gratis
06:32:08 <Orphi> VMware is not only non-free, but *expensive*. ;)
06:32:15 <Orphi> I guess my job does have a few tiny perks...
06:32:23 <tensorpudding> is the gratis VMWare significantly faster than QEMU?
06:32:27 * JordiGH doesn't consider tha a perk.
06:32:37 <tensorpudding> assuming you don't have KVM support
06:34:24 * Orphi doesn't consider his job good.
06:37:09 <Orphi> I would think that any VM that uses hardware support is faster than QEMU without hardware support.
06:37:41 <tensorpudding> how can VMware use the virtualization extensions if they aren't available on the hardware?
06:38:01 <Orphi> it can't.
06:39:15 * Orphi beginning to regret compiling gtk2hs.
06:45:30 <heatsink> Anyone here know why GHC doesn't allow GADT newtypes?
06:46:23 <benmachine> how would that work and what would be the point
06:47:46 <heatsink> Well, it would work the same as ordinary newtypes: one type is interpreted as another
06:48:15 <heatsink> The point is when you have a parametric type that only makes sense at some specific instantiation of its parameters
06:49:33 <heatsink> I'm using the following: data WhnfWrapped t s where WhnfWrapped :: t s -> WhnfWrapped t (Whnf s)
06:49:57 <heatsink> The type 't' is pretending to be a container type holding (Whnf s), but it actually holds s
06:52:19 <benmachine> pass
06:53:13 <benmachine> (it looks to me like ghci fails at tab-completing operators)
06:53:56 <benmachine> (when you try to tab-complete an operator you get all the in-scope variables as well, fine, but you also get all the in-scope operators even though they wouldn't work there)
06:54:51 <benmachine> (it would probably be more DWIM to assume you're going to leave space between your operators and operands, but even if not the operators could still be fixed a little)
06:55:19 <heatsink> Aren't operators usually three or fewer characters long?
06:55:27 <benmachine> yes
06:55:42 <benmachine> but I use tab-completion as a spell check of sorts
06:55:49 <benmachine> an easy way of finding out if something is in scope or not
06:56:03 <heatsink> o i c
06:59:14 <Blablaw> hi all
06:59:18 <Blablaw> anyone from iceland?
07:01:01 <heatsink> I'm not from Iceland, but I've been wondering something.  Is Icelandic ? really pronounced as an alveolar, rather than dental, consonant?
07:01:17 <benmachine> icelandic question mark?
07:01:29 <benmachine> good old unicode.
07:01:30 <heatsink> eth
07:01:59 <heatsink> I accidentally picked uppercase instead of lowercase eth.
07:02:14 <heatsink> Oh well.  I guess I'll never know.
07:06:26 <MisterN> heatsink: there was an icelander here a while ago
07:06:42 <MisterN> well, not in this channel but on freenode
07:07:14 <MisterN> so it might not be impossible to find out. just unlikely.
07:07:54 <heatsink> ...okay...
07:10:29 <cooleSache> Nur ne Kleine Frage, kennt den jemand? http://www.facebook.com/photo.php?pid=3629610&id=266453492661
07:14:13 <damd`> what makes erlang a "functional" language?
07:16:34 <tensorpudding> depends on your definition of functional
07:18:19 <damd`> does it have higher-order functions?
07:20:12 <tensorpudding> don't know that one
07:20:27 <damd`> i would have expected lots of comments about this from #haskell :|
07:20:34 <tensorpudding> i've never used erlang
07:24:33 * hackagebot darcs-monitor 0.3.8 - Darcs repository monitor (sends email)  http://hackage.haskell.org/package/darcs-monitor-0.3.8 (MarcoSilva)
07:31:27 <DerisionSnort> Is there something like this in the standard libary?
07:31:27 <DerisionSnort> f `by` g = f . map g
07:31:46 <damd> :t f . map g
07:31:47 <lambdabot>     Ambiguous type variable `b' in the constraints:
07:31:48 <lambdabot>       `Show b' arising from a use of `f' at <interactive>:1:0
07:31:48 <lambdabot>       `SimpleReflect.FromExpr b'
07:31:49 <damd> darn
07:32:27 <arjanb> :t \f g -> f . map g
07:32:28 <lambdabot> forall b a b1. ([b1] -> b) -> (a -> b1) -> [a] -> b
07:32:34 <DerisionSnort> This allows code like "sum `by` age" for example
07:32:43 <damd> @hoogle ([b1] -> b) -> (a -> b1) -> [a] -> b
07:32:43 <lambdabot> Data.Generics.Aliases ext1Q :: (Data d, Typeable1 t) => (d -> q) -> (t e -> q) -> d -> q
07:33:56 <heatsink> :k (~)
07:33:57 <lambdabot> parse error on input `~'
07:34:07 <DerisionSnort> Of course .map and `by` both are four characters long, but I find `by` a lot more readable
07:43:58 * Lycurgus wenn Sie dies lesen konnten es sollte "DerisiveSnort" sein.
07:50:20 <Erica1981> hi
07:50:35 <Erica1981> what is haskell
07:50:49 <damd> the slowest programming language ever
07:51:09 <Erica1981> ok))
07:51:42 <Erica1981> is anybody here likes offtopic? becose i hate offtopic
07:51:43 <pastorn> Erica1981: you can't do shit in it... all you get is type errors
07:51:48 <Saizan> oh, don't take that from ruby, they'll feel hurt
07:51:56 <pastorn> Erica1981: we have #haskell-blah for that :)
07:51:57 <burp> the debian language shootout says something else
07:52:11 <damd> if you want to learn haskell you must understand monads - monads are very very difficult to use! they are magical.
07:52:21 <pastorn> hahahhahaha
07:52:29 * pastorn can't stop laughing
07:52:34 <pastorn> damd: NICE :D
07:52:39 <burp> 
07:52:40 <Erica1981> ah... first i need to learn english)))
07:52:42 <damd> feeding the trolls on a very special sunday afternoon.
07:52:55 <mauke> no, john. you are the trolls.
07:53:14 <pastorn> Erica1981: do you know any programming languages?
07:53:14 <Erica1981> damd ??? Do you have some food??? I am hungry...
07:53:31 <Erica1981> pastorn BASIC))))
07:53:45 <mauke> @where basic
07:53:45 <lambdabot> I know nothing about basic.
07:53:45 <damd> Erica1981: do you like Sunn O)))?
07:53:47 <pastorn> Erica1981: you're in for a ride :)
07:54:06 <damd> Erica1981: augustsson wrote BASIC for haskell, so it's all good
07:54:14 <Erica1981> damd i dont know what is sunn
07:54:29 <damd> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/BASIC-0.1.5.0
07:54:51 <pastorn> Erica1981: and you've got IFs, though in haskell you ALWAYS have to say 'if someBool then x else y'
07:55:02 <mauke> http://augustss.blogspot.com/2009/02/more-basic-not-that-anybody-should-care.html
07:55:02 <pastorn> there's no IF without an ELSE
07:55:23 <damd> does BASIC have "else" btw?
07:55:40 <Erica1981> no.. to difficult to me.. i am not programmer..
07:56:06 <pastorn> damd: maybe they do it by if b {...} if !b {...}
07:56:26 <pastorn> Erica1981: they're just messing with you
07:56:27 <mauke> pastorn: dude, learn about goto
07:56:29 <damd> pastorn: i was thinking something like IF x THEN y\nGOTO somewhere
07:57:09 <pastorn> damd: no COMEFROM?
07:57:10 <Erica1981> pastorn i dont care))) i hardly can translate it)))
07:57:20 <damd> pastorn: not in BASIC98, no :)
07:57:24 <burp> what are these ")))"?
07:57:32 <damd> parentheses
07:57:36 <burp> funny
07:57:38 <damd> apparently Erica1981 uses lisp
07:57:52 <pastorn> damd: apparently :))))))
07:58:01 <Erica1981> v ))) it is a spesial command in BASIC - it kills all human
07:58:06 <mauke> M-M-M-MULTICHIN
07:58:17 <Erica1981> *c
07:58:57 <damd> Erica1981: what is your favourite feature about basic?
07:59:11 <mauke> THE CONSTANT SHOUTING
07:59:19 <Alpounet> haha
07:59:46 <damd> shouting is for side effects i suppose
07:59:55 <Erica1981> damd if then else
08:00:06 <danderson> haskell would tend to validate that theory
08:00:10 <danderson> since all side-effects occur in IO
08:00:11 <damd> Erica1981: troll fail, there is no else in basic
08:00:40 <danderson> screaming orders down to the I/O controllers on the motherboard
08:00:41 <damd> okay, my bad, there is
08:00:44 <Erica1981> damd no, it is you stupid troll))) becose there is ELSE hahahahahahaha
08:00:49 <damd> hahaha
08:01:41 <Erica1981> damn nerev mind )))
08:01:46 <Erica1981> never
08:02:47 <benmachine> what the hell is going on
08:03:00 <pastorn> benmachine: trolling bonanza
08:03:02 <damd> trolls looking to exchange their changelings
08:03:08 <benmachine> augh
08:03:13 * benmachine disapproves
08:03:17 <damd> this is a pretty funny troll though
08:03:22 * pastorn desapproves of benmachine
08:03:26 <benmachine> touché
08:03:32 <pastorn> baradish
08:03:38 <damd> hiyoooo
08:03:41 * shepheb >:-C
08:03:44 <Erica1981> who is troll?? i dont see !!!
08:03:57 <pastorn> i like this :)
08:03:58 * Lycurgus wonders if Erica1981 knows Ludmilla, I get a lot of email from her.
08:03:59 <damd> )))
08:03:59 <nlogax> how is troll formed
08:04:01 <pastorn> serious sunday
08:04:16 <cheater2> how is troll formed?
08:04:31 <Erica1981> I am not Ludmila, 100%
08:04:35 <damd> hahahahaha
08:04:42 <pastorn> hehehe
08:04:45 <pastorn> Erica1981: no homo
08:05:37 <Erica1981> pastorn ??? what that mean? that do you wanna homo?
08:05:50 <pastorn> no homo
08:05:57 <benmachine> just iso?
08:06:06 <damd> стоп тролинг, трол
08:06:15 <Erica1981> A TUT VOOBSHE SWOI EST"????????
08:06:19 <xerox> what is going on here
08:06:25 <pastorn> anyone else here but me who plays forumwarz?
08:06:27 <benmachine> xerox: something unpleasant, it seems
08:06:39 <pastorn> xerox: serious sunday
08:06:49 <Erica1981> xerox DO YOU CAN TALK??? Oh MY BRAIN
08:06:53 <damd> Erica1981: до у лике то смека дицкен
08:06:55 <burp> omg, move that to #haskell-blah
08:06:57 <benmachine> I can't remember which one is everywhere'
08:07:05 <xerox> damd: could you please stick to english in #haskell ?
08:07:15 <damd> i will, sorry about that
08:07:29 <Erica1981> damn no!!!!! i am not faggot as you!!!!
08:07:34 <gwern> we accept only three languages here: haskell, english, and math
08:07:54 <Erica1981> gwern 2+2=?
08:08:04 <burp> I think it's enough
08:08:07 --- mode: ChanServ set +o xerox
08:08:09 <gwern> Erica1981: ||||
08:08:14 <benmachine> > let 2 + 2 = 5 in 2 + 2
08:08:15 <lambdabot>   5
08:08:40 <damd> what benmachine just did involves monads, they let you do everything in haskell... to learn haskell you must use monads which is very hard.
08:08:46 <benmachine> oh stop it
08:08:50 <benmachine> all of you
08:08:54 <gwern> damd: it does not
08:09:14 <pastorn> Erica1981: homo?
08:09:19 <mauke> damd: stop trolling
08:09:25 <Erica1981> no!!! 2+2=group sex!!! not 5
08:09:33 <damd> mauke: i'm only counter-trolling, but yeah, we've all had enough i suppose
08:09:37 <Erica1981> maybe after 9 month
08:09:42 <gwern> -_-
08:09:55 <pastorn> Erica1981: /join #haskell-blah
08:12:40 <Erica1981> 8)
08:13:27 <Erica1981> eternity.......
08:15:44 <Erica1981> is anybody still here? or all die?
08:15:51 <pastorn> Erica1981: DEDD
08:16:00 <cheater2> deeeeed
08:16:06 <Erica1981> DEDD what is it i cant translate
08:16:08 <nlogax> all die, fly to sky
08:16:18 <pastorn> @faq can haskell kill people?
08:16:18 <lambdabot> The answer is: Yes! Haskell can do that.
08:16:19 <Erica1981> fly to Pandora!!!!!!!
08:16:35 <Erica1981> We kill all navi's!
08:16:36 <cheater2> @faq can haskell form babby?
08:16:36 <lambdabot> The answer is: Yes! Haskell can do that.
08:16:43 <pastorn> haha
08:16:43 <damd> Erica1981: are you a раб?
08:16:45 <Erica1981> Using haskell
08:17:06 <Erica1981> damn of course not! stupid
08:17:20 <cheater2> what is pa\sigma?
08:17:27 <pastorn> damd: pa6?
08:17:35 <damd> that's cyrillic, i think it means slave
08:17:41 <damd> russian rather
08:17:42 <danderson> http://donotfeedtheenergybeast.com/
08:18:08 --- mode: xerox set +b *!*@ppp7-252.tis-dialog.ru
08:18:20 <xerox> let's take the energy out of the beast for 1h or something
08:18:25 <pastorn> danderson: haha, nice
08:18:28 <danderson> xerox: thanks.
08:19:23 <cheater2> we're on irc
08:19:27 <cheater2> the only winning move is /quit
08:19:58 <pastorn> Erica1981: http://www.youtube.com/watch?v=YIAnkrPgTvY
08:20:19 <Saizan> the good old tradition of overflowing trolls with in-topic informations is lost?
08:20:23 <danderson> not really. The winning move is /ban and getting on with it.
08:20:37 <xerox> Saizan: I guess it's because it's sunday
08:20:51 <danderson> and on that enlightened note from Saizan, what are good starting points for time/space profiling in Haskell?
08:20:55 <tensorpudding> sunday, floody sunday
08:21:04 <Saizan> ?google ghc profiling
08:21:05 <lambdabot> http://haskell.org/ghc/docs/latest/html/users_guide/profiling.html
08:21:06 <lambdabot> Title: Chapter�5.�Profiling
08:21:14 <danderson> so far I'm still busy writing the code, but eventually once it's running I'll need to tighten it up
08:21:27 <gwern> tensorpudding: don't you mean, 'sunday, bloody sunday'?
08:21:33 <danderson> ah, wonderful. Clearly I should RTFM
08:21:35 <danderson> Saizan: thanks!
08:21:35 <tensorpudding> it was a pun
08:21:40 <pastorn> gwern, tensorpudding: if you know swedish that song is hilarious!
08:21:43 <Saizan> danderson: np :)
08:21:49 <tensorpudding> on how we were being flooded by trolling
08:22:00 <gwern> pastorn: everything is hilarious in the scandinavian languages
08:22:08 <tensorpudding> i don't actually know the words to the song
08:22:09 <gwern> because it sounds like you're always being obscene or cursing
08:22:12 <pastorn> he doesn't sing "sunday, bloody sunday", he sings "små negrer i sanden" == "small negros in the sand"
08:22:28 <damd> way to promote scandinavia pastorn!
08:22:37 <pastorn> damd: you know it!
08:22:40 <gwern> pastorn: why does he sing that
08:22:51 <pastorn> gwern: don't ask me, i didn't write it
08:23:12 <Erica1981new> Xerox did i ever tell you, that you are an faggot???7
08:23:19 <tensorpudding> isn't sunday bloody sunday about the troubles?
08:23:35 <pastorn> but once you know that he sings it, you can never again here "sunday, bloody sunday"... all i see now is black children buried to their necks in a sandbox
08:23:36 --- mode: xerox set +b *!*@ppp*.tis-dialog.ru
08:23:43 --- mode: xerox set -b *!*@ppp7-252.tis-dialog.ru
08:24:04 <tensorpudding> who made a swedish version anyway
08:24:24 <pastorn> tensorpudding: nono... that's what you hear, listening to him singing in english :)
08:24:25 <danderson> Erica1981new: your repentance speech is rejected, apparently.
08:24:46 <pastorn> awwww
08:24:48 --- kick: Erica1981new was kicked by xerox (Erica1981new)
08:25:25 <tensorpudding> oh
08:25:44 <tensorpudding> so if you don't know swedish, and you hear the swedish version, it sounds funny
08:26:01 <mauke> did you mean: english
08:26:11 <pastorn> tensorpudding: now we're explaining the joke... so it won't be funny
08:26:54 <pastorn> if you know swedish, and you hear bono singing it in english, then you can hear him singing "small negros in the sand" instead of the actual lyrics
08:27:13 <pastorn> tensorpudding: >:(
08:27:18 <tensorpudding> what?
08:27:36 <pastorn> NEVERMIND
08:27:37 <tensorpudding> so when you hear someone singing in english, you mentally translate it to swedish?
08:27:42 <pastorn> yes
08:27:51 <mauke> "translate"
08:28:23 <tensorpudding> so you don't actually think in english when you hear english?
08:29:31 <mauke> http://www.albinoblacksheep.com/flash/yatta
08:29:54 <pastorn> tensorpudding: ^^^
08:30:33 <roconnor> >3^(1/13)
08:30:35 <roconnor> > 3^(1/13)
08:30:36 <lambdabot>   Ambiguous type variable `t' in the constraints:
08:30:37 <lambdabot>    `GHC.Real.Fractional t'
08:30:37 <lambdabot> ...
08:30:43 <roconnor> > 3**(1/13)
08:30:44 <lambdabot>   1.0881822434633168
08:30:48 <roconnor> > 2**(1/12)
08:30:49 <lambdabot>   1.0594630943592953
08:35:57 <mxc> hi
08:37:41 <roconnor> hi
08:38:35 <pastorn> sup?
08:40:36 <mxc> just wondering if there is a simple way to get the curl bindings building under windows
08:40:41 <mxc> but i've pretty much given up
08:40:46 <mxc> and I think its vbox + arch
08:47:59 * hackagebot barchart 0.1 - Creating Bar Charts in Haskell  http://hackage.haskell.org/package/barchart-0.1 (SebastianFischer)
08:50:00 * hackagebot barchart 0.1.1 - Creating Bar Charts in Haskell  http://hackage.haskell.org/package/barchart-0.1.1 (SebastianFischer)
08:57:27 <toymakerii> So I am new to Haskell and I am trying to work out some datatype issues, anybody willing to look at my stack implementation
08:58:09 <Lemmih> toymakerii: maybe...
08:59:50 <toymakerii> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23309#a23309
09:00:19 <toymakerii> I am using Hugs and Haskell 98, I seem to be getting a compile error on the pop term
09:00:25 <danderson> ugh, not good
09:00:30 <toymakerii> ??
09:00:41 <danderson> if haskell can't keep up with reading data out of tun/tap devices, eventually the file handle just goes bad
09:00:46 <danderson> and crashes the haskell process
09:00:51 <Lemmih> toymakerii: Try: error "Can't pop an empty stack."
09:01:19 <danderson> which occurs after about 64 packets of a flood ping
09:02:09 <ulfdoz> Hier war es den ganzen Tag khl und sonnig.
09:02:12 <ulfdoz> ewin
09:02:30 <Lemmih> toymakerii: It's recommended that you also post error messages together with any defunct code.
09:02:45 <toymakerii> Lemmih: THat seems to have worked
09:03:05 <toymakerii> :Lemmih my appologies, thank you sir
09:03:09 <toymakerii> Lemmih++
09:43:31 * jmcarthur is thinking about trying to make a better gpipe
09:47:25 <Alpounet> jmcarthur, tell us more 'bout that
09:48:11 <jmcarthur> Alpounet: well, you are aware of what gpipe is, right?
09:51:43 <jmcarthur> Alpounet: my goals are to make a strictly simpler and more expressive interface and retain at at minimum the efficiency of gpipe as it already exists
09:51:51 <danderson> what's the cabal option to tell it to always build profiling versions of libraries again?
09:52:32 <jmcarthur> Alpounet: the simplest change i want is to use a different vector type, but i'd also like to experiment with embedding the lambda calculus into it, and i would like to make it more testable and decoupled from glut
09:53:32 <danderson> nvm, found it
09:53:35 <jmcarthur> Alpounet: and ultimately i would like a high level graphics library, but i might just copy somebody else's semantics for that
09:54:09 <Alpounet> jmcarthur, yeah I know gpipe.
09:54:27 <jmcarthur> Alpounet: the high level graphics library might be slower coming. i'm getting back into just trying to make a game. i would like to work with shaders and gpipe just seems too clumsy to me
09:54:42 <Alpounet> jmcarthur, have you seen drawing-combinators, gluss and all ?
09:55:09 <jmcarthur> Alpounet: yes. i don't really like gloss that much, but graphics-drawingcombinators is pretty good
09:56:48 <solistic> Is there a way to see whether ghci was linked with editline or readline?
09:57:31 <jmcarthur> Alpounet: oh, and while i don't think i can hide the different units of the graphics pipeline while still staying low-level enough to still be just a nicer shader interface, i think i could maybe simplify what gpipe does
09:57:44 <jmcarthur> at least i hope i can
09:57:58 <jmcarthur> it's not so bad as it is. it's just difficult to pick up
09:58:16 <MaciejP> What was the name of the package that helps improving the code? I thought it was `hint' but it wasn't.
09:58:22 <ben> hlint
09:58:37 <MaciejP> Ah thanks
09:59:41 <Alpounet> jmcarthur, I LOVE the combinator approach to stuffs
09:59:54 <Alpounet> it has proven to be incredibly powerful
10:00:01 <Alpounet> and flexible
10:00:25 <Alpounet> jmcarthur, if you start something, please tell me :)
10:01:51 <jmcarthur> gpipe appears to have you wrap a bunch of vertices up, manipulate them there, convert to fragments, manipulate them there, then rasterize them to a framebuffer. i'd like to make it such that you create a function that does all the manipulation and then you feed it a collection of vertices and get a framebuffer. (yeah this is on the level of the shader api still, but i think it might be nicer than
10:01:53 <jmcarthur> gpipe's model at least)
10:02:28 <jmcarthur> at least this way would make it more clear what is done on the gpu and what is done on the cpu
10:02:32 <Alpounet> I agree
10:02:39 <Alpounet> if the library can take care of more things
10:02:47 <Alpounet> and just let you combine different functionalities, that's great
10:04:36 <toymakerii> alright, now I am writing a test class, which isn't working. any suggestions :  http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23309#a23312
10:04:49 <jmcarthur> Alpounet: well, i've started a project
10:04:51 <toymakerii> I have got to be an idiot, this stuff should be easy
10:05:15 <jmcarthur> Alpounet: i'm just working with the api and a pure haskell implementation at the moment (which i will probably keep around so you can test your generic code with quickcheck and such)
10:05:25 <jmcarthur> via type classes, i mean
10:05:37 <jmcarthur> i'm giving the finally tagless approach a shot
10:05:50 <Alpounet> jmcarthur, where is it ?
10:05:53 <Alpounet> github ?
10:06:05 <jmcarthur> Alpounet: nowhere yet. i just started it today
10:06:20 <jmcarthur> Alpounet: it will be on patch tag when i finally put it up though
10:07:24 <jmcarthur> anyway, i think it's time to go shoe shopping (joy). be back later
10:07:32 <Alpounet> heh ok
10:07:32 <Alpounet> keep me posted please
10:07:39 <jmcarthur> will do
10:08:38 <toymakerii> did anyone coming from an imperative languages find functional this frustrating?  (when they started this)
10:09:11 <MaciejP> toymakerii: You are using the do-notation on lists, so in a statement `x <- xs' the xs has to be a list. But in `ns <- pop s' pop s is not a list.
10:10:07 <toymakerii> MaciejP: . . . so I can only use do-notation on one type?
10:10:50 <MaciejP> toymakerii: You can use it on all monads, like [a], IO a, ...
10:10:52 <dobblego> toymakerii, all people who come from imperative languages find it frustrating
10:11:10 <Ian_Corne> I came from imperative, learned declarative first semester, functional this one
10:11:15 <Ian_Corne> it's refreshing :)
10:11:17 <toymakerii> MaciejP: ok I will try to rewrite it
10:11:43 <MaciejP> But I think using the do-notation on lists make things unnecessarily compilcated here.
10:11:48 <toymakerii> dobblego, Ian_Corne: I am in grad school, just started Scheme and Haskell
10:11:53 <shepheb> Ian_Corne: which languages?
10:12:03 <dobblego> toymakerii, try to forget everything you knew
10:12:20 <toymakerii> MaciejP: I was going to change it to: return (stackToList (pop s) ((top s) : l))
10:12:25 <SamB_XP> I used to find the lack of choice of monads a pain in other languages ... but had no actual idea what it was that was missing ;-)
10:13:17 <toymakerii> Haskell and Scheme are just tough for me to learn, I write in alot of Imperative and Declarative languges
10:13:31 <Ian_Corne> shepheb: scheme->C++->java,ambient talk,smalltalk,ruby->prolog->haskell
10:13:59 <MaciejP> toymakerii: But then you are still in a monad. return is of type (a -> m a) where m is a monad.
10:14:00 <SamB_XP> Ian_Corne: what do the arros signify ?
10:14:09 <Ian_Corne> year transitions
10:14:19 <Ian_Corne> 1e bachelor, 2nd, 3rd, and now in my first master
10:14:27 <Ian_Corne> the last arrow is a semester transition :p
10:16:20 <toymakerii> MaciejP:Holy Smoke!  It worked.  I removed the "returns" and the "do"
10:18:10 <MaciejP> toymakerii: Does it just typecheck or also do what you want?
10:20:29 <toymakerii> maciejp: both,  it compiles and then when I run I get a list as output.
10:20:44 <toymakerii> maciejp: its a small part of a FORTH interpreter I am trying to write
10:25:00 <Eelis> do i understand correctly that the "theorems for free" business is really just the observation that parametrically polymorphic functions in haskell are always natural transformations?
10:28:14 <byorgey> Eelis: that's the idea to a first order approximation (and a very good intuition), but free theorems encompass much more than that
10:28:33 <Eelis> oh, interesting. then i'll have to read some more :)
10:29:25 <byorgey> try reading some of Janis Voigtlaender's recent work on free theorems in more general contexts
10:29:35 <Eelis> alright, i will
10:31:13 <danderson> so, um, I just recompiled my binary for profiling, and ran it +RTS -p
10:31:19 <danderson> and I get only space profiling, not time
10:31:42 <danderson> that is, my program apparently took 0.0s to run, and all cost centres account for 0% of runtime
10:32:31 * hackagebot binary-shared 0.8 - Sharing for the binary package  http://hackage.haskell.org/package/binary-shared-0.8 (JuergenNicklischFranken)
10:32:47 <benmachine> is it a really really good algorithm
10:33:07 <benmachine> alternatively, did you compile it with -auto-all
10:33:32 * hackagebot ltk 0.8 - Leksah tool kit  http://hackage.haskell.org/package/ltk-0.8 (JuergenNicklischFranken)
10:39:33 * hackagebot haddock-leksah 2.5.0 - A documentation-generation tool for Haskell libraries  http://hackage.haskell.org/package/haddock-leksah-2.5.0 (JuergenNicklischFranken)
10:41:34 * hackagebot haddock-leksah 2.6.0 - A documentation-generation tool for Haskell libraries  http://hackage.haskell.org/package/haddock-leksah-2.6.0 (JuergenNicklischFranken)
10:42:45 <danderson> benmachine: yes, compiled with -auto-all -caf-all
10:43:08 <danderson> my next guess is going to be that being on a Xen VM is messing up the timing code somehow
10:44:48 <ulfdoz> s/du/die/
10:44:49 <ulfdoz> ewin
10:47:37 * hackagebot leksah-server 0.8 - Metadata collection for leksah  http://hackage.haskell.org/package/leksah-server-0.8 (JuergenNicklischFranken)
10:52:41 * hackagebot leksah 0.8 - Haskell IDE written in Haskell  http://hackage.haskell.org/package/leksah-0.8 (JuergenNicklischFranken)
11:09:22 <devinus> is there an actively maintained modern haskell web framework perhaps using some of the cool new concurrency features being put into haskell?
11:09:55 <Ke> now there are cool concurrency features?
11:10:25 <Ke> data parallelism is something like early middle ages
11:11:35 <mux> haskell is so great... I went from reading about BK trees in a blog post to an implemntation so quickly
11:11:40 <mux> http://gist.github.com/324563
11:12:13 <mux> do you guys like it?
11:13:56 <dobblego> you need to write levenshtein instance for MetricSpace!
11:14:03 <mux> yes, I do
11:14:05 <dobblego> also, I'd consider a data type rather than a type class
11:14:21 <mux> yes, that's still open to debate in my mind
11:14:24 <dobblego> note there is a bk-tree on hackage
11:14:35 <devinus> Ke: ?
11:14:41 <mux> hah, great, I'll see how it looks
11:15:41 <mux> wow, scarily close
11:16:02 <mux> hmmm, why does he keep an Int value in each node?
11:16:14 <mux> for size
11:16:20 <mux> this can be deduced from the IntMap
11:16:22 <mux> oh well
11:16:51 <mux> dobblego: the implementation on hackage also uses a type-class
11:16:59 <dobblego> yes
11:17:01 <mux> this is going to be awkward for implementing String instances, of course
11:17:51 <dobblego> I think you want (Eq a) => [a] instance
11:20:39 <gwern> :t 1.0
11:20:40 <lambdabot> forall t. (Fractional t) => t
11:23:08 <mux> dobblego: I think I'll just have a ByteString instance for now ;-)
11:23:21 <mux> besides, using String for that kind of work would probably be very inefficient
11:23:40 <dobblego> ok
11:29:18 <mux> dobblego: the hackage version doesn't seem to implement "inexact" lookups as with my query function, am I missing something?
11:52:39 <danderson> okay, so when I run my program under -p, with -auto-all profiling, I don't get any timing information, only space information. The program runs way longer than the 20ms ticks that the profile report mentions.
11:52:43 <danderson> Help?
11:55:14 <gloob_> hello..I am haskell n00b and I wonder what '$=' does..can you help me please?
11:55:38 <ben> gloob_: Not a standard operator, check relevant library documentation :)
11:56:31 <byorgey> gloob_: where did you see this?
11:56:51 <aavogt> probably in the opengl binding
11:57:00 <aavogt> @hoogle ($=)
11:57:00 <lambdabot> No results found
11:57:09 <gloob_> right it was in some opengl source code
11:57:20 <gloob_> thanks
11:57:56 <sshc> how do I do the inverse of spaces (many1 . satisfy $ not isSpace) with parsec?
11:58:14 <mauke> ... like that?
11:59:20 <sshc> mauke: huh.
11:59:25 * sshc remembers to think more
11:59:38 <aavogt> you want parsec to unparse?
11:59:43 <aavogt> to pretty-print?
11:59:55 <sshc> I want it to parse anything that's not whitespace
12:01:41 <sheikra> hey. I'm studying SPJ's paper "imperitive functional programming". I used to think case expressions are the places where computation really happens, but it seems not to be the case?
12:02:30 <djahandarie> (No pun intended.)
12:03:10 <MaciejP> sshc: many1 $ noneOf [' ', '\t', ...] ?
12:03:12 <aavogt> sheikra: so where does it happen then?
12:03:14 <sheikra> I mean, doesn't case force the evaluation of its cargument?
12:03:42 <aavogt> > case undefined of _ -> "no"
12:03:43 <lambdabot>   "no"
12:04:08 <sheikra> aavogt: oh ...
12:04:37 <aavogt> though if you're more specific that pattern matching in a case expression does it, then you're right
12:05:00 <aavogt> > case undefined of Just _ -> "no"
12:05:01 <lambdabot>   "* Exception: Prelude.undefined
12:05:13 <sheikra> aavogt: they have this example about "world": case (mw) of MkIORes a -> ka w
12:05:47 <sheikra> So in order to do the pattern matching, does (m w) need to be evaluated?
12:07:02 <aavogt> it needs to be evaluated enough to know that it has a MkIORes constructor
12:07:41 <sheikra> hmmm...
12:07:50 <ddarius> Unless MkIORes was a newtype constructor.
12:09:48 <sheikra> So this example says "If (m w) can be evaluated to know there is a MkIORes and a value, and k ignore its arguments, then the evaluation of m and k could happen in any order"... that makes sense.
12:11:52 <aavogt> ddarius: aren't newtypes sort of redundant if you're allowed strictness annotations on data constructors?
12:12:55 <damd> no, newtypes are homomorphic to the type that they wrap, whereas data constructors can never have a morphism to that category
12:13:04 <sheikra> but how does the example compare with the original definiton of BindIO m k w = case (m w) of MkIORes a w' -> k a w' ?
12:13:58 <sheikra> damd: Do you mean that newtypes exist only logically and not in the runtime code?
12:14:15 <damd> what i just said was randomly chosen words, i have no idea what that means
12:14:28 <aavogt> damd: so there's a difference in program operation if you substitute for   `newtype A a = A a'   `data A a = A !a'?
12:14:58 <damd> aavogt: sorry, i have no idea
12:15:01 <sheikra> aavogt: yes. You have a constructor in the latter but not the former
12:15:14 <maltem> aavogt, a pattern match on a newtype will always suceed
12:15:43 <aavogt> maltem: but doesn't that data also always succeed?
12:16:08 <maltem> With  data A a = A !a,  a pattern match will diverge whenever the value is _|_
12:16:19 <ddarius> aavogt: Yes.
12:16:31 <maltem> or did I get this wrong? Let me check
12:16:35 <ddarius> newtypes and strict data are subtly different.
12:17:03 <ddarius> maltem: That's correct.
12:17:12 <ddarius> The Report has a good section on this.
12:18:23 <maltem> ok.
12:18:29 <sheikra> ddarius: I think my explanation is quite intuitive. data will put a constructor in the data object, while newtype does not
12:19:39 <sheikra> oh, I digressed. is anybody interested in my queston about "world" for IO?
12:20:58 <sheikra> I can't seem to justify the existence of the "real world" in the IO monad.
12:21:56 <ddarius> sheikra: I don't even know what you mean by "put a constructor in the data object."
12:22:28 <sheikra> ddarius: I mean a tag in the data, so that case can match the constructor.
12:22:29 <ddarius> Anyway, the Report covers this here http://haskell.org/onlinereport/decls.html#datatype-renaming and here http://haskell.org/onlinereport/exps.html#pattern-matching
12:23:24 <sheikra> ddarius: That'll happen if you have more than one variants like data T a = A !a | B !a
12:24:05 <sheikra> but maybe data with only one variant can be optimized so as to remove the runtime tag?
12:24:13 <ddarius> sheikra: Sure it can.
12:24:34 <ddarius> Also, GHC, for example, didn't use "tags" before and doesn't always now.
12:25:16 <sheikra> ddarius: But case needs "tags" (or maybe I'm using the wrong word)
12:26:34 <sheikra> ddarius: The constructors for the variants will each result in a tag in the runtime data, if I imagined it correctl
12:27:31 <sheikra> for example data T a = A a | B a. will put two different tags in the data, so that we can know what elements we are getting from a list of type [T].
12:28:04 <sheikra> sorry I miss an argument the type should be something like [T Int]
12:29:26 <sheikra> but maybe data A a = A !a is really the same as newtype?
12:29:27 <ddarius> sheikra: They'll have to be differentiated some way, but they don't need "tags" to do it, though that's one method.
12:29:38 <ddarius> sheikra: It isn't.
12:29:41 <Gracenotes> sheikra: I believe, because of laziness, the list element might only be 'created' when you lazily need it, so GHC skips the whole tagging business and just sends the data to where it needs to go.
12:30:01 <ddarius> Another way is to use a method similar to dynamic dispatch in OO languages.
12:30:25 <Gracenotes> with just the knowledge of the A-data-handler and the B-data-handler
12:31:06 <sheikra> Gracenotes: but how do we know whether it is A-data or B-data?
12:31:15 <ddarius> sheikra: The representations of data A a = A !a and newtype A a = A a might be the same, but that doesn't mean they behave the same.
12:31:55 <sheikra> ddarius: can I say that they are the same after an optimization on data with only one variant?
12:32:00 <ddarius> (Incidentally, the Report requires that the representation of a newtype be the same as its underlying type.)
12:32:11 <Gracenotes> sheikra: you evaluated it far enough to know what constructor the user put in their code
12:32:56 <sheikra> Gracenotes: but doesn't the user need to put the constructor information somewhere in the data?
12:33:33 <ddarius> sheikra: Newtype and strict data aren't the same, even if they may (or may not) have the same representation.
12:34:19 <sheikra> ddarius: ahh. I see, newtype doesn't need to be strict!
12:34:20 <aavogt> well if you wrote all strict-one-constructor data matches with ~, they would behave the same
12:34:50 <ddarius> sheikra: No, that's not it.  It doesn't make sense to talk about a "lazy" newtype.
12:36:13 <sheikra> well. I'd better get my question back here. Can anybody tell me the difference between two different bindIO: case (m w) of MkIORes a -> k a w and case (m w) of MkIORes a w' -> k a w'? Does the "world" (w) make any difference in the evlauation order here?
12:36:57 <sheikra> ddarius: What I meant is that it doesn't need to be forced to a value
12:39:10 <sheikra> ddarius: so that's what maltem mentioned. pattern matching of newtype always succeed... what a relelation! :)
12:39:17 <ddarius> The difference between newtype and strict one field data, e.g. between newtype N a = N a and data D a = D !a is simply and only the equation: case undefined of N _ -> True === True and case undefined D _ -> True === undefined.  There is no other way to tell the difference within Haskell.
12:40:02 <korstya> hello all. can anybody help me please? I have got a seg. fault while executing c++ code. I try to run libcurl.
12:40:19 <ddarius> The Report also says that a newtype must have the same underlying representation but there is no way for the Report to actually enforce that.
12:40:20 <mauke> korstya: how is that a haskell question?
12:40:34 <korstya> mauke: I try to run it from haskell
12:40:42 <korstya> in c++ it works ok
12:41:00 <sheikra> ddarius: I think that means newtype only exist logically ...
12:41:08 <korstya> I build a lib to import it from haskell
12:41:32 <ddarius> sheikra: Yes, newtypes are figments of the type checkers imagination.  Once type checking is complete, newtype can be erased.
12:41:44 <sheikra> ddarius: I still think there needs a tag in data A a = A !a
12:42:01 <ddarius> There does not.
12:42:26 <copumpkin> sheikra: what would it be for?
12:42:46 <jmcarthur> i don't normally use unicode in source because it's a pain to set up my editor to do it easily, but i have a function that would otherwise be called "lambda," so i clearly don't have a choice
12:42:51 <ddarius> You could just as well erase single constructor and field strict data types as well if you replace certain case statements with a seq.
12:42:56 <sheikra> ddarius: It seems to be the case in SPJ's old "tutorial of the implementation of a functional language" where he talked about core language and data representations. time has changed?
12:43:57 <sshc> is there a strict version of hGetContents?
12:44:21 <ddarius> sheikra: What a specific implementation does does not impact what is required, and GHC does not use "tags" except in some cases.
12:44:23 <sheikra> I still think the evaluation is a runtime thing, and tags are necessary, unless you point me to the evidence
12:44:47 <danderson> 'the hell?
12:44:55 <ddarius> sheikra: GHC is based on (a now highly modified) STG.  STG stands for "spineless tagless G-machine"
12:45:04 <danderson> so if I set a handle to nonblocking mode, it'll systematically read data one byte at a time?
12:45:06 <ddarius> sshc: The ByteString version is strict.
12:45:18 <danderson> this even if there is (say) 1.5k bytes available for reading?
12:45:26 <ddarius> sheikra: Also, I already mentioned a scheme that will make tags unnecessary for single constructor strict data fields.
12:45:26 <danderson> um, not nonblocking
12:45:30 <danderson> to no-buffering mode
12:45:41 <sshc> ddarius: I want to read an entire file at once, but I'm not sure how to do this in Haskell
12:45:54 <sheikra> ddarius: I should look into STG... thank you
12:46:18 <sheikra> ddarius: this is very interesting
12:47:05 <jmcarthur> copumpkin: you've done a fair bit of unicode with haskell right? do you use haskell-mode? have you managed to find a convenient way to work with unicode in haskell-mode?
12:47:13 <copumpkin> jmcarthur: nope, no unicode
12:47:22 <jmcarthur> oh, maybe i have you mixed up with somebody else
12:47:24 <copumpkin> I only use it for agda
12:47:28 <jmcarthur> ah
12:47:33 <jmcarthur> yeah i love the way agda-mode does it
12:48:48 <ddarius> I would think you would be able to just copy and paste the way agda-mode works.
12:49:32 <copumpkin> yeah
12:49:49 <copumpkin> I'd do unicode in haskell if there were a better solution for lambdas :)
12:50:17 <jmcarthur> copumpkin: in this case i'm actually glad for the unicode lambda not being treated the same as \
12:50:24 <jmcarthur> because i want it for a function name
12:50:32 <copumpkin> I can understand why they don't do it and support that
12:50:41 <copumpkin> but in that case we should go with more LCey notation
12:50:59 <zygoloid> why do lambdas use -> not .?
12:51:10 <copumpkin> beats me
12:51:16 <copumpkin> dots are composition
12:51:17 <copumpkin> and other thing
12:51:20 <Heffalump> ML history?
12:51:36 <zygoloid> i guess it predates "forall x."; .'s not special in '98, is it?
12:52:11 <Heffalump> forall x is in a different lexical context, I suspect
12:52:16 <ddarius> zygoloid: No, but . can't occur at the type level, so the . in forall doesn't overlap anything.
12:52:24 <Heffalump> certainly a different parsing context
12:52:30 <zygoloid> ddarius: . can't occur at the top level in patterns either...
12:52:42 <ddarius> @src (.)
12:52:42 <lambdabot> (f . g) x = f (g x)
12:52:43 <zygoloid> . in forall overlaps type operators
12:52:48 <jmcarthur> ddarius: in ghc 6.10 i used (.) as a type operator with TypeOperators, but not in ghc 6.12
12:52:51 <ddarius> zygoloid: Which are an extension.
12:53:00 <zygoloid> sure. :)
12:53:02 <jmcarthur> ddarius: it doesn't work in 6.12 :)
12:53:04 <jmcarthur> *:(
12:53:21 <sheikra> ddarius: That's a good reference. I'm convinced :-)
12:53:45 <jmcarthur> yeah i'm hoping i can rip it from agda-mode
12:53:48 <copumpkin> jmcarthur: wait, how did (.) work as a type operator?
12:54:21 <danderson> so, um, stupid question here, but...
12:54:35 <ddarius> copumpkin: The mathematical lambda could be used for \, but that would probably lead to confusion.
12:54:52 <danderson> when I Data.ByteString.hGetNonBlocking data from a handle, at the system level, it *does* actually read those bytes out of the FD, as opposed to peeking them or whatever?
12:54:53 <copumpkin> I suggested that in a ticket
12:54:55 <ddarius> λλ -> λ
12:55:02 <copumpkin> but apparently it's marked as a letter in unicode anyway
12:55:24 <jmcarthur> copumpkin: i used it like this:    Composition (.) => (f . g) a
12:55:27 <danderson> because I have here a pipe (kernel->userspace pipe, tun/tap device, same difference) which dies deterministically after N network packets transmitted
12:55:30 <zygoloid> @type let foo :: forall Data.Set.Set; foo = undefined in foo
12:55:31 <lambdabot> parse error on input `Data.Set.Set'
12:55:39 <zygoloid> ddarius: ^^ that's legal in haskell'10 i think
12:55:45 <danderson> and looking at the kernel source code, that happens iff the send queue overflows
12:55:50 <copumpkin> jmcarthur: I'm surprised that worked
12:55:56 <danderson> which suggests that my binary isn't actually reading this stuff right...
12:55:57 <jmcarthur> copumpkin: well, it did, but not anymore :(
12:56:13 <danderson> but I am getting and processing the data, so it makes no sense at all to me.
12:56:24 <jmcarthur> it may have been against the spec though, so i'm not going to fuss about it
12:56:59 * zygoloid has succeeded in answering his own question
12:57:57 <zygoloid> > (\(Data.Maybe.Just a) -> a) (Just 42)
12:57:58 <lambdabot>   42
12:58:05 <zygoloid> ^^ that's why it's -> not . i guess :)
12:59:19 <ddarius> Lambda notation has existed much longer than the hierarchical modules notation.
12:59:30 <jmcarthur> or perhaps a better example would be > (\Data.Maybe.Nothing -> "foo") Nothing
12:59:58 <jmcarthur> since it lacks the parens
13:00:29 <jmcarthur> we already have (.) being whitespace sensitive when there is a constructor preceding it though, so i don't think it's a show stopper here
13:00:46 <ddarius> I think the (original) motivation not to use . was simply to avoid overloading it.
13:02:06 <ddarius> Also I don't think there is any syntax (pre-hierarchical modules) that is a valid identifier and a keyword/operator (in different contexts, of course).
13:05:30 <sheikra> ddarius: It's a long paper. It is obvious that the immediate pattern matching after a call can be optimized to use a dispatch table or putting a tag in a register. It's not so clear a list containing those values can do without tags
13:08:02 <sheikra> ddarius: sorry. This last point is obvious now :-)
13:08:25 <ddarius> sheikra: You have to (in general) have something to differentiate the cases, but they don't need to be tags.  And in many cases, you can conceivably get rid of any kind of (run-time) differentiation (i.e. it will all be statically known.)  This is certainly the case for single constructor strict field.
13:10:37 <kw317> I'm trying to build gtk2hs from darcs and I'm getting this error: glib/System/Glib.hs:14:1: Failed to load interface for `System.Glib.UTFString'
13:10:41 <kw317> has anyone seen this before?
13:11:21 <sheikra> ddarius: It feels like the constructors are passed with a vector of continuations and then a certain constructor just invoke a certain element in the vector
13:12:00 <ezyang> oh man new sigfpe post
13:12:02 <sheikra> ddarius: so the constructors are no longer considered "primitive"
13:12:40 <ddarius> sheikra: Yes, that's how modern GHC works for >4 or >8 constructors and how I believe GHC 6.6 and earlier (for a long while) worked for all constructors.
13:12:45 <sheikra> or maybe they are not primitive in any way already
13:13:18 <ddarius> However, I would not be surprised if JHC avoids any run-time differentiation in many cases as it is a whole-program compiler.
13:14:14 <sheikra> ddarius: unless by running the progam and then produce its value as the compiled code ;-)
13:14:34 <ddarius> Also, with GHC's modern pointer tagging which handles data type with a small number of constructors, a single constructor data type would correspond to using 0-bits for pointer tagging, i.e. to having no run-time "tagging" of any knd.
13:14:49 <sheikra> So it is partial evaluation in either case
13:15:22 <sheikra> ddarius: Thanks for the paper. this is very interesting
13:19:25 * ezyang still doesn't know enough category theory to understand sigfpe's post. :-( 
13:19:39 <copumpkin> aw
13:19:41 <jmcarthur> λ :: (f a -> f b) -> f (a -> b)  -- I just realized this is pretty much a counterpart to (<*>) :: f (a -> b) -> (f a -> f b)
13:20:16 <Veinor> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23316#a23316
13:20:18 <copumpkin> lax comonoidal functor?
13:20:43 <kw317> aaargh.. I give up.. I've been trying to get criterion up and running for two days or so.. gtk2hs is just impossible
13:20:45 <Veinor> So right now, this recurses forever because of the f' <- f. How do I get it to be lazy about evaluating that?
13:20:46 <jmcarthur> i have no idea what that is
13:20:57 <ezyang> kw317: what opearting system?
13:21:05 <jmcarthur> kw317: if you're on arch you can just install the aur package
13:21:35 <copumpkin> Veinor: change the if around
13:21:37 <kw317> ezyang: both snow leopard and gentoo
13:21:56 <Veinor> copumpkin: meaning?
13:22:03 <ezyang> gentoo: I'm surprised gentoo does have a recipe for gtk2hs building
13:22:04 <copumpkin> c <- getChar; if c /= 'q' then do f' <- f; return (c : f'); else [c]
13:22:10 <Veinor> Ahhh.
13:22:10 <ezyang> not sure if I can help you on snow leopard
13:22:10 <copumpkin> else return [c], I mean
13:22:21 <kw317> ezyang: well, I get the same problem on gentoo
13:22:57 <ezyang> So this doesn't work? http://packages.gentoo.org/package/dev-haskell/gtk2hs
13:23:43 <kynky> i got gtk2hs working on ghc 6.12.1 on gentoo
13:23:47 <kw317> ezyang: it works with vanilla 6.10.4 but not with 6.13
13:24:22 <ezyang> Ohhh, you're doing 6.13!
13:24:29 <ezyang> "kabloeey"
13:24:35 <kw317> the error I get is quite odd: Failed to load interface for System.Glib.UTFString
13:25:10 <kynky> i based it on the gtk2hs-darcs
13:26:14 <kynky> i needed to use the ghc-gtk2hs-0.10.1.20100110-1.fc13.src.rpm patch to get it to work
13:26:39 <shapr> whee!
13:29:27 <kw317> kynky: where do I get hold of that patch?
13:30:07 <Jordi> hi
13:30:17 <Jordi> is anyone familiar with haskell-src?
13:30:33 <IceDane> I just reinstalled my system, reinstalled ghc and now, when trying to recompile some of my stuff, I get " Could not find module `Control.Monad.Reader':" <- any hints?
13:30:57 <kynky> kw317, was inside an rpm for gtk2hs
13:33:37 <danderson> anyone around who knows the haskell RTS?
13:34:03 <danderson> I'm still debugging my disappearing file descriptor problem, and strace says that the RTS closes the fd out of the blue at some point
13:34:20 <danderson> and then obviously fails to further select() on it, because it's no longer a valid FD
13:34:22 <Veinor> IceDane: you need to install mtl
13:34:47 * hackagebot txt-sushi 0.5.1 - The SQL link in your *NIX chain  http://hackage.haskell.org/package/txt-sushi-0.5.1 (KeithSheppard)
13:34:47 <kynky> think it was gtk2hs-0.10.1.20100110-Graphics.UI.Gtk.Display.StatusIcon-haddock-rec.patch found inside it, http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/ghc-gtk2hs-0.10.1.20100110-3.fc13.src.rpm
13:35:29 <Lemmih> danderson: You're talking about GHC's RTS.
13:35:31 <Heffalump> danderson: your best bet is to email glasgow-haskell-users
13:35:37 <danderson> Lemmih: yes, sorry.
13:35:43 <danderson> Heffalump: thanks for the pointer.
13:36:00 <Heffalump> I'm sure Simon Marlow will be able to help :-)
13:36:50 <danderson> I certainly hope so, because after a few hours of debugging, I'm reasonably sure that I'm just getting picked on by the I/O thread :)
13:36:52 <kynky> kw317, my ebuild is http://dpaste.com/169177/
13:37:10 <gloob_> is it possible (in UDP server app) to forkIO after recieving UDP connection from client and then read message contents?
13:38:57 <IceDane> I just reinstalled my system, reinstalled ghc and now, when trying to recompile some of my stuff, I get " Could not find module `Control.Monad.Reader':" <- any hints?
13:39:47 <Heffalump> IceDane: lack of mtl package?
13:39:56 <Heffalump> if it's something like debian, it comes in a separate package
13:40:02 <IceDane> Heffalump: Yeah, it's ubuntu
13:40:07 <IceDane> I was wondering which package it was, thanks
13:40:10 <Heffalump> libghc6-mtl-dev or similar IIRC
13:40:42 <Veinor> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23318#a23318
13:40:49 <Veinor> Is this considered sufficiently idiomatic?
13:41:18 <Heffalump> Veinor: looks ok to me
13:41:56 <Veinor> cool. it was the first thing I thought of for 'read ints until you get a 0, then output sum'
13:42:13 * ezyang is tempted to golf that code 
13:42:33 <Heffalump> read <$> getLine (<$> from Control.Applicative) is gaining favour these days
13:42:37 <Heffalump> but liftM is fine IMO
13:42:51 <Veinor> well, I originally had an str and an int until I remembered about liftM
13:42:51 <copumpkin> liftM is hellspawn
13:42:59 <Veinor> :P
13:43:08 <Heffalump> I guess it's rare to put the where in a definition on the same line as the definition
13:43:19 <Heffalump> normally it goes with the subdefinitions or on a line of its own
13:43:35 <Phyx-> > foo
13:43:37 <lambdabot>   * Exception: Prelude.(!!): negative index
13:43:40 <Phyx-> heh
13:43:43 <Phyx-> it actually exists?
13:43:48 <Phyx-> @type foo
13:43:49 <lambdabot> forall b. (Fractional b) => Int -> b
13:43:54 <Phyx-> > foo 0
13:43:55 <lambdabot>   1.0
13:43:58 <Phyx-> > foo 2
13:43:59 <lambdabot>   1.5
13:44:01 <Phyx-> wtf
13:44:05 <Veinor> @src foo
13:44:05 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
13:44:12 <Veinor> quick! we have to figure out what it is!
13:44:21 <Veinor> > map foo [-2..2]
13:44:22 <lambdabot>   [* Exception: Prelude.(!!): negative index
13:44:34 <Veinor> > map foo [0..10]
13:44:35 <lambdabot>   [1.0,2.0,1.5,1.6666666666666667,1.6,1.625,1.6153846153846154,1.619047619047...
13:44:44 <Veinor> approximating phi.
13:45:09 <Veinor> I think foo !! n == 1 + 1 / (foo !! (n-1))
13:45:41 <dixie> hmm. that "leksah" name is very crazy to remember :( I always do some typo like "lekhas"
13:45:55 <Veinor> leskah?
13:46:01 <FauxFaux> Lexer.
13:47:06 <mapreduce> > reverse "leksah"
13:47:07 <lambdabot>   "haskel"
13:47:10 <kynky> ll
13:47:12 <kynky> lol
13:47:17 * cebewee wonders why it's not called lleksah ;)
13:47:27 <Veinor> pronounced 'yek-sah'
13:47:56 <copumpkin> or thleksah
13:47:57 <medfly> that explains why it's called leksah...
13:47:59 <ddarius> "Leksah" sounds like a female name.
13:48:25 <ddarius> E.g. "Alexa"
13:48:26 <mapreduce> That's appelling.
13:48:53 <dixie> > reverse "haskell-ide"
13:48:54 <lambdabot>   "edi-lleksah"
13:49:10 * djahandarie hopes this does not become a trend
13:49:10 <kynky> maybe yrruc would be name for an associated app
13:49:34 <dixie> > reverse "netbeans"
13:49:35 <lambdabot>   "snaebten"
13:49:49 <medfly> Curry is a language.
13:49:51 <medfly> (too.)
13:50:05 <kynky> and nice too eat
13:50:18 <copumpkin> (using the LL in the welsh sense, that is)
13:50:26 <copumpkin> not sure how else to approximate it in english
13:50:33 <kynky> llamah sense
13:50:42 <mapreduce> Curiously, a girl I liked when I was 10 was far more interested in a program that does the same as Haskell's reverse, than she was in my 'find your way through the maze' game.
13:51:01 <medfly> mapreduce, it was a 50 year old paedophile.
13:51:02 <copumpkin> maybe (f/th)leksah
13:51:23 <gwern> mapreduce: maybe recursion (to reverse) is more intersting than straight iteration (through a maze)
13:51:29 <copumpkin> gwern: do you speak welsh?
13:51:47 <gwern> copumpkin: nobody speaks welsh. they just splutter vowels and pretend they understand each other
13:51:51 <mapreduce> gwern: Bah.  One can recurse through a maze.  In fact that's quite handy for backtracking.
13:51:51 <copumpkin> lol
13:51:55 <medfly> lol
13:52:02 <copumpkin> I'll take that as a no
13:52:04 <gwern> inner qwghlm and outer qwghlm if ye ken
13:52:10 <kynky> does welsh have a word for blue ?
13:52:23 <gwern> kynky: if it doesn't, it has a word for blue-green
13:52:36 <medfly> I see I'm not the only one that reads about this.
13:52:49 <copumpkin> 青い
13:53:16 <mapreduce> The only words used much translate to English as "oh crap, an Englishman, let's speak Welsh" and "I think he's leaving."
14:01:17 <linsensibile> ciao
14:02:05 <Phyx-> hmm, inexplicably, after reading here for a few minutes, I feel like stopping my procrastination
14:02:52 <metaperl_> i ruined the number of the beast :)
14:06:03 <gwern> what's the lightspeed delay to just pluto? a few days?
14:06:23 <tensorpudding> probably more like a few hours
14:06:58 <gwern> mm. mars is like half an hour, and that's really close
14:07:34 <tensorpudding> it ranges 30-50 AU, so 30-50 times 6 minutes
14:08:18 <Lemmih> 28.8 AU = 237 lightminutes.
14:08:18 <gwern> so 600 minutes roundtrip?
14:08:53 * Lemmih is too slow as usual.
14:12:41 <metaperl_> I have a windows machine, I prefer cygwin. How can I run Haskell under Cygwin? Otherwise I guess I will go the Windows route.
14:15:42 <jmcarthur> copumpkin: i noticed you are not using unsafe functions in the implementation of vector-static. any particular reason?
14:16:00 <copumpkin> I am where I could
14:16:02 <copumpkin> where?
14:16:06 <jmcarthur> unboxed
14:16:09 <copumpkin> (that project is failed though)
14:16:12 <jmcarthur> oh wait
14:16:19 <jmcarthur> ah nevermind
14:16:29 <jmcarthur> i didn't realize you were importing Generic.Static. i thought G was just Generic
14:16:36 <jmcarthur> i was being dumb
14:16:41 <jmcarthur> why is it failed?
14:16:45 <ddarius> metaperl_: You can run GHC under Cygwin just like you run any other Windows program under Cygwin.
14:16:50 <capitrane> anyone familiar with this error http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23319?
14:17:06 <copumpkin> jmcarthur: because it's really painful to do anything interesting with type-level stuff in haskell
14:17:12 <jmcarthur> ah
14:17:21 <metaperl_> ddarius: I see. I will give it a try... I remember you from long ago... remember me?
14:17:30 <copumpkin> I tried writing some basic algorithms in it and it was way harder than it should have been
14:17:45 <copumpkin> will probably write something higher level next :)
14:17:51 <jmcarthur> heh
14:17:57 <copumpkin> I have several ideas that are waiting for this term to be over
14:18:17 <jmcarthur> well, i *think* i have a reasonable use for vector-static that probably won't result in too much strangeness at the type level
14:18:18 <monadic_kid> metaperl_: I prefer using a virtual machine over cygwin
14:18:23 <copumpkin> jmcarthur: what is it?
14:18:42 <metaperl_> monadic_kid: I see.... yes virtual box is nice... however this visual haskell thing is looking good!
14:18:44 <copumpkin> I wrote a very simple DFT with the obvious O(n^2) implementation
14:18:45 <kynky> cygwin is horriblle, vm is much preferred
14:18:50 <metaperl_> imagine an emacs person liking that
14:18:55 <copumpkin> but doing an actual FFT was so painful I gave up
14:19:18 <monadic_kid> metaperl_: you mean visual haskell for VS? it's quite dated
14:19:20 <jmcarthur> copumpkin: parameterizing my gpu interface. the static lengths are necessary so i can use glsl's vec2, vec3, and vec4 types properly. the exposed functionality should be quite limited, so i'm not concerned with type blowup
14:19:28 <copumpkin> ah ok
14:19:33 <metaperl_> monadic_kid: this thing - http://www.haskell.org/visualhaskell/screenshots.html
14:19:44 <copumpkin> jmcarthur: well the repo is sitting on github if you want to make any changes and reupload to hackage
14:20:02 <copumpkin> I'm treating it as a failed experiment mostly, but it gave me plenty of ideas about a separate project with similar goals
14:20:09 <jmcarthur> copumpkin: is there anything you have knowingly left unimplemented or in bad state?
14:20:38 <monadic_kid> metaperl_: yes but this pluging hasn't been updated for years and it works with an old version of ghc, I don't think it's trivial to get it working with newer versions.
14:20:46 <copumpkin> I can't think of anything. There's a TODO file with things I think need doing. witnessNat is the main gotcha in there
14:20:50 <metaperl_> oh I see monadic_kid
14:20:52 <jmcarthur> ah
14:20:53 <copumpkin> but I've avoided it as much as possbile in my own functions
14:21:00 <jmcarthur> i'm not so concerned with witnessing for this use case
14:21:03 <monadic_kid> metaperl_: http://hackage.haskell.org/platform/
14:21:17 <jmcarthur> oh snap
14:21:24 <jmcarthur> copumpkin: you're not inlining the functions! :P
14:21:32 <copumpkin> jmcarthur: not on hackage, but the github version is
14:21:36 <jmcarthur> ah
14:21:49 <copumpkin> it also has a nicer Nat setup that Saizan contributed
14:21:55 <jmcarthur> hmm
14:22:35 <jmcarthur> copumpkin: something nice i thought of yesterday for vector-static is that if you know the length of the vector you can nest it inside an unboxed vector
14:22:52 <jmcarthur> *the length of an unboxed vector
14:22:52 <copumpkin> ah, that's true
14:23:11 <copumpkin> I guess you could write an Unbox instance for them
14:23:17 <copumpkin> would be quite nice
14:23:21 <jmcarthur> indeed
14:23:35 <jmcarthur> if i do anything that is probably among the things i will try
14:23:48 <copumpkin> sure thing, do anything you want with it :)
14:24:52 <copumpkin> do you use git much?
14:24:56 <jmcarthur> i used to
14:25:16 <jmcarthur> i've switched to darcs, but i don't hold any malice toward git
14:25:38 <jmcarthur> and from the darcs side of the fence there are still a couple git features i envy (stash, for example)
14:25:43 <ezyang> oh, has darcs gotten that good?
14:26:03 <jmcarthur> ezyang: well, it's fast enough for me and i like cherry picking a lot
14:26:20 <copumpkin> there's that darcs UI for git
14:27:01 <dolio> ddarius: So, it occurred to me earlier today that it's pretty easy to write values of type Π A:Type. Type that are not parametric in A.
14:27:17 <jmcarthur> git can cherry pick but only commits that nobody else has seen yet
14:27:31 <jmcarthur> and that really just sucks. so i use darcs
14:27:33 <copumpkin> makes sense
14:28:41 <ezyang> not sure what you mean by that, but I don't cherrypick very often
14:28:56 <jmcarthur> i wish i could locally enable and disable patches in a single repository using darcs. that would alleviate my stash withdrawals, and it would also be a good equivalent to git's in-place branching
14:29:14 <jmcarthur> ezyang: you probably don't do it often because git doesn't lend itself to that kind of workflow
14:29:29 <copumpkin> cherrypicking means that it's almost impossible to come up with a succinct description of the state of your repository
14:29:31 <Heffalump> jmcarthur: that's an interesting way of looking at it
14:29:38 <Heffalump> (stash)
14:30:08 <jmcarthur> copumpkin: that's what tags are for
14:30:20 <gwern> yeah, but tags have nasty effects
14:30:25 <gwern> by their implementation
14:30:29 <jmcarthur> gwern: like what?
14:30:33 <copumpkin> it's just annoying for reporting bugs, mostly
14:30:53 <copumpkin> "I'm on 1231ab421fc1743 and have bug X"
14:30:57 <copumpkin> that's fairly nice
14:31:05 <gwern> jmcarthur: well, suppose you in a few years discover that file Foo is a copyvio, and if it doesn't disappear from your repo history, you will be bankrupt next year
14:31:07 <dixie> jmcarthur: local inplace branches forced me to switch to git. but i'm now darcs when i realized that darcs pull / unpull can do work.
14:31:09 <Tomas> if a type is a list and a second type is a list of the first type, do I get a list of lists?
14:31:17 <jmcarthur> copumpkin: i think bug tracking should be part of the VCS, but that's not a common feature of VCSs yet
14:31:19 <Veinor> Tomas: Yep.
14:31:26 <Veinor> :t [[1,2],[3]]
14:31:27 <lambdabot> forall t. (Num t) => [[t]]
14:31:32 <copumpkin> jmcarthur: I agree
14:31:38 <gwern> jmcarthur: without any tags at all, you can do something like 'darcs get --match'not touch Foo', and you will get exactly that.
14:31:39 <Heffalump> gwern: it's highly unlikely that a tag would make that problem worse.
14:32:00 <Heffalump> gwern: you'll get every patch that doesn't touch Foo or depend on a patch touching Foo.
14:32:14 <jmcarthur> gwern: that problem sucks in any VCS though
14:32:17 <gwern> jmcarthur: with tags, you have to either start over completely, or figure out how (and whether) you can get rid of the tag patch and then try to do that get
14:32:27 <Heffalump> In reality it's very likely that after some time transitive depdendencies will expand to cover the entire repo anyway
14:32:34 * gwern is not sure it's always possible to remove all the tags either
14:32:49 <Heffalump> tags can always be unpulled because nothing depends on them
14:32:52 <gwern> Heffalump: most commits cover only one file
14:32:59 <Heffalump> nonsense
14:33:14 <jmcarthur> Heffalump: most of my patches are just for one file
14:33:23 <Heffalump> ok, look at something like darcs for a counterexample
14:33:35 * gwern offers xmonad-contrib as a counter-counterexample
14:33:43 <Heffalump> anyway, apart from also having to blow away your tags, tags make no difference at all to the problem
14:33:56 <Heffalump> xmonad-contrib is basically the union of a bunch of independent projects, though
14:33:58 <gwern> the occasional 2-5 file patch, but mostly 1 file after another
14:34:30 <jmcarthur> i treat most of my modules as separate projects even when part of the same larger project
14:34:48 <jmcarthur> i only update more than one module at a time if i change one and have to change dependents
14:35:08 <Heffalump> jmcarthur: right, but just those patches will probably be enough to create dependencies across the whole repo
14:35:19 <gwern> Heffalump: you're handwaving that
14:35:30 <Heffalump> no, I'm not, I've actually graphed this on the darcs repo :-)
14:35:35 <jmcarthur> Heffalump: usually true
14:35:36 <Heffalump> though I don't have the results to hand.
14:36:03 <jmcarthur> Heffalump: but often you end up with modules that become very mature and decoupled over time and then you hardly ever touch it
14:36:09 <gwern> the darcs repo is pretty unusual
14:36:22 <gwern> how many are as old and as large? not terribly many
14:36:50 <Heffalump> I'll have a look at GHC once the stuff I wrote to do it performs ok on that :-) (it was by nature quadratic time, which is a bit inconvenient on large repos)
14:36:58 <jmcarthur> and darcs seems subject to a lot of sweeping changes too, if my observations lead me to the right conclusions
14:37:20 <Heffalump> anyway, to get back to my original point, tags make no difference to the problem if you're happy to blow them away
14:37:53 <ezyang> and orthogonal to the conversation, I'm primarily a git user; I think a patch algebra is the "right way" but that it requires a lot of engineering to do performantly
14:51:26 <sshc> > '.' :: Word8
14:51:27 <lambdabot>   Couldn't match expected type `GHC.Word.Word8'
14:51:27 <lambdabot>         against inferred type...
14:51:52 <sshc> against inferred type `GHC.Types.Char'
14:57:44 <gio123> xml expert is here?
14:58:10 <ezyang> askl your question
14:58:25 <BONUS> he is here?!?
14:58:33 <BONUS> quick, everyone look busy
14:58:58 <Zao> I've got some HSP code in my browser. Does that make me an XML expert?
14:59:20 <copumpkin> would you want to be an xml expert?
14:59:32 <Zao> As it tends to be associated with web dev, not really.
14:59:49 <copumpkin> don't forget being enterprise-readty
14:59:50 <lament> I'm an XML expert
15:00:05 <lament> I spent many decades poring over tomes of long-forgotten XML lore
15:00:17 <Zao> lament: How's your SGML?
15:00:33 <lament> of course, XML is such a vast subject, a lifetime is not enough to become a true expert
15:00:47 <copumpkin> fo shizzle
15:01:28 <lament> like they say, it takes five minutes to learn, and a lifetime to master
15:02:12 <Botje> shrug, xml is easy
15:02:25 <luite> any univerities offering PhD programs in XML?
15:02:32 <nostrand> haha
15:02:47 * copumpkin is getting one
15:02:55 <metaperl_> luite: HXT was an M.S. Project....
15:03:48 <lament> thankfully, like i said, it only takes five minutes to learn :)
15:04:19 <copumpkin> it takes a lifetime to learn and 5 minutes to master
15:04:38 <luite> HXT took me more than five minutes, but I hadn't really used arrows before
15:13:08 <metaperl_> lament: hi!
15:13:49 <DerisionSnort> Is there something like this in the standard library?
15:13:50 <DerisionSnort> sameElement (x:xs) = all (x ==) xs
15:14:38 <horms> nub would be close, though possibly expensive
15:14:45 <dons> i think its really cool that vector's (being strict in their length), that self-referential vector functions are optimized to bottom
15:14:50 <dons> a lot of code gets erased
15:15:20 <copumpkin> :t null . drop 1.  group
15:15:21 <lambdabot> forall a. (Eq a) => [a] -> Bool
15:15:45 <copumpkin> > null . drop 1 . group $ [1,1,1,11,1]
15:15:47 <lambdabot>   False
15:15:50 <copumpkin> > null . drop 1 . group $ [1,1,1,1,1]
15:15:51 <lambdabot>   True
15:16:20 <copumpkin> dons: oh that fibonacci thing you posted to cafe earlier?
15:16:36 <copumpkin> > null . drop 1 . group $ []
15:16:37 <lambdabot>   True
15:16:41 <copumpkin> :P
15:17:04 <copumpkin> DerisionSnort: what would you want it to do on an empty list?
15:17:24 <DerisionSnort> it doesn't matter
15:17:33 <DerisionSnort> there are no empty lists in my use case
15:17:40 <horms> does it matter if its lazy or not?
15:17:44 <DerisionSnort> nope
15:17:49 <horms> :^)
15:18:08 <djahandarie> DerisionSnort, in that case it'll get back to you in a few days... probably
15:18:31 <DerisionSnort> a chatroom with lazy answers? that would be new :)
15:18:37 <copumpkin> I'd use mine (but then again, I did write it)
15:18:51 <djahandarie> copumpkin, usually people hate what they write
15:19:03 <copumpkin> true
15:19:08 <copumpkin> maybe I copied it
15:19:27 <lament> metaperl_: hi
15:19:32 <djahandarie> That'd be an interesting way of detecting plagiarism
15:20:06 <djahandarie> "Check out this cool thing I just wrote!!" "Yeah? Cool? Tell me where you stole it from you thief!"
15:20:16 <copumpkin> :P
15:21:15 <dons> copumpkin: well, someone else wrote it, and it didn't work. but ghc does a great job in not making it work :)
15:21:26 <copumpkin> :D
15:21:30 <dons> it basically finds the simplest possible program that has the semantics of the original
15:21:38 <dons> fib = fib, is what his code is optimized to
15:21:52 <dons> very clever, imo.
15:21:57 <copumpkin> yeah
15:22:41 <idnar> yeah, that was pretty cool
15:23:10 <dons> the essence of non-termination in a strict setting.
15:30:18 * hackagebot bindings-DSL 1.0.6 - FFI domain specific language, on top of hsc2hs.  http://hackage.haskell.org/package/bindings-DSL-1.0.6 (MauricioAntunes)
15:32:17 <pokoko222> someone knows the solution for euler 51? not the algorithm but the actual solution number? I need it to debug my solution, i get the result for 7 prime families, but nothing for 8
15:36:20 * hackagebot bindings-glib 0.1.2 - Low level bindings to GLib.  http://hackage.haskell.org/package/bindings-glib-0.1.2 (MauricioAntunes)
15:36:46 <Lemmih> pokoko222: http://www.haskell.org/haskellwiki/Euler_problems/51_to_60 ?
15:37:25 <pokoko222> ok got it
15:37:59 <copumpkin> heh
15:39:03 <pokoko222> i solve it in c++ that is why i ask, i know that haskell page
15:39:16 <pokoko222> i would not have asked for haskell
15:39:23 <copumpkin> o.O
15:39:36 <copumpkin> if you wanted the number, you could load that file into ghc and have it spit out the number
15:39:50 <pokoko222> i kinda forgot haskell already :D including loading
15:39:55 <pokoko222> i am kiding :D
15:40:11 <pokoko222> i gota do c++ now and leave haskell for the moment cause i do exams on c++
15:45:45 <mreh> D:
15:46:11 <mreh> C++ is good for one thing, Finite State Automata
15:46:29 <copumpkin> better than haskell?
15:46:32 <ddarius> ?
15:46:39 <mreh> I don't know
15:46:39 <ezyang> ??
15:46:46 <copumpkin> haskell seems pretty nice for automata :)
15:47:59 <NEEDMOAR> What's being good for FSM? Implementing them easily?
15:48:23 <copumpkin> yeah, and if you're especially good He'll touch you with His Noodly Appendage
15:48:44 <NEEDMOAR> copumpkin: haha.
15:49:03 <NEEDMOAR> I meant FSA.
15:49:33 <drd> can anyone explain this memoized fibonacci: http://www.haskell.org/haskellwiki/Memoization#Memoization_with_recursion ? (n00b over here)
15:49:44 <drd> i can see what's supposed to happen, but i can't parse the syntax
15:49:57 <mreh> that's a contradiction
15:50:08 <ben> drd: is the (foo !!) part the problem?
15:50:15 <drd> ben: yes pretty much :)
15:50:23 <ben> drd: It means \x -> foo !! x, !! is a list operator
15:50:27 <dons> drd: all prior results are stored in that list
15:50:27 <ben> @src (!!)
15:50:27 <lambdabot> xs     !! n | n < 0 = undefined
15:50:27 <lambdabot> []     !! _         = undefined
15:50:28 <lambdabot> (x:_)  !! 0         = x
15:50:28 <lambdabot> (_:xs) !! n         = xs !! (n-1)
15:50:40 <dons> and its got a (silly) pointfree thing to remove the index argument
15:51:04 <dons> memoized_fib n = ... fs = map fib [0 ..] ; ... in fs !! n
15:51:37 <drd> ok, that makes a little more sense now
15:51:40 <drd> thanks :)
15:52:38 <drd> so basically i call memoized_fib 500 and it says, give me the 500th index in the list and backfills?
15:53:27 <ben> It is pretty much a non-function definition that contains all fibonacci numbers, but lazily
15:53:31 <copumpkin> yeah, and it isn't as efficient as it could be
15:53:38 <ben> Since it is not a function, it does not get thrown out once evaluated
15:54:06 <copumpkin> luqui's memocombinators uses a lazy infinite trie
15:54:06 <drd> hmm, cute ;)
15:54:15 <copumpkin> which would make it logarithmic for lookups
15:54:21 <pokoko222> copumpkin i now i am triple HaskellLove, i so hate c++ and i love haskell even more :D
15:54:23 <ben> "not a function definition" i guess
15:54:34 <copumpkin> pokoko222: :P
15:54:55 <ben> dons: Would giving the n parameter explicitly not remove the memoizing magic?
15:54:59 <systemfault> I love both C++ and Haskell, am I wrong?
15:55:01 <systemfault> :P
15:55:07 <copumpkin> ben: it has no effect at all
15:55:15 <copumpkin> systemfault: definitely
15:55:19 <systemfault> Awwww
15:55:26 * hackagebot multisetrewrite 0.6 - Multi-set rewrite rules with guards and a parallel execution scheme  http://hackage.haskell.org/package/multisetrewrite-0.6 (MartinSulzmann)
15:55:30 <metaperl_> How many Forth lovers here?
15:57:18 <copumpkin> that's a good way to kill the conversation
15:57:46 <pokoko222> systemfault u r a ninja
15:58:08 <systemfault> :(
15:59:49 <dons> ben: no effect at all
16:03:08 <NEEDMOAR> What are the rules for something to being memoized and where I can read about it?
16:04:37 <copumpkin> things don't get memoized in general
16:04:53 <copumpkin> datastructures don't get garbage collected if there are still references to them
16:05:06 <NEEDMOAR> copumpkin: I mean memoized by lazy evaluation.
16:05:08 <ben> I am not sure who is keeping the reference
16:06:14 <NEEDMOAR> copumpkin: http://hackage.haskell.org/packages/archive/data-memocombinators/0.4.0/doc/html/src/Data-MemoCombinators.html
16:06:14 <copumpkin> NEEDMOAR: that's what I mean. lazy evaluation allows you to memoize by creating (possibly infinite) datastructures that are full of lazy "holes" and don't get GCed
16:06:28 <NEEDMOAR> How does the bool function there works?
16:06:44 <NEEDMOAR> I do not see any datastructure.
16:07:30 <copumpkin> (f True) and (f False) are what actually computes the values
16:07:42 <copumpkin> cond is keeping them around
16:08:11 <NEEDMOAR> But why cond is being memoized?
16:08:50 <NEEDMOAR> Or what's doing the work there?
16:08:56 <jmcarthur> copumpkin: eek, nat does look expensive :\
16:09:04 <copumpkin> > map ((2 + 5) +) [1..5]
16:09:05 <lambdabot>   [8,9,10,11,12]
16:09:29 <copumpkin> NEEDMOAR: it doesn't recompute that 2 + 5 every time
16:09:36 <copumpkin> jmcarthur: how do you mean?
16:09:53 <jmcarthur> s does, anyway
16:10:04 <copumpkin> well it's unary
16:10:06 <copumpkin> you don't want to use it :)
16:10:07 <jmcarthur> 1+1+1+1+1+1+1+1+...
16:10:10 <jmcarthur> heh
16:10:44 <NEEDMOAR> copumpkin: but why then it doesn't memoize the original function?
16:11:04 <copumpkin> NEEDMOAR: map got passed an f and is holding on to it for the entire traversal of the list
16:11:11 <copumpkin> that f will get reduced once
16:11:29 <jmcarthur> at least intToFin looks efficient
16:11:43 <copumpkin> on the other hand, if I call map ((2 + 5) +) in two different unrelated places, the 2 + 5 will get computed twice
16:12:01 <copumpkin> there must be a better way to explain this, but I don't know how to :)
16:12:09 <copumpkin> @get-cale
16:12:10 <lambdabot> Unknown command, try @list
16:12:18 <jmcarthur> lol
16:12:24 <jmcarthur> we really need that
16:12:40 * jmcarthur blows a horn
16:15:06 <ben> < dons> ben: no effect at all <- That is not what I observe
16:15:33 <copumpkin> ben: it's called eta reduction and should have no effect
16:15:37 <ben> Yeah, well
16:15:43 <ben> memoized_fib' n = let fib 0 = 0 ; fib 1 = 1 ; fib n = memoized_fib' (n-2) + memoized_fib' (n-1) in  (map fib [0 ..] !! n) hangs for me, for n = 1000 or whatever
16:16:27 <pikhq> Uh... That doesn't memoise anything...
16:16:31 <copumpkin> that's different
16:16:50 <NEEDMOAR> I find memoizing obscure.
16:16:57 <ben> pikhq: That was my question
16:17:08 <NEEDMOAR> Is there any resource where can I read about it?
16:17:10 <jmcarthur> memoizing isn't so obscure once you have a grasp of the evaluation model
16:17:13 <dons> ben: you're not calling memo-fib anymore
16:17:25 <dons> let's see..
16:17:29 <jmcarthur> @where memoization
16:17:30 <lambdabot> I know nothing about memoization.
16:17:34 <jmcarthur> i thought would be so
16:17:48 <dons> http://www.haskell.org/haskellwiki/Memoization#Memoization_with_recursion
16:17:49 <jmcarthur> http://www.haskell.org/haskellwiki/Memoization
16:18:52 <ben> dons: It appears I misread your code and then asked the wrong question, I apologise
16:19:23 <NEEDMOAR> jmcarthur: those are tricks to memoize, I want to understand lazy evaluation 'native' memoization.
16:19:30 <dons> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23321#a23321
16:19:32 <dons> ben: ^
16:19:33 <jmcarthur> NEEDMOAR: you mean thunks?
16:19:47 <copumpkin> NEEDMOAR: it won't recompute a given thunk is the simplest explanation of it
16:19:49 <NEEDMOAR> I don't know... the kind of memoization that the evaluation model imposes.
16:20:05 <copumpkin> you can pass thunks around
16:20:11 <copumpkin> if they've been computed once they won't be computed again
16:20:16 <jmcarthur> NEEDMOAR: the evaluation model doesn't impose any memoization, to be honest. thunks are just how we happen to implement it in GHC
16:21:06 <NEEDMOAR> jmcarthur: I thought that lazy evaluation imposed memoization :-/
16:21:09 <jmcarthur> NEEDMOAR: a thunk is code that, when executed, rewrites itself and returns the answer, and the next time it's executed the rewritten version will always just return the answer without recomputing it from scratch. that's a basic explanation, from an operational point of view
16:21:45 <pikhq> NEEDMOAR: "Memoization" is merely the practice of using the same value instead of recomputing a value.
16:21:55 <jmcarthur> NEEDMOAR: haskell is really just specified to have non-strict evaluation
16:21:57 <c_wraith> also, it's important to say that GHC doesn't (and can't) memoize everything.  Only values that are held by a reference are used again.
16:22:00 <pikhq> You do this by passing around the value itself.
16:22:20 <ddarius> Memoization usually is meant to apply to functions, not values.
16:22:20 <jmcarthur> NEEDMOAR: i guess to be technically correct, "lazy" evaluation is call-by-need, which is just a memoized call-by-name
16:22:26 <pikhq> (or, of course, binding a name to the value)
16:22:45 <jmcarthur> NEEDMOAR: and as ddarius points out, it's not really memoization
16:22:53 <chrisdone> http://www.youtube.com/watch?v=M6PIs7UzXn4
16:22:58 <NEEDMOAR> jmcarthur: and what's it then?
16:22:58 <chrisdone> someone explain this? anyone speak german?
16:23:05 <jmcarthur> NEEDMOAR: it's just thunks
16:23:17 <NEEDMOAR> jmcarthur: where can I read about thunks then?
16:23:23 <jmcarthur> google?
16:23:28 <pikhq> NEEDMOAR: There's nothing to thunks.
16:23:37 <jmcarthur> NEEDMOAR: i pretty much just explained it earlier
16:23:42 <jmcarthur> NEEDMOAR: a thunk is code that, when executed, rewrites itself and returns the answer, and the next time it's executed the rewritten version will always just return the answer without recomputing it from scratch. that's a basic explanation, from an operational point of view
16:24:02 <ben> dons: I do not understand why it "works" as a program but hangs when I run the code in ghci
16:24:04 <pikhq> NEEDMOAR: Thunks are a way of performing lazy evaluation in a strict language. In essence: \() -> ...
16:24:11 <NEEDMOAR> I don't get how that gets to explain how the Data.MemoCombinators work.
16:24:19 <ddarius> pikhq: Thunks have more connotations than that.
16:24:30 <jmcarthur> NEEDMOAR: thunks are prerequisite knowledge, not a full explanation of memoization
16:24:34 * hackagebot hake 1.3.4 - make tool. ruby : rake = haskell : hake  http://hackage.haskell.org/package/hake-1.3.4 (YoshikuniJujo)
16:24:38 * NEEDMOAR is extremely confused
16:25:06 <ddarius> You don't need thunks at all to understand memoization, though you can view thunks as memoized versions of () -> a functions.
16:25:13 <ben> > let memoized_fib = let fib 0 = 0 ; fib 1 = 1 ; fib n = memoized_fib (n-2) + memoized_fib (n-1) in  (map fib [0 ..] !!) in memoized_fib 1000
16:25:14 <lambdabot>   434665576869374564356885276750406258025646605173717804024817290895365554179...
16:25:16 <ben> > let memoized_fib k = let fib 0 = 0 ; fib 1 = 1 ; fib n = memoized_fib (n-2) + memoized_fib (n-1) in  (map fib [0 ..]) !! k in memoized_fib 1000
16:25:20 <lambdabot>   mueval-core: Time limit exceeded
16:25:21 <jmcarthur> NEEDMOAR: data-memocombinators just creates containers of thunks, where the thunks are all the possible results of the functions you memoize
16:25:34 <jmcarthur> NEEDMOAR: and the memoized versions of the functions index into the containers
16:26:28 <dons> ben: ah, let's see.
16:26:45 <jmcarthur> thunks are a highly operational idea though. if you are just wanting to figure out data-memocombinators then you should figure it out top down, not bottom up (in my opinion)
16:27:00 <c_wraith> I think it's useful to note that in most languages, there's a distinction between memoization and dynamic programming.  In lazy languages, they're the same thing.
16:27:03 <ddarius> ben: The lambda is on the inside in the former and the outside in the latter leading to memoized_fib being recreated each time.
16:27:27 <jmcarthur> c_wraith: yet another reason laziness is awesome
16:27:29 <ben> ddarius: but magically it still evaluates instantly when compiled and run as a program
16:27:45 <dons> the optimizer floats it out.
16:27:46 <ddarius> ben: That's because lambda-lifting/dropping is an optimization.
16:27:47 <pikhq> ben: That's because GHC optimises things a lot.
16:27:53 <dons> so they end up as the same program. but ghci doesn't optimize
16:28:06 <ben> Oh. That is cheating.
16:28:16 <jmcarthur> barely
16:28:20 <ddarius> Not really.  The Report specifies no sharing behavior whatsoever.
16:28:22 <dons> it's just a lot slower in ghci, with the native semantics
16:28:40 <ben> I did not know it got to float bindings in a way that affects memoisation.
16:28:53 <dons> so the pointfree version is meaningful, in that the sharing is important.
16:28:54 <jmcarthur> memoization is an optimization anyway
16:29:00 <dons> which is subtle.
16:29:22 <ben> So assuming that the former is memoised is relying on, say, ghc's optimisations?
16:29:22 * jmcarthur feels like he's echoing ddarius is different words a lot, reading back over the conversation
16:29:46 <jmcarthur> *in different
16:29:50 <ddarius> ben: Yes.
16:30:06 <ddarius> ben: You can implement Haskell using call-by-name (i.e. no sharing whatsoever) and be correct.
16:30:11 <ben> All right, thank you all for clearing it up for me :)
16:30:33 <c_wraith> Sharing is good.  Except when it's bad.  Isn't it magical?
16:31:16 <jmcarthur> when is it bad?
16:31:26 <jmcarthur> space?
16:31:31 <pikhq> When you would prefer to save space.
16:31:33 <ddarius> jmcarthur: There are times, which is why CSE isn't done.
16:31:40 <dons> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23322#a23322
16:31:47 <dons> is what ghc does to it with -O2 vs -Onot
16:31:50 <dons> quite interesting.
16:31:54 <jmcarthur> ddarius: i've heard horror stories about ghc performing cse, i thought
16:32:00 <ddarius> The full laziness transform was taken out because it sometimes led to space-leaks.
16:32:13 <copumpkin> what's the full laziness transform?
16:32:17 <jmcarthur> huh
16:32:17 <TacticalGrace> ging noch
16:32:22 <TacticalGrace> oops
16:32:25 <copumpkin> TacticalGrace: I see.
16:32:36 <copumpkin> :)
16:32:50 <jmcarthur> i'm going to guess it's CSE that introduces sharing?
16:32:58 <TacticalGrace> copumpkin: wrong channel ;)
16:33:26 <jmcarthur> which i guess CSE would inherently do in a lazy language
16:34:23 <ddarius> copumpkin: Basically floating things as far out as possible.
16:34:30 <copumpkin> ah
16:34:36 <ddarius> jmcarthur: CSE introduces sharing in any language.
16:35:00 <jmcarthur> ddarius: i'm used to only using "sharing" in the context of laziness, but i suppose that makes sense
16:35:05 <c_wraith> > let x = 1000000000; f n = length $ [1..x] ++ [1..n] ++ [1..x] in f 5
16:35:09 <lambdabot>   mueval-core: Time limit exceeded
16:35:16 <c_wraith> > let x = 1000000000 :: Int ; f n = length $ [1..x] ++ [1..n] ++ [1..x] in f 5
16:35:20 <lambdabot>   mueval-core: Time limit exceeded
16:35:32 <c_wraith> > let x = 100000000 :: Int ; f n = length $ [1..x] ++ [1..n] ++ [1..x] in f 5
16:35:36 <lambdabot>   mueval-core: Time limit exceeded
16:35:42 <c_wraith> woo.  benchmarking lambdabot
16:36:26 <ddarius> A mildly interesting exercise is to consider what the meaning of mutation is in a call-by-name everywhere language.
16:39:50 <c_wraith> ah, here we go.  tested to usually work the way I mean it to!
16:39:58 <c_wraith> > let x = 10000000 :: Int ; f n = length $ [1..x] ++ [1..n] ++ [1..x] in f 5
16:40:02 <lambdabot>   mueval-core: Time limit exceeded
16:40:09 <c_wraith> bah.  usually
16:40:12 <c_wraith> > let x = 10000000 :: Int ; f n = length $ [1..x] ++ [1..n] ++ [1..x] in f 5
16:40:14 <lambdabot>   20000005
16:40:23 <c_wraith> > let x = [1..10000000] :: [Int] ; f n = length $ x ++ [1..n] ++ x in f 5
16:40:34 <lambdabot>   mueval: ExitFailure 1
16:40:53 <c_wraith> common subexpression elimination is bad there. :)
16:41:09 <ddarius> c_wraith: The typical example is the powerset function.
16:41:09 <NEEDMOAR> jmcarthur: and when the thunks are created and when destroyed, when they are reused?
16:41:50 <c_wraith> NEEDMOAR: basically, there isn't enough memory to keep the whole list around.
16:42:02 <c_wraith> NEEDMOAR: so it's better to just recalculate it
16:42:46 <sshc> Binary defines an instance of (Maybe a); but I have a data type Foo, and I want a special case of Maybe for this type, but GHC wants to use the generic instance instead of my own special case of Foo when I write "instance Binary (Maybe Foo)"
16:42:55 <NEEDMOAR> In the original fibonacci definition, why doesn't it just create a thunk for each expression (fib n) and reuse it?
16:43:03 <sshc> how do I use my special case of Maybe Foo?
16:43:37 <ddarius> If you want a particular format, don't use the Binary class.
16:44:29 <c_wraith> NEEDMOAR: basically, because of what I just showed.  The compiler can't know when holding on to all the intermediate values is worth it or not.  So it leaves it up to the programmer.
16:44:31 <sshc> ddarius: ok, I will.  But, if I were to use the Binary class, how would I do that?
16:44:54 <ddarius> sshc: You can't.
16:45:10 <c_wraith> Use a newtype wrapper. >_>
16:45:27 <c_wraith> That's always the answer when the question is "how can I make a different instance?"
16:50:39 <NEEDMOAR> c_wraith: http://www.haskell.org/haskellwiki/Memoization#Memoization_with_recursion What's what tell the compiler "keep the list" in memoized_fib and not tell it keep the (slow_fib n) values?
16:52:14 <c_wraith> NEEDMOAR: the map call.  (sort of)
16:52:18 <copumpkin> the list is being held by by !!
16:53:00 <copumpkin> very similar to the cond in the bool memocombinator
16:53:17 <c_wraith> that example looks to me like it'd still be O(n^2).  >_>
16:53:26 <ben> NEEDMOAR: It is keeping the values, but in slow_fib, it has no way of knowing where to look for them since they are required in distinct subexpressions
16:53:37 <copumpkin> c_wraith: better than exponential :)
16:53:47 <ben> NEEDMOAR: in memoized_fib, it always boils down to the result of map
16:54:04 <c_wraith> copumpkin: sure, but why not use a memoization example that's both clearer and  O(n).
16:54:23 <copumpkin> c_wraith: how would you get O(n) on that? I can see how you'd get O(loggish n)
16:54:40 <c_wraith> well, pretending that (+) is O(1)
16:54:50 <copumpkin> using http://hackage.haskell.org/package/data-inttrie
16:54:59 <c_wraith> Use an array.
16:55:00 <copumpkin> (a pretty neat package btw)
16:55:06 <copumpkin> c_wraith: arrays are finite
16:55:21 <c_wraith> That's fine.  You know n when the function is called.
16:56:02 <copumpkin> omg it's CAle
16:56:26 --- mode: ChanServ set +o Cale
16:56:29 <dantheman_> Hey, is there anyone here who could perhaps help me with a problem installing gtk2hs?
16:56:40 --- mode: Cale set +b *!*@95.66.8.144
16:56:42 --- kick: CO_gairah_tinggi was kicked by Cale (CO_gairah_tinggi)
16:56:50 <NEEDMOAR> ben: grr. I don't see why it's always the same map that is being used.
16:56:54 --- mode: Cale set -o Cale
16:57:26 <Cale> This bloody city seems to knock out the power once a month like clockwork, and this time it claimed my power supply unit.
16:57:38 <dantheman_> Trying to build it on windows, been a bit of a nightmare, but I've finally got ./configure and make to work....
16:57:45 <c_wraith> NEEDMOAR: It's not.  That's why it's O(n^2).  But it only creates O(n) maps
16:57:57 <c_wraith> err.  well.  O(N^2) maps.
16:58:06 <dantheman_> however when I do make install it gives me a weird error, see: http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=23323#a23323
16:58:46 <NEEDMOAR> c_wraith: but the maps share something?
16:58:50 <dons> Cale: you're in the northern wilderness, right?
16:58:55 <Cale> I'm not sure what happened, but as best I can tell, it seems not to put out the full 400 watts anymore, and it wasn't enough to power my main hard drive, so I scalped a PSU from my dad's old machine that he wasn't using.
16:59:00 <dons> on the edge of civilization
16:59:49 <Cale> dons: In Southern Ontario, not really on the edge of it, but this city is not exactly the height of technological civilisation either.
17:01:10 <Cale> I think my uptime was almost exactly one month. I remember checking it a couple days ago and it was at 28 days then.
17:01:37 <Cale> I'm beginning to get suspicious about whether it's actually planned.
17:02:50 <NEEDMOAR> Bah, I give up.
17:03:04 <copumpkin> NEEDMOAR: I'm sure Cale can help you!
17:03:21 <Cale> NEEDMOAR: What are you having trouble with?
17:04:20 <c_wraith> Cale: You running into the 28.5 day counter overflow bug in old versions of windows? ;)
17:04:40 <Cale> c_wraith: nope, no windows
17:04:41 <copumpkin> that's quite an overflow if it knocks out his town's power and destroys his power supply
17:04:46 <Cale> Oh, heh
17:04:54 <Cale> yeah, maybe at the power company ;)
17:05:47 * copumpkin is doing fancy graphics
17:06:01 <jmcarthur> copumpkin: you can't do fancy graphics!
17:06:05 <copumpkin> why not?
17:06:08 <jmcarthur> copumpkin: i'm doing fancy graphics!
17:06:08 <copumpkin> :(
17:06:12 <copumpkin> :O
17:06:15 <jmcarthur> so lay off
17:06:15 <copumpkin> NO U
17:06:31 <jmcarthur> copumpkin: what are you doing?
17:06:32 <c_wraith> gah.  Data.Array.! has much too high of precedence. :(
17:06:40 <copumpkin> jmcarthur: slides for a talk I'm giving tomorrow
17:06:47 <jmcarthur> oh, that kind of fancy graphics
17:06:52 <copumpkin> yep
17:06:53 <jmcarthur> okay, you have my blessing
17:06:57 <copumpkin> thank you sir
17:07:53 <Cale> brb, one moment
17:08:34 <c_wraith> NEEDMOAR:  http://hpaste.org/fastcgi/hpaste.fcgi/view?id=23324#a23324
17:08:41 <c_wraith> I think the memoization is a lot clearer in there.
17:08:57 <c_wraith> Also, if you ignore the fact that addition isn't O(1), that's O(n)  :)
17:10:12 <copumpkin> where n is the number of bits, I presume? :)
17:10:26 <copumpkin> unless you're a fan of unary numbers
17:10:45 <copumpkin> I guess binary addition is also O(n) but not in an interesting way
17:11:35 <c_wraith> I mean, I could do a full analysis, showing that addition is O(d), and d is exponential in n, so the final timing is actually O(n^2)
17:11:54 <c_wraith> But that just gets in the way of showing off a clean example of memoization
17:12:18 <copumpkin> most things are O(BB(n))
17:12:19 <c_wraith> So it's easier to pretend that addition is O(1), and that algirhtm is O(n)
17:12:24 <copumpkin> I propose we use that as a new complexity bound
17:12:40 <ddarius> Or you can simply say it's O(n) additions.
17:12:49 <theorbtwo> On most CPUs, addition of a given type is O(1).
17:12:58 <copumpkin> theorbtwo: this is Integer addition though
17:12:59 <copumpkin> not Int
17:13:07 <theorbtwo> copumpkin: Ah, that's fair, then.
17:13:08 <c_wraith> theorbtwo: I specifically told it to use Integer. :)
17:13:27 <ddarius> On all computers addition is constant time, for a potentially very large constant.
17:13:36 <copumpkin> :)
17:13:42 <c_wraith> all calculations are O(lifespan of the universe)
17:14:04 <theorbtwo> Well, yes.  The definition of O() is somewhat silly like that.
17:14:28 <c_wraith> and since the lifespan of the universe is believed to be a constant, clearly all computations are O(1)
17:14:33 <jmcarthur> is O(lifespan of the universe) the same as O(1)?
17:14:40 <jmcarthur> bah beat me to it
17:14:58 <c_wraith> At the very least, it's unlikely that the lifespan of the universe will depend on the arguments to the function you're analyzing.
17:15:05 <FauxFaux> The main sillyness is that O(n!!!!!!!) can be significantly faster than an O(1) algorithm for all representable inputs. :P
17:15:28 <copumpkin> FauxFaux: the whole point is to characterize the rate of growth against independent variables you care about
17:15:57 <NEEDMOAR> c_wraith: I think I understand the idea of using the list to memoize. What I don't get is what is kept in memory for reuse and what not.
17:17:12 <c_wraith> NEEDMOAR: the only things kept in memory for re-use are the ones the garbage collector can find.  That is, there's a reference to them in a closure somewhere, or..  on the equivalent of the stack.
17:18:01 <c_wraith> NEEDMOAR: further, it only re-uses values if the re-use is explicit.
17:18:21 <NEEDMOAR> Then I don't understand when something gots a reference and when not.
17:18:34 <jmcarthur> you also have to understand that the garbage collector can find CAFs
17:18:48 <copumpkin> if you're using it, it's referenced
17:21:41 <jmcarthur> copumpkin: i guess the commented out functions in vector-static are just ones you haven't thought of a good mapping to static lengths for yet?
17:22:00 <copumpkin> jmcarthur: yeah, many of them would require cont-like existentials and stuff like that
17:22:16 <copumpkin> I did that for one of them and felt dirty
17:22:20 <copumpkin> can't remember which one
17:22:20 <jmcarthur> heh
17:22:32 <jmcarthur> yeah i think i say that one a few days ago. i don't remember it either
17:22:35 <jmcarthur> *saw
17:22:58 <jmcarthur> then again, if that's all you can do then that's all you can do
17:23:45 <jmcarthur> i'm starting to feel the hackiness though. not sure if i will use vector-static for this after all, but i don't know what i would rather use
17:23:49 <jmcarthur> i could just use tuples i guess
17:24:00 <jmcarthur> or i could use the Vec package like gpipe does (but i'd rather not...)
17:24:05 <copumpkin> jmcarthur: yeah :/
17:24:33 <jmcarthur> would be nice to have the efficiency of Vector for the CPU side of this
17:25:01 <jmcarthur> another downside to this is that i'd have to implement a whole matrix math library
17:25:09 <jmcarthur> which would be done for me already if i just use Vec
17:25:17 <jmcarthur> i... just don't like Vec that much
17:25:20 <NEEDMOAR> Let's see. If I have memoized_fib 5, after some steps of reductions don't I end up with let fib = ... in fib 4?
17:26:57 <jmcarthur> i guess there's hmatrix-static... a bit better than Vec...
17:27:09 <jmcarthur> actually, i might actually like Vec better
17:27:12 <jmcarthur> *sigh*
17:27:27 <NEEDMOAR> I don't see where I keep the list referenced by following the reduction steps.
17:29:33 <c_wraith> NEEDMOAR: It's kept referenced by the !!
17:30:12 <c_wraith> Since the !! forces evaluation of the list up to the index it's given, it needs to keep it around.
17:31:42 <c_wraith> It's sort of a sloppy example, though, since it really does a lot more recalculation than it should.
17:32:21 <c_wraith> the *most* haskell way of solving the problem is to just create a list that contains all the fibs, and then find the value you're looking for.
17:32:41 <NEEDMOAR> !! (map fib [0..]) 5 -> !! ((fib 0):(map fib [1..]) 5 -> !! (map fib [1..]) 4
17:32:53 <ddarius> If you only need one fib, then the best way is the logarithmic way.
17:32:56 <NEEDMOAR> Right? Why would I keep a reference to the array?
17:33:08 <c_wraith> NEEDMOAR: first, it's a list, not an aray
17:33:15 <NEEDMOAR> Sorry :-p
17:33:27 <c_wraith> that does matter, though.
17:33:41 <c_wraith> It means to find the nth element, it needs to at least calculate the spine of the list through all the proceeding elements
17:34:02 <NEEDMOAR> But I do not need to calculate the values, do I?
17:35:04 <c_wraith> > fix $ (0:) . scanl (+) 1 -- Not the most obvious way to do this
17:35:08 <lambdabot>   mueval-core: Time limit exceeded
17:35:27 <c_wraith> huh?  Didn't that used to work?
17:35:49 <c_wraith> > take 100 . fix $ (0:) . scanl (+) 1 -- Not the most obvious way to do this
17:35:51 <lambdabot>   [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946...
17:36:08 <jmcarthur> mueval does it weird
17:36:18 <NEEDMOAR> I would use the tuples trick to write it :-/
17:36:22 <theorbtwo> c_wraith: Are you sure you want scanl, and not one of the other variants?
17:36:33 <ddarius> theorbtwo: Yes, he is.
17:37:05 <theorbtwo> OK.
17:37:29 <copumpkin> guh
17:37:44 <planetbeing__> buh
17:37:49 <copumpkin> planetbeing__: shush you
17:37:50 <Drk-Sd> hi guys!
17:38:16 <Drk-Sd> I'm new with haskell and i saw something like :
17:38:29 <Drk-Sd> foo@(Pattern bar)
17:38:42 <copumpkin> it binds foo to the entire thing being matched
17:38:49 <Drk-Sd> does it mean that foo is an alias to Pattern bar ?
17:38:51 <Drk-Sd> ok
17:38:56 <Drk-Sd> thank you
17:39:00 <NEEDMOAR> !! (map fib [0..]) 5 -> !! ((fib 0):(map fib [1..]) 5 -> !! (map fib [1..]) 4, where should I keep the reference to the start of the list?
17:39:00 <theorbtwo> ...and still binds bar as well!
17:39:02 <copumpkin> > let foo@(x:xs) = [1..5] in (foo, x, xs)
17:39:03 <lambdabot>   ([1,2,3,4,5],1,[2,3,4,5])
17:39:15 <Drk-Sd> thx
17:51:17 <kw317> if I have a library installed but cabal fails to find it and needs as a dependency, how can I troubleshoot it?
17:55:57 <walrus> is really a bad idea to use a unidimensional vector of data.vector to model a 2D grid?
17:56:40 <Drk-Sd> depends on what you wanna do with the grid
17:56:41 <NEEDMOAR> @src (!!)
17:56:42 <lambdabot> xs     !! n | n < 0 = undefined
17:56:42 <lambdabot> []     !! _         = undefined
17:56:42 <lambdabot> (x:_)  !! 0         = x
17:56:42 <lambdabot> (_:xs) !! n         = xs !! (n-1)
17:57:20 <walrus> I'm using in a metropolis algorithmn in a physics simulation
17:57:30 <walrus> http://haskell.pastebin.com/Zt0gguEa
17:58:39 <walrus> I defined some operator to convert a tuple to a unidimensional coordinate, but don't know if was a good idea to use another data structure.
18:03:13 <reynard> hello, I am new to haskell, but have a little lisp experience.  I always hear that haskell is pure functional language.  However, I do not understand how one can do simple things such as updating an in memory datasets, or model a bank account balance without assignment.  Would be grateful if anyone can help, thanks.
18:04:06 <NEEDMOAR> http://www.hpaste.org/fastcgi/hpaste.fcgi/view?id=23325#a23325 -> any hint?
18:04:52 <pikhq> reynard: Why, you simply model the bank account balance as a value. And deal with it with functions from bank account balance to bank account balance.
18:05:00 <dons> reynard: these things are impure, which is allowed in haskell, it is just not the default
18:05:14 <dons> usually though we avoid mutating structures
18:05:24 <dons> instead using persistent structures that modify copies each time.
18:05:34 <dons> reynard: play with ghci a bit and you'll see how it works
18:05:43 <dons> makes parallelism a lot easier, and reasoning/refactoring
18:06:05 <danderson> wait... Can GHC actually make a haskell program reach GC-less steady state while doing stuff?
18:06:42 <dons> "reach GC-less steady state"
18:06:43 <reynard> thanks, I will look into it.
18:06:48 <dons> you mean, not allocate on the heap?
18:07:00 <danderson> my program, which parses network data, appears to require no garbage collection in steady state, despite eating megabytes/sec of data from a socket
18:07:16 <dons> it may all be stack or register allocated data
18:07:24 <danderson> or I'm just reading the reports wrong.
18:07:32 <dons> you can usually reduce GC down to 1-5% of running time.
18:07:33 <dons> 0 is rare.
18:07:43 <danderson> hmm, yeah, never mind
18:07:47 <danderson>   %GC time       5.3%  (0.1% elapsed)
18:07:50 <dons> there we go :)
18:07:56 <danderson> what's the 0.1% elapsed?
18:08:07 <dons> parallel gc?
18:08:21 <dons> oh, exluding system time.
18:08:27 <danderson> ah
18:08:46 <danderson> (no idea if I'm running the parallel GC or not, 6.10.4 runtime)
18:09:30 <djahandarie> Hmmm..... I think it was a x.x.2 that it was implemented in, can't remember which, haha
18:10:40 <djahandarie> Oh, no it was 6.10.1
18:13:28 <danderson> so, from these GC stats: http://code.bulix.org/sqpg50-74529
18:13:48 <danderson> what I read is that my heap isn't growing at all after the first two GC passes
18:13:52 <danderson> does that sound right?
18:14:06 <dons> looks right
18:14:11 <dons> you can confirm this with a heap profile
18:14:17 * hackagebot semiring 0.3 - Semirings, ring-like structures used for dynamic programming applications  http://hackage.haskell.org/package/semiring-0.3 (SashaRush)
18:14:56 <dons> compile with -prof -auto-all, run with +RTS -p -hy
18:15:08 <dons> run hp2ps
18:15:19 <dons> and you'll get a graph of the heap, that should make the steady state clear
18:15:30 <dons> nice evidence to give to your boss things are working :)
18:15:43 <danderson> running now - need to give it a bit of time to churn
18:15:56 <djahandarie> It'd be cool if my boss cared about anything I wrote in Haskell
18:16:08 <dobblego> get a new boss
18:16:28 <dons> win him over with quality and cost effectiveness
18:16:32 <danderson> hmm
18:16:35 <danderson> something weird is afoot
18:16:38 <djahandarie> dobblego, maybe after I graduate. ;)
18:16:40 <danderson> the graph is completely empty
18:16:54 <dons> possibly didn't have enough time to take samples
18:17:06 <danderson> after running for 30s?
18:17:11 <dons> if it is mostly sleeping
18:17:15 <dons> or in system stuff
18:17:35 <danderson> it's reading stuff off the network and parsing it. So maybe it's spending its life in I/O.
18:17:49 <dons> try adding -i0.01
18:17:57 <dons> as the +RTS flag for how often to take heap samples
18:18:11 <danderson> ah, yeah, that'll probably help
18:18:23 <danderson> heh, the network I/O I'm doing is brutal to the rest of the system
18:18:27 <dons> and check your log file has stuff in it.
18:18:31 <danderson> typing this into an ssh connection, and it's getting laggy.
18:18:38 <dons> http://www.haskell.org/ghc/docs/latest/html/users_guide/prof-heap.html
18:18:56 <dons> we love heap profiles at galois
18:20:12 <danderson> need more precision, but the first profile looks flat
18:20:20 <danderson> actually, ever so slightly decreasing
18:21:33 <dons> sounds like it doesn't allocate much, 5% gc, so mostly bytestring shuffling?
18:22:11 <danderson> yup. network-bytestring to get packets off the network, and attoparsec (bytestring based) to dissect them
18:22:21 <dons> awesome.
18:22:34 <dons> should be quite efficient. network-bytestring avoids several copies
18:23:10 <danderson> so the only construct that needs to be created is an IpDatagram type, which just contains the information pulled from the IP datagram
18:24:56 <dons> danderson: i wonder if you'd be able to write up what you did -- seems like a great example of things just working, using our nice modern tools
18:25:19 <dons> use criterion to do some performance timing, some nice heap profiles to show resource use
18:26:16 <danderson> that's doable, yes. Since this is my moment of Enlightenment as to the applicability of Haskell to network programming, I'm eager to share :)
18:26:20 * hackagebot DP 0.1 - Pragmatic framework for dynamic programming  http://hackage.haskell.org/package/DP-0.1 (SashaRush)
18:26:55 <dons> danderson: sounds like you're using the right tools. you might even think of using  the event/epoll lib + networkbytestring to get a bit better performance under load
18:27:00 <dons> have you played with it?
18:27:11 <danderson> dons: network-bytestring I am already using
18:27:20 <dons> but not epoll-based forkIO/event ?
18:27:37 <dons> http://donsbot.wordpress.com/2010/01/17/playing-with-the-new-haskell-epoll-event-library/
18:27:37 <danderson> the new event lib I haven't poked at yet. My understanding is that eventually it'll replace the current IO manager and everything will magically become better
18:27:43 <dons> yeah
18:27:52 <dons> or you can manually replace forkIO with a callback at the moment.
18:28:00 <c_wraith> huh.  That DP package looks interesting.  Can't wait for the docs to make an appearance. :)
18:28:14 <danderson> oh, so I can actually swap it in now without rebuilding the RTS?
18:28:18 <danderson> hmmm, shiny.
18:28:52 <dons> yeah
18:29:01 <dons> but its an async event style api
18:29:23 <dons> example http://haskell.org/haskellwiki/Simple_Servers
18:29:31 <danderson> that's acceptable, my code can adapt
18:29:38 <dons> the forkIO body becomes a callback
18:29:40 <danderson> dons: that said, I can't really push the limits further back using that lib
18:29:50 <danderson> because I can't generate traffic any faster to test it :)
18:29:57 <dons> hehe
18:30:23 <danderson> I'm saturating the network I/O bandwidth into my virtual interface, and using (ps ax talking here) 0.1% of cpu and 0.0% of memory doing so
18:30:32 <theorbtwo> > ['a'..'z', 'A'..'Z']
18:30:34 <lambdabot>   <no location info>: parse error on input `,'
18:30:45 <dons> bos: ^^ danderson's doing something interesting with attoparsec. getting good results on networking code
18:30:49 <theorbtwo> What is the correct way to write that?
18:30:57 <dons> with ++
18:30:57 <danderson> which is about two orders of magnitude better than I was expecting for a first attempt
18:31:02 <dons> hehe
18:31:14 <dons> i'm happy when things just work.
18:31:27 * theorbtwo slaps forehea.
18:31:39 <danderson> bos: and to complement what dons said, I'm using the hg tip of attoparsec, not the 0.7 on hackage.
18:32:35 <danderson> dons: the x axis of the heap profile graph is confusing me somewhat. What does http://natulte.net/~dave/tunskell.ps say to you?
18:33:41 <danderson> it looks pretty much as expected, some high startup costs (lots of lists, regular strings, some subprocesses and FFI calls) which then drop
18:33:53 <danderson> but the x axis is from 0 seconds to 0 seconds, which doesn't sound very right :)
18:34:37 <danderson> oh, it just got 2 samples apparently. And that's with -i0.01.
18:36:12 <dons> danderson: yeah, the sames are too few
18:36:39 <dons> its running in a tiny amount of space, and spending most of its time in the kernel or waiting on io, i guess
18:36:43 <danderson> yeah, giving it an even longer run with an even higher sampling rate.
18:36:47 <dons> yeah
18:36:50 <c_wraith> also, the graphs are way prettier if you add -c to hp2ps
18:37:01 <dons> or you might even consider the new hp2any tools on hackage
18:37:04 <dons> for very pretty profiles
18:39:15 <danderson> hmm, not sure the sampling rate and extra time produced a more intelligible profile :)
18:39:18 <c_wraith> It's occurred to me that there are times I might like to see the allocation and free rates, rather than the used total.
18:39:20 <danderson> (refresh the .ps)
18:39:49 <c_wraith> to distinguish between "lots of frees and lots of allocations" and "very few of each"
18:40:02 <danderson> it's still only barely sneaking in samples even now
18:40:08 <danderson> c_wraith: yeah.
18:40:28 <dons> the retainer profile kind of shows that
18:41:00 <dons> i'm going to take a wild guess and say that's running in constant space
18:41:35 <dons> in a tiny footprint. (try +RTS -M600k ) etc to see what the minimum footprint is :)
18:41:46 <walrus> is there any reason to vectors in Data.Vector to just use Int in the index?
18:42:08 <dons> the underlying ghc primitives use Int#
18:42:11 <danderson> which is very cool indeed, considering that aside from using network-bytestring and attoparsec, I didn't give any thought to optimizing
18:42:22 <dons> yay
18:42:39 <dons> library author does the hard thinking. user gets all that knowledge for free
18:42:45 <danderson> and the whole thing is 254 lines of haskell, which includes a lot of FFI noise and some unrelated code
18:43:07 <danderson> openvpn can't configure a virtual interface in that much code, much less get and analyze data :)
18:43:23 <dons> hehe
18:43:46 <danderson> (openvpn is also much more robust and portable, but I'm going to pretend the comparison was just)
18:44:13 <dons> hard to beat productivity in this caes.
18:44:29 <walrus> what is the best, in terms of speed, haskell lib/type to use in a n-dimensional mutable array?
18:44:44 <dons> hmatrix, i think
18:45:04 <danderson> dons: and safety. I'm hacking up a VPN server, which is usually considered a security critical piece of infrastructure.
18:45:21 <danderson> the state of the art is to use hand-carved C code, with all the security fun that implies
18:45:24 <dons> yes, you can generate some of  the core code in Agda :)
18:45:55 <QtPlatypus> Lunch soon?
18:46:16 <danderson> dons: honestly, just the elimination of buffer overflow exploits (or at least their minimization) is a huge step up
18:46:31 <danderson> I'll get to formally proving the system later ;)
18:47:26 * hackagebot bindings-gobject 0.1.1 - Low level bindings to GObject.  http://hackage.haskell.org/package/bindings-gobject-0.1.1 (MauricioAntunes)
18:47:32 <walrus> hmatrix dons? I thought that it had just 1d arrays or 2d matrix
18:49:35 <dons> walrus: oh, it might not allow n-dimensions. i've not checked.
18:51:19 <walrus> dons: yes, I think I will stay with data.vector.unboxed because of speed. And in this way I can create differents operators to acces the data that can model differents boundary conditions. thanks
18:51:59 <dmead> ?hoogle combination
18:51:59 <lambdabot> No results found
18:52:07 <dmead> ?hoogle choose
18:52:08 <lambdabot> Test.QuickCheck choose :: Random a => (a, a) -> Gen a
18:58:10 <dmead> ?src filter
18:58:10 <lambdabot> filter _ []     = []
18:58:11 <lambdabot> filter p (x:xs)
18:58:11 <lambdabot>     | p x       = x : filter p xs
18:58:11 <lambdabot>     | otherwise = filter p xs
19:03:07 <aavogt> @type (\\)
19:03:09 <lambdabot> forall a. (Eq a) => [a] -> [a] -> [a]
19:03:44 <aavogt> dmead: though using Set instead of lists is probably more convenient
19:04:09 <aavogt> but it should be possible to do it taking into consideration that the lists are all ascending
19:05:07 <aavogt> I mean, you can do the naive:   product [1..n] / (product [1..k] * product [1..n-k])
19:07:41 <dmead> sup?
19:10:47 <DerisionSnort> intersperse puts a separator between elements, for example intersperse ',' "abcde" == "a,b,c,d,e". Is there a similar function that also puts the separator before the first element and after the last, e.g. ",a,b,c,d,e,"?
19:11:27 <Alpounet> :t interleave
19:11:28 <lambdabot> forall (m :: * -> *) a. (MonadLogic m) => m a -> m a -> m a
19:11:33 <Alpounet> hm
19:12:35 <dolio> > let f x = (x:) . (>>= \y -> [y, x]) in f ',' "abcdefg"
19:12:36 <lambdabot>   ",a,b,c,d,e,f,g,"
19:15:20 <dolio> > let f x = unfoldr g . (,) False where g (False, l) = Just (x, (True, l)) ; g (True, y:ys) = Just (y, (False, ys)) ; g (True, []) = Nothing in f ',' "abcdefg"
19:15:21 <lambdabot>   ",a,b,c,d,e,f,g,"
19:16:46 <aavogt> > ',': concatMap (:",") "abcdefg"
19:16:47 <lambdabot>   ",a,b,c,d,e,f,g,"
19:17:16 <aavogt> which is more or less a specialization of dolio's first version
19:17:26 <dolio> Note:
19:17:30 <dolio> > let f x = unfoldr g . (,) False where g (False, l) = Just (x, (True, l)) ; g (True, y:ys) = Just (y, (False, ys)) ; g (True, []) = Nothing in f ',' ""
19:17:32 <lambdabot>   ","
19:17:37 <dolio> > let f x = (x:) . (>>= \y -> [y, x]) in f ',' ""
19:17:39 <lambdabot>   ","
19:17:52 <dolio> Oh, they are the same there.
19:17:58 * dolio needs some sleep, apparently.
19:22:35 * hackagebot yesod 0.0.0 - A library for creating RESTful web applications.  http://hackage.haskell.org/package/yesod-0.0.0 (MichaelSnoyman)
19:22:40 <Hannahaus> http://imgnow.info/DSC-7-03-10.jpg/ do my tits look small?
19:27:48 <DerisionSnort> @pl \x -> f x x x
19:27:48 <lambdabot> join (join f)
19:28:08 <DerisionSnort> :t join
19:28:09 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
19:33:37 <metaperl_> debian/testing or debian/stable is best for getting a recent GHC and Batteries included setup?
19:38:33 <jcreigh> well, debian/stable is usually pretty far behind.
19:38:37 <jcreigh> (just in general)
19:39:28 <jcreigh> looks like both stable and testing have GHC 6.8.2 at the moment.
19:39:56 <jcreigh> I don't recall enough about the version history to know if you'll really be missing anything super-important with those.
19:43:21 <aavogt> type families
19:47:08 <Niccus> what's this peanut_bu doing messaging me
19:47:12 <dmead> :t product
19:47:13 <lambdabot> forall a. (Num a) => [a] -> a
19:51:44 * hackagebot estimators 0.1.4 - Tool for managing probability estimation  http://hackage.haskell.org/package/estimators-0.1.4 (SashaRush)
19:53:38 <k23z__> can haskell interface with C ?
19:54:11 <pikhq> Easily.
19:54:24 <k23z__> how
19:54:36 <pikhq> @where ffi
19:54:36 <lambdabot> http://www.cse.unsw.edu.au/~chak/haskell/ffi/
19:54:52 <k23z__> do I install something from cabal ?
19:54:53 <k23z__> hackage
19:55:04 <pikhq> No, it's part of GHC.
19:55:18 <pikhq> And that's an annoying link; that's the *spec*.
19:56:21 <pikhq> http://www.haskell.org/haskellwiki/FFI_Introduction Better page.
20:01:10 <dons> k23z__: http://book.realworldhaskell.org/read/interfacing-with-c-the-ffi.html
20:01:23 <dons> foreign import ccall "math.h sin" c_sin :: CDouble -> CDouble
20:01:44 <k23z__> I was asking because we can have Perl and C interoperate
20:01:53 <k23z__> and if we could have Haskell and C interoperate
20:02:06 <k23z__> we can build an indirect bridge   Haskell <--->  C  <--->  Perl
20:02:09 <dons> haskell can interoperate with any language with a C calling convention. C, C++, Python, Perl, Ruby, etc.
20:02:12 <k23z__> and that wouldbe pretty cool
20:02:14 <dons> there's already a perl bridge, iirc.
20:02:22 <k23z__> what's it called ?
20:02:31 <dons> http://hackage.haskell.org/package/HsPerl5
20:04:58 <jcreigh> dons: hmm, I wonder if it would actually work the call Ruby's C API Haskell.
20:05:28 <dons> http://www.infoq.com/news/2009/08/haskell-ruby-hubris
20:06:14 <jcreigh> huh.
20:06:16 <jcreigh> well there you go.
20:07:14 <dons> pretty famous project this year
20:07:26 <Cale> pikhq: The spec is a fine intro to the FFI
20:07:39 <dons> http://www.engineyard.com/blog/2010/a-hint-of-hubris/
20:07:51 <Cale> pikhq: Unlike the rest of the Haskell report, it's pretty close to being a tutorial about how to use it.
20:08:02 <dons> blackdog: do you track all the great press about hubris somewhere?
20:08:05 <dons> free documentation
20:08:10 <pikhq> Cale: Oh, okay.
20:08:21 <dons> though the ffi spec has a few things you'll almost never need to use
20:08:25 <dons> needs a 'quick start'
20:08:31 <dons> i guess that's what the RWH does.
20:12:08 <scutigera> http://www.unsafecoerce.com:8080/fastcgi/hpaste.fcgi/view?id=8506#a8506
20:12:40 <scutigera> the first version is dreadfully slow.  the second is just fine.  I think I know why on the first version, was hoping for more comments.
20:13:53 <sjanssen> scutigera: what is multiply?
20:14:26 <jcreigh> and "sub", for that matter.
20:14:49 <scutigera> sjanssen: multiply two polynomials,  sub subtract two polys. polys are lists.
20:15:22 <dons> its harder to help if we can't compile it :)
20:15:26 <scutigera> version 1 is making non-tail calls "twice", so I thinks it's recursing n^2 times.  it get's _really_ slow for n = 50 :-)
20:16:02 <aavogt> yeah, this is the same deal as naive fibonacci?
20:16:11 <sjanssen> scutigera: actually, you're going exponential there
20:16:19 <scutigera> aavogt: good point - might be.
20:16:28 <scutigera> sjanssen: well, that would be bad.
20:16:55 <sjanssen> I agree with aavogt, it's Fibonacci recursion
20:17:21 <scutigera> the first version is definitely not tail call, right.  loop would have to be the last and only thing called...
20:17:51 <sjanssen> scutigera: lack of tail recursion is not the major issue here
20:18:14 <aavogt> yeah, calculate loop (n-1) from the result of loop (n-2)
20:18:49 <scutigera> aavogt: oh crap, n^n ????
20:19:15 <scutigera> or "only" 2^n :-)
20:19:18 <aavogt> I don't know exactly, but you should share some results
20:20:35 <scutigera> this is not really performance related, more educational.  I coded up the first one and then saw it's suckage and came up with the second.  I just wanted to make sure I understand why the first is so bad.
20:20:48 <scutigera> so I don't do it again :-)
20:20:48 <jcreigh> scutigera: if you've run it to completion with n = 50, I wouldn't think it's n^n
20:21:10 <jcreigh> > 50**50
20:21:11 <lambdabot>   8.881784197001252e84
20:21:19 <jcreigh> ^^^ a large number.
20:21:21 <scutigera> jcreigh: no no ! ctrl-c for 50 :-) I backed off and it starts taking awhile at about 25 or so.
20:21:24 <sjanssen> it's O(phi^n)
20:21:25 <scutigera> > 2^24
20:21:27 <lambdabot>   16777216
20:21:44 <scutigera> sjanssen: phi is golden ?
20:21:48 <sjanssen> it's actually probably worse than that
20:22:02 <sjanssen> scutigera: yes, an approximation of the Fibonacci function
20:22:41 <scutigera> sjanssen: yes - I have the wike fib page open, so I can see how that applies.
20:22:52 <scutigera> s/wike/wiki/
20:31:29 <scutigera> sjanssen: looks exactly like naive fib which needs O(fib n); fib 50 = 12586269025 mult/subs
20:31:29 <scutigera>  
20:41:55 <scutigera> is there a "tuple operator", i.e. 1 `op` 2 = (1,2) ?  hoogle says no.
20:42:08 <pikhq> :t (,)
20:42:09 <lambdabot> forall a b. a -> b -> (a, b)
20:42:14 <jmcarthur> i wish i could just prevent specific functions from being exported instead of having to explicitly listing all the functions i do want exported
20:42:20 <jmcarthur> *explicitly list
20:43:40 <scutigera> pikhq: argh.  Just typed (,) in ghci instead of :t (,) ....
20:44:28 <pikhq> Please note that for confusing reasons, infix partial application of that doesn't work.
20:44:34 <pikhq> (... By default)
20:44:39 <jmcarthur> copumpkin: i now have these defined in my local copy of vector-static:  Unbox a => Unbox (Vec Z a) ; (Unbox a, Unbox (Vec n a)) => Unbox (Vec (S n) a)
20:44:40 <jmcarthur> :D
20:44:51 <copumpkin> cool :)
20:44:53 <jmcarthur> whether they work is another story, but it's close enough for government work
20:44:59 <copumpkin> lol
20:45:25 <scutigera> pikhq: that's ok.  I do map (\x -> (x, f x)) ls a LOT, and was idly wondering about something hackier
20:47:01 <ddarius> map (id&&&f)
20:47:57 <jmcarthur> aaand, it's pushed to github
20:48:38 <Jonno_FTW> is anyone here good with the Text.xhtml library?
20:49:14 <Cale> ap (,) f
20:49:25 <scutigera> :t ap (,) f
20:49:26 <lambdabot> forall a a1. (Show a, SimpleReflect.FromExpr a1) => a -> (a, a1)
20:49:35 <Cale> heh
20:49:47 <Cale> :t \f -> ap (,) f
20:49:48 <lambdabot> forall a a1. (a -> a1) -> a -> (a, a1)
20:50:21 <scutigera> Cale: ap is a a monad thingy ?  I seem to remember running across it not too long ago.  sort of a liftM*.
20:50:35 <Cale> Yeah...
20:50:37 <Cale> :t ap
20:50:38 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
20:50:41 <ddarius> ap = liftM2 ($)
20:50:50 <Cale> So here, we're using it with m = (->) e
20:50:56 <Cale> So its type becomes
20:51:07 <Cale> (e -> (a -> b)) -> (e -> a) -> (e -> b)
20:53:01 * hackagebot DP 0.1.1 - Pragmatic framework for dynamic programming  http://hackage.haskell.org/package/DP-0.1.1 (SashaRush)
20:53:29 <Cale> and in this instance, we effectively have  ap f g x = f x (g x)
20:53:45 <Cale> which, if you're familiar with the SK calculus, is just S.
20:54:06 <scutigera> > map (ap (,) (*2)) [1..5]
20:54:07 <lambdabot>   [(1,2),(2,4),(3,6),(4,8),(5,10)]
20:54:16 <scutigera> :-)
20:54:31 <ddarius> > map (id &&& (2*)) [1..5]
20:54:32 <lambdabot>   [(1,2),(2,4),(3,6),(4,8),(5,10)]
20:54:40 <scutigera> :t &&&
20:54:41 <lambdabot> parse error on input `&&&'
20:54:47 <scutigera> :t (&&&)
20:54:49 <lambdabot> forall (a :: * -> * -> *) b c c'. (Arrow a) => a b c -> a b c' -> a b (c, c')
20:56:25 <scutigera> ddarius: I'm sorry was that supposed to hurt my head ?
20:56:47 <ddarius> Set a = (->)
20:57:11 <scutigera> trying  to   remember   arrows   discussion
20:57:29 <ddarius> Ignore Arrows and just replace the a with (->)
20:57:41 <ddarius> You get (b -> c) -> (b -> c') -> b -> (c,c')
20:58:59 <scutigera> ddarius: oh right.  as Cale demonstrated with ap
20:59:12 <elspru> import System.Random
20:59:13 <elspru> ?
20:59:24 <elspru> be supported in ghc 6.8 .10 ?
21:01:33 <elspru> problem compiling http://hackage.haskell.org/packages/archive/sat/1.1.1/logs/failure/ghc-6.10
21:01:59 <elspru> runhaskell seems fine
21:03:15 <elspru> anyone home?
21:03:29 <elspru> did you run out of entropy?
21:03:33 <elspru> lol
21:03:44 * Gracenotes is hiding in your cupboard
21:04:47 <elspru> it's a great sat solver, quite quick, and extremely simple algorithm
21:04:54 <elspru> max sat as well.
21:05:19 <elspru> I made it for a uni course.
21:05:29 <Gracenotes> the random package should come with GHC by default, though
21:05:32 <elspru> or while at a uni course that emphasized sat solvers.
21:05:34 <jmcarthur> hmm... this kind of sucks. i have some Vector types that i'm instantiating existing type classes with, and all the generic functions that use that type class aren't going to be automagically INLINEd
21:05:58 <Cale> oh, apparently it depends on random, but doesn't list it in its build-depends line
21:06:02 <scutigera> jmcarthur: wasn't there a cafe thread about that recently ?
21:06:25 <jmcarthur> scutigera: i read a thread in which don said you should basically INLINE every function that uses Vectors
21:06:25 <Cale> elspru: If you're wondering about what's causing the build to fail
21:06:36 <jmcarthur> scutigera: or somebody did, anyway
21:06:38 <elspru> Cale: thanks, I'll go check it out
21:07:03 <scutigera> jmcarthur: yes that's what I'm thinking of.  sounds like you are doing something a little different.
21:07:08 <jmcarthur> scutigera: but my problem is that these are functions i have no control over :(
21:07:08 <Cale> build-depends: base
21:07:19 <Cale> Just add  ", random" to the end of that line
21:07:44 <Cale> and see if it fixes the problem -- you might also need some other packages, as lots of things got split out of base a while back
21:07:55 <scutigera> jmcarthur: that will make it harder.
21:08:25 <elspru> how do I include a readme? and documentation
21:08:51 <elspru> I think maybe that's why it hasn't been used, even though it's so useful (for sat solving people).
21:09:33 <elspru> Cale: i think it worked, your suggestion :-)
21:09:38 <Cale> cool
21:10:58 <Cale> I think you can use an "extra-source-files: " to list extra files you want included in the package.
21:11:19 <Cale> Normally people document things using Haddock, but that works for libraries more than for executables
21:11:22 <elspru> thanks :)
21:12:26 <Cale> also, your home page link is dead
21:12:40 <elspru> ya, i'll have to update that
21:14:54 <elspru> so how's australia?
21:15:20 <elspru> my spouse and I be planning on circumnavigating by sailboat.
21:15:24 <k23z__> any chances of employment with haskell in the near future ?
21:15:34 <k23z__> non-universities
21:15:36 <k23z__> and non-galois
21:15:43 <k23z__> and non-abn amro
21:15:44 <aavogt> haskell is not an employer
21:15:47 <elspru> were thinking of visiting Australia.
21:15:54 <k23z__> aavogt: yes haskell is a langauge who can produce jobs
21:15:58 <elspru> but it seems like an oppressive regime.
21:16:01 <k23z__> aavogt: I'm asking about the jobs
21:16:10 <Jonno_FTW> is australia is excellent
21:16:11 <Gracenotes> time for a @faq I think
21:16:32 <elspru> Gracenotes: ?
21:16:41 <Gracenotes> nothin
21:16:44 <elspru> Cale: aren't you australian?
21:16:51 <aavogt> @faw yes?
21:16:52 <lambdabot> The answer is: Yes! Haskell can do that.
21:18:27 <SubStack> @faw Can haskell prove the Riemann Hypothesis?
21:18:27 <lambdabot> The answer is: Yes! Haskell can do that.
21:18:31 <SubStack> excellent
21:18:40 <ville> Howdy. You might wish to kick peanut_bu, he sends a private message to anyone joining about some bots and hosting services on anohter IRC network.
21:18:47 <scutigera> elspru: bring your life jackets and watch out for those floating cargo containers
21:19:04 <Jonno_FTW> it was a floating ice box
21:19:08 <elspru> scutigera: I was more concerned about how it doesn't seem like anything is legal in australia.
21:19:35 <SubStack> k23z__: do a haskell startup!
21:19:58 * SubStack is doing this
21:20:36 <elspru> I was hoping there was a "workaround" the locals have found.
21:20:52 <elspru> but if not, it's okay, we'll just avoid it.
21:21:11 <SamB_XP> elspru: well, if you have to break the law to breath in .au, I guess everyone in .au are outlaws ;-P
21:21:34 <Jonno_FTW> we sure are
21:21:40 <Jonno_FTW> we also ride around on kangaroos
21:21:45 <scutigera> when you outlaw breathing only outlaws will be breathing, er..
21:22:24 <elspru> i've heard the american legal system has grown so large, on average people commit 3 crimes a day, simply through ignorance that there was a law preventing them from doing so
21:22:30 <aavogt> SubStack: what are you doing?
21:22:54 <SamB_XP> elspru: I'm sure not aware of any law preventing me from committing crimes
21:23:02 <SubStack> aavogt: web-based virtual machine console and management
21:23:23 <elspru> so american laws tend to be "overlooked" if there are bribes.
21:23:25 <scutigera> elspru: there is cruft in the legal code.  in lots of places it's literally illegal to spit on the sidewalk.
21:24:14 <elspru> scutigera: but is it enforced? or is it just a fancy
21:24:56 <elspru> i was thinking about guns and armour mainly.
21:25:06 <scutigera> elspru: no, not enforced.  it's a holdover from long ago when people chewed a lot of tobacco and no one's gotten around to removing them.
21:25:11 <elspru> as well as precious metals
21:25:45 <scutigera> SubStack: go on...
21:26:04 <scutigera> SubStack: what's the haskell advantage ?
21:26:56 <scutigera> elspru: armour ? seriously ?
21:27:06 <elspru> well on the high seas ...
21:27:15 <elspru> it's quite reasonable
21:27:21 <SubStack> scutigera: it's a nice language for going between the vm framebuffer and javascript frontend
21:27:50 <elspru> i'm intetested in self preservation
21:28:05 <scutigera> elspru: aren't we all !
21:28:23 <elspru> so armour is a form of self preservation
21:28:27 <ddarius> scutigera: Clearly not.
21:28:58 <scutigera> SubStack: but is the advantage because it's functional, lazy, etc...?
21:29:04 <elspru> having personal armour, is cheaper than having boat armour
21:29:32 <elspru> oh well, we'll figure it out.
21:29:36 <scutigera> ddarius: ?
21:29:54 <ddarius> scutigera: Not everyone is interested in self-preservation.
21:29:56 <scutigera> elspru: I'm not an authority, but I'm pretty sure body armor is legal.
21:30:28 <scutigera> ddarius: oh right, I suppose there is that _insane_ minority.
21:30:34 <SubStack> scutigera: the advantage is that stuff written in haskell tends to just work once it passes the typechecker
21:30:55 <SubStack> haskell is a great prototyping language
21:31:21 <scutigera> SubStack: yeah! I used scheme for quite a while and I didn't think I really needed the typing, but I've really learned to appreciate it.
21:31:23 <c_wraith> eh.  Once you get into real code, the type checker is insufficient
21:31:31 <elspru> SubStack: agreed
21:32:01 <elspru> c_wraith: you mean "your code"
21:32:15 <c_wraith> elspru: I mean multi-thousand line codebases.
21:32:30 <SubStack> I have been bitten so many times by stupid type errors in duck-typed languages and segfaults in C++
21:32:32 <c_wraith> A small program, really.
21:32:42 <c_wraith> But it's not just a toy example
21:32:55 <elspru> c_wraith: keeping individual functions small allows for easier comprehension
21:32:59 <elspru> also good practice
21:33:03 --- mode: ChanServ set +o Cale
21:33:05 <c_wraith> elspru: real life still interferes.
21:33:06 <dons> c_wraith: the haskell typechecker?
21:33:09 <elspru> there's no haskell function length checker.
21:33:12 <dons> maybe you're not using enough types.
21:33:13 --- mode: Cale set -o peanut_bu
21:33:19 --- mode: Cale set +b *!*@95.66.5.137
21:33:19 <SubStack> and STM is really nice for concurrent craziness
21:33:20 --- kick: peanut_bu was kicked by Cale (peanut_bu)
21:33:23 <elspru> c_wraith: real is agreed upon between a set of people
21:33:30 <c_wraith> STM was a seriously problem with this application
21:33:38 <elspru> SubStack and I have a reality where typechecking is usually sufficient
21:33:43 <c_wraith> Using STM often lead to bad space behavior.
21:33:44 <dmead> dudes.
21:33:48 <dmead> whats not equal?
21:33:51 <Cale> hmm, seems like every time I join the channel, there's another spammer
21:33:57 <dons> c_wraith: weird. haven't heard that before. space behaviour??/
21:34:02 <dmead> Cale, internet haters
21:34:08 <Cale> Maybe I should ban all of 95.66.*
21:34:08 <dons> you had a retainer in a transaction?
21:34:19 <scutigera> dmead: /=
21:34:25 <dons> might be worth writing down how it happened, c_wraith , in order to improve the stm profiling tools
21:34:39 <c_wraith> dons: threads weren't finishing because they were endlessly retrying transactions, so everything stayed in memory
21:34:51 <dons> so lots of contention. ok. well, stm can do that.
21:34:56 <dons> need short sharp transactions
21:35:08 <Cale> apparently that's a Kuwaiti IP range
21:35:09 <scutigera> and timeouts ?
21:35:14 <c_wraith> dons: switching to using a single MVar to serialize access reduced CPU load and allowed threads to finish in a timely manner
21:35:22 <dons> cool
21:35:32 <elspru> I like to minimize types
21:35:39 <dons> have things wait instead of being optimistic
21:35:55 --- mode: Cale set +b *!*@95.66.*
21:35:56 <dons> that's likely a basic design decision -- are things mostly going to succeed? or mostly going to have to wait?
21:36:00 --- mode: Cale set -bb *!*@95.66.5.137 *!*@95.66.8.144
21:36:03 --- mode: Cale set -b *!*@95.66.32.248
21:36:03 <dons> if the former, stm, if the latter, mvars
21:36:08 --- mode: Cale set -b *!*@95.66.40.124
21:36:17 --- mode: Cale set -b *!*@95.66.40.240
21:36:19 <c_wraith> it's true that this was a bad case for STM, as there was only a single value.
21:36:28 <c_wraith> Err, single TVar, when it was using STM.
21:36:33 --- mode: Cale set -o Cale
21:36:42 <elspru> i use the types Integer, String, and [String]
21:36:43 <c_wraith> That's a worst-case for STM.
21:36:55 <elspru> sufficient for all my needs, in compiler writing.
21:37:03 <c_wraith> because every concurrent access will cause retries
21:37:37 <elspru> well all my needs. but mainly i work on compiler.
21:38:53 <elspru> c_wraith: can you use a lock file, or some way of linearizing access?
21:38:59 <Cale> I'm a little worried about the generality of that ban, but I think that's enough attempts at spamming to get the whole range banned for a while.
21:39:04 <c_wraith> elspru: an MVar does that just fine
21:39:16 <dons> elspru: seriously?
21:39:29 <elspru> dons: seriously
21:39:33 <dons> you're using basic types when designing a compiler?
21:39:44 <dons> most of the type system in haskell is designed to encode compiler patterns
21:39:48 <elspru> writing compiler
21:40:00 <dons> so you're probably not using haskell to its full power.
21:40:12 <elspru> it's "confusing power"
21:40:15 <elspru> lol
21:40:25 <elspru> i just keep it simple
21:40:25 <dons> have a look at ghc. it has some nice examples of compiler design patterns in types.
21:40:29 <dons> "type directed development"
21:40:32 <SubStack> types are pretty great
21:40:37 <dons> so that when you break something, the types tell you
21:40:45 <jmcarthur> sticking to Integer, String, and [String] is anything but simple
21:40:47 * SubStack likes to figure out the types first and then fill in the implementation later
21:40:51 <elspru> I like how haskell works, like SubStack mentioned, once it compiles, it works as expected.
21:40:55 <elspru> typically
21:41:13 <elspru> unless there's logistics error or something,
21:41:17 <azathoth99> what are the big apps that have been done in haskell?
21:41:21 * SubStack uses types all over the place
21:41:21 <azathoth99> darcs?
21:41:26 <c_wraith> ghc. :)
21:41:37 <dons> azathoth99: galois has a fair few things between 20k and 200k
21:41:44 <dons> there's some large open source things as well.
21:41:49 <azathoth99> galois?
21:41:55 <dons> several of the older commercial users have big code bases. 50k, 100k+
21:41:58 <azathoth99> what is galois?
21:42:06 <Cale> azathoth99: A company
21:42:08 <dons> security company that uses haskell
21:42:11 <azathoth99> ah
21:42:22 <Cale> http://www.galois.com/
21:42:26 <jmcarthur> a security company that uses a nicer language than the security company i work for
21:42:30 <dons> there's something like 2M lines of code on hackagen now
21:42:31 <azathoth99> is there a dns server or anything in haskell?
21:42:48 <dons> probably. look on http://hackage.haskell.org
21:42:53 <SamB_XP> I thought the whole point of using Haskell was to keep your programs shorter!
21:42:58 <azathoth99> lol
21:42:59 <elspru> my /src dir for huspol (human speakable programming language) is 120K
21:43:13 <azathoth99> well I am sure in that many lines the functionality is better than equiv c or whatever
21:43:14 <jmcarthur> SamB_XP: and that's why we haven't taken over the world yet
21:43:17 <ddarius> A DNS server would be really easy to write and, as far as I can tell, mostly pointless.
21:43:24 <elspru> mostly comments though
21:43:27 <dons> azathoth99: there's too many things released to be sure what particular packages exist
21:43:29 <c_wraith> Complicated logic can't be encoded in non-complicated code. :)
21:43:46 <azathoth99> so its building up like CPAN for perl?
21:43:53 <azathoth99> I noticed hws and happstack
21:43:53 <elspru> c_wraith: so simplify the logic
21:43:55 <dons> http://hackage.haskell.org/package/hsdns
21:44:11 <azathoth99> happstack I cant make head not tils of it sliek some kind fo haskell library breakdown
21:44:16 <azathoth99> not much about how it works
21:44:18 <c_wraith> elspru: once again, you're ignoring the real world.  OpenID is complicated.  You can't make the program simpler than the problem domain.
21:44:20 <ddarius> dons: That's a resolver, not a server.
21:44:27 <dons> yeah, closest i could find.
21:44:51 <dons> openid's not too bad. (isn't the one on hackage a 100 lines or so)?
21:44:55 <dons> oauth's a bit more complicated.
21:45:00 <dons> even google uses a simpler wrapper
21:45:07 <SubStack> dons: it's a bit more complicated
21:45:13 <c_wraith> openid is *not* 100 lines, no matter how much you try.
21:45:13 <elspru> c_wraith: so you can't change the logic/specifications.
21:45:16 <SubStack> also doesn't work on a lot of sites for some annoying reason
21:45:28 <c_wraith> There's a LOT in the protocol, that most people ignore.
21:45:34 <c_wraith> My company can't ignore those pieces.
21:46:01 <elspru> ya, i like making simple alternatives to things.
21:46:08 <elspru> things even I can grok.
21:46:34 <dons> http://hackage.haskell.org/package/openid prob a bit more than 100 lines :)
21:46:53 * SubStack probably has the only openid-enabled happstack site on the net
21:47:33 <elspru> for instance, instead of making a specific protocol, am making a simple generic protocol huspol.
21:47:33 <c_wraith> just the discover file is over 100 lines
21:47:50 <c_wraith> which *is* the most complicated part
21:47:51 <SubStack> I only use it to access my admin panel though, so I don't care about other people being able to login for now
21:48:23 <elspru> c_wraith: syn ack ?
21:48:51 <elspru> er, is that the purpose of the discover file?
21:49:15 <dons> http://hackage.haskell.org/packages/archive/openid/0.1.3.0/doc/html/src/Network-OpenID-Discovery.html#discover
21:49:21 <c_wraith> It's to handle any of the at least 5 different methods specified for an openid identifier to specify what server is authoritative for it.
21:50:06 <elspru> wow, that is a hassle
21:50:12 <azathoth99> so cabal is this like packaging thing that lets me install a lib and its deps?
21:50:14 <elspru> 5 languages in 1
21:50:32 <elspru> phrase
21:50:40 <elspru> for 1 phrase *
21:50:45 <c_wraith> elspru:  sometimes, you're stuck with external complexity. ;)
21:50:48 <Cale> azathoth99: yeah
21:51:05 <elspru> c_wraith: so can't your company just implement one?
21:51:23 <azathoth99> so is there a bulletin board app or a cms or something like digg with voting on hackage?
21:51:28 <elspru> like the most popular perhaps
21:51:34 <c_wraith> elspru: not in our market position.  Our job is to do the complex fiddly things. :)
21:51:49 <elspru> uber rich, bursting at the seams?
21:52:35 <dons> azathoth99: there's no voting. but it tracks downloads with cabal-install
21:53:24 <azathoth99> http://hackage.haskell.org/package/salvia here is something, is useage supposed to be liek obvious from the code because no website or docs?
21:53:29 <Cale> dons: I think he's asking if there's a project of that sort
21:54:15 <dons> well, happs-tutorial is probably a good start. or gitit.
21:54:23 <dons> there's quite a few web apps and frameworks
21:54:38 <SubStack> there's an awesomer framework built on top of happstack
21:54:50 <azathoth99> yeah?
21:54:59 <SubStack> http://github.com/nfjinjing/hack
21:54:59 <azathoth99> happstack uses that prevalyer style
21:55:22 <SamB_XP> prevalyer?
21:56:43 <azathoth99> www.prevayler.org
21:58:51 <SubStack> http://github.com/substack/virtual-beanstalk/blob/master/Main.hs <-- something I wrote that uses hack, which is awesome
21:59:01 <SubStack> hack is awesome, not necessary what I wrote, I mean to say
22:00:23 <pastorn> SubStack: get?
22:00:34 <pastorn> not the Control.Monad.State get?
22:01:03 <SubStack> it's different
22:01:35 <pastorn> type signature?
22:02:58 <kniu> what does "Inferred type is less polymorphic than expected" mean?
22:03:10 <dons> ah
22:03:20 <dons> depends on your code.
22:03:22 <c_wraith> kniu: it can mean a few things.  Best to provide some sample code
22:03:26 <dons> you might want to hpaste.
22:03:32 <pastorn> kniu: you're probably using a type with an 'a' in it the wrong way
22:03:50 <pastorn> kniu: did you write a typeclass?
22:03:53 <kniu> @hpaste
22:03:53 <lambdabot> Haskell pastebin: http://moonpatio.com/fastcgi/hpaste.fcgi/
22:05:20 <kniu> http://moonpatio.com/fastcgi/hpaste.fcgi/view?id=8511#a8511
22:06:14 <kniu> yeah, I wrote some typeclasses.
22:06:17 <c_wraith> yikes.  class restrictions on data declarations never end up good
22:06:27 <pastorn> kniu: does adding typeclasses for your fonctuons do anything?
22:06:39 <Cale> kniu: The type of the entity function implies that for any type of Entity e, it can take a value of type t and produce that type of Entity.
22:07:27 <kniu> if t is an instance of Thing, right?
22:07:32 <Cale> kniu: Whereas, in the instances you wrote, the type of the value e is a specific unknown type in the class Entity
22:07:34 <Cale> yeah
22:08:05 <kniu> I'm quite confused.
22:08:32 <Cale> Let's look at the instance of Thing for Light
22:09:03 <Cale> The contract for entity is that it's going to take a Light, and, no matter what type of Entity its caller needs, it will deliver that type of Entity
22:09:45 <kniu> okay.
22:09:52 <pastorn> kniu: do you have to hide the entity type?
22:10:13 <kniu> no, I don't think I have to.
22:10:16 <Cale> However, the implementation you provided produces the value e from the Light, which is of some specific, but forgotten type
22:10:52 <kniu> I think I got it now.
22:11:35 <Cale> The only things you can do with e are those things you can do with any Entity (which I don't know since I don't have the definition of that class)
22:11:59 <Cale> and you certainly can't return it from a function, since GHC doesn
22:12:06 <Cale> doesn't support first class existential types
22:52:41 <Zeiris_> @commands
22:52:41 <lambdabot> Unknown command, try @list
22:52:43 <Zeiris_> @list
22:52:43 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
22:53:12 <Zeiris_> @pl decode key = initialize (normalize key) >>= return . pack . cipher . shuffle
22:53:13 <lambdabot> decode = ((pack . cipher . shuffle) `fmap`) . initialize . normalize
22:54:09 <Zeiris_> Huh. Cool. Don't know if it's an improvement, but cool.
22:54:18 <kniu> to the author(s) of Leksah:
22:54:51 <kniu> how come function arrows and "theta" get transformed into special symbols,
22:55:01 <kniu> but "forall", "phi" and "rho" don't?
22:58:40 <kniu> no way to define one's own syntactic candy, either.
22:59:25 <Zeiris_> @pl f key = elems $ foldr swap (listArray (0,15) key) (zip from to)
22:59:25 <lambdabot> f = elems . flip (foldr swap . listArray (0, 15)) (zip from to)
23:02:53 <dons> kniu: i think there is a way to modify the mappings
23:02:58 <dons> there's a demo online from the last hackathoon
23:03:00 <dons> you tweak a file, reload
23:03:08 <kniu> oh cool.
23:11:52 <freiksenet> there is no dropUntil function in haskell?
23:12:03 <freiksenet> so like dropWhile but with not . predicate
23:12:13 <dobblego> @type dropWhile . not
23:12:14 <lambdabot>     Couldn't match expected type `a -> Bool'
23:12:14 <lambdabot>            against inferred type `Bool'
23:12:14 <lambdabot>     Probable cause: `not' is applied to too many arguments
23:12:22 <dobblego> @type fmap fmap fmap dropWhile not
23:12:23 <lambdabot>     Couldn't match expected type `f (a -> Bool)'
23:12:23 <lambdabot>            against inferred type `Bool'
23:12:23 <lambdabot>       Expected type: Bool -> f (a -> Bool)
23:12:42 <freiksenet> i use it like dropWhile not . predicate list
23:13:29 <dobblego> @type dropWhile . (not .)
23:13:30 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
23:13:43 <freiksenet> dobblego: thanks :)
23:14:22 <dons> Prelude> dropWhile (< 5) [1..10]
23:14:22 <dons> [5,6,7,8,9,10]
23:14:22 <dons> Prelude> dropWhile (not . (< 5)) [1..10]
23:14:22 <dons> [1,2,3,4,5,6,7,8,9,10]
23:14:39 <freiksenet> hm, doesn't work
23:15:39 <freiksenet> I mean dropWhile . (not .)
23:16:13 <dobblego> > (dropWhile . (not .)) (< 5) [1..10]
23:16:14 <lambdabot>   [1,2,3,4,5,6,7,8,9,10]
23:16:22 <freiksenet> ok, taht works
23:16:24 <freiksenet> :) thanks al ot
23:17:07 <wasmahen> hi, i have created a url shortener, anyone would want it?
23:31:15 --- mode: ChanServ set +o mauke
23:31:15 --- kick: azathoth99 was kicked by mauke (azathoth99)
23:31:19 --- mode: mauke set +b $a:azathoth99
23:33:19 --- mode: mauke set -o mauke
23:40:10 <thor_L> can I somehow hook into GCC's compilation process and put MY ASSEMBLY CODE for it to perform peephole optimizations on it so I can see how dumb I am ?
23:44:31 <SubStack> thor_L: http://www.haskell.org/haskellwiki/FFI_Introduction
23:45:14 <SubStack> but yeah, premature optimization and all of that
23:45:36 <thor_L> except this is not premature
23:46:09 <SubStack> is the native haskell version too slow?
23:47:10 <thor_L> this has nothing to do with haskell
23:47:15 <thor_L> it has to do with assembly
23:48:00 <SubStack> this is #haskell and all
23:50:33 <SubStack> in other news, I've *almost* got the rudimentary haskell-src-exts transformations in place to automaticaly @pl-ify an entire module from source
23:51:07 <SubStack> which will possibly be actually useful
23:57:32 <sinelaw> greetings, mortals
23:57:32 <lambdabot> sinelaw: You have 1 new message. '/msg lambdabot @messages' to read it.
23:59:57 <sinelaw> ivanm, cool i've never heard of gloss before
