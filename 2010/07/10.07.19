00:00:03 <FunctorSalad_> (I think it's 'the', but 'a' at least)
00:00:06 <c_wraith> And I'm too lazy for that. :)
00:00:13 <ksf> @check \m n -> logBase 2 m + logBase2 n == logBase 2 (m + n)
00:00:14 <lambdabot>   Not in scope: `logBase2'
00:00:18 <ksf> @check \m n -> logBase 2 m + logBase 2 n == logBase 2 (m + n)
00:00:18 <lambdabot>   "Falsifiable, after 0 tests:\n-4.0\n3.25\n"
00:00:42 <ksf> ( \m n -> logBase 2 m + logBase 2 n == logBase 2 (m + n)) (-4) 3.25
00:00:45 <FunctorSalad_> hmm I don't know how O-classes in two variables are defined, actually
00:00:59 <ksf> > ( \m n -> (logBase 2 m + logBase 2 n, logBase 2 (m + n))) (-4) 3.25
00:00:59 <lambdabot>   (NaN,NaN)
00:01:03 <FunctorSalad_> the one-variable definition makes use that there's just one way to go to infinity
00:01:07 <ksf> well fork you.
00:01:15 <FunctorSalad_> for two variables you have infinitely many directions towards infinity
00:01:40 <FunctorSalad_> me? bot?
00:02:02 <ksf> @check \m n -> m <= 0 || n <= 0 || logBase 2 m + logBase 2 n == logBase 2 (m + n)
00:02:03 <lambdabot>   "Falsifiable, after 2 tests:\n1.0\n3.25\n"
00:02:10 <ksf> > ( \m n -> (logBase 2 m + logBase 2 n, logBase 2 (m + n))) (1) 3.25
00:02:10 <lambdabot>   (1.7004397181410922,2.0874628412503395)
00:02:37 <c_wraith> FunctorSalad_: You just fix one of the variables, and prove that the assertion is true for the other variable for any value of the first.
00:02:44 <FunctorSalad_> ksf: anyway, if you take the diagonal direction then it's `log n + log n' vs `log (n+n)'
00:03:02 <FunctorSalad_> 2 * log n    vs      log 2 * log n
00:03:12 <FunctorSalad_> so, just a constant factor
00:04:24 <FunctorSalad_> hmm, wait, log (2*n) = log 2 + log n actually ;)
00:04:42 <FunctorSalad_> but still constant factor, just larger ;)
00:05:28 <FunctorSalad_> c_wraith: my intuition with sequences is that that doesn't tell you the whole story 
00:05:44 <FunctorSalad_> in general - maybe there's some simplifying property with this problem here
00:05:53 <c_wraith> At the very least, your choice of k and n1 will depend on m
00:06:00 <c_wraith> Which might complicate things.
00:06:48 <c_wraith> Yeah, I think my suggestion doesn't work in all cases.
00:07:00 <FunctorSalad_> what would the answer be for m+0*n vs 0*m+n?
00:07:20 <FunctorSalad_> iirc we have a total order for 1 dimension, not here it seems
00:07:33 <FunctorSalad_> (f in O(g) or g in O(f))
00:08:57 <c_wraith> yeah.  I'm reminded of implicit derivatives.
00:09:11 <c_wraith> err...  that may be the wrong term.  I've tried to block out calculus. :)
00:10:36 <FunctorSalad_> well yes, I've been thinking of calculus examples where you get a different answer if you fix one index and vary the other vs. use diagonal indices (or some other direction)
00:10:43 <FunctorSalad_> but it's been a long time
00:11:00 <c_wraith> partial derivatives are fixing one index.
00:11:15 <c_wraith> I liked them, because they were much easier. :)
00:11:21 <o^_^o> how do I debug a pure function ?
00:11:42 <c_wraith> Two main ways:  break it down into multiple parts, and test each of them
00:11:43 <FunctorSalad_> yeah and it's not trivial at all to prove that they happen to be enough to determine the derivative-as-a-linear-map if the function is smooth enough
00:11:45 <o^_^o> if I put print it changes the meaning of the function entirely
00:11:57 <c_wraith> Or use the  Debug.Trace module
00:11:57 <tensorpudding> Pure functions are good for testing.
00:12:14 <o^_^o> tensorpudding, how so I can't figure out what is happening inside
00:12:21 <tensorpudding> In fact, if it is easy enough to explain what the function is supposed to do, you might consider writing the test first
00:12:47 <c_wraith> too many math/food names.
00:13:16 <FunctorSalad_> (you can make up functions that are differentiable in the directions of your basis vectors, but not differentiable in the approximate-by-linear-map sense)
00:14:15 <FunctorSalad_> don't remember the details :)
00:17:25 <ksf> lookup of a node by its label is O(n) in fgl, isn't it?
00:17:42 <ksf> ...at least I can't find anything that would make it fast in the Graph class.
00:19:47 <FunctorSalad_> (that part about determining the derivative was a bit sloppy, but I'll stop the OT)
00:31:40 <o^_^o> ack...the ghci debugger just remembers the variables in that step
00:31:54 <o^_^o> and nothing about all the other variables it encountered in gettingt here
00:32:01 <o^_^o> s/here/there
00:36:52 <drbean> I'm surprised String and [] derive Ordered. But it makes sense.
00:37:17 <drbean> > [1,2] < (repeat 1)
00:37:18 <lambdabot>   False
00:37:46 <drbean> I guess.
00:38:47 <drbean> I guess String is Ordered because lists are.
00:39:30 <gwern> Ordered?
00:40:50 <gwern> oh, Ord
00:44:09 <FunctorSalad_> the 'deriving'-derived order is lexical order? nice
00:45:51 <FunctorSalad_> as long as you put the nil constructor first
00:46:18 <FunctorSalad_> (hmm but I thought [] wasn't defined in source)
00:48:15 <drbean> "" < "a"
00:48:26 <Saizan> i think drbean used "derive" in the OOP sense
00:49:06 <drbean> > "" < "a"
00:49:07 <lambdabot>   True
00:49:41 <drbean> Did I get the terminology wrong?
00:53:30 <handonson> it's not particularly an OOP sense
00:53:42 <handonson> think about "data Something deriving Eq"
00:56:21 <olsner> well... "deriving" in haskell refers to the *automatic* implementation of instances, so if there's an explicit typeclass instance then nothing is being derived
01:10:08 <handonson> Can I specify what library to statically link and what to dynamically link when compiling with GHC?
01:16:09 <jbapple> I just used ByteStrings to make a program 5 times faster
01:16:36 <jbapple> But what's really cool is they made the program three times faster than the same code in C++
01:16:49 <Zao> Your C++ must have sucked then :)
01:16:54 <handonson> Unbelievable.
01:16:57 <jbapple> I guess the program must have been IO bound
01:17:31 <Cale> jbapple: Lazy ByteStrings?
01:17:39 <jbapple> Cale: nope
01:17:52 <jbapple> or, wait -- the default is strict, right?
01:17:56 <Cale> yeah
01:18:03 <jbapple> Data.ByteString.Char8
01:18:06 <Cale> I suppose there's still a significant amount of fusion which goes on for strict bytestrings.
01:19:09 <jbapple> Maybe general laziness made the program not do any work. I didn't output anything, but by changing some constants I'm pretty sure the program is doing work
01:19:12 <Cale> Try compiling with -ddump-simpl-stats and see if many rules related to bytestrings fired :)
01:19:13 <jbapple> let me double check
01:19:21 <jbapple> Cale: I'll try that next
01:20:07 <jbapple> ok, it's definitely not not doing anything
01:20:29 <c_wraith> err.  so...  it's doing...  something? :)
01:20:30 <jbapple> which is equivalent to doing something, in classical logic :-)
01:20:50 <Cale> c_wraith: Sort of, but more intuitionist-y ;)
01:21:15 <c_wraith> Is it doing the right thing? ;)
01:22:39 <jbapple> c_wraith: I don't do any output, so I can't be sure, but the program is very simple, so I think so
01:22:57 <Cale> jbapple: Maybe make it do some output?
01:23:09 <jbapple> Cale: 23 RuleFired. How can I read off which ones are BS related?
01:23:17 <jbapple> Cale: changing program
01:24:01 <Cale> jbapple: The rules for bytestrings tend to have "Bytestring" in their names
01:24:28 <jbapple> none of the rules fired do
01:24:57 <jbapple> I'm beginning to suspect most of the work of the program was just reading in strings, which [Char] made unusually painful
01:26:45 <Cale> What does the program do?
01:28:13 <jbapple> Just reads in /usr/share/dict/words, put them all in a dictionary, then does a bunch of lookups which it throws away. I just changed it to actually force the top level constructor of the lookups (Nothing or Just), and it's taking much longer now
01:28:28 <handonson> ByteString rules!
01:28:28 <jbapple> I'm going to benchmark with Strings to check the speedup
01:30:23 <jbapple> ok, now BS only reduces the run time of the program by 40%
01:30:48 <c_wraith> that sounds a lot more realistic
01:31:02 <lispy> a mere 40%, bummer ;)
01:32:47 <jbapple> A now the ByteString Haskell version of the program is about 2.7 times as slow as the C++ version
01:34:03 <lispy> jbapple: Wait, the C++ version is faster?
01:34:10 <jbapple> yes
01:34:20 <lispy> jbapple: ah, then you haven't optimized yet :)
01:34:24 <jbapple> sigh
01:34:40 <lispy> Isn't C++ usually slower?
01:35:07 <Cale> That depends on a lot of stuff
01:36:26 <Peaker> C++ is pretty great for speed..
01:36:32 <Peaker> at least at the micro level
01:36:36 <ksf> errr
01:36:57 <ksf> when you want to look up stuff in /usr/share/dict, do a kmp search over it.
01:36:59 <Peaker> Operational semantics are simpler/more direct... Denotational semantics are hell, instead :)
01:37:23 <ksf> reading stuff into a map takes time, much time.
01:40:25 <handonson> Can someone check http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27790
01:41:09 <handonson> The situation is: test2.hs runs test.hs and communicate via standard I/O. When I remove "the line in question" in test2.hs, it works.
01:41:34 <handonson> (printing "START")
01:41:59 <handonson> however, when I add the line { request "Ahoy there!" }, it doesn't even print "START"
01:43:00 <o^_^o> in my function I am returning some type a
01:43:11 <o^_^o> I want to print something and still return the type a
01:43:29 <o^_^o> not return as in monad return, return as in spit out
01:43:30 <handonson> So far I have figured out: Everything is fine as long as I feed test.hs with some input. Then I try fetching some string via stdout of test.hs, which works as well.
01:44:27 <handonson> However, if I try putting some input to stdin and and getting some output from stdout AND THEN putting some input to stdin, everything starts to go wrong.
01:45:00 <handonson> I have no idea why this is happening. Can somebody help me?
01:51:45 <o^_^o> wow..cool
01:51:49 <o^_^o> trace actually prints stuff
01:55:24 <sdschulze> Hi, I'm trying to understand understand http://cvs.haskell.org/Hugs/pages/users_guide/quantified-types.html...
01:56:27 <sdschulze> So basically rank-1 is: function with polymorphic argument.
01:56:53 <sdschulze> rank-2: function with function with polymorphic argument as its very own argument
01:56:58 <sdschulze> ?
01:58:33 <ivanm> something like that I think
01:59:23 <sdschulze> But I thought rank-3 was undecidable -- why does GHC support it anyway?
01:59:32 <quicksilver> handonson: test.hs is buffering, I imagine.
01:59:41 <quicksilver> you haven't told it not to.
02:02:45 <handonson> quicksilver: You're right. I just figured it out with some help. Thank you, anyway.
02:03:10 <quicksilver> in a program like that it's probably wise to explicitly hFlush after output.
02:03:16 <quicksilver> that's faster than turning off buffering
02:03:29 <quicksilver> (if you turn off buffering, you will be writing chars 1 by 1, if you're not careful)
02:03:53 <handonson> Though I wonder why test.hs sometimes prints out "START" and sometimes not?
02:06:17 <quicksilver> buffering is not required to be deterministic.
02:08:01 <McManiaC> template haskell: how do you add a "SigD" to a "FunD" (a "type" to a function definition)?
02:09:45 <McManiaC> or do you use something different?
02:18:07 <manjunaths> I forget what the trace function does and keep rediscovering it every few weeks
02:18:26 <manjunaths> it is like short-term memory loss
02:18:45 <manjunaths> everytime I discover trace...I am like woooooooow
02:19:00 <manjunaths> then after a few days I forget everything about it
02:19:13 <Sugar> .
02:22:29 <Sugar> Haskell 2010 is out?why?
02:23:05 <handonson> out as in available for the general public, i think
02:23:43 <manjunaths> Sugar, what do you mean why ?
02:23:49 <manjunaths> Sugar, why is it available ?
02:24:20 <handonson> manjunaths: i think the question was something like "Haskell 2010 has been kicked out of the table? why?"
02:24:29 <Sugar> yes
02:24:36 <manjunaths> ah...
02:25:01 <Sugar>  what's the mean?
02:25:24 <handonson> mean is a synonym of average.
02:25:53 <manjunaths> http://projects.haskell.org/pipermail/haskell-platform/2010-July/001097.html
02:26:04 <manjunaths> handonson, are you translating for Sugar  ?
02:26:31 <Sugar> 中文
02:26:33 <manjunaths> Sugar, it is available for windows here http://projects.haskell.org/pipermail/haskell-platform/2010-July/001097.html
02:26:39 <manjunaths> Sugar, is that what you wanted ?
02:26:40 <Sugar> OK
02:27:41 <ivanm> preflex: seen edwardk 
02:27:41 <preflex>  edwardk was last seen on #haskell 1 day, 1 hour, 31 minutes and 43 seconds ago, saying: Heffalump: probably because i think cale has lambdabot treating (++) as mappend
02:28:14 <TommyOnMac> hi
02:28:20 <handonson> Hello.
02:29:42 <Sugar> I understand out meaning is not used
02:29:44 <handonson> Except it seems they tend not to greet, since there are so many coming and leaving people that if they all greeted the log will explode.
02:30:46 <handonson> Except THAT was a useless remark, adding a garbage line to the log.
02:30:49 <handonson> and that too.
02:30:54 <handonson> I'll shut up.
02:31:06 <Sugar> Who can help me about how to learn haskell
02:31:24 <TommyOnMac> I'm thinking of how to represent cpu status flags in an emulator for a cpu, in haskell. The cpu in question is the good old 6502(C64, Atari etc). There are like 5-6 flags or so. How would you chose to store those flags in Haskell? A tuple?
02:32:29 <handonson> data CPUStatus = CPUStatus { flagOne :: Bool, flagTwo :: Bool, ... }
02:32:30 <TommyOnMac> I read the OmegaDB source but that seems both too advanced for me currently, and perhaps too over designed to be performant
02:32:31 <handonson> I would.
02:32:48 <manjunaths> Sugar, what do you want to know ?
02:33:18 <Sugar> i am see the (real word haskell)
02:34:21 <manjunaths> Sugar, ok so you have seen Real World Haskell book ?
02:34:21 <handonson> RWH is a very good book. If you have no (or little) prior programming experience, http://learnyouahaskell.com/ could be quite helpful as well.
02:34:28 <TommyOnMac> handonson: hmm, ok a simple record then :)
02:34:32 <Sugar> yes
02:34:33 <manjunaths> Sugar, It is a good source for learning Haskell
02:35:24 <manjunaths> Sugar, Also http://learnyouahaskell.com/chapters is good
02:35:46 <TommyOnMac> reading is only half of the learning
02:35:51 <TommyOnMac> doing is the other half
02:36:21 <Sugar> thanks for you help .
02:36:39 <handonson> You are welcome.
02:36:52 <Sugar> I am a beginner HASKELL
02:37:16 <handonson> TommyOnMac: and I think that's better than a tuple especially when you have to frequently consult a flag value, since extracting values from a big (like 6- or 7-) tuple requires some additional code
02:37:56 <TommyOnMac> handonson: i'm more concerned about the possibility of bugs by reading the wrong tuplette
02:38:22 <handonson> oh, right. that's an issue too
02:38:41 <manjunaths> Sugar, you are welcome...
02:39:44 <TommyOnMac> i started a cycle exact c64 emulator in javascript+canvas, the code ended up very repetative and boring.
02:40:20 <TommyOnMac> the ultimate goal would be to make some sort of DSL for emulating the chips of a C64
02:40:38 <TommyOnMac> and to make a DSL -> other target compiler
02:40:39 <TommyOnMac> :)
02:41:01 <handonson> sounds AWESOME.
02:41:25 <TommyOnMac> the chips are mostly simple state machines inside
02:41:50 <McManiaC> no template haskell gurus here? :(
02:42:29 <handonson> just curious, but why C64? your favorite games there?
02:42:46 <TommyOnMac> and I don't know if one could/should emulate things like the cpu hogged the bus too long so the graphics chip missed a read and instead is showing what the cpu last read(you see code as colors)
02:42:57 <TommyOnMac> because it's a simple machine that i know since childhood
02:43:40 <TommyOnMac> with lots of interesting "bugs" in the hardware that people use to remove screen borders, get more colors, more sprites, new graphics modes etc
02:44:31 <handonson> what a cool system for hackers
02:44:47 <TommyOnMac> people are still coding demos on it, in 2010 :)
02:45:26 <ksf> is there a specialized map for sets?
02:45:53 <ksf> ...that is, one in which the lookup of a set is the union of its elements
02:46:56 * ski . o O ( "ifli" )
02:46:57 <handonson> the lookup of a set is the union of its elements? like lookup [[a]] :: [a]?
02:48:51 <ksf> well, the idea is that a lookup e.g. could avoid re-starting at the root of the tree and just keep on looking
02:56:58 <zygoloid> \o/ remote heap scavenging: working \o/
03:12:05 <aristid> handonson: huh?
03:12:07 <aristid> :t lookup
03:12:08 <lambdabot> forall a b. (Eq a) => a -> [(a, b)] -> Maybe b
03:12:17 <handonson> aristid: I know
03:12:24 <handonson> I use that function very often
03:12:26 <aristid> handonson: that type does not look like [[a]] -> [a] at all
03:12:37 <aristid> concat / join has this type, though.
03:12:48 <handonson> I was ASKING, man
03:13:03 <aristid> handonson: i don't UNDERSTAND your question then, man!
03:13:11 <handonson> I was asking because I couldn't understand "lookup of a set is the union of its elements"
03:13:17 <handonson> See the context, man!
03:13:22 <handonson> I wasn't asking YOU, either!
03:13:37 <aristid> :(
03:13:51 <Tomsik> > (sin+cos) 3
03:13:52 <lambdabot>   -0.8488724885405782
03:14:11 <Tomsik> @where instance Num (a->b) 
03:14:11 <lambdabot> I know nothing about instance.
03:14:18 <Gracenotes> blame ksf
03:14:19 <Tomsik> @src instance Num (a->b) 
03:14:19 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
03:14:23 <Gracenotes> witchhunt, witchhunt
03:14:27 <quicksilver> Tomsik: you won't find it that way.
03:14:31 <Tomsik> :(
03:14:36 <Tomsik> I wonder where it comes from
03:14:40 <quicksilver> lambdabot.
03:14:44 <aristid> Tomsik: the instance uses Applicative's pure/fmap/liftA2
03:14:49 <quicksilver> f + g = \x -> f x + g x
03:14:50 <quicksilver> etc.
03:14:55 <aristid> no, vector-spaces
03:15:01 <Tomsik> yeah, but is it from some package?
03:15:02 <quicksilver> no.
03:15:06 <quicksilver> it's from lambdabot.
03:15:08 <Tomsik> ah
03:15:13 <Tomsik> like (.) = fmap?
03:15:14 <aristid> quicksilver: Cale said vector-spaces yesterday
03:15:23 <aristid> did he lie, or did i misunderstand him?
03:15:28 <Cale> It's from vector-space
03:15:34 <quicksilver> hmm
03:15:37 <quicksilver> ok :)
03:15:58 <Cale> Data.NumInstances
03:17:05 * quicksilver doesn't like (ab)using instances like that, but it's probably just a matter of taste/familiarity.
03:18:16 <aristid> :t join (+)
03:18:17 <lambdabot> forall a. (Num a) => a -> a
03:27:14 <ksf> zomg my code works
03:27:46 <ksf> which means, as I can now reverse and determise, that I get MINIMISATION FOR FREE
03:28:54 <ksf> and it seems to be fast, too.
03:29:03 <ksf> ...for a four-state nfa, that is.
03:29:34 <Tomsik> heh
03:30:14 <Tomsik> Where does dfa minimization lie? PSPACE? 
03:30:40 <ksf> k n log n
03:31:00 <ksf> ...the double-reverse thing should at least come close to PSPACE in the worst case, though.
03:31:37 <ksf> the thing is, people fail to observe the worst case, and double-reverse regularily outperforms k n log n in randomized tests
03:32:40 <Tomsik> well, I guess it's like with quicksort
03:32:58 <Tomsik> nobody really sees n^2 if you don't feed it malicious data
03:33:45 <ksf> and if k is large enough to matter, many, many transitions are going to coincedence.
03:33:47 * gwern feeds Tomsik malicious data. keikaku doori!
03:34:33 <ksf> they should probably try to prove that dfa's with such insane connectivity can't be possibly doing anything sensible.
03:35:15 <Tomsik> I think it might be easier to prove that there's a negligible (in strict sense) number of them
03:36:09 <theorbtwo> What is the strict sense of negligible?
03:36:23 <Tomsik> less than 1/2^n
03:36:32 <Tomsik> O( ) obviously
03:37:28 <Tomsik> the proper definition is quantity f(n) is negligible if O(1/f(n)) >= 2^n
03:40:20 <ksf> four folds, one map, one explicit recursion (depth first scan)
03:40:36 <theorbtwo> Ah, I see.  It's negligible if it's not the highest-order contribution to the average case, and thus doesn't show up in the O()?
03:40:42 <ksf> ...and a lot of set and map operations
03:40:59 <handonson> @seen dons
03:40:59 <preflex>  dons was last seen on #ghc 15 hours, 59 minutes and 43 seconds ago, saying: yep.
03:41:00 <lambdabot> Unknown command, try @list
03:42:09 <Tomsik> theorbtwo: I'm not sure what you mean exactly, but it's like n^2 case for quicksort is negligible as it's one in n! cases
03:42:28 <handonson> "cabal install plugins" fails with a compile error!
03:42:29 <handonson> src/System/Plugins/PackageAPI.hs:61:24: Not in scope: `package'
03:43:14 <ksf> Tomsik, don't try to sell that to hard rt people, though.
03:43:38 <Tomsik> rt?
03:43:42 <ksf> real time
03:43:58 <zygoloid> http://metafoo.co.uk/heap <-- adventures in remote heap scavenging
03:44:00 <Tomsik> who are these? never heard that term
03:44:24 <aristid> Tomsik: hard real time = only worst case matters
03:44:25 <handonson> dons: "cabal install plugins" fails with a compile error
03:44:49 <ksf> I vaguely remember a developer staring at his code, wondering why the testers reported seemingly random, quite long framedrops. he already ruled out gc.
03:45:02 <ksf> ...he used a bleeding hash table.
03:45:07 <Tomsik> heh
03:45:18 <Tomsik> but you know, worst case for sat is 2^n
03:45:21 <zygoloid> Tomsik: the trouble is if the one in n! cases happens to be a common case (like if you use the first element as a pivot, it's the case where the list is already sorted)
03:45:26 <Tomsik> and there are reasonable sat-solvers already
03:46:07 <ksf> games are only soft rt because you only get fragged, not killed.
03:46:20 <Tomsik> yeah
03:46:21 <dschoepe> Not exactly a Haskell question, but I'll ask anyway: How do I prove that two terminal objects(let's call them 1 and 1') in a category are isomorphic? I already know that there have to be arrows f : 1 -> 1' and g : 1' -> 1, because they are terminal, but how do I show that f . g = id_1' and id_1 = g . f?
03:46:58 <zygoloid> dschoepe: what arrows exist from the objects in question? what can f . g be?
03:48:15 <zygoloid> (how many inhabitants does the 'type' 1 -> 1 have?)
03:48:37 <dschoepe> ah, thanks.
03:49:50 <ksf> the scary thing is that determinising amounts to 20 LOC
03:50:27 <dschoepe> zygoloid: so whenever I have some composition of arrows with the same domain and codomain, it has to be equal to the identity arrow? Or is this a special case because f and g are unique?
03:51:01 <quicksilver> dschoepe: it is certainly a special case.
03:51:05 <Tomsik> ksf: LOC?
03:51:09 <quicksilver> dschoepe: the point is by the definition of terminal object.
03:51:11 <zygoloid> dschoepe: that's a special case because the codomain is a terminal object. the definition of a terminal object means that arrow is unique
03:51:18 <ksf> lines of code
03:51:27 <Tomsik> heh
03:51:33 <quicksilver> in general there can of course be many arrows from an objection to itself.
03:51:38 <Tomsik> 20 is hell a lot of lines for haskell
03:51:49 <zygoloid> domain == codomain means there exists such an arrow which is the identity. therefore your arrow is also the identity.
03:52:37 <dschoepe> zygoloid, quicksilver: Okay, I think I got it. thanks
03:52:56 * zygoloid should implement a heap object pretty-printer. (:) (C# 'c') ((:) (C# 'h') $1) ~> "ch" ++ $1 would be nice
03:52:58 <edwardk> zygoloid: well, i think you might want to be careful with that. you know they are the same, because they are both unique and have the same source and destination
03:52:58 <lambdabot> edwardk: You have 1 new message. '/msg lambdabot @messages' to read it.
03:53:32 <quicksilver> zygoloid: isn't there some of that in vacuum?
03:53:33 <zygoloid> edwardk: right. we have uniqueness, and existence of one such arrow. therefore all such arrows are that arrow.
03:53:45 <quicksilver> ISTR it has special cases for some built-in types
03:54:36 <zygoloid> quicksilver: thanks, i'll have a look. my representation and its are slightly different, but if nothing else it should be a good source of ideas
03:55:38 <ksf> in the reverse case, it's four lines. three to change start to end nodes and vica-versa, and one to map those three lines over the graph and a call to grev...
03:56:56 <ksf> but, yes, most haskell LOC always end up to be boilerplate. actual algorithms are insanely dense.
03:58:23 <Tomsik> like any other language I guess
03:59:14 <ksf> in the c case, there tend to be a lot of lines doing pointer mangling.
03:59:28 <p_l> Tomsik: I'm not sure if I had seen lots of dense algorithms in Java
03:59:39 <p_l> however, Java is a language where you need four lines to open a file
03:59:41 * zygoloid has hundreds of lines of haskell doing pointer mangling ;-)
03:59:57 <zygoloid> it would be nice if ghc used a more uniform heap representation ;(
04:00:25 <Tomsik> p_l: still there's a lot of boilerplate there
04:01:20 <p_l> Tomsik: Well, I'm not a haskell expert (just dabbling around) but I find precious little boilerplate in Haskell, though I possibly classify different things as boilerplate
04:02:08 <Tomsik> well, truth is that in things like Java you rarely write any algorithms at all
04:02:27 <manjunaths> how do I set XScopedTypeVariables in ghci ?
04:03:24 <manjunaths> ah...found it
04:13:00 <illissius> McManiaC: just make a separate SigD and FunD, and make sure they use the same name, I would think?
04:29:31 <CakeProphet> What are some good packages for stream abstractions?
04:30:10 <Twey> Iteratee
04:35:20 <burp> http://pi.nersc.gov/cgi-bin/pi.cgi?word=haskell&format=char
04:38:24 <CakeProphet> Twey:  that's not a standard typeclass is it?
04:38:35 <CakeProphet> er, data structure
04:39:13 <CakeProphet> :t ShowS
04:39:14 <lambdabot> Not in scope: data constructor `ShowS'
04:39:17 <Twey> CakeProphet: Err… it's a package that provides stream abstraction
04:39:31 <CakeProphet> Twey:  ah. I was reading from the Haskell wiki about the concept.
04:39:38 <Twey> (which is an implementation of the concept of the same name)
04:40:02 <Twey> burp: I'm confused.  What encoding are they using?
04:40:10 <CakeProphet> hmmm, there's a lot of packages. What should I use for simple string handling?
04:40:21 <CakeProphet> well, I guess IO.Handle is good
04:40:26 <CakeProphet> since I'm using a Handle.
04:41:02 <burp> Twey: a-z from 1 to 26 binary encoded
04:41:09 <Twey> burp: Ah, okay
04:41:14 <CakeProphet> apparently fds are preferred. Can you convert Handle to Fd?
04:41:34 <Twey> CakeProphet: I'm confused as to what you're attempting to do.
04:41:51 <Twey> CakeProphet: Handles don't provide any form of stream abstraction.
04:42:15 <CakeProphet> Twey:  I'm not entirely sure what stream abstractions are used for, I assume IO handling of some kind?
04:42:38 <Twey> FDs are an internal implementation detail, and not intended for use
04:43:10 <Twey> Stream abstractions are used for… abstracting streams?
04:43:52 <CakeProphet> Twey:  right, but what practical purposes does that serve?
04:44:23 <Twey> CakeProphet: Composability, performance, brevity, separation of concerns
04:45:07 <Twey> CakeProphet: You seem to have asked for ‘stream abstractions’ without really knowing what you meant by the term
04:45:14 <Twey> CakeProphet: Would you like to revise your query?
04:46:54 <CakeProphet> ...nevermind
04:49:41 <CakeProphet> Twey:  I assume a stream abstraction allows you to apply some kind of processing to the stream right? 
04:54:09 <mrdk> How can I simplify an expression like `(take (n - length a - length b) (repeat ""))`?
04:55:12 <CakeProphet> :t replicate
04:55:13 <lambdabot> forall a. Int -> a -> [a]
04:55:20 <CakeProphet> > replicate 10 ""
04:55:21 <lambdabot>   ["","","","","","","","","",""]
04:55:43 <CakeProphet> mrdk:  use that instead.
04:55:57 <CakeProphet> from the same module.
04:56:05 <mrdk> CakeProphet: thank you, this is much nicer
04:56:20 <CakeProphet> @src replicate
04:56:20 <lambdabot> replicate n x = take n (repeat x)
04:56:45 <mrdk> oh, hehe
04:57:36 <CakeProphet> abstraction is fun like that. 
04:58:05 <mrdk> indeed
05:00:09 <CakeProphet> is there an easy way to cut down on the computational expense of string processing? Things like text replaces, for example.
05:01:04 <opqdonut> bytestrings can help
05:07:59 <Twey> "" `replicate` n - length a - length b
05:08:15 <Twey> CakeProphet: See the ‘text’ package
05:08:24 <Twey> CakeProphet: Streams are themselves an abstraction
05:08:42 <Twey> CakeProphet: The OS provides you with the standard C FD interface, over which Handles are a thin wrapper
05:08:57 <portnov> @src error
05:08:58 <lambdabot> error s = throw (ErrorCall s)
05:08:59 <Twey> CakeProphet: Whereby you have to explicitly read, process, and write
05:09:31 <Twey> CakeProphet: A stream is an abstraction over this (and other things) that represents the input as a single, continuous stream that can be processed in series
05:10:09 <Twey> CakeProphet: Lazy IO also provides a ‘stream abstraction’, of sorts, but iteratees have many advantages over lazy IO
05:10:29 <ath> jMTt6Z97RuCunkoLiX
05:10:29 <ath> ;; then enter the text in that file's own buffer.
05:10:29 <ath> jMTt6Z97RuCunkoLiX
05:10:29 <ath> jMTt6Z97RuCunkoLiX
05:11:19 <CakeProphet> Twey:  Lazy IO is getContents, for example?
05:11:48 <Twey> Yes
05:12:28 <CakeProphet> what kinds of advantages? I'm more familiar with regular string processing, so I might not use a stream abstraction at all due to lack of need.
05:12:54 <Twey> It's a rather patchy abstraction, as it fails to encapsulate many of the features of the original (like predictable reads/writes and error-handling)
05:13:24 <CakeProphet> ah. hmmm
05:14:17 <Twey> If Handle suffices for your purposes, then by all means use it — there's no point abstracting if you don't need to.  It was you who asked for abstractions.
05:14:40 <Twey> OTOH, iteratees are very much worth learning.
05:14:45 <CakeProphet> yeah, I'm just wondering if there are better ways to do things. I don't necessarily know what those things are though.
05:15:22 <Twey> Iteratee is probably the one to go for, then.
05:15:42 <zygoloid> mrdk: i suspect you're trying to pad a string. you can do that better than by using 'length'...
05:15:49 <CakeProphet> I only have some minor processing I'd like to do.
05:16:58 <Twey> I don't think so… those are empty strings
05:17:14 <zygoloid> > (\n xs -> take n $ xs ++ repeat "") 5 ["hello", "world"]
05:17:15 <lambdabot>   ["hello","world","","",""]
05:17:34 <zygoloid> Twey: yeah, that's true. but what it's a list /of/ doesn't really matter :)
05:17:56 <Twey> Yeah — my point was that they're unlikely to be trying to pad a string using null strings
05:18:18 <zygoloid> yes, i agree. i missed that on my first readong
05:19:24 <mrdk> zygoloid: I'm not trying to pad, this is what I am doing: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27794
05:19:41 * Twey squints.
05:21:02 <zygoloid> mrdk: ah, i see. you're adding "padding" or whatever to the middle of the list. that's trickier :(
05:21:15 <mrdk> zygoloid: exactly :)
05:21:57 <zygoloid> mrdk: it might be cleaner to use Maybe String there (unless you also want special handling for empty strings in a and b?)
05:23:02 <mrdk> zygoloid: yes, a and/or b could be two empty lists
05:23:06 <zygoloid> mrdk: i'm guessing it's an error if n < length a + length b?
05:23:15 <zygoloid> mrdk: can a and b contain ""?
05:23:48 <mrdk> zygoloid: yes
05:24:42 <mrdk> I also declared it as `number n [] [] = map show [1..n]`
05:26:10 <zygoloid> it'd be a little lazier to write: show i ++ (if s /= "" then "-" ++ s else ""), but that's not likely to make any real difference
05:27:03 <mrdk> zygoloid: well, at least something
05:28:11 <mrdk> I was thinking about how to simplify The if..else, but this seems to be the only way
05:28:35 <zygoloid> you can write something like: guard (s /= "") >> ('-':s), but that's significantly less clear imo
05:28:56 <zygoloid> or you could factor it out into a function (showSuffix or something)
05:29:26 <Deewiant> if null s then s else '-':s
05:30:22 <mrdk> oh that one's nice
05:30:54 <zygoloid> i'd be tempted to write the whole thing as a zipWith rather than as a comprehension
05:30:58 <Twey> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27794#a27796
05:31:00 <Deewiant> (if null s then id else ('-':)) s
05:31:12 <Twey> Mmm, zipWith might be nice
05:32:27 <zygoloid> > let f n a b = zipWith showWithSuffix [1..] (a ++ take (n - length a - length b) (repeat "") ++ b); showWithSuffix n "" = show n; showWithSuffix n s = show n ++ "-" ++ s in f 5 ["hello", "world"] ["goodbye"]
05:32:29 <lambdabot>   ["1-hello","2-world","3","4","5-goodbye"]
05:33:46 <mrdk> I see there are a lot of ways to do it
05:34:46 <zygoloid> i'm still not keen on the 'length', but removing it is awkward :(
05:35:46 <Twey> Yeah
05:35:57 <Twey> I feel there should be a better way to do this than the intermediate null strings
05:36:06 <Twey> But damned if I know what it is
05:36:23 <CakeProphet> what is the problem?
05:39:27 <mdmkolbe> What is the proper term for the relationship between "Typeable" and "Data"?  "superclass"?
05:39:38 <zygoloid> > let f n a b = [show i ++ maybe "" ('-':) (M.lookup i m) | i <- [1..n]] where m = M.fromList (zip [1..] a) `mappend` M.fromList (zip [n,n-1..] (reverse b)) in f 5 ["hello", "world"] ["goodbye"]
05:39:39 <lambdabot>   ["1-hello","2-world","3","4","5-goodbye"]
05:39:47 <zygoloid> ^^ the lengths are gone, at least :)
05:40:07 <zygoloid> but it's asymptotically slower, and less lazy ;(
05:40:27 <zygoloid> (it also gives different results if length a + length b > n
05:40:55 <CakeProphet> okay. So if I want logging support inside a monad should I use WriterT?
05:40:56 <zygoloid> mdmkolbe: yes.
05:41:19 <zygoloid> CakeProphet: yep, that's a reasonable choice.
05:41:27 <mrdk> zygoloid: nice, but I think I stick to the simpler solution :P
05:41:56 <fxr> what is the meaning of MonadIO instance defined for IterateeG? I mean what MonadIO instance provides?
05:42:30 <zygoloid> fxr: (MonadIO m) provides liftIO :: IO a -> m a. this allows you to run arbitrary IO actions insode m.
05:42:47 <fxr> oh, okay.
05:43:13 <fxr> thank yo zygoloid 
05:44:21 <fxr> @let runtest i = unWrap ∘ runIdentity ∘ run ∘ runIdentity $ (enumBS abc (i >> stream2stream))
05:44:22 <lambdabot>  <local>:1:12: Not in scope: `unWrap'
05:44:23 <lambdabot>  
05:44:23 <lambdabot>  <local>:1:19: Not in scope: `∘'
05:44:23 <lambdabot>  
05:44:23 <lambdabot> ...
05:45:00 <Zao> Cute ball codepoint, once you find a font that has it.
05:45:05 <fxr> so in order to use IO in my iteratees, say defining runtestIO , I'll liftIO twice right?
05:46:43 <CakeProphet> hmmm, so listen returns (a,w)?
05:47:14 <fxr> ok, worked. thanks.
05:47:24 <CakeProphet> @src mappend []
05:47:24 <lambdabot> Source not found. Take a stress pill and think things over.
05:47:35 <CakeProphet> @src [a] mappend
05:47:35 <lambdabot> Source not found. Do you think like you type?
05:48:17 <Deewiant> @src [] mappend
05:48:18 <lambdabot> Source not found. There are some things that I just don't know.
05:48:25 <Deewiant> Doesn't have it
05:48:31 <Deewiant> @src [] return
05:48:32 <lambdabot> return x    = [x]
05:50:12 <varnie> hello. could someone help me in understanding why do we the following code snippet doesn't work?
05:50:13 <varnie> snd fst(("one",2), True)
05:50:40 <quicksilver> varnie: that tries to call "snd" with two arguments
05:50:48 <quicksilver> ...the first argument being the function 'fst'
05:50:53 <zygoloid> varnie: that parses as (snd fst) (("one", 2), True)
05:50:55 <Zao> That's (snd fst) ((...
05:50:58 <quicksilver> and the second being (("one",2"),True)
05:51:11 <varnie> and why so? function application should occur firstly, if i'm not mistaken
05:51:19 <Zao> varnie: That's what it does.
05:51:22 <quicksilver> function application is first, yes
05:51:23 <zygoloid> varnie: it's left-associative.
05:51:25 <varnie> it computes "from right to the left", right?
05:51:27 <Zao> It applies the function snd to fst.
05:51:32 <quicksilver> no, from left to right
05:51:42 <CakeProphet> hmmm... okay
05:51:43 <handonson> function application occurs firstly, so "snd fst" is associated first
05:51:50 <quicksilver> "f a b" is f applied to a and b
05:51:54 <varnie> ahha, now i see!!
05:51:56 <Zao> Note that the parens in  omg(wtf)   do not tighten any bonds.
05:52:05 <quicksilver> not a applied to b and f applied to the results of that
05:52:07 <Zao> It's exactly the same as  omg wtf
05:52:25 <Zao> Parens group things.
05:52:33 <Zao> (and form tuples, I guess)
05:52:39 <CakeProphet> so for Writer. Would it be reasonable to make a data structure that basically represents different types of log messages. data Log s = DebugLog s | WarningLog s | ErrorLog s | GeneralLog s
05:53:11 <CakeProphet> and then make a monoid instance for log?
05:53:18 <varnie> one more newbie question: why there's no cons for tuple construction?
05:53:29 <handonson> I often want "f a b" to be "f (a b)", but since it's not really consistent with the Haskell's concept that if "f :: a -> b -> c" then "f a" returns a function that is "b -> c", it's impossible.
05:53:34 <Zao> There's a tuple section extension.
05:53:37 <CakeProphet> varnie:  cons? as in (,)
05:53:47 <zygoloid> CakeProphet: i'm guessing you probably want to use [Log s] as your monoid
05:53:48 <Zao> > (,,) "omg" "wtf" "bbq"
05:53:49 <lambdabot>   ("omg","wtf","bbq")
05:53:56 <varnie> as for [2]:[1]:[]
05:54:05 <CakeProphet> zygoloid:  I was just considering that.
05:54:06 <zygoloid> CakeProphet: (or something like it, but less inefficient when used in a writer)
05:54:18 <CakeProphet> zygoloid:  what would an example of that be?
05:54:25 <Zao> varnie: How would it know the arity of the end result, and what would the type of the intermediary be?
05:54:28 <handonson> so I end up using with $ everywhere in my code, which makes it look very capitalistic like PHP
05:54:45 <zygoloid> Dual [Log s] is reasonable but reverses the order of log messages. ([Log s] -> [Log s]) is also reasonable.
05:54:50 <Zao> handonson: Use a different font that replaces the glyph with a peace sign.
05:55:02 <varnie> Zao, thanks. i should think about that.
05:55:06 <zygoloid> (i guess if you ContT the WriterT that should be fine too?)
05:55:08 <CakeProphet> zygoloid:  I was thinking a linked list whose mappend was more like (:) than (++)
05:55:12 <mm_freak_> hmm…  somehow i have the impression that everywhere, where arrows are used, monads and regular functions could have been used just as well =/
05:55:15 <handonson> varnie: err... [2]:[1]:[] is not valid, actually.
05:55:32 <zygoloid> > handonson why not? it's [[2], [1]]
05:55:33 <lambdabot>   Not in scope: `handonson'Not in scope: `why'Not in scope: `it's'Not in scop...
05:55:34 <mm_freak_> looks valid to me
05:55:39 <Zao> varnie: Note that the list (:) constructor is   a -> [a] -> [a]
05:55:42 <mm_freak_> > [2]:[1]:[]
05:55:43 <lambdabot>   [[2],[1]]
05:55:49 <CakeProphet> zygoloid:  so I could append O(1) and then do a O(n) reverse before log output.
05:56:00 <varnie> handsons, it works: Prelude> let c = [2]:[1]:[]
05:56:00 <varnie> Prelude> c
05:56:00 <varnie> [[2],[1]]
05:56:15 <Zao> Odd choice of example though.
05:56:23 <zygoloid> CakeProphet: yeah, that'd be fine. Dual does that for you, to some extent, by changing the right-mappend into a left-mappend.
05:56:37 <handonson> oops, I got confused. [2]:[1]:[0] is the one of problem
05:56:41 <CakeProphet> zygoloid:  left-mappend?
05:56:57 <zygoloid> instance Monoid m => Monoid (Dual m) where Dual a `mappend` Dual b = Dual (b `mappend` a)
05:57:06 <handonson> varnie: but is it really what you meant? [[2], [1]] instead of [2, 1] ?
05:57:08 <CakeProphet> zygoloid:  does that mean the first argument is copied? I think that might be counterproductive.
05:57:33 <CakeProphet> ah.
05:57:34 <zygoloid> CakeProphet: it means that you can use 'tell' in the writer, and the thing you tell gets prepended rather than appended.
05:57:44 <CakeProphet> right.
05:57:55 <varnie> handonson, it is a good question. it doesn't matter currently, because i just wanted to demonstrate the work of cons for lists
05:58:28 <zygoloid> i guess ContT (WriterT [Log s]) would be more elegant, but i'm not 100% sure it solves the problem.
05:58:36 <quicksilver> > (,) 2 1
05:58:37 <lambdabot>   (2,1)
05:58:41 <quicksilver> ^^ cons for tuple construction.
05:58:44 <handonson> cons like the cons function in Data.ByteString? then it's definitely not [2]:[1]:[]
05:58:47 <quicksilver> not sure if that's what varnie meant.
05:59:00 <Deewiant> > (,) 3 ((,) 2 1)
05:59:01 <lambdabot>   (3,(2,1))
05:59:06 <CakeProphet> zygoloid:  but mappend copies the right-hand side correct? So wouldn't non-dual mappend be more efficient in this case?
05:59:28 <zygoloid> CakeProphet: it depends on the monoid. for [], mappend copies the spine of the LHS.
05:59:29 <Zao> quicksilver: Are those available without -XTupleSections?
05:59:35 <byorgey> > (1,,3) 2
05:59:36 <lambdabot>   <no location info>: parse error on input `,'
05:59:45 <orlandu63> why does (,,), (,,,), etc work? is it syntactic sugar or does it functionally make sense?
05:59:46 <quicksilver> Zao: (,) is in the prelude always has been.
05:59:51 <varnie> my question is from one haskell tutorial. it's been asked what are the restrictions that lead to decision not to "invent" const for tuples
05:59:58 <quicksilver> orlandu63: they're just names.
06:00:02 <zygoloid> orlandu63: it's just the name of the constructor for an n-tuple.
06:00:04 <byorgey> orlandu63: those are just the names of the tuple constructors.
06:00:07 <quicksilver> orlandu63: there is a little magic in that they're not normally names
06:00:12 <quicksilver> not normally legal, I mean
06:00:16 <byorgey> orlandu63: really, (1,2,3) is syntactic sugar for (,,) 1 2 3
06:00:17 <quicksilver> but apart from that, they're just names.
06:00:19 <CakeProphet> zygoloid:  ah, so Dual [] will have a more efficient tell, because the smaller list's spine will be copied instead.
06:00:21 <Deewiant> Zao: Tuple sections enables stuff like ("foo",) :: a -> (String,a)
06:00:27 <zygoloid> CakeProphet: right.
06:00:28 <orlandu63> ah okay
06:00:49 <varnie> i meant "cons" not "consts" of course. just a typo, sorry.
06:01:05 <quicksilver> varnie: then I don't know what they are talking about.
06:01:14 <quicksilver> (,) is 'cons' in the traditional lisp sense.
06:01:17 <quicksilver> It builds pairs.
06:01:49 <Zao> Say that the cons operator is %. What would be the type of a%b in a%b%c?
06:01:56 <Zao> Assuming it's supposed to be a 3-tuple?
06:01:57 <quicksilver> arguably, so is (:) - the only difference between (,) and (:) is that which is imposed by the type checker, and of course that's the big difference between haskell and lisp.
06:02:11 <quicksilver> both (:) and (,) are arguably LISP cons.
06:03:02 <CakeProphet> :t runStateT
06:03:03 <lambdabot> forall s (m :: * -> *) a. StateT s m a -> s -> m (a, s)
06:03:15 <zygoloid> Zao: (%) :: (Cons a b ~ c) => a -> b -> c, with some OverlappingInstances :o
06:03:41 * zygoloid feels dirty for suggesting that
06:04:23 <opqdonut> if you think about "data List a = List (a,List a) | Nil"
06:04:40 <Zao> zygoloid: Kinky.
06:04:44 <opqdonut> then (:) is just (List .) . (,)
06:07:03 <CakeProphet> how does deriving Ord work?
06:07:25 <zygoloid> CakeProphet: left-to-right over constructors, lexicographically within them
06:07:28 <quicksilver> lexicographic for sum types
06:07:37 <quicksilver> erm
06:07:42 <quicksilver> lexicographic for product types
06:08:00 <quicksilver> in order for sums, and using the existing instances for included types.
06:09:01 <CakeProphet> ....that's a very complicated procedure.
06:09:11 <mm_freak_> does anyone know of a good example of really using arrows?  i mean something, which illustrates, why in that particular case arrows are better than monads or even regular functions
06:09:19 * zygoloid wonders how GHC codegens the left-to-right ordering for constructors. presumably it doesn't generate O(n^2) code.
06:09:34 <zygoloid> i'm guessing ctorIndex :: D -> Int
06:09:48 <CakeProphet> okay so I have
06:09:55 <CakeProphet> data Log s         = Debug s | Info s | Warning s | Error s deriving (Eq,Ord,Enum)
06:10:13 <quicksilver> CakeProphet: it's not really that complex.
06:10:15 <CakeProphet> Debug "Hello" < Info "Apples"
06:10:18 <CakeProphet> correct?
06:10:20 <zygoloid> yes
06:10:20 <quicksilver> yes.
06:10:25 <quicksilver> Debug < Info < Warning < Error
06:10:33 <CakeProphet> alright, good. :)
06:10:39 <quicksilver> and Debug x < Debug y iff x < y
06:10:45 <quicksilver> and deriving Enum there might be a mistake.
06:10:52 <CakeProphet> oh?
06:11:13 <quicksilver> I think that requires 's' to have an Enum instance to use. Or maybe it simply doesn't work.
06:11:30 <quicksilver> I don't remember how Enum behaves with nested types
06:11:49 <quicksilver> but assuming s = String is a common example, and String doesn't have an Enum instance...
06:11:51 <zygoloid> if you have data Foo = Foo A B C, then compare (Foo a1 b1 c1) (Foo a2 b2 c2) = compare a1 a2 `mappend` compare b1 b2 `mappend` compare c1 c2
06:12:06 <varnie> how some function which doesn't return nothing must be declared ?
06:12:22 <quicksilver> varnie: what's the point of a function which doesn't return anything?
06:12:44 <varnie> suppose, it checks smth and prints smth on the screen, NOT returning that
06:12:55 <zygoloid> varnie: ah, then you want to return IO a, for some a.
06:12:55 <quicksilver> that wouldn't be a function.
06:13:08 <quicksilver> IO ()
06:13:18 <quicksilver> is the type of an IO action which has no interesting value to return
06:13:31 <quicksilver> @type putStrLn "hi"
06:13:32 <lambdabot> IO ()
06:13:35 <quicksilver> for example.
06:13:55 <varnie> that's fine. so, speaking shortly, haskell functions should return smth anyhow. is it correct statement?
06:13:57 <zygoloid> varnie: really, your function isn't printing something and returning nothing. it's returning a recipe for printing something and producing no value.
06:14:49 <zygoloid> varnie: the difference is, if your function is 'putStrLn', then: "do let v = putStrLn "Hello"; v; v" will print "Hello" twice, not once
06:15:12 <Zao> f :: a  <- the function takes no parameters and returns something of type a.
06:15:23 <Zao> f :: () <- the function is nullary and returns a value of type ().
06:15:46 <Zao> f :: IO () <- nullary function returning an "IO action that produces something of type ()"
06:15:48 <quicksilver> obviously, I'm being pedantic, but, neither of those is a function.
06:15:59 <varnie> Zao, and how should we program the 2nd function to return () then ?
06:16:00 <quicksilver> a function has type a -> b
06:16:04 <Zao> What would you call a nullary function? value?
06:16:07 <quicksilver> yes.
06:16:24 <Zao> f = () -- this would be   f :: ()
06:16:44 <Zao> Much like how f x = ()  would be f :: a -> ()
06:16:59 <quicksilver> that really is a function which always returns ()
06:17:08 <quicksilver> ...but it's not a very useful function in general :)
06:17:11 <handonson> technically they're values not functions, but it also makes sense (and easier for me) to think everything's function in Haskell
06:17:17 <zygoloid> it's the same general sort of pedantry which would refer to 'a -> b -> c' as a function returning a function rather than a 2-argument function :)
06:17:29 <quicksilver> I don't think it makes sense to think everything is a function.
06:17:39 <quicksilver> -> is the function constructor.
06:17:50 <Zao> quicksilver: You need more procedural damage.
06:17:59 <varnie> damage? :)
06:18:01 <handonson> well, "=" is not function either
06:18:27 <quicksilver> if I'm discussing how it's hard to serialise functions, or how functions can conceal exceptions, or...
06:18:34 <Twey> A function is a mapping from an input to an output
06:18:45 <handonson> by 'everything' i meant functions, values, data constructors, etc.
06:18:51 <quicksilver> then when I say function, I mean function. (Or how it's hard to write an Ord instance for a function, or any number of other contexts where I would use the word 'function')
06:19:12 <Zao> quicksilver: What is your feeling on the use of the term "functor" in C++? :D
06:19:20 <quicksilver> ;)
06:19:29 <quicksilver> I don't expect C++ terminology to make sense.
06:19:35 <quicksilver> I expect it to cause facial bleeding.
06:19:42 <quicksilver> I have higher hopes for haskell.
06:19:47 <handonson> this approach was especially useful for me when I had to think about what I could pass around
06:20:14 <quicksilver> zygoloid: I don't think it's quite the same. I'm quite happy with a -> b -> c as being a function which takes two arguments.
06:20:29 <quicksilver> zygoloid: but I'm just not at all happy with (5::Int) being a function.
06:20:39 <zygoloid> quicksilver: but you're not happy with generalizing to functions which take zero arguments?
06:20:42 <Twey> … what is the C++ use of the term ‘functor’?
06:21:02 <vanadium> Any f that you can say f(x, y, ...) on is a functor
06:21:04 <zygoloid> (i can certainly understand that distinction, what with the former being a function and the latter not)
06:21:07 <handonson> so in this approach, values are nullary functions, technically-strict functions that take values and return values are unary functions, functions that take value->value functions and return values are binary functions, ...
06:21:12 <quicksilver> zygoloid: I can see it as a handy thing to consider when generalizing a theorem. But for every day usage, no.
06:21:15 <Twey> « Functors are functions with a state. »
06:21:15 <FunctorSalad_> is there some kind of hybrid of State and Writer that supports mappending to the output and reading the output, but not shortening it?
06:21:18 <Twey> Oh gods
06:21:19 <FunctorSalad_> (or overwriting it)
06:21:22 <handonson> oops.
06:21:37 <FunctorSalad_> (reading the output so far as in State's get)
06:21:42 <handonson> i mean, functions that take values and return value->value functions are binary functions, ...
06:21:50 <kdvh> function objects i think, Twey
06:21:50 <quicksilver> FunctorSalad_: Writer.
06:22:00 <FunctorSalad_> (I don't know if this extra restriction on state gives any performance benefit)
06:22:06 <zygoloid> @type listen
06:22:07 <lambdabot> forall (m :: * -> *) a w. (MonadWriter w m) => m a -> m (a, w)
06:22:09 <zygoloid> FunctorSalad_: ^^
06:22:30 <quicksilver> C++ functors are things which support function call syntax
06:22:46 <quicksilver> i.e. things that you can instantiate a template over, which is expecting a "function", and not get an error.
06:22:47 <FunctorSalad_> hmm I thought of `listen' but it isn't quite `get' ;) never used listen so I'm not sure where you can use it
06:23:15 <quicksilver> in practice that's either a true function or a type with an overloaded operator()
06:23:20 <zygoloid> FunctorSalad_: you have to wrap it around the computation which produces the log you're interested in
06:23:22 <quicksilver> unless there is a third way I've forgotten.
06:23:28 <vanadium> or a function pointer *cough*
06:23:32 <quicksilver> vanadium: thanks :)
06:23:46 <quicksilver> but a true function is a function pointer, in C++, more or less?
06:24:08 <Zao> If you intend to juggle it around at all, yeah.
06:24:09 <FunctorSalad_> zygoloid: yep, so get seems like fix (\self -> fst <$> listen self) or so ;)
06:24:12 <Twey> quicksilver: My poor brain
06:24:13 <zygoloid> quicksilver: it's not quite "things which support function call syntax" though, since f->*pmf isn't a functor iirc
06:24:14 <vanadium> Rather less, but you cannot pass functions by value, and you can call a function pointer just like a function, so the distinction does not buy you much.
06:24:34 <FunctorSalad_> (haven't thought that through)
06:24:57 <quicksilver> zygoloid: you are very likely right. Not tried that :) If it isn't, I bet boost has a wrapper which makes it one.
06:24:59 <handonson> in the strict sense of function, all functions are unary, but that's not good for everyday use. RWH, LYH, and other good documentations all use the concept of more-than-binary functions, like "this functions takes n arguments"
06:25:05 <FunctorSalad_> @type fix (\self -> fst <$> listen self)
06:25:06 <lambdabot> forall a b (f :: * -> *). (MonadWriter b f, Functor f) => f a
06:25:19 <zygoloid> quicksilver: there's mem_fun in the STL for that (but it's a bit awkward)
06:25:31 <handonson> this function*
06:25:34 <quicksilver> zygoloid: awkward? C++? STL? Say it isn't so!
06:25:37 <zygoloid> sorry, i guess the second half of that was implied by the first half!
06:25:38 <FunctorSalad_> meh I extracted the value, not the log
06:25:58 <zygoloid> speaking of c++, i better do some if i want to get paid :)
06:26:00 <vanadium> There is boost::bind which is more general and therefore less awkward :)
06:26:11 <quicksilver> handonson: Sure.  It's fine to talk of a function taking 2 arguments etc,
06:26:13 <FunctorSalad_> (but anyway, that was just in respones to "having to know the previous computation" vs State "knowing itself")
06:26:29 <quicksilver> (but it's important to remember that really a function taking 2 arguments is a function taking 2 or more arguments)
06:26:42 <Zao> function<> is the saviour of mankind.
06:27:13 <quicksilver> Zao: if we accept that is so, then we have to remark that if it wasn't for C++ mankind wouldn't have been in peril?
06:27:28 <Zao> I'm quite surprised that you can abuse syntax enough to get  function<T (A1,A2,A3)>
06:27:35 <zygoloid> quicksilver: as it happens i think there's yet another viewpoint on what is/isn't a function; operationally, there's a difference between a function which needs 1 argument before it runs some code and a function which needs 2 arguments before it runs some code
06:27:46 <quicksilver> zygoloid: certainly.
06:27:57 <Zao> quicksilver: Callbacks otherwise tend to be quite demonic, with interface classes to implement and oh my.
06:28:04 <quicksilver> zygoloid: and that's interesting but subordinate to all the above discussion.
06:28:13 <zygoloid> though i guess it's far from obvious what the arity of a function is from the source level
06:28:14 <Zao> quicksilver: That's one interpretation :D
06:28:16 <zygoloid> yeah, agreed.
06:28:19 <quicksilver> zygoloid: things which are 'only' operational are subordinate to things which are denotational.
06:28:31 <Zao> What's the arity of printf?
06:28:43 <quicksilver> the question only makes sense when you fix the type
06:28:54 <zygoloid> Zao: you mean the typeclass-hacky printf?
06:28:57 <quicksilver> printf is overloaded so it doesn't have a type out of context
06:29:10 <quicksilver> but for a simpler example, note that "id" takes one argument:
06:29:12 <quicksilver> @type id
06:29:12 <Zao> zygoloid: There's other ones?
06:29:13 <lambdabot> forall a. a -> a
06:29:19 <zygoloid> Zao: there's at least one TH one
06:29:19 <quicksilver> but we can treat it as if it takes two:
06:29:20 <FunctorSalad_> printf-TH produces very simple types....
06:29:23 <FunctorSalad_> :)
06:29:23 <quicksilver> @type uncurry id
06:29:24 <lambdabot> forall b c. (b -> c, b) -> c
06:29:51 <FunctorSalad_> sadly I don't know of any way to postcompose printf-TH with something
06:29:53 <Twey> Zao: It's a single-argument function, like every other Haskell function.  ;)
06:30:00 <FunctorSalad_> for example to make a putStrF
06:30:10 <FunctorSalad_> seems like you'd have to hack the TH function
06:30:13 <handonson> quicksilver: I remember some time in past, in this channel, someone (a newbie) was confused, asking, what is the return value of "f :: a -> b -> c". I answered "it takes to arguments a and be, and return c", but other people started lecturing what higher-order function is, how first-class functions are in Haskell, and what variety of things f can return, etc. I never thought they were doing the right thing. it was just too much information for a newbie, not
06:30:13 <handonson>  helpful at all, only increasing the confusion the questioner had, ...
06:30:24 <zygoloid> given "foo True = id; foo False = \f x -> f x", the arity of "foo b" depends on b, even.
06:30:48 <SevenInchBread> hmmm
06:30:52 <FunctorSalad_> (but that hack could probably be done once and for all)
06:31:03 <CakeProphet> I should learn TH. I bet there are some convenient things one can do with it.
06:31:14 <quicksilver> handonson: Yes, that's a real problem in this channel.
06:31:20 <Twey> handonson: In the short term, that may be so; however, to talk about multi-argument functions in Haskell will cause the newbie serious confusion in the long run.
06:31:37 <handonson> Twey: no, it won't.
06:31:41 <handonson> Twey: I am a living example.
06:31:43 <FunctorSalad_> gprintf :: String -> ExpQ -> ExpQ
06:31:44 <quicksilver> handonson: it's always tricky with complex questions and multiple people having their own opinion on the best way to teach the answer.
06:31:44 <FunctorSalad_> it'd wrap the second arg around the result of printf
06:31:47 <zygoloid> CakeProphet: you may be disappointed. TH is /almost/ great. but it's got loads of arbitrary limitations.
06:31:52 <CakeProphet> in particular I have a typeclass similar to Read and Write, but intended to read/write persistent data only.
06:32:18 <Twey> handonson: The fact that you managed to overcome a misleading answer and understand the real answer on your own does not mean that the misleading answer is the way to go
06:32:23 <FunctorSalad_> not so many limitations if you're willing to do without quotation, though
06:32:28 <CakeProphet> it would be nice to auto-generate a typeclass declaration with a function that takes a list of persistent field names.
06:32:36 <FunctorSalad_> and just furnish trees by hand
06:33:01 <Twey> handonson: Or that others will do so as easily as you — I've seen many Haskell newbies come here and be horribly confused by currying because they've been taught that Haskell has multi-argument functions
06:33:12 <FunctorSalad_> CakeProphet: that sounds doable, except I don't know what 'persistence' means here
06:33:35 <zygoloid> it'd be nice if you could register a TH function for deriving a typeclass.
06:33:47 <CakeProphet> FunctorSalad_:  application defined. The whole point is that there are some fields in a record that you do want to persist, and others you do not. The template Haskell function would take a list of the field that are intended to be saved to file.
06:34:19 <quicksilver> Twey: I don't agree. I think it's perfectly reasonable to talk of haskell as having multiple argument functions, but it allows you to partially apply them.
06:34:23 <FunctorSalad_> zygoloid: hmm? the toplevel syntax is already as simple as it gets
06:34:29 <quicksilver> totally natural, and that is how I think about it as well as talk about it.
06:34:34 <FunctorSalad_> myDeriver ''MyType
06:34:38 <zygoloid> FunctorSalad_: you can't write 'data Foo = Bar deriving (MyClass)'.
06:34:53 <quicksilver> I think the line of thought which says it only has 1-argument functions - whilst a correct view - is less helpful.
06:34:57 <quicksilver> this is subjective and YMMV.
06:35:00 <handonson> Twey: they are horribly confused? then correct them. what's the problem?
06:35:27 <Twey> handonson: They take lots of effort to correct, because they can't get their minds around the concept once they've been taught to think of it a certain way.
06:35:44 <handonson> Twey: for learning, there are always stages. you can't (and shouldn't) expect them to learn everything correctly at the first place.
06:35:48 <Twey> quicksilver: I think that's a much more complex way of looking at it
06:35:53 <FunctorSalad_> CakeProphet: as long as you already know how to make the serialization code itself, that should be easy
06:36:14 <quicksilver> Twey: and I think it's simpler and more useful. We must agree to differ. ;)
06:36:19 <FunctorSalad_> CakeProphet: but it could be solved with newtypes and no TH I think
06:36:21 <handonson> Twey: think about how people learn physics. why do they start with the classical Newtonian physics, while it is proven to be wrong today?
06:36:25 <CakeProphet> FunctorSalad_:  how so?
06:36:40 <Twey> handonson: It's one thing to gloss over some points, but quite another to install contradictory points in their place
06:36:44 <benmachine> all physics is an approximation!
06:36:57 <benmachine> but some physics are more approximation than others.
06:37:01 <Twey> handonson: It's not really wrong — it still holds in the areas in which they are taught to apply it
06:37:02 <FunctorSalad_> CakeProphet: newtype Transient a = Transient a; instance Serialize (Transient a) where serialize _ = return ()
06:37:17 <FunctorSalad_> ('Serialize' class made up - Show, Binary or whatever)
06:37:29 <Twey> handonson: The causes behind it are different, of course
06:37:33 <FunctorSalad_> then use 'Transient a' for fields instead of 'a'
06:37:40 <FunctorSalad_> (if they shouldn't be serialized)
06:37:57 <handonson> Twey: besides, it is often very important for newbies that their code just works. that's the starting point of having interest and willingness to learn more. teaching a whole set of theory doesn't help here
06:37:59 <benmachine> FunctorSalad_: might be wise for the serialise instance to put an "unused" marker in
06:38:29 <benmachine> otherwise reading it back'll be a pain
06:38:39 <Twey> It's not really a ‘whole set of theory’ — it's just one point
06:38:40 <handonson> this is a good example of approach that I support: http://blog.sigfpe.com/2007/11/io-monad-for-people-who-simply-dont.html
06:39:06 <Twey> And it's important because other things build on top of it, which are very difficult to grasp if one is missing the central point
06:39:19 <CakeProphet> FunctorSalad_:  ah okay. I was just going to do class Persistent p where inflate :: String -> p; deflate :: p -> String.  Indetical to a combination of Show and Read, but the restriction of being valid Haskell is no longer required.
06:39:49 <FunctorSalad_> benmachine: hmm? I thought reading would be handled by the Read/Binary.get implementation, which would have to conjure up a default value
06:39:50 <handonson> you can get started with rough and inaccurate ideas, but they can be easily corrected as you continue to learn deeper.
06:39:51 <Twey> TBH, People Who Simply Don't Care are probably going to be using Java.  :þ
06:39:56 <CakeProphet> FunctorSalad_:  pattern matching the Transient would add a lot of boilerplate to simple functions.
06:39:57 <benmachine> CakeProphet: it's not really required with Show and Read
06:40:02 <benmachine> FunctorSalad_: oh, I suppose so
06:40:36 <benmachine> CakeProphet: I think it's kind-of-recommended with Show and Read, but there are various standard-ish libraries that don't follow it
06:40:45 <Twey> handonson: Again, the distinction is between ‘rough and inaccurate’, which can be smoothed into more accurate knowledge as we go further, and ‘contradictory and completely wrong’
06:40:57 <FunctorSalad_> (say, data Foo = Foo A (Transient B) C;  ...... get = Foo <$> get <*> pure (Transient thedefault) <*> get
06:40:59 <FunctorSalad_> )
06:41:05 <Twey> Which interferes with the learning of the correct information later on
06:41:08 <triyo> Anyone know of any parsec combinator for Data.Time's parseTime?
06:41:39 <handonson> Twey: really? function taking multiple argument and returning one value is contradictory and completely wrong?
06:41:44 <FunctorSalad_> (for Binary's get)
06:41:52 <FunctorSalad_> CakeProphet: yes, unfortunately
06:41:55 <handonson> Twey: so, then, RWH is wrong? LYHGG is wrong? in your opinion?
06:42:13 <FunctorSalad_> CakeProphet: though you could write a fold for the type containing a transient once and for all
06:42:22 <FunctorSalad_> (autounwrapping the Transient)
06:42:38 <Tomsik_> Who is arguing about what in context of functions?
06:42:44 <Twey> I think that the People Who Simply Don't Care probably don't care because they think things like monad laws are abstract nonsense with no relevance to them — they need to be taught otherwise, not pandered to
06:42:58 <handonson> Twey: almost all good documentations about Haskell use the convenience concept of function taking multiple arguments and returning one value. you think they're all wrong?
06:43:10 <Twey> handonson: Does RWH ever teach that Haskell functions are not curried?  What is LYHGG?
06:43:20 <handonson> Learn you a Haskell
06:43:20 <CakeProphet> what's the simplest way to completely ignore newlines in a string?
06:43:23 <Twey> Oh, LYAH
06:43:25 <Twey> Okay
06:43:34 <Twey> Yeah, I forgot the subtitle for a moment there :þ
06:43:40 <kdvh> LYAH explains currying
06:43:52 <benmachine> Twey: ooi, do you consider a function (a, b) -> c could be reasonably said to take two arguments?
06:43:57 <handonson> Twey: why on earth do you bring the currying issue? it's not there at all
06:44:09 <Tomsik_> CakeProphet: filter (=='\n') string, or something?
06:44:24 <Twey> benmachine: It can… it can also be said to take one argument, though, which is the more consistent view
06:44:30 <FunctorSalad_> CakeProphet: concat . lines
06:44:31 <FunctorSalad_> ;)
06:44:38 <benmachine> Twey: a statement which is always true isn't much use :P
06:44:40 <Twey> handonson: What?  We were talking about explaining curried functions.
06:44:41 <Tomsik_> :t unlines
06:44:42 <lambdabot> [String] -> String
06:44:48 <FunctorSalad_> dunno if 'lines' is aware of dos vs unix
06:44:49 <Tomsik_> :t lines
06:44:50 <lambdabot> String -> [String]
06:44:57 <Twey> It isn't
06:45:04 <FunctorSalad_> :(
06:45:06 <Twey> The IO layer does that translation
06:45:06 <benmachine> that should be handled by the I/O stuff
06:45:08 <Tomsik_> > unlines . lines $ "abababa\nbababa"
06:45:09 <lambdabot>   "abababa\nbababa\n"
06:45:29 <Tomsik_> > concat . lines $ "abababa\nbababa"
06:45:30 <Twey> You should only get UNIX-style newlines in non-IO code
06:45:30 <lambdabot>   "ababababababa"
06:45:34 <FunctorSalad_> it could just split on either \r or \r\n, maybe that's bad design
06:45:44 <benmachine> yes
06:45:46 <handonson> Twey: the guy was asking what "f :: a -> b -> c" takes and what it returns. (RWH often says it takes two arguments and return one value, because it's too complicated and useless to describe it technically-correctly)
06:45:50 <Twey> FunctorSalad_: What about all the other linebreaks?
06:45:53 <FunctorSalad_> (unlines would have to do IO, OTOH)
06:46:00 <Tomsik_> uh
06:46:07 <Tomsik_> isn't things like a -> b -> c
06:46:12 <Tomsik_> can't they be viewed as both 
06:46:17 <Tomsik_> function that takes two arguments
06:46:24 <FunctorSalad_> Twey: heh I agree that having only \n in pure code would be much better
06:46:24 <Tomsik_> or that takes one and returns a function
06:46:30 <handonson> Twey: I'm saying people should have answered "it takes a and b, then returns c" just as good tutorials and documentations do. instead they started lecturing about higher order functions and first-class-ness of functions etc
06:46:36 <benmachine> Tomsik_: yes
06:46:38 <FunctorSalad_> ah, you're saying the IO layer *already* does this
06:46:39 <FunctorSalad_> good
06:47:01 <benmachine> it *does* take two arguments
06:47:04 <Twey> handonson: A function is called ‘curried’ if it uses the currying method to represent multiple arguments (being a unary function that returns more functions) rather than the uncurried tuple style used by e.g. C++
06:47:15 <Tomsik_> it takes as many arguments as you feed it, up to two :p
06:47:19 <handonson> Twey: I KNOW WHAT'S CURRYING!
06:47:37 <benmachine> Tomsik_: ok but if you feed it fewer than two, not much happens
06:47:50 <benmachine> you just get a box with "more arguments pls" written on it
06:47:52 <Twey> benmachine: Not much happens no matter how many you feed it
06:48:04 <Twey> benmachine: Nothing happens until evaluation time anyway
06:48:24 <benmachine> Twey: you don't give it the arguments until evaluation time, either
06:48:30 <benmachine> so something does happen
06:48:42 <Twey> And it could take more than two arguments, Tomsik_, if c is a function type :þ
06:48:48 <benmachine> it could do
06:48:49 <Tomsik_> benmachine: unless you get (a->b)->d somewhere
06:48:53 <benmachine> but it definitely takes at least two
06:48:59 <Tomsik_> and you can feed it with that
06:49:06 <handonson> Twey: from RWH: "The first tool is the sepBy function. This function takes two functions as arguments ..." this is what a good tutorial should say
06:49:10 <Tomsik_> I don't understand what's the problem
06:49:30 <Tomsik_> Are you arguing over what?
06:49:40 <handonson> and this is what the channel should have told the newbie, in my opinion. that's what i'm talking about.
06:49:45 <Twey> Tomsik_: I think we're converging.
06:49:48 <benmachine> we're arguing over how important the idea that every function takes one argument is
06:50:15 <kdvh> It was bolded in the tut I used (LYAH) so I guess it was important :P
06:50:21 <benmachine> heh
06:50:25 <Twey> handonson: And I think it isn't.  Sure, we often say that sort of thing, and in a way it's true; but it's a shorthand, and it's important that the newbie understand how we arrive at it.
06:50:36 <FunctorSalad_> > let f k x = k (concat ["1",x,x,"2",x]) in (f lines "\n" , f words " ")
06:50:37 <lambdabot>   (["1","","2"],["1","2"])
06:50:48 <FunctorSalad_> (fun trivia)
06:50:48 <handonson> Twey: so many tutorials out there are all wrong, in your opinion, right?
06:50:51 <Twey> (because in some cases, it ceases to be true)
06:50:56 <benmachine> I think it really depends on what you mean by taking arguments, and in most of the meanings people care about, functions take more than one argument
06:51:01 <Twey> handonson: I didn't say that.
06:51:21 <FunctorSalad_> (I somehow assumed 'words' and 'lines' where exactly analogous before)
06:51:24 <FunctorSalad_> *were
06:51:45 <Twey> handonson: I presume (perhaps optimistically) that RWH has previously explained how functions *really* work, and now is using the uncurried terminology as a shorthand, much as we Haskellers generally do.
06:52:13 <handonson> Twey: most tutorials don't make much effort for that, and i don't think they should at all
06:52:24 <benmachine> Twey: but what exactly is wrong about saying that sepBy takes two arguments?
06:52:51 <FunctorSalad_> (maybe tutorials should mention 'xargs' as a familiar example of currying in use :))
06:52:58 <benmachine> Twey: what is your concept of taking arguments anyway? what would a function that took more arguments look like, that there aren't any in haskell
06:53:01 <triyo> What is the most correct data type to represent a Data/Time? I saw that System.Directory (getModificationTime) returns a ClockTime... however System.Time is deprecated. Then there is of course the Data.Time with its own types such as UTCTime, ZonedTime, LocalTime... 
06:53:01 <FunctorSalad_> for a linux audience
06:53:03 <Twey> handonson: We talk about ‘extracting values from monads’, too, which isn't what happens either: we don't pretend that's what's *really* going on, and we don't try to teach it to newbies as truth.  It's just a convenient way of talking about it.
06:53:06 <Tomsik_> I think learning about functors should be kind of for later parts or something
06:53:47 <Tomsik_> It's like you don't tell about complex numbers to kids in preschool
06:53:58 <FunctorSalad_> benmachine: hmm I don't see the theoretical problem... a value takes arguments if it type unifies with a -> b
06:54:03 <Twey> benmachine: I think that ‘-> c’ thing that was mentioned earlier is the most important distinction
06:54:27 <FunctorSalad_> it's just that there's no easy way to make that first class that I know of
06:54:30 <benmachine> Twey: ah, that's more interesting
06:54:41 <CakeProphet> hmmm
06:54:42 <FunctorSalad_> (maybe overlapping instances works)
06:55:03 <handonson> Twey: you have to feed functions to functions anyway to use Haskell in order to do something practical, because many library functions take functions, so you're forced to naturally learn what, for example, "take 5" means. that's why your concern that newbies may go horribly wrong if we just say "this function takes three arguments" is invalid
06:55:06 <Twey> benmachine: It's virtually impossible to explain things like ‘const id 5 3’ if the newbie doesn't understand how Haskell functions really work
06:55:08 <CakeProphet> what would be a nice operator for this function:  f x y = x ++ (show y)
06:55:25 <zygoloid> f :: (# a, b #) -> c would 'sort of' be a function which takes two arguments, if it were well-kinded
06:55:34 <benmachine> Twey: hmm, I'm not so sure
06:55:41 <Twey> CakeProphet: +>$
06:55:41 <CakeProphet> <+>?
06:55:50 <CakeProphet> hmmm
06:55:55 <handonson> people have get familiar with passing functions around, if they want to code in Haskell, anyways
06:55:56 <Twey> <+> is an Arrow function
06:56:00 <CakeProphet> dunno, maybe just +$
06:56:06 <CakeProphet> or $+
06:56:07 <FunctorSalad_> Tomsik_: actually some people think that the complex exponential should be taught instead of trigonometric identities
06:56:11 <Twey> handonson: That's true, which is even more the reason to avoid misleading them
06:56:18 <aristid> :t (<+>)
06:56:19 <benmachine> FunctorSalad_: those people are a little odd.
06:56:19 <lambdabot>     Ambiguous occurrence `<+>'
06:56:19 <lambdabot>     It could refer to either `Control.Arrow.<+>', imported from Control.Arrow at State/L.hs:5:0-19
06:56:19 <lambdabot>                           or `Text.PrettyPrint.HughesPJ.<+>', imported from Text.PrettyPrint.HughesPJ at State/L.hs:53:0-46
06:56:22 <zygoloid> CakeProphet: i'd call it ++show ;-)
06:56:22 <Twey> CakeProphet: I was thinking the ‘$’ could stand for ‘show’
06:56:26 <handonson> Twey: no
06:56:28 <Tomsik_> well, trigonometric identities are the last thing that should be taught so
06:56:30 <Twey> zygoloid: Hehe.
06:56:39 <FunctorSalad_> benmachine: the basic law is much simpler, and trigonometric id's follow from it
06:56:52 <triyo> anyone?
06:57:00 <FunctorSalad_> (exp(x+y)=exp(x)*exp(y))
06:57:04 <Twey> FunctorSalad_: Really?  Cool :-\
06:57:06 <benmachine> FunctorSalad_: it depends on your perception of simplicity
06:57:09 <FunctorSalad_> it does require more preliminaries though
06:57:37 <benmachine> wait actually
06:57:40 <handonson> from RWH: "We don't use parentheses or commas to group or separate the arguments to a function; merely writing the name of the function, followed by each argument in turn, is enough. As an example, let's apply the compare function, which takes two arguments."
06:57:41 <zygoloid> triyo: iirc you're "supposed" to use Date.Time's stuff. not sure what the situation with getModificationTime is
06:57:43 <benmachine> f x y = x ++ show y = flip shows?
06:57:45 <Tomsik_> trigonometric identities here are taught as "well, look at these formulas and memorize them"
06:57:46 <FunctorSalad_> Twey: if you also use cos = 1/2 (exp + (conjugate . exp)) etc
06:57:51 <benmachine> hmm no
06:57:53 <CakeProphet> Twey:  yeah. I think I'll have $+, +$, and $+$  :)  The location of the $ indicates which argument is a Show instance and which is a String.
06:57:54 <Twey> triyo: UTCTime, I'd say
06:57:54 <benmachine> but almost
06:58:02 <Twey> triyo: Unless you need a timezone as well.
06:58:10 <handonson> Twey: what a horrible explanation, huh?
06:58:14 <benmachine> triyo: I don't think you can completely get out of using System.Time yet, a lot of libraries use it
06:58:27 <triyo> Twey: thats the one I pretty much am settling on... You can covert to ZonedTime, from there too
06:58:31 <Twey> handonson: Ick.  :-\
06:58:36 <Twey> triyo: Yeah.
06:58:47 <jedai> CakeProphet: maybe you should use $++ ++$ and so on though, so that concatenation and not addition is more clearly indicated
06:58:50 <handonson> Twey: that's what RWH says, and FYI theres no prior notice like "functions actually take only one argument" etc at all
06:58:53 <zygoloid> CakeProphet: what do you do about associativity?
06:59:11 <zygoloid> (that affects where you put the $s, of course...)
06:59:14 <handonson> Twey: you're saying (assuming you're consistent) most Haskell tutorials out there are horribly misleading
06:59:31 <CakeProphet> zygoloid:  ?  I assume infixr like ++. Will that cause problems?
06:59:36 <Twey> :t (\x y -> x ++ show y, flip shows)
06:59:37 <lambdabot> forall a a1. (Show a, Show a1) => (String -> a -> String, String -> a1 -> String)
06:59:40 <triyo> benmachine: I noticed it to be a deprecation process that may take some time of course. Just wanted to insure I don't contribute to the problem. :)
06:59:41 <FunctorSalad_> Twey: I might be underestimating the dependencies needed for it to seem simpler
06:59:57 <Twey> handonson: I would say that that part of RWH is rather misleading, yes.
07:00:06 <handonson> Twey: and I'm saying no, they are not. your concern that it is horribly misleading is invalid, and the explanation just works for so many people
07:00:24 <zygoloid> CakeProphet: well, if it's infixr then you will almost never want a +$, since the RHS is probably a String.
07:00:27 <Twey> handonson: Until they have to understand how it really works.
07:00:35 <Twey> Then they have to unlearn it.
07:00:43 <quicksilver> I don't accept that.
07:00:46 <quicksilver> There is no unlearning.
07:00:49 <handonson> me neither.
07:00:53 <quicksilver> just a slight extra elaboration.
07:00:59 <FunctorSalad_> @forget
07:00:59 <lambdabot> Incorrect arguments to quote
07:01:06 <jedai> Twey: maybe they don't completely have to unlearn it but rather reconstruct their intuition on a more solid basis ?
07:01:10 <benmachine> Twey: flip shows combines the strings backwards
07:01:16 <quicksilver> Functions which take two parameters - well if you give them only one parameter, they are partially applied, and expect one more argument.
07:01:29 <quicksilver> not much unlearning required, just elaboration, IMO.
07:01:43 <handonson> no unlearning required at all
07:01:49 <handonson> you just add knowledge
07:01:49 <Twey> quicksilver: But then how do you explain ‘const id’?
07:01:53 <Twey> :t const id
07:01:54 <lambdabot> forall a b. b -> a -> a
07:02:03 <quicksilver> you just explain it.
07:02:08 <Twey> How?
07:02:10 <FunctorSalad_> . o O ( virtual types cancelling (->) )
07:02:12 <benmachine> it's a function that returns a function
07:02:19 <handonson> you were using "take 5 [2, 4 ..]" and now you come to understand that "take 5" is a new function that takes a list. that's a new knowledge that doesn't cause any conflict to the old knowledge
07:02:22 <zygoloid> by pointing out that it's b -> (a -> a)
07:02:27 <quicksilver> you just say "in fact, a function which takes two arguments is the same thing as a function taking one argument and returning one"
07:02:33 <kdvh> It was just a case of finding out HOW they took multiple arguments for me.
07:02:34 <quicksilver> ...which is itself a function.
07:02:37 <kdvh> No unlearning
07:02:38 <CakeProphet> zygoloid:  infixr means (x + (y + ( ...)))  right?
07:02:43 <Twey> So in the end you have to explain it properly anyway
07:02:44 <zygoloid> CakeProphet: correct.
07:02:44 <quicksilver> it's not a big "Oh you were lieing to me" moment.
07:02:50 <FunctorSalad_> a `antiarrow` a -> b =~ b
07:02:52 <FunctorSalad_> ;)
07:02:52 <quicksilver> it's just a "Oh, that's how it works".
07:02:54 <Twey> Also, curry/uncurry
07:02:56 <quicksilver> Twey: yes, indeed you do.
07:03:00 <quicksilver> but it's not a big deal.
07:03:02 <CakeProphet> zygoloid:  so what if +$ were infxl instead?  
07:03:10 <quicksilver> and in practice, we speak of compare as a function which takes two arguments.
07:03:13 <Twey> It's not a big deal to explain it to start with, either
07:03:26 <quicksilver> sure, explain it at the beginning.
07:03:31 <zygoloid> CakeProphet: then you'd get the same sort of thing with $+. and your operators would be less efficient ;-)
07:03:33 <quicksilver> just don't try to avoid the phrase "Which takes two arguments"
07:03:39 <FunctorSalad_> hmm wait, for this direction `antiarrow` is just (,)
07:03:39 <benmachine> we need more hapless peons to test our didactic theories on
07:03:41 <quicksilver> because that's a natural phrase, which is widely used
07:03:44 <quicksilver> and doesn't cause problems.
07:03:53 <quicksilver> explain it whenever you choose.
07:04:12 <CakeProphet> "Hello, " ++ x $+ "!"  
07:04:22 <handonson> which is UNIVERSALLY used. i can give hundreds of examples, documentations using "this function takes n arguments and..."
07:04:40 <Twey> quicksilver: I wouldn't dream of it.  I just think it's important that they understand that that's not really the same as ‘taking n arguments’ in e.g. C++.
07:04:42 <CakeProphet> hmmm... okay. I see. +$ is unnecessary in most cases. It's only needed in the situation where you only have one more thing to concat onto the string
07:05:00 <quicksilver> Twey: you seemed earlier to be completing against talking of functions as taking two arguments.
07:05:01 <benmachine> Twey: it's not hugely different, I think
07:05:04 <quicksilver> that's what I'm arguing with.
07:05:09 <zygoloid> it's only needed when the last thing in the chain of ++ needs to be shown. otherwise you'd want the $ on the right of the argument
07:05:12 <quicksilver> it's really no different at all from C++
07:05:17 <zygoloid> ($+) = shows, by the way.
07:05:17 <quicksilver> it's just that C++ doesn't let you partially apply.
07:05:19 <FunctorSalad_> (if you don't mind that strictly speaking (a,a->b) =~ b is just a retract not an iso)
07:05:21 <Twey> quicksilver: Ah, no — just for the newbies.
07:05:39 <benmachine> zygoloid: shows x s = show x ++ s
07:05:43 <Twey> quicksilver: I generally think of C++ functions as functions that take a single tuple
07:05:44 <benmachine> weren't we aiming for s ++ show x?
07:06:00 <zygoloid> benmachine: no, $+ is supposed to show on the left.
07:06:03 <Twey> quicksilver: Except with magic tuples.
07:06:04 <benmachine> oh ok
07:06:45 <handonson> he's saying the RWH should have begun with the technically correct description of how function works, instead of just saying "let's start with a function called compare, which takes two arguments!"
07:06:54 <handonson> wow.
07:06:58 <zygoloid> > let infixr 5 $+; ($+) = shows in 4 $+ True $+ 42 $+ ""
07:06:59 <lambdabot>   "4True42"
07:07:23 <aristid> :t shows
07:07:24 <lambdabot> forall a. (Show a) => a -> String -> String
07:07:33 <Twey> > shows 4 "two"
07:07:35 <lambdabot>   "4two"
07:08:01 <zygoloid> > let infixr 5 $+; ($+) = shows in 4 $+ " " ++ True $+ " " ++ 42 $+ " done"
07:08:02 <lambdabot>   "4 True 42 done"
07:08:30 <FunctorSalad_> @let (&) = (,) -- fight rsi
07:08:31 <lambdabot>  Defined.
07:08:37 <FunctorSalad_> > 1 & 2 & 3
07:08:39 <lambdabot>   ((1,2),3)
07:08:40 <FunctorSalad_> ;)
07:09:38 <CakeProphet> "t shows
07:09:40 <CakeProphet> :t shows
07:09:41 <lambdabot> forall a. (Show a) => a -> String -> String
07:10:02 <CakeProphet> > shows 1 "test"
07:10:03 <lambdabot>   "1test"
07:10:09 <CakeProphet> ah :)
07:10:13 <aristid> FunctorSalad_: rsi? from having to type (a, b) instead of a, b?
07:10:21 <CakeProphet> @src shows
07:10:21 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
07:10:54 <aristid> @let infixr 5 &; (&) = (,) in 1 & 2 & 3
07:10:54 <lambdabot>   Parse error: KW_In
07:11:01 <aristid> > let infixr 5 &; (&) = (,) in 1 & 2 & 3
07:11:01 <lambdabot>   (1,(2,3))
07:11:09 <FunctorSalad_> aristid: not single-handedly, but it adds up ;)
07:11:21 * hackagebot ghc-mod 0.4.4 - Happy Haskell programming on Emacs  http://hackage.haskell.org/package/ghc-mod-0.4.4 (KazuYamamoto)
07:11:29 <FunctorSalad_> and I just particularly dislike typing parens physically
07:11:40 <aristid> FunctorSalad_: it would be cool if you could pattern match against that too
07:11:57 <aristid> f (a & b & c) instead of f (a, (b, c))
07:12:30 <quicksilver> you could make a QQ for that but it would then look ugly.
07:12:50 <quicksilver> f [$amp| a & b & c |] = ....
07:12:52 <FunctorSalad_> hmm sounds doable for constructor synonyms, but it'd confuse newbies who would conjecture it's a more general principle
07:13:02 <zygoloid> data a :& b = a :& b ?
07:13:10 <FunctorSalad_> (which it crucially isn't for noninjective functions)
07:13:20 <aristid> FunctorSalad_: constructor synonyms? is that an existing extensioN?
07:13:53 <aristid> zygoloid: is it possible to specify associativity for infix constructors?
07:14:04 <FunctorSalad_> aristid: no, my phrasing
07:14:05 <zygoloid> aristid: yep, just specify it at the top level.
07:14:06 <aristid> because i feel that it should be right-associative.
07:14:25 <FunctorSalad_> something that is syntactically just f = SomeCtor
07:14:25 <aristid> FunctorSalad_: i like that non-existing extension anyways :)
07:14:35 <FunctorSalad_> (it's undecidable semantically)
07:14:35 <zygoloid> (it applies to both the type constructor and the data constructor)
07:15:27 <FunctorSalad_> what I just said seems like a great argument against it
07:15:38 <aristid> huh?
07:16:01 <FunctorSalad_> spooky code-breakage at a distance by changing (&) = (,) to (&) = if False then undefined else (,)
07:16:15 <FunctorSalad_> which is equivalent semantically but no longer a 'constructor synonym'
07:17:28 <aristid> FunctorSalad_: well, how about this: constructor (&) = (,), then it is clear that it's not a normal definition
07:17:31 <FunctorSalad_> so you'd get patterns in other modules no longer compiling just for making an equivalence transformation 
07:17:39 <FunctorSalad_> yes, that'd be better
07:17:44 <zygoloid> aristid: you need the ctor to start with uppercase still
07:18:04 <aristid> zygoloid: so :&?
07:18:07 <zygoloid> yeah.
07:18:22 <CakeProphet> er, how do you make an instance of Read? Apparently you don't define read itself.
07:18:41 <zygoloid> hmm. actually, do you? i assumed it was necessary for pattern matching, but i'm not sure it is...
07:18:47 <aristid> zygoloid: in that case (:&) = (,) would suffice, because (:&) can never be a normal function
07:19:01 <FunctorSalad_> CakeProphet: {-# OPTIONS -ddump-deriv #-}, derive Read somewhere, copy&paste
07:19:02 <FunctorSalad_> ;)
07:19:09 <zygoloid> aristid: a :& b = (b, a) woudl be ambiguous
07:19:19 <CakeProphet> FunctorSalad_:  hahaha. :)
07:19:31 <aristid> zygoloid: i don't think changing the structure needs to be allowed
07:19:32 <FunctorSalad_> at least that's what I do for Show
07:19:39 <FunctorSalad_> (to make some minor modification)
07:19:56 <FunctorSalad_> it's quite tricky if you want to get all the precs right
07:20:03 <zygoloid> aristid: then how do you write nullary constructor synonyms?
07:20:16 <quicksilver> FunctorSalad_: I thought dump-deriv produced Core not hs?
07:20:19 <aristid> zygoloid: huh?
07:20:40 <aristid> Empty = Nothing
07:20:47 <handonson> i've made a very simple and trivial (but also critical for some people) patch to Graphics.Rendering.OpenGL and sent Sven Panne an email, but the reply seems to take forever. i guess there's gotta be a better place to send this patch.
07:20:49 <handonson> any idea?
07:21:02 <FunctorSalad_> quicksilver: hehe, haskell disguised by qualified GHC-internal names and variables like xa_93
07:21:07 <quicksilver> handonson: you could send it to the haskell opengl mailing list
07:21:15 <zygoloid> aristid: that's ambiguous. if you wrote that line twice, the first time would be a definition of a synonym and the second would be a trivial pattern match
07:21:18 <FunctorSalad_> or maybe it is core that happens to be haskell too
07:21:30 <quicksilver> I think so.
07:21:44 <quicksilver> I think someone mentioned some cases where it produces Core which cannot be produced by haskell.
07:21:47 <aristid> zygoloid: ok i guess a keyword would be nice, in any case.
07:21:50 <quicksilver> (although I think that's for GeneralizedNewtype)
07:21:55 <FunctorSalad_> IIRC it does compile without modification if you import the modules
07:21:59 <aristid> constructor Empty = Nothing -- no confusion
07:22:04 <FunctorSalad_> (Show)
07:22:06 <helge> Could someone take a look at http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27799 ? The problem is that it doesn't know which instance to use?
07:22:21 <CakeProphet> FunctorSalad_:  I can't derive Read for this type because it has fields that are not Read instances.
07:22:22 <zygoloid> aristid: yeah. i think that's been proposed with the keyword 'view' or 'data view' or something
07:22:23 <handonson> where should I bug-report the problem in the "plugins" package, that "cabal install plugins" fails with a compile error? dons?
07:22:35 <FunctorSalad_> CakeProphet: use a similar mockup type then
07:22:46 <CakeProphet> FunctorSalad_:  ah, comments. :)
07:22:57 <FunctorSalad_> you just want to copy&paste it once after all
07:23:17 <quicksilver> helge: Yes.
07:23:24 <handonson> or someone else?
07:23:36 <quicksilver> helge: "1" could be an Int or an Integer or a Double so it has no way to know which instance to use.
07:23:38 <zygoloid> helge: yeah. defaulting doesn't kick in because the JSON typeclass is not in the special list
07:23:51 <CakeProphet> FunctorSalad_:  hmmm, I'm not sure if I want Read and Show at all now. :(  Getting complicated.
07:24:07 <helge> how would I go about solving this problem? Or do I have to specify with :: if I want to use toJSON ?
07:24:16 <CakeProphet> what I'm trying to do has more side-effects than that.
07:24:30 <zygoloid> helge: use a type annotation, somewhere.
07:24:44 <helge> okey
07:24:46 <helge> thanks
07:25:04 <zygoloid> helge: alternatively, you may well find that in a 'full program' the issue doesn't arise
07:25:15 <zygoloid> (because the type is likely to be forced by something else anyway)
07:25:51 <FunctorSalad_> CakeProphet: I'd also recommend sed -Ee 's/(\S+\.)+([^.[:space:]]+)/\2/g' or so ;)
07:26:07 <FunctorSalad_> to unqualify names
07:26:31 <FunctorSalad_> (that was off-hand, probably some syntax error)
07:27:20 <FunctorSalad_> ("any number of (nonspace followed by a dot), then any number of nonspace nondot chars")
07:27:31 <FunctorSalad_> keeping just the latter
07:28:04 <FunctorSalad_> hmm will break for operators containing dots ;)
07:28:25 <aristid> is there a good reason for the existence of flat n-tuples with n>2? like (a,b,c). couldn't that always be written as (a,(b,c))?
07:28:38 <aristid> or a&b&c
07:28:42 <handonson> let me first clarify the problem before I bug-report. can anybody succesfully "cabal install plugins"? if you've got time, please try it and let me know the result. i want to know if this is specific for my system or not
07:29:02 <zygoloid> aristid: (a,(b,c)) has the value (_|_, _|_) which is not a value of (a,b,c).
07:29:15 <Saizan> handonson: what error do you get?
07:29:34 <handonson> Saizan: a compile error. src/System/Plugins/PackageAPI.hs:61:24: Not in scope: `package'
07:29:39 <FunctorSalad_> aristid: I don't see a good reason except the artificial one from the parenthesis notation ;))
07:29:57 <aristid> zygoloid: is that of practical concern?
07:30:26 <FunctorSalad_> zygoloid: I think aristid was asking why they exist in the first place, not how they're different
07:30:30 <zygoloid> aristid: it might be. it means that (a,(b,c)) uses two words more heap than (a,b,c)
07:30:41 <Saizan> handonson: same hre
07:30:43 <FunctorSalad_> hmm, true
07:31:05 <quicksilver> handonson: plugins is, I think, inherently unstable to new GHC revisions
07:31:09 <quicksilver> since it depends on GHC internal names.
07:31:16 <quicksilver> and it's not very actively maintained?
07:31:28 <FunctorSalad_> zygoloid: nvm I misunderstood that you're pointing out a semantical diff rather than 'formally is a different type'
07:31:49 <Saizan> handonson: sounds like it didn't survive some API change in Cabal
07:32:00 <quicksilver> it's not been updated since March last year
07:32:09 <quicksilver> there have been some big cabal+ghc releases since then.
07:32:23 <Cale_> Also flat tuple elements can be accessed immediately without following the extra pointer (implementation-wise)
07:32:54 <FunctorSalad_> usind the "GHC" module directly is not all that scary for basic tasks like "compile these files", FWIW
07:32:55 <quicksilver> that's not very different to zygoloid's point really?
07:32:56 <zygoloid> FunctorSalad_: yeah. but the semantic difference would be a bit boring if it didn't lead to (a,(b,c)) being operatioanlly worse than (a,b,c) in terms of time and space
07:32:57 <FunctorSalad_> *using
07:33:30 <aristid> zygoloid: yeah, and it obviously is quite a bit worse
07:33:41 <FunctorSalad_> the boilerplate ghc-monadic-block is on the wiki somewhere, even
07:33:43 <quicksilver> if you actually care about the different between how logn it takes to access c in (a,b,c) and (a,(b,c)) then really you probalby want the compiler to elide the tuple  entirely.
07:34:03 <quicksilver> which, unfortunately, GHC almost never (never?) will, in either case.
07:34:15 <quicksilver> but, if it did, there wouldn't be a difference between the two.
07:34:31 <quicksilver> (this could only happen if it could prove appropriate strictness, naturally)
07:34:35 <FunctorSalad_> but a strict and UNPACK tuple would work?
07:34:42 <FunctorSalad_> (for nested tuples)
07:35:16 <quicksilver> you can't unpack a 2-place constructor in GHC I don't think.
07:35:34 <quicksilver> not unpack it all the way into its enclosing constructor, I mean
07:35:36 <FunctorSalad_> hmm I thought you can unpack arbitrary fields
07:35:40 <FunctorSalad_> ah
07:35:52 <quicksilver> you can remove the pointers to "b" and "c"
07:36:02 <quicksilver> but I don't think it will ever remove the pointer to "(b,c)"
07:36:45 <Saizan> i think it does splice multiple fields into the parent constructor
07:37:02 <Saizan> but {-# UNPACK #-} works only with monomorphic types anyhow
07:37:10 <FunctorSalad_> (now that I think of it, I guess the pragma is just ignored for a type which isn't known to be a "value type"?)
07:37:16 <handonson> quicksilver: do you think there's any alternative to plugins, then?
07:37:32 <quicksilver> handonson: yes.
07:37:46 <FunctorSalad_> (how would you unpack a pointer to a black box?)
07:38:44 <handonson> quicksilver: my goal is to have a system that has a central program and subprograms, and you can change the subprogram code and reload it while the central program is running
07:39:10 <handonson> i was looking for something other than Hint because Hint looked too gigantic
07:39:24 <quicksilver> handonson: dyre, metaplug, hint, mueval
07:39:34 <handonson> ...
07:39:38 <handonson> uhm.
07:39:40 <triyo> Hmm, this code ....    utcToZonedTime (TimeZone 120 False "SAST") $ zonedTimeToUTC d ... should return the same result. The 'd' binding in my case is the zoned time as per "SAST"... I don't get the same value back. Am I missing something?
07:39:56 <quicksilver> I'm afraid I can't specifically recommend one, I don't know the pros and cons.
07:40:02 <quicksilver> there is also direct-plugins, I think
07:40:07 <quicksilver> or just using the GHC API directly
07:42:54 <benmachine> triyo: maybe utcToZonedTime doesn't do what you think it does
07:43:18 <Cale_> handonson: if you have the choice, I don't think there's much that plugins does that hint doesn't.
07:43:28 <benmachine> (fwiw, you seem to think it does the logical thing, but there's no guarantee the library authors were so sensible :P )
07:45:53 <triyo> benmachine: hehe, right, forgot about that one
07:48:06 <handonson> so I'm writing some small network script that I'll upload to a small server and run, and I want to remotely add/change some functions without killing and restarting it. so far i've come up with: 1. use Hint or something like that, including GHC into the script 2. compile each plugin as executables, and communicate via stdio
07:50:43 <handonson> i like the latter more, but the drawbacks (that i can think of) are 1. i can only communicate with String/ByteString 2. i may have to copy the same thing all over the memory, each process having one copy
07:50:59 <CakeProphet> where is MonadIO located?
07:51:02 <Zao> handonson: You could use shared memory?
07:51:08 <opqdonut> ?info MonadIO
07:51:08 <lambdabot> MonadIO
07:51:13 <Zao> Although that'd probably require suitable serializing anyway.
07:51:14 <opqdonut> ...
07:51:20 <opqdonut> that was helpful!
07:51:27 <Zao> CakeProphet: Isn't that in mtl and transformers and such?
07:51:42 <Zao> Never quite understood the relationship between all those.
07:51:45 <CakeProphet> ah, yes. I bet I don't even need to import it explicitly.
07:52:05 <handonson> Zao: I can use shared memory in Haskell? Cool! Does it require a lot of low-level coding?
07:52:12 <Zao> It probably does.
07:52:19 <handonson> aww.
07:52:22 <CakeProphet> ah yes... importing the module where the transformer was located also imported MonadIO
07:53:08 <quicksilver> I think getting unix-style SHM working for bytestrings (e.g.) is probably more work than getting HiNT going for dynamic recompilation.
07:53:11 <quicksilver> YMMV.
07:54:54 <handonson> I'm not worried about "more work" because the reason I'm doing this in Haskell is to learn more of it
07:55:18 <Zao> I'd just communicate with messages over pipes or whatnot.
07:55:38 <handonson> I'm worried about having to include the entire GHC and run it in my friend's small and slow server, though
07:56:50 <quicksilver> but you were talking about compiling the plugins
07:56:55 <quicksilver> so you need GHC there anyway, no?
07:57:13 <handonson> I can compile them on my machine and upload them
07:57:26 <handonson> if I choose the latter approach, I mean.
07:58:03 <handonson> I think I'd have to use the -dynamic option, in that case
07:58:25 <handonson> otherwise each plugin will have separate copy of RTS and Parsec and ByteString and everything
08:02:53 <quicksilver> compiling GHC executables ona  different machine to the one you run them on is no fun.
08:03:11 <quicksilver> it's not impossible but it's a fuss and may not be worth it.
08:03:26 <quicksilver> (it's OK if they run exactly the same OS and have exactly the same library versions installed)
08:04:29 <handonson> both Ubuntu 10.04
08:06:23 <benmachine> quicksilver: I'm fairly sure I've run a 6.12 executable on a machine that had 6.8 installed
08:06:27 * benmachine tries an experiment
08:06:40 <handonson> quicksilver: acutally, a good point. I may also include the shared library files in my project in order to avoid the version hell issue. thanks.
08:07:36 <quicksilver> benmachine: you can, if you or your OS habitually bundles all the used libraries.
08:07:50 <handonson> there were quite a lot of libraries when I "ldd Main"ed last time, but many of them are supported by Ubuntu by default, and the rest of them are... not too many to include, i think
08:07:55 <quicksilver> benmachine: on versions of GHC which statically link all the haskell stuff it's only GMP and such like to worry about.
08:08:10 <quicksilver> benmachine: ...on versions which dynamically link the haskell libs you have to worry about all of them too.
08:08:14 <benmachine> yeah
08:08:21 <quicksilver> handonson: I'm not sure ldd tells the truth. I think something is dlopen()ed
08:08:29 <quicksilver> I could be wrong though.
08:08:33 <quicksilver> this is a vague memory.
08:08:35 <quicksilver> try it and see ;)
08:09:08 <chrisdone> i just tried this to see what would happen, best error message ever:
08:09:08 <lambdabot> chrisdone: You have 2 new messages. '/msg lambdabot @messages' to read them.
08:09:10 <chrisdone> <interactive>:1:4:
08:09:10 <chrisdone>     My brain just exploded.
08:09:10 <chrisdone>     I can't handle pattern bindings for existential or GADT data constructors.
08:09:13 <chrisdone>     Instead, use a case-expression, or do-notation, to unpack the constructor.
08:09:13 <handonson> is there a version of GHC that dynamically links, even when you don't force it to? i thought no
08:09:16 <CakeProphet> :t liftIO
08:09:16 <lambdabot> forall a (m :: * -> *). (MonadIO m) => IO a -> m a
08:09:17 <Saizan> quicksilver: that only happens in ghci i think
08:09:50 <quicksilver> Saizan: hopefully you're right.
08:09:53 <djahandarie> chrisdone, lol, ghci actually gave that eror?
08:09:54 <djahandarie> error
08:09:57 <chrisdone> djahandarie: yeah
08:09:58 <zygoloid> chrisdone: yeah, that's unfortunate. it'd be nice to have a better error for that
08:10:11 * djahandarie lols
08:10:15 <Saizan> how could it be better?
08:10:33 <Zao> chrisdone: That one is especially funny when it occurs at 5 AM.
08:10:33 <zygoloid> Saizan: "lazily matching against a GADT does not allow type improvement"
08:10:35 <quicksilver> I think they leave the "my brain just exploded" bit in there for sentimental reasons.
08:10:36 <chrisdone> "use GADTs, you dinosaur"
08:10:52 <quicksilver> in one version that was the only message
08:10:56 <Saizan> zygoloid: well, that doesn't change only the error :)
08:10:57 <chrisdone> hahaha
08:11:01 <djahandarie> Zao, until you realize you need to be finished 30 minutes later. :(
08:11:04 <quicksilver> the bit that comes after is the useful part
08:11:22 <handonson> 00:10 here. Good night all.
08:11:36 <Zao> So that's why I had  \x -> case x of (Foo bar) -> ...
08:11:44 <zygoloid> Saizan: well, it upgrades it from "My brain asplode, I can't handle this" to "look, you're asking for an unsound type system"
08:13:01 <Saizan> zygoloid: your phrasing suggested that a lazy match would be allowed but it wouldn't bring the type equalities into scope, but i see now :)
08:13:03 <zygoloid> to be honest, it would seem reasonable to me to allow existential pattern bindings which didn't do type improvement, but i don't think they'd often be very useful.
08:13:54 <zygoloid> (not useful to the point where a compiler error would seem a better outcome)
08:14:02 <chrisdone> turns out an existential isn't really what i want
08:14:23 <chrisdone> or do i
08:14:34 <zygoloid> hmm, does GHC allow strict matching against an existential in a let-binding?
08:14:52 <chrisdone> can't decide whether i want to use a data with constructors for each type of action in my list of actions, or existentials with classes that implement the action
08:15:11 <chrisdone> both are nice
08:16:06 <Saizan> do both
08:16:41 <zygoloid> chrisdone: do you want an open or closed set of action types?
08:16:43 <geheimdienst> DTSTTCPW
08:17:01 <quicksilver> chrisdone: if you can't decide, use the constructors.
08:17:17 <quicksilver> that's considerably more elementary than the existential and slightly less fiddly to use.
08:18:10 <chrisdone> aye, i'll stick with constructors
08:18:20 <quicksilver> it's not like it's the end of the world to change later
08:18:32 <quicksilver> refactoring is generally easier in haskell :)
08:19:33 * Saizan is going to change a type used in several places over cabal-install, now we'll see how easy refactoring is!
08:19:34 <chrisdone> i have pure actions and actions that involve the database or file, in the type system i like to distinguish between them
08:19:37 <illissius> at one point, someone will say "it's not the end of the world" and be wrong
08:19:41 <zygoloid> hmm, that's unfortunate. a strict let binding can't match an existential. a lazy case binding is rejected, though.
08:19:44 <chrisdone> Saizan: haha, report your findings!
08:19:45 <illissius> unfortunately, there'll be no one left to survey the irony
08:20:53 <chrisdone> (unless your name is Arthur Dent)
08:24:26 <quicksilver> zygoloid: well there is still the nested scope issue for lets, even when strict.
08:25:01 <chrisdone> is there a library that contains all the HTTP statuses?
08:25:07 <quicksilver> zygoloid: you'd need to statically verify that there was a way to order the bindings in that mutual group so that no earlier binding referenced the contents of a later existential-unpack
08:25:30 <quicksilver> zygoloid: ...which amounts to , you need to show the let can be converted to nested cases.
08:26:00 <zygoloid> quicksilver: is that really necessary? (i'm not saying it isn't, but it's not really clear to me either way)
08:26:35 <zygoloid> there must be a 'cut' point where you have a normal (non-existential) match or a lazy match, otherwise the whole expression must be _|_
08:27:33 <quicksilver> zygoloid: perhaps I should restate it thus:
08:27:36 <zygoloid> essentially, if the body is evaluated, then the strict unpacking must have terminated, which means any equality constraints are conceptually non-_|_, so valid
08:27:47 <quicksilver> existential must be unpacked using Core-case.
08:27:58 <quicksilver> currently, GHC compiles haskell-let to Core-let and haskell-case to core-case
08:28:08 <zygoloid> even for strict let-bindings?
08:28:17 <quicksilver> you're asking it to spot one particular phenomenon and then convert haskell-let to core-case
08:28:25 <quicksilver> this isn't an unreasonable suggestion
08:28:29 <zygoloid> i thought strict-let was already converted to core-case
08:28:30 <ClaudiusMaximus> @hoogle DieHorribly
08:28:30 <lambdabot> Network.HTTP.Base DieHorribly :: String -> ResponseNextStep
08:28:31 <quicksilver> ..but it's a change. I think.
08:28:45 <chrisdone> ClaudiusMaximus: haha
08:29:03 <quicksilver> zygoloid: I think strict-let is convert to let + seq.
08:29:06 <quicksilver> I could be wrong.
08:29:17 <quicksilver> obviously later optimisation passes can change stuff.
08:31:01 <ClaudiusMaximus> chrisdone: i had a look, but there isn't even HdrStatus in the list of HeaderName
08:31:05 <zygoloid> quicksilver: ghc-core gives a case for a strict let, but i think that's the final result.
08:32:27 <quicksilver> I think so to.
08:32:29 <quicksilver> But I don't know.
08:32:46 <quicksilver> I have a feeling there is a trac ticket which sheds some light but google has stopped indexing trac tickets again.
08:33:07 <quicksilver> maybe not
08:33:11 <quicksilver> well I can't find it, whatever the reason
08:34:35 <zygoloid> quicksilver: looks like the desugarer converts strict let into case
08:36:39 <quicksilver> zygoloid: hmm. If the desugarer is prepared to do that, it seems like it could do it for existentials too.
08:36:48 <quicksilver> still, I'm inclined to dislike strict-lets anyway :)
08:37:34 <chrisdone> is it a faux pas to define generic functions and types in modules under the standard hierarchies? e.g. I have Network.CGI.IO and Network.CGI.Pure--two implementations that I've used in two different projects, useful for running parts of my sites in GHCi
08:38:04 <chrisdone> i.e. would you find it confusing to see that and think that it was defined in a standard library somewhere?
08:38:34 <jmcarthur> chrisdone: that seems typical practice to me
08:38:39 <zygoloid> chrisdone: no, i don't think that's confusing. module and package names are unrelated in my mind
08:38:47 <quicksilver> chrisdone: not necessarily. If it's private code then who cares anyway. If you plan to release it I think it's polite to try to communicate with the people who own the enclosing hierarchy.
08:38:54 <int80_h> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27800#a27800
08:39:01 <int80_h> could someone check that out?
08:39:25 <zygoloid> it depends though. if someone's squatting on Language.Python and you want Language.Python.Marshall or Language.Python.Pickle, i think that's fair game
08:40:05 <quicksilver> int80_h: use ghc --make
08:40:20 <zygoloid> if it's Data.XMonad.something then it makes sense to get in touch with the xmonad guys
08:40:26 <int80_h> doh!
08:40:32 <int80_h> I knew that!
08:40:35 <int80_h> thanks :)
08:41:29 <Saizan> chrisdone: it was quite easy, indeed
08:45:02 <Eduard_Munteanu> Hi.
08:45:42 <Eduard_Munteanu> Oh crap, that Zeilberger dude has some really interesting things to say.
08:46:04 <Eduard_Munteanu> Not that I agree with him on all grounds, but still, interesting.
08:47:44 <CakeProphet> > show $ Map.empty
08:47:45 <lambdabot>   Not in scope: `Map.empty'
08:47:49 <CakeProphet> > show $ Data.Map.empty
08:47:49 <lambdabot>   Not in scope: `Data.Map.empty'
08:47:58 <geheimdienst> > show empty
08:47:59 <lambdabot>   Ambiguous occurrence `empty'
08:48:00 <lambdabot>  It could refer to either `Control.Applicative...
08:48:04 <CakeProphet> > show M.empty
08:48:05 <lambdabot>   "fromList []"
08:48:16 <geheimdienst> @src M.empty
08:48:17 <lambdabot> Source not found. Your mind just hasn't been the same since the electro-shock, has it?
08:48:27 <jmcarthur> @src Data.Map.empty
08:48:27 <lambdabot> Source not found. Listen, broccoli brains, I don't have time to listen to this trash.
08:48:42 <geheimdienst> woah. if you "show" it, it gives you a String with haskell code inside
08:48:47 <jmcarthur> right
08:48:58 <jmcarthur> much easier to read than the naive show would do
08:49:05 <jmcarthur> and still fits the "valid haskell code" requirement
08:49:37 <geheimdienst> yeah, it's really not bad
08:50:08 <jmcarthur> > show $ M.fromList [("foo", 3), ("bar", 4)]
08:50:09 <lambdabot>   "fromList [(\"bar\",4),(\"foo\",3)]"
08:50:33 <quicksilver> You know what would be cooler?
08:50:44 <geheimdienst> > M.fromList [(3,4)]
08:50:44 <lambdabot>   fromList [(3,4)]
08:50:54 <quicksilver> if show produced [$map| "foo" --> 3, "bar" --> 4 |]
08:51:04 <jmcarthur> o_O
08:51:18 <quicksilver> or, well, something a bit cleverer if you like, that was a first thought.
08:51:21 <geheimdienst> what is $map?
08:51:25 <quicksilver> a quasiquoter
08:51:30 <quicksilver> (a fictional one, in fact)
08:51:38 <geheimdienst> is that template haskell witchcraft ...?
08:51:39 <CakeProphet> :t mapM
08:51:40 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
08:51:49 <quicksilver> but I was just reflecting that quasiquoters could permit more attractive show instances without violating the haskell code rule.
08:51:55 <jmcarthur> you don't need a quasiquoter to get that syntax ;)
08:52:11 <quicksilver> geheimdienst: no, although it happens to be implemented using TH, it's a simpler thing in concept.
08:52:32 <quicksilver> jmcarthur: true, true.
08:52:40 <jmcarthur> > let (-->) = (,) in M.fromList ["foo" --> 3, "bar" --> 4]
08:52:41 <quicksilver> hence the 'cond' trick.
08:52:41 <lambdabot>   fromList [("bar",4),("foo",3)]
08:56:54 <geheimdienst> > let (-->) = M.insert in 3 --> 4 $ 5 --> 6 $ M.empty
08:56:55 <lambdabot>   fromList [(3,4),(5,6)]
08:57:23 <geheimdienst> suppose i wanted to get rid of the $s in there. could infixr or infixl help me?
08:57:30 <geheimdienst> > let (-->) = M.insert in 3 --> 4  5 --> 6  M.empty
08:57:31 <lambdabot>   Overlapping instances for GHC.Show.Show
08:57:31 <lambdabot>                              (Data....
09:01:11 <triyo> Hmm, parseTime of Data.Time.Format first param is of type System.Locale (TimeLocale), which is old-locale. does that make sense? 
09:01:54 * geheimdienst always imports Data.Time and System.Locale (defaultTimeLocale) *shrug*
09:03:21 <Athas> I have a problem with my haskell98 package.  I have a global installation of array-0.3.0.0 and a user installation of array-0.3.0.1.  Cabal thinks haskell98 always needs to be reinstalled, because the version of array changed from 0.3.0.0 to 0.3.0.1, yet for all I can see, it uses array-0.3.0.1 every time.
09:03:43 <Athas> Also, I have haskell98-1.0.1.1 installed at both global and user level.
09:05:07 <quicksilver> triyo: yeah, old-locale got renamed because it was intended to be deprecated, but there is no new version.
09:05:22 <quicksilver> triyo: since there is no new version it's not really deprecated :(
09:05:35 <monochrom> delete array-0.3.0.1. if it means deleting more packages, do so.
09:05:40 <CakeProphet> :i interleave
09:05:43 <quicksilver> geheimdienst: no, because function application always binds tighter than infixes.
09:05:47 <CakeProphet> :t interleave
09:05:47 <lambdabot> forall (m :: * -> *) a. (MonadLogic m) => m a -> m a -> m a
09:05:56 <monochrom> use "ghc-pkg unregister array-0.3.0.1" to delete
09:06:16 <quicksilver> geheimdienst: (3 --> 4 5 --> 6) is *always* going to parse as (3 --> (4 5) --> 6)
09:06:22 <CakeProphet> > interleave "," "test"
09:06:23 <lambdabot>   ",test"
09:06:38 <CakeProphet> > interleave "test" ","
09:06:38 <lambdabot>   "t,est"
09:06:50 <geheimdienst> quicksilver, thanks for looking at it. so that's what the guy meant the other day with " " is the "operator" which binds tightest
09:06:57 <CakeProphet> > interleave "test" ",,,"
09:06:58 <lambdabot>   "t,e,s,t"
09:07:08 <CakeProphet> > interleave "test" (repeat ',')
09:07:09 <lambdabot>   "t,e,s,t,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,...
09:07:24 <CakeProphet> :t intercalate
09:07:25 <lambdabot> forall a. [a] -> [[a]] -> [a]
09:07:27 <geheimdienst> > intersperse ',' "lolcats"
09:07:27 <lambdabot>   "l,o,l,c,a,t,s"
09:07:35 <CakeProphet> ah. :)
09:07:59 <geheimdienst> > intercalate "__" "lolcat"
09:08:00 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
09:08:00 <lambdabot>         against inferred ty...
09:08:27 <wjt> @index extraleave
09:08:28 <lambdabot> bzzt
09:08:30 <wjt> aww :(
09:08:35 <wjt> @index uninterleave
09:08:36 <lambdabot> bzzt
09:09:47 <quicksilver> geheimdienst: right.
09:10:08 <quicksilver> geheimdienst: the virtue is it makes it easier to predict what code does without understanding all the infixl/r of the custom operators
09:10:21 <quicksilver> geheimdienst: (at least you know function binds tighest) - makes the language more uniform.
09:10:26 <zygoloid> > outerleave "test" "hello"
09:10:27 <lambdabot>   "sthellost"
09:10:31 <quicksilver> geheimdienst: the disadvantage is you can't do clever tricks like that!
09:11:07 <aristid> :t outerleave
09:11:08 <lambdabot> forall t. [t] -> [t] -> [t]
09:11:13 <aristid> @src outerleave
09:11:13 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
09:11:20 <geheimdienst> quicksilver, very true. thanks for the explanation :)
09:11:29 <geheimdienst> > outerleave "XYZ" "lolcat"
09:11:30 <lambdabot>   "ZXlolcatZ"
09:11:31 <triyo> quicksilver: thanks for your answer about the old-locale. At least I now know.
09:11:37 <geheimdienst> > outerleave "TEST" "lolcat"
09:11:38 <lambdabot>   "STlolcatST"
09:11:47 <geheimdienst> why is there no E in that?
09:11:59 <Eduard_Munteanu> > outerleave "12ST" "lolcat"
09:12:00 <lambdabot>   "S1lolcatST"
09:12:10 <Eduard_Munteanu> Hm.
09:12:26 <zygoloid> > outerleave "ABCD" "EFGH"
09:12:27 <lambdabot>   Not in scope: `outerleave'
09:13:01 <quicksilver> geheimdienst: with quasiquoters you can do any trick you want - you get to define your own language, anything you can parse.
09:13:21 <quicksilver> geheimdienst: but the syntax is a little bit [$ugly| don't you think? |]
09:13:43 <zygoloid> it's also hard to [| embed $( arbitrary haskell expressions ) |]
09:13:44 <quicksilver> probably map was a bad example but *in principle* QQ could be a fun way to do your Show instance.
09:14:20 <quicksilver> zygoloid: is it hard? I thought QQ had unquoting?
09:14:29 <zygoloid> quicksilver: it doesn't have haskell parsing
09:14:39 <zygoloid> you can use haskell-src-meta, but i'd prefer to use the /same/ parser :)
09:14:47 <quicksilver> yes, it would be nice to be given access to the actual parser.
09:17:00 * zygoloid ponders why his heap scavenging is missing things which are clearly still referenced
09:17:34 <Eduard_Munteanu> Mmm, do we have some sort of 'eval' in Haskell? Not necessarily in core stuff.
09:17:41 <Saizan> the ghc api is not hiding a String -> TH AST functions somewhere, is it?
09:17:52 <chrisdone> are records possible with GADTs
09:18:08 <chrisdone> ah, yes
09:18:21 <chrisdone> just got the syntax wrong
09:18:26 <zygoloid> Saizan: sadly i don't believe so.
09:18:29 <Eduard_Munteanu> (i.e. evaluating Haskell code dynamically / reflection)
09:18:31 <Tomsik__> >outerleave "123456" "what"
09:18:40 <quicksilver> Eduard_Munteanu: various packages use the GHC API to do that
09:18:44 <zygoloid> Tomsik__: moar space required
09:18:49 <quicksilver> hint, mueval, plugins, dyre
09:18:49 <Tomsik__> > outerleave "123456" "what"
09:18:50 <lambdabot>   "531what246"
09:19:03 <Tomsik__> that's a weird function out there
09:19:30 <Eduard_Munteanu> quicksilver: ah, thanks.
09:19:42 <Saizan> dyre just calls ghc as a process, iiuc :)
09:20:22 <Eduard_Munteanu> But still, I'd expect context to be present in the evaluation.
09:20:23 <otto_s>  > outerleave "()[]{}" "what"
09:20:27 <otto_s> > outerleave "()[]{}" "what"
09:20:28 <lambdabot>   "{[(what)]}"
09:20:53 <Tomsik__> that'd be cooler if it were in prolog-eque style
09:21:00 <Eduard_Munteanu> Like for instance "eval \"foo a\"" takes a from the outer context.
09:21:11 * zygoloid is having some pain implementing a ghci-style interface (but in a more interesting monad than IO) with the ghc api
09:21:12 <Tomsik__> like, "{[(what)]}" = outerleave X Y
09:21:36 <monochrom> «eval "foo a"» is more readable, requiring less unescaping by humans
09:21:43 <aristid> > outerleave "123456789" "a"
09:21:44 <lambdabot>   "97531a2468"
09:21:54 <Eduard_Munteanu> Yeah, I was lazy to just replace " by '.
09:22:26 <aristid> Eduard_Munteanu: i wouldn't have bothered quoting at all :D
09:22:42 <monochrom> «'h' : "ello I'm smart"» will deny you of both ' and " :)
09:22:46 <quicksilver> Eduard_Munteanu: no. That's phenomenally hard.
09:22:57 <quicksilver> Eduard_Munteanu: by the time the code runs "a" doesn't exist any more.
09:23:05 <quicksilver> GHC discards variable names (and types) at compile time.
09:23:27 <Eduard_Munteanu> quicksilver: yeah, it probably can't be implemented as a lib. Needs real reflection support.
09:23:34 <Tomsik__> it could strip automatically too then I guess
09:23:34 <quicksilver> so managing a dynamic eval which had access to *local* scope would be a lot of work.
09:23:51 <quicksilver> Eduard_Munteanu: s/real reflection support/an entirely different compiler design/
09:24:24 <quicksilver> deciding to keep some chunk of *global* scope accessible is not a big problem, though - that's what a library interface is.
09:24:25 <Saizan> Eduard_Munteanu: you can do "eval "foo" $ a" though :)
09:24:34 <Eduard_Munteanu> quicksilver: considering ghci is an interpreter, perhaps it's not so impossible to do it.
09:24:53 <quicksilver> but then the whole thing is interpreted so I'm not sure what the point is.
09:24:59 <Eduard_Munteanu> Saizan: yeah, I was just wondering, I actually don't have any use for that :)
09:25:16 * chrisdone shrieks at a Haskell `eval'
09:25:24 <FunctorSalad_> didn't read the context but poor man's eval: dump to file, invoke ghc o_o
09:25:28 <zygoloid> you could capture the lexical scope around calls to eval, i suppose
09:26:11 <zygoloid> though i'm not sure what you'd do about type variables. i guess they'd need to be made rigid?
09:26:11 <FunctorSalad_> Saizan: @ String -> TH_AST: parse to GHC AST, convert?
09:26:20 <quicksilver> zygoloid: yup. Be quite expensive and would defeat quite a lot of the optimisations that GHC does though I think
09:26:26 <FunctorSalad_> there *has* to be a converter in there :)
09:26:34 <FunctorSalad_> for when you reify stuff
09:26:40 <Saizan> FunctorSalad_: it might not be exposed!
09:26:41 <Eduard_Munteanu> This kind of lispy stuff could work as a TH replacement I suppose.
09:27:06 <FunctorSalad_> Saizan: hmm that'd be unfortunate
09:27:19 <Eduard_Munteanu> Not really the best way of extending a language though.
09:27:29 <zygoloid> quicksilver: urgh. well, i'm going to be asking for some debug info in closures at some point, and that would cover somewhat similar information
09:27:31 <Saizan> FunctorSalad_: i guess ghc HQ wouldn't mind a patch for that though
09:27:39 <zygoloid> s/closures/info tables/
09:28:32 <quicksilver> zygoloid: but how do you make that not-fragile w.r.t inlining?
09:28:33 <Eduard_Munteanu> Reification doesn't require reflection at all, AFAICT.
09:28:46 <chrisdone>  Can't make a derived instance of `Show Output'
09:28:46 <chrisdone>       (Constructor `Output' does not have a Haskell-98 type)
09:28:48 <chrisdone> :((((
09:28:49 <quicksilver> zygoloid: (by only turning it on in a debug mode which turns inlining off?)
09:28:50 <FunctorSalad_> Eduard_Munteanu: it requires producing TH AST from source
09:28:51 <FunctorSalad_> ;)
09:29:19 <Eduard_Munteanu> FunctorSalad_: ah, I was referring to reification a la Dynamic.Typeable.
09:29:21 <zygoloid> quicksilver: well, that'd be one option. i'd want to do "the best we can do" with the state the core has been mangled into :)
09:29:24 <FunctorSalad_> chrisdone: try the brand-new reckless stalonederiving
09:29:42 <FunctorSalad_> it will just go ahead with any type you feed it :)
09:29:53 <chrisdone> FunctorSalad_: oh really :)
09:29:53 <quicksilver> zygoloid: The problem is that a single closure may be used "normally" in some cases but inlined in others
09:29:55 <FunctorSalad_> (and possibly fail to compile, but many work)
09:30:08 <quicksilver> zygoloid: so you may find it unexpectedly only works when the inliner is on your side.
09:30:15 <quicksilver> zygoloid: AIUI. I may not have this quite straight.
09:30:17 <zygoloid> quicksilver: sure. but you know from the closure itself (or rather from its info table pointer) which instance it is
09:30:22 <FunctorSalad_> Eduard_Munteanu: ok, I meant the Quasi monad method
09:30:35 <FunctorSalad_> (Name -> Q Info or similar)
09:31:52 <zygoloid> quicksilver: it'd be really useful to have just the file, lines, columns the info table was generated for (if known) and an array of names (and ideally types) for the slots in the closure. i think all of that information is practical to keep and export.
09:32:13 <quicksilver> zygoloid: yes, agreed. Especially if it was optional.
09:32:30 <zygoloid> absolutely. (hooray, another factor of two increase in my table sizes!)
09:37:25 <Athas> Why does my containers-0.3.0.0 insist on reinstalling itself because the array package changed from 0.3.0.0 to 0.3.0.1?  I've rebuilt containers a dozen times now, but it still thinks the version of array has changed.
09:41:12 <Saizan> Athas: because of a bug in cabal-install wrt multiple installations of the same package and same version, it does an early shadowing, so the new containers it installs is not even considered afterwards.
09:41:24 <Athas> Saizan: how can I fix that?
09:41:58 <Saizan> Athas: the sanest option, if possible, would be to get rid of your  array-0.3.0.1
09:42:01 <chrisdone> remove until there is only one remaining
09:42:08 <FunctorSalad> retry with a different order and/or grouping of packages? sorry, I don't know a good solution either :(
09:42:12 <Saizan> Athas: or!
09:42:27 <Saizan> Athas: you could install containers by bumping the version
09:42:27 <FunctorSalad> (grouping of passing them to a single cabal install)
09:42:54 <FunctorSalad> . o O ( script to make renamed clones of cabal packages )
09:42:57 <Saizan> Athas: i.e. "cabal unpack containers-0.3.0.0", edit the .cabal file to say version: 0.3.0.1; then "cabal install"
09:43:06 <FunctorSalad> (and autoadjust dependencies)
09:43:11 <chrisdone> ciao
09:43:22 <FunctorSalad> to turn the DAG into a tree
09:43:24 <Saizan> Athas: at this point cabal will default to this new 0.3.0.1 version just installed
09:43:30 <Athas> Urgh.
09:43:51 <Athas> Downgrading to array-0.3.0.0 seems like it would cause the least pain in the longer run.
09:43:57 <FunctorSalad> (not a serious suggestion but maybe this would work as a last resort ;))
09:44:01 <Saizan> Athas: exactly
09:44:37 <FunctorSalad> you mean array-0.3.0.1 isn't the new version coming with ghc? in that case I agree, not worth it
09:44:39 <Saizan> now, i'll go back to finishing the patch to solve this :)
09:44:51 <FunctorSalad> nice
09:45:48 <Athas> Saizan: thank you!
09:46:53 <Saizan> np
09:48:36 <int80_h> @
09:48:58 <int80_h> how do I use lambdabot to test an expression?
09:49:25 <quicksilver> > 3 + 4
09:49:25 <lambdabot>   7
09:49:32 <quicksilver> int80_h: like that? I'm not sure what you mean by 'test'
09:49:34 <int80_h> >:t digit
09:49:42 <int80_h>  > :t digit
09:49:47 <quicksilver> @type digit
09:49:48 <lambdabot> Not in scope: `digit'
09:49:56 <Tomsik_> :t isDigit
09:49:57 <lambdabot> Char -> Bool
09:50:37 <int80_h> hmm, I'm running through the "write a scheme..." tutorial, and it mentions a variable (or something) called digit. It's bugging me it makes no mention of where it came from, so I wanted to see if it was a part of Parsec, or something.
09:51:47 <quicksilver> sounds like parsec, yes.
09:51:49 <quicksilver> @hoogle digit
09:51:49 <lambdabot> Text.Parsec.Char digit :: Stream s m Char => ParsecT s u m Char
09:51:50 <lambdabot> Text.ParserCombinators.Parsec.Char digit :: Stream s m Char => ParsecT s u m Char
09:51:50 <lambdabot> Data.Char digitToInt :: Char -> Int
09:52:02 <int80_h> ah, good.
09:52:05 <quicksilver> int80_h: NB, hoogle is not a lambdabot command, it is a website, you should use it directly.
09:52:17 <quicksilver> it is excellent for answering questions like that one.
09:52:27 <int80_h> thanks. I'm still learning how to use the tools available.
09:52:28 <quicksilver> (well obviously it is a lambdabot command too, but you see what I mean ;)
09:54:43 <ManateeLazyCat> Currently, ghc-6.12.3 statically linked everything in one execute file? My execute file looks too huge (37MB)....
09:55:12 <Tomsik_> tried stripping it?
09:55:26 <Zao> ManateeLazyCat: Unless you say -dynamic, the RTS and all is statically linked in.
09:56:10 <ManateeLazyCat> Zao: So ghc has support dynamic link *complete*?
09:57:02 <ManateeLazyCat> Zao: Looks ghc default use statically linked.
09:57:11 <Zao> http://www.haskell.org/ghc/docs/6.12.2/html/users_guide/using-shared-libs.html
09:59:24 <Zao> Note the restrictions on what platforms you can do things on.
10:00:09 <monochrom> works greatly on linux
10:00:33 <ManateeLazyCat> Zao: Hmm, looks dynamic linked haven't support on Windows.
10:03:37 <aristid> i like this: http://bonsaicode.wordpress.com/2010/07/13/programming-praxis-word-cube/
10:04:54 <RyanT5000> how would i go about finding the code that actually implements LANGUAGE Arrows ?
10:05:26 <RyanT5000> (i've never really looked at GHC's extension code before)
10:06:35 <jmreardon> could someone help me understand what's going on in this code? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27803
10:06:45 <ManateeLazyCat> Zao: Dynamic linked is very important for Haskell plugins system, otherwise execute file will too big....
10:07:03 <ManateeLazyCat> Zao: Unfortunately, looks ghc don't support Windows yet.....
10:07:15 <Saizan> RyanT5000: grep? it finds me compiler/typecheck/TcArrows.lhs and compiler/deSugar/DsArrows.lhs which look promising
10:08:00 <jmcarthur> ManateeLazyCat: if you build all your dependencies with --enable-split-objs you should be able to shrink it down a bit
10:08:24 <jmcarthur> huh, i didn't know that ghc strips binaries by default though
10:08:44 <RyanT5000> Saizan: thanks; i was hoping there was some central place that that information was organized, but grep will certainly do
10:08:46 <ManateeLazyCat> jmcarthur: No, i said last execute file.
10:09:15 <jmcarthur> ManateeLazyCat: i'm saying that if you link against libraries that were built with --enable-split-objs then the final executable should be smaller
10:09:33 <ManateeLazyCat> jmcarthur: Currently, ghc use statically link, ghc will put *everything* in execute file too make it too big.
10:09:44 <jmcarthur> right
10:09:58 <jmcarthur> ManateeLazyCat: --enable-split-objs means it links against smaller binaries
10:10:35 <jmcarthur> ManateeLazyCat: "Use the GHC -split-objs feature when building the library. This reduces the final size of the executables that use the library by allowing them to link with only the bits that they use rather than the entire library. The downside is that building the library takes longer and uses considerably more memory."
10:11:22 <jmcarthur> oh
10:11:28 <jmcarthur> i didn't realize that was a dynamic linking thing
10:11:38 <jmcarthur> i didn't think it was, strictly...
10:12:21 <Saizan> wow, there's actually a bitmap for these flags in the lexer/parser
10:12:36 <jmcarthur> "Tell the linker to split the single object file that would normally be generated into multiple object files, one per top-level Haskell function or type in the module. This only makes sense for libraries, where it means that executables linked against the library are smaller as they only link against the object files that they need. However, assembling all the sections separately is expensive, so this
10:12:38 <jmcarthur>  is slower than compiling normally. We use this feature for building GHC's libraries (warning: don't use it unless you know what you're doing!)."
10:12:42 <ManateeLazyCat> jmcarthur: Infact, we can link all libraries dynamically, then we will got minimum execute file, special for a plugins system.
10:12:48 <jmcarthur> (GHC's -split-objs flag)
10:13:25 <conal> does ghc's CPP have a token splice mechanism like "foo##bar" for "foobar"?
10:13:35 <ManateeLazyCat> jmcarthur: At last, we not just can link Haskell library dynamically, we can link any dynamic libraries that written by other language.
10:13:36 <jmcarthur> RyanT5000: is something broken or needing improvement in arrow notation?
10:14:19 <RyanT5000> jmcarthur: well, i'm interested in decreasing the use of "arr" in the translation of the "proc -> do" form
10:14:30 <jmcarthur> ah
10:14:32 <int80_h> quicksilver : could you help me understand the type for Text.ParserCombinators.Parsec.Char digit? And also confirm for me that this is the type that http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours/Parsing refers to?
10:14:34 <RyanT5000> it obfuscates a lot of stuff
10:14:38 <jmcarthur> i bet
10:14:46 <RyanT5000> and eliminates a lot of opportunities for optimization in the code i'm writing
10:14:58 <RyanT5000> specifically, i wrote an incremental evaluation arrow transformer
10:15:03 <ManateeLazyCat> jmcarthur: Yes, --enable-split-objs can split object library, but once your main library need any libraries, ghc will link everything in execute file.
10:15:04 <jmcarthur> i don't like arr anyway. i wish it was separated from the other Arrow stuff into another class, personally
10:15:17 <RyanT5000> which works great - saves lots of computation - when you hand-code things with *** and &&& and such
10:15:25 <jmcarthur> ManateeLazyCat: doesn't that defeat the purpose?
10:15:30 <deo-> I would be grateful if someone explained the difference between compiling a .hs file with ghc and opening it with ghci.. I tried to compile an example - it didnt work, but when I opened the file (in ghci) I could call main ok
10:15:38 <RyanT5000> but when it's all arr _ >>> something >>> arr _ something >>> arr something
10:15:44 <RyanT5000> then there's essentially no benefit
10:16:01 <illissius> deo-: if it gave linker errors, you should use ghc --make
10:16:03 <RyanT5000> (or, to get a benefit, i'd have to do deep introspection of each result to try to find things that were not changed)
10:16:12 <jmcarthur> RyanT5000: there's always rewrite rules :(
10:16:15 <deo-> illissius: thanks, ill try that
10:16:26 <Saizan> RyanT5000: there are also RULES in Control.Arrow that will convert even more things to arr :\
10:16:31 <RyanT5000> lame
10:16:40 <jmcarthur> Saizan: yuck!
10:16:50 <RyanT5000> well, maybe there's something wrong with my approach entirely...
10:17:16 <Saizan> e.g. "arr f *** arr g = arr (f *** g)"
10:17:26 <RyanT5000> gah, that's exactly what i don't want :P
10:17:39 <RyanT5000> i'd like the opposite rule :)
10:17:46 <Saizan> same here!
10:17:50 <RyanT5000> well, hm
10:17:52 <deo-> illissius: yay, that worked out, thanks a bunch!
10:17:57 <Saizan> http://www.haskell.org/ghc/docs/6.12.2/html/libraries/base-4.2.0.1/src/Control-Arrow.html <- look for RULES here
10:18:02 <illissius> deo-: yw :)
10:18:23 <RyanT5000> well, could we get arr out of arrows entirely?
10:18:26 * jmcarthur wonders what happens if you encode a less general version of the opposite rule
10:18:34 <jmcarthur> for your type, i mean
10:18:57 <RyanT5000> which type?
10:19:00 <RyanT5000> oh
10:19:07 <RyanT5000> my arrow transformer type
10:19:20 <jmcarthur> like you let Control.Arrow rules do their things, then your stuff gets inlined and your rules can fire
10:19:20 <RyanT5000> i haven't actually tried messing around with rules yet
10:19:36 <RyanT5000> though honestly i'd rather not heavily rely on rules
10:19:46 <jmcarthur> yeah, they can be unpredictable
10:20:16 <RyanT5000> i wonder how difficult it would be to compile arrow computations without arr
10:20:22 <RyanT5000> it seems like they're just used for plumbing, mostly
10:20:54 <jmcarthur> if you can manage that please convince somebody to include your patch in GHC and move arr to another class :)
10:21:27 <RyanT5000> i think the problem is that in proc (blah) -> do, blah is any pattern
10:21:52 <RyanT5000> we'd need a way of pattern matching without lambdas
10:21:58 <RyanT5000> which we already have for pairs
10:22:06 <Saizan> not sure about the proc syntax desugaring, though arr is kind of the only way to lift a pure function..
10:22:32 <RyanT5000> sure, but the ability to lift a pure function doesn't need to be present in every conceivable arrow
10:22:33 <jmcarthur> could "just" avoid proc syntax
10:22:47 <Saizan> RyanT5000: *nod*
10:23:02 <RyanT5000> in fact, it might be nicer if arr were just "lift" from ArrowTransformer
10:23:09 <jmcarthur> yes
10:23:15 <RyanT5000> and anything that wanted arr was an arrowtransformer of (->)
10:23:42 <RyanT5000> so, in addition to (,), we can also bind Either a b using ArrowChoice
10:23:44 <jmcarthur> then the rest of Arrow would look a bit more like Bifunctor, which would be my preference
10:24:01 <jmcarthur> rather, the (***), either, etc. stuff would
10:24:22 <RyanT5000> perhaps we just need to have two classes: ArrowSum and ArrowProduct
10:24:34 <RyanT5000> the first binds sum types, the second binds product types
10:24:35 <jmcarthur> Bifunctor (->) Either, Bifunctor (->) (,), etc.
10:25:01 <RyanT5000> i'll need to look up bifunctor
10:25:09 <jmcarthur> we dont' have one standard
10:25:15 <RyanT5000> ah
10:25:29 <c_wraith> does bifunctor give fmap1 and fmap2, or is it some other interface?
10:25:52 <jmcarthur> RyanT5000: the project is basically dead now, but here is some of my take on the arrow stuff https://patch-tag.com/r/jmcarthur/alt-stdlib/snapshot/current/content/pretty/Control/Arrow.hs
10:27:54 <mauke> @where lambdabot
10:27:54 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot.html
10:28:31 <jmcarthur> i'm still thinking about making a few separate libraries based on alt-stdlib and just sticking them on hackage to use with base
10:28:41 <RyanT5000> hm, yeah
10:29:22 <RyanT5000> well, i think what i'm going to do is plow along with the other couple of arrow transformers i was going to make, and profile the whole thing once i'm done
10:29:34 <jmcarthur> RyanT5000: it's also interesting to note that even with our current Control.Arrow, Arrow is equivalent in power to the combination of Category and Applicative
10:29:35 <RyanT5000> it seems very likely that something will need to change
10:30:21 <RyanT5000> jmcarthur: hm, i didn't realize applicative was that powerful
10:30:39 <c_wraith> Applicative is the equivalent of a pushdown automata.
10:31:30 <c_wraith> That's a fun result from noticing that Applicative parsers can parse context-free grammars, but not context-sensitive grammars.
10:31:42 <RyanT5000> huh
10:32:41 <aristid> c_wraith: now what about Category parsers? :D
10:33:54 <jmcarthur> aristid: not far fetched. we have monoidal parsers already. Category is much more limiting though
10:34:12 <jmcarthur> well, unless you just set the parameters to () () anyway
10:34:45 <jmcarthur> i don't see much benefit in a category parser, myself
10:35:00 <jmcarthur> even monoidal parsers can pretty much only do some forms of lexing
10:35:15 <jmcarthur> but they benefit from being easy to parallelize
10:35:35 <aristid> in theory at least
10:35:53 <jmcarthur> aristid: ask edwardk about it next time he's in
10:37:00 <jmcarthur> aristid: or just look over this: http://comonad.com/reader/2009/iteratees-parsec-and-monoid/
10:37:45 <ManateeLazyCat> Anyone familiar with dons hs-plugins? Can you fix it? Looks dons very busy at the moment, i really want to use it, but i'm not sure i understand very details.
10:38:09 <ManateeLazyCat> Now hs-plugins just can't works with Cabal-1.8.
10:38:31 <ManateeLazyCat> So core code that interactive with ghc should okay...
10:39:00 <aristid> jmcarthur: he did some esplainin already, and it involved Data.Reflection :)
10:39:34 <jmcarthur> err
10:39:37 <jmcarthur> that's new then
10:40:32 <aristid> jmcarthur: well it was about constructing monoidal DFAs, and getting the grammar in there with reify IIRC
10:41:05 <Saizan> c_wraith: bifunctor gives bimap :: (a -> b) -> (c -> d) -> (f a c -> f b d) -- potentially with some or all the inner arrows overloaded 
10:41:12 <aristid> jmcarthur: i notice that i didn't really understand it :D
10:42:19 <c_wraith> Saizan: ok, thanks.
10:42:38 <ManateeLazyCat> Bye all, night.
10:45:17 <int80_h> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27807#a27807
10:45:27 <int80_h> help?
10:46:43 <Taejo> int80_h: what is the type of (>>=)
10:46:44 <Taejo> ?
10:47:49 <int80_h> > :t >>=
10:47:50 <lambdabot>   <no location info>: parse error on input `:'
10:47:56 <int80_h> oh swell
10:47:59 <Taejo> :t (>>=)
10:48:00 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
10:48:11 <int80_h> I don't know how to evaluate that
10:48:15 <Taejo> "> foo" evaluates foo
10:48:38 <Taejo> ok, in this case m = Parser
10:48:59 <Taejo> so (>>=) :: Parser a -> (a -> Parser b) -> Parser b
10:49:09 <Taejo> now, what type is read?
10:49:19 <int80_h> > :t read
10:49:20 <lambdabot>   <no location info>: parse error on input `:'
10:49:31 <int80_h> :t read
10:49:32 <Taejo> int80_h: "> foo" evaluates foo
10:49:32 <lambdabot> forall a. (Read a) => String -> a
10:50:05 <Taejo> int80_h: that doesn't look like something -> Parser something2, does it?
10:50:15 <int80_h> nope
10:50:24 <Taejo> so it can't be the second argument of (>>=)
10:50:50 <int80_h> Taejo : I'm having trouble with the >>= operator.
10:51:04 <int80_h> In my mind >>= doesn't have a second operator
10:51:25 <Taejo> you mean a second argument?
10:51:31 <Taejo> so what do you think >>= does?
10:51:33 <int80_h> the tutorial explains >>= as a pipe. So I htink of it as a | (in scripting terms)
10:51:48 <int80_h> I mean second argument, yes
10:51:57 <Tomsik_> monads are boxes and >>= gets stuff out of the box, that's how I see it
10:52:04 <Taejo> I'm not sure if that's a good way, but shell pipes do have second arguments
10:52:11 <Tomsik_> like list is a box of things and maybe is box that maybe has something ini t
10:52:18 <djahandarie> @type (>>=)
10:52:19 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
10:52:33 <Taejo> it's "a | b", not "a |" or "| b"
10:52:35 <djahandarie> Screw the analogies, if the types match you're good ;)
10:53:02 <Tomsik_> yeah, sometimes you need just types to match
10:53:12 <Tomsik_> and something works
10:54:05 <int80_h> many1 digit >>= read >>= Number, I think is supposed to pass the result of many1 evaluating digit to read, which then passes the result of it's evaluation to Number.
10:54:17 <int80_h> is that totally wrong?
10:54:22 <Taejo> ok, this is why the pipe explanation is shit
10:54:34 <Taejo> because it doesn't say why that is wrong
10:54:50 <Saizan> unless you say something like "read and Number are not processes" :)
10:55:05 <Taejo> Saizan: but then what are they?
10:55:37 <Saizan> int80_h: basically the second argument to (>>=) has to construct a monadic action, but read and Number are just pure functions, i.e. they don't return a Parser something
10:55:49 <Saizan> int80_h: though we have return :: a -> Parser a
10:56:26 <Saizan> int80_h: you could then write "many1 digit >>= (return . read) >>= (return . Number)"
10:56:28 <Taejo> usually you won't be mixing do notation and >>= (until you know what you're doing)
10:56:45 <int80_h> Saizan, so will I have to lift their return value into a Parser monad?
10:57:05 <djahandarie> Ugh, the word "return" strikes again
10:57:14 <int80_h> Taejo, yeah I was just following the assignment. I'm kinda lost here, not even sure if I'm asking questions that make sense.
10:57:42 <Saizan> int80_h: essentially yes, like in the code i've just shown
10:57:51 <Saizan> int80_h: but, m >>= return . f == liftM f m, so you can rewrite that as "liftM Number (liftM read (many1 digit))"
10:57:58 <int80_h> I mean the value as the result of the function evaluation, not the haskell return. I think I understand what that does.
10:58:12 <Taejo> Saizan: if you look at the paste, you'll see that's what he started with
10:58:18 <Taejo> almost
10:58:31 <Saizan> int80_h: and liftM f . liftM g = liftM (f . g), so you can rewrite the whole thing as "liftM (Number . read) (many1 digit)"
10:58:38 <int80_h> Saizan, I need to use do notation and >>= as part of the tutorial assignment
10:58:58 <Taejo> int80_h: are you sure you aren't supposed to write *two* versions?
10:59:05 <Taejo> one with do and the other with >>=
10:59:09 <Taejo> that makes more sense
10:59:40 <int80_h> oh crap!! that could be right. I almost had one written with do notation working. Then I decided I needed to combine the two in one version
11:00:02 * hackagebot HaTeX 1.0.1 - Library for generate LaTeX code.  http://hackage.haskell.org/package/HaTeX-1.0.1 (DanielDiaz)
11:00:09 <Saizan> for the other you can cheat with @undo :)
11:00:19 <int80_h> Taejo, would you do me the service of peeking at the answers to exercises to see if thats what the author had in mind?
11:00:37 <Taejo> int80_h: no problem
11:01:06 <Taejo> where are the solutions?
11:01:24 <Saizan> (alternatively you can follow my reasoning starting from the bottom, equivalences ftw)
11:01:38 <int80_h> Taejo: http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours
11:01:47 <int80_h> the table of contents are there
11:02:20 <Taejo> yes, there are two answers
11:02:30 <Taejo> one with >>= and the other with do
11:02:35 <Saizan> "m >>= (return . f) >>= (return . g) == m >>= return . f . g" also
11:03:06 <BMeph> IOW, Saizan FTW! ;)
11:03:48 * Saizan wonders what's a good way to show the latter
11:04:01 <jmcarthur> f . g <$> m
11:04:11 <int80_h> FTW == for those wondering?
11:04:17 <jmcarthur> for the win
11:04:34 <BMeph> ^^ jmcarthur FTW! ;)
11:05:13 <Saizan> yeah, probably going via "m >>= return . f = f <$> m" is the sanest route
11:05:41 <BMeph> Saizan: FSVO "sane", I guess... ;)
11:06:07 <Tomsik_> f `fmap` m sounds more explicit to me
11:06:35 <Saizan> alternatively we can build a monadic expressions normalizer and compare the normal forms :)
11:06:46 <jmcarthur> m >>= (return . f) >>= (return . g)  ==  f <$> m >>= return . g  ==  g <$> (f <$> m)  ==  g . f <$> m
11:06:52 <zygoloid> m >>= return . f >>= return . g = m >>= (\x -> return (f x) >>= return . g) = m >>= (\x -> return (g (f x))) = m >>= return . g . f
11:07:35 <djahandarie> lol...
11:08:07 * Saizan hires jmcarthur and zygoloid to do his Agda proofs about monads
11:08:11 <zygoloid> ('s no harder to use the monad laws directly)
11:08:19 * jmcarthur is not good with agda proofs
11:08:41 <Saizan> the difference with what you've done is that you've to name the law too :)
11:09:03 <zygoloid> associativity, left identity, left identity :)
11:09:28 <jmcarthur> yeah, naming the law isn't so bad there
11:09:31 <zygoloid> (oops, only 1x left identity)
11:10:10 * hackagebot RefSerialize 0.2.7 - Write to and read from Strings maintaining internal memory references  http://hackage.haskell.org/package/RefSerialize-0.2.7 (AlbertoCorona)
11:13:25 <jmreardon> anyone want to help with an IO problem? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27808#a27808
11:14:14 * Eduard_Munteanu wonders if the automatic Graphite loop parallelization in GCC 4.5 is worth trying to rebuild all packages on his Gentoo system.
11:14:26 <Eduard_Munteanu> At least when it's going to be unmasked.
11:14:26 <Saizan> jmreardon: sounds like some problem with I/O buffering
11:14:40 <Saizan> jmreardon: try inserting an hFlush stdout before getLine
11:15:21 <Ke> Eduard_Munteanu: that is really ricing^n
11:15:25 <Eduard_Munteanu> BTW, is there a similar feature in GHC?
11:15:55 <Saizan> there are parMap and friends, and the Data Parallel Haskell arrays
11:16:01 <Ke> Eduard_Munteanu: there are some parallel trivila data structures
11:16:16 <jmreardon> Saizan: I've tried flushing and setting buffering options but they've had no effect
11:16:20 <Eduard_Munteanu> Ke: yeah, most likely it would parallelize noninteresting stuff.
11:16:48 <Ke> graphite is mostly interesting only for science apps
11:17:05 <Ke> and there openmp is omnipresent anyways
11:17:12 <Ke> well ~
11:17:38 <Eduard_Munteanu> Ke: and where important stuff is already hand-optimized ;)
11:17:47 <Saizan> jmreardon: oh, probably because isEQF needs to see some input to return False and so let the next iteration run
11:17:59 <Eduard_Munteanu> Saizan: well yeah, that still requires explicit annotation.
11:19:12 <Saizan> jmreardon: so with that kind of loop you always need at least one char to be inputed before the putStrLn could run
11:20:04 <jmreardon> is there a more appropriate way to get interactive input in Haskell?
11:20:14 <Saizan> you could use "let before = putStrLn "Before getting the line" in before >> untilM_ (getLine >>= putStrLn >> putStrLn "After gettting the line" >> before) isEOF" but that's ugly.
11:20:44 <Saizan> jmreardon: i think your problem is manly that untilM_ is a bad fit for your kind of loop
11:20:46 <Eduard_Munteanu> Though in Haskell's case it's probably cheaper to do worthless paralellization, due to the way user threads are multiplexed.
11:20:58 <Eduard_Munteanu> s/cheaper/safer
11:22:06 <Saizan> Eduard_Munteanu: afaiu, early research on fully automatic parallelism wasn't showing promising result, so the focus shifted to lightweight annotations, things might have changed with current CPUs though..
11:22:15 <Saizan> *results
11:22:49 <Eduard_Munteanu> Saizan: yeah, that seems reasonable, after all it's a hell of a hard problem to do useful parallelization. 
11:23:35 <jmreardon> Saizan: how should I be getting input without checking for eof though?
11:25:10 <Saizan> jmreardon: i'm pretty sure getLine just returns the empty string on EOF, or otherwise it'll throw an exception
11:25:19 <Eduard_Munteanu> jmreardon: you should also see if you need to disable line buffering
11:25:39 <jmreardon> Eduard_Munteanu: I've checked that
11:26:14 <Eduard_Munteanu> jmreardon: and try using 'interact' instead of that.
11:26:18 <Eduard_Munteanu> :t interact
11:26:19 <lambdabot> (String -> String) -> IO ()
11:26:20 <Saizan> jmreardon: right, you get an "hGetLine: end of file" exception
11:27:24 <Eduard_Munteanu> Something like 'main = interact (unlines . f . lines)' is probably a better way to do IO
11:27:32 <jmreardon> Eduard_Munteanu: The code posted is just the demonstrate my problem, I'm doing more than output another string in my actual program, so interact is no good
11:27:55 <jmreardon> Saizan: so just catch the exception and move on?
11:28:53 <Saizan> jmreardon: right
11:28:59 <dolio> The problem with automatic parallelism is that there's too much parallelism to be had. Forking to evaluate each subexpression in (5 + 6) + (7 + 8) is (likely) slower than doing it all on the same CPU/core.
11:29:16 <jmreardon> Saizan: cool, thanks!
11:29:35 <Saizan> forever loop `catch` \e -> handle e
11:29:45 <Saizan> using Control.Exception.catch
11:30:03 <Saizan> ?hoogle isEOF
11:30:03 <lambdabot> System.IO isEOF :: IO Bool
11:30:03 <lambdabot> System.IO.Error isEOFError :: IOError -> Bool
11:30:03 <lambdabot> System.IO.Error isEOFErrorType :: IOErrorType -> Bool
11:30:15 <wli> dolio: Hence M:N threading.
11:30:25 <Eduard_Munteanu> dolio: yeah, thread creation ain't cheap. You need a good way to evaluate the CPU-boundness of subtasks, and that's dificult.
11:30:36 <dolio> wli: I mean even forking a green thread for each.
11:30:40 <Eduard_Munteanu> and execution time.
11:30:48 <Eduard_Munteanu> Yeah.
11:31:15 <pikhq> Eduard_Munteanu: Well, green threads are actually very cheap.
11:31:15 <dolio> Each of those is one instruction. Setting up a green thread almost certainly is more than that.
11:31:44 <pikhq> It's just that they're not necessarily cheaper than just doing the calculation.
11:31:56 <Saizan> well, just count the instructions
11:31:59 <Eduard_Munteanu> pikhq: yeah
11:32:39 <Eduard_Munteanu> Saizan: usually optimizations are done on an intermediate representation, and even if you do it on asm it's probably not easy
11:33:02 <Eduard_Munteanu> Actually a HIR tree or something like that.
11:33:10 <wli> dolio: Um, green threads are not used for anything serious. It's all M:N threads, i.e. setting the number of OS worker threads via env var or similar and the software threads are whatever the program spawns etc.
11:33:22 <Saizan> gcc must be doing something like that though, no?
11:33:45 <Eduard_Munteanu> Saizan: I'm really not sure how good its heuristics are.
11:33:58 <Eduard_Munteanu> I'd be interested to see worst-case performance though.
11:34:19 <Eduard_Munteanu> (GCC has no green thread AFAIK)
11:34:45 <dolio> wli: Fine. Take whatever you call the light-weight threads in your M:N threading model. Setting up one of the lightweight threads is almost certainly going to dwarf the cost of performing a single addition.
11:35:00 <Ke> Eduard_Munteanu: openmp uses those
11:35:19 <Eduard_Munteanu> Ke: ah, so it does on OpenMP
11:35:21 <dolio> So setting one up to get a single addition operation evaluated in parallel is going to be a net loss over just doing the addition sequentially with a couple others in the same thread.
11:35:31 <Ke> Eduard_Munteanu: ie. pthreads are native threads, but gcc does support green ones
11:35:33 <wli> You don't have cpu-boundedness farted around with, you do everything nonblocking/async/etc. so when something is IO-bound it's trapped by the threading runtime.
11:35:57 <wli> dolio: Okay, the chunking factor has to be substantially larger than that.
11:35:59 <Eduard_Munteanu> Ke: yeah, it most likely multiplexes green threads on pthreads, I don't see any other way
11:36:18 <Ke> Eduard_Munteanu: to my limited view gcc approach is much more pleasant
11:37:04 <wli> Eduard_Munteanu: That idea is called M:N threading but it takes a lot more than "green threads on pthreads" makes it sound like.
11:37:04 <dolio> wli: And that's why automatic parallelism based on functional purity doesn't work. There's too much to be had, so you need to annotate the useful levels of granularity.
11:38:07 <pikhq> Thank goodness that trivial parallelism *does* work.
11:38:53 <Saizan> "trivial parallelism"?
11:39:02 <pikhq> par and friends.
11:39:08 <pikhq> I'm not sure what it's actually called.
11:39:16 <pikhq> But it's pretty darned trivial.
11:39:17 <pikhq> :P
11:39:29 <monochrom> user-friendly parallelism
11:39:41 <Saizan> heh, parallel annotations, i believe :)
11:39:43 <Eduard_Munteanu> Well you could have the instruction selector just recurse down the tree and figure total costs for any given node, but it won't really work in reality.
11:39:46 <pikhq> Ah, right.
11:39:56 <pikhq> Eduard_Munteanu: Halting problem says "no" to total costs.
11:39:57 <pikhq> :D
11:40:14 <Eduard_Munteanu> Because most interesting and time consuming stuff can't be unrolled or simplified at compile time.
11:40:21 <Eduard_Munteanu> pikhq: yeah
11:40:26 <Saizan> that's why turing complete languages are silly, we can't have nice things!
11:40:27 <Ke> pikhq: you can guess 99% correct even without proven algorithm
11:40:36 <nschoe> Hi all! Can anyone advise me? I need my program to do a task every hour, every day etc. I searched timers or something equivalent, but didn't find what I was looking for.
11:40:39 <Eduard_Munteanu> Saizan: heh, true.
11:41:01 <Ke> or could if you had the proper magics
11:41:19 <Tomsik_> you could let user specify "parrallelizable"
11:41:25 <Tomsik_> what to parallelize and what not
11:41:43 <Eduard_Munteanu> That's what it's currently done, yeah.
11:41:51 <Eduard_Munteanu> And it will probably stay that way for a looong time.
11:41:56 <dons> @tell sclv truncate -> double2int via RULES in ghc 6.12.x
11:41:56 <lambdabot> Consider it noted.
11:42:24 <monochrom> nschoe: I use Control.Concurrent.threadDelay
11:42:30 <Tomsik_> until Church-Turing thesis is defeated? :p
11:42:49 <Saizan> nschoe: the happstack guys might have a good cron-like thing, otherwise you've to roll your own i believe, and pay attetion to arithmetic overflow :)
11:42:56 <Ke> Tomsik_: just try to think like an engineer
11:42:57 <nschoe> monochrom: thank you. I'll take a look in on haskell.org
11:43:00 <Eduard_Munteanu> With notable exceptions, as some have mentioned (e.g. scientific), where loop transformations might just prove something to be worth to parallelize.
11:43:27 <nschoe> Saizan: hum okay, so it means there is nothing already "standard" for such things?
11:43:36 <Tomsik_> if I were to think like engineer, I'd try to write a program to solve PCP
11:43:40 <Eduard_Munteanu> E.g. some loops can be unrolled at compile time, and some subset of those would be nice to parallelize
11:43:43 <chrisdone> Baughn: baagen
11:43:54 <Saizan> nschoe: right, afaik
11:43:56 <Eduard_Munteanu> Tomsik_: PCP?
11:44:02 <Eduard_Munteanu> That sounds intoxicating.
11:44:21 <Tomsik_> or totality of regular expressions with complement
11:44:25 <Tomsik_> post correspondence problem
11:44:30 <Eduard_Munteanu> Ah.
11:44:38 <nschoe> Saizan: he, okay. thanks for the info.
11:44:40 <Tomsik_> equivalent to halting problem, only less obvious :p
11:44:51 <monochrom> snide remark about engineering
11:45:18 <Eduard_Munteanu> Well even with total languages I don't think the problem is avoided.
11:45:35 <Eduard_Munteanu> It's just that you place stuff into categories and make it easier for compilers.
11:45:38 <Tomsik_> you can try to put estimates on run time
11:46:01 <Tomsik_> like "map is 150*length*f time" or something
11:46:10 <Tomsik_> only it's hell of an overkill
11:46:14 <Eduard_Munteanu> Tomsik_: heh, in that case you might just as well manually annotate parallelization :)
11:46:21 <Tomsik_> maybe some simple probabilistic algorithm would work
11:46:35 <Eduard_Munteanu> Profiling could do.
11:46:44 <Eduard_Munteanu> (I avoid to say the dreaded word "JIT")
11:46:54 <chrisdone> monochrom: please /j #haskell-blah
11:47:29 <Tomsik_> like, run a thread with 50% in parallel
11:47:33 <Tomsik_> maybe 25%
11:48:09 <ddarius> With total languages you simply go from impossible to infeasible.
11:48:58 <Tomsik_> Maybe the probabilistic approach has some sense
11:49:00 <Tomsik_> really
11:49:13 <Eduard_Munteanu> ddarius: hi. I've read some of Zeilberger's stuff. Interesting stuff, even if I don't fully agree with it.
11:49:24 <Tomsik_> I mean, overhead is smaller 
11:49:25 <nschoe> monochrom: Doesn't threadDelay consume too much processor resource?
11:49:28 <ddarius> Eduard_Munteanu: Yeah, he's a bit out there.
11:49:35 <monochrom> No.
11:49:59 <Tomsik_> and you do uses parallelism
11:50:17 <dons> jbapple: you should really call our just how bad jdh's methodology is here
11:50:26 <alexsuraci> having some trouble with profiling on OS X; profiling works but time shows 0.00 secs, and all the %time columns are 0.0
11:50:34 <Eduard_Munteanu> Tomsik_: yeah, basically I think JIT-heads already proposed this.
11:50:42 <dons> jbapple: very hard to determine what exactly he's measuring, since he chops and changes bits all the time.
11:50:44 <Tomsik_> JIT?
11:50:51 <alexsuraci> (also heap profiling doesn't work at all; the resulting file has 0 data)
11:51:00 <Eduard_Munteanu> Tomsik_: as in JIT (Just In Time) compilers
11:51:08 <dons> jbapple: seems to be no consistent standard for what he's trying to measure.
11:51:14 <Eduard_Munteanu> (Java stuff for instance)
11:51:20 <Tomsik_> that's horrible :p
11:51:29 <Eduard_Munteanu> Yeah it is :)
11:51:45 <jbapple> dons: There are lots of things to criticize. I don't think it's a very useful benchmark, so I wrote a different one that I though would be more interesting
11:51:51 <Eduard_Munteanu> (And they're merely reinventing the wheel and making it friendlier.)
11:52:33 <jbapple> (it's on the reddit thread on coding) It puts stdin into a string dictionary and does 50 lookups for every insert, with one failed lookup and 49 successful ones
11:52:41 <Tomsik_> maybe running the application a thousand times and gathering the data with profiler
11:52:54 <Tomsik_> and figuring out what to parallelize automatically
11:53:40 <Eduard_Munteanu> Considering Zeilberger's stuff, I'm wondering if anybody thought/tried making some seti@home Djinn spinoff. Like cluster theorem proving. Might work if you find a way to figure which proofs are "interesting". 
11:53:47 <dons> jbapple: indeed. a good suite of benchmarks could have been produced in a subset of the time jdh's spent reposting this stupid thing. what is it supposed to measure exactly?  i strongly suspect he has no use case that looks even remotely like this script. and the methodology is all wonky.
11:53:52 <jbapple> dons: I expect there may be flaws (even many flaws) in my suggestion, but I suspect it is more likely to reflect real-world HT usage than just inserting floating point numbers and doing one lookup
11:54:25 <dons> jbapple: anyway, you should package up your benchmarks, describe and publish the result.
11:54:42 <Eduard_Munteanu> Tomsik_: yeah, that might be worthy in _some_ cases. But then again profiling isn't really useful after all.
11:54:55 <Eduard_Munteanu> (rather profile-based automatic optimization)
11:54:57 <jbapple> dons: Maybe so, but GHC is still several times slower than C++, Java, and F# on the dictionary benchmark
11:55:44 <jbapple> dons: maybe I will post somewhere about it. I doubt it is interesting enough to be academic publishable
11:55:47 <dcoutts_> dons: hey, notice he managed to get the HP installed ok :-)
11:56:10 <Tomsik_> jb55: "several times slower" doesn't fit in range of C++ and Java
11:56:14 <dcoutts_> dons: I remember he used to complain that it takes days to get everything installed :-)
11:56:16 <Baughn> @tell chrisdone Um, okay?
11:56:16 <lambdabot> Consider it noted.
11:56:20 <jbapple> dons: Also, I think it might be fun and useful to improve Haskell's default HT for mor reasonable benchmarks
11:56:23 <Tomsik_> Java is a dozen times slower than C++ already
11:56:57 <jbapple> Tomsik_: Not on this benchmark
11:57:08 <Araneidae> Trying to learn how parallelism works: can anyone tell me why my m1 hangs in this: http://haskell.pastebin.com/HwRrUx28 ?
11:57:08 <Eduard_Munteanu> That depends. I like bashing those guys, but I don't like them coming back picking at my statements :)
11:57:35 <jbapple> Tomsik_: http://www.reddit.com/r/coding/comments/cr1yk/haskells_hash_table_performance_revisited_with/c0um4vk
11:57:52 <Eduard_Munteanu> Similarly, perhaps GHC should be bashed on the same grounds.
11:58:02 <jbapple> You have to scroll down to see the error I made with the haskell benchmark - I don't think the code I originally wrote forced the lookups enough
11:58:11 <Araneidae> Don't really know what I'm doing, but the idea is that `merge a b` does a & b in parallel and returns them in the order they complete.  But I haven't got it right, clearly...
11:58:29 <Tomsik_> haskell isn't about performance, is it
11:58:31 <jbapple> BTW, bytestring-trie was just awful for most benchmarks I tried -- worse than Data.Set
11:58:51 <dons> jbapple: yes, having some just work on the HT would be great.
11:59:03 <Eduard_Munteanu> Hm, F#/Mono faring so well?
11:59:05 <dons> jbapple: its fairly easy to modify, after all.
11:59:16 <dons> Eduard_Munteanu: no, not really. NET hashes do type specialization
11:59:25 <Tomsik_> you can't expect this level of abstraction to have the same performance as an object-oriented assembler like C++ :p
11:59:28 <dons> which is why they outperform java/C++/Haskell, afaik. all of which are about  the same
11:59:33 <jmcarthur> jbapple: bytestring-trie is that bad? :(
11:59:35 <jbapple> dons: Yes, the implementation is quite simple. I already suggested a patch a few days ago for one improvement
11:59:37 <Eduard_Munteanu> Ah, yet another thing that can't be generalized but people would love to.
11:59:59 <dons> jbapple: i think you can just send darcs patches :)
12:00:06 <dons> dcoutts_: yes. of course, he won't retract that stuff.
12:00:09 <jbapple> dons: how do they type specialize more than C++ templates?
12:00:27 <dons> dcoutts_: and likely will continue to say the same things he's said  in the past. modifying his views based on new information isn't something i see.
12:00:27 <Araneidae> Have I chosen a bad time to ask my beginner's question?
12:00:37 <dons> jbapple: well,  the  template stuff should also work
12:01:08 <Eduard_Munteanu> Araneidae: no, just persist.
12:01:12 <Araneidae> Sigh!
12:01:23 <Araneidae> Well, I've been experimenting, and merge isn't clearly wrong.
12:01:24 <dons> but seriously, there should be a big internet fail award for years of stupid `benchmarks'
12:01:32 <dons> and getting away with it.
12:01:36 <monochrom> Araneidae: try merge t1 t0
12:01:37 * Eduard_Munteanu agrees
12:01:39 <Araneidae> merge t0 t0  and  merge t1 t1  both work
12:01:52 <Araneidae> Yes, that works, monochrom
12:02:17 <Araneidae> But  merge t0 t1  hangs
12:02:38 <Araneidae> Is forkIO the right primitive to use here?  
12:02:41 <monochrom> the forked thread does putMVar. now the mvar is full. the main thread now does putMVar too, but the mvar is full, stuck
12:02:51 <Araneidae> Oh damn
12:02:54 <jbapple> I wonder if it is possible to do tyep specialization for array-like types in haskell with OverlappingInstances and having all array access go through a type class? Maybe that way unboxing would work without having to change to an unboxed array type, though I think the calling code would still have to be monomorphic to get the correct typeclass instance. If so, perhaps arrays could be as fast as the unboxed ones in F#
12:03:06 <Araneidae> I could fork them both, but seems clumsy.  Ok, I'll try that
12:03:10 <monochrom> don't rely on "the other thread won't start immediately"
12:03:21 <monochrom> don't rely on "the other thread will start immediately" either
12:03:39 <dcoutts_> dons: but we should just remove the Data.Hash if it's clearly so bad
12:04:04 <Araneidae> Great, that works: http://haskell.pastebin.com/Sp4YQJpG
12:04:13 <dcoutts_> dons: and wait for someone to implement a decent one, the current one is not used
12:04:18 <monochrom> you could also use Chan
12:04:23 <Araneidae> Now the question is: is this the right way to solve this problem (merging concurrent IO streams)?
12:04:32 <jbapple> Tomsik_: The C++ code was not very low level, though the polymorphism design is. (compiler copypasta) Nonetheless, .NET manages both type specialization and reasonable polymorphism, so it's not a complete tradeoff
12:04:34 <dons> dcoutts_: its not bad, these days
12:04:47 <monochrom> Yes.
12:04:53 <zygoloid> mmm, delicious copypasta
12:04:53 <dons> dcoutts_: as jbapple shows its better than java, and a bit worse than C++, within 1x (jbabble, right?)
12:04:58 <jbapple> jmcarthur: oh yes, it was quite bad. Are you the maintainer? I can send you a benchmark later today if you like.
12:05:18 <dcoutts_> dons: and the default Data.HashTable ought to be pure, with a separate impure variant
12:05:26 <Araneidae> I can extend this to  mergeL :: [IO a] -> [IO b] -> [IO (Either a b)]  but I don't know if all those MVars and forkIOs are the way to go.
12:05:48 <Araneidae> Chan?
12:05:51 * Araneidae goes hoogle
12:05:56 <monochrom> Control.Concurrent.Chan
12:06:00 <dcoutts_> dons: i.e. accumulate the hashtable all in one go, then freeze it to a pure lookup table/function
12:06:22 <monochrom> you need many forkIOs but you only need one MVar
12:06:42 <Araneidae> Ok, that makes sense: one MVar for the consumer, one forkIO per producer
12:07:25 <jbapple> A few days ago, after some benchmarks showed GHC to be competitive with (and sometimes faster than Java and OCaml), JDH claimed that hash table benchmarks were no longer very interesting. When I reminded him that he called them, "interesting" in April 2009, he claimed they are just 1/2 as interesting each year
12:07:33 <Araneidae> Well, that's encouraging: I think I have an inkling of something now :)
12:08:04 <dcoutts_> jbapple: so when did the Data.HashTable get rewritten?
12:08:58 <jbapple> dcoutts_: It's not worthless - it's still faster than IntSet and Set for some benchmarks
12:09:59 <Tomsik_> hash tables are a horrible thing
12:10:57 * dcoutts_ would also split the mutable HashTable into ST and IO versions
12:11:15 <jmcarthur> jbapple: not the maintainer, no
12:11:16 <dcoutts_> with the IO a trivial wrapper around the ST version
12:11:23 <jmcarthur> i just had higher hopes for it
12:11:23 <jbapple> dons: actually, I don't know anymore if GHC is faster than Java. I think we can all agree than inserting a bunch of Doubles and then lookup up one is probably not the most likely use case. I suspect the smartest HT benchmark I've run in the past few days is inserting strings and then looking each one up many times (not in a row). On that benchmark, Java, C++, and F# are all about tied on my machine, and Data.HashTable is 3x slower with
12:11:49 <jbapple> dcoutts_: How would you like the HT to be pure? ST? Tries?
12:11:51 * ddarius thinks we should just have a "mutable map" interface and people should use that.
12:12:06 <jbapple> dcoutts_ ok, I see, sorry, still catching up
12:12:09 <dcoutts_> jbapple: a pure version would have separate construction and lookup phases
12:12:24 <dcoutts_> jbapple: like the way we can construct a pure array
12:12:39 <ddarius> @hackage bloom-filter
12:12:40 <lambdabot> http://hackage.haskell.org/package/bloom-filter
12:12:57 <jbapple> dcoutts_: I don't know that Data.HashTable has been rewritten recently. Did I say something that implied that?
12:12:57 <dcoutts_> jbapple: of course if one needs to interleave inserts and lookups then one has to use a mutable version, e.g. in ST
12:13:19 <jmcarthur> i've been thinking about giving a HAT-trie library a go, but i haven't yet determined whether it would rely on mutation for efficiency. i need to scour down on the papers more closely
12:13:25 <monochrom> http://hackage.haskell.org/package/bloomfilter
12:13:31 <deech> Hi all, I am planning on undertaking a cross-platform command line tool using Haskell. I am comfortable that GHC works well on Windows, Linux and Mac, but what about Solaris?
12:13:57 <dcoutts_> jbapple: I assumed it would have had to be tweaked (beyond the recent IOArray GC fixes) to be competitive. I thought it uses a fairly simple scheme.
12:14:15 <dcoutts_> deech: works ok on Solaris
12:14:36 <deech> dcoutts_: But there are no binaries available, correct?
12:14:49 <dcoutts_> deech: we test it on Sparc Solaris, there are also binaries for x86 I think
12:15:10 <jbapple> dcoutts_: I would agree with "IO wraps ST" as a good strategy in general, but the recent PrimMonad problems may be evidence that we shouldn't put two chickens in one egg, or something. OTOH, code duplication is bad, OT3H, We wouldn't let Data.Set be Data.Map _ () just to be stubborn, would we? Maybe type families can make some of this less confusing, I dunno.
12:15:53 <deech> I don't see the binary listed on the GHC page. Are Solaris binaries hosted elsewhere?
12:16:10 <ddarius> There was a time when Data.Set was Data.Map k (), it didn't work out very well.
12:16:21 <Zao> Didn't that christian whatever guy use to build them?
12:16:51 <dcoutts_> jbapple: I don't know about PrimMonad problems, but unlike Data.Set vs .Map, there's no representation problem with ST vs IO
12:16:52 <jbapple> jmcarthur: Yes, it does. Most fast tries depend on flattening the trie out, which we can't really do because Arrays don't play well with others
12:17:20 <Zao> There doesn't seem to be any solaris builds since 6.12.1 though.
12:17:26 <jmcarthur> ah
12:18:15 <Zao> deech: x86 or sparc64?
12:18:22 <dcoutts_> jbapple: I presume the hash impls in java and .net do not use buckets containing linked lists. I don't know much about hashes but I was under the impression that the best implementations use some probing scheme and occasional resizing.
12:18:25 <jbapple> dcoutts_: Yes, Data.HT is pretty simple right now: HT sizes are powers of two, the table never shrinks, and collisions are dealt with by bucketing (sometimes called chaining). The chains are jsut usual lists, and there are no separate Map and Set implementations
12:19:47 <jbapple> dcoutts_: Because of the PrimMonad problems, there became a representation problem (as I understand it) :-) It might have been the other way around though - ST might have been fast when used through PrimMonad while IO was slow
12:19:57 <dcoutts_> jbapple: so my suggestion is that we nuke Data.HashTable from the base package and get someone who knows what they are doing (not me) to make some better implementations for the containers package
12:20:27 <dcoutts_> jbapple: any link to said PrimMonad problems?
12:20:53 <jmcarthur> is this why vector seems to be slower than uvector?
12:21:12 <jbapple> dcoutts_: Yes, I think chaining is not recommended. I have seen some claims that small fixed sized buckets are fast, though. Chaining is easier, but linear probing might have better cache locality
12:21:38 * BMeph nukes Data.HashTable from orbit - it's the only way to be sure...
12:21:42 <jbapple> especially if we can get unboxed HTs up and running
12:22:20 <jbapple> dcoutts_: I think the nuclear option is hasty -- they are still faster than other options like bytestring-trie and Data.Map
12:22:37 <jbapple> dcoutts_: let me find you a link to the PrimMonad probs
12:22:52 <jbapple> jmcarthur: I think this is part of it, yes.
12:22:58 <c_wraith> Isn't the next version of containers going to have a hash trie?
12:23:12 <jmcarthur> ooh, really?
12:23:15 <dcoutts_> jbapple: well, ok, deprecate Data.HashTable and add new Data.HashTable.* implementations to the containers package
12:23:40 <dcoutts_> c_wraith: it was in the recent paper, I don't know if it's going into the containers package
12:24:07 <jbapple> PrimMonad issues: http://hackage.haskell.org/trac/ghc/ticket/4184
12:24:55 <jbapple> c_wraith: Even if so, tries may be slower, and the ones on Hackage only handle Ints (I think)
12:25:18 <jbapple> phew, I'm all caught up now :-)
12:25:37 <c_wraith> jbapple, well, the hashtrie in the paper was tested decently well..  And it hashed to ints
12:26:09 <Paczesiowa> is there a canonical parsec tutorial (teaching how to build such a library, not use one)?
12:27:11 <monochrom> yes, there was a parser combinator paper: http://www.cs.nott.ac.uk/~gmh/bib.html#monparsing
12:27:25 <chrisdone> hmm. are our beginner channels busy?
12:27:25 <lambdabot> chrisdone: You have 1 new message. '/msg lambdabot @messages' to read it.
12:27:31 <chrisdone> s/busy/active
12:28:01 <monochrom> oh, and "monadic parsing in haskell", just above that one
12:28:02 <Saizan> Paczesiowa: there's a nice paper on how ReadP got designed
12:28:06 <chrisdone> I'm thinking of using this neat Freenode webchat to embed into tryhaskell.org and then launch it on reddit    ... "^_^
12:28:25 <arcatan> sounds like an excellent idea!
12:28:25 <jbapple> c_wraith: What I meant is that I think the one on hackage only hashes *from* Ints. I could be mistaken, though
12:28:36 <monochrom> oh god
12:28:47 <Tomsik_> Paczesiowa: preparing a new haskell course for this semester? :p
12:28:58 <c_wraith> jbapple: oh, this was in a paper on optimizing containers, not on hackage
12:29:13 <jbapple> c_wraith: In any case, I suspect there is little chance of a hash trie being faster than a hash table while a hash table is faste than a (non-hash) trie
12:29:14 <monochrom> but I guess it beats "hi google points me here for vb help"
12:29:32 <c_wraith> jbapple, read the paper
12:29:38 <jbapple> c_wraith: The paper mentioned that the package is now on hackage
12:29:53 <Botje> since vb.net was strongly influenced by haskell, i think we could pull it off :p
12:30:00 <chrisdone> monochrom: it could be a great haskell learning frenzy
12:30:05 <jbapple> c_wraith: I read the paper, but I also tested IntSets vs. Data.HashTable, and I found the latter to be much faster
12:30:15 <Paczesiowa> Tomsik_: there will be no haskell course this semester
12:30:19 <monochrom> I just have issues with advertising on reddit. They are trolls and/or morons.
12:30:42 <jmcarthur> chrisdone: what if somebody trolls from the web interface? would we have to ban the whole thing?
12:30:46 <Paczesiowa> monochrom: there's a difference between proggit and /r/haskell
12:31:00 <chrisdone> I believe the web interface provides unique ids per IP
12:31:11 <jmcarthur> oh then that sounds pretty reasonable
12:31:35 <chrisdone> (that's why mibbit was banned at one point, for not supporting banning a user)
12:32:05 <monochrom> the last webchat trolling shows that they troll from multiple IPs
12:32:20 <jmcarthur> you mean spamming?
12:32:34 <jmcarthur> i think spamming would require banning the web client
12:32:50 <jmcarthur> but the main problem i see with a link from proggit would be simple trolling
12:32:57 <monochrom> I mean trolling. My definition anyway.
12:34:25 <chrisdone> hmm
12:34:44 <monochrom> then again getting advertised on reddit is inevitable. if you don't advertise, someone else will. there is no shortage of over-enthuiastic reporters all over the world
12:35:41 <chrisdone> it was posted on reddit four months ago when i first made it despite me requesting it not be, it didn't have a proper interactive tutorial or anything then
12:35:43 <jmcarthur> i'd just try it and have my finger on the giant red "abort" button
12:35:45 <monochrom> (this is why "w00t I found another blog on number patterns in pi!" is possible on math reddit)
12:35:55 <Paczesiowa> if it wasn't for dons I wouldn't even know about reddit...
12:36:07 <chrisdone> jmcarthur: yeah, it's easy to remove from the site, or if i'm not here, ban the web client
12:37:13 <chrisdone> we could have a #tryhaskell channel, but it seems like the helpful contributors here wouldn't bother joining or wouldn't know about it. joining a dead channel would defeat the purpose
12:37:25 <jmcarthur> yeah
12:37:39 <jmcarthur> i say just go for it with #haskell and be prepared to pull it if necessary
12:37:59 <jmcarthur> or maybe compromise on changing it from #haskell to #tryhaskell if things get crappy
12:38:16 <chrisdone> yeah, sounds reasonable
12:38:46 <jmcarthur> i don't think i would submit to proggit initially
12:38:47 <chrisdone> the first time it was posted on reddit it had 3,000 hits in a day or two. gulp
12:38:51 <jmcarthur> try /r/haskell first
12:38:53 <monochrom> no, change it to #vb or something :)
12:39:23 <jmcarthur> chrisdone: does the client autoconnect or do you have to ask it to?
12:39:31 <chrisdone> jmcarthur: I'm scared someone would just post it to proggit immediately
12:39:48 <jmcarthur> maybe you could have the user put in a nick or something before connecting. that might rid us of some of the "just look and leave" people
12:39:49 <monochrom> don't be scared. it is a certainty.
12:39:51 <jmcarthur> prevent join spam
12:39:52 <chrisdone> jmcarthur: I think it asks you for a nickname and such
12:39:55 <jmcarthur> okay good
12:40:19 <jmcarthur> chrisdone: the question is *how* immediate that would be
12:40:28 <monochrom> I expect that my only surprise will be "oh it takes 1 year rather than 1 month"
12:40:31 <jmcarthur> if we get... twenty minutes or so first, then we can feel it out first
12:41:33 <jmcarthur> chrisdone: is it possible to put an identifying string in the user's host saying they are coming from tryhaskell?
12:41:41 <chrisdone> okay. I'll add it to the site. currently there are only around 80-100 hits a day, so that's a good tester
12:41:48 <chrisdone> ermm
12:42:00 <chrisdone> good question
12:42:02 <jmcarthur> the hostname string from the client, i mean
12:42:13 <jmcarthur> or whatever it's called
12:42:25 <monochrom> we do need a channel-size growth to 750 now :)
12:42:33 <jmcarthur> indeed :)
12:42:55 <dons> jbapple: btw, truncate => double2Int# in ghc
12:43:01 <dons> while floor has no such fast rule.
12:43:27 <jbapple> dons: Thanks for the tip
12:43:30 <jmcarthur> chrisdone: maybe it would be prudent to ask in #haskell-ops before doing this, just to see if there are any suggestions for making it more manageable
12:43:47 <FunctorSalad_> jmcarthur: no idea but I thought the 'host' is something that stays fixed
12:43:50 <chrisdone> jmcarthur: ok. maybe we could pick a date to try it
12:43:58 <FunctorSalad_> unless you edit their system configuration files
12:44:15 <FunctorSalad_> err and even those just define it locally AFAIK
12:44:34 <jbapple> Does anyone know how to quickly the the bit representation out of a floating point number?
12:44:34 <jmcarthur> FunctorSalad_: i just don't even know how the client works, whether it connects to the irc server from the user's machine or if it goes through some other server first or something
12:44:55 <Botje> wouldn't Binary do that?
12:45:20 <jbapple> Botje: I couldn't see how a few days ago. Let me try again
12:45:23 <monochrom> perhaps idoru measures mean-time-between-enter
12:45:26 <jmcarthur> Storable?
12:45:27 <dons> jbapple: hmm. unsafeCoerce# x :: Word64#
12:45:27 <zygoloid> jbapple: unsafeCoerce is the quick way
12:45:57 <jbapple> I guess it's as good as any
12:46:47 <jbapple> jmcarthur: I tried Storable, but it was really slow.
12:46:54 <dons> Prelude Unsafe.Coerce> unsafeCoerce (pi :: Double) :: Data.Word.Word64
12:46:54 <dons> 4614256656552045848
12:47:18 <dolio> I'd be wary about using the unsafeCoerce from Unsafe.Coerce.
12:47:20 <jmcarthur> ah
12:47:33 <zygoloid> dolio: why so?
12:47:34 <jmcarthur> unsafeCoerce should be pretty much free i think
12:47:34 <dolio> I've seen it do odd things.
12:48:00 <dons> import GHC.Prim (unsafeCoerce#)
12:48:00 <dons> unsafeCoerce :: a -> b
12:48:00 <dons> unsafeCoerce = unsafeCoerce#
12:48:10 <dolio> zygoloid: Because it isn't just coercing from one unboxed primitive type to another. It's casting from a boxed wrapper to another.
12:48:15 <dons> main2 =
12:48:15 <dons>   case $fFloatingDouble_pi
12:48:15 <dons>        `cast` (CoUnsafe Double Word64
12:48:15 <dons>                :: Double ~ Word64)
12:48:15 <dons>   of _ { W64# ww_aSj ->
12:48:17 <dons>   $wa17 ww_aSj
12:48:21 <Igloo> Note that the above coerces aren't safe in GHC
12:48:24 <int80_h> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27807#a27809
12:48:32 <Botje> we have a CoUnsafe now?!
12:48:46 <zygoloid> dolio: right. but they're both represented as a CONSTR_0_1 closure when forced...
12:48:51 <dolio> Not that the former is really safe, either.
12:49:05 <dons> Botje: conversion  == Co.
12:49:16 <jbapple> Igloo: So, is there a safe & fast way to get the bytes from a Double?
12:49:20 <dons> safer  would be to coerce the primops, wouldn't it?
12:49:25 <dons> primitive type.
12:49:38 <monochrom> heh CoUnsafe
12:49:46 <dons> the above looks dicey
12:49:54 <dons> i'd have preferred it unpacked the closure first
12:50:07 <Botje> int80_h: return . liftM looks wrong
12:50:59 <Botje> Number (read newdigit) is of type LispVal
12:51:07 <dons> main2 =
12:51:07 <dons>   $wa17
12:51:07 <dons>     (3.141592653589793
12:51:07 <dons>      `cast` (CoUnsafe Double# Word#
12:51:07 <dons>              :: Double# ~ Word#))
12:51:13 <Botje> you only have to figure out how to go from LispVal to Parser LispVal
12:51:19 <Igloo> see http://hackage.haskell.org/trac/ghc/ticket/2209 and http://hackage.haskell.org/trac/ghc/ticket/4092
12:52:01 <dons> wa17 is the W64# constructor  i think
12:52:43 <int80_h> Botje : thanks
12:52:49 <jbapple> Igloo: ok, thanks
12:54:18 <hpc> man, low-level haskell looks freaky
12:55:07 <monochrom> do you mean what dons pasted? that is not haskell.
12:55:52 <djahandarie> Haha CoUnsafe
12:56:02 <rafab> !rules
12:56:23 <djahandarie> There isn't a !rules command as far as I know...
12:56:27 <djahandarie> !rules
12:56:33 <hpc> @rules
12:56:33 <djahandarie> Nope
12:56:33 <lambdabot> Unknown command, try @list
12:56:42 <hh> @lsit
12:56:42 <lambdabot> Maybe you meant: gsite let list quit
12:56:46 <hh> @list
12:56:46 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
12:56:46 <rafab> Seems like there isn't :P
12:57:28 <djahandarie> rafab, if you have a question feel free to just ask
12:57:44 <rafab> djahandarie, thank you, I've one, quite simple I think
12:58:21 <rafab> For indentin, tabs or spaces? 4 or 8 spaces width? I'm not a programmer, I'm editing a config :x
12:58:44 <rafab> *indenting, sorry for my English
12:58:47 <djahandarie> The consensus is to use all spaces
12:58:57 <dolio> Are we talking about indenting Haskell?
12:59:06 <djahandarie> Oh
12:59:13 <djahandarie> Yeah, The consensus for Haskell is to use spaces
12:59:18 <rafab> dolio, yes
12:59:18 <monochrom> use spaces to avoid hearing a complicated answer.
12:59:22 <dolio> Then yes, spaces.
12:59:24 <rafab> djahandarie, thank you
12:59:38 <rafab> 4 spaces, 8 spaecs or doesn't matter?
12:59:45 <hpc> doesn't matte
12:59:46 <dolio> Whatever looks nice to you.
12:59:55 <hpc> 8 spaces will cooperate with tabs
13:00:00 <cozachk> i like 1 space per indent level 
13:00:00 <hpc> i generally use 2
13:00:13 <rafab> I see
13:00:25 <dolio> Someone on the haskell reddit was adamantly defending use of tabs for indentation...
13:00:35 <jbapple> I feel kind of silly asking, but I'm having trouble peeking & poking --Foreign.Ptr has no way of getting a Ptr t from a t. Should I use Foreign.ForeignPtr?
13:00:52 <rafab> dolio, as long the compiler doesn't complain I'm happy :P
13:00:57 <jbapple> or maybe StablePtr?
13:01:07 <rafab> Thank you all, have a really nice day guys!
13:01:08 <monochrom> I understand defending tabs, but it's a losing cause.
13:01:11 <illissius> i think StablePtr is what you want
13:01:14 <dolio> But then way down the thread, it became clear to me that given his definition of "indentation", my haskell code contains almost no indentation.
13:01:41 <dolio> It's all "alignment" or something, so I have no opportunities to use tabs.
13:02:17 <dolio> And the one place I regularly indent, and thus would use tabs, the tabs would be set to one space.
13:02:24 <jbapple> illissius: Is StablePtr slower than Ptr?
13:02:51 <msieradzki> tabs are easy to use in vim :)
13:02:59 <illissius> jbapple: what do you need the Ptr for?
13:03:25 <msieradzki> is there 1 blessed haskell indent for vim?
13:03:34 <monochrom> @hoogle Ptr
13:03:35 <lambdabot> module Foreign.Ptr
13:03:35 <lambdabot> Foreign.Ptr data Ptr a
13:03:35 <lambdabot> Foreign.Ptr ptrToIntPtr :: Ptr a -> IntPtr
13:03:44 <illissius> you need StablePtr if you want to pass things to C code, because with a plain Ptr the GC could move things around and invalidate it
13:03:45 <jbapple> I need to get a Double to a Word64, and it is the suggested method to peek and poke: http://hackage.haskell.org/trac/ghc/ticket/4092
13:03:54 <monochrom> @hoogle b -> Ptr a
13:03:55 <lambdabot> Foreign.Ptr castFunPtrToPtr :: FunPtr a -> Ptr b
13:03:55 <lambdabot> Foreign.Ptr castPtr :: Ptr a -> Ptr b
13:03:55 <lambdabot> Unsafe.Coerce unsafeCoerce :: a -> b
13:04:31 <illissius> oh, hmm
13:05:23 <monochrom> jbapple: Foreign.Marshal.Alloc is where and how you obtain Ptr.
13:05:37 <jbapple> monochrom: thanks!
13:05:48 <illissius> :t \d -> alloca $ \p -> poke p d; peek (castPtr d)
13:05:49 <lambdabot> parse error on input `;'
13:05:59 <msieradzki> do?
13:06:04 <illissius> :t \d -> alloca $ \p ->  poke p d >> peek (castPtr d)
13:06:04 <lambdabot> Not in scope: `alloca'
13:06:05 <lambdabot> Not in scope: `poke'
13:06:05 <lambdabot> Not in scope: `peek'
13:06:09 <msieradzki> :>
13:06:09 <illissius> :meh
13:06:20 <jmcarthur> @pl \d -> alloca $ \p -> poke p d >> peek (castPtr d)
13:06:20 <lambdabot> alloca . ap (flip . ((>>) .) . flip poke) (peek . castPtr)
13:06:27 <jmcarthur> yuck
13:07:11 <jbapple> this is still pretty confusing
13:07:26 <monochrom> it is complicated :)
13:07:33 <jbapple> Foreign.Marshall.Alloc lets me malloc and free.
13:07:38 <jbapple> @hoogle peek
13:07:38 <lambdabot> Foreign.Storable peek :: Storable a => Ptr a -> IO a
13:07:39 <lambdabot> Foreign.Marshal.Array peekArray :: Storable a => Int -> Ptr a -> IO [a]
13:07:39 <lambdabot> Foreign.Marshal.Array peekArray0 :: (Storable a, Eq a) => a -> Ptr a -> IO [a]
13:07:58 <illissius> jbapple: alloca uses type inferencing magic to figure out what type you need, allocates enough memory for it, and returns a pointer to it
13:08:09 <monochrom> but what illissius says. allocate, poke, cast, peek. (deallocate is implicit if you use a nice function to allocate)
13:08:09 <illissius> or rather, calls the function you pass to it with the pointer
13:08:21 <jbapple> Which peek should I use?
13:09:06 <jbapple> monochrom: what is a "nice function"?
13:09:06 <illissius> jbapple: double_to_w64 d = alloca $ \p -> poke p d >> peek (castPtr d)
13:09:06 <jmcarthur> Foreign.Storable
13:09:28 <monochrom> such as alloca. it deallocates for you
13:09:49 <illissius> I'm not sure if alloca allocates on the stack but either way it's allegedly much faster than malloc
13:09:53 <jbapple> @hoogle castPtr
13:09:53 <lambdabot> Foreign.Ptr castPtr :: Ptr a -> Ptr b
13:09:54 <lambdabot> Foreign.Ptr castPtrToFunPtr :: Ptr a -> FunPtr b
13:09:54 <lambdabot> Foreign.StablePtr castPtrToStablePtr :: Ptr () -> StablePtr a
13:10:25 <jbapple> ok, so I need Foriegn.Marshal.Alloc, Foreign.Storable, and Foreign.Ptr
13:10:35 <illissius> right
13:10:42 <jmcarthur> storableCoerce :: (Storable a, Storable b) => a -> IO b; storableCoerce a = alloca $ \p -> poke p a >> peek (castPtr p)
13:10:49 <jbapple> ok, I'll try that. Thanks for the help everyone
13:11:14 <illissius> yw -- I hope it actually works heh
13:12:12 <illissius> jmcarthur: ideally you'd also have some kind of assert that sizeOf b <= sizeOf a
13:12:42 <jmcarthur> illissius: yeah. having that would even make it pure if you return a Maybe
13:12:56 <jmcarthur> well
13:12:58 <jmcarthur> maybe not actually
13:13:15 <jmcarthur> if different internal representations of a value are allowed to have different Storable representation then it would not be pure
13:13:19 <jmcarthur> so nevermind
13:17:39 <jbapple> Well, it did *something*
13:18:36 <jmcarthur> how safe is the "unsafePerformIO hack" really (the one the gives you top-level mutable references)?
13:19:15 <jmcarthur> i have been using it a lot lately to help me wrap an impure library
13:20:04 * FunctorSalad remembers something about 'associative commutative central io'
13:20:13 <FunctorSalad> but just a proposal
13:20:56 <FunctorSalad> jmcarthur: a monad won't do?
13:21:24 <jmcarthur> i'm trying to expose a pure API
13:21:26 <FunctorSalad> which makes sure initialization is done if you "execute" it down to IO
13:21:28 <FunctorSalad> ah
13:21:46 <jmcarthur> i'm not concerned about the ordering of initialization
13:22:00 <jmcarthur> more about whether NOINLINE guarantees that it won't be inlined at all
13:22:16 <jmcarthur> or if it's just a hint
13:23:05 * FunctorSalad doesn't know
13:23:36 <c_wraith> I was reading through this part of the ghc manual in the last couple days
13:23:38 <mwc> Is it portable to use newtype'd types in foreign declarations?
13:23:42 <c_wraith> NOINLINE is a strict statement
13:23:51 <jmcarthur> c_wraith: so i can rely on it?
13:23:57 <c_wraith> INLINE may be ignore, but NOINLINE is always obeyed
13:24:02 <jmcarthur> awesome
13:24:48 <mwc> ie, if I have newtype Foo = Foo { unFoo :: CInt }, can that be portably used when importing foreign functions? foreign import "doFoo" cDoFoo :: Foo -> IO () ?
13:24:53 <jmcarthur> FunctorSalad: is that proposal you mentioned the one that would allow you to use something like do notation at the top level?
13:25:00 <illissius> jmcarthur: i remember a discussion here recently, iirc there's a potential race condition the first time the top-level thunk(?) is evaluated if multiple threads try to do it at the same time
13:25:04 <mwc> The FFI spec is mum on if newtypes are allowed
13:25:06 <illissius> but dunno the details
13:25:13 <FunctorSalad> jmcarthur: hmm the manual entry is very short :(
13:25:15 <jmcarthur> illissius: oh that makes sense
13:25:25 <FunctorSalad> c_wraith: oh? where?
13:25:31 <FunctorSalad> I looked up NOINLINE in the index
13:25:40 <c_wraith> I was looking at the section about optimization phases
13:26:24 <FunctorSalad> jmcarthur: apparently, I didn't read through it, but associative & commutative seem to be the properties needed so you don't have to define an init order across all the modules
13:26:33 <FunctorSalad> which I imagine would be a huge mess
13:26:35 <jmcarthur> makes sense
13:26:55 <FunctorSalad> though if 'central' is in the algebra sense that'd imply 'commutative'
13:27:09 <jmcarthur> as i am just creating references at the top level, i'm pretty sure they are commutative
13:27:43 <jmcarthur> MVars, to be exact
13:27:54 <FunctorSalad> (or actually, elements can't be commutative in either case, they could commute with each other though... I don't see how an initialization could actually be *central*)
13:27:58 <jmcarthur> it would indeed suck to end up with the race condition that illissius mentioned
13:28:05 <c_wraith> are you doing unsafePerformIOs at the top level?
13:28:09 <jmcarthur> yes
13:28:13 <jmcarthur> with NOINLINE
13:28:15 <c_wraith> yeah, there's a race condition
13:28:27 <jmcarthur> dang
13:28:31 <FunctorSalad> (except if you demand that we don't move statements around in a way that breaks the lexical scope, then newMVar looks like it should be central)
13:28:45 <c_wraith> I really wish ghc had a mechanism to allow top-level IO actions in a race-free manner
13:28:59 <c_wraith> err, top-level IO execution
13:29:02 <FunctorSalad> (`central' as in `commutes with every IO action' (given that we don't break scope))
13:29:06 <jmcarthur> maybe i could just require an "init" function to be called in the top of main that forces all the global references
13:29:15 <c_wraith> But I can see people abusing it horribly
13:29:24 <c_wraith> jmcarthur, several libraries have a "withXDo" kind of function
13:29:28 <c_wraith> You could use that.
13:29:28 <jmcarthur> yeah
13:29:34 <c_wraith> err, that pattern, I mean
13:29:37 <jmcarthur> i guess i have to
13:29:47 <sshc> I've just started teaching myself Arrows.  They seem quite handy.
13:29:49 <c_wraith> It's the only really safe and portable way I've seen.
13:30:01 <jmcarthur> c_wraith++
13:30:11 <FunctorSalad> c_wraith: it's unsafe if we're thinking of the same thing
13:30:14 <sshc> I probably could have used them sometimes when I used the State monad, but where it probably wasn't appropriate
13:30:37 <FunctorSalad> withMagicTokenDo (\mt -> return mt)
13:30:41 <FunctorSalad> will export the magic token
13:30:52 <FunctorSalad> I think you need something like ST does
13:30:56 <c_wraith> Actually, I was thinking more like the network library
13:31:03 <c_wraith> and "withSocketsDo"
13:31:10 <c_wraith> Which doesn't have a high-level token.
13:31:27 <FunctorSalad> (this unsafeness applies only if withMagicTokenDo has type (Token -> IO a) -> IO a)
13:31:28 <c_wraith> It's just a wrapper for doing init/cleanup for the sockets library to work properly
13:31:29 <jmcarthur> FunctorSalad: i'm thinking withXDo m = mapM_ evaluate allGlobalReferences >> m
13:31:42 <FunctorSalad> c_wraith: hmm ok
13:32:09 <jmcarthur> the difference is that it ends up that i'm requiring this initialization to use otherwise pure functions
13:32:19 <jmcarthur> to be pendantic i should put them in IO :(
13:32:22 <jmcarthur> *pedantic
13:32:27 <FunctorSalad> jmcarthur: hmm I thought the user actually has to handle the refs
13:32:41 <FunctorSalad> otherwise it'd work like you and c_wraith said I guess
13:32:53 <jmcarthur> FunctorSalad: no, they are internally used only
13:33:09 <FunctorSalad> (handle them directly or hiddenly by the pure interface, I mean that "m" would have to take them as args)
13:33:12 <int80_h> eee
13:33:20 <jmcarthur> hmm
13:33:24 <c_wraith> There really is some need for a mechanism to safely execute top-level IO actions...  But it also seems really prone to abuse.
13:33:31 <BMeph> "affine central", so definitely an algebraic referrence.
13:33:51 <tamiko>  Hi folks. I wonder what is a sane way to lift doesDirectoryExist :: FilePath -> IO Bool into partition :: (FilePath -> Bool) -> [FilePath] -> ([FilePath],[FilePath]) .
13:33:52 <FunctorSalad> BMeph: ahhh thanks for fixing my malabbreviation ;)
13:33:57 <jmcarthur> i really don't want to pass this stuff around as a token. that would defeat some of the purpose of making it pure
13:34:05 <Philippa> c_wraith: weeell, what you really need to do it right is first-class modules
13:34:06 <FunctorSalad> which 'affine' meaning is it?
13:34:12 <Philippa> then you just have a module-building computation
13:34:21 <Philippa> oh, and a good way of passing them implicitly
13:34:44 <BMeph> That'd be a good name for an algrabraic SIG...
13:35:33 <BMeph> :t filterM
13:35:35 <lambdabot> forall a (m :: * -> *). (Monad m) => (a -> m Bool) -> [a] -> m [a]
13:35:39 <FunctorSalad> as I understand it withMagicToken *can* be made safe with the ST higher-rank trick
13:35:54 <tamiko> BMeph: ic. Thank you!
13:35:59 <FunctorSalad> not that I disagree that it'd mess up the pure interface
13:36:07 <Philippa> I'm coming to this without context, but if withMagicToken is what I think it is then yes
13:36:21 <Philippa> you don't actually need a monad to tie it to
13:36:29 <hpc> :t splitM
13:36:30 <lambdabot> Not in scope: `splitM'
13:36:33 <hpc> :t split
13:36:34 <lambdabot> forall g. (RandomGen g) => g -> (g, g)
13:36:41 <Philippa> you just need a function with the forall in the right place
13:37:03 <BMeph> tamiko: Eh? NO, I'd suggest looking at filterM in Control.Monad, and use it as an example to write your own "partitionM". :)
13:37:06 <FunctorSalad> Philippa: actually I introduced that name without knowing exactly what jmcarthur is doing too :) but it'd contain resource handles acquired during initialization of the foreign library and things like that, I think
13:37:30 <FunctorSalad> so you don't want these leaking outside the argument to withTokenDo
13:37:44 <FunctorSalad> (if you want to be able to close them after the argument is run)
13:38:08 <tamiko> BMeph: Yes, I thought so.
13:38:42 <BMeph> tamiko: Okay, good. As long as I'm not *knowingly* misleading you, I'm happy. :)
13:38:51 <illissius> FunctorSalad, though, would anyone ever end up doing that (\mt -> return mt) by accident?
13:38:52 <c_wraith> There are some provisos, though.  I was looking at a withConnection for hdbc that used rank-2 types to prevent the connection from leaking.  However, since the connection allows creation of a Statement, which is just as dangerous, preventing the connections from leaking didn't really help.
13:38:57 <tamiko> BMeph: I just had a blackout for a minute, not thinking about the monad equivalents of filter, etc.
13:39:08 <tamiko> *monadic
13:39:19 <illissius> and the question is whether you want to catch accidental errors, or make even intentional sabotage impossible, and the usability tradeoff between the two
13:39:59 <FunctorSalad> illissius: probably not the right level for protecting against sabotage, there's always unsafeCoerce
13:40:04 <FunctorSalad> illissius: I meant accidents
13:40:41 <FunctorSalad> illissius: I consider it unlikely too as long as the basic pattern is known
13:41:11 <jmcarthur> i think i'm just going to live with the ugliness of withXDo that initializes stuff that is implicitly used in pure functions
13:43:20 <ezyang> Is there a module that gives me the functionality of `which`? 
13:43:28 <jmcarthur> which?
13:43:37 <ezyang> `which echo` => /bin/echo 
13:43:40 <jmcarthur> oh
13:43:54 <jmcarthur> System.Process can give you that :)
13:44:23 <jmcarthur> i don't know of anything that provides that for you without calling out to another process though
13:45:01 <ezyang> it would be pretty simple to implement, but I don't want to reimplement stuff. 
13:51:51 <ezyang> Bah, there's no findM :: (a -> m Bool) -> [a] -> m (Maybe a) 
13:52:59 <msieradzki> Is Data.Vector in any way better than lists? I'm asking because there is some suggestion that it supports stream fusion better/at all
13:53:25 <Paczesiowa> ezyang: it's googlable
13:53:49 <ezyang> Paczesiowa: ? 
13:54:16 <Paczesiowa> ezyang: wait, I meant partitionM, not findM, sorry
13:54:35 <notabel> ezyang: what exactly are you trying to do?  Data.Foldable has 	find  :: Foldable t => (a -> Bool) -> t a -> Maybe a
13:54:49 <ezyang> notabel: I'm implementing `which` in Haskell. 
13:55:04 <ezyang> I have a list of candidate paths, and I want to return the first one that exist. Sounds like a job for find. 
13:55:10 <FunctorSalad> illissius: maybe "do { r <- newEmptyMVar; withTokenDo (\t -> .... >> putMVar r t >> ...) }" is a more obscure way to accidentally export it (and one that isn't eliminated by fixing the type of withTokenDo to (Token -> IO ()) -> IO ())
13:55:27 <jmcarthur> msieradzki: it's better for certain things, sure
13:56:27 <FunctorSalad> ezyang: readProcess "which" argz ""
13:56:43 <ezyang> It's gotta work on Windows :-) 
13:57:38 <FunctorSalad> readProcess "bash" (["-ic","type -a \"$@\"","--"]++args) ""
13:57:58 <FunctorSalad> -- get aliases and shell functions defined in an interactive shell session, too ;)
13:58:01 <zygoloid> @type let findM f = foldM t Nothing where t Nothing a = do { b <- f a; return $ if b then (Just a) else Nothing }; t a _ = return a in findM
13:58:02 <lambdabot> forall a (m :: * -> *). (Monad m) => (a -> m Bool) -> [a] -> m (Maybe a)
13:58:03 <ezyang> dons lets me know that findExecutable exists :o) 
13:58:26 <FunctorSalad> ezyang: ah, I inferred linux-only from 'which' ;)
13:58:37 <zygoloid> > let findM f = foldM t Nothing where t Nothing a = do { b <- f a; return $ if b then (Just a) else Nothing }; t a _ = return a in findM (const [False,True]) [1,2,3]
13:58:38 <lambdabot>   [Nothing,Just 3,Just 2,Just 1]
13:58:57 <FunctorSalad> ezyang: grab the $PATH and glob it if all else fails
13:59:06 <FunctorSalad> (we do have a portable glob?)
13:59:28 <FunctorSalad> ah, or 'which' doesn't even need glob, it has to match exactly
13:59:59 <Trevion> How do you determine what's "executable" in a platform-independent way?
14:01:02 <ezyang> @src findExecutable 
14:01:02 <lambdabot> Source not found. Are you on drugs?
14:01:17 <ezyang> @src System.Directory.findExecutable 
14:01:17 <lambdabot> Source not found. Sorry.
14:01:22 <ezyang> blah blah blah 
14:04:02 <Trevion> Meh.. the implementation of findExecutable ignores document associations on Windows.
14:10:06 <Paczesiowa> are there any languages with implicit arguments (dynamic scoping with static types) besides ghc?
14:10:20 <Trevion> Scala
14:10:44 <Hunner> Languages that which when brought up implicitly elicit an argument over its merits? :P
14:10:48 <jmcarthur> agda
14:12:05 <Paczesiowa> Trevion: does scala work like ghc? iirc implicits in scala are for type conversions
14:13:36 <arcatan> hmm, what are implicit arguments?
14:14:25 <Paczesiowa> http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.9849
14:15:33 <Trevion> Paczesiowa: http://www.scala-lang.org/node/114 suggests you can use them just like in GHC, although they're commonly used for conversions and type-class-like patterns
14:15:47 <Paczesiowa> Trevion: from this http://www.scala-lang.org/node/114 it seems that it dispatches values based on types
14:16:53 <Paczesiowa> Trevion: hmm, but those type definitions are statically scoped, so you can awkwardly use it like that
14:17:02 <Paczesiowa> Trevion: thanks!
14:17:22 <arcatan> oh, interesting
14:22:42 <Trevion> Paczesiowa: yeah, they've mixed impliict variables and an approximation of the Haskell instance selection algorithm into a single keyword.
14:25:05 <FunctorSalad> Paczesiowa: curious what you're up to, are you proposing that dynamic scope is not so bad after all with a good static type system?
14:25:36 <pchiusano> Paczesiowa: I use scala a lot... could answer questions about implicits
14:26:00 <Paczesiowa> pchiusano: I need questions first:)
14:26:07 <pchiusano> you can use them to mimic typeclasses (just take an implicit module) and for other stuff
14:26:40 <Paczesiowa> pchiusano: I need any impure language with implicit arguments
14:26:52 <FunctorSalad> jmcarthur: heh, incidentally, wouldn't they be an option for you?
14:26:57 <FunctorSalad> random thought
14:26:57 <ddarius> Dynamic scoping isn't that bad as long as its not the default/primary/implict.
14:27:02 <pchiusano> Paczesiowa: nice thing is that modules are first class in scala, so you don't have to make the (somewhat arbitrary) decision about whether to make something a data type or a typeclass, ala haskell
14:27:12 <Ziphilt> i can't seem to find a way to print Ints or turn them into Strings; surely there is a way?
14:27:25 <Paczesiowa> > show (2::Int)
14:27:26 <lambdabot>   "2"
14:27:27 <monochrom> > show (1 + 1)
14:27:28 <lambdabot>   "2"
14:27:30 <ddarius> print 3
14:27:36 <FunctorSalad> (put a record of IORefs into an implicit param and forget about it)
14:27:36 <Ziphilt> oh
14:27:38 <Ziphilt> is it show
14:27:42 * Ziphilt facepalms
14:27:49 <ddarius> :t print 3
14:27:51 <lambdabot> IO ()
14:28:04 * Heffalump likes implicit parameters
14:28:10 <Paczesiowa> FunctorSalad: have you seen implicit params in ghc? contexts keep track of IORefs
14:28:26 <FunctorSalad> ddarius: agreed @ 'default'
14:28:26 <benmachine> implicit params are kind of silly
14:28:57 <FunctorSalad> Paczesiowa: I just thought of that as a solution for the global-iorefs issue jmcarthur had
14:29:07 <Ziphilt> thanks all you who answered immediately with the same answer
14:29:16 <FunctorSalad> it'd clutter up all your type signatures, but it'd be propagated automatically
14:29:27 <Paczesiowa> FunctorSalad: that's what I want too
14:30:10 <Paczesiowa> I have a suspicion that we all use use implicit arguments all the time. explicitly.
14:30:52 <zygoloid> Paczesiowa: type class instances?
14:31:19 <jmcarthur> FunctorSalad: that had occurred to me when Philippa mentioned first class modules
14:31:25 <FunctorSalad> I guess you'd have a "execute" function of type "(?r::MyRefs => IO a) -> IO a" (or the rank2-trick if you want to make it impossible to leak the refs)
14:31:36 <jmcarthur> FunctorSalad: i didn't think it through though. was planning to when i get home later
14:31:38 <Paczesiowa> zygoloid: something like that
14:32:26 <jmcarthur> i'd still hate to clutter the types with implementation details like that though
14:32:34 <jmcarthur> it would be different if they weren't implementation
14:32:59 <FunctorSalad> Paczesiowa: isn't it like lexical scope except you can put stuff at the toplevel, as long as you don't pull anything tricky?
14:33:32 <FunctorSalad> (like reentry of a dynamic binder... but maybe that's just equivalent to something in lexical scope too?)
14:34:30 <FunctorSalad> but I mean in the tame case where you'll just enter the dynamic binder _once_ during startup
14:35:15 <Paczesiowa> FunctorSalad: no idea, I can't grasp it atm, but I have a feeling that it's a deep rabbit hole with red pills
14:35:26 <FunctorSalad> (haven't tried anything more complicated personally)
14:35:49 <mauke> preflex: seen Cale
14:35:49 <preflex>  Cale was last seen on #haskell 11 hours, 19 minutes and 51 seconds ago, saying: Data.NumInstances
14:36:07 <FunctorSalad> Paczesiowa: yes I'm likely to be overlooking the complications if you don't have this simple case
14:36:32 <ddarius> Hmm, greasy pattie melt or less greasy sub?
14:36:34 <FunctorSalad> (and are just taking a lexical scope program and flattening all the indentation away ;))
14:37:43 <FunctorSalad> (so you can :type things independently and so on)
14:37:46 <Paczesiowa> Trevion: how are those things implicit, if you must provide type sigs for every method? isn't that just like adding the extra arg?
14:38:16 <Paczesiowa> FunctorSalad: flattening indentation?
14:39:06 <ddarius> Paczesiowa: You don't have to pass the argument at every call.
14:39:30 <FunctorSalad> Paczesiowa: I was just trying to say that I think the safest use of IPs would be to take a lexical scope program without IPs, uproot some local bindings to the toplevel, and make the now-free variables IPs instead
14:39:50 <Paczesiowa> ddarius: so it's half implicit
14:39:57 <FunctorSalad> or can that go wrong already? ;)
14:41:03 <Paczesiowa> FunctorSalad: but why? there are plenty of "x", if you lift them to the top level, they would have to share the same value (and type)
14:41:29 <FunctorSalad> ('safe' not in the 'doesn't break typesystem' sense, just in the 'no surprises for someone not used to lex. scope' sense)
14:42:10 <FunctorSalad> Paczesiowa: you'd have to uniquify names first
14:42:26 <FunctorSalad> names are meaningless for bound variables after all
14:42:38 <FunctorSalad> (but not on the toplevel)
14:42:58 <FunctorSalad> Paczesiowa: TH for example already does this for you :)
14:43:06 <FunctorSalad> you'll get names like x2183983 for your local x
14:43:19 <FunctorSalad> or so I remember
14:43:21 <Paczesiowa> I don't want any x2183983 on my toplevel
14:43:45 <FunctorSalad> :) I'd only put stuff to the toplevel if it is meaningful on its own
14:44:11 <FunctorSalad> (but still needs context)
14:45:19 <Paczesiowa> ok, thanks for suggestions. time to get some sleep. bye
14:47:53 <FunctorSalad> good night
14:48:29 <ezyang> sleep tight 
14:56:36 <FunctorSalad> I'll take a break from all my chattering too ;) cya
14:56:49 <arcatan> don't let the bugs bite
14:57:29 <FunctorSalad> :)
14:59:24 <ezyang> What does  <- in a guard do? 
14:59:38 <zygoloid> ezyang: that's a pattern guard
14:59:51 <ezyang> that's... odd. 
14:59:53 <zygoloid> ezyang: if the pattern matches it binds it, otherwise it skips to the next guard
15:00:46 <zygoloid> > let foo k | Just v <- lookup k [("a",1), ("b",2)] = v * 3 in foo "a"
15:00:47 <lambdabot>   3
15:01:07 <zygoloid> > let foo k | Just v <- lookup k [("a",1), ("b",2)] = v * 3  | otherwise = 0 in foo "c"
15:01:08 <lambdabot>   0
15:01:26 * aavogt is rather fond of that extension
15:02:34 <zygoloid> it's not an extension any more, it's official haskell now
15:03:06 <FunctorSalad> the slightly odd part is that it converts what would crash the program in other patterns to a mere falsity, maybe, ezyang 
15:03:26 <FunctorSalad> hmm or actually it wouldn't crash, just call 'fail' in do blocks :)
15:04:05 <FunctorSalad> ("odd" at least if you expect the RHS of a pattern to be primarily a truth value)
15:04:14 <aavogt> it moves on to the next equation
15:04:19 <ezyang> it strikes of view patterns 
15:04:33 <beutdeuce> i have a question about the Parsec, what does the (>>) signify in parse(eol >> eof) "" "\n" ?
15:04:42 <mauke> sequencing
15:04:43 <zygoloid> do { Just v <- lookup k ...; return $ v * 3 } <|> do { return 0 }
15:04:49 <beutdeuce> space between parse and the parens
15:04:52 <zygoloid> ezyang: you know about view patterns but not pattern guards? ;-)
15:05:09 <arcatan> zygoloid: that was the order i learned about them, too!
15:05:26 <zygoloid> huh. view patterns are a lot newer. maybe that's why :)
15:05:35 <aavogt> zygoloid: view patterns aren't that new anymore...
15:06:08 <aavogt> (in terms of when they were added to ghc)
15:06:09 <ezyang> I only know view patterns because Anders used them in static-cat :-) 
15:07:26 <zygoloid> aavogt: they were introduced in 6.10. that's pretty new.
15:07:58 <FunctorSalad> aren't pattern guards just a warning without the extension, even?
15:08:13 <aavogt> eh, 2 years may be longer than the average person here has known haskell
15:08:30 <zygoloid> FunctorSalad: yeah.
15:08:41 <Cale_> Views are a good deal older, but I don't know if they were ever implemented
15:08:49 <zygoloid> aavogt: they've been involved in haskell less long than i have. that's new in my book :)
15:09:49 <Trevion> Cale_:  I don't think views have ever been implemented.  Not only have they been around longer, tho, they're actually in <1.0 version of the Haskell report.
15:10:00 <Trevion> versions*
15:10:04 <FunctorSalad> views?
15:10:48 <Trevion> FunctorSalad: "Views: a way for pattern matching to cohabit with data abstraction", from http://homepages.inf.ed.ac.uk/wadler/topics/language-design.html\
15:11:12 <FunctorSalad> Trevion: sounds like view patterns :) it is the same with a small diff?
15:11:43 <Cale_> FunctorSalad: yeah. They let you define additional data constructors along with how to convert back and forth to the real ones when pattern matching 
15:12:24 <FunctorSalad> how was the direction that isn't view patterns used?
15:12:28 <Cale_> They differ from view patterns in that the syntax is a bit more transparent
15:12:44 <FunctorSalad> sounds good
15:12:57 <FunctorSalad> (if it doesn't cause parsing complications)
15:13:25 <aavogt> that would make predicting performance even more difficult
15:14:06 <Cale_> I liked the idea myself, but I think some people thought they complicated reading code with an eye to performance, yeah
15:14:29 <jmcarthur> so views would allow you to implicitly convert a value to another type when you pattern match on it?
15:14:43 <jmcarthur> that's what i would find ideal, personally
15:15:06 <aavogt> the conversion looks explicit to me
15:15:11 <jmcarthur> with some sort of a multiparameter View type class maybe
15:15:18 <illissius> there's a proposal to have a 'class View a b where view :: a -> b' and if they compiler sees 'foo (-> Foo)' it hooks into that view function automatically; a taken-further version of the proposal would omit even the ->, and be (afaict?) pretty similar to full views, but has other other complications
15:15:28 <FunctorSalad> aavogt: it could be made less sneaky with some new prefix or postfix character
15:15:30 <Trevion> FunctorSalad: Views are two-way, and don't require you to name the constructors and destructors.  View pattens are one-way, and require you to name destructors.
15:15:32 <illissius> heh. serendipity
15:15:34 <jmcarthur> aavogt: i mean as opposed to View Patterns
15:15:46 <FunctorSalad> (for the pseudo-ctor name)
15:15:51 <jmcarthur> Trevion: oh, two way, i like it even more :)
15:15:53 <Trevion> So other than everything, they're the same.
15:16:05 <illissius> see also http://hackage.haskell.org/trac/ghc/ticket/3583
15:16:22 <jmcarthur> actually, two-ways seems less useful if you consider smart constructors
15:16:37 <FunctorSalad> Trevion: not needing names is nice too
15:16:45 <Saizan> i thought i could reproduce Athas problem but that's not the case, now i won't know if i've fixed it :\
15:16:54 <Trevion> Also avoids the <- -><- syntax warts.
15:17:07 <Cale_> sort (Least x xs) = x : sort xs
15:17:11 <jmcarthur> as if i wasn't sold already, anonymous view types sounds even better
15:17:21 <FunctorSalad> I still don't see how the other way is a pattern at all
15:17:27 <jmcarthur> Cale_: lol
15:17:36 <FunctorSalad> you construct values of the real types in *expression* context, so it'd be just a function...
15:17:46 <FunctorSalad> was it implicit in expr context too?
15:17:51 <FunctorSalad> (the un-view)
15:18:59 <Trevion> FunctorSalad: View constructors and destructors are both implicit.
15:19:14 <jmcarthur> Cale_: that is very strange. it kind of makes me think of passing a pointer to a C function to get its result, for some reason
15:19:25 <FunctorSalad> (e.g. if [a] had a view to a 'FirstTwo a' type, the other direction would simply be two make a list given head, second and rest)
15:19:35 <FunctorSalad> (no patterns involved)
15:19:49 <Cale_> Miranda also had an implemented feature called laws which allowed definition of datatypes with implicit structural transformations
15:19:51 <FunctorSalad> so the other direction would be just an uppercase ordinary function
15:20:11 <jmcarthur> Cale_: huh, neat
15:20:13 <Cale_> Dinner. bbiab
15:20:19 <jmcarthur> runtime rewrite rules?
15:20:26 <jmcarthur> on structures
15:20:34 <jmcarthur> not quite the same i guess
15:20:42 <illissius> I'm not sure about making implicit view patterns look the same as normal patterns... could be confusing at first to figure out 'wtf is this'
15:21:02 <FunctorSalad> illissius: maybe an extra character?
15:21:07 <FunctorSalad> or UPPERCASE :D
15:21:08 <jmcarthur> illissius: if it requires a type signature then that can clear things up a lot
15:21:35 <Trevion> Cale_: laws are fantastic.  I hadn't known about them.
15:21:39 <illissius> have to realize "oh, it's not pattern matching on the actual constructors, but using a view pattern..." and then look up the definition of both the view type and the instance for View
15:21:45 <jmcarthur> i don't think that would be required though unless you could overload the constructors
15:21:56 <illissius> otoh, it would def make refactoring easier
15:21:58 <Trevion> I wonder if those were also in Haskell < 1.0
15:22:03 <FunctorSalad> (obviously UPPERCASE isn't disjoint from plain ctor names, but we are just looking for a visual hint anyway)
15:22:08 <jmcarthur> i don't think it would be that confusing you just use it wisely
15:22:31 <jmcarthur> cale's example above is a great example of using it badly, in my opinion ;)
15:22:37 <FunctorSalad> and almost nobody uses all-uppercase ctor names today
15:22:38 <illissius> FunctorSalad: well the current leading proposal is to use foo (-> ViewCon), which is two extra characters
15:23:02 <FunctorSalad> two confusing chars IMHO
15:23:07 <jmcarthur> i'd prefer implicit, personally
15:23:21 <FunctorSalad> poor -> is already so overloaded
15:23:47 <illissius> FunctorSalad: if it were proposing to introduce -> where it weren't before, sure
15:23:55 <illissius> but view pattern already have it exactly the same
15:24:01 <illissius> it's just omitting the name of the function
15:24:05 <illissius> *patterns
15:24:08 <FunctorSalad> yes, I given view patterns it should stay
15:24:25 <FunctorSalad> s/I// (sentence restructure fail)
15:24:45 <illissius> anyway, I'm ambivalent between the two, I'd be happy with either
15:24:58 <FunctorSalad> what's the other?
15:26:18 <FunctorSalad> assuming you don't mean my CAPS
15:26:56 <FunctorSalad> which has the visual advantage of remaining atomic rather than an expression you need to precedence-parse mentally
15:27:00 <illissius> FunctorSalad: completely implicit vs. ->
15:28:10 <illissius> also see also http://neilmitchell.blogspot.com/2009/11/reviewing-view-patterns.html esp. the comments
15:28:37 <illissius> "We thought about this but never did it, mostly because we couldn't make up our minds about the fundeps on the view class. If people get some experience and decide what the fundeps should be, it would be easy to implement." (re: implicit view patterns)
15:30:28 <Trevion> Um, any fundep on the view class would be wrong.
15:30:39 * FunctorSalad is skeptical of completely invisible conversion too
15:31:05 <FunctorSalad> Trevion: a view type should know its real type
15:31:18 <FunctorSalad> since view types are created ad-hocly anyway
15:31:39 <FunctorSalad> and it'd greatly help the type inferator I assume
15:31:49 <FunctorSalad> (deduce argument type from pattern)
15:31:51 <Trevion> View t u means that t's can be viewed as u's.  There will be many types that could be viewed as u's, and t's could presumably be viewed as a number of different u's
15:31:56 <illissius> all three have advantages and drawbacks afaict
15:31:58 <illissius> http://hackage.haskell.org/trac/ghc/wiki/ViewPatterns#ImplicitViewFunctions
15:32:28 <FunctorSalad> Trevion: well reusing a u for many t seems expandable for the advantage I mentioned
15:32:32 <illissius> allegedly if there's no fundep you have type inference problems with nested view patterns
15:32:36 <mauke> class (Applicative m) => Monad m where { instance Functor m where { map f m = m >>= return . f }; instance Applicative m where { mf <*> mx = mf >>= \f -> mx >>= \x -> return (f x) }; return :: a -> m a; (>>=) :: m a -> (a -> m b) -> m b; m >>= f = join (map f m); join :: m (m a) -> m a; join m = m >>= id }
15:33:13 <Trevion> You do, because the meaning is unclear.  You have problems with read . show as well, but that doesn't mean that we need a fundep on Read and Show.
15:33:20 <illissius> and you might want to use the same view for multiple types (obvious example: []), and also multiple views for the same type (ViewL/ViewR for Seq, for example)
15:33:33 <FunctorSalad> (it might be cute to view a sequence as a list but do you really have to do that if it breaks type inference?)
15:33:48 <FunctorSalad> (just use an ordinary view pattern or make a clone of the list type)
15:34:06 <illissius> clones of the list type don't have the nice syntax :-)
15:34:40 <FunctorSalad> still, it seems like a novelty item at a large cost
15:35:01 <FunctorSalad> (at least if my expectation that most view types are ad-hoc is true)
15:35:08 <FunctorSalad> like ViewL/ViewR or Cale's Least
15:35:35 <illissius> not having used nested view patterns before I also have no idea how big the type inference issues would be
15:35:52 <illissius> and how easy it would be to resolve by just adding a type signature
15:36:10 <illissius> if it's easy to resolve that way that i'd just go for no fundep
15:36:39 <FunctorSalad> it's not just nested patterns
15:36:51 <FunctorSalad> you'll need a typesig whenever an intermediate type is undetermined
15:37:05 <FunctorSalad> just like with matrix multiplication without fundeps
15:37:11 <FunctorSalad> (the example in the manual)
15:37:36 <FunctorSalad> (x .*. y) .*. z -- error, undetermined intermediate
15:38:11 <FunctorSalad> (if .*. is a method of a three-parameter typeclass Mul a b c, (.*.) :: a -> b -> c)
15:38:32 <FunctorSalad> you'll get exactly the same problems I think
15:38:34 <ksf> @hoogle (a -> b) -> (a,c) -> (b,c)
15:38:35 <lambdabot> Data.Graph.Inductive.Query.Monad mapFst :: (a -> b) -> (a, c) -> (b, c)
15:38:35 <lambdabot> Data.Graph.Inductive.Query.Monad (><) :: (a -> b) -> (c -> d) -> (a, c) -> (b, d)
15:38:35 <lambdabot> Data.Graph.Inductive.Graph nmap :: DynGraph gr => (a -> c) -> gr a b -> gr c b
15:38:41 <illissius> yeah I have no idea
15:38:41 <ksf> @more
15:38:48 <Peaker> ksf, first ?
15:39:14 <Peaker> > first (*2) (10, 11)
15:39:15 <lambdabot>   (20,11)
15:39:18 <illissius> it's not like the stakes are very high either because you could resolve the issues with any of the three by just giving the view function explicitly
15:39:39 <illissius> which i guess is part of why people haven't managed to come to an agreement
15:39:48 <illissius> the smallest things tend to provoke the biggest arguments
15:39:53 <FunctorSalad> illissius: my intuition is that the "View type determines real type" fundep is a great help to the inferer. You encounter a pattern "f (ViewL x y)" and instantly infer the real type
15:40:06 <FunctorSalad> vs. making a new unknown variable
15:40:14 <FunctorSalad> (with a constraint)
15:40:38 <FunctorSalad> yes :) @ smallest things
15:41:41 <ksf> hey fgl has mapFst
15:42:18 <ksf> Peaker, I don't want to explode dependencies.
15:42:43 <Peaker> ksf, Control.Arrow is a pretty conventional one?
15:42:55 <ksf> but I already depend on fgl
15:42:57 <ivanm> ksf: fgl has a lot of weird things like that
15:43:10 <ivanm> ksf: first is in Control.Arrow and comes with base...
15:43:45 <ksf> don't need it, anyway, my perception of list/tuple nesting was skewed.
15:43:51 <illissius> :t first
15:43:52 <lambdabot> forall (a :: * -> * -> *) b c d. (Arrow a) => a b c -> a (b, d) (c, d)
15:44:10 <FunctorSalad> f (ViewL x y) = ....  (other function:) g = f 1
15:44:18 <FunctorSalad> I think this will already fail without a sig
15:44:24 <ksf> we should really, really have Bifunctors in base.
15:44:32 <ksf> Tri and quad, too, at the very least.
15:44:41 <FunctorSalad> you'd have to compute the intersection of Num a and HasView a ViewL
15:44:46 <ivanm> ksf: I was thinking of writing a BiFunctor class just for graphs...
15:44:54 <FunctorSalad> AFAIK the inferer doesn't do such things
15:45:01 <ksf> :t nmap
15:45:02 <lambdabot> Not in scope: `nmap'
15:45:09 <ivanm> but they'd need to be restricted BiFunctors, which means it wouldn't go into base
15:45:09 <ksf> ...anyway, fgl comes with it.
15:45:17 <ivanm> @hoogle nmap
15:45:17 <lambdabot> Data.Graph.Inductive.Graph nmap :: DynGraph gr => (a -> c) -> gr a b -> gr c b
15:45:33 * ivanm often wants nlmap :: (Node -> a -> c) -> gr a b -> gr c b
15:45:36 <Peaker> yay! break away from one-letter type-var names!
15:45:39 <illissius> they really should've used some kind of infix thing for arrows :(
15:45:40 <ksf> @hoogle emap
15:45:41 <lambdabot> Data.Graph.Inductive.Graph emap :: DynGraph gr => (b -> c) -> gr a b -> gr a c
15:45:41 <lambdabot> module Data.Graph.Inductive.Internal.FiniteMap
15:45:41 <lambdabot> Data.Graph.Inductive.Internal.FiniteMap data Ord a => FiniteMap a b
15:45:45 <Peaker> soon we might even have type variables with sensible names :)
15:46:01 <illissius> :t (&&&)
15:46:01 <lambdabot> forall (a :: * -> * -> *) b c c'. (Arrow a) => a b c -> a b c' -> a b (c, c')
15:46:14 <ivanm> Peaker: I beg to differ
15:46:25 <ivanm> "gr n l" would make much more sense
15:46:51 <FunctorSalad> ivanm: how about an infix var? ;)
15:46:59 <FunctorSalad> though there's nothing obvious for graph
15:47:02 <ivanm> FunctorSalad: *shudder*
15:47:13 <Peaker> ivanm, I'm actually ok with a lot of one-letter ones when they really only denote structure.  "gr" is ok if the context is really clear that it is short-hand for "graph".  But in the arrow case they should be closer to "arrow" than to "a".
15:47:16 <ksf> so, what's the fastest way to look something up in a sorted, non-overlapping list of ranges and singletons?
15:47:28 <FunctorSalad> n .<--=</ l
15:47:31 <FunctorSalad> (kidding)
15:47:33 <ivanm> Peaker: *nod*
15:47:37 <ksf> construction time is not an issue.
15:47:48 * ivanm heads off to uni
15:47:56 <Peaker> ksf, example?
15:48:09 <Peaker> ksf, of "non-overlapping list of ranges and singletons"?
15:48:10 <illissius> :t (>>>)
15:48:11 <lambdabot> forall (cat :: * -> * -> *) a b c. (Control.Category.Category cat) => cat a b -> cat b c -> cat a c
15:48:21 <djahandarie> :t Control.Arrow.(>>>)
15:48:22 <lambdabot> Couldn't find qualified module.
15:48:29 <ksf> [x == 'a', 'c' < x < 'z', x == 'A']
15:48:35 <Peaker> illissius, what infix operator are you missing?
15:49:02 <Peaker> ksf, flip Set.member . Set.fromList . concat ?
15:49:24 <ksf> oh, and the alphabet is too large to do perfect hashing over the expanded ranges.
15:49:29 <illissius> Peaker: oh nothing, just seeing first (*2) (10, 11) == (20,11) set off a tiny lightbulb above my head
15:49:39 <ksf> ...or doing a set.
15:49:45 <benmachine> ksf: I imagine something treeish?
15:49:47 <illissius> so i set out to try and comprehend what the rest of these arrow things do
15:49:57 <ksf> this should be useable over the whole of unicode.
15:50:26 <mauke> Set Range
15:50:29 <Peaker> @where SEC
15:50:29 <lambdabot> http://conal.net/blog/posts/semantic-editor-combinators/
15:50:32 <Peaker> illissius, I suggest reading that ^^
15:50:41 <illissius> I have :)
15:50:57 <illissius> but I do need to revisit it
15:51:00 <Peaker> ksf, what mauke said
15:51:10 <FunctorSalad> uh how'd that work?
15:51:16 <ksf> that won't work.
15:51:17 <FunctorSalad> you can't deduce the range given a point query
15:51:19 <illissius> along with a bunch of other things I read not-so-recently and only half understood at the time
15:51:22 <ksf> I need to lookup single values.
15:51:41 <ksf> oh, and it's not a set, it's a map.
15:52:08 <ksf> and at the end of it all, I want to compile it down to code via TH.
15:52:09 <Peaker> ksf, Map/Set expose binary-searching capabilitiesw
15:52:37 <Peaker> ksf, so you can search single values in the sorted ranges
15:52:56 <ksf> doh.
15:52:58 <FunctorSalad> ksf: precompile a decision tree based on digits of the input?
15:53:02 <ksf> single values are of course ranges, too.
15:53:28 <ksf> FunctorSalad, I like your thinking.
15:53:51 <Jafet> Well, that's a radix tree.
15:54:05 <FunctorSalad> Jafet: I vaguely had that word in mind, yes
15:54:07 <FunctorSalad> :)
15:54:18 <ksf> can we agree on "IntMapish"?
15:54:20 <Jafet> A scapegoat tree could be very fast, but that's more impure than a bad your mom joke
15:54:27 <FunctorSalad> you'd probably take more than one binary digit at a time
15:54:54 <ksf> I don't think I want to compile a self-modifying structure to straight code.
15:55:06 <ksf> FunctorSalad, so does IntMap
15:55:22 <Peaker> ksf, what's this TH stuff you're doing?
15:55:32 <ksf> compiling DFAs
15:55:34 <FunctorSalad> ksf: I've never seen IntMaps internals
15:55:42 <Jafet> ...you could profile a straight tree, then unbalance it based on the profile.
15:55:42 <FunctorSalad> so it's a radix tree?
15:55:43 <Peaker> ksf, why do you need TH for this?
15:55:57 <ksf> because TH is an easy way to get fast code.
15:56:15 <Peaker> ksf, Probably there's a pragma to ask ghc to pre-compute a pure value?
15:56:19 <Jafet> I imagine it would be similar to a Huffman tree construction.
15:56:25 <FunctorSalad> a tree based on order alone seems like a waste if he has a real-number structure
15:56:30 <ksf> ...and a straight chain of ifthenelses is _way_ faster than matching a tree.
15:56:50 <Peaker> ksf, why?
15:56:53 <ksf> I guess we can safely assume that things are expressible in binary.
15:57:03 <ksf> Peaker, because we don't have a supercompiler.
15:57:13 <FunctorSalad> (the radix tree corresponds to chopping up the interval into equal-sized subintervalls, I suppose)
15:57:19 <FunctorSalad> (in one level of tree)
15:57:24 <ksf> ...ghc doesn't know how to specialize a lookup for a specific tree.
15:57:27 <Peaker> I never understood what "supercompiler" meant
15:57:36 <Peaker> a compiler with "really good" optimizations? :)
15:57:48 <Peaker> or a compiler that supports "partial evaluation"?
15:58:03 <Jafet> @google gnu supercompiler
15:58:08 <lambdabot> http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.96.5585&rep=rep1&type=pdf
15:58:08 <lambdabot> Title: A Supercompiler for Core Haskell
15:58:44 <Jafet> @faq can lambdabot magically find haskell related papers via google?
15:58:45 <lambdabot> The answer is: Yes! Haskell can do that.
15:58:53 <benmachine> superawesomecompiler
15:59:09 <ddarius> Peaker: Read Turchin's original papers.
15:59:57 <hpc> "supercompiler" makes me think of "supercollider" which makes me think "Glaskow Haskell Collider"
16:00:11 <illissius> heh
16:00:22 <mauke> /usr/bin/lhc
16:01:50 <jmcarthur> funny enough lhc is a real haskell compiler
16:02:13 <illissius> @faq can the Large Hadron Collider compile Haskell programs?
16:02:13 <lambdabot> The answer is: Yes! Haskell can do that.
16:04:05 <ksf> hey that black/white radix tree thing is perfect.
16:05:15 <illissius> would be nice to have a supercompiler for the Core, LLVM for the machine code bits, and then you just need something awesome for the in-between (STG/GRIN?)
16:07:16 * ddarius doesn't understand the "love" for supercompilation.  Supercompilation is nice, but in the Venn diagram of (high-level) compiler optimizations it doesn't contain everything else and even less does positive supercompilation.
16:08:08 <napping> The thing I like, is that it *looks* like you can trust it to remove apparent abstraction penalties like function boundaries and stuff
16:09:17 <Jafet> supercompile :: AST -> AST; supercompile _ = ⟂ -- compliments of D. Hofstadter
16:09:25 <ddarius> napping: So does inlining and partial evaluation and ...
16:09:51 <napping> inlining is not nearly so complete. partial evaluation is cool too
16:10:08 <handonson> Is there an STM implementation in Haskell that supports process-to-process communication? (compared to thread-to-thread communication)
16:10:42 <napping> what other optimizations do you have in mind?
16:13:02 <napping> supercompilation (and partial evaluation) seem to do a reasonble job of taking a nicely abstracted bunch of small pretty functions, and smooshing them together into something specialized you might write by hand
16:13:24 <napping> I claim that in most cases persuading people not to do that by hand is the real win in compiler optimization
16:13:44 <jmcarthur> supercompilation has a cool name, too
16:13:49 <handonson> I see there's one in Python
16:13:59 <Peaker> I think it was John Carmack who said "Don't generalize. There's always something to exploit in the specific case"
16:14:36 <hpc> carmack also wrote some of the strangest fast code ever
16:14:42 <ddarius> Peaker: If there wasn't, then why would you be using the specific case at all?
16:14:50 <benmachine> google tells me, "
16:14:52 <benmachine> The Java Supercompiler Version 1 is scheduled for completion in late 2003."
16:14:55 <benmachine> well, great
16:15:00 <hpc> bwahaha
16:16:35 <ksf> heh. kart trees are cool.
16:17:20 <ksf> lookup consists of branching on a single bit specified in the node.
16:17:27 <kyagrd> Is anyone in conctatc with the author of logic-TPTP package: Daniel Schuessler?
16:17:27 <napping> hpc: which code?
16:17:28 <ksf> ...bit position, that is.
16:17:40 <hpc> inverse square root
16:17:53 <ddarius> napping: http://scholar.google.com/scholar?q=Towards+unifying+partial+evaluation,+deforestation,+supercompilation,+and+GPC&hl=en&as_sdt=0&as_vis=1&oi=scholart
16:17:57 <hpc> carmack's reverse is also a funny algorithm, but not nearly as insane
16:18:08 <kyagrd> It hasn't ben updated more than a year so it needs very minor updates just to make it compile.
16:18:14 <napping> handonson: I don't know of any package specficially for interprocess stuff, though you might also look for post-commit hooks
16:18:37 <napping> handonson: are you doing some weird stuff with OS permissions and user accounting?
16:18:55 <ksf> and due to utf8's magnificent byte layout, I can match the encoded form, directly.
16:18:59 <kyagrd> I seem to be one of the major customer, and i would be happy to take over the maintinaer if he isnt any more pushing it.
16:19:07 <napping> hpc: that square root is pretty nifty, but wasn't originated by Carmack
16:19:39 <napping> hpc: I expect that he's done some pretty awesome things, but haven't read his code or heard of specific examples
16:19:40 <Peaker> napping, who originated it?
16:19:56 <napping> http://www.beyond3d.com/content/articles/8/
16:20:42 <napping> traces is back several steps
16:20:46 <Peaker> napping, the coolest thing I heard of him - is his adaptation of the algorithm for checking whether some point is in a polygon to detecting whether a point falls within a shadow of an object or not, using an ingenius trick with the stencil buffer which was never meant for that purpose
16:21:16 <napping> oh, the exact shadows
16:21:19 <handonson> napping: uhm, no. I'm not doing anything about OS permissions and user accounting. why do you think so?
16:22:23 <napping> handonson: well, I don't know of any interprocess STM, but I don't really need multiple processes for much either
16:23:11 <napping> In particular, GHC's runtime uses multiple cores quite nicely, and there's some thread pinning stuf to handle calls to foreign libraries with thread local state
16:23:22 <handonson> I want some interprocess communication in Haskell in which you don't have to copy the same value everywhere in the memory
16:24:00 <Twey> You want threads?
16:24:01 <napping> Ok. That might be a bit easier to find if you don't absolutely require transactions
16:24:16 <handonson> No, I want processes
16:24:19 <jmcarthur> Peaker: you mean something like shadow volumes?
16:24:31 <Twey> STM doesn't exist for processes because there's no shared memory
16:24:36 <Peaker> jmcarthur, don't know what that is
16:24:36 <Twey> That's kind of the point
16:24:51 <Twey> Processes can't share memory
16:24:55 <Twey> By definition
16:24:56 <mauke> Twey: what
16:25:04 <napping> jmcarthur: you can use accumulations in the stencil buffer to see what ends up in shadow
16:25:47 <napping> Terminology is getting confused, but I think handonson means OS processes
16:26:20 <jmcarthur> Peaker: it's when you extrude polygons from the edges of a model, render them to the stencil buffer where the depth of the pixel already there has some effect on it, and then depending on how those polygons overlap or face determines whether the pixel is in shadow
16:26:28 <jmcarthur> very roughly
16:26:35 <napping> jmcarthur: yeah, that's it
16:26:46 <Twey> mauke: A thread is a process with shared memory.
16:27:07 <napping> the trick is to do it fast by rendering front and back faces and increment and decrement stencil ops
16:27:18 <mauke> Twey: processes can share memory
16:27:40 <jmcarthur> i thought of a version of it independently and then googled it and found out that it was already done.
16:27:53 <Peaker> jmcarthur, I was with you up to "render them to stencil buffer". then afaik you just take points which have odd stencil values and they're "in-shadow", even and they're "out-of-shadow", iiuc
16:27:54 <napping> Twey: consider mmap.
16:27:54 <jmcarthur> i did not think of using the stencil buffer for it though. mine would have been a bit slower
16:28:02 <jmcarthur> it was a screen space computation though
16:28:04 <Twey> napping: Hm
16:28:06 <handonson> I'm doing the interprocess communication with stdio now, but sending one megabyte of data through pipe requires copying it every time, you know
16:28:35 <mauke> consider shmat
16:28:42 <jmcarthur> Peaker: yeah that's the idea
16:29:00 <Twey> Then I'm confused.  What *is* the difference between a thread and a process?
16:29:03 <jmcarthur> there are other ways to do it to. i believe the wikipedia article covers three ways to accumulate interesting results
16:29:06 <napping> handonson: ah, so you are already serializing
16:29:14 <Peaker> jmcarthur, oh, now I understand what you said about the depth -- you have to do z-buffer-clipping on the stencil-draw indeed
16:29:19 <jmcarthur> yeah
16:29:30 <msieradzki> Twey, thread is a process that shares all the memory of the parent - more or less
16:29:40 <msieradzki> oversimplifying
16:30:09 <handonson> napping: for now, i don't serialize explicitly at all, since the data i want to pass around is fortunately a ByteString
16:30:15 <napping> oh, ok
16:30:21 <illissius> Twey: basically what you said, except processes can also share some memory if they explicity request it from the OS
16:30:22 <Peaker> I think Linux did it right with fork being clone(share nothing).  Having a flat hierarchy of "processes" with arbitrary sharing. Then they changed to the sillier model with processes "containing" threads
16:30:42 <Peaker> and an overly-restrictive distinction
16:31:03 <napping> handonson: well, it's touchy trying to share actual values
16:31:08 <jmcarthur> Peaker: but you're a functional programmer and linux is not :P
16:31:11 <jmcarthur> *linus
16:31:16 <msieradzki> C solution is to map shared memory I guess
16:31:33 <Peaker> jmcarthur, Linux did it well, I think.. they just succumbed to pressure to do it sillily like everyone else
16:31:54 <Peaker> jmcarthur, I guess for better compatibility
16:31:58 <illissius> (it's complicated to deal with though, what with not just concurrency, but pointers from one process's memory being totally invalid in the other process)
16:31:59 <handonson> so there's no shared memory abstraction in Haskell, right?
16:32:11 <Peaker> handonson, There are libraries that do that
16:32:13 <ksf> linux has processes _and_ threads.
16:32:13 <napping> well, there are bindings for mmap
16:32:28 <napping> I don't know if there's anything higher level built on that
16:32:28 <handonson> Peaker: you mean Haskell libraries?
16:32:30 <Peaker> ksf, It used to have just arbitrary-sharing processes with clone, afaik
16:32:31 <ksf> and internally, they're virtually identical, use the same scheduler etc. at least from what I gathered.
16:32:50 <Peaker> ksf, (Of course fork() and pthread_create() both existed with the "right" semantics, so it had "both")
16:32:56 <Twey> illissius: Hm, thanks.
16:32:57 <Peaker> handonson, Or Haskell bindings
16:33:01 <jmcarthur> ksf: yes
16:33:07 <msieradzki> shared heap is a nice thing where you guarantee that only 1 process can have a reference to it
16:33:08 <napping> handonson: there's bytestring-mmap for opening files in an mmaped way
16:33:09 <handonson> do I have to look into System.Posix?
16:33:18 <msieradzki> did anyone write it for haskell?
16:33:28 <napping> and I believe vector-mmap lets you map mutable vectors
16:33:29 <Peaker> so -- why doesn't someone optimize the hash table benchmark so GHC performs as well as F# to shut jdh up? :)
16:33:30 <jmcarthur> ksf: they are indeed the same thing
16:33:37 <napping> (I'm just searching hackage at this point)
16:33:49 <jmcarthur> Peaker: because it won't shut him up
16:33:56 <msieradzki> Peaker, I wanted to repro and it turned out that benchmarks are in 10 different places
16:34:12 <msieradzki> and I no longer knew what to compare to what
16:34:14 <ddarius> jmcarthur stole my answer
16:34:15 <ksf> Peaker, because hash tables aren't the fastest thing I can do.
16:34:18 <napping> msieradzki: yeah, we could really do with some linear types for shared heaps
16:34:39 <Peaker> msieradzki, Well, http://www.reddit.com/r/coding/comments/cr1yk/haskells_hash_table_performance_revisited_with/ apparently contains people who manage to reproduce?
16:34:54 <napping> handonson: I'm sorry, but could you explain a why you have separate processes?
16:35:17 <msieradzki> I read it somewhere else
16:35:20 <msieradzki> not on reddit
16:35:26 <msieradzki> flyingfrogblog or something
16:35:40 <napping> oh, that's jdh directly
16:35:40 <msieradzki> maybe stackoverflow and there were no links to code samples or I missed them
16:36:14 <jmcarthur> jdh doesn't produce fake numbers for his benchmarks. he just pits weaknesses of ghc against strengths of other compilers and lies about its significance
16:36:23 <msieradzki> though insertion only is stupid :)
16:36:40 <msieradzki> every microbenchmark is a lie
16:36:46 <jmcarthur> indeed
16:37:02 <jmcarthur> that's basically the definition of microbenchmark
16:37:13 <handonson> napping: I want the functionality of adding/changing functions (plugins, extensions) without having to restart the process (closing and reopening all sockets) so I decided to make each plugin a small, separate executable
16:37:37 <napping> and what data does a plugin need to get at?
16:37:39 <handonson> "closing and reopening all sockets" means the script I'm writing is network-related
16:38:04 <napping> using mmap would require some control over what is allocated where
16:38:08 <jem777> is there a function to lookup a key in a [(key, value)]?
16:38:15 <jmcarthur> :t lookup
16:38:15 <handonson> jem777: lookup
16:38:16 <lambdabot> forall a b. (Eq a) => a -> [(a, b)] -> Maybe b
16:39:08 * ddarius doesn't know why Haskell has to choose such cryptic names.
16:39:19 <handonson> agreed.
16:40:16 <handonson> so bytestring-mmap is unix-only, as I expected
16:40:18 <napping> have you looked at "plugins"?
16:40:27 <napping> hmm, dunno how portable that is either
16:40:36 <napping> but it's for dynamically loading and unloading Haskell code
16:41:11 <handonson> napping: yesterday I've gotten advices about plugins, dyre, metaplug, hint, and mueval
16:41:15 <napping> but you can ask dons when he gets on
16:41:17 <p_l> handonson: should be kept like that, though - Windows has mmap as well, in fact it's kinda stupid to implement a filesystem driver in windows that doesn't support it
16:42:52 <napping> well, unless you can arrange for data to be recieved into shared memory in the first place you won't avoid a copy
16:43:13 <kfish> hi TacticalGrace :)
16:44:12 <handonson> napping: my choice was between including the entire GHC into the central process and easily handle all source codes (plugins, dyre, metaplug, hint, mueval, ...), or compiling each plugin beforehand and the central process simply turning them on and off
16:45:09 <TacticalGrace> Hey kfish, how are you going?
16:45:17 <handonson> there were pros and cons for both of them, and for me somehow the latter looked cooler
16:45:55 <napping> hmm, would it work to pass the actual sockets to the plugins?
16:46:29 <handonson> what do you mean
16:46:41 <handonson> suppose you have one socket
16:46:43 <napping> pass the socket itself along a pipe and let a plugin use it
16:46:53 <handonson> oh, along a pipe
16:47:09 <handonson> yeah that's similar to what i'm doing now
16:47:15 <kfish> TacticalGrace, great :) working at tsuru now (trading company in tokyo), 100% haskell :)
16:48:01 <handonson> napping: i talked to him last night, and he told me plugins was broken since the latest cabal update
16:48:24 <napping> yeah, it's not the most robust
16:48:50 <handonson> i'm not sure if he is intending to fix it in near future, as you have other options and the package is not being updated for more than a year
16:48:55 <napping> I wonder if it could be worked more closely into the language - I think SML  has some loading features
16:49:52 <msieradzki> japple seems to be testing something in this reddit post
16:49:56 <handonson> p_l: could you elaborate
16:50:30 <p_l> handonson: Notepad.exe doesn't work on filesystems that don't support Windows' equivalent of mmap() call
16:51:12 <p_l> so if you write an IFS driver, you better make at least a copying mockup of mmap :)
16:51:15 <msieradzki> http://hackage.haskell.org/package/accelerate-0.7.1.0 this seems pretty awesome
16:51:24 <msieradzki> with CUDA support like 2 days after I asked about it :)
16:51:36 <ksf> hmmmmmmmmmmm
16:51:39 <handonson> suppose I'd write an abstraction layer of mmap so that the same Haskell code using mmap would work on both unix and windows
16:51:39 <ksf> hmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
16:51:49 <handonson> is this a bad idea
16:51:53 <msieradzki> well except that hackage haddock page contains no docs
16:52:03 <napping> well, it does sound like an awful lot of work
16:52:09 <ksf> actually, I could transform dfas on bits into dfa's that work on say 128-bit ints.
16:52:37 <napping> if it's feasible just to compile everything into one big executable and just not use the bits you don't need
16:53:14 <napping> Ideally design an interface so you could efficiently run them out of process later if you need to
16:53:38 <handonson> out of process?
16:54:16 <napping> make the plugins use an 
16:54:16 <ksf> the state explosion would most likely be prohibitive, though. but transforming bit dfa's to byte dfa's and byte dfa's to word dfas might be feasible.
16:54:44 <napping> an API that would be possible to implement over mmap
16:55:25 <napping> I guess I'm assuming you want this to speed development of something you want to keep as a long-running instance
16:55:53 <napping> I don't know of any servers in Haskell popular enough to have a giant plugin ecosystem
16:56:11 <napping> but maybe you are trying to write one?
17:00:58 <handonson> I never really wrote a real plug-in system. I always focused on making the code work, not considering any extensibility. The code got dirtier and dirtier. I knew it was wrong in a long run, but I just ... did.
17:02:15 * hackagebot logic-TPTP 0.2.0.1 - Import, export etc. for TPTP, a syntax for first-order logic  http://hackage.haskell.org/package/logic-TPTP-0.2.0.1 (KiYungAhn)
17:02:28 <kyagrd> Hopefully this is not rude but I just updated someone other's pakcage to make it compile on ghc 6.12.x :(
17:03:27 * ksf thinks he should define all his word8 and unicode dfa's in terms of an 0,1,Align n alphabet.
17:03:39 <handonson> So this time I decided to implement the truly extensible system from scratch, something too advanced for a ridiculously small and simple network script
17:03:40 <kyagrd> I gave him ( FunctorSalad ) the full repository access though
17:03:57 <ksf> ...where align n _matches_ a byte or word boundary, it doesn't seek, of course.
17:05:19 <ksf> kyagrd, you might want to @tell him that.
17:05:38 <napping> handonson: I see. Well, as you've heard the options in Haskell for real interprocess stuff or dynamic loading are not so nice
17:05:45 <kyagrd> ksf, I tried contacting his email (which he has multiple of them) and wasn't successful.
17:05:50 <napping> handonson: but that doesn't mean you can't write things in a modular what
17:05:52 <ksf> I mean lambdabot.
17:06:05 <ksf> @tell kyagrd you can use @tell to tell someone something
17:06:05 <lambdabot> Consider it noted.
17:06:25 <napping> you make a Plugin type and a defined API that's all they can use, and so on, without actually fiddling around with mmap
17:06:27 <kyagrd> Does FunctorSalad come in these days?
17:06:27 <lambdabot> kyagrd: You have 1 new message. '/msg lambdabot @messages' to read it.
17:06:34 <ksf> daily.
17:06:36 <ddarius> He's here pretty often.
17:06:42 <kyagrd> Oh
17:06:44 <napping> run them in forkIO'd threads for isolation to stay honest, maybe
17:06:47 <mauke> preflex: seen FunctorSalad
17:06:47 <preflex>  FunctorSalad was last seen on #haskell-blah 47 minutes and 7 seconds ago, saying: seeya=)
17:06:49 <handonson> kyagrd: just curious, but how come you use TPTP
17:06:53 <ddarius> preflex: seen FunctorSalad
17:06:53 <preflex>  FunctorSalad was last seen on #haskell-blah 47 minutes and 13 seconds ago, saying: seeya=)
17:06:56 <handonson> kyagrd: is it for your PL research
17:07:07 <kyagrd> It was for an internship.
17:07:22 <handonson> ah.
17:07:45 <kyagrd> And wrote a small paper on it now writing a journal version tried recompiling but failed since I upgraded to 6.12.x
17:07:45 <EvanR> Cale: you there?
17:09:26 <kyagrd> @tell FunctorSalad I dumped your logic-TPTP repository into patch-tag and also included you as a member.
17:09:26 <lambdabot> Consider it noted.
17:13:08 <handonson> i just got re-struck by this idea
17:13:16 <handonson> what if i just use a file
17:13:23 <handonson> for interprocess communication
17:13:37 <handonson> since the OS will do the sharing part for me
17:15:11 <handonson> and as modern OSs do the buffering before actually writing to the secondary storage, it shouldn't cause much more r/w overhead than mmap
17:15:24 <handonson> napping: what do you think
17:15:25 <Zeiris> Can Parsec parse bit-packed data?
17:15:31 <napping> It should come out about the same as mmap
17:15:32 <Zeiris> (Bit-packed, non-byte-aligned.)
17:15:48 <ksf> Zeiris, not efficiently.
17:15:57 <napping> pretty low level of abstraction either way
17:15:59 <ksf> cereal can do such things, and data.binary
17:16:14 <Zeiris> Great. My hand-rolled parser is starting to look kinda like Parsec, so I was worried about duplication.
17:16:23 <napping> but if the semantics it offers is enough for you, I don't think practical issues will get in your way
17:16:42 <dolio> You could write a Stream instance for whatever bit packed format you're using.
17:16:49 <ksf> ...and I just decided that I'm going to support bit parsing natively. both aligned and unaligned, mixed.
17:18:05 <dolio> In Parsec 3, that is.
17:18:31 <Zeiris> Actually, neither cereal nor data.binary seem to support bit parsing :\
17:18:35 <dolio> Unless I'm misunderstanding what you mean.
17:18:45 <ksf> you mean you want to represent each bit by a 64-bit pointer and a 64-bit tag?
17:19:28 <benmachine> Zeiris: Parsec's input type only needs to support erm
17:19:37 <benmachine> it needs to be an instance of Stream
17:19:58 <benmachine> so you need uncons :: s -> m (Maybe (t, s))
17:20:11 <benmachine> where t is the token type you parse, m is some monad
17:20:20 <benmachine> and s is 'stream state'
17:20:42 <ksf> backtracking is the sux
17:20:57 <ksf> damn xchat, it won't let me write t e h
17:22:28 <dcoutts_> Zeiris: bit parsing is quite tricky to do efficiently if we also want to support fast byte or word aligned operations
17:23:41 <alex_kidd> Zeiris: what is it for?
17:23:50 <ksf> a) define a dfa over 0,1,Boundary n b) express all other alphabets in terms of it. c) profit.
17:24:02 <alex_kidd> Zeiris: if you dont mind
17:24:13 * ddarius envisions a "polymorphic" bit/byte parser.
17:25:24 <ksf> well, b.5) includes transforming the bit-dfa into byte, word, dword etc dfa's, depending on state explosion.
17:27:34 <adnap> Does anyone ever feel like they would like to use popular names for operations on types they've created like (-)?  I think it would make the most sense, but it's annoying to have name conflicts.  Should I just use 'sub' or something like that instead?
17:28:06 <ezyang> adnap: You can import Prelude hiding it 
17:28:09 <ezyang> but you might confuse people. 
17:28:11 <ksf> instance Num Foo where (-) = ...
17:28:25 <handonson> is there a Python pickle equivalent in Haskell?
17:28:28 <ezyang> ksf: Then he has to implement a whole raft of functions :-) 
17:28:31 <ezyang> handonson: Show? 
17:28:35 <ezyang> handonson: binary? 
17:28:50 <ksf> (+) = error "don't call me"
17:28:51 <handonson> binary? never heard of that before
17:28:55 <ezyang> cereal? 
17:28:57 <handonson> the name's cool
17:29:09 <handonson> cereal is cooler
17:29:19 <kyagrd> I hope there is some semi-automation to make (read . show == id)  property to hold.
17:29:23 <adnap> Yeah, it might be confusing.  I have a point type, and I would like to define subtraction for points.
17:29:39 <Saizan> kyagrd: derive both :)
17:29:55 <c_wraith> the thing is, subtraction between two points results in a vector.
17:29:57 <Zeiris> alex_kidd, parsing a very complex bit-packed data structure in a computer game. I understand that incorporating bits has a performance cost for bytes, and is thus avoided :)
17:30:17 <kyagrd> Well, sometimes people wants to show them more compactly writing their own show function.
17:30:37 <zygoloid> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27819  \o/
17:30:40 <ksf> c_wraith, points _are_ vectors.
17:31:28 <dolio> Everything is a rose tree.
17:31:32 <adnap> Is this bad? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27821#a27821
17:31:48 <zygoloid> dolio: my rose tree is cyclic ;-)
17:31:55 <adnap> c_wraith: Yeah, I know.  That's what I've done.
17:32:30 * zygoloid -> successful remote heap exploration -> bed
17:32:32 <c_wraith> ksf: points aren't vectors.  Vectors are relative.  points are absolute.
17:32:41 <Saizan> kyagrd: "Tillmann Rendel and Klaus Ostermann. Invertible syntax descriptions: Unifying parsing and pretty printing." <- at Haskell Symposium 2010, might be interesting to read :)
17:32:54 <ksf> points are vectors relative to the origin.
17:33:21 <adnap> c_wraith: Can you look at my code and tell me if it's reasonable?
17:33:36 <c_wraith> My main concern is that while they may have similar representations, often times you mean one or the other, explicitly, and don't want to mix the two.
17:33:45 <adnap> c_wraith: I agree.
17:33:47 <c_wraith> adnap: I missed your description of what your code is doing.
17:33:50 <handonson> ezyang: my idea is, something like data A = A Int Int Int must have some binary representation on memory, and I want to use it for fast serialization/deserialization. is this possible with, say, GHC
17:34:05 <ksf> c_wraith, then make a phantom type and provide casts.
17:34:09 <adnap> c_wraith: I posted an hpaste link.  It's pretty obvious.
17:34:13 <ezyang> Unfortunately not; you'll need to help a little bit. See binary/cereal. 
17:34:18 <ksf> anyway, - is the same, in both cases.
17:34:34 <kyagrd> Saizan, great someone eventually made their hands down on that.
17:34:35 <handonson> that's too bad.
17:35:08 <dcoutts_> handonson: the in-memory representation is not flat, it uses pointers
17:35:11 <c_wraith> adnap: I'd probably use a custom type for Point2 and Point3, rather than tuples, and make it strict.
17:35:31 * ksf would just use Vec
17:35:33 <Saizan> kyagrd: yeah, it was kind of floating around for a while, let's hope it's actually good :)
17:35:34 <handonson> dcoutts_: yes, i expected that should be the tricky part
17:35:36 <c_wraith> adnap: but nothing in that code looks wrong.
17:35:40 <dcoutts_> handonson: it would be flat if you told ghc to make it flat
17:35:44 <adnap> c_wraith: What do you mean by strict?  Also, is it okay that I'm doing 'sub2' and 'sub3'?
17:36:09 <handonson> dcoutts_: can you use that binary representation for serialization then?
17:36:33 <adnap> c_wraith: Also, what do you think about separate modules? For instance, Point2.sub and Point3.sub
17:36:48 <dcoutts_> handonson: not really, there's also a heap header word and you don't want to serialise that
17:37:01 <c_wraith> adnap: I think separate modules makes sense if the use cases for the two don't overlap heavily.  If they do, it might as well be a single module.
17:37:05 <dcoutts_> handonson: in any case, ghc does not really give you access to the raw in-memory heap representation
17:38:36 <handonson> hmm.
17:38:57 <c_wraith> adnap: As far as strict, well..  That's something you should learn about separately from this, I think.  It's important, but this isn't the best intro to it.
17:39:48 <handonson> serialization will be superfast if it's allowed. but then there are problems if it's allowed. it could be a violation (extension?) to the language spec, i guess.
17:39:49 <kyagrd> Saizan, were you able to find a copy of that paper? Draft seem to be on neither of author's hompage.
17:41:21 <Saizan> kyagrd: no :\
17:44:09 <dcoutts_> handonson: it's pretty quick to serialise and deserialise in the standard way
17:44:33 <dcoutts_> if done well it should easily saturate the memory bandwidth
17:46:44 <ezyang> What does the error message "no match in record selector" mean? 
17:47:25 <Saizan> from ghc?
17:47:40 <shane2> hello world haha
17:48:12 <shane2> anyone talking in here?
17:48:19 <lucca> yes
17:48:27 <shane2> experienced programmers?
17:48:29 <ezyang> Saizan: possibly from user code. 
17:48:31 <handonson> no
17:48:44 <handonson> do not expect any experienced programmers here
17:48:58 <handonson> they're all lousy programmers
17:49:10 <handonson> like developers of GHC
17:49:16 <handonson> oh my god how horrible is that
17:49:21 <shane2> well im just trying to learn programming and stuff thats all
17:49:43 <Saizan> shane2: this channel is about the Haskell programming language in particular
17:49:43 <shane2> and i was wanting to ask some questions is all
17:50:04 <shane2> oh ok 
17:50:05 <handonson> shane2: I am sorry. Apparently my sarcasm didn't work for anyone.
17:50:16 <shane2> haha its ok
17:50:21 <Saizan> if you want to learn haskell you're welcome :)
17:50:34 <shane2> what kind of programming language is that?
17:50:52 <tommd> shane2: read up on it at haskell.org
17:50:56 <Saizan> (even general compsci/programming questions are ok i guess)
17:51:34 <shane2> are any other programming languages required to learn haskell?
17:51:52 <tommd> no
17:51:55 <ksf> duh. converting from bit to bytes (no I didn't do that I did nibbles) doesn't explode states.
17:52:17 <ksf> there are, after all, no new states you can end up in just by traversing stuff.
17:52:32 <Saizan> no, actually haskell being so different from the more mainstream languages you'd have to forget about those to learn it anyway :)
17:52:38 <ksf> this makes perfect hashing feasible, again.
17:52:57 <shane2> well im learning html(yea i know lame but i gotta start from the beginning)
17:53:15 <ksf> depending on the ratio of (wordsize / target states), that is.
17:53:45 <Saizan> html is not really a programming language, more like a data format for structured text
17:54:22 <shane2> so is it a pointless thing to learn?
17:54:39 <Saizan> no, just a different kind of thing to learn :)
17:54:43 <ksf> it would'nt be bad if you grokked the principle.
17:55:04 <adnap> So, with the FFI, am I limited to functions that return primitive types if I'm to be calling Haskell functions from C?
17:55:10 <ksf> ...but as to memorizing tags, definitely no. not useful for haskell or any other PL.
17:55:15 <Saizan> still quite required if you want to do any web programming
17:55:57 <shane2> ok....im learning it now cause im getting ready to start school for programming and analysis and its a class i have to take for the first semester so i figured id learn it before school started to make it a little easier haha
17:56:04 <msieradzki> road from HTML/XML to Lisp isn't long :P
17:56:42 <akapra> shane2, where do you have heard about haskell?
17:57:08 <Saizan> adnap: ForeignPtr can reference more complex data, and they can be passed to the C side i think, or something like that.
17:57:47 <shane2> i just heard about it in here haha...i googled programmer chat rooms so i could talk to other programmers and find out basic info like what the best order of languages to learn is and such
17:58:32 <kyagrd> shane2, learn pure functional language first you'll have fun.
17:58:38 <Saizan> adnap: though i guess that if you want to look at the results from C you need some intellegible chunk of bytes, which you could produce with a Storable instance for example
17:58:55 <lispy> shane2: In my experience the order is less important, but you should consider learning languages that represent the various major paradigms
17:59:25 <shane2> lispy, what languages would u say then?
17:59:47 <illissius> adnap: you can return StablePtrs
17:59:53 <kyagrd> lispy, I think it's good to learn functional languages with ADTs before learning about trees and linked lists.
17:59:55 <lispy> C -- imperative, Java/C# -- "industry OO languages", Haskell -- functional programming, python -- dynamically typed, prolog -- logic, agda -- dependently typed, etc
18:00:00 <akapra> shane2, with high probability, you already have a rough idea of what programming looks like. Haskell is "esoteric" in this sense, so maybe it's better to start with an imperative language, like python.
18:00:16 <msieradzki> eww python
18:00:24 <msieradzki> smells like VB/PHP
18:00:29 <RyanT5000> what's the term for an EDSL implemented via a GADT and an interpreter, as opposed to one implemented directly in functions?
18:00:34 <mauke> msieradzki: no, it doesn't
18:00:43 <jbapple> How can I run a fast mapM_ on a mutable vector? Do I need to know something about fusion?
18:00:55 <RyanT5000> it's something like "loose" versus "tight", but i don't think those are the terms
18:01:23 <c_wraith> deep and shallow?
18:01:28 <RyanT5000> yeah, that's it
18:01:30 <shane2> well i was thinking of c,c++, java, python, perl, visual basic, sql and stuff
18:01:35 <jbapple> In particular, I'm not really sure how to get a Stream from an MVector
18:01:41 <RyanT5000> "deep embedding" is the GADT version?
18:01:42 <lispy> RyanT5000: Well, I've seen approaches with gadts that model the function types in the target language using the ones in the host language.  And those have been called high-order abstract syntax, HOAS
18:01:47 <Saizan> RyanT5000: yep
18:01:57 <jbapple> Although I'm not sure that's what I should be asking in the first place :-)
18:02:04 <RyanT5000> cool, thanks guys
18:02:16 <Saizan> RyanT5000: well, not necessarily GADT, even ADT works in some cases :)
18:02:29 <adnap> illissius: It says a StablePtr wont be affected by garbage collection, but there is no garbage collection in C, so I assume it's useful for other languages.
18:02:31 <RyanT5000> Saizan: yeah
18:02:45 <jbapple> Should I unsafeFreeze my MVector, maybe?
18:02:45 <RyanT5000> in my case, it's a GADT though
18:02:53 <shane2> is an ADT an abstract data type?
18:03:10 <RyanT5000> shane2: algebraic
18:03:13 <lispy> shane2: it can be.  Here we mean algebraic data type
18:03:14 <Saizan> Algebraic here
18:03:18 <kyagrd> shane2, in haskell and functionl languages ADT usually means algebraic data type.
18:03:23 <illissius> adnap: no, it means GHC won't garbage collect it (or otherwise move it around)
18:03:27 <RyanT5000> shane2: g = generalized
18:03:42 <shane2> oh ok i understand
18:03:43 <illissius> so it's safe to juggle it over the C and back and whatever
18:03:52 <adnap> illissius: Okay
18:03:53 <shane2> so haskell is a very mathematical programming language?
18:03:55 <lispy> shane2: algebraic because we have sum types and product types.  And recursive types
18:03:57 <illissius> *to
18:04:22 <kyagrd> inductive data type might have been a better name
18:04:47 <kyagrd> well maybe not because there are coinductive types and other strange things definable
18:04:53 <lispy> Do we have coalgebraic data types in Haskell?
18:05:18 <shane2> haha i think i just erupted an interesting subject 
18:05:39 <illissius> what about coalgebraic codata cotypes?
18:05:47 <lispy> :)
18:06:11 <lispy> map (co:) [algebraic, data, types]
18:06:22 <aristid> it would be pretty coincidental
18:06:29 <bcw> shane2, not as "mathematical" as some languages, but haskell is more closely tied to math than object oriented or imperative languages (basically everything a beginner has probably seen)
18:06:48 <shane2> what website would i download python? and anyone know the best site to use to learn it?
18:06:56 <shane2> oh ok i understand bcw
18:07:03 <bcw> shane2, python.org
18:07:29 <Twey> And diveintopython.org
18:07:36 <bcw> is where you would download it, and they have tutorials there too, but some people may think other sites are best for learning
18:07:43 <Twey> I'd recommend Lua over Python for learning purposes, though
18:07:49 <shane2> ok thx
18:08:22 <bcw> diveintopython.org is considered terribly presented by #python (you should consider going there too, if you want to learn python)
18:08:31 <Saizan> maybe you should take the language(s) you'll see in your first year of uni in consideration..
18:08:48 <akapra> Saizan, so you're suggesting java ;)
18:09:02 <shane2> whats uni?
18:09:06 <akapra> university
18:09:12 <shane2> haha im retarded
18:10:43 <Saizan> akapra: well the "consideration" might be "anything except those" :)
18:10:57 * ksf is befuddled
18:11:13 <shane2> well for my AS i gotta take html,css,c++,java,visual basic
18:11:16 <akapra> Saizan, ahahah, you're right :D
18:11:18 <ksf> there's no perfect hash implementations that are able to generate collisions?
18:11:54 <akapra> ksf, umh? can you rephrase?
18:12:27 <akapra> perfect hashes are built from a static set, the absence of collisions is guaranteed only for objects belonging to *that* set
18:12:28 <ksf> I have e.g. a full nibble with all permutations set that map to only 4 elements.
18:13:01 <bcw> shane2, all of those except visual basic are okay languages, but again they are mostly imperative and object oriented (css and html are declarative, but whatever)
18:13:04 <ksf> so, in a nutshell, I want to generate code that can transform a nibble into 0..4.
18:13:18 <deech> Hi all, I am building a cross-platform tool for Windows, Mac, Linux and Open Solaris. Do I have to build the compiler from scratch on Open Solaris?
18:13:42 <adnap> illissius: Where is the best place to read about using the FFI and StablePtrs?  I want to know how to take something like a list of a custom type and marshal it to C.
18:14:24 <shane2> so bcw......any advice on which to learn first to help me understand other languages better?
18:15:08 <adnap> illissius: Let's say I have this: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27824#a27824  Now, I want to maybe printf all of my Points in C.
18:15:11 <kyagrd> shane2, lambda calculus
18:15:36 <RyanT5000> so, is there any practical way to parameterize strictness?
18:15:53 <akapra> ksf, so you've partitioned all the configurations of a nibble into four sets?
18:16:04 <bcw> shane2, i'd at least learn html and css.  the others you can pick from, but the problem with them is, they wire your brain to think like the computer does (and not consider other ways of solving problems)
18:16:15 <ksf> akapra, exactly.
18:16:18 <mm_freak_> is there a way to restrict a type variable to be anything (allowed by the context) /but/ a certain type?
18:16:44 <mm_freak_> i need this to solve an overlapping instances problem
18:16:49 <akapra> ksf, can't you use the definition of the partitioning to assign codes?
18:17:36 <ksf> the definition of the partitioning is a dfa
18:17:45 <ksf> ...over a bit alphabet.
18:18:17 <RyanT5000> is there a typeclass for "const"
18:18:35 <RyanT5000> (in the same sense that Category is a typeclass for (.) and id)
18:19:10 <akapra> ksf, so what's the problem? it doesn't seem too slow to emulate four steps of a DFA 
18:19:17 <RyanT5000> and, if not, would it be reasonable to create a typeclass CategoryConst that supports it?
18:21:06 <ksf> akapra, I want to compile the bit dfa into one that works on words. as that's quite a reduction in bit tests.
18:21:22 <ksf> ...especially because the bit dfa will be generated from unicode/whatever dfa's.
18:22:26 <ksf> most importantly, it seriously reduces branching.
18:22:37 <ksf> less pipeline stalls, etc.
18:23:53 <akapra> yeah, but the hashing approach requires a table in the order of 2^n (n is the number of bits)
18:24:04 <akapra> maybe it's better to have some pipeline stalls
18:24:10 <mm_freak_> RyanT5000: what would be the type of 'const'?
18:24:20 <mm_freak_> const :: a b c -> b
18:24:23 <mm_freak_> something like that?
18:24:36 <ksf> 2^n would be a plain table lookup
18:25:15 * bcw wonders if shane2 was asking about which of *any* languages he should learn first, or only of those he gave.  i would have suggested prolog and maybe lisp (as well as haskell) to give him an idea of other kinds of languages
18:25:56 <RyanT5000> mm_freak_: const :: CategoryConst cat => b -> cat a b
18:26:08 <mm_freak_> oh, yeah, makes more sense
18:26:19 <mm_freak_> but out of curiousity, what would you need that for?
18:26:31 <akapra> ksf, so, what's the problem? take a routine that builds a perfect hash upon all the configurations of your nibble / word and fill it with the partition number
18:26:31 <RyanT5000> mm_freak_: well, i have an Arrow-based EDSL
18:26:41 <RyanT5000> and it turns out that using arr (const blah) is pretty inefficient
18:26:51 <RyanT5000> (arr is my nemesis)
18:27:07 <Veinor> arr!
18:27:10 <ksf> the problem is that every single library I came across doesn't take values.
18:27:33 <ksf> ...they hash multi-byte keys to integers.
18:27:38 <RyanT5000> so i'd like to be able to have a constructor in my deep embedding GADT like this: Const :: b -> MyArrow a b
18:28:00 <mm_freak_> RyanT5000: you seem to do much more with arrows than i do…  each time i tried to write an arrow i found myself saying:  well, i can force this to be an arrow, but it's stupid…  it's much easier without an arrow
18:28:12 <mm_freak_> the only arrow that makes a lot of sense to me is the function arrow
18:28:22 <RyanT5000> mm_freak_: well, i made an incremental computation arrow
18:28:45 <akapra> ksf, oh, now I understand. Sorry, I can't help you with that
18:28:52 <RyanT5000> which saves every sub-result, so that when you make small changes to the input, it takes a small amount of recomputation to produce the new output
18:29:00 <RyanT5000> (for some reasonable definition of "small" in both places)
18:29:40 <mm_freak_> yes, but that too sounds like something, which i would write as a monad
18:30:05 <RyanT5000> mm_freak_: well, i don't want to impose any kind of ordering on it
18:30:29 <RyanT5000> (my arrows do not have side effects; at least not observable ones)
18:30:33 <mm_freak_> for a couple of days (since i tried yampa) i'm trying to understand the rationale behind arrows
18:30:53 <RyanT5000> honestly, for me, the main benefit of arrows is that i can make them with the arrow syntax
18:31:27 <RyanT5000> they give me a bit more of the structure of the underlying code
18:31:33 <mm_freak_> is there something in arrow syntax, which monad 'do' notation can't do?
18:32:06 <msieradzki> uhm why does yesod not have joins/anything really relational
18:32:12 <mm_freak_> i mean, i can always write "do y <- c1 x" instead of "do y <- c1 -< x"
18:32:15 <bcw> i just noticed shane2 /msg'd me asking how to avoid the problem, so i guess he was asking about what of any languages i'd suggest. <sigh>, i wish he'd stayed around long enough for me to think about it
18:32:58 <mm_freak_> as an experiment i tried to write something like this:
18:33:04 <mm_freak_> newtype a :-> b = ND { runNondet :: [a] -> [b] }
18:33:23 <mm_freak_> i found it doesn't give me any benefit over Monad []
18:33:46 <RyanT5000> mm_freak_: well, i'm not sure that arrows are fundamentally more expressive than monads, although i've heard people say that they are
18:34:06 <mm_freak_> i heard that, too
18:34:10 <RyanT5000> however, i think about them like i think about circuit diagrams
18:34:22 <RyanT5000> and while i might be able to think about monads the same way, i'm not sure how
18:34:57 <mm_freak_> well, something like:  turn every 'a b c' into 'b -> a c'
18:35:10 <mm_freak_> and turn 'y <- c -< x' into 'y <- c x'
18:35:11 <RyanT5000> basically, i'm not sure how to express the rule "(first f >>> second g) === (second g >>> first f)" in terms of monads
18:35:52 <mm_freak_> is that even true?
18:35:59 <RyanT5000> no, not in general :)
18:36:01 <RyanT5000> but i like it to be true
18:36:04 <RyanT5000> so it's true of my arrows
18:36:09 <mm_freak_> ok =)
18:36:22 <RyanT5000> (i'm told that that severely limits the power of my arrows)
18:36:27 <RyanT5000> well, i should be specific: it's semantically true
18:36:44 <RyanT5000> i don't mind if an arrow's implementation involves some order-dependence under the cover
18:37:06 <RyanT5000> one difference between what you're suggesting for a monad and arrows
18:37:12 <RyanT5000> is that arrows pipe values around differently
18:37:18 <mm_freak_> but by the way, there must be some strength lying in first/second and the arrow notation, which monads can't provide
18:37:27 <mm_freak_> i haven't understood that strength
18:37:32 <RyanT5000> well
18:38:17 <RyanT5000> if i could get rid of "arr", then there would be a very powerful thing going on: all the "real computation" would be happening in the arrow bits
18:38:24 <RyanT5000> which would be order-independent
18:38:32 <RyanT5000> which would mean you could automatically parallelize arrows
18:38:45 <RyanT5000> (with all the usually-attendant performance concerns)
18:39:01 <RyanT5000> but the point is that the Arrow notation exposes the data dependencies to the caller
18:39:11 <RyanT5000> (at least, it does unless you heavily use arr)
18:39:16 <RyanT5000> (which the arrow notation currently does)
18:40:42 <mm_freak_> 'arr' is also one bit, which confuses me a lot
18:40:55 <mm_freak_> it seems that every arrow represents some kind of function/mapping
18:41:11 <mm_freak_> and that ordinary functions can be lifted to them
18:41:29 <RyanT5000> yes
18:41:33 <mm_freak_> for monads only simple values are lifted (which is more general, actually)
18:41:37 <mm_freak_> that makes sense to me
18:41:38 <RyanT5000> i think arr is probably a mistake
18:42:00 <TacticalGrace> kfish: oh, didn't know you moved to Tokyo
18:42:09 <TacticalGrace> kfish: sounds great!
18:42:28 <Gracenotes> oh, hm, ICFP is in Maryland this year?  that's.. close to here!
18:42:33 <RyanT5000> i would prefer something like this: arr :: ArrowHaskell a => (b -> c) -> a b c
18:42:42 <RyanT5000> in the same way we have MonadIO with liftIO
18:43:03 <dcoutts_> Gracenotes: ah, in that case you should definitely go, and present something at the HIW
18:43:08 <RyanT5000> my arrows, e.g., implement arr as lift . arr
18:43:14 <mm_freak_> RyanT5000: how is that related?
18:43:20 <RyanT5000> mm_freak_: arrow transformers
18:43:24 <RyanT5000> (->) is an arrow
18:43:46 <RyanT5000> so you only get to lift (a -> b) into your arrow if (->) is the bottom of your arrow stack
18:43:50 <Gracenotes> it would conflict with school, though nothing I can't make up. hm, maybe amtrak passes closeby
18:44:02 <mm_freak_> i don't know how arrow transformers work
18:44:13 <RyanT5000> they're just like monad transformers
18:44:18 <mm_freak_> what's the type of an arrow transformer?  or is that something, which can't be expressed as types directly?
18:44:39 <RyanT5000> http://hackage.haskell.org/packages/archive/arrows/0.4/doc/html/Control-Arrow-Transformer.html#t%3AArrowTransformer
18:45:27 <mm_freak_> that's over my head yet
18:45:32 <mm_freak_> let me understand arrows first =)
18:45:36 <RyanT5000> haha alright :)
18:46:06 <mm_freak_> the argument i hear mostly of arrows is higher performance
18:46:20 <mm_freak_> and when i look under the hood of some arrow types, they mostly look like a DSL
18:46:28 <RyanT5000> yeah
18:46:36 <mm_freak_> while the parser monad is a state monad, the parser arrow is a DSL
18:46:51 <RyanT5000> yeah; i'm only using Arrows like DSLs right now
18:46:59 <RyanT5000> the thing is, they're DSLs that get some access to sharing info
18:47:08 <RyanT5000> and data flow info
18:47:27 <RyanT5000> without doing any kind of StableName hackery
18:47:57 <mm_freak_> hmm
18:49:02 <mm_freak_> can you recommend a simple arrow, which i could implement, which might enlighten me?
18:49:30 <RyanT5000> hm
18:50:03 <RyanT5000> i'm not sure i know any simple ones; i just recently dove into Yampa's source and started learning from there
18:50:40 <RyanT5000> well, you could try implementing something like ArrowReader, which is basically like MonadReader
18:51:06 <RyanT5000> there's already an implementation of that
18:51:20 <RyanT5000> maybe browse around the "arrows" package
18:51:42 <tg_zzz> i would also look at the packages related to visualizing arrows
18:52:26 <mm_freak_> looks like (->) is the "identity" arrow
18:52:30 <mm_freak_> is that true?
18:53:10 <RyanT5000> mm_freak_: i don't think so; i think it's more akin to IO
18:53:29 <RyanT5000> though perhaps not
18:53:43 <RyanT5000> Identity doesn't do anything
18:53:52 <mm_freak_> well, the 'arrows' package provides a ReaderArrow, but that's a transformer
18:54:07 <RyanT5000> yeah; practically everything is a transformer
18:54:13 <mm_freak_> using (->) as the underlying arrow, it gives the classic reader monad/whatever
18:54:27 <RyanT5000> yeah, (->) does seem like Identity in that way
18:54:54 <RyanT5000> but it strikes me as much more powerful than simply being analogical to Identity
18:55:27 <mm_freak_> what's the difference between the reader monad and the reader arrow?  i have the impression that i can change the type of the environment
18:56:30 <RyanT5000> yes, it looks like you can
18:56:37 <RyanT5000> which makes sense to me
18:57:17 <RyanT5000> basically, it makes the environment available anywhere within a "block" of the circuit
18:57:35 <RyanT5000> (i'm very attached to my circuit metaphor for now - i've only been seriously working with arrows for about 5 days)
18:58:07 <RyanT5000> oh, no
18:58:11 <RyanT5000> it looks like you can't change the type
18:58:26 <RyanT5000> there's a fundep
18:58:55 <ksf> no cryptographers here? number theorists?
18:59:58 <ksf> I'd like to have an algorithm to find a hash function for a partitioning of [0..2^n] into m sets.
19:00:18 <ksf> that is, design a hash to collide at specific places.
19:00:55 <dnul> ksf: i can read you... 
19:01:42 <monochrom> use withReader to change type of environment
19:02:26 <mm_freak_> monochrom: i think, you missed the context
19:02:52 <mm_freak_> ksf: well, the obvious method would be to use modulo
19:02:54 <Ziphilt> i implemented a function that takes a string of digits and converts it into that integer
19:02:58 <Ziphilt> i feel successful
19:03:00 <monochrom> because I am not run in a reader monad XD
19:03:07 <Ziphilt> did one already exist?
19:03:19 <ksf> mm_freak_, I wasn't totally clear, those sets aren't continuous.
19:04:10 <mm_freak_> ksf: modulo isn't continuous either
19:04:34 <tg_zzz> @src ToInt
19:04:35 <lambdabot> Source not found. Where did you learn to type?
19:04:36 <mm_freak_> x `mod` n puts x into one of n equivalence classes
19:05:15 <dnul> mgv: puto
19:05:55 <mm_freak_> > sum . zipWith (*) (iterate (*10) 1) . map (fromIntegral . subtract (ord '0') . ord) . reverse $ "1374"
19:05:56 <lambdabot>   1374
19:07:01 <ksf> time for an example.
19:08:58 <ksf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27827#a27827
19:09:20 <ksf> the input to the hash is 0..2^4, the output a,b,c or d.
19:10:06 <mm_freak_> ksf: unless there is some pattern or some simple function mapping the values to a class, you'll need a table
19:10:37 <ksf> I've got the dfa that the table is generated from, if that helps.
19:10:47 <mm_freak_> 'dfa'?
19:10:54 <ksf> but I was hoping that there's a method to compute a hash for such tables.
19:11:00 <ksf> deterministic finite automaton
19:11:15 <mm_freak_> the length of the hash must be at least double the length of the numbers
19:11:20 <mm_freak_> because of the birthday paradox
19:11:25 <ksf> ...that's four state transitions rolled into one on a nibble.
19:11:25 <mm_freak_> so hash functions don't help
19:11:41 <mm_freak_> why not use the dfa?
19:11:56 <ksf> because bits aren't particularily efficient to work with.
19:12:14 <mm_freak_> then you need a table
19:12:27 <mm_freak_> something like UArray Int Category will do
19:12:48 <mm_freak_> (assuming that Category can be unboxed)
19:13:06 <ksf> I'm going to generate code via th
19:13:26 <mm_freak_> code to do the lookup?
19:13:34 <ksf> yep. the whole dfa, in fact.
19:13:57 <mm_freak_> note that fetching an element from a UArray is an O(1) operation and probably the fastest you can get
19:14:23 <mm_freak_> and you don't need TH for that
19:14:45 <ksf> but that'd be something like 265 * states of the dfa bytes, which is bound to blow the cache.
19:14:58 <mm_freak_> and additionally, the UArray is the most compact representation you can get
19:15:06 <mm_freak_> the actual value is implicit
19:15:38 <mm_freak_> unless you run the DFA, that table is going to be encoded in some way anyway
19:18:48 <mm_freak_> ksf: how large is 'n' and how many classes are there?
19:20:41 <ksf> n is at least 8, and at most 128, at least on my machine. I'd be fine with almost anything. I can't say anything about the classes, that depends on the specific dfa.
19:21:08 <ksf> they're at most as big as the number of states in the dfa, but might also be smaller.
19:21:13 <mm_freak_> UArray is fine for n = 8
19:21:24 <mm_freak_> for n = 128, you will have to run the DFA
19:21:55 <ksf> well, looking up the table _is_ part of running the dfa.
19:22:05 <ksf> ...just n steps at a time.
19:22:53 <mm_freak_> how can that be?  you can't have a lookup table for 2^128 elements
19:23:30 <ksf> ...that's why I am investigating hashing.
19:23:46 <ksf> 128 bits is my widest integer register.
19:24:02 <mm_freak_> hashing won't help…  you need a compact function to map one of those values to a class
19:24:56 <mm_freak_> continuous integral numbers (and anything equivalent to them) are the most compact representation possible
19:25:44 <ksf> ...a table of 128 numbers isn't smaller than shiftL 2 to partition the set.
19:26:04 <mm_freak_> 128 numbers?
19:26:10 <mm_freak_> i think, we're talking about 2^128
19:26:30 <ksf> the problem is whether such a function, or combination of functions, exists for a specific mapping.
19:27:46 <ksf> I wouldn't care if the algorithm bails out if it can't find anything, I can always fall back to a 256-element table.
19:28:05 <mm_freak_> let's restate the problem:  you have 2^n input numbers and each of them is associated with a class…  there is a complex function to calculate the class out of every such input number
19:28:11 <mm_freak_> did i get this right?
19:28:16 <ksf> yes.
19:28:20 <Rotaerk> 2^128 ~ 64 * 10^36
19:28:25 <mm_freak_> and n can get as large as 128?
19:28:29 <ksf> the function is regular, though. no turing completeness involved.
19:28:44 <ksf> on my machine, yes. _in principle_, that is.
19:29:00 <mm_freak_> ok, what do you need?  a precalculated lookup table or a cache?
19:29:03 <ksf> dunno what would be the most efficient way to do it, I guess 32 or 64.
19:29:23 <mm_freak_> even with n = 32 a complete table is going to blow your RAM
19:29:30 <ksf> yep.
19:29:39 <mm_freak_> → what do you need?  a precalculated lookup table or a cache?
19:29:57 <ksf> ...but I can fall back to four steps of 256-byte table lookups.
19:30:19 <ksf> I need a way to find the next state, in ideally the most efficient way.
19:31:02 <mm_freak_> what is the current and the next state?
19:31:47 <ksf> ...that depends on the dfa, of course.
19:32:22 <mm_freak_> i mean, how would a table help to do that lookup?
19:32:29 <mm_freak_> uhm
19:32:33 <mm_freak_> that transition
19:32:35 <ksf> the example I posted is the table for four bits when you're at table A
19:32:40 <ksf> er state A
19:32:57 <ksf> ...it's got a self loop on 0, so obviously you stay in A, then, etc.
19:33:42 <mm_freak_> so your "class" is actually a state
19:33:47 <ksf> yep.
19:34:07 <mm_freak_> how are the numbers involved?
19:34:25 <jmcarthur> what are you trying to do, memoization?
19:34:34 <mm_freak_> to generate anything (cache/lookup table) you first need some relation
19:34:47 <mm_freak_> if that relation differs from DFA to DFA, the method of optimization probably does, too
19:35:03 <ksf> in the example, two trailing 0s mean that the transition goes to A.
19:35:08 <ksf> ...in every case.
19:35:22 <mm_freak_> two trailing zeroes of what?
19:35:41 <Cale> What's up?
19:35:58 <ksf> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27827#a27827
19:36:02 * hackagebot vorbiscomment 0.0.1 - Reading of Vorbis comments from Ogg Vorbis files  http://hackage.haskell.org/package/vorbiscomment-0.0.1 (ChrisWagner)
19:36:02 <ksf> of the nibble. in that case.
19:36:31 <Cale> Trying to guess the structure of a DFA from sample input?
19:36:54 <mm_freak_> sounds like he's trying to optimize a state transition by making a lookup table
19:37:18 <mm_freak_> instead of invoking a lengthy calculation, that is
19:37:36 <ksf> well jumping to another state for every bit in the input is just inefficient.
19:37:57 <mm_freak_> anyway, in this case, if only two bits are involved, use a UArray
19:38:11 <jmcarthur> so you're wanting to precompute it, or just memoize it?
19:38:48 <ksf> precomputing it is easy, compiling it to the fastest possible code is hard.
19:39:23 <mm_freak_> well, again:  a UArray is the fastest possible data structure, and in most cases also the most compact one
19:39:38 <ksf> oh, and practically speaking, that example is very extreme, it matches binary strings containing 0*101.*
19:39:52 <ksf> I know.
19:40:03 <mm_freak_> and as a side note:  doing lookups in code (e.g. through pattern matching) is one of the worst solutions in almost all cases
19:40:10 <ksf> but data structures aren't necessarily more compact or faster than code.
19:40:32 <ksf> at least in the binary tree case, it's way faster.
19:41:05 <ksf> ...if the tree is sparse enough, at least.
19:43:07 <mm_freak_> i mean:  if you want to do lookups, you're going to use some data structure
19:43:45 <ksf> the dfa is static at compile time.
19:43:45 <mm_freak_> a "lookup" being naive mapping of some key to a value
19:45:54 <ksf> ...the whole library is meant to be optimised to parse regular grammars that stay constant during run-time, like e.g. a network protocol.
19:46:17 <jmcarthur> how much redundancy is in this?
19:46:23 <jmcarthur> can it actually be compressed?
19:46:30 <jmcarthur> because if not this is pointless
19:47:29 <ksf> compression is a good prompt.
19:48:22 <mm_freak_> that was basically my question
19:48:26 <ksf> jmcarthur, redundancy depends on the dfa.
19:48:45 <ksf> in practice, it's going to be way higher than in the example
19:48:46 <mm_freak_> and as said:  the way you optimize this depends on the DFA
19:49:07 <jmcarthur> what exactly are you doing? compiling DFAs to programs?
19:49:27 <ksf> ...as this is a dfa directly defined over bits, and not a bit dfa generated from a byte or utf8 dfa.
19:49:32 <ksf> yes.
19:50:08 <ksf> single-bit loops, e.g., would be rare in practice.
19:51:42 <jmcarthur> there's always http://en.wikipedia.org/wiki/Karnaugh_maps
19:51:52 <jmcarthur> but have fun solving those for huge inputs
19:52:30 <jmcarthur> there are faster ways to do that
19:52:32 <jmcarthur> but still
19:52:55 <jmcarthur> http://en.wikipedia.org/wiki/Binary_decision_diagram
19:52:56 <ksf> I'm not worried about compilation speed, I can deal with stalin-like performance.
19:53:16 <jmcarthur> i think TAoCP discusses this stuff
19:53:51 <jmcarthur> one of the later fascicles i think
19:54:20 <jmcarthur> aha, volume 4 fascicle 1
19:54:35 <jmcarthur> draft available for download: http://www-cs-faculty.stanford.edu/~knuth/fasc1b.ps.gz
19:56:22 <ksf> jmcarthur, you just saved my day.
19:57:03 <jmcarthur> :D
20:05:57 <ksf> ahh would but all authors write like knuth
20:08:44 <p_l> somepeople had been waiting for vol4 for over 30 years...
20:10:29 <pikhq> Volume 4's coming out in a few months.
20:14:59 <manjunaths> what is volume 4 ?
20:15:31 <manjunaths> ah art of programming
20:19:10 <EvanR> what do you guys think of implementation inheritance
20:20:23 <sshc> What are some commonly used arrows?
20:20:24 <ksf> useful in 0.001% of the cases where it's commonly used.
20:20:32 <ksf> (,) is the most commonly used.
20:21:01 <EvanR> ksf: alternative for the 99.998% ?
20:21:08 <Veinor> implementation inheritance?
20:21:19 <ksf> getting rid of java and c++.
20:21:24 <EvanR> ah
20:22:13 <ksf> if you really feel like taking the fixed point of a record, go for it.
20:22:27 <ksf> it's useful in some cases.
20:22:39 <EvanR> im trying to actually understand this stuff
20:22:46 <Philippa> I wish it were easier to do sometimes, and it's definitely tedious delegating with instances
20:23:08 <EvanR> taking the fixed point of a record?
20:23:20 <ksf> http://yi-editor.blogspot.com/2008/12/prototypes-encoding-oo-style.html
20:24:51 <EvanR> wow
20:25:18 <EvanR> head explode
20:26:25 <sshc> How do I enable arrows in the source?
20:29:18 <monochrom> too bad moonpatio is gone. I had similar examples there. I called it "ooopen recursion"
20:29:32 <sshc> Is all I need -farrows?
20:30:33 <monochrom> I forgot whether -farrows works. I use {-# LANGUAGE Arrows #-}
20:31:28 <monochrom> also you need either for the "proc x -> do ..." notation only. if you don't use that notation, you don't need extensions.
20:32:04 <sshc> monochrom: I am.  If {-# LANGUAGE Arrows #-} works, then I certainly want to use that.
20:46:10 <mm_freak_> ksf: (,) is an arrow?!
20:46:15 <mm_freak_> how?
20:46:42 <Axman6> @src Arrow
20:46:42 <lambdabot> class Arrow a where
20:46:42 <lambdabot>     arr, pure   :: (b -> c) -> a b c
20:46:42 <lambdabot>     (>>>)       :: a b c -> a c d -> a b d
20:46:42 <lambdabot>     first       :: a b c -> a (b,d) (c,d)
20:46:42 <lambdabot>     second      :: a b c -> a (d,b) (d,c)
20:46:44 <lambdabot>     (***)       :: a b c -> a b' c' -> a (b,b') (c,c')
20:46:46 <lambdabot>     (&&&)       :: a b c -> a b c'  -> a b (c,c')
20:46:52 <ksf> > first toUpper ('a','b')
20:46:53 <lambdabot>   ('A','b')
20:47:07 <Veinor> (b -> c) -> (b,c)  is a populated type?
20:47:29 <mm_freak_> ksf: that's (->), not (,)
20:47:34 <ksf> hmmm
20:47:34 <monochrom> @djinn (b -> c) -> (b,c)
20:47:35 <lambdabot> -- f cannot be realized.
20:47:38 <ksf> well, yes.
20:47:50 <ksf> still, that's the most widely used thing.
20:48:01 <mm_freak_> i'm struggling with arrows right now
20:48:28 <mm_freak_> trying to find other arrows than (->), for which monads are really less convenient or even impossible
20:49:16 <Veinor> > (first toUpper) ('a', 'b')
20:49:17 <lambdabot>   ('A','b')
20:49:31 <Veinor> @src (,) First
20:49:31 <lambdabot> Source not found. My pet ferret can type better than you!
20:49:35 <Veinor> @src (,) first
20:49:35 <lambdabot> Source not found. I feel much better now.
20:49:39 <Veinor> @src first (,)
20:49:39 <lambdabot> Source not found. Do you think like you type?
20:49:40 <Veinor> bah
20:51:34 <monochrom> the only non-monad arrow I know is a bit advanced. some kind of parser of a clever design and unusual feature. I wouldn't demand it as a beginner.
20:52:03 <monochrom> In fact, when I was a beginner I didn't demand it, and therefore I made great progress.
20:52:54 <mm_freak_> @src (->) first
20:52:55 <lambdabot> first f = f *** id
20:53:38 <mm_freak_> monochrom: it doesn't have to be non-monad, just maybe "more elegant" than a monad
20:54:31 <monochrom> a->[b] is sometimes more elegant as arrow than as monad
20:55:15 <mm_freak_> i tried to write an [a] -> [b] arrow and found it has no advantage
20:56:05 <monochrom> more elegant as arrow when you pretend "a->[b] means multi-answer function from a to b" and start doing function composition f >>> g >>> h
20:56:34 <mm_freak_> well, there is (>=>)
20:57:01 <monochrom> people never thought of >=> until arrow became well-known
20:57:46 <monochrom> so it's really >=> stealing from >>>, proving that arrow is more elegant, so elegant monad has to steal ideas from it.
20:57:59 <mm_freak_> are you sure?  it was one of the first monad functions i asked for before getting in touch with arrows at all
20:58:13 <mm_freak_> and i'd probably have written it, if i hadn't found it
20:58:22 <monochrom> then you are a genius. but I am sure.
20:58:33 <listofoptions> :t (>=>)
20:58:34 <lambdabot> forall a (m :: * -> *) b c. (Monad m) => (a -> m b) -> (b -> m c) -> a -> m c
20:58:39 <mm_freak_> why a genius?
20:58:52 <mm_freak_> it appears to be natural for me to ask for a (.) for monads =)
20:58:58 <monochrom> because you independently invent things
20:59:07 <mm_freak_> and that would be flip (>=>) or (<=<)
20:59:09 <Cale> (>=>) is really old
20:59:16 <monochrom> yes yes yes all genius say "it's natural to me"
20:59:16 <Cale> or (<=<), rather
20:59:26 <Cale> It's older than Haskell, for sure :)
20:59:32 <mm_freak_> hehe, true
20:59:48 <mm_freak_> (@ Cale, that is)
21:00:58 <mm_freak_> the time when i really felt like i was reborn is when i found Control.Applicative
21:01:23 <mm_freak_> (and when i discovered haskell, of course)
21:04:30 <Cale> Control.Applicative didn't seem all that special to me until I realised that it was also a generalisation of the SK calculus :)
21:08:11 <gwern> Cale: oh of course
21:08:16 <ksf> any hints on what bdd library I should use?
21:08:17 <gwern> how extremely stupid of me not to realize that
21:09:05 <ksf> I'd prefer a dumbed down interface where I can specify a truth table and get a function out...
21:10:14 <gwern> ksf: just go use knuth's MMIX stuff!
21:10:28 <gwern> I keep hearing how nice our FFI is, so why not use it?
21:10:53 <ksf> ...does it include a bdd reducer?
21:11:24 <gwern> if a reducer is of any use, I'm sure he included it. he's something of a completist
21:12:06 <ksf> ...why would the mmix distribution include bdd's, in the first place?
21:14:10 <ksf> he writes great books, but apparently doesn't know how to include directories in tarballs...
21:15:36 <gwern> ksf: apparently bdds and zero bdds are incredibly useful for a whole bunch of combinatorial problems and whatnot, and knuth did a whole fasicle on them last year
21:15:49 <gwern> )I tried to read it, but quickly got lost)
21:15:55 <ksf> yes.
21:16:18 <ksf> although they're mindboggingly useful, we don't have a proper library for them.
21:16:53 <ksf> there's obdd, which links to a useable library, which doesn't seem to have its source available.
21:17:14 <gwern> they're pretty new and esoteric. wouldn't surprise me if no haskeller has bothered to write something
21:17:49 <ksf> early 90's is new?
21:18:16 <ksf> what I don't get is how one can write a library for a thesis and then not publish it.
21:23:53 <gwern> ksf: for something as fundamental as this? early 90s is pretty late in the game
21:24:27 <gwern> in cs, pretty much everything feels like it was invented in the 50s or 60s, and everything since has been variants - ooh, *lazy* parsing! ooh, *offline* regexps!
21:36:17 <manjunaths> using Data.ByteString.Lazy.Char8 how do I read a file line by line ?
21:36:34 <mm_freak_> manjunaths: readFile and lines
21:36:52 <manjunaths> mm_freak_, thanks
21:37:11 <mm_freak_> at least if you want to /process/ it line by line
21:37:25 <mm_freak_> if you really want to /read/ line by line, you have to set a proper buffering method first
21:38:50 <ksf> you _never_ want to use line buffering
21:38:59 <ksf> ...use a proper line editor, instead.
21:39:12 <mm_freak_> you never want to use a line editor
21:39:18 <mm_freak_> use a proper emacs instead
21:39:33 <ksf> emacs is neither proper nor an editor.
21:39:39 <mm_freak_> ;)
21:40:09 <handonson> manjunaths: 1. open the file and get the handle for that file, using a function in System.IO (forgot the exact name... openFile?)
21:40:10 <ksf> it's the earliest documented large-scale dos attack.
21:40:24 <mm_freak_> handonson: withFile
21:40:33 <handonson> yeah that's usually the better practice
21:40:53 <handonson> manjunaths: 2. hGetLine (in Data.ByteString. ...) with that handle
21:41:52 <handonson> I'm almost sure there's an hGetLine in Data.ByteString.Lazy.Char8
21:42:01 <mm_freak_> well, in that case i'd use strict bytestrings…  if you use lazy bytestrings anyway, you can use readFile and lines
21:42:07 <manjunaths> hmm...
21:42:23 <manjunaths> I am doing something slightly different
21:42:27 <mm_freak_> (or do it properly and use iteratee, but i don't want to confront manjunaths with that yet) =)
21:42:34 <manjunaths> readFile with L.lines
21:42:42 <ksf> lazy bytestrings are going to read everything that's available and fits into a 512byte or something buffer.
21:42:45 <handonson> yeah i personally prefer to use strict ByteStrings and control the reading process by myself
21:42:54 <manjunaths> handonson, ok
21:43:03 <mm_freak_> ksf: that why i made the distinction between /reading/ and /processing/
21:43:40 <mm_freak_> manjunaths: there is both 'readFile' and 'lines' in all Data.ByteString.*Char8
21:43:43 <ksf> in general, how you read shouldn't matter.
21:44:38 <manjunaths> this is small test program to learn how to read
21:44:48 <manjunaths> I have a file with 4 int's in each line
21:44:56 <manjunaths> and a function that takes 4 int's
21:45:02 <Cale> Lazy ByteStrings have been pretty carefully tuned to use chunk sizes that result in good performance.
21:45:11 <manjunaths> so I need to read the Int's and give it to func
21:46:23 <mm_freak_> manjunaths: you may want to try writing a real parser using, say, attoparsec or one of the recent parsecs (>= 3.0)
21:47:06 <manjunaths> mm_freak_, ok, but why ?
21:47:21 <handonson> hey, i'm just curious, but can parsec parsers parse ByteString with ByteStrings and return ByteString?
21:47:33 <manjunaths> handonson, you can pack and unpack
21:47:49 <handonson> manjunaths: which is very undesirable
21:47:52 <manjunaths> handonson, of course that is not the answer you were looking for probably :-)
21:48:00 <manjunaths> handonson, heh...yeah
21:48:05 <mm_freak_> manjunaths: there is a great parsec tutorial here: http://legacy.cs.uu.nl/daan/download/parsec/parsec.html
21:48:43 <manjunaths> mm_freak_, thank you
21:49:05 <mm_freak_> handonson: parsec >= 3.0 can parse ByteString
21:49:09 <handonson> i know
21:49:27 <manjunaths> in writing a simple opengl program and debugging it I am getting the opportunity to learn things that I haven't even imagined in haskell ;-)
21:49:33 <mm_freak_> and all (monadic) parsers can return ByteString, of course =)
21:49:40 <manjunaths> but that is a good thing I think
21:49:42 <handonson> my question is whether I can parse ByteString 'with' ByteStrings and 'return' ByteString, without packing/unpacking overhead
21:50:09 <mm_freak_> handonson: you mean, for example, to match against ByteStrings?
21:50:11 <manjunaths> because I am trying to learn haskell...although I am concerned that one single opengl program is taking me a month to write
21:50:17 <handonson> mm_freak_: exactly
21:50:23 <mm_freak_> handonson: yes, attoparsec can do that
21:50:28 <mm_freak_> it's tuned specifically for speed
21:50:37 <handonson> the only reason i'm considering to switch from Parsec to attoparsec is this
21:50:50 <mm_freak_> i'm using attoparsec for my projects
21:50:57 <mm_freak_> i'm happy with it
21:51:19 <handonson> and I thought it would be silly to switch and use a new package if Parsec can do the same
21:51:51 <mm_freak_> manjunaths: most haskell programmers have the desire to REALLY understand things
21:51:55 <handonson> so there is my question
21:52:07 <mm_freak_> if you can suppress this desire, you can get programs done very fast
21:52:41 <mm_freak_> handonson: dunno, i have the impression that attoparsec is much simpler
21:52:53 <mm_freak_> and it's also /way/ faster even if you don't use ByteString matching
21:53:09 <handonson> why is it attoparsec
21:53:13 <handonson> what is atto
21:53:39 <handonson> a wild guess: at the top of parsec
21:53:44 <mm_freak_> i think it's something like "milli" and "micro", but much smaller
21:53:51 <handonson> oh
21:53:54 <manjunaths> mm_freak_, then I am not confident I will finish my program anytime soon
21:53:57 <manjunaths> :-)
21:54:06 <handonson> wow that makes sense man
21:54:23 <handonson> since parsec is such a long distance for human
21:55:22 <manjunaths> Debug.Trace why doesn't one need to put this in a do construct even though it does IO ?
21:55:43 <Jafet> It... doesn't.
21:55:53 <Jafet> @hoogle trace
21:55:53 <lambdabot> Debug.Trace trace :: String -> a -> a
21:55:53 <lambdabot> Network.HTTP.Base TRACE :: RequestMethod
21:55:53 <lambdabot> module Debug.Trace
21:56:02 <manjunaths> but it prints stuff
21:56:09 <Jafet> Unsafely.
21:56:20 <mm_freak_> manjunaths: 'do' is just syntactic sugar
21:56:32 <manjunaths> mm_freak_, but it is required for IO ?
21:56:52 <mm_freak_> manjunaths: try this:  main = getArgs >>= mapM_ (readFile >=> putStr)
21:56:57 <mm_freak_> no 'do' =)
21:57:15 <manjunaths> mm_freak_, but it has >>= which is like <-
21:57:21 <mm_freak_> it's not "like"
21:57:23 <mm_freak_> it's the same
21:57:46 <manjunaths> yes...ok
21:57:59 <mm_freak_> (technically there is a minor difference, though, when it comes to pattern matching)
21:58:17 <manjunaths> now if I need to do a print I need a >> or a >>=
21:58:28 <handonson> manjunaths: afaik trace breaks the rule that no function can cause side-effect unless it is monadic
21:58:36 <manjunaths> handonson, ah
21:58:42 <mm_freak_> (i've never used Debug.*)
21:58:42 <handonson> manjunaths: so it is a rule breaker, and it's there only for convenience
21:58:50 * Jafet guess: trace msg x = unsafePerformIO (putStr msg) `seq` x
21:59:03 <handonson> manjunaths: and it MUST not be used for any reason other than debugging
21:59:06 <manjunaths> Jafet, ok
21:59:16 <manjunaths> handonson, ok
21:59:23 <manjunaths> I understand
21:59:32 <manjunaths> so monads are not required for IO :-)
21:59:38 <mm_freak_> they are
21:59:44 <mm_freak_> 'do' notation for monads is not required
21:59:56 <mm_freak_> :t (>>=)
21:59:57 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
22:00:15 <c_wraith> well, there were versions of haskell before the Monad formulation of IO.  But the Monad formulation turned out to be much easier to use than the previous approaches.
22:00:27 <mm_freak_> true
22:00:40 <Jafet> IO is a Monad, so normal usage of IO requires Monad.
22:00:46 <handonson> instead there was this... action list concept, iirc
22:00:49 <mm_freak_> and it's also wrong that monads are required in general…  there is at least one other approach used by the language Clean
22:01:22 <manjunaths> mm_freak_, ok
22:01:24 <dolio> Clean's approach is just to use the underlying implementation of IO that GHC uses.
22:01:46 <pikhq> Though it does seem that a non-monadic approach would confuse people less. The word "monad" seems to invoke an attitude of mysticism... :P
22:01:46 <dolio> With some fancy type system features that enforce correctness, instead of correctness by construction.
22:01:47 <mm_freak_> dolio: it uses state passing, right?
22:01:50 <manjunaths> ok
22:02:04 <dolio> Yes, you pass the real world around.
22:02:12 <handonson> i still can't imagine what Haskell would have been like without monads
22:02:18 <mm_freak_> pikhq: /using/ the IO monad is very easy and intuitive
22:02:23 <manjunaths> handonson, easier for newbies  ?
22:02:28 <mm_freak_> it's just the word that confuses people
22:02:35 <pikhq> mm_freak_: Yes, yes.
22:02:48 <pikhq> mm_freak_: It's just the attitude of mysticism that gets people.
22:03:11 <mm_freak_> yeah…  that's probably why microsoft prefers to avoid the word "monad", when it comes to C# and F# =)
22:03:28 <manjunaths> pikhq, but some questions like why monads are needed for IO. When there are non-monadic IO methods are never answered anywhere generically
22:03:37 <pikhq> Clearly we should've called it "Incantations" and had the operators "construct" and "bind", and have the run-time system *cast* the incantations.
22:03:37 <gwern> mm_freak_: but what will they call monoids?
22:04:04 <mm_freak_> gwern: i don't think there is such a notion at all in C#/F#
22:04:12 <pikhq> manjunaths: A "monad" is nothing more than a type with the functions (>>=) and return defined.
22:04:50 <pikhq> manjunaths: So, one can reasonably say there are no monadic functions on IO; there's just functions that operate on IO, which happens to be a monad.
22:05:05 <mm_freak_> manjunaths: as said, don't worry too much about what makes IO a monad…  the 'do' syntax is very easy to understand and use
22:05:08 <dolio> You don't need monads for IO. But the language you use for describing IO computations is a monad, and it's useful to notice that.
22:05:19 <Jafet> gwern: Secure Enterprise Association Groups
22:05:25 <manjunaths> hmm..that is interesting
22:05:30 <gwern> mm_freak_: you know there will be one eventually
22:05:31 <manjunaths> I am kinda getting it
22:05:34 <gwern> they envy us too much
22:05:35 <mm_freak_> just remember that (in IO) 'return' is not a language construct, but just something like a monadic identity function
22:05:45 <dolio> The old IO methods in Haskell would have allowed you to define an IO type that was a monad, too.
22:06:00 <mm_freak_> x <- return 3
22:06:02 <mm_freak_> makes x == 3 
22:06:05 <manjunaths> ok
22:06:06 <dolio> In fact, the continuation passing style IO looks a lot like monadic IO.
22:06:17 <dolio> Because they're similar in general.
22:06:32 <tensorpudding> monoids, now with 20% more agile
22:07:14 <mm_freak_> manjunaths: once you've learned to do IO in haskell without problems, you can start really understanding monads
22:07:23 <mm_freak_> personally i would start with State monads
22:07:39 <manjunaths> mm_freak_, yes that is what I am doing in fact
22:07:40 <pikhq> manjunaths: And remember: all the while, *there is absolutely no magic involved*.
22:07:51 <manjunaths> atleast I am happy I am going in the right direction
22:07:59 <dolio> The [Response] -> [Request] model is rather different. It's also kind of worse.
22:08:01 <pikhq> (well. The implementation of IO has a very tiny piece of magic in it. Irrelevant, though.)
22:08:04 <dolio> Since you can write deadlocks.
22:08:05 <mm_freak_> the Maybe and list monads are useful, too
22:08:07 <manjunaths> pikhq, yeah..heh
22:08:13 <manjunaths> mm_freak_, yes
22:08:14 <dskippy> For me, and I think a lot of people, it's not the word monad that's a turn off. It's not the concepts behind the monad. It's the fact that adding IO to a function that's deeply nested within my program requires changing the type signature of all the functions that have eventually called it. As a beginner in Haskell, I don't know how to get around that. 
22:08:24 <mm_freak_> and my personal (controversial) opinion is that monad transformers are one of the most powerful things haskell provides =)
22:08:36 <dolio> dskippy: Don't add IO to deeply nested functions.
22:08:38 <manjunaths> dskippy, Debug.Trace FTW!
22:08:42 <manjunaths> :-) sorry
22:08:58 <dskippy> manjunaths: Yeah, I do trace.
22:09:08 <mm_freak_> dskippy: you don't
22:09:11 <mm_freak_> =)
22:09:14 <Jafet> @quote oasis
22:09:15 <lambdabot> chromatic says: My productivity increased when Autrijus told me about Haskell's trace function. He called it a refreshing desert in the oasis of referential transparency.
22:09:19 <pikhq> dskippy: The answer: do *not* do IO to deeply nested functions. It is either room for nasty bugs, or debugging.
22:09:19 <dskippy> dolio: It's not really that simple for a lot of programs.
22:09:22 <dskippy> mm_freak_: What?
22:09:26 <manjunaths> dskippy, it helps if you have separated your code into pure and fnuctions which require do construct
22:09:28 <dolio> Yes, it is. :)
22:09:29 <mm_freak_> dskippy: you don't get around that
22:09:50 <manjunaths> dskippy, I learnt that with practical mistakes :-)
22:09:55 <pikhq> I should note, though, that good programs in *any* language tend not to do IO deeply nested down in with the computation of things.
22:10:13 <mm_freak_> well, i use StateT a lot
22:10:28 <pikhq> They tend to, instead, have computation and IO seperated.
22:10:45 <dskippy> It's just very different from other methods of programming. It exposes the internal workings of some functions that others consider to not be part of the interface. Haskell programmers consider it part of the interface.
22:10:59 <manjunaths> mm_freak_, there also pure functions should be called from StateT functions rather than polluting them I think
22:11:29 <pikhq> dskippy: Most of the time, an internal function doing IO is a bug.
22:11:30 <mm_freak_> dskippy: in fact, the type of a function tells a lot about how the function works in haskell
22:11:39 <mm_freak_> this is a feature unique to pure functional languages
22:11:49 <dskippy> For example I might have a function that gets an audio file. It's part of my music player. It's deep within my program. It's a black box. It gets an audio file. Now I decide I'll play with that function. Make it random. Make it read from a play list on the disk. Make it ask the user. 
22:11:52 <pikhq> dskippy: One of the major things about Haskell is that there's less room for bugs. :P
22:12:04 <mm_freak_> manjunaths: IMO it's not a mistake to stay in IO for a long time
22:12:06 <manjunaths> but the drawback (or is it advantage) is that one needs to think through the code before writing it
22:12:10 <pikhq> dskippy: Why would you have such a function *deep* in your function?
22:12:19 <dskippy> A lot of programming languages (all I know) just say "Yeah fine. As long as it takes no arguments and returns a string, fine"
22:12:20 <mm_freak_> it's a mistake to stay there /too long/
22:12:36 <pikhq> dskippy: Erm, program.
22:12:45 <manjunaths> mm_freak_, yes some of the function in opengl are just IO only
22:12:46 <pikhq> dskippy: Seriously, that is the sort of thing I beat people for doing in C.
22:12:48 <pikhq> *Beat*.
22:13:01 <handonson> dskippy: the idea is that in Haskell you separate the pure algorithm and the side-effectors. actually, this idea is seen in other languages as well. the popular Model-View-Controller model, for example, has a similar separation
22:13:05 <dskippy> pikhq: I'm just explaining what newbies have a problems with in Haskell.
22:13:11 <mm_freak_> manjunaths: actually you don't need IO for doing games, graphics, simulations and stuff
22:13:15 <mm_freak_> there is functional reactive programming
22:13:33 <manjunaths> mm_freak_, haha...I am far away from understanding that
22:13:37 <dskippy> pikhq: Also I believe there are plenty of reasons to have such a function nested deeping in the dynamic calls of a program and not be bad design.
22:13:54 <mm_freak_> manjunaths: are you coming from an imperative language?
22:13:59 <manjunaths> mm_freak_, what FRP needs is an amazing tutorial where someone
22:14:02 <manjunaths> mm_freak_, yes C++
22:14:09 <pikhq> dskippy: Believe me, it's almost certainly cause for violence.
22:14:10 <mm_freak_> don't worry, i came from C =)
22:14:26 <handonson> however, i have to admit that i had this moment, a while ago, that i freaked out realizing i had to change more than half of my functions to have the return type of IO a (i was writing an opengl script)
22:14:28 <manjunaths> mm_freak_, takes all the glut examples and ports them to FRP :-)
22:14:32 <dskippy> pikhq: Right...
22:14:34 <handonson> it doesn't happen any more
22:14:36 <manjunaths> mm_freak_, thanks that is reassuring
22:14:40 <pikhq> manjunaths: FRP is a bunch of nice concepts without a lot of good implementations.
22:14:50 <manjunaths> pikhq, I know :-(
22:14:53 <pikhq> dskippy: This is the C coder in me talking, BTW.
22:14:59 <mm_freak_> manjunaths: i started to understand FRP using yampa
22:15:04 <mm_freak_> and for some reason i hate GLUT
22:15:06 <mm_freak_> i use SDL
22:15:06 <handonson> because now i (think i) understand the appropriate way of separating pure algorithm and side-effectors
22:15:20 <pikhq> dskippy: Your "read a file" thing should probably be called from main, or be a callback from the UI.\
22:15:37 <manjunaths> mm_freak_, I am familiar with GLUT so I am starting with it, maybe I will move to SDL later. Currently I have problems reading in files...heh
22:15:53 <mm_freak_> handonson: i kinda split the effects into certain classes…  in a certain sense i split IO into many monads and stick them together
22:16:10 <mm_freak_> i do that using monad transformers
22:16:11 <handonson> mm_freak_: it seems there are many Haskellers who happen to be GLUT haters, including you and me
22:16:13 <mm_freak_> mostly StateT
22:16:23 <manjunaths> mm_freak_, interesting...
22:17:18 <dskippy> pikhq: I just completely disagree. Sorry. There are totally valid things to encapsulate that you may want to eventually change the internal definitions of to make them read from disk or something. It happens all the time in software engineering. This is not a dig on Haskell. It's just what people get hung up on.
22:17:22 <mm_freak_> (that's why i like to think of IO as one giant state monad, but some people don't like that analogy)
22:17:35 <dskippy> Or at least people I know. 
22:17:45 <handonson> mm_freak_: imagine the age before monad transformers
22:17:56 <pikhq> dskippy: I suppose these same people think that null pointers are a neat idea?
22:18:25 <mm_freak_> handonson: i can't, because i love my transformers =P
22:18:40 <pikhq> Or perhaps having arrays without index validation?
22:18:58 <dskippy> pikhq: What's with the off-topic insult? I suppose you just don't want to have a reasonable conversation about software design and instead just blindly defend your language like it's your baseball team or something?
22:19:26 <ksf> gwern, it was mid-60's to late 70's according to KNUTH
22:19:31 <pikhq> dskippy: ... I'm saying that being able to do arbitrary IO anywhere is about as stupid as null pointers is all. It may be non-obvious, but still.
22:20:11 <pikhq> Now if you'll excuse me, I'm going to shut up before I set the channel on fire.
22:20:21 <dskippy> In your opinion they are equally stupid. Doesn't mean that people who think one is a good idea would think others are. 
22:20:21 <mm_freak_> pikhq: yampa is a nice design and implementation, but has some minor problems
22:20:37 <mm_freak_> most of them can be worked around easily
22:21:01 <handonson> what if models and views had side-effects in the MVC model
22:21:10 <pikhq> mm_freak_: Ah, yeah. Still, it all feels like it's rough, proof-of-concept implementations.
22:21:25 <handonson> enabling side-effects everywhere is definitely not a good idea, even OOP people admit that
22:21:35 <mm_freak_> i think FRP is difficult to implement
22:21:51 <mm_freak_> just like a fast haskell compiler is difficult to implement
22:22:00 <mm_freak_> so just wait a couple of years =)
22:22:21 <pikhq> :)
22:22:26 <mm_freak_> handonson: OOP isn't necessarily an imperative style
22:22:39 <handonson> and then you'll be able to use a fantastic FRP implementation done by some smart guys with Ph.D, for free
22:22:44 <mm_freak_> in fact you can easily combine OOP and FP
22:22:59 <handonson> mm_freak_: technically, OO paradigm is a subset of imperative paradigm
22:23:29 <mm_freak_> handonson: why?  it's up to you whether you use destructive update or object passing
22:23:48 <mm_freak_> Number &Number::sqrt();
22:23:54 <dcoutts_> dskippy: I think the best argument is that you can't really encapsulate side effects well
22:23:59 <handonson> it's up to you and that's why it's imperative
22:24:11 <mm_freak_> it's up to you in haskell, too
22:24:50 <handonson> you can write a C code with referentially transparent functions, but it doesn't mean C is referentially transparent
22:24:51 <mm_freak_> every programming paradigm can be used in an imperative manner =)
22:25:06 <handonson> but this is not the point
22:25:19 <mm_freak_> it is:  OOP is a very generic concept
22:25:25 <handonson> no i mean
22:25:25 <dskippy> dcoutts: I guess I don't agree or disagree with that. But people are used to doing it all the time. Maybe Haskell is the only programming language that realizes this is bad and prevents it. But I'm just hoping to give people some insight on what people find hard to understand about Haskell. And even once they understand it, they find off-putting.
22:25:27 <handonson> it is not my point
22:25:34 <pikhq> And it does, in fact, get done in Haskell.
22:25:38 <dskippy> dcoutts: It's a decent point though.
22:25:41 <handonson> my point is that OO is a mainstream paradigm, and even OO people discourage doing side-effects everywhere
22:25:46 <mm_freak_> so a statement like:  "OOP can be used imperatively" is a statement like "the sky is blue"
22:25:57 <pikhq> dskippy: Haskell is not exactly about conventions. So, yeah. ;)
22:26:23 <dcoutts_> dskippy: of course one can also allow side effects, one simply has to tag the fact in the type, so the fact that there are possible side effects becomes visible
22:26:30 <mm_freak_> dskippy: have a look at the agda language
22:27:47 <handonson> FP has such a broad meaning that saying "FP can be ..." doesn't really mean much
22:28:00 <mm_freak_> it's the first language i've seen, which indeed /cannot/ be used imperatively =)
22:28:02 <handonson> some people call Python functional
22:28:12 <handonson> because they can pass functions around
22:28:13 <dskippy> handonson: Those people are crazy.
22:28:29 <handonson> dskippy: then there are very many crazy people
22:28:30 <mm_freak_> well, i can write a list construct in python using closures
22:28:39 <mm_freak_> so IMO it fully supports the functional paradigm
22:28:41 <rracer> When using Data.Vector, what's the easiest way to grow a vector? Append new elements to the vector.
22:28:46 <pikhq> mm_freak_: I can do it in C. :)
22:28:46 <mm_freak_> (even though it doesn't do TCO)
22:28:55 <handonson> closures? then what modern high-level language isn't FP
22:28:58 <mm_freak_> pikhq: you can't…  i tried to, but i needed GCC extensions
22:29:00 <Jafet> mm_freak: but have you proven that you cannot use agda imperatively?
22:29:04 <dskippy> handonson: I mean all sure, lots of languages support a function subset. But Python's thinking of getting rid of their lambda.
22:29:07 <pikhq> mm_freak_: Would you like a pastebin?
22:29:15 <mm_freak_> pikhq: in fact, here is my result:  http://ertes.de/cfact/cfact3.c
22:29:22 <mm_freak_> pikhq: sure
22:29:47 <mm_freak_> Jafet: you provably cannot construct a pointless infinite loop in agda…  note that agda is /not/ turing-complete
22:30:00 <pikhq> mm_freak_: http://sprunge.us/GGSS Requires explicit closing.
22:30:24 <handonson> dskippy: dynamic, object-oriented, funtional, ... this are words i saw most often used to describe the paradigm of Python
22:30:38 <pikhq> Used that implementation to create a Lazy K interpreter. (well, a slightly more complex version; I had thunks shoved in there too, you see.)
22:30:41 <handonson> i don't care what functional 'truly' means, i'm just saying people are using it that way
22:30:44 <mm_freak_> pikhq: implementing closures is not the problem
22:30:49 <mm_freak_> pikhq: implementing currying is
22:31:05 <dskippy> handonson: I didn't disagree. Just surprised.
22:31:12 <pikhq> mm_freak_: Yeah, I did it explicitly.
22:31:55 <mm_freak_> pikhq: well, your code already implements an interpreter for a higher level language
22:32:00 <mm_freak_> i tried to avoid that in my code
22:32:28 <pikhq> mm_freak_: I had also just done explicit usage of it for testing...
22:32:54 <pikhq> Somewhat annoying, but yeah, I did lists & church numerals.
22:33:37 <mm_freak_> conclusion:  C is an ugly, primitive language =P
22:34:28 <c_wraith> sadly, C doesn't even match the primitives that modern assembly languages provide
22:34:57 <handonson> some newbie needs to enter this channel and ask some questions whose answers are so clear that the context can be safely changed
22:34:57 <pikhq> mm_freak_: :P
22:34:59 <dskippy> c_wraith: It's really weird to watch that happen.
22:35:17 <wli> Assembly languages don't do much that I'm aware of. What on earth is a "modern assembly language?"
22:35:22 <Jafet> @quote monads.are
22:35:23 <lambdabot> mattam says: [Monads are] much more elegant [than soccer] in general.
22:35:29 <mm_freak_> c_wraith: more sadly, you can't write useful macros in C and there are valid reasons against all of its language primitives
22:35:30 <dskippy> c_wraith: The semantic gap can favor assembly for some reasonable programs on decent, modern chips. Crazy.
22:36:16 <mm_freak_> wli: i think he meant a macro assembler
22:36:23 <mm_freak_> something like GCC or TASM
22:36:50 <c_wraith> Or the explicit vector operations supported by most chips now
22:36:56 <wli> Never seen TASM (probably x86-only or something).
22:37:04 <mm_freak_> yes, x86 only
22:38:07 <etpace> Ok, I currently have a list of files and run a metric over it, and put the results into another file and call gnuplot on it -- this can easily be parallised (it takes a while as the files are big) but i'm wondering on how I can tell when all the files have finished, so I know when to call gnuplot
22:38:37 <mm_freak_> etpace: use concurrency primitives
22:38:47 <mm_freak_> i'd use an MVar, others would use a semaphore
22:39:09 <c_wraith> I might use a list of mvars...  But a QSem is the most natural fit.
22:39:24 <mm_freak_> in such a simple case it's probably safe to use an IORef with atomicModifyIORef
22:41:08 <etpace> how would that signify when all the threads are complete though?
22:41:28 <etpace> just change from false to true or something?
22:42:55 <c_wraith> well, actually, QSemN is the most natural for this application.
22:43:08 <mm_freak_> the MVar approach is this:  forkIO $ doSomething >> putMVar doneVar ()
22:43:11 <mm_freak_> and then:
22:43:34 <mm_freak_> replicateM_ numberOfThreads $ takeMVar doneVar
22:43:54 <mm_freak_> but the QSem approach may be much simpler
22:44:09 <c_wraith> You use forkIO to start each process, count how many times you do it.  At the end of that process, you signal the QSemN with the value 1.  After you fork all the processes, the main thread calls wait with the number of threads forked
22:44:17 <mm_freak_> MVars have one advantage though:  you can pass some result to the waiter (instead of ())
22:44:33 <c_wraith> Yes, if you need to return something, MVars are the way to go
22:45:34 <mm_freak_> btw, use 'finally'
22:45:40 <mm_freak_> otherwise you may run into strange bugs =)
22:46:06 <mm_freak_> doSomething `finally` putMVar doneVar ()
22:46:59 <etpace> cheers
23:00:38 <etpace> something along the lines of this? http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27830#a27830
23:02:42 <handonson> i forgot: how do i make ["the", "quick", "brown", "fox"] to "the quick brown fox" ?
23:02:49 <handonson> inter... something?
23:02:52 <c_wraith> intercalate " "
23:02:55 * ManateeLazyCat Love Teshima Aoi's voice.......
23:02:59 <etpace> unwords also?
23:03:00 <handonson> oh, thanks.
23:03:42 * ManateeLazyCat てしまあおい in Japanese...
23:04:46 <pikhq> 手嶌　葵, you mean.
23:04:49 <freedrull> だいすきね？
23:04:53 <ManateeLazyCat> pikhq: Yep
23:05:08 <ManateeLazyCat> pikhq: Love her voice.
23:05:13 <tensorpudding> Hmm
23:05:18 <pikhq> Mmm.
23:05:26 <tensorpudding> those characters are all in three different fonts
23:05:38 <freedrull> haha
23:05:45 <ManateeLazyCat> pikhq: http://www.xiami.com/radio/play/type/5/oid/23975
23:06:02 <ManateeLazyCat> pikhq: My radio for 手嶌　葵
23:06:58 <pikhq> tensorpudding: Presumably your font for Japanese only includes jinmeiyou kanji(人名用漢字), and you default to a font for simplified Chinese, and have a font for traditional Chinese?
23:07:22 <tensorpudding> actually it might only be two
23:07:25 <tensorpudding> it's hard to tell
23:07:36 <ManateeLazyCat> pikhq: When I listen to her song my heart was calm.
23:07:37 <tensorpudding> but the second kanji is definitely in a different set than the others
23:07:45 <pikhq> ManateeLazyCat: She is, indeed, a good singer.
23:08:17 <ManateeLazyCat> tensorpudding: I recommend you install ttf-wqy-microhei font, include CJK.
23:08:20 <pikhq> tensorpudding: Ah. Yeah, 嶌 is not exactly a common kanji...
23:08:31 <ManateeLazyCat> tensorpudding: "sudo aptitude install ttf-wqy-microhei -y" if you use Debain system.
23:09:09 <pikhq> It's the not-jinmeiyou kanji version of 島.
23:09:11 <tensorpudding> I've no idea how emacs manages which font to use by default for which section of Unicode.
23:09:38 <tensorpudding> anyway, that font is already installed
23:10:05 <pikhq> (that is, it's semantically the same, *but* not in standard use in Japan. That *specific* character is only really used in family names.)
23:10:23 <pikhq> Darned family names, being more orthographically conservative than anything else.
23:10:41 <ManateeLazyCat> pikhq: Another Japanese singer i like is 坂井泉水
23:11:20 <tensorpudding> Man, how do font foundries tackle chinese/japanese at all?
23:11:22 <pikhq> ManateeLazyCat: Mmm.
23:11:29 <dolio> You know what I like? Haskell.
23:11:43 <tensorpudding> It sounds like too much effort to target a working subset
23:12:27 <pikhq> tensorpudding: They create glyphs for the constituent parts of characters and have a computer program compose them.
23:12:29 <ManateeLazyCat> pikhq: When i recommend ttf-wqy-microhei font to my Japanese friend, they say it's Japanese font is good enough. So i wonder what's favorites font for Japanese?
23:12:33 <tensorpudding> at the level of typographical care that is assigned to your common alphabets with reasonable numbers of characters
23:12:45 <nettok> ハスケルが好きだ
23:12:48 <ManateeLazyCat> pikhq: s/is not good enough
23:13:04 <pikhq> ManateeLazyCat: They tend to just stick with what Windows installs by default.
23:13:17 <ManateeLazyCat> pikhq: Oh.
23:13:22 <tensorpudding> How do you make one that actually has a unique identity when at normal text sizes it's hard to make out details on those more complicated than average?
23:13:45 <tensorpudding> those glyphs
23:13:48 <pikhq> tensorpudding: They almost all suck at normal text sizes on computers.
23:14:06 <tensorpudding> I'm speaking about typography in general
23:14:08 <pikhq> tensorpudding: So, you make a unique identity by being *usable*.
23:14:37 <pikhq> Ah, on a page? It's not that hard.
23:15:09 <pikhq> The details on most characters on a printed page aren't hard to make out; it just seems like that to people unused to reading them.
23:15:16 <tensorpudding> If it was about being usable, wouldn't there only be a very small number of noticeably different faces?
23:15:52 <pikhq> ManateeLazyCat: Before Vista, the fonts were MS Mincho and MS Gothic, and after that it's Meiryo.
23:16:53 <pikhq> ManateeLazyCat: These fonts support all of the characters in the JIS character set, which is a very common character set in Japan. As such, they *tend* to suffice.
23:17:20 <pikhq> tensorpudding: There's a decent chunk of variation in the fonts, but nowhere near as much as in Western typography.
23:17:24 * ManateeLazyCat I hope someday i can *goto* Japan to study how to speak Japanese, very interested it.
23:17:29 <tensorpudding> What do computer systems that deal with names do with family names with unfamiliar kanji?
23:17:36 <pikhq> tensorpudding: This is *primarily* because of the prohibitive cost of making a font.
23:18:15 <pikhq> If the character is in Unicode, then they stick it in and hope the font has it. If the character is *not* in Unicode, then, uh.
23:18:25 <pikhq> Varies from country to country, and sometimes from clerk to clerk.
23:18:41 <gwern> there's stuff not in unicode?
23:18:45 <gwern> unpossible!
23:18:48 <pikhq> Ranging from "well, stick in a similar one" to "we'll use this as a placeholder, and *ask Unicode to add it*."
23:18:53 <tensorpudding> Unicode doesn't have Klingon yet do they?
23:19:06 <pikhq> tensorpudding: There's a Private Use Area assignment.
23:19:12 <ManateeLazyCat> tensorpudding: If you use Unicode, and want a font include all character in CJK, so use ttf-way-microhei.
23:19:13 <arw> tensorpudding: unfortunately, they refuse to add fictional languages.
23:19:21 <gwern> 'Klingon is not part of the Unicode Standard. This page tests the Unicode Private Use Area defined for Klingon alphabet (U+F8D0 - U+F8FF) by the ConScript Unicode Registry (last revised 2004-01-15, current as of 2006-01-31).'
23:19:21 <arw> tensorpudding: also no elvish...
23:19:23 <pikhq> arw: Not true.
23:19:26 <gwern> http://www.wazu.jp/gallery/Test_Klingon.html
23:19:32 <tensorpudding> PUA means not in Unicode, for all intents and purposes
23:19:44 <pikhq> arw: They refused Klingon because no Klingon speakers used it for writing Klingon.
23:19:55 <pikhq> arw: After this, Klingon speakers started using Klingon script.
23:19:59 <tensorpudding> There is Tengwar I believe.
23:20:13 <tensorpudding> Err, nevermind.
23:20:17 <pikhq> tensorpudding: That's a proposal which has hung in limbo for a decade.
23:20:29 <ManateeLazyCat> tensorpudding: http://wenq.org/ a Chinese team to develop CJK *free* font.
23:20:31 <tensorpudding> There are real languages which are not in Unicode though.
23:20:31 <gwern> tengwar is a cool script. too bad
23:20:34 <tensorpudding> Mostly ancient ones
23:20:43 <ManateeLazyCat> tensorpudding: High quality.
23:21:05 <pikhq> tensorpudding: There's been efforts to fix that. ;)
23:21:35 <tensorpudding> So unfortunately your Hittite documents will not be able to be put into Unicode, sorry for you
23:21:54 <pikhq> There's an assignment for hieroglyphics.
23:22:34 * ManateeLazyCat In fact, I want to learn Japanese is the original Japanese animation. 
23:22:50 <tensorpudding> Hittite isn't included among those hieroglyphics yet supported
23:23:34 <gwern> hittite isn't a script, I thought, but a language written in akkadian cuneiform, which I was pretty sure was in unicode
23:23:41 <pikhq> ManateeLazyCat: Well, since you already know 漢字, you already know what stops most people.
23:23:52 <pikhq> gwern: Yes, it is.
23:24:04 <gwern> so tensorpudding was not correct then
23:24:08 <pikhq> It was added in Unicode 5.0.
23:24:19 <earthy> :)
23:24:30 <tensorpudding> I was going off of http://unicode.org/standard/unsupported.html
23:24:47 <ManateeLazyCat> pikhq: :)
23:25:47 <pikhq> ManateeLazyCat: 少し日本語を分かる！
23:25:49 * earthy grins
23:25:49 <tensorpudding> it's been a solid twenty minutes since anyone said anything ontopic
23:25:59 <gwern> 'Anatolian hieroglyphs are an indigenous logographic script native to central Anatolia, consisting of some 500 signs. They were once commonly known as Hittite hieroglyphs, but the language they encode proved to be Luwian, not Hittite, and the term Luwian hieroglyphs is used in English publications. '
23:26:11 <gwern> maybe someone should tell unicode.org that
23:26:46 <tensorpudding> Okay
23:26:50 <handonson> how do i obtain the appropriate CInt in "MkSocket CInt Family SocketType ProtocolNumber (MVar SocketStatus)" ? (Network.Socket)
23:27:05 <gwern> > 1 :: CInt
23:27:06 <lambdabot>   Not in scope: type constructor or class `CInt'
23:27:09 <tensorpudding> Your documents, which you mistakenly thought was Hittite, but is in fact Luwian, will not work in Unicode.
23:27:22 <handonson> the documentation tells me it's a file descriptor
23:27:35 <handonson> which, in C, you get assigned by socket()
23:27:42 <ManateeLazyCat> pikhq: Yes, i will. :)
23:28:04 <handonson> I don't specify it by myself in C, and I don't think I'd be able to do in Haskell
23:28:41 <pikhq> tensorpudding: BTW, an example of one guy's efforts: http://www.evertype.com/formal.html
23:28:46 <gwern> tensorpudding: I now find myself wondering how one *would* write in luwian hieroglyphs
23:28:46 <handonson> it's at http://hackage.haskell.org/packages/archive/network/2.2.1.7/doc/html/Network-Socket.html#v%3AMkSocket
23:28:56 <pikhq> tensorpudding: Yes, that's a single person's Unicode proposals.
23:29:05 <pikhq> ManateeLazyCat: 良い！
23:29:14 <ManateeLazyCat> handonson: You mean how to convert between CInt and Haskell/Int?
23:29:18 <handonson> NO
23:29:19 <tensorpudding> gwern: religious texts, instructions on planting crops, grocery lists
23:29:27 * earthy is more interested in nepal pracalit... which is actually still being used
23:29:28 <handonson> i mean how to obtain the appropriate file descriptor
23:29:29 <gwern> tensorpudding: no no, *how*, not what
23:29:36 <earthy> (and not in unicode either)
23:29:42 <tensorpudding> oh
23:30:04 <tensorpudding> they need to add a spot for that new rupee
23:30:12 <handonson> when I open a socket, the OS gives me the file descriptor. this is how it works, basically, iirc
23:30:41 <gwern> tensorpudding: that's one of the most recent proposals on pikhq's link
23:31:04 <tensorpudding> I know, that's why I mentioned it
23:31:12 <tensorpudding> I presume it hasn't gone through
23:31:34 <handonson> but in MKSocket, it says I have to specify the fd
23:31:35 <tensorpudding> since the new symbol is only like a week old
23:31:51 <RayNbow> byorgey: was it your intention to make people LOL while reading your post about LOL? :p
23:32:01 <handonson> but how am I supposed to know what's a feasible fd? the system only knows
23:32:06 <ManateeLazyCat> pikhq: BTW, do you know rubikitch ? A Japanese emacser?
23:32:17 <pikhq> tensorpudding: I should note, again, that that list is *Michael Everson*'s proposals.
23:32:23 <pikhq> ManateeLazyCat: No, I'm afraid I don't.
23:33:15 <pikhq> He is also responsible for the ConScript registry...
23:35:20 <handonson> wait
23:35:22 <handonson> never mind.
23:35:26 <handonson> figured it out
23:35:39 <gwern> what was it?
23:35:41 <tensorpudding> pikhq: What does the fact that it is by Michael Everson have to do with anything?
23:37:08 <handonson> gwern: i was not supposed to use MKSocket at all
23:39:12 <handonson> i feel (very slightly) unsatisfied about that the authors of Network.Socket exported a data constructor which is not supposed to be used by coders at all
23:39:28 <c_wraith> PortNumber?
23:39:53 <handonson> MKSocket
23:40:13 <handonson> MkSocket, sorry
23:40:20 <c_wraith> oh
23:43:05 <handonson> but hey, now that you mention it, PortNumber sounds truly useless
23:43:39 <c_wraith> Actually, it's worse
23:43:46 <handonson> the Network module is supposed to be high-level enough
23:43:59 <c_wraith> The PortNumber constructor is byte order sensitive
23:44:05 <handonson> why didn't they just make connectTo take a string and an Int
23:44:20 <c_wraith> But the Enum instance for it is not byte order sensitive
23:49:54 <Itkovian> Any idea why cabal still wants to configure syb-0.2.1 when it's installed (shows up in ghc-pkg list) when installing (a configured and built) parsec-3.0.1? Target ghc is 6.13.x, with base being at 4.3.0.0 and syb requiring < 4.3 when not yet installed. 
23:50:43 <dreixel> I still don't quite understand the way cabal-install handles syb and base.
23:51:34 <Itkovian> It's weird. it should be able to fdin syb, as ghc-pkg list shows it. But apparently it does not get found when cabal does a ghc-pkg dump global
23:51:59 <dreixel> Itkovian: this is with cabal-install, right?
23:52:07 <Itkovian> right
23:52:19 <Itkovian> Maybe I should just use Setup to install?
23:52:23 <dreixel> have you tried using runghc Setup.hs configure?
23:53:08 <Itkovian> doing so now.
23:53:13 <Itkovian> complains about the need to reconfig
23:53:16 <Itkovian> trying that path
23:53:37 <Itkovian> complains about mtl and syb missing
23:53:45 <Itkovian> which should not be the case.
23:53:56 <dreixel> that is odd, though
23:54:02 <Peaker> Itkovian, dreixel: cabal install -v explains why it does these things
23:54:54 <Peaker> Itkovian, typically if you put --constraint some-base-package==<install ver>  for a bunch of packages you can fix that
23:55:23 <dreixel> I know the workaround, but I would really prefer if this would work as expected
23:56:20 <Peaker> yeah, I think it would be more sane if cabal-install used signature matching rather than version specs
23:56:46 <dreixel> but even just using versions, it's doing something odd here.
23:57:31 <Itkovian> Peaker: yes, it does not seems to find syb.
23:57:51 <dreixel> Itkovian: so what does cabal install -v say?
23:58:13 <Itkovian> "cabal: cannot configure syb-0.2.1. It requires base >=4.0 && <4.3"
23:58:49 <Itkovian> which does not make sense. syb was installed, after I changed the version requirements in that package. Would it recheck those, eve if the package was installed?
23:58:49 <Itkovian> ]
23:58:58 <dreixel> can you please post the entire output somewhere?
23:59:16 <Itkovian> sure
