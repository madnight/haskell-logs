00:00:18 <napping> even then getting a polymorphic object language is really tough
00:00:52 <Dashkal> wli: Execution time constraints are possible, but would require the interpreter to run in IO.  The current design forbids that being a requirement so such protections would be optional
00:01:14 <Dashkal> napping: Wait until I start on TypeClasses and in-language functions of a -> a
00:01:19 <Dashkal> Then my brain will melt...
00:01:33 <Philippa> Dashkal: not true, you can do time constraints just by using a 'clock' in a StateT that gets updated and checked every bind
00:02:02 <Philippa> that works fine so long as you always call a bind within bounded time, which you will do if your interpreter lives firmly in the monad
00:02:11 <Dashkal> Philippa: That becomes tricky to define.  The language is functional.  Maybe I can count function applications...
00:02:47 <Dashkal> or let scopes
00:03:22 <wli> I'm not sure how the counter works. I think it's supposed to be like termination analysis.
00:03:42 <Dashkal> I'm not terribly concerned about resource exaustion at this point.  That kind of issue is for rev 3
00:03:51 <Dashkal> So I'll probably just watch for stack overflow and leave it at that
00:04:07 <napping> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27076#a27076
00:04:21 <Philippa> wli: heh, no, just treat certain points in the interpreter as a 'tick', just as if it were a virtual CPU
00:04:28 <Dashkal> Given that the language is pure/functional and without tail-calls, stack overflow will always be reached given enough code anyway
00:04:36 <Philippa> wli: it's not even that far off it, it's not so far from an interpreter to an abstract machine
00:04:53 <Dashkal> Philippa: Again, not so simple.  The language is pure functional.  Example: let x = x in x
00:04:58 <Dashkal> When would I kill evaluation of that?
00:05:30 <napping> probably you have interpreter steps
00:05:31 <Philippa> either when you run into the blackhole, or $clockcount through the attempt to force x
00:05:49 <napping> if you are actually converting it to haskell code, then it's trickier
00:06:10 <Dashkal> no conversion.
00:06:12 <napping> like, if eval (Let ...) = let .. = eval .. in eavl ...
00:06:48 <Dashkal> The interpreter doesn't really have 'steps'.  The core 'interp' function is just a giant set of equations that evaulate each kind of AST node.
00:07:05 <Philippa> recursively. Which sounds suspiciously like a step to me
00:07:26 <Dashkal> Here is interp from rev 1: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27077#a27077
00:07:31 <Philippa> honestly, once per trip round the interpreter's fixpoint is probably good enough
00:07:43 <Philippa> *wince*
00:07:48 <Dashkal> Yes, I can stick counter code into interpLet and interpApp
00:07:48 <Philippa> that's not good style
00:07:57 <Philippa> no, not good enough
00:08:04 <Philippa> you need to count whenever you force an evaluation
00:08:21 <Philippa> that's how you catch the infinite loop you just showed
00:08:24 * Dashkal facepalms
00:08:27 <Dashkal> sec
00:08:58 <Dashkal> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27077#a27078
00:09:01 <Dashkal> Oh look, a place for a counter
00:09:35 <Philippa> you /are/ doing lazy evaluation and not just call by name, I hope?
00:09:40 <Dashkal> unthunkr recursively un-thunks code.  That's the actual force
00:10:46 <Dashkal> a lambda is an unbound var and an expression that uses it.  application converts a lambda into a thunk, while binding the var.  interp' and functions that strictly use their argument are the only places that unthunk.
00:13:04 <Dashkal> Unless I missed something, that should be proper lazy evaluation
00:15:52 <napping> Dashkal: did you look at the code I pasted?
00:16:30 <Gertm> is "The Haskell school of expression" still a good resource to learn the language? (differences with more recent versions?)
00:16:43 <Dashkal> napping: sorry, got distracted by the laziness questions.  Reading again
00:16:47 <napping> one thing you can do, or do much more reasonbly, is recover type class information without casting to a concrete type
00:17:51 <Dashkal> murr?
00:19:14 <Dashkal> napping: Reading back, I'm lost on the dynamic example you gave me.
00:19:17 <napping> If you have that fixed type Rep of type representations, you can extract it and return stuff relatively sanely
00:19:26 <napping> which part?
00:20:03 <napping> try "test (1::Int)" and "test False" in the shell
00:21:22 <Dashkal> aha! I missed your hpaste.  Got it now
00:22:37 <turiya> how do to write let bindings inside bind operations (>>=) when not using the do construct?
00:23:11 <Saizan_> use "let .. in .."
00:23:21 <Saizan_> > let x = () in x
00:23:22 <lambdabot>   ()
00:24:12 <Dashkal> napping: Reading that, I see a closed type system where all types must have a Rep data constructor
00:24:34 <turiya> Saizan_: thanks
00:24:50 <Dashkal> I'd like to avoid having a single 'external' type that all external data must use.  I'd like differing external types to still follow the type rules
00:25:28 <Dashkal> So, in the context of a MUD using the script library, Players and Rooms are seperate types and cannot be mixed.
00:26:28 <napping> Dashkal: not at all. Int, Bool, and Maybe are the types here
00:26:36 <napping> Rep is just a tag.
00:27:01 <Dashkal> And if I want to add, say, Char?  How can I do it without adding a new data constructor for char to Rep?
00:27:35 <napping> you have to add a constructor to Rep. It is a closed system, but the types you know about are external
00:28:21 <Dashkal> Yeah, I need an open system.  I need types being contributed from outside the script library
00:28:37 <Philippa> then you're down to nominal vs structural
00:28:46 <Dashkal> And so I use Dynamic to hold values
00:32:58 <Dashkal> Philippa: I don't understand what you mean by nominal vs structural
00:34:17 <napping> how are new types defined?
00:34:27 <napping> do you mean types defined in scripts, or types defined in Haskell?
00:34:39 <Dashkal> For r2, scripts cannot define types.
00:34:45 <Dashkal> that's an r3 thing
00:35:15 <Dashkal> Creating a type comes down to mkFSType "Integer" and feeding the result to the interpreter
00:35:30 <Dashkal> well, bad example.  The 6 I mentioned are always in there.
00:35:43 <Dashkal> Since they're used by language constructs
00:37:42 <Dashkal> It really is that simple.  types do not define representation.  Constructor functions define representation.  Misbehaving code can cause issues by constructing FSValue instances directly, but I'm not concerned about that at this point
00:38:03 <napping> how can scripts use the new types?
00:38:03 <Dashkal> That will just lead to unexpected Nothings when code tries to exctact values
00:38:11 <napping> you provide funnctions that do things with them?
00:38:17 <Dashkal> Scripts can use non-core types only via contributed functions
00:38:47 <Dashkal> The library comes with those 6 types, language constructs to create them, and a small library to work with them.
00:39:05 <Dashkal> Consumers of that library define any new types required, and functions to work with those new types.
00:40:08 <adu> what scripts?
00:40:34 <Dashkal> adu: context: I'm writing a script interpreter library.
00:41:28 <adu> ic
00:43:38 <Dashkal> Philippa: a little delayed, but why did you complain that my interpreter dispatch function was in poor style?
00:43:49 <Dashkal> All it was doing was dispatching on an AST node.
00:46:10 <adu> maybe it wasn't what you wrote, but _how_ you wrote it
00:46:54 <Dashkal> looked like a pretty basic unwrap and process block
00:47:50 <adu> maybe s/he thinks unwraping is poor style?
01:05:17 <Philippa> Dashkal: to be fair I was assuming the functions don't get called from anywhere else - if they do, fair enough, factoring is more important
01:05:39 <Philippa> if not, then the functions really don't need to be there
01:06:09 <Dashkal> Philippa: They do only get called from there.  The reasoning was to keep the pattern matches nice and neat and for simple comments.
01:06:29 <Dashkal> Everything lines up nicely and is easy to read at a glance
01:06:57 <Philippa> except it all it tells you is to go read the real code elsewhere. Indent a bit and everything still lines up
01:07:13 <Dashkal> And end up with a monster function
01:07:28 <Philippa> really? How big are the other functions?
01:07:42 <Dashkal> 3-10 lines each
01:07:48 <Philippa> that's not worth the separation
01:07:52 <Dashkal> with do blocks and other such fun
01:08:20 <Philippa> it's an interpreter, we know you're dispatching on AST nodes, and as a reader I want to get to the meat straight away
01:08:28 <Dashkal> scroll down :P
01:08:50 <Dashkal> You find the meat for each type of node immediately below interp.
01:08:55 <Philippa> in which case I have to waste time confirming that you really are just taking the node parms and passing them to the function
01:09:02 <Dashkal> It's not spread through the rest of the file.  Each one is defined in tern
01:09:15 <Dashkal> turn*
01:09:47 <Dashkal> You can tell that at a glance in less than a second.  Every equation has the exact same form.  To the point where I wish there was some sort of pointfree form to do that block in
01:10:04 <Dashkal> But that only works for construction, not deconstruction
01:10:12 <Philippa> it's called inlining the offending functions :-)
01:10:33 <Dashkal> Which again, ends up with a function that
01:10:36 <Philippa> just lay the dos out on the RHS of the =
01:10:39 <Dashkal> 's a good 50+ lines long
01:10:57 <Philippa> yes, but with the cases already clearly marked out, so it's no worse than the separate functions on that count anyway
01:11:24 <Philippa> this is one of the exceptions to the idea that you shouldn't write 50 line functions. Just lay it out right
01:11:31 <Dashkal> Meh, I think we're going to disagree on this one.  I usually factor once a function breaks 20 lines.  I like small functions.
01:11:48 <Philippa> small function, small block, what's the difference?
01:11:54 <Dashkal> It makes commenting easier, and makes testing easier.
01:12:09 <napping> meh, you could break every function down to two lines if you wanted
01:12:49 <Philippa> commenting is no harder, you can put a comment in above each case. Testing is only improved by getting to test that the cases map to the right function
01:12:56 <adu>  i only have 1 rule: at least 2 newlines between functions. so if its a choice between 1 large function and 50 small functions, i would choose 1 big function since it would take up fewer lines
01:13:24 <Dashkal> I'd find that to be a nearly undigestable chunk of code.
01:13:33 <napping> convert to SK combinators and do bigfun = part1 part2; part1 = part11 part12; part2 = part21 part22 ...
01:14:05 <Dashkal> If I have to spend three hours digesting a super-dense function, I've gained little.
01:14:09 <Philippa> napping: quite
01:14:33 <napping> in other words, what is someone reading the code going to have to figure out, and are you factoring out unrelated information, or just forcing them to read several functions in parallel?
01:15:04 <Philippa> it's just as clear - and as easily checkable - that the cases are just dispatching on AST node type. So it's genuinely down to whether you can visually lay it out in such a way that blocks don't get in each others' way while you're reading them
01:15:15 <Dashkal> The reader is usually me.  I digest code in small chunks.  Ok, this chunk does this.
01:15:31 <napping> now, there's probably a reasonable case that the alternatives are mostly independent
01:15:55 <napping> but you've probably gone a bit too far.
01:16:07 <Dashkal> Pretty much.  Each AST node does its own thing.  Literals are not handled anything like function application.
01:16:11 <napping> things like e.g. which cases cost a "tick" for your infinite loop protection
01:16:33 <Dashkal> I'll be ticking on thunk evaluation.
01:16:33 * wli tends to like three address code.
01:16:51 <napping> even if it's already been forced before?
01:17:13 <Dashkal> A thunk will evaulate once and only once.  Working on that.  Probably a map hiding in the interpreter state.
01:17:49 <Philippa> wli: that's overcomplication when you're starting out though
01:17:57 <Dashkal> Current thought is this: Once a thunk is evaluated, any variable bound to that thunk is rebound to the result.
01:18:20 <Dashkal> A little indirection and I may be able to update only one place.
01:18:20 <wli> Maybe for functional languages. If you're starting off imperative it's not so big a deal.
01:18:21 <augur> is there any research on unification of objects which might be of as of yet indeterminate structure?
01:18:50 <Philippa> if you're starting off simple first-order imperative, perhaps
01:18:54 <Dashkal> But that's being put off until after I get polymorphic functions in place.
01:19:17 <Philippa> the thunk /is/ the indirection
01:19:28 <wli> Sorry, monomorphic first-order imperative, yes.
01:20:19 <Philippa> yeah, but who the hell wants to bother implementing one of those?
01:20:25 <Dashkal> Philippa: a thunk can't replace itself in memory with it's evaluated version without some sort of IO variable.  The interpreter should be able to run in a pure context.  I'll have to indirect again
01:20:43 <napping> Dashkal: if you are in pure code you can just make Haskell thunks
01:20:46 <Philippa> *cough*StateT IntMap*cough*
01:20:51 <Dashkal> So var name -> id.  id -> value./  value being either Thunk or a known value
01:21:23 <napping> an if code isn't pure it really shouldn't be getting lazily evaluated
01:21:30 <Philippa> except the 'known value' can be the thunk "return foo"
01:21:37 <Dashkal> napping: I'm still in a monad.  Evaluation order is forced.  Only IO is optional
01:21:41 <Philippa> napping: lazy object language
01:22:22 <napping> Philippa: yeah, so just map the variable to (eval env exp) in your updated environment
01:25:50 <tibbe> Can I associated data types to replace run-time overloading with compile time overloading as in the case of C++ templates vs (pure virtual) inheritance?
01:25:50 <lambdabot> tibbe: You have 1 new message. '/msg lambdabot @messages' to read it.
01:26:37 <napping> tibbe: mostly
01:26:51 <napping> associated data types certainly let you use specialized representations for different argument types
01:28:17 <tibbe> napping: If I define a method in my type class can it be resolved statically without using inlining?
01:28:25 <tibbe> let me see if I can come up with an example
01:28:51 <tibbe> class C a where { data T a; unit :: T }
01:29:01 * tibbe wonders if that's the correct syntax
01:29:30 <Saizan_> unit :: T a
01:29:33 <Dashkal> Meh, it's getting far too late to deal with polymorphic functions.  id will have to wait until tomorrow
01:29:33 <tibbe> if we know the concrete type of a then the return type of unit is known
01:29:40 <wli> I'm not sure you can declare data in classes unless that's some extension I'm unfamiliar with.
01:29:53 <tibbe> wli: TypeFamilies
01:29:58 <napping> tibbe: if the type is known, the call can be resolved statically
01:30:11 <wli> That would be an extension I'm unfamiliar with.
01:30:23 <tibbe> napping: but perhaps that was the case already before ATs
01:30:30 <napping> if you have a polymorphic function, it will only be resolved if inlined (or with SPECIALIZE)
01:31:02 <tibbe> napping: right, so function of the type :: C a =>a ...
01:31:09 <tibbe> napping: would need to be resolved statically
01:31:09 <Saizan_> tibbe: what ATs change in all of this is only that you can have specialized data representations
01:31:12 <tibbe> dynamically*
01:31:28 <tibbe> Saizan_: yes, I think it makes sense in my head now
01:31:39 <napping> tibbe: well, they get a dictionary passed
01:31:58 <tibbe> Saizan_: that's interesting as (I think) C++ templates don't give you that option, things have to be resolved statically
01:32:05 <napping> if they are called from a context where the type is known statically, and they are inlined or there is a RULES for that case, it will be resolved
01:32:22 <tibbe> Saizan_: although in C++ you know that all your template functions will be specialized statically
01:32:37 <tibbe> Saizan_: but in Haskell you'd have to play with INLINE
01:34:34 <Saizan_> well, they could be resolved statically in principle aside from existentials
01:34:55 <Saizan_> ATs i mean
01:35:19 <Saizan_> it's just a metter of how much code you want to duplicate, and how much separate compilation you want to keep
01:35:45 <Saizan_> (duplicate during the compilation pass, not at the source level)
01:36:07 <tibbe> Saizan_: right
01:36:25 <tibbe> Saizan_: enough inline pragmas would force the code duplication
01:43:06 <augur> Saizan_: hey
01:57:10 <Saizan_> augur: hi
01:57:34 <augur> you know anything about unifying currently indeterminate objects?
01:58:44 <augur> for instance, suppose that K{F} is a context/filler pattern, so that, for example, K{a} = (a,b) yields K = (_,b)?
01:58:46 <Saizan_> not in those terms at least, unless it's just a matter of unifying two meta-variables
01:59:21 <Saizan_> ah, that looks like higher order unification
01:59:36 <augur> oh?
02:00:26 <augur> because, im trying to figure out how to build a unifier where you can do that successfully on, for instance, the lists   [K{a}, L{b}, (a,b)] =:= [X,X,X]
02:00:45 <Saizan_> well, K is almost like a function/lambda term, that when applied to a gives you the tuple
02:00:48 <augur> to yield K = (_,b), L = (a,_), and X = (a,b)
02:00:59 <augur> yeah, basically
02:02:44 <Saizan_> so you're matching (a,b) with "K a" (if you see K as a function) and that brings you into higher order unification territory, afaiu
02:03:02 <augur> ill check out higher order unification then, thanks :)
02:03:26 <Saizan_> which is undecidable in general but there are known decidable subsets, but i don't know more than that :)
02:04:17 <Saizan_> lolli and twelf are logic languages that support it
02:05:12 <augur> yeah i just need unification for simple finite structures
02:05:17 <augur> so i think that should be decidable
02:05:39 <augur> i mean, K{a} or K{F} on a finite structure with no variables is decidable
02:05:53 <augur> its just a matter of unzipping the structure
02:09:30 <kmc> Dashkal, monads don't in general force evaluation order
02:09:50 <kmc> Dashkal, IO isn't about constraining evaluation order so side effects execute properly
02:10:15 <kmc> Dashkal, IO is about decoupling execution order from evaluation order
02:10:21 <Saizan_> twelf can't solve "K a = pair a b"
02:11:43 <dolio> There's more than one answer for functions in general.
02:11:51 <dolio> \_ -> pair a b and \a -> pair a b
02:11:55 <Saizan_> true
02:12:12 <Saizan_> "forall x. K x = pair x b" gets simplified in fact
02:12:41 <augur> Saizan_: oh? why not?
02:12:59 <Saizan_> what dolio wrote :)
02:13:13 <augur> eh.. oh i see
02:13:30 <augur> well, the assumption im working with is that K must use the argument
02:13:33 <augur> it cant throw it away
02:13:42 <augur> even if theres more than one answer, tho, thats fine
02:14:09 * hackagebot free-theorems-counterexamples 0.3 - Automatically Generating Counterexamples to Naive Free Theorems  http://hackage.haskell.org/package/free-theorems-counterexamples-0.3 (DanielSeidel)
02:14:28 <augur> K{a} = (a,a) ==> K = (_,a) ; K = (a,_)
02:16:21 <Saizan_> yeah, i guess twelf just doesn't try to enumerate the possible solutions for some reason
02:17:05 <augur> i have a semi-working solution to this, but i dont know how correct it is
02:18:20 <dolio> If what you're looking for is one-hole contexts, that's probably decidable.
02:18:38 <dolio> As you said, walk through the zipper looking for things that match, and return all such zippers.
02:18:55 <dolio> Then K = \x -> fill zipper x
02:19:16 <augur> well, any number of holes
02:19:24 <augur> it doesnt matter so long as the structure is finite and has no variables
02:19:50 <sm> hello all
02:19:53 <augur> hi sm
02:20:15 <Dashkal> kmc: Bleh, looks like I'm getting hung up on lazy evaluation again
02:20:43 <sm> ghc 6.12 on a US mac with default "C" locale breaks on non-ascii input unless you set LANG=en_US.UTF-8
02:21:00 <dolio> augur:  Incidentally, you might want to look into combinatorial species. Some Haskell folks have been trying to introduce them to the larger community.
02:21:11 <augur> will do
02:21:27 <augur> brief summary? :D
02:21:39 <sm> if I want to make a mac haskell app that just works, then, should I forcibly set that env var/locale in my startup ?
02:21:47 <sm> in the app, I mean
02:22:13 <dolio> For the purpose of Haskell and the like (from what I gather), they're what mathematicians came up with with regard to the arithmetic of datatypes.
02:22:23 <dolio> And presumably derivatives are in there somewhere.
02:23:59 <dolio> Anyhow, they might be relevant to zipper-related stuff.
02:24:10 <augur> ok
02:24:41 <Saizan_> sm: it makes more sense to set the encoding on the Handle's you're using, i'd think
02:26:25 <Saizan_> yeah, for example the zipper of a Bag is just another Bag, since e^x/dx = e^x/dx :)
02:26:36 <sm> Saizan_: thanks, so eg hSetEncoding stdin utf8 >> hSetEncoding stdout utf8 >> hSetEncoding stderr utf8 ?
02:27:18 <sm> and it should probably check for C locale first
02:31:13 <sm> hm.. it's rather difficult to check the encoding if TextEncoding doesn't implement Eq ? I guess I can add that myself
02:31:38 <sm> yikes.. or not
02:33:05 <augur> i want toast with butter and jam :(
02:33:08 <ivanm> blackdog_: situation resolved?
02:33:14 <ivanm> augur: then go get some!
02:33:32 <augur> i dont have bread, nor butter, and its 5:30am
02:33:35 <augur> stores arent open yet
02:33:35 <augur> :(
02:37:58 <ivanm> augur: this is why you should keep some emergency bread + butter n the freezer
02:38:13 <ivanm> of course, there's a better question: wtf are you doing up at 5:30AM? :o
02:38:34 <Saizan_> that's when you code.
02:38:39 <augur> precisely
02:38:42 <augur> when else would i be up? :|
02:39:03 <augur> ive been up since 2am, and went to bed yesterday at 5pm
02:39:10 <augur> my sleep schedule is all messed up
02:39:13 <augur> so im trying to correct it
02:40:59 <napping> augur: avoiding that problem is where you get decidable subsets - if you want to match \a b -> K a with \a b -> (a,b)
02:41:24 <augur> no, i dont know if thats what i want to match at all :P
02:41:28 <napping> then you can only get (_,b), because a and b are not in scope at the top level
02:48:46 <om-foxy> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27084#a27084
02:49:21 <om-foxy> how does one get haddock to document the instances in the documentation for Numeric.Interface?  (see hpaste link above).
02:52:44 <ivanm> om-foxy: as of haddock-2.7, you can document the overall instance
02:52:58 <ivanm> but you can't document the actual methods of the instance
02:53:02 <ivanm> is that what you meant?
02:53:42 <napping> how do you use TypeEq to avoid overlapping instances?
02:53:53 <napping> I have a stack of constructors like T1 (T2 TEnd)
02:54:24 <napping> and want to make a class with instances Constains T1 (T2 (T1 End))
02:54:59 <om-foxy> ivanm: not quite, in documentation you see a list of types that are an instance of a class:
02:55:00 <om-foxy>    Instances
02:55:01 <om-foxy>      Num Float
02:55:03 <om-foxy>      Num Double
02:55:04 <om-foxy> etc...   but I'm unable to propagate those from Numeric.Instances (a hidden module) into the Numeric.Interface documentation.
02:55:14 <ivanm> om-foxy: oh, right
02:55:31 <ivanm> put this at the top of the hidden module: {-# OPTIONS_HADDOCK hide #-}
02:55:54 <om-foxy> does that hide the instances or unhide them?
02:56:09 <ivanm> it should show them in an exposed module
02:56:27 <om-foxy> ah....
02:56:27 <ivanm> I'm assuming that Numeric.Interface exports Numeric.Instances?
02:56:57 <ivanm> om-foxy: it may not, however; instances get shown attached to the class and to the datatype
02:57:06 <ivanm> in this case, they're obviously not going to be attached to the data type
02:57:31 <ivanm> but here, unless the module containing the class can see the module containing the instances, I'm not sure if haddock will put the instances with the module...
02:57:41 <ivanm> (this is a problem with orphan instances)
02:57:46 <ivanm> I _think_ it will, though
03:01:20 <om-foxy> hm...  Interface exports Instances, and I attached the pragma, but still no show.  (The instances work fine in code, its just documentation that I'm working on here.)
03:01:53 <om-foxy> I see what you mean about orphans.  The classes are standard and the data types are defined elsewhere (for circularity reasons).
03:04:05 <om-foxy> ivanm:  Hm... the instances are _actually_ attached to the datatype file, even though Numeric.Vector does not import Instances.  My mistake.
03:05:03 <om-foxy> clever Haddock
03:19:43 <keep_learning_> http://pastebin.com/f3F8p34B   kindly some one plese tel me this code is right or wrong 
03:20:09 <keep_learning_> i simply implemented rabinmiller from wiki 
03:20:25 <keep_learning_> but i am getting wrong answer 
03:20:49 <tab> the code is wrong then :)
03:21:10 <keep_learning_> for some input i am getting correct answer  and for other wrong answer 
03:21:45 <turiya> how to fix the ambiguous occurrence message from cabal?
03:22:13 <keep_learning_> some one please 
03:22:45 <keep_learning_> i just wanted to know if i implemented the code right or not 
03:23:53 <ivanm> turiya: hmmm?
03:24:25 <ivanm> keep_learning_: well, I have no idea what rabinmiller is
03:24:29 <turiya> i thin readTVarIO is defined in two places
03:24:42 <ivanm> error message?
03:24:49 <napping> Dashkal: still here?
03:25:27 <ivanm> keep_learning_: what's the point of "Just Bool" ?
03:25:35 <keep_learning_> ivanm : http://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test
03:25:40 <turiya> ivanm: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27085#a27085
03:25:47 <ivanm> and using "mkStdGen 3" all the time means that your randomness isn't going to change much...
03:25:49 <keep_learning_> the algorithm given at wiki
03:25:55 <ivanm> you kinda need to keep passing the new split state around
03:26:12 <ivanm> turiya: which version of GHC?
03:26:29 <turiya> 6.12.1
03:26:55 <napping> how is TypeEq not overlapping instances?
03:27:19 <ivanm> strange, readTVarIO was only defined in 6.12.1 ...
03:27:36 <keep_learning_> ivanm : i am not expert but some time that function may not return anything 
03:27:51 <ivanm> ahhhh
03:28:38 <ivanm> keep_learning_: I take it your `a' is your version of `k' from wiki?
03:28:48 <keep_learning_> ivanm :  it rabinmiller is true all the time then will return nothing
03:28:56 <keep_learning_> ivan m 
03:29:04 <keep_learning_> ivanm : yes
03:29:41 <ivanm> what's "fun" meant to be?
03:30:50 <ivanm> and your usage of fancy characters make it hard to work out wtf you're doing
03:30:55 <keep_learning_> n-1=2^d*m
03:31:17 <ivanm> I'm guessing that that's meant to be "b0 == 1 || b0 == (n-1)"
03:31:21 <keep_learning_> ivanm : :) sorry but new to haskell
03:31:26 <keep_learning_> yes
03:31:51 <keep_learning_> that fancy charctors are because of leksah
03:31:56 <ivanm> ugh
03:32:48 <ivanm> so fun is meant to do that "write n-1 as 2^s * d" bit?
03:33:07 <keep_learning_> ivanm:yes
03:34:43 <ivanm> hmmm, you could use divMod to clean up your definition of f, but that's not that big a deal
03:35:09 <ivanm> keep_learning_: when using System.Random, you're meant to keep passing a new state value around
03:35:56 <wli> You probably need to avoid duplicate numbers and I think there might also be some conditions on things like quadratic residue or something.
03:36:21 <keep_learning_> ivanm : i did not get you but i took 10 random numbers and testing on  each number
03:36:43 <keep_learning_> ivanm : the a in the algorithm is random number 
03:36:49 <keep_learning_> between 2 and n-2
03:37:03 <ivanm> also, I don't think you're meant to do recursive calls back to rabinmiller; you're meant to recurse in a helper function
03:37:39 <ivanm> keep_learning_: so what's k?
03:37:47 <ivanm> I think you're doing it completely wrong
03:38:18 <keep_learning_> k will store a value Maybe False or Nothing 
03:38:38 <keep_learning_> if my number failed on all the 10 random numbers 
03:38:41 <ivanm> uhhhh, your code doesn't match the algorithm at all
03:38:46 <ivanm> you're doing it completely wrong
03:39:00 <keep_learning_> ivanm: ohhhh
03:39:02 <keep_learning_> :(
03:39:13 <ivanm> keep_learning_: you're meant to be passing in some value k, you're not
03:39:21 <ivanm> you're passing in a, which is meant to be your random value
03:39:42 <ivanm> and there's no need for the Maybe
03:39:49 <ivanm> False == composite, True == probably prime
03:40:02 <keep_learning_> ivanm : ok 
03:40:33 <keep_learning_> actually k is just to store the value 
03:41:10 <keep_learning_> i am passing a random number to rabinmiller n (random number x from list)
03:41:30 <ivanm> yes, you're doing it wrong
03:41:36 <ivanm> you're not meant to recurse rabinmiller
03:41:43 <ivanm> you're meant to recurse on an internal helper function
03:42:11 <etpace> does anyone happen to know a parallel merging of lists algorithm? my current attempt seems a bit slow
03:42:31 <keep_learning_> ivanm: i think if i have to run it rabinmiller on 10 random values 
03:42:39 <keep_learning_> so i have to call it 10 times 
03:43:02 <ivanm> no, you do the inner bit 10 times
03:43:13 <ivanm> keep_learning_: what's your main overall function? rabinmiller or primality test?
03:43:21 <ivanm> s/primalitytest/primetest/
03:43:34 <keep_learning_> rabinmiller is my main function 
03:43:41 <ivanm> then yes, you're doing it wrong
03:44:03 <keep_learning_> would it be possible 
03:44:04 <ivanm> rabinmiller is meant to take the number to test and `k', an accuracy parameter
03:44:12 <keep_learning_> if u can modify my code
03:44:29 <ivanm> and in this case, you should also pass it in a StdGen
03:44:32 <ivanm> keep_learning_: is this homework?
03:44:41 <keep_learning_> no 
03:44:45 <ivanm> i.e. is this something you're meant to be doing, or just something you want to do?
03:44:50 <keep_learning_> i am learning haskell
03:45:01 <keep_learning_> so its not a home work 
03:45:10 <keep_learning_> as i am professional 
03:45:22 <keep_learning_> or tell me 
03:45:26 <keep_learning_> how to change it
03:45:36 <keep_learning_> it is more better 
03:45:39 <keep_learning_> tell me what to change
03:48:27 <augur> ahhh
03:48:35 <augur> bread and butter gotten :)
03:48:48 <augur> toaste and butter and jam to be had
03:48:51 <augur> :D
03:52:07 <napping> how do (TypeEq x x HTrue) and (TypeEq a b flag) not overlap?
03:53:18 <ivanm> keep_learning_: I'm working on it
03:53:23 <napping> oh, it's just not used at overlapping types in TypeEq.hs
03:53:47 <keep_learning_> ivanm: thank you 
03:58:14 * hackagebot HaRe 0.6 - the Haskell Refactorer.  http://hackage.haskell.org/package/HaRe-0.6 (ChrisBrown)
04:07:19 <ivanm> cabalised HaRe! \o/
04:10:58 <ivanm> keep_learning_: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27086#a27086
04:11:05 <ivanm> voila!
04:11:16 <ivanm> I could probably make it neater/prettier, but that seems to work
04:11:50 <keep_learning_> kindly paste it paste bin
04:12:03 <keep_learning_> its not opening from here 
04:12:10 <keep_learning_> sorry 
04:12:55 <ivanm> huh? works fine here...
04:13:16 <keep_learning_> but its not working from my network 
04:13:29 <keep_learning_> Server not found
04:13:35 <keep_learning_> so it would be nice 
04:13:38 <ivanm> http://pastebin.com/DzJuPwJe
04:13:43 <keep_learning_> thank yoy
04:13:48 <keep_learning_> you
04:14:37 * ivanm facepalms
04:14:51 <ivanm> why didn't I just google? :s http://www.haskell.org/haskellwiki/Prime_numbers#Miller-Rabin_Primality_Test
04:16:17 <ivanm> and that code used to be on the wikipedia page apparently :s
04:16:25 <ivanm> keep_learning_: ^^ anyway, there's an alternate version
04:16:56 <ivanm> however, I think my version is better
04:17:39 <ivanm> (since that version uses the same value of `a' all the time, and uses `s' as `k'...
04:18:38 <ivanm> that'd be right, he quits after he got what he wanted
04:20:01 <augur> is there a name for the non-disjunctive equivalent of something like the list monad? (or the set monad, if that exists)
04:20:19 <ivanm> huh?
04:20:35 <augur> well im just thinking about nondeterminism
04:20:59 <augur> and what i suppose can be viewed as multi-valued variables
04:21:04 <augur> or objects or whatever
04:22:07 <ivanm> still not following, sorry
04:22:12 <augur> imagine that <1,2,3> is the values 1, 2, and 3 all at the same time, so that if you put it in a list, like say: [<1,2,3>] you get <[1],[2],[3]>
04:22:21 <augur> which is the lists [1], [2], and [3] all at the same time
04:23:02 <augur> which i suppose is a sort syntactically auto-CPS for <1,2,3> >>= \x -> <[x]> or something but
04:23:03 <ivanm> you want a probability monad?
04:23:18 <augur> no this right now is just sort of list monady
04:23:35 <augur> only where the binding is implicit
04:24:14 <augur> [<1,2>,<3,4>] would be <[1,3],[1,4],[2,3],[2,4]>
04:24:15 <augur> etc
04:25:22 <augur> but is there a version where like.. [<1,2>,<3,4>] = [1,2,3,4]?
04:25:45 <ivanm> I really still have no idea what you're talking about, sorry
04:25:48 <augur> :|
04:25:57 <augur> i hate you so much :(
04:26:04 <ivanm> :o
04:26:08 <ivanm> that's not very nice!
04:26:23 <augur> >|
04:26:30 * ivanm goes off to sulk
04:26:31 <Tomsik> there is a set module
04:26:46 <Tomsik> but I'm not sure what you're talking about
04:27:11 <augur> its quite simple
04:27:12 <Tomsik> and non-determinism is usually thought of as subset of states, at least in finite automata
04:27:22 <augur> this is true, yes
04:27:42 <augur> so think of the <...> as a convenient way of representing this
04:27:51 <ivanm> are you wanting something like amb in prolog?
04:27:57 <augur> dunno what amb is
04:28:06 <ivanm> augur: I still think what you're talking about is a probability monad
04:28:11 <ivanm> @google haskell probability monad
04:28:12 <lambdabot> http://web.engr.oregonstate.edu/~erwig/pfp/
04:28:12 <lambdabot> Title: PFP - Probabilistic Functional Programming in Haskell
04:28:18 <Tomsik> nay ivanm 
04:28:25 <Tomsik> probabilistic != non-deterministic
04:28:30 <Tomsik> there is a huge difference
04:28:44 <ivanm> hmmmm....
04:28:44 <augur> well, no, theres not
04:28:55 <ivanm> augur: http://rosettacode.org/wiki/Amb
04:29:02 <augur> non-deterministic is like probabilistic but lets pretend that the actual probabilities dont matter
04:29:35 <ivanm> the Haskell definition there is a rather poor one; I've seen better IIRC
04:29:45 <Tomsik> Wait. What are you trying to do augur.
04:29:51 <augur> i mean, its related to whatever it is when you allow like .. this isnt haskell, but, [*x,c,*y] == [a,b,c,d,e] where x = [a,b] y = [c,d]
04:30:13 <ManateeLazyCat> I use function "readFile" read a *huge file* (44MB), and use putStrLn print *result string*, works fine. But when i use "withCStringLen :: String -> (CStringLen -> IO a) -> IO a" transfer *String Pointer* to C function, it's eat *all* memory in my box. Any trick?
04:30:21 <ivanm> augur: look like what you want? http://www.haskell.org/haskellwiki/Amb
04:30:24 <Tomsik> augur: now you're talking about unification or what?
04:30:42 <augur> Tomsik: not necessarily. i mean, you could do it in the other direction, right
04:30:42 <ivanm> ManateeLazyCat: sounds like you're reading the entire file into memory
04:30:50 <ManateeLazyCat> ivanm: Yep.
04:30:51 <augur> [*[a,b],c,*[d,e]] = [a,b,c,d,e]
04:31:01 <Tomsik> augur: I'm not sure what you want to do, though
04:31:01 <ManateeLazyCat> ivanm: But i use putStrLn, it can print string.
04:31:07 <augur> i just showed you :|
04:31:10 <Tomsik> and I have no idea what are you talking about
04:31:15 <Tomsik> Well, you haven't said
04:31:15 <ivanm> ManateeLazyCat: yeah, but if you're saving it in some variable...
04:31:25 <Tomsik> if I show you 1,2,4,8, ... 
04:31:30 <ivanm> Tomsik: be careful, or he'll have you as well ;-)
04:31:31 <Tomsik> what will be the next term?
04:31:46 <Tomsik> or wait, was it after 32
04:32:02 <augur> ivanm: no, its not amb
04:32:04 <augur> not quite
04:32:06 <Tomsik> I mean, it could be a polynomial
04:32:08 * ManateeLazyCat pasted "example code." at http://paste2.org/get/906395
04:32:09 <Tomsik> or 2^n
04:32:10 <ManateeLazyCat> ivanm: Above code, when i use putStrLn, works fine. textBufferSetText can't work.
04:32:12 <Tomsik> or something else
04:32:32 <augur> Tomsik: i just showed you an example of the operation. if you dont get the example, well, fine. it was clear enough, but whatever.
04:32:32 <Tomsik> I'm not going to do guesswork to try to understand what do you want to do
04:32:52 <ManateeLazyCat> ivanm: I use "str <- readFile "/test/Download/Huge.hs" " save entire file into variable, i also can use "putStrLn str" print string.
04:33:16 <augur> you're already doing guesswork by interacting with humans. if you dont want guesswork, you should start speaking in predicate logic.
04:33:18 <ClaudiusMaximus> ManateeLazyCat: i'd find out how many bytes the file contains, then use hGetBuf to read it directly into memory rather than going via String
04:33:44 <Tomsik> augur: _(a(*b)) -> bbbbbb, aab, aa, abbbbbbbbba
04:33:45 <ManateeLazyCat> @hoogle hGetBuf
04:33:45 <lambdabot> System.IO hGetBuf :: Handle -> Ptr a -> Int -> IO Int
04:33:46 <lambdabot> System.IO hGetBuffering :: Handle -> IO BufferMode
04:33:46 <lambdabot> System.IO hGetBufNonBlocking :: Handle -> Ptr a -> Int -> IO Int
04:33:48 <Tomsik> what do I mean?
04:34:02 <ivanm> ManateeLazyCat: it's because you have that intermediate "str" variable
04:34:10 <ivanm> use an explicit >>= or something
04:34:17 <ClaudiusMaximus> > 16 * 44
04:34:18 <lambdabot>   704
04:34:42 <Tomsik> If you can't tell me, then go back to the preschool where they teach you how to communicate with people
04:35:10 <ManateeLazyCat> ClaudiusMaximus: Use hGetPut instead withCStringLen can fix problem?
04:35:32 <gwern> 1,2,4,8 - obviously the next number is 3, as they are all positive ints
04:35:45 * ManateeLazyCat pasted "textBufferSetText" at http://paste2.org/get/906396
04:35:45 <ManateeLazyCat> ivanm: Above is source code of textBufferSetText in gtk2hs.
04:35:52 <augur> ivanm, do you get the gist of what im saying in [*[a,b],c,*[d,e]] = [a,b,c,d,e]?
04:36:19 <ivanm> augur: not at all
04:36:21 <augur> ok.
04:36:28 <ivanm> I have no idea what you're talking about
04:36:49 <Tomsik> Obviously we're too stupid to talk to augur 
04:38:06 <ivanm> is there a generic version of zipWith that works on Seq values?
04:38:12 <augur> Tomsik: i'd say you certainly are. ivanm, however, doesn't understand quite what i mean, and so thats my fault.
04:38:57 * ivanm goes back to hacking on graphviz
04:39:19 <Deewiant> ivanm: http://www.haskell.org/haskellwiki/Foldable_and_Traversable#Generalising_zipWith
04:39:27 <ivanm> ta Deewiant 
04:39:40 <ManateeLazyCat> ivanm: textBufferSetText textBuffer =<< readFile "/test/Download/Huge.hs" , nothing help, maybe it's a problem of withCStringLen that withCStringLen use intermediate variable in it's implementation.
04:39:41 <ivanm> wait, actually, I don't want zipWith anyway, as I want to keep the longer version...
04:40:14 <ManateeLazyCat> ivanm: So my memory problem will fix if i avoid use intermediate variable? Or have better solution? 
04:40:23 <ivanm> ManateeLazyCat: I think that will do it, yes
04:40:35 <ivanm> but my IO-fu is weak :s
04:41:10 <etpace> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27090#a27090 <- anyone got any tips? this doesnt actually work at all because the merge m1 m2 just causes an infinite loop, so i think im approaching this incorrectly
04:41:11 <ManateeLazyCat> ivanm: Thanks for your help, i will try to change gtk2hs code to avoid textBufferSetText use intermediate variable.
04:41:13 <augur> ivanm: you can sort of imagine the * in [*[1,2],3,*[4,5]] as "stripping" the brackets off it's argument. not that thats how it would be implemented, right
04:41:32 <ivanm> I still am not sure what you're actually doing there
04:41:45 <augur> in what sense?
04:43:03 <augur> you see the brackets right? how theres a list next to the *'s? well pretend like "applying" * to the list means to erase the brackets for that list. no in any literal sense, but just in terms of how the representations look before and after evaluation
04:43:28 <ivanm> what you're trying to do
04:44:16 <augur> what i'm trying to do ...
04:44:18 <augur> yes?
04:44:32 <ivanm> I don't get what you're trying to do
04:44:35 <iocor> can anyone take a look at my happy grammar and suggest why it's erroring with "Undefined rule '!'" http://dpaste.com/215456/
04:45:43 <Tomsik> iocor: is this when you're compiling, parsing something or?
04:45:53 <iocor> Tomsik: when I'm compinling the gramamr
04:45:56 <gwern> ivanm: what would zipWith look like on Seq? Seq a -> Seq b -> Seq (a,b)?
04:46:19 <ivanm> gwern: well, that'd be zip
04:46:32 <gwern> ivanm: well, I can't remember what the function is supposed to look like
04:46:41 <Gertm> is "The Haskell school of expression" still a good resource to learn the language? (differences with more recent versions?)
04:46:51 <gwern> ivanm: if the result is [(a,b)], then zipWith on Seq is just zipWith . toList :)
04:47:02 <ivanm> anyway, I just want to compare two Seqs and see which is longer; not sure why I thought of zipWith :s
04:47:08 <iocor> Tomsik: any ideas?
04:47:08 <gwern> ivanm: what
04:47:09 <ivanm> Gertm: it's fairly decent
04:47:19 <Gertm> ivanm: I feel a 'but' coming :)
04:47:26 <gwern> ivanm: you want to shun a O(1) Seq.length in favor of zips?
04:47:31 <ivanm> gwern: some of its ideas are a bit old
04:47:36 <ivanm> s/gwern/Gertm/
04:47:49 <Gertm> ivanm: old but not wrong?
04:47:50 <Tomsik> Oh well, I thought I could help with the grammar itself if this was the problem, but no, I don't know the syntax too well
04:47:52 <Tomsik> sorry :(
04:48:07 <ivanm> Gertm: I haven't read SoE for a while, but Craft of Functional PRogrammign uses Floats for example, whereas I can't recall the last time I saw "Float" in real Haskell code
04:48:34 <ivanm> gwern: I want to compare the values: if one is a prefix of the other, take the longer; if not take the first one
04:48:50 <Tomsik> Or maybe it's the problem with ambiguity of '!'
04:48:58 <Tomsik>     | '!' (Exp) {Not $2}
04:49:02 <gwern> ivanm: prefix, huh. that's going to be expensive
04:49:06 <Tomsik>     | '!' Term {Not (Term $1)}
04:50:02 <iocor> Tomsik: you were right
04:50:03 <ivanm> gwern: I don't expect them to be long; this is comparing in which clusters a node is in in Dot code
04:50:56 <Tomsik> Oh :p
04:50:58 <augur> ivanm, i cant write this in actual haskell for type reasons, but i think this will explain the _algorithm_
04:50:58 <augur> roughly
04:51:19 <Tomsik> Generally, things like unary '-' and binary '-' are a nightmare when it comes to grammars
04:51:40 <Gertm> ivanm: so what would be a good step after working through that book?
04:52:01 <Gertm> ivanm: haskell scares me, I want a 'soft' path, SoE seems to be just that
04:52:49 <Tomsik> iocor: I'm not sure why you use terms as a different category of things
04:52:54 <augur> stripStar xs [] = xs ;  stripStar xs (Star y):ys = stripStar (xs ++ [y]) ys ;  stripStar xs y:ys = stripStar (xs ++ [y]) ys
04:52:57 <ivanm> Gertm: either SoE, Craft or "programming in Haskell" should be good as beginner books (the last one is rather new and up-to-date, but does use symbols which can be confusing)
04:53:09 <ivanm> Gertm: there's also LYAH if you're happy with an online tutorial
04:53:16 <ivanm> once you've finished them, I recommend you hack on a project
04:53:20 <ivanm> and after a whiel read RWH
04:53:46 <augur> no sorry, i wrote that wrong ivanm :D
04:53:56 <augur> stripStar xs [] = xs ;  stripStar xs (Star y):ys = stripStar (xs ++ y) ys ;  stripStar xs y:ys = stripStar (xs ++ [y]) ys
04:54:42 <augur> ivanm: /now/ do you understand?
04:55:14 <ivanm> OK, put it this way; I accept that for some reason you want to have some kind of list-like data structure where you can perform such an operation
04:55:23 <ivanm> what I don't get is _why_ you want this, or what the point is
04:55:33 <augur> i wasnt asking you to understand why :|
04:55:47 <augur> i was asking you if you've heard of anything like this so i could do read some papers
04:56:22 <ivanm> not really
04:56:25 <augur> if you asked me if ive ever heard of a probablistic programming language i would bitch about how i dont understand why you'd want such an thing blah blah blah
04:56:26 * ivanm doesn't read many CS papers
04:56:32 <augur> i'd just tell you about Java2k
04:57:02 <augur> or i'd say no, if i didnt know of one
04:57:24 <augur> *sigh*
04:57:42 <augur> i should stick to talking to Saizan and Cale and ddarius and ski
04:58:15 <augur> they're not .. whatever this is.
04:58:29 <wli> Probabilistic grammars are around, so you can get the sort of programming language -like affair as you get out of semi-Thue systems maybe with some other limits.
04:59:05 <Tomsik> what does semi-Thue has to do with this now
04:59:12 <ManateeLazyCat> @src withCStringLen
04:59:13 <lambdabot> Source not found. Take a stress pill and think things over.
04:59:33 <ivanm> augur: I was wondering what you wanted it for to possibly suggest an alternate approach
04:59:44 <wli> Tomsik: Enough crap added onto grammars to make them programmabe.
04:59:45 <ivanm> I mainly just use Haskell, rather than being an FP researcher or anything
05:00:12 <Tomsik> wli: I know what semi-Thue is and why it is so scary, but I'm not sure why you're mentioning it now
05:00:14 <augur> Tomsik, for the record on /your/ intelligence, I asked the same question to a programming-naive friend. he understood fine. you should look into that.
05:00:40 <Tomsik> augur: asking for motivations and context is a natural thing
05:01:11 <wli> Tomsik: Probabilistic grammars basically want the idea of a grammar to be extended enough to program with.
05:01:29 <augur> ivanm: its not that i want it for anything, per se. i mean, i have a use for it, and a solution that works fine. im just curious if its something anyone has looked at, because it seems like the logical converse of non-deterministic values
05:01:43 <wli> Tomsik: That is, to get enough of whatever to have a probabilistic programming language.
05:01:54 <ManateeLazyCat> ivanm: Out of curiosity, why intermediate variable will cause readFile eat memory?
05:02:09 <FunctorSalad> is there something in HSH corresponding to ";" in the shell?
05:02:11 <ivanm> ManateeLazyCat: because it loads the entire file into memory and keeps it there in case you need it
05:02:15 <Tomsik> okay, but you need just ab -> c and a -> bc kind of rules to get full semi-Thue
05:02:16 <ivanm> *need it later on
05:02:26 <FunctorSalad> (on the level of combining ShellCommand instances)
05:02:33 <ivanm> augur: *shrug* I do graph stuff ;-)
05:02:47 <augur> now i know
05:03:18 <ManateeLazyCat> ivanm: But why it eat *all* memory even i file size just 42MB ?
05:03:33 <ivanm> good question ;-)
05:03:37 <ivanm> probably something else going on
05:03:44 <ivanm> ManateeLazyCat: try a smaller file, see if it still blows up
05:03:59 <FunctorSalad> or any other way to do: "{ foo; bar; } | baz" other than HSH.run'ing the foo and bar
05:04:08 <wli> Tomsik: I'm not sure what the minimum necessary to be able to program is.
05:04:19 <FunctorSalad> (I think that'd strictify the pipe)
05:06:42 <Eduard_Munteanu> Hi.
05:06:56 <Tomsik> Hello there
05:07:28 <Eduard_Munteanu> I'm trying to compile lambdabot on Gentoo, but it bails out on /usr/lib64/libreadline.so because it's a script.
05:07:31 <FunctorSalad> running as in: (\() -> liftM2 (++) (runString foo) (runString bar)) -|- baz
05:07:37 <Eduard_Munteanu> How would I go about overriding stuff in the build process?
05:07:48 <FunctorSalad> I'd like a command-level combinator like -|- instead
05:08:20 <Ke> Eduard_Munteanu: I think there has been discussions about a generic solution for that kind of problems
05:08:25 <wli> Tomsik: Anyway, there are plausible programming language semantics for it all.
05:08:38 <Ke> there was some patch for ghc, that would be applied later
05:08:53 <Tomsik> Well. It's Turing-complete, so. :p
05:08:58 <Eduard_Munteanu> Ke: ah, thanks.
05:09:05 <Eduard_Munteanu> Though I'm still looking for a workaround.
05:09:14 <Eduard_Munteanu> *an easy one.
05:09:19 <augur> mph.
05:09:33 <augur> my linguistic theorem prover is turing complete. XD
05:09:37 <Ke> Eduard_Munteanu: meanwhile I guess you could link against some libreadline that is not a script
05:10:06 <Eduard_Munteanu> Ke: yeah, but I can't tell how. It's not exactly the normal Makefile build system I'm accustomed to :)
05:10:19 <Ke> =o)
05:10:34 <augur> ok, im off to university. see you guyses in a bit
05:10:43 <Eduard_Munteanu> augur: have fun.
05:11:13 <ManateeLazyCat> ivanm: I guess something is wrong, gtk2hs binding (Foreign.C.withCStringLen) or readFile, i can use gedit or emacs open those huge file.....
05:11:41 <ivanm> ManateeLazyCat: as I said, try with a small file and see if the memory still blows up
05:11:52 <ManateeLazyCat> ivanm: Yes, i'm trying it....
05:11:54 <Gertm> ivanm: thanks for the help, thebookdepository.co.uk seems to have most of those at a reasonable price. I'll probably get 'programming in' and SoE
05:12:05 <zygoloid> woo, haskell 2010 is finally out :)
05:12:09 <Eduard_Munteanu> I tried using --extra-lib-dir on cabal install, and LD_LIBRARY_PATH, but won't do.
05:12:11 <ivanm> Gertm: are you at a uni?
05:12:21 <ivanm> because if so, you might be able to get programming in online via ACM
05:12:22 <FunctorSalad> btw does anyone know if the maintainer of HSH is still active (here maybe?)?
05:12:27 <ivanm> FunctorSalad: who is it?
05:12:50 <FunctorSalad> (otherwise it'd be frustrating to add that combinator properly ;))
05:13:13 <FunctorSalad> ivanm: John Goerzen
05:13:37 <FunctorSalad> thought I'd seen a similar nickname here once ;)
05:13:39 <Gertm> ivanm: no, I've graduated quite some time ago :) Just want to learn Haskell as a hobby
05:13:51 <ivanm> fair enough
05:13:54 <ivanm> FunctorSalad: CosmicRay
05:13:59 <ivanm> and he's very rarely online
05:14:03 <ivanm> better off emailing him
05:14:06 <FunctorSalad> ah thanks
05:14:10 * Eduard_Munteanu thinks of trying LDFLAGS.
05:15:08 <FunctorSalad> just had a bad experience with a th-fold upgrade that never got an answer ;) but didn't consider it brilliant enough to make a fork
05:15:28 <FunctorSalad> (not rejected, just no answer)
05:17:11 <FunctorSalad> (and the package hasn't changed otherwise either)
05:21:18 <ivanm> @hoogle monadplus
05:21:18 <lambdabot> Control.Monad class Monad m => MonadPlus m
05:30:25 <zygoloid> haskell seems uncharacteristically inconsistent about its use of Captials in types versus in expressions
05:30:39 <ManateeLazyCat> ivanm: I have test, looks i need 40 ~ 50 times the memory, when i read 1MB, it eat 407MB memory. If so, when i open 40MB file, then memory used up 1.6GB, and i just 2GB RAM in my box...
05:30:53 <zygoloid> (constants at the type level are capitalized but constants at the value level are not)
05:31:06 <Axman6> eh?
05:31:06 <ivanm> ManateeLazyCat: OK, you're doing something wrong :p
05:31:08 <Axman6> example?
05:31:24 <ivanm> zygoloid: types and constructors are capitalised; everything else isn't
05:31:26 <ivanm> greetings Axman6 
05:31:31 <Axman6> ManateeLazyCat: are you reading in a file as a String?
05:31:33 <Axman6> 'lo
05:31:37 <Jafet> > let true = True in true == True
05:31:38 <lambdabot>   True
05:31:38 <ManateeLazyCat> Axman6: Yes.
05:31:42 <zygoloid> ivanm: yes. but at the exression level it's only constructors which are capitalized
05:32:01 <ivanm> well, yes, how is that inconsistent?
05:32:13 <zygoloid> type Plus3 a = Succ (Succ (Succ a)); plus3 a = succ (succ (succ a))
05:32:18 <zygoloid> ^^ that's inconsistent
05:32:19 <Jafet> lazycat: Char is 4 bytes probably, and that's not including the extra tags for [a]
05:32:21 <Axman6> ManateeLazyCat: well unless you process the String lazily, the whole thing will be read into memory, as a vary inefficient String. use a ByteString
05:32:32 <Axman6> or make sure that you only pass over the data once
05:32:32 <ManateeLazyCat> Axman6: Above are example, 
05:32:33 * ManateeLazyCat pasted "example code." at http://paste2.org/get/906437
05:33:52 <ManateeLazyCat> Axman6: In gtk2hs have function "textBufferSetText", it use withCStringLen convert *readFile string* to CString pointer with String Length.
05:33:57 <zygoloid> this is very apparent with type families, where type functions are capitalized, but value functions aren't.
05:34:11 <ManateeLazyCat> Axman6: I guess withCStringLen eat my memory...
05:34:39 <Jafet> GUI scrolling buffers should be lazy, anyway
05:35:10 <zygoloid> (i guess this is ultimately caused by the implicit foralls in types -- you need the variable/NotVariable distinction to know what to quantify over)
05:36:11 <FunctorSalad> hmm lowercase type syn families might be a good idea (to make it clear they're not injective)
05:36:11 <dolio> Seems likely.
05:36:30 <ManateeLazyCat> @hoogle withCStringLen
05:36:31 <lambdabot> Foreign.C.String withCStringLen :: String -> (CStringLen -> IO a) -> IO a
05:36:42 <zygoloid> FunctorSalad: yeah. at the expression level, capitalized implies injective (which implies pattern-matchable)
05:37:00 <ManateeLazyCat> Jafet: Do you have any idea that read file and transfer C pointer to C function?
05:37:03 <FunctorSalad> maybe grab some spare character as leader to avoid clash with variables ;)
05:37:04 <zygoloid> at the type level you just have to know that some things are type families and some things are data families
05:37:16 <FunctorSalad> type instance @plus ....
05:37:52 <ManateeLazyCat> @hoogle withCStringLen
05:37:52 <lambdabot> Foreign.C.String withCStringLen :: String -> (CStringLen -> IO a) -> IO a
05:37:58 <ManateeLazyCat> @hoogle CStringLen
05:37:58 <lambdabot> Foreign.C.String type CStringLen = (Ptr CChar, Int)
05:37:58 <lambdabot> Foreign.C.String newCStringLen :: String -> IO CStringLen
05:37:58 <lambdabot> Data.ByteString packCStringLen :: CStringLen -> IO ByteString
05:38:06 <FunctorSalad> "it's a variable if it isn't a type family" would be too brittle
05:38:13 <zygoloid> FunctorSalad: why do you need a spare character at all? type instance a `plus` b seems unambiguous
05:38:26 <FunctorSalad> (against changing the name of the tysyn family)
05:38:29 <zygoloid> ah right, in type signatures, yeah :/
05:38:43 <FunctorSalad> (you wouldn't get an error, or not the correct one)
05:39:18 <zygoloid> type families in all-uppercase? :)
05:39:25 <Jafet> lazycat: maybe Foreign.Marshall
05:39:38 <ManateeLazyCat> Jafet: Thanks, i reading it.
05:39:42 <FunctorSalad> I mean that if you change the name of the family at declaration but not at usage, you suddenly get universal quantification instead of a name error
05:40:05 <dolio> That'd probably still lead to an error.
05:40:06 <zygoloid> yes, that's true. implicit foralls to blame still :)
05:40:07 <dolio> Just not a good one.
05:40:31 <Jafet> Although, putting 40 MB in a gtk text buffer doesn't ever sound like a good idea.
05:40:50 <ManateeLazyCat> Jafet: But i can read it in Emacs or gedit.
05:41:02 * zygoloid thinks that perhaps the type and the expression language are just a little too different for type-level programming to ever feel completely natural
05:41:04 <ManateeLazyCat> Jafet: Since gedit also use GTK+, so i think it's wrong with withCStringLen.
05:42:08 <ManateeLazyCat> Jafet: I'm develop a gtk+ editor, there is no reason not to support large files.....
05:42:10 <zygoloid> the closest we have to * at the type level is Dynamic
05:43:21 <FunctorSalad> uh and the value level isn't a wannabe prolog ;)
05:43:37 <ManateeLazyCat> Jafet: I have test gedit, it use 200MB after open 40M file.
05:43:48 <FunctorSalad> seems easier to state the commonalities than the diffs
05:44:12 <ManateeLazyCat> Jafet: Since gtk2hs use same APIs, we should use same memory.....
05:44:17 <zygoloid> yeah, there's no value-level unification (but conal's lub is pretty close)
05:44:40 * ManateeLazyCat Investigate withCStringLen....
05:44:48 * zygoloid deliberately ignores functional dependencies
05:45:30 <Jafet> Ok. gedit doesn't use ordinary text buffer though
05:45:41 <FunctorSalad> ignore? how do you get anything at all done on the type level without them or type fams?
05:45:52 <FunctorSalad> afk
05:47:00 <ManateeLazyCat> Jafet: What do you mean "gedit doesn't use ordinary text buffer though" ? 
05:48:16 <Jafet> ManateeLazyCat: doesn't it use gtkSourceView, not gtkTextBuffer?
05:48:36 <ManateeLazyCat> Jafet: I think GtkSourceView is base on GtkTextBuffer.
05:49:08 <ManateeLazyCat> Jafet: GtkSourceView just add extra feature about variable language, such as syntax highlight. 
05:49:24 <ManateeLazyCat> Jafet: Infact, GtkSourceView is TextViewClass 
05:50:02 <ManateeLazyCat> Jafet: GtkSourceBuffer base on GtkTextBuffer, GtkSourceView base on GtkTextView.
05:50:15 <Jafet> Er, right.
05:50:56 <ManateeLazyCat> Jafet: For loading file content, i think GtkSourceBuffer same as GtkTextBuffer.
05:52:57 <ManateeLazyCat> Jafet: When i open 10MB file, gedit just use 47.5MB, but gtk2hs use 410.9MB, so i think gtk2hs binding cause speak leak.
05:53:48 <Jafet> Well... you're using Bytestring all the way, right?
05:53:58 <ManateeLazyCat> Jafet: No, i just use readFile.
05:54:08 <Raynes> Boom
05:54:33 <ManateeLazyCat> Jafet: ByteString will help since gtk_text_buffer_set_text need argument type "String"?
05:54:51 <ManateeLazyCat> need CString pointer.
05:55:11 <Jafet> I think you can get a foreign ptr out of bytestring
05:55:49 <ManateeLazyCat> Jafet: Have any APIs that convert ByteString to ForeignPtr?
05:56:08 <kmc> Leading member of Haskell community declares that Haskell is "inconsistent in more than two ways"
05:56:27 <Jafet> Stop press!
05:56:31 <Jafet> lazycat: http://www.haskell.org/ghc/docs/6.12.2/html/libraries/bytestring-0.9.1.6/Data-ByteString.html#22
05:56:47 <ManateeLazyCat> Jafet: Thanks for your help, reading.....
05:58:48 <ManateeLazyCat> @hoogle CStringLen
05:58:49 <lambdabot> Foreign.C.String type CStringLen = (Ptr CChar, Int)
05:58:49 <lambdabot> Foreign.C.String newCStringLen :: String -> IO CStringLen
05:58:49 <lambdabot> Data.ByteString packCStringLen :: CStringLen -> IO ByteString
05:58:58 <ManateeLazyCat> @hoogle useAsCStringLen
05:58:58 <lambdabot> Data.ByteString useAsCStringLen :: ByteString -> (CStringLen -> IO a) -> IO a
05:58:59 <lambdabot> Data.ByteString.Char8 useAsCStringLen :: ByteString -> (CStringLen -> IO a) -> IO a
05:58:59 <lambdabot> Data.ByteString.Unsafe unsafeUseAsCStringLen :: ByteString -> (CStringLen -> IO a) -> IO a
05:59:06 <ManateeLazyCat> Hmm, interesting...
05:59:51 <ManateeLazyCat> @hoogle withCStringLen
05:59:52 <lambdabot> Foreign.C.String withCStringLen :: String -> (CStringLen -> IO a) -> IO a
06:01:36 * ManateeLazyCat Try to use useAsCStringLen re-implement textBufferSetText...
06:02:12 <kamatsu> hm
06:02:27 <kamatsu> would a feature in haskell to automatically generate catamorphisms for a data type be useful?
06:02:53 <kamatsu> e.g you could have a typeclass and a deriving instance.
06:03:20 <kamatsu> oh, except the catamorphism would vary in type and kind.
06:03:22 <kamatsu> hm
06:04:43 <kmc> yes
06:05:07 <kmc> there is a good deal of research on this subject under the name of "generic programming"
06:05:23 <kamatsu> ah, so that's what all that stuff is about
06:05:26 <kamatsu> i never could penetrate it
06:05:34 <ManateeLazyCat> Jafet: Works!
06:05:38 <wli> In-core B-trees are a bit painful.
06:05:38 <kamatsu> does someone have a link to help me read + understand it?
06:06:01 <Jafet> lazycat: great
06:06:06 <ivanm> greetings kamatsu 
06:06:10 <ManateeLazyCat> I use useAsCStringLen re-implement textBufferSetText, then i just use 53MB RAM when i open 10MB file. 
06:06:13 <kamatsu> ivanm: greetings ivanm
06:06:25 <ManateeLazyCat> Jafet: Thank you very much! :)
06:07:11 <kmc> the type of the catamorphism depends on the type of the data type
06:07:11 <kmc> so it's not as straightforward as a simple type class
06:07:11 <kmc> "depends on the shape of the data type" i mean
06:09:39 <kmc_> :t gfoldl
06:09:40 <lambdabot> forall (c :: * -> *) a. (Data a) => (forall d b. (Data d) => c (d -> b) -> d -> c b) -> (forall g. g -> c g) -> a -> c a
06:10:08 <kmc> warning: attempting to understand the type of gfoldl has been known to cause madness
06:10:16 <Jafet> -XDeriveUntilItCompiles
06:10:36 <kmc> wrap every type error in unsafeCoerce
06:11:29 <wli> I don't know of B/B+ tree algorithms to maintain ranks but I am aware of binary tree algorithms to do so.
06:11:31 <ManateeLazyCat> Jafet: Can you explain why such a big gap between String and ByteString?
06:12:32 <Jafet> lazycat: I did. [] is non-strict and Char is 4 bytes, so that adds up to maybe 10x overhead per character
06:12:50 <Jafet> Or more
06:12:57 <ManateeLazyCat> Jafet: I see.
06:13:21 <ManateeLazyCat> Jafet: gtk2hs use String everywhere.... 
06:15:17 <quicksilver> Jafet: 24x, IIRC
06:15:27 <quicksilver> (on a 64-bit machine, 16x on a 32 bit, again IIRC)
06:15:52 <ManateeLazyCat> quicksilver:  24x really? All the time?
06:15:59 <quicksilver> yes.
06:16:19 <ManateeLazyCat> quicksilver: Maybe i need convert all gtk2hs APIs to ByteString......
06:16:27 <quicksilver> I don't think so.
06:16:38 <quicksilver> in most cases the memory usage is irrelevant
06:16:46 <quicksilver> String is more convenient and occasionally even faster.
06:16:49 <ManateeLazyCat> quicksilver: I just found a problem with gtk2hs function "textBufferSetText" use 400MB, it just use 50MB when i change to ByteString.
06:17:10 <quicksilver> ByteString or Text is appropriate for very large strings yes
06:17:20 <quicksilver> most strings in the gtk2hs API are not very large
06:17:27 <ManateeLazyCat> quicksilver: Yes.
06:17:29 <Saizan_> kmc: cata :: Functor f => (f a -> a) -> Mu f -> a, so simple! :)
06:17:38 <ManateeLazyCat> quicksilver: Just some APIs need read from *huge* file.
06:17:42 <quicksilver> in fact, in a typical gtk program, 84% of the strings are the two-character string "OK".
06:18:24 <ManateeLazyCat> quicksilver: When i use old version "textBufferSetText" to read 40MB file, it freeze my box.
06:18:39 <wli> That sounds like unnecessary bloat.
06:19:03 <quicksilver> ManateeLazyCat: I don't disagree that for huge files ByteString/Text is better.
06:19:15 <quicksilver> I just disagree that you should convert "all gtk2hs APIs"
06:19:21 <quicksilver> maybe I misunderstood what you meant.
06:19:33 <ManateeLazyCat> quicksilver: I said "maybe". :)
06:20:31 <quicksilver> MaybeLazyCat
06:20:53 <ManateeLazyCat> quicksilver: If i change all APIs, i think all gtk2hs user will curse me. 
06:20:55 <ManateeLazyCat> :)
06:23:02 <Tomsik> can't you just have ByteString versions for things that might take large data?
06:23:13 <Tomsik> or even better, give them suffix "Large" :p
06:23:23 <FunctorSalad> kamatsu: there's even a paper about how it has become a cottage industry IIRC ;)
06:23:32 <FunctorSalad> (generics frameworks)
06:23:37 <ManateeLazyCat> Tomsik: Yes, i plan add ByteString version instead replace String version.
06:23:44 <orlandu63> 09:18:59     quicksilver | maybe I misunderstood what you meant.                                                                              x Anti-X
06:23:47 <orlandu63> oops
06:23:54 <ManateeLazyCat> Tomsik: textBufferSetByteString something.
06:23:58 <Tomsik> yeah
06:24:02 <FunctorSalad> the devil is (at least in part) in the details with that stuff
06:24:27 <FunctorSalad> (e.g. making the final interface understandable to others ;))
06:26:09 <eikke> if I got an existing typeclass A, and I create a typeclass B myself, is there any obvious way to define a generic implementation of B for every instance of A?
06:28:01 <ManateeLazyCat> Haven't useAsUTFStringLen? I want convert ByteString to UTF version.
06:28:17 <quicksilver> a byte string is just bytes
06:28:24 <quicksilver> you can't "Convert" it to UTF8
06:28:33 <quicksilver> it either is, or it isn't, and it's your fault - you made it.
06:28:48 <Jafet> eikke, that seems to need overlapping instances
06:28:49 <quicksilver> you can encode a String as UTF8 into a ByteString, of course.
06:29:43 <eikke> Jafet: guess I'll have some reading ahead then
06:29:51 <kmc> the overlapping instances solution doesn't really work
06:29:59 <kmc> otherwise we'd use it to solve the Monad/Applicative problem
06:30:17 <kmc> eikke, there isn't a good way, to my knowledge :/
06:34:01 <kmc> eikke, the way Applicative kinda-solves the problem is to introduce «newtype WrappedMonad m a = WrappedMonad (m a)» and «instance Monad m => Applicative (WrappedMonad m)»
06:34:05 * ManateeLazyCat Hmmm, looks gtk_text_buffer_set_text encode string to utf8 automatically, i don't need convert it....
06:34:08 <kmc> that's cumbersome and i don't think many people use it
06:34:23 <tibbe> anyone have experience of using Hinze style views and getting the intermediate data type to get optimized away?
06:35:55 <eikke> kmc: guess I wont use a typeclass then and just hardcode usage of A, and prey I'll never need a completely different implementation
06:36:20 <kmc> eikke, maybe you can describe in more detail what you're doing?
06:36:26 <kmc> maybe it doesn't require type classes at all
06:36:37 <kmc> it is hard to abstract over type classes, but all you need to abstract over a function is another function
06:37:22 <eikke> kmc: I'm trying to write some toy server application which should be able to store and retrieve values from a datasource
06:37:37 <eikke> I wanted to define a class for this datasource (get/set) interface
06:41:09 <kmc> eikke, ok. where do multiple classes come in?
06:42:13 <eikke> kmc: there's a library I'd like to use, which exposes several backends, all instances of a single class
06:43:17 <quicksilver> 1. mutter at library author for using classes. 2. Write overloaded function which converts class to Dictionary. 3. mutter some more. 4. profit
06:43:29 * edwardk waves hello.
06:43:36 * benmachine waves edwardk 
06:43:55 * edwardk is waved.
06:44:02 * djahandarie does the wave
06:44:33 * Jafet particles
06:44:55 <aristid> quicksilver: this doesn't sound like haskell?
06:45:26 <kmc> yeah what quicksilver said
06:46:04 <kmc> i wish instances were first-class, so this weren't necessary
06:46:18 <quicksilver> quicksilver's first rule of using typeclasses - if you think you want a typeclass, you don't. Think again.
06:46:24 <FunctorSalad> :)
06:46:49 <quicksilver> typeclasses are a neat hack for overloading operators. They are not a general abstraction mechanism.
06:46:53 <FunctorSalad> I was just thinking why ShellCommand isn't just a function too
06:47:05 <quicksilver> When you try to use them as a general abstraction mechanism you find out how bad they are at that.
06:47:08 <aristid> quicksilver: so Monad for example should not be a typeclass?
06:47:19 <quicksilver> Monad is an excellent example of what *should* be a typeclass.
06:47:26 <quicksilver> It's all about overloading, and not at all about abstraction.
06:47:59 <kmc> yeah, monad is the way you overload operators (>>=) and "return"
06:48:05 <FunctorSalad> class (Show a) => ShellCommand a where fdInvoke :: a -> Environment -> HSH.Channel.Channel -> IO (HSH.Channel.Channel, [InvokeResult])
06:48:10 <FunctorSalad> ^^^^ this one
06:48:14 <aristid> quicksilver: should Data.Foldable be a typeclass?
06:48:30 <edwardk> aristid: yes
06:48:42 <FunctorSalad> admittedly, have a TC gives you String and (String,[String]) as instances, which is nice
06:48:50 <FunctorSalad> OTOH that could be solves with -XOverloadedStrings
06:48:51 <kmc> yes, it's how you overload foldr and foldMap and such
06:48:55 <FunctorSalad> *solved
06:49:11 <kmc> the problem comes when people use type classes solely as a way to associate different behaviors with different values
06:49:11 <Saizan_> quicksilver: i never really quite grasped what you mean by abstraction vs. overloading when you say that, i only have some vague idea
06:49:17 <kmc> we already have a way to do that, they're called functions
06:49:21 <aristid> hmm do you have an example for what should NOT be a typeclass? :)
06:49:48 <kmc> aristid, a database backend
06:49:48 <FunctorSalad> how's a typeclass + existential any worse than just starting with the dictionary though?
06:50:08 <Saizan_> FunctorSalad: harder to make instances on the fly
06:50:14 <aristid> kmc: that should be a parameter to polymorphic module :)
06:50:18 <kmc> yes ideally
06:50:19 <aristid> *to a
06:50:26 <kmc> but a simple record does well enough
06:50:28 <FunctorSalad> Saizan_: the existential would itself be a universal instance :)
06:50:35 <quicksilver> Saizan_: well, for example, they shouldn't be used the way classes are in Java.
06:50:38 <FunctorSalad> (and you can make values of it at runtime)
06:50:40 <kmc> aristid, it's common to write APIs like «class DB a where { readDb :: a -> IO Row; ... }; instance DB MySql where ...; instance DB Postgres where ...»
06:50:48 <kmc> often here the types MySql and Postgres aren't even storing anything useful!
06:50:51 <kmc> they're just tags to select a function
06:50:55 <kmc> this is backwards, Java thinking
06:51:01 <FunctorSalad> instance Show AnyShow where show (AnyShow x) = show x
06:51:05 <quicksilver> yes, kmc's example is good.
06:51:08 <aristid> hmm
06:51:13 <kmc> data DB = DB { readDb :: IO Row; writeDb :: Row -> IO a }
06:51:14 <aristid> what about the PointSet example in http://cale.yi.org/index.php/A_look_at_OO_from_Haskell ?
06:51:26 <Saizan_> FunctorSalad: that's not relevant for my point i think
06:51:45 <kmc> if you needed any data you were storing in the value of type MySql, it's now stored by closure in the values for readDb etc
06:51:54 <kmc> and nicely encapsulated without its type being exposed to users
06:52:11 <FunctorSalad> Saizan_: admittedly I forgot that you still need a throwaway newtype
06:52:15 <Saizan_> FunctorSalad: for example to make an instance that closes over some runtime acquired value you've to use the reflection package
06:52:28 <kmc> instead of "interfaces are classes, implementations are types" we have "interfaces are types, implementations are values"
06:52:53 <kmc> and this is real nice, because Haskell's powers of value abstraction are great, its powers of type abstraction less great, and its powers of class abstraction virtually nonexistent
06:53:01 <FunctorSalad> Saizan_: why? newtype Closure = Closure Foo , if Foo is the type of that runtime value
06:53:21 <kmc> aristid, did you read http://lukepalmer.wordpress.com/2010/01/24/haskell-antipattern-existential-typeclass/
06:53:24 <FunctorSalad> but I was off about the existential, yes
06:53:28 <aristid> kmc: not yet!
06:53:31 <kmc> :)
06:53:35 <FunctorSalad> the universal instance I was thinking of is the explicit dictionary
06:53:46 <kmc> it's about things that are classes and shouldn't be ;)
06:54:02 <FunctorSalad> (or an existential + explicit dictionary, even ;))
06:54:32 <FunctorSalad> newtype AdHocClosure19283 would be more accurate
06:54:54 <aristid> kmc: record inheritance might be nice
06:55:06 <kmc> aristid, what do you mean?
06:55:07 <aristid> data Window inherits Widget :D
06:55:16 <Saizan_> FunctorSalad: yeah, that's doing the reflection thing by hand :)
06:55:24 <FunctorSalad> ah ok
06:55:36 <aristid> kmc: it would pull in all record members
06:55:55 <kmc> oh, and provide the "upcast" function?
06:55:58 <kmc> yeah, that would be nice
06:56:01 <kmc> you could do it with TH
06:56:06 <FunctorSalad> Saizan_: hmm for some reason I thought reflection stores all the information in a type
06:56:12 <edwardk> anyways, i agree, if you're going to throw a typeclass in a box, you're probably better off just unboxing it and passing around functions
06:56:13 <arw> aristid: i rather like "window contains widget". less fiddly with overloading and stuff.
06:56:26 <quicksilver> it's only a marginal convenience over data Window { widget :: Widget, ... more stuff .. }
06:56:33 <kmc> i like that, because it seems to give the benefits of subtyping without actually introducing complication to the type system
06:56:49 <shapr> Gooood morning #haskell!
06:56:56 <quicksilver> and even that marginal convenience is mostly mitigated by a decent fclabels-like library.
06:57:36 <FunctorSalad> there's also a little bit of extra static knowledge
06:57:37 * shapr cheerfully throws lambdas
06:57:43 <alexbobP> of all irc channels I'm in, this is the only one that seems to be active 24/7
06:57:51 <FunctorSalad> that certain dictionaries must be equal (because they're for the same type)
06:57:59 <shapr> alexbobP: And we're fun and family friendly!
06:58:11 <FunctorSalad> sort-of
06:58:13 <shapr> alexbobP: So what got you into Haskell?
06:58:17 <FunctorSalad> (family friendly)
06:58:28 <aristid> quicksilver: which fclabels-like library should i learn?
06:58:34 <HugoDaniel> :D
06:58:36 <HugoDaniel> yay shapr! :D
06:58:45 <Jafet> We're type family friendly
06:58:49 <kmc> FunctorSalad, yeah, that static knowledge is important with things like the Ord constraint on Map
06:59:05 <FunctorSalad> edwardk: if you always box it anyway the TC is useless, but sometimes it might allow you to skip the boxing and just use the TC directly?
06:59:17 <shapr> Good morning HugoDaniel! How's code?
06:59:24 <alexbobP> shapr: what got me into haskell is how damned beautiful it is
06:59:29 <alexbobP> shapr: also mm_freak_
06:59:32 <FunctorSalad> seems like some slightly increased flexibility (purely convenience-wise)
06:59:38 <alexbobP> shapr: and how damned beautiful he is
06:59:43 <FunctorSalad> kmc: *nod*
06:59:52 <shapr> alexbobP: OK, I can understand the language factor, but I've never met mm_freak_ 
06:59:58 <edwardk> FunctorSalad: that is the main excuse i have for the existentially boxing like that. less hassle sometimes
07:00:26 <alexbobP> shapr: he wrote one of the bajillion monad tutorials (http://ertes.de/articles/monads.html) and he lurks in ##crypto
07:00:31 <edwardk> shapr: speaking of factor. ;) slava will apparently be at boston lisp this month
07:00:33 <shapr> alexbobP: Ah, that's cool.
07:00:44 <shapr> edwardk: Yeah, I saw that. I gotta get off the Boston geek mailing lists.
07:00:50 <edwardk> shapr: haha
07:00:55 <alexbobP> shapr: oh, another thing that got me into haskell is my rage against all the dang loosely typed languages popping up, with a corresponding flood of bad code that has really bizarre bugs
07:01:21 * edwardk whistles innocently about loose typing.
07:01:26 <shapr> alexbobP: Yup, I've spent years dealing with that.
07:01:47 <kmc> alexbobP, yeah.  there's a backlash against static types thanks to C++ and Java
07:01:56 <shapr> alexbobP: I ran across a bunch of production Python code in Plone where the common cases worked, and the other cases could never have done anything useful other than crash.
07:02:00 <quicksilver> aristid: probably fclabels.
07:02:05 <FunctorSalad> . o O ( taking the special case of static typing, where you forego actually proving anything about your code, as a "feature"... ;) )
07:02:07 * ManateeLazyCat Looks Cairo/Pango use hardware accelerate, when operate 1 million lines file still very fast...
07:02:07 <quicksilver> aristid: I have misgivings about it but I can't remeber what they are. ;)
07:02:18 <alexbobP> kmc: man, I like java a lot... it has a heaping helping of issues, but it's a fantastic language for rapid development
07:02:39 <alexbobP> I'd rather prototype something up in java than python any day.  at least my ide can still do static analysis :P
07:02:45 <kmc> alexbobP, but the effort:benefit ratio of Java's type system is much worse than Haskell's
07:02:59 <alexbobP> kmc: once someone is accustomed to haskell, sure
07:03:04 <ManateeLazyCat> alexbobP: Infact, i think Java's IDE is awesome.
07:03:05 <alexbobP> kmc: I'm still a newbie at it
07:03:09 <kmc> yeah fair enough
07:03:13 <alexbobP> ManateeLazyCat: which, eclipse?  that's what I use
07:03:20 <aristid> ManateeLazyCat: java has multiple IDEs
07:03:36 <kmc> i'm not talking about your situation personally; i was mostly explaining why i think there's a backlash against static types
07:03:47 <kmc> they're associated with a lot of effort and little gain
07:03:47 <alexbobP> shapr: yeah.  it bugs me how people don't even consider it a problem when overtly incorrect code will run just fine until it hits the specific problem part of the code
07:04:18 <alexbobP> meh, I don't think that's the case with java
07:04:27 <kmc> not as bad as C++, certainly
07:04:42 <alexbobP> Maybe it tkaes a bit of extra thinking to deal with static types, but if you spend more than 2 hours coding, it pays off
07:04:53 <aristid> i disagree, C++ has a much more expressive type system than java
07:05:01 <kmc> that doesn't contradict what i said
07:05:09 <shapr> kmc: Yeah, I explain that Haskell has all the effort of Python with type safety better than that of C++ or Java.
07:05:11 <alexbobP> because after 2 hours, you don't remember every little thing you've written, and it's *nice* to have your static analysis tools able to tell you useful things like "what the hell is the type of this variable here"
07:05:11 <ManateeLazyCat> alexbobP: If we have Haskell IDE like Eclipse for Java, then comparison is fair.
07:05:43 <alexbobP> ManateeLazyCat: man, if there was a haskell ide that could do what eclipse does, that's be teh secks
07:05:44 <FunctorSalad> advanced typing is hard, but that's because theorem proving is hard... it's not "for nothing"
07:05:50 * ManateeLazyCat I still think IDE just tools, but it's not mean you don't need the detail of yourself code.
07:05:54 <kmc> i have at about as much trouble understanding type errors from g++ as from ghc.  but once i understand a ghc error, it usually reveals either a typo or a deep conceptual mistake.  whereas the g++ error is often as not something picky and irrelevant
07:06:05 <alexbobP> aristid: I agree with you, I am a big fan of C++ ever since I learned it
07:06:12 <kmc> oh dear
07:06:17 <kmc> that'll start a big flamewar
07:06:18 <shapr> Maybe Yi will be the Haskell version of Eclipse?
07:06:19 <alexbobP> aristid: I hear a lot of complaints about C++ though, but they mostly seem to stem from "I've seen bad C++ code and it made me hurt"
07:06:35 <FunctorSalad> conversely, you could always make your haskell code very weak-typed to avoid the funny type errors... but often we choose not to
07:06:53 <aristid> alexbobP: but i think haskell is overall nicer than c++
07:07:08 <FunctorSalad> (Map String Dynamic instead of a record will make generics etc easy ;))
07:07:10 <Tomsik> Haskell and C++ have different purposes so
07:07:14 <shapr> FunctorSalad: Dynamic?
07:07:16 <alexbobP> aristid: I would put haskell as the number 1 sexiest programming language
07:07:16 <Tomsik> It's apples to oranges
07:07:18 <aristid> Tomsik: do they?
07:07:20 <edwardk> shapr: leksah seems to be stepping up nicely into that interactive role
07:07:25 <alexbobP> aristid: not to say I'd use it over C++ for every task, of course
07:07:28 <FunctorSalad> shapr: the existential for Typeable IIRC
07:07:28 <shapr> edwardk: Tell me!
07:07:38 <aristid> alexbobP: heh you sure love your static typing ;) (i love it too)
07:07:50 <nus> shapr, maybe, if people shut off their IRC clients and get coding (-;
07:07:53 <Tomsik> aristid: yeah, compact code vs low-overhead programs
07:07:58 <alexbobP> aristid: a friend and I have an mmo in the early planning/development stage, and we're going to use haskell and c++ together (since they can call each other)
07:08:10 <alexbobP> aristid: since it's easier to do the imperative grunt work in c++, and game logic in haskell
07:08:15 <aristid> Tomsik: well let's say these areas are overlapping
07:08:18 <quicksilver> alexbobP: it's not, actually.
07:08:29 <quicksilver> alexbobP: it's easier to do the imperative grunt work in haskell.
07:08:31 <alexbobP> quicksilver: hush, I like mah flat address space model!
07:08:35 <quicksilver> haskell is the best imperative language I know.
07:08:37 <kmc> "imperative" is not a reason to use C++ over haskell.  "soft real-time" and "explicit memory management" are valid reasons
07:08:42 <shapr> nus: Oh wait, we could integrate lambdabot into Yi!
07:08:48 <quicksilver> what *is* easier in C++ is real time / memory control
07:09:00 <Jafet> shapr: shudder
07:09:08 <Tomsik> aristid: I'm not sure about that
07:09:10 <alexbobP> kmc: well okay, that then.  the point is we are making a game engine, that will be working closely with graphics and physics apis, and stuff like that
07:09:16 <shapr> Jafet: Aw, it'd be fun! Yi could be the premier irc client for #haskell
07:09:20 <kmc> yeah
07:09:20 <aristid> quicksilver: the decision not to have a GC does have benefits
07:09:21 <Tomsik> I mean, in many areas you can use both Haskell and C++
07:09:24 <kmc> that makes sense alexbobP
07:09:26 <edwardk> alexbobP: only if your game logic can surivive 300ms pause times while GC happens
07:09:30 <FunctorSalad> shapr: http://www.haskell.org/ghc/docs/6.12.2/html/libraries/base-4.2.0.1/src/Data-Dynamic.html#Dynamic
07:09:37 <alexbobP> edwardk: :O  that doesn't sound okay...
07:09:38 <nus> shapr, heh, more like it would work other way around, embedding some collaborative coding setup into lambdabot (-:
07:09:45 <Tomsik> But if you think about programmer time and execution speed 
07:09:50 <Tomsik> then one always clearly wins
07:09:51 <FunctorSalad> not quite the existential, but isomorphic I'd say
07:09:55 <aristid> edwardk: 300 ms? i thought the haskell gc was faster than that
07:09:59 <Tomsik> considering a specific task
07:10:02 <kmc> GHC GC you mean?
07:10:08 <kmc> it rarely pauses 300 ms, but it can
07:10:10 <aristid> kmc: yes i just wanted to correct myself
07:10:12 <alexbobP> I mean if there are 300ms pauses we would seriously have to consider not using haskell -_-
07:10:19 <shapr> nus: Close enough... I can see integration with hpaste that lets you dump it directly into ghci
07:10:21 <alexbobP> is it possible to make sure that doesn't happen?
07:10:27 <kmc> good question
07:10:29 <FunctorSalad> (Foo,Foo->Bar) being isomorphic to (Foo,Bar)
07:10:33 <ManateeLazyCat> alexbobP: I think we can build awesome Haskell IDE similar Eclipse for Java.
07:10:37 <FunctorSalad> (is it?)
07:10:45 <aristid> :t uncurry (flip ($))
07:10:46 <lambdabot> forall a b. (a, a -> b) -> b
07:10:47 <edwardk> alexbobP: fraid not. the immix stuff in this year's GSoC might help, might not
07:10:51 <alexbobP> ManateeLazyCat: It's certainly doable.  I hope it happens.
07:11:12 <ManateeLazyCat> alexbobP: http://farm5.static.flickr.com/4098/4771492256_e1f3a318ef_b.jpg
07:11:14 <edwardk> alexbobP: anyways there is a reason i don't write game code in haskell ;)
07:11:15 <aristid> FunctorSalad: well, not isomorphic because it only goes in one direction i think
07:11:24 <kmc> an MMO will have occasional network lag; occasional gc lag might not be significant on that scale
07:11:28 <FunctorSalad> hmm only isomorphic with the extra knowledge that the Foo -> Bar (the typeclass method) is constant for a fixed Foo
07:11:31 <FunctorSalad> aristid: yeah
07:11:42 <kmc> it's not as though nobody writes games that use garbage collection
07:11:45 <edwardk> ManateeLazyCat: what window manager is that?
07:11:46 <aristid> :t uncurry (flip ($)) &&& snd
07:11:47 <lambdabot> forall a b. (a, a -> b) -> (b, a -> b)
07:11:53 <aristid> hmm!
07:11:56 <ManateeLazyCat> edwardk: Not window manager, it's GTK+ notebook
07:11:56 <kmc> Lua is an extremely popular language for game logic scripting
07:12:01 <aristid> :t fst &&& uncurry (flip ($))
07:12:02 <kmc> and afaik is always implemented with GC
07:12:02 <lambdabot> forall c b. (c, c -> b) -> (c, b)
07:12:19 <FunctorSalad> (the motivating example was exists a. Typeable a => a vs (a,TypeRep), aristid )
07:12:19 <kmc> and usually by bytecode interpreter
07:12:21 <ManateeLazyCat> edwardk: It's a gtk2hs program that integrate webkit-browser, file-manger, editor, pdf-viewer... etc.
07:12:25 <kmc> though i guess people JIT it too
07:12:41 <shapr> Has anyone tried yi lately?
07:12:45 <ManateeLazyCat> edwardk: It's gtk2hs OS. :)
07:12:51 <edwardk> kmc: erm, actually anything done with, say, XNA, on xbox uses GC, but sadly the GC on the actual device is crappier than what you get in the dev environment
07:12:58 <alexbobP>  edwardk isn't this potential gc time dependant on how much data haskell actually manages?
07:12:59 <kmc> sad
07:13:03 <aristid> FunctorSalad: hmm i don't know Typeable and i think i don't want to know it yet
07:13:05 <edwardk> alexbobP: yes
07:13:14 <exDM69> ManateeLazyCat: what is that PDF about Yi in the screenshot?
07:13:28 <FunctorSalad> aristid: btw it goes in both directions, but it's just a retract, not an iso... (right to left: id *** const)
07:13:34 <alexbobP> edwardk: so game logic with a working set measuring in kilobytes shouldn't be a problem, eh?  All the large resources (models, textures, etc) will be handled only in the C++ side
07:13:43 <edwardk> alexbobP: (XNA on the PC uses generational GC, the version on the actual xbox isn't generational, and can be MUCH slower)
07:13:44 <aristid> FunctorSalad: well it's a different function
07:13:48 <ManateeLazyCat> exDM69: Yi-Editor.pdf
07:13:51 <Philippa> edwardk: to the extent that if I develop for it I'm seriously considering using completely manual memory management, yeah
07:13:53 <aristid> :t id *** const
07:13:54 <lambdabot> forall b b' b1. (b, b') -> (b, b1 -> b')
07:14:06 <exDM69> ManateeLazyCat: where can I find it, google for yi-editor.pdf did not yield results
07:14:10 <alexbobP> edwardk: well we're coding for real computers, none of that gaming console crap
07:14:13 * shapr cranks up Yi
07:14:17 <exDM69> neither did the name of the author + keywords
07:14:21 <tg_afk> is 'michael snoyman' here?
07:14:35 <alexbobP> kmc: lua is dynamically typed!  eew...
07:14:47 <kmc> *shrug*
07:14:52 <edwardk> alexbobP: anyways i know the gc latency was enough that ryant5000 and company had to move all the rendering out of haskell and into c++, and just use haskell for ai planning
07:14:57 <aristid> lua does have a GC too, doesn't it?
07:15:00 <Philippa> if it's in single kilobytes then the generational GC is very much your friend, yeah
07:15:05 <FunctorSalad> aristid: it has a left-inverse but not right
07:15:12 <alexbobP> edwardk: hahaha, rendering in haskell, that's rich!  :P
07:15:13 <edwardk> but if you're using haskell for any decent amount of AI you're talking a lot more than a few k of data ;)
07:15:21 <jmcarthur> edwardk: i find it strange that it was the *rendering* code that they moved out of haskell though
07:15:32 <kmc> i'm not sure that was the reason
07:15:35 <edwardk> jmcarthur: rendering, frame management, animation, etc.
07:15:39 <wli> I'm kind of a fan of treadmills but anyway.
07:15:42 <jmcarthur> edwardk: also remember this is on the iphone, where i bet gc performs much worse than on desktop computers
07:15:51 <edwardk> jmcarthur: sure
07:15:57 <kmc> alexbobP, i've written realtime OpenGL apps in Haskell.  they were simple but i don't recall any significant gc lag
07:16:11 <alexbobP> kmc: ah, that's cool
07:16:19 <alexbobP> kmc: well we're using Ogre3D so it's not even our decision
07:16:23 <jmcarthur> kmc: well, the GC time goes up with complexity of course
07:16:26 <aristid> jmcarthur: i don't think it's strange that they moved out the rendering code, because it's worse not to render than to lose AI for a short time
07:16:32 <edwardk> well, coming from a game dev background i'm somewhat leery of not having the ability to do manual memory allocation and flush whole swathes of it every frame ;)
07:16:37 <kmc> again, plenty of OpenGL apps in Java and Python and C#
07:16:57 <jmcarthur> aristid: my surprise is that it was the rendering code that was causing the allocations
07:17:08 <edwardk> since you have such a natural saw-tooth pattern to your memory usage
07:17:10 <aristid> jmcarthur: oh, was it? hmm
07:17:13 <ManateeLazyCat> edwardk: http://farm5.static.flickr.com/4135/4771506102_4cccd58e8d_b.jpg See? It's gtk+ program, not variable program in WM.
07:17:23 <ManateeLazyCat> edwardk: Previous screenshot is fullscreen module. :)
07:17:37 <jmcarthur> aristid: it would have to be the case, otherwise there wouldn't be much point in moving it out.... i suppose unless they moved it to another thread in the process
07:17:38 <edwardk> ManateeLazyCat: a shame. it looked like what i want in a window manager =)
07:17:40 <Jafet> You can do manual memory management from haskell.
07:17:52 <Jafet> It's just unrealistic to expect it to be any easier than doing it in C.
07:18:01 <ManateeLazyCat> edwardk: My program don't need WM. :)
07:18:02 <kmc> Jafet, and you can't do *only* manual memory management
07:18:08 <ManateeLazyCat> edwardk: It do everything i want.
07:18:09 <ManateeLazyCat> :)
07:18:14 <soupdragon> ManateeLazyCat: nice!
07:18:18 <jmcarthur> Jafet: well, you can't really do memory management of pure structures
07:18:21 <kmc> i think GC latencies are not so significant in most apps that operate at human timescales
07:18:43 <kmc> if you're doing aircraft control or high-frequency stock trading, that's another story
07:18:50 <aristid> kmc: well 300 ms are definitely a human timescale
07:18:57 <ManateeLazyCat> soupdragon:  In last testing, open release will soon.... 
07:18:58 <FunctorSalad> yeah that'd suck in a game or so
07:19:07 <jmcarthur> my inclination is to believe that if you can't write significant portions of your game in haskell for *gc* issues, then you're doing something wrong
07:19:12 <alexbobP> hey soupdragon!
07:19:15 <jmcarthur> i can see plenty of other reasons, but gc...
07:19:21 <kmc> aristid, but i think it's rare for a GC to last that long in any popular implementation of a GC language
07:19:25 <quicksilver> games-playing humans are pretty adept at noticing uneven framerates
07:19:26 <kmc> unless you're Doing It Wrong
07:19:30 <edwardk> aristid: that was in an iphone setting, so take it with a grain of salt, on a pc you're probably fine if you're cognizant of it
07:19:47 <FunctorSalad> I wasn't saying it's unsolvable, just that if unmitigated it'd be annoying =)
07:19:52 <aristid> edwardk: ok yeah i guess if it's 300 ms on the iphone, it would be much less on the PC
07:20:00 <quicksilver> a 60fps frame only takes 16ms; if you're pushing the CPU pretty hard then you only need the GC to take 5ms to cause stutter
07:20:11 <edwardk> aristid: well, that depends, you can cram a lot more in ram on a PC ;)
07:20:17 <FunctorSalad> are threads enough to keep the app responsive at all times?
07:20:24 <quicksilver> no, GC stops all the threads.
07:20:28 <kmc> FunctorSalad, not in GHC's current RTS; all threads pause to do GC
07:20:29 <FunctorSalad> :(
07:20:32 <kmc> though they do it in parallel
07:20:45 <kmc> FunctorSalad, but you could spawn threads external to GHC; that's one advantage of doing the rendering loop in C++ or whatever
07:20:46 <aristid> kmc: are there plans to improve that?
07:20:46 <quicksilver> and in any case you need, essentialy, to have a single thread making the graphics calls.
07:20:47 <technogeeky> that sounds like the opposite of what I'd ideally want
07:20:50 <quicksilver> and that thread has to GC some time.
07:20:53 <technogeeky> though what I ideally want isn't possible :)
07:20:59 <kmc> aristid, there is desire to improve it.  i think it's decided that it's pretty hard :)
07:21:12 <edwardk> this is one case where we suffer compared to erlang's nice isolated gcs.
07:21:17 <aristid> kmc: maybe it's easier to use multiple OS processes even in haskell
07:21:21 * alexbobP is becoming more and more glad he is using ogre3d and doesn't have to deal with rendering from haskell :P
07:21:33 <aristid> (as a user)
07:21:40 <technogeeky> has anyone used Processing with Haskell?
07:21:43 <aristid> (and only if stop the world is a problem)
07:21:50 <technogeeky> to your knowledge?
07:21:54 <kmc> aristid, what do you mean?
07:22:08 <Jafet> aristid: have fun doing IPC
07:22:09 <edwardk> alexbobP: of course interfacing with ogre3d from haskell due to our low level ffi knowing nothing about c++ is a chore in its own right ;)
07:22:20 * ManateeLazyCat Hmm, i found Yi have same problem with huge file........
07:22:23 <aristid> kmc: let's say you have two different OS processes: one for game logic, one for rendering
07:22:35 <FunctorSalad> can't you quickly juggle control of the graphics between two processes? ;o
07:22:39 <aristid> kmc: then one won't stop the other
07:22:42 <kmc> ah i see
07:22:49 <kmc> sorry, i misread "processes" as "threads"
07:23:02 <FunctorSalad> (or forkOS threads? not sure if what you just said applies only to ghc threads)
07:23:04 <aristid> when i say "OS process", i mean PROCESS :P
07:23:12 <kmc> yes
07:23:13 <kmc> i misread
07:23:17 <aristid> :D
07:23:22 <kmc> though the words "process" and "thread" get used lots of different ways
07:23:25 <alexbobP> edwardk: actually we are interfacing with ogre3D from C++ code, which also interfaces with haskell code
07:23:29 <technogeeky> aristid: though in Linux, they are the same thing :o
07:23:30 <wli> I wonder if C++ has changed enough since 1994 to cause me trouble.
07:23:39 <jmcarthur> no they aren't
07:23:42 <aristid> technogeeky: well, only to some degree
07:23:43 <Botje> C++0x has typeclasses!
07:23:45 <technogeeky> they have the same data structure
07:23:54 <edwardk> wli: much greater adoption of templates in practice
07:23:54 <Botje> and a rude form of type inference as well :)
07:24:04 <aristid> technogeeky: modern linux adheres to the POSIX-mandated differences
07:24:05 <jmcarthur> processes are threads with extra stuff
07:24:16 <kmc> FunctorSalad, as a way of avoiding stop-the-world?
07:24:19 <technogeeky> jmcarthur: I know what they are, I used to be a kernel developer :o
07:24:20 <aristid> technogeeky: ultimately both go down to clone, but they use very different flags
07:24:21 <edwardk> wli: and defined happens before semantics in c++0x
07:24:23 <FunctorSalad> kmc: yes
07:24:47 <kmc> FunctorSalad, you can't.  forkOS doesn't change much about the Haskell-evaluating behavior
07:24:48 <edwardk> FunctorSalad: forkos won't help
07:24:49 <wli> edwardk: Not parsing that last line.
07:24:50 <jmcarthur> technogeeky: i am one ;)
07:24:52 <kmc> it's significant for FFI calls only
07:24:56 <technogeeky> jmcarthur :)
07:25:05 <technogeeky> It was a snarky comment anyhow.
07:25:13 <FunctorSalad> thought forkOS guarantees that you get an OS thread?
07:25:18 <kmc> no
07:25:23 <aristid> STM only works between threads inside the same haskell RTS, right?
07:25:24 <FunctorSalad> or only when deemed necessary due to ffi calls?
07:25:26 <kmc> it guarantees that, when you make FFI calls, they come from the same OS thread
07:25:31 <FunctorSalad> hmm ok
07:25:37 <technogeeky> jmcarthur: speaking of our GC talk, why can't you implement a GC using the same scheme as the O(1) scheduler?
07:25:39 <kmc> it has no required effect on the Haskell-evaluating behavior
07:25:40 <ManateeLazyCat> FunctorSalad: Control graphics in two processes?
07:25:48 <kmc> FunctorSalad, forkOS or not, all the Haskell-evaluating threads share a single heap, and thus they need to coordinate garbage collection
07:25:48 <ManateeLazyCat> FunctorSalad: Like Chrome's framework.
07:25:58 <FunctorSalad> ManateeLazyCat: not my present problem, it was just a random idea
07:26:07 <kmc> FunctorSalad, so even if you had a dedicated OS thread for the Haskell evaluation, it would need to coordinate
07:26:13 <wli> technogeeky: Which iteration thereof?
07:26:19 <FunctorSalad> kmc: I see
07:26:20 <kmc> and if you had a solution for it not to need to coordinate, that would readily apply to the whole RTS
07:26:26 <ManateeLazyCat> FunctorSalad: If you want render Graphics in multiple processes, the answer is yes!
07:26:32 <technogeeky> wli: the basic 2.6 scheduler
07:26:34 <kmc> forkOS is really poorly named...
07:26:38 <edwardk> wli: hans boehm (the boehm collector guy) worked on c++0x, his major contribution was a semantics for which operations can be considered 'serializing events' when different threads communicate, and the introduction of an atomic<> typeclass that exposes atomic integers, with control over read/write barriers
07:26:48 <ManateeLazyCat> FunctorSalad: http://farm5.static.flickr.com/4135/4771506102_4cccd58e8d_b.jpg every window is running in separate process
07:26:51 <quicksilver> kmc: haskell threads don't entirely share a heap.
07:27:05 <edwardk> the semantics in question talks about serializing events that 'happen-before' other serializing events, with other event orders being undefined.
07:27:06 <jmcarthur> technogeeky: i honestly don't see the parallel between the scheduler and GC that you seem to be drawing
07:27:06 <quicksilver> kmc: they have thread-local nurserys - so nursery GCs could be entirely local.
07:27:17 <ManateeLazyCat> FunctorSalad: Then use GtkSocket/GtkPlug render graphics to another process.
07:27:19 <wli> edwardk: That's already enough things changing in C++ since 1994 to cause me trouble.
07:27:23 <edwardk> hence the phrase 'happens-before' semantics
07:27:25 <kmc> hmm interesting quicksilver
07:27:32 <FunctorSalad> ManateeLazyCat: yeah but for a opengl game you'd have to be able to switch control of the... screen? opengl? whatever ;) really quickly
07:27:35 <kmc> what's the nursery and how can it be thread-local?
07:27:37 <FunctorSalad> <50ms
07:27:44 <ManateeLazyCat> FunctorSalad: Yes, i can.
07:27:49 <quicksilver> kmc: the nursery is where new constructions are allocated
07:27:52 <ManateeLazyCat> FunctorSalad: I can embedded OpenGL in my framework.
07:27:59 <quicksilver> kmc: if they end up 'persisting' they get 'promoted' to the main heap
07:28:06 <edwardk> wli: well, boehm's issue was that 'threads can't implemented (safely) be a library', because low level optimizations change their semantics, so they needed support from the language
07:28:08 <wli> technogeeky: You're basically wanting a treadmill.
07:28:15 <quicksilver> kmc: but typical functional programs generate a lot of transient stuff
07:28:16 <ManateeLazyCat> FunctorSalad: Because GtkSocket/GtkPlug use Xembeded protocol, you can send Event cross-process.
07:28:21 <FunctorSalad> ManateeLazyCat: that screenshot is a browser project?
07:28:23 <quicksilver> kmc: that is immediately GCed - never leaves the nursery.
07:28:24 <technogeeky> jmcarthur: it isn't well thought out. What I mean is, in the scheduler there are two process trees and in the GC (with which I am not familiar) there are two levels of stale, right?
07:28:28 <ManateeLazyCat> FunctorSalad: OS project.
07:28:29 <kmc> quicksilver, yeah.  but as soon as a pointer is stored somewhere another thread might get to it, you have to promote?
07:28:46 <tibbe> edwardk: was it you and I who discussed using view patterns and ATs to implement a more efficient Map data type?
07:28:49 <quicksilver> kmc: yes, or at least keep a record of the cross-references. But those are typically rare.
07:28:55 <edwardk> tibbe: yes
07:29:05 <ManateeLazyCat> FunctorSalad: http://farm5.static.flickr.com/4098/4771492256_e1f3a318ef_b.jpg
07:29:06 <Jafet> kmc: not necessarily, but it's less complicated
07:29:08 <kmc> quicksilver, so when would that promotion occur? upon updating a closure in the heap?
07:29:15 <tibbe> edwardk: I managed to get it to work with views as well
07:29:20 <technogeeky> nevermind. This is pointless. You can't operate on either structure without locking first. :/
07:29:23 <tibbe> edwardk: after starting at the Core until it gave in
07:29:29 <ManateeLazyCat> FunctorSalad: Webkit browser, file-manager, editor, pdf-viewer is running in separate processes, but all Graphics is render in Daemon process.
07:29:35 <edwardk> tibbe: =)
07:29:50 <ManateeLazyCat> FunctorSalad: And you can send gtk+ event cross-process.
07:29:57 <quicksilver> kmc: I don't know :)
07:29:59 <edwardk> tibbe: the views worked well for me, though i had to move major operations into the typeclass to get them to properly inline
07:30:09 <technogeeky> wli: at the risk of wasting your time, what did you mean by treadmill?
07:30:10 <jmcarthur> technogeeky: to be more precise, you can have however many generations in our gc that you want
07:30:13 <ManateeLazyCat> FunctorSalad: I have release new package gtk-serialized-event to send gtk+ event over the network.
07:30:24 <tibbe> edwardk: I've kept everything outside and it still works
07:30:27 <ManateeLazyCat> @hackage gtk-serialized-event
07:30:27 <lambdabot> http://hackage.haskell.org/package/gtk-serialized-event
07:30:34 <edwardk> hrmm
07:30:38 <ManateeLazyCat> FunctorSalad: http://hackage.haskell.org/package/gtk-serialized-event
07:30:43 <tibbe> edwardk: I only have 3 methods, two to create the data constructors and one that returns a view
07:30:47 <edwardk> you're balancing outside of your typeclass?
07:30:50 <FunctorSalad> looks nice; can't comment anything about gtk technologies
07:30:52 <tibbe> edwardk: yes
07:31:13 <tibbe> edwardk: although I'm not done with the balancing code yet so I might still run into trouble
07:31:21 <edwardk> tricky, i saw a huge win when i moved that into the typeclass itself, because then things like insert, etc. used it intelligently
07:31:22 <kmc> quicksilver, ok, thanks for the information :)
07:31:30 <tibbe> edwardk: but things like lookup inline fine
07:31:41 <ManateeLazyCat> FunctorSalad: I bulid it base on gtk2hs, but i'm sure this technology is stable though has some hacking way... :)
07:31:51 <edwardk> *nods*
07:32:12 <edwardk> i think in my case it was the larger methods that blew up
07:32:16 <ManateeLazyCat> FunctorSalad: I test my multiple-processes render/control framework day after day, every stable.
07:32:28 <tibbe> edwardk: ok, sounds like I still have some fun to look forward to
07:32:40 <edwardk> just so long as you're cognizant of the fact that you can move anything problematic into the dictionary you should do fine
07:32:58 <tibbe> edwardk: right
07:33:09 <ManateeLazyCat> FunctorSalad: For more information, you can read "Xembeded Protocol" by Goole.
07:33:19 <tibbe> edwardk: I wonder if the problem is that you can't get enough inlining to fire, in principle it should work to keep things outside
07:33:38 <ManateeLazyCat> FunctorSalad: I event can embedded any x11/gtk+/qt by XEmbeded protocol...
07:33:42 <Saizan_> i've a connected DAG and an equivalence relation over its nodes, is there a smart way to pick a representative for each equivalence classes such that you get a connected subgraph?
07:34:12 <edwardk> well, i think what happens is that when i have something that uses the views, etc. moved into the dictionary the choice of dictionary is known, so it doesn't keep redispatching or constructing it
07:34:24 <tibbe> edwardk: it's a shame that the best way for users to add their own instances is to call a CPP macro :/
07:34:34 <edwardk> i use template haskell
07:34:44 <FunctorSalad> Saizan_: is it NP-complete? looks like a candidate...
07:35:01 <tibbe> edwardk: interesting thought
07:35:01 <edwardk> or would like to anyways
07:35:15 <FunctorSalad> it's in NP clearly... (glossing over how one encodes an equiv. relation ;))
07:35:23 <edwardk> there is a much more interesting prospect that i was working on
07:35:26 <tibbe> primMap(IntIntMap,Int,Int,IntIntTip,IntIntBin)  <-- my macro to create a map of int key and values
07:35:31 <edwardk> but its a fair bit more complicated =)
07:35:33 <Saizan_> FunctorSalad: i don't know, might be! i need it for cabal-install ..
07:35:34 <tibbe> edwardk: what's that?
07:35:38 <quicksilver> Saizan_: surely in general that's not possible.
07:35:45 <tibbe> edwardk: I mainly care about API simplicity
07:35:48 <FunctorSalad> Saizan_: just guessing because you have lots of at-face-value-independent choices to make
07:35:57 <quicksilver> Saizan_: depending what you mean by subgraph
07:36:02 <edwardk> well, it comes down to the fact that there are only so many different kinds of values.
07:36:04 <FunctorSalad> (say when every equivalence class has 2 members)
07:36:18 <edwardk> right now you need an instance for every type, every tuple, etc.
07:36:18 <tibbe> edwardk: what do you mean?
07:36:23 <tibbe> edwardk: right
07:36:28 <Saizan_> quicksilver: yeah, sorry, i want to find it or have an explicit failure
07:36:28 <FunctorSalad> but I haven't thought about whether there's a smart method that cuts those choices down
07:36:29 <Tomsik> Reduction to 3-coloring is trival
07:36:33 <FunctorSalad> (@ Saizan_ )
07:36:45 <Tomsik> Get a graph you want to color
07:36:52 <edwardk> so if you have two slots one boxed one unboxed you need to make a container that can hold that
07:36:56 <tibbe> edwardk: my problem is that all the instances are the same i.e. Bin {-# UNPACK #-} !<specific key type> {-# UNPACK #-} !<specific value type>
07:36:58 <Tomsik> and put 3 vertices per each vertex in the graph
07:37:03 <Tomsik> connect these of different colors
07:37:12 <edwardk> but what i challenge is that most of those unboxed types are largely interchangeable
07:37:39 <FunctorSalad> Tomsik: of different colors? thought the graph isn't colored yet
07:37:50 <Saizan_> FunctorSalad: in my use case most of nodes in an equivalence class will be connected to nodes in the same other classes
07:37:50 <tibbe> edwardk: I don't quite follow
07:38:04 <edwardk> there aren't many different unboxed types really. lets say Double#, Int#, boxed references, (and some things for dealing with arrays#/bytearrays#)
07:38:14 <Tomsik> FunctorSalad: of what you intend to be of different colors :p
07:38:22 <edwardk> lets move to #haskell-overflow =)
07:38:25 <tibbe> edwardk: well, you can unpack any single constructor type
07:38:43 <tibbe> edwardk: you mean us?
07:38:44 * ManateeLazyCat Bye all, i'm very happy that fix read huge file problem ....
07:38:46 <edwardk> yeah
07:38:47 <FunctorSalad> Tomsik: but what's the input to the thing solving Saizan_ 's stated problem?
07:38:56 <edwardk> its flooding faster than i can finish my thoughts
07:39:11 <Tomsik> FunctorSalad: each equivalence class is these 3 vertices
07:39:18 <FunctorSalad> ok
07:39:20 <Tomsik> that you replace one vertex with
07:39:29 <FunctorSalad> (what about the original edges?)
07:40:01 <kmc> Saizan_, hmm. we can ignore edges within a class, right?
07:40:10 <Tomsik> If vertices are not connected, you connect all of them, it doesn't matter which you pick then
07:40:21 <Saizan_> kmc: right, there shouldn't be
07:40:29 <FunctorSalad> Saizan_: 'connected' after forgetting directions, btw?
07:40:32 <kmc> so it's a k-partite graph
07:41:03 <kmc> (if that's a thing)
07:42:10 <Saizan_> FunctorSalad: does it matter?
07:42:53 <Tomsik> I guess you could use a SAT-solver :p
07:42:55 <FunctorSalad> Saizan_: I mean in contrast to "directed path between any two nodes". I never remember the strong/weak terminology for that
07:43:39 <om-foxy> what could cause ghci to try to load an unknown package?  It just loaded a newer version a few lines earlier.
07:44:11 <FunctorSalad> om-foxy: import Foo.Bar, and ./Foo/Bar.hs exists? ;)
07:44:27 <FunctorSalad> in that case it will prefer loading to importing from the packagedb
07:45:17 <FunctorSalad> nvm I think I missed the point as so often
07:45:57 <Saizan_> FunctorSalad: oops, i was using a weird idea of "connected", but yeah it corresponds to the usual connected when you forget directions
07:46:30 <FunctorSalad> om-foxy: hmm another attempt: trying to import something that doesn't exist in the newer version?
07:46:33 <om-foxy> FunctorSalad: the package (a) is a dependency of an imported Module from another package (b)
07:46:41 <FunctorSalad> (quickcheck for example...)
07:46:43 <om-foxy> ah.., perhaps
07:47:12 <technogeeky> are any of the lambdabot developers in here?
07:47:23 <technogeeky> I think dons is the maintainer at the moment, right?
07:47:31 <Saizan_> Cale is, sort of
07:47:43 <FunctorSalad> why "sort of"?
07:47:49 <technogeeky> I just want advice on what direction I should take if I want to try to make lambdabot2.0
07:47:56 <Saizan_> that he runs the bot an accepts patches :)
07:48:14 <technogeeky> s/if/when/
07:48:15 <FunctorSalad> but nobody understands the code anymore? ;)
07:48:24 <FunctorSalad> that'd explain why bot has changed little
07:48:47 <Saizan_> not all of the code at least :)
07:48:50 <technogeeky> FunctorSalad: I was going to revamp it for use a physics chatroom :o
07:50:25 <Saizan_> technogeeky: i'd rewrite the core engine from scratch, probably using a more concurrency oriented structure, and then convert the useful Plugins to the new architecture
07:50:45 <technogeeky> Saizan_: I was going to try to use the Intel CC packages
07:51:43 <Saizan_> well, not that an irc bot requires any extreme focus on performance or high concurrency
07:52:00 <quicksilver> it's nice to have a reasonable architecture which lets it be in many many channels at once
07:52:01 <Saizan_> it just needs to not be a maze of little twisted callbacks :)
07:52:05 <quicksilver> (without using particular resources)
07:52:20 <quicksilver> because once a bot becomes good, lots of people want it in their channels.
07:52:21 <jmcarthur> i'd be curious what it'd look like using chp
07:52:28 <technogeeky> quicksilver: I was thinking the same thing, but I wasn't confident enough to say it :o
07:52:30 <Saizan_> quicksilver: true
07:52:53 <quicksilver> and I guess if you're in 50+ busy channels you're processing quite a lot of messages
07:52:53 <technogeeky> Would it be useful for the bot to have a per-user scope?
07:52:56 <Saizan_> but most of the memory/time is probably going to be consumed by plugins.
07:53:03 <quicksilver> even if you're ignoring 90% of them
07:53:04 <FunctorSalad> how are multiple channels an issue?
07:53:11 <jmcarthur> technogeeky: i would love that. also per channel
07:53:20 <jmcarthur> so that you can have local definitions and stuff
07:53:22 <quicksilver> yeah, lambdabot really needs a channel scope
07:53:27 <technogeeky> jmcarthur: can you easily imagine a way to share scope on demand with other users?
07:53:33 <jmcarthur> hmm
07:53:48 <technogeeky> i guess you could publish the scope
07:53:49 <jmcarthur> i guess there could be a command to merge scopes or something?
07:53:51 <technogeeky> and let others grab it
07:53:52 <quicksilver> @run-quicksilver code evaluated in my scope
07:53:52 <lambdabot> Unknown command, try @list
07:53:54 <jmcarthur> hmm
07:54:05 <quicksilver> @run-#haskell-ops code evaluated in that scope
07:54:06 <quicksilver> etc.
07:54:06 <lambdabot> Unknown command, try @list
07:54:28 <FunctorSalad> hmm? it's not like we're running out of names in lambdabot already =)
07:54:35 <jmcarthur> technogeeky: also, it would be really nice if it was persistent (as long as there are some reliable ways to recover from errors too)
07:55:02 <FunctorSalad> @let it=2
07:55:03 <lambdabot>  Defined.
07:55:24 <quicksilver> Saizan_: callbacks are OK. They are the right way to do many things. Just try not to arrange them into twisted maze :)
07:55:50 <om-foxy> @quote missile
07:55:51 <lambdabot> lennart says: Should Haskell also provide unrestricted side effects, setjmp/longjmp, missile launching functions, etc?  After all, people who don't want to use them can just avoid them. :)
07:56:01 <Saizan_> quicksilver: never meant otherwise :)
07:56:09 <technogeeky> well
07:56:13 <kmc> we do provide unrestricted side effects and we do avoid them ;)
07:56:15 <quicksilver> that quote should really be augustss, since that's his IRC nick.
07:56:17 <technogeeky> After having been in this chatroom only a week now
07:56:36 <kmc> Saizan_, your graph problem is driving me crazy now
07:56:48 <technogeeky> I'm pretty confident that the collective helpfulness of this chatroom knows almost no bounds, so I feel comfortable with jumping in the deep end.
07:56:54 <Jafet> quicksilver: not that many quotes are looked up by nick
07:56:55 <kmc> i've failed to reduce from 3SAT and from 3-coloring
07:57:01 <quicksilver> kmc: is that sufficient to prove NP-complete? Is KMC-Mad a strict subet of NP-complete?
07:57:04 <Saizan_> kmc: at least it's not just me!
07:57:07 <kmc> heh
07:57:12 <kmc> i'm not very good at complexity theory
07:57:12 <kmc> so, no
07:57:45 * kmc 's favorite class is BPP^NP: Black Panther Party with NP Oracle
07:58:46 <FunctorSalad> I have the dumb in addition to not being a complexititian, so nothing from me either ;)
07:59:14 <Jafet> Someone should draw moe-anthromorphized complexity classes, in the style of axis powers hetalia
07:59:21 <Jafet> It'd be educational!
07:59:32 <Saizan_> oooh
07:59:50 <Saizan_> that'd be nice in CS courses.
08:00:02 <zenzike> I'm having troubles compiling something, and it seems that the error is a line that says:
08:00:03 <zenzike> package random-1.0.0.2-81c9f631b0081165c591e09a577f60ef is shadowed by package random-1.0.0.2-cf650c34bae72c01e165a0d26c11236b
08:00:07 <J-roen> Hi. It looks like someone is putting spam links on the wiki: http://haskell.org/haskellwiki/?title=WxHaskell&diff=34961&oldid=33207. Is this a known issue?
08:00:12 <zenzike> any idea how that happened, or how to fix it?
08:00:28 <Saizan> zenzike: try passing -package-id random-1.0.0.2-81c9f631b0081165c591e09a577f60ef
08:00:38 <technogeeky> J-roen: spam. On the internet?
08:00:54 <J-roen> technogeeky: There must be a better term, but I couldn't come up with it... :)
08:01:10 <technogeeky> We should call Senator Ted Stevens
08:01:12 <Jafet> spam.com? Don't see any links there
08:01:19 <FunctorSalad> . o O ( On MY internet? )
08:01:38 <aristid> J-roen: i think technogeeky is mocking you for asking "is this a known issue?" yes, spam is a known issue on the internet ;)
08:01:40 <Saizan> J-roen: automatic registration got closed because of spam, maybe that's a leftover
08:01:55 <zenzike> Saizan: thanks, that worked. Do you know why that might have happened?
08:02:21 <J-roen> aristid: Thanks for explaining :).
08:02:33 <J-roen> Saizan: Okay, great. Can I report leftovers somewhere?
08:02:44 <Saizan> zenzike: well, you got two installations of random-1.0.0.2, that might have happened for many reasons though
08:02:46 <technogeeky> J-roen: :)
08:02:56 <FunctorSalad> accounts are still not available?
08:02:57 <Saizan> J-roen: not sure who is maintaining the wiki..
08:03:12 <zenzike> Saizan: hm. how do I remove one of them?
08:03:13 <FunctorSalad> if you have an account, you just revert it without a thought
08:03:35 <c_wraith> I think it's gwern and byorgey who are capable of creating accounts on the wiki these days
08:03:42 <J-roen> FunctorSalad: Yeah, I don't... I might consider registering just for this :).
08:04:23 <Saizan> zenzike: if one is in the global and one is in the user db, you can use ghc-pkg unregister random-1.0.0.2 with either --global or --user, that'd break the packages that depend on that particular installation
08:05:43 <FunctorSalad> unfortunately it sometimes switches back and forth between two different ABIs of the same version of a package
08:05:48 <zenzike> Saizan: thanks. it seems that unregistering either global or user will break the same packages ...
08:05:57 <FunctorSalad> (all in the global cache)
08:06:18 <FunctorSalad> I never had the error where both are available at the same time though
08:06:26 <technogeeky> can I get a quick distro dump in the chatroom? What are you guys using?
08:06:38 <Saizan> zenzike: that sounds weird, it shouldn't be possible afaik
08:06:38 <kmc> debian
08:06:39 <technogeeky> Ubuntu 10.04.
08:06:59 <FunctorSalad> (I had this with the 'network' pkg)
08:07:09 <zenzike> I guess I'll just unregister both and reinstall
08:07:38 <FunctorSalad> maybe it would help to add more constraints when installing the packages that use random
08:07:54 <FunctorSalad> so that both will compile against the same 'random' ABI
08:08:19 <FunctorSalad> first guess would be that one has the base4 flag set and the other doesn't
08:09:10 <FunctorSalad> (don't know if this situation is solvable if you have packages that *only* work with base 3)
08:09:56 <FunctorSalad> zenzike: maybe reinstall all the stuff depending on random simultaneously?
08:10:11 <Saizan> FunctorSalad: why is base4 relevant?
08:10:37 <technogeeky> Saizan: BASE4 recently launched a revolutionary line of Silicone Bakware with stainless steel reinforced rims.
08:11:23 <Saizan> technogeeky: are you spamming me?:)
08:11:39 <technogeeky> Saizan: I guess, technically, yes.
08:11:45 <technogeeky> But I'll transitively blame google.
08:12:18 <FunctorSalad>     Dependencies:  base >=3 && <5, time -any
08:12:22 <FunctorSalad> ^^^^^^ Saizan 
08:12:42 <FunctorSalad> building it against 3 will give a different ABI than against 4 AIUI
08:13:26 <FunctorSalad> leading to a diamond problem with A1 and A2 use 3 resp. 4, and B deps on A1,A2
08:14:02 <FunctorSalad> (all with the disclaimer that I'm just rambling about things I don't really understand)
08:14:25 <FunctorSalad> s/with/if/
08:14:48 <technogeeky> that regex makes less sense
08:14:49 <FunctorSalad> and I mean A1 depends on random-built-against-base3
08:14:50 <FunctorSalad> and so on
08:14:58 <technogeeky> s/if/with/
08:15:19 <FunctorSalad> no (I think :))
08:15:47 <FunctorSalad> "if A1 and A2 depend .... , it will lead to a diamond problem"
08:15:56 <FunctorSalad> not "with A1 and A2 ...." ;)
08:16:08 <technogeeky> oh
08:16:15 <technogeeky> i thought you were correcting inside the ( ... )
08:18:32 <FunctorSalad> maybe "A1 linked against random-linked-against-base3" is more accurate
08:18:32 <zenzike> I think I've got this problem because I am building a version of a package from source, and for some reason it doesn't see that random-1.0.0.2 is already there, so when it resolves dependencies, that package gets reinstalled
08:19:44 <FunctorSalad> zenzike: this "not seeing" is due to the sub-versions of 1.0.0.2 created through different configurations (base3/base4) in my conjecture
08:20:21 <FunctorSalad> it'd reinstall back and forth depending on whether the package you want to install prefers base 3 or 4...
08:20:58 <zenzike> FunctorSalad: so it's because some of my packages require base 3, and others need base 4 huh?
08:22:01 <FunctorSalad> (the funny hashes in the error message you gave are a function of the version and of the hashes of the linked-against dependencies, I'd guess)
08:22:48 <FunctorSalad> zenzike: in the good case, they wouldn't *require* 3, just use it by default ;)
08:23:02 <soupdragon> is anyone good at javascript??
08:23:04 <FunctorSalad> then you could reinstall everything consistently against base-4
08:23:20 <zenzike> FunctorSalad: yeah, giving that a shot
08:23:25 <FunctorSalad> ( --constraint='base>=4.0.0.0' or so)
08:23:29 <soupdragon> my script only works if it's got  alert('foo');  placed strategically
08:23:29 <FunctorSalad> to cabal install
08:23:31 <soupdragon> (lol)
08:23:39 <soupdragon> I want rid of it
08:23:44 <zenzike> ah, thanks, i was about to start modifying .cabal files :-)
08:23:47 <FunctorSalad> zenzike: but like I said, I'm overstepping my knowledge a bit too
08:26:59 <zenzike> FunctorSalad: thanks for the help, I'll keep poking at stuff
08:30:58 <pchiusano> question: is there any reason haskell doesn't put more of the "derived" methods of a typeclass into the typeclass itself, just with default impls?
08:31:10 <Saizan> FunctorSalad: base-4 and base-3 are special cased, so cabal-install won't try to rebuild a package just to only use base-3 in the set, also because it'll end up using base-4 transitively anyway :)
08:31:56 <Zao> My favorite typeclass is the one for peeking/poking which has cyclical definitions.
08:32:18 <Zao> It's great fun discovering that you're supposed to implement one of several subsets of it for it to work.
08:32:24 <kmc> pchiusano, by "derived" you mean methods defined solely in terms of those in the class?
08:32:43 <Saizan> FunctorSalad: that's also the reason why --constraint='base >= 4" is essentially ignored
08:33:01 <pchiusano> kmc: well, and in terms of other functions not specific to the type in question
08:33:14 <pchiusano> kmc: like liftM2, for instance
08:33:21 <kmc> pchiusano, it would introduce more potential for bugs
08:33:30 <pchiusano> kmc: how so?
08:33:31 <Zao> (oh right, Foreign.Storable it was)
08:33:31 <kmc> because it introduces more type class laws that must be satisfied
08:33:39 <aristid> @src liftA2
08:33:40 <lambdabot> liftA2 f a b = f <$> a <*> b
08:33:48 <aristid> @pl liftA2 f a b = f <$> a <*> b
08:33:48 <lambdabot> liftA2 = (. (<*>)) . (.) . (<$>)
08:34:19 <pchiusano> kmc: is that the only reason? because you could provide default implementations that do satisfy the laws because they are implemented in terms of the class primitives
08:34:57 <pchiusano> if you really want to override with something more efficient, then it is on you to make sure that your impl has the same behavior
08:35:12 <pchiusano> but i see no reason to prevent that
08:35:48 <kmc> well preventing people from making certain types of errors is a big thing in Haskell :)
08:35:55 <kmc> but there might be another reason
08:36:07 <zenzike> This is so strange. ghc-pkg tells me that the only random I have installed relies on base 4, and when I fix the package I'm building to rely on base >= 4, and random, it doesn't see random, and wants to build a new one
08:36:10 <kmc> perhaps there are advantages to keeping type class dictionaries small
08:36:18 <pchiusano> kmc: maybe just to make the dictionaries smaller?
08:36:27 <kmc> or perhaps you want code locality between the same instance at different types
08:36:30 <kmc> err same method
08:36:34 <kmc> but they might get specialized anyway
08:37:32 <pchiusano> hmm
08:37:48 <kmc> also, the set of methods in a class is not open
08:37:52 <Twey> soupdragon: Paste
08:37:57 <kmc> so this approach is only available to the person defining the class
08:38:19 <FunctorSalad> Saizan: :( that explains some apparently erratic behaviour 
08:39:43 <pchiusano> kmc: you mean defining the instance?
08:40:20 <Saizan> zenzike: if you pass --dry-run -v to cabal you should see the actual reason why it wants to build a new random
08:40:41 <zenzike> Saizan: thanks
08:40:47 <quicksilver> Saizan++ # explaining cabal weirdness to mere mortals
08:40:48 <Saizan> zenzike: base-4 vs. base-3 should never be one
08:41:36 <kmc> pchiusano, i mean that if i come up with some boffo new monad combinator, i can't make it part of the Monad class
08:41:49 <FunctorSalad> Saizan: I suggested it because it seemed to be the only free parameter in random :)
08:42:08 <pchiusano> kmc: yes, that is true, but you can still have it as a standalone function
08:42:15 <FunctorSalad> no flags, and the other dep is "time -any"
08:42:23 <kmc> pchiusano, right.  but you were asking "why aren't more standalone functions put into the class"
08:42:27 <pchiusano> it just couldn't be overridden by any instances
08:42:31 <FunctorSalad> don't know if there are two versions of time circulating
08:42:48 <Saizan> quicksilver: sometimes i think i should write it up somewhere in a coherent fashion, but i'm not really a writer..
08:44:06 <Saizan> there actually are a few versions of time
08:44:08 <FunctorSalad> maybe a bullet list or diagram then ;))
08:48:13 <BrianHV> what does a ! mean in a type declaration?  (e.g., http://www.scribd.com/doc/19503176/The-Design-and-Implementation-of-xmonad slide 16)
08:48:36 <Jafet> A strict constructor
08:48:51 <Jafet> (By the way, link to real files if you want people to read them)
08:49:19 <kmc> e.g. BrianHV, if a StackSet value is in WHNF, the "current" field inside it will also be in WHNF
08:49:26 <Twey> Ew, scribd
08:49:42 <kmc> was going to say "i don't mind scribd"
08:49:47 <kmc> then it crashed my chromium tab
08:49:49 <Twey> Haha
08:49:51 <BrianHV> heh :)
08:50:21 <BrianHV> thanks all.  have something I can actually google now.
08:50:59 <monochrom> BrianHV: http://www.vex.net/~trebla/haskell/strict-field.xhtml
08:51:39 <BrianHV> even better.  thanks
08:55:37 <zenzike> Saizan: it was because of QuickCheck since that needed an old version of base
08:56:58 <soupdragon> Does anyone know of an explanation of  exp(pi sqrt(136))  suitable for high school level ??
08:57:49 <Saizan> zenzike: really? the line about random only mentioned base in the changes?
08:58:12 <soupdragon> sorry ill ask #math
08:58:53 <Axman6> > exp (pi * sqrt 136)
08:58:54 <lambdabot>   8.151279246142427e15
08:59:03 <Axman6> > exp (pi * sqrt 136) :: CReal
08:59:04 <lambdabot>   8151279246142431.919930164198136708643722829067349427109
08:59:07 <LeoD> > exp (pi * i)
08:59:08 <lambdabot>   exp (pi * i)
08:59:18 <soupdragon> I meant 163
08:59:28 <Axman6> > exp (pi * sqrt 163) :: CReal
08:59:29 <lambdabot>   262537412640768743.9999999999992500725971981856888793538563
08:59:29 <technogeeky> why 163 as opposed to any other number?
08:59:44 <Axman6> what's it supposed to do?
09:00:29 <kmc> > log 262537412640768744 / sqrt 163
09:00:30 <lambdabot>   3.141592653589793
09:00:50 <Axman6> > pi
09:00:51 <lambdabot>   3.141592653589793
09:01:14 <soupdragon> kmc wowww
09:01:14 * Axman6 -> sleep
09:01:23 <technogeeky> sqrt 163 is almost ~ 4pi
09:01:33 <soupdragon> > 4*pi
09:01:34 <lambdabot>   12.566370614359172
09:01:37 <soupdragon> > sqrt(163)
09:01:38 <lambdabot>   12.767145334803704
09:01:43 <kmc> > log 262537412640768744 / sqrt 163 :: CReal
09:01:44 <lambdabot>   3.1415926535897932384626433832797266193476
09:01:50 <kmc> > pi :: CReal
09:01:51 <lambdabot>   3.1415926535897932384626433832795028841972
09:01:57 <Jafet> soupdragon: if your high school curriculum includes class field theory
09:02:00 <soupdragon> 3.141592653589793238462643383279 <--- that many places
09:02:03 <djahandarie> Need moar digits
09:02:03 <soupdragon> is how accurate it is
09:02:04 <soupdragon> amazing
09:02:49 <kmc> > exp pi - pi
09:02:50 <lambdabot>   19.999099979189474
09:02:56 <zenzike> Saizan: I don't know why QC is involved, but it seems that it's the packages which requires the wierd version of random that's causing troubles
09:03:03 <Axman6> > 3141592653589793238462643383279 / 10000000000000000000000000000 :: CReal
09:03:04 <lambdabot>   314.1592653589793238462643383279
09:03:08 <Axman6> > 3141592653589793238462643383279 / 1000000000000000000000000000000 :: CReal
09:03:09 <lambdabot>   3.141592653589793238462643383279
09:03:12 <Axman6> :O
09:03:23 <djahandarie> hahahaha
09:03:26 <djahandarie> Amazing!
09:03:30 <Axman6> :D
09:03:37 * Axman6 -> sleep fo realz
09:04:03 <arw> sleep fo int!
09:04:14 <monochrom> (5 minutes later: "* Axman6 -> sleep fo complexz")
09:04:47 <technogeeky> "I have always wished for my computer to be as easy to use as my telephone; my wish has come true because I can no longer figure out how to use my telephone."--Bjarne Stroustrup
09:04:56 <soupdragon> can you solve exp x - x = 20?
09:04:59 <monochrom> haha
09:05:22 <Saizan> zenzike: well, i've QuickCheck-1.2.0.0 installed against a random built against base-4, so i'd tend to think the problem is something else, it'd be interesting to see the --dry-run -v, but if you already solved the problem nvm
09:05:38 <soupdragon> oh it's solution is the W product-log function
09:06:59 <djahandarie> W has some cool plots on the complex plane
09:08:25 <zygoloid> why is (>>) a separate method in Monad? i'm having a hard time thinking of any case where it could be implemented noticeably more efficiently than the obvious call to (>>=)...
09:08:44 <zygoloid> (conversely, why is join /not/ a separate method?)
09:08:56 <djahandarie> It isn't just a call to >>= ?
09:08:59 <djahandarie> @src (>>)
09:09:00 <lambdabot> m >> k      = m >>= \_ -> k
09:09:08 <technogeeky> anonymous
09:09:09 <Saizan> that's only the default
09:09:16 <zygoloid> djahandarie: that's the default. but instances can override it for efficiency
09:09:38 <djahandarie> But you don't need to
09:09:59 <technogeeky> djahandarie: that might be his point?
09:10:21 <zygoloid> correct. if you do override it, it must be extensionally equivalent to the default.
09:10:43 <djahandarie> (>>) can always be derived from (>>=) and it is useful (to make stuff shorter), so why not include it in Monad?
09:11:34 <zygoloid> djahandarie: the normal action should be to not include extraneous stuff in a typeclass.
09:11:54 <zygoloid> adding (>>) needs more justification than just "why not", in my opinion
09:12:08 <djahandarie> Sure, but I don't know if "not extraneous" means "needs to be defined in every instance"
09:12:33 <zygoloid> it could be defined equally well outside of the class.
09:12:49 <monochrom> perhaps it was thought that everyone used >>= and >>, no one used join.
09:12:59 <djahandarie> Unless you want to redefine it
09:13:07 * sm reaches upgrade-all-to-ghc-6.12 day, hurrah
09:13:07 <djahandarie> So I guess the idea is that you'd never ever want to redefine it?
09:13:21 <quicksilver> zygoloid: you can certainly define (>>) for the list monad more directly. Whether it's actually faster depends on the optimiser.
09:13:40 <quicksilver> zygoloid: whether you would ever actually *use* (>>) in the list monad is another question ;)
09:14:25 <zygoloid> quicksilver: guard is an obvious case where you want to use (>>) in the list monad
09:14:30 <zygoloid> fsvo "obvious"
09:14:33 * quicksilver nods
09:15:11 <quicksilver> I guess that if the definition of >>= gets inlined, there is never any advantage.
09:15:32 <zygoloid> yes. whereas the generated (>>) will presumably have the (>>=) inlined into it, and the lambda will disappear
09:16:05 <zygoloid> (even if >> is being used in code which is polymorphic in the actual monad used)
09:16:38 <sm> hmm, wasn't ghc 6.12 going to eliminate double-building of libs and programs ? I still see it
09:16:47 <quicksilver> zygoloid: actually, on reflection...
09:16:51 <monochrom> what is double-building?
09:17:03 <quicksilver> zygoloid: if your >>= is a bit strict in its implementation
09:17:15 <sm> you know.. cabal install pkg... build all modules for the lib ... build all same modules again for a program
09:17:16 <quicksilver> zygoloid: then it might do un-necessary work, to pass to the (\_ -> ) and be ignored
09:17:33 <quicksilver> zygoloid: so if you want a rather strict >>= in general, but still an efficient (>>), you might indeed want to special case.
09:17:36 <sm> maybe it's a cabal thing
09:18:03 <dcoutts> sm: the sharing has to be done explicitly, it's not automatic
09:18:15 <sm> dcoutts: in each package's .cabal file ?
09:18:21 <dcoutts> sm: by making the exe depend on the lib, rather than using the same modules directly
09:18:28 <zygoloid> quicksilver: do you mean value-strict, or internally-doing-stuff-to-extract-the-value-strict?
09:18:28 <sm> aha. Thanks, I must do that
09:18:29 <monochrom> aha
09:19:21 <quicksilver> zygoloid: I mean something fairly vague
09:19:40 <monochrom> {name: me-and-myself; executable mam { build-depends: me-and-myself ... :)
09:19:44 <quicksilver> zygoloid: I mean "if the strictness properties of >>= are such that it actually partially forces some part of the argument to its RHS before applying it"
09:19:52 <dcoutts> sm: and making sure the source paths don't mean that you just end up using the local modules anyway, since local modules are preferred to ones from packages
09:19:52 * zygoloid could imagine x >>= f = let a = expensiveExtract x in a `seq` f (getValueFrom a); _ >> v = v
09:20:07 <quicksilver> zygoloid: yes, that kind of thing.
09:20:09 <sm> ok
09:20:34 <dcoutts> sm: note there's still a bug for haddocking in this new feature
09:20:37 <sm> dcoutts: do you know offhand of a package that's done it ?
09:20:38 <zygoloid> quicksilver: hmm, interesting. yeah, i could actually imagine that pattern coming up in practice
09:21:11 <dcoutts> sm: I'm not sure which ones are on hackage, I've tested it with darcs, but I think the haddock bit is not working yet (so I've been told)
09:21:12 <thedward> if I've got a monad transformer stack with IO on the bottom, is there a way to get the functionality of bracket?
09:21:14 <zygoloid> quicksilver++
09:21:23 <sm> ok, thank you
09:22:04 <thedward> that is, I know I can runIO bracket, but I want to be able to pass in values of my monad rather than just IO values
09:23:47 <Saizan> dcoutts: btw, do you have some tests to judge how "sane" cabal-install's dependency solver is? to check that i've not messed up the heuristics
09:24:27 <dcoutts> Saizan: not specially, just try the obvious examples
09:24:33 * dcoutts is disappearing for a week
09:24:36 <c_wraith> There's no bugs related to unGetChan, are there?
09:24:51 <c_wraith> err,  there *are*...
09:25:15 <c_wraith> isChanEmpty is the only real bug in Chan, iirc?
09:26:24 <cizra> Is there a difference between  writeIORef and modifyIORef besides interface?
09:26:45 <roconnor> @src modifyIORef
09:26:45 <lambdabot> modifyIORef ref f = writeIORef ref . f =<< readIORef ref
09:27:02 <roconnor> @src atomicallyModifyIORef
09:27:02 <lambdabot> Source not found.
09:27:04 <Saizan> c_wraith: i think unGetChan will also block if there's some readChan blocked on the same chan
09:27:10 <cizra> roconnor: Thanks!
09:27:12 <Saizan> c_wraith: should be easy to test.
09:27:21 <cizra> @src atomicModifyIORef
09:27:21 <lambdabot> Source not found. I am sorry.
09:27:52 <c_wraith> Saizan, indeed, that should be easy to test
09:30:23 <c_wraith> yep.
09:30:31 <c_wraith> unGetChan blocks if there's a readChan blocking
09:30:42 <c_wraith> ok...  alternate idea!  list in an MVar!
09:31:03 <c_wraith> Err, that doesn't work either.
09:31:10 <c_wraith> crap
09:31:25 <c_wraith> I want a concurrent LIFO.
09:31:35 <c_wraith> This might be harder than I thought.
09:31:57 <zygoloid> it's pretty easy if you don't want it to be efficient :)
09:32:46 <technogeeky> that's a nice address
09:32:53 <quicksilver> c_wraith: TChan
09:33:39 <c_wraith> oh. Hmm.
09:33:57 <c_wraith> That's correct, but I've developed a fear of using STM in production code.
09:34:11 <jmcarthur> why?
09:34:33 <c_wraith> I've been bitten by it before.
09:34:38 <zygoloid> c_wraith: do you really want a strict LIFO, or would some approximation of LIFO be enough?
09:34:38 <c_wraith> as far as performance
09:34:40 <kmc> why not list in mvar?
09:35:05 <jmcarthur> TChan has been shown to be faster than Chan sometimes
09:35:08 <c_wraith> kmc: I need someone to be able to wait on getting the next element out until someone else puts an element in
09:35:29 <c_wraith> jmcarthur, I mean specifically STM's behavior under high contention
09:35:44 <kmc> c_wraith, so you can represent that by an empty mvar
09:35:50 <zygoloid> c_wraith: (i don't see how you can require strict LIFO without having inherent race conditions)
09:35:56 <jmcarthur> yeah. i love the STM semantics, but i wish we had a few implementations to choose from
09:36:05 <jmcarthur> optimistic STM is only appropriate sometimes
09:36:10 <kmc> perhaps it's really MVar (NonEmptyList a)
09:36:25 <jmcarthur> i've started different implementations twice, but never finished them
09:36:30 <c_wraith> kmc: that might work
09:36:34 <jmcarthur> like most of my projects
09:38:00 <kmc> c_wraith, hmm, except you don't have a uniform "write" then
09:38:18 <kmc> because it has to know whether to take first
09:38:45 <c_wraith> MVar (MVar (NonEmptyList)) ?
09:38:46 <kmc> maybe (by analogy with Chan) you want nested MVar
09:38:47 <kmc> yeah
09:39:10 <kmc> i think it's a simplification of the Chan code to have only one "end"
09:39:18 <Saizan> or you could use tryPutMVar ?
09:39:35 <aristid> @hoogle NonEmptyList
09:39:35 <lambdabot> No results found
09:39:37 <kmc> but if it fails you need a take/put sequence, and that'd race
09:39:51 * hackagebot HaRe 0.6.0.1 - the Haskell Refactorer.  http://hackage.haskell.org/package/HaRe-0.6.0.1 (ChrisBrown)
09:40:06 <jmcarthur> does it *have* to be a stack? could it just as easily be a plain MVar with a single value?
09:40:29 <davekong> What is the typical layout for a haskell module? should I put all the function signatures by the top or just leave them with there definitions?
09:40:37 <quicksilver> MVar () + MVar [a] works too, I think.
09:40:43 <quicksilver> but seriously I think TChan is simplest.
09:40:45 <jmcarthur> i haven't ever used Chan because MVar is typically fine for me. maybe that would apply in this case too?
09:40:53 <zygoloid> what about a plain mvar with a single value where writes are just forkIO $ putMVar v x
09:41:03 <kmc> hmm nice zygoloid :)
09:41:13 <jmcarthur> that would be fine if order is unimportant
09:41:15 <zygoloid> it won't be strictly LIFO, but i'm pretty sure that can't be a requirement
09:41:16 <kmc> that's (probably?) queue order though
09:41:26 <c_wraith> yeah, that is a queue order.
09:41:27 <kmc> if order doesn't matter at all, Chan is fine
09:41:33 <jmcarthur> it's not queue order either
09:41:40 <kmc> i'm not sure it's guaranteed what order mvar blockers are woken up in
09:41:44 <jmcarthur> forkIO doesn't guarantee running immediately, does it?
09:41:45 <kmc> davekong, i put them by definitions.  haddock will generate a nice summary for you
09:41:54 <eflister> question getting bytestring to play nice with Parsec -- i use "manyTill anyChar" a lot, but this fixes the output as a String that i have to then pack back into a bytestring -- this touches almost all of my bytestring input, and probably kills the advantage of using bytestring in the first place.  do others run into this?  any canonical fix?
09:41:55 <jmcarthur> kmc: the order of blockers have a guaranteed order
09:42:05 <jmcarthur> but i don't think forkIO is predictable here
09:42:13 <davekong> kmc: Okay, cool... I will have to check out haddock
09:42:36 <zygoloid> jmcarthur: if all dequeues block, then you can never tell that a forkIO has been delayed
09:42:37 <c_wraith> well..  The thing I really want to guarantee is "If something has been used, and is available, don't use something that hasn't been used before"
09:43:12 <aristid> hmm, fclabels uses monads-fd and transformers and not mtl.
09:43:13 <zygoloid> c_wraith: hmm, you might want to consider a work-stealing queue.
09:43:32 <zygoloid> that'll be LIFO in-thread and FIFO across threads, which is probably better for cache performance than LIFO in your case
09:43:47 <zygoloid> not sure if there's an implementation on hackage though
09:43:50 <jmcarthur> zygoloid: forkIO (putMVar mvar x) >> forkIO (putMVar mvar y) >> takeMVar  -- does it return x or y?
09:44:03 <zygoloid> jmcarthur: not necessarily ;-)
09:44:14 <quicksilver> zygoloid: good answer :)
09:44:36 <jmcarthur> zygoloid: the putMVars are guaranteed to wake up in the order that they are executed, but the forkIOs are not guaranteed to execute in any particular way
09:44:57 <zygoloid> jmcarthur: sure. it'd only work if you don't care at all about the queue order
09:45:05 <jmcarthur> that's all i was trying to say
09:45:13 <zygoloid> (or if an approximation of FIFO is good enough, maybe)
09:45:19 <eflister> anyone able to help with my Bytestring/Parsec question above?
09:46:04 <quicksilver> eflister: I can't think of a clever answer. If the strings are relatively short (say, under 16K) then the re-packing into bytestring happens in-cache and it probably doesn't matter.
09:46:18 <alc> > 4294967296 :: Int
09:46:19 <lambdabot>   4294967296
09:46:23 <zygoloid> jmcarthur: oh, i thought you were also worried about the problem that you can do a push followed by a tryPop and have the pop fail even though no other thread has popped in between
09:46:23 <c_wraith> heh.  I think MVar (MVar (NonEmptyList a)) is the simplest way to get what I want.
09:46:30 <alc> > maxBound :: Int
09:46:31 <zygoloid> jmcarthur: in wholeheartedly agree :)
09:46:31 <lambdabot>   9223372036854775807
09:46:38 <zygoloid> s/n//
09:46:41 <quicksilver> eflister: if the strings are long - say, 128M - then it's a disaster and you probably shouldn't use parsec
09:46:55 <aristid> quicksilver: when i have a record Widget { show :: IO () } and a record Window { widget :: Widget }, would a typeclass for show be reasonable, or would you always use show . widget?
09:47:21 <eflister> quicksilver: cool, thx - they are very short, just a few hundred characters
09:48:11 <quicksilver> aristid: hard to say without more context. The question is "do you often have functions which work on arbitrary showable things" - so that the typeclass abstraction buys you something.
09:48:32 <quicksilver> aristid: I'd err on the side of starting without the typeclass and adding it later when it was blindingly obvious it improved code.
09:48:54 <Saizan> eflister: with a suitable stream type you could write a slice :: Parser a -> Parser ByteString operator that gives you the input consumed by the parser passed as argument
09:49:45 <quicksilver> Saizan: can you? Nice.
09:49:50 <Saizan> maybe "consumed" would be a better name
09:50:05 * hackagebot blaze-html 0.1.1 - A blazingly fast HTML combinator library.  http://hackage.haskell.org/package/blaze-html-0.1.1 (JasperVanDerJeugt)
09:50:34 <Saizan> quicksilver: yes, edwardk should also have the implementation somewhere
09:50:42 <aristid> quicksilver: i see
09:50:45 <quicksilver> that's the ultimate oracle.
09:50:50 <eflister> Saizan: if i understand you right, i think that's what i did.  the definition is (Bytestring.pack <$>)
09:50:51 <quicksilver> we should replace @faq
09:51:01 <quicksilver> Yes! edwardk has an implementation of that!
09:51:11 <Saizan> eflister: no, nothing like that
09:51:28 <quicksilver> Saizan: well, denotationally very like it :)
09:51:35 <quicksilver> Saizan: but operationally something other.
09:51:45 <Saizan> quicksilver: the type doesn't match :)
09:52:15 <Saizan>  Parser a -> Parser ByteString <- doesn't care about the result of the argument parser
09:52:36 <Saizan> but yeah, "nothing" was excessive
09:52:59 <eflister> Saizan: :) hm, can you explain for me?
09:53:51 <eflister> also: is it obvious why the lazy bytestring api's don't have functions like sort and isInfixOf?
09:53:54 <Saizan> eflister: the idea is that you get the state of the input before and after running the parser and by that you can tell which portion of the input got consumed by the parser
09:54:03 <_minoru> hello, can anybody define a function myDataType :: (Data a) => IO a that prints datatype of a in the terms of Data.Data?
09:54:15 <aristid> eflister: why use an operator section when you can use fmap instead?
09:54:49 <eflister> Saizan: oh ok, would that have any advantages? i don't get when i would want to do this in non-String situations
09:55:00 <eflister> aristid: for some reason sectioning is easier for me to see than currying
09:55:09 <_minoru> Data.Generics.Text does something like that in gread :: (Data a) => String -> [(a, String)]
09:55:16 <Saizan> eflister: that you directly do a take/drop into the original bytestring, without going via String
09:55:27 <_minoru> but i can't understand it
09:56:29 <Saizan> _minoru: isn't there also a gshow?
09:56:48 <eflister> Saizan: oh ok.  but the argument parser still will have made a String, right?
09:56:49 <_minoru> Saizan, yes, it is
09:56:51 <aristid> eflister: train currying by using it :)
09:57:34 <Saizan> eflister: it could also not make anything, it'd just need to scan the right part of the input
09:57:54 <sm> dcoutts_: would you know how to get cabal install to pass -L/usr/lib to ghc, to avoid undefined iconv symbols in the presence of macports ?
09:58:34 <Saizan> sm: --extra-lib-dirs, maybe
09:58:35 <jmcarthur> okay arch users, that has plagued me ever since i started actually using yaourt/bauerbill/etc. to manage my haskell packages. is there a correct thing to do in this case? install packages X and Y, then later upgrade package X to a newer version. in my experiences, if Y depends on X then you cannot upgrade X. would it not make more sense for major version changes to have new system packages altogether?
09:59:07 <jmcarthur> the problem is that it has to uninstall the old X before installing the new one
09:59:15 <jmcarthur> and ghc-pkg says no
09:59:28 <sm> Saizan: by golly I thought I tried that. That does it, thanks!
10:00:21 <chicom___master> hm
10:00:26 <Saizan> _minoru: i don't think i understand what myDataType should do..
10:00:36 <chicom___master> with haskell probly best to use haskells own pacakger
10:00:47 <chicom___master> as it is its own world
10:00:55 <jmcarthur> chicom___master: that is not the usual advice
10:01:12 <jmcarthur> chicom___master: cabal/cabal-install are not package managers anyway
10:01:15 <chicom___master> no distro concentrates on updates to one app as much as they do the distro
10:01:26 <chicom___master> so they will lag
10:01:32 <_minoru> Saizan, myDataType must print it's own datatype name
10:01:39 <zygoloid> > dataTypeName . dataTypeOf $ 42
10:01:40 <jmcarthur> chicom___master: we're talking about arch here. it's a bleeding edge rolling release
10:01:40 <lambdabot>   "Prelude.Integer"
10:01:48 <chicom___master> arch does an unually good job
10:01:59 <zygoloid> _minoru: ^^ is that what you mean?
10:01:59 <kmc> _minoru, what difficulty have you in understanding gshow?
10:02:04 <_minoru> Saizan, for example, myDataType :: Int prints "Prelude.Int"
10:02:11 <eflister> anyone can explain to me why the lazy bytestrings don't have isInfixOf and sort, etc?
10:02:15 <soupdragon> If one considers these three universal constants as the basis for a 3-D coordinate system and one envisions a unit cube, then this pedagogical construction provides a framework referred to as the "cG cube" or "physics cube". This cube can used for organizing major subjects within physics as occupying each of the eight corners.
10:02:18 <soupdragon> WOW
10:02:25 <soupdragon>     * Classical mechanics (_,_,_)
10:02:25 <soupdragon>     * Special relativity (c,_,_), Gravitation (_,G,_), Quantum mechanics (_,_,h)
10:02:25 <soupdragon>     * General relativity (c,G,_), Quantum field theory (c,_,h), Quantum gravity(_,G,h)
10:02:25 <soupdragon>     * Theory of everything (c,G,h)
10:02:33 <chicom___master> a lot of physics is bs
10:02:35 <soupdragon> It's like Dependent types theory
10:02:39 <jmcarthur> the physics cube?
10:02:39 <chicom___master> academics sittting around
10:02:48 <chicom___master> I personally am not even sure quantum is real
10:02:48 <soupdragon> chicom: s being arc length but what's b?
10:02:48 <_minoru> kmc, gshow is really a piece of cake, but i need understand gread, and gread is really difficult
10:02:51 <jmcarthur> oh, that's actually its name
10:02:54 <jmcarthur> heh
10:03:01 <kmc> _minoru, oh.  you asked for an example like gshow
10:03:04 <soupdragon> now we just Pure Physics Systems
10:03:04 <chicom___master> they simply desiciverd that ueranium is unstable and when exploded causes nuclear reaction
10:03:12 <kmc> gread is pretty hairy ;P
10:03:12 <_minoru> kmc no, i asked for an example like gread
10:03:16 <soupdragon> infinite heirarchies of universal constants
10:03:17 <kmc> oh
10:03:19 <chicom___master> unless quantum now is thought to encompass atomic physics
10:03:19 <soupdragon> with relations between them
10:03:25 <kmc> chicom___master, imploded ;P
10:03:29 <chicom___master> so if say the same then you could drag quantum in
10:04:04 <chicom___master> I had annoying physics teachers
10:04:09 <chicom___master> uncool as hell
10:04:12 <_minoru> kmc, exactly, the problem is how to understand how gread passes it's own datatype to readConstr :: DataType -> String -> Maybe Constr by it's first argument
10:04:15 <chicom___master> same as chem
10:04:20 <chicom___master> teachers were just dooshes
10:04:52 <djahandarie> I've only met a few people who were actually annoying in my entire life, and they certainly weren't my teachers
10:05:04 <Saizan> _minoru: i'd write it like "myDataType :: forall a. Data a => IO a; myDataType = print (dataTypeOf (undefined :: a)) >> return undefined" 
10:05:07 <nolrai> Hey is there a function that takes a list of sorted lists, and efficently concats them into a sorted list. (sort . concat) would lose almost all the internal sorting.
10:05:17 <Saizan> _minoru: using ScopedTypeVariables
10:05:53 <nolrai> Saizan: does that work?
10:06:03 <nolrai> cause if so that is cool.
10:06:10 <sm> yay. Here's how to use macports libs, while still preferring /usr/lib for compatibility with GHC: cabal install --extra-lib-dirs=/usr/lib --extra-lib-dirs=/opt/local/lib --extra-include-dirs=/usr/include --extra-include-dirs=/opt/local/include 
10:06:12 <Saizan> it should, yeah
10:06:24 <benmachine> you can usually avoid ScopedTypeVariables using asTypeOf
10:06:31 <kmc> nolrai, you mean an n-way merge?
10:06:42 <nolrai> kmc: yes!
10:06:43 <Saizan> sm: you can set those in ~/.cabal/config too, btw
10:06:55 <kmc> :t S.toList . S.unions . map S.fromList
10:06:56 <lambdabot> forall a. (Ord a) => [[a]] -> [a]
10:06:57 <sm> indeed, I will do that immediately
10:07:01 <kmc> using Data.Set
10:07:07 <soupdragon> http://en.wikipedia.org/wiki/CGh_physics
10:07:09 <soupdragon> AWESOME
10:07:12 <kmc> should be reasonably fast, but ymmv.  profile :)
10:07:19 <djahandarie> kmc, duplicates?
10:07:22 <Saizan> S.fromAscList
10:07:29 <kmc> hmm, harder with duplicates
10:08:21 <nolrai> kmc: unfortunatly I can't garenty unique keys. This is for a simi - hierarchecal zording.
10:08:22 <eflister> why does Network.Browser.request parameterize Request and Response on the same type?  and why does Network.HTTP.getRequest hardcode the Request parameter as String?  together, these make it a pain to get a Response Bytestring.
10:08:24 <Saizan> also, that's quite stricter than necessary
10:08:50 <benmachine> multisets?
10:08:59 <benmachine> or bags or whatever they're called
10:09:09 <nolrai> (strict is fine for my stuff, will be immedietly walked though.)
10:09:24 <sm> in fact I won't, I need to see what regular users see
10:10:30 <nolrai> maps to [a] should work..do I care? bah I don't think its worth the efort at this stage. If its slow I'll worry about it then.
10:11:22 <sshc> Aren't bags just sets of sets?
10:11:41 <djahandarie> nolrai, fyi I found this stackoverflow post about your question http://stackoverflow.com/questions/941699/merge-sorted-inputs-in-haskell
10:11:44 <chicom___master> physicists have trouble explaining the existance fo the human brain
10:11:45 <cypher-> nope, bags are sets with multiplicity of more than 1
10:12:12 <cypher-> sshc: as in you actually keep track of #elements
10:12:13 <zygoloid> @type let merge as@(a:at) bs@(b:bt) | a < b = a:merge at bs | otherwise = b:merge as bt; merge as bs = as ++ bs in foldr merge []
10:12:15 <lambdabot> forall t. (Ord t) => [[t]] -> [t]
10:12:22 <zygoloid> nolrai: ^^ that ought to do it
10:12:29 <cypher-> you can regard them as functions Universe -> |N
10:12:42 * zygoloid ponders whether foldl' would be more efficient
10:12:55 <zygoloid> yeah, it probably would.
10:13:00 <sshc> Multiplicity?
10:13:06 <cypher-> #elements
10:13:09 <soupdragon> chicom___master: no offence but kinda lost intrested in what you have to say when you started insulting 'academics'
10:13:12 <cypher-> technical term is multiplicity IIRC
10:13:21 <cypher-> zygoloid: yeah, you can avoid using ++ if you use an accumulator
10:13:25 <cypher-> zygoloid: massive win
10:13:35 <soupdragon> chicom___master: not really a good way to your preface philosophical musings
10:13:42 <zygoloid> cypher-: one side of ++ or the other is always []
10:13:45 <sshc> Then are they sets of (Integral, something)?
10:13:56 <danharaj> Physicists don't have trouble explaining the existence of the human brain.
10:13:58 <_minoru> Saizan, thanks, forall a really does a trick (getting ambiguous type variable error instead)
10:14:02 <danharaj> Mainly because they don't try to explain its existence.
10:14:05 <bremner> cypher-: I think in a lazy context it matters less. Or is at least harder to figure out.
10:14:22 <zygoloid> cypher-: that was just laziness on my part (not bothering writing the extra cases)
10:14:43 <nolrai> zygoloid: isnt [] ++ long list still very slow?
10:14:46 <nolrai> ah
10:14:49 <cypher-> sshc: zet of pairs would be just an implementation, conceptually they are just like functions
10:14:59 <zygoloid> nolrai: nope. but long list ++ [] isn't great.
10:15:01 <cypher-> sshc: you can use a list of paris too if you like
10:15:31 <nolrai> thanks!
10:15:34 <JuanDaugherty> we'll always have paris
10:15:48 <cypher-> sshc: you know the term characteristic function?
10:16:23 * hackagebot liboleg 2010.1.7.1 - An evolving collection of Oleg Kiselyov's Haskell modules  http://hackage.haskell.org/package/liboleg-2010.1.7.1 (DonaldStewart)
10:16:25 <sshc> cypher-: I don't
10:17:04 <djahandarie> lol @ liboleg
10:17:15 <cypher-> sshc: a characteristic function for a set basically it's just a function from elements to Bool, f_X(x) = True if x is in X
10:17:24 <cypher-> sshc: that's one way of thinking of ordinary sets
10:17:39 <chicom___master> well physicists cna do worse than all the phd in economics who didn't predict 2008
10:17:42 <cypher-> sshc: more concrete mathematical notion
10:18:13 <cypher-> with bags you just make a change of range from Bool to |N
10:18:20 <chicom___master> I am amazed mass produced housing hasn't become a bigger thing, with all the advances in physics
10:18:37 <cypher-> and lists of tuples or sets of tuples or trees of tuples is just an implementation detail
10:19:07 <kmc> chicom___master, do you plan to say anything on-topic?
10:19:12 <sshc> cypher-: I see, thanks
10:20:04 <kmc> ([] ++ long_list) will reduce to long_list quickly.  but (long_list ++ []) will re-allocate the spine of the list
10:20:34 <kmc> it's still as lazy as long_list, and won't walk to the end all at once
10:20:43 <djahandarie> It'd be nice if ++ [] didn't do anything
10:20:45 <kmc> but it will reallocate the spine and that has a space and time cost
10:21:07 <kmc> djahandarie, could be RULES perhaps.
10:21:15 <aristid> > length ([undefined] ++ [])
10:21:16 <lambdabot>   1
10:21:28 <kmc> > length [undefined, undefined]
10:21:29 <lambdabot>   2
10:22:07 <aristid> i don't see why ++[] shouldn't be optimized away in that case
10:22:26 <aristid> it doesn't change bottomness, apparently
10:22:40 <kmc> the definedness of the elements in the list is irrelevant either way
10:23:06 <zygoloid> aristid: how are you going to tell it's []?
10:23:13 <aristid> zygoloid: ?
10:23:16 <zygoloid> > head ([0..] ++ undefined)
10:23:17 <lambdabot>   0
10:23:20 <kmc> i mean you can just write (++) with an extra case
10:23:22 <kmc> @src (++)
10:23:22 <lambdabot> []     ++ ys = ys
10:23:22 <lambdabot> (x:xs) ++ ys = x : (xs ++ ys)
10:23:22 <lambdabot> -- OR
10:23:22 <lambdabot> xs ++ ys = foldr (:) ys xs
10:23:33 <kmc> except that'd force ys "too early"
10:23:36 <zygoloid> kmc: that would break the example that i just gave
10:23:44 <kmc> yeah
10:24:02 <kmc> you could get clever with unamb
10:24:20 <kmc> but probably this is best left to more specific cases
10:24:27 <kmc> rather than putting a complicated heuristic in the standard (++)
10:24:33 <aristid> zygoloid: which example?
10:24:42 <eflister> why do lazy ByteStrings lack functions like isInfixOf, unzip, sort, hPutStr, getLine?
10:24:43 <zygoloid> aristid: [0..] ++ undefined
10:25:12 <aristid> ooh
10:25:21 <aristid> :t unamb
10:25:22 <lambdabot> Not in scope: `unamb'
10:25:36 <djahandarie> @hoogle unamb
10:25:36 <lambdabot> No results found
10:25:40 <djahandarie> @hackage unamb
10:25:40 <lambdabot> http://hackage.haskell.org/package/unamb
10:25:43 <djahandarie> ^^
10:26:04 <aristid> zygoloid: does haskell98 guarantee ++undefined to be safe?
10:26:09 <kmc> fancier: http://hackage.haskell.org/package/lub
10:26:26 <kmc> aristid, it's not just for undefined.  it breaks the lazines of (++) completeley
10:26:41 <kmc> in (xs ++ ys) if you only ask for one element, and xs has at least one element, it shouldn't do any of the work of computing ys
10:26:43 <aristid> kmc: checking for []? it would force the outer cons, yes
10:26:56 <kmc> perhaps it is very expensive for ys to produce the first element
10:27:11 <aristid> ah, i see
10:27:21 <kmc> anyway the Report specifies most prelude functions by a reference implementation, so yes i expect the full laziness is required
10:27:50 <kmc> though iirc the stream fusion paper mentions they found some weirdness with the laziness of standard prelude functions
10:28:43 <jmcarthur> eflister: what would be the type signature for unzip over ByteStrings?
10:30:34 <eflister> jmcarthur: whoops, i guess only Data.Bytestring.Char8.Lazy omits it.  Data.ByteString.Lazy has unzip :: [(Word8, Word8)] -> (ByteString, ByteString)
10:30:44 <jmcarthur> oh, from lists
10:30:52 <jmcarthur> *a list
10:31:16 <edwardk> even better. xs ++ ys | unsafeGetTagBits ys == 0 = xs
10:31:24 <edwardk> er
10:31:35 <edwardk> xs ++ ys | unsafeGetTagBits ys == 1 = xs
10:31:44 <edwardk> then it won't bottom out on you ;)
10:32:00 <edwardk> a poor man's spoon ;)
10:32:11 <kmc> haha how evil
10:32:53 <aristid> :t BL.unzip
10:32:54 <lambdabot> Couldn't find qualified module.
10:33:04 <aristid> hmm wrong guess
10:33:16 * edwardk runs around beating his new golden hammer on everything ;)
10:33:29 <kmc> a golden hammer would be exceptionally useless
10:33:30 <zygoloid> edwardk: keep pimping out your new whore :)
10:33:32 <aristid> edwardk: unsafeGetTagBits is ghc-only, i hope?
10:33:45 <c_wraith> ok, once again I'm looking for someone to talk me out of unsafeInterleaveIO...
10:33:49 <edwardk> aristid: yes, but elsewhere it just returns 0 ;)
10:34:08 <edwardk> aristid: its buried in my speculation library
10:34:20 <kmc> one could imagine a portable extension to observe constructors without forcing "when possible"
10:34:30 <kmc> but it does not exist
10:34:42 <aristid> edwardk: i wonder if it would be worth the overhead for (++)
10:34:42 <edwardk> unsafeGetTagBits a = W# (and# (unsafeCoerce# a) (int2Word# mask#)) where !(I# mask#) = sizeOf (undefined :: Int) - 1
10:35:12 <zygoloid> c_wraith: i had a cunning plan to implement performIO :: IO a -> a in terms of unsafeInterleaveIO and pipes
10:35:14 <edwardk> by the time the compiler gets done with it, it becomes ptr `and` 7 == 1
10:35:33 <zygoloid> (well, technically it was using non-'unsafe' lazy IO, but...)
10:35:39 <c_wraith> My alternative to using unsafeInterleaveIO would appear be to create a thunk structure manually.
10:35:56 <c_wraith> In which case..  maybe unsafeInterleaveIO is ok?
10:36:09 <zygoloid> c_wraith: well, it sounds like you're pretty happy with the 'unsafe'-ness.
10:36:16 <chrisdone> :t maybe unsafeInterleaveIO
10:36:17 <lambdabot> Not in scope: `unsafeInterleaveIO'
10:36:27 <c_wraith> I really just want deferred evaluation of the IO action
10:36:47 <hpc> :t System.IO.Unsafe.unsafeInterleaveIO
10:36:48 <lambdabot> forall a. IO a -> IO a
10:36:50 <zygoloid> c_wraith: why do you want that in the first place?
10:37:25 <c_wraith> zygoloid: it's an action to create a database connection, and said connection might never be needed.
10:37:31 <danharaj> What version of GHC does the latest haskell platform deliver?
10:37:36 <c_wraith> oh, actually, I want to clean them up, too.
10:37:45 <c_wraith> That means I need an explicit structure.
10:37:51 <c_wraith> ok, talked myself out of it again
10:37:55 <zygoloid> hooray!
10:37:58 <edwardk> c_wraith: what are yo trying to do? i just tuned in
10:38:25 <c_wraith> edwardk, lazy database connection pool.  I don't want to create connections unless they're needed
10:38:38 <monoidal> danharaj: 6.12.1 afaik
10:38:52 <monoidal> danharaj: http://hackage.haskell.org/platform/contents.html
10:39:07 <edwardk> are your actual uses of the connection pool imperative? what keeps you from just having a connection be a reference to the primitive connection
10:39:19 <edwardk> and then having the usage of it, fill the reference if needed
10:39:56 <danharaj> monoidal: Thanks. Balls. It is still using 6.12.1
10:40:11 <edwardk> data Connection = Connection ConnectionString (IORef ActualConnection)
10:40:45 <danharaj> What am I supposed to do if something that has been riding my back has been fixed in the interim?
10:40:59 <edwardk> danharaj: wait 6 months and revisit it? ;)
10:41:42 <c_wraith> edwardk, I don't think my current plan is too far from that in spirit...  Just using a slightly different mechanism
10:41:43 <danharaj> edwardk: :| I think I feel a masochistic adventure of setting up my own haskell dev environment on windows ensuing.
10:42:40 <edwardk> danharaj: you have a very odd sense of adventure ;)
10:43:02 <danharaj> edwardk: When you work with open source tools on windows, every adventure is about as enticing as gargling battery acid.
10:43:20 <edwardk> yum.
10:43:56 <theorbtwo> danharaj: I use vmware player (free for personal use), and putty to ssh inside it.
10:44:00 <theorbtwo> It works quite well.
10:44:07 <danharaj> what the hell does that mean.
10:44:27 <theorbtwo> I have a windows desktop with a linux virtual machine running inside of it.
10:44:32 <danharaj> Putty to SSH Inside sounds like a skateboard trick.
10:45:07 <danharaj> theorbtwo: Oh. That wouldn't work for me, I want to develop for windows and GHC has shady cross compilation.
10:46:47 <theorbtwo> danharaj: Aha.
10:47:48 <zygoloid> danharaj: Awesome 720 SSH to Colo-box Inside VPN!
10:48:25 <augur> is the simply typed lambda calculus turing complete?
10:48:34 <zygoloid> augur: nope. it's strongly-normalizing.
10:48:42 <augur> ok. thats what i thought.
10:48:55 <danharaj> no strongly-normalizing typed lambda calculus with decidable type checking in turing complete.
10:49:02 <danharaj> is*
10:49:15 <augur> what level of type complexity yields a turing complete typed LC?
10:49:23 <augur> minimum, i mean.
10:49:36 <augur> quanticiational types?
10:49:43 <augur> .. quantificational*
10:49:43 <danharaj> intersection types does it
10:49:50 <augur> oh? ok.
10:49:50 <danharaj> what dose quantificational mean?
10:49:56 <danharaj> wow my spelling is bad today.
10:50:12 <augur> well, polymorphic types like forall a. a -> a
10:50:13 <zygoloid> existential types is certainly enough, if that's what you meant by quantificational
10:50:25 <augur> tho i'd accept any quantification not just universal :p
10:50:57 <zygoloid> well, universal and existential types are dual so it's hard to have one without being able to simulate the other
10:51:21 <augur> ya, but i dont know if you can simulate it in types, as such
10:51:33 <augur> i mean whats ~(forall a. a -> a)?
10:52:03 <danharaj> is ~ not?
10:52:07 <augur> yeah
10:52:17 <zygoloid> exists a. F a  can be simulated with  forall a r. (F a -> r) -> r.
10:52:32 <augur> really? interesting.
10:52:32 <mauke> @djinn Not (Not a) -> a
10:52:33 <lambdabot> -- f cannot be realized.
10:52:54 <danharaj> ~(forall a. a -> a) is not inhabited.
10:52:58 <zygoloid> sorry, forall r. (forall a. F a -> r) -> r
10:53:13 <augur> hm.
10:53:34 <augur> anyone read Jay's Pattern Calculus?
10:53:40 <danharaj> anyone remember that new package manager that got released for Windows?
10:53:47 <danharaj> the name escapes me and google fails.
10:54:03 <zygoloid> danharaj: the microsoft-supported open source thing?
10:54:12 <danharaj> zygoloid: I don't know.
10:54:38 <BMeph> WinPackMan?
10:54:41 <zygoloid> danharaj: that ws called CoApp
10:55:00 <danharaj> no, those are old, this one came out very recently.
10:55:02 <aristid> heh, fclabels convinces me that Category is a usefull typeclass
10:55:02 <danharaj> Oh shit I remember now.
10:55:09 <danharaj> Excuse my snooty french.
10:55:29 <zygoloid> CoApp isn't old, it was announced a couple of months ago
10:55:48 <zygoloid> it's so new it's still utterly useless :)
10:56:45 <danharaj> TakeOffGW
10:57:14 <danharaj> zygoloid: I feel like 90% of open source projects that get released fizzle and die before they become usable.
10:57:45 <zygoloid> danharaj: that's certainly been the case on projects i've started :)
10:59:11 <mauke> announcement: ad-hoc polymorphism is hereby renamed to portuguese polymorphism. thank you.
11:00:17 <aristid> danharaj: evolution at work :P
11:00:41 <danharaj> aristid: the best part is when they don't leave any indication that the project is orphaned.
11:01:18 <aristid> danharaj: well maybe they like to think that they haven't ACTUALLY orphaned the project
11:01:57 <danharaj> aristid: And maybe Richard Stallman is right.
11:01:59 * danharaj cough
11:02:05 * danharaj cough no
11:03:11 <aristid> danharaj: richard stallman is never right
11:04:30 <chicom___master> lol
11:04:35 <chicom___master> hurd!
11:04:47 <chicom___master> will the haskell os ever be viable?
11:04:53 <danharaj> what haskell os?
11:04:54 <chicom___master> one can dream
11:05:04 <chicom___master> the low level one
11:05:07 <chicom___master> on metal
11:05:15 <danharaj> I have no idea what you're talking about.
11:05:28 <chicom___master> I can look it up one sec
11:05:46 <arcatan> badabum http://programatica.cs.pdx.edu/House/
11:06:00 <danharaj> Well anyway, time to embark on my adventure into the wonderful world of setting up a dev environment on Windows.
11:06:01 <ManateeLazyCat> I found two XMPP libraries : network-protocol-xmpp and XMPP-0.1.2, who use both? Make a comparison?
11:06:11 <danharaj> What do I need other than ghc, darcs, and cabal as a base?
11:06:29 <chicom___master> http://programatica.cs.pdx.edu/House/
11:06:38 <chicom___master> ya
11:07:36 <edwardk> groom++
11:07:39 <monochrom> in .cabal/config what does "preference:" do?
11:08:53 <ManateeLazyCat> @hackage groom
11:08:53 <lambdabot> http://hackage.haskell.org/package/groom
11:08:57 <nolrai> @type concatMap
11:08:58 <lambdabot> forall a b. (a -> [b]) -> [a] -> [b]
11:09:35 <nolrai> groom looks nice
11:13:22 * ManateeLazyCat Reading RFC3920...
11:15:41 <jmcarthur> oh groom does indeed look nice
11:16:04 <ManateeLazyCat> jmcarthur: Looks i need try groom...... :)
11:18:50 <Tomsik> Grooms? And where are the brides?
11:19:19 <monochrom> the brides forgot their oil
11:19:22 <ManateeLazyCat> @hackage groom
11:19:23 <lambdabot> http://hackage.haskell.org/package/groom
11:19:25 <chrisdone> > let life = 'mariage' : 'divorce' : life in life
11:19:26 <lambdabot>   <no location info>:
11:19:26 <lambdabot>      lexical error in string/character literal at chara...
11:19:39 <chrisdone> > let life = "mariage" : "divorce" : life in life
11:19:40 <lambdabot>   ["mariage","divorce","mariage","divorce","mariage","divorce","mariage","div...
11:20:04 <nolrai> @type groom
11:20:05 <lambdabot> Not in scope: `groom'
11:20:08 <nolrai> dang
11:20:13 <chrisdone> > let life = "mariage" : "divorce" : life; henry8th = take 6 in henry8th life
11:20:14 <lambdabot>   ["mariage","divorce","mariage","divorce","mariage","divorce"]
11:20:26 <nolrai> lol
11:20:35 <chicom___master> privatize marriage
11:20:40 <chicom___master> nomarriage.com
11:20:55 <BMeph> @where ops
11:20:55 <lambdabot> shapr Cale glguy dons sjanssen sorear dcoutts Saizan allbery_b dibblego conal Philippa bos arjanb psnl xerox vincenz davidhouse Heffalump kosmikus wli Pseudonym Igloo musasabi quicksilver monochrom
11:21:28 <monochrom> yes?
11:21:36 --- mode: ChanServ set +o allbery_b
11:22:26 --- kick: chicom___master was kicked by allbery_b (chicom___master)
11:22:43 --- mode: allbery_b set -o allbery_b
11:23:05 <mauke> what
11:23:18 <chrisdone> er
11:23:31 <chrisdone> why did you just kick chicom___master?
11:23:56 <chrisdone> allbery_b is like the cracken
11:24:13 <chrisdone> applies destruction indiscriminately
11:24:27 <allbery_b> unrelated advertising in channel
11:24:52 <allbery_b> activated by keyword, apparently
11:25:55 <mauke> I thought it was a joke
11:26:11 <mauke> also, what keyword?
11:26:18 <chrisdone> either that or we'll see a blog post saying "i was chatting in haskell and i got kicked. it's as bad as #lisp!!"
11:26:23 <eflister> i have: (j :: [c] -> c) <$> (mapM ((h :: c -> c) . (g :: b -> c) . (f :: a -> b)) =<< m [a]).  i think f, g, h, and j could all run in parallel.  how do i set that up?
11:28:38 <allbery_b> "marriage"
11:28:51 <allbery_b> also I find it interesting that chrisdone who's whining about the kick was also the trigger
11:29:04 <mauke> no one said "marriage"
11:29:19 <allbery_b> it was misspelled, so?
11:29:21 <mauke> 4 preceding lines contained "mariage" without triggering anything
11:29:24 <allbery_b> fine, invite the bot back
11:29:42 <allbery_b> or should I just quote it again and do its work for it?
11:29:45 <Tomsik> Marriage marriage marriage marriage married marriage
11:29:56 <allbery_b> <chicom___master> privatize marriage
11:29:56 <allbery_b> <chicom___master> nomarriage.com
11:30:03 <chrisdone> http://marrychrisdone.com/applynow
11:30:07 <allbery_b> fine I quoted the bot you love so much,m happy now?
11:30:10 <chrisdone> oh sh- i'm the bo-
11:30:15 <mauke> what the dick
11:30:50 <allbery_b> look, someone did the @op thing, I looked in here and saw spam, now I'm the enemy.  fine
11:31:09 <chrisdone> lol what
11:31:40 <chrisdone> similar to the cracken in many ways
11:31:52 <mauke> did you mean: zak mccracken
11:32:27 * BMeph was the someone
11:32:37 <mauke> BMeph: you're on notice!
11:32:44 <chrisdone> BMeph: do you feel like Jack Sparrow now?
11:32:54 <BMeph> mauke: Thank you for noticing me! ;þ
11:33:05 <chrisdone> oh wait, he released calypso
11:35:25 <Tomsik> cracken sux
11:46:58 <technogeeky> evening conal.
11:47:04 <technogeeky> well, good afternoon for you.
11:47:41 <conal> technogeeky: hi
11:49:21 <Heffalump> morning for conal, surely
11:49:35 <technogeeky> Just barely.
11:49:41 <technogeeky> Unless he's a late riser ;)
11:49:59 <technogeeky> Which, given the scenery where he lives... I could understand.
11:50:23 <eikke> did anyone ever use hslogger-template with a 64bit GHC (6.12.2 or 6.12.3) on OSX? seems to crash the compiler
11:51:42 <aristid> :t pos
11:51:43 <lambdabot> Not in scope: `pos'
11:53:20 <conal> i'm usually up at 6am in the summer.  sun comes in the window.  and outside work before it gets too hot.
11:53:47 <conal> pleasant start to the day
11:53:52 <technogeeky> How hot is too hot?
11:53:58 <technogeeky> :)
11:55:19 <conal> for physical work -- 95F is too hot for me.  shade helps a lot.  we often get 100-105F on summer days.  sometimes higher.
11:55:24 * technogeeky sighs.
11:55:37 <aristid> .oO(must use time machine to kill mr fahrenheit)
11:55:40 <technogeeky> ACTA, as expected, turns out to be just as horrible as we guessed it would be.
11:55:46 <conal> :)
11:56:03 <aristid> conal: yes 35 °C is rather hot
11:56:11 <p_l> conal: please use sensible units, Fahrenheit is unworkable :P
11:56:18 <technogeeky> lololol
11:56:20 <technogeeky> I love it!
11:56:38 * technogeeky shames himself.
11:56:44 <aristid> well i guess we should use Kelvin
11:57:00 <technogeeky> conal: Yeah, that's my upper limit. We have similar heat, plus humidity (though this year has been fine).
11:57:08 <aristid> so 95 fahrenheit is 308.15 kelvin
11:57:11 <p_l> aristid: Celsius has acceptable range for everyday use and maps easily to Kelvin...
11:57:18 <technogeeky> aristid: well, since celcius has a bijective mapping to kelvin
11:57:27 <aristid> technogeeky: so does fahrenheit
11:57:40 * technogeeky asks for a more precise word than bijective
11:57:51 <technogeeky> unitary?
11:57:53 <aristid> additive?
11:57:53 <technogeeky> there.
11:57:58 <technogeeky> unitary.
11:58:02 <danharaj> unitary?
11:58:24 <technogeeky> It's just a shift in a number line.
11:58:28 <technogeeky> correct?
11:58:39 <danharaj> I suppose.
11:58:44 <technogeeky> farenhiet is not
11:58:52 <technogeeky> and it's harder to spell, evidently.
11:58:53 <conal> maybe someone could hack lambdabot for a variety of units conversions
11:58:59 <technogeeky> conal: alrady on it
11:59:12 <technogeeky> i'm taking on the task of writing l2.0
11:59:37 <p_l> fahrenheit has some creepy fractions in conversion, iirc
11:59:42 * Heffalump is schizophrenic about temperatures, I can only understand human temperatures in fahrenheit, but weather temperatures in celsius
11:59:43 <technogeeky> p_l: that was my point
11:59:48 <technogeeky> i just don't know how to say it
12:00:02 <technogeeky> bijective means one-to-one and onto, right?
12:00:06 <Heffalump> technogeeky: yes
12:00:18 <alexyk> dafis: what's the Data.BAIntMap in the latest files, is it the local IntMap.hs?
12:00:35 <epicbeardman_> p_l: x-32*5/9
12:00:43 <technogeeky> (x-32) * 5/9
12:00:47 <technogeeky> parents
12:00:49 <technogeeky> parens
12:00:55 <BMeph> @google 95F in celsius
12:00:55 <lambdabot> http://lancaster.unl.edu/food/ciq-celsius.shtml
12:00:56 <lambdabot> Title: Temperature Conversion: Fahrenheit and Celsius
12:01:02 <aristid> x 32 - 5 * 9 /
12:01:02 <technogeeky> man. I just got back from the gym, and I'm still shaky. I need to stop typing for a few minutes.
12:01:14 <BMeph> Now THAT's lazy lookup! :D
12:01:17 <technogeeky> yeah
12:01:28 <aristid> @google 95 f in c
12:01:29 <lambdabot> http://lancaster.unl.edu/food/ciq-celsius.shtml
12:01:29 <technogeeky> @google 90 F in C
12:01:29 <lambdabot> Title: Temperature Conversion: Fahrenheit and Celsius
12:01:31 <lambdabot> http://www.ncdc.noaa.gov/oa/climate/conversion/tempconvert.html
12:01:31 <lambdabot> Title: NCDC: Celsius to Fahrenheit Conversion ChartT OF SNOW
12:01:33 <technogeeky> seriously?
12:01:40 <p_l> well, a temperature difference of 1 degree in kelvin scale and 1 degree celsius is almost identical (identical enough, I'd say), so you only need to add or subtract 273 to convert...
12:01:40 <technogeeky> werod
12:01:41 <aristid> lambdabot: why do you ignore google's own answer?
12:01:42 <technogeeky> weird
12:01:46 <technogeeky> yeah, it must be an api thing
12:01:58 <technogeeky> that's strange
12:02:14 <technogeeky> that means it totally excludes using google as a calculator and as a reference (for data, like astronomy and physics)
12:02:27 * technogeeky sractches that onto the todo list
12:02:28 <technogeeky> @todo
12:02:29 <lambdabot> 0. SamB: A way to get multiple results from a google search
12:02:29 <lambdabot> 1. dons: improve formatting of @dict
12:02:29 <lambdabot> 2. dons: write Haskell Manifesto
12:02:29 <lambdabot> 3. lispy: don't let lambdabot's prettyprinter split the sequence @foo across lines
12:02:29 <lambdabot> 4. TheHunter: priviledged users should get priviledged listcommands.
12:02:31 <lambdabot> [29 @more lines]
12:02:45 <aristid> @todoy technogeeky
12:02:45 <lambdabot> Plugin `todo' failed with: @todo has no args, try @todo-add or @list todo
12:02:52 <technogeeky> @todo technogeeky 
12:02:52 <lambdabot> Plugin `todo' failed with: @todo has no args, try @todo-add or @list todo
12:03:09 <aristid> technogeeky: it actually recognised @todoy as @todo :D
12:03:13 <technogeeky> @todo-add technogeeky fix @google so it returns calc, data results.
12:03:13 <lambdabot> Entry added to the todo list
12:03:30 <chrisdone> guys see this? pretty useful for pondering what module hierarchies are appropriate for your package http://chrisdone.com/posts/2010-07-04-haskell-module-landscape.html
12:03:35 <technogeeky> aristid: good. That means I already have the code to get the shortest match :o
12:03:55 * alexyk feels progress being made before our eyes
12:04:01 <aristid> technogeeky: uh, what?
12:04:16 <technogeeky> @tod test
12:04:16 <lambdabot> Maybe you meant: todo todo-add todo-delete
12:04:30 <technogeeky> it already does better string matching than exact
12:04:36 <technogeeky> so I don't have to worry about that :0
12:04:46 <technogeeky> @todooooooolololo
12:04:47 <lambdabot> Unknown command, try @list
12:04:53 <technogeeky> @todooo 
12:04:54 <lambdabot> 0. SamB: A way to get multiple results from a google search
12:04:54 <lambdabot> 1. dons: improve formatting of @dict
12:04:54 <lambdabot> 2. dons: write Haskell Manifesto
12:04:54 <lambdabot> 3. lispy: don't let lambdabot's prettyprinter split the sequence @foo across lines
12:04:54 <lambdabot> 4. TheHunter: priviledged users should get priviledged listcommands.
12:04:56 <lambdabot> [30 @more lines]
12:05:04 <technogeeky> sorry for the spamming guys.
12:05:18 <aristid> chrisdone: somehow haskell's disparate package / module naming makes me feel uncomfortable
12:05:32 <twanvl> @@ @run filter ("technogeeky" `isInfixOf`) . lines $ @show @todo
12:05:33 <lambdabot>   ["34. technogeeky: technogeeky fix @google so it returns calc, data results...
12:05:55 <technogeeky> ok
12:05:58 <technogeeky> so my name was spurrious
12:05:58 <BMeph> chrisdone: Nice wallpaper.
12:06:05 <chrisdone> BMeph: :D
12:06:15 <technogeeky> anyway, i'll just play with him in PM
12:06:19 <technogeeky> and read the source code
12:06:24 <technogeeky> I really wish I could take the name 'tg'.
12:06:29 <aristid> twanvl: you win
12:07:17 <conal> is there a way to list hackage packages for a specified maintainer, without getting multiple versions of the same package?  i'd like just the latest versions.
12:07:42 <technogeeky> i'll find out, I suppose
12:11:09 <lowasse1> Does anybody know any obstacles to parallelizing *haddock* ?
12:12:59 <technogeeky> lowasse1: No clue. Can you specify the advantages?
12:13:14 <danharaj> hmm I think I actually managed to get ghc, cabal, and msys installed without any pain.
12:13:26 <lowasse1> Mostly, "haddock isn't so slow on my bigger packages"
12:14:11 <nus> danharaj, anaesthasia?-)
12:14:22 <danharaj> nus: God I wish.
12:14:46 <technogeeky> danharaj: is there a little pain in not being certain if it will work properly in the future?
12:15:46 <danharaj> technogeeky: That pain has become so uniform and ubiquitous that I am not even conscious of a reality without it anymore.
12:15:59 <technogeeky> are you trying to run in windows? :o
12:16:05 <danharaj> Yes.
12:16:08 <davekong> what is the easiest way to write a function/set up a ordered binary tree so deleting a node does not mess everything up
12:16:09 * technogeeky giggles
12:16:16 <technogeeky> I actually contemplated suicide when trying that last year.
12:16:37 <technogeeky> I stopped both activities and installed Linux in a vm.
12:16:57 <danharaj> That would almost be an option.
12:17:15 <danharaj> If I could be bothered to learn a completely different operating system, and if GHC could cross compile well.
12:17:20 <danharaj> Neither of these conditions hold.
12:17:39 <technogeeky> Well, I need it to work in Windows too.
12:17:47 <technogeeky> I'm just waiting for you to do the work first :)
12:17:57 <danharaj> what to work?
12:18:00 <technogeeky> So, I suppose, thanks.
12:18:15 <technogeeky> Improving it and testing that things install in Windows :
12:19:19 <danharaj> if this doesn't work I'm going to throw a fit on a mailing list.
12:19:24 <danharaj> Don't rely on me to do real work ;p
12:19:32 <technogeeky> that's work.
12:19:49 <technogeeky> Kicking tires and lighting fires is still work :)
12:20:23 <danharaj> I hate being treated as a second class citizen because my operating system wasn't built by and for 'hackers'.
12:20:46 <technogeeky> I don't think that distinction is really necessary, but I understand it.
12:21:09 <Tomsik> you have to be a function or a data of some type to be a first-class citizen so
12:21:13 <technogeeky> I am using Windows because it's the only OS that seems to accelerate 3+ video cards
12:22:02 <danharaj> gah, there is no information on how to build the SDL library.
12:26:02 <chrisdone> man i really hate typing uppercase lettering when writing code
12:26:14 <lowasse1> davekong: what's the application?
12:26:31 <chrisdone> i wonder if i can write a little app to change parsefile into parseFile for me after i've written all the code
12:26:50 <Botje> chrisdone: .. or make haskell case insensitive
12:27:27 <danharaj> Haskell encodes some semantics in case, at least for the first letter.
12:27:49 <lowasse1> Also, you'd break Template Haskell and all the other meta-Haskell facilities, no?
12:28:06 <lowasse1> Live with the language, it's not worth the trouble =P
12:28:11 <chrisdone> Botje: i just don't like typing camelOrWhateverItIsCalledCase
12:28:21 <p_l> sounds like issues with "modern" mode for CL
12:28:23 <chrisdone> don't like typing_liek_this_either
12:28:23 <Botje> chrisdone: don't you have code completion? :)
12:28:35 <p_l> chrisdone: glasses-mode?
12:28:40 <chrisdone> Botje: not for variable names i haven't invented yet :p
12:28:56 <danharaj> you have to enable -XReadMyMind
12:29:02 <chrisdone> p_l: i saw that a while ago but it seemed to not do anything useful. let me check
12:29:03 <davekong> lowasse1: just playing with trees, trying to learn haskell, I have a tree with Int key values
12:29:04 <technogeeky> just do regex substitution with your editor :o
12:29:32 <chrisdone> hmm, no
12:29:37 <chrisdone> my problem is typing it out
12:29:40 <technogeeky> or encode it in callbacks
12:29:41 <lispy> that todo item of mine is ancient
12:29:45 <chrisdone> not reading it or code-completing it
12:29:49 <lowasse1> I hear red-black trees are actually pretty straightforward in a functional language with pattern matching and all
12:30:05 <lowasse1> heck, any standard balancing scheme would work
12:30:10 <technogeeky> or encode it in callbacks in your dvcs
12:31:33 <lispy> lowasse1: yeah, there is at least one easily accessible paper about purely functional red-black trees
12:31:50 <lispy> lowasse1: and some less-accessible papers about using the type system to enforce the invariants
12:33:58 <lowasse1> hah
12:34:41 <lowasse1> start with the first kind of paper, and then figure out how to use the type system to enforce the invariants by yourself as an exercise
12:34:52 <lowasse1> it's a good exercise =D
12:35:04 <lispy> Especially if you're a grad student
12:35:15 <lowasse1> hah, also if you're an undergraduate!
12:35:15 <technogeeky> or unemployed
12:36:00 <tibbe> dons: yt?
12:36:23 <alexyk> unemployed : undergraduate == employed : der graduate?
12:36:59 <chrisdone> tibbe: did you try my align-imports.el?
12:37:09 <technogeeky> der?
12:37:11 <aristid> alexbobP: unemployed : graduate == employed : undergraduate?
12:37:15 <aristid> GAH
12:37:16 <tibbe> chrisdone: I never got around to do it :/
12:37:20 <danharaj> what line do you put in a .cabal file to add extra include and extra library directories?
12:37:21 <aristid> alexyk: i meant you
12:37:21 <chrisdone> ok ;)
12:37:25 <alexbobP> aristid>:) I am all four of those
12:37:36 <technogeeky> high five!
12:37:38 <tibbe> chrisdone: did you eventually add support for e.g. alphabetically sort the import lists? that's something I wanted
12:37:40 <technogeeky> i think.
12:37:57 <tibbe> chrisdone: that sorts by module name rather than what Emac's sort-lines does.
12:38:09 <leino> quick question: are there some special indentation rules concerning the 'do' notation?
12:38:13 <alexyk> technogeeky: as in, Kaiser WIlhelm der Große or something
12:38:19 <chrisdone> tibbe: no. it's really easy to add, but i'm not really sure what to do if there are comments inbetween imports
12:38:34 <chrisdone> tibbe: or should we ignore that case?
12:38:40 <aristid> alexyk: "der" just means "the" :)
12:38:51 <alexyk> aristid: right :)
12:39:19 <monoidal> leino: yes: do f $ \x -> do <next line can be indented same level>
12:39:25 <monoidal> leino: but that's a small detail
12:39:30 <alexyk> aristid: how come you dropped the anglicized suffix es?
12:39:32 <technogeeky> how about, Kaiser WIlhelm der [my shitty IRC client doesn't do unicode]
12:39:46 <technogeeky> no matter
12:39:47 <technogeeky> bbl
12:39:47 <tibbe> chrisdone: just sort groups of imports that are not separated by something (empty lines, comments)
12:40:16 <monoidal> leino: I'm not sure if that is haskell 98/10 or GHC specific
12:40:20 <aristid> alexyk: suffix "es"?
12:40:24 <alexyk> aristid: I mean in your nick; I like it that way
12:40:31 <alexyk> Aritstid & Themistokl
12:40:46 <alexyk> s/tst/st/
12:40:50 <aristid> alexyk: no idea, probably my parents are crazy
12:41:15 <leino> monoidal: ok, when I try to indent to the same level using tabs, I get errors, but with spaces its all good :)
12:41:29 <aristid> alexyk: having a unique first name is quite useful, too
12:41:32 <chrisdone> tibbe: sure. that fits my use-case anyway
12:41:38 <monoidal> leino: tabs are 8 characters, but shouldn't really be used
12:41:49 <monoidal> 8 spaces
12:41:49 <alexyk> aristid: well this is at leat how it's used in Russian, I reckon after the original Greek: Аристид.  Any Greeks here to type it in the original?
12:42:13 <aristid> alexyk: the name is relatively common in russia?
12:42:33 <aristid> alexyk: i only know it from the haitian dictator and some french artist guy (i think)
12:42:35 <alexyk> aristid: no, only in history books about that prick who annoyed Themistocles :)
12:42:44 <mauke> I'm not greek, but I can type random greek characters
12:43:08 <alexyk> mauke: go ahead, stir the air, it's hot anyways
12:43:11 <monoidal> leino: http://urchin.earth.li/~ian/style/haskell.html, search for "Tabs"
12:43:17 <mauke> such as Αριστιδης, which may or may not have any relation to reality
12:43:40 <leino> monoidal: thanks
12:43:42 <alexyk> mauke: then the suffix is real, which would be interesting
12:44:16 <alexyk> actually now I think it is; dropped in Russian usage of Greek names historically
12:44:20 <mauke> wikipedia says Ἀριστείδης
12:44:45 <mauke> nickname: the Just
12:44:50 <mauke> THEN WHO WAS NOTHING
12:44:51 <alexyk> exactly
12:44:56 <ibt> any idea who runs projects.haskell.org? it seems down
12:45:13 <danharaj> Can anyone help me out? I'm trying to build a library, and the readme says to modify the .cabal file and add "Include-Dirs: C:\Foo" at the end of it, but when I run Setup.lhs configure, I get "Construct not supported at this position"
12:45:18 <aristid> Ἀριστείδης Etymology Derived from Ἀριστεύς
12:45:41 <alexyk> he looked down on the unwashed masses too ignoble to appreciate Haskelles
12:46:01 <alexyk> lead by Clojurus
12:46:19 <alexyk> and his evil twin bother Ocamles
12:46:32 <mauke> Ἁσκελλης
12:46:45 <alexyk> !
12:47:55 <aristid> alexyk: all of them are of course virtuous compared to Scalaes and Fsharpes, the brothers of pure evilness
12:48:07 <dons> tibbe: pong
12:48:56 <tibbe> dons: I was playing around with AT maps today, I'm not sure if it's possible to avoid the 1M instance problem given current GHC features
12:49:01 <alexyk> right, and teh great dictator Cius Cplusplusius Java and his smug advisor Csharpius
12:50:30 <p_l> I'm not sure integrating C, C++ and Java into one being is correct
12:50:57 <ibt> err, anyone know of a projects.haskell.org mirror?
12:50:58 <mauke> that doesn't stop C++ from trying
12:50:59 <alexyk> p_l: a triple-headed beast is good for a propaganda enemy
12:51:05 <dons> tibbe: agreed. i think we'll need to state that in the proposal. one idea i had was to not provide instances, instead encouraging the use of a macro at the use site. 
12:51:09 <dons> tibbe: i.e. standalone deriving
12:51:18 <aristid> mauke: http://instantrimshot.com/
12:51:29 <mauke> did you mean: sting
12:51:30 <dons> $(deriveMap Int Bool)
12:51:32 <tibbe> dons: so I have a macro that generates an instance
12:52:19 <dons> is the code somewhere, I'll want to talk about it in the paper (I'm doing IntMap)
12:52:41 <aristid> dons: what does deriveMap do?
12:52:58 <dons> aristid: it would generate an instance of AdaptMap under tibbe's model
12:52:59 <tibbe> dons: I have a really small skeleton for a generic Map
12:53:02 <dons> but at the use site.
12:53:13 <tibbe> dons: couldn't that give us orphan instances?
12:53:16 <dons> yes
12:53:29 <tibbe> dons: what exactly are you doing with IntMap, doing an AdaptIntMap?
12:53:34 <dons> that's what it would expose us to. so it would be a mentioned workaround, short of compiler specialization of data types
12:53:43 <dons> tibbe: yeah. 
12:54:00 <tibbe> dons: an IntMap could really fall under a normal Map with the adapt scheme as we could use an IntMap whenever the key is of type Int :)
12:54:06 <aristid> dons: why isn't it possible to use haskell's native polymorphism instead of template haskell? (sorry if this is a stupid question)
12:54:11 <dons> we could switch to a differeent type, yes.
12:54:19 <dons> though that's more broadly towards a general containers class
12:54:29 <tibbe> dons: I want to do an AdaptHashSet
12:54:30 <dons> aristid: oh, we don't want to use native polymorphism.
12:54:39 <dons> aristid: we want to specialize the data type at each element type
12:54:51 <dons> tibbe: do we have the new containers patches yet from the paper?
12:54:59 <tibbe> dons: should be easy once we have an AdaptIntMap
12:55:07 <tibbe> dons: no, I checked today
12:55:08 <aristid> dons: "specialize"?
12:55:35 <tibbe> dons: I might have reinvented some of the patches already while hacking today
12:56:01 <dons> aristid: List Int --> ListInt = Null | Cons {-# UNPACK #-}!Int ListInt
12:56:55 <aristid> dons: does that yield better performance?
12:57:10 <dons> indeed it does.
12:57:13 <dons> better data density
12:59:31 <alexyk> dons: dafis' binary instances bring lookup down to 55 secs
12:59:36 <alexyk> and RAM to 8 GB
13:00:53 <alexyk> dons: so RAM for the mutable map is already lower than ocaml, while time is just 4x more than the mutable thing -- AND haskell decompresses a 665 M file where OCaml reads 1.3 GB uncompressed as it can't lazily decompress
13:01:38 <alexyk> dons: so now haskell is unashamed
13:02:07 <tibbe_> dons: so are you already working on the paper or only playing around with IntMap?
13:02:28 <alexyk> tibbe: I tried dons' AdaptMap instead of Data.IntMap, and it was worse than dafis' IntMap strictified blue
13:02:38 <tibbe_> dons: we should share ideas, I use view patterns (which get inlined away) to avoid code duplication (e.g. I only implement lookup once)
13:03:01 <tibbe_> aleator: dafis' IntMap strictified blue?
13:03:11 <tibbe_> alexyk: ^^
13:03:20 <tibbe_> aleator: misstell
13:03:25 <alexyk> tibbe: dafis made IntMap strict
13:03:33 <alexyk> to get all speedup we could get
13:03:42 <tibbe_> alexyk: for Ints I would expect IntMap to beat an AdaptMap
13:03:58 <tibbe_> alexyk: strict where? In the elements? UNPACKed?
13:04:03 <tibbe_> alexyk: code? :)
13:04:28 <monoidal> Functor has (GHC.Base.<$) :: a -> f b -> f ain definition. what is the usage/reason? performance?
13:05:08 <alexyk> http://github.com/alexy/husky/blob/master/IntMap.hs
13:05:13 <alexyk> tibbe: ^^
13:05:26 <alexyk> that kicks OCaml's ass
13:06:04 <alexyk> tibbe: for values, we used [(Int,Double)]
13:06:14 <alexyk> so not just Ints
13:06:20 <tibbe> alexyk: you can unpack that for better data density
13:06:45 <alexyk> tibbe: looks like data IntMap as UNPACK peppered in?
13:06:49 <alexyk> has
13:07:36 <tibbe> Tip {-# UNPACK #-) !Key {-# UNPACK #-} !Int {-# UNPACK #-} !Double !NonEmptyIntDoubleList
13:08:27 <alexyk> tibbe: but that would be a specialized IntMap for those values then?
13:08:38 <tibbe> alexyk: data NonEmptyIntDoubleList = IntDoubleSingle {-# UNPACK #-} !Int {-# UNPACK #-} !Double | Cons {-# UNPACK #-} !Int {-# UNPACK #-} !Double !NonEmptyIntDoubleList
13:08:56 <tibbe> alexyk: yes, what dons and I'm working on would do that without the code duplication
13:09:03 <CakeProphet> so what is the distinction between Control.Monad.State
13:09:04 <CakeProphet> and
13:09:08 <tibbe> alexyk: but it would save you a bunch of space
13:09:09 <CakeProphet> Control.Monad.State.Lazy?
13:09:17 <Zao> CakeProphet: One is lazy in the state?
13:09:24 <alexyk> tibbe: wow.  So we should try that specific type and yours then.
13:09:28 <tibbe> alexyk: yes
13:09:32 <CakeProphet> Zao:  isn't Haskell implicitly lazy and explicitly eager though?
13:09:34 <tibbe> alexyk: can the list of values be empty?
13:09:42 <aristid> why doesn't {-# UNPACK #-} work on polymorphic types?
13:09:46 <CakeProphet> Zao:  why isn't the normal State monad lazy in such a way?
13:09:46 <tibbe> alexyk: if not you need a list that can be empty
13:09:48 <Zao> CakeProphet: You can always ! bang types.
13:10:08 <tibbe> aristid: unfortunately not, the representation needs to be the same (a pointer)
13:10:13 <Zao> CakeProphet: Because such long accumulations tend to leak spac?
13:10:14 <alexyk> tibbe: no.  For my data, it won't happen.  Is being non-empty crucial for it to work?
13:10:15 <Zao> *space
13:10:22 <tibbe> alexyk: no
13:10:33 <tibbe> alexyk: it save you a bit of space if you know it's never empty
13:10:44 <alexyk> ok
13:10:45 <CakeProphet> Zao:  so State is implicitly eager unless you use State.Lazy?
13:10:53 <tibbe> alexyk: actually, just use an AdaptList (Pair Int Double) where I had my NonEmptyIntDoubleList
13:10:55 <aristid> tibbe: sounds like a deficiency of the compiler
13:11:06 <tibbe> aristid: possibly
13:11:21 <alexyk> tibbe: where do I get the AdaptList?
13:11:22 <Taejo> CakeProphet: neither is the default -- one just has a shorter name
13:11:24 <tibbe> aristid: question is, how do functions operating on the polymorphic container know about the data layout?
13:11:39 <tibbe> alexyk: http://hackage.haskell.org/package/adaptive-containers
13:11:45 <alexyk> aha
13:11:49 <CakeProphet> Taejo:  ??? I don't think that answers my question though.
13:11:59 <dons> aristid: ocaml and haskell use a "uniform representation" to support parametric polymorphism.
13:12:17 <Taejo> CakeProphet: it's not implicitly anything: you choose between a lazy or a strict State
13:12:22 <dons> though haskell lets you specialized functions and types via instances now. similar to C++ template specialization
13:12:25 <tibbe> alexyk: so Tip {-# UNPACK #-) !Key !(AdaptList (Pair Int Double))
13:12:32 <dons> its an alternative approach to a form of polymorphism
13:12:34 <CakeProphet> Taejo:  and so Control.Monad.State is the eager variety then? That is my question.
13:12:40 <Taejo> yes
13:12:56 <dons> aristid: the full story is heree:  http://donsbot.wordpress.com/2009/10/11/self-optimizing-data-structures-using-types-to-make-lists-faster/
13:12:56 <CakeProphet> Taejo:  How is this done? internally or is there way it is done in source?
13:12:57 <monoidal> there's Control.Monad.State.Strict too
13:13:04 <Zao> http://hackage.haskell.org/packages/archive/mtl/1.1.0.2/doc/html/src/Control-Monad-State.html
13:13:11 <alexyk> tibbe: if I hack that into IntMap.hs, would I have to hack some more if it?
13:13:15 <Zao> This seems to imply that .Lazy-less State is Lazy.
13:13:20 <tibbe> alexyk: if the list is never empty you can do like I did above and put the first list element in the Tip constructor itself, saving some space in case singleton lists are very frequent
13:13:30 <Taejo> CakeProphet: you don't need special-casing in the compiler if that's what you mean
13:13:31 <Zao> At least in MTL.
13:13:32 <CakeProphet> Zao:  then I am entirely confused.
13:13:33 <tibbe> alexyk: don't think so
13:13:43 <Taejo> you just put seq in the right place
13:13:44 <alexyk> tibbe: yeah, we'll get a lot of singletons
13:13:50 <tibbe> alexyk: (but then again it's late here and I'm sleepy)
13:14:07 <CakeProphet> I guess I just didn't realize that eager evaluation could be done implicitly like that.
13:14:19 <CakeProphet> I thought the ! types were needed.
13:14:25 <monoidal> Control.Monad.State == Control.Monad.State.Lazy
13:14:33 <Zao> CakeProphet: I would, based on the evidence of that source, say that C.M.State is C.M.State.Lazy in at least mtl-1.1.0.2
13:14:35 <Taejo> CakeProphet: no
13:14:44 <Zao> And in general.
13:14:57 <CakeProphet> monoidal:  ah. This makes more sense.
13:14:58 <monoidal> CakeProphet: compare f (x,y) = (x,y) and f x = x
13:14:59 <Taejo> CakeProphet: (+) is strict on integers, for example
13:15:09 <tibbe> alexyk: I used that trick for creating a HashSet on top of IntMap, the value of the IntMap is the list of colliding keys, since this list is frequently only one element and never empty once can save some space using some UNPACKing tricks
13:15:18 <Zao> Disregard my previous guess that the non-lazy one was stricter, as one might infer from other libraries like bytestring.
13:15:21 <monoidal> CakeProphet: first one forces that pair is evaluated, second one doesn't
13:15:34 <tibbe> alexyk: if you want some help implementing a faster Map/IntMap, drop me an email
13:15:37 <lowasse1> Query: I always thought you had to use {-# UNPACK #-} with !.  Is the ! implicit?
13:15:40 <CakeProphet> Taejo:  is there any kind of documentation or something I could read about all of the different cases of strict evaluation in Haskell?
13:15:46 <Taejo> > runState (put undefined) undefined
13:15:47 <lambdabot>   ((),*Exception: Prelude.undefined
13:15:52 <aristid> dons: "You can see this tradeoff most vividly in this picture of a list of pairs:" - the picture is completely blank
13:15:55 <tibbe> alexyk: I was inspired to improve the data density in the containers library by the whole twitter analysis
13:16:21 <alexyk> tibbe: sure, I'd try anything to get my huge runs faster... where do I find your email?
13:16:41 <dons> aristid: oh.
13:16:49 <Taejo> CakeProphet: there is, but my international internet connection is down so I can't go looking
13:17:01 <dons> aristid: doesn't look blank to me
13:17:01 <Taejo> CakeProphet: look up the "seq" function
13:17:07 <dons> aristid: http://code.haskell.org/~dons/images/vacuum/tuple-list.png ??
13:17:09 <Taejo> a `seq` b)
13:17:10 <tibbe> alexyk: I should write a blog post about counting how many bytes a Haskell data structure will take
13:17:12 <CakeProphet> Taejo:  seq is the strictness primitive of sorts? 
13:17:13 <Taejo> ack
13:17:19 <dons> tibbe: simonmar did that already
13:17:20 <monoidal> yes
13:17:28 <tibbe> dons: where?
13:17:31 <aristid> dons: does not load
13:17:36 <monoidal> CakeProphet: seq a b forces a and returns b
13:17:39 <Taejo> CakeProphet: yes, although for non-polymorphic types it can be done in other ways
13:17:49 <dons> aristid: works for me. anyone else?
13:18:00 <dons> aristid: oh, maybe c.h.o is down and it is in my cache
13:18:02 <tibbe> alexyk: what exactly did you guys change in the IntMap, made the children strict?
13:18:02 <alexyk> png hangs
13:18:10 <dons> tibbe: http://ghcmutterings.wordpress.com/2009/02/12/53/
13:18:16 <dons> code.h.o must be down
13:18:18 <dons> Igloo: ^^^
13:18:18 <tibbe> alexyk: sent you my email in a prive msg
13:18:53 <CakeProphet> aaaah. Okay. I just read about seq and saw it used in the definition of ($!). I believe I understand how it works and it looks quite useful for cutting down space leaks and such.
13:18:55 <alexyk> tibbe: right, dafis did it
13:19:00 <tibbe> dons: oh, I meant actually describing how to do it by hand (and understand what takes space) rather than have a function tell you
13:19:17 <tibbe> alexyk: strict spines usually makes sense, the rest of the containers (e.g. Data.Map) uses that
13:19:30 <CakeProphet> Taejo:  could you explain these other ways?
13:19:36 <dons> tibbe: oh, dcoutts does that in his thesis, iirc
13:19:37 <alexyk> dafis added a whole lot of bangs to my code and it started flyng.  Looks like you need a bangification extension.
13:19:38 <dons> dcoutts_: ^^
13:19:55 <dons> tibbe: i've seen programs double as fast with lazy spines 
13:20:01 <dons> one of my IntMap ones was like that.
13:20:07 <Taejo> CakeProphet: f a b = case a of { True -> b; False -> b}
13:20:12 <tibbe> dons: he does in the bytestring report
13:20:14 <dons> depends on how you traverse.
13:20:23 <Taejo> this f is the same as seq, but only works on Bool
13:20:31 * hackagebot gbu 0.1 - planar graph embedding into a plane  http://hackage.haskell.org/package/gbu-0.1 (DaneelYaitksov)
13:20:47 <tibbe> dons: I did a comparison on a few container classes and they were faster with it
13:21:08 <alexyk> a simple loading from Binary and lookup in the Map ByteString [(Int,Double)] going to 38 GB and 1 hour was eye-opening
13:21:09 <tibbe> dons: reason being that GHC can avoid some evaluation checks and things generally get evaluated at once while the cache is hot
13:21:13 <CakeProphet> Taejo:  hmmmm, Bool -> a -> a right?
13:21:21 <Taejo> CakeProphet: right
13:21:32 <CakeProphet> Taejo:  what about other uses of case with non-Bools?
13:21:43 <mreh> @google google trends cake
13:21:44 <lambdabot> No Result Found.
13:21:55 <monoidal> CakeProphet: also http://en.wikibooks.org/wiki/Haskell/Laziness
13:22:10 <tibbe> alexyk: I hope to cover strictness (and strictness annotations) at my high-performance Haskell tutorial at CUFP.
13:22:23 <Taejo> CakeProphet: for any concrete data type (not (->)), you can write a specialised version of seq
13:22:28 <monoidal> CakeProphet: you can write seq for any type defined with data by case a of { C1 _ _ _ -> b; ... }
13:23:02 <monoidal> CakeProphet: how many values of type () -> () can you tell?
13:23:04 <CakeProphet> Taejo:  oooh, okay. It's not case specifically. I see what's going on. It's just the semantics of lazy evaluation that cause a to be forced in that example.
13:23:16 <mreh> :t const ()
13:23:16 <Taejo> yes
13:23:17 <lambdabot> forall b. b -> ()
13:23:18 <aristid> dons: hah, i wasn't aware of uniform representation, but it does make sense when thinking about it
13:23:46 <CakeProphet> Taejo:  so seq itself is still lazily evaluated, but once it is evaluated it forces its first argument.
13:23:52 <Taejo> yes
13:24:20 <CakeProphet> > undefined `seq` "Hello, World"
13:24:21 <lambdabot>   "*Exception: Prelude.undefined
13:24:28 * alexyk wonders if analyzing Twitter data at Dartmouth & contemplating startups for it qualifies for CUFP
13:24:43 <alexyk> where the data is massaged with smooth FP tools only
13:24:45 <CakeProphet> > let x = undefined `seq` undefined in "Hello, World!"
13:24:46 <Taejo> CakeProphet: you sometimes hear people talking about seq-free Haskell; this is because you can't define seq from within Haskell (and it's specifically (->) that gives trouble)
13:24:46 <lambdabot>   "Hello, World!"
13:25:15 <Taejo> > undefined `seq` "Hello, World!"
13:25:15 <lambdabot>   "*Exception: Prelude.undefined
13:25:20 <CakeProphet> Taejo:  ...I don't see any big deal with a language having built-in primitives. That's how languages are built.
13:25:24 <alexyk> how about "CCUFP -- Contemplating ..."?
13:25:52 <tibbe> alexyk: do you work at twitter?
13:26:02 <Taejo> CakeProphet: well, you can define the non-IO part of seq-free Haskell without builtin functions
13:26:07 <tibbe> dons: I missed your answer about the paper thing, have you started looking at it yet?
13:26:15 <alexyk> tibbe: no :)  I talked to them a lot when I did it in Scala though
13:26:18 <Taejo> but seq breaks some nice theorems
13:26:27 <alexyk> and used the Streaming API in its infancy
13:26:28 <Taejo> that's why people talk about seq-free Haskell
13:26:31 <tibbe> alexyk: so the data is public?
13:26:55 <monoidal> a strict pattern match f (!x) = y is equivalent to f x | x `seq` True = y
13:27:19 <alexyk> tibbe: they have a stream which is free for research; my data is also cleared for distribution with my FP shootout for it
13:27:25 <Taejo> CakeProphet: the reason this happens is because a lot of reasoning in the end relies on the idea that the only thing you can do with a function is call it -- but seq allows you to a) call it, or b) force it
13:27:43 <tibbe> alexyk: cool
13:27:49 <hpc> :t (seq `seq` seq)
13:27:50 <lambdabot> forall a t. a -> t -> t
13:27:50 <dons> tibbe: looking at what?
13:28:13 <tibbe> alexyk: I compare your IntMap to the standard one (http://haskell.org/ghc/docs/6.12.2/html/libraries/containers-0.3.0.0/src/Data-IntMap.html) and couldn't see any extra strictness/unpacking
13:28:26 <tibbe> dons: have you started writing it? :)
13:29:15 <dons> tibbe: the paper, yes. about 3 pages and the overall structure.
13:29:26 <dons> tibbe: but i need more implementations and benchmarks of the approach.
13:29:32 <alexyk> tibbe: I'll ask dafis about it...  I thought there were some extra bangs
13:29:35 <tibbe> dons: ok, where you interested in collaborating or do you have it down already?
13:29:41 <dons> tibbe: i need indexed monad classes for an auto-specializing Control.Monad.State for example.
13:29:53 <dons> tibbe: i'd like to collaborate with you on it. 
13:30:03 <tibbe> alexyk: ok, just commenting that the data representation is the same (and thus the memory usage of the map)
13:30:07 <tibbe> dons: :D
13:30:15 <tibbe> dons: drop me an email, I can run some benchmarks
13:30:24 <dons> ok. excellent. i'll set up a repo we can both work from.
13:30:33 <dons> deadline's about 2 months, so plenty of time to make sure the code is fast.
13:30:33 <tibbe> dons: sounds great
13:30:41 <tibbe> dons: should be no problem
13:30:45 <dons> and i want to use graphs from vacuum and criterion.
13:30:49 <dons> really solid benchmarks of many types
13:31:11 <tibbe> alexyk: I have a vague memory of you using a map of Strings/ByteStrings, did you replace that by an IntMap?
13:31:12 <alexyk> is it too late to submit a talk about my trilingual FP experience wth Twitter to ICFP in some form?
13:31:26 <dons> alexyk: yeah, sadly.
13:31:32 <dons> alexyk: you might consider PADL 
13:32:01 <luite> does anyone know haskell implementations of algorithms that generate all (unlabeled, unique) graphs with certain properties?
13:32:16 <alexyk> tibbe: yeah, lookup times were 32% of the runs, so I interned ByteStrings, compute with IntMap, and disintern into a Map ByteString or a Trie
13:32:48 <alexyk> dons: how about some ad-hockery for a workshop or such?  We have a policy of going to conferences with presentations only :)
13:33:03 <alexyk> and now I must attend tibbe's CUFP workshop! :)
13:33:18 <tibbe> alexyk: ok, unfortunately for you your in the middle of a containers library overhaul, if you did this in 2 months you could probably just use an off-the-shelf HashMap (which would be implemented using IntMap) and be done with it
13:33:59 <alexyk> tibbe: well, but now I have a chance to look under the hood.  Very educational.
13:34:26 <tibbe> alexyk: :)
13:34:27 <tibbe> alexyk: http://hackage.haskell.org/package/hashmap
13:34:54 <tibbe> alexyk: that HashMap came out of the recent paper on containers, apparently there a few improvements that haven't been integrated yet
13:35:27 <CakeProphet> > const undefined 10
13:35:28 <lambdabot>   *Exception: Prelude.undefined
13:35:31 <CakeProphet> :o
13:35:38 <CakeProphet> wait a second
13:35:41 <CakeProphet> why?
13:35:45 <tibbe> @src fromIntegral
13:35:45 <lambdabot> fromIntegral = fromInteger . toInteger
13:35:45 <mauke> what did you expect?
13:35:55 <CakeProphet> I expected 10 not bottom.
13:36:03 <mauke> > const 10 undefined
13:36:04 <lambdabot>   10
13:36:08 <monoidal> :t const
13:36:08 <CakeProphet> oh... ha
13:36:09 <lambdabot> forall a b. a -> b -> a
13:36:12 <CakeProphet> I mixed up the arguments.
13:36:30 <mauke> > flip flip undefined const 10
13:36:32 <lambdabot>   10
13:37:08 <CakeProphet> mauke:  not a pro at pointless style so I have trouble following that one.
13:37:21 <Arnar> hey all
13:37:27 <Arnar> is projects.haskell.org down?
13:37:32 <CakeProphet> > const 10 $! undefined
13:37:33 <lambdabot>   *Exception: Prelude.undefined
13:37:34 <aristid> :t flip flip
13:37:35 <lambdabot> forall (f :: * -> *) a b. (Functor f) => a -> f (a -> b) -> f b
13:37:51 * tibbe wishes he had some more hacking time.
13:37:59 <aristid> :t Prelude.flip Prelude.flip
13:38:00 <lambdabot> forall a b c. b -> (a -> b -> c) -> a -> c
13:38:01 <mauke> CakeProphet: inline flip and proceed from there
13:38:23 <CakeProphet> mauke:  so flip flip basically makes an infix operator?
13:38:31 <mauke> heh
13:38:33 <tibbe> dons: I'm off to bed, feel free to drop me an email
13:38:39 <tibbe> alexyk: time to sleep, gnight
13:38:48 <tibbe> alexyk: drop me an email if you want help/input
13:39:16 <mauke> > flip id 10 const undefined
13:39:18 <lambdabot>   10
13:39:51 <CakeProphet> mauke:  ...but...... why?
13:39:53 <dons> tibbe: ok. great
13:39:58 <mauke> CakeProphet: why not?
13:40:02 <CakeProphet> haha. I guess.
13:41:05 <monoidal> flip flip flip flip flip == flip flip flip flip flip flip
13:41:19 <monoidal> from 5 up they are the same
13:42:18 <monochrom> id can take on the special type (a->b)->a->b which behaves as ($)
13:42:36 <Arnar> does anyone have a recent tarball of haskell-mode (f. emacs)? projects.haskell.org seems down..
13:42:38 <monoidal> :t flip flip flip flip flip flip flip flip flip flip flip flip
13:42:39 <lambdabot> forall (f :: * -> *) a b (f1 :: * -> *) b1. (Functor f, Functor f1) => f1 ((f (a -> b) -> a -> f b) -> b1) -> f1 b1
13:42:47 <monoidal> :t flip flip flip flip flip flip
13:42:48 <lambdabot> forall (f :: * -> *) a b (f1 :: * -> *) b1. (Functor f, Functor f1) => f1 ((f (a -> b) -> a -> f b) -> b1) -> f1 b1
13:42:51 <monoidal> same type, same function
13:46:05 <Taejo> @pl \s -> (s,s)
13:46:05 <lambdabot> join (,)
13:46:48 <Arnar> :t join
13:46:49 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
13:47:19 <djahandarie> :t \s -> (,) s
13:47:20 <lambdabot> forall a b. a -> b -> (a, b)
13:47:33 <djahandarie> Whoops
13:47:39 <djahandarie> :t (,) s
13:47:40 <lambdabot> forall b. b -> (Expr, b)
13:47:51 <mauke> > join f x :: Expr
13:47:52 <lambdabot>   f x x
13:48:30 <djahandarie> I remember thinking about the type signatures once but I don't remember now
13:50:43 <CakeProphet> Expr is black magic to me.
13:51:04 <mauke> why?
13:51:11 <CakeProphet> because I don't know how it works, of course. :)
13:51:27 <mauke> it's just some type
13:51:40 <CakeProphet> but how can you simply do :: Expr
13:51:42 <CakeProphet> on any expression?
13:51:45 <mauke> you can't
13:51:50 <mauke> only those of type Expr
13:51:58 <CakeProphet> :t join
13:51:59 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
13:52:00 <mauke> > "bzzt" :: Expr
13:52:01 <lambdabot>   Couldn't match expected type `SimpleReflect.Expr'
13:52:02 <lambdabot>         against inferred ...
13:52:11 <mauke> :t x
13:52:12 <lambdabot> Expr
13:52:30 <aristid> mauke: last time i checked, "bzzt" was not polymorphic?
13:52:38 <aristid> :t "bzzt"
13:52:39 <lambdabot> [Char]
13:52:50 <mauke> aristid: yes, that's the point
13:53:04 <aristid> mauke: oh, you were... making a point?
13:53:26 <CakeProphet> mauke:  oooh, okay. I forgot that Expr defines special variables. That is why I thought it was black magic.
13:53:32 <hpc> @src Expr
13:53:32 <lambdabot> Source not found. :(
13:53:44 <aristid> :t x+y
13:53:45 <lambdabot> Expr
13:54:04 <Arnar> hmm.. cabal update is giving me some "incorroect (zlib) header check
13:54:08 <aristid> CakeProphet: you can also cast numbers to Expr because they are polymorphic
13:54:11 <Arnar> am I the only one?
13:54:36 <CakeProphet> aristid:  example?
13:54:37 <aristid> > foldr (+) 0 [1..5] :: Expr
13:54:38 <lambdabot>   1 + (2 + (3 + (4 + (5 + 0))))
13:54:45 <EvanCarroll> what is the difference between Data.Char and Char ?
13:54:48 <aristid> > foldr (+) 0 [1..] :: Expr
13:54:48 <lambdabot>   1 + (2 + (3 + (4 + (5 + (6 + (7 + (8 + (9 + (10 + (11 + (12 + (13 + (14 + (...
13:54:53 <aristid> FUN
13:54:57 <monoidal> Arnar: works for me
13:55:05 <Arnar> monoidal: thanks..
13:55:05 <Arnar> hmm
13:55:09 <CakeProphet> EvanCarroll:  I don't believe there is one.
13:55:12 <aristid> :t 1
13:55:12 <lambdabot> forall t. (Num t) => t
13:55:17 <aristid> > 1 :: Expr
13:55:18 <lambdabot>   1
13:55:20 <CakeProphet> EvanCarroll:  well, Data.Char is a module. Char is a type.
13:55:22 <mauke> EvanCarroll: Char is the old Haskell98 module, Data.Char is the modern version
13:55:24 <aristid> CakeProphet: see?:)
13:55:42 <CakeProphet> aristid:  indeed I do. But I don't understand how you can "cast" numbers to Expr. Is Expr an instance of Num?
13:55:43 <monoidal> Arnar: what about ghc-pkg check?
13:55:53 <aristid> CakeProphet: it is!
13:56:21 <aristid> :t 1 2
13:56:21 <lambdabot>     Ambiguous type variable `t' in the constraint:
13:56:22 <lambdabot>       `Num t' arising from the literal `2' at <interactive>:1:2
13:56:22 <lambdabot>     Probable fix: add a type signature that fixes these type variable(s)
13:56:28 <aristid> :t 1 2 :: Expr
13:56:28 <monoidal> :t 1 2 :: Expr
13:56:29 <lambdabot> Expr
13:56:29 <lambdabot> Expr
13:56:30 <EvanCarroll> mauke++ # thanks.
13:57:02 <Arnar> monoidal: I'm having this problem: http://hackage.haskell.org/trac/hackage/ticket/622
13:57:11 <aristid> CakeProphet: Expr -> Expr -> Expr seems to be an instance of Num too
13:57:13 <CakeProphet> aristid:  .... Expr makes numbers functions?? 
13:57:16 <Arnar> my proxy is unzipping the stream >(
13:57:23 <aristid> CakeProphet: yes, Expr is teh crazy
13:57:35 <mauke> CakeProphet: I don't think that's Expr
13:57:43 <mauke> there are two different Num instances here
13:57:56 <mauke> > 42 () :: Int
13:57:57 <lambdabot>   42
13:58:16 <mauke> instance (Num a) => Num (b -> a)
13:58:21 <aristid> mauke: huh? where does that instance come from?
13:58:29 <mauke> no idea
13:58:40 <ddarius> vector-space
13:58:43 <aristid> mauke: but it does make sense for expr
13:58:46 <hpc> i think it comes from messing with people's minds
13:58:47 <aristid> > f 1
13:58:48 <lambdabot>   Ambiguous type variable `a' in the constraints:
13:58:48 <lambdabot>    `SimpleReflect.FromExpr ...
13:58:52 <aristid> > f 1 :: Expr
13:58:53 <lambdabot>   f 1
13:58:58 <hpc> > 1 f
13:58:59 <lambdabot>   Ambiguous type variable `a' in the constraint:
13:58:59 <lambdabot>    `SimpleReflect.FromExpr a...
13:59:05 <aristid> > 1 f :: Expr
13:59:06 <lambdabot>   Ambiguous type variable `a' in the constraint:
13:59:06 <lambdabot>    `SimpleReflect.FromExpr a...
13:59:16 <hpc> > fix f
13:59:16 <lambdabot>   Ambiguous type variable `a' in the constraints:
13:59:17 <lambdabot>    `GHC.Show.Show a'
13:59:17 <lambdabot>      a...
13:59:22 <aristid> :t f
13:59:23 <lambdabot> forall a. (SimpleReflect.FromExpr a) => a
13:59:24 <ddarius> > fix f :: Expr
13:59:25 <lambdabot>   f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (...
13:59:39 <monochrom> or fix (f :: Expr -> Expr)
13:59:56 <CakeProphet> > map (+x) [1..10] :: EXpr
13:59:57 <lambdabot>   Not in scope: type constructor or class `EXpr'
14:00:00 <monochrom> > fix f `asTypeOf` a
14:00:00 <aristid> > foldr1 ($) (repeat f) :: Expr
14:00:00 <CakeProphet> > map (+x) [1..10] :: Expr
14:00:01 <lambdabot>   f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (...
14:00:01 <lambdabot>   Occurs check: cannot construct the infinite type: a = a -> b
14:00:01 <lambdabot>   Couldn't match expected type `SimpleReflect.Expr'
14:00:01 <lambdabot>         against inferred ...
14:00:02 <ddarius> or fix (f :: (Expr -> Expr) -> Expr -> Expr) 3
14:00:06 <monochrom> oops :)
14:00:12 <aristid> > foldl1 ($) (repeat f) :: Expr
14:00:13 <lambdabot>   Occurs check: cannot construct the infinite type: a = a -> b
14:00:20 <aristid> > foldl1 (flip ($)) (repeat f) :: Expr
14:00:21 <lambdabot>   Occurs check: cannot construct the infinite type: a = a -> b
14:00:24 <aristid> hmmm
14:00:31 <ddarius> :t foldl1
14:00:32 <lambdabot> forall a. (a -> a -> a) -> [a] -> a
14:00:50 <monochrom> think of what type is "repeat f"
14:01:05 <ddarius> Not necessary to think of that.
14:01:21 <monochrom> yes necessary
14:01:29 <ddarius> The issue is the type of ($) is not of the form a -> a -> a without an a = a -> b
14:01:36 <ddarius> :t foldl1 ($)
14:01:37 <lambdabot>     Occurs check: cannot construct the infinite type: a = a -> b
14:01:37 <lambdabot>     Probable cause: `$' is applied to too few arguments
14:01:37 <lambdabot>     In the first argument of `foldl1', namely `($)'
14:01:39 <CakeProphet> > map (+3) (repeat x) :: Expr
14:01:40 <lambdabot>   Couldn't match expected type `SimpleReflect.Expr'
14:01:40 <lambdabot>         against inferred ...
14:01:44 <monochrom> alright I see
14:01:56 <milaz> hi, all!
14:02:16 <CakeProphet> :t foldl
14:02:17 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
14:02:32 <aristid> monochrom: but repeat is obviously ALSO the problem
14:02:36 <aristid> so it fails in two ways
14:02:39 <CakeProphet> foldl (+) 0 [1..5] :: Expr
14:02:41 <mreh> given: switch :: SF a (b, Event c) -> (c -> SF a b) -> SF a b
14:02:45 <mreh> switch identity (const (arr fst)) --- huh?
14:02:46 <CakeProphet> > foldl (+) 0 [1..5] :: Expr
14:02:47 <lambdabot>   0 + 1 + 2 + 3 + 4 + 5
14:03:00 <mreh> my internal type checker gives me an infinite type
14:03:03 <Taejo> it seems to me that in the reverse state monad you can't write modify in terms of get and put -- is that right?
14:03:05 <milaz> can anybody give me an advise which type to use best if i want to create a 3-dimensional array of Word8?
14:03:15 <orlandu63> > map (+3) (repeat x :: [Expr]) :: [Expr]
14:03:16 <lambdabot>   [x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x + 3,x ...
14:03:37 <Taejo> :t x
14:03:38 <lambdabot> Expr
14:03:55 <ddarius> milaz: It depends on what you want to do with it.
14:04:01 <aristid> :t f
14:04:02 <lambdabot> forall a. (SimpleReflect.FromExpr a) => a
14:04:46 <milaz> ddarius: i'd read it once from a file, and then will be analyzing it. i won't do any mutations on it.
14:04:56 <ddarius> > foldr ($) x (repeat f)
14:04:57 <lambdabot>   f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (...
14:05:24 <ddarius> milaz: What kind of "analyses" will you be doing?
14:05:50 <aristid> ddarius: hmm
14:06:04 <aristid> :t repeat f
14:06:05 <lambdabot> forall a. (SimpleReflect.FromExpr a) => [a]
14:06:16 <aristid> :t foldr ($) x
14:06:17 <lambdabot> [Expr -> Expr] -> Expr
14:06:51 <monochrom> @type foldl
14:06:52 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
14:07:01 <dons> heavily optimized particle simulation program, no heap allocation, so is happiest with tiny heap, http://www.galois.com/~dons/images/DLA-time-gc-space.svg
14:07:09 <dons> useful to remember if you have a lot of numerical/unboxed code
14:07:16 <monochrom> @type foldr
14:07:17 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
14:07:41 <monochrom> > foldr ($) a [f,f,f] :: Expr
14:07:42 <lambdabot>   f (f (f a))
14:07:46 <ddarius> dons: Sounds like an interesting program, where is it?
14:08:03 <monochrom> > foldr ($) a (repeat f) :: Expr
14:08:04 <lambdabot>   f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (...
14:08:09 <monochrom> hehe
14:08:21 <dons> ddarius: unpublished yet. diffusion limited aggregation
14:08:34 <monochrom> in .cabal/config what does "preference:" do?
14:08:49 <ddarius> dons: Is it just a demo program or was it actually made to do something?
14:08:52 <Taejo> > iterate f u
14:08:53 <lambdabot>   [u,f u,f (f u),f (f (f u)),f (f (f (f u))),f (f (f (f (f u)))),f (f (f (f (...
14:08:56 <milaz> ddarius: some fold-like operations (i mean programming folds, not those related to integration), and also something like element-wise summing of two surfaces of 3-dimensional array
14:09:05 <Taejo> ffffffffffu
14:09:15 <ddarius> @hackage repa
14:09:16 <lambdabot> http://hackage.haskell.org/package/repa
14:09:21 <aristid> > foldl (flip ($)) x (repeat f)
14:09:22 <dons> ddarius: oh, its a kernel that we're using for some experiments in using haskell for scientific programming. so a demo in that sense.
14:09:24 <ddarius> milaz: You may be interested in that package.
14:09:27 <lambdabot>   mueval: ExitFailure 1
14:09:57 <aristid> > foldl (flip ($)) x [f,f,f]
14:10:03 <lambdabot>   mueval-core: Time limit exceeded
14:10:07 <aristid> oO
14:10:10 <dons> ddarius: it generates these http://softology.com.au/gallery/dla3d02.jpg 
14:10:13 <monochrom> hrm that is strange!
14:10:15 <dons> etc.
14:10:17 <Taejo> > f f f u
14:10:18 <lambdabot>   Ambiguous type variable `a' in the constraints:
14:10:18 <lambdabot>    `SimpleReflect.FromExpr ...
14:10:26 <Taejo> > f f f u :: Expr
14:10:27 <lambdabot>   Ambiguous type variable `a' in the constraints:
14:10:27 <lambdabot>    `GHC.Show.Show a'
14:10:27 <lambdabot>      a...
14:10:50 <monochrom> > foldl (flip ($)) x [f,f,f] :: Expr
14:10:52 <lambdabot>   f (f (f x))
14:11:13 <Taejo> oh, I guess you'd need Expr = Expr -> Expr for (f f) to work
14:11:16 <monochrom> a different type was inferred with a different behaviour
14:11:26 <ddarius> dons: 3D then?
14:11:29 <ddarius> I've made 2D ones.
14:12:54 <aristid> :t f f :: Expr
14:12:57 <lambdabot>     Ambiguous type variable `a' in the constraints:
14:12:57 <lambdabot>       `Show a' arising from a use of `f' at <interactive>:1:0-2
14:12:57 <lambdabot>       `SimpleReflect.FromExpr a'
14:13:01 <aristid> hmm
14:13:16 <aristid> :t f (fromExpr f) :: Expr
14:13:17 <lambdabot> Not in scope: `fromExpr'
14:13:32 <mauke> > f (var "f") :: Expr
14:13:33 <lambdabot>   f f
14:13:35 <monochrom> "FromExpr" is a type class
14:13:47 <aristid> mauke: cheater!
14:13:56 <aristid> monochrom: and fromExpr is a funciton in that type class
14:13:58 <mauke> > var "f f"
14:14:00 <lambdabot>   f f
14:14:01 <monochrom> I see.
14:14:03 <mauke> no, that's cheating
14:14:04 <aristid> http://hackage.haskell.org/packages/archive/simple-reflect/0.2/doc/html/Debug-SimpleReflect-Expr.html#t%3AFromExpr
14:14:05 <benmachine> not exported, though
14:14:19 <monochrom> Perhaps someone deliberately hid it when importing.
14:14:34 <aristid> > fix ("f ("++)
14:14:35 <lambdabot>   "f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f ...
14:14:50 <aristid> > text $ take 100 $ fix ("f ("++)
14:14:51 <lambdabot>   f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (...
14:14:57 <benmachine> > intercalate " . " $ cycle "f"
14:14:58 <lambdabot>   Couldn't match expected type `[GHC.Types.Char]'
14:14:58 <lambdabot>         against inferred ty...
14:15:02 <benmachine> > intercalate " . " $ repeat "f"
14:15:03 <lambdabot>   "f . f . f . f . f . f . f . f . f . f . f . f . f . f . f . f . f . f . f ...
14:15:26 <arw> > print $ unlines ["foo", "bar", "baz"]
14:15:27 <lambdabot>   <IO ()>
14:15:45 <arw> > show $ unlines ["foo", "bar", "baz"]
14:15:46 <lambdabot>   "\"foo\\nbar\\nbaz\\n\""
14:16:20 <milaz> ddarius, dons: thanks, i'll look into this. It is noted that "You must use the GHC head branch > 6.13.20100309 to get decent performance". Will it work on ghc 6.12?
14:16:33 <ddarius> milaz: It should work, it just won't be as fast.
14:16:40 <CakeProphet> > x >> y
14:16:41 <lambdabot>   Couldn't match expected type `m a'
14:16:41 <lambdabot>         against inferred type `SimpleRef...
14:16:46 <CakeProphet> :)
14:16:52 <arw> somehow unlines and print doesn't do what i think it should. 
14:17:03 <aristid> arw: ?
14:17:09 <arw> i've got something like [[Char]] which i want to print.
14:17:17 <mauke> arw: print how?
14:17:20 <arw> each inner string on a single line
14:17:25 <Taejo> :t mfix
14:17:26 <lambdabot> forall a (m :: * -> *). (MonadFix m) => (a -> m a) -> m a
14:17:26 <mauke> putStr . unlines
14:17:46 <hpc> or (map putStrLn)
14:17:55 <mauke> did you mean: mapM_
14:18:04 <hpc> er, yes
14:18:06 * ddarius usually mapM_ putStrLn in those cases.
14:18:12 <hpc> :t map
14:18:13 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
14:18:19 <arw> mauke: thx, works.
14:18:54 <aristid> :t ((.).(.)) sequence map
14:18:55 <lambdabot> forall (m :: * -> *) a a1. (Monad m) => (a1 -> m a) -> [a1] -> m [a]
14:18:58 <arw> i guess print doesn't work because it first does 'show' on the string which escapes the newlines or something?
14:19:22 <ddarius> arw: Yes.
14:20:48 <CakeProphet> so how does one use StateT?
14:20:52 <CakeProphet> compared to State.
14:21:22 <Taejo> CakeProphet: very similarly
14:21:26 <Taejo> :t get
14:21:27 <lambdabot> forall (m :: * -> *) s. (MonadState s m) => m s
14:21:50 <CakeProphet> Taejo:  how do I use the internal monad?
14:21:56 <Taejo> :t lift
14:21:57 <lambdabot> forall (m :: * -> *) a (t :: (* -> *) -> * -> *). (MonadTrans t, Monad m) => m a -> t m a
14:22:06 <Taejo> CakeProphet: with lift
14:22:26 <ddarius> or if you are using methods in the Monad* class, e.g. get in MonadState, the lifting will be done for you in most cases.
14:22:56 <CakeProphet> Taejo:  so z <- lift $ getContents
14:23:14 <CakeProphet> Taejo:  in the case of StateT s IO a
14:23:18 <ddarius> CakeProphet: You should use liftIO for that.
14:24:01 <CakeProphet> what is the benefit there?
14:24:16 <ddarius> CakeProphet: If you stack on another monad transformer you don't need to change your code.
14:26:09 <monochrom> @hackage x
14:26:10 <lambdabot> http://hackage.haskell.org/package/x
14:26:52 <CakeProphet> ddarius:  ah. okay I see how it works. it recursively calls instance overloads of liftIO until it reaches IO itself
14:43:57 <duairc> Is there any way to print a warning message at compile time with Template Haskell?
14:47:32 <monochrom> I forgot the details but yes. Generally all IO is allowed in Template Haskell.
14:48:09 <duairc> Ah okay then, cool.
14:48:10 <monochrom> I used to joke about "use TH so it plays a movie while the compiler takes 2 hours to build stuff" :)
14:50:09 <duairc> :)
14:50:25 <duairc> Now I really want to do that!
14:52:48 <duairc> Ah, runIO is what I want
14:53:53 <soupdragon> :t runIO
14:53:54 <lambdabot> Not in scope: `runIO'
14:54:41 <duairc> It's in Language.Haskell.TH
15:02:56 <CakeProphet> will GHC warn you if two imported names conflict?
15:03:09 <ddarius> Possibly with -Wall.
15:03:22 <CakeProphet> alright
15:03:34 <Igloo> If you use the name it's an error
15:03:40 <Igloo> Otherwise, I don't think it can warn
15:05:32 <PetRat> problem with ghci reading .ghci file --- on Windows XP --- works on my desktop but notg my laptop --- I put .ghci in C:/Documents and Settings/Mike/ApplicationData/ghc -- on laptop ghci just igrnoes it -- any ideas?
15:06:30 <PetRat> The fact that there is a ghc directory within my application tree strongly suggests that ghci knows about it and should be looking there--the haskell-platform install put that ghc directory there
15:06:48 <PetRat> and there is no ghc directory under any other user
15:06:58 <tg_afk> PetRat: as per the unix convention, there might also be a directory called ".ghc" or ".ghci"
15:07:08 <tg_afk> if this follows the unix convention, it might be hidden
15:07:27 <CakeProphet> in XP . directories aren't hidden
15:08:30 <tg_afk> CakeProphet, but they can be hidden, correct?
15:08:37 <CakeProphet> yes.
15:08:43 <PetRat> yes I have setting to display all directories
15:08:45 <tg_afk> I don't know what they are done by the haskell installer
15:08:53 <PetRat> they can be hidden until you change the settings
15:08:59 <Saizan> PetRat: what is %AppData% on your laptop?
15:09:42 <tg_> where is .ghci supposed to go? above his 'ghc' directory?
15:10:08 <PetRat> %AppData% is c:\<doc & set>\Mike\<app data> --- same place that has a ghc subdir and where I am putting .ghci
15:10:29 <PetRat> confusing thing is works on desktop and I don't know of any diff in config
15:10:53 <chicom___master> find / -type f -iname "*ghc*"
15:12:21 <PetRat> chicom___master: I don't think that command is on windows
15:12:41 <PetRat> there is a "find" in windows (dos) but it is basically the same as grep
15:13:35 <monochrom> finding files doesn't solve the problem anyway.
15:14:11 <RichardBarrell> PetRat: out of curiosity, what does %APPDATA% expand to when you echo it in the shell?
15:14:12 <tg_> PetRat: did you use The Haskell Platform?
15:14:17 <PetRat> The GHCI manual suggests it might look in %HOME% --- I will investigate that
15:14:18 <tg_> ie, can I replicate this quickly? :o
15:14:23 <soupdragon> I don't understand discriminants
15:14:29 <tg_> soupdragon: nobody does
15:14:31 <PetRat> tg_: yes
15:14:32 * monochrom contemplates a O(n) solution: for each directory, try putting .ghci there, see if it is honoured :)
15:14:34 <RichardBarrell> Oh, ignore me, you've already tried that.
15:14:50 <tg_> while monochrom codes this
15:14:53 <RichardBarrell> monochrom: an excellent solution, but only on ReiserFS. :)
15:14:55 <soupdragon> really?
15:15:18 <tg_> soupdragon: Leonard Susskind doesn't get them.
15:15:38 <soupdragon> well I don't understand Leonard Susskind :P so maybe I have a chance at understanding discriminants
15:15:46 <tg_> haha.
15:15:49 <tg_> touche
15:16:01 <tg_> I do, and I still don't.
15:16:01 <soupdragon> weall I think it's more that I lack the background for quantum theory..
15:16:07 <soupdragon> anyway
15:16:08 <ddarius> monochrom: What if the directory doesn't exist?
15:16:26 <napping> the funny bit is how they can be computed efficiently - permanents seem to be very hard
15:16:40 <soupdragon> now I odn't even know what a permanent is !
15:16:43 <PetRat> GHCI manual says that it looks for .ghci : (1) first in currednt dir (2) second in %APPDATA% (3) third in %HOME%
15:17:08 <napping> sum over all the paths like in a determinant, but don't put on the alternating signs
15:17:12 <PetRat> in my case %HOME% is not defined ---and I am sure I am using same directory as %APPDATA%
15:17:23 <PetRat> oh well I will just use current dir
15:17:29 <napping> [a,b;c,d] -> a*d+b*c, etc
15:17:29 <soupdragon> ahar
15:17:40 <monochrom> perhaps try defining OME%
15:18:34 <monochrom> %HOME%
15:18:37 <tg_> napping: but why
15:18:40 <soupdragon> \begin{equation} \dn(s_1,s_2,\ldots,s_n) = \prod_{i=1}^n \prod_{j=i+1}^n (x_i-x_j)^2, \end{equation}
15:18:56 <tg_> why use either?
15:18:57 <Saizan> PetRat: try  %APPDATA% rather than  %APPDATA%\ghc
15:19:11 <tg_> Saizan: I suggesthed that, for the record.
15:19:25 <tg_> how did... a ... an h get in there?
15:19:31 <PetRat> ok defining HOME works !!!
15:19:38 <tg_> excellent
15:19:39 <ddarius> Discriminant /= determinant
15:19:48 <PetRat> this is a perfectly usable soluation, thanks
15:20:14 <PetRat> maybe HOME is defined already on my desktop
15:20:15 <soupdragon> "The discriminant vanishes if and only if p   has multiple roots" <--- what the hell?
15:20:26 <soupdragon> quadratics with positive discriminant have two roots
15:21:00 <CakeProphet> is there a mutable hash table data structure in Haskell?
15:21:09 <PetRat> question about i/o --- is there a way to read a character from stdin without waiting for <return>?
15:21:21 <mauke> CakeProphet: yes
15:21:32 <monochrom> use setBuffering to turn off buffering
15:21:40 <monoidal> getChar
15:21:40 <arw> PetRat: getChar
15:21:41 <CakeProphet> setBuffering None  I think?
15:21:44 <CakeProphet> and then getChar
15:21:47 <napping> mauke: is it worth using?
15:21:50 <ddarius> soupdragon: The discriminant is equal to the product of the square of the difference of each pair of roots.  So if a root has multiplicity > 1 then you'll get a 0.
15:21:53 <mauke> napping: no
15:22:08 <roconnor> soupdragon: by multiple roots they mean repeated roots ... hopefully
15:22:09 <napping> CakeProphet: Data.HashTable has been slower than Map
15:22:21 <soupdragon> oh I see
15:22:22 <monoidal> hSetBuffering stdout NoBuffering
15:22:24 <PetRat> what module has setBuffering?
15:22:24 <monochrom> System.IO.hSetBuffering. set it to NoBuffering for stdin
15:22:27 <soupdragon> that's new to me
15:22:31 <CakeProphet> napping:  oh really? How does it scale compared to Map?
15:22:35 <PetRat> System.IO
15:22:45 <napping> I think someone did some benchmarks recently
15:22:52 <napping> there might be another module that has one that works better?
15:23:03 <napping> or maybe there were some GC fixes for large array handling?
15:23:26 <ddarius> In some scenarios Data.HashTable wins, but Map wins in others and is much more convenient and flexible.
15:23:54 <roconnor> soupdragon: I admit is it a bit of a stretch of an interpretation
15:24:11 <soupdragon> so if the roots are complex (not real) then the (real) discriminant will be negative
15:24:30 <roconnor> soupdragon: are the coefficents real?
15:24:34 <soupdragon> yes
15:24:38 <roconnor> then yes
15:24:54 <ddarius> soupdragon: The square of a real number is always positive and the product of positive numbers is positive.
15:26:19 <monochrom> perhaps consider http://hackage.haskell.org/package/hashmap
15:27:54 <CakeProphet> a hash table should have O(1) lookup. So I can't see how Data.Map is faster than a mutable hash table unless the implementations of hash tables are just really bad.
15:27:56 <monochrom> this also helps: http://hackage.haskell.org/package/judy
15:28:07 <mauke> CakeProphet: O(1) does not mean fast
15:28:31 <monochrom> don't be dogmatic about hash tables.
15:28:43 <napping> I think there were some issues with GC time also
15:28:46 <djahandarie> monochrom, who are you talking to? ;-)
15:28:47 <CakeProphet> I'm not
15:28:53 <monochrom> everyone
15:28:57 * djahandarie agrees
15:28:59 <CakeProphet> and yes O(1) doesn't mean fast. But it means it scales perfectly.
15:29:06 <RichardBarrell> Data.Hashtable is a bit old and has surprisingly bad constant factors.
15:29:17 <napping> In particular, if you mutate a value that's in the old generation you need to rescan what it points to now
15:29:38 <roconnor> how do you hash arbitrary data in O(1) time?
15:29:51 <monochrom> methinks the two packages I suggested are fast. since no one is proving anything by hard data anyway.
15:29:53 <RichardBarrell> If you want fast maps in Haskell, Data.Map is very fast for small sets.
15:29:55 <ddarius> roconnor: The same way you multiply numbers in O(1) time.
15:30:08 <CakeProphet> I don't think I'll be dealing with small sets though.
15:30:12 <CakeProphet> which is why I want a mutable hash table.
15:30:25 <RichardBarrell> For large sets, I would suggest uh, trying to remember the name.
15:30:34 <napping> I think for quite a long time, if you mutated an array it would rescan *all* the array
15:30:34 <RichardBarrell> Julia Arrays?
15:30:34 <monochrom> also to scare you about hash tables: http://enfranchisedmind.com/blog/posts/problems-with-hash-tables/
15:30:41 <napping> so actually O(n) insert
15:30:51 <ddarius> RichardBarrell: You are probably thinking of Judy trees which monochrom mentioned above.
15:31:03 <RichardBarrell> Ah yes, thank you.
15:31:27 <eflister> i have: (j :: [c] -> c) <$> (mapM ((h :: c -> c) . (g :: b -> c) . (f :: a -> b)) =<< m [a]).  i think f, g, h, and j could all run in parallel.  how do i set that up?
15:31:30 <monochrom> Data.IntMap and most things based on Data.IntMap are fast.
15:31:41 * napping observes the memory hierarchy
15:31:45 <monochrom> Data.IntMap uses a more optimized technique than Data.Map
15:32:01 <napping> factor of a million speedup from blocking a simple matrix multiply 
15:32:15 <monoidal> http://stackoverflow.com/questions/3058529/ on the hashtable problem
15:32:18 <RichardBarrell> CakeProphet: if you don't mind the fact that you can't really use them in pure code, Judy trees are really scarily fast.
15:33:01 <CakeProphet> RichardBarrell:  I am considering mutable hash tables. So, no, I don't mind that at all.
15:33:05 <RichardBarrell> http://hackage.haskell.org/package/judy
15:33:46 <CakeProphet> my use case here is a standard set of string-value pairs. A mutable namespace.
15:34:06 <eflister> why don't lazy Bytestrings have isInfixOf?
15:34:07 <CakeProphet> so I don't think I'll need to resize often, as N will, generally, remain fairly fixed.
15:34:38 <CakeProphet> I just want fast amortized lookup and insert
15:34:40 <napping> um, why?
15:34:45 <napping> then don't index by strings!
15:35:02 <napping> or at least not by String
15:35:05 <CakeProphet> napping:  what would you suggest I do other wise. The names have semantic importance.
15:35:20 <napping> for the love of alpha-equivalence, why?
15:35:27 <napping> Data.Unique is nice
15:35:28 <CakeProphet> napping:  and the names can be arbitrary. I think that calls for Strings unless I use some kind of interning scheme.
15:35:46 <monochrom> (how long are the strings?)
15:35:50 <CakeProphet> short. words
15:35:58 <CakeProphet> variable names, more or less. but not for a programming language.
15:35:59 <tg_> the keys and the values are?
15:36:08 <napping> even so, String = linked list of boxed unicode chars
15:36:42 <monochrom> hashing short strings is still barely tolerable, I'll grant that.
15:36:44 <napping> so, stop worrying about efficiency
15:37:24 <RichardBarrell> ByteString or Data.Text would be better as both are packed formats.
15:38:02 <PetRat> My program to read stdin with no buffering isn't working. sitll needs a <return>  http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27106#a27106
15:38:04 <CakeProphet> Unique looks somewhat promising.
15:38:43 <aristid> PetRat: the operating system might insist on the <return>.
15:39:05 <napping> also, if you don't need multiple environments you might consider making a map from identifiers to IORef's to be applied once
15:39:21 <ddarius> If the data is short strings then a trie would have a low complexity for your case and it would fit the data well.
15:39:28 <PetRat> aristid: I recall reading that Windows is kind of fussy about non-buffered input. In Python, doc says it is unreliable
15:39:36 <CakeProphet> napping:  there will be multiple environments. But it's a concurrent design, thus each process will generally have access to only one such environment.
15:39:39 <monoidal> PetRat: works for me (ubuntu 10.04)
15:40:04 <PetRat> monoidal: that is evidence that Windows is the culprit
15:41:41 <aristid> works for me too (ubuntu 10.04)
15:42:27 <monoidal> http://hackage.haskell.org/trac/ghc/ticket/2189
15:42:28 <CakeProphet> PetRat:  solution, stop using windows. :P
15:42:46 <monochrom> easier said than done
15:42:48 <PetRat> CakeProphet: definitely an ideal solution. unfortunately not a practical one.
15:42:57 <CakeProphet> of course. :D
15:43:11 <PetRat> CakeProphet: sorry I didn't see the :P
15:43:20 <monochrom> use MacOS. best of both worlds. :)
15:43:27 <monoidal> seems it is sheduled for 6.14.1, you can do ugly OS call instead
15:43:49 <PetRat> Is Prelude going away in a future version of GHC?
15:43:59 <monochrom> I think not.
15:44:03 <benmachine> it can be disabled though
15:44:10 <soupdragon> tbh I prefer ubuntu to mac os
15:44:10 <CakeProphet> I'm not quite sure why mapM_ putChar is used instead of putStr
15:44:13 <monoidal> -XNoImplicitPrelude, or import Prelude ()
15:44:17 <soupdragon> just can't get the bloody thing to install
15:44:33 <soupdragon> so im stucking running it in a VM and it takes half my RAM
15:44:37 <soupdragon> stuck*
15:45:15 <monoidal> PetRat: have you tried the linked workaround?
15:45:16 <CakeProphet> @src putStr
15:45:16 <lambdabot> putStr s  = hPutStr stdout s
15:45:23 <CakeProphet> @src hPutStr
15:45:23 <lambdabot> Source not found. Just what do you think you're doing Dave?
15:45:38 <CakeProphet> @src System.IO.hPutStr
15:45:38 <lambdabot> Source not found. I feel much better now.
15:45:48 <monochrom> don't trust @src. pedagogical only.
15:46:22 <monochrom> in GHC's lib putStr etc are quite a bit more complicated
15:46:50 <djahandarie> I'd really like to know why hackage.haskell.org is constantly choking on something
15:46:55 <monoidal> somehow I always want to know source of used functions much more in haskell than in other languages
15:46:58 <napping> CakeProphet: do you ever need to take one string and look it up in several environments?
15:47:08 <monoidal> i love equational reasoning
15:47:20 <napping> if not, you might tie the knot ahead of time and avoid lookups entirely
15:47:29 <djahandarie> lispy, do you know what's up with the galois server?
15:47:34 <CakeProphet> okay so the keys to my string-indexed map will come from socket data. Is there a way to read in socket data as a ByteString or Text instead of String?
15:48:03 <monoidal> PetRat: nevermind, seems that workaround is buggy
15:48:18 <monochrom> Yes! Both ByteString and Text have hGetBlahblah functions too.
15:48:24 <CakeProphet> napping:  not in the most basic implementation. That might be a feature at some point. I plan on using message passing to read/write to different environments. They're kind of like concurrent tables.
15:48:42 <CakeProphet> monochrom:  then I might use ByteString instead of String. I won't be using Unicode anyways (I think?)
15:49:06 <napping> sending open terms between environments? ew
15:49:39 <CakeProphet> it is necessary.
15:49:53 <CakeProphet> well, not between environments
15:50:06 <CakeProphet> between processes, I guess.
15:50:27 <CakeProphet> in most cases it will be simple lookup/read.
15:51:34 <CakeProphet> so can someone explain the disadvantages of using ByteString compared to String? Where is it bad?
15:51:53 <aavogt> which ByteString?
15:51:59 <napping> String is simpler as a data structure
15:52:00 <aavogt> (strict or lazy)
15:52:01 <CakeProphet> oh uh....
15:52:09 <napping> it's easier to pattern match and work Char by Char and stuff
15:52:10 <CakeProphet> Data.ByteString, I guess. 
15:52:21 <CakeProphet> oh, what about Parsec?
15:52:25 <CakeProphet> can I use them with Parsec?
15:52:44 <napping> Maybe Parsec3 can handle ByteStrings?
15:52:46 <napping> not earlier versions
15:52:50 <aavogt> Data.ByteString is strict (I'm pretty sure)
15:52:50 <monochrom> Yes, make sure you select Parsec version 3 for ByteString support.
15:53:28 <CakeProphet> How can I tell what Parsec I currently support? Doesn't it come in the std lib? What version is that?
15:53:58 <aavogt> CakeProphet: so if you compute a very long ByteString and use it once, you won't be able to generate it as needed
15:54:03 <CakeProphet> Glasgow Haskell Compiler, Version 6.10.1, for Haskell 98, stage 2 booted by GHC version 6.6
15:54:03 <RichardBarrell> napping: Parsec2 works fine with lists of any tokens.
15:54:16 <napping> which ByteString is not
15:54:37 <RichardBarrell> napping: you could use it with ByteString and the `unpack` function from Data.ByteString.Internal.
15:54:42 <napping> well, ok
15:54:50 <monochrom> ByteString is a list of 64KB chunks or thereabouts. Whenever you do substringing, it's a pair of indexes (begin, end) internally. From this you can derive what ByteString is good or bad for.
15:55:10 <napping> Lazy bytestring, that is
15:55:13 <CakeProphet> hmmm. Perhaps I will simply use String and be done with it. If I encounter horrible time lags (I don't think it will matter...) then I will optimize at that point.
15:55:15 <RichardBarrell> CakeProphet: ignore all of this, write the slow version using Data.Map and String, *then* optimise it using faster libraries. You'll have more fun that way anyway.
15:55:31 <RichardBarrell> CakeProphet: that's the spirit! :)
15:56:03 <aavogt> monochrom: I think you're confusing http://hackage.haskell.org/packages/archive/bytestring/0.9.1.7/doc/html/src/Data-ByteString-Internal.html#ByteString  with http://hackage.haskell.org/packages/archive/bytestring/0.9.1.7/doc/html/src/Data-ByteString-Lazy-Internal.html#ByteString
15:56:07 <napping> for an interpreter you will probably do better by avoiding lookups entirely at runtime anyway
15:56:16 <soupdragon> a conic can be represented as a polynomial or a matrix equation - the determinant of the first equals the discriminant of the second
15:56:48 <aavogt> but nobody knows which ByteStringS we're actually comparing (because we don't know the use-case)
15:56:56 <CakeProphet> napping:  like I said it's not actually a programming language interpreter. It's something akin to a multi-user concurrent command line. I am making an online text-based game. :)
15:57:09 <CakeProphet> so I don't really know why I'm worried about efficiency at this point
15:57:25 <napping> an you are worried about performance dealing with human input?
15:57:32 <napping> how many millions of concurrent users do you have?
15:57:36 <CakeProphet> not worried. Merely considering the best option.
15:57:37 <BMeph> Is anyone else here amused that folks now call the use style of colons for cons and types "Haskell style", vice "Miranda style"?
15:57:43 <CakeProphet> napping:  at the moment zero. :)
15:57:47 <RichardBarrell> CakeProphet: I was once told (cannot remember by whom) that most MUDs spend a truly shocking amount of CPU time inside of sprintf() :)
15:58:00 <napping> BMeph: wasn't that style invented for Haskell?
15:58:12 <napping> oh, and shouldn't that be Miranda(TM) style?
15:58:35 <aristid> RichardBarrell: a SHOCKING amount of time?
15:58:36 <CakeProphet> RichardBarrell:  having worked on an old C codebase for a MUD, that doesn't surprise me at all.
15:59:05 <RichardBarrell> BMeph: no more so than how people refer to mutable pass-everything-by-value with first-class pointers as "C-style semantics" rather than "BCPL-style semantics"? :)
15:59:33 <RichardBarrell> aristid: indeed, truly uncivilised. It'd make your monocle fall right out of your head if you heard the details.
15:59:49 <napping> wasn't BCPL mostly untyped?
15:59:49 <aristid> *gasp*
15:59:54 * wli was under the impression MUD's weren't CPU-bound.
16:00:06 <monochrom> perhaps sprintf is turing-complete and MUD programmers really use that.
16:00:21 <CakeProphet> wli:  you are most likely correct. Perhaps I should be more concerned with memory consumption.
16:00:32 <tg_> RB: I had a hearty guffaw at that quip, sir.
16:00:38 * monochrom spreads rumour: I heard c++ programs spend 99% cpu time at compile time...
16:01:02 <RichardBarrell> CakeProphet: don't be, yet. Memory consumption will (IMO, in most programs) be easier to profile for and fix in Haskell than CPU speed would.
16:01:13 <aristid> monochrom: sounds accurate
16:01:14 <wli> CakeProphet: Or maybe the critical issue is external algorithms to avoid being IO-bound.
16:01:16 <RichardBarrell> wli: probably you are right, but I wouldn't be surprised if nearly all of the CPU time that they *do* spend goes on sprintf. :)
16:01:28 <CakeProphet> RichardBarrell:  then what should I be concerned with? Good design? That's a new idea.
16:01:45 <cheater99> is it possible to have a set with O(1) complexity?
16:01:54 <cheater99> for the lookup that is
16:02:04 <wli> CakeProphet: Though they're probably more latency-oriented than anything.
16:02:09 <benmachine> doesn't sound likely
16:02:15 <benmachine> unless it's a set containing everything
16:02:23 <cheater99> that's what i was thinking
16:02:23 <RichardBarrell> cheater99: no because you can only fit O(d^3) sticks of RAM within `d` centimetres of the CPU. :)
16:02:24 <napping> cheater99: for some very limited sorts of sets. union-find for example
16:02:31 <BMeph> napping: Good call about the "tramp stamp"; to Whom it May Concern: I meant no abuse of IP - Miranda™
16:02:42 <cheater99> what's union-find?
16:02:46 <aavogt> suppose you may only have a finite number of elements
16:02:58 <napping> RichardBarrell: I believe it's in fact O(d) if you want to avoid making black holes
16:03:21 <monochrom> union-find is http://en.wikipedia.org/wiki/Union-find
16:03:27 <CakeProphet> RichardBarrell:  also, at what point does the size of Map become "big" exactly? I think I can expect anywhere from 20-40 keys per map.
16:03:35 <RichardBarrell> CakeProphet: most of these switch-from-library-A-to-library-B things can, in Haskell, basically be done by making the switch in *one* place, trying to compile, making the switch in the first place that GHC tells you it finds a mismatch, and so on recursively. :)
16:03:37 <monochrom> summary: great way to manage equivalence classes
16:03:43 <RichardBarrell> Oh, 20-40 is tiny.
16:03:48 <tg_> what is the complexity of a set without more information than that?
16:03:55 <benmachine> napping: volume of a sphere radius d, surely
16:04:12 <RichardBarrell> Dons had some numbers for the Judy arrays library, where he benchmarked the crossover point where Judy becomes faster than Data.Map.
16:04:13 <CakeProphet> RichardBarrell:  well that is comforting. 
16:04:21 <napping> benmachine: ah, but the Schwartzchild radius is linear in mass. Don't remember what rotations do
16:04:36 <napping> benmachine: if we're talking asymptotics :)
16:04:40 <benmachine> hmmmm
16:05:11 <BMeph> Can we have an IntMap specialized to Int64, please? :)
16:05:12 <benmachine> linear in mass?
16:05:19 <benmachine> but mass is O(d^3) surely
16:05:21 <RichardBarrell> CakeProphet: Data.Map implements balanced binary trees, so 40 items is still ~6-7 branches at worst. :)
16:05:23 <tg_> napping: rotations aren't correct, so it doesn't matter
16:05:26 <monochrom> there is some holographic limit saying you don't really get all of d^3, you only get d^2
16:05:40 <benmachine> it's not linear in radius so it's fine
16:06:19 <CakeProphet> RichardBarrell:  that's not bad, right? When should I be concerned?
16:06:38 <CakeProphet> RichardBarrell:  also, the keys are going to be Strings.
16:06:48 <tg_> oh well that does it
16:07:53 <cheater99> monochrom: thanks a lot
16:07:59 <RichardBarrell> CakeProphet: eh, measure. Don't be concerned unless you're either optimising just for the sport of it, or the program is actually slow enough to inconvenience you. :)
16:08:34 <napping> monochrom: ah, that's right. Apparently you can store more bits per unit mass in more space. Guess that makes sense
16:08:52 <CakeProphet> RichardBarrell:  lazily evaluate my need for optimization? :P  I think at this point I /am/ just optimizing for sport.
16:09:00 <tg_> napping: why do you think tha makes sense intuitively?
16:09:17 <tg_> as a physicist, I'm curious :o
16:09:27 <lispy> djahandarie: what galois server?
16:09:43 <djahandarie> abbot.galois.com
16:09:45 <djahandarie> The hackage one
16:10:24 <RichardBarrell> CakeProphet: well, there's a fast library for almost anything that you can think of somewhere on Hackage. :)
16:11:32 <napping> tg_: well, you've got position, lower frequencies available, that sort of thing
16:11:41 <lispy> djahandarie: I haven't heard anything.  What's wrong?
16:11:47 <napping> tg_: not that it's necessarily intuitive that it should be linear, but that you get a bit more
16:11:50 <CakeProphet> RichardBarrell:  can you point me in the direction of a fast protein folding library. :)
16:12:05 <RichardBarrell> CakeProphet: why yes, I can.
16:12:09 <lispy> djahandarie: I just ran 'cabal update'
16:12:19 <CakeProphet> RichardBarrell:  ha, oh... nevermind then.
16:12:22 <lispy> djahandarie: I didn't have any problems from inside the galois network
16:12:30 <RichardBarrell> CakeProphet: You use System.Process to fire up wget and you download folding@home and you run that. :D
16:12:37 <CakeProphet> hahaha.
16:12:52 <CakeProphet> oh wow, it's even distributed!
16:13:03 <djahandarie> lispy, hackage has been choking all day for me, from two different locations (in the same state though)
16:13:37 <RichardBarrell> Just mind that you might write yourself into a corner. If you plan to try Judy arrays later then you probably want to use IORef Data.Map now, instead of plain Data.Map, so that you don't accidentally end up relying on the fact that Data.Map is persistent. :)
16:14:39 <CakeProphet> RichardBarrell:  if I don't use IORef it will very likely be a similar type. TVars?
16:15:08 <RichardBarrell> You can't really use an IO-only data mapping inside a transactional variable either...
16:15:14 <CakeProphet> or perhaps my map should have Tvar values...
16:15:43 <CakeProphet> a Tvar of a Map of Tvar values?  o_o
16:15:50 <CakeProphet> :)
16:16:03 <djahandarie> lispy, galois.com responds quickly, if that helps
16:16:04 <napping> that wouldn't help, if you want to be able to switch to a map in IO
16:16:10 <napping> the outer var would have to be IORef
16:16:31 <lispy> djahandarie: I'm not sure what to say :)
16:16:38 <djahandarie> Okay
16:16:41 <djahandarie> Hopefully it's just me
16:16:55 <lispy> yeah, it's working here but maybe that's not entirely fair...
16:17:42 <CakeProphet> napping:  hmmm, ah okay. Then perhaps IORef is the way to go. I'm still figuring out which of all these various container types I need to be using anyways, so none of that has been implemented yet.
16:18:27 <nolrai> @hoogle second
16:18:27 <lambdabot> Control.Arrow second :: Arrow a => a b c -> a (d, b) (d, c)
16:18:28 <lambdabot> Data.Time.Clock secondsToDiffTime :: Integer -> DiffTime
16:18:28 <lambdabot> Data.Time.Clock.TAI type LeapSecondTable = Day -> Integer
16:18:36 <monadic_kid> "I think Haskell's type classes don't compare quite favorably with D's constrained templates. Haskell's facility is nicely principled but is rigid, verbose, and difficult to use, in addition of being quite underpowered: type classes constrain one type, whereas D's constrained templates naturally allow establishing constraints involving several types and also values.
16:18:36 <monadic_kid> Haskell does allow constraints on multiple types, but it's quite an advanced trick, as mentioned by a paper I just reviewed for WGP 2010."
16:18:37 <benmachine> time cabal update says 22.7 seconds
16:18:40 * benmachine wonders if that's normal
16:18:44 <monadic_kid> http://www.reddit.com/r/programming/comments/cmn67/c_concepts_a_postmortem/c0tpl2v
16:19:25 <monadic_kid> He doesn't clearly understand type constraints
16:20:48 <tg_> conal?
16:21:11 <mreh> preflex: seen conal
16:21:11 <preflex>  conal was last seen on #haskell 4 hours, 13 minutes and 53 seconds ago, saying: is there a way to list hackage packages for a specified maintainer, without getting multiple versions of the same package?  i'd like just the latest versions.
16:21:38 <mreh> favourtism ay?
16:21:44 <conal> yo
16:21:58 <mreh> someone was looking for you
16:22:05 <mreh> someone called tg_
16:22:06 <tg_> -> pm
16:22:19 <conal> mreh: thx.  i think it's technoguy
16:22:29 <tg_> conal: indeed
16:22:49 <mreh> I thought you said "technology"
16:23:15 <danharaj> Question: Why is cabal saying "construct not supported at this position" about "include-dirs"? Am I putting it in the wrong part of .cabal?
16:24:33 <mreh> danharaj: are you wanting to add extra source files?
16:25:19 <danharaj> mreh: I am trying to install SDL on WIN32. The readme says I have to modify the .cabal file by adding "Include-Dirs: C:\blahblah\SDLStuff\include" at the end of the file.
16:25:35 <danharaj> I then try runghc Setup.lhs configure, and I get the aforementioned error.
16:25:36 <BMeph> monadic_kid: Fess up - was that a jdh30 quote? ;)
16:25:57 <napping> monadic_kid: It sounds like he is talking about multiple-parameter type classes
16:26:00 <mreh> danharaj, always a good place to start with the cabal docs
16:26:09 <mreh> I've got a copy installed :D
16:26:28 <monadic_kid> napping: he was, getting mixed up with multiple type constraints
16:26:41 <mreh> danharaj, is it whitespace?
16:27:03 <mreh> it goes under the "library" or "executable" headings I do believe
16:27:27 <monadic_kid> napping: trying to say they are "quite underpowered" is ridiculous
16:27:32 <danharaj> by god I think that was it
16:27:39 <mreh> \o/
16:27:41 <danharaj> So great, the sdl documentation just flat out lied to me.
16:27:42 <danharaj> FFFFFFF
16:27:51 <mreh> send a patch
16:27:55 <monadic_kid> BMeph: no just some D programmer
16:28:01 <danharaj> mreh: never >:|
16:28:39 <danharaj> now I just have to figure out if I should use Windows style or Unix style directories, because I'm using MSYS
16:29:14 <mreh> check out this confusing type-fu: (switch identity (const (arr fst)))
16:29:28 <mreh> switch :: SF a (b, Event c) -> (c -> SF a b) -> SF a b
16:29:35 <mreh> how they fit together I don't know
16:29:42 <mreh> my brane tells me b = (Event c, b)
16:29:48 <mreh> which is unpossible
16:30:18 <mreh> identity has type :: SF a a
16:31:10 <mreh> oh wait, I has it!
16:32:06 <napping> monadic_kid: well, D does have proper compile time evaluation
16:32:31 <napping> not as pretty as dependent types, but type class junk is an ugly hack compared to either
16:33:28 <monadic_kid> napping: Template Haskell for meta-programming and type families for type computations
16:34:33 <dibblego> @type MaybeT
16:34:34 <lambdabot> Not in scope: data constructor `MaybeT'
16:35:53 <danharaj> Ok. So I have done all that the all mighty readme demands, and the build script still cannot detect SDL
16:36:00 <danharaj> BAH I SAY. BAH.
16:36:03 <napping> Template Haskell doesn't really help with many sorts of things
16:36:26 <napping> BMeph: alexandrescu did STL
16:36:30 <eflister> why don't lazy Bytestrings have isInfixOf?
16:36:55 <BMeph> napping Was he involved with C++'s STL, or just D's?
16:37:12 <BMeph> s/g/g:/
16:37:27 <napping> It's the same Alex Alexandrescu, no?
16:37:37 <monadic_kid> he didn't invent STL
16:38:06 <PetRat> monoidal: I was away but just wanted to appreciate your additional investigation of hPutStr. By the way, I want input. I don't know if that changes things.
16:38:24 <napping> ah, that was Stepanov. different guy then
16:38:41 <PetRat> hmm monoidal hasn't typed in a bit
16:39:10 <monadic_kid> Alexander Stepanov was behind STL and he started his work in Ada Generics before moving to C++
16:39:41 <pizza_> nobody's perfect
16:39:50 <chicom___master> ept me
16:39:53 <eflister> can anyone answer my question about why lazy Bytestrings don't have isInfixOf?
16:40:31 <ezyang> eflister: It sounds like taht function would encourage sloppy style 
16:40:43 <ezyang> isInfixOf would require traversing the entire lazy bytestring in the worst case. 
16:41:25 <eflister> ezyang: yeah, worst case, but why not just indicate that in some documentation?
16:41:57 <ezyang> ...because you really should be using a strict bytestring anyhoo? 
16:42:18 <eflister> ezyang: it has other functions that would cause it all to evaluate
16:43:07 <PatrioticNigra> !calc 2.2*150
16:43:14 <PatrioticNigra> /calc 2.2*160
16:45:38 <soupdragon> I'm struggling to understand the equation Ax^2+Bxy+Cy^2=D
16:46:19 <danharaj> I think Stepanov actually started very early in ML
16:48:11 <lispy> soupdragon: Is that an equation or a crazy emoticon?
16:48:26 <soupdragon> yeah it's someone wearing a totem pole
16:48:31 <hpc> lispy: yes
16:49:26 <lispy> hpc: ah sum types...
16:49:51 <RichardBarrell> soupdragon: it's the expansion of (ax+by)(cx+dy)=D for some a,b,c,d.
16:50:00 <lispy> data Soupdragon = Equation | TotemPole
16:50:25 <soupdragon> it SEEMS like there are two zeros on the x axis iff there are two zeros on the y axis -- but that goes against my understand of the shapes it defiens
16:51:41 <soupdragon> oh I'm silly
16:54:17 <PetRat> eflister: this is Michael Mossey. thanks so much for sharing your code
16:54:40 <PetRat> (the music code)
16:54:59 <BMeph> Ooh...I think we just had another quake in SoCal...
16:55:05 <danharaj> is there a command to cabal that makes it list installed packages on a machine?
16:56:02 <Zao> ghc-pkg list ?
16:56:26 <danharaj> Zao: Is that the same as cabal'd packages?
16:56:38 <danharaj> Yes it is.
16:56:39 <danharaj> Thanks.
16:56:41 * cads wishes he knew more about polynomials of more than one variable
16:56:54 <Zao> danharaj: Note that there's two sets of packages, one global and one user.
16:57:07 <danharaj> Is there a way to uninstall packages?
16:57:18 <soupdragon> cads: do you know the GCD algorithm?
16:57:31 <soupdragon> of Euclid
16:57:32 <cads> for integers
16:57:33 <Zao> danharaj: There's two meanings of 'cabal'. One is the Cabal library which is about package descriptions, tasks and stuff.
16:57:34 <soupdragon> yes
16:57:46 <danharaj> Zao: And cabal install, yes?
16:57:52 <Zao> The other one is cabal-install, which has the `cabal' tool with which you can download and install packages.
16:58:18 <soupdragon> cads: this is a good problem: try to solve this equation (find a pair of values of x and y which satisfy it): ax + by = (a,b)
16:58:20 <benmachine> danharaj: wrt uninstalling packages, there is no convenient command to delete all files associated with a package
16:58:26 <Zao> Deletion of packages is typically done by invoking unregister with ghc-pkg and deleting the directories yourself, I believe.
16:58:30 <benmachine> however you can easily tell GHC to "forget" a package exists
16:58:35 <soupdragon> I wrote a haskell program that finds the numbers 
16:58:35 <danharaj> :|
16:58:58 <benmachine> or, less drastically, you can tell GHC to hide a package from normal use
17:00:44 <cads> soupdragon: it seems like the solution is easy: x = (1,0), y = (0,1)
17:01:04 <soupdragon> cads, it's supposed to be in integers sorry 
17:01:47 <cads> shouldn't it be ax + by = 0, then? Otherwise we're trying to find a sum of integers which should equal a vector
17:02:14 <soupdragon> cads, for example  it could be  3x + 6y = 2
17:02:16 <hpc> unless it is ai + bj
17:02:20 <soupdragon> and you have to find x and y
17:02:30 <soupdragon> umm
17:02:34 <hpc> where i and j are unit vectors
17:02:35 <soupdragon> > gcd 3 6
17:02:36 <lambdabot>   3
17:02:38 <soupdragon> sorry
17:02:43 <soupdragon> it could be  3x + 6y = 3
17:03:00 <cads> oh.. is (a,b) the same as gcd(a,b)?
17:03:03 <soupdragon> yeah
17:03:18 <cads> okay that's itneresting
17:03:20 <soupdragon> I really shouldn't perpetuate the bad notations people show me ...
17:03:22 <c_wraith> cads, that's typical Number Theory convention for gcd.
17:03:40 <blackdog_> so, anyone read the Haskell 2010 report in depth? a cursory look seems to be just canonising some of the GHC extensions
17:03:52 <cads> c_wraith: yeah, that gets me every once in a while
17:05:19 <_linuxftw> Hi, I just started haskell today and i've written this: http://pastebin.com/fNHV3mgw, problem is it's an infinite loop and I don't know how to tell it to only use part of the list rather than evaluating the full one
17:06:24 <ezyang> _linuxftw: You need more base cases 
17:06:35 <Zao> (note that a monotically increasing sequence can be written [a,b..c] (where the difference between a and b is the step)
17:06:37 <ezyang> maybe. 
17:07:01 <_linuxftw> ezyang: for which function?
17:07:07 <ezyang> isPrime 
17:07:08 <Zao> > [3,5..14]
17:07:09 <lambdabot>   [3,5,7,9,11,13]
17:07:11 <ezyang> Actually, not quite base case 
17:07:22 <Zao> > [3..14]
17:07:23 <lambdabot>   [3,4,5,6,7,8,9,10,11,12,13,14]
17:07:24 <ezyang> You need to stop consuming the list when the numbers are bigger than yours. 
17:07:55 <Zao> ezyang: Or tighter, bigger than your square root.
17:07:56 <ezyang> but that won't quite fix it either. 
17:08:01 <ezyang> Zao: Yeah. 
17:08:13 <Zao> (but that's an optimization, anyway)
17:08:16 <cads> soupdragon: for any a,b in Z there is x, y in Z such that ax + by = gcd(a,b), which is a theorem I know in relation to the euclidean algorithm. But I don't have a proof handy.
17:08:19 <_linuxftw> isPrime a p = if (head p) > a then False?
17:08:35 <cads> But it seems like it would be easy to construct x and y from the way the euclidean algorithm works
17:08:49 <cads> soupdragon: neat problem, I'll try it out
17:08:50 <Zao> (why is it saying my Int are not Floating a instances, lol)
17:08:52 <soupdragon> cads yes exactly :) you use the euclidean algorithm to produce a new algorithkm
17:08:53 <ezyang> That won't work, because by your code you'll never have gotten to a value bigger than yours until you've figured out if it's prime. 
17:09:08 <ezyang> I'm trying to figure out what the conceptual problem is. 
17:09:10 <soupdragon> cads - infact there are quite a few problems which one can modify the euclidean algorithm to find solutions for
17:09:28 <theorbtwo> cads: That's pretty much just the definition of divisor, isn't it?
17:09:43 <soupdragon> (the other one I know only counts as a single variable problem though)
17:09:45 <ezyang> I know: You need a notion of "primes which are smaller than the number I'm testing", which is not given by an "infinite list of all primes" 
17:09:57 <_linuxftw> ahh right
17:10:00 <ezyang> or, more precisely, you can't generate the latter with the former 
17:10:13 <cads> hmm
17:10:14 <ezyang> erm, you can't generate the latter using itself 
17:10:46 <ezyang> If you had a list of all primes that /worked/, this would work, but as such it doesn't. 
17:10:58 <ezyang> And this would be kind of pointless anyway, seeing as you have the list :^) 
17:11:03 <BMeph> _linuxftw: if (head p) > a then True ; theoretically, your list of primes should be empty by then. :)
17:11:14 <BMeph> _linuxftw: Here's a first revision for you: http://pastebin.com/Q4kpySye
17:11:26 <_linuxftw> thanks BMeph
17:12:02 <_linuxftw> Still an infinite loop
17:14:28 <ddarius> (m,n) isn't completely ridiculous notation.  The gcd is the categorical product in an appropriate category.
17:15:00 <ddarius> (But yeah, I'd use a more explicit notation in all cases.)
17:15:47 <danharaj> cabal-install needs to make C binding libraries easier to build.
17:16:00 <cads> if d = gcd(a,b) goes into a a' times and into b a total of b' times, then our problem becomes finding integers i, j such that ix' + jy' = 1
17:16:21 <cads> which, umm.. doesn't give me an immediate solution :)
17:16:23 <ezyang> danharaj: How so? 
17:16:34 * soupdragon doesn't know what a' and b' are
17:16:51 <soupdragon> ddarius hah! cool
17:16:57 <danharaj> ezyang: Right now, you have to build the C libraries yourself, but cabal-install could do that, too. It has access to make and gcc.
17:16:58 <soupdragon> (about the product in some category)
17:17:06 <soupdragon> is that the poset category?
17:17:07 <danharaj> or maybe that's asking too much. But I think C bindings are pretty important.
17:17:18 <cads> soupdragon:  they would be a' = a / gcd(a,b), b' = b / gcd(a,b)
17:17:20 <ezyang> danharaj: Cabal is not a package manager for the rest of the C ecosystem. 
17:17:36 <danharaj> ezyang: Maybe I'm just grumpy because I'm on windows and I don't have a package manager ;)
17:17:40 <ezyang> Cabal can compile C itself, but it has pretty explicitly not put compiling C library dependencies 
17:17:46 <ezyang> danharaj: That would do it :-) 
17:17:54 <danharaj> Like stabbing myself to death with a cheese grater.
17:18:05 <soupdragon> cads ah yeah, that lets you reduce the problem to solving  ax + by = 1  with gcd(a,b) = 1  
17:18:11 <ezyang> The bindings I'm working on right now bundle the library, because it's a pain in the ass to build as a library and we're using an unreleased version and we needed to patch it. 
17:18:29 <ddarius> cads: And you can derive a solution to that fairly easily by asserting the loop invariant ax+by=c and then rewriting the equation in such a way that c eventually reaches 1.
17:18:51 <eflister> bmeph: i'm in san diego -- heard on npr that it was a 5.9 in anza borrego.  are you in LA?
17:18:55 <danharaj> ezyang: You're doing it wrong. The correct approach is to not document which library version you are using, and point the user to an outdated version of your patch.
17:19:06 <danharaj> ezyang: also make sure your build instructions don't make sense.
17:19:08 <ezyang> Heehee :-) 
17:19:14 <eflister> petrat - hey good to hear from you.  did you wind up taking a look at it?
17:19:18 <cads> ddarius: the loop invariant of the euclidean algorithm?
17:19:23 <danharaj> ezyang: Is my bitterness showing? >:|
17:19:37 <ezyang> Just a wee bit 
17:20:29 <danharaj> But asking hackers to make useful instructions is completely unreasonable. They are too busy being awesome, creating projects and abandoning them more efficiently than a smack whore and her children.
17:20:35 * danharaj blood vessel bursts
17:20:51 <eflister> petrat - i know we talked a while ago about portmidi, have been wondering if you ever took a look at that livecoding framework i sent...
17:21:07 <ddarius> soupdragon: Oh, I missed your question.  Yes, the divisibility poset or its opposite.  I forget which way it normally goes.
17:21:10 <BMeph> eflister: I'm at work, in Poway. :)
17:21:22 <soupdragon> huh divisibility poset? I've never heard of that
17:21:27 <soupdragon> ddarius I've got a question
17:21:31 <danharaj> poset products and coproducts are joins and meets right?
17:21:35 <ddarius> a <= b if a|b (or the other way around)
17:21:36 <soupdragon> if you got all these arithmetical categories
17:21:37 <ddarius> danharaj: Yes.
17:21:45 <soupdragon> could you build new categories from them
17:21:51 <soupdragon> and what would you discover/
17:21:51 <soupdragon> ?
17:21:52 <danharaj> You know I always forget which one was join and which one was meet.
17:21:56 <ddarius> danharaj: Other way around (usually).  Not that it matters for posets.
17:21:56 <danharaj> Is there a good mnemonic?
17:22:22 <soupdragon> one mans category is another mans C^op
17:22:31 <ddarius> danharaj: Probably.  I more or less just remember.  join is associated with (set) union for me and meet intersection.
17:23:51 <eflister> bmeph: sweet -- where in san diego employs haskellers?  do you ever read the socal-fp list?  i was trying to see if people wanted to have a san diego hangout :)
17:23:58 <danharaj> I guess meet shares more letters wtih intersection than union. That's how I'll remember it :p
17:24:14 <ddarius> soupdragon: I'm not sure what you mean by "arithmetical category."  You can, of course, make new ones using any of a variety of constructions on categories.  You probably won't discover much from it unless you have some intuition guiding you.
17:25:09 <BMeph> eflister: I (may) use it _at_ work, but I don't use it for work..."if you know what I mean"... ;)
17:25:12 <danharaj> So I managed to successfully install the SDL bindings.
17:25:23 <danharaj> Now I dare to try my luck by installing two more related bindings.
17:25:58 <eflister> bmeph: :)
17:27:32 <ddarius> "I (may) use my Armalite AR-18 _at_ work, but I don't use it for work ... 'if you know what I mean'..."
17:30:52 <etpace> Hmm, i've got a simple parrallel sorting algorithm from RWH, but it seems to take so long it never terminates
17:31:05 <etpace> but using data.list sort terminates fine, any ideas what could be going wrong?
17:31:33 * BMeph prefers the P-90 - more compact, so "easy to get those 'hard-to-reach' areas"... >;)
17:38:14 <PetRat> Is eflister here now?
17:38:26 <eflister> petrat: hey
17:38:37 <PetRat> eflister: hey it's Michael Mossey here
17:38:50 <eflister> petrat - hey i belatedly replied above :)
17:38:57 <eflister> petrat - was afk
17:39:00 <PetRat> I disconnected so I missed it
17:39:45 <PetRat> eflister: so I was wondering about your music program and the use of types like Half, Dotted, etc. Is that because you are entering notes in a human-readable format?
17:40:18 <eflister> petrat - it's already logged at http://tunes.org/~nef//logs/haskell/10.07.07, but i didn't say anything interesting.  ;)  just cool to hear from you, interested in hearing if you are checking out that code...
17:40:50 <eflister> petrat - well i was striving to live up to the 'edsl' idea
17:41:32 <PetRat> I guess my question is: why not represent durations as Rational? I understand first that you were suggesting we be "agnostic" about the type and just constrain it to classes Real and Fractional... but
17:42:09 <eflister> petrat - i like the idea of matching up with domain-practitioners' ontology, plus it maps nice to engraving output, etc
17:42:15 <PetRat> A duration in a normal score is always a fraction of the beat: 1%1, 3%2, or in the case of 7-tuples 1%7
17:42:49 <PetRat> Okay, so maybe we have different goals because my program is playing the music via midi but not engraving it
17:43:05 <eflister> petrat - agreed, i capture that with the edsl and avoid numeric altogether -- i was saying not to go numeric until you actually need to place notes in time
17:43:25 <eflister> petrat - i write out realtime midi -- we talked a few months ago about portmidi
17:43:43 <theorbtwo> Hm, strange.
17:43:58 <PetRat> Now my other question was: the reason I want Rational instead of Float is because I don't want to deal with rounding errors... what I mean is....
17:44:03 <theorbtwo> I have difficulty thinking of durations as anything but numbers, expressed somewhat oddly.
17:44:26 <eflister> petrat - the traditional note durations turn out to be nice to use imo -- 'dotted quarter' doesn't have any precision problems :)
17:44:57 <PetRat> Let's say there are two parts in the score. I want to find "verticals"---notes played at the same time --- I never have to worry about 1.5 != 1.4999999
17:45:07 <PetRat> does that make sense or do I not understand something?
17:46:01 <eflister> petrat - it makes sense to avoid floats for that reason but i argue this is not a numeric problem at all
17:46:04 <soupdragon> cads although once you've solved the problem it's still a bit of a trick to turn it into a program - sort of like fitting back together a rubiks cube
17:46:07 <PetRat> I understand dotted quarter doesn't have precision issues, but I only really care about the performance via midi so I would just represent dotted quarter as 3%2
17:46:29 <PetRat> I don't understand -- not a numeric problem? sorry can you explain that?
17:47:01 <eflister> petrat - you don't need numerics (things you can apply arithmetic operations to) til you really want to decide when to timestamp a midi note, which my code has those durationMS functions for, etc
17:47:29 <eflister> petrat - your way will work fine, i am just being pedantic and picky about representing the problem with exactly the corresponding mathematical objects
17:47:32 <cads> soupdragon: reading about it makes me want to study algebra to understand the euclidean algorithm abstract settings
17:47:39 <cads> in abstract settings*
17:47:45 <PetRat> Okay, but I also manipulate the score in certain ways *before* I need to timestamp a midi event
17:48:05 <PetRat> like finding verticals, making changes to the score, filtering out sections
17:48:16 <eflister> petrat - and i argue all that can/should be done without arithmetic
17:48:20 <soupdragon> hhehe yeah you can apply GCD to a bunch of stuff
17:48:59 <PetRat> eflister-- well you have a point, and I think I don't completely understand your code, so it is probably very cool once I understand it. 
17:49:31 <eflister> petrat - yeah i'd love to discuss it/find ways to improve it or make it easier to understand
17:50:08 <PetRat> your idea sounds very neat, I just am not at that level of computer science. I guess I think very concretely because my programming background is just a serf in a large scientific programming environment. hell we use Fortran
17:50:15 <eflister> petrat - what part doesn't make sense?  i am totally unclear when forall's are required, i just add them when the compiler says it wants them or someone on #haskell points out i need one
17:50:51 <PetRat> eflister -- I only skimmed your code. Let's take the problem of finding verticals. How is that done without arithmetic?
17:51:25 <PetRat> You have to compute that, let's say,   [Eigth, Eight, Eight] has same duration as [Dotted Quarter]
17:53:19 <eflister> petrat - well it's a matter of determining whether two notes 'intersect' -- maybe compute the beats that two notes 'cover' and see if the intersection of those sets is empty
17:54:58 <PetRat> eflister - I guess I don't understand how that is done with numerics. Hmm, are beats represented in a list?
17:55:09 <PetRat> *without* numerics
17:55:42 <eflister> petrat - i'm not entirely happy with my treatment of subdiv as a real fractional -- that will bring in numerics, so let's not allow subdivisions of beats for now
17:56:36 <eflister> petrat - before writing intersect :: Note -> Note -> Bool, let's write beats :: Integral a => Note -> [a]
17:56:55 <PetRat> Well, I think you are doing something neat and abstracting the problem -- I have never been a student in a computer science program, but I imagine students are taught, "abstract, abstract, abstract"
17:57:49 <BMeph> eflister: Do you not like tripled notes? ;)
17:58:21 <PetRat> BMeph: are you referring to his disallowal of subdivisions?
17:58:37 <eflister> petrat - then intersect is straightforward, right?  and it's clear how to write beats -- (beat numbers *will* require arithmetic).  and we have beats :: (NoteDur a, Real x, Fractional x) => a -> x
17:58:43 <theorbtwo> I was about to say that common durations don't have floating point problems because they are nice numbers in binary, but that ignores tripples.
17:58:54 <eflister> BMeph: triplets are covered!  i'll hpaste
17:58:57 * hackagebot converge 0.1 - Limit operations for converging sequences  http://hackage.haskell.org/package/converge-0.1 (JamesCook)
17:59:22 <theorbtwo> That is, they are all small multiples of a small power of two.
17:59:44 <eflister> bmeph: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27111
18:00:04 <BMeph> eflister: "Accessing..." ;)
18:00:28 <FunctorSalad> what are tripled notes?
18:00:44 <FunctorSalad> sorry newb question =(
18:01:08 <eflister> functorsalad: 'triplets' are notes with durations that are some multiple of divisions of a beat into thirds
18:01:14 <poseidon> Is there a way I can relenquish a variable so I can assign it to something else?
18:01:33 <ddarius> poseidon: No.
18:01:35 <PetRat> can I ask a basic question? what does (NoteDur a, Real x, Fractional x) =>  mean? Does it constrain x to a type that is a member of BOTH classes or EITHER class?
18:01:35 <ezyang> poseidon: In what context? 
18:01:54 <eflister> petrat: both
18:01:58 <PetRat> Note that the correct term is "triplet" not "tripled"
18:02:06 <FunctorSalad> hmm ok, use { 1/(2^n * 3^m) | n,m natural } as generators then?
18:02:18 <theorbtwo> FunctorSalad: A triplet is also a decoration of sorts on a set of notes, saying to multiply all durations expressed inside it by some fraction -- 1/3rd if the notation doesn't say otherwise.
18:02:20 <jmacc> hola
18:02:23 <FunctorSalad> for you time-number type
18:02:23 <PetRat> eflister: "both" - I don't understand
18:02:41 <theorbtwo> FunctorSalad: The notation generalizes, it's just *normally* 1/3rd.
18:03:03 <eflister> functorsalad: things can be both real and fractional :)  rationals for instance.  floats too.
18:03:17 <eflister> s/functorsalad/petrat
18:03:32 <FunctorSalad> (is that thing a ring already? with integral linear combinations)
18:03:33 <theorbtwo> Other then that, durations are n/2^m.  "Dotted" notes have the value of the non-dotted * 1.5.
18:03:39 <PetRat> eflister: I'm asking how the compiler interprets that notation, though
18:03:49 <FunctorSalad> looks like it
18:03:52 <PetRat> how does the compiler read that constraint?
18:03:59 <blackh> poseidon: If you use the 'in' part of your let the right way, you can scope your variables and re-use the name outside that scope.  You can also shadow variable names.  But all this does is re-use the variable's name.  It doesn't change the variable at all.
18:04:01 * hackagebot continued-fractions 0.9 - Continued fractions.  http://hackage.haskell.org/package/continued-fractions-0.9 (JamesCook)
18:04:11 <eflister> functorsalad: but (1/64)/3 is not natural to a musician :)
18:04:29 <PetRat> eflister: unless you're Ferneyhough
18:04:30 <FunctorSalad> theorbtwo: the decoration would fit well into the ring I mentioned too
18:04:39 <FunctorSalad> eflister: not to me either =)
18:05:02 <FunctorSalad> I meant "integral linear combinations of the numbers of the form 1/(2^n * 3^m)
18:05:12 <theorbtwo> FunctorSalad: Unless it's a "triplet" that says "1/5" below it.
18:05:26 <Pseudonym> "tuplet" in general.
18:05:36 <FunctorSalad> "integral" as in the coefficients of the generators, not the results ;)
18:05:38 <tg_> http://arxiv.org/abs/1005.1213
18:05:42 <tg_> tyranny
18:05:44 <eflister> petrat: this is just a regular old gadt
18:05:47 <orlandu63> is there a literal data type for a list?
18:05:53 <Pseudonym> But yes, I've seen all sorts of denominators in tuplets.
18:05:56 <Pseudonym> "7" is common.
18:06:01 * hackagebot polynomial 0.5 - Polynomials  http://hackage.haskell.org/package/polynomial-0.5 (JamesCook)
18:06:16 <Pseudonym> I've seen cadenzas with "13" or "17".
18:06:22 <FunctorSalad> a representation would be: IntMap (IntMap Integer)
18:06:46 <PetRat> eflister: I don't really know what a gadt is (generalized abstract data type... but what does "generalized" mean?)
18:06:53 <eflister> pseudonym: yeah i bailed on tuplets.
18:07:13 <FunctorSalad> 1/(2^n * 3^m) =: singleton 2 (singleton 3 1)
18:07:19 <theorbtwo> Try http://lilypond.org/doc/v2.12/Documentation/user/lilypond/Writing-rhythms#Tuplets
18:07:19 <PetRat> my laptop is out of juice so I'm signing off. But nice meeting you online, Erik.
18:07:30 <FunctorSalad> err sorry
18:07:36 <FunctorSalad> 1/(2^n * 3^m) =: singleton n (singleton m 1)
18:07:37 <eflister> petrat - i'm not so clear on that myself, i think it has something to do with the idea that you can use existentials in the fields
18:07:39 <FunctorSalad> ^^^^^^ correction
18:07:42 <eflister> petrat - ok, cool, later
18:07:57 <FunctorSalad> hmm maybe currying is bad here though
18:08:55 <ddarius> @google "temporal modulation"
18:08:55 <lambdabot> http://colorusage.arc.nasa.gov/flashing.php
18:08:55 <lambdabot> Title: Blinking, Flashing and Temporal Response
18:08:56 <theorbtwo> I'd just call the duration of a note a CReal and be done with it.
18:09:02 <ddarius> Not what I wanted...
18:09:33 <theorbtwo> Oh, as an extra bonus, BTW, these are all durations in beats, which are implicitly relative to the current tempo.
18:09:44 <theorbtwo> ...and the tempo itself can change during a piece.
18:09:54 <ddarius> @google "tempo modulation"
18:09:55 <Pseudonym> There are a number of pieces which require different hands on a piano or different instruments of an orchestra or different voices in a choir to play triplets against duplets.
18:09:55 <lambdabot> http://en.wikipedia.org/wiki/Metric_modulation
18:09:55 <lambdabot> Title: Metric modulation - Wikipedia, the free encyclopedia
18:10:07 <eflister> theorbtwo: but then you have 0.005208333333333 instead of "triplet sixty-fourth"
18:10:08 <Pseudonym> It's hard to play on the piano, but even harder to conduct.
18:11:05 <theorbtwo> Pseudonym: Sounds downright evil.
18:11:06 <FunctorSalad> (the construction I mentioned isn't the whole rationals, is it? denominators won't be anything else than in the generators)
18:11:29 <FunctorSalad> (which are redundant, but I don't know how to fix it ;))
18:12:56 <Twey> eflister: CReals are capable of representing fractions
18:13:10 <ddarius> "Evolutivity has become a major criteria of quality for enterprise software."  
18:13:16 <Twey> Haha
18:13:50 <eflister> twey: (3/64)/2 is not very useful either
18:14:26 <Twey> From the Latin roots ex + volumen, meaning ‘blow-hard’
18:15:36 <FunctorSalad> is that like the opposite of involutivity? :F
18:16:20 <FunctorSalad> Twey: but efficiently? or as an overkill digit generating algorithm 
18:16:30 <blackh> It's so important that it's a "criteria" not just a boring old "criterion"
18:17:00 <FunctorSalad> (not sure if a CReal generates digits or "epsilon-challenge--response" rationals)
18:17:19 <Twey> FunctorSalad: CReals don't generate digits unless asked
18:17:46 <FunctorSalad> of course =)
18:18:01 <FunctorSalad> (would be hard to do it eagerly :))
18:18:05 <Twey> Right :þ
18:18:29 <FunctorSalad> I was wondering what the typical closure for a rational would look like...
18:18:48 <FunctorSalad> (and how efficient operations on it are compared to plain rationals)
18:19:56 <FunctorSalad> (they are closures, or not?)
18:20:03 <FunctorSalad> @src CReal
18:20:03 <lambdabot> Source not found. Just what do you think you're doing Dave?
18:20:14 <dolio> CReal is Integer -> Integer internally, or something similar.
18:20:29 <FunctorSalad> @vixen could you index all of hackage please? :(
18:20:30 <lambdabot> i just turned 19
18:20:31 <Twey> Integer -> Integer?
18:20:39 <dolio> Yes.
18:20:39 <Twey> digits -> representation?
18:20:48 <Twey> Ah
18:21:00 <Twey> So yes to closure, then
18:21:04 <FunctorSalad> maybe the input is allowed error too
18:21:31 <dolio> You give it e, and it generates i such that i/(b^e) is accurate to within 1/(b^e), I think.
18:21:35 <FunctorSalad> IIRC that avoids the nonunique-digit-expansion problem
18:21:43 <FunctorSalad> (if it is one in this case)
18:22:04 <ddarius> Curse ivanm.
18:22:40 <dolio> That'd be my guess, at least. I've not studied the implementation.
18:23:41 <dolio> It might be Int -> Integer, actually.
18:24:08 * FunctorSalad finds it funny that this apprently-irrelevant detail more or less leads to the difference between getting a continuum or cantor dust =)
18:24:26 <FunctorSalad> (if you take the space of all digit expansions)
18:27:46 <FunctorSalad> (the set of binary sequences represents the cantor set if you define: value("0.b1 b2 b3 b4 ...") = value of the base-3 expansion 0.c1 c2 c3 c4 .... , where all 1's have been replaced with 2's
18:27:58 <dolio> I think numdigits -> digitinteger would be less convenient for arithmetic.
18:28:38 <FunctorSalad> (that actually gives an injective function/unique digit representations... but for the cantor set)
18:30:06 <dolio> Yes. It's nice, because it's easy to diagonalize (Nat -> Bool), and show that the Cantor set is computably uncountable.
18:30:17 <dolio> Or Nat -> (Nat -> Bool)
18:30:34 <BMeph> I think this is my favorite quote from that hash table blog-art: "Hash tables are real fast- right up until they’re not."
18:30:54 <soupdragon> the weirdest thing about constructive math (that I am aware of) is the fact that diagonalization still works
18:33:03 <ddarius> soupdragon: If you mean Cantor's diagonalization argument, it simply a direct refutation (a direct proof that assuming countability implies a contradiction).
18:33:21 <dolio> I don't see why that's weird.
18:36:45 <theorbtwo> LurkingBM: There was a big bruhaha in the perl community about that a while back.  It's not that hard to fix, once you think of it as a angorithmic problem instead of a security problem.
18:36:49 <ddarius> A proof by contradiction would go like: Assume X isn't true, then we get a contradiction, thus X is true.  (If we artificially make a proof by contradiction we get not (not (not a)) => not a which is intuitionistically provable.) Diagonalization is simply X is true implies a contradiction, i.e. X => False the definition of negation usually used by intuitionists.
18:37:49 <theorbtwo> You notice when almost all the data ends up in one bin of the hash, change a constant in the hash function, and reshuffle the data.
18:46:28 <phenom_> what is the best place to learn haskell ?
18:46:56 <jesusabdullah> What do you mean, phenom_ ?
18:47:10 <Tomsik_> Read the code, write the code, repeat
18:47:31 <phenom_> what or where is the best free resource to learn haskell? :P
18:47:41 <jesusabdullah> As far as good references to start with, a lot of people like "Learn you a haskell"
18:47:44 <phenom_> and if not free, best in general
18:47:46 <Pseudonym> phenom: What languages do you speak?
18:47:50 <Pseudonym> Programming languages, that is.
18:48:01 <jesusabdullah> and "real world haskell" is something people also like as well
18:48:03 <phenom_> java, python, erlang and some scala
18:48:03 <blackh> phenom_: http://www.learnyouahaskell.com/ and http://book.realworldhaskell.org/ are both great
18:48:12 <Pseudonym> phenom: Then I'd pick Real World Haskell.
18:48:37 <phenom_> kk, thnx
18:48:48 <jesusabdullah> RWH is more aimed towards people that want to get up to speed really fast, while lyah, I think, has a more explorative feel. that said, ymmv
18:48:55 <Pseudonym> Yeah.
18:49:05 <jesusabdullah> Oh, and phenom_, /r/haskell is a good place to pick up little things and nifty blog posts too
18:49:09 <FunctorSalad> dolio: are you implying the diagonalization argument for [0,1] itself is nonconstructive, for nonunique digit rep reasons?
18:49:18 <jesusabdullah> and here is a good place to lurk also!
18:49:27 <Pseudonym> LYAH is great if you want to do computer science.  RWH is better if you've got a program in mind that you already want to write.
18:49:30 <blackh> phenom_: And of course this IRC channel is excellent for newbie questions
18:49:37 <dolio> FunctorSalad: No, I'm implying it's harder.
18:50:22 <FunctorSalad> ah
18:50:29 <Pseudonym> Again, IMO.
18:50:47 <poseidon> I just solved my first problem in Haskell.  It was something that would have taken me ~10 lines in c.  However, I solved it in 1 in Haskell using lists.  It really is an awesome language
18:51:08 <Tomsik_> only 10 : 1? :p
18:51:09 <Pseudonym> OTOH, you can also replace 1 line of C with 10 lines of Haskell.
18:51:12 <Tomsik_> That's not good yet
18:51:14 <dolio> You have to prove that your diagonal element isn't accidentally equal to some representation that's actually in the given map.
18:51:16 <ddarius> "LYAH is great if you want to do computer science."  ?
18:51:18 <Twey> Haskell one-liners go up to about thirty lines of C often.
18:51:32 <Tomsik_> There was this project euler thing
18:51:41 <Tomsik_> that was haskell one-liner under 80 characters
18:51:47 <Tomsik_> in C it was about 50 lines
18:51:55 <Pseudonym> ddarius: "Computer science" is my mental shorthand for programs which rely heavily on discrete algorithms and data structures.
18:52:07 <danharaj> your mental shorthand sucks.
18:52:09 <Pseudonym> And yes, I realise that's an abuse of notation.
18:52:10 * danharaj :p
18:52:14 <bremner> Pseudonym: Wittgenstein
18:52:21 <ddarius> I should perhaps actually read LYAH.  I skimmed it briefly a long while ago when it was still young.
18:52:34 <Pseudonym> I know, the ghost of Wittgenstein is going to get me some day.
18:52:53 <aavogt> I don't think it teaches very much discrete math
18:53:09 <djahandarie> ddarius, it has nice pictures and good analogies
18:53:15 <djahandarie> ddarius, it also teaches stuff in the proper order
18:53:20 <Pseudonym> It doesn't.  But it's much more focussed on the implicit theory of what Haskell is "good for".
18:53:26 <poseidon> Tomsik_: The example I was talking back was actually a project euler problem :)
18:53:40 <Pseudonym> Haskell is "good for" discrete algorithms and data structures and hard-core structure munging.
18:53:43 <Pseudonym> You know the drill.
18:53:54 <djahandarie> Haskell is good for a lot of stuff
18:53:55 <poseidon> Also, I didn't solve it using C yet.  I just figured it would take about 10 lines.  It might take more
18:54:01 <Pseudonym> Of course it is.
18:54:15 <ddarius> poseidon: It might take less.
18:54:20 <Pseudonym> But all programming languages develop an implicit theory of what they're "good for".
18:54:58 <ddarius> Pseudonym: Perhaps communities develop an implicit theory of what a language is "good for".  Soon you'll be haunted by Dijkstra as well.
18:54:59 <theorbtwo> s/(all programming language)/$1 user/
18:55:12 <Pseudonym> LYAH doesn't explicitly accept that theory, but it betrays that heritage, if you know what I mean.
18:56:08 <Pseudonym> What I'm trying to say is that LYAH _may_ give the mistaken impression that Haskell is only "good for" propeller-headed computer science.
18:56:20 <ddarius> Well why didn't you just say that?
18:56:21 <Pseudonym> If you don't also read RWH.
18:56:37 <Pseudonym> Because the idea was far more vague when I started this conversation.
18:57:08 <kmc> most introductions to FP may give that impression
18:57:19 <kmc> it's something anti-FP trolls bring up frequently
18:57:28 <kmc> i've not decided if it's a legit criticism
18:57:34 <ddarius> "WARNING: This introduction to Functional Programming may be harmful to your mental health."
18:58:33 <kmc> for most programmers, learning FP and especially learning Haskell requires the ability to delay gratification
18:58:40 <kmc> you don't write interesting programs right away
18:59:04 <kmc> you have to trust someone that writing nine different ways to calculate prime numbers will pay off down the road
18:59:07 <tg_> kmc: I'm beginning to actually believe the old adage that all of the best things require delayed gratification
18:59:16 <jesusabdullah> That's an issue for me XD
18:59:26 <Pseudonym> Anything worth doing requires getting through a certain amount of drudge.
18:59:38 <Pseudonym> It's sad, but true.
18:59:48 <tg_> Pseudonym: I don't think that's good relationship advice, though.
18:59:51 <tg_> hehe
18:59:59 <kmc> i think it is
19:00:01 <Pseudonym> You sure about that?
19:00:08 <tg_> Well, I think it's better said how I said it
19:00:29 <Pseudonym> You're saying that getting a good partner doesn't inevitably involve a bunch of bad dates with unsuitable partners?
19:00:43 <Pseudonym> Some people luck out, it's true.
19:01:29 <jesusabdullah> Or, that partners eventually have their First Fight?
19:01:41 <ddarius> Fight /= drudge
19:02:13 <tg_> thinking...
19:02:33 <tg_> let me go get my quote book
19:02:33 <tg_> brb
19:04:09 <kmc> the fight isn't drudge, but being extra nice to the other person in lots of small ways afterward to make up for it might be
19:04:21 <kmc> but perhaps the idea is that you care enough that it isn't
19:04:41 <kmc> but perhaps that's the idea with Haskell too -- hence why we find these fibonacci programs unnaturally beautiful :)
19:05:22 <tg_> well, or why we should stop using the fibonacci sequence as our foremost example
19:05:50 <tg_> here's a good quote that's relevant, but not the thought I was looking for:
19:06:16 <tg_> "During the first period of a man's life the greatest danger is not to take the risk." Soren Kierkegaard, 1831-1855
19:07:05 <poseidon> ahhh.  Everytime I get something I move onto something new which is different from anything I've ever learned.  There are no for loops ?!?!
19:07:34 <Pseudonym> On the other hand, there is one aspect of learning Haskell that many commentators don't "get".
19:07:39 <tg_> poseidon: would you write a for loop that calls for loops?
19:07:46 <Pseudonym> The point isn't that you can write a practical quicksort in two lines, because you can't.
19:08:16 <tg_> Pseudonym: maybe we need a better explanation that once we write quicksort, we won't need to worry about it any longer.
19:08:37 <Pseudonym> The point is that given that you can get quicksort out of a can these days, the only reason to write it yourself (assuming standard requirements) is to learn something about it.
19:08:41 <aavogt> @src forM
19:08:42 <lambdabot> forM = flip mapM
19:08:56 <aavogt> @type Data.Foldable.for
19:08:57 <lambdabot> Not in scope: `Data.Foldable.for'
19:09:06 <aavogt> @type Data.Traversable.for
19:09:06 <tg_> I can't follow up my earlier comment. Re: relationship advice, I was talking about the maturation of a good relationship, not the follies of those engaging in and disengaging in relationships.
19:09:07 <lambdabot> forall (t :: * -> *) a (f :: * -> *) b. (Data.Traversable.Traversable t, Applicative f) => t a -> (a -> f b) -> f (t b)
19:09:31 <tg_> But the phrase "the juice is worth the squeeze" comes to mind. The best relationships are worth the work to keep them.
19:12:40 <jesusabdullah> Does haskell have anything akin to docstrings?
19:13:50 <blackh> jesusabdullah: The closest thing is haddock comments.  Typeable / Dynamic is the only sort of reflection you get at runtime.
19:14:38 <tg_> jesus: you can also use inline haskell (like with gitit)
19:14:54 <tg_> that is a different way to do things, it doesn't provide identical functionality
19:18:13 <poseidon> how can I iterate through each item in an array?
19:18:21 <poseidon> s/array/list/
19:18:57 <blackdog_> poseidon: what do you want to do to each?
19:19:13 <blackdog_> do you want a list that has each element transformed back?
19:19:29 <blackdog_> or are you looking to do something like summing a list of integers?
19:19:52 <poseidon> blackdog_: I have a list of lists which contains Integers.  I want to find the list in which all integers equal 100
19:19:59 <djahandarie> :t filter
19:20:00 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
19:20:02 <poseidon> *sum of all integers
19:20:16 <ddarius> Sheet music notation makes some things complicated...
19:20:49 <blackdog_> poseidon: ok, so at the top level, filter is the right combinator
19:21:03 <ddarius> poseidon: The answer to any "iteration" question in Haskell is recursion, though we much prefer to use higher order functions that do the recursion for us rather than use it directly.
19:21:16 <blackdog_> you know you're applying some predicate to decide which elements to keep
19:21:38 <blackdog_> so then you just need to work out how to write the predicate "is the sum of this list equal to 100?"
19:21:43 <danharaj> It's all about combinators.
19:22:21 <danharaj> actually doing explicit recursion should be low in the list of tools.
19:23:22 <djahandarie> I really wish "a gnetle introduction to haskell" was not the first result for "haskell tutorial"
19:23:38 <djahandarie> gentle*
19:23:53 <djahandarie> harsh* to be honest
19:24:09 <ddarius> It's the first thing I read and I liked it.
19:24:22 <djahandarie> Coming in with what background?
19:24:26 * conal too
19:24:39 <conal> my first exposure to haskell.  i liked it a lot.
19:25:05 <danharaj> it's probably the main resource I went to while learning the basics.
19:25:49 <conal> though i'd already programmed a lot in ML and some in miranda.
19:26:01 <blackdog_> djahandarie: it's gentle compared to the report :)
19:26:38 <djahandarie> I'm not really badmouthing it, I just don't think it'd be the nicest thing for random joe to stumble upon when he's trying to learn Haskell
19:26:41 <dolio> Knowing Miranda is arguably cheating. :)
19:26:50 <conal> yeah :)
19:27:01 <ddarius> djahandarie: I knew Scheme, Common Lisp and Prolog at the time (plus many other things), but I was primarily a C++ programmer.
19:27:20 <conal> and i'd implemented & played with a lazy lisp dialect in grad school.
19:27:25 <ddarius> That was around my senior year of high school.
19:28:24 <djahandarie> ddarius, apparently your life parallels mine just like your name does. Although s/C++/PHP/
19:28:40 <danharaj> My only language coming in was C++.
19:29:03 <danharaj> Took me a long time. I'm not sure how much of it was actually learning Haskell and how much of it was coming to terms with lambda calculus as my model of computation.
19:34:39 <poseidon> ddarius: I just finished my senior year in high school.  I'm in the same boat you were :)  However, I'm looking over "learn you a haskell for good."  Do you have any other recommendations for learning?
19:35:32 <djahandarie> Why weren't all these people in my high school? :P
19:35:54 <aavogt> how can you be sure about that, djahandarie?
19:36:41 <djahandarie> I knew nearly everyone who even knew what programming was. So I'm certain to a fairly high extent that they were not.
19:36:45 <poseidon> djahandarie: Everybody I knew in highschool did not know anything about CS either.  Even the people who took AP CS with me...
19:37:46 <poseidon> djahandarie: you don't know.  Maybe that really hot preppy cheerleader liked to go home and solve project Euler problems for fun
19:38:08 <djahandarie> All our cheerleaders were fat
19:38:30 <poseidon> Then I guess it might be a little more plausable
19:38:47 <aavogt> djahandarie: I knew stuff, but didn't take any courses or show any signs of knowing stuff
19:39:04 <aavogt> I guess those people don't count :)
19:39:33 <poseidon> I was the same.  I did take AP CS, however, other than the three people who took it with me (none of which were in my grade) I never talked about the stuff
19:40:27 <djahandarie> What happened to copumpkin
19:40:50 <djahandarie> preflex: seen compumkin
19:40:50 <preflex>  Sorry, I haven't seen compumkin
19:40:55 <djahandarie> preflex: seen copumpkin
19:40:56 <preflex>  copumpkin was last seen on #haskell-blah 30 days, 18 hours, 44 minutes and 51 seconds ago, saying: * copumpkin goes poof
19:41:03 <djahandarie> preflex: seen pumpkin
19:41:04 <preflex>  pumpkin was last seen on #haskell-blah 29 days, 16 hours, 55 minutes and 4 seconds ago, saying: Ciao!
19:41:20 <ezyang> how fitting. 
19:41:40 <aavogt> supposedly travels?
19:42:51 <ddarius> poseidon: There are a -lot- more resources available for learning Haskell now than were available eight years ago.
19:43:07 <djahandarie> A lot more monad tutorials too
19:43:16 <ddarius> So you are in a better position than I was.
19:43:58 <ddarius> djahandarie: Regretably.  The best one was made years before I started Haskell.
19:44:28 <djahandarie> Which are you refering to?
19:44:49 <phenom_> im on a mac should i get ghc 6.12.3 or the haskell platform for playing around and some solid development ?
19:44:58 <erikc> haskell was so much cooler before it went mainstream
19:45:24 <djahandarie> phenom_, platform is a good choice
19:47:51 <ddarius> "The essence of functional programming"  (or "Monads for functional programming" I think is the title of a very similar one.)  Both by Phil Wadler.
19:57:13 <SevenInchBread> does my application have to have a Main module? or can I simply have a main function in one of the modules?
19:58:43 <Cale> CakeProphet: It's not absolutely required, but if you want the main action to be anything but Main.main, you need to give a --main-is option to GHC.
19:59:02 <ddarius> The Main module can be in a file of any given name though.
19:59:29 <Cale> CakeProphet: The typical thing to do is simply not to put a module declaration in the main module of the program.
19:59:48 <Cale> CakeProphet: Then you can name the file anything you like, but it will get the default module name, which is Main
19:59:54 <CakeProphet> ah okay
20:00:00 * ddarius usually puts "module Main() where ..."
20:01:10 <CakeProphet> :t (,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,)
20:01:11 <lambdabot> forall a b c d e f g h i j k l m n o p q r s t u v w x y z t28 t29 t30 t31 t32 t33 t34 t35 t36 t37 t38 t39 t40 t41 t42 t43 t44 t45 t46 t47 t48 t49 t50 t51 t52 t53 t54 t55 t56 t57 t58 t59 t60 t61 t62
20:01:11 <lambdabot> t63. a -> b -> c -> d -> e -> f -> g -> h -> i -> j -> k -> l -> m -> n -> o -> p -> q -> r -> s -> t -> u -> v -> w -> x -> y -> z -> t28 -> t29 -> t30 -> t31 -> t32 -> t33 -> t34 -> t35 -> t36 ->
20:01:11 <lambdabot> t37 -> t38 -> t39 -> t40 -> t41 -> t42 -> t43 -> t44 -> t45 -> t46 -> t47 -> t48 -> t49 -> t50 -> t51 -> t52 -> t53 -> t54 -> t55 -> t56 -> t57 -> t58 -> t59 -> t60 -> t61 -> t62 -> t63 -> (a, b, c,
20:01:11 <lambdabot> d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, t28, t29, t30, t31, t32, t33, t34, t35, t36, t37, t38, t39, t40, t41, t42, t43, t44, t45, t46, t47, t48, t49, t50, t51, t52, t53,
20:01:11 <lambdabot> t54, t55, t56, t57, t58, t59, t60, t61, t62, t63)
20:01:15 <CakeProphet> ....
20:01:40 <CakeProphet> what? No Typeable63?
20:03:42 <soupdragon> http://i.imgur.com/g59pY.png
20:04:34 <soupdragon> silly
20:04:46 <soupdragon> "we picture it as follows:                                                 "
20:04:46 <pizza_> o_O
20:06:27 <CakeProphet> soupdragon:  bad joke?
20:06:41 <soupdragon> I don't really know yet
20:07:09 <soupdragon> oh it looks like they're all missing
20:07:21 <adu> hi
20:07:27 <cheater99> soupdragon: i think it's a place for you to fill in the dots
20:07:35 <soupdragon> yeah ill draw my own pictures
20:07:48 * djahandarie hands over the crayons
20:07:55 <cheater99> draw a picture of a spider
20:13:15 <djahandarie> Well this sentence is confusing
20:14:12 <djahandarie> "Given a set P of n points, and a segment s (which may not be determined by two of the points) we say that the k vertical nearest neighbors above (below) s are those k points above (below) the line through s, and within the slab defined by vertical lines through the endpoints of s, such that no other point with the same restrictions is closer to s."
20:14:42 <djahandarie> I'm interpreting the "(below)" in both cases to mean that it can be either both above or both below
20:14:56 <c_wraith> yes, I agree with that much
20:15:01 <c_wraith> and that it's not well written
20:15:27 <djahandarie> On the bright side I found a paper about what I was trying to do
20:16:01 <ddarius> I interpret it as defining both "k vertical nearest neighbors above" and "... below" simultaneously.
20:16:19 <c_wraith> same thing, really
20:16:28 <ddarius> Incidentially, I understand that definition.
20:16:40 <c_wraith> Oh, a second readthrough, and it made enough sense
20:16:59 <c_wraith> But it probably could have been written more clearly
20:17:11 <c_wraith> and it leaves undefined points actually on S
20:17:13 <ddarius> c_wraith: The way I interpreted what you said is not the same as what I said.
20:17:59 <ddarius> c_wraith: That depends on the definition of the "above" and "below" relation.  If they are strict, then presumably the points on the line don't count.  If they aren't strict then presumably a point can be k-nearest above and below.
20:19:23 <ddarius> The definition does not uniquely characterize the k-nearest points (regardless of the definition of "above" or "below") despite the use of "the."
20:19:34 <c_wraith> anyway..  also, is "closer" vertical distance, or "nearest point in the segment" distance?
20:20:19 * djahandarie 's head is spinning
20:20:24 <ddarius> c_wraith: The metric probably doesn't matter, but probably the Euclidean one is intended, but maybe the one you suggest as well.
20:23:23 <sbahra> oi edwardk 
20:23:35 <edwardk> heya samy
20:57:59 <ketralnis> If i define a function "divide mid lst = (filter (<=mid) lst, filter (>mid) lst)", is Haskell smart enough to walk 'lst' only once?
20:58:08 <soupdragon> no
20:58:21 <aavogt> @type partition
20:58:22 <lambdabot> forall a. (a -> Bool) -> [a] -> ([a], [a])
20:58:23 <soupdragon> I think you will get this from attribute grammars
20:58:30 <soupdragon> but not plain haskel
20:58:35 <ketralnis> That makes sense
20:58:59 <aavogt> use another function which collects elements that are true and false separately
20:59:12 <soupdragon> you can derive a single walk from this definition using the algebra of programming
20:59:52 <kmc> ketralnis, the language standard does not require that degree of cleverness, and to my knowledge no compiler implements it currently
20:59:59 <soupdragon> first notice that they are both folds - then smash them together
21:00:11 <ketralnis> And my second question, I'm having trouble with syntax. I have a similar function here http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27121#a27121 but it doesn't compile with "temp.hs:11:37: parse error on input `='"
21:00:20 <kmc> but it's not an inconceivable optimization
21:00:36 <kmc> ketralnis, are you using tab characters in your source?
21:00:39 <ketralnis> I've played with it every which way but obviously I'm still learning and can't for the life of me see what I got wrong
21:00:54 <ketralnis> No, I have emacs in "don't ever use bloody tabs ever" mode
21:01:00 <kmc> good :)
21:01:12 <kmc> line 11 is the line 11 of that paste?
21:01:23 <kmc> oh, you don't need the "if" keyword there
21:01:26 <ketralnis> Yeah
21:01:29 <kmc> | x <= mid = ...
21:01:31 <Pwlahallpwk> http://tinyurl.com/hwpq102 - THE GAY NIGGERS HAVE A MESSAGE FOR YOU: You present a real and true perspective. A perspective of one who spends all his time surfing conspiracy websites and schizophrenic web forum postings, disregarding anything that conflicts with a predetermined conspiracist conclusion.
21:01:38 <kmc> @where ops
21:01:38 <lambdabot> shapr Cale glguy dons sjanssen sorear dcoutts Saizan dibblego conal Philippa bos arjanb psnl xerox vincenz davidhouse Heffalump kosmikus wli Pseudonym Igloo musasabi quicksilver monochrom
21:01:48 --- mode: ChanServ set +o monochrom
21:01:54 --- mode: monochrom set +b *!*@gateway/web/freenode/ip.69.167.158.167
21:01:54 --- kick: Pwlahallpwk was kicked by monochrom (Pwlahallpwk)
21:02:00 <ketralnis> kmc: oh! That's from a previous incarnation that was broken in some other way
21:02:00 <napping> kmc: I think supercompilation might handle it
21:02:02 <ketralnis> Thanks :)
21:02:12 <kmc> napping, i was wondering that
21:02:24 <kmc> didn't come to a conclusion either way
21:02:27 <napping> kmc: selector thunks are exactly to permit that sort of function to be written efficiently anyway
21:02:27 <lippersEnemn> http://tinyurl.com/hwpq102 - THE GAY NIGGERS HAVE A MESSAGE FOR YOU: Would you like another piece of waddymelon to go with that fried chicken and malt liquor? Beat it shitskin banjolips. This is a place for humans.
21:02:36 --- mode: monochrom set +b *!*@gateway/web/freenode/ip.221.130.17.20
21:02:49 <monochrom> seems time to disable webchat again?
21:03:29 <kmc> sigh
21:03:31 <bhiloerj_enemn> http://tinyurl.com/hwpq102 - THE GAY NIGGERS HAVE A MESSAGE FOR YOU: If your daughter listens to hip hop music, you should caution her against taking MDMA, commonly known as ecstasy if she plans to go to hip hop concerts or hip hop clubs. As everyone knows, when you add E to rap, you get RAPE.
21:03:36 <SubStack> o_O
21:03:59 --- mode: monochrom set +q *!*@gateway/web/freenode/*
21:04:52 --- mode: monochrom set -bb *!*@gateway/web/freenode/ip.69.167.158.167 *!*@gateway/web/freenode/ip.221.130.17.20
21:05:28 <napping> kmc: I guess it depends on the residuation process
21:06:05 <napping> (filter (<=mid) (x:xs), filter (>=mid) (x:xs)) would have to be split into something applied to the recursive call
21:06:17 <kmc> napping, hmm, can you explain how selector thunks work?
21:06:27 <kmc> i'm reading the ghc wiki section and it's sort of comprehensible
21:06:28 --- kick: qwwLippersPwk was kicked by monochrom (qwwLippersPwk)
21:06:32 --- kick: behwlgary was kicked by monochrom (behwlgary)
21:06:46 <napping> functions like (\(a,b)->a) turn into a very special kind of thunk
21:06:56 --- kick: bhiloerj_enemn was kicked by monochrom (bhiloerj_enemn)
21:07:03 <soupdragon> "a special kind of thunk"
21:07:04 <soupdragon> lol
21:07:05 <napping> it records what argument you want, and the thunk to project it from
21:07:12 <soupdragon> I don't know hyw just sounds funnnny
21:07:24 <napping> if the garbage collector sees that the target is evaluated, it evaluates the projection right away
21:07:44 <kmc> ok
21:07:49 <napping> e.g, in unzip ((x,y):zs) = let (xs,ys) = unzip zs in (x:xs,y:ys)
21:07:49 <kmc> so the point is to prevent leaks by holding onto b?
21:08:04 <kmc> prevent leaks which would result from holding onto b, i mean
21:08:33 <napping> suppose you have a definition like let (xs,ys) = unzip (zip [1..] [1..])
21:08:58 <napping> you'll get a thunk T = unzip (zip [1..] [1..]), and xs = proj 1 T, ys = proj 2 T
21:09:53 <napping> then if you force xs a bit, you'll get something like T = (1:proj 1 T2,2:proj 2 T2) T2 = unzip (zip [2..] [2..])
21:10:06 <napping> and xs evaluates to 1:proj 1 T2
21:10:27 <napping> and you can keep forcing down one list like that, and the pair of lists hangs around for a bit
21:10:58 <napping> but then the GC comes along, sees that ys = proj 2 T and T has already been evaluated to a pair, and replaces ys with the indirection to the snd of the pair
21:11:41 <napping> so only the second list will actually be retained by holding onto ys, even though it's defined in this intertwined way with pairs and matching on the recursive call
21:12:33 <kmc> i see
21:13:16 <kmc> hmm ghc has a lot of kinds of heap object
21:13:31 <napping> does it?
21:13:33 <kmc> yes
21:13:38 <kmc> http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects?redirectedfrom=Commentary/Rts/HeapObjects
21:13:51 <kmc> "A PAP [partial application] should never be entered, so its entry code causes a failure."
21:13:53 <kmc> i'm confused by this
21:14:06 <kmc> wouldn't «map succ `seq` ()» enter a PAP?
21:19:01 <Llyr> Hey guys, quick question. What's the time complexity for length?
21:19:45 <kmc> O(n)
21:19:50 <kmc> @src length
21:19:50 <lambdabot> Source not found. :(
21:20:00 <kmc> length [] = 0; length (x:xs) = 1 + length xs
21:20:00 <Llyr> Dang, I was hoping it was O(1).
21:20:11 <kmc> Llyr, lists are simple and lazy, but not fast
21:20:23 <Llyr> Duly noted. :/
21:20:38 <kmc> there are lots of other choices when you need fast
21:20:45 <Llyr> As an exercise, I'm trying to implement a queue.
21:21:08 <Llyr> I want at least amortized O(1) push and pop
21:21:20 <Llyr> but the solution I was just thinking of wanted length to be O(1).
21:21:25 <kmc> and in fact, you can make a singly linked list which caches the length at every node.  but you'll never have O(1) push and pop at both ends
21:21:58 <napping> kmc: I assume it checks the info before trying to enter it, or maybe uses pointer tagging
21:22:09 <kmc> yeah
21:22:11 <FunctorSalad> does cabal-install somehow support full-info search?
21:22:23 <napping> kmc: it says functions have entry code that evaluates an application, so you can't just blindly enter those either
21:22:26 <FunctorSalad> other than writing your own loop in the shell ;)
21:22:32 <kmc> napping, i guess i'm still thinking of STG in terms of push/enter, but it's moved to eval/apply
21:22:43 <kmc> i'm reading the "making a fast curry" paper again
21:22:58 <napping> Llyr: you can make your own type that keeps the length
21:23:00 <Llyr> kmc: Yeah, I know I'm not going to get O(1) on both ends, but I think I can get O(1) on one end and amortized O(1) on the other end.
21:23:04 <napping> do yo uhave a copy of Okasaki?
21:23:05 <CakeProphet> what is pseq? parallel seq? What would that be used for?
21:23:14 <CakeProphet> also par
21:23:34 <Llyr> napping: That's not a bad idea. Maybe I'll think about that if I can't find a way around needing length.
21:23:51 <napping> it's one of the standard bootstrapping tricks
21:24:05 <napping> along with making a wrapper that holds the smallest/first/tip element
21:24:15 <kmc> CakeProphet, par does (potentially) parallel evaluation
21:24:22 <kmc> whereas pseq is very much like seq
21:24:25 <kmc> it's not parallel
21:24:26 <napping> How do you think you can get worst-case O(1) on one side?
21:24:43 <kmc> CakeProphet, for the differences  between seq and pseq see http://www.mail-archive.com/glasgow-haskell-users@haskell.org/msg10973.html
21:24:58 <FunctorSalad> for x in $(cabal list --simple | sed -Ee 's/(\S)+.*/\1/ ); do cabal info $x | grep generic; done
21:24:59 <FunctorSalad> =)
21:25:13 <FunctorSalad> (\S+)
21:25:15 <FunctorSalad> in the regex
21:25:25 <Llyr> napping: So I was thinking about arrays in Ye Olde Imperative Language, and how they have amortized O(1) insertion, right?
21:25:51 <napping> um, I guess. I don't entirely believe you can index an arbitrarily large array in constant time
21:26:09 <kmc> Llyr, Haskell has those arrays too
21:26:15 <napping> but don't worry about that
21:26:21 <Llyr> napping: You preallocate yourself a bunch of slots, and when you fill up the last slot and try to add another element, you allocate yourself twice the current size of the array and copy the old array into it.
21:26:24 <napping> anyway, you were saying worst-case O(1)?
21:26:32 <napping> sure, that gets you amortized
21:26:36 <Llyr> napping: That's an O(n) operation, but its ... exactly.
21:27:03 <Llyr> napping: So I was thinking of something similar for a queue.
21:27:06 <napping> um, actually O(1) insert is easy to get in a single-threaded structure, isn't it
21:27:28 <napping> Queue a = Queue [a] [a]
21:27:35 <napping> cons onto one list to insert
21:27:40 <napping> pop off the other list to remove
21:27:45 <nyingen> > let 2 = 3 in 2
21:27:46 <lambdabot>   2
21:27:53 <nyingen> it seems like that ought not to work
21:27:53 <napping> reverse the first list into the second when a pop comes up empty
21:27:58 <Llyr> napping: Assume that pop is O(1). How can we get push to be amortized O(1)? I mean, you're never going to get exactly ..
21:27:59 <Llyr> Yeah
21:28:05 <Llyr> That's basically what I was going for.
21:28:07 <Llyr> Except!
21:28:15 <Llyr> If you do it that way, you're not amortizing right.
21:28:15 <napping> backwards - pop is amortized O(1)
21:28:26 <napping> no, what goes wrong is it's not persistant
21:28:36 <Llyr> Because your cost is paid off *after* your big operation, instead of before.
21:28:42 <napping> Queue "long stuff" "" is in a state where popping is expensive
21:28:52 <Llyr> Exactly, and if you only pop once?
21:28:54 <Llyr> You're screwed.
21:28:56 <napping> ... that's why it's only okay if you use it in a single threaded way
21:29:02 <napping> nah, you can put the cost on the inserts
21:29:19 <Llyr> Not really - that single pop just cost you O(n).
21:29:24 <napping> you did N constant time pushes, and one pop that took N time
21:29:30 <napping> still 2N = O(1) per op
21:29:40 <Llyr> Right, but each operation should separately be O(1).
21:29:47 <napping> Sure, it is
21:30:01 <wli> Each operation separately isn't amortized accounting.
21:30:11 <napping> you spend an extra unit of time on the worst-case O(1) push, and store that little bit of extra time on the cons cell
21:30:19 <napping> then you use that time on the popping
21:30:31 <Llyr> Here's the way I was thinking about it, and correct me if I'm wrong.
21:30:45 <Llyr> Go back to the amortized O(1) insertion into arrays, right?
21:30:54 <napping> it's amortized cause you had to call up credits, but still O(1) net time
21:31:00 <napping> you really need a copy of Okasaki
21:31:09 <Llyr> Your big O(n) operation is coming up on like a 2^k'th element.
21:31:23 <napping> he eventually defined confluently persistent dequeues with strict worst case O(1) cost
21:31:27 <Llyr> But that operation was paid for by the O(1) insertions from 2^(k-1) to 2^k - 1.
21:31:27 <CakeProphet> if an exception is left unhandled in a thread, will it exit the whole program or only kill the thread?
21:31:35 <napping> CakeProphet: only the thread
21:31:38 <CakeProphet> good. :)
21:31:49 <napping> um, might be careful if it's the main thread
21:32:03 <CakeProphet> killing main kills the whole program, yes?
21:32:14 <napping> Llyr: yes, that's the usual credit analysis
21:32:20 <Llyr> So you're building up a savings account and spending it on a big O(n) operation, rather than going into debt for an O(n) and paying it back later.
21:32:40 <Llyr> So if you're like, Queue "long stuff is long" ""
21:32:46 <Llyr> and you pop just once?
21:32:57 <Llyr> Your pushes were all O(1), that's true, but your pop was O(n).
21:33:14 <Llyr> And you don't ever get the chance to pay back that O(n) debt with the faster pops afterwards.
21:33:17 <napping> that's why I said that structure works if you use the queue in a single-threaded way
21:33:46 <Llyr> I'm not sure what you're going at there.
21:33:56 <napping> if you only use each version once, then you have the credits from the pushes
21:34:09 <napping> if you want a persistent structure, then debt analysis is more reliable
21:34:54 <Llyr> I guess the thing I'm really disbelieving you on is, how can the cheap pushes (which I'm taking for granted) amortize an expensive pop?
21:35:11 <napping> Llyr: it only can if you enforce linearity
21:35:25 <Llyr> so I'm not entirely sure I even believe you if you have linearity.
21:35:29 <napping> if you are not allowed to do something like let q = .. in pop q, pop q
21:35:39 <Llyr> like, how is one function allowed to pay off another?
21:35:49 <napping> if you do have linearity, then the only way to get to Q "bigbig" "" is by having dones N pushes
21:36:03 <napping> A cons actually takes 1 time
21:36:13 <Llyr> Right.
21:36:14 <CakeProphet> question: can labelThread be called more than once?
21:36:19 <napping> you promise instead to do a cons in 2 time, worst case
21:36:28 <napping> and to do a pop in 1 time, worst case
21:36:55 <napping> that is - you promise that for any queue state q, you can force (push _ q) in 2 time, worst case
21:37:19 <napping> amortized, you are just promising that if you start with the empty queue and to M pushes and N pops, the total time will be at most 2M+N
21:37:40 <Llyr> I suppose that makes enough sense.
21:37:55 <napping> so each push you do, you are allowed to take 2 time and only actually took 1 time, so you are one step ahead
21:38:12 <Llyr> Right, and those extra credits are applied to the N time you need to reverse the list and start popping.
21:38:18 <napping> you can define a potential function on the whole structure computing the extra time, or track it as "credits" on individual constructor
21:38:22 <napping> yeah
21:38:28 <monochrom> seems like the trolling has subsided, safe to allow webchat again
21:38:28 <djahandarie> Man, I swear some papers would be 100x easier to read if they just had some code in them
21:38:31 <napping> so as long as you use it linearly you never fall behind
21:38:41 --- mode: monochrom set -q *!*@gateway/web/freenode/*
21:39:10 <napping> that all goes out the window when you want a persistent structure
21:39:12 <Llyr> And 2 time is still O(1) time.
21:39:22 <Llyr> Meh, I'm not interested in using this in a multithreaded environment.
21:39:38 <napping> persistent here just means being able to save old versions
21:39:40 <napping> or fork a structure
21:40:13 <Llyr> Yeah, I don't see myself using it in either of those situations either.
21:40:32 <Llyr> mostly I'm writing it as an exercise in data structures in functional programming...
21:40:51 <Llyr> Eventually I want to implement a priority queue and use it to generate prime numbers, based on this interesting paper I read.
21:42:11 <Llyr> All right guys, and especially napping, thanks for your help.
21:42:42 <Llyr> I might be back later if this thing starts exploding at me. :)
21:46:57 <CakeProphet> can someone explain alwaysSucceeds?
21:47:04 <CakeProphet> I'm having trouble following the logic and the use.
21:48:06 <gwern> I wonder if Llyr realized that there are many priority queues in haskell
21:48:22 <Jafet> Always room for one more.
21:48:42 <napping> didn't sound like a priority queue, just a plain queue
21:48:50 <napping> CakeProphet: It seems funny
21:49:24 <napping> the explanation suggests it adds a global invariant, but I have no idea how you could remove it
21:50:24 <CakeProphet> so basically the invariant must always suceed or it will trigger an exception in the transaction that causes it to fail?
21:51:02 <napping> that's what it sounds like, but the scope isn't clear
21:51:21 <CakeProphet> it says "at the end of every subsequent transaction" so I assume it's global.
21:52:15 <CakeProphet> I'm wondering if it always throws an exception, or if the exception must be thrown explicitly.
21:52:28 <CakeProphet> because it could simply cause a standard STM failure
21:53:14 <napping> I think a paper mentioned something like that, but research.microsoft.com seems to be down again
21:54:26 <CakeProphet> unsafeTOToSTM.  hahaha. I love Haskell because it gives you all these terrible ways to break everything.
21:55:18 <Jafet> For truly lazy programmers
21:56:50 <Jafet> CakeProphet: T next to I? Weird layout
21:57:24 <BMeph> CakeProphet: That function's as tame as id compared to `unsafeFunctionCallOfC'Thulhu`... ;)
21:57:32 <CakeProphet> hahaha
21:57:38 <nyingen> anyone know why 'let 2 = 3 in 2' parses?
21:57:53 <CakeProphet> > let 2 = 3 in 2
21:57:54 <lambdabot>   2
21:57:56 <nyingen> it seems like 'let 2 = ...' should cause an error, but obviously it doesn't
21:58:01 <nyingen> I'm curious about this
21:58:04 <Axman6> no it shouldn't
21:58:24 <Axman6> you're pattern matching, which happens lazily
21:58:32 <Axman6> > let x@2 = 3 in x
21:58:33 <lambdabot>   *Exception: <interactive>:1:145-151: Irrefutable pattern failed for pattern...
21:58:35 <CakeProphet> yeah I was going to say lazy evaluation is probably why
21:58:45 <Axman6> there is no evaluation
21:58:54 <nyingen> ah, hm
21:59:10 <Axman6> if you say let x = y in <some expression not using x> then that's exactly the same as the expression that doesn't use x
21:59:23 <nyingen> I was thinking about it syntactically, as in, why is '2' allowed in that position, where one would normally see some kind of identifier
21:59:27 <Jafet> > let 2 + 2 = 5 in 2 + 2
21:59:28 <lambdabot>   5
21:59:38 <nyingen> but yeah, it's not evaluated, because even though 2 appears on the right, it's just a literal
21:59:46 <CakeProphet> nyingen:  same reason 2 is allowed in a case statement.
22:00:05 <pastorn> joed_: booo
22:00:11 <nyingen> heh, duh. I should have realized that
22:00:14 <pastorn> Jafet: ^^^ (sorry joed_)
22:00:27 * Jafet throws pastorn down the memory hole
22:00:44 <nyingen> Room 101
22:01:02 <CakeProphet> > let x = undefined; y = 3 in y   --nyingen 
22:01:03 <lambdabot>   3
22:01:33 <nyingen> Yeah, I understand the lazy aspect. It just seemed odd that you could equate a literal with anything
22:01:42 <CakeProphet> nyingen:  you can't.
22:01:42 <nyingen> but I see now how it falls out from the laziness
22:02:57 <CakeProphet> nyingen:  what you are doing in that case is pattern matching.  2 = 3 doesn't bind 3 to 2 it attempts to match 3 to 2, which will fail. But since nothing ever refers to it this pattern match never occurs and thus no error.
22:03:58 <CakeProphet> > case 3 of 2 -> "Hello, World!"
22:03:59 <lambdabot>   "*Exception: <interactive>:1:141-170: Non-exhaustive patterns in case
22:04:20 <Cale> nyingen: things like 2 = 3 are basically just a corner case of the syntax. You can write f 2 = 3, to define f, which means that there must be numeric literal patterns. You can also take any pattern and directly bind it to some expression
22:04:43 <CakeProphet> > case 3 of 2 -> "Hello, World!"; _ -> undefined
22:04:44 <lambdabot>   "*Exception: Prelude.undefined
22:05:12 <Cale> As in  (x,y) = break (== ' ') "hello world"
22:05:29 <nyingen> I see
22:05:30 <Cale> so, put those two things together, and you can get the silly things like 2 = 3 :)
22:06:15 <CakeProphet> > let (x,y) = (undefined, 3) in y
22:06:17 <lambdabot>   3
22:09:30 <ski> > case (3,"hey !") of (2,x) -> x
22:09:31 <lambdabot>   "*Exception: <interactive>:1:141-170: Non-exhaustive patterns in case
22:10:03 <ski> > case (3,"hey !") of (2,x) -> "not x"
22:10:04 <lambdabot>   "*Exception: <interactive>:1:141-176: Non-exhaustive patterns in case
22:10:50 <ski> > case (False,(3,"hey !")) of (b,~(2,x)) -> b
22:10:51 <lambdabot>   False
22:11:01 <ski> > case (False,(3,"hey !")) of ~(b,(2,x)) -> b
22:11:02 <lambdabot>   *Exception: <interactive>:1:141-183: Irrefutable pattern failed for pattern...
22:11:04 <ski> > case (False,(3,"hey !")) of ~(b,(2,x)) -> ()
22:11:05 <lambdabot>   ()
22:11:08 <ski> > case (False,(3,"hey !")) of ~(b,~(2,x)) -> b
22:11:09 <lambdabot>   False
22:18:15 <Chris> af/ws 5
22:21:56 <Yrogirg> Hello! What CAS are you using if any? What CAS resembles Haskell most? Axiom?
22:23:15 <etpace> Hmm. I'm trying to time/benchmark some pure functions, but laziness/memoisation seems to be screwing with the results, any ideas? i've got a force to force evaluation but the memoisation is still there
22:23:15 <Cale> Yrogirg: I tend to use Mathematica. It doesn't resemble Haskell very much. It resembles how Lisp was originally intended to look before Lisp people got hooked on S expressions.
22:24:51 <Axman6> etpace: there is no memoisation in haskell unless you implement it
22:25:08 <etpace> hmm]
22:25:26 <etpace> I wonder what could be messing with the results then
22:25:34 <Cale> etpace: Except that each variable, as long as it remains in scope, won't be evaluated more than once.
22:26:08 <Cale> So, for instance, you can use a constant lazy array to implement memoisation.
22:26:36 <Cale> But if you write something like f x + f x, it will evaluate the application of f to x twice.
22:28:32 <etpace> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27127#a27127
22:28:44 <etpace> a in this context is merging some lists, and i have three different implementations i want to check
22:28:49 <gwern> etpace: use criterion?
22:28:51 <etpace> but haskell seems to be saving some result
22:28:57 <gwern> etpace: it's supposed to take care of that for you
22:29:06 <etpace> i would rather keep it lightweight, as its just a few simple functions
22:29:13 <etpace> but ill keep it in mind if i cant figure this out 
22:29:27 <gwern> criterion isn't that heavyweight
22:29:31 <Cale> etpace: Use Control.Exception.evaluate
22:29:36 <gwern> the second time you use it, anyway
22:29:37 <Cale> To sequence evaluation with IO
22:29:59 <kmc> evaluate (rnf x)
22:30:06 <kmc> evaluate from Control.Exception, rnf from Control.DeepSeq
22:30:42 <Axman6> etpace: i don't think your force function does very much, except run along the spine of the list. you don't want to evaluate the elements?
22:30:57 <etpace> thats true
22:31:09 <etpace> so use evaluate and rnf instead of force?
22:31:19 <Axman6> what you want is something like go (x:xs) = x `seq` go xs
22:31:30 * Axman6 would use deepSeq
22:32:17 <Cale> Oh, right, you're forcing the spine of the list, but not necessarily any of its elements
22:32:25 <Cale> Is that really what you want?
22:33:24 <edwardk> preflex: xseen gracenotes
22:33:24 <preflex>  gracenotes was last seen on freenode/#haskell-blah 1 day, 8 hours, 7 minutes and 32 seconds ago, saying: tensorpudding: aka pythonic
22:33:58 <etpace> it's not Cale
22:34:05 <etpace> i was trying to force evaluation basically
22:34:07 <etpace> as seq wasnt doing it
22:35:12 <Gracenotes> edwardk: hi
22:35:45 <CakeProphet> etpace:  but that's what seq does...
22:36:25 <Cale> seq xs y  where xs is a list will evaluate xs just far enough to determine if it's an empty list or not
22:37:46 <CakeProphet> > [0..] `seq` "Hi I'm lambdabot"
22:37:47 <lambdabot>   "Hi I'm lambdabot"
22:37:54 <CakeProphet> so it seems.
22:37:54 <kmc> etpace, see also http://hackage.haskell.org/packages/archive/parallel/2.2.0.1/doc/html/Control-Parallel-Strategies.html
22:38:13 <kmc> yeah, seq forces only to weak head-normal form (whnf), meaning only to the outermost constructor, which here is (:)
22:38:38 <kmc> seq :: [a] -> b -> b; seq [] x = x; seq (_:_) x = x
22:38:51 <kmc> this implement seq as specialized to the type [a]
22:39:37 <etpace> hmm, it seems I cant use rnf as I don't have NFData for my custom datatype
22:39:45 <CakeProphet> > [undefined, 0] `seq` 1
22:39:47 <lambdabot>   1
22:40:20 <CakeProphet> > (undefined, 0) `seq` 1
22:40:22 <lambdabot>   1
22:40:39 <kmc> > Just undefined `seq` 1
22:40:40 <lambdabot>   1
22:41:20 <kmc> etpace, right.  if you want to force your data type "all the way", you have to write your own function to do so, and you might as well make that an NFData instance
22:41:32 <kmc> there might be a way to do it with SYB
22:42:55 <etpace> I just implemented a rnf (R x y) = x `seq` y `seq` (), but it doesnt really help
22:43:05 <etpace> infact, now it says all my functions are 0.000 time 
22:43:06 <turiya> can getLine and putStrLn be sequenced without using monads?
22:43:12 <etpace> (after replacing force with evaluate . rnf
22:45:14 <CakeProphet> turiya:  no. Why would you want to do that?
22:45:55 <turiya> CakeProphet: was just trying to understand the (>>) operation
22:47:07 <CakeProphet> turiya:  ah. well in the case of the IO monad, there is no way to "escape" it.
22:47:49 <turiya> CakeProphet: yes, that was my problem, for the other monads, one need not use the monadic combinators
22:50:12 <CakeProphet> turiya: here is unsafePerformIO, but it is, obviously, unsafe.
22:50:14 <CakeProphet> *there
22:50:40 <CakeProphet> turiya:  :: IO a -> a
22:51:18 <ski> @tell napping hm, would you happen to know whether (re selector thunks) Christina von Dorrien's lic. thesis "Stingy Evaluation" (1989-05) is available online somewhere ?
22:51:18 <lambdabot> Consider it noted.
22:51:25 <ski> gwern : criterion ?
22:51:42 <turiya> CakeProphet: the implementation of (>>) for IO is in a way very different from ordinary functions in haskell as the arguments are executed in order..is that right?
22:52:19 <ski> turiya : functions doesn't execute anything
22:52:36 <ski> you need to distinguish between execution and evaluation
22:52:59 <CakeProphet> turiya:  well no, >> works like a regular function. There is no evaluation order imposed. The seq primitive function does that.
22:53:33 <ski> `(>>)' is a function that combines two actions (like `IO'-actions, e.g.), into a new action. and *that* action, when executed, will execute the two first actions in order
22:53:54 <ddarius> turiya: It's that IO is an abstract type that makes you need to use the monad combinators, not that the monad combinators are something magical.  They are just functions.
22:54:21 <ski> note that this still doesn't say anything about whether the first argument of `(>>)' is *evaluated* before the second, or vice versa (or some other variant)
22:55:33 <turiya> ski: so effectively (>>) does glue the IO actions in order..
22:56:38 <turiya> i am trying to understand at what point exactly "order" comes into haskell.. as otherwise there would be no order due to laziness
22:56:45 <ski> it glues two actions together into a new action, which when executed will first evaluate the two actions in any order (maybe in parallel, maybe not), and execute them in order from left to right
22:56:49 <CakeProphet> > [undefined] >> [1,2,3,4]
22:56:50 <lambdabot>   [1,2,3,4]
22:57:17 <pastorn> > [undefined,undefined] >> [1,2,3,4]
22:57:19 <lambdabot>   [1,2,3,4,1,2,3,4]
22:57:36 <CakeProphet> > undefined  --what happens when undefined is evaluated
22:57:40 <lambdabot>   *Exception: Prelude.undefined
22:57:48 <ski> in the case of the list monad, the execution ordering corresponds to nesting of "for loops", roughly
22:58:21 <ski> in the case of the `IO' monad, the execution ordering corresponds to a sequential ordering in time
22:59:36 <ski> in the case of the `Reader r' monad, the execution ordering doesn't really correspond to any ordering at all (it just disappears, becomes irrelevant)
23:00:41 <turiya> ski: so the bind operation in these two monads are fundamentally different?
23:00:43 <ski> (so, in the reader monad, `do x <- foo; y <- bar; return (x,y)' is the same as `do y <- bar; x <- foo; return (x,y)')
23:00:56 <ski> yes
23:01:26 <turiya> ok..finally it boils down to the implementation of (>>) in the respective monad
23:01:42 <CakeProphet> >> is defined in terms of >>=
23:01:53 <CakeProphet> I think in all cases? I'm not sure.
23:02:04 <kmc> yes turiya
23:02:07 <ski> a monad is defined by : (a) a type constructor `m', (b) two operations `return' and `(>>=)' that has `m' in their types, and (c) the `return' and `(>>=)' operations need to satisfy s few natural laws
23:02:20 <kmc> laziness is about evaluation; evaluation order is supposed to be irrelevant and monads don't change that
23:02:29 <kmc> monads define execution order by defining what (>>) means
23:02:40 <Cale> It always can be, and in all cases its behaviour should satisfy  x >> y = x >>= const y, but instances are allowed to define what >> means separately
23:02:43 <ddarius> turiya: One conceivable way to implement IO is to have IO a be a String that is the source code of a C program that would produce an a value when executed.  Then M >> N could simply be M++N.  This just makes a String.  Nothing happens.  Eventually we give that String to a C implementation that executes the code.
23:02:43 <ski> this is similar to how a queue is a type constructor, some operations, and a few laws relating them
23:02:57 <turiya> kmc: yes..
23:03:03 <CakeProphet> turiya, (>>) m n = m >>= (\_ -> n)
23:03:23 <kmc> CakeProphet, it's allowed to overload (>>) separately from (>>=), but it should always be equivalent to that
23:03:29 <turiya> CakeProphet: yes, the relation between (>>) and (>>=) always holds
23:03:34 <turiya> i think
23:04:02 <ski> yes, it's a law that `(>>)' and `(>>=)' are supposed to satisfy
23:04:07 <ddarius> The C implementation could choose to execute the code in some non-standard way, e.g. backwards, in which case M >> N would "do" N first then M.  The "execution ordering" comes from whatever interprets the IO data structure, which is the run-time system in Haskell.
23:04:50 <kmc> turiya, another answer to "can getLine and putStrLn be sequenced without using monads": yes, we can pretend that (>>=) :: IO a -> (a -> IO b) -> IO b, and we can do IO just fine without recognizing this generalization called "monads"
23:05:23 <turiya> kmc, i meant without using (>>) or (>>=)
23:05:37 <ski> turiya : fine, call it `primBindIO', if you want
23:05:57 <kmc> turiya, ok. an implementation could provide an IO-specific bind operator
23:06:04 <ski> @src IO (>>=)
23:06:04 <lambdabot> m >>= k     = bindIO m k
23:07:38 <kmc> GHC's IO implementation is based on lies and trickery
23:07:42 <turiya> ski, eg: for the Maybe monad, anything that can be done using (>>=) can also be done otherwise
23:07:48 <ski> this `bindIO :: IO a -> (a -> IO b) -> IO b' is just a primitive operation, just like `plusInt :: Int -> Int -> Int' could be
23:08:09 <ski> turiya : that is because `Maybe' is a defined type, rather than a primitive, abstract type
23:08:14 <kmc> turiya, there's another angle here, which is that IO is an abstract data type (no exposed constructors), whereas Maybe and [] aren't
23:08:30 <ddarius> turiya: That's only because Maybe isn't an abstract data type.  An analogy could be Data.Set.  Your question is like asking "Can I make a Set without using empty, singleton, or fromList?"
23:08:35 <kmc> there are other monads which are abstract types
23:08:38 <ski> turiya : how would you define `plusInt :: Int -> Int -> Int' yourself (without `n+k' patterns) ?
23:09:55 <ski> (s/defined/in-language defined/)
23:10:03 <turiya> ok.. IO is an abstract data type ..  did not know this ..
23:10:07 <CakeProphet> @src STM (>>=)
23:10:07 <lambdabot> Source not found. Sorry.
23:10:12 <CakeProphet> :)
23:10:47 <turiya> i did try to see what it was and there was a bunch GHC.RealWorld etc..
23:11:02 <CakeProphet> @src Control.Concurrent.STM (>>=)
23:11:02 <lambdabot> Source not found. Just try something else.
23:11:14 <CakeProphet> aw.
23:12:00 <ddarius> turiya: Yes, and using those (obviously very non-standard/non-public) interfaces, you could write IO functions without using (>>=) and co.  Though they may still not really work because GHC's implementation of IO is a hack.
23:12:32 <turiya> ddarius: a hack?
23:13:07 <ddarius> The implementation requires special cases in the compiler to work.
23:13:18 <turiya> ok..
23:14:22 <ski> (well, i wouldn't really say that that necessarily implies it is a hack ..)
23:14:29 <ski> (.. which it is, i suppose)
23:15:16 <kmc> turiya, you could make a Haskell implementation where IO is not an abstract type, yet things mostly work out
23:15:36 <kmc> for example, the above mentioned "data IO a = IO { codeOfCProgram :: String }"
23:15:53 <quicksilver> the thing to recognise about the implementation using RealWorld#, is that that is not haskell.
23:15:55 <ddarius> ski: One way to describe at least one issue is that for the conceptual model behind GHC's implementation of IO to work, RealWorld should be linearly typed, but GHC doesn't have that notion so the optimizations in the compiler have to be tweaked to make sure they don't accidentally duplicate or drop RealWorld.
23:15:59 <turiya> kmc, then we would not be forced to use (>>=) etc.. even thought there would be no reason to ?
23:16:05 <turiya> though*
23:16:12 <quicksilver> so it may be interesting, and it may possibly be enlightening if you understand it well enought
23:16:20 <kmc> turiya, then you could write arbitrary C programs and give them IO types, yes
23:16:23 <quicksilver> but it doesn't show you how you might implement IO in haskell
23:16:26 <kmc> though nothing will keep your C programs type-safe
23:17:25 <kmc> another example of non-abstract IO is is the GADT IO type: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27131#a27131
23:17:29 <kmc> this is mostly pretty safe
23:17:46 <ski> ddarius : *nod* (i just meant that the fact that it's special-cased doesn't necessarily imply it's a hack)
23:18:09 <kmc> you can't use this GADT to do anything silly like unsafePerformIO or breaking the type system
23:18:18 <kmc> because the values of this GADT are just totally inert constructor applications
23:18:33 <ddarius> ski: I understood, but I decided to give my reply anyway once you added the "i suppose."
23:18:48 <kmc> it does break the monad laws for IO, because you can pattern-match and distinguish ((a >> b) >> c) from (a >> (b >> c))
23:18:57 <turiya> ok..
23:19:08 <ski> kmc : though, you'll need to make that abstract (so that you actually get a quotient of that), to make the monad laws work
23:19:13 <kmc> yes
23:19:29 <ski> possibly if you use a CPSed version, you can avoid that
23:20:00 <kmc> you could implement IO using MonadPrompt
23:20:16 <kmc> and you'd have non-abstract primitive actions
23:20:20 <kmc> but monad laws preserved
23:20:41 <ski> i.e. call the GADT type `IOResult' (maybe changing some things) and then define `newtype IO a = MkIO (forall o. (a -> IOResult o) -> IOResult o)' or something like that
23:21:10 <ddarius> ski: That's always a monad regardless of what is placed in the "IOResult o" positions.
23:21:25 <ski> ddarius : yes
23:22:10 * ski wonders what happens if you put `IOWriteRef' in place of `IOResult', there ..
23:22:25 <ddarius> Nothing.
23:24:05 <ski> hm, i see
23:24:29 <ski> @hoogle (a -> IORef a) -> IO (IORef a)
23:24:29 <lambdabot> Control.Monad.Fix mfix :: MonadFix m => (a -> m a) -> m a
23:24:29 <lambdabot> Control.Monad.Cont runContT :: ContT r m a -> (a -> m r) -> m r
23:24:29 <lambdabot> Prelude (=<<) :: Monad m => (a -> m b) -> m a -> m b
23:24:32 <CakeProphet> hmmm
23:24:49 <ski> er
23:24:56 <ski> @hoogle (IORef a -> a) -> IO (IORef a)
23:24:56 <lambdabot> No results found
23:24:57 <ski> i meant
23:25:16 <CakeProphet> >>! m n = m >> (m `seq` n)   --???
23:25:28 <CakeProphet> (>>!)
23:25:42 <ski> CakeProphet : when would that be useful ?
23:25:46 <CakeProphet> no clue
23:25:49 <CakeProphet> just a thought. :)
23:28:05 <ski> @type mfix . (Data.IORef.newIORef .)
23:28:06 <lambdabot> forall a. (GHC.IOBase.IORef a -> a) -> IO (GHC.IOBase.IORef a)
23:28:10 <kmc> @src ($!)
23:28:10 <lambdabot> f $! x = x `seq` f x
23:28:39 <ski>   f $! !x = f x  -- :)
23:29:27 <etpace> http://hpaste.org/fastcgi/hpaste.fcgi/view?id=27133#a27133 <- A strikefile is just [ByteString], Can anyone tell me why this is slower than the supposedly naiive solution of: sort . concat listOffiles? (using Data.List.Sort)
23:29:46 <turiya> can someone suggest me a good place to learn about Arrows?
23:31:38 <ski> turiya : maybe the papers at <http://www.haskell.org/arrows/> ?
23:31:59 <kmc> turiya, out of curiosity, why do you want to learn arrows?
23:32:19 <ddarius> kmc: Never ending quest for the magic.
23:32:27 <turiya> kmc: i was trying to write a GUI with wxFruit
23:32:31 <kmc> ok
23:33:02 <turiya> ddarius: thats true as well
23:33:17 <ski> maybe also the papers on Fudgets (thogh that is pre-arrows, i think it could have used arrows)
23:34:05 <kmc> etpace, did you compile your code with -O2 and run it with +RTS -s
23:34:21 <kmc> optimization is important, and the RTS option will print some useful information
23:34:28 <turiya> ski: thanks, i will look there
23:36:46 <etpace> it compiles with O2, I didnt use the -s though
23:36:46 <kmc> etpace, you're doing what looks like a parallel fold, but that's not too effective on a cons list
23:36:47 <etpace> ill try now
23:37:02 <ski> turiya : there's some FRP libraries using arrow notation too .. e.g. yampa iirc
23:37:06 <etpace> yeah im trying to do a parallel fold, but a more divide and conquer-y way
23:37:16 <kmc> etpace, for a parallel associative fold you want to split the list in half recursively, probably to some fixed depth
23:37:35 <kmc> and splitting a list in half is inefficient, so you want the input to be a tree
23:37:40 <kmc> a balanced binary tree
23:38:42 <etpace> it also seems to become a lot slower the more cores I use kmc
23:38:55 <etpace> is that consistent with the splitting of lists?
23:39:09 <ski> if `merge' is commutative, it should do as well to take each other element as etpace is doing, no ?
23:39:36 <kmc> etpace, don't know.  ThreadScope may be useful
23:39:43 <kmc> but i think fixing the list split is essential
23:40:09 <ski> (and what effectively gives a mostly balanced tree .. not sure whether the tree is built in right order for this to matter, though)
23:40:27 <ski> (s/built/"built"/)
23:40:45 <etpace> my idea was kind of a double fold, pair up the list merging them, and come back through merging them into back to the final result
23:40:52 <etpace> ill try the binary tree implementation
23:41:22 <ddarius> ski: To get what you want that way, you'd need to feed merge back into itself until you got to a trivial case.
23:41:23 <ski> hm, actually ..
23:41:36 <ski> ddarius : yeah, i just realized etpace wasn't doing that :(
23:43:00 <ski> etpace : so, try transform `[x0,x1,x2,x3,...]' into `[merge x0 x1,merge x2 x3,...]' repeatedly until you're left off with `[x]'
23:43:28 <ddarius> ski: That doesn't rely on commutativity.
23:43:39 <ski> (it might still be better to pre-transform into a tree .. or use parallel arrays .. i don't know)
23:43:54 <ski> .. hm, i guess it doesn't
23:44:18 * ski was thinking of something else, apparently, when he said that on commutativity
23:45:43 <ski> (oh, right, apparently my mind was secretly thinking about top-down merging, without telling me)
23:51:46 <etpace> ok thanks ski kmc, ill have a go
23:53:22 <CakeProphet> @let
23:53:24 <lambdabot>  Defined.
23:53:27 <CakeProphet> :o
23:57:05 <dmwit> :t let foldb f z [] = z; foldb f z [x] = x; foldb f z xs = foldb f z (chunk xs) where chunk (x:y:zs) = f x y : chunk zs; chunk xs = xs in foldb
23:57:06 <lambdabot> forall a. (a -> a -> a) -> a -> [a] -> a
