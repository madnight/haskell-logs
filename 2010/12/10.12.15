00:01:02 <redd_> We can establish equality of functions outside the language, however. Surely nobody thinks that computing equality of functions (with infinite domains, etc.) is necessary in order to treat functions as values.
00:01:27 <Cale> right
00:02:45 <Cale> But it means that (computational) sets in our language can only represent some of the finite sets of values in our language.
00:02:52 <redd_> Which means, essentially, that having a method for determining equality cannot determine whether something is a value or is of a type in a language, I guess.
00:03:09 <redd_> Yes, you're right.
00:05:46 <redd_> I guess: those finite sets being sets of values over which a total ordering can be defined (hence the ordering restriction in Haskell).  It's interesting, because we're used to defining a set in terms of predicates or functions.
00:06:20 <Cale> yeah
00:06:47 <Cale> And while we can have functions  a -> Bool  those are really not very satisfying as computational sets
00:07:06 <Cale> (at least, not for most of the uses of Data.Set)
00:08:28 <c_wraith> seems like merging them with liftM2 (||) would get slow, eventually
00:09:57 <c_wraith> well, the merge is always fast, but queries would get slower and slower
00:10:05 <redd_> I'm not sure what you mean. Certainly it's necessary to form sets using functions a -> Bool, i.e., a predicate determining membership?
00:11:23 <c_wraith> he means the a -> Bool representation isn't very good for many of the purposes Data.Set is used for
00:12:19 <redd_> Ah, I thought you meant using a function a -> Bool to define a set S from a set of elements of type a.
00:12:40 <redd_> But yes, that makes sense.
00:12:56 <quicksilver> c_wraith: well you end up with O(modifications)
00:13:09 <quicksilver> c_wraith: which, in some circumstances, might be faster than O(log n)
00:13:28 <quicksilver> c_wraith: but overall, it's clearly less satisfactory, because it's opaque
00:14:16 <quicksilver> (also have to consider the complexities of the atomic a -> Bools!)
00:24:34 <Saizan_> Set.elems wouldn't be very nice
01:11:14 <redd_> I have <http://pastebin.com/KezKaftA>, converts a rule in a CFG to a set of rules in CNF. Is there some way to assert the initial return value for a stateful function without saying something like "return S.empty", etc.?
01:21:43 <redd_> ah, nevermind. foldM looks like what I want.
01:26:06 <tsbo> Is there a filter equivalent for the enumerator package? I.e. dropping chunks that fail some predicate.
01:30:03 <ajnsit> is there a way to quickly search within a BlazeHTML tree for some criteria (e.g. that the node has a specific attribute)?
01:30:40 <ajnsit> Text.Blaze seems to have combinators that build a tree but no functions to search within that tree
01:31:28 <Flintlock> howdy y'all
01:33:31 <aleator_> Anyone know how I can get data from file to Data.Array.Accelerate fast?
01:33:59 <aleator_> D.A.A.fromList seems to index list for each element which is .. a bit slow.
01:36:25 <Baughn> aleator_: It does /what/?
01:36:36 <Baughn> aleator_: Source link, please?
01:36:58 <Baughn> nm., found it
01:36:58 <aleator_> http://hackage.haskell.org/packages/archive/accelerate/0.5.0.0/doc/html/src/Data-Array-Accelerate-Array-Sugar.html#fromList
01:37:34 <Baughn> ..what the frack
01:37:42 <aleator_> Baughn: My thoughts exactly.
01:37:59 <aleator_> First they put a man year into this and, then slap that on top.
01:38:08 <Baughn> aleator_: I'd say 'fix the function', but..
01:38:22 <Baughn> aleator_: Using the fromIArray function might be faster anyway
01:40:10 <aleator_> Baughn: Yeah. I would've liked to have a direct memcopy, but maybe I can live with going via array
01:40:37 <Baughn> aleator_: If you're IO-heavy then CUDA is unlikely to be a performance win anyway
01:41:30 <aleator_> Well, I'm not IO heavy. I just want [(x,y) | x<-[1..100], y<-[1..100]] as input data for my cuda testing
01:41:58 <Baughn> Ah. Then I'd say go with an IArray, and you won't even notice the time taken.
01:42:00 <Jafet> GPUs have tremendous IO, as long as it's all parallel and doesn't leave the board
01:42:27 <redd_> Hmm, I'm not sure how to express this using monad combinators `f g v [] = return v; f g v (x:xs) = do f xs >>= \xs' -> g x >>= \x' -> return $ something with x' and xs'`. It seems like it should be a fold of some kind, but I can't get foldM to do it.
01:42:37 <aleator_> Baughn: Is there easier way than going through listArray?
01:42:38 <Baughn> janbanan: Yeah.. he was talking about disk I/O, though. :P
01:42:45 <redd_> (`do` should not be there).
01:42:45 <janbanan> What?
01:42:50 <Baughn> Er, jafet
01:43:31 <aleator_> Even my real application isn't exactly disk heavy (just few dozen gb to read), but that still can't take ages.
01:44:01 <Baughn> aleator_: "Easier" in what sense? listArray is slowish, but we're only talking 10,000 elements.
01:44:07 <Jafet> Oh, you're that guy with the bunch of voxels.
01:44:12 <Jafet> Someday I will remember
01:45:40 <Jafet> redd: I don't see any fold
01:45:51 <aleator_> Baughn: This is already list -> array -> d.a.a.array -> array -> image -> file, which is bit lot of pipeline for such simple thing
01:47:17 <tsbo> Is https://gist.github.com/741815 the "correct" way to implement a `filter` analogue for enumerators?
01:48:37 <redd_> Well, it has similarities to something like `f g v h = foldr (\a s -> h (g a) s) v`, where h is (:) or S.insert and v is something like [] or S.empty.
01:50:46 <Jafet> In fact, you define a 3-ary function f, and then you use f as if it was unary
01:50:58 <Jafet> You'd better write a less confusing example
01:52:49 <Baughn> aleator_: There are various complex functions you could use to directly create the array instead of copying from a list, but.. honestly, typing fromList is /faster/.
01:53:17 <redd_> Okay: f g = foldr (\x xs -> g x `S.insert` xs) S.empty, for instance. Except I need to iterate from left to right, and `g` needs to make changes in the state monad.
01:53:32 <redd_> the return value needs to be a set of the (g x).
01:55:58 <redd_> I suppose something like `f g = S.fromList . mapM g` would work, though.
01:56:22 <redd_> (err, S.fromList needs to be lifted, but whatever).
02:26:12 * hackagebot fclabels 0.11.1.1 - First class accessor labels implemented as lenses.  http://hackage.haskell.org/package/fclabels-0.11.1.1 (SebastiaanVisser)
02:59:59 <dobblego> I am using MPTC and trying to give a function the type inferred by ghc -- the function doesn't use all the type variables in the MPTC so it is "forall" -- how do I specify the type?
03:06:45 <cncl> 512mb of ram is not enough to link ghc-compiled programs? :[
03:07:04 <cncl> ld uses like ~490mb of ram when trying to link darcs
03:08:14 <cncl> or is something wrong with my setup
03:08:42 <koala_man> 512mb of ram sometimes isn't enough to compile C programs. gcc failed compiling itself with that last time I tried
03:09:09 <cncl> i guess i'm just behind the times
03:10:28 <dobblego> http://paste.pocoo.org/show/305096/ how can I give this function a type signature?
03:11:16 <cncl> dobblego: open the file in ghci and do :t isRight
03:11:26 <cncl> it will print the inferred type signature
03:11:28 <dobblego> cncl, I have -Wall
03:11:29 <koala_man> dobblego!
03:11:38 <dobblego> cncl, this is true, but doesn't answer the question
03:11:40 <dobblego> koala_man!!!
03:11:40 <cncl> dobblego: so?
03:11:55 <cncl> do you mean, what is the syntax for a type signature?
03:11:56 <dobblego> cncl, so with -Wall I see the type inferred, since it generates a warning
03:12:05 <dobblego> cncl, no, quite explicitly, how do I add that type
03:12:08 <dobblego> cncl, please try it
03:12:37 <cncl> dobblego: there are cases where you cannot actually add type signatures
03:12:49 <dobblego> cncl, this is true, but is this one of them? it's a top-level function after all
03:12:56 <cncl> let me see
03:20:24 <dobblego> cncl, :)
03:24:30 <dobblego> am I to assume that it is not possible to give this top-level function an explicit signature?
03:25:13 <cncl> you can if you use functional dependencies
03:25:25 <cncl> class Eith e a b z | e a b -> z where
03:26:24 <blackh> dobblego: I think think you are right that this function can't be given a type signature, but you should be able to do it if you add z to the type signature of isRight
03:26:46 <quicksilver> cncl: "gold" uses much less memory to link haskell programs than GNU ld.
03:26:47 <dobblego> blackh, yes I can if I add z to isRight, but I don't want to :)
03:27:18 <cncl> dobblego: enable functional dependencies (they are used very frequently with multiparam typeclasses) and it will work
03:27:52 <cncl> if you also change the class to what i pasted above, anyway
03:28:00 <dobblego> yes that works
03:28:19 <cncl> but it doesn't solve your problem exactly (not sure how to do it)
03:28:23 <quicksilver> dobblego: it's worse than that function can't be given a type signature.
03:28:28 <quicksilver> that function really shouldn't compile
03:28:32 <quicksilver> seems like a bug in GHC if it does.
03:28:36 <quicksilver> it's an ambiguous function.
03:28:47 <dobblego> yes so I think fundeps is the correct solution
03:28:54 <cncl> i don't think it actually compiles
03:28:59 <cncl> you can't ever use it
03:29:31 <cncl> i remember reading this in a paper somewhere but i already forgot which
03:29:34 <dobblego> can I say that more than one type variable depends on another?
03:29:42 <quicksilver> cncl: well, it compiles in the sense that GHC accepts it.
03:29:52 <pedro3005> which is better: http://paste.pocoo.org/show/305098/ or http://paste.pocoo.org/show/305099/ ?
03:30:02 <quicksilver> cncl: I think you're right that GHC reports essential ambiguities "lazily" - i.e. only when used.
03:30:35 <cncl> dobblego: sure, class Eith e a b z | e a b -> z, e a -> z where
03:31:12 <blackh> pedro3005: Well, they're both defined in terms of map, so map' = map would be best.
03:31:16 <dobblego> cncl, great thanks
03:31:45 <pedro3005> blackh, well I was just implementing map to learn, and I was wondering which would be a better technique
03:31:51 <pedro3005> list comprehension or recursion
03:31:56 <quicksilver> pedro3005: well list comprehensions are just an alternative syntax for map.
03:32:18 <quicksilver> [ f x | x <- xs ] is just a funny way to spell  "map f xs", by definition
03:32:25 <blackh> pedro3005: I'm with ya.  Well, for the first one, I think you intended to write map' f xs
03:32:32 <quicksilver> so it doesn't really count as re-implementing it.
03:33:08 <quicksilver> better than "[f x] ++ map f xs" - or, at any rate, more natural - would be "f x : map f x"
03:33:18 <merijn> Is it good practice to shove subexpressions into a where clause to avoid evaluating twice? i.e. "foo f x y = if bar /= [] then bar else f y; where bar = f x" vs "foo f x y = if f x /= [] then f x else f y"
03:33:50 <cncl> dobblego: you could also look at using type families (a more recent GHC addition) instead of multiparam+fundeps, it will allow you accomplish the same thing but in a different style
03:33:58 <blackh> merijn: Yes, it is
03:34:09 <dobblego> cncl, ok cheers
03:34:20 <quicksilver> merijn: yes, where or let.
03:34:23 <cncl> dobblego: the paper 'func with type functions' gives an intro
03:34:29 <cncl> er fun with type functions
03:34:51 <merijn> That's what I expected, of course that means running into my arch nemesis, the hardest CS problem, yet again. :\
03:35:20 <merijn> "Naming things"
03:35:53 <quicksilver> merijn: let f_of_x = f x in ... ;)
03:36:47 <merijn> quicksilver: That looks awful, though :p
03:37:47 <cncl> merijn: actually GHC will optimize that unless you disable the common-sub-expression optimization
03:38:00 <blackh> merijn: How about case f x of { [] -> f y ; fx -> fx } or is that no better?
03:38:21 <cncl> so it's fine to re-use the same subexpression multiple times and not worry about performance (most of the time, anyway)
03:40:21 <merijn> blackh: This wasn't a specific example, more a general question. It is something I started doing and then figured "wait, is this the canonical way of doing things/does it even make sense?"
03:41:25 <blackh> Well, I learnt something.  I thought common sub-expression optimization didn't happen for some reason.
03:42:04 <cncl> i think it can be messed with if someone is using unsafePerformIO or something, i don't know very much about writing high-performance haskell
03:42:37 <merijn> I'm more aiming at "reasonable-performance haskell" for now :p
03:42:55 <cncl> then i think you're ok :)
03:44:19 <merijn> cncl: Yeah, but if its common practice for people to explicitly write out the where clause it doesn't hurt to get into the habit of doing it
03:45:46 <quicksilver> cncl, blackh, merijn : GHC does not do CSE, in general.
03:45:56 <cncl> no?
03:45:58 <quicksilver> no.
03:46:11 <quicksilver> it does in a few specfic cases, which don't come up that often I don't think.
03:46:11 <cncl> what are the cases where it does
03:46:21 <quicksilver> let y = f x in f x + f x + y
03:46:23 <blackh> I generally assume it doesn't.
03:46:37 <quicksilver> if 'f x' already has a name, it will decide it's safe to common up other uses of it.
03:46:38 <cncl> you are right
03:46:52 <quicksilver> CSE causes increased sharing which can be a memory leak.
03:47:09 <quicksilver> GHC has to be a bit careful about that kind of thing, it's an issue with lazy languages + GC.
03:47:12 <merijn> quicksilver: Can you elaborate?
03:47:13 <cncl> most of the time i do it seems to be where it does apply though
03:47:23 <quicksilver> not that it doesn't have optimisations which change sharing, of course
03:47:29 <quicksilver> but it tries to be conservative.
03:48:26 <quicksilver> merijn: assume y is a very long list in (foldr f z y,foldr g z y)
03:48:41 <merijn> How does increased sharing leak memory? Blind stab in the dark: the computed value could be significantly larger then a thunk an needlessly kept in memory until later occurences use it?
03:48:58 <quicksilver> if those ys are CSEd, the one used by the first foldr will be kept in memory until the second one runs.
03:49:11 <quicksilver> if htey're not it will be generated twice but can be GCed as it goes a long, both times.
03:49:30 <Shlomi> Hi
03:49:46 <merijn> So basically just a traditional memory vs computation trade off
04:30:15 <pedro3005> is there something equivalent to python's 'pass' in haskell?
04:30:26 <augur> whats pythons pass
04:30:42 <merijn> pedro3005: That makes no sense
04:30:52 <merijn> pedro3005: "pass" is impossible in haskell
04:30:54 <FauxFaux> if (foo) ; in c-like languages.
04:30:59 <lars9> pass = nope
04:31:07 <augur> wtf is pass :|
04:31:13 <merijn> augur: Pass is an empty statement
04:31:15 <Boxo> where would you want to use pass?
04:31:26 <augur> merijn: whats the point of that
04:31:27 <Boxo> is haskell
04:31:28 <Bynbo7> there are no statements in haskell!
04:31:34 <Boxo> *in
04:31:39 <pedro3005> calm down :p
04:31:53 <sipa> pedro3005: can you just explain what it does?
04:31:54 <merijn> augur: Since python uses indentation for blocks you might need to have a statement to show indentation without wanting to do anything
04:32:04 <merijn> sipa: ^
04:32:11 <augur> merijn: wtf
04:32:12 <pedro3005> on an if statement, I want to return a value if the condition is met or else do nothing
04:32:21 <sipa> :t when
04:32:24 <lambdabot> forall (m :: * -> *). (Monad m) => Bool -> m () -> m ()
04:32:35 <merijn> augur: Example, I want to declare an empty class "class Empty(object): pass"
04:32:36 <Bynbo7> pedro3005: then you probably want to use something like Maybe
04:32:41 <augur> merijn: :|
04:33:03 <merijn> augur: Without pass there would be no indentation, therefore no block, thus syntax error. But in Haskell context pass would make zero sense
04:33:26 <lars9> merijn: undefined  ?
04:33:29 <elliott> Is there a function like break but returning ([a],a,[a])?
04:33:35 <Bynbo7> undefined does something
04:33:37 <quicksilver> in the context of "when", pass is "return ()"
04:33:41 <elliott> e.g. foo (==2) [1,2,3,4] -> ([1],2,[3,4])
04:33:56 <quicksilver> but with normal expressions you must always give a value.
04:34:00 <merijn> pedro3005: Haskell if statement don't work like that. They must *always* return something
04:34:02 <Boxo> > if 1+1==2 then "qq" else undefined
04:34:03 <lambdabot>   "qq"
04:34:11 <augustss> howdy
04:34:11 <lambdabot> augustss: You have 1 new message. '/msg lambdabot @messages' to read it.
04:34:11 <Boxo> > if 1+1==3 then "qq" else undefined
04:34:12 <lambdabot>   "*Exception: Prelude.undefined
04:34:28 <merijn> Boxo: That'll crash if your condition is not true, though. Which likely isn't what he wants
04:34:48 <Boxo> what does he want though?
04:34:58 <merijn> pedro3005: Can you pastebin your if/else as an example?
04:35:26 <merijn> But I'm betting Bynbo7 is right that he wants Maybe
04:35:55 <pedro3005> merijn, I was trying this "if f x == True then x else []" but empty list isn't what I wanted
04:36:16 <quicksilver> I think you have to ask the question "what do I want?"
04:36:17 <merijn> pedro3005: Because x is not a list?
04:36:24 <quicksilver> you have to have *something* if "f x" is not True
04:36:24 <BONUS> pedro3005: needs more context
04:36:28 * merijn agrees with quicksilver
04:36:51 <merijn> also, isn't "if f x == True" redundant?
04:37:00 <merijn> Why not just "if f x"?
04:37:04 <quicksilver> it is, but I write it sometimes anyway :)
04:37:04 <pedro3005> why's that quicksilver ?
04:37:18 <quicksilver> pedro3005: because "if blah then blah else blah" is an expression.
04:37:24 <merijn> pedro3005: Because if/else is an expression and expressions must *always* return a value
04:37:27 <quicksilver> pedro3005: expressions evaluate to values.
04:37:32 <augustss> quicksilver: what don't you write (f x == True) == True?
04:37:38 <quicksilver> pedro3005: and you have to decide what value(s) you want.
04:37:53 <Bynbo7> :t foldl (==)
04:37:54 <lambdabot> Bool -> [Bool] -> Bool
04:37:54 <Boxo> > fix (== True)
04:37:58 <lambdabot>   mueval-core: Time limit exceeded
04:38:01 <pedro3005> then I need something which doesn't *need* to return a value
04:38:01 <merijn> What is x and what does "f x" do?
04:38:06 <Boxo> > fix (True ==) 
04:38:10 <lambdabot>   mueval-core: Time limit exceeded
04:38:15 <Bynbo7> hmm, does that have a common name? 
04:38:16 <quicksilver> augustss: in contexts where I want code to look similar to other code which is non-Bool
04:38:22 <quicksilver> augustss: or I think it might not always be a Bool.
04:38:24 <merijn> pedro3005: As I (and Bynbo7) said, you want Maybe
04:38:43 <Boxo> @google haskell maybe tutorial
04:38:44 <lambdabot> http://en.wikipedia.org/wiki/Monad_(functional_programming)
04:38:44 <lambdabot> Title: Monad (functional programming) - Wikipedia, the free encyclopedia
04:38:51 <Boxo> whoops
04:38:52 <merijn> > let a = 5 in if a == 7 then Just a else Nothing
04:38:53 <lambdabot>   Nothing
04:39:00 <merijn> > let a = 7 in if a == 7 then Just a else Nothing
04:39:01 <lambdabot>   Just 7
04:39:32 <merijn> :t \a -> if a == 7 then Just a else Nothing
04:39:33 <lambdabot> forall a. (Num a) => a -> Maybe a
04:39:47 <ketil> pedro3005, in a monad, you can use 'when' and 'unless' to conditionally execute actions.
04:40:04 <merijn> ketil: I think bringing out monads is overshooting his goals
04:40:41 <ketil> merijn, Well, for once, I get to confuse others in this channel.  Making up for all the times it was the other way around :-)
04:41:40 <merijn> pedro3005: As my examples (hopefull) demonstrate Maybe lets you return a value under some conditions and "Nothing" under others. The rest of you code can then simply which of the two it was
04:42:20 <luite> bah my system's hard drive occasionally stops working... :(
04:42:21 <ketil> pedro3005, I guess merijn is right - the point is that 'if ... then ... else ...' is an expression, and it needs to have a value.  The value can be an error if you want (if f x then x else error "wrong x!") but it has to be something.  Unless it's Nothing, which is also really a something.
04:42:27 <ketil> So, there, confusion cleared up!
04:42:48 <pedro3005> oh, thanks
04:42:59 <pedro3005> I ended up figuring out another way to do it, without an if
04:44:57 * hackagebot splot 0.1.6 - A tool for visualizing the lifecycle of many concurrent multi-staged processes.  http://hackage.haskell.org/package/splot-0.1.6 (EugeneKirpichov)
04:46:51 <augustss> @seen dmwit
04:46:51 <lambdabot> Unknown command, try @list
04:46:51 <preflex>  dmwit was last seen on #xmonad 10 hours, 59 minutes and 17 seconds ago, saying: ChrisPitzer: See the FAQ for a whole slew of solutions.
04:58:17 <aristid> :t \a -> guard (a == 7) >> return a
04:58:18 <lambdabot> forall a (m :: * -> *). (Num a, MonadPlus m) => a -> m a
04:58:22 <aristid> @pl \a -> guard (a == 7) >> return a
04:58:22 <lambdabot> ap ((>>) . guard . (7 ==)) return
04:59:26 <ziman> is there a simpler way to write "foldl (.) id" ?
04:59:51 <aristid> ziman: isn't it very simple already?
04:59:54 <ziman> i'd like it to be mconcat but there's the inconvenient Endo stuff :)
05:00:20 <aristid> ziman: if the list is always non-empty, how about  foldl1 (.)
05:00:47 <pedro3005> what's wrong with http://paste.pocoo.org/show/305115/ ?
05:01:04 <Kaidelong> "foldl (.) id" is simple and obvious to me, personally
05:01:13 <aristid> :t foldl (.) id
05:01:13 <lambdabot> forall a. [a -> a] -> a -> a
05:01:27 <Bynbo7> pedro3005: what error are you getting?
05:01:55 <pedro3005> http://paste.pocoo.org/show/305116/
05:02:04 <Bynbo7> pedro3005: oh, you need to use `div` instead of /
05:02:08 <Bynbo7> :t (/)
05:02:08 <lambdabot> forall a. (Fractional a) => a -> a -> a
05:02:18 <Bynbo7> :t (`div`)
05:02:18 <lambdabot> parse error on input `)'
05:02:22 <Bynbo7> bah
05:02:23 <Kaidelong> :t div
05:02:23 <lambdabot> forall a. (Integral a) => a -> a -> a
05:02:24 <Bynbo7> :t div
05:02:25 <lambdabot> forall a. (Integral a) => a -> a -> a
05:02:35 <pedro3005> Bynbo7, ah, thanks
05:02:42 <Kaidelong> :t quot
05:02:43 <lambdabot> forall a. (Integral a) => a -> a -> a
05:02:59 <Kaidelong> > 4 `quot` -3
05:03:00 <lambdabot>   Precedence parsing error
05:03:00 <lambdabot>      cannot mix `GHC.Real.quot' [infixl 7] and pre...
05:03:04 <Kaidelong> > 4 `quot` (-3)
05:03:05 <lambdabot>   -1
05:03:10 <Kaidelong> > 4 `div` (-3)
05:03:11 <lambdabot>   -2
05:03:40 <ziman> aristid, hm, thanks. I'm not golfing, just trying to be abstract; I'll think about it. :)
05:03:51 <quicksilver> @type appEndo.mconcat.(Endo .)
05:03:52 <lambdabot> forall a. [a -> a] -> a -> a
05:04:05 <Bynbo7> :t Endo
05:04:06 <lambdabot> forall a. (a -> a) -> Endo a
05:04:15 <aristid> quicksilver: that is evil. i think this is a place where you should use map, not (.)=fmap
05:04:25 <aristid> :t appEndo . mconcat . map Endo
05:04:25 <lambdabot> forall a. [a -> a] -> a -> a
05:04:43 <aristid> but that's more complicated than foldl (.) id
05:04:44 <quicksilver> aristid: yes, I strive to great evils.
05:05:08 <aristid> quicksilver: you want to poison us with mercury?
05:05:26 <quicksilver> that's a very boring kind of evil.
05:05:38 <aristid> but it fits your nickname
05:05:40 <quicksilver> I'd rather poison you with subsersive semantics and tenuous type-hackery.
05:05:44 <aristid> which is very important IMO
05:09:04 <ziman> @pl \g x -> g . f x
05:09:04 <lambdabot> (. f) . (.)
05:13:36 <xplat> so let's split the difference and quicksilver can poison us with unusually efficient logic programming
05:15:04 <aristid> xplat: written in the haskell type system?
05:15:25 <xplat> of course, this is #haskell isn't it?
05:16:07 <xplat> although some of it could also be value-based and written in monadic style or something
05:16:38 <xplat> because the type system is just what we'd be expecting!
05:18:04 <aristid> right, and logict would be too obvious as well
05:24:26 <elliott> xplat: it'd be done with monads in the type system, duh
05:24:30 <elliott> (with oleg's help)
05:36:12 * hackagebot hjson-query 1.0 - library for querying from JSON  http://hackage.haskell.org/package/hjson-query-1.0 (YuriyIskra)
05:37:12 * hackagebot quick-generator 0.1.2 - Generator random test data for QuickCheck  http://hackage.haskell.org/package/quick-generator-0.1.2 (YuriyIskra)
05:54:05 <pedro3005> any relation between haskell monads and category theory monads?
05:54:24 <Bynbo7> sure
05:54:31 <byorgey> pedro3005: absolutely.
05:54:52 <Bynbo7> he hem, monads are just morphisms in the category of endofunctors
05:54:59 <Bynbo7> did i get that right?
05:55:12 <byorgey> pedro3005: Haskell monads are category-theoretic monads over the category Hask, the category with Haskell types as objects and functions as morphisms.
05:55:31 <byorgey> Bynbo7: in *a* category of endofunctors =)
05:55:37 <byorgey> there are lots
05:56:19 <xrch> (the difference is, I think, that we often d"efine"
05:56:21 <xrch> oops
05:56:29 <byorgey> Bynbo7: also, *monoids* in a category of endofunctors
05:56:40 <Bynbo7> whatevs :P
05:56:44 <byorgey> hehe =)
05:57:04 <xrch> that we often define monads with return and join in category theory whereas we use more often (>>=) in Haskell)
05:57:16 <dblhelix> Bynbo7: do you mean that monads are monoids in the category of endofunctors of some category
05:57:20 <dblhelix> ?
05:57:35 <xrch> there would be no difference if there was a Functor constraint on the monad
05:57:38 <xrch> (or Applicative)
05:57:51 <dblhelix> Bynbo7 byorgey : ah, indeed :)
05:57:57 <xrch> because you cn define bind in terms of join, but you need fmap to do that
05:58:00 <xrch> *can
05:58:25 <aristid> :t uncurry mappend
05:58:26 <lambdabot> forall a. (Monoid a) => (a, a) -> a
05:58:29 <aristid> :t join
05:58:30 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
05:58:37 <byorgey> xrch: well, the definition of category-theoretic monads is only in terms of functors anyway
05:59:01 <byorgey> xrch: (>>=) actually shows up quite a bit in category theory too
05:59:02 <aristid> :t const mempty
05:59:03 <lambdabot> forall a b. (Monoid a) => b -> a
05:59:05 <aristid> :t return
05:59:06 <lambdabot> forall a (m :: * -> *). (Monad m) => a -> m a
05:59:10 <xrch> oh?
05:59:19 <byorgey> often with the arguments flipped, it is represented by the operator (-)^*
05:59:30 <xrch> (I actually don't know much about category theory)
05:59:33 <xrch> oh, ok
05:59:44 <byorgey> i.e.  f :: a -> m b,  f^* :: m a -> m b
06:00:17 <xrch> hmm ok
06:00:43 <byorgey> xrch: but you're right that category-theoretic monads are most often presented in terms of return (eta) and join (mu)
06:01:40 <Bynbo7> :t \f m -> join 
06:01:41 <lambdabot> forall t t1 (m :: * -> *) a. (Monad m) => t -> t1 -> m (m a) -> m a
06:01:47 <Bynbo7> :t \f m -> join (fmap f m)
06:01:48 <lambdabot> forall a (m :: * -> *) a1. (Functor m, Monad m) => (a -> m a1) -> m a -> m a1
06:02:02 <Bynbo7> :t \m f -> join (fmap f m)
06:02:02 <lambdabot> forall a (m :: * -> *) a1. (Functor m, Monad m) => m a -> (a -> m a1) -> m a1
06:05:41 <aristid> :t join .: fmap
06:05:42 <lambdabot> forall (m :: * -> *) a a1. (Monad m, Functor m) => (a1 -> m a) -> m a1 -> m a
06:06:21 <xrch> :t (.:)
06:06:21 <lambdabot> forall a b (f :: * -> *) (g :: * -> *). (Functor f, Functor g) => (a -> b) -> f (g a) -> f (g b)
06:06:26 <aleator_> Anyone here who could walk me through to add some direct memory access to Data.Array.Accelerate arrays? According to source shouldn't be very difficult 
06:12:48 <Xilon> does `xmonad --recompile` compile with multithreading?
06:12:59 <Xilon> bah wrong channel
06:15:33 <hpc> :t fmap fmap join
06:15:34 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> a -> b) -> f a -> f b
06:36:19 <audunska> what's the currently preferred FRP library?
06:36:34 <audunska> Data.Reactive seems nice, but it's a little bit-rotten
06:39:31 <quicksilver> audunska: not only bitrotten but it always had known problems.
06:39:44 <quicksilver> audunska: yampa seems to be the most practical (I haven't used it myself)
06:39:50 <quicksilver> you might also look at elerea
06:40:48 <audunska> thanks
06:41:11 <quicksilver> I feel elerea is too much like cheating, but it works for some people
06:42:41 <audunska> FieldTrip is also bitrotten. Are there any other declarative 3d libraries?
06:42:58 <quicksilver> hmm
06:43:02 <lars9> @src (,)
06:43:02 <lambdabot> Source not found. Wrong!  You cheating scum!
06:43:20 <lars9> how is (,) (,,) ... defined?
06:43:30 <quicksilver> audunska: http://www.haskell.org/haskellwiki/GPipe ?
06:43:35 <quicksilver> lars9: they are part of the language.
06:43:47 <quicksilver> lars9: (,) is no different from data Pair a b = Pair a b, though
06:43:52 <quicksilver> (apart from syntax)
06:44:00 <lars9> > Pair 1 2
06:44:01 <lambdabot>   Not in scope: data constructor `Pair'
06:44:09 <quicksilver> that doesn't exist, it was an example :)
06:44:23 <audunska> quicksilver: nice, i'll check it out.
06:44:28 <lars9> quicksilver: i see :)
06:48:28 <lars9> it's really magic that (e->) is a functor
06:53:07 <lars9> @instances Monad
06:53:08 <lambdabot> ((->) r), ArrowMonad a, Cont r, ContT r m, Either e, ErrorT e m, IO, Maybe, RWS r w s, RWST r w s m, Reader r, ReaderT r m, ST s, State s, StateT s m, Writer w, WriterT w m, []
06:53:16 <lars9> @instances Monoid
06:53:17 <lambdabot> (), (a -> b), (a, b), (a, b, c), All, Any, Dual a, Endo a, First a, Last a, Maybe a, Ordering, Product a, Sum a, [a]
06:53:23 <lars9> @instances Arrow
06:53:23 <lambdabot> (->), Kleisli m
06:53:28 <lars9> @instances Category
06:53:28 <lambdabot> Couldn't find class `Category'. Try @instances-importing
06:54:50 <mightybyte> @pl (\a -> return a >> threadDelay 500)
06:54:50 <lambdabot> const (threadDelay 500)
06:55:15 <merijn> :t const
06:55:15 <lambdabot> forall a b. a -> b -> a
06:55:44 <mightybyte> @pl (\a -> f a >> threadDelay 500)
06:55:44 <lambdabot> (>> threadDelay 500) . f
06:56:45 <lars9> :t (->)
06:56:46 <lambdabot> parse error on input `->'
06:57:09 <merijn> lars9: It's not a type, so :t
06:57:12 <merijn> doesn't work
06:57:22 <lars9> :i (->)
06:57:39 <lars9> merijn: how to query info of type constructor?
06:57:44 <merijn> :k (->)
06:57:44 <lambdabot> ?? -> ? -> *
06:58:04 <merijn> Depends which info you want?
06:58:13 <merijn> :k []
06:58:13 <lambdabot> * -> *
06:59:04 <lars9> :k (Int ->)
06:59:05 <lambdabot> parse error on input `)'
06:59:11 <lars9> :k Int ->
06:59:12 <lambdabot> parse error (possibly incorrect indentation)
06:59:20 <lars9> :k (e ->)
06:59:20 <lambdabot> parse error on input `)'
06:59:34 <lars9> :k (->) Int
06:59:35 <lambdabot> ? -> *
06:59:56 <lars9> :k (-> Int)
06:59:57 <lambdabot> parse error on input `Int'
07:00:06 <lars9> does (-> Int) make sense?
07:00:07 <quicksilver> type sections aren't real syntax.
07:00:17 <quicksilver> it's obvious what it means
07:00:21 <quicksilver> but it isn't legal haskell
07:00:39 <lars9> is -> a type constructor?
07:00:50 <lars9> :k (->) Int Char
07:00:51 <lambdabot> *
07:00:58 <lars9> seems yes?
07:02:20 <quicksilver> yes.
07:11:20 <fram> hi, I don't understand the ".|." notation, I thought it was used to define masks, but with GHC I get "Not in scope  '.|.' " ... and I cannot google it, since google ignores punctuation, so here I am...
07:11:43 <blueonyx> @hoogle .|.
07:11:43 <lambdabot> Data.Bits (.|.) :: Bits a => a -> a -> a
07:11:49 <lars9> @instances Functor
07:11:49 <lambdabot> ((,) a), ((->) r), Cont r, ContT r m, Either a, ErrorT e m, IO, Maybe, RWS r w s, RWST r w s m, Reader r, ReaderT r m, ST s, State s, StateT s m, Writer w, WriterT w m, []
07:12:27 <fram> thx a lot!
07:12:45 <blueonyx> why doesnt hayoo find it? :/
07:13:11 <Twey> @hayoo (.|.)
07:13:11 <lambdabot> Unknown command, try @list
07:13:17 <Twey> Blast :þ
07:13:38 <Twey> fram: It's not really ‘notation’ — it's just a function
07:14:55 <merijn> Does Haskell even have operators which are not just functions defined as infix?
07:15:41 <blueonyx> :t ->
07:15:41 <lambdabot> parse error on input `->'
07:15:42 <Starfire> Unary minus maybe?
07:15:56 <tromp> > let a = 1 in  -a
07:15:56 <merijn> Starfire: Good point
07:15:57 <lambdabot>   -1
07:16:11 <blueonyx> :t (-)
07:16:12 <lambdabot> forall a. (Num a) => a -> a -> a
07:16:57 <merijn> Of course unary minus is still a function, just not infix
07:16:58 <wtcross> i am about to bash my head against my keyboard, can somebody please help me figure out how to convert [Double] to a string?
07:17:00 <tromp> :t \a -> -a
07:17:00 <lambdabot> forall a. (Num a) => a -> a
07:17:11 <merijn> wtcross: show?
07:17:14 <merijn> :t show
07:17:14 <lambdabot> forall a. (Show a) => a -> String
07:17:28 <merijn> > show (1.58626585 :: Double)
07:17:28 <lambdabot>   "1.58626585"
07:17:29 <unkanon> > show [0.12, 0.342343245]
07:17:30 <lambdabot>   "[0.12,0.342343245]"
07:18:07 <wtcross> No instance for (Show ([Double] -> [Double]))
07:19:52 <xrch> what's your code?
07:20:37 <Jafet> Hint: try using show on [Double], not [Double]->[Double]
07:21:48 <wtcross> there is too much code to paste thanks for asking though
07:21:57 <wtcross> Jafet: thanks for the tip i will examine the code and figure out what i did wrong
07:22:18 <wtcross> i'm terrible at examining the haskell interpreter output
07:22:24 <wtcross> <--noob
07:22:50 <Jafet> If I were less of an obnoxious jerk, I might say "Hint: that means a function is not fully applied". But I'm not, so I won't.
07:23:07 <xrch> huhu
07:24:20 <lars9> why ((->) r) uses an 'r'? it's not at the result position, but the parameter position
07:24:48 <Kaidelong> r s t ..?
07:24:57 <Jafet> So that the instance has kind * -> *.
07:25:13 <Jafet> Also think about ((,) a).
07:25:56 <xrch> lars9: huhu? is it really important?
07:26:04 <xrch> it's just a name
07:26:20 <Jafet> And also more importantly, think about what happens if you plug a function into the functor laws
07:27:58 <lars9> another question, how come Set is not a functor because it requires Ord on its elements but Map is? they are both implemented as binary search tree so they both require Ord
07:28:06 <Jafet> There are other ways to think about it, like functions being maps, or burritos
07:28:48 <Jafet> What would be the semantics for instance Functor Set?
07:29:47 <lars9> fromList . f . toList ?
07:30:13 <xarch> hum
07:30:19 <Jafet> That fails to satisfy the associative law.
07:30:42 <quicksilver> Jafet: really?
07:30:42 <Jafet> Wait, I should check before I say things like that
07:30:44 <xarch> and anyway toList returns a list, so that would mean f should take a list…
07:30:51 <quicksilver> fromList . map f . toList
07:30:55 <quicksilver> is what lars9 wanted :)
07:31:04 <lars9> quicksilver: thanks
07:31:33 <quicksilver> lars9: "Set" is not parametric over all types 'a', whereas "Map k" is, indeed, parametric over all types 'v'.
07:31:34 <xarch> someone I know had an idea regarding functor instances of Set and Map
07:31:48 <quicksilver> lars9: the point being that the Ord constraint is not on the 'contained type' so that's OK.
07:32:44 <xarch> the idea was more or less to have some funny kind of kind, for example #Ord (random notation) could denote the kind of types having an instance for Ord
07:33:11 <lars9> quicksilver: oh it makes sense very much
07:33:32 <lars9> though k must be Ord but v not
07:33:39 <Kaidelong> @pl \f-> toList . map f . fromList
07:33:39 <lambdabot> (toList .) . (. fromList) . map
07:33:49 <Jafet> That fmap will need an Ord constraint though
07:34:14 <Jafet> fmap for Map doesn't, if its implementation is occult
07:35:55 <xarch> :t In
07:35:55 <lambdabot> forall (f :: * -> *). f (Mu f) -> Mu f
07:36:03 <xarch> :t out
07:36:04 <lambdabot> forall (t :: * -> *). Mu t -> t (Mu t)
07:36:48 <xarch> @pl fix \f r -> f . fmap r . out
07:36:48 <lambdabot> (line 1, column 5):
07:36:48 <lambdabot> unexpected "\\"
07:36:48 <lambdabot> expecting variable, "(", operator or end of input
07:37:11 <xarch> @pl fix (\f r -> f . fmap r . out)
07:37:11 <lambdabot> fix ((. ((. out) . fmap)) . (.))
07:37:30 <xarch> :t fix (\f r -> f . fmap r . out)
07:37:31 <lambdabot>     Occurs check: cannot construct the infinite type: a = Mu ((->) a)
07:37:31 <lambdabot>       Expected type: Mu ((->) a) -> a -> a
07:37:31 <lambdabot>       Inferred type: Mu ((->) a) -> a -> Mu ((->) a)
07:37:39 <xarch> huhu
07:37:57 <xarch> :t fix (\f r -> f . fmap (r f) . out)
07:37:57 <lambdabot>     Occurs check: cannot construct the infinite type:
07:37:57 <lambdabot>       a = (a -> b) -> a1 -> b1
07:37:57 <lambdabot>     Probable cause: `r' is applied to too many arguments
07:38:01 <xarch> woops
07:38:04 <lars9> what is Int out Mu? totally lost  m(_ _)m
07:38:27 <Jafet> @src Mu
07:38:27 <lambdabot> newtype Mu f = In { out :: f (Mu f) }
07:38:31 <xarch> that's just something else
07:38:46 * hackagebot xml-enumerator 0.0.0 - Pure-Haskell utilities for dealing with XML with the enumerator package.  http://hackage.haskell.org/package/xml-enumerator-0.0.0 (MichaelSnoyman)
07:39:12 <xarch> > let foo = fromList . f . toList
07:39:13 <lambdabot>   not an expression: `let foo = fromList . f . toList'
07:39:20 <xarch> @let foo = fromList . f . toList
07:39:20 <lambdabot>  <local>:1:21: Not in scope: `toList'
07:40:04 <Jafet> :t let fm f = Data.Set.fromList . map f . Data.Set.toList in fm
07:40:04 <lambdabot> forall a a1. (Ord a1) => (a -> a1) -> S.Set a -> S.Set a1
07:40:33 <xarch> oh ok
07:40:46 * hackagebot xml-enumerator 0.0.0.1 - Pure-Haskell utilities for dealing with XML with the enumerator package.  http://hackage.haskell.org/package/xml-enumerator-0.0.0.1 (MichaelSnoyman)
07:41:10 <xarch> @let fold f = f . fmap (fold f) . out
07:41:11 <lambdabot>  Defined.
07:41:15 <xarch> @pl fold
07:41:15 <lambdabot> fold
07:41:19 <xarch> woops
07:41:40 <danr> @unpl (f .) . (. g)
07:41:41 <lambdabot> (\ e j -> f (e (g j)))
07:42:41 <Jafet> You just had to point that out.
07:44:09 <xarch> @let (--->) f g h = g . h . f
07:44:10 <lambdabot>  Defined.
07:44:26 <xarch> @let (--->) g f h = g . h . f
07:44:26 <lambdabot>  <local>:2:0:
07:44:26 <lambdabot>      Warning: Pattern match(es) are overlapped
07:44:26 <lambdabot>               In...
07:44:32 <xarch> oh
07:44:38 <xarch> @let (--->) f g h = g . h . f
07:44:38 <lambdabot>  <local>:2:0:
07:44:38 <lambdabot>      Warning: Pattern match(es) are overlapped
07:44:38 <lambdabot>               In...
07:44:48 <xarch> hum
07:44:50 <wtcross> I found out what I was doing wrong and got it to work. Can somebody tell me how they would go about converting an [[Double]] -> String with '\n' after each of the inner arrays?
07:45:27 <wtcross> i'm just looking for a better solution
07:45:38 <danr> Jafet: was that a pun?
07:47:02 <quicksilver> wtcross: unlines . map show
07:47:04 <xarch> :t concat $ map show . intercalate "\n" . map show
07:47:05 <lambdabot>     Couldn't match expected type `[[[Char]]]'
07:47:05 <lambdabot>            against inferred type `[a] -> [String]'
07:47:05 <lambdabot>     In the second argument of `(.)', namely `map show'
07:47:19 <xarch> oh hum
07:47:24 <wtcross> quicksilver: much appreciated, let me try it out
07:47:28 <quicksilver> > (unlines . map show) [3.1,4.2]
07:47:32 <lambdabot>   mueval-core: Time limit exceeded
07:47:37 <quicksilver> !
07:47:38 <quicksilver> > (unlines . map show) [3.1,4.2]
07:47:38 <xarch> oh hum
07:47:40 <lambdabot>   "3.1\n4.2\n"
07:47:43 <quicksilver> better :)
07:48:06 <quicksilver> > (unlines . map show) [[3.1,4.2],[5.6,7.8]]
07:48:07 <lambdabot>   "[3.1,4.2]\n[5.6,7.8]\n"
07:48:13 <quicksilver> ^^ what you actually asked for :)
07:48:46 <quicksilver> > (unlines . map (unwords . map show)) [[3.1,4.2],[5.6,7.8]]
07:48:47 <lambdabot>   "3.1 4.2\n5.6 7.8\n"
07:48:53 <quicksilver> ^ another version!
07:48:57 <danr> looks nice :)
07:49:52 <lars9> @src (.)
07:49:52 <lambdabot> (f . g) x = f (g x)
07:49:52 <lambdabot> NB: In lambdabot,  (.) = fmap
07:49:57 <Kaidelong> > doc $ (unlines . map show) [[3.1,4.2],[5.6,7.8]]
07:49:58 <lambdabot>   Not in scope: `doc'
07:50:10 <Kaidelong> how'd you get lambdabot to actually show things like print again?
07:50:13 <wtcross> quicksilver: thanks :D
07:50:13 <quicksilver> text
07:50:27 <Kaidelong> would lambdabot actually print multiple lines in this case?
07:50:36 <Kaidelong> > text $ (unlines . map show) [[3.1,4.2],[5.6,7.8]]
07:50:36 <lambdabot>   [3.1,4.2]
07:50:37 <lambdabot>  [5.6,7.8]
07:50:39 <Kaidelong> yes
07:51:04 <quicksilver> maximum six lines or something, but don't overuse it
07:51:50 * hackagebot attosplit 0.0.1 - Split a lazy bytestring at boundaries defined by an attoparsec parser  http://hackage.haskell.org/package/attosplit-0.0.1 (YitzGale)
08:00:03 <lars9> so Functor law is not a really "law" because compiler can not verify it?
08:00:45 <Kaidelong> lars9: a lot of laws are like that. But not satisfying the functor law would seem kind of silly
08:01:03 <kosmikus> lars9: you can't rely on it to be true for Functor instances in Haskell
08:01:30 <lars9> kind of strange.
08:01:37 <sipa> it is like not obeying the rule of not reading uninitialized memory in C - it is very hard to verify, possible still useful if you don't obey it, but definitely hard to define what will happen
08:02:16 <Jafet> Well, you can rely on it being true or privileges to smack the author over the internet
08:02:22 <Twey> lars9: It's a mathematical law, not a Haskell law
08:02:36 <sipa> Twey: right
08:02:39 <Kaidelong> lars9: it'd be nice if you could add those proofs to the class and use them but Haskell wasn't that ambitious
08:02:42 <Kaidelong> that said
08:02:46 <Twey> Haskell doesn't enforce it, but you can nevertheless rely on it being true, because if it's not all sorts of things will break
08:02:47 <lars9> Twey: ok that makes more sense.
08:03:04 <Kaidelong> the functor law is so mind-numbingly simple it is hard to think of how you would break it without trying to specifically
08:03:15 <Kaidelong> at least so long as you are programming purely
08:03:17 <Twey> (also, it's pretty hard to accidentally create a Functor that doesn't obey it, though of course it's trivial if you try)
08:04:16 <interferon> So with GADT's you can statically prevent "head []" from evaluating to bottom.  Are there any disadvantages to using lists like that everywhere, other than historical reasons?
08:04:47 <Jafet> It's more sadistic to make a Functor instance that doesn't match the Monad instance, since only a few people will run into that
08:05:18 <Twey> Jafet: Heheheh.
08:05:40 <Jafet> interferon: hm, what would happen when you try?
08:05:55 <kmc> interferon, (if I understand you correctly) the disadvantage is that you now have a burden of proving that your lists are non-empty
08:06:04 <kosmikus> interferon: more work
08:06:29 <kmc> the disadvantage of static typing in general is that you have to convince the machine your code is correct
08:06:33 <kmc> the advantage is that then your code is correct ;)
08:06:37 <kmc> and if you convince yourself, it probably isn't
08:06:49 <Jafet> It sounds like more work than safeHead, too
08:06:50 <kmc> yourself only*
08:07:33 <kmc> vanilla Haskell has very good type inference, which makes the burden of static typing pretty low.  but when you're encoding high-level correctness properties using GADTs you end up doing more work
08:07:38 <kosmikus> in general keeping track of lists being empty or non-empty is not enough, so you have to keep track of the length of the list. that's possible, but already requires quite a bit of work and type-level programming in Haskell.
08:08:11 <kmc> yeah, to prove (tail xs) is non-empty, you have to prove xs has length >= 2
08:09:18 <kosmikus> interferon: but if you really want that, you might want to look at dependently typed languages (such as Agda, Idris, Coq, Epigram, ...)
08:10:13 <interferon> True, it's only a limited guarantee
08:11:01 <interferon> I'm not concerned about the safety (safeHead wfm) but was just curious if there were efficiency or expressiveness losses from doing that
08:11:39 <sipa> interferon: you are doing a limited form of dependent typing in that case, which is possible through GADTs
08:12:03 <quicksilver> interferon: well, what is the length of the list returned by "f x = if x then [2,3] else [2,3,4]" ?
08:12:41 <mux> it is "if x then 2 else 3" :-)
08:12:41 <quicksilver> and, therefore, is it safe to call head . tail . tail on it?
08:12:42 <sipa> but know that that will prevent you from writing a function for which it is impossible to tell at compile time, based on the emptyness of its arguments, whether its return value will be the empty list
08:12:57 <interferon> Good point
08:13:11 <quicksilver> (what is the length of the list returned by "s <- getLine" ?)
08:14:07 <dmwit> exists n. n
08:14:18 <interferon> So yeah, generalized length restrictions are a bit much 
08:15:44 <Jafet> head $ drop 5 fermatPrimes
08:16:22 <Zao> last fermatTheorems
08:24:16 <chvalenkar> hello, anybody out there to help me with the csv-bytestring package ?
08:26:06 <FauxFaux> Not if you don't ask a question.
08:28:01 <chvalenkar> fine ;-) .. the does perform very well for my needs (compared to Text.CSV) but it lacks support for embedded "," in fields .. .e.g. "a,b",c gets parsed wrong
08:28:43 <Zao> Oh god, CSV, run away! :D
08:28:49 <chvalenkar> I am new to haskell, so I am not able to fix it
08:29:20 <chvalenkar> if it is corrected somewhere, it would help me
08:31:03 <chvalenkar> or is there any other (simple) alternative to parse CSV to ByteString ?
08:32:09 <Jafet> You could chuck a copy of RFC4180 at the library author
08:33:51 <chvalenkar> then I would have two problem ;-)
08:35:26 <yrlnry> Is there a Haskell function whose type is analogous to Löb's theorem, m(a -> m a) -> m a ?
08:36:26 <kmc> yrlnry, yes! http://blog.sigfpe.com/2006/11/from-l-theorem-to-spreadsheet.html
08:36:55 <yrlnry> Wow, the most excellent possible answer!  Thanks very much.
08:37:07 <kmc> ours is the most excellent of all possible worlds
08:37:22 <dankna> also the only
08:37:28 <yrlnry> Worlds with Dan Piponi and #haskell are pretty excellent, I agree.
08:40:04 * ziman agrees, too. :)
08:41:30 <sipa> @djinn m (a -> m a) -> m a
08:41:30 <lambdabot> -- f cannot be realized.
08:43:04 <copumpkin> @djinn Monad m => m (a -> m a) -> m a
08:43:04 <lambdabot> -- f cannot be realized.
08:43:28 <benmachine> djinn doesn't do monads does it?
08:43:33 <copumpkin> clearly it does
08:43:33 <lambdabot> copumpkin: You have 1 new message. '/msg lambdabot @messages' to read it.
08:43:43 <sipa> @hoogle m (a -> m a) -> m a
08:43:43 <lambdabot> Control.Monad.Fix mfix :: MonadFix m => (a -> m a) -> m a
08:43:43 <lambdabot> System.IO fixIO :: (a -> IO a) -> IO a
08:43:43 <lambdabot> Control.Monad.Cont runContT :: ContT r m a -> (a -> m r) -> m r
08:43:57 <copumpkin> :t join . mfix
08:43:57 <lambdabot> forall (m :: * -> *) a. (MonadFix m) => (m a -> m (m a)) -> m a
08:44:14 <copumpkin> :t join . fmap mfix
08:44:15 <lambdabot> forall (m :: * -> *) a. (MonadFix m, Functor m) => m (a -> m a) -> m a
08:44:23 <copumpkin> :t join . liftM mfix
08:44:23 <lambdabot> forall (m :: * -> *) a. (MonadFix m) => m (a -> m a) -> m a
08:44:29 <sipa> :t (\m -> m >>= mfix)
08:44:30 <lambdabot> forall (m :: * -> *) b. (MonadFix m) => m (b -> m b) -> m b
08:44:45 <sipa> @pl (\m -> m >>= mfix)
08:44:45 <lambdabot> (mfix =<<)
08:47:22 <benmachine> @djinn Monad m => a -> m a
08:47:22 <lambdabot> f = return
08:47:26 <benmachine> oh, woo
08:47:56 <byorgey> @djinn Monad m => m (a -> m a) -> m a
08:47:56 <lambdabot> -- f cannot be realized.
08:48:19 <byorgey> I think djinn doesn't use fix
08:48:23 <copumpkin> @djinn-add class Monad m => MonadFix m where mfix :: (a -> m a) -> m a
08:48:23 <lambdabot> Cannot parse command
08:48:24 <benmachine> @djinn Monad m => (a -> b -> c) -> m a -> m b -> m c
08:48:24 <lambdabot> -- f cannot be realized.
08:48:24 <byorgey> for obvious reasons
08:49:07 <benmachine> @type liftM2
08:49:08 <lambdabot> forall a1 a2 r (m :: * -> *). (Monad m) => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
08:49:15 * benmachine realises f
08:49:27 <Kaidelong> djinn has trouble with type-classes
08:49:39 <benmachine> right
08:55:12 <lars9> is Map.fromList strict? i mean all (k,v) pairs are evaluated?
08:55:31 <dmwit> It is spine-strict.
08:55:35 <stepcut> is there a twitter feed or something that explains why code.haskell.org is down again ? I thought dons said you are suppose to follow something on twitter, but I don't see a link it the account on the front page of haskell.org in the community section
08:55:42 <dmwit> v's may not be evaluated.
08:55:45 <benmachine> lars9: the keys must be evaluated enough to compare them with each other, I think
08:55:49 <kmc> dmwit, are (,)'s evaluated?
08:55:59 <dmwit> Yes, probably.
08:56:19 <copumpkin> stepcut: http://twitter.com/#!/haskellorg
08:56:27 <Itkovian> any idea which haskell platform tarball is usable on centos?
08:57:20 <stepcut> copumpkin: thanks! Can you think of a good reason not to add that to the community links  section ?
08:57:25 <copumpkin> nope :)
09:00:18 <stepcut> i just gotta figure out which section .. should I add it to 'reddit, stackoverflow' or 'mailing lists, irc' 
09:00:42 <stepcut> i think i'll add it to the web 2.0 site list (reddit, stack overflow)
09:00:56 <monochrom> yeah :)
09:02:40 <stepcut> done: http://www.haskell.org/haskellwiki/Haskell
09:02:48 <stepcut> haters can revert it if they don't like it :p
09:03:45 <monochrom> haters will just rename "web 2.0" to "low SNR" :)
09:04:00 <stepcut> heh
09:04:40 <Zao> monochrom: I like to call it "don't dare clicking on any apparently inactive part of the site, as things will pop up when you least expect it and will JS you a new one"
09:04:55 <Zao> For someone who is habitually clicking idly on any blank part of sites, it's horribly annoying.
09:05:32 <monochrom> blank space should not have side effects
09:07:31 <ion> If nothing else, blank space that magically does something (e.g. lets you edit the text) should have an immediate hover effect, such as an appropriate mouse cursor and a highlighted background color.
09:08:06 <ion> It should not look like a blank space when your cursor is over it.
09:08:28 <quicksilver> Zao: HELP I ACCIDENTALLY THE BLANK PART
09:08:46 <monochrom> there are dysfunctional html authors who write like <a href="xxx"><div class="heading"><h1>Title</h1><p>Welcome</p></div></a> rather than the correct <div class="heading"><a href="xxx"><h1>Title</h1></a><p>Welcome</p></div>
09:09:16 <monochrom> and you can imagine similarly attaching onclick="yyy()" to the div rather than the h1
09:09:24 <benmachine> there are functional html authors but sometimes they seem to be in the minority
09:12:04 <monochrom> the previous incarnation of hpaste had this problem
09:12:32 <monochrom> functional html authors are a minority among even functional programmers
09:12:59 <dankna> more to the point
09:13:15 <dankna> there shouldn't be a div there, nor a paragraph of text
09:13:23 <dankna> (the one is a technical issue, the other a design issue)
09:13:39 <dankna> you should use css to give the h1 the appearance you want
09:13:41 <krey> hi, i'm still trying to understand continuations, should I learn scheme?
09:13:55 <dankna> if you need a wrapper to do that, use js to add the wrapper at load-time
09:29:15 <Astro> hi
09:29:26 <Astro> code.haskell.org & darcs.haskell.org are super-slow for me today
09:29:31 <Astro> any mirrors known?
09:35:27 <mightybyte> Has the Haskell community ever discussing the idea of disallowing GPL packages from hackage?
09:36:04 <dankna> why would we do that?
09:36:14 <dankna> I'm no friend of the GPL, but that doesn't seem like a friendly or productive thing to do
09:36:24 <mightybyte> Because allowing GPL packages is essentially a contradiction.
09:36:32 <ion> to what?
09:36:48 <Zao> dankna: It's way too easy to taint your application, especially if they're dependencies a bit away in the chain.
09:37:05 <mightybyte> To the implicit social contract of making your code public to the Haskell community.
09:37:16 <quicksilver> it's not a contradiction.
09:37:17 <ion> zao: That could be fixed by being noisy about licenses when installing stuff.
09:37:25 <quicksilver> it's simply taking a stance on what you want your code to be used for.
09:37:40 <Zao> ion: Thankfully GPL is the only copyleft wanker one.
09:37:57 <mightybyte> quicksilver: What are you saying when you make something public?  Typically you're saying that you want people to use your code.
09:38:02 <ion> “You’re about to install packages using the following restrictive licenses: GPL 2+. Continue?”
09:38:25 <mightybyte> In a community where BSD is the defacto license, releasing code under the GPL contradicts that.
09:38:47 <quicksilver> mightybyte: that's just two assumptions.
09:38:57 <quicksilver> certainly, uploading code to hackage implies you want people to use your code.
09:39:02 <ion> mightybyte: Now it’s you placing restrictions on software. ;-)
09:39:11 <quicksilver> I don't think it implies that you have no restrictions in mind.
09:39:13 <mightybyte> ion: I refuse to be baited. :)
09:39:27 <Twey> BSD places restrictions as well >.>
09:39:34 <kmc> oh for fuck's sake, not this again
09:40:10 <mightybyte> quicksilver: Right, but if you want GPL restrictions, then you are by default saying that you don't want the majority of the Haskell community to use it.
09:40:34 <mightybyte> kmc: I did start by asking if it's been discussed before.
09:40:35 <quicksilver> mightybyte: where is your evidence that the majority of the haskell community are unable to comply with the terms of the GPL?
09:40:35 <kmc> mightybyte, that's not true.  the majority of the Haskell community is complying with the terms of the GPL by accident
09:40:50 <quicksilver> it's certainly not my anecdotal experience.
09:41:09 <quicksilver> I very rarely hear of haskell used in ways which would be incompatible with the GPL, should it happen to be on any of the libraries in use.
09:41:18 <mightybyte> kmc: How?  By the fact that their code is really GPL when they think it's BSD?
09:41:33 <quicksilver> no, their code is still BSD, if that's what they say it is.
09:41:37 <kmc> quicksilver, it does happen -- some companies paid IHG to get rid of the GMP dependency in GHC
09:41:55 <quicksilver> if it depends on a GPLed library, that just means that any complete product based on it woul dhave to adhere to the terms of the GPL
09:42:04 <quicksilver> but you could still derive things from it
09:42:14 <quicksilver> like you might make a derived version which didn't require that GPL lib, for example :)
09:42:18 <quicksilver> and BSD would apply.
09:42:21 <quicksilver> kmc: sure.
09:42:30 <quicksilver> kmc: mightybyte claimed it was the 'majority' of the community
09:42:31 <lars9> > print 1 <*> print 2
09:42:31 <lambdabot>   Couldn't match expected type `a -> b' against inferred type `()'
09:42:40 <quicksilver> kmc: that's not the way it seems/feels to me; which is why I asked for evidence.
09:42:54 <mightybyte> Well, I don't have the hackage stats, but I would assume that the majority of hackage packages are BSD.
09:43:24 <kmc> you should hear the shit i got when i released BSD3-licensed bindings to non-free software
09:43:42 <mightybyte> kmc: From who?
09:43:51 <kmc> reddit
09:43:53 <kmc> haskell reddit
09:44:00 <mightybyte> Oh, heh.
09:44:11 <kmc> of course the Windows API bindings are BSD as well
09:44:40 <rothwell> can't stand restrictively licensed bindings
09:44:49 <mightybyte> kmc and quicksilver: Are you saying that packages that depend on GPL packages can be licensed as BSD and still be compliant?
09:44:51 <rothwell> the ada community tend to GPL all bindings, regardless of the original license...
09:45:24 <kmc> mightybyte, no, i'm saying that they could be relicensed GPL without anyone having to change what they're doing
09:45:25 <tab> mightybyte: yes absolutely
09:45:25 <kmc> in most cases
09:46:04 <kmc> i think releasing your code BSD is a nice thing to do, but releasing your code GPL is reasonable if you care a lot about specific things
09:46:20 <kmc> i think Cabal should track the flow of license obligations through dependencies, where possible
09:46:37 <mightybyte> kmc: I was thinking the same thing.
09:46:37 <kmc> i think banning GPL from Hackage is absurd and that suggesting such is a deliberate attempt to provoke a license flamewar
09:46:41 <Adamant> kmc: pretty much
09:46:43 <dcoutts_> kmc: people are working on that
09:46:50 <kmc> nice
09:46:51 <mightybyte> But that would result in one of two things.
09:47:05 <mightybyte> 1. GPL would be pushed out
09:47:22 <mightybyte> 2. GPL would take over and people would switch just because it's the path of least resistance.
09:47:25 <dcoutts_> kmc: I reviewed an initial version of such a patch, the author is working on an update
09:47:49 <dcoutts_> mightybyte: I disagree, if your code is BSD and depends on GPL then that's fine, you do not need to relicense
09:47:59 <kmc> mightybyte, i don't agree.  i don't think automated license tracking would have a big effect
09:48:01 <mightybyte> How so?
09:48:02 <tab> mightybyte: you clearly don't understand licensing :(
09:48:08 <kmc> whatever checks it's doing, people should already be doing manually
09:48:08 <mightybyte> tab: Apparently so.
09:48:31 <merijn> mightybyte: Because the GPL licensing applies to the final product which is distributed, not its component parts
09:48:39 <jix> mightybyte: the GPL can't stop you from giving away your code under the BSD license
09:48:48 <dcoutts_> mightybyte: it's a very common misconception that if A depends on B and B is GPL, then it means A must be GPL too
09:48:49 <merijn> mightybyte: And the GPL specifies that all components must grant AT LEAST the freedom specified in the GPL
09:49:10 <mightybyte> Ahhh, interesting.
09:49:14 <sm> mightybyte: read up on the fsf site
09:49:16 <mightybyte> Well that clears it up then.
09:49:16 <jix> mightybyte: no license can stop you from doing what you want with your code as you retain full copyright
09:49:25 <merijn> mightybyte: BSD license gives *more* freedom then GPL, and so BSD code can be freely combined with GPL. The end product would be GPL, but the BSD parts are still BSD
09:49:56 <merijn> mightybyte: i.e. I can take and modify the BSD parts and distribute them as non-GPL as long as I don't distribute any GPL code with them
09:49:58 <mightybyte> So the whole thing came up regarding the Snap framework's use of pandoc.
09:50:00 <tab> and nothing stop you to reimplement a GPL dependancy with a BSD license code, and they use the result as BSD
09:50:08 <dcoutts_> mightybyte: so licensing is not sensitive to dependency direction, it's undirected. In the end, the distributor just have to comply with all the licenses of all the components.
09:50:59 <dcoutts_> mightybyte: so if I give you a binary using snap and pandoc, then I must comply with the BSD and GPL
09:51:15 <kmc> which requires you to give source for *both*
09:51:17 <kmc> yes?
09:51:22 <dcoutts_> no
09:51:30 <merijn> mightybyte: This is also were the concept of GPL-compatible licenses come from. The GPL says all code must be at least as free as GPL, if a license on part of the code says you're not allowed to grant some of the freedoms GPL requires then you have a contradiction and can't legally distribute the product 
09:51:33 <tab> kmc: depends how they are combined
09:51:44 <dcoutts_> kmc: oh, erm, yes
09:52:03 <dcoutts_> kmc: would be no for LGPL 
09:52:05 <merijn> kmc: Yes, but the only thing you need to do to to comply with BSD is preserve copyright and the license disclaimer
09:53:14 <mightybyte> Ok, that clears it up for me.
09:53:44 <dcoutts_> merijn: but since you have to comply with the GPL too, then you have to provide access to the source of it all
09:53:52 <merijn> dcoutts_: Correct
09:54:20 <merijn> Hence complying to "both" BSD and GPL is rather redundant
09:54:25 <dcoutts_> right
09:54:31 <mightybyte> It seems contradictory to me.
09:54:53 <mightybyte> BSD + GPL ~= GPL
09:54:53 <dcoutts_> but complying with both BSD and LGPL is more interesting
09:55:02 <merijn> mightybyte: Yes
09:55:15 <mightybyte> But that's not what people writing BSD code want.
09:55:19 <kmc> a license isn't a property of software; it's a promise by the copyright holder saying "you can use my software if you do foo"
09:55:42 <merijn> mightybyte: The end product of BSD + GPL = GPL, but I can still take the BSD parts and throwaway the GPL
09:55:56 <merijn> mightybyte: Most likely because a lot of people forget what licenses really are. They are written agreements about who can use software and under what conditions
09:56:00 <dcoutts_> mightybyte: if they do not want that, then they should not use GPL components
09:56:07 <mightybyte> kmc: So how can the copyright holder say both "you can have this only if you GPL it" (GPL) AND "you can have this and do whatever you want with it" (BSD)?
09:56:12 <copumpkin> licenses form a lattice?
09:56:25 <dcoutts_> copumpkin: I think it's not that simple
09:56:26 <merijn> Most companies require you to pay for a license, BSD and GPL say "everyone who complies with these terms is granted permission to use it"
09:56:52 <copumpkin> dcoutts_: oh, true
09:56:59 <copumpkin> just a partial order of some sort, I guess
09:57:05 <merijn> mightybyte: The copyright holder of a piece of software is free to distribute whichever license he wants to whomever he wants
09:57:09 <mightybyte> merijn: But since the GPL's terms are more restrictive than BSD's, BSD effectively goes out the window.
09:57:28 <tab> mightybyte: the BSD License doesn't say anything against putting extra restrictions.
09:57:29 <merijn> mightybyte: I can tell everyone you can have my code under GPL and then grant a specific person a non-GPL license, then that person is not bound by the GPL
09:57:29 <mightybyte> merijn: But not if he's got to GPL
09:57:59 <mightybyte> tab: I know the license doesn't say anything, but typically if you're using that license you don't want the extra restrictions.
09:58:05 <dcoutts_> mightybyte: it obviously has to be possible to comply with both simultaneously, otherwise they cannot be used together
09:58:07 <merijn> The only requirement for using software (legally) is that you have a valid license
09:58:37 <dcoutts_> mightybyte: that's what precludes proprietary and GPL from being combined, it's not possible to simultaneously satisfy both
09:58:43 <tab> mightybyte: of course, but that's the up to the developer/user to depends on only BSD stuff in this case
09:58:51 <merijn> mightybyte: You are correct, and as dcoutts_ points out BSD permits you to take the code and put restrictions on it. Hence why you can combine BSD and GPL
09:59:05 <mightybyte> dcoutts_: Right, that's why I think hackage should at the very least warn when you list BSD but depend on something GPL
09:59:35 <dcoutts_> mightybyte: I think a warning is wrong, but what it should do is say what other licenses you would have to comply with
09:59:47 <mightybyte> That might work too.
09:59:50 <dcoutts_> mightybyte: and that's what the Cabal patch people are working on is for
10:00:03 <dcoutts_> mightybyte: a warning suggests there is something wrong, when there isn't
10:00:27 <kmc> yes, it is entirely consistent that i might license my software BSD knowing full well that anyone using it has to license their product GPL
10:00:35 <kmc> due to a dependency
10:00:35 <mightybyte> Well, in my mind there is something wrong if I'm telling cabal that I want BSD when I really have to also specify GPL.
10:00:44 <kmc> there are several good reasons for that mightybyte
10:00:58 <kmc> and again, it's not that *you* have to specify GPL
10:01:07 <kmc> it's that anyone building a binary with your lib and its dependencies has to comply with GPL
10:01:13 <dcoutts_> mightybyte: it's the distinction between the package itself and the combined tree of dependencies (which is really rather fluid)
10:01:15 <merijn> mightybyte: Counter example:
10:01:34 <kmc> but maybe i want to license my library BSD, in anticipation that others might adapt it for something unrelated, or that a BSD replacement for my GPL dep may come about
10:01:45 <dcoutts_> mightybyte: we can calculate the "effective" set of licenses, and it depends on what choices of dependencies the user makes
10:01:51 <mightybyte> Yeah, but as a Snap framework author, I don't want any GPL creeping in anywhere.
10:02:10 <kmc> but the GPL can't creep into your BSD-licensed code
10:02:17 <merijn> Take a library which is GPL, I have a BSD program using it. I could obtain a non-GPL license from the owner to distribute the GPL library with my software under the BSD license (this probably wouldn't happen, it makes no sense, but you could do it)
10:02:21 <kmc> it can only creep into binaries built with both your code and some GPL code
10:02:22 <copumpkin> there's a lot of FUD about the GPL out there
10:02:28 <mightybyte> kmc: Precisely
10:02:31 <dcoutts_> mightybyte: that's semantically a different thing, and it's a reasonable thing to want to look for
10:02:41 <quicksilver> mightybyte: then it's your responsibility to look at the packages you depend on - or consider depending on .
10:02:56 <quicksilver> mightybyte: really, it's *always* your responsibility to look at the license of libraries you plan to use.
10:03:09 <tab> absolutely
10:03:12 <quicksilver> I think you might have been saying "If everything on hackage was forced to be BSD, I wouldn't have to think like this"
10:03:12 <tab> and understand what license ares
10:03:15 <dcoutts_> mightybyte: and once we can calculate the effective set of licenses then it's easy to check that against an assertion like == [BSD3] (ie no more than that set)
10:03:15 <kmc> there is a meaningful difference between "this library is GPL" and "this library, if compiled today with these exact dependencies, would be also bound by GPL requirements"
10:03:18 <quicksilver> that's true, of course.
10:03:26 <quicksilver> but, it doesn't mean we should do it ;)
10:03:34 <quicksilver> plenty of people want to write GPL software.
10:03:37 <kmc> yeah, it's a nice thing to say if you want to start a flamewar
10:03:45 <dcoutts_> kmc: right, especially given optional dependencies and packages changing their license
10:04:23 <kmc> i think the case of "someone else makes a BSD replacement for the GPL library" is particularly relevant
10:04:37 <mightybyte> quicksilver: Right, but I think it gets a little more involved.  Because the desire to write BSD (minus GPL) code (which I think is common in this community is common) is poisoned by the existence of an increasing body of GPL work.
10:04:38 <kmc> "oh, GHC depends on libgmp, we might as well license all of GHC under the GPL"
10:04:38 <kmc> no.
10:05:00 <quicksilver> mightybyte: I don't really think it's poison. You're no worse off than if it simply wasn't tehre.
10:05:05 <kmc> mightybyte, see, i'd have more confidence that you're interested in a serious debate, rather than trolling, if you'd avoid words like "poisoned"
10:05:05 <quicksilver> mightybyte: no one is forcing you to use it.
10:05:13 <kmc> anyway i have real work to do
10:05:48 <mightybyte> quicksilver: I disagree, because it leads the community to believe that it's there for GPL-less use when it's really not.
10:06:09 <dcoutts_> mightybyte: some commercial users are interested in checking that, because they want to release proprietary software. That's mainly why we've been working on this license patch for cabal
10:06:17 <quicksilver> mightybyte: no, it doesn't.
10:06:23 <quicksilver> mightybyte: only to ignorant members of the community.
10:06:29 <quicksilver> the licenses are there, to read them.
10:06:30 <mightybyte> Yes
10:06:33 <copumpkin> how about having hackage/cabal tell you "this is the license for this package directly, and this is the most restrictive license of its dependencies" separately?
10:06:37 <mightybyte> People tend to gloss over licenses.
10:06:54 <quicksilver> nothing "leads people to believe libraries are there for GPL-less use"
10:06:55 <dcoutts_> copumpkin: I'd prefer to list the set of licenses
10:06:56 <quicksilver> that's just a fiction.
10:06:56 <copumpkin> I guess there isn't necessarily a most restrictive license
10:06:57 <merijn> mightybyte: Their fault
10:07:03 <mightybyte> Doubly so when the points of interest are way down the dependency tree.
10:07:04 <quicksilver> some people may hold that fiction in their heads
10:07:04 <copumpkin> since it isn't a lattice, as we already established :P
10:07:07 <dcoutts_> copumpkin: and check that the set is not inconsistent
10:07:14 <copumpkin> dcoutts_: yeah, much better idea :)
10:07:33 <dcoutts_> mightybyte: yes, I'm sure people are violating the BSD left right and centre
10:07:33 <quicksilver> tools to make licenses more visible are a good idea - viz. what dcoutts_ is discussing.
10:07:50 <copumpkin> preflex: seen Berengal 
10:07:51 <preflex>  Berengal was last seen on #haskell 4 days, 12 hours, 48 minutes and 56 seconds ago, saying: kmc: Or you could allow the constraint by adding context aliases/families or some similar magic extension
10:09:39 <mightybyte> Yeah, I think these tools will be helpful.
10:10:00 <dcoutts_> copumpkin: the first version of the patch that I reviewed took the lattice approach (which sort-of follows the incorrect GPL poisoning idea), I suggested moving to the set + consistency check model.
10:10:19 <copumpkin> dcoutts_: cool, I can't wait :)
10:10:27 <copumpkin> well, I obviously can :P
10:10:29 <dcoutts_> the other part is collecting license files
10:10:31 <copumpkin> but I'm looking forward to it
10:10:46 <dcoutts_> since as I said, I'm sure we violate the BSD licenses of the base libs all the time
10:10:54 <dcoutts_> because it's too hard to collect the license files
10:11:18 <mightybyte> dcoutts_: How do we violate the BSD licenses?
10:11:45 <dcoutts_> mightybyte: do you always include the copyright notice and license for all the dependencies?
10:11:48 <iFire> sublicensing? no idea
10:11:52 <mightybyte> Ahh
10:12:01 <dcoutts_> it's what the license says we must do
10:12:05 <iFire> dcoutts_ well they removed the advertising clause
10:12:05 <mightybyte> Yeah
10:12:23 <iFire> dcoutts_ so you go and strip out all the exisiting licenses?
10:12:40 <merijn> mightybyte: Assuming the base libs are BSD your program should be distributed listing the copyright holders of the base lib
10:12:42 <iFire> shouldn't they still be in the source folders?
10:12:57 <merijn> If you code is lacking this information you're violating the license
10:13:01 <mightybyte> ok
10:13:07 <dcoutts_> iFire: sure they removed the advertising clause, but not the bit that says "Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution."
10:13:26 <dcoutts_> ie the LICENSE file of that package
10:13:49 <dcoutts_> so you need to collect the license file for all the dependencies
10:14:00 <merijn> mightybyte: But I'd recommend just *reading* the BSD license, its like 15 lines of text, tops
10:14:22 <iFire> I guess the mit has sublicensing
10:14:27 <iFire> mit license
10:14:51 <iFire> it doesn't have that requirement
10:15:04 <ramb0> mightybyte: There's also a poetic version of the bsd license: http://www.gerv.net/writings/poetic-licence/bsd.html
10:15:15 <mightybyte> ramb0: Heh
10:15:35 <iFire> merijn hmm I wonder how hard it is to "grep" for the bsd licenses and chug them into a text file
10:15:52 <iFire> automated
10:15:55 <dcoutts_> iFire: it's a similar text in the MIT "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software."
10:15:59 <rothwell> http://en.wikipedia.org/wiki/ISC_license
10:16:00 <rothwell> <3
10:16:18 <dcoutts_> iFire: we can do better than that, .cabal files specify a license file
10:16:36 <mightybyte> The source of my error was the fact that when I think "BSD" I am implicitly assuming that I *don't* want GPL tacked on.
10:16:43 <merijn> iFire: Pretty easy, probably
10:16:55 <dcoutts_> mightybyte: right, maximum rather than minimum
10:17:04 <iFire> of course cabal has all the licenses
10:17:08 <mightybyte> Yeah, which I think might be a common thought.
10:17:22 <rothwell> i'm not sure cabal has ISC
10:17:27 <rothwell> it's been a while since i checked, though
10:17:33 <dcoutts_> mightybyte: which is why we want to make the information available
10:17:56 <merijn> mightybyte: For example, some company could take your BSD code and distribute it as a closed source proprietary license and it'd be legal. As long as the binary produces the license information somewhere (About box, for example?)
10:18:21 <iFire>  "Copyright by Foo Bar, 2009" statement? is good enough?
10:18:46 <merijn> iFire: No, I believe the entire notice has to be shown
10:19:08 <elitheeli> I often want to partition a list of things based on constructor. For example, if I have data Fruit = Apple String | Orange String, and I want to get all the apples in foos :: Fruit, I write an isApple predicate and then call "partition isApple foos". Is there an easier way to say "has a certain constructor"?
10:19:11 <merijn> iFire: See: "Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution."
10:19:53 <iFire> anyone use google chrome. check out their about:credits page
10:21:17 <Saizan> elitheeli: not really, though if you want only the ones that match a list comprehension is handy: [ x | x@(Apple _) <- xs ]
10:22:57 <sm> wow.. what did you do to my colloquy (about:credits)
10:23:32 <elitheeli> Saizan: that's neat. I do want to partition, though. Would something like partition (\x -> null [True | (Apple _) <- [x]) foos work?
10:25:48 <Saizan> elitheeli: better to use "partition (\x -> case x of Apple _ -> True; _ -> False)" then
10:26:19 <elitheeli> k
10:26:48 <copumpkin> that's an interesting approach to that case though :P
10:27:51 <Saizan> btw, you can use Apple{} instead of Apple _; so it'll work even if Apple changes arity
10:28:07 <hpc> Saizan: ooh, that's a cool trick
10:28:09 <chrisdone> Good evening.
10:28:17 <hpc> Saizan: does that work on non-record types?
10:28:34 <hpc> > let foo True{} = True in foo True
10:28:35 <lambdabot>   True
10:28:43 <hpc> :D :D :D
10:29:15 <hpc> > let foo Left{} = True in Left error
10:29:16 <lambdabot>   Overlapping instances for GHC.Show.Show ([GHC.Types.Char] -> a)
10:29:16 <lambdabot>    arising ...
10:29:31 <hpc> > let foo Left{} = True in foo (Left error)
10:29:32 <lambdabot>   True
10:33:35 <Saizan> hpc: yeah, quite nice :)
10:34:02 <Cin> What exactly is the trick?
10:34:35 <hpc> Cin: match on constructor only
10:34:37 <Cin> The {} syntax?
10:34:53 <Cin> (Oh, I thought that was quite well known.)
10:37:12 <Saizan> it's nothing new, but it doesn't get much airtime
10:37:33 <Saizan> (a bit like the aztec god from yesterday..)
10:37:35 <Cin> It is a really nice feature, I use it often.
10:39:58 <Cin> I think I will snatch the zero-arity constructor capability for Lisk.
10:41:48 <Cin> E.g.
10:41:49 <Cin> (= is-just 'nothing 'false)  => isJust Nothing{} = False
10:41:49 <Cin> (= is-just 'just 'true)      => isJust Just{} = True
10:41:49 <Cin> Nice.
10:41:55 * Cin gives hpc cake for the idea.
10:42:14 <hpc> :D
10:42:28 * hpc adds it to his collection of pie and ice cream
10:52:05 * BMeph prefers to collect such things...IN HIS BELLY!
10:59:48 <elliott> <Cin> (= is-just 'nothing 'false)  => isJust Nothing{} = False
10:59:48 <elliott> <Cin> (= is-just 'just 'true)      => isJust Just{} = True
10:59:51 <elliott> i don't like those implicit parens ...
11:00:29 <mauke> what implicit parens?
11:03:53 <Cin> elliott: You mean the implicit curly braces? If so, why?
11:04:40 <duckinator> hi
11:04:48 <elliott> Cin: It should be (= (is-just 'nothing) 'false), no?
11:05:24 <Twey> I guess the last element of the list is special…
11:05:39 <elliott> i.e., implicit parens. :P
11:06:19 <Cin> elliott: Oh, yes. There are implicit parens for the parameters. (= is-just 'nothing 'false) => (= is-just ('nothing) 'false).
11:06:40 <elliott> Cin: Erm, presumably you mean (= (is-just 'nothing) 'false).
11:06:45 <Cin> No.
11:07:03 <elliott> If not, this language has long strayed from the realms of Lisp and even plain S-Expressions into the realms of "basically prefix notation with parens around the whole expression". :p
11:07:26 <mauke> (defun is-just ('nothing) 'false)
11:07:28 <Cin> Not really, Common Lisp would be (defun is-just (nothing) ..)
11:07:38 <mauke> commonmind
11:07:51 * Cin commonlaughs
11:08:15 <elliott> Oh, oh, it's a definition.
11:08:20 <hpc> this conversation is hurting my comind
11:08:22 <elliott> Not a check for equality.
11:08:35 <elliott> That makes much more sense then.
11:08:36 <duckinator> oh aren't you guys punny!
11:09:10 <duckinator> or, compunny, maybe?...no....*wanders off*
11:09:26 <elliott> these puns are way too common
11:09:38 <duckinator> *rimshot*
11:09:40 <mauke> oh, come on
11:09:44 <elliott> i suggest we establish commpununism ... there, nobody can top the badness of that pun now
11:09:56 <elliott> we can all stop knowing we can't possibly ascend the ranks of bad
11:10:08 <duckinator> mauke: was that intentional? if so, well played :P
11:10:47 <Cin> elliott: It's mostly to mirror vanilla Haskell. Also, it matches with: (fn x x) => (\x -> x)
11:10:51 <Twey> elliott: Surely you must feel some compunction about spoiling everyone's pun.
11:11:01 <elliott> Cin: Right.
11:11:10 <elliott> Twey: Has this now become "words starting with com"? :P
11:11:18 <duckinator> any of you guys played with a VM/emulator of any sort in haskell?
11:11:23 <elliott> I need a companion to help me achieve world pun domination.
11:11:31 <Twey> elliott: It has ‘pun’ in it too.  :þ
11:11:45 <Twey> Cin: Are you basing this off Liskell?
11:12:07 <elliott> Basing anything off Liskell is a mistake :P
11:12:08 <Cin> Twey: No.
11:12:15 <Twey> Why?
11:12:35 <pumpkin> I love that this guy is getting upvoted when his code doesn't work, http://www.reddit.com/r/programming/comments/em0ln/static_vs_dynamic_language_challenge/c194ycf
11:12:58 <duckinator> lol
11:13:18 <pumpkin> furthermore, it doesn't even make sense
11:16:03 <Cin> I'm basing it off Haskell, and adding a sexpr twist.
11:16:04 <Cin> Twey: Things I don't like about Liskell are: (lambda (x) x) instead of (fn x x), (* 1 (* 2 3)) instead of (* 1 2 3), (Just 1) instead of ('just 1), (defmodule HelloWorld) instead of (module hello-world), etc. Liskell doesn't feel very Lispy to me. It takes the (subjective) bad things from both Haskell and Lisp, IMHO.
11:17:55 <duckinator> Cin: writing a compiler/interpreter in haskell, or..?
11:18:36 <Cin> duckinator: A .hs file preprocessor from a Lispy Haskell to vanilla Haskell.
11:18:50 <duckinator> ah, neat
11:18:52 <lispy> Lispy Haskell?
11:19:02 <lispy> Are you saying I code in a weird style/
11:19:03 <lispy> ?
11:19:06 <duckinator> haha
11:19:15 <duckinator> lispy: read what he said a few lines above that :P
11:19:49 <roconnor> pumpkin: I don't understand what this CodeTree thing is supposed to do
11:19:54 <Cin> lispy: Don't play coy with me. It's like reading Pascal in reverse.
11:20:01 <pumpkin> roconnor: "add polymorphism!"
11:20:05 <pumpkin> read the one above it
11:20:16 <Eelis> ugh. i'm trying to revive some old code of mine, and apparently the OpenGL package now defines GLdouble as a newtype of Double with a hidden constructor, instead of a simple type alias. consequently, it now needs its own separate Random instance, and i can't even figure out how to convert a normal Doubel to a GLdouble. what a mess
11:20:34 <Eelis> *Double
11:20:47 <mauke> Eelis: big guns. realToFrac.
11:20:47 <pumpkin> Eelis: realToFrac maybe?
11:21:03 <Cin> Eelis: Can't you just derive?
11:21:05 <pumpkin> you can use standalone deriving and newtype deriving to get instances for it
11:21:20 <Eelis> standalone deriving doesn't work because the constructor is hidden
11:21:35 <Eelis> mauke: will that compile down to just the ctor?
11:21:36 <Cin> I herd you like instances so we enabled -XGeneralisedNewtypeDeriving so you can derive while you derive.
11:21:36 <lispy> What I love is when I tell people I write Haskell code for a living and they say, "People still use Pascal?"
11:21:43 <Cin> Ahh, drat.
11:21:51 <burp> pascal? o0
11:22:00 <mauke> Eelis: I don't know
11:22:03 <ezyang> lispy: I get that a lot too! 
11:22:03 <duckinator> lispy: ...wha? o.O
11:22:08 <Cin> lispy: Ever heard someone pronounce "Haskell" like "Pascal"?
11:22:18 <Eelis> @src realToFrac
11:22:18 <lambdabot> realToFrac = fromRational . toRational
11:22:25 <Eelis> so that sucks.
11:22:43 <duckinator> Cin: personally, i've never heard someone pronounce haskell, so... D;
11:22:56 <hpc> Cin: i do
11:23:00 <pumpkin> yeah, the generic realToFrac is terrible
11:23:09 <pumpkin> it has lots of rewrite rules for the builtins, but that's not useful here
11:23:39 <Cin> Eelis: Will that compile down to unGLDouble . GLDouble?
11:23:42 <jmcarthur> Cin: i have. they were quickly corrected
11:23:44 <lispy> Cin: I have and it's hard to listen to
11:23:51 <c_wraith> Obviously, the answer is unsafeCoerce :)
11:24:08 <jmcarthur> and i'm also had people think i was saying Pascal, too
11:24:09 <Eelis> Cin: i need to convert a Double to a GLdouble, not the other way around (yet)
11:24:11 <jmcarthur> (i've
11:24:11 <duckinator> i tend to pronounce it "hask-ell", as surprising of a pronunciation as that may be. Is that correct, or do I risk being shunned if I keep doing that? ;P
11:24:29 <pumpkin> Eelis: unsafeCoerce!
11:24:30 <jmcarthur> it's pronounced like "rascal"
11:24:34 <Cin> SPJ said that if an instance is derived for newtypes then use of the methods esp. for converting is a no-op.
11:24:36 <jmcarthur> but with an h
11:24:49 <Eelis> pumpkin: :'(
11:25:11 <c_wraith> Eelis, this is a case where unsafeCoerce is correct....  So long as the implementation remains a newtype
11:25:26 <Cin> E.g. newtype MyString = MyString String deriving (IsString); fromString "x" :: MyString is equivalent to (MyString "x").
11:25:38 <jmcarthur> unsafeCoerce is not correct here unless you are modifying the OpenGLRaw package
11:25:40 <duckinator> jmcarthur: i was only a letter off :P of course, technically people also only a letter off if they pronounce it "pascal" *hides*
11:25:41 <Eelis> c_wraith: maybe i'll use it as a kludge and ask the GL package maintainer to add a Random instance to the package then
11:25:51 <duckinator> are also* :|
11:26:01 * duckinator should proofread what he says a bit more
11:26:23 <c_wraith> Eelis, I think you'd be better off asking for efficient conversion functions to and from Double
11:27:25 <Eelis> c_wraith: well, i suspect that the whole point of changing to newtypes was to get rid of the assumption that GLdouble is basically a Double, so i'd expect the guy to be reluctant to add such a conversion :)
11:27:50 <c_wraith> Eelis, the advantage of having such conversion functions is that they would at least remain correct if the underlying type did change
11:28:10 <dskippy> I am interested in creating two types that have a mathematical relationship. Both are Enums. Call them Note and Interval. A Note + Interval = Note. Also Interval + Note = Note. A Note + Note is nonsense. Note - Note = Interval. I have written a bunch of operations out using fromEnum and toEnum all of the place. Is there a cleaner way? Perhaps using "instance Num"?
11:29:06 <ezyang> dskippy: Trying to make Interval -> Note -> Note commutative is... not really a good idea. 
11:29:34 <roconnor> dskippy: such a thing is called a torsor
11:29:47 <c_wraith> dskippy, this kind of problem is also common in time libraries, where you have timestamps and durations
11:29:52 <jmcarthur> dskippy: what does it mean when you say that Note + Interval = Note?
11:29:57 <roconnor> dskippy: also known as a principle homogenous space
11:30:07 <roconnor> dskippy: http://en.wikipedia.org/wiki/Principal_homogeneous_space
11:30:22 <roconnor> dskippy: also, they are totally awesome
11:30:25 <jmcarthur> dskippy: does it mean that you are extending the duration of the note?
11:30:26 <Eelis> jmcarthur: presumably that he has a meaningful "addition" operation of type  Note->Interval->Note
11:30:40 <jmcarthur> Eelis: i'm talking about the *meaning* of that operation
11:30:48 <Eelis> k
11:30:58 <c_wraith> jmcarthur, A + 8th = A
11:31:00 <kisielk> an interval is the distance between two pitches. Presumably if you add an interval to a pitch, you raise or lower the pitch by that interval
11:31:10 <jmcarthur> oh that kind of interval, duh
11:31:13 <kisielk> at least that would be my interpretation
11:31:23 <jmcarthur> i was thinking too much frp ("duration")
11:31:28 <c_wraith> Yes, an 8th is a stupid interval. :)
11:31:33 <elitheeli> I have a complicated record type and usually only one thing of this type, let's call it foo. I often use the pattern let foo1 = foo {x = y} ; foo2 = doStuff foo1 ; etc ; in fooN. I'm pretty sure the right way to do this would be some type of monad instead of a record... just not quite sure where to get started.
11:31:44 <jmcarthur> c_wraith: not really. could be A1 + 8th = A2
11:31:50 <duckinator> dskippy: for Note+Interval=Note there's no reason for it to be commutative afaik, and would likely be simpler to not make it so
11:31:55 * hackagebot clock 0.2.0.0 - High-resolution clock and timer functions:  realtime, monotonic, cputime, etc.  http://hackage.haskell.org/package/clock-0.2.0.0 (CetinSert)
11:32:13 <c_wraith> jmcarthur, it's just that usually you'd say "an octave", not "an 8th" :)
11:32:19 <dskippy> duckinator: Sure. I can skip the commutativity.
11:32:25 <jmcarthur> dskippy: it sounds to me like you have an affine space. checkout the vector-space package for some type class goodies
11:32:34 <pumpkin> dskippy: why should Note - Note = Interval?
11:32:41 <pumpkin> why not dist Note Note = Interval :P
11:33:08 <roconnor> pumpkin: presumably Interval is signed
11:33:17 <jmcarthur> dskippy: http://hackage.haskell.org/packages/archive/vector-space/0.7.2/doc/html/Data-AffineSpace.html
11:33:22 <pumpkin> I just wonder why you'd want (-) there
11:33:30 <duckinator> dskippy: if you figure out how to implement Note+Interval=Note, can you let me know? i'm kinda new to haskell, curious about that kind of stuff ;)
11:33:31 <dskippy> roconnor: jmcarthur   This is music theory.
11:33:40 <jmcarthur> dskippy: i know what it is
11:33:48 <jmcarthur> dskippy: math is relevant ;)
11:33:50 <roconnor> pumpkin: that is the normal notation for an affine space or a commutative torsor
11:33:59 <pumpkin> roconnor: one that doesn't have addition?
11:34:05 <pumpkin> it seems odd to talk about subtraction without addition
11:34:12 <pumpkin> or even a notion of an additive inverse
11:34:13 <jmcarthur> pumpkin: http://hackage.haskell.org/packages/archive/vector-space/0.7.2/doc/html/Data-AffineSpace.html
11:34:35 <pumpkin> ah, I see
11:34:36 <dskippy> pumpkin: And interval is defined by two notes. It's the semitones between them.
11:34:53 <jmcarthur> dskippy: what you have is just an affine space
11:35:04 <kisielk> the question is, is the Note here just the pitch? or does it also include the duration?
11:35:21 <kisielk> the use of - could be ambiguous in that case..
11:35:56 <elitheeli> pumpkin: it makes sense to subtract two points (gets the vector from 2nd to 1st), makes sense to add a point and a vector, makes sense to add two vectors, makes sense to subtract a point and a vector, doesn't really make sense to add two points.
11:36:02 <dskippy> jmcarthur: Is there a library for this sort of thing? Or a common idiom for constructing these types?
11:36:09 <jmcarthur> dskippy: i just linked you to it
11:36:11 <jmcarthur> http://hackage.haskell.org/packages/archive/vector-space/0.7.2/doc/html/Data-AffineSpace.html
11:36:11 <pumpkin> elitheeli: that last bit is what I was talking about :P
11:36:13 <dskippy> Or should I just make my own + - functions?
11:36:27 <dskippy> Oh I miseed that 
11:36:30 <jmcarthur> that's actually the third time i've linked it ;)
11:36:35 <roconnor> dskippy: you should make your own + and - functions
11:37:00 <elitheeli> pumpkin: I know, what I'm saying is that it's pretty common to have two types where mashing them together in every way except one makes sense
11:37:33 <elitheeli> anyway, someone wanna lend me some monadic advice?
11:37:58 <shepheb> elitheeli: take a look at Data.Accessor, maybe?
11:38:00 <roconnor> jmcarthur: ironically that isn't the definition of an Affine Space
11:38:07 <roconnor> jmcarthur: that is a torsor
11:38:29 <roconnor> @tell conol: 
11:38:29 <lambdabot> Consider it noted.
11:38:32 <roconnor> oops
11:39:16 <roconnor> @tell conal Your definition of Affine Space at http://hackage.haskell.org/packages/archive/vector-space/0.7.2/doc/html/Data-AffineSpace.html#t:Diff isn't an Affine Space.  Rather it is a Torsor.  An Affine Space is a torsor with a scaler product.
11:39:16 <lambdabot> Consider it noted.
11:39:43 <jmcarthur> ah i was about to ask what the difference was
11:40:27 <kisielk> does anyone here use Vim as their Haskell editor? I'm look for an example of a good automatic alignment configuration
11:41:20 <benmachine> kisielk: I do but I don't get it to indent for me :P
11:41:58 <kisielk> seems that Emacs has some pretty fancy alignment facilities for Haskell
11:42:52 <jmcarthur> not that fancy. just toggles between a few somewhat sensible levels of indentation
11:42:53 <benmachine> emacs has some pretty fancy everything
11:44:38 <conol> hi
11:44:38 <lambdabot> conol: You have 1 new message. '/msg lambdabot @messages' to read it.
11:47:28 <elitheeli> shepheb: Data.Accessor looks a little old, it uses deprecated things
11:48:55 <benmachine> which ones?
11:49:21 <roconnor> Data.Accessor is awesome!  what's the problem?
11:49:21 <benmachine> usually if something is deprecated that's easy to fix
11:50:20 <roconnor> elliott: don't forget you also can use data-accessor-monadLIb data-accessor-monads-fd data-accessor-tf data-accessor-mtl data-accessor-template or data-accessor-transformers as required
11:50:34 <benmachine> neat
11:50:55 <roconnor> in particular I hold up http://hackage.haskell.org/package/data-accessor-transformers as a geeming gem of greatness
11:51:27 <roconnor> granted, I don't know the problem trying to be solved
11:51:39 <elliott> roconnor: wait wut
11:51:45 <elliott> i think you meant me not
11:51:55 <roconnor> er
11:51:56 <roconnor> sorry
11:52:14 <roconnor> I meant elitheeli
11:52:35 <roconnor> who disappeared?
11:52:47 <benmachine> oh, so they did
11:52:51 <benmachine> immediately
11:52:54 <roconnor> :/
11:54:05 <roconnor> wtf.
11:54:15 <roconnor> data-accessor was last updated Nov 22nd
11:54:19 <roconnor> how is that old?
11:55:06 <elliott> roconnor: it's old in INTERNET TIME!
11:55:17 <roconnor> you mean swatch's time?
11:55:39 <elliott> roconnor: no, i mean internet-attention-span-time
11:55:45 <roconnor> http://en.wikipedia.org/wiki/Swatch_Internet_Time
11:55:52 <elliott> i know :P
12:02:04 * hackagebot cmdargs 0.6.5 - Command line argument processing  http://hackage.haskell.org/package/cmdargs-0.6.5 (NeilMitchell)
12:05:53 <byorgey> oooh, new cmdargs!
12:06:25 <arcatan> once again?
12:06:30 <Cin> om nom ndm
12:09:06 <pedro3005> how can I sort a list of tuples considering only the second element of each tuple?
12:09:20 <Zao> @type (comparing snd)
12:09:20 <lambdabot> forall a b. (Ord b) => (a, b) -> (a, b) -> Ordering
12:09:29 <Zao> @type sortBy
12:09:29 <copumpkin> sortBy (comparing snd)
12:09:29 <lambdabot> forall a. (a -> a -> Ordering) -> [a] -> [a]
12:09:37 <Zao> copumpkin: Aaw, spoiler.
12:09:40 <copumpkin> lol
12:09:59 <Cin> copumpkin: What happens at the end of Sixth Sense?
12:10:19 <copumpkin> it was his dog, all along!
12:10:35 <Adamant> Cin: DUMBLEDORE DIES
12:10:51 * Cin throws his lambdas out of the pram
12:11:41 <absentia> http://i.imgur.com/2dr29.jpg
12:15:29 <McManiaC> dumbledore? :>
12:15:33 <byorgey> haha
12:15:34 <absentia> :-)
12:17:05 <conal> roconnor: thanks for the message about torsor vs affine.
12:19:54 <aWagner> Hey, does anyone know what happened to that very nice tutorial "Haskell for C Programmers"? It seems to have been deleted.
12:20:05 <conal> roconnor: have you looked at the alerp function in Data.AffineSpace? is it the scalar product you meant?
12:20:34 <conal> roconnor: alerp :: (AffineSpace p, VectorSpace (Diff p)) => p -> p -> Scalar (Diff p) -> p
12:21:42 <pedro3005> can somebody help me with http://paste.pocoo.org/show/305314/ ?
12:21:57 <ezyang> pedro3005: What's the problem? 
12:22:26 <pedro3005> ezyang, http://paste.pocoo.org/show/305316/
12:24:06 <ezyang> :t compare 
12:24:07 <lambdabot> forall a. (Ord a) => a -> a -> Ordering
12:24:50 <ezyang> :t sortBy 
12:24:51 <lambdabot> forall a. (a -> a -> Ordering) -> [a] -> [a]
12:25:43 <ezyang> What is the type of y? 
12:25:53 <pedro3005> tuple
12:26:01 <ezyang> What is the type of snd y? 
12:26:31 <pedro3005> Int
12:27:16 <ezyang> Your lambda expands to \y y' -> compare (snd y) y' 
12:27:25 <ezyang> What is the type of y'? 
12:28:10 <pedro3005> it does?
12:28:14 <pedro3005> I guess Int too?
12:28:14 <ezyang> Yes. 
12:28:38 <ezyang> Have you figured it out then? 
12:29:34 <pedro3005> I don't think so
12:29:57 <ezyang> Ok, so x :: tuple, and y :: int 
12:30:05 <ezyang> What is the type of the function a compareBy takes? 
12:30:35 <ezyang> erm, y :: tuple, y' :: int 
12:31:44 <teki> is there a version of (!!) which takes second argument an Integer?
12:31:50 <teki> as opposed to an Int
12:31:52 <ezyang> teki: Use fromIntegral 
12:31:58 <mauke> genericIndex
12:31:58 <teki> oh right
12:32:14 <teki> muake: that is neat
12:32:17 <teki> i hadn't heard of that
12:32:27 <teki> ezyang: i didn't think of that :: facepalm
12:33:42 <HugoDaniel> hi
12:34:00 <HugoDaniel> what is the fastest text parser in haskell ?
12:34:22 <HugoDaniel> does the uu-parsinglib have a good performance ?
12:34:36 <pedro3005> ezyang, I see, it takes two of the same type
12:34:54 <ezyang> Yep. 
12:38:29 <pedro3005> ezyang, well my problem was to sort the list by the second element of the tuples
12:38:46 <ezyang> pedro3005: Sure. In that case, you need to snd both arguments, not just the first one. 
12:39:14 <ezyang> Alternatively use Data.List.Key 
12:39:20 <ezyang> or some variant. 
12:41:59 <pedro3005> ezyang, like (\y z -> compare $ (snd y) snd z) ?
12:42:13 <ezyang> pedro3005: Yes, but your precedence is wrong. 
12:43:16 <Twey> sortBy (comparing snd) lst
12:52:21 <tromp> :t comparing
12:52:22 <lambdabot> forall b a. (Ord a) => (b -> a) -> b -> b -> Ordering
12:52:40 <hpc> comparing = (compare `on`)
12:52:42 <hpc> @src on
12:52:42 <lambdabot> (*) `on` f = \x y -> f x * f y
12:55:19 <shapr> Does anyone know of an assembler written in Haskell?
12:55:27 <shapr> I think I asked this question before, but I forget the answer.
12:55:55 <copumpkin> shapr: harpy?
12:56:06 <copumpkin> or you mean something that parses assembly first?
12:56:19 <hpc> http://hackage.haskell.org/package/assembler perhaps?
12:57:02 <shapr> copumpkin: I wanted to see how hard it would be to write my own assembler, so I figured I'd examine some other assembler written in Haskell.
12:57:16 <copumpkin> @hackage harpy
12:57:16 <lambdabot> http://hackage.haskell.org/package/harpy
12:57:20 <shapr> hpc: that does look interesting
12:57:31 <copumpkin> so if you write a simple parser, this does the rest :P
12:57:47 <shapr> copumpkin: Er, what about non-x86?
12:57:48 <hpc> judging from the module naming, it compiles 64-bit powerPC code
12:57:52 <copumpkin> shapr: pff!
12:58:08 <copumpkin> shapr: I might eventually get around to doing an ARM one, but it's pretty low on the todo list
12:58:11 <shapr> I want to write an assembler for atmel and msp430 chips.
12:58:19 <copumpkin> and the todo list tends to be infinitely long
12:58:48 <hpc> copumpkin: do what i do; declare todo-list bankruptcy every so often
12:58:57 <copumpkin> hpc: but I want to do everything on it!
12:58:59 <shapr> hpc: I do that.
12:59:15 <shapr> or I take the leaky bucket approach... everything at the bottom of the list falls off
12:59:54 <hpc> heh
13:00:07 <shapr> Nowadays my approach is far simpler, my todo list includes work, school and girlfriend. Everything else is done for fun, and may never be released.
13:00:30 * geheimdienst has a todo list that features mostly "look at lolcats"
13:00:51 <sproingie> i tend to not put stuff on my todo list that has no concrete deadline
13:01:05 <Astro> heya
13:01:18 <shapr> sproingie: That makes more sense. But how do you put a deadline on fun projects?
13:01:19 <Astro> I'm fighting with: The last statement in a 'do' construct must be an expression
13:01:23 <sproingie> like "join gym".  yeah i should do that, but since i procrastinate on it indefinitely, it's going to clutter up my list
13:01:33 <geheimdienst> > join gym
13:01:33 <Astro> can I pass a flag to ghc to show me the transformation of the do-block?
13:01:34 <lambdabot>   Not in scope: `gym'
13:01:35 <sproingie> and putting it on the list doesn't actually push me
13:01:41 <hpc> Astro: the last line of your do block is foo <- bar?
13:01:51 <Astro> hpc: nope, it's return $ ...
13:02:01 <hpc> Astro: check indentation
13:02:15 <Astro> is perfect and space character only
13:02:18 <hpc> hmm
13:02:20 <sproingie> shapr: the fun of a project is its own driver and doesn't need to be a todo
13:02:26 <mauke> Astro: show your code
13:02:30 <hpc> ^
13:02:40 <sproingie> if it's a work project then i have a schedule.  the only todo item might be "update project schedule"
13:03:06 <Astro> http://hpaste.org/42349/synthhs
13:03:16 <Astro> ghc says Synth.hs:126:19
13:03:49 <Astro> rm line 161 changes nothing
13:03:51 * sproingie likes rememberthemilk and the android widget that comes with it
13:04:36 <byorgey> Astro: check the indentation of line 126 vs. line 162
13:04:58 <Astro> they're equal
13:05:13 <mauke> Astro: 134
13:05:52 <mauke>     else -2 / (1 - chPulseWidth c)4) *
13:06:04 <Astro> ooooh
13:06:07 <Astro> thank you very much!
13:06:13 <Astro> you must have laser-sharp eyes :)
13:06:50 <geheimdienst> is it necessary in this case to say amp <- case of ... -> return ... -> return ... -> return ... ? seems to me like you could cut all the returns and just say let amp = case
13:07:22 <mauke> there's a put in Noise
13:07:24 <geheimdienst> uh, wait
13:07:35 <geheimdienst> yeah, just saw that :) ignore me
13:07:51 <Astro> mauke: intended
13:11:07 <hpc> geheimdienst: lol
13:17:33 <thierry> hi, I'm trying to run a filter on the list [0..10^12]. It works with [0..10^11] but 10^12 gives me a empty list directly, why?
13:18:11 <Botje> are you using Int as your type?
13:18:14 <roconnor> > 10^12 :: Int
13:18:15 <lambdabot>   1000000000000
13:18:18 <roconnor> > 10^12 :: Int32
13:18:19 <lambdabot>   -727379968
13:18:23 <roconnor> > 10^11 :: Int32
13:18:24 <lambdabot>   1215752192
13:18:30 <roconnor> > 10^12 :: Integer
13:18:30 <lambdabot>   1000000000000
13:18:33 <djahandarie> thierry, what is your function?
13:18:34 <tromp> > 10^12 > (maxBound::Int)
13:18:34 <lambdabot>   False
13:18:49 <roconnor> > 10^12 > (maxBound::Int32)
13:18:50 <lambdabot>   False
13:19:01 <roconnor> :P
13:19:02 <thierry> djahandarie : mm I should post my code if you want to see it, where can I do that?
13:19:08 <djahandarie> @where hpaste
13:19:08 <lambdabot> http://hpaste.org/
13:19:12 <djahandarie> Thar ^^
13:19:14 <roconnor> thierry: If you buy a 64 bit processer your problem will go away
13:19:16 <roconnor> :)
13:19:21 <tromp> > 10^12 > fromInteger (maxBound::Int32)
13:19:22 <lambdabot>   Couldn't match expected type `GHC.Integer.Internals.Integer'
13:19:22 <lambdabot>         agains...
13:19:31 <roconnor> *toInteger
13:19:35 <tromp> > 10^12 > fromIntegral (maxBound::Int32)
13:19:36 <lambdabot>   True
13:20:03 <djahandarie> But yeah, this is likely a problem with 10^12 evaluating to some negative number for a 32-bit integer
13:20:17 <tromp> > 10^12 :: Int32
13:20:18 <lambdabot>   -727379968
13:20:32 <thierry> kk thanks
13:20:43 <thierry> my code is here if you want to see : http://hpaste.org/42351/1012
13:20:45 <djahandarie> > [0 .. -512313]
13:20:46 <lambdabot>   []
13:20:51 <djahandarie> Essentially that is what is happening
13:21:08 <djahandarie> That should be using Integer
13:21:24 <teki> could somebody point me to a good resource for working with multiple kernel-level threads with Haskell?
13:21:27 <thierry> k, I'm a bit newbie with haskell, how can I force the type of my list?
13:22:19 <roconnor> [1..10^12] :: [Integer]
13:22:20 <Zao> > let x = [42, 3, 5] : [Integer] in x
13:22:21 <lambdabot>   Not in scope: data constructor `Integer'
13:22:23 <Zao> Erm, ::
13:22:26 * Zao blames #$@#$ SML.
13:22:57 <thierry> k thanks :)
13:23:04 <Botje> thierry: length returns an Int. use genericLength instead
13:23:22 <djahandarie> Ah, that's where the problem was
13:23:54 <thierry> ho I see, :)
13:24:02 <djahandarie> Who needs efficiency anways
13:24:05 <roconnor> ya, things like length and (!!) are where Int sneaks into programs. :^)
13:24:10 <djahandarie> Who needs spelling anyways
13:28:47 <thierry> I also get an error when using sum, it tell me to add an instance declaration (Num [Integer]), how do I do that?
13:29:19 <merijn> thierry: Looks like you're doing something wrong, pastebin the code?
13:29:46 <merijn> You seem to be trying to sum a list containing lists of integers rather then a list containing integers
13:30:22 <thierry> merijn : ho yeah that it
13:30:28 <thierry> that's*
13:31:30 <merijn> thierry: Basically it was complaining the sum is only defined for (Num a) => [a] and that [Integer] is not defined as a number
13:32:10 <thierry> merijn : thanks :)
13:43:47 <shapr> sproingie: mind if I quote that bit about fun projects being their own motivation and reward?
13:43:53 <RichardBarrell> teki: it's not all that complicated. You want to look up how to ask the RTS to start multiple threads, and how to implement communication between threads using MVars.
13:44:04 <sproingie> shapr: go for it
13:45:22 <RichardBarrell> teki: GHC Haskell's design is to have as many Haskell threads (created with forkIO) as you wish to use spread out over a fixed pool of OS threads (you tell the RTS how many to create. Usually you want one per CPU core.)
13:45:46 <ManateeLazyCat> Send *any format* mail to manatee.mailclient@gmail.com, i'm testing Mail-Client for Manatee, thanks a lots! Off to coding. :)
13:46:12 <monochrom> onoes
13:46:32 <RichardBarrell> teki: in the rare event that you specifically need OS threads rather than Haskell threads, there's an action "forkOS" somewhere in Control.Concurrent. Usually you want Haskell threads instead of true OS threads because they're faster, but some APIs (such as OpenGL) require separate OS-level threads.
13:46:36 <Botje> ManateeLazyCat: how about I send you all my spam?
13:46:44 <monochrom> haha
13:46:46 <aristid> ManateeLazyCat: so you're writing a complete computing system
13:46:47 <ManateeLazyCat> Botje: Welcome! :)
13:46:51 <Botje> spammers can get very creative with mail-wrangling.
13:47:08 <Botje> ManateeLazyCat: also, do you know about the presentation "email hates the living" ?
13:47:26 <c_wraith> RichardBarrell, forkOS isn't actually about forking a new OS thread.  It's about creating a green thread that's always bound to the same capability.
13:47:38 <RichardBarrell> c_wraith: my bad, sorry.
13:47:42 <ManateeLazyCat> aristid: I'm try to write script-engine first before i'm writing any other extension, but i haven't so much time on script-engine, so i decide write mail client first. :)
13:47:57 <Botje> http://video.google.com/videoplay?docid=7054401183589794595#
13:48:06 <c_wraith> RichardBarrell, it still solves the opengl issue, but it's not quite the same thing :)
13:48:11 <RichardBarrell> c_wraith: it's just to cope with existing APIs that abuse thread-level storage, right?
13:48:19 <c_wraith> yeah
13:48:25 <RichardBarrell> Thank you.
13:48:46 <ManateeLazyCat> Ok, all. If you want see Haskell Mail Client faster, send *any* mail to manatee.mailclient@gmail.com include spam.... :)
13:48:59 <ManateeLazyCat> s/faster/soon
13:49:33 * RichardBarrell facepalms.
13:49:41 <ManateeLazyCat> aristid: I have tell you guys i'm writing OS before. :)
13:49:56 <RichardBarrell> You just caused me to type "mail" into a terminal experimentally, and it turns out that I have a lot of backlogged crap from cron jobs. :)
13:51:12 <ManateeLazyCat> Bye all. :)
13:55:44 <hpc> @instances Monoid
13:55:44 <lambdabot> (), (a -> b), (a, b), (a, b, c), All, Any, Dual a, Endo a, First a, Last a, Maybe a, Ordering, Product a, Sum a, [a]
14:00:09 <roconnor> hmm, I think I can remove the rank-3 polymorphism in Multiplate, but at the expense of making the user write a few more functions.
14:00:26 <elliott> roconnor: what's wrong with rank-3 polymorphism?!
14:00:33 <elliott> if it doesn't get close to dependent types it's not worth using
14:00:40 <roconnor> elliott: no inference
14:00:46 <elliott> roconnor: bah!
14:00:50 <roconnor> I'd still have rank-2 polymorphism
14:01:00 <roconnor> but IIRC rank-2 has inference
14:01:04 <roconnor> which is why it gets it's own flag
14:01:35 <roconnor> also refactoring out this rank-3 function may make multiplate more general
14:02:07 <roconnor> and probably less efficent
14:03:44 <roconnor> oh wait, my cunning plan doesn work
14:03:46 <roconnor> :(
14:04:30 <copumpkin> no inference on rank 2 either
14:04:45 <roconnor> copumpkin: what is the good thing about rank-2 polymorphism then?
14:04:58 <copumpkin> I vaguely remember someone saying it was possible to infer
14:05:04 <copumpkin> but it seems like ghc doesn't
14:05:17 <copumpkin> I imagine it's just a historical thing
14:05:27 <roconnor> your two statement appear to be contradictary
14:05:28 <copumpkin> maybe rank2 came first then they generalized it and didn't want to break existing code?
14:05:35 <copumpkin> it is possible, in theory, to infer
14:05:37 <copumpkin> but ghc doesn't
14:05:42 <copumpkin> :t \x -> x x
14:05:43 <lambdabot>     Occurs check: cannot construct the infinite type: t = t -> t1
14:05:43 <lambdabot>     Probable cause: `x' is applied to too many arguments
14:05:43 <lambdabot>     In the expression: x x
14:05:53 <roconnor> who cares what ghc does or doesn't do.  I'm a programmer :P
14:05:53 <copumpkin> :t \(x : forall a. a -> a) -> x x
14:05:54 <lambdabot>     Illegal view pattern:  (x : forall a . a -> a)
14:05:54 <lambdabot>     Use -XViewPatterns to enable view patterns
14:05:54 <lambdabot> Not in scope: `forall'
14:06:01 <roconnor> I write programs
14:06:04 <copumpkin> pff
14:11:31 <lispy> I program therefore, I am.
14:12:16 <merijn> I program therefor, I am confused.
14:12:41 <tromp> I program therefore, I introduce bugs
14:13:10 <merijn> That doesn't really need a therefore introducing bugs and programming are the same :p
14:13:21 <merijn> s/therefore/therefore, /
14:22:31 <wornof> I just tried to use ghc's -prof option as per RWH's instructions, but it didn't work because I'm using hmatrix which doesn't seem to have a profiling library. Does this scupper any attempt to use GHC's profiling, and if so, is there any obvious alternative to easily see where my program's time is going?
14:23:26 <luite> you should reinstall those packages with profiling enabled
14:23:31 <Cale> wornof: Reinstall hmatrix with cabal install --reinstall -p hmatrix
14:23:49 <Cale> Or better yet, turn library profiling on in your ~/.cabal
14:24:06 <Cale> ~/.cabal/config
14:24:07 <byorgey> is there a way to have cabal install --reinstall -p  work recursively?
14:24:08 <Cale> rather
14:24:15 <Cale> library-profiling: True
14:24:21 <byorgey> I just had to do it today and it was annoying manually tracking down dependencies by seeing what broke each time
14:24:22 <mreh> @src enum
14:24:22 <lambdabot> Source not found. There are some things that I just don't know.
14:24:27 <mreh> @src Enum
14:24:27 <lambdabot> class  Enum a   where
14:24:27 <lambdabot>     succ                     :: a -> a
14:24:27 <lambdabot>     pred                     :: a -> a
14:24:27 <lambdabot>     toEnum                   :: Int -> a
14:24:27 <lambdabot>     fromEnum                 :: a -> Int
14:24:27 <Cale> byorgey: Good question. I've needed that a couple of times
14:24:29 <lambdabot> [3 @more lines]
14:24:31 <luite> byorgey: I don't think there is, unfortunately
14:24:31 <wornof> Cale: That simple? Thanks very much!
14:25:08 <Cale> wornof: Of course, if you change the cabal config, you still have to reinstall.
14:26:27 <byorgey> hmmm, didn't I just see a package/tool someone released for computing package deps?
14:26:43 <byorgey> maybe it could be used with  | xargs cabal install --reinstall -p  ...
14:26:59 <dcoutts_> cabal-sort?
14:27:02 <byorgey> http://hackage.haskell.org/package/cabal-sort
14:27:05 <dcoutts_> though that's for local packages
14:27:06 <byorgey> \o/
14:27:10 <luite> ertert
14:27:12 <byorgey> oh.
14:27:16 <dcoutts_> I think
14:27:31 <byorgey> what's the opposite of \o/
14:27:37 <alpounet> /o\
14:27:47 <Saizan> one could mangle the output of cabal install --dry-run
14:27:52 <alpounet> (hands on the head)
14:27:56 <Saizan> (-v)
14:28:01 <luite> whoops, sorry, my laptop has terrible wifi here
14:28:07 <luite> lots of lag
14:28:25 <byorgey> luite: np, I thought you were just excited about cabal-sort
14:29:16 <luite> and the system hd in my desktop died :(
14:31:14 <luite> don't buy a hitachi 7k2000 :p
14:35:06 <haha> are you here? yindong``
14:39:02 <dmwit> > iterate (*11) 1
14:39:03 <lambdabot>   [1,11,121,1331,14641,161051,1771561,19487171,214358881,2357947691,259374246...
14:39:34 <fryguybob> What's the minimal to implement for Ord? 
14:39:42 <copumpkin> it says so in the docs
14:39:45 <copumpkin> I think compare or <=
14:39:55 <fryguybob> ok
14:42:42 <haha> yindong???
14:42:54 <dmwit> > sqrt 13310
14:42:55 <lambdabot>   115.36897329871667
14:43:33 --- mode: ChanServ set +o copumpkin
14:43:51 <dmwit> > sqrt 1331
14:43:52 <lambdabot>   36.4828726939094
14:44:02 <copumpkin> haha, lookforyindong: what's up?
14:45:43 <haha> ...
14:46:28 <copumpkin> haha, lookforyindong: maybe you want #haskell.fr ?
14:47:16 <lookforyindong> if it exist
14:47:21 <copumpkin> it does
14:47:27 <copumpkin> type /join #haskell.fr
14:47:41 <lookforyindong> but i dont need in fact.. thx =)
14:48:15 <kmc> you mean #ocaml
14:48:16 * kmc ducks
14:48:51 <yitz> @slap kmc
14:48:51 * lambdabot slaps kmc
14:49:31 <kmc> @slap lambdabot
14:49:31 * lambdabot moulds lambdabot into a delicous cookie, and places it in her oven
14:49:51 <copumpkin> @slap herself
14:49:51 <lambdabot> I'd rather not; herself looks rather dangerous.
14:49:55 <copumpkin> :(
14:50:12 --- mode: copumpkin set -o copumpkin
14:50:18 <mreh> permanent channels ops?
14:50:21 <mreh> oh no
14:50:42 <copumpkin> the distinction between clueless and troll is often subtle :)
14:50:55 <copumpkin> when I saw another webchat join with the same IP, I figured I'd be prepared
14:51:04 <mreh> cf. 4chan
14:54:16 <ddarius> mreh: Because everyone on 4chan is both clueless and a troll?
14:55:49 <mreh> ddarius: I always figured trolling was mostly done by people posing as newf*gs
14:56:11 <mreh> anyway excuse me, I have some cat pictures to caption
15:06:40 <ddarius> copumpkin: So the place I mentioned on Sunday that I'd like to go to is http://www.druidpub.com/irishmusic.html  The location is more convenient for me though.  It looks like the Lechmere or Central Station stops are the closest.
15:09:12 <copumpkin> ah, that looks nice
15:10:43 <copumpkin> I could definitely make it out there sometime. Not sure when though, as I have several people coming to visit in the near future
15:10:58 <copumpkin> I have furniture now!
15:11:08 <Pseudonym> Party at copumpkin's place!
15:11:12 <copumpkin> yeah!
15:11:15 <copumpkin> except it's not very large
15:11:31 <HaudRex> I second that!
15:11:37 <Pseudonym> If you've got WiFi and a fridge, that's all we need.
15:11:45 <copumpkin> yeah, got those :)
15:11:50 <HaudRex> hoo-ray
15:12:02 <copumpkin> anyway, speaking of furniture, I should go start unpacking stuff and moving furniture around
15:12:09 <copumpkin> since I have no room to move around in my living room at all right now
15:12:21 <HaudRex> need help?
15:13:04 <copumpkin> hah I'm not sure I could fit you in right now :) I'm going to have to be sokoban-style creative to get at my stuff
15:13:27 <HaudRex> right-o
15:13:40 <ylmson_> hi, I'm reading haskell tutorial, and am a bit confused about the '->'. what does it really do?
15:13:58 <Pseudonym> There are two types of ->.
15:14:12 <Pseudonym> There's the one you see in types and the one you see in lambda expressions.
15:14:16 <Pseudonym> f :: A -> B
15:14:20 <Pseudonym> \x -> foo
15:14:21 <ylmson_> I think I can understand the one in case. 
15:14:22 <copumpkin> there's also the one you see in kinds!
15:14:28 <Pseudonym> Oh, yes, in case.
15:14:30 <Pseudonym> And kinds.
15:14:33 <Pseudonym> OK, there are lots of ->.
15:14:41 <jmcarthur> and then there's extensions like fundeps
15:14:44 <Pseudonym> True.
15:14:53 <ylmson_> o.o lots of ->
15:14:55 <Pseudonym> ylmson_: So do you have an example?
15:15:14 * jmcarthur tries to think of more
15:15:16 <jmcarthur> view patterns
15:15:25 <ylmson_> ugg.. can't paste in this terminal
15:15:31 <Pseudonym> That's okay.
15:15:43 <Pseudonym> !hpaste
15:15:43 <ylmson_> the one in the tutorial is something like in types
15:15:46 <Pseudonym> Erm.
15:15:52 <Pseudonym> So it's something like this:
15:15:52 <c_wraith> in types, -> indicates a function
15:15:56 <Pseudonym> f : A -> B -> C
15:15:58 <Pseudonym> ::
15:16:26 <Pseudonym> Correct?
15:16:32 <ylmson_> btw, this is the first time I read about functional programming as well, so concepts are a bit unfamiliar :P
15:16:54 <Pseudonym> No problem.
15:17:00 <kmc> things in Haskell don't "do" things ;)
15:17:01 <kmc> they mean things
15:17:03 <Pseudonym> So you know mathematical notation, correct?
15:17:12 <Pseudonym> f : R -> R  where f(x) = x^2
15:17:13 <kmc> ylmson_, yes, Haskell is a very atypical functional language
15:17:22 <kmc> there's a lot of concepts in Haskell that are beyond / outside of "classical FP"
15:17:23 <Pseudonym> You've seen stuff like that already?
15:17:32 <jmcarthur> ylmson_: A -> B means a function from things of type A to things of type B
15:17:38 <ylmson_> oh, R->R like in mapping?
15:17:41 <Pseudonym> Yeah.
15:17:44 <Pseudonym> That's exactly what this is.
15:17:45 <kmc> right.  if S and T are types, then "S -> T" is a type
15:17:48 <ylmson_> yes, I've seen that in maths
15:17:57 <kmc> the type of functions which taken an argument of type S, and return a result of type T
15:17:57 <Pseudonym> What you might not "get" is:
15:18:02 <Pseudonym> f : A -> B -> C
15:18:09 <ylmson_> indeed
15:18:12 <jmcarthur> somebody's been using agda too much
15:18:13 <Pseudonym> Which is something you don't usually see in maths.
15:18:24 <ylmson_> is it something like A->B, then B->C?
15:18:28 <Pseudonym> The arrow operator associates to the right.
15:18:34 <kmc> f :: A -> (B -> C)
15:18:35 <Pseudonym> So it's: f :: A -> (B -> C)
15:18:38 <ylmson_> oh
15:18:45 <Pseudonym> It's a function which takes an argument and returns a function.
15:18:52 <Pseudonym> This may help:
15:18:57 <Pseudonym> f :: A -> B -> C -> D
15:18:58 <ylmson_> hmm, returns a function
15:19:01 <Pseudonym> f a :: B -> C -> D
15:19:11 <Pseudonym> f a b :: C -> D
15:19:15 <Pseudonym> f a b c :: D
15:19:21 <kmc> all Haskell functions have only one argument; the convention for encoding a multi-argument function is that you take one arg and return a function which takes the second arg
15:19:34 <Pseudonym> Putting in parentheses:
15:19:36 <kmc> and the syntax of Haskell is set up so that this convention ("currying") is the most natural way
15:19:45 <Pseudonym> f :: A -> (B -> (C -> D))
15:19:53 <Pseudonym> f a :: B -> (C -> D)
15:20:02 <Pseudonym> (f a) b :: C -> D
15:20:08 <ylmson_> kmc: oh, that is helpful
15:20:12 <Pseudonym> ((f a) b) c :: D
15:20:13 <aavogt> counting the number of arguments is a useful concept
15:20:28 <ylmson_> so I don't understand what the a means in 'f a'..
15:20:31 <ylmson_> is it an argument?
15:20:40 <jmcarthur> yes
15:20:40 <Pseudonym> That's f(a) in mathematical notation.
15:20:46 <ylmson_> oh ok
15:20:52 <Pseudonym> In Haskell, function application is so important we don't even use a symbol for it.
15:21:04 <sipa> sure we do, $ ;)
15:21:09 <ylmson_> then f a b is "f(a,b)"?
15:21:11 <jmcarthur> but $ is defined
15:21:14 <Pseudonym> Except it's got the wrong associativity.
15:21:14 <jmcarthur> in haskell
15:21:16 <kmc> the operator for function application is the one with the biggest key on your keyboard
15:21:23 <kmc> because it's so important
15:21:25 <Pseudonym> ylmson: Correct, except that f(a,b) also means something.
15:21:32 <hpc> kmc: ^^
15:21:35 <Pseudonym> f :: (A,B) -> C
15:21:43 <Pseudonym> That's a function which takes one argument, a pair.
15:21:44 <kmc> ylmson_, under the "curried convention" i described, yes
15:21:55 <kmc> but (a,b) is a value by itself -- a pair or "tuple"
15:21:57 <kmc> > (2,3)
15:21:58 <lambdabot>   (2,3)
15:22:01 <ylmson_> oh right
15:22:13 <Pseudonym> The difference is subtle, and not important right now.
15:22:17 <ion> Equivalent to f(a,b) in some other language, but more similar to (f(a))(b) in that other language.
15:22:17 <kmc> there's functions curry :: ((a,b) -> c) -> (a -> b -> c)
15:22:25 <kmc> and uncurry :: (a -> b -> c) -> ((a,b) -> c)
15:22:32 <Pseudonym> It's more idiomatic to curry than to pass a tuple.
15:22:34 <kmc> > curry (+) (2,3)
15:22:35 <lambdabot>   Overlapping instances for GHC.Show.Show
15:22:35 <lambdabot>                              (b -> ...
15:22:41 <kmc> dur
15:22:42 <hpc> it is perhaps most similar to the mathematical convention "f(a, b)"
15:22:44 <kmc> > uncurry (+) (2,3)
15:22:44 <lambdabot>   5
15:22:52 <ylmson_> so the example you were just showing, is f a :: B equivalent to f :: A->B?
15:23:03 <kmc> ylmson_, if a :: A
15:23:09 <ylmson_> okay
15:23:24 <kmc> "x :: y" means "x has type y"
15:23:24 <ylmson_> I take it that :: just means definition.
15:23:32 <Pseudonym> It's not quite correct to say they're "equivalent", but if one is type correct, the otehr is too.
15:23:34 <kmc> type signatures are usually optional
15:23:36 <Pseudonym> We wrote that:
15:23:37 <Pseudonym> write
15:23:42 <kmc> but it's a good idea to put them in at type level
15:23:43 <kmc> err
15:23:44 <kmc> top level
15:23:49 <Pseudonym> f :: A -> B              a :: A
15:23:53 <Pseudonym> -------------------------------
15:23:58 <Pseudonym>            f a :: B
15:24:11 <jmcarthur> nice, TAPL in #haskell ;)
15:24:13 <djahandarie> Usually a good idea to put them at the type level too
15:24:23 <kmc> \usepackage{bussproofs}
15:24:23 <Pseudonym> Note that this is also Modus Ponens.  If A -> B is true and A is true, then B is true.
15:24:25 <hpc> type signatures are required when the typechecker can't infer it
15:24:29 <ezyang> Yum, inference rules. 
15:24:34 <hpc> which is quite often, with typeclass-constrained code
15:24:45 <ylmson_> oh, so you first define the type of a to be A, then define a function which will know what to map between
15:25:00 <Pseudonym> Or the type of a could be inferred.
15:25:02 <kmc> yeah but we usually don't declare the types of local variables
15:25:17 <hpc> unless it helps in some way
15:25:36 <jmcarthur> ylmson_: that notation says that given f with type A -> B and given a with type A, f a has type B
15:26:29 <ylmson_> jmcarthur: but can you say f :: A->B means f has type 'A->B'?
15:26:35 <kmc> that's exactly what it means
15:26:44 <jmcarthur> ylmson_: yes. :: can be read as "has type"
15:26:46 <ylmson_> what is type A->B?
15:26:56 <ylmson_> I thought A and B are two types
15:26:57 <hpc> ylmson_: a function from A to B
15:26:58 <Pseudonym> It's the type of a function.
15:27:03 <ylmson_> oh, function type
15:27:05 <dmwit> (A -> B) is the type of functions that take an A and yield a B.
15:27:10 <jmcarthur> ylmson_: -> takes two types and gives you another type
15:27:18 <kmc> if A and B are two types, A -> B is also a type
15:27:29 <bll-tegatai> Tegatai Aurora - Fortinet Secured VMware vCloud Hosting: Choose from Arch Linux, CentOS, Debian, Fedora, FreeBSD, Gentoo, NetBSD, OpenBSD, Open Solaris, Open SUSE, OpenWall, Slackware, Ubuntu, and more. High performance secure VMs with four-provider blended tier-1 bandwidth, starting at $24.99 a month. http://www.tegataiphoenix.com/
15:27:44 <ylmson_> now I think I am getting this a bit
15:27:55 <hpc> ylmson_: the type (A -> B) would be written in java as B foo(A a) {...}
15:27:57 <dmwit> ?where ops
15:27:57 <lambdabot> shapr Cale glguy dons sjanssen dcoutts Saizan dibblego conal Philippa bos arjanb xerox Heffalump kosmikus wli Pseudonym Igloo quicksilver monochrom Lemmih jmcarthur copumpkin
15:28:01 <ion> bll-tegatai: Thanks for telling us what to boycott.
15:28:21 <jmcarthur> woah, what, i'm not an op anymore?
15:28:28 <jmcarthur> when did that happen?
15:28:31 <dmwit> You're in that list...
15:28:31 <kmc> ylmson_, Haskell's type system has a vastly better effort to payoff ratio than other static type systems you may be familiar with
15:28:32 <ylmson_> hpc: you mean foo(A a) { B ret; ..  return B } ?
15:28:46 <ylmson_> oh right
15:28:51 <ylmson_> missed that B there
15:28:52 <jmcarthur> dmwit: chanserv says i'm not authorized to op
15:28:56 <dmwit> huh
15:29:03 <kmc> so most type annotations are optional, yet many bugs can be caught
15:29:22 <ylmson_> I've done programmings before in C# java and python mainly, and haskell feels quite different.
15:29:25 <kmc> functional style helps of course -- types don't do much good when every function is "void f() { .. some side effects here .. }" because all the types are trivial
15:29:40 <dmwit> ?quote cale inconsistent
15:29:40 <lambdabot> No quotes match. BOB says:  You seem to have forgotten your passwd, enter another!
15:29:55 <kmc> ylmson_, to me the Java type system feels like the strawman argument that you'd construct if you wanted to convince people that static types are bad
15:30:05 <kmc> and indeed a lot of Ruby and Python users are convinced static types are bad for this reason
15:30:13 <dmwit> ?quote Cale inconsistent
15:30:13 <lambdabot> Cale says: But in another sense, functional programmers are applied logicians who spend all their time proving trivial theorems in interesting ways in an inconsistent intuitionist logic.
15:30:40 <hpc> haha, that quote made my day
15:30:58 <ylmson_> is the bot here written in haskell? :P
15:31:02 <kmc> yes
15:31:03 <dmwit> Yup.
15:31:06 <kmc> @hackage lambdabot
15:31:06 <lambdabot> http://hackage.haskell.org/package/lambdabot
15:31:15 <kmc> ylmson_, as is the bot in ##c++
15:31:17 <kmc> geordi
15:31:27 --- mode: ChanServ set +o jmcarthur
15:31:30 --- mode: jmcarthur set -o jmcarthur
15:31:30 <dmwit> Hah, didn't know that.
15:31:34 <kmc> (turns out C++ is a terrible language for implementing C++, while Haskell is a great language for implementing Haskell)
15:31:43 <jmcarthur> okay i guess i just wasn't signed in for my nick
15:32:11 <aavogt> pastorn: you can WriterT
15:32:28 <ylmson_> oh, factorial :: (Num a) => a->a, what does => mean here?
15:32:45 <aavogt> class constraint
15:32:54 <c_wraith> it separates the context from the type.  the context contains class constraints
15:33:07 <ylmson_> so context always goes in the left?
15:33:12 <hpc> ylmson_: indeed
15:33:17 <kmc> ylmson_, which Haskell tutorial are you reading?
15:33:31 <aavogt> @ty something
15:33:31 <c_wraith> So that type means "a function that takes any type, and returns that same type.  Assuming that type is an instance of Num"
15:33:32 <lambdabot> forall u a. (Data a) => GenericQ (Maybe u) -> a -> Maybe u
15:33:37 <ylmson_> kmc: the 'learn_in_10_minutes' one
15:33:38 <HugoDaniel> hey there!
15:33:51 <kmc> ylmson_, not familiar with it
15:33:54 <kmc> @where rwh
15:33:54 <lambdabot> http://www.realworldhaskell.org/blog/ http://book.realworldhaskell.org/read/
15:33:55 <kmc> @where lyah
15:33:55 <lambdabot> http://www.learnyouahaskell.com/
15:33:59 <kmc> we recommend both those ylmson_
15:34:06 --- mode: ChanServ set +o jmcarthur
15:34:07 <dmwit> > let factorial _ x = product [1..x] in (factorial :: a -> Num b => b -> b) 32 32
15:34:07 <lambdabot>   Could not deduce (GHC.Num.Num b, GHC.Enum.Enum b)
15:34:07 <lambdabot>    from the context ()
15:34:07 <lambdabot>   ...
15:34:26 <kmc> the idea of "Learn Haskell in 10 minutes" is hilarious
15:34:29 --- mode: jmcarthur set +q *!*@ip68-98-120-6.ph.ph.cox.net
15:34:32 --- mode: jmcarthur set -o jmcarthur
15:34:33 <dmwit> > let factorial _ x = product [1..x] in (factorial :: a -> (Num b, Enum b) => b -> b) 32 32
15:34:34 <lambdabot>   Could not deduce (GHC.Num.Num b, GHC.Enum.Enum b)
15:34:34 <lambdabot>    from the context ()
15:34:34 <lambdabot>   ...
15:34:35 <kmc> http://norvig.com/21-days.html
15:34:40 <hpc> lyah is probably better if you are learning from scratch
15:34:45 <aavogt> kmc: it's an introduction on haskell.org
15:34:46 <dmwit> I'm bothered that there's no parse error.
15:35:00 <c_wraith> dmwit, is that rank-2 syntax?
15:35:15 <dmwit> I thought it was illegal syntax. =P
15:35:17 <ylmson_> thanks, reading lyah now
15:35:20 <pastorn> aavogt: yes, but that's just not enough
15:35:32 <pastorn> i don't want to clutter this code with Writer
15:35:41 <c_wraith> I just mean, is it syntax enabled by an extension, rather than enabled by default?
15:35:52 <dmwit> c_wraith: No, it parses fine in plain ghci as well.
15:36:00 <Pseudonym> ylmson_: BTW, you may have noticed that we REALLY like this type of question. Haskellers are very proud of their type system and love it when people ask about it.
15:36:37 <kmc> that's true, but there's no substitute for a real tutorial for basics like "what does => mean"
15:36:38 <hpc> indeed; it's what separates us from the proletariat of turing-tape langauges
15:36:47 <ddarius> kmc: Haskell -clearly- takes e^pi minutes to learn.
15:36:48 <hpc> :P
15:36:48 <ylmson_> Pseudonym: well, I'm still thinking in the python terms of loose typing at the moment
15:37:25 <kmc> if you recognize "loose vs. strict" as orthogonal to "dynamic vs. static" then python's typing is rather strict
15:37:28 <kmc> compare to Perl or Javascript
15:37:51 <Pseudonym> Yeah.  Python programs generally don't crash due to pointer misuse.
15:37:51 <hpc> strict dynamic typing is the ultimate evil
15:38:05 <hpc> you get all of the crashes and none of the compile checks
15:38:15 <Pseudonym> COBOL, right?
15:38:15 <dmwit> ...but also all of the expressiveness.
15:38:18 <kmc> hpc, i disagree.  Perl and Javascript's implicit type conversions are incredibly counterintuitive
15:38:19 * jmcarthur prefers to call it "strong"
15:38:28 <kmc> they try to second-guess the programmer and inevitably fail
15:38:33 <jmcarthur> and i disagree and strong, dynamic typing is worse the weak, dynamic typing
15:38:40 <jmcarthur> s/and/that/
15:38:42 <hpc> yeah, perl's types are rather odd
15:38:45 <dmwit> Strong, dynamic typing can make sense when type-checking is undecidable (as it probably is for Python).
15:38:46 <Pseudonym> Ruby == strong dynamic typing, no?
15:38:47 <kmc> i don't want my programming language to try to read my mind; i want it to follow a simple, consistent set of rules
15:38:48 <jmcarthur> s/the/than/
15:39:09 <jmcarthur> dmwit: depends on what kind of types you're talking about
15:39:13 <hpc> dmwit: python can be decidable; it uses duck typing
15:39:22 <Pseudonym> No, I guess not.
15:39:28 <hpc> which is essentially an implicit typeclass for every member function
15:39:38 <jmcarthur> Pseudonym: ruby is strong, dynamic, yes
15:39:44 <dmwit> hpc: Please publish a paper, and write a type-checker for Python!
15:39:48 <dmwit> People would definitely use it.
15:39:51 <jmcarthur> most dynamic type systems are strong, but not all
15:40:17 <Saizan> the papers got written already, i think, though the types would be huge
15:40:23 <Pseudonym> @remember BenjaminPierce I spent a few weeks... trying to sort out the terminology of "strongly typed," "statically typed," "safe," etc., and found it amazingly difficult.... The usage of these terms is so various as to render them almost useless.
15:40:23 <lambdabot> Done.
15:40:26 <dmwit> (There have been a number of attempts at hacks that sort of do type-checking for Python, and they're used from time to time, but the overhead is too much for now for widespread use, I think.)
15:40:35 <ylmson_> so when should you use "let" and when not?
15:40:38 <Pseudonym> Just in case we need that quote in the future.
15:40:44 <dmwit> ylmson_: "go with your heart"
15:40:57 <ylmson_> lol
15:40:59 <kmc> ylmson_, use "let" when you want a local name for something and/or you want to save the result of an intermediate computation to avoid recomputing it
15:41:03 <hpc> ylmson_: use "let" for things that are too damn long
15:41:16 <Pseudonym> "let" vs "where" is entirely a matter of taste, though.
15:41:22 <hpc> ylmson_: or for things that are expensive to calculate, as you can use "let" to make it calculate only once
15:41:31 <aavogt> Pseudonym: it's a matter of scope too
15:41:31 <hpc> "where" turns into "let" during compilation
15:41:33 <Pseudonym> Unless only one applies.
15:41:35 <Pseudonym> Yeah.
15:41:43 <jmcarthur> > let x = sum [1..1000] in x*x
15:41:44 <lambdabot>   250500250000
15:41:47 <dankna> use it (either of them) when it deserves it own name for clarity's sake
15:41:48 <ylmson_> huh, I'm not aware of that
15:42:08 <ylmson_> > x = sum [1..1000] in x*x
15:42:08 <lambdabot>   <no location info>: parse error on input `='
15:42:16 <ylmson_> so you have to use let here?
15:42:27 <aavogt> > let x = y where y = 1 + 1 in x -- people who prefer 'where' write expressions like this
15:42:28 <lambdabot>   2
15:42:32 <Pseudonym> > x*x where x = sum [1..1000]
15:42:33 <lambdabot>   <no location info>: parse error on input `where'
15:42:44 <Pseudonym> OK, that doesn't work.
15:42:51 <jmcarthur> well, you could say (sum [1..1000] * sum [1..1000]) if you wanted, but it would be slower and is redundant to type
15:43:04 <ylmson_> aavogt: what does the "in x" do?
15:43:16 <kmc> the syntax is "let .... in ...."
15:43:17 <dmwit> ylmson_: It ends the "let" clause.
15:43:18 <jmcarthur> ylmson_: "in" is part of "let" syntax.
15:43:28 <dmwit> ylmson_: You may be getting confused because "in" is not required in "do"-blocks.
15:43:32 <Saizan> (i think the question was "when can i use = alone?")
15:43:38 <dmwit> But please avoid that for now. =)
15:43:39 <Pseudonym> "let b in e" is more or less the same as "e where b"
15:43:48 <jmcarthur> lyah doesn't teach do notation that early does it?
15:44:37 <aavogt> (decl = let b in e)    is more like     (decl = e where b)
15:44:55 <kmc> ylmson_, you might be thinking that "let" is a form of variable assignment
15:45:04 <kmc> it's not really; variables don't change value in Haskell
15:45:05 <ylmson_> so the part after in is the real assignment?
15:45:06 <aavogt> kmc: I do too
15:45:08 <ylmson_> oh
15:45:20 <ylmson_> right, I remember reading something about immutable values
15:45:31 <hpc> jmcarthur: it teaches it early, but as magic IO foolery
15:45:32 <kmc> values are immutable, in any language, period.  that's what the word "value" means
15:45:40 <jmcarthur> ylmson_: "let ... in ..." forms an expression. all let does is name a subexpression so you can use it in another expression
15:45:42 <hpc> jmcarthur: to get people comfortable with printing shit out to the terminal, right away
15:45:45 <kmc> but in Haskell, variables stand for values, and not for cells-holding-values
15:46:00 <jmcarthur> hpc: :\
15:46:16 <hpc> jmcarthur: it makes sense to do, and it explains that 'do' is not magic, later
15:47:03 <kmc> ylmson_, so "let" just defines local names for things
15:47:11 <kmc> and the scope of those names is the stuff after "in"
15:47:25 <jmcarthur> hpc: it's just backwards from how i would do it, but i accept that it is the norm and i understand why
15:47:27 <kmc> anyway, i think a tutorial like LYAH will get to this
15:48:34 <ylmson_> > ahh, I think I get it now
15:48:34 <lambdabot>   <no location info>: parse error on input `,'
15:48:53 <ylmson_> oops
15:49:13 <ylmson_> it seems like just straightforward math notation
15:49:18 <krey> how can I learn continuations?
15:50:05 <jmcarthur> krey: continuations are simpler than they may at first appear
15:50:40 <krey> jmcarthur: I'm soo desperate, I've started learning scheme
15:50:41 <jmcarthur> krey: all it is is instead of returning a value from a function, you give the function what you want it to do with the value
15:51:01 <jmcarthur> s/value/result/
15:51:07 --- mode: ChanServ set +o Cale
15:51:15 <krey> yeah, I did some coding in CPS
15:51:19 --- mode: Cale set +b *!*@ip68-98-120-6.ph.ph.cox.net
15:51:19 --- kick: bll-tegatai was kicked by Cale (bll-tegatai)
15:51:27 --- mode: Cale set -o Cale
15:51:29 <ylmson_> thanks everyone, I think I'm going to spend some time with the book
15:51:42 <jmcarthur> Cale: was he nagging in PM or something? i'd +qed him already
15:51:48 <Cale> oh
15:51:51 <Cale> I missed that
15:51:55 <Cale> sorry :)
15:51:58 <jmcarthur> oh well
15:52:02 <krey> jmcarthur: but I still don't get them
15:52:22 <krey> jmcarthur: callCC as well...
15:52:22 <jmcarthur> krey: can you identify what you find difficult about it?
15:52:32 <jmcarthur> callCC is tougher, i admit
15:52:42 <krey> jmcarthur
15:52:43 <Cale> (I just came back and noticed I was highlighted and saw the spam right above it)
15:52:46 <krey> oh god
15:52:57 <krey> this typing is gloves thing just isn't working
15:53:10 * krey takes his gloves off
15:53:13 <Cale> krey?
15:53:20 <krey> Cale: yes?
15:53:28 <Cale> Oh, typing as in keyboard.
15:53:41 <krey> Cale: :)
15:54:14 <krey> jmcarthur: sooo, no more typos hopefully
15:54:29 <krey> jmcarthur: so, I did recursive functions
15:54:39 <krey> jmcarthur: mostly on lists
15:55:16 <jmcarthur> krey: you're talking about haskell right, not scheme?
15:55:17 <krey> jmcarthur: and noticed that they followed a common pattern: the base case was return something, and the inductive step was fmap
15:55:28 <krey> jmcarthur: yep, haskell
15:55:55 <krey> jmcarthur: this is true, right?
15:57:02 <jmcarthur> krey: most recursive functions over lists can be written using higher level functions instead of explicit recursion, if that's what you mean
15:57:27 <jmcarthur> krey: i don't know what you mean by saying that the inductive step was fmap though. i'd need to see the code you are talking about
15:57:29 <krey> jmcarthur: no, not folding
15:57:42 <jmcarthur> folding is just one kind of recursion over lists
15:57:43 <krey> jmcarthur: code is happening atm
15:57:58 <jmcarthur> what does this have to do with continuations?
15:58:01 <krey> jmcarthur: ooh, what else?
15:58:07 <jmcarthur> zip, for example
15:58:11 <jmcarthur> also unfoldr
15:58:16 <krey> jmcarthur: oh, true
15:58:28 <jmcarthur> and various specializations, of course
15:58:29 <krey> jmcarthur: anyway, I'm writing this code, and you'll see in a minute
15:58:32 <jmcarthur> okay
15:59:53 <jmcarthur> krey: i'll brb
16:00:30 <sina> How can I check if (a,b) or (b,a) (both chars), is a member of [(Char,Char)] ?
16:02:12 <hpc> sina: match x@(a,b) l = let y = (b,a) in any (\z -> z==x || z==y) l
16:02:17 <hpc> perhaps
16:02:32 <kmc> :t elem
16:02:33 <lambdabot> forall a. (Eq a) => a -> [a] -> Bool
16:02:47 <hpc> or something with that...
16:02:53 <sina> I'm thinking about elem myself, but its for (a,b) only
16:02:58 <Cale> \(x,y) -> any (liftM2 (||) (== (x,y)) (== (y,x)))
16:03:14 <kmc> sina, lists aren't good for searching
16:03:49 <sina> kmc: does haskell have anything better than lists?
16:03:52 <kmc> yes
16:03:53 <kmc> Data.Set
16:04:01 <kmc> there's a lot of data structures in the standard library
16:04:25 <kmc> http://www.haskell.org/ghc/docs/latest/html/libraries/
16:04:45 <Cale> Lists are good if you plan to go through all the elements one by one in order.
16:04:50 <kmc> sina, f p@(a,b) | (a > b) = (b,a) | otherwise = p
16:04:55 <Cale> (they're essentially optimal for that)
16:05:06 <kmc> Data.Set.fromList $ map f yourpairs
16:05:22 <kmc> then you can do the lookup only once, by passing the key through f before you lookup
16:06:11 <Cale> Heh, it probably wouldn't be very efficient, but if you wanted to be cute, you could build a Data.Map indexed by Data.Set values :)
16:06:19 <sina> kmc,Cale: ok, thanks :) I think I should do (elem (a,b) list || elem (b,a) list)
16:06:26 <Cale> (It wouldn't be terribly inefficient either)
16:06:28 <kmc> that's simple, yes
16:06:28 <krey> jmarthur: here it is: http://pastebin.com/fWdAAgLb
16:06:34 <kmc> and if your list is short, it will perform just as well
16:06:36 <krey> jmcarthur:^
16:07:42 <sina> its not gonna be really long and my input is a list. I have to change the whole program if I want to use something else
16:08:19 <kmc> fair enough
16:08:42 <kmc> it's best not to worry about performance without a good reason
16:09:03 <ddarius> Luckily, there's usually good reason.
16:09:12 <meltingwax> hi
16:09:35 <jmcarthur> krey: if you had just used the Cont monad then these would be defined for you already
16:09:44 <meltingwax> lol monads
16:09:58 <djahandarie> lol functors
16:10:00 <jmcarthur> meltingwax: are you going to be a problem?
16:10:04 <krey> jmcarthur: yeah, I know, this is one of my vague attempts to understand the Cont monad
16:10:09 <jmcarthur> ah okay
16:10:17 <sina> kmc: fortunately, computers can handle performance issues nowadays :)
16:10:30 <meltingwax> jmcarthur: do i know you?
16:10:54 <ddarius> If a computer can handle it, it's not a performance issue.
16:10:54 <krey> jmcarthur: but I don't really get the 'join' and the whole using callCC in the Cont monad thing
16:11:03 <kmc> meltingwax, did you have a question about monads?
16:11:19 <meltingwax> my thesis was on monads.. i rarely have questions about them
16:11:29 <kmc> sina, that's the attitude which creates all this bloated software i have to avoid
16:11:33 <jmcarthur> meltingwax: i doubt it. joining and starting your conversation with "lol monads" just isn't a good sign
16:11:36 <krey> jmcarthur: at the moment I would be happier to learn how to use them, and then understand them
16:11:49 <lispy> meltingwax: cool, what did you write about them?
16:12:09 <copumpkin> meltingwax: we get a fair number of trolls in here, so sometimes are a little touchy when people join with things like what you said
16:12:11 <kmc> the silver lining is that the cheap-ass machine which just barely runs Windows Vista will run everything i need beautifully
16:12:24 <meltingwax> i apologize
16:12:29 <sina> kmc: lol, I know what you mean... :)
16:12:29 <jmcarthur> krey: is there a direct question lurking in there somewhere? i'm not trying to be rude, i just don't know what you're hoping for
16:12:29 <meltingwax> i'm surprised people would troll in here
16:12:35 <meltingwax> i mean there's #lisp for that 
16:12:42 <copumpkin> lol parentheses
16:12:49 <copumpkin> :P
16:12:54 <lispy> copumpkin: watch it :)
16:12:57 <meltingwax> i would think people would have respect for a real functional language
16:13:10 <krey> jmcarthur: oh yes, no direct question, I just don't get continuations, what should I do to change that?
16:13:12 <lispy> I mean, (copumpkin watch it)
16:13:14 <copumpkin> trolling 101: 1) join channel 2) say "lol <commonly known fact about language>"
16:13:35 <lispy> meltingwax: this thesis, what was it about?
16:13:59 <jmcarthur> krey: using them is a good start. :) i'd actually just recommend not worrying about it unless you find a case where you need it
16:14:02 <meltingwax> lispy: hasn't been published yet, so i'm going to keep quiet about it ;)
16:14:15 <lispy> I see...
16:14:16 <jmcarthur> krey: i've only once bothered with Cont, and even then it wasn't really necessary
16:14:23 <copumpkin> omg he's solved the open question on monads!
16:14:33 <ddarius> lispy: You mean (watch copumpkin it)
16:14:38 <jmcarthur> copumpkin: what open question is that?
16:14:46 <krey> THE open question
16:14:55 <copumpkin> jmcarthur: it's so open, even the question of what the question is is open
16:15:04 <lispy> (watch 'copumpkin it)  ; don't evaluate copumpkin unnecessarily
16:15:23 <copumpkin> :O
16:15:27 * ddarius forces copumpkin all the time.
16:15:28 <copumpkin> I am quite lazy
16:15:38 * djahandarie raises eyebrow
16:15:39 <krey> jmcarthur: I'm interested in the theory of functional programming, and it would be important to learn continuations cos they pop up all the time
16:15:42 * jmcarthur reduces copumpkin to normal form
16:15:49 <copumpkin> pie? :(
16:16:00 * ddarius reduces jmcarthur to abnormal form.
16:16:14 <jmcarthur> krey: in practice they kind of pop up a lot, but you rarely need to recognize them as such
16:16:19 <copumpkin> ouch
16:16:23 <lispy> if copumpkin is in WHNF does that make him a cojackalantern?
16:17:08 <Cale> meltingwax: That just makes us curious about it! :)
16:17:35 <sina> can I use let ... in anywhere I want in my haskell program?
16:17:45 <ddarius> sina: Anywhere you can use an expression.
16:17:48 <Cale> sina: It's an expression form, so anywhere you need an expression.
16:18:12 <jmcarthur> krey: the most i usually use continuations in haskell and actually identify them as such is when i am doing some fancy tricks with higher rank types, and that's really about it. even then it isn't important they they're continuations. it's just a name for the concept
16:18:14 <sina> like | otherwise = let c = ... in (a,c)
16:18:19 <Cale> yep
16:18:28 <sina> cheers
16:18:47 <ddarius> > (let 1 = 2 in 1) + 1
16:18:47 <lambdabot>   2
16:19:01 <jmcarthur> krey: but even a lot of your common functions take continuations as parameters. (>>=) for example
16:19:04 <jmcarthur> :t (>>=)
16:19:05 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
16:19:06 <Cale> Continuations are useful for dealing with resource acquisition and release.
16:19:19 <meltingwax> the reason i like haskell is because it actually gets *easier* when i'm drunk
16:19:20 <jmcarthur> :t bracket
16:19:21 <lambdabot> Not in scope: `bracket'
16:19:22 <Cale> :t withFile
16:19:23 <lambdabot> Not in scope: `withFile'
16:19:26 <Cale> heh
16:19:27 <jmcarthur> :t Control.Exception.bracket
16:19:28 <lambdabot> forall a b c. IO a -> (a -> IO b) -> (a -> IO c) -> IO c
16:19:31 <Cale> We both fail :D
16:19:36 * ddarius isn't keen on calling practically every higher function a "continuation" or "taking continuations."
16:19:41 <Cale> meltingwax: :)
16:19:42 <krey> jmcarthur: why >>= ?
16:20:03 <jmcarthur> ddarius: i tend to only use the word for functions that you can't necessarily supply an argument to yourself
16:20:19 <jmcarthur> krey: the second argument is a continuation
16:20:24 <ddarius> jmcarthur: So none of them?
16:20:28 <sina> ddarius: why did that end up as 2 and not 3 ?
16:20:52 <jmcarthur> ddarius: using (>>=) as an example, you can't just take the a out of the IO a.
16:20:58 <krey> jmcarthur: I don't really see that
16:21:28 <krey> jmcarthur: to me  m >>= f = join (map f m)
16:21:58 <jmcarthur> krey: foo >>= bar   ==>  bar (fictionalRunIO foo)
16:22:08 <jmcarthur> krey: the former being CPS and the latter being direct style
16:23:23 <krey> jmcarthur: so this "direct style", how would this work for say the State monad?
16:23:33 <krey> or any monad that's not IO
16:23:56 <jmcarthur> krey: i'm just talking about the type
16:24:32 <jmcarthur> krey: notice i had to invent a function even for IO. i would have to do the same for many other monads
16:24:44 <jmcarthur> (ignoring unsafePerformIO, i had to invent it, that is)
16:24:57 <jmcarthur> i intentionally invented a new one because you'd have to for most monads
16:25:26 <krey> jmcarthur: can you give an example for another (proper) monad?
16:25:47 <jmcarthur> krey: it's a continuation because (>>=) passes its result(s) to the continuation
16:25:56 <jmcarthur> krey: rather than returning the result to you
16:26:04 <sina> if I have a which is Just x, how can I return the x part of it? is the easiest way (\Just x-> x) a ?
16:26:16 <jmcarthur> sina: there's fromJust
16:26:22 <jmcarthur> sina: it's partial though, of course
16:26:38 <jmcarthur> krey: any other examples would just be new names
16:26:39 <sshc> Does "listenOn" typically require root permissions?
16:26:55 <krey> jmcarthur: ?
16:26:57 <jmcarthur> krey: foo >>= bar  ==>  bar (functionalRunState foo)
16:27:07 <jmcarthur> krey: i just have to make it up. i'm not talking about implementations here
16:27:21 <jmcarthur> *fictional
16:27:22 <krey> jmcarthur: oh I thought you were
16:27:36 * krey is majorly confused now
16:27:36 <jmcarthur> krey: no. i'm talking about the second parameter to (>>=), not how (>>=) works
16:27:41 <sshc> What actions should I use when the program does have root permissions before its permissions are downgraded to those of a user to listen on a socket?
16:27:47 <sina> jmcarthur: thanks
16:27:57 <jmcarthur> krey: the second parameter to (>>=) is a continuation
16:27:59 <pastorn> how do i get this? No instance for (Data.String.IsString Data.ByteString.Internal.ByteString)
16:28:01 <jmcarthur> that's all i'm saying
16:28:48 <aavogt> pastorn: import something? Otherwise you have to write the instance
16:28:54 <krey> jmcarthur: higher order function?
16:28:57 <sshc> Ah, it looks like I can call "listenOn" as root, and use "accept" on the socket as a sure?
16:29:08 <pastorn> aavogt: Data.Binary.Get uses this kind of ByteString: http://hackage.haskell.org/packages/archive/bytestring/latest/doc/html/Data-ByteString-Lazy.html
16:29:29 <krey> jmcarthur: I mean, function, (m >>=) being higher order
16:30:07 <jmcarthur> krey: i don't understand what you mean here. i just mean that (>>=) doesn't return its result to the caller. it passes its result to a continuation instead
16:30:20 <jmcarthur> the type signature constrains it that way
16:30:45 <krey> jmcarthur: well sure, in the end, you get something inside M
16:30:52 <sshc> How do I determine whether a given port is already bound by a socket?  I want to continually try subsequent ports to bind to until a free one is found
16:31:01 <krey> jmcarthur: but that is only a continuation if M is Cont
16:31:06 <jmcarthur> krey: direct style would not have that continuation parameter. i'm not talking about the M here
16:31:26 <jmcarthur> krey: that was the point of my contrast with the fictional direct style earlier
16:31:35 <jmcarthur> brb
16:31:50 <krey> jmcarthur: don't worry, I give up (for today)
16:32:01 <krey> jmcarthur: thank you so much for trying to explain this!
16:32:54 <jmcarthur> sorry i have to go
16:32:58 <ddarius> jmcarthur: So is map taking a continuation?
16:37:41 <pastorn> Data.Binary should provide a working readfile-function
16:38:12 <pastorn> or rather a 'getWith :: FilePath -> Get a -> IO a'
16:38:27 * pastorn goes AttoParsec now
16:38:35 <phao> does haskell have a symbol for infinity? to use in [1..<infinity>] ?
16:38:48 <ion> [1..]
16:38:52 <phao> thx
16:39:03 <pastorn> phao: it has infinity
16:39:05 <walt> I am trying to get latest ghc with cabal. cabal list shows ghc in the list, but cabal install ghc says the package does not exist. What could be wrong?
16:39:08 <pastorn> > 1 / 0
16:39:09 <lambdabot>   Infinity
16:39:21 <pastorn> @type Infinity
16:39:21 <lambdabot> Not in scope: data constructor `Infinity'
16:39:29 <parcs> > [1..(1/0)]
16:39:29 <hpc> phao: or just [1..]
16:39:29 <lambdabot>   [1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17....
16:39:35 <Saizan> walt: you can't install ghc with cabal
16:39:39 <hpc> > maxBound :: Float
16:39:40 <lambdabot>   No instance for (GHC.Enum.Bounded GHC.Types.Float)
16:39:40 <lambdabot>    arising from a use of...
16:40:02 <phao> thx
16:40:02 <pastorn> hpc: that would've been cool :)
16:40:16 <Saizan> walt: the ghc package is on hackage mostly to make the documentation available on hackage
16:40:27 <walt> ah, ok
16:40:35 <pastorn> is there a library for infinite precision floats?
16:40:41 <hpc> CReal
16:40:42 <pastorn> or at least in the exponent
16:40:49 <walt> I am wondering what the best way is to get ghc 7 then on ubuntu. 
16:40:52 <hpc> it's arbitrary precision
16:41:01 <hpc> decided when you request a view of the output
16:41:11 <pastorn> hpc: go lazy stuff :)
16:41:13 <hpc> so the operations are lazy over precision that isn't needed
16:41:15 <Saizan> walt: haskell.org/ghc has generic binary tarballs for linux
16:41:17 <hpc> :D
16:41:22 <walt> Saizan: thanks
16:41:32 <lars9> @pl id &&& (+1)
16:41:32 <lambdabot> id &&& (1 +)
16:42:10 <ion> > ([2**1023..] !! 0) == ([2**1023..] !! 100000)
16:42:11 <lambdabot>   True
16:42:14 <ion> Floats ♥
16:42:56 <medfly> > [2**1023..]
16:42:58 <lambdabot>   [8.98846567431158e307,8.98846567431158e307,8.98846567431158e307,8.988465674...
16:43:17 <hpc> i suppose that's the max bound of a well-defined float number
16:43:31 <hpc> (excluding infinity, the various NaNs, etc
16:43:33 <hpc> )
16:44:27 <ddarius> > let xs = [10000000000000.0..] in head xs == head (tail xs)
16:44:27 <lambdabot>   False
16:47:03 <lars9> hpaste is down?
16:47:06 <ion> Yeah, in a 64-bit IEEE 754 float, the range for the exponent is −1022..1023 and the maximum significand = 0.999…, so i assume 2^1023 is represented as exponent = 01111111111 and significand = (all ones), no way to do a +1.0. :-)
16:47:37 <ion> That is, the closest value to 2^1023 is represented as…
16:47:53 <lars9> what else site can we use?
16:48:11 <hpc> pastebin, codepad, there's thousands
16:48:18 <hpc> or at the very least, tens
16:48:48 <Bynbo7> > 2*1024
16:48:49 <lambdabot>   2048
16:48:55 <Bynbo7> > 2^1024
16:48:56 <lambdabot>   179769313486231590772930519078902473361797697894230657273430081157732675805...
16:48:56 <Bynbo7> even
16:49:03 <Saizan> hpc: units!
16:49:09 <augustss> > 2**53 + 1 == 2**53
16:49:10 <lambdabot>   True
16:49:11 <lispy> dpaste is nice
16:49:22 <lispy> http://dpaste.com/
16:49:31 <augustss> No need for 1024
16:49:34 <lispy> hpaste is up for me
16:49:50 <ion> Sorry, brainfart. I utterly forgot that the significand has an implied “1.” in front, so you can go all the way up to ~ 2^1023·1.999… but can not reach 2^1024.
16:50:05 <lispy> The annoying thing about hpaste though is that it requires a user name (why?) and a post name (who cares?)
16:50:17 <unkanon> yeah it's really annoying
16:50:34 <unkanon> there's a lisp paste that I used to like, because it sends it to the #lisp channel
16:50:43 <unkanon> hpaste would be better if it sent the link to #haskell
16:50:52 <unkanon> I always fill that out hoping that it will :)
16:50:54 <lispy> It used to do that, but I think they disabled it due to spam
16:51:08 <lispy> That was a paste bin or two ago
16:51:38 <unkanon> hmm
16:51:39 <lispy> unkanon: if you want to fix it, here is the source: https://github.com/chrisdone/amelie
16:51:42 <lars9> pastebin, codepad do not work either...
16:51:44 <Saizan> i think it got disabled due to not getting reimplemented on the later pastebins
16:51:55 <lars9> something wrong here
16:52:28 <ddarius> > [0.0 .. 1.0]
16:52:29 <lambdabot>   [0.0,1.0]
16:52:37 <Bynbo7> It's the great pastebin mass suicide of 2010!
16:53:09 <ddarius> > let xs = [100000000000000000000000000000000.0..] in head xs == head (tail xs) -- this should be enough zeroes
16:53:10 <lambdabot>   True
16:54:37 <aristid> @pl \xs -> head xs == head (tail xs)
16:54:37 <lambdabot> liftM2 (==) head (head . tail)
16:54:48 <unkanon> lispy: thanks for the link btw :)
16:55:09 <lispy> unkanon: np
16:55:13 <lars9> hi i just did a test on memoization, http://openetherpad.org/woG0hilzXf, fibm, fibm3 can do memoization, but fibm2, fibm4 can not, why?
16:55:38 <hpc> oh god, the scriptiness
16:55:58 <augustss> > let xs = [9007199254740992.0..] in head xs == head (tail xs)
16:55:58 <lambdabot>   True
16:56:10 <augustss> Why are you using these weird decimal numbers?
16:56:14 <lispy> ?tell ezyang if you are learning Isabelle you might enjoy #isabelle here on freenode and there is a subreddit too (http://reddit.com/r/isabelle)
16:56:14 <lambdabot> Consider it noted.
16:56:26 <lispy> ezyang: I mention that because I saw your blog mentioned Isabelle
16:57:19 <augustss>  let xs = [9007199254740991.0..] in head xs == head (tail xs)
16:57:36 <augustss> > let xs = [9007199254740991.0..] in head xs == head (tail xs)
16:57:36 <lambdabot>   False
16:58:48 <Cale> lars9: Because the definition of the memoising list is inside the lambda, and so gets garbage collected as soon as the lambda finishes evaluating.
16:59:31 <aavogt> @ty ((==) `on` head) `ap` tail
16:59:32 <lambdabot> forall a. (Eq a) => [a] -> Bool
16:59:44 <Saizan> lars9: it's the difference between "let fibs = ... in \x -> .." and "\x -> let fibs = .. in ..", in the latter case fibs get only generated after you've applied the function, and a new one will be created for every application
16:59:49 <Cale> lars9: The important distinction here, after desugaring, is one between  \x -> let ... in ... and  let ... in \x -> ...
17:00:16 <aavogt> > (((==) `on` head) . tail) "_aa" "aa"
17:00:16 <lambdabot>   True
17:00:19 <Cale> the latter will memoise the things defined in the let, the former will not
17:01:34 <lars9> Saizan Cale is it just an implementation choice, or is there some theory behind?
17:01:39 <Cale> lars9: This is because in \x -> let ... in ..., the definitions made in the let are part of the function's result, and in let ... in \x -> ..., the definitions being made in the let are part of the definition of the function.
17:01:58 <djahandarie> Is there any elegant way to do bottom-up dynamic programming in Haskell?
17:01:59 <Cale> It's partly an implementation choice. Obviously these things are semantically equivalent.
17:02:14 <Cale> But their operational semantics is different intentionally.
17:02:23 <Cale> It gives you control over time/space complexity.
17:02:37 <lispy> djahandarie: we tend to call it "tying the knot" when we do dynamic programming (or memoization), but I'm not sure what the modifier "bottom-up" means in this context
17:02:49 <augustss> djahandarie: recursive array definitions, perhaps?
17:03:51 <djahandarie> I mean like, "give me a higher-order function and I give you a bottom-up dynamic programming version of it". Sort of like what conal wrote on memoization
17:04:13 <djahandarie> I think this may be a more difficult problem though
17:04:25 <lars9> Cale Saizan is there any document on this?
17:04:59 * djahandarie will think about this
17:05:07 <ddarius> lars9: The Report doesn't specify this behavior one way or another.
17:05:53 <augustss> djahandarie: I think you'll have to come up with a crisper problem statement
17:05:57 <pastorn> anyone here have a working attoparsec-parser which uses the IsString instance?
17:06:05 <djahandarie> augustss, yeah
17:06:23 <ddarius> djahandarie: I recommend adding steam as you are baking it.
17:07:14 <lars9> ddarius: but it seems everyone knows it ? :)
17:07:59 <pastorn> i have (char :: Char -> Parser Char), used like this (mapM char "LOD"), but here it says that i have an instance of (IsString (Parser ByteString)): http://hackage.haskell.org/packages/archive/attoparsec/0.8.2.0/doc/html/Data-Attoparsec.html
17:08:09 <augustss> lars9: word-of-mouth
17:08:10 <ddarius> lars9: The Report also doesn't specify tail call optimization or lazy evaluation.
17:09:20 <pastorn> so i should be able to have just ("LOD") on a line in my parser and it should work?
17:09:31 <pastorn> (using OverloadedStrings)
17:10:41 <lars9> augustss ddarius i guess it should be mentioned somewhere
17:10:54 <lars9> augustss ddarius they are fundamental for memoization
17:11:42 <phao> I'm trying to run this code, but I'm getting "test.hs:14:2: parse error on input `|'" ... what is wrong with the code? http://ix.io/1jw
17:11:50 <kmc> yeah, the Haskell standard is insufficient to write portable code if you care about performance
17:11:58 <kmc> because it says nothing about performance
17:12:04 <Cale> lars9: There are various papers about how GHC works from which you can infer things like this, but they're not really very well-suited to beginners. We really need to make sure to mention things like that in tutorials. :)
17:12:43 <kmc> Cale, you could write up your awesome graph-reduction explanations of stuff...
17:12:46 <Cale> phao: 'where' is part of the function declaration and goes after all the guards
17:12:56 <phao> right
17:13:00 <Cale> phao: however, you could also choose to use 'let' instead, which is an expression form
17:14:09 <Cale> kmc: yeah...
17:14:17 <augustss> lars9: It really should be mentioned somewhere.  Perhaps in a document that augments the report which describes the expected operational semantics.
17:14:40 <lars9> the most important thing is to tell ppl if it is just an implementation or following some theory, otherwise someone's mind will be struggling to understand it :)
17:14:43 <ion> > 2**(2^10-1) * fromRational (2 - (1 % 2^52)) -- Maximum possible numeric float64, i think.
17:14:44 <lambdabot>   1.7976931348623157e308
17:14:54 <Cale> lars9: The thing is, it's a bit of both
17:15:39 <augustss> > let maxFloat x = encodeFloat (floatRadix x ^ floatDigits x - 1) (snd (floatRange x) - floatDigits x) in maxFloat (1::Double)
17:15:40 <lambdabot>   1.7976931348623157e308
17:15:40 <Cale> lars9: Haskell implementations are allowed to evaluate expressions in any order that they want (so long as their choices don't adversely affect termination behaviour), and are allowed to discard or keep results around arbitrarily.
17:15:52 <augustss> > let maxFloat x = encodeFloat (floatRadix x ^ floatDigits x - 1) (snd (floatRange x) - floatDigits x) in maxFloat (1::Float)
17:15:53 <lambdabot>   3.4028234663852886e38
17:16:08 <ion> Ah, encodeFloat. My hoogle/google-fu wasn’t good enough. :-)
17:16:10 <Cale> lars9: However, lazy evaluators (one implementation of non-strict semantics) work in a particular way which is predictable.
17:16:28 <Cale> lars9: This is complicated by the fact that GHC isn't just a straightforward lazy evaluator
17:16:56 <Cale> (It strictifies some things as it sees fit)
17:17:25 <lars9> Cale: i see.
17:17:25 <augur> how do guards work in do notation??
17:17:33 <Cale> But GHC tends to be very conservative about anything which affects space usage.
17:17:33 <ddarius> The DeathImplementation 9000 for Haskell would be interesting...
17:17:51 <Cale> augur: *in* do notation?
17:17:58 <Cale> augur: You mean inside a case inside a do?
17:18:00 <jmcarthur> how do cars work on bridges?
17:18:11 <c_wraith> jmcarthur, usually by falling off the side
17:18:19 <Cale> augur: They'll work the very same way as elsewhere.
17:18:22 <augur> Cale: noo like.. do x <- xs ; guard (odd x) ; ...
17:18:29 <Cale> Oh, the guard function
17:18:35 <jmcarthur> guard is just a function
17:18:40 <jmcarthur> :t guard
17:18:41 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
17:18:45 <Cale> guard b = if b then return () else mzero
17:19:04 <Cale> In the list monad, mzero = []
17:19:10 <Cale> In Maybe, mzero = Nothing
17:19:10 <augur> Cale: i see..
17:19:13 <augur> hmm. ok
17:19:57 <augur> oic
17:20:08 <augur> i think
17:20:09 <augur> hmm
17:20:24 <Cale> Yeah, you have to think about how >>= works in these monads a bit to see how it works out in practice.
17:20:33 <jmcarthur> augur: wherever you see guard you can just inline its definition to see what it's doing
17:20:39 <jmcarthur> as with all haskell functions
17:20:39 <Cale> But here's a clue...
17:20:44 <augur> jmcarthur: i know :P
17:20:50 <Cale> In the list monad, let's count the elements of x >>= f
17:20:54 * ddarius inlines putChar.
17:21:11 <ion> do x <- [1,2,3]; guard …; return x is equivalent to do x <- [1,2,3]; [()]; return x in the true case and do x <- [1,2,3]; []; return x in the false case. Try what happens if you make the middle array [(),()].
17:21:16 <Cale> it'll have the sum over v in x of length (f v)  elements.
17:21:16 * djahandarie inlines ST RealWorld
17:21:26 <Cale> and so if x has no elements
17:21:32 <Cale> then the whole thing has no elements
17:21:59 <Cale> So, guard effectively cuts off that branch of the computation when the condition fails.
17:22:24 <Cale> ion: s/array/list/ :)
17:22:31 <ion> cale: Yeah :-)
17:22:47 <Cale> (Haskell has arrays too!)
17:22:52 <ion> aye
17:23:33 <Cale> (actually, it almost has too many array types, especially if you include what's available on hackage :P)
17:23:58 <augustss> Cale: not "almost", it has too many arrays
17:24:18 <lars9> is there any associative data structure which does not need to strictly evaluate all keys?
17:24:29 <ion> It also might be helpful to think of the example in terms of this pseudocode: for x in [1,2,3]; for _ in [()]; return x
17:24:32 <Cale> lars9: a function?
17:24:33 <Cale> ;)
17:25:01 <lars9> Cale: the only choice?
17:25:12 <ddarius> lars9: There are plenty that don't -need- to.
17:25:12 <jmcarthur> lars9: a list?
17:25:27 <Cale> Oh yeah, a list of pairs works.
17:25:46 <jmcarthur> well i meant its semantics, but that too
17:25:57 <Cale> lars9: The reason that Map evaluates the keys as they're inserted is so that it can arrange the elements into an order which is efficient for searching later. If you're not allowed to look at the keys, you can't do that.
17:26:11 <sina> Why do I get the error Undefined variable "fromJust"? should I import any library for maybe?
17:26:22 <augustss> sina Data.Maybe
17:26:24 <kmc> Data.Maybe
17:26:25 <copumpkin> lars9: ->
17:26:26 <kmc> but don't use fromJust
17:26:32 <kmc> > fromJust Nothing
17:26:33 <lambdabot>   *Exception: Maybe.fromJust: Nothing
17:26:42 <kmc> because that's a profoundly useless error message
17:26:46 <kmc> which will crash your whole program
17:26:53 <sina> best way to do that would be (\Just x -> x) ?
17:26:58 <copumpkin> sina: that's equivalent
17:27:00 <kmc> no that's about as bad
17:27:00 <jmcarthur> just as bad
17:27:03 <lars9> jmcarthur: i meant some data structure can help memoization, so list does not fit
17:27:04 <kmc> you should use pattern-matching
17:27:09 <c_wraith> > (\Just x -> x) Nothing
17:27:10 <lambdabot>   Constructor `Data.Maybe.Just' should have 1 argument, but has been given 0
17:27:10 <kmc> case foo of Nothing -> ....; Just y -> ...
17:27:17 <jmcarthur> lars9: list does too fit
17:27:19 <kmc> sina, or use 'maybe' or 'fromMaybe'
17:27:20 <kmc> :t maybe
17:27:21 <lambdabot> forall b a. b -> (a -> b) -> Maybe a -> b
17:27:22 <kmc> :t fromMaybe
17:27:22 <lambdabot> forall a. a -> Maybe a -> a
17:27:24 <c_wraith> > (\ (Just x) -> x) Nothing
17:27:25 <lambdabot>   *Exception: <interactive>:1:134-148: Non-exhaustive patterns in lambda
17:27:32 <copumpkin> :t (>>=)
17:27:33 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
17:27:35 <copumpkin> :t (>=>)
17:27:35 <lambdabot> forall a (m :: * -> *) b c. (Monad m) => (a -> m b) -> (b -> m c) -> a -> m c
17:27:40 <copumpkin> (those too)
17:27:41 <kmc> :t fromMaybe (error "a more helpful error message") -- sina
17:27:42 <lambdabot> forall a. Maybe a -> a
17:27:47 <sina> I am pretty sure that the input will be Just something. cause I have if input == Nothing and this is in the else clause
17:28:04 <jmcarthur> lars9: tries are popular for memoization
17:28:09 <kmc> then you should pattern match instead of using 'if'
17:28:18 <jmcarthur> lars9: because you can generate a trie lazily
17:28:23 <kmc> case input of Nothing -> ...; Just x -> ...
17:28:34 <jmcarthur> lars9: see http://hackage.haskell.org/package/MemoTrie
17:28:39 <kmc> or:  let f Nothing = ...; f (Just x) = ... in f input
17:29:02 <lars9> jmcarthur: yeah im using MemoTrie without understanding it, now im trying to understand how it works:)
17:29:37 <sina> I already have a let just before the if clause. that makes it messy :D
17:29:47 <jmcarthur> lars9: if you understand what a trie is, how you can generate one from a function lazily, and how memoization commonly works with ghc, you're off to a good start
17:30:06 <kmc> you can put it in the same 'if'
17:30:10 <kmc> err
17:30:12 <kmc> in the same 'let'
17:30:15 <jmcarthur> lars9: conal has a series of blog posts about memoization somewhere
17:30:29 <jmcarthur> not sure how helpful they would be for you
17:30:35 <kmc> but probably 'case', 'maybe', or 'fromMaybe' is the way to go
17:30:49 <kmc> if you're disassembling a Maybe value into Nothing and (Just x), you should pattern match
17:30:56 <conal> There is a tag on my blog
17:31:04 <kmc> using 'if' and 'fromJust' would be Doing It Wrong™
17:31:05 <lars9> jmcarthur: memo = untire . tire
17:31:20 <Boxo> Why does ghci says "overlapping instances" here? http://pastebin.com/sA0JTFSC
17:31:30 <sina> kmc: the pattern match would be using the let ... in ?
17:31:39 <kmc> using "case"
17:31:42 <kmc> most directly
17:31:45 <kmc> case input of Nothing -> ...; Just x -> ...
17:31:53 <augustss> sina: never use an if and == to check for Nothing, always use pattern matching
17:31:57 <jmcarthur> Boxo: because defining a Functor instance for everything overlaps existing Functor definitions
17:32:14 <kmc> Boxo, whether an instance overlaps is determined entirely by its "head" and not by the context
17:32:20 <kmc> so you have "Functor Maybe" and "Functor f"
17:32:24 <lars9> conal: thanks i read your blog, it's how i got to know how to make memoization in haskell without recursive definition of Map/Array etc
17:32:27 <kmc> and setting f=Maybe shows the overlap
17:32:37 <sina> thanks all. I need to take a look at case then :)
17:32:38 <Boxo> No, I have Functor1 f => Functor f :(
17:32:44 <kmc> no, you have "Functor f"
17:32:47 <jmcarthur> Boxo: Functor1 f is your context. it doesn't count
17:32:48 <kmc> for the purposes of instance selection
17:33:02 <kmc> contexts aren't used in instance selection at all... it selects an instance by the head only, then checks the context and either fails or succeeds
17:33:04 <kmc> there is no backtracking
17:33:05 <jmcarthur> Boxo: constraints are checked kind of separately from types
17:33:40 <kmc> besides there's nothing stopping someone else from writing "instance Functor1 Maybe" and then it really would overlap
17:33:41 <Boxo> damn. seems stupid but okay.
17:33:53 <kmc> i agree that it's stupid; i'd like to see backtracking as an extension at least
17:33:54 <jmcarthur> it's not really that stupid
17:34:00 * ddarius writes instance Functor1 Maybe.
17:34:06 <kmc> ddarius, nooooooo
17:34:11 <jmcarthur> this restriction makes modular programming much simpler
17:35:37 <ddarius> Modular programming is overrated.
17:35:41 * ddarius etches some silicon.
17:37:11 <lars9> should all functions defined in GADT's data ... where ... be data constructors?
17:37:26 <ddarius> They are data constructors by definition.
17:38:07 <Pseudonym> ddarius: I don't want to see your VHDL.
17:38:13 <sina> I like "case" :)
17:38:17 <ddarius> Pseudonym: What VHDL?
17:38:52 <blackh> sina: You ain't seen nothing yet. :)
17:38:54 * Pseudonym doesn't want to see your hand-designed circuits, then
17:39:38 <kmc> sina, yeah.  Haskell has some experimental/controversial features, and then it has some features that are just like, "why has any language in the past 40 years not had this feature"
17:39:54 <kmc> pattern matching is firmly one of the latter, imo :)
17:40:03 <maurer_> kmc: Typeclasses.
17:40:19 <maurer_> That's the one thing that the OCaml and SML junkies seem to envy strongly
17:40:24 <sina> kmc: I will find it hard getting back to java later :-s
17:41:02 <ddarius> sina: Just don't go back.
17:41:03 <kmc> sina, yep... if your livelihood depends on being happy programming java, you might not want to study haskell
17:41:18 <kmc> (i don't actually think that's a good reason -- knowledge is good -- but i'm not kidding about the effect)
17:41:52 <ddarius> Dead and knowledeable is the way to be.
17:42:00 <ddarius> +g
17:42:03 <blackh> sina: I agree with kmc.
17:42:04 <sina> I'm not sure of any job out there asking for haskell...
17:42:23 <blackh> sina: You have to make your own luck at this stage, but that will change (IMO).
17:42:35 <medfly> I've learned about Haskell and I had no issue programming in PHP for money
17:42:35 <ddarius> Any recommendations for a good, graphical wafer-level simulator/editor?
17:42:42 <medfly> stop being such pussies
17:43:24 <maurer_> ddarius: magic does this if I remember correctly
17:43:29 <sina> I'm still learning haskell.....
17:43:46 <djahandarie> Who would name their program 'magic'?/
17:43:47 <kmc> sina, fwiw i don't consider Haskell the only tolerable language, either
17:43:55 <djahandarie> "Oh yeah, you just need magic for that to work"
17:43:58 <blackh> medfly: I have written some enormous programs, and I couldn't face writing another one in any language other than Haskell.
17:43:58 <kmc> hehe
17:43:59 <maurer_> ddarius: http://opencircuitdesign.com/magic/
17:44:35 <ddarius> djahandarie: "You can do it with magic."
17:44:47 <medfly> too bad
17:44:47 <sina> doesn't python have some functional programming bits? like lambda
17:45:04 * ddarius hopes that Tk isn't the only interface available...
17:45:06 <kmc> it does sina
17:45:22 <kmc> as does every other half-decent language
17:45:44 <lars9> kmc: lol
17:45:53 <kmc> it's not as though lambda is a new or controversial idea
17:45:59 <kmc> the idea literally predates computers
17:46:10 <ddarius> Oh crap.  John Ousterhout.  There's no way this will just be a coincidence.
17:46:12 <Cale> Or at least electronic computers :)
17:46:25 <sina> I think I'll focus on python later instead of java. I mostly do php and web
17:46:26 <medfly> someone needs to slap you for that comment
17:46:27 <kmc> fair enough Cale
17:46:37 <maurer_> kmc: "every other half-decent" Counterpoint: C and other systems languages do not have, and should not have lambdas.
17:46:38 <Cale> medfly: who?
17:46:38 <kmc> ;)
17:46:39 <pastorn> shit, attoparsec is difficult :/
17:46:47 <medfly> well, preferably me
17:46:47 <kmc> yeah, i give them a break for that maurer_
17:46:55 <kmc> but i didn't feel like layering in every qualifier
17:46:59 <Cale> medfly: I mean who is 'you'?
17:47:55 <kmc> anyway the way comparison of programming languages is taught in school is idiotic and leads to a lot of very old, broadly applicable good ideas being lumped into little sidelined areas where few go
17:47:58 <Philippa> kmc: I'm not sure there's anything in haskell where I find it appropriate to ask the "why has any language in the last 40 years not had...?" question, or at least where I haven't got a fair idea of a range of perfectly sensible answers
17:48:18 <Philippa> yeah, including the "right tool, right job" line
17:48:20 <kmc> why does Java not have lambda?
17:48:25 <Philippa> a lot of bullshit gets shoveled under that :-(
17:48:27 <ddarius> Philippa: What about TCO?  But then Haskell doesn't have that.
17:48:35 <Philippa> ddarius: quite
17:48:40 <ddarius> kmc: Because objects are better than lambda.
17:48:58 <maurer_> ddarius: I thought we did have tailcall optimisation...
17:49:01 <Philippa> kmc: well, the reasons there are mostly social, but that doesn't mean you can extend it to ask the same question of C++ fairly
17:49:15 <lars9> what is computer before electronic computer? does this count? http://en.wikipedia.org/wiki/Abacus
17:49:15 <Philippa> maurer_: not required in the standard like Scheme does
17:49:25 <ddarius> maurer_: You thought wrong.
17:49:27 <Philippa> lars9: person, pen, paper, instructions
17:49:33 <maurer_> Philippa: Sure, but why does that go in a standard?
17:49:44 <maurer_> ddarius: Why do my massive foldls not explode?
17:49:45 <ddarius> lars9: See Babbage's analytical engine.
17:49:53 <kmc> because otherwise it is meaningless to ask "does Haskell have" and only "does GHC have..."
17:50:05 <BMeph> How is Babbage formed? ;þ
17:50:07 <maurer_> kmc: True.
17:50:10 <ddarius> Because they are not massive enough.  Perhaps you meant foldl's.
17:50:45 <Philippa> maurer_: because if it's not in the standard, you can't actually rely on it being a property of your code as opposed to your code as interpreted by a particular implementation
17:50:50 <lars9> how does Abacus fit in modern computation theory? some ppl still use it today, as fast as electronic calculators.
17:50:59 <Philippa> (consider: lazy evaluation isn't in the standard either, only non-strictness...)
17:51:07 <maurer_> I suppose I might have done that? I don't remember what I did the last time I folded over more than a million elements)
17:51:16 <ddarius> Which tells where the slow part is in electronic calculators.  Hint: It's the people.
17:51:30 <Philippa> lars9: it has much the same role as pen'n'paper - it's externalised memory on which we have some nice algorithms we can use it as a component for
17:51:34 <kmc> Philippa, it's fair that certain special-purpose systems languages would lack lambda.  my point is just that there's some things that are "paradigms" and some that are "generally good ideas" and a lot of the latter get categorized by the further by people who need an excuse not to learn them
17:51:42 <medfly> Cale, you
17:51:42 <kmc> as the former*
17:51:43 <Eduard_Munteanu> That's like with computers, IO is slowest :)
17:51:52 <Philippa> kmc: agreed, you should have a reason not to support HOFs
17:52:17 <ddarius> Eduard_Munteanu: It's not like that; it is that.
17:52:27 <Philippa> that's not to say that "functional programming" isn't also a paradigm, but I support narrowing the borders and also talking about higher-order procedural/imperative programming
17:52:47 <kmc> in that vein i'd support talking about "denotational programming" rather than "functional programming"
17:53:02 <Philippa> both are useful terms
17:53:20 <kmc> i do higher-order imperative programming in Haskell but people like conal are right to point out that it's not denotational
17:53:27 <Eduard_Munteanu> Okay, you guys seem in a certain mood... mind suggesting an intro to denotational semantics?
17:53:34 <Philippa> I use functional programming in contexts where denotational programming isn't entirely appropriate: the meta-style I tend to use in haskell that's full of EDSLs, for example
17:54:03 <Philippa> Eduard_Munteanu: it's "just" defining a language via a pure-functional interpreter, FWIW
17:54:05 <nostrand> can i search for instances of a certain class in hoogle/yahoo?
17:54:15 <roconnor> when is denotational programming not entirely appropriate?
17:54:51 <jmcarthur> Eduard_Munteanu: you're best off if you get conal in a talkative mood :)
17:54:52 <Philippa> roconnor: as a term to describe code that's full of embedded languages that aren't denotational, but where having a functional language as host is an important feature
17:54:55 <Eduard_Munteanu> Hm, I see. I've been reading a "programming in Coq" tutorial that took a similar approach.
17:55:01 <Eduard_Munteanu> Heh.
17:55:11 <lispy> What means you, "denotational programming".  As in, can you give me examples of denotational programs and ones that are not?
17:55:28 <sina> If I want to see if a list contains Nothing, the best way would be using filter?
17:55:38 <Philippa> lispy: it's a bit like "OOP" - it comes down to how the semantics of the system are ("canonically") expressed
17:55:47 <roconnor> lispy: all of ruby.  Who knows what that code denotes.  Could do anything!
17:55:50 <roconnor> :P
17:56:23 <maurer_> @src elem
17:56:23 <lambdabot> elem x    =  any (== x)
17:56:27 <Philippa> conal's probably the best-placed to explain it - I understand it as roughly "identify the domain, construct a denotational semantics around it, reason and program with that"
17:56:28 <maurer_> sina: ^^
17:56:37 <jmcarthur> Eduard_Munteanu: denotational semantics is really nothing more than defining the meaning of a language in terms of compositions of things with other meanings
17:56:47 <sina> maurer_ : right, forgot elem
17:58:18 <Philippa> (note: "domain" as in "sensible target set-or-suitable-replacement for a function", not in the wider sense seen in "domain-specific language")
17:58:45 <conal> in denotative programming, types have precise mathematical meanings.
17:59:55 <conal> and ops on those types have meanings defined purely in terms of the type meanings
18:00:11 <conal> (compositionally)
18:00:28 <lispy> conal: I have to run soon.  Do you happen to have a (or many) blog posts about the meaning of denotational programming or a book I could read?
18:00:59 <conal> peter landin suggested the term. looking for a post ...
18:01:16 <lispy> conal: thanks!
18:01:37 <Philippa> conal: out of interest, given that I have a habit of highly-monad-ridden programming most of which is purely expressible at root, would you consider it reasonable to describe that as denotational? (I /mostly/ don't actually reason in terms of those properties, but mostly I don't have to: I probably rely on them a lot at an intuitive level)
18:02:01 <Philippa> (I /do/ believe in insulating everything else from IO with extreme prejudice)
18:02:41 <sina> It might sound noob, but what does $ do in haskell?
18:02:47 <conal> lispy: http://conal.net/blog/posts/is-haskell-a-purely-functional-language/#comment-35882
18:02:53 <dmwit> ?src ($)
18:02:53 <lambdabot> f $ x = f x
18:03:25 <sina> dmwit, so, why should someone use $ here?
18:03:27 <wornof> sina: (p $ q) takes q, and gives it to p as an argument
18:03:37 <lispy> sina: well, it's the identity function with restricted domain/range.  We use it a lot because it's infix and makes it so we can save some parens
18:03:49 <dmwit> sina: I don't know where "here" is, but at a guess: to avoid parens.
18:03:54 <wornof> This is useful if, for instance, q is (someFunction x 19 [1..5])
18:04:00 <wornof> So you don't need brackets around all that
18:04:00 <Philippa> not only does it "save" parens, it indicates a specific paren pattern
18:04:18 <Philippa> so once you're used to it, it's quicker to parse because it saves you having to pay attention to a nesting level
18:04:23 <conal> Philippa: depends on whether you have denotational models and stick to them
18:04:30 <lispy> conal: I appreciate the link, I have to run now but I'll look it over later.
18:04:33 <sina> oh, nice
18:04:42 <Philippa> (effectively it tail calls the level below the one it's written at when it's done, IYSWIM)
18:04:53 <conal> lispy: take care
18:05:02 <lispy> conal: thanks, you too!
18:05:15 <Philippa> conal: what counts as "stick to them"? Merely not violating them (or at least extending it into another denotational model), or something stronger?
18:05:22 <sina> thanks :)
18:06:49 <conal> Philippa: that you don't go outside your model to define your ops
18:06:57 <Philippa> (I tend to have the EDSL/monad implementation "be" the denotational model to some extent, but then I tend to keep the cores fairly simple: I do play 'semantic lego' a lot)
18:07:24 <Philippa> yeah, that'd count as "violating the model" to me - and fair enough
18:07:43 <conal> whether a monad or doesn't effect denotativeness
18:08:00 <Philippa> er, think you missed a word there?
18:08:25 <c_wraith> Maybe a couple of them
18:08:34 <conal> whether or not
18:08:52 <Philippa> (it's not monadicness in particular I have in mind, though: I'm more asking whether you consider the 'rot' to be IO specifically or the embedding of traditionally-non-denotational models that can be denotationally expressed but aren't usually thought of that way - I think I have an answer)
18:09:27 <conal> my first time IRCing on an iPad
18:10:15 <Philippa> FWIW I do play a lot with implicit shorthands denotationally but essentially always in such a manner that I know how to generate the complete denotational model if I have to - I get the impression you find my taste in implicitness mildly problematic for discussion until I've at least sketched it out for you, but *shrug*
18:12:46 <Philippa> (I know I'll merrily use a bunch of isomorphisms that you find problematic when not stated clearly, and I think my willingness to play with constructs that are some specific structure "up to" some need to ignore a detail probably irks a lot of people when I don't state the "up to" extremely clearly - as in "Writer is referentially transparent up to 'logging order'")
18:13:42 <Starscream> What do you guys think about using Haskell for writing compilers?
18:14:03 <Philippa> unless you have very tight resource constraints on the system running the compiler, it's awesome at it
18:14:15 <augur> :D
18:14:23 <augur> list comps in object-scheme! :D
18:14:47 <Philippa> if you do have such constraints, it's still not a bad prototyping language - the ease of refactoring makes it easier to carry out big changes, and you can port it into something like C when you're done and know it passes tests and so forth
18:15:52 <Philippa> (I'd be interested to know how easy it is to do resource-tight programming in haskell itself, the Galois folks're probably most likely to know but it'd involve a much higher level of bordering-on-voodoo because the language's semantics don't normally care about memory usage much)
18:16:03 <djahandarie> And I think tight space resources are more problematic than tight time resources... you can usually make Haskell go pretty fast if you need to usually
18:16:09 <Philippa> (so you'd really be programming to GHC-haskell or similar if you're doing that)
18:17:16 <Philippa> Starscream: anyway, time to refine the question if you want more info? Algebraic datatypes are fundamentally the Right Structure for a lot of compiler work, or at least the starting point for defining it, which is a big help to get you started in the small
18:18:00 <Starscream> are you saying it would produce a good quality compiler, but wouldn't be memory efficient?
18:18:31 <Philippa> approximately. If you want to fit in 2MB at runtime, you might have problems
18:18:43 <blackh> Starscream: Haskell has about the same memory efficiency as other high-level languages, i.e. less memory efficient than C.
18:19:02 <djahandarie> (As long as you are careful about space leaks.)
18:19:22 <blackh> Starscream: Haskell is good for most things, but especially good for writing compilers.
18:19:28 <Philippa> blackh: that, and it's harder to trace memory usage than in a strict language for reasons beyond "it's GCed"
18:20:08 <Philippa> but once you've got the discipline down, the pathological cases aren't too hard to avoid. It's just a question of whether you've got specific space requirements rather than "don't create a 2TB heap"
18:21:09 <blackh> Starscream: Another answer is, "I don't think you could find a better language for writing a compiler."
18:21:53 <Philippa> blackh: heh. Depends on your exact needs, but it's certainly my default tool for it unless I know I have specific needs that suggest otherwise (eg I want proofs about it, or I want to fit in a narrow heap footprint)
18:22:01 <ddarius> If you have tight time constraints then you have tight space constraints.
18:22:19 <copumpkin> yay, I have two bookshelves set up, two papasans, a rug, and a coffee table
18:22:23 <ddarius> Unless you can do a whole lot of off-line processing...
18:22:24 <copumpkin> as well as my bed and dressers
18:22:32 <Philippa> yes and no: the space constraints may be a lot tighter than the time constraints
18:23:37 <Philippa> (and I expect that of compilation of a 'nice' modern language - one that's not designed to be easily compiled with tech of a 50s-70s vintage - on a device with small amounts of memory - to come under that category if you need to fit in a small space)
18:25:09 <ddarius> At any rate, see Virgil.
18:25:46 <Philippa> Starscream: what do you actually want to achieve? The caveats I'm pointing out are minority concerns these days
18:26:06 <Philippa> and if you're happy to eat a half gig of heap if need be, haskell is awesome for most compiling needs
18:27:39 <blackh> Half a gig of heap? What are you talking about? Haskell's memory consumption is not worse than other high-level languages.
18:28:05 <blackh> I should say GHC's.
18:28:08 <jmcarthur> ghc is a great example of a compiler taking a ton of memory
18:28:18 <copumpkin> agda beats it hands down!
18:28:19 <jmcarthur> the compiler itself, i mean
18:28:20 <blackh> Yes, but we're not talking about the compiler.
18:28:30 <ddarius> Not as good an example as JHC.
18:28:31 <jmcarthur> copumpkin: but agda is not considered a mature compiler
18:28:33 <Saizan> but ghc is a compiler written in haskell :)
18:28:48 <jmcarthur> blackh: we're not? i thought we were
18:29:02 <blackh> No - we're talking about writing a compiler in Haskell.
18:29:09 <jmcarthur> blackh: rather, compiler written in haskell, which ghc is
18:29:25 <Philippa> blackh: there are plenty of plausible situations where a modern compiler might eat a half gig of heap, especially if you want to instrument it fully
18:29:39 <jmcarthur> blackh: anyway, i was going to add that ghc is merely an example of such a compiler, not that all compilers written in haskell would have similar space requirements
18:29:45 <Philippa> half a gig is /also/ not that big a deal these days
18:29:56 <blackh> Yes, but you're giving the impression that Haskell wastes memory, which is not true.
18:30:06 <blackh> (GHC-compiled programs, I mean.)
18:30:06 <Philippa> "if need be" - significant words
18:30:11 <jmcarthur> ghc has made me run out of memory on a few occasions, and i have four gigs
18:30:41 <Saizan> ghc or ld?
18:30:45 <jmcarthur> ghc
18:30:55 <sshc> Does Data.ByteString.hGetLine include the newline charactar?
18:31:10 <Philippa> Starscream: anyway, please carry on asking before we spend the rest of the evening infighting and ignore you? :-)
18:31:50 <Starscream> Well, you guys got me kind of confused, no offense
18:31:54 <jmcarthur> language-python was a problematic example for one of the ghc 6.12.* versions, but i think 6.12.3 sort of fixed the issue. i don't think it was considered a bug though
18:32:14 <jmcarthur> Starscream: haskell is awesome for writing compilers
18:32:50 <jmcarthur> Starscream: unless the compiler must run under tight resource requirements, in which case writing it in anything but something like C would be silly anyway. if you have such requirements, you know already
18:32:53 <blackh> Starscream: Haskell is an excellent language to write a compiler in, and Haskell (as compiled by GHC) is very fast, and comparable with other high-level languages in terms of memory usage.  Phew.
18:33:24 <Philippa> blackh: "comparable with other high-level languages" is potentially misleading if you haven't fully understood laziness, but yes. 
18:33:31 <djahandarie> Starscream, if you say nothing, we'll just keep on talking and confuse you more ;)
18:33:40 <Philippa> Starscream: we're picky about the details, but learn haskell and have a crack
18:33:45 <jmcarthur> *better* than other high-level languages is more like it :)
18:33:45 <Starscream> Well, it doesn't matter too much, I'm planning on using haskell as the bootstrapping language
18:33:46 <blackh> Philippa: Laziness is totally irrelevant!
18:33:56 <jmcarthur> blackh: ?
18:34:05 <djahandarie> Ultimate #haskell trolling strategy: Silence.
18:34:16 <Starscream> So, I guess even if it was a memory hog, it wouldn't matter for long anyway
18:34:28 <Starscream> The language itself seems great for defining a compiler
18:34:30 <jmcarthur> laziness is very important for compositions and often misunderstood by beginners. it's certainly relevant
18:34:37 <jmcarthur> *composition
18:34:52 <Philippa> right, and sometimes the 'obvious' composition is less rather than more memory efficient
18:35:09 <jmcarthur> 'obvious' to some beginners, that is
18:35:29 <Philippa> Starfire: yeah, so run with it. Do you have other languages on your list of possible languages to use, and if so would you like a comparison?
18:35:46 <djahandarie> 7.2.1 already, lol
18:36:28 <Philippa> jmcarthur: or even obvious to experienced coders who just mostly haven't cared about that particular kind of issue before. Sometimes just bashing the don't-care-about-resources semantics down will get you daft behaviour
18:36:29 <blackh> jmcarthur: The mechanisms of memory management (in GHC's case, laziness) is not relevant to the degree of memory efficiency of the language.
18:41:08 <Philippa> blackh: if we're being nitpicky, there is no "memory efficiency of the language", just the efficiency of particular programs as interpreted by particular implementations and the constraints the language puts on the latter. But without learning a range of strategies that are completely different from non-lazy languages, the risk of writing inefficient code can be high
18:42:04 <Pseudonym> There is big-oh memory efficiency, as in this program must take O(f(n)) memory on any fully-lazy implementation.
18:42:16 <Pseudonym> Not that Haskell implementations are required to be fully-lazy.
18:42:57 <blackh> Philippa: So, in other words, "if you define memory efficiency rigorously, the concept ceases to be meaningful", and "it is possible to write buggy code in Haskell."
18:42:59 <Philippa> Starscream: yeah, haskell's an excellent bootstrapping language given that a bootstrapping compiler doesn't have to be particularly "good"
18:43:17 <Philippa> blackh: no
18:44:00 <blackh> I don't disagree with you. :)
18:44:16 <Philippa> (and really, anyone using the latter characterisation can head off back to other languages: we're supposed to know /better/ here than leaving it at "it's possible to screw up")
18:45:51 <Philippa> Starscream: the local culture here's comparatively picky in a good way, just note that there were some potential concerns you didn't understand for later reference and come back and ask if you think you're running into them :-) Your use case sounds like a good one for Haskell
18:48:44 <Berengal> #haskell is the ultimate Haskell reference, with lazy semantics but speculative evaluation
18:49:01 <Philippa> heh
18:49:03 <ddarius> Big-oh, not to be confused with big-o' as in, this program takes a big o' pile of memory.
18:54:12 <tswett> > (reads "0x", reads "0x0") :: ([Integer], [Integer])
18:54:13 <lambdabot>   Couldn't match expected type `GHC.Integer.Internals.Integer'
18:54:13 <lambdabot>         agains...
18:54:35 <tswett> My attempt at not spamming the channel by using the bot twice failed.  :P
18:54:43 <tswett> @type reads
18:54:44 <lambdabot> forall a. (Read a) => String -> [(a, String)]
18:54:53 <sina> @src isNothing
18:54:53 <lambdabot> isNothing Nothing = True
18:54:53 <lambdabot> isNothing _       = False
18:55:04 <sshc> How do I pass expressions to ghc?
18:55:08 <tswett> > (reads "0x", reads "0x0") :: ([(Integer, String)], [(Integer, String)])
18:55:08 <lambdabot>   ([(0,"x")],[(0,"")])
18:55:12 <ddarius> sshc: ghc -e ?
18:55:17 <sshc> With modules?
18:55:27 <sshc> I'm trying to figure out whether hGetLine includes the newline character or not
18:55:33 * sshc tries ghc -e "import Data.ByteString; import System.IO; main = print =<< hGetLine stdin"
18:55:40 <aavogt>  -e ":module System" -e ".."
18:56:01 <tswett> sshc: it sounds a bit like you're trying to use ghc as ghci.
18:56:03 <dmwit> sshc: I've written a file Dmwit.hs that loads a bunch of modules and defines a few handy functions.
18:56:12 <dmwit> shachaf: So for me, it's ghc Dmwit.hs -e "..."
18:56:25 <dmwit> Sorry, shachaf, I meant sshc.
18:57:43 <sshc> aavogt: Thanks, that's exactly what I was looking for
18:57:50 <sshc> dmwit: That's also a gook idea
18:58:13 <sshc> tswett: ghci accepts -e?
18:58:25 <sshc> .i ji'a coi
19:00:32 <Rotaerk> lojban?
19:00:45 <sshc> lojban!
19:07:48 <Starscream> Phillipa: My irc client stop scrolling so I wasn't aware you replied. Thanks for the help though. My other choices for language were C, C++ (though not a preferred choice), or a high-level interpreted language (python,ruby,lua,scheme... etc)
19:08:02 <Starscream> It seems though that for my purposes haskell would suffice
19:08:36 <ddarius> For writing a compiler out of those choices I would definitely choose Haskell.  After that would be Scheme.  After that C++.
19:09:14 <tswett> sshc: is #lojban where I recognize you from?
19:09:18 <Philippa> I'm in two minds about C++ vs ruby myself
19:09:24 <sshc> go'i
19:09:31 <tswett> coi
19:09:39 <Starscream> Phillipa: Well, they are two very different languages.
19:09:41 <ddarius> Philippa: The answer is C++.  Cognitive dissonance resolved.
19:09:54 <tswett> sipna co'o
19:09:59 <sshc> co'o sipna
19:10:08 <sshc> mi ji'a bazi sipna
19:10:35 <Philippa> Starscream: yep, and to be fair I last used C++ before Boost was as big/popular as it is now. It's a choice of which engineering considerations to place highest, anyway: typing vs ease of abstraction
19:10:40 <dmwit> Yikes, do we need a #haskell.loj now? ;-)
19:10:45 <blackh> Starscream: Dynamic typing like they've got in Python, Ruby, etc can count against you in a compiler-type problem.
19:10:54 <tswett> #haskell.jbo, you mean.  That's its IPA code.  :P
19:11:12 <ddarius> There probably is one.
19:11:13 <Starscream> blackh: Can you elaborate that?
19:11:21 <ddarius> There are more than a few Lojban speakers in the Haskell community.
19:11:37 <sshc> Why not #haskell-jbo?
19:12:33 <Philippa> Starscream: a good type system can catch a /lot/ of ways to fuck up in a compiler, and some of them are really easy to do by accident
19:12:40 <blackh> Starscream: The thing is, if you haven't used Haskell, you don't really know how good static typing can be.  For a problem like a compiler, it makes it really hard to make mistakes and the types drive the whole process. With dynamic typing, not only is that help not there, but it is replaced by a constant risk of runtime errors (i.e. lots and lots of debugging / unit testing).
19:12:51 <Philippa> once you've screwed up, debugging can be a real PITA unless you've got some good tests
19:13:06 <ddarius> Where "good tests" == "typed intermediate language"
19:13:17 <Philippa> (and that's once you've found out you have a problem!)
19:13:32 <Philippa> I'd say => rather than ==
19:13:46 <blackh> Starscream: Haskell is all about static typing, but it goes much further than just catching errors.
19:13:54 <Philippa> I mean, it only helps you so much when you find your desugarer spits out type-correct but semantically wrong code for something
19:14:00 <ddarius> It's catches baseballs and diseases too!
19:15:05 <blackh> Starscream: So, in Haskell the types drive the design, to the extent that the compiler even debugs your thinking.
19:15:07 * ddarius notes a distinct lack of seriousness in ddarius's messages for the past eight years or so.
19:15:58 * djahandarie notes the usage of third-person.
19:16:23 * augustss notes signs of insanity
19:16:55 * Starscream notes the noting.
19:17:05 <Philippa> ddarius: FWIW, I think my #1 reason for using something like Scheme would be that increasingly I favour lots of lightweight transformations between lots of closely related languages (if we can fuse 'em, so much the better, but I don't want to be writing the fused version by hand with no unfused point of reference)
19:17:18 * Philippa builds an infinite tower of metanotes
19:18:39 <Starscream> So, you are saying, if I write the compiler in Haskell, debugging the compiler will be simpler/easier?
19:19:20 <ddarius> It will be simpler and easier because you will have less bugs to debug.
19:19:31 <blackh> Starscream: Yes. But not only that... writing the compiler will be easier, and what happens is this...
19:19:59 <Philippa> ddarius: the reason that matters is that haskell's not good at relating all those AST types :-(
19:20:12 <blackh> you fight the GHC compiler and go crazy... the compiler says "what are you doing here??" and you have to think about it... then you run your program...
19:20:36 <blackh> and fall over in surprise because it works.  You were not necessarily aware of it at first, but you've already done your debugging.
19:20:59 <blackh> You get used to it very quickly.
19:21:06 <dmwit> Man, am I the only person who has a different experience?
19:21:08 <Saizan> Philippa: scheme is?
19:21:18 <dmwit> I finally get the compiler to agree that what I wrote makes sense, run it...
19:21:19 <blackh> dmwit: What's your experience?
19:21:30 <dmwit> ...and then the bugs are ten times more subtle than they were when I was coding in any other language.
19:21:47 <ddarius> Just do what the TDD folk say.  Compile a blank file and then fix the type errors.  TDD meaning "Type Driven Development" of course.
19:22:00 <Saizan> Philippa: or better, how does scheme solve/is better at it? (i've no experience with scheme)
19:22:04 <blackh> Starscream: Opinions differ, obviously. :)
19:22:20 <Philippa> Saizan: scheme lets you pun, and you can have isomorphisms that work implicitly rather than explicitly, because you can do the equivalent of having the same data constructor belong to multiple types
19:22:33 <ddarius> dmwit: Yes, Haskell isn't nearly as rewarding as other languages.  In other languages you get to fix all kinds of bugs before you even notice the subtle ones.
19:22:51 <dmwit> Perhaps that's so. =)
19:23:34 <blackh> dmwit, Starscream: My take on laziness is this: Most of the features of Haskell give you a huge gain with very little cost.  Laziness, on the other hand, gives you a significant gain with a significant cost.
19:23:38 <jmcarthur> ddarius: "Haskell isn't nearly as rewarding as other languages."  <-- Completely true, except when you are using other languages.
19:24:10 <jmcarthur> i disagree. i think the cost of laziness is pretty tiny. it's only significant when you are still learning how to work with it
19:24:11 <blackh> On balance is it worth it? I can't decide either way.  But now that I have got over the "laziness learning curve" it isn't a problem in practice.
19:24:42 <blackh> The cost of laziness is in the learning curve, in my opinion, but it is a fairly significant cost.
19:25:10 <jmcarthur> i put learning curve pretty low on my list of priorities when deciding whether a language is worth it
19:26:03 <jmcarthur> and honestly, people who go through their entire programmer careers without even *knowing* what it's like to use a non-strict language are really missing out on a lot of things
19:26:23 <blackh> Don't get me wrong - I would take the problems with Haskell's laziness x 10 before I would take dynamic typing.
19:26:44 <jmcarthur> dynamic typing beats typeless :)
19:26:53 <dmwit> Sometimes laziness is just what the doctor ordered.
19:27:07 <blackh> Laziness has benefits, too - I just think that it doesn't come without a cost.
19:27:13 <dmwit> Even in strict languages, it can sometimes be nicer to fake laziness than to hack the strict solution together.
19:27:27 <jmcarthur> i only experienced problems with laziness for, say, the first six months of using haskell
19:27:34 <jmcarthur> and even then, it was only rarely
19:28:12 <Philippa> dmwit: or just plain semantically necessary to encode it somehow, like when you're manipulating infinite structures
19:28:41 <blackh> It took me a little longer, I think, but I don't get any space leaks now that I can't fix easily.  The reason why that's true is that I treat the level of strictness as a design issue.
19:28:49 <jmcarthur> Philippa: of course those without the experience of using a lazy language don't even necessarily realize they are working with infinite structures
19:28:56 <Philippa> jmcarthur: not everyone has the same learning curve - maybe this is a symptom of when I started learning and what my domains of choice have been, but I don't think I've really learned adequately how to handle it even though I can reason through eg list processing situations
19:29:54 <blackh> Essentially, you can get reasonably far without dealing with space leak issues, but ultimately, you can't get away without understanding them (hence the learning curve).
19:30:03 <jmcarthur> blackh: the interplay between strictness and non-strictness is semantically meaningful. i don't think i could classify the difficulty with using it effectively as a design flaw.
19:30:22 <jmcarthur> blackh: indeed
19:30:52 <Philippa> jmcarthur: to the extent I can, it's almost inherent in turing-complete languages with algebraic datatypes - there's no algebra/coalgebra separation
19:31:15 <jmcarthur> Philippa: point
19:31:20 <blackh> I classify space leaks as the worst thing about Haskell.  But like someone said, it's like saying Marilyn Monroe has bad toenails.
19:31:28 <jmcarthur> blackh: lol
19:31:37 <jmcarthur> @quote Marilyn
19:31:37 <lambdabot> No quotes match. Maybe you made a typo?
19:31:42 <jmcarthur> aw man
19:31:55 <blackh> I think it was blackdog.
19:32:17 <Philippa> (for those who aren't aware: in CPO, and thus in any turing complete functional language that doesn't try /really hard/ to avoid it, algebras and coalgebras are isomorphic)
19:34:11 <Boxo> @unpl liftM join . join . liftM sequence
19:34:11 <lambdabot> (\ c -> liftM (\ e -> e >>= \ d -> d) ((liftM sequence c) >>= \ i -> i))
19:36:40 <copumpkin> :t liftM join . join . liftM sequence
19:36:41 <lambdabot> forall a (m :: * -> *). (Monad m) => m [m [a]] -> m [a]
19:36:51 <copumpkin> oh my
19:37:39 <Boxo> that's join for (ListT m), just without the newtype boilerplate :)
19:38:20 <lars9> are let/where just syntax sugar, or have some syntax meaning?
19:38:31 <jmcarthur> that's a pretty standard-looking definition of join for composed monads, actually
19:38:47 <jmcarthur> lars9: they are semantically meaningful
19:38:55 <jmcarthur> lars9: at least in ghc
19:39:20 <lars9> jmcarthur: is there any doc about it?
19:39:40 <jmcarthur> lars9: if you bind a value with let or where it will only have to be evaluated at most once
19:39:56 * Boxo dislikes the boilerplate so much he writes the functions and their boilerplated versions separately
19:40:03 <jmcarthur> lars9: whereas if you were to inline the definition, each occurrence of the expression would have to be evaluated separately
19:40:22 <jmcarthur> lars9: i'm sure the spec documents it decently
19:42:08 <lars9> jmcarthur: lets say f x = let g = ... in ...; so the meaning is when g is evaluated once when evaluating f every time.
19:42:13 <lars9> not all times
19:42:21 <lars9> right?
19:43:29 <jmcarthur> lars9: no
19:43:33 <jmcarthur> lars9: here's an example:
19:44:00 <jmcarthur> > let x = 5 * 5 in x * x  -- lars9: 5*5 is only computed once
19:44:01 <lambdabot>   625
19:44:57 <Boxo> :t \join -> ListT . join . (liftM.map) runListT . runListT
19:44:57 <lambdabot> Not in scope: data constructor `ListT'
19:44:57 <lambdabot> Not in scope: `runListT'
19:44:57 <lambdabot> Not in scope: `runListT'
19:44:59 <Saizan_> when we say "once" here, it's relative to the life of the scope where the variable is defined
19:45:23 <lars9> what if f y = let x = 5*5 in x*y, and f is evaluated many times? such as map f [1..100]
19:45:25 <jmcarthur> lars9: it happens to be the case that ghc might might make that only evaluate once across *all* function calls, as you guessed, but that's merely an optimization (ghc will sometimes lift things to the top level so they can be shared for the entire run of the program). that is not always the case, and in fact a let bound expression can sometimes depend on a variable
19:45:45 <Saizan_> lars9: then 5*5 will be evaluated many times
19:46:01 <jmcarthur> lars9: it's *likely* that ghc will cause that 5*5 to be shared across all uses of the function, but that's not what i'm talking about
19:46:25 <jmcarthur> lars9: if x depended on y, for example, it couldn't do that optimization
19:46:39 <jmcarthur> e.g.   f y = let x = y*y in x*y
19:46:41 <Cale> lars9: Without optimisations, a plain lazy evaluator will re-evaluate that x every time
19:46:55 <lars9> according to my test, f y = let x = 5*5 in x*y, x will be evaluated many times, but for f = let x = 5*5 in x*, x is evaluated only once.
19:47:13 <Cale> lars9: right
19:47:21 <jmcarthur> lars9: yeah, because the latter is not a function, so it can be shared
19:47:24 <lars9> Cale: so that's just an optimization?
19:47:25 <Cale> Or: f = let x = 5*5 in \y -> x*y
19:47:39 <Cale> (which is equivalent)
19:47:50 <Cale> See, f is a constant
19:48:00 <Cale> and so it'll only be evaluated once
19:48:11 <jmcarthur> yeah that's probably not something worth explaining right now ;)
19:48:18 <Cale> It evaluates to a functions
19:48:20 <Cale> -s
19:48:29 <lars9> so the point is, a value is evaluated only once?
19:48:29 <jmcarthur> the difference between  f y = ...  and  f = \y -> ...
19:48:47 <jmcarthur> lars9: values are indeed only evaluated once
19:48:48 <Cale> Yeah, that's the main difference between lazy evaluation and plain outermost-first evaluation
19:49:13 <Cale> With lazy evaluation, any variable will be evaluated at most once.
19:49:14 <jmcarthur> lars9: let allows you to *use* a value more than once without reevaluating it
19:49:40 <Cale> Oh, I'm not talking about the difference between f y = ... and f = \y -> ...
19:49:52 <lars9> i see, so that's the point, ghc makes an optimization which make sure a value is evaluated only once, because values are constant in haskell, do i get it?
19:50:04 <jmcarthur> lars9: no
19:50:07 <Cale> lars9: All lazy evaluators do.
19:50:10 <jmcarthur> lars9: this has nothing to do with optimizations
19:50:21 <Cale> Well, it's sort of an optimisation that you get all the time.
19:50:31 <Cale> It's built into the way that GHC evaluates things in the first place
19:50:41 <jmcarthur> it's an evaluation strategy
19:51:19 <Cale> (Which is basically to start them out as representations of expressions, and mutate those into representations of the final values once they're evaluated.)
19:51:21 <lars9> jmcarthur: by an eval strategy you mean: a value is evaluated only once, ?
19:51:25 <jmcarthur> lars9: i just want to make clear that it's not magic and you aren't just relying on GHC's intelligence
19:51:49 <Cale> Let's do the double (double 5) example!
19:51:49 <jmcarthur> (it's not uncommon to rely on GHC's intelligence, but this is not one of those cases)
19:51:53 <jmcarthur> oh boy!
19:51:59 <Cale> :)
19:52:10 <Cale> So imagine we have the following definition:
19:52:10 <jmcarthur> lars9: pay attention to Cale. this is a well exercised example :)
19:52:15 <Cale> double x = x + x
19:52:24 <Cale> and we want to evaluate  double (double 5)
19:52:50 <Cale> Using a strict (innermost-first) evaluator, it goes like this:
19:52:53 <Cale> double (double 5)
19:52:56 <Cale> -> double (5 + 5)
19:52:58 <Cale> -> double 10
19:53:02 <Cale> -> 10 + 10
19:53:03 <Cale> -> 20
19:53:38 <Cale> Good? That should be the way that you're used to thinking of function evaluation from strict programming languages.
19:53:45 <lars9> yea
19:54:01 <jmcarthur> e.g. call-by-value
19:54:21 <Cale> okay, but that's not the only way we could do things
19:54:21 <Cale> We could also have expanded the outermost double first.
19:54:23 <Cale> (I can never understand the rationale behind the call-by-X names, so I don't use them)
19:54:25 <jmcarthur> err... i.e.
19:54:39 <lars9> Cale: me neither
19:54:45 <Cale> So, under outermost-first evaluation, we get this:
19:54:48 <Cale> double (double 5)
19:54:55 <Cale> -> (double 5) + (double 5)
19:55:02 <Cale> -> (5 + 5) + (double 5)
19:55:07 <Cale> -> 10 + (double 5)
19:55:11 <Cale> -> 10 + (5 + 5)
19:55:14 <Cale> -> 10 + 10
19:55:16 <Cale> -> 20
19:55:18 <jmcarthur> i'll explain that rationale after you're done so as not to clutter your example
19:55:38 <Cale> Here, we're reducing the outermost function application which can pattern match successfully.
19:56:01 <Cale> (In the case of +, we're taking this to mean that both arguments are fully evaluated)
19:56:02 <lars9> yeah
19:56:15 <Cale> But this is clearly not efficient, because we evaluated double 5 twice.
19:56:34 <Cale> and the reason we did that was that the parameter x to double is duplicated in the body of double
19:56:37 <Cale> double x = x + x
19:57:18 <Cale> So, lazy evaluation adds the optimisation that any parameter to a function (or any bound variable at all) is evaluated at most once (as long as it remains in scope)
19:57:44 <Cale> and the results of evaluating it are shared between any copies
19:58:03 <Cale> If you'll allow me to use the let/in syntax to represent the sharing, here's how it'll look:
19:58:09 <Cale> double (double 5)
19:58:21 <Cale> -> let x = double 5 in x + x -- note that this is still outermost-first
19:58:28 <Cale> -> let x = 5 + 5 in x + x
19:58:32 <Cale> -> let x = 10 in x + x
19:58:42 <Cale> -> 10 + 10
19:58:44 <Cale> -> 20
19:59:02 <Cale> (that second last step may or may not correspond to any real operation)
19:59:37 <jmcarthur> usually not
19:59:42 <Cale> yeah
20:00:22 <Cale> Innermost-first evaluation evaluates every function parameter exactly once. Outermost first evaluation evaluates function parameters zero or more times. Lazy evaluation evaluates each parameter 0 or 1 times.
20:00:38 <Cale> (and so is the best of both worlds when looked at in that way)
20:01:55 <Cale> and that's pretty much all there is to it :)
20:02:05 <lars9> i see,
20:02:06 <jmcarthur> in what sense is call-by-value "innermost-first"? is it when you think of arguments as being surrounded by parentheses? i find the call-by-* terminology more intuitive, myself :)
20:02:32 <Cale> jmcarthur: I think of my evaluator as replacing expressions with other expressions.
20:02:55 <ddarius> jmcarthur: Parentheses justs syntactically reflect the nesting in the AST.
20:02:59 <Cale> innermost-first evaluators will find the innermost (leftmost) reducible subexpression, and replace that first
20:03:17 <Cale> That is, the deepest one in the expression tree/graph
20:03:37 <sina> In a recursion, having (h:t) and (h:[ ]) will not be enough to catch all the conditions? it is saying pattern match failure
20:03:48 <Cale> sina: You missed the empty list case
20:03:59 <lars9> so in this case: f = let x=5*5 in x+; print map f [100]; because f is evaluated only once, x is evaluated only once?
20:04:01 <jmcarthur> Cale: i interpret that wording as reducing under lambdas
20:04:05 <Cale> h:t is a list of length at least one, h:[] is a list of length exactly one
20:04:13 <Cale> but you're missing the list of length 0
20:04:31 <Cale> jmcarthur: Oh, none of these necessarily reduce under lambdas
20:04:41 <sina> Cale: right. was not expecting it... I haven't slept for 2 days... making stupid mistakes :|
20:04:46 <Cale> jmcarthur: (and in practice, that's extremely uncommon)
20:05:07 <Cale> lars9: Modulo the syntax error, yes.
20:05:12 <ddarius> sina: Your time might more productively be used sleeping then.
20:05:26 <jmcarthur> Cale: i know. i'm currently researching various forms of laziness :)
20:05:45 <jmcarthur> okay, now i'll explain the call-by-* terminology
20:05:56 <sina> ddarius: have an assignment to hand in in few hours
20:06:03 <Cale> In particular, call by name makes no sense to me.
20:06:13 <Cale> What do names have to do with anything?
20:06:15 <ddarius> sina: I stand by my statement.
20:06:41 <jmcarthur> call-by-value implies that the function is applied to "values," pretty simple.
20:06:55 <Cale> Yes, I suppose that one isn't so bad.
20:07:08 <lars9> Cale: is there any semantic diff with: f y = let x=5*5 in x+y; print $ map f [0..100]? is f evaluated only once here?
20:07:14 <Cale> Though I still dislike 'call' :P
20:07:23 <Cale> apply-to-value :P
20:07:27 <jmcarthur> i'm pretty sure that call-by-name is actually an artifact stemming from the fact that people originally thought of it as textual substitution
20:07:56 <Cale> lars9: f is evaluated only once, but it evaluates to \y -> let x = 5*5 in x + y
20:08:10 * ddarius always prefers names that are artifacts to names that carry some semantic weight.
20:08:13 <Cale> lars9: and that is as far as evaluation goes. Lambdas are considered to be completely evaluated.
20:08:28 <jmcarthur> and call-by-need also has fairly obvious connotations, i think.
20:08:42 <Cale> lars9: So, each time that lambda is applied to a different value y, the x will need to be evaluated again
20:08:45 <jmcarthur> Cale: i'm with you that "call-by" kinda sucks. apply-to would be nicer
20:09:15 <Cale> apply-to-value, apply-to-expression, apply-to-expression-with-sharing
20:09:40 <copumpkin>   mapAllSubexpressions = error "urk!" (mapVars, (/@/), makeTotal, ifNew)
20:09:50 <copumpkin> never seen the result of error x being applied before!
20:10:14 <jmcarthur> to tread into lesser known territory, Michael Thyer's thesis Lazy Specialization coins some terms for an orthogonal axis of laziness that is less often considered
20:10:22 <ddarius> Application is strict in its first argument.
20:10:36 <jmcarthur> usually we only consider how arguments are treated
20:10:39 <Cale> jmcarthur: Note that plain outermost first evaluation also only demands the evaluation of the parameters if they're needed, so it could also rightly be called call by need.
20:10:50 <lars9> Cale: you mean there is a difference between let x = 5*5 in x+ from \y -> let x = 5*5 in x+y? the former one is 'more evaluated' than latter one?
20:10:52 <jmcarthur> Cale: indeed
20:11:03 <Cale> (In fact, it evaluates them each time they are needed :)
20:11:09 <jmcarthur> also to consider is how we treat the functions
20:11:31 <Cale> lars9: You really need parens around your x+ there
20:11:37 <Cale> But there is a difference.
20:11:45 <Cale> It's not that one is more evaluated than the other
20:11:52 <Cale> Neither one will reduce to the other
20:12:06 <jmcarthur> Thyer calls the terms for these strategies substitute-by-*. call-by-* has to do with how arguments are treated, and substitute-by-* has to do with how functions are treated
20:12:39 <jmcarthur> most languages are substitute-by-name: they copy the function body without any reductions
20:12:49 <jmcarthur> *reductions under the lambda, that is
20:13:17 <lars9> so what things is "let x = 5*5 in (x+)"? we can call "\y -> let x = 5*5 in x + y" a lambda
20:13:19 <Cale> What is the "name" the name of?
20:13:22 <jmcarthur> there's also substitute-by-value, where you reduce the function to some value form first (hnf, nf, etc.)
20:13:45 <jmcarthur> Cale: (yeah, i know. maybe we could try to start some better terminology here)
20:13:49 <Cale> lars9: Well, it's a let expression which happens to define a function.
20:14:20 <Cale> Are we assuming that functions are never anonymous or something?
20:14:31 <jmcarthur> finally, there's substitute-by-need, where you lazily reduce parts of the function as needed in the application, sharing those reductions with other uses of the function
20:14:35 <Cale> It seems weird except in the absence of lambda
20:14:51 <zachk> how do i generate a fibaonacci sequence using scanl ? i think i saw it posted in here yesterday 
20:15:19 <Cale> > fix (0 : scanl (+) 1)
20:15:20 <lambdabot>   Couldn't match expected type `[t]'
20:15:20 <lambdabot>         against inferred type `[a] -> [a]'
20:15:25 <Cale> > fix ((0 :) . scanl (+) 1)
20:15:26 <lambdabot>   [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946...
20:15:45 <zachk> uh whats fix do, do i have to use it? 
20:15:53 <Cale> > let fibs = 0 : scanl (+) 1 fibs in fibs
20:15:54 <lambdabot>   [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946...
20:16:02 <jmcarthur> Cale: like i said, i'm pretty sure "name" is just an artifact. the idea back in the day was that it was textual substitution. of course, we know better. in the case of substitute-by-name, i mean that the function *definition* is copied
20:16:02 <Cale> fix f = x where x = f x
20:16:27 <Cale> jmcarthur: But even if it's textual substitution, calling a whole expression graph a "name" is a little weird.
20:16:30 <Philippa> right, name ~= term
20:16:32 <jmcarthur> Cale: for example, when you expand (double x) to (x * x)
20:16:34 <jmcarthur> Cale: i agree
20:16:48 <ddarius> I'm pretty sure the "call-by-name" terminology came out of Algol 60.
20:16:52 <lars9> Cale: so is let "expression" a haskell term?
20:16:59 <jmcarthur> ddarius: that's what i was thinking, but i wasn't sure
20:17:00 <Cale> ddarius: Did Algol 60 have lambda?
20:17:27 <zachk> call by name makes more sense to me when you have a global mutable name space 
20:17:28 <Philippa> lars9: yeah, haskell uses 'expression' where lambda calculi often use 'term' for what it's worth
20:17:29 <jmcarthur> Cale: the purpose in algol was just to have the ability to define things like if
20:17:44 <jmcarthur> Cale: *imperative* if
20:17:51 <Cale> lars9: Well, yes. let <decls> in <expr> is an expression form, and any expression of that form is called a let expression
20:18:32 <jmcarthur> anyway, ghc is call-by-need, substitute-by-name
20:18:35 <Cale> lars9: Similarly, we have case-expressions and if-expressions, and so on.
20:18:56 <jmcarthur> languages that are substitute-by-value often have some form of eager function specialization
20:19:23 <jmcarthur> a language that is call-by-need and substitute-by-need is called completely lazy
20:19:50 <Philippa> jmcarthur: any interesting proofs about space usage in a completely lazy language?
20:20:07 <jmcarthur> Philippa: space usage goes up considerably in a lot of practical programs
20:20:37 <jmcarthur> Philippa: but i don't know of any proofs
20:20:44 <jmcarthur> it's not very deeply explored, sadly
20:21:14 <jmcarthur> it's been proven not to be the same as optimal evaluation by example
20:21:19 <lars9> Cale: so "f = let x=5*5 in (x+)" defines a let expression, and when evaluated, it's evaluated to a function?
20:21:23 * zachk thinks it could be very compiler/interpreter/implmentation dependent 
20:21:53 <Cale> Yeah, it defines the function f to be that let expression.
20:22:27 <jmcarthur> Philippa, zachk: here's an implementation to play around with http://thyer.name/lambda-animator/
20:22:35 <Cale> So, I dunno... we could evaluate something using that to see how it works...
20:22:40 <zachk> lars9: but you cant print or show a function in haskell, you cant even compare them 
20:22:49 <jmcarthur> set to call-by-need and substitute-by-need to get completely lazy evaluation
20:24:56 <zachk> > let x = 5*5 in (x+) 5
20:24:57 <lambdabot>   30
20:25:20 <Cale> > (let x = 5*5 in (x+)) 5
20:25:20 <lambdabot>   30
20:25:38 <zachk> !_!
20:25:39 <Cale> > let x = 5*5 in ((x+) 5)
20:25:40 <lambdabot>   30
20:26:02 <FauxFaux> @pl let x = 5*5 in (x+) 5
20:26:02 <lambdabot> 30
20:26:04 <jmcarthur> Philippa: probably the cleanest explanation is Sinot's paper A Natural Semantics for Completely Lazy Evaluation (i think i got the paper's name right)
20:26:07 <FauxFaux> Oh. ¬_¬
20:26:22 <FauxFaux> @pl let x = a*a in (x+) a
20:26:23 <lambdabot> a * a + a
20:26:35 <lars9> Cale: that would require x in "f = let x=5*5 in (x+)" to be evaluated when f is evaluated?
20:26:47 <jmcarthur> Philippa: Thyer's thesis has a completely different kind of explanation though, and it's the only place that i've seen that explanation about substitute-by-need
20:27:33 <Philippa> jmcarthur: thanks. Probably don't have time to paper-chase at the mo, but I'll try to at least remember the terms to google later :-) Are we still logging #haskell to the web? If so I'll get back to your paper recommendations :-)
20:27:41 <Cale> lars9: Well, it actually happens only after f is applied to a parameter and that's evaluated, demanded by (+), but sharing ensures that every "copy" of f is really the same f and the reduction of x will apply to all of them.
20:27:46 <jmcarthur> yeah it's still logged
20:27:56 * Philippa watches her mouth freeze in place and walks around everywhere with a goofy smile
20:28:03 <Philippa> cool
20:28:30 <Cale> lars9: Because, thinking really operationally now, every f is a pointer to the same expression in memory (or if you prefer, an arc to the same vertex in a graph)
20:29:28 <Cale> lars9: and that expression (the subgraph below that vertex) will contain the definition of x, which will be evaluated at most once
20:30:10 <lars9> Cale: kind of be able to connect everything now
20:30:28 <zachk> lars9: i believe the key thing in haskell is "referential transparency" it doesn't matter how your "pure" code is evaluated because there is no side effects so you always get the same answer whether its inner or outer 
20:30:47 <zachk> the only really non pure things are of type IO a 
20:31:07 <Cale> zachk: Right, I think lars9 knows this, but has been interested in efficiency and memoisation behaviour.
20:31:11 <zachk> ahhh
20:31:18 <zachk> i still dont grok memoization in haskell 
20:31:28 <lars9> zachk: the key is the difference between lambda and let expression
20:31:39 <zachk> lars9: memoization in haskell will kill your memory 
20:31:56 <Cale> zachk: Not necessarily.
20:32:11 <Cale> Of course memoisation in any language can kill your memory if you do too much of it :)
20:32:25 <Philippa> out of interest, has anyone figured out a reasonable way to carry around a memoised 'cache' and flush it in pure code?
20:32:26 <zachk> ive easily chewed gigs and then crashed using simple functions that are memoizaed 
20:32:32 <Cale> It's explicitly about making a space/time tradeoff in the first place of course.
20:32:34 <Philippa> (forget how you decide /when/ to flush for now)
20:32:42 <Cale> zachk: But how are you memoising them?
20:32:53 <zachk> i was using scanl mostly 
20:32:58 <zachk> couldnt wrap my head around the other stuff 
20:33:06 <Cale> zachk: So, just using a big list?
20:33:13 <zachk> yeap 
20:33:32 <Cale> So long as you process that list once in a pipeline fashion, and the early elements can be GC'ed, you'll be fine.
20:33:54 <Cale> But if you keep it around and index into it randomly, that's not a good plan.
20:34:14 * zachk did that and ate gigs || 8 gigs 
20:34:18 <Cale> (unless you know that there's some reasonable upper limit on how far you'll index into the infinite? list)
20:35:01 <Cale> A better approach might be to use a fixed-size array to memoise your function on small values, and use those to recompute larger values as necessary (assuming that your function is recursive)
20:35:43 <zachk> if you have an upper bound memoizations eating of memory can easily be controlled 
20:35:44 <Cale> Especially since as the size of the number increases, the likelihood of your needing that result again usually falls.
20:36:35 <lars9> is lambda == function?
20:36:50 <zachk> i believe so 
20:36:54 <ddarius> Cale: Algol 60 had (limited?) higher order functions.  I'm pretty sure it did not have an anonymous procedure form though.  See 4.7 and 5.4 in http://www.masswerk.at/algol60/report.htm
20:36:58 <Philippa> a lambda is one way of writing a function, yes
20:37:16 <Philippa> all lambda expressions are functions, not all functions are lambda expressions
20:37:17 <zachk> a function is just a named lambda imho 
20:37:42 <Philippa> zachk: that depends on your language, many have recursive let as a primitive rather than a built-in fixpoint operator
20:39:37 <Cale> zachk: A lambda expression counts as a function
20:39:38 <Cale> (value)
20:39:52 <Cale> zachk: but so do other types of expressions which have function values
20:40:20 <Cale> such as  let x = 5*5 in (+) x
20:40:34 <Cale> which isn't a lambda, but is still a function
20:41:11 <Cale> ddarius: Thanks for the reference
20:41:31 <sina> can a where clause have a where clause?
20:41:45 <Cale> definitions inside a where clause can have their own where clauses
20:41:49 <ddarius> sina: The values defined in a where clause can themselves have where clauses.
20:42:11 <sina> it can be done by indenting the second where?
20:42:37 <Cale> Yeah, the 'where' keyword should start in a later column than the start of the thing being defined
20:43:09 <Cale> and the contents of the 'where' should generally start in a later column than the 'where' itself, and should all line up.
20:43:22 <Cale> foo x = y
20:43:30 <Cale>   where y = z + z
20:43:40 <Cale>           where z = x^2
20:44:16 <Cale> There are some other variations on that layout, where you put a line break after each 'where'
20:44:40 <sina> ok
20:44:49 <Cale> (which can help keep the indentation low if you have long lines)
20:45:20 <Cale> Note that you can also often collapse the where clauses together.
20:45:37 <Cale> (unless things defined inside the nested one depend on a function parameter)
20:45:50 <Cale> It can change the space behaviour of the program to do that though.
20:46:01 <Cale> (as we've been discussing with lars9 :)
20:46:15 <sina> Cale, that will get confusing I guess :D
20:47:08 * ddarius has used thrice nested wheres upon many an occasion.
20:48:06 <sina> I think usually there can be better alternatives to nested wheres. like right now, I changed the code to have just one where
20:48:23 <Philippa> I think nested is better than flat a lot of the time
20:48:36 <Philippa> the scope delineation's a useful shorthand for the reader
20:48:52 <Philippa> (if you need to hoist it up for refactoring purposes, that's significant!)
20:49:28 <ddarius> My alpaca, cashmere, silk yarn is way more luxurious than some similar looking cheap acrylic yarn which is also reasonably pleasant.
20:49:34 <sina> Is it possible to have guards inside guards?
20:50:11 <Philippa> probably
20:50:27 <Philippa> the question's at what level of nesting, and which variety of guards
20:50:37 <Philippa> (I'm guessing it's fairly trivial with pattern guards)
20:50:48 <ddarius> Guards take expressions.  Expressions can contain definitions which can contain guards.
20:51:10 <sina> I got this error: Syntax error in declaration (unexpected `|')
20:51:55 <sina> and that happened after I had | condition (now next line, indented) | (condition2) = ... (next line, same indentation) | otherwise = ...
20:53:17 <ddarius> sina: You can, you know, look at the BNF and clearly see what the syntactical structure of Haskell is.
20:53:38 <sina> BNF?
20:53:54 * ddarius shudders.
20:54:57 <Philippa> the grammar for haskell
20:55:31 <Philippa> (Backus Normal Form, a particular metalanguage for describing Context Free Grammars)
20:56:28 <Philippa> (also part of one of the early major achievements of computer science!)
20:57:32 <Axman6> oh no, I deid!
20:57:34 <Axman6> died too!
20:59:07 <sina> should I use if else inside the guards then? cause I cant get this to work :-s and I cant find anything on the internet
20:59:58 <ddarius> Axman6: It happens.
21:00:24 <ddarius> The Report is on the internet and it completely specifies the syntax of Haskell.
21:01:42 <Axman6> Philippa: which was?
21:02:01 <sina> I cant find BNF and haskell on google :-s
21:04:00 <Philippa> Axman6: the formalisation and development of significant classes of language with corresponding theories and parsing techniques for them
21:28:02 <sina> is multiple @ allowed? like list@(h@(a,b),_) ?
21:29:04 <copumpkin> > let f x@(Just (y@(Just q))) = (x, y, q) in f (Just (Just 5))
21:29:04 <lambdabot>   (Just (Just 5),Just 5,5)
21:29:09 <lispy> sina: yeah
21:29:12 <copumpkin> it would appear to be so
21:29:37 <sina> thanks :)
21:29:58 <ddarius> Of course it is so.  The syntax for patterns is <p> ::= identifier@<p> | ...
21:30:36 <ddarius> > let x@(y@3) in (x,y)
21:30:37 <lambdabot>   <no location info>: parse error on input `in'
21:30:47 <ddarius> > let x@(y@3) = 3 in (x,y)
21:30:48 <lambdabot>   (3,3)
21:32:36 <sina> ddarius: I can't figure out what this means ? x@(y@3)
21:33:28 <copumpkin> anyone have hoopl compiling on ghc 7?
21:33:45 <copumpkin> parts of it seem integrated in the GHC codebase now (as of 7.0.1) but the package doesn't compile
21:33:52 <copumpkin> (not even the repo version)
21:35:25 <Philippa> sina: it binds x to the value matched by (binds y to the value matched by (3))
21:36:14 <Philippa> sina: a more useful example might be xs@(x:xs')
21:36:31 <Philippa> (xs is the whole list, xs' is tail xs)
21:37:08 <sina> I understand @ and I used the multiple @ in my code and it worked fine. I just find it hard to get my head around x@(y@3)
21:38:48 <duckinator> dskippy: if you figure out how to implement Note+Interval=Note, can you let me know? i'm kinda new to haskell, curious about that kind of stuff ;)
21:38:50 <duckinator> ...
21:38:53 <duckinator> sorry :( wrong window
21:39:00 <duckinator> (managed to hit up+enter..)
21:39:17 <copumpkin> duckinator: that affine space/torsor thing looked like it was pretty much exactly what was needed
21:40:03 <duckinator> copumpkin: hm, i'll look into that in a bit. trying to rewrite an irc bot in a less ugly manner atm :P
21:48:11 <tehgeekmeister> how do i build haddocks for a package i have installed?
21:49:50 <sina> how to negate in haskell? like if not
21:50:28 <tehgeekmeister> > not True
21:50:29 <lambdabot>   False
21:50:29 <sm> not ...
21:50:38 <tehgeekmeister> > not $ not True
21:50:39 <lambdabot>   True
21:50:43 <tehgeekmeister> that seems to work.
21:50:46 <Boxo> What's up with the fact that this works? http://pastebin.com/BC6nzsK8 Do FunDeps actually do anything?
21:51:11 <sina> > if not True then False else True
21:51:11 <lambdabot>   True
21:52:02 <Boxo> "They let you state that in a multi-parameter type class, one of the parameters can be determined from the others, so that the parameter determined by the others can, for example, be the return type but none of the argument types of some of the methods." Also, how do you reconcile that with MonadState
21:52:44 <copumpkin> Boxo: what's wrong with it?
21:52:50 <Boxo> s is determined and an argument of put
21:53:11 <copumpkin> that's what it means
21:53:16 <copumpkin> m determins s
21:53:29 <Boxo> I guess I don't understand what having that FunDep there stops me from doing
21:53:32 <copumpkin> you couldn't define MonadState1 Bool Maybe now
21:53:34 <copumpkin> try it
21:53:37 <Boxo> huh
21:54:05 <Boxo> yeah I can't
21:54:21 <meltingwax> does anyone else fall in love when a girl knows what a monad is
21:54:28 <copumpkin> it just means that the first parameter is fully determined by the second, in this case
21:54:49 <copumpkin> so whenever it sees Maybe in the second place (or infers it from your use of the methods), it knows that the first must be Int here
21:55:19 <Boxo> Right. I thought it was something like s had to occur in the actual type...
21:55:30 <copumpkin> oh, no
21:55:39 <copumpkin> in this case it's essentially creating a type function
21:55:45 <copumpkin> from m to s
21:55:57 <copumpkin> but you can create bidirectional dependencies too
21:56:20 <copumpkin> or combinations of parameters and so on
21:56:38 <lispy> copumpkin: do type families/associated types, let you create bidirection stuff too?
21:56:38 <copumpkin> I think I'm in the minority, but I quite like having both type families and fundeps
21:56:40 <Boxo> "the parameter determined by the others can, for example, be the return type but none of the argument types" Still, what's with that, s IS a an argument type
21:56:50 <ddarius> class C a | -> a
21:56:51 <copumpkin> lispy: they will eventually
21:57:10 <lispy> my main objection to FDs are: 1) the error messages are really confusing, 2) I'm not a fan of prolog style coding
21:57:25 <copumpkin> lispy: the whole type system is prolog-style though
21:57:29 <copumpkin> regardless of fundeps
21:57:44 <lispy> I'm not sure I agree with that
21:58:08 <lispy> I don't need horn clauses to think about types
21:58:23 <ddarius> Actually functional dependencies are less like Prolog and more like Mercury.
21:58:42 <lispy> I'm not familiar with mercury :(
21:59:47 <sina> cool, I'm close to finish my code which is supposed to break enigma code !!!!
21:59:57 <lispy> sina: oh, neat
22:00:02 <jmcarthur> just because your types aren't that complicated doesn't really change whether the type system is a lot like prolog
22:00:09 <copumpkin> lispy: for example, if something is clearly (what one would usually consider) relational, I prefer using an MPTC rather than a fundep outputting a type-level bool
22:00:35 <copumpkin> rather than a type family I mean
22:00:37 <copumpkin> but for things that are functions, I think type families are nice
22:00:49 <copumpkin> and data families have a nice niche of their own
22:01:04 <copumpkin> so if I had typenats and wanted <=, I'd use an MPTC, and + would be a type family
22:01:18 <jmcarthur> since type families were introduced i've used them many times. i think i have used fundeps only once since then.
22:01:19 <lispy> I need to study type families/data families/etc in earnest.
22:01:24 <copumpkin> the whole Blah x y ~ True constraint is ugly
22:01:26 <jmcarthur> aside from using libraries that themselves use fundeps, of course
22:01:57 <copumpkin> Booleans are a hack to get around not having easy ways of dealing with relations :P
22:02:06 <copumpkin> (among other things)
22:17:57 <Boxo> So is I replace fundeps with type families... http://pastebin.com/pXhSsSje
22:18:02 <Boxo> *if
22:19:26 <copumpkin> yep
23:01:08 <Guest21321> www.miss34.com/head-under-water
23:09:54 <tg_> i'm guessing that's not a good link to click
23:49:51 <doudou> Hi, i dont know haskell, i wonder about its interessest as it not very human friendly, my question is unix world have promoted regex as a very important tool, has haskell some similar phylosophy with such tool? I read haskell does not like too much variables, did i understood the phylosophy?
23:52:41 <Axman6> doudou: i don't understand your question
23:52:56 <Axman6> haskell isn't very human friendly? i would disagree
23:53:33 <Axman6> and regular expressions in haskell are often looked down upon. writing actualy parsers in haskell is very easy, and usually preferred
23:56:19 <doudou> well it is phylosophy, a regex motor could easily writen in haskell or not?
23:56:43 <danharaj> doudou what is your native language?
23:56:49 <danharaj> maybe someone here speaks it and can help better.
23:56:49 <doudou> and human friendly ... it is mainly abstract language, even not object?
23:56:59 <doudou> i am australian
23:57:04 <doudou> austrian
23:57:14 <danharaj> and German speakers in the house?
23:57:45 <doudou> do you feel your question about native language very stupid?
23:58:03 <danharaj> I am not sure I understand the question.
23:58:21 <danharaj> any*
23:58:25 <doudou> ok dont try to answer questions you dont understand, that a bad idea
23:59:12 <doudou> but i agree my syntax is very unclear, and the question not very precise too
23:59:18 <doudou> thanks
