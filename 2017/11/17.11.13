00:25:02 <ertes-w> hllo
00:38:25 <wz1000> data Some (k :: * -> Constraint) where Box :: forall a k. (k a) => a -> Some k
00:38:38 <wz1000> ^ does something like this exist on hackage?
00:39:49 <wz1000> and is there any way to turn it into a newtype?
00:42:03 <mniip> wz1000, no
00:42:21 <mniip> (k a) => works almost like an additional field inside the Box constructor
00:42:33 <mniip> ultimately Box is a binary constructor
00:43:13 <mniip> I've made a proposal that Dict :: c => Dict c could be allowed to be a newtype but it gained no traction
00:43:24 <mniip> even though implementationally feasible
00:44:26 <fxcg> lol
00:46:22 <phadej> wz1000: it is on hackage
00:46:40 <phadej> wz1000: at least http://hackage.haskell.org/package/exists-0.2/docs/Data-Exists.html
00:47:48 <wz1000> phadej: thanks
00:48:54 <phadej> https://www.stackage.org/haddock/lts-9.13/hackage-security-0.5.2.2/Hackage-Security-Util-Some.html#t:Some variation on the idea
00:49:22 <phadej> and https://www.stackage.org/haddock/lts-9.13/dependent-sum-0.4/Data-Some.html#t:Some
00:49:27 <phadej> which I have encountered myself
00:50:17 <phadej> a bit unfortunate that you'd need two `Some`, one for * -> Constraint, and one for * -> *
00:50:32 <phadej> k -> Constraint, and k -> *, sorry.
00:50:44 <wz1000> hmm, I didn't know !(...) was valid syntax for GADT constructor arguments
00:53:38 <Hafydd> It's in the GHC manual.
01:47:24 <Guest63054> Hey, got a quick question about Monads anyone happy to help?
01:49:01 <phadej> shoot
01:55:12 <rzhanka> why is the following acceptable to the ghci repl, but not to the compiler: data Foo a = Foo a | Bar deriving (Show); main = print Bar -- The compiler complains that the type of Bar is ambiguous, which I understand. What I don't understand is why the compiler insists the ambiguity matters, but the repl doesn't.
01:59:56 <mud> rzhanka: Typically that comes about because the repl has more defaulting rules (it'll pick a type for you that matches a constaint in many more circumstances). But I'm not sure what is defaulting there, I guess it's picking a Show instance, maybe () ?
02:03:48 <lamba_> Hi! I am trying to make a random instance for the V type of the linear library, but it's a bit more annoying than expected.
02:03:57 <rzhanka> mud: I was guessing it was something like that, I thought maybe there was some obvious rule that might correspond to a compiler directive or something. I'm not sure what the repl is assuming, or how to test that.
02:05:07 <lamba_> this is my attempt: random = runState (sequence (mapM state (pure random)))
02:05:09 <lamba_> but it fails
02:06:48 <lamba_> i have the type f (a -> (g,a)) and want to turn it into a -> (f g, a) by doing a monadic scan like operation
02:06:58 <mud> rzhanka: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#type-defaulting-in-ghci has quite a bit about it
02:07:24 <phadej> lamba_: I'd start from pure () :: V (), and `traverse` it with `() -> m a`, to get `m (V a)`, where m is some Monad/Applicative capable of generaing random numbers
02:08:22 <phadej> or then you could pure action, where action :: m a, and then sequence it
02:08:34 <phadej> i.e. only one sequence or mapM/traverse, not both
02:08:54 <lamba_> yes i am doing pure action
02:09:12 <lamba_> in this case the monad is the State monad
02:09:36 <lamba_> didn't make it generic as in MonadRandom
02:09:39 <phadej> maybe, sequence (pure (state random)) ?
02:10:18 <phadej> in general: write out intermediate values and types for them, and think what you need to add in between to proceed
02:10:21 <phadej> :)
02:10:43 <rzhanka> mud: exactly what I needed, thanks very much
02:10:53 <lamba_> alright thanks i'll try
02:11:45 <phadej> lamba_: e.g. in your example changing `mapM` to `fmap` might also work
02:12:10 <phadej> and sequence . fmap = traverse; or fmap f (pure x) = pure (f x)
02:12:18 <phadej> up to you how to (if at all) to rewrite
02:16:02 <lamba_> phadej thanks runState $ sequence (pure (state random)) worked
02:16:13 <phadej> +1
02:24:25 <rzhanka> mud++
02:36:24 <Guest63054> Is a monad just an sequence of steps that form an alternative to function composition in the case where the functions being composed expect a type b as input and both functions perform the same mapping of type a to another arbitrary type?
02:37:00 <opqdonut> well, kinda
02:37:02 <opqdonut> :t (>=>)
02:37:04 <lambdabot> Monad m => (a -> m b) -> (b -> m c) -> a -> m c
02:37:45 <opqdonut> you just need return and >=> to get a monad
02:39:16 <Guest63054> So >=> is a type?
02:39:27 <mniip> no
02:39:30 <opqdonut> no, it's a function
02:39:37 <opqdonut> "monadic function composition"
02:40:09 <mniip> well first and foremost, a monad is an endofunctor
02:40:10 <Guest63054> And return gives a different function?
02:40:50 <mniip> from then on definitions diverge
02:41:45 <mniip> Guest63054, to be frank, your attempt at a definition made no sense to me
02:42:06 <tdammers> as far as Haskell is concerned, a Monad is a type m, two functions (>>=) :: m a -> (a -> m b) -> m b and return :: a -> m a, and the Monad Laws
02:42:12 <opqdonut> yeah
02:42:26 <tdammers> (and if you want, you can use (>=>) instead of (>>=) in your definition)
02:42:35 <dysfun> tdammers: not really, haskell doesn't check the monad laws
02:42:42 <mniip> a Free monad is kind of like a sequence of steps,
02:42:55 <mniip> and there are homomorphisms from Free to any monad
02:42:56 <opqdonut> instead of >>= or >=>, you can also define "join :: m (m a) -> m a"
02:43:14 <tdammers> dysfun: it doesn't check them, but programmers expect them to hold; it's not part of the language implementation, but it is part of the language's idiom
02:43:15 <mniip> but bar that I don't think what you said is useful in understanding what a monad is
02:44:00 <dysfun> tdammers: i agree programmers expect them to hold, but haskell doesn't
02:44:27 <dysfun> tdammers: i remember watching SPJ say that some of the monads which didn't obey the laws were some of the most useful
02:44:35 <opqdonut> I guess libraries might have some rewrite rules that expect them to hold
02:44:45 <Guest63054> Sorry what is m in your explanation exactly tdammers?
02:44:50 <opqdonut> for these problematic monads you need to relax the interpretation of = usually
02:44:53 <mniip> Guest63054, the monad
02:44:58 <tdammers> Guest63054: m is the monad type
02:45:04 <tdammers> Guest63054: the m in Monad m => ...
02:45:09 <Guest63054> Okay so a monad is a type itself
02:45:12 <tdammers> no
02:45:15 <tdammers> Monad is a typeclass
02:45:21 <Guest63054> whats the difference
02:45:24 <mniip> Monad is a typeclass, yes
02:45:25 <Guest63054> between a type and typeclass
02:45:28 <mniip> but *a monad* is a type
02:45:31 <dysfun> *a* Monad is an implementation of the typeclass
02:45:34 <mniip> like I said,
02:45:35 <mniip> 1510569594 [13:39:54] <mniip> well first and foremost, a monad is an endofunctor
02:46:06 <tdammers> Guest63054: a type is, well, a type - naively, a set of values (although this definition is not 100% accurate)
02:46:36 <dysfun> "it's just a costate comonad coalgebra, what's hard about that?"
02:46:54 <tdammers> Guest63054: a typeclass is a "class of types"; you can think of it as an open set of types, or as a constraint that reduces the set of all types to a subset of types
02:47:04 <mniip> dysfun, doubly irrelevant though
02:47:15 <tdammers> Guest63054: specifically, typeclasses can have *methods*, which form an "interface" that any type in the typeclass must implement
02:47:34 <mniip> dysfun, costate comonad coalgebras are lenses and that's a bad way to talk about them as you can't express prisms in the same framework
02:47:45 <tdammers> Guest63054: E.g., the Show typeclass can be thought of as the set of all types for which the show function is defined, but you can also think of it as an interface that consists of the show method
02:47:55 <Guest63054> So a type has properties of a particular typeclass
02:47:56 <dysfun> mniip: indeed, that was a quote about lenses
02:48:00 <tdammers> Guest63054: likewise, Monad is the set of all types that are monads
02:48:21 <mniip> ugh
02:48:28 <mniip> this is terminologically confusing
02:48:32 <tdammers> Guest63054: kind of, yes. The typeclass enforces that every type in it has certain properties, expressed as methods
02:49:16 <Guest63054> So a monad is a type that follows certain rules defined in the monad typeclass
02:49:27 <mniip> in haskell, yes
02:49:29 <Guest63054> (apologies only ever used Javascript and python)
02:49:47 <mniip> Guest63054, sounds like you might wanna hang out in #haskell-beginners instead
02:49:48 <Guest63054> Yeah only talking about haskell here
02:49:55 <drdo> Guest63054: You can also think of a typeclass as a dictionary specification
02:50:05 <mniip> see monad originates from mathematics
02:50:14 <drdo> And instances are just concrete dictionaries with all the items filled in
02:50:21 <mniip> and haskell monads are modelled after the mathematical entity
02:51:56 <Guest63054> So would return and >=> be considered methods of the Monad typeclass?
02:52:02 <mniip> yes
02:52:06 <mniip> in reality it's return and >>=
02:52:13 <mniip> >=> is a freestanding function
02:52:20 <Guest63054> Ok I feel like I am getting somewhere
02:52:42 <Guest63054> so the actual implementation of these methods are what differentiation Monad types ( IO monad vs State etc)
02:52:50 <mniip> not only
02:53:01 <drdo> Guest63054: Maybe look at some other typeclasses you might be more familiar with first
02:53:07 <drdo> Like Eq
02:53:10 <mniip> a monad is not only the implementations of the methods, but also the type itself
02:53:54 <mniip> i.e say Maybe and (State s), both monads - look different "on the inside"
02:54:33 * Maxdamantus doesn't like thinking of the type as part of the monad.
02:54:34 <drdo> Even I'm getting confused!
02:54:44 <Maxdamantus> unless "type" means "set of values"
02:54:55 <Guest63054> Great, thanks so much everyone for your help. I feel like I have a better direction now for my learning. So will read up on types and typeclasses and then come back with more questions in the future :)
02:54:56 <mniip> Maxdamantus, well excuse me, would you say that Functor is just the fmap function?
02:55:38 <drdo> mniip: Are we discussing the Functor typeclass, or functors?
02:55:44 <ventonegro> mniip: That's a pretty good starting point
02:55:48 <Maxdamantus> mniip: I would say `Functor` is a type function that returns the type of functor instances.
02:56:23 <Maxdamantus> mniip: where a "functor instance" is basically an fmap function
02:56:33 <mniip> well
02:56:37 <Maxdamantus> (or a wrapper around it)
02:56:39 <mniip> in category theory
02:56:42 <mniip> it goes:
02:57:36 <mniip> a functor F is a mapping X |-> F X  from one category's objects to another category's objects
02:58:10 <ventonegro> mniip: It's just a bit strange that at the same time you suggest someone go to #haskell-beginners, you bury them with pedantry
02:58:12 <mniip> equipped, for every X, Y in the first category, a mapping of morphisms f |-> F f from X -> Y to F X -> F Y
02:58:25 <mniip> ventonegro, I didn't bury *them* with pedantry
02:58:39 <drdo> the functor typeclass is pretty much this: data Functor f = Functor { fmap ∷ ∀ a b. (a → b) → f a → f b }
02:58:50 <drdo> I don't know where all this crazyness is coming from
02:59:03 <Maxdamantus> ^ which is pretty much what I described it as
02:59:32 <mniip> the implication, at the time, was that functors are nothing more than instances of some typeclass
02:59:34 <mniip> which is wrong
02:59:47 <Maxdamantus> `Functor` there is a function that takes something of kind `* -> *` and returns a type that should be implemented for that particular `* -> *`
03:00:01 <drdo> and an instance is pretty much this: listFunctor = Functor { fmap = map }
03:00:56 <mniip> drdo, fascinating.
03:01:07 <Maxdamantus> to be fair, I've always been confused when trying to understand what it means in category theory. I can read precisely what the types mean in Haskell at least.
03:02:35 <drdo> In fact you could really do this without any support for typeclasses in the language, you just explicitly pass those around instead of having the helpful syntactic sugar
03:02:40 <Maxdamantus> in concrete Haskell terms, is "a functor" an instance of `Functor f` for some `f :: * -> *` (ie, an implementation of `fmap`)?
03:02:43 <mniip> Maxdamantus, a function F : Ob(C) -> Ob(D) and a function family F_X,Y : hom_C(X, Y) -> hom_D(F(X), F(Y)) satisfying some laws
03:02:45 <Maxdamantus> or is it something else?
03:03:02 <mniip> drdo, sigh
03:03:15 <mniip> drdo, please take a moment to reread what my point is
03:03:21 <drdo> mniip: You have a point?
03:05:11 <mniip> drdo, do I look like I'm arguing for entertainment
03:05:29 <drdo> yes, kinda
03:05:30 <drdo> :P
03:06:12 <Maxdamantus> anyway, I feel more comfortable saying what "a monad" is .. "a monad" is just a particular instance oy those operations (`return`, `(>>=)`, or something equivalent), possibly in combination with the values they operate over.
03:07:00 <Maxdamantus> Analogous to a monoid, which is some associative binary operator, an identity element, and possibly the elements they operate over.
03:07:32 <Maxdamantus> eg, `0, (+), [0..]` would be one monoid, `1, (*), [0..]` would be another.
03:07:34 <drdo> All this because someone new was trying to understand typeclasses
03:07:42 <drdo> Which have nothing to do with this
03:08:37 <mniip> Maxdamantus, a monoid (mathematics) also always includes the laws
03:09:04 <Maxdamantus> mniip: I think even in mathematics, you would say that a monoid obeys laws.
03:09:36 <mniip> <N_0, (+), 0> is nothing without the proof of the laws
03:09:53 <Maxdamantus> If the proposed identity value and binary operator do not together conform to the monod laws, they are not a monoid.
03:09:54 <mniip> you can't call it a monoid until it satisfies laws
03:10:04 <mniip> yeah
03:10:10 <mniip> and then there's the haskell Monoid
03:10:20 <Maxdamantus> It's not like you have different laws for different monoids.
03:10:32 <mniip> you have different proofs though
03:10:56 <Maxdamantus> Sure, and proofs are usually though of as external to propositions.
03:11:19 <Maxdamantus> The propositions exist without the proofs.
03:11:39 <Maxdamantus> and there can be many different ways to prove the same proposition.
03:11:46 <Maxdamantus> afk
03:12:29 <mniip> my point is that either you mention the laws, or you make it clear that you're talking about Class Data.Monoid.Monoid
03:12:42 <mniip> and not a monoid (mathematics)
03:13:07 <mniip> and
03:13:12 <mniip> for someone learning what a monoid is
03:13:22 <mniip> I don't think the exact perks of what Data.Monoid.Monoid is are useful
03:14:24 <Guest21836> If anyone is up for tutoring/mentoring sessions via Skype then let me know (beginner)
03:14:41 <mniip> (the default implementations and compiler-supplied partial implementations, the extraneous mconcat method, the dictionaries, the implicit dictionary TyCon, the category of constraints, and the =>/-> erasure in core)
03:16:56 <xyz_> Hi all, I'm new to this IRC thing and not sure if this is the right place to ask questions. But i will just go ahead: How do i extract the value of a MonaThrow instance?
03:17:01 <xyz_> *MonadThrow
03:17:44 <jollygood2> is there a way to globally make my local module available to stack instead of having to add it to each project's packages: section in stack.yaml?
03:17:58 <drdo> xyz_: You don't, in general
03:19:00 <xyz_> I have got the following type signature for a Bimap lookup: lookup :: (Ord a, Ord b, MonadThrow m) => a -> Bimap a b -> m b 
03:19:26 <xyz_> I would like to lookup a value and return a default if the key is not present
03:20:31 <drdo> xyz_: Use Maybe for example
03:22:03 <xyz_> I am using https://hackage.haskell.org/package/bimap-0.3.3 but the lookup function does not return a Maybe, but an instance of MonadThrow
03:22:17 <drdo> So take m = Maybe
03:23:09 <drdo> example: lookupDefault default a = maybe default id . lookup a
03:24:14 <dibblego> s/maybe default id/fromMaybe default
03:28:33 <xyz_> Thanks alot, I was just able to use 'fromMaybe'. But there might be something I do not understand: If Maybe implements MonadThrow, I think I should be able to use MonadThrow functions on Maybe and not the other way round, shouldn't I?
03:29:04 <drdo> xyz_: That's correct
03:29:30 <drdo> But what you are doing there is not using an arbitrary MonadThrow
03:30:25 <drdo> That function works for any MonadThrow m, and you are just calling it with the specific m = Maybe
03:30:57 <xyz_> But the typesignature: 'lookup :: (Ord a, Ord b, MonadThrow m) => a -> Bimap a b -> m b' does not tell me, there will be a Maybe as a result
03:31:46 <drdo> xyz_: But it tells you that it can return any type m, as long as it's an instance of MonadThrow
03:31:54 <drdo> And you are choosing Maybe
03:32:39 <xyz_> Ah, i see now. By calling "fromMaybe" the correct instance of "MonadThrow" can be infered.
03:33:19 <drdo> xyz_: yes
03:33:37 <xyz_> Thank you!
03:40:39 <jollygood2> is this a good way to check whether double is whole? (==1) . denominator . toRational
03:41:26 <drdo> Why do you want to do that?
03:41:31 <jollygood2> > let f = (==1) . denominator . toRational in f (5 :: Double)
03:41:33 <lambdabot>  True
03:41:40 <jollygood2> > let f = (==1) . denominator . toRational in f (5.2 :: Double)
03:41:42 <lambdabot>  False
03:42:47 <jollygood2> drdo for printing purposes. I want to print it without .0 if it is "whole". I guess string replace woud work too
03:42:52 <ertes-w> :t properFraction
03:42:54 <lambdabot> (Integral b, RealFrac a) => a -> (b, a)
03:43:00 <ertes-w> jollygood2: ^
03:43:25 <ertes-w> jollygood2: however, don't compare the snd to 0, but rather its absolute value to some small value
03:43:44 <drdo> jollygood2: check out the functions here: https://hackage.haskell.org/package/base-4.10.0.0/docs/Numeric.html
03:43:46 <mlehmk> ahh, the float thing again
03:43:55 <ertes-w> > properFraction 5.2
03:43:57 <drdo> Maybe something will be useful
03:43:57 <lambdabot>  (5,0.20000000000000018)
03:44:48 <mlehmk> > properFraction 5.175
03:44:49 <lambdabot>  (5,0.17499999999999982)
03:45:32 <ertes-w> @let isAlmostWhole = (<= 1e-15) . abs . snd . properFraction
03:45:34 <lambdabot>  Defined.
03:45:44 <ertes-w> > isAlmostWhole 5.001
03:45:46 <lambdabot>  False
03:46:02 <ertes-w> > isAlmostWhole 5.00000000000000001
03:46:05 <lambdabot>  True
03:46:45 <jollygood2> yeah almostWhole is better fit, as I am printing just one decimal
03:47:09 <jollygood2> > isAlmostWhole 1.01
03:47:12 <lambdabot>  False
03:47:15 <jollygood2> I want this to be True too
03:48:05 <jollygood2> > let isAlmostWhole = (<= 0.1) . abs . snd . properFraction in isAlmostWhole 1.01
03:48:07 <lambdabot>  True
03:48:22 <jollygood2> > let isAlmostWhole = (<= 0.1) . abs . snd . properFraction in isAlmostWhole 1.05
03:48:24 <lambdabot>  True
03:50:06 <jollygood2> > let isAlmostWhole = (<= 0.1) . abs . snd . properFraction in isAlmostWhole 1.04  
03:50:08 <jollygood2> not quite
03:50:08 <lambdabot>  True
03:56:39 <jollygood2> > let isAlmostWhole = (<= 0.05) . abs . snd . properFraction in isAlmostWhole 1.04
03:56:41 <jollygood2> > let isAlmostWhole = (<= 0.05) . abs . snd . properFraction in isAlmostWhole 1.05
03:56:41 <lambdabot>  True
03:56:44 <lambdabot>  False
04:06:50 <ertes-w> jollygood2: you could also just use printf
04:11:16 <ertes-w> nevermind, printf can't do it apparently
04:12:20 <ertes-w> > showGFloat (Just 1) (0.1 :: Double) ""
04:12:23 <lambdabot>  "0.1"
04:12:26 <ertes-w> > showGFloat (Just 1) (0.11111 :: Double) ""
04:12:28 <lambdabot>  "0.1"
04:12:31 <ertes-w> > showGFloat (Just 1) (5 :: Double) ""
04:12:33 <lambdabot>  "5.0"
04:12:58 <ertes-w> > showFFloat (Just 1) (5 :: Double) ""
04:13:00 <lambdabot>  "5.0"
04:14:23 <ertes-w> @let roundPrec p x = fromInteger (round (p*x)) / p
04:14:25 <lambdabot>  Defined.
04:14:45 <ertes-w> > roundPrec (recip 0.1) 15.14
04:14:48 <lambdabot>  15.1
04:14:49 <ertes-w> > roundPrec (recip 0.1) 15.15
04:14:51 <lambdabot>  15.2
04:15:16 <ertes-w> > showGFloat Nothing (roundPrec (recip 0.1) 15.15 :: Double) ""
04:15:19 <lambdabot>  "15.2"
04:15:20 <ertes-w> > showGFloat Nothing (roundPrec (recip 0.1) 15 :: Double) ""
04:15:23 <lambdabot>  "15.0"
04:15:27 <ertes-w> huh?!
04:18:13 <jollygood2> I'm tempted to just printf "%.1f" x, then replace ".0" with ""
04:41:54 <saurabhnanda> does anyone know if yesod handlers can specify their return type, like servant? Does everything need to be a `Handler Value`? Can it be a `Handler User`?
04:53:00 <lyxia> saurabhnanda: what happens if you change the type
04:53:28 <saurabhnanda> lyxia: didn't understand your question.
04:53:56 <saurabhnanda> that's `Handler Aeson.Value` vs `Handler User`. In the latter the web library takes care of converting to JSON for you.
04:58:14 <lyxia> Aren't there also handlers for HTML, in which case yesod may be sufficiently polymorphic for you to add your own types
05:00:04 <saurabhnanda> can't find any examples to do this. not even in the yesod book. Unless I've overlooked something.
05:02:04 <lyxia> That's why I suggested to nevertheless try the handler with the type you want, and see what error GHC outputs
05:19:13 <__Lorn__> 6hello
05:20:44 <raek> hi
05:21:23 <__Lorn__> raek: hi
05:21:40 <shae`> hi
05:44:16 <jollygood2> is there a way to globally make my local module available to stack instead of having to add it to each project's packages: section in stack.yaml?
05:44:37 <fizbin> Anyone know of any resources for getting a serious handle on latency and making timings of haskell programs deterministic?
05:44:51 <M4GNV5> > [1..]
05:44:53 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
05:45:42 <fizbin> I'm trying to do https://cryptopals.com/sets/4/challenges/31 and https://cryptopals.com/sets/4/challenges/32 , and I can't seem to get even vaguely consistent timings out of a web request.
05:50:43 <lyxia> jollygood2: no, each .cabal must list all its dependencies
05:52:16 <lyxia> jollygood2: Maybe there are some more configurable build systems so you can generate the .cabal files from a common template, but I don't know much about them.
05:54:55 <ertes-w> fizbin: with some experience you can make latency and timings somewhat deterministic, however it's impossible to get any guarantees
05:55:25 <fizbin> I should take where I am and push it to github so that I can actually point people at the code.
05:55:48 <jollygood2> lyxia I did list it as a dependency. but stack tries to search hackage for that module, instead of finding it locally. to stop this I have to manually create stack.yaml file, instead of using stack init. and I have to do it for every project that uses my module (nearly all but the simplest ones)
06:06:22 <mniip> hmm
06:06:32 <mniip> lenses...
06:07:46 <mniip> edwardk: are you around
06:10:01 <mniip> basically, I'm looking at FreeT
06:12:17 <mniip> and how token :: Writer t (m t)
06:12:27 <lyxia> jollygood2: yeah you need to specify all local packages in stack.yaml
06:12:40 <jollygood2> no global equivalent?
06:12:56 <mniip> leads to m (Writer [t] a)
06:12:58 <lyxia> jollygood2: Have you tried to put all your packages under a single stack.yaml
06:12:59 <jollygood2> at the very least, is there a way to specify them while calling stack init?
06:13:07 <mniip> and token :: Reader t (m t)
06:13:43 <mniip> leads to [t] -> m a
06:13:44 <jollygood2> lyxia I have one massive package where I put all my library code. and it is in its own stack.yaml
06:13:53 <mniip> in other words
06:14:25 <mniip> token :: WriterT t m t
06:14:33 <mniip> -> enumerate :: WriterT [t] m a
06:14:41 <mniip> and token :: ReaderT t m t
06:14:46 <mniip> -> parse :: ReaderT [t] m a
06:14:49 <mniip> and it reminded me
06:14:50 <mniip> of lens
06:15:18 <ertes-w> mniip: you're asking how (FreeT ((,) a)) is a producer of 'a' and (FreeT ((->) a)) is a consumer of 'a'?
06:15:34 <mniip> ertes-w, that much is clear
06:15:39 <mniip> question is, what does this mean
06:15:47 <lyxia> jollygood2: "stack init ../my-big-library ./"
06:15:48 <mniip> can we... generalize?
06:16:32 <ertes-w> mniip: there are lots of directions to generalise from this…  do you have something specific in mind?
06:16:32 <mniip> hmmm
06:16:37 <mniip> :t (StateT (maybe empty pure . uncons) >>=)
06:16:38 <lambdabot> (Alternative m, Monad m) => (a -> StateT [a] m b) -> StateT [a] m b
06:16:43 <mniip> :t (uncurry $ (>>) . tell . return)
06:16:44 <lambdabot> (Monad m1, MonadWriter (m1 a) m2) => (a, m2 b) -> m2 b
06:17:08 <infinisil> How can I group each 2 elements of a list?
06:17:11 <mniip> joining these two is a way to go
06:17:27 <infinisil> something like [a] -> [(a, a)]
06:17:43 <mniip> infinisil, [1,2,3] -> [(1,2),(2,3)] ?
06:17:55 <infinisil> Well I could just write it myself, but maybe there's a fancy builtin function
06:18:01 <infinisil> mniip: It's an infinite list
06:18:02 <mniip> infinisil, yes/no?
06:18:27 <mniip> are you looking for [(1,2),(2,3),(3,4),..] or [(1,2),(3,4),(5,6)..] ?
06:18:37 <infinisil> ah, the second one
06:18:50 <mniip> that's slightly more complicated
06:19:45 <ertes-w> mniip: a few years ago i wanted to write a library based on this idea, where you use sums of functors to combine streaming effects, but i never finished it, and now that 'machines' exists i'm not really inclined to do it either
06:19:51 <infinisil> g2 (x:y:z) = (x,y) : g2 z   could work probably
06:20:00 <ertes-w> there is also the 'streaming' library, but it follows a different design
06:20:15 <mniip> infinisil, that's probably the way to go.
06:21:03 <ertes-w> one interesting feature of FreeT/FT-based streaming is the built-in notion of delimiters
06:21:09 <mniip> infinisil, there isn't a nice way to write this functionally
06:21:26 <ertes-w> here is a stream of 'a' that is two levels deep:  FreeT (FreeT ((,) a) m) m r
06:21:35 <mniip> ertes-w, you are familiar with yoctoparsec, right?
06:21:43 <ertes-w> mniip: superficially
06:21:53 <infinisil> mniip: Well this function seems rather nice to me :)
06:22:20 <mniip> infinisil, it's partial and relies on case analysis
06:22:51 <infinisil> hmm true
06:23:14 <mniip> ertes-w, that looks like a parser composition to me
06:23:25 <mniip> oh er, enumerator composition rather
06:23:38 <ertes-w> mniip: i stole the idea from pipes-parse
06:24:05 <ertes-w> you could call it a form of composition, but i'd rather call it layering
06:24:40 <mniip> well yes
06:24:43 <mniip> it's still separable
06:25:10 <mniip> basically the inner FreeT describes a language homomorphism
06:25:27 <ertes-w> the motivation is the following:  say you have a stream of Text chunks, and you want to break it into lines, but you want to keep it constant-memory
06:25:59 <mniip> I have never considered FreeT in a performance context
06:26:09 <mniip> rather it's just a nice mathematical representation
06:26:14 <ertes-w> now you can map a FreeT transform over the inner layer that cuts off each line after a certain number of characters
06:26:22 <ertes-w> and it's still constant-memory
06:26:31 <ertes-w> it's nice both in terms of math and performance =)
06:26:33 <mniip> to think of it,
06:26:41 <mniip> picking apart a FreeT
06:26:46 <mniip> is similar to language differentiation
06:26:46 <jollygood2> lyxia if I try stack init on a project that uses my local package stack tries dozen different resolvers, and then ends up failing ot compile. so stack init becomes useless, and I have to manually copy and modify stack.yaml
06:27:01 <jollygood2> which is annoying
06:27:41 <mniip> you know, ∂L/∂c
06:27:56 <ertes-w> mniip: i had a fairly mundane use case for this:  take a ByteString stream from the network, split it into "lines", cut off each line at a certain protocol-specific length
06:28:16 <ertes-w> but it fit the use case perfectly…  i was able to write this in a very compositional way
06:28:30 <mniip> ertes-w, do you know of any papers on this topic
06:28:39 <ertes-w> nope, sorry
06:28:55 <ertes-w> i mostly figured it out from pipes-parse and type juggling
06:29:04 <mniip> I was wondering if I might have anything worth contributing
06:29:14 <mniip> cause I came up with this fairly independently
06:30:01 <ertes-w> you probably came to it from a more theoretical angle
06:30:29 <mniip> very much so
06:30:59 <mniip> my original idea went like
06:31:02 <mniip> well
06:31:13 <mniip> [t] -> [(a, [t])]
06:31:15 <mniip> that sucks
06:31:23 <mniip> because hidden invariant
06:31:45 <mniip> how do we get rid of this and make our type algebraically equivalent to a parser
06:32:18 <mniip> Parser t a = [a + (t -> Parser t a)]
06:32:36 <fizbin> Okay, so here's my issue: I'm attempting https://cryptopals.com/sets/4/challenges/31 and also problem 32. My solution to problem 31 is at https://github.com/fizbin/cryptopals-solutions/blob/master/src/Set4/HMACVerifyWebService.hs and the attack is https://github.com/fizbin/cryptopals-solutions/blob/master/src/Set4/AttackHMACVerifyWebService.hs
06:32:37 <mniip> but oh wait, that exists and it's called FreeT ((->) t) []
06:32:51 <mniip> and why bother with restricting to [] if we can generalize to MonadPlus
06:33:26 <ertes-w> and then you can go one step further and generalise it to MonadFree, so you can leverage FT
06:34:02 <ertes-w> get right-biased (>>=) for the underlying monad for free
06:34:17 <fizbin> It's a straightforward "attack a timing leak in string comparisons" issue, but when I scale the leak back to 5ms per byte compared, I can't find the timing leak any more in the noise.
06:34:59 <mniip> MonadFree?
06:35:09 <ertes-w> mniip: Control.Monad.Free.Class
06:35:17 <mniip> I mean er, that's for Free
06:35:25 <mniip> does a similar thing exist for FreeT
06:35:25 <ertes-w> it's for all of them
06:35:37 <ertes-w> Free, F, FreeT, FT
06:35:46 <mniip> ah I see
06:35:51 <mniip> well that's fairly minor
06:36:05 <mniip> I am thinking of generalizing the functor
06:36:12 <mniip> over which we build our free monad [transformer]
06:36:56 <ertes-w> mniip: i used functor sums…  or i was going to, but it turned out not to buy me much
06:37:12 <mniip> functor sums?
06:37:42 <mniip> (f :+: g) of some sort?
06:37:46 <ertes-w> newtype Sum f g a = LeftF (f a) | RightF (g a)
06:37:50 <ertes-w> s/newtype/data/
06:37:51 <fizbin> (that github project has a top-level cabal file, and if you run 'cabal run hmac-verify-webservice' in one terminal you can attack it in another with 'cabal run attack-hmac-verify-webservice -- http://localhost:9000/test cat')
06:38:02 <mniip> right
06:38:05 <mniip> that's what :+: is
06:38:15 <mniip> albeit it's defined in an odd place
06:38:54 <ertes-w> mniip: but it's not really abstracting over the nature of "reading", but rather over "other effects from reading"
06:39:15 <ertes-w> if you want the former, you can probably generalise to some category with extra structure
06:39:43 <ertes-w> check out the 'machines' library, as it already does that to support multiple input streams
06:40:06 <ertes-w> specifically the MachineT type
06:41:23 <jollygood2> <lyxia> jollygood2: "stack init ../my-big-library ./" <- I missed that one. thanks
06:41:29 <mniip> hmmm
06:41:43 <mniip> well FreeT can too read from multiple tapes
06:41:56 <mniip> with, yes, the exact same trick
06:42:27 <mniip> ertes-w, ok, consider this
06:44:08 <mniip> (keep considering)
06:46:05 <jollygood2> lyxia actually, no, it does not work. if I do that stack build just builds that local package. it doesn't build the actual project that depends on it
06:48:27 <ertes-w> hmm, yeah…  that's an interesting consideration…  i think…
06:49:47 <mniip> yeah gimme a few minutes I need to iron out some types
06:51:17 <ertes-w> take your time =)
06:59:53 <mniip> ertes-w, ok basically what I'm trying to do is
06:59:57 <mniip> I have these two:
07:00:05 <mniip> parse :: MonadPlus b => Yocto (->) b t a -> [t] -> b (a, [t])
07:00:05 <mniip> parse = runStateT . iterTM (StateT (maybe empty pure . uncons) >>=)
07:00:07 <mniip> enumerate :: Monad b => Yocto (,) b t a -> b (a, [t])
07:00:07 <mniip> enumerate = runWriterT . iterTM (uncurry $ (>>) . tell . return)
07:00:17 <mniip> and I think you'll notice
07:00:31 <mniip> (->) ~ Reader, [t] -> b (a, [t]) ~ ReaderT [t] b a
07:00:47 <mniip> (,) ~ Writer, b (a, [t]) ~ WriterT [t] b a
07:01:11 <mniip> it's some kind of "monad lens"
07:01:17 <mniip> monad morphism?
07:03:14 <ertes-w> i'm seeing the monad morphism aspect, but not quite the "monad lens" aspect
07:03:28 <Guest34007> hello all
07:03:29 <mniip> yeah no it's just a reminiscent feel
07:03:54 <mniip> ertes-w, recall that lenses are all about (a -> f a)   ->   (s -> f s)
07:04:35 <mniip> question is,
07:05:15 <mniip> to what degree can we go
07:06:10 <Guest34007> I am working on something where I want to keep a shared mutable vector between two threads ... one will right on it i.e. update it periodically very fast and other has to read the value ... how this can be done in Haskell any specific library
07:06:12 <ertes-w> what does "~" mean?  isomorphism?
07:06:16 <mniip> yes
07:06:34 <mniip> to what degree can we go with FreeT (f t) m a -> f [t] m a
07:07:17 <ertes-w> that looks like a kind error to me
07:07:19 <Guest34007> I have little time with me otherwise I could have read simon Marlow's book on it
07:07:34 <Guest34007> please help me ... its urgent for me
07:07:57 <ertes-w> Guest34007: use a mutable vector with a lock?
07:08:44 <mniip> ertes-w, hmmm
07:08:54 <Guest34007> I using a mutable vector but don't know how to use lock .... never done it before
07:08:57 <ertes-w> mniip: also your isomorphisms aren't quite right
07:08:58 <mniip> FreeT (f t Identity) m a -> f [t] m a
07:08:59 <mniip> I guess
07:09:10 <mniip> ertes-w, how so
07:09:15 <ertes-w> Guest34007: read about MVar
07:09:29 <ertes-w> Guest34007: an (MVar ()) is a lock
07:09:47 <ertes-w> mniip: [t] -> b (a, [t]) ~ ReaderT [t] b a
07:09:58 <ertes-w> ReaderT [t] b a ≃ [t] -> b a
07:10:09 <mniip> oh er yes
07:10:23 <mniip> that's StateT
07:10:44 <mniip> another good question
07:10:50 <Guest34007> okay , well I have a problem ... writing or updating will be done repeatedly but I don't want the reader to block until all writes .. is this possible with MVar or I have to go with STM
07:11:50 <ertes-w> Guest34007: for that you need STM, but it has a cost…  in particular we don't have any efficient STM arrays yet
07:11:51 <mniip> what's StateT again?
07:12:04 <mniip> ReaderT s (WriterT (Endo s) m)
07:12:49 <Guest34007> ertes-w: my size of state i.e the vector is not going to be too large
07:12:54 <makalu> how can I get a Ptr (Ptr ()) from a Ptr ()? I want to do the equivalent of "&x" in C.
07:13:03 <ertes-w> Guest34007: then i would just lock
07:13:31 <ertes-w> Guest34007: alternatively go with a pure data structure, unless you have a good reason to use arrays
07:14:02 <ertes-w> Guest34007: an (MVar (IntMap a)) is properly transactional and doesn't block readers
07:14:18 <ertes-w> Guest34007: in fact an IORef would probably suffice, if you use atomicModifyIORef'
07:14:25 <Guest34007> ertes-w: I need mutable vector because I have to do too many updations i.e. may be 10k times per sec
07:15:01 <ertes-w> Guest34007: 10k elements or 10k batches?
07:15:03 <mniip> FreeT (f t Identity) m a -> f [t] (WriterT (Endo [t]) m) a
07:15:07 <mniip> this seems far-fetched
07:15:20 <Guest34007> ertes-w: 10K batches
07:15:52 <ertes-w> mniip: i can't really comment on this without more context…  i'm not quite sure where this leads
07:16:01 <Guest34007> ertes-w: i.e. 10k times I may need to update some index k of a vector z
07:16:02 <mniip> ertes-w, there isn't more context
07:16:09 <mniip> I'm just throwing and seeing what sticks
07:16:29 <mniip> isn't that how research is done
07:16:33 <ertes-w> Guest34007: that's 10k batches, one element each, right?
07:17:00 <ertes-w> mniip: just explaining why i'm not responding =)
07:17:11 <Guest34007> ertes-w: not necessary one element it may be several elements one time
07:17:55 <mniip> hmm context
07:18:02 <Guest34007> I need performence
07:18:24 <ertes-w> Guest34007: there is a trade-off to be made here…  a vector comes at the price that you need locking, which blocks readers for the duration of a batch
07:18:48 <Guest34007> ertes-w: yes then what else
07:19:07 <ertes-w> Guest34007: with an IORef of an IntMap the new map can be built independently, and until it's ready all readers read the old map
07:19:17 <ertes-w> it's lock-free
07:19:28 <ertes-w> and the update is just a pointer update
07:19:55 <Guest34007> ertes-w: so it will not take much memory
07:20:26 <ertes-w> Guest34007: the mutable vector is likely cheaper in terms of memory, but may very well be more expensive in terms of throughput
07:20:42 <Guest34007> my vector may have 1 k elements
07:21:01 <ertes-w> you have to benchmark
07:21:34 <Guest34007> okay for io ref whatI have to read
07:21:53 <Guest34007> and also for mutable vector with locks
07:22:09 <Guest34007> so that I can test performence of both
07:22:43 <ertes-w> read about MVar for locking
07:22:57 <ertes-w> and IORef is just a mutable variable, in which you can store an IntMap
07:23:12 <Guest34007> what is an IntMap
07:23:31 <Guest34007> is this a map 
07:23:50 <ertes-w> it's like (Map Int) in purpose, but much more efficient
07:24:37 <Guest34007> key value 
07:25:12 <Guest34007> ertes-w: okay thanks a lot for helping me quickly
07:25:21 <ertes-w> https://hackage.haskell.org/package/containers-0.5.10.2/docs/Data-IntMap-Strict.html
07:26:38 <ski> makalu : you'd have to allocate storage for a `Ptr ()', somewhere (just like in C)
07:27:05 <makalu> ski: I found 'with' in Foreign.Marshal.Utils
07:27:34 <ski> a `Ptr ()' is just a value. `&x' in C doesn't work on a(n) (r-)value `x', only on an l-value
07:28:11 <ski> @type Foreign.Marshal.Utils.with
07:28:12 <lambdabot> Foreign.Storable.Storable a => a -> (GHC.Ptr.Ptr a -> IO b) -> IO b
07:28:22 <ski> makalu : *nod*, that probably allocates on a stack somewhere
07:29:05 <makalu> yeah it's alloca + poke and Ptr() is Storable so it should work I hope :)
07:29:26 <mnoonan> writing up this report, I'm realizing what a boon for testing parametric polymorphism is. knowing that I can swap in some simpler type for unit testing without affecting behavior seems like a big deal. does anybody have a reference to an article or blog post making this point that I could quote?
07:29:41 <ski> (the dynamic extent of that ends when the callback ends. if that's not enough for you, you'd have to allocate more permanent storage, perhaps using `new :: Storable a => a -> IO (Ptr a)')
07:30:02 <ski> makalu : sounds likely :)
07:31:20 <Guest34007> ertes-w: which will be better for locking thing according to my problem MVar or STM
07:32:02 <ertes-w> Guest34007: most likely MVar
07:33:40 <Guest34007> ertes-w: with MVar can I do .... like if I will lock for say min of either 30 secs of all present updates then I will read and this process continues
07:34:21 <Guest34007> ertes-w: 30 secs or (all present updates)
07:35:17 <Guest34007> ertes-w: I wanted to say that ... I want reading should no longer wait then a fixed time ...
07:37:34 <ertes-w> Guest34007: can you read while updating the array?
07:39:04 <Guest34007> ertes-w: no ... but if I have batches of update and reading request also then for reading I want to wait max for a time k units only then updation should be done only after reading
07:40:11 <Guest34007> ertes-w: can I do that ... with a mutable vertor one thread reads that and other updates concurently ... is that possible
07:40:25 <ertes-w> Guest34007: you're overengineering, and that will likely come at a cost of its own
07:40:40 <ertes-w> benchmark locking vs. IntMap first
07:40:48 <Guest34007> whats the cost here ...
07:41:15 <ertes-w> well, you can do multiple reads with a single lock, so i guess it would be fine
07:42:05 <Guest34007> okay ..Thank you ... I'll try
07:54:53 <tabaqui> if I have pointer to some finished thread
07:55:15 <tabaqui> can it be valid in the future?
07:55:40 <tabaqui> I mean, it is just a bunch of int's somewhere inside
07:57:43 <ertes-w> tabaqui: what's the type of that pointer?
07:57:49 <tabaqui> in general, is use-after-free possible in haskell?
07:57:57 <tabaqui> ThreadId#
07:58:32 <c_wraith> tabaqui: it's easy when misusing the FFI
07:58:43 <c_wraith> tabaqui: if you're not using the FFI, I can't imagine how you'd manage it.
07:59:11 <c_wraith> (The whole reason touchForeignPtr exists is to prevent use-after-free issues)
07:59:33 <tabaqui> what I really want:
07:59:55 <tabaqui> I'm writing with resourceT monad and want to spawn many child threads with finalizers
08:00:39 <tabaqui> and I'm not sure what happend if a thread has finished and global finalize will be called
08:01:10 <tabaqui> it tries to kill thread that is already dead for a long time
08:01:33 <tabaqui> *happens
08:02:29 <geekosaur> the finalizer will be run when the thread is gc-d. it is not part of some global finalizer list
08:02:43 <geekosaur> this is not C, the only memory managed by malloc/free is that used by FFI
08:03:52 <geekosaur> an object will only be gc-d if there are no live references
08:04:19 <geekosaur> so use after free can only happen with bad FFI coe
08:04:47 <tabaqui> yeah, sorry
08:04:55 <tabaqui> a didn't mean forkFinally
08:05:20 <tabaqui> allocate (fork doSmth) (\tid -> killThread tid)
08:05:25 <tabaqui> *forkIO
08:05:47 <infinisil> Hmm, I'm having a bit of a problem with Socket/Handle's: My goal is to have a server make TCP connections to clients, and as soon as 2 clients are connected call a function to start a game between the two
08:05:50 <tabaqui> when the flow leaves the monad it will kill the thread
08:06:16 <tabaqui> but the thread can finish by other reason and will be killed again in the future
08:07:08 <infinisil> And I'm not sure how to handle disconnects properly
08:07:43 <infinisil> I'm converting sockets to handles for easier handling, the I can use the blocking hIsEOF to see if it got closed
08:07:58 <tabaqui> infinisil: I impelement barrier with MVar () in such cases
08:08:02 <tabaqui> like:
08:08:07 <nshepperd> GHC.Conc.Sync has this to say: "/Note/: in GHC, if you have a 'ThreadId', you essentially have a pointer to the thread itself.  This means the thread itself can't be garbage collected until you drop the 'ThreadId'. This misfeature will hopefully be corrected at a later date."
08:08:16 <tabaqui> control <- newEmptyMVar
08:08:33 <tabaqui> forkFinally (handle first) (const $ putMVar control ())
08:08:38 <tabaqui> forkFinally (handle second) (const $ putMVar control ())
08:08:42 <tabaqui> takeMVar control
08:09:36 <tabaqui> nshepperd: this is funny, I've asked about a week ago
08:09:37 <infinisil> hmm alright I'll digest this
08:09:56 <tabaqui> I have a service with 3 months uptime
08:10:14 <tabaqui> and it didn't collect any child thread
08:10:25 <nshepperd> I'm not sure what that means exactly. it sounds like it actually keeps more of the thread data alive than it needs to
08:10:50 <tabaqui> looks like "void . forkIO" is pretty safe
08:13:20 <infinisil> tabaqui: Wait, so this terminates whenever one of the two threads terminates?
08:14:00 <geekosaur> yes, whichever thread finishes first will putMVar and your takeMVar will wake up
08:14:22 <geekosaur> that said, this sounds like it might be a use case for async package?
08:14:45 <dminuoso> Wow.. I think I just had a revelation laws. The monad laws.. they seem to just state: "kleisi arrows form a category"
08:14:46 <tabaqui> dunno, async in haskell totally sucks
08:14:52 <user3> hello I am confusedbetween https://lagunita.stanford.edu/courses/course-v1:Engineering+Algorithms1+SelfPaced/about   and haskell.....Should I learn algorithms first or haskell if my aim is to become very better programmer
08:14:59 <nshepperd> probably want tryPutMVar rather than putMVar there so that the second thread to terminate will be reaped
08:15:07 <dminuoso> Is my assessment correct?
08:15:09 <tabaqui> nshepperd: you're right
08:15:51 <tabaqui> and I usually add some tag in the mvar
08:16:05 <tabaqui> like takeMVar >>= logError
08:16:28 <tabaqui> *takeMVar control >>= logError
08:16:37 <nshepperd> oh, actually if you have only two threads it's fine but tryPutMVar is needed for three or more 
08:16:49 <infinisil> Hmm.. not sure if that's really what I need, I'll try to explain a bit better
08:17:08 <nshepperd> (with two threads the second one would finish after the main thread does takeMVar)
08:17:14 <dminuoso> Considering: (return >=> g ≡ g) and (f >=> return ≡ f), this looks just like (id . f ≡ f) and (g . id ≡ g), and (f >=> g) >=> h ≡ f >=> (g >=> h) is basically just the categorical associativity of arrows.
08:17:32 <user3> hi experts please kindly answer me
08:17:35 <dminuoso> Which makes me wonder whether there was a concious choice of the >=> operator to even look like an arrow.
08:18:35 <ski> dminuoso : yes
08:19:10 <infinisil> An idea I had was to have a lazy clientList :: [ Handle ], which would contain all clients ever connecting, produced by some foldl or so. Filter this list by handles that are open and get 2 of those
08:19:14 <nshepperd> dminuoso: yeah. you know there is instance Monad m => Category (Kliesli m) too
08:19:27 <dminuoso> nshepperd: No way. :o
08:19:32 <nshepperd> newtype Kliesli m a b = Kliesli (a -> m b) of course
08:19:45 <ski> (not sure about the `(>=>)' question. i.e. probably it was meant to look like some kind of arrow. but i'm not sure whether that has any relation to morphisms in categories also being known as "arrows")
08:21:09 <infinisil> I actually wrote a function acceptHandles :: Socket -> IO [Handle], but when I use it my main thread it obviously blocks
08:21:26 <ski> dminuoso : .. i assume you know that in terms of `do'-notation, the laws amount to allowing "obvious refactoring"
08:22:13 <ski> in terms of `return' and `join' (and also `fmap'), the laws are somewhat more involved .. but correspond to the laws of a moniod (in a more abstract sense)
08:22:19 <dminuoso> ski: Well I've done some refactoring using functor and applicative laws. But this just hit me from a categorical perspective.
08:23:07 <dminuoso> So in order words `m a` is exactly then a monad, if the set of all (a -> m b) forms a category?
08:23:19 <ski> the Kleisli category perspective is nice to know about. it's probably easier to get a feel for the laws in terms of `return' and `(>=>)', than in terms of `return' and `(>>=)'
08:24:03 <ski> `m a' is not a monad, `m' may be, when the kleisli construction over `m' yields a category
08:24:14 <ski> (s/may/will/)
08:26:38 <ski> (the kleisli construction being : starting from an endofunctor `M' over a category `C', we attempt to specify a new category by : objects should be the objects of `C'; a morphism from `A' to `B' should be a morphism from `A' to `M B' in `C'; further, identity morphisms, and morphism composition needs to sbe specified; and finally the laws checked for these)
08:27:05 <user3> I am badly ignored :( May be very welll intrested topic going on ok carry on guys :)
08:27:29 <infinisil> user3: You didn't ask a question..
08:27:36 <infinisil> OH you did
08:28:09 <user3> yup some thinbg experts can answer 
08:28:52 <infinisil> user3: Go for what you have motivation for
08:29:02 <ski> user3 : i suppose you could probably take either first. both sounds useful
08:29:05 <infinisil> only then you'll become a good programmer
08:29:29 <infinisil> mostly
08:29:50 * ski recalls getting interested in algorithms and data structures, after reading about a few examples of such, in a book about assembly language programming
08:30:07 <ski> (i didn't know what the topic was called, only that "i want to learn more about this kind of stuff")
08:30:51 <user3> ski:  both at a time ?? Haskell and algorithms together ? I can go one after another as my time is limited :(
08:31:09 <ski> one after another should be ok
08:31:30 <user3> which one should be first
08:31:35 <ski> perhaps both at the same time, if you think you can handle it, wrt time and motivation
08:31:40 <user3> haskell I heard it takes 2 years to learn 
08:31:43 <ski> whichever you fell like
08:31:51 <ski> s/fell/feel/
08:32:19 <ski> i suppose the Haskell course is only an intro to FP ?
08:32:33 <ski> or does it assume that you already know something about algorithms ?
08:32:38 <ski> you should check that
08:33:24 <user3> ski:  no it is only algorithms not haskell 
08:33:35 <user3> haskell I am learning seperately 
08:34:02 <ski> no, i mean : does the Haskell course assume you already know something about algorithms ?
08:35:36 <user3> ski:  which haskell course you are saying? I have haskellbook (first prinnciples)
08:36:15 * ski has no idea which Haskell course(s) user3 is considering to take
08:37:39 <user3> ski:  not any course just read from book
08:37:58 <ski> ok
08:37:58 <user3> but only that algorithm course I find...haskell I find none
08:38:13 <user3> on google I came to know haskellbook is best
08:38:26 <ski> you could try
08:38:28 <ski> @where CIS194
08:38:28 <lambdabot> http://www.seas.upenn.edu/~cis194/spring13/
08:40:41 <ski> also don't hesitate to ask questions here (or perhaps #haskell-beginners)
08:40:47 <MarcelineVQ> he has haskell from first principles he says, cis194 while the best free resource is pretty bare in comparison
08:41:29 <haskellCat> hey, can anyone recommend a haskell library for parsing CSV files?
08:41:46 <ertes-w> haskellCat: cassava works fine
08:41:51 <haskellCat> thanks
08:42:19 <ski> well, they asked for a course
08:42:20 <MarcelineVQ> rather the issue here is he's asking life advise about what he's able to learn best, and how that will help him later on, as if anyone could know. user3, all you can do is try either resource and see how it goes.
08:42:51 <MarcelineVQ> ski: hmm, I didn't see them ask for that but alrighty
08:43:04 <ski> <user3> ski:  which haskell course you are saying? I have haskellbook (first prinnciples)
08:43:13 <MarcelineVQ> he's asking which one you're talking about hehe
08:43:50 <user3> Sorry for the confusion
08:44:15 <ertes-w> user3: do you know a language other than haskell?
08:44:26 <ski> i didn't talk about anyone in particular, but as they seemed to be interested in courses, i mentioned CIS194
08:45:05 <user3> Yes
08:45:06 <ski> (s/anyone/any course/ .. before mentiong that one, of course)
08:45:16 <ski> user3, which ?
08:45:30 <user3> I like course than books 
08:45:48 <ertes-w> user3: reason i'm asking is that you might want to know how to program at the very least before you start with algorithms and data structures
08:46:10 <user3> ertes-w:  I know html/css/js 
08:46:53 <ventonegro> Then the "haskell from first..." is a good choice, there are no prerequisites
08:47:03 <ski> you may already have heard this, but be prepared that learning a programming language based on a different programming paradigm (such as Functional Programming), takes more time than learning a new language in a paradigm you already know. it's better if you come with the fresh mindset of learning programming from scratch (though it's not quite that extreme, of course)
08:48:11 <ertes-w> also learning haskell might actually ruin you for JS…  however, learning about algorithms and data structures will have a similar effect =)
08:48:47 <user3> I mostly do js by googling
08:49:01 <user3> I just know syntax
08:49:27 <ventonegro> user3: Just don't skip the exercises in the book, and you will learn Haskell, 99% guaranteed
08:49:38 <user3> I hardly did 5 websites so far
08:49:48 <ertes-w> it's a common coding strategy with JS
08:50:07 <EvanR> you dont know the entirety of the DOM API etc ?
08:50:13 <EvanR> by heart? geez
08:50:33 <user3> no I didnt basic websites 
08:50:56 <user3> there is something called learnyounode there learnyoujavascript
08:50:57 <ertes-w> EvanR: the answer to that question changes daily
08:51:02 <user3> I finished that course
08:51:16 <user3> its interactive
08:51:21 <user3> and 13 exercises
08:51:39 <ertes-w> the more interesting question is: "what?  you don't know how 'this' works?"
08:51:41 <user3> but I feel its not making me a good programmer
08:51:54 <user3> since my problematic thinking not good
08:52:13 <ertes-w> user3: algorithms and haskell will, both in very different ways
08:52:46 <user3> So on lot of google I found that algorithms course and I heard algorithms will make me better programmer also I heard haskell make be better programmer but I see blogs like haskell in 5 years etc
08:52:49 <user3> which is scary
08:53:00 <ertes-w> one will help you with implementation, the other will help you with engineering
08:53:35 <user3> what is implementation? and how different to engineering...which is to real world
08:54:05 <geekosaur> haskell has many levels. you can learn the basic levels relatively quickly. but advanced techniques aren't necessarily difficult; advanced haskell is a moving target 
08:54:24 <geekosaur> ghc is both a production compiler and an experiment in advanced type theory
08:54:46 <geekosaur> so the high end continues to grow
08:54:50 <ertes-w> engineering means the way components are composed and their interfaces, implementation means the exact way your components do their work
08:55:30 <ertes-w> you might call the former "software design"
08:57:12 <geekosaur> (and nobody's going to expect you to know the advanced type theory. I don't think any undergrad courses even acknowledge its existence)
08:57:12 <user3> geekosaur:  I dont want to study for marks/degrees
08:57:33 <geekosaur> right, my point is you don't care about the 5-years-to-master stuff
08:59:08 <user3> thank you all
08:59:36 <ski> user3 : it's good to have a mindset that you're never done with learning, there's always something new to learn. but that doesn't mean that you're not capable to do anything interesting somewhat soon
09:00:11 <ski> (s/to do/of doing/)
09:04:05 <aplainzetakind> In the 99 problems, I can't for the life of me see a difference between problems 46 and 47.
09:06:26 <lyxia> There doesn't seem to be one
09:07:14 <lyxia> the solution only mentions precedence...
09:07:29 <aplainzetakind> lyxia: That's a relief.
09:08:19 <Hafydd> The difference seems to be that in 47 they are defined "as operators", which is probably more notable a difference in Prolog than in Hasekll.
09:08:47 <Hafydd> Presumably, in Haskell, it means "as infix operators".
09:09:26 <aplainzetakind> Well I didn't even engage how the argument function might be defined in 46. I built lines of a, b, f a b, where a b runs over all possibilities. Is that missing the point of the question?
09:09:51 <lyxia> maybe it would be clearer if and' and or' were renamed to &&. and ||.
09:11:12 <lyxia> aplainzetakind: that's fine, though it could be shorter
09:11:34 <ski> is there a link to these problems ?
09:11:38 <MarcelineVQ> you can define fixity for `and'` just as well as && so I guess that's what they'd like :X
09:11:40 <MarcelineVQ> ski: https://wiki.haskell.org/99_questions/46_to_50
09:11:46 <ski> ty
09:13:18 <user3> ok thnak yu ski  I agree "Learning and working" are directly proportial to production of the world..the moment we stop learning/woprking we stop ourself from the growth/production of the world :)
09:16:20 <ski> (hm, for the Prolog solution of problem 46, i'd had used forall/2 and a conditional, rather than failure-driven loops and cuts)
09:19:10 <ski> Hafydd : i don't think it's more of a notable difference in Prolog than in Haskell. one difference is that any symbol/atom in Prolog can be declared infix, not just ones consisting of symbolic characters, as in Haskell. but i don't think that matters much here
09:28:13 <srpx> Hello, could someone link me a paper explaining when recursion is "obviously terminating" on the λ-calculus? Sure, structural recursion is, but that involves algebraic datatypes. I'm looking for the most general case where it is "obviously safe" on the λ-calculus itself
09:28:29 <srpx> I Googled for "positive recursion" and similar terms, but got a lot of unrelated results
09:28:43 <srpx> Perhaps there is a better keyword for what I'm looking?
09:29:23 <EvanR> lambda calculus doesnt have recursion
09:29:36 <AWizzArd> What is that “Constraint” doing here? I asked ghci    :k Monad    and it gave me:   Monad :: (* -> *) -> Constraint
09:29:40 <anks> Hi, how would I most efficiently split Lazy Bytestring into chunks, n-bytes each? I have already used splitAt, but it seems unefficient :(
09:30:41 <geekosaur> AWizzArd, it means it's suitable for use on the left of a =>
09:30:57 <EvanR> why does splitAt seem inefficient
09:31:37 <geekosaur> AWizzArd, https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#the-constraint-kind
09:32:04 <AWizzArd> thx
09:32:07 <dminuoso> EvanR, but what about fixed point combinators?
09:32:15 <dminuoso> You can trivially rig LC with recursion through them
09:32:26 <EvanR> its still not recursive in some way
09:32:33 <anks> i've had it profiled, and a simple function that split all input into 20bytes chunks takes 11% of time
09:32:37 <EvanR> so i dont understand the question precisely
09:32:38 <dminuoso> Im really curious now. Can you explain in what way?
09:33:19 <EvanR> anks: im not sure what that proves, 89% its doing what else?
09:33:41 <EvanR> you could modify the rest of the program to make those percents anything
09:34:34 <anks> it's true but, it barely do anything, and it's one of the most costly operation
09:34:43 <anks> does*
09:34:44 <EvanR> compared to...
09:35:13 <anks> parsing frames of data 
09:35:20 <anks> building bytestring representations
09:35:39 <EvanR> parsing is expected to be more costly? im not sure i understand the science behind this
09:36:39 <EvanR> a lazy bytestring is a lazy list of strict bytestrings, you can get at that list with toChunks and do your own splitting algorithm
09:37:06 <EvanR> but thats what splitAt is doing
09:37:06 <anks> well, im chunking 20MBs of data and it takes 0.5 secs, is it reasonable?
09:38:16 <EvanR> why dont you read 20 bytes from input at a time
09:38:36 <EvanR> and not deal with a single lazy bytestring at all
09:39:03 <anks> that's an idea, going to check if this have better performance
09:39:03 <anks>  
09:39:37 <anks> thanks
10:24:48 <superpat[m]> Hi everyone, I've been using UTCTime for timestamps and I'm happy with it, but I was wondering what date / time package would be best to represent planned start / end dates for something like events. I'm guessing Data.Date?
10:30:16 <EvanR> superpat[m]: for date + time of day, you can use LocalTime or ZonedTime if you also want to save an offset
10:30:57 <EvanR> but since events take place in a specific place, LocalTime might make more sense
10:32:37 <monochrom> There is actually no one-size-fits-all answer since "event" is still too broad.
10:33:29 <EvanR> i was thinking concerts, parties, activities
10:33:34 <monochrom> Suppose I'm in Toronto and I set an alarm at 8AM. Then I bring it with me and fly to Hong Kong. Should the alarm sound at 8AM HKT or should it be 9PM HKT?
10:33:36 <Samo_svoj> if i write simple fib function and compile - can I expect that compiled code will run in parallel automatically or I have to manually write such code?
10:33:39 <EvanR> a giant money maker right now
10:33:46 <monochrom> Right, and I'm getting to that too.
10:34:04 <geekosaur> Samo_svoj, you have to write that code
10:34:26 <Samo_svoj> geekosaur: so it meand ghc will compile for one thread?
10:34:54 <monochrom> Suppose I'm in Toronto and enter "December 1 7PM concert". But I will be in Hong Kong. How do you know whether "December 1 7PM" refers to EST? HKT?
10:34:54 <geekosaur> automatic parallelization as a discipline still only works in a limited number of cases. ghc doesn't even try.
10:35:46 <monochrom> So actually IIRC iPhone actually lets you specify which one you mean. Because the programmer just doesn't know.
10:35:48 <EvanR> the concert is in hong kong so
10:35:49 <superpat[m]> EvanR : My planned use case is to store a date from an html datepicker (in elm to be precise)
10:36:02 <EvanR> by date you mean date + time
10:36:29 <simendsjo> I'm trying to find an elegant way to do the following. I have an [a] and an [a->b], and I would like to end up with [[b]] where I run all a->b for each a. Just doing x <*> y would give me [b], and I could chunk this by the length of my [a->b], but I imagine this could be written better. Any tips?
10:36:31 <cocreature> that sounds like the user picks it so you probably want to use the timezone of the user
10:36:51 <monochrom> The thing is I'm entering the entry when I'm in Toronto, and only my brain knows I mean HKT.
10:37:03 <EvanR> in isolation, no one knows anything
10:37:14 <monochrom> Right, that's what I'm saying.
10:37:22 <EvanR> i was suggesting that for the specific case of located events, the local time makes more sense, as long as you know where it is
10:37:26 <monochrom> The programmer can't make the decision. You have to ask the user.
10:38:07 <EvanR> the time planes leave and land are given in the local time of the location they leave from and land in
10:38:17 <cocreature> simendsjo: not particularly clever but imho definitely better than chunking afterwards: \fs xs -> map (\f -> map f xs) fs
10:38:29 <cocreature> @pl \fs xs -> map (\f -> map f xs) fs
10:38:29 <lambdabot> flip (map . flip map)
10:38:33 <mlehmk> local time is ambiguous
10:38:37 <cocreature> ugh
10:38:46 <monochrom> What mlehmk says.
10:39:17 <mlehmk> in case of daylight savings time, when the clock is turned back, there's the same hour in a day twice
10:39:30 <monochrom> If you see "December 1 7PM concert in Hong Kong" you know. But who's going to enter that much?
10:39:30 <EvanR> no, its fine
10:39:39 <pierrot> Hi. I have written the following code: http://sprunge.us/fagG. It compiles but it shows the warning "No explicit implementation for ‘GHC.Base.fmap’ • In the instance declaration for ‘Functor Tree’". What does it mean and how can I get rid of it?
10:39:57 <mlehmk> Keep time in UTC or as a DateTimeOffset
10:40:06 <EvanR> LocalTime is not the same as local time
10:40:07 <mlehmk> datetime + offset from UTC
10:40:08 <cocreature> pierrot: you need to indent fmap
10:40:40 <EvanR> UTC is good if you are dealing with times that need to be compared across the world
10:41:02 <mlehmk> and LocalTime is broken in zones that have daylight savings
10:41:09 <EvanR> no it isnt
10:41:36 <ski> pierrot : you must indent the definition of `fmap' there
10:41:58 <mlehmk> I was just checking, yes it is
10:42:07 <erisco> simendsjo, I would start with something like  \fs xs -> fmap (\x -> fmap (\f -> f x) fs) xs  and simplify from there
10:42:45 <EvanR> if a recurring event happens at 3 PM every single day (no one does DST crap at 3 PM) then this data is local time, UTC would complicate this by having to deal with DST
10:42:55 <pierrot> Thanks, cocreature and ski. Now that I've indented it, it shows a different error "‘fmap’ is not a (visible) method of class ‘Functor’"
10:42:57 <ski> pierrot : if you enable the `InstanceSigs' language extension, you can also uncomment that type signature for `fmap'
10:43:18 <cocreature> pierrot: can you show us the full error please? (in a paste)
10:43:20 <ski> pierrot : don't hide `fmap' in the `import'
10:43:41 <mlehmk> but a recurring event at 1:30AM or 2:30AM depending on timezone could happen twice or never
10:43:48 <mlehmk> or 0:30AM
10:43:49 <EvanR> that does not come up in practice
10:44:11 <ski> (i suppose it suggested hiding it, because you attempted to define a new `fmap' (unrelated to the `Prelude.Functor' one). but as you wanted to make an instance of `Functor', you probably should not hide `fmap')
10:44:17 <EvanR> we should not impose programmer sensibilities on the poor people who live in abstract times we dont agree with
10:44:19 <geekosaur> pierrot, since fmap is a method, you don't need or want to hide it on import
10:44:21 <EvanR> in the first place
10:44:26 <geekosaur> it needs to be visible
10:44:48 <pierrot> Thanks, ski, cocreature and geekosaur 
10:45:02 <mlehmk> it's enough proof of ambiguity of LocalTime and thus why it is broken
10:45:15 <EvanR> uh huh
10:46:23 <EvanR> there is a situation where it is tricky, and its when asking the user to choose a UTC time that is shown to them as local time
10:46:27 <EvanR> then you have a problem with DST
10:46:28 <simendsjo> cocreature: erisco: Thanks. I'll see if I can get something working
10:46:52 <mlehmk> another would be arrival or depature times in LocalTime
10:47:00 <EvanR> if you ask them to choose a LocalTime, there is no inherent problem with that
10:47:12 <EvanR> it depends on what you will need it for
10:47:15 <cocreature> simendsjo: note that erisco’s solution and mine are different. one will group by the functions first and one by the list
10:48:06 <EvanR> planes dont depart during DST shifts :)
10:48:17 <superpat[m]> Since my api is going to get most of its data from an elm frontend, perhaps I should be looking at it from  whatever date format (a hypothetical datepicker I havent built yet) would output
10:48:30 <mlehmk> if a flight arrives at 2:30AM on the last Sunday in Octobre in Berlin, when is that?
10:48:42 <EvanR> arrival is not as bad i think
10:49:18 <ski> also, it seems weird that you can't use a qualified name (in binding position) for a method binding, in an `instance' declaration
10:49:20 <EvanR> if the airline has the arrival time in UTC, you can show them the duplicated local time
10:49:21 <ski> apparently, if you qualify the class name, it seems the method names (in binding positions) are implicitly qualified with the same module name/alias
10:49:32 <mlehmk> if I tell you it is 2:30AM CEST, you'll know
10:49:37 <EvanR> youll get there when you get there
10:50:06 <EvanR> departure time though
10:50:26 <mlehmk> because it is a local time with timezone offset, that's the missing piece of information to eliminate the ambiguity
10:50:42 <EvanR> if you want all that information, just use UTC
10:52:17 <EvanR> unlike numbers, which we can seemingly talk about and process without regard to what theyre for, all the time types heavily depend on the use case
10:52:48 <EvanR> ah the humanity!
10:54:12 <superpat[m]> Thanks for the thoughts guys, I'll think about it a bit more, but I think I'm leaning towards UTC
10:55:14 <mlehmk> and approx. 99.99% accuracy
10:56:31 <pierrot> ski: I added some comments to the function of the other day. I also chose a more descriptive name to the function which does the polymorphic recursion (`closestUpperPair') : https://glot.io/snippets/evgnn93c7j
10:56:41 <pierrot> it looks even nicer now :)
10:59:52 <ski> ok
11:00:03 <pierrot> well, even a better name would have be `closestUpperOrEqualPair'
11:00:07 <pierrot> but it's a bit long
11:00:12 <pierrot> been*
11:05:44 <[exa]> wasn't that called lower_bound?
11:11:40 <mud> That's c++'s name for it anyway. At least its concise
11:13:41 <pierrot> it doesn't make sense to talk about the "lower bound" of an *element* in a poset. bounds are usually defined for subsets.
11:19:43 <Tuplanolla> fg
11:19:49 <ski> bg
11:19:54 <Tuplanolla> Finally this happened to me too.
11:21:13 <Tuplanolla> > (^.^)
11:21:15 <lambdabot>  Delightful!
11:41:58 <ph88> what does this mean "we can now express logic directly in the robot’s programming" in http://newartisans.com/2012/08/meta-programming-with-the-free-monad/ ?
11:42:12 <crucify_me> hi is it typical (good form) to start with a pattern match and go into guard cases like this? thanks https://ptpb.pw/Tbyn
11:43:14 <c_wraith> crucify_me, that pattern is common, yes. I'll skip pointing out details of how silly that example is.
11:43:32 <ski> i'd say it's nicer to replace the guards by two defining equations there. replacing `x' with `False'
11:44:08 <ski> (possibly replacing `x' with `True' (or `_') in the other one)
11:44:50 <ski> if you have guards that aren't better represented using pattern-matching, then sure, that looks sensible
11:45:47 <crucify_me> c_wraith, please critique, I was trying to do it differently than other solutions online that I peeked at.
11:45:50 <crucify_me> thanks ski
11:46:17 <c_wraith> well, (== False) is the same as not
11:46:42 <crucify_me> cool thanks
11:46:55 <c_wraith> and really, it's way easier to just use (&&)
11:47:48 <crucify_me> please paste it c_wraith if you have time
11:48:03 <crucify_me> I like the not
11:49:37 <c_wraith> I mean, the second equation can just be "... = x && andd xs" in a single clause.
11:50:21 <c_wraith> and the whole thing reduces to (foldr (&&) True) if you want.
11:51:37 <crucify_me> foldr yes I could do a one-liner thanks c_wraith 
11:52:15 <c_wraith> anyway, I thought the original question deserved an answer independent of those things.
11:52:43 <c_wraith> since it was a good question, and getting distracted by the example might be unhelpful
11:52:45 <crucify_me> well, yeah my solution was valid and using not is a lot prettier
11:53:13 * ski raises eyebrow
11:53:21 <crucify_me> why ski
11:53:37 <ski> how are you using `not' here, such that it would be a lot prettier ?
11:54:03 <c_wraith> replacing x == False with not x
11:54:30 * ski waits for crucify_me to confirm
11:54:49 <crucify_me> yeah its nicer
11:55:11 <crucify_me> but I don't like && , guess I need to start using it.
11:55:12 <ski> why not swap the order of the guards, then, negating the condition ?
11:55:48 <ski> (imho, `(&&)' is even nicer here, if you're going away from the explicit matching on booleans version)
11:56:51 <crucify_me> well yeah, (foldr (&&) True) is very nice as per c_wrai*th
11:57:05 <EvanR> all ?
11:57:39 <ski> `all id' looks a bit silly, considering this is an implementation of `and'
11:57:46 <EvanR> oh
11:57:48 <ski> (it might be different in a strict language)
11:57:49 <EvanR> and
11:58:18 <ski> (but even without `foldr', with explicit recursion, i think `(&&)' is nicer than using a guard)
11:58:38 <crucify_me> never used all - its early in the textbook
11:58:51 <crucify_me> ski please paste since I can't write it
11:58:51 <ski> @src all
11:58:51 <lambdabot> all p = and . map p
11:59:01 <ski> crucify_me : paste what ?
11:59:35 <crucify_me> your version of (&&) if its unlike c_wrai*th
12:00:05 <ski> oh. it isn't
12:01:06 <ski> just pointing out a preference over using boolean operation, over explicit conditionals (guards, or `if'-`then'-`else', or `case'-`of' for that matter)
12:01:19 <ski> s/over using/of using/
12:02:17 <crucify_me> cool thanks. I'm just looking for say 3 solutions so I can compare. what do you call it when you go for absolute minimum chars in a solution for brevity, ad nauseum ?
12:02:19 <ski> a use of a bare boolean literal in a branch can usually be reformulated in a nicer way
12:02:48 <vaartis> Hey, i have a question about strange optimizations (?) and Async. Basically the thing is, my function returns the type State <state_record> IO (), and the final statement in the do block is the main thing 
12:02:50 <ski> crucify_me : sillyness ?
12:03:25 <vaartis> So when i just return my main action, nothing happens, it doesn't run
12:03:44 <crucify_me> please paste example of bare boolean branch to reformulation ski. I can't quite follow your thought
12:03:45 <vaartis> BUT if i add `return ()` to the end of the do, it works fine
12:04:02 <vaartis> Any idea why this is happening?
12:04:51 <ski> crucify_me : `if foo then True else bar' is equal to `foo || bar', `if foo then bar else False' is equal to `foo && bar'. `if not foo then bar else baz' is equal to `if foo then baz else bar'
12:06:34 <vaartis> https://paste.kotobank.ch/paste/YF56GE
12:06:43 <vaartis> (the code)
12:07:25 <crucify_me> thanks, yeah well if then else is barbarian even to this beginner
12:07:32 <beryl-stone> is earley the standard library for parsing cfgs? 
12:10:26 <vaartis> Also, building with "stack build --fast" does not help. I am really confused about this
12:11:12 <crucify_me> @src
12:11:13 <lambdabot> src <id>. Display the implementation of a standard function
12:11:29 <crucify_me> @src all
12:11:29 <lambdabot> all p = and . map p
12:11:38 <crucify_me> sorry ski I don't get this ^
12:12:38 <dminuoso> Is there some way of knowing whether a given code path does unsafePerformIO?
12:13:00 <geekosaur> dminuoso, no
12:13:41 <ski> crucify_me : it's equivalent to `all p xs = and (map p xs)'. understanding that requires first understanding `map'
12:13:48 <dminuoso> geekosaur, not even a sneaky language extension?
12:14:01 <geekosaur> not even
12:14:20 <[exa]> dminuoso: grep?
12:14:28 * ski . o O ( `Safe' )
12:14:49 <geekosaur> well, there is that I guess, but that operates on module level not individual code paths
12:14:52 <mud> hlint :)
12:14:57 <mud> But ya, that
12:15:41 <crucify_me> ski thanks yeah fiddling with that...
12:15:43 <dminuoso> [exa], fair enough. I guess Ill `rg` the modules. :)
12:15:46 <dminuoso> Thank you.
12:16:19 <ski> > all (> 5) [7,15,9]
12:16:21 <lambdabot>  True
12:16:26 <ski> > all (> 5) [7,15,3,9]
12:16:28 <lambdabot>  False
12:16:48 <[exa]> dminuoso: I'm not sure about how common unsafePerformIO is, but running through dowloaded cabal packages can't hurt :]
12:16:55 <ski> @check all (> 5)
12:16:57 <lambdabot>  *** Failed! Falsifiable (after 3 tests and 2 shrinks):
12:16:58 <lambdabot>  [-1]
12:17:06 <cement> how similar are cassava and aeson in terms of usage?
12:17:53 <cement> nvm, looks like they're nearly the same thing
12:19:21 <vaartis> > (the code)
12:19:22 <vaartis> also, it seems that replacing mapTasks_ with mapTasks also solves the problem
12:19:23 <lambdabot>  error: Variable not in scope: the :: t0 -> terror:
12:19:23 <lambdabot>      • Variable not in scope: code
12:19:23 <lambdabot>      • Perhaps you meant one of these:
12:31:53 <crucify_me> so ski ...
12:32:16 <crucify_me> https://ptpb.pw/zvUP  obviously I am confused this won't work for test the list
12:32:23 <crucify_me> testing*
12:34:45 <erisco> @check all (\x -> x /= 12345)
12:34:47 <lambdabot>  +++ OK, passed 100 tests.
12:36:25 <Tuplanolla> @check \ xs -> reverse xs == xs
12:36:27 <lambdabot>  +++ OK, passed 100 tests.
12:36:45 <maerwald> the only quickcheck test that is actually elegant
12:37:03 <crucify_me> https://ptpb.pw/zvUP  anyone tell me how this works using all ?
12:38:12 <monochrom> You are on to a false start when you wrote "annd p" instead of "annd xs".
12:38:49 <crucify_me> monochrom, thanks hold on please
12:39:07 <monochrom> Oh w00t 8.2.2 RC3
12:39:28 <monochrom> Oh I guess that's old news.
12:41:21 <monochrom> No this is not old news. This is very strange. The email announcements of RC2 and of RC3 have both the same timestamp "Tue, 31 Oct 2017 14:15:24 -0400" this is a mystery!
12:41:58 <crucify_me> @src all
12:41:58 <lambdabot> all p = and . map p
12:42:02 <monochrom> bgamari: Achievement unlocked: Your RC3 announcement email has the exact same timestamp as your RC2 email announcement!
12:45:02 <xertrov> hey - Came here to ask a quick question - I have a vague memory of an online spreadsheet that used haskell syntax for formula in cells, and it might be written in GHCJS or Haste (can't remember) - can anyone point me in the right direction? Googling around FP and spreadsheets isn't bringing anything up
12:48:24 <shapr> xertrov: alphasheets
12:48:42 <bgamari> monochrom, heh, yes, I noticed
12:49:03 <bgamari> monochrom, I noted the peculiarity on the Reddit thread
12:49:25 <bgamari> I wasn't sure whether to spam people's inboxes with yet another message to fix the issue
12:49:57 <bgamari> message-mode apparently doesn't elide the Date: field before sending a message
12:51:35 <crucify_me> monochrom is the body just all xs or is that some sort of curry ?
12:51:41 <MarcelineVQ> crucify_me:   all p = and . map p     can be read as    all p xs = and (map p xs)
12:52:43 <crucify_me> thanks MarcelineVQ what is p there?
12:53:39 <MarcelineVQ> the first argument to all
12:53:41 <MarcelineVQ> :t all
12:53:42 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
12:53:51 <MarcelineVQ> so it's a function of  (a -> Bool)
12:54:05 <crucify_me> thanks working...
12:54:30 <xertrov> @shapr - Thanks! I had "powersheets" in my head.. close but no cigar
12:54:30 <lambdabot> Come on, let's all slap - Thanks! I had "powersheets" in my head.. close but no cigar
12:54:47 <MarcelineVQ> hoho, shapr you're a slapper :>
12:55:14 <monochrom> @shapr monochrom
12:55:15 * lambdabot beats up monochrom
12:55:18 <monochrom> :)
12:55:36 <crucify_me> but the function is annd :: [Bool] -> Bool so how do I write that to test if all members of a list are True ?
12:55:40 <monochrom> There is a reason I say "the iron fist of shapr" :)
12:57:28 <MarcelineVQ> crucify_me: in that case you already have Bool so you'd need a function which trivially returns its argument
12:58:04 <MarcelineVQ> in haskell this is called  id :: a -> a   and it looks just like you might guess,  id x = x
13:00:05 <crucify_me> MarcelineVQ, I wrote this and had it critiqued, this other stuff with all Im confused about
13:00:09 <crucify_me> https://ptpb.pw/Tbyn
13:03:16 <monochrom> You may like to think of "all p [a,b,c]" as "p a && p b && p c".
13:03:18 <MarcelineVQ> I've got to eat lunch, try to come up with a specific question people can help you along with though
13:04:56 <crucify_me> thanks I'm always confused. 
13:15:30 <MarcelineVQ> you didn't come up with a question :(
13:18:54 <verement> @src all
13:18:54 <lambdabot> all p = and . map p
13:19:12 <verement> @src and
13:19:12 <lambdabot> and = foldr (&&) True
13:22:51 <EvanR> is it possible to write any list function using foldr
13:24:19 <dsal> @src any
13:24:19 <lambdabot> any p = or . map p
13:26:15 <dsal> I wonder if minimum short circuits.  I'd assume not, but  minimum seems like a pretty simple way to write all.
13:27:10 <monochrom> minimum doesn't short-circuit. minimum uses Ord, but Bool's Ord doesn't short-circuit.
13:27:20 <monochrom> > False <= undefined
13:27:22 <lambdabot>  *Exception: Prelude.undefined
13:27:35 <dsal> I'd have to special case Bounded
13:27:37 <monochrom> > minimum [False, undefined]
13:27:39 <lambdabot>  *Exception: Prelude.undefined
13:27:48 <monochrom> So it's a bit unfortunate.
13:28:02 <ski> i think so, EvanR
13:29:19 <ph88> what does this mean "we can now express logic directly in the robot’s programming" in http://newartisans.com/2012/08/meta-programming-with-the-free-monad/ ?
13:29:21 <monochrom> ski's answer causes me to rethink and now I remember Lambek's lemma which says that there is a roundabout way to go from foldr to arbitrary pattern matching so yeah the rest is history.
13:29:59 <ski> what's that lemma ?
13:33:07 <dsal> @check ((\x -> minimum x == all id x) :: [Bool] -> Bool)
13:33:09 <lambdabot>  *** Failed! Exception: 'Prelude.minimum: empty list' (after 1 test):
13:33:09 <lambdabot>  []
13:33:10 <monochrom> http://www.cs.ox.ac.uk/publications/publication2360-abstract.html  Section 2.5.5
13:33:16 <dsal> minimum can't minimum nothing
13:33:43 <dsal> But all says that all of nothing is True.
13:40:42 <monochrom> Because "all" actually knows it's doing Bool.
13:43:46 <nshepper1> minimum :: (Ord a, Bounded a) => [a] -> a could return maxBound on empty list, as well as shortcutting. But that might be a controversial choice
13:52:42 <monochrom> Actually these days with the totality policing, Ord a => [a] -> a is the controversial one, the totality police prefers (Ord a, Bounded a) => [a] -> a and Ord a => NonEmpty a -> a
13:52:42 * ski . o O ( refinement types )
13:53:42 <ph88> did anyone see this yet ? http://chriswarbo.net/git/haskell-te/
13:58:41 <nshepper1> Would be quite wasteful though, checking (==minBound) for each element
13:58:46 <nshepper1> In most applications
13:59:13 <ski> monochrom : ty for that paper link
14:53:04 <hexagoxel> ph88: a late reply to the free monad article question: the author means something along the lines of "a (free) monad is more expressive than a list of instructions", which is true, but the example does not really show that.
14:53:32 <ph88> ah ye .. i already felt i was missing something :P
14:54:06 <ph88> hexagoxel, can i pick your brain on another issue? maybe you have an idea how to solve it
14:55:51 <hexagoxel> for a more interesting example, your functor needs some constructor that looks like `data MyFunctor = .. | Obtain (Bool -> next)`
14:56:52 <hexagoxel> now your interpreter must provide a Bool to continue, and your free-monadic-value can depends on this value that is not known before interpretation-time.
14:58:37 <hexagoxel> eh, that is `data MyFunctor next = ..` of course
14:59:12 <ph88> ok but would that be hard to write otherwise without Free Monad ?
15:01:37 <hexagoxel> yes, i don't think it is possible. You can of course "inline" your Functor into the definition of `Free`, but really that does not change that the thing is a free monad.
15:02:20 <hexagoxel> e.g. the list-of-instructions approach does not work
15:04:35 <ph88> hhmm ok i can't really imagine it yet .. i would need to try it sometimes. But ok it's useful for interpreting ..
15:05:25 <hexagoxel> yeah, i usually need to apply these constructs at least once in a non-trivial fashion to get a grip.
15:08:43 <codeshot> hexagoxel, if a free monad is more expressive than a list of instructions then how do we implement a free monad in a computer that interprets a list of instructions
15:09:21 <johnw> codeshot: you could interpret your free monadic construction as a list of instructions
15:09:31 <johnw> once you use the word 'implement', you're not thinking free-ly anymore
15:12:52 <hexagoxel> if you consider `foo >>= \b -> if b then executeA else executeB`, that already is not a list-of-instructions.
15:13:36 <johnw> it's a list of instructions with conditional branching, the same as what you'd emit for x86 assembly
15:13:50 <hexagoxel> yeh, exactly.
15:14:09 <johnw> so, your list-of-instructions has limits I wasn't aware of then
15:15:26 <hexagoxel> if that was the IO monad and ghc knows how to translate that, then ghc already has the power to translate this kind of branching to assembly.
15:15:54 <hexagoxel> johnw: i meant "instruction" more in the sense like it is used in the article about free monads.
15:17:20 <hexagoxel> of course if you have labels and conditional jumps in that instruction-set then the thing is turing-complete already, probably :)
15:17:53 <hexagoxel> well, you need some infinite memory, too.
15:21:47 <Guest73194> I have a situation where I have a type like `Mailbox {send :: a -> IO (), getNext :: IO a}`, and I want to make it a Functor (or something similiar) such that I can map over it and change what "a" is
15:22:07 <mniip> that's not a functor
15:22:11 <Guest73194> This is too strong for a Functor, because I need to map both covariantly and contravariantly
15:22:23 <Guest73194> mniip: Yup, definitely agree
15:22:30 <Guest73194> Now I am aware of Profunctors
15:22:38 <mniip> it's not that either
15:23:30 <mniip> there's a (possibly poorly named) Invariant functor class in some package
15:23:34 <mniip> https://hackage.haskell.org/package/invariant-0.4.3/docs/Data-Functor-Invariant.html
15:23:49 <Guest73194> It could be, couldn't it? Squinting our eyes, we could see mapping covariantly (a -> b) and contravariantly (b -> a) to establish a Mailbox b?
15:24:30 <Guest73194> Since "send" requires b -> a before sending and "getNext" requires a -> b before returning?
15:24:31 <mniip> no
15:24:40 <mniip> you'd need Mailbox to be a binary type constructor
15:24:55 <mniip> which is a fine solution tbh
15:25:06 <Guest73194> sure. Let's say it is, Mailbox a a
15:25:10 <Guest73194> is there any other issue you see?
15:25:12 <mniip> Mailbox a a'
15:25:34 <mniip> well yes, then it's a profunctor
15:27:26 <Guest73194> Right. But then -- regardless of if I use Profunctor or Invariant and adjust the type parameters accordingly, which is certainly possible:
15:27:57 <Guest73194> is there no way that I can establish a bijection between the two types and pass that as an argument, instead of two mapping functions?
15:28:33 <Guest73194> Because really, there's only one piece of information here: what maps to what? Since in both cases, it's b and a interacting
15:29:06 <Guest73194> I'm using bijection a little too loosely actually, I guess I more mean a two-way mapping
15:32:49 <mniip> you could use lens's Iso
15:33:07 <mniip> :t iso
15:33:08 <lambdabot> (Functor f, Profunctor p) => (s1 -> a1) -> (b1 -> t1) -> p a2 (f b2) -> p s2 (f t2)
15:34:27 <Guest73194> hmm, that's pretty cool, thanks for pointing me to it
15:35:06 <Guest73194> I guess what I'm thinking of just isn't quite do-able, two-way mapping expressed as a single function would end up just containing the two way mapping inside it...
15:35:26 <Guest73194> Thanks though, you helped me realize that what I'm doing doesn't quite make sense
15:35:51 * geekosaur thinks thtis sounds like nothing so much as a van laarhoven lens...
15:40:36 <hexagoxel> (was hackagebot disabled on purpose?)
15:50:58 <pierrot> Why `Foldable' is called that way? What's the intuition behind that?
15:51:28 <LKoen> because the function 'fold' can be applied to such a type
15:51:44 <pierrot> yes, but what does "fold" mean?
15:52:39 <LKoen> you can fold a list onto itself to get a result that depends on all of its elements
15:54:14 <lyxia> pierrot: It means to transform a structure into a more compact form.
15:55:12 <dsal> I wouldn't say "more compact" -- it's a catamorphism.  Many folds will lose information.
15:55:20 <dsal> I guess that'd make it a "lossy compression"
15:55:28 <ClaudiusMaximus> > foldr (+) z [a,b,c,d]
15:55:30 <lambdabot>  a + (b + (c + (d + z)))
15:56:01 <c_wraith> a catamorphism can easily have a larger output than input.
15:56:28 <ClaudiusMaximus> > foldr (:) [] [a,b,c,d]
15:56:30 <lambdabot>  [a,b,c,d]
15:56:31 <dsal> Heh, technically, that's true of many compression things, but yeah.  I wouldn't think of it that way in general.
15:56:37 <spakhm> wait what happened there?
15:56:54 <spakhm> how did lambdabot print the expansion?!
15:57:03 <dsal> Yeah, that magic is kind of freaking me out.
15:57:04 <ClaudiusMaximus> Debug.SimpleReflect
15:57:17 <spakhm> > foldl (+) z [a,b,c,d]]
15:57:19 <lambdabot>  <hint>:1:22: error: parse error on input ‘]’
15:57:21 <Axman6> :t a
15:57:22 <lambdabot> Expr
15:57:24 <spakhm> > foldl (+) z [a,b,c,d]
15:57:24 <Axman6> :t f
15:57:25 <lambdabot> FromExpr a => a
15:57:26 <lambdabot>  z + a + b + c + d
15:57:30 <Axman6> :t f a
15:57:31 <lambdabot> FromExpr t => t
15:57:44 <dsal> Oh.  Ha
15:57:46 <spakhm> what is going on?!
15:58:07 <geekosaur> @hackage simple-reflect
15:58:07 <lambdabot> http://hackage.haskell.org/package/simple-reflect
15:58:07 <ski> a catamorphism "tears down" structure. it may also build up some other structure, in the process
15:58:08 <Axman6> it's just a simple package for showing expressions
15:58:11 <spakhm> > foldl (+) 1 [1, 2, 3, 4]
15:58:14 <lambdabot>  11
15:58:27 <pierrot> lyxia: thanks. I was expecting something like that. dsal: yeah, I understand that it's a lossy compression 
15:58:36 <Axman6> > foldr (+) z [1,2,3]
15:58:37 <ski> otoh, an anamorphism "builds up" structure (possibly while tearing down other structure)
15:58:38 <lambdabot>  1 + (2 + (3 + z))
15:59:15 <ski> > foldr f z [a,b,c]
15:59:17 <lambdabot>  f a (f b (f c z))
15:59:19 <ski> > foldl f z [a,b,c]
15:59:21 <lambdabot>  f (f (f z a) b) c
15:59:34 <ski> > a^5
15:59:36 <lambdabot>  a * a * (a * a) * a
15:59:37 <spakhm> how does it know to expand the expression rather than interpret it as an error?
15:59:46 <ski> @type a^5
15:59:47 <lambdabot> Expr
15:59:48 <Axman6> there is no error?
15:59:51 <geekosaur> I just pointed at the package that does it
15:59:55 <geekosaur> :t a
15:59:56 <lambdabot> Expr
16:00:10 <spakhm> ah, I see
16:00:25 <geekosaur> all the single-letter names are bound by default to simple-0reflect's Expr type in one way or another (some of them are bound to function types on Expr instead)
16:00:28 <geekosaur> :t f
16:00:29 <lambdabot> FromExpr a => a
16:00:37 <ski> @type f :: Expr
16:00:38 <lambdabot> Expr
16:00:41 <ski> @type f :: Expr -> Expr
16:00:42 <lambdabot> Expr -> Expr
16:00:44 <spakhm> that's really clever
16:00:44 <ski> @type f :: Expr -> Expr -> Expr
16:00:45 <lambdabot> Expr -> Expr -> Expr
16:00:49 <ski> @type f :: (Expr -> Expr) -> Expr
16:00:50 <lambdabot> (Expr -> Expr) -> Expr
16:00:54 <ski> oh, nice
16:01:04 <ski> > fix f
16:01:05 <lambdabot>  error:
16:01:06 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M643128217739...
16:01:06 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
16:01:27 <ski> > fix f :: Expr
16:01:30 <lambdabot>  f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f...
16:01:49 <lyxia> cute
16:02:32 <ski> > f (id :: Expr -> Expr) :: Expr
16:02:34 <lambdabot>  f <Expr -> Expr>
16:02:35 <ski> heh
16:06:39 <benzrf> > fix error
16:06:41 <lambdabot>  "*Exception: *Exception: *Exception: *Exception: *Exception: *Exception: *Ex...
16:17:28 <jle`> pierrot: in one sense, foldl' is a fundamental operation for Foldable's.  basically Foldable provides a way to 'iterate' though items and collapse them into a single result
16:17:57 <jle`> :t foldl
16:17:59 <lambdabot> Foldable t => (b -> a -> b) -> b -> t a -> b
17:29:01 <pierrot> jle`: Yes, I know that. But since I'm not a native English speaker, I couldn't find any relation between what `fold' does and its name. The Spanish equivalent is "plegar", but it didn't make sense to me "plegar una estructura de datos".
17:31:14 <pierrot> But now I understand better. It's kind of a compression similar to then when you fold your clothes.
19:01:02 <plakband> I'm using a Haskell function as a callback from C (using inline-c). When declaring it, I can call it just fine, but when it's called as a callback, it's returning garbage and its side-effects don't fire. Could it be that function is garbage collected (even though it's a top-level declaration) in the meantime?
19:21:48 <junktion>  
19:22:29 <shae> junktion: HI
19:23:20 <Axman6> plakband: functions don't get garbage collected
19:23:46 <Welkin> they get recycled
19:24:14 <Axman6> has the function been exported? also are you initialising the haskell runtime system at the beginning of your program (If you're running haskell, which calls C which calls back to Haskell you should be fine)
19:24:59 <plakband> well, I don't have an export list and it's in my exposed-modules, so yes?
19:25:06 <plakband> and yeah, it's called from Haskell
19:25:39 <plakband> Or rather, Haskell wraps inline-c, which calls Haskell
19:25:44 <Axman6> you may need to do a foreign export declaration (this is not a module export, it's similar to what you do to import a C function to call from Haskell)
19:26:09 <plakband> I see
19:26:20 <plakband> do I just search for foreign export declaration?
19:26:40 <Axman6> you should read https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ffi-chap.html#using-the-ffi-with-ghc to begin with I think
19:26:56 <plakband> alright, i'll give that a read, tyvm
19:27:58 <Axman6> I'm not sure how much inline-c performs for you though
19:32:27 <junktion> shae: oops, hi
20:05:12 <shostakovich> when recursively constructing data types that change depending on the codepath, how do I get all the types to match? 
20:05:15 <shostakovich> example: https://hastebin.com/mexoleturu.erl
20:05:41 <shostakovich> Depending on how nested the expressions are, the final "state" type produced could be arbitrary
20:06:10 <shostakovich> so I can't just do an Either over all the types because this could produce infinite potential state types
20:07:07 <pacak> shostakovich: Suppose you did it and you got a value of some unknown type. What are you going to do with it?
20:07:27 <i_minify_users_p> Hello!
20:07:42 <i_minify_users_p> Could someone help me with installing intero on arch>
20:07:43 <i_minify_users_p> ?
20:07:50 <i_minify_users_p> configure is giving me an eror?
20:07:53 <i_minify_users_p> damn, typing is hard
20:07:59 <i_minify_users_p> *configure is giving me an error
20:08:30 <Axman6>  shostakovichis that Erlang?
20:08:38 <shostakovich> pacak: I would see if the machine accepts some input
20:08:54 <shostakovich> Axman6: It's just some haskell typedefs, but pseudocode/simplified
20:09:59 <pacak> shostakovich: How would you do that? You want to get a function :: String -> a and you don't know your a  upfront. What are you going to do with it?
20:10:16 <Axman6> this may be possible using GADTs
20:11:01 <shostakovich> pacak: well I don't have to worry about the state types when I run it, it just takes [Glyph] and returns True or False
20:11:28 <shostakovich> pacak: the input could well be Machine state glyph where both are type variables (not sure if that's the right word)
20:11:29 <pacak> shostakovich: So types are not arbitrary then, it's :: [Glyph] -> Bool...
20:11:44 <pacak> Or  rather String -> [Glyph] -> Bool
20:12:03 <pacak> Yes?
20:12:24 <shostakovich> pacak: I don't understand
20:12:48 <shostakovich> pacak: there's, Machine state glyph, and a function accepts :: Machine state glyph -> [glyph] -> Bool
20:12:56 <pacak> what is "codepath" you mention?
20:13:06 <shostakovich> but state and glyph are arbitrary, they could be Int, [Int], (Int, Int) etc
20:13:23 <shostakovich> I meant the way it recurses through the Ands or Ors before hitting the "base case"
20:16:07 <pacak> I'm still having problems understanding the question.
20:17:28 <shostakovich> pacak: so I want to create a Machine corresponding to some formula like ((b > d) and ((y == z) or (z < a)))
20:17:41 <i_minify_users_p> Does anyone know why I might be getting "configure: error: cannot run C compiled programs." when building "terminfo-0.4.1.0" while running "stack build intero" on Arch?
20:17:57 <shostakovich> I can construct primitives, ==, <, and > correspond to "Machine Int Bitvec" as a concrete type
20:18:37 <shostakovich> then for an and, I just intersect the two machines together - forming, perhaps, Machine (Int, Int) Bitvec if the children were primitives
20:19:06 <pacak> Machine? Is that like an AST for computation? What are a, b, d, y, z?
20:19:23 <shostakovich> in my case they're finite automata
20:19:38 <shostakovich> for now we could think of those as literal numbers
20:21:12 <Axman6> i_minify_users_p: you'll need to look at the logs to see where the C compile failed
20:33:12 <i_minify_users_p> Where's the log? Stack directs me to config.log, but I can't find that. Configure failed after "checking whether we are cross compiling", though
20:43:54 <shostakovich> pacak: random thought, would it help if the definition was instead Machine (StateWrapper state) glyph? where state may differ but the type of the entire thing will always be StateWrapper?
20:45:39 <pacak> shostakovich: You can work with polymorphic state machine but you need to provide functions to deal with state and glyphs
20:47:48 <shostakovich> pacak: what do you mean by polymorphic?
20:48:19 <pacak> shostakovich: I mean it can still be of type state/glyph
20:59:59 <ClaudiusMaximus> how do sparks interact with bound threads and FFI with unsafePerfomIO ?
21:00:46 <ClaudiusMaximus> ie, can i be sure that if i evaluate something in a bound thread its unsafePerformIO FFI will be in the same OS thread even with sparks?
21:01:02 <ClaudiusMaximus> (actually, does it even hold for unsafePerformIO without sparks?)
21:01:35 <ClaudiusMaximus> i know the performance will be poor (no parallelism due to serialization to one OS thread) but correctness is issue here
21:02:34 <ClaudiusMaximus> this is for dealing with a library with thread-local flags (similar to errno, used for almost the same purpose)
21:03:43 <pacak> Spark threads are created on free capabilities and they steal work. I don't think you can tell which os thread to use for sparks.
21:16:35 <geekosaur> ClaudiusMaximus, I think you want https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.10.0.0/Control-Concurrent.html#v:forkOS
21:17:06 <geekosaur> if you need even more control there is https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.10.0.0/GHC-Conc.html#v:forkOn
21:20:17 <ClaudiusMaximus> geekosaur: yes that's why i mentioned bound threads
21:20:43 <ClaudiusMaximus> geekosaur: i wanted to know how those two functions interact with sparks and unsafePerformIO
21:22:49 <geekosaur> unsafePerformIO should not matter unless you are forking a new thread in there (in which case you likely deserve whatever happens; I'd expect it to not be pretty, TLS or no)
21:23:59 <geekosaur> and the whole point of forkOS is to ensure the created spark runs and does its FFI on the same OS thread
21:25:05 <ClaudiusMaximus> ok, i wasn't sure if it was just the thread's FFI or also any sparks spawned by that thread
21:25:39 <ClaudiusMaximus> thanks!
21:26:22 <geekosaur> sparks either fizzle or become new threads. what kind of thread depends on how they were created, but I don;t think you get any guarantees they'll share a capability
21:26:33 <geekosaur> use forkOn if you absolutely need that
21:27:31 <ClaudiusMaximus> ok
21:28:11 <geekosaur> I am not sure that is a wise idea, though; seems to me if you really need them to be on the same OS thread, you shouldn't be making new sparks at all
21:28:51 <ClaudiusMaximus> i doubt it will matter much in practice tbh, either you care about the error flags so much that you need to do the FFI explicitly in IO to ensure ordering of operations, or you're using the pure interface and hoping no errors are flagged
21:29:11 <geekosaur> after all, you aren't actually gaining much from it, because if they're forced onto the same capability, necessarily they can't run in parallel
21:29:26 <ClaudiusMaximus> this is an MPFR wrapper, for context - the error flags are things like overflow / underflow / imprecision
21:29:27 <geekosaur> at which point I wonder if you want ST instead
21:30:40 <ClaudiusMaximus> either i wrap all the functions at the C level to reset / restore and return the flags via pointers at every call, or i need bound threads
21:31:01 <ClaudiusMaximus> threadlocalstorage--
21:31:12 <geekosaur> my question is why the plural
21:31:32 <geekosaur> if you;re binding them to the same capability, there's no real point in having more than one Haskell thread
21:31:54 <geekosaur> if you were looking to isolate Haskell state (as opposed to TLS) then you likely want ST instead of multiple Haskell threads
21:33:26 <ClaudiusMaximus> i know, but i suppose there might be a case where a library wants to do some par stuff with (Num a => a), and the client of the library wants to be sure the MPFR error flags are all ok afterwards, and it breaks because even though the client called the library in a bound thread sparks ran on other OS threads...
21:34:07 <geekosaur> that makes me wonder what you think a spark is
21:34:08 <ClaudiusMaximus> i'm probably overthinking it, it's a modularity / reuse issue rather than anything major
21:35:32 <geekosaur> forkOS always creates a Haskell thread. forkIO defers it until it needs to run, and then checks if the work was already done by another thread (in which case it fizzles); this matters if you're, say, using par to map evaluation of (chunks of) a list across threads
21:36:17 <geekosaur> if you are using forkIO then all bets are off with respect to thread local storage anyway, so I don't see how sparks enter into it
21:36:21 <Axman6> you're mixing up threads and sparks
21:36:54 <Axman6> forkIO threads don't fizzle, sparks do
21:37:23 <geekosaur> forkIO creates a spark and only converts it to a thread if it doesn't fizzle, no?
21:37:57 <Axman6> forkOS locks a forkIO'd thread to a specific core (HEC?), necessary for calling some C APIs
21:37:57 <geekosaur> I was not pedantically clear on that, I admit, but I would have expected 'defers it ... in which case it fizzles' made that point
21:38:01 <Axman6> no
21:40:21 <Axman6> forkIO's threads will always be run, it doesn't make any sense to do anything else. sparks (which come from calling par) can fizzle when the value which has been sparked is being evaluated, it is found that the work has already be done. there's no connection between threads and sparks in this context
21:40:48 <geekosaur> mm, I thought that was pushed a level lower then
21:41:16 <geekosaur> I think sparks still don't enter into it though, if you're par-ing this stuff then all bets are still off
21:45:11 <geekosaur> (you can't force them to forkOn, and --- again --- if you replace par with your own that does, you aren't actually getting any parallelization)
21:45:34 <geekosaur> so why do sparks matter here?
21:46:57 <Axman6> because it's sparks which fizzle, not forkIO threads, you were getting confused by the two
21:47:19 <geekosaur> sorry I did not mean you
21:47:54 <ClaudiusMaximus> i know it won't be parallel, it's a modularity issue - and probably not that important anyway...
21:48:15 <geekosaur> ClaudiusMaximus was asking how sparks interact with bound threads, the answer is they are not bound and should not be used if bound threads are needed
21:49:31 <ClaudiusMaximus> geekosaur: thanks, that's clear - now seeing as sparks are pure, how to know which pure functions can/can't be used when bound threads are needed for any internal unsafePerformIO
21:51:06 <ClaudiusMaximus> i guess it's called unsafe* for a reason
21:51:17 <Axman6> yeah sparks can be stolen by any HEC at any time (work stealing queues)
21:51:39 <Axman6> so there's no way to know where a spark would run
22:03:48 <seafood> Can anyone here tell me about p_dyn_hi files?
22:03:55 <seafood> I really can't find much on Google about them.
22:04:05 <seafood> Obviously something to do with profiling.
22:08:31 <Axman6> if I had to guess I would say it's the profiling version version of a dynamically linked haskell interface file. Other than that, #ghc might be a good place to ask
22:44:56 <geekosaur> profiling, dynamic (as opposed to static) haskell interface files
22:45:33 <geekosaur> the .hi file contains type information and code exposed by the module for inlining in other modules
22:45:48 <jcarpenter2> why do my eyes roll whenever i see the word ByteString
22:45:53 <jcarpenter2> is this normal?
22:46:22 <geekosaur> do you imagine there is no other kind of string?
22:47:30 <jcarpenter2> no, but there's also String and Text
22:47:44 <jcarpenter2> it's like i'm always packing or unpacking something
22:48:00 <geekosaur> yes, well, files and network streams are bytestrings.
22:48:11 <mud> ByteString means something fundamentally different from String/Text
22:48:29 <geekosaur> it's conventional to try to hide the former, because they're not prone to switch encoding on you. network streams, however, do
22:57:34 <vaibhavsagar> how do I force stack to rebuild a certain package?
22:58:11 <jcarpenter2> stack exec -- ghc-pkg unregister [package]
22:58:24 <vaibhavsagar> I thought `stack exec -- ghc-pkg unregister <package> --force` would be enough, but immediately after stack tells me '<package>: using precompiled package'
22:58:40 <vaibhavsagar> observe: https://travis-ci.org/gibiansky/IHaskell/jobs/301803911
22:58:47 <jcarpenter2> interesting
22:59:19 <vaibhavsagar> the nuclear option is to clear all caches, which would lead to unbearable build times
22:59:24 <jcarpenter2> you could put it into the "packages:" section in stack.yaml
22:59:43 <vaibhavsagar> how would this help?
23:00:29 <jcarpenter2> because i'm fairly sure those are searched before the snapshot is searched
23:02:02 <vaibhavsagar> what if the package I want to rebuild is a dependency?
23:02:33 <jcarpenter2> it'll be pulled in from the location you specify in "packages"
23:03:47 <jcarpenter2> why do you want to rebuild the package anyway?  is it customized?
23:04:13 <vaibhavsagar> The travis build used to use zeromq4 built from source
23:04:34 <vaibhavsagar> now I'm switching to the apt-get version, but the compiled package expects the old location
23:04:48 <jcarpenter2> oh interesting
23:07:34 <jcarpenter2> it says "unregistering would break the following packages: ihaskell-0.9.0.1 ipython-kernel-0.9.0.0 (ignoring)"
23:07:44 <jcarpenter2> even though you used --force, which is strange
23:07:54 <jcarpenter2> either way, try unregistering all of those packages
23:07:59 <geekosaur> you'd have to find and nuke the cached version under .stack-work
23:08:02 <jcarpenter2> (and recurse as needed)
23:08:24 <jcarpenter2> or, does "ignoring" mean it's ignoring the problem, not ignoring your command
23:08:47 <jcarpenter2> i do not know
23:08:51 <geekosaur> this isn't going to help, stack keeps its prebuilt copies in a common location and copies them as needed to specific projects
23:09:03 <geekosaur> it ignored the problem and unregistered the package
23:09:12 <geekosaur> and stack will just copy its prebuilt back in next time
23:09:17 <geekosaur> and re-register it
23:12:59 <vaibhavsagar> stack build <package> --force-dirty seemed to fix my issue
23:16:07 <vaibhavsagar> jcarpenter2: '(ignoring)' means it's going ahead and unregistering anyway, despite the problems it would cause
23:31:35 <dminuoso> Other than f = f, is there any possible implementation for f :: a -> b ?
23:31:40 <dminuoso> I think parametricity tells me that this is the only thing one can do.
23:32:12 <mud> Other variations of bottom, but ya not much else.
23:32:12 <dminuoso> Because whatever that function does, it cant do anything type specific. And if it does not know about either type, the only thing f could know is that both types are inhabited by bottom.
23:32:29 <dminuoso> mud: Right.
23:34:12 <dminuoso> mud: Would this function be somehow related to absurd by any chance?
23:35:21 <dminuoso> :t absurd
23:35:23 <lambdabot> Void -> a
23:36:37 <dminuoso> I mean a -> b is general enough to be as least as absurd as that type.
23:38:13 <mud> It seems similar, in that  :: a -> b  would have to be able to allow a ~ Void
