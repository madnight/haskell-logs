00:12:50 <codeshot> nshepperd
00:13:02 <codeshot> interesting, is that defined for all haskell?
00:13:40 <codeshot> does that mean performance characteristics can change dramatically by just by adding polymorphism?
00:15:39 <codeshot> And does that mean memory will be consumed up to the highest input value just in case there's a later usage? I recall seeing a paper where Simon Peyton-Jones said ghc specifically avoids saving things in case it should be needed later.
00:16:17 <codeshot> anyway, I think fibs is polymorphic, the number type is free among Num
00:18:55 <codeshot> regarding the memoising limitation, I'm aware, I was just playing with someone else's structure. I might later apply some heuristic to memoise selected waypoints
00:19:55 <codeshot> hence the fixedpoint so I can trivially insert a conditionally memoising wrapper
01:04:51 <fakenullie> is there library for asynchronous (but not threaded) io?
01:05:11 <vaibhavsagar> does skylighting have support for cabal file syntax highlighting?
01:07:33 <fakenullie> oh, those not threads are not os
01:11:33 <qaz> Where's the reference to find such things like ">>=" or ".|." ?   I don't see them here: https://wiki.haskell.org/Keywords
01:12:08 <osa1> fakenullie: just compile your program without `-threaded` argument and your app will run in single OS thread (aka. async but not threaded)
01:13:23 <fakenullie> qaz: https://www.haskell.org/hoogle/?hoogle=%3E%3E%3D
01:13:33 <osa1> threads are how you do async programming in Haskell. whether your threads will scale across cores depends on -threaded compile-time option and `+RTS -N` runtime option.
01:13:33 <fakenullie> qaz: these are operators, not keywords
01:16:43 <c_wraith> qaz: notably, those are all library-defined operators.
01:20:46 <qaz> (>>=) :: forall a b. m a -> (a -> m b) -> m b
01:20:55 <qaz> and what is the dot after b?
01:21:39 <fakenullie> part of forall clause
01:21:53 <c_wraith> The terminator of the forall clause, in particular
01:22:24 <Maxdamantus> or possibly more accurately, the parameter list of the forall clause.
01:22:43 <Maxdamantus> Since the inner type expression is probably also considered part of the forall clause.
01:23:04 <Maxdamantus> (er, that is, the terminator of the parameter list)
01:25:58 <grahamperrin[m]> Hi, I'm not a programmer, just driving by with an observation that https://ghc.haskell.org/trac/summer-of-code/ticket/1548 – xmonad: compositing support – might be closed.
01:26:52 <grahamperrin[m]> – https://wiki.haskell.org/Xmonad/Frequently_asked_questions#How_do_I_use_compositing_with_xmonad.3F answers a frequently asked question about compositing.
01:29:20 <Maxdamantus> grahamperrin[m]: well, if it's using xcompmgr, xmonad isn't doing the actual compositing.
01:31:16 <grahamperrin[m]> Ah, thanks/sorry. I'm not familiar with the technologies. So it's probably safe to ignore my drive-by :-)
01:33:52 <jollygood2> hi. I am experiencing some weirdness. cabal install works fine but cabal repl throws and error. here's my minimal .cabal and main.hs and error http://lpaste.net/7300727667647578112
01:33:59 <jollygood2> an error*
01:34:16 <Maxdamantus> I imagine there could be useful functionality that could come from compositing support in xmonad.
01:34:25 <jollygood2> I'm using ghc  7.8.4
01:34:48 <Maxdamantus> eg, you could implement things like window selection, where all windows are shown at once, scaled down.
01:35:40 * Maxdamantus has been thinking recently about making a simple WM suitable for mobile devices.
01:43:25 <dysfun> many already exist
01:50:30 <jollygood2> cabal run works too. weird!
02:00:21 <cocreature> jollygood2: try upgrading ghc, 7.8 is quite old and I vaguely recall that a few linker errors in ghci have been fixed since
02:03:03 <jollygood2>  cocreature yeah I guess it is time. should I give stack a try too over cabal sandbox?
02:03:19 <jollygood2> I never used it before
02:04:16 <cocreature> if you’re already familiar with cabal I would probably stick with it until you have a reason to switch
02:07:00 <phadej> there's cabal new-build, which is cool
02:07:25 <phadej> cabal sandbox's are slowly but steadily deprecated
02:07:51 <jollygood2> what about new-build vs stack?
02:08:42 <jollygood2> I'll have to recompile all the sources anyway, so I might as well use something other than sandbox
02:09:16 <phadej> I'm biased, cabal new-build feels to (re-)compile stuff less than stack
02:09:55 <cocreature> at this point new-build is also more experimental than stack. it’s not too hard to hit things that simply don’t work yet in new-build
02:11:10 <phadej> cocreature: yes, and no. some things don't work in stack either, i.e. stack also isn't done :)
02:11:17 <jollygood2> I have a huge module where I put all my library code, that depends on ton of things, including gtk and lens. I should really split that into multiple libraries, but until I do, will either stack or new-build help not having to download and recompile all the libraries for each project that depends on my library?
02:11:34 <phadej> jollygood2: both will
02:11:40 <jollygood2> nice
02:11:56 <cocreature> phadej: sure but I don’t think claiming that stack and new-build are at the same level of completeness is fair
02:14:08 <cocreature> don’t get me wrong, I love new-build but I’m cautious when recommending it to others since I know about the things that don’t work yet
02:17:29 <cocreature> the nice thing is that at least for my usecases both stack and new-build are vastly superior to sandboxes so we’re definitely moving in the right direction :)
02:18:54 <phadej> cocreature: OTOH, if "we" don't start recommend cabal new-build to others, missing and unworking bits won't be discovered
02:19:12 <phadej> cocreature: personally, cabal new-build has all we need to do production code
02:21:08 <jollygood2> I like how stack installs appropriate ghc version and compatible modules for that version of haskell. does new-build do the same?
02:23:20 <jollygood2> also I often compile on windows, any preference on stack vs new-build there?
02:24:14 <cocreature> new-build doesn’t install ghc for you
02:24:45 <cocreature> no idea about windows, sry
02:25:25 <jollygood2> does it keep track on what libraries are compatible iwth what version of ghc? making your project ethernally compilable (in theory)
02:26:08 <jollygood2> if I understood correctly that is what stack gives you (together with install ghc for you, which is just a nice bonus but not a necessity)
02:27:29 <cocreature> by default, cabal does dependency solving based on the version constraints in the build-depends section in packages
02:27:54 <cocreature> but you should be able to get cabal.config files for the stackage snapshots stack uses and use those with new-build
02:29:26 <jollygood2> just one last question (promise :) ). I am currently using emacs, which works nicely with cabal sandboxes, giving me cabal repl inside emacs buffer, as well as type hints, function name completion, etc. would I have the same thing without any changes if I switched to stack or new-build?
02:30:00 <jollygood2> or to rephrase, do they you use cabal repl with them, or something else?
02:30:09 <jollygood2> do you use cabal repl with them*
02:32:53 <cocreature> afaik the stuff built into haskell-mode works with both new-build and stack. other tooling like ghc-mod doesn’t support new-buily yet (but ghc-mod does support stack)
02:34:04 <raindev> Those problems I had on Arch with packages in Cabal sandbox conflicting with globally installed packages: I'm happy to report that the problems do not exist on Gentoo.
02:34:27 <raindev> I can have a diffent version of a global package installed in a sandbox without any issues.
02:34:59 <jollygood2> is the final goal of new-build to replace stack? or are their aims different
02:35:46 <raindev> And Gentoo also uses dynamic linking for Haskell libraries so those problems seem to be unrelated to it.
02:36:21 <raindev> cc geekosaur
02:37:01 <cocreature> jollygood2: I don’t think so. at least for the near future, neither stack or new-build will disappear. they are developed by different groups and they focus on different things
02:37:08 <cocreature> and a bit of competition is nice :)
02:37:28 <cocreature> cabal development sped up significantly once stack was released :)
02:37:49 <raindev> So yeah, compiling GHC worth is :P It took 55 minutes on my laptop. I spent much more time debugging the issue on Arch.
02:38:10 * [exa] still waiting for hs-autotools
02:38:28 <raindev> ^The answer to EvanR's question
02:41:47 <raindev> [Sorry for throwing those messages out of blue. The context is in the history from the Friday night.]
02:52:33 <haskellnoob> Heyy all
02:55:56 <[exa]> eyy
02:57:59 <haskellnoob> yo [exa] 
03:06:38 <haskellnoob> hi if I learn multiple programming languages at the same time will it make me confused/or leave at no where?
03:07:14 <Tuplanolla> Not more than any other two things would. Why?
03:07:34 <raindev> haskellnoob: didn't work well for me :)
03:10:08 <haskellnoob> Haskell only one housr everyday due to personal interest and in office I want to learn python and also use python to implement small small algorithms  hope it doesnt make me bad styled programmer
03:25:16 <jollygood2>  i wantto give stack a try, should i just let stack install ghc for me? 
03:26:00 <jollygood2> askingfour both windows and linux
03:29:11 <cocreature> jollygood2: yeah, that’s the easiest solution
03:34:42 <jollygood2> I dont mind doing it the harder way if there are notable benefits
03:35:17 <cocreature> not really
03:38:21 <Tuplanolla> I have this problem, jollygood2: https://github.com/commercialhaskell/stack/issues/2885
03:43:24 <jollygood2>  I am about to try stack for the first time so I am afraid I cant help much
03:51:59 <troydm> after switching to latest lts mongoDB client driver started printing execution stats, anybody know how to disable it?
03:52:29 <troydm> I'm talking about this package http://hackage.haskell.org/package/mongoDB
03:56:48 <drdo> "This  function is only atomic if there are no other producers for this MVar."
03:57:06 <drdo> What does this mean in the documentation of modifyMVar_ ?
03:57:48 <Unhammer> Hi, I was hoping to make a simple project with haskell-gi, but it keeps crashing on simple stuff like using the file picker. Does anyone know what I'm doing wrong in https://github.com/unhammer/xcb-vs-gtk/blob/master/app/Main.hs that makes it crash like one out of 5 times? I've put the error messages I'm getting in https://github.com/unhammer/xcb-vs-gtk/#haskell-gi-crash-test-case (that repo should be
03:57:50 <Unhammer> possible to just git clone and
03:57:52 <Unhammer> build to test)
04:00:23 <lyxia> Unhammer: Did you forget to add a .cabal file
04:00:59 <Unhammer> oh foobar
04:01:49 <Unhammer> sorry, updated
04:04:20 <ph88> if i give --ghc-options to stack will it still use the options in the cabal file ?
04:04:42 <srhb> drdo: It's implemented in terms of takeMVar and putMVar
04:05:00 <srhb> drdo: meaning, someone else can putMVar after the first step.
04:05:12 <srhb> drdo: And now modifyMVar will block since the MVar is already full.
04:05:40 <srhb> drdo: (And the value stored there may differ from what modifyMVar took)
04:05:48 <drdo> srhb: oh, right, of course
04:06:14 <lyxia> ph88: yes
04:06:25 <ph88> ok thats good :P
04:06:27 <drdo> I still think that's a rather confusing statement to make
04:06:42 <Bor0> when one works with a specific system, say Peano, what other systems are assumed besides logic? e.g. Peano uses the notion of a function for successor definitionni
04:07:23 <ph88> talking about debugging ... is there a level between ghci trace and gdb ?
04:08:39 <cocreature> Bor0: the peano axioms are fully expressible in first-order logic
04:09:08 <ph88> what's first-order logic ?
04:09:41 <Bor0> cocreature, so both Peano+SetTheory and just Peano work?
04:09:45 <cocreature> ph88: I’m going to let you read the wikipedia page for yourself :P
04:09:49 <ph88> ok :P
04:10:00 <Bor0> ph88, it's propositional logic plus quantifiers
04:10:23 <cocreature> Bor0: what do you mean by “work”
04:11:01 <Bor0> I mean they can be represented in both systems. I am wondering how successor would look like without it being a function
04:11:22 <cocreature> I’m not sure where set theory suddenly comes into play here
04:11:54 <Bor0> so succ(n) is a function within Peano (which we can use set theory to represent, right?)
04:12:43 <Bor0> I guess my question is how "stand-alone" Peano is
04:13:02 <cocreature> you just need first-order logic to write down the axioms
04:13:22 <Bor0> how can we define succ by just using fo logic?
04:13:46 <cocreature> https://en.wikipedia.org/wiki/Peano_axioms#First-order_theory_of_arithmetic
04:14:22 <ph88> i keep reading that as piano
04:16:12 <cocreature> Bor0: note that first-order logic supports functions
04:16:34 <Bor0> oh, it does?
04:17:15 <Bor0> I was just gonna ask what is S in x + S(y) = S(x + y) :D
04:17:30 <cocreature> you can’t quantify over them (that’s why it’s called first-order) but you can talk about specific functions
04:17:59 <Bor0> is first-order logic independent of set theory?
04:19:56 <Bor0> hmm "The non-logical symbols represent predicates (relations), functions and constants on the domain of discourse. It used to be standard practice to use a fixed, infinite set of non-logical symbols for all purposes."
04:20:23 <Bor0> what I am trying to do is understand the hierarchy of formal systems
04:20:39 <jollygood2> as far as stack is concerned, is there any difference whether I uninstall ancient ghc I have installed directly (7.8.4) years ago?
04:20:45 <cocreature> Bor0: iirc you can formulate FOL without mentioning sets
04:21:02 <Bor0> it looks as if first order logic is the base but still depends on sets
04:21:11 <cocreature> and you can express zfc (if that’s what you mean by set theory) in fol
04:21:39 <Bor0> yes, ZFC :)
04:22:18 <Bor0> ok cocreature, this helps! thank you!
04:31:02 <lyxia> Unhammer: I've opened 15 files and see no crash, only lots of -3
04:31:15 <ph88> jollygood2, no
04:31:46 <mixxio70> ciao
04:31:54 <ph88> hai
04:32:06 <mixxio70> Hi
04:32:13 <Unhammer> lyxia,  odd … maybe related to gtk version? 
04:32:21 <Unhammer> heisenbugs :(
04:32:42 <mixxio70> !list
04:34:21 <Unhammer> libgtk-3-dev	3.22.24-0ubuntu1	for me at least
04:35:05 <Unhammer> (but thanks for trying lyxia )
04:40:39 <lyxia> Unhammer: I'm on arch if that helps.
04:42:56 <Unhammer> well, tht
04:43:10 <Unhammer> *that gives me hope :)
04:44:33 <Unhammer> (since then it might be a gtk bug that's been fixed in later versions)
04:44:33 <jollygood2> stack new project uses ghc-7.10.2. should I prefer that over 8.0.2? LTS Haskell 9.12 (ghc-8.0.2)
04:45:47 <jollygood2> my mistake, it uses lts-9.12 by default, which uses ghc-8.0.2
04:48:22 <jollygood2> as always my timing is bad.. stack will probably have long term support for 8.2.2 in a week :)
04:48:55 <MarcelineVQ> you can use a nightly and change it later if you desire 8.2
04:49:54 <MarcelineVQ> nightly is 8.2.1 though I I'm not convinced lts would have 8.2.2 within a week, unless some stack dev told you that
04:50:11 <jollygood2> I'm probably fine with 8.0.2. I had 7.8.4 until now
04:50:25 <jollygood2> no it was just a wild guess
04:53:39 <cocreature> unless you have a specific reason to use 8.2, I’d stick with the most recent lts and 8.0.2
04:57:05 <Unhammer> hm, arch has gtk 3.22.26
04:58:25 <jollygood2> so I have a project that already has its own cabal file and that I built using cabal sandboxes. I deleted sandbox, but now I'm not quite sure how to proceed trying to build it with stack. should I copy stack.yaml that I got from stack new test and leave project cabal as is?
04:58:49 <MarcelineVQ> you run  stack init  to make a stack.yaml for a project with a .cabal file
04:59:03 <MarcelineVQ> if it needs things from hackage you can run stack init --solver
04:59:36 <MarcelineVQ> Or edit your version bounds in the cabal file to match your chosen resolver
04:59:51 <MarcelineVQ> versions are here https://www.stackage.org/lts-9.12
05:15:29 <jollygood2> first attempt to build stack project failed :|. here's the cabal file and log where it failed: http://lpaste.net/359977
05:16:10 <jollygood2> full log: http://lpaste.net/359978
05:19:30 <jollygood2> seems to be relevant page: https://github.com/commercialhaskell/stack/issues/2617
05:21:16 <MarcelineVQ> yes or https://github.com/commercialhaskell/stack/issues/3492 which is the same issue it looks like but isn't listed as resolved
05:23:07 <MarcelineVQ> could try running your build command with -j1 to see if that reduces clashes, dunno
05:31:50 <jollygood2> running stack build again worked. so multiple threads attempting to access the same file seems to be the issue, like post on your link said 
05:39:08 <kuribas> I propose naming Monads as design patterns, to increase adoption by OO programmers: Monoid = combination pattern.  Foldable = reduction pattern,  Functor = transform pattern, Monad = effect propagation pattern, Traversable = effectful transform pattern, Applicative = effectful application pattern
05:40:38 <erisco> they might be confused, because patterns are not objects in the language
05:40:53 <srhb> Those are just pattern patterns.
05:41:34 <kuribas> OO paterns are objects?
05:41:41 <erisco> no
05:42:43 <erisco> how about I use the word "feature" instead of "object", for less confusion
05:44:18 <kuribas> erisco: I don't get what you are trying to say?
05:45:20 <erisco> you listed several type classes, but patterns are not features of the language
05:45:52 <liste> design patterns exist because OO languages lack the abstraction capabilities to actually implement the concepts in the language, so another, purely communication-based "layer of abstraction" is introduced
05:46:13 <erisco> the usual confusion is thinking type classes are like interfaces, and to some extent they are, except TCs are not types whereas interfaces are
05:51:04 <hexagoxel> liste: type class laws seem to be similarly communication-based.
05:54:00 <exio4> due to limitations in our current technology :) 
05:54:12 <exio4> (and mathematics?)
05:54:35 <exio4> proving the laws within the language is quite complex, and it might be non-trivial for certain instances
05:57:43 <erisco> no I think it is because it wasn't on the brain when the language was made, and if it was, or was since, then it has been argued it is too burdensome to use
06:12:54 <bennofs1> Is there some package for star semirings or kleene algebra?
06:13:53 <lyxia> @hackage star
06:13:54 <lambdabot> http://hackage.haskell.org/package/star
06:14:29 <lyxia> It's pretty new
06:17:31 <sm> jollygood2: using GHC 8.2 should fix it, eg stack install --resolver=nightly ...
06:30:00 <jollygood2> sm thanks I'll give it a try
06:30:25 <pzp> Anyone know how to best write a Parsec combinator for atLeast and atMost?
06:30:26 <jollygood2> if it works can I wipe everything stack downloaded for 8.0.2 somehow? to avoid extra space on my ssd
06:33:28 <hpc> atLeast n p = sequence (repeat n p) >> many p?
06:34:15 <hpc> (with changes depending on what you want it to return)
06:37:45 <hpc> atMost might be trickier
06:37:49 <hpc> er, and it's replicate, not repeat
06:38:21 <pzp> hpc: this is what I came up with for atLeast, but I think your way might be better https://www.irccloud.com/pastebin/OF8spjbR/
06:39:00 <pzp> atMost seems a bit tricky due to lookahead and what not
06:39:18 <hpc> yeah
06:39:20 <troydm> did anyone had probleming with csv parsing after lts upgrade?
06:39:42 <troydm> like now I can't parse data that previously parsed without issues
06:39:58 <troydm> and I think only because it has ,, empty values
06:40:31 <hpc> i think the first step to writing atMost is to have a better understanding of try
06:42:46 <pzp> hpc: That seems fair. I am wondering if I should just hardcode it this time since it's only atMost 3
06:43:15 <hpc> yeah, probably
06:43:42 <hpc> is it something simple like -v, -vv, -vvv in an arg parser, or some more complex parser?
06:44:30 <hpc> if it's relatively involved, i bet by hardcoding it to 3 you'll get pretty close to a general atMost
06:46:51 <Massy07> ciao
06:46:55 <Massy07> !list
07:05:43 <jollygood2> I'm using HXT to parse a webpage, and was wondering if there is a way to simplify this type signature? myParser :: ArrowXml t => t (NTree XNode) [Char]
07:06:02 <jollygood2> all the code I found online omits function signatures, but I'd prefer to have them
07:07:13 <jollygood2> is there a way to list all defined instances of class in ghci?
07:07:43 <hpc> probably :i
07:08:09 <hpc> yeah, :i works on both classes and types
07:08:24 <hpc> it'll only show what's in scope, obviously
07:10:05 <jollygood2> I found it. didn't help much as far as answering the question I asked above
07:11:12 <jollygood2> (simplifying  myParser :: ArrowXml t => t (NTree XNode) [Char])
07:16:53 <jollygood2> a bit nicer: myParser :: ArrowXml a => a XmlTree [Char]
07:20:25 <sm> jollygood2: yes, if you explore stack's directories you'll see the old ghc and old snapshot(s)
07:20:58 <jollygood2> sm ok nice
07:20:59 <sm> but stack's snapshots tend to depend on older ones, so it's probably best to wipe all and restart
07:21:11 <jollygood2> I see
07:21:18 <sm> all snapshots
07:23:46 <MarcelineVQ> jollygood2: be sure to try    :info!     if you're not seeing isntances you expect in :i
07:26:47 <MarcelineVQ> "<sm> but stack's snapshots tend to depend on older ones, so it's probably best to wipe all and restart" what do you mean by depend on?
07:30:29 <kamog> Is there a library function to compute function's graph on a list, like with the type (a->b)->[a]->[(a,b)]?
07:31:58 <sm> MarcelineVQ: if you wipe an old snapshot from disk, newer ones are likely to start giving errors
07:34:33 <jollygood2> I find hxt a bit weird to work with. what other web scraping libraries are recommended?
07:34:36 <MarcelineVQ> oh? never seen that, odd, I thought newer lts without actual package version changes are supposed to copy when a depends is requested, not simlink or otherwise. Guess nuking is easy enough if you've bandwidth to spare and not space
07:34:54 <MarcelineVQ> depends what you're scraping, json, html, xml?
07:35:36 <jollygood2> html
07:38:01 <sm> snapshots reuse a single on-disk copy of the package when they can, as you might expect
07:38:17 <MarcelineVQ> hmm I'd probably have a look at https://hackage.haskell.org/package/tagsoup first
07:39:05 <sm> I remember thinking it was safe to wipe previous LTS's, but I wouldn't bet on it
07:39:35 <cocreature> kamog: something like "\f -> map (\x -> (x, f x))"? that hardly seems to warrant a library :)
07:40:29 <dminuoso> What's the deal behind naming runIdentity runIdentity? I mean it doesn't "run" anything, or is this just about lazy evaluation?
07:42:09 <cocreature> dminuoso: it’s commonly used for unwrapping monad newtypes, e.g. runReader, runState, runIdentity, …
07:43:23 <kamog> cocreature: I use it quite often, so writing two lambdas is too much.
07:43:41 <cocreature> kamog: then just define it locally
07:44:27 <dminuoso> cocreature: Still, that doesn't explain the particular choice of the word "run" when it just unpacks
07:45:12 <cocreature> dminuoso: I think in general the idea is that it “runs the effects” whatever that means for a specific Monad instance. for Identity the effects are just nonexistent :)
07:45:12 <tinco> hi, how can I help GHC deduce this? it's generated by some TH code:
07:45:13 <tinco> Could not deduce (Data.Vector.Generic.Base.Vector V.Vector (Int, Float, Float, Float, Float, Float, Float)) arising from a use of ‘Data.Vector.Generic.Base.basicUnsafeFreeze’
07:45:15 <ggVGc> run == evaluate?
07:46:24 <ggVGc> tinco: we probably need a paste with some more context code to help
07:46:49 <dminuoso> cocreature: So it is just about forcing evaluation of the inner value, and thus about "running those effects" ?
07:46:53 <kamog> cocreature: locally as in a utility library or in each expression with let?
07:47:26 <cocreature> dminuoso: there is really not much to the name. trying to interpret too much into it only makes it more confusing :)
07:47:43 <dminuoso> cocreature: Fair enough :)
07:47:51 <ggVGc> what do you guys think about modern javascript taking "let" and turning it into "declare a local variable"
07:47:57 <tinco> ggVGc: http://lpaste.net/359987
07:48:15 <MarcelineVQ> locally as in a function in the same module or project, defining it for each expression defeats the purpose of avoiding the lamda really
07:48:27 <cocreature> ^
07:50:15 <kamog> MarcelineVQ: I need it when I use top-level as calculator to look at values of some functions, so there is no module
07:50:51 <MarcelineVQ> there's always a module, is this going in a .ghci file or something though you mean?
07:51:12 <kamog> oh, I can probably put code there!
07:52:13 <kamog> yes, it works
07:52:43 <tinco> could it be it could not deduce because the tuple is too long?
07:53:01 <tinco> it's (Int, Float, Float, Float, Float, Float, Float)
07:53:14 <ggVGc> I'm not exactly sure what's going on
07:53:51 <cocreature> it looks like vector only provides instances up to a length of 6
07:53:59 <tinco> ah
07:54:25 <cocreature> arguably you should me making a separate type anyway instead of using larger tuples :)
07:55:09 <ggVGc> purescript taught me that long tuples generally are not very good in the long run
07:55:50 <cocreature> although it is going to be annoying since even vector-th-unbox can’t save you for larger types since iirc it’s based on being able to convert to something that already has an instance
07:56:19 <tinco> yeah.. I just removed one value from the tuple and it compiled
07:56:54 <tinco> that's good, who needs that last value anyway :P
07:57:13 <ggVGc> I often wonder why languages need a type level and a value level language. seems to me it would be possible to unify
07:57:13 <tinco> thanks!
07:57:35 <ggVGc> but pretty much every programming language I've seen have basically two languages, including haskell
07:57:42 <cocreature> ggVGc: welcome to the wonderful world of dependent types :)
07:57:51 <ggVGc> cocreature: yeah I guess that's what it is
07:58:06 <cocreature> ggVGc: you might want to play around with idris if you’re interested in this
07:58:13 <ggVGc> yeah, been meaning to for a long time
07:58:22 <ggVGc> but you know, time and prioritites...
07:58:25 <ggVGc> priorities*
07:58:44 <cocreature> hm, do we have a package that creates Unbox instances that are not based on being able to convert to existing types that have an instance?
07:59:11 <cocreature> luckily I’ve not been in the situation where I had types with more than 6 fields that I’ve wanted to unbox but the next time I’d like to do this, I don’t want to have to write the instance myself
08:00:57 <tinco> wow my little thing went from using upwards of 20gb of ram to using about 130mb by switching to Vector.Unboxed
08:01:41 <cocreature> tinco: that sounds more like it fixed a space leak than the space savings you get from unboxing itself
08:02:26 <tinco> yeah my calculations indicated an optimal version would use about 400mb if it keeps the vector in memory
08:03:06 <tinco> not sure if it's actually working though, it's not printed any results yet
08:03:21 <cocreature> who cares if it’s correct as long as it uses less memory
08:03:25 <tinco> :D
08:03:25 <cocreature> :)
08:03:29 <tinco> oh it's printing
08:03:51 <tinco> nice, so max allocated mem was 460mb, that's pretty close to my estimate
08:04:10 <tinco> and it went from taking 15 minutes to ~4 minutes it seems
08:04:56 <tinco> still a bit long for my tastes, but certainly acceptable
08:06:18 <tiganu80> hi, can somebody explain why this code http://lpaste.net/359990 evaluates to ["apple", "banana"] and not ["banana", "apple"] ?
08:07:22 <lyxia> start with [], append "apple" at the end, ["apple"], append "banana" at the end, ["apple", "banana"].
08:08:26 <tiganu80> why start with append "apple" and not append "banana" ?
08:08:38 <tinco> I think that's because of how <*> is defined
08:08:56 <lyxia> indeed
08:09:08 <sm> and apples are in season
08:14:44 <tinco> so I have this 400MB Vector.Unboxed that took a couple of minutes to generate, it'd be nice if I could skip the couple of minutes on the next invocation by having it serialize/deserialize to some efficient format
08:14:57 <tinco> any Haskell library/system you could recommend for achieving that?
08:15:18 <MarcelineVQ> if you're prototyping consider https://hackage.haskell.org/package/rapid
08:15:20 <tinco> I'm on a quick ssd so I think loading 400MB of data should just take a second or two
08:15:36 <tinco> thanks :)
08:15:47 <tinco> ahh for hot reloading
08:15:59 <MarcelineVQ> if you need serialization eventually though it's probably better to go that route
08:16:44 <MarcelineVQ> like Binary or Serial, I'm not sure what's the current favorite
08:16:48 <tinco> yeah rapid looks really interesting, but I'm looking for something that I could use to speed up redeploys/restarts and maybe larger datasets as well
08:18:35 <codeshot> tinco, I'm on an eSSD and it would load that in 1/7 of a second
08:22:40 <tinco> codeshot: yeah this thing has got an NVMe thingy so it should be quick
08:23:09 <codeshot> yeah, NVMe, that's the thing
08:23:36 <codeshot> I got me a skull canyon NUC
08:29:02 <codeshot> Psybur, https://pastebin.com/kd8PhjvA
08:29:11 <codeshot> I did some playing
08:29:49 <Psybur> codeshot, quick rundown? 
08:30:54 <Psybur> In this version of `memoize`, everytime you calculate a non memoized value, you first put it in the packing map and then retrieve it?
08:31:09 <Psybur> s/packing/backing
08:31:19 <codeshot> yes, I'd like to retreive in one step, but Haskell seems to optimise it
08:31:44 <Psybur> Does the optimisation avoid the map lookup?
08:31:45 <codeshot> but also, I used only State not StateT in the memoize function
08:32:04 <codeshot> Psybur, not sure really, but yours has the same thing
08:32:35 <Psybur> Mine adds it to the map, but then returns the value, instead of returning the value after looking it up in the map
08:32:47 <codeshot> you lookup the place to see if it's there, then if it's not you look up the place to insert it
08:32:57 <codeshot> so its 6 of one, half a dozen of the other
08:32:57 <Psybur> Ah I see
08:33:06 <codeshot> but look at the type
08:33:24 <codeshot> and later I use (hoist generalize) to make it be a StateT
08:33:47 <codeshot> so the memoize function is written entirely without regard to the fact it will be a transformer
08:34:02 <codeshot> I also played with a ListT transformer (nonstandard)
08:34:33 <codeshot> and I re-ordered the numbers and found that haskell entirely memoises this situation anyway (main2 and main3)
08:35:05 <codeshot> I also played with "fix" so I could later thread memoise through the fib function to memoise selected intermediates - though I didn't get that far
08:35:12 <Psybur> I notice the lift $ lift. Could that be replaced with liftIO ?
08:35:20 <codeshot> the first one could
08:35:30 <codeshot> but liftIO is just lift for the IO monad
08:35:50 <Psybur> Yes, I think I remember it is intended to be used to avoid having to use repeated lifts for IO?
08:36:07 <codeshot> no, it's just a monomorphic version
08:36:30 <codeshot> I avoid repeats in some places in this example
08:36:55 <codeshot> lift $ do {foo;bar} only lifts once for both actions
08:38:12 <codeshot> The use of fix is not terribly common, *but* it's wonderful because you can do: fix (wrap_selected_intermediates memoize fib)
08:38:37 <codeshot> and the search for the answer will save selected answers in the state
08:38:55 <codeshot> even on the way to calculating the final answer
08:39:34 <codeshot> eg, memoize all n=k^2 from the list
08:39:47 <Psybur> I mean repeated uses of lift as in https://www.schoolofhaskell.com/user/commercial/content/monad-transformers#lift-vs-liftio
08:39:54 <Psybur> In one line, not multiple lines
08:41:03 <codeshot> oh, I didn't know it would do that
08:41:27 <codeshot> It's not necessarily what one wants to do but yeah
08:41:57 <codeshot> I prefer not to treat IO with extra privileges so that I always make generic, composable code
08:42:05 <codeshot> and I'm always prepared to be able to read it
08:44:55 <Psybur> codeshot, now refactor your code so that functions only have one responsibility. So right now your functions are managing the calculation of fibs and the printing :D
08:48:59 <Psybur> So get rid of repeated code. Is it possible to put the pretty printing in one function and compose it with three different methods of running the fib calculations?
08:59:25 <codeshot> yes, I already did that
09:02:57 <erisco> codeshot, how many partial functions do you use?
09:03:20 <codeshot> https://pastebin.com/yU8b8a96
09:03:44 <codeshot> I hadn't thought about it explicitly
09:03:48 <Psybur> codeshot, I mean instead of having three functions that each putStr show example, putStr ": ", shortShow answer. Take that repeated bit out and then compose it back in
09:03:51 <codeshot> I think they're all total
09:04:09 <codeshot> hm, one or two
09:04:50 <codeshot> hm fib and fibMemoized I think
09:04:52 <Psybur> codeshot, btw what I just said was not in response to what you just posted
09:04:59 <Psybur> Looking now
09:05:11 <erisco> do all TLDs have an associated type declaration?
09:05:19 <codeshot> nope
09:07:03 <Zemyla> So in Linear Haskell, will there be a way to make functions that aren't actually linear, but are conceptually so, into actual linear functions?
09:08:00 <codeshot> erisco, FYI, I only made this source to show Psybur some features of haskell around the area he was learning
09:08:25 <johnw> Zemyla: if you wrap them with a linearly typed function
09:08:25 <codeshot> It's a variation of his studying exercises
09:08:34 <Psybur> Is lifting considered a code smell? I think I remember reading if youre using lift youre probably doing something wrong?
09:08:57 <johnw> Zemyla: or maybe it's the other way around that's possible: non-linear can always call linear, but perhaps not vice versa
09:09:00 <johnw> I have to reread the paper
09:09:07 <Zemyla> johnw: Yeah, it's that way.
09:09:18 <Psybur> Ah here is the article http://blog.ezyang.com/2013/09/if-youre-using-lift-youre-doing-it-wrong-probably/
09:10:57 <monochrom> I wouldn't always avoid lift.
09:14:01 <codeshot> I didn't entirely follow what that blog post was saying. I imagined that lift always had to be given once for each step of the stack
09:14:08 <codeshot> I wouldn't want it any other way
09:15:53 <codeshot> I can't see how you can write a function for one monad and then use it when that monad's behaviour is provided in a transformer stack unless you use lift
09:17:13 <codeshot> Is there a type that takes a non-transformer monad and converts it to BlahT Identity a ?
09:17:28 <codeshot> like a type-level type class
09:21:02 <jollygood2> what is stack equivalent of cabal sandbox add-source?
09:23:26 <bennofs1> jollygood2: I think it is editing the stack.yml to add a source dep
09:23:29 <jollygood2> i built my module and I'm trying to build a program that depends on it. since I am using it often the best thing would be to have it available globally
09:24:46 <np356> hello everyone
09:25:13 <codeshot> erisco, another issue beyond those that you've asked about is the memoize can be used with multiple different functions so the state can be poisoned
09:25:49 <np356> As you all know the internet is full of Monad tutorials, but monad is really simple: its just a way to chain computations together and guarantee order between different functions. Now I'm looking for a similarly brain-dead explenation of what are Monad Transformers.
09:25:52 <jollygood2> bennofs1 can I make it globally available? a bit annoying having to add it to both .cabal and stack.yml file, on all the projects I use it (almost all of them)
09:25:53 <np356> Thoughts?
09:26:22 <monochrom> I wouldn't be so certain about "guarantee order".
09:26:30 <np356> a >>= b
09:26:35 <np356> a happens before b
09:26:36 <np356> right?
09:26:41 <bennofs1> take a look at the reverse state monad
09:26:46 <monochrom> can run b multiple times, or 0 times.
09:26:49 <merijn> np356: Define "happen" and "before"
09:26:52 <np356> ok, I'm not trying to get fancy :)
09:27:00 <monochrom> [] isn't fancy
09:27:10 <np356> print "a" >>= print "b" will output "ab"
09:27:27 <merijn> np356: The monad instance for IO *specifically* guarantees that, yes
09:27:36 <monochrom> That's just IO. All you have said is merely "IO guarantees order". Great information.
09:27:42 <merijn> np356: But that says something about what >>= means *for IO*
09:27:50 <np356> no, bind guarantees order, not IO
09:28:00 <merijn> np356: bind for IO guarantees order
09:28:14 <merijn> np356: For other monad instances it might not even make sense to talk about order
09:28:21 <merijn> np356: See monochrom's list example
09:28:23 <np356> so give me an example where bind doesnt guarantee order
09:28:47 <merijn> np356: Look at bennofs1's mention of "reverse state"
09:28:51 <monochrom> [1,2,3] >>= b runs b 3 times. Or "runs".
09:28:58 <np356> anyway... before I'm completely detrained from my question... what is the simplest intuition for monad transformers?
09:29:03 <monochrom> Oh yeah that too.
09:29:07 <merijn> np356: https://lukepalmer.wordpress.com/2008/08/10/mindfuck-the-reverse-state-monad/
09:29:46 <dancek> noob here. would be great to have a list of "the simplest intuition for x".
09:29:53 <merijn> np356: Honestly, the simplest intuition, IMO is to implement one yourself. It's pretty easy if you've implemented State: https://gist.github.com/merijn/098106abd45c940dab09
09:29:54 <monochrom> Also Control.Monad.State.Lazy http://lpaste.net/41790/  not fancy because the moment you say "import Control.Monad.State" you are already doing this.
09:30:18 <merijn> np356: If you haven't implemented State before, then I recommend doing that first, see the same link
09:30:26 <dancek> (otoh I find that all the intuitions i've had for monad this far are wrong or lacking, so...)
09:30:32 <merijn> dancek: I find that "simplest intuitions" or often wrong :p
09:30:41 <dancek> indeed
09:31:01 <merijn> dancek: The intuition for monad is: "an interface obeying several properties that happens to occur in many places", tbh
09:31:06 <monochrom> People conflate "simple" with "simple-minded".
09:31:16 <merijn> dancek: Are you familiar with Monoid?
09:31:30 <monochrom> There is a simple intution but it differs from most people's simple-minded intuition.
09:31:31 <codeshot> Psybur, I did a little edit
09:31:46 <dancek> merijn: not really, but I think i understand Applicative
09:31:54 <codeshot> just moved a lift and a pure to the correct place
09:31:58 <dancek> iirc Monoid is something simple
09:32:06 <np356> k, thanks
09:33:01 <merijn> dancek: It is. A monoid consists of 3 things: 1) a set of elements (in haskell all values of a specific type), 2) a binary operation that combines two set elements into a new element, and 3) a unique identity element which is the left and right identity of the binary operation
09:33:25 <np356> So.. to understand Monad Transformers I need to implement State Monad? Is that what you're tryiong to tell me?
09:33:29 <merijn> dancek: i.e. if the binary operation is mappend and the identity element is mempty, then "mappend mempty x = x = mappend x mempty"
09:33:51 <merijn> np356: In my experience for many people implementing those two in the link is very enlightening
09:34:15 <np356> merijn: will do
09:34:40 <np356> Btw. Anyone here also lives in Berlin and is going to next Wednesday's haskell meetup?
09:34:53 <dminuoso> np356: There's a haskell meetup in Berlin?
09:34:54 <dminuoso> :o
09:34:59 <np356> yes
09:35:11 <np356> shitty one, but there is one.
09:35:15 <merijn> dancek: Every programmer knows at least 3 monoids: addition of natural numbers with 0 as identity, multiplication of natural numbers with 1 as identity, and list appending with empty list as identity
09:35:32 <dminuoso> np356: Oh its a biweekly meetup?
09:36:03 <dminuoso> merijn: and endofunctions with function composition!
09:36:04 <np356> dminuoso: https://www.meetup.com/berlinhug/events/244553715/
09:36:04 <merijn> dancek: You can actually build quite some neat generic functions from all of this, and the reason those functions can be written is because you know some specific things about what monoids can/can't do
09:36:22 <merijn> dminuoso: I prefer the non-endo monoid for functions :p
09:36:36 <dminuoso> merijn: It's not a monoid because they dont freely compose if types dont match
09:36:51 <merijn> dminuoso: Eh, yes they are a monoid
09:36:54 <merijn> dminuoso: The best one
09:37:04 <merijn> dminuoso: "instance Monoid m => Monoid (r -> m)"
09:37:04 <EvanR> hehe
09:37:11 <merijn> I use that instance so much
09:37:47 <bennofs1> instance Monoid m, Functor f => Monoid (f m) is often useful
09:38:01 <bennofs1> sadly you cannot define it in the general way because it would overlap :/
09:38:28 <merijn> dancek: So there's really just not much to get about monads, they're pretty abstract. The real trick is in realising how incredibly many different (and common!) programming patterns happen to match the rules/operations of Monad
09:38:46 <codeshot> Psybur, note the very long time to exit the program after the IO is done
09:38:49 <np356> So the reason I feel like I need to learn monad transformers is because I was doing something in the MongoDB monad and then it had a nested do with an IO monad and I couldn't make the compiler happy.
09:39:00 <np356> readerT and friends...
09:39:10 <np356> so I need to actually understand that
09:39:32 <merijn> dancek: Incidentally, the original Wadler paper on monads is very good and doesn't get enough credit. Every beginner seems to skip it, but it's very nice. Shows you 3 or 4 different patterns, then shows how you can abstract all those into a single pattern (i.e. Monad)
09:39:37 <codeshot> I think this is because ghci's rather excessing builtin uncontrollable memoization. Someone messed up putting that in
09:39:42 <dminuoso> dancek: I personally found it easiest to just use monads and implement some. As far as programmers are concerned, they really just reflect a very particular programming pattern.
09:40:04 <merijn> dancek: http://roman-dushkin.narod.ru/files/fp__philip_wadler_001.pdf
09:41:02 * dminuoso learned Monads the hard way through category theory.
09:41:09 <dminuoso> That was some painful 2 weeks. :-)
09:41:23 <np356> the internet is full of material for beginners and category theory PhDs. There is very little for people in between... :(
09:41:30 <jollygood2> how do I specify local package to stack? extra-deps: accepts paths relative to stack.yml, and it doesn't accept ..
09:41:46 <dminuoso> np356: Actually category theory is not that hard for beginners to dive into.
09:42:05 <np356> I'm familiar with category theory, but it doesn't compile with GHC
09:42:06 <merijn> dminuoso: well...
09:42:06 <np356> hehe
09:42:18 <dancek> merijn, dminuoso: thanks. I'll have to meditate on these a bit after I've fed the kids and got them to bed. :) On a quick glance it seems even Monoid is easy to understand, to use its properties and to check if something is a Monoid---but I can't immediately find an intuition for it.
09:42:45 <merijn> dminuoso: I mean, sure morphisms and objects are easy and several bits of that, but quickly becomes confusing, imo
09:43:11 <merijn> dancek: Well that's the point, the patterns are so general there isn't a single unifying "intuition" beyond "this is the pattern"
09:43:29 <np356> dancek: monoid is std::binary_function
09:43:32 <dminuoso> dancek: In the end a monoid just encompasses the idea of "combining two things" in some meaningful way, and being able to combine the result with other things further.
09:43:42 <merijn> dancek: I mean, to illustrate, remember how I said lists + appending is a monoid?
09:43:58 <merijn> dancek: Well, turns out that "lists + prepending" is also a monoid
09:44:08 <merijn> i.e. "mappend xs ys = ys ++ xs"
09:44:17 <merijn> instead of "mappend xs ys = xs ++ ys"
09:44:42 <merijn> Finding a more sensible definition than "combine two things" will be very hard
09:44:47 <codeshot> dancek, Monoid is fold with it's operation
09:45:09 <codeshot> It's eating and thinking
09:45:21 <monochrom> dminuoso: Oh, just two weeks? That's fast. :)
09:45:50 <monochrom> Two weeks is only enough for me to learn Emacs...
09:46:18 <monochrom> Actually Perl too but meh.
09:46:32 <np356> ok, another haskell question. I'm using readDirectoryWith from System.Directory.Tree... how to parallelize that? I've tried various of combinations fo forkIO and it didn't work.
09:47:17 <np356> I need to read 2 petabytes of html files and do stuff to them, in other languages its trivial to parallelize enumeration of directory contents
09:47:19 <dminuoso> dancek: The only specialty about a monoid, is that the combination has to be associative. And that really means if you have 3 things to combine, it doesn't matter which order you combine them in. So it's combining things assocaitively.
09:47:30 <Xion__> Pardon me butting in, but if anyone could have a look at my beginner-to-intermediate post about currying-friendly API design, it'd be great :) http://xion.io/drafts/currying-api-design.html
09:47:35 <dminuoso> You can even ignore the identity element, as you usually have one and if not you can trivially invent one.
09:48:11 <Xion__> dminuoso: If you really cannot invent one, you can always go for Semigroup instead of Monoid.
09:48:28 <dminuoso> Xion__: Yeah, and it wont change much about the intuition either.
09:48:37 <merijn> dminuoso: Eh, it does matter which order
09:48:55 <merijn> dminuoso: Just not how you group
09:49:22 <monochrom> "order" is overloaded
09:49:37 <np356> in C# its as elegant as: Directory.GetSubdirectories(".").AsParallel()
09:49:39 <dminuoso> merijn: I was talking about the order of combination. :|
09:49:49 <dminuoso> But I do agree that it was a bit ambiguous.
09:50:06 <np356> in c++ its: tbb::parallel_foreach(...)
09:50:12 <np356> haskel makes life hard :(
09:50:18 <monochrom> I agree.
09:51:02 <dminuoso> np356: Have you seen how typeclasses will be implemented in the next C++ version (well. hopefully) ?
09:51:08 <np356> open letter to the Haskell Comitte: "Grow the fuck up. we need to build actual real systems here!"
09:51:41 <merijn> Why blame the Haskell Committee for some random library?
09:51:41 <monochrom> I do wonder what's the type of Directory.GetSubdirectories(".")
09:52:22 <np356> merijn: I don't think that being able to parallelize enumeration over a collection is "a random library"
09:52:32 <np356> that is a language-feature level thing
09:52:39 <merijn> np356: Wut?
09:52:43 <Xion__> How does this AsParallel work exactly? You could technically parallelize at every level of the tree but that would rarely make sense
09:53:10 <merijn> np356: Considering we have multiple libraries to do exactly that, it definitely sounds like a library thing to me
09:53:10 <merijn> np356: For example: async's mapConcurrently
09:53:15 <merijn> Also, parallel strategies
09:53:18 <np356> Xion__: it has a partioner,. that dequeues work as cores free up, but makes sure they're always busy
09:53:54 <merijn> Right...so exactly the kinda thing parallel strategies does. Except that's only for pure code. But if you need impure you can just use async
09:54:21 <Xion__> Ah, BFS with synchronized queue
09:54:57 <np356> ok, so how would you parallelize readDirectoryWith from System.Directory.Tree ?
09:55:43 <Xion__> Tbf this isn't an obvious functionality to have in a standard library, and the fact that C# specifically has it seems kinda weird to me
09:55:45 <np356> that's what I'm talking about....
09:55:52 <monochrom> Actually why parallelize this? You have 10 disks instead of 1?
09:56:08 <merijn> np356: Depends what you're trying to do. That library isn't really well designed for wanting to parallely traverse directory trees
09:56:09 <dminuoso> How does Haskell allow for multiple Monoids with the same type by the way? I mean let's take Int, how can I gain access to either (Int, +, 0) or (Int, *, 1) ?
09:56:10 <np356> No, but I want to process 10 files at a time
09:56:21 <merijn> np356: OTOH, if you just wanna process files in parallel that's trivial with async
09:56:40 <Xion__> dminuoso: Newtypes
09:56:59 <Xion__> dminuoso: There exist a Sum and Product newtypes for specifically the cases you mentioned
09:57:02 <monochrom> mapConcurrently sounds about right.
09:57:35 <monochrom> Also I don't know where to find System.Directory.Tree so I don't even know how to use it.
09:57:57 <dminuoso> Xion__: Ah. That's a bit dirty. :|
09:57:59 <np356> merijn: readDirectoryWith (\d -> putStrLn d) "."      how would you make this parallel?
09:58:23 <Xion__> dminuoso: It'd be nicer if we had named instances but oh well
09:58:29 <monochrom> readDirectoryWith (\d -> forkIO (putStrLn d)) ?
09:59:11 <Xion__> monochrom: If I read the library docs correctly, this will give you a thread per file which is probably *too* parallel :)
09:59:18 <merijn> np356: You stop using readDirectoryWith, you use "readDirectory" extract the internal DirTree and do "mapConcurrently (\d -> putStrLn d)"
09:59:32 <monochrom> Yeah replace forkIO by some thread pool thingie.
09:59:49 <cocreature> Xion__: well you can easily wrap than in a semaphore
09:59:50 <np356> merijn: good call
09:59:54 <merijn> np356: Which will do one thread per file, as Xion points out, but that's trivially solved by simply wrapping the putStrLn in a QSem
10:00:21 <merijn> np356: See this example: https://stackoverflow.com/questions/18896103/can-haskells-control-concurrent-async-mapconcurrently-have-a-limit
10:00:34 <np356> Haskell needs to agree on how to work with enumerable types
10:00:54 <monochrom> I don't understand what's that.
10:00:57 <merijn> Although I'd probably grab Control.Concurrently.QSem as semaphore
10:01:40 <Xion__> TIL about QSem.
10:01:52 <dminuoso> Athas: That talk from Stephanie Weinrich about dependent types in Haskell was pretty amazing. I have not much experience with dependent types, but this was something that immediately seemed useful.
10:01:57 <cocreature> how is there no withQSem :(
10:02:01 <merijn> Xion__: In that case you should probably browse through all of Control.Concurrently :p
10:02:37 <np356> ok, anyone has good links for intuition about monad transformers? I understand the state monad..
10:02:40 <monochrom> http://hackage.haskell.org/packages/search?terms=thread+pool
10:02:41 <Xion__> So you'd make `newQSem numberOfCores` and simply do \d -> frokIO $ waitQSem >> putStrLn d, while still having gazillion threads? :)
10:02:44 <np356> I undersntand monads
10:02:48 <np356> and all that jazz
10:02:48 <dminuoso> np356: Implemet them yourselves.
10:02:54 <np356> I did already
10:02:57 <Xion__> I didn't know the GHC runtime is *that* effective with its green threads
10:02:59 <dminuoso> np356: Which ones?
10:03:01 <cocreature> Xion__: no you put the qsem outside of the forkIO
10:03:07 <np356> I know, I might be too dull, but.. bear with me :)
10:03:10 <np356> state
10:03:14 <Xion__> cocreature: Oh right, so you have one per core
10:03:19 <dminuoso> np356: Now do ListT.
10:03:23 <dminuoso> np356: And MaybeT.
10:03:27 <merijn> Xion__: 10k-100k threads should be no issue on a beefy desktop/average server
10:03:38 <Xion__> :O
10:03:42 <cocreature> Xion__: also use something like "bracket waitQSem signalQSem (\_ -> forkIO …)"
10:03:46 <merijn> Xion__: GHC green threads are even less resource intensive than Goroutines/erlang processes
10:03:52 <Xion__> Neat.
10:04:04 <merijn> Xion__: I think the overhead is like 1KB per thread?
10:04:10 <hpc> the bottleneck for green threads is ram
10:04:16 <np356> everything suffixed with "T" is a transformer?
10:04:23 <dminuoso> np356: Not everything, but transformers are.
10:04:26 <dminuoso> :p
10:04:29 <np356> ok
10:04:30 <Xion__> That's the convention.
10:04:38 <Athas> dminuoso: yes.  It'll be interesting to see where it goes.
10:04:40 <np356> I love and hate haskell in the same time.
10:04:47 <merijn> My "data AST" type is not a transformer, for one :p
10:04:51 <Athas> Although I'm personally a little disillusioned with the complexity of heavy type-level programming in Haskell.
10:04:54 <np356> Its like this hot crazy girlfriend...
10:04:54 <Xion__> np356: Yeah, Haskell does that ;)
10:04:56 <monochrom> Haskell has agreed on how to work on enumerable types. Look at Foldable and Traversable. Note that mapConcurrently takes and produces a Traversable.
10:05:35 <monochrom> Hatred is usually caused by ignorance.
10:05:54 <np356> deep thoughts are usually caused by boredom.
10:06:02 <dminuoso> 19:02           np356 | I undersntand monads
10:06:06 <dminuoso> This is the second phase of Monad understanding.
10:06:59 <Xion__> dminuoso: I thought that'd be "Monad sucks omg", i.e. Anger.
10:07:08 <np356> Monad undersanding came to me after working with Intell TBB, boost::future and PPL, with their .then() continuation monad
10:07:14 <np356> then it all made sense
10:07:28 <np356> but I can't find a similar anology for MTL
10:07:42 <dminuoso> np356: So what is a monad?
10:08:11 <dminuoso> Lets see if I can get you to phrase 3, "realizing that ones understanding about monads was wrong"
10:08:23 <monochrom> MTL is when you build a compound monad from several ingredients. That's all.
10:08:28 <np356> a monad is a piece of computation the yields its results to the thing that is bound to it. guaranteeing that it will complete before the bound computation is invoked.
10:08:31 <np356> right?
10:08:32 <Xion__> dminuoso: C.f. "I don't need monads anyway" (Denial), "Monads suck!" (Anger), "Can I just use IO perhaps?" (Bargaining), "I will never figure this out :/" (Depression), "(>>=) :: f a -> (a -> f b) -> f b" (Acceptance / Understanding)
10:08:41 <dminuoso> Oh that!
10:08:43 <dminuoso> Yes that!
10:08:55 <monochrom> And unfortunately the ingredients cannot be monads themselves.
10:09:33 <dminuoso> np356: not really. monads can model computation, but they dont have to.
10:09:39 <np356> but I can't speak about monad transformers with such a finesse :)
10:09:49 <monochrom> And you can wait for boost or C# to give you monad transformers (or will it be called LINQ transformers?) and then you will get it.
10:09:55 <np356> dminuoso: don't try to get too fancy :P
10:10:17 <Xion__> "Computation" is kind of ambiguous anyway. Monadic bind is just a specific way of composing functions.
10:11:00 <dminuoso> np356: bind is just sugary because thats how you frequently use it, but the real power lies in join
10:11:10 <sm> Xion__: you forgot "Here's my clarifying monad tutorial!" (Exuberance)
10:11:41 <np356> dminuoso: elaborate please
10:11:45 <monochrom> "computation" would have worked before we had Applicative
10:11:47 <cocreature> dminuoso: that doesn’t make sense, bind and join have the same power
10:12:24 <monochrom> Because before Applicative, you could have pulled "monad is computation" in the same sense as "survival of the fit".
10:13:12 <monochrom> In other words, if someone asked you "so how do you define 'fit'?", answer: those who survive. "so how do you define computation?", answer: monadic values.
10:13:57 <monochrom> But then came Applicative and screwed up it all, because now some "computation"s are non-monad applicative values.
10:14:33 * np356 is reminding everyone that the original question was about the intuition for monad trasformers...
10:14:40 <np356> just sayin'...
10:15:01 <dminuoso> cocreature: Fair enough.
10:15:05 <monochrom> I already answered.
10:16:07 * monochrom reminds everyone that monochrom always gives a direct answer before further musings.
10:17:01 <dminuoso> cocreature: I just like to see the CT perspective where you define a functor F:C->C with the two natural transformations η:X→T(X) and μ:T(T(X))→T(X)
10:17:03 <sm> np356: in practical terms, the intuition for monad transformers is layered monads. When something isn't type checking, you have to understand the layering and maybe unwrap or apply a layer or two
10:17:10 * monochrom also reminds everyone that monochrom has Delphi's curse: always right on head on but no one notices.
10:17:29 <dminuoso> cocreature: Perhaps it's just me that has an easier time gaining intuition from join than from bind.
10:18:09 <erisco> intuition for monad transformers?
10:18:15 <cocreature> dminuoso: sure "join" is a valid viewpoint that might be easier to understand for some. but claiming that it’s more powerful is just wrong
10:18:16 <np356> sm: what is layering?
10:18:26 <np356> sm: type casts/
10:18:27 <np356> ?
10:18:37 <erisco> I'd just go to the definition ... not much an intuition but seems sensible enough to me
10:18:42 <dminuoso> cocreature: Perhaps "powerful" was the wrong word. "Clean" might be what I was hoping for.
10:18:54 <sm> "..the MongoDB monad and then it had a nested do with an IO monad.." <- mongo monad is probably layed on top of io monad. Eg.
10:19:08 <monochrom> Oh "cleaner" is also relative. :)
10:19:14 <sm> you can probably find some docs explaining this better 
10:19:29 <monochrom> join is cleaner for algebraic purposes. >>= is cleaner for programming purposes.
10:19:38 <sm> when you see lift or liftIO, that is unwrapping a layer
10:19:44 <erisco> let your intuition be integration of the formality into your mind
10:20:09 <monochrom> I agree with erisco. That's what I've always done.
10:20:09 <np356> sm: can I use your brain for a sec? So how does the context get propagated across monads? say one is aware about an open connection to mongodb and another one is dealing with IO
10:20:23 <np356> where do I begin to look for material that explains it?
10:20:36 <dminuoso> np356: the "how" is exactly defined by the monads involved.
10:20:46 <humanoyd> erisco: that sounds like the beginning of some hardstyle track ;)
10:21:13 <monochrom> In fact when learning minimax and alpha-beta pruning, when it comes to "admissible", I understood the math definition and completely confounded by the essay explanation.
10:21:24 <cocreature> one of the most common examples of combining monads that a lot of haskellers seem to discover for themselves is combining the short-circuiting of Either/Maybe with IO
10:21:27 <sm> how about https://encrypted.google.com/search?hl=en&q=monad%20transformers
10:22:16 <erisco> acknowledging that some good informal explanations can guide your learning, I think it is also true that the people who are successfully coming up with the informalisms are the ones who already know the formalisms
10:22:25 <np356> var connection = new MongoDBConnection("connection-string"); foreach (var entry in connection.query("document")) { Console.WriteLine("found: {0}", entry.Name); }
10:22:32 <np356> how would you write this shit in haskell?
10:23:05 <sbrg> np356: depends on the library obv. but it's possible to do it in a very similar manner
10:23:25 <monochrom> I would learn Haskell.
10:23:25 <np356> how similar?
10:23:42 <monochrom> But look for mapM_ for now.
10:23:51 <sbrg> do { conn <- newConnection ".."; results <- query "foo"; mapM_ print results; }
10:23:57 <np356> monochrom: you're very arrogant.\
10:24:04 <sbrg> `query conn "foo"` *
10:24:29 <monochrom> You also want to look up Control.Exception.bracket for an exception-safe way to open and close a connection.
10:25:00 <monochrom> No I am not arrogant, I am candid.
10:25:15 <erisco> humanoyd, hm, I am kind of liking these remixes
10:25:32 <sm> monochrom: and often pedantic and unhelpful, be honest :/
10:25:58 <monochrom> How is "but look for mapM_ for now" unhelpful and pedantic?
10:26:16 <np356> that was helpful
10:26:23 <np356> so mapM_ sequences actions
10:26:24 <dminuoso> Honestly
10:26:25 <np356> I know that
10:26:42 <Xion__> Well tbf the original C# code didn't use try/finally or using, so you don't need bracket to replicate it in Haskell ;)
10:26:46 <dminuoso> If you walk in here and ask "how do implement this shit from my favourite imperative language in Haskell", then "I would learn Haskell" is a proper response.
10:26:59 <np356> applies f to everyting in xs in order
10:27:04 <joeoeoe> Hello, I have some code like this http://lpaste.net/360002 if I load the file in ghci and then call "main" then each carriage return, ">" is printed, but if I use runhaskell then I see no output
10:27:30 <erisco> np356, what materials have you read on Monad? are you looking for some?
10:27:33 <joeoeoe> not until I enter a command for which "parse" produces some output
10:27:47 <dminuoso> joeoeoe: Say thanks to buffered IO
10:27:56 <monochrom> I didn't just deal out "learn Haskell" blindly blanketly. I was seeing some person who have never heard of mapM_. That was my evidence.
10:28:13 <sbrg> joeoeoe: you can possibly fix that by using `hSetBuffering stdin NoBuffering` or something
10:28:16 <sbrg> @hoogle hSetBuffering
10:28:16 <lambdabot> System.IO hSetBuffering :: Handle -> BufferMode -> IO ()
10:28:16 <lambdabot> GHC.IO.Handle hSetBuffering :: Handle -> BufferMode -> IO ()
10:28:16 <lambdabot> System.Path.IO hSetBuffering :: Handle -> BufferMode -> IO ()
10:28:20 <dminuoso> joeoeoe: just use `hFlush stdout`
10:28:23 <hpc> joeoeoe: try sending EOF (ctrl-D in linux terminals) and see if it outputs a bunch of stuff at once
10:28:30 <dminuoso> joeoeoe: (or turn stdout to NoBuffering)
10:28:37 <sbrg> *stdout
10:28:37 <hpc> joeoeoe: if you want to see buffering in action
10:28:38 <sbrg> indeed
10:28:47 <joeoeoe> yeah it does, thanks
10:29:17 <joeoeoe> at least it's an easy fix
10:29:24 <np356> i guess I should stick with C++17 and possibly rust.
10:29:46 <np356> I can't make my team go throuh this everytime they have a question :)
10:29:51 <sbrg> np356: suit yourself, of course.
10:29:53 <sbrg> go through what?
10:30:16 <monochrom> Go through Prelude.
10:30:18 <np356> looking for an answer to syntactic thing for over 1h
10:30:29 <erisco> you have to do a lot of reading and practice to learn Haskell
10:30:30 <np356> not even con eptual
10:30:34 <Xion__> Introducing Haskell to a team or company all by yourself is always a daunting task, probably more so than for other languages
10:30:34 <sbrg> what syntatic thing?
10:30:36 <np356> *conceptual
10:30:39 <joeoeoe> what was the issue?
10:30:46 <erisco> I haven't followed the whole convo but you can't expect someone to re-explain several chapters worth of material in IRC for you
10:30:54 <np356> monad tranfroemers
10:30:56 <monochrom> Unfortunately mapM_ isn't syntactic, so that's why you looked in the wrong places.
10:31:01 <sbrg> ends with T, that question?
10:31:03 <np356> I can't use mongodb with IO
10:31:08 <sbrg> oh
10:31:18 <np356> I know, I might be retarded... etc..
10:31:22 <np356> but so is my team.
10:31:28 <sbrg> I'm not familiar with any mongodb library.
10:31:36 <johnw> monochrom: I at least thought you were trying to be helpful
10:31:39 <hpc> that's pretty much the crux of it
10:31:42 <sbrg> but if you're referring to some mongodb monad in which you cannot do IO, I'm sure there is a reason for that.
10:31:49 <np356> https://github.com/bitemyapp/bloodhound/blob/master/examples/Tweet.hs
10:31:50 <hpc> you've basically asked a library question without saying what library you are using
10:34:17 <erisco> np356, I have not read this thoroughly, just skimmed it, but it might be a good resource to get you started because it has plenty of examples https://www.vex.net/~trebla/haskell/IO.xhtml
10:34:25 <dminuoso> 19:29        np356 | I can't make my team go throuh this everytime they have a question :)
10:34:31 <dminuoso> np356: Are you planning to introduce Haskell teamwide?
10:34:52 <monochrom> I wouldn't call it "plenty".
10:35:07 * erisco *shrugs*
10:35:12 <np356> yeah, I have the mandate to start a new team and I want to hire haskellers over Berlin. but I must actually believe in what I'm sauyiong.
10:35:24 <monochrom> It would need 5x more examples to qualify for "plenty".
10:35:27 <erisco> in comparison to what I have been reading lately it feels like a lot... more than just a list of definitions :P
10:35:28 <np356> Haskell is beautiful but not practical.
10:35:37 <sbrg> np356: Any monad that is an instance of MonadIO can "run IO" using liftIO. If it isn't an instance of MonadIO, then there's either a reason(like, say, for the STM monad) or it's an oversight by the author. 
10:35:38 <monochrom> Also it has a laughably low number of exercises.
10:35:53 <np356> If anyone of you feels like you have a different opinion about this I'd be happy to grab coffee in Berlin.
10:35:55 <hpc> usually it's not an oversight
10:36:02 <MarcelineVQ> monochrom: you're full of beans this morning
10:36:08 <erisco> okay, well, link your favourite one
10:36:14 <hpc> np356: it sounds like you don't know haskell, but are expected to hire people who do?
10:36:24 <erisco> I just spotted this one a while ago and it seemed decent
10:36:30 <monochrom> Although, http://www.vex.net/~trebla/haskell/cont.xhtml is where the dude begins to have a reasonable number of exercises.
10:36:57 <monochrom> Oh I agree it's the most decent. Just doesn't have as many examples and exercises as I would like.
10:37:17 <monochrom> Also I'm still wondering how to add the "recipe" story there.
10:37:25 <Xion__> I'd start by actually finding a Haskell specialist first and then growing into yourself alongside him, while also expanding the team.
10:37:38 <np356> hpc: I know algorithms very well, and I'm very good at math. IU expect my haskellers to fit into that framework.
10:37:48 <monochrom> Or whether it already has the "recipe" story implicitly and I don't have to make it explicit.
10:37:53 <hpc> if you're expected to also code you really do just need to go through the work of learning it, otherwise you still need to learn enough to hire that first person and let them be your filter for the rest
10:38:26 <np356> hpc, I will. really, that's why I'm exploring this space.
10:38:39 <np356> I'm doing my best man...
10:39:08 <np356> I'm actually a pretty badass coder if you what to go that route....
10:39:10 <Xion__> BTW this brochure should be relevant to anyone trying to introduce Haskell or any other "niche" language into their team or company: https://esl-website-production.s3.amazonaws.com/uploads/document/file/81/The_route_to_the_successful_adoption_of_non-mainstream_programming_languages_-_Erlang_Solutions_Whitepaper_2017_.pdf
10:39:48 <EvanR> np356: me too
10:40:30 <erisco> we were all bad-asses at one time
10:40:50 <sbrg> i thought i was a badass once. writing C and stuff.
10:40:51 <EvanR> you havent seen my final form though
10:40:55 <erisco> then we met more people and realised where we ranked :P
10:40:56 <sbrg> then i just wanted to write code that works. 
10:41:03 <sbrg> erisco:.. and that <.<
10:42:01 <erisco> the only consolation is that everyone has finite time, so you can still find some place to make an improvement
10:42:10 <monochrom> I was a badass math student.
10:42:10 <dminuoso> <.< is not an operator, is it?
10:42:28 <sbrg> I'm not entirely convinced that kmett isn't a time-traveling alien or something tbh
10:42:29 <EvanR> > let (<.<) = (+) in 2 <.< 2
10:42:31 <lambdabot>  4
10:42:37 <dminuoso> Heh :)
10:43:33 <np356> static_cast<int*>(&monochromoe) = 0;
10:43:34 <monochrom> But the meta metamorphsis is the same as yours. From someone who valued doing things the hard way, to someone who value making things easier.
10:44:12 <monochrom> So for example 20 years ago I would explain ordinals the same way every set theory textbook does.
10:44:15 <merijn> sbrg: He's a robot
10:44:17 <EvanR> how do i make 3d graphics on the raspberry pi easier
10:44:18 <sbrg> yep. it's like my early twenties. Initially I thought I had to party all the time to not miss out or whatnot. now I just want to be not hung over. 
10:44:25 <dminuoso> np356: Im going out on a limb, but I believe this could be UB.
10:44:26 <sbrg> kind of the same with programming languages
10:44:30 <sbrg> writing C gives me a hangover
10:44:38 <sbrg> merijn: time-traveling alien robot
10:44:44 <monochrom> But since 10 years ago I just tell you about well-ordering.
10:44:57 <np356> what is "UB"?
10:44:59 <erisco> the kind where 1 ⊆ 2 ? :s
10:45:05 <sbrg> undefined behavior?
10:45:10 <np356> ah
10:45:15 * EvanR scowls at erisco 
10:45:27 <erisco> it's free theorems, man
10:45:45 <hpc> undefined behavior is the language designer abdicating responsibility for saying what programs do
10:45:58 <merijn> hpc: undefined behaviour is the worst...
10:46:05 <np356> so,. my takeaways for tonight: 1) Haskell is not ready yet 2) haskell is beautifull and I should keep exploring it in my private time.
10:46:17 <hpc> merijn: there's a really heinous one in C i read about the other day, lemme find it
10:46:18 * np356 just made a decision for over 25 devs :)
10:46:20 <merijn> hpc: Hell, just define all undefined behaviour to be implementation defined and life would be better
10:46:32 <EvanR> humanity is not ready yet
10:46:41 <MarcelineVQ> your takeaway should be to learn a language before shopping for a team for that language
10:46:46 <erisco> You can't handle the truth!
10:47:09 <hpc> merijn: https://blog.regehr.org/archives/213 - search for "unmatched"
10:47:10 <johnw> np356: um, how is it not ready yet?
10:47:12 <merijn> I like how occasionally people come in here saying "haskell is not ready" while huge amounts of haskell are deployed in multiple companies
10:47:21 <johnw> exactly, what merijn said
10:47:22 <np356> MarcelineVQ: I never shop for people for a languge. I shop for math and algo skills
10:47:24 <dminuoso> And I dont think you can sufficiently learn Haskell to be competent to hire and *lead* a team in a anything less than a year .
10:47:32 <np356> languges can always be learent
10:47:33 <sbrg> if I were a compiler writer for a language whose spec contains a bunch of UB cases, I would intentionally try to generate code for those cases that is completely absurd.
10:47:39 <erisco> np356, the unreadiness of Haskell has been greatly exaggerated: https://github.com/Gabriel439/post-rfc/blob/master/sotu.md
10:47:46 <MarcelineVQ> that's an amazing sidestep from the point
10:48:12 <erisco> np356, also https://wiki.haskell.org/Haskell_in_industry
10:48:36 <merijn> sbrg: You might be interesting in the thought experiment of the "maximally malicious compiler"
10:48:46 <erisco> every major player is in on it… be there or be square!
10:48:59 <erisco> or maybe it is be there *and* be square…
10:49:10 <monochrom> Only Dennis Ritchie ever grokked the logical conclusion to the maximally malicious compiler. >:)
10:49:30 <erisco> tell me more
10:49:35 <merijn> sbrg: I can't find the link anymore, but it was cpercival discussing analysing the security of crypto code and proposing a "maximally malicious compiler", i.e. the compiler that has the maximum malicious effect on code while still being standard compliant
10:49:40 <hpc> and a maximally malicious compiler still produces valid C code too!
10:49:45 <erisco> maximal by what ordering?
10:49:52 <merijn> sbrg: Such as the realisation that there's no guaranteed way to safely zero out memory in C
10:49:54 <monochrom> If you could find his Turing Award acceptance speech, it's there.
10:50:24 <merijn> monochrom: No, because his trusting trust compiler isn't C standard compliant
10:50:46 <merijn> monochrom: Specifically this was about "what's the maximum negative impact UB can have"
10:51:25 <erisco> generally or in context of C specifically?
10:51:31 <dysfun> even ignoring UB, a malicious standards-compliant compiler can fuck you up
10:51:37 <erisco> seems to be an odd question generally speaking
10:51:39 <romanix> i'm recompiling all the dependencies in my project with stack build --executable-profiling --library-profiling --ghc-options="-fprof-auto"
10:51:48 <dminuoso> dysfun: Not if your program is strictly conforming.
10:52:04 <hpc> actually yeah, what's the difference between UB and implementation-defined?
10:52:07 <dysfun> yes, cryptocode
10:52:19 <dminuoso> hpc: implementation-defined *has* to be defined by the implementation.
10:52:20 <hpc> afaict, both can still emit rm -rf
10:52:22 <dysfun> hpc: your compiler vendor gets to decide what ID does
10:52:23 <romanix> if I then recompile without profiling, will the deps be reused? they take forever to build :)
10:52:24 <merijn> hpc: UB doesn't even have to do the same thing each time
10:52:28 <hpc> ah
10:52:38 <merijn> hpc: implementation defined can do whatever, but has to consistently do the same thing
10:52:43 <MarcelineVQ> romanix: if they were build without profiling previously they won't need to be built again
10:52:45 <EvanR> UB = maybe monkeys fly out of your nose?
10:52:47 <merijn> UB can arbitrarily pick what it does at runtime
10:52:48 <hpc> can a compiler define its implementation to tread ID behavior as UB?
10:52:50 <dminuoso> hpc: And it must not only define it, but document that implementation.
10:53:02 <dminuoso> hpc: Which is why GCC for example has a section where each bit of implementation defined behavior is listed.
10:53:04 <dysfun> *in practice*, UB tends to cause code elision
10:53:07 <merijn> hpc: Not sure
10:53:09 <hpc> surely a compiler can document what a particular undefined behavior does
10:53:14 <dminuoso> dysfun: Or it causes code reordering.
10:53:20 <jollygood2> is there a "splitOnce" function in either prelude or Data.List.Split? splitOnce " " "one two three" => ["one", "two three"]
10:53:28 <dminuoso> Which is extremely frustrating because code wont seem to execute in order of your program.
10:53:29 <dysfun> you should expect code reordering anyway
10:53:29 <merijn> hpc: Compilers CAN treat UB reliably, but are not required to
10:53:33 <MarcelineVQ> romanix:  --profile implies --executable-profiling --library-profiling  if you want to save some keys
10:53:34 <sbrg> jollygood2: span?
10:53:37 <sbrg> :t span
10:53:38 <lambdabot> (a -> Bool) -> [a] -> ([a], [a])
10:53:39 <monochrom> But the short story is that you can insert malicious code into one version of the compiler source code, and if you do it cleverly enough, you don't need to keep this malicious code in the next version source code, the malicious version will compile the next benign version to be malicious too.
10:53:44 <hpc> merijn: my point is, they can tread ID unreliably as well
10:53:49 <sbrg> > span (== ' ') "foo bar baz"
10:53:51 <lambdabot>  ("","foo bar baz")
10:53:56 <sbrg> oops.
10:53:58 <hpc> merijn: by just documenting the implementation as "does some arbitrary thing we don't know what it does"
10:53:59 <dminuoso> dysfun: Yes but for example you can produce situations one `printf` is reordered around the next.
10:54:01 <sbrg> > span (/= ' ') "foo bar baz"
10:54:03 <lambdabot>  ("foo"," bar baz")
10:54:07 <hpc> there, the implementation defined ID as UB
10:54:16 <exio4> hpc: implementation defined can also be quite restricted, I mean, the actual size of an int is ID
10:54:36 <monochrom> But listen to merijn. I am not talking about UB. I'm just talking about malicious.
10:54:36 <exio4> (with a minimum size)
10:54:37 <dysfun> dminuoso: are you talking about if you have a race condition?
10:54:41 <dminuoso> dysfun: No
10:54:43 <jollygood2> sbrg didn't use the best example, it should split by string, which may contain more than one character
10:54:58 <merijn> hpc: I don't think that actually holds
10:55:04 <hpc> exio4: ah that makes sense then
10:55:11 <merijn> hpc: Because it doesn't make sense for the first couple of cases I see about ID
10:55:12 <jollygood2> string contains sequence to split on, not a list of delimiters
10:55:14 <sbrg> jollygood2: then perhaps just `listToMaybe (split ..)`
10:55:17 <dminuoso> dysfun: Violating strict aliasing rules has some bizarre effects because it causes the compiler to not see R/W dependencies. This can cause some proper code reordering, or not emitting some code at all.
10:55:19 <exio4> hpc: another example, in C++11, UB means you have 0 guarantees when it comes to race conditions, ID still has to respect quite a lot (iow, it cannot go against the memory model, for example)
10:55:27 <sbrg> > listToMaybe ["foo", "bar baz"]
10:55:29 <lambdabot>  Just "foo"
10:55:33 <dysfun> ah yes, aliasing, that whole other bag of fun
10:55:34 <exio4> I repeated too much, ignore my crappy english :) 
10:55:39 <merijn> hpc: For example: "A conforming implementation shall produce at least one diagnostic message (identified in an implementation-defined manner) if a preprocessing translation unit or translation unit contains a violation of any syntax rule or constraint"
10:56:55 <erisco> can we just get new languages with actual semantics and not look back, please
10:56:57 <monochrom> I think UB allows nondeterminism while ID doesn't. Right?
10:56:59 <dysfun> exio4: that's sort of a side effect almost though. the contract is you assert that your code does not have race conditions, and *therefore* it can assume that there are no race conditions
10:57:15 <dminuoso> monochrom: UB allows anything. ID must be well defined according to the rules of the abstract machine.
10:57:48 <exio4> dminuoso: that's a nice way to put it :P 
10:57:55 <merijn> dminuoso, monochrom: I don't actually see any details on what ID "is", besides: "A conforming implementation is required to document its choice of behavior in each of the areas listed in this subclause."
10:58:28 <merijn> ok, I'm getting somewhere
10:58:36 <merijn> "Implementation-define behaviour: unspecified behavior where each implementation documents how the choice is made"
10:58:55 <monochrom> I think the choice of the word "defined" also carries information.
10:59:20 <merijn> "unspecified behavior: use of an unspecified value, or other behavior where this International Standard provides two or more possibilities and imposes no further requirements on which is chosen in any instance"
10:59:34 <dminuoso> merijn: behavior, for a well-formed program construct and correct data, that depends on the implementation and that each implementation documents
10:59:42 <dminuoso> merijn: that is straight from the current draft.
10:59:53 <merijn> hpc: I think the standard implicitly assumes that when an "implementation defined value" is referred too, it means a specific unique one
11:00:05 <merijn> dminuoso: My quote is straight out of C11
11:00:13 <dminuoso> merijn: Oh we are talking about different languages then.
11:00:15 <monochrom> This is so Sunday school Bible study group.
11:00:23 <merijn> dminuoso: Which one are you talking about, then? o.O
11:00:29 <hpc> K&R bible study ;)
11:00:31 <dminuoso> merijn: C++
11:00:44 <merijn> dminuoso: Who the fuck is crazy enough to even open the C++ spec? >.>
11:00:45 <dminuoso> merijn: but in this respect they are the same it appears.
11:01:28 <dminuoso> merijn: what do you expect to happen when you define such a complex language with operational semantics?
11:01:30 <dminuoso> :P
11:01:59 <monochrom> Still easier than writing out a denotational semantics.
11:02:03 <erisco> 3.8 "C provides the infinitely-abusable goto statement, and labels to branch to. Formally, the goto is never necessary, and in practice it is almost always easy to write code without it." So sayeth we all.
11:02:19 <merijn> erisco: I call BS
11:02:25 <dminuoso> erisco: Thats nonsense. 
11:02:27 * johnw is waiting for how this all relates to Haskell again...
11:02:39 <erisco> read it and weep XD
11:02:46 <merijn> I have run into a bunch of situations where goto was the only real option when dealing with breaking out of nested loops
11:02:46 <dminuoso> erisco: if is just a conditional goto. So jumping to specific points in code must be useful.
11:02:52 <merijn> johnw: Never!
11:02:55 <exio4> we're going to write Haskell compiler, and we need to know C semantics johnw :)
11:03:08 <johnw> need to take it #haskell-bash-other-languages
11:03:26 <romanix> MarcelineVQ, thank you
11:03:29 <merijn> johnw: Or maybe, soon, since I'm about to stop language lawyering and see if I can maybe get my phone repaired so I'm not completely cut off from the real world >.>
11:04:12 <dminuoso> merijn: Just do what everyone does: buy a new phone.
11:04:23 <johnw> merijn: isn't that a positive thing though?
11:04:29 <dminuoso> Much faster than this tedious repair process. You also get that exciting feeling of unwrapping fresh plastic.
11:04:43 <merijn> dminuoso: It broke on the way to a conference, so not really an option
11:05:13 <merijn> dminuoso: Not going to buy a phone in the US, because that'd leave me SOL on warranty/repairs if that breaks when I get home
11:05:14 <dminuoso> They dont have phone shops there?
11:05:17 <dminuoso> Ah.
11:05:26 <merijn> dminuoso: Also, different carrier frequencies, etc.
11:05:41 <dminuoso> merijn: Where are you from originally?
11:05:47 <hpc> it's because phones in the US are NTSC
11:05:49 <merijn> dminuoso: Netherlands
11:05:58 <dminuoso> hpc: Never the same color?
11:06:10 <erisco> merijn, dminuoso, it is okay. K&R also sanctions appropriate uses of goto. Study carefully :)
11:06:27 <merijn> You'd be surprised how easy it is to get lost abroad when you're used to 100% relying on a phone and google maps >.> But that's probably more -offtopic territory :p
11:07:10 <dminuoso> erisco: Im much more excited about languages supporting COMEFROM.
11:07:17 <dminuoso> Now that's how you can write exciting code.
11:07:35 <hpc> how would a conditional comefrom work?
11:07:47 <erisco> lol
11:08:35 <monochrom> We have a little of that in exception handlers already. "If I come from an IOException, print it; else if I come from a division by zero, return 1; else if..."
11:08:57 <hpc> ah
11:09:06 <hpc> so you just have to write a sum type for every goto in your program and you're good
11:09:14 <hpc> what could go wrong
11:09:25 <dminuoso> Except that exceptions only work from nested code. COMEFROM works from arbitrary code locations!
11:09:29 <erisco> yeah no problem just keep a list of line numbers on the company fridge
11:09:33 <monochrom> I'm deliberately misinterpreting. Obviously they mean "if 3>x then I come from line 45" and I still don't know how to do that.
11:10:12 <hpc> obviously what we need is a stack-based exception system
11:10:23 <hpc> instead of lexical try-catches, you just push a handler onto a global stack
11:10:27 <erisco> what is the exception for an exception stack overflow?
11:10:29 <hpc> and maybe remember to pop it later
11:13:20 <monochrom> Oh I know how to do "if 3>x then I come from line 45". cabal has been doing that.
11:13:35 <dminuoso> monochrom: You just throw an ExceptionException. And becaue the stack is full, akin to triple faults, you just reboot the system,
11:14:32 <erisco> maybe give them a QR code to scan
11:14:35 <monochrom> Because you write "if myflag then base >= 3 && < 4", then the semantics is: if you find that your base is version 3.5 for example, then set myflag to true.
11:15:21 <erisco> I haven't looked at cabal but I wonder then if it is not a procedural semantics
11:15:43 <monochrom> Sometimes it is Prolog semantics.
11:15:59 <monochrom> myflag :- base >= 3 && < 4
11:16:00 <erisco> right, that would start to give some sense to the idea
11:16:34 <monochrom> And sometimes it is vanilla if-then, e.g., "if impl(ghc) then ..."
11:17:06 <monochrom> It can get very funny when you mix the two.
11:17:51 <erisco> and that is procedural? or is it just an implication?
11:18:05 <monochrom> Procedural.
11:18:22 <monochrom> Hmm, I am not sure.
11:18:31 <monochrom> IANACL
11:19:31 <exio4> cabal lawyer? :)
11:19:32 <erisco> how about an "undo" feature, such as "undo 45" which means the state is now as though line 45 was not executed
11:20:00 <monochrom> Implication. Both favours of "if-then-else" are just a lot of logical sentences looking for a solution.
11:20:51 <monochrom> I mean you try to solve for all the variables (e.g., flag values, package versions) to satisfy all sentences.
11:23:00 <erisco> that may not be so unreasonable for backtracking
11:23:15 <monochrom> About the "how to find out which equvalence class" question you had yesterday, my thought is this.
11:23:57 <monochrom> So for example Data.Ratio. First instinct is you can ask for numerator and denominator, so it looks like you ask to see a canonical representative. But this was not on my mind.
11:24:44 <monochrom> On my mind was for example its Show instance. You have a Rational->String function, and it's injective (module the equivalence relation).
11:26:32 <monochrom> So generally "how to find out which equivalence class" or even for any given type "how to find out which value" at all: First you have to assume a codomain that you agree to be meaningful or readable or comprehensible to you. For example String.
11:27:08 <monochrom> And you don't ever ask the foundational question "but how do I know which String? how do I tell apart two String values?"  You have to stop somewhere.
11:27:37 <Unhammer> lyxia,  apparantly my haskell-gi crash was solved in https://github.com/haskell-gi/haskell-gi/commit/814a6d35909e554f6b5a6a4650b18402f9bbb645 and it seems my nagging got Iñaki to release haskell-gi-base-0.20.5 :) 
11:27:41 <monochrom> But with that, you can now require an injective function, an observer, from the mysterious type to your codomain.
11:28:18 <monochrom> If the mysterious type is a quotient type, then injectivity is just up to equivalence, but you already expect that.
11:29:55 <erisco> does this differ from canonical representatives? is this function just a means to obtain it?
11:30:42 <monochrom> My rationale behind this is Leibniz. For all function f that you care, if x=y then f(x)=f(y). This draws a line between equivalence relations and equality. All equalities satisfy this, some equivalence relations don't have to.
11:31:52 <monochrom> Yes for the Data.Ratio example, because the Show instance happens to go like "3%5". No in general, I could have some other scrambled but still injective observer.
11:32:36 <monochrom> I could go Rational->Integer too. There are many contrived injections for that.
11:33:04 <monochrom> In other words the injective observer doesn't have to be user-friendly.
11:33:12 <lyxia> Unhammer: hurray!
11:34:19 <Unhammer> :)
11:35:05 <monochrom> My basic philosophy is to tear apart the question "how to find out which value or equivalence class I'm holding in my hand" and ask back "OK if I gave you an answer, how would you read that answer anyway?" So there is no escape from an observer function, and how Leibniz connects functions with equality.
11:35:30 <monochrom> And if you need an observer function then you need an informative codomain.
11:37:16 <erisco> if I have a canonical representative r, and my equivalence ≅ then I can determine if any other element is in the same equivalence class as r
11:37:26 <erisco> that would be my version of "reading it back"
11:38:29 <erisco> also, because you have r, say you also have another representative s, then you can determine if they are different or identical equivalence classes
11:38:33 <monochrom> You don't always need canonical.
11:38:40 <pzp> hpc:  I think I got it without using lookahead!
11:38:45 <pzp> https://www.irccloud.com/pastebin/1mCglZP0/
11:38:57 <erisco> so that is how you can then determine which class it is, by comparing with other representatives
11:39:42 <stevenxl> Hello. where do folks on the persistent library hang out? I tried #persistent but that chan was empty.
11:39:43 <erisco> without the representative, and just the equivalence relation, then you need a way to compare the relation, which isn't possible if we use a general function
11:40:33 <erisco> but by requiring a representative we also exclude quotients that have classes where no canonical representative is computable … trade offs I suppose
11:40:54 <monochrom> If you just want that, you don't even need to open up the abstract value to see the conrete representation.
11:41:09 <dminuoso> Why are (->) not Eq?
11:41:27 <monochrom> If you give me x,y::Rational, I can already do x==y, without me asking for numerator or denominator.
11:41:38 <johnw> it's the wrong kind, do you mean ((e) ->)?  In that case, how do compare functions?
11:41:41 <erisco> dminuoso, try to implement it
11:41:46 <johnw> oops, ((->) e)
11:42:04 <lyxia> Eq ((->) e) is still not well-kinded
11:42:08 <dminuoso> erisco: My inability does not translate to something being impossible or really hard.
11:42:15 <johnw> lyxia: oh, right
11:42:19 <johnw> mental slip
11:42:21 <lyxia> :)
11:42:24 <dminuoso> Mmm.
11:42:26 <jared-w> Pretty excited to be doing some "real" stuff in Haskell. I really need to do these small fun projects more often
11:42:27 <erisco> dminuoso, it might translate to insight :)
11:42:32 <dminuoso> erisco: Ohh ok.
11:42:37 <dminuoso> Let me try then. :)
11:42:45 <slack1256> What are my resources for learning to optimize haskell? learning core and recognize how good core looks like? that is the first right?
11:43:25 <lyxia> slack1256: that's a good first step
11:43:35 <dminuoso> erisco: Mmm. Well fine ((->) a b) for some given a and b.
11:43:38 <jared-w> slack1256: As far as learning to optimize haskell, I'd say that learning to read core is probably towards the last step, honestly
11:44:22 <erisco> monochrom, you're right, but it is relevant for implementing == where you do have to open it up
11:44:23 * geekosaur notes that the universe package has an (Universe a, Universe b) => Eq (a -> b) instance. it's potentially a very slow instance
11:44:44 <jared-w> like sure, it's helpful, but a large amount of it is going to be some equational reasoning and reasoning about lazy behavior w.r.t. space and time. Core just gives you a sense of what your code compiled to, which only really helps if you know what it "should be" compiling to in the first place
11:45:04 <erisco> monochrom, in the back of my mind I am thinking about a generic  Quot a b  type which is  a/b
11:45:15 <erisco> maybe you can notationally make that  a :/ b
11:45:26 <monochrom> erisco: But implementing == needs just a representative, no need to canonicalize.
11:45:29 <dminuoso> geekosaur: considering it being universe, does this just test whether both produce the same reults for any possible input?
11:45:37 <geekosaur> exactly
11:45:47 <geekosaur> and there's a reason for that
11:45:55 <jared-w> http://www.vex.net/~trebla/haskell/lazy.xhtml slack1256 this is a good thing to read
11:46:58 <dminuoso> geekosaur: Im guessing that there is no efficient algorithm to show that two lambda expressions are equal?
11:47:19 <dminuoso> (And by equal I mean extensionally equivalent)
11:47:39 <monochrom> That's a very different question.
11:47:52 <geekosaur> and "efficient" doesn't come into it
11:48:04 <dminuoso> ability does?
11:48:41 <erisco> Church's undecidability theorem was the first in mathematics, so I read
11:48:46 <monochrom> If I am giving two lambda expressions, I can take a look at their source code. But a compiled Haskell program can't look at it.
11:50:32 <erisco> monochrom, hm, yeah, that is weaker… you just need to determine if two terms join
11:53:45 <monochrom> In practice we usually know a canonical representative. Not just that, we actually design it to be computationally cheapest. Amazing, eh?
11:53:55 <dminuoso> Ohh, its a result from Rice's theorem. :|
11:54:07 <erisco> or was it "meet" … have to dig out some reference material oO
11:54:26 <monochrom> Like 1/2 + 3/4 is much cheaper than 10000/20000 + 30000/40000
11:55:02 <dminuoso> This is interesting, if I could construct such a general function, it could solve the halting problem (which has been proven to be unsolvable)
11:55:04 <dminuoso> :o
11:55:47 <Tuplanolla> Do you happen to know the performance difference between representing rationals as factorizations, monochrom?
11:56:05 <monochrom> No.
11:56:07 <Tuplanolla> That would be interesting.
11:56:22 <monochrom> I do think that addition ruins the day.
11:56:49 <monochrom> (2^10934 / 1) + (1/1)  Oh my God I don't want to do it.
11:58:01 <monochrom> Whereas GCDing every so often is at least known to be polynomial time. :)
11:58:16 <slack1256> thanks jared. Indeed I don't know what core should look like
11:58:17 <xcthulhu> When do you gcd?
11:58:30 <monochrom> When I do 3/5 + 2/5
11:58:41 <monochrom> Or rather, right after.
11:59:01 <xcthulhu> Hmm... couldn't you just do it when displaying?
11:59:06 <erisco> monochrom, what I am thinking of is what you do put in the constructor
11:59:13 <xcthulhu> Or maybe when dividing?
11:59:42 <monochrom> I could, but why store 500000/500000 for the next 24 hours when I can just store 1/1?
11:59:46 <erisco> monochrom, a canonical representative works … I am not sure what else would
12:00:09 <xcthulhu> monochrom: It's a memory/time trade off I guess
12:00:12 <geekosaur> also multiplying. but now remember that addition and subtraction may end up multiplying if the denominators aren't identical
12:00:14 <erisco> assuming that we are going to let users pattern match our constructor
12:01:28 <erisco> efficiency is a balance between being proactive and being lazy ;)
12:01:50 <monochrom> xcthulhu: Denominators grow rapidly, I think exponentially, if you procrastinate GCDing. And it is not always time vs space. A longer number takes longer to add or multiply.
12:01:54 <erisco> proactive and procrastinating is better word play
12:02:25 <erisco> and takes longer to read and write to memory
12:02:26 <Kaelara> What does GCD mean?
12:02:35 <geekosaur> greatest common denominator
12:02:39 <Kaelara> Thanks
12:02:42 <geekosaur> er divisor
12:02:57 <geekosaur> you want the smallest representyation that doesn;
12:03:00 <geekosaur> t lose data
12:03:04 <Tuplanolla> Augment every object with a machine learning component that figures out the perfect time to simplify the representation.
12:03:18 <monochrom> erisco: By having an equivalence relation, and by requiring all operations to respect it, we are logically implying that any representative already gives correct answers. So the rest is just going for better efficiency.
12:04:40 <erisco> that's fine but I would preferably achieve a solution such that you can't not respect it
12:05:08 <erisco> which is a not straight-forward as making sure even pattern matching the constructor does not reveal any differences in the same equiv class
12:05:28 <geekosaur> so 5/8 + 5/8 = 10/8, (gcd 10 8) is 2 so normalize to 5/4. this case is trivial but it gets nastier as you operate with rationals; as monochrom said, the denomirnators grow exponentially because to e.g. add 3/2 and 1/3 you need to convert both to have the same denominator
12:05:48 <Tuplanolla> (In fact Octave does something to that effect with array representations.)
12:06:34 <geekosaur> and of course multiplication and division will operate on both, and for division you may have to arrange for the denominator to remain integral
12:06:35 <monochrom> xcthulhu: Also of interest is mod-n arithmetic. Compute ((3^2309843) `mod` 4), vs a loop that multiplies by 3 but then mods 4 right away before the next ieration.
12:06:40 <erisco> note that this is a correct use of the word "exponentially" ;)
12:08:03 <monochrom> Oh! Right, if you want to support pattern matching, you'd better decide upon a canonical representative that's both efficient and aesthetic.
12:08:37 <erisco> maybe go for the "compute me once shame on you, compute me again shame on me" reduction strategy … oh that's just laziness ;)
12:08:38 <monochrom> I think for most programmable quotient types we actually manage that. Don't know why but it's amazing.
12:08:53 <monochrom> The Unreasonable Effectiveness of Programmers Figuring It Out.
12:09:37 <monochrom> Oh Haha I know how to confound all this.
12:10:09 <monochrom> I want the abstract type of ordering set, i.e., say, call it "Set a" and I can afford the "Ord a" constraint.
12:10:27 <monochrom> Oh wait that's too easy.
12:11:12 <monochrom> OK, the abstract type of set, call it "MSet a", M for monochrom, and I can afford the "Eq a" constraint, but I don't have Ord a.
12:11:18 <monochrom> CANONICALIZE THAT
12:12:01 <monochrom> You can't even say "use a list internally, keep it sorted" because I've just castrated Ord from you.
12:12:09 <erisco> I know :\
12:12:21 <monochrom> Using a list internally is OK but you don't have a preferred order.
12:12:33 <erisco> and don't use the word "castrated"… makes me uncomfortable
12:12:45 <monochrom> I knew there was a reason God made me teach that pesky data structure course.
12:12:53 <monochrom> OK sorry.
12:13:50 <monochrom> The really annoying part is that mathematically Eq is enough for basically all finite set operations. Just not so efficient.
12:14:43 <monochrom> So everything is fine, or rather "can't be helped", until you want to pattern-match and expose a representative.
12:14:49 <nshepperd> newtype MSet a = MSet (a -> Bool)
12:14:53 <erisco> what equivalence do I have to use?
12:15:11 <nshepperd> oh, that doesn't support (==) on sets
12:15:23 <xcthulhu> monochrom: https://hackage.haskell.org/package/set-monad
12:15:40 <xcthulhu> monochrom: This avoid Eq and Ord
12:15:44 <xcthulhu> *avoids
12:15:46 <monochrom> Mutual subsetness. Or in more detail, xs == ys iff every element of xs is found in ys, and vice versa.
12:16:29 <erisco> oh, well that makes things more tractable
12:16:48 <xcthulhu> monochrom: There's also this old Oleg article: http://okmij.org/ftp/Haskell/set-monad.html
12:16:56 <erisco> I am going to suggest \\
12:17:09 <monochrom> xcthulhu: Explain "Ord a => Eq (Set a)" to me.
12:17:49 <erisco> is that good or do I have to spell out the whole implementation?
12:18:26 <monochrom> Yeah \\ is good. It isn't all that different from what I said.
12:18:39 <monochrom> Also I think you need to compute both xs\\ys and ys\\xs
12:19:07 <monochrom> > [1] \\ [1,2,3]
12:19:09 <lambdabot>  []
12:19:37 <erisco> that's right… \\ was just to be the key player in implementing a test for your property there
12:20:11 <xcthulhu> monochrom: It's a type of an Eq instance for set, from Data.Set.  If you import instances from Data.Set, then for any type a instancing Ord, then `Data.Set a` will instance `Eq`
12:20:57 <erisco> if I had to somehow come up with a canonical representative which was structurally identical, then I don't know
12:21:27 <monochrom> OK so set-monad has not eliminated Ord.
12:21:54 <monochrom> My definition of "doesn't need Ord" is "Eq (Set a)" no and, or, but.
12:22:22 <xcthulhu> monochrom: Oh, I don't think the Set monad has an instance for `Ord a => Eq (Set a)`
12:22:51 <monochrom> I'm reading set-mond.
12:22:56 <monochrom> err set-monad.
12:23:12 <monochrom> Anyway could you read the scrollbuffer again?
12:25:40 <stevenxl> .usd
12:26:03 <MarcelineVQ> .btc
12:26:20 <xcthulhu> monochrom: Okay, I see that apparently the set monad implements `Ord a => Eq (Set a)` aftter all, my bad
12:27:21 <monochrom> If you read the conversation and the context, I don't even care about monadness.
12:28:04 <monochrom> I brought up sets for quotient types and equivalence classes and data structures.
12:29:02 <xcthulhu> monochrom: Okay, well like you said, you can't get canonical representations with just Eq
12:29:37 <xcthulhu> monochrom: If you want a an abstract set that doesn't need Eq or Ord, here's how the set monad does it: https://github.com/giorgidze/set-monad/blob/master/Data/Set/Monad.hs#L167
12:30:32 <xcthulhu> Obviously it's not a quotient type anymore when you represent sets that way
12:31:07 <xcthulhu> (which, in the case of the set monad, is just monad algebra)
12:39:44 <xcthulhu> monochrom: If this isn't helpful I'm sorry
12:41:27 <stevenxl> Hi folks. Not sure if there is a specific irc channel for the spock framework.
12:41:34 <stevenxl> I'm looking at this: https://www.spock.li/tutorials/rest-api
12:42:03 <stevenxl> They mention Web.Spock.Action.setStatus
12:42:06 <stevenxl> But I don't see that module.
12:42:11 <stevenxl> Am I missing something?
12:43:56 <merijn> stevenxl: I don't see that thing mentioned anywhere there?
12:44:40 <merijn> oh, in the hints
12:48:23 <stevenxl> merijn: Yea
12:49:06 <merijn> No clue, I guess the tutorial bitrotted
12:49:14 <stevenxl> Cool - thank you.
12:51:47 <Kaelara> I don't think the tutorial literally bitrotted
12:55:11 <stevenxl> No. I think the documentation is not there. 
12:55:28 <stevenxl> setStatus is defined
12:55:34 <stevenxl> -- Defined in ‘Spock-core-0.12.0.0:Web.Spock.Internal.CoreAction’
12:55:56 <stevenxl> that function is jsut not documented.
13:03:43 <nshepperd> monochrom: I wrote a silly solution to your problem, based on hiding the list inside a lambda http://lpaste.net/360007
13:03:59 <nshepperd> it's just Cont Bool
13:04:20 <nshepperd> which happens to be possible to treat as a set
13:05:30 <nshepperd> i'm not certain if it is a perfect representation. it might be possible to write a (a -> Bool) -> Bool that is not a valid set
13:08:00 <nshepperd> the meaning of xs :: (a -> Bool) -> Bool as a set representation, is that xs (ys :: a -> Bool) if and only if xs is subset of ys
13:08:16 <nshepperd> where ys is interpreted as a set in the obvious way
13:11:42 <nshepperd> it's a silly solution because it doesn't really canonicalize, and gets slower linearly with every operation you do on the set. unless you're lucky and the laziness of (&&) helps you out
13:24:46 <jared-w> Do y'all prefer to do:   fmap f <$> thing, or (fmap . fmap) f $ thing  ?
13:26:21 <lyxia> (fmap . fmap) !
13:26:30 <hexagoxel> fmap (fmap f) $ thing
13:27:06 <Tuplanolla> Hardly ever operators when there's a choice. I even use `lens` with the long names.
13:31:29 <jared-w> It'd be neat if there was some even more concise way to do that sort of thing... But meh
13:31:52 <jared-w> hlint suggests fmap f <$> thing, which I found amusing
13:32:14 <jared-w> Tuplanolla: why the hate on operators? I personally really like them, although spaghetti abuse is easier to do for sure
13:32:40 <merijn> jared-w: I prefer the "fmap f <$> thing" one
13:32:47 <Tuplanolla> I really just want a better Scheme, jared-w.
13:32:48 <hexagoxel> getCompose . fmap f . Compose
13:32:55 <merijn> jared-w: tbh, I decide on a case-by-case basis depending on readability
13:33:41 <jared-w> `WebPage -> fmap fixUrl <$> scrapeStringLike xml wpUrls`  is the full ilne of code, for reference
13:34:02 <merijn> jared-w: Seems fine to me
13:35:24 <tinco> I get this: Ambiguous type variable ‘e0’ arising from a use of ‘try’
13:35:25 <tinco>       prevents the constraint ‘(Exception e0)’ from being solved.
13:35:38 <tinco> but I don't really care about e0, I just want to catch any exception
13:35:46 <tinco> is there a function that lets me do that?
13:35:55 <merijn> tinco: Use SomeException
13:36:00 <monochrom> You will want to read my http://www.vex.net/~trebla/haskell/exception-tutorial.xhtml
13:36:01 <merijn> tinco: That captures everything
13:36:09 <merijn> tinco: Also, read that
13:36:26 <monochrom> It is actually a bad idea to "catch any exception". Most of the time you don't mean it.
13:36:29 <tinco> ah thanks
13:36:45 <merijn> monochrom: meh, I think it really depends
13:36:50 <monochrom> Or at least, to responds to all exceptions the same way.
13:37:07 <monochrom> Sure, I just have "most of the time".
13:37:08 <merijn> monochrom: Usually I want to respond to all exceptions with "log and ignore"
13:37:14 <tinco> it would be so nice if Haskell would someday be pure.. is it ever under consideration to remove Exceptions from IO?
13:37:32 <Tuplanolla> Exceptions can come from anywhere, tinco.
13:37:34 <[exa]> Oh the impure world1
13:38:08 <[exa]> anyways, did you guys read the linearity paper from POPL? https://arxiv.org/pdf/1710.09756.pdf
13:38:08 <monochrom> Logging counts as "not responding to all exceptions the same way" because different exceptions yield different log messages.
13:38:21 <tinco> Tuplanolla: yeah perhaps, but they shouldn't arise from any Haskell libraries.. it just makes no sense it's implemented this way
13:38:36 <Tuplanolla> Consider `AllocationLimitExceeded` for example, tinco.
13:39:04 <merijn> tinco: I really dislike the fact that Haskell exceptions are unchecked, yeah
13:39:19 <monochrom> Exceptions being uncatchable outside IO is actually how Haskell stays pure.
13:39:26 <jared-w> If haskell is impure I don't even wanna know what the fuck PHP is lol
13:39:42 <tinco> impure :P
13:39:46 <tdammers> PHP is everything you want it to be... ex falso quodlibet...
13:39:55 <Tuplanolla> @hackage inline-php
13:39:55 <lambdabot> http://hackage.haskell.org/package/inline-php
13:39:59 <monochrom> In the same way getLine being impossible outside IO is how Haskell stays pure.
13:40:00 <jared-w> ಠ_ಠ
13:40:06 <merijn> monochrom: I've been working on a prototype implementation for pure checked exceptions with catch outside IO, but I don't have the time to continue with it
13:40:11 <hpc> is unsafePerformIO standard?
13:40:22 <tinco> if you have a soup and there's a hair in it, then it's impure like haskell is, and if you have a soup and someone pooped in it, then it's impure like php is :P
13:40:26 <merijn> monochrom: I'm not convinced it's required to keep exceptions in IO to be pure
13:40:31 <merijn> hpc: Yes, part of the FFI chapter
13:40:35 <hpc> the presence of that requires effects to be a member of every type
13:40:40 <[exa]> hpc: you ask this from a system written in C/C++? :D
13:40:41 <hpc> so from that perspective haskell is impure
13:40:47 <merijn> hpc: At least in Haskell2010 and Haskell98+FFI addendum
13:41:35 <hpc> (although that's mostly nitpicking)
13:42:09 <monochrom> merijn, what you have in mind is probably highly deterministic and synchronous exceptions, which are Either, sure.
13:42:25 <monochrom> But I analogized with getLine for a reason.
13:44:52 <geekosaur> I still think quite a few things that are currently exceptions ought to be Except e
13:45:11 <jared-w> as opposed to?
13:45:24 <monochrom> Oh you would be right to say that to all deterministic synchronous exceptions such as end-of-file.
13:45:38 <monochrom> or rather s/say that to/say that of/
13:45:46 <monochrom> Damn English.
13:46:16 <monochrom> jared-w, I suppose as opposed to the status quo e.g., getLine :: IO String  what a happy type.
13:47:08 <monochrom> Half of the people prefer getLine :: IO (Either IOException String) or a newtype thereof.
13:47:36 <monochrom> There are also people who prefer div :: Integral a => a -> a -> Maybe a
13:47:43 <jared-w> and the other half think IO implies exception anyway so why bother with the extra wrapping? :p
13:48:07 <monochrom> At some point the debate is equivalent to that about implicit types.
13:48:14 <geekosaur> I am more interested in the openFile case than end of file, which I am not sure is an exception at all
13:48:42 <monochrom> OK openFile is fairer.
13:48:44 <geekosaur> tht is, openFile synchronously knows whether it has failed or not, and shouldn't throw an exception
13:49:12 <jared-w> should it just be in a Maybe then, geekosaur?
13:49:14 <monochrom> But you're supposed to withFile instead. Now it can simply take two continuations and skip the sum type.
13:49:54 <geekosaur> jared-w, Maybe loses information. IO (Except e ())
13:50:01 <geekosaur> er, Excepot e Handle
13:50:03 <geekosaur> bleh
13:50:46 <monochrom> reborn_withFile "/dev/zero" ReadMode (\h -> hGetChar) (\e -> putStrLn "Oh you're on Windows" >> return '\0')
13:51:59 <jared-w> How is Except e different than throwing an exception?
13:53:19 <drdo> jared-w: That's basically Either
13:54:19 <jared-w> drdo: ah okay, I was just reading something wrong and getting confused for no reason then :p
13:54:22 <geekosaur> as opposed to some thing I have to separately catch
13:54:40 <geekosaur> Except is just Either that recognizes Left is a failure condition, whereas Either is supposedly agnostic
13:54:57 <geekosaur> (it's still not for historical reasons)
13:56:03 <monochrom> You will sometimes see me doing, or wanting, openFile xxx ReadMode <|> openFile yyy ReadMode.
13:56:27 <monochrom> So I won't want IO (Except ...). But you can talk me into ExceptT IO.
13:56:55 <drdo> ExceptT on IO seems strange
13:57:11 <drdo> just throw the exception
13:57:15 <monochrom> Well, ExceptT IO_without_exception
13:57:26 <geekosaur> I'm also trying to navigate the weirdness where base can't use mtl
13:57:36 <drdo> monochrom: but there is no IO_without_exception
13:57:39 <monochrom> But yes I am a fan of simply IO Handle, at least for this.
13:57:52 <monochrom> I AM ON YOUR SIDE!
13:58:05 <geekosaur> and bringing mtl into it brings the whole upgrading-stuff-that-comes-with-ghc/base mess into it
13:58:22 <drdo> I don't have a strong opinion at all on exceptions
13:58:43 <drdo> Just pointing out that we are stuck with IO being able to throw exceptions at any time
13:59:28 <monochrom> Bottomline: I want to do "openFile xxx ReadMode <|> openFile yyy ReadMode" so any type that allows this is fine with me.
13:59:28 <merijn> No, it's definitely *not* Either, because if it was I would just use Either
14:00:24 <monochrom> Then again I guess if xxx fails on the slight pretext of ThreadKilled then I'm wrong.
14:00:56 <drdo> monochrom: ye I'm not sure why you'd wanna do that except in some throwaway script
14:01:20 <monochrom> Oh but most of my Haskell programs are throwaway scripts!
14:01:57 <merijn> monochrom: It won't work with async exceptions, sure. But in the grand scheme of things there's a lot that hierarchical exceptions like we have in IO can do that Either can't if you don't need async exceptions
14:02:03 <nshepper1> <|> in such a case "catches all exceptions" right?
14:02:05 <merijn> monochrom: I'm not entirely sold on async exceptions anyway
14:02:08 <monochrom> Where is np356 when we need them to say "see, Haskell is not ready?"? :)
14:02:19 <monochrom> Yeah nshepper1
14:02:45 <drdo> exceptions sure do make things a lot trickier to do
14:03:36 <nshepper1> An ExceptT mechanism or something could at least separate sync (io) exceptions from async exceptions
14:03:43 <monochrom> Oh subtyping makes exceptions nicer. The SML people found this out.
14:04:02 <nshepper1> So that your <|> would only catch io exceptions
14:04:11 <merijn> monochrom: Either also doesn't really work well with unions of exceptions
14:04:24 <monochrom> Some SML people use SML exceptions for ordinary class hierarchies!
14:04:29 <drdo> My issue with exceptions is that control flow can go bananas at any time, makes it harder to reason about things
14:04:55 <monochrom> Object : Java :: Exception : SML.
14:06:49 <nshepper1> Separately, you could try to make exceptions in io act like checked exceptions, which means having type level sets or something, and writing functions and datatypes that are polymorphic over the checked exception set
14:08:10 <merijn> nshepper1: Well, yeah, that's roughly the kinda thing I was trying to do
14:08:25 <drdo> nshepper1: Well, you can still receive any exception at all via throwTo
14:08:29 <merijn> But sadly, no one wants to pay me for hacking on languages :\
14:08:44 <merijn> drdo: Well, like I said, I'm not really sold on async exceptions yet
14:08:45 <pzp> Why is concatMap not generalized to work for all Monoids?
14:08:56 <monochrom> Exception control flow is as good as Either control flow: http://www.vex.net/~trebla/haskell/exception.xhtml
14:08:57 <pzp> something like this maybe https://www.irccloud.com/pastebin/p02pGF07/
14:09:06 <drdo> merijn: How else would you kill threads?
14:09:07 <nshepper1> drdo: async exceptions would be handled separately
14:09:50 <merijn> drdo: Who says async exceptions should work the exact same way as regular exceptions?
14:10:04 <pzp> or better yet `concatMap f = foldr (mappend . f) mempty`
14:10:05 <drdo> merijn: No one, I suppose
14:10:21 <drdo> But you still have to be ready for your thread to be terminated at any point
14:10:24 <monochrom> @type \f -> foldr (mappend . f) empty
14:10:26 <lambdabot> (Alternative f, Monoid (f a1), Foldable t) => (a2 -> f a1) -> t a2 -> f a1
14:10:27 <drdo> So the difficulties remain
14:10:48 <monochrom> err
14:10:50 <monochrom> @type \f -> foldr (mappend . f) mempty
14:10:52 <lambdabot> (Monoid b, Foldable t) => (a -> b) -> t a -> b
14:10:53 <drdo> Which are mostly resource cleanup in my experience
14:11:06 <pzp> monochrom: Yeah, exactly
14:11:18 <monochrom> @type foldMap
14:11:19 <lambdabot> (Monoid m, Foldable t) => (a -> m) -> t a -> m
14:11:39 <pzp> oh nice! completely forgot about that little guy
14:11:46 <pzp> thanks monochrom 
14:11:50 <monochrom> Heh
14:12:54 <merijn> drdo: Do you, do?
14:12:59 <nshepper1> Well, checked exceptions can't give you some assurance that your program will succeed. Someone could pull the power on your machine
14:13:11 <merijn> drdo: Why not have 2 classes of threads? 1 which can be killed and one that can't
14:13:29 <merijn> drdo: I think the way Haskell does threading/forkIO is flawed too
14:13:36 <nshepper1> But they can give assurance that you haven't forgotten to handle a failure to open a file or something
14:13:43 <merijn> I think you want first-class threading/concurrency and I haven't seen a language that does that
14:13:54 <drdo> merijn: We already have that, just uninterrutibleMask exceptions and catch everything
14:14:05 <Tuplanolla> I have yet to see a satisfying way to handle error conditions in any language.
14:14:28 <merijn> drdo: I'm not entirely sure what it'd look like, I have an ongoing thing about designing a language like that too, but honestly like the exception stuff I haven't touched it in more than a year due to lack of time
14:14:39 <barrucadu> merijn: What do you mean by "first class threading/concurrency"?
14:14:56 <drdo> I have no opinions on this, although I find dealing with exceptions in practice a major pain in the ass
14:15:00 <merijn> barrucadu: I'm not sure yet what I mean :)
14:15:23 <merijn> barrucadu: Consider how Haskell has first class IO (can be passed to functions, manipulated, etc.) there's no such thing for threads
14:15:33 <merijn> barrucadu: Threads only exist implicitly after you've done forkIO
14:15:39 <ertes> i'd be fine if threads simply couldn't be killed
14:15:53 <merijn> barrucadu: There's no explicit tracking of what threads can communicate with, what they can be interrupted by, who they can interrupt, etc.
14:16:24 <ertes> however, there would still be a question of how to interrupt actions like e.g. timing out Handle reads
14:16:24 <drdo> I still think the major issue is resource cleanup
14:16:39 <ertes> can't think of a better solution than async exceptions right now
14:17:15 <monochrom> Pride And Prejudice And Zombies --- three classes of threads.
14:17:43 <pierrot> Hi. I'm reading this book http://learnyouahaskell.com/functors-applicative-functors-and-monoids#monoids and it seems that at the time the author wrote it, the types of Data.Foldable's `foldr' and the `foldr' from Prelude were different. When did they become the same?
14:18:11 <monochrom> Around the time of GHC 8.0
14:18:20 <merijn> GHC 7.10, I think?
14:18:33 <pierrot> Does Prelude re-export Data.Foldable's `foldr' ?
14:18:41 <monochrom> Yes.
14:18:43 <Tuplanolla> @index foldr
14:18:43 <lambdabot> Data.Foldable, Data.List, Prelude, GHC.OldList, Data.ByteString.Lazy.Char8, Data.ByteString.Lazy, Data.ByteString.Char8, Data.ByteString, Data.IntMap.Strict, Data.IntMap.Lazy, Data.IntMap, Data.
14:18:43 <lambdabot> IntSet, Data.Map.Lazy, Data.Map.Strict, Data.Map, Data.Set
14:18:44 <merijn> Yeah, AMP and foldable's changes happened in 7.10
14:18:44 <drdo> pierrot: base 4.8.0.0 it looks like
14:19:18 <pierrot> Thanks
14:20:44 <monochrom> Books are outdated when the writing begins.
14:22:47 * romanix is looking for tips on why stack build --profile consumes all his ram and never finishes
14:23:11 <monochrom> Perhaps it really needs RAM.
14:23:59 <monochrom> If you say "I have 20GB and it's still asking for more" I don't know how to answer that.
14:24:01 <romanix> 8gb to generate profiling info for a web app?
14:24:50 <monochrom> But given that it demands more than 20GB, and you don't give it, you're going into swap space and that means "memory access" becomes 1000x slower.
14:25:16 <romanix> exactly, when it starts swapping i usually kill it
14:25:32 <romanix> because it's pointless
14:27:13 <drdo> I have to watch my ram closely, otherwise the machine will start thrashing when I least expect it
14:27:30 <drdo> Usually a combination of firefox and some compilation, sometimes just firefox
14:27:49 <monochrom> Aw, and Firefox already uses less memory than Chrome.
14:28:05 <drdo> They both just probably have massive memory leaks
14:28:19 <Tuplanolla> It goes over 4 GB after a months or two.
14:28:28 <drdo> If I restart it and reopen the exact same threads, it's suddenly using only a little memory
14:28:35 <monochrom> No I don't think it's leak because I can close some tabs and it frees up memory.
14:28:40 <drdo> monochrom: not here
14:28:47 <drdo> I have to close firefox at least once a day
14:28:55 <drdo> closing all threads does nothing
14:28:58 <merijn> drdo: Do you keep tabs open a long time?
14:29:05 <drdo> *all tabs
14:29:11 <monochrom> OK, I do close everything once a day, in fact I power off once a day.
14:29:18 <drdo> I never power off
14:29:32 <merijn> drdo: Chrome is fine for me, but I've noticed there's a lot of shitty JS leaking memory in popular sites
14:29:49 <merijn> In which case you can't really blame chrome, since the offending code is in some websites JS
14:29:59 <Tuplanolla> I only power off for the annual cleanup, so I have the same problems drdo does.
14:30:19 <drdo> powering off or not doesn't really make much difference in my case
14:30:21 <monochrom> Annual Internet Cleanup eh?
14:30:31 <drdo> Having to restart firefox is a daily occurrence
14:30:34 <drdo> sometimes several times a day
14:34:53 <raindev> I wonder how do you patch your kernels' security vulnerabilities without powering off :)
14:35:35 <Welkin> drdo: switch to firefox quantum
14:36:35 <Tops2> How do I link my students to the function composition operator?
14:36:36 <Tops2> Hoogle gives me http://hackage.haskell.org/package/base-4.10.0.0/docs/Prelude.html#v:-46- but it's not jumping to the definition like it usually does.
14:36:56 <dminuoso> How can I create a recusive type for a list of a list of a list.. ad infinitum ?
14:37:11 <Samo_svoj> any tutorial how to use machine lib?
14:37:32 <erisco> newtype X = X [X]
14:38:19 <dminuoso> erisco: Ohh that was easier than I thought. Thanks.
14:38:39 <merijn> Tops2: https://hackage.haskell.org/package/base-4.10.0.0/docs/Prelude.html#v:.
14:39:17 <merijn> dminuoso: Also, that's just Fix/Mu
14:39:33 <merijn> Although I forget where it's defined
14:39:50 <Tuplanolla> @hackage recursion-schemes
14:39:51 <lambdabot> http://hackage.haskell.org/package/recursion-schemes
14:39:53 <Tuplanolla> Here, merijn.
14:40:11 <M4GNV5> hey, i have a stupid question again: when i compile the following code with -O2 -threaded and run with +RTS -N4 it still runs only on one core, can someone tell me why? https://pastebin.com/rS83Q1WG
14:40:33 <merijn> M4GNV5: Because you're only using 1 thread?
14:40:34 <M4GNV5> i was looking at https://wiki.haskell.org/Haskell_for_multicores and i don't see much i am doing differently from there
14:40:37 <Tops2> Thanks, merijn :D
14:40:47 <merijn> M4GNV5: It doesn't magically parallelise your code
14:41:15 <merijn> M4GNV5: -threaded just means that if you're using threads (i.e. forkIO) it will use multiple cores to execute them
14:41:42 <merijn> M4GNV5: You're creating 4 capabilities (i.e. 4 thread executers), but you only give them 1 thread to run, so only one of the 4 is busy
14:42:10 <dminuoso> merijn: Huh. Fix datatypes is a thing too? 
14:42:29 <dminuoso> merijn: Honest question. Does the head ever stop to spin with Haskell?
14:42:32 <merijn> dminuoso: I can't parse that question
14:42:44 <dminuoso> Well I just stumbled over this: newtype Fix f = Fix (f (Fix f))
14:43:01 <M4GNV5> merijn, ahh lol im stupid, i totally overread that `par` in the wiki page i linked
14:43:03 <merijn> dminuoso: Right, which is basically the thing you wanted, but for arbitrary functors
14:43:07 <M4GNV5> thanks anyways x,x
14:43:09 <dminuoso> Yeah this is amazing. :)
14:43:20 <merijn> dminuoso: It's the functor fixpoint
14:43:46 <merijn> dminuoso: Which is related to Free, which you might also be interested in
14:44:39 <merijn> dminuoso: And no, your head never stops spinning with Haskell
14:48:27 <Samo_svoj> anyone willing to help with pipes, conduits....
14:48:29 <Samo_svoj> ?
14:49:01 <lyxia> Just ask your question
14:49:28 <Samo_svoj> what is the difference between stream/pipe/conduit/machine/datatype programming?
14:51:05 <tinco> Samo_svoj: between all of those? :P
14:51:45 <Samo_svoj> tinco: if you show me the link for some decent tutorial?  :)
14:52:10 <tinco> what are you trying to accomplish?
14:52:10 <dminuoso> merijn: The weird thing is, Ive used all of this a while ago when either you or someone else guided me through implementing the Y-combinator by hand.
14:53:30 <Samo_svoj> tinco: i am just exploring alternatives for streams and i realize that i do not know why other models has been invented and how it relates to dataflow (no datatype, my mistake!) programming?
14:53:37 <dminuoso> Is it conceivable that parametric types have more than just one fixed point?
14:54:02 <merijn> I don't actually know :)
14:55:13 <royal_screwup21> I'm trying to remove duplicates from a list and here's my code: https://thepasteb.in/p/AnhrOlmWnqRIv The compiler threw an error saying: https://thepasteb.in/p/98hRqNZBjZ6uk What does the error mean?
14:55:20 <tinco> Samo_svoj: afaik they're only technically different, not philosophically
14:55:47 <merijn> tinco: Depends where you draw the line between technical and philosophy
14:55:51 <tinco> i.e. pipes, streams, conduits, lazy bytestrings, they're all sort of the same thing, but with different api's, performance characteristics, etc
14:56:05 <merijn> tinco: You could argue that the difference between pipes/conduits on how they handle leftovers are philosophical
14:56:08 <Samo_svoj> tinco: philosophically they are all part of dataflow programming
14:56:12 <lyxia> dminuoso: Maybe can be seen as having two fixed points, one with Just (Just (...)), one without.
14:56:23 <merijn> Samo_svoj: Eh, no, they're stream processing
14:56:34 <merijn> Samo_svoj: Data flow programming is something entirely different
14:56:46 <Samo_svoj> merijn: what is the difference!?
14:57:02 <Samo_svoj> stream ~ dataflow
14:57:04 <merijn> Samo_svoj: dataflow generally has many "stream" of input
14:57:08 <merijn> Samo_svoj: It's really not
14:57:21 <merijn> Samo_svoj: https://en.wikipedia.org/wiki/Dataflow_programming
14:57:36 <Samo_svoj> merijn: i read it
14:57:37 <merijn> dataflow is more like data traversing a graph of operations
14:57:49 <merijn> Samo_svoj: Stream processing performs operations on a single stream of data
14:57:56 <Samo_svoj> merijn: isn't stream processing the same thing??
14:58:05 <merijn> You could argue that stream processing is a degenerate case of dataflow, I suppose
14:58:11 <merijn> But that helps no one
14:58:32 <Samo_svoj> merijn: stream processing is dataflow when you have ONE input stream!
14:59:40 <merijn> Like I said a degenerate case. If you say dataflow programming to anyone using it they will automatically assume complex graphs of operations/inputs
15:00:14 <Samo_svoj> merijn: what are pipes/conduits then?
15:00:27 <merijn> Stream processing
15:00:32 <merijn> They can't do arbitrary dataflow
15:01:07 <Samo_svoj> how they are different?
15:01:47 <Samo_svoj> what are machines? why they are invented?
15:07:41 <royal_screwup21> I want to replicate a number n times in a list. For example, let's say my number is 5 and I want to replicate it 3 times. The output would be [5,5,5]. Is there a quick way to do this? In python you could could do 3*[5] -- is there an equivalent ?
15:08:16 <jared-w> Hmm... I have a function that returns IO (IO [Int]). I'm sure there's an easy way to 'smash' the two IOs together but for the life of me I can't think of what it is
15:08:34 <ahihi> :t join
15:08:35 <lambdabot> Monad m => m (m a) -> m a
15:09:07 <merijn> royal_screwup21: Eh, replicate?
15:09:13 <jared-w> yeah that's what I thought, but I can't return join because it's only IO [int] inside the function
15:09:14 <merijn> > replicate 5 'c'
15:09:16 <lambdabot>  "ccccc"
15:09:32 <merijn> > replicate 5 4
15:09:32 <jared-w> oh, join $ do, dur
15:09:34 <lambdabot>  [4,4,4,4,4]
15:09:36 <royal_screwup21> merijn: ah cool, thanks.
15:09:55 <merijn> jared-w: :)
15:10:17 <Cale> royal_screwup21: It's amusing that you even used the word replicate in your question :)
15:10:20 <ahihi> jared-w: if you're doing `return someValueAlreadyInIO`, you can just skip the return
15:10:27 * jared-w /knows/ that do is just a function but also forgets the full implications of that
15:10:40 <merijn> jared-w: do is not a function, though?
15:11:19 <jared-w> meh, that wasn't what I meant to say; I meant to say more that do can go anywhere and you can stick things in front of it, after it, assign things to a do block, etc
15:11:28 <merijn> jared-w: Sure :)
15:14:53 <erisco> doesn't work in lambdabot, but a fun one in ghci is  do it
15:16:05 <lyxia> Just do it
15:16:42 <erisco> Just (do it)
15:16:58 <erisco> do Just it
15:22:52 <merijn> hmm, cabal parallel build is a good way to kill laptop battery, apparently
15:23:33 <erisco> your battery life is contingent on a dim screen and a throttled CPU
15:24:16 <merijn> erisco: I know, but I wasn't expecting it to kill 10% of the battery in about 2 minutes :p
15:24:56 <erisco> how long would the battery normally last?
15:25:09 <merijn> 6-8 hours on a full charge
15:26:03 <Samo_svoj> what do you think - does it make sense in haskel to use explicit parallelism or just to leave compiler to deal with it?
15:26:39 <merijn> Samo_svoj: Well, since the compiler doesn't add/do any parallelism, I'm gonna go with "using it explicitly"
15:27:36 <Samo_svoj> merijn: if your program is purely functional then it can execute different parts concurrently?
15:28:43 <merijn> "can" does not equal "will", automatic parallelisation is crazy hard, so GHC doesn't do it
15:28:52 <jared-w> I feel slightly weird about my do block ending with  'let stuff = ...' ; stuff }
15:28:55 <jared-w> meh
15:29:14 <erisco> is it recursive?
15:29:14 <merijn> jared-w: lpaste the code?
15:29:28 <Samo_svoj> merijn: what is advantage of haskell then?
15:31:57 <erisco> Samo_svoj, check out haskell.org
15:32:46 <monochrom> Samo_svoj: http://haskell.cs.yale.edu/?post_type=publication&p=366
15:33:28 <royal_screwup21> what's the difference between (func1 (func2 n list) n) and func1 (func2 n list) n?
15:33:30 <Samo_svoj> haskell.org: Concurrent
15:33:31 <Samo_svoj> Haskell lends itself well to concurrent programming due to its explicit handling of effects. Its flagship compiler, GHC, comes with a high-performance parallel garbage collector and light-weight concurrency library containing a number of useful concurrency primitives and abstractions.
15:34:08 <n_blownapart> hi this is an arithmetic sequence that rightly causes an infinite loop . since this sequence converges to 2, how do I express that in the list comprehension so that I could give it an arbitrary termination point?         gg = sum [ x | x <- [1/2, 1/4..]] + 1
15:34:52 <merijn> n_blownapart: How would it decide where that arbitrary termination point is?
15:35:34 <monochrom> you can add "x < 1/1000".
15:35:49 <erisco> maybe you want lazy numbers
15:35:58 <monochrom> [ x | x <- [1/2, 1/4 ..], x < 1/1000]
15:36:05 <merijn> monochrom: eh, no?
15:36:06 <ahihi> [1/2, 1/4..] may not be what you expect it to be
15:36:10 <merijn> monochrom: That'd still infinite loop
15:36:14 <monochrom> Although, I don't know that [1/2, 1/4 ..] is Haskell.
15:36:20 <monochrom> Oh, right.
15:36:24 <merijn> monochrom: Sure it is?
15:36:32 <merijn> monochrom: Why wouldn't that be haskell?
15:36:32 <ahihi> > take 10 [1/2, 1/4..]
15:36:35 <lambdabot>  [0.5,0.25,0.0,-0.25,-0.5,-0.75,-1.0,-1.25,-1.5,-1.75]
15:36:41 <merijn> I mean, it's probably not RIGHT
15:36:42 <monochrom> Oh ha
15:36:45 <merijn> But it is haskell
15:36:58 <monochrom> You need to use a takeWhile outside the list comprehension.
15:37:25 <n_blownapart> following this ... takeWhile, cool.
15:37:31 <n_blownapart> ok so...
15:37:44 <merijn> n_blownapart: You're using the Enum instance of Double there, which is downright evil
15:37:49 <jared-w> merijn: http://lpaste.net/360010
15:38:09 <merijn> jared-w: eh...why not just have the case in the do block?
15:38:28 <merijn> jared-w: http://lpaste.net/360010
15:38:49 <jared-w> yeah, just realized I could do that... well that solves that issue :p
15:39:01 <n_blownapart> << not evil
15:39:15 <merijn> n_blownapart: I mean the Enum instance of Double is evil and wrong
15:39:16 <crucify_me> wait so....
15:39:17 <jared-w> n_blownapart: just out of curiosity, why do you always switch between two nicks?
15:39:39 <jared-w> Although I am doing more things with the function eventually, so I'll see what it ends up being
15:40:25 <crucify_me> sorry jared-w will try to be consistent
15:41:16 <crucify_me> so using takeWhile ..
15:41:33 <merijn> crucify_me: Did you see ahihi example of what your list comprehension does?
15:42:16 <crucify_me> yeah it return float values using take. 
15:42:25 <crucify_me> to be summed
15:43:13 <crucify_me> returns*    sorry working on this. I haven't conceived it yet
15:43:13 <jared-w> whoo, finally made the epiphany that I had to do (traverse . traverse) instead of (fmap . traverse) and I finally figured out how to get it working without the case statement
15:43:16 <merijn> crucify_me: Is it' returning what you expect, though?
15:43:18 <ahihi> i assume you wanted a geometric sequence like [1/2, 1/4, 1/8, 1/16, ..]
15:43:19 <merijn> > take 10 [1/2, 1/4..]
15:43:21 <lambdabot>  [0.5,0.25,0.0,-0.25,-0.5,-0.75,-1.0,-1.25,-1.5,-1.75]
15:43:25 <ahihi> but that's not what this code produces
15:43:40 <ahihi> consider building the initial list using `iterate`
15:43:46 <crucify_me> oh it goes negative?
15:44:15 <crucify_me> so yeah I cannot use a generator like that
15:44:50 <crucify_me> how would you express the convergence of the arith sequence on 2, preferably using a list comprehension?
15:45:27 <crucify_me> of *that intended* arith sequence
15:45:29 <monochrom> I wouldn't shoehorn everything into list comprehensions.
15:45:43 <ahihi> > iterate (/2) (1/2)
15:45:45 <lambdabot>  [0.5,0.25,0.125,6.25e-2,3.125e-2,1.5625e-2,7.8125e-3,3.90625e-3,1.953125e-3,...
15:45:50 <monochrom> I would use "iterate" as they're all saying.
15:47:12 <crucify_me> interesting , er 
15:47:55 <aplainzetakind> I'm not sure you can express convergence.
15:48:02 <crucify_me> thanks. any illustrations appreciated I prolly don't know how to do it.
15:48:05 <aplainzetakind> If you could, you could model real numbers
15:48:48 <jared-w> :t iterate
15:48:49 <lambdabot> (a -> a) -> a -> [a]
15:48:58 <jared-w> noice
15:50:04 <crucify_me> aplainzetakind: thanks,  thanks jared-w
15:53:00 <crucify_me> could I do it with lazy numbers as per erisco s suggestion?
15:54:30 <Cale> crucify_me: Well, what do you mean by "express the convergence of"?
15:54:42 <Kaelara> Is there any reason to not use Haskell for a new project other than that 1) your boss told you to use something else 2) you want to use a library from another language that's hard to use with haskell, or 3) haskell is too slow or too high-level?
15:54:55 <merijn> Kaelara: eh, no?
15:55:16 <Cale> Kaelara: for 3, it's even questionable ;)
15:55:21 <merijn> Kaelara: I use it for everything from throwaway scripts for use in shell scripts to bigger programs
15:55:29 <Kaelara> Then why isn't haskell more popular? Those three issues don't seem like big deals for most projects
15:55:39 <merijn> Kaelara: Programmers hate learning
15:55:45 <Cale> Kaelara: You can often use Haskell as a metalanguage for emitting lower level code really effectively
15:55:51 <exio4> Kaelara: it's too different :) 
15:55:53 <Kaelara> But learning is an O(1) cost with O(n) benefits
15:55:54 <merijn> Kaelara: If you don't already know haskell, you have to learn it first :p
15:56:01 <crucify_me> Cale thanks. I guess meaning to return a number that is fairly close to 2 that computes relatively fast
15:56:11 <merijn> Kaelara: Sure. You know that, I know that. But it's hard to convince others
15:56:46 <aplainzetakind> crucify_me: I suppose you want to implement this for a general class of numbers and not just 2?
15:56:58 <Kaelara> Merijn: But why? Can't you just be like, "Look, I know these really smart programmers who love haskell, and I love haskell, so please just look into using it"?
15:57:10 <merijn> Kaelara: Try it sometime :p
15:57:11 <Cale> 2 is fairly close to 2 and computes relatively fast ;)
15:57:26 <merijn> Kaelara: A lot of programmers are aggressively anti-learning/new approaches
15:58:26 <Cale> crucify_me: A common thing to want is just to go out far enough in the sequence that adjacent pairs are within some epsilon of one another.
15:58:28 <exio4> Kaelara: "I am doing well enough (or so I believe), why should I learn a different language, knowing that implies a lot of work, specially given Haskell is way different to most languages I am used to"
15:58:49 <Cale> crucify_me: For expressing that, something like zip xs (tail xs) can be useful
15:59:27 <geekosaur> ...wouldn't that be a reason *to* learn it? stretch your boundaries
15:59:28 <Kaelara> exio4: But using an inferior language in the long run takes much more work than biting the bullet and learning a new one now, right? Do they not realize this?
15:59:34 <ahihi> there is also a fairly common impression that haskell is "academic" and not "pragmatic"
15:59:41 <aplainzetakind> Cale: That definition is universally quantified. You can't check "for all indices > foo" and hope to halt
15:59:45 <ahihi> which reinforces the anti-learning/new approaches thing
15:59:46 <merijn> geekosaur: See the previous point about programmers being anti-learning :)
15:59:47 <exio4> Kaelara: how do you know if a language is better or worse at a certain task if you haven't used it before? 
15:59:48 <Cale> aplainzetakind: correct
16:00:00 <Kaelara> exio4: By asking people who do know it
16:00:06 <crucify_me> sorry? well I mean expressing the arithmetic sequence of 1/2, 1/4, 1/8 ...   Cale  ok, well..  
16:00:11 <geekosaur> most people are anti learning :(
16:00:11 <Cale> This isn't even strictly speaking relevant to whether the sequence converges at all
16:00:24 <merijn> Kaelara: But those people are elitist jerks who think they're smarter than me!
16:00:54 <Kaelara> merijn: That's because they are smarter than you so you should listen to them! XD
16:01:05 <ahihi> crucify_me: it's worth noting that this sequence is not arithmetic, but geometric
16:01:08 <aplainzetakind> crucify_me: do you mean [ 1/(2^n) | n <- [0..]]
16:01:25 <Kaelara> But thanks for clearing my doubts, everyone. I was concerned that Haskell had some big flaw I was missing that was hampering its usefulness
16:01:33 <exio4> Kaelara: there is a "tradeoff", why spend a whole year for a 5% improvement? 
16:01:44 <Cale> but in practical terms, it's often the best you can do to give inputs which you know to be convergent, and then look for some sign that the terms of the sequence are actually close to the limit like this.
16:01:57 <exio4> Kaelara: (5% being a "value I am used to when learning a new platform/library/task/whatever")
16:02:39 <crucify_me> ahihi:   thanks well-taken so aplainzetakind thats the ticket?
16:02:42 <Kaelara> exio4: I think learning haskell gives quite a bit more than a 5% improvement, and I think it takes less than a year to learn Haskell enough to be able to use it for useful things
16:02:56 <Cale> Kaelara: One big flaw is that if you want to hire a large team of Haskell programmers in a hurry, it's difficult.
16:03:11 <Cale> But that's obviously not intrinsic to the language :)
16:03:34 <Kaelara> Cale: Good point, though I think higher a large team of good programmers is hard in general
16:03:35 <aplainzetakind> crucify_me: Your aim isn't exactly clear to me. That list comprehension gives the terms of the infinite series you want to sum. But then what?
16:03:47 <Cale> Kaelara: If you want to do it right, yeah.
16:03:48 <Kaelara> s/higher/highering
16:03:57 <Cale> hiring*
16:04:08 <Kaelara> Curse this foul English of mine
16:04:37 <asivitz_> Kaelara: humans do a lot of things suboptimally. You are basically asking why humans don't always make the best choices :P
16:04:40 <aplainzetakind> You can produce the sequence of its partial sums with scanl.
16:05:35 <Kaelara> asivitz_: What I'm really asking is why humans make suboptimal choices when another choice is obviously superior
16:05:43 <crucify_me> aplainzetakind: express the truth that that particular sequence converges on 2, which I guess means setting a termination point that suggests 2 but is far enough away to compute quickly
16:06:17 <merijn> Kaelara: Just be glad you've seen the light :)
16:06:21 <aplainzetakind> > take 20 (scanl (+) 0 [1/fromIntegral (2^n) | n <- [0..]])
16:06:22 <lambdabot>  [0.0,1.0,1.5,1.75,1.875,1.9375,1.96875,1.984375,1.9921875,1.99609375,1.99804...
16:06:23 <crucify_me> ie since it cannot return 2 anyway
16:06:26 <Cale> Kaelara: To be honest, Haskell might not even always be the best choice, depending on how soon you want something done, if you don't know it.
16:07:15 <Cale> Kaelara: It took me a couple months to feel like I could do useful things in Haskell and about a year to be comfortable (for some definition of that). If I was struggling to bring something to market, that on-ramp time might have been unacceptable.
16:07:47 <Cale> Of course, I think it was worth it overall, as I've been able to benefit from that over the following decade and a half or so. :)
16:07:49 <Kaelara> Cale: Well, yeah, Haskell isn't *always* the best choice, but sometimes it seems clearly better than what's actually used. *cough* Java *cough*
16:07:58 <aplainzetakind> crucify_me: That is not theoretically robust, but you can use something like what I did above and and check if you get a certain run of values within an acceptable error that you specify.
16:08:45 <crucify_me> thanks aplainzetakind ! Cale could you spin up a    zip xs (tail xs) solution? so I can compare these two? 
16:08:55 <aplainzetakind> But that won't guarantee that the sequence won't drift off somewhere else after the point you checked up to.
16:09:11 <crucify_me> drift off?
16:09:15 <Cale> crucify_me: Well, take the output from what aplainzetakind gave you, and put it through zip xs (tail xs)
16:09:25 <Cale> crucify_me: You'll get a list of pairs
16:09:36 <crucify_me> cool thanks working ....
16:11:01 <Cale> crucify_me: you can do something like  find (\(x,x') -> abs (x' - x) < 10^^(-9)) or something.
16:11:37 <aplainzetakind> In this particular sequence, you already know that it converges to 2. If I give you a sequence defined in an opaque way, your criterion for "good enough" convergence could be satisfied for the firs 10^10 terms, but then things might start behaving differently. You could never be sure.
16:11:40 <Cale> and find the first pair where the absolute difference between adjacent terms is below some threshold.
16:12:02 <aplainzetakind> Or something could converge very slowly, and your criterion could give you a false negative.
16:12:04 <Cale> You can't ever be sure, but nothing you can do from here could ever make you sure anyway
16:12:22 <aplainzetakind> :t find
16:12:23 <lambdabot> Foldable t => (a -> Bool) -> t a -> Maybe a
16:12:42 <Cale> find is never going to give you Nothing here
16:12:45 <Cale> It'll just keep looking
16:13:07 <Cale> But you may also want to set a cutoff on the input list if you don't want to loop forever
16:13:37 <Moe> Hi,everyone i want to talk avout something i am goin through, i have 0 expierience in programming in general, and studying in the first semester, so we started with Functional programming an haskell in specific,i really like cs and sometimes i study so that i even forget to eat!! But we get homeworks and it takes sometimes a whole day just solve one question,and all my friends like maximum two hours, i always get C,any advices ? 
16:13:40 <haskellnoob> polymorfic function is which contains type variables....how exactly/ where do we use this ?
16:14:00 <aplainzetakind> Note: This test will think [0.1,0.2 ..] converges to 2.
16:14:08 <Moe> I spend most of the time on parsing errors,defining types mostly
16:14:25 <crucify_me> dang its more complicated than I thought. I thought, once you had the correct generator set, you just set a limit that would eventually return 1.9445 or something
16:14:35 <aplainzetakind> This test being the "check if there is a term near target" test.
16:14:57 <lyxia> :t length  -- haskellnoob, everywhere.
16:14:58 <lambdabot> Foldable t => t a -> Int
16:14:59 <d6e> Moe: take your time and practice more?
16:15:16 <aplainzetakind> crucify_me: I think you need to look into the nature of real numbers.
16:15:21 <Cale> Moe: It's hard to know what to recommend when it comes to syntax errors... I guess the trick there is just to learn what the syntax is and be careful about it.
16:15:36 <aplainzetakind> And see that you can't have a general answer to this problem.
16:16:04 <haskellnoob> lyxia:  ?/
16:16:11 <Welkin> Moe: like the 3 stooges? Or the guy from the simpsons? Or anime memes?
16:16:14 <Cale> Moe: For type errors, well, you might not understand what the error means, but you have a line number. Think through what types of things are required and produced there, and then read over the message again.
16:17:02 <Cale> Moe: Usually it will give you a lot of relevant information about what types of things *it* things are produced and required, and what the types of things in scope are, which can be helpful.
16:17:08 <Cale> thinks*
16:17:38 <Welkin> the compiler can think?
16:17:54 <Moe> Cale :many thanks for your time
16:17:55 <Cale> Welkin: It's a mechanical brain
16:18:09 <Cale> Welkin: with no moving parts
16:18:19 <Welkin> I wouldn't go as far to call it a brain
16:18:33 <Welkin> it is not sentient
16:18:36 <Cale> I'm joking, this is an old-fashioned way to describe computers
16:18:53 <nshepperd> it thinks about all sorts of things
16:19:04 <crucify_me> aplainzetakind: thanks again. where you use scanl (+) 0  ,  I guess that accumulator/seed value must be 0 right ? because the sequence actually begins with 1 before going to 1/2   Cale
16:19:11 <Welkin> computers used to be people!
16:19:19 <Welkin> computers is people!!
16:19:20 <Cale> I think it's okay to imagine that the compiler is thinking about your code -- it's at least doing something very similar to what you'd do by thinking.
16:19:20 <lyxia> haskellnoob: For example many operations on lists don't care what the type of elements is. Without polymorphism you would have to write one length function for every type of lists.
16:19:28 <nshepperd> (brains don't have to be sentient, either)
16:19:57 <haskellnoob> lyxia: Ok 
16:19:58 <Cale> crucify_me: yeah, that 0 is the initial value it uses
16:20:46 <aplainzetakind> The State Monad chapter of the wikibook is confusing me. If I define "newtype State = ..." as in the example, I can't import Control.Monad.Trans.State, because multiple definitions, but then the monad instance definition given uses the 'state' function from that module. I can't understand if that 'newtype State = ...' is a hypothetical example or if not how to proceed.
16:21:44 <aplainzetakind> crucify_me: For any sequence, if you want the partial sums (sum of the first n terms) of that sequence, you don't want to add anything else, clearly.
16:22:03 <lyxia> aplainzetakind: https://en.wikibooks.org/wiki/Haskell/Understanding_monads/State this one?
16:22:07 <Welkin> as functional programmers, we abhor state
16:22:15 <Welkin> but what about an anarchist functional programmer?
16:22:20 <Welkin> would they use State?
16:22:29 <d6e> Today someone told me that they disliked lambda calculus in favor of "codata". I've been reading briefly about codata (and coinduction?), but these terms are new to me. Is it even fair to compare codata with lambda calculus?
16:22:37 <jared-w> What about a communist functional programmer?
16:22:48 <aplainzetakind> lyxia: Yes
16:22:49 <jared-w> d6e: whoever told you that either was horribly confused or horribly wrong
16:22:57 <d6e> jared-w: oh?
16:23:14 <crucify_me> aplainzetakind: not sure I follow that.. if I added 1 after the take.. expression, I could get a more accurate result, right?
16:23:23 <lyxia> aplainzetakind: you should be fine if you define state = State
16:23:39 <jared-w> codata is the dual of data. Data can be thought of as a data structure you can tear down recursively with constructors (a list, tree, etc., for example)
16:23:55 <jared-w> codata, being the dual of data, is data that you build up from a base case corecursively
16:24:00 <Cale> aplainzetakind: So, a bit of history. There used to be a separate definition for the plain State monad, but now in the transformers library, that gets defined as a type synonym for StateT s Identity
16:24:02 <aplainzetakind> lyxia: So I actually won't import the module that the chapter says it will be using?
16:24:07 <lyxia> aplainzetakind: right
16:24:17 <jared-w> A stream is a great example of codata
16:24:29 <Cale> aplainzetakind: But when that happened, the data constructor State :: (s -> (a,s)) -> State s a obviously went away
16:24:33 <aplainzetakind> Hmm, OK then.
16:24:35 <Welkin> jared-w: you mean an inifinite list
16:24:37 <aplainzetakind> Thanks.
16:24:41 <Cale> aplainzetakind: so as an apology, they defined a function of that type manually
16:24:54 <Cale> (with a lowercase s since it's no longer a data constructor)
16:25:03 <jared-w> Welkin: same thing, essentially :p  although I did butcher my data/codata explanation pretty badly, now that I think about it
16:25:08 <Welkin> the differences between data/codata and recursion/corecursion are more confusing than they are worth talking about
16:25:17 <Welkin> to much co-
16:25:18 <Welkin> co-itis
16:25:25 <Cale> aplainzetakind: If you're implementing the monad yourself, you should be able to just use the State with uppercase S.
16:25:46 <Cale> Maybe someone should clean up the Wikibook so that it's consistently one way or the other.
16:25:58 <Cale> Or I haven't looked at it, maybe it's just a typo.
16:26:08 <Welkin> I actually haven't heard of codata before
16:26:24 <Welkin> I still don't know the definition of a coalgebra
16:26:25 <jared-w> d6e: Although the point remains that lambda calculus is a language and data/codata are "things" and recursion/corecursion are methods of dealing with data/codata, to be a bit handwavy about it.  Comparing LC to that is like trying to sound smart by saying "yeah I don't really like Java, it's far inferior to linked lists, y'know?"
16:26:50 <aplainzetakind> Cale: I can't follow completely the reasons of that history, I'm rather new, but I think the takeaway is that I'm not supposed to import anything and implement a barebones state to follow the chapter.
16:27:06 <d6e> jared-w: aren't lists and trees infinite though? Couldn't those then be streams? Or am I misunderstanding what is meant by "streams"?
16:27:08 <jared-w> Welkin: the tl;dr would be that if a finite List is a data structure, its codata counterpart is the Stream
16:27:10 <Welkin> aplainzetakind: you will be well served to implement your own State monad
16:27:15 <Welkin> for learning
16:27:19 <Cale> Welkin: The difference between data and codata is only important if you don't have general recursion, and are working in a language which ensures that all computations producing data terminate, and that all definitions producing codata are productive.
16:27:28 <aplainzetakind> Welkin: I agree.
16:27:32 <jared-w> d6e: you are not. In Haskell, data and codata are essentially the same since the laziness of the language allows you to handle infinite data structures
16:27:32 <aplainzetakind> Thanks everyone.
16:28:14 <Cale> aplainzetakind: Yeah, well, I can't quite follow the reasons of that history either, but that's what happened ;)
16:28:14 <d6e> jared-w: ahhh
16:28:14 <lyxia> aplainzetakind: this chapter reimplements the stuff that's in Control.Monad.Trans.State, so importing it would just make a headache of definition conflicts.
16:28:40 <jared-w> Essentially, knowing about data/codata and recursion/corecursion differences is really just a pop-trivia bit of knowledge when working in programming languages since they're turing complete and the distinction dissappears and starts to become splitting hairs for no reason
16:28:56 <Cale> jared-w: At least, most programming languages.
16:29:22 <d6e> jared-w: so a data structure can be either or both?
16:29:26 <jared-w> Cale: Well, I suppose Agda and Idris still qualify as "programming languages"
16:29:33 <aplainzetakind> crucify_me: If you want to sum a_1, a_2, ..., then you want to do foldl (+) 0 [a_1,a_2, ..], If you want their sum and then add 1 to it, you would do foldl (+) 1
16:29:35 <jared-w> d6e: yeah
16:29:35 <Cale> and Coq, even
16:29:55 <Welkin> Cale: and css?
16:29:55 <jared-w> > take 1 [1..] -- this is a codata structure
16:29:57 <d6e> jared-w: cool, that clears up a lot of what I was reading
16:29:57 <lambdabot>  [1]
16:30:10 <marvin2> idris isn't turing complete? I know agda isn't, but thought iris was
16:30:12 <Cale> It requires a lot of heroism to program real-world things in Coq, but hey, there's a pretty complete C compiler written in it :)
16:30:21 <Welkin> marvin2: you can turn it on and off
16:30:26 <jared-w> marvin2: idris has an optional termination checker
16:30:43 <jared-w> It tries pretty hard to not be turing complete but also doesn't try super hard to be 100% total :p
16:30:59 <Cale> Idris also has type in type, right?
16:31:03 <Cale> Or did they change that?
16:31:12 <jared-w> ¯\_(ツ)_/¯ 
16:31:28 <Cale> Anyway, abusing that would be pretty noticeable ;)
16:31:42 <jared-w> Keeping up with all the concessions and modifications people hack into their theorem provers to make them less painful is a lot of work ;)
16:31:44 <Cale> actually that would be a really good obfuscated code competition
16:32:13 <Cale> Find the subtlest way you can to use type-in-type to introduce an infinite loop into an otherwise termination-checked program
16:32:43 <jared-w> > let fibs = 1 : 1 : zipWith (+) fibs (tail fibs) in take 20 fibs -- this is corecursion, d6e. It /builds/ up an infinite list from the base case of 1.
16:32:45 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765]
16:32:49 <Welkin> Cale: just use one of the FFIs
16:33:14 <Welkin> jared-w: it starts at 0!  >:O
16:33:56 <jared-w> > let fib 0 = 1; fib 1 = 1; fib n = fib (n-1) + fib (n-2) in fib 20 -- This is recursive. You start from "the top" and work down to the base case.
16:33:58 <lambdabot>  10946
16:34:29 <Welkin> that is a very poor implmenetation of a fibonacci generator
16:34:39 <Welkin> to make it better you need to memoize
16:34:56 <jared-w> It also happens to be dead simple to understand as an example of a recursive function, so hush :p
16:35:02 <Welkin> the corecursive version is automatically efficient (linear time)
16:35:05 <d6e> :)
16:35:56 <d6e> jared-w: okay... why the prefix "co-"?
16:36:09 <jared-w> so to summarize: [1..] is codata, [1..10] is data as it's finite. fib is recursive and fibs is corecursive. In a total language, the difference matters because you don't have general recursion and the language is not turing complete; in general (heh) it doesn't
16:36:23 <Welkin> d6e: no idea
16:36:31 <jared-w> Mathemeticians tend to stick 'co' in front of things which are the opposite. Especially in category theory
16:36:43 <d6e> ah, like "comonad"
16:36:49 <jared-w> exactly
16:36:50 <Welkin> but what about tonal languages!?
16:37:04 <Welkin> introduce tones into programming languages
16:37:16 <jared-w> Welkin: they use snakecase and we understand them, but shun them and don't approve of their life choices
16:38:14 <crucify_me> aplainzetakind: sorry , did you tinker with take x to get take 20, or did you know mathematically that was the correct argument? 21 also works to slight advantage
16:41:24 <d6e> Welkin, jared-w are we talking about python? :P
16:41:49 <aplainzetakind> crucify_me: What do you mean correct argument?
16:42:10 <d6e> or is there another snakecase language I'm unfamiliar with?
16:42:27 <aplainzetakind> It was a random not-too-small number of terms to visibly show you get a sequence of numbers approaching 2.
16:42:37 <Welkin> d6e: tons of languages use snake_case
16:42:56 <Welkin> it's common in C, rust, ruby, python, lua
16:43:04 <d6e> Welkin: ones that are tonal programming languages? :P
16:43:25 <Welkin> I did write a haskell program completley in chinese
16:43:33 <Welkin> I think that counts as a tonal programming language
16:43:40 <Welkin> maybe I can make a DSL with it
16:43:56 <crucify_me> aplainzetakind: yeah I see I could do take 20+n all night. thanks, sorry just tripping
16:45:00 <lyxia> aplainzetakind: there, I replaced all uses of state with State
16:45:04 <d6e> Would it? To be pedantic, the characters are decoupled from any phonetics, right?
16:45:23 <Welkin> d6e: sure, but all chinese languages are tonal
16:45:33 <d6e> not d6e-lang :P
16:45:36 <Welkin> unless we are talking about korean or japanese use of the characters
16:45:39 <troydm> lets say I have strict really big ByteString (few humdred megs csv file), can I get lazy [ByteString] of lines from it
16:45:42 <troydm> ?
16:45:47 <Welkin> vietnamese used to use chinese characters too, but it is also tonal
16:46:25 <Welkin> troydm: you can convert between the two yes
16:46:26 <d6e> Welkin: did you use traditional or simplified?
16:46:31 <jared-w> troydm: you should look at a streaming library or two. You're looking for how to analyze a large file in increments using constant space which is the exact purpose streaming libraries were designed to accomplish
16:46:35 <Welkin> and if you need to stream the data in, use pipes or conduit
16:46:43 <aplainzetakind> lyxia: Thanks. But it seems in this case one needs to supply instances for Applicative and Functor afresh.
16:46:45 <geekosaur> troydm, you can, although it seems a bit late to do so if it's already a strict ByteString
16:46:48 <Welkin> d6e: simplified on the computer
16:46:57 <lyxia> aplainzetakind: oh that too...
16:47:02 <d6e> okay ;)
16:47:09 <troydm> geekosaur: it's mmap ByteString
16:47:11 <aplainzetakind> Which is nice, but the reader should be warned probably.
16:47:23 <jle`> troydm: you can generate the list lazily, but getting the first item in the lazy list will force the evaluation of the entire original strict bytestring
16:47:36 <jle`> it's just the breaking up of the original bytestring into 'lines' that will be done lazily
16:47:43 <jle`> s/will/could
16:47:54 <Welkin> troydm: it;s better to stream the csv file using pipes or conduit
16:48:10 <Welkin> then you will never use more than a constant amount of memory (and it will be faster)
16:48:14 <troydm> Welkin: too much stuff to rewrite
16:48:27 <jared-w> Is it though? It's not too bad to rewrite things in Haskell :p
16:48:49 <jle`> rewriting things easily is actually one of haskell's "killer apps"
16:48:51 <troydm> jared-w: yes if it's only few lines
16:49:09 <jle`> ,actually haskell makes large re-writes really easy and safe :O
16:49:15 <jle`> across your entire project
16:49:18 <jle`> since the compiler checks correctness
16:49:21 <Welkin> I do huge rewrites of javascript apps all the time
16:49:27 <lyxia> aplainzetakind: okay let me add that
16:49:29 <Welkin> haskell is certainly much easier
16:49:57 <jared-w> huge rewrites of JS? How lol
16:50:14 <Welkin> but keeping the whole program in my head
16:50:28 <Welkin> and knowing every line of the codebase beforehand
16:50:33 <Welkin> and writing a lot of tests
16:50:43 <Welkin> by*
16:50:54 <aplainzetakind> Why is s not in scope here:     fmap f (State g) = State (\s -> (f a', s')) where (a',s') = g s
16:51:07 <jle`> aplainzetakind: what 's' do you think it is referring to
16:51:09 <aplainzetakind> Oh of course.
16:52:04 <aplainzetakind> Hmm.
16:52:23 <aplainzetakind> The argument of the lambda.
16:52:26 <Axman6> using let inside the lambda instead of where might help
16:52:47 <jared-w> Welkin: I suppose that works :p
16:53:37 <aplainzetakind> Axman6: yes it works that way.
16:54:15 <jle`> aplainzetakind: it helps to remember that 'where' is a part of declaration syntax
16:54:31 <jle`> and 'let ... in ...' is a part of expression syntax
16:54:39 <aplainzetakind> But there's clearly something I don't understand about where clauses. They fail to work as I expect them rather often.
16:54:46 <aplainzetakind> And, what's the distinction?
16:55:02 <jle`> so when you define/declare/name something, 'where' is a part of that syntax
16:55:09 <jle`> some_function ... = ... where ....
16:55:20 <jle`> it's attached to a declaration
16:55:36 <jle`> whereas, 'let ... in ...' is an expression, like any other expression
16:55:53 <jle`> so anywhere you would use an expression (like 5, "hello", foo x y), you can use (let .. in ..)
16:56:27 <jle`> (let .. in ..) is syntactically an expression
16:56:34 <Welkin> isn't `where` rewritten as a `let` that wraps the whole body of the function?
16:56:44 <jle`> so for something like (\s -> ... some expression ...), you can put a "let" in there
16:56:56 <jle`> but it doesn't make sense to put a 'where' in there, becuase you are not declaring anything
16:57:48 <jared-w> I think it is; regardless, the desugaring difference between let and where makes them not 100% interchangeable
16:58:20 <jle`> aplainzetakind: you can think of it as saying that any time you say blah = blah (using "=" to declar something), you have the option of attaching a "where" to that declaration.  so `func ... = ... where ...` is a single syntactic construct
16:58:53 <hpc> > let {x = y where y = 5} in x
16:58:55 <lambdabot>  5
16:59:24 <aplainzetakind> jle`: I see, kind of.
16:59:25 <jared-w> > let x = y in let y = 5 in x 
16:59:26 <aplainzetakind> Thanks.
16:59:27 <lambdabot>  y
16:59:35 <hpc> hehe
16:59:36 <jared-w> hmm...
16:59:41 <hpc> :t y
16:59:42 <lambdabot> Expr
16:59:42 <jle`> aplainzetakind: are you familiar with the ternary operator, from other languages?
16:59:50 <jle`> b ? x : y
17:00:14 <aplainzetakind> No, I don't really know any other languages. Some python.
17:00:18 <jle`> ah ok
17:00:33 <jared-w> ahh
17:00:38 <jle`> but yeah, you should think of 'something ... = ... where ...' as a single syntactic unit
17:00:39 <hpc> python has a ternary if operator iirc, it's just not what most other languages use
17:00:43 <jared-w> > let x = 5 in let y = x in y
17:00:45 <lambdabot>  5
17:00:50 <hpc> in python it's "truecase if condition else falsecase"
17:00:55 <jared-w> lexical scoping :p
17:01:13 <aplainzetakind> So in my usage, where looks at the definition of fmap, and of course can't see inside the lambda.
17:01:35 <jle`> yeah, it just sees the arguments to fmap
17:02:13 <aplainzetakind> > (\s -> f s where f = succ) 1
17:02:15 <lambdabot>  <hint>:1:12: error: parse error on input ‘where’
17:02:22 <aplainzetakind> This also doesn't work.
17:02:27 <aplainzetakind> Alright.
17:02:29 <jle`> yes, because you aren't declaring anything
17:02:36 <jle`> 'where' alone doesn't make any sense
17:03:01 <jle`> its syntactical role is attached to a `blah .. = .. where ..`
17:03:06 <jared-w> > let f = succ in (\s -> f s) 1
17:03:08 <lambdabot>  2
17:03:12 <aplainzetakind> So let ... in ... is sort of like a declaration plus a where packed together.
17:03:23 <aplainzetakind> Hmm no.
17:03:28 <jle`> yeah, the first part lets you list declarations
17:03:38 <jle`> let {declaration; declaration; declaration} in {expression}
17:03:56 <aplainzetakind> OK.
17:03:58 <aplainzetakind> Thank you.
17:03:59 <jared-w> > if True then 5 else 2 -- this is a single expression in Haskell, not a conditional branch
17:04:01 <lambdabot>  5
17:04:15 <crucify_me> as per Cale 's suggestion I used zip. though when I put the take 20 part in functione here, I get back 16 tuples. why is that? https://ptpb.pw/HO0B
17:04:16 <jared-w> `let .. in ..`  works the same way
17:04:25 <jared-w> (except the `in` is optional)
17:04:31 <crucify_me> aplainzetakind: ^ if you have time
17:04:36 <jle`> wait no the in is not optional
17:04:49 <hpc> crucify_me: because you're taking 16 and not 20?
17:05:05 <jared-w> jle`: why does my code work without the 'in' then? :p
17:05:14 <jle`> 'let' is an overloaded keyword
17:05:20 <crucify_me> how is that taking 16 hpc ? sorry
17:05:22 <jle`> it's used in other syntax things
17:05:26 <jle`> so it's kind of confusing, heh
17:05:27 <jared-w> ahh, gotcha
17:05:31 <jle`> 'where' is also super overloaded lol
17:05:32 <hpc> crucify_me: functione = take 16 (zip gg (tail gg))
17:05:42 <jared-w> No way that could ever be... confusing... ಠ_ಠ
17:06:08 <jle`> haskell syntax ~
17:06:10 <hpc> jle`: where else is 'let' used? i am totally blanking
17:06:19 <jle`> it's a part of do notation syntax
17:06:23 <geekosaur> do, list comprehensions
17:06:26 <hpc> ah
17:06:28 <crucify_me> weird that was an editing mistake I didn't :r
17:06:33 <crucify_me> sorry hpc
17:06:34 <jared-w> ghci too :p
17:06:38 <crucify_me> thanks
17:06:38 <hpc> crucify_me: eh it happens
17:06:46 <geekosaur> ghci's pretending to be the inside of a do still
17:06:59 <jle`> yeah, it's special ghci syntax, but it's meant to 'emulate' familiar syntax
17:07:08 <geekosaur> even though that particular fiction has been increasingly fragile since around 7.2
17:07:28 <jared-w> oh yeah. But, as of GHC 8.0 or so you can just say 'x = 5' without the let and it works. Very nice
17:07:47 <Mark__> Beginner question … I know how to get a command-line argument as a String. What’s the recommended way to convert it to an Int and handle possible errors?
17:07:58 <jle`> Mark__: you can use readMaybe
17:07:59 <hpc> :t reads
17:08:01 <lambdabot> Read a => ReadS a
17:08:06 <hpc> :t readMaybe
17:08:07 <lambdabot> error: Variable not in scope: readMaybe
17:08:10 <jle`> readMaybe :: String -> Maybe Int 
17:08:14 <jle`> @let import Text.Read
17:08:15 <lambdabot>  Defined.
17:08:19 <Mark__> Thanks!
17:08:20 <geekosaur> :t Text.Read.readMaybe
17:08:21 <Axman6> @hoogle readMay
17:08:21 <lambdabot> Safe readMay :: Read a => String -> Maybe a
17:08:21 <lambdabot> ClassyPrelude readMay :: (Element c ~ Char, MonoFoldable c, Read a) => c -> Maybe a
17:08:21 <lambdabot> BasicPrelude readMay :: Read a => Text -> Maybe a
17:08:21 <lambdabot> Read a => String -> Maybe a
17:08:22 <hpc> oh wow, that's in base now
17:08:27 <jle`> > readMaybe "3" :: Maybe Int
17:08:29 <lambdabot>  Just 3
17:08:34 <jle`> > readMaybe "5" :: Maybe Int
17:08:36 <lambdabot>  Just 5
17:08:38 <jle`> > readMaybe "five" :: Maybe Int
17:08:41 <lambdabot>  Nothing
17:08:51 <jle`> Mark__: but i'm assuming you're familiar with Maybe
17:09:02 <Mark__> Just barely.
17:09:16 <jle`> for now you can work with it just by pattern matching
17:09:24 <jle`> data Maybe a = Just a | Nothing
17:09:45 <jle`> > case readMaybe "3" of Nothing -> 0; Just x -> x + 9
17:09:47 <lambdabot>  12
17:09:54 <Axman6> do [arg] <- getArgs; case readMaybe arg of Nothing -> error "Oops, argument not an Int"; Just n -> print (n^2 :: Int)
17:09:54 <jle`> > case readMaybe "hello" of Nothing -> 0; Just x -> x + 9
17:09:54 <Mark__> Something like this? case readMaybe arg :: Int of …
17:09:56 <lambdabot>  0
17:10:03 <geekosaur> there's also
17:10:04 <crucify_me> hpc hey why did member suggest I put the results in tuples like that ?
17:10:05 <geekosaur> :t fromMaybe
17:10:06 <lambdabot> a -> Maybe a -> a
17:10:10 <Axman6> Mark__: Maybe Int, not just Int
17:10:28 <jle`> also in these modern times you can do readMaybe @Int arg
17:10:33 <jle`> which will read it as a Maybe Int
17:10:43 <geekosaur> > fromMaybe 0 (readMaybe "five")
17:10:45 <lambdabot>  0
17:10:53 <hpc> crucify_me: not sure, you were probably going to use consecutive values in some follow-up logic?
17:10:54 <jle`> but usually in the real world you won't need to give an explicit type annotation
17:10:58 <Axman6> I think suggesting language extensions to someone who's just started with the language is a bit premature
17:11:05 <geekosaur> agreed
17:11:08 <jle`> because you'll end up using the value you read somehow, in a way that lets ghc infer the type
17:11:09 <aplainzetakind> crucify_me: What's that zip for.
17:11:16 <jle`> Axman6: i feel like this is like introducing TupleSections
17:11:33 <jle`> type applications should be a standard part of beginner haskell because it's useful for teaching
17:11:44 <Mark__> I need to pass the value to a function that requires an Int. That’s why I thought I needed to specify the type I want readMaybe to give me.
17:11:48 <Axman6> That would also be a bit premature for someone who isn't comfortable with Maybe
17:11:54 <crucify_me> Ca*le wanted me to, maybe to watch progression in a certain light? IDK
17:12:07 <crucify_me> aplainzetakind: ^
17:12:14 <jle`> i think it's something that i would teach very early actually these days
17:12:24 <jle`> at the same time as typeclasses
17:12:24 <hpc> jle`: i feel the same way about GADTs (or at least GADTSyntax)
17:12:36 <jle`> learning typeclasses is much easier with type applications
17:12:50 <jle`> Mark__: yeah if your function requires an Int, then you don't need a type annotation
17:12:50 <crucify_me> whats type applications
17:12:51 <hpc> it feels a bit like another wink-wink-nudge-nudge toward dependent types as well
17:12:52 <Axman6> Mark__: right, take a look at thge type of readMaybe: Read a => String -> Maybe a, so it must return a Maybe something, so you can't say readMaybe str :: Int, because an Int is not a Maybe a. you need Maybe Int
17:12:54 <jle`> because haskell will infer that you want an Int
17:13:26 <geekosaur> Mark__, if it requires Int, then using it in an expression with readMaybe will cause readMaybe to be inferred at String -> Maybe Int
17:13:44 <geekosaur> read does not determine the type based on the string value, it chooses a parser based on the requested result type
17:13:59 <geekosaur> (this is a general rule)
17:13:59 <aplainzetakind> crucify_me: I think he suggested something like using zipWith to check the difference from two.
17:14:49 <aplainzetakind> :t fmap (abs . (2-)) -- you should be able to do this.
17:14:50 <lambdabot> (Num b, Functor f) => f b -> f b
17:15:32 <crucify_me> aplainzetakind: hmm, in any case I can watch the miniscule increments , right?
17:15:38 <aplainzetakind> fmap (abs . (2-)) gg will give you the diffence to 2 in absolute value of each term.
17:15:58 <crucify_me> that's cool thanks
17:15:59 <aplainzetakind> I really don't undersatnd the end purpose, so I can't comment on that.
17:16:22 <aplainzetakind> Oh just use map instead of fmap. Same for lists.
17:16:31 <crucify_me> ok thanks
17:18:07 <Mark__> Got it working! That type inference is magical.
17:18:12 <Mark__> main = do
17:18:13 <Mark__>   args <- getArgs
17:18:14 <Mark__>   let arg = head args
17:18:16 <Mark__>   case readMaybe arg of
17:18:17 <Mark__>     Just n -> putStrLn (show (factorial n))
17:18:17 <Mark__>     Nothing -> putStrLn (arg ++ " is not an Int")
17:18:33 <Mark__> So it really figured out I need an Int just because that is what factorial wants?
17:18:41 <jollygood2> sure
17:19:29 <aplainzetakind> :t factorial
17:19:30 <geekosaur> at some point you should work through what is happening; you'll come out of it with a much better understanding of how types work
17:19:31 <lambdabot> error: Variable not in scope: factorial
17:19:50 <geekosaur> also I would suggest using a paste site of some kind instead of pasting code into the channel
17:20:02 <jollygood2> pretty awesome isn't it, you didn't declare a single type in that snippet, yet type of everything is known at compile time
17:20:15 <Mark__> I didn’t include the definition of factorial in what I pasted. Good idea about using a paste site. I’ll do that from now on.
17:20:40 <jollygood2> you can replace `putStrLn (show (factorial n))' with `print (factorial n)' btw
17:22:36 <Mark__> Thanks jollygood2! What module defines print?
17:22:50 <geekosaur> it's in Prelude
17:22:59 <geekosaur> @index print
17:23:00 <lambdabot> System.IO, Prelude
17:23:11 <jollygood2> you don't have to import anything
17:26:30 <Mark__> Is there any consensus on the best test tool/library for Haskell?
17:26:52 <jared-w> Mark__: people really like quickcheck for most things
17:27:22 <jared-w> Alrighty, this is what I've been working on this weekend in my spare time :)  any thoughts, improvements, style suggestions, etc?  http://lpaste.net/9033782611222200320
17:28:46 * jared-w notes that this is, amusingly, he probably gives too much advice on this channel considering this is the first thing he's ever written in Haskell that wasn't a book exercise or a GHCi one-liner
17:34:21 <Mark__> As a beginner, should I learn about the “stack” tool?
17:34:48 <aplainzetakind> lyxia: So, when I implement an Applicative instance for State s, how am I to check if it's a good definition. It typechecks alright, but?
17:35:48 <Henson> hey folks, I'm trying to understand the appropriate use of typeclasses in designing a numerical ODE integration library.  The integrator can be a constant-step or adaptive-step integrator.  Constant stepper depend on a stepper, like RK4, or other kinds.  An adaptive stepper depends on a step controller, like RK5, whiich itself depends on a stepper.  The output of the integrator can also be....
17:37:32 <Henson> different types, like a single time step, or an array of time steps, or just the value at the final time.  Now I can think that a typeclass might be appropriate to model a stepper, as there can be several different variations of a stepper.  Instances of a stepper would just have to implement a "makeStepper" function that would output the type as a stepper.  But I could also just have a data....
17:38:02 <Henson> type with various options like "data Stepper = StepperRK4 | Stepper?? | Stepper?? | etc..."
17:38:19 <jared-w> Henson: you could pass dictionarys manually, then whenever that gets too painful write the typeclass to automate it (since that's all typeclasses "really do")
17:39:53 <Henson> It seems to me like Typeclasses are best used when the library designer wants somebody to be able to take their own datatype and hook it in to the functionality of the library, but I don't think that's necessarily appropriate in this case.
17:40:34 <Henson> does anybody have any advice?  I could elaborate more if necessary.
17:41:13 <Henson> jared-w: I was thinking I could either use functions within typeclasses, or just functions that operate on data types.
17:42:03 <jared-w> not sure what you mean by 'functions within typeclasses' honestly
17:42:04 <Henson> jared-w: this is really a wrapper for a C++ library, so the underlying data types would probably be pointers to a C structure which would be modified by functions to build up the operating state of the integrator.
17:42:22 <jared-w> A typeclass acts like implicitly passing in a record as the first parameter of every function that uses it
17:42:33 <Henson> jared-w: well, in order for something to be a member of a typeclass, it has to implement certain functions of that typeclass.
17:54:19 <monochrom> methods?
17:54:43 <monochrom> But take note of methods like Bounded's maxBound which is not a a function.
17:57:59 <lyxia> aplainzetakind: there are laws given in the documentation of Applicative
17:58:09 <lyxia> aplainzetakind: You can also test that (<*>) = ap
17:58:16 <lyxia> (if you have a working monad)
17:59:10 <jollygood2> @hoogle exit
17:59:10 <lambdabot> Graphics.UI.GLUT.Initialization exit :: MonadIO m => m ()
17:59:10 <lambdabot> Shelly exit :: Int -> Sh a
17:59:10 <lambdabot> Shelly.Lifted exit :: MonadSh m => Int -> m a
17:59:50 <aplainzetakind> lyxia: Thanks.
18:00:47 <geekosaur> jollygood2, System.Exit.exit{Success,With}
18:12:02 <jollygood2> geekosaur, thanks. I'm not sure I like exception there, instead of quietly returning non-0 to terminal
18:13:53 <geekosaur> I think the idea is to let resource cleanup (e.g. bracket) happen, which is important if resources are shared between processes/systems
18:14:29 <shae`> How do I get a Megaparsec parser to handle optional parses? The datatype I'm using has a Maybe value in that field, but I'm not sure how to sew it all together.
18:15:03 <geekosaur> although that thread gotcha is a bit of a warning about mismatched expectations
18:15:05 <monochrom> Unlike C, Haskell's main doesn't use "return value" for exit code, so if you want exit code you will have to use explicit System.Exit.exit.
18:16:37 <Axman6> shae`: you can use Alternative's optional function
18:16:40 <Axman6> :t optional
18:16:42 <lambdabot> Alternative f => f a -> f (Maybe a)
18:16:46 <shae`> ah, thanks
18:17:11 <shae`> works!
18:17:50 <Axman6> It's pretty common for functionality like that to be implemented in other classes like that these days, so it's worth getting to know all the instances things like Parsers implement, and the derived functions those classes give you
18:20:44 <jollygood2> so exit throws exception and exits, regardless if you catch it or not?
18:21:45 <monochrom> I'm pretty sure if you catch it then it's busted.
18:27:00 <careless_esper> Just starting to learn Haskell. Why on earth can Cabal not uninstall things, and how are reinstalls dangerous?
18:27:08 <careless_esper> Not a good first impression to the ecosystem
18:27:37 <geekosaur> stack can't uninstall either. they're not full package mangers, they're library managers
18:28:28 <geekosaur> you can deregister a library but uninstallation can disturb shared files especially if your system package manager also uses it (with --global)
18:29:14 <geekosaur> and with stack, actually uninstalling a package could break other projects using it
18:29:58 <careless_esper> Ok, what about reinstalls then?
18:31:01 <jollygood2> uncaught exceptions leave the impression of a bug, so if that is the only way to let functions in System.Exit exit I hope there is also a function that exits and does nothing else
18:31:57 <monochrom> There is normal termination of main, which gives the exit code 0.
18:33:20 <ertes> i just noticed how far Coercible inference goes
18:33:26 <ertes> you can actually write: over = coerce
18:33:42 <monochrom> My http://www.vex.net/~trebla/haskell/sicp.xhtml#pigeon explains what can go wrong with reinstalls.
18:33:44 <jollygood2> I want  to return non-0 without  displaying exception error to user
18:34:03 <monochrom> It is not always wrong, but there are common wrong scenerios.
18:35:24 <ertes> jollygood2: just throw ExitFailure
18:35:30 <ertes> (and don't handle it)
18:36:12 <ertes> jollygood2: i.e. use exitWith/exitFailure
18:37:05 <aplainzetakind> @find
18:37:06 <lambdabot> error:
18:37:06 <lambdabot>     parse error (possibly incorrect indentation or mismatched brackets)
18:38:04 <careless_esper> Well, fantastic
18:38:10 <careless_esper> I've already screwed everything up then
18:38:45 <careless_esper> Installed parsec without a sandbox. Can't uninstall it. Unregistered it, tried to install it in a sandbox, but it says it's already installed
18:38:59 <careless_esper> Pretty dumb
18:39:11 <monochrom> Basically any time you use a compiler rather than an interpreter, reinstall can be wrong because of ABI mismatch.
18:40:02 <monochrom> You don't usually see this with C libraries just because most Linux distros give you a walled garden so you never have version freedom. But just look at Windows DLL hell.
18:40:37 <monochrom> With GHC ABI mismatch happens more often because cross-library inlining because we're performance freaks.
18:40:38 <jollygood2> enter oh, I see exception in emacsbut notif I run the program in termi-
18:41:17 <monochrom> You can easily point to Python, Ruby, and Emacs Lisp for worryless ecosystems but that's precisely because they have no ABI.
18:41:35 <monochrom> In Haskell land you can ditch GHC and switch to Hugs for the same safety.
18:42:03 <careless_esper> Why not install the libs locally?
18:42:03 <monochrom> Even then I heard that some Python users talk of Gem hell or something.
18:42:28 <monochrom> What does "locally" mean?
18:42:49 <monochrom> I am installing on my own computer. I am not installing on the Internet. Is that local enough?
18:42:57 <careless_esper> Let me specify a directory
18:43:42 <monochrom> You think cabal is not already doing that?
18:44:24 <monochrom> You probably don't have enough machine-code-level concept to appreciate what's ABI mismatch.
18:44:44 <careless_esper> I have no idea. All I know is that it's telling me I can't uninstall or reinstall, so some disconnect between the implementation and my mental model
18:44:56 <careless_esper> I do. I'm coming from C++
18:45:04 <careless_esper> Never had to deal with this nonsense before
18:45:53 <monochrom> Sure, I've already explained that one.
18:46:32 <monochrom> If you want a walled garden, use stack.
18:48:45 <monochrom> And I'm pretty sure if you do C++ on Windows you face just as much Windows DLL hell as every other Windows user.
18:49:20 <careless_esper> Meh, DLL Hell really hasn't been an issue for a lonnnng time
18:49:24 <monochrom> Although to be fair I haven't run into one lately despite all the Steam games I installed and play.
18:49:54 <careless_esper> Just take a look at your WinSxS directory size and you'll know why
18:51:19 <careless_esper> Well, looks like VC++ libs don't even use it anymore. They just put the version number in the filename. How novel
18:51:37 <nshepperd> the windows solution to dll hell seems to be to distinguish between system dlls and application dlls, and ruthlessly demand perfect compatibility from system dlls and consequently install every version of such a dll along side each other
18:52:01 <nshepperd> meanwhile anything that isn't "system" has to be shipped with the application
18:52:20 <monochrom> cabal new-build is comparable to that.
18:52:34 <careless_esper> Cool. I'll take a look at new-build. thanks
18:53:02 <xcthulhu> nshepperd: I haven't use Nix very much, but I've heard it's like that...
18:53:03 <monochrom> cabal sandboxing is comparable to "make it project-local".
18:53:17 <nshepperd> I may ask why indeed cabal can't uninstall stuff since it knows what depends on what
18:53:42 <nshepperd> just uninstall all the dependencies at the same time
18:54:09 <monochrom> But until you appreciate cross-library inlining, you can't do a fair comparison against C++
19:00:28 <monochrom> C++ is actually sitting somewhere between compiled and interpreted.
19:01:20 <monochrom> You have a large chunk of executable source code lurking in the *.h files and you're saying basically recompile it every time something else depends on your library.
19:02:08 <monochrom> This gets rids of a ton of ABI mismatches since you aren't re-using existing binaries.
19:02:11 <whatkk> hi guys. what does \n mean in haskell?
19:02:36 <xcthulhu> whatkk: It's a newline character
19:02:44 <monochrom> escape code for newline.
19:02:46 <geekosaur> > ord '\n'
19:02:48 <lambdabot>  10
19:03:06 <whatkk> ok thanks
19:03:10 <monochrom> Or part of a lambda expression. You should give the complete unabridged verbatim context.
19:03:36 <whatkk> one sec
19:04:35 <aplainzetakind> Similarly to what was done for rollNDiceIO, implement a function rollNDice :: Int -> State StdGen [Int] that, given an integer, returns a list with that number of pseudo-random integers between 1 and 6.
19:04:46 <aplainzetakind> ^ This is an exercise from the wikibook.
19:04:49 <whatkk> ghci> :type lines lines :: String -> [String] ghci> lines "line 1\nline 2" ["line 1","line 2"] ghci> lines "foo\n\nbar\n" ["foo","","bar"]
19:04:54 <whatkk> this is from realworld haskell
19:05:04 <monochrom> Alright it is newline.
19:05:05 <geekosaur> @paste
19:05:05 <lambdabot> Haskell pastebin: http://lpaste.net/
19:05:16 <geekosaur> multiline stuff is a bit saner in a pastebin
19:05:24 <geekosaur> note that
19:05:33 <geekosaur> > "|\n|"
19:05:36 <lambdabot>  "|\n|"
19:05:36 <whatkk> i'm completely new to programming....so i'm not sure exactly what does this newline do
19:05:39 <monochrom> If you do a putStrLn "aaa\nbbb" you get two lines of printout, 1st line aaa, 2nd line bbb.
19:05:44 <geekosaur> which goes through show, that escapes newlines
19:05:51 <geekosaur> > text "|\n|"
19:05:54 <lambdabot>  |
19:05:54 <lambdabot>  |
19:05:55 <aplainzetakind> According to the type signature, 'a list with that number of pseude-random integers' is not what's returned. Am I wrong?
19:06:14 <whatkk> let me try it out in ghci
19:06:15 <monochrom> aplainzetakind: What was the type of rollDiceIO?
19:06:21 <geekosaur> lambdabot cant use I/O so that's a bit of a hack; to see the difference in ghci, use print for the escaped one or putStrLn for the unescaped/literal one
19:06:57 <aplainzetakind> monochrom: IO (Int, Int)
19:07:51 <monochrom> OK you are wrong. There is no conflict between rollNDice's type and the question text.
19:08:13 <xcthulhu> aplainzetakind: StdGen might be a type alias for Int
19:08:31 <monochrom> In other words suppose I have "xxx <- rollNDice 4". Then I expect xxx to have length 4.
19:08:39 <aplainzetakind> Formally, this is analogous, but IO is closed anyway, the output of this type signature is kind of waiting for a generator value to actually produce the numbers, no?
19:08:50 <monochrom> No, StdGen is not a type alias for Int.
19:09:19 <monochrom> No, rollDiceIO is unsimilar to rollNDice.
19:09:44 <xcthulhu> monochrom: How is the type of rollDiceIO :: IO (Int, Int) ... don't you need to keep the rng state somewhere?
19:10:08 <monochrom> Ever read the doc of System.Random and the types there?
19:10:37 <xcthulhu> monochrom: I am admittedly relearning Haskell for a project
19:10:45 <geekosaur> there's a set of random functions that are in IO and keep the state in a private IORef
19:11:42 <xcthulhu> monochrom: If I have looked at System.Random, I've forgotten it
19:12:56 <jle`> you don't quite need to worry about the implementation details of rollDiceIO
19:13:28 <jle`> xcthulhu: its type IO (Int, Int) means that it is an IO action that produces an observably "random" pair of Int's when executed
19:13:33 <monochrom> rollDiceIO is unsimilar to rollNDice because rollDiceIO wants exactly 2 dice rolls but rollNDice takes a parameter for how many rolls the user wants.
19:13:35 <jle`> it does so using IO processes
19:13:48 <monochrom> In other words unsimilar in API.
19:13:52 <aplainzetakind> The type of evalState rollDie (mkStdGen 0) is plainly Int. When I read the question without the type signature, I am inclined to write 'evalState (sequence $ rollDie <$ [1..n]) (mkStdGen 1)' to produce [Int], is all I'm saying.
19:14:28 <monochrom> When the textbook says "similar" it's referring to an implementation technique (get, work, put) rather than API and how-to-use.
19:15:30 <monochrom> Sure. Now extract (sequence $ rollDie <$ [1..n]) and declare victory.
19:16:25 <monochrom> Programmers need to use the subtraction method more and delete more code.
19:16:46 <aplainzetakind> I know that that corresponds to the type signature and I can stop there.
19:17:07 <aplainzetakind> I just got cofused by calling what this returns a 'list of integers'
19:17:41 <jle`> indeed i would not call a State StdGen [Int] a list of integers
19:17:42 <aplainzetakind> When it's a function in a wrapper taking a generator returning a list of integers.
19:17:45 <aplainzetakind> That's all/
19:17:47 <monochrom> Sure, I don't like the whole concept of "return value" either.
19:18:06 <jle`> i wouldn't even necessarily call it a function in a wrapper, since you can think of State as an abstract data type
19:18:27 <jared-w> monochrom: the subtraction method?
19:18:43 <monochrom> Oh by the time you generalize to MonadState blahblah you don't even know what you're coding against. :)
19:19:14 <monochrom> The subtraction method solves problems by deleting things rather than adding things.
19:20:49 <jared-w> ah, right. Makes sense
19:23:23 <monochrom> We need a better word for the Y in e.g. "IO Y" or "State S Y".
19:23:41 <monochrom> If I don't want to call it "return type", then what is it?
19:24:39 <jle`> for things that represent actions, i call it the result type
19:24:47 <monochrom> Alternatively it is OK to call it "return type" but you don't say it of X->Y.
19:25:20 <monochrom> But oh X->Y = ((->) X) Y so we are not escaping from monadology eh?
19:25:33 <jle`> but i typically don't refer to these things uniformly
19:25:33 <jle`> oh i wasn't even considering monads
19:25:40 <jle`> just specifically IO and State s
19:26:38 <geekosaur> I generally say result type
19:27:06 * monochrom writes a paper called "The Logical Foundation for Morally Saying 'Return Type/Value' of Both Effectful Actions And Pure Functions"
19:27:11 <jle`> it makes sense in the context of the specific type you are talking about
19:27:18 <jle`> (result type)
19:27:22 <jle`> but definitely not for monads in general
19:28:06 <jle`> an 'IO Y' is an IO action whose result is of type Y
19:28:41 <jle`> IO and State are both similar in that their motes semantically represent "actions" of some sort
19:29:48 <jle`> but 'result type' also makes sense for Parser, i suppose
19:29:49 * jared-w proposes "that return result type thingy over there on the far right"
19:30:14 <jle`> maybe it makes sense for all motes that represent 'producers' of some sort
19:31:38 <monochrom> Oh don't worry, I think virtually all monadic actions are producers, apart from degenerate cases or scenerios.
19:32:14 <monochrom> Because if aaa :: M Y where M is a monad, then I can do "aaa >>= \y -> whee".
19:32:55 <monochrom> And either my \y->whee is not used at all, or it is given a value of type Y, meaning something has produced this value for my consumption.
19:33:26 <monochrom> You have to say "what if aaa = Nothing" to avoid producing.
19:39:50 <jle`> what about monads that don't produce anything
19:40:17 <jle`> sorry that came out weird
19:40:28 <jared-w> aren't those just Applicatives dressed up in a shiny suit?
19:40:54 <jle`> i mean, the idea of a monad isn't tied to production, but most Monads used in practice in computer engineering can be said to represent producers of some kind i suppose
19:41:03 <jle`> the obvious degenerate counter-example is Proxy
19:41:13 <jle`> but like, i'm not sure if that's a useful way of looking at things
19:41:19 <jle`> like, []
19:41:29 <jle`> hm
19:41:33 <jle`> er soryr that was a bad example heh
19:41:39 <jle`> 'Maybe'?
19:42:39 <jared-w> Well you can't... determine... the production of [], so I guess it counts? :p
21:23:24 <holycleugh> small naming convention question: should I prefer dfaUnion or unionDFA? also, for a function that converts NFAs to DFAs, should it be called nfaToDFA or just toDFA?
21:30:14 <jle`> toY is definitely more common than xToY
21:30:28 <jle`> well, xToY pops up a lot in base
21:30:57 <jle`> as for the first one, i don't really know anything else about the context so i can't really say
21:34:44 <holycleugh> jle`: analogy might be setUnion or unionSet
21:34:59 <jle`> abut what do they do
21:35:17 <holycleugh> it takes two sets and returns a set that is the union of those two sets
22:05:09 <ddk> hello all
22:06:19 <ddk> I need urgent help regarding creation of mutable unboxed vector which I need to modify regularly under controled STM
22:06:30 <ddk> please help me if possible I have little time to complete
22:07:17 <ddk> I want to keep this vector as a state which will be modified by various threads
22:07:56 <ddk> so I thought mutable version of Integer vector will be efficient but I dont know how to use or create it
22:08:55 <ddk> hello .... is anyone there with proper knowledge of mutable vectors ...Q
22:10:25 <jcarpenter2> ddk: write it in C :V
22:13:13 <ddk> jcarpenter2: nice joke ... but I love haskell and my whole program is written in Haskell
22:14:14 <ddk> can some one help me with creation of unboxed mutable vectors 
22:15:01 <ddk> how to create an unbox mutable vector of Integer 
22:15:28 <ddk> please help if you know 
22:15:47 <ddk> its urgent for me
22:22:15 <dmj`> I don’t think you can, Integer is memory bound and heap allocated, of Int yes. You need an Unbox instance.
22:28:31 <jle`> holycleugh: i don't think there'd be any preference either way
22:40:14 <holycleugh> jle`: okay, thanks
23:02:56 <koz_> If I have a Tasty testGroup containing QuickCheck properties, how do I tell the test runner that I want it to run more than 100 tests for those properties?
23:05:49 <Axman6> for one specific group?
23:07:24 <koz_> Axman6: For one specific property ideally, but I'll take for one specific group.
23:11:16 <Axman6> does this help? https://hackage.haskell.org/package/QuickCheck-2.10.0.1/docs/Test-QuickCheck-Property.html#v:withMaxSuccess
23:12:42 <koz_> Axman6: I'm aware of that. I don't know how to do that with Tasty.
23:13:09 <Axman6> use it on the quickcheck tree of tests
23:16:52 <koz_> Axman6: I think I need https://www.stackage.org/haddock/nightly-2017-11-10/tasty-quickcheck-0.9.1/Test-Tasty-QuickCheck.html#t:QuickCheckMaxSize , but I have no clue where it goes.
23:18:15 <Axman6> the IsOption makes it a command line argument you can set afaiui
23:18:29 <Axman6> https://www.stackage.org/haddock/nightly-2017-11-10/tasty-0.11.3/Test-Tasty-Options.html#t:IsOption
23:19:35 <Axman6> https://www.stackage.org/haddock/nightly-2017-11-10/tasty-quickcheck-0.9.1/src/Test.Tasty.QuickCheck.html#line-100 - use --quickcheck-max-size on the command line (to set it for all quickcheck tests though)
23:20:11 <koz_> Axman6: Would that work with stack? Would it be something like 'stack test --quickcheck-max-size 1000' or something?
23:20:24 <Axman6> possible -- --quickcheck...
23:20:30 <Axman6> possibly*
23:20:39 <Axman6> or, try stack test --help
23:21:11 <mud> You probably want --test-arguments "--whatever"
23:22:15 <koz_> mud: That seems to do nothing - still runs 100 tests, and not the 10000 I requested.
23:22:45 <Axman6> remove a layer of indirection, run the test executable directly
23:23:54 <koz_> Axman6: Still ignores it.
23:24:04 <koz_> I'd rather set it programatically anyway.
23:24:32 <Axman6> I don't think you can without the function I showed you to modify quickcheck tests
23:24:44 <Axman6> tasty isn't designed for this level of control
23:25:45 <koz_> Given that https://www.stackage.org/haddock/nightly-2017-11-10/tasty-quickcheck-0.9.1/Test-Tasty-QuickCheck.html#t:QuickCheckMaxSize exists, there has to be a way to use it, surely?
23:26:16 <Axman6> that's a global option though, you only want a subset right?
23:26:24 <koz_> I'll settle for global right now.
23:26:55 <Axman6> so what did you actually try when you called the test executab;e directly?
23:27:06 <Axman6> and what does calling it with --help say?
23:27:49 <koz_> Axman6: ./name-of-test-executable --quickcheck-max-size 10000
23:28:07 <koz_> When I cal ./name-of-test-executable --help, I get a list of options, including that one.
23:28:08 <Axman6> is that the one stack is calling?
23:28:12 <koz_> Axman6: Yeah.
23:30:05 <Axman6> what happens if you use that flag and give a garbage value (something which can't be parsed as a number)
23:30:21 <koz_> I get a 'could not parse' error.
23:30:30 <Axman6> huh, interesting
23:31:12 <koz_> Good at least that stack isn't at fault.
23:33:08 <koz_> ... turns out I needed --quickcheck-tests...
23:33:11 <koz_> Thanks anyway, Axman6.
