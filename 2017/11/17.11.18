02:03:25 <howdoi> A JS problem, looking for a haskell advise: trying to avoid two filters on something like: [].map(...).filter(...).filter(Boolean) 
02:08:51 <liste> > let { f = filter (\x -> x > 0 && x < 10); g = filter (> 0) . filter (< 10) } in (f [-5,1,2,3,12,-2], g [-5,1,2,3,12,-2])
02:08:53 <lambdabot>  ([1,2,3],[1,2,3])
02:08:58 <liste> howdoi: ^
02:10:07 <howdoi> liste: my case is more like: xs.map(x => x.ks.map(y => y.c && y.c+1))
02:18:16 <Aleksejs> Hi, I'm installing one project via stack build on DO droplet and it takes forever to build pandoc. I googled and it seems to be common problem with pandoc, but couldn't find any working solution. Any help?
02:19:43 <Aleksejs> it shows warning Package pandoc uses a custom Cabal build, but does not use a custom-setup stanza
02:21:12 <Aleksejs> I added --verbose and I see that it stuck on Run process: /tmp/stack2029/pandoc-1.19.2.1/.stack-work/dist/x86_64-linux/Cabal-1.24.2.0/setup/setup --builddir=.stack-work/dist/x86_64-linux/Cabal-1.24.2.0 build --ghc-options " -ddump-hi -ddump-to-file"
02:24:06 <ggVGc> man, I know I've been down this path before, but I really can't see a good reaon to use Reader rather than just a function argument
02:24:31 <ggVGc> why is (Reader t) => a -> b better than t -> a -> b
02:24:49 <ggVGc> eh, well, that syntax is wrong
02:24:52 <ggVGc> but still
02:26:04 <Lowl3v3l> ggVGc: in case the function needs any functions from typeclass Reader its way clearer. and in general its a good pattern to specify types as precisely as possible to make reading your code easier
02:26:53 <ggVGc> why is using Reader more precise?
02:27:05 <ggVGc> I think Env -> Int -> String is as clear as it gets
02:27:19 <ggVGc> take an environment, give me a function from Int to String
02:28:19 <Lowl3v3l> ggVGc: if you read the type definition you directly see t has to have Reader-functions and your function requires those.   If you define a type for env itself there's no big difference though, but in your original thing you didn't specify it ;)
02:28:43 <ggVGc> what do you mean "has Reader functions"?
02:28:56 <ggVGc> the only thing Reader supplies is getting an environment
02:29:05 <ggVGc> which is the same thing as passing a value
02:29:08 <Lowl3v3l> ggVGc: has functions in the Reader typeclass^^
02:30:04 <Lowl3v3l> ggVGc: i assumed your question to be a general one, where Reader is only an example typeclass
02:31:01 <ggVGc> no, I mean specifically Reader
02:31:30 <ggVGc> I really don't see the big benefit of an implicit environment rather than an explicit one
02:31:39 <ggVGc> actualy, I think it's added complexity for no real gain
02:31:42 <Lowl3v3l> ggVGc: in that case, i'd possibly still specify it since thats how i do it usually, but yeah, in this specific instance both are fine
02:32:03 <ggVGc> Lowl3v3l: tell me an instance then where Reader is to be prefered
02:32:21 <WinterFox[m]> Why is it when I try to run `head` on `[Text]` I get an error about `Ambiguous occurrence ‚Äòhead‚Äô` between `Data.List` and `Data.Text` when only the `Data.List` one works on `[Text]`? Shouldn't GHC be able to work out that only one of those functions can handle the datatype?
02:32:43 <Lowl3v3l> ggVGc: not "Reader" but other typeclasses. E.g. when having own Numerical Types i prefer specifying the typeclass
02:33:08 <liste> WinterFox[m]: no, there's no type-directed name resolution
02:33:23 <WinterFox[m]> Is that by design?
02:33:25 <Cale> WinterFox[m]: It needs to know which one you have in order to be able to typecheck in the first place.
02:33:47 <Cale> It's not about to try all possible combinations of names in every expression and see how many of them typecheck
02:34:06 <Cale> Instead, usually what people do is
02:34:11 <Cale> import Data.Text (Text)
02:34:18 <Cale> import qualified Data.Text as T
02:34:40 <u0_a77> good evening, my fellow haskellers
02:35:14 <WinterFox[m]> Cale: Does that make Data.Text.length only accessible through T.Length?
02:35:15 <Cale> But also, do you really need to use the head function? Pattern matching is almost always better
02:35:19 <Cale> Yeah
02:35:30 <Cale> T.length
02:35:44 <ggVGc> I have banned a lot of functions from Prelude mentally
02:35:45 <ggVGc> including head
02:35:48 <WinterFox[m]> Oh yeah head
02:35:55 <WinterFox[m]> Mixed those up
02:35:56 <u0_a77> I am inexperienced in the eay
02:36:10 <u0_a77> *way of Applicative
02:36:23 <WinterFox[m]> Cale: Why is head bad?
02:36:37 <ggVGc> WinterFox[m]: head is non-total. and will crash your program if the list is empty
02:36:55 <u0_a77> it's partial and non-natural in a technical sense
02:36:55 <ggVGc> something we're not too fond of in haskell
02:37:04 <Cale> Not only will it crash your program, it will crash it with a useless error message
02:37:06 <Cale> > head []
02:37:07 <WinterFox[m]> Oh
02:37:08 <lambdabot>  *Exception: Prelude.head: empty list
02:37:12 <liste> :t listToMaybe -- this is a bit better alternative to head
02:37:13 <lambdabot> [a] -> Maybe a
02:37:22 <ggVGc> Cale: yep, "great, where did that happen???"!
02:37:23 <liste> but usually pattern matching is even better
02:37:31 <Cale> If you really think head is the right thing, it's usually even better to use (\(x:_) -> x)
02:37:45 <Cale> Since at least then if it fails, the pattern match failure has a line number
02:37:47 <ggVGc> let head = listToMaybe
02:37:49 <ggVGc> ^ solved
02:38:11 <Cale> Well, listToMaybe doesn't usually solve the problem
02:38:31 <tdammers> if you're dealing with text, you may also want to use take 1 instead of head, then you can match on the entire string more naturally
02:38:40 <Cale> You still then have to deal with the Maybe, and if you're going to pattern match that, you might as well have pattern matched the list
02:38:52 <ggVGc> is there a difference between non-total and partial?
02:39:07 <u0_a77> I can't understand how to construct an applicative version of ifte combinator
02:39:16 <u0_a77> no, there is not
02:39:34 <liste> what's ifte combinator?
02:39:53 <u0_a77> ifte t f c = if c then t else f
02:40:46 <liste> :t bool
02:40:47 <lambdabot> a -> a -> Bool -> a
02:40:51 <liste> so this?
02:40:53 <Cale> The best you can do is  liftA3 (\b t e -> if b then t else e)
02:41:04 <liste> :t liftA3 bool
02:41:06 <lambdabot> Applicative f => f d -> f d -> f Bool -> f d
02:41:11 <Cale> Note that this will always have the effect both branches
02:41:16 <Cale> of*
02:41:42 <Cale> Assuming that you have an f Bool here and not a Bool of course
02:42:31 <ggVGc> man, I have a question I'm not sure how to express
02:43:08 <Cale> The ability to decide the continuation of a computation based on the result of some particular computation is exactly (>>=), and that's a decent way of describing what makes Monad stronger than Applicative
02:44:09 <u0_a77> thx, my applicative has trivial effects, so it was a driving force to downgrade from monad in the first place
02:44:46 <ggVGc> Say I've got several functions that are all typed X -> Y, but they each require different environments. So technically they are Env1 -> X -> Y, and Env2 -> X -> Y etc. I now want to make another function that executes these, suplying them the environments they need, but only calculates the environment for a given thing if it is needed
02:44:54 <ggVGc> how could I structure this?
02:45:20 <ggVGc> the only way I can think of is supplying a dict of functions as the environment
02:45:46 <u0_a77> Rw
02:45:58 <u0_a77> *Reader?
02:46:07 <ggVGc> how does reader help me
02:46:30 <Cale> ggVGc: I'm not sure I understand the question. You're worried about the cost of computing the value of type Env1 you're supplying?
02:46:41 <fakenullie> You can use record as environment
02:46:57 <Cale> Lazy evaluation will usually take care of that
02:47:05 <ggVGc> fakenullie: right, that's what I was thinking
02:47:14 <u0_a77> you stick your funcs in it and operate on objects of Env type
02:47:42 <ggVGc> right so all of this boils down to what I already figured, which is to use a record of functions as the Env
02:47:50 <ggVGc> rather than a separate Env type for each sub-function
02:47:59 <Cale> I don't see how any amount of shuffling things around with monads will help address the concern about whether the environments get calculated or not
02:48:41 <Cale> But maybe I just don't understand what you want.
02:50:05 <ggVGc> Cale: basically, what I was looking for was instead of something like API -> X -> Y as the type of all the functions. I wanted each one to somehow state in the type which part of the API it wants, and then have an evaluation function take a set of these and calculate the needed environments and pass them
02:50:17 <ggVGc> as I said, I don't know how to clearly express it :)
02:51:06 <Cale> Maybe just write it straightforwardly first and then think about how to simplify things
02:51:19 <Cale> Pass the arguments explicitly, and see what you end up with
02:52:06 <ggVGc> but lets say there is a Record 'API' that has functions 'getFoo' and 'getBar'. Instead of going API -> X -> Y, and inside that function using getFoo. I'd like to specify something like (WantsFoo f) => f X -> Y
02:52:20 <ggVGc> Cale: passing explicitly would mean a record of all the API functions
02:52:33 <ggVGc> which doesn't tell me what part of the API that function is using
02:52:51 <Cale> uhh
02:53:05 <Cale> What's the type of getFoo?
02:53:19 <ggVGc> doesn't matter. Letis say it's Foo
02:53:29 <Cale> Then why not just make that Foo -> X -> Y?
02:54:39 <ggVGc> Cale: because there's a set of these X -> Y functions, and they all might use one of more parts of the api. And I want to write an evaluator function that supplies each of them with the extra environment they need
02:54:57 <cocreature> you can also use some kind of classy lens approach but that might be overkill
02:55:01 <ggVGc> passing in a record of the api makes it simple, but I was wondering if I could make it more explicit in their types
02:56:01 <ggVGc> I guess I'm looking for something like traits in other languages?
02:56:38 <Cale> ggVGc: I guess if you really need the polymorphism, you can make individual type classes for extracting bits of the API, and parameterise your other functions over an arbitrary type that satisfies these conditions corresponding to the bits and pieces of the API
02:57:04 <Cale> but I don't immediately see how that's better than just taking the things as function arguments.
02:57:32 <Cale> (In most cases, I would expect that to be a bit silly)
02:59:15 <Cale> Like, if the issue is that you want some function to be able to be used in places where not all of the API can be defined or something, then factor your big API type into some smaller ones
02:59:17 <u0_a77> anybody used pandoc?
02:59:20 <codeshot> Cale, are you looking for (API,X) -> Y ?
02:59:23 <codeshot> I mean ggVGc
02:59:24 <Cale> and have it only take the parts that you need
02:59:28 <codeshot> sorry Cale
02:59:35 <Cale> That's okay
02:59:48 <Cale> u0_a77: Slightly
03:00:30 <u0_a77> I see a walkM but what I really need is a walkA
03:02:15 <Cale> u0_a77: Which Applicative are you using which isn't a Monad?
03:02:38 <Cale> (there are a few of those around, but not too many...)
03:04:51 <u0_a77> it's Reader but I do not need any of the monad stuff, so all the program is really parallel and not sequential
03:05:20 <u0_a77> I think it could be better optimised with just an applicative constraints
03:05:30 <Cale> Whether you use Monad or not won't change how the code works
03:06:06 <Cale> It's all going to be compiled into a bunch of parameter passing anyway
03:06:46 <u0_a77> lol, it won't change the semantics
03:07:11 <u0_a77> but effectiveness has nothing to do w/it
03:07:30 <Cale> It ought not to change how the code runs in a meaningful way either
03:07:41 <Cale> It *certainly* won't result in code running in parallel
03:08:03 <Cale> (you'd have to be explicit about where parallelism is introduced)
03:08:08 <u0_a77> I will do some par magic maually if needed
03:08:28 <u0_a77> but in the monad presence I doubt it will be useful
03:08:43 <Cale> Why is that?
03:09:51 <u0_a77> here you've got me
03:10:19 <Cale> Note that if you're really just using plain Reader, the inliner's typically going to eliminate all the uses of (>>=) from the code anyway
03:10:46 <Cale> It's all just a bunch of parameter passing
03:12:00 <u0_a77> Unfortunately I have to show off in front of my advisor and have some guarantees stronger than "you know, GHC will do some voodoo and it's fine"
03:13:12 <ggVGc> Cale: so, something along the lines of this, but I'd like the WantsFoo to be in the type, somehow, the best
03:13:15 <ggVGc> eh, sorry
03:13:23 <ggVGc> Cale: https://gist.github.com/anonymous/b569d5211cb8ddf2b59f5153851260ec
03:17:30 <zennist> so for monoids, if implementation involves 'overriding' i.e., configuration objects that override one another, is the convention to have left to override right objects, or the reverse?
03:17:30 <u0_a77> workhorse function in the project is constructInterpreter :: Algebra Grammar (Reader Env Value)
03:17:31 <u0_a77> -- another layer of indirection and you're golden
03:18:07 <zennist> I thought it was more intuitive to have right ones to override left ones, but than I realize the Monoid instance of Map for example, has the opposite behavior
03:20:41 <sternmull> What does the r in rpar/rseq stand for? Recursive?
03:21:18 <u0_a77> + iirc
03:45:59 <Cale> ggVGc: I really don't understand why Foo -> X -> Y isn't the answer to your question
04:01:50 <codeshot> zennist, maths doesn't have conventions
04:02:37 <codeshot> Map's behaviour is not a left overriding, it's a right re-using
04:04:21 <codeshot> If you want to have a specific behaviour really you should make your type be an instance of a suitable class as well as monoid - there are a variety of semigroup classes in hackage for various behaviours
04:05:18 <codeshot> then your functions that take a monoid can take (LeftOverride a) => a -> b -> c
04:05:52 <codeshot> and then they can use the methods defined in the suitable class which are the only reason it matters anyway
04:08:22 <codeshot> zennist, https://en.wikipedia.org/wiki/Special_classes_of_semigroups
04:10:35 <codeshot> zennist, from that page I think you're talking about cancellative variants of semigroups
04:22:37 <codeshot> nope it's a partially zero-ing semigroup
04:34:11 <royal_screwup21> Why does this foldr (\acc x -> acc+1) 0 [1,2,3,4] return 2, and not 4? Doing the same thing except with foldl returns 4. I know foldl and foldlr have different definitions but I'm struggling to see how the former returns 2
04:38:23 <cocreature> royal_screwup21: your variable names are off, the accumulator is the second parameter for fold-right (the intuition is that for foldr the accumulator is on the right and for foldl on the left)
04:38:39 <cocreature> so you are just completely ignoring the accumulator and the result is 1+1
04:39:22 <royal_screwup21> oh okay
04:39:41 <royal_screwup21> thanks cocreature
04:40:25 <royal_screwup21> is it safe to assume foldl(\acc x -> stuff) and foldr (x acc -> stuff) return the same value?
04:41:32 <royal_screwup21> like are they equivalent, given the same list and the same starting accumulator?
04:42:14 <cocreature> > foldr (\x acc -> x) 0 [1,2,3]
04:42:17 <lambdabot>  1
04:42:21 <cocreature> > foldl (\acc x -> x) 0 [1,2,3]
04:42:23 <lambdabot>  3
04:42:31 <cocreature> so the answer is ‚Äúno‚Äù :)
04:42:48 <fizbin> royal_screwup21: no, but I see cocreature beat me to it with a much more succinct example.
04:43:25 <cocreature> if your operation is associative, they‚Äôre equivalent
04:44:06 <royal_screwup21> alrighty
04:44:29 <lavalike> these diagrams show you why https://wiki.haskell.org/Fold#List_folds_as_structural_transformations
04:45:16 <fakenullie> Except infinite list
04:57:49 <royal_screwup21> https://thepasteb.in/p/DRhjADX7vDoFy I'm trying to write a tail function using maybe, where tail' [] = nothing and tail' list = Just (tail list). The first implementation works, but the second doesn't. Could someone point me in the direction as to why the second doesn't work?
04:59:05 <royal_screwup21> essentially it boils down to: how is Maybe [a] different from Maybe b? From what I understand, the first one ensure that the thing we're returning IS a list, while the second one says it could be anything
04:59:42 <cocreature> royal_screwup21: not quite, the second says that you are able to return anything and the caller can choose what "b" is
04:59:48 <sternmull> the documentation says that ref <- newIORef '1'; forever $ atomicModifyIORef ref (\_ -> ('2', ())) would leak memory. Why is that? Even if the ref is never evaluated... isn't the ref replaced with a new thunk and the old one can be garbage collected?
05:01:17 <royal_screwup21> cocreature: hmm, how would I make it work with Maybe b?
05:01:47 <cocreature> royal_screwup21: you can‚Äôt. your function is not sufficiently general for a "Maybe b" return type
05:02:37 <cocreature> royal_screwup21: say I am the caller, I choose a to be Int and b to be Bool, now you need to provide me with a Maybe Bool based on the [Int] I gave you
05:02:40 <cocreature> that‚Äôs not going to work
05:03:31 <sternmull> the documentation is right, it leaks. But i don't understand why.
05:04:20 <royal_screwup21> cocreature: ah okay...well theoretically I could pattern match for all [a] -> Bool but...yeah that's not possible
05:07:50 <cocreature> sternmull: after applying atomicModifyIORef once the contents of the IORef look like "((\_ -> '2') 1)". after applying it again it looks like "((\_ -> '2') ((\_ -> '2') 1))" and it just keeps on growing
05:08:52 <sternmull> cocreature: I somehow assumed that the _ would not hold a reference.
05:09:44 <cocreature> sternmull: it‚Äôs not the _ that holds the reference, it‚Äôs the function application of (\_ -> '2')) to the argument that causes the argument to be retained
05:11:18 <sternmull> ah, ok. I really have problems understanding space leaks.
05:18:30 <qaz> why ghci doesn't get this? let A x = "A(" ++ x ++ ")"
05:19:47 <sternmull> qaz: because of the capital A. This is reserved for types.
05:20:54 <qaz> thank you
05:29:08 <gfixler> forall x. (a -> x) -> f x ~ f a
05:29:18 <gfixler> ^ what's the "~ f a" bit?
05:29:56 <kuribas> doesn't ~ mean unify?
05:30:22 <kuribas> meaning f x and f a are the same type?
05:30:57 <gfixler> kuribas: okay, I heard that ~ means f a was the same thing, but wasn't sure if meant same as f x, or same as the whole function type
05:31:12 <mniip> ~ is just a constraint
05:31:32 <ggVGc> what are your prefered testing frameworks/helpers/toolkits?
05:31:36 <mniip> ah I might've misread the type
05:31:48 <ggVGc> I've only really used HSpec before but looking into Tasty now
05:32:46 <kuribas> ggVGc: tasty, hunit and quickcheck
05:34:14 <ggVGc> kuribas: what are the main positives of using tasty in your experience?
05:34:35 <ggVGc> I seem to see informtation of people using tasty on top of hspec
05:35:03 <kuribas> ggVGc: I just use it because it works nicely with cabal, I haven't really made a comparison though.
05:35:12 <kuribas> ggVGc: it works fine for my purposes
05:37:21 <ggVGc> fair
05:37:22 <ggVGc> thaanks
05:43:15 <zennist> has anyone found the need to have something that can automatically find all identifiers to export from a haskell file and put into the export list?
05:43:46 <zennist> I'm using emacs and hope someone writes a elisp function that does that; right now I have to manually copy identifiers and shift them to the top, very manual
05:45:23 <zennist> nvm found this functionality exists in HaRe, will try to integrate into my emacs
05:45:29 <zennist> kudos to HaRe devs!
05:46:05 <alanz> zennist: have your tried lsp-mode/lsp-haskell with hie?
05:46:38 <alanz> As a good place to build that functionality in
05:52:45 <zennist> alanz: have not tried the new language server, have been using the haskell-mode, plus some personal hacks like everyone : )
05:53:09 <alanz> ok. It is starting to get usable, in my opinion.
05:53:53 <alanz> And it supplements haskell-mode, does not replace it
05:54:10 <alanz> brings in stuff via flycheck, xref provider, etc
05:54:24 <alanz> And adds some extra commands
05:54:27 <ggVGc> why does stack build my executable when I run stack test?
05:54:49 <ggVGc> in my cabal file the test suite does not reference the exe one
05:55:01 <ggVGc> crybot-0.1.0.0: unregistering (local file changes: test/Spec.hs)
05:55:01 <ggVGc> crybot-0.1.0.0: build (lib + exe + test)
05:55:11 <ggVGc> why is the 'exe' part there?
05:55:19 <ggVGc> shouldn't it only build the lib and the test suite?
05:56:16 <lambdamu> alanz: hie depends on ghc-mod, right? Does that work well? I had nothing but bad experience with ghc-mod and came to the conclusion that something like that has to be build in to GHC to be usable
05:58:01 <alanz> it does use ghc-mod, from the repo
05:58:21 <alanz> And it works pretty well. Detects if a project is stack or cabal, and works accordingly
05:58:45 <alanz> But does not yet have cabal new-build support in iit
05:59:00 <lambdamu> alanz: How is performance and memory usage compared to ghci based dante or intero?
05:59:17 <alanz> I have not used either of those, so can't comment
05:59:23 <ertes> zennist: i haven't found the need for that, because there are only two cases: either i want to establish a document structure, in which case i have to write the export list myself anyway, or i just want to export everything as is, in which case i just don't use an export list at all
05:59:25 <lambdamu> alanz: Ah alright
05:59:26 <alanz> But I have heard people say it is faster
06:00:04 <alanz> intero/dante do all the heavy lifting in elisp, as a layer on top of modified ghci
06:01:01 <ertes> zennist: example: https://github.com/esoeylemez/predictive/blob/master/Data/Predictive.hs#L7-L23
06:01:06 <lambdamu> alanz: dante at least uses upstream ghci, and to be fair they have a much smaller scope than hie/lsp
06:01:13 <ggVGc> I used intero with vim
06:01:21 <ggVGc> it's a lot better than ghci for me, since it works well with stack
06:01:27 <ggVGc> eh, sorry, ghcmod
06:01:36 <ggVGc> I was having a lot of issues with ghc-mod in the past
06:01:44 <ggVGc> also I feel intero is a lot faster
06:01:49 <ggVGc> but it does use a lot of memory occasionally
06:02:01 <ertes> ggVGc: it's probably GHC itself that does
06:02:07 <ggVGc> yep, certainly
06:02:10 <alanz> ghc-mod went through a bad patch, when a large number of ghc changes came through, a few years ago
06:02:15 <ertes> i use GHCi integration with haskell-mode, and it also uses a lot of memory
06:02:15 <alanz> and it took forever to adapt
06:02:22 <ggVGc> ertes: but there's something extra with intero, where I think it sometimes launches too many instances
06:02:28 <ggVGc> or that might be the fault of the vim plugin
06:02:50 <alanz> btw, there is an LSP plugin for neovim
06:02:52 <ggVGc> alanz: well, ghc-mod was also started before stack existed, afaik. So intero has a leg up
06:02:55 <alanz> Which should allow hie to wor
06:03:06 <ggVGc> yeah, I've been meaning to check out lsp
06:03:12 <ggVGc> it's the language server thing right?
06:03:21 <ggVGc> looks good
06:03:27 <ggVGc> I've had similar ideas for years, but never got to it
06:03:29 <ggVGc> glad someone did
06:03:42 <ertes> what's the purpose of LSP?  is it something like haskell-interactive-mode, but language-agnostic?
06:03:56 <ggVGc> ertes: no, it's a general protocol for language support
06:04:07 <ggVGc> so you can write a single plugin for an editor, and a single backend for a language
06:04:11 <ggVGc> and it'll work
06:04:20 <ertes> across editors?
06:04:21 <ggVGc> surprised we haven't had it ages ago
06:04:22 <ggVGc> yeah
06:04:28 <ertes> ah, that sounds like a great idea
06:04:38 <ggVGc> ertes: so, you write a plugin for vim, like this, https://github.com/prabirshrestha/vim-lsp and get "language support features"
06:04:44 <ggVGc> then you write a server part that knows haskell
06:04:46 <ggVGc> and then they talk
06:04:53 <ertes> i see
06:04:59 <ggVGc> but you might write another server part that knows C++, and you don't need to change the plugin
06:05:07 <ertes> so there is no generic LSP server, but one for each language‚Ä¶  it's just about the standard protocol
06:05:14 <ggVGc> yep, afaik
06:05:35 <alanz> and haskell-ide-engine is a language server for haskell
06:06:59 <ertes> how well does LSP handle language-specific features like GHC holes or the aforementioned export lists?
06:07:49 <alanz> ertes: it is extensible. For example the HaRe commands are exposed
06:07:53 <alanz> So they can be added
06:08:18 <ertes> does your editor have to support those extensions?
06:08:19 <alanz> And it supports the concept of quick-fixes, where they can be suggested
06:08:26 <alanz> Something like what intero does
06:08:48 <alanz> yes, the client side needs to add something specific
06:08:52 <alanz> unfortunately
06:09:14 <alanz> There are issues raised against the protocol, but they have been pushed into a future version
06:09:36 <alanz> I am hoping to be able to work around it by offering CodeAction/quickfixes, from the server side
06:09:56 <alanz> But I am currently buried under GHC, so this is on the back burner
06:10:18 <alanz> That said, I will cheerfully point volunteers in the right direction
06:49:56 <_sideeffect> is there a good article on how to implement pure functional graphs?
06:53:23 <qaz> could anybody please provide an example of two functions that could be called this way: 'ghci> func1 func2 "str"' ?
06:53:41 <hpc> > fmap succ "ooger booger"
06:53:43 <lambdabot>  "pphfs!cpphfs"
06:57:00 <qaz> i mean functions whose code i could read
06:57:55 <ongy> > map toUpper "str"
06:57:57 <lambdabot>  "STR"
06:58:33 <ongy> you can find most functions code with hoogle.haskell.org and then click the little "Source" link on the right side
07:01:07 <qaz> Not in scope: ‚ÄòtoUpper‚Äô
07:03:11 <ongy> @index toUpper
07:03:11 <lambdabot> Data.Char
07:06:05 <qaz> thank you
07:19:02 <timothyh> anyone wise to the GHC API? How much do I need to be wise to DynFlags if I'm just calling Outputable functions
07:20:21 <timothyh> I'm porting a very old Haddock patch (2011!) to HEAD and its sparing use of showPpr is busted, since all that stuff requires dflags now.
07:26:56 <cocreature> timothyh: you might have more luck in #ghc with that question
07:29:11 <mniip> timothyh, not much
07:29:16 <mniip> the default dynflags are fine
07:29:45 <mniip> the Outputable-related dynflags are stuff like -fprint-explicit-kinds and the lik
07:30:59 <timothyh> silly question, where can I find the default dynflags? in Haddock I notice they pull them from some global variable in IO
07:32:06 <mniip> runGhc _ getSessionDynFlags ?
07:33:43 <timothyh> ah, looks like `showSDocUnsafe` just reads from the same place.
07:33:48 <timothyh> thanks mniip !
08:38:18 <eacameron> Feedback requested: Some libraries use QuasiQuotes to allow you to have interpolated strings. Such libraries are interpolated-strings, here, etc. But what if we had an option to do interpolation as a preprocessor instead? It would simply pull out things inside, say ${..} and stick <>...<> around them. This would allow interpolation without TH or QQ at all.
08:47:49 <mud> Haskell strings do rather suck a lot in terms of lacking heredocs, multiline strings and other random nice things from other languages.
08:48:07 <cocreature> mud: Haskell has multiline strings
08:49:07 <mud> cocreature: Barely, and they suck. You're talking about \ at the end/beginning, right?
08:49:43 <cocreature> yes, they have their problems but ‚Äúbarely‚Äù seems a bit too harsh :)
08:51:50 <mud> Well, they're annoying and ugly enough that I personally avoid them, to the point of throwing in some TH/QQ when I actually need them instead, or doing concat ["bunch", "o", "strings"], etc. And I know I'm not the only one.
08:52:41 <sm> you're not the only one
08:56:34 <timothyh> anyone know where to submit patches to hscolour?
09:00:01 <ggVGc> man, I can't figure out how to get "stack test" to not build my executables
09:00:12 <ggVGc> except removing the definitions from the .cabal file while running tests
09:00:16 <ggVGc> which is a bit annoying
09:00:55 <hvr> timothyh: I'd say email Malcolm directly
09:01:21 <machinedgod> 1/6
09:01:23 <codeshot> How do FRP systems avoid memoize unchanged values until the next event that affects them?
09:01:55 <codeshot> Since we tend to describe a signal with monadic bind
09:02:43 <codeshot> The final expression depends on all prior expressions
09:02:49 <ggVGc> argh.. seems this is the issue, https://github.com/commercialhaskell/stack/issues/1406
09:02:54 <codeshot> there's no poset
09:03:45 <codeshot> s/avoid //
09:06:02 <hvr> ggVGc: you could try cabal new-build; it works fine there
09:07:12 <ggVGc> hvr: i want to use stack though
09:07:27 <hvr> that's unfortunate :-/
09:08:13 <ggVGc> well, my current solution is to comment out the "executable" components from my cabal file while working on tests
09:08:18 <ggVGc> not the best solution I reckon
09:08:26 <ggVGc> but it halves my build time
09:09:03 <hvr> I know that problem quite well :-)  and new-build helps a lot if you have e.g. a package with 30 executables
09:09:26 <hvr> you can either build them individually as you need them; or you can have them build in parallel
09:09:27 <eacameron> mud: If QQ is an option then I think Haskell's story for interpolation is actually much better than most langs. Most langs only offer one very specific form of interpolation. And the multiline story has a very interesting advantage in that you have total control of the whitespacing which is a continual source of pain in, say, Python's """ """ syntax.
09:09:34 <hvr> both speeds up things a lot
09:13:03 <MarcelineVQ> ggVGc: there is a solution though it's a little lame, less lame that editing the cabal each time though.  put    flag test \n default :false  in your cabal file and   if flag(test): \n buildable: false  in the executable stanza, and run with   stack test --flag test
09:13:30 <MarcelineVQ> *default: false
09:14:45 <MarcelineVQ> iow you're saying, when I've set 'test' don't build my goddamn executable
09:16:08 <hexagoxel> default: false manual: true
09:18:35 <ggVGc> MarcelineVQ: ah, yeah, not sure why I didn't think of that
09:18:36 <ggVGc> thanks
09:19:16 <MarcelineVQ> though I guess in stack that's,  stack test --flag mylibname:test
09:20:14 <timothyh> hvr: ack
09:20:16 <MarcelineVQ> *myprojectname  whatever, if you know the target syntax roughly you'll get it hehe
09:21:36 <sh4pe[m]> Hello there! I've got a question for all the `stack` users out there
09:22:17 <lyxia> @ask
09:22:18 <lambdabot> Who should I ask?
09:22:20 <sh4pe[m]> Is there a command that just downloads and installs all dependencies of my binaries/libraries?
09:22:33 <timothyh> hvr: his email is not available on the hscolour website or hackage metadata, could you perhaps /msg it to me?
09:23:18 <cocreature> sh4pe[m]: stack build --only-dependencies
09:23:35 <sh4pe[m]> i.e. I don't want my libraries and executables to be build, but all their `build-depends`
09:23:42 <sh4pe[m]> Ah - nice :)
09:23:55 <MarcelineVQ> sh4pe[m]: just curious, why do you want that?
09:24:57 <sh4pe[m]> I want to cache the contents of my .stack-work directory after that. I'm using CircleCI and I want all of these dependencies to be cached
09:26:36 <sh4pe[m]> cocreature: Thanks for your hint, works like a charm üëç
09:28:24 <MarcelineVQ> oh neat, though I'm not sure everything will be in there, things from the resolvers come out of the .stack/snapshots  and .stack/programs I think
09:28:42 <MarcelineVQ> that is to say ~/.stack
09:29:01 <MarcelineVQ> so you'll want that cached if it's not and you're able to do so
09:29:46 <cocreature> in fact I‚Äôd say caching ~/.stack is far more important in most cases, not caching the local .stack-work can be reasonable if you want clean builds of your own packages and don‚Äôt have too many extra-deps
09:30:22 <sh4pe[m]> Ah - nice, thank you.
09:30:52 <sh4pe[m]> So the stuff I'm installing with `stack build --only-dependencies` will be in ~/.stack, right?
09:34:25 <MarcelineVQ> I think if it's not a git entry or extra-dep from your stack.yaml it should be in  ~/.stack/snapshots  and if it's something that comes with ghc it's in  ~/.stack/programs , do you know if that's the case cocreature?
09:36:34 <ggVGc> MarcelineVQ: that's a pretty good hack!
09:36:46 <ggVGc> bot shit that we need a hack though
09:39:33 <MarcelineVQ> ggVGc: that's just part of the reality of computers and humans having to live together :(
09:48:43 <saurabhnanda> sh4pe[m]: we've spent a LOT of time in getting CircleCI to work well with stack.
09:49:03 <saurabhnanda> have pretty much nailed it (long pending blog post). what's your issue?
09:49:46 <sh4pe[m]> No issue yet, just starting to work with it. Could you please send me the link to the blog post? I'm very interested in reading it
09:49:56 <saurabhnanda> I can sent you our CircleCI script.
09:50:13 <sh4pe[m]> That would be awesome too!
09:50:22 <saurabhnanda> it solves for stack, compiling in limited memory environment, caching to enable faster incremental builds, everything.
09:50:32 <saurabhnanda> how big is your project?
09:51:21 <saurabhnanda> sh4pe[m]: do you have a UI/JS component also that you need to build? and finally you need to deploy the build artefacts OR just run tests?
09:51:39 <sh4pe[m]> Small (<5ksloc yet)
09:51:50 <saurabhnanda> our config file is for building & deploying artefacts right now. Not running tests. Next thing is to run testa and write an XML test collector.
09:51:57 <cocreature> MarcelineVQ: sounds about right at least for the current stable release of stack. I‚Äôm not sure if the extensible snapshot stuff in the next release changes things with regards to extra-deps
09:52:02 <saurabhnanda> hang on... stripping out the proprietary stuff
09:52:14 <sh4pe[m]> No need to deploy the build artefacts yet (but maybe later). I'm more interested in building and running the tests yet
09:53:04 <sh4pe[m]> But I'd still be interested in your config - caching the dependencies is the issue I'm working on now
09:53:32 <sh4pe[m]> saurabhnanda: Thank you, that is very kind of you :)
09:54:45 <saurabhnanda> this is circleCI v2, mind you. More complicated, but more powerful.
09:54:48 <amx> is there a reasonably elegant way to combine n optional filters (WHERE clauses) with postgresql-simple? I'd like to avoid writing 2^n queries.
09:54:51 <saurabhnanda> sh4pe[m]: are you using docker for your builds?
09:55:09 <saurabhnanda> amx: string interpolation, or move to a higher level lib.
09:55:16 <sh4pe[m]> saurabhnanda: Yes
09:55:42 <sh4pe[m]> saurabhnanda: And I'm using v2 too
09:55:56 <saurabhnanda> okay, give me 10mins... writing some comments as well
09:56:13 <sh4pe[m]> Awesome!
09:56:24 <d-fish> The example http://hackage.haskell.org/package/bytestring-0.10.2.0/docs/Data-ByteString-Lazy.html#v:splitWith is for List split
10:01:03 <hvr> saurabhnanda: was there anything specific to take into account for CircleCI? I'm curious as I've been meaning to look into supporting CircleCI for cabal new-build
10:01:34 <saurabhnanda> hvr: yes -- the haskell working directory doesn't cache well across incremental builds
10:02:14 <hvr> how does circle CI's persistance work?
10:08:21 <saurabhnanda> sh4pe[m]: https://gist.github.com/saurabhnanda/1ce4a937aef9b5b867ec3188636924e9 -- see if this helps you. it doesn't have tests, btw. but you can add a `stack test` step at the end. 
10:09:05 <saurabhnanda> hvr: not anything to do with circle-ci really. but if the repo is checked out again, stack thinks every file has changed and it recompiles the ENTIRE project all over again.
10:10:14 <sh4pe[m]> Wow - thank you! I'll have a look at it
10:10:58 <hvr> saurabhnanda: ah ok, that's something that new-build does better
10:11:29 <hvr> saurabhnanda: as it doesn't rely on timestamps only
10:11:33 <saurabhnanda> sh4pe[m]: please read every single line and make sure you understand it. else you'll spend unnecessary time in deploy/debug cycles.
10:12:03 <sh4pe[m]> Okay. It will take some time...
10:12:15 <saurabhnanda> sh4pe[m]: there's a circleci library to do this stuff locally. we discovered it after putting in all the hard work at the very end. see if you can get it setup to speed up the initial config file setup.
10:12:41 <sh4pe[m]> Yes, I've just installed it 2 hours ago
10:12:49 <saurabhnanda> cool.
10:12:56 <sh4pe[m]> saurabhnanda: Thank you very much!
10:17:55 <saurabhnanda> hvr: gawd, how I hate this stack / cabal divide. Spoke about it in my talk today, as well. And hate the fact that Rust devs can just point to cargo and say "it works" and that's end of story. Get back to actual development. I don't know how - but this needs to be fixed. Somehow stack & cabal should merge to build one awesome build tool which works for a broad set of workflows.
10:18:35 <MarcelineVQ> erm, you can point at cabal and say it works
10:18:41 <saurabhnanda> btw, cool TIL. Rust can have tests in the main source file (one extra annotation), and benchmarks (extra annotation) and cargo can handle both.
10:21:44 <fendor> is there a package for capturing mouse movements?
10:22:05 <WzC> question for the lens people: suppose I have a value v :: Vector (a,b), and I want to get (snd <$> v :: Vector b), is there a way to write that in "lens"? Preferrably even using the '_2' lens instead of just the function snd ?
10:22:26 <Gurkenglas> v ^. _2
10:22:49 <ggVGc> am I bad for often importing Data.Function and using someList & map someFun
10:23:03 <Gurkenglas> WzC, nvm, I'm wrong there
10:23:33 <WzC> yeah that doesn't seem to work 
10:24:11 <WzC> and s.t. like v^..traverse._2 also does not what I want 
10:24:25 <Gurkenglas> fmap (view _2) -- view _2 == snd
10:25:22 <Gurkenglas> over traverse snd -- fmap == over traverse
10:25:31 <MarcelineVQ> ggVGc: it's fine you're allowed to be bad with haskell because the compiler knows the difference between bad and wrong
10:25:57 <Gurkenglas> WzC, perhaps less useless rephrasings could be made if you give more context
10:25:59 <[exa]> fendor: that depends on where are you going to take the mouse movement from (it's possible directly from X11 or windows API, you can use Qt/GTK etc., some other toolkits, gmp, ....)
10:26:15 <ggVGc> MarcelineVQ: I just really often want to map a function over something without giving it a name and (flip fmap) sucks :(
10:27:02 <lyxia> (<&>) = flip fmap
10:27:05 <fendor> [exa], i dont want to use a graphics library such as Qt or SDL, seems a little bit like overkill, and if possible cross-plattform, but will settle for X11
10:27:14 <MarcelineVQ> without giving it a name?
10:28:31 <ski> ggVGc :  (`map` someList) $ \x -> ..x..
10:29:13 <ggVGc> ski: not sure that's better than bar & fmap foo
10:29:36 <cocreature> fendor: tbh making a window and capturing mouse movements seems pretty much what SDL was made for, Qt is another story but SDL is not that big
10:30:05 <ggVGc> sfml is a much better choice
10:30:11 <MarcelineVQ> ggVGc: what's your actual usecase? cause I'm not sure how that's better than   fmap foo bar  hehe
10:30:13 <ggVGc> if all you want is a window and input
10:30:38 <fendor> cocreature, i'm looking for something like python pyuserinput package, i "just" want to capture all mouse movements while running, not only in a window
10:30:39 <ggVGc> MarcelineVQ: just that I want to map an anonymous function over something, and usually that something is a single name while the function is longer
10:30:49 <ggVGc> so I prefer to have the function as the last argument
10:30:53 <ski> ggVGc : or a list comprehension, i suppose, since you had a list
10:31:17 <WzC> Gurkenglas: well that really is just the "problem". I'm currently using the (snd <$> v) somewhere in the middle of a lens setter, i.e. : myRecord&myLens .~ (snd <$> v), and I was wondering if there was a way of writing the (snd <$> v) part more "lensy" 
10:31:45 * ski has sometimes defined `pam = flip map'
10:31:59 <MarcelineVQ> ggVGc: ah alrighty, seems like a fine use then. (`map` someList)  is the same number of chars as flip map someList anyway
10:32:26 <MarcelineVQ> for some meaning of same number :>
10:33:29 <Gurkenglas> WzC, where does v come from?
10:34:57 <[exa]> fendor: I'd hack through the source code of Xeyes or something similar then, and just adapt it to haskell
10:35:19 <WzC> its some parameter in the function I'm writing 
10:35:31 <fendor> [exa], thats what i am currently doing ^^ 
10:35:34 <Gurkenglas> WzC, do you happen to need fst <$> v somewhere else, and never use v directly?
10:35:57 <Gurkenglas> Or, why are the fsts passed to the function in the first place
10:36:10 <fendor> is there reason haskell does not have a lot of utility tools for mouse events, or keyboard compared to python?
10:36:38 <WzC> yes, the v is used somewhere else as well 
10:36:56 <WzC> (where I'm using the fst's) 
10:37:27 <Gurkenglas> WzC, https://hackage.haskell.org/package/vector-0.12.0.1/docs/Data-Vector.html#v:unzip
10:40:06 <WzC> hmm ok that is a decent solution as well 
10:41:15 <Gurkenglas> Are the fsts used up or also merely stored as the snds?
10:41:49 <WzC> what do you mean by "used up"?
10:42:22 <Gurkenglas> Not sure, hoped you could guess :P. How are the fsts used?
10:42:23 <WzC> directly consummed by the function I'm implementing? I guess you might say that 
10:44:50 <monochrom> Perhaps "used up" means "evaluated".
10:46:55 <fendor> [exa], well, looks like X11 or something like that: https://linux.die.net/man/3/xquerypointer
10:47:55 <fendor> or at least xlib
10:48:01 <Gurkenglas> If it were myLens .= (snd <$> v), perhaps it could be myLens <~ for v (\(a, b) -> do use_up a; return b) (as a starting point for further refactoring), shame we're missing ArgumentDo
10:55:51 <jhu> Hello haskellers. I would appreciate some recommendations on a book about category theory. I have been looking at Lawvere's "Conceptual mathematics." Any recommendations for that one? It seems to be highly regarded. My issue with it is that looking at the index I can not find "lax monoidal functors" (applicatives) or "natural transformations." So I am wondering whether a haskeller would like its contents. I 
10:55:57 <jhu> have a math background, but not really in topology or group theory (assumed by many advanced books).
10:56:23 <Guest87701> \pl \x y -> (g y) . f x
10:57:10 <Guest87701> @pl \x y -> (g y) . f x
10:57:10 <lambdabot> flip ((.) . g) . f
10:57:10 <ski> jhu : i second that one. still, it doesn't go much into some more advanced concepts
10:57:43 <Guest87701> @pl \x y r -> (g y) . f x r
10:57:44 <lambdabot> flip ((.) . (.) . g) . f
10:58:04 <ski> jhu : there's also a thin one called "Basic Category Theory for Computing Scientists" (iirc), by Benjamin Pierce (or is it Peirce ? i can never remember)
10:58:27 <jhu> ski: So start with Lawvere and then proceed to deeper waters if I still feel like swimming?
10:58:32 <cocreature> not having natural transformations is a bit weird
10:58:49 <cocreature> that‚Äôs fairly standard material in category theory regardless from which angle you look at
10:59:02 <jhu> cocreature: Natural transformations might just be missing from the index.
10:59:05 <cocreature> jhu: personally I‚Äôm quite fond of awodey‚Äôs book
11:00:52 <jhu> cocreature: "Looking inside" Awodey's @ Amazon...
11:01:26 <ski> jhu : and a thicker one "Categories, Types, and Structures : An Introduction to Category Theory for the Working Computer Scientist" by Andrea Asperti,Giuseppe Longo and i think someone else i can't remember ?
11:02:03 <ski> jhu : yea, the Lawvere&Schanuel one should be relatively easy-going, "kindergarten style" at times :)
11:02:10 <alp> Awodey's book is the one that worked best for me too, FWIW
11:02:45 <cocreature> I should probably read it again at some point, I‚Äôve forgotten half of it by now :)
11:03:18 <ski> jhu : there's an "Categories and computer science" by R. F. C. Walters, which talks a bit about automata and such
11:04:38 <ski> jhu : and "Computational category theory" by David E. Rydeheard,Rod M. Burstall that implements various categorical concepts as data structures and operations on them, in SML. iirc, it doesn't have that many motivating examples for the concepts, though
11:05:22 <ski> hm, i see there's a "Category theory for computing science" by Michael Barr,Charles Wells, which i don't recall checking out
11:05:48 <Guest87701> @pl \r p -> fromMaybe (f r) p
11:05:49 <lambdabot> fromMaybe . f
11:07:02 <jhu> all: Doing active searches on all of your recommendations...
11:07:28 <ski> jhu : Lawvere and Rosebrugh has a book "Sets for mathematics", that's about a categorical (topos) outlook on sets and math. perhaps it might be interesting to check out, later
11:09:04 <ski> there's a thick book, "The Joy of Cats: Abstract and Concrete Categories" by Adamek, Herrlich, Strecker (you should be able to find a PDF, i think). that i found interesting. it's not for the faint of heart, though, lots of the examples requires knowledge about one or another particular mathematical field
11:09:11 <Guest87701> @pl \r p -> fromMaybe p (f r)
11:09:11 <lambdabot> flip fromMaybe . f
11:09:38 <ski> and there's one called "Toposes, Triples and theories" or something like that, which you could make also take a glance at
11:09:52 <ski> (maybe that's the Awodey one ? i don't remember)
11:11:57 <ski> hmm .. "Elementary Categories, Elementary Toposes" by Colin McLarty is also about sets from a categorical perspective. i better understood the notion of an internal language (which is related to type theory) in a topos, after reading this
11:13:19 <ski> but these four latter i mentioned aren't books to start with (my impression is that the simplest of these four to get started with may be the first, or maybe the last)
11:26:07 <jhu> Ok, "Joy of cats" and "Categories, types and structure" seem to be online (PDF) now, so getting them is easy.
11:30:52 <crucify_me> hi aside from the type definition, where exactly does this program do the merge. ie when x and y are consed in the guards, how does it form a single list ? https://ptpb.pw/Yhfk
11:32:36 <crucify_me> since x : xs    and y : ys   ,    it still looks like 2 lists would be returned
11:32:49 <crucify_me> except for the type signature
11:37:37 <crucify_me> did I answer my own question, that the signature dictates that ?
11:37:52 <cocreature> crucify_me: (x:xs) and (y:ys) are the inputs to the function not the output, the output is "x : merge xs (y : ys)" in the first case and a slight variation of that in the second case
11:38:49 <alsoStevenXL> Hello.
11:39:05 <alsoStevenXL> Has anyone used the citext postgres type with persistent?
11:39:09 <crucify_me> cocreature, thanks,  so where the conses occur  ...
11:39:29 <bigHaskellNoob> Hello
11:40:08 <crucify_me> I visualize x and y choosing their lists, but I look at them as separate. do you see what I mean cocreature ?
11:40:17 <cocreature> crucify_me: tbh I don‚Äôt :(
11:41:19 <monochrom> Yeah that's too much anthropomorphizing to imagine.
11:41:23 <cocreature> crucify_me: how can an element choose a list? what is that supposed to mean?
11:42:01 <crucify_me> I just mean x and y go to their respective lists
11:42:35 <alsoStevenXL> wow - that was painless. Enable the citext extension on the db, and then use sqltype=citext
11:42:35 <cocreature> there is only a single output list, that‚Äôs the whole point of merging them
11:42:38 <alsoStevenXL> ;-)
11:42:49 <cocreature> so I‚Äôm really not sure what ‚Äúgoing to their respective lists‚Äù is supposed tom ean
11:43:00 <Tuplanolla> I wonder if you could build a programming language that resembles those puzzles where perfect logicians try to get out of a sticky situation.
11:43:02 * ski looks at bigHaskellNoob
11:43:24 <crucify_me> yes, the single output list is defined only in the signature right?
11:43:38 <ski> the signature doesn't define anything
11:43:49 <cocreature> you can remove the signature and the code will still work
11:43:59 <ski> it specifies what "type constraints" a definition would have to satisfy
11:44:14 <jhu> ski, alp, cocreature: Thanks a lot. Searched all your suggestions, will be taking a closer look. Most have great reviews in amazon, not surprisingly the number of reviewers is often epsilon-like. After a quick glance my top candidates are Lawvere (basic version) and Awodey. Might start with one of them and see how I feel after that. I have become very interested in Haskell lately, working through a number of 
11:44:20 <jhu> books concurrently. Expanding my vision with (category) theory while I am at it. Thanks a lot!
11:44:26 <codeshot> crucify_me, a list is a head item and a remainder, each remainder is a list
11:44:33 <Tuplanolla> Then you could canonicalize the idea that program fragments think and make choices.
11:44:52 <codeshot> so its head_1:(head_2:(head_3:(head_4:[])))
11:44:56 <monochrom> Tuplanolla: I think some puzzles are expressible in Prolog or any logic programming language.
11:45:00 <alp> jhu, best of luck to your brain for digesting all these things simultaneously :)
11:45:22 <codeshot> the guards decider whether head_1 of the output will come from the first or second list
11:46:09 <Jikstra[m]> Is there any benefit of the `head_1:(head_2:(head_3:(head_4:[])))` over `head_1:head_2:head_3:[]` syntax? Any use case? 
11:46:11 <codeshot> then the function repeats on two lists, one of which is shorter now, to determine what will be the remainder of the output
11:46:22 <monochrom> Still, it is the Prolog executor, not the predicates or values, that chooses.
11:46:28 <glguy> Jikstra[m]: They're the same
11:46:50 <codeshot> Jikstra[m], yeah, a:b:c:[] looks like it could be conceptually a monoid
11:47:04 <ski> jhu : i think Bartosz Milewski has videos on Haskell <https://www.youtube.com/watch?v=N6sOMGYsvFA> and Category Theory <https://www.youtube.com/playlist?list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_>
11:47:10 <glguy> codeshot: Which part?
11:47:15 <ski> jhu : might want to give them a try
11:47:24 <codeshot> Jikstra[m], and I think that's why crucify_me is having trouble
11:47:31 <jhu> alp: Haven't had this much fun since I don't know when. Worked through my SICP years ago, but Haskell and its abstractions are quite something else.
11:47:44 <ski> jhu : there's also <https://www.youtube.com/user/TheCatsters>
11:47:50 <glguy> codeshot: No, crucify_me just doesn't understand Haskell syntax
11:48:01 <codeshot> Jikstra[m], but by adding the parentheses it is required that there is an item followed by a remainder
11:48:10 <crucify_me> ok yes codeshot so the recursive merger in the guards, that relies on the base cases. one will empty and the other is returned. 
11:48:34 <gfixler> crucify_me: I joined the party late - is the code you're discussing in a paste somewhere?
11:48:34 <monochrom> "monoid" does not refer to a single list like a:b:c:[]. It refers to the collection of all lists, and also the append operation and the empty list.
11:48:42 <ski> jhu : and edwardk's blag could have interesting blags about CT
11:48:48 <crucify_me> gfixler, sorry yeah https://ptpb.pw/Yhfk
11:48:50 <ski> (in the context of Haskell, i mean)
11:48:53 <gfixler> crucify_me: thanks
11:48:55 <monochrom> Likewise no one really says "4 is a ring".
11:49:07 <glguy> They might say that zero is
11:49:11 <Jikstra[m]> thanks codeshot :)
11:49:13 <monochrom> haha
11:49:42 <monochrom> Sometimes you get the feeling that you're watching a Haskell-fiction movie.
11:50:24 <crucify_me> codeshot, that's correct, right? that the base cases will return a single list.
11:50:39 <codeshot> crucify_me, what are "the base cases"?
11:50:53 <monochrom> In which the characters speak like "I'm going to insert the 42 monoid into the quantum field SSL tunnel"
11:51:03 <ski> jhu : i found Bartosz' explanation of limits and colimits (like terminal, initial, product, coproduct, equalizer, coequalizer, pullback, pushout, &c.) as "filtering" "search results" for the best, a nice way to think of it
11:51:10 <crucify_me> merger xs [] = xs   and  merger [] ys = ys
11:51:17 <codeshot> monochrom, no a monoid is a thing which exists outside of Haskell's pretend monoids
11:51:36 <monochrom> That still doesn't make a:b:c:[] a monoid.
11:51:56 <monochrom> Or 42 a ring.
11:52:07 <codeshot> monochrom, I was too imprecise and louche with my words, sorry
11:52:47 <jhu> ski: I took a look at Bartosz's material some weeks ago, but somehow didn't find it that appealing. I will add it to the list and take another look after digesting a book. Also, other online sources noted, thanks again. Need to run. Over and out, see you later.
11:53:19 <ski> crucify_me : `merger', given two list arguments, will always return a single list, not just in the base cases
11:54:31 <crucify_me> ski thanks one moment pls
11:54:32 <monochrom> Oh this can go down like one of those "how many triangles are there in this picture?" puzzles.
11:55:47 <codeshot> crucify_me, do you have a text that explains how haskell recursive functions work and how you can translate guards into a 'case' expression ?
11:56:48 <crucify_me> yes thanks I can see the two cases here codeshot 
11:58:02 <codeshot> CryptoCalsius[m], those two cases are used once one of the two input lists has already had all its elements merged
11:58:05 <codeshot> oops
11:58:12 <codeshot> crucify_me, those two cases are used once one of the two input lists has already had all its elements merged
11:58:42 <crucify_me> but the way I see this is that the base cases will return either list xs or list ys. right thanks codeshot so in other words 
11:59:04 <dxtr> Okay building ghc 7.10 with stack on openbsd is no easy feat
11:59:20 <crucify_me> one list becomes empty and the other one is returned, right?
11:59:30 <codeshot> yes, but of course because this is recursive that xs or ys could be only a remainder part of one of the original two lists
12:00:24 <crucify_me> ok, I understand codeshot ski . thanks, sometimes when I consider the base cases I can see what is happening
12:00:29 <codeshot> during the fancy case with the guarded subcases, as recursion happens the xs or ys will be shortened
12:00:49 <codeshot> sometimes one and sometimes the other
12:00:51 <codeshot> ok
12:00:55 <crucify_me> shortened until one is empty right?
12:00:59 <codeshot> yep
12:01:07 <codeshot> and then one of the base cases matches
12:01:22 <codeshot> and wallop, you're done
12:01:27 <crucify_me> yeah, ok, I need to read the base cases more carefully first
12:01:53 <crucify_me> thanks kindly ALL
12:06:45 <ski> crucify_me : here's an example of `merger' in action
12:07:14 <ski>      merger (0:3:4:7:[]) (1:2:6:7:8:9:[])    -- `0 < 1' is `True'
12:07:35 <ski>   =  0:merger (3:4:7:[]) (1:2:6:7:8:9:[])    -- `3 < 1' is `False'
12:07:47 <ski>   =  0:1:merger (3:4:7:[]) (2:6:7:8:9:[])    -- `3 < 2' is `False'
12:07:59 <ski>   =  0:1:2:merger (3:4:7:[]) (6:7:8:9:[])    -- `3 < 6' is `True'
12:08:10 <ski>   =  0:1:2:3:merger (4:7:[]) (6:7:8:9:[])    -- `4 < 6' is `True'
12:08:21 <ski>   =  0:1:2:3:4:merger (7:[]) (6:7:8:9:[])    -- `7 < 6' is `False'
12:08:46 <crucify_me> word
12:08:55 <crucify_me> thanks very helpful
12:09:11 <ski>   =  0:1:2:3:4:6:merger (7:[]) (7:8:9:[])    -- `7 < 7' is `False', note that we "move over" the `7' in the second list, here
12:09:38 <ski>   =  0:1:2:3:4:6:7:merger (7:[]) (8:9:[])    -- `7 < 8' is `True', and now we move over the other `7'
12:10:10 <ski>   =  0:1:2:3:4:6:7:7:merger [] (8:9:[])    -- now one list is empty, so we reach a base case, replacing the recursive call with the remainder of the other list
12:10:21 <ski>   =  0:1:2:3:4:6:7:7:8:9:[]    -- and we're done !
12:11:20 <codeshot> wallop!
12:11:27 <crucify_me> bingo
12:11:28 <ski> so, as we "walk" the lists, by making recursive calls on smaller lists, we (eventually) reach closer to the end of them
12:11:31 <drdo> Is there something I can use to easily show a clickable and updatable labelled tree?
12:12:34 <ski> so when you see `merger [] ys = ys', since `merger' is recursive, calling itself on smaller lists (i.e. on tails of the original lists), you should read this base case as "when we have reached the end of the first list : ..." (the end being the empty list)
12:12:41 <codeshot> I can't help thinking we'd be better off if we had to use fix for recursion
12:12:43 <crucify_me> yeah, what I was doing was looking at the recursive calls as having, and keeping , two separate lists. but recursion sends all the elements to one list ultimately, and it is returned
12:12:58 <ski> yes
12:13:06 <codeshot> so we can inject a status printing wrapper into any sample code
12:13:07 <crucify_me> hooray
12:13:09 <ski> the "two separate lists" are kept in the two arguments
12:13:21 <ski> and "decremented" as the recursion proceeds
12:13:46 <ski> while the recursive calls "spit out" elements "to the left", taken from one or the other of the argument lists
12:14:09 <crucify_me> yep, I knew that back in scheme days while learning recursion. there is a lot of information in the base cases, and I seem to forget that
12:14:31 <ski> since Haskell is non-strict, this means that the recursion doesn't have to progress to the end, just for the caller to be able to check the first elements of the result
12:14:50 <ski> this is an incremental recursion
12:15:06 <crucify_me> check the first elements of the result?
12:15:18 <ski> a "bulky" recursion would be one that doesn't deliver any information to its caller, until it has proceeded entirely through its recursion. an example of that is `reverse'
12:15:29 <ski> yea, if you evaluate something like
12:15:39 <ski>      take (merger (0:3:4:7:[]) (1:2:6:7:8:9:[]))
12:15:48 <ski>   =  take (0:merger (3:4:7:[]) (1:2:6:7:8:9:[]))
12:15:53 <ski>   =  0:take (merger (3:4:7:[]) (1:2:6:7:8:9:[]))
12:16:03 <ski>   =  0:take (1:merger (3:4:7:[]) (2:6:7:8:9:[]))
12:16:13 <ski>   =  0:1:take (merger (3:4:7:[]) (2:6:7:8:9:[]))
12:16:17 <ski>   =  0:1:[]
12:16:27 <ski> oops, i forgot to put a count argument to `take' :)
12:16:42 <crucify_me> yeah I thought it took one arg by default
12:16:46 <crucify_me> as you had it
12:16:54 <ski> well, i meant to say `take 2', and then decrement that to `take 1' and finally to `take 0' after having "spit out" both `0' and `1'
12:17:09 <ski> at that point, `take' doesn't care about remaining elements of the result of the `merger' call
12:17:11 <crucify_me> yes , that's an interesting way to write it, which is prolly precisely how the machine does it
12:17:26 <ski> and since the `merger' call is incremental, it doesn't have to actually merge the remainder of the two lists
12:17:44 <crucify_me> yeah its already sorted
12:19:10 <ski> however, if you do `take 2 (reverse (2:3:5:7:11:13:17:19:23:29:31:37:41:43:47:[]))', then `reverse' will actually go through the whole list before emitting the first element of the result, for `take' to pick up and return
12:19:20 <ski> so, in this case, the whole of the `reverse' call will have to be done
12:19:35 <crucify_me> right, it is sadly inefficient
12:20:03 <ski> but there's no way around that here. the only way to get the last two elements in a single-linked list is to traverse to the end
12:20:21 <crucify_me> yeah its the nature of the function tis all
12:20:45 <crucify_me> ski just to make sure of something...
12:21:57 <crucify_me> never mind I can add 2 to your example with take..merger  thanks!
12:22:10 <ski> as i said, yea
12:22:39 <crucify_me> I like the notation with 0:take what-have-you
13:37:45 <dsal> Is there a shortcut to implementing a bounded enum?
13:40:08 <mauke> data Boolean = True | False | FileNotFound deriving (Eq, Ord, Enum, Bounded, Show, Read)
13:40:26 <hpc> :D best booleaon
13:40:37 * hpc smoothly pretends that wasn't a typo
13:42:03 <dsal> I just copy and pasted the code from here: http://hackage.haskell.org/package/base-4.10.0.0/docs/Prelude.html#t:Enum
13:43:13 <mauke> what code?
13:45:23 <drdo> So I'm getting undefined references in parsec and text when linking, what are the usual problems?
13:45:43 <drdo> (when building my own project that uses those)
13:45:46 <mauke> what command are you using and what's the error?
13:45:49 <drdo> no cabal, just ghc --make
13:46:01 <mauke> --make is the default
13:46:39 <dsal> "enumFrom and enumFromThen should be defined with an implicit bound, thus"
13:47:04 <dsal> If I don't do that, it just keeps running past maxBound
13:48:34 <drdo> mauke: Sure, but now what? :P
13:50:05 <mauke> now you can tell me what command are you using and what's the error?
13:50:06 <drdo> Hmm, could it be because some FFI parts were compiled with clang instead of gcc?
13:50:22 <mauke> dsal: do what?
13:50:23 <drdo> /usr/lib64/parsec-3.1.11/ghc-8.2.1/libHSparsec-3.1.11-BVmLZs3bAgy82GyAubUNiq_p.a(Prim.p_o):sks7_info: error: undefined reference to 'textzm1zi2zi2zi2zmB3zzsvJlE5vu3r4fNcvu4ZZJ_DataziTextziInternalziFusionziSizze_compareSizze_CgLI_cc'
13:50:25 <mauke> dsal: what are you talking about?
13:50:28 <drdo> And a bunch more similar ones
13:50:50 <mauke> oh, fun
13:51:39 <mauke> I don't know what causes that
13:52:28 <mauke> does 'ghc-pkg check' report anything?
13:52:33 <drdo> nope, all clear
13:53:24 <drdo> recompiled parsec with gcc instead of clang, parsec linking errors are gone
13:53:34 <drdo> text still having problems though
13:53:43 <geekosaur> odd
13:55:08 <geekosaur> hah. you have found a bug in text-1.2.2.2
13:55:27 <drdo> I have?
13:55:31 <geekosaur> Data.Text.Internal.Size is not mentioned in its cabal file
13:55:50 <geekosaur> oh wait, wrong module name, sorry
13:55:56 <geekosaur> .Fusion.Size and it is present. oh well
13:56:15 <drdo> I love mysterious errors when I have stuff to do
13:56:57 <geekosaur> yeh
13:57:04 <joebetz> http://lpaste.net/360130 <-- my attempt to get lambdabot running in a freenode room, which isn't working. do I have to set up an identify before it can actually connect?
13:57:27 <geekosaur> I would probably be looking at the symbols in the text package's library at this point
13:59:58 <geekosaur> joebetz, you need to change the 'lambdabot' in the irc-connect line to something else
14:00:16 <geekosaur> it's the nick to connect as. you will note there is already a 'lambdabot'
14:01:26 <geekosaur> (on freenode)
14:01:42 <joebetz> okay, makes sense
14:01:59 <drdo> ok, found the issue
14:02:04 <drdo> something to do with LTO
14:02:15 <drdo> disabling LTO when compiling parsec and text fixed it
14:02:22 <joebetz> geekosaur: do you know what the userinfo parameter corresponds to?
14:02:43 <geekosaur> it's the user information you can see in a /whois
14:03:47 <geekosaur> back when I ran one, I had info there saying to contact me if the bot was acting up
14:04:08 <joebetz> nice
14:04:49 <joebetz> so I changed the nick, but I'm still getting that "No Ident response" message
14:04:58 <mauke> that's normal
14:04:59 <geekosaur> the information for admin commands is kinda sparse, I had (still a trifle sparse because I didn't want to say too much publicly about them) better info in my help file. which happens to still be online for some reason: https://users.ece.cmu.edu/~allbery/lambdabot/COMMANDS
14:05:09 <joebetz> okay
14:05:25 <joebetz> but I'm not seeing the bot inside the room
14:05:28 <geekosaur> irc servers try to contact an identd for historical reasons. for security reasons, nobody runs identd any more
14:05:48 <mauke> what is the bot called?
14:06:02 <monochrom> I run identd.
14:06:03 <geekosaur> do you have the @join command(s) to enter the room?
14:06:19 <geekosaur> read the admin command section of the help file I linked earlier
14:06:33 <monochrom> But I'm nobody and nobody is perfect and so I'm perfect.
14:06:51 <geekosaur> might help you sort out how to configure your bot. this stuff isn;t documented, you get the example files (which are a little misleading) and otherwise I had to dig through the source and experiment
14:07:01 <joebetz> okay, I'll take a look
14:08:13 <joebetz> I'm not sure which commands I have because @list ircPlugin returns nothing, even though it ircPlugin shows up in @listmodule
14:08:14 <geekosaur> (the non-dmin section is not as helpful, it includes plugins that normal lambdabot doesn;t have and omits several that a Haskell bot would; I was mainly using it in a sysadmin channel)
14:08:36 <geekosaur> right, none of the commands come from the irc module
14:08:46 <joebetz> ah
14:08:52 <geekosaur> it's actually badly misnamed, all the real irc functionality is scattered throughout lambdabot's core :(
14:09:24 <geekosaur> there's like one function in that plugin and it doesnt do very much
14:10:01 <joebetz> mauke: lambdabottest1234321
14:11:12 <geekosaur> that would be truncated to 14 chars
14:11:15 <joebetz> geekosaur: lambdabot> @join irc.freenode.net:#LambdabotTestRoom
14:11:15 <joebetz> [WARNING] : sending message to bogus server: IrcMessage {ircMsgServer = "irc.freenode.net", ircMsgLBName = "urk!<outputmessage>", ircMsgPrefix = "", ircMsgCommand = "JOIN", ircMsgParams = ["#LambdabotTestRoom"]}
14:11:34 <joebetz> and nothing seems to happen
14:11:48 <geekosaur> that is the first parameter you have to @irc-connect ?
14:11:54 <geekosaur> *gave to
14:12:30 <geekosaur> er. what is the first parameter you have to @irc-connect ?
14:12:39 <joebetz> ah,
14:12:45 <joebetz> I think I mixed them up
14:13:01 <joebetz> my first parameter was the channel name
14:13:31 <geekosaur> that error message looks like you got them correct though?
14:13:46 <joebetz> seems so
14:13:57 <joebetz> I was going off of this: https://github.com/lambdabot/lambdabot/blob/master/lambdabot-irc-plugins/src/Lambdabot/Plugin/IRC/IRC.hs#L39
14:15:18 <geekosaur> so the first parameter to @irc-connect is a connection ID. you use that in other commands like @join
14:15:27 <geekosaur> the doc I linked to calls that SERVER
14:15:54 <geekosaur> so I would have @irc-connect freenode irc.freenode.net 6667 ...
14:16:08 <geekosaur> then @join freenode:#LambdabotTestRoom
14:18:49 <joebetz> @irc-connect freenode irc.freenode.net 6667 grebglog09 test
14:18:49 <lambdabot> Not enough privileges
14:18:54 <joebetz> heh
14:19:00 <joebetz> but yeah, that throws the same error :/
14:20:18 <geekosaur> wonder if the connect had actually finished by then. that was another issue I had, had to wait through the whole connect thing including a couple pages of message-of-the-day before it's sufficiently connected to accept join commands
14:20:30 <joebetz> btw, I'm running this in a linux mint VM
14:20:42 <geekosaur> (the server info is not complete until it has received and parsed a bunch of status and config information from the IRC server)
14:21:09 <joebetz> hmm
14:21:15 <geekosaur> ...I don;t know if it still has this problem but back when I ran it, I actually had to 'nurse' it through the connection
14:21:51 <geekosaur> I'd only get those output lines about the identd and then it'd delay a long time and then disconnect. had to keep hitting return to force it to read from the server until the connection was fully established
14:21:59 <geekosaur> after which it would be fine
14:22:01 <joebetz> yeah, actually, it didn't actually return to the lambdabot prompt, so it doesn't seem to have finished
14:23:51 <geekosaur> at this point you probably need someone who's run a lambdabot within the past few years (it's been almost a decade since I was at CMU...)
14:24:08 <joebetz> damn
14:25:10 <joebetz> I know #reflex-frp has one, and that's only been around for a couple of years
14:25:20 <geekosaur> @listchans
14:25:20 <lambdabot> ##categorytheory ##logic ##megaharem ##proggit ##scalaz #agda #archlinux-haskell #aurapm #bfpg #clash-lang #cplusplus.com #csa_uva #darcs #diagrams #esoteric #fedora-haskell #fp@nith #friendly-
14:25:20 <lambdabot> coders #functionaljava #gentoo-haskell #ghc #hackage #happs #haskell #haskell-beginners #haskell-blah #haskell-br #haskell-by #haskell-cn #haskell-fr #haskell-freebsd #haskell-game #haskell-gsoc #
14:25:20 <lambdabot> haskell-id #haskell-in-depth #haskell-infrastructure #haskell-it #haskell-lens #haskell-llvm #haskell-overflow #haskell-pl #haskell-soc #haskell.au #haskell.cz #haskell.de #haskell.dut #haskell.es #
14:25:20 <lambdabot> haskell.fi #haskell.hr #haskell.jp #haskell.no #haskell.ru #haskell.scandinavian #haskell.se #haskell.tw #haskell.vn #haskell_ru #hilbertspace #hledger #learnmath #learnprogramming #ledger #lpmc #lw-
14:25:20 <lambdabot> prog #lysa #macosx #macosxdev #mainehackerclub #nicta-course #numerical-haskell #plaimi #qfpl #reflex-frp #rosettacode #scala #scala.pl #scalaz #scannedinavian #snapframework #sshc #tanuki #the-fort
14:25:22 <lambdabot> #trains #unicycling #vinyl #xmonad #yi
14:25:34 <tsani> unicycling?!
14:25:53 <geekosaur> blame shapr :p
14:26:07 <joebetz> trains too :D
14:27:27 <geekosaur> so you need to find someone running a lambdabot that is not *the* lambdabot :)
14:27:43 <geekosaur> (in theory you could talk to this lb's maintainer, but he's kinda busy)
14:30:06 <joebetz> how does *the* lambdabot get added to new channels? someone just runs @join on whatever server it's running on?
14:30:08 <ph88> what's the go to library for serializing/deserializing xml ?
14:30:24 <geekosaur> its maintainer, yes. then adds the @join to the config file so it'll rejoin when it's restarted
14:30:47 <platz> ph88: well the top two libs on hackage are 'xml' and 'xml-conduit'
14:31:12 <platz> aparrently they aren't C-speed fast, but are used frequently
14:31:40 <joebetz> geekosaur: got it. and yeah, I'll ask around. would be really nice to have for teaching haskell to a friend of mine over chat.
14:38:19 * bigHaskellNoob looks at ski
14:38:52 * ski stares into the abyss
14:39:02 <geekosaur> joebetz, you might consider also using a low volume channel where this lambdabot already lives. #haskell-overflow is usually quiet, for example
14:39:05 * bigHaskellNoob stares back into ski
14:40:00 <geekosaur> or #haskell-in-depth which isn't *quite* appropriate but the channel is pretty much never used these days
14:40:06 * ski smiles unnervingly
14:42:42 <nshepperd> a disconcerting ogle!
14:45:51 <ph88> thx platz 
14:48:00 <joebetz> geekosaur: okay, I'll keep that in mind as a backup. would really prefer something private to start, but that might work, if people don't complain about random lambdabot commands with no acccompanying dialogue :)
14:48:53 <MarcelineVQ> no dialogue?
14:49:27 <joebetz> yeah, because that part I would at least like to keep private
14:50:04 <geekosaur> likely in person...
14:50:45 <MarcelineVQ> in person? does lambdabot not accept input from ghci?
14:50:46 <geekosaur> politeness suggests yiou ask before starting in such channels anyway so you include that you're doing the discussion elsewhere
14:51:01 <joebetz> yeah, that's fair
14:51:14 <geekosaur> there is goa but it's a fragile hack and I bet the 8.x changes broke it
14:52:22 <tabemann> I have a very stupid, non-haskell-related question
14:52:31 <tabemann> what are these [m]s after people's nicks?
14:52:39 <astronavt> they're logged in through matrix.org
14:52:51 <astronavt> there's a relay between matrix and freenode
14:52:52 <geekosaur> that's the default nick for someone on matrix, yeh
14:53:32 <platz> they're a bit brand/marketing heavy
14:54:02 <MarcelineVQ> also commonly through riot.im which I thiiink is a frontend for matrix
14:54:11 <astronavt> yes
14:54:56 <astronavt> riot is the official desktop client, but theres also a weechat plugin, some webclients, and mobile clients
14:56:17 <astronavt> how hard is it to call haskell from c? for a) an experienced programmer, and b) for someone who is a novice in both languages
14:56:37 <koz_> Something something inline-c.
14:56:48 <geekosaur> other way around, koz_
14:56:53 <platz> haskell *from* c is kind of a weird use-case
14:57:21 <tabemann> it isn't difficult to call C from haskell, but I have no clue as to how one would call haskell from C
14:57:21 <koz_> geekosaur: I guess my mind filled in the more common use-case.
14:57:25 <MarcelineVQ> not that weird from the frequency it comes up
14:57:31 <geekosaur> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ffi-chap.html#making-a-haskell-library-that-can-be-called-from-foreign-code
14:57:35 <astronavt> i did see that
14:57:43 <geekosaur> it's a bit involved
14:57:54 <astronavt> i want to patch ctags to use pandoc for parsing asciidoc, rst, and md
14:58:02 <astronavt> not to mention html and latex
14:58:03 <Eduard_Munteanu> Note you can call Haskell from C from Haskell.
14:58:29 <alp> 'foreign export' is quite reasonable
14:58:40 <alp> sparkle uses that, for instance
14:58:44 <platz> also this old post https://wiki.haskell.org/Calling_Haskell_from_C
15:00:05 <astronavt> it looks like its literally using GHC to generate C code and then using GHC again to compile its own generated code
15:00:31 <Eduard_Munteanu> So whenever you need to call Haskell from C, you could just have Haskell code call into C code and set up proper callbacks.
15:00:36 <platz> not at runtime though
15:01:05 <astronavt> Eduard_Munteanu: that is well beyond me
15:01:53 <geekosaur> for use from something like ctags, you jsut want the haskell-library-from-C version
15:02:02 <geekosaur> nto the fancy callback stuff
15:02:08 <Eduard_Munteanu> astronavt, it's not that uncommon, many C libraries take callbacks for various purposes, and if you call them you can supply Haskell code to be ran.
15:02:24 <astronavt> right that does make sense
15:03:43 <merijn> platz: Not at runtime what?
15:04:04 <platz> "generate C code and 
15:04:05 <platz>             then using GHC again to compile its own generated code"
15:04:30 <merijn> hmmm, I missed the contexts of what we're trying to achieve
15:05:07 <merijn> astronavt: If you're familiar with C, then calling C from Haskell (or vice versa) is relatively simple
15:05:37 <geekosaur> [18 22:57:32] <astronavt> i want to patch ctags to use pandoc for parsing asciidoc, rst, and md
15:05:57 <Eduard_Munteanu> For ctags, you could even provide a separate ctags-haskell binary and have ctags invoke it with arguments.
15:06:04 <astronavt> oh really?
15:06:10 <astronavt> ctags can call external programs?
15:06:34 <Eduard_Munteanu> No reason why not.
15:06:35 <geekosaur> tbh I would almost think it easier to provide a ctags output format in pandoc
15:06:53 <astronavt> geekosaur that's a good point
15:07:08 <Eduard_Munteanu> Yeah, that would be a good first step, actually.
15:07:14 <astronavt> it'd be cool if the universal-ctags guys were thinking about making a "libctags" for manipulating tag files
15:07:32 <astronavt> give me a nice consistent C api that i can wrap in python, haskell, whatever
15:07:36 <Eduard_Munteanu> Indeed.
15:09:08 <Eduard_Munteanu> I think it's kinda sad that in 2017-2018 we still don't call a proper compiler for tag generation.
15:09:27 <astronavt> agreed
15:09:43 <astronavt> so much great code-parsing code is locked away in proprietary IDEs
15:10:05 <michalrus> Wouldn‚Äôt it be safer for `execWriterT` to be `WriterT w m () -> m w` instead of `WriterT w m a -> m w`? The current signature allows swallowing values. :C
15:10:31 <astronavt> i'd do some dirty things if it meant jetbrains would open-source pycharm's intelli-code-whatever algorithms
15:11:07 <platz> I'm not sure IDE's acutally produce tag files as opposed to in-memory data structures though
15:11:22 <astronavt> oh no, but its lightning fast and handles huge projects
15:11:33 <geekosaur> thats kinda the point, no? they want to use the parsing part and replace the IDE's native output with a tags writer
15:11:47 <astronavt> plus theres nothing wrong with a little sqlite
15:13:53 <Gurkenglas> michalrus, don't forget forever and (>>)
15:14:13 <michalrus> Yes, huh.
15:14:18 <michalrus> :(
15:28:42 <joebetz> theoretical question: are there separate names for types that are sums of values (like Boolean), and types that are sums of other types (like Either)? or are those both just called sum types?
15:29:53 <nshepperd> enumeration?
15:31:16 <geekosaur> that's more a practical one than a theoretical one, I think? there's not much difference from a theoretical standpoint, I think. unless you want to talk about parameterized types; there's a missing case in that distinction
15:31:28 <geekosaur> (consider data Foo = Nope | Yup Int)
15:33:56 <joebetz> good point
15:35:17 <joebetz> saying it's a sum of values unifies all three, since types are just sets of values. so I suppose that would be the most general definition.
15:38:35 <pierrot> Hi. Given a string (that contains a extremely simplified html), I need to count its number of <br> and <li> tags. How could I do that?
15:38:40 <astronavt> Maybe a = Nothing | Just a
15:38:50 <astronavt> there's your edge case right there
15:43:11 <merijn> pierrot: Grab a HTML parser and use whatever API that has for counting tags?
15:44:22 <Eduard_Munteanu> pierrot, you can try tagsoup. Of course, you could just do string manipulation, but that's less reliable.
15:45:22 <joebetz> astronavt: hmmm
15:53:55 <pierrot> merijn and Eduard_Munteanu : it's for an exercise. This one: https://i.imgur.com/FcnDtiV.png I've done a) and b) and here's my code: https://glot.io/snippets/evmednx9rv
15:54:34 <pierrot> for the shallow embedded DSL, I implement it simply as a string
15:55:04 <koz_> Could someone please let me know what's wrong here? I don't even understand what the error messages are saying: http://lpaste.net/360131
15:55:34 <pierrot> so now I need to count <br> and <li> tags in a string
15:55:51 <pierrot> hmm or maybe change the implementation, I'm not sure
15:56:13 <Eduard_Munteanu> pierrot, well you don't need to parse, you already have the structure there in the DSL.
15:56:38 <pierrot> Eduard_Munteanu: yeah, but for the deep embedded DSL
15:56:52 <pierrot> I need to count lines in the shallow embedded DSL too
15:57:27 <pierrot> for the deep embedded DSL, it's easy, because I have the AST
16:03:59 <Eduard_Munteanu> pierrot, well, if you're using Text, it has a count function.
16:04:06 <Eduard_Munteanu> :t Data.Text.count
16:04:07 <lambdabot> Data.Text.Internal.Text -> Data.Text.Internal.Text -> Int
16:06:03 <pierrot> I'm using String
16:06:05 <Eduard_Munteanu> > count "<br>" "foo<br>bar<br>baz"
16:06:07 <lambdabot>  error:
16:06:07 <lambdabot>      ‚Ä¢ Variable not in scope: count :: [Char] -> [Char] -> t
16:06:07 <lambdabot>      ‚Ä¢ Perhaps you meant one of these:
16:08:16 <Eduard_Munteanu> pierrot, you can do it yourself, I suggest using stripPrefix
16:08:35 <Eduard_Munteanu> > stripPrefix "<br>hi"
16:08:37 <Eduard_Munteanu> Er.
16:08:37 <lambdabot>  <[Char] -> Maybe [Char]>
16:08:46 <Eduard_Munteanu> > stripPrefix "<br>" "<br>hi"
16:08:48 <lambdabot>  Just "hi"
16:08:59 <Eduard_Munteanu> > stripPrefix "<br>" "a<br>hi"
16:09:01 <lambdabot>  Nothing
16:09:07 <pierrot> hmm that's nice
16:13:18 <CodeWeaver> Once again I find myself baffled by behaviour I thought I understood, and I come humbly asking for the mental might of the channel. :)
16:14:02 <CodeWeaver> I was exploring GHC 8.0.2 in interpreted mode.  in the REPL I gave
16:14:22 <pierrot> oh, maybe I could also change the representation... Instead of `type SMarkup = String' I could define `type SMarkup = (Int,String)' where the first element in that pair is the number of lines
16:14:41 <CodeWeaver> I gave:  let f _ = (last xs,head zss)  where (xs,zss) = splitAt 1000000000 (bigList 1000000000)
16:15:31 <CodeWeaver> biglist just builds a big list using a concat of just increasing integers, capped with -1 at the end.
16:17:45 <geekosaur> ,,,and?
16:17:48 <CodeWeaver> The odd thing was, I got the expected delay on printing the tail of the big first part of the list.... and an expected delay on printing the head of the remainder of the list...  but between the two, my memory usage didn't increase.  Its as if the two parts fully evaluate different thunks.  But the code showing via hackage doesn't illuminate to me why there shoudl be both a delay but no memory usage.
16:19:39 <hpc> you have 3 lists of importance
16:19:42 <CodeWeaver> The classic definition for splitAt would suggest between the two the head of the whole list would result in holding on to the whole list between the two.
16:19:44 <CodeWeaver> Sure.
16:19:48 <hpc> biglist, the right split, and the left split
16:19:49 * CodeWeaver listens
16:20:09 <hpc> lists are structured like x:(y:(zs)), with the tail of a list being another list
16:20:19 <hpc> so the right split can be just part of that same original biglist
16:20:32 <hpc> the left split can't work the same way
16:20:33 <CodeWeaver> Okay so far.
16:20:47 <CodeWeaver> Agreed, no problem so far.
16:21:03 <hpc> so when you evaluate the left split, no evaluation happens on the right split
16:21:11 <hpc> when you evaluate the right split, it evaluates the start of biglist as well
16:21:20 <CodeWeaver> Sure.  Also agreed.
16:21:21 <hpc> which contains the same data as the left split, but a copy of it
16:21:27 <hpc> so you get that evaluation twice
16:21:29 <CodeWeaver> Wait, why a _copy_?
16:21:43 <hpc> because in say, x:(y:zs)
16:21:46 <CodeWeaver> See that's the thing... I would have expected leftSplit and rightSPlit to be starting from the same bigList thunk
16:21:52 <hpc> the right split can just be zs
16:22:02 <hpc> the left split is x:y:[]
16:22:17 <hpc> but y:[] is different from y:zs so you have to construct a different cons cell
16:22:42 <hpc> and the outer cons cell, x:(y:[]) refers to a different tail than x:(y:zs)
16:23:10 <CodeWeaver> Okay, but in building the left thunk,isn't the spine of the bigthunk list being expanded out?
16:23:27 <CodeWeaver> Errr biglist
16:23:57 <hpc> oh yeah, hmm
16:24:22 <CodeWeaver> THen the right list gets built, and at least part of the biglist should be already evaluated... which is fine, that explains the delay.
16:24:33 <CodeWeaver> But it doesn't explain the lack of memory usage just before that happens.
16:25:23 <hpc> the parts of the list that aren't being used can be discarded immediately
16:25:53 <CodeWeaver> But until the right half is started to be evaluated, presumably the first major chunk of the biglist _is_ in use -- by the unevaluated right list, no?
16:26:21 <CodeWeaver> The entire billion element prefix, in principle.
16:26:32 <hpc> so going back to that example list, say we do something that needs us to get at zs, but we don't need anything before that
16:26:51 <joebetz> geekosaur: got my lambdabot working! basically just let it sit for a while, hit enter, then ran the join command.
16:26:54 <hpc> so you compute the first cons cell, and have <thunk of x> : <thunk of y:zs>
16:26:58 <hpc> you can drop that first thunk
16:27:06 <hpc> and you don't need the cons cell either
16:27:16 <joebetz> however, all > commands respond with Terminated
16:27:18 <geekosaur> joebetz, that makes sense. in fact I suggested it earlier
16:27:31 <hpc> so you've done a bit of computation, and now you continue crunching on <thunk of y> : <thunk of zs>
16:27:40 <hpc> do the same dropping again, now you have <thunk of zs>
16:27:49 <hpc> which you can evaluate or pass along to other functions as you need
16:27:54 <geekosaur> (I mentioned that you might have to wait for it to receive and process all the server connection messages)
16:28:05 <CodeWeaver> But if that's true, why does it take any time at all to get the head of the right hand half unless it has to walk through x and y again?
16:28:23 <koz_> I'm genuinely confused with this code, and ST stuff generally. If someone could take a look and help me understand better, I would be very grateful: http://lpaste.net/360132
16:31:14 * CodeWeaver scratches chin
16:31:16 <joebetz> geekosaur: right. nothing was printed to the terminal in the hour or so I let it sit, but I guess it was doing something ...
16:31:20 <hpc> yeah, not sure
16:31:40 <CodeWeaver> Okay, well, at the very least we both agree that's odd.  That's something. :)
16:31:50 <monochrom> I'm pretty sure Data.Permute.ST adds one more layer of complexity than vanilla ST.
16:31:51 <geekosaur> joebetz, idling likely, quietly responding to server are-you-there messages, otherwise waiting to be told what to do
16:32:08 <joebetz> gotcha
16:32:14 <koz_> monochrom: So you suggest I just use runST instead of runSTPermute?
16:32:41 <hpc> CodeWeaver: someone who is better at practical profiling will have to chime in i think
16:32:51 <geekosaur> hpc, CodeWeaver, seems to me this is just that it had to compute it twice, because f having a paraeter prevents memoizing. so computed once and allocated memory, then gc-d iot, then the second recomputes reusing the original memory
16:33:12 <monochrom> Yes and more.
16:33:24 <joebetz> geekosaur: so, I installed it on a VM that literally nothing else haskell-related on it. so basically just `cabal install lambdabot`. is there anything else I need to get it working?
16:33:25 <CodeWeaver> Sure, and to be fair, this is behaviour ad-hoc examined in the interpreter... but a billion elements should show up in a pretty gross memory usage measurement via my OS...and the delay is palpable... very peculliar
16:33:30 <koz_> monochrom: What do you mean by that?
16:33:39 <hpc> geekosaur: ah maybe, depending on how f gets called
16:33:55 <CodeWeaver> I called it as:  f 0
16:33:59 <monochrom> At this point it's analogous to "I haven't figured out adding numbers but I'm doing multiplication exercises".
16:34:04 <geekosaur> joebetz, you did get the message from the one plugin saying you needed to install an external utility (djinn iirc?)
16:34:09 <hpc> if you're doing something like print (fst (f 0)) >> print (snd (f 0)), you'll get recomputation
16:34:12 <joebetz> ah, yes I did
16:34:13 <CodeWeaver> Note that memoization should still happen inside, yes? 
16:34:25 <geekosaur> but you're not savbing the inside
16:34:28 <CodeWeaver> I"m not calling f0 twice.  That woudl be fair.
16:34:39 <geekosaur> oh, hm
16:34:40 <CodeWeaver> f is only called once as :  f 0
16:34:58 <CodeWeaver> Inside that, the left and right hand bits should share whatever the internals of splitAt say can be shared.
16:35:01 <hpc> yeah, let (a, b) = f 0 wouldn't do recomputation afaik
16:35:04 <CodeWeaver> Or I would have guessed that.
16:35:13 * CodeWeaver confused.
16:35:26 <CodeWeaver> Example:
16:35:41 <CodeWeaver> No, no example.  I mean, just f 0.  Returning the tuple.
16:35:43 <CodeWeaver> In the editor.
16:36:03 <koz_> monochrom: I appreciate the fact I don't understand, but ultimately, that's why I asked. I don't even get where I'm going wrong here.
16:36:16 <CodeWeaver> Takes a while, prints the tail o the left. Takes a while, prints the head of the right.  No memory usage of significance.
16:36:27 <geekosaur> laziness? just returning the tuple only computes enough to get to that point; inspecting either element of it does more computation
16:36:33 <monochrom> "(a,b) = f 0" is equivalent to "a = fst x; b = snd x; x = f 0"
16:37:20 <CodeWeaver> Okay, but on evaluating x as a thunk, it should be whatever's inside f 0, yes?  In that example, f0 is still only evaluated once as a function call?
16:37:41 <monochrom> Yes.
16:37:53 <monochrom> Also I need to weaken my "equivalent".
16:37:57 <CodeWeaver> In which case, any sharing of data shoudl be internal to the splitAt still.
16:38:05 <CodeWeaver> And I still have my mystery I think.
16:38:25 <monochrom> my "equivalent" is only true of the dynamic semantics (evaluation), not of the static semantics (types)
16:38:32 <CodeWeaver> hm.
16:39:01 <CodeWeaver> I mean the classic splitAt n xs = (take n xs, drop n xs)
16:39:16 <monochrom> Type-checking treats it as "a = fst (f 0); b = snd (f 0)". In case "f 0" is polymorphic, this matters.
16:39:23 <CodeWeaver> and in that you can see the sharing.  The actual implementation is more complicated, but I can't see how I would get both no memory usage, but delay in printing the head of the right.
16:39:33 <CodeWeaver> ....
16:39:38 <geekosaur> koz_, the result of newCopyPermute is an ST s (STPermute s), but the result of freeze on that is ST s Permute
16:39:56 <geekosaur> if I understand this properly
16:39:58 <koz_> geekosaur: So what should I do to 'conclude' the operation?
16:40:09 <koz_> If anything.
16:40:19 <CodeWeaver> I agree that's what it would look at from a type point of view, but would it really evaluate twice?  The original you posted suggested x would be a common subexpression from the point of vew of evaluation.
16:40:21 <geekosaur> so you declared it as returning the un-frozen one, but you do need to freeze it before exiting ST
16:40:45 <monochrom> It won't be evaluated twice.
16:40:52 <CodeWeaver> Oh good.
16:40:58 <geekosaur> the STPermute version can only exist inside of ST; so your result type wants to be ST s Permute
16:41:00 <CodeWeaver> Well at least that bit makes sense.
16:41:17 <CodeWeaver> But then we're back to why I'm using no memory but taking piles of time to print the head of the right.
16:41:34 <CodeWeaver> I wonder what I can do tracewise or profile wise to find out why this happens.
16:41:39 <hpc> monochrom: polymorphism is a good theory
16:42:01 <CodeWeaver> I... guess I don't get how....'polymorphism'.... explains this.  I'm missing something.
16:42:24 <geekosaur> koz_, that is, I think you wanted theNeedful :: ST s Permute
16:43:14 <koz_> geekosaur: OK, I've modified it, but I still have the error around newCopyPermute
16:43:20 <hpc> CodeWeaver: once polymorphism gets involved, you lose a guarantee that's required to reuse the computation
16:43:34 <koz_> Let me re-paste what I hav enow.
16:43:41 <geekosaur> joebetz, also note that once the bot is up and running on IRC, I don't think you get the console working right any more; you'd need to feed it the @offline command from IRC
16:43:59 <geekosaur> at least that's how it used to work; I think they tried to change that but failed, and you may be seeing a side effect of that
16:44:01 <hpc> an example of where it falls apart is if you need it to produce Int values, and later Double values
16:44:02 <joebetz> geekosaur: installed djinn and that message went away, but all @run commands are still returning Terminated
16:44:16 <hpc> CodeWeaver: what's the type of f?
16:44:17 <joebetz> okay, good to know
16:44:44 <geekosaur> joebetz, you mays till be missing something. iirc @run relies on a mueval executable to build and run stuff?
16:44:49 <koz_> geekosaur: OK, edited now: http://lpaste.net/360132
16:44:55 <koz_> What's the issue here?
16:45:09 <monochrom> I skip tracing and profiling. I read Core directly.
16:46:34 <CodeWeaver> hpc:  I see, yes, the first parameter is an unspecified type even though I'm not using it.  But if I'm really actually only calling it once, how would that change how f uses splitAt?  SHoulldn't it be splitAt that shares or doesn't share memory?  And the code for splitAt wouldnt' be affected by how f is defined, yes?
16:47:20 <CodeWeaver> Good test for me:  Define all the types more concretely to see what happens.
16:48:25 <geekosaur> koz_, oh, I see now. I think you go back to the old signature and the use of runSTPermute, and return p instead of using freeze on it. (runSTPermute does that, since it takes an STPermute s and gives you back a Permute)
16:48:57 <geekosaur> ...and just verified that last looking at its source
16:49:18 <joebetz> geekosaur: installed mueval, and now I'm getting this from @run commands: mueval-core: GhcException "cannot satisfy -package lambdabot\n    (use -v f...
16:49:38 <geekosaur> did you build this in a sandbox?
16:50:22 <geekosaur> mueval seems to not be in that same sandbox, or at least not be running within it. you may need to run lambdabot via the sandbox (e.g. stack exec lambdabot or cabal exec lambdabot)
16:50:55 <Henson> hi all.  Does anybody know if there's a way to tell Haskell about memory that's allocated in a foreign language.  If I allocate 5 MB of data in a C call and pass a ForeignPtr to that aroun Haskell with a finalizer, Haskell doesn't know about the allocated memory.  I have a case where I think the garbage collector isn't deallocating unused ForeignPtrs quickly enough because it doesn't know...
16:50:58 <koz_> geekosaur: Still erroring in a very similar way: http://lpaste.net/360132
16:51:21 <geekosaur> joebetz, unfortunately I am less familiar with @run/mueval, I ripped that out of the lambdabot I ran
16:51:43 <CodeWeaver> Holy haleakala, sudden major memory usage.  You guys are goooooood.  I'm not sure I entirely understand when this situation kicks in though and this bothers me greatly in terms of my understanding when things may or may not get re-evaluated.
16:52:08 <Henson> they're really pointing to megs of data each, which is quickly filling up the memory of my computer.  Someone a few days ago suggested a Storable instance might be appropriate, but I can't figure out how.  My only idea is to export a Haskell function to C that takes a StablePtr and allows a call to Haskell to be made from within C that allocates Haskell memory, passes it as a pointer to C for...
16:52:51 <CodeWeaver> My thanks. I have something new to explore.
16:53:18 <geekosaur> koz_, sigh. looks like you get a St s Permute from newCopyPermute, that is it's generated frozen and you need to thaw it before changing it
16:53:22 <Henson> use there, and then allows Haskell to get that ForeignPtr when the C call finished.  Kind of a lot of work when some kind of garbage collector hint would do the job.
16:53:31 <geekosaur> I had misread it at first and thought it was giving you the mutable one
16:53:37 <koz_> geekosaur: Oh, so that's what it was... I misread it in the same way.
16:53:49 <koz_> So it should be p <- thaw . newCopyPermute $ p1 ?
16:54:19 <geekosaur> fmap thaw
16:55:14 <joebetz> geekosaur: not using a sandbox, no. and I got the same error even when I ran it using cabal exec lambdabot.
16:55:21 <koz_> geekosaur: So it should read p <- map thaw (newCopyPermute p1) ?
16:55:30 <__Lorn__> 5hello
16:55:43 <geekosaur> koz_, fmap instead of map, but I think yes
16:57:03 <geekosaur> joebetz, I'm out of my depth then. maybe mueval is using a different ghc somehow. this sounds like a package database mismatch from what mueval is using and where lambdabot was installed, but there are too many possibilities there :(
16:57:10 <koz_> geekosaur: Still unhappy, although for seemingly-different reasons.
16:57:13 <koz_> geekosaur: http://lpaste.net/360132
16:57:18 <CodeWeaver> hpc, monochrom:  One last thing... is there somewhere I could read up on how polymorphism can impact that kind of sharing or thunk re-use?  I'd like to get a handle on it.
16:57:48 <hpc> i don't know of any central resource, but maybe look for the motivations behind the monomorphism restriction
16:57:56 * geekosaur goes to look at thaw again
16:57:59 <CodeWeaver> Right.  That's a good term to search for.  Thanks.
16:58:02 <hpc> (which helps with this sort of thing, but not without drawbacks of its own)
16:58:17 <geekosaur> oh.
16:58:31 <geekosaur> no fmap and no composition. I thought that seemed slightly odd.
16:59:15 <geekosaur> if you want to combine it in that one expression then I think you want: newCopyPermute p >>= thaw
17:00:00 <geekosaur> (seemed a bit strange that it looked pure at first, if it's generating a mutable thing it should be in ST...)
17:01:00 * geekosaur is ... not sharp enough today. fronts moving through messing with head, sigh
17:02:58 <joebetz> geekosaur: okay. appreciate the help. I'll play around with it some more tomorrow, and let you know if I can get it to work.
17:06:13 <geekosaur> joebetz, in any case I would look for extra copies of ghc on the system, and/or make sure the lambdabot and mueval packages are both installed in the same place
17:06:37 <geekosaur> (the *packages*, not the executables)
17:11:57 <CodeWeaver> Oh wow, that's a fascinatingly subtle thing, that monomorphism impact on my little puzzle.  <totallynerdsniped>
17:15:50 <koz_> geekosaur: So the first line should be 'p <- newCopyPermute p1 >>= thaw' ?
17:17:54 <geekosaur> koz_, I think so
17:18:06 <koz_> That still errors. Let me update with what it says.
17:18:16 <koz_> (thank you for all your help - I have no clue wth is up with it)
17:18:40 <Welkin> better yet, flip the >>= ot =<<
17:18:42 <Welkin> to*
17:19:23 <dsal> heh, flip the ot
17:19:48 <koz_> geekosaur: http://lpaste.net/360132 <-- with the new errors
17:20:43 <geekosaur> I'm running short of clue as well
17:21:40 <geekosaur> sigh, it doesn't think that's in the same ST for some reason
17:21:45 <geekosaur> I have no idea at this point
17:21:59 <geekosaur> and I am noit in a position toinstall all this stuff and experiment locally
17:22:05 <koz_> geekosaur: Thanks for your help anyway - I'm just (if not more) baffled than you are.
17:22:13 <koz_> s/just/just as/
17:23:26 <koz_> geekosaur: Apparently, it wanted 'p <- thaw p1; p' <- newCopyPermute p'.
17:23:56 <geekosaur> hm
17:25:00 <malaclyps> so I wanted to use a library on hackage that appears to be a bit out of date -- stack is complaining that it can't resolve the dependencies, and it looks like it's because it's expecting old versions of libraries
17:25:34 <malaclyps> I'd like to have a bash at updating it to newer dependencies, but not sure how to do that. ( The package is https://hackage.haskell.org/package/beeminder-api-1.0 )
17:25:35 <geekosaur> you'd need to tell stack to use an older resolver. stack solver might hlp
17:25:42 <malaclyps> ah
17:25:56 <malaclyps> is that more sensible than bringing it up to date with a new resolver?
17:26:25 <geekosaur> it could well be. I don't know this package to know how hard it would be to use it with newer deps
17:26:45 <c_wraith> It's not that old.  late update was in June
17:27:03 <Welkin> sometimes it's as simple as bumping the upper limit on some dependencies
17:27:14 <geekosaur> there's also --allow-newer=pkgname
17:27:31 <geekosaur> which would let you try it with newer versions and then adjust the deps as things are found to work
17:27:32 <malaclyps> geekosaur, where would i use that option?
17:27:44 <geekosaur> in stack build
17:28:34 <malaclyps> like "stack build --allow-newer=beeminder-api"?
17:29:44 <geekosaur> you apply that to the dependencies that are old
17:29:53 <geekosaur> not to beeminder-api
17:31:36 <mud> malaclyps: In a more ... permanent way, eventually, you'll probably want to do something like 'stack unpack beeminder-api' to get a local copy you can mess with, and change your stack.yaml to use your local one instead of the one it'll try to get from hackage. If you didn't already know. Or maybe there's a way to permanently-ish set that flag in stack.yaml, assuming it works? I forget.
17:32:19 <geekosaur> I would use allow-newer only to find out what deps can be slipped, and then edit an unpacked copy to adjust them
17:32:31 <geekosaur> and submit a request to hackage for the deps to be adjusted there
17:33:08 <geekosaur> anyway it looks like the big one is base dep excludes ghc 8.2, so if you have ghc 8.2.1 then start with --allow-newer=base
17:33:26 <Welkin> I used to fork packages and point to a git repo (or a local package) after adjusting dependencies
17:33:43 <Welkin> it's even better to have the author update it though
17:34:40 <geekosaur> you may need to adjust a few others as well
17:35:05 <CodeWeaver> hpc:  Interestingly subtle.  The type of f doesn't matter.  It's the type of the bigList function that does... specifically its input parameter for size being non-polymorphic.  The type of the elements don't matter.  
17:38:47 <fredfoobar> testing
17:38:47 <fredfoobar> testomg
17:39:06 <fredfoobar> testing
17:39:15 <fredfoobar> tabemann
17:39:19 <nshepper1> CodeWeaver: if you know of the dictionary transformation, a value of type 'SomeConstraints x => t' is actually a function that takes a dictionary for those constraints and produces a t
17:39:19 <fredfoobar> testing
17:40:04 <nshepper1> So the t can't be shared between uses
17:40:44 <nshepper1> Not without adding some explicit code to memoize that function
17:41:06 <CodeWeaver> nshepper1:  I'm not familiar with that, actually, so I will attempt to use that as a research point.
17:42:16 <CodeWeaver> nshepper1:  I suppose I'm surprised that, once a specific usage is bound to a varlable, like x = bigLIst 1000 in my example, and x is used in several separate computations, that it should matter whether bigList is polymorphic... it's the same value.
17:42:36 <geekosaur> functions are values :)
17:43:00 <geekosaur> just binding something doesn't automatically fix its type, at least not in ghci (which disables the monomorphism restriction by default)
17:43:11 <CodeWeaver> That may be part of it.
17:43:12 <Welkin> functions are people, too!
17:43:31 <CodeWeaver> I mean in my head, my misunderstanding about ghci's policy there.
17:43:39 <Welkin> ghci is weird
17:43:49 <Welkin> always test by compiling and running, never in ghci
17:43:58 <CodeWeaver> Sure, sure, I'm on board with that.
17:44:01 <geekosaur> laziness and polymorphism interact in "fun" ways
17:44:04 <CodeWeaver> This is about understanding why I saw what I saw.
17:44:15 <CodeWeaver> I'm getting a handle on that.
17:45:32 <nshepper1> I wonder if maybe turning off MR in ghci was a mistake. The difference seems to confuse people frequently
17:46:27 <CodeWeaver> I am a little shocked the rules are different. 
17:47:28 <geekosaur> well, the rules are different anyway
17:47:30 <CodeWeaver> I mean it didn't give me a different _result_ of course... but it does mean I have to be careful about trusting what I see in GHCI as an example of how thunks and memoization work.
17:47:35 <CodeWeaver> Yah, maybe so.
17:48:03 <geekosaur> if the MMR is on then ghci is *more* restrictive than a program, because the program can solve the monomorphic type based on a later usage whereas ghci has to decide it immediately because itneeds a type *now* and can't know what you'll type next
17:48:43 <CodeWeaver> Hmmmm interesting, that.
17:48:53 <Welkin> CodeWeaver: see this book for a good explanation of how lazy evaluation works in haskell http://chimera.labs.oreilly.com/books/1230000000929/ch02.html#sec_par-eval-whnf
17:49:01 <CodeWeaver> I really have to visit here more often.  I learn loads, way faster. :P
17:49:08 <nshepper1> Oh yeah that's true
17:49:09 <CodeWeaver> Ooh, thanks.
17:49:49 <CodeWeaver> I mean, its not like i haven't exploited haskell's lazy evaluation before, and written more elaborate programs than just that code snippet.  But that particular result surprised me.
17:50:08 <CodeWeaver> WHich makes me want to go back to my old code and see if I made unreasonable assumptions.
18:07:22 <benana> setdefault
18:10:28 <koz_> How can I read what Core my Haskell compiles into?
18:11:31 <geekosaur> ghc-core package is helpful in taking the raw compiler output (ghc ... -ddump-ds), removing a lot of mostly unneeded internal detail, and colorizing it for readability
18:12:12 <MarcelineVQ> ^ that sounds like a good idea. I usually use -dsuppress-all -ddump-to-file -ddump-prep -fforce-recomp
18:12:39 <koz_> geekosaur: Is it possible to do this with Stack? My code is a Stack project.
18:13:02 <geekosaur> running it with stack exec, it should be
18:13:23 <koz_> So 'stack exec ghc -- src/Whatever.hs -ddump-ds' ?
18:14:08 <geekosaur> I' add at least -dsuppress-all to that and probably -fforce-recomp, but yes
18:14:19 <geekosaur> or use ghc-core that way instead of ghc directly
18:14:26 <MarcelineVQ> ds is not sufficient to view optimized core is it?
18:14:27 <geekosaur> *I'd add
18:14:49 <koz_> geekosaur: So I should stack install ghc-core first?
18:15:06 <geekosaur> I would not do 'stack ghc' shiurtcut though as it might add its -ddump-to-file (it captures some stuff for its own use)
18:15:11 <geekosaur> yes
18:16:39 <geekosaur> hm. I understood ds to be the closest to the actual final core, with prep being an earlier (possibly pre-optimization) stage?
18:17:00 <MarcelineVQ> ah no that's simpl and prep
18:17:13 <MarcelineVQ> but it's worth checking in case I'm wrong
18:17:16 <koz_> geekosaur: So I assume after I install it, it's just 'stack exec ghc-core -- src/Whatever.hs'?
18:17:30 <geekosaur> koz_, yes, maybe with some pager options
18:17:34 <MarcelineVQ> simpl is the simplifier passes and prep is everything ready for going to stg
18:17:39 <koz_> geekosaur: OK, thanks.
18:18:13 <koz_> Argh, it doesn't seem to like default extensions from the cabal file, argh.
18:18:25 <MarcelineVQ> -ddump-to-file (which stack has on by default I believe) will place dump files deep within your .stack-work/ dir
18:18:43 <MarcelineVQ> you'll want to run like,    find .stack-work/ -iname "*dump*"  to find them easiest prob
18:19:09 <geekosaur> nut it shouldn't be able to apply that to the ghc invocation used by ghc-core
18:19:20 <geekosaur> that was why I warned against using the 'stack ghc' shortcut earlier
18:19:38 <Welkin> nut it?
18:19:47 <geekosaur> "but it"
18:20:12 * geekosaur is captain typo, you might have noticed...
18:22:31 <MarcelineVQ> ggVGc: uhm heh, appearantly stack has --skip now. at least in my version, check if your does,     stack test --skip myexecutablesname   will not build the exe
19:07:07 <ggVGc> MarcelineVQ: still not as good as the flag though, imo
19:38:51 <codeshot> How do you write the show instance for:
19:38:52 <codeshot> data Fixed (t :: (* -> *) -> * -> *) a
19:38:52 <codeshot>   = Fixed {spool :: t (Fixed t) a}
19:38:52 <codeshot> I can't figure out the constraints, unless it's always undecidable
19:38:52 <codeshot> I'm guessing undecidable
20:14:30 <suzu> that is making my brain melt trying to understand it
20:21:31 <d-fish> The cryptonite documentation (https://github.com/haskell-crypto/cryptonite) keeps mentioning "use higher level apis", but it never says wht those are. State of the haskell ecosystem doesn't mention cryptogrophy. What are the crypography libraries of Haskell? I'm looking to use AES
20:22:59 <merijn> d-fish: Any specific reason for AES?
20:23:21 <d-fish> https://cryptopals.com/sets/1/challenges/7
20:23:27 <d-fish> Practicing
20:23:33 <merijn> Because there was a library wrapping NaCl, iirc
20:24:06 <merijn> d-fish: You can use it for this sorta thing
20:24:37 <geekosaur> http://packdeps.haskellers.com/reverse/cryptonite might provide some clues as to higher level packages
20:24:40 <merijn> d-fish: That "higher level API" thing is just saying "cryptonite makes no attempt to stop you from cryptographically shooting yourself in the foot"
20:25:00 <merijn> d-fish: i.e. "don't write your own homegrown custom crypto in production with this"
20:25:17 <merijn> d-fish: If you're doing crypto-attack challenges, it should be fine
20:26:36 <geekosaur> https://github.com/Risto-Stevcev/haskell-crypto-simple#readme jumps out btw
20:27:43 <d-fish> Thanks! That's a lot of info. 
20:33:16 <dsal> Can I have non-haskell "source" files as part of a stack build?  e.g., I've got a text file I'd like to keep as close to its source as possible and then parse it as part of the library initialization.
20:34:36 <lyxia> dsal: there is a section in .cabal files for that
20:35:24 <dsal> What does it do at a high level?  Ideally, I'd like the library build to fail on a parser error.  It's sort of source code, but more of a lookup table.
20:35:50 <dsal> I did it in go by just shoving the whole file into a string in source and parsing it from within.  It mostly worked OK.
20:38:05 <lyxia> extra-source-file just makes stack or cabal track additional file to package up. You might want to change the build-type if you want to do anything more.
20:38:47 <dsal> Ah.  Yeah, I don't want an IO dependency.
20:41:49 <geekosaur> one way to do it is to use one of the file quasiquoters
20:42:11 <geekosaur> otherwise a Setup,hs can parse and generate a new source file and add it to the deps
20:42:28 <geekosaur> (but note that dependencies for Setup.hs can be tricky still)
20:43:14 <dsal> yeah, quasiquote might be good.  The last time I looked, it didn't seem excessively simple.
20:43:42 <geekosaur> http://hackage.haskell.org/package/heredoc-0.2.0.0/docs/Text-Heredoc.html
20:44:08 <geekosaur> theData = [there|filename goes here]
20:51:23 <geekosaur> (note that if you change only the text file, you may have to touch the .hs file to get it to rebuild; ghc has no idea you have a text file dependency read by a quasiquoter)
20:52:23 <geekosaur> (and I don't think a GHC_OPTIONS -fforce-recomp would work, as it wouldn't look at the file contents during recomp checking)
20:52:57 <dsal> Oh, so the compiler reads the files?  That's pretty great.
20:53:18 <geekosaur> a quasiquoter is Haskell code that runs during compilation
20:53:30 <dsal> Yeah, I misread here and there.
20:54:34 <geekosaur> so when the Quasiquotes extension is on, it oparses that [there|...] as meaning 'call, at compile time, the function "there" passing it the string in "...", and interpolate the resulting AST into the compiler's parse tree'
20:55:17 <geekosaur> (also note the ambiguity with list comprehension syntax; if you also have list comprehensions in the file, you probably want to insert spaces before their |s)
20:55:17 <HaskellLord69> Can anybody recommend a good source for learning more about template haskell?
20:55:20 <EvanR> and "there" can do IO
21:02:23 <merijn> HaskellLord69: I don't know if there's a good single source. There's several decent small tutorials, but not a single comprehensive guide, afaik
21:04:06 <HaskellLord69> ok thanks, I guess ill hunt around sometime then
21:07:03 <EvanR> the ghc manual and the haddocks for template haskell is a good starting point
21:13:46 * geekosaur is no TH guru. quasiquoters are relatively simple though (at least to use)
21:15:44 <geekosaur> the biggest problem with TH is that you have to produce a GHC AST fragment instead of Haskell source, and the various pieces of compile-time data you can access are likewise in AST format (for example, bindings that are in scope)
21:16:20 <geekosaur> conceivably a clever enough quasiquoter could hide that, but it'd be a huge and probably fragile hack that would need to be revised with every new ghc version
21:16:54 * EvanR doesnt understand what quasiquoters have to do with wikipedia quasiquotation article
21:17:02 * geekosaur wonders how badly "Trees that Grow" will break the existing TH ecosystem...
21:17:46 <geekosaur> EvanR, they're (kinda poorly) handled by the first thing in italics
21:18:11 <geekosaur> which reference is rather Lisp-centric but iirc does discuss non-Lisp quasis
21:18:20 <MarcelineVQ> geekosaur: there is a [|| typed th ||], so could be interesting
21:19:38 <geekosaur> "Quine stole my headline!"
21:20:16 <EvanR> in lisp, dont your variables get interpolated into quasi quotes
21:20:29 <geekosaur> only with , or ,@ prefix
21:20:56 <geekosaur> (the latter "unrolls" a list in line instead of inserting a reference to it)
21:21:09 <EvanR> but no such thing is possible in a haskell quasi quoter
21:21:13 <EvanR> afaik
21:21:38 <geekosaur> sure it is. inline-c uses $ prefix iirc
21:21:53 <EvanR> oh... you could implement it yourself
21:22:09 <geekosaur> it just doesn;t give you any help since the quasiquoter language is under your control isntead of forced to be the same as the host language
21:22:32 <geekosaur> well,t he quasiquoter author's control
23:02:00 <EvanR> does this exist
23:02:20 <EvanR> race :: STM a -> STM a -> STM a
23:02:49 <EvanR> or ... -> IO a, where at most only one of the stm actions succeeds
23:05:57 <ongy> STM has an Alternative instance which I used to get the first readable Handle before, maybe that works?
23:06:00 <geekosaur> orElse? also STM has an Alternative instance, suggesting <|> (but I suspect that's just orElse)
23:06:22 <geekosaur> and indeed it is
23:07:17 <geekosaur> hm, but you apparently want them to run concurrently, given the name you used
23:07:38 <geekosaur> not sure that's even well defined tbh
23:08:25 <geekosaur> or, hm. guess it is, but it's certainly not primitive
23:09:06 <EvanR> yes run both in separate atomicallys, but somehow get not both to succeed
23:09:34 <EvanR> i guess orElse technically solves it by having the first one always win
23:10:04 <cocreature> you could have them both write to a TMVar when they‚Äôre finished and if it‚Äôs already full they fail
23:10:19 <geekosaur> http://hackage.haskell.org/package/async-2.1.1.1/docs/Control-Concurrent-Async.html#g:5 might be useful in building one, but I don;t see one prebuilt
23:11:11 <EvanR> fail?
23:11:38 <EvanR> throwSTM
23:12:25 <cocreature> yeah throwSTM was what I was thinking of
23:12:59 <EvanR> that should do it
