00:02:30 <koz_> Athas: OK, that helps too. Thanks!
00:03:39 <Athas> koz_: I would strongly recommend Accelerate, unless you cannot get it to work (it requires specific LLVM versions and such).
00:06:06 <koz_> Athas: How specific are we talking here?
00:06:45 <Athas> koz_: fairly recent versions.  Might even support just one version - I think that was the case last time I used it.
00:07:05 <Athas> But you can always install LLVM locally in your homedir, which takes up a few GiB of space and an hour of your time, but works OK.
00:07:37 <koz_> Athas: I'm on Arch, so my system LLVM is quite recent.
00:13:44 <nohTo> Hello everyone. I'd like to write a dsl for specifying systems that can have a number of inputs and outputs. They can be put in parallel and composed sequentially, the latter only if the number of outputs / inputs match. I'd like the compiler to tell me if I'm trying to compose systems that don't fit together, how could I do that in Haskell?
00:16:27 <vaibhavsagar> nohTo, sounds like you might be interested in dependent types
00:16:56 <vaibhavsagar> you can do this in Haskell, but it's easier and simpler in other languages such as Idris or Agda
00:18:26 <ertes-w> helo
00:19:18 <nohTo> vaibhavsagar: I tried doing it in Idris, however I spent a lot of time trying to convince the compiler to accept a system with (n+0) inputs for one with n inputs and now I'm wondering if maybe I can use typeclasses in a smart way for this?
00:23:06 <ertes-w> nohTo: sounds like you have a left recursive (+), so while 0 + n = n is trivial, n + 0 = n is not
00:23:42 <ertes-w> nohTo: you need to prove the latter first, and the easiest way to do it is to prove commutativity
00:25:37 <ventonegro> ertes-w: No need, one can use `rewrite` with `plusZeroRightNeutral`
00:27:14 <ventonegro> nohTo: https://github.com/idris-lang/Idris-dev/blob/master/libs/prelude/Prelude/Nat.idr#L464
00:29:08 <nohTo> So you think the best way to get that type safety is to go with idris? Would you say it is worth the additional hassle? Or maybe I should better go for runtime errors?
00:30:08 <ventonegro> nohTo: Well, it's really up to you... But if you choose compile-time errors, I'd say Idris would make that part easier
00:36:06 <forker> I want to implement a filter that would "guard" function evaluation: onlyAdmin :: (a -> b -> m r) -> User -> a -> b -> m r . Is it possible to abstract over amount of function's arguments?
00:49:53 <ertes-w> forker: do you need m-effects to decide whether you want to allow the access?
00:51:06 <forker> ertes-w: yes, indeed 
00:52:35 <forker> ertes-w: though I'd be interested to look into examples without m-effects as well
00:53:23 <forker> ertes-w: any library pops up as an example?
00:54:20 <ertes-w> forker: well, i guess you need an m-effect to signal failure anyway
00:54:33 <ertes-w> forker: i can think of two approaches that don't involve overengineering
00:55:31 <ertes-w> 1. onlyAdmin :: (X -> a -> m r) -> User -> X -> a -> m r  -- X is needed for the check, and everything else can be collected in 'a' using e.g. tuples when necessary
00:56:17 <ertes-w> 2. onlyAdmin :: (X -> m r) -> User -> X -> m r  -- this is perhaps a cleaner solution, and the idea is to instantiate 'r' as a function type
00:56:49 <ertes-w> example: onlyAdmin :: (X -> m (Y -> m Z)) -> User -> X -> m (Y -> m Z)
00:58:14 <ertes-w> onlyAdmin myFunc user x {- pass the information required by onlyAdmin -} >>= \f -> f y z {- pass the remaining arguments here -}
01:02:49 <forker> ertes-w: thanks for suggestions! in your example arity is still fixed, isn't it?
01:04:58 <forker> ertes-w: you brought up a good point with possibly needing one of the arguments for guard check. return type potentially as well.
01:05:36 <ertes-w> forker: well, in haskell all functions have arity 1
01:05:52 <ertes-w> forker: the idea to abstract over arity is to leave one of the types polymorphic
01:06:27 <ertes-w> forker: id :: a -> a  -- for example you can instantiate this at (a = b -> c -> d), yiealding ((b -> c -> d) -> b -> c -> d)
01:06:59 <forker> ertes-w: I've just understood the option 2 you suggested :)
01:07:15 <ertes-w> however, this becomes more difficult when a functor is involved, because now you can no longer leave the return type fully polymorphic
01:07:28 <ertes-w> that's why i asked whether you need m-effects
01:07:56 <ertes-w> option 2 uses the fact that 'm' is a monad
01:10:11 <forker> But that pushes the trouble to the evaluator of the whole shebang, isn't it?
01:10:35 <ertes-w> what do you mean?
01:12:05 <forker> something downstream will have to know how far to fold this whole thing: m (X -> m (Y -> m (Z -> ..) ))
01:12:39 <forker> (if I actually understood you correctly)
01:13:58 <ertes-w> no, there is only two levels of M
01:14:16 <saurabhn_> is there a quick way to time tests in Tasty?
01:14:32 <ertes-w> forker: onlyAdmin :: (X -> m (Y -> Z -> m R)) -> User -> X -> m (Y -> Z -> m R)
01:14:35 <saurabhn_> Content: Have made sweeping changes to a codebase and want to measure the before/after easily.
01:14:45 <saurabhn_> s/Content/Context
01:15:01 <ertes-w> saurabhn_: the most quick-n-dirty way is to use the 'time' command of your shell
01:16:12 <forker> ertes-w: so is this one of those cases where people roll multiple instance for different amount of args? like onlyAdmin1, onlyAdmin2 etc?
01:16:52 <saurabhn_> ertes-w: ah okay... nothing more fine-grained built into Tasty? Any 'criterion'one-liner than I can use to wrap around each test which also gives me the time taken to execute that test?
01:17:15 <forker> ertes-w: saurabhn_: RTS flags are not an option?
01:17:37 <saurabhn_> forker: they are. what are you suggesting?
01:17:56 <forker> on -T flag: "These options produce runtime-system statistics, such as the amount of time spent executing the program and in the garbage collector, the amount of memory allocated, the maximum size of the heap, and so on."
01:18:38 <saurabhn_> forker: do you have sample output of -T lying around anywhere? can I give pass it a module and it reports statistics broken down by top-level functions in that module?
01:18:44 <ertes-w> forker: no, the two examples i showed are all instances of the same onlyAdmin
01:19:00 <ertes-w> forker: this one: onlyAdmin :: (X -> m r) -> User -> X -> m r
01:19:06 <ertes-w> forker: note that 'r' is fully polymorphic
01:19:16 <ertes-w> onlyAdmin doesn't even know that you're cascading 'm'
01:19:42 <ertes-w> as far as onlyAdmin is concerned the function to guard only ever takes a single argument before returning the action
01:26:59 <forker> saurabhn_: I think:./myprog +RTS -t -RTS or ./myprog +RTS -S -RTS (not an expert by any means)
01:29:39 <forker> ertes-w: so what I was getting at is: given the suggested  onlyAdmin :: (X -> m r) -> User -> X -> m r
01:29:39 <forker> and having defined earlier a function (a -> b -> c -> m z) I would need to rework it into (a -> m (b -> m (c -> m z)))?
01:31:10 <ertes-w> forker: no, into (a -> m (b -> c -> m z))
01:31:17 <quchen> There was this project where a small webservice or so would be implemented in many different languages, Haskell being one of them. It was something small yet realistic to compare languages, on Github I believe. Does anyone know of such a project? I can’t find it anymore.
01:31:37 <ertes-w> forker: this is a mechanical process, which you can do on the fly
01:32:04 <ertes-w> :t (pure .)
01:32:05 <lambdabot> Applicative f => (a1 -> a2) -> a1 -> f a2
01:32:42 <ertes-w> :t (pure .) :: (Applicative m) => (a -> b -> c -> m z) -> a -> m (b -> c -> m z)
01:32:43 <lambdabot> Applicative m => (a -> b -> c -> m z) -> a -> m (b -> c -> m z)
01:32:50 <ertes-w> forker: ^
01:34:08 <forker> ertes-w: oh gee, thanks!
02:10:47 <jle`> quchen: todo mvc, maybe?
02:11:59 <quchen> jle`: In the same spirit, but what I remember wasn’t for the frontend 
02:12:41 <jle`> ah i see now that you wrote webservice, as one word.
02:20:30 <quchen> jle`: Ah, I think it was https://www.todobackend.com
02:39:31 <dysfun> has the new ghcjs codegen landed?
02:43:30 <AdamWendell> quchen: there's also https://github.com/gothinkster/realworld
03:19:38 <totom> why is there iterative structure like "If then" in functional language like haskell
03:20:08 <dminuoso> Can someone explain to me the monoid structure of an applicative Const functor?
03:20:15 <dminuoso> How is this useful?
03:20:42 <Cale> totom: if b then t else e  is just syntax sugar for  case b of True -> t; False -> e
03:20:55 <Cale> totom: Apart from that, I don't really understand what you're asking.
03:21:10 <Cale> How is if/then/else iterative?
03:21:44 <Cale> (also, Haskell has lots of imperative style loops and stuff, it's just they don't tend to be built in to the language, but rather written as library functions)
03:22:23 <Cale> dminuoso: Do you mean how the monoid operation is used by the Applicative operations?
03:22:31 <totom> ok, i just started haskell so i had a newbie questio in mind
03:22:56 <dminuoso> Cale: No that much seems obvious as Const l <*> Const r = Const (l <> r)
03:23:34 <dminuoso> Cale: Im rather wondering what this is for.
03:23:49 <Cale> So you mean like,  instance Monoid m => Monoid (Const m a)?
03:23:53 <dminuoso> Yeah
03:23:59 <Li[m]> whats the data serialization format thatll superseed json?
03:24:19 <Li[m]> if you had to write something to be used in 5 years from now
03:24:48 <Cale> Li[m]: I mean, the main reason json is popular I would guess is that there's browser support for it.
03:25:14 <dminuoso> Cale: Based on my previous discoveries, I have a feeling that this has some deeper meaning in lenses.
03:25:33 <Li[m]> for me, tomorrow's killer feature is energy efficiency, so Im leaning towards more efficient
03:25:42 <Li[m]> msgpack ?
03:25:52 <Li[m]> I thought this would be the best spot to ask
03:27:33 <[exa]> Li[m]: +1 for the efficiency
03:27:43 <Cale> Li[m]: I don't know. I tend to think of JSON as an arbitrary line encoding whose specifics don't matter at all. Basically all my JSON serialisation is produced automatically by Template Haskell macros, and it might as well be producing a binary format.
03:28:42 <Cale> Might be nice to shave some bytes, but the main reason we don't do that is because the browser will prettyprint JSON for us while debugging, but if you shove binary data over a websocket or in requests, it won't help you much.
03:30:46 <Li[m]> its a tooling problem
03:30:48 <Cale> Maybe I'm an atypical JSON user though
03:31:12 <Cale> Not *too* many people yet who get to share their Haskell code between the frontend and backend of their applications :)
03:32:25 <Cale> But it's rather nice that we basically never have to worry about JSON encoding related bugs, which were upwards of 90% of all bugs on some other web applications I worked on in the past.
03:32:40 <Cale> (type safety!)
03:37:24 <Hafydd> I'm a full-stack developer specialising in JSON programming.
03:38:05 <Cale> I'm a full stack of pancakes specialising in secret syrup.
03:39:14 <orion> Cale: If you were writing a brand new web application from scratch (front and back), and you were interested in doing it in a Haskelly way (GHC, GHCJS, PureScript, etc), what libraries would you use for the backend and frontend?
03:40:47 <Cale> orion: I'd start with reflex-platform, using reflex-dom for the frontend. I'm not sure which backend I'd prefer. Snap is pretty okay.
03:43:27 <Cale> If you're developing a single page application with a bunch of dynamically changing data, most of the backend complication is not something that existing web server frameworks really help much with.
03:44:26 <nohTo> Maybe this isn't the right place to ask, but I have the weirdest issues just trying to install a package from hackage. I set up a cabal sandbox and it fails compiling anything saying that it couldn't find module prelude
03:44:53 <orion> Cale: What do you mean by, "backend complication"?
03:47:05 <Cale> orion: I mean like all the code which takes descriptions of what data users want to see from the frontend and pairs it up with notifications from the database about new data and queries for existing data.
03:48:01 <orion> Ah. I've been using Oapleye and Servant.
03:49:03 <Cale> As far as I know, Servant won't help you communicate continuously over a websocket based on a stream of DB notifications though
03:49:13 <orion> ah
03:49:54 <orion> When you said this: "it's rather nice that we basically never have to worry about JSON encoding related bugs" it made me think of having a single definition for the JSON structures for both the front and the back.
03:49:56 <Cale> Also, I'd really like far better support from the databases in this regard...
03:50:07 <Cale> Yeah, we do have that at least :)
03:50:30 <orion> That means you're using GHCJS?
03:50:32 <Cale> We have a bunch of Haskell data types which are shared between the frontend and backend, and they have automatically-generated FromJSON and ToJSON instances.
03:50:43 <Cale> We're using ghcjs for the web, yes.
03:50:54 <Cale> and GHC's ARM support for mobile
03:53:58 <Cale> In the current reflex-platform on github, you can try out the mobile build support for iOS and Android :)
03:54:39 <orion> Wow, you're doing Haskell on mobile!?
03:54:44 <Cale> yep
03:54:53 <orion> Are you hiring? ;x
03:55:40 <Cale> The fun bit is that the applications actually run faster on my phone than they do on desktop in a web browser, because native ARM code controlling the DOM beats the hell out of Javascript, even when run on a fast desktop machine.
03:56:12 <orion> What do you use for the desktop browser?
03:56:16 <Cale> Actually, I think we might be? Send a message to Ryan Trinkle :)
03:56:31 <Cale> orion: I mean like, Firefox or Chrome
03:57:25 <orion> Ah, I meant to ask: Are you able to use reflex-platform/dom for both mobile and desktop?
03:58:08 <Cale> Ah, there's also the GHC for x86/64 desktop version, and that's generally much faster than the GHCJS build as well.
03:59:18 <orion> "desktop" meaning Firefox/Chrome on the desktop
03:59:26 <Cale> Well, not in that last line
03:59:35 <Cale> I was previously referring to the web versions
03:59:42 <orion> No, that's what I was asking about.
03:59:47 <Cale> But we can also build native code for desktop that controls a webview
04:00:04 <Cale> (and that obviously runs much faster as well)
04:00:14 <orion> I meant to ask: "Are you able to use reflex-platform/dom for both mobile Firefox and desktop Firefox?"
04:00:46 <Cale> Well, running the apps on a mobile web browser is a bit slow
04:01:27 <Cale> You'd much prefer to use the native code generation if you're going to run the thing on a phone
04:01:38 <orion> I see.
04:03:31 <orion> What library/project is responsible for producing the APK?
04:04:09 <orion> Surely I can't type "stack build" and get an APK.
04:06:43 <Cale> orion: nix
04:09:09 <Cale> John Ericson spent a lot of time and effort encoding all the crazy and involved details of setting up cross compilation into nix expressions for us :)
04:09:55 <Cale> and if you're using reflex-platform, there are binary caches, so you probably don't have to actually sit through hours of building compilers and stuff.
04:19:15 <orion> Cool. I've never used nix before. Are these nix expressions open source?
04:26:48 <ClaudiusMaximus> does reflex-whatever have any stuff to make FFI to emscripten-compiled C/C++ libraries nice?
04:30:04 <ClaudiusMaximus> i guess i should try it at some point, maybe a native app would be a good first start because emscripten js is around 90x slower than native code in one test i did... just that having something that runs in a web brower without needing to install anything is so convenient...
04:40:46 <e-dt> aya
04:41:02 <e-dt> does anyone have a lambda calculus to iota compiler
04:41:16 <e-dt> yes?
04:41:21 <e-dt> maybe?
04:41:22 <e-dt> no?
04:41:22 <e-dt> i
04:42:36 <e-dt> hello?
04:42:37 <e-dt> anyone there
04:42:40 <Cale> hi
04:42:47 <e-dt> does anyone have a lambda calculus to iota compiler
04:42:59 <Cale> I'm assuming that if they did, they would have answered :)
04:43:36 <e-dt> wow
04:43:38 <e-dt> cale
04:43:47 <hamid> I have a function with this signiture "f :: [Maybe a] -> Maybe [a]" and it process all elements in the list and if one of them is "Nothing" the result is Nothing but if all of them are "Just a" then it returns list of all those elements "Just [a]". I know I can do this with simple foldl but I wanna know since both List and Maybe are monads, Is there way to use a monadic operations to produce the same 
04:43:52 <e-dt> well they might just not be lookin
04:43:53 <hamid> result?
04:44:03 <e-dt> *signature
04:44:21 <Cale> e-dt: Yeah, that's also possible
04:45:06 <Cale> hamid: That's sequence
04:45:22 <Cale> > sequence [Just 1, Just 2, Just 3]
04:45:23 <lambdabot>  Just [1,2,3]
04:45:29 <Cale> > sequence [Just 1, Just 2, Nothing, Just 3]
04:45:31 <lambdabot>  Nothing
04:45:55 <hamid> Cale, nice. how is it implemented?
04:46:16 <Cale> sequence :: Monad m => [m a] -> m [a]
04:46:21 <Cale> sequence [] = return []
04:46:41 <Cale> If the list is empty, we produce an action which does nothing except give the empty list as its result
04:46:49 <Cale> sequence (x:xs) = ...
04:46:53 <Cale> If the list is nonempty
04:46:58 <Cale> sequence (x:xs) = do v <- x; ...
04:47:12 <Cale> we run the first action in the list, obtaining some result v
04:47:21 <Cale> sequence (x:xs) = do v <- x; vs <- sequence xs; ...
04:47:31 <Cale> then we run the rest of the list, getting a list of results vs
04:47:38 <Cale> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs)
04:48:11 <Cale> Heh, getting threatened by Sigyn for spam :)
04:48:43 <Cale> Anyway we combine the first result with the rest and return the completed list
04:49:32 <hamid> Cale, Thank you ;) 
04:50:08 <Boomerang> :t sequenceA
04:50:09 <lambdabot> (Applicative f, Traversable t) => t (f a) -> f (t a)
04:50:24 <Cale> Yeah, there's a generalisation
05:50:22 <momi> hi there
05:50:32 <momi> new to haskell and FP
05:50:38 <momi> need help
05:50:51 <quchen> momi: You’ve come to the right place!
05:51:11 <momi> how to print on standard output a Data.Map
05:51:18 <momi> Map String Int
05:52:21 <momi> https://thepasteb.in/p/oYhlYvKlJ3oHZ
05:52:21 <momi> mapM_ putStrLn $ M.keys myMap
05:52:29 <momi> this one works for keys
05:52:46 <quchen> momi: You can convert a Map to a String by using Show
05:52:51 <momi> but I want to print keys and values
05:53:12 <quchen> > show (M.fromList [(1,"hello"), (3,"world")])
05:53:14 <lambdabot>  "fromList [(1,\"hello\"),(3,\"world\")]"
05:53:27 <quchen> momi: You can also use M.assocs to get the list of key/value pairs
05:53:34 <quchen> > show (M.assocs (M.fromList [(1,"hello"), (3,"world")]))
05:53:36 <lambdabot>  "[(1,\"hello\"),(3,\"world\")]"
05:53:48 <momi> hm .. lets give it a try
05:56:07 <momi> mapM_ putStrLn $ show(M.assocs myMap)
05:56:20 <momi> id doesn't compile
05:59:48 <quchen> Why?
06:00:01 <quchen> Oh, you’re trying to »putStrLn« tuples now.
06:00:13 <quchen> Try »mapM_ print (M.assocs myMap)
06:00:17 <quchen> ?src print
06:00:17 <lambdabot> print x = putStrLn (show x)
06:00:34 <quchen> This way, it will print each (key, value) tuple on its own line
06:02:02 <quchen> Wait, you weren’t putStrLn’ing tuples. You had »show (…)«, which is a String.
06:02:28 <quchen> You then have mapM_, which expects a list of things as second argument. Works, because a String is a list of Char.
06:02:49 <quchen> But then the putStrLn is applied to each of the characters, and GHC complains that you’ve mismatched Char and String.
06:03:01 <quchen> At least that’s what my head typechecker says without running any of these examples ;-)
06:03:49 <momi> yes
06:04:21 <momi> using print, it print every character on new line
06:04:22 <momi> :D
06:04:38 <quchen> Yeah, because mapM_ applies print to each element of the list
06:04:49 <momi> like this:
06:05:02 <momi> '['
06:05:02 <momi> '('
06:05:02 <momi> '"'
06:05:02 <momi> 's'
06:05:02 <momi> 'o'
06:05:02 <momi> 'm'
06:05:03 <momi> 'e'
06:05:03 <momi> 'o'
06:05:04 <momi> 't'
06:05:04 <momi> 'h'
06:05:05 <momi> 'e'
06:05:05 <momi> 'r'
06:05:40 <momi> I just need to print like this
06:05:44 <momi> key value
06:05:48 <momi> key value
06:06:40 <quchen> mapM_ (\(key, value) -> print (show key ++ " " ++ show value)) (M.assocs myMap)
06:07:56 <quchen> Or use traverseWithKey, which is equivalent to the above, M.traverseWithKey (\(key, value) -> print (show key ++ " " ++ show value)) myMap
06:08:31 <momi> ok
06:08:33 <momi> thank you
06:08:39 <momi> that is it
06:08:53 <Xion_> Or forM_, which is reversed mapM_ which is probably a nicer looking syntax for this
06:10:46 <quchen> momi: You could also use a list comprehension to do this, by the way. I think it looks pretty natural for maps.
06:11:03 <quchen> [ print (key, value) | (key, value) <- M.assocs myMap ]
06:11:12 <quchen> That gives you a list of IO actions.
06:11:17 <quchen> You can run these with »sequence«.
06:11:38 <quchen> Sooo: sequence […|…<-M.assocs…]
06:12:34 <merijn> quchen: I'd use forM instead
06:12:50 <quchen> And I’d like to paint the shed green ;-|
06:12:54 <merijn> "forM_ (M.assocs myMap) $ \(key, value) -> do { ... }"
06:13:14 <merijn> :(
06:13:27 <merijn> I like forM, looks much like the for-each loop people are used to
06:13:27 <momi> This one: mapM_ (\(key, value) -> print (show key ++ " " ++ show value)) (M.assocs myMap)
06:13:32 <momi> works just fine for me
06:15:03 <quchen> merijn: I like »for« even more lalala.
06:15:20 <quchen> I mean the M is for Monad, and forM requires nothing monadic.
06:15:29 <quchen> Light green, by the way. I want it light green.
06:15:52 <quchen> momi: Your solution is fine, ignore us ;-)
06:15:52 <merijn> I just want my shed with less C++ templates >.>
06:16:28 <quchen> Haha
06:18:38 <Psybur> If I wanted to make a generic memo map, is there a map which can use a function in its key?
06:18:58 <momi> it is extremely hard for me to think functionaly
06:19:14 <momi> after years on java, php, python
06:19:44 <quchen> momi: Yes, it’s a big change, much bigger than going from say PHP to Python.
06:19:54 <momi> yes
06:20:00 <Psybur> Something like: memoize :: M.Map (a -> b,a) b -> (a -> b) -> a -> (b, M.Map (a ->b,a) b)
06:20:09 <quchen> But most here would argue that it was worth it. And you’ll be surprised how much of your new knowledge applies to your other languages as well.
06:20:17 <quchen> Not just »lambdas and stuff«, but ways of structuring your programs.
06:20:43 <momi> I hope so
06:20:44 <quchen> Psybur: No, you cannot use functions as keys for maps, since functions cannot be ordered. And maps (of more than one element) require ordered keys.
06:22:29 <Psybur> quchen, I guess I'd have to encapsulate each function I want to memoize in its own definition I suppose
06:22:34 <dminuoso> What are some realistic usecases of ($ a) ?
06:22:37 <quchen> momi: The upside is that once you know Haskell, learning other functional languages is fairly trivial.
06:22:58 <dminuoso> Im trying really hard to find to use patterns, where describing the application of a function to a specific parameter is useful.
06:23:01 <quchen> dminuoso: any ($ x) [isEven, (== 1), (== 3]
06:23:19 <quchen> dminuoso: In other words, checking whether some predicates apply to a value
06:23:42 <quchen> Typical use case, apply many tests to a single input value
06:23:51 <dminuoso> Ohh, that's interesting.
06:23:55 <Psybur> Or create a function that returns a memoizer for a function heh
06:24:18 <matheus23> Hello, I'm trying to install glib (via stack install glib) on ArchLinux, but I get linker errors... "ld returns 1". It tells me to "recompile with -fPIC", so I tried "stack install glib --ghc-options -fPIC" but I get eactly the same error... 
06:24:35 <matheus23> exactly*
06:24:36 <quchen> Psybur: Have a look at the data-memocombinator function for a non-Map based implementation of memoization
06:25:11 <ventonegro> Another day, another Arch Linux problem...
06:25:28 <quchen> I don’t think this is ArchLinux’ fault
06:25:35 <dminuoso> quchen: Thank you, that was helpful.
06:25:37 <quchen> I remember having this problem myself (Ubuntu)
06:25:56 <matheus23> quchen: Do you remember, what solved this problem?
06:26:00 <pranz> matheus23: https://github.com/commercialhaskell/stack/blob/master/doc/faq.md
06:26:02 <Psybur> quchen, I will in a bit. Working this exercise out on my own for now heh
06:26:04 <Psybur> makeMemoizer :: (a -> b) -> (a -> (b,M.Map a b))
06:26:07 <pranz> if you search on fpic you will see something about it there
06:26:52 <pranz> seems like a bug that's not been fixed yet
06:27:31 <Psybur> makeMemoizer :: (a -> b) -> (a -> M.map a b -> (b,M.Map a b))
06:46:26 <Psybur> Seems I cannot login as "guest" at https://ghc.haskell.org/trac/ghc/wiki/ReportABug
06:48:50 <mpickering> Psybur: I'm not sure that works anymore
06:49:15 <mpickering> Either make an account of ask someone in #ghc to make the issue for youi
06:49:41 <betawaffle> is there a name for a set that you can only test for membership (you can't enumerate the members)?
06:50:57 <hexagoxel> such set it called "a -> Bool"
06:51:14 <betawaffle> yes, exactly. i was wondering if there's some mathy name
06:52:48 <fakenullie> uncountable set?
06:53:05 <betawaffle> maybe
06:55:29 <barrucadu> It's not uncountable, because `() -> Bool` is a representation of a set that has 0 or 1 elements.
06:55:33 <fakenullie> but it can't be bigger than set of values you're testing against it
06:55:55 <fakenullie> Real -> Bool ?
06:56:23 <betawaffle> i want to make a type class to represent things that can be Set-like
06:56:38 <betawaffle> one where i don't exclude such things
06:59:04 <fakenullie> well, typeclass for this is a -> Bool
06:59:05 <matheus23> Thanks pranz ! your link and this one https://bbs.archlinux.org/viewtopic.php?id=230091 helped me fix my problem (installing ncurses-full and libtinfo5)
07:01:49 <hexagoxel> betawaffle: how about "(unary) predicate" ?
07:02:12 <betawaffle> hexagoxel: what's that?
07:02:53 <betawaffle> oh, you mean as a name?
07:02:57 <hexagoxel> yes
07:06:07 <fakenullie> well, it should be just Set
07:06:16 <fakenullie> and enumerable set is a different entity then
07:35:02 <betawaffle> what's the GHC extension that allows associated types?
07:37:38 <lyxia> TypeFamilies
07:38:14 <ertes-w> betawaffle: just use (-> Bool)
07:38:26 <ertes-w> for the set thing
07:38:29 <betawaffle> ertes-w: isn't that Bool -> a ?
07:38:59 <betawaffle> also, then i can't mix in Set and IntSet, since they have constraints... hmm
07:39:03 <ertes-w> no, a -> Bool
07:39:21 <ertes-w> why not?
07:39:46 <ertes-w> :t flip S.member
07:39:47 <lambdabot> Ord a => S.Set a -> a -> Bool
07:39:47 <betawaffle> wouldn't it complain about the constraints?
07:39:53 <ertes-w> why would it?
07:40:09 <betawaffle> ok, let me try it...
07:44:21 <betawaffle> No instance for (Ord a) arising from a use of ‘S.difference’
07:55:34 <Psybur> Do you think this code demonstrates a good understanding of memoization with haskell? https://pastebin.com/57FULrDZ
07:55:35 <ertes-w> betawaffle: what are you trying to do?
07:56:34 <betawaffle> ertes-w: operate on abstract sets without condensing them all to the same type
07:56:40 <betawaffle> (if possible)
07:59:10 <betawaffle> i want to write functions that can work on a -> Bool, Set a, and IntSet
08:00:10 <betawaffle> i wonder if i need GADTs
08:01:14 <mnoonan_> betawaffle: just make a typeclass for the operations you want? or are you trying to do things like intersect an a -> Bool with a Set a?
08:01:47 <ertes-w> betawaffle: i don't see how you can unify them without pretty much giving up all performance properties of the individual instances
08:01:49 <betawaffle> mnoonan_: well, yeah i'd love to do the latter too, but i was trying to get the former to work first
08:01:59 <betawaffle> ertes-w: ok
08:02:20 <ertes-w> betawaffle: what problem are you solving?
08:02:41 <betawaffle> ertes-w: i'm just messing around atm
08:04:15 <betawaffle> hmm, maybe i want data families?
08:04:32 <ertes-w> i think you want to stop overengineering =)
08:04:56 <betawaffle> i'll start by writing explicit functions for each of the types, i guess
08:07:33 <hexagoxel> for the linear type proposal, is () implicitly unrestricted? alternatively, is the multiplicity of any recursively-exposed datatype arbitrary because you can consume and create it again freely?
08:08:35 <hexagoxel> what types exactly would be "recursively exposed" in that sense?
08:11:09 <hexagoxel> ertes-w: if you have time, i'd still be interested in answers to the state/automaton design questions from yesterday.
08:12:25 <ertes-w> hexagoxel: oh, yeah…  could you repeat the questions, please?
08:14:47 <hexagoxel> ertes-w: 1) does this approach not collapse entirely once you want to save/load (game) states? 2) how does the expressivity of FRP compare to the composability gained with this approach?
08:14:59 <hexagoxel> both in reference to the hangman example.
08:18:35 <ertes-w> hexagoxel: 1) there is an equivalent formulation in terms of a final encoding, which exposes an existential state value…  you can then add constraints to that state in order to serialise/deserialise it…  alternatively you can make serialisation/deserialisation part of the Hangman interface
08:18:59 <ertes-w> hexagoxel: 2) FRP is orthogonal…  you would use FRP together with this
08:19:56 <ertes-w> hexagoxel: no promises, but i might write a little example over the weekend
08:27:38 * hexagoxel is still thinking
08:34:54 <hexagoxel> i can agree with FRP being orthogonal. I am not convinced yet that you'd be able to serialize/deserialize without manually converting representations.
08:38:20 <hexagoxel> you can certainly make the serialized data monoidal, but then how do you deserialize?
08:39:32 <ertes-w> hexagoxel: i'll see if i can write a small example…  i've done something similar with AFRP in the past (serialisable wires)
08:39:44 <ertes-w> bbl
08:39:50 <hexagoxel> ertes-w: thanks!
08:39:58 <hexagoxel> example would be nice :)
08:49:39 <betawaffle> tada: https://gist.github.com/betawaffle/a7152242965077548dfafcc877cb7900
08:50:37 <Ero> i'm watching this vid from GDC titled 'fallout 4's modular level design' and my first thoughts was: this sounds relevant to my interests
08:51:24 <Ero> turns out that they had big issues when they took the way they did interior level design, and then tried to make that model fit exterior design
08:52:13 <Ero> All along I was thinking, they would have seen these issues coming if they had modelled their design first using some kind of type theory
09:17:51 <tabaqui> how should I work with resourceMask correctly?
09:18:08 <tabaqui> should I lift 'catch` function while using restore?
09:18:11 <tabaqui> like
09:18:43 <tabaqui> resourceMask $ \restore -> (liftA2 catch) smth (\e -> parse e)
09:19:01 <tabaqui> *(restore smth)
09:19:11 <tabaqui> or some other way?
09:26:50 * superpat[m] sent a long message: superpat[m]_2017-11-10_17:26:27.txt <https://matrix.org/_matrix/media/v1/download/matrix.org/sHmwmfRlgxPVBPUnCJwQwJhd>
09:29:40 <ski> superpat[m] : should `c' be the same as `d' ?
09:30:07 <ski> (or perhaps a better question : should `kind' be the same as `d' ?)
09:30:10 <superpat[m]> Same type yes
09:30:38 <superpat[m]> yeah
09:31:11 <ski> how about you (a) remove the `kind' argument (and the corresponding `c ->' in the type signature); (b) rename `d' in the signature to `kind'; and (c) add `forall d.' after the `::' in the signature ?
09:31:25 <ski> you'll also need to enable the `ScopedTypeVariables' language extension
09:31:36 <Psybur> In do notation, when I use: x <- monadicOperation, monadicOperation will be combined with the next monadicOperation in the do block?
09:32:01 <Psybur> Thats what it looks like based on my observations playing around, wanted to see if thats correct
09:32:21 <ski> hm, maybe `O.runQuery' will require you to add some class constraint on `kind' as well ..
09:32:36 <ski> Psybur : yes
09:32:43 <tabaqui> Psybur: of course, do-notation is just a sugar
09:33:03 <Psybur> ski, thanks. For whatever reason I used to think that extraction wouldnt apply the monadic operation being extracted from to the next ones D:
09:33:05 <tabaqui> `do; x <- f; g x` equals to `f >>= g`
09:33:14 * ski isn't sure superpat[m] really needs `ScopedTypeVariables' here, though
09:33:53 <ski> Psybur : i don't understand what you just said. (perhaps you'd like to rephrase)
09:34:40 <Psybur> so I used to think in "do x <- mc1; mc2", that this wouldnt turn into mc1 >> mc2. It would just be mc2 :D
09:34:58 <Psybur> But now I see it will in fact be mc1 >> mc2 right
09:35:33 <tabaqui> actually to `mc1 >>= (\_ -> mc2)` what is equal to `mc1 >> mc2`
09:36:37 <Psybur> And am I using StateT well, or is there a more elegant way to do the following: https://glot.io/snippets/evdah8m6mj
09:37:18 <superpat[m]> ski: is this what you mean? `getRow :: forall kind. (O.QueryArr a b) -> a -> AppM (Maybe kind)` 
09:37:42 <superpat[m]> I get a not in scope: type variable error for a and b now
09:37:43 <Psybur> Wondering if runMemoized is done the idiomatic way
09:38:03 <ski> `act >>= respond' (iow `do x <- act; respond x') is the action that, when executed, will start by executing `act' (yielding result `x'), and then continue by executing the action `respond x' (which may thus depend on the result `x' of the former "sub"-action). the result of executing `respond x' will be the result of executing the whole compound action `act >>= respond'
09:39:13 <ski> superpat[m] : hm, you also removed the `auth' argument (of type `Maybe UserRead') ? you may need to also add `a' and `b' after the `forall' (like `forall a b kind. ...')
09:39:34 <tabaqui> what about resourceMask, again?
09:40:14 <superpat[m]> Oh yeah, disregard that argument, I meant to remove it before but forgot.
09:40:16 <tabaqui> how should I catch exception with restore?
09:40:44 <ski> Psybur : your `runMemoized' can be written with `mapM_' / `forM_'
09:41:04 <oaao> if anyone missed out on a 34c3 ticket but still wants to go, message me since i'm not using mine anymore
09:43:44 * superpat[m] sent a long message: superpat[m]_2017-11-10_17:43:21.txt <https://matrix.org/_matrix/media/v1/download/matrix.org/EFRQhxupxORVqOKNiwcxAQYx>
09:44:30 <superpat[m]> Would adding a class constraint for Default on kind fix that?
09:45:03 <ski> superpat[m] : well, it would have helped more if you had stated that error message from the start :)
09:45:08 <ski> yes
09:45:46 <ski> and, if that works, try to remove the `forall' and the type ascription, and see whether it doesn't work then, without those
09:46:14 <ski> (of course, you could keep those. but it's good to understand better when that kind of thing isn't necessary)
09:46:14 <Psybur> ski, so would you say this is idiomatic? That "state $" is bugging me though xD https://glot.io/snippets/evdaqp4fey
09:48:18 <ski> well, imho, all or most `$'s in there could be removed, with no loss ;)
09:48:32 <ski> what bugs you about `state' there ?
09:48:56 * ski isn't even sure what the paste is supposed to accomplish
09:49:13 <Psybur> ski, its showing memoization in practice
09:49:17 <codeshot> Psybur, that doesn't look very idiomatic to me, although I'm a newbie
09:49:22 <ski> what does that mean ?
09:49:49 <ski> it shows an explicit, state-based, approach to memoization
09:49:49 <Psybur> Do you know what memoization is?
09:49:55 <Psybur> Yes
09:50:01 <ski> if that's what you want to do, i think your approach is ok
09:50:06 <codeshot> yes, I know memoisation
09:50:17 <Psybur> codeshot, I was responding to ski :D
09:50:22 <codeshot> oh :)
09:51:33 <Psybur> So "state" bothers me because Im wondering if it makes sense to use state in the do block, or should I have modified memoize to return State
09:51:53 <Psybur> I chose state in the do block because it leaves the memoize function more flexible right?
09:52:02 <Psybur> Or should I have wrapped memoize in another function that returns state
09:52:06 <Psybur> Then used that in the do block
09:52:09 <ski> that (modifying `memoize') might be nicer
09:58:05 * superpat[m] sent a long message: superpat[m]_2017-11-10_17:57:42.txt <https://matrix.org/_matrix/media/v1/download/matrix.org/FyIRGFBtvEytkkizXxXhAhHr>
09:59:54 <ski> move the `forall a b kind.' before the `Default O.QueryRunner b kind =>'
10:00:24 <ski> `b' and `kind' needs to be in scope *before* the constraint `Default O.QueryRunner b kind'
10:00:31 <orion> In aeson I can use `fail` to describe why parsing failed, however that function will be deprecated soon. What should I do instead?
10:00:55 <ski> the way you wrote it, the `forall' effectively introduces new *different* variables `b' and `kind' (shadowing the ones in the constraint)
10:02:08 <ski> (you can see in the error message that it actually renamed the shadowing variables to `b1' and `kind1', to make it clearer to you that you had specified these to be distinct from the `b' and the `kind' in the constraint)
10:03:23 <humanoyd> Why do (>>) and (*>) have different precedence levels when they do the same thing?
10:03:44 <ski> superpat[m] : then, after you've done this exchange, you can probably (as i said before) remove the `forall' quantification (and the type ascription in the body of the function definition)
10:05:41 <superpat[m]> ski: That clears it up, first time is used forall in a type signature. It compiles just fine now! Like you said I was then able to remove the forall and it still worked. I did have to add FlexibleContexts though.
10:05:53 <superpat[m]> Thanks a lot for the help
10:06:07 <ski> superpat[m] : did you try removing the `forall' and the type ascription ?
10:06:17 <ski> ah, you did, ok
10:06:20 <superpat[m]> yes
10:06:22 <superpat[m]> and it worked!
10:07:33 <ski> superpat[m] : point is that, *sometimes*, you *do* want to mention a type variable in the body of the code (in a type ascription, like your `... :: IO [kind]'), and then you (for imho silly reasons) *do* need to explicitly use `forall' in the type signature, to bring the type variables into scope in the definition
10:07:47 <monochrom> humanoyd: I don't know, but I bet they're usually used in different contexts to begin with.
10:08:06 <ski> superpat[m] : but in your case, the problem was actually that you had forgotten (or not realized you needed) to add the constraint on `b'/`c'/`kind' in the type signature
10:08:54 <ski> superpat[m] : given that, the type ascription wasn't necessary, since it could figure out on its own that `kind' in the result type should occur in the type of the expression which you added the ascription on
10:10:00 <ski> superpat[m] : anyways .. sometimes it can be handy to pass a "type argument", say `b' to a function. what you tend to do then, is you actually pass a value of type `Proxy b', which acts a "stand-in" for the type `b' itself. i just wanted to mention this, so that you can look into `Proxy' another time
10:10:34 <superpat[m]> ski: Ah so thats whats happening in servant
10:11:18 <ski> (however if `b' occurs in the result type (or in an argument type), then i would probably refrain from passing a `Proxy b' argument)
10:11:46 <superpat[m]> ski: I definitly did not realize that I could make my life easier by adding those class constraints. I'll have to revisit part of my code.
10:13:06 <ski> well, if you use an operation in your code which requires such constraints, *and* you decide to be polymorphic (rather than just picking some particular type which is known to satisfy the constaint), *then* you do need such constraints in your type signature
10:13:55 <ski> otherwise you'd be promising that any caller could use your operation with any particular type whatsoever, regardless of whether it satisfied that constraint or not .. but that doesn't work, because your implementation uses an operation which requires the constraint
10:14:34 <humanoyd> monochrom: yes, probably...I just (falsely) assumed they could be used interchangeably as PureScript got rid of (>>) in favor of (*>)
10:14:40 <Ero> anyone here familiar with linear logic? I'm wondering if linear logic's resources has any impact on big O notation 
10:15:55 <johnw> what do you mean by linear logic's "resources"?
10:16:55 <Ero> speficially regarding session types
10:17:04 <Ero> i suppose really i meant session types, not linear logic
10:17:20 <johnw> those I know nothing about
10:17:27 <Ero> oki, ty
10:17:39 <tac-tics> I wish there were a nice theoretical introduction to linear logic.
10:17:42 <Ero> do you know much on the topic of linear logic, johnw ?
10:17:53 <johnw> much, no, but some
10:18:02 <tac-tics> I tried piecing together an understanding from Wikipedia. But it did not go over so well.
10:18:04 <johnw> i look forward to using them once GHC gains the ability
10:18:11 * ski recalls doing a presentation on Wadler's paper on session types and linear logic
10:18:31 <johnw> linear logic imposes a meaning on functions, such that some arguments can only be used in very specific ways
10:19:02 <tac-tics> It seems like there are some different interpretations to it, and I want to understand how "canonical"(or something?) it is.
10:19:21 <tac-tics> Since people like to use linear-looking ideas and brand them (Uniquness types, Session types, etc)
10:19:30 <ski> arguments/variables/assumptions can "only be used once"
10:19:35 <tac-tics> right
10:19:37 <johnw> once and only once
10:19:43 * ski nods
10:19:43 <johnw> not never, not twice
10:19:54 <ski> ("at most once" would be affine)
10:20:10 <codeshot> superpat[m], I feel this is more idiomatic: let memoize f x = do {modify (insertWith (flip const) x $ f x); gets (! x)}
10:20:13 <tac-tics> I get that it does some things to manipulate the context as you typecheck
10:20:25 <tac-tics> as opposed to what STLC does, which only ever adds to the context.
10:20:29 <ski> with linearity, you ensure that a datum will not be duplicated in the future
10:20:37 <johnw> but you can always use the value to produce a new one, like an updated file handle with a new position; so a series of writes is seen to use the "same" handle (although strictly speaking, each write *must* use a new version of the original handle)
10:20:40 <ski> with uniqueness, you ensure that a datum has not been duplicated in the past
10:21:10 <ski> uniqueness leads to efficient update-in-place implementation of versions of states
10:22:24 <tac-tics> I guess the resources I've seen always presents linear logic as a two-sided sequent calculus
10:22:33 <ski> (iow reusing memory block that are to become dead, for new values, possibly avoiding copying over parts which doesn't change. if no new value, then one gets compile-time GC, iow an insertion of a `free' call)
10:22:34 <tac-tics> whereas I'm used to a 1-sided sequent calculus
10:23:03 * ski always thought the one-sided ones looked .. odd :)
10:23:14 <codeshot> it says update the value by reinserting the existing one if it's there else inserting the new one, then lookup the value as the result
10:24:16 <ski> in Mercury, you can have a predicate which is given a unique reference to a datum, and which *doesn't* consume it (you get it back after the call) -- though i'm not sure how well supported this is in the implementation, yet
10:24:23 <tac-tics> I'm not sure how to interpret A |- B, C
10:24:29 <tac-tics> with a common on the right
10:24:47 <ski> given `A', `B' or `C' obtains ?
10:24:59 <ski> (where the "or" is a multiplicative one)
10:25:26 <tac-tics> Yeah. I just don't know what that really means in terms of things i already understand.
10:25:34 <tac-tics> If I wanted to write a typechecker, for instance
10:25:52 <ski> well, multiplicative or is one of the harder things to understand in linear logic
10:26:10 <tac-tics> I know I would want to take my term a and the supposed type A and derive a proof of |- a : A 
10:26:58 <tac-tics> I suppose I just want to do the same exact thing
10:27:10 <ski> in one version, one could have `Gamma |- e : A | Delta', where `Gamma' is a value variable environment, and `Delta' is a continuation variable environment (`e' is an expression, that may mention these variables. `A' is a type)
10:27:12 <codeshot> superpat[m], then using alterF it should be practical to avoid the second traversal of the map too
10:27:21 <tac-tics> and when typechecking a program, I am not allowed to end with |- b : B, c : C because I only have one term in the end
10:27:43 <tac-tics> ski, what is the | there for?
10:27:47 <ski> one can also imagine stuff like `... |- e0 : A , e1 : B', where we have multiple expressions to the right .. this is more interesting
10:28:04 <ski> tac-tics : separating the "focused" conclusion (`A') from the other conclusions
10:28:29 <ski> in terms of proof terms, it separates the (value) expression to be typed, from the continuation variables that it may use
10:28:50 <ski> iirc someone (Girard ?) called it the "stoup"
10:30:17 <ski> in any case, with multiple expressions on the right, we get the interesting feature that variables bound in one expression can be used in the other expression (seemingly out of scope)
10:32:28 <ski>   |- (\x. {}) : A -o _|_ , (\(). x) : T -o A
10:33:50 <ski> (`_|_' is multiplicative false, `{}' is the "abort" (or "kill thread") expression of that type. `T' is multiplicative true ("unit"), with `()' the value of that type)
10:34:39 <Ero> johnw: so in essence it is a bit like how the IO monad already works?
10:34:45 <danharaj> T is additive conjunctive unit, 1 is multiplicative conjunctive unit
10:35:06 <ski> danharaj : in Girard's notation, yes
10:35:38 <danharaj> sorry, i just scanned and saw "Girard" and "T is multiplicative" :p
10:37:16 <johnw> Ero: it might be how the IO monad is coded, but there's no restriction on how the IO monad is used. That's what Linear types guarantee.
10:37:48 <shapr> Anyone want to hack some Haskell in Boston between Nov 27 and Dec 8?
10:38:02 <tac-tics> And why are they called the multiplicative and additive versions of things?
10:38:03 <shapr> johnw: are you near Boston in that time frame?
10:38:45 <tac-tics> if I'm not mistaken, it's really about "and" and "or" oriented towards a producer vs a consumer, right?
10:39:06 <ski> (i prefer ⌜1⌝ being the categorical terminal object, ⌜×⌝ (`*') being the categorical product, and ⌜+⌝ being the categorical coproduct, reserving ⌜⊤⌝ (`T') for the "tensorial unit" (multiplicative true), and ⌜⊕⌝ (`(+)')) for multiplicative disjunction)
10:39:24 <johnw> shapr: no, Seattle
10:39:27 <danharaj> tac-tics: multiplicative connectives combine the contexts of their premises. the premises of additive connectives are in "superposition"
10:39:29 <shapr> too bad, worth asking
10:40:08 <ski> tac-tics : multiplicative conjunction distributes over additive disjunction. multiplicative disjunction distributes over additive conjunction
10:40:28 <danharaj> yes, the terminology comes from isomorphisms that behave like addition and multiplication
10:41:35 <Ero> johnw: linear types guarentee how IO a is used?
10:41:43 <tac-tics> ski, But the other combinations don't distribute at all?
10:41:49 <tac-tics> danharaj, that's an interesting perspective
10:42:25 <johnw> Ero: it guarantees how you use a certain API on top of IO, like working with files
10:42:48 <danharaj> tac-tics: http://llwiki.ens-lyon.fr/mediawiki/index.php/Sequent_calculus#Equivalences
10:43:02 <ski> tac-tics : there is an entailment from `A (*) (B (+) C)' to `(A (*) B) (+) C', but not in the other direction. this is similar to going from `(A,C -> B)' to `C -> (A,B)' in Haskell
10:43:32 <tac-tics> "Adjunctions, how do they work?" :P
10:43:48 <tac-tics> I guess maybe I should ask, is there a tidy categorical theory of linear logic?
10:43:48 <Ero> johnw: so linear logic provides a set of laws that guarentee... distribution of state?
10:43:55 <tac-tics> In the way that a CCC is the lambda calculus?
10:44:32 <Eduard_Munteanu> Linearity enforces threading of the RealWorld at type level.
10:44:50 <ski> with `A (*) (B (+) C)' we get an `A', and separately from that, we get an "interaction between a potential `B' and a potential `C'" (information used when destructing one of them may affect how the other one develops)
10:45:10 <ski> with `(A (*) B) (+) C', suddenly `A' can also interact with `C', not only `B'
10:45:12 <danharaj> tac-tics: *-autonomous categories and traced monoidal categories depending on how you want to model it. but neither is really satisfactory
10:45:38 <johnw> Ero: linear logic only allows types to express that a value *must* be used exactly once
10:45:51 <johnw> what you do with that, what it means for your API, is up to you
10:46:01 <Ero> huh, ok that makes a lot of sense now
10:46:29 <johnw> turns out it can be a very handy restriction
10:46:44 <Ero> Although... I would of thought that sort of thing was obvious? whats the big difficulty behind its implementation?
10:47:02 <johnw> it's a new kind of type, a restriction that didn't exist previously
10:47:04 <Ero> is it a case of retroactively putting it into all the existing work?
10:47:39 <Ero> i see
10:47:42 <johnw> because you can't just have a new type Linear, you also need the type checker to enforce this "value of such a type is used only once" property, which requires examining how those values are used
10:47:57 <johnw> so rather than do it with a weird type abstraction (which *has* been done, btw)
10:48:23 <Ero> yea i would of thought the point of haskell would be to use a type abstraction?
10:48:28 <johnw> you make it internal to the type system, so that a type like a ->. (a, a) suddenly becomes impossible to write
10:48:29 <Ero> what makes that so weird?
10:48:43 <johnw> i mean, a value of that type becomes impossible to construct (without undefined)
10:48:48 <wat_is_stack> How do I use stack ghci if I'm using stack script?
10:48:55 <johnw> the type abstraction route is _very_ awkward
10:49:08 <Ero> ok
10:49:08 <johnw> see https://www.cis.upenn.edu/~jpaykin/papers/pz_linearity_monad_2017.pdf
10:49:13 <Ero> thx once again johnw 
10:49:24 <johnw> that's very recent work, presented at ICFP, and I spent several hours discussing the approach with its author
10:49:41 <Ero> i love reading papers but i have this issue where after the first ... 2 pages? my ability to comprehend starts to drop off drastically
10:49:55 <johnw> then skim
10:49:55 <Ero> thats so cool johnw 
10:50:06 <johnw> read it for what you can gain, but don't set an expectation
10:50:12 <Ero> one day i hope to be an active participant in computer science like yourself
10:50:14 <johnw> I skip pages in papers all the time
10:50:32 <Ero> thanks for the advice, that gives me encouragement
10:50:37 <erisco> it took weeks or months to come up with the paper, so don't expect to understand it all so quickly
10:52:07 * danharaj skimmed a book 3 or 4 times before trying to read it page-by-page
10:52:22 <Ero> i'm a bit of a dreamer, so i come up with things that seem right to me but without an accurate understanding of whether or not im in the realm of possibility
10:52:38 <johnw> think of the material as existing to serve your interests, not you to serve it as a reader :)
10:52:56 <Ero> thats... really profound lol
11:02:31 <sternmull> I have two functions that result in an ExceptT with the same error type (but different result types). Both use throwError to abort if something goes wrong. Is there a way to call one function inside the other and have its error "bubble" up? It would also be nice if i could handle it to add some context to the error before it aborts the outer function.
11:05:44 <monochrom> I thought you could just do it?
11:05:46 <johnw> this is exactly what "bind" means for ExceptT
11:05:59 <johnw> you can compose the two actions, and either way can abort the composition
11:06:02 <johnw> s/way/one
11:08:27 <sternmull> i probably do it totally wrong, here is what it looks like at the moment: http://lpaste.net/359951
11:08:58 <johnw> looks ok to me, what's the problem?
11:09:07 <johnw> oh, the error there, duh
11:09:12 <sternmull> :)
11:09:17 <johnw> you need a runExceptT
11:09:25 <johnw> no, no wait
11:09:48 <johnw> you're evaluating msg where an action is wanted
11:09:58 <lyxia> what do you think putting msg on line 28 does
11:09:59 <sternmull> runExceptT gives me an Either, i would prefer to only continue if it is Right and then directly with the value inside Right.
11:10:01 <johnw> just comment out that line, it's not doing anything
11:10:18 <johnw> you don't need to worry about that
11:10:27 <johnw> once an exception happens, srvClientImpl won't continue any further
11:10:42 <monochrom> This is not how you annotate type.
11:10:48 <sternmull> johnw: But i want to use msg as an Msg later in the code
11:10:54 <johnw> that's fine
11:11:02 <monochrom> Again, this is not how you annotate type.
11:11:03 <johnw> what you're doing is OK, just don't evaluate msg the way you are now
11:11:49 <sternmull> ah... i think i get it. Its not a value but an action that results in an Msg!
11:12:09 <lyxia> BTW at line 5 you want to use ScopedTypeVariables
11:12:10 <monochrom> No. msg is a Msg value
11:12:20 <monochrom> Again, this is not how you annotate type.
11:12:26 <johnw> readMsg h is the action that results in a value of type Msg
11:12:28 <johnw> just delete line 28
11:12:40 <johnw> and write the rest of your client implementation
11:13:05 <sternmull> johnw: Ok, thanks.
11:13:43 <iqubic> What is the issue we are tackling.
11:14:18 <monochrom> You were taking inspiration from "let { x = 5; x :: Int }" and just extrapolating that this would work for do-blocks too with just s/=/<-/.
11:14:29 <monochrom> And you were wrong.
11:14:39 <iqubic> I missed the problem statement.
11:14:43 <johnw> monochrom: how about showing him a way that _would_ work?
11:14:55 <johnw> insisting that it's wrong won't help much, if he thought that this would work
11:15:16 <monochrom> You already did. I won't be redundant.
11:15:36 <monochrom> And you didn't cover my point so someone has it.
11:15:42 <sternmull> lyxia: Well... i tried it with ScopedTypeVariables. But then it works only if i do "Right (val :: a) -> return val" and not if i do "Right val -> return (val :: a)". And i don't really understand the problem of that function. I would expect it to work without any explicit type annotation inside the function because i expect return type to already define everything that is needed. But GHC doesn't see it my way.
11:16:17 <lyxia> sternmull: To use ScopedTypeVariables you need to add "forall a." at line 2
11:16:51 <lyxia> sternmull: without that extension and that binder the variable a at line 5 is totally unrelated to the one at line 2
11:17:11 <iqubic> Can I see the code we're working with?
11:17:16 <lyxia> iqubic: http://lpaste.net/359951
11:17:52 <monochrom> You should learn to use your scroll buffer.
11:18:06 <iqubic> monochrom: I just joined.
11:18:16 <iqubic> I don't have the paste in my buffer.
11:18:49 <tabaqui> funny
11:18:52 <sternmull> lyxia: I don't understand why the type of "return val" is not derived/unified/whatever with the return type "ExceptT String m a". But i will later look into your "forall" suggestion. Hopefully i will understand it at some point.
11:19:02 <monochrom> You think I didn't check before I said that?
11:19:21 <tabaqui> allocate (pure ()) (\_ -> print "Free") >> resourceForkIO (sleep 5)
11:19:25 <tabaqui> doesn't print anything
11:19:45 <tabaqui> looks like GC collects child thread
11:19:54 <lyxia> sternmull: ah I didn't pay attention, this is indeed strange
11:20:06 <tabaqui> while resource monad think that it holds the release action
11:20:10 <tabaqui> dunno
11:21:43 <codeshot> sternmull if you just want to ensure your msg is a Msg to keep the possible type errors limited try "pure (msg :: Msg)" instead of just "msg :: Msg"
11:21:49 <tabaqui> I bet on a bottle of whiskie that will not memory leak-free application with resourceT
11:21:56 <codeshot> otherwise you shouldn't need that line at all
11:21:56 <tabaqui> *will not build
11:22:36 <sternmull> codeshot: That does it. Thanks!
11:23:40 <sternmull> that line was just to check if the type was what i expected... and i expressed my intention the wrong way.
11:23:53 <codeshot> on a line on it's own in do notation, msg is a pure value being used as a monadic one, so you have to say "pure value" instead of just "value"
11:24:18 <codeshot> "return" is another name for "pure", but you can see above why pure is a better name once you get past the basic examples
11:25:20 <sternmull> codeshot: Yeah.. my understanding of monads is still a bit unprecise. Still have to get used to all the type puzzles. But its getting better every day.
11:25:31 <codeshot> this was my experience too
11:27:54 <Psybur> Anybody have an idea why `runMemoized` returns different results than `fib` ? https://glot.io/snippets/evddj6b52p
11:28:56 <monochrom> Oh man I have to scroll back and forth just to read 27 lines of code in a 10-line window?!
11:32:53 <Psybur> monochrom, sorry Ill put it somewhere else :D
11:33:01 <monochrom> Is it just because fibs is [Integer] but runMemoized is Int?
11:33:16 <Psybur> monochrom, let me take a look
11:33:33 <monochrom> Oh it's OK I found the editor window size setting.
11:34:33 <dropout> I'm going through Write Yourself a Scheme in 48 Hours (http://bit.ly/2AsHG9o). Why the author use monad operators at places where functor operators will be sufficient? I've seen it so many times. What are the benefits?
11:36:22 <codeshot> monochrom, the cog icon at top-right lets you increase the number of lines
11:36:31 <codeshot> ah, I see you found it
11:36:36 <dropout> (Bad link, sorry. Should be the overall page)
11:37:44 <monochrom> dropout: It was written decades ago. Back then, sometimes we forgot the functorness of monads.
11:37:46 <Psybur> monochrom, I see. Does Int have wrapping issues?
11:37:54 <monochrom> Yes.
11:38:02 <codeshot> Psybur,  why `runMemoized` returns different results than `fib` . After fibbing a lot, remembering all the fibs becomes difficult and you start to return the truth sometimes ?
11:38:10 <monochrom> > 2^100 + 1 :: Int
11:38:12 <Psybur> codeshot, :D
11:38:12 <lambdabot>  1
11:38:20 <Psybur> monochrom, thanks a lot
11:38:37 <monochrom> > 2^100 + 1 :: Integer
11:38:39 <lambdabot>  1267650600228229401496703205377
11:38:51 <monochrom> Now of course I don't know whether it really is correct. :)
11:40:03 <lavalike> > log (1267650600228229401496703205377 - 1) / log 2
11:40:05 <lambdabot>  100.0
11:40:35 <monochrom> Although, I don't understand "excluding -29 digits".
11:40:42 <dropout> monochrom: Oh, I understand. Are there any performance benefits to use functors over monads?
11:41:01 <monochrom> I don't think there is any.
11:41:13 <dropout> Thanks.
11:42:11 <monochrom> In principle there could be. I don't think we know of an actual case that happened.
11:44:00 <monochrom> Psybur: I erred. fibs :: [Int] too.
11:45:03 <kwf> Hi all - does anyone want to help me troubleshoot using ghcid in a stack project?
11:45:23 <kwf> I'm getting a bewildering error
11:46:06 <kwf> Specifically:
11:46:14 <kwf> No files loaded, GHCi is not working properly.
11:46:14 <kwf> Command: stack exec --test -- ghci -fno-code src/Variadic.hs
11:46:16 <monochrom> I'm now wondering if it's an off-by-1 error. "last (take n xxx)" is "xxx !! (n-1)"
11:48:19 <codeshot> monochrom, that expression is in fibs
11:48:22 <codeshot> so it can't be
11:48:39 <monochrom> No, it's in fib, not fibs.
11:48:48 <codeshot> Why do you think your first idea is wrong? fibs n is whatever type n is
11:49:07 <codeshot> yeah, typo, same conclusion though
11:49:11 <monochrom> Um, fibs is a list, there is no "fibs n".
11:49:21 <codeshot> yeah, you can see the typo though can't you
11:49:36 <monochrom> fib n 's type is not going to be n's type.
11:49:58 <monochrom> fib n = fibs !! (n-1) in a nutshell.
11:50:39 <codeshot> oh yeah re. the type thing
11:50:56 <monochrom> So if you try to ask for "fib 10" or "runMemoized 10" you will get the same answer as fibs!!9 not fibs!!10
11:51:18 <codeshot> fib n is Int when used in runMemoize because the type of the values in the map is overconstrained
11:52:23 <codeshot> Psybur, should be: runMemoized :: Int -> StateT (Map Int a) IO a
11:52:30 <codeshot> try that and let us know
11:52:40 <monochrom> You need "Num a" or something.
11:52:55 <codeshot> yop monochrom = super
11:53:01 <monochrom> Oh maybe Ord a too.
11:53:10 <codeshot> Psybur, should be: runMemoized :: Num a => Int -> StateT (Map Int a) IO a
11:53:16 <codeshot> No, ord would be for the key
11:53:27 <codeshot> but it would be a better function
11:53:37 <codeshot> Psybur, should be: runMemoized :: (Num a, Ord k) => Int -> StateT (Map k a) IO a
11:53:45 <monochrom> Ah.
11:54:21 <monochrom> No, you want k to be Int, or whatever you write in "Int ->"
11:54:28 <codeshot> Psybur, should be: runMemoized :: (Num a, Ord k) => k -> StateT (Map k a) IO a
11:55:27 <monochrom> No, "take" will force k to be Int.
11:55:43 <codeshot> then we don't want take
11:56:23 <codeshot> we want the map type to be our worst constraint
11:56:27 <mniip> ooh I have a cool function for this somewhere
11:57:09 <mniip> @let memoTree f = lup (jn (p2 (-1) 0) 0 (p2 0 1)) where jn l a r = Free (Compose ((a, f a),bool l r)); lup (Free (Compose ((b, x), f))) a = case compare a b of { LT -> lup (f False) a; EQ -> x; GT -> lup (f True) a }; p2 i j = if i >= 0 then jn (bi i j) j (p2 j (2 * j)) else jn (p2 (2 * i) i) i (bi i j); bi i j = let m = (i + j) `div` 2 in jn (bi i m) m (bi m j)
11:57:10 <lambdabot>  Defined.
11:57:13 <mniip> :t memoTree
11:57:14 <lambdabot> Integral t => (t -> p) -> t -> p
11:57:43 <monochrom> Well, you could do a "fib n = fibs !! fromIntegral n" to be general. Or (n-1) I don't know which.
11:58:44 <mniip> @let fibs = memoTere go where go 0 = 1; go 1 = 1; go n = fibs (n - 1) + fibs (n - 2)
11:58:45 <codeshot> actually, I think we want to label each element of fibs and find the first (==) label
11:58:45 <lambdabot>  .L.hs:164:8: error:
11:58:46 <lambdabot>      • Variable not in scope: memoTere :: (a -> p) -> a -> p
11:58:46 <lambdabot>      • Perhaps you meant ‘memoTree’ (line 170)
11:58:51 <mniip> @let fibs = memoTree go where go 0 = 1; go 1 = 1; go n = fibs (n - 1) + fibs (n - 2)
11:58:52 <lambdabot>  Defined.
11:58:54 <mniip> > fibs 1000
11:58:55 <codeshot> this will naturally force the correct strictness
11:58:56 <lambdabot>  7033036771142281582183525487718354977018126983635873274260490508715453711819...
11:59:36 <codeshot> mnip, unfortunately the user is learning by writing his/her own memoize function
11:59:54 <mniip> well then I don't expect them to be abnle to read mine!
12:00:31 <Psybur> Ok, here is the final result. Yes, take was giving me grief with the whole Int/Integer thing :D https://pastebin.com/n7wA1cRK
12:01:20 <Psybur> mniip, you crazy :D
12:01:38 <codeshot> Psybur, nice
12:01:51 <codeshot> Did you see my memoize earlier? I thought it was more idiomatic
12:02:09 <codeshot> it should have identical performance characteristics (I think)
12:02:38 <mniip> who needs Map when you have Free (Compose (Writer (t, p)) (Reader Bool))
12:04:14 <codeshot> Psybur, you're using insert, which means you're not memoising
12:04:27 <codeshot> you need insertWith (flip const) instead
12:04:37 <Psybur> codeshot, I follow what you mean with that type signature. I made the types explicit because I dont intend for that runMemoized to be a generic function for running things in a memoized fashion. I named that function poorly :D
12:04:55 <Psybur> codeshot, it does memoize
12:04:56 <codeshot> ah, but you asked about idiomatic ;)
12:05:00 <lyxia> mniip: nice. This looks so efficient.
12:05:10 <codeshot> and that means keeping to the most general type
12:05:27 <codeshot> mniip, I'm intrigued by your type
12:05:41 <Psybur> codeshot, yes, I think more idiomatic approach would be to skip the runMemoized thing and use another mapM over a mapM fibMemoize that shortens the text
12:06:40 <Psybur> Im nt sure what you mean about inserWith (flip const) though. It is already memoizing
12:06:42 <mniip> data M a b = T b | B (M a b) a b (M a b)
12:07:07 <mniip> type MF a b c = (a, b, c, c)
12:07:11 <codeshot> oh yeah, you lookup to decide if there's a value there
12:07:23 <mniip> M a b ~ Free (MF a b) b
12:08:08 <codeshot> mniip, I heard Free often gives non-optimal code and Codensity is often used to improve it. Does that apply to your type?
12:08:19 <mniip> MF a b c ~ (a, b, Bool -> c) ~ ((a, b), Bool -> c) ~ Compose ((,) (a, b)) ((->) Bool)
12:08:22 <monochrom> I think no.
12:08:57 <Psybur> Ive heard about the Church encoded Free. Think its just F?
12:09:00 <monochrom> mniip is using Free as a data tree structure rather than a free monad.
12:09:18 <codeshot> ah, thanks
12:09:32 <codeshot> That has given me a clue to learn more
12:09:49 <Psybur> Why use Free instead of another datatype like [] ?
12:10:10 <Psybur> Sorry, not like "another datatype"
12:10:16 <monochrom> Free is closer to binary trees than [].
12:10:24 <Psybur> If youre using Free like a structure and not a monad, why not use []
12:10:34 <mniip> [] doesn't give you a buinary recursion
12:10:43 <mniip> see MF a b c contains two c's
12:10:53 <codeshot> Am I right that free is a type-level fix with monadic structure?
12:11:01 <monochrom> Yes.
12:11:04 <mniip> I could use a type-level Fix too yes
12:11:09 <mniip> but that would add another compose
12:11:09 <codeshot> okay, I'm on track
12:11:13 <mniip> which is sheared off by Free anyway
12:11:45 <iqubic> mniip: Type level Fix is Free.
12:11:54 <mniip> no
12:12:00 <mniip> compare
12:12:16 <codeshot> Fix is type level fix
12:12:20 <mniip> data Free f a = Pure a | Free (f (Free f a))
12:12:28 <mniip> data Fix f a = Fix (f (Fix f a))
12:12:46 <iqubic> Right, Free is a terminating Fix.
12:13:14 <iqubic> How does one construct a thing of type Fix?
12:13:58 <mniip> errr
12:14:01 <mniip> sorry
12:14:06 <mniip> data Fix f = Fix (f (Fix f))
12:14:10 <mniip> no a's
12:14:28 <iqubic> Fix has kind (* -> *) -> * I think
12:14:31 <mniip> yes
12:14:39 <iqubic> How do you construct something of type Fix?
12:14:43 <mniip> like usual
12:15:19 <mniip> Fix Maybe ~ Nat
12:15:23 <iqubic> But it's a recursive type. 
12:15:24 <mniip> Fix ((,) e) ~ Stream e
12:15:35 <mniip> Fix (Compose ((,) e) Maybe) ~ [e]
12:15:40 <iqubic> I see.
12:15:53 <Tuplanolla> :t Fix Nothing :: Fix Maybe
12:15:55 <lambdabot> Fix Maybe
12:16:01 <dropout> Why parameters of (<$>) are not flipped? It would be possible to chain functions (x <$> f1 <$> f2) like it is possible with monads? Why it was chosen like that? What I'm missing?
12:16:03 <iqubic> What does Compose do?
12:16:18 <mniip> Tuplanolla, I don't think that type restruction was necessar
12:16:19 <lyxia> dropout: that way it looks like function application
12:16:23 <mniip> iqubic, why don't you look that up
12:16:40 <lyxia> dropout: there's   (<&>) = flip (<$>)   in some places
12:16:40 <monochrom> I think iqubic is looking it up.
12:16:44 <iqubic> I am
12:16:50 <mniip> dropout, there's a series of functions like & and <&> in lens
12:17:01 <monochrom> I think iqubic uses their left hand to ask in IRC and their right hand to ask Google.
12:17:03 <dropout> Thanks.
12:17:07 <codeshot> Psybur, https://pastebin.com/HbA4fVjy
12:17:11 <iqubic> I see.
12:17:27 <monochrom> So I think you can safely ignore all their questions. They're just thinking aloud.
12:17:35 <monochrom> Don't answer to answer. Just don't answer.
12:17:50 <iqubic> monochrom: That's more or less correct.
12:18:38 <sternmull> The documentation for Data.ByteString.hGetNonBlocking says "Note: on Windows and with Haskell implementation other than GHC, this function does not work correctly; it behaves identically to hGet.". Does that mean it blocks on windows even with GHC? Or does GHC support nonblocking behavior on all platforms?
12:18:40 <Psybur> Hows this for idiomatic? :D https://pastebin.com/uuRpJBM5
12:18:45 <Psybur> codeshot, ill take a peek now :D
12:19:00 <monochrom> To chain functions I'm fmapping, I would just use (g . f) <$> x 
12:20:11 <dropout> monochrom: That just seems less readable for me.
12:20:15 <Psybur> codeshot, so youre skipping the Maybe check and doing it all in one go? Cool
12:21:16 <Psybur> codeshot, whats with the "!" in gets ?
12:21:45 <monochrom> Is it because "g (f x)" is readable and "(g . f) x" is not readable?
12:23:24 <codeshot> operator form of lookup
12:23:31 <dminuoso> dropout: I found that a lot of "this seems unreadable to me" comes from not being used to haskell, and b not seeing the patterns as intended.
12:23:34 <codeshot> but I didn't notice you have import Data.Map as M
12:23:48 <Psybur> Interesting
12:24:04 <dminuoso> dropout: Had the same revelation about <$> the other day, where I asked why it existed together with fmap.
12:24:23 <dminuoso> Well. Asked myself anyway.
12:24:31 <codeshot> I almost always use (foo <$>) instead of (fmap foo)
12:24:39 <Psybur> codeshot, so you are retrieving the result from the state? So you have to traverse the tree after calculating?
12:24:49 <codeshot> yes, instead of before
12:24:55 <dminuoso> codeshot: That however feels less intuitive. To me <$> expresses application, fmap expresses lifting.
12:25:11 <codeshot> liftA expresses lifting
12:25:20 <codeshot> fmap = (<$>)
12:25:27 <iqubic> liftA confuses me.
12:25:32 <iqubic> :t liftA
12:25:33 <lambdabot> Applicative f => (a -> b) -> f a -> f b
12:25:43 <dminuoso> iqubic: It comes from historic times.
12:25:54 <iqubic> :t ap
12:25:55 <lambdabot> Monad m => m (a -> b) -> m a -> m b
12:26:13 <iqubic> :t <*>
12:26:14 <lambdabot> error: parse error on input ‘<*>’
12:26:22 <dminuoso> codeshot: Well, to me `fmap` has been burned into mind to mean `lifting` :)
12:26:24 <codeshot> take a function that applies a pure function to a pure value, and return one that applies an applicative function to an applicative value
12:26:30 <m4lvin> :t (<*>)
12:26:31 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
12:26:43 <dminuoso> codeshot: Also liftA may not be available if your functor is not an applicative.
12:26:45 <iqubic> :t (<*>)
12:26:46 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
12:26:54 <dminuoso> so, fmap is the only thing you have to generally express lifting in a clean way
12:27:04 <dropout> Is there any reason why <&> is not part of Prelude?
12:27:15 <monochrom> To me, fmap expresses prefix, <$> expresses infix. That's all. Superficial cosmetic difference.
12:27:22 * codeshot begins forging a brand in the shape of (<$>)
12:27:32 <codeshot> hold still there dminuoso
12:28:18 <monochrom> And liftA and liftM are just there for the sake of completeness.
12:28:20 <codeshot> dropout, my guess is that it would be nice to reserve it until someone deduces a meaning that parallels <|>
12:28:38 <dminuoso> monochrom: I guess the real question is, why is fmap not called lift?
12:28:46 <dminuoso> or liftF 
12:28:50 <mnoonan_> or “map” :|
12:28:55 <dminuoso> :|
12:29:09 <dminuoso> mnoonan_: why map?
12:29:34 <codeshot> dminuoso, because it doesn't lift, it's only builds a kleisli morphism from a pure function rather than lifting the pure function
12:29:37 <monochrom> Like you have to purchase both Park Place and Boardwalk in order to build house on Boardwalk, and you have to build almost the same number of houses on Park Place too, so you let Park Place exist for the sake of completeness but it doesn't mean you really care.
12:30:05 <mnoonan_> because map :: (a -> b) -> [a] -> [b] took the good name with a restrictive type
12:30:28 <mnoonan_> actually, I guess “fap” is the best name (for “functor application”, obviously). dunno why it wouldn’t catch on.
12:30:28 <monochrom> I think "lift" is not always the right analogy.
12:30:51 <monochrom> Sometimes actually "demote" is the right analogy.
12:30:52 <iqubic> :t lift
12:30:53 <lambdabot> (Monad m, MonadTrans t) => m a -> t m a
12:31:10 <iqubic> Lift is different than what I think it should do.
12:31:24 <iqubic> Why do you need MonadTrans there?
12:31:51 <iqubic> Why not just have (Monad M, Monad T) => m a -> t m a
12:32:02 <dminuoso> monochrom: What notion of "lift" do you have to say it doesnt fit?
12:32:11 <codeshot> oh, wait, I just imagined the type of fmap all wrong and I now know it intuitively
12:32:15 <codeshot> how dumb of me
12:32:45 <codeshot> it does lift
12:32:49 <codeshot> it exactly lifts
12:32:55 <monochrom> map f [1,2,3] = [f 1, f 2, f 3] does not look like lifting f. It looks like embedding or sprinkling or hiding f's in a pudding.
12:33:27 <iqubic> map isn't a form of lift is it?
12:33:42 <dminuoso> iqubic: map is.
12:33:48 <iqubic> it is?
12:34:01 <dminuoso> monochrom: Well, let's drop the list for a second. map f, what does map do?
12:34:12 <dminuoso> it changes f into a different but related function
12:34:20 <hexagoxel> dropout: there are also functors for which fmap is sufficiently expensive that you will prefer (fmap (g . f)) or (<&> (f .> g)) over two fmaps.
12:34:26 <iqubic> It applies f to all elements of a list.
12:34:40 <monochrom> Is [X] "higher" than X? Is IO X "higher" than X?
12:34:43 <codeshot> why do we have fmap, liftM, liftA ? instead of just fmap ?
12:34:49 <dminuoso> iqubic: map is just fmap but limited to lists, nothing else.
12:35:17 <monochrom> And for that matter does return/pure "lift" too? return/pure :: a -> [a]/IO a
12:35:26 <iqubic> but fmap is not a lifting function right?
12:35:30 <dminuoso> codeshot: historical reasons. back then Applicative and Monad were not in the inheritance they are now.
12:35:41 <codeshot> that explains the excess liftA
12:35:45 <dminuoso> codeshot: at some point it was made so that Monad is an Applicative is a Functor.
12:35:47 <codeshot> but not the excess liftM
12:35:55 <monochrom> codeshot: See what I said about Park Place :)
12:36:21 <geekosaur> liftM was to recover fmap from Monad since, having no Applicative constraint, it also had no Functor
12:36:51 <codeshot> Monad didn't derive from Functor either?
12:36:55 <dminuoso> codeshot: correct
12:36:56 <codeshot> ok
12:37:27 <dminuoso> codeshot: All books I read discourage the usage of liftA and liftM, and just point towards fmap and <$>
12:37:44 <codeshot> that's why Monads have been so difficult to learn, not being an extension of more basic tools ...
12:37:47 <codeshot> I guess
12:39:10 <monochrom> OTOH some teachers could not come up with a story that goes from functor to monad. (They already had an independent monad story.) (They spoke up in haskell-cafe, that's how I know.)
12:39:12 <fakenullie> :t on
12:39:14 <lambdabot> (b -> b -> c) -> (a -> b) -> a -> a -> c
12:39:38 <monochrom> Actually more precisely they could go functor->applicative but couldn't do applicative->monad.
12:40:26 <codeshot> iqubic, lift is a method of MonadTrans used to access a Monad that has been built upon by a monad transformer
12:41:10 <dminuoso> codeshot: I found Monads hard to grok in the beginning because they are a highly generalized concept. But by just using them with some simple directed assignments I discovered what they were about after a short while.
12:41:13 <monochrom> Teaching is hard. Let's just download Haskell to your brain.
12:41:37 <codeshot> pure makes a kleisli morphism relative to a pure category, and lift makes an parallel morphism relative to a monad category
12:42:59 <iqubic> codeshot: I get what lift does.
12:42:59 <iqubic>  
12:43:01 <dminuoso> monochrom: Curious, what do you mean by "couldn't do applicative->monad" ?
12:43:41 <monochrom> They don't know how to explain that monad builds upon applicative.
12:43:52 <monochrom> And they probably don't know why themselves, too.
12:44:08 <codeshot> I'm only just scratching the surface of Monads. I'm starting to see the division into 2 spaces, one of answers + no answer, and one for the nature of the process of answering
12:44:13 <iqubic> I just don't understand why you need the MonadTrans constraint for lift.
12:44:47 <codeshot> because it only shares elements of its name with liftA and liftM
12:45:10 <codeshot> it's lifts in a different dimension
12:45:55 <codeshot> fmap, liftA and liftM lift a value across an incoming functor
12:46:54 <codeshot> lift lifts the context of a monadic action across an interleaved monad embellishment/decoration
12:47:10 <dminuoso> codeshot: fmap does not lift values.
12:47:14 <dminuoso> codeshot: fmap lifts functions.
12:47:21 <codeshot> yes, sorry
12:47:44 <codeshot> pure lifts a value across an incoming functor
12:49:27 <codeshot> lift seems like it's actually the opposite of lifting in that other dimension because its the context in which you're writing that's lifted rather than what you've just written
12:50:26 <codeshot> so what you've just written actually gets depressed
12:50:37 <ongy> :t when
12:50:38 <lambdabot> Applicative f => Bool -> f () -> f ()
12:50:40 <dminuoso> codeshot: I suppose in a way "transport" or "beam" is a little more fitting since it lacks the notion of "up" and "down"
12:50:58 <ongy> is there a conceptional reason this is on () and not mempty? Or is it just "because it was done like this"
12:51:00 <codeshot> yeah, but the directionality is still important
12:51:07 <dminuoso> codeshot: the directionality is a circl
12:51:09 <dminuoso> circle
12:51:11 <ongy> er, Monoid, return mempty on False
12:51:17 <dminuoso> Since we are mostly just talking about Endofunctors when we say Functor.
12:51:45 <codeshot> Not sure about that. That requires the two end categories to be isomorphic with each other
12:52:04 <codeshot> unless you've got some fixedpoint functor
12:52:12 <codeshot> (categorically speaking)
12:55:34 <dminuoso> codeshot: categorically speaking when we say functor we mean endofunctor in Hask.
12:55:44 <codeshot> yeah, but that's the Functor type
12:56:37 <codeshot> when talking about lift with respect to Monads (including the composed monads of MonadTrans) there are functors between categories which are then embedded in Hask
12:57:33 <fresheyeball> hey out there, I am struggling to make regex work in Haskell
12:57:58 * shapr hops quietly
12:58:07 <codeshot> and those functors parallel the functors between categories that are embedded in Hask and represented by Functor instances
12:58:16 <fresheyeball> I have it working fine in an online tester
12:58:25 * codeshot pokes shapr in the bladder to hasten the panic
12:58:29 <fresheyeball> but the tester is PCRE and Haskell is POSIX
12:58:42 <shapr> codeshot: nooo, I'm writing a parser!
12:59:19 <codeshot> oh marvellous
12:59:59 <shapr> SDP parser, even
13:00:22 <lavalike> fresheyeball: If the mountain will not come to Muhammad, then Muhammad must go to the mountain.
13:01:07 <fresheyeball> lavalike: deeep
13:01:56 <lavalike> that is to say, I guess you should either use a PCRE package for haskell or a POSIX test tool (:
13:02:00 <shapr> is there an online posix tester?
13:02:06 <shapr> I thought that's what lavalike meant.
13:02:46 <shapr> codeshot: are you writing something nifty?
13:02:54 <geekosaur> yes, there are also regex testers that let you select which variant you're using
13:03:05 <fresheyeball> geekosaur: I couldn't fine one
13:03:13 <lavalike> https://regex101.com
13:03:47 <fresheyeball> lavalike: Where is the posix option. That is actually the tester I was using
13:03:57 <lavalike> "golang"
13:04:16 <lavalike> if I am not 
13:04:20 <iqubic> Go is terrible .
13:04:53 <lavalike> I think at least!
13:05:19 <fresheyeball> shit
13:05:23 <fresheyeball> same result
13:05:24 <lavalike> my first search was for pcre on hackage and that finds some results
13:05:27 <MarcelineVQ> iqubic: what's terrible about it specifically?
13:05:28 <fresheyeball> still works in the tester
13:05:55 <fresheyeball> https://regex101.com/r/hGpPdV/1
13:06:04 <lavalike> maybe I'm wrong about the flavor it supports
13:06:31 <fresheyeball> http://lpaste.net/4342527990014410752
13:07:11 <geekosaur> .*? is not posix
13:07:43 <fresheyeball> geekosaur: posix equivlant? 
13:08:16 <geekosaur> in this case, [^/]*
13:09:37 <geekosaur> wow there's a lot of confusion out there. half the sites that claim "posix re" actually mean pcre
13:09:48 <fresheyeball> geekosaur: no shock
13:09:53 <monochrom> dminuoso: https://mail.haskell.org/pipermail/haskell-cafe/2015-November/122258.html
13:09:58 <fresheyeball> still not finding an online tester
13:10:36 <geekosaur> I'm not seeing the one I'd found before (but didn't bookmark because I don't need them...) that let me select a bunch of different regex forms including posix bre and ere
13:11:24 <geekosaur> (that would actually be a good discriminant for finding out if they actually support posix re, come to think of it)
13:11:53 <fresheyeball> subRegex  (mkRegex "/<takt:[^/]*/>/g") "|takt|\1|taktend|"
13:12:07 <geekosaur> also I will take this learning moment to point out that this is a good example of why not to use regex...
13:12:14 <fresheyeball> That results in "|takt|\SOH|taktend|"
13:12:18 <fresheyeball> what the heck is SOH?
13:12:24 <geekosaur> control-A
13:12:39 <geekosaur> > ord '\SOH'
13:12:41 <lambdabot>  1
13:12:43 <codeshot> shapr, I hope so
13:12:48 <dminuoso> monochrom: Mmm, well honestly I dont understand the specialty of Applicative quite yet. Functors are easy, Monads too. Applicative is just in this weird spot, but then again I dont consciously know of any Applicatives that are not Monads.
13:12:59 <codeshot> mainly to learn the very best I can
13:13:17 <geekosaur> you would need \\1 because \1 means something in haskell strings
13:13:24 <geekosaur> but you have no capture so it'd be a runtime error
13:13:47 <fresheyeball> geekosaur: "|takt|\\1|taktend|"
13:14:02 <fresheyeball> you sure?
13:14:18 <geekosaur> yes, but you still have no capture in the regex
13:14:38 <fresheyeball> I changed it to the posix equivlant capture no?
13:14:40 <geekosaur> ([^/]*) perhaps? I am not clear on what exactly you are trying to do
13:14:56 <geekosaur> you have no parens at all in the regex
13:15:13 <geekosaur> what do you think the capture is?
13:15:23 <fresheyeball> In pcre I know
13:15:35 <fresheyeball> but I misunderstood your advice in translating to posix
13:15:48 <geekosaur> I was talking specifically about the .*? sequence
13:16:14 <fresheyeball> geekosaur: I intended it to mean 'whatever' as in capture whatever exists between 
13:16:23 <geekosaur> which doesn't exist in posix, and in this case you have to limit it some other way by noting that it's followed by / so the correct posix pattern is [^/]*
13:16:24 <fresheyeball> "<takt:" and "/>"
13:17:24 <fresheyeball> subRegex  (mkRegex "/<takt:([^/]*)/>/g") "|takt|\\1|taktend|"
13:17:30 <fresheyeball> no change
13:17:33 <fresheyeball> I also tried it with `|
13:17:42 <geekosaur> subRegex  (mkRegex "/<takt:([^/]*)/>/g") "|takt|\\1|taktend|" -- but I( am trying to figure out if the leading and trailing / are issues, you might need to escape the internal /s as well if so
13:17:46 <fresheyeball> I also tried it with "\1" instead of "\\1"
13:18:39 <geekosaur> I don;'t think you get to use those, in fact
13:18:48 <geekosaur> nor the g flag
13:19:08 <geekosaur> subRegex  (mkRegex "<takt:([^/]*)/>") "|takt|\\1|taktend|"
13:19:12 <geekosaur> if this is posix ere
13:19:40 <geekosaur> if it is bre then: subRegex  (mkRegex "<takt:\\([^/]*\\)/>") "|takt|\\1|taktend|" -- that is, the ( ) need to be escaped for BRE
13:20:28 <fresheyeball> I just tested both ERE and BRE options
13:21:29 <fresheyeball> and they both yieled the same result
13:21:36 <fresheyeball> |takt|\\1|taktend|
13:22:37 <geekosaur> uh, so the subRegex I see doesn;t work the way you shopwed
13:22:50 <geekosaur> subRegex regex inputstring replacement
13:23:09 <geekosaur> you have the replacement as the input string?
13:23:26 <geekosaur> could you please post actual code and test input to lpaste?
13:23:30 <dminuoso> monochrom: Whats the reason to not even mention it?
13:24:02 <dminuoso> Ohh wait, I misclicked. Reading the entire discussion now.
13:24:05 <fresheyeball> geekosaur: you nailed it
13:24:18 <fresheyeball> I'm a dumbass, and needed `flip`
13:24:26 <fresheyeball> also the capture now works
13:25:04 * shapr hugs cement 
13:26:03 * hodapp nudges at shapr with foot
13:26:05 * hodapp looks around
13:26:09 <fresheyeball> I owe you geekosaur 
13:26:10 <shapr> o hi hodapp!
13:26:13 <shapr> how you doin?
13:26:19 <shapr> Writing some cool Haskell code?
13:26:22 <hodapp> good, just making sure you didn't die there
13:26:24 <hodapp> and nope :|
13:29:03 <SegFaultAX> Is there a general pattern for composing together partial functions? I have a series of functions of the type `f :: String -> Maybe (T String)` and I want to compose them together kinda like `f <|> g <|> h` such that if f fails g will be tried and so on.
13:29:33 <SegFaultAX> First, what's an accurate way to describe that. :) Second, what's a good way to accomplish it.
13:29:37 <monochrom> I think it's exactly <|>
13:29:47 <monochrom> > Just 5 <|> Nothing
13:29:49 <lambdabot>  Just 5
13:30:28 <monochrom> Err I guess not exactly, you have to plug in your parameter, \x -> f x <|> g x <|> etc
13:31:50 <SegFaultAX> Yea. And I have an interesting case where the valid inputs for each functions is mutually exclusive, so really the order doesn't matter (in other words they could be tried in parallel and I would expect either 0 or 1 Just from the group)
13:33:26 <lyxia> asum $ sequence [f, g, h] x   very not readable.
13:34:03 <pierrot> Hi. For an exercise, I'm supposed to implement the lookup function defined here: https://glot.io/snippets/evdgz1dk88
13:34:21 <SegFaultAX> Indeed, something like that had crossed my mind. I have a weird combination of applicative and alternative...
13:34:56 <pierrot> I don't know how to do it. I also don't understand how that structure can be used as a Map k a
13:35:37 <monochrom> Onoes polymorphic recursion.
13:36:10 <SegFaultAX> pierrot: Suggestion: Start by filling out the cases for lookup and thinking about the types for each variant.
13:36:22 <monochrom> I'm pretty sure you're better off posting complete assignment handout and lectures and tutorials and everything.
13:36:43 <pierrot> But there'd be dummy nodes, right?
13:38:30 <SegFaultAX> Admittedly that is a strange tye. Well, Node in particular is odd.
13:38:52 <monochrom> I mean I have taught 2-4 trees and generally B-trees but I wouldn't model them this way, not with polymorphic recursion. So this means your instructor is trying to introduce an extra technique that can only be found in your class and is non-standard.
13:41:12 <monochrom> Node is actually pretty ordinary. A 2-3 tree is such that each node has 2 or 3 keys (or is it 2 or 3 children? I forgot) so you do expect two cases, 1st case two things, 2nd case three things.
13:41:12 <pierrot> I'll give you more details. Let me one minute...
13:43:11 <lavalike> this might be a long shot, but does anyone know how to stop GHCi from going to the background (of the current shell) on CTRL+y? it conflicts with readline's yank, every time I try to paste something instead I background the interpreter, very frustrating!
13:43:20 <monochrom> Oh I guess the polymorphic recursion is an almost-dependent-type way to enforce tree depth, eh? Because we require every leaf to be at the same depth.
13:43:46 <pierrot> monochrom: yes, that's right. 
13:45:44 <pierrot> monochrom: this is the assignment https://i.imgur.com/6AvYl7Z.png. it's an "extension" of the datatype defined in page 199 of this document: http://www.cs.tufts.edu/~nr/cs257/archive/ralf-hinze/finger-trees.pdf
13:48:20 <tiganul80> hi all, can somebody explain me why I get this error http://lpaste.net/359953
13:48:37 <fakenullie> s@(x:xs) matches even on empty list?
13:48:52 <fakenullie> ah, no, I see
13:49:36 <geekosaur> tiganul80, you need parentheses
13:49:43 <tiganul80> found it, function application has higher priority
13:50:31 <geekosaur> yes
13:50:41 <SegFaultAX> Infix operators usually have lower precedence than normal application
13:51:29 <EvanR> usually?
13:51:44 <geekosaur> always. only thing with higher precedence is record update syntax foo {bar = baz}
13:51:45 <SegFaultAX> Is it always?
13:52:02 <suzu> yes
13:52:08 <EvanR> heh
13:52:13 <SegFaultAX> My mistake :)
13:52:17 <EvanR> f x y foo {bar = baz} z
13:52:22 <suzu> function application has the highest precendence to anything, just below record update syntax
13:52:40 <cement> EvanR: stop that
13:52:42 <SegFaultAX> I was hedging on the possibility that you could fix an infix operators precedence to be higher
13:52:45 <SegFaultAX> But I guess not
13:53:12 <tiganul80> if I want to use the result of that, say putStrLn, how can I do it with composition or ($) ?
13:53:16 <pierrot> monochrom: I'm asked if lookup is even possible to implement, so maybe it isn't.
13:54:00 <tiganul80> tried this: putStrLn $ (($).(++))
13:54:03 <tiganul80> fails 
13:54:15 <cement> tiganul80: you're looking for >=>
13:54:25 <cement> or <=<. actually
13:55:00 <SegFaultAX> tiganul80: More to the point, why are you doing that?
13:55:13 <cement> oh wait, you're trying to display the function itself?
13:55:30 <tiganul80> I want to display the result 
13:55:46 <fishythe_> putStrLn $ (($).(++)) "a" "b"
13:55:53 <SegFaultAX> tiganul80: ($) is just really low precendence application.
13:56:02 <pierrot> monochrom: what I see is that, if for example, I want to create a tree for storing countries and its population (in millions), one possible tree would be:
13:56:13 <pierrot> Succ (Succ (Zero "" (Node2 "" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))
13:56:41 <pierrot> but, as I said before, there're "dummy" keys
13:57:04 <pierrot> (I chose "" to be those dummy keys)
13:57:06 <fishythefish> cement: where does kleisli composition come into it?
13:57:12 <cement> it doesn't
13:57:18 <cement> I misread what he wrote
13:57:21 <tiganul80> SegFaultAX, I'm trying to define a function which takes two strings, concatenates them, and outputs the result 
13:57:26 <fishythefish> ah, okay, just checking
13:57:41 <tiganul80> SegFaultAX, using point free syntax
13:58:40 <cement> :t print $ (++)
13:58:41 <lambdabot> error:
13:58:41 <lambdabot>     • No instance for (Typeable a0) arising from a use of ‘print’
13:58:41 <lambdabot>     • In the expression: print $ (++)
13:58:56 <geekosaur> :t (putStrLn .) . (++)
13:58:57 <lambdabot> [Char] -> [Char] -> IO ()
13:59:00 <fishythefish> @pl f a b = putStrLn (a ++ b)
13:59:00 <lambdabot> f = (putStrLn .) . (++)
13:59:10 <fishythefish> i.e. what geekosaur said
13:59:23 <pierrot> monochrom: I also don't know how to do recursion over that type becasuse the type of the arguments would be different in the recursive call
13:59:37 <fishythefish> that said, if it's this much of a struggle to come up with point-free syntax, you're better off not writing it point-free
13:59:46 <lavalike> :t ((.) . (.)) putStrLn (++)
13:59:48 <lambdabot> [Char] -> [Char] -> IO ()
13:59:53 <tiganul80> geekosaur, digesting 
14:00:20 <geekosaur> agreed. pointfree has its uses, but eventually gets in the way of readable / understandable code
14:00:47 <cement> my code's only pointfree if hlint tells me to eta-reduce
14:00:51 <fishythefish> heh
14:02:20 <tiganul80> thank you
14:05:57 <pierrot> monochrom: as you said, because of the type definition, all the leafs are necessarily at the same depth. But the nodes that are not leafs, they also have a key associated with them. What I don't understand is what values they're supposed to have
14:06:24 <pierrot> "dummy" values?
14:07:50 <monochrom> This is something only your instructor can answer.
14:08:21 <monochrom> Either that, or there are class material you haven't shown that answers this.
14:08:29 <SegFaultAX> Well if the picture you shared is part of the assignment, one of the questions is specifically "what are the difficulties in implementating `lookup`" right?
14:08:41 <monochrom> And damn English singular-plural divide.
14:08:47 <SegFaultAX> So maybe a valid answer is explaining why it's hard to write a general solution to `lookup` :)
14:09:02 <monochrom> Actually it can be done.
14:10:14 <monochrom> Basically at the very least you can do "serialize the tree to a list of the k's, [k]". But then you can do lookups on a list.
14:11:02 <tabemann> the thing is the general solution may not be the solution you want
14:11:34 <tabemann> e.g. a binary tree - a solution specific to binary tries is going to be more performant than a solution that collapses the tree first
14:11:42 <tabemann> *trees
14:11:54 <monochrom> I am only proving computability, tabemann.
14:12:05 <EvanR> a binary try is a safety
14:12:36 <SegFaultAX> I'm only saying you should describe as part of your answer why it's harder than monomorphic recursion. I understood that to be part of the question anyway.
14:12:38 <monochrom> And also some technique in the serialization can be re-used in a logarithmic solution.
14:13:36 <monochrom> You will need two lookup functions, one for Tree and one for Node.
14:14:18 <monochrom> The Tree one will have to call the Node one for help. This is basically the technique you need. The finger-tree paper also says this, just very indirectly and hiding it behind a class.
14:15:02 <monochrom> And this is what I learned by serializing to a list, a much simpler problem that illustrates the core issue without distractions such as "oh I need to do a search".
14:15:04 <sternmull> how do i handle exceptions thrown by System.Process? I would like to turn them into Either String a. My attempt with Control.Exception.try and IOException for e does not catch anything.
14:15:32 <monochrom> The meta technique is how I get straight A+'s and all the other students get C's.
14:15:50 <tabemann> how do you know they are IOExceptions?
14:15:58 <monochrom> They confront the big problem head-on and get nowhere.
14:16:01 <sternmull> i don't. I just tried :)
14:16:36 <sternmull> the documentation of Sytem.Process does not tell what type of exception i should expect.
14:16:37 <monochrom> I confront a watered-down problem first, see what I can learn from it, and then now suddenly the original big assignment question has cracks.
14:17:43 <geekosaur> you may not be able to. if the exception happens in the child before it exec()s the external program, there is nothing to catch it
14:18:13 <tabemann> sternmull: have you tried catching all exceptions and then doing show to find out the type of the exception?
14:18:36 <tabemann> (yes, I see that the docs aren't very specific about what exception is raised)
14:18:39 <sternmull> tabemann: I have no idea how to do that. How does that work?
14:18:47 <pierrot> monochrom: so do you suggest two lookup functions to keep the logarithmic performance?
14:19:00 <monochrom> No you misunderstood.
14:19:08 <tabemann> foo `catch` (\(e :: SomeException) -> putStr $ show e)
14:19:11 <sternmull> i just want a string to print what was going wrong, nothing fancy.
14:19:15 <monochrom> Having two lookup functions is just to make it solvable at all.
14:19:26 <pierrot> oh, ok
14:19:37 <monochrom> For logarithmic you have to start making assumptions about the keys.
14:20:01 <monochrom> But your posts show no such assumptions.
14:20:14 <sternmull> tabemann: Thanks! That did the trick.
14:20:56 <tabemann> time to go; bbl
14:20:58 <pierrot> I had thought that maybe instead of dummy keys, I could put the smallest value of the corresponding subtree there
14:21:03 <pierrot> or the biggest, I don't know
14:22:40 <pierrot> (and assume that insert behaves that way, because I don't have to implement any other function apart from lookup)
14:24:11 <pierrot> hmm when I'm saying "the smallest value" I'm referring to the smallest value of a key, not values associated with keys
14:24:24 <ph88> do session types work well in haskell ?
14:26:07 <Samo_svoj> are machines/pipes/conduits/streams examples of dataflow programming?
14:27:41 <johnw> looks like it
14:33:27 <lavalike> does anyone know how to stop GHCi from going to the background (of the current shell) on CTRL+y? it conflicts with readline's yank, so one can't paste something instead GHCi just squirrels to the bg and have to type fg to bring it back up
14:34:14 <monochrom> My GHCi doesn't.
14:34:18 <Tuplanolla> Isn't that usually C-z, lavalike?
14:34:33 <lavalike> I'm dumbfounded 
14:34:40 <lavalike> it indeed usually is
14:34:56 <monochrom> Most Unix and Linux defaults are ctrl-z. But this is an stty setting not a GHCi setting.
14:35:13 <monochrom> So yes look for "man stty"
14:35:15 <Tuplanolla> Are you suffering from a German keyboard layout?
14:35:26 <monochrom> Oh heh.
14:35:32 <lavalike> if I do the same in psql, say, I go to the beginning of the line after typing something, CTRL+k to kill the line, CTRL+y to yank it, it pastes it
14:35:35 <monochrom> Still, "man stty".
14:35:45 <lavalike> if I do the same on GHCi, it says [1]+ Stopped ghci and I have to fg it again
14:36:10 <lavalike> that's mostly why I thought it was a GHCi configuration(?) issue
14:36:10 <geekosaur> ctrl-y is delayed suspend on bsdish systems
14:36:26 <geekosaur> stty dsusp '^-'
14:36:44 <lavalike> geekosaur: amazing
14:37:13 <geekosaur> ("delayed' in that ^Z acts immediately but ^Y waits for the program to do a read on the tty)
14:37:38 <lavalike> monochrom: I am trying to backtrack from dsusp to the relevant bit in that manpage but I would have never gotten to it, it just appears in a table
14:38:07 <lavalike> thank you both! that stty goes straight into the shell profile
14:38:43 <lavalike> geekosaur: do you just know it by heart? or how did you find it?
14:38:53 <geekosaur> know it by heart
14:38:58 <lavalike> well then (:
14:39:17 <geekosaur> back in the day, I had to do a lot of afdapting between BSDish and System V-ish tty subsystems
14:39:49 <geekosaur> actually ended up in the first edition of unix power tools for it, but that was published right around when posix made that knowledge mostly obsolete >.>
14:39:57 <raindev> Hi there! I'm having issues trying to set up a super simple Cabal project for a library with Hspec tests.
14:40:01 <geekosaur> but dsusp still hangs around on bsds
14:40:05 <lavalike> geekosaur: aha! :)
14:40:07 <raindev> |> There're two files: Mod/Lib.hs and Mod/LibSpec.hs
14:40:12 <raindev> |> In cabal file there's a library with `exposed-modules: Mod.Lib`
14:40:16 <raindev> |> And `test-suite tests` with `other-modules: Mod.LibSpec` and `main-is: Mod/LibSpec.hs`
14:40:21 <raindev> |> When I run the tests I get: module ‘main:Algo.PrintSpec’ is defined in multiple files: ./Mod/LibSpec.hs Mod/LibSpec.hs
14:41:18 <lavalike> GHCi is so much more fun with yanking (:
14:41:19 <raindev> |> Sorry, that broken symbols are forward ticks
14:41:23 <geekosaur> I think you don't want it in other-modules
14:42:20 <raindev> Mod.LibSpec in test-suite you mean?
14:42:51 <pierrot> where can I find examples of polymorphic recursion that could be helpful for my task?
14:43:10 <geekosaur> raindev, yes
14:43:34 <geekosaur> you have in effect already declared it in main-is, so you don;'t need to do so again in other-modules
14:47:20 <raindev> Makes sense, fixed the immediate issue
14:49:55 <raindev> Guess, I also need to add my package name to build-depends for test-suite
14:52:32 <monochrom> Yes I think so.
14:52:46 <raindev> But now I'm stuck with "Could not find module Prelude" when compiling Mod.Lib
14:52:59 <monochrom> Do you list base?
14:53:42 <monochrom> I mean, do you have base in build-depends? You should.
14:56:30 <raindev> Yes, I have it
14:57:13 <raindev> base >=4.10 && <4.11 is the only item in build-depends list for Mod.Lib
14:58:38 <raindev> The error also says "There are files missing in the base-4.10.0.0 package"
14:58:44 <monochrom> That sounds conceptually wrong.
14:59:20 <monochrom> You put build-depends under a "library" section, or a "executable blah" section, or a "test-suite" section. Not under "Mod.Lib".
15:00:01 <geekosaur> raindev, are you on arch by any chance?
15:00:39 <raindev> monochrom: sorry for being unclear, it's in library section (where Mod.Lib is exposed)
15:00:56 <raindev> geekosaur: I am :)
15:01:51 <geekosaur> was afraid of that. arch keeps breaking its haskell packaging. I don't think we know how to fix the broken packages issue (packages throwing "There are files missing")
15:02:06 <geekosaur> started with their last update to ghc
15:02:12 <MarcelineVQ> you'll probably want the package  ghc-static  installed if you don't have it
15:02:19 <zachk> arch worked great for me for a bit, till it broke after an update
15:02:31 <geekosaur> you might make sure ghc-static package is installed, but I don't think that fixes this
15:03:57 <raindev> Alright, I'll try to get ghc-static. Have another reason to go Gentoo, I guess
15:06:04 <EvanR> gentoo... would build ghc from source? doesnt sound like a solution
15:06:13 <geekosaur> ghc-static is an arch package
15:06:32 <geekosaur> it contains the static haskell libraries corresponding to the dynamic ones in arch's ghc package
15:06:35 <zachk> how about a haskell platform livecd?
15:06:52 <geekosaur> arch for some reason decided nobody needs static ghc libraries, even though for ghc they are the default and there is good reason for it
15:10:15 <raindev> So I've got ghc-static which fixed my issue with missing Prelude files. But now I have the same but for hspec :/
15:11:13 <raindev> geekosaur: is there a place to read about the reason behind static linking being the default?
15:11:48 <raindev> EvanR: if that would mean packages working as expected than, yes
15:12:17 <EvanR> ive never had issues on linux, but i never use packages for haskell stuff
15:12:17 <geekosaur> https://wiki.haskell.org/Shared_libraries_and_GHC
15:12:53 <geekosaur> raindev, there are no arch packages for non-base static libs. only way around that is only build those libs via cabal, don;'t use the arch packages
15:16:19 <raindev> Thanks for the link. Shouldn't cabal sandbox help me to solve the issue?
15:17:13 <raindev> I mean I did `cabal install hspec`, didn't do an Arch package installation
15:18:01 <geekosaur> that should have worked. unless something else installed the hspec libs via arch --- and a cabal sandbox won't help there because it only sandboxes user installed libs, not the global ones
15:18:48 <geekosaur> sandboxing the global db requires full control over the installed ghc, for which you'll need to use stack and have it install its own ghc --- which leads to other issues, because none of the ghcs it can install was intended for Arch
15:21:23 <raindev> geekosaur: you're right Arch's stack package pulled in hspec package transitively
15:40:34 <raindev> One step closer, but now it turned out that I have quickcheck global package installed which leeds to "files missing" again :(
15:40:52 <pierrot> monochrom: I started implementing the lookfunction for Node as you suggested. I assume that those nodes that aren't leafs, have the biggest key of the corresponding subtree as their key.
15:41:01 <pierrot> I wrote as comments my pseudocode:
15:41:03 <pierrot> https://glot.io/snippets/evdkgfy5cj
15:42:56 <pierrot> I have basically two things to make my idea work. First, I don't know how to check if ai are Nodes. Second, the recursive calls "lookup key a1" and "lookup key a2" wouldn't work literally as they are
15:46:01 <raindev> No, seriously, is the situation better on Gentoo?
15:46:26 <pierrot> actually, I meant "lookupNode key a1" and "lookupNode key a2"
15:47:37 <raindev> If there's no way to contain cabal sandbox to be isolated from the global packages than stack is the only option I've got on Arch?
15:48:40 <pierrot> When I said "I assume that those nodes that aren't leafs, have the biggest key of the corresponding subtree as their key", I mean that, for example, instead of having "dummy" keys like this:
15:48:44 <pierrot> Succ (Succ (Zero "" (Node2 "" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))
15:48:58 <pierrot> the tree would be:
15:48:59 <pierrot> Succ (Succ (Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))
15:49:26 * raindev joins #gentoo-haskell
15:49:52 <pierrot> I think that's a good idea to make an efficient search
15:50:22 <pierrot> becase you know when to cut the recursion
15:50:48 <raindev> Thanks for the help folks <3
15:51:45 <geekosaur> stack can still have problems, as I mentioned
15:51:47 <geekosaur> 2017 Nov 09 19:56:11 <MarcelineVQ>	idk about that specifically, I've never used xmonad. to get around my stack ghc problem I had to install from the AUR  ncurses5-compat-libs  and also add   ghc-build: nopie    to my .stack/config.yaml
15:52:02 <geekosaur> arch is a hot mess :(
16:02:06 <raindev> That's sad :( How does it differ in other distributions/OSes?
16:04:59 <ph88> can i pass options to stack just like with cabal install -f option  ?
16:09:04 * raindev going to sleep
16:10:46 <MarcelineVQ> ph88: https://docs.haskellstack.org/en/stable/GUIDE/
16:12:02 <ph88> is this a problem with the package ?  https://bpaste.net/show/bb0587e99d25
16:14:31 <MarcelineVQ> try a newer resolver that has libffi
16:15:40 <ph88> oh ok
16:15:41 <MarcelineVQ> you're installing an idris version from, hmm, ghc 7.10 resolvers it looks like, but libffi isn't on stackage until ghc 8 resolvers
16:15:48 <ph88> ok
16:16:10 <ph88> 6.30 :D
16:17:08 <ph88> so i go into my global project and stack clean and rebuild everything ?
16:17:15 <MarcelineVQ> I'm also not sure if you can pass flags to packages you build that come from a resolver, guess we'll find out, that might just be a limitation for dependencies
16:18:03 <MarcelineVQ> nnnooo, you edit your .stack/global-project/stack.yaml to a resolver version that has what you need in it, resolvers can be browsed here https://www.stackage.org/
16:18:12 <ph88> yes i know i did that
16:18:24 <ph88> but since i already have compiled binaries before with the global project
16:18:27 <ph88> stylishhaskell
16:18:29 <ph88> hsdev
16:18:35 <ph88> eh .. don't remember what else
16:18:42 <ph88> maybe they need rebuilding with newer LTS now
16:18:57 <MarcelineVQ> nah you don't need to do anything special, try making your idris install
16:19:08 <ph88> ya it's compiling now
16:19:17 <ph88> i just thought it would be nice to recompile the other tools as well
16:19:37 <MarcelineVQ> whatever makes you happy, it's just not required is all
16:25:54 <Skyb0rg> I'm having an issue with chaining functions with 'getLine' together
16:26:24 <Skyb0rg> It seems like Haskell is using the same input twice
16:28:09 <Skyb0rg> http://lpaste.net/359956
16:28:40 <Skyb0rg> when I run this code, there is not a prompt for input at line 61
16:28:49 <Skyb0rg> and it just errors out
16:31:33 <ph88> Skyb0rg, what error ?
16:34:22 <Fekinox> yeah an error message would be useful here
16:34:43 <monochrom> Yes, this is pretty complex, I think you should spell out what is your observation that you consider a problem.
16:35:08 <Skyb0rg> I found out that the issue is I used getChar once, which didn't reset the stdin
16:35:20 <Skyb0rg> I changed it so that I only used getLine and now it works
16:35:27 <monochrom> OK.
16:35:28 <Skyb0rg> not sure why that is a problem though
16:36:13 <monochrom> Well I still don't know what "problem" you're talking about. But bear in mine stdin is usually line-buffered when it's a terminal.
16:36:49 <monochrom> Meaning the OS witholds what you type until you hit return. And only then does the OS send anything to your code.
16:38:31 <Skyb0rg> The error message wasn't helpful (Just said cannot read a char to an Int) but the problem was I pressed enter once, and it sent that input to both getChar and getLine
16:38:49 <Skyb0rg> probably an issue with the terminal
16:39:16 <monochrom> OK sure, but I think you're also misunderstanding the behaviour.
16:39:47 <monochrom> Suppose I have code that does getChar then getLine. Suppose during run time I enter "abc" and press enter.
16:40:04 <monochrom> Then getChar receives the 'a' and the subsequent getLine receives the "bc".
16:40:15 <Skyb0rg> I see
16:40:32 <monochrom> I wouldn't call it "they receive the same input" though.
16:40:44 <Skyb0rg> so if stdin is "a" then getChar gets 'a' and getLine gets [], so it errored out
16:40:52 <Skyb0rg> Thanks!
16:41:23 <ski> Skyb0rg : i think `repeatFilter' may be problematic. after executing `ss' initially, you execute it again, in the  'n'  case. if there's been a  'y'  previously, that means we're in a recursive call, so `ss' is actually `filterSchedules x', so that action will be executed twice then. i suspect that's not what you intended ?
16:42:04 <ski> Skyb0rg : if this is not what you intended, i think the thing to do would be to change the signature to `repeatFilter :: [[Section]] -> IO [[Section]]', and accordingly adapt the code
16:42:27 <ph88> when i use stack install for my global project how can i set O2 ?
16:43:03 <ski> Skyb0rg : also, `findCourse' should probably `hFlush stdout' after the `putStr', unless you `hSetBuffering stdout NoBuffering' at the start (in `main') (perhaps that what you intended to do, considering the `getChar' in `repeatFilter' ?)
16:45:08 <ski> Skyb0rg : `read <$> getLine' is better written as `readLn' (that will cause any read error to occur at this point of execution, rather that later, when the result is used). also the type ascription here shouldn't be necessary, since `replicateM' already knows it wants an `Int'. type inference will figure out that `read'/`readLn' is supposed to read an `Int'
16:45:11 <mniip> does anyone know any algorithms that would provide some kind of sorting of an infinite list with guarantees about the upper/lower bounds of the sequence
16:45:53 <monochrom> I don't know stack. If you switch to cabal, then I know. It's --enable-optimization=2
16:46:12 <c_wraith> mniip: that's a pretty well studied problem for use in things like log aggregators
16:46:43 <monochrom> I also know how to put that in $HOME/.cabal
16:46:56 <monochrom> err, $HOME/.cabal/config
16:47:06 <mniip> c_wraith, I'm really looking for the list of all positive rationals sorted by sum of numerator and denominator
16:47:23 <ph88> which folder can i remove safely from  .stack ?  want to clean that up and rebuild
16:47:34 <mniip> which... I guess is better represented as a nubBy on the diagonalization
16:47:43 <ph88> indices is 1.3G and snapshots 4.2G
16:47:56 <c_wraith> mniip: that seems like a simple list comprehension...
16:48:06 <monochrom> Oh I happen to know that one for cabal, too...
16:48:41 <ski> Skyb0rg : `case length filtered of 0 -> return Nothing; _ -> return $ Just filtered' could be reformulated as `return $ case filtered of [] -> Nothing; _ -> Just filtered'. if you just want to know whether a list is empty, `length' is overkill. pattern-matching (or calling `null', in an `if'-`then'-`else', if you prefer) suffices
16:49:28 <mniip> > [(n, s - n) | s <- [2..], n <- [1 .. s - 1], gcd n (s - n) == 1 ]
16:49:30 <lambdabot>  [(1,1),(1,2),(2,1),(1,3),(3,1),(1,4),(2,3),(3,2),(4,1),(1,5),(5,1),(1,6),(2,...
16:50:06 <ski> Skyb0rg : fwiw, instead of the `>>'s in `findCourse', you could use `do'-expressions, one instead each `case' branch, you know ..
16:50:49 <tarragon> hei
16:50:51 <ski> Skyb0rg : instead of `head' there, i'd use pattern-matching
16:51:01 <tarragon> I am sure many here is aware of pandoc
16:51:57 <tarragon> anybody got an explanation why pandoc got 121 haskell dependencies??
16:52:01 <ph88> can i remove .stack-work safely ?
16:52:44 <MarcelineVQ> ph88: yes
16:52:59 <monochrom> 121 = 11*11
16:53:08 <ski> Skyb0rg : in `filterSchedules', perhaps it would be more helpful to reask the question, in case you can't interpret the answer you got ?
16:53:31 <MarcelineVQ> ph88: also if you desired you could delete .stack/ itself completely without harmig anything, but it's a long download and rebuild
16:53:40 <monochrom> "1,2,1" is also the second row of the Pascal triangle.
16:54:17 <ski> Skyb0rg : ditto for `filterTeach'. what if the user types something else by mistake ?
16:54:37 <tarragon> batshit crazy!!
16:54:51 <tarragon> can pandoc be coded with plain ghc??
16:55:28 <monochrom> Yes, but does anyone have economic incentive to do that?
16:55:44 <johnw> is plain ghc just "no extensions"?
16:55:48 <sm> tarragon: if you trace the deps and read their names, you can probably figure out why many of them are pulled in
16:56:17 <monochrom> Oh I thought "plain ghc" means "all ghc extensions are fair game"
16:56:25 <johnw> lol
16:56:38 <MarcelineVQ> that's odd, my pandoc only has 119 depdendencies
16:56:39 <Tuplanolla> I think he's referring to what the system package manager suggests.
16:57:51 <monochrom> No, I think we should exploit the vague wording until they learn to use precise diction.
16:58:25 <tarragon> monochrom: hundred and twenty one
16:58:42 <Tuplanolla> This part is very precise.
16:58:47 <raynold> ahh it's a wonderful day
16:58:52 <monochrom> Yes, I already explained hundred and twenty one equals eleven squared.
16:59:04 <tarragon> or 000,000,121.00
16:59:27 <monochrom> Ooohhhh you think precision is for numbers only...
16:59:38 <MarcelineVQ> monochrom: you're full of beans tonight
16:59:45 <tarragon> this last one should clear all type of disambiguation.
17:01:00 <tarragon> why 121 and not, let's say, 10?
17:01:04 <tarragon> something smaller
17:01:42 <MarcelineVQ> well it does have something smaller you see, but that smalle number each need a few
17:01:49 <monochrom> You're basically asking a question in the same genre as "why does monochrom have 10 fingers?"
17:01:50 <MarcelineVQ> so in that way it adds up
17:02:38 <monochrom> Why else, a lot of historical accidents and conveniences and luck.
17:02:44 <MarcelineVQ> pandoc only has around 18 dependencies in it's cabal file, I think, but those depdendencies need dependencies you see
17:02:54 <tarragon> I don't want to have exploitable functions lurking on my system to be frank.
17:03:11 <tarragon> MarcelineVQ: exactly!
17:03:31 <MarcelineVQ> oh I see your issue is system-level. arch right? don't install pandoc via pacman, it's awful :(
17:04:33 <monochrom> You are free to roll your own.
17:05:39 <MarcelineVQ> you can get pandoc-bin off the AUR and save a lot of the extra-package hassle, if it works at least, I've not tried it
17:08:41 <monochrom> I love to be frank, too. To be frank, I think the very kernel of your OS is already one big piece of exploitable function. What are you gonna do?
17:09:58 <MarcelineVQ> assuming my above guess was the issue: note that you can install pandoc via cabal or stack as well, it's not dirty or anything, it'll just put the executable in .cabal/something or .local/bin
17:18:30 <Tuplanolla> Looks like C has 86 unqualified default-storage primitive types in the standard. I wonder if our `base` has them beat.
17:20:06 <monochrom> We don't have that many primitive types.
17:21:06 <monochrom> But counting primitive types plus data's plus newtype's is another story.
17:21:15 <monochrom> And to some extent, more fair.
17:21:32 <Fekinox> restricting ourselves to just the prelude?
17:22:55 <pierrot> can anyone tell me if my pseudocode is a good idea?
17:22:58 <monochrom> We don't have that many types in Prelude.
17:27:13 <Maxdamantus> Tuplanolla: I'm guessing that's counting multiple representations of the same type.
17:27:33 <Maxdamantus> Tuplanolla: eg, `long` = `long int` = `int long`
17:27:42 <Tuplanolla> Not the case, Maxdamantus.
17:27:58 <Maxdamantus> Hm, okay.
17:29:48 <Tuplanolla> There's lot of weird stuff like `max_align_t`, `float_t`, `mbstate_t` and `tss_dtor_t`.
17:45:11 <pierrot> I'm stuck with my function. Its signature is: lookupNode :: Ord k => k -> Node k a -> Maybe a. But the type variable a is like a black box, I can know its type so I don't know how to do the recursion.
17:45:57 <pierrot> I can't asume it's a Node2 something or Node3 something
17:46:21 <pierrot> can't know *
17:48:38 <boj> pierrot: the caller has to specify the type
17:49:02 <zachk> @type lookup
17:49:03 <lambdabot> Eq a => a -> [(a, b)] -> Maybe b
17:49:19 <zachk> it almost looks like that if you squint hard enough
17:51:47 <Cale> pierrot: Can you say how the type Node is defined?
17:52:04 <Cale> pierrot: You can pattern match against the possible data constructors for Node
17:52:20 <pierrot> https://glot.io/snippets/evdkgfy5cj
17:52:27 <pierrot> Cale: yeah, that was what I tried
17:52:33 <pierrot> but it doesn't work
17:53:02 <pierrot> because the type variable is "a" and I can't assume anything about it
17:53:28 <Cale> I don't know why you'd need to
17:53:50 <Fekinox> yeah, the type variable is specified by the caller
17:54:14 <Cale> You're either producing Just applied to one of the values of type a which are in the given Node, or you're producing Nothing
17:54:25 <Cale> You shouldn't have any reason to pattern match on the value of type a
17:54:33 <Fekinox> oh yeah, that too
17:54:46 <Fekinox> you don't really need to look inside the type variable in the first place
17:54:56 <pierrot> I need to
17:55:13 <pierrot> what I wrote compiles but it's not what I want
17:55:20 <pierrot> what I need is what it's in the comments
17:56:17 <pierrot> if a1 is a value of type Node, I need to do a recursion over it
17:56:49 <Cale> Okay, so what would you expect the result to be when we have lookupNode 2 (Node2 1 "hello" 3 "world")
17:57:09 <Cale> No, you don't get to do that because you don't know that a is a Node.
17:57:23 <pierrot> Yes, that's my problem
17:58:21 <Welkin> are you sure it's not because you are a clown?
17:58:31 <Cale> huh?
17:59:04 <Welkin> pierrot ^
17:59:20 <Cale> ???
17:59:41 <Fekinox> if you have an 'empty' or 'singleton' type for your nodes, you can return that from the function and have the caller pattern match out the entry I think
18:00:07 <Cale> Node isn't a recursive type, there's no cause to try to make lookup for Node be recursive
18:00:22 <Fekinox> didn't follow, oop
18:00:28 <Cale> lookup for Tree might be recursive
18:00:33 <Welkin> Cale: pierrot is a clown o.o
18:00:35 <pierrot> Sorry, my IP changed and lost connection from my ZNC
18:00:47 <Cale> Welkin: Why do you say that?
18:00:59 <Welkin> https://en.wikipedia.org/wiki/Pierrot
18:01:47 <Fekinox> oh right I didn't think to look at the source here
18:01:51 <Fekinox> my b
18:02:09 <Cale> Clowns to the left of me, jokers to the right
18:02:40 <Cale> anyway, perhaps try writing lookup for Tree -- that's the one you're going to want to have recursion in it
18:02:59 <Welkin> but there are so many kinds of trees
18:03:11 <pierrot> Cale: some values of Node can be like this: Node2 "" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "" (Node2 "Colombia" 48.7 "Uruguay" 3.4)
18:03:17 <Welkin> the truffula trees!
18:03:18 <Cale> There's exactly one type of tree which is defined in the source file we're talking about
18:03:26 <Welkin> and the barbaloots in their barbaloot suits!
18:03:35 <pierrot> Cale: the "a" in the definition of Node, can also be a Node
18:03:50 <Cale> pierrot: Sure, but that *can't* matter in this definition
18:04:05 <Cale> pierrot: If you have a type variable, you have no information about which type it is.
18:04:21 <Welkin> where is the type defined?
18:04:28 <Cale> https://glot.io/snippets/evdkgfy5cj
18:04:35 <Welkin> o.o glot
18:05:02 <Welkin> that is a strange definition
18:05:11 <ski> it's a perfectly balanced tree
18:05:13 <pierrot> Welkin: maybe I'm not a clown ?
18:05:18 <pierrot> ;)
18:05:18 <Cale> It's a pretty normal way to do trees of bounded depth
18:06:12 <Welkin> a 2-3 tree?
18:06:32 <Cale> Yeah, this is a 2-3 tree where all the leaves are at the same depth
18:06:51 <Fekinox> ah
18:07:08 <Fekinox> this is starting to hurt my head the more I think over it
18:07:08 <Cale> You'll either get Zero, with a leaf immediately
18:07:41 <pierrot> I need that lookupNode "Brasil" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)) returns 207.7
18:07:57 <ski> pierrot : you could think of `lookupNode', in the context of `lookup', as selecting the appropriate child subtree .. but `lookupNode' doesn't (isn't allowed to) know that it will (`Maybe') return a subtree -- and it doesn't need to know that, either
18:08:09 <Cale> Or you'll get Succ of a Tree whose eventual result is one node deeper
18:08:11 <pierrot> how can I do that if I can't recurse into ai ?
18:08:31 <ski> `lookupNode' won't be recursive, simple as that
18:08:37 <ski> `lookup' possibly will
18:08:43 <Cale> pierrot: You can make lookup for the complete tree be recursive (and probably should)
18:09:11 <ski> (if you prefer, you could make `lookup' call a recursive helper ..)
18:09:20 <Cale> yeah
18:09:37 <pierrot> Thanks for your help Cale and ski. 
18:09:44 <pierrot> But...
18:10:11 <Cale> You're going to recursively build up a function for looking up a value in a tree of known depth
18:10:12 <pierrot> is there any way to build a function lookupNode that behaves like this:
18:10:55 <pierrot> lookupNode "Brasil" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)) = 207.7 ?
18:11:00 <ski> not with `lookupNode' having the type specified in the signature in that paste
18:11:00 <Cale> no.
18:11:07 <pierrot> sorry, Just 207.7
18:11:14 <Cale> Well, okay
18:11:15 <ski> (same answer)
18:11:21 <Cale> You could do it, but what type does that have?
18:11:37 <Cale> What's the type of  (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)) ?
18:12:28 <Cale> It's something like  Node String (Node String Double), right?
18:13:01 <Cale> So if you wrote a function which worked like that, it would only operate on trees of depth exactly 2
18:13:48 <Cale> yes?
18:14:14 <pierrot> yes
18:14:16 * ski . o O ( "let's write a function which, for any given `n', can build a function that can operate on trees of depth `n'" )
18:15:06 <pierrot> I need it to work on an arbitrary number of compositions of Node.
18:15:14 <ski> "it" being what ?
18:15:23 <ski> `lookupNode' ? `lookup' ?
18:15:29 <pierrot> lookupNode
18:15:35 <ski> then, no you don't
18:15:41 <Cale> pierrot: You need lookup to be able to handle that
18:15:45 <Cale> pierrot: Not lookupNode
18:15:55 <pierrot> Ok
18:16:01 <ski> <ski> pierrot : you could think of `lookupNode', in the context of `lookup', as selecting the appropriate child subtree .. but `lookupNode' doesn't (isn't allowed to) know that it will (`Maybe') return a subtree -- and it doesn't need to know that, either
18:16:35 <ski> `lookup' will use `lookupNode' multiple times
18:17:12 <ski> (perhaps only a single call to `lookupNode' in the implementation of `lookup'. but a call to the latter will typically involve multiple calls to the former)
18:17:43 <pierrot> I still don't see how to do it.
18:18:00 <ski> perhaps start trying to write `lookup' ?
18:18:14 <ski> see what your input could possibly be, and what you could possibly do with it ?
18:18:33 <pierrot> lookUpNode was an auxiliary function that I thought it was needed
18:18:40 <pierrot> it could be removed 
18:18:54 <pierrot> lookup is the function that I need
18:18:57 <ski> it may also help to consider a few sample values of type `Tree String Double' (not merely `Node String (Node String Double)' or `Node String Double', &c.)
18:19:00 <pierrot> but it lookes even harder
18:19:18 <ski> methinks you can use `lookupNode' to define `lookup'
18:19:42 <pierrot> yes, that was the idea
18:19:55 <ski> can you form a value of type `Tree String Double', based on the sample value of type `Node String (Node String Double)', that you gave above ?
18:20:36 <ski> if you could get an idea of how values of type `Tree String Double' can possibly look, i think that might help with getting an idea of how to process such values in `lookup'
18:22:26 <pierrot> ski: Sure
18:22:34 <pierrot> the value you want is simply:
18:22:37 <pierrot> Succ (Succ (Zero "" (Node2 "" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))
18:23:15 <pierrot> its type should be Tree String Double
18:23:19 * ski was thinking the `k'-typed argument to `Zero' looked a bit strange, yes ..
18:23:44 <ski> yes, correct
18:24:21 <ski> so, for each outer `Succ', you've got a corresponding inner tree level of nodes
18:24:40 <ski> the second `Succ' corresponds to the first `Node' layer (the initial `Node2')
18:25:04 <ski> the first `Succ' corresponds to the second `Node' layer (that is the `Node3' and the sibling `Node2')
18:26:08 <ski> after you peel off the first `Succ', you get something of type `Tree String (Node String Double)' -- which, on the face of it, is a tree whose elements are of type `Node String Double'
18:26:21 <pierrot> all `Tree k a` values have the form `Succ^n (Zero t)` where t :: Node k (Node k ( ...)) (n times)
18:27:34 <pierrot> it's a tricky structure
18:27:41 <pierrot> it's inspired by http://www.cs.tufts.edu/~nr/cs257/archive/ralf-hinze/finger-trees.pdf
18:27:51 <pierrot> page 199
18:28:12 <pierrot> but that's simpler since it contains single element
18:28:25 <pierrot> the one I have to deal with contains pairs key value
18:28:39 <ski> the "elements" here are actually the lowest level in the `Tree String Double'
18:28:45 <pierrot> True
18:29:04 <pierrot> the elements are the leafs of the trees
18:29:13 <pierrot> but there're nodes that are nots leafs
18:29:23 <pierrot> and they also have a key associated with them
18:29:33 <ski> so, by peeling off the outer/first `Succ', we're sortof cutting off the lowest nodes of the tree as "elements" of their own
18:30:07 <ski> if you used `lookup', recursively, on this `Tree String (Node String Double)', you'd (`Maybe') get a `Node String Double' back
18:30:43 <ski> this would be the last layer of the tree, the recursive `lookup' call already having navigated all the way to the element you're looking for, except not having traversed the last layer
18:31:04 <pierrot> since there are nodes with keys that are nots leafs, what keys should they have?
18:31:29 <pierrot> in order to make lookup efficient, I decided that they should have the biggest key of the corresponding subtree
18:31:31 <ski> so, the current call to `lookup' needs to do said traversal, *after* the recursive call
18:32:01 <pierrot> so, in my example, instead of
18:32:07 <pierrot> Succ (Succ (Zero "" (Node2 "" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))
18:32:10 <pierrot> I'd have:
18:32:22 <pierrot> Succ (Succ (Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))
18:32:45 <ski> ok, makes sense
18:32:45 <pierrot> istead of "dummy" keys, the biggest key of the corresponding subtree
18:33:32 <ski> is the tree also supposed to be sorted ?
18:33:47 <pierrot> Yes, it is
18:33:47 <ski> i suppose it would be, why else require `Ord' ?
18:34:02 <pierrot> it's sorted
18:34:58 <ski> so, what do you think of the idea i outlined, above ?
18:35:05 <ski> does it make any sense to you ?
18:36:12 * pierrot is reading...
18:37:20 * ski thinks that CPS might be slightly nicer here .. but doing it direct-style should also work
18:43:20 <pierrot> I don't understand this:
18:43:26 <pierrot> ski: ―so, the current call to `lookup' needs to do said traversal, *after* the recursive call
18:43:58 <ski> first you traverse `n-1' layers of the tree. then you traverse the last layer
18:44:25 <ski> (you already know how to traverse a single layer)
18:45:11 * ski is still waiting for pierrot to actually attempt start writing `lookup' ..
18:45:53 <pierrot> I still don't understand several things.. lol
18:46:26 <ski> if you try, then maybe you can ask more when you get stuck ?
18:46:37 <ski> (if you don't see by then how to continue further)
18:47:01 <ski> "follow the types"
18:47:32 <pierrot> you said that sometimes lookup could return a Maybe (Node String Double)
18:47:41 <ski> (by which i mean : keep in mind the *types* of the values you're currently handling .. also the type of the result you're currently trying to produce)
18:47:51 <ski> yes
18:48:00 <pierrot> if then, the recursion would be done
18:48:05 <ski> (when, exactly ?)
18:48:13 * ski nods
18:48:35 <pierrot> so, after that call lookupNode ?
18:48:55 <ski> sorry, could you rephrase that question ?
18:49:19 * ski can't seem to parse that
18:49:50 <pierrot> once lookup returned a value of type Maybe (Node String Double), should I call lookupNode over that value?
18:50:10 <ski> tias ?
18:50:24 <ski> ("try it and see")
18:52:10 <pierrot> it's wrapped in a Maybe, but that wouldn't matter
18:54:30 <pierrot> at some moment, I need a lookupNode function that behaves this way:
18:54:42 <pierrot> lookupNode "Brasil" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)) = Just 207.7
18:55:12 <pierrot> lookupNode "Germany" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)) = Nothing
18:55:38 <ski> no
18:56:28 <pierrot> oh, sorry. you said that at the end I'd have only the innermost level of Nodes
18:58:03 <pierrot> I think that I finally caught your point
18:58:28 <pierrot> I'll be out for dinner, but I'll continue on this later
18:58:40 <pierrot> ski: thank you very much for your help
18:58:49 <ski> yw
20:11:06 <pierrot> ski: are you still around? I'm trying to define `lookup key (Zero k a)`. Again, I have the same problem that I don't know anything about a.
20:14:07 <Cale> pierrot: Again, you still shouldn't need to know anything about it. Either the result is going to be Just a, or it's going to be Nothing
20:14:20 <Cale> and it only depends on whether k is key or not.
20:15:18 <pierrot> Cale: suppose that key == k holds
20:15:29 <pierrot> and then I return Just a
20:15:53 <pierrot> that's not how my function should behave
20:16:03 <Cale> Why?
20:16:21 <Cale> Well, what's the type of a here? Doesn't it match the type of the result you want to produce?
20:18:30 <pierrot> Cale: suppose that x is
20:18:33 <Cale> pierrot: You're looking up the result in a tree of depth 0
20:18:41 <pierrot> Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4))
20:18:45 <Cale> so there's not much looking to do
20:18:45 <pierrot> and I do
20:18:59 <pierrot> lookup "Brasil" x
20:19:07 <pierrot> then the result would be Nothing
20:19:13 <Cale> Indeed
20:19:21 <pierrot> since "Brasil" is different than "Uruguay"
20:19:23 <pierrot> and that's wrong
20:19:29 <pierrot> the expected result is
20:19:33 <pierrot> Just 207.7
20:20:01 <Cale> Is it though? You were looking for "Brasil", and the only key in the tree was Uruguay, the fact that the value at that key was another tree is irrelevant
20:20:14 <monochrom> I stopped participating because this is not a standard 2-3 tree.
20:20:31 <pierrot> Cale: you're wrong about that
20:20:50 <Cale> How so?
20:20:51 <pierrot> the keys are "Argentina", "Brasil", "Chile", "Colombia" and "Uruguay"
20:20:58 <Cale> Nope
20:21:04 <pierrot> yes, they're are
20:21:06 <Cale> there's a Zero there
20:21:13 <Cale> so the tree has depth 0
20:21:18 <monochrom> A standard 2-3 tree is such that if a node has two keys then it has three children. This pretender is such that if a node has two keys then it has either two values or two children. This is completely broken.
20:22:21 <Cale> pierrot: If you stick some occurrences of Succ on the front, I would agree with you
20:22:47 <pierrot> Cale: yes, you're right
20:24:58 <pierrot> two ocurrences of Succ on the front
20:25:49 <pierrot> Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)) is not "valid"
20:26:32 <pierrot> since its type is not Tree String Double
20:27:43 <pierrot> Succ (Succ (Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)))) is right
20:28:09 <jcarpenter2> does haskell have a type-level map :: (* -> *) -> [*] -> [*] ?
20:28:43 <jcarpenter2> i'd like to write code like "HVect (map Maybe ts)"
20:28:50 <jcarpenter2> using Data.HVect
20:33:53 <jcarpenter2> found it, got to use a type family
20:53:00 <mekeor> does stack.yaml allow to include another yaml-file?
21:10:16 <Welkin> mekeor: check the docs or try it out
21:10:35 <Welkin> I know you can include sections of yaml inside of other parts of the file
21:13:53 <pierrot> Cale: how would it be lookup over something of the form Succ ?
21:33:48 <ski> pierrot : did you try the outline from above yet ?
21:34:45 <pierrot> ski: yes, I'm trying to follow your instructions
21:35:34 <pierrot> I need to do pattern matching on something of type Succ (Tree k (Node k a))
21:36:36 <ski> your input is of type `Tree k a'. if the match with the pattern (of said type) `Succ t' succeeds, that means that `t' will now have .. which type ?
21:37:27 <ski> (btw, `Succ (Tree k (Node k a))' is not a type, which is why i'm asking this question, to check whether you understand the situation)
21:38:19 * ski looks at pierrot
21:38:41 <pierrot> yes, because Succ is a data constructor which takes a Tree k (Node k a) value as its argument
21:39:05 <pierrot> t will be Tree k (Node k a)
21:39:08 <ski> so .. what's the type of `t', assuming the match of the input to `lookup' to the pattern `Succ t' succeeds ?
21:39:11 <ski> right
21:39:20 <ski> now, what can you do with a datum of that type ?
21:39:39 <ski> (or, if you prefer .. what would you like to do to the input now ?)
21:41:39 <pierrot> I could recursively call lookup...
21:41:46 * ski idly wonders whether pierrot has caught on to the trail ..
21:41:51 <ski> yes, you could
21:42:04 <ski> what type would the result of such a recursive call be ?
21:42:27 <pierrot> Maybe (Node k a) ?
21:42:39 <ski> right
21:43:44 <ski> you're calling `lookup', recursively, not at type `Ord k => k -> Tree k a -> Maybe a' (the type of the current call), but at the type `Ord k => k -> Tree k (Node k a) -> Maybe (Node k a)', where the `a' has been replaced by `Node k a', this `a' being the "current" `a' of the current call
21:44:03 <ski> so, if we make this recursive call, it will *not* use the same `a' as the current call
21:44:09 <ski> that is called "polymorphic recursion"
21:44:12 <ski> unlike in e.g.
21:44:14 <ski> @src map
21:44:14 <lambdabot> map _ []     = []
21:44:14 <lambdabot> map f (x:xs) = f x : map f xs
21:44:40 <ski> where the recursive call to `map' is at type `(a -> b) -> [a] -> [b]' which is the same as the type of the `map' of the current call
21:44:57 <pierrot> I see.
21:45:17 <ski> anyway .. i just mentioned this, to give a name to what's happening here -- and perhaps to explain better how such a recursive call would work
21:45:38 <ski> now .. how can you further process the result of type `Maybe (Node k a)' ?
21:45:53 <pierrot> Yes, your explanations are definitively useful for me
21:45:55 <ski> (you could also reflect over what exactly this recursive call would accomplish ..)
21:47:06 <ski> well, it would also possibly help if you recalled what the *desired* result type (of the current call to `lookup') is ..
21:48:02 <ski> (iow, what is the type of the thing that this `lookup' call is supposed to return ? and how far from getting there are we ?)
21:48:44 <pierrot> the whole `lookup` function should return a Maybe a
21:51:04 <ski> (the recursive call in `map' would be "monomorphic recursion" .. that might at first seem wrong, since `map' is a polymorphic operation. however, *inside* `map', it's as if `map' had a monomorphic type, `(A -> B) -> [A] -> [B]', for two unknown, but fixed, types `A' and `B'. and the recursive call is just an ordinary recursive call here, just like if you had written a recursive function with signature `sum :: [Integer] -> Integer'. the only difference is th
21:51:19 <ski> (er, cut off near ".., just like if you had written a recursive function with signature `sum :: [Integer] -> Integer'. the only difference is that `Integer' is actually known here, not abstract/opaque)")
21:52:02 <ski> pierrot : yeah, so you have to close the gap between the recursive result of type `Maybe (Node k a)', and the desired result (of the current call) of type `Maybe a'
21:52:17 <ski> got any idea how to do that ?
21:53:13 <pierrot> Hmm
21:54:48 <ski> (while, inside `lookup', to be able to make this recursive call, we *can't* treat `lookup' as monomorphic, with `k' and `a' standing for fixed but unknown/abstract/opaque types. we can do that for `k', but not for `a', because we need to call recursively with a different type in place of `a' (namely `Node k a', for the `a' that we were given in the current call))
21:55:40 <ski> (that's why this recursive call inside `lookup' is a polymorphic recursive call. we can't treat `lookup' as "internally monomorphic", as regards to this recursive call)
21:57:06 <pierrot> regarding to your question, shouldn't I use fmap?
21:57:28 <ski> that would be one possible way to approach this. but not enough
21:57:58 <ski> (not saying it is wrong. but i am saying it's not the only way)
21:58:37 <ski> to which problem would we have reduced the current problem, if we used `fmap' here ?
21:58:45 <ski> (or which problems, if several)
21:59:51 <pierrot> this polymorphic recursion confuses me a lot
22:01:06 <ski> i could give you another example, or two, of it, if you'd like
22:02:00 <pierrot> I understand the concept and the difference between the normal recursion like in map
22:02:18 <ski> would you like another example ? perhaps later ?
22:02:18 <pierrot> but I still doesn't catch how it works in this particular situation
22:02:25 <ski> ok
22:02:28 <pierrot> Yes, I'd love it
22:02:53 <pierrot> all examples are welcome, and thank you very much for your patience
22:03:27 <ski> well, first a pretty silly example
22:04:14 <ski> @let sillyShower :: Show a => [a] -> [String]; sillyShower [] = []; sillyShower (x:xs) = show x : sillyShower (map (: []) xs)
22:04:16 <lambdabot>  Defined.
22:04:26 <ski> > sillyShower [0,1,2,3]
22:04:28 <lambdabot>  ["0","[1]","[[2]]","[[[3]]]"]
22:06:46 <ski> in the recursive call, `map (: []) xs' has type `[[a]]', so we're calling `sillyShower' recursively at `Show [a] => [[a]] -> [String]' (but there's an `instance Show a => Show [a]', so we can discharge the required `Show [a]' constraint on the recursive call, by using the constraint `Show a' that was provided to the current call)
22:07:24 <ski> so, in the example, in the initial call, `a' is `Integer'. in the recursive call `a' is `[Integer]'. in the next recursive call, `a' is `[[Integer]]', and so on
22:07:37 <pierrot> Nice
22:07:56 <ski> this is silly, because we're not actually doing anything sensible with the polymorphic recursion here
22:08:08 <ski> now, consider this less silly example
22:08:23 <pierrot> Yes, but it helps to understand the concept
22:08:35 * ski nods
22:08:40 <ski> @let data SwapList a b = Nil | Cons a (SwapList b a) deriving Show
22:08:42 <lambdabot>  Defined.
22:09:45 <ski> note how `SwapList' is not a "regular" recursive datatype. it's irregular, in the same way your `Tree' is, namely by that the recursive instances of the type in the body of the `data' type definition doesn't use the *same* type arguments as to the left of the `='
22:10:02 <ski> namely, here `a' and `b' are swapped in the recursive "call" in this `data' definition
22:10:27 <ski> in your `Tree' example, instead of `Tree k a' you have `Tree k (Node k a)', iow in place of the `a' parameter, we have `Node k a'
22:10:39 <ski> the point is that the parameter doesn't stay the same, it's changing
22:11:10 <ski> to do anything non-trivial with such an "irregular" recursive datatype, polymorphic recursion is required
22:11:10 <pierrot> Yes, I noted that
22:11:42 <ski> however, as you noticed with `sillyShower', one can also have polymorphic recursion, without an irregular recursive data type
22:12:00 <ski> so, consider e.g. the following operation
22:12:43 <ski> well, actually, operations
22:14:04 <ski> @let mapEvens :: (a0 -> a1) -> SwapList a0 b -> SwapList a1 b; mapEvens _ Nil = Nil; mapEvens f (Cons x yxs) = Cons (f x) (mapOdds f yxs); mapOdds :: (b0 -> b1) -> SwapList a b0 -> SwapList a b1; mapOdds _ Nil = Nil; mapOdds f (Cons x yxs) = Cons x (mapEvens f yxs)
22:14:06 <lambdabot>  Defined.
22:14:38 <pierrot> wow, I'd need a time to process all those declarations... let me see
22:15:03 <ski> `mapEvens f xys' will apply `f' to all the elements at *even* indices of `xys'. `mapOdds f xys' will apply `f' to all the elements at *odd* indices of `xys'
22:15:23 <pierrot> I see
22:15:40 <ski> hm, actually, on second thought, i just realized that this is actually not polymorphic recursion :)
22:15:55 <ski> so, let's take the actual polymorphic recursion operation on `SwapList'
22:16:32 <ski> (i was thinking it could make it slightly simpler, but i now realized that the above is ordinary (monomorphic), though mutual, recursion)
22:16:54 <ski> (if you want to, you could ponder *why* it is monomorphic (mutual) recursion)
22:17:04 <pierrot> yeah, two recursive functions one used in the impelementation of the other
22:17:23 <ski> if you look at the signatures again
22:17:28 <ski>   mapEvens :: (a0 -> a1) -> SwapList a0 b -> SwapList a1 b
22:17:37 <ski>   mapOdds  :: (b0 -> b1) -> SwapList a b0 -> SwapList a b1
22:17:52 <ski> and, renaming the type variables of one of them, e.g. the second
22:17:54 <ski>   mapEvens :: (a0 -> a1) -> SwapList a0 b -> SwapList a1 b
22:17:54 <pierrot> SwapList a0 b and SwapList a1 b
22:18:04 <ski>   mapOdds  :: (a0 -> a1) -> SwapList b a0 -> SwapList b a1
22:18:16 <ski> you'll see that the type of `f' in both cases is the same
22:18:32 <pierrot> yes, I realized that
22:18:35 <ski> but the parameters to `SwapList' (both the argument type and the result type) have been swapped
22:18:47 <ski> but that's what happens when you peel off one `Cons'
22:19:29 <ski> so, when you go from `mapEvens' to `mapOdds', and then back to `mapEvens' .. you end up calling `mapEvens' at the *same* type as the former call to it
22:19:34 <ski> hence, monomorphic recursion
22:19:35 <ski> anyway
22:20:24 <ski> @let mapSwapList :: (a0 -> a1) -> (b0 -> b1) -> SwapList a0 b0 -> SwapList a1 b1; mapSwapList _ _ Nil = Nil; mapSwapList f g (Cons x yxs) = Cons (f x) (mapSwapList g f yxs)
22:20:25 <lambdabot>  Defined.
22:20:36 <ski> now, *this* is actually polymorphic recursion :)
22:21:03 <ski> in the recursive call, we're swapping `a0' for `b0', and `a1' for `b1'
22:21:15 <ski> indicated e.g. by swapping the `f' and `g' parameters
22:22:35 <pierrot> I see
22:22:47 <ski> however, if you would "unroll" the recursive loop once, so that you did "two steps in one", like
22:22:53 <ski>   mapSwapList :: (a0 -> a1) -> (b0 -> b1) -> SwapList a0 b0 -> SwapList a1 b1
22:23:11 <ski>   mapSwapList _ _  Nil         = Nil
22:23:18 <ski>   mapSwapList f g (Cons x yxs) = Cons (f x) (helper yxs)
22:23:21 <ski>     where
22:23:33 <ski>     helper  Nil         = Nil
22:23:37 <ski>     helper (Cons y xys) = Cons (g y) (mapSwapList f g xys)
22:23:45 <ski> then this would be reduced to monomorphic recursion
22:24:11 <ski> this is possible here, since we were just swapping the type variables around, and there's a finite number of permutations (in this case two)
22:25:02 <pierrot> nice examples. I'll reread them later and think about them to deeply understand this topic
22:25:04 <ski> however, in the `sillyShower' case, there's an infinite chain `a',`[a]',`[[a]]',`[[[a]]]' of progressively larger types, so that way of avoiding polymorphic recursion doesn't work there
22:25:46 <ski> you should also note that it *needs* to build, at *run-time*, `Show' instances for all these types, because it can't know how many of them it'll need in advance
22:26:21 <pierrot> wow, I hadn't thought about that
22:26:24 <ski> polymorphic recursion is one case where it is (in general) impossible to build all the instances that a program needs, at compile-time
22:27:16 <ski> (the other case is existential quantification, where a type has been forgotten. but that's a language extension. polymorphic recursion is not an extension)
22:27:47 <pierrot> wow so polymorphic recursion is something rather sophisticated
22:28:38 <ski> it's not present in the ML language (now a family, including SML and OCaml), from which much of the design (especially the type system) of Haskell derives
22:29:31 <ski> anyway .. i thought i'd do one further example of polymorphic recursion
22:29:35 <ski> if you're up for it ?
22:29:42 <pierrot> yes, of course
22:30:12 <ski> @let data PBBT a = Elems a | Double (PBBT (a,a)) deriving Show
22:30:14 <lambdabot>  Defined.
22:30:23 <ski> `PBBT' stands for "perfectly balanced binary tree"
22:30:30 <ski> consider
22:31:13 <ski>   (((0,1),(2,3)),((4,5),(6,7))) :: (((Integer,Integer),(Integer,Integer)),((Integer,Integer),(Integer,Integer)))
22:31:27 <ski>   Elems (((0,1),(2,3)),((4,5),(6,7))) :: PBBT (((Integer,Integer),(Integer,Integer)),((Integer,Integer),(Integer,Integer)))
22:31:41 <ski>   Double (Elems (((0,1),(2,3)),((4,5),(6,7)))) :: PBBT ((Integer,Integer),(Integer,Integer))
22:31:54 <ski>   Double (Double (Elems (((0,1),(2,3)),((4,5),(6,7))))) :: PBBT (Integer,Integer)
22:32:04 <ski>   Double (Double (Double (Elems (((0,1),(2,3)),((4,5),(6,7)))))) :: PBBT Integer
22:32:17 <ski> this is similar to your `Tree' case, but a little simpler
22:32:43 <pierrot> yes
22:32:57 <ski> now, to write a `elemsOf :: PBBT a -> [a]' function
22:34:21 <ski> @let elemsOf (Elems x) = x; elemsOf (Double xxt) = [x | (x0,x1) <- elemsOf xxt,x <- [x0,x1]]
22:34:22 <lambdabot>  .L.hs:191:1: error:
22:34:22 <lambdabot>      • Couldn't match type ‘[a]’ with ‘([a], [a])’
22:34:22 <lambdabot>        Expected type: PBBT ([a], [a]) -> [(a, a)]
22:34:37 <ski> note that we get a type error, if we try this, without a type signature ! :)
22:34:46 <ski> @let elemsOf :: PBBT a -> [a]; elemsOf (Elems x) = x; elemsOf (Double xxt) = [x | (x0,x1) <- elemsOf xxt,x <- [x0,x1]]
22:34:47 <lambdabot>  .L.hs:193:21: error:
22:34:47 <lambdabot>      • Couldn't match expected type ‘[a]’ with actual type ‘a’
22:34:47 <lambdabot>        ‘a’ is a rigid type variable bound by
22:35:49 <ski> oh, right, sorry
22:36:01 <ski> i should use a singleton list in the base case :)
22:36:05 <ski> let's try again
22:36:12 <ski> @let elemsOf (Elems x) = [x]; elemsOf (Double xxt) = [x | (x0,x1) <- elemsOf xxt,x <- [x0,x1]]
22:36:13 <lambdabot>  .L.hs:191:1: error:
22:36:13 <lambdabot>      • Occurs check: cannot construct the infinite type: a ~ (a, a)
22:36:13 <lambdabot>        Expected type: PBBT (a, a) -> [(a, a)]
22:36:20 <ski> @let elemsOf :: PBBT a -> [a]; elemsOf (Elems x) = [x]; elemsOf (Double xxt) = [x | (x0,x1) <- elemsOf xxt,x <- [x0,x1]]
22:36:22 <lambdabot>  Defined.
22:36:26 <ski> that's more like it :)
22:36:28 <jcarpenter2> whew, haskell is alright
22:37:06 <ski> the thing i wanted to note here is that polymorphic recursion is one of the cases where Haskell can't *infer* the type signature
22:37:27 <ski> you'll *need* to write it yourself .. and to do that, you need to figure out what type to write yourself
22:37:35 <ski> type inference won't help you here
22:37:52 <pierrot> I see
22:37:53 <ski> that's an important point about using polymorphic recursion
22:38:33 <pierrot> so whenever I use polymorphic recursion, I need to explicitly specify the signature of that function
22:39:29 <ski> (another case where you need to write a signature is when you're matching on a "GADT" data type .. but that's a language extension .. which incidentally is similar to irregular data types in that it allows one to "vary" the type parameters .. only that it also allows one to vary the type parameters of the *result* type of the data constructors, not just the recursive argument types of them)
22:39:35 <ski> right
22:40:31 <ski> instead of `[x | (x0,x1) <- elemsOf xxt,x <- [x0,x1]]' here, i could have said `map (\(x0,x1) -> [x0,x1]) (elemsOf xxt)', which gets a `[[a]]', and then `concat' to get to a plain `[a]' again
22:41:20 <ski> in your case with `lookup', you'll need to do something a *bit* similar, to get from `Maybe (Node k a)' to `Maybe a'
22:42:19 <pierrot> in my case, I still don't see when I need to do the comparison between the keys of the structure
22:42:25 <ski> in case your `Maybe (Node k a)' is a `Nothing', that means that the recursive `lookup' call failed to find a subtree for the given key
22:42:25 <pierrot> and the first argument of `lookup'
22:43:07 <ski> if it's a `Just n', then it has found a subtree (actually a `Node k a', but that represents the "last" subtree "above" the element you're looking for, in case it's there)
22:43:35 <ski> can you get to `Maybe a', in either of these two cases ?
22:45:24 <pierrot> No
22:45:42 <ski> in which case can't you get to `Maybe a' ?
22:46:54 <pierrot> let me recapitulate a bit, because I'm a bit lost
22:47:09 <ski> take your time
22:48:49 <pierrot> I have to define `lookup key (Succ t)', right? where `t' has type `Tree k (Node k a)'
22:49:00 <ski> yep, that's it
22:49:29 <ski> that's where we were, when we got side-tracked on talking about polymorphic recursion, for a bit
22:50:25 <pierrot> if I call recursively at `lookup key t', that would return a value of type `Maybe (Node k a)'
22:50:41 * ski nods
22:59:17 <pierrot> and as you said, if that result is "a `Nothing', that means that the recursive `lookup' call failed to find a subtree for the given key" and then I should return Nothing
23:00:02 <ski> sounds reasonable
23:00:46 <pierrot> and "if it's a `Just n', then it has found a subtree"... but what would the interpretation of that Node n ?
23:01:24 <ski> it's the last layer above the element you're looking for (if it exists)
23:01:45 <ski> the recursive call descends `n-1' layers into the tree
23:01:49 <ski> there's only one layer left
23:02:01 <ski> (given a tree with `n' total layers)
23:03:15 <jcarpenter2> Anybody ever written this before? http://lpaste.net/359958
23:03:53 <jcarpenter2> quick edit: no need for the Nat in the type sigature, i'm sure that can be made a separate function
23:04:20 <pierrot> if I have: `let x = Succ (Succ (Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4))))', then I call `lookup "Brasil" x'
23:05:10 <ski> if we say `x = Succ y', then that will in turn call `lookup "Brasil" y' ..
23:05:42 <pierrot> the pattern matching that would apply would be `lookup key (Succ t) = ...' and the result of `lookup "Brasil" t' what would be?
23:05:49 <ski> (.. and that recursive call ought to return what ?)
23:06:03 * ski nods and smiles
23:06:24 <pierrot> I actually asked the same you asked to me
23:06:25 <pierrot> lol
23:07:33 <jcarpenter2> thank god for Idris, knowing something about full dependent types make these GHC extensions make a lot more sense
23:07:53 <jcarpenter2> dependent types are like the meet (or, join) of these various type system extensions
23:08:14 <pierrot> ski: Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9 ?
23:08:21 <jcarpenter2> it helps make sense of the jungle
23:08:33 <ski> pierrot : yep, albeit wrapped with `Just'
23:08:39 <pierrot> True
23:08:52 <ski> now what ?
23:10:16 <pierrot> now I'd need something to convert that value into "Just 207.7"
23:10:40 * ski waits for cogs to turn in pierrot's head
23:13:56 <dysfun> i have a cabal sandbox into which i have install fay and fay-text, but when i try to use the fay from it, it complains the fay-text package is hidden. any ideas?
23:14:18 <dysfun> i am invoking it as ./cabal-sandbox/bin/fay
23:20:49 <pierrot> ski: I think that I could do the following:
23:23:25 <pierrot> define a function `lookupNode :: k -> Node k a -> a', and then I'd do `fmap (lookupNode key) (lookup key t)'
23:23:30 <pierrot> would that make sense?
23:28:32 <nshepper1> dysfun: https://github.com/faylang/fay/wiki/Installing-and-running#sandboxes looks relevant
23:29:00 <dysfun> already did that
23:29:15 <dysfun> i just discovered that it was removed from stackage at the end of the 8.x series
23:30:17 <dysfun> so i'm going to try and use it through stack from an old snapshot
23:33:14 <ski> pierrot : it would
23:33:44 <ski> pierrot : only one question : when will `lookup key t' be `Nothing' ?
23:36:07 <pierrot> hmm if `lookup key t' returns `Nothing' then `fmap (lookupNode key) (lookup key t)' would return Nothing, right?
23:36:26 <ski> yes, but that leads back to the same question
23:36:35 <ski> when does `lookup key t' return `Nothing' ?
23:37:40 <ski> if `t' is `Zero k x', can you get `Nothing' ?
23:38:24 <dysfun> yay, it's working on stack lts-8.24
23:39:11 <pierrot> I had implemented lookup key (Zero k x) as if k == key then Just x else Nothing
23:39:17 <pierrot> but I don't think if that's right...
23:40:19 <ski> well, the key labelling a subtree should be the largest key for that subtree
23:40:34 <pierrot> yes, that was my decision...
23:41:09 <pierrot> (it wasn't said in the assignament, but I assumed it that way)
23:41:14 <ski> in your example above, you had `Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4))'
23:41:39 <ski> so, with `lookup "Brasil"' on that, using `k == key', you'd get `Nothing'
23:42:30 <pierrot> yes
23:42:48 <ski> is that the right answer, for that query ?
23:43:38 <pierrot> I think it's not
23:44:00 <ski> how to adapt this case for `lookup', then ?
23:44:19 * Taneb is planning to mess around with Accelerate today
23:44:54 <pierrot> k <= key ?
23:45:42 <Athas> Taneb: what will you be writing?
23:46:27 <Taneb> Athas, I was going to try and write some matrix multiplication stuff
23:46:44 <Taneb> Athas, had a little go yesterday but didn't quite get it
23:46:54 <ski> so if the `key' you're looking for is greater than or equal to the key `k' labelling the tree, that's a success ?
23:47:36 <pierrot> sorry, I inverted it
23:47:47 <pierrot> if was key <= k
23:48:06 <pierrot> it*
23:48:13 <Athas> Taneb: that's a good exercise.  IIRC, it's surprisingly tricky/mind-bending.
23:49:11 <pierrot> hmm but even less or equal would be wrong
23:49:14 <pierrot> 🤔
23:49:43 <ski> example ?
23:50:48 <pierrot> oh, no. Maybe the final result could be Nothing despite it's a success at that moment
23:52:02 <pierrot> I was thinking about something like lookup "Canada" t
23:52:11 <pierrot> where t = Zero "Uruguay" (Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4))
23:52:38 <ski> ok ?
23:53:12 <pierrot> as "Canada" <= "Uruguay", that would return `Node2 "Chile" (Node3 "Argentina" 43.9 "Brasil" 207.7 "Chile" 17.9) "Uruguay" (Node2 "Colombia" 48.7 "Uruguay" 3.4)'
23:53:24 <pierrot> sorry, Just that
23:53:43 <ski> sounds good, since that's where `"Canada"' would be, if it was in the tree at all
23:54:21 <ski> so, you've located the subtree in which to find the key, if present
23:54:46 <ski> how about the `Succ t' case ?
23:55:33 <pierrot> well, I had thought what I told you before
23:56:24 <pierrot> `lookup key (Succ t) = fmap (lookupNode key) (lookup key t)'
23:57:03 <ski> yes, but have you implemented that `lookupNode' ?
23:58:30 <pierrot> Not yet. But its cases should been:
23:58:48 <pierrot> lookupNode key (Node2 k1 a1 k2 a2) and lookupNode key (Node3 k1 a1 k2 a2 k3 a3)
23:59:27 <pierrot> I should define those
