00:13:31 <ertes-w> helo
01:57:40 <merijn> Does anyone here bother marking versions of their packages as preferred on Hackage?
01:59:03 <Athas> merijn: no.
01:59:10 <Athas> I did not even know that is a thing.
01:59:43 <merijn> Athas: You can deprecate/prefer versions, which causes cabal to try to find a plan with a preferred version, only using something else as last resort
02:01:03 <merijn> Athas: I have a tasty output reporter whose interface doesn't change, but I'm still playing around with the formatting, so I end up setting the most recent version as preferred
02:03:04 <cocreature> I’ve seen some packages marking all old versions as deprecated since maintainers don’t want to support them anymore but I’m too lazy to do that myself
02:03:38 <merijn> cocreature: Deprecated also makes cabal only pick them as last resort, so that can avoid breakage that way
02:04:38 <cocreature> nobody maintains old versions of packages anyway in the Haskell ecosystem apart from maybe adjusting bounds
02:11:00 <michowski> Hello guys. I've encountered such a strange thing. I'm using a lazy ByteString for reading from and writing to files/std. My app supports piping, so you can run it like: `app cmd1 | app cmd2 | app cmd3`. When you run it with some flag, you can actually read from file or write to file, like so: `app cmd1 -r file | app cmd2 | app cmd3 -w file` - It reads from file, does some stuff and writes to the same file. And this works just fine
02:11:31 <michowski> However, what happens when you run: `app cmd1 -r file | app cmd2 | app cmd3 > file` is unbelievable! The output which goes to „file” modifies it and thus changes the input for cmd1! It’s like a loop and you get some very strange behaviour. I can imagine it’s because of the lazy implementation, but I still can’t explain how it can possibly work! Any ideas?
02:12:01 <merijn> michowski: Input redirection (i.e. >) empties the entire file immediately
02:12:30 <michowski> Ah...
02:12:34 <merijn> michowski: So the second command makes "file" empty before anything starts
02:12:39 <michowski> Wow
02:13:08 <michowski> Never knew it. Why wouldn't it wait for the execution and then do it, right before writing?
02:13:20 <michowski> execution of the left-side app, I mean.
02:13:34 <merijn> michowski: That's a historical/implementation question for bash/bourne shell
02:14:07 <michowski> Alright. thank you so much. In such a case, do you have any idea for a nice interface for the application, possibly following "The unix philosophy"?
02:14:15 <michowski> Just another "-w" flag for writing to file?
02:14:27 <merijn> michowski: Yeah, that seems the best solution
02:14:39 <michowski> Thank you :) . Awesome thing to know.
02:15:07 <michowski> The "lazy theory" did not make any sense to me given that every piped process was closed.
02:15:21 <michowski> You never know though!
02:22:04 <Taneb> Hey everyone! The company I work for (Myrtle Software) is hiring Haskell programmers! We're based in Cambridge, UK and work to compile neural networks to FPGAs
02:22:10 <Taneb> https://www.myrtlesoftware.com/vacancies/
02:24:37 <noobie_> hi guys, what does it mean if a function has a return type 'm ()', where m is Monad? Is it possible to propagate some value out of such function or not?
02:25:18 <ventonegro> noobie_: in general (for every monad), no
02:25:37 <ertes-w> michowski: i think the issue is a more general one: you have to processes using the same file concurrently…  that is bound to be unreliable
02:25:38 <ventonegro> noobie_: Some monad instance may provide a way to access data
02:25:54 <ertes-w> michowski: *two processes
02:29:42 <ventonegro> noobie_: "()" is the unit type, a type with a single value also written "()"
02:32:48 <kaychaks> Is there some ops on `Map` like `fromList` but with sig `[(k,a)] -> Map k [a]`
02:34:28 <ertes-w> :t M.fromListWith
02:34:30 <lambdabot> Ord k => (a -> a -> a) -> [(k, a)] -> M.Map k a
02:34:52 <ertes-w> :t M.fromListWith (++) . map (fmap pure)
02:34:53 <lambdabot> Ord k => [(k, a)] -> M.Map k [a]
02:35:00 <ertes-w> kaychaks: ^
02:35:55 <ertes-w> although you may want this instead:
02:36:06 <ertes-w> :t M.fromListWith S.union . map (fmap S.singleton)
02:36:08 <lambdabot> (Ord a, Ord k) => [(k, a)] -> M.Map k (S.Set a)
02:39:21 <royal_screwup21> so I was reading up on how to create a binary tree http://shuklan.com/haskell/lec06.html#/0/2 What's with all the blank spaces up above the "add" function?
02:39:44 <michowski> ertes-w: "you have to processes using the same file concurrently…  that is bound to be unreliable"
02:40:14 <michowski> ertes-w: Why concurrently? I was expecting the the piped processes to execute first and THEN redirect output to file.
02:40:22 <michowski> Apparently it's not the case with how redirection works.
02:40:56 <ertes-w> michowski: no, the processes run at the same time
02:42:16 <ertes-w> (and i'm glad they do)
02:42:48 <michowski> Alright, seems that I need to educate on that matter.
02:43:40 <ertes-w> michowski: the usual approach is to write to a temporary file and then rename it to replace the original file
02:43:51 <tdammers> lazy evaluation in Unix predates Haskell by two decades :)
02:44:03 <michowski> Haha
02:44:14 <tdammers> it's actually quite a common thing to do
02:44:16 <ertes-w> michowski: that's also safer…  imagine one of the commands in the pipe fail…  now the original file is gone and you're left with a corrupted file
02:45:02 <tdammers> the most popular use case is avoiding unnecessary disk space usage though
02:46:27 <michowski> Alright, alright! I really know nothing, it seems. Do you know any good resources to learn more about this stuff?
02:46:50 <merijn> michowski: Any good intro book on unix?
02:47:08 <merijn> I honestly don't remember what I used to learn all that, though
02:47:57 <michowski> Yes. Although, the common problem I have with "intro books" is that I need to skip so much stuff explaining the very basics. Perhaps it's just my wrong attitude though.
02:48:40 <tdammers> I recommend Eric S. Raymond's "The Art Of Unix Programming"
02:48:59 <tdammers> it's more about Unix philosophy than actually programming on Unix, really
02:49:17 <tdammers> there's a free-to-read online version out there, shouldn't be hard to find
02:51:04 <merijn> hmmm...I should've included a progress bar for the haskell build part of my makefile >.>
02:51:31 <ertes-w> i learned it mostly from experience and playing around
02:52:11 <ertes-w> merijn: how do you make a progress bar in a makefile?
02:52:41 <merijn> ertes-w: You don't. You realise that 2 years ago you should've started out with Shake instead of using make and then you'd have it for free >.>
02:52:52 <tdammers> progress bars suck
02:53:13 <ertes-w> i'm actually kind of a fan of the 'pv' program
02:53:28 <tdammers> they rarely provide useful information, and they tend to mess up the terminal when you're forwarding through a bunch of ssh connections, terminal multiplexers, and the like
02:53:39 <merijn> tdammers: I dunno, staring at a single line of "CABAL new-build project" for 10 minutes with no clue how far it is isn't helpful either
02:54:11 <tdammers> no, it's not, which is why make tends to forward output from its children to the controlling terminal
02:54:27 <ertes-w> tdammers: i find progress bars very helpful, even if they only display relative information
02:54:33 <tdammers> some sort of progress indicator would be nice of course, but I don't think stdout / stderr are the appropriate channel
02:54:56 <tdammers> and if you have to do it that way, at least make it opt-in
02:55:02 <tdammers> (looking at you, npm)
02:55:06 <ertes-w> btrfs send … | pv | ssh blah btrfs receive
02:55:21 <tdammers> yeah, something like that
02:55:25 <ertes-w> now i know how much data has been sent and at what rate it's currently sending
02:56:03 <tdammers> I'd love to see some sort of generally accepted convention for a progress report channel
02:56:39 <tdammers> something like, read the $PROGRESS_FILE env var, and write progress updates to the file it points to
02:57:16 <tdammers> then you can run something like cat $PROGRESS_FILE | pv in a separate window, or you could build a simple wrapper that handles progress information in a sane way
02:57:25 <tdammers> or you could even feed it into, idk, dzen or xmobar or whatever
02:57:34 <ertes-w> tdammers: i have written a package called 'progress-meter' for progress info on stderr that can deal with concurrent log output
02:57:56 <ertes-w> i don't know of any more satisfying solution except perhaps to settle on a certain FD number
02:58:02 <ertes-w> stdprog
02:59:32 <tdammers> the convention would be super simple
02:59:56 <tdammers> a producing program would just look at $PROGRESS_FILE; if it points to a valid file, it would write progress information into that file, one line per update
03:00:43 <tdammers> so you could either point it to a regular file and tail -f it, or you could point it to a fifo and use cat, for the simplest possible way of displaying progress
03:01:13 <tdammers> but you could also easily use it to drive other programs to display more advanced progress information, including GUI programs and whatnot
03:01:18 <tdammers> it'd also be super script friendly
03:01:21 <tdammers> *and*
03:01:30 <ertes-w> tdammers: that's inconvenient
03:01:45 <tdammers> what's inconvenient about it?
03:01:47 <ertes-w> now i need an extra terminal, while the one where the action happens just idles around
03:02:03 <ertes-w> or i need extra engineering to display the progress info concurrently
03:02:30 <tdammers> $PROGRESS_FILE could just default to stderr or stdout, you know
03:03:04 <ertes-w> that's good enough i suppose
03:03:11 <tdammers> always having progress information in stdout is more inconvenient IMO
03:03:25 <ertes-w> i would just say: FD 3 is progress output
03:03:34 <ertes-w> stdout is the wrong channel anyway
03:04:11 <tdammers> oh sure, but stderr is also bad, especially when you're running multiple programs in concert, or when the program that produces the progress info also drives other programs that dump warnings into stderr
03:04:27 <tdammers> FD 3 would be awesome, but I bet it'd break a lot of existing programs
03:04:33 <ertes-w> multiple programs writing to stderr is wrong anyway, even if they're just displaying log output
03:05:10 <tdammers> even if you route stderr from subprocess through the main process, you still have a problem
03:05:26 <tdammers> you have to pick between displaying only warnings, or only progress, or both but in a broken way
03:05:32 <ertes-w> unless you pipe each individually to some kind of collector
03:05:56 <ertes-w> i agree that stderr is a poor choice
03:05:59 <tdammers> well yes, and that's exactly what the $PROGRESS_FILE idea would do - send progress updates to a collector
03:06:27 <tdammers> if you want it to work like a pipe, then make it a pipe, you just have to hook it into the file system so that you can reliably reference it
03:06:44 <ertes-w> but until there is a standard for progress info i will send to stderr, and let's face it, there's not gonna be one any time soon =)
03:07:05 <tdammers> that's why I said I wish there were a standard
03:07:14 <ertes-w> progress-meter checks if stderr is a terminal, and if not, it only writes log output
03:08:16 <tdammers> btw., the PROGRESS_FILE proposal would also make it relatively easy to write a wrapper that checks an arbitrary program's stderr, filters out everything that looks enough like a progress bar, and routes that to the progress file, outputting only the remaining stuff
03:08:18 <ertes-w> that's kind of the "standard" we currently have
03:08:37 <tdammers> a standard for writing progress updates to a separate channel, I mean
03:16:04 <michowski> So another question which I'd like to ask regarding ByteString: Are default ByteString IO functions suitable for pipeable program, or I need some pipes library to achieve a reasonable performance?
03:16:46 <michowski> By "pipeable" I mean "such that you can run it like so: program cmd1 | program cmd2 | program cmd3"
03:22:24 <ertes-w> michowski: while ByteString has a lazy input interface its use is discouraged…  if you need stream processing, you should use a stream processing framework
03:22:31 <ertes-w> (lazy output is fine though)
03:23:05 <michowski> May I ask for some reasoning why it's discouraged for input?
03:24:33 <michowski> Because aseon uses it and I wonder if it would be straightforward to use a different string representation for stdin.
03:25:06 <michowski> And make it work with aeson, of course.
03:30:40 <tdammers> the problem with lazy IO is that it often leads to surprising results, and that it makes file handle cleanup unpredictable
03:31:35 <tdammers> you can do line-buffered IO and such with plain old strict IO though, no streaming libraries needed
03:38:25 <cocreature> michowski: aeson exposes attoparsec parsers that you can use in combination with streaming libs. for pipes there is already a package called “pipes-aeson”, you can probably find someting similar for other packages
03:45:38 <ertes-w> BTW, please don't call it lazy I/O, because lazy O is totally fine
03:45:43 <ertes-w> lazy input is the problem
03:58:09 <osa1> anyone here have experience with the dejafu library? I'm wondering if deadlock detection is improved since the 2016 paper
03:58:47 <osa1> source code seems to be different than what's shown in the paper. for example, I can't see `AKnowsAbout` etc. constructors in the current source
03:59:22 <osa1> threre's also a deadlock test in the dejavu-tests package so it seems like deadlock detection is improved since the paper
04:01:55 <Taneb> osa1: I'm aware the author has been making improvements but I'm afraid I don't know the scope of them :(
04:02:28 <tdammers> ertes-w: lazy output isn't entirely fine either, just less not-fine
04:03:22 <tdammers> come to think of it, there really isn't any such thing as lazy output, just laziness in general
04:03:54 <tdammers> output just consumes stuff, and if said stuff happens to be lazy, then yes, it gets evaluated lazily when you try to output it
04:04:09 <osa1> how is lazy output less not-fine than input?
04:04:12 <osa1> thanks Taneb
04:04:40 <tdammers> osa1: with lazy input, you can easily have a file closed on you when before you're done reading from it
04:04:58 <osa1> same for output, you can try to write to a closed handle
04:06:38 <tdammers> yeah, but the writing happens the moment the write actions get executed; the read actions however defer reading to whenever somebody decides to evaluate the output
04:07:01 <tdammers> so if you do open, write, close, then that's generally safe
04:07:26 <tdammers> but open, read, close, do stuff may not, because the close may happen before the "do stuff" part
04:07:51 <osa1> ah, makes sense. write operations usually don't return anything that you can evaluate later in the future.
04:08:02 <tdammers> so you have to either force the stuff you've read, or leave the file handle dangling, or move the "do stuff" part inside the open/close block
04:08:23 <tdammers> yes. writing doesn't defer actual I/O
04:08:51 <tdammers> except of course at the OS level, where stuff may or may not get buffered
04:10:11 <barrucadu> osa1: Detecting deadlock involving only a subset of the threads (which GHC can sometimes do) isn't done.  It'll only report deadlock if every thread is blocked.
04:10:49 <barrucadu> However there is an execution length bound by default, so if your main thread is blocked and a few other threads are livelocked, in practiced that'll show up as the execution being aborted after a while
04:10:58 <michowski> Ok, thank you everyone :) . It seems that I will just stick to default ByteString IO for now and analyze every other option in the meantime.
04:11:03 <osa1> awesome, thanks barrucadu
04:11:25 <osa1> barrucadu: this may worth mentioning somewhere in the README/documentation. or is it already there? I can't see anything relevant in the docs
04:11:40 <barrucadu> Yeah I should add that somewhere
04:11:48 <merijn> tdammers, osa1: You forgot the far more common issue with lazy input
04:12:13 <merijn> Which is most lazy operations use their own handle and close it at the end, so premature closing is not an issue. But not closing at all and/or closing way too late is
04:12:53 <merijn> File handles are a limited resource, in long running processes, like servers, is a real problem, since if you run out, you're boned
04:15:58 <osa1> we actually have this problem today even though we don't do any lazy IO -- warp sometimes leaks sockets :) we can't reproduce it in test environment so as a workaround we restart it when our file descriptor monitor is triggered. *sigh*
04:16:24 <osa1> happens very rarely
04:17:47 <michowski> And I thought that Haskell lazy evaluation on its own is already a complexed topic... Combined with all the requirements like streaming, error handling, different use cases it seems like a really tough stuff...
04:18:36 <merijn> michowski: It's not so bad. Streaming libraries like pipes/conduits already deal with most of that for you
04:18:48 <merijn> michowski: lazy IO and lazy evaluation are only tangentially related
04:19:18 <merijn> michowski: IO is strict and you need to use unsafeX to end up with lazy IO
04:19:57 <osa1> yeah so the problem I mentioned is more about resource management and not directly related to lazy IO -- you could have the same problem in other languages.
04:20:35 <michowski> Ah, alright :)
04:25:22 <michowski> Haskell really makes me feel like learning C again
04:25:35 <osa1> barrucadu: I'm looking at the round-robin scheduler -- it seems like it doesn't have a "ready" queue or anything like that, so if I have hundreds of threads, but most of them are blocked in an MVar operation, it'll iterate through these threads rather than only considring threads that are ready for making progress. is that right or am I missing anything?
04:25:58 <osa1> I don't think C makes resource management any easier but you could maybe try languages with RAII like C++ or Rust :)
04:28:22 <barrucadu> osa1: It's not exceptionally clear, but the scheduler is only given a list of runnable threads.  That's another docs improvement I should make.
04:29:16 <osa1> barrucadu: ah! so "runnable" in the documentation means that. makes sense :)
04:31:19 <michowski> osal: Ofc. I did not mean that C makes life any easier, such a statement would be insane! Just seeing all the Haskell libraries with C FFI and understanding how you can build a beatiful abstraction on top of a bare-metal code is inspiring :) .
04:31:57 <michowski> Very often I wish I could understand source code of a Haskell library.
04:32:00 <merijn> michowski: If you already know C the Haskell FFI is actually really easy to use
04:33:11 <merijn> I would even call it trivial, as long as these two caveats hold: 1) You don't want/have to pass/return structs by value and 2) you don't want/have to mutate C structs from within Haskell.
04:33:31 <merijn> If you do need those two things it becomes slightly more obnoxious, but still not really bad
04:38:27 <saurabhnanda> quick qn: in haddock, how do I bold/italics something?
04:38:57 <osa1> saurabhnanda: see hackage page
04:39:01 <merijn> saurabhnanda: https://haskell-haddock.readthedocs.io/en/latest/markup.html#markup
04:39:25 <saurabhnanda> merijn: yup thanks :)
04:39:46 <saurabhnanda> wow! what text formatting is this?
04:39:46 <raynold> ahh it's a wonderful day :D
04:40:30 <Taneb> saurabhnanda: my understanding it's original to Haddock
04:40:42 <saurabhnanda> hmm...
04:41:05 <Taneb> Similar to markdown but I think that's because it's solving the same problem
04:41:29 <merijn> Taneb: Also because markdown is based on old plain text mailing list conventions, just like Haddock
04:44:03 <merijn> Man...I wish there was a version of (/) that called fromIntegral on it's arguments...
04:46:08 <osa1> :t curry (uncurry (/) . bimap fromIntegral fromIntegral)
04:46:10 <lambdabot> (Integral a2, Integral a1, Fractional c) => a1 -> a2 -> c
04:46:13 <osa1> :-p
04:47:35 <mclaren> for a minute i thought that meant the integral in calculus. lmao
05:10:20 <Boomerang> :t (/) `on` fromIntegral
05:10:22 <lambdabot> (Integral a, Fractional c) => a -> a -> c
05:11:19 <merijn> Boomerang: hah, I actually forgot about on!
05:12:03 <Boomerang> :)
05:12:38 <ertes-w> tdammers: what are the issues with lazy output?
05:17:10 <cloudhead> hey, can anyone help with this linking error http://lpaste.net/359822 ? I'm using ghc-8.2.1 with ld.gold on linux - I've already googled it but couldn't find anything..
05:18:18 <cloudhead> I have the same issue with the clock package
05:18:25 <merijn> cloudhead: First question for any and all linker errors: Are you using Arch?
05:18:40 <cloudhead> merijn: yes
05:18:46 <merijn> cloudhead: Ding, ding.
05:19:01 <barrucadu> haha
05:19:14 <cloudhead> I know about the dynamic linking issue, but I thought that using stack's own ghc it wouldn't be an issue?
05:19:15 <merijn> cloudhead: Arch changed their Haskell setup earlier this year, guaranteeing that almost everything is completely fucked
05:19:20 <cloudhead> hahaha
05:19:22 <cloudhead> hm
05:19:34 <merijn> cloudhead: Maybe, I honestly have no idea how stack installs ghc and how to ensure it uses that one
05:19:54 <cloudhead> I see I see
05:20:02 <merijn> cloudhead: These look like C bindings
05:20:06 <cloudhead> yes
05:20:26 <merijn> cloudhead: -fPIC refers to Position Independent Code (which is what you need for relocatable libraries, like dynamic libraries)
05:21:05 <cloudhead> I see
05:21:57 <merijn> cloudhead: Could be that Arch has their C compiler configured with different default flags, etc.
05:22:19 <cloudhead> yeah I've never had issues until the static ghc clusterfuck tbh
05:22:21 <merijn> cloudhead: Basically, given the frequency of problems my default assumption is: Arch fucked up, unless proven otherwise ;)
05:22:28 <cloudhead> yeah
05:22:53 <k0ral> Hello
05:23:45 <int-e> It's linking an executable and passing -fno-PIE to gcc ... is this somehow not passed on to gold?
05:23:52 <cloudhead> ok I need to figure out how to use only the stack ghc then, that might be a solution
05:24:12 <cloudhead> int-e: yeah it could be an ld.gold issue too.. do you know how to select which linker to use?
05:29:09 <k0ral> is it possible to use dependent types to express a "set membership" constraint in Haskell ? For example: `removeElement :: (Member e phantom1 ~ True, Member e phantom2 ~ False) => e -> SetType phantom1 -> SetType phantom2`
05:29:33 <merijn> k0ral: Well, since Haskell doesn't *have* dependent types...no
05:29:52 <merijn> k0ral: You can try and get by with DataKinds and TypeFamilies, but that'll become painful quick
05:30:02 <EvanR> i have a feeling f x = True and f x = False are bad ways to say his
05:30:04 <EvanR> this
05:30:41 <k0ral> merijn: well, we have finite-typelits, I wondered if we could express more powerful things in Haskell
05:31:06 <merijn> k0ral: Some inspiration for you: https://gist.github.com/merijn/6130082
05:31:25 <int-e> cloudhead: not sure, editing ghc's shipped settings file may work? (that would be  /usr/lib/ghc-8.2.1/settings  as far as I can see)
05:31:35 <k0ral> EvanR: how would you "say" this ?
05:32:25 <EvanR> a set is either empty or some element added to a set, and somehow you normalize it (sorting?)
05:32:39 <EvanR> then you can define a remove for Add x s to be s
05:32:52 <EvanR> this is my random speculation
05:33:54 <k0ral> merijn: my question is about whether it's feasible, not about how painful it is ; if I can encapsulate the pain in a non-leaky abstraction, I'm willing to endure it :)
05:33:54 <tdammers> ertes-w: same as with lazy evaluation, really (insofar as lazy output is a thing even): things happening on a different thread than you expect
05:34:21 <ertes-w> tdammers: the lazy part is pure though, so i don't really care on which thread they happen
05:34:31 <ertes-w> *it happens
05:34:41 <merijn> k0ral: Is it possible? I think so. Is it possible to do in an encapsulated way? Maybe, my intuition says no. Will it be painful? Yes. :)
05:34:45 <k0ral> EvanR: it would take linear time to resolve the constraint, isn't that bad ?
05:34:56 <merijn> k0ral: Performance will suck, yes
05:35:02 <tdammers> ertes-w: I'd say the bigger picture is that Haskell ignores performance as an effect
05:35:19 <EvanR> a nice constructive theory of finite sets, is one thing. then you want it to be fast...
05:35:34 <EvanR> head explode
05:36:22 <EvanR> arent the sets going to be pretty small for type level stuff
05:36:30 <ertes-w> tdammers: putStrLn (repeat 'X')  -- is that not a good way to print an infinite stream of Xes?
05:36:46 <k0ral> EvanR: no, and there's no reason I should assume that anyway
05:36:51 <merijn> ertes-w: Well, I would say it isn't, but for reasons unrelated to laziness :p
05:37:04 <ertes-w> merijn: tell me
05:37:18 <merijn> ertes-w: No block based buffering :p
05:37:31 <merijn> k0ral: It's definitely never going to be fast in Haskell
05:37:33 <ertes-w> well, hSetBuffering before that
05:37:54 <merijn> k0ral: If you want this AND fast, you really should be looking at things like Idris
05:38:14 <EvanR> k0ral: for speed, i presume that you could develop a theory, develop a fast data structure, develop an isomorphism between the two, then prove things about the nice theory and compute with the data structure. but i dont know if anything actually does this
05:38:32 <EvanR> cough idris and speed...
05:39:07 <EvanR> my types for this interface here take about 20 minutes to check, and its only 3 out of 10 of the axioms
05:39:14 <merijn> ertes-w: Type level sets will certainly be faster in Idris than Hasochism :p
05:39:24 <merijn> s/ertes-w/EvanR
05:39:39 <EvanR> and actually, its axioms for set theory :)
05:39:52 <EvanR> we havent even implemented the interface yet
05:40:48 <ertes-w> and there i thought that i mattered…  that i somehow played an important role in the universe…  that someone somewhere on the internet addressed *me*…  *directly*…  and then i learned the truth…  that someone who got my hopes up really just sucked at tab completion
05:41:54 <exio4> ertes-w: thanks for making my morning :)
05:43:32 <k0ral> I never thought I would reach that day so early where I consider switching from Haskell to another language... just because it's missing dependent types 
05:44:16 <ertes-w> do i have 50 fields?  i do have 50 fields!
05:44:46 * supercynic powers up
05:44:48 <EvanR> dependent types is a mind f****
05:45:25 <exio4> f****? forth? 
05:46:26 <supercynic> fuckr…  because everything is better with a missing e
05:46:54 <Taneb> exio4: obtuse and confusing but extremely powerful? Forth sounds about right
05:47:21 <supercynic> is forth really that powerful?
05:47:42 <Taneb> I've heard so but I'll admit I've never actually used it
05:48:58 <mantasg> Hi guys. If I have two Conduit sources (a :: Source IO Int) and (b :: Source IO Int) how to I sequence them into one combined source?
05:49:48 <phaazon> hi peeps
05:49:55 <k0ral> mantasg: (>>) ?
05:49:55 <phaazon> what is the best way to persist (with persistent) enums?
05:50:04 <phaazon> fromEnum and use an Int?
05:52:53 <mantasg> k0ral: Of course! Thank you.
05:54:44 <merijn> phaazon: https://github.com/yesodweb/persistent/blob/master/docs/Persistent-entity-syntax.md#field-level
05:54:57 <phaazon> thanks merijn 
06:18:34 <ttoe> is Data.Vector.Storable Vector able to hold tuples of Doubles? i am trying to zip two vectors, to make tuples..
06:19:42 <ttoe> I always get error:  No instance for (Storable (Double, Double))         arising from a use of ‘zipColumns’
06:19:44 <merijn> ttoe: Depends, do tuples have a Storable instance?
06:19:48 <opqdonut> there's no Storable instance for tuples
06:19:52 <merijn> ttoe: Right, so they don't
06:19:57 <opqdonut> somebody else was missing one just some time ago too
06:20:07 <opqdonut> but it seems Storable is for types that correspond to C types
06:20:28 <c_wraith> Yes.  Storable gets heavily overused..
06:20:30 <merijn> opqdonut: Not really
06:20:31 <ttoe> hmm ok thanks for confirming. i did not know how to determine that myself
06:20:43 <ttoe> I am using it because hmatrix seems to use it
06:20:52 <merijn> opqdonut: Storable is for types that have specific memory layout
06:20:58 <opqdonut> a tuple Storable instance is pretty simple to write though
06:21:03 <c_wraith> merijn: no, really.  it's part of the FFI
06:21:05 <merijn> ttoe: You can define your own datatype + storable instance
06:21:23 <merijn> c_wraith: The fact that it's defined in the FFI and used by that does not in anyway mean it's limited to that
06:22:02 <c_wraith> merijn: it means it makes design decisions that don't make sense in other contexts.
06:22:04 <merijn> c_wraith: Storable is literally just "a datatype that you can sensibly peek/poke"
06:22:11 <merijn> c_wraith: Such as?
06:23:01 <ttoe> i'll look into that. maybe i can just convert hmatrix's solver output to "normal" vectors though, using toList and fromList again
06:24:25 <merijn> c_wraith: The only things it defines is: alignment, size, peek, & poke. Which corresponds to my definition of "specific memory layout" and doesn't seem all that tied to C in any way
06:24:49 <c_wraith> merijn: being only for fixed-size data (C data is fixed-size), having no plan for dealing with sum types (C doesn't have sum types)
06:25:04 <opqdonut> there's a pretty natural tuple instance, but it's missing for some reason
06:25:20 <merijn> c_wraith: That doesn't contradict my description, though?
06:26:02 <c_wraith> merijn: it contradicts "useful for non-FFI purposes"
06:26:22 <merijn> c_wraith: Counter-example exhibit A: https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/Model.hs#L60-L87
06:26:26 <cocreature> isn’t Data.Vector.Storable already an example where it’s usable for non-ffi purposes?
06:26:37 <merijn> c_wraith: Please enlightend me how to accomplish that without Storable
06:26:39 <merijn> cocreature++
06:26:41 <cocreature> and the store library uses it as well iirc
06:26:49 <c_wraith> cocreature: Data.Vector.Storable is FFI
06:26:57 <merijn> c_wraith: I disagree
06:27:12 <merijn> Data.Vector.Storable is a vector of object with fixed memory layout
06:27:19 <merijn> i.e., see my example
06:27:45 <cocreature> if you define everything that uses Storable as FFI then sure Storable is only for FFI
06:28:59 <c_wraith> The only reason to prefer Data.Vector.Storable over Data.Vector.Unboxed is for using it in the FFI...
06:29:17 <c_wraith> If you're doing anything else with it, you're paying a huge performance cost for nothing
06:31:36 <merijn> c_wraith: You still haven't answered how you'd do my example without Storable vector
06:33:09 <merijn> Unboxed only works sensibly simple types like the numeric ones
06:33:21 <c_wraith> Unboxed has tuple instances..
06:33:44 <merijn> c_wraith: Which works by decomposing into multiple vectors
06:34:09 <merijn> Unboxed vector of (a,b) is implemented by simply using a separate unboxed 'a' and unboxed 'b' vector
06:34:28 <merijn> That's unacceptable as it completely ruins caching
06:34:29 <c_wraith> Yes, column-oriented layouts have big advantages when composing things of different sizes.
06:34:52 <merijn> c_wraith: The unboxed version is dramatically slower due to ruined caching
06:35:12 <cocreature> merijn: have you actually measured if the overhead incurred by Storable doesn’t outweigh the cache benefits?
06:35:17 <merijn> cocreature: Yes
06:36:26 <merijn> cocreature: The Storable instance is pretty trivial to optimise, so I don't really expect that have that much overhead anyway
06:38:15 <lyxia> Also how's Storable.Vector Int different from Unboxed.Vector Int
06:38:42 <EvanR> i didnt really understand what "storable based vectors" means
06:38:46 <c_wraith> Unboxed removes the indirection that allows the laziness
06:38:50 <lyxia> One uses Storable, the other Prim, but they look the same modulo unboxedness
06:38:58 <c_wraith> err.  allows laziness
06:39:19 <EvanR> storable vector allows laziness somehow?
06:39:24 <c_wraith> Oh, wow, I totally misread that.  sorry, it doesn't
06:39:43 <merijn> EvanR: No
06:39:52 <EvanR> so what is the difference
06:40:19 <EvanR> storable vectors allow more kind of elements, not limited to unboxables?
06:40:48 <merijn> EvanR: Storable vectors allow anything with a Storable instance
06:41:31 <merijn> lyxia: Well, unboxed uses ByteArray, so that might reduce fragmentation compared to ForeignPtr. OTOH copying ByteArray's might slow down GC
06:41:59 <EvanR> which one uses foreignptr
06:42:04 <cocreature> Storable
06:42:10 <EvanR> wacky
06:42:12 <merijn> But I don't see any particular reason to expect Storable to be significantly slower, unless you have a weirdly complex/slow storable instance
06:42:13 <c_wraith> Since it's for the FFI, it has to
06:42:15 <lyxia> merijn: can the GC move ByteArrays around?
06:42:18 <merijn> lyxia: Yes
06:42:30 <lyxia> Okay thanks.
06:42:40 <EvanR> didnt know that either
06:42:49 <cocreature> only if they’re unpinned
06:42:54 <cocreature> iirc pinned byte arrays have the same type
06:43:00 <c_wraith> I mean, the whole purpose is to get a Ptr value out...
06:43:04 <merijn> cocreature: Ah, could be, not sure about that
06:43:20 <cocreature> https://hackage.haskell.org/package/ghc-prim-0.5.1.0/docs/GHC-Prim.html#v:newByteArray-35-
06:44:05 <EvanR> what does creating a basic vector create, unpinned?
06:48:00 <lyxia> looks like it's unpinned. Unboxed uses Primitive under the hood, and it calls newByteArray.
06:48:19 <EvanR> readArrayArrayArray# haha
06:50:20 <lyxia> c_wraith: Storable is also useful to have a vector that doesn't take twice the memory it needs because of a stop-and-copy GC (on top of avoiding the copy in the first place).
06:52:52 <lyxia> The allocation may use some FFI calls, but after that the vector can be used only on the Haskell side.
06:53:21 <EvanR> its interesting that storable vector of word8 and bytestring are essentially the same thing, but we dont have a standard conversion process even a safe one
06:53:59 <EvanR> yet both are in use
06:54:50 <merijn> EvanR: Converting is fairly easy
06:54:57 <merijn> EvanR: Safety depends on how you define safe?
06:55:14 <merijn> EvanR: https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/Model.hs#L101-L105
06:55:59 <EvanR> yes applying a function is easy
06:56:01 <merijn> EvanR: Just gotta make sure you don't use the ByteString while using the Vector
06:56:10 <EvanR> safe would be copy it
06:56:25 <EvanR> unsafe would not
06:56:36 <merijn> EvanR: Yeah, you can also safely do this conversion, but for my use-case that is unnecessary overhead
06:57:09 <EvanR> im saying one or both should be provided as functions somewhere since libs use both 
06:57:10 <merijn> (I'm only reading the vector, not writing, and the bytestring is only used for reading/writing to the database)
06:57:35 <EvanR> instead of having the user hack foreign pointers
06:58:30 <merijn> EvanR: That would require vector to add a bytestring dependency (or vice versa), though
06:58:47 <EvanR> i see it cant go in either lib since they pretend either other dont exist
06:58:57 <EvanR> each other
07:00:01 <lyxia> Surely there is some all-contiguous-memory-things library to do these conversions?
07:00:40 <EvanR> there is a questionable package with only this one thing im talking about in it
07:01:39 <EvanR> but i think people would rather hack foreign pointers than rely on it
07:01:45 <EvanR> :(
07:04:26 <cocreature> do we have something in base that will give me all prefixes of a list?
07:05:05 <merijn> init ?
07:05:21 <merijn> eh, no inits
07:05:27 <cocreature> ah thanks
07:05:28 <merijn> > inits [1..5]
07:05:31 <lambdabot>  [[],[1],[1,2],[1,2,3],[1,2,3,4],[1,2,3,4,5]]
07:05:38 <cocreature> I knew I had seen it somewhere but couldn’t remember the name :)
07:08:35 <EvanR> @src inits
07:08:35 <lambdabot> inits []     = [[]]
07:08:35 <lambdabot> inits (x:xs) = [[]] ++ map (x:) (inits xs)
07:08:56 <EvanR> obligatory [] first
07:09:14 <cocreature> I just used tail . inits :)
07:11:11 <EvanR> that implementation seems wacky
07:11:18 <EvanR> [[]] at each step
07:11:55 <merijn> EvanR: You do know that @src is just make believe, right?
07:12:11 <EvanR> yeah
07:12:34 <EvanR> supposed to be the coolest version, not necessarily fastest
07:12:46 <supercynic> i wish bytestring would just die in favour of vector
07:13:22 <EvanR> in favor of storable vector?
07:13:33 <supercynic> in favour of whatever fits the task
07:13:44 <supercynic> in most cases storable, yes
07:14:31 <merijn> I just wish we'd release the package bytestring as "bytes" with ByteString renamed to Bytes and reduced bytestring to a shim of re-exports from bytes with "type ByteString = Bytes"
07:14:51 <EvanR> huh
07:15:05 <cocreature> how to solve the Haskell string problem: rename bytestring
07:15:23 <c_wraith> the only string problem is that people don't understand that "strings" are not simple.
07:15:39 <c_wraith> The reason there are so many string types?  They do different things.
07:15:45 <c_wraith> This is not a language problem.
07:15:48 <merijn> EvanR: Too many newcomers still think ByteString is anything related to Bytes
07:16:00 <EvanR> what is Bytes
07:16:02 <cocreature> merijn: did you mean String? :)
07:16:07 <supercynic> we don't really have a "string problem" other than that [Char] is the default string type
07:16:12 <cocreature> because ByteString is related to bytes :)
07:16:22 <merijn> cocreature: Yes
07:16:26 <supercynic> lazy Text would be a better choice for most things
07:16:27 <merijn> cocreature: Typing is hard...
07:16:41 <c_wraith> even ByteString isn't as simple as possible.
07:16:59 <c_wraith> ShortByteString is simpler
07:17:40 <cocreature> if only ShortByteString had a decent API …
07:17:44 <c_wraith> But the two aren't interchangeable.  They do different things because they have different use cases.
07:18:00 <c_wraith> Once again, there is not a problem with them being different types.
07:18:01 <supercynic> however, bytestring is such a pointless library…  i propose that we add a lazy vector type and then just let bytestring die
07:18:06 <c_wraith> Even if they're not strings
07:18:27 <supercynic> newtype LazyVec v a = LazyVec { fromLazyVec :: [v a] }
07:18:28 <c_wraith> supercynic: Vector doesn't have anything that matches the use case of ShortByteString
07:18:28 <EvanR> i like bytestring
07:18:47 <supercynic> c_wraith: that could be added as well
07:19:45 <cocreature> I thought unboxed vectors are relatively close to ShortByteString?
07:19:50 <supercynic> c_wraith: also ShortByteString is very close to unboxed vectors
07:19:59 <cocreature> ah I guess they add slicing
07:20:15 <c_wraith> avoiding slicing is the whole reason to use ShortByteString
07:20:33 <supercynic> well, there is nothing wrong with adding a variant of Vector that can't be sliced
07:20:43 <cocreature> it’s not the whole reason, avoiding pinning is also a good reason :)
07:20:43 <supercynic> and then you basically have a generalised ShortByteString
07:21:17 <supercynic> pick unboxed unslicable vector of Word8, then you have exactly ShortByteString
07:21:23 <supercynic> except you can still use the full vector API =)
07:21:32 <supercynic> ShortByteString is super-annoying to use
07:22:32 <c_wraith> wow, Data.Lens doesn't even have anything for it.
07:22:40 <c_wraith> Err.  lens
07:22:45 <cocreature> if it’s not in lens it doesn’t exist
07:32:15 <boothead> Hi folks. I'm trying to figure out how to use the Map type function from singletons, but I'm getting stuck on how the TyFun works.
07:32:42 <boothead> Can I use this with my own * -> * type families? Or do I need to write my own Map type family?
07:38:31 <lyxia> boothead: you can use it with your type families, though you have to go through some hoops.
07:42:24 <boothead> lyxia: do you know how I can use it or where I can read up? Concrete example is wanting to Map (* -> Symbol) over a type level list so can then call fromSing to get [String] at the type level...
07:42:58 <Michowski> Is there any monad similar to Either, but with which I could combine the results of consequent failures? Of course I could just implement my own version of "bind-like" operator, but maybe there's a more elegant solution?
07:43:34 <Michowski> For example, for Either String Something I would like to concatenate all the "Lefts".
07:43:55 <Taneb> Michowski: what would "leftish x >>= \k -> if k then leftish y else leftish z" get you
07:43:56 <Michowski> When calling e1 >>= e2 >>= e3
07:43:58 <lyxia> boothead: Say you have a type family F :: * -> *, you need to define a "defunctionalization symbol", which is just a data type: data FSym0 (l :: TyFun * *), that represents the function F at the type level. You need to define application for that symbol, type instance Apply FSym0 x = F x, now you can write Map FSym0 xs
07:44:33 <cocreature> Michowski: that’s not possible for Monad but you can get an Applicative instance for a type like that
07:44:49 <lyxia> boothead: that is how you write "map F xs" with singletons.
07:45:12 <cocreature> Michowski: try implementing your own bind operator any you’ll quickly see the problem
07:45:14 <lyxia> boothead: I believe there is some quasiquotation to help with all that boilerplate.
07:45:20 <Michowski> Ah yes.
07:45:33 <Michowski> That collides with the definition of monad I guess.
07:45:54 <cocreature> Michowski: if an Applicative instance suffices, take a look at https://hackage.haskell.org/package/validation-0.6.2/docs/Data-Validation.html#t:AccValidation
07:45:57 <Michowski> Which "stops on failure".
07:46:59 <boothead> lyxia: thanks, and wow :-)
07:48:01 <boothead> another question: Why doesn't a type family already "represent F at the type level" my mental model is that that's exactly what a type family is...
07:48:14 <cocreature> boothead: it’s really more of a “meh just give us real dependent types” than a “wow”
07:48:14 <Michowski> cocreature: Thank you, exactly what I was looking for.
07:48:45 <ventonegro> @hoogle Bool -> Except e ()
07:48:45 <lambdabot> Control.Monad.Except mapExcept :: (Either e a -> Either e' b) -> Except e a -> Except e' b
07:48:45 <lambdabot> Control.Monad.Trans.Except mapExcept :: (Either e a -> Either e' b) -> Except e a -> Except e' b
07:48:45 <lambdabot> Intro mapExcept :: (Either e a -> Either e' b) -> Except e a -> Except e' b
07:49:20 <ventonegro> @hoogle Bool -> ExceptT e m ()
07:49:20 <lambdabot> Control.Error.Util isLeftT :: (Monad m) => ExceptT a m b -> m Bool
07:49:20 <lambdabot> Control.Error.Util isRightT :: (Monad m) => ExceptT a m b -> m Bool
07:49:20 <lambdabot> Control.Error.Safe tryAssert :: (Monad m) => e -> Bool -> ExceptT e m ()
07:49:52 <cocreature> Michowski: there’s also basically the same type in the "either" package if you already depend on that
07:50:01 <cocreature> I have no idea why we have both tbh
07:50:34 <lyxia> boothead: you can't pass a type family as an argument to another one, you can only match on actual "data" types.
07:50:44 <cocreature> probably some silly hystorical reason
07:52:17 <lyxia> boothead: Map F xs is ill-formed because the type family F is not fully applied (where the number of required arguments is determined by the type family declaration, I'm assuming you defined type family F (x :: *) :: *, rather than type family F :: * -> *)
07:55:18 <supercynic> some silly hysterical reason?
07:55:27 * ski thinks this business about fully applied is reminiscent of macros (well, really staged programming)
08:04:57 <boothead> ah I see, thanks lyxia 
08:10:55 <cldhas> hello all !
08:13:08 <jjk_> hello all !
08:14:08 <jjk_> I need a little guidance to start programming with could haskell specifically with distributed-process ... is there someone who can help me
08:15:02 <jjk_> I have read the nice documentation but still got stucked to start writing practical programs
08:15:52 <jjk_> my first doubt is how to write a program through which I can send messages across different physical machines i.e. remote nodes
08:16:33 <jjk_> if someone here knows the stuff then please help me its urgent for me
08:18:49 <jjk_> if someone here can help me with writing programs with cloud haskell ....Q'
08:19:35 <supercynic> jjk_: cloud haskell uses the network-transport library for that
08:19:49 <jjk_> supercynic: yes I saw that
08:20:07 <supercynic> it's similar in design and purpose to something like ZMQ, and you should be able to learn it by just looking at the API
08:20:40 <jjk_> supercynic: yes the API is really nice
08:21:13 <jjk_> supercynic: I want to experiment with the API and got stuck with this problem
08:22:05 <jjk_> supercynic: once I cross this hurdle ...I can go further  .... but right now I am not getting to do this simple task using cloud Haskell
08:22:29 <jjk_> supercynic: well I don't know about ZMQ
08:23:46 <supercynic> jjk_: networking and discovery are not part of the network-transport API…  you will find that in the individual backend modules like network-transport-tcp or network-transport-zeromq
08:25:05 <jjk_> supercynic: ohk so I should look at network-transport documentation for that
08:25:33 <jjk_> supercynic: okay thanks ... I will look at it ...
08:26:14 <supercynic> jjk_: you should probably read The Book…  it has a chapter on cloud haskell
08:26:16 <supercynic> @where parconc
08:26:16 <lambdabot> http://chimera.labs.oreilly.com/books/1230000000929
08:27:05 <jjk_> supercynic: okay many thanks !!
08:45:34 <gitNoob> hi
08:46:16 <gitNoob> im using threepenny gui, and I'm trying to figure out how to read left up down and right. I'm trying to make 2048 , but I can't seem to find the keycode for these inputs
08:46:22 <gitNoob> https://hackage.haskell.org/package/threepenny-gui-0.8.2.0/docs/Graphics-UI-Threepenny-Events.html#t:KeyCode
08:49:38 <royal_screwup21> is there any difference between xs++(ys++zs) vs (xs++ys)++zs? I mean, I don't think is any because ++ is a monoid, and monoids are associative. Am I on the right track?
08:50:48 <Taneb> royal_screwup21: you're precisely righ
08:50:49 <Taneb> t
08:51:03 <Taneb> That said, there may be a difference in efficiency
08:51:56 <Taneb> (xs ++ ys) ++ zs, if GHC doesn't figure it out, will have to build xs ++ ys, then copy that to build the whole thing
08:52:20 <rotaerk> Is it correct to refer to Nothing as a "polymorphic value", and 'c' as a "monomorphic value"?
08:52:27 <Taneb> Which isn't the case for xs ++ (ys ++ zs)
08:52:53 <royal_screwup21> Taneb: cool, will keep that in mind
08:53:14 <rotaerk> Or is my usage of the jargon off
08:54:29 <jle`> royal_screwup21: xs ++ ys will in general re-allocate xs
08:54:33 <jle`> check out the definition of (++) to see why
08:54:38 <jle`> 'ys' it can leave untouched
08:56:39 <rotaerk> Or is it only types that are monomorphic/polymorphic
08:57:12 <lyxia> rotaerk: values are monomorphic/polymorphic.
08:57:40 <lyxia> rotaerk: I don't understand what you mean by 'c' though.
08:57:47 <alp> the Char
08:58:05 <rotaerk> Yep
08:58:16 <alp> :t 'c' -- this 'c'
08:58:17 <lambdabot> Char
08:58:41 <rotaerk> I'm trying to reconcile this concept of polymorphism with that of oop
08:59:32 <Guest14295> rotaerk: It's like generics from Java, not inheritance
08:59:45 <gitNoob> how do u read keyboard input like left or right in haskell? I'm using the three penny gui but I can't figure out how
09:00:12 <tdammers> rotaerk: https://programming.tobiasdammers.nl/blog/2017-10-17-object-oriented-haskell <- maybe this could help (or further confuse...)
09:01:50 <ski> rotaerk : types may also be polymorphic. however a type like `forall a. [a] -> [a]' is not polymorphic
09:03:39 <rotaerk> I'm thinking in this case the values are polymorphic, and thus can take many shapes.  In oop, the reference is polymorphic, in that it can refer to values of more than one type, but those values themselves are monomorphic
09:05:22 <TweyII> rotaerk: The e.g. Java equivalent of Nothing is a generic function <T> Maybe<T> nothing(), rather than a value
09:05:51 <ski> by a polymorphic value, i mean a value which have many times, all fitting a general pattern, described via type variables. so a polymorphic value has a type of the general shape `forall a. ..a..' (what i call i universal type, or a `forall'-type. *not* a polymorphic type, which is something else)
09:06:12 <ski> s/many times/many types/
09:07:39 <ski> an example of a polymorphic type would be `Proxy' (its kind is `forall k. k -> *', see the `forall' !). otoh the kind of `forall a. [a] -> [a]' is `*' (no `forall' wrapping the whole), so `forall a. [a] -> [a]' is a *monomorphic* type
09:08:14 <ski>   data Proxy (a :: k) = Proxy
09:08:52 <rotaerk> So a polymorphic value fits multiple types, and a polymorphic type fits multiple kinds?
09:09:14 <ski> (another example would be `data Flip f b a = MkFlip (f a b)', where `Flip :: forall k0 k1. (k0 -> k1 -> *) -> (k1 -> k0 -> *)'. `Flip' is a polymorphic type)
09:09:24 <ski> yes, roughly
09:09:28 <rotaerk> K
09:09:41 <TweyII> gitNoob: Use keydown: https://hackage.haskell.org/package/threepenny-gui-0.8.2.0/docs/Graphics-UI-Threepenny-Events.html#g:3
09:09:54 <gitNoob> TewyII: Thank you!
09:10:49 <ski> (the point is that the meaning of "polymorphic" is the same in both cases, the only difference is whether it's being applied on the value level, or on the type level. *some* people have called a type like `forall a. ..a..' (which is the *type* of what i call a polymorphic value) -- but i think this is confusing, especially now when GHC actually have support for polymorphic types, in the sense of the term that i use)
09:11:25 <EvanR> polykinded types?
09:11:34 <ski> (er, some people have called a type like that, polymorphic .. but i don't like that)
09:11:47 <ski> yes, EvanR, i don't like that term, either :)
09:12:22 <frobnicator> isn't polykinded that the type has a free type variable quantified over the kinds?
09:12:38 <ski> that's what i call a polymorphic type
09:13:46 <ski> at least if you mean things like `Proxy :: forall k. k -> *', or `Flip :: forall k0 k1. (k0 -> k1 -> *) -> (k1 -> k0 -> *)', above
09:15:03 <ski> (though `k', respectively, `k0',`k1', there are kind variables, not type variables, so now i'm unsure whether you meant this, or if not, perhaps stuff like `reverse :: forall a. [a] -> [a] :: *')
09:16:45 <portnov> hi all
09:16:54 <portnov> https://vimeo.com/71278954 
09:17:02 <portnov> in case someone did not see it yet, like me :)
09:35:47 <fresheyeball> anyone willing to walk me through writing a Generic instance for a GADT?
09:36:37 <lyxia> you generally can't
09:37:27 <fresheyeball> lyxia: why?
09:38:07 <royal_screwup21> so I was learning about the recursive trees data structure and I came across this https://thepasteb.in/p/pghQoQQjL16sR I understand the data structure, but I'm confused as to how the sumtree function works. Is it "looping" through every node until it finds a leaf?
09:39:33 <lyxia> fresheyeball: Generic types are sums of products. GADTs have a more complex structure, and generic programming with GADTs is an open problem.
09:41:31 <royal_screwup21> eh, never mind, that was a bad SE answer
09:42:35 <monochrom> Haha
09:42:50 <monochrom> "So simple it's obviously wrong."
09:43:23 <monochrom> Telltale sign: sumtree doesn't call sumtree.
09:43:57 <lyxia> fresheyeball: There is no way in GHC.Generics to represent types like    data E a where I :: E Int ; J :: E Bool
09:44:41 <fresheyeball> lyxia: gotcha, I suspected as much
09:45:58 <portnov> heh
09:46:12 <portnov> generic programming with generic data types is too generic, eh? :)
09:57:36 <EvanR> generalized data types
09:58:04 <EvanR> maybe the solution is to use generalized programming
10:28:06 <L0g4nAd4ms> How are supposed  to indent in haskell ? e.g. if i have "if EXPRESSION then otherEXP"
10:28:26 <L0g4nAd4ms> and i want to put and else after that just in the next line with 4 spaces indented ?
10:28:30 <dmwit> I usually align `if`, `then`, and `else` with each other.
10:29:18 <L0g4nAd4ms> so all in one line ?
10:29:20 <dmwit> The actual rule is just that `then` and `else` must be indented enough to be in the same block as the `if`, though, which is a surprisingly lax rule.
10:29:27 <dmwit> No, three lines. =)
10:29:46 <L0g4nAd4ms> but you indent with 4 spaces ?
10:29:55 <dmwit> http://dmwit.com/tabs for my practice
10:30:06 <dmwit> But beware that this is not a popular practice.
10:30:57 <L0g4nAd4ms> yeah that seems to be a rather egy style
10:31:06 <dmwit> I don't think I actually address if-then-else explicitly on that page, but if you read it you will know what I mean by "I align if, then, and else". =P
10:32:12 <L0g4nAd4ms> wow coming from c-style languages i am a bit overwhelmed right now.
10:32:14 <dmwit> I will often put the whole if-then-else on a single line if it fits, too.
10:40:38 <gitNoob> in haskell what is the key code for left button or wasd? https://hackage.haskell.org/package/threepenny-gui-0.8.2.0/docs/src/Graphics-UI-Threepenny-Events.html#keydown
10:41:44 <L0g4nAd4ms> dmwit, ok i got for a short if else the if and then on the same line and the else aligned on the same level with the "then"
10:45:08 * shapr hops randomly
10:47:09 * cement waves at shapr
10:47:16 <shapr> what's the recommended MIME parser module?
10:47:20 <shapr> howdy cement! How's code?
10:47:27 <shapr> I'm hacking on a simple SIP parser, yay!
10:47:38 <cement> if nix worked, it would be fantastic!
10:47:39 <shapr> for work, even!
10:48:06 <shapr> friend of mine is trying to get me to blow away my Linux isntall and jump headfirst into nixos.
10:48:08 <shapr> I dunno man
10:48:17 <shapr> if I can't play my steam games, I'll be way too productive
10:48:31 <cocreature> shapr: just try nix on your current distro
10:49:23 <TweyII> shapr: We have an environment for running Steam ;)
10:52:51 <shapr> Does stack handle github enterprise?
10:54:03 <shapr> so I need an easily extended MIME parser for my SIP stack
10:54:14 <mud> In what way would it need to handle github enterprise?
10:54:54 <mud> For most everything it'll fetch from any arbitrary git repo, anything git can clone really. Like the dependencies you specify in stack.yaml and etc.
10:56:08 <shapr> mud: I wanted to put our internal github enterprise hostname into github-username
10:56:24 <shapr> bah, quchen has been gone for A WEEK
10:56:36 <shapr> people are not allowed to take that long of a vacation from IRC, OKAY?
10:57:19 <mud> Oh, that's just for use in templates, like when you do stack new. I don't think the templates will be able to handle that, you'll probably have to manually modify the URL it puts in there. (it's just for the uhm, .cabal file, to specify the git repo so it gets listed in hackage and elsewhere)
10:57:29 <shapr> yeah, just wondering
10:58:24 <gitNoob> does haskell have methods to read up down left and right arrow keys being pressed?
10:59:35 <Redrield> I'm just sort of skimming various sections of Real World Haskell, and I've found an issue. When I try to import Data.ByteString or any submodules, I find that I can't. This is what is spat out of GHCi:  https://hasteb.in/dawoxugeva.vhdl
11:00:28 <lyxia> gitNoob: https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent/keyCode ArrowLeft
11:01:13 <cement> Redrield: you need to specify bytestring in your .cabal file
11:01:17 <mud> Redrield: You need to depend on the bytestring package in the whatever.cabal file for your project
11:01:23 <mud> In the build-depends section
11:01:36 <gitNoob> lyxia: Thanks!
11:02:56 <Redrield> :| thanks
11:31:00 <osa1> anyone know if Haskell 2010 gives typing judgements for Haskell expressions? I can't find it
11:37:31 <monochrom> No, it just says "for each strongly-connected component, HM"
11:38:13 <monochrom> But look for Mark Jones's "Typing Haskell in Haskell".
11:40:25 <osa1> monochrom: thanks. do you know where does it say "for each strongly-connected component ..."?
11:40:53 <monochrom> 4.5
11:42:27 <monochrom> Oh I guess it doesn't use those words, but "minimal set of mutually dependent bindings" equals strongly connected component.
11:43:01 <osa1> do you know any papers with expression typing judgements/ code like Typing Haskell in Haskell that also includes GADTs?
11:43:30 <EvanR> how do i take a .lhs file and make it readable
11:43:51 <EvanR> pardon the irony
11:44:15 <monochrom> Maybe something listed in https://wiki.haskell.org/Simonpj/Talk:OutsideIn helps
11:44:24 <lyxia> EvanR: pandoc
11:44:32 <monochrom> What is "readable"?
11:45:21 <fr33domlover> If you want to remove the comments, iirc there's a command? Or just grep ^>
11:45:35 <EvanR> http://www.cs.bham.ac.uk/~mhe/papers/fun2011.lhs
11:45:55 <EvanR> pandoc ok
11:46:15 <EvanR> readable = colors and formatting, like the software foundations book
11:46:29 <monochrom> \documentstyle eh? That's pretty old.
11:47:22 <lyxia> NPlusKPatterns too
11:47:26 <EvanR> well pandoc did give me HTML where the code was monospace font
11:47:50 <EvanR> otherwise looks like the original file verbatim
11:50:16 <EvanR> better than nothing
11:57:53 <L0g4nAd4ms> How do i get the "middle character" of a string ? My "algorithm" would be to 1. check if length str > 0 as matchguard and then i would return the string !! ceiling length str / 2
11:58:03 <L0g4nAd4ms> but this does not work, it gives me syntax errors :P
11:59:07 <liste> > let str = "abcde" in str !! (length str `div` 2)
11:59:09 <lambdabot>  'c'
11:59:32 <liste> :t (ceiling, (/))
11:59:33 <lambdabot> (Fractional a2, Integral b, RealFrac a1) => (a1 -> b, a2 -> a2 -> a2)
11:59:45 <liste> see Fractional and RealFrac there ↑
11:59:54 <liste> :t div
11:59:56 <lambdabot> Integral a => a -> a -> a
12:00:05 <liste> that one's integer division
12:00:26 <L0g4nAd4ms> yeah but i do the / division cuz i want to ceil that thing
12:02:15 <L0g4nAd4ms> because if i would just use the integer division and i got a string with a length of 2^n-1 i would not get the "right element"
12:02:38 <L0g4nAd4ms> because middle "abc" would give me then 'a' instead of 'b'
12:02:53 <L0g4nAd4ms> @liste, ^
12:02:54 <lambdabot> No module "^" loaded
12:03:15 <liste> > let {str = "abcdef"; strlen = length str} in str !! (strlen `div` 2 - (1 - strlen `mod` 1))
12:03:17 <lambdabot>  'c'
12:03:23 <liste> > let {str = "abcde"; strlen = length str} in str !! (strlen `div` 2 - (1 - strlen `mod` 1))
12:03:25 <lambdabot>  'b'
12:03:51 <merijn> So...any stack users that use windows around? I'm seeing a weird panic in GHC 8.0.2 during typechecking and I'm a bit confused where to even start figuring out what's wrong...
12:04:26 <L0g4nAd4ms> liste, "abcde" should return 'c'
12:04:32 <liste> L0g4nAd4ms: I know
12:05:27 <liste> > let {str = "abcde"; strlen = length str} in str !! (strlen `div` 2 - (1 - (strlen `mod` 1)))
12:05:30 <lambdabot>  'b'
12:06:08 <paolino> > head (drop (length "abcde" `div` 2) "abcde")
12:06:08 <MarcelineVQ> there's a sneakier solution to this problem using pattern matching
12:06:10 <lambdabot>  'c'
12:06:46 <liste> what am I missing, strlen should be 5 so strlen `mod` 1 should be 1 so the right side should be just strlen `div` 2
12:07:00 <EvanR> first, duplicate the thunk containing your string. then step through both, one twice as fast as the other, until it runs out
12:07:05 <EvanR> :)
12:07:09 <MarcelineVQ> EvanR: that's the one
12:07:53 <EvanR> this one works on infinite strings!
12:08:02 <merijn> Specifically this crash is what I'm seeing: http://lpaste.net/2126640944806625280
12:10:52 <merijn> Ah, ok, so I have found the bug and it's apparently already fixed in 8.2, so how can I tell stack to either 1) downgrade to using 7.10 or 2) upgrade to using 8.2?
12:11:37 <MarcelineVQ> change your resolver up or down, list of resolvers by version here  https://www.stackage.org/
12:11:54 <MarcelineVQ> use nightly for 8.2.1 currently
12:13:21 <merijn> I don't think nightly is a good idea, I don't like recommending beginners to use the cutting edge. But I'll figure out which resolver has 7.10 then
12:13:38 <paolino> compiler :8.2.1
12:14:18 <MarcelineVQ> it says on the front page there which resolver is for the 7.* version you prefer
12:15:49 <drdo> Now this is what I call a netsplit
12:16:38 <merijn> paolino: But that's exactly what I don't want :p But I've got the right resolver now (I think?) we'll see whether this fixes things
12:27:14 <sternmull> on Windows is there a way to get the raw commandline? System.Environment.getArgs is the best i can see, but that returns a list of arguments where quotes and whitespaces are already processed.
12:28:17 <merijn> sternmull: eh...there is no such thing as a raw commandline
12:28:42 <merijn> sternmull: At least, you definitely can't get that on *nix, I'm fairly confident the same applies to windows
12:28:49 <sternmull> merijn: There is for windows: https://msdn.microsoft.com/en-us/library/windows/desktop/ms683156(v=vs.85).aspx
12:29:10 <merijn> sternmull: Then you'll probably have to use the FFI to access that, I doubt it's builtin
12:29:26 <monochrom> Yeah I don't think the standard library has it.
12:29:50 <monochrom> Actually more, I haven't come across a third-party library for this either.
12:30:16 <Hafydd> What does GetCommandLine return when there is no command line, I wonder?
12:30:31 <Hafydd> Or if the arguments contain spaces.
12:31:01 <merijn> "stack setup" is supposed to grab and install the required GHC for a project, yes? So how come that ends in: http://lpaste.net/2782934878465818624
12:31:53 <sternmull> Hafydd: it returns the unprocessed commandline that was used to create the process. This is useful for example if you want to pass some arguments through to create a child process that itself parses the "raw commandline".
12:33:08 <pierrot> Hi. how can I convert c::Char which (isAscii c) is True to Word8?
12:33:43 <EvanR> > fromIntegral (fromEnum 'a') :: Word8
12:33:45 <lambdabot>  97
12:33:57 <Hafydd> ...I see that CreateProcess really does take a single string as the command line. That's strange.
12:34:00 <EvanR> > fromIntegral (ord 'a') :: Word8
12:34:03 <lambdabot>  97
12:35:06 <pierrot> Thanks, EvanR 
12:35:43 <EvanR> > let w8 = fromIntegral . fromEnum in w8 'a'
12:35:46 <lambdabot>  97
12:35:49 <EvanR> :t fromIntegral . fromEnum
12:35:51 <lambdabot> (Enum a, Num c) => a -> c
12:36:06 <codeshot> Hafydd, nmake in windows doesn't have @ (silent line) support either, it relies on the shell to take care of that
12:36:13 <EvanR> wonder what a good name for that is
12:36:41 <codeshot> Passing things direct seems to be pretty common in that world
12:38:54 <Hafydd> Yet C programs take an array of arguments, so there must be a standard way of parsing the command-line.
12:39:59 <geekosaur> yes, and t's wired into the crt on Windows
12:40:15 <merijn> Hafydd: That's what the C runtime is for
12:40:38 <geekosaur> Windows passes the raw command line as is, minus the program name which you have to get by a different call (and iirc can't actually get what they typed, just the name/path of the executable)
12:40:39 <merijn> Hafydd: main is the entry point for your C code, but it's not what the OS starts running
12:42:35 <geekosaur> even on Unix there is preprocessing: traditionally the entry point has to walk the stack pointer backwards to construct argv and envp from the strings stored on it
12:42:36 <sternmull> it gets interesting when you have a windows program that expects arguments like this: /foo:"some value". Then the quotes get removed by the normal commandline parser and there is no chance to get the unprocessed version of this option. Which might be needed if you just want to forward it to another process.
12:43:43 <ahihi> your entry point could also be WinMain()
12:44:49 <ahihi> sternmull: doesn't GetCommandLine() give you the raw string?
12:45:17 <sternmull> ahihi: It does... but it seems i don't have easy access to it from haskell.
12:45:34 <ahihi> ah
12:45:40 <ahihi> never had to use winapi from haskell yet :P
12:45:54 <sternmull> but its ok, in my case i can expect the user to give the child-process-command as single parameter. So he has to quote/escape it for me.
12:45:56 <merijn> sternmull: tbh, calling that C functions from haskell should be fairly trivial
12:47:19 <merijn> sternmull: If you know C, the C FFI is trivial to use as long as you 1) don't want to pass/return structs by value or 2) modify structs from Haskell
12:47:24 <sternmull> merijn: Yes, probably. There is already a Win32 package with many bindings. Adding GetCommandline should be trivial.
12:56:27 <centril> is there some online ghci thingy?
12:56:38 <centril> for when you don't have ghci installed locally?
12:56:58 <codeshot> Yay!, thanks to mniip I finally figured out how to use hoist: let b = (either (throwIO . NoMethodError) pure) . runExcept
12:57:39 <codeshot> zero'd monad has to stay zero'd, a monad with value has to stay a monad with value
12:57:53 <monochrom> Yes, there is repl.it
12:58:21 <centril> monochrom: nice
12:58:31 <centril> now I can answer at stackoverflow faster
12:59:34 <merijn> ideone.com also compiles Haskell, I think?
13:04:37 <codeshot> I'm starting to be very deeply attracted to monads
13:04:54 <phadej> or do-syntax?
13:05:42 <monochrom> I went through that phase too.
13:05:46 <codeshot> I like do-syntax, but I would live with monads even if we only had a few operators to our name
13:06:23 <monochrom> But it is true that a lot of EDSLs are monads.
13:07:08 <monochrom> Only a few are weaker than monads and have to go arrow etc.
13:08:06 <codeshot> I just realised I can write code that tries to get a datum, if it can't then assume a default and continue processing. Then later change the monad and the assumptive line to support explicit assumptions and now my code elsewhere can report all the assumptions made to default the analysis
13:08:46 <monochrom> \∩/ datum
13:09:09 <monochrom> Civilization is on the blink of forgetting about that word altogether.
13:09:32 <codeshot> because "data item" is so much easier
13:09:43 * codeshot farts at "data item"
13:10:47 * codeshot mentally defines the Assumptive type class and instances for several basic monads
13:10:58 <[exa]> I like how prolog gets everywhere
13:11:06 <merijn> You know what annoys me? Whenever reviewers correct my use of data as an uncountable noun...
13:11:30 <codeshot> huh, how do they do that?
13:11:59 <[exa]> merijn: did you sometime notice that native-speaking reviewers tend to be worst at grammar?
13:12:01 <codeshot> "Mr Merijn, you said 'some data' and you should have said 'several data' or 'numerous data'"
13:12:02 <merijn> codeshot: demanding it be treated as a plural
13:12:04 * codeshot farts
13:12:04 <monochrom> Do your data support it, or does your data support it? >:)
13:12:26 <merijn> codeshot:  ^^ that sorta thing
13:12:31 <codeshot> 2 data?
13:12:37 <codeshot> never heard of such a thing
13:12:41 <codeshot> 2 dati ?
13:12:49 <merijn> codeshot: No, data is the plural of datum
13:13:11 <merijn> codeshot: Which would normally imply that you write, e.g. "do your data support it"
13:13:22 <codeshot> what's the mass noun version supposed to be?
13:13:55 <merijn> codeshot: However, in common usage over the past decades data has become an "uncountable noun", which means you'd use "does your data support it"
13:14:07 <merijn> codeshot: "data" is the mass noun
13:14:26 <codeshot> what's the countable plural?
13:14:50 <merijn> codeshot: Also data, but nobody uses it like that anymore
13:14:55 <merijn> Anyway, time to go :p
13:14:56 <codeshot> oh, interesting
13:15:27 <Younder> A countable plural is just a finite set, isn't it?
13:16:07 <codeshot> no
13:16:21 <Younder> Mostly avoiding 'fuzzy' terms lime 'many' or 'some.
13:16:23 <codeshot> in can be uncountable
13:16:46 <codeshot> you define a finite set by counting some of them
13:17:06 * codeshot farts
13:17:26 <monochrom> The continuum hypothesis states that data is uncountable. >:)
13:18:05 <codeshot> merijn says that data *are* uncountable
13:18:24 <codeshot> and that data *is* uncountable if you'd like to say that
13:18:25 <Younder> Sounds impractical. I have a upper bound mu..
13:18:32 <[exa]> s/data/flour/ pls
13:18:43 <phadej> hypothesis-hypotheses
13:21:04 <phadej> data is fun word, as it's a bit like "wood", but here's no singular of "wood" (if you assume it's plural)
13:21:31 <phadej> so never found natural use case for "datum"
13:22:32 <mud> Words with fun pluralizations ... dice is good. Yeah "datum" doesn't get used a lot. You'd more likely hear "data point" or something instead even.
13:23:05 <phadej> mud, yes, because we say "I have a piece of wood"
13:23:15 <phadej> i.e. used to that way of counting uncountable
13:23:25 <MarcelineVQ> 'I have a piece of the woods'
13:23:34 <phadej> :)
13:23:56 <MarcelineVQ> also the singular for data is dat, dat thing over dere
13:24:48 <phadej> one "fun" plusalisation, one have to know is calculus-calculi
13:24:49 <MarcelineVQ> if its local data it's dis
13:25:19 <phadej> at least one on this channel :)
13:25:57 <codeshot> MarcelineVQ, lol
13:26:30 <codeshot> Plurals, dees and dose ?
13:26:35 <Younder> pedantic philosophers pedaling pointlessly
13:27:10 <Tuplanolla> I wish index--indices and vertex--vertices would extend to sex--sices and ex--ices.
13:29:53 <monochrom> dat thing over dere, data things over deres? :)
13:31:34 <MarcelineVQ> data thinga ovah dera
13:31:44 <monochrom> Ah!
13:42:49 <codeshot> dees dunces, don't dey dink dose data deserve dictionaries?
13:45:37 <monochrom> Well done. :)
13:45:56 <dmwit> Tuplanolla: Sure, and T-rex -> T-rices
13:46:41 <MarcelineVQ> dmwit: I would like this to be a thing please.
13:50:06 * codeshot bows
14:04:35 <dminuoso> ertes: Hey I just started on your "homework assignment" (work stuff has kept me busy). Just to be sure, it seems like I need to enable DeriveFoldable to make that type work.
14:04:48 <dminuoso> Or was your intention to have me implement that as well?
14:08:31 <n_blownapart> hi these two factorial programs work fine separately but not in the same file. I'm getting a indent/brackets error. I tried removing all whitespace. this is in vim. thanks url: https://ptpb.pw/CKOM
14:09:22 <ertes> dminuoso: if you want to, you can, but it's orthogonal to the subject, so for now just enable DeriveFoldable
14:09:40 <geekosaur> n_blownapart, your last guard in factt is wrong
14:09:44 <ertes> dminuoso: if you do want to solve it, implement Foldable in terms of foldMap or fold
14:10:00 <ertes> s/solve/do/
14:10:04 <n_blownapart> thanks sorry one sec
14:10:07 <geekosaur> and, er, I doubt it actually worked by itself since it's a syntax error as written
14:10:20 <n_blownapart> weird I thought it was working
14:14:16 <n_blownapart> geekosaur duh I added the otherwise keyword thanks
14:17:08 <shapr> I think matrix is having issues
14:17:18 <shapr> geekosaur: ooh, I want a homework assignment.
14:17:26 <shapr> oh wait, that was ertes 
14:17:30 <shapr> I still want a homework assignment :-P
14:17:38 <geekosaur> was wondering if you had us confused...
14:18:04 <shapr> geekosaur: any ideas for a homework assignment?
14:18:04 <codeshot> shapr, Your assignment is to draw, with wax crayons, a happy dinosaur
14:18:09 * shapr hops randomly
14:18:14 <shapr> codeshot: ooh, I can do that
14:18:18 <shapr> if I can find crayons
14:18:34 <codeshot> crayons can be purchased in exchange for currency or credit
14:18:38 <MarcelineVQ> 'They were all sad so I tried drawing them upside down, now they're all terrifying'
14:18:57 <codeshot> MarcelineVQ, lol, what's that from?
14:18:57 <shapr> codeshot: wait, can I use diagrams?
14:19:07 <codeshot> Are they happy, scaly diagrams?
14:19:19 <shapr> well, byorgey's diagrams usually look cheerful to me.
14:19:30 <MarcelineVQ> codeshot: I made it up just now to fit the situation
14:19:33 <shapr> codeshot: what Haskell lib would you suggest for drawing a happy dino?
14:20:04 * shapr looks at https://archives.haskell.org/projects.haskell.org/diagrams/gallery.html
14:20:24 <codeshot> MarcelineVQ, I like the cut of your jib
14:20:33 <shapr> codeshot: does this look cheerful to you? https://archives.haskell.org/projects.haskell.org/diagrams/gallery/Factorization.html
14:20:59 <codeshot> Very much so, and a bit scaly !
14:21:17 <codeshot> but it's a little on the picasso side if it's supposed to be a dinosaur
14:23:06 <codeshot> Does anyone know a haskell library for doing geometry like geogebra?
14:23:51 <Tuplanolla> Numerical or symbolic, codeshot?
14:24:18 <codeshot> well, it's haskell, so I suppose I should be able to choose, but symbolic really
14:24:29 <Tuplanolla> There isn't one.
14:24:46 <codeshot> that's a shame, I would have thought it was perfectly suited
14:26:18 <codeshot> Is there a type in haskell for modelling nondeterminism including limits (ie, any of an symbolically defined infinite set or class or distribution)?
14:27:51 <dsal> Man, I added some <?> to my parser and now my code coverage is lower.  I guess that's "correct"
14:28:23 <codeshot> add a strictness annotation ?
14:28:45 <codeshot> that's probably cheating
14:28:51 <dsal> Yeah, I thought about that.  heh
14:29:07 <codeshot> but that's what we do in other languages
14:29:26 <codeshot> If it's listed in the code before the branch it's covered. Happy days :D
14:29:34 <dsal> Yeah, thats true.  I could just fuzz the hell out of the test.
14:31:02 <codeshot> Or add a sample of each failure like you're 'sposed to
14:31:42 <dsal> Right, but that's kind of a pain.  "Sample of each way it can fail and verify it fails with the correct message" sounds not fun.
14:37:03 <ertes> shapr: right, here is a homework assignment: write an efficient variant of IORef that is split into a reader and a writer end, such that the reader end is a monad
14:37:23 <monochrom> This is why they give testing jobs to fresh grads.
14:38:30 <ertes> shapr: bonus points, if it's possible to do multiple updates simultaneously (semantically), but without the cost of STM
14:39:08 <monochrom> And then I get to explain Bayes theorem using the story of "your code fails a fresh grad's test case, what's the probably that it really is your bug?"
14:41:44 <dmwit> codeshot: I think there's an interval tree based on fingertrees.
14:43:32 <mud> monochrom: As opposed to a bug in the testcase?
14:48:43 <mud> In my earlier career, I remember spending the better part of a day on a buggy testcase once. That was pretty embarassing. Educational though I guess.
14:49:15 <EvanR> should have written a test for the test
14:50:03 <mud> Indeed.
14:57:00 <codeshot> dmwit, ta
15:02:31 <ski> whee
15:03:57 <EvanR> i dont see the matrix quit join messages anymore, just blonde brunette redhead
15:04:38 <ski> codeshot : hm, are you thinking of something like constraint programming/solvers (as in CP and CLP (Constraint Logic Programming)) ?
15:14:00 <dminuoso> ertes: So Ive managed to write something that type checks, but I have absolutely no clue why.
15:14:13 <dminuoso> But this is a product of the infinite monkey theorem Im sure.
15:14:58 <dminuoso> This feels like the y combinator all over again.
15:19:29 <jared-w> codeshot: the programming language Curry can natively handle nondeterminsm
15:19:54 <jared-w> the compiler kics2 can also compile Curry into Haskell and the way it models nondeterminism is very cool to read about, if you're up for a semi technical paper or two :)
15:20:01 <pmade> If I have a sum type `f a`, is there a way to write a generic function `[f a] -> [a]` to get all the values created with a specific data constructor?
15:20:45 <EvanR> TH could generate such a function
15:21:13 <jared-w> (the tl;dr is that it extends all types with additional constructors. `data MyType = ... | Failure | Choice (...)` where Failure denotes a branch that didn't work out and the Choice data-type is what encodes the searchtree into the datatype; you can simulate nondeterminsm by building and traversing this search tree)
15:21:14 <pmade> EvanR: Sure, I guess I could do that.
15:21:22 <geekosaur> \x -> [ Cons a | a <- x ]
15:21:37 <geekosaur> er
15:21:51 <geekosaur> \x -> [ a | a@(Cons {}) <- x ]
15:23:05 <pmade> geekosaur: Is that meant for me?  Wouldn't that call `fail` on a failed pattern match?
15:23:17 <geekosaur> it does, but fail on list is the empty list
15:23:29 <pmade> Whoa, nice.
15:29:08 <jared-w> Hmm... having a bit of trouble wrapping my head around that. Is there an example input I can play around with that?
15:35:38 <codeshot> If hoist :: (forall a. m a -> n a) -> t m a -> t n a, what function is :: (forall a. m a -> n a) -> m a -> n a
15:35:44 <betawaffle> @unmtl MaybeT (State s) a
15:35:44 <lambdabot> s -> (Maybe a, s)
15:35:45 <codeshot> ... do doo do do do
15:36:02 <Axman6> codeshot: id?
15:36:21 <codeshot> oh my of course
15:36:41 <betawaffle> @unmtl MaybeT (ListT (State s)) a
15:36:44 <ski> jared-w : do you happen to have a link handy to that paper ?
15:37:06 <codeshot> so IdentityT's MonadTrans has hoist = id I suppose ?
15:37:36 <Axman6> generally functions of the type forall a. m a -> n a are either monad transformer runner functions (runState, runWriter etc) or monad transformer constructors (StateT but usually by something like lift)
15:37:53 <codeshot> uhh, it's MFunctor
15:37:56 <lambdabot> s -> ([] (Maybe a), s)
15:38:03 <jared-w> ski: https://www.informatik.uni-kiel.de/~mh/papers/WFLP11_KiCS2.pdf#cite.AntoyHanus02FLOPS  -- Should be highly approachable to someone who understands haskell well and has a smattering of compiler know-how
15:38:08 <Axman6> hoist f (IdentityT ma) = IdentityT (f ma)
15:38:29 <codeshot> yeah, I want to use the same function I'd use for hoist to convert from one Monad to another (not a MonadTrans)
15:38:31 <dmwit> codeshot: It is id, up to newtype wrappers.
15:38:36 <jared-w> imho the interesting bits start in section 3, ski
15:38:42 <codeshot> so, yeah, id is the one
15:39:00 <codeshot> I want to keep my mind in a regular pattern
15:39:05 <codeshot> brain bran
15:39:41 <betawaffle> hmm, what's the transformer stack for building a list of filtered maybes from nondeterministic stuff?
15:39:54 <ski> jared-w : hmm .. it might be interesting to abstract that "extends all types with additional constructors" pattern into a type constructor, similar to how "Embedding Prolog into Haskell" by Seres and Spivey, and "Typed Logical Variables in Haskell" by Claessen and Ljunglöf, does for logic variables
15:40:04 <ski> jared-w : ty
15:41:04 <jared-w> oooh nice. No idea how I haven't seen this paper
15:41:46 * jared-w gets the crazy idea to translate the pakcs Curry compiler into haskell by way of Curry -> Prolog -> Haskell and use that to double check the correctness of the kics2 compiler
15:42:55 <jared-w> I managed to befuddle my professor by writing a curry program that worked and compiled in pakcs but hung on kics2 past a certain complexity :p
15:44:09 <zen_> hey! I'm wondering if anyone has a good paper on the constraint generation / solving approach to typecheckers... specifically for something more complex than vanilla HM but less than GHC
15:44:27 <jared-w> zen_: Ever looked at the omega language?
15:44:32 <zen_> no!
15:44:57 <jared-w> A professor at my university wired a constraint solver (I think it was Z3?) into a functional language like haskell and used it to do all kinds of crazy shit :)
15:45:04 <phryk> is there something like pythons pip for haskell?
15:45:28 <jared-w> https://hackage.haskell.org/package/omega
15:45:57 <jcarpenter2> phryk: there is stack
15:45:57 <lyxia> phryk: cabal or stack?
15:46:00 <jared-w> http://lambda-the-ultimate.org/node/4088
15:46:03 <zen_> ah jared-w: I'm looking for for typecheckers using constraint solving as a way to dis-entangle unification
15:46:04 <phryk> ah right, cabal
15:46:13 <phryk> i really ought to look into haskell again :F
15:46:33 <zen_> similar to GHC's OutsideIn alg (but ideally simpler)
15:46:37 <phryk> holy hell, i don't even have ghc in my package repo :F
15:46:37 <jared-w> zen_: One of the main benefits of omega's wiring into the constraint solver is the magic it allows in its type system as a result
15:46:48 <jcarpenter2> :F indeed
15:46:50 <jcarpenter2> what distro
15:47:12 <zen_> jared-w: I'm sure it's really cool (and I'm going to read the source now) but Im hoping for a simple example :P
15:47:31 <jared-w> hah, I'm sure. I just thought of that when you mentioned constraint solving :)
15:47:46 <zen_> constraint solving in type systems is so cool
15:48:22 <zen_> Im just having a hard time finding examples in the gap between HM and GHC
15:48:28 <betawaffle> @unmtl MaybeT (StateT s []) a
15:48:28 <lambdabot> s -> [] (Maybe a, s)
15:49:35 <phryk> jcarpenter2: freebsd, but i have a custom package repository. just added ghc and cabal to the list of stuff to maintain, but can't tell it to compile the two right now because the cron-caused daily compile job is currently running ^^;
15:49:59 <jared-w> https://stackoverflow.com/questions/415532/implementing-type-inference I'm assuming you've seen this link?
15:50:02 <jcarpenter2> lol
15:50:30 <phryk> jcarpenter2: still the best os i ever had^^
15:50:38 <jcarpenter2> the gentoo people tried to tell me, "oh just create a cron job to recompile the whole system"
15:50:51 <jared-w> But yeah it does seem unfortunate that there's such a huge gap between HM and GHC. You might actually have an easier time jumping straight to dependently typed systems, zen_. They're actually a much simpler theoretical system than GHC
15:50:59 <phryk> jcarpenter2: i'm a bit more optimized. used to run gentoo.
15:51:13 <phryk> jcarpenter2: i have one centralized pkg repo for all my machines (which all run freebsd^^)
15:51:36 <jcarpenter2> but i know (know) that no matter when i schedule it for, i'll be awake and working during that time, and wonder why my pc is suddenly so slow
15:52:18 <zen_> yea, unfortunately I'm searching for this because I'm rewriting the typechecker for my language, jared-w. I'm intentionally trying to keep the language 'simple' to focus on using modern tools / algs
15:52:19 <EvanR> zen ?
15:52:19 <phryk> it maintains packages from a list of specified ports (i.e. EVERYTHING I need), uses quarterly ports (i.e. stable+security fixes)
15:52:49 <phryk> jcarpenter2: i just have a homeserver, it's my biggest machine and constantly running. :P
15:52:56 <jared-w> Well, if you want more than ML and less than GHC you're looking for a type system of complexity right around the complexity level of dependent types, honestly
15:53:09 <zen_> well I'm looking for HM + Typeclasses
15:53:44 <EvanR> oh zen isnt a system
15:53:45 <zen_> unfortunately all the papers on constraint solving typecheckers leave out typeclasses with a comment along the lines of 'left as exercise for the reader'
15:54:43 <jared-w> Did you see this one? http://www.cs.yale.edu/publications/techreports/tr900.pdf  (didn't scan super closely but it looks somewhat close to what you want?)
15:56:27 <zen_> unfortunately that doesn't seem to be it
15:56:53 <jared-w> https://link.springer.com/chapter/10.1007/11924661_2  there's also this paper which looks closer. "Our results provide new insights on how to perform type inference for advanced type extensions"
15:57:04 <jared-w> (it's multi parmeter type classes though, so a bit beyond normal typeclasses)
15:57:05 <ski> jared-w : i'm also reminded of a Prolog (subset, with mode annotations) to Haskell compiler .. which i unfortunately can't find atm. given `foo(A,B;C,D)' (`A',`B' being inputs, `C',`D' being outputs), it generated a corresponding Haskell function of type `A -> B -> [(C,D)]'
15:57:20 <zen_> what im looking for is akin to https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/jfp-outsidein.pdf?from=http%3A%2F%2Fresearch.microsoft.com%2F~simonpj%2Fpapers%2Fconstraints%2Fjfp-outsidein.pdf
15:57:59 <zen_> except instead of chapter 7:  Instantiating X for GADTs, type classes, and type families
15:58:06 <zen_> I just want type classes :P
15:58:32 <jared-w> Should be trivial to strip out the other fun stuff and just get type classes /s
15:58:50 <dminuoso> So I got a question. I just implemented `traverse f (V3 a b c) = V3 <$> f a <*> f b <*> f c` and it typechecks (but I have zero clue why it does, or why my code works.)
15:58:57 <zen_> lol
15:59:10 <dminuoso> Now I would like to know how I can inspect what type `V3 <$> f a` in that gives.
15:59:38 <dminuoso> (Just want to know how I can figure this out myself)
15:59:40 <jared-w> ski: that's nifty. Sounds really simliar conceptually to what was used in the curry to haskell compiler
15:59:55 <jared-w> :t traverse
15:59:57 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
16:00:02 <ski> zen_ : perhaps <https://wiki.haskell.org/Simonpj/Talk:OutsideIn> is relevant (i don't recall)
16:00:19 <jared-w> I gotta go drive home but I'll be on later tonight :)
16:00:29 <ski> jared-w : those omega things look interesting, ty
16:00:30 <jared-w> feel free to ping me with any relevant stuff
16:00:31 <geekosaur> dminuoso, one useful hack is to enable ImplicitParameters in ghci and ask :t V3 <$> ?f ?a
16:00:32 <dmwit> dminuoso: Write `traverse f (V3 a b c) = (V3 <$> f a :: _) <*> f b <*> f c` and it will tell you what type the `_` should be.
16:00:40 <geekosaur> or that
16:01:10 <geekosaur> (using PartialTypeSignatures, which may also need to be enabled
16:01:15 <dmwit> dminuoso: e.g. here it says something along the lines of "Found type wildcard '_' standing for 'f (a -> a -> V3 a)'" and a bunch more detail.
16:01:24 <ski> jared-w : fwiw, i figured out a trick to translate some non-trivial (as in aliasing, maybe also partial structures) uses of logic variables (including backtracking) into uses of `mfix' in Haskell
16:02:39 <zen_> ski: yes, I posted the paper from that page above
16:03:02 <zen_> unfortunately, since its meant for GHC its too much for me to bite off 
16:03:05 <ski> oh, i missed that, then :/
16:03:07 <ski> ok
16:03:29 <johnw> Does anyone know of academic or engineering work on parsing incomplete programs? I ask this in the context of creating an IDE for analyzing the position of the cursor in a program that may not be fully written yet.
16:03:34 <dminuoso> geekosaur, dmwit: Both techniques are adequate. Thank you folks a lot. :)
16:03:39 <zen_> It's a little annoying because every paper talks about how splitting constraint generation and solving is better than doing it in one pass. 
16:03:42 <ski> perhaps Philippa has some other suggestion. istr they were interested in this
16:03:51 <ski> (see #lambdanow)
16:04:12 <johnw> ski: was that answer to me? 
16:04:15 <zen_> but then every algorithm with split generation / solving is for RankN  / GHC / Dependent Types etc...
16:04:33 <dmwit> johnw: You might like to look into the literature on incremental parsing.
16:04:58 <lyxia> johnw: have you seen edwardk's recent talks about monoidal parsing?
16:05:14 <johnw> lyxia: yes, and heard it from him in person on several occasions now :)
16:05:41 <pflanze> Hi. I'm looking for a function foo with something like type (a -> b) -> a -> b  that takes a list of length n and returns a list of length n-1, where the elements are the result of the argument function applied to the successive elements of the input.
16:05:44 <johnw> but it's not exactly what I need
16:06:00 <dminuoso> dmwit: No seriously thank you. Just seeing that partial type made it click. :)
16:06:09 <pflanze> I.e. foo (-) [3,2,4,9] == [1,-2,-5]
16:06:18 <pflanze> or similar.
16:06:32 <dmwit> > ap (zipWith (-)) tail [3,2,4,9]
16:06:34 <lambdabot>  [1,-2,-5]
16:07:20 <pflanze> Hmm okay, nothing named for this?
16:07:33 <dmwit> I encourage you to give it a name.
16:08:02 <ski> johnw : no, to zen_
16:08:38 <ski>   mapAdjacent
16:10:14 <Axman6> johnw: Talk to edwardk about his coda project, it's exactly for this sort of work (see ekmett/coda on github, and his boston haskell talk on youtube too)
16:18:39 <Axman6> uh, missed that someone else had already mentioned it
16:25:24 <jle`> codeshot: close, hoist = coerce
16:25:51 <Axman6> I was going to say that earlier, I wonder if that actually works
16:26:02 <Axman6> hmm, yes it should, nevermind
16:26:53 <lyxia> there may be issues with impredicativity
16:29:55 <jle`> you're right it doesn't work :'(
16:30:12 <Axman6> :(
16:33:30 <dsal> Whatever large performance discrepancy I had between OS X and Linux seemed to go away when I stopped using regex.
16:33:34 <jle`> it works if i make coerce a specific type
16:37:24 <Affabul_> anyone good with phsyics?
16:37:56 <monochrom> No.
16:38:28 <Axman6> I don't believe in physics
16:38:43 <Axman6> or phsyics
16:40:19 <jle`> i just know one physic
16:40:27 <jle`> but throw in more than one and i'm useless
16:41:02 <codeshot> :t coerce
16:41:03 <Axman6> Affabul_: as a general rule, asking open questions like that won't get you much help - the first rule of ITC is "Don't ask to ask, just ask", so even if it's not on topic, asking your actual question will get better answers than questions of the form "Does anyone know about X?"
16:41:03 <lambdabot> error:
16:41:03 <lambdabot>     • Variable not in scope: coerce
16:41:03 <lambdabot>     • Perhaps you meant ‘coerced’ (imported from Control.Lens)
16:41:19 <Affabul_> true
16:41:21 <Axman6> IRC*
16:42:19 <codeshot> because "Me! Me! I know about X" gets you a feeling of commitment to see support through to the end that most of us end up unhappy about having
16:43:07 <codeshot> you quickly learn to sit and wait for some question that you can easily help with and stop when you like
16:44:14 <Affabul_> i was mainly desperate but didnt want to get banned :)
16:46:20 <jle`> Affabul_: you should have just asked your question directly
16:46:43 <jle`> it would have been much less channel noise (only one message sent), so nobody's going to ban you
16:46:58 <jle`> if it's off topic we'll just let you know.  or if someone reads it and wants to help they can contact you
16:47:19 <Eango> hello I have question
16:47:34 <jle`> if you just send your question first, there are no negative consequences and you have 1700 people reading your question and any of them can look over and help if they can
16:48:09 <jle`> but now look where we are -- you asked if anyone was good with physics, and you are waiting for someone to reply and so then send even another message.  much more noisy :)
16:48:14 <johnw> Eango wins the open question award
16:48:53 <jle`> asking to ask is catastrophically worse than just asking your question
16:48:59 <jle`> for all parties :'(
16:49:43 <Affabul_> Question: https://d2vlcm61l7u1fs.cloudfront.net/media%2Fb4c%2Fb4c224ce-b796-47e8-a21f-6db597c470b4%2FphpLYIFLE.png.  ANSWER:https://unsee.cc/ziputoma/
16:49:59 <johnw> that is a very suspicious sounding link
16:50:45 <Affabul_> eh its not lol
16:52:41 <EvanR> sorry your answer must be in the form of a question
16:53:15 <Affabul_> can someone tell me if my answer is correct lol
16:53:33 <johnw> is it a Hasekll question?
16:53:50 <Affabul_> no 
16:53:58 <johnw> then wrong channel to ask, I'm afraid
16:54:02 <Affabul_> indeed
16:54:14 <Axman6> There is a good chance there is a #physics on freenode
16:54:16 <Affabul_> my apologies
16:54:24 <Affabul_> its too quiet
16:54:43 <EvanR> ##physics
17:02:49 <remexre> This is more of a general funcprog question than a Haskell one, but is codata always infinite?
17:03:18 <EvanR> no
17:04:20 <EvanR> you could have a type that is necessarily infinite, or necessarily finite, or could allow either
17:04:33 <remexre> and both would be valid codata?
17:04:43 <EvanR> all three
17:04:52 <remexre> erm, yeah
17:04:56 <remexre> hm
17:05:03 <fishythefish> for example, the polynomial functor corresponding to [a] is F X = a * X + 1
17:05:08 <fishythefish> the initial algebra gives you finite lists
17:05:18 <fishythefish> the terminal coalgebra gives potentially infinite co-lists
17:05:28 <fishythefish> if you remove the + 1, then the terminal coalgebra gives necessarily infinite co-lists
17:05:33 <fishythefish> (some call these streams)
17:06:31 <newbie123> is there an easy way to check if a number is in an infinite list?
17:06:50 <EvanR> > elem 3 [1..]
17:06:52 <fishythefish> newbie123: depends on if you require the algorithm to terminate for all inputs
17:06:53 <lambdabot>  True
17:06:57 <mud> newbie123: In guaranteed finite time? You'd have to know more about the infinite list.
17:07:21 <remexre> fishythefish: Okay, it was always explained to me as "lists = data, streams = codata"
17:07:28 <EvanR> there are infinite structures searchable in finite time
17:07:38 <remexre> is there a "recommended reading" for learning what a algebra/coalgebra are? :P
17:09:16 <newbie123> mud well the list is all prime number, if i check for a prime number i get true, but I don't get False if its not in the list
17:09:24 <fishythefish> remexre: that's a common way of putting it, but the distinction really comes down to whether you make use of values recursively or corecursively
17:10:01 <fishythefish> finiteness is tricky; it's muddled a bit by strictness considerations and because in haskell, data and codata actually coincide
17:10:24 <mud> newbie123: Well, there are prime testing algorithms. That would likely make more sense. Or if you really want to do exactly the same thing, I assume the list is ordered? If so you could just stop once you reach numbers being than the needle you're looking for.
17:10:34 <fishythefish> newbie123: elem won't do what you want because as long as there are more elements in the list, it'll keep checking
17:10:37 <mud> numbers bigger*
17:10:52 <newbie123> that's my problem with elem fishythefish 
17:10:54 * ski prefers to say "potentially finite"
17:10:55 <remexre> fishythefish: so would recursively be ([dataA] -> dataB), corecursively would be (codataA -> codataA)? Also, I'm imagining a hypothetical Total Haskell for this
17:10:57 <ski> (streams)
17:10:58 <newbie123> mud:  yeah the list is ordered
17:11:21 <mud> So you'd probably want to do something like takeWhile (<= n), and then use elem
17:11:43 <mud> Note that filter does something similar, but in this case it's not similar enough.
17:12:03 <newbie123> thanks I will try takeWhile
17:12:41 <fishythefish> remexre: recursion is what you're most likely used to: pattern match to determine which constructor is used, and perform more operations on the smaller bits you get from the match
17:12:51 <fishythefish> corecursion is something like `ones = 1 : ones`
17:12:55 <mud> I'd mention again though that this is unlikely to be a very good way to do primality testing, just in case. I assume you're fine with that though.
17:13:00 <fishythefish> the constructor appears on the RHS and is used to build up bigger values
17:13:07 <ski> remexre : try "A Tutorial on (Co)Algebras and (Co)Induction" by Bart Jacobs,Jan Rutten in 1997 at <http://www.cs.ru.nl/B.Jacobs/PAPERS/JR.pdf> ?
17:13:10 <remexre> fishythefish: oh, so conceptually (codataA <- codataA)?
17:13:13 <remexre> ski: thanks!
17:13:25 <fishythefish> remexre: not sure what you mean by that notation
17:13:57 <remexre> fishythefish: trying to denote that the "larger" value is being produced from the input
17:14:53 <newbie123> mud efficiency is important, so is there a better way if it's not a good way to do it?
17:15:07 <ski> remexre : structural recursion would be `Data -> X', while structural corecursion would be `X -> Codata'
17:15:33 <fishythefish> ^
17:15:58 <remexre> hm, okay
17:16:03 <mud> newbie123: How big are the numbers you need to test? One fairly easy to write and fast way is miller-rabin. It's a probabalistic algorithm, but it can be made deterministic easily if you can limit the range of numbers (like to below 2^64)
17:16:13 <ski> remexre : also, you might be interested in taking a quick look at the first two papers by Erik Poll here :
17:16:18 <ski> @where ErikPoll
17:16:18 <lambdabot> "Subtyping and Inheritance for Inductive Types" in 1997 at <http://www.cs.ru.nl/E.Poll/papers/durham97.pdf>,"Subtyping and Inheritance for Categorical Datatypes" in 1997 at <http://www.cs.ru.nl/E.
17:16:18 <lambdabot> Poll/papers/kyoto97.pdf>,"A Coalgebraic Semantics of Subtyping" in 2000 at <http://www.cs.ru.nl/E.Poll/papers/cmcs00.pdf>,later version of that in 2001 at <http://www.cs.ru.nl/E.Poll/papers/ita01.
17:16:18 <lambdabot> pdf>
17:16:26 <fishythefish> newbie123: is using an existing library an option?
17:16:30 <mud> newbie123: Or if the range is smallish, maybe a few million or so, you can do a sieve, which is easier to understand than miller-rabin.
17:16:31 <ski> as well as the copatterns paper by Andreas Abel,et al.
17:16:39 <ski> @google copatterns Andreas Abel
17:16:41 <lambdabot> http://www.cse.chalmers.se/~abela/
17:16:41 <lambdabot> Title: Andreas Abel
17:16:45 <mud> Or yes, using a library is the better idea of all, but you still might need to know a bit what methed it is using.
17:17:03 <newbie123> well I lied about the being a primes list, it is actually a list of 3 primes multiplied 
17:17:17 <newbie123> if that changes anything
17:17:25 <fishythefish> newbie123: what exactly are you trying to solve?
17:17:27 <ski> remexre : corecursion/coinduction is naturally expressed using "copatterns" (i prefer to call it "message-dispatching", cf. pattern-matching)
17:17:48 <mud> Hm, it does change things, but it could still be possible. Your problem would look more like prime-factorization then. Like you can prime-factorize the number and see if it is exactly the product of 3 distinct primes.
17:17:52 <Cale> newbie123: So you're trying to determine if a number is a product of exactly three primes?
17:18:00 <remexre> ski: huh, okay. I'm probably gonna take a bit of afk to read these. thanks!
17:18:20 <mud> Or is it not necessarily 3 distinct ones? Any variation will be pretty similar though.
17:18:38 <newbie123> it's an uni assignment ( i wan't to solve it on my own): I have a list [1..9000] (for example), and i want to know which numbers in this list are a product of three primes
17:18:48 <ski> remexre : the first paper i mentioned is more directly relevant to what you were asking. but i figured the others could be interesting, relating to this topic as well
17:18:56 <mud> You can do variations of sieves that allow prime factorization is pretty reasonable times.
17:19:08 <newbie123> the three primes have to be uhhh "behind each other" tho
17:19:31 <ski> consecutive, i belive the term would be ?
17:19:37 <newbie123> yes thanks 
17:19:49 <mud> A lot depends on how big the numbers in the list can be. If they're only up to 9000, the naive way might really be fine.
17:20:03 <codeshot> I have a StateT a (Except String) b, I want to "modify" the state using a value of type (Except String (a -> a)), preferably within do notation, what are the options?
17:20:04 <newbie123> mud:  i already use sieve to work with primes
17:20:24 <Cale> newbie123: An idea might be to use the cube root of the number to get an idea of the area around which you should search then
17:20:26 <codeshot> (a -> a) will use the (b) obtained moments before
17:20:30 <newbie123> mud:  I don't really know how big the numbers are going to be, but I think the professor will put in some hard cases
17:21:11 <mud> One cute way to prime factorize is to have an array of, for each number, the biggest prime factor that that number has. Then you can write a very fast recursive algorithm to factor anything that's in that list.
17:21:14 <ski> codeshot : `modify =<< lift myAction', perhaps ?
17:21:45 <Cale> newbie123: If you know it's got to be p_(n-1) * p_n * p_(n+1), you should definitely make use of that fact.
17:21:53 <ski> @do lift myAction >>= modify
17:21:53 <lambdabot> do { a <- lift myAction; modify a}
17:22:09 <mud> newbie123: Hm, that's problematic. The answer changes depending on just how evil they are. Like are the numbers up to a few million? That's one answer. Are the numbers up to 2^512? A different answer again, etc.
17:22:22 <codeshot> ski: hm, interesting
17:22:25 <codeshot> thanks
17:22:25 <mud> Oh are they of that form? That's a much easier problem if so, that'd be good.
17:22:38 <newbie123> well I already have my threeprimes list, which is an infinite list of "three prime numbers multiplied" cale, so I think that fact is factored in
17:23:08 <newbie123> mud: I'll try the takeWhile approach and see how long it works fast
17:23:17 <mud> newbie123: But if you're not explicitly using that fact (if it is actually a property of your problem), you're almost certainly being a lot less efficient than you can be.
17:24:06 <Cale> newbie123: Well, it's probably possible to do better than a linear search through that list
17:24:14 <Cale> (which is all you can do if you make a list like that)
17:24:44 <mud> Lists are fun, and very often a decent idea in FP, but they limit you sometimes.
17:25:03 <newbie123> I think you are correct in it not being the best thing, it was just the first thing I thought of cale
17:25:04 <Cale> Basically, if you make a list, you're saying "I'm going to iterate over these things in this order"
17:25:40 <mud> Without giving too much away, if that's the form of the thing you have to check, an array sounds much more interesting to yield a somewhat sane solution.
17:26:29 <Cale> I wouldn't make an array either
17:26:48 <Cale> I'd figure out the rough magnitude of the primes involved
17:26:56 <newbie123> wouldn't I fill the array with the same stuff as the list mud
17:27:06 <mud> newbie123: Yes, but you could look at it in different orders.
17:27:09 <Cale> and then compute the next and previous primes from there, which is much much faster than computing all the primes up to that point
17:27:35 <mud> Right, that does seem like an interesting way to go. miller-rabin I guess from there?
17:27:37 <codeshot> ski, yup
17:27:53 <codeshot> I'm too tired, need to sleep on this stuff a few days
17:28:58 <newbie123> woah mud miller-rabin looks scary tho
17:29:26 <mud> It's really not bad, though understanding it is a bit involved. If you're not into number theory.
17:29:28 <Cale> yeah, start with the cube root, then use a fast primality test like Miller-Rabin to get the next/previous primes and search from there. It might be possible to do a little better than just the cube root as an estimate if you want to use a little analytic number theory :)
17:30:38 <Cale> But yeah, I don't know what's expected for the course :)
17:31:07 <mud> I doubt it's that, you'd probably get in trouble turning that in, haha. But it's still clever as hell.
17:33:11 <mud> You could really use that one on like, any size numbers, that's quite impressive. Though it'd be probabalistic eventually.
17:34:42 <newbie123> I'll definitely try it cale, thanks for the tip
17:35:31 <mud> newbie123: I'd seriously recommend you not turn that in though, unless your teacher is very okay with outside help. For most courses, that'd be ... surprising to come in with.
17:36:56 <aplainzetakind> Hello.
17:37:13 <newbie123> mud: good idea, I currently have the takeWhile approach work for [1..100000] in ~3 secs - which should be enough I'd think
17:38:22 <aplainzetakind> I installed System.Clock through the gentoo overlay. It works fine in ghci, but somehow syntastic (using hdevtools) is oblivious to it in vim and complains that it cant find it. What could be the problem?
17:39:07 <geekosaur> hdevtools was built against a different ghc?
17:39:46 <aplainzetakind> No, no change in ghc.
17:51:18 <aplainzetakind> Ah, it was running in the background even though I restarted vim. Killed it and then restarted vim and it recognized the new things.
18:02:38 <dumptruckman> https://cdn.discordapp.com/attachments/331887622018301973/377276035626172427/unknown.png
18:02:51 <dumptruckman> Are the < and > like symbols a different symbol than < and >?
18:03:26 <Cale> yeah, they're produced using \langle and \rangle in TeX
18:04:17 <dumptruckman> ah
18:04:32 <dumptruckman> nice, perfect, thanks
18:04:39 <Cale> In this case, I'm not sure why this text is using them rather than ordinary parentheses, since I would guess that this is defining the equivalence relation on DFAs
18:04:53 <Cale> I suppose some people like to write tuples that way
18:04:53 <dumptruckman> indeed
18:17:29 <monochrom> Oh this is from a computability textbook.
18:18:13 <monochrom> Sipser's "introduction to the theory of computation".
18:19:17 <monochrom> This angle bracket is not just a tuple. You will find them emphasizing that this is an encoding of whatever is inside the angle bracket, a string encoding that you would put on a Turing tape.
18:20:07 <monochrom> So whereas A is a DFA (in the math sense), <A> is a string representation of that DFA you would have a Turing machine parse.
18:20:40 <monochrom> And <A,B> is abbreviation for <(A,B)>, a string representation of a tuple of two DFAs.
18:21:28 <monochrom> And I say "them" because it is not just Sisper. Basically every teacher of Turing-based computability will make a big fuss about this.
18:23:43 <monochrom> So now EQ_DFA is a set of strings—a language—and now you can talk about whether this language is decidable. (Turns out this one isn't.)
18:24:04 <monochrom> Err wait maybe it is. I forgot.
18:49:27 <dmwit> Regular languages are great. Everything about them is decidable.
18:49:38 <dmwit> In particular: yes, it is decidable whether two DFAs accept the same language.
19:46:53 <Arcaelyx> Is there a way to exec stack projects without having to designate the name every time?
19:47:05 <Arcaelyx> Like instead of stack exec project-name, just stack run or w/e.
20:10:10 <jle`> Arcaelyx: stack allows git-like plugins
20:10:19 <Arcaelyx> jle`: In what sense?
20:10:32 <jle`> so if you type in 'stack run', it'll search the path for an executable stack-run
20:10:53 <jle`> and so anyone can write a program to extend stack functionality
20:11:18 <jle`> something like this? https://hackage.haskell.org/package/stack-run
20:29:23 <sm> Arcaelyx: or add $(stack exec -- which EXE) to $PATH. Or stack install it.
20:30:42 <Arcaelyx> jle`: Tyvm.
20:34:55 <jle`> Arcaelyx: np
20:58:51 <Arcaelyx> jle`: Works wonderfully, awesome.
21:16:33 <jle`> Arcaelyx: glad it works!  i actually use something similar myself.
21:20:19 <balor> Does the TypeFamily instance declaration `type instance X a b = a` allow me to refer to an `X` but actually mean "the `a` bit from the X`? The docs at https://downloads.haskell.org/~ghc/7.8.1-rc1/docs/html/users_guide/type-families.html don't quite help me, and I'm struggling to Google it due to my lack of understanding of TypeFamilies.
21:21:24 <dminuoso> ertes: Okay, after staring at the type of traverse for too long, I finally figured it out after getting some sleep
21:21:33 <dminuoso> instance Traversable V3 where traverse f (V3 a b c) = pure V3 <*> f a <*> f b <*> f c
21:21:59 <dminuoso> (Originally I came up with one that used <$>, but this felt a bit more expressive and easier to read as a beginner)
21:22:44 <dminuoso> So I immediately recognized, that traversing with an Identity functor was equivalent to using fmap instead.
21:29:34 <jle`> balor: i'm not sure how to interpret your question
21:30:21 <jle`> `type instance X a b = a` is defining an instance of the type family X for two "wildcard" inputs
21:30:26 <jle`> and returning the first one
21:30:38 <jle`> balor: so it's like the function x a b = a
21:30:42 <jle`> > let x a b = a in x 10 "hi"
21:30:45 <lambdabot>  10
21:30:51 <jle`> essentially 'const'
21:31:02 <balor> jle`, thanks a lot
21:31:05 <jle`> fwiw x is a pretty bad name for a function/type family
21:35:30 <sebastianrkg> is there any good, approved-of way of reading the output of multiple STM queues as if they are all one big queue? Maybe a conduit-type utility?
21:36:37 <sebastianrkg> I'm currently using the `unagi-chan` library, but I could potentially switch to stm-conduit or pipes-concurrency or something like that
21:36:57 <sebastianrkg> trying to make a system for processing a graph of actors and mailboxes
21:38:22 <sebastianrkg> it would need to have its own buffer after the queue that it's reading all the messages into, I suppose, because otherwise the messages would get undecidably ordered from the perspective of the actor (if you wait until you need them to read them, you're not sure which queue's message was there first)
21:39:30 <sinsnare> Hi, how can I use record data syntax with type constraints? I want to do something like `data A (num a) = A { getA :: a }` but where do i put the `num a`?
21:39:47 <jchia> Building with GHC, can I expect a program to run more slowly if I build it with -prof but run it without the -p RTS option?
21:40:08 <jchia> Any reason to not always build with profiling enabled?
21:43:19 <sinsnare> Well, I really just want to say that a type is an abstract number, doesnt have to be a `num a`
21:47:42 <geekosaur> you can't do that, because it doesn't do what you want. (in particular, it would check the constraint when creating the value, but not bring the constraint into scope when you extract/pattern match it)
21:48:22 <geekosaur> with a GADT it can bring the constraint into scope, at the price of making 'a' an existential type
21:49:33 <sinsnare> Yeah, im just gonna do it the hard way :( I have a type that i want to be both a Double and a CInt in different circumstances, but ill just do the transformation manually
21:50:27 <jle`> sinsnare: yes usually when you want something like that, there's a much simpler way to do it
21:50:31 <geekosaur> sometimes its easiest to just data A = ADouble Double | AInt CInt
21:50:56 <jle`> asking for constraints on type parameters to data types is something that new haskellers commonly ask about, but it's actually usually not even what they want
21:51:49 <jle`> alternatively you can always just do data A a = A { getA :: a} without the constraint, and just constrain the use sites
22:04:40 <jchia> I just compared program performance (total running time) with and without profiling. Before, built without profiling, total running time was 11s. Now, built with profiling, regardless of RTS -p, the total running time was 16s. So, there is a slowdown regardless of RTS -p.
22:05:17 <geekosaur> it has to disable some optimizations because they make profiling useless
22:05:57 <jchia> rebuilding my project and all the external packages with profiling enabled is such a pain
22:06:22 <geekosaur> in particular, you can't really profile something that has been inlined, because it can subsequently be optimized away or transformed by optimization such that it can't really be recorded
22:06:23 <jchia> i wonder if i can specify the stack that i want to build my project with profiling enabled but not for external packages.
22:06:36 <jchia> "specify to stack"
22:06:38 <geekosaur> that also makes profiling useless
22:06:53 <jchia> geekosaur: Why?
22:08:03 <geekosaur> because of cross-module inlining and that, i9n the presence of laziness, you can;t tell if something profiled is using a lot of time itself or because something in an external librayr forced a large thunk
22:08:42 <geekosaur> ghc won't even link if you don't have dependencies including external libs built for profiling; it wants the .p_o or .p_so files to link against
22:09:41 <geekosaur> stack can't do anything about this, because it's ghc forcing it and not stack
22:13:59 <nshepperd> today i learned about https://ghc.haskell.org/trac/ghc/wiki/Debugging/TickyTicky profiling, which can be enabled per module and work with all optimizations but at the cost of being kinda useless because it doesn't actually measure the amount of cpu time expended in each closure
22:15:26 <nshepperd> only the number of times entered and allocations by it
22:16:05 <nshepperd> (because it's mainly for debugging the ghc optimizer)
23:21:13 <mniip> fascinating
23:21:14 <mniip> 1510039224 [10:20:24]  /usr/lib/ghc-8.2.1/ghc-prim-0.5.1.0/libHSghc-prim-0.5.1.0-ghc8.2.1.so: undefined symbol: stg_gc_unpt_r1
23:25:02 <mniip> hmm I think I compiled it wrong
23:33:18 <mniip> ghc -L/usr/lib/ghc-8.2.1/rts/ -lHSrts-ghc8.2.1
23:33:23 <mniip> ...I feel like I shouldn't be typing this out
23:59:35 <dminuoso> Is there a more concise way to write `traverse f (V3 a b c) = pure V3 <*> f a <*> f b <*> f c` ?
