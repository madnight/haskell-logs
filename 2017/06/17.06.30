00:00:40 <Jello_Raptor_> Cocreature: I'm basically looking for a way to have my cake and eat it too.
00:05:58 <cocreature> Jello_Raptor_: afaik you can’t do that but I’m probably also the wrong person to ask here since I never found recursion schemes particularly compelling
00:06:07 <jared-w> oooh recursion schemes
00:06:19 <jared-w> they're shiny bits of magic I don't understand yet, but they look nifty
00:07:45 <Jello_Raptor_> Cocreature: yeah, good to know. It seems like dependent types would be necessary but I'm not confident of that. 
00:09:51 <cocreature> Jello_Raptor_: I don’t think dependent types help here. the problem is that the Fix + cata approach relies on being able to change the type of the thing you’re recursing on while GADTs are all about fixing that.
00:13:31 <cocreature> if you try to press recursion on GADTs into a uniform shape you loose the advantage of using a GADT in the first place.
00:15:52 <Jello_Raptor_> Cocreature: right, but effectively you'd be erasing the extra info a GADT lets you store as you evaluate, if you could create a type function that correctly transformed your Gadt types into the ones your evaluator needs.
00:16:41 <cocreature> Jello_Raptor_: but that only works for some evaluators, e.g. for an "Expr a -> a" you can’t erase the info
00:17:42 <cocreature> basically it only works for evaluators that ignore the fact that you have a GADT
00:18:14 <cocreature> so at this point you could just first transform your type to a non GADT version and everything will work out
00:19:11 <Jello_Raptor_> Oh? It wouldn't let you use ID 
00:19:24 <cocreature> ID?
00:19:30 <cocreature> also what is “it”
00:23:54 <mschristiansen> What's the recommended way to log information from a Servant app?
00:24:23 <mschristiansen> Don't necessarily want to throw exceptions, simply log info about application flow
00:25:08 <mschristiansen> Could simply use `putStrLn`, but isn't there a way to hook into logging functionality already part of warp or wai?
00:25:20 <mschristiansen> Or doesn't it matter?
00:25:24 <merijn> mschristiansen: I've been using monad-logger atm, it's not great, but ok
00:25:34 <cocreature> mschristiansen: I don’t think there is anything in warp or wai. just use whatever logging framework you like
00:25:55 <Jello_Raptor_> Cocreature: ahh okay, I see what you mean now. Sorry, took me a bit to grok. You can't put the type function for the evaluator into the standard form of cata, you'd need something that isn't like a functor at all.  
00:26:33 <cocreature> Jello_Raptor_: right, functor is for “uniform” things while the whole point of a GADT is to not be uniform and instead specialize the type variable
00:28:42 <bvad> mschristiansen: monad-logger works, and it's pretty easy to customize the output format 
00:29:30 <mschristiansen> merijn: cocreature: thanks. I'm already using request-logger from wai-extra and warp will automatically log exceptions
00:30:04 <mschristiansen> bvad: merijn: sounds like monad-logger is what is being used
00:30:11 <mschristiansen> will have a look at that
00:42:24 <bollu> hey guys, what's a good libraries for treees?
00:42:41 <bollu> a good library*
00:42:51 <merijn> bollu: What kinda trees?
00:43:18 <Axman6> @hoogle RoseTree
00:43:18 <lambdabot> Data.Tree.Rose class RoseTree (c :: * -> *)
00:43:19 <lambdabot> package twentefp-rosetree
00:43:27 <Axman6> hmm, not the one I was after
00:43:31 <Axman6> @hoogle Tree
00:43:32 <lambdabot> module Data.Tree
00:43:32 <lambdabot> Data.Tree data Tree a
00:43:32 <lambdabot> Control.Arrow.ArrowTree class Tree t
00:43:32 <bollu> merijn non binary trees
00:43:35 <bollu> hmm
00:43:40 <bollu> so which one do I use?
00:44:05 <Axman6> Data.Tree is rose trees - data Tree a = Node a [Tree a] (approximately)
00:44:28 <Axman6> but also, defining your own trees is trivial and fun!
00:45:39 <cocreature> the only nontrivial functions provided by Data.Tree are drawing of trees so if you don’t need that rolling your own is just as easy or even easier if it doesn’t quite fit what you had in mind
00:45:53 <merijn> cocreature: And that's a debug function anyway :)
00:46:03 <cocreature> merijn: but it’s a really useful one :)
00:52:02 <ski> @let newtype Fix1 f i = In1 {out1 :: f (Fix1 f) i}
00:52:03 <lambdabot>  Defined.
00:52:10 <ski> @let data ExpF exp :: * -> * where Lit :: Integer -> ExpF exp Integer; Sub :: exp Integer -> exp Integer -> ExpF exp Integer; IfNonNeg :: exp Integer -> exp a -> exp a -> ExpF exp a
00:52:11 <lambdabot>  Defined.
00:52:17 <ski> @let mapExpF :: (forall a. exp0 a -> exp1 a) -> (forall a. ExpF exp0 a -> ExpF exp1 a); mapExpF _ (Lit n) = Lit n; mapExpF f (Sub e0 e1) = Sub (f e0) (f e1); mapExpF f (IfNonNeg e e0 e1) = IfNonNeg (f e) (f e0) (f e1)
00:52:18 <lambdabot>  Defined.
00:52:23 <ski> @let cataExp :: forall r. (forall i. ExpF r i -> r i) -> (forall i. Fix1 ExpF i -> r i); cataExp phi = loop where loop :: forall i. Fix1 ExpF i -> r i; loop = phi . mapExpF loop . out1
00:52:24 <lambdabot>  Defined.
00:52:31 <ski> @let evalExp :: forall i. Fix1 ExpF i -> i; evalExp = runIdentity . cataExp alg where alg :: forall i. ExpF Identity i -> Identity i; alg (Lit n) = Identity n; alg (Sub (Identity n0) (Identity n1)) = Identity (n0 - n1); alg (IfNonNeg (Identity n) (Identity n0) (Identity n1)) = Identity (if n >= 0 then n0 else n1)
00:52:32 <lambdabot>  Defined.
00:52:36 <ski> > evalExp (fix (In1 . Sub (In1 (Lit 0))))
00:52:38 <lambdabot>  *Exception: stack overflow
00:52:39 <ski> > evalExp (In1 (IfNonNeg (In1 (Sub (In1 (Lit 5)) (In1 (Lit 2)))) (In1 (Sub (In1 (Lit 3)) (In1 (Lit 4)))) (fix (In1 . Sub (In1 (Lit 0))))))
00:52:41 <lambdabot>  -1
00:52:48 <ski> Jello_Raptor_ : something like ^ ?
00:55:25 <Lokathor> so is Haskell's tail-call elimination a natural result of call-by-need evaluation?
00:55:39 <merijn> Lokathor: Haskell doesn't have explicit tail-call elimination
00:56:00 <merijn> Lokathor: It's also kinda irrelevant with the way GHC compiles Haskell :)
00:56:16 <merijn> Lokathor: Because, why do people use/want tail-call optimisation?
00:56:32 <EvanR> to avoid use of stack
00:56:34 <Lokathor> hmm, well *I* want potentially infinite recursion
00:56:44 <merijn> Lokathor: Right, which is a problem, because?
00:56:55 <Lokathor> what EvanR said
00:56:59 <Lokathor> C-style stack explosion
00:57:05 <Axman6> isn't it kind of inherent in the way GHC compiles haskell? it's all just jumps, sometimes its jumps to the same function, making a tail call
00:57:06 <merijn> Lokathor: Except GHC doesn't have/use a function call stack
00:57:18 <merijn> Lokathor: So there is not call stack that grows
00:57:26 <jared-w> and because it doesn't have one, the whole benefit for tail-call optimization is gone
00:57:28 <EvanR> or jumps to any function making a tail call
00:57:35 <merijn> Lokathor: So the entire optimisation is just inherent to the way GHC compiles things.
00:58:01 <jared-w> merijn: and the way haskell goes about it is CPS, right?
00:58:02 <ski> not the whole benefit, no
00:58:02 <EvanR> but thunks can end up piling up in memory like a stack
00:58:05 <Axman6> Lokathor: the only place you'll see a call instruction in Haskell is when calling C functions
00:58:06 <slack1256> ghc has a stack that use when evaluating thunks. Just no a call stack
00:58:06 <Lokathor> so the effect is there inherently, but not for the reason one might at first think
00:58:15 <EvanR> and case analysis uses a stack
00:58:16 <quchen> Welllll… what people call »tail call« often matches a »non-pattern-matching case«, so it’s often a good idea to write function tail-call looking
00:58:16 <slack1256> the effect is the same
00:58:21 <merijn> Lokathor: Depending on your point of view either no function in (GHC) Haskell is tail-recursive, or they all are. Since all functions calls in GHC Haskell are basically jumps
00:59:14 <merijn> Lokathor: There's a pattern match stack, which can grow/overflow. The solution to that is making things stricter, but in some cases the only way to add the necessary strictness is rewriting (as quchen said) to something that looks like a tail-call
00:59:31 <merijn> Lokathor: But the "tail-call" bit is really just accidental, it's the strictness that fixes the issue
00:59:35 <osa1> merijn: what do you mean? some function calls require pushing continuation address to the stack, some don't
00:59:51 <merijn> osa1: No, pattern matches have continuations. Functions don't
01:00:15 <Lokathor> http://lpaste.net/356575 so here's the specific example that i'm wondering in reference to
01:00:35 <Lokathor> I'm writing a tutorial aimed at explaining what's going on to Python/C/Javascript folks
01:00:43 <osa1> merijn: well unless you're evaluating scrutinee of a case you're doing tail call
01:00:57 <Lokathor> and if I say "this won't make the stack explode, trust me", i'm not wrong
01:01:02 <merijn> Lokathor: Whether that matters depends on the >>= implementation of Hexes
01:01:24 <merijn> Lokathor: If it's basically IO, then it's fine
01:01:28 <Lokathor> it's just ReaderT (IORef DataStuff) IO a
01:01:28 <jared-w> Lokathor: depending on how nerdy you get, I'd probably go for the continuation-passing explanation or the "everything is a 'function pointer jump' that avoids the call stack entirely"
01:01:36 <merijn> Lokathor: yeah, that should be fine, tbh
01:02:18 <Lokathor> saying "this looks like a tail call, but trust me it's not, because actually there aren't any calls at all" also seems... well a little silly perhaps
01:02:29 <ski> (`foldl' clearly is tail-recursive; while `foldr' is, only in case the callback uses its second argument in tail position)
01:03:05 <EvanR> tail position being top most?
01:03:18 <quchen> Also note that »foldl'« is not tail recursive
01:03:56 <EvanR> could have mistaken `foldl' for foldl' :)
01:04:09 <quchen> Yes, that’s why I use my fancy quotes ;-)
01:04:24 <EvanR> i figured thats just whats on your keyboard
01:04:55 <quchen> "yes", said “quchen”, I have many „quotes“ on my »keyboard«.
01:05:11 <Axman6> macOS?
01:05:12 <EvanR> the third one is goofy as hell
01:05:12 <slack1256> maybe we should make enfasis on not having a "call-stack" because of graph reduction. But having a possibly nested "stack-frames" when forcing a thunk
01:05:15 <Lokathor> do you live on mars
01:05:19 <slack1256> *emphasis
01:05:19 <Lokathor> with a martian keybaord
01:05:37 <quchen> EvanR: The third one are standard German quotes
01:05:39 <Axman6> all those are available on macOS by default
01:05:40 <Lokathor> EvanR, that's how Europe does double quotes in some places, and yes it is goofy as hell
01:05:43 <ski> `<hole>' is in tail position in e.g. `<hole>',`if ... then <hole> else ...',`let ... in <hole>',`case ... of ... -> <hole>; ...'
01:05:51 <quchen> Axman6: I’m on Linux
01:06:52 <quchen> ski: Hmm, I wonder what »tail position« means exactly.
01:07:02 <Axman6> hmm, not all of them actually (that i can find)
01:07:04 <EvanR> too bad we cant get away from stacks completely
01:07:24 <EvanR> because having to worry about stacks while also not having a stack trace is embarassing!
01:07:38 <ski> slack1256 : fwiw, even in a cbv language like Scheme, there's no call stack. calls don't push activation frames. evaluating a subexpression does
01:07:58 <quchen> EvanR: Well, printing the GHC stack would not be very useful, it just lists a bunch of things case-matched on
01:08:18 <EvanR> ghc vis should be pretty useful for debugging
01:08:29 <EvanR> but that doesnt show stacks
01:09:03 <EvanR> listing all the things currently being case match on, somehow, would also be good
01:09:06 <EvanR> better than nothing
01:09:18 <EvanR> dont ask me what it would look like
01:09:33 <quchen> See STGi
01:10:05 <ski> quchen : i suppose you could define contexts like `T[] ::= if true then [] else e | if false then e else [] | ...' and then have a small-step transition like `T[e] >~> e'
01:11:02 <quchen> ski: I guess the easier definition is »tail call is every jump that does not grow the stack«, but that’s probably circular
01:11:17 <slack1256> ski: I could see that. (+ 9 (- 8 1)) doesn't pushes (- 8 1) to the stack, the standard evaluation rule does when it needs. That what you mean?
01:11:23 <Lokathor> so, let me refresh some terms: Haskell is a non-strict language, and GHC implements that with Lazyness, correct?
01:11:36 <slack1256> yep
01:11:37 <Lokathor> are there non-lazy ways to implement non-strictness?
01:12:07 <EvanR> you can be technical and define lazy evaluation to be a particular optimization for normal order evaluation
01:12:15 <EvanR> which can be non strict
01:12:36 <EvanR> and naively is worse than lazy
01:12:53 <quchen> Lokathor: Yes: laziness memorizes previous results so you don’t have to recalculate for example. Recalculate each thunk every time again and you’re still non-strict, but not lazy anymore.
01:12:54 <slack1256> you could forbid sharing, which is all laziness differs from call-by-name
01:13:18 <ski> slack1256 : yes. so function call is just a jump
01:13:18 <EvanR> or just dont have thunks
01:13:46 <Lokathor> so lazyness is an optimized sub-type of non-stictness, in a sense.
01:13:48 <quchen> Lokathor: Or evaluate all thunks in parallel when they are created, and when one of them crashes hold on to the exception until it is required
01:13:57 <ski> Lokathor : yes, cbn as EvanR mentioned. also speculative evaluation
01:14:18 <quchen> Lokathor: They’re different domains. Strictness is denotational, laziness is operational.
01:14:27 <EvanR> why that got labeled lazy evaluation i dont know
01:14:31 <quchen> Lokathor: Laziness is one way to implement non-strict semantics.
01:15:12 <bollu> quchen "Strictness is denotational, laziness is operational" I need to write that down somewhere
01:15:26 <bollu> quchen that is the clearest explanation of nonstrict versus lazy I have heard to date
01:15:32 <ski> ask monochrom for details
01:15:38 <quchen> O:-)
01:16:02 <quchen> ?call-monochrom
01:16:02 <lambdabot> Unknown command, try @list
01:16:07 <quchen> How is that not a Lambdabot command
01:16:17 <EvanR> tail call?
01:16:19 <ski> @help get-shapr
01:16:19 <lambdabot> get-shapr. Summon shapr instantly
01:16:21 <quchen> (I think they removed call-shapr as well)
01:16:25 <quchen> Oh, nevermind.
01:16:35 <quchen> ?botsnack
01:16:35 <lambdabot> :)
01:16:50 <EvanR> @get-EvanR
01:16:50 <lambdabot> Unknown command, try @list
01:16:55 <Lokathor> I think they got mixed up because 95% of people only care about operational :P
01:16:57 <EvanR> ?get-EvanR
01:16:57 <lambdabot> Unknown command, try @list
01:17:06 * Lokathor hides from all the professors
01:17:35 <EvanR> many operational things in ghc are like, you really dont want to know
01:17:44 <EvanR> pretend it acts like graph reduction
01:17:56 <bollu> EvanR lol
01:17:58 <Lokathor> it's not graph reduction?
01:18:06 <EvanR> conceptually
01:18:20 <EvanR> but its not modifying a literal graph like in the books
01:18:20 <slack1256> I am confused by RTS options , how are -A and -H different? -A is how "big the step are" on growing the heap right?, -H tell "this should be the mean size of the heap, reach it sooner"?
01:18:49 <EvanR> or its not the one you think it is
01:19:27 <merijn> Lokathor: If you care about operational semantics and you've got a few hours to kill, I have THE things for you :p
01:20:06 <merijn> Lokathor: Because the answer to "I wanna understand GHC operational semantics" is always "start with the STG paper"
01:21:23 <Lokathor> merijn, if it's a link to stuff i can bookmark it
01:21:32 <Lokathor> but i've gotta get to sleep in like, 20 minutes ago
01:21:32 <quchen> ?google spineless tagless g-machine
01:21:34 <lambdabot> https://stackoverflow.com/questions/11921683/understanding-stg
01:21:39 <quchen> Eeek okay wrong
01:22:01 <quchen> Lokathor: SPJ’s paper from 1992, »Implementing lazy functional languages on stock hardware«
01:22:38 <quchen> Lokathor: Also https://github.com/quchen/stgi/
01:22:39 <Lokathor> ho boy
01:22:47 <Lokathor> doesn't sound like simple reading on the bus
01:22:54 <merijn> Lokathor: https://pdfs.semanticscholar.org/5c70/ed80977204a5b84f1f02764d6c3b5d9b8185.pdf
01:23:03 <merijn> Lokathor: Honestly, the title is A LOT more intimidating than the content
01:23:26 <merijn> Lokathor: IMO you require like beginner/intermediate Haskell knowledge and a tiny bit of C/asm experience couldn't hurt, but other than that...
01:23:51 <MarcelineVQ> Lokathor: spj is very easy to read
01:23:55 * Lokathor saves as "SPJ - Implementing lazy functional languages on stock hardware.pdf" because there's only one SPJ
01:23:55 <slack1256> when does parallel gc hurts performance? what characterists does those programs have?
01:24:11 <quchen> The third chapter (mapping to C) isn’t really necessary to understand how the machine works either
01:24:14 <merijn> slack1256: You mean concurrent GC?
01:24:22 <slack1256> *characteristics
01:24:24 <quchen> That leaves you with about 20 pages to read
01:24:30 <merijn> slack1256: Parallel GC == GC runs in parallel on multiple cores
01:24:40 <slack1256> no, parallel. Multiple cores running the GC
01:24:43 <merijn> slack1256: Concurrent GC == GC runs while program is running (i.e., not stop the world)
01:24:46 <quchen> The only annoying part is that the transition rules are in tabular form, but without any form of separators.
01:24:51 <slack1256> yep
01:25:09 <merijn> slack1256: Assuming your GC is stop-the-world anyway, there's zero downside
01:25:23 <slack1256> I use to think that too!
01:25:28 <slack1256> then reddit happenned
01:25:30 <merijn> slack1256: If you don't have a stop-the-world GC, then parallel can hurt in that you have to pause useful cores
01:25:33 <Athas> merijn: zero downside to parallel GC?
01:25:49 <EvanR> does ghc do parallel gc
01:25:52 <cocreature> there is never zero downside to parallelizing anything
01:25:54 <Athas> You can have all kinds of interesting cache coherency-related slowdown unless you implement it well.
01:25:54 <merijn> Athas: Well, if your cores are stopped ANYWAY, there's no point in not having them do GC :)
01:26:05 <Athas> Yes, there is.  Synchronisation is not free.
01:26:06 <slack1256> there is cache locality issues
01:26:07 <merijn> Athas: Well, I didn't say it was EASY to implement :)
01:26:27 <Athas> And if you're memory-bound anyway...
01:26:36 <slack1256> https://www.reddit.com/r/haskell/comments/6fqnke/speed_up_your_haskell_programs_with_one_weird/
01:26:39 <EvanR> how do you guarantee all your cores are available at the same time for a gc "now" ?
01:26:55 <EvanR> and not on some other process
01:27:30 <slack1256> this thread. I shows a program when -qb -qc help performance
01:27:33 <Athas> In my experience, most of the performance advantage of simple parMap-style parallelism in Haskell can be eaten up by the parallel GC.
01:28:56 <slack1256> I don't understand why though. In my head, it should be always a win
01:29:23 <slack1256> reading the rts source, they even avoid the common pitfall of loadbalancing the nursery and barring it from happening
01:43:37 <mbw> Ok this is going to sound stupid. If in "S <: T", S is a subtype of T, is "T :> S" valid notation as well?
01:44:01 <ph88> i have   let wn = nextWindow w    how can i make sure wn is evaluated at this point ?
01:44:20 <EvanR> do 
01:44:25 <EvanR> let !wn = nextWindow w
01:44:29 <ph88> ok
01:44:40 <anohigisavay> hi. what are the use cases of non-parameter classes?
01:45:10 <quchen> I can’t think of one
01:45:14 <anohigisavay> used to read about it but failed to find references on google
01:45:20 <EvanR> might have to :set -XBangPatterns
01:45:42 <EvanR> or {-# LANGUAGE BangPatterns #-} in the file
01:46:12 <anohigisavay> just ran into it when reading purescript docs
01:46:28 <anohigisavay> which has something like `head :: forall a. Partial => Array a -> a`
01:46:43 <ph88> ye i set it
01:47:00 <anohigisavay> and `unsafePartial :: forall a. (Partial => a) -> a`
01:47:46 <ph88> i knew that one
01:48:48 <anohigisavay> but i'm still very confused
01:49:24 <EvanR> i am not sure how purescript works, but Partial could be seen as a dictionary that is auto passed
01:49:31 <EvanR> and theres is exactly one
01:49:46 <EvanR> ok thats silly in retrospect
01:50:19 <EvanR> so purescript is putting documentation in the context
01:52:05 <lfairy> It's kind of like Rust's unsafe system? But defined as a type class rather than built in to the language
01:52:05 <anohigisavay> https://leanpub.com/purescript/read
01:52:12 <anohigisavay> part 6.10
01:52:27 <anohigisavay> https://leanpub.com/purescript/read#leanpub-auto-nullary-type-classes
01:55:34 <ph88> looks to me like it's a way to describe that some functions are compatible with each other or not
01:56:40 <ph88> grouping of functions
01:57:27 <anohigisavay> if without such `unsafePartial` function it'd be impossible to call those functions
01:58:09 <ph88> i think the other way around ... you can call them but you can never escape the Partial constraint without unsafePartial
01:58:29 <ph88> i think you can wrap ordinary values in Partial
01:59:01 <ph88> myValue :: Partial => Bool    myValue = True
01:59:06 <ph88> i'm guessing here :P
01:59:44 <anohigisavay> k how would one define unsafePartial then? or is it magic inside the compiler?
01:59:48 <geekosaur> think of it as IO as a typeclass constraint, maybe. what happens in Partial stays in Partial
01:59:58 <ph88> maybe check out the source for unsafePartial
02:00:17 <anohigisavay> o yea 
02:00:18 <ph88> ye it reminds me of the context in monads .. but i didn't want to mention it :P
02:00:48 <ph88> i think this constraint is a fact (in a logic sense)
02:01:02 <anohigisavay> foreign import unsafePartial :: forall a. (Partial => a) -> a
02:01:06 <anohigisavay> _(:з」∠)_
02:01:11 <anohigisavay> makes sense
02:01:15 <ph88> :D
02:01:46 <anohigisavay> thank you guys
02:01:58 <Philonous> Does aeson have a streaming parse function? I can't seem to find it
02:04:03 <ertes-w> helo
02:04:17 <ertes-w> Philonous: yes, it exposes an attoparsec parser
02:04:18 <cocreature> Philonous: iirc it doesn’t but I remember seeing some package that supports streaming json parsing on hackage
02:04:23 <Philonous> Ah, via attoparsec
02:04:33 <Philonous> Thanks
02:04:44 <cocreature> well you can’t take a look at the result until you’ve parsed everything
02:04:49 <cocreature> so streaming is not that useful
02:05:00 <ertes-w> Philonous: but it's only streaming in the sense that you don't have to have the whole *input* string in memory
02:05:24 <Philonous> It does tell me how much data I need to read though
02:05:31 <cocreature> I think https://hackage.haskell.org/package/json-stream was the one I saw
02:06:04 <Philonous> cocreature, attoparsec parsers support what I need, thanks
02:06:10 <cocreature> great :)
02:20:12 * ski . o O ( `unsafePartial Dict :: Dict Partial' )
02:28:43 <ph88> i have this piece of code and i don't understand why i get trace output like i do  https://bpaste.net/show/25cd9b0e3f91
02:28:52 <lfairy> hackagebot 2.0 is alive now!
02:29:08 <lfairy> if it does something silly, please report to git.io/hircine-issues
02:29:24 <ph88> on line 22 in paste it prints False, so i goes to line 6 in paste .. but why then do i still get the extra debug output on line 23 ?
02:30:01 <lfairy> (I've added that URL to hackagebot's realname, so /who will show it as well)
02:32:56 <lfairy> ooh, hackagebot's first message is coming up!
02:33:56 * hackagebot hsparql 0.3.3 – A SPARQL query generator and DSL, and a client to query a SPARQL server. – https://hackage.haskell.org/package/hsparql
02:34:19 <lfairy> \o/
02:46:06 <Gurkenglas> ph88, would you be as surprised to get 2 bars out of "let bar x = trace "bar" x in bar 1 + bar 1"?
02:48:51 <ph88> noes
02:49:11 <ph88> Gurkenglas, you think you see the problem ?
02:49:23 <Gurkenglas> Oh wait, now I get it, no :D
02:49:29 <ph88> :D
02:49:40 <Gurkenglas> Let's shrink it.
02:49:53 * ph88 lays on the big sofa
02:49:57 <ph88> go on
02:50:32 <Gurkenglas> > if False then let !w = undefined in "wut" else "k"
02:50:33 <lambdabot>  "k"
02:51:21 <ph88> k
02:51:55 <Gurkenglas> (why do you show windowB_start twice?)
02:52:24 <ph88> no reason
02:52:31 <ph88> copy one too many times
02:52:45 <Gurkenglas> What are windowB_start and windowB_end? I don't see their definition
02:53:05 <ph88> they are of type Int
02:53:15 <ph88> i can paste the full function but it's really messy at the moment
02:53:54 <ph88> i didn't clean this up yet ... https://bpaste.net/show/82399f5ce33f  
02:54:32 <Gurkenglas> Debug.Trace does not gurantee order iirc. Are you sure line 23 is traced by a call that comes from whatever pastes line 22?
02:54:37 <ph88> don't even mind line 88 or so .. not all the comments are relevant
02:55:29 <ph88> Gurkenglas, no i'm not sure  .. also when i replace  line 6 from   [w]  to   trace "getAllWindows B" [w]   it's not in order
02:59:01 <ph88> i wish i could put a make everything strict thing in my file, then debug it, then make everything lazy again
03:05:06 <ph88> can i make arguments of a function strict ?
03:05:32 <cocreature> ph88: {-# LANGUAGE Strict #-}
03:06:14 <felixphew> what's the quickest path from lazy ByteString to Text?
03:06:44 <felixphew> because, as I just discovered, you can't decodeUtf8 a lazy bytestring
03:07:15 <Philonous> You can decodeUtf8 to a lazy Text
03:07:24 <cocreature> Philonous: Data.Text.Lazy.Encoding
03:07:28 <cocreature> eh ^ Philonous 
03:07:30 <cocreature> eh ^ felixphew 
03:07:32 <cocreature> I give up
03:07:48 <Philonous> Or you can use toStrict to convert to a strict ByteString first 
03:08:29 <felixphew> disadvantages of each?
03:08:34 <felixphew> I've never used lazy Text
03:09:01 <pacak> Why do you want to use lazy bytestring?
03:09:09 <pacak> (or laxy text)
03:09:11 <Philonous> Sometimes you don't have a choice
03:09:12 <pacak> lazy
03:09:14 <felixphew> because that's what CGI gives you
03:09:41 <pacak> CGI? O_o
03:09:49 <felixphew> Network.CGI
03:09:58 <pacak> Is it still alive? :)
03:10:26 <felixphew> yes, very much so
03:11:24 <felixphew> there was a new major release about a year ago, and the latest minor update was November
03:11:58 <Philonous> felixphew, Same as for lists vs. vectors, I suppose. You don't have to keep the entire thing in memory (probably irrelevant in your case) and productive functions have to do less work if you only need a prefix
03:12:14 <cocreature> felixphew: a lazy Text/ByteString is basically a linked list of strict Text/ByteString. it can be infinite and you can produce and consume it lazily so you can gc parts of it and get better memory usage. but it will be slower and use slightly more memory than strict bytestrings if you need to have the entire thing in memory
03:12:33 <felixphew> well, well, I am always going to be processing the entire string
03:12:52 <felixphew> so maybe converting to strict is the way to go
03:12:54 <cocreature> processing the entire thing does not mean you need to keep the entire thing in memory at the same time
03:13:02 <Philonous> I've never actually used lazy ByteStrings/Text. Whenever I need streaming I use conduits anyway 
03:13:09 <cocreature> e.g. length [1..10000]  can run in constant space
03:13:41 <felixphew> true... maybe lazy is the way to go
03:13:58 <felixphew> ugh now I'm going to have to go and change the types on everything
03:14:04 <felixphew> thanks everyone
03:14:14 <ventonegro> How can I check the precedence of an operator in ghci?
03:14:41 <Philonous> ventonegro, :i ($) 
03:14:51 <ventonegro> Philonous: thanks!
03:14:55 <Philonous> Or rather, :i (<operator>)
03:15:00 <felixphew> > :i ($)
03:15:02 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
03:15:11 <Philonous> lambdabot isn't ghci :)
03:15:16 <felixphew> :(
03:15:26 <ventonegro> :i (<*>)
03:15:35 <ventonegro> meh
03:17:58 * hackagebot superrecord 0.1.1.0 – Supercharged anonymous records – https://hackage.haskell.org/package/superrecord
03:19:21 <mbw> Is there some shortcut for list comprehensions of the form [ (i,j,k,l) | i <- [1..n], j <- [1..n], k <- [1..n], l [1..n] ] ?
03:19:30 <ski> ph88 : `BangPatterns' ?
03:20:34 <ski> > replicateM 4 [1 .. 2]
03:20:36 <lambdabot>  [[1,1,1,1],[1,1,1,2],[1,1,2,1],[1,1,2,2],[1,2,1,1],[1,2,1,2],[1,2,2,1],[1,2,...
03:21:09 <ski> you can `map (\[i,j,k,l] -> (i,j,k,l))' if you need quadruples
03:21:30 <Philonous> Naughty partial functions :(
03:21:49 <ski> it's safe in this case
03:22:11 <ski> > (,,,) <$> [1 .. 2] <*> [1 .. 2] <*> [1 .. 2] <*> [1 .. 2]
03:22:13 <lambdabot>  [(1,1,1,1),(1,1,1,2),(1,1,2,1),(1,1,2,2),(1,2,1,1),(1,2,1,2),(1,2,2,1),(1,2,...
03:24:07 <ski> (aka `liftA4 (,,,) [1 .. 2] [1 .. 2] [1 .. 2] [1 .. 2]')
03:24:19 <mbw> The replicateM approach looks nice.
03:24:42 <mbw> Although the applicative instance looks as well.
03:24:46 <mbw> Oh no! Choices...
03:25:17 <ski> with `replicateM', `i',`j',`k',`l' will all have the same type
03:25:40 <mbw> Hopefully GHC doesn't float out the iteration space to a CAF.
03:26:24 <cocreature> we really need a decent way to prevent ghc from doing that
03:27:26 <superlinux> hello
03:28:23 <ski> hello there
03:30:39 <ph88> cocreature, thanks :)  do you think it's a good debug strategy to make it work with strict first ?
03:31:13 <superlinux> ski. hi
03:31:56 <cocreature> ph88: tbh no. understanding how strictness affects things and then using it where necessary is a lot better than forcing everything to be strict
03:32:19 <superlinux> well i want to know how to install the GUI library if I use stack to setup my project. please help.
03:32:29 <superlinux> the GUI library is HTK
03:32:41 <mbw> gtk?
03:32:49 <cocreature> huh I didn’t even know htk was a thing
03:32:50 <superlinux> the tkinter of haskell
03:32:53 <cocreature> http://www.informatik.uni-bremen.de/htk/
03:33:32 <cocreature> “Currently, HTk is "orphanware" - while still being used and e.g. ported to later versions of the GHC if it is not too much trouble, it is not actively developed, and new releases are sparse. Its future prospects are uncertain. Use at your own peril.” sounds great
03:33:35 <superlinux> i mean how can I add it to my project if I initialized a project using stack
03:33:45 <cocreature> superlinux: add it to build-depends in your cabal file
03:34:07 <cocreature> superlinux: you probably also need to add it to extra-deps in your stack.yaml but stack will tell you that if you forget to do so
03:34:10 <superlinux> mmm ok
03:35:10 * hackagebot chatwork 0.1.0.0 – The ChatWork API in Haskell – https://hackage.haskell.org/package/chatwork
03:43:39 <ventonegro> huh both <$> and <*> have precedence 4
03:44:05 <ventonegro> and yet GHC tells me I cannot mix my own operator with precedence 4 in the same infix expression
03:46:05 <ventonegro> ah, never mind. I typed `infix` instead of `infixl`
03:53:47 <zomg> Oh. I accidentally used ExistentialQuantification correctly... I think. At least it compiled so I guess it works :P
03:54:46 <cocreature> it typechecks! ship it!
03:55:26 <zomg> Yep!
03:55:40 <zomg> Have a record with functions in it, ie. stuff :: IO Blah
03:55:53 <zomg> wanted to change IO to MonadIO m without having to put m on left side
03:56:10 <zomg> after several failed attempts with RankNTypes I randomly just put the constraint into a different place and it worked :P
03:56:20 <zomg> I guess I must've learned *something*
03:56:40 <quchen> You’ll learn something when you try accessing your value.
03:56:49 <cocreature> I don’t want to destroy your euphoria but RankNTypes seems more appropriate
03:57:07 <zomg> quchen: I have a bunch of code which was working with IO already and I changed it into MonadIO m and it compiled so I'd guess it works :)
03:57:32 <zomg> cocreature: well I just got a million rigit type variable errors with RankNTypes so no idea
03:57:40 <zomg> *rigid
03:57:56 <cocreature> zomg: you’ll have to be a bit more specific and show us some code and the actual error message, if you’d like help :)
03:58:20 <zomg> sure - it's basically just data Foo = Foo { func1 :: X -> IO y }
03:58:47 <zomg> what I tried and failed was forall m. (MonadIO m) => func1 :: X -> m y
03:58:58 <zomg> but moving it into forall m. (MonadIO m) => Foo {... worked
03:59:07 <cocreature> with RankNTypes you are saying “this function wroks for any m that is an instance of MonadIO”. with EXistentialQuantification you are saying “there is some m for which this function works but all I’m going to tell you about this m is that it’s an instance of MonadIO
04:00:10 <zomg> Yep that's what I gathered but haven't really fully grokked what it means in practice I think :)
04:00:16 <cocreature> where is "y" coming from?
04:00:25 <zomg> oh sorry, that should've been a concrete type
04:00:37 <zomg> for example Int
04:00:38 <zomg> or whatever
04:02:14 <cocreature> zomg: with your existential type you can construct a Foo by supplying it a function of signature "X -> MyMonad Int" if MyMonad is an instance of MonadIO. with a rankntype you can conly construct a Foo if you have a function of signature "MonadIO m => X -> m Int", i.e., it has to be polymorphic
04:02:22 <cocreature> zomg: http://lpaste.net/356577 works just fine for me
04:03:05 <zomg> it started complaining at the point where my actual code defining values for that tried to use IO or such
04:03:32 <cocreature> now we’re back to you having to show us the code and the error messages that are actually causing problems :)
04:03:33 <zomg> which probably would make sense since RankNTypes requires it to be polymorphic 
04:05:36 <zomg> well, for example if I was to define func1 as print n >> return n
04:05:48 <zomg> but I'm guessing it's because print constrains m to just IO
04:06:14 <cocreature> right you’ll need to define your function using "liftIO (print n) >> return n"
04:06:26 <zomg> Ah
04:06:30 <zomg> of course :)
04:06:38 <cocreature> the problem with the existential type is that you can’t actually do anything with func1
04:06:57 <cocreature> all you know is that it’s some function of type "X -> m y" for some m that is an instance of MonadIO
04:07:08 <cocreature> but without knowing what m is (and you don’t know this) you can’t use that function
04:08:45 <zomg> Right - I guess the only way to "unbox" the value in this case would be to include some function along with it to do so
04:09:11 <zomg> well, it wouldn't really "unbox" it per-se, but rather you could pass it to allow making some operation on the value
04:09:36 <ski> `data Foo = Foo { func1 :: forall m. MonadIO m => X -> m Y }' means that the type `Foo' contains a *polymorphic* function of type `forall m. MonadIO m => X -> m Y'
04:10:46 <ski> `data Foo = forall m. MonadIO m => Foo { func1 :: X -> m Y }' means that the type `Foo' contains an "abstracted" function of type `exists m. MonadIO m *> X -> m Y', iow there is (/ *exists*) some opaque/forgotten type `m', about which we only know that it's an instance of `MonadIO'
04:11:17 <zomg> Yeah, I think I'm starting to understand it a bit better
04:11:52 <ski> in the former case, the data consstructor have signature `Foo :: (forall m. MonadIO m => X -> m Y) -> Foo'. this is not a polymorphic data constructor. it is rank-2. it otoh requires the *argument* to be polymorphic
04:13:22 <ski> in the latter case, the data constructor have signature `Foo :: forall m. MonadIO m => ((X -> m Y) -> Foo)' (extra brackets for emphasis). this *is* a polymorphic data constructor. the signature is logically equivalent to `Foo :: (exists m. MonadIO m *> (X -> m Y)) -> Foo'
04:14:54 <ski> (just like `length :: forall a. ([a] -> Int)' is logically equivalent to `length :: (exists a. [a]) -> Int'. the former says that given any type `a', `length' can accept a list of `a's, and produces an `Int'. the latter says that `length' will produce an `Int', as long as there *exists* an `a' such that the argument has type `[a]'. these two are the same thing)
04:16:50 <zomg> Thanks - Not sure if I really got all of that but I'm sure I'll make the connection eventually :D
04:16:59 <ski> as cocreature said, with the "universal" `Foo', you can only pack a polymorphic function, not a monomorphic one, e.g. of type `X -> M Y' (assuming `MonadIO M'). but you can use the polymorphic contents as `X -> IO Y' or `X -> M Y', &c.
04:17:51 <ski> while with the "existential" `Foo', you can pack a monomorphic one like `X -> M Y'. otoh when you extract the contents and want to you it, you don't know anything about `m', except that `MonadIO m' holds
04:18:05 <zomg> yeah as far as I understand at this point with RankNTypes, you can pass whatever fits the constraints when calling the function
04:18:07 <ski> s/to you it/to use it/
04:18:17 <zomg> but the function itself just cannot make any judgements about what those types might be
04:18:40 <ski> zomg : "you can pass whatever fits the constraints when calling the function" -- which definition of `Foo' do you have in mind, when saying this ?
04:19:04 <zomg> the RankNTypes one
04:19:37 <ski> i want to confirm that you've correctly understood which definition of `Foo' is the one that requires `RankNTypes'
04:20:22 <zomg> data Foo = Foo { func1 :: forall m. MonadIO m => X -> m Y }
04:20:30 <ski> right
04:21:26 <ski> so i suppose then that "the function" in "you can pass whatever fits the constraints when calling the function" referred to the function `func1' inside (or the corresponding field selection function), not the data constructor function `Foo'
04:21:51 <zomg> Yeah
04:22:22 <ski> i would probably say that you can pick and choose whatever `m' you like, when using that function, as long as its an instance of `MonadIO'
04:23:18 <zomg> Yep that's pretty much what I meant :)
04:23:54 <ski> when *using* a value of universally quantified type (aka a polymorphic value, often a function), one may pick and choose any particular type to use for the type variable, as long as it satisfies any present constraints after the quantifier, delimited by `=>'
04:25:15 <ski> when *defining* such a value, otoh, one must treat that type variable as an unknown/opaque/hidden/abstract type. the caller will decide on it, the callee must henceforth accept anything the caller picks, so the callee can assuming nothing about it (apart from explicitly granted constraints with `=>')
04:27:04 <zomg> Yep
04:27:23 <zomg> it was a bit of a "how do I do anything with this" if I can't define what it is in the function itself
04:27:32 <ski> otoh, when *defining* a value of existentially quantified type, or a value packed inside an "existential" data type, one (the callee) may pick and choose whatever particular type for the type variable one wants, as long as it satisfies extant associated constraints, delimited by `*>' (imaginary syntax)
04:27:36 <zomg> but I seem to have missed the fact that I could have just used liftIO :)
04:28:41 <ski> while, when *using* a value of existentially quantified type (or ...), one (the caller/user) must treat the type variable abstractly/opaquely, as a hidden/unknown type, about which only the (with `*>') given constraints are known
04:29:28 <ski> my point here is that the situation with `forall' vs. `exists' are reversed, when we consider callee/definer vs. caller/user
04:29:40 <zomg> Yeah
04:29:59 <ski> (so the user of an existential must be *polymorphic* in the hidden type)
04:32:18 <zomg> That's a very comprehensive explanation, thanks
04:32:39 <zomg> I think I roughly get these now at least on this basic level :)
04:32:43 <ski> hm .. i'm not sure whether `data Foo = Foo { func1 :: forall m. MonadIO m => X -> m Y }' is actually of any more use than simply `data Foo = Foo { func1 :: X -> IO Y }'
04:33:04 <ski> regarding
04:33:06 <ski>   data Foo = forall m. MonadIO m => Foo { func1 :: X -> m Y }
04:33:31 <ski> what is often confusing at first, is that this is an "existential" data type, but still it uses the `forall' keyword
04:33:44 <zomg> well it's mostly that one of the Foos needed to use a monad transformer instead of plain IO so it became a bit of a hassle
04:33:46 <ski> that's because the type signature of the data constructor `Foo' here is
04:34:10 <ski>   Foo :: forall m. MonadIO m => ((X -> m Y) -> Foo)
04:34:24 <ski> so the data constructor *is* polymorphic (hence the `forall')
04:34:56 <ski> however, the type variable `m' which the type is universally quantified in, doesn't appear in the result type !
04:35:41 <zomg> I don't have any mathematical background on forall and all that so I have no confusion coming from anything like that :D
04:35:41 <ski> this means that after a use of the data constructor, the actual `m' used by whoever constructed the value is *gone* from the type, hidden/forgotten
04:36:29 <ski> so, when pattern-matching on a value of type `Foo', we have no idea what `m' was used (it could have been decided as late as run-time, e.g.)
04:36:41 <ski> so, the type signature
04:36:44 <ski>   Foo :: forall m. MonadIO m => ((X -> m Y) -> Foo)
04:36:49 <ski> is logically equivalent to
04:36:49 <zomg> yeah, that's basically why I was trying to use it - the issue was just mostly how to actually make it work :P
04:37:01 <ski>   Foo :: (exists m. MonadIO m *> (X -> m Y)) -> Foo
04:37:51 <ski> as long as there *exists* some `m', being an instance of `MonadIO', you can pass a function of type `X -> m Y', for that `m', to the data constructor, and get a `Foo' value
04:38:15 <ski> well, the confusion i referred to would be what the difference between
04:38:22 <ski>   data Foo = forall m. MonadIO m => Foo { func1 :: X -> m Y }
04:38:23 <ski> and
04:38:41 <ski>   data Foo = Foo { func1 :: forall m. MonadIO m => X -> m Y }
04:38:51 <ski> seeing as both uses `forall' (and `=>')
04:39:33 <zomg> Yeah
04:40:14 <zomg> I read about how these features work but the stuff doesn't touch a whole lot on what it means in practice
04:40:16 <ski> the (crucial) difference is in the placement of `forall'. in the former (existential) case, the data constructor itself is polymorphic (having universal / `forall' type). in the latter ("universal") case, the *argument* of the data constructor is required to be polymorphic (to have universal type)
04:40:22 * ski nods
04:40:25 <zomg> I think what made it click a bit more was when cocreature mentioned that I could just use liftIO
04:40:51 <zomg> because it made it a lot more concrete in terms of what it means in practice
04:41:13 <ski> the key parts are how one can construct (and can't construct) values in the two cases, as well as how one can use (and can't use) them, with pattern-matching
04:41:30 <ski> then it also helps with concrete examples that are useful
04:42:40 <ski> (i think that realizing that (e.g.) `length :: forall a. ([a] -> Int)' is the same thing as `length :: (exists a. [a]) -> Int' can also help, seeing as this is a simpler, and more familiar case)
04:44:00 <ski> e.g. if you wanted to make a data type for representing *implementations* of queue operations (on an element type `a'), you could use `data QueueOps a = forall q. MkQO {emptyQ :: q,enqueue :: a -> q -> q,dequeue :: q -> Maybe (q,a)}'
04:45:22 <ski> one value of type `QueueOps a' could pick `q' to be a list type `[a]', then we have `emptyQ = []; enqueue a q = q ++ [a]; dequeue [] = Nothing; dequeue (a:q) = Just (q,a)'
04:45:48 <ski> (if one prefers, one could add to the other side of the list, but then `dequeue' is a little bit more involved)
04:50:12 <zomg> yep
04:50:21 <ski> another value of type `QueueOps a' could pick `q' as the folklore implementation `([a],[a])' (front & reversed back, amortized linear time), with `emptyQ = ([],[]); enqueue a (front,revBack) = (a:front,revBack); dequeue (front,[]) = case reverse front of {[] -> Nothing; a:revBack -> Just (([],revBack),a)}; dequeue (front,a:revBack) = Just ((front,revBack),a)'
04:52:25 <ski> a value of type `QueueOps a' acts like "a module implementing the queue interface", except that we can select which "module" to use as run-time (and the operations are the fields in the record. the abstract data type in the module has turned into the existentially quantified type variable, in the representation type (conceptually) being `exists q. (q,a -> q -> q,q -> Maybe (q,a))')
04:52:58 <ski> typically, to use it, we open `QueueOps a' once, then use the operations contained inside, until we're done
04:54:24 <ski> otoh, if we wanted to emulate object-orientation, then we'd store not `emptyQ' but `currentQState' in the record (renaming the type to just `Queue a'), and after each update, we'd repack the new state with the operations into a new `Queue a' value
04:55:10 <ski> so, we'd repeatedly unpack and pack the existential. this is not the same thing as the ADT usage pattern of existentials
04:56:19 <ski> with the ADT usage pattern (as in `QueueOps' here), we can easily implement "merge"-operations, of type `x -> x -> x', `x' being the hidden type
04:57:02 <ski> otoh, with the OO usage pattern, we can't do that easily, since we repack constantly, and so we forget which values use the same hidden representation type `x'
04:58:04 <zomg> well, once I get this mostly done I'll probably have more complicated issues =)
04:58:30 <zomg> I have a bunch of checks in code right now which does stuff like "does this Foo support this particular value"
04:58:46 <ski> (if we want to take the union of two sets, then we'd usually prefer knowing the representation of both of them. e.g. some particular kind of balanced trees)
04:58:50 <zomg> which feels like it should be something the typechecker makes redundant by making it so you can't even pass in unsupported values
04:59:06 <zomg> but I wasn't quite able to figure out how to set it up for my specific case in a way that it didn't make everything else painfully tedious :D
04:59:33 <ski> example of "does this Foo support this particular value" ?
05:00:05 <zomg> well, I'm basically writing clients for cryptocurrency exchanges for this random project I'm working on
05:00:31 <zomg> so they might provide a function to get an exchange rate between a fiat currency and cryptocurrency
05:00:47 <zomg> some exchanges support euros, others do not - so this seems like something that could be encoded in types
05:02:29 <ski> hm, possibly
05:03:37 <zomg> I might be completely off the track but my best guess was if each currency was a type, I could potentially define a typeclass for each exchange, and give each supported currency an instance for it
05:04:11 <zomg> but it's not something I intend to try and implement right now :) maybe when it kinda works otherwise
05:19:36 <dredozubov_> I did typesafe money once
05:19:43 <dredozubov_> it was a pain in the butt
05:19:53 <bollu> there's a library for that, no?
05:20:02 <dredozubov_> ended up not merged
05:20:10 <bollu> https://github.com/k0001/safe-money
05:20:13 <bollu> safe money^
05:20:40 <dredozubov_> I had an other use case for that
05:20:52 <dredozubov_> so I had to come up with a different design
05:21:22 <dredozubov_> basically I had a bunch of projects and each of them operate on a closed set of currencies
05:22:22 * hackagebot amqp 0.15.1 – Client library for AMQP servers (currently only RabbitMQ) – https://hackage.haskell.org/package/amqp
05:22:41 <dredozubov_> ended up with dependent typing, singletons, existential wrappers, pretty weird instance search with reflection
05:22:48 <dredozubov_> so, yuck
05:23:24 <dredozubov_> by the time I moved the first project to that, I was completely exhausted
05:24:06 <dredozubov_> if you have plenty of exchanges, you have a similar situation
05:24:45 <dredozubov_> you have to define money generically, but each exchange corresponds to the closed set of currencies
05:27:58 <quchen> Why not just Tagged (cur :: Symbol) Fixed*?
05:28:27 <dredozubov_> I needed a list of supported currencies for each project
05:28:48 <quchen> Tagged Currency Fixed; Currency sum type with Enum instance?
05:29:59 <dredozubov_> you can't properly deserialize values with that approach
05:30:11 <dredozubov_> you need singletons for that
05:31:18 <dredozubov_> you can deserialize them to SomeMoney of course
05:31:37 <dredozubov_> but how would you cast it to `Money 'USD` later if you need it?
05:32:03 <dredozubov_> you need a witness for that
05:36:55 <Myrl-saki> Is `Compose Fix` == `Free`?
05:39:01 <zomg> dredozubov_: good to know it was a pain, think I might just avoid it then and do something more productive :D
05:40:07 <cocreature> Myrl-saki: do you really mean Compose? Compose is for composing two functors but Fix is not a functor.
05:42:14 <ski> @kind Compose Fix
05:42:15 <lambdabot> (k -> * -> *) -> k -> *
05:42:26 <dredozubov_> zomg: it depends on your requirements
05:42:29 <ski> @kind Compose IORef MVar
05:42:31 <lambdabot> error:
05:42:31 <lambdabot>     Not in scope: type constructor or class ‘IORef’
05:42:31 <lambdabot> error:
05:42:31 <dredozubov_> YMMV
05:42:44 <Myrl-saki> @kind Free
05:42:46 <lambdabot> error:
05:42:46 <lambdabot>     Not in scope: type constructor or class ‘Free’
05:42:46 <lambdabot>     Perhaps you meant ‘Tree’ (imported from Data.Tree)
05:42:53 <Myrl-saki> Ree
05:43:04 <ski> @kind Compose Data.IORef.IORef Control.Concurrent.MVar
05:43:05 <lambdabot> * -> *
05:43:26 <cocreature> Myrl-saki: leaving Compose aside, the Fix constructor is very much like the Free constructor but the Free type also has Pure
05:43:42 <Myrl-saki> cocreature: Right, that's my point.
05:43:54 <ski> `Compose' is not just for composing functors, though that's probably the most common use case
05:43:57 <cocreature> Myrl-saki: also the things you’re parametrizing over are of different kind
05:43:59 <Myrl-saki> cocreature: I was wondering if we can get Free from Fix.
05:44:17 <cocreature> ski: well it’s not restricted to composing functors but I think it is very much intended for composing functors
05:44:17 <Myrl-saki> If the functor has an applicative instance.
05:44:19 <Myrl-saki> Anyway, BRB, eat.
05:47:45 <zomg> Gah - of course there ends up being a pattern match error with the existential, and with RankNTypes it eventually just cannot deduce that the MonadIO m should also have MonadReader m
05:48:05 <ski> Myrl-saki : `Control.Monad.Free f a' is basically `Fix (Compose (Either a) f)'
05:48:11 <zomg> Potentially because the original data type declaration only has MonadIO m, but the whole point of this exercise was to allow some other monad as long as it was MonadIO... bleh
05:48:25 <zomg> (and not force everything to also be a MonadReader)
05:48:57 <zomg> I might just go back and partially apply the functions to manually pass around the stuff that would've been in the reader
05:49:01 <zomg> that'll at least work :D
05:49:04 <ski> zomg : yes .. i was wondering how you were going to use the existential ..
05:49:17 <cocreature> zomg: you really need to start and include code snippets with your complaints so people can actually help you :)
05:49:29 <zomg> yeah I was happily chugging away because it compiled... the only issue was none of my compiling code was actually using that specific function :P
05:49:34 <ski> (not really getting the complete picture of what you want to do)
05:50:00 <cocreature> usually if you’re not sure if you want existential types you don’t want them :)
05:50:19 <zomg> cocreature: yeah I went back to using RankNTypes as you mentioned it sounded more like the right thing
05:50:27 <zomg> let's see if I can simplify this enough for a sample :P
05:51:34 <zomg> well, I guess it's basically that I want to have data Foo = Foo { forall m. (MonadIO m) => X -> m Y }
05:51:51 <zomg> which works as long as any value for Foo only puts MonadIO constraints on m
05:52:12 <zomg> however the whole reason I wanted to use MonadIO instead of plain IO there was so I could use some arbitrary monad transformer stack as `m`
05:52:39 <zomg> where from the caller's perspective the only relevant aspect is that it's MonadIO, the rest is irrelevant for the caller
05:52:54 <zomg> (because it would just be used to carry internal state)
05:53:23 <cocreature> I think you are confusing two things here: that type allows you to _use_ the function wrapped in Foo in an arbitrary monad transformer. being able to _use_ the function in an arbitrary monad transformer requires that it is _defined_ without making any assumptions about which monad it runs in
05:53:55 <cocreature> if you have a function that is defined in terms of Double you can’t use it for Int even though both are instances of Num
05:54:04 <cocreature> that’s basically the same problem you have
05:54:35 <cocreature> but it’s not a problem you can solve. if the function makes assumptions about the monad you’re not going to be able to run it in some other monad
05:55:31 <zomg> right, so the function itself is happy as long as it's MonadIO because it can do runReaderT within MonadIO - meaning it doesn't make any assumptions beyond the constraint
05:55:50 <zomg> at least that's as far as I can understand this :)
05:56:07 <zomg> But I guess it means I also cannot add other constraints on `m` in the function's definition
05:56:17 <cocreature> right
05:56:25 <zomg> which circles back to the original issue
05:56:28 <Myrl-saki> ski: Oh lol
05:56:37 <zomg> I guess there's some other way to do this without running into it...
05:56:50 <gonz_> Does stack pass '-O2' to GHC by default on `stack install`?
05:57:00 <cocreature> zomg: so step 1. figure out how you are going to use Foo
05:57:13 <cocreature> zomg: i.e. what constraints are you able to satisfy at the use site?
05:57:27 <zomg> MonadIO is enough for that
05:57:34 <quchen> gonz_: -O only
05:57:42 <cocreature> zomg: it’s not about being enough, it’s about can you provide m ore than MonadIO?
05:57:49 <quchen> gonz_: -O2 is rarely worth the increased compilation time
05:57:53 <cocreature> zomg: because that will allow more functions to be passed as arguments to Foo
05:58:34 <merijn> quchen: What about -fgotta-go-fast? :p
05:58:42 <zomg> cocreature: Ah right, I could probably just pass whatever at the use site :)
05:58:47 <cocreature> zomg: basically it boils down to “be as polymorphic as you can when you’re defining things” and “be as specific as you can in the things passed to you”
05:59:02 <zomg> hmm
05:59:16 <cocreature> if you’re only calling Foo in a context where you have MonadIO, MonadState s and MonadReader r you can add those constraints in Foo
05:59:19 <gonz_> quchen: Ah, ok. Yeah, 'cause I'm seeing no difference when I pass '--ghc-options=-O2' to the command, so I was thinking maybe it's implicit.
05:59:24 <cocreature> and then the functions you pass to Foo can use those constraints
05:59:57 <zomg> yeah makes sense
06:00:14 <zomg> I suspect the next issue would be how does each Foo potentially have its own environment in Reader
06:00:21 <Myrl-saki> @let import Control.Monad.Free
06:00:22 <lambdabot>  Defined.
06:00:23 <zomg> or rather, right now I only have one which needs reader, the rest don't
06:00:28 <Myrl-saki> @kind Free
06:00:29 <lambdabot> (* -> *) -> * -> *
06:00:35 <Myrl-saki> @kind Fix
06:00:36 <lambdabot> (* -> *) -> *
06:02:01 <Myrl-saki> Okay...
06:02:13 <zomg> because I get the feeling that even if I was to add the correct constraints, using asks in the implementation would again make it non-polymorphic
06:02:15 <Myrl-saki> I have no idea. lol.
06:03:06 <cocreature> zomg: you’ll end up with "(MonadReader r m, MonadIO m) => X -> m Y"
06:03:35 <zomg> Yeah, so doesn't that constrain the function so it has to be polymorphic for `r` as well?
06:03:57 <cocreature> zomg: if all monads you want to use this in are an instance of "MonadReader r" you’re fine. if not then maybe you should consider not using the same "Foo" type for everything because you want different things
06:04:07 <cocreature> zomg: I was thinking of "r" as a specific type
06:04:17 <cocreature> so MonadReader Int m or whatever
06:04:51 <zomg> Right, this would probably have different r's for each Foo
06:04:57 <bollu> itihas ping
06:05:18 <cocreature> zomg: you could add the r as a type parameter to Foo
06:05:56 <zomg> At that point I might as well just add the monad as a type parameter :)
06:06:25 <cocreature> well as always it depends on what you want to express :)
06:06:42 <cocreature> but there is nothing inherently wrong with adding the monad as the type parameter
06:06:48 <zomg> yeah essentially it's a bunch of api clients where certain actions are performed on all of them
06:07:10 <zomg> so the reason I was trying to avoid it in the first place was so I could just stick 'em all in a list easily
06:07:23 <zomg> and then do something like mapM whatever clients
06:07:26 <dredozubov> what's wrong with having a MonadReader constraint?
06:08:32 <zomg> mostly that as far as I can tell if it was done using RankNTypes it would constrain the function to be polymorphic for the environment
06:08:50 <zomg> which would pretty much make it kind of useless since the reader was supposed to carry state specific to that value :)
06:09:32 <cocreature> zomg: well you can also have a list of type "forall m. MonadIO m => [X -> m Y]"
06:09:53 <cocreature> :t [(+1),(+2)]
06:09:54 <lambdabot> Num a => [a -> a]
06:10:02 <cocreature> similar to that
06:11:17 <zomg> hm
06:11:49 <zomg> oh I guess you mean I could put the functions into the list rather than the containing values?
06:12:18 <dredozubov> exactly
06:12:29 <dredozubov> but you'll need a wrapper for that, I believe
06:12:46 <cocreature> what kind of wrapper?
06:13:07 <cocreature> I’ve just demonstrated that you don’t need a wrapper to put polymorphic functions in a list so I’m not sure what you’re suggesting
06:13:18 <zomg> hmm
06:13:25 <zomg> I guess I can see if I can make that work
06:13:26 <cocreature> they just need to be polymorphic in the same way but that’s the case for Foo as well
06:13:38 <zomg> but this is basically descriptive of my feeling right now: http://cdn1.meme.am/cache/instances/folder413/500x/78270413/magnets-how-do-they-work-types-how-do-they-work.jpg
06:13:41 <zomg> lol
06:14:00 <dredozubov> cocreature: you're right, I misread a signature
06:14:25 <cocreature> zomg: I think it might be helpful if you first think about what your problem is on an abstract level and then try to encode that into types
06:14:27 <osa1> anynone know if warp's response function blocks the caller?
06:14:28 <zomg> anyway think I'll give this a spin, and if it doesn't work I'll just stick to partially applying the damn reader environment into the function =)
06:14:55 <cocreature> zomg: it seems like you are really having some logic errors in your thoughts here and it’s not Haskell’s type system preventing something sensible but something which just doesn’t make sense
06:15:25 <zomg> that seems likely
06:15:40 <zomg> I just don't know how to work with some of the more advanced features of the typesystem
06:15:57 <zomg> which probably makes me think of it in a way that's not helpful :)
06:16:30 <zomg> but let's see, at least I'm closer to somewhat understanding RankNTypes and ExistentialQuantification now so at least that's a step into some direction
06:16:33 <zomg> :P
06:21:11 * hackagebot vector-mmap 0.0.3 – Memory map immutable and mutable vectors – https://hackage.haskell.org/package/vector-mmap
06:24:21 <Myrl-saki> ski: I get it now. Free can't be nested forever, while Fix has to be.
06:24:28 <Myrl-saki> ski: Well, can be nested not forever.
06:25:51 <k0001> dredozubov: RE that safe-money thing: You can deal with "unknown" currencies with `RankNTypes` using some of the `withXxxRep` functions, or `fromXxxRep` if you know the target type (i.e., your "closed world"). Please ping me if you have any doubts or requests. 
06:26:18 <dredozubov_> k0001: oh hey man
06:26:42 <dredozubov_> I think i did my own thing before you've released safe-money
06:27:08 <dredozubov_> so i haven't really looked into it
06:27:22 <quchen> Free f a = Fix (λ rec -> Either a (f (rec f)))
06:27:25 <quchen> Something like this?
06:28:35 <quchen> Fix = Free Void
06:29:19 <Myrl-saki> quchen: I didn't actually think of the `Free Void`, that's pretty smart.
06:29:32 <k0001> dredozubov_: Ah, OK. Well, if you ever explore it, please let me know how it goes :)
06:30:00 <cocreature> quchen: it should be Fix f = Free f Void no?
06:30:18 <quchen> Yeah
06:30:31 <quchen> Messed up the argument order 
06:31:49 <Myrl-saki> quchen: Flip Free Void :D
06:32:13 <dredozubov> k0001: how do you deal with deserializing money values there?
06:32:31 <bollu> quchen wow
06:32:34 <dredozubov> I expect there to be a term-level witness of currency
06:33:01 <bollu> quchen Free Void is something I never thought I'd see. I didn't realize it was a valid functor
06:33:17 <quchen> That was just a typo.
06:33:31 <quchen> Free Void a = a ;-)
06:33:43 <bollu> yeah, because the Void doesn't add anything on layering
06:33:44 <bollu> heh
06:33:54 <bollu> Free Void a ~= Leaf a ~= a
06:33:55 <bollu> cool
06:34:21 <bollu> quchen I'll be spending my saturday compiling toy programs and reading asm to see the difference
06:34:32 <bollu> quchen between what prettyprinter generates and what pretty generates
06:34:44 <bollu> quchen ship me alcohol to bear the pain, please :P 
06:34:44 <quchen> \o/
06:35:00 <quchen> Sorry, I can’t affort shipping to Switzerland
06:35:04 <quchen> I’m from a poor country
06:35:16 <bollu> quchen I was deeply disturbed that I broke stage2 because of changing the pretty printer.
06:35:22 <bollu> :)
06:35:24 <quchen> uuhh??
06:35:28 <dredozubov> does the postal service even work like this?
06:35:29 <quchen> That sound strange indeed
06:35:37 <bollu> yeah, it looks like it generates incorrect asm
06:35:41 <dredozubov> it's not like you're delivering it in person
06:36:06 <bollu> haskell gets compiled incorrectly, because the pretty printer is used to generate asm in GHC
06:36:25 <bollu> so, because I don't have 1:1 equivalence between pretty & prettyprinter, something breaks.
06:36:30 <bollu> it's painful indeed.
06:36:36 <quchen> Haha in the end I can say that my code is deeply intertwined with the GHC NCG
06:36:40 <bollu> lol
06:36:42 <bollu> indeed
06:36:58 <bollu> quchen hopefully I'll rip out with simplexhc at some point in the future ;)
06:37:18 <quchen> »Soooo David, what did you do for the GHC backend?« – »Well, I made the leading spaces align nicely in the ASM, I’m a pretty 1337 hacker you know«
06:37:30 <bollu> quchen replace the C-- -> asm backend with the STG -> LLVM thing
06:37:34 <quchen> »The bugs were fixed by this other guy though« ;-)
06:37:59 <bollu> quchen "I also inflicted horrible pain on a teenager in the process" ;)
06:38:03 <bollu> quchen if you want to be dramatic
06:38:06 <quchen> Maaaybe it has something to do with the $+$ issue?
06:38:13 <bollu> quchen yes, I suspect so myself
06:38:16 <bollu> quchen I'll have to look.
06:38:33 <quchen> bollu: I don’t see how inflicting horrible pain onto teenagers is useful for selling compiler backends
06:38:49 <quchen> Must be some new age stuff
06:38:51 <bollu> quchen "ooh, these people are into some hardcore stuff. Maybe we should join the GHC team"
06:39:06 <ski> bollu : could you use QuickCheck to generate and check for difference ?
06:39:07 <dredozubov> quchen: it just may be pleasant in a very weird way
06:39:17 <bollu> ski good point, I think I could.
06:39:34 <dredozubov> also know your audience with a selling pitch
06:39:35 <ski> (with shrinking, to remove irrelevant parts
06:39:36 <ski> )
06:39:38 <dredozubov> they may be into that
06:39:44 <quchen> I think the output should be easy to diff though. Long, but diffable.
06:39:45 <bollu> ski right
06:40:03 <bollu> ski but that would involve teaching QC how to shrink Doc, no?
06:40:40 <quchen> Or to shrink ASM
06:40:44 <ski> well, shrink whatever you're generating, which is fed into the pretty printers, no ?
06:40:49 <bollu> hm, that works
06:40:54 <k0001> dredozubov: you deserialize your raw bytes to one of `DenseRep`, `DiscreteRep` or `ExchangeRateRep` (there are helper constructors named `mkXxxx` for these in the `Internal` module, they probably should be in the `Data.Money` module), and then you use the `withXxxRep` or `fromXxxRep` to go to the typeful representaion.
06:42:08 <itihas> hello, is this a coherent instance? http://lpaste.net/356584
06:43:09 <bollu> itihas you're asking if LabelTree l is a valid monad with that instance, right?
06:43:20 <c_wraith> itihas: the Functor instance is broken
06:43:22 <ski> itihas : missing case for `fmap f Empty'
06:43:30 <sepakorayl> how would i write a modify function that takes a lens and a type and does nothing if the type is not compatible with the lens ?
06:43:30 <glguy> line 10 is wrong
06:43:50 <ski> yeah, type error
06:44:04 <c_wraith> sepakorayl: fortunately, the compiler prevents that before your function even sees it
06:44:19 <k0001> sepakorayl: perhaps you want a Traversal or Prism instead?
06:44:25 <glguy> sepakorayl: generally you wouldn't
06:44:40 <bollu> itihas pattern matching with [x] means that you're matching on a list with _one_ element x
06:44:46 <ski> (er, actually also missing cases there)
06:44:49 <bollu> > let [x] = [1] in x
06:44:51 <lambdabot>  1
06:44:54 <Gurkenglas> sepakorayl, can you give us a type signature for what you want?
06:44:58 <bollu> > let [x] = [1, 2] in x
06:45:00 <lambdabot>  *Exception: <interactive>:3:5-16: Irrefutable pattern failed for pattern [x]
06:45:02 <bollu> ^ 
06:45:18 <bollu> > let (x:xs) = [1, 2] in show x ++ show xs
06:45:20 <lambdabot>  "1[2]"
06:45:50 <ski> itihas : `case' on line `17' is also missing branch for `Empty'
06:47:51 <sepakorayl> data perhapsModify :: (SupportsLens (Lens a b) t) => Lens a b -> t -> b -> t. basically use lens if a ~ t do nothing otherwise
06:47:58 <sepakorayl> ignore data
06:48:11 <sepakorayl> pseudocode I don't remember lenses very well
06:49:15 <Gurkenglas> sepakorayl, how would you use it? When you do, you should already know whether the type supports the lens
06:49:47 <sepakorayl> I am looking at alternatives to generating a ton of boilerplate
06:50:20 <Gurkenglas> Kinda sounds like Control.Lens.Plated might help. Can I look at sample code to simplify?
06:50:45 <sepakorayl> I will try give me a moment
06:53:57 <bollu> http://lpaste.net/356586
06:54:01 <bollu> is that lawful? ^
06:54:05 <bollu> I fixed the bugs in the tree
06:54:18 <bollu> I need to check the monad laws, functor laws seem correct.
06:58:07 <bollu> ski could you check if the laws are coherent? I think they are, but I'm not super sure.
07:00:09 <Gurkenglas> Using http://hackage.haskell.org/package/lens-4.15.3/docs/src/Data.Data.Lens.html#mightBe (why doesn't it export that?): perhapsSet :: Lens' s a -> a -> x -> x; perhapsSet = case mightBe :: Maybe (Is s x) of Nothing -> const $ const id; Just Refl -> set
07:00:41 <Gurkenglas> "(Typeable s, Typeable x) => " in front, of course
07:02:27 <Gurkenglas> (afaik, Typeable means monomorphic and tells ghc to keep type information around during runtime)
07:04:13 <Gurkenglas> Oh wait, mightBe is eqT from Data.Typeable. Why does lens define mightBe?
07:10:16 <sepakorayl> http://lpaste.net/356587, http://lpaste.net/356588. I basically want an easy way to write the second paste's validate function or at least avoid handling all constructors.
07:13:42 <ventonegro> I have a large-ish record and need to insert it in a DB. I am dreading typing `toField (fieldAccessor rec)` for all the record fields. Reader doesn't help much here because the end result should be a list, `[SQLData]`
07:14:21 <ventonegro> Does anyone have an idea of how I can avoid this repetition?
07:15:22 <Gurkenglas> sepakorayl, "ifEqual :: (Typeable s, Typeable a) => Setter' s a; ifEqual = case eqT :: Maybe (s :~: a) of Nothing -> const pure; Just Refl -> id" should be close to what you want
07:20:06 <sepakorayl> "Could not deduce (Typeable s1) arising from a use of ‘eqT’"
07:20:20 <Lokathor> https://lokathor.gitbooks.io/using-haskell/content/roguelike/week-2-graphics-and-dungeon-basics.html so far, am I saying anything that's actually wrong? i'm particularly wondering near the end when I try to touch on lazy evaluation
07:31:02 <Cale> Lokathor: I only looked for a few seconds, I don't really have time to read carefully right now, and I don't know how much you want to nitpick about this, but GHC doesn't *just* do lazy evaluation
07:32:02 <Lokathor> it's okay if GHC does more that isn't talked about right away, this is beginner's stuff. I just wanted to bring up the subject a bit at all
07:32:04 <Cale> Lokathor: It actually evaluates things in a different order a lot of the time from what lazy evaluation would do -- it does a bunch of strictness analysis, figuring out when it can prove that it will need something eventually, and evaluating it earlier.
07:32:52 <Lokathor> hmm, but doesn't that analysis let it change the order when the changes wouldn't have an effect on the actual result?
07:33:40 <Lokathor> like, isn't that the point of the analysis, so that it doesn't make changes if that would affect the evaluation, like hitting an undefined by accident or something
07:33:45 <Cale> We assume that evaluating things in a different order will never have an effect on the actual result, so long as we're not so eager as to fail to terminate
07:34:12 <Lokathor> hmm
07:34:42 <Cale> But yeah -- practically speaking -- that means evaluating stuff which you wouldn't have otherwise been evaluated at all is forbidden
07:34:59 <Cale> (pretty much)
07:35:09 <Cale> -you
07:35:52 <Cale> It might be okay if it can prove that the evaluation terminates, but it's not very smart in that regard. Mostly it's looking for stuff which will definitely be pattern matched
07:36:40 <Cale> If a function immediately pattern matches its arguments against constructor patterns, it must be strict in those arguments, and it's possible to assume that they will need to be evaluated
07:37:23 <Cale> So no thunk need be allocated for the expressions there, it can just evaluate direct arguments to such a function immediately.
07:39:28 <Cale> I don't tend to think too much directly at the level of thunks when trying to figure out the performance of Haskell programs -- I prefer to think at the level of expressions (or at least expression graphs)
07:39:59 <Cale> I tend to think of the stack as consisting of case expressions waiting to match one of their patterns
07:40:15 <Cale> i.e. waiting for their scrutinee to be sufficiently evaluated to match a pattern
07:40:28 <Lokathor> yeah
07:40:49 <Lokathor> alright i'll edit a bit
07:40:50 <dolio> There are other things on the stack, too.
07:41:17 <dolio> Like writeback cells for lazy evaluation.
07:41:18 <Cale> dolio: right, there's applications waiting for the function to be sufficiently evaluated to apply
07:41:57 <Cale> ah, yeah
07:42:43 <Cale> But typically, if you actually get to the point of having a stack overflow, it's the case expressions waiting around which are usually the bulk of it
07:43:01 <Cale> At least, I don't ever recall seeing a non-contrived situation where it was anything else :)
07:46:21 <dolio> Yes.
07:46:40 <dolio> There's actually an easy optimization where you can never stack overflow just from update frames.
07:48:14 <dolio> So if you try to construct a pathological example, it will just use constant stack.
07:53:12 * hackagebot codec-rpm 0.1.0 – A library for manipulating RPM files – https://hackage.haskell.org/package/codec-rpm
08:07:20 <fresheyeball> anyone out there know dante?
08:14:27 * hackagebot codec-rpm 0.1.1 – A library for manipulating RPM files – https://hackage.haskell.org/package/codec-rpm
08:21:36 <Shockk> curious question, is there some part of mathematics that defines the precedence of operators (like + and x) explicitly? 
08:22:04 <Athas> Shockk: explicitly how?
08:22:06 <Shockk> I know that it's obviously defined in a certain way, but I'm wondering if this is explicitly defined in some mathematical way, or if it's just common knowledge
08:22:20 <Athas> You usually just specify it in text.
08:22:27 <Shockk> Athas: explicitly in the kind of way that haskell explicitly defines how tightly an operator binds
08:22:29 <Kristjan55555> http://imgur.com/a/6v4VA
08:22:38 <Athas> You can make it fully formal by specifying an actual grammar for the valid terms in your logic.
08:22:45 <Shockk> ah right, okay
08:22:54 <Athas> This is pretty common when mechanising proofs, just as when implementing programming languages.
08:23:28 <Shockk> hmm I have another loosely-related question
08:24:28 * hackagebot shakers 0.0.23 – Shake helpers. – https://hackage.haskell.org/package/shakers
08:24:39 <Shockk> how exactly are Haskell operators parsed? I mean, take this example:  5 + 3 * 2
08:24:53 <Shockk> based on the precedence of + and *, this should end up as:
08:25:11 <ski> bollu : i started trying to (more or less) formally prove the associative law .. i'm pretty sure that the `Empty -> Empty' branch in the `WTNode' case must be wrong (doesn't satisfy the law). i got lost a bit in the other cases, though (i'm a bit tired atm)
08:25:22 <Shockk> * (+ 5 3) 2   as the AST, or something like that, if that makes any sense
08:25:38 <Shockk> but the parser can't build the correct AST in that way until it knows the precedence of all operators
08:26:11 <Shockk> so is there a pre-parser pass that parses for precedences defined with infix/infixl/infixr?
08:26:17 <Athas> Shockk: first it creates some parse that does not take priority into account, then it fixes it later.
08:26:23 <Shockk> ahh right
08:26:28 <Shockk> so it does a full parse? 
08:26:46 <Athas> Yes.
08:26:51 <Shockk> hmm interesting, okay
08:27:06 <Shockk> that's the approach I was considering taking but I didn't know if there was some better way to do it
08:27:09 <Shockk> makes sense, thanks
08:27:09 <Athas> In Haskell, you always know lexically whether something is infix or not, so it can do a kind of pre-parse that can be easily fixed up later.
08:27:20 <Athas> SML, for example, does not have this property.
08:27:20 <Shockk> right, yes
08:28:20 <Shockk> reason I ask is that I'm making a lang currently, with definable operators, so wanted to know how parsing is done taking that into account
08:28:22 <Shockk> thanks
08:29:44 <Athas> Some languages, like F#, go even further, and define the fixity of an operator based on the first few characters of the operator.
08:29:57 <Athas> For example, any operator starting with '+' has the same behaviour as '+'.
08:30:02 <Shockk> hmm I see
08:30:48 <Athas> That's the approach I've gone with for my own language.  A little more clunky for DSLs, but you can parse without resolving module imports, and I find the code more readable in the end.
08:30:57 <ski> OCaml does the same, iirc
08:31:06 <ski> > [2 + 3 + 4 | let (+) = (-); infixl 5 +]
08:31:08 <lambdabot>  [-5]
08:31:09 <ski> > [2 + 3 + 4 | let (+) = (-); infixr 5 +]
08:31:12 <lambdabot>  [3]
08:31:14 <Athas> Yeah, I think OCaml invented it.
08:31:45 <Shockk> interesting
08:32:46 * hackagebot texmath 0.9.4.1 – Conversion between formats used to represent mathematics. – https://hackage.haskell.org/package/texmath
08:32:55 <Shockk> want to check something
08:32:58 <Shockk> > [2 + 3 - 4 | let (+) = (-); infixr 5 +]
08:33:00 <lambdabot>  [3]
08:33:46 <ski> the usual ones are `infixl 6 +,-'
08:33:48 <Shockk> hm maybe I'm misthinking this but if I try this
08:33:58 <Shockk> > [2 + 3 - 4 | let (+) = (-); infixr 5 +; infixl 5 -]
08:34:00 <lambdabot>  error:
08:34:00 <lambdabot>      The fixity declaration for ‘-’ lacks an accompanying binding
08:34:02 <Athas> I had no idea you could define fixity inside of a list comprehensis, wtf.
08:34:13 <Shockk> okay that didn't work, I'll just ask
08:34:19 <ski> i just realized it myself. neat, huh ? ;)
08:34:35 <Shockk> you can't combine opposing fixities in the same list of operations without brackets, right?
08:34:45 <Shockk> so if + is infixr and - is infixl, you can't do 2 + 3 - 4, right?
08:34:59 <monochrom> fixities are top-level global, not local.
08:35:02 <ski> (i already tried `let (+) = ... in let infixl 5 + in ... + ...'. doesn't work)
08:35:27 <ski> monochrom : sorry, no
08:36:04 <monochrom> Ah, but then you shouldn't use two let's, you should use one let, right?
08:36:09 <ski> right
08:36:27 <ski> i just tried separating the binding from the fixity, to make sure :)
08:37:09 <Shockk> aha got it, cannot mix `>>' [infixl 1] and `=<<' [infixr 1] in the same infix expression
08:37:10 <Shockk> great
08:37:53 <ski> @type let zipWith (+) (a:as) (b:bs) = (a + b) : zipWith (+) as bs where {infixl 5 +}; zipWith _ _ _ = [] in zipWith  -- sadly doesn't work, though
08:37:54 <lambdabot> error:
08:37:54 <lambdabot>     The fixity declaration for ‘+’ lacks an accompanying binding
08:37:54 <lambdabot>       (The fixity declaration must be given where ‘+’ is declared)
08:44:47 * hackagebot di 0.2 – Easy, powerful, structured and typeful logging without monad towers. – https://hackage.haskell.org/package/di
09:06:02 * hackagebot preamble 0.0.40 – Yet another prelude. – https://hackage.haskell.org/package/preamble
09:25:14 * hackagebot shakers 0.0.24 – Shake helpers. – https://hackage.haskell.org/package/shakers
09:34:21 * hackagebot highlight 1.0.0.0 – Command line tool for highlighting parts of files matching a regex. – https://hackage.haskell.org/package/highlight
10:08:20 <tempeh> freinds. i have achieved Data.Fix. i am just excited and wanted to share :)
10:09:49 <srhb> tempeh: Good job!
10:29:57 <johnw> tempeh: well done
10:32:36 <pikajude> is there any difference in performance/codegen between using `go where go = ...` and `fix $ \ go -> ...`
10:32:42 <pikajude> i see the first a lot and very rarely the second
10:32:51 <tempeh> thanks :)
10:32:56 <johnw> pikajude: I'd check Core
10:32:57 <tempeh> best code i've ever written
10:33:15 <johnw> I think I've seen cases when go x y z = ... is different from go = \x y z -> ...
10:33:27 <pikajude> that's weird
10:33:31 <pikajude> what will they think of next
10:33:33 <johnw> it has to do with saturation
10:33:47 <bitemyapp> yep, changes CAF
10:33:53 <pikajude> preposterous
10:34:09 <bitemyapp> I was pretty mad when it suddenly made my program slow.
10:34:16 <bitemyapp> checking heap profile cleared it up in a jiffy
10:34:23 <bitemyapp> talking to Carter regularly also helps to make you aware of things like this
10:34:33 <johnw> the smarter the compiler gets, the more we need analysis to understand the impact of any change
10:34:44 <bitemyapp> he does a lot of stuff that seems superstitious (never use anony lambda syntax, never use point-free) until you bump into something like this.
10:35:00 <carter> bitemyapp: :))
10:35:01 <bitemyapp> then you're annoyed and start doing the same juju
10:35:23 <johnw> I do appreciate it when performance doesn't matter enough to have to care about such things
10:35:24 <carter> It's a core part of how ghc rts and core work
10:36:38 <pikajude> never use point-free???
10:36:45 <pikajude> maybe we should replace the @pl command then
10:36:50 <bitemyapp> well, not never-never
10:37:00 * johnw hugs his point-free syntax
10:37:00 <bitemyapp> like John said, if perf doesn't matter...
10:37:15 <pikajude> it would be funny to replace it with a message: "stop it, you're not helping anyone"
10:37:29 <johnw> pikajude: or: "Heh, golfing are we?"
10:37:57 <pikajude> even better suggestion: translate the code to polish
10:38:00 <pikajude> like the name @pl would suggest
10:38:35 <monochrom> I support that.
10:38:35 <bitemyapp> reminds me of that german shepherd in the UK that seemed to be untrained
10:38:46 <bitemyapp> until the staff at the shelter tried talking to it in polish
10:38:55 <pikajude> debugging "thread blocked indefinitely on STM transaction" exceptions in your own code: 2 hours. debugging it in someone else's library code: priceless.
10:38:56 <bitemyapp> suddenly it started obeying standard commands and seemed very well trained
10:39:20 <monochrom>  @pl \x y z -> x + y - z    --->  \x y z -> (-) ((+) x y) z
10:40:15 <pikajude> oh it didn't happen this time. neato
10:40:16 <monochrom> Fortunately, in Hong Kong, the police etc. train dogs in English too.
10:41:03 <LKoen> bitemyapp: reminds me of first-aid work. one of my collegues had declared someone as "unconscious" because they weren't responsive. it turned out the person was deaf.
10:41:34 <monochrom> Not just police dogs. Dogs who help the blind too.
10:41:39 <bitemyapp> LKoen: I watched a video of this german shepherd, it was pretty funny because humans speaking English basically didn't exist to the dog.
10:41:48 <bitemyapp> LKoen: it wouldn't even make eye-contact until you spoke Polish
10:41:52 <pikajude> man, even police dogs speak more languages than me ):
10:41:57 <monochrom> haha
10:42:14 <bitemyapp> tfw monolingual
10:44:14 <SLi> "#::
10:47:32 <johnw> pikajude: lol
10:47:45 <johnw> pikajude: if you only need a 100 word vocabulary, you could speak a lot more languages too
10:55:34 <pikajude> fair
10:57:20 * hackagebot monad-control 1.0.2.1 – Lift control operations, like exception catching, through monad transformers – https://hackage.haskell.org/package/monad-control
11:04:17 <zomg> I wonder if there's any interest on cryptoexchange related libs in the haskell land
11:04:27 <zomg> because I have four of them roughly implemented to a point where you could do algotrading
11:04:39 <zomg> although I have no idea whether my code is particularly good for haskell code... =)
11:05:14 <zomg> maybe I'll split them out from the main app at some point and put them somewhere for people to tell me how I'm doing things wrong
11:13:32 <SepakoRayl> guys who was it that gave me the  typeable solution?
11:14:48 <orion> What is the current status of the various oauth packages out there? Is there one you'd trust for production systems?
11:15:08 <hsk3> How can I combine     import Data.Text (Text, unpack)       with     import qualified Data.Text as T (null)     ?
11:15:08 <hsk3> I want to use Text and unpack directly, but I want to use null as T.null
11:17:11 <shapr> zomg: I want to play with it!
11:19:31 <lyxia> hsk3: The way you did it looks fine, though you can also remove the import list in the qualified import.
11:36:49 <pikajude> how *do* you debug blocked indefinitely on an STM transaction
11:37:14 <zomg> shapr: cool, I'll be sure to ping you if/when I get around to putting it on github or something :)
11:37:21 <pikajude> is there some way to trace what transactions are going on
11:39:31 <angryMonk> Hey there, how y'all doing.
11:40:28 <angryMonk> I'm trying to run runQ in GHCi but I keep getting parsing error.
11:40:55 <dmj`> angryMonk: can you paste the code?
11:41:01 <angryMonk> Running template haskell successfully in files and I'm wondering what went wrong.
11:41:08 <angryMonk> Sure dmj`
11:41:09 <hsk3> lyxia thanks!
11:41:29 <angryMonk> runQ [| 1+1|]       
11:41:30 <angryMonk>                                                  
11:41:30 <angryMonk> <interactive>:80:7: error: parse error on input ‘
11:41:58 <angryMonk> umm, the error is on input '|'
11:42:15 <SepakoRayl> is there some way to create a modify function that applies a lens to a value if it is compatible with it's type but does nothing otherwise?
11:42:25 <shapr> zomg: thanks
11:42:42 <SepakoRayl> someone posted a solution using Typeable but I can't find it
11:44:49 <lyxia> angryMonk: enable TemplateHaskell
11:44:55 <angryMonk> I did!
11:45:07 <angryMonk> :set -XTemplateHaskell
11:45:14 <lyxia> Well it's the error I get without the extension, and I don't get it with.
11:45:28 <angryMonk> lyxia: huh.
11:45:40 <angryMonk> I'm using stack ghci instead of a global ghci
11:45:46 <angryMonk> could that be the issue?
11:47:50 <lyxia> I don't see what could be wrong with that. (It works for me either way.)
11:48:43 * angryMonk is sad....
11:48:48 <angryMonk> well thanks!
11:48:51 <zennist> up
11:48:54 <johnw> sadMonk
11:49:10 <angryMonk> I'm installing a global ghci (new system.)
11:49:16 <angryMonk> hopefully that will work.
11:49:18 <fryguybob> pikajude: There is -Dm but that might not be useful at all.
11:49:38 <pikajude> oh, good
11:49:47 <pikajude> i'm going to run with -xc first
11:49:47 <angryMonk> \nick sadMonk
11:50:06 <sadMonk> johnw: you're absolutely right.
11:50:11 <johnw> lol
11:52:27 <sadMonk> lyxia: it's working on global ghci.
11:52:49 * sadMonk shrugs at weird error.
11:52:55 <sadMonk> Thanks for the help!
11:55:17 <angryMonk> before someone gets on my case for changing nicks.
12:05:38 <pikajude> dis-grunkled
12:06:12 <bitemyapp> grunking out
12:23:20 <SepakoRayl> How do we use Typeable's Refl ?
12:24:57 <monochrom> Find a function that returns a :~: type.
12:25:30 <monochrom> for example eqT.
12:26:09 <SepakoRayl> thanks
12:28:35 <mnoonan> I wrote a dumb s-expression parser in Parsec, and it came out very slow. profiling shows most time in parsec's 'satisfy', '(>>=)', and 'mplus'. Any ideas about how to proceed?
12:28:38 <mnoonan> the profile: http://lpaste.net/356593
12:29:23 <monochrom> 51 seconds on how big an input file?
12:30:03 <mnoonan> looks like about 6500 lines
12:30:38 <monochrom> About 100 lines per second.
12:30:59 <monochrom> I guess even humans are faster than that :)
12:33:39 <monochrom> I haven't really used parsec on large files, so I don't really know why.
12:33:47 <johnw> mnoonan: you could use parsec-free to gain more insight into what your parser is doing
12:34:29 <mnoonan> johnw: oh, very cool! trying it now..
12:35:17 <johnw> if you need help getting it going, let me know; it should be an exact drop-in replacement
12:35:25 <johnw> and then you need to call a different function to use it
12:35:31 <monochrom> Actually, I indirectly have, but it's also different. I use HXT on 500-line files, and HXT uses parsec. But my files are 1% xml tags and 99% words, so it's quite different from typical s-expression files.
12:36:24 <dolio> Is 6500 lines a big file?
12:36:41 <johnw> what if each line is 4MB long? :)
12:37:24 <monochrom> Right, on composite number days I think I'm a short person, and on prime number days I think I'm tall.
12:37:32 <mnoonan> looks like an average of 40 chars / line, very 80-col friendly :)
12:38:40 <dolio> Anyhow, without showing the parser, I don't think anyone's going to be able to guess based on the profile what's going on.
12:39:26 <johnw> oh, I can guess
12:39:37 <johnw> it's just worthless
12:41:02 <monochrom> OMG so many data constructors in parsec-free's ParsecF
12:41:05 <mnoonan> not a MWE but all the parser is here: http://lpaste.net/356594
12:41:15 <johnw> monochrom: one for every possible operation :)
12:41:42 <johnw> it turns your use of parsec into a value that can be denoted back into a parser, but with analysis
12:41:56 <mnoonan> what, only ~100? pfft.
12:42:04 <monochrom> This is the one single reason why a pointer-tagging paper has to talk about "what if there are 100 constructors?!"
12:43:16 <dolio> This has a lot of 'try' in it.
12:43:43 <mnoonan> true
12:44:48 <mnoonan> actually, now that you mention it.. trying a dotted list before every normal list is pretty crappy
12:44:52 <monochrom> I think p_Nil and p_Hashed deserve try's. But large things like p_List don't.
12:45:06 <inductive> Hello, looking for someone familiar with type theory, equality, and identity types.
12:45:08 <angryMonk> hey can i get an example of dataInstD? I'm guessing it's to declare an instance of a data family but the doc is pretty crappy.
12:45:17 <monochrom> So generally I use try for token-level things and I think it's OK.
12:45:44 <mnoonan> monochrom: basically anything that will fail quickly if it isn't going to succeed?
12:45:51 <monochrom> Yeah.
12:45:57 <mnoonan> that makes sense
12:46:34 <monochrom> You don't really want a Θ(n) try, unless you're really into ambiguous grammars. (But then you would be using ReadP.)
12:46:57 <lyxia> inductive: what's the question
12:47:23 <mnoonan> I bet its the dottedlist/list backtracking, especially since it does that for nested lists..
12:47:26 <monochrom> Although, the "Θ(n)" there is inaccurate. If you have a length-n reserve word, of course you have to use try for it.
12:47:44 <inductive> lyxia: I wanted to ask about the relationship between identity (equality) types and the reflexive rule found on page 102 of the HoTT book.
12:48:41 <dolio> mnoonan: Yeah, I think the guess would be that you're reparsing a lot of stuff.
12:48:48 <monochrom> Hmm this is interesting. What is the sane way to disambiguate dotted lists and spaced lists? Clearly a very high-level try doesn't scale.
12:49:35 <mnoonan> maybe parse it as if . were a valid identifier, then go back after the list is parsed to classify it as List / DottedList / garbage?
12:49:41 <monochrom> Ah s-expression is not as straightforward as I thought. I have always neglected (x . y)
12:49:59 <lyxia> inductive: Someone else might answer you here. Also ask #coq and #hott.
12:50:47 <johnw> mnoonan: have you seen https://github.com/aisamanra/s-cargot?  I'm not sure if you're doing this for educational purposes, or you just need something that works
12:51:02 <dolio> monochrom, mnoonan: Also, even nil is not trivial.
12:51:09 <dolio> It can have a comment inside it.
12:51:21 <angryMink> Could I get a little help with template haskell? I'm a bit new and the doc is horrible.
12:51:32 <monochrom> Like this? '( (* hehehe! *) )
12:51:36 <angryMink> can i get an example of dataInstD? I'm guessing it's to declare an instance of a data family that already exists.
12:51:37 <dolio> So in theory, it could be parsing a lot.
12:51:38 <mnoonan> johnw: it was just hacked out in minimal time, because everybody knows how trivial parsing s-expressions is :)
12:51:42 <dolio> Looks like line comments only.
12:52:06 <monochrom> Oh wait I conflated Pascal with s-expressions.
12:52:46 <johnw> mnoonan: oh, so just like writing an RFC-822 parser, got it
12:53:01 <monochrom> Haha
12:54:25 <mniip> inductive, continue
12:54:48 <mniip> reading about HoTT myself so am interested whether I can answer it or not
12:55:37 <monochrom> angryMink: GHC's flag -ddump-splices is going to be useful when you explore.
12:55:38 <inductive> mniip: I'm mainly asking in the context of dependently typed languages and so on.
12:56:04 <monochrom> add -ddump-to-file if you want it to be in a file rather than stdout.
12:56:39 <angryMink> monochrom: Thanks! Will get to testing.
12:56:40 <johnw> inductive: I think you have everyone sufficiently interested, please ask :)
12:56:47 <inductive> Ok
12:57:07 <inductive> Suppose it was possible to form a type with this signature:
12:57:16 <inductive> (in Haskell or your favorite lang)
12:57:41 <inductive> f : a = b
12:58:17 <inductive> This has at most one inhabitant.
12:58:31 <mniip> well, haskell has that kind of type, yes
12:58:34 <dredozubov> it's quite possible
12:58:55 <dredozubov> there's a type called :~:
12:58:59 <johnw> inductive: there's Data.Type.Equality
12:59:06 <inductive> Well let me put in some added context, because what I am trying to do is not possible without dependent types.
12:59:29 <inductive> This may help:
12:59:34 <dredozubov> data a :~: b where Refl :: a :~: a
12:59:37 <mniip> are you sure? it can probably be solved with singletons
12:59:43 <inductive> http://docs.idris-lang.org/en/latest/tutorial/theorems.html
12:59:58 <inductive> data (=) : a -> b -> Type where Refl : x = x
13:00:15 <inductive> (Yes, I am also asking in #idris)
13:00:31 <dredozubov> you can see the same haskell definition above
13:00:43 <johnw> also, if you say "it has at most one inhabitant", then you're not considering hott?
13:01:21 <johnw> for example, if a and b are points in a toroidal space, then it has two possible inhabitants
13:01:22 <inductive> johnw: Well that's a good question. I would say aren't we half right, as it's a "mere" proposition and not a path.
13:01:35 <johnw> oh, as an hprop?
13:01:38 <inductive> Right
13:01:45 <mniip> johnw, what does a toroidal type look like?
13:01:47 <inductive> And I wanted to ask about that
13:02:07 <johnw> mniip: where points can be equal in two different ways (depending on which route they take around the "hole")
13:02:22 <mniip> right but is there a non-contrived example?
13:02:23 <inductive> He means a trivial loop across the surface of it being contractable.
13:02:45 <dolio> It's just a definition.
13:02:50 <inductive> As related to this idea of a higher identity type being a family (collection) of all the (non-trivial) ways two things are equal.
13:03:22 <johnw> mniip: I've never made use of them, so I have no practical example
13:03:26 <inductive> Here is something more concrete, though: consider a generic hashing function.
13:03:27 <dolio> data Torus where point : Torus ; around : point = point ; through : point = point ; commute : around . through = through . around
13:03:36 <mniip> well, one thing I don't understand about HoTT is what does a path have to do with equality
13:03:49 <mniip> I can understand the definitions
13:03:53 <mniip> but not the motivation
13:04:11 <mnoonan> so would ((T,T), (T,T)) be toroidal?
13:04:35 <inductive> One of the motivations is to capture the notion of isomorphism and relate it to equality.
13:04:47 <inductive> So that one can create representations of types in others in a formal way.
13:05:05 <jcjf> mniipp: as in why do it this way or why this notion?
13:05:08 <johnw> mniip: see https://golem.ph.utexas.edu/category/
13:05:18 <johnw> sorry, I meant https://golem.ph.utexas.edu/category/2015/04/a_synthetic_approach_to_higher.html
13:05:39 <johnw> in that paper, Schulman motivates paths pretty clearly (to me)
13:08:23 <mniip> jcjf, when you say that instead of considering X such that P, we could consider all X; the natural question is when is not P?
13:08:43 <dolio> johnw: The torus has more than two inhabitants of the path space, too.
13:08:56 <johnw> dolio: sure
13:09:14 <dolio> Because you can go around in each loop n times in a given direction.
13:09:32 <dolio> So it's probably like Z * Z.
13:09:33 <johnw> ah, right, round-trips might accumulate computationally relevant results
13:10:00 <johnw> HoTT is still a mind trip for me
13:10:44 <dolio> Or maybe it's even more complicated than that. I'm not totally sure.
13:12:04 <dolio> The circle's path space looks like Z, I know.
13:18:01 <johnw> inductive: was your question ever answered?
13:19:42 <inductive> johnw: Nope, asking in many channels
13:19:58 <inductive> johnw: I admit it is a really advanced question
13:20:24 <johnw> I'm not certain if I've seen the actual question yet
13:21:18 <inductive> johnw: I begin with this quote from HoTT page 102: "As mentioned before, *extensional* type theory include also a 'reflection rule' saying that if p : x = y, then in fact x ≡ y. Thus extensional type theory is so named because it does not admit any purely intensional equality: the reflection rule forces the judgmental equality to coincide with the more extensional identity type."
13:22:15 <inductive> johnw: I then wanted to ask what happens when we omit this rule in a type system that permits types that depend on impure terms.
13:22:45 <inductive> I was originally asking it in the context of Idris' definition of equality.
13:23:06 <mniip> johnw, so, am I getting this right? I could define a type of rationals as a quotient N*N / (\(a, b) (c, d) -> ad=bc)
13:23:23 <mniip> and then =_Q would have multiple inhabitants?
13:25:01 <mniip> hmm, still not
13:25:10 <mniip> only one way to prove it for any (a, b) (c, d)
13:25:57 <mniip> well, if I defined R as quotient of cauchy sequences by the limit=0 equalivalence relation
13:26:03 <dolio> Even if there were multiple ways, you'd have to say what happens when you make a 'quotient' to get an answer.
13:26:13 <johnw> mniip: what you've stated is in section 11.1 of the HoTT book
13:26:23 <mniip> I didn't get that far :v
13:26:26 <johnw> not about multiple inhabitants, but about that formulation of Q
13:26:33 <JScully> hi, sorry for being off topic. does someone know a channel where i can find help prooving that a language is context free :| i have trouble with that
13:26:51 <mniip> johnw, well I knew that formulation from basic calculus?
13:26:58 <johnw> JScully: do you want a formal proof?  #coq might be able to help
13:27:01 <johnw> mniip: :)
13:27:12 <mniip> JScully, ##cs
13:27:21 <johnw> mniip: I was just suggesting that maybe reading ahead in the HoTT book might offer better answers than I can give
13:27:21 <mniip> JScully, you mean with something like a pumping lemma?
13:27:26 <JScully> yes exactly
13:27:32 <JScully> pumping lemma :(
13:27:37 <JScully> thanks for the channels
13:27:38 <mniip> ##cs should help
13:27:42 <dolio> Isn't the pumping lemma for proving something _isn't_ context free?
13:27:51 <dolio> (or regular)
13:27:51 <JScully> yes
13:28:04 <mniip> er, yes
13:28:13 <mniip> to prove context freeness just construct a grammar
13:28:43 <JScully> i can follow the examples online but its always the same example
13:29:00 <JScully> L = { a^n b^n }, my task seems to be more complex though :|
13:29:49 <mniip> is this an undergrad language theory course?
13:30:06 <JScully> it is
13:30:37 <mniip> could be that it's the first course where you have to really come up with a formal proof :p
13:30:38 <mniip> was for me
13:31:02 <JScully> i try to ask at thoses channels
13:31:06 <JScully> thank you!
13:35:37 <katychuang_> does anyone know.. what are the most up to date or feature rich web scraping libraries?
13:49:54 <mniip> johnw, when exactly would we benefit from equalities that aren't mere propositions?
13:50:31 <johnw> mniip: when you want to work with equivalences as your definition of equality
13:50:52 <johnw> in a computationally relevant setting where equivalence means "provide a way to convert my data from one type to another"
13:51:27 <johnw> without rich equalities, this is a separate notion that you have to bolt on externally, requiring much book-keeping and other work (for example, dealing with hierarchies of setoids)
13:56:02 <johnw> and if equivalence is part of the structure of a type, you don't need to constantly prove that every new function you define respects that equivalence, which is what setoids require
13:59:09 <johnw> seem to be some neat examples here: https://ncatlab.org/nlab/show/higher+inductive+type
14:01:57 <dolio> The obvious programming example is transporting between different representations of some abstract type, via isomorphism.
14:02:30 <dolio> And it's not super obvious how to enable that via identities without making multiple paths between some types.
14:03:00 <Tuplanolla> Are there programming systems that implement this, dolio?
14:17:43 * hackagebot VKHS 1.9 – Provides access to Vkontakte social network via public API – https://hackage.haskell.org/package/VKHS
14:18:24 <diegorrfc> oi
14:18:34 <diegorrfc> tem alguém ai que domine haskell? kk
14:20:09 <ski> /join #haskell-fr
14:20:10 <ski> ?
14:21:20 <Tuplanolla> Looks more like Spanish or Portuguese to me, ski.
14:21:34 <ski> oh, ok
14:22:32 * ski was thinking french, because of "que"
14:23:43 <ski> (seems there's a #haskell.es)
14:23:45 <geekosaur> Spanish uses that too... but looks Portuguese to me and ip check confirms .br
14:24:42 <ski> (and a #haskell-br)
14:50:06 * hackagebot fltkhs 0.5.3.2 – FLTK bindings – https://hackage.haskell.org/package/fltkhs
14:58:12 * hackagebot hledger 1.3, hledger-api 1.3, hledger-lib 1.3, hledger-ui 1.3, … and 1 more
14:58:12 * hackagebot  → https://hackage.haskell.org/packages/recent
14:59:09 <felixphew> ok, so if I'm inside a do block in CGIT IO, how do I get a value from an IO Int?
15:00:12 <felixphew> I can't use let (which gives me an IO Int), and I can't use <- (which gives me Couldn't match type ‘IO’ with ‘CGIT IO’)
15:01:19 <srhb> felixphew: Assuming CGIT is a transformer, i <- liftIO theIOInt
15:01:32 <felixphew> it is, so thanks!
15:04:40 <sm> nice, hackagebot
15:15:32 <abhiroop> I am trying to collect the values from a simple record using `Data.Data` http://lpaste.net/356595
15:15:55 <abhiroop> But I am not able to as listed here: http://lpaste.net/356595
15:24:05 <geekosaur> I suspect toConstr is not what you wanted, because it did what its name implies: it got you the outermost constructor (a String being a list of Char)
15:26:04 <abhiroop> Oh I see
15:27:53 <geekosaur> I think it's only the right way to get a primitive value, not something like a list
15:30:13 <abhiroop> yeah thats like a nested constructor
15:36:22 <Shockk> would it be on-topic in #haskell to ask about how some syntax looks, for the lang I'm developing? specifically, I wrote how I'd like the (.) operator to look
15:36:49 <Shockk> I meant to say "would it be off-topic" but it's kind of the same question anyway
15:38:41 <bluebaron> If I call, say, `inc 1`, from two different functions, would that be calculated twice?
15:41:08 <johnw> bluebaron: I believe that usually, yes
15:42:00 <bluebaron> johnw: Alright, that's what I thought
15:42:31 <bluebaron> Trying to implement a very straightforward tf-idf corpus search, didn't want the API to inadvertently replicate efforts
15:43:31 * hackagebot simple-effects 0.9.0.0 – A simple effect system that integrates with MTL – https://hackage.haskell.org/package/simple-effects
15:45:45 <abhiroop> geekosaur: `gmapQ cast (X "abc" "def") :: [Maybe String]` this kind of works
15:58:53 <Shockk> :info (.)
15:58:58 <Shockk> er
15:59:02 <Shockk> @info (.)
15:59:03 <lambdabot> (.)
15:59:07 <Shockk> thanks a lot
15:59:29 <Shockk> is lambdabot extra helpful today?
15:59:50 <ReinH> It's always that helpful.
16:01:17 <pikajude> what does -Dm do
16:04:27 <dfeuer> Anyone know how I can time a Cabal test suite? I don't want to know how long it takes to compile; I only want to know how long it takes to run.
16:04:55 <dfeuer> So just using time cabal test doesn't seem likely to do the trick.
16:07:07 <pikajude> this is so bothersome
16:07:22 <pikajude> I'm getting a blocked indefinitely on STM error because I can't guarantee when performGC is being run
16:08:05 <dfeuer> pikajude: why's that giving you an error?
16:08:13 <pikajude> dfeuer: pipes-concurrency
16:08:17 <geekosaur> Shockk, there is no @info or :info in lambdabot (too much output)
16:08:27 <geekosaur> but it editcorrects to @undo
16:08:33 <pikajude> afaict, the input/output ends of these things are closed after a GC
16:08:37 <pikajude> and i spawned like 4 of them
16:09:06 <pikajude> i'm assuming that the output end of one is closed before the input end, or vice versa
16:09:14 <pikajude> because the error doesn't happen on every run, it's roughly 1/3rd of the time
16:09:19 <colonelj> today my haskell program went "Killed" with no explanation, how can I debug?
16:09:32 <dfeuer> pikajude: I'm not familiar with that package yet.
16:09:41 <pikajude> it's ok it's really simple
16:09:55 <geekosaur> colonelj, try heap profiling; that's usually the kernel out-of-memory killer
16:10:03 <pikajude> you just use `spawn` to produce an input end and an output end, and then you can use other functions to convert those into Consumer or Producer
16:10:55 <colonelj> geekosaur: how does one heap profile
16:11:34 <geekosaur> hm, actually heap profiling won't do it as it would have to complete normally to generae the report iirc
16:12:13 <dfeuer> geekosaur: no it doesn't.
16:12:25 <dfeuer> The heap profiler spews as it goes.
16:12:28 <ALoneNoMad> why is java so much better than haskell
16:12:30 <dfeuer> You can even watch it live.
16:12:52 <colonelj> why is c++ so much better than everything?
16:12:55 <wespiser> ALoneNoMad: in what context?
16:13:09 <dfeuer> ALoneNoMad: are you a troll, or do you have an actual question?
16:13:11 <ALoneNoMad> c++ is faster than c right
16:13:22 <ALoneNoMad> i meant as in portability
16:13:23 <ALoneNoMad> sorry*
16:13:42 <ALoneNoMad> why doesnt haskell also run in every system like java does 
16:13:42 <dfeuer> Portability?
16:13:46 <geekosaur> colonelj, https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html#profiling-memory-usage
16:13:57 <wespiser> ALoneNoMad: Haskell does a lot of things better than Java, like serve as a research platform for functional programming and type theory, and also compile functional programs, but java does some other things better, like is used everywhere
16:14:26 <wespiser> ALoneNoMad: can you give an example?
16:14:34 <dfeuer> Java chose not to offer machine integers, which increases portability at the expense of performance.
16:14:35 <ALoneNoMad> like write once anywhere type 
16:14:37 <geekosaur> because java has a virtual machine that has to be built for each supported platform, then java programs run in that VM. same kind of thing with erlang.
16:14:44 <ALoneNoMad> will hasell ever be like that?
16:14:49 <wespiser> yea, LLVM
16:14:59 <ALoneNoMad> REALLY
16:15:07 <dfeuer> Java doesn't seem to offer particularly good platform integration compared to Haskell.
16:15:10 <geekosaur> Java only runs "everywhere" if you have a JRE for that platform, which is "most platforms you care about but not ALL platforms"
16:15:17 <wespiser> but the advantages of the JVM are almost integrated out of Java at this point
16:15:30 <ALoneNoMad> o thanks i was very misguided then
16:15:47 <ALoneNoMad> can haskell do mobile platform too?
16:15:51 <wespiser> deploying Java and deploying Haskell is just about an equal task
16:16:00 <dfeuer> ALoneNoMad: yes.
16:16:16 <geekosaur> and the JVM has some ridiculous limitations which lead to Scala being the main FP language on the JVM and ML/Haskell not being that easy to implement well on it
16:16:41 <ALoneNoMad> wait so you can write swift with haskell?
16:17:01 <wespiser> no swift is a different lang
16:17:16 <ALoneNoMad> i mean like u know c# can do it with xamrain
16:17:19 <ALoneNoMad> does haskell have that
16:17:22 <dfeuer> Anyone able to help me with the cabal test timing question, or should I go shower?
16:17:39 <wespiser> dfeuer: get out of here while you still can
16:17:48 <ALoneNoMad> ....
16:17:55 <ALoneNoMad> i was misguided b4 from someone
16:18:01 <ALoneNoMad> but u helped clairfy it 
16:18:53 <wespiser> np, you should really be using a third party to check this stuff, that way its more reliable than me, this group, or another person. I usually collect general prog lang info from wikipedia
16:18:57 <colonelj> geekosaur: can I do profiling whilst using stackage?
16:19:09 <geekosaur> stack has options for profiling
16:19:19 <ALoneNoMad> wespiser what langauges do you know
16:19:58 <stevebash> Hi, I'm interfacing with a C lib that has a function that may exist or not depending on the lib version
16:20:02 <stevebash> Say
16:20:06 <stevebash> foreign import ccall "math.h sin32"
16:20:08 <stevebash>   c_sin :: CDouble -> CDouble
16:20:40 <stevebash> sin32 doesn't exist I wrap that in haskell then call it
16:21:04 <stevebash> Calling it gives me a ByteCodeLink: can't find label
16:21:19 <stevebash> Would like to handle that error but doing 'catch' doesn't work
16:21:46 <stevebash> How could I achieve handling that error?
16:34:25 <koserge> is there a way to make Cabal keep the intermediate files of a failed build?
16:34:32 <stevebash> Seems that ByteCodeLink happens at compile time, can't even query the version of the lib in the wrapped haskell function to avoid that error
16:34:49 <stevebash> So cannot do this:
16:34:51 <stevebash> fastsin :: Integer -> Double -> Double
16:34:53 <stevebash> fastsin version x = 
16:34:55 <stevebash>   if version > 9
16:34:57 <stevebash>     then realToFrac (c_sin (realToFrac x))
16:34:59 <stevebash>   else
16:35:01 <stevebash>     error "Not supported"
16:35:03 <stevebash> main = mapM_ (print . fastsin 10) [0/10, 1/10 .. 10/10]
16:35:07 <suzu> don't paste stuff in here
16:35:13 <suzu> please use lpaste in the topic
16:35:20 <stevebash> My bad
16:35:25 <suzu> no worries
16:35:44 <colonelj> how does one go about plugging space leaks??
16:43:40 <colonelj> geekosaur: I don't know how to turn profiling on
16:45:08 <colonelj> nvm I found the option on stack
16:46:51 <colonelj> hmph downloading all the packages again, presumably debug versions
17:02:40 <ReinH> @google haskell space invariants
17:02:42 <lambdabot> http://apfelmus.nfshost.com/blog/2013/08/21-space-invariants.html
17:02:42 <lambdabot> Title: apfelmus - Reasoning about space leaks with space invariants
17:02:51 <ReinH> colonelj: ^
17:03:40 <colonelj> ReinH: seems a bit theoretical
17:04:03 <ReinH> What?
17:04:53 <ReinH> Plugging space leaks requires either understanding space leaks or trying a bunch of stuff at random and getting lucky.
17:05:07 <ReinH> If understanding space leaks is "a bit theoretical" then ok, good luck.
17:05:09 <colonelj> oh god this is so horrible
17:05:28 <colonelj> I can't even do anything yet, it's still building package
17:06:28 * hackagebot llvm-pretty 0.7.1.1 – A pretty printing library inspired by the llvm binding. – https://hackage.haskell.org/package/llvm-pretty
17:06:44 <colonelj> I tried to force the program to reduce to strong normal form earlier but I couldn't even get that to work
17:06:54 <colonelj> (using the deepseq library)
17:08:11 <slack1256> Does each capability get an independent allocation area or is shared?
17:08:12 <colonelj> anyway I still think this article is theoretical having read 1/3 of it
17:08:18 <ReinH> deepseq is almost never what you want
17:08:33 <ReinH> which is, again, why I recommend having a good mental model for space usage in Haskell rather than trying stuff at random.
17:08:44 <ReinH> which is what that "a bit theoretical" blog post provides
17:09:00 <colonelj> the blog post doesn't tell me anything practical about how to identify and squash space leaks
17:09:08 <ReinH> Yes it does.
17:10:21 <colonelj> how do I know what's evaluated and what isn't?
17:10:59 <ReinH> By reasoning about evaluation.
17:11:26 <ReinH> heap profiling can also help, but heap profiling won't tell you how to fix it.
17:11:34 <colonelj> well that's useless then isn't it
17:11:41 <ReinH> No, it isn't.
17:11:48 <monochrom> In fact I don't even think profiling is all that informative.
17:11:51 <ReinH> I guess you can lead a horse to water and all that.
17:12:23 <colonelj> I want to know what is taking up all the damned space and why
17:12:41 <monochrom> I mean it contains the necessary information but it's scrambled and buried and few people actually know how to analyze it.
17:12:53 <slack1256> colonelj: I joined latter, could you show me the code or post?
17:13:12 <colonelj> no it's company intellectual property
17:13:40 <colonelj> I'm just looking for general advice really
17:13:48 <schell> did ircebrowse.net lose its search function? or am i remembering incorrectly?
17:13:55 <ReinH> It seems to me that you're looking for a magic bullet.
17:14:26 <colonelj> no I'm looking for debug tools
17:14:39 <slack1256> Mmm I got two general advices for space leaks. One for avoiding them at design stage and other for noticing where they are once you have written your code
17:14:44 <monochrom> Case in point today: Someone had a slow parser and showed the profiling report and even tl;dr'ed for us "it says most of the time is spent on satisfy, >>=, and mplus". Eventually it was utterly useless. We looked at the code and dolio pointed out "you have a lot of try's".
17:15:23 <ReinH> Debug tools won't tell you why you have a space leak. For that, you must think.
17:15:58 <colonelj> is the runtime so obfuscated that it's impossible to tell where space leaks are using tools?
17:16:14 <ReinH> Where isn't the same thing as why.
17:16:15 <monochrom> No, you are totally not looking for general advice, regardless of what you claim. Because you have already been given patently general advice. Clearly this doesn't solve anything.
17:16:31 <monochrom> I say that you are looking for free solutions.
17:16:39 <ReinH> apfelmus's blog post is the best general advice I've found on finding and fixing space leaks.
17:17:06 <ReinH> It is not a magic tool that will find them for you, and since no such tool exists, you will be disappointed no matter what advice we offer.
17:17:18 <monochrom> Because if you offered a bounty of 10 bitcoins say, pretty sure someone here could let you use them as wetware debugging tools. But you aren't going to do that, are you?
17:18:01 <monochrom> Lazy evaluation is obfuscated. FSVO obfuscated.
17:19:02 <colonelj> btw does anyone know how to actually profile my app now I've compiled it with --library-profiling?
17:19:14 <ReinH> The GHC manual knows.
17:19:35 <colonelj> I'm using Stackage
17:19:43 <ReinH> I don't see how that's relevant.
17:19:53 <colonelj> --library-profiling was a stack option
17:19:55 <ReinH> You're still compiling with GHC.
17:20:29 <monochrom> The problem with leaky abstractions.
17:22:20 <ReinH> The options for profiling are GHC options. Alll stack does is pass them through when you pass them to stack properly.
17:22:38 <colonelj> I think the thing I was missing was +RTS
17:22:50 <ReinH> Which is a GHC option.
17:23:14 <slack1256> what does the +RTS -N2 -A64M -n2M -RTS offer us that +RTS -N2 -A64M -RTS doesn't ?
17:23:57 <monochrom> Enormous overhead due to 2 million threads for much ado about nothing? :)
17:24:18 <monochrom> (And they are OS threads, mind you.)
17:24:46 <MarcelineVQ> monochrom: -n
17:24:48 <ReinH> monochrom: -n is the same as -N?
17:24:51 <slack1256> monochrom: that was to me or colonel ?
17:24:56 <monochrom> Oh oops, nevermind, I don't know.
17:24:58 <slack1256> no.
17:25:10 <monochrom> For you but I was wrong.
17:25:14 <colonelj> performance seems to have decreased substantially when compiling with profiling...
17:25:16 <slack1256> oh, no problem
17:25:52 <ReinH> I don't know of any -n option.
17:26:02 <MarcelineVQ> -n<size> Allocation area chunk size (0 = disabled, default: 0)
17:26:30 <ReinH> I thought allocation was -m
17:27:03 <colonelj> my memory usage looks like a big RIGHT ANGLED TRIANGLE
17:27:03 <MarcelineVQ> -m is minimum heap size
17:27:04 <ReinH> Oh, -m is % of heap devoted to allocation
17:27:12 <dmj`> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html#rts-flag--n
17:27:20 <slack1256> marlow says "-A64M -n2M will chunk the allocation area from 64M to 2M chunks, this helps with parallelism as now HEC get another chunk instead of triggering GC"
17:27:41 <colonelj> what does PINNED mean??
17:27:44 <ReinH> Ah. Seems good.
17:27:45 <monochrom> I think the user guide explains one benefit (but only when -N2 or greater).
17:28:15 <slack1256> yet I don't understand, the allocation area is per HEC. Surely, divinding such allocation area in chunk doesn't matter if the HEC will still reach the GC at 64M"
17:28:40 <ReinH> @google haskell profiling pinned
17:28:41 <lambdabot> https://stackoverflow.com/questions/20478805/what-does-pinned-mean-in-hc-profile-of-haskell-program
17:28:58 <monochrom> pinned is for example what bytestring uses.
17:29:22 <monochrom> GC doesn't relocate pinned blocks.
17:30:05 <colonelj> well it's just that 97%+ of the memory seems to be in the PINNED category
17:30:53 <colonelj> PINNED goes up and everything else stays where it is
17:31:31 <colonelj> so how can I get anywhere near useful info?
17:31:51 <ReinH> I already said that heap profiling won't tell you why you have a space leak.
17:32:06 <ReinH> At some point you are going to have to think about how your code works.
17:33:02 <colonelj> it's all monads and maps and stuff
17:36:38 <ReinH> Here is another excellent post on space leaks that you will probably not like because it advocates thinking about your problem rather than using a magic tool to fix it for you. http://blog.ezyang.com/2011/06/pinpointing-space-leaks-in-big-programs/
17:36:51 <colonelj> for some benchmark numbers then... 500 simulations each having 3 prices for 51 years, each a double, that's 500 * 3 * 51 * 8 = 612K
17:37:01 <colonelj> the returns is another ~600K
17:37:21 <colonelj> then there's the end analysis which is tiny amounts of data
17:37:26 <colonelj> why's it taking up 1GB memory
17:37:39 <ReinH> That's the question you need to answer.
17:38:05 <ReinH> You won't show us your code, so we couldn't find it for you even if we wanted to.
17:38:23 <monochrom> Your description is ambiguous. I know how to code it up using 2MB and how to code it up using 2GB. Your description is informationless.
17:39:01 <monochrom> Oh I guess it contains 1 bit of information. You're using the 2GB way.
17:39:26 <monochrom> And to think that you've just typed up 100 bytes to convey 1 bit.
17:39:51 <colonelj> I don't know what you're talking about but it isn't very helpful
17:40:13 <lambdamu_> colonelj: I think people had success with this method: https://neilmitchell.blogspot.de/2015/09/detecting-space-leaks.html
17:40:30 <ReinH> Well, when I tried to help you you called my help "useless", so I'm not super motivated to keep trying.
17:40:33 <ReinH> But I have been anyway.
17:42:38 <Shockk> quick question, my brain isn't working
17:42:51 <Shockk> what fixity does -> have?
17:43:44 <MarcelineVQ> you can ask ghci, it's infixr 0
17:43:46 <monochrom> It is the -> in types, right?
17:43:59 <Shockk> monochrom: yep
17:44:02 <Shockk> MarcelineVQ: ah right, thanks
17:44:08 <Shockk> I don't have easy access to ghci currently
17:44:34 <Shockk> instead i asked 1553 ghcis in her
17:44:35 <Shockk> here*
17:44:36 <monochrom> I just asked ghci :info -> and it says parse error
17:44:43 <slack1256> maybe lambdabot can be asked such questions
17:44:47 <Shockk> has to be in brackets doesn't it?
17:44:49 <slack1256> > :info (->)
17:44:51 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
17:44:58 <slack1256> @info (->)
17:44:58 <lambdabot> <unknown>.hs:1:2:Parse error: ->
17:45:01 <monochrom> Ah damn
17:45:05 <MarcelineVQ> :info (->) would work, interestingly other operators don't need parens
17:45:17 <monochrom> Yeah, that's why I didn't try (->)
17:45:20 <Shockk> I thought they did, interesting
17:45:31 <MarcelineVQ> for info they don't, for :t they do
17:45:38 <Shockk> hm weird
17:45:40 <monochrom> Try this some time: :info + - * /  
17:45:44 <colonelj> lambdamu_: I'm trying this method but it doesn't sound very reliable
17:46:01 <Shockk> does it work for other two-character operators?
17:46:02 <duckqlz> exit
17:46:03 <monochrom>  :type wants absolutely an expression so you have to say (+)
17:46:12 <monochrom> But :info just wants a name.
17:46:13 <Shockk> like >> for instance
17:47:09 <lambdamu_> colonelj: It is not, space leaks or bugs in general can be arbitrarily hard to explain and fix in my experience
17:47:17 <geekosaur> there is no @info / :info in lambdabot (again)
17:47:24 <geekosaur> @info edit-corrects to @undo
17:47:25 <lambdabot> <unknown>.hs:1:23:Parse error in expression: to@undo
17:47:42 <monochrom> @info ReaderT () IO Int
17:47:42 <lambdabot> ReaderT () IO Int
17:47:45 <colonelj> lambdamu_: how do you know the space has anything to do with the stack???
17:47:53 <monochrom> oops
17:48:02 <Shockk> geekosaur: it wasn't me this time D: I saw your ping earlier
17:48:04 <monochrom> @info do { x<-y; return x }
17:48:04 <lambdabot> y >>= \ x -> return x
17:48:18 <Lokathor> ReaderT () IO Int, what a... strange type
17:48:30 <lambdamu_> colonelj: You don't, quote from the blog post: "Our approach is based around the observation that most space leaks result in an excess use of stack."
17:49:05 <colonelj> well maybe it's related
17:49:35 <colonelj> the stack overflow seems to happen in Data.Vector.Fusion.Util.>>= if that means anything to anyone
17:52:12 <colonelj> what's confusing is I'm using the same function DataAnalysis.expect to do the previous calculation and it uses the same values
17:53:52 <lambdamu_> colonelj: Relaying information like that is far to incomplete/ineffienct for anyone to have an idea how to fix your specific problem, even if they wanted to
17:54:21 <colonelj> well because of laziness I can't say what's evaluated and what isn't
17:54:42 <colonelj> all this function is supposed to do is take a whole bunch of 3x3 matrixes and find the average
17:54:45 <colonelj> that's all
17:54:46 <lambdamu_> colonelj: We can even less, given that we don't know the code
17:55:08 <colonelj> I've put it down to 100 3x3 matrices now
17:55:41 <colonelj> but the calculation for those matrices is difficult
17:55:59 <lambdamu_> colonelj: Not trying to be rude, but if you are not willing to show code you have to be content with general advice and references
17:57:18 <colonelj> well the link you gave "Attempt to fix the space leak, confirm by rerunning with -K32K."
17:57:29 <colonelj> essentially: fix it
17:58:06 <lambdamu_> colonelj: Yes it helps you pinpoint the location, it doesn't explain it to or fix it for you
17:58:07 <colonelj> and I have no clue where the leak is, it's somewhere before the point it says
17:58:26 <colonelj> is there some way I can bound where it is?
18:01:14 <lambdamu_> Only by reasoning, a space leak is excess use of memory that could be avoided, so the only requirement for being the source of a space leak is that some allocation happens, which is basically anywhere in the program
18:03:03 <lambdamu_> Actually that is to simple, what a space leak is and what the source of a particular example is, is often debatable
18:03:56 <colonelj> is it worth throwing ! on things like $! and bangpatterns??
18:04:52 <lambdamu_> colonelj: I know profesisonal haskell programmers who make the data structures strict by default
18:05:11 <colonelj> but it's only WHNF though :(
18:05:33 <colonelj> it's easy to get to WHNF for list processing
18:05:57 <lambdamu_> Yes there is NFData for deeply forcing data types if that's what you want
18:07:14 <colonelj> I said earlier that I tried that and it didn't seem to do what it said on the tin
18:07:47 <colonelj> I don't think my NFData instances were wrong I just forced the tuple of stuff inside
18:08:39 <monochrom> Time for http://www.vex.net/~trebla/humour/tautologies.html #4
18:09:10 <lambdamu_> colonelj: Did you write them by hand or did you use generics?
18:10:01 <colonelj> generics didn't work
18:10:54 <lambdamu_> why?
18:11:14 <colonelj> can't derive instances for fancy GADTs with contexts in their constructors
18:15:04 <lambdamu_> colonelj: Well that sucks, there might be a way around that, but again without code I can't say definitely, also I can't tell you if your NFData instances are correct, I can tell you that NFData works mostly likely as advertised provided your instances are correct
18:15:13 <mniip> man... infty-groupoids are cool
18:16:47 <lambdamu_> colonelj: Anyway randomly strictifying your program could work, and alternative would be to rip stuff out of your program until the leak disapears then look at the previous version and try to reason from there
18:17:05 <lambdamu_> mniip: Why?
18:17:34 <colonelj> lambdamu_: I'm trying to rip stuff out but it doesn't seem to be having much effect
18:18:01 <lambdamu_> colonelj: Be happy about it, the more you can rip out, the less you have to reason about
18:22:34 <colonelj> lambdamu_: I can change a foldl1 to a head or last and it doesn't overflow the stack...
18:22:51 <mniip> lambdamu_, they happen to work as the foundational structure of most of math
18:22:58 <mniip> as opposed to say, sets
18:23:00 <colonelj> oh there's a foldl1'
18:23:10 <colonelj> I can't remember the difference between these folds
18:23:17 <lambdamu_> colonelj: Yeah foldl is notoriously plagued by space leaks
18:23:23 <colonelj> foldl1' doesn't crash out the stack
18:23:28 <mniip> colonelj, foldr is the lazy one
18:23:34 <mniip> foldl is the other direction
18:23:42 <mniip> foldr1/foldl1 need at least one element
18:24:18 <colonelj> p.s. I'm using the Data.Vector foldl1' 
18:24:49 <colonelj> I think I'll revert the code with this one change and see how the heap usage has changed
18:25:33 <lambdamu_> mniip: What do you mean by they work as opposed to sets?
18:25:49 <mniip> lots of things in mathematics can't be sets
18:25:55 <lambdamu_> mniip: Did someone find a flaw in ZFC?
18:25:58 <mniip> yet are still worth studying
18:26:13 <mniip> no, ZFC is still consistent
18:26:28 <mniip> but, uh, what was it called
18:26:34 <lambdamu_> mniip: Actually I don't think anyone knows that or can know that provided it is
18:27:13 <lambdamu_> mniip: And groupoids can be defined in terms of sets, I suppose infinity groupoids, too
18:27:31 <mniip> no - well
18:27:46 <mniip> there can be groupoids that are too large for sets
18:28:00 <mniip> it's more of a proper class thingy
18:29:46 <colonelj> is debugging why the code is slow easier than space leaks?
18:30:33 <lambdamu_> mniip: I don't think that this is a feature specific of groupoids, you can have set theories that exceed what can be defined in ZFC, too, for example grothendieck universes
18:30:57 <mniip> right
18:32:28 <colonelj> well I'm still getting a lovely big triangle going up to 1G
18:32:48 <lambdamu_> colonelj: That can't be answered in the general
18:35:04 <colonelj> I'll try repeating the method to find the next inefficiency on the stack
18:36:19 <colonelj> the problem seems to have moved to Internal.Algorithms.add
18:40:17 <monochrom> mniip: What is nifty-groupoids?
18:40:24 <mniip> infty
18:40:30 <monochrom> oops
18:40:34 <mniip> heh
18:40:47 <monochrom> OK! I propose to rename them to nifty. That would be nifty!
18:40:59 <mniip> well that would definitely make them nifty
18:41:15 <monochrom> But I guess "infinity groupoid" is more informative.
18:41:30 <mniip> \infty-groupoid is how it's typeset
18:42:15 <mniip> monochrom, it's a groupoid equipped with an additional structure that lets you reason about equality of two elements
18:42:34 <mniip> that equality operation induces an \inftry-groupoid
18:43:00 <mniip> that, once again, is a groupoid with a deeper equality and a yet deeper \infty-groupoid
18:43:53 <mniip> hence the name \infty-groupoid. It's an infinite tower of "homotopy" equality groupoids
18:44:10 <monochrom> On that note, I've recently conceived a better way to say "it's turtles all the way down"
18:44:20 <monochrom> It's lasagna all the way down!
18:44:25 <mniip> \infty-lasagna
18:51:49 <dolio> monochrom: Well, the earlier profile did tell something. The bottleneck was raw parsing, and not something else.
18:52:07 <dolio> Then there are about 3 possibilities.
18:52:21 <dolio> 1) Parsec is fundamentally very slow (bad guess)
18:52:58 <dolio> 2) The parsing is inheriting costs building the string (or something) that we can't see (also not very good).
18:53:10 <dolio> 3) The grammar is bad.
18:53:30 <dolio> But profiling can't tell you how the grammar is bad.
18:55:38 <monochrom> Ah OK.
19:00:07 <colonelj> lambdamu: yeah, this method doesn't seem to be working for me
19:01:08 <colonelj> oh wait I changed the wrong fn
19:08:38 <dolio> Reading the backlog, the "PINNED" stuff makes me skeptical that the stack overflow thing will work.
19:09:12 <dolio> It might, I suppose.
19:11:06 <dolio> But I tend to think that technique works to find space leaks where lazy evaluation is causing delays in evaluating something simple, and the stack overflow happens when you go to evaluate that thing.
19:11:22 <dolio> Whereas PINNED means you're retaining references to a lot of data.
19:11:39 <dolio> Not thunks.
19:12:39 * hackagebot solr 0.4.3 – A minimal Solr client library – https://hackage.haskell.org/package/solr
19:12:39 * hackagebot highlight 1.0.0.1 – Command line tool for highlighting parts of files matching a regex. – https://hackage.haskell.org/package/highlight
19:14:24 <lambdamu> dolio: The thunks can contain references that could otherwise be collected, no? Those references could be e.g. to ByteStrings hence the PINNED
19:14:44 <dolio> They could.
19:15:37 <colonelj> I nobbled my addition function so it just takes the seocond element and that seems to make most of the memory usage go away
19:16:43 <colonelj> and the PINNED is then just a narrow strip
19:17:13 <dolio> Maybe I'm wrong, then.
19:17:30 <colonelj> idk how to interpret this really
19:17:32 <dolio> Are you adding up a bunch of numbers that you got by reading them out of byte strings?
19:18:47 <colonelj> not byte strings, Storable vectors
19:19:05 <dolio> Okay, Storable vectors also use pinned memory.
19:22:13 <lambdamu> On fold like operations over data structures the accumulator should basically always be strict
19:22:48 <colonelj> is that the foldl' style ones?
19:22:57 <mniip> hmm, is it the case in HoTT that |A -> B| -> |A| -> |B|
19:23:09 <colonelj> oh you mean the accumulator argument
19:23:23 <colonelj> how could it possibly not be strict?
19:23:49 <mniip> lambdamu, unless you want to be lazy
19:24:27 <lambdamu> colonelj: Well yes that is why foldl' exists
19:24:43 <lambdamu> colonelj: It is strict in the accumulator unless foldl
19:25:15 <lambdamu> colonelj: It is actually the simplest case of space leak, here is a good explanation of it: https://hackhands.com/lazy-evaluation-works-haskell/
19:25:54 <lambdamu> mniip: That's kind of tautological, isn't it? You want to be strict unless you want to be lazy
19:27:25 <mniip> lambdamu, non-strict* ;)
19:27:42 <colonelj> does anyone know how I interpret DataAnalysis.calcReturns.\.\ in the stack trace
19:29:59 <geekosaur> \ is an anonymous function/lambda
19:30:39 <colonelj> is it referring to the only lambda within a lambda I have in that function
19:30:56 <colonelj> it's not really terribly surprising that it'd be at the top of the stack
19:34:36 <EvanR> mniip: yes, thats basically the classical modus ponens
19:34:56 <mniip> which is obviously false
19:35:04 <EvanR> huh
19:35:49 <mniip> under axiom of univalence (2 = 2) = 2
19:36:07 <EvanR> looks like a type error
19:37:17 <mniip> (2 =_U 2) =_U 2
19:37:26 <mniip> where 2:U is 1+1 or some such
19:39:15 <EvanR> is that the same U
19:39:18 <EvanR> not sure
19:39:41 <EvanR> i mean, is the first one in U
19:39:44 <EvanR> or U1
19:40:05 <EvanR> there is a channel for hott
19:41:36 <EvanR> ##hott
19:41:50 <mniip> beat you to it
19:42:56 <nshepperd_> So when are you neither strict nor lazy
19:43:28 <mniip> nshepperd_, you can be strict *and* lazy
19:43:31 <nshepperd_> I guess if you evaluate your argument on another thread
19:43:48 <mniip> think e.g ahead of time evaluation as done by the strictness analyzer or ghc's sparks
19:44:37 <mniip> sourcewise your function is non-strict but in practice it is because ghc finds it cheaper and mathematically equivalent
19:45:33 <AndChat-556404> Should I use iorefs to represent memory in a brainfuck interpreter?
19:46:03 <mniip> that depends
19:46:49 <AndChat-556404> Should I use a state monad?
19:47:03 <mniip> do you plan to execute brainfuck in a pure environment? do you seek speed? are you ready to get into IO-infested code?
19:47:48 <mniip> do you plan to make your tape infinite? in how many directions?
19:48:38 <AndChat-556404> I tried to construct an infinite tape using mapM and newIoref but that didn't work
19:49:08 <AndChat-556404> How would I do it an a pure environment?
19:49:19 <nshepperd_> You'll need an infinitely big computer to do that
19:49:33 <AndChat-556404> Yeah lol
19:49:49 <nshepperd_> Make a type for the interpreter state
19:50:49 <nshepperd_> And a function that executes one instruction and returns the new state
19:50:56 <AndChat-556404> Oh ok
19:51:14 <AndChat-556404> And have memory built into the datatype
19:51:33 <AndChat-556404> As a list of something
19:52:38 <lambdamu> AndChat-556404: With a list you have linear reads and writes, I would go for an IntMap
19:53:10 <AndChat-556404> Oh ok I look into that
19:53:10 <EvanR> a total intmap
19:53:28 <nshepperd_> An intmap or something similar seems like the way to go yeah
19:54:54 <lambdamu> AndChat-556404: That's at least log n, if you want to deploy you brainfuck interpreter (hah), a mutable vector would probably be in order
19:55:03 <nshepperd_> Start with it empty i guess and extend as needed
19:55:51 <AndChat-556404> That's the plan
20:01:41 <colonelj> well I'm still clueless as to what's getting space leaked after all this time
20:02:59 <nshepperd_> Actually, since bf data pointer can only move one step at a time you could use a zipper made of two infinite lists, that would also work
21:10:34 <Lokathor> alright folks, https://lokathor.gitbooks.io/using-haskell/content/roguelike/week-2-graphics-and-dungeon-basics.html
21:10:55 <Lokathor> Wrote a tutorial thing, this stage is only halfway done, but feel free to fact check
21:11:55 <wespiser> Lokathor: cool, i'll take a look right now
21:17:21 <wespiser> Lokathor: use the name "fmap" for <$>
21:17:57 <wespiser> or look up to make sure of what its called, or give the type. I've found it best to walk people through things w/ the types.
21:19:08 <wespiser> Also, i would drop template haskell as a dependency if you could
21:19:34 <Lokathor> to quote a hot new comedy show, "hard no"
21:19:49 <Lokathor> packing the whole program into one file that doesn't depend on other files is too good to give up
21:20:22 <Lokathor> the <$> == fmap thing does get menioned in the indepth section
21:21:19 <wespiser> okay
21:21:50 <wespiser> dude, just be super light with template Haskell, it will make your project compile in hours if you use it all over the place
21:22:02 <wespiser> but that makes sense
21:22:51 <Lokathor> I don't intend to use it other than file-embed
21:23:31 <wespiser> yea, that's a neat trick
21:23:45 <Lokathor> if this were some other tutorial, i could imagine showing off inline-c, but since this is somewhat angled at showing python/javacript folks that Haskell is the bee's knees, using inline-c seems unlikely
21:27:02 <wespiser> nice, i have my own tutorial along the same lines, https://wespiser.com/writings/wyas/home.html
21:29:31 <Lokathor> neato
21:29:58 <Lokathor> the roguelikedev reddit is doing roguelike tutorial go-throughs as a summer group project sort of thing
21:30:00 <Lokathor> so i'm That Guy
21:31:43 <Lokathor> though, once this project is done, I think I might diverge to elixir for a little bit
21:32:14 <wespiser> yea, i'm all over the place with projects
21:32:37 <wespiser> the write you a scheme version 2 i showed you, i'm just finishing the last 2 chapters, 6 months after starting
21:33:00 <wespiser> i'm working on a project using Haskell for web programming next
21:34:30 <xormor> Lokathor, do you support omega-rpg?
21:34:49 <Lokathor> xormor, i've never heard of that
21:35:15 <xormor> Lokathor, it is roguelike. I have a bugfix for it: "dataprint()" needs to be added to the code after "hp=maxhp".
21:35:19 <xormor> Lokathor, ok.
21:35:42 <Lokathor> xormor, oh, well, seems to be written in C, so I don't really support it :P
21:36:15 <xormor> Lokathor, ok.
22:22:39 * hackagebot chart-unit 0.3.2 – A set of native haskell charts. – https://hackage.haskell.org/package/chart-unit
22:45:13 <codygman> is there a way I can use Pipes.Text.Prelude.readFileLn to read over every line? I feel like maybe I can use for to accomplish this
22:53:13 <pikajude> for "thread blocked indefinitely in an STM transaction" can I actually have it print out the ThreadId involved
22:53:16 <pikajude> that would be really handy
23:04:41 <ADG> how to do -> Data.Map.IntMap.fromListWith (:) [...list of (a,b)...]
23:06:39 <cocreature> codygman: “read” as in the "read" function?
23:06:58 <kadoban> ADG: Use  fromListWith (++) . map (fmap (:[])) $ [...list of (a, b)]
23:07:30 <ADG> well is (++) effective?
23:08:37 <kadoban> ADG: I don't understand the question
23:08:49 <cocreature> do you mean "efficient"?
23:08:52 <ADG> isn't ++ sloweer than (:)
23:09:28 <kadoban> Well, since (:) doesn't work here, I'm not sure slower applies. It's infinitely faster than something that won't compile.
23:10:38 <kadoban> There's likely a possible thing that's more efficient, though that's what I'd start with.
23:11:44 <cocreature> you probably end up with "[x] ++ ([y] ++ …)" and that’s really not that much slower than (:)
23:12:10 <pikajude> kadoban: or infinitely slower
23:12:28 <kadoban> pikajude: Yeah, could go either way I suppose.
23:12:40 <cocreature> maybe flip (++). the docs don’t seem to explain which argument is the existing value
23:12:47 <cocreature> you want that to be the right argument
23:17:33 <codygman> cocreature: Nah, I'm trying to do modify lines of a text file using pipes-text and a function from Text -> Text and having trouble.
23:19:08 <cocreature> codygman: readFileLn >-> Pipes.map yourFunction
23:22:20 * hackagebot unmed2 0.0 – Extract useful information from Amiga MED files – https://hackage.haskell.org/package/unmed2
23:42:39 * hackagebot path 0.6.1 – Support for well-typed paths – https://hackage.haskell.org/package/path
23:43:31 <sternmull> I fail to write a data definition that "reuses" the constraint of a class: http://lpaste.net/356597 I would be thankful if someone could give me a hint on how to solve this.
23:44:58 <cocreature> sternmull: putting constraints on data definitions doesn’t really work. instead you should put the constraints on the functions that actually make use of the constraint
23:46:36 <sternmull> i had the vague hope that i could use GADTs to put the constraint on the data constructor
23:47:25 <cocreature> sternmull: are you familiar with ExistentialQuantification?
23:47:44 <sternmull> slightly
23:47:52 <cocreature> GADTs are just a different syntax for that
23:48:40 <c_wraith> It's still usually better to put the constraint on the functions, even compared to using existentials
23:48:56 <cocreature> sternmull: but let’s step back for a moment, why do you want to put the constraint on the type in the first place instead of putting it on the things that actually use the constraint?
23:49:26 <sternmull> that sounds plausible. I want to say "s in my data definition can be any s that is valid for UTF8Bytes b s"
23:49:50 <cocreature> but it’s sufficient to say that on the functions that actually use this fact
23:49:57 <cocreature> otherwise you are just unnecessarily restricting your type
23:50:38 <sternmull> that is true. But it would be ok for me.
23:52:15 <codygman> cocreature: Oh.... that was... stupidly simple. I thought I'd need to use pipes-group and Text.fromHandle but found that fromHandle combined with over Text.lines did not do what I thought because the producer made by fromHandle is bounded by the buffer size allocation. Thanks!
23:52:53 <sternmull> cocreature: I can't really tell why i tried to have that constraint. Maybe i find out again in the next minutes.
23:53:59 <cocreature> codygman: pipes-group is for when you want to do grouping but still stream _within_ a group. if your function take the whole line as the input you can’t stream within a line anyway so there is no reason to go through the trouble of figuring out pipes-group (which tbh can be quite confusing)
23:54:58 <codygman> cocreature: Yeah, I had a feeling I was over-complicating things somehow. Though I have the nagging suspicion pipes-group could simplify some problem escaping my mind atm.
23:57:12 <cocreature> codygman: let’s say that you want to count the number of characters in each line. that’s obviously still possible in a streaming fashion. however without pipes-group you can’t run in constant memory since each line will be kept in memory and lines can be arbitrarely long. pipes-group allows you to group things at line boundaries and count the characters in each substream while still only ever having a
23:57:13 <cocreature> constant amount of text in memory
23:57:16 <penguin359> Hello
23:58:10 <codygman> cocreature: Actually I could use pipes-group to do my fixed width to delimited function I think. I'd need to somehow create a producer with chunksOf, feed it some indexes, and then accumulate I think.
23:59:21 <sternmull> cocreature: When i define the mempty i want to set all counters to zero. I can't do that without telling that they are actually Num. I think that was the reason i tried to pull the constraint from the class into the data definition.
23:59:29 <penguin359> Working on my first useful Haskell program after going through a couple language tutorials.
23:59:48 <cocreature> sternmull: but what do you gain by not putting the constraint on the class?
