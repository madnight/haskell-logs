00:00:50 <Atomic_e_knq> sup
00:01:37 <jared-w> sup
00:24:50 <jared-w> oh man
00:25:20 <jared-w> after like 1.5 hours I finally realize that the ZipList and List applicative instances in the Haskell Book are the same data structure, just representing both methods of writing an applicative instance for a List...
00:25:32 <jared-w> Clearly, I am too tired to be doing this :p
00:32:10 <quchen> jared-w: Not clear enough to find out immediately, not unclear enough to ask here? ;-)
00:33:16 <jared-w> pretty much lol
00:33:29 <jared-w> the quick check was working, but the practical examples weren't
00:33:57 <jared-w> then I realized I wrote something wrong for the ZipList pure function, then I went down the rabbit hole of fixing small errors here and there and trying to get everything working
00:34:29 <jared-w> Finally... the typeclassopedia made the last tiny piece fall into place
00:35:39 <jared-w> One thing that still bugs me is that the haskell book defines a monoid instance using applicative functions and I'm not really sure how kosher that is
00:36:57 <kadoban> jared-w: For the monoid instance of what? Though I'm not sure I see what's wrong with that necessarily.
00:37:14 <quchen> If it’s law-abiding then it’s fine.
00:37:44 <jared-w> The ZipList representation of a List
00:38:08 <jared-w> instance Monoid a => Monoid (ZipList a) where; mempty = pure mempty; mappend = liftA2 mappend
00:38:56 <jared-w> I mean, it's law abiding, it just feels like cheating to me. Although that's probably influenced by the fact that the book covers semigroups, then monoids, then functor, then applicative, so it feels backwards to define a monoid with applicative functions
00:39:24 <quchen> I often define Functor in terms of Monad.
00:39:56 <quchen> instance Functor Foo where fmap = liftM -- done
00:40:21 <kadoban> Hm, weird. I wonder if that's really the Monoid for ZipList. But yeah haskell/GHC doesn't care about "backwards" at all of course. Unless you mean something like pedagogically it's backwards, which I'm not sure about.
00:40:29 <jared-w> I, uhh, well if that's fine then clearly I don't need to worry about how idiomatic it is to write instances from the bottom up rather than the top down
00:40:51 <jared-w> kadoban: I meant pedagogically speaking. I know GHC doesn't care about "backwards" :p
00:41:10 <kadoban> Oh okay. Then yeah that does sound possibly odd.
00:47:58 <jared-w> https://wiki.haskell.org/Why_not_Pointed%3F
00:48:11 <jared-w> "...(he still provides the pointed package only because “people were whinging”)..."
00:48:16 <jared-w> what a legend
00:50:03 <kadoban> Heh
01:08:31 <jared-w> "This also means that parsers built using an Applicative interface can only parse context-free languages; in order to parse context-sensitive languages a Monad interface is needed" bam, finally reading this shit and understanding it #hype
01:09:27 <Athas> In Haskell, a monadic parser can even parse Turing-complete languages.
01:09:48 <earthy> applicative precludes the cut operator.
01:09:49 <ventonegro> I love the feeling when some understanding dawns on me.
01:10:26 <ventonegro> It's like I can see further.
01:11:31 <johnw> ventonegro: agreed
01:14:32 <ClaudiusMaximus> good morning!  i added some features to hp2pretty (a tool to graph heap profiles)  https://mathr.co.uk/blog/2017-06-29_hp2pretty-0.8_released.html has some pictures exhibiting the new stuff
01:15:53 <jared-w> Also, apparently because of generic recursion, any finite alphabet context-sensitive language can be parsed with alternative and applicative :p
01:16:16 <jared-w> Love seeing how the beautiful and pure math gets finnicky in the details when it comes to implementing it
01:16:52 <kadoban> http://codeforces.com/blog/entry/52977 my complaint to codeforces about their haskell support being kind of broken (due to safe haskell) if anyone is interested or has any input or whatever.
01:17:39 <ClaudiusMaximus> hp2pretty still misses features from hp2ps including monochrome output, multipage (separate page for key), (encapsulated) postscript support (hp2pretty is svg-only, still..), size options (for header and graph, not sure what hp2ps is up to with big box etc) -- patches for any of these would be very welcome
01:19:45 <Tothler> hey folks, I finished LYaHfGG and decided I needed a project--chose writing a text editor. I'm having problems with state changes and I'm not sure how to call my "State -> NewState" function from main
01:23:33 <Tothler> I was thinking about my state function as the inner loop, but because it's the State monad, I can't do "main = <stuff> >>= stateloop"
01:25:44 <srhb> Tothler: But you can certainly recursively run your stateful computation.
01:27:01 <Tothler> yes, but I need IO too, in between each recurse
01:27:55 <Tothler> would it help if I posted a snippet of my terrible terrible code?
01:28:01 <jared-w> sure
01:31:19 <Tothler> here's the offending code
01:31:22 <Tothler> http://lpaste.net/356545
01:32:36 <LiaoTao> How can I create a Ptr (Ptr foo) from a Ptr foo?
01:33:27 <IOFlop> I have a blog of json that looks something like: '{ "items": [ .. ]}` where each '..' is an object which represents something I have a FromJSON instance of - what's the machinery for parsing this and getting my list of data? What I've tried is to case on `Value` but a) I can't get the types to line up and b) This feels overly boilerplatey
01:33:35 <IOFlop> Blob of json*
01:35:21 <ventonegro> Tothler: `case args of (arg:_) => getFileText arg ...`
01:36:35 <Tothler> I'm aware the command line interaction needs work
01:37:03 <Tothler> but how could I make mainLoop compile?
01:37:07 <mbw> How can I make sense of the relationships in the lens package in terms of covariance and contravariance? I keep trying to wrap my head around this, and by now I know the relationships between getters, setters, folds, traversals, lenses etc. off by heart, but unfortunately only by repetition. But theoretically it should be possible to reason about this in terms along the lines of "covariant in return type, 
01:37:13 <mbw> contravariant in function argument", right? Can this kind of terminology applied to the relationship between Traversals and Lenses, for instance?
01:37:23 <ventonegro> Tothler: If you need IO mixed with state, the obvious answer is StateT
01:37:34 <Tothler> change it to type "EditState -> IO ()"?
01:38:18 <jared-w> Tothler: there is an actual StateT transformer monad
01:38:29 <ventonegro> Tothler: `type EditState a  = StateT a IO`
01:38:39 <Tothler> I'll read up on it
01:38:43 <jared-w> @info StateT
01:38:43 <lambdabot> StateT
01:38:59 <jared-w> thx bro, knew I could count on you
01:39:07 <ventonegro> Tothler: https://wiki.haskell.org/Simple_StateT_use
01:41:44 <jared-w> :t (map . map . map)
01:41:45 <lambdabot> (a -> b) -> [[[a]]] -> [[[b]]]
01:42:00 <Tothler> the types are poorly named; EditState is the actual state at that moment and Mode is a synonym for "KeyPress -> State EditState ()"
01:42:17 <jared-w> I finally truly understand this, woo.
01:43:03 <mbw> :t (fmap `fmap` fmap `fmap` fmap)
01:43:05 <lambdabot> (Functor f, Functor f1, Functor f2) => (a -> b) -> f2 (f1 (f a)) -> f2 (f1 (f b))
01:43:09 <dibblego> mbw: you might mean profunctors, not lens
01:43:14 <jared-w> Tothler: I'd suggeset something like GlobalState or EditorState or DocumentState
01:43:34 <jared-w> ಠ_ಠ
01:44:21 <jared-w> 5 fmaps, only 3 functors
01:44:59 <merijn> hmm, so suppose I have a StaticPtr in a library, then two different executables, both linking against said library should be able to communicate those with each other, no?
01:45:04 <mniip> :t fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap fmap
01:45:06 <lambdabot> (Functor f, Functor f1, Functor f2) => (a -> b) -> f2 (f1 (f a)) -> f2 (f1 (f b))
01:45:38 <jared-w> does lambdabot just give up after 3 functors or something?
01:45:55 <mniip> No that's just how types work
01:46:03 <kadoban> Nope, that's its actual type, funnily enough.
01:46:06 <zomg> Anyone know if there's a http://devdocs.io type solution for Hackage packages?
01:46:18 <zomg> DevDocs has Haskell but I think it's just `base`
01:46:20 <jared-w> Yeah just realized that
01:46:48 <merijn> zomg: Which features are you looking for?
01:48:04 <jared-w> 5 fmaps gets you back to only one functor
01:48:58 <zomg> merijn: mostly just quickly looking up stuff like which package something lives in
01:49:02 <jared-w> heh, that's cool
01:49:12 <zomg> google works but it's not always that fast to go there and then find the relevant hackage link
01:49:29 <bollu> quchen ping
01:49:37 <bollu> quchen I find the behaviour of nest a little counter intuitive
01:50:03 <cocreature> zomg: http://hoogle.haskell.org/ has all of stackage
01:50:19 <merijn> zomg: So, if you set it up in you cabal config (not sure if it's default) cabal will put local copies of the docs of each installed package (including an index of all identifiers) on your machine. If you want something more general (not just installed), there's Hoogle, but that doesn't support, e.g. fuzzy finding
01:50:43 <merijn> zomg: Although, I'm pretty sure Hoogle improvements would be welcome :)
01:50:54 <merijn> Also, you can run a local Hoogle which indexes more packages
01:51:14 <jared-w> anyway I'm going to head to bed. Stayed up too late looking at random haskell stuff
01:51:15 <zomg> cocreature: hm that might be a tiny bit faster than looking it up from google :)
01:51:38 <mniip> jared-w, fmap fmap `fmap` fmap fmap = fmap (fmap fmap fmap)
01:51:42 <merijn> zomg: Also, if you weren't aware of Hoogle yet, then yes. Stop using google :p
01:51:44 <mniip> That's a law
01:51:52 <merijn> Hoogle <3
01:52:00 <zomg> merijn: yeah I knew of it but just going to google out of habit :P
01:52:21 <bollu> quchen http://lpaste.net/356546
01:52:24 <jared-w> I do the same. I'll get that hoogle into my muscle memory soon
01:52:29 <zomg> it's quick to tab into the browser and just do ctrl+l and type a phrase
01:52:29 <merijn> zomg: I actually have a shortcut in chrome so that "h <query>" just directly dumps me to Hoogle :0
01:52:39 <zomg> oh nice it can do those now?
01:52:40 <jared-w> mniip: thanks, that helps
01:52:49 <zomg> I didn't even know it did those now.. I remember that feature was so great in Opera
01:53:08 <jared-w> zomg: that's like the oldest trick in the browser book. Google, firefox, etc., have all been able to do it for ages
01:53:09 <mniip> Just realized that you can curry HoTT into literally "HoT Theory"
01:53:20 <zomg> jared-w: heh, somehow I just never checked I guess :P
01:53:37 <zomg> I just remember having a lot of those back in the day when Opera still was Opera and not a reskin of Chromium
01:53:55 <merijn> zomg: Chrome has been able to do that for, like, years now :)
01:54:13 <jared-w> yeah I had a ton too
01:54:41 <jared-w> then google got scary good at stuff and now I can just type like "thing word, woohoo, haskell" and it's the top result, and now I don't really bother
01:54:57 <mniip> I can't remember the last time I've used hoogle
01:55:11 <zomg> jared-w: yeah pretty much :P
01:55:17 <mniip> It's lacking in modules
01:55:26 <merijn> mniip: It's gotten better
01:55:35 <merijn> mniip: Also, see earlier remark of "just run a local hoogle" :p
01:55:37 <zomg> I think the reason I never found chrome did that was because it was so well hidden in the setting screen
01:55:37 <jared-w> Does it not fully index hackage?
01:55:40 <cocreature> mniip: there is a huge difference between hoogle.haskell.org and haskell.org/hoogle
01:55:41 <merijn> Then you can run things from the commandline
01:55:42 <merijn> jared-w: No
01:55:45 <zomg> took me a while to find it :P
01:55:50 <cocreature> the latter has basically no packages while the former has all of stackage
01:55:53 <mniip> And google is creepily smart in personalized results
01:55:56 <jared-w> man that's a shame
01:56:07 <merijn> zomg: That's because hoogle.haskell.org is the alpha for Hoogle 5
01:56:12 <cocreature> the typesarch is kind of shitty in the former but I never found that to be particularly useful
01:56:13 <merijn> zomg: The main one is still using 4
01:56:13 <jared-w> wait, so which should I be using? hoogle.haskell.org?
01:56:15 <mniip> Like I can google "lens" and kmett will be on the first page
01:56:26 <merijn> jared-w: ^^ see above
01:56:31 <merijn> jared-w: It's alpha
01:56:33 <zomg> merijn: huh?
01:56:41 <zomg> I was talking about the chrome feature for `h foo` being hidden
01:56:45 <jared-w> It's like 2am, every now and then it takes me a second to mentally parse "former" and "latter"
01:56:50 <merijn> oh :)
01:56:51 <trigone> hiya, first time on an IRC channel and therefore here too!
01:57:03 <jared-w> I gotchu though
01:57:19 <trigone> first question is how the hell can you read as fast as everyone is typing?
01:57:43 <jared-w> damn, I still get optics, camera lenses, etc when I google "lens"
01:58:06 <jared-w> trigone: I personally read at about 400 wpm and type at about 80-120
01:58:06 <merijn> trigone: 1) You get used to, 2) you stop trying to follow all conversations at once ;)
01:58:31 <trigone> merijn: lol i'll do that
01:58:44 <jared-w> Really dense material I have to slow down to almost 250 wpm but that's only if I'm reading heavy mathematical notation or stuff edward is saying :p
01:58:57 <cocreature> type faster so they need to stop typing to read what you typed
01:58:59 <quchen> bollu: You’re looking for indent
01:59:12 <mniip> Stuff edward is saying is 1 wpy at best
01:59:26 <quchen> bollu: Nest just increases the nesting level, which has no effect on the current line, only after the next newline
02:00:04 <mniip> trigone, also the channel isn't always as crowded
02:00:09 <jared-w> Anyway, pretty sure I mentioned bed at somepoint... Thanks for the fmap law, mniip. See y'all tomorrow
02:00:33 <jared-w> In fact, most of the time the channel is pretty slow until about midnight-2am my time ¯\_(ツ)_/¯
02:01:01 <mniip> Timezones
02:01:18 <trigone> jared-w: what time is it there?
02:01:23 <jared-w> I'm PST, it's 2am right now :p
02:02:06 <mniip> Midday, been reading HoTT the whole night
02:02:11 <trigone> ok :) so i'll try avoiding 11am
02:02:28 <trigone> HoTT?
02:02:41 <mniip> Homotopy Type Theory
02:02:45 <jared-w> Homeopathic Tea Therapy
02:02:45 <Unhammer> why does this not show whenM https://www.haskell.org/hoogle/?hoogle=m+Bool+-%3E+m+%28%29+-%3E+m+%28%29
02:03:16 <merijn> Unhammer: Where is whenM from? I haven't seen that before, tbh
02:03:18 <trigone> jared-w: still better than java
02:03:36 <mniip> jared-w, Horizontal Tiredness Treatment?
02:03:40 <jared-w> Unhammer: http://hoogle.haskell.org/?hoogle=whenM&scope=set%3Astackage
02:04:24 <jared-w> That's the alpha version of hoogle. Much shinier, much better, just learned about it 5 minutes ago
02:04:30 <jared-w> mniip: ahh speaking of which...
02:04:31 <Unhammer> aha
02:04:51 <merijn> Unhammer: Hoogle doesn't index all of Hackage, so it can't find everything
02:05:29 <mniip> trigone, I've always handwaved the foundations of CT/TT, until I became interested in those recently
02:05:39 <cocreature> merijn: whenM is in monad-loops
02:05:44 <cocreature> and extra
02:06:01 <Unhammer> Control.Monad.Extra here
02:06:06 <Unhammer> thanks jared-w 
02:06:07 <trigone> mniip: CT/TT? the latter is Type theory?
02:06:12 <cocreature> Unhammer: if you search for this http://hoogle.haskell.org/?hoogle=Monad%20m%20%3D%3E%20m%20Bool%20-%3E%20m%20()%20-%3E%20m%20() even the typesearch works
02:06:18 <merijn> I usually just use LambdaCase or just binding with when
02:06:18 <cocreature> without the constraint it seems to break
02:06:25 <mniip> Category Theory and yes
02:06:46 <trigone> mniip: whatever HoTT is, it exists in haskell?
02:06:57 <mniip> It is tangential
02:06:59 <NickHu> trigone: I don't think so
02:07:10 <mniip> At this moment, at least
02:07:16 <mniip> Might change later
02:07:18 <merijn> trigone: Not really, HoTT is basically trying to create a new foundation for math
02:07:40 <NickHu> This is the closest implementationgy thing I've seen for HoTT
02:07:42 <NickHu> https://github.com/mortberg/cubicaltt
02:08:25 <trigone> mniip: all of math? pretty cool. when they say foundation, do they mean "something onto which you can rebuild everything else"?
02:08:40 <mniip> Yes
02:09:18 <trigone> mniip: but that's still above the level of pure logic right? or my question makes no sense?
02:09:28 <mniip> You've probably built most of math on top of sets. Haskellers do similarly with categories
02:09:42 <mniip> But what is a set? A category?
02:09:46 <bollu> quchen ah, I see
02:09:47 <NickHu> It's about using type theory instead of predicate logic right?
02:10:07 <mniip> NickHu, that's a minor aspect
02:10:23 <mniip> The major aspect is proof-relevance
02:10:48 <IOFlop> Anyone familiar with Data.Aeson? I have a blog of json that looks something like: '{ "items": [ .. ]}` where each '..' is an object which represents something I have a FromJSON instance of - what's the machinery for parsing this and getting my list of data? What I've tried is to case on `Value` but a) I can't get the types to line up and b) This feels overly boilerplatey
02:10:54 <mniip> Where you're interested in the structure of a proof as much as its existence
02:11:29 <Unhammer> ok, need "Monad m" at least then
02:11:41 <trigone> mniip: focusing more on what is what, rather than what does what? i'm saying that since types don't say how things are done in programs (not explicitly), they just say what they are. i know the semantics are not very good but if you speak of structure vs content (aka the truth value of the proof)
02:11:54 <mniip> With the univalence axiom the identity types can actually be inhabited by multiple values
02:12:05 <trigone> if seen as just an expression that can be true or false, tho maybe you can't see things as such?
02:12:20 <trigone> (i meant proofs seen as boolean expressions)
02:12:20 <merijn> trigone: Most of math is currently using ZFC set theory as fundaments. Category Theory has been used to generalise lots of different branches of math, which let to an idea of seeing whether CT could replace set theory as fundament. HoTT is, afaict, a CT inspired version of type theory with much the same goal
02:12:47 <mniip> trigone, in FP we spend a great deal on mathematical correctness of programs
02:13:05 <merijn> trigone: But all those is rather far (well, not THAT far) from "practical programming", so it's more something to satisfy your mathematical/theoretical curiosity :)
02:13:18 <mniip> Hence we have to know the basics very precisely
02:13:24 <trigone> merijn: so, CT has not been checked entirely as possible replacement for ZFC yet? or did it?
02:13:31 <mniip> Lest we prove russell's paradox
02:13:37 <mniip> Or solve halting
02:13:45 <merijn> trigone: Honestly, I'm not that well versed in CT, tbh :)
02:13:59 <trigone> merijn: yeah i gathered :) but everytime math tries to get abstract one way or another it's applied beautifully IRL
02:14:14 <trigone> (as in, one day)
02:14:30 <mniip> ZFC can be implemented in HoTT
02:14:36 <mniip> From what I've seen
02:14:50 <trigone> mniip: if you solve russell's paradox, you prove god's existence? ^^
02:15:19 <merijn> trigone: I totally think people should dig into this stuff, it's just that people should realise that they should only do that out of personal curiosity, not because it's somehow required to write, e.g. Haskell :)
02:15:43 <NickHu> trigone: There's a survey by Awodey called something like Types to sets to categories to types (probably got the wrong order)
02:15:52 <NickHu> Which shows you can start with any of them as the foundation
02:15:56 <IOFlop> Where's a better place to ask my question? Not getting any responses here
02:15:59 <NickHu> And build the other stuff
02:16:37 <trigone> mniip: and it's usable? because you can implement numbers with N = Z | S N but it's not terribly practical for arithmetics (is it?)
02:16:46 <mniip> But can you define god in terms of ∈
02:17:02 <merijn> IOFlop: Well, here's good, but it depends on who's active (i.e. when is the aeson/web crowd on). StackOverflow usually also has a really active Haskell crowd.
02:17:25 <trigone> merijn: haha nobody requires me to write nothing in haskell! are there people *forced* into it?!
02:17:36 <mniip> trigone, it is practical in some cases
02:17:55 <trigone> mniip: i guess, it's good for recursion i supposed
02:18:17 <trigone> mniip: god in terms of membership?
02:18:24 <mniip> I've tried defining binary arithmetic on the type level
02:18:31 <mniip> It was not fun
02:18:43 <mniip> And I don't think I've finished it
02:18:48 <NickHu> mniip: How does univalent foundations solve the decidability problem (if it does?)?
02:19:23 <trigone> mniip: in fact N = Z | S N is a bit like "base 1" if it were possible in positional numerotation. it's like writing 0 for 0, 00 for 1, 000 for 2...
02:19:30 <mniip> NickHu, are you referring to my comment about halting? That was random
02:19:34 <trigone> mniip: that hard? makes me wanna try
02:19:44 <trigone> mniip: you mean in haskell or in math?
02:19:55 <merijn> trigone: There's this, very persistent, meme online that "I need to learn CT to write Haskell", which is a bit annoying, since that's like the opposite of true :)
02:19:57 <mniip> In base 1 the only number is 0
02:19:58 <trigone> mniip: that you tried making binary type operations
02:20:06 <NickHu> mniip: Not really - I only have a glancing understanding of what HoTT is, but I know about the decidability properties of FOL
02:20:07 <mniip> In haskell
02:21:00 <trigone> mniip: i'd rather say, the only set that can be represented in base one is the trivial set. i mean, you can't really talk about numbers with only one number, can you?
02:21:00 <mniip> NickHu, they define decidable types. A is decidable if A + Not A
02:21:14 <mniip> And decidable equality in a similar matter
02:21:36 <NickHu> Ah ok
02:21:45 <NickHu> I'd really love to learn more about HoTT, but I should probably take a course in topology first..
02:21:53 <trigone> mind you i could not answer "what is a number" so...
02:22:22 <trigone> i'm just basing myself on the fact every other base can represent an infinity of different values
02:22:32 <mniip> trigone, base-n usually refers to a positional number system where digits are 0 to n-1 and their value is multiplied by a power of n
02:22:45 <mniip> In base-1 the only digit is 0
02:23:00 <mniip> And 0 = 00 = 000 = ...
02:23:58 <mniip> trigone, this is an interesting case
02:25:08 <trigone> mniip: yes, that's why i said it was not really base 1. i'm just saying, base 1 isn't really a thing, since before defining a way to represent numbers, you define numbers, and if say the numbers is [0..] then a "base 1" sys that would only allow representation of one value, does not work
02:25:41 <mniip> Formally a base-n singleton is N = (pi k. (k < n) × (k > 0)) + (N -> pi k. (k < n))
02:26:13 <mniip> When n = 1 such a type is uninhabited
02:26:28 <trigone> it's like, i just invented a new way to represent numbers: "turnip" is used for 42, and "butternut" is for 100, every other number is fat chance -- i would not call that a proper representation of numbers
02:26:52 <mniip> Looks good to me
02:27:16 <mniip> You need to define turnippy and butternutty functions
02:27:38 <trigone> mniip: but then it means you define "numbers" based on the values representable by the system. it's one way to see it, but if you start from the notion of numbers and seek ways to represent them, then "base 1" falls short
02:27:41 <mniip> And it's classical logic all over again
02:28:10 <trigone> mniip: there are functions in base 1? what does it even mean "functions in base x"
02:28:11 <mniip> trigone, you were referring to "unary", I get it
02:28:13 <[exa]> people were, like, not made to express themselves in classical logic
02:28:27 <trigone> mniip: unary?
02:28:45 <mniip> [12:19] (trigone) mniip: in fact N = Z | S N is a bit like "base 1" if it were possible in positional numerotation. it's like writing 0 for 0, 00 for 1, 000 for 2...
02:29:52 <trigone> mniip: not sure. if it's akin to romans saying 3 = III then yes. it's the representation that multiplies the symbol by the amount the symbol represents instead of relying (only) on position
02:37:17 <ertes-w> mniip: base 1 doesn't really make sense mathematically
02:38:59 * [exa] joins the base-flame
02:39:07 <ertes-w> @let baseEncode b = unfoldr (\x -> case divMod x b of (0, 0) -> Nothing; (q, r) -> Just (r, q))
02:39:09 <lambdabot>  Defined.
02:39:18 <ertes-w> > baseEncode 2 13
02:39:20 <lambdabot>  [1,0,1,1]
02:39:21 <ertes-w> > baseEncode 1 13
02:39:24 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
02:39:33 <[exa]> it does, but definition of base numbers requires you to sacrifice one number as zero
02:39:44 <[exa]> which squashes all numbers to infinite amount of zeroes
02:39:58 <phz_> is there an easy way to install ghcjs with stackage?
02:40:05 <[exa]> maybe you could distinguish between numbers based on ordinal amount of the zeroes in the representation
02:40:41 <[exa]> which might be a legally defendable reason why base-1 isn't practical :]
02:41:39 <shadowdao> https://en.wikipedia.org/wiki/Shape_of_the_universe
02:42:28 <shadowdao> https://en.wikipedia.org/wiki/Zero-energy_universe
02:43:00 <mniip> baseDecode x = case unpackClosure# x of (# i, _, _ #) -> I# (addr2int# i)
02:43:26 <shadowdao> Nothing means anything.
02:44:07 <[exa]> shadowdao: good point. :]
02:53:05 <yogayaourt> yesterday
02:53:50 <yogayaourt> 9
02:53:57 <yogayaourt> Battles
03:04:42 <trigone> <[exa]>: there is a partial logic to seeing base 1 as meaning 1 = 1, 11= 2, 111= 3.
03:05:29 <trigone> scratch that, i meant 0,10, 100, 1000 = 0,1,2,3
03:08:07 <trigone> scratch that again, it really does not work
03:09:52 <trigone> technically you can think of 00 = 1 as meaning "i added a number because i exhausted the options for 1-digit number with the interval [0,0]. then you add yet another 0, and another. the main issue is that 0 is supposed to mean "nothing at that position" but at the same time it's the only number allowed if you have a base 1.
03:24:48 <trigone> hiya again
03:25:51 <trigone> got a question to whoever: where shud i go if i've got something like 100lc little project, and i'd like reviews for getting better?
03:26:35 <peddie> trigone: you could post the code on lpaste.net and share the link here, especially if you have some specific questions
03:27:19 <trigone> also i've heard sometimes some lucky people found mentors to help them rise from the middle-beginner stage. nobody thinking about becoming a mentor by any chance? (mind you i don't offer money)
03:27:53 <freeside> irc is the perfect place for drive-by, distributed mentoring
03:28:05 <freeside> all you have to do is ... take advice
03:28:13 <trigone> peddie: ok thanks! i'll do that when i refactored it a bit, got new ideas recently and there's no point asking for reviews before doing all i can :)
03:28:29 <freeside> good attitude.
03:29:00 <piyush-kurur> I just merged portable C implementation of blake2s and blake2b into raaz
03:29:12 <trigone> freeside: take advice?
03:29:14 <piyush-kurur> seems that we are doing fine (in fact slightly better) than openssl
03:29:21 <piyush-kurur> https://gist.github.com/piyush-kurur/9b219da994ac257165f4f4c7b26f5096
03:30:17 <trigone> freeside: as long as nobody criticizes my use of tabs we're fine
03:30:38 <trigone> just kidding. i wonder if GHC compiles tabs?
03:31:30 <mauke> tabs are "fine" but the standard says tab stops are at every 8 columns
03:32:32 <mniip> -fno-warn-tabs is love
03:32:37 <mniip> -fno-warn-tabs is life
03:33:01 <mauke> -fdelete-source-on-error
03:33:40 <mniip> export LD=rm
03:34:30 <piyush-kurur> mniip: that is cruel
03:35:29 <mniip> trigone, personal advice from a tabs advocate: figure out "let" indentation s
03:36:25 <trigone> mniip: you really advocating tabs? like, everything indented is at least 8-character indented?
03:36:40 <mniip> Hard tabs
03:36:47 <mniip> No spaces
03:37:48 <trigone> mniip: i don't get what you say. do you imply that if you never use spaces, it does not matter the size of the tab does not match onscreen and as ghc sees it?
03:38:01 <trigone> unless you actually visually indent with 8 characters
03:38:25 <trigone> let indentations? meaning you jump one line after the keyword?
03:38:26 <mniip> I indent my code in a way that makes tab width irrelevant
03:38:42 <mniip> You could say, tabs are forall-quantified
03:38:47 <trigone> mniip: you create a newline after every keyword?
03:38:50 <mniip> Haha I'm so funny
03:38:55 <mniip> No
03:39:08 <trigone> forall-quantified? well that's one i don't get at all
03:39:16 <mniip> That would be silly
03:39:37 <mniip> But I do put a newline after 'where' if I need multiple binders
03:40:39 <trigone> let's consider "let". how do you put more than one equation when the second line is supposed to be indented of 4 characters after the start of the word "let"?
03:40:59 <trigone> unless you add tons of spaces after let?
03:41:22 <trigone> or you use multiple lets one into the others?
03:41:33 <mniip> let\n\t\tbinders\n\tin\n\t\texp
03:42:06 <trigone> you kidding me? ^^ i asked if you always added a newline after every keyword and you said no
03:42:16 <mniip> Not every
03:42:21 <trigone> well that was a useful debate :P
03:42:34 <trigone> mniip: you mean you only do so when you have more than one equation, that's it?
03:42:40 <mniip> Yes
03:43:08 <mniip> I don't consider let, in, case and where to be all keywords
03:43:58 <trigone> mniip: ok ^^ but why tabs then? i say that after having advocated for tabs in JS for years, but now i'm just realizing that either way the editor has to handle it, and so it does not really matter, but there are issues given most times tabs seem to win the favors of all (cf haskell itself)
03:43:59 <mauke> I used to do that but decided that it's not worth it
03:44:11 <trigone> mniip: i meant keyword in terms of indentation rules
03:44:14 <mauke> haskell syntax is fundamentally not based on indentation levels
03:44:31 <mniip> Got used to it
03:44:50 <mniip> I cant get myself to vertically align stuff
03:45:20 <trigone> mauke: but i recently realized that if i did not use a newline after let, where, etc. it was harder to manage: i could not copy-paste lines easily if they start or not with a keyword
03:46:05 <trigone> mauke: do you always put the first equation after the keyword?
03:46:12 <trigone> keyword in a loosely sense
03:46:15 <[exa]> I wonder when someone finally abstracts out the indentation from the editors so we can pull the definitions around using a mouse or something
03:46:18 <trigone> meaning
03:46:22 <trigone> (meaning)
03:46:29 <mniip> [exa], that exists
03:46:39 <mniip> It's called scratch
03:46:46 <trigone> [exa], vim forever! #killallmouses
03:46:54 <trigone> or emacs for that matter
03:46:58 <[exa]> oh noes!
03:47:06 <[exa]> :]
03:47:12 <mniip> ed is the default text editor
03:47:28 <trigone> mniip: it's called crying. might as well replace programming by a mouse with a button "1" and a button "0"
03:47:42 <[exa]> trigone: I actually use vim, but well imagine for example yD/dD as yank/delete definition
03:47:52 <[exa]> and some smartass paste for that
03:48:49 <trigone> [exa] but what's the connection with mouses? i mean ofc if mouses become sort of gloves or anything similarly fast... otherwise
03:48:58 <[exa]> similarly as for example ciB (that one's brutally good btw)
03:49:31 <[exa]> trigone: take mousing the defs around as an extreme
03:50:09 <trigone> [exa] i don't get the idea of mousing, you mean moving around the code?
03:50:28 <trigone> and the indentation would automatically apply as shouldbe?
03:50:49 <[exa]> yeah, just take a definition from one binding block and put it in another, editor fixes up the rest
03:51:10 <trigone> that would be cool. you spoke of vim bindings, do you mean it's already implemented?
03:51:10 <[exa]> no matter if it's drag&drop or dD/p
03:51:21 <[exa]> nope
03:51:36 <[exa]> but if you don't know caB/ciB/ci( etc, do try. :]
03:52:08 <[exa]> imho :help iB should work
03:52:15 <trigone> because there are stuff i've vaguely seen around about abstracting the way vim thinks of texts as objects, hypothetically it could work
03:52:40 <trigone> or you can go bruteforce: everytime you copy/paste you send an autoformattor on the content of the file and you reload it
03:53:23 <trigone> block selection, cool. and that's wired with how haskell syntax highlighting works?
03:53:37 <[exa]> wrong-indented haskell can't be autoformatted afaik, only heuristically fixed
03:53:55 <trigone> is there a way to hide the join/quit parade? or to move it somewhere else? it's a bit hard to read...
03:54:23 <[exa]> trigone: I actually didn't try it on haskell yet, but it could work for blocks. Certainly works on different kinds of parens
03:54:58 <trigone> [exa]: i admit, i'm not sure it's doable either... maybe it could be based on where you put it. say you put one line right after another, and you can decide to either paste it as such, or to modify the indentation to match the previous line indentation
03:55:59 <trigone> i mean automatic indentation is also "guess work", but most times it works and as long as the system allows you to choose (say with a special mode of pasting), i don't see why not
03:56:37 <trigone> is there a way to make newline in messages?
03:57:03 <[exa]> usually solved by a better irc client
03:57:25 <trigone> no i mean, is there a way to send a message tha would spawn for several lines?
03:57:41 <mauke> no
03:57:41 <trigone> *spread onto
03:57:54 <mniip> No, you send several messages
03:57:55 <trigone> well that's a shame (and also a very good thing)
03:57:57 <[exa]> irc is talking, do you talk lines? :D
03:58:00 <mniip> And get klined
03:58:08 <[exa]> and that ^
03:58:28 <trigone> mniip: yeah but if you wanna show some small code snippet and there's one more random person that joins/quits in the middle... who knows what the code would do then !!!
03:58:38 <[exa]> pastebin.
03:58:42 <mauke> that's why we have paste sites
03:58:56 <mauke> also prevents the code from scrolling off while we're talking about it
03:59:27 <mniip> My rule of thumb is 4 lines -> pastebin
03:59:29 <trigone> [exa]: might as well reconvert if the written word has to be as annoying as speaking. NO MORE DOTS ALLOWED AT ENDS OF FILES, WE"RE SPEAKING IN HERE!
03:59:37 <trigone> *ENDS OF LINES
03:59:39 <mniip> 3 lines I'd consider it
03:59:40 <mauke> hah
03:59:55 <trigone> yeayea i'mma go there :P just saying
04:00:01 <mauke> the rule in #perl is pretty much: pasting anything -> pastebin
04:00:11 <mauke> I'm willing to tolerate 1 line
04:00:24 <trigone> mauke: what happens at the second one?
04:00:38 <mauke> depends on which ops are active
04:00:42 <mniip> But I copy-paste sentences in the inputbox as I speak!
04:00:58 <mauke> you might get /kick'd out temporarily
04:01:35 <mauke> personally I'll frown at you and ask you to use the paste site in the /topic
04:01:46 <mniip> I forget, is mst an op there?
04:01:51 <trigone> mauke: hope it does not hurt too much...
04:01:52 <mauke> or just /kick if the paste doesn't seem to stop
04:01:57 <mauke> yep
04:02:27 <mauke> the fun thing with pasting into irc is that in your local client it all seems to appear instantly
04:02:39 <mniip> Yeah fun thing
04:02:39 <mauke> but for everyone else it trickles in one line at a time
04:03:02 <mauke> so a long paste can disrupt the channel for a long time
04:03:13 <trigone> mauke: hence my question on newlines. there could be a maximal number allowed (to avoid spamming), but then ofc that would not be an irc would it
04:03:34 <trigone> i(i meant on newlines inside one single message)
04:03:45 <mniip> trigone, wait till you see some of the spam
04:03:51 <trigone> mniip: there are?
04:03:55 <mniip> Then imagine if it was VERTICAL
04:04:04 <trigone> i dont get it
04:04:25 <trigone> unless it's a variance of INTERCAL
04:04:26 <mauke> hah. we already have ascii art spam
04:04:36 <mauke> .oO( penisbird.jpg )
04:04:51 <trigone> mauke: birds don't have any
04:05:20 <mauke> that's ... not what that picture is. also, look up duck penises
04:05:26 <mauke> they're impressive
04:05:46 <quchen> mauke: I’m not sure what I expected searching that picture online
04:06:10 <mniip> I'm sure ducks like haskell very much
04:09:36 <trigone> hey btw i had some question: haskell is really great for most things, but say one day i need a very low level thing, which could be a good complement? and i mean, one that would be at least somewhat as well-made as haskell, respectively to their domains of application
04:10:03 <trigone> i heard of rust but some say it's not very mature, and there are big lacking stuff or not-yet-stable thingies.
04:10:07 <sbrg> I think I'd probably go with Rust, but I'd probably try to do it in Haskell if it was at all possible. you can always use the C FFI.
04:10:41 <trigone> but after having gotten a taste of haskell, darn if i don't wanna code in anything loosely-typed or non-functional again!
04:11:15 <trigone> they speak of paradigms, but given the little there is in common between the different kinds of programming, i'm thinking they'd practically deserve their own words
04:11:18 <mniip> Been there done that
04:11:19 <mauke> depends on what you mean by low-level
04:11:26 <trigone> been there done that?
04:11:26 <mniip> Lasted about 2 years
04:12:05 <mniip> The disgust with untyped imperative madness, I mean
04:12:31 <trigone> mauke: honestly, i'm not really sure. i guess i mean for those cases when haskell does not shine enough. since one of its only weak points is efficiency (time/memory), at least in some cases (i'm aware sometimes it's rocket fast, but maybe not always)
04:12:42 <trigone> mniip: and now you changed your mind?
04:13:02 <trigone> mniip: as in now you like/tolerate it?
04:14:12 <trigone> mauke: what i mostly ask is "since haskell is not 100% perfect, what do i do when i need C-level power but without sacrificing the good parts of haskell, at least when it's about strong typing and, why not, purity"
04:14:21 <mniip> You can write beautiful code in all languages
04:15:23 <dredozubov> I don't want to touch rust before it'll get HKT at least
04:15:37 <dredozubov> affine types are good and all, but damn
04:15:38 <trigone> mniip: to me beautifully wrt coding means manageable and modulable. OOP or imperative fall short: lines upon lines of hard-to-read codes, even if you never do any dirty coding
04:15:51 <mniip> trigone, what you should avoid at all costs is disgust with applied stuff
04:15:58 <mniip> Like I had
04:16:04 <trigone> mniip: applied stuff?
04:16:14 <trigone> mniip: you mean by contrast with math?y
04:16:22 <mniip> Practical stuff vs theoretical
04:16:22 <dredozubov> software = disgust
04:17:22 <trigone> as i said, i mean disgusted not at the artistic level, more at the pragmatic level. basically i'd like a programming language for all that which haskell falls short, but without sacrificing practicality, reusablity, readability, etc. all things that make practical stuff doable without feeling oppressed by the code
04:17:31 <trigone> but maybe i'm too pessimistic
04:17:46 <dredozubov> trigone: just compile haskell to whatever you need
04:17:48 <trigone> maybe haskell is good for anything? and the rest is negligible? dunno
04:18:21 <trigone> trigone: you mean transpile? what's the gain if the starting point is haskell?
04:18:30 <mauke> "transpile" is a stupid word
04:18:37 <mauke> it means the same thing as "compile"
04:18:47 <dredozubov> it's "compile" to me
04:18:59 <dredozubov> but yeah, you get type safety and refactoring power from haskell
04:19:19 <dredozubov> and you get something that's applicable for your project if ghc rts is not an option
04:19:46 <trigone> mauke: it mostly means, to me, getting a source code out of another source code. in that regard, either you consider machine code as source code, in which case compiling is transpiling. otherwise it's a way to say you'll need another compiler and interpreter, and you get a code both shaped by the source and target languages' specificieites
04:20:06 <mniip> Heh, I almost made my own language that way once
04:20:26 <mniip> Couldn't get over the architectural austronacy
04:21:04 <mniip> It was primarily aimed at osdev
04:21:07 <raek> "compile" is a stupid word
04:21:10 <raek> it means the same thing as "translate"
04:21:13 <raek> ;-P
04:21:16 <trigone> dredozubov: but what about laziness? cuz honestly if it were not about some cases of efficiency, i would not even think about using anything but haskell. and i'll still use haskell as much as possible unless i find better suited for a specific task
04:21:27 <mniip> raek, homomorph
04:21:39 <mauke> raek: you have a point :-)
04:21:45 <dredozubov> trigone: what about laziness?
04:22:14 <mniip> Actually etymologically compile is more of ld's job than cc1's
04:22:24 <dredozubov> laziness is frequently far more efficient for hairy business logic, because you don't have to think about the data you have to force per se
04:22:31 <dredozubov> runtime does that for you
04:22:36 <mniip> Because to compile is to collect and aggregate
04:23:26 <trigone> this is good -> ceci est bien. just compiled english to french (yeah right, etymology matters less than use)
04:23:49 <trigone> yeah i know laziness is sometimes way better
04:24:03 <dredozubov> it depends on the use case
04:24:15 <dredozubov> I think it's a good default
04:24:16 <mniip> Laziness is always better time-asymptotically
04:24:20 <trigone> ok, the general question is: will i ever feel limited in whatever way by haskell to the point that to reach the goals i want for my program i'd need some other language?
04:24:31 <dredozubov> going from lazy to strict is easier than the other direction
04:24:38 <mniip> Might be exponentially worse in terms of memory
04:25:05 <trigone> mniip: well i did say efficiency in terms of time *and memory*
04:25:11 <mniip> trigone, you wouldnt write a driver in haskell
04:25:24 <mniip> Nor program a microcontroller
04:25:33 <dredozubov> haskell has a huge runtime, GC and memory usage may be pretty high in some cases
04:25:43 <mniip> Nor implement an ISR
04:26:03 <mniip> Nor a realtime system
04:26:19 <dredozubov> if I don't have a hard restriction like this, I'd just use haskell without any thinking
04:26:25 <mniip> I'm sure there's research in all these areas but in practice you can't
04:26:30 <trigone> mniip: then i am right: sometimes i'd need something else. what would you choose?
04:26:35 <dredozubov> If I have a restriction, there's a chance I'll still use haskell
04:26:36 <mniip> Assembly
04:26:39 <mniip> C
04:26:49 <dredozubov> or at least will do a prototype with it and see how it goes
04:27:07 <mniip> C++ maybeish after doublechecking
04:27:20 <trigone> yeah i gathered, but i wanted to know if there were not any language that could not sacrifice the reasons why you'd otherwise code in haskell rather than c++, java, or whatever
04:27:30 <dredozubov> mniip: as I said above, you can always compile haskell to C 
04:27:51 <mniip> Wouldn't get rid of the rts
04:28:54 <trigone> dredozubov: if it were possible i'm pretty sure no haskeller would ever need the FFI (at least wrt C)
04:28:54 <mniip> Haskell is not freestanding
04:29:12 <mniip> C needs about 6 lines of assembly to work
04:29:31 <dredozubov> trigone: some people do that, kaspersky lab compile haskell to C for some security components in their system
04:29:48 <trigone> hey that's a question i wondered: how big are haskell executables compared to C-ish executables?
04:30:19 <dredozubov> I never occured to me to compare something like that
04:30:27 <dredozubov> It*
04:31:27 <trigone> dredozubov: ok, then what do they do with the c code? they maybe modify it, then they compile it using GCC. yes it helps optimization (i heard), but i don't really think there would be any other point. it's not like you're gonna make sandwitches out of C code. why's haskell in C code better than haskell in code machine (putting aside gcc optimizations)?
04:32:24 <trigone> it's not bc they compile it to C that it magically will be just as if they had tried coding it in C without any haskell complexity. 
04:33:57 <trigone> well, anyway mniip said it all. in a very vague way, it's like comparing the source code of say Python's interpreter, coupled with a big string representing the python source code. well, you put all that inside a C file, but it'll still not be different in any way than just using the python source code with the (compiled) interpreter.
04:35:03 <mniip> https://github.com/mniip/os/blob/master/start.S#L94,L108
04:35:14 <trigone> ofc it's relatively different, but still i guess it's not too absurd to compare the runtime thingy of haskell to an interpreter that would have been made to execute only one source code (with the source code already half-interpreted or whatever)
04:35:17 <mniip> All you need for C to work
04:38:47 <trigone> so, you'd advocate for C over Go or whatever? since rust seems a bit young and all? and i don't know of any other low-level thingy that tries at making a "good" C like you could think haskell to be (loosely) a "good" ... well actually i don't know. most that-high-level OOP languages are interpreted, it seems...
04:39:27 <mauke> I'm pretty sure Go needs a fancier runtime system because GC
04:39:40 <trigone> GC?
04:40:43 <yushyin> trigone: garbage collector
04:41:36 <dredozubov> trigone: I don't see why you'd want to modify C code generated by something else
04:41:57 <dredozubov> logically it's not the source code
04:42:02 <yushyin> trigone: maybe have a look at Ada
04:42:27 <trigone> dredozubov: ok, how do you define "C code" if it's not the source code?
04:43:03 <dredozubov> it's an intermediary media to get rid of garbage collection and rts
04:43:12 <dredozubov> and look at it this way
04:43:32 <dredozubov> if you code in C, you have to deal with not safe memory management
04:43:48 <trigone> dredozubov: so they do manage to transform haskell code into C code? and it works the same way?
04:44:07 <dredozubov> type-safe edsl in haskell can guarantee that you produce C code that is working with memory allocations correctly
04:44:35 <trigone> well darn if that's not weird. why do anyone would not do so then if they could have everything of haskell without the limitations of the GC and so on?
04:44:38 <dredozubov> it's possible because the type system in haskell is much more powerful that type system of C
04:44:56 <srhb> trigone: Writing a sufficiently comfortable DSL might be tricky.
04:45:03 <dredozubov> they use https://github.com/GaloisInc/ivory
04:45:56 <trigone> dredozubov: yes, there's the type system, but there's also laziness. without a way to reason in terms of thunks and so on (aka without having a level of abstraction between C's strictness and haskell's lazy behavior), you can't do that in plain C, can you?
04:46:10 <dredozubov> how is laziness relevant?
04:46:23 <dredozubov> you produce a piece of text
04:46:40 <dredozubov> does it matter how much laziness is going on when you do that?
04:46:57 <dredozubov> you don't port lazy runtime to C
04:47:15 <dredozubov> you generate a straightforward C code, which is strict
04:48:06 <dredozubov> you don't have any guarantees that your memory allocation are correct in C if you write in by hand
04:48:17 <trigone> dredozubov: i think i lack knowledge in how exactly haskell is compiled. and i specifically talked about abstracting the laziness. aka, the whole code is strict, but there are big parts used to *fake* that there is laziness involved (since at the end the executable must react like a haskell function, therefore, lazy by default)
04:48:25 <dredozubov> you can't guarantee that you won't free the same memory twice
04:48:37 <dredozubov> It doesn't matter how haskell is compiled
04:48:53 <dredozubov> what matters is haskell has a powerful type system
04:49:05 <dredozubov> which allows you to force invariant on your code
04:49:24 <dredozubov> you write some haskell, which produces a program
04:49:35 <dredozubov> if you run that program, it produces some C code
04:49:43 <dredozubov> which you embed in your build process
04:50:07 <dredozubov> if you have to change something, you change your haskell program, re-run the build
04:50:10 <dredozubov> here you go
04:50:15 <dredozubov> that's what I'm talking about
04:50:19 <trigone> wait, you mean programs made specifically to output C code?
04:50:39 <dredozubov> yeah, sure
04:50:41 <trigone> or even to output compiled C code?
04:51:24 <trigone> huh, cool. i'd thought about doing sth like that. after all you can reason about any source code from above just like haskell reasons about impure functions without touching them...
04:51:30 <dredozubov> that's the philosophy, you pick a language that gives you the most static(sompile-time) guarantees you can get
04:51:37 <dredozubov> then you generate whatever you want
04:51:54 <dredozubov> i've heard of projects generating erlang from haskell as well
04:51:55 <trigone> dredozubov: still, the question is, how easy it is to write haskell programs made to create C programs
04:52:02 <dredozubov> then you can run it on BEAM
04:52:28 <ADG> I am trying to fibonacci type program where I need to use a list as coefficient, I am thinking of zip & iterating...
04:52:48 <dredozubov> ADG: do that, why not
04:53:15 <ADG> for fibonacci we can do
04:53:17 <ADG> >  iterate (\(f, f') -> (f', f+f')) (1, 1)
04:53:19 <lambdabot>  [(1,1),(1,2),(2,3),(3,5),(5,8),(8,13),(13,21),(21,34),(34,55),(55,89),(89,14...
04:53:34 <ADG> maybe map fst too..
04:53:38 <dredozubov> map fst on it
04:53:48 <dredozubov> or `fst <$> fib`
04:54:02 <trigone> dredozubov: well that's very interesting (haskell to C stuff). i'll check it out!
04:54:03 <ADG> but what if I have F[i] = F[i-1] + x[i] * F[i-2] wherein xs is given?
04:54:54 <ADG> If there was some way of zipping it with iterated result and using it...
04:57:37 <dredozubov> if you need to refer to [i-2], then you obviously need to have at least two previous values
04:57:46 <dredozubov> which would be a little bit more involved
05:00:48 <ADG> is there a **concatMapMaybe**
05:02:12 <ClaudiusMaximus> :t (>>=) -- ADG, this?
05:02:14 <lambdabot> Monad m => m a -> (a -> m b) -> m b
05:02:22 <ClaudiusMaximus> with m = Maybe
05:03:02 <dredozubov> if you run your computation in a MaybeT monad transformer over list, then it's concatMap
05:03:32 <dredozubov> show us the code, it's not clear what you want to accomplish
05:04:51 <ADG> I have `f :: a -> [Maybe b]` and a list `[a]`. I need to do `[a] -> [b]` i.e. map each element to list of maybes, remove nothing, take values out of just
05:05:46 <ADG> e.g. solveFS :: (Int, Int) -> [Maybe (Int, Int)]  and concatMapMaybe solveFs fs where fs :: [(Int, Int)]
05:05:49 <dredozubov> why do you have f :: a -> [Maybe b]?
05:06:04 <dredozubov> i have a hunch it's supposed to be f :: a -> Maybe [b]
05:06:11 <dredozubov> or am I wrong?
05:06:41 <ADG> mathematical function, returns solutions by taking some range of values and each value in range might give no solution that is nothing or a solution that is Just x 
05:07:04 <ADG> these range of values depend on the initial value given to function
05:07:32 <ADG> i.e. (1,2) might give [3..9] and then each value can give Just x or Nothing
05:07:52 <quchen> There is no concatMapMaybe, but you can write your own.
05:07:57 <quchen> It’s not complicated.
05:08:36 <dredozubov> you'll want to default a value somewhere, if you have a 'Maybe Int' and you need to transform that to Int
05:09:19 <quchen> :t catMaybes -- This might help, ADG 
05:09:20 <lambdabot> [Maybe a] -> [a]
05:09:31 <ADG> > catMaybes . conatMap
05:09:33 <lambdabot>  error:
05:09:33 <lambdabot>      • Variable not in scope: conatMap :: a1 -> [Maybe a]
05:09:33 <lambdabot>      • Perhaps you meant one of these:
05:09:35 <quchen> > catMaybes [Nothing, Just "hello", Nothing, Nothing, Just "world"]
05:09:37 <lambdabot>  ["hello","world"]
05:09:44 <dredozubov> i'm not sure if he wants to use catMaybes or sequence in this case
05:09:46 <ADG> > :t catMaybes . concatMap
05:09:48 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
05:10:02 <glguy> :t concatMap . (catMaybes .) -- it'd have been this
05:10:03 <lambdabot> Foldable t => (a -> [Maybe b]) -> t a -> [b]
05:10:09 <ADG> >:t catMaybes . conatMap
05:10:26 <dredozubov> what do you do Nothing's in a solution of type [Maybe a]?
05:10:38 <ADG> do not include it
05:10:47 <ADG> :t concatMap
05:10:48 <lambdabot> Foldable t => (a -> [b]) -> t a -> [b]
05:10:50 <glguy> or \f xs -> catMaybes (concatMap f xs)
05:10:55 <dredozubov> catMaybes will remove all the Nothings from the list
05:10:58 <ADG> :t catMaybes . concatMap
05:11:00 <lambdabot> error:
05:11:00 <lambdabot>     • Couldn't match type ‘[a] -> [b]’ with ‘[Maybe a1]’
05:11:00 <lambdabot>       Expected type: (a -> [b]) -> [Maybe a1]
05:11:16 <ADG> OK
05:16:11 <quchen> :t \f xs -> [ x | Just x <- map f xs ]
05:16:13 <lambdabot> (a -> Maybe t) -> [a] -> [t]
05:21:15 <dredozubov> quchen: I expected it to fail tbh
05:21:34 <quchen> ?
05:21:47 <dredozubov> how does it desugar? to a guard call for the second case?
05:22:18 <glguy> :t \f xs -> [y | x <- xs, Just y <- f x]
05:22:19 <lambdabot> (t1 -> [Maybe t]) -> [t1] -> [t]
05:22:26 <dredozubov> you have a list comprehension with non-exhaustive pattern-matching over there
05:22:53 <quchen> Incomplete patterns result in [].
05:22:55 <dredozubov> so I though it'll use fail method for the other constructor(Nothing in this example)
05:23:18 <quchen> List comprehensions do not desugar to monadic stuff, they have their own rules, independent of fail
05:23:22 <dredozubov> Now I wonder how it works with monad comprehensions
05:23:36 <dredozubov> it should use MonadPlus under the hood
05:23:36 <quchen> The Report includes list comprehensions and mentions their rules specifically
05:23:50 <quchen> (They match the List monad, of course, in terms of denotational semantics)
05:23:52 <dredozubov> I never use list comprehensions, so I have no clue
05:24:21 <dredozubov> sometimes I use do-notation instead of list comprehensions
05:24:49 <phadej> > (\f xs ->  [y | Just y <- map f xs]) (const Nothing) "foo"
05:24:51 <lambdabot>  []
05:24:55 <phadej> > (\f xs ->  [y | ~(Just y) <- map f xs]) (const Nothing) "foo"
05:24:57 <lambdabot>  [*Exception: <interactive>:3:12-38: Irrefutable pattern failed for pattern J...
05:25:49 <phadej> > (\f xs ->  do { Just y <- map f xs; return y }) (const Nothing) "foo"
05:25:51 <lambdabot>  []
05:25:58 <phadej> > (\f xs ->  do { ~(Just y) <- map f xs; return y }) (const Nothing) "foo"
05:26:00 <lambdabot>  [*Exception: <interactive>:3:17-37: Irrefutable pattern failed for pattern J...
05:26:54 <phadej> it uses `fail`
05:30:10 <phadej> Prelude> Just y <- readLn :: IO (Maybe Char)
05:30:10 <phadej> Nothing
05:30:10 <phadej> *** Exception: user error (Pattern match failure in do expression at <interactive>:19:1-6)
05:30:54 <phadej> IO has more fatal `fail`
05:31:13 <glguy> List comprehensions don't translate to the same code as do-notation unless you turn on MonadComprehensions
05:31:24 <glguy> even though they have the same behavior
05:31:41 <glguy> The performance can vary
05:31:45 <phadej> glguy: is it so, that compiler knows about them intimately?
05:32:25 <phadej> e.g. can do foldr/build fusion automatically
05:33:53 <glguy> I assume that that's why it is treated differently
05:34:14 <mniip> IO's empty is just as fatal
05:35:51 <phadej> less descriptive error though
05:37:03 <phadej> Prelude Control.Monad> mzero
05:37:03 <phadej> *** Exception: user error (mzero)
05:40:21 <codedmart> Is there already a func if I want to go from [("one", Just 1), ("two", Nothing)] -> [("one", 1)]. Like catMaybes but on the second element in a tuple? I wrote my own, but seems like it could be something provided already.
05:41:10 <glguy> > mapMaybe sequence [("one", Just 1), ("two", Nothing)]
05:41:12 <lambdabot>  [("one",1)]
05:41:14 <dreams> How do you read a file in real time? So any new line added to the file will be read in real time
05:41:29 <codedmart> glguy: Ah that is the combination I needed.
05:41:45 <codedmart> Thanks!
05:51:42 <thblt> Hi, I'm not sure I know what I'm doing there.  I'm trying to write a typeclass with a parameter, with a single function that takes an instance of that typeclass as a parameter, and returns an instance of that typeclass' parameter.
05:51:52 <thblt> I'm writing it this way:
05:51:54 <thblt> class Page p => Site p where
05:51:54 <thblt>   sitePages :: Site s => s -> [p]
05:51:54 <thblt>  
05:52:45 <thblt> Is this correct?  (Is this even meaningful?)
05:52:46 <thblt> Thanks :)
05:53:27 <quchen> Does the compiler accept it?
05:54:02 * Maxdamantus doubts it.
05:54:40 <Maxdamantus> I imagine GHC will if you add a bunch of crazy options.
05:54:52 <thblt> Nope, Intero (Haskell IDE) doesn't report errors on this line when I write this you, but the build fails elsewhere.
05:55:04 <quchen> ?let class Page p
05:55:05 <lambdabot>  .L.hs:174:1: error:
05:55:06 <lambdabot>      Multiple declarations of ‘Page’
05:55:06 <lambdabot>      Declared at: .L.hs:169:1
05:55:09 <quchen> ?let class Page p => Site p where sitePages :: Site s => s -> [p]
05:55:10 <lambdabot>  .L.hs:174:1: error:
05:55:10 <lambdabot>      Multiple declarations of ‘Site’
05:55:10 <lambdabot>      Declared at: .L.hs:171:1
05:55:13 <quchen> Meh.
05:55:16 <quchen> ?undef
05:55:16 <lambdabot> Undefined.
05:55:18 <quchen> ?let class Page p
05:55:19 <lambdabot>  Defined.
05:55:20 <quchen> ?let class Page p => Site p where sitePages :: Site s => s -> [p]
05:55:21 <lambdabot>  Defined.
05:55:39 <Maxdamantus> thblt: think about the type declared for that method.
05:55:41 <quchen> There you go, it works. I don’t know what it’s supposed to do, but it’s valid Haskell. :-)
05:56:23 <Maxdamantus> Oh, oops, I read it at `Page p => Site s`
05:56:24 <thblt> Maxdamantus: that's what makes me think I'm wrong.  I feel like I'm not forwarding the "constraint" under the actual type for Page.
05:56:36 <thblt> Maybe I should explain the underlying problem, so you can tell me how wrong I am :)
05:56:36 <trigone> hi, if anyone uses GIT, i'd like to know something. i just started using it, and followed some tutorial
05:56:55 <thblt> I'm writing a kind of static site generator (I know there's Hakyll, but I'm trying to learn some Haskell mostly)
05:57:07 <glguy> thblt: start by not using a class at all
05:57:08 <trigone> which told me at some point to use "git commit", and now i'm in my editor and there are tons of text with hashes before
05:57:28 <trigone> am i supposed to remove the hashes or to write something above all this?
05:57:35 <codedmart> Is there a point free or better way to write this. I feel like I am missing something simple this morning `newtype AdminUser = AdminUser User; fmap (\(AdminUser a) -> firstName a) maybeAdminUser` expecting `Maybe Text`?
05:57:50 <lieven> trigone: just write something above all this. It will be the commit message.
05:58:00 <Maxdamantus> trigone: don't remove the hashes. They're comments that will be removed when the commit is actually made.
05:58:20 <nshepperd_> thblt: this says that every site is also a page, and that you can convert any instance of Site into a list of any other instance of Site
05:58:25 <trigone> lieven: ok thanks! so the rest is for the internals of git, right? i mean otherwise why to use it?
05:58:36 <thblt> nshepperd_: Definitely not what I had in mind
05:58:38 <trigone> i mean why to have comments generated if they're not used
05:58:51 <freeside> they're for you to read, not for git
05:58:55 <Maxdamantus> It's not for the internals of git. It's just to give you a summary while you write your commit message.
05:59:12 <thblt> What I meant was that every Site such as Page p => Site p must contain a single method of type sitePages :: Site p => [p]
05:59:12 <Maxdamantus> The lines starting with # are simply removed once you exit the editor.
05:59:21 <trigone> ok!! thanks, i get it now. it's pretty smart. thanks again for your quick help :)
06:00:00 <thblt> Is there a way to express something like this, or is it just me thinking it wrong?
06:00:34 <glguy> thblt: It sounds like you're trying to use Haskell's typeclasses like OO classes
06:00:37 <thblt> The underlying idea for Site being a class (the project is a kind of static site generator) is that it declares the bare minimum, and the user add whatever they need to their implementation (eg site name, whatever)
06:00:57 <thblt> glguy: I see, thank you.
06:01:10 <thblt> Would it make more sense to use something like:
06:01:47 <thblt> data Site p c = Site { sitePages :: (Page p) => [p], siteData :: c}
06:02:01 <thblt> where c is any type the user will want to provide which match what they need for *their* site?
06:02:06 <trigone> hey btw, wrt GIT, if i never made any link with the web servers, to commit a change will only save some snapshot on my machine, right?
06:02:21 <glguy> thblt: Perhaps; data Site p c = Site { sitePages :: [p], siteData :: c }
06:02:51 <glguy> thblt: The "Page p" part doesn't belong in the datatype you're defining
06:03:38 <thblt> guy: I think I see.  (Page p =>) belongs on my generator's functions where they need a special type for the sitePages to be able to do something with them?
06:03:49 <thblt> s/guy/glguy sorry
06:04:29 <Maxdamantus> trigone: right, unless you use something like `git push` (or someone else does `git fetch` or `git pull` on your repository), anything you do will just modify your own repository.
06:04:41 <glguy> thblt: Yeah, you only need the typeclass constraints when you need them. Keep in mind if you use this datatype that you can only have a single type of "page" per site
06:05:22 <thblt> glguy: Thank you.  Yes, having a single "Page" type is the idea, the point is that the user know what they need for their page so should write their own type.
06:06:26 <freeside> Typeclasses are like salt and pepper. A little goes a long way, but you don't want to build your meal around them.
06:06:37 <trigone> Maxdamantus: when you say my own repository, you mean offline locally? because in that case how could anyeone fetch what i have on my drive? they can't can they?
06:06:46 <nshepperd_> "class Page p => Site p s where { sitePages :: s -> p }" would be the correct way to do the typeclass thing
06:07:38 <thblt> freeside: thanks, I think I'm still too much stuck in OOP-style reasoning, I'm trying to make classes the whole meal and the wines :)
06:08:06 <freeside> yeah, i spent a long time trying to make sense of https://arxiv.org/pdf/cs/0509027.pdf before giving up
06:08:14 <merijn> Cabal sandbox question, suppose I have a directory with 3 (or whatever) cabal projects in subdirectories. Is there a convenient way to instantiate a single sandbox that they all use/build in?
06:08:19 <Maxdamantus> trigone: right, the one on your current filesystem. They can't unless they have access to your filesystem (or you're running git-daemon or sshd with access restricted to git-shell)
06:08:35 <trigone> Maxdamantus: ok, thanks again :)
06:08:51 <freeside> afaik nobody in the real world uses the OOHaskell library, so shrug
06:10:27 <nshepperd_> But, if the only thing the generator functions even do with a Site is call sitePages to turn it into a list of peeves
06:10:39 <nshepperd_> Pages
06:11:07 <nshepperd_> Then you might as well just pass them a list of pages and forget about Site
06:11:08 <phadej> merijn: cabal packages? "cabal sandbox add-source <path-to-dir-with-.cabal-file>"
06:11:26 <merijn> phadej: I know that, but that doesn't really share the sandbox, no?
06:11:46 <phadej> if you have single sandbox and add all three packages as a sources there, it will work
06:12:49 <thblt> nshepperd_: That's obvious now you say it... Thank you.  
06:13:25 <merijn> phadej: I'm trying to make it so that running caball in any of the subdirs ends up using the same sandbox
06:13:44 <phadej> merijn: also cabal init sandbox takes a path to existing sandbox
06:13:51 <thblt> nshepperd_: I had the idea that Site may hold user "custom" global values (the site name, whatever) but their place is clearly not with the set of pages.
06:13:51 <phadej> cabal sandbox init
06:13:54 <phadej> whatever it is
06:14:43 <phadej> cabal sandbox init --sandbox=DIR 
06:15:25 <phadej> but honestly, I'd just use cabal-install-head and new-build
06:15:49 <nshepperd_> If you need custom global values such as the site name you can have them, through the magic of closures
06:16:12 <merijn> phadej: I don't like being on the cutting edge of discovering new ways things aren't quite working yet >.>
06:16:24 <nshepperd_> Ie. Just have them in scope when defining your pages
06:17:20 <phadej> merijn: true, but many things already work
06:17:33 <phadej> at least I remember creating sandbox once this year
06:17:46 <phadej> for very specific need
06:20:42 <merijn> phadej: Welp...the cabal 2.0 docs site doesn't load for me, and I don't really know how it's supposed to be distributed, so that makes me hesistant to change my scripts to work with new-build :p
06:24:13 <ezyang> readthedocs does look down lol 
06:24:17 <ezyang> oh it's up now 
06:25:05 <merijn> ezyang: Not for me
06:25:12 <merijn> DNS error for all of readthedocs
06:26:11 <ezyang> well, I guess you could crack open the source file in Cabal repo ^^" 
06:26:18 <slack1256> what kind of programs don't benefit from parallel GC? 
06:26:38 <merijn> Actually, maybe an alternative for sharing the sandbox. How do I tell cabal to look for projects in places other than Hackage? Basically, I have a handful of related cabal packages that I wanna keep separate, but shouldn't go on Hackage
06:27:11 <merijn> They depend on eachother, so I want cabal to conveniently be able to find the others, but I'm not sure how to best accomplish that
06:27:23 <ezyang> merijn: This is *exactly* what new-build excels at 
06:27:48 <merijn> Except I have no way of learning how it works or how I'd even go about switching to cabal 2.0 :p
06:28:28 <ezyang> https://cabal.readthedocs.io/en/latest/ also broken? 
06:28:51 <merijn> ezyang: All of readthedocs.io is broken
06:29:04 <ezyang> http://webcache.googleusercontent.com/search?q=cache:1EvgVZ-J27QJ:cabal.readthedocs.io/en/latest/nix-local-build-overview.html+&cd=1&hl=en&ct=clnk&gl=us&client=ubuntu 
06:31:35 <merijn> ezyang: That doesn't help much, since all the links are dead unless I google cache those too. Any specific reason why the docs aren't simply hosted on the same machine as the old user guide/docs?
06:34:20 <phadej> merijn: http://cabal.readthedocs.io/en/latest/
06:34:37 <merijn> phadej: Welcome to 5 minutes ago :p
06:34:44 <phadej> :/
06:34:47 <phadej> maybe it had cold caches
06:35:02 <merijn> phadej: No, the DNS is fucked
06:35:17 <merijn> phadej: I'm getting DNS not resolved errors in Chrome and Safari
06:35:50 <phadej> and about why they aren't hosted on some machine: they will when 2.0 release is cut
06:36:06 <phadej> but readthedocs is useful for the /latest/, so we don't need to update them manually
06:36:18 <geekosaur> it loaded for me but took a bit (sadly I can't tell if that is local or remote)
06:38:41 <ezyang> Yeah, they will be hosted on the real website, but we haven't actually released 2.0 yet 
06:39:00 <ezyang> I wanted to setup continuous push to haskell.org but if we did that, the push process would also have access to, e.g., the GHC binaries 
06:39:05 <ezyang> it's a security problem 
06:39:41 <c_wraith> I'm glad you think of such things, unlike... some other projects
06:39:52 <Shockk> I have a quick question; what exactly does Haskell call the precedence that's given to infix/infixl/infixr? I ask because I notice that in other contexts, lower number means higher precedence / more tightly binding
06:40:07 <Shockk> whereas in Haskell, a higher number means it binds more tightly
06:40:18 <merijn> Shockk: eh...no?
06:40:24 <merijn> Shockk: higher precedence binds more tightly
06:40:42 <merijn> oh, wait, that's what you said :)
06:40:56 <Shockk> merijn: I know that, but I see conflicting numbering schemes, some contexts use a lower /number/ to indicate a higher /precedence
06:41:02 <mauke> Shockk: it calls it precedence
06:41:04 <merijn> Shockk: I'm not quite sure why you'd expect a different name?
06:41:05 <Shockk> ah okay
06:41:49 <Shockk> I just wondered if there's a general consensus in language development on ascending/descending precedence or not
06:42:07 <Shockk> thanks
06:43:03 <merijn> ezyang, phadej: I n general there's no easy method of providing local configurations to cabal unless you explicitly pass them into cabal configure, is there?
06:48:09 <phadej> merijn: configurations like?
06:48:12 <ezyang> what do you mean by local config? 
06:49:40 <jchia_2> Can I get a code review for this code that uses conduit & State? 25 lines. http://lpaste.net/356549
06:50:12 <phadej> merijn: you can add stuff to e.g. cabal.sandbox.config
06:50:51 <phadej> if you want to use sandboxes
06:52:16 <merijn> phadej, ezyang: Things like: packages are in this dir, build-dir should be here, etc.
06:52:40 <phadej> that sounds more what cabal.project does in new-build
06:52:57 <merijn> phadej, ezyang: I'm just trying to fit cabal into the (gmake) build system of my code
06:53:28 <merijn> phadej: ok, I guess I'll just have to put this off until the docs come back online
06:53:53 <phadej> though I don't know if dist-newstyle directory is configurable :D
06:54:08 <glguy> the docs are still inline, you might need to refresh something
06:54:13 <glguy> online*
06:54:39 <merijn> glguy: You're like the 5th person saying "they're online", but that's irrelevant, since the DNS isn't working so even if the machine is up I can't access it
06:55:04 <merijn> And I can't just grab the IP, because then I don't get forwarded to the right VHOST
06:55:09 <glguy> try a different dns then, Google has 8.8.8.8 for example
06:55:33 <jamiecook_> merijn: you can add a record to your /etc/hosts to allow vhosting to work
06:56:11 <jamiecook_> is anyone able to help with a noobie question?
06:56:14 <jamiecook_> http://lpaste.net/356551
06:57:07 <merijn> jamiecook_: hmm, I could try that, I guess
06:57:32 <ezyang> oh yeah, new-build is not really equipped to integrate with a bigger build system :( 
06:57:46 <glguy> jamiecook_: what's your question?
06:58:49 <jamiecook_> in that paste I am trying to modify readHex to run across multiple things at once 
06:59:21 <jamiecook_> basically  converting readHex :: a -> b to readHex [a] -> b
06:59:28 <jamiecook_> sorry [a] -> [b]
06:59:44 <jamiecook_> but i can't get my types to line up
06:59:46 <merijn> ezyang: Not being able to control the build location is not ideal, but I could live with that, I suppose
06:59:58 <ubuntu1> is there a more specific name for trees that look like directory trees: n leafs?
07:00:26 <quchen> ubuntu1: Rose trees
07:00:33 <ubuntu1> thanks!
07:00:36 <jamiecook_> the closest i can get is returning a [c]... and I have a function convertFromRaw :: c -> b
07:01:32 <glguy> jamiecook_: if you're going to paste code, include the imports. don't make us guess what everything is
07:02:03 <merijn> ezyang: It's rather unclear where people are supposed to get cabal2.0 from, btw
07:02:39 <merijn> ezyang: Is it supposed to be installed from, e.g., git?
07:03:09 <jchia_2> jamiecook_: What is Geos? Is it the monad type of your do blocks?
07:04:19 <jamiecook_> glguy: sorry about that... it's part of a fairly large library so i was going for terseness, probably could have put the bytestring import in though
07:04:36 <jamiecook_> jchia_2: yes exactly right
07:04:53 <jamiecook_> and I think i've just figured out what was staring me in the face
07:05:34 <jamiecook_> the conversion method also operates in the same monad
07:06:39 <jamiecook_> so while I was playing around with fmap and <$> ... what I needed was ANOTHER foldM
07:09:15 <jchia_2> jamiecook_: I can't tell the type of S.readHex. Is it the readHex you list from L1? Also, have you tried converting some parts of the code to holes (_) and see what type ghc thinks they should be?
07:11:02 <ezyang> merijn: At the moment, yes. There's also a copy you can get from hvr's PPA 
07:20:41 <mjacob> if i define some top-level value (which is necessarily constant i think), when will it be evaluated if compiling with ghc?
07:20:52 <mjacob> compile time, load time, or first use?
07:21:35 <glguy> mjacob: Either compile time or first use, depending on optimizations. There is no load time
07:21:35 <mjacob> something like `foo = 1 + 2`
07:21:44 <merijn> mjacob: Depends, what kinda constant?
07:21:57 <mauke> MR or no MR?
07:22:45 <jamiecook_> jchia_2: it is yes
07:23:00 <jamiecook_> and that's a great idea ... i should have thought of that
07:23:11 <jamiecook_> just kept on trying things that didn't work :)
07:23:36 <jamiecook_> thanks for your help... turns out it was traverse (not mapM) that I needed
07:26:05 <mjacob> merijn: the question was general.  the simple case would be `foo = 1 + 2` and a more complex example would be `main = putStrLn "Hello, World!"` whose right side is also a constant expression technically
07:26:46 <mjacob> mauke: was that referring to my question?  in this case i don't know what you mean by MR
07:27:32 <merijn> mjacob: Monomorphism restriction
07:28:02 <mjacob> in which case could that make a difference?
07:29:29 <mjacob> except that the compiler won't type check some stuff with MR that it would without MR
07:29:38 <freeside> (the dreaded)
07:29:40 <merijn> mjacob: No, that's not the difference!
07:30:12 <geekosaur> if it's polymorphic, it can't precompute it (at what types do you expect it to be precomputed?)
07:30:31 <c_wraith> geekosaur: just the most common 1000 or so
07:30:31 <merijn> mjacob: The difference between MR and no MR is: With MR you get loud compiletime complaints if you try and use something that looks like a value as two different types (which would stop it from behaving like a value), with no MR it silently works and your code might just be inexplicably slower
07:30:51 <merijn> The MMR is our friend and we should cherish him!
07:31:45 <quchen> Satanist!
07:31:48 <merijn> If you like trivial to fix compile time warnings, use the MMR. If you like debugging fake inexplicable slow downs, disable it...
07:31:55 <quchen> Devil worshipper!
07:32:19 <freeside> Job security!
07:32:28 <glguy> Liking the MR isn't controversial
07:32:45 <c_wraith> it's rare to actually hit one of those slowdowns, though.  It usually requires multiple modules be involved
07:32:55 <quchen> I know. It was a low-hanging fruit joke though.
07:33:07 <geekosaur> worth remembering is that a number can be more complex than you think. there are, for example, function instances of Num out there. and integral numeric literals desugar to fromInteger (theValue :: Integer)
07:33:16 <Cale> The monomorphism restriction can cause compile time *errors* which in some cases are quite sneaky.
07:33:22 <geekosaur> so no, there is no 'just do the obvious, they're just numbers'
07:33:29 <merijn> c_wraith: Sure, it's rare, but since the solution to monomorphism warnings is trivial, what's the point in avoiding it
07:33:57 <merijn> geekosaur: Just enable -fmake-it-so :)
07:34:03 <freeside> numbers can certainly be complex. it's not an imaginary problem. or rather it is.
07:34:26 <Cale> For example, try defining a function which would normally be Monad or Applicative polymorphic in points-free style, and neglect to give it a type signature before attempting to use it with some ST code.
07:34:54 <mjacob> Cale: would you say that the MR itself make some errors quite sneaky or is it the defaulting rules?
07:35:05 <Cale> mjacob: It's the MR itself in this case.
07:35:06 <c_wraith> that specific case is 100% MR
07:35:53 <Cale> You'll end up with complaints when you try to runST the resulting actions, but it won't be apparent why you shouldn't be able to.
07:36:43 <Cale> At least, last time I bumped into that, it wasn't at all apparent
07:37:18 <mjacob> do i understand correctly that conceptually the value definition will be "executed" at first use, and everything being executed at compile time is just an optimization?
07:37:25 <Cale> (now I would know to think about the monomorphism restriction as a possibility)
07:37:45 <Cale> mjacob: What is executed at compile time?
07:38:10 <mauke> mjacob: yes
07:38:14 <Cale> GHC does very little in the way of compile time evaluation
07:38:16 <merijn> I think he just means constant folding
07:38:35 <merijn> Cale: Yeah, but I think even GHC can manage "1+2" and if not, the LLVM backend definitely should
07:38:35 <mjacob> Cale: in the `foo = 1 + 2` it's obvious that executing `1 + 2` will only give benefits
07:38:39 <Cale> I think we could safely expect a lot more constant folding than presently takes place.
07:39:03 <merijn> mjacob: The problem is, you can't apply that logic to EVERY expressions
07:39:12 <merijn> mjacob: Because, if you do, it takes you weeks to compile a file :)
07:39:40 <merijn> mjacob: The hard part about super-compilation, constant folding, etc. is not "doing it", it's "how much can we do it before it takes a decade to compile some code?"
07:39:46 <mjacob> merijn: yes, i see that e.g. in the `main = putStrLn "Hello, World!"` example it doesn't really make sense
07:40:14 <merijn> mjacob: Why not?
07:40:32 <Cale> What we ought to be able to do is run the compiler in a mode where it just keeps finding new optimisations for us and storing them in a database, and as long as we don't touch particular definitions, it will continue to improve them over time.
07:41:04 <mauke> the putStrLn case ought to be simple
07:41:10 <sproingie> might sound silly, but what about JIT compilation?
07:42:40 <Cale> I mean the compiler will work for an indefinitely long period of time to find static optimisations that it could apply to a given codebase.
07:42:51 <Cale> Like, GHC-as-a-server :)
07:42:59 <mjacob> merijn: that would partially evaluate the whole stdio library (although in this very simple case it might not be a problem)
07:43:22 <merijn> mjacob: Why would it do that?
07:43:23 <sproingie> Cale: sounds like a good job for an OS
07:43:46 <Cale> sproingie: The OS doesn't have enough information though
07:43:57 <Cale> Unless we expect it to understand the source code
07:44:00 <sproingie> i mean as a haskell-based OS
07:44:33 <sproingie> obviously not replacing linux with it, but the idea of the runtime being this constant background service
07:45:00 <Cale> sproingie: Well, have you seen HaLVM?
07:45:10 <sproingie> heard of it, not looked at
07:45:40 <Cale> But what I'm talking about is sort of orthogonal to that -- though I suppose they might work rather well together
07:51:45 <mjacob> merijn: good question. :) what does "executing" `putStrLn "Hello, World!"` actually mean?  normal form?  head normal form?
07:52:03 <merijn> mjacob: We normally distinguish between "evaluation" and "execution"
07:52:04 <ph88> i try to use ghci break on exception, i type :trace and :back but it says  no more logged breakpoints  ..  how can i figure out where the exception has been thrown in my code ?
07:52:19 <merijn> mjacob: Evaluation is the way haskell expression evaluate to (weak head) normal form
07:52:25 <ph88> to  run i use   :main
07:52:57 <merijn> mjacob: "IO a" is really just an opaque datatype. It just happens that the RTS understands how to execute this datatype (thus running the program)
07:53:10 <sproingie> at the very least, it involves packing the string literal into some more optimal form regardless of overloaded string settings
07:53:20 <ph88> oh i think i found my answer on SO :)
07:53:20 <sproingie> since nothing else is going to take it apart after all
07:53:21 <merijn> mjacob: It makes perfect sense to think about "IO a" as any other value which can be evaluated to (WH)NF, put into data structures, etc.
07:54:17 <sproingie> though i guess that would require more optimal implementations of, say, putStrLn
07:54:33 <merijn> mjacob: Conceptually there's no problem with evaluating main to WHNF form at compile time
07:55:57 <sproingie> i still just tend to think of "IO a" as "impure a"
07:56:23 <merijn> sproingie: IO a is so much more :>
07:56:31 <merijn> First class IO is like one of the best things about haskell
07:56:48 <sproingie> perhaps not so much IO itself
07:57:06 <lambdamu> merijn: why?
07:57:45 <merijn> lambdamu: Well, for one thing, it obsoletes a whole lot of things that in other language require all sorts of dependency injection nonsense
07:58:55 <Cale> lambdamu: You can invent your own control structures without need for the awkwardness of macro systems.
07:58:56 <sproingie> not sure where DI comes in
07:58:56 <mjacob> merijn: ok, i see how i was wrong with my assumption that evaluation of `putStrLn "Hello World"` would partially evaluate the stdio libary
07:59:42 <merijn> sproingie: Coming up with examples on the fly is hard!
08:00:15 <lambdamu> merijn: You mean things like the with/bracket/etc patterns we have? True that would be akward without first class IO
08:00:21 <sproingie> my beef with IO is that it's such an overflowing junk drawer
08:00:25 <merijn> lambdamu: Well, one example I have is needing to abstract across channel types for some benchmarks. Solution: Just wrap the channels into a closure and store the operation inside a datatype: https://github.com/merijn/broadcast-chan/blob/master/benchmarks/Channels.hs#L51-L56
08:00:30 <Cale> lambdamu: yeah, that's one class of examples
08:00:31 <merijn> sproingie: Oh sure, it could certainly be nicer
08:00:33 <mjacob> but back to my original question, when ignoring optimizations, would the right side of the top level definition only ever be evaluated at first use?
08:00:46 <merijn> mjacob: "It Depends (TM)"
08:00:57 <sproingie> i wrote a DI framework called ItDepends
08:01:10 <Cale> Right, abstracting over how writing to a channel takes place is something that I now *always* do whenever I would otherwise be using Chan (or many of the cases where I would use MVar)
08:01:20 <merijn> mjacob: Sometimes GHC decides "This looks cheap to compute" and decide that forcing it to only be evaluated once is too expensive and allow multiple evaluations in parallel
08:01:37 <sproingie> i renamed it to Fuel later (Fuel Injection, get it?)
08:01:41 <Cale> It's so nice when later you want to add logging to what gets communicated over the channel, and you then only have to change the code in one place.
08:02:40 <Cale> There was a time when I was working on a video game in Haskell, and that actually let me create a replay system basically for free, which was great for testing purposes
08:03:28 <merijn> lambdamu: In general stuff that in many other languages requires defining some interface that you're specific instance can inherit from to make parameterising over IO possible is just "pass a value in haskell"
08:04:28 <Cale> (To save a replay, just store everything which was sent over the channel used for user input, which already included timestamps, and write it into a file, and then to replay, write all the stuff which was recorded in the file into the channel.)
08:04:32 <merijn> lambdamu: Imagine, you want to write a protocol handler than reads stuff in from either files, sockets, pipes, haskell channels, etc. in most language you'd define an interface, write wrappers for all these things to implement that interface, and then write your code with that interface
08:04:55 <sproingie> instance IO a => GameAction a ; instance TestAction a => GameAction a ; that sort of thing?
08:05:09 <merijn> lambdamu: In haskell you just write a function "IO String -> IO YourResult" and anyone can pass in anything they want
08:05:19 <mjacob> merijn: ok, thank you (and all the others as well)!
08:05:46 <Cale> sproingie: No, not type classes... I'm talking about the communication between the thread which consumes user input and the rest of the game
08:05:53 <merijn> lambdamu: Wanna work with a file? "hGetLine myFile", socket? "recv mySocket", etc.
08:06:41 <sproingie> wanna eat up all your RAM?  hGetLine and the rest of lazy I/O
08:06:57 <ventonegro> Most languages abstract away the IO source...
08:07:25 <lambdamu> merijn: Hm somehow I don't use IO like that
08:07:36 <Cale> sproingie: So, rather than just creating a Chan or TChan or something, and passing the Chan off to the thread which handles input, instead we pass writeChan :: UserCommand -> IO ()
08:07:45 <Cale> as an argument
08:07:58 <merijn> lambdamu: It depends a lot on what kinda code you write :)
08:08:07 <Cale> So (the thing which spawns) that thread is parameterised by how to actually write to the channel
08:08:16 <lambdamu> merijn: But the control structure argument is convincing
08:08:31 <Cale> and so adding some logging is easy -- just pass it an action which also writes to the log while writing to the Chan
08:09:01 <merijn> lambdamu: Honestly, I write a lot of very imperative Haskell, so lots of IO everywhere and first class IO is really one of the things making Haskell my favourite imperative language :)
08:09:08 <sproingie> so the channel itself is an implementation detail of the function arg to writeChan?
08:09:19 <Cale> sproingie: That's right
08:09:28 <sproingie> Cale: sounds downright functional ;)
08:09:42 <merijn> sproingie: That's exactly what's going on in the benchmarks I linked earlier
08:09:52 <Cale> sproingie: Also, that lets you experiment easily with other blocking semantics -- e.g. perhaps you'd like to try a bounded channel, or even an MVar
08:10:12 <Cale> sproingie: In a lot of situations with concurrency, you're not quite sure what the best communication structure would be
08:10:23 <Cale> and so abstracting from the beginning can be a good idea
08:10:24 <sproingie> i guess i kinda did that when i was all gung ho about actors, i always passed a "channel adaptor object" in
08:10:31 <lambdamu> merijn: Well the problem is IO is as opaque as it gets and I encounter few situations where I can work with basically any IO, it's mostly just exception handling / resource cleanup
08:10:36 <sproingie> in test code, the adaptor had no channel at all, just a log
08:10:54 <sproingie> this was pretty easy to fudge in python of course
08:11:08 <merijn> lambdamu: Yeah, like I said, it depends on the code. I do a lot of stream processing of files, SQL results, lots of forking to parallelise things, lots of networking, etc.
08:15:16 <freeside> speaking of doing in haskell what used to be done in Perl ...
08:15:25 <freeside> is there a best practice for the following STDIN processing idiom?
08:15:29 <freeside> whileNotEOF x = do eof <- isEOF; if eof then return () else do x
08:15:29 <freeside>     
08:15:29 <freeside> main = whileNotEOF $ do
08:15:42 <freeside>    ...
08:16:28 <sproingie> "main = whileNotEOF $ do" looks pretty nice to me
08:16:33 <freeside> i tried to do a `guard (not eof)` but that spits out an mzero error under 8.0.2 upon ^D
08:17:54 <sproingie> maybe using whileM for more flexibility of conditions
08:18:47 <freeside> thanks
08:19:03 <Cale> freeside: many!
08:19:06 <Cale> :t many
08:19:07 <lambdabot> Alternative f => f a -> f [a]
08:19:42 <Cale> I wish there were a many_ but it's possible to write that pretty easily as well
08:20:22 <Cale> IO is an instance of Alternative where x <|> y will use y as a sort of exception handler for x
08:20:45 <freeside> i just want the program to exit silently upon eof
08:20:46 <Cale> It's a bit hacky given that it'll catch anything, but for quick work, it's rather nice
08:21:11 <Cale> I mean, many can be used as a "whileNotEOF"
08:22:06 <freeside> intriguing
08:22:13 <freeside> let me try to enspell the correct incantation
08:23:12 <Cale> Try something like  main = do xs <- many getLine; print xs
08:23:57 <Cale> Note that it's not lazy in any way -- it'll consume all the lines, and keep them all in memory here
08:24:07 <Cale> But you could move the print xs inward
08:24:20 <freeside> i was hoping to do line by line, in an interactive terminal
08:24:20 <Cale> er, well, you could move *some* kind of printing inward :)
08:24:40 <Cale> many will continue to run any action repeatedly until there is an exception
08:25:04 <Cale> It collects a list of the results of the action, which you can discard if you're not interested in them
08:25:27 <Cale> If your program is really long running, you may want to write a variation on many which doesn't collect the results of the actions
08:26:42 <Cale> many_ x = some_ x <|> return (); some_ x = x >> many_ x
08:27:33 * freeside scratches head
08:27:35 <Cale> main = many_ $ do x <- getLine; print x
08:27:36 <dreams> Any simple way of reading end tail of file as it is being update like tail -f?
08:29:09 * sproingie ponders an appropriate english word for many_
08:31:09 <freeside> thanks Cale, i have it working in the simplest possible way: main = many $ do ...
08:31:29 <freeside> don't really need a many_
08:31:33 <Cale> freeside: Yeah, the only issue with doing that is that it will very slowly leak memory
08:31:39 <sproingie> simple way to tail -f a file is polling.  ideal way is inotify.
08:32:10 <sproingie> https://stackoverflow.com/questions/41230293/how-to-efficiently-follow-tail-a-file-with-haskell-including-detecting-file
08:33:10 <Cale> freeside: whereas many_ doesn't attempt to build a list of the results, so it avoids that
08:33:20 <Sornaensis> how do I get a job using haskell all day
08:33:21 <Cale> I don't know why it's not in Control.Applicative :)
08:34:01 <dreams> Sornaensis: https://jobs.functionalworks.com/
08:34:09 <Sornaensis> thanks
08:34:38 <dreams> sproingie: thanks. Came across it but thought its a bit ugly.
08:35:15 <Cale> Sornaensis: One thing I think helps a good deal with the employers who exist is if you can show some code that you've written -- at least, whenever I've been involved in a hiring process, people's github repos or whatever other code they've provided has been a major factor in deciding who to pick
08:36:28 <dreams> Sornaensis: also https://news.ycombinator.com/item?id=14460777 - look for Haskell
08:36:55 <dreams> I think its hard to get a Haskell job, specially junior level. 
08:37:21 <sproingie> there's not a lot of entry-level haskell jobs, no.  you sort of have to sneak haskell in.
08:38:07 <sproingie> jobs where you write small tools for internal use are great for that sort of thing.  often they don't care what you write them in.
08:38:29 <freeside> hm, i'm going to need to write one of these hiring posts in the next year or so, i think.
08:38:58 <freeside> what i'd really like to do is post saying "in 6 months i want to hire someone with the following skills, and if you don't already have those arrows in your quiver here are some resources to go study".
08:39:44 <dreams> sproingie: yeah but not sure if that will qualify for mid-level/senior Haskell; wrote some X tool for parsing Y in Haskell is not gonna cut it.
08:40:31 <ph88> is there any way to get a slice of a vector but keep the indices the same as the original vector? For example when i have these values 8 4 1 2 9 7  and i get slice  1 2 9  i still want 1 to have index 2 (8 was index 0)
08:40:33 <freeside> fortunately, i've already written the "things to study" page: SAT/SMT, BNFC, GF, and 4 months of reading papers in computational linguistics and legal contract formalization.
08:40:36 <ventonegro> sproingie: heh, I'm doing that as we speak...
08:41:31 <glguy> ph88: If you want the same indexes, then just use the original vector
08:41:41 <sproingie> dreams: "wrote some X tool that's now a vital piece of infrastructure" always looks good
08:41:43 <ventonegro> Very simple tool with cgi and sqlite-simple
08:41:50 <glguy> ph88: vector doesn't let you pick a different indexing scheme. You need the array package for something like that
08:41:58 <ph88> glguy, ye but then i can not apply operations to only part of the vector .. like finding the maximum value
08:42:24 <glguy> ph88: Right
08:42:37 <dreams> sproingie: Scala is the alternative for me, way more job postings. Support for functional style. 
08:42:43 <ph88> so i shot myself in the foot using Vector then ?
08:42:47 <freeside> https://hackage.haskell.org/package/sparse-lin-alg-0.4.3/docs/Math-LinearAlgebra-Sparse-Vector.html ?
08:42:58 <sproingie> dreams: sure, don't limit yourself to a single language.  scala has a lot of opportunities.
08:43:09 <maerwald> scala isn't even functional
08:43:13 <maerwald> it's worse than java
08:43:22 <sproingie> uninformed opinion noted
08:43:24 <ventonegro> shots fired
08:43:33 <maerwald> sproingie: lol, I've done webdev in scala xD
08:43:36 <ph88> how does vector and array compare in performance ?
08:43:37 <Clint> how is anything worse than java?
08:43:46 <glguy> Java and Scala are offtopic in #haskell
08:44:09 <dreams> maerwald: If you like Java then Scala is better than Java. 
08:44:18 <sproingie> as have I.  scala has some warts, but it ain't php
08:44:22 <dreams> maerwald: *If you like Java then Java is better than Scala. 
08:44:40 <sproingie> if you like Blub, then Blub is better than NotBlub
08:45:07 <maerwald> it's not about liking, it's about how a language is maintained and how strict their policies are to introduce random features and inconsistencies
08:45:08 <sproingie> instance Ord a => ValueSystem a
08:45:25 <ph88> glguy, i hardly see any convenience functions on array https://hackage.haskell.org/package/array-0.5.1.1/docs/Data-Array-IArray.html
08:45:44 <dreams> maerwald: well then why Twitter, LinkedIn..etc are migrating to Scala?
08:45:53 <maerwald> dreams: HDD
08:45:56 <dreams> from Java that is.
08:45:59 <dreams> HDD?
08:46:03 <glguy> dreams: When I said Scala was offtopic I meant that you aren't welcome to chat about it here
08:46:04 <maerwald> hype driven development
08:46:14 <dreams> maerwald: lol
08:46:15 <sproingie> come to think that type class instance i gave is reversed
08:47:08 <dreams> maerwald: which framework did you use for web?
08:47:20 <sproingie> might want to take the scala stuff to PM
08:47:21 <maerwald> we were just told to be offtopic
08:47:41 <dreams> fine
08:47:58 <wespiser> I use Scotty for web servers
08:48:05 <wespiser> its great, i love Haskell so much
08:48:22 <ph88> how can i get all the convenience functions of Vector with Array ?
08:48:35 <mnoonan> argh, I'm trying to clean up something with lenses (microlens), but the type errors are killing me
08:49:01 <wespiser> mnoonan: yea, that's the reason I don't use lenses
08:49:09 <mnoonan> I just want a utility function that looks like this: "pop stack = do { (_ : rest) <- use stack; stk .= rest; }"
08:49:33 <wespiser> mnoonan: its a little ignorant, but I can't help but feel like I'm adding more complexity when using lenses than I am solving
08:49:39 <mnoonan> but it's complaining that 'stack' in the .= is a Getting [t] s [t] instead of an ASetter s s [t] [t]
08:49:50 <glguy> mnoonan: You're using 'stack' at two different types
08:50:16 <glguy> mnoonan: You can either use cloneLens on the argument or take a ReifiedLens, or use a Rank-2 type for pop
08:50:55 <mnoonan> glguy: hmm, I didn't know about ReifiedLens.
08:52:19 <mnoonan> for the rank-2 type, I assume I'll have to give an explicit type signature?
08:53:00 <glguy> Yes, higher-ranked types are not inferred
08:54:03 <mnoonan> argh, I just saw that I had also typo'd LANGUAGE to LANGAUGE in the RankNTypes pragma :|
08:54:22 <shapr> I've done that, it's frustrating
08:54:40 <shapr> maybe haskell-mode or intero-mode could check for that?
08:54:42 <shapr> or haskell-stylish?
08:54:54 <mnoonan> -Wnot-quite-a-pragma
08:54:59 <shapr> heh
08:55:01 <ReinH> Does hlint catch it?
08:55:23 <glguy> mnoonan: -Wunrecognised-pragmas
08:55:32 <shapr> Is that really a thing?
08:55:59 <sproingie> sure ought to be
08:57:48 <sproingie> looks like it's an error by default, actually
08:58:12 <sproingie> foo.hs:1:14: error: Unsupported extension: Fooblah
08:58:27 <mnoonan> -Wunrecognised-pragmas didn't seem to catch it
08:59:22 <maerwald> it probably only catches LANGUAGE RankXXXType
08:59:31 <maerwald> not when you typo language itself
08:59:55 <glguy> Demo.hs:1:1: warning: [-Wunrecognised-pragmas] Unrecognised pragma
09:00:04 <glguy> It notices misspelled language
09:02:00 <sproingie> seems anything inside {-# #-} gets properly parsed
09:02:41 <sproingie> looks like that wasn't always the case
09:13:58 <mnoonan> got there with the explicit rank-N type signatures, thanks glguy
09:14:12 <mnoonan> the signature is as long as the implementation :)
09:16:34 <sproingie> rank-N Bass
09:33:43 <glguy> mnoonan: Another solution is not to use the argument twice, http://dpaste.com/19KTS9A
09:34:52 <mnoonan> I considered that too, but I'm currently at lens operators of length <= 2.
09:35:03 <glguy> Ah, bummer.
09:38:11 <glguy> popOf l = zoom l $ do x:xs <- get; put xs; return x
09:38:24 <glguy> You didn't have any rules against letters z or p?
09:38:39 <glguy> oh, p is certainly allowed, the original was named pop
09:50:27 <NemesisD> hey folks. i've got a need for a little single use case DSL that lets you specify steps of a job. reqts are 1. it needs to be able to resume a job and fast-forward to the correct step, 2. need a full monad, 3. it needs to be able to "save" the job between steps and peek the next step. my first attempt uses a free monad https://gist.github.com/MichaelXavier/5e3554416d48675c2fa05191d788629c
09:50:58 <NemesisD> does this seem like a reasonable solution to you all or is there something better i should consider?
10:01:19 <dtornabene> question about the stack ghci command;  how do i get it to load a different version of ghci outside of a project?
10:04:05 <MarcelineVQ> the resolver determines that, specify the resolver you want either by  stack ghci --resolver=lts-7.15 (or wichever version)   or by setting the resolver in .stack/global-project/stack.yaml to the one you'd like to use
10:04:32 <MarcelineVQ> the front page here https://www.stackage.org/ suggests different resolver versions to use depending what version of ghc/ghci you want
10:04:38 <dtornabene> thank you!
10:10:28 <ph88> how can i find the maximum value in an array ?
10:10:56 <NemesisD> ph88: Data.Foldable.maximum
10:11:34 <NemesisD> ugh, Data.Foldable.maximum is partial?!
10:11:35 <ph88> how can i get the maximum value with it's index ?
10:12:24 <ericshortcut> Prelude> let f = \xs -> foldl max 0 xs
10:12:25 <ericshortcut> Prelude> f [1,10,8,3]
10:12:30 <NemesisD> ph88: what actual data structure are you using? list, vector?
10:12:47 <ph88> NemesisD, i'm using Vector but i'm considering to switch to Array
10:13:04 <NemesisD> ph88: vector has maxIndex and lookup should be O(1)
10:13:22 <ph88> ye i know about vector since i'm already using it
10:13:46 <merijn> ph88: Why would you wanna switch to Array?
10:14:10 <ph88> because when i make a slice of the vector it doesn't correlate to the indices of the original vector
10:14:50 <NemesisD> wow, Array's API is pretty sparse
10:14:59 <ph88> i know right :/
10:15:33 <NemesisD> i guess it probably wants you to use what foldable provides, and the maximum there doesn't know about indices (and is also unsafe, love that prelude)
10:15:57 <NemesisD> could you zip your array with [0..] and then use foldable's maximum, perhaps?
10:15:58 <ph88> my use case is that i need a lot of windows (also sliding windows) into a vector and find the min/max value with it's index, but i need that index to correlate back to the original vector to be able to compare and combine windows
10:16:10 <NemesisD> then maximum would give you (idx, val)
10:16:25 <ph88> zip with linked list ?
10:16:33 <NemesisD> and i guess you'd have to use maximumBy snd
10:17:04 <ph88> i can do the same with the Vector to keep the original indices
10:17:10 <NemesisD> well you'd construct an array with that range i guess
10:17:43 <NemesisD> i guess array doesn't give you zip either
10:18:00 <NemesisD> yuck
10:18:21 <ph88> ye it's becomming very ugly
10:20:13 <ph88> ok i guess i will make the original vector of type (Int, Double) instead of Double where Int is the index :\
10:20:30 <ph88> ew
10:20:44 <NemesisD> well you only have to do that for your operation, yeah?
10:20:54 <ph88> what do you mean ?
10:21:20 <NemesisD> like at the moment that you need this maximum you could lazily construct this vector of tuples from the vector of doubles in order to find the maximum idx + double pair
10:21:49 <NemesisD> wait so you're not going to use Array?
10:21:58 <ph88> i wanted to use Array but i don't know how
10:22:07 <cocreature> ph88: which operations do you want to call on the sliced vector?
10:22:10 <ph88> i need to find the maximum with the index it's at
10:22:17 <ph88> and also the minimum
10:22:36 <NemesisD> ok well if you're back on vector you can do both of those with just the vector API
10:22:43 <NemesisD> without having to zip anything
10:23:05 <ph88> right now i'm making slices, do indexing with VU.!! (VU Vector Unboxed) and do folds
10:23:09 <cocreature> you just need to keep track of which index in the original vector index 0 in the sliced vector corresponds to
10:23:17 <cocreature> so just wrap it in some type which does that
10:23:35 <cocreature> implement wrappers for min and max which return the adjusted index and you’re done
10:24:04 <ph88> that was my first idea ..
10:24:09 <ph88> i will try it then ^^
10:24:35 <ph88> but it still seems ugly because when i make a slice it's reindexed and then i do artheritmic myself to convert it back to the original index :/
10:25:22 <cocreature> well you can also do the slicing yourself
10:26:01 <cocreature> which is not too hard, just make something like "data Slice a = Slice { originalVec :: Vector a, start :: Int, length :: Int }"
10:26:59 <cocreature> but unless your index calculations are really causing problems I wouldn’t worry about it
10:28:17 <Akii> one question: Maximum is a Monoid, so in this case wouldn't it be possible to traverse with a pair (???, Maximum) to get the index and maximum?
10:28:26 <Akii> if so, what would be the appropriate Monoid to use
10:29:10 <Akii> I can't think of a way of doing that
10:29:42 <merijn> Akii: Max is a semigroup, not a Monoid (what'd mempty be?)
10:29:48 <Akii> yes, sorry
10:30:20 <merijn> Akii: However, there is monoid-extras which has a monoids for max/min with an additional positive/negative infinity
10:30:31 <Akii> just replace monoid with semigroup above :D
10:31:21 <Akii> doesn't work with the pair though; I guess one could make a newtype MaximumWithIndex = MWI (Int, Int)
10:31:25 <merijn> Akii: Data.Semigroup (from base or semigroups, depending on GHC version) has a min/max semigroup
10:31:36 <Akii> I know ^^
10:32:11 <Akii> ph88 wanted the maximum with index
10:32:15 <Akii> sounded like a semigroup to me
10:33:08 <cocreature> Akii: but they want the index in the _original_ vector while they are only calculating the maximum on a slice of that vector
10:35:22 <ph88> cocreature, ok i will go ahead with that idea. It doesn't really sit right with me, but it seems the best so far. I'm trying to reduce calculations in other areas (especially on folds on vectors) so the index calculations would get more significant if i'm able to reduce the workload in other parts
10:38:10 <ph88> cocreature, i have this function i use mostly (i have others but this is an important one)  https://bpaste.net/show/c3985729db4d  what did you mean with implement wrappers ?
10:39:29 <Akii> this is what I had in mind http://lpaste.net/356558
10:40:05 <Akii> obviously doesn't work
10:41:14 <ph88> Akii, maybe you need a comparison function there ?  and add  Ord a   .. look at my paste i did the same
10:41:32 <Akii> yes but that'd be cheating
10:41:34 <cocreature> ph88: you can implement this function for your custom vector slice type by calling your current function and then adjusting the result by adding the index
10:41:53 <cocreature> Akii: it’s not cheating, your current function is just too general
10:41:57 <Akii> the issue is a) it is unknown what Semigroup a does
10:42:14 <Akii> and b) one cannot observe it
10:42:20 <Akii> unless you add a constraint like Eq
10:42:31 <Akii> and even then it would only really work on things like Max/Min/Last/First
10:42:38 <cocreature> if the Semigroup instance of a does not just choose one of the values but actually combines them to something new, the index makes no sense
10:42:45 <Akii> yep
10:42:58 <Akii> this only makes sense with a limited amount of semigroups
10:44:23 <cocreature> basically semigroups that you can implement in terms of an "a -> a -> Bool" function which tells you which element you need to choose
10:48:37 <nshepperd_> Ord a => Ord (Ix a)
10:49:22 <nshepperd_> Then you can use the normal maximum / minimum functions
10:55:01 <Akii> lol, just implemented sconcat just to find out that it already exists
10:55:54 <jared-w> lol, nice
10:56:22 <jared-w> for some reason google keeps wanting to not give me wikipedia pages and if it gives me them, it's in like german or french or something...
10:57:04 <Akii> http://lpaste.net/356558
10:59:43 <ReinH> as an aside, I'd prefer data Indexed a = Ix Int a and zipWith Ix [0..]
10:59:50 <nitrix> Can I easily have a parsec parser that tries to apply a given parser and if it succeeds, it continues to apply the same parser after, but if it fails, it just drops the first character and tries again?
10:59:59 <[exa]> jared-w: I had the same problem, well in fact, try duckduckgo
11:00:03 <nitrix> I'd also like to collect all the successful parses.
11:01:09 <ReinH> Hmm. You can certainly write a law-abiding Semigroup for Indexed a, but would its behavior be useful? It sounds like you want to use the monoid instance for ordered lists instead.
11:01:47 <ReinH> i.e., newtype Merge a = Merge [a] and <> is merge.
11:03:44 <ReinH> Or perhaps newtype IxedList a = [Indexed a] for ordered, indexed lists and a monoid instance that updates the indices.
11:04:18 <jared-w> also, I hate "error"; I much prefer just leaving it undefined.
11:04:39 <jared-w> To me, "error" means "I have /literally/ no other way to handle the error and I want the program to explode if this happens" which is what undefined does already
11:04:54 <Akii> it's just a thought experiment of mine
11:05:03 <ReinH> Wait, that isn't a monoid because it isn't associative.
11:05:21 <Akii> everyone hates error
11:05:24 <ReinH> Hmm. Maybe it is associative. It certainly isn't commutative.
11:05:33 <kadoban> jared-w: undefined means I haven't gotten around to defining it yet.
11:05:44 <ReinH> jared-w: Yes, but sometimes you want a nicer error message.
11:06:10 <ReinH> If you're using it for anything other than "blow up with a specified error message", you are using it wrong anyway.
11:06:38 <dtornabene> back again: I've got an older version of ghc installed via stack but I can't seem to find the right incantation of arguments to get an interpreter via that older ghc version outside of a project
11:06:41 <jared-w> So then handle it with a better error format like Maybe, Either, or something else? idk, if the point of error is "this is never going to happen" then why bother using it when undefined does the same?
11:06:56 <ReinH> jared-w: Again: because it lets you provide a better error message.
11:07:07 <dtornabene> so: what is the command/args for invoking the non-default ghci via stack?
11:07:11 <kadoban> dtornabene: stack ghci --resolver lts-2.22 (or whatever old resolver you want)
11:08:08 <ReinH> You aren't arguing against error. You're arguing against using bottom for error handling, which is a straw-man. Everyone agrees that you shouldn't use bottom for error handling.
11:08:12 <dtornabene> kadoban: thank you so much! this was crazy making, much appreciated.
11:08:20 <aj013> hello, i install a package with cabal using a sandbox, what option do i need to run on ghci so i can import it? Thanks
11:08:24 <kadoban> You can also specify --package foo --package bar  if you need packages, which doesn't seem to be as well known as it should be :)
11:08:47 <ReinH> > head []
11:08:49 <lambdabot>  *Exception: Prelude.head: empty list
11:08:50 <ReinH> That's a use of error
11:08:55 <ReinH> would you prefer it to just say
11:08:58 <ReinH> > undefined
11:09:00 <lambdabot>  *Exception: Prelude.undefined
11:09:16 <Akii> what have I done :D
11:09:41 <ReinH> error is for bottoms that you want to give a better error message.
11:09:41 <dtornabene> kadoban: do you know if its possible to get even older versions of ghc than 7.8.4 from stack? I'm trying to use it setup an environment to use older books to study from
11:09:45 <ReinH> It is perfectly suited for that use.
11:10:16 <kadoban> dtornabene: You can't get stack to install them for you, but if it's on your PATH you can trick stack into using it if you really want. So ... stack doesn't really help much.
11:10:22 <dtornabene> specifically Real World Haskell and the first version of Programming in Haskell both of which are near ten years old
11:10:43 <ReinH> dtornabene: Strongly recommend that you not do that.
11:10:44 <jared-w> mmm, okay; makes sense
11:10:51 <dtornabene> kadoban: ha, thanks, yeah I wanted to avoid the unix-y hacks as much as possible
11:11:03 <kadoban> There's no stackage snapshots using older GHCs or those old libraries either. So yeah, it's not a recipe for any kind of fun.
11:11:07 <dtornabene> ReinH: What do you mean?
11:11:15 <jared-w> dtornabene: Why can't you just get Programming In Haskell (3rd edition)?
11:11:18 <ReinH> dtornabene: you should use modern learning materials and modern GHC.
11:11:32 <ReinH> Rather than learn something that is already obsolete.
11:11:36 <dtornabene> right, but, I'm pretty broke at the moment
11:11:42 <ReinH> @where learnhaskell
11:11:43 <lambdabot> https://github.com/bitemyapp/learnhaskell
11:11:45 <jared-w> I do recommend Haskell From First Principles over that, anyway.
11:11:47 <ReinH> Lots of free materials.
11:11:58 <ReinH> Hutton's new book is fantastic.
11:12:29 <jared-w> Which book is Hutton's?
11:12:44 <ReinH> dtornabene: You'd have more luck trying to convert Hutton's old edition's code to modern GHC. It isn't very far off.
11:13:10 <ReinH> RWH would be much harder to convert.
11:13:14 <dtornabene> ReinH: i figured it was going to be something like that, seemed like a good learning experience as well
11:13:44 <ReinH> Or Introduction to Functional Programming Using Haskell by Bird.
11:13:56 <jared-w> small rant: I think it's slightly ridiculous that the "learning material" on the sidebar of r/haskell is useless
11:13:59 <dtornabene> ReinH: I'll start with the hutton book then, I've been relatively surprised by how many people have warned me off of RWH at this point
11:14:10 <ReinH> jared-w: I don't think anyone here is in control of that.
11:14:13 <kadoban> RWH I think is mostly about old libraries, which would probably still work with GHC 7.8.4 or something. I bet there's some invocation of stack that would work, but it'd probably be a pain in the ass to figure out.
11:14:22 <jared-w> Stack overflow, RWH, LYAH, seriously? /that/ is what we suggest to people?
11:14:44 <ReinH> dtornabene: It was a good book 10 years ago, but since it focuses on the "real world" it is much less future proof than a book like Hutton's which focuses on general principles.
11:14:54 <ReinH> It has to recommend certain libraries and such, which go out of date.
11:14:56 <kadoban> LYAH is pretty bad. RWH is interesting for what it is, but I didn't have great luck learning from it as a primary source, and now it's badly out of date with respect to libraries and such.
11:14:58 <dtornabene> ReinH: makes sense
11:15:08 <Clint> jared-w: there are a lot of people who are in denial about RWH being utterly obsolete
11:15:35 <ReinH> Modern Haskell is pretty similar to Haskell 1998 as a language, at least the core language.
11:15:38 <jared-w> It's got like 2 useful sections in the book and even then, only sort of useful. Everything else is garbage now. Which is a shame
11:16:10 <ReinH> If you read RWH for its advice on how to solve problems, it's still pretty good.
11:16:15 <dtornabene> i'm also going to use Thinking Functionally with Haskell, the Bird book, via safarionline
11:16:21 <ReinH> If you read it for code you can copy to apply that advice, it is not good at all.
11:16:36 <Akii> dtornabene: you could contact bitemyapp about getting a discount for the book
11:16:38 <dtornabene> ReinH: then that is what I'll do. 
11:16:43 <Akii> worth a try imo
11:16:47 <ReinH> dtornabene: Bird's new book is essentially a rewrite of Intro to FP Using Haskell, which is my favorite programming book.
11:16:57 <ReinH> The new one is also extremely good.
11:17:06 <dtornabene> ReinH: I've read the first chapter and its *excellent*
11:17:13 <jared-w> Right, which tells me you could probably write a much smaller and condensed version of RWH all about approaching problems and with far less code
11:17:15 <dtornabene> very pleased with it
11:17:16 <ReinH> It takes a very different tack than bitemyapp's. Hutton's is somewhere in between.
11:17:28 <dtornabene> Akii: i appreciate the thought, maybe something I can do
11:18:09 <jared-w> ReinH: is it the 2014 Thinking Functionally  With Haskell that you're talking about?
11:18:12 <dtornabene> ReinH: I took to it, very much so, enough to be excited about discovering the rest of the book as I go
11:18:26 <ReinH> dtornabene: A combo of Bird's and Hutton's new books and Marlow's Parallel and Concurrent Prorgamming in Haskell (which is free would be my current recommendation for someone wanting to learn Haskell and willing to buy some books.
11:18:35 <ReinH> whoops, missed a ')'
11:18:58 <jared-w> ReinH: why don't you recommend HFFP? Just curious
11:19:21 <dtornabene> fwiw, I took a detour into OCaml after a few frustrating weeks, and it helped immensely in clarifying type-driven programming
11:19:30 <ReinH> It's a very good book, but I prefer the style of Bird and Hutton's books.
11:19:44 <ReinH> I think they do a better job of teaching you "The Haskell Way".
11:19:50 <dtornabene> ReinH: I'll do it, as I already have the hutton book, and can access the other two
11:19:59 <ReinH> It depends to a large extent on how you like to learn.
11:20:03 <jared-w> dtornabene: if you think that's amazing, check out the Idris Type Driven Development book
11:20:15 <ReinH> HFFP is more focused on pragmatics
11:20:17 <dtornabene> jared-w: Looking forward to that one
11:20:27 <ReinH> The Idris book is excellent.
11:20:50 <jared-w> ReinH: makes sense. I've really liked the HFFP book personally because I needed something to just commit to and run through and get down into learning stuff. I really needed some pragmatics it appears
11:21:00 <dtornabene> I'm very much into solvers and stuff like that
11:21:04 <ReinH> Yep, it's very good for some people.
11:21:14 <chaoticlambda> What do you think of haskell: the craft of functional programming by Simon Thompson? 
11:21:22 <ReinH> Hutton is very good for other people. Bird is very good for still other people. (There is lots of overlap too.)
11:21:24 <jared-w> Now that I'm /almost/ at the Monad chapter (just need to finsh the final exercises for Applicative) I'm going to blend it with Bird since I /am/ atheorist at heart
11:21:38 <ReinH> It's good to read a chapter of each and see which style you prefer.
11:21:54 <ReinH> We're in a very nice place right now for Haskell books.
11:22:15 <jared-w> In fact, one of my frustrations with HFFP so far has been a lack of learning the haskell way of thought. I'm just learning the tools of Haskell and how to use it (which is great, and I needed that)
11:22:29 <ReinH> Yep. That's where Bird shines.
11:22:40 <ReinH> I also recommend his Pearls book for further study.
11:22:46 <jared-w> awesome, I'll definitely be looking into Bird's book then. Oooh and pearls
11:22:56 <ReinH> https://www.amazon.com/Pearls-Functional-Algorithm-Design-Richard-ebook/dp/B009019VUK
11:23:12 <jared-w> ahh yup, I've definitely heard of that one lol
11:23:14 <ReinH> and if you're interested in data structures as well as algorithms, Okasaki's thesis and the book it later turned into.
11:23:17 <ReinH> @where okasaki
11:23:17 <lambdabot> http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf
11:23:34 <jared-w> I've had that on my computer for a while. Definitely interested in it :)
11:24:00 <ReinH> And if you're interested in applying category theory to programming and can find a cheap version, Bird's Algebra of Programming.
11:24:10 <kadoban> FPDS is really good, love that book
11:24:16 <kadoban> PFDS*
11:24:38 <ReinH> And if you're interested in learning category theory per se, Tom Leinster's Basic Category Theory is now available for free with a creative commons license from arxiv.
11:24:47 <jared-w> oooh
11:24:53 <ReinH> It is very good.
11:24:55 <jared-w> yup, defintely a category theorist
11:25:02 <jared-w> or theorist in general, rather :p
11:25:06 <ReinH> A bit short, but that's not necessarily a bad thing.
11:25:19 <jared-w> I lean towards analysis and theory  ¯\_(ツ)_/¯
11:25:21 <ReinH> And you can always supplement it with Awodey and Mac Lane.
11:26:04 <jared-w> It's weird that I haven't heard about Bird's new book at all compared to HFFP
11:26:09 <homieomorphism> awodey's OPLSS 2012 category theory talks are up on youtube
11:26:12 <kadoban> After PFDS, there's also this list, which is perhaps the best answer I've ever seen on stackoverflowish sites https://cstheory.stackexchange.com/questions/1539/whats-new-in-purely-functional-data-structures-since-okasaki
11:26:20 <ReinH> Yeah, bitemyapp has better marketing :)
11:26:25 <jared-w> Of course, bitemyapp is pretty good at marketing :p
11:26:39 <ReinH> homieomorphism: Yes, they are very good. And there's Eugenia Cheng's Catsters videos, which are one of the things I originally learned from.
11:26:41 <kadoban> Well, he's part of this community so it's fairly expected. Not even sure that counts as marketing.
11:26:57 <ReinH> (I interviewed her for a podcast recently and it was amazing.)
11:27:11 <ReinH> kadoban: It does. Marketing isn't necessarily bad.
11:27:38 <homieomorphism> ReinH: link to the podcast? i'd love to hear it 
11:27:47 * jared-w wishes he could listen to podcasts ;-;
11:28:20 <Cale> jared-w: perhaps too good... I feel a little bit suspicious about that book, though it's hard for me to say, since I haven't had time to read it.
11:28:23 <ReinH> homieomorphism: Looks like it isn't up yet but it'll be at http://www.greaterthancode.com/
11:29:10 <jared-w> Cale: I personally really like it. I have a few super small niggles with it but it's been excellent for me
11:29:10 <homieomorphism> awesome
11:29:13 <ReinH> Cale: Judging by the quality of questions I've seen about the book, I am a *little* suspicious. I still think it's a good book.
11:29:34 <jared-w> Although, there seems to be two camps of people who use the book
11:30:02 <jared-w> Those that already have enough theory and mental fortitude to really take advantage of "just learning the tools" and those that, somehow, never click with FP "naturally"
11:30:58 <jared-w> I also tend to excessively read a lot of extraneous material, so between typeclassopedia, r/haskell, random blogs, etc., I probably have picked up quite a lot of supplementary material I didn't even realize that subconsciously covered over any weaknesses of the book
11:32:28 <ReinH> tbh one of the best things for learning Haskell is a familiarity with Algebra as a symbol-rearranging game.
11:32:50 <ReinH> Since that's essentially what programming Haskell is like.
11:33:10 <maerwald> ReinH: no one knows, since it's not free. I don't like learning material that is not free.
11:33:23 <ReinH> (Even moreso than most languages.)
11:35:40 <chaoticlambda> What are some projects involving HoTT and haskell?
11:35:40 <sproingie> all language is a symbol-rearranging game.  haskell just has a *lot* more grammar rules
11:35:52 <sproingie> (not in the sense of parsing grammar, but usage)
11:36:36 <jared-w> I suppose my strong mathematical background also helps, too... I've taken quantum mechanics, quantum computing, differential equations, calculus, etc., so "algebra" is trivial to me
11:36:48 <sproingie> the compiler is that nagging twit that always corrects you to say "you and *I*"
11:37:07 <maerwald> jared-w: and rocket science?
11:37:29 <ReinH> chaoticlambda: There's a cubical type theory proof assistant written in Haskell
11:37:33 <Cale> chaoticlambda: There isn't much -- Haskell's type system isn't quite where it would need to be to express the central ideas of HoTT.
11:37:45 <Cale> But yeah, the things which do exist are implementations of other languages :)
11:37:46 <jared-w> nah, I didn't like newtonian physics as a lower division undergrad course
11:37:59 <ReinH> Hmm, I can't find it now.
11:38:00 <Cale> Agda is also written in Haskell and can be used to carry out HoTT proofs.
11:38:01 <sproingie> laziness puts a really deep wrinkle into the CT of the type system
11:38:12 <chaoticlambda> ReinH: yes, I think that's Tom lagatta's work
11:38:21 <ReinH> Cale: As long as you get rid of that pesky axiom k
11:38:31 <chaoticlambda> Cale: what is missing?
11:38:33 <Cale> ReinH: Yeah, they have an option for that though.
11:38:40 <Cale> chaoticlambda: Dependent types, primarily.
11:38:58 <ReinH> Cale: Yep. I've even read the paper! :)
11:39:11 <jared-w> I have that paper in my web browser right now lol
11:39:18 <Cale> chaoticlambda: You especially need a usable identity type.
11:39:25 <jared-w> https://lirias.kuleuven.be/bitstream/123456789/452283/2/icfp14-cockxA.pdf
11:39:34 <ReinH> You especially need a usable identity type with non-trivial inhabitants ;)
11:39:44 <Cale> Well, that too!
11:39:51 <ReinH> But having one at all would be a start.
11:40:17 <chaoticlambda> Cale: from what I understand dependent types are being rolled out in future versions of haskell? Also is unit insufficient for identity?
11:40:31 <jared-w> So, Awodey and Mac Lane, the book specifically is "Category Theory" second edition, right?
11:40:41 <demoo> "the floor is readability"
11:40:42 <jared-w> chaoticlambda: unit is a trivial inhabitant
11:40:46 <Cale> chaoticlambda: By "identity type" I mean a type suitable for expressing equality of terms
11:40:47 <ReinH> Some aspects of dependent types are being bolted onto Haskell.
11:40:59 <ReinH> It still won't be able to represent Pi types, afaik
11:41:09 <jared-w> Dependent Haskell will have Pi types, I believe
11:41:12 <demoo> why do you guys like haskell, I'm about to get into it and I hear it is a big shock for people coming from python
11:41:21 <demoo> because of the change in syntax
11:41:30 <johnw> and the types
11:41:31 <jared-w> https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell There's a pi quantifier
11:41:33 <glguy> demoo: Why're you getting into it?
11:41:34 <ninjazoete> Any room for beginner question?
11:41:38 <demoo> I hear it is very fast
11:41:39 <jared-w> ninjazoete: of course
11:41:42 <kadoban> ninjazoete: This one
11:41:44 <glguy> ninjazoete: Yes, there's room here
11:41:44 <ReinH> Luckily, Haskell has very little syntax.
11:41:45 <marvin2> different syntax is a minor issue
11:41:45 <Cale> chaoticlambda: One of the fundamental constructions you can carry out in a dependently typed system is to define for each choice of type A, and for each x and y of type A, the type Id A x y
11:41:47 <geekosaur> syntax is the least of it... IO and laziness will really get you :)
11:41:47 <demoo> glguy: just to expand my knowledge
11:41:59 <ninjazoete> Can i paste a few lines of code here or pastebin etc?
11:42:06 <demoo> Haskell is a functional language?
11:42:10 <glguy> Yes, you can use a pastebin and share the link here
11:42:11 <ReinH> jared-w: Oh, cool, I guess I don't know much about dependent haskell!
11:42:14 <geekosaur> preferably an ad-free pastebin. in channel is not the best idea
11:42:20 <kadoban> ninjazoete: Yeah, lpaste.net is recommended
11:42:22 <glguy> ninjazoete: Include any relevant error messages
11:42:23 <jared-w> ReinH: there's some interesting tradeoffs being made in the progress of it
11:42:30 <Cale> chaoticlambda: which has but a single constructor, usually called refl : forall (A:Type), forall (x:A), Id A x x for "reflexivity"
11:42:49 <Cale> chaoticlambda: and from that, you can define symmetry and transitivity as functions
11:43:00 <demoo> I figure that experience ina functional programming language will help me out
11:43:02 <dtornabene> Cale: I've been slowly perusing Software Foundations and learning basic Coq to do stuff like this
11:43:11 <Cale> dtornabene: yep :)
11:43:19 <dtornabene> Cale: I've loved it
11:43:20 <johnw> dtornabene: great way to start
11:43:21 <jared-w> ReinH: https://typesandkinds.wordpress.com/2016/07/24/dependent-types-in-haskell-progress-report/ Richard has talked fairly extensively about what design tradeoffs he's making for dependent types
11:43:21 <ninjazoete> Ok so here is my code: https://pastebin.com/BSbEuxBY - I want to generate two random matrices and use them by multiplying them etc. I want to get rid of the DO notation and can't figure out how could I link those two?
11:43:31 <ReinH> dtornabene: SF is great.
11:43:44 <geekosaur> demoo, sort of. I started out with SML experience; like I said, IO and laziness will be your gotchas :)
11:43:48 <chaoticlambda> Cale: i see so this is not yet possible until something more expressive than refl is developed?
11:43:48 <dtornabene> ReinH: I was surprised at how easy it was to pick up
11:44:05 <geekosaur> oh, and let being recursive by default :)
11:44:18 <Cale> chaoticlambda: In Haskell, even if we bolted on dependent types, we have the problem that Haskell allows general recursion, so Id A x y would *always* be inhabited, meaning we'd have that any two terms of any type are equal.
11:44:20 <demoo> geekosaur: im just reading about it for the first time right now but hav enot seena  mention of IO. Whats the difference?
11:44:27 <dtornabene> ReinH: but I spent years with this book so it wasn't that far afield http://www.hup.harvard.edu/catalog.php?isbn=9780674324497
11:44:29 <exio4> demoo: Haskell is often unreadable if you don't know it, I mean, it makes sense, if you don't know Arabic it looks like random lines without meaning, doesn't it?
11:44:41 <ReinH> ninjazoete: Your lets are constructing actions, so you can bind with <- to get the values those actions produce.
11:44:58 <Cale> chaoticlambda: Of course, so long as you care *which* proof of equality you have, that might not be such a big problem
11:45:04 <Cale> But it sure makes things weird
11:45:27 <ReinH> ninjazoete: i.e., m1 <- inputMatrix; m2 <- weightMatrix; do stuff with m1 and m2
11:45:37 <exio4> cabal update ends up with Unexpected response 400for http://hackage.haskell.org/01-index.tar.gz
11:45:39 <ninjazoete> ReinH: yes but I want to get Matrix monad and it is fine but I don't really know how to proceed now. Do I need to write my whole program in this DO notation under those lines?
11:45:41 <exio4> any ideas?
11:45:46 <kadoban> demoo: Haskell's type system can differentiate between "pure" code (without side effects, like doing IO or using global mutable variables) and code which can have side effects. This is a pretty big departure from python and similar languages
11:46:00 <geekosaur> demoo, you can't just do I/O anywhere like you can in e.g. SML or OCaml. all I/O has to link back to main via IO types, and things are a bit weird-looking because we cheat to get IO with purity (you are not actually doing I/O, you are chaining pure opcodes together to make a "program" for the runtime)
11:46:07 <kadoban> It also has different abstractions that you don't see in other languages, which looks a bit bizarre until you get to know them.
11:46:09 <chaoticlambda> Cale: is there a way of imposing cardinality on equivalence classes?
11:46:11 <EvanR> Cale: this dependent haskell thesis seems pretty smooth, not that bolted on. some aspects of haskell seem to make dependent types work even better than normal. though not for proving math theorems
11:46:23 <Cale> If you want to do HoTT proper, it's better to do it in a system which restricts recursion so that you don't expect every type to be inhabited (i.e. you can distinguish true and false propositions)
11:46:39 <ReinH> ninjazoete: Your whole program has to be structured as an IO action (called main). The goal is to figure out how to get stuff *into* IO, not how to get stuff out.
11:46:57 <demoo> kadoban: can you define side effects?
11:47:02 <ReinH> You don't have to write your program in an imperative style in a do block, no.
11:47:19 <chaoticlambda> Cale: like agda? 
11:47:42 <Cale> chaoticlambda: Yeah, Agda and Coq are the really popular systems for exploring HoTT
11:47:53 <EvanR> you can also download existing hott work already written for coq and agda
11:47:55 <ReinH> You also ideally would like a system without axiom k, but you can work around it by avoiding pattern 
11:47:57 <ninjazoete> ReinH: but let's say I don't want to use DO notation at all - could I somehow create those matrices and link the monads somehow to use them both further?
11:48:00 <ReinH> ...matching if you really need to
11:48:01 <Cale> There might be a few more now, it's been several months since I last really looked
11:48:15 <jared-w> demoo: yup, you can. Haskell has a lot of very powerful ways of expressing exactly what side effects you want
11:48:28 <ReinH> ninjazoete: do notation is sugar for >>= and >>. You can always write without do notation. But I suspect that's not your question.
11:48:35 <demoo> ahh, ive found an explanation online about side effects
11:48:41 <EvanR> haskell doesnt have side effects, only intended effects!
11:48:45 <kadoban> demoo: In haskell the result of a pure function is *entirely* a function of its inputs, and it's not allowed to change anything else, like it can't write to a file, output to the screen, launch missiles, modify global variables, etc. Those are what I mean by side effects
11:48:53 <demoo> jared-w: sorry, by what I said I means explain
11:49:00 <chaoticlambda> EvanR: thanks, I'll look around for them
11:49:01 <ReinH> ninjazoete: when you say "link the monads somehow", what do you mean by "monad"?
11:49:16 <jared-w> ReinH: what did you think of the Frege to Gödel book?
11:49:37 <Cale> chaoticlambda: There are some implementations of cubical type theories, which try to avoid the fact that HoTT as originally discussed by the book incorporates an axiom, called the univalence axiom, and that acts as an obstruction to computation.
11:50:04 <ninjazoete> ReinH: I mean I use bind to get to the list of values from random generator but can I somehow access those two matrices at the same time by using bind >>= ?
11:50:06 <kadoban> So in python if you do f(2)  and then f(2) again, the result of those could be entirely different. That can't happen in haskell in pure code. Haskell has a concept of imperative execution, and you can certainly do it, you just have to tell the type system that that's your intention.
11:50:06 <ReinH> jared-w: That I should find the time to read it. :)
11:50:11 <jared-w> cubical type theories are weird though...
11:50:18 <Cale> Yeah, they are.
11:50:22 <demoo> kadoban: i see, that is interesting
11:50:40 <Cale> Personally, I really hope that there's some more natural type theory in which UA is provable.
11:50:55 <ninjazoete> ReinH: Sorry, I feel like a dumb person can't even ask a precise question
11:51:04 <Cale> Cubical type theory seems a bit contrived for the purpose
11:51:06 <jared-w> Agreed. I'm not a fan of ZFC because of how ugly it is to shoehorn all of math into it
11:51:20 <ReinH> ninjazoete: You can use Functor, Applicative, or Monad interfaces to structure computations of monad actions, depending on what you are trying to do.
11:51:24 <jared-w> I'd prefer if we didn't make a similarly ugly type theory :p
11:51:26 <exio4> demoo: a "simple" thing like that, can open a whole new world of programming! how do you represent things without mutation? how do we deal with concurrency?
11:52:14 <ReinH> :t liftA2
11:52:15 <exio4> demoo: what does this gives us? now that we functions are simply equations from the inputs, we can equational reasoning, for example! 
11:52:16 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
11:52:26 <EvanR> jared-w: cubical is ugly?
11:52:29 <ninjazoete> ReinH: Okay, would you continue my work in the DO notation here ? just your opinion :)
11:52:48 <ReinH> liftA2 lets you work with two monad actions by providing a function on the underlying values, for example.
11:53:03 <Cale> EvanR: It's certainly not *as* ugly as ZFC's axioms, but it's kind of ugly, yeah. :)
11:53:04 <WinchellsM> Is anyone aware of a Haskell "telemetry" (i.e., user analytics) service to track user behavior on the backend of a webapp, etc?
11:53:05 <jared-w> EvanR: not ugly, no. Just weird. But some of the stuff I've seen seems like it's headed towards becoming highly contrived
11:53:07 <EvanR> jared-w: in comparison... try to do anything for real in HoTT
11:53:09 <ReinH> ninjazoete: Well, I'm not sure what you're trying to do.
11:53:25 <jared-w> And yeah, it's slightly ugly :p
11:53:29 <EvanR> thats not in the book (which itself uses highly informal version of itself)
11:54:07 <EvanR> what kind of formal system would be considered not ugly?
11:54:15 <Cale> Well, all the stuff in the Book has been carried out formally
11:54:24 <ninjazoete> ReinH: writing a simple neural network example. Thank you for your time. I will figure it out
11:54:38 <EvanR> yeah, but go out on your own and try to use it...
11:54:43 <Cale> hm?
11:54:53 <EvanR> its pretty hellish
11:54:56 <jared-w> EvanR: One in which UA is provable but you don't have to jump through a billion hoops to finangle the system around, for example?
11:55:08 <jared-w> ninjazoete: ahhh, neural networks?
11:55:10 <Cale> I'm not sure I agree about that. It's fairly usable.
11:55:26 <Cale> Certainly much nicer than trying to formalise stuff in ZFC
11:55:32 <EvanR> when you need to use the dependent version of transport nested like 3 times
11:55:53 <ninjazoete> jared-w: learning NN and wanted to try my luck with Haskell as I am learning it too :) 
11:56:00 <jared-w> ninjazoete: https://github.com/alpmestan/hnn look at this library
11:56:01 <EvanR> hott works great for talking about specifically algebraic topology it seems
11:56:28 <EvanR> but even then... try to show a mobius strip is homotopy equivalent to a circle
11:56:49 <jared-w> ninjazoete: however, to be perfectly honest... Haskell should likely be learned on its own and NNs should likely be learned "on their own". Getting an understanding of both and then combining them will likely be more fruitful
11:56:51 <EvanR> i couldnt find anyone who could make it looks nice !
11:57:10 <ninjazoete> jared-w: thank you, looks interesting 
11:57:17 <Cale> EvanR: It depends on what you're doing, obviously. The only case where I really ran into a rat's nest of transports that wasn't easy to deal with was in trying to port a proof from algebraic topology that the circle's fundamental group is commutative which doesn't factor through the proof that it's Z.
11:57:33 <jared-w> The reason python is often used for neural networks is because there's tons of resources for it and it's a natural fit to start hacking and tinkering around without needing to learn a lot of programming. Haskell is the opposite and doesn't always lend itself to certain problem domains "naturally"
11:57:55 <ninjazoete> jared-w: ye but I cought myself on reading about Haskell only for weeks and never touching it. Now I feel like without practice I will never learn it
11:57:56 <Cale> (basically, I was trying to define a multiplication operation on *all* paths on the circle, between arbitrary pairs of points)
11:58:06 <ninjazoete> jared-w: so I decided to finally do something with it
11:58:18 <jared-w> ninjazoete: that's true :p pick up a programming book and get started?
11:58:38 <Cale> i.e. an abstract version of complex multiplication of paths on the unit circle in C
11:58:39 <chaoticlambda> HoTT could be useful for methods in TDA and load process calculi.  . . Exploring to see if so
11:58:41 <EvanR> the stuff that appears in the book seems like the cherry picked situations where hott worked nicely
11:58:57 <Cale> EvanR: I would say the stuff in the book is fairly broad though
11:58:59 <EvanR> which are really nice
11:59:09 <ninjazoete> jared-w: so I did a few months ago and I am on some bigger topics but still have not really used it :) Here I am just trying to write some matrix operations and get familiar with it
11:59:10 <Cale> They did get in a good number of pretty different areas of mathematics there
11:59:22 <Cale> and it works out even nicer when it comes to group theory
11:59:48 <Cale> (There's a proof that two groups are equal if they are isomorphic, if you use the straightforward definition of a group)
12:00:03 <EvanR> yes
12:00:10 <jared-w> https://github.com/jbarrow/LambdaNet ninjazoete this is another one. I like this one better, I think
12:00:15 <EvanR> which is not a usual result of group theory!
12:00:21 <Cale> Right
12:00:45 <EvanR> but we have paths through a type universe linking groups together
12:01:06 <Cale> It's very nice though, because it means that constructions in terms of groups will automatically be preserved under group isomorphism.
12:01:08 <EvanR> and surfaces linking those together
12:01:23 <EvanR> is that not usually the case?
12:01:24 <ninjazoete> jared-w: readme is better thats for sure
12:01:40 <Cale> EvanR: It's usually the case, but you usually need to actually check it.
12:01:55 <jared-w> ninjazoete: https://github.com/brunjlar/neural this one is even newer and has more shiny things, possibly
12:02:02 <Cale> EvanR: e.g. you get *for free* that group rings built on the isomorphic groups will be equal
12:02:09 <jared-w> At the very least, you can see how people do things in the source code and play with it
12:02:20 <Cale> EvanR: and thus have all the same properties themselves
12:02:41 <Cale> That usually requires boring checking if you carry stuff out in ZFC or practically any other foundations
12:03:05 <Cale> (and you'd only be aiming for isomorphism of the rings, and not equality)
12:03:12 <ninjazoete> jared-w: okay thanks, what is overwhelming for me also is the style of Haskell. When I look at bigger libraries I am completely lost. So much to learn!
12:03:18 <mniip> hmm, what would be the easiest way to insert some "shellcode" inside an IO action?
12:03:24 <mniip> ffi?
12:03:30 <merijn> mniip: eh...system? :p
12:03:39 <EvanR> ninjazoete: lens?
12:03:52 <jared-w> mniip: https://github.com/Gabriel439/Haskell-Turtle-Library does this work?
12:03:54 <mniip> nah I have a couple assembly commands that I need executed
12:03:57 <merijn> :t System.Process.shell
12:03:59 <lambdabot> String -> process-1.4.3.0:System.Process.Common.CreateProcess
12:04:38 <ninjazoete> EvanR: are you asking if I am confused when looking at lens library?
12:04:39 <MitchellSalad> what is "x-uses-tf"?
12:04:42 <EvanR> Cale: people actually check real math against ZFC?
12:04:57 <EvanR> ninjazoete: if thats the example big library youre talking about
12:05:03 <jared-w> god I can't imagine. I thought ZFC was just there to be ignored
12:05:27 <mniip> I can write inline STG right?
12:05:37 <mniip> well, perhaps not inline
12:05:47 <merijn> EvanR: Not directly, but most of the usual things that people use have been verified with ZFC
12:05:53 <merijn> mniip: eh...no?
12:06:09 <merijn> mniip: You can use foreign primops to import Cmm primitives
12:06:17 <merijn> mniip: But no inline things
12:06:21 <mniip> right
12:06:30 <mniip> can I use inline assembly in Cmm primitives?
12:11:00 <jared-w> No idea. But... why do you want to?
12:11:20 <EvanR> to get wicked speed
12:11:35 <EvanR> obv :)
12:12:23 <mniip> no
12:17:26 <mniip> so how do you declare IO primops?
12:17:39 <mniip> neither :: IO () nor :: State# RealWorld -> State# RealWorld seems to work
12:17:56 <demoo> holy cow haskell is cool
12:18:42 <EvanR> yes, though not because of RealWorld hacks
12:20:02 <mniip> should I just foreign import ccall
12:20:22 <mniip> there's literally no documentation on foreign import prim and integer-gmp doesn't seem to use it contrary to the wiki
12:21:03 <geekosaur> integer-gmp was rewritten relatively recently, so not surprising the wiki is out of date
12:24:18 <mniip> huh
12:24:21 <mniip>     Unacceptable result type in foreign declaration:    ‘(# State# s, Word# #)’ cannot be marshalled in a foreign call
12:24:28 <mniip> literally copy-paste from integer-gmp 0.5
12:25:11 <mniip> ah, UnliftedFFITypes
12:29:02 <glguy> mniip: Presumably you're already reading https://ghc.haskell.org/trac/ghc/wiki/Commentary/PrimOps#Foreignout-of-linePrimOpsandforeignimportprim
12:29:10 <mniip> yes
12:33:06 <vise890> hi all, i'm trying to set `-with-rtsopts=-TN` in my `.cabal` file and i can't get it to work.
12:33:20 <vise890> -TN -> flag -T given an argument when none was expected: -TN
12:33:40 <vise890> -NT -> bad argument to N
12:33:50 <geekosaur> "-T -N"
12:33:53 <geekosaur> with the quotes
12:34:41 <vise890> tried that .. doesn't even compile : "ghc: unrecognised flag: -N"
12:36:08 <glguy> vise890: That's why you have to use the quotes
12:36:42 <vise890> .. that is with the quotes glguy
12:36:59 <vise890> my full line is: ghc-options:         -threaded -rtsopts -with-rtsopts="-T -N"
12:37:59 <vise890> i've also tried specifying -rtsopts multiple times, but it seems to ignore the second one i put in
12:38:41 <glguy> vise890: "-with-rtsopts=-N -T"
12:39:40 <vise890> ok that worked!
12:39:48 <vise890> thanks glguy !
12:44:47 <EvanR> merijn: oh right, mizar, metamath
12:50:42 <Wizek> Hello. Does anyone know of a generic list builder monad that is able to do something like the following? https://gist.github.com/Wizek/65816d22bfa45c11b767536011509f78
12:51:41 <NemesisD> Wizek: maybe a wrapper around `tell` from Writer that makes a singleton?
12:51:55 <acyed> hello everyone! I'm working on my first Yesod app, and I'm lost. I want to perform a function that has type Int -> IO (), but I'm working in the (HandlerT App IO Html) monad. I honestly dont even know where to begin
12:52:11 <NemesisD> acyed: look into "liftIO"
12:52:25 <NemesisD> liftIO :: (MonadIO m) => IO a -> m a
12:52:39 <Wizek> NemesisD, perhaps, and toList would concat them?
12:52:41 <acyed> copy! I'll go read about that, thanks!
12:52:59 <NemesisD> Wizek: yeah toList would be like evalWriter or something
12:53:29 <NemesisD> also consider not using lists or perhaps another strategy for performance critical code
12:54:03 <Wizek> of course, I forgot to mention "or IsList"
12:54:16 <NemesisD> ?
12:56:06 <hsk3> Is there an idiomatic way to fold together the N last elements in a list? foldLast :: Int -> [a] -> [a]
12:56:21 <hsk3> or should I just roll out my own?
12:56:44 <hsk3> sorry guys
12:56:57 <kadoban> hsk3: You just mean take except the last N instead of the first N?
12:57:16 <hsk3> I meant   foldLast :: Int -> (a -> a -> a) -> [a] -> [a]
12:58:42 <Wizek> I mean that toList could have the type `IsList l => m a -> l a` so it can produce sequences other than [].
12:58:45 <Wizek> NemesisD, ^
12:59:30 <kadoban> hsk3: I'd probably just do   reverse, take n, and another reverse and then the fold you want. It's not quite optimal I'm sure, but it shouldn't be too awful.
12:59:41 <kadoban> I don't know of one built in anyway.
13:00:55 <NemesisD> Wizek: sure, although don't do it for performance because i don't think it will help. but you can get singleton from IsList
13:01:03 <acyed> so, in the do block, I had to use the _ <- liftIO $ func to get it to work, it wouldn't compile with just liftIO $ func. I thought it do notation would turn that into >>, right?
13:01:28 <acyed> *it do = do
13:01:46 <NemesisD> acyed: was it producing a warning with just liftIO func? something about discarding a result?
13:01:53 <kadoban> acyed: Are you sure it wasn't just a warning?
13:02:26 <Cale> acyed: Do you have -Wall -Werror turned on?
13:02:35 <geekosaur> some people think -Werror is a good idea (hint: forget compatibility with other ghc versions)
13:03:03 <Cale> Personally, I hate that it tries to force you to write _ <- ...
13:03:31 <Sornaensis> why Cale
13:04:23 <NemesisD> i am one of those people
13:04:29 <kadoban> I'm not sure I've ever really been saved by that warning. I'm sure there's cases where it helps, I guess, but I don't know what they are exactly.
13:04:42 <acyed> I do not have those turned on. Shouldn't _ <- , and a function on the line by itself,  be the same thing?
13:04:50 <NemesisD> its very easy to set your flags to make it opt in but i do not work on my own haskell projects or work projects without -Werror
13:05:13 <NemesisD> i get saved all the time by discarded results warnings, about 50/50 i actually should have been using that result
13:05:28 <Cale> acyed: yes, they are
13:05:41 <NemesisD> you can also use void from Control.Monad
13:05:57 <chiralcarbon> yo
13:06:01 <hsk3> kadoban yeah, i'll just roll out my own like that ,thanks
13:06:06 <Cale> acyed: But if you have -Wall turned on, it will warn you that you're implicitly discarding a result
13:06:10 <kadoban> At the very end of a do block  _ <- blah  wouldn't be legal. But otherwise, yeah they're the same except you can get a warning for the version without the _ <-
13:06:24 <Cale> acyed: and if you use -Werror, that warning becomes an error
13:06:30 <kadoban> And that'd be the opposite result, so I'm not sure how you were getting an error.
13:06:43 <Cale> Ohh... yeah, you can't have <- at the end of a do-block at all.
13:06:50 <geekosaur> acyed, can you show code and full error?
13:06:52 <geekosaur> @paste
13:06:53 <lambdabot> Haskell pastebin: http://lpaste.net/
13:08:06 <acyed> I'll try, one sec
13:11:29 <acyed> http://lpaste.net/356564
13:12:35 <acyed> took a bit, appoligies. So, I've messed with the code since I got that error. My original thought was I could have a do block for my function, and then a do block for yesod. That might have been the problem
13:12:42 <geekosaur> that looks to me like you had an indentation issue
13:13:08 <geekosaur> and it read the rest of the 'do' as continuation lines
13:16:01 <blender> hi, does anyone know if hlint's --path option is working?
13:16:51 <blender> I am trying `hlint lint --path /some/path` but the command does not seem to work
13:23:17 <jp_rider> What's the name of the function that compares two Text's in a fixed amount of time (ie. doesn't leak information via a timing channel)? 
13:26:08 <kadoban> jp_rider: Do you mean you suspect one is built in, or? I could probably write one that I wouldn't expect GHC to optimize out, though it might be a little tricky. What do you mean fixed? That it doesn't depend on if they differ early on? That it doesn't depend on their length at all? That it doesn't depend on if you're comparing the same exact values multiple times maybe?
13:26:51 <geekosaur> this sounds like something crypto related so I'd be looking at the various crypto packages
13:27:42 <koala_man> sounds hard. how do you account for improved branch prediction when you run out of characters in one string?
13:27:46 <jp_rider> I'm pretty sure I've used it before, but I can't find it now. I'd prefer to use an existing implementation
13:27:56 <Clint> which crypto libraries use Text?
13:29:16 <cocreature> there is https://hackage.haskell.org/package/securemem-0.1.9/docs/Data-SecureMem.html for ByteString
13:29:25 <cocreature> I don’t know of anything for Text
13:30:43 <jp_rider> Ah, I think it's constEqBytes
13:31:54 <jp_rider> I guess you still need to convert it to a bytestring
13:37:47 <cocreature> and make sure that you’re doing that in constant time because otherwise your constant time comparison is worthless
13:41:38 <jp_rider> I'm using encodeUtf8, which I think should be fine since all the characters are alphanumerics
13:42:12 <kadoban> Well, encoding is going to take different amounts of time based on the length, no?
13:42:58 <jp_rider> sure, but so is the comparison. the length is constant/public
13:43:35 <kadoban> Yeah it was unclear to me exactly what you were trying to get it not to depend on.
13:45:07 <jp_rider> gotcha. thanks for the help!
13:53:28 <ReinH> hsk3: I would say that if you want convenient access to the tails of a sequence then [] is not an ideal data structure. Data.Sequence might be better.
13:55:34 <ReinH> jp_rider: I would above all else not recommend implementing your own constant time equality check. They are extremely fiddly.
13:56:30 <ReinH> I think you would want to FFI to ensure that your comparison is cycle-accurate.
13:57:10 <ReinH> side-channel attacks are getting extremely sophisticated so "almost constant time comparison" is becoming less and less viable.
13:57:17 <hsk3> ReinH yeah, thanks
13:59:43 <ReinH> I've seen some implementations and they are magical. I would never trust myself to write one in Haskell executed by GHC.
14:01:44 <ReinH> Well, they are indistinguishable from magic.
14:06:43 <homieomorphism> i still have a small heart attack every time i see ghc request 1tb of vram
14:09:35 <jared-w> lol
14:09:55 <dolio> Only 1? I thought it was 2.
14:10:09 <jared-w> I think it'll just request the maximum amount of vram possible on the system
14:10:42 <geekosaur> 1TB and it's not actually requesting it, just populating the page table for it. which confuses various "top" programs
14:11:30 <geekosaur> we went through this in the 90s when X servers started mapping VRAM and top reported huge sizes as a result; but X servers are more visible to people so top was fixed for that
14:11:31 <jared-w> which makes sense, don't a lot of modern compilers do that sort of thing?
14:11:43 <geekosaur> I'm not sure anyone cares enough to fix top for ghc
14:12:09 <geekosaur> not generally, most things use standard mmap, not madvise
14:12:19 <geekosaur> there's some lisp dialects that use madvise I think
14:12:47 <koala_man> haha I remember that
14:13:49 <dolio> Go apparently does it, too.
14:14:31 <dolio> Possibly Java, as well.
14:14:37 <jared-w> Go has upgraded from 100% terrible to 99.97% terrible to me. Nice
14:14:44 <amf> the example in https://github.com/rampion/constraint-unions#readme has `equalsString0 = resolve @(Show a) @(Eq a, Read a)` what is the @ syntax? (im used to seeing a variable before the @)
14:15:42 <MarcelineVQ> amf: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#visible-type-application
14:15:44 <jared-w> "GHC needed some help figuring out what instance of resolve we needed, so we used TypeApplications to tell us what constraints we were choosing between"
14:17:05 <amf> ha! thanks!! the 8.0.1 explains why ive only started seeing it recently
14:18:58 <ReinH> Go's ecosystem is actually pretty nice. It's the language itself I find untenable.
14:19:43 <mekeor> are there any haskell bindings for the Matrix protocoll? <https://matrix.org>
14:26:12 <ReinH> mekeor: I'm not sure, but it's extremely easy to write JSON-y clients and servers with Aeson.
14:26:26 <Wizek> NemesisD, I was able to make a working version quiet easily with Writer, thanks for the pointer.
14:26:37 <ReinH> So much so that pressure to write separate libraries for every such protocol is sort of diminished.
14:26:53 <ReinH> And Wreq for clients.
14:29:32 <mekeor> cool, ReinH, thanks
14:36:28 <zomg> Was there some method for Aeson to parse stuff like numbers as strings with generated instances? Looking at the Aeson docs it seems the only way to deal with that is a custom parseJSON function
15:08:07 <ertes> i have…  for the first time in my life…  used the 'tac' command…  for a real-world purpose
15:08:45 <koala_man> no way
15:08:58 <Rembane> What did you use it for?
15:09:06 <ertes> reversing a playlist
15:09:07 <EvanR> tac command not found
15:10:13 <ertes> now you're supposed to say one of: ["congratukations", "i didn't even know tax existed"]
15:10:20 <koala_man> it's actually pretty useful in semi-IRL to process logs. that way, grep will give the newest rather than the oldest entries
15:11:47 <pikajude> ertes: trust me, I knew tax existed
15:14:12 <EvanR> Cale: about copattern based codata construction, in the paper theres a clear distinction between ADT data variants, and codata records. Which seemed cool until... it seems like you cant properly represent the type data Program = Get (Word8 -> Program) | Put Word8 Program | Ended Char
15:15:12 <EvanR> since its a variant, it must be a "data", and so the one thing you cant do is an infinite stream of Puts, the classic basic loop of printing hello world over and over again
15:15:43 <EvanR> my confidence in codata is once again shattered!
15:21:39 <Cale> EvanR: wait, what? Why can't that be codata?
15:23:45 <pikajude> is anyone who is familiar with pipes able to explain to me how I make someProducer >-> someConsumer return someProducer's return value when the pipeline terminates, even if someConsumer returns ()?
15:25:20 <pikajude> someProducer will return an error type indicating why it stopped producing messages
15:26:23 <EvanR> Cale: in the paper specifically, codata only takes the form of a recursive record. all the fields are observations that always make sense
15:27:09 <EvanR> but in a variant, observations either dont always make sense, or you need auxilliary "isGet" "isPut" and "isEnded" observations and make the other observations Maybe... like Java
15:27:24 <EvanR> or make them all Maybe
15:27:46 <EvanR> which puts a damper on a sane way to construct this kind of program
15:28:08 <EvanR> since you could make Get and Put simultaneously happening, makes no sense
15:28:51 <EvanR> it *is* codata in existing systems, based on construction not destruction
15:34:00 <EvanR> i thought the additional distinction of variant vs record was cool but its clearly limited...
16:01:42 <ski> EvanR : you could have a record with a single field ..
16:02:55 <chb0b> Hi! when using ghci, I get this long prompt "Prelude> Prelude System.IO H Data.Functor.Identity Text.ParserCombinators.Parsec Text.Parsec.Prim| Prelude System.IO H Data.Functor.Identity Text.ParserCombinators.Parsec Text.Parsec.Prim| Prelude System.IO H Data.Functor.Identity Text.ParserCombinators.Parsec Text.Parsec.Prim| Prelude>"
16:03:06 <chb0b> is there way to simplify the prompt?
16:03:34 <unknownln> `:set prompt ">>> "`
16:03:51 <chb0b> this is when I run multi-line src
16:03:55 <Tuplanolla> Don't forget to set `prompt2` as well.
16:04:02 <unknownln> what's prompt2?
16:04:26 <EvanR> ski: Program = { run :: Cmd }, Cmd = < Get (Word8 -> Program) | Put Word8 Program | Ended Char > ?
16:04:29 <Tuplanolla> It's for continued lines.
16:05:07 <EvanR> i wonder if that type checks
16:06:27 <chb0b> I get something like "Prelude> Prelude> Prelude> Prelude> Prelude> Prelude> Prelude> Prelude> Prelude> "
16:06:28 <ski> EvanR : yes, something like that
16:06:31 <chb0b> with >>>
16:06:47 <EvanR> that explains how you could write imperative code with copatterns
16:06:52 <EvanR> if its sound
16:06:59 <geekosaur> chb0b, how are you using ghci?
16:07:15 <geekosaur> that looks like you are feeding input to it non-interactively. perhaps you want runghc instead
16:07:16 * ski was reading this paper last night, changing to personal notation to compare
16:07:19 <geekosaur> or ghc -e
16:07:28 <chb0b> org-babel
16:07:49 <chb0b> i can also see the *haskell* buffer
16:07:54 <chb0b> which shows ghci
16:08:41 <geekosaur> well, that's just showing a bunch of prompts without echoing what it read, which is normal if emacs is feeding it stuff
16:09:05 <EvanR> run main = Put 255 main
16:09:26 <chb0b> hm. is there way not to show so many?
16:09:32 <EvanR> run main = Put f0 (Put 0f main)
16:09:45 <EvanR> er no
16:10:00 <geekosaur> probably not; ghci was not designed for what org-babel is doing with it
16:10:18 <geekosaur> just hit enter to get a clean new line
16:10:20 <ski>   main = loop 0 where run (loop n) = Put n (loop (n + 1))
16:10:36 <chb0b> thanks geekosaur
16:11:03 <ski> fwiw, i don't like the `Program = { run :: Cmd }' syntax, in conjunction with `run main', here
16:11:32 <EvanR> run step1 = Put f0 step2; run step2 = Put 0f step1
16:12:06 <EvanR> or step1.run
16:12:35 <EvanR> ski: why
16:14:13 <ski> either it should use some alternative syntax for projection, such as `#run main' (SML) or `main .run' (to distinguish between the field `run' of type `Cmd', and the field selector `#run'/`(.run)' of type `Program -> Cmd')
16:14:45 <EvanR> sure its .run in the paper, after a certain point
16:14:49 <ski> or it should be declared something like `record Program where run :: Program -> Cmd' (and now `run' is the field selector)
16:14:51 <EvanR> heh
16:15:16 <EvanR> and you can write stuff like f x .run
16:15:29 <EvanR> which parses to (f x).run
16:15:34 <EvanR> wacky
16:15:57 <ski> (one can imagine "GADT"-like records with the latter declaration syntax, in which some fields of the record only exist in case some indices are something in particular)
16:16:21 <ski> well, i think that precedence rule makes sense
16:16:41 <EvanR> but they dont even have polymorphism much less GADTs or dependent types
16:17:05 <ski> (i may ask Andreas Abel whether he's seen the Erik Poll papers)
16:17:18 <ski> aye, that's just an aside
16:17:35 <EvanR> the erik poll papers?
16:17:45 <ski> @where ErikPoll
16:17:45 <lambdabot> "Subtyping and Inheritance for Inductive Types" in 1997 at <http://www.cs.ru.nl/E.Poll/papers/durham97.pdf>,"Subtyping and Inheritance for Categorical Datatypes" in 1997 at <http://www.cs.ru.nl/E.
16:17:45 <lambdabot> Poll/papers/kyoto97.pdf>,"A Coalgebraic Semantics of Subtyping" in 2000 at <http://www.cs.ru.nl/E.Poll/papers/cmcs00.pdf>,later version of that in 2001 at <http://www.cs.ru.nl/E.Poll/papers/ita01.
16:17:45 <lambdabot> pdf>
16:17:51 <ski> (the first two)
16:18:07 <Tuplanolla> This guy's username better be epoll.
16:18:16 * ski grins
16:18:19 <EvanR> ouch at the url beign divided
16:18:55 <ski> that's where i first saw this syntax suggested
16:19:29 <ski> i know i've gone through the `runState' example in this channel several times
16:19:56 <EvanR> which syntax
16:20:23 <ski>   return :: a -> State s a
16:20:31 <ski>   return a `runState` s = (s,a)
16:20:45 <EvanR> yeah that part is really nice
16:20:48 <ski>   (>>=) :: State s a -> (a -> State s b) -> State s b
16:21:11 <ski>   (ma >>= amb) `runState` s0 = (s2,b)
16:21:13 <ski>     where
16:21:28 <ski>     (s1,a) =  ma   `runState` s0
16:21:35 <ski>     (s2,b) = amb a `runState` s1
16:21:58 <EvanR> hmm it was shorter in the paper
16:22:04 <ski> so i'm happy to see this paper also did this example
16:22:18 <ski> yea, for efficiency, you should eta the `(s2,b)'
16:23:00 <ski> (but for a first conceptual version, this explicit one may be clearer)
16:23:52 <EvanR> if every runState produces two runStates, how does the population ever go down? :)
16:24:21 <ski> nah, `runState' on every `.. >>= ..' produces two new `runState's :)
16:24:41 <ski> but not for `return',`get',`put',&c.
16:24:57 <EvanR> oh right, runState on return 
16:25:25 <ski> @src State (>>=)
16:25:25 <lambdabot> m >>= k = State $ \s ->
16:25:25 <lambdabot>   let (a, s') = runState m s
16:25:25 <lambdabot>   in  runState (k a) s'
16:25:30 <ski> is the same, except clumsier
16:25:43 <EvanR> return a .runState s = (a,s)
16:26:11 <EvanR> i see a ruby on rails -like killer app on the horizon, based on this
16:26:42 * ski has tentatively called this syntax "message-dispatching syntax", to go with "pattern-matching syntax"
16:26:55 <ski> (i don't think "copatterns" is that vivid)
16:27:22 <EvanR> messages...
16:27:29 <EvanR> im not sure i see messages happening
16:27:35 <nshepperd_> Oh, you're defining a record-producing function by a pattern for each record accessor
16:27:36 <EvanR> observations?
16:27:37 <ski> another name for field projection
16:27:49 <ski> or observations, yes (though that's a slightly more general term)
16:28:00 <EvanR> "deep copatterns" though
16:28:17 <ski> we already have that, in the form `f x y = ..x..y..'
16:28:23 <ski> `(f x) y' here
16:28:38 <EvanR> functions are defined via copatterns!
16:28:43 <ski> yes
16:28:52 <EvanR> application is an observation
16:29:03 <ski> or, they're defined in terms of how they behave, when applied to an argument
16:30:09 <ski> i've also experimented with allowing definitions like `case f x of {Nothing -> n; Just y -> j y} = ..x..n..j', where the definiendum is a `case'
16:30:57 <ski> in this case, you have to insist that the type of the `case' is a type variable, which is universally quantified over the definition
16:31:32 <nshepperd_> It's a copattern because a product of them makes a value, rather than a sum?
16:32:52 <ski> i suppose they called it "copattern" because you define something in terms of what you can project out of the output
16:33:29 <ski> rather than define a function by pattern-matching, in terms of how the input could have been injected
16:33:38 <EvanR> i like how it fixes cofix issues in coq
16:33:47 * ski doesn't use the term "copattern", though
16:34:01 * ski nods
16:34:05 <ski> i don't like that many of the judgements in the paper are algorithmic only, not also logical
16:34:23 <EvanR> what does that mean
16:35:26 <ski> if you take the inference rule that from `Gamma,x : A |- e : B' you can infer `Gamma |- \x. e : A -> B', and erase the proof terms, you get the logically valid rule that from `Gamma,A |- B' you can infer `Gamma |- A -> B'
16:35:49 <ski> several of the judgements in the paper have no obvious logical interpretation along such lines
16:35:57 <ski> i consider that a defect
16:36:35 <EvanR> like what
16:37:17 <chb0b> :quit
16:40:35 <ski> e.g. `Delta | A |- q => C', sec. 3.3
16:41:17 <EvanR> ah yeah
16:41:37 <ski> or `A <| | Q,...' in sec. 5.2
16:42:08 <ski> (also `Delta | p <= A' in sec. 3.3, though that's probably less obvious)
16:44:08 <ski> (.. now, if i could find my old notes on this, i wouldn't have to try to again reconstruct my rules from vague memory)
16:44:12 <EvanR> k all these proofs are way over my head
16:44:38 <ski> the proofs are mostly just hints, i think
16:44:56 <EvanR> but the finite variant infinite record thing is making sense again!
16:45:02 <ski> "if you try this, and do the obvious, you'll see that it works out"
16:45:07 <EvanR> heh
16:46:05 <ski> (it helps to have an interactive proof assistant to explain what needs to be done at each step, and to pass between states)
16:47:26 <ski> i remember in my version, i could define more than one identifier, by a single defining equation. they always have a single one, indicated by a dot in the equations
16:48:08 <ski> (i'm not sure how useful that ability would be, but i thought : why not, it works)
16:48:34 <EvanR> to get a non trivial imperative program out of this, youd need a lot of equations
16:48:50 <EvanR> equational reasoning taken seriously!
16:48:57 <ski> not sure what you mean by "imperative" here, but ok
16:49:05 <EvanR> Get Put 
16:49:13 <ski> state machine ?
16:49:16 <EvanR> no
16:49:20 <augur> is there a good library for pixel-oriented graphics?
16:49:36 <EvanR> the Program and Cmd type from before
16:49:42 <EvanR> im calling that an imperative language
16:50:03 <EvanR> every step needs a new equation to get a guard
16:50:55 <ski> ok
16:52:14 <EvanR> it seems to be describing a core language so might not be a big deal
16:52:36 <ski> you could always monadize it, i suppose
16:52:43 <EvanR> you could translate to it from do notation
16:53:06 <ski> (hiding `Program'/`Cmd')
16:54:55 <ski> hm, this now reminds me of some Scheme paper about unfolding monad abstractions (like `mtl') by macros, to avoid overhead (which also reminds me of the "Multi-return function call" Shivers' paper, which i tend to refer to as "unboxed variant types" (the continuation is unboxed))
16:57:47 <EvanR> cool
16:58:33 <EvanR> that would cut out 1/2 of the memory usage
17:02:23 <ski> the idea is to get something similar as using CPS (and unboxing or uncurrying), but without as much syntactic fuss (and possibly further improved performance ?)
17:02:37 <d34df00d> Hi!
17:02:59 <d34df00d> Is it possible to make a mutable vector of mutable vectors, and then V.convert those into a vector of vectors?
17:03:03 <ski> but one would need to add restrictions on how these constructions can be used, to be able to give those guarantees
17:03:05 <d34df00d> Something along the lines of this:
17:03:10 <d34df00d> http://bpaste.net/show/3c672d236ecb
17:08:30 <pikajude> hmm, I don't understand how the return types of pipes could be useful
17:08:47 <jared-w> pikajude: what return type in general are you looking at?
17:08:56 <pikajude> well i asked this question earlier
17:09:06 <pikajude> but i have a pipe that's producing parsed messages from a Handle and a pipe that's processing them
17:09:20 <pikajude> the producer will return a Reason once it stops producing messages, could be a parse failure, disconnect, etc.
17:09:32 <pikajude> but the consumer then also has to return a Reason, which doesn't make sense
17:09:40 <pikajude> otherwise i can't compose them using >->
17:11:07 <jared-w> d34df00d: https://wiki.haskell.org/Numeric_Haskell:_A_Vector_Tutorial does anything in here help you?
17:15:27 <d34df00d> jared-w: nope, not much, sadly. Right now I operate with a mutable vector of pure vectors, and everything is fine, but I can't seem to be able to make the vector to hold mutable subvectors, probably on type level.
17:16:00 <jared-w> Why do you want nested mutable vectors?
17:16:35 <d34df00d> jared-w: I did some profiling and figured out filling the subvectors is my (next) bottleneck.
17:17:06 <jared-w> So you want to fill it mutably instead?
17:17:06 <d34df00d> Namely, the allocations count and CPU time is too high.
17:17:09 <d34df00d> Yes.
17:17:10 <EvanR> so you want a jagged matrix
17:17:28 <EvanR> otherwise, wouldnt you want to treat a 1D vector as a 2D
17:18:04 <d34df00d> Moving from immutable to mutable first-level vector gave me 4x MUT speedup and like 2.5x GC speedup.
17:18:30 <d34df00d> So I want to try this approach to see if it further improves the performance (and it should, according to profiling results).
17:18:52 <d34df00d> EvanR: yeah, exactly! Consider this to be a transitions table for an NFA execution engines.
17:19:12 <EvanR> ok
17:19:33 <EvanR> really, is generating these tables a bottleneck
17:19:38 <EvanR> and is helped somehow by mutation
17:20:25 <jared-w> That's surprising to me, honestly
17:20:30 <d34df00d> Yep, at least, at first level I reduced the run time from 50 s to around 18 s.
17:20:33 <d34df00d> The state machines are huge.
17:21:22 <ski> @type traverse Data.Vector.unsafeFreeze <=< Data.Vector.unsafeFreeze
17:21:23 <lambdabot> Control.Monad.Primitive.PrimMonad m => Data.Vector.Mutable.MVector (Control.Monad.Primitive.PrimState m) (Data.Vector.Mutable.MVector (Control.Monad.Primitive.PrimState m) a) -> m (Data.Vector.
17:21:24 <lambdabot> Vector (Data.Vector.Vector a))
17:21:30 <ski> d34df00d : can you use that ^ ?
17:21:39 <d34df00d> ...on one dimension, at least. 10^3 to 10^4 states, about 1-3 (input, new state) transitions per state on average.
17:21:54 <d34df00d> ski: uh, let me try...
17:21:54 <jared-w> damn
17:22:08 <sepakorayl> here is a problem for all. We have a type-deduction state that annotates nodes with type information. Now perhaps there are errors so the type-deducer can't produce a completed annotated ast, it will have either have to produce a maybe completed ast or  an ast with maybe-type annotations.
17:23:07 <ski> would be nice to avoid the intermediate outer `Vector', hm
17:23:34 <jared-w> sepakorayl: I don't understand what the problem is
17:23:55 <sepakorayl> it's 3 am here I am not surprised
17:24:33 <jared-w> You just stated a hypothetical, you didn't actually say what problem you're having with it
17:25:08 <sepakorayl> in the first case it would seem that the type-deducer would have to explicitely handle, unwrap and propage the maybe nodes. The second would seem to be able to support an applicative style.
17:25:54 <ski> "handle, unwrap and propage" ?
17:26:01 <jared-w> These are still neutral hypotheticals. I'm not sure what you're trying to achieve here. Are you asking which scenario is preferable?
17:26:19 <d34df00d> ski: the problem is, that construction expects a value of type VM.MVector (PrimState m) (VM.MVector (PrimState m) a)
17:26:41 <sepakorayl> give me one moment, I 'm writing in chunks
17:26:48 <d34df00d> ski: while stuff I have is (PrimMonad m1, PrimMonad m) => m1 (VM.MVector (PrimState m1) (m (VM.MVector (PrimState m) a)))
17:27:01 <d34df00d> Note the extra inner m for the values of the outer vector, that is different from the outer m1.
17:27:05 <ski> d34df00d : you'd use `runST' instead of `create' here
17:28:10 <d34df00d> ski: yeah, but it seems like there is another problem: inner vectors and the outer vector are indexed by different values for s in ST.
17:28:36 <ski> (iiuc, you get separate `m1' and `m' because you're trying to use two `create's ?)
17:28:50 <d34df00d> ski: nope, right now I don't even have a create.
17:29:03 <ski> ok
17:29:10 <d34df00d> @type Data.Vector.Mutable.replicate 10 $ Data.Vector.Mutable.new 0
17:29:12 <lambdabot> (Control.Monad.Primitive.PrimMonad m, Control.Monad.Primitive.PrimMonad m1) => m1 (Data.Vector.Mutable.MVector (Control.Monad.Primitive.PrimState m1) (m (Data.Vector.Mutable.MVector (Control.Monad.
17:29:12 <lambdabot> Primitive.PrimState m) a)))
17:29:32 <sepakorayl> so say we go with the second option and we have type-deducer functions of the form: typeDeduceNode :: Node -> M (NodeWithAnnotatedTypes (Maybe Type)) instead of typeDeduceNode :: Node -> M (Maybe (NodeWithAnnotatedType Type)).
17:29:39 <ski> i was first thinking you could use `createT' with `create', but then you'd run into the "different values for s" problem
17:29:48 <d34df00d> So, moreover, inner vectors are indexed by the very same s for all of them, which disallows me to runST each of them separately.
17:29:50 <d34df00d> ski: exactly!
17:30:16 <d34df00d> So, ideally you'd have a type like (PrimMonad m1) => m1 (VM.MVector (PrimState m1) (forall m. PrimMonad m => m (VM.MVector (PrimState m) a)))
17:30:22 <d34df00d> But that's impredicative polymorphism.
17:30:36 <ski> d34df00d : oh, shouldn't you use `replicateM', not `replicate' ?
17:30:53 <d34df00d> Yay.
17:30:59 <d34df00d> That changes things drastically!
17:31:34 <d34df00d> So, in plain English, I'm already inside a monad, and I'd like to use the context of that monad to replicate, hence replicateM and not replicate?
17:32:42 <d34df00d> ski: but yeah, combining that with what you've written above solves the problem.
17:33:06 <d34df00d> I'm gonna try to do this with the actual code tomorrow and bug you folks more if it doesn't work.
17:33:08 <d34df00d> Thanks a lot!
17:33:27 <ski> d34df00d : yes, you don't want a vector with the same value in all components, you want a vector where you run the same action to produce a value (not necessarily the same one) for all components
17:33:46 <sepakorayl> How can we then transform NodeWithAnnotatedType (Maybe T) to NodeWithAnnotatedType T in case of no errors ? In this case we can just make it an instance of Functor but what do we do in the general case of multiple annotations and therefore multiple type parameters?
17:34:04 <d34df00d> And I can use the same approach should I decide to move from inner vectors to, dunno, Data.Hashtables.
17:34:05 <d34df00d> That's neat.
17:34:12 <ski> (because in the former case, the value was actually another action. so you had a vector containing unexecuted actions .. not that useful here)
17:34:39 <d34df00d> ski: yeah, I kind of understood that, hopefully, but apparently I wasn't able to wrap my head around enough to figure out replicateM would be my friend.
17:36:18 <ski> sepakorayl : if `Traverseable NodeWithAnnotatedType', then `sequence :: NodeWithAnnotatedType (Maybe T) -> Maybe (NodeWithAnnotatedType T)'
17:36:21 <ski> (sepakorayl : fwiw, have you considered whether `typeDeduceNode :: Node -> MaybeT M (NodeWithAnnotatedTypes Type)' makes sense ?)
17:37:08 <ski> hm, multiple annotations
17:37:34 <sepakorayl> It's a writer monad which I use for error reporting while I am making the maybe-annotated tree so I think not.
17:37:46 <ski> would you like to be able to selectively apply `Maybe' to attributes ?
17:39:25 <sepakorayl> Traversable is my goal but it seems I have to write a ton of boilerplate.
17:39:58 <ski> have you tried deriving it ?
17:41:47 <sepakorayl> yes it's straightforward for simple datatypes of one parameter. My typechecker has two parameters so deriving only works for one of those.
17:42:09 <sepakorayl> So I found the geifunctor library which produces general traversable instances
17:43:42 <sepakorayl> but then I tried to rewrite everything according to the trees-that-grow paper, and the library can't handle type classes.
17:43:50 <sepakorayl> type families*
17:45:04 * ski can't recall reading that paper
17:46:02 <sepakorayl> so I am trying to recheck my assumptions to see if I can avoid this mess
18:05:11 <sepakorayl> I guess I will just go with prepareNode :: NodeWithAnnotatedType (Maybe T1) (Maybe T2) -> Maybe (NodeWithAnnotatedType T1 T2)
18:05:53 <sepakorayl> if I handle all errors during the type deucer stage then these should be simple applicative-style functions
18:22:23 <jared-w> ski: it's a great paper. https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/trees-that-grow.pdf
18:23:15 <Axman6> it sure is
19:23:42 <mniip> cute http://tcpst.net/bx8_.png
19:43:13 <wespiser> jared-w: i love the idea of using 'Phase-Indexed Fields' from that paper 
19:43:53 <wespiser> so you can modify the contents of the tree by type parameterizations throughout the stages of compilation
20:39:41 <davr0s> does haskell have a way of enforcing that a function must be commutative
20:39:47 <tabemann> no
20:40:21 <davr0s> are there any proposals for something like that or features in other languages like that
20:40:43 <davr0s> i guess some annotation or assertion in a  typeclass or something
20:41:11 <masaeedu[m]> What domain do you want it to be commutative over?
20:41:16 <davr0s> i'm thinking of folds and wanting to say where a certain type of fold operation doesn't depend on the order
20:41:51 <davr0s> (what do you mean by 'over what domain')
20:42:14 <masaeedu[m]> Is the a limited set of values in the type of the operand?
20:42:30 <davr0s> it would have to be commutative for all potential values
20:42:48 <davr0s> for any value that the system could possibly present ,  f(a,b) === f(b,a)
20:43:22 <davr0s> i guess we're back into the world of unit tests etc for such things
20:43:43 <EvanR> you can express it with dependent types
20:44:21 <davr0s> i've not looked into languages with those, i've heard of 'idris' ?
20:44:36 <davr0s> i'm not about to distract myself again with another language tangent :)
20:44:36 <kadoban> There's concepts of typeclasses that express such things, like Semigroup is an associative operation by law. Though haskell doesn't enforce it, it assumes you're not lying.
20:44:37 <EvanR> and it would likely be touch to produce proof that a given function is commutative
20:44:47 <EvanR> tough*
20:44:48 <kadoban> I don't know of a typeclass that is commutative, but it's not that far away from that in concept.
20:45:11 <EvanR> right a typeclass specifically for documenting the commutativity would be interesting
20:45:25 <davr0s> well all i have in my head at the momemnt is - "imagine if you could write conditions in the typeclass that must hold" 
20:45:32 <davr0s> i suppose template haskell might let you roll unit tests
20:45:45 <EvanR> you can certainly test properties like that with quickcheck
20:45:56 <EvanR> lambdabot can do it... but i dont know the syntax
20:46:38 <EvanR> but you usually specify the requirements in the documentation
20:47:19 <kadoban> What's the algebraic name for that? It's not abelian, that imposes more stuff, it's not a magma, it's not a semigroup ... is there one that's just commutative?
20:47:20 <davr0s> the specific example i have is quite straightforward, 'a bounding volume typeclass',   'a function for combining ttwo bounding volumes ' .. 'that should be a commutative function'. ->  in turn , you know that folding a collection of bounding volumes.. you can use 'whatever is the most efficient traversal', rather than asking for 'foldl or foldr specifically'
20:47:32 <masaeedu[m]> Perhaps you could somehow tag the values with types
20:47:41 <masaeedu[m]> Using phantom types
20:47:45 <EvanR> commutative magma?
20:47:49 <EvanR> haha
20:47:55 <kadoban> Heh, ya I guess that's good enough, right?
20:48:16 <davr0s> i imagine literally just writing   "combineBounds a b = combineBounds b a" in the typeclass
20:48:25 <EvanR> not having assoc is kind of weird
20:48:36 <davr0s> if thats not too simplistic
20:49:18 <davr0s> as for how to say 'this argument must be a commutative function', i have no specific suggestions  on how that would be best done..
20:49:46 <EvanR> in the documentation comments
20:49:50 <davr0s> thats probably more important for them to figure out
20:50:06 <davr0s> sure 'doc comments' are awesome
20:50:19 <EvanR> the ones that get turned into fancy docs
20:50:27 <davr0s> ... they're awesome, as a stopgap :)
20:50:38 * EvanR gives davr0s dependent types
20:51:13 <EvanR> (f : A -> A -> A, Pi[x,y:A] f x y = f y x)
20:51:18 <davr0s> i set off a few days ago to launch into haskell, as a distraction from my recent forray into rust, as a distraction to ...
20:51:49 <davr0s> is it time for me to drop haskell and launch into a dependantly typed language :)
20:51:51 <kadoban> I keep trying to try rust, after a long forray into haskell.
20:51:55 <pacak> EvanR: I suspect dependent types might not work as well in haskell as they work in a languages where things must be total.
20:52:35 <EvanR> i dont know about that type specifically, but from the dependent haskell paper, it looks like itll be pretty cool, perhaps *because* were not total
20:52:55 <EvanR> it simplifies some aspects of using dependent types
20:53:00 <pacak> It is cool, but you won't be able to use haskell as theorem prover.
20:53:08 <EvanR> thats fine
20:56:45 <jared-w> Dependent haskell will require occasional runtime proofs
20:57:09 <EvanR> right
20:57:11 <jared-w> But you can skip them with a hold-my-beer-it-totally-workz-trust-me-bro annotation in the code, sorta like a rewrite rule
20:58:13 <EvanR> really?
20:58:43 <davr0s> i'm just trying to think which i want more,
20:59:12 <davr0s> 'declaring that this function is commutative' -> gives you more information about what it does
20:59:36 <jared-w> EvanR: yes, that's one of the tradeoffs to making DH practical
20:59:38 <davr0s> or demanding this function argument is commutative  (prevents erroneous use )
21:00:08 <EvanR> youre not really going to strictly require a commutative argument with haskell
21:00:19 <EvanR> it canna be done!
21:00:21 <jared-w> Haskell already is not total, nor consistent. A runtime proof isn't that "strong" anyway compared to, say, an Agda proof
21:00:37 <EvanR> jared-w: i mean, you can skip it?
21:00:56 <EvanR> sort of like a fromJust, "trust me its not Nothing"
21:01:45 <EvanR> haskell is not total, but you write total / productive code anyway right :)
21:01:49 <pacak> More like unsafeCoerce, "trust me", [a] is Maybe a.
21:02:03 <jared-w> https://typesandkinds.wordpress.com/
21:02:31 <jared-w> EvanR: yeah you can. Start reading at the @jlimperg: Pervasive laziness....
21:02:54 <pacak> To make a proof in coq/idris you need to construct a term of specific type using only legit things.
21:03:34 <pacak> In haskell even if you constructed this term - it doesn't mean it's 100% legit.
21:04:19 <masaeedu[m]> I wonder if it is possible to express certain kinds of dependent typing proofs as arithmetic errors in type families using Nat kinds
21:04:58 <EvanR> in idris you can construct anything you want with believe_me
21:06:13 <EvanR> nothings ever 100% legit! there could be a bug in the software or a bug in the entire theory!
21:06:47 <jared-w> I mean, shit, you can be 100% right and then the moon's gravitational pull throws off your math. What do?  ¯\_(ツ)_/¯
21:06:57 <d34df00d> > (f : A -> A -> A, Pi[x,y:A] f x y = f y x)
21:06:58 <pacak> In coq there's also admit and Axiom, but they are usually visible. Plus you can always ask "Which unproven assumptions are required by theorem"
21:06:59 <lambdabot>  <hint>:1:35: error:
21:06:59 <lambdabot>      parse error on input ‘=’
21:06:59 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
21:07:01 <d34df00d> What does that mean?
21:07:05 <d34df00d> What's Pi?
21:07:07 <EvanR> its not valid haskell, or anything
21:07:15 <d34df00d> Oh ok.
21:07:17 <pacak> d34df00d: 3.1415...
21:07:32 <EvanR> Pi[x,y:A] f x y = f y x means for all x y of type A, f x y = f y x
21:07:49 <d34df00d> So I assume it's not some real language, as you said.
21:08:09 <jared-w> It's a bastardization dependent type syntax. EvanR's personal flavor of notation
21:08:12 <EvanR> well, with slight changes to the syntax you can express this in other languages
21:08:21 <jared-w> Intricately designed to be mostly unreadable and highly annoying
21:08:22 <EvanR> itll just take up more space
21:08:27 <d34df00d> I should finally learn some dependently typed language.
21:08:28 <jared-w> (jk)
21:08:41 <mniip> in haskell you'd write    pi (x :: A). B
21:08:43 <pacak> forall f: A -> A-> A ->, forall x y : A, f x y = f y x.
21:08:45 <pacak> valid coq.
21:08:47 <mniip> much like forall
21:08:52 <pacak> I think.
21:08:53 <EvanR> will haskell have equality type?
21:08:53 <d34df00d> Just grasping how one expresses this and how they prove it to the type checker should be interesting.
21:08:59 <mniip> EvanR, of course
21:09:03 <EvanR> ok
21:09:18 <mniip> :t Data.Type.Equality.Refl
21:09:19 <lambdabot> forall k (a :: k). a :~: a
21:09:45 <EvanR> d34df00d: well, you only have 1 tool to prove equality, Refl
21:10:02 <d34df00d> I seem to not have the right mindset yet.
21:10:05 <EvanR> for a given f, you expand f x y and f y x, and hope you can massage it into a form like foo = foo
21:10:16 <d34df00d> Also, what's the paper on DH you mentioned?
21:10:33 <jared-w> which one?
21:10:34 <EvanR> https://www.cis.upenn.edu/~sweirich/papers/eisenberg-thesis.pdf
21:10:41 <d34df00d> Cool, thanks!
21:10:48 <jared-w> That's the main one. The blog I linked earlier is much more approachable
21:11:10 <EvanR> what will a sigma type look like in haskell?
21:11:15 <jared-w> https://typesandkinds.wordpress.com/
21:11:40 <d34df00d> Thanks folks.
21:11:57 <d34df00d> I'm already irritating my colleagues enough with haskell, gonna irritate them with dependent types stuff more.
21:12:03 <EvanR> good!
21:14:08 <EvanR> mniip: herm, isnt that just for types
21:14:23 <mniip> with dependent types does it matter?
21:16:02 <EvanR> i guess k could be Nat ?
21:16:12 <EvanR> and a are values
21:22:05 <Lokathor> @src ($)
21:22:05 <lambdabot> f $ x = f x
21:27:56 <colonelj> what's the function to apply a function n times???
21:28:23 <Lokathor> hmm, iterate?
21:28:28 <Lokathor> :t iterate
21:28:29 <lambdabot> (a -> a) -> a -> [a]
21:28:40 <Lokathor> :t repeat
21:28:42 <lambdabot> a -> [a]
21:28:46 <colonelj> I want something like Integer -> (a -> a) -> a
21:28:56 <Lokathor> guess you want iterate mixed with take
21:29:02 <EvanR> with !! really
21:29:10 <Lokathor> oh right
21:29:16 <EvanR> an astonishingly appropriate use case of !!
21:29:25 <Lokathor> one of the few
21:29:45 <EvanR> colonelj: youll need a starting value
21:29:49 <colonelj> I have one
21:29:55 <EvanR> in your sig i mean
21:29:58 <colonelj> yeah forgot to put that lol
21:30:31 <EvanR> @pl \n f x -> iterate f x !! n
21:30:31 <lambdabot> flip (flip . ((!!) .) . iterate)
21:33:48 <jared-w> there's an appropriate use case of !!?
21:34:21 <Lokathor> why would you use !!?
21:34:54 <Lokathor> I'm assuming that it gives a (Maybe a) back
21:35:10 <colonelj> don't be silly
21:36:26 <jared-w> :t (!!)
21:36:27 <lambdabot> [a] -> Int -> a
21:36:44 <jared-w> We don't work with maybe here, this stuff is 100% grade-A testosterone
21:36:52 <Lokathor> but you said !!?
21:37:05 <jared-w> oooh
21:37:15 <jared-w> (there's an appropriate use case of !!)  ? 
21:37:19 <Lokathor> ah, ha
21:37:59 <EvanR> !! does not give Maybe
21:38:15 <EvanR> > [1,2,3] !! 4
21:38:17 <lambdabot>  *Exception: Prelude.!!: index too large
21:38:28 <EvanR> > [1..] !! 4
21:38:30 <lambdabot>  5
21:39:07 <EvanR> oh !!?
21:39:20 <EvanR> should exist (maybe)
21:39:45 <EvanR> any heard of Mondrian? is there any resource for it anywhere
21:40:15 <jared-w> :t (!!?)
21:40:16 <lambdabot> error:
21:40:16 <lambdabot>     • Variable not in scope: !!?
21:40:16 <lambdabot>     • Perhaps you meant ‘!!’ (imported from Data.List)
21:40:21 <jared-w> eh, worth a shot
21:40:27 <Lokathor> i'm sure there's some sort of safe package with !!? in it
21:40:33 <EvanR> atMay
21:41:15 <jared-w> I like atMay better than !!. Shiny little operators just give people way too much encouragement to sprinkle them everywhere like glitter
21:42:00 <Lokathor> > 1 <$ [1,2,3]
21:42:02 <lambdabot>  [1,1,1]
21:42:06 <Lokathor> huh
21:42:40 <Lokathor> feels weird that that's part of Functor's typeclass, and not just defined in terms of const or whatever
21:42:50 <Lokathor> i guess for potential overrides?
21:43:00 <EvanR> weird operators give people excuse for dismissing haskell because of weird "syntax"
21:43:19 <ski> @type \n f -> case n of 0 -> id; _ | n > 0 -> let foo 0 _ g = g; foo n f g = bar n f where bar n f | even n = bar (n `quot` 2) (f . f) | otherwise = foo (n - 1) f (f . g) in foo (n - 1) f f
21:43:21 <lambdabot> Integral t => t -> (a -> a) -> a -> a
21:43:26 <Cale> I use <$ several times in a typical day actually
21:43:49 <Cale> Specifically with Reflex's Event
21:44:12 <kadoban> Heh, yeah. The only times I seem to use <$ and friends is either in parsing or or reflex
21:44:17 <jared-w> EvanR: well, on one hand, I really like weird operators
21:44:30 <kadoban> EvanR: People will always find some reason or another if they want to.
21:44:32 <jared-w> Beautiful abstractions and powerful, general tools should be very easily accessible
21:44:55 <jared-w> <*> , $,  <$>, >>=, etc, are really great because of that
21:45:22 <jared-w> But when you put non powerful tools or even very-rarely-actually-the-right-thing and give them a super convenient and pretty operator... 
21:45:59 <jared-w> That's why I don't like !!. I'm fine with an `at` function, but giving it a pretty and accessible infix operator just encourages abuse, to me :p
21:46:10 * ski . o O ( syntactic salt )
21:49:45 <codygman> I think my pipe is wrong since using Pipes.Group.maps f is giving different results than map f, but I'm not sure what the issue is. Is there a function that turns a function into a pipe which applies that function?
21:49:46 <codygman> https://github.com/codygman/fixedWidthToDelimited/blob/master/library/Example.hs#L46
21:50:12 <Lokathor> so, given map's rewrite rules, is using map over fmap going to end up faster when you know you're working with lists?
21:50:23 <Lokathor> or is the fmap for list written in terms of map?
21:52:50 <davr0s> haskell operators can't override function applcation in precidence, rigth?   a b+c d   is always (a b)+(c d)  for any user defined operators
21:52:59 <Lokathor> correct
21:54:21 <davr0s> it does make logical sense (and I wouldnt want to change it) but it's one of several things that makes haskell still feel slightly alien to a C++ conditioned brain
21:54:53 <davr0s> i hope i can get used to this
21:55:03 <davr0s> maybe i could use electric shock therapy
21:55:52 <davr0s> i can see haskell syntax with the lack of brackets r.e. function application makes much more sense for currying
21:56:10 <davr0s> currying foo(a,b,c)  foo(a,b) etc wouldn't be as sensible
21:56:27 <ski>   foo(a)(b)(c)
21:57:25 <Lokathor> in fact, when Purescript spits it's haskell-like langauge out as javascript, it generates javascript that runs exactly like that
21:57:30 <Lokathor> foo(a)(b)(c)
21:57:38 <davr0s> i try to keep a space between any ident and brackets to remind me *this is not a function call*
21:57:43 <ski> > let foo(a)(b)(c) = a <= c && c <= b in map(foo(3)(5))([0 .. 9])
21:57:45 <lambdabot>  [False,False,False,True,True,True,False,False,False,False]
21:58:25 <Lokathor> davr0s, (1) why all the brackets? You can live without brackets, (2) stop trying to take over the universe with your robots
21:58:54 <davr0s> Lokathor they are 'travel machines' for living creatures, not robots
22:10:45 <Lokathor> Cale, you said that you use <$ a lot, but does your use of it affect if it should part of Functor or just defined in terms of fmap and const?
22:11:07 <Lokathor> I think it's just an efficiency thing for the few types that could do it better than fmap and const
22:14:03 <jared-w> Lokathor: where did the robot comment come from? lol
22:14:25 <davr0s> he was confusing my creations with robots
22:14:37 <davr0s> when everyone knows they are not robots
22:16:46 <Lokathor> jared-w, davr0s, https://www.youtube.com/watch?v=K7_KXL6VBBE
22:17:29 <jared-w> I don't know what creations you're talking about, either
22:18:00 <davr0s> jared-w 1min,
22:18:17 <davr0s> https://www.youtube.com/watch?v=dkelV2WUNdw
22:19:15 <jared-w> oooh, doctor who reference, gotcha
22:21:35 <jared-w> oh man, the 70s
22:22:27 <Cale> Lokathor: Oh, no. I was responding to the sentiment that there are too many operator symbols :)
22:22:55 <Cale> Lokathor: Though I don't know actually. I'd have to look and see if <$ is implemented more efficiently for Event
22:23:04 <jared-w> In theory, it could be...
22:23:32 <jared-w> (and the theorist, satisfied that it /could/ be made faster if anyone cared enough, wrote "pull requests accepted" and left it at that)
22:23:45 <jared-w> s/accepted/welcome/
22:24:00 <Cale> Ah, apparently it's not specially implemented in Spider.
22:24:02 <Lokathor> good
22:24:47 <Cale> I can't really imagine it would ever be *much* more efficient.
22:26:10 <jared-w> Then again, a little bit here, little bit there, and all the sudden you might be surprised  ¯\_(ツ)_/¯
22:26:20 <kayess> I've got a good one. I've managed to get map to produce an infinite list from a finite one. That should never happen right?
22:26:43 <Lokathor> kayess, sounds like a wonky Functor instance?
22:27:03 <kayess> Something is clearly not right. Start with this: let p s t = map (\x -> x) [(s-t+1)..s]
22:27:13 <jared-w> > map (repeat) [1..5]
22:27:15 <lambdabot>  [[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...
22:27:24 <jared-w> bam, produce infinite list from finite list
22:27:47 <ski> > length (map repeat [1..5])
22:27:49 <lambdabot>  5
22:27:49 <kayess> And then try it with some big number (hold on, it killed  my ternnal again)
22:28:00 <ski> (it's a finite list)
22:28:13 <jared-w> ah, right, it's nested
22:28:17 <Lokathor> yeah
22:28:26 <kayess> let p s t = map (\x -> x) [(s-t+1)..s]
22:28:26 <kayess> p 9223372036854775808 10
22:28:26 <kayess> ^^ That's fine
22:28:37 <kayess> But change the lambda to be \x -> x/2 and blam
22:28:45 <ski> > map (take 4) (map repeat [1..5])
22:28:47 <lambdabot>  [[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4],[5,5,5,5]]
22:29:01 <kayess> let p s t = map (\x -> x/2) [(s-t+1)..s]
22:29:01 <kayess> p 9223372036854775808 10
22:29:01 <kayess> ^^ Dies a fiery death
22:29:10 <ski> > zipWith take [2 ..] (map repeat [1..5])
22:29:12 <lambdabot>  [[1,1],[2,2,2],[3,3,3,3],[4,4,4,4,4],[5,5,5,5,5,5]]
22:29:13 <Lokathor> > let p s t = map (\x -> x) [(s-t+1)..s] in p 9223372036854775808 10
22:29:17 <lambdabot>  [9223372036854775799,9223372036854775800,9223372036854775801,922337203685477...
22:29:24 <Lokathor> > let p s t = map (\x -> x/2) [(s-t+1)..s] in p 9223372036854775808 10
22:29:26 <lambdabot>  [4.611686018427388e18,4.611686018427388e18,4.611686018427388e18,4.6116860184...
22:29:46 <kayess> Try it in ghci, I'm using 8.0.2
22:30:06 <Lokathor> > let p s t = map (\x -> x/2) [(s-t+1)..s] in length $ p 9223372036854775808 10
22:30:12 <lambdabot>  mueval-core: Time limit exceeded
22:30:19 <Lokathor> well it's certainly a long list
22:30:36 <kayess> The input is only 10 long and all the lambda does is a division
22:30:43 <kayess> That should spit out 10 numbers right?
22:30:52 <Lokathor> > let p s t = map (\x -> x/2) [(s-t+1)..s] in length $ p 20 10
22:30:54 <lambdabot>  10
22:31:06 <Lokathor> > let p s t = map (\x -> x) [(s-t+1)..s] in length $ p 20 10
22:31:07 <lambdabot>  10
22:31:09 <kayess> Keep increasing 's' and it will blow
22:31:26 <kayess> Bug right?
22:31:27 <Lokathor> well that's because the length of the list is s-t, ish
22:31:50 <Lokathor> it's not infinite, you just run out of memory trying to keep it all active at once
22:32:04 <Lokathor> > 9223372036854775808 - 10
22:32:06 <lambdabot>  9223372036854775798
22:32:21 <kayess> I expect that the conversion to double is lossy enough that the +1 produces the same number all the time
22:32:34 <kayess> How would you force it to produce the list before it does the division?
22:32:39 <ski> > length (let s = 9223372036854775808; t = 10 in [s-t+1 .. s])
22:32:40 <lambdabot>  10
22:33:05 <jared-w> > let p s t = map (\x -> x) [(s-t+1)..s] in length $ p 9223372036854775808 10
22:33:07 <lambdabot>  10
22:33:11 <jared-w> neat
22:33:22 <kayess> :)
22:33:36 <Lokathor> hmm
22:33:51 <ski> i suppose you want to you a fractional number type, rather than an integral one ?
22:33:57 <Lokathor> > let p s t = map (\x -> fromIntegral x / 2.0) [(s-t+1)..s] in length $ p 9223372036854775808 10
22:33:59 <lambdabot>  10
22:34:00 <ski> s/to you/to use/
22:34:02 <cocreature> do we have some library that implements different search strategies somewhat generically, i.e., depth first, breadth first, iterative deepening depth first and whatever else there is?
22:34:07 <Lokathor> > let p s t = map (\x -> fromIntegral x / 2.0) [(s-t+1)..s] in p 9223372036854775808 10
22:34:09 <lambdabot>  [4.611686018427388e18,4.611686018427388e18,4.611686018427388e18,4.6116860184...
22:34:25 <Lokathor> i think your s is just too big for floating math
22:34:28 <kayess> Is there a way to use big integers and have ratios instead of convert to a double?
22:34:31 <jared-w> Yup, I'm almost positive it's number conversion that's making it infinite because it just repeats a number over and over
22:34:51 <kayess> It's clearly a loss of precision associated with the reals
22:34:52 <Lokathor> :t (%)
22:34:53 <lambdabot> Integral a => a -> a -> Ratio a
22:35:17 <acyed> If I'm in a do block, and I use a case statement, do I leave that monadic environment?
22:35:26 <Lokathor> acyed, no
22:35:29 <jared-w> cocreature: how would you define those different types of strategies on certain data structures; for instance, DFS, BFS, on a list?
22:35:32 <Lokathor> > let p s t = map (\x -> (x % 1) / 2.0) [(s-t+1)..s] in p 9223372036854775808 10
22:35:34 <lambdabot>  [9223372036854775799 % 2,4611686018427387900 % 1,9223372036854775801 % 2,461...
22:35:57 <codygman> Is it sensible to try and make this function that would allow me to apply Text functions to pipes groups? type: (T.Text -> T.Text) -> FreeT (Producer T.Text m) m () -> FreeT (Producer T.Text m) m ()
22:36:11 <ski> acyed : there is no `case' command. it's a `case'-expression. if you want to use `<-', or multiple commands inside branches, you must use `do' again
22:36:59 <kayess> I'm getting: Variable not in scope: (%) :: t -> Integer -> b
22:37:02 <cocreature> jared-w: I don’t want it to work on _all_ types. I was thinking of some kind of typeclass to provide the operations the search needs for my data type. but if it uses a fixed representation, that’s probably also not too bad (although I would like to avoid inductive graphs).
22:37:10 <ski> kayess : `import Data.Ratio'
22:37:10 <kayess> Isn't % modulo?
22:37:26 <cocreature> jared-w: also you can easily view a list as a graph and directly translate the strategies that way
22:37:29 <ski> no, it's rationals
22:37:38 <ski> @type mod
22:37:39 <lambdabot> Integral a => a -> a -> a
22:37:55 <ski> > 1 % 2 + 1 % 3
22:37:56 <lambdabot>  5 % 6
22:38:05 <jared-w> true, didn't think about that. I suppose since any data structure can be represented as a graph (?) that you can create generic traversable methods...
22:38:29 <kayess> Can I force a conversion to a double at the end of my calculation?
22:38:47 <ski> > realToFrac (1 % 3)
22:38:49 <lambdabot>  0.3333333333333333
22:39:15 <jared-w> > realToFrac (1 % 3) :: Double
22:39:17 <lambdabot>  0.3333333333333333
22:39:21 <jared-w> bam, it's now ad ouble
22:39:24 <jared-w> a double*
22:39:24 <kayess> > let p s t = realToFrac % foldl1 (*) $ map (\x -> x%s) [(s-t+1)..s]
22:39:26 <lambdabot>  <no location info>: error:
22:39:26 <lambdabot>      not an expression: ‘let p s t = realToFrac % foldl1 (*) $ map (\x -> x%s...
22:39:46 <kayess> > let p s t = realToFrac % foldl1 (*) $ map (\x -> x%s) [(s-t+1)..s] in p  9223372036854775808 10
22:39:48 <lambdabot>  error:
22:39:48 <lambdabot>      • Couldn't match expected type ‘[Ratio a] -> t1’
22:39:49 <lambdabot>                    with actual type ‘Ratio (t0 b0 -> b0)’
22:39:59 <kayess> I"m still doing something stupid....
22:40:18 <jared-w> the $ is throwing it off I'm pretty sure
22:40:38 <ski> > let p s t = realToFrac (foldl1 (*) (map (% s) [s - t + 1 .. s])) in p 9223372036854775808 10
22:40:40 <lambdabot>  1.0
22:40:44 <jared-w> It's not a magical "avoid only the parens I don't wanna type" operator
22:40:48 <kayess> I'm an idiot. Typed % when I meant $
22:41:08 <jared-w> np, we all do it :p
22:41:14 <kayess> > let p s t = realToFrac $ foldl1 (*) $ map (\x -> x%s) [(s-t+1)..s] in p  9223372036854775808 10
22:41:16 <lambdabot>  1.0
22:41:31 <kayess> Yup, and it's even better when done in public right? :)
22:41:58 <kayess> That helped though. Now I get answers that look right
22:41:59 <jared-w> How do you think I'm so useful in here? I just try to be helpful and watch everyone shoot me down for being wrong
22:49:13 <slack1256> custom prelude for numerics? (matrix types etc)
22:52:22 <acyed> ok, second case-expression question: if I have a function that returns m (Maybe a), inside the monad, can I match against the Maybe a part? Yesod uses a stack of HandlerT App IO a, and I can't figure out how to get past it. http://lpaste.net/356568 
22:53:29 <jared-w> slack1256: there are several custom preludes out there that do different things
22:54:36 <jared-w> acyed: try changing the :: Int to :: HandlerT App IO Int
22:54:49 <mud> acyed: Maybe you want let parsedNumber = that stuff on line 8 ?
22:55:04 <mud> That type doesn't seem to make sense otherwise
22:57:01 <acyed> it's still saying Actual type: NonNull (NonNull String) -> HandlerT App IO Int
22:58:04 <jared-w> oh wait, whoops
22:58:29 <jared-w> the type is actually Int, that's fine. You want a let parsedNumber =, like what mud suggested
22:59:05 <jared-w> the <- was throwing it off because it was expecting an IO sort of action from the bind
23:06:18 <acyed> alright, I've put that line as a let expression. I've tried fmap-ing and LiftIO, but I'm lost
23:06:46 <jared-w> Did it not work?
23:07:00 <jared-w> Can you edit your lpaste with the current code and current error?
23:07:04 <acyed> unfortunately not
23:08:25 <colonelj> can someone help me with random-fu and mersenne-random-pure64?
23:08:48 <colonelj> I'm not sure how the pieces fit together
23:09:04 <jared-w> I don't know what those are
23:09:33 <colonelj> libraries for random number generation
23:09:40 <jared-w> ahh gotcha
23:09:45 <colonelj> PureMT is an instance of RandomGen
23:10:54 <jared-w> What are you trying to do with them?
23:11:31 <colonelj> I want to generate a series of multivariate normal timeseries and still hold onto the seed
23:12:08 <colonelj> I mean the internal state
23:12:08 <Lokathor> colonelj, use the next method? if you want to be fancy, check into the MonadRandom package / monad
23:12:35 <colonelj> yes I think I want to use MonadRandom
23:12:56 * jared-w accidentally spawned 200 firefox windows
23:12:59 <jared-w> that was entertaining
23:15:20 <Lokathor> @src ($)
23:15:20 <lambdabot> f $ x = f x
23:15:26 <Lokathor> :t ($)
23:15:27 <lambdabot> (a -> b) -> a -> b
23:15:41 <jared-w> So, I'd probably stay away from mersenne-random-pure64 for now. The higher quality the random sources, the more of a pain in the ass they are to use. Once you have something working with a lower quality random generator, it's much easier to get the fancier ones working
23:16:20 <jared-w> oh nvm, I see how they're connected now
23:16:53 <jared-w> random-fu uses the mersenne library internally as its random-source and provides a interface to use it
23:18:24 <colonelj> I don't think it does, I think it's an option
23:19:10 <colonelj> where the hell is sampleRVar defined
23:20:03 <acyed> sorry, my computer crashed (damn ebay thinkpad and/or debian) 
23:23:31 <jared-w> ebay thinkpads are tanks, man
23:25:10 <jared-w> colonelj: the library has 3 major parts. A random-source that provides RVarT's backend
23:25:55 <Jello_Raptor_> Hey all, is there some reasonable variant of F-algebras for languages that have types? I've got a little simply typed lambda calculus DSL that I would like to embedded in Haskell in a way that lets me hijack the Haskell type checker 
23:26:12 <jared-w> You can use any supported entropy source (the example the readme uses is System.Random.MWC), in the random-source source directory, there's PureMT, MWC, IO, DevRandom, Std, StdGen
23:26:56 <acyed> http://lpaste.net/356569
23:27:10 <jared-w> each one correlates to the supported entropy generator library that can be used as a backend
23:27:24 <jared-w> If you're using PureMT, you're using the mersenne package
23:27:26 <Jello_Raptor_> I could abuse GADTs or try to use type families as type functions but that all ends up horribly breaking the nice properties of an f algebra. 
23:28:01 <jared-w> Jello_Raptor_: Look up FC, haskell's very own typed F-algebra (I think...)
23:28:29 <jared-w> acyed: oh whoops, you changed the let, but forgot to change the :: HandlerT App IO Int back to :: Int
23:29:02 <colonelj> jared-w: where are you reading about supported backends from?
23:30:06 <jared-w> colonelj: in the readme for random-fu, `random source` is the backend for RVarT. It is arbitrary sourcces of entropy
23:30:21 <jared-w> Which tells me that in the random-source there's going to be various backends for whichever entropy sources the package has supported
23:30:46 <jared-w> Also, in Usage, the package mentions importing Data.Random and some supported entropy source
23:31:19 <acyed> jared-w: I updated the lpaste with the error. How to people work through problems like this? I with there was a way to stop the compiler at the error and mess around with ghci
23:31:25 <jared-w> So, then I trekked off to random-source, src/Data/Random, source.hs
23:31:55 <acyed> whoops, new error but I didn't update that I changed it to just :: int
23:32:23 <acyed> fixed
23:33:26 <jared-w> Well, a few things stick out to me.
23:33:50 <jared-w> you have an in do, but the following lines of code don't look indented correctly
23:34:48 <jared-w> and when you say "let x = fun in do" you scope it unnecessairly. Which is fine, if you want that...
23:35:57 <acyed> ahhh, Text is not the same thing as [Char]
23:36:18 <acyed> damn, I've been looking at this for a long time and I didn't realize 
23:36:20 <jared-w> colonelj: and the source.hs is just the random source exports, so going into Source/ you see, voila, all of the backends
23:36:44 <jared-w> haha, I didn't even notice that myself
23:36:45 <cocreature> Jello_Raptor_: can you be a bit more specific? I’m not quite sure what problems GADT cause for you. in general, GADTs are the easiest solution for typechecking dsls via the Haskell typechecker
23:36:47 <colonelj> jared-w: I'm trying to just read the docs
23:37:06 <jared-w> what docs?
23:37:19 <colonelj> on hackage
23:37:34 <colonelj> I don't even know where the Usage part you found is
23:37:46 <jared-w> oh I was on github
23:38:53 <jared-w> Yeah, random variable sampling: https://hackage.haskell.org/package/random-fu-0.2.7.0/docs/Data-Random.html "is done w.regard to a generic basis of primitive variables"
23:39:28 <jared-w> "User defined variables should use existing high-level variables such as Uniform and Normal. Data.Random.Source defines classes for entropy sources that provide implementations... Several are available in the Data.Random.Source.* modules"
23:39:36 <colonelj> do you know where sampleRVar is?
23:41:15 <jared-w> Should be in Data.Random.RVar?
23:41:50 <jared-w> https://github.com/mokus0/random-fu/blob/master/rvar/src/Data/RVar.hs#L91
23:42:00 <colonelj> yea just found it
23:42:21 <jared-w> did you find it in github or in hackage?
23:42:25 <colonelj> hackage
23:42:35 <colonelj> it's in a different package clearly
23:43:07 <jared-w> it's in rvar/src/Data/RVar.hs  ¯\_(ツ)_/¯
23:43:29 <colonelj> https://hackage.haskell.org/package/rvar-0.2.0.3/docs/Data-RVar.html
23:43:48 <colonelj> that github has multiple packages in it
23:44:05 <jared-w> yeah, I see that now
23:44:17 <jared-w> people call me crazy for looking at the github first instead of hackage
23:44:43 <jared-w> but this is why. It's really rare for me to find a hackage layout that makes more sense than the github layout. Takes actual author skill in writing to do that and most people suck at it
23:45:25 <colonelj> the hackage docs seem to pull together random subsets of docs from elsewhere so then bits are randomly missing
23:46:13 <jared-w> yeah, it's pretty common when people split things into separate packages but they're all part of one "concept"
23:46:56 <colonelj> how would I declare a MonadRandom instance?
23:47:09 <colonelj> for State PureMT
23:47:50 <Jello_Raptor_> Cocreature: mainly different evaluators, if I want to evaluate the calculus normally then each term becomes the relevant Haskell type `Foo int -> int; Foo bool -> bool` (which doesn't let me encode recursion nicely) but if I want to rendet
23:48:49 <Jello_Raptor_> Render the code to text, a different evaluators would  have some `Foo a -> String`
23:49:00 <Jello_Raptor_> For all a
23:49:37 <cocreature> Jello_Raptor_: if you implement your evaluator as "Foo a -> a" it should work no?
23:51:05 <colonelj> jared-w: would it be "MonadRandom (State PureMT)"?
23:52:47 <jared-w> :t MonadRandom (State PureMT)
23:52:48 <lambdabot> error:
23:52:48 <lambdabot>     Data constructor not in scope: MonadRandom :: t0 -> t
23:52:48 <lambdabot> error:
23:52:54 <jared-w> fudge
23:53:05 <jared-w> colonelj: no idea, but that looks plausible
23:53:54 <colonelj> jared-w: it's ok I found the instance in the sauce
23:54:10 <Jello_Raptor_> Cocreature: that won't be true for evaluator, so I can't have some nice version of `cata` from https://www.schoolofhaskell.com/user/bartosz/understanding-algebras
23:54:27 <Jello_Raptor_> True for every evaluator*
23:54:43 <jared-w> colonelj: ahh right, yeah you shouldn't need to do any monadRandom instances if you're using what's already in the source.* modules
23:56:07 <jared-w> colonelj: if you're interested, https://github.com/mokus0/random-fu/blob/master/random-source/src/Data/Random/Source/Internal/TH.hs this is the template haskell if you want to "unroll" the TH instance of monadRandom 
23:57:31 <colonelj> jared-w: yeah... I'll just assume it works
23:58:05 <cocreature> Jello_Raptor_: right but the problem starts earlier: you can’t express GADTs using Fix
23:58:08 <colonelj> this is maybe a noobish question but how do I actually seed the RNG and create some initial State
23:59:54 <Jello_Raptor_> Cocreature: yeah :/ the best solution I can get is make some sum type for each evaluator that wraps up every typed element as it works from bottom up. 
