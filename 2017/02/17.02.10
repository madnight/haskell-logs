00:00:11 <ezyang> look at http://cabal.readthedocs.io/en/latest/nix-local-build.html#cfg-field-profiling-detail 
00:01:31 <ezyang> you probably want toplevel-functions 
00:01:35 <qmm> is there an equivalent of repeat for Vector?
00:02:03 <geekosaur> the problem with not profiling the libraries you use is that laziness means your thunks may be forced in those libraries (which won't then profile them properly) and their thunks may be forced in your code (which then might also mis-profile)
00:02:34 <geekosaur> basically you end up with profiling output that is at best untrustworthy and at worst completely meaningless
00:03:03 <geekosaur> so ghc tries to prevent you from doing it
00:03:04 <dhalgren_> is these something pointfree I could do instead of \(x,y)->(x, y x) ?
00:03:39 <geekosaur> @src (,) fmap
00:03:39 <lambdabot> fmap f (x,y) = (x, f y)
00:03:54 <geekosaur> so, not exactly
00:04:00 <dhalgren_> hm!
00:04:26 <jchia> ((,,) <$> fst <*> snd <*> fst)
00:04:29 <ezyang> geekosaur: The need to profile libs is more of a technical limitation 
00:04:59 <jchia> sorry, misread
00:07:39 <jchia> dhalgren_: pointfree.io has something but it's ugly
00:08:22 <dhalgren_> haha, thx, I'll take a look
00:08:24 <geekosaur> @pl  \(x,y)->(x, y x)
00:08:24 <lambdabot> uncurry (liftM2 (.) (,) (flip id))
00:08:37 <geekosaur> but you dont get non-ugly for that I'm pretty sure
00:08:38 <dhalgren_> yeah
00:09:51 <dhalgren_> so that's a pointfreefy bot? nice :D
00:10:06 <tsahyt> qmm: vectors are finite, there can't be an equivalent of repeat. There is replicate though.
00:10:08 <geekosaur> also known as the obfuscated code generator >.>
00:10:28 <qmm> tsahyt: ruh roh!
00:10:46 <dhalgren_> @pl  \(x,y) -> (x, zipWith (+) x y)
00:10:46 <lambdabot> uncurry (liftM2 (.) (,) (zipWith (+)))
00:10:47 <qmm> monochrom: your emerge function will not work
00:10:50 <tsahyt> qmm: what would you need that for?
00:10:53 <dhalgren_> yeah, uf
00:11:18 <qmm> emerge xs ys = V.zipWith (++) (map (:[]) xs ++ repeat ([""])) ys
00:11:34 <qmm> merge xs ys = zipWith (++) (map (:[]) xs ++ repeat ([""])) ys -- rather
00:12:17 <monochrom> Maybe "" needs to be BL.empty because you're doing ByteString.
00:12:19 <geekosaur> @djinn (a, b -> c) -> (a, c)
00:12:19 <lambdabot> -- f cannot be realized.
00:12:22 <qmm> merge xs ys = V.zipWith (V.++) (V.map (V.cons []{- <-um.. -}) xs V.++
00:12:31 <geekosaur> figured. exference didn't like it either
00:12:43 <monochrom> (:[]) becomes V.singleton
00:13:02 <geekosaur> actually I think I got that type wrong, it makes no sense
00:13:23 <monochrom> you will have to replace "repeat" by "V.replicate something something" and compute the necessary length yourself
00:13:41 <geekosaur> @djinn (a, a -> c) -> (a, c)
00:13:42 <lambdabot> f (a, b) = (a, b a)
00:13:53 <monochrom> There is also the issue of urls :: [String] but you will need [ByteString] eventually
00:13:53 <dhalgren_> well, yes
00:13:57 <geekosaur> yeh, nothing useful there, it doesnt generate pointfree
00:14:09 <geekosaur> and "piping" it through @pl would just get you the same garbage
00:14:26 <geekosaur> @. pl djinn (a, a -> c) -> (a, c)
00:14:26 <lambdabot> f = uncurry (liftM2 (.) (,) (flip id))
00:14:53 <qmm> monochrom: there isn't an equivalent of repeat for Vector i'm told
00:15:03 <qmm> merge xs ys = zipWith (++) (map (:[]) xs ++ repeat ([""])) ys
00:15:14 <monochrom> you will have to replace "repeat" by "V.replicate something something" and compute the necessary length yourself
00:15:21 <Lokathor> vector is sadly light on the functions it includes
00:15:29 <geekosaur> repeat makes no sense for a vector
00:15:33 <geekosaur> vectors are fixed length
00:15:36 <geekosaur> as has already been stated
00:15:41 <qmm> merge xs ys = V.zipWith (V.++) (V.map (V.singleton) xs V.++ V.repeat ([BL.empty])) ys
00:15:45 <geekosaur> wishing will not change that
00:15:54 <monochrom> No, vector is sadly heavy and plentiful on the functions it includes.
00:16:10 <tsahyt> monochrom: why sadly?
00:16:11 <dhalgren_> its prob as good as its gonna get . I was thinking (\(x,y)-> (x, y x)).(id *** (zipWith (+))) and then something for that pointed part to clean it up but prob then what I started with is better \(x,y) -> (x, zipWith (+) x y)
00:16:47 <monochrom> When I look at its doc, it goes on forever and longer than Data.List and makes me think "I thought list was the infinitely long one"
00:17:44 <Lokathor> monochrom, sorry, I mean that DAta.Vector.Unboxed.Mutable specifically is light on the functions I often want :P
00:17:45 <tsahyt> and I still find myself missing some things from Data.Vector. There is unsafeHead and head but no safeHead for example
00:18:04 <tsahyt> i.e. Vector a -> Maybe a
00:19:01 <monochrom> OK, yes, the mutable ones are impoverished. I think because "you can loop over read/write yourself, or you can always freeze-thaw"
00:19:55 <monochrom> But also yes they should have a view :: Vector a -> Maybe (a, Vector a)
00:20:14 <dhalgren_> do people avoid partial functions systematically? even when the err state would actually be an impossible state (that should error out)?
00:20:21 <Lokathor> i don't follow why view gives back a vector
00:20:37 <monochrom> it merges head and tail
00:20:45 <Lokathor> ah ha
00:20:49 <monochrom> some people avoid partial functions religiously. I don't.
00:21:25 <dhalgren_> seems to me a shame to deal w some Maybe wrapper when in the end I really want to Nothing -> error "wtf?" anyhow
00:21:36 <Lokathor> dhalgren_, if there's an error state you can reach only when things are unrecoverably bad to the "you'll need to rewrite and recompile this" point, then sure throw the error
00:21:37 <tsahyt> me neither, as long as I can guarantee that they're total under the assumption that my invariants hold
00:21:41 <Lokathor> :t fromJust
00:21:42 <lambdabot> Maybe a -> a
00:21:46 <Lokathor> dhalgren_, ^
00:21:53 <tsahyt> if they break in that case, there's no sane way to recover anyhow
00:21:53 <monochrom> I want view, not because of the totality religion, but because of the pattern-matching religion. http://www.vex.net/~trebla/haskell/crossroad.xhtml
00:22:21 <dhalgren_> Lokathor: yeah, that fn is exactly my "sin"  in some code I'm playing with
00:22:45 <monochrom> @quote monochrom safeFromJust
00:22:45 <lambdabot> monochrom says: I use safeFromJust :: Maybe a -> Maybe a
00:22:52 <Lokathor> hahahahah
00:23:04 <monochrom> And for a naughty one:
00:23:10 <monochrom> @quote monochrom unsafeCoerce
00:23:10 <lambdabot> monochrom says: isTrue = (unsafeCoerce :: Either a b -> Bool) . (unsafeCoerce :: Maybe c -> Either a b) . (unsafeCoerce :: Bool -> Maybe c)
00:23:42 <Lokathor> i can't even follow that one in IRC
00:23:58 <monochrom> Don't worry, I didn't test it.
00:24:02 <cocreature> Lokathor: it’s just id, created by composing unsafeCoerce three times
00:24:04 <Lokathor> my window wraps it at just the wrong part to read it easily :P
00:24:06 <tsahyt> I want to test that though
00:25:12 <Lokathor> https://github.com/Lokathor/galaxy-break/blob/master/lib/GalaxyBreak.hs guys check out my sweet text adventure game
00:25:15 <tsahyt> TIL unsafeCoerce False :: Maybe c == Nothing
00:25:17 <Lokathor> there's FIVE whole rooms!
00:26:15 <geekosaur> tsahyt, yep. constructor tags start at 0, Bool has two of them as do Maybe and Either, Bool does not have associated values -> as long as you immediately unsafeCoerce away again instead of doing something that would access a value, it works
00:26:48 <Lokathor> sounds like rust's "nullable pointer optimization" with Option<&T>
00:26:48 <dhalgren_> Lokathor: r u familiar with the interactive fiction scene? Inform seems like a fascinating language...
00:27:10 <Lokathor> dhalgren_, I know it exists, but because of the eventual scope of this game it's not at all suitable to my needs
00:27:31 <dhalgren_> as in tiny or huge?
00:27:45 <tsahyt> geekosaur: I see. that's still terrible though.
00:27:47 <Lokathor> as in, this is a text adventure that morphs into an incrimental game :P
00:27:49 <geekosaur> it's moderately evil and requires knowing how ghc lays things out
00:27:57 <dhalgren_> ha!
00:28:00 <tsahyt> I tried unsafeCoerce True :: Maybe c first and it broke ghci
00:28:16 <Lokathor> dhalgren_, https://github.com/Lokathor/galaxy-break/wiki explains it a bit
00:28:17 <geekosaur> and I think it is possible if you used it in some circumstances with ghc8 and optimization, it would break
00:28:31 <geekosaur> because ghc8 does some optimizations automatically that used to require annotations
00:29:03 <tsahyt> but doesn't that whole chain just optimize away to id anyhow? at the end it's just unsafeCoercing from Bool back to Bool
00:29:23 <geekosaur> (with respect to packing and unboxing... although ... it should not apply those to any type that has more than one constructor, so probably safe anyway)
00:31:47 <geekosaur> you'd hope. but unsafeCoerce is actually somewhat tricky and even if you think you know what you are doing you can get into trouble
00:33:14 <geekosaur> btw I *think* you could have done that in separate steps in ghci if you disabled the automatic `print it`
00:33:27 <geekosaur> but, as I said, it's a bit tricky
00:34:53 <dhalgren_> Lokathor: I'd suggest you take a look at some intfiction regardless (and maybe some articles - famous author Emily Short has a rather rich blog for eg, w bunch of theory etc), simply to evaluate their take (takes actually) on the UI; for eg in my experience, there's nothing more frustrating than an overly primitive parser that promises more freedom than it delivers. yet there are ways to make its 
00:34:59 <dhalgren_> affordances clearer even if smallish  (modern restricted parser games)
00:36:33 <tsahyt> geekosaur: I've never had a real world usecase for it anyhow tbh
00:36:45 * geekosaur is now recalling ancient text adventures where one of the minigames was figuring out what the parser would let you do...
00:37:07 <bollu> STGI uses trifecta, right?
00:38:41 <geekosaur> tsahyt, afaik the only real world usecase for it is manually optimizing an edge case in newtype wrappers
00:39:02 <tsahyt> what edge case would this be?
00:39:10 <tsahyt> I thought the wrapper optimizes away completely anyhow?
00:39:48 <geekosaur> it's supposed to but there is some case I am not recalling where the compiler can't completely optimize it away and you end up with a pointless runtime call to id
00:40:28 <tsahyt> that sounds like it'd be very hard to find in the first place
00:40:32 <Lokathor> dhalgren_, I'd say that my plans, in terms of interface, are more influenced by Aardwolf MUD than anything else, if you're familiar with it, or with MUDs in general
00:42:19 <geekosaur> tsahyt, as I understand it, is's actually a fairly formulaic situation (and the fact that the compiler can't optimize it is an ongoing frustration, but it's a particularly tricky case to deal with from the compiler, it's only "obvious" to people)
00:42:56 <dhalgren_> aha, I see. well, I played only a handfull of sessions on one server, can't even identify which off the top of my head, though it was FUDGE based and scifiish..
00:43:01 <tsahyt> is there some resource that I can read about this? I think it'd be good to know what that case looks like just so I can avoid it
00:43:15 <tsahyt> especially because I've started to make very liberal use of newtype wrapping over the last year or so
00:43:24 <qmm> monochrom: thank you for helping me today
00:43:51 <bollu> is there a tutorial for trifectra?
00:44:24 <qmm> monochrom: this isn't a rushed thing, i'll think on how to use V.replicate and compute the length
00:44:42 <qmm> anything i do in haskell is never rushed :P
00:45:16 <geekosaur> tsahyt, http://stackoverflow.com/questions/22847740/use-of-unsafecoerce at "A more common example"
00:45:29 <monochrom> You'r welcome
00:45:40 <geekosaur> basically, if things get too polymorphic then the compiler can't with certainty eliminate the wrapper
00:47:58 <tsahyt> geekosaur: I suppose the safe coerce variant that you get automatically for newtypes doesn't help either?
00:51:20 <geekosaur> tsahyt, I do not know
00:52:38 <geekosaur> but I suspect that in the cases in question, if the compiler cannot tell with certainty that it can eliminate the wrapper itself, it also cannot tell with certainty that it has a Coercible constraint
00:53:14 <geekosaur> (because they're pretty much the same thing stated two different ways)
00:54:18 <geekosaur> in fact I wouldn't be surprised if it determines it can eliminate the wrapper by looking for a Coercible constraint...
00:54:42 <tsahyt> well that does make some sense
00:54:42 <geekosaur> but if it's polymorphic enough then it can't infer such a constraint
00:55:27 <dhalgren_> Lokathor: wiki mentions locals and "someone who'll explain what's going on" what are your thoughts on NPCs? dumb or complex? do they have emotional states or track knowledge? and dialogue system? are they trees? simple ASK/TELL w/o context? or do you model contexts and topic transitions etc while maintaining freedom to ask/tell about anything? etc?
00:56:53 <Lokathor> dhalgren_, Well, I'd say to PM me, but I'm about to go to bed anyway. I am interested in thinking about this though. How about file an issue on the repo and I'll get back to you?
00:57:17 <dhalgren_> Lokathor: yeah, sure
01:43:03 <mniip> :t (>>>)
01:43:04 <lambdabot> forall k (cat :: k -> k -> *) (a :: k) (b :: k) (c :: k). Category cat => cat a b -> cat b c -> cat a c
01:56:31 <flxw> Hi all. Is there a combinator for two functions a -> b, a -> c which gives a -> (b,c)?
01:56:50 <Taneb> :t (Control.Arrow.&&&)
01:56:52 <lambdabot> Arrow a => a b c -> a b c' -> a b (c, c')
01:57:16 <Taneb> > (reverse &&& length) "wxlf"
01:57:19 <flxw> (so that one doesn't need to write the lambda abstraction by hand)
01:57:19 <lambdabot>  ("flxw",4)
01:58:00 <Taneb> flxw, is this what you were after?
01:58:57 <flxw> cool, yes. thank you!
01:59:40 <Taneb> :)
02:09:10 <lpaste_> monochrom pasted “let-polymorphism” at http://lpaste.net/352302
02:14:19 <lpaste_> monochrom revised “let-polymorphism”: “let-polymorphism” at http://lpaste.net/352302
02:17:26 <monochrom> @tell jle` http://lpaste.net/352302
02:17:27 <lambdabot> Consider it noted.
02:17:41 <monochrom> @tell dmwit http://lpaste.net/352302
02:17:41 <lambdabot> Consider it noted.
02:31:21 <lpaste_> monochrom revised “let-polymorphism”: “let-polymorphism” at http://lpaste.net/352302
02:43:28 <thatguy> what do the ! mean in front of the the Ints? data Matrix a = M {  nrows :: !Int -- ^ Number of rows. , ncols :: !Int -- ^ Number of columns., mvect ::  V.Vector (V.Vector a)   } deriving Eq
02:43:42 <liste> thatguy: it's a strictness annotation
02:44:04 <thatguy> ah so it will get evaluated right when you make a matrix?
02:44:26 <liste> thatguy: https://wiki.haskell.org/Performance/Data_types#Strict_fields
02:44:39 <thatguy> liste, thanks!
02:45:55 <liste> thatguy: also, http://stackoverflow.com/q/8576795/1283954
02:51:39 <thatguy> does ghc automatically do parallelization?
02:52:15 <ezyang> no 
02:52:45 <thatguy> to bad
02:59:27 <biglama> hi guys, yesterday I asked why my parser written with megaparsec was slow and some people told me to try attoparsec instead
02:59:34 <biglama> well, it's even slower !
02:59:42 <lpaste_> biglama pasted “Slow attoparsec” at http://lpaste.net/352305
02:59:53 <biglama> here is the code if someone is interested
03:00:04 <bollu> stack init is failing
03:00:13 <bollu> at "updating package index"
03:00:26 <bollu> is it picking up proxy settings or something? I just got back from college, so I don't have a proxy here
03:00:56 <lpaste_> biglama pasted “Profiling slow parser with attoparsec” at http://lpaste.net/352306
03:00:59 <biglama> and here is my profiling
03:02:00 <bollu> lol, nvm, just shitty internet
03:12:10 <mpickering> If I have a javascript function which returns a string. How should I write the JavascriptFFI foreign import? Something like `f :: JSString -> Int -> IO JSString`? 
03:16:35 <mpickering> If I do this, console.log shows the right output but then I get a nasty "Cannot read property 'codePointAt' of undefined" when actually trying to use the string in haskell land
03:19:45 <tsahyt> biglama: why are you using text for IO but bytestrings for parsing?
03:20:01 <tsahyt> moreover, strict IO and lazy parsing
03:20:32 <tsahyt> biglama: also instead of your mySep function, look at skipSpace
03:21:19 <tsahyt> although I don't think that this is causing the huge buildup you're experiencing
03:21:39 <Zowlyfon> tsahyt, morning
03:22:04 <tsahyt> hello Zowlyfon 
03:23:35 <tsahyt> biglama: disregard the bytestring/text thing, I read that wrong in the import list
03:24:27 <systadmin> hello
03:35:15 <Grisha> hi everyone
03:35:37 <biglama> tsahyt: i'm a bit confused between bytestring and text
03:35:46 <Grisha> ho do I lift Either a b to EitherT a IO b?
03:36:19 <biglama> tsahyt: is it more efficient to read a file with bytestring and process it as Text ? 
03:36:43 <alexbiehl> Grisha: try hoistEither from Control.Monad.Trans.Either
03:36:51 <Grisha> i’ve got a function returning Either a b and would like pipe the result of an IO action into it, obtaining EitherT a IO b as the resulting type
03:37:06 <merijn> biglama: It's simple: Pretend the String part of ByteString doesn't exist
03:37:07 <Grisha> alexbiehl: I’ll take a look, thanks a lot
03:37:19 <merijn> biglama: ByteString == Bytes with unfortunate naming for historical reasons
03:38:06 <Grisha> alexbiehl: on a second thought - do you think the the whole constellation smells a bit?
03:38:20 <Grisha> alexbiehl: in theory, I would rather want to abstract IO away
03:38:58 <biglama> merijn: so the readFile from ByteString reads any file format but returns byte ?
03:39:23 <biglama> merijn: btw, this version with attoparsec does not finish :(
03:39:37 <dhalgren_> would a pipeline like this be reasonably idiomatic, or too pointless? uncurry zip . first (scanl1 (+)) . unzip . map ((uncurry (*)) &&& id) . zip frequency . zipWith (/) candidates $ ...
03:39:39 <tsahyt> biglama: you can think of bytestring as being like [Word8], but obviously with a better internal representation
03:40:06 <merijn> dhalgren_: Written like that? No. But if you split into a bunch of stuff defined in where clause with reasonable names it might
03:40:08 <tsahyt> i.e. it's a string of bytes, but not a string as in "textual data"
03:40:35 <dhalgren_> thx!
03:40:49 <biglama> tsahyt: okay. So is it better to use readFile from bytestring, than convert to Text ? Or use readFile from Text ?
03:40:53 <merijn> biglama: It's odd that I don't see any major hotspots in the profile. Are you compiling with -O or -O2? Are the libraries compiled with that?
03:41:20 <biglama> merijn: I used -O2, but I'm not sure the libraries are optimized 
03:41:32 <biglama> merijn: I used stack build --ghc-options -O2
03:42:07 <alexbiehl> Grisha depends, can you show code? 
03:42:10 <merijn> I don't know stack, so can't say if that works :)
03:42:18 <Grisha> alexbiehl: wat a sec
03:43:06 <systadmin> Stack is a RAM killer
03:44:11 <biglama> merijn: I think stack compiled the libraries for profiling at some time but were not compiled again for optimization
03:44:21 <Grisha> alexbiehl: http://lpaste.net/352307
03:45:11 <tsahyt> biglama: stack keeps profiling builds separate
03:45:37 <tsahyt> for libraries I mean
03:46:25 <tsahyt> biglama: have you had a look at RAM usage?
03:47:23 <biglama> tsahyt: is hp2ps the tool for that ?
03:47:37 <tsahyt> for a start, I usually just run it with +RTS -s
03:47:41 <alexbiehl> Grisha, people argue that having ExceptT Err IO a is an anti pattern because
03:47:47 <alexbiehl> checkout: https://www.fpcomplete.com/blog/2016/11/exceptions-best-practices-haskell
03:48:02 <tsahyt> biglama: big red flags are when it uses an unreasonably large amount of RAM or the productivity value is very low
03:48:17 <Grisha> alexbiehl: that exactly answers my question
03:48:59 <Grisha> alexbiehl: basically I want it just to be able to play around in repl, having a monad around my Statements and poking them by <$>
03:50:18 <tsahyt> biglama: do you have some test data somewhere that you can share? I'd like to try rewriting some parts of it in an applicative style and see whether that helps
03:51:27 <biglama> tsahyt: I watched htop during the execution but the ram usage was very low
03:51:33 <tsahyt> hmm okay
03:52:15 <alexbiehl> You could hide IO in your monad and make sure to convert any exception occuring to your explicit error type
03:52:16 <biglama> tsahyt: sure. I have a small test case (10 000, 60s on my computer with profiling)
03:52:25 <biglama> 10 000 lines*
03:52:56 <biglama> thanks for your time btw. I'm a little bit at loss here
03:53:08 <tsahyt> yeah, so am I with my project, so I can use a little distraction
03:53:11 <biglama> I also posted on the haskell-beginners mailing list out of desperation
03:53:17 <biglama> despair*
03:55:39 <biglama> tsahyt: https://drive.google.com/open?id=0B6BoMOZHCeZESC1Pb05KNXQ0V28
03:55:45 <tsahyt> biglama: I see that you often parse something, give it a name and then don't use it
03:55:46 <biglama> if google drive is okay for you
03:56:00 <tsahyt> google drive is ok
03:56:19 <tsahyt> e.g. in the time parser, you parse t' but never use it afterwards. is that intentional?
03:56:19 <biglama> tsahyt: can you give me an example ?
03:56:45 <tsahyt> same in iter, you parse t and then don't use it later on
03:56:46 <biglama> t' should be used, but I did add it at the moment 
03:57:32 <biglama> tsahyt: yes, should be used later, if I got the code working
03:57:48 <tsahyt> biglama: I suppose instead of the 0?
03:58:49 <merijn> biglama: tbh htop is pretty useless for determining RAM usage
03:58:52 <_sras_> When I make lenses for a record, how can I make certain fields read only?
03:59:59 <biglama> tsahyt: oh right, I was debugging earlier on. sorry
04:00:19 <tsahyt> I was just asking because it's actually simpler to use it in applicative style than leave it out
04:00:44 <biglama> merijn: what do you recommend instead ? 
04:01:02 <biglama> tsahyt: I'm not that good with applicative either 
04:01:11 <tsahyt> biglama: how long does it take for you without profiling?
04:01:20 <tsahyt> I forgot to benchmark the before
04:01:29 <merijn> biglama: The profiling output of GHC that tsahyt mentioned
04:02:36 <merijn> biglama: The problem is that htop reports a lot of different memory statistics, and you need to know exactly what they mean to divine anything useful from them. For example, if you use GHC8 on x64 htop will basically just report every program, including hello world using about 1TB of RAM
04:02:45 <tsahyt> biglama: in the time parser, what's supposed to happen to t'?
04:03:41 <biglama> tsahyt: 67s (with 58s in cpu time) for the file 10 000 lines
04:03:44 <tsahyt> biglama: is 0.0,1,7.0,25.0,25.0,0.0,0.0,0.0,0,0,0,2,0 the correct output for this test case?
04:03:55 <biglama> merijn: is it the .prof file ? I posted it earlier : http://lpaste.net/352306
04:03:58 <tsahyt> what I did shouldn't have broken anything I think, just making sure
04:05:13 <biglama> tsahyt: you should have around 7000 lines like these
04:05:18 <tsahyt> that is interesting
04:05:22 <biglama> did you replace mySep by skipSpace ?
04:05:25 <tsahyt> yes
04:05:54 <biglama> tsahyt: the parser is a bit clunky for newlines and spaces
04:06:18 <biglama> tsahyt: which is why is used mySep, to avoid parsing newlines (it serves as a delimiter)
04:06:56 <tsahyt> alright that makes a difference
04:07:17 <biglama> tsahyt: the idea of the parser is basically to just reformat all lines from the input file
04:07:59 <tsahyt> takes 30 seconds now on this file
04:08:05 <tsahyt> I'll test the original
04:08:55 <tsahyt> but 30s still seems way too slow imo
04:09:05 <biglama> as a comparison, I have some C++ code which just reads the file line by line and print them in the new format
04:09:11 <biglama> takes 1s for 200 000 lines
04:09:13 <biglama> so yes
04:09:43 <tsahyt> is it really a line by line transformation?
04:09:43 <merijn> Well, one problem is that you're reading the entire file into memory, parsing than writing out, whereas the C++ one is probably streaming?
04:09:56 <merijn> In which case something like conduit/pipes would be more appropriate
04:10:05 <merijn> But also less beginner friendly :)
04:10:51 <tsahyt> agreed, a streaming abstraction would make a lot of sense in that case
04:11:12 <biglama> good point
04:11:48 <biglama> the format is a list of objects, where each object contains a set points coordinates
04:12:07 <biglama> mega/attoparsec gives me a lot of flexibility in the output format as I deal with data type
04:12:38 <_sras_> When I make lenses for a record, how can I make certain fields read only?
04:13:04 <tsahyt> biglama: the encoding for your input is always ASCII?
04:13:05 <biglama> the c++ version just call readline() till the end of file
04:13:15 <biglama> tsahyt: should be, yes
04:13:56 <tsahyt> so every one of those blocks ends up as one output line then I suppose?
04:14:43 <biglama> tsahyt: each point (the Particle data type in the code) is written as one line, yes
04:14:49 <biglama> (at the moment)
04:15:11 <biglama> merijn: if I have to use streaming, I'll keep the c++ version
04:15:19 <biglama> merijn: I wanted some abstraction for once
04:15:36 <merijn> biglama: To be fair, there's some pretty nice streaming abstractions in Haskell :)
04:15:41 <tsahyt> biglama: have you seen the pipes library? I would call that a nice abstraction
04:16:51 <tsahyt> what you want (when opting for pipes) is pipes, pipes-{bytestring,text}, and pipes-attoparsec. the parsing code can look mostly the same as before, and you just have to plumb it together using pipes.
04:17:02 <tsahyt> which comes down to not much more code than the IO code you already have, but you get streaming for it
04:18:01 <biglama> tsahyt: so I get to keep my datatype ?
04:18:12 <tsahyt> Particle and Iteration? sure
04:18:47 <insitu> hello, I am trying to write some code for (de)serializing data type with the concept of versions
04:18:49 <biglama> tsahyt: that would be nice
04:19:15 <tsahyt> you have a Producer which reads from the file and shovels lines downstream, and a Consumer which eats the output from upstream and writes it to the file
04:19:38 <insitu> the idea is that you can have an older (byte-level) representation of some data type that you want to deserialise, knowing it has some version X
04:19:47 <biglama> tsahyt: okay, I'll look into it when I have some free time
04:19:53 <tsahyt> inbetween you have a parser, pulling lines as needed from upstream, pushing out Particles downstream, and a serializer which takes the parser output and converts it into text
04:20:02 <biglama> just wanted to introduce Haskell at work by showing how easy it was to use 
04:20:21 <biglama> for that, it's a bit of a failure :)
04:20:22 <tsahyt> biglama: the pipes version would be a lot more elegant imo, and maybe even a better way to show off Haskell
04:20:40 <biglama> tsahyt: okay, thanks for the explanation
04:20:53 <biglama> but! it does not explain why attoparsec is so slow 
04:20:54 <insitu> I made it work by going down into the plumbing of the deserialisation code 
04:20:54 <biglama> :)
04:20:56 <tsahyt> of course you can also use conduit to do it or any other streaming IO library, but pipes is the only one I have worked with so far
04:21:21 <merijn> insitu: There's a library for that, I think
04:21:25 <insitu> greate
04:21:50 <merijn> @hackage safecopy
04:21:50 <lambdabot> http://hackage.haskell.org/package/safecopy
04:22:26 <_sras_> is it possible to generate only getters using Lens package?
04:22:34 <insitu> thanks a lot, will look at it
04:23:22 <insitu> oh, I don't want to keep the old type around
04:23:45 <biglama> tsahyt, merijn : thanks for the help anyway
04:24:33 <insitu> and I would like things to be composable, so if I have a getter for version X -> Y and a getter for version Y -> Z, I can have a getter for X -> Z
04:25:50 <insitu> the version is a global property (within the limits of some domain) so I don't need to have it around for each element
04:25:59 <tsahyt> biglama: the most likely culprit that I can make out is the way you treat spaces, but I'm not sure
04:26:20 <insitu> but safecopy is definitely interesting to explore
04:28:36 <biglama> tsahyt: you think it could make the code run that slow ?
04:29:23 <_sras_> When I make lenses for a record, how can I make certain fields read only?
04:30:13 <lyxia> make getters instead
04:37:52 <_sras_> lyxia: how do I do that?
04:39:54 <tsahyt> biglama: dunno, the one big cost center is somewhere buried in attoparsec code, but it gets called by mySep at some point, unless I've counted the indents wrong
04:43:26 <tsahyt> biglama: good news
04:43:41 <tsahyt> I've converted it to use lazy text and now I get 7000 lines of output in about 0.2 seconds
04:43:51 <tsahyt> the streaming really does make the difference apparently
04:43:54 <ondraa> hello, what is the standard way to convert Int -> Text?
04:44:04 <ondraa> I can't find anything on hoogle 
04:44:32 <ondraa> by convert I mean standard 1234 -> "1234"
04:45:05 <tsahyt> biglama: unfortunately I'm not entirely sure why the strict version is that slow in comparison, but at least you have a working solution now
04:46:04 <tsahyt> biglama: at least I think it's working, http://sprunge.us/QXQT
04:46:35 <tsahyt> everything else is the same as in your code, just changing some imports and the necessary changes to make it work again
04:48:08 <hpc> ondraa: pack . show?
04:49:02 <ondraa> hpc: I was hoping I could avoid the conversion to string in the middle
04:49:48 <merijn> ondraa: https://hackage.haskell.org/package/text-1.2.2.1/docs/Data-Text-Lazy-Builder-Int.html ?
04:49:59 <phadej> or text-show
04:50:08 <phadej> anyhow, the performance loss is really neglible
04:50:32 <merijn> phadej: Depends on how many numbers you show ;)
04:50:50 <phadej> merijn: well, then you definitely should use Builder, and not Int -> Text
04:51:32 <phadej> and maybe even ByteString one
04:52:21 <hpc> ondraa: the string never exists in memory all at the same time, it's more of the data definition of a loop in this scenario
04:54:06 <lyxia> _sras_: once you have a Lens you can specialize it to a Getter. Hide the original Lens, export the Getter.
04:54:31 <puregreen> _sras_: afaik there's a flag to generate getters instead of lenses
04:54:56 <puregreen> http://hackage.haskell.org/package/lens-4.15.1/docs/Control-Lens-TH.html#v:generateUpdateableOptics
04:55:17 <lyxia> oh indeed
04:55:26 <unclechu> hey guys, how I can handle closing stdout?
04:56:46 <ondraa> hpc, phadej, merijn: thank you for your help. I am gonna go with pack . show for now. By chance is there some article with comparison of these approaches?
04:56:58 <hpc> unclechu: hClose stdout
04:57:16 <puregreen> I think pack.show is actually fast but my memory might be hazy
04:57:25 <DonaldJTrump> how can i into haskell
04:57:28 <DonaldJTrump> pls help me
04:57:38 <unclechu> hpc: no, i mean, how i can catch when parent of my app closing stdout?
04:57:43 <Profpatsch> Design question:
04:57:45 <Profpatsch> setInnerHTML :: Element -> Text -> Dom ()
04:57:51 <Profpatsch> setInnerHTML :: Text -> Element -> Dom ()
04:57:58 <hpc> hIsEOF or something like that
04:58:04 <hpc> a closed handle is a closed handle
04:58:34 <puregreen> Profpatsch: I'd go with the latter
04:59:05 <hpc> https://hackage.haskell.org/package/base-4.9.1.0/docs/System-IO.html#v:hIsEOF and possibly https://hackage.haskell.org/package/base-4.9.1.0/docs/System-IO.html#v:hIsClosed
04:59:25 <unclechu> hpc: what I'm suppoed to do with it? fork a thread and check by timer interval is it isn't closed?
04:59:47 <Profpatsch> puregreen: The varying elements should be on the right, right?
05:00:00 <unclechu> it would be a horrible way I think
05:00:29 <dramforever> :t modifyIORef
05:00:30 <hpc> unclechu: or check when you read from it
05:00:32 <lambdabot> error:
05:00:32 <lambdabot>     • Variable not in scope: modifyIORef
05:00:32 <lambdabot>     • Perhaps you meant one of these:
05:00:32 <dramforever> :t modifyMVar
05:00:35 <lambdabot> error: Variable not in scope: modifyMVar
05:00:36 <dramforever> hey
05:00:45 <dramforever> :t Data.IORef.modifyIORef
05:00:49 <lambdabot> GHC.IORef.IORef a -> (a -> a) -> IO ()
05:01:31 <puregreen> Profpatsch: more like “make it easy for people to use”
05:01:47 <pavonia> Is there a single, possibly more generic function for concat . sequence?
05:01:49 <puregreen> e.g. modifyIORef often takes a lambda so it makes sense to make that lambda the last parameter
05:01:51 <Profpatsch> puregreen: And what does that mean for argument order?
05:02:23 <phadej> :t concat . sequence
05:02:25 <lambdabot> (Foldable t, Monad t) => [t a] -> [a]
05:02:28 <puregreen> on the other hand, if you anticipate something like “mapM_ (setInnerHTML "") [e1, e2, e3]” then it would make sense to make text the first argument
05:03:06 <Profpatsch> Hm.
05:03:07 <puregreen> on the third hand, if you anticipate “setInnerHTML e $ "Hello my dear friend! Let me offer you " ++ ...” then the flipped order makes sense
05:03:07 <phadej> :t \xss -> xss ^.. folded . folded
05:03:10 <lambdabot> (Foldable f1, Foldable f) => f (f1 a) -> [a]
05:03:19 <phadej> :t foldMap fold
05:03:21 <lambdabot> (Monoid m, Foldable t1, Foldable t) => t (t1 m) -> m
05:03:31 <phadej> :t foldMap foldMap pure
05:03:33 <lambdabot> (Monoid m, Foldable ((->) m), Foldable t) => t a -> m
05:03:37 <phadej> :t foldMap (foldMap pure)
05:03:39 <lambdabot> (Monoid (f a), Foldable t1, Foldable t, Applicative f) => t (t1 a) -> f a
05:03:44 <Profpatsch> puregreen: For reference, the GHCJS API puts the objects first.
05:03:46 <phadej> näh
05:04:00 <unclechu> hpc: hmmm. I'm actually don't think that `stdout` supposed to be readed at all :) and most important thing is that I really need stop my application when parent died and really don't want wait to some moment to realize like 'whoah, my parent is done long time ago and i'm just wasting cpu time for nothing, well at least i will stop at this moment, better late than never'
05:04:35 <Profpatsch> But that’s just because it’s mirroring the DOM API; maybe it’s better the other way around for an abstraction.
05:04:46 <phadej> pavonia: not sure what you mean, do you want:
05:04:51 <phadej> :t > fmap concat . sequence
05:04:53 <lambdabot> error: parse error on input ‘>’
05:04:55 <phadej> :t fmap concat . sequence
05:04:57 <lambdabot> (Traversable t, Monad f) => t (f [a]) -> f [a]
05:05:06 <puregreen> if you don't have any clear usecases in mind that you could optimise for, I'd suggest mirroring the DOM API as well, I guess :)
05:05:07 <Profpatsch> Normally my hunch would be to put the arguments that are more “static” for the user more to the left.
05:05:49 <Profpatsch> On the other hand it would be el `setInnerHTML` "foo"
05:05:53 <pavonia> phadej: Without the fmap. Run some actions, collect the results and put them together
05:06:42 <phadej> pavonia: :t concat . sequence
05:06:46 <phadej> :t concat . sequence
05:06:48 <lambdabot> (Foldable t, Monad t) => [t a] -> [a]
05:06:53 <puregreen> Profpatsch: I wouldn't expect the backticked form to be used often, though maybe I'm biased
05:07:28 <phadej> foldable and monad t
05:07:29 <puregreen> it's just that I rarely see backticked forms even when the library authors intended them to be used (with exceptions of `finally`, `div` and `elem`)
05:07:32 <phadej> thjat's suspicious
05:08:01 <hpc> unclechu: actually, another thought, though it's a pretty silly one
05:08:04 <phadej> :t concatMap toList
05:08:06 <lambdabot> error:
05:08:06 <lambdabot>     Ambiguous occurrence ‘toList’
05:08:06 <lambdabot>     It could refer to either ‘F.toList’,
05:08:10 <phadej> :t concatMap F.toList
05:08:11 <pavonia> phadej: t is Parser in my case, so it doen't need to be a Monad
05:08:12 <lambdabot> (Foldable t1, Foldable t) => t (t1 b) -> [b]
05:08:15 <hpc> unclechu: have a thread that's always pulling data from stdout and stuffing it in a Chan
05:08:25 <Profpatsch> phadej: No, sequence comes from Monad
05:08:35 <hpc> unclechu: the rest of your code consumes from the Chan, and the thread pulling data is always either receiving text or waiting for it to arrive
05:08:46 <hpc> so stdout is always being watched and you can get that eof instantly
05:09:25 <phadej> pavonia: is your Parser `Foldable`, otherwise `concat . sequence` won't type check
05:09:28 <phadej> I doubt
05:12:21 <pavonia> phadej: Hhm, no. And actually you were right, it's concat <$> sequence :S
05:14:01 <phadej> :) but I'm pretty sure there isn't shorter name for that
05:15:03 <pavonia> :t \cs -> concat <$> sequence cs
05:15:06 <lambdabot> (Traversable t, Monad f) => t (f [a]) -> f [a]
05:15:52 <phadej> :t fmap mconcat <$> sequenceA cs
05:15:55 <lambdabot> error:
05:15:55 <lambdabot>     • Variable not in scope: cs :: f1 (f [b])
05:15:55 <lambdabot>     • Perhaps you meant one of these:
05:15:58 <phadej> :t fmap mconcat . sequenceA
05:16:00 <lambdabot> (Monoid b, Applicative f) => [f b] -> f b
05:19:12 <phadej> :t foldM
05:19:14 <lambdabot> (Foldable t, Monad m) => (b -> a -> m b) -> b -> t a -> m b
05:21:52 <tsahyt> is there an example of a Foldable that is not a Functor?
05:21:57 <phadej> Set
05:22:08 <tsahyt> ah right, thanks!
05:23:29 <phadej> pavonia:
05:23:34 <phadej> :t foldM (\x y -> (x <>) <$> y ) mempty
05:23:36 <lambdabot> (Monoid b, Foldable t, Monad m) => t (m b) -> m b
05:23:43 <phadej> might be better, though uglier
05:24:31 <pavonia> Yeah, that's less readable, I'll stick with the other version. Thanks though
05:27:13 <merijn> Right, any (conduit) people care to help me clean up some code?
05:28:10 <lpaste_> merijn pasted “Conduit auto-sized request” at http://lpaste.net/352314
05:28:22 <phadej> pavonia: it's different also, when you have some state in the parser for example
05:29:07 <phadej> (relates to liftA2 (&&) isn't short-circuiting, but sometimes you need it to be)
05:32:59 <biglama>  tsahyt : the running time is great !
05:33:13 <tsahyt> biglama: I hope the result is also correct
05:33:14 <dramforever> > liftA2 (&&) (Just False) (Just undefined)
05:33:17 <lambdabot>  Just False
05:33:23 <dramforever> Well for some definition of short-circuiting :P
05:33:32 <dramforever> > liftA2 (&&) (Just False) Nothing -- of course
05:33:35 <lambdabot>  Nothing
05:33:43 <bollu> does GHC generate LLVM by default?
05:33:53 <merijn> bollu: No, default is native code
05:34:07 <bollu> merijn: the LLVM is generated from STG?
05:34:12 <tsahyt> on the topic of LLVM, I was wondering, are there any benefits to using the LLVM backend?
05:34:17 <dhalgren_> ghc panic?  "thread blocked indefinitely in an MVar operation" I'm pretty sure its just a 15yro laptop running out of mem; but is it worth a bug report?
05:34:17 <bollu> merijn: if so, I'm super interested in the generated LLVM code
05:34:39 <bollu> dhalgren_: 15 years old laptop? laptops existed back then? :O
05:34:49 <tsahyt> bollu: they did, I remember thinkpads from the 90s even
05:34:55 <tsahyt> IBM thinkpads those were
05:35:00 <merijn> bollu: I believe both go "Haskell -> Core -> STG -> Cmm" and then the default goes "Cmm -> native code" whereas LLVM goes "Cmm -> LLVM assembly -> LLVM stuff -> native code"
05:35:01 <dhalgren_> bollu: early 00s, sure
05:35:10 <bollu> ah, I see
05:35:15 <mniip> moo
05:35:29 <bollu> dhalgren_: I was too young to remember the early 00s. TIL you had laptops
05:35:38 <bollu> wel, somewhat young
05:35:44 <merijn> bollu: LLVM (usually) performance a decent bit better on numeric code, but the GHC native code generally does better on "non-numeric" code :)
05:36:00 <bollu> merijn: :) "non numberic" being "everything else"? :P
05:36:07 <bollu> merijn: do you know of a detailed analysis?
05:36:14 <merijn> bollu: Not really
05:36:24 <bollu> merijn: like, I wanted to help with generating better LLVM tbh
05:36:27 <bollu> or at least
05:36:34 <bollu> learn how LLVM is generated for GHC
05:36:41 <merijn> bollu: Pretty sure you can have it dump out the generated LLVM
05:37:00 <merijn> bollu: Those questions are probably going to get better answers in #ghc and on the ghc-dev mailing list
05:37:08 <cocreature> bollu: you can help angerman with his llvm bitcode generation plugins for ghc
05:37:24 <merijn> bollu: Pretty sure LLVM help is plenty welcome if you have llvm experience :)
05:37:28 <dhalgren_> bollu: actually its second hand; old equipment I got for free just a couple of years ago; took it as a challenge to use regardless of its age :D  but my partner had a toshiba from early 00s and used it till the screen cracked just a couple of years back
05:38:02 <bollu> merijn: well, I'm "new" (as in, I've messed about but I don't know much). However, I'll be spending around the next year learning a bunch about LLVM
05:38:12 <bollu> merijn: so I'd like to help with GHC, hopefully
05:38:23 <bollu> (dream since I was a teenager and all that :P)
05:39:44 <tsahyt> biglama: how does it compare to the C++ implementation on the 200000 line file now?
05:39:45 <bollu> cocreature: do I ping him?
05:39:59 <dhalgren_> anyhow, I'm gonna ignore the ghc panic; its the machine surely...
05:40:54 <cocreature> bollu: that’s probably best (or search for his email address, I’m not sure how actively he monitors irc). the repos are on github https://github.com/angerman but it probably makes sense to ask him what needs to be done
05:41:06 <cocreature> he was looking for help a while back so I’m sure he’ll welcome any contributor
05:41:17 <bollu> cocreature: I'm somewhat of a noob, but I'm ready to learn. I hope he is okay with that?
05:41:30 <cocreature> bollu: I can’t answer that question for him :)
05:41:38 <cocreature> bollu: but I would be very surprised if not
05:41:43 <bollu> cocreature: heh, thanks
05:41:53 <biglama> tsahyt: yes, the output is ok !
05:42:01 <biglama> tsahyt: I owe you a beer
05:42:18 <tsahyt> heh it's alright, all I did was change some imports after all
05:42:32 <tsahyt> and while I was at it I got a new idea on how to tackle this problem I'm working on, so it's win-win
05:43:07 <cocreature> bollu: another llvm related task is bundling llvm with ghc so that it stops being a second class backend. thoughtpolice has been planning that for quite some time but I don’t know what the current state is
05:43:17 <biglama> tsahyt: so you just become lazy and everything is all right ? damn
05:43:51 <tsahyt> yeah, I'm not quite sure why the difference is that massive. attoparsec is written with incremental parsing in mind though, so that might have something to do with it
05:44:16 <biglama> this is definitively an improvement over megaparsec then
05:45:16 <tsahyt> dunno, maybe megaparsec would have been a lot faster with lazy text underneath as well
05:45:32 <bollu> cocreature: do you have anything related to LLVM in mind BTW?
05:45:43 <tsahyt> but attoparsec is well suited to the task at hand, and is generally faster than megaparsec, so I'd stick with that
05:45:58 <biglama> tsahyt: my only complaint is the error messages are not helpful
05:46:08 <biglama> they remind me of boost's spirit 
05:46:24 <tsahyt> biglama: that's the tradeoff that attoparsec makes
05:46:43 <cocreature> bollu: our support for exceptions in llvm-hs is pretty rudamentary, adding support for the remaining instructions would be great. apart from that orc jit support also needs to be expanded & improved. and finally there is the pass manager stuff we talked about earlier
05:46:47 <tsahyt> it's designed to do things like protocol parsing in a network stack etc, where performance is paramount and the parser is not directly user-facing
05:47:25 <bollu> cocreature: is there a mailing list or something where this is discussed? also, I have both GHC 8 and a new-ish LLVM version on my laptop right now. Do I need to compile GHC to pick this up?
05:47:33 <tsahyt> biglama: but since your output is also generated by some software (from what I can tell), the lack of error messages should be a temporary nuisance until you've got the parser right
05:47:38 <cocreature> bollu: which part? :)
05:47:40 <bollu> cocreature: I'm curious to check if GHC can use the polyhedral optimisations in poly
05:47:44 <merijn> bollu: Yes, the aforementioned ghc-dev mailing list :)
05:47:44 <tsahyt> biglama: remember that you can always test your parser components in ghci using parseTest
05:47:45 <bollu> cocreature: the LLVM :)
05:47:49 <bollu> merijn: oh xD
05:47:53 <cocreature> bollu: in ghc or llvm-hs?
05:48:01 <tsahyt> biglama: make sure that the individual components are well behaved, and the use composition to make sure that the larger ones are
05:48:10 <bollu> cocreature: GHC
05:48:13 <biglama> tsahyt: yeah, I was just thinking from the point of view on an user
05:48:17 <biglama> thanks
05:48:41 <tsahyt> you're welcome. I'm always happy when I can save someone from using C++ :)
05:49:01 <merijn> tsahyt: When are you saving me? :p
05:49:02 <cocreature> bollu: there are probably track issues somewhere and as merijn mentioned there is the mailing list. there is also a #ghc channel
05:49:17 <cocreature> eh *trac
05:49:46 <tsahyt> merijn: first I'll have to understand haskell well enough to get rid of the last usecase for C++
05:50:03 <tsahyt> performance in particular can be a bit tricky at times
05:55:15 <merijn> Any suggestions how I could get rid of evalStateC on line 20 http://lpaste.net/352314 I'd like to see if I can entirely remove the "hoist (lift.lift)" on line 22
05:57:54 <BernhardPosselt> hi, can you define a monoid for maybe?
05:58:15 <opqdonut> yeah, you just need to decide whether to keep the left or the right value
05:58:40 <BernhardPosselt> and the thing inside needs to also have a monoid right?
05:58:48 <lieven> you have Monoid a => Monoid (Maybe a)
05:58:56 <BernhardPosselt> right
05:59:10 <cocreature> BernhardPosselt: not necessarily you can make a monoid that just always uses the left value
05:59:32 <opqdonut> so the default Monoid instance for Maybe is Monoid a => Monoid (Maybe a)
05:59:42 <cocreature> BernhardPosselt: https://hackage.haskell.org/package/base-4.9.1.0/docs/Data-Monoid.html#t:First
05:59:50 <cocreature> or https://hackage.haskell.org/package/base-4.9.1.0/docs/Data-Monoid.html#t:Last
05:59:54 <opqdonut> then there are Monoid (First a) and Monoid (Last a)
06:00:03 <BernhardPosselt> i see
06:00:19 <BernhardPosselt> so basically you can do what you want as long as the laws match
06:00:27 <opqdonut> yes
06:01:07 <opqdonut> another valid instance would be "instance Monoid (Maybe a) where mempty = Nothing; mappend _ _ = Nothing" :)
06:01:13 <opqdonut> it's a bit boring though
06:01:23 <lieven> the forgetful Monoid
06:01:34 <Profpatsch> The actual Monoid instance for Maybe is interesting, though.
06:02:05 <Profpatsch> It should actually read Semigroup a => Monoid (Maybe a)
06:02:19 <Profpatsch> Somebody should make that breaking change sometime?
06:02:54 <merijn> AFAIK Semigroup is coming into base
06:03:05 <Profpatsch> I thought it was already. Hrm.
06:03:08 <bollu> is it possible to skip the clone of all-cabal-hashes?
06:03:12 <BernhardPosselt> isnt it the same thing?
06:03:12 <bollu> I'm on a shitty network at home
06:03:15 <bollu> it's _going_to break
06:03:15 <merijn> Whether the Monoid for Maybe will change is doubtful
06:03:16 <cocreature> merijn: it already is
06:03:19 <merijn> oh?
06:03:21 <BernhardPosselt> semigroup and monoid?
06:03:23 <cocreature> merijn: https://hackage.haskell.org/package/base-4.9.1.0/docs/Data-Semigroup.html
06:03:35 <Profpatsch> BernhardPosselt: Semigroup is monoid without mempty
06:03:45 <cocreature> semigroup being in base not a different monoid instance for maybe
06:03:53 <Profpatsch> And a Magma would be a semigroup with no associativity.
06:04:08 <merijn> cocreature: Not for me, since I'm not on GHC 8 yet :p
06:04:23 <Profpatsch> merijn: y not?
06:04:30 <tsahyt> > (Just 3 <|> Nothing, Nothing <|> Just 3)
06:04:32 <lambdabot>  (Just 3,Just 3)
06:04:35 <tsahyt> good
06:04:40 <merijn> Profpatsch: I haven't had a compelling reason to upgrade?
06:04:46 <tsahyt> finally found a use case for <|> with maybes :)
06:04:49 <Profpatsch> Now you have. :P
06:04:56 <cocreature> merijn: don’t you know that new is always better? :)
06:05:05 <merijn> cocreature: New is generally worse ;)
06:05:09 <merijn> GHC is the exception :p
06:05:15 <bollu> Profpatsch: who even uses magma? :P
06:05:17 <Profpatsch> tsahyt: Yeah, that’s an extremely cool instance.
06:05:18 <merijn> But I like not breaking my code :p
06:05:22 <dramforever> New is better than old
06:05:34 <dramforever> but old is usually better than bleeding-edge new
06:05:40 <BernhardPosselt> ah
06:05:47 <bollu> Profpatsch: I don't think there are any theorems you can write on a magma, are there?
06:05:51 <BernhardPosselt> semigroup is a monoid without neutral element
06:06:22 <Profpatsch> bollu: Well, you know you have a binary operation (a,a) -> a and that’s pretty much it.
06:06:25 <bollu> BernhardPosselt: semigroup is atleast useful since you have the notion of a "semigroup action"
06:06:59 <Profpatsch> There’s a new article by Bartosz: https://bartoszmilewski.com/2017/02/09/monoids-on-steroids/
06:07:52 <Profpatsch> I’ve read the first 4 paragraphs and already learned stuff.
06:08:06 <BernhardPosselt> another question: regarding the reader monad: is it just for passing common stuff around?
06:08:06 <Profpatsch> Which is impressive from a density standpoint.
06:09:17 <merijn> Is there any particular difference between a recursive binding in a let vs one using fix?
06:09:24 <merijn> In terms of performance, that is?
06:11:19 <Profpatsch> tsahyt: I’m using the Alternative instance of MaybeT to do type matching in GHCJS:
06:11:52 <bollu> merijn: intuitively, yes, right? because a let is a binding while calling fix is a function call?
06:12:05 <bollu> merijn: I could be dead wrong, I'd  like to know myself
06:12:27 <merijn> I ask because conduit seems to prefer fix everywhere
06:12:32 <Profpatsch> tsahyt: (tryT HTMLInputElement >>= \inpEl -> …) <|> (tryT RadioNodeList >>= \rnl -> …) <|> …
06:12:53 <Profpatsch> where tryT t = MaybeT $ node `asTry` t
06:13:30 <tsahyt> I've just used it to try two lookups in a map and return the one that succeeds, so I don't have to store both the positive and negative versions of a literal
06:13:31 <Profpatsch> Took a while to figure out, but works like a charm.
06:15:14 <angerman> cocreature bollu, ha since having irccloud I actually get notifications. :D
06:15:34 <bollu> angerman: hello :) I also sent you an email
06:15:55 <bollu> angerman: so yes, how could I help with Haskell's LLVM story?
06:16:03 <angerman> bollu: I saw it. Yep :)
06:16:44 <angerman> bollu: what I try to do is actually replace the aging existing llvm backend, which heavily relies on the textual llvm ir with a bitcode llvm ir, which would be more resilent to llvm version updates.
06:17:49 <angerman> bollu: to achieve that without having to rebuild ghc each and every time, I extended the plugin interface a bit, so building the whole thing is not trivial. However with nix, you should be able to build and try it out rather easily. The relevant nix expression is provided in https://github.com/angerman/data-bitcode-plugin-env
06:21:25 <angerman> bollu: now, what needs to be done is: a) try to compile some haskell source, see where the llvm code gen plugin breaks, and fix the corresponding code path in the code gen (this basically involved reading the textual code gen in ghc right now, and porting it over to the new code gen in the llvm-plugin). (or just try to port everyting that is missing). b) add
06:21:25 <angerman> support for metadata to the data-bitcode and data-bitcode-llvm, such that data-bitcode-llvm can work with tbaa and function argument metadata. c) Add function level vst (value-symbol-lookup table), those would allow to give the function argument more readable names, instead of being simply enumerated.
06:22:07 <angerman> bollu: And in the end, integrating data-bitcode, data-bitcode-llvm, and data-bitcode-plugin into ghc. Either via an extended plugin system, or hardwiring it to replace the existing code gen.
06:23:30 <bollu> angerman: I usee
06:23:33 <bollu> I see*
06:25:55 <bollu> cocreature: LLVM-hs versus llvm-general?
06:26:14 <bollu> angerman: cool, I shall start playing around with this
06:26:42 <angerman> bollu: try to get the data-bitcode-plugin-env running :)
06:26:57 <angerman> bollu: and file issues, if something doesn't work as expected :D
06:26:58 <bollu> xD sure
06:27:06 <bollu> angerman: I need to install Nix first
06:28:41 <cocreature> bollu: llvm-hs is a fork of llvm-general created by a bunch of people that are a bit annoyed with llvm-general.
06:29:31 <lpaste_> merijn pasted “One lift left to eliminate...” at http://lpaste.net/7015480017433919488
06:30:05 <merijn> I feel this could be cleaner without the StateT, but I can't really make it work :\
06:30:36 <angerman> cocreature bollu, not sure if this was mentioned already, however the data-bitcode stuff is pure haskell, contrary to what I believe llvm-general and llvm-hs do, by linking against llvm. Please correct me if I'm wrong, cocreature 
06:30:49 <cocreature> yep that’s correct
06:30:57 <bollu> cocreature: annoyed because of slow development?
06:31:02 <bollu> cocreature: also, llvm-hs is not up on hackage?
06:31:30 <cocreature> bollu: we’ll do a release once llvm 4.0 is released which should happen in the next few weeks (rc2 got released today)
06:31:59 <bollu> cocreature: I see. so for now, if I want to pick it up..?
06:32:09 <cocreature> bollu: https://github.com/llvm-hs/llvm-hs
06:37:26 <max3> does anyone here use vscode with the ghc-mod extension? i'm getting `Couldn't start ghc-mod process Error: Command failed: [object Object] version`
06:37:51 <max3> even though i've cabal installed and seemingly set the correct ghcmod executable path
06:40:47 <kgadek> max3: didn't use vscode, but my first guess would be to check the $PATH used by vscode
06:41:07 <kgadek> i.e. are you sure that vscode can /see/ the ghc-mod?
06:41:53 <max3> i think i'm changing settings incorrectly
06:42:13 <kgadek> run `ps -wwE -p PID_OF_VSCODE`
06:42:29 <kgadek> this will show env vars for given process
06:45:34 <bollu> angerman: nix-shell errors at error: opening file ‘/Users/bollu/work/ghc-all/data-bitcode-plugin-env/data-bitcode-plugin/default.nix’: No such file or directory
06:48:56 <max3> what does this syntax mean? `instance PGType "segment"` i'm familiar with implementing a type class but i don't understand the string here
06:49:23 <c_wraith> max3: the string is a type. :)
06:49:42 <c_wraith> max3: using the DataKinds extension, String literals are types of kind Symbol
06:50:38 <max3> okay but then what is this `instance Range.PGRangeType "segment" "interval"`
06:50:49 <max3> two types?
06:51:17 <c_wraith> Yes.  Are you familiar with multiparameter type classes?
06:51:37 <max3> no
06:52:10 <c_wraith> Ah.  It's another GHC extension.  It allows you to make classes that take multiple type parameters.
06:52:22 <max3> on compilation i'm getting complaints that `Range.PGRangeType` is being applied to too many type arguments
06:53:00 <c_wraith> Then maybe it's not a multiparameter type class.
07:05:31 <lpaste_> merijn pasted “And slowly progress is made...” at http://lpaste.net/5100689670237323264
07:11:01 <angerman> bollu did you clone with submodules?
07:11:36 <alx741> hello everyone
07:12:15 <alx741> I'd like to have access to (globally) stack installed packages from normal ghci (not stack ghci) so I can to `ghci file.hs`, is that possible?
07:12:26 <alx741> s/to/do
07:12:57 <opqdonut> alx741: why not "stack ghci file.hs"?
07:13:43 <opqdonut> there's an implicit global stack project that gets used for "stack install" and "stack ghci" etc. if you don't have a stack.yaml
07:14:33 <alx741> opqdonut: according to the stack documentation `stack ghci file.hs`  will figure out which component the file is associated with (in a stack project) but if 'file.hs' is a standalone file it doesn't work
07:15:37 <alx741> in particular I get this: "Warning: Couldn't find a component for file target /home/alx/test/t.hs. Attempting to load anyway." and the file seems to not be loaded whatsoever
07:16:08 <alx741> but doing `ghci file.hs` works fine, except I have no access to stack installed packages from there
07:18:50 <alx741> doing `stack ghci file.hs` doesn't load 'file.hs', but then while already in the repl, doing ':l file.hs' works just fine. It's just the file in the command line argument doesn't work
07:22:12 <nesqi> Is there a cleaner way to write 'fromMaybe <$> fail "Error message" <*> maybeExpr ...'
07:24:10 <kgadek> nesqi: do you need custom err msg? if not: fromJust
07:25:41 <nesqi> I this particular case I need the custom error message.
07:25:54 <nesqi> But i could just make my own fromJust
07:26:05 <nesqi> (with some other name)
07:26:15 <nesqi> thanks
07:30:03 <merijn> tbh that code seems like a completely silly use of fromMaybe and fail
07:33:29 <Boomerang> > round (0/0) -- What do you think of this behavior? Does it make sense?
07:33:31 <lambdabot>  -269653970229347386159395778618353710042696546841345985910145121736599013708...
07:34:00 <Jinixt> isn't anything fair game once you divide by zero?
07:34:12 <Tuplanolla> Anything is fair game once you introduce floating-point numbers.
07:34:13 <Boomerang> I would expect an error
07:34:28 <merijn> Boomerang: Which error?
07:34:29 <kgadek> dividing by 0 in floats give NaN
07:34:32 <nesqi> merijn: yeah... it's not working...
07:34:49 <Boomerang> NaN shouldn't be convertible to an Int though
07:34:50 <merijn> nesqi: Which Applicative is that and what are you trying to do?
07:34:50 <phadej> > rount (0/0 :: Float)
07:34:52 <lambdabot>  error:
07:34:53 <lambdabot>      • Variable not in scope: rount :: Float -> t
07:34:53 <lambdabot>      • Perhaps you meant one of these:
07:34:54 <phadej> > round (0/0 :: Float)
07:34:56 <lambdabot>  -510423550381407695195061911147652317184
07:35:42 <phadej> > round (0/0 :: Rational)
07:35:44 <nesqi> I'm in the Action monad (shake build system) and want to fail with an error message if getEnv fails.
07:35:46 <lambdabot>  *Exception: Ratio has zero denominator
07:35:50 <Boomerang> > round (1/0) -- The behavior for infinity is fair enough, it depends on the definition of Int
07:35:51 <Prutheus> Hello! I wanna build a library with stack (stack instal ...) .... how can I do something my ram is not gettting full and the server crashes?
07:35:54 <lambdabot>  1797693134862315907729305190789024733617976978942306572734300811577326758055...
07:36:09 <phadej> > round (0/0 :: Float) :: Int
07:36:11 <kgadek> well. If we assume NaN is an error, then even more functions needs rethinking if we want to preserve totality
07:36:11 <lambdabot>  0
07:36:30 <opqdonut> in java round NaN => 0, floor NaN => NaN
07:36:31 <opqdonut> weird
07:36:48 <phadej> wedify: floor is :: -> Integral
07:36:52 <phadej> opqdonut: ^
07:36:52 <opqdonut> ah, it's because round returns integral
07:36:56 <phadej> eys
07:36:57 <alx741> Prutheus: have a big enough swap partition, but remember is not a good idea to -build- on the server, build on your machine and then deploy binaries
07:37:00 <opqdonut> (in java too)
07:37:03 <Boomerang> Actually even infinity is weird, where does the value come from? It's not 64bit Int, is it?
07:37:09 <phadej> ah, too late on Friday, cannot type anymore
07:37:16 <Prutheus> okay
07:37:19 <phadej> Boomerang: 
07:37:25 <phadej> > maxBound :: Double
07:37:28 <lambdabot>  error:
07:37:28 <lambdabot>      • No instance for (Bounded Double) arising from a use of ‘maxBound’
07:37:28 <lambdabot>      • In the expression: maxBound :: Double
07:37:36 <phadej> ah, but somethign like that
07:37:49 <Boomerang> phadej: Ah yes this makes sense
07:39:12 <phadej> The value of this constant is positive 1.7976931348623157E+308
07:39:54 <mniip> that's because it uses bit tricks
07:40:01 <mniip> > properFraction (0/0)
07:40:03 <lambdabot>  (-26965397022934738615939577861835371004269654684134598591014512173659901370...
07:40:08 <mniip> > properFraction (0/0 :: Float)
07:40:11 <lambdabot>  (-510423550381407695195061911147652317184,0.0)
07:40:29 <kgadek> IEEE754 defines NaN as non-comparable, so the "value of NaN" is implementation detail
07:40:53 <Boomerang> What does properFraction do exactly?
07:41:28 <mniip> > properFraction 3.5
07:41:30 <lambdabot>  (3,0.5)
07:41:46 <kgadek> Boomerang: https://hackage.haskell.org/package/base-4.9.1.0/docs/Prelude.html#v:properFraction
07:42:41 <Boomerang> Thanks!
07:44:45 <quchen> ?check \x -> let (a,b) = properFraction x in x == fromIntegral a + b
07:44:47 <lambdabot>  +++ OK, passed 100 tests.
07:46:28 <mniip> > let x = 0/0 in let (a,b) = properFraction x in x == fromIntegral a + b
07:46:31 <lambdabot>  False
07:46:54 <Boomerang> > (0/0) == (0/0)
07:46:55 <mniip> ah well, nan == whatever
07:46:56 <lambdabot>  False
07:47:13 <mniip> though fromIntegral that number is -Infinity and not Nan
07:47:20 <mniip> because it doesn't use encodeFloat
07:47:33 <mniip> fistp is faster
07:49:37 <novakboskov> If infinite list of integers can be constructed like this [1..] how could one construct infinite list of True values?
07:49:51 <Boomerang> The reason I tested "round (0/0)" in Haskell is because I saw how it behaves in Elm and it's pretty bad. Under the hood Elm uses floats to represent Ints and the abstraction leaks when doing "round (0/0)" as it returns NaN
07:50:01 <merijn> novakboskov: repeat True?
07:50:05 <merijn> > repeat True
07:50:08 <lambdabot>  [True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,...
07:50:12 <quchen> Boomerang: Probably because Javascript doesn’t have integers.
07:50:34 <Tuplanolla> > [True, True ..]
07:50:37 <lambdabot>  [True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,...
07:50:59 <Boomerang> quchen That makes sense but doesn't it break the type system?
07:51:14 <merijn> Boomerang: Define "break the type system"?
07:51:17 <dhalgren_> is there a both arrow? something that does (f *** f)?
07:51:24 <mniip> javascript? what's a type system
07:51:38 <merijn> dhalgren_: Yes, but maybe you're looking for Data.Bifunctor?
07:51:52 <dhalgren_> hm!
07:52:00 <Boomerang> Well NaN is part of the definition of floating point numbers but not integers, right?
07:52:15 <quchen> > bimap (*2) (++ "hello") (10, "world")
07:52:18 <lambdabot>  (20,"worldhello")
07:52:20 <nshepperd_> Elm's type system
07:52:23 <charleselpapi> hello world
07:53:02 <novakboskov> Tuplanolla: Hm... it can parse [1..] without space between integer literal and dots whereas space is required when there is True/False literal. Right?
07:53:32 <quchen> Boomerang: Yes. NaN is part of IEEE floats. There is no IEEE integer because they’re easy to represent.
07:53:44 <Tuplanolla> :t (Data.Function..) -- It's because of this, novakboskov.
07:53:46 <lambdabot> (b -> c) -> (a -> b) -> a -> c
07:53:53 <quchen> The only issues you can have with integers are overflows, that’s it.
07:54:01 <nshepperd_> Yes, coercing a NaN to an integer without care is surely a bug
07:54:21 <quchen> And maaaybe how to round divisions, but other than that I can’t imagine what there is to discuss about integer numerics.
07:55:25 <quchen> novakboskov: [True..] is interpreted as a list containing the ».« operator from the »True« package.
07:55:33 <quchen> > True..
07:55:37 <lambdabot>  <hint>:1:1: error: parse error on input ‘True..’
07:55:43 <quchen> :t (Prelude..)
07:55:45 <lambdabot> (b -> c) -> (a -> b) -> a -> c
07:56:01 <quchen> :t (Prelude.+)
07:56:03 <lambdabot> Num a => a -> a -> a
07:57:42 <novakboskov> Tuplanolla: It means that double dot at the end of [1..] is double function composition?
07:58:00 <Tuplanolla> No, novakboskov. You already got two explanations.
07:58:14 <quchen> No, the last dot is function composition, the first one is how we disambiguate module components.
07:58:19 <quchen> Data.Functor <- dot
07:58:25 <quchen> Prelude.head <- dot
07:58:30 <quchen> Prelude.. <- dot
07:59:14 <Tuplanolla> > read "1." :: Double -- This interpretation might have been allowed at some point as well.
07:59:15 <novakboskov> Tuplanolla: Sorry but I don't understand it. You just referenced type of function composition from like
07:59:17 <lambdabot>  *Exception: Prelude.read: no parse
07:59:17 <novakboskov> :t (Data.Function..)
07:59:19 <lambdabot> (b -> c) -> (a -> b) -> a -> c
07:59:59 <byorgey> novakboskov: in  Prelude..  the two dots are playing different roles.  The first dot separates the name of the module (Prelude) from the name of something contained in the module.
08:00:10 <byorgey> The second dot is the name of the (.) operator which is in the Prelude.
08:03:18 <novakboskov> byorgey: OK, it's clear, then Prelude.. is function composition. I've asked what is difference between [1..] and [True..] and why latter requires space between dots and True to work and Tuplanolla sad ":t (Data.Function..) -- It's because of this, novakboskov."
08:04:00 <Tuplanolla> The point was that `True..` and `Data.Function..` are syntactically equivalent, novakboskov.
08:04:33 <Taneb> novakboskov, because True begins with a capital letter, GHC goes "Aha! This looks like a module! I'm going to find (.) in the True module"
08:05:05 <Tuplanolla> This is not the case for `1..` since it belongs to a different name space.
08:05:21 <novakboskov> Taneb: Oh, right...
08:06:16 <novakboskov> Tuplanolla: Its clear. Thanks.
08:07:02 <novakboskov> BTW I didn't expected parse error, rather something like "no module" message...
08:07:26 <Rodenbach> Is there syntactic sugar for currying the first parameter of a binary function away.   I can do (foo 10) and then the first arg will be 10. But I want the second one to be 10.
08:08:18 <c_wraith> Rodenbach: no, but there are functions like flip for that purpose
08:08:30 <byorgey> flip foo 10
08:08:30 <Rodenbach> Ah okay!
08:15:40 <ClaudiusMaximus> Rodenbach: you can also use operator sections: (`foo` 10)
08:32:44 <markasoftware> is Stack available on Gentoo as a package?
08:35:09 <markasoftware> hmm, seems not
08:35:17 <Logio> markasoftware: there's an ebuild in the haskell overlay
08:35:29 <sternmull> the atom editor causes 100% cpu load with haskell-ghc-mod when i open a big project (git-annex). It does a lot of calls to ghc and doesn't seem to finish with that. Any ideas how to fix that?
08:37:17 <markasoftware> sternmull: atom in a nutshell...
08:38:55 <sternmull> markasoftware: i don't know if its a problem with atom or with ghc-mod, maybe i would have the same experience when using emacs
08:40:19 <lambdamu> Hi, I'm looking to hash STRef, is it fair to asume that they are pointers internally and can be casted to 64-bit (or 32-bit, depending on architecture) words and that they are not moved by the garbage collection?
08:41:27 <lambdamu> I was also wondering if it is were possible to have some kind of critical region where garbage can't strike?
08:42:08 <lambdamu> So that it were even possible to compare plain values by reference
08:42:26 <ClaudiusMaximus> StablePtr can be used to work around GC moving things, afaik (not used it myself)
08:43:11 <lambdamu> Hm yes I know, if I had pure values i would use them probably, but here I already have references
08:43:31 <phadej> lambdamu: Eq on STRef is pointer equality
08:43:43 <phadej> lambdamu: and http://hackage.haskell.org/package/base-4.9.1.0/docs/System-Mem.html could be used to run GC before critical section
08:44:43 <lambdamu> phadej: On the critical section: That would make it unlikely to run immediately again, but not impossible i guess?
08:45:09 <phadej> lambdamu: not impossible.
08:45:30 <phadej> I have no first-hand experience, but I'd expect it to run highly unluckily
08:45:38 <novakboskov> What is cause of this: foldr (||) False [False ..]
08:45:41 <novakboskov> foldr (||) False [False ..]
08:46:10 <phadej> lambdamu: I mean, if your section generates abnormal amounts of garbage, it has to be collected
08:46:19 <ClaudiusMaximus> would be nice to have critical regions with no gc and no pre-emption from other haskell threads (to allow some FFI things with thread-local variables like errno), but i guess not possible without major changes to ghc
08:46:19 <lambdamu> phadej: Eq on STRef: Im looking to keep the stref in a hashtable so Eq alone isn't sufficient, question is, is the pointer equality check safe because it runs atomically not giving the gc a chance to strike or because gc doesn't move the ptrts?
08:46:44 <novakboskov> > foldr (||) False [False ..]
08:46:46 <lambdabot>  True
08:47:14 <ClaudiusMaximus> @src or
08:47:15 <lambdabot> or = foldr (||) False
08:47:24 <lambdamu> phadej: Or are those questions misguided? Maybe I'm having the wrong operational model in mind
08:48:50 <ClaudiusMaximus> lambdamu: are you trying to have a hashtable of stref within a larger data structure, or 'bare'?  maybe you could make the hash instance ignore the stref, or include a dummy counter when you create your (Int64, STRef a)
08:49:20 <ClaudiusMaximus> (and use the Int64 in the hash instead of the stref)
08:49:40 <phadej> lambdamu: I'm not 100% sure, but STRef is MutVar# which is a pointer to object on a heap
08:49:47 <oisdk> > [False ..]
08:49:51 <lambdabot>  [False,True]
08:50:11 <phadej> but there are barriers, so if the object on the heap moves the MutVar#s should be updated
08:51:28 <lambdamu> phadej: Ah so things on the heap can move in general, if this happens to something that is pointed at it finds all occurences of the pointers and updates all the values, in the nominally pure data?
08:51:55 <lambdamu> ClaudiusMaximus: I'm not sure I understand let me think about it
08:52:10 <lambdamu> phadej: Effectively meaning the ptrs are not unaffected by the gc
08:52:39 <lambdamu> phadej: They are just corrected to point correctly to a new location
08:53:18 <phadej> lambdamu: I'm not sure, but yes, in the same way as (:) has pointers. With MutVar# you can *mutate* the pointers, so that's the difference
08:54:09 <lambdamu> phadej: No worries if your not certain anything helps
08:54:16 <ClaudiusMaximus> lambdamu: you'd write something like   mkNewSTRef' :: ST s (a -> ST s (Int64, STRef s a))  where you use its result value in place of newSTRef
08:54:49 <phadej> lambdamu: but I wouldn't write overly long ST computations
08:55:11 <lambdamu> phadej: Sometimes there seems to be no choice
08:55:31 <phadej> lambdamu: I'm curious, what you are working on?
08:55:59 <lambdamu> phadej: I'm implementing Self-Adjusting Computation after the 2008 paper by Acar
08:56:47 <lambdamu> "An experimental analysis of Self-Adjusting Computation" is the title
08:57:35 <phadej> is it FRP without events?
08:58:23 <phadej> lambdamu: I remember skimming those, wondering would it work if build on top of STM
08:58:34 <phadej> effectively enough
08:59:28 <lambdamu> phadej: I'm not sure about implementations of FRP really, I've heard the comparison come up a few times but it never so it given any depth
09:00:00 <phadej> lambdamu: I see.
09:00:46 <lambdamu> phadej: I'm not sure about STM either, I thought utilizing it in some way but it doesn't strike me as obvious
09:01:30 <lambdamu> phadej: the is no concurrency ongoing
09:02:21 <lambdamu> phadej: But the internal implementation details of STM could maybe be reused for tighter integration with the compiler faclliating change propagation
09:02:47 <lambdamu> phadej: but thats currently far out of the scope 
09:03:04 <phadej> lambdamu: from the application writer pov. I calculate once. Then the change comes (to random thread), I do stm transaction which updates the state
09:03:17 <phadej> -> profit
09:03:52 <phadej> lambdamu: https://www.youtube.com/watch?v=acZkF6Q2XKs might be interesting to you
09:04:34 <lambdamu> phadej: Yes I suppose, the dynamic depence graph has to be guarded with a lock, since the mutator can have multiple threads
09:04:48 <Ferdirand> p/win 5
09:05:07 <lambdamu> phadej: but thats really appears to be a minor detail and i guess i go with a mvar for efficieny
09:05:35 <phadej> lambdamu: that's why I'm interested in STM, so you don't need to have global lock
09:05:49 <phadej> global lock doesn't sound very sexy
09:07:28 <lambdamu> phadej: I would have to think about it, but I don't think it would gain much, since there is no fine grained concurrency possible, either the dependence graph is currently in propagation or it's not
09:08:11 <lambdamu> phadej: At least it's not obvious to me
09:08:43 <phadej> lambdamu: I'm not sure either. For static graph, where you can use topological sort to propagate stuff, only a part of graph have to be recalculated
09:09:39 <phadej> I'm not sure you can call that "SAC"
09:10:50 <phadej> lambdamu: I made https://github.com/phadej/menrva in JS for that, and it works well for everything (toy-sized though) I have thrown it upon
09:11:00 <phadej> haven't time / need to port it to haskell + stm
09:11:34 <lambdamu> phadej: I'll take a look
09:12:23 <dhalgren_> I seem to have a bunch of fromIntegral.length around, because I divide it to get doubles. is it generally needed or am I missing something obvious
09:12:28 <lambdamu> lambdabot: Are you dealing with any kind of higher-order signal?
09:12:52 <lambdamu> phadej: meant you
09:13:07 <phadej> lambdamu: no, the dependency graph is static
09:14:23 <phadej> I use it to make buttons change colors :)
09:14:55 <lambdamu> phadej: ah you sent the propagator talk, I remeber seeing it, any having no clou what it is about despite having implemented a sat solver and reading about SAC
09:15:18 <lambdamu> phadej: Should have listen more carefully
09:16:24 <lyxia> dhalgren_: genericLength is a standard function that does the same.
09:16:35 <dhalgren_> nice
09:18:03 <lyxia> dhalgren_: it's fine not to use it too.
09:19:27 <phadej> lambdamu: I don't remember the details, but perturbing inputs in cas is "adding more information" to the lattice
09:34:28 <bollu> omg omg, this is offtopic, but google code is down?!
09:34:39 <bollu> I had written a game as a kid that was hosted on google code. IS there ANY way I can get it back? :(
09:34:45 <bollu> it was called "herogame" IIRC
09:36:53 <Jinixt> may still be archived if you're lucky
09:37:06 <bollu> yes, I checked! looked like it is
09:37:13 <bollu> I'm downloading the archive now :')
09:37:43 <bollu> holy fuck I want to read the utterly byzantine horror show of C++ I had written as akid
09:37:46 <bollu> as a *
09:41:00 <mmachenry> bollu: One thing I like about Haskell is that my 15-year old Haskell code that I very recently had to revisit was actually fairly reasonable compared to my 15-year old code I've written in most other languages. 
09:42:08 <bollu> mmachenry: xD I can believe that
09:42:27 <bollu> mmachenry: I went very overboard with this though, because IIRC I would up reading "design patterns" at that point in my life
09:42:32 <bollu> I was.. heavily influenced
09:43:13 <Sonolin> I haven't been working with haskell long enough to deal with "old code", but the thing I like most about haskell is code maintenance
09:43:23 <yyyyy> mmachenry: my impression is that in 15-years from now your 30-year old code will read fine, but maybe your current day code will be unreadable to anyone not super experienced in haskell.
09:43:54 <Tuplanolla> That happened to me already, yyyyy.
09:44:03 <Sonolin> even if code is riddled with bad code and/or "procedural-style" thinking, I can usually completely replace all of it with a handful of funtions 
09:44:13 <mmachenry> yyyyy: Why is that? Too many new features in Haskell?
09:44:15 <yyyyy> Tuplanolla: the future is now!
09:45:36 <yyyyy> mmachenry: language extensions, “cool” things coming from academia adopted due to their coolness etc. 15 years ago you had no Free monads, no extensible effects, no :latest-thing:.
09:45:50 <yyyyy> no hasochism :)
09:46:23 <yyyyy> i'm not against it, just stating my impression of a trend
09:46:33 <mmachenry> yyyyy: Yeah… I will counter your prediction with the fact that I tend to be a bit of a simpleton. I actually program in Haskell because I'm dumb, not smart. :) I haven't adopted most of those features in my actual code.
09:46:40 <Tuplanolla> You don't even need those, yyyyy.
09:47:14 <yyyyy> no, of course you don't. but sometimes you will be client to a library that might use those concepts. then you have to at least understand it.
09:47:24 <mmachenry> Or I'll be more charitable and say I'm aware of my limitations and wisely use Haskell for that. I'm not using Haskell because I want to try all the crazy awesome stuff.
09:47:44 <mmachenry> Yeah makes sense. That might happen.
09:47:48 <yyyyy> mmachenry: likewise. i tend to keep things simple.
09:49:04 <lpaste_> Tuplanolla pasted “Obvious Algorithm” at http://lpaste.net/352328
09:49:44 <Tuplanolla> It's not even a year old and I already don't know how it works.
09:51:11 <yyyyy> Tuplanolla: lol! i suffer from the “it’s a local definition, so let me use a single letter for this function…” followed by weeks later obligatory “what do this even…”
09:52:40 <yyyyy> and you even went pointfree on it, shame on your future self :p
09:53:10 <Tuplanolla> I didn't even use the owl.
09:54:43 <yyyyy> hahahaha! but was it due to lack of opportunity?
09:57:16 <Tuplanolla> Maybe...
09:58:04 <yyyyy> every once in a while i see a library using lens pervasively and am reminded of my lack of patience to understand it more thoroughly. i feel specially dumb when said code is littered with its operators, leading to having one monitor with haddock and one with actual library code. it's a slow process.
09:59:28 <Tuplanolla> The textual versions of the operators are much easier to remember.
09:59:31 <yyyyy> and yet… i end up using a subset of those operators on some projects, simply because it saves me time. so i can’t blame whoever wrote with more on theirs.
09:59:36 <Tuplanolla> That's totally not my Lisp envy talking.
10:00:02 <yyyyy> hahaha
10:00:33 <yyyyy> i suppose if you use it as your daily DSL for lots of things you get used to them to the point where you can’t remember how you hated it in the beginning.
10:02:08 <Tuplanolla> Where else have I heard of users needing their daily dose of some abbreviation?
10:02:16 <Javran> > ((,) <$> minimumOf traverse <*> maximumOf traverse) [1..10]
10:02:19 <yyyyy> APL?
10:02:20 <lambdabot>  (Just 1,Just 10)
10:02:55 <Javran> hm I want to know can I do better than this, or to retrieve min and max at the same time do I have to traverse twice?
10:06:23 <reactormonk> How do I make a Lift instance for a phantom type without using deriving Lift?
10:08:37 <dmwit> > foldMap (\x -> (Min (Just x), Max (Just x))) [1..10]
10:08:40 <lambdabot>  error:
10:08:40 <lambdabot>      • Data constructor not in scope: Min :: Maybe Integer -> t
10:08:40 <lambdabot>      • Perhaps you meant one of these:
10:10:53 <dmwit> > foldMap (\x -> (Just (Semigroup.Min x), Just (Semigroup.Max x))) [1..10 :: Int]
10:10:55 <lambdabot>  (Just (Min {getMin = 1}),Just (Max {getMax = 10}))
10:11:00 <dmwit> Javran: ^^
10:11:23 <reactormonk> Ah, doens't work at all. https://github.com/mboes/th-lift/commit/cd382e016339cd5d5dbe55edf78a1027020736c0
10:11:36 <Tuplanolla> > foldMap (Min &&& Max) [1 .. 10]
10:11:39 <lambdabot>  error:
10:11:39 <lambdabot>      • Data constructor not in scope: Min :: Integer -> c
10:11:39 <lambdabot>      • Perhaps you meant one of these:
10:11:51 <Tuplanolla> > foldMap (Semigroup.Min &&& Semigroup.Max) [1 .. 10]
10:11:55 <lambdabot>  error:
10:11:55 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M100692917862...
10:11:55 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
10:12:07 <Tuplanolla> That should work anyway.
10:12:10 <dmwit> > foldMap (Just . Semigroup.Min &&& Just . Semigroup.Max) [1 .. 10 :: Int]
10:12:13 <lambdabot>  (Just (Min {getMin = 1}),Just (Max {getMax = 10}))
10:12:32 <dmwit> I think the Just is necessary. foldMap demands Monoid
10:12:35 <Tuplanolla> You don't even need `Maybe`.
10:12:38 <reactormonk> ah nope, that's not it. blubb.
10:12:40 <dmwit> Prove it.
10:12:46 <Tuplanolla> > foldMap (Sum &&& Product) [1 .. 10 :: Int]
10:12:49 <lambdabot>  (Sum {getSum = 55},Product {getProduct = 3628800})
10:13:09 <dmwit> :t foldMap
10:13:11 <lambdabot> (Monoid m, Foldable t) => (a -> m) -> t a -> m
10:13:21 <dmwit> Tuplanolla: Sum and Product are Monoids. Min and Max are not.
10:13:23 <Tuplanolla> Oh, `Min` is a bit different.
10:13:30 <Tuplanolla> Indeed.
10:13:45 <glguy> Option is good for promoting a Semigroup to a Monoid
10:13:51 <dmwit> Tuplanolla: Oh, actually, Min and Max *are* Monoids.
10:14:02 <dmwit> Provided the contained type is Ord and Bounded. So I am the one who is wrong!
10:14:32 <dmwit> > foldMap (Semigroup.Min &&& Semigroup.Max) [1 .. 10 :: Int]
10:14:35 <lambdabot>  (Min {getMin = 1},Max {getMax = 10})
10:14:56 <dmwit> Although the answer you get for [] could be a bit surprising if you're not paying attention.
10:15:12 <dmwit> Using Maybe (or Option, outside of lambdabot) is probably cleaner.
10:15:23 <Tuplanolla> Yes.
10:15:25 <dmwit> > foldMap (Semigroup.Min &&& Semigroup.Max) ([] :: [Int])
10:15:28 <lambdabot>  (Min {getMin = 9223372036854775807},Max {getMax = -9223372036854775808})
10:15:58 <Tuplanolla> Do we have a point-at-infinity `Integer` type?
10:17:05 <dmwit> Yes, in monoid-extras there is PosInf and NegInf.
10:17:33 <dmwit> http://hackage.haskell.org/package/monoid-extras-0.4.2/docs/Data-Monoid-Inf.html
10:18:13 <dmwit> The primary difference between `PosInf a` and `Option (Min a)` is that `PosInf` promises that `max` will treat the infinity correctly and `Option` doesn't.
10:18:28 <dmwit> One of `Option (Min a)` and `Option (Max a)` does not (cannot) treat the infinity correctly.
10:19:05 <dmwit> Well. `compare`, not `max`. But you get the idea.
10:21:25 <Javran> I see, thanks all!
10:33:10 <kubbe> Hello! Is it possible to take out a value out of a Table, which contains tuples?
10:34:18 <glguy> That'd depend on what a Table is
10:37:26 <kubbe> The table is a character counter atm. It saves the character and the amount of times it occurs in the string
10:37:40 <kubbe> but we need to take out these values and create a tree of  them. How should we do it?
10:37:52 <dmwit> Hi again kubbe. =)
10:38:11 <kubbe> Hello! I have more or less the same problems as yesterday :( dmwit
10:38:43 <janos> kubbe: do you have some code we can see? Still struggling to understand what the problem is :)
10:38:46 <dmwit> Nobody can really answer the question you're asking unless you show the code (or at least the type signatures for the API) of Table.
10:39:03 <dmwit> ?paste in case you've lost the link to the paste site we prefer
10:39:03 <lambdabot> Haskell pastebin: http://lpaste.net/
10:39:04 <kubbe> Yeah sure thing! 2 seconds.
10:43:09 <kubbe> Huffman-file: http://lpaste.net/352329 | PrioQueue-file: http://lpaste.net/352330 | Table-file: http://lpaste.net/352331
10:50:39 <kubbe> The problem is that I dont really know how to create my huffman tree.
10:57:59 <cocreature> kubbe: so you are looking for a function of type "Table k v -> Tree k v"?
10:58:19 <cocreature> or Table Char Int -> HuffmanTree?
10:58:20 <kubbe> Yes!
10:58:32 <kubbe> exactly. I need help with figuring that one out at the moment
11:01:30 <cocreature> kubbe: are you familiar with how you build a huffman tree given the letters you are trying to encode and the number of their occurences? (on a conceptual level, not in haskell)
11:01:41 <Boomerang> kubbe: You have to start with an empty HuffmanTree (Void) and add entries in the form of Leafs and Node one by one. To get an optimal Huffman Tree you want the two branches of each Node to have more or less the same weight. The weight is the sum of the weight from the two branches. When adding a new entry, if the current Node has the same weight as the entry put them side by side in two branches, if 
11:01:47 <Boomerang> not recurse down one of them to add the entry and propagate the weight change back up. I think this is how the algorithm goes, I would write the code but I think this is an assignement
11:02:59 <kubbe> cocreature: Well, I think so yes!
11:03:50 <cocreature> kubbe: are the functions in the PrioQueue already implemented or do you need to implement them yourself?
11:04:23 <cocreature> oh nvm they are at the bottom
11:04:30 <kubbe> they are done! yeah
11:04:52 <cocreature> kubbe: well in that case, you already have all the building blocks needed for the algorithm. so where are you stuck?
11:05:30 <kubbe> So I guess I like need to use PQ-functions
11:05:49 <cocreature> kubbe: take a look at the first algorithm here https://en.wikipedia.org/wiki/Huffman_coding#Compression
11:05:50 <kubbe> to start to how to create the tree! like Boomerang says, that algorithm is correct
11:05:58 <kubbe> but I am not sure how to start the code...
11:06:41 <cocreature> kubbe: so let’s go through this step by step. what should initially be stored in the priority queue?
11:07:05 <Boomerang> You can think of it as a fold of insert on an empty tree (after the priority queue)
11:07:54 <kubbe> in the PQ it should store a lists of tuples with 1 polymorphic value and 1 int. the poly-value is in our cases always a character
11:09:09 <cocreature> kubbe: you first need to decide which algorithm description you follow. the one Boomerang described is slightly different than the one described on wikipedia
11:09:42 <Boomerang> I didn't read Wikipedia, definitely trust it over what I said (just wrote it from memory)
11:10:54 <kubbe> Okey! Well, our assignment says that the character that occur the least amount of times is at the bottom of the tree. Then it should be the algorithm from wikipedia?
11:12:42 <cocreature> kubbe: alright, let’s go with that. so you said that your priority queue contains characters (and their weight) but this is not correct. take a look at step 2.3 and think about the type of the thing you are inserting here
11:14:26 <kubbe> Just to make things clear: highest priority = highest int = closest to the root?
11:15:54 <cocreature> no, highest prriority = smallest int
11:16:10 <cocreature> your priority gives you a “least” operation not a “max” operation
11:16:33 <kubbe> But yes, I understand that step.. I think. So we are supposed to take out the 2 tuples with the highest priority, add the two INT's and then create a new NODE holding that INT?
11:17:11 <monochrom> w00t, min priority queue vs max priority queue?
11:17:22 <cocreature> kubbe: right, so you are adding a Node to your priority queue, so the type of the things it holds can’t be Char
11:19:20 <kubbe> Hmm.. well no! But it is polymorphic so it can be anything then? It should be of type leaf then
11:19:24 <kubbe> not Char
11:22:03 <cocreature> kubbe: Leaf is not a type
11:22:22 <Younder> Tree is the type?
11:22:43 <monochrom> Yes
11:22:48 <Younder> Sorry for barging in.
11:23:05 <kubbe> Oh yeah, ofc. Tree is the type!
11:23:11 <monochrom> No problem, it's a long conversation, and even I only know a bit.
11:23:18 <kubbe> Its fine Younder
11:23:54 <kubbe> monochrom, this conversation havnt been so long today :D
11:24:28 <monochrom> I just mean more than 5 minutes
11:24:45 <kubbe> haha, oh
11:25:49 <cocreature> kubbe: alright, so what should initially be in the priority queue?
11:26:57 <kubbe> a bunch of trees?
11:27:15 <cocreature> kubbe: but which trees and with which priority?
11:28:12 <cocreature> remember that you are given a Table Char Int
11:30:56 <kubbe> cocreature: ehmm... well I guess the sub-trees that is holding the character and the priority. the priority is the same as the value of how many times the character is in the string that I input
11:32:49 <cocreature> kubbe: exactly, so start by writing a function "Table Char Int -> PriorityQueue HuffmanTree" that produces that initial priority queue
11:35:10 <kubbe> Yeah alright, so some sort of help-function in addition to the huffmanTree
11:37:35 <monochrom> Wait a second, PriorityQueue HuffmanTree doesn't look right.
11:38:36 <monochrom> Isn't it supposed to be, conceptually, Table Char Int -> PriorityQueue Char, and then PriorityQueue Char -> HuffmanTree?
11:39:33 <cocreature> monochrom: no, you keep removing the two huffman trees with the least weight from the queue, create a new tree and insert that back in the queue
11:39:38 <cocreature> once there is only one tree left you are done
11:39:56 <cocreature> you can ofc insert a PriorityQueue Char step in between but that’s not really helpful
11:40:16 <monochrom> Oh, that's neat.
11:42:02 <kubbe> But the first line of code, my base-case in that helpfunction... 
11:42:10 <kubbe> what is that? In haskell
11:43:18 <cocreature> kubbe: your basecase is the empty Table
11:43:32 <kubbe> I have discussed it with my grouppartner and we are not really sure where to start. Since how do I take out the huffmantrees from the Table Char Int
11:44:02 <cocreature> kubbe: do you know how you can pattern match on a list?
11:44:30 <kubbe> well yes, but not on a Table
11:44:44 <Boomerang> I think the point of Table is to hide the fact that it's implemented with a list, you should use the functions you created
11:44:56 <Boomerang> You can build your PQ using Table.iterate
11:45:00 <cocreature> oh right, you are probably supposed to use "iterate"
11:45:13 <emilymhorsman> I'm using Snap and it uses strict `Data.ByteString`s for everything (as opposed to lazy ones). I'm trying to convert an Int to a strict ByteString. I have `toStrict . toLazyByteString . intDec` which works, but I'm wondering if there's a better way.
11:45:24 <volhovm> Hello everyone. I wonder is there anything one can say _in general_ about lazy transformers in stack -- should they be used, or it's better to use strict versions?
11:45:42 <cocreature> kubbe: so the type of iterate is "Table k v -> (b -> (k, v) -> b) -> b -> b". do you know what that function does and what its arguments are?
11:46:58 <kubbe> I think I do. It iterates over all values in the Table, but not what the arguments are no
11:47:16 <cocreature> kubbe: so the first argument should be obvious. that’s just the table that it iterates over
11:47:28 <kubbe> yes, haha
11:47:41 <cocreature> kubbe: are you familiar with foldl/foldr?
11:48:39 <monochrom> volhovm: In general, understand what is lazy what is strict, use strict when you need strict, use lazy when you need lazy.
11:48:52 <kubbe> i am familiar with them, but I havnt used them so much
11:49:07 <cocreature> kubbe: alright, let’s stick with your iterate function then
11:49:15 <monochrom> General questions begets tautological answers.
11:49:34 <cocreature> kubbe: the first argument is obvious, let’s move to the third argument next. that’s the initial value used before the actual iteration starts
11:50:32 <kubbe> the third argument is the v, right? It is the value connected to the key. In our case, this is the prioritity
11:50:55 <cocreature> kubbe: no the third argument is the "b"
11:50:58 <volhovm> monochrom: so strictness is defined by the outer layer transformer, right?
11:51:07 <cocreature> the first is Table k v, the second is (b -> (k, v) -> b), the third is b
11:51:11 <cocreature> and the function returns "b"
11:51:31 <kubbe> Yes, okey! Hmm, let me think of this a second..
11:52:03 <cocreature> kubbe: the second argument is a “step” function, it takes the current accumulated value (initially this is the third argument) and a (k, v). the (k, v) is one entry in your table. 
11:52:20 <cocreature> kubbe: this function produces a new accumulator value
11:52:24 <monochrom> No, the world is not a simple boolean "lazy vs strict".
11:52:45 <cocreature> kubbe: iterate just keeps applying the step function to each entry in your table and passes the accumulator around
11:52:53 <monochrom> Ever heard of 50 shades of grey? There are even more shades of lazy or strict.
11:53:28 <volhovm> I obviously get it, just exepcted some theorems to exist about it.
11:53:54 <kubbe> alright, i get that!
11:54:07 <volhovm> So i could understand how `MaybeT (pure $ repeat 5) >>= \a -> liftIO (print $ take 2 a)` behave in different contexts
11:54:15 <volhovm> depending on what is under MaybeT
11:54:23 <volhovm> ... without testing it in ghci
11:54:24 <cocreature> kubbe: maybe try implementing a function that counts the number of entries in your table using "iterate" before you try the function that produces the priority queue
11:55:28 <monochrom> Because you have "pure", that one only needs monad laws.
11:55:36 <dolio> I think you can understand that expression without testing in ghci, but it doesn't have to do with strict and lazy stuff much.
11:55:41 <kubbe> oh, as a exercise
11:55:42 <monochrom> = liftIO (print (take 2 (repeat 5)))
11:56:44 <dolio> I think it's actually a type error as written, though.
11:57:27 <monochrom> Right, actually MaybeT (pure $ repeat 5) is a type error.
11:57:44 <monochrom> So you don't even need monad laws. You just need type judgments.
11:59:47 <kubbe> cocreature, well I could try. But in actual code: how should my basecase look like? I have no idea what the first input is since it doesnt work with empty, Table.empty or []
12:00:57 <cocreature> kubbe: you don’t need a basecase, "iterate" already does the recursion for you
12:01:07 <dolio> If you fix it in the obvious way, though, it's what monochrom said.
12:02:04 <monochrom> One of the parameters of iterate is your base case. (Another one is your induction step.)
12:04:32 <kubbe> cocreature: http://lpaste.net/352333 this is what I have come up with so far
12:05:14 <Boomerang> kubbe: you don't need characterCounts in this function, you are already given a Table as input
12:05:19 <cocreature> kubbe: you need to pass the argument of huffmanTree' to Table.iterate, not some random "characterCounts" variable that you got from somewhere
12:05:27 <cocreature> also I don’t know what s is supposed to be
12:06:20 <Boomerang> kubbe: characterCounts will be used later on along with huffmanTree to create "compress"
12:07:29 <kubbe> Oh, ofcourse! Okey :D
12:07:51 <kubbe> so: huffmanTree' = Table.iterate huffmanTree' 
12:07:56 <kubbe> and some more stuff afterwards ofc
12:08:05 <cocreature> no!
12:08:06 <kubbe> ohh, okey Boomerang
12:08:19 <cocreature> now you are passing the function that you are defining using Table.iterate to Table.iterate
12:08:22 <cocreature> that is not going to go well
12:10:06 <kubbe> i have a trouble of understanding what "argument of huffmantree'" means. Either it means: Char and Int 
12:10:10 <kubbe> or PriorityQueue
12:10:19 <kubbe> if you ask me :p
12:10:40 <cocreature> kubbe: I really recommend that you do the simpler exercise that I proposed first if you are having trouble with this
12:12:09 <kubbe> is it possible for you to give me an working example of Table.iterate? In code, so I can see what input it takes
12:12:17 <kubbe> after that i'll give that simpler exercise a go
12:13:27 <Boomerang> kubbe: for the simpler exercise cocreature gave you (length :: Table Char Int -> Int) if it helps the type of Table.iterate to use is Table Char Int -> (Int -> (Char, Int) -> Int) -> Int -> Int
12:14:16 <Boomerang> For this particula exercise, the values (Char, Int) don't matter since you're just trying to find the length
12:14:52 <kubbe> Yes! I want to find the length of the Table
12:16:40 <cocreature> kubbe: if it helps, write the function using "foldl" on lists first. iterate is just a wrapper around foldl so you can easily translate your foldl code to iterate later
12:18:09 <kgadek> hi. anyone knows any real-world usage of freer? I'm curious about the actual experience
12:18:38 * kgadek is watching "MTL vs Free deathmatch" and started wondering on this even more
12:19:47 <kubbe> Im going to try cocreature!
12:26:51 <max3> can anyone help me with this error? it doesn't seem like it should be occurring http://pastebin.com/G8fAaj1s
12:27:50 <cocreature> max3: where is PGArrayType from?
12:27:59 <kubbe> I give up
12:28:11 <max3> cocreature, https://github.com/databrary/databrary/blob/master/Databrary/Model/Segment.hs
12:28:29 <max3> cocreature, line 26 and 43
12:28:35 <kubbe> I have no clue what so ever to make a foldl-function work, and less how to make the algorithm work!
12:28:55 <cocreature> max3: which package does that module belong to?
12:29:43 <max3> cocreature, i think the answer to your question is the parent one as indicated by that github link
12:30:02 <cocreature> max3: there is no postgres folder in https://github.com/databrary/databrary/tree/master/Databrary
12:30:37 <max3> which module do you mean? Segment or Database.PostgreSQL.Typed.Array
12:30:37 <cocreature> alright it’s from postgresql-typed
12:30:47 <max3> sorry yes
12:30:57 <max3> cocreature, what i don't understand
12:31:07 <max3> is i thought i had the syntax understood
12:31:23 <max3> instance PGType "segment[]" declares "segment[]" an instance of PGType
12:31:46 <cocreature> max3: "sement[]" is not a type (without advanced extensions)
12:32:06 <max3> DataKinds at the top of the file
12:32:10 <cocreature> ah ok
12:32:33 <cocreature> max3: well for PGArrayType the problem is simple, you are passing two types but PGArrayType is not a multiparam typeclass
12:32:38 <cocreature> haven’t looked at range type yet
12:33:04 <cocreature> PGRangeType is also not a multiparam typeclass
12:33:40 <Boomerang> kubbe: don't give up! folds are just a way to simplify a certain type of recursion. Take a look at the source code for the length of a list:
12:33:44 <Boomerang> @src length
12:33:44 <lambdabot> Source not found. Maybe you made a typo?
12:34:00 <Boomerang> Oh, what about sum?
12:34:07 <Boomerang> @src sum
12:34:07 <lambdabot> sum = foldl (+) 0
12:34:16 <merijn> sum is actually a pretty terrible example, since it leaks space all over the place...
12:34:50 <max3> cocreature, is there any chance it could be something else? this code is running in production
12:35:02 <Boomerang> right, we were trying to explain how folds work, it seemed like a simple example
12:35:18 <kubbe> yeah, but if wanted to use that one in an actual example
12:35:22 <cocreature> max3: not really. maybe you are using an older version of postgresql-typed that uses a multipparamtypeclass here?
12:35:28 <merijn> hmmm, there really isn't a reasonable way to do a closable channel without STM, is there?
12:36:31 <kubbe> since I cant just learn by theory, i need to acutally see some working code and there is relative hard to actually find that in this particular language
12:37:00 <kubbe> I need to go brb for 15-20 minutes now, though
12:37:14 <Tuplanolla> Hackage is full of working code, kubbe.
12:37:52 <Tuplanolla> You can `cabal get` packages and look inside.
12:41:07 <max3> cocreature, `class (PGType ta, PGType t) => PGArrayType ta t | ta -> t, t -> ta where` from 0.4.3
12:41:13 <max3> that means multiparameter right?
12:41:26 <max3> although i don't understand the | in the definition
12:42:03 <cocreature> max3: yep that’s multiparameter, looks like it changed in 0.5
12:42:14 <max3> what does the alternation mean?
12:42:18 <cocreature> max3: | followed by the part after this is a functional dependency
12:42:26 <cocreature> ta -> t means that ta uniquely determines t
12:45:41 <cocreature> max3: so it looks like 0.5 switched from using fundeps to using type families
12:49:14 <merijn> Whee!
12:49:32 <cocreature> merijn: whuuu!
12:49:42 <merijn> I realised that, not only would it probably be easy to implement what I want. But I already have 90% of the code implemented in a package already :D
12:51:13 <merijn> GHC doesn't warn for non-exhaustive patterns in do notation?
12:51:20 <merijn> That's...pretty fucking awful
12:52:52 <merijn> I don't suppose there's a way to fix that? Or does GHC8 perchance have that?
12:52:57 <pikajude> no, because of fail
12:53:13 <merijn> Yet another reason to hate fail
12:54:44 <merijn> I was planning to rely on warnings to find all places to change things :(
12:55:19 <dolio> If you turn on -XMonadFailDesugaring, it will have a different type.
12:56:49 <merijn> dolio: That just infers a MonadFail constraint, no?
12:57:04 <dolio> Yes, that is a different type.
12:57:17 <merijn> dolio: Except I have a fixed monad (IO)
12:57:31 <merijn> So, since I'm assuming that has a MonadFail instance it doesn't actually help me here
12:57:37 <dolio> Ah.
12:58:04 <pikajude> it does have a MonadFail instance
12:58:07 <merijn> I guess I'll have to use grep...like a savage
13:02:58 <dolio> It sounds like -Wincomplete-uni-patterns should warn about this, but it seems like it doesn't.
13:03:47 <merijn> dolio: ok, then I don't have to bother upgrading GHC either :p
13:11:21 <ClaudiusMaximus> merijn: one possibly-insane-amount-of-work way might be make an newtype over IO with Monad but no MonadFail instance?  maybe a MonadIO instance could help too?  (especially if you can find MonadIO m => versions for your primitive IO actions)
13:11:51 <merijn> ClaudiusMaximus: That'd like quadruple the code I have :p
13:12:17 <ClaudiusMaximus> ok, then grepping for <- might do
13:12:33 <merijn> ClaudiusMaximus: Or just the specific constructor I'm expanding :)
13:12:43 <ClaudiusMaximus> that too
13:29:10 <drostie> So the normal ListT done right is newtype ListT m x = ListT { runListT :: m (Maybe (x, ListT m x)) }. I have a desire for streams like this in JS but the newtypes and returns are creating tons of allocations, slowing the code down bigly. 
13:29:30 <ryantrinkle> is there something like bytestring-trie, but for Text?
13:31:32 <drostie> It seems like the obvious thing to do is to replace (x, ListT m x) with (Array Int x, ListT m x) so that I can skip the allocations for these sorts of tasks, but then I hypothetically want to move the pair constructor outside of the maybe as well, newtype ListT m x = ListT { runListT :: m (Array Int x, Maybe (ListT m x)) }.  In either case you then get that the original ListT is only isomorphic to a certain equivalence class of the 
13:31:32 <drostie> new ListTs.
13:32:49 <drostie> So I guess my question to you guys is "Is that a really bad idea and I'm just not realizing it?" or so.
13:34:25 <drostie> (The equivalence class is basically [[1,2], [3,4], [5,6]] being equivalent to [[1,2,3], [4,5,6], []] in the identity monad.)
13:37:24 <monochrom> No, don't go (Array Int x, Maybe (ListT m x)). In the case of Nothing, now you still have to provide a fictitious array, and the user has so many more cases to worry about.
13:38:23 <drostie> Cases?
13:38:45 <monochrom> Think about what the user has to go through.
13:39:00 <drostie> Yes, I do have to allocate an empty array to return ([], None) for the empty array.
13:39:09 <drostie> er, empty ListT.
13:42:52 <merijn> So...some advice: Suppose I have two variants of a function that's say, 2-4 lines of code, extract into generic version and write the special cases in terms of the generic one or just duplicate the code?
13:43:29 <benzrf> depends on context probly
13:43:50 <drostie> monochrom: oh, maybe I see what you're saying. I think you're saying that it's conceptually more complicated to have to process []
13:43:59 <monochrom> If the first option is not slower, do it, and write comments to explain.
13:44:16 <drostie> I mean, if it occurs in the middle of the ListT.
13:44:21 <merijn> The context is: it's a particularly tricky 2-4 lines of concurrent code, but the generic version doesn't cleanly fall out
13:44:39 <monochrom> So write comments to explain.
13:44:57 <monochrom> Write the whole bloody derivation proof in comments. That's what comments are for.
13:45:16 <monochrom> Comments should be for explaining to humans. Not explaining to the computer "don't compile this code".
13:45:55 <drostie> merijn: also depends on what you're doing whether you introduce an extra dependency.
13:46:11 <monochrom> The other day someone noticed that many editors' colour schemes give comments a faint, invisible colour, and wondered why.
13:46:46 <merijn> monochrom: I'm confused whether you're complaining at me or not :p
13:46:50 <monochrom> My theory is that people now believe in the dystopia of "self-documenting code", and so the only purpose left for comments is to comment out code.
13:48:52 * merijn is still unsure >.>
13:49:17 <monochrom> Do you believe in the dystopia of "self-documenting code"?
13:50:07 <merijn> monochrom: I think the file I currently have open has about 50:50 code to comment ratio? But then, I didn't write most of those...so maybe? >.>
13:50:41 <monochrom> Then my complaint may be including you.
13:50:53 <drostie> merijn: I'm thinking particularly in my current case I had this bright idea, "hey, I have this simple .take() and .drop() set of methods, I could .takeWhile() and .dropWhile() but all of the code those don't duplicate with .take() and .drop() they duplicate with each other, about checking whether the prefix is still valid." So it seems like I should refactor out the count-prefix code and then take or drop the corresponding prefix.
13:51:05 <drostie> 3 guesses why this is actually a stupid idea. ^_^
13:52:38 <monochrom> Actually let's make it more fun. Do you simultaneously believe in "self-documenting code" and "personal growth in the programming career"? Because they are in fundamental contradiction.
13:52:39 <merijn> Maybe I should just write a CPP macro...
13:53:00 <merijn> Ugh...this line of thinking is going to be my thesis all over again...
13:53:24 <monochrom> Namely, if all you see is self-documenting code, you will never learn the more subtle and advanced things, therefore no personal growth.
13:55:24 <monochrom> If you go with the first option, you are doing your maintainer a service --- you are teaching them a non-obvious generalization (or specialization).
13:55:40 <monochrom> Something they will never learn by reading self-documenting code.
13:55:54 <monochrom> But be sure the teaching happens in comments.
14:03:53 <monochrom> Hrm, old literature says "overloaded function" instead of "method" (for class methods).
14:04:31 <monochrom> It is in Mark Jones's "typing haskell in haskell" but there are also a few relics in Haskell 2010.
14:11:26 <monochrom> onoes, he also uses "Monad m => X -> m Y" for partial functions relying on "fail"
14:18:58 <merijn> Anyone know where I can get more up-to-date vim syntax highligthing for cabal files? Mine seems rather out of date
14:19:15 <monochrom> He also writes "f x y | Ctor x == y" instead of "f x (Ctor z) | x == z"
14:20:53 <monochrom> I guess it is more uniform because he has other guards that do not require y == Ctor something
14:44:35 <Jello_Raptor> Okay, so I found a way to get "shared constructors" on my datatypes :/ but it's cludgy and I'd appreciate any insight on better ways to solve the problem. 
14:44:37 <Jello_Raptor> http://lpaste.net/352341
14:45:34 <Jello_Raptor> I'd really just like to be able to use type families as type functions :/ but the requirement that they have to be fully applied means I have to wrap everything in random new datatypes 
14:45:58 <Jello_Raptor> and then use typeclasses and pattern synonyms to abstract over all that
14:48:32 <monochrom> I am reading the code and I think I'm more lost than before reading. What does "shared constructors" mean?
14:49:34 <monochrom> Rather, how would I use (not implementer) shared constructors?
14:53:10 <glguy> Jello_Raptor: What version of GHC are you using?
14:53:56 <glguy> Oh, I see, the top version isn't expected to work
14:54:04 <Jello_Raptor> monochrom: "shared constructors" is a bad name. I'm trying to solve that problem where you have 15 versions of effectively the same data structure "data Foo1 = A1 Int | B1 Bool","data Foo2 = A2 String | B2 String", etc..
14:54:45 <Jello_Raptor> glguy: the last bit works in 8.0.1 (barring some incomplete pattern match warnings) 
14:55:50 <monochrom> No, Foo1 and Foo2 look dissimilar to me. Unless I should abstract away enough so that Foo1 is Either Int Bool and Foo2 is Either String String. In which case you already have Left and Right.
14:57:02 <monochrom> Left replaces A1 and A2. Right replaces B1 and B2.
14:57:28 <monochrom> The overarching type is "Either a b"
14:57:44 <Jello_Raptor> monochrom: mm? they have the same shape, many operations over them are going to be the same, they just store different values. Also that's just an example, the actual types I'm working with are complex and recursive, they're fundamentally ASTs for a DSL 
14:57:50 <lpaste_> glguy annotated “Datatype with shared structure?” with “Datatype with shared structure? (annotation)” at http://lpaste.net/352341#a352343
14:58:20 <glguy> Jello_Raptor: how about that?
14:58:26 <monochrom> Sure. Let me show you something I wrote for a "very general type for expressions"
14:58:56 <monochrom> Pardon the mult-line right in the channel.
14:58:58 <monochrom> data Term q o v = BV !Int   -- ^local variable, de Bruijn 0-based index
14:58:58 <monochrom>                 | FV v     -- ^free variable
14:58:58 <monochrom>                 | A { operator :: o, operands :: [Term q o v] }
14:58:58 <monochrom>                   -- ^compound term; application; leaf term (empty operands)
14:58:58 <monochrom>                 | Q { quantifier :: q, varname :: v, body :: Term q o v }
14:58:59 <monochrom>                   -- ^quantified term
14:59:11 <monochrom> See I have 3 type variables q, o, v there?
15:00:01 <monochrom> So I can have a million special cases beginning from "Term String ByteString Text", "Term Int Char ()", "Term ByteString Text Bool", ... etc etc
15:00:04 <Jello_Raptor> monochrom: yes, I know how to use type variables :P the problems start happening when I have a dozen of them being thrown around.
15:00:36 <monochrom> OK, buy a wider monitor if you have 12 type variables?
15:00:55 <ezyang> Jello_Raptor: Clearly, you should use Backpack ;) 
15:01:10 <ezyang> One of the problems it solves is eliminating type variables 
15:01:49 <EvanR> Term q o v... you just covered pretty much every formal language
15:01:55 <monochrom> YES!
15:02:25 <monochrom> And I have a unification function that works without knowing q, o, v! (But needs Eq etc)
15:02:32 <merijn> monochrom: *pedantic complaint that you miscapitalised De Bruijn*
15:02:52 <monochrom> Wait, I need De there?
15:03:04 <monochrom> Do you have a citation?
15:03:30 <EvanR> duh bruijns
15:03:47 <merijn> monochrom: Two rules in Dutch: Rule 1) First letter of a name is always capitalised, 2) "tussenvoegsels" (connectors, I suppose?) are not capitalised. With rule 1 trumping 2
15:04:04 <merijn> monochrom: So "Nicolaas Govaert de Bruijn", but "De Bruijn-indices"
15:04:24 <monochrom> Yikes. I need a drink.
15:04:38 <merijn> monochrom: Which pretty much the entire computer science world gets wrong, but I won't stop my pedantic crusade!
15:04:45 <monochrom> Fixed in my file now.
15:05:11 <merijn> (or "N.G. de Bruijn" if using initials)
15:05:37 <monochrom> Well at least you have rules. English doesn't.
15:05:54 <monochrom> English is of the absurd opinion "the exception proves the rule"
15:06:06 <merijn> Reading "Something, something de Bruijn" feels like when you misjudge the number of steps on stairs
15:06:28 <merijn> monochrom: Oh, we have so many exceptions to the rules, we actually have rules for the exceptions. Then have exceptions on those, because fuck logic
15:06:33 <monochrom> I understand. I get that all the time even with just pure English.
15:06:45 <EvanR> Pure English Systems
15:07:11 <merijn> Of course the whole internet is running amok with our traditional naming scheme anyway
15:07:12 <monochrom> "There exists a monster for all people" you don't even know how to parse it.
15:07:33 <monochrom> (Oh, you do know that a parse exists.)
15:07:35 <EvanR> i object, not all binding forms are quantifying
15:08:02 <merijn> International software like Blackboard, etc. screws up everything because it has no regards for locale specific naming conventions
15:08:25 <merijn> Such as the fact that when alphabetically sorting names "De Bruijn" should go under 'B'
15:08:49 <merijn> This whole computer and internet thing was a mistake!
15:09:42 <monochrom> I suppose my IRC connection should disappear now in a puff of logic.
15:10:18 <merijn> In a slightly more haskelly issue. cabal claims to be unable to resolve my dependencies, despite my code having only 3 and I don't understand why
15:10:35 <Rembane> merijn: And you don't understand why your code only has three dependencies?
15:10:47 <merijn> (2 of those dependencies are base and stm)
15:10:49 <merijn> http://lpaste.net/352346
15:10:59 <merijn> Rembane: No, I don't understand why cabal can't figure it out
15:11:02 <Rembane> merijn: Oh.
15:11:19 <monochrom> I'm thinking I may dislike Backpack because it relies so much on the spirit of implicit parameters.
15:11:22 <Rembane> merijn: I thought I had a nice clue there for a while.
15:11:52 <merijn> I mean, can't get more trivial than this....
15:12:11 <EvanR> gotta love explicit parameters, especially in agda when youre trying to do the most basic thing in category theory
15:12:21 <EvanR> entire page of parameters 
15:12:36 <monochrom> What is "global constraint"?
15:13:28 <dcoutts> merijn: got the .cabal file ?
15:14:28 <merijn> dcoutts: http://lpaste.net/352346
15:14:29 <Boomerang> What would be simple and easy to setup Haskell package giving access to keyboard events (key presses and releases)?
15:15:11 <dcoutts> merijn: is this classic cabal, or using a sandbox, or new-build?
15:15:17 <merijn> dcoutts: sandbox
15:15:34 <dcoutts> merijn: were things installed already? e.g. vector
15:16:04 <glguy> Jello_Raptor: Did you see my message?
15:16:38 <dcoutts> merijn: it's not obvious to me why it's not tried some other versions of things. Certainly it's right that with the latest version of vector it's not going to work. You can try --max-backjumps=-1.
15:17:09 <merijn> dcoutts: I didn't install anything inside the sandbox (I just created it)
15:17:16 <dcoutts> hmm ok
15:17:23 <merijn> dcoutts: And I didn't think the global package db should be relevant?
15:17:45 <dcoutts> the global one is relevant, but the user one is not
15:18:05 <merijn> Oh, I never install global global
15:18:08 <merijn> Just user
15:18:09 <geekosaur> Boomerang, sdl2 might be the easiest
15:19:08 <merijn> dcoutts: global package db seems to only be GHC boot libs, certainly doesn't have vector
15:19:24 <merijn> dcoutts: oh, max-backjumps=-1 seems to have worked?
15:19:39 <dcoutts> merijn: so the solver reports the shortest error, which means it's not always clear what else it tried. You can explore it by using --max-backjumps=-1 and try forcing things like --constriant='vector < 0.12' etc
15:20:03 <merijn> At least, it's installing stuff and my lap is getting hot... >.>
15:20:09 <dcoutts> merijn: what cabal version btw?
15:20:20 <dcoutts> we increased the default backjumps limit at some point
15:20:32 <merijn> cabal-install 1.22.6.0 and Cabal 1.22.4.0
15:20:40 <Boomerang> Thanks geekosaur I might give that a go, any FRP library that works well with sdl2?
15:20:50 <geekosaur> that I don't knoiw
15:21:02 <dcoutts> merijn: ok, iirc it got increased in 1.24 (which also has the new-build preview/beta)
15:21:17 <geekosaur> if you want FRP you will probably be forced into whatever the FRP framework you choose wants to use, so you're doing this backwardsw
15:21:40 <merijn> dcoutts: Yeah, at some point I should probably move to GHC8 and newer cabal, but so far I've been too lazy to turn my laptop in a toaster for 3 hours rebuilding the world :p
15:22:02 <dcoutts> merijn: cabal can be upgraded independently of ghc
15:22:43 <merijn> dcoutts: Yeah, but I have ghc-mod which links with both cabal and ghc atm, so either way stuff breaks and I'd rather break it all at once :)
15:22:52 <Boomerang> geekosaur: right, I'm probably doing this backwards, but maybe FRP is overkill for my purposes anyway. Thanks!
15:23:50 <sm>  Boomerang: also gloss
15:24:05 <Boomerang> Oh yeah, that's a simple API
15:47:43 <Jello_Raptor> glguy: yup, I'm doing basically that now, it's a lot nicer than the kludge I had before 
15:49:38 <jmg8766> if ++ takes linear time? then does that mean the examples of sorts that use it are really slow? like quicksort = quicksort smaller ++ pivot ++ quicksort larger ?
15:50:07 <merijn> jmg8766: The "standard" quicksort example is pretty awful, yes
15:50:22 <merijn> jmg8766: The actual sort GHC uses is an optimised merge sort
15:50:31 <jmg8766> merijn okay I knew it thanks
15:51:13 <merijn> jmg8766: The GHC source has a bunch of comments and older sort implementations discussing performance: https://hackage.haskell.org/package/base-4.9.1.0/docs/src/Data.OldList.html#sort
15:51:36 <monochrom> With ++ linear time, I think qsort is still n log n on average.
15:52:01 <merijn> Could be, but it certainly doesn't help your constants
15:52:38 <monochrom> It's basically n log n + 3n vs n log n + 2n or something.
15:52:39 <geekosaur> worth remembering is that a lot of the "canonical" examples, including those in the Report, are tutelary in nature
15:53:08 <geekosaur> implementations are expected to match them with respect to laziness but not necessarily with respect to asymptotics
15:53:58 <monochrom> Also the optimized merge sort has the dual problem of taking linear time to cut a list into two halves.
15:54:16 <dolio> It's not that kind of merge sort.
15:54:46 <merijn> monochrom: It doesn't really bother repeatedly dividing
15:56:21 <dolio> It has to concatenate lists, though.
16:05:50 <dolio> Or rather, it has to merge them, which can involve rebuilding both lists, instead of just one.
16:06:54 <dolio> So perhaps you should consider why you'd worry about quick sort without being worried about merge sort.
16:11:37 <monochrom> Yes, my main point as well.
16:31:12 <xcmw> What is the best dom frp library?
16:31:58 <jmg8766> will (filter (<x) xs) ++ [x] ++ (filter (>=) xs) have linear time?
16:36:09 <monochrom> Yes.
16:37:04 <monochrom> reflex-dom may be a good dom frp library
16:38:42 <xcmw> monochrom: Ok. That was the one I was planing to use.
16:40:03 <monochrom> Cale uses it for work. You may like to ask him more.
16:42:27 <xcmw> monochrom: Do you how to install reflex for use with stack?
16:42:36 <monochrom> No.
17:01:57 <binary> I have a question about Data.Binary.decodeFileOrFail.
17:02:02 <binary> The code is here https://hackage.haskell.org/package/binary-0.8.4.1/docs/src/Data.Binary.html#decodeFileOrFail
17:02:17 <binary> This seems like the fastest way to go from a file to a Haskell data structure
17:02:25 <binary> My question is about the use of B.length
17:02:34 <binary> Specifically here: https://github.com/kolmodin/binary/blob/master/src/Data/Binary.hs#L226-L228
17:02:50 <binary> Why would they use B.length over B.null?
17:03:09 <binary> B.null is O(1) whereas B.length is O(n)
17:03:14 <monochrom> I don't know. I bet personal mood.
17:03:25 <monochrom> What is B?
17:03:36 <Welkin> but is it actually evaulated that way?
17:03:43 <binary> import qualified Data.ByteString as B ( hGet, length )
17:03:43 <Welkin> the result is either 0 or anything else
17:03:50 <Welkin> it's possible it is still O(1)
17:03:57 <monochrom> OK, now how do you know that B.length is O(n)?
17:04:10 <binary> Docs. One sec!
17:04:38 <binary> https://hackage.haskell.org/package/bytestring-0.10.8.1/docs/Data-ByteString-Lazy.html#v:null
17:05:12 <monochrom> Computer, is "Data.ByteString" the same as "Data.ByteString.Lazy"?
17:05:17 <binary> The only theory I have on why they'd use length is laziness
17:05:24 <monochrom> > "Data.ByteString" == "Data.ByteString.Lazy"
17:05:28 <lambdabot>  False
17:05:37 <Welkin> binary: non-strictness, you mean
17:05:47 <binary> Also, Welkin, I believe that `case` will force evaluation for the pattern match
17:05:49 <monochrom> OK, so why is the doc of Data.ByteString.Lazy relevant?
17:06:01 <binary> Oops!
17:06:20 <binary> Ahh, both are O(1) in strict!
17:06:20 <binary> https://hackage.haskell.org/package/bytestring-0.10.8.1/docs/Data-ByteString.html#v:null
17:06:56 <binary> Probably using an if is still a bit faster (saves a comparison) but not a huge deal
17:07:02 <monochrom> I was asking about B.length.
17:07:34 <monochrom> OK, you now know.
17:07:53 <monochrom> So it's just swing of mood when the author wrote it. There is insignificant difference.
17:08:12 <binary> Cool, thanks!
17:08:15 <monochrom> With that tiny difference, do not over-analyze it.
17:08:27 <binary> Nah, it's just that I found the wrong docs
17:08:54 <Welkin> but, but, they used end-of-line commas instead of beginning-of-line commas!
17:09:45 <barrucadu> The commas-at-the-start-of-the-line thing is such a weird convention I've never seen in any other language
17:09:55 <Welkin> yeah
17:09:58 <Welkin> I love it o.o
17:10:07 <barrucadu> It's great
17:10:16 <Welkin> tried it in javascript
17:10:16 <Clint> amen
17:10:18 <Welkin> got errors
17:10:46 <monochrom> There was a time commas or semicolons at the beginning helped indentation algorithms.
17:10:55 <Welkin> oh lol
17:11:08 <monochrom> I still have old code doing it in do-blocks
17:11:10 <Welkin> you reminded me of some webpage that shows C in different styles
17:11:12 <Welkin> haha
17:11:15 <Welkin> I wonder if I can find it
17:11:22 <Welkin> it shows "lisp style"
17:11:27 <Welkin> and "python style"
17:11:51 <monochrom> Like this? http://lpaste.net/311978
17:12:09 <Welkin> something like that, yeah
17:12:11 <monochrom> There was a tweet inspiring mine
17:12:53 <geekosaur> there was a webpage showing a course example of java in python style like that
17:13:10 <Welkin> geekosaur: maybe that was it?
17:13:12 <geekosaur> (with the page begging people to do something about the prof/ta...)
17:13:23 <monochrom> haha that's worse. a whole course with a teacher doing that for a dozen weeks.
17:13:56 <barrucadu> I remember a page with C written in increasingly-bizarre styles, and I'm sure it included "Peyton-Jones Style" which had leading semicolons.
17:14:29 <monochrom> I am symphathetic to that style but you really need a computer to auto-insert the {;}s because with this format you can't trust a human to do it right.
17:14:32 <Welkin> LOL
17:14:35 <Welkin> yes barrucadu 
17:14:37 <Welkin> that was it
17:14:39 <Welkin> I remember that too
17:14:43 <barrucadu> Ah, this: https://twitter.com/aisamanra/status/779057953542242304
17:14:47 <geekosaur> which, apparently, was in turn a misattribution of https://www.reddit.com/r/ProgrammerHumor/comments/2wrxyt/a_python_programmer_attempting_java/
17:15:58 <monochrom> w00t I love the one using multiple semicolon stuffers
17:16:28 <monochrom> The battle between space and tab has finally ended!
17:16:56 <Tuplanolla> How do you open the Twitter link? It's tag soup for me.
17:18:26 <monochrom> hahaha I accidentally found a tweet making a joke about intuitionistic logic.
17:18:47 <monochrom> https://twitter.com/aisamanra/status/807718428886716417
17:19:24 <monochrom> This tweeter is funny
17:35:15 <monochrom> Haha so the redditor's username is "mkdir"
17:47:55 <InHale> hi guys, I know this is the wrong channel but could someone help me with a c++ issue?  It's more logic I think so language shouldnt matter too much
17:48:10 <Lokathor> well we do love logic
17:48:17 <InHale> haha
17:48:19 <Welkin> have you tried #c++ ?
17:48:22 <InHale> ok let me paste it
17:48:29 <jle`> ask the question first and we'll see if it is suitable
17:48:29 <Lokathor> but we might tell you how to write it in Haskell instead :3
17:48:29 <InHale> yeah but I cant talk in that channe;l
17:48:37 <InHale> haha
17:48:53 <InHale> well I am checking if randomly generated numbers are prime or not and keeping a count for each
17:49:05 <glguy> Sorry, this is the wrong channel for C++ help.
17:49:20 <InHale> but I dont think I did it right because my counters are always showing the non-prime as 3
17:49:50 <Lokathor> ah, you want to use StateT possibly, sounds like there's a few values you're juggling at once
17:49:58 <monochrom> Could you rewrite it in Haskell? That might fix the bug.
17:50:09 <InHale> Lol, has to be c++
17:50:16 <Lokathor> that's the bug right there
17:50:19 <InHale> brb, laptop about to die
17:50:45 <monochrom> Use C++ to write a simple Haskell interpreter. Then you have fulfilled the requirement.
17:51:41 <jle`> write it in haskell and ask us to fix the haskell code, then translate it back into c++
17:51:45 <kgadek> or write a Haskell->C++ compiler in Haskell. Then write an assignment in Haskell, transpile and you're done
17:54:39 <Lokathor> might be easier to make a Cmm to C++ compiler?
17:55:15 <kgadek> hmm, now that I'm thinking about it, LLVM output just might be it for generating C++
17:57:43 <Lokathor> is there a LLVM -> C++ reverse translator that's any good?
17:58:53 <InHale> didnt make it to the charger lol
17:58:58 <InHale> Anyway
17:59:10 <InHale> Would anyone mind looking at the code?
17:59:22 <InHale> Or the prime checking function, rather.
17:59:41 <Lokathor> we can check any haskell version of it that you care to write
17:59:47 <kgadek> InHale: I think this is C++ question, not about logic per se
18:00:23 <monochrom> "logic" has many different meantings.
18:00:37 <monochrom> To most laypersons it just means "thinking".
18:01:10 <kgadek> anyway, InHale: did you try at ##c++ ?
18:01:28 <InHale> Yes, nobody can chat in there for some reason
18:01:50 <InHale> and Haskel was the friendliest channel I had used a little while ago so I thought someone might know C++ here
18:01:57 <monochrom> create a new channel. pm everyone there to invite.
18:02:13 <kgadek> or let's just jump to ##c++
18:02:16 <Welkin> lol really? c++ is muted?
18:02:28 <monochrom> You feel that we're great procrastinators right?
18:02:28 <InHale> I cant talk in there, and I dont see others talking
18:02:29 <kgadek> I'm there now anyway
18:02:41 <kgadek> you're not in the channel
18:02:54 <InHale> I am now
18:02:54 <kgadek> i.e. I don't see you on user list
18:03:00 <kgadek> k
18:03:02 <Lokathor> InHale, sounds like you might need to DC and reconnect to freenode
18:03:10 <Lokathor> get things cleared up
18:03:13 <InHale> It's always like that in that channel for me
18:03:29 <InHale> cannot send to channel ##c++
18:04:07 <sandonfuge> Would you guys mind telling me a good place to study Haskell?
18:04:25 <InHale> I see your text, but I can't reply lol kgadek
18:04:36 <sm> sandonfuge: where have you tried so far ?
18:04:47 <Lokathor> sandonfuge, like a physical location?
18:05:06 <sandonfuge> Sorry how do I whisper again
18:05:34 <Welkin> @where learnhaskell -- sandonfuge 
18:05:34 <lambdabot> https://github.com/bitemyapp/learnhaskell
18:05:36 <kgadek> InHale: my guess is that you're not a registered user. It's simple 
18:05:37 <kgadek> https://freenode.net/kb/answer/registration
18:05:51 <sandonfuge> I have tried "Learn you a Haskell for a great good", codewars and youtube
18:06:07 <sm> sandonfuge: how about Haskell Tutorial And Cookbook
18:06:12 <Welkin> go to the link above
18:06:20 <sandonfuge> And no I don't mean a physical location
18:07:30 <sandonfuge> I haven't tried Haskell Tutorial and Cookbook, and thanks for the link I'll check it out
18:07:35 <Lokathor> sandonfuge, http://www.seas.upenn.edu/~cis194/spring13/lectures.html this course has homeworks that are quite good at teaching you how to use haskell
18:08:34 <sandonfuge> Great! Thank you guys so much
18:08:55 <sandonfuge> It's just that no matter how much I study the language I always feel like I know nothing lol
18:09:27 <sm> don't forget to use it
18:09:29 <sm> (also)
18:09:46 <Welkin> sandonfuge: that's how it works, until you actually write a program
18:09:55 <Lokathor> consider writing some small programs, which will help you focus on things to learn with practical applications, which is usually how people remember stuff
18:10:07 <Welkin> I felt useless with it until I actually built a non-trivial web application with yesod
18:10:24 <Welkin> now it feels very natural
18:28:47 <kgadek> fyi: there is ##C++-basic. I suspect this piece of info could get handy sometimes
19:17:08 <boccato> Sry to bother, can anyone help me with this: https://gist.github.com/boccato/f9b833d7372118f121b842d1a58fcd85
19:19:45 <boccato> The test was working before I included the withTempFile line.
19:20:26 <boccato> I am not sure how I would make WaiSession an instance of MonadMask, or if this even makes sense.
19:22:49 <geekosaur> I suspect the real problem is that `shouldRespondWith` is not applying to what you think it should, and that's confusing the web framework
19:23:52 <boccato> How so?
19:23:53 <geekosaur> *possibly* this is closer to what you need: (withTempFile "." "bla.txt" $ \file _ -> delete "bla") `shouldRespondWith` 200
19:25:27 <geekosaur> because you applied shouldRespondWith to the delete operation, so it's trying to use the WaiSession as the test framework and that would be a type error. If I'm reading it correctly, that is
19:27:36 <markasoftware> is it possible to do high-performance text processing in haskell?
19:27:48 <markasoftware> for, like, 200gb of data
19:27:51 <markasoftware> faster than node or awk
19:28:10 <boccato> geekosaur: same error
19:28:14 <geekosaur> if you use Data.Text and a reasonable streaming I/O abstraction (that is, pipes or conduit), I'd expect so
19:28:48 <boccato> The code is easier to understand though, which is a win :)
19:28:54 <geekosaur> boccato, then the problem is likely that you are not in a place where you can do withTempFile
19:29:04 <geekosaur> but I don;t know enough to help with that
19:30:11 <boccato> =) thanks for trying, I think I need to understand what is MonadMask for and why is it there... but I have a feeling I am going the wrong way
19:30:51 <geekosaur> yeh, that's where I stop being able to figue out what's going on too >.>
19:32:27 <geekosaur> I presume it's part of the test framework. "mask" usually means something about exceptions, so probably it wants to restrict exceptions to the test and not have them leak into the test framework itself --- but I don't know
19:35:17 <boccato> I think the MonadMask comes from the withTempFile function.
19:35:37 <boccato> @type withTempFile
19:35:39 <lambdabot> error: Variable not in scope: withTempFile
19:37:03 <boccato> :: (MonadIO m, MonadMask m) => String -> (FilePath -> Handle -> m a) -> m a
19:38:19 <barrucadu> liftIO (withTempFile "." "bla.txt" $ \file _ -> delete "bla") `shouldRespondWith` 200 -- might work, the liftIO will force it to use IO, which is both a MonadIO and a MonadMask
19:38:36 <barrucadu> MonadMask comes from the exceptions package
19:38:55 <barrucadu> https://hackage.haskell.org/package/exceptions-0.8.3/docs/Control-Monad-Catch.html#t:MonadMask
19:43:02 <geekosaur> actually I would expect that to fail
19:43:17 <geekosaur> because yes the withTempFile will work, but now the delete is not in WAI
19:43:32 <geekosaur> it's in IO and won't work from there
19:44:11 <boccato> it fails
19:44:30 <boccato> Couldn't match type ‘WaiSession’ with ‘IO’
19:45:25 <boccato> I think the lambda should be returning an IO for this to work isn't it?
19:46:01 <geekosaur> the lambda is being run in an IO context, so it can't get at the WaiSession
19:46:16 <geekosaur> I suspect you cannot arrange for the WaiSession to be available at that point
19:46:53 <boccato> Isn't the delete creating the WaiSession?
19:53:23 <geekosaur> no, it wants to run inside one.  (getLine likewise does not "create an IO")
19:54:15 <notfed> oh this is where it's at, DANG there's a lotta people in here
19:55:35 <notfed> I'm a newb to IRC, can someone explain how there can be 100+ people in a chat room and absolutely no one talking? I must be doing it wrong.
19:56:13 <Xe> 100 clients in a room doesn't mean 100 people looking at this channel actively
19:56:36 <jle`> notfed: most of the people just idle/leave their client logged on while they do their normal stuff
19:56:44 <notfed> True enough I suppose. 
19:58:05 <boccato> This one works: https://gist.github.com/boccato/f6de52c0ae18cd31e1972f029e5064da
20:00:51 <nitrix> notfed: Another plausible explanation more specific to #haskell is that we attempt to not step on each others while we talk and also only talk when questions are asked. We have #haskell-offtopic for the noise.
20:01:38 <boccato> I don't understand the concept of running inside.
20:02:16 <dmwit> notfed: The top 10 most active people in here account for about 1/3 of all the content.
20:02:21 <boccato> As I understand, getLine returns (evaluates to) a value of the type IO String.
20:02:37 <dmwit> notfed: So it's one of those long tail sorts of things.
20:03:14 <nitrix> dmwit: 80:20 https://en.wikipedia.org/wiki/Pareto_principle ?
20:03:51 <dmwit> oh no
20:04:06 <dmwit> Way more than 80% of the activity comes from the top 20%.
20:04:26 <dmwit> 5408 nicks have been in here in the last month.
20:04:29 <nitrix> 20% of 1442 gives 288 people.
20:04:47 <Welkin> I'd probably say it's less than that
20:04:53 * nitrix agrees.
20:04:56 <Welkin> maybe 100
20:05:02 <dmwit> http://ircbrowse.net/nicks/haskell
20:05:16 <notfed> Nitrix, I was thinking perhaps no one wanted to say anything lest they change the state of the chat. 
20:05:56 <dmwit> 100% of the content in the last month came from the top 20% of nicks.
20:06:07 <nitrix> How is ertes speaking more than the bot! He must not be human.
20:06:12 <jle`> notfed: i see what you did there
20:06:12 <dmwit> 5408 nicks visited, 1102 nicks spoke
20:06:41 <Welkin> ertes has more than lambdabot lol
20:08:01 <Lokathor> https://github.com/Lokathor/scratch/blob/master/RustForHaskellUsers/Errors.md not everyone knows rust, but if I made any obvious Haskell blunders that'd be nice to know
20:09:19 <Welkin> Lokathor: looks interesting, thanks
20:09:25 <Welkin> I just started learning rust this week
20:14:11 <timbod7> Is it reasonable that lts-7.13 uses ghc-8.0.1, and yet specifies Cabal-1.24.2.0, whilst the Cabal built in to ghc-8.0.1 is Cabal-1.24.0.0?
20:15:37 <geekosaur> Cabal can in general be updated safely (few libraries packaged with the compiler can claim this) so yes, it's reasonable
20:15:43 <timbod7> When I try to build the cairo package, I get errors that indicated inconsistent Cabal versions.
20:17:09 <geekosaur> that tends to be because the Cabal linked into its Setup.hs doesn't match the one cabal/stack was built with, which only becomes an issue with Setup.hs that do complex things (cairo's does). it's a known shortcoming that both cabal-install and stack fight with; Setup.hs is a fragile place
20:18:17 <timbod7> geekosaur So that means that I can only build packages like cairo with stackage snapshots that don't override the ghc supplied cabal?
20:18:34 <timbod7> error here, by the way: http://lpaste.net/352359
20:18:36 <geekosaur> I think it has more to do with what stack *itself* is using
20:18:50 <geekosaur> but I don't understand the full interaction.
20:18:52 <nitrix> You could try: stack setup --upgrade-cabal
20:18:55 <nitrix> At your own risks.
20:20:36 <geekosaur> because stack has to communicate with Setup.hs and this communication can break down if the Cabal stack is built with and the Cabal Setup.hs gets built with don't match. stack tries to ensure Setup.hs is built with *its* Cabal instead of the one in the resolver, but this can fail if the Setup.hs also links against other packages (most of the gtk-related packages do this)
20:20:40 <geekosaur> as I understand it
20:20:52 <timbod7> nitrix looking for a manual entry... what is `stack setup --upgrade-cabal` going to do?
20:21:17 <Lokathor> down with gtk! we need to make our own pure-haskell GUI toolkit! rah rah rah!
20:21:43 <geekosaur> I think both the cabal-install and stack devs would like to see gtk disappear :)
20:22:15 <geekosaur> or at least, gtk that relies on Setup.hs that isn't a default
20:22:18 <nitrix> I indeed learned that command while playing with gtk.
20:22:44 <geekosaur> (gtk packages write out gtk bindings on the fly from Setup.hs because there are so many different gtk versions in the wild)
20:23:59 <timbod7> geekosaur I've experienced perhaps related problems, where I wanted to generate code in my adl compiler, but couldn't reliably depend on another package to provide the code generation tool.
20:24:16 <timbod7> It ended up easier to just commit the generated code to the repository.
20:24:17 <Lokathor> i tried that fltk library, it seemed okay, even on windows
20:24:29 <nitrix> timbod7: It'll upgrade the version of Cabal used by stack; possibly fixing the conflicts it has with the Setup.hs file. You can still delete the sandbox if you have no success with it.
20:24:36 <Lokathor> but the compile times are insane. The docs say that they're "large" but that's a gross understatement
20:24:55 <geekosaur> yes, but every linux distro/release has a different gtk release and every gtk release has a slightly different api
20:25:02 <timbod7> Lokathor: I'm kind of committed to gtk for now. At least the cairo library. The haskell Chart library depends on it.
20:25:21 <Lokathor> ah, well, if you're stuck with it
20:25:22 <geekosaur> gtk cares not about useless things like compatibility between releases
20:25:57 <timbod7> nitrix: thanks. Just trying that now.
20:27:35 <timbod7> sigh: need a faster computer. or a faster ghc.
20:40:29 <timbod7> nitrix That appears to have solved the problem. Thank you again!
20:40:39 <nitrix> :]
20:40:42 <aarvar> does this exist somewhere? data Foo z a = End z | Cons a (Foo z a)
20:47:36 <nitrix> The closest that I'm aware is: data NonEmpty a = a :| [a]
20:47:58 <nitrix> (Whereas the `z` parameter is missing)
20:48:49 <nitrix> aarvar: Nothing prevents you from naming your little creation :P
20:49:07 <aarvar> nitrix: naming is too hard
20:49:52 <aarvar> EndList?
20:52:34 <Lokathor> DottedList :P
20:54:36 <dmwit> aarvar: ([a], z) seems even nicer
20:54:42 <dmwit> don't have to make it all the way to the end of the list to get the z
20:56:43 <Lokathor> you haskellers and your moon magic with types
20:57:00 <Lokathor> if it's not a void* I don't know why you'd want it!
20:57:47 <nitrix> haskellToC :: Haskell -> Void
20:58:04 <nitrix> New FFI proposal.
20:58:18 <sleblanc> CType c => c -> VoidP
20:58:28 <Lokathor> Ptr ()
20:58:44 <sleblanc> excellent
20:58:56 <Lokathor> that's what sdl2 uses
20:59:04 <aarvar> dmwit: sure, but then what about something like tails?
20:59:21 <aarvar> then you end up creating a bunch of new objects
21:00:30 <dmwit> v. cheap objects
21:00:35 <aarvar> though for what I'm doing it doesn't really matter, I was just curious if that existed
21:01:12 <Lokathor> aarvar, you're already programming in Haskell. GHC already ate up all of your RAM. Gotta just go with it
21:06:33 <markasoftware> why does ghc seem so much less efficient than other compilers for other langs?
21:07:01 <Lokathor> GHC is plenty efficient
21:07:11 <aarvar> markasoftware: try scalac
21:07:20 <Lokathor> you're just asking for a lot with all that lazyness stuff
21:07:28 <markasoftware> oh god
21:07:37 <markasoftware> i mean, the outputted code is ok
21:07:42 <markasoftware> but in terms of compilation time, ram usage, etc
21:08:19 <Lokathor> oh. plenty of optimizations that are needed and all that
21:08:26 <Lokathor> you should look at rust's compiles some time
21:08:29 <timbod7> markasoftware I find recent ghc performance frustrating. But the haskell compiler is doing more work that other compilers: more sophisticated type checking, more optimisation etc etc.
21:08:45 <timbod7> So it's hard to draw a comparison really.
22:45:36 <ertes> aarvar: this one does exist:  data Foo a r = Nil r | Cons a (Foo a r)  -- note the flipped type arguments
22:45:54 <ertes> aarvar: one version of it is pipes' Producer a Identity r
22:46:04 <ertes> aarvar: another version is Free ((,) a) r
22:46:28 <ertes> and there are probably more
23:04:02 <mniip> hmm
23:04:07 <mniip> all types are profunctors
23:07:09 <c_wraith> in what category?
23:07:53 <mniip> Hask^op x Hask -> Hask, I believe
23:08:15 <mniip> maybe something more interesting in presence of HKTs
23:08:52 <c_wraith> Err.  I don't think types are even objects in that category
23:08:58 <mniip> well
23:09:14 <mniip> (Hask^n)^op x Hask^n -> Hask
23:09:23 <mniip> where n is the number of free variables in the type
23:12:19 <mniip> e.g
23:12:34 <ertes> mniip: so Bool : 1^op × 1 -> Hask?
23:12:48 <mniip> yeah
23:13:02 <mniip> namely the profunctor that selects Bool
23:13:09 <ertes> let 2 = 1 + 1  -- how many free variables?
23:13:10 <mniip> I'm talking about things more like
23:13:33 <mniip> [a] would be the profunctor \(X', X) -> List(X)
23:13:50 <mniip> and then forall a. [a]  would be the end (over X) of that
23:13:56 <mniip> and that end is isomorphic to ()
23:13:58 <ertes> do you really mean free variables?
23:15:53 <ertes> data Bool2 = True2 () | False2 ()  -- is that one or two free variables?
23:16:11 <mniip> 0
23:16:34 <ertes> and [] has one?
23:16:39 <mniip> :t []
23:16:42 <lambdabot> [t]
23:16:51 <ertes> [], the type
23:17:00 <mniip> [] isn't a concrete type
23:17:09 <ertes> ah, now i see what you mean
23:17:25 <mniip> I mean types with free variables
23:17:31 <mniip> can be represented with profunctors
23:17:36 <mniip> and then forall-bindings are just ends
23:17:49 <ertes> so Either a b : (Hask^2)^op × Hask^2 -> Hask
23:17:54 <mniip> yes
23:18:24 <ertes> yeah, now it makes sense…  not sure if it's an actual profunctor, but i get the idea =)
23:18:59 <mniip> everything is a profunctor
23:19:48 <mniip> the datatype P a = P (F a) (G a)
23:20:12 <mniip> is \(A', A) -> (F(A', A), G(A', A))
23:20:28 <mniip> S a = L (F a) | R (G a)
23:20:43 <mniip> is \(A', A) -> F(A', A) + G(A', A)
23:20:51 <mniip> H a = H (F a -> G a)
23:21:05 <mniip> is \(A', A) -> Hom(F(A, A'), G(A', A))
23:21:13 <mniip> note the flipped arguments
23:21:42 <mniip> oh yeah
23:21:48 <mniip> Identity = \(A', A) -> A
23:21:55 <lyxia> (->) a b ?
23:22:43 <ertes> \((A', B'), (A, B)) -> Hom(A, B)?
23:22:49 <lyxia> oh I can deduce it with F c = a, G c = b...
23:23:19 <mniip> Hom(A', B)
23:23:48 <mniip> the intuition is that every free variable gets 2 arguments: one for contravariant appearances and the other for covariant
23:24:22 <lyxia> Yeah.
23:24:32 <mniip> then
23:24:47 <mniip> forall a. F a   ->   End_A F(A, A)
23:27:46 <aluminumtubes> what's the difference between a = ((<) 3) and a = (< 3) ?
23:28:05 <mniip> (< 3) is \x -> x < 3
23:28:06 <ertes> aluminumtubes: (< 3) = \x -> x < 3
23:28:21 <mniip> ((<) 3) is \x -> (<) 3 x
23:28:23 <mniip> aka 3 < x
23:28:46 <mniip> compare with
23:28:50 <mniip> > (/ 2) 5
23:28:51 <ertes> aluminumtubes: just like (3 /) is dividing 3 by, and (/ 3) is dividing by 3
23:28:53 <lambdabot>  2.5
23:28:54 <ertes> hehe
23:28:55 <mniip> > ((/) 2) 5
23:28:58 <lambdabot>  0.4
23:29:48 <lyxia> > let a = ((<) 3) in [(b, a b) | b <- [2.5, 2.6 .. 3.5]]
23:29:50 <lambdabot>  [(2.5,False),(2.6,False),(2.7,False),(2.8000000000000003,False),(2.900000000...
23:29:55 <lyxia> pffff
23:30:12 <ertes> > let a = ((<) 3) in [(b, a b) | b <- [2.5, 2.75 .. 3.5]]
23:30:14 <lambdabot>  [(2.5,False),(2.75,False),(3.0,False),(3.25,True),(3.5,True)]
23:30:42 <aluminumtubes> cool
23:30:49 <aluminumtubes> thanks you guys are awesome
23:31:14 <ertes> use rationals with a power-of-2 denominator to avoid rounding errors
23:54:47 <lyxia> What should I use to generate Haskell code? haskell-src? what if I want haskell2010/GHC-haskell?
23:55:16 <lyxia> Can template haskell generate whole modules?
23:56:26 <systadmin> hey
23:57:44 <c_wraith> template haskell doesn't have the ability to generate imports or module declarations, so it doesn't sound like what you want
23:58:53 <lyxia> Okay, that's what I thought.
