00:00:11 <jchia1> cocreature: First time I'm actually going to use Typeable in anger.
00:01:25 <cocreature> jchia1: does a “closed GADT” not work for you? i.e. instead of providing Max1 which works for arbitrary a, make a Max1Int and a Max1Bool or whatever you need
00:01:32 <cocreature> then you can get away without typeable
00:02:42 <jchia1> cocreature: I actually want it to be closed. I only have Value Bool, Value Double and Value Md. Is that what you mean by closed?
00:02:48 <jchia1> How do I express that?
00:02:57 <cocreature> jchia1: what is Max1 supposed to do?
00:03:08 <cocreature> and yes that’s what I mean by closed
00:03:19 <jchia1> max of some literal (Double) and a (Value Double) to get a Value Bool
00:03:25 <jchia1> I mean to get a Value Double
00:03:43 <cocreature> jchia1: ok, can you do a Max1Bool, Max1Double and a Max1Md?
00:04:09 <jchia1> Then I can get rid of the a -- is that the point of the separation?
00:04:36 <jgt> ah… I figured it out. I actually wanted `fmap (fmap encodeUtf8) [(...`
00:05:13 <cocreature> or alternatively make a GADT "data Literal a where BoolLiteral :: Bool -> Literal Bool; DoubleLiteral :: Double -> Literal Double; MdLiteral :: Md -> Literal MD" and change max1 to "Max1 :: Literal a -> Value a -> Value a"
00:06:20 <cocreature> jchia1: yep, it won’t remove the boilerplate but you can get rid of Typeable and all the other constraints since you can now figure out if for a given "Value a" and "Value b" a and b are equal simply by pattern matching on the constructors
00:07:31 <jchia1> cocreature: I'm OK with Typeable. Is there any downside I need to be aware of, like typically poor performance?
00:07:37 <cocreature> jchia1: basically, GADTs work best if you can recover the concrete types of type parameters by pattern matching
00:08:33 <cocreature> jchia1: it’s not so much Typeable as it is existentials in general. you end up having to shove more and more constraints on things and it all becomes kind of ugly
00:09:39 <cocreature> and if you only want to have Value Bool, Value Double and Value Md, simply expressing that in the definition of Value seems like a good idea
00:11:10 <jchia1> cocreature: OK. I'm actually currently more concerned about not being able to derive Eq.
00:12:18 <cocreature> I don’t think using the limits of GHC’s deriving mechanism as guidance for how you should write your types is a good idea
00:14:37 <jchia1> cocreature: The code becomes very long and my manually-written boilerplate can have errors. I'm mostly done with the code other than adding new items to the GADT.
00:15:27 <cocreature> fair enough, I give up :)
00:32:27 <saurabhn_> dmj`: it was something stupid I was doing, amplified by the runtime error not showing up anywhere
00:32:46 <dmj`> saurabhn_: did it get resolved?
00:32:58 <saurabhn_> dmj`: yes.
00:33:10 <dmj`> saurabhn_: oh good :)
00:33:29 <saurabhn_> dmj`: the default error handling of async is pretty bad. If the thread throws a runtime error, it doesn't show up **anywhere**
00:33:54 <saurabhn_> even if you're on GHCi, it doesn't show-up on the STDOUT or STDERR
00:35:22 <dmj`> hmm
00:35:24 <dmj`> in ghci
00:35:25 <dmj`>  Left d <- waitCatch =<< async (error "foo")
00:35:40 <dmj`> It gets caught
00:35:46 <merijn> saurabhn_: async can only sensibly report errors if you wait on it's results
00:37:31 <saurabhn_> dmj`: in my finalizer, I was doing something that led to a runtime error. And it all went into a black-hole.
00:40:16 <ogrady> Is there a sensible signature for a commutative, associative dyadic function?
00:41:54 <saurabhn_> ogrady: what's the use-case?
00:43:17 <ogrady> saurabhn_: nothing in particular, really. I just want to have a datatype that encapsulates a function (a -> a -> a) and I'd like to make sure that it is commutative and associative. I was wondering whether that is expressible via signature.
00:49:25 <mud> ogrady: Haskell's type system doesn't really know how to encode that. The usual way to do it would be with a typeclass, perhaps, but haskell won't know what that means either, it'll just be documentation really
00:49:47 <ogrady> mud: okay, I can go with that. Thank you. :)
01:22:31 <eikke> would anyone have a clue why hsc2hs isn't expanding '#const NAME' clauses?
01:24:52 <saurabhn_> what does ghc use clang for?
01:25:12 <saurabhn_> and can stack do parallel builds? this thing is too damn slow...
01:25:14 <merijn> saurabhn_: linking and preprocessing, probably?
01:25:34 <merijn> Assuming clang is your system linker
01:26:09 <ertes-w> ello
01:26:42 <saurabhn_> ghc is using 4 threads while doing a stack build on my 4-core machine. Does it mean it's compiling at full paralllisation anyways?
01:26:56 <ertes-w> dmj`: do you find it surprising that it gets caught?
01:27:14 <saurabhn_> 7mins of CPU time and counting...
01:27:40 <dmj`> ertes-w: no
01:27:48 <saurabhn_> will building in docker be significantly slower than on bare metal?
01:28:05 <ertes-w> i just joined, so i may lack context
01:29:29 <supercynic> saurabhn_: no, should be barely measurable
01:29:48 <supercynic> unless you use docker on one of those platforms, where it has to fire up VMs
01:30:17 <saurabhn_> setting up our deployment pipeline now. Build locally on dev machines in docker and rsync the build artefacts to production servers.
01:31:00 <saurabhn_> 10m CPU time and counting... why is this taking so long? slower than building an Android app... and I lost my shit when I was building our Android app last time around.
01:31:31 <MarcelineVQ> got any large records?
01:31:42 <supercynic> saurabhn_: does it take longer than on the host system?
01:31:46 <saurabhn_> MarcelineVQ: got TONNES of records.
01:31:51 <saurabhn_> and TONNES of lenses.
01:32:23 <merijn> saurabhn_: Are you generating those lenses via Template Haskell?
01:32:38 <tdammers> saurabhn_: if you have record types with lots of fields, then you may be hitting an edge case for which ghc is insanely slow
01:32:42 <saurabhn_> 105 records (mapped to DB tables) with 599 unique column names amongst them.
01:32:50 <saurabhn_> merijn: nope -- code-gen FTW.
01:33:27 <tdammers> saurabhn_: compiling a source file that has only a data type with 500 fields in it, no dependencies, currently takes about 30 seconds on my machine
01:33:28 <saurabhn_> btw, loading in GHCi via -fobject-code is **much** faster
01:33:44 <saurabhn_> I have a feeling this is the linking step that is taking so long...
01:33:47 <saurabhn_> any way to confirm?
01:33:56 <supercynic> saurabhn_: yes, look at the output
01:33:59 <eikke> saurabhn_: check in 'ps' whether the linker is running? :)
01:34:00 <merijn> saurabhn_: Which linker does your system have?
01:34:14 <saurabhn_> STUCK AT ==> 2017-10-17 13:48:22.072691: [debug] Run process: /Users/saurabhnanda/.stack/setup-exe-cache/x86_64-osx/Cabal-simple_mPHDZzAJ_1.24.2.0_ghc-8.0.2 --builddir=.stack-work/dist/x86_64-osx/Cabal-1.24.2.0 build lib:webservice exe:webservice-exe --ghc-options " -ddump-hi -ddump-to-file" 
01:34:30 <merijn> saurabhn_: The default linker on many linux systems is notoriously shit (unless your distro switched to gold)
01:34:38 <supercynic> saurabhn_: if your docker is set up properly you can do 'docker logs -f NAME'
01:34:39 <saurabhn_> on Mac OSX
01:34:58 <saurabhn_> clang would be the linker on Mac OSX? It's not running. 
01:35:29 <saurabhn_> https://www.dropbox.com/s/holdumds4d25ecn/Screenshot%202017-10-17%2014.05.02.png?dl=0
01:37:08 <saurabhn_> any way to make stack/ghc/cabal output some stats, about what took so long?
01:37:12 <geekosaur> clang would be used to launch the system linker (so you also get the C runtime and shared object glue), and also to compile FFI stubs
01:37:21 <saurabhn_> what **is taking** so long... still not finished!
01:37:24 <supercynic> saurabhn_: are you ignoring me?
01:37:33 <saurabhn_> supercynic: no... I missed your comment.
01:37:40 <supercynic> *comments
01:37:47 <saurabhn_> supercynic: I'm not on docker yet. first running on bare metla./
01:38:09 <saurabhn_> supercynic: and this was for you ---> STUCK AT ==> 2017-10-17 13:48:22.072691: [debug] Run process: /Users/saurabhnanda/.stack/setup-exe-cache/x86_64-osx/Cabal-simple_mPHDZzAJ_1.24.2.0_ghc-8.0.2 --builddir=.stack-work/dist/x86_64-osx/Cabal-1.24.2.0 build lib:webservice exe:webservice-exe --ghc-options " -ddump-hi -ddump-to-file"
01:38:14 <supercynic> ah…  in that case look at the output…  if it's stuck on a module, then the records might be your problem
01:38:49 <saurabhn_> doing a :l of Main on GHCi is **much** faster than this. The only difference is I've gone from -O0 to -O2
01:39:24 <saurabhn_> 17min CPU time and counting... I hope it comes under 25mins. That's the time taken for our Rails test-suite to run end-to-end!
01:39:25 <geekosaur> I don;t think you will see much about what;s going on unless you can pass -v3 to ghc
01:39:31 <supercynic> saurabhn_: -fobject-code is not quite the same as native object compilation (i.e. "what 'ghc' does")
01:39:48 <saurabhn_> geekosaur: how to do that via stack?
01:39:50 <geekosaur> or turn on all the -ddump-* options and infer its current action by what dump files got created
01:40:37 <saurabhn_> could -O2 be doing this? Is there a separate optimisation pass that can be instrumented and benchmarked?
01:40:37 <geekosaur> I don't use stack but stack "should" relay any -v options through, as well as itself becoming more verbose
01:40:40 <eikke> saurabhn_: pass --ghc-options ... to stack
01:40:55 <MarcelineVQ> -ddump-to-file used to be on by default and probably still is, annoyingly actually since ghc doesn't have a  -dno-dump-to-file
01:41:01 <supercynic> saurabhn_: for the most part -O2 is like -O, except that it takes much much longer
01:41:11 <saurabhn_> COMPLETED:      1384.97 real      1232.77 user        93.36 sys 
01:41:13 <supercynic> saurabhn_: the default is -O alias -O1
01:41:20 <supercynic> (cabal's default that is)
01:41:43 <supercynic> you should go with that one, unless you really have a reason to use -O2
01:41:57 <supercynic> and even then -O2 is probably best used on individual modules
01:42:01 <saurabhn_> supercynic: production builds should be optimised, no?
01:42:02 <geekosaur> fwiw it's generally recommended no to use -O2 unless you actually need the optimizations it does; it's much slower, and the optimizations aren't always optimizations
01:42:10 <supercynic> saurabhn_: -O is optimised
01:42:14 <supercynic> -O0 isn't
01:42:18 <geekosaur> -O1 is reocmmended for production
01:42:21 <geekosaur> and -O is -O1
01:42:22 <saurabhn_> so, -O1 == -O ?
01:42:52 <supercynic> saurabhn_: yeah, ideally just don't set optimisation levels at all and let cabal handle it
01:43:14 <saurabhn_> what?! Where is this documented? And one would just **assume** that higher level of optimisations would make the code faster at the cost of compile times. If -O2 does something completely different it should be a different flag!
01:43:35 <nano-> jle`: I finally have something that compiles and emits something I can work with, can I simplify this some way? http://cf15d6698cb258bc.paste.se/
01:43:56 <supercynic> saurabhn_: no, -O2 just enables the more expensive optimisations, and the effect will be negligible on most code
01:44:07 <supercynic> saurabhn_: that's why -O1 is the default
01:44:09 <merijn> saurabhn_: It doesn't do something completely different. It's just that higher levels of optimisations aren't guaranteed to be noticable
01:44:10 <MarcelineVQ> saurabhn_: the list of things -O* deals with are here https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html#o-convenient-packages-of-optimisation-flags
01:44:13 <geekosaur> ok, looks like they may have cleaned up -O2 so it no longer enables  the risky ones
01:44:22 <geekosaur> as documented at that link
01:44:32 <saurabhn_> 23 minutes for an -O2 build. Let's try with -O1 now.
01:44:32 <geekosaur> it used to enable some other things that could make things worse sometimes
01:45:10 <MarcelineVQ> be sure to stack clean --full  if you want to be scientific about the timing
01:45:38 <saurabhn_> Awesome :) == "We don’t use a -O* flag for day-to-day work. We use -O to get respectable speed; e.g., when we want to measure something. When we want to go for broke, we tend to use -O2 (and we go for lots of coffee breaks)."
01:45:57 <saurabhn_> --full will nuke the package db as well, MarcelineVQ?
01:46:35 <MarcelineVQ> depends what you mean by package db, it'll nuke the .stack-work dir of the current project
01:46:52 <saurabhn_> okay. Trying with -O
01:47:43 <saurabhn_> I have forked the airbrake package locally, but stack somehow loves checking it for changes and probably recompiling it. How do I make it stop doing that?
01:48:18 <MarcelineVQ> dunno, I used to have that problem with git entries in my stack.yaml
01:48:33 <MarcelineVQ> you have  extra-dep: true  set for it yes?
01:48:34 <saurabhn_> MarcelineVQ: yes, it's a git entry
01:48:39 <supercynic> saurabhn_: one option would be to work with git worktrees
01:48:41 <saurabhn_> MarcelineVQ: yes, it's set to "yes"
01:48:56 <MarcelineVQ> does yes mean true in yaml?
01:48:58 <supercynic> saurabhn_: make a separate worktree for references
01:49:27 <saurabhn_> sorry, set to "true"
01:49:48 <saurabhn_> but is it expected from stack? to keep checking local-deps for changes over & over again?
01:49:49 <MarcelineVQ> I've not used git entries in a bit so idk if that's a solved issue
01:50:40 <MarcelineVQ> sure, it should check, but it shouldn't rebuild them if there aren't changes.
01:51:25 <saurabhn_> okay... waiting for -O build to finish.... 3m 30s and counting...
01:54:33 <supercynic> "how may i help?" – "i'd like to order more compute resources from the cloud" – "sure, how much?" – "the rest" – "oh, compiling haskell again?"
01:56:03 <eikke> saurabhn_: are you deriving Generic instances for those records?
01:56:25 <merijn> @quote this.bug.cost
01:56:25 <lambdabot> SimonMarlow says: This is the largest program (in terms of memory requirements) I've ever seen anyone run using GHC.  In fact there was no machine in our building capable of running it, I had to
01:56:25 <lambdabot> fire up the largest Amazon EC2 instance available (68GB) to debug it - this bug cost me $26.
01:57:17 <MarcelineVQ> saurabhn_: I should mention that rebuiding the git entries is expected after a stack clean --full because .stack-work is where a project pulls git things to
01:57:48 <etiago> use Haskell, they said. the type system will avoid bugs, they said...
01:58:00 <geekosaur> someone lied to you...
01:58:40 <geekosaur> (type system helps, but a type system that would actually prevent bugs (a) is more work than is worth it (b) quite likely impossible in most cases anyway (ohai typechecking halting problem)
01:59:23 <ventonegro> https://pbs.twimg.com/media/DCV46-aXUAEOnqf.jpg
01:59:23 <fakenullie> can't we just settle that after X steps typecheck should just fail
02:00:51 <saurabhn_> 12min and counting
02:01:01 <eikke> saurabhn_: are you deriving Generic instances for those records?
02:01:24 <saurabhn_> eikke: yup... deriving Eq, Show, Generic is like muscle memory for me.
02:01:51 <supercynic> type *checking* is kinda the least interesting feature of a powerful type system
02:02:00 <eikke> saurabhn_: if you don't really need Generic, remove that, can cause quite some build time inflation. Eq/Show maybe, but those are more likely to be required
02:03:26 <saurabhn_> eikke: almost every record uses ToJSON/FromJSON and ToSchema/FromSchema... so, they are required. Unless I switch to TH for ToJSON/FromJSON, which will add a lot of TH and will again slow-down the build. Basically GHC is dead-slow. There is no denying that. Question is, who is doing what about it? And how can we help?
02:04:16 <saurabhn_> might as well watch something on Netflix in the meantime...
02:05:59 <eikke> saurabhn_: TH may be faster than using Generic I think, because less 'values' will be generated
02:07:19 <saurabhn_> 18m (-01) vs 23m (-02)
02:08:58 <saurabhn_> does anyone know how long Serva (on Rust) take to compile?
02:13:18 <merijn> saurabhn_: GHC's implementation of deriving is dead slow, so lots of (large) datatypes with lots of deriving is going to kill your compiletime
02:14:22 <saurabhn_> and also run-time?
02:15:09 <saurabhn_> 6m (-O0) vs 18m (-O1) vs 23m (-O2)
02:15:16 <saurabhn_> is Generics the culprit here, or the opimiser?
02:15:33 <merijn> Both?
02:15:59 <saurabhn_> don't have the correct mental model of what the compiler's doing. Could you explain?
02:16:13 <merijn> I don't know your codebase, so I'm just guessing
02:16:24 <Athas> The performance of the optimiser is heavily dependent on the amount of code, and deriving generates large amounts of code.
02:16:37 <saurabhn_> deriving Generics doesn't have anything to do with the optimisation level, right?
02:16:54 <merijn> saurabhn_: See Athas' remark
02:17:07 <saurabhn_> yes, just saw.... human concurrency issue 
02:17:22 <ventonegro> Deriving is GHC's C++ templates
02:18:08 <saurabhn_> hmmm... is there no pass which eliminated dead code **before** it optimises? In this case, if a Generics class is not being used, it can be thrown away?
02:18:28 <merijn> saurabhn_: No, because other libraries might use it
02:18:28 <geekosaur> instances are global so it can;t know it's dead
02:18:34 <eikke> saurabhn_: how can the compiler know wheter an instance is 'used'? Instances are open
02:19:12 <Athas> Welcome to a land called Typeclasses. *whipcrack*
02:19:16 <saurabhn_> ummm, compiling a binary. It's the very end of the compile-chain.
02:19:29 <eikke> saurabhn_: compilation is per-module
02:19:49 <Athas> The optimiser doesn't know whether you are compiling a library or an executable.
02:20:07 <saurabhn_> can it take that into account as an additional arg?
02:20:17 <saurabhn_> I know it's not there today, but is it technically possible?
02:20:20 <Athas> No.  I don't think there is a technical reason for this restriction.
02:20:25 <ventonegro> You may have noticed GHC-compiled programs are huge...
02:20:35 <merijn> ventonegro: They're not that huge, tbh
02:20:37 <Athas> It might be hard to make it work reliably for multi-module programs, unless you did whole-program compilation.
02:20:52 <ventonegro> merijn: Do you even pandoc?
02:20:55 <Athas> merijn: my Haskell program is a 37MiB binary.
02:21:05 <merijn> Athas: Compared to similar statically linked C++ programs
02:21:09 <saurabhn_> Athas: how man loc and how many modules?
02:21:09 <Athas> That's for 48000 SLOC of Haskell, and not many libraries.
02:21:16 <Athas> Little less than 200 modules.
02:21:21 <Boomerang> Is there a way to represent a Float (or other approximation of real numbers) at the type level? The same way we have type level Nats. If it is not possible, why is that the case?
02:21:31 <saurabhn_> Athas: counted via cloc?
02:21:37 <Athas> saurabhn_: yes.
02:21:37 <merijn> If we're comparing statically linked GHC programs with dynamically linked C that's a lame ass comparison
02:22:19 <saurabhn_> 1,232 Haskell files & 28,500 LOC. Taking 18m to build with -O1
02:22:28 <geekosaur> Boomerang, because you really do not want the typechecker dealing with the fuzzy equality needed for IEEE floats
02:22:39 <merijn> Boomerang: It's not possible yet, afaik. And the reason why is that float's are pain in the ass and no one could be arsed with that in the typechecker
02:23:08 <Boomerang> geekosaur: Right it would be a pain indeed. Maybe I should go for a rational representation then?
02:23:22 <MarcelineVQ> the question follows as well, what is the advantage of floats as type indexes
02:23:29 <geekosaur> and if you don;t use IEEE floats... well, the other discussion here is already about slow typechecking. CReal type level floats would make it even slower
02:23:41 <saurabhn_> Okay... this is now a major problem. With Rails it took 25mins to run testing end-to-end. With Haskell (and it's just a single feature developed in haskell right now), it's taking 18-23mins to get the build out!
02:23:50 <geekosaur> Rats could work but someone'd have to impleent it
02:23:54 <saurabhn_> what happens in the next build?
02:23:55 <ski> (unification of rational numbers ?)
02:24:08 <ventonegro> merijn: GHC programs still link dynamically to libc, so I don't know what you are talking about
02:24:11 <Athas> merijn: so what would be a fair comparison?  What about Go executables?  They are statically linked.
02:24:17 <geekosaur> if you're the one who wants it, you'd prbably have to contribute the implementation. ther's too few ghc devs for random user requests
02:24:29 <merijn> ventonegro: All Haskell libraries are linked static by default
02:24:34 <Athas> I thought that GHC was widely recognised as generating large executables.
02:24:39 <MarcelineVQ> saurabhn_: it might help you work on seperation of concerns, but a route to try that has been suggested is trying TH instead of Generics and see if that helps at all
02:24:43 <ventonegro> Athas: it is
02:24:45 <geekosaur> ventonegro, Haskell libraries default to static, for good reasons
02:24:48 <merijn> ventonegro: C libs are linked dynamically, sure
02:25:17 <saurabhn_> MarcelineVQ: what would be the easiest way to do that across the app? Regex-replace?
02:25:22 <geekosaur> (go take a look at the mess on arch, for one. then consider that you cannot reuse a shared library *and* get the runtime speedups from cross-module inlining, which exposes private parts of your API)
02:25:27 <merijn> Athas: I'm not arguing they're *small*, but I don't think they're particularly huge either
02:25:36 <ventonegro> Athas: Pandoc is 60MB here on my machine, and it's a console application
02:25:37 <MarcelineVQ> I've no idea how best to edit your codebase saurabhn_ :X
02:26:00 <saurabhn_> I was hoping for some super-secret -- -XDeriveGenericsViaTH flag :)
02:26:00 <merijn> ventonegro: "it's a console application" <- wtf does that even mean? Postgres is arguably a console application too...
02:26:24 <merijn> Why would console applications be small? Especially one as complex and big as pandoc
02:26:37 <ventonegro> merijn: GUI libraries are usually huge
02:26:57 <saurabhn_> btw, generally, how much speed-up can one expected in -O0 vs -O1?
02:27:58 <eikke> saurabhn_: the idea is not to derive Generic through TH, but not to derive Generic and use TH to create your from/toJSON instances
02:28:42 <Athas> Xlib was one of the original motivations behind dynamic linking.
02:28:48 <eikke> saurabhn_: also, if I'm not mistaken you said before your module is code-gen'ed, so changing the codegen to make that change should be feasible ;)
02:29:04 <saurabhn_> hmm, so drop Generics completely. How come people spew so much hate on TH, when it is the only viable real-world option out there? Why not just make it easier and better to use than to keep inventing new complicated type-level stuff?
02:29:20 <ventonegro> Athas: There is the `-fsplit-objs` workaround, but it makes linking take much more time and memory
02:29:21 <saurabhn_> eikke: yes, if the TH idea works, that's what I'm going to do...
02:29:35 <saurabhn_> I just with something like lisp macros were there in Haskell. Life would be so much more simpler.
02:29:51 <Athas> saurabhn_: people spew hate because *none* of the solutions are particularly nice.
02:30:01 <Athas> TH probably works the best, but it is an ugly solution by most measures.
02:30:19 <merijn> Athas: I actually like (Typed) Template Haskell, tbh
02:30:20 <saurabhn_> is it conceptually ugly or is the UX around it ugly?
02:30:20 <Athas> It's just a deficiency in the language.
02:30:33 <Athas> saurabhn_: both.  For me, the conceptual uglyness is worst.
02:30:36 <merijn> Athas: I wish GHC/TTH had better support for staged compilation
02:30:43 <MarcelineVQ> I like TH ehe
02:30:49 <Athas> merijn: I find it _way_ too complicated.  Something is utterly wrong once we reach that stage.
02:31:00 <ventonegro> saurabhn_: http://docs.racket-lang.org/hackett/index.html :)
02:31:00 <merijn> Athas: What's wrong with staged compilation?
02:31:03 <saurabhn_> Athas: what's conceptually wrong with TH? You don't like lisp macros as well?
02:31:20 <Athas> I dislike TH because it would be quite hard to put in a language specification, and very hard to implement in another compiler.
02:31:25 <geekosaur> I suspect what's not liked is that you cant make the AST look like the surface language like you can in Lisp
02:31:32 <Athas> saurabhn_: Lisp macros are conceptually simpler.  And fit Lisp better than TH fits Haskell.
02:31:36 <geekosaur> and yes, it's inherently going to be compiler specific
02:31:50 <Athas> I like languages that are languages, and not just the input format for a specific compiler.
02:31:58 <saurabhn_> ventonegro: have seen that... 6-8 months ago I was having the same existential crisis myself. Isn't the type-system just another Lisp?
02:32:04 <tdammers> I think the main complaint with TH is that it obscures code
02:32:06 <Athas> But I also like to write programs, so here I am, using (a little!) TH in my own code...
02:32:29 <ski> (s/just another Lisp/just another Prolog/ might be more sensible ?)
02:32:31 <ventonegro> saurabhn_: The typechecker is implemented in the macro system
02:32:49 <tdammers> just look at Yesod... in order to navigate a sufficiently complex yesod project, you need to memorize the rules by which the yesod-specific TH generates functions and data types, otherwise you simply won't find the definitions
02:32:55 <saurabhn_> right now, every time I've reached out for the super-sexy hyped up type extension, ultimately it turns out code-gen/TH would've been better.
02:33:12 <tdammers> you get those weird situations where you encounter an identifier for which grep gives absolutely no matches other than the usage you are looking at
02:33:21 <ventonegro> saurabhn_: It's based on a recent paper... It's in my queue to implement the techniques for fun some day
02:33:23 <saurabhn_> tdammers: actually that's a tooling problem. 
02:33:39 <merijn> saurabhn_: Who is hyping all these type extensions to you?
02:33:51 <Athas> saurabhn_: code generation is definitely a super pragmatic solution.  That's why you see it in all kinds of languages.  TH is just built into the compiler.
02:33:56 <saurabhn_> tdammers: a sufficiently smart IDE (non-existent in Haskell), should be able to tell you which splice an identifier is coming from, and macro-expand it inline for you.
02:34:08 <Athas> saurabhn_: pretty sure that's undecidable.
02:34:09 <merijn> saurabhn_: Maybe you should just stop listening to people hyping experimental/new tools to you
02:34:11 <Athas> TH is Turing-complete.
02:34:16 <tdammers> saurabhn_: maybe so, but a tool that would solve this would have to compile the code at least to the point where the TH can be run, and then run the TH
02:34:24 <merijn> Athas: Yet another reason to kill Turing-completeness!
02:34:53 <Athas> I hope the Racket crowd will eventually figure out a way to do language-integrated code generation that is conceptually simple and sufficiently powerful.
02:34:55 <ski> (with hygienic macros, a macro expansion can't introduce identifiers not explicitly mentioned in the macro call)
02:35:12 <saurabhn_> is **anyone** solving these day-to-day problems in Haskell, at all?!
02:35:31 <tdammers> yes
02:35:31 <Athas> Everyone has different day-to-day problems.
02:35:45 <MarcelineVQ> there's a whole channel of people doing that saurabhn_ #ghc
02:35:48 <Athas> My day-to-day problems don't involve much boilerplate, so I generate very little code.
02:35:52 <saurabhn_> tdammers: which is probably again a tooling problem... GHC doesn't have Java-like partial compilation, does it?
02:35:54 <tdammers> the solution to the TH problem is to use TH sparingly, and prefer other abstractions where possible
02:35:56 <MarcelineVQ> not the editor problem, that's a different channel
02:35:59 <merijn> saurabhn_: Yes, by not using all these "super sexy & hyped" extensions
02:36:22 <tdammers> Haskell has this culture of being a language that doesn't rely on tooling a lot
02:36:34 <tdammers> and I really really like that
02:37:09 <tdammers> I can comfortably do production-quality work on a Haskell codebase with just a command line, a vanilla vim setup, and unix coreutils
02:37:19 <saurabhn_> back to the priblem at hand... time for a dockerized build.
02:37:58 <tdammers> this is also important because it means I get to pick whichever tools I want, and my teammates can pick radically different tools, and we won't have any problems whatsoever
02:38:19 <tdammers> all the stuff that matters is embedded in the code itself, and you can get it out with minimal tooling
02:38:59 <Athas> I like that aspect of Haskell too.
02:39:13 <Athas> Although it's a bit of a workaround for the fact that what tooling exists is pretty poor.
02:39:18 <saurabhn_> tdammers: yeah... I'm long past that individualistic approach. I'd rather have standardised tooling on steroids to push dev productivity. I **used** to be like that back in my Gnu/Linux / Church of Emacs days... but it's not worth my time any more.
02:39:22 <Athas> Haskell does not seem to be an easy language to write tools for.
02:39:38 <tdammers> Athas: I think it cuts both ways - Haskell has little tooling because the need isn't as pressing
02:39:41 <merijn> Athas: I think writing tools isn't harder than other languages
02:39:48 <merijn> Athas: It's just no one's getting paid to write tooling
02:39:57 <tdammers> and indeed, writing tools isn't harder, there's just a lot less pressure to actually do it
02:40:01 <merijn> Athas: And all people capable of doing so are already plenty busy so don't invest the time
02:40:16 <saurabhn_> I've been thinking about this for so long... would a kick-starter with sufficient money on the table make a difference?
02:40:16 <Athas> merijn: then how come haskell-mode/GHCI is so much worse than SLIME for Common Lisp?  The Haskell community is larger and much more vibrant.
02:40:37 <Athas> saurabhn_: there are already commercial companies slowly working on building tooling.  Just give them time.
02:40:46 <merijn> Athas: Well, how many people maintain haskell-mode? 0.5 on a good day?
02:40:49 <tdammers> Athas: same effect. In Lisp, the interactive development environment *has* to be good, because it's the only thing you have
02:40:51 <eikke> saurabhn_: a Kickstarter doesn't magically create qualified devs ;)
02:40:52 <Athas> We have stack and intero now, which is much better than it used to be.
02:40:59 <merijn> Athas: Lisp people seem far more willing to maintain/contribute stuff
02:41:01 <Athas> merijn: it's not like SLIME has/had an industrial team behind it.
02:41:07 <tdammers> Athas: in Haskell, we can offload 80% of what you'd do in a REPL in Lisp to the type checker
02:41:07 <madknight> Athas, never heard about SLIME what is it?
02:41:22 <saurabhn_> wouldn't FP Complete and Well-typed take something like this up?
02:41:28 <Athas> madknight: a very good Common Lisp mode for Emacs.
02:41:31 <Athas> saurabhn_: they are.
02:41:36 <Athas> Intero and stack is by FP Complete.
02:41:36 <fakenullie> I find haskell instrumentation pretty good compared to python
02:41:40 <merijn> Athas: No, but in the lack of industrial funding you need volunteers. And as tdammers points out the need isn't high enough for volunteers to happen
02:42:06 <madknight> Athas, hmm and whats with vim users?
02:42:18 <saurabhn_> Athas: difference being, IIUC, no one paid them to do it directly. Vs kickstarter funding for building out haskell-ide-engine completely.
02:42:22 <tdammers> madknight: lispers use emacs. Problem solved.
02:42:27 <Athas> madknight: too bad, I guess?  I don't know what Vim-using Lispers do.  From what I remember, they were few in number.
02:42:52 <tdammers> that said, I've done quite a bit of clojure work in vim, but it's a pretty terrible experience.
02:43:00 <merijn> madknight: Vim users are boned :p
02:43:03 <merijn> madknight: Sadly :\
02:43:18 <tdammers> the vim plugins are broken to the point of being useless
02:43:19 <merijn> madknight: You can use ghc-mod, if you don't use Cabal-2.x or new-build
02:43:35 <tdammers> so you basically end up just running your editor and a repl side by side, and copy-pasting between them a lot
02:43:41 <tdammers> it's not fun
02:43:49 <merijn> tdammers: ghc-mod works decently, but Cabal-2.x support is still work in progress and new-build integration is meh
02:44:10 <Boomerang> What's missing to get ghc-mod to work with Cabal-2.x?
02:44:16 <tdammers> merijn: I was talking about clojure. For Haskell, I feel absolutely no need for editor integration beyond :!
02:44:19 <merijn> Boomerang: Not sure, ask in #ghc-mod?
02:44:38 <merijn> Boomerang: Last time I talked he was to busy to finish up 2.x support
02:44:43 <fakenullie> what's ":!"?
02:44:57 <Boomerang> I didn't know there was a channel, it'd be great to get it working again.
02:44:59 <tdammers> fakenullie: a family of vim commands that run subprocesses
02:45:06 <fakenullie> oh, ok
02:45:12 <tdammers> fakenullie: e.g., :%!sort pipes the current buffer through the sort command
02:45:30 <MarcelineVQ> I'm not sure what ghc-mod is for now that ghci can do what it does, other than some editors have plugins for ghc-mod but not ghci yet
02:45:32 <merijn> Boomerang: Daniel is rather helpful/responsive, just a bit busy to work on it enough
02:45:53 <Boomerang> Fair enough :)
02:45:53 <Athas> merijn: when linking dynamically, GHC still manages to turn *my code* into a 53MiB .so.
02:46:02 <merijn> MarcelineVQ: ghci doesn't do auto-completion suggestions, afaik. More importantly, still no vim plugins supporting ghcid
02:46:26 <Athas> Add to that the remaining 96 dynamic libraries required by the executable, and it's *way* bigger than the original 37MiB static executable.
02:46:36 <merijn> Boomerang: If you're willing to invest time into ghc-mod I'd <3 you forever if you managed to get new-build working too :)
02:46:39 <MarcelineVQ> merijn: I can do completion suggestions
02:46:44 <MarcelineVQ> *It
02:46:57 <merijn> Boomerang: I spent some time trying to fix it, but since this is the end of my phd I had to give up and get back to "real" work
02:48:26 <madknight> merijn, maybe you need to start another phd to finish your work :)
02:48:31 <merijn> Incidentally, since we actually seem to have people here right now!
02:48:59 <merijn> Who here is using multi-ghc-travis to generate their Travis test scripts?
02:49:11 <merijn> And who of those is willing to play guinea pig? ;)
02:50:57 <Boomerang> I've recently been doing a massive upgrade of the work codebase from ghc8.0 to ghc8.2.1. I saw ghc-mod didn't work so I disabled it but if I could get to it work again, it'd be great. I'll try to take a better look at the current pull request.
02:51:44 <merijn> Boomerang: If you ask dxld what needs work he can probably point you in the right direction
02:51:55 <athan> Is there an open bounty board for OSS haskell libs? :D
02:52:09 <merijn> athan: Not afaik
02:52:16 <athan> hmm...
02:52:24 <Boomerang> merijn: thanks!
02:52:27 <merijn> There were a couple of bitcoin bounties posted on r/haskell or so
02:52:40 <athan> oh I might just do that
02:52:56 <athan> dbus needs some work I think, but I don't know / am too lazy to learn dbus properly
02:53:09 <athan> the dbus library needs work*
02:53:50 <merijn> athan: See here for example: https://www.reddit.com/r/haskell/comments/5s96gd/im_creating_a_bounty_for_anyone_who_can_modernize/ https://www.reddit.com/r/haskell/comments/5w8frm/successful_bounty_completed_cabalmacosx_update/
02:56:11 <athan> That's perfect, thank you merijn
03:06:22 <ogrady> Say I have a datatype `data Foo a = Foo a` and another type `data Bar = Bar [Foo]`. I'd like to express: "Bar contains a list of Foo, regardless of the parameter of Foo (may even be mixed)". Is that possible?
03:07:06 <freyr> do you mean heterogenious lists?
03:07:31 <ogrady> Yes. But even without knowing what heterogenuous types it contains.
03:08:56 <erisco> ogrady, there is nothing you can do then, unless there is also a constraint
03:09:15 <ogrady> Okay, thank you.
03:09:21 <freyr> how the compiler should infer the type of Foo a then? The best you can do is to use heterogenious list
03:09:26 <erisco> but, if there is a constraint, often you can just call whatever function you wanted and put the result in the list instead
03:10:18 <ogrady> The compiler should not infer at that point. I'd like it to not care at all there. But I see how that would cause troubles once I'd get the nth element of that list.
03:10:56 <erisco> you can have such a list, there is just no value to it
03:12:14 <tdammers> well, you *could* use Dynamic, but there'd still be very limited value to it, because when you pull things out, you need to know which exact type to cast to
03:12:19 <erisco> there is possibly value if you also have a constraint, but it only makes sense for some constraints
03:13:09 <tdammers> it looks like you want runtime polymorphism here, and the standard answer to that is to convert all your list elements to the same type, such that that type can express everything you may want to do with your objects
03:13:11 <ogrady> I am also open for other solutions to this: I'd like to model somewhat OOPish programs. You can have `data Attribute t v = Attribute t v` being an attribute with a type and value. And then you have Structs, which consist of an arbitrary number of Attributes of mixed type.
03:13:51 <fakenullie> eh
03:15:11 <tdammers> ogrady: you can have OOP in Haskell... it's not pretty, but it works. The basic approach is to write your interfaces as data types, with methods modeled as record fields; and then for each type that implements the interface, you write a function that converts it to the interface type
03:15:20 <fakenullie> opqdonut: you can model oopish data types in haskell
03:15:36 <erisco> that is one approach, and another is to use type classes
03:15:49 <tdammers> erisco: you use both
03:16:18 <erisco> okay… well you don't have to
03:16:19 <Boomerang> ogrady: Can't you use a sum type to represent your attributes? That requires that you statically know what type of attributes you could have
03:16:22 <ogrady> tdammers: right, I don't actually want to program in an OOP-way there but rather _model_ OOP programs. Kind of like an OOP DSL.
03:17:16 <tdammers> data INamed = INamed { getName :: INamed -> String }; class IsNamed a where { cast :: a -> INamed }; instance IsNamed User where { cast = \user -> INamed { getName = \this -> userUsername user } }
03:17:17 <ogrady> Boomerang: I might be able to do that, yes. That would get rid of `t`, at least. I'd still haveto specify `v`, wouldn't I?
03:17:36 <tdammers> the additional `this` parameter is needed for virtual methods
03:17:37 <Boomerang> ogrady: sure but then you can make v depend on t :)
03:17:54 <ogrady> Hmm... fair point!
03:18:07 <Boomerang> data Attribute = Name String | Power Double | ID Int...
03:18:29 <freyr> there are lots of options then. You can model your object as a dispatcher function and methods as GADTs then for example (if you wanna dsl)
03:18:33 <erisco> class INamed a where getName :: a -> String; data Named where Named :: forall a. INamed a => a -> Named
03:18:50 <erisco> this is only as good as the String, which is why it only makes sense for some constraints
03:19:54 <ogrady> Okay, I think I got some pointers now from which I can go on. Thank you all!
03:20:00 <erisco> actually maybe you swap Named and INamed
03:20:02 <Boomerang> Alternatively if you still want your values to be a bit more generic they can still be parameters: data Attribute s d = Name s | Power d | ID Int
03:20:15 <tdammers> erisco: it gets more useful once you have methods depend on other methods; then you can do proper runtime dispatch
03:20:32 <tdammers> call back into the runtime vtable of the `this` object
03:20:56 <ogrady> Boomerang: then I'd have to parametrise `Object` which I am trying to avoid
03:21:17 <erisco> I am not sure if I disagree or I just don't see the necessity
03:22:42 <ogrady> Having `data Attribute s d = ...` would require me to have this `data Object s d = [Attribute s d]` wouldn't it?
03:22:53 <tdammers> erisco: the necessity is a rather specific one that doesn't occur often
03:22:56 <Boomerang> ogrady: I think there are some extensions that allow to hide these parameters (as long as it is still sound): data Object = forall s d. Object { attrs :: [Attribute s d],...}
03:23:07 <erisco> does it actually happen in OOP?
03:23:16 <tdammers> erisco: one situation where I did need it was when I was modeling query generator functions for various SQL dialects
03:23:29 <Boomerang> But it's probably overkill and I would just pass the parameters to the object
03:24:09 <tdammers> erisco: in order to compose a SELECT query, you need to know how to quote fields, so the method that composes the SELECT query needs to be able to call back into the SqlDialect object to resolve the quoteField call
03:24:26 <erisco> too complicated for me to follow
03:26:01 <Boomerang> ogrady: If you are interested in the possibility of hiding the parameters https://en.wikibooks.org/wiki/Haskell/Existentially_quantified_types But I would recommend you try without it first.
03:26:21 <ogrady> Thank you, Boomerang, will look into it. :)
03:26:26 <tdammers> erisco: say you have a data structure representing an SQL query: data SqlSelect = { tableName :: String, selectColumns :: [String], whereConditions :: [Condition], orderBy :: [OrderBy], limit :: Limit }
03:26:54 <tdammers> erisco: and now you want to write functions SqlSelect -> String, one for each SQL dialect you need to support
03:32:26 <erisco> tdammers, I think you are talking about virtual methods, so I am writing an example of how to do that
03:40:21 <tdammers> erisco: oh, I know how to do it - one way or another, you need to pass a `this` object back in at runtime so that you can resolve the virtual method calls
03:50:10 <ski> ogrady : existentials ?
03:52:52 <mkwia> Hi, I'm new to haskell and I'm curious how this scenario would work: I've got my app written and I want it to run all the time connecting to and dispensing websockets and querying databases and so on on my prouction server. How would I set this up?
03:53:11 <ogrady> ski: will read up on that too, thanks
03:57:03 <erisco> mkwia, how has it been written yet does not do this already? that sounds contradictory to me
03:58:39 <mkwia> erisco, it is not yet written sorry just a hypothetical
03:59:31 <erisco> there are a variety of web frameworks and networking libraries
04:00:14 <saurabhn_> how do I append more elements to a Data.List.NonEmpty?
04:03:00 <erisco> saurabhn_, probably with the Semigroup instance
04:06:19 <Boomerang> saurabhn_: alternatively if you want to use (++) you can use -XOverloadedLists
04:06:45 <saurabhn_> Semigroup worked. 
04:06:45 <erisco> that sounds awful =\
04:07:12 <Boomerang> Yeah Semigroup is better. NonEmpty does have an IsList instance though...
04:07:25 <erisco> but it has to be a partial function
04:07:55 <Boomerang> Sure but if you're appending it sounds pretty risk free :)
04:08:43 <erisco> [] will be an error, regardless if you're appending
04:09:20 <erisco> it seems to be taking NonEmpty and defeating its very purpose
04:10:42 <phadej> if you have to append [] or NonEmpty, you are doing something fishy
04:12:09 <phadej> use dlist or http://hackage.haskell.org/package/dlist-nonempty-0.1.1/docs/Data-DList-NonEmpty.html (FWIW, I'd probably need to add `appendList` and `appendNonEmpty` (and prepend) functions)
04:12:26 <phadej> ... but didn't need them myself, yet
04:38:34 <erisco> tdammers, the fields carry the instance data, and the constraint carries the methods
04:42:11 <ch3pjw> I've been playing with yesod's Persistent library. Made a lot of nice progress, but I've run into a bit of an issue where I don't quite understand what the template haskell is doing. I have a module that defines an EmailRegistration database record/table/datatype via mkPersist, and then I have a query which wants to get values ordered by EmailRegistrationId. I can use EmailRegistrationId fine to do that, but I can't expor
04:42:11 <ch3pjw> t it from one module and import it into another explicitly. It just works if I don't do any explicit import export. What am I doing wrong?
04:45:43 <lyxia> what does the error message say?
04:51:20 <ch3pjw> lyxia: Data constructor not in scope:
04:51:20 <ch3pjw>         EmailRegistrationId :: DB.EntityField EmailRegistration typ0
04:51:31 <ski> tdammers : by "needed for virtual methods", are you referring to "open recursion" ?
04:52:36 <ch3pjw> Even when it's in the export list just fine. I tried exporting `EmailRegistrationId(..)` but then it says I don't have a constructor, so I'm not sure what kind of thing it is, and it's a bit obfuscated behind the template haskell
04:54:36 <tdammers> ski: idk if that's the term... the thing to achieve with this is to be able to have methods of some object call other methods of the same object, such that the method implementations of both are resolved at runtime
04:54:59 <lyxia> ch3pjw: It looks like EmailRegistrationId is a value constructor, not a type constructor, which are those you can export.
04:55:22 <ch3pjw> lyxia: I appear to have placated it with the slightly strange export of `EntityField(..)`, and importing `EntityField(EmailRegistrationId)`
04:56:00 <ch3pjw> lyxia: Yes, I thought it might be something like that. I just thought it would be a value constructor of something like `EmailRegistration` or something prefixed with that name
04:56:05 <ski> tdammers : an example is if you have a method `m' in a class, calling method `n'. then you make a derived class, overriding `n', and you now want `m' to automagically call your new `n'
04:56:19 <tdammers> ski: yes, exactly
04:56:27 <ch3pjw> In trying to use another field I got a more explicit error message that hinted it belonged to `EntityField`
04:56:31 <ski> ok, that's "open recursion"
04:56:39 <tdammers> ski: weird name
04:56:42 * ski agrees
04:56:55 <ch3pjw> So... in short. Working \o/, and I have a better understanding now that you've clarified what's going on lyxia, thanks!
04:57:29 <ch3pjw> Longer answer: hmm, the template haskell for yesod persist is still a little beyond me *scratches chin in a confused manner*
04:58:41 <lyxia> ch3pjw: you can look at TH splices with the GHC option -ddump-splices to see what types look like
04:59:19 <lyxia> ch3pjw: haddock probably works too if you want to see what constructor corresponds to what type
05:01:35 <ch3pjw> lyxia: Cool - I tried that with stack (`stack build --ghc-options -ddump-splices`), and I could find some files with splices in the name in .stack-work, but I couldn't quite see anything to do with the Persistent stuff in it.
05:05:29 <carbolymer> guys, stupid question, how can I use deprecated pragma for a function? I am putting at the beginning of the file with my module {-# DEPRECATED addNewBlock "Don't use these" #-}
05:06:06 <carbolymer> and I am getting error: https://pastebin.com/B86zSPKa
05:06:07 <carbolymer> ?
05:07:05 <opqdonut> put it after the "module Foobar where" line
05:07:06 <opqdonut> ?
05:10:44 <carbolymer> opqdonut, does not help: https://pastebin.com/6mcB6HqH
05:10:46 <lyxia> carbolymer: you may be missing a "module Blockchain where" header at the top
05:10:56 <carbolymer> no no
05:11:04 <carbolymer> if I remove this pragma, everything compiles
05:11:09 <carbolymer> the GHC error is a bit misleading
05:11:35 <carbolymer> I am confused: where should I put this pragma
05:11:38 <lyxia> put it after imports
05:11:47 <lyxia> it's parsed as part of declarations
05:12:20 <lyxia> so when you first put it at the top, GHC sees a declaration and no longer expects "module" or "import" lines
05:13:10 <lyxia> if you put it between "module" and "import", it doesn't expect "import" after it.
05:13:19 <carbolymer> hm, seems to be working
05:13:19 <carbolymer> thanks
05:34:16 <abai> hey, i'm just beginning to learn haskell, i was wondering if when using guards it is possible to add something to a list and then recursively call the function with the new list if the predicate returns true
05:35:52 <merijn> Yay for reimplementing like 200 lines of code from some other module because it wasn't exported :\
05:37:20 <erisco> hm, up casting is easy, but what about down casting … not sure how to retain enough information
05:37:22 <lavalike> abai: maybe? what process are you trying to capture exactly?
05:38:18 <erisco> unless I explicitly try all the parent classes oO
05:40:11 <erisco> say I have an Int, and there is some function  c a => a -> r  then the idea is to know if  c Int
05:40:43 <erisco> I don't know how to know that
05:41:57 <abai> lavalike: i have a list (h:t) and another list of [a] i want to search through the list (h:t) and add each element of (h:t) to the list [a] if it fufills some condition
05:43:43 <erisco> if I know  c Int  then I can discharge the constraint and apply the Int
05:44:02 <Boomerang> erisco: Can you give an example of what constraint c you have to provide? There are ways to build up a proof that the constraint is valid
05:44:15 <erisco> any constraint
05:44:44 <erisco> the constraint itself can be constrained, but I don't know what constraints would help
05:44:47 <erisco> I was thinking Typeable
05:44:50 <merijn> Anyone have a favourite string formatting library?
05:45:00 <erisco> but knowing  Proxy (c Int)  isn't enough, it seems
05:45:11 <lavalike> abai: so stepping back from `do's and `guard's for a moment, if we take "adding to" to mean concatenate at the end, calling the first list xs and the second ys, it would be ys ++ filter predicate xs?
05:45:19 <erisco> case gcast :: Maybe (Proxy (c Int)) of Just Proxy -> m  is not enough for m to know c Int
05:46:15 <abai> lavalike: what do you mean by filter?
05:46:32 <lavalike> abai: the function filter :: (a -> Bool) -> [a] -> [a]
05:47:01 <Boomerang> erisco: I have used code that provided proofs by pattern matching on Refl https://hackage.haskell.org/package/base-4.10.0.0/docs/Data-Type-Equality.html#v:Refl
05:47:43 <abai> lavalike: yeah i think it would be
05:47:52 <erisco> okay, well, if you have any other details, I am listening
05:48:34 <Boomerang> If you want to conditionally provide a proof I think returning a Maybe (a :~: b) after checking some conditions at the value level works pretty well
05:49:05 <erisco> what is trying to be implemented is something like  (c a => a -> r) -> Maybe r
05:49:14 <Boomerang> But Proxy should work too depending on how your constraints work
05:49:27 <erisco> I have some particular value captured, lets say 5 :: Int
05:49:31 <lavalike> abai: good! I don't think there is a natural way to describe that process with the list monad.
05:49:32 <abai> lavalike:is it possible to just use filter?
05:49:43 <erisco> I have to look at the constraint c and determine if c Int
05:49:53 <erisco> if so, then Just (f 5) and if not then Nothing
05:49:54 <abai> lavalike: I'll give it a go thank you very much
05:49:55 <lavalike> abai: I am not sure I understand the question, you can definitely use filter :D
05:50:11 <abai> lavalike: i'll try it out now, thank you very much :)
05:50:12 <erisco> I don't have constraints, it is an arbitrary constraint
05:50:26 <lavalike> abai: sure thing!
05:51:01 <Boomerang> erisco, let me play around with ghci for a bit :)
05:51:17 <erisco> is the question clear to you?
05:51:44 <marvin2> filter filters, ++ adds two lists together. if you want to do both you need to use both functions, not just one
05:52:03 <Boomerang> I think so, do you have a function that tells you if the condition holds at the value level?
05:52:06 <lyxia> erisco: can you carry around a dictionary containing (c Int)
05:52:14 <Boomerang> In your example `f`
05:52:39 <erisco> I may constrain c, otherwise no
05:53:07 <lyxia> There is no function that will tell you for an arbitrary c whether c Int is satisfied otherwise.
05:53:52 <ski> lavalike : hm, who mentioned the list monad ?
05:54:01 <erisco> the idea is that if I know 5 :: Int then I know all the constraints which this satisfies too
05:54:04 * ski suspects abai may want to reimplement `filter' ?
05:54:27 <lavalike> ski: they wanted to see if there was a way to represent that expression with `do's using `guard'
05:54:29 <erisco> so, if someone asks if c Int, i.e. "does Int satisfy my constraint" I should be able to answer that
05:54:52 <erisco> is there some reason I could not know this, conceptually?
05:55:27 <ski> lavalike : i don't see them mentioning `do'
05:55:37 <lavalike> ski: I took it implicitly when they mentioned guard
05:56:23 <lavalike> :t guard
05:56:25 <lambdabot> Alternative f => Bool -> f ()
05:56:29 <ski> "guard" could either refer to the `guard' function, or the `|' syntax (like `f | foo = bar | otherwise = baz')
05:56:38 <lavalike> I actually thought it was part of the `do' syntax
05:56:46 <ski> nah
05:57:09 <ski> it's part of defining equation (and `case') syntax
05:57:39 <Boomerang> erisco: In your code the constraint c is polymorphic or are you just saying c because you don't know what the constraint is yet?
05:57:44 <ski> (i was suspecting you took it implicitly, i just didn't see why)
05:57:45 <lavalike> overloaded terms!
05:58:10 <ski> s/polymorphic/a type variable/ ?
05:58:36 <ski> (or perhaps, class variable ?)
05:58:48 <lyxia> erisco: Type classes are erased pretty early at compilation, all that's left are dictionaries being passed around.
05:59:28 <ski> erisco : you can't (for any `c') decide whether `c Int' holds
06:01:07 <mxf> Which Package on hackage is recommended to get directory listings, which implements FilePath as ByteString or Text?
06:01:36 <lyxia> erisco: more conceptually, instances live in an open world, so a procedure to decide whether a constraint is satisfied would be inconsistent (its semantics depend on whether some instances are visible).
06:02:41 <ski> erisco : you may (or may not), be able to write `semiDecide :: forall a. Foo a -> Maybe (Dict (c a))', for a given specific `c'
06:02:45 <Boomerang> erisco: What I was thinking about involves knowing the constraint statically even if you are only providing the proof of whether it holds or not dynamically.
06:03:26 <Boomerang> Basically something along the lines of what ski is describing
06:04:39 <ski> (`Proxy' just gives you a way to avoid ambiguity, to name a tyvar. it provides no run-time information)
06:05:10 <ski> erisco : are you looking for `Dict', in "case gcast :: Maybe (Proxy (c Int)) of Just Proxy -> m  is not enough for m to know c Int" ?
06:12:14 <merijn> Is there a string formatting library nicer than Text.Printf anywhere?
06:13:29 <ayds> hi, i am very new to haskell and have found out that it is a lazy language, meaning it will not iterate through a whole if statement if one of the statements returns true, however i would like to be able to go through all the code before the if statement breaks. can someone help me!!
06:15:01 <ayds> to add some context i would like to be able to add an item to a list on one line of a guard, and on the next i would like to add another, however the if statement breaks before i can add to the second list 
06:17:27 <phadej> ayds: I don't understand what you want precisely, could you paste an example (to e.g. lpaste.net) in your language of choice
06:17:31 <fendor> ayds, well, maybe a if statement is not the right construct for you use case? Also, this has nothing to do with haskell being lazy 
06:18:05 <Boomerang> ayds: do you want to add 2 elements to your list if your two guards are true?
06:18:31 <ayds> i will add an example, give me 2 secs 
06:21:58 <ayds> here is some example code 
06:21:59 <ayds> http://lpaste.net/359321
06:22:31 <ayds> when i run this, it only adds the item to some_list and then never adds to some_list2
06:23:21 <ski> ayds : did you mean `foo t some_list2' in the recursive call ?
06:23:25 <jollygood2> not sure how you are running this when it doesn't even compile?
06:24:00 <ayds> well i dont run it, im just using a little snippet 
06:24:26 <jollygood2> you also can't add things to some_list, it is immutable
06:25:01 <ayds> its a list, not a tuple 
06:25:07 <ski> ayds : when you say "then add to some_list2", it sounds like you want to add to the second list *result* -- but then i don't know whether by "then add to some_list" you want to add to the second list *argument* or the first list *result*
06:25:22 <jollygood2> ayds this isn't python, lists are immutable too :)
06:25:50 <Boomerang> For the guards, as soon as one of them is True (from top to bottom), that branch and only that one is taken.
06:26:11 <ski> (it looks like at least one of the second list argument, first list result, second list result, will be used to "accumulate" items)
06:26:21 <ayds> boomerang, that is my problemm is there a way to access the other branches also 
06:27:30 <ayds> jollygood2, i have been able to add to lists in haskell in the past 
06:27:33 <Boomerang> ayds: you will have to reorganize your logic so that it checks if both conditions are true beforehand
06:27:35 <ski> ayds : define your new versions of `some_list' and `some_list2' in a where (using guards if you want to), (re)using the previous value in case you don't want to add ?
06:27:54 <jollygood2> ayds you can create a new list, list1 ++ list2, but this will not change either list1 or list2
06:27:57 * ski thinks that might be the simplest ..
06:28:04 <ski> .. assuming i understood correctly
06:28:39 <ski> jollygood2 : presumably they're now familiar with making new versions of values (e.g. accumulators) ?
06:28:46 <jollygood2> it appears that you want to add elements to top-level some_list and some_list2, and you definitely can't do that
06:29:40 <ski> yea, you can drop those top-level definitions, that's dead code :)
06:30:13 <ayds> haha i apologise i am v new to haskell 
06:30:21 <ayds> but where would i define the lists otherwise ?
06:30:31 <ski> no worry, newbie questions are welcome here
06:30:56 <ski> often you "carry" it in a function parameter
06:31:29 <ski> recursive calls can then call with a new value (usually computed from the old in some way. it sounded like you wanted to add an item)
06:32:13 <ayds> i will have another look using the where function 
06:32:17 <ayds> thanks everyone 
06:32:55 <ski> alternatively, you can have it as a result (the only result, or one of several results. in your case it looked like you wanted two list results ?). then the current call will "modify" the result from the recursive call before passing it on "upwards" to its caller
06:33:13 <ski> oh, they left :/
06:33:24 * ski was going to say `where' is not a function
06:34:38 <merijn> You know what? I have decided that the person who implemented true-name is a genius who I shall love forever
06:36:38 <erisco> can't have proper OOP without downcasting, so I give up
06:37:27 <ski> well, i'm not convinced downcasting is that sensible to begin with ..
06:38:13 <erisco> in a world without sum types, which most OOPLs seem to be in, downcasting is helpful
06:38:53 <ski> any use for it, that's not simulating variant types, or binary operations of a module ?
06:39:20 <ski> hm, are you programming in a system with a lack of variant/sum types ?
06:39:51 <erisco> you can use downcasting as an implementation, or lets say emulation, of sum types
06:40:23 * ski nods
06:41:00 * ski was thinking erisco wanted to simulate some OO aspects in Haskell, judging from previous discussion, rather than vice versa
06:41:12 <erisco> yes, that is exactly what I am doing
06:41:21 <merijn> Ah...rats
06:41:28 <merijn> true-name can't grab functions :(
06:42:59 <jgt> how can I write tests that stub out network calls?
06:46:23 <erisco> here is the upcast, anyways http://lpaste.net/359322
06:47:00 <merijn> jgt: In what sense?
06:47:21 <erisco> I can't figure out what information I can keep after an upcast to then enable a downcast
06:49:54 <jgt> merijn: I think I'm looking for something like Ruby's VCR
06:50:17 <jgt> since network calls (I'm building an SMS redundancy layer) cost actual money
06:50:50 <merijn> jgt: I have no clue what VCR is, tbh
06:50:58 <jgt> but then again, maybe I should just test against the network and use test phonenumbers
06:51:28 <jgt> merijn: VCR records real network calls, and then stubs them on subsequent runs
06:51:47 <jgt> so you run your test 100 times, but only one real network call was made
06:51:57 <supercynic> erisco: isn't "upcasting" and "downcasting" technically just a conversion between types?
06:52:08 <jgt> merijn: https://github.com/vcr/vcr
06:52:27 <erisco> supercynic, what is a conversion to you?
06:52:38 <supercynic> erisco: a function
06:52:59 <erisco> id does the upcast
06:53:07 <merijn> jgt: That seems to assume some sort ability to automatically intercept/override the behaviour of a library you call and there's no sane way of doing that
06:53:28 <supercynic> erisco: is there something more you want to achieve than just having those conversion functions?
06:53:50 <erisco> yes, but they're not optional
06:53:51 <ski> jgt : .. hm, sounds reminiscent of "Idempotent I/O for safe time travel" by Zoltan Somogyi in 2003-09 at <https://www.mercurylang.org/documentation/papers.html#aadebug03-paper>
06:54:29 <ski> supercynic : recover instances, it seemed
06:54:37 <jgt> merijn: yeah, I think it may only be a thing in monkeypatch-land
06:55:18 <merijn> jgt: The sanest way to do something like that would be to change your API to have, say, "URL -> IO HttpRequestData" function as extra argument 
06:55:21 <supercynic> ski: i don't know what that means
06:55:39 <merijn> jgt: Then your tests could provide a caching/replay version of your real implementation
06:56:03 <merijn> jgt: Or just store the HttpRequestData on disk in a file and then load those, whatever
06:56:38 <merijn> jgt: But at that point, why nost just eliminate all that entirely
06:56:59 <merijn> jgt: If your application code is "HttpRequestData -> IO Foo", you don't even need to stub the network, just test that
06:57:11 <merijn> With, say, data from disk.
06:57:26 <ski> supercynic : something like .. given an `exists a. Foo a *> T a', decide whether `C a', for that particular `a', holds
06:57:54 <supercynic> say i have (x :: House) and (f :: Building -> X), then i can use (toBuilding :: House -> Building), which i might call an "upcast", so i can apply 'f'…  similarly for "downcasts"…  is my thinking too simple?
06:58:11 * ski once did a "replay" monad
06:58:54 <supercynic> f (toBuilding x)  -- problem solved, no?
06:58:55 <merijn> jgt: This assumes the http library does something like "fetch :: URL -> IO HttpRequestData", if you have "application :: HttpRequestData -> IO Foo" then your code would be 'fetch "http://example.com/index" >>= application" and your tests would be a trivial "loadDataFromDisk >>= application"
06:59:17 <merijn> jgt: Seems far simpler than a complicated mocking/stubbing framework
06:59:31 <ski> merijn : perhaps there's more interaction, which is hard to spoof manually ?
06:59:36 <merijn> ski: Maybe
06:59:52 <merijn> ski: But don't rule out simple solutions until you have too :p
07:00:04 <erisco> supercynic, the upcast function I provided is general to any upcast operation, so you can specialise it however you want for particular types
07:00:27 <erisco> supercynic, the goal is to have a general downcasting function as well, otherwise one has to have a separate definition for each downcast
07:00:54 <ski> supercynic : erisco seemed to be talking about simulating OO stuff in Haskell earlier, possibly using existentials and type classes
07:01:29 <ski> merijn : yea :)
07:02:33 <supercynic> erisco: a downcast involves coming up with missing information, right?
07:03:07 <erisco> the value is not missing but the type is, lets say
07:03:16 <supercynic> i don't know what that means
07:03:32 <ski> erisco : except i was thinking maybe that's not actually true
07:03:47 <ski> (depending on particulars of what you want to do)
07:03:59 <erisco> in OOP, when you upcast you just make a pointer that points to a different part of the same structure
07:04:06 <erisco> it is structured like a nesting doll
07:04:16 <erisco> when you downcast, you move the pointer back
07:04:36 <supercynic> so a downcast always follows an upcast?
07:04:40 <erisco> of course, if you downcast and the appropriate structure is not there then that is an error, so checks may be done
07:04:46 <erisco> no
07:05:05 <supercynic> i see…  so far that sounds a lot like lenses to me
07:05:38 <supercynic> class Mono a b where mono :: Lens a b  -- "upcast"
07:05:46 <ski> i don't think "pointer" should here be taken as "relative path"
07:05:57 <ski> hm
07:06:53 <supercynic> 'mono' is both an "upcast" and a safe "back-down-cast"
07:07:21 <erisco> if I knew exactly how GHC represented the dicts in memory then maybe the same thing is possible
07:07:53 <supercynic> is there anything here that OOP can do that lenses can't do?
07:08:02 <erisco> is an Ord dict an appendage to an Eq dict? no idea
07:08:16 <erisco> I don't see how lenses is related
07:08:46 <supercynic> my thinking may be too pragmatic
07:11:35 <twey1> What happened to the slides from Rúnar Óli Bjarnason's machines talk?  They seem to have link-rotted away.  Does anybody know if they're still available somewhere?
07:12:01 <erisco> I don't know anything that wouldn't just be writing in all the possible casts
07:12:30 <erisco> particularly troubling is something like upcast from C to A, then downcast to B, where C extends B
07:12:37 <ski> erisco : you can implement `forall a. Dict (Ord a) -> Dict (Eq a)'. but not the other way around, not even if you add a `Typeable a' constraint
07:13:52 <c_wraith> But you can totally (and uselessly) implement Ord a => Dict (Eq a) -> Dict (Ord a)
07:14:30 <ski> (you can, as you say, check for some non-exhaustive number of types, getting `forall a. Typeable a => Proxy a -> Maybe (Dict (Ord a))')
07:14:57 <erisco> yeah, that is writing them all in
07:15:20 <supercynic> is there an example use case for 'upcast'?
07:15:25 <ski> ("if `a' is `Int', then fine; if `(b,c)' where both `b' and `c' have `Ord' instances, then fine; &c.)
07:16:01 <supercynic> if i got an 'a' together with (Ord a), i already have the (Eq a)
07:16:05 <ski> (ftr, `Proxy' above is just convenience)
07:16:28 <erisco> supercynic, it operates on 'A' which is an existential for the type class
07:16:35 <dminuoso> What's the purpose of `forall` in haskell? Is it just for explicitness?
07:16:55 <erisco> An Ord  is some value with an Ord instance, for example
07:17:11 <ski> dminuoso : sometimes you want to put a polymorphic operation inside a data-structure, or pass it as an argument
07:17:12 <c_wraith> dminuoso: It depends on what extensions are active.
07:17:51 <supercynic> erisco: even if i get an A, i can just pattern-match on it
07:17:53 <c_wraith> dminuoso: ScopedTypeVariables, PolymorphicComponents/Rank2Types/RankNTypes, and ExistentialTypes all use it to mean different things
07:18:11 <dminuoso> Ahh I see.
07:18:17 <erisco> supercynic, so?
07:18:21 <ski> dminuoso : it's also used to specify an "existential data constructor" (which is polymorphic in a tyvar not occuring in the result type). .. also (perversely, imho) used for locally scoped tyvars
07:18:38 <erisco> supercynic, how do you think I implemented the upcast? :P
07:19:02 <ski> s/ExistentialTypes/ExistentialQuantification/
07:19:29 <ski> (also, it arguably means the same thing there as normally)
07:19:47 <supercynic> erisco: i'm trying to understand its point, and how a "downcast" would even make sense without a prior upcast…  if you just pattern-match, the more specialised A is still in scope
07:20:20 <erisco> a downcast is only useful after an upcast, otherwise it fails
07:20:52 <ski> supercynic : "i can just pattern-match on it", no you can't, since "'A' [..] is an existential for the type class"
07:21:04 <supercynic> erisco: you could of course introduce a variant of A that tracks the upcast history
07:21:40 <supercynic> ski: case (A EQ :: A Ord) of A x -> …
07:21:44 * ski thinks the discussion might be a bit clearer, with more explict examples
07:22:22 <supercynic> ski: now both the value and its corresponding Eq and Ord instances are in scope
07:24:11 <ski> supercynic : i don't know what that is an example of (nor how your specific `A' is defined. however, iiuc, erisco didn't have a particular `A' in mind, but rather an existentially quantified tyvar)
07:25:30 <c_wraith> By the way, do we really need 3 extensions that do the exact same thing?  I understand that in theory PolymorphicComponents/Rank2Types/RankNTypes are different, but GHC treats them all as meaning RankNTypes
07:25:30 <ski> c_wraith : i think they used to be different ?
07:25:30 <supercynic> ski: i'm using the A from erisco's earlier paste
07:25:30 <supercynic> ski: data A (c :: * -> Constraint) where A :: c a => a -> A c
07:25:30 <ski> oh, ty
07:25:30 <ski> missed that
07:25:30 <erisco> supercynic, I gave a scenario already where the history is irrelevant
07:25:30 <c_wraith> ski: they're actually identical in power, even in theory, thanks to the ability to always nest newtype wrapped polymorphic functions.  RankNTypes just makes some cases more convenient.
07:25:30 <erisco> supercynic, A extends B extends C, upcast A to C, then downcast C to B
07:25:30 <ski> c_wraith : granted
07:25:30 <cocreature> c_wraith: huh I didn’t even know PolymorphicComponents are a thing
07:25:30 <supercynic> erisco: the history is relevant there…  you don't know that you can downcast to B, if you don't remember that you upcasted from A
07:25:30 <Welkin> what...
07:26:19 <erisco> supercynic, no, that is more information than necessary
07:26:19 <Welkin> erisco: what kind of mad science are you doing onw?
07:26:19 <Welkin> now*
07:26:19 <supercynic> erisco: sure, you need less information than that, but you need the history
07:26:27 <supercynic> you need to know at least that you could have been a B at some point
07:26:28 <ski> that `upcast' looks like an `fmap' thing, like `forall c d. (forall a. Dict (c a) -> Dict (d a)) -> (A c -> A d)'
07:26:29 <erisco> knowing that the smallest type is A is sufficient
07:26:37 <erisco> you do not need the history
07:28:08 <ski> since `A c' uses `c' covariantly (and not contravariantly), i don't see how you could hope for `forall c d. (forall a. Dict (d a) -> Dict (c a)) -> (A c -> A d)', even if you wrap the result in a `Maybe', and add `Typeable' constraint on `a'
07:28:15 <supercynic> data c :=> d where Some :: (c a, d a) => a -> c :=> d
07:28:37 <ski> perhaps one could figure out a scheme where you add some constraint on `c' ior `d' .. but i don't see how that'd work
07:29:08 <supercynic> some :: (c a) => a -> c :=> c
07:29:33 <erisco> I don't know how to even remember that A is the smallest type in any useful way
07:29:47 <erisco> well, we shouldn't be saying type, we should be saying constraint
07:30:22 <supercynic> recast :: (forall a. c a => Dict (d a)) -> c :=> d' -> c :=> d
07:30:26 <supercynic> something like that might work
07:30:41 <erisco> ski, I don't know if there is a better witness than id to the fact that c implies c'
07:31:46 <erisco> supercynic, you have to forget what the smallest constraint is in the type, otherwise it is not satisfactory
07:31:51 * ski suspects that what erisco wants (at least under some plausible interpretation) violates parametricity
07:32:14 <erisco> it'd be like you're saying  x :: Dog :=> Animal  instead of  x :: Animal
07:32:18 <hexagoxel> erisco: what is the original problem? you have an lpaste i missed in the history?
07:32:24 <erisco> the point is to have Cat and Dog both be Animal
07:32:47 <ski> erisco : your `upcast' is fine, it's the "downcastin" you're talking about that i'm having doubts for
07:33:06 <erisco> I suspect this is just not a possible thing in Haskell, and at best would exploit particulars of GHC heavily
07:33:25 <supercynic> erisco: you can always elevate the strongest constraint at the expense of no longer being able to downcast to it
07:33:41 <erisco> that is too costly :) defeats the purpose
07:33:42 <AWizzArd> I have local code in some folder that I would like to add as a dependency in my .cabal file. So, something that I can’t just add in the `build-depends:` section. How can I do this?
07:34:07 <supercynic> erisco: i don't see how to forget that you are an Ord type while still maintaining your ability to go back to Ord
07:34:20 <supercynic> (from, say, Eq)
07:35:09 <merijn> AWizzArd: You mean like an unreleased/non-public package?
07:35:48 <supercynic> erisco: you could create a separate Trunk type that remembers it, but then it's pretty much just pattern-matching and scoping in disguise
07:36:02 <AWizzArd> merijn: yes, something like https://github.com/hdbc/hdbc-odbc
07:36:29 <merijn> AWizzArd: Are you using cabal-install or stack?
07:36:31 <AWizzArd> merijn: It’s not on stackage.
07:36:34 <AWizzArd> Stack
07:36:50 <merijn> AWizzArd: Ah, then I can't help you :)
07:38:30 <AndreasK> AWizzArd: Is your code a proper package or just a bunch of files? You can add packages as usual and then can give the path to them in the yaml file
07:38:55 <AndreasK> Not sure if/how it works for "just files"
07:39:10 <AWizzArd> AndreasK: it looks like a proper package. Something which _could_ in principle be uploaded to stackage, but which simply wasn’t done.
07:39:36 <AWizzArd> I think I would like to specify a path to a certain folder as a dependency.
07:40:10 <AndreasK> AWizzArd: https://docs.haskellstack.org/en/stable/yaml_configuration/ check under packages that should have the info you need
07:40:19 <AndreasK> I did it a while ago but no longer remember the specifics
07:40:40 <AWizzArd> AndreasK: oki, thanks for the pointer
07:40:46 <supercynic> AWizzArd: it's code you want to use from your project?
07:41:04 <supercynic> ah, already answered
07:41:08 <AWizzArd> si
07:44:15 <anarcat> hi again
07:44:23 * anarcat banging his head against formatTime and friends
07:44:34 <anarcat> i expanded on my pandoc filter, and now i'm stuck at date parsing
07:45:01 <anarcat> i want to turn [Str "2017",Str "-",Str "October",Str "-",Str "2,"] into [[!meta date="2017-10-02T12:00:00-0500"]], basically
07:45:06 <cement> I'd recommend the library my boss wrote for that, but it's not documented
07:45:21 <anarcat> i got to the mouthful: cleanBlock (Div (id, [cls], _) [Para [Str mth, Space, Str day, Space, Str yr], Para _]) | cls == "GAByline" = [Para [Str (formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%s%z" (parseTimeOrError True, defaultTimeLocale, "%Y-%B-%e", (yr ++ "-" ++ mth ++ "-" ++ day)))]]
07:45:50 <anarcat> but this gave me: http://paste.debian.net/991258/
07:47:38 <anarcat> i'm utterly confused
07:51:11 <Welkin> anarcat: like a cow?
07:51:20 <anarcat> wat
07:51:27 <Welkin> utter
07:51:29 <Welkin> udder
07:52:13 <anarcat> hilarious
07:52:35 <lyxia> anarcat: do you have a FormatTime instance for tuples?
07:52:47 <lyxia> I don't see one in the time library
07:52:51 <anarcat> lyxia: i have no idea
07:52:57 <anarcat> oh, i shouldn't have commas there should i
07:53:42 <anarcat> i think i'm trying to use https://hackage.haskell.org/package/time-1.8.0.3/docs/Data-Time-Format.html#t:FormatTime and https://hackage.haskell.org/package/time-1.8.0.3/docs/Data-Time-Format.html#v:parseTimeOrError
07:54:07 <anarcat> removing the commas yields this: http://paste.debian.net/991261/
07:54:59 <mivael> Hello all!  I'm playing with text parsing (yes, again).  Having Parsec related question, with the following context: (1) not using Attoparsec because I was advised against parsing text with ByteString-based means, (2) not using Megaparsec because it is not "Safe Haskell".
07:55:10 <mivael> parseRow = fmap (== '#') <$> many1 (oneOf "#.")  -- Is there an evident/possible inefficiency in this (Text.Parsec,Data.Text.Lazy)-based parsing implementation?
07:55:23 <mivael> Benchmarking shows that this Parsec-based implementation is about twice slower comparing to a (Data.Text.Lazy)-based ad hoc parsing.
07:55:33 <mivael> Profiling blames this (parseRow) function for the added processing time.
07:55:33 <sm> eh, what does 2 mean ?
07:55:47 <mivael> The parseRow function is called 10'000 times, each time it parses a line of 1'000 consequtive '#' characters.
07:55:58 <mivael> I also tried (satisfy (> ' ')) instead of (oneOf "#.") -- with no notable changes.
07:56:11 <lyxia> anarcat: add a type annnotation on the result of parseTimeOrError
07:56:32 <anarcat> lyxia: yeah, i saw that suggestion, but i don't understand what it means
07:56:39 <mivael> sm, is this for me?
07:56:48 <sm> yes
07:56:58 <lyxia> anarcat: (parseTimeOrError ... :: Day), perhaps
07:57:26 <mivael> sm, see "Safe Haskell: None" at https://hackage.haskell.org/package/megaparsec-6.2.0/docs/Text-Megaparsec.html
07:57:56 <anarcat> here we are, anarcat meets monads again
07:58:17 <sm> mivael: I think this is the norm for most hackage packages. Safe Haskell is a relatively new and little-used feature 
07:58:35 <anarcat> lyxia: ... "Day"?
07:58:35 <lyxia> anarcat: where do you see monads
07:58:42 <anarcat> lyxia: here: https://hackage.haskell.org/package/time-1.8.0.3/docs/Data-Time-Format.html#v:parseTimeM
07:58:59 <mivael> sm, ...and this usually means that it is not likely installed at remote sites to which I post my Haskell code.
07:59:17 <lyxia> anarcat: just think of m as Maybe here
07:59:30 <anarcat> yeah, Maybe is confusing to me still
07:59:52 <sm> ok. megaparsec may not be installed, indeed, but it's not because of that Safe Haskell thing. It's just less "default" than parsec
08:00:16 <anarcat> lyxia:     Not in scope: type constructor or class ‘Day’
08:00:22 * ski slowly convolutes the day
08:00:38 <mivael> sm, I've seen reasonong like "not safe" at competitive programming sites (codeforces.com, if I'm not mistaken)
08:00:58 <anarcat> i split out the code to a different function to try and clarify things: http://paste.debian.net/991268/
08:01:30 <sm> hmm, though I see Parsec does have the Safe Haskell: Safe annotation, so what do I know..
08:01:40 <mivael> s/reasonong/reasoning/
08:02:17 * anarcat is tempted to parse the date by hand
08:02:43 <cement> down that path lies a gauntlet of minor annoyances
08:03:11 <cement> also applicative, lots and lots of applicative
08:03:12 <sm> mivael: re your question, do you see different memory allocation between that parser and the non-parsec one ?
08:03:29 <mivael> sm, I will check
08:04:50 <anarcat> lyxia: figured it out, thanks! turns out you're right, Day *is* a valid type, in Data.Time
08:04:58 <anarcat> now i just need to trim a comma out of there :p
08:06:16 <sm> I guess, keep simplifying it in small steps until you see performance improve
08:19:50 <mivael> sm, yes, the memory allocation differs significantly.  Parsec vs. ad hoc: total alloc = 13,097,483,656 vs. 7,245,797,768 bytes (excludes profiling overheads)
08:20:30 <mxf> Hi *, I'm using emacs+intero/stack, what's the fastest way to add an additional dependency?
08:21:24 <mivael> sm, I'm not sure what you mean by simplifying in small steps.  Converting my ad hoc parsing to Parsec-based parsing in small steps?
08:21:37 <cocreature> mivael: re “not using attoparsec because I was advised against parsing text with ByteString-based means”: what do you mean by that? attoparsec has a Data.Attoparsec.Text module which is specifically for parsing text
08:22:11 <mivael> cocreature, oops, I did not see it
08:23:21 <mivael> cocreature, now I see it: http://hackage.haskell.org/package/attoparsec-0.13.2.0/docs/Data-Attoparsec-Text-Lazy.html
08:23:22 <merijn> Anyone aware of a package that'll let me forcibly import hidden modules? i.e. like true-name but for modules?
08:23:31 <mivael> cocreature, my bad
08:24:08 <chenyu> http://zguide.zeromq.org/hs:hwclient, why they use liftIO?
08:24:54 <cocreature> chenyu: because they need something of type "ZMQ z a" (due to the type of runZMQ) but "putStrLn …" has type IO ()
08:25:17 <chenyu> cocreature: Oh, ok, thanks a lot!
08:27:18 <dsal> I'm a little surprised pattern matching on (+) vs. (-) gives me a duplicate pattern error.
08:27:38 <geekosaur> you can't pattern match functions
08:28:02 <geekosaur> som booth of those are infix bindings the same way trying to pattern match on mempty creates a new binding instead of using the value of mempty at that type
08:28:27 <geekosaur> you can only pattern match constructors.
08:29:33 <dsal> Yeah.  The code was slightly more convenient for that when I had a distinct data type that meant what the function does, but the evaluation code was less convenient.
08:31:07 <geekosaur> @src on
08:31:07 <lambdabot> (*) `on` f = \x y -> f x * f y
08:34:07 <dsal> That actually answers a question that I had, but didn't ask. heh
08:35:21 <geekosaur> but note that just because you used something that is normally an operator, doesn't mean it has to bind a function
08:35:24 <anarcat> damnit
08:35:32 <anarcat> i just want the time as a string, why is this so hard
08:35:43 <anarcat> currentTime = formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%S%z" getCurrentTime
08:35:43 <royal_screwup21> I'm trying to get unique elements out a list. I wrote this function: uni list = foldl(\acc x -> if x not `elem` acc then acc ++ [x] else acc) [] list But it throws an error https://thepasteb.in/p/wjh036l2JQqIv I can't seem to make sense of it; what am I doing wrong?
08:35:48 <anarcat> ikiwikiMetaUpdated = "[[!meta updated=\"" ++ currentTime ++ "\"]]"
08:35:50 <anarcat> boom.
08:36:01 <geekosaur> > let add (/) (*) = (/) + (*) in add 3 4
08:36:04 <lambdabot>  7
08:36:27 <geekosaur> anarcat, time is not a constant. getCurrentTime is in IO
08:36:41 <anarcat> > "[[!meta updated=\"" ++ (formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%S%z" getCurrentTime) ++ "\"]]"
08:36:44 <lambdabot>  error:
08:36:44 <lambdabot>      Variable not in scope: formatTime :: t0 -> [Char] -> t1 -> [Char]error: ...
08:36:50 * anarcat  headdesks
08:36:51 <fakenullie> royal_screwup21: there's nub in Data.List
08:37:02 <anarcat> geekosaur: i have a hard time with IO - how do i decapsulate that stuff?
08:37:52 <royal_screwup21> fakenullie: yeah, but I want to write it from scratch. I realized what the problem was - I think "not `elem`" is syntactically incorrect
08:38:16 <fakenullie> And you're using operator the wrong way
08:38:31 <geekosaur> do { t <- getCurrentTime; return $ "[[!meta updated=\"" ++ formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%S%z" t ++ "\"]]" }
08:39:01 <geekosaur> and your function must be in IO, and again you have to use <- (or learn how do notation becomes (>>=) operator) to use the result
08:40:11 <fakenullie> > let uni list = foldl (\acc x -> if not (x `elem` ac) then acc ++ [x] else acc) [] list
08:40:14 <lambdabot>  <no location info>: error:
08:40:14 <lambdabot>      not an expression: ‘let uni list = foldl (\acc x -> if not (x `elem` ac)...
08:40:46 <geekosaur> lambdabot is not ghci
08:40:48 <anarcat> geekosaur: so it's still IO
08:40:52 <geekosaur> you haved to use the let ... in form
08:40:54 <fakenullie> @let uni list = foldl (\acc x -> if not (x `elem` ac) then acc ++ [x] else acc) [] list
08:40:56 <lambdabot>  .L.hs:165:40: error:
08:40:56 <lambdabot>      • Variable not in scope: ac :: t0 a
08:40:56 <lambdabot>      • Perhaps you meant one of these:
08:40:57 <geekosaur> anarcat, it will be in IO
08:41:04 <geekosaur> time is not a constant. it will be ion IO
08:41:09 <anarcat> geekosaur: so i can't just use it... 
08:41:12 <anarcat> i don't understand :/
08:41:21 <anarcat> now i have: ikiwikiMetaUpdated = do { t <- getCurrentTime; return $ "[[!meta updated=\"" ++ formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%S%z" t ++ "\"]]" }
08:41:27 <anarcat> and: cleanBlock (Div (id, [cls], _) [Para [Str month, Space, Str day, Space, Str year], Para _]) | cls == "GAByline" = [Plain [RawInline (Format "html") (ikiwikiMetaDate year month day),
08:41:27 <anarcat>                                                                                                                           RawInline (Format "html") ikiwikiMetaUpdated]]
08:41:32 <mivael> cocreature, unfortunately it does not seem to be supported on competitive programming sites anyway: https://www.codechef.com/view/error/15886522
08:41:38 <geekosaur> [17 15:38:38] <geekosaur> and your function must be in IO, and again you have to use <- (or learn how do notation becomes (>>=) operator) to use the result
08:41:38 <anarcat> i'm still stuck in the same place
08:42:06 <dsal> geekosaur: Yeah, that makes sense.  I was using literal (+) to represent my add op in my parser.  The only issue I had was I couldn't Show it.
08:42:13 <fakenullie> > uni "aaabbccccddaa"
08:42:15 <lambdabot>  error:
08:42:16 <lambdabot>      • Variable not in scope: uni :: [Char] -> t
08:42:16 <lambdabot>      • Perhaps you meant ‘un’ (imported from Control.Lens)
08:42:25 <geekosaur> dsal, yes, functions have no Show instance
08:42:32 <cocreature> mivael: that link is not working (restricted content) but if some competitive programming site imposes weird limitations there is probably not much you can do about this
08:42:49 <geekosaur> and can't have one aside from the trivial one in Data.Function.Show (which just produces the literal string "<function>")
08:43:05 <sm> mivael: I meant the opposite, removing things from the parsec parser until you see the memory/performance improve, because I can't see the inefficiency by code inspection (though I bet others here can)
08:43:18 <dsal> geekosaur: Right, and I couldn't make one that distinguished based on the function.  I can imagine why, but it was still a little surprising that the match just told me it was duplicate.
08:43:20 <geekosaur> well, there's a more clever one that can be used if and only if the function is monomorphic. (+) is not.
08:43:35 <fakenullie> > uni "aaabbccccddaa"
08:43:38 <lambdabot>  "abcd"
08:43:39 <anarcat> geekosaur: so i tried RawInline (Format "html") <- ikiwikiMetaUpdated..., but that still fails
08:43:44 <anarcat> i feel i'm missing some fundamentals
08:43:47 <geekosaur> what is it to do? it's the same situation as: foo a = ...; foo b = ...
08:44:12 <fakenullie> royal_screwup21: uni list = foldl (\acc x -> if not (x `elem` acc) then acc ++ [x] else acc) [] list
08:44:14 <dsal> Yeah, I guess that makes sense.
08:44:26 <fakenullie> royal_screwup21: but I think foldr is better
08:45:08 <royal_screwup21> thanks! "`notElem`" is apparently a thing as well...
08:45:13 <geekosaur> @where iotut
08:45:13 <lambdabot> https://www.vex.net/~trebla/haskell/IO.xhtml
08:45:19 <geekosaur> ^ anarcat
08:46:44 <mivael> sm, I'm not sure I understand how to replace Parsec-based code pieces with non-Parsec-based ones...  For example, I'm not sure by what I should replace (oneOf "#.") part without changing the rest of Parsec-dependent code.
08:48:56 <sm> mivael: well, eg you could make that char '.' and see if it has an impact
08:49:20 <anarcat> geekosaur: i'm still completely confused :(
08:49:22 <cocreature> mivael: tbh I’m not sure what you’re looking for. parsec is going to be slower than a handtuned parser in most cases
08:49:27 <anarcat> geekosaur: sorry, but i don't know if i can grok this
08:49:54 <anarcat> i tried to add a do {} block, but it still fails on IO errors
08:49:57 <geekosaur> you need to, either via that (which seems to work for most people, better than the usual learning materials) or some other source
08:50:11 <geekosaur> you will likely have to add IO types to things
08:50:13 <anarcat> current code is: http://paste.debian.net/991280/
08:50:48 <sm> cocreature: I think mivael was wondering why, and if it was an inefficienty in their one line parser. Or maybe parsec just has a fixed overhead
08:51:39 <mivael> cocreature, I'm looking for a fancy (yet fast) text parsing solution that would work on competitive programming sites...  I want to avoid boilerplate code of hand-tuned solutions.
08:52:03 <geekosaur> anarcat, since you are using IO in one leg of the cleanBlock definition, you need to use it in all of them
08:52:19 <anarcat> geekosaur: ouch.
08:52:32 <anarcat> geekosaur: unfortunately, that's basically impossible - those definitions are constrained from outside
08:52:33 <cocreature> mivael: if megaparsec and attoparsec don’t work on those sites then I don’t think there is anything you can do apart from complain to the people hosting these sites
08:52:54 <anarcat> geekosaur: this is a pandoc filter, which has predefined type primitives
08:53:05 <mivael> cocreature, this is what I'm going to do, then   :)
08:53:10 <geekosaur> then you cannot use the current time
08:53:24 <geekosaur> yes, there is a hack that would typecheck. no, it will not do the right thing.
08:53:59 <anarcat> geekosaur: that sounds nuts
08:54:15 <anarcat> geekosaur: i can't output the current time in a pandoc filter, is what you're saying
08:54:32 <cocreature> mivael: just to be clear, I’m not trying to say that wanting a fast parser is not a reasonable request. I’m just saying that parsec is not the right tool for that job and if you’re really stuck with it you’re just going to have to accept that there is some overhead
08:54:50 <byorgey> anarcat: what do you mean, a pandoc filter has predefined type primitives?
08:55:02 <byorgey> anarcat: isn't a pandoc filter just an arbitrary program that reads from stdin and writes to stdout?
08:55:08 <anarcat> byorgey: sure
08:55:15 <byorgey> anarcat: well, then, it can do IO.
08:55:19 <anarcat> byorgey: yes.
08:55:43 <anarcat> byorgey: but i made the bad choice of writing it in haskell, with Text.Pandoc.JSON and toJSONFilter expects certain things
08:56:00 <byorgey> anarcat: where are those defined?
08:56:13 <anarcat> frankly, i don't know anymore
08:56:21 <mivael> cocreature, I just wanted to investigate first: whether I'm stuck with Parsec performance, or maybe I'm using it inefficiently.  How could I know that?
08:56:29 <geekosaur> it sounds to me like you are doing something wrong, but if this is your reaction to Haskell then yes, go elsewhere.
08:56:30 <byorgey> ah, in pandoc-types
08:56:40 <byorgey> anarcat: hang on, let me take a look
08:56:46 <mnoonan> https://hackage.haskell.org/package/pandoc-types-1.19/docs/Text-Pandoc-JSON.html
08:56:56 <mnoonan> says you can use a function of type "a -> IO a"
08:57:12 <byorgey> anarcat: toJSONFilter can take... what mnoonan just said
08:57:44 <cocreature> mivael: a factor of two sounds sounds like you’re just hitting the performance penalty imposed by parsec
08:57:45 <warbo> here's a pandoc filter written in Haskell, using toJSONFilter, which executes arbitrary shell code: https://hackage.haskell.org/package/panpipe-0.2.0.0/docs/src/PanPipe.html#panpipeMain
08:57:59 <warbo> so it's possible to do IO ;)
08:58:03 <anarcat> this is what i have so far: https://gitlab.com/anarcat/scripts/blob/master/lwn-clean.hs
08:58:09 <anarcat> okay, well, i haven't figured out how to do that
08:58:18 <anarcat> i guess i'm just not a haskell programmer just yet :)
08:58:39 <mivael> cocreature, thank you for this hint
08:58:45 <geekosaur> mivael, there is attoparsec which is significantly faster than parsec but has its own restrictions
08:59:06 <geekosaur> (like worse error reporting)
08:59:28 <byorgey> anarcat: you'll have to rewrite that a bit to make cleanBlock have type Block -> IO [Block], and then cleanAll will have type  Pandoc -> IO Pandoc
08:59:55 <byorgey> anarcat: and note you can't just change the types, you'll have to rewrite them a bit.  But it is definitely possible.
09:00:13 <warbo> hello all, I'm trying to learn lens and lens-aeson, to 'pull out' some data from JSON objects and add a new field based on the results
09:00:22 <anarcat> byorgey: alright, thanks!
09:00:32 <mivael> geekosaur, as I said earlier, it seems to be not supported on competitive programming sites like codechef.com: Failed to load interface for ‘Data.Attoparsec.Text.Lazy’
09:00:35 <warbo> I've got a program which type checks and builds, but isn't adding the new field
09:00:58 <byorgey> anarcat: definitely check out the tutorial geekosaur linked, https://www.vex.net/~trebla/haskell/IO.xhtml
09:01:26 <anarcat> yeah well, the problem is i read that stuff over and over again
09:01:30 <mivael> geekosaur, ...and I'm going to complain about that
09:01:36 <warbo> my functions have types like `Value -> Value`, but I want them to have something like `Value -> Either ErrorMessage Value`
09:01:37 <anarcat> i either don't really understand it, don't use it, or forget it
09:01:57 <anarcat> i mean i went through haskell for a great good... 
09:02:00 <warbo> or perhaps `Value -> ([ErrorMessage], Value)`
09:02:33 <warbo> and basically let me tell whether a lens (actually, a prism) has "failed" to pull out the required data
09:02:52 <geekosaur> mivael, there are a few tricks you can try to speed things up, mostly refactorings, but by and large this is just the price you pay to get decent error messages and such. any parser with good error reporting will add overhead, sometimes significant overhead.
09:03:14 <geekosaur> anarcat, LYAH is kinda lousy for actually learning.
09:03:18 <EvanR> megaparsec supposedly has good errors
09:03:19 <byorgey> anarcat: have you read that specific tutorial before?  or just LYAH?
09:03:20 <geekosaur> @wherfe cis194
09:03:20 <lambdabot> http://www.seas.upenn.edu/~cis194/spring13/
09:03:27 <EvanR> or lets you put your own good errors
09:03:32 * byorgey also doesn't really like LYAH.
09:03:41 <geekosaur> but megaparsec's not muh faster than parsec
09:03:47 <anarcat> byorgey: i must admit i haven't
09:04:02 <EvanR> according to the docs, the latest megaparsec "is much slower than" attoparsec, if you do it right
09:04:11 <EvanR> "is NOT much slower than"
09:04:36 <geekosaur> that's good. but I bet the site that doesn't have attoparsec also doesn't have megaparsec, much less the latest version thereof
09:04:42 <EvanR> but also, attoparsec has its own issues
09:04:59 <byorgey> anarcat: well, give it a try.  Even just reading several different tutorials, even if they are not that great, can help a lot since you get different perspectives.  And IMO this particular tutorial is pretty good.
09:05:05 <EvanR> ah didnt know this was about some site
09:05:07 <geekosaur> and 'if you do it right' that's likely the same thing I said earlier about refactoring the grammar
09:05:09 <dsal> From reading docs, megaparsec was the easiest to get going.
09:05:57 <anarcat> byorgey: the problem is i'm having basic trouble with the language syntax
09:06:01 <supercynic> warbo: a lens never fails to pull out the data…  however, a traversal can "fail" (it can point to nothing)
09:06:17 <anarcat> byorgey: i just can't wrap my head around all the syntactic sugar... ie. <$> >>= <- ... it's all very confusing to me
09:06:25 <anarcat> it reminds me of learning perl, except harder
09:06:28 <supercynic> warbo: you can use something like 'has' to check whether there are points
09:06:34 <anarcat> because there are too many ways of doing the same thing
09:06:46 <supercynic> > (has traverse [], has traverse [()])
09:06:48 <lambdabot>  (False,True)
09:06:52 <supercynic> warbo: ^
09:07:29 <warbo> supercynic: yeah, I saw `has`, but can't figure out how to compose such "lenses with failure"
09:07:40 <supercynic> warbo: you can also use a traversal as, well, a traversal, so you can use some effect to signal that you found points while processing them
09:07:49 <warbo> (other than using `error "foo not found"`)
09:08:15 <supercynic> warbo: a lens cannot fail
09:08:28 <warbo> supercynic: yes, hence the quotes
09:08:29 <EvanR> anarcat: haha, timtowdi?
09:08:36 <warbo> maybe I should have said "optic"
09:08:55 <anarcat> EvanR: yeah, that.
09:09:07 <supercynic> warbo: lenses point to exactly one thing and are a special case of a traversals, which can point to arbitrarily many things, including zero
09:09:10 <EvanR> there are many ways to do stuff, regardless of haskell
09:09:23 <supercynic> warbo: for example 'traverse' can be used as a traversal into a list's elements
09:09:25 <EvanR> many ways that havent been invented yet
09:09:36 <supercynic> warbo: and 'has' checks whether it has any points on a specific value
09:09:40 <EvanR> never stop learning
09:10:00 <supercynic> warbo: _Just is a traversal into the payload of a (Maybe a), which of course may not exist
09:10:05 <supercynic> > has _Just (Just 5)
09:10:08 <lambdabot>  True
09:10:09 <supercynic> > has _Just Nothing
09:10:12 <lambdabot>  False
09:10:12 <warbo> anarcat: `<-` is syntactic sugar (it's part of "do notation"). Those other things are just function names (although admittedly they're a bit funky looking)
09:10:20 <EvanR> youre brain is like a muscle, the more you exercise it, the more it can lift. but you need heavier stuff to progress afterward
09:10:27 <EvanR> your*
09:10:54 <anarcat> yep
09:11:04 <supercynic> warbo: so the first step is to have a proper (i.e. non-lens) traversal in the first place
09:11:28 <supercynic> warbo: proper traversals composed with traversals are proper traversals (remember: lenses are traversals as well)
09:17:39 <warbo> supercynic: thanks, I'll do some experimenting :)
09:26:12 <buttbutter> Does #haskell have a sort of #not-haskell channel for more casual/don't-want-to-spam the channel sort of things? 
09:27:15 <geekosaur> #haskell-offtopic ?
09:27:29 <buttbutter> geekosaur: thanks
09:35:55 <supercynic> warbo: BTW, one particular function i found very handy for these use cases is 'zoom'
09:36:25 <supercynic> warbo: if you use a state monad to manipulate your structure, you can 'zoom' into its substructures
09:37:06 <supercynic> warbo: the really nice part is that you can 'zoom' into traversals, which means that the zoom action will run for every individual point
09:37:39 <supercynic> there is also a reader variant called 'magnify'
09:37:54 <warbo> supercynic: I've come across that before, but not looked too hard at it (since I don't use monad transformers)
09:38:50 <warbo> supercynic: I think the reason for my confusion was that many of the lens/optics functions have an `f` in their type, which I thought I could use for this error logging
09:39:28 <warbo> supercynic: but my top-level function is using `values` from lens-aeson, which doesn't have this Applicative in its type
09:39:45 <supercynic> warbo: not quite…  the lens operators always insist on a particular 'f' that really has only effects that are interesting for the task at hand (like reading the point of a lens)
09:40:25 <warbo> ah ok
09:40:28 <supercynic> for example 'over' will insist on (f = Identity), while 'view' will insist on (f = Const a)
09:41:47 <warbo> I suppose a simple `toListOf` and `mapM` would do the trick though
09:42:30 <warbo> oops, I mean `sequence` not `mapM`
09:46:03 <royal_screwup21> I'm trying to write a function to determine if a number is prime, like so: isPrime k = null [ x | x <- [2..sqrt k], k `mod`x  == 0] But this throws an error https://thepasteb.in/p/wjh036EJvZ9hv I'm guessing it's expecting k to be a float? I tried isPrime 5.0 but that didn't work as well
09:47:12 <warbo> royal_screwup21: if you use `5.0`, it's hard to fathom what numbers would be included in `[2..sqrt k]`
09:47:42 <mivael> sm, tried your advise...  building a [Bool] seems to be a bottleneck: parseRow = fmap (== '#') <$> many1 (oneOf "#.")
09:47:44 <royal_screwup21> hmm true. So I guess I'm going to have to typecast sqrt k to an int?
09:48:08 <warbo> royal_screwup21: no, that's very dubious
09:48:17 <warbo> royal_screwup21: what you want to do is round it up
09:48:26 <warbo> try the `ceiling` function
09:48:40 <mivael> sm, at least, this debug version works significantly faster: parseRow = (const . take 1000 . repeat $ True) <$> many1 (oneOf "#.")
09:50:55 <royal_screwup21> warbo: so I tried this: isp k = null [i | i <- [2..ceiling $ sqrt k], k `mod`i==0] - but it throws the same error
09:52:06 <dsal> :t ceiling
09:52:08 <lambdabot> (Integral b, RealFrac a) => a -> b
09:52:08 <warbo> royal_screwup21: what's the error? I'm getting an "ambiguous type variable" message
09:52:21 <royal_screwup21> https://thepasteb.in/p/wjh036ExWzpFv
09:54:45 <royal_screwup21> I don't get it
09:54:59 <cement> afaik, you neeed to put a type annotation
09:54:59 <dsal> What's the type of isp?
09:55:06 <warbo> ok, so the `sqrt` is problematic for 2 reasons: it takes a float in, and it gives a float out
09:55:20 <royal_screwup21> isp :: (Floating a, Integral a, RealFrac a) => a -> Bool
09:55:24 <warbo> `ceiling` can round up the result
09:55:45 <royal_screwup21> we did that
09:56:05 <royal_screwup21> type annotation hmm
09:56:10 <warbo> but we need `fromIntegral` to convert `k` from a whole number into a float
09:56:36 <warbo> so `ceiling (sqrt (fromIntegral k))`
09:56:40 <cement> right, but then you need to "remind" GHC what type you're expecting to get back
09:56:41 <dsal> You may also just want to pass k in as an Integer.    isp :: Integer -> Bool   seems a lot more reasonable.
09:56:53 <Tuplanolla> Besides, `ceiling . sqrt` is always a mistake.
09:58:21 <cement> the list comprehension approach can work, but you need [2.0,3.0..sqrt k]
09:58:48 <dsal> Why 3.0?
09:58:57 <dsal> > [2.0 ..]
09:58:59 <warbo> to indicate the step size
09:59:01 <lambdabot>  [2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18....
09:59:15 <warbo> ah
09:59:32 <warbo> explicit vs implicit though :)
09:59:38 <dsal> I kind of hoped succ on a floating point number would be epsilon.
10:00:19 <dsal> You don't need to do all the math with floating point, though.  The sqrt is there just to not do too much work.
10:00:42 <cocreature> Tuplanolla: why is ceiling . sqrt a mistake?
10:01:07 <Tuplanolla> It's susceptible to rounding errors, cocreature.
10:01:19 <warbo> dsal: or Enum could just enumerate bitstrings and read them as Floats.... ;)
10:01:47 <dsal> Yeah, that's basically how I hoped it'd work.  I guess that's doable.
10:03:02 <warbo> dsal: pretty sure that wouldn't be incrementally adding epsilon though; it would spend at least some time flipping sign and exploring all of the NaNs
10:03:54 <dsal> Yeah, I never got a great mental model for floating point.
10:04:55 <cement> anyone have experience with STM?
10:05:08 <dsal> I used it once!
10:05:39 <cocreature> Tuplanolla: ah good point, thx!
10:05:49 <cocreature> cement: yes but you are going to get better answers if you ask your actual question :)
10:06:23 <cement> I've got a function that does ~3 things, and ideally I want to run that function on some arbitrarily high number of threads (waiting on network so slow)
10:06:50 <cement> is it better to atomically do each of the 3 things, or atomically run the whole function?
10:06:56 <dsal> What are the things?
10:07:38 <cement> talk to network (up to 3 times) using a queue, shuffle some data, add more to queue
10:07:40 <cocreature> cement: do you want for the 3 things to be a single atomic operation or not?
10:07:45 <dsal> I'd expect "better" would be whichever is more correct.  If you need three things to happen atomically, then they must.  If they can happen independently, you'll have less contention if you don't try to do them at the same time.
10:07:52 <cocreature> you can’t atomically talk to the network
10:07:54 <Tuplanolla> I don't have a counterexample of this particular instance, but here's the previous one, cocreature.
10:07:56 <dsal> You can't mix IO and STM
10:08:08 <Tuplanolla> > 4 ^ 3
10:08:11 <lambdabot>  64
10:08:23 <Tuplanolla> > floor (64 ** (1 / 3) :: Double) -- Thus this ought to be 4.
10:08:26 <lambdabot>  3
10:09:45 <cement> but I can do the data shuffling and queue adding (or subtracting in weird cases) atomically. hmmm
10:11:31 <cocreature> cement: step 1. figure out if you need these two steps to be a single atomic operation or not
10:11:59 <Lokathor> so in rust they introduced a cool method for floats that's basically, fromBits :: Word32 -> Maybe Float
10:12:32 <Lokathor> where it throws out NaN results but any other bit pattern that's an allowed float is just converted bitwise instead of trying to arrive at the same number
10:13:36 <Lokathor> so my question is: can I do that somehow in Haskell?
10:14:05 <cement> they're basically atomic (together) already, as in, the data shuffling "modifies" the queue (it's a pure function rn) and then does a tail-recursion
10:14:56 <cocreature> cement: can you show us some code?
10:18:26 <cement> http://lpaste.net/359325
10:19:18 <cement> eachThread is the functionality that needs to be concurrent (each IO [a] can take up to 3 seconds to complete)
10:21:32 <cocreature> cement: alright, what happens if you call getMore, then some other thread modifies the data, and then getCurrentThings is called? does that cause problems/is it possible in your application? if so, you need them to be atomic, if things like that cannot occur or do not pose a problem then wrap each of them separately in atomically
10:22:47 <cement> modifies the data returned from getMore?
10:23:20 <cocreature> some data accessed by getMore,/getCurrentThings/getOtherStuff. it’s hard to say since you’re not showing us those definitions :)
10:24:06 <cement> ok, that data isn't ever modified, just moved around and collated etc by shuffleTheData
10:24:39 <cocreature> if your data is never modified, then you don’t need to worry about atomicity.
10:24:52 <cocreature> but if you only have read-only data I’m also not sure what you need STM for in the first place
10:25:26 <cement> because of the "queue" which is the first parameter for eachThread
10:26:05 <cocreature> so the queue is part of the data accessed by the threads and it probably is modified!
10:26:33 <cocreature> I think it might be helpful if you show us teh definitions of getMore, getCurrentThings and getOtherStuff so we can give you concrete examples of potential problems
10:28:48 <monochrom> Every thread cannot even see the parameters and local bindings of other threads.
10:30:13 <cement> right.
10:30:45 <cement> the only things that the threads should share is the queue and return list
10:30:56 <monochrom> What queue?
10:31:34 <monochrom> Where is the queue in your shown code?
10:33:07 <cement> the "queue" is the first list in the function arguments
10:33:21 <monochrom> <monochrom> Every thread cannot even see the parameters and local bindings of other threads.
10:33:31 <cocreature> why do you need STM to access elements in a list?
10:33:40 <portnov> ping?
10:33:57 <cocreature> portnov: pong
10:34:28 <cement> I'm probably going to rewrite that argument to be a TQueue
10:34:46 <portnov> hi all
10:34:57 <Gurkenglas> How do I find the cause of an infinite loop?/join #emacs
10:34:59 <Gurkenglas> Dangit
10:35:13 <monochrom> Look, if I have two threads and each thread computes "fib 5", is it meaningful to say "the two threads share 5"?
10:35:48 <cement> I don't think so, no
10:35:54 <monochrom> Same with lists.
10:36:13 <monochrom> Our Haskell lists are as immutable as 5. Think math.
10:36:32 <cocreature> cement: maybe start writing the code you actually want (TQueue instead of list, …) and then worry about atomicity
10:36:52 <monochrom> At most you can say the two threads begin with the same initial conditions. But henceforth they don't even know what the other thread is doing.
10:38:05 <monochrom> More specifically they don't know how the other thread consumes the list and what is the progress.
10:38:47 <monochrom> If one thread is giving the starting list [1,2,3,4,5] it is going to walk through 1,2,3,4,5 because that's all it sees.
10:38:56 <monochrom> If another thread is giving the starting list [1,2,3,4,5] it is going to walk through 1,2,3,4,5 because that's all it sees.
10:39:00 <cement> my issue is that I'm not quite sure how to start writing the code I want. is it sensible to pass the queue as an argument, or do I need to do like "readMVar" and then pass the result?
10:39:12 <monochrom> Oh it happens that both threads walk through [1,2,3,4,5].
10:39:20 <portnov> Any data/type family specialists around?
10:39:36 <portnov> I have a trouble with exporting/importing data family constructors
10:39:40 <portnov> https://gist.github.com/portnov/c6cd459ece6e4681b256a0e7d626e8fb
10:40:06 <portnov> Maybe I'm exporting something wrongly?
10:40:32 <monochrom> So read Simon Marlow's book? http://chimera.labs.oreilly.com/books/1230000000929
10:40:52 <monochrom> Read it 3 more times.
10:41:42 <monochrom> No, s/read/study/
10:42:00 <cement> yeah, I'm on pass 1 of that book, and the impression I got was that I should rethink my function's semantics before trying to make it concurrent
10:43:14 <Tuplanolla> > 16777217 ^ 2
10:43:17 <lambdabot>  281475010265089
10:43:22 <Tuplanolla> > ceiling (sqrt 281475010265089 :: Float) -- Here's your counterexample, cocreature.
10:43:25 <lambdabot>  16777216
10:43:43 <cement> you've actually helped me already, I should probably have the function use a single element from the queue instead of having the function see/use the whole thing
10:44:02 <cocreature> Tuplanolla: nice, thx!
10:44:40 <Tuplanolla> I should collect these somewhere so that I don't need to derive them every time this topic comes up.
10:45:42 <Gurkenglas> I'm trying to find an infinite loop with ghci, but hspec throws some missing-config-file exceptions to itself early on. Can I catch only exceptions that nobody else catches, or only those that come from manual Ctrl-C?
10:47:28 <cocreature> Gurkenglas: for ctrl-c, catch AsyncException and rethrow if it’s not UserInterrupt https://hackage.haskell.org/package/base-4.10.0.0/docs/Control-Exception.html#v:UserInterrupt
10:47:57 <Gurkenglas> How do I tell ghci that?
10:48:25 <cocreature> use "catch" and write an appropriate handler
10:49:17 <Gurkenglas> But ghci breakpoints on the throwing of exceptions, not when they'd stop the program because nobody caught them
10:49:59 <Gurkenglas> stack test --profile worked yesterday, then when it didn't work we figured out in the channel that I have to kill the previous instance before starting the next. This time it errors like so: http://lpaste.net/6837737666381873152
10:50:26 <Gurkenglas> Did running it with other rts flags since it worked break it?
10:51:22 <cocreature> what exactly are you doing in ghci? are you using the builtin debugger? by default ghci doesn’t set any breakpoints
10:52:07 <cocreature> also maybe try a "stack clean" and see if it helps
10:52:52 <jle`> nano-: you can use withArray
10:53:23 <Lokathor> the answer to my earlier question is, it seems, "use GHC 8.4"
10:53:43 <Gurkenglas> cocreature, I followed https://downloads.haskell.org/~ghc/7.4.1/docs/html/users_guide/ghci-debugger.html -> "Debugging Exceptions"
10:54:11 <cocreature> Lokathor: there is wordToDouble in https://hackage.haskell.org/package/data-binary-ieee754-0.4.4/docs/Data-Binary-IEEE754.html#v:wordToDouble for older versions but it doesn’t have the NaN behavior you’re describing
10:54:27 <Lokathor> what does it do for NaNs?
10:54:39 <cocreature> I think it just gives you back a NaN
10:55:27 <Lokathor> I was told that some NaN values cause things to be flagged and stuff in the CPU, which is why you'd want a bit conversion to get a silent NaN
10:56:13 <cocreature> Gurkenglas: sounds like you can use -fbreak-on-error and then wrap the code you’re running in a catch that catches everything apart from UserInterrupt
10:56:48 <Lokathor> i guess using that and then running isNaN on it works
10:57:01 <Gurkenglas> You mean ":trace catch … main …"
10:57:09 <cocreature> yes
10:59:22 <anarcat> byorgey: thanks for the reference to the IO tutorial, quite helpful
10:59:50 <anarcat> byorgey: one bit seems to be missing in my context - most of my functions do *not* return "IO a" - how do i "fake" return IO?
11:00:04 <Gurkenglas> http://lpaste.net/9000122385587765248 <- https://github.com/Gurkenglas/ord-graph/blob/master/ord-graph.cabal means that test doesn't build src, right?
11:00:40 <anarcat> or wait
11:00:46 <anarcat> should i pass the time downwards maybe...
11:02:22 <nano-> jle`: thanks!
11:03:08 <madknight> anarcat, it returns IO plus the terminal object ()
11:04:00 <anarcat> madknight: sorry?
11:04:50 <madknight> anarcat, a object is terminal if for every object X in the (Category) C there exists a single morphism X -> T
11:05:42 <anarcat> ah
11:06:14 <madknight> anarcat, and this is the case for () in Hask
11:06:22 <Gurkenglas> cocreature, but since all other exceptions are already caught anyway, I shouldn't wrap main, right? (*tries it* nope Ctrl-C aborts the computation without triggering a breakpoint)
11:07:24 <cocreature> Gurkenglas: then I don’t understand what your problem actually is. you said ghci was stopping on exceptions and you want to catch them and now you’re saying they’re already caught and ghci is not stopping?
11:07:49 <anarcat> madknight: i'm not sure i follow
11:07:58 <Gurkenglas> The program throws exceptions and then catches them and then goes into an infinite loop
11:08:07 <Gurkenglas> I want to step through what it's doing during the loop
11:08:10 <anarcat> but what i'm trying to do is to generate a formatted string representing the current time in the following pandoc filter: https://gitlab.com/anarcat/scripts/blob/master/lwn-clean.hs#L43
11:08:30 <anarcat> from what i understand i need to rewrite all my functions to do IO foo instead of just foo
11:08:43 <anarcat> but then that means i must make normal functions return IO, and i'm not sure how to do that
11:08:54 <Gurkenglas> -fbreak-on-exceptions breaks on the irrelevant exceptions at the start, -fbreak-on-error doesn't seem to break on my manual Ctrl-C during the infinite loop
11:09:29 <dsal> anarcat: That sounds like a design problem.  Generally you separate the that do IO from pure functions.
11:09:42 <anarcat> dsal: yep
11:10:01 <anarcat> dsal: i'm not sure how to fix that... the "IO" i am doing is just fetching the time
11:10:10 <dsal> Yeah, that's a side effect.
11:10:19 <dsal> You can give it the time in a few different ways.
11:10:33 <dsal> Directly is easy if that makes sense.
11:10:38 <dwrodri> anyone in here happen to have any experienec using the dot2graphml package? just tryng to convert some files using the library.  
11:11:24 <madknight> anarcat, you can define pure functions and call them from your IO function
11:11:27 <anarcat> dsal: i was thinking of passing the timestamp down from main, but i'm not sure how to do that given the prototypes i have now: https://gitlab.com/anarcat/scripts/blob/master/lwn-clean.hs#L94
11:11:42 <anarcat> i don't quite understand what i did there with the "bottomUp" stuff
11:12:07 <dsal> What's that doing with time?
11:12:42 <anarcat> this is all stuff i cargo-culted from pandoc's john macfarlane :p
11:13:00 <anarcat> dsal: i want to put the text representation of the current time in the heading of the document
11:14:00 * hackagebot pretty-simple 2.0.1.0 – pretty printer for data types with a 'Show' instance. – https://hackage.haskell.org/package/pretty-simple
11:14:22 <cmotoche> Is it possible to use conditional to check values on Hakyll? Something like: `$if(thing == x)$ ...`  
11:15:13 <madknight> anarcat, maybe you should try another thought model, instead of passing the time around functions, think of it as applying functions to the time
11:15:29 <humanoyd> Is there a more elegant way for writing `(,) <$> f1 a <*> f2 a`, i.e. without repeating `a`?
11:16:29 <anarcat> madknight: i'm not sure i see the difference
11:16:45 <Apocalisp> humanoyd: ((,) <$>) . (<*>) <$> f1 <*> f2
11:17:03 <erisco> humanoyd, yes, it is  liftA2 (,) <$> f1 <*> f2
11:17:51 <madknight> anarcat, you can apply pure functions to no pure "stuff" like a timestamp
11:18:20 <anarcat> madknight: sure
11:19:32 <madknight> anarcat, so you don't have to rewrite all your functions "to do IO foo instead of just foo"
11:19:35 <anarcat> madknight: the question, in my case, is how do i gracefully pass down a time value from main (which would presumably do the time I/O) down into those functions, through the bottomUp stuff
11:19:46 <anarcat> madknight: i.e. https://gitlab.com/anarcat/scripts/blob/master/lwn-clean.hs#L94
11:20:19 <anarcat> i guess i should just split out the dateparsing out of cleanBlock eh
11:20:55 <madknight> anarcat, as i said you don't pass the time value around, you apply pure functions to it, as you already agreed is possible
11:21:10 <anarcat> see, i don't understand the different here
11:21:24 <humanoyd> erisco: Thanks!
11:21:45 <anarcat> difference*
11:21:53 <madknight> anarcat, so you need to call your pure functions form your IO function acting on your timestamp
11:21:56 <humanoyd> Apocalisp: hm, that doesn't work here
11:24:01 <madknight> anarcat, http://lpaste.net/359331
11:24:41 <anarcat> madknight: won't that return a IO a?
11:25:15 <Apocalisp> humanoyd: How about `liftA2 (,) . f1 <*> f2`
11:27:29 <dsal> Yeah, that function is   :: IO String
11:27:44 <humanoyd> Apocalisp: that works :) thx!
11:27:53 <Apocalisp> :)
11:28:20 <erisco> liftAn f <$> g1 <*> g2 ... <*> gn = \x -> f <$> g1 x <*> g2 x ... <*> gn x
11:28:32 <madknight> anarcat, its perfectly fine to return IO a, you can also return IO String or IO Int
11:28:32 <Apocalisp> liftA2 (,) <$> f1 a <*> f2 a = (,) <$> f1 a <*> f2 a
11:29:18 <anarcat> madknight: but i thought the *whole* point here was to *not* have to change the signatures on all the functions to return IO a
11:29:18 <dsal> madknight: Sure, but now everything has to be in the IO monad because something somewhere wants the time.  I think anarcat was looking for a way to avoid that.
11:29:36 <anarcat> dsal: in fact, that's what you were saying was a bad design, no? :)
11:29:36 <ski>   liftA2 (,) (f1 a) (f2 a) = (,) <$> f1 a <*> f2 a  -- itym, Apocalisp
11:29:48 <madknight> anarcat, i think you need to shift your logic, code "inside" a function that is IO such as main and then call your pure functions from there
11:29:52 <ski> @type \f1 f2 -> liftA2 (liftA2 (,)) f1 f2
11:29:54 <lambdabot> (Applicative f2, Applicative f1) => f1 (f2 a) -> f1 (f2 b) -> f1 (f2 (a, b))
11:30:03 <Apocalisp> what ski said
11:30:03 <ski> @type (liftA2 . liftA2) (,)
11:30:05 <lambdabot> (Applicative f2, Applicative f1) => f1 (f2 a) -> f1 (f2 b) -> f1 (f2 (a, b))
11:30:21 <anarcat> holy crap i made it
11:30:28 <ski> in this case, `f1 = (a ->)'
11:30:29 <dsal> anarcat: To be fair, I said it's a design problem.  :)  It may not be bad design here if you can't express what you're doing in a pure function.  Passing around the data could be OK.
11:31:10 <madknight> dsal, everything starts with the main function that already is IO, so you cant "escape" IO (without bad tricks)
11:31:21 <anarcat> dsal / madknight / byorgey / geekosaur : last diff: http://paste.debian.net/991315/
11:31:25 <erisco> and because  liftAn f g1 g2 ... gn = f <$> g1 <*> g2 ... <*> gn  then  liftAn f <$> g1 <*> g2 ... <*> gn = (liftAn . liftAn) f g1 g2 ... gn
11:32:03 <anarcat> so basically, i split out the date processing code in a separate function
11:32:15 <anarcat> then get the time in main, since that's already IO
11:32:25 <anarcat> and then i craft a function that does Pandoc -> Pandoc normally out of that
11:32:28 <ski>   (,) <$> f1 a <*> f2 a  =  liftA2 (,) (f1 a) (f2 a)  =  (liftA2 (,) <$> f1 <*> f2) a  =  liftA2 (liftA2 (,)) f1 f2 a  =  (liftA2 . liftA2) (,) f1 f2 a
11:32:32 <anarcat> to pass to JSONwhatever
11:32:34 <dsal> madknight: Well, yes, but that doesn't mean every function is inherently impure because it's called by something impure somewhere up the stack.
11:33:05 <anarcat> dsal: so i pass the "time" down the stack - does that make sense?
11:33:30 <ski> (dsal,madknight : fwiw, something of type `IO Blah' is not a function. it's an I/O action)
11:33:59 <dsal> anarcat: That makes sense to me.
11:34:01 <madknight> dsal, well no because we carry around the state of the whole universe (or so is the thought modell) and return a modified version of it when our haskell programm terminates
11:34:05 <anarcat> dsal: awesome
11:34:31 <anarcat> now the only problem i have left is that the timestamps are UTC :p
11:35:00 <ski> impure/pure is a matter of perspective .. a matter of which language you use to describe things
11:35:25 <anarcat> it's kind of comforting that my problem brought you guys in a philosophical debate
11:35:30 <ski> in Haskell, everything (including I/O) is pure
11:35:33 <anarcat> i'm not such a crap haskell programmer after all :p
11:35:55 <madknight> dsal, so the main function takes the state of the universe, acts on the universe and returns the modified universe and thats pure by definition, thats why its called a pure language
11:38:03 <ski> (I/O is not a side-effect, because there's no "side" to it (in Haskell). we're, *explicitly* (not implicitly) representing the *effects* (Input/Output, or other kinds of effects, as the case may be); one can't use a value of type `IO Blah' in place of a value of type `Blah', or vice versa. one can use `return' to explicitly convert in *one* direction, though)
11:39:32 <madknight> in the official documentation they name it RealWorld instead of whole universe (but its the same) main :: RealWorld -> ((), RealWorld) you can read about it here https://wiki.haskell.org/IO_inside
11:39:51 <ski> @quote the.cake
11:39:51 <lambdabot> ski says: <ski> `getLine :: IO String' is a recipe for how to interact with the world to acquire a `String'  <ski> the recipe is not the cake
11:39:53 <ski> @quote /bin/ls
11:39:53 <lambdabot> shachaf says: getLine :: IO String contains a String in the same way that /bin/ls contains a list of files
11:40:58 <ski> in Clean, it's `Start :: *World -> *World' (the `*' signifies that you've got a unique reference (which can't be copied; can't have the cake and eat it too))
11:42:32 <ski> Haskell doesn't have uniqueness typing in the type system, though. so instead of `type IO a = *RealWorld -> (a,*RealWorld)', we have `IO' as an abstract data type. but as an initial approximation, you may use this picture of it
11:43:14 <madknight> and it also includes all possible parallel universes, although i'm not quiet sure about that one :)
11:44:52 <ski> (one problem with this "world-passing" view is that it's hard to see how to handle declarative concurrency (e.g. how `unsafeInterleaveIO' or `unsafeInterleaveST' can be used), and non-declarative (with race conditions) concurrency is even harder. for the former, one'd need to split the world up into smaller (non-interacting) pieces, the puzzle them together later. for the latter, one need to handle interaction between them as well)
11:45:59 * hackagebot text-format-heavy 0.1.4.0 – Full-weight string formatting library, analog of Python's string.format – https://hackage.haskell.org/package/text-format-heavy
11:45:59 * hackagebot ginger 0.7.2.0 – An implementation of the Jinja2 template language in Haskell – https://hackage.haskell.org/package/ginger
11:46:32 <ski> (think mutices, condition variables, semaphores, messages, mailboxen, channels, &c.)
11:47:03 <madknight> ski, is there any thought model that fits `unsafeInterleaveIO`?
11:48:37 <ski> (a) the same as for `unsafeInterleaveST'
11:49:14 <ski> (b) one can think of it as concurrency. the computation is scheduled to occur "sometime later", but before you access the result (when demanding it). it just so happens that it always seems to happen right before you demand it (and gets perpetually postponed, if you don't demand it)
11:51:09 <ski> one problem with (b) is that this doesn't give you a detailed explanation of exactly when it happens -- but what can you expect, when compiler optimizations possibly may reshuffle your code ("compiler refactoring",deforestation,other optimizations) so that things are demanded in another way than the simplistic one you had in mind ?
11:52:19 <ski> i wonder whether it'd be possible to (formally) translate data dependencies into (partial) ordering of the corresponding I/O actions ..
11:53:19 * osfameron giggles at "mutices"
11:55:28 <tdammers> mutices and mailboxen
11:56:02 <ski> one can still wonder how one thread of execution can transmit the resulting `a' value back to the user
11:56:27 <humanoyd> erisco: ski: I just read through your explanations...so basically (liftAn . liftAn . liftAn) does the same drill-down trick as (fmap . fmap . fmap), right?
11:56:31 <ski> it may be interesting to compare with the `read' operation in
11:56:35 <ski> @hackage ivar-simple
11:56:36 <lambdabot> http://hackage.haskell.org/package/ivar-simple
11:56:48 <ski> also see the `IVar' versions in
11:56:52 <ski> @hackage data-ivar
11:56:52 <lambdabot> http://hackage.haskell.org/package/data-ivar
11:56:56 <ski> @hackage monad-par
11:56:56 <lambdabot> http://hackage.haskell.org/package/monad-par
11:56:59 <ski> @hackage lvish
11:57:00 <lambdabot> http://hackage.haskell.org/package/lvish
12:04:40 <erisco> humanoyd, if you choose n = 1, so liftA, then yes
12:06:27 <ski> (also see "I-Structures: Data Structures for Parallel Computing" by Arvind,Rishiyur S. Nikhil,Keshav K. Pingali in 1989 at <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.5638>)
12:06:44 <anarcat> okay, i have another annoying one for ya
12:07:14 <anarcat> i have a structure like Plain [Str "Copyright",Space,Str "\169",Space,Str "2017,",Space, [...]] that i want to match
12:07:35 <anarcat> i tried cleanCopy (Str "©":Space:Str ds:xs) and cleanCopy [Str copy,_] | copy == "Copyright" = []
12:07:37 <anarcat> none work
12:07:54 <anarcat> s/©/Copyright/
12:08:13 <erisco> and what are the details of "none work"?
12:09:19 <anarcat> well crap, nevermind
12:09:22 <anarcat> i figured it out
12:09:36 <ski> as for (a), the idea is that if the computation you pass to `unsafeInterleaveST'/`unsafeInterleaveIO' access (only) state (or other effects) which is disjoint from the state accessed by the rest of the surrounding computation, then conceptually these operations split the world in two pieces, pass the smaller one to the given computation, and the larger one to the remaining one
12:10:41 <ski> humanoyd : aye, and this works because
12:11:11 <ski>   fmap :: Functor f => (  a ->   b)
12:11:12 <ski>                     -> (f a -> f b)
12:11:52 <ski>   liftA2 :: Applicative i => (  a ->   b ->   c)
12:11:52 <ski>                           -> (i a -> i b -> i c)
12:11:56 <ski> and so on
12:12:53 <ski> the point being that we've chosen to order the (curried !) arguments here, such that we can "align" it as taking a function and returning a "corresponding" ("lifted") function, in some sense
12:14:11 <ski> (`liftA2 :: Applicative i => ((a,b) -> c) -> ((i a,i b) -> i c)' would also have worked -- the input and output function wouldn't have to be curried)
12:25:57 <anarcat> well, that was fun
12:26:00 <Gurkenglas> http://lpaste.net/2147106064540106752 what do?
12:28:47 <anarcat> https://gitlab.com/anarcat/scripts/compare/1e302c7657355fbf4fa8deb333b9e532784b080f...c63bd20fd54004ac98600d61df85661ab36964c0
12:29:49 <anarcat> thanks again, dsal, madknight, byorgey, geekosaur and lyxia !! :)
12:56:21 <Gurkenglas> "stack hpc report" gives coverage reports which fixed my bug and shall be a useful tool. What command makes .prof files useful, and what other things of that sort am I missing?
13:22:00 <crobbins> is there a type class which effectively combines Functor and Contravariant? It'd need one method: (a -> b) -> (b -> a) -> f a -> f b
13:23:15 <fakenullie> woudln't it just ignore second function?
13:24:20 <crobbins> no, in my case i need to go from `f a` to `f b` but i need both an `a -> b` and a `b -> a` to make that happen
13:24:45 <fakenullie> looks impossible to me
13:25:02 <fakenullie> a -> b already gives you b
13:25:02 <johnw> well, an fmap between groupoids might have such a requirement...
13:25:06 <hexagoxel> crobbins: hayoo to the rescue: https://hayoo.fh-wedel.de/?query=(a%20-%3E%20b)%20-%3E%20(b%20-%3E%20a)%20-%3E%20f%20a%20-%3E%20f%20b
13:25:06 <EvanR> isnt there only 1 such data type 
13:25:31 <crobbins> hexagoxel: i always use hoogle, guess hayoo > hoogle?
13:25:35 <johnw> crobbins: an 'f' which is both Functor and Contravariant is called Invariant
13:25:49 <johnw> there are incredibly few instances of this type, most of them being phantom-typed
13:26:00 <johnw> (kinds of instances, I should say)
13:26:33 <crobbins> that is exactly what i need, thanks!
13:26:36 <johnw> Invariance here basically says that fmap'ing may change the type, but it won't change the term
13:26:40 <Gurkenglas> EvanR, you're thinking of "one method: f a -> f b"
13:27:23 <crobbins> in my case, i have a `JsonFormat a` and what to be able to create a `JsonFormat b` from two functions (this is for Scala, but discussions here usually are of higher quality ;)
13:28:30 <hexagoxel> crobbins: hayoo seems to have a bigger index. i think it is weaker in some other aspects.
13:29:26 <crobbins> good to know, thanks hexagoxel 
13:29:33 <geekosaur> its type search isn;t as good, hoogle(4) can do fuzzy type searches like finding more general types than the one you gave it
13:29:34 <crobbins> may have to make another search keyword for it
13:29:58 <geekosaur> (but hoogle5 is having issues in that area iirc)
13:30:52 <ironChicken> is (<$>) exported into the Prelude? i mean, do i have to import it explicitly?
13:31:12 <geekosaur> @index (<$>)
13:31:12 <lambdabot> Data.Functor, Control.Applicative, Prelude
13:31:46 <ironChicken> geekosaur: cool. btw is there a ghci command that does that?
13:32:11 <geekosaur> :info (<$>) should tell you, provided it's already in scope
13:32:34 <geekosaur> ...but it might tell you the original module, not the one you imported (Prelude reexports it from Control.Applicative, I think)
13:32:54 <ironChicken> yeah, :info only says "defined in"
13:40:32 <ironChicken> so specifically, someone is complaining that some code of mine doesn't compile on his MacOS 10.10 system with up-to-date Haskell Platform with the error "Not in scope: ‘<$>’"
13:41:02 <ironChicken> but it does compile for me, and also for him on his System 10.11 laptop
13:41:07 <johnw> weird
13:41:16 <shapr> import applicative?
13:41:24 <johnw> yeah, in the old days you needed Control.Applicative
13:41:31 <shapr> I bet that's the problem
13:41:34 <AndreasK> maybe a old version in path
13:41:37 <ironChicken> (<$>) hasn't changed between base 4.9 and 4.10 has it?
13:41:41 <monochrom> I would impeach the "up-to-date" part.
13:41:56 <monochrom> But Prelude has changed.
13:42:39 <geekosaur> it was missing in ghc 7.10.x iirc
13:42:53 <geekosaur> check $PATH, verify ghc version
13:43:08 <ironChicken> ok, yeah, the offending 10.10 machine is a notorious mess (it's an XServe that anyone and everyone has installed stuff on)
13:43:23 <soumyadsanyal> --nick
13:43:30 <soumyadsanyal> --nick -n
13:43:34 <soumyadsanyal> --nick -n soumya
13:43:37 <monochrom> Trust only "ghc --version"
14:03:13 <herzmeister[m]> what is the security track record of haskell, or the ghc for that matter? it's a runtime like many others after all, like java etc. still i never heard of any issues. just because it's still not widely used? :-]
14:03:13 <erisco> is there a library more particular for something like Sequence Char?
14:03:25 <erisco> similar to how Text is more particular than an array of Char
14:05:20 <shapr> herzmeister[m]: hm, facebook uses ghc for fighting spam
14:05:31 <erisco> it is appealing that Sequences can be efficiently edited at any point
14:05:52 <maerwald> spam is orthogonal to security
14:06:06 <maerwald> ghc is not security focuses in any way
14:15:18 <shapr> oh funny, the hotswapping Haskell post uses a trick heffalump came up with years ago for dynamically reloading lambdabot plugins
14:15:21 <shapr> http://simonmar.github.io/posts/2017-10-17-hotswapping-haskell.html
14:18:33 <maerwald> herzmeister[m]: also, compared to java vm the exposure is probably something in the dimension of 0.x%, so attempts to mess with e.g. the GC, timing and so on... are not really "discovered" yet I'd say
14:20:00 <maerwald> but it's arguable whether that's an advantage or a disadvantage... 
14:21:34 <maerwald> you'll probably less likely find 0-day exploits for ghc on the black market (or so I think) than for the java vm and there is an academic theory that the price for stuff like 0-day exploits is what constitutes the "attack surface" of a system
14:21:52 <maerwald> but that's just one approach
14:23:29 <sqooq> sup nerds
14:24:58 <geekosaur> hack the nsa, check their exploit cache :p
14:25:14 <EvanR> hack the nsa, either get sent to gitmo or hired
14:25:25 <maerwald> nsa?
14:26:09 <shapr> no such agency
14:26:22 <maerwald> yeah, no idea what you guys are talking about
14:29:48 <erisco> a smart sequence of char would pack chars into, say, arrays of 8
14:29:56 <erisco> or some number like this to improve locality
14:34:16 <subtle> Hey all - I've got a beginner question. Could anyone point me in the right direction?
14:34:34 <maerwald> herzmeister[m]: check https://www.researchgate.net/profile/Stuart_Schechter/publication/2870863_Computer_Security_Strength_Risk_A_Quantitative_Approach/links/53e250d80cf24f90ff65dec8/Computer-Security-Strength-Risk-A-Quantitative-Approach.pdf
14:34:44 <dsal> subtle: http://www.catb.org/esr/faqs/smart-questions.html
14:36:01 <maerwald> the alternative approach is more "technical" http://reports-archive.adm.cs.cmu.edu/anon/2008/CMU-CS-08-152.pdf
14:36:12 <maerwald> and has not been done for GHC, I am pretty sure
14:37:12 <ski> shapr : hm .. i seem to remember an old paper (thesis ?), on dynamic loading stuff in Haskell (or statically typed immutable functional programming ?). i find dons thesis, but i think i may be looking for a different one
14:43:54 <geekosaur> I remember dons's paper (and the plugins package). not sure about others
14:45:44 <ski> (my memory first associated it to Andres Löh, but that may be incorrect)
14:48:52 <crucify_me> > :t ((: []) . (: [])) ()
14:48:54 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
14:50:10 <dsal> :t ((: []) . (: [])) ()
14:50:11 <lambdabot> [[()]]
14:50:36 <dsal> > "evaluates things"
14:50:39 <lambdabot>  "evaluates things"
14:50:58 <hpc> > putStrLn "doesn't execute things"
14:51:00 <lambdabot>  <IO ()>
14:51:25 <dsal> @pl frees x = points x
14:51:25 <lambdabot> frees = points
14:51:40 <crucify_me> got it thanks that was for sk*i   :)
14:52:02 <crucify_me> :t ((: []) . (: [])) ()
14:52:04 <lambdabot> [[()]]
14:52:06 <hpc> :P
14:52:42 <crucify_me> sk*i had helped me on the beginners channel hpc   ..
14:55:15 <c01nwarr10r[HD]> VOISE, going to be the largest music market in the world in the next few years, VOISE offers a free decentralized market for artists to promote and sell 100% of their work on their terms
14:55:19 <c01nwarr10r[HD]> going to be a big market
14:55:31 <c01nwarr10r[HD]> anyone and everyone can participate, not just mainstreamers
14:55:32 --- mode: ChanServ set +o johnw
14:55:32 --- mode: johnw set +b *!18722504@gateway/web/cgi-irc/kiwiirc.com/ip.24.114.37.4
14:55:32 --- kick: c01nwarr10r[HD] was kicked by johnw (Kicked)
14:55:32 --- mode: johnw set -o johnw
14:55:41 <johnw> there's a market for ya
14:56:26 <[exa]> I like the accuracy of his predictions
14:57:09 <maerwald> zomg, opportunities!
15:08:33 * ski . o O ( ‟‛yields a contradiction, when preceded by its quotation.’ yields a contradiction, when preceded by its quotation.” )
15:09:12 <iqubic> I like that.
15:09:18 <iqubic> It's like a quine.
15:09:31 <fishythefish> Uh...true. I'll go "true".
15:10:11 <iqubic> ski: I first saw it with s/a contradiction/false/
15:10:34 <ski> i don't recall the exact formulation i saw
15:10:41 <iqubic> And also s/preceded/followed/
15:58:33 <johnw> how do I turn a NominalDiffTime into microseconds?
16:04:09 <geekosaur> fromEnum to get a Pico (see Data.Fixed), divide by 1000000?
16:05:49 <geekosaur> hm, actually it relays the fromEnum to Pico so you should just get an Integer representing picoseconds out
16:07:24 <johnw> I just decided to use thyme for now
16:27:56 <dhiaa> emptu
16:38:11 <Silver_Ni> 05Is cool chat join 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml
16:38:13 <Silver_Ni> 05Is cool chat join 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml
16:38:14 <Silver_Ni> 05Is cool chat join 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml
16:38:14 <Silver_Ni> 05Is cool chat join 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml 12www.SitioChat.ml
16:39:32 <johnw> is it just me, or pipes-binary confusingly difficult to use?
16:39:53 <johnw> I love pipes, but there is little documentation on how its sub-packages should interoperate
16:40:26 <jb55> johnw: I've been trying to figure out those sub packages for years
16:40:40 <jb55> I almost always give up
16:40:45 <johnw> in this case, I need to combine pipes-binary, bytestring and parse
16:40:49 <johnw> but omg is this crazy
16:41:06 <jb55> yup
16:41:23 <jb55> parsing is pretty brutal in streams
16:41:25 <jb55> err pipes
16:42:42 <dmj`> pipes-aeson too, had to stop blaming myself after a while
16:43:08 <jb55> I no joke ended up using ShQQ and sed
16:43:23 <johnw> ah, found my bug
16:43:29 <johnw> forgot to use 'forever' in a Pipe
16:43:33 <johnw> now all is working, phew
16:43:37 <johnw> wasn't pipes-* at fault 
16:44:34 <johnw> I had: runEffect $ for ((() <$ P.stdin ^. P.decoded) >-> segments) P.encode >-> P.stdout
16:44:51 <johnw> this decodes packets from stdin, breaks them up into segments, encodes the segments, then writes those to stdout
16:45:14 <johnw> I still feel it should look prettier, since it's such a straightforward tranformation on the input; but it's a transformation on a structured view within a bytestring stream, so maybe not
16:45:16 <Axman6> still, many things in the pipes universe are much harder than you would expect them to be. I remember trying to do some crypto stuff and realising you had no idea when you'd reached the end of a stream so returning the hash of the stream turned out to be really difficult (can't remember the exact details, but it was very unsatisifying)
16:45:56 <johnw> yes, I have to admit, conduit just wins here
16:46:02 <johnw> since it was designed for practical use, theory be damned
16:46:33 <jb55> didn't you do something with pipes+coq?
16:46:45 <Axman6> pipes can be as correct as it wants to be, but I have never found it _useful_, despite running into many problems it feels like it should be the right abstraction for
16:46:55 <johnw> yes, I proved all the categorical constructions are valid
16:48:03 <Cale> I've put pipes-* to use and had an enjoyable time with it
16:48:43 <rotaerk> same
16:48:58 <jb55> did that help you understand the library? use it effectively?
16:49:02 <johnw> most of the time I'm happy with it; I think I just need a lot more practice with Parsers
16:49:06 <Cale> (I replaced an ad-hoc implementation of streams in snap's websockets support with it)
16:49:27 <rotaerk> I never really understood why people say conduit is practical while pipes is correct at the expense of practicality
16:49:44 <johnw> rotaerk: so, at one point I wrote hackage-mirror
16:50:01 <johnw> a completely-streaming based downloader that downloads packages asynchronously while it's processing the package manifest
16:50:01 <jb55> ah rip my connection
16:50:23 <johnw> in conduit, this was beautiful streaming code, reading almost exactly as you'd describe the problem in English, about 7 segments to the pipeline
16:50:29 <johnw> in pipes, it became rather horrible, actually
16:50:40 <johnw> I have both versions in version control, if you're interested
16:50:51 <rotaerk> sure, I'm curious to see how they look in comparison
16:50:56 <johnw> ok, one sec
16:51:38 <Nash_> hello #haskell. I'm stuck trying to use `streamUpload` from this package: https://hackage.haskell.org/package/amazonka-s3-streaming-0.2.0.3/docs/Network-AWS-S3-StreamingUpload.html
16:52:17 <Nash_> I suppose I have to somehow runAWS to get "Sink ByteString m CompleteMultipartUploadResponse" to Sink ByteString () CompleteMultipartUploadResponse"?
16:53:37 <geekosaur> why do you think it needs to have a () for m?
16:53:38 <MP2E> interesting to read about the comparisons between pipes and conduit here, as a newbie I never did know which one to look at
16:53:56 <johnw> rotaerk: no, I don't have it. :(  The hackage-mirror only uses conduit (I think I gave up on the conversion). What I was thinking of was my Hakyll site generator, but my Git history there is truncated.
16:54:01 <rotaerk> Nash_, you can't putt () in place of m.  m is of kind *->*.  it also has to fit the type class constraints
16:54:05 <geekosaur> (because that would mean 'somehow do this without any connection to AWS')
16:54:07 <rotaerk> johnw, ah, np
16:54:21 <geekosaur> if it even made sense type-wise
16:55:33 <geekosaur> anyway yes, you need runAWS to get a connection to AWS to work with. this includes an environment containing login credentials etc.
16:57:50 <Nash_> @geekosaur -- I see. based on the snippet here (https://hackage.haskell.org/package/amazonka-1.4.5/docs/Network-AWS.html), will `send` be able to run the sink created by `streamUpload`? is there something I need to do for runConduit?
16:57:50 <lambdabot> Unknown command, try @list
17:13:30 <johnw> ah, more idiomatic: for (void (P.stdin ^. P.decoded) >-> P.mapFoldable f) P.encode >-> P.stdout
17:13:46 <johnw> where f is my a -> b "within" the incoming/outgoing bytestring stream
17:13:56 <johnw> actually, a -> [b]
17:15:59 <Axman6> Nash_: hey, I wrote that package - you need to provide a Source m ByteString of the data you want to upload, and connect it to the Sink produced by streamUpload, and join them using Conduit's $$
17:17:30 <Axman6> Nash_: there's no need to use send, that is called inside the Sink, you just need to run the combination of your Source and the Sink combined inside a monad which is an instance of MonadAWS
17:18:36 <Axman6> hmm, that package should probably export ChunkSize and NumThread's definitions
17:24:37 <Axman6> I feel there's a simpler way to do this: chunkSize = maybe minimumChunkSize (max minimumChunkSize) mcs
17:26:22 <geekosaur> :t maybe
17:26:24 <lambdabot> b -> (a -> b) -> Maybe a -> b
17:26:39 <geekosaur> right, that definition seems wrong
17:26:54 <geekosaur> oh, no, I see what it's doing
17:27:45 <geekosaur> max minimumChunkSize (fromMaybe 0 mcs) -- ?
17:28:05 <Axman6> yeah, I was just thinking that
17:28:24 <hpc> use minBound instead of 0
17:28:54 <hpc> although that changes the type if you're going for maximum polymorphism
17:29:00 <geekosaur> think that inly matters if minimumChunkSize could be negative, which seems wring
17:29:05 <geekosaur> wrong even
17:29:23 <hpc> personally, i would just pattern match on mcs
17:29:30 <hpc> since that's what maybe emulates, anyway
17:35:08 <ski>   maximum (minimumChunkSize : maybeToList mcs)  -- not sure this counts as nicer or simpler, Axman6
17:35:57 <ski> (removes the repeated mention, though)
17:36:26 <Axman6> yeah, the repeated mention was the most annoying thing really
17:37:54 <Axman6> Nash_: did you get it working?
17:41:17 <ski>   foldMap (Endo . max) mcs `appEndo` minimumChunkSize  -- another try, without lists
17:48:58 <ski>   foldl max minimumChunkSize mcs
17:49:18 <ski> Axman6 ^
17:49:48 <Axman6> ooo, pretty
17:49:52 <Axman6> might use that
17:50:01 * ski obviously hasn't used `Foldable' much for `Maybe'
18:15:49 <pacak> foldl'....
18:36:40 <orion> Does anyone know on a high level how Haxl is able to group commands together which can run concurrently?
18:37:46 <orion> I think the key point is that it's a free Applicative as opposed to a free Monad.
18:37:53 <orion> But I don't know much more than that.
18:40:37 <geekosaur> in x >> y, if x fails y should not be run (see the monad laws). in x *> y, x cannot fail (it could bottom, but so can anything else)
18:40:52 <geekosaur> so you can run x and y concurrently in Applicative, but not in Monad
18:42:08 <orion> Yes, but as I understand it, Haxl is able to build a tree describing the dependencies between commands.
18:42:42 <orion> So if a later command depends on the results of a previous command, they are run in sequence. If they are uncoupled, they are run in parallel.
18:43:05 <Welkin> lol haxl
18:43:12 <Welkin> that was just mentioned in a talk I attended
18:43:23 <orion> What are your thoughts on it?
18:48:58 <Welkin> it was only mentioned in passing to show what haskell can do
18:49:00 <Welkin> but very cool
18:49:19 <Welkin> it was about turning a N+1 database query into 2 queries
18:49:24 <MarcelineVQ> "<orion> So if a later command depends on the results of a previous command, they are run in sequence. If they are uncoupled, they are run in parallel." that sounds like a pretty interesting basis for robotics control
18:55:03 <bigs> anyone have a preferred library for sized vectors?
18:55:19 <bigs> i.e. vects w/ type indexed lengths
18:58:40 <bigs> looks like vector-sized is solid
19:00:11 <Welkin> as opposed to liquid or gaseous?
19:01:23 <nash_> my issue is: trying to use a cassava-conduit `source` with a amazonka-s3-streaming `sink` (streamUpload).
19:07:27 <bigs> yes Welkin precisely
19:14:08 <ski> > Nothing *> undefined  -- can't fail ?
19:14:11 <lambdabot>  Nothing
19:14:58 <Welkin> why would it fail?
19:15:05 <Welkin> > Nothing >> undefined
19:15:07 <lambdabot>  Nothing
19:15:15 <Welkin> it is just the monad instance for Maybe
19:15:21 <Welkin> ori n your case, Applicative
19:15:36 <Welkin> haskell is so lazy
19:19:52 <ski> geekosaur said "in x *> y, x cannot fail (it could bottom, but so can anything else)"
19:19:58 <ski> perhaps i misinterpreted them
19:21:26 <ski> pacak : well, it doesn't matter much, since `Maybe' has a low upper bound on number of elements .. i had `foldr' before, but changed to `foldl' in order to preserve argument ordering of `max'
19:34:00 <Welkin> > 0 + undefined
19:34:02 <Welkin> er
19:34:02 <lambdabot>  *Exception: Prelude.undefined
19:34:06 <Welkin> > 0 * undefined
19:34:09 <lambdabot>  *Exception: Prelude.undefined
19:34:15 <Welkin> > undefined * 0
19:34:17 <lambdabot>  *Exception: Prelude.undefined
19:34:21 <Welkin> I would have sworn that was a special case
19:34:36 <Welkin> I saw the source code o.o
19:35:03 <Welkin> > 0/0
19:35:06 <lambdabot>  NaN
19:35:13 <Welkin> > 1/0
19:35:16 <lambdabot>  Infinity
19:35:24 <Welkin> > (negate 1/0)
19:35:27 <lambdabot>  -Infinity
19:35:32 <Welkin> > min (negate 1/0) undefined
19:35:36 <lambdabot>  *Exception: Prelude.undefined
19:35:40 <Welkin> oh well
19:35:44 <Welkin> be more lazy!
19:42:13 <Axman6> > 0 * undefined :: Natural
19:42:15 <lambdabot>  0
19:49:17 <mnoonan_> does anybody have a ghc nightly handy? I have several tests for a library that started failing between 8.0.* and 8.2.1. I’m curious if they continue to fail.
19:51:03 <ski> > min 3 (fix succ) :: Natural
19:51:05 <lambdabot>  3
19:51:06 <ski> > min (fix succ) 3 :: Natural
19:51:09 <lambdabot>  3
19:51:47 <ski> > max 3 (fix succ) > (10 :: Natural)
19:51:50 <lambdabot>  True
19:51:50 <ski> > max (fix succ) 3 > (10 :: Natural)
19:51:53 <lambdabot>  True
19:52:28 <Welkin> > fix ((0:) . scanl (+) 1)
19:52:32 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
19:52:33 <Welkin> :D
19:52:36 <Welkin> my favorite
19:55:50 <ski> > nubBy (((0 ==) .) . flip mod) [2 ..]
19:55:53 <lambdabot>  [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,...
19:56:48 <Welkin> prime numbers?
19:57:04 <ski> yes
19:57:19 <ski> it's a bit of an abuse
20:51:54 <ben2354> Can someone help me understand a type of the library jsonrpc-conduit?
20:52:26 <ben2354> If I have `data Method m where Method :: forall i m o. (FromJSON i, ToJSON o) => (i -> m (Either MethodError o)) -> Method m` I can't do anything with it, as the input & output are hidden?
20:53:22 <ben2354> Only the monad type is exposed, but I can't think of how this type is useful
20:53:47 <geekosaur> the point of a type like that is generally so you can use it with other combinators without *those* being able to see/affect the types 
20:55:15 <ben2354> Hmm ok, is there anything I could google to help me understand this?
20:55:18 <iqubic> I don't understand how such a function would work at all.
20:57:01 <iqubic> What does that Method function even do?
20:57:25 <geekosaur> the idea is you pass a Method to another function, and all it can do is call it with some input of a type it doesn't know about and get back something of a type it doesn't know about --- generally you control the input and output types and wrap the function using those types in a Method. this way you can have RPC call functions that don't need to know the types used by the RPC, just how to perform an RPC
20:58:12 <ben2354> ok I think I understand the idea, thanks!
20:58:34 <geekosaur> so you have http://hackage.haskell.org/package/jsonrpc-conduit-0.3.0/docs/Data-Conduit-JsonRpc-Server.html#v:serve
20:59:12 <geekosaur> it is passed a table of Methods. it doesn't know anything about them, it just dispatches them. the Method itself knows what it is doing, and how to handle the data input and output.
20:59:40 <geekosaur> this is also how you allow that table to contain Methods that have different types
21:00:13 <iqubic> RPC being Recursive Parser Combinator, I assume?
21:00:25 <geekosaur> this is JSON remote procedure calls
21:00:44 <ben2354> Ahh, so the runMethod is still able to use the to/from json classes
21:00:51 <slack1256> any `vector` hacker around? I got a question about the internal Bundle data type
21:01:04 <ben2354> iqubic: rpc in this case is remote procedure call
21:01:40 <slack1256> I don't see much uses of sChunks on the package. Are Bundle then mainly a way to have informed guesses about the size of the Stream ?
21:02:44 <ben2354> geekosaur: i was getting confused previously because I wasn't understanding how the to/fromjson classes could still be used, your explanation helped a lot thanks
21:04:11 <geekosaur> yeh, the server just gets a JSON-encoded request, FromJSONs it to get the inpiut data and method name, invokes the method on the decoded input data, ToJSONs the result, and replies to the requesting client. all it needs to know is it can use FromJSONToJSON and the table of methods. type compatibility is up to the Method to determine and the client to get right
21:05:24 <geekosaur> which is pretty much all you can do; web RPC is stringly typed
21:05:34 <geekosaur> (not a typo)
21:08:00 <Welkin> http is all strings
21:08:11 <Welkin> base 64
21:22:35 <saurabhnanda> about a year ago, I remember reading a blog post which benchmarked compile times with various -j and -A flags. Can't seem to find it now. Does anyone know anything about it?
21:34:41 <slack1256> saurabhnanda: I remember a post about how parallel GC killed the perf of some program and playing with the allocation size of the nursery (-A) helped a little bit
21:34:58 <saurabhnanda> slack1256: do you have that link?
21:35:13 <slack1256> I could search on r/reddit search box
21:35:31 <saurabhnanda> I'll do that... remember the post title?
21:36:14 <slack1256> found it https://www.reddit.com/r/haskell/comments/6fqnke/speed_up_your_haskell_programs_with_one_weird/?utm_term=eb5cf3c7-5a19-42b3-8828-a602db638aef&utm_medium=search&utm_source=reddit&utm_name=haskell&utm_content=1
21:37:52 <slack1256> reading the post, it doesn't touch the -A flag. I remember reading about that followin that post because the -A value interacts a lot on the parallel perf of the gc
21:55:13 <saurabhnanda> using -j doesn't seem to be speeding up my build, it seems
22:00:43 <saurabhnanda> "-A: Set the allocation area size used by the garbage collector." >> what exactly is this setting? the threshold after which the GC kicks in?
22:10:02 <saurabhnanda> with `stack build` how do I pass +RTS options to GHC?
22:10:21 <saurabhnanda> This is not doing the right thing >> --ghc-options="-dshow-passes -j +RTS -A32m -RTS"
22:11:41 <MarcelineVQ> what is -j
22:12:24 <geekosaur> -A is normally the size of the 'nursery', i.e. twhere fast allocations happen. When it gets filled, it is compacted, any still-referenced data is moved to generation 1, and allocation resumes from the nursery. (gen 0 gc is fast)
22:12:25 <pacak> try -j4 or -j8...
22:12:44 <MarcelineVQ> saurabhnanda: oh sorry, I thought you were passing -j as an rts op my bad
22:13:12 <MarcelineVQ> Are you sure it's not doing the right thing though?
22:13:50 <Lokathor> i don't know who to bug about it, but some docs in base have bugged haddock
22:13:51 <Lokathor> https://hackage.haskell.org/package/base-4.10.0.0/docs/Foreign-C-Types.html
22:13:52 <saurabhnanda> MarcelineVQ: GHC is erroring out. The command line being prepared is: --ghc-options -j --ghc-options +RTS --ghc-options -A32m --ghc-options -RTS
22:14:11 <Lokathor> under "Platform differences" it doesn't use the bold and italics that they clearly intended
22:14:21 <saurabhnanda> basically, stack is not passing down the args to GHC/Cabal properly
22:16:18 <saurabhnanda> let it be... adding it to package.yaml itself
22:16:59 <saurabhnanda> geekosaur: so most allocations for local loops, etc. would be in the nursery?
22:18:03 <MarcelineVQ> saurabhnanda: What is the issue you're having though, what is it not doing that convinces you it's not working?
22:18:14 <saurabhnanda> ghc errors out...
22:18:35 <saurabhnanda> ghc: unrecognised flag: -A32m // unrecognised flag: -RTS
22:19:23 <MarcelineVQ> that's useful, I'd blame --ghc-options -RTS  for that, tried it without a closing -RTS ?
22:19:59 <MarcelineVQ> Actually I'd blame the chopping up since it's not keeping -A32m with +RTS
22:20:47 <saurabhnanda> MarcelineVQ: yup... that's what's happening...
22:20:50 <MarcelineVQ> I wonder if it's a shell issue causing that --ghc-options expansion you showed above, your line works in one of my projects
22:21:11 <MarcelineVQ> rather, this works:  stack build --ghc-options="-dshow-passes -j +RTS -A32m -RTS"
22:21:29 <geekosaur> saurabhnanda, there's a threshold for 'large allocations' (-AL) which arre handled separately, but all other allocations come from the nurery (it's literally just bumping a pointer and returning the old value)
22:23:06 <saurabhnanda> MarcelineVQ: very, very strange.... anyways, let it be. I added it to cabal file and moved on. Btw, do I need to add those opts to library and executable section, both?
22:23:23 <MarcelineVQ> two other issues you'll run into shortly are that stack has -ddump-to-file on by default, so if you don't see what you expect look for a dump file somewhere within .stack-work/dist/x86_64-linux-nopie/Cabal-1.24.0.0/build/ or your directory equivalent, the other is that ghc won't rebuild buitl things, so you will sometimes need -fforce-recomp to see anything
22:24:06 <saurabhnanda> for the second one - "stack clean" doesn't do the job?
22:24:10 <MarcelineVQ> saurabhnanda: not sure about that, I've only tried to used ops like that for executables
22:24:28 <MarcelineVQ> saurabhnanda: dunno, just making you aware of it in case it comes up
22:24:52 <cocreature> if the goal is to speed up compilation times, you need to put it in the library and the executable section
22:25:06 <saurabhnanda> thanks for the tip, MarcelineVQ
22:25:27 <saurabhnanda> cocreature: yes, that's the idea... will stop the current build and fix the cabal file first.
22:25:47 <saurabhnanda> btw build finished, and it had no impact. Guess the library section also needs it
22:26:55 <cocreature> you can use "stack build --cabal-verbose" to see how GHC is invoked and make sure it’s receiving the options you want to pass
22:27:08 <saurabhnanda> the RTS flag should show up in `ps axw`, right?
22:29:14 <saurabhnanda> -j starts more **processes** or more **threads**? how do I verify that it is having any impact (via 'ps' or 'activity monitor')?
22:30:25 <Welkin> -j uses all available cores (or however many you pass it)
22:30:27 <Welkin> I think
22:31:04 <pacak> saurabhnanda: -j creates internal haskell threads and if it's over 4..8 ghc will spend more time doing ghc than actually compiling.
22:31:25 <pacak> You should see ghc using >100% cpu in top
22:32:00 <saurabhnanda> pacak: ghc is using 16 threads in my build right now...
22:32:10 <pacak> Too much.
22:32:58 <saurabhnanda> hang on... let me close docker and emacs. Let's give this more RAM.
22:34:01 <saurabhnanda> 6m without -j and 4m with -j --- how to make this even faster?
22:34:09 <saurabhnanda> how to confirm that -A32m is actually being respected?
22:35:10 <pacak> -j4 ... -j8
22:35:39 <pacak> You can speed it up by running several ghc processes in parallel via ghc -M and shake/make, but it's a bit more tricky to setup.
22:35:58 <pacak> I'm having ~20% speed up this way
22:36:14 <saurabhnanda> would CirlceCI be doing the multiple GHC process thingie?
22:37:36 <pacak> I don't think so. I had to specifically write my own build system to get this effect.
22:37:59 <saurabhnanda> and 20% speedup with the custom build infra?
22:38:07 <pacak> yep
22:38:26 <saurabhnanda> and that's with -O0 or -O1 ?
22:38:30 <pacak> -O2
22:40:00 <pacak> The idea is to run ghc -M on all the sources first then use make (or I'm using shake) to compile all the things compiling one file at a time.
22:40:27 <saurabhnanda> what does ghc -M do?
22:41:05 <saurabhnanda> btw, +RTS -A64m -RTS seems to be having no impact... do I need to use some other flags/
22:41:05 <cocreature> figure out imports
22:41:41 <cocreature> saurabhnanda: have you tried it without -j?
22:42:34 <pacak> It creates a Makefile with module dependencies. It won't contain some things from TH since it's evaluating any TH at that time.
22:43:25 <cocreature> pacak: so you need to handle things like addDependentFile manually in your build system?
22:44:24 <cocreature> oh actually it looks like -M does support addDependentFile
22:44:44 <pacak> cocreature: Does it? O_o It didn't last time I checked...
22:44:54 <cocreature> pacak: at least https://github.com/haskell/cabal/issues/4746#issuecomment-327787181 claims so
22:45:46 <saurabhnanda> cocreature: will try next... 
22:46:11 <pacak> cocreature: One other problem is to handle stale .hi files. Suppose you add a module Data.Maybe in your project, compile it - this will create o/Data/Maybe.hi, then remove this module - next time you try to compile your project ghc will die with some funny error message.
22:47:36 <saurabhnanda> starting from the top.... after closing docker, emacs, and intero...
22:48:18 <saurabhnanda> so, even without -j, GHC uses 4 threads. With -j it uses 16.
22:48:59 <saurabhnanda> should I do all this benchmarking with -O0 or -O1? Where will these options have a higher impact?
22:50:08 <cocreature> depends on whether you care about getting the build times down for -O0 or -O1 :)
22:54:26 <pacak> https://hackage.haskell.org/package/template-haskell-2.12.0.0/docs/Language-Haskell-TH-Syntax.html#v:addDependentFile 
22:54:26 <pacak> Notes: ghc -M does not know about these dependencies - it does not execute TH.
22:54:29 <pacak> cocreature: ^
22:55:28 <cocreature> pacak: hm, werid. I’m also not entirely sure what makes refold say that it does support it in that cabal issue
22:59:34 <xuanrui> xposted from ubuntu: does anyone know of an ubuntu ppa w/ an up-to-date version of stack?
23:01:14 <pacak> With haskell I prefer to use separately installed things for development, this way upgrade in distr won't force you to upgrade your ghc and the other way - you upgrading to newer ghc won't break your xmonad/etc.
23:06:23 <mud> xuanrui: Should just use the installer stack recommends really
23:34:25 <saurabhnanda> baseline with -O1: 16m 45sec
23:34:54 <saurabhnanda> does the -j flag figure out the optimum parallelisation or should I give it -j4 / -j8 or something?
23:35:42 <saurabhnanda> GHC is giving the CPU some solid exercise now... 250% usage!
23:36:15 <cocreature> -j does not figure out the optimum parallelisation. it just uses the number of cores you have
23:37:30 <saurabhnanda> which is a sensible default, no?
23:37:51 <Axman6> it's not a bad place to start, but will depend on the actual job
23:38:21 <cocreature> especially if you have a large number of cores, the overhead of distributing work over those cores will at some point outweigh the potential speedup
23:39:05 <pacak> cocreature: GC costs will overweight much sooner.
23:39:29 <pacak> saurabhnanda: try adding +RTS -sstderr  and comparing productivity
23:39:32 <cocreature> pacak: eh right, I was including GC costs in the “overhead” but I phrased it badly
23:40:02 <saurabhnanda> GC costs with the parallel GC? will turning off the parallel GC make things faster?
23:40:21 <pacak> No.
23:40:31 <saurabhnanda> referring to https://inner-haven.net/posts/2017-05-08-speed-up-haskell-programs-weird-trick.html -- +RTS -qg
23:40:57 <pacak> When ghc does more stuff at the same time - it keeps more stuff in memory, all the  things in memory needs to be GCed
23:42:23 <saurabhnanda> pacak: -sstderr will print stats like the ones given in that blog post?
23:42:34 <cocreature> yes
23:42:46 <pacak> yes
23:43:11 <saurabhnanda> and it'll be one per `stack build` or one per module? (sorry, can't break my current build to try this...)
23:44:07 <pacak> One per run of ghc, not sure how stack does it
23:48:16 <cocreature> stack builds via Cabal the lib so it’s still ghc --make afaik
23:49:09 <pacak> Is there's something like foo :: Profunctor p => p a b -> p a c -> p a (b, c) ?
23:54:10 <saurabhnanda> baseline (with -O1): 16m 45 sec // -O1 -j: 13m 34 sec
23:54:58 <pacak> saurabhnanda: -sstderr - compare GC overhead in both cases. Try reducing number of cores used.
23:57:01 <cocreature> :t \f g -> rmap (\x -> (x,x)) Control.Category.id >>> first' f >>> second' g
23:57:02 <lambdabot> error:
23:57:02 <lambdabot>     • Variable not in scope: first' :: t -> cat (a, a) b0
23:57:02 <lambdabot>     • Perhaps you meant one of these:
23:57:13 <cocreature> :t \f g -> rmap (\x -> (x,x)) Control.Category.id >>> Data.Profunctor.first' f >>> Data.Profunctor.second' g
23:57:15 <lambdabot> (Data.Profunctor.Strong.Strong cat, Category cat) => cat a b1 -> cat a b2 -> cat a (b1, b2)
23:57:31 <cocreature> ^ pacak if you have a Category instance, that works. otherwise I’m not sure
23:58:19 <pacak> cocreature: I think I can get one, yea.
