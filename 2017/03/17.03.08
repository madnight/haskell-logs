00:00:38 <wizard1337> is there any relation to his experience at rentech?
00:00:44 <wizard1337> and is he paid to work on ghc?
00:01:55 <ezyang> "because it's fun and intellectually stimulating" 
00:04:11 <n1> 'pure math' is a matter of perspective!
00:04:43 <wizard1337> what are the major sources of funding for ghc?
00:09:52 <Cale> wizard1337: Well, it's an open source project, but I suppose you could have a look at the places that the developers are working.
00:10:03 <wizard1337> so do people who are actually good with haskell get snapped up
00:10:27 <wizard1337> or is it what i have read, which is that there are tons of people who are great with haskell who are desperate to find a position anywhere
00:10:40 <Cale> It's a bit of both.
00:10:40 <wizard1337> *and are
00:10:52 <wizard1337> those are sorta mutually exclusive
00:10:59 <n1> I believe SPJ works on ghc for microsoft research
00:11:19 <wizard1337> right, so that would be 1 job
00:11:28 <Cale> wizard1337: Well, there are a fair number of us who are employed and spend our day jobs writing Haskell
00:11:38 <wizard1337> i guess it's appropriate to respond with an existence proof?
00:11:47 <wizard1337> ;-P
00:11:55 <Cale> I'm one of them :)
00:12:29 <wizard1337> right,... but it's not like there are agencies which will be absorbing pretty much anybody who is tall enough to ride the roller coaster
00:12:47 <wizard1337> or are there...?
00:13:08 <Cale> There's Takt, they've been snapping up lots of people lately :)
00:13:54 <Cale> (They're a startup, but they have quite a lot of funding from what it seems)
00:14:17 <wizard1337> lol ive worked at startups with about 30 times that in funding :)
00:14:30 <wizard1337> 30 m is significant but not remarkable
00:15:08 <Cale> Well, it's enough to hire a bunch of people and to do a bunch of business with the other Haskell development companies
00:15:23 <Cale> The entire community is only so large to begin with.
00:15:35 <wizard1337> i see
00:15:36 <ezyang> GHC dev is basically MSR + Well Typed + Army of PhDs 
00:16:06 <ezyang> with MSR and other industrial people funding the Well Typed committment 
00:16:34 <Cale> A couple people at Obsidian also have been getting into it a bit lately, if a bit in anger :)
00:17:16 <wizard1337> carmack likes haskell
00:17:36 <wizard1337> said that he started a project in it
00:17:49 <wizard1337> but other people working on it stormed his office and said "what the hell is a monad?"
00:18:40 <Cale> Monads are not a big deal. It's just a mathematical name for a pattern that's been showing up in functional programming for much longer than we had a name for it.
00:18:57 <wizard1337> yeah, i'm not saying these people had the right idea
00:21:03 <Cale> The harder part of learning to program in Haskell is usually going to have more to do with the change in mindset required regarding programming with immutable data structures most of the time.
00:21:34 <wizard1337> yaeh
00:27:47 <Cale> wizard1337: Also, when it comes to IO, the fact that IO is a monad, though it seems to be what people often fixate on, is not usually going to be any kind of a problem -- it just means we have a certain API for sticking these things together. The weird part that takes some getting used to is that IO is a type at all, and that we have a type of values which represent effectful programs, and their execution is a separate process from 
00:27:47 <Cale> evaluation of expressions.
00:28:50 <wizard1337> i don't fully understand monads but everything i've seen about them so far isn't troublesome
00:29:07 <wizard1337> containing state is a very sensible thing
00:29:11 <Cale> You basically learn a bunch of examples of them
00:29:13 <wizard1337> i did that naturally when i wrote imperative code
00:29:25 <wizard1337> purity, totality, state containment,...
00:29:30 <Cale> and gradually get a good sense that way for what kinds of things to usually expect
00:31:00 <maerwald> what's a nice xml parser in haskell without lens, TH or other complexity I don't care about
00:31:06 <wizard1337> lol
00:31:20 <wizard1337> if you don't like complexity, why are you using xml
00:31:31 <maerwald> because it's the input
00:31:42 <Cale> maerwald: What do you need it for? hexpat-pickle is old, but it might be good.
00:31:46 <cocreature> maerwald: I’ve used xml-conduit and found it quite nice
00:31:53 <maerwald> Cale: parsing the capec database
00:32:11 <cocreature> you don’t need to use conduit for it to be useful
00:33:42 <wizard1337> use kaggle and hire someone to train a neural net to parse xml
00:35:38 <rom1504> great idea
00:41:26 <wizard1337> oh, it's the gghc
00:41:28 <wizard1337> not ghc
01:00:07 <Cale> wizard1337: ??
01:00:27 <Cale> oh, Glorious Glasgow Haskell Compiler? :)
01:01:41 <errorondefault_> Hi everyone I'm doing a challange for a jobinterview and got stuck on level04 can I ask here for help?
01:02:39 <wizard1337> will you pay us part of your salary?
01:02:51 <Cale> lol, "I only want 7%"
01:03:07 <wizard1337> and are you using gghc or ghc?
01:03:16 <errorondefault_> haha nice one :D its a job as working student so it probably will be barely enough to pay for rent through college :D
01:03:36 <wizard1337> are you using the gghc compiler or ghc?
01:03:38 <Cale> What are you stuck on?
01:03:39 <errorondefault_> but its in infosec and thats where I want to go so I really want this job
01:03:50 <errorondefault_> well I probably need to start from the beginning
01:03:58 <Cale> wizard1337: Are you joking about the Glorious bit?
01:04:00 <wizard1337> because you want a pole dancer girlfriend?
01:04:29 <errorondefault_> so via email I get a link to this challenge cant share it because I have my personal login and Im sure they check
01:05:11 <errorondefault_> so lets say its www.web.com. On there it says: Intro Welcome Continue with Level00 Rules: Use your brain NO DoS, NO bruteforce. Level00 is a link to www.web.com/level00
01:05:56 <wizard1337> can i use neural nets?
01:06:02 <Cale> Do you have an actual Haskell question though?
01:06:10 <errorondefault_> no
01:06:22 <cocreature> if you can’t share the question then maybe the point of the challenge is that you figure out the solution yourself
01:06:25 <Cale> This channel is for discussion of Haskell...
01:06:30 <errorondefault_> right now I think its related to php and just figuering out this riddle
01:06:31 <wizard1337> but he has an actual potential haskell job
01:07:06 <errorondefault_> and i really want this job :D
01:07:28 <wizard1337> that's code for "i'm not qualified"
01:07:55 <wizard1337> seriously though asking other people about job interview questions is really bad,
01:07:58 <errorondefault_> well im not :D Im second semester but Im eager to learn ;)
01:08:05 <Cale> anyway, if you have questions regarding the programming language Haskell, I'm sure people here would be happy to help
01:08:11 <wizard1337> because if you advance to the next step,
01:08:14 <Cale> Otherwise, it's not really the right place
01:08:25 <wizard1337> you'll waste their time in that step
01:08:30 <wizard1337> rather than now
01:08:35 <errorondefault_> ok youre right sorry about that
01:08:44 <wizard1337> and subsequent steps often involve actually interviewing at a whiteboard etc
01:08:49 <Cale> wizard1337: pls
01:09:05 <errorondefault_> thanks anyways guys
01:09:32 <wizard1337> no etquiette allowed? even functional etiquiette?
01:10:00 <wizard1337> i resolved his "haskell question"
01:11:30 <biglama> hi guys, I would like to use HStringTemplate with a custom datatype 
01:11:49 <biglama> but one of the field of my datatype is another datatype and I would like to have a custom show for this field
01:12:17 <biglama> I've tried to instantiate ToSElem and Show but it still resort to the default show
01:23:00 <Cale> biglama: Well, what does toSElem produce for your type?
01:24:55 <lpaste_> biglama pasted “Custom formatting with HStringTemplate” at http://lpaste.net/5642642439081558016
01:25:03 <biglama> Cale: it returns a string
01:25:18 <biglama> Cale: I've pasted the code as it may be clearer
01:25:35 <lpaste_> biglama revised “Custom formatting with HStringTemplate”: “Custom formatting with HStringTemplate” at http://lpaste.net/5642642439081558016
01:26:41 <dxtr> Good morning, fellow youngsters
01:27:42 <Cale> biglama: If you remove the Show instance for Children (you shouldn't need it after all), does it complain?
01:28:52 <biglama> Cale: it does not complain but it does not change the output. Instancing show does not help either !
01:29:18 <Cale> Well, if it doesn't complain about the lack of an instance of Show, then writing one can't possibly help anything.
01:29:21 <biglama> I'm a bit confused
01:30:01 <Cale> oh, what's this GenericStandard business?
01:30:25 <Cale> Remove all the Data instances too
01:30:32 <Cale> Just to be sure it's not using those
01:31:10 <biglama> Cale: GenericStandard avoid to define ToSElem instances actually. But then I would have to define a ToSElem instance for person too ?
01:31:24 <Cale> Possibly, yes
01:31:57 <brynedwards> The StringTemplate docs have "class Show a => StringTemplateShows a where"
01:32:25 <brynedwards> Which takes and optional format string, and its default is show. Have you tried instantiating that?
01:33:17 <Cale> ah, you'd be using the ToSElem instance for Person as it stands
01:33:32 <Cale> Since you're doing setAttribute with a Person value
01:33:56 <biglama> brynedwards: I've tried but I'm a bit confused between ToSElem and StringTemplateShows
01:34:01 <Cale> So if that instance is just based on the Data.Data generic representation entirely, it won't do what you want.
01:34:17 <biglama> I do not need the format string so I though instantiang ToSElem would be enough
01:34:35 <Cale> Try just writing a ToSElem instance for Person
01:34:48 <brynedwards> Yeah but it says the format string is optional so maybe it uses it regardless
01:35:30 <Cale> You're not actually using the ToSElem instance for Children at all, iiuc
01:36:19 <Cale> (you should be able to comment out / delete that instance and still have the program build if I'm right)
01:37:38 <Cale> Personally, I avoid libraries like this. Usually it's easy enough just to concatenate strings together the way you want, and do whatever formatting is necessary in-place with whatever functions are appropriate.
01:38:54 <Cale> (Though, I couldn't help writing one of them anyway ;)  https://hackage.haskell.org/package/category-printf
01:40:13 <biglama> Cale: here  is a trimmed-down example with juste an instance of ToSElem, but it does not work
01:40:16 <biglama> Cale: http://lpaste.net/6884328818773852160
01:40:31 <biglama> I'm trying with an instance of StringTemplateShows now
01:40:43 <Cale> What happens? You get a complaint that the name and children fields aren't present?
01:40:47 <biglama> Cale: well, I wanted something clean :)
01:41:07 <biglama> Cale: the code runs but the output is empty for the field, as in
01:41:09 <biglama> "Your full name is , children = ."
01:41:12 <Cale> nice
01:41:26 <Cale> I suspect that's what the SMap constructor is for
01:42:00 <Cale> Actually, I would throw this library out on the spot for producing that output rather than an error of some sort.
01:42:27 <biglama> :)
01:42:49 <biglama> How would SMap play a role here ? I'm looking at the code but don't see where it's used
01:43:01 <Cale> Well, where you're currently producing a STR
01:43:22 <Cale> You want the person thing to have some named subfields which you refer to in your template
01:43:37 <Cale> So, presumably there's some way to define what those expand to
01:43:59 <Cale> and if you look at the SElem type
01:44:29 <Cale> The only thing which looks like it could be doing that job is the SM constructor which takes an "SMap a"
01:44:42 <Cale> and apparently  type SMap a = Map String (SElem a)
01:45:06 <Cale> So I'd expect that to be a Map from the "field names" to how to format them.
01:46:53 <Cale> So try something like   toSElem x = SM $ Map.fromList [("name", STR $ name x), ("children", STR $ "lol")]
01:47:06 <biglama> So brynedwards is right, I should instantiate StringTemplateShows instead ?
01:47:06 <Cale> and I think you can leave out the toSElemList
01:47:16 <Cale> The default instance for that should do
01:48:45 <biglama> Cale: your solution works !
01:49:24 <biglama> I find it a bit cumbersome though
01:49:43 <Cale> I do too. It's certainly much worse than just writing what you mean
01:51:09 <Cale> displayPerson :: Person -> String; displayPerson x = "Your full name is " <> name x <> ", children = lol."
01:51:20 <biglama> yeah
01:51:26 <Cale> Ah I suppose you can use ++ for String
01:51:37 <Cale> I would usually use Text these days :)
01:52:03 <biglama> I wanted a generic solution for very large datatype, where you would only have to instantiante show
01:53:11 <Cale> Also, generally you should try to make show x produce valid source code for constructing x
01:53:19 <Cale> (or something close to it)
01:53:35 <Unhammer> if we had no list fusion, would it be right to assume "map (a.b) l" to be more performant than "map a$map b l" ?
01:53:45 <Cale> Unhammer: yes
01:53:58 <Unhammer> ok, cool
01:54:17 <Cale> Though I reserve the right to wince at "more performant than"
01:54:59 <biglama> Cale: can you give me an example ?
01:55:07 <biglama> of "producing source code"
01:55:15 <Cale> > show [1,2,3,4,5]
01:55:18 <lambdabot>  "[1,2,3,4,5]"
01:55:32 <Unhammer> Cale,  sorry, "more performanter from"
01:55:46 * Unhammer ducks
01:56:01 <biglama> oh right
01:56:14 <Cale> > M.fromList [(1,"hello"), (2,"world")] -- Data.Map tries its best as well
01:56:17 <osa1> sometimes I wish we had let/letrec distinction in Haskell
01:56:18 <lambdabot>  fromList [(1,"hello"),(2,"world")]
01:56:30 <biglama> Cale: thanks a bunch anyway, it was very interesting, even though not very productive :)
01:56:47 <Cale> biglama: What does your overall program do?
01:56:52 <Cale> What are you using the templates for?
01:57:13 <Cale> osa1: So you can get away with confusing shadowing?
01:57:14 <Cale> :)
01:57:31 <biglama> Cale: I'm generating configuration files randomly and then call an executable 
01:57:41 <biglama> unit testing by hand
01:59:28 <biglama> my configurations files are in the INI format
02:00:02 <Cale> Unhammer: hehe, I just feel that whenever someone uses the word "performant" it's because they haven't actually done enough work to justify whatever claim it is that they're about to make -- otherwise they'd talk directly about what kind of performance they meant
02:02:34 <Unhammer> Cale,  yeah … I haven't done any work to measure :) I just got a suggestion from hlint, and started wondering if that was a "pure style" thing, or there were some deeper reason. 
02:03:02 <Cale> It will use less time because it does fewer allocations.
02:03:21 <Cale> It may use slightly less space, but not significantly less, in isolation.
02:04:31 <Cale> (because the cons cells of the intermediate list will immediately become garbage the moment they're created)
02:04:45 <Unhammer> Even without measuring, experienced coders do kind of write more performant code "by default", pattern-matching on previous experiences or whatnot. My early emacs-lisp was full of tail-recursion because I simply didn't know that .el doesn't TCO, now I'd never think about doing that without good reason.
02:05:46 <SpinTensor> Hi, started learning Haskell. As exercise i wanted to rewrite the elem function. I get a compile error and I don't know why: http://pastebin.com/c6jJpQnh
02:05:56 <spatial_>  do   val <- value a index   return ( BoardState xloc oloc index) val is an IO Int. So there is an error.
02:06:07 <Cale> "Tail calls" are kind of a weird thing in Haskell as well. There's no need for tail call optimisation because there's nothing which really corresponds to an ordinary call stack to begin with.
02:06:17 <Cale> (at least in GHC)
02:06:30 <SpinTensor> (n==x) returns a bool, so why does the compiler want a type (Eq a) somewhere?
02:06:36 <spatial_> IO Int will become Int. When ?
02:06:47 <Unhammer> yeah … I pretty much don't manually recurse in haskell =P
02:06:58 <Cale> spatial_: I'm having trouble parsing that
02:07:29 <Unhammer> spatial_,  you can't really escape IO
02:07:32 <Cale> spatial_: What's the type of  value a index?
02:07:45 <Cale> Is it IO (IO Int) somehow?
02:08:06 <Cale> I'm assuming the triple space there is a newline
02:08:37 <Cale> Wait, do you use val at all?
02:09:04 <spatial_> http://pastebin.com/5V3uzVUq val isn't used now. It will be.
02:09:28 <Cale> Well, this clearly doesn't have the type you've given it
02:09:56 <Cale> You're constructing an IO action which, when executed, is going to give a BoardState
02:10:05 <mniip> SpinTensor, what are the types of n and x
02:10:11 <Cale> So this has type  IOArray Int Int -> BoardState -> IO BoardState
02:10:27 <spatial_> Intention was to get Int from val which is IO Int and use it
02:10:31 <Cale> If you want to read an IOArray, you'll need to be executing an IO action, you can't do that elsewhere.
02:10:59 <mniip> SpinTensor, you're saying that elem' can be applied to a value of any type and a list of values of that type
02:11:01 <Cale> Where's the definition of value?
02:11:23 <mniip> SpinTensor, and then you proceed to use == on those types, but == doesn't work on all types
02:11:29 <spatial_> value :: ( IOArray Int Int) -> Int -> IO Int value a index =  liftIO (runReaderT (readvalue index ) a) 
02:11:32 <mniip> only those that are Eq, hence the type error
02:11:34 <SpinTensor> it should not matter what they are, right?
02:11:40 <Cale> mniip: thanks for answering SpinTensor's question btw :)
02:12:09 <mniip> SpinTensor, of course it does matter
02:12:13 <mniip> not all types can be =='d
02:12:21 <SpinTensor> mniip: oh. so I need to write elem' for specific types when using pattern matching?
02:12:23 <Cale> spatial_: whaaaaa
02:12:30 <mniip> SpinTensor, no
02:12:49 <mniip> SpinTensor, you just have to specify that 'a' in your type signature should be a type that supports being =='d
02:12:54 <Cale> spatial_: Are you sure you don't just want  value = readArray ?
02:13:05 <mniip> see:
02:13:07 <mniip> :t (==)
02:13:08 <SpinTensor> mniip: how do i do that?
02:13:10 <lambdabot> Eq a => a -> a -> Bool
02:13:22 <Cale> spatial_: What's the ReaderT shenanigans about?
02:13:29 <mniip> that 'Eq a' is telling you that 'a' should be an instance of Eq in order to use ==
02:13:33 <Cale> and that liftIO is definitely unnecessary and does nothing
02:13:41 <Cale> liftIO :: IO a -> IO a  doesn't do anything
02:13:48 <mniip> you should put a similar 'Eq a =>' context on your type sig
02:14:00 <Cale> It's only interesting when you're converting an IO action into an action of some other monad
02:14:56 <SpinTensor> mniip: thanks that did it. its kind of complicated to get your head around all this type stuff
02:15:41 <mniip> there is actually way to figure out that type signature programmatically, and that's what GHC would have done if you had omitted the type signature,
02:15:52 <mniip> but you should learn to see it conceptually
02:16:02 <Cale> SpinTensor: However, note that this advice is exactly what the compiler suggested you do (it doesn't always provide good advice, but it managed to be right in this case!)
02:16:46 <Cale> However, it didn't actually show you the change it wanted you to make, and only described it with technical language :/
02:16:50 <mniip> Cale, I wouldn't expect a beginner to know what "context" means
02:16:54 <Cale> yeah
02:16:55 <mniip> yeah
02:17:20 <SpinTensor> cale: I saw the (Eq a) in the error, but I had no idea where to include it. I tried something like elem' :: (Eq a) -> a -> Bool but that got different errors with constraint types.
02:17:32 <spatial_> Cale: That is separate piece to read and write arrays. That piece works.
02:17:34 <Cale> yeah, needs to be =>
02:18:00 <spatial_> Just trying to use the value read from the array.
02:18:10 * mniip . o O ( how confusing would it be to beginners if we had Constraint ~ * )
02:18:29 <SpinTensor> Thanks for your help guys. Hope i understood it.
02:18:45 <Cale> spatial_: So, in a do-block for an IO action, you can indeed read the array
02:19:02 <Cale> spatial_: But that entire do-expression will be an IO action, and will have type IO t for some type t
02:19:34 <Cale> spatial_: This is unavoidable -- if you want to read an IOArray, you can't do it from evaluation, you must do it from execution of an IO action.
02:19:49 <spatial_> Oh. How do I separate IO and non-IO ?
02:20:32 <Cale> Do you need to interleave writes and reads here, or are you done with writing?
02:21:03 <Cale> You might want to 'freeze' the IOArray into another array type that is immutable and has operations to read it that aren't IO actions.
02:21:09 <mniip> SpinTensor, btw I think you defined elem pretty much how it is in Prelude
02:21:27 <mniip> ...unless it's something like foldr . (==)
02:21:29 <spatial_> Reads and writes are there here.
02:22:02 <spatial_> I am going back to Java :-)
02:22:02 <Cale> spatial_: So, if you want to stick with using IOArray, you have no choice but to work with IO actions.
02:22:13 <SpinTensor> mniip: cool. the version from the book uses guards, but i refused to look at the solution.
02:22:23 <Cale> There are lots of other data structures you could consider using instead, if you want to avoid IO
02:22:56 <Cale> I would strongly consider Map, most of the time
02:23:14 <Cale> (Or IntMap, given that your indices are Int values here)
02:23:27 <spatial_> But these are very large arrays for Machine Learning.
02:23:39 <mniip> elem _ []       = False
02:23:40 <mniip> elem x (y:ys)   = x==y || elem x ys
02:23:50 <mniip> --GHC.List
02:23:59 <Cale> and you're reading and writing them randomly?
02:24:07 <spatial_> Yes
02:24:52 <mniip> you could use an unboxed array (I mean a library that implements arrays using one)
02:25:01 <Cale> Okay, then just stick with IO, and either IOArray or perhaps MVector
02:25:23 <Cale> Oh, and yeah, IOUArray would be more compact
02:25:47 <SpinTensor> mniip: i pack everything in () because I'm not at the chapter with operator priorities yet.
02:25:48 <spatial_> Any function that reads or writes an IOArray cannot return a non-IO state ?
02:25:51 <Cale> Your IOArray Int Int will be an array of pointers to code which construct Int values.
02:26:09 <mniip> SpinTensor, that's not an issue
02:26:14 <mniip> as long as it's readable
02:26:38 <mniip> Cale, is that a fancy way to say that it's lazy?
02:26:43 <Cale> spatial_: Yeah, because it might produce a different thing every time. The function itself will always produce the same IO action, but the result of that IO action will depend on when you run it.
02:26:54 <Cale> mniip: yeah
02:27:06 <mniip> you can make it strict can't you
02:27:09 <Cale> mniip: and that it's boxed
02:27:22 <Cale> It's boxed for polymorphism's sake regardless
02:27:27 <mniip> right
02:27:46 <Cale> IOUArray sidesteps that by only working for particular types
02:28:27 <spatial_> So I need to move all these smaller functions into a larger one.
02:28:54 <spatial_> And manage it
02:29:02 <Cale> spatial_: You don't necessarily have to -- IO actions can be broken up into smaller parts as well if you like
02:29:09 <mniip> MVector sounds cool
02:29:13 <mniip> looks like it works with ST
02:29:15 <Cale> But perhaps start with a big lump of code and decide how to carve it up later
02:29:19 <mniip> which is a nice thing in this context
02:29:47 <Cale> Oh, and yeah, there's STArray if you want to compute something using mutable arrays and end up with a pure function in the end.
02:30:03 <Cale> But stick with IOArray for the time being until you get the hang of that
02:30:06 <mniip> STArray is eh
02:30:16 <mniip> I was more hinting at STVector
02:30:23 <Cale> Well, it's similar
02:33:11 <Cale> spatial_: Just for reference, the Vector library we're referring to is this thing: https://hackage.haskell.org/package/vector
02:33:57 <Cale> It has Data.Vector.Mutable, which is not so different from IOArray or STArray, except that the single type can be used as either one.
02:45:43 <kuribas> I tested this: https://www.reddit.com/r/haskell/comments/1rcc8t/performance_of_the_st_monad_over_the_state_monad/
02:46:09 <kuribas> I get the same performance, the St monad being slightly slower.
02:47:52 <kuribas> I guess ghc (and base) made a lot of progress in 4 years...
02:48:53 <spatial_> Cale: Let me look at it. Now I have to go back to the drawing board :-)
02:51:06 <Yttrill> hi, i have a question about the gc and threads: am i correct assuming the shared heap collection requires a world stop?
02:53:39 <Cale> Yttrill: Yeah, GHC's GC is parallel but stops the world. I seem to recall at some point that they tried a variant which didn't stop the world, and its throughput was much worse. I could be imagining that though.
02:54:13 <Yttrill> do you know how they stop the threads?
02:54:49 <Yttrill> it's OS dependent of course assuming native threads
02:55:19 <Yttrill> Linux has a signal but I still don't see how the top of stack can be found
02:55:33 <ongy> the RTS schedules more threads than it has OS threads either way, it can take over on every heap allocation a thread does
02:56:33 <Yttrill> hang on you said two things: second, it has control on an allocation, my GC stops the world that way also
02:56:52 <Cale> http://simonmar.github.io/bib/papers/parallel-gc.pdf -- I think this paper is still relevant
02:57:01 <Yttrill> which is not very nice if you're running something long that doesn't do any allocation ;(
02:57:34 <Yttrill> Yeah i read that paper, but it explains how the GC operates not how it stops the threads
02:58:04 <Cale> Yeah, it looks like it just describes what takes place immediately following that bit of synchronization
02:58:33 <Yttrill> i have a suspicion that there is a per thread local heap that can be collected without a world stop
02:58:44 <Cale> yes, there is
02:58:59 <Yttrill> but a stop is still required, i'm curious how to organise the stop
02:59:27 <Yttrill> the Boehm collector using OS hacks eg SIGSTOP on Linux
02:59:46 <Yttrill> but i have no idea how that helps find the stack top
03:00:06 <Yttrill> i know there's a way to do this on Windows
03:00:36 <Yttrill> so non-Linux unix and OSX remain a mystery :)
03:00:37 <Cale> Or at least, I think that's right... but I'm now less certain :)
03:01:30 <Yttrill> the paper is old so there may be improvements
03:01:44 <Yttrill> if the world stop is done on allocation it makes sense 
03:02:27 <Yttrill> it means Haskell will have to have its own mutex, condition variables etc
03:02:54 <Yttrill> ones that time out often enough to check for a world stop
03:03:48 <Cale> Well, GHC's runtime has its own n:m thread scheduler anyway
03:03:51 <Yttrill> but what happens if a thread is multiplying two matrices? its a long wait until the next allocation
03:05:11 <Yttrill> how does the RTS do that? it would have to capture timer interrupts or make allocations reschedule points .. 
03:05:53 <Cale> oh, right, I was thinking of this version of the GC: http://simonmar.github.io/bib/papers/local-gc.pdf
03:06:19 <Cale> I'm not sure the version described in that paper is what actually made it
03:06:23 <_sras_> Does template haskell have a function of type [Dec] -> String ?
03:07:07 <Cale> _sras_: Which gives you the text of the declarations? That would be nice, but it doesn't.
03:07:35 <Cale> _sras_: You can get close (sort of) using -ddump-to-file -ddump-splices
03:07:52 <Cale> Assuming you just want to look at the generated code
03:08:17 <Yttrill> that second paper is 2011 which is a bit later
03:09:55 <Cale> The person to talk to about this kind of thing would be Simon Marlow, who is sometimes around as JaffaCake on IRC, but he usually hangs out in #ghc moreso than #haskell
03:10:04 <Yttrill> ok second paper mentions "spark pool" which i believe from docs is in there
03:10:32 <Yttrill> ok
03:10:32 <Cale> The spark pool is part of the mechanism for pure parallelism, rather than for concurrency in general.
03:10:51 <Yttrill> ok thanks for that info
03:11:24 <Yttrill> i'm just learning Haskell but i am also a compiler writer and language designer so curious about some deeper issues
03:12:11 <Cale> When you evaluate par x y, the expression x gets "sparked" which means it's added to a queue of work that can be stolen from by the various Haskell execution contexts if they have nothing better to do.
03:12:48 <Yttrill> ok, sort of like a thread pool
03:13:09 <Cale> (and the result of the evaluation is y)
03:13:13 <kuribas> Cale: does it run on another core, or just another thread?
03:13:49 <Cale> Usually it will be another HEC, which is probably running on another core
03:14:05 <Yttrill> i would guess it depends on tuning parameters
03:14:15 <Cale> But there's no guarantee that it'll be evaluated on another core
03:14:43 <Cale> and if you end up needing it too soon, your thread just evaluates it as normal
03:15:59 <kuribas> Why does is stop the world when it runs in parallel?  Does that mean some parts run in parallel, and other stop the world?
03:16:09 <Cale> There is a window of a couple cycles during which the main thread and some other thread can both begin to evaluate x, and that is just allowed to happen, since they will both produce the same result anyway, and the extra mechanisms required to prevent that are more costly on average than the occasional extremely unlikely duplication
03:16:38 <Cale> It means that it stops the world, and then all the capabilities help to collect garbage at the same time
03:16:49 <Yttrill> yeah, that was proposed in the 2008 paper for the GC as well
03:17:44 <_sras_> Cale: Yes. Can you take a look the the fullTableText function here ( https://github.com/folsen/opaleye-gen/blob/14938df0081187539f23f8547fb1b7762e286ac3/src/Generate.hs) and see if it could work?
03:17:46 <Yttrill> kuribas: the usual reason to stop the world is to find all the roots, which are usually all the thread stacks
03:18:49 <kuribas> Does it prevent real-time code?
03:18:50 <Yttrill> there's some kind of new development in the GC world I believe
03:18:56 <kuribas> (if the stops are long)
03:19:27 <Yttrill> kuribas: there are collectors which are incremental
03:19:44 <kuribas> and ght?
03:19:45 <Yttrill> dunno if the Haskell one is
03:20:14 <Yttrill> actually the design would appear to support the possibility
03:20:59 <Yttrill> a traditional copying collector copies all live stuff from one huge memory block to another so it cannot be incremental
03:21:38 <Yttrill> but the GHC one uses blocks and copies old to new with blocks, even the same block
03:21:48 <Cale> Yttrill: From what I understand, the current collector is a generational hybrid of a copy collector and mark/sweep
03:21:53 <Yttrill> so it can probably just give up collecting any time
03:23:57 <Yttrill> mark/sweep can be incremental because you just delete garbage so you can give up any time you like
03:24:03 <Cale> (and most of the time, it uses the copy collector)
03:24:39 <Yttrill> yeah but it uses blocks for copying
03:25:26 <Yttrill> it looks like it could just give up the collection part way through
03:25:54 <Yttrill> so you could just run the collector more often and give up after a fixed period, which would make the collector suitable for real time
03:26:07 <Cale> https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/GC -- this looks like it might be helpful
03:26:18 <Yttrill> the problem is more likelyt that Haskell is not suitable for real time :)
03:27:01 <Yttrill> yeah that looks good if its up to date thanks Cale
03:27:30 <Cale> In the threaded RTS, there is one nursery per Capability, as each Capability allocates independently into its own allocation area. Nurseries are therefore stored in an array nurseries[], indexed by Capability number.
03:27:33 <Cale> aha
03:27:49 <Cale> So we were right about that :)
03:28:23 <Yttrill> well that article says "last modified 6 years ago" :)
03:28:56 <Cale> haha
03:29:03 <Yttrill> which is 2011 when the PJ/SM paper was done
03:29:34 <Cale> Yeah, I don't recall hearing about anything too major going on with the GC since that time though
03:29:41 <Cale> I could be wrong though
03:39:19 <Yttrill> http://www.cs.utexas.edu/users/speedway/DaCapo/papers/immix-pldi-2008.pdf
03:39:53 <Yttrill> something has happened recently: Ocaml is going multicore, and that is because only now is there a suitable GC available
03:40:10 <Yttrill> but that's all i know at the moment
03:40:40 <Yttrill> different performance needs from Haskell though
03:49:32 <Axman6> bgamari: Hey, I just have your wkt package a go and it's not liking my input, seems to not like numbers which don't have a decimal point
03:49:40 <Axman6> gave*
03:56:47 <surelyourejoking> I'm doing the Learn You a Haskell tutorials, and I don't understand the syntax for `groupBy`
03:57:02 <surelyourejoking> e.g groupBy (\x y -> (x > 0) == (y > 0)) values  
03:57:50 <surelyourejoking> where values is a list of some positive and negative floats
03:58:41 <Axman6> which part do you not understand?
03:58:50 <surelyourejoking> I suppose the lambda
03:59:16 <surelyourejoking> (\x y -> (x>0) == (y>0))
03:59:17 <Axman6> (\x y -> (x > 0) == (y > 0)) is a lambda function which takes two argument named x and y and returns the expression (x > 0) == (y > 0)
03:59:33 <surelyourejoking> what does the right hand side evaluate to
03:59:40 <Axman6> > (\x y -> (x > 0) == (y > 0)) 1 1
03:59:46 <lambdabot>  mueval-core: Time limit exceeded
03:59:49 <int-e> > let x = 1; y = -1 in ((x > 0), (y > 0), (x > 0) == (y > 0))
03:59:53 <lambdabot>  (True,False,False)
03:59:55 <Axman6> uh, come on lambdabot
03:59:57 <surelyourejoking> so it's true if x and y are positive
04:00:18 <Ferdirand> or if x and y are not positive
04:00:31 <Axman6> it's true if x and y have the same sign (roughly)
04:00:46 <Axman6> (assuming 0 is negative =) )
04:01:32 <surelyourejoking> ok it's an XNOR logic gate then.
04:01:37 <surelyourejoking> right I understand the lambda function then
04:01:49 <Axman6> looks like a nice way to find groups of increasing or decreasing  runs... but that's not actually what it'll do sadly, because groupBy's behaviour is a surprising
04:02:23 <Axman6> > groupBy (\x y -> (x > 0) == (y > 0)) [1,2,3,2,1,0,-1,-2,-3,-2,-1]
04:02:30 <lambdabot>  mueval-core: Time limit exceeded
04:02:38 <Axman6> what are you doing lambdabot!
04:02:38 <int-e> Axman6: the given relation is symmetric, so groupBy should not produce any surprises.
04:02:50 <int-e> @undef
04:02:51 <lambdabot> Undefined.
04:02:58 <int-e> > groupBy (\x y -> (x > 0) == (y > 0)) [1,2,3,2,1,0,-1,-2,-3,-2,-1]
04:02:58 <Axman6> > groupBy (\x y -> (x > 0) == (y > 0)) [1,2,3,2,1,0,-1,-2,-3,-2,-1]
04:03:02 <lambdabot>  [[1,2,3,2,1],[0,-1,-2,-3,-2,-1]]
04:03:03 <lambdabot>  [[1,2,3,2,1],[0,-1,-2,-3,-2,-1]]
04:03:18 <surelyourejoking> so let me clarify, whenever the equality condition is met, groupBy causes a split in the list?
04:03:31 <surelyourejoking> sorry for the appaling terminology.
04:03:43 <surelyourejoking> *appalling.
04:03:53 <fweth> is there a built-in function like f::Just a->Just a->Just a; f(x)_=Just x; f(Nothing)(Just y)=Just y; f(Nothing)(Nothing)=Nothing ?
04:04:02 <brynedwards> :t groupBy
04:04:05 <lambdabot> (a -> a -> Bool) -> [a] -> [[a]]
04:04:24 <brynedwards> I'd say groupBy groups a list into multiple lists ;)
04:04:31 <int-e> surelyourejoking: no, it's the oppisite, a split happens when the first element of the current group is not in relation with the list element being processed
04:04:36 <fweth> Sorry, I mean f::Just a->Just a->Just a; f(Just x)_=Just x; f(Nothing)(Just y)=Just y; f(Nothing)(Nothing)=Nothing ?
04:04:55 <jle`> fweth: looks like <|>
04:05:00 <Axman6> int-e: many people are surprised that the comparison isn't make on consequtive elements, so groupBy (>) would produce lists of increasing runs. I also think the current definition is useful, but both versions would have the same type and neither convey their behaviour
04:05:05 <jle`> fweth: or mplus
04:05:09 <fweth> thanks!
04:05:19 <jle`> no problem!
04:05:27 <int-e> > groupBy (<) [3,6,4,0,6,3,-1,-2,-3]
04:05:32 <lambdabot>  [[3,6,4],[0,6,3],[-1],[-2],[-3]]
04:05:32 <jle`> it's also the behavior that a lot of people want for <>/mappend for Maybe
04:05:42 <jle`> but we do not live in that world
04:05:48 <jle`> can u imagine tho
04:06:24 <int-e> Axman6: right, actually I should have used the term "equivalence relation" because symmetry alone is not enough to avoid such surprises.
04:06:28 <Axman6> > groupBy (>)[1,100,2,300,2,0,1,2]
04:06:33 <lambdabot>  [[1],[100,2],[300,2,0,1,2]]
04:07:03 <Axman6> uh should've been (<) (or (<=)) obviously
04:07:17 <Axman6> > groupBy (<)[1,100,2,300,2,0,1,2]
04:07:23 <Hafydd> groupBy shouldn't be used without an equivalence relation.
04:07:25 <lambdabot>  [[1,100,2,300,2],[0,1,2]]
04:08:37 <int-e> Axman6: the "surprise" really only comes up when you start thinking about how groupBy could be implemented and then see that one of the possible implementations would be useful to produce increasing runs of a sequence.
04:09:03 <int-e> and then you find out that the actual implementation is not the one that allows this trick.
04:15:00 <surelyourejoking> ok what on earth does `groupBy (>) xs` do
04:15:10 <surelyourejoking> I see that it makes sublists of increasing length
04:15:10 <surelyourejoking> but why
04:15:26 <kuribas> If (m1,m2) = Data.Map.Split x is O(log n), then is Data.Map.Union m1 m2 also O(log n)?
04:15:42 <int-e> surelyourejoking: it doesn't.
04:16:08 <int-e> surelyourejoking: basically forget that you ever saw this and stick to "groupBy shouldn't be used without an equivalence relation"
04:16:34 <surelyourejoking> ok I'm very happy to do so.
04:17:09 <int-e> surelyourejoking: (the sublists that it does produce have the property that the first element is the smallest. I can't think of a case where this is useful.)
04:17:13 <surelyourejoking> So one more time, groupBy looks at elements of a list two at a time, and makes a split when the equality condition between those two items is not met?
04:18:04 <dramforever> Sounds pretty deterministic to me, actually
04:18:38 <int-e> surelyourejoking: No, it always compares the next element to the first element of the current group. But if the relation is an equivalence relation then your model produces the same results.
04:21:35 <surelyourejoking> and as you've said, I should stick to equivalence relations.Thank you for the help!
04:47:51 <hoppfull> Hello! I would like to create a "random" function that is pure. I need it for a simulation so that I get "random" behaviour but I can easily reproduce a situation with the same starting seed. However I seem to be having trouble finding what I'm looking for. If it rings a bell do you think you could help me by pointing me in the right direction? Is there a formal term for what I am looking for?
04:49:27 <pacak> :t random
04:49:29 <lambdabot> (Random a, RandomGen g) => g -> (a, g)
04:49:56 <pacak> :t mkStdGen
04:49:59 <lambdabot> Int -> StdGen
04:50:24 <pacak> > fst (random (mkStdGen 10)) :: Int
04:50:31 <lambdabot>  mueval-core: Time limit exceeded
04:50:33 <kuribas> hoppfull: https://xkcd.com/221/
04:50:42 <pacak> lambdabot: WAT?
04:51:33 <kuribas> > take 20 $ randomRs (0, 1) (mkStdGen 0)
04:51:36 <unclechu> hey guys, is registration on hackage working? it tells me that confirmation email sent but i don't see in my inbox anything, also in smap directory
04:51:36 <lambdabot>  [1,1,1,0,0,1,1,1,1,0,1,0,0,0,0,1,0,1,1,0]
04:51:48 <pacak> hoppfull: Anyway, look at System.Random
04:52:27 <hoppfull> Thanks guys
04:53:30 <kuribas> > take 20 $ (randomRs (0, 1) (mkStdGen 0)) :: [Double]
04:53:35 <lambdabot>  [0.9871468153391151,6.761085639865827e-2,5.591622274642816e-2,0.621389914632...
04:56:56 <Cale> unclechu: you might want to email admin@hackage.haskell.org with that
05:04:34 <kuribas> There should be an unSplit in Data.Map, the reverse of split...
05:05:17 <kuribas> or unSplitUnsafe.
05:06:04 <Hafydd> There should be a safePerformIO, which is the inverse of unSafePerformIO.
05:07:37 <magthe> In emacs I apparently have flycheck configured to use ghc to warn me of issues in my code (my flycheck-checker is set to haskell-stack-ghc), given that I read elisp *really* badly I searched online for how this might have been down... I managed to find nothing. Anyone in here who can offer some pointers on this? (I'd like to see if I can use something similar in my git pre-commit hook)
05:07:52 <magthe> s/down/done
05:09:08 <cocreature> Hafydd: that’s call "pure"
05:09:41 <cocreature> *called
05:10:22 <kuribas> or id?
05:10:40 <kuribas> :t id putStrLn
05:10:44 <lambdabot> String -> IO ()
05:11:07 <kuribas> magthe: try #haskell-emacs
05:12:17 <Hafydd> But it doesn't have the property that safePerformIO . unSafePerformIO = id. It can't recover the nondeterminism from the result of unSafePerformIO.
05:13:59 <hpc> safeUnPerformIO
05:14:00 <Hafydd> The function it produces is interesting, though... IO a -> IO a, which freezes one result in time and makes it pure.
05:14:31 <merijn> Hafydd: Eh, isn't this a rather indirect way of trying to reinvent ST?
05:15:03 <pacak> counsafePerformIO maybe...
05:15:07 <Tuplanolla> :t safeUnperformIO
05:15:10 <lambdabot> a -> IO a
05:15:25 <Hafydd> Ah, there we go.
05:15:56 <Hafydd> merijn: I don't think so. Not even ST allows you to recover an action from its result.
05:17:38 <Hafydd> This is possible in the extremely powerful and esoteric Const Monad, though.
05:17:53 <merijn> Const isn't a monad
05:17:58 <merijn> Did you mean Cont?
05:19:12 <spatial> http://pastebin.com/AN9S7YLW if loop standard is this ?
05:19:41 <Hafydd> Oh, whoops, I mean Identity.
05:20:08 <spatial> I mean indentation has a slight problem.
05:20:28 <Hafydd> It's so powerful and esoteric that I sometimes forget its name.
05:26:30 <kuribas> There should be a way to delete a range from a Map in O(log n).
05:27:19 <merijn> kuribas: Isn't dfeuer working on that kinda thing?
05:27:37 <kuribas> merijn: that would be great.
05:28:50 <Ferdirand> assuming the number of elements covered by the range is << n ? 
05:29:09 <maerwald> any useful xml package with xpath support?`the 'xml' package doesn't seem to have it and hxt is just useless complexity
05:29:11 <Ferdirand> or do you ignore the average gc cost ?
05:30:03 <kuribas> Ferdirand: I don't think GC is linear in garbage collected.
05:30:12 <kuribas> ghc likes garbage.
05:31:21 <quchen_> It’s copying, so shouldn’t it be linear in the garbage *not* collected?
05:31:57 <spatial> http://pastebin.com/C3Fp7MAx This has the indentation problem.
05:32:06 <quchen_> … up to linear factors ;-)
05:32:40 <kuribas> quchen_: it doesn't copy the hole heap, does it?
05:33:14 <quchen_> kuribas: Nope, it’s generational
05:33:33 <quchen_> spatial: There is no »else«
05:34:08 <spatial> I thought that is acceptable
05:35:12 <merijn> maerwald: xml-conduit?
05:35:34 <quchen_> spatial: No, every »if« must have both »then« and »else« in Haskell.
05:35:40 <merijn> quchen_: Correct
05:35:52 <merijn> GHC's GC is linear in the amount of live data
05:35:54 <quchen_> merijn: I know my ifs! ;-)
05:36:01 <quchen_> Oh, the GC thing. Yes that too.
05:36:02 <merijn> quchen_: I meant the GC :p
05:36:04 <spatial> http://stackoverflow.com/questions/15256471/nested-control-structure-in-haskell
05:36:07 <kuribas> spatial: what should it return if the condition is false?
05:36:38 <spatial> No return. Only state changes.
05:36:51 <kuribas> :t when
05:36:53 <lambdabot> Applicative f => Bool -> f () -> f ()
05:37:10 <kuribas> spatial: perhaps you want "when"
05:37:20 <merijn> Basically, GHC's GC is optimised for high-throughput workloads with a, preferably, not too excessive resident set
05:37:57 <spatial> kuribas: haven't seen when
05:38:13 <quchen_> ?src when
05:38:13 <lambdabot> when p s = if p then s else return ()
05:38:23 <maerwald> merijn: where does it have xpath support?
05:38:40 <merijn> maerwald: Not direct xpath support, but the combinators are modelled after xpath
05:39:05 <kuribas> spatial: look at lambdabots output
05:39:18 <maerwald> merijn: that's pretty limited, xpath is a language
05:39:21 <merijn> maerwald: So most (all?) XPath queries should be fairly trivial to write
05:39:37 <maerwald> not interested in that kind of oddity
05:39:53 <quchen_> spatial: It’s basically single-branch »if«, as long as you’re in an Applicative context.
05:40:02 <Aruro> is brew install ghc a trap? takes hours to compile.
05:40:20 <merijn> Aruro: Why are you compiling? Why aren't you installing a binary distribution?
05:40:26 <spatial> But this is a simple 'if'
05:40:31 <Aruro> i just did brew install ghc
05:40:33 <merijn> Aruro: In short, yes that's a trap
05:40:41 <Aruro> wanted to be SMART.
05:40:43 <merijn> Aruro: I don't use brew, so I dunno wtf they do
05:40:53 <spatial> I have no idea what Applicative is.
05:41:05 <Aruro> they have 8.0.2 compiling from source
05:41:07 <quchen_> spatial: Oh. Well, IO is an example of one. In IO, you can use »when«.
05:41:10 <merijn> Aruro: There's https://ghcformacosx.github.io/ but that's 7.10
05:41:15 <maerwald> guess this is another case of: try to find a useful library in haskell, realize there are only two options: 1. libraries that lack almost all required functionality to do a real-world project, 2. libraries that are just DSLs with a sh*tload of complexity, requiring you to invest more time than is useful
05:41:23 <quchen_> spatial: Hold on a second.
05:41:28 <Aruro> which takes more than 3 hours, im getting ready for 8 hours compiling
05:41:28 <kuribas> spatial: it's more general as Monad.  You can substitue Monad for it.
05:41:31 <merijn> Aruro: There's also stack (never used it), or just manually installing the GHC bindist from the GHC website
05:41:47 <merijn> Aruro: Compiling a release GHC is slow, yes. It needs to bootstrap
05:41:53 <Aruro> merijn: perhaps i had to install via stack, there is haskell-stack formula
05:42:07 <spatial> But even if loops are Monads in Haskell :-)
05:42:11 <Aruro> so 4 hours in i give up? :)
05:42:12 <cris_> hi , i write up a library an upload to git , but i am not sure if the structure is right, as i could not import all of them in ghci, see https://github.com/szehk/Haskell-Carbonara-Library/blob/master/src/Data/Carbonara.hs
05:42:59 <quchen_> spatial: Loops aren’t monads. (I don’t think the statement makes much sense.)
05:43:08 <cris_> i intended to use /src/Data/Carbonara.hs  to load all the other modules, not sure if this file is correct
05:43:21 <quchen_> spatial: In IO, you have a value that just does nothing: »pure ()«.
05:43:31 <quchen_> It’s a NOOP that does nothing but return »()«.
05:43:38 <quchen_> You can use that to do nothing.
05:43:44 <spatial> Yes
05:43:55 <quchen_> Sooo:   if a == 0 then putStrLn "hello" else pure ()
05:44:02 <quchen_> This will print if a is 0, and do nothing otherwise.
05:44:16 <spatial> () should be in else ?
05:44:22 <quchen_> »when« is a convenience definition for this,
05:44:22 <cris_> my system is Slackware 14.2  + nixpkgs
05:44:30 <quchen_> when (a == 0) (putStrLn "hello")
05:45:01 <spatial> So this if loop is wrong ?
05:45:12 <quchen_> If loop?
05:45:36 <spatial> http://pastebin.com/C3Fp7MAx
05:46:58 <quchen_> Yes, it’s wrong. But you can fix it by adding »else« branches to all »if«.
05:47:20 <spatial> Let me try
05:47:21 <quchen_> And if you don’t want to do anything in the else branch, let it evaluate »pure ()«.
05:48:24 <kuribas> spatial: in C an if statement isn't an expression, it doesn't need to return anything.  But in haskell it does.
05:48:46 <cris_> when i type ghci> :m + Data.Carbonara  
05:48:56 <kuribas> spatial: without "else", haskell doesn't know what to return.
05:48:58 <cris_> this error msg appears: error:     Could not find module `Data.Carbonara'     It is a member of the hidden package `carbonara-0.0.1@carbonara-0.0.1-9mRaHjrFnefKzrLX1w1WSO'. Prelude> 
05:50:18 <spatial> http://pastebin.com/bdKJ3Gr3 Like this ?
05:50:54 <quchen_> spatial: There’s still another else missing.
05:51:06 <quchen_> 3 ifs, only 2 else
05:51:34 <Unhammer> wtf do I do with bimodal criterion graphs :-S
05:55:15 <cocreature> Unhammer: run your benchmarks again and hope one mode disappears :)
05:56:09 <spatial> quchen_:() is »pure ()« ?
05:56:43 <spatial> newnextstate :: ( IOArray Int Int) -> BoardState-> IO ()        That is the type
05:56:45 <Unhammer> cocreature,  now they're trimodal! haha I should probably check top … 
05:56:50 <dramforever> no, literal 'pure ()'
05:56:58 <quchen_> No, () is the (single possible) value of the () type (pronounced »unit«). »pure ()« is the »pure« function applied to it.
05:57:07 <dramforever> letter p, letter u, letter r, letter e, space, open paren, close paren
05:57:12 <quchen_> pure () :: () -> IO ()
05:57:27 <dramforever> you mean pure :: () -> IO ()
05:57:47 <spatial> Thanks. All this for a if loop :-)
05:58:49 <Logio> spatial: what should your code be doing with the IOArray it's given?
05:58:50 <dramforever> well, that's what you get by writing haskell programs like that :(
05:58:51 <Itkovian> how do I tell ghc that libgmp.a is not in the expected location?
05:59:54 <Logio> spatial: because right now it seems to me that the parameter a is not used at all, but instead shadowed by a <- readvalue index
05:59:59 <spatial> It works with all your help
06:00:03 <kuribas> spatial: or with multiway if http://lpaste.net/353306
06:00:14 <spatial> Login: Fixed that
06:00:27 <spatial> Logio: Fixed
06:01:05 <kuribas> spatial: it looks very imperative
06:01:09 <Itkovian> ok nvm, -L should not have a space behind it :/
06:01:25 <spatial> kuribas: That is more legible.
06:01:28 <quchen_> spatial: There are no »if loops«. Ifs don’t loop. At best, you could argue »if« to be a loop that is run 0 to 1 times. But then you’d also have to say »statement loop« for things that run exactly once.
06:02:14 <kuribas> quchen_: maybe he want multiway if, like lisp COND
06:03:07 <quchen_> Yes, a multi-if would be useful here.
06:03:19 <spatial> I got 'when' now
06:08:30 <Dasio> Hello, could someoen help me how to Group list by equivalence relation, I tried something like this http://pastebin.com/JdH1J0K4
06:10:36 <c_wraith> Dasio: group only groups *consecutive* elements by an equivalence relation
06:12:32 <Dasio> c_wraith: I found this http://stackoverflow.com/questions/8262179/group-list-by-equivalence-relation, so i have to somehow sort it ? but idk how
06:12:49 <c_wraith> sort is one approach, but it's not the only one
06:14:18 <Dasio> is there any simpler solution ?
06:14:30 <c_wraith> You could repeatedly use partition
06:14:37 <c_wraith> well, partitionBy
06:14:50 <c_wraith> Err, no.  partition is the one that takes a predicate
06:29:28 <mathk> Hi, Anyone can show me some example of use of `Monad ((,) a)` ?
06:30:11 <mauke> > return 42 :: (String, Integer)
06:30:13 <lambdabot>  ("",42)
06:31:10 <c_wraith> mathk: It's exactly the same thing as the Writer monad, if that helps
06:31:59 <mathk> I see thanks
06:38:05 <mathk> c_wraith: Because of the Monoid constrain, should I understand that not only it is a Writer but it also collect the different write ?
06:38:29 <c_wraith> Writer has the same Monoid constraint
06:38:38 <mathk> ok
06:45:58 <unclechu> hi guys, does anyone know how to specify 'cabal' version for Travis-CI config?
06:46:47 <cris_> hi, could you check if my "personal libraries" section are correct? thanks in advance https://hastebin.com/ijeviqoqit.rb
06:47:31 <cris_> this is my ~/.nixpkgs/config.nix   
06:48:02 <Aruro> is it possible to run servant in sate monad? so the server can print its own log?
06:48:40 <cris_> i want to install my own library into nix ; i search over google and come up with above , but it still not working anot working
06:49:15 <cris_> after i run $ nix-env -iA nixpkgs.myHaskellEnv
06:49:30 <bennofs> cris_: it should look like https://hastebin.com/ilujoqaxif.m
06:50:23 <bennofs> cris_: also if you want to have carbonara in the env, you should add to the list of packages in the ghcWithPackages call
06:50:47 <bennofs> cris_: like https://hastebin.com/hutepuxeqi.m
06:51:09 <bezirg> hello, I have a type erro: ambiguous type, with only one potential instance. Can I force ghc to pick that instance, even if that means that the open world assumption of type classes will be broken?
06:53:21 <jan_path> bezirg: Is an explicit type signature an option?
06:54:49 <Aruro> does cabal have option of installing all libraries with prefix ? like : cabal install lens*
06:55:07 <cris_> thanks bennofs
06:55:08 <bezirg> jan_path: nope
06:56:41 <lyxia> bezirg: can you show us the instance and the use site
06:57:13 <cris_> bennofs: i got this error $ nix-env -iA nixpkgs.myHaskellEnv error: value is a set while an integer was expected, at /home/hp/.nixpkgs/config.nix:4:18
06:59:15 <bennofs> cris_: try https://hastebin.com/ayutuyibif.m, nix does not support ~ i believe
06:59:58 <lpaste_> bezirg pasted “A subtyping ambiguity error” at http://lpaste.net/353312
07:01:00 <bezirg> I lpasted it, I use an explicit subtyping function. I wish it was semi-explicit (no need to resolve the ambiguity) than explict (having to add type signatures)
07:02:39 <bezirg> btw, I_ is a subtype of I in that code
07:02:46 <bezirg> it is a contrived example
07:03:28 <lyxia> bezirg: will I ever be a subtype of something else
07:03:55 <bezirg> lyxia: no, let's assume closed world
07:03:56 <lyxia> this question sound weird if taken out of context
07:04:10 <cris_> hi bennofs , i have changed the path to hard path , but no luck , still see the same error ... h
07:04:26 <lyxia> bezirg: then you can rewrite the instance Sub I I to instance I ~ b => Sub I b
07:05:12 <lyxia> bezirg: it says exactly that I is only a subtype of itself, and helps type inference.
07:05:31 <bennofs> cris_: oh also try removing the slash at the end of the path
07:06:33 <bezirg> lyxia: thank you, this indeed helped
07:06:51 <bezirg> lyxia: however, how can I say the same for I_ ? that I_ is  a subtype of itself
07:06:58 <tsahyt> hello! is there a type that represents floating point numbers between 0 and 1 only?
07:07:06 <bezirg> lyxia: if I use the same EqualityConstraints pattern, it leads to another ambiguity
07:07:06 <tsahyt> including both endpoints
07:07:44 <lyxia> bezirg: well it's false for I_. I_ is not only a subtype of itself.
07:07:47 <cris_> hi bennofs, it works this time!!
07:07:51 <byorgey> tsahyt: no
07:08:13 <tsahyt> byorgey: not even in some library?
07:08:32 <bezirg> lyxia: indeed
07:08:39 <byorgey> tsahyt: I don't know, there might be one in some library somewhere, who knows
07:08:45 <lyxia> bezirg: you end up with an instance overlapping with Sub I_ I, so this doesn't help.
07:08:59 <bezirg> lyxia: OverlappingInstances will not do the job you think?
07:09:10 <lyxia> bezirg: you maybe it is only a super type of itself, then you could have instance a ~ I_ => Sub a I_
07:09:12 <byorgey> tsahyt: it depends what these numbers should represent and what kind of operations they should support.
07:09:32 <tsahyt> byorgey: seems easy enough to provide a wrapper around Double with smart constructors and numeric instances implementing either some form of modular or saturating arithmetic. but that seems like wasting a lot of the possible range of Double
07:10:09 <tsahyt> well I want to write a function [0,1] -> a, representing the (interpolated) frequency domain of a signal
07:10:18 <tsahyt> so really querying it would be enough I suppose
07:10:29 <byorgey> tsahyt: sure, it's pretty easy, which is probably why there's no standard library for it (and because there are lots of choices one could make for the operations and no obvious "right" choice)
07:10:36 <tsahyt> fair enough
07:10:45 <cris_> hi bennofs , i believe i should have installed my carbonara library to my nix ; when i enter ghci and type this ghci> :m + Data.Carbonara   , then this error msg shows:  Could not find module `Data.Carbonara'     It is a member of the hidden package `carbonara-0.0.1@carbonara-0.0.1-9mRaHjrFnefKzrLX1w1WSO'.
07:10:47 <tsahyt> I'll think about whether this is a smart idea and possibly implement my own if it makes sense
07:10:51 <byorgey> tsahyt: who cares about wasting the range of Double?  If you really care about memory usage, then use Float instead of Double
07:11:12 <jan_path> bezirg: Would a functional dependency do: class Sub a b | a -> b. So any type can only be subtype of at most one supertype?
07:11:12 <bezirg> lyxia: I added instance (a ~ I_) => Sub a I_ where up = id  , but it didn't work
07:11:15 <lyxia> bezirg: it won't. Let's say you had instance {-# OVERLAPPABLE #-} b ~ I_ => Sub I_ b, but also instance Sub I_ I, then the first instance will never be selected as long as b is unknown
07:11:26 <lyxia> because it overlaps with the second.
07:11:27 <tsahyt> byorgey: well I could have better precision within the same number of bits. not that it really matters in practice I guess
07:11:45 <byorgey> tsahyt: sure, you just have to decide what you care about.
07:11:49 <lyxia> bezirg: it will only be selected if you know in advance that b ~ I_, which defeats the whole point of the trick.
07:12:04 <tsahyt> first I need to figure out how to interpolate the spectrum in the first place
07:12:32 <tsahyt> this is simultaneously an attempt at learning more about DSP, so I'm writing this code as I go and discover the concepts.
07:12:38 <byorgey> sounds like fun
07:13:10 <tsahyt> it's been quite entertaining so far. I have no idea how well my code would run in the real world yet and there are quite a few challenges to be solved still to make this actually usable
07:13:27 <bezirg> lyxia: y, you are right
07:14:32 <bezirg> jan_path: I don't think functional dependency works, because there is not a single mapping from a to b. There may be many a's mapping to different b's
07:14:50 <lyxia> bezirg: Oh I didn't realize instance a ~ I_ => Sub a I_ overlaps with the previous one, that's pretty bad.
07:14:54 <bezirg> lyxia: I also tried ClosedTypeFamilies, AllowAmbiguityTypes but it didn't work
07:16:28 <lyxia> I can't see how these extensions would help
07:18:18 <bezirg> lyxia: I thought maybe I can close somehow the Sub typeclass through ClosedTypeFamilies, but it didn't work. AllowAmbiguityTypes can be used to "delay?" ambiguity resolution to the call site. Also didn't work
07:18:30 <bgamari> Axman6, hi
07:18:49 <bgamari> Axman6, did you work it out?
07:20:28 <lyxia> bezirg: you don't have definitions with ambiguous types though. The ambiguity is only at the call site.
07:20:48 <bezirg> lyxia: I thought maybe "default" could help here, but that is restricted to single parameter type classes of Eq,Ord,Num,Show
07:21:11 <lyxia> bezirg: This kind of explicit subtyping relation looks like an antipattern, because of this kind of issues and hacks involved.
07:21:40 <bezirg> lyxia: y definitely it is an antipattern. Standard Haskell does not support subtyping
07:21:45 <lyxia> But, maybe you have other good reasons. *shrugs*
07:22:00 <bezirg> lyxia: y indeed
07:22:21 <merijn> lyxia: No ambiguous definitions is only true without extensions :)
07:23:09 <merijn> Higher rank types don't have a unique most general type, so there types can be ambiguous even at the definition
07:33:37 <cris_> bennofs: I have resolved the issue, it was due to my old version of carbonara still lie in the system, which interfere with my current version; i just $ ghc-pkg unregister ...
07:33:53 <cris_> bennofs: thanks v much for your help
07:35:44 <bezirg> lyxia: what about IncoherentInstances?
07:38:05 <lyxia> Don't use this.
07:39:22 <merijn> IncoherentInstances secretly enables -XILikePainAndHateMyself
07:44:34 <bezirg> lyxia: I understand it is bad, but do you think it will lead to false positives (programs with concrete subtyping errors compiling correctly)? I can only think that it will lead to false negatives
07:45:28 <lyxia> You might end up picking instances you did not intend to.
07:48:36 <nilof> If I define a typeclass that extends another, how do I declare default implementations of the second in terms of the first?
07:49:29 <lyxia> nilof: DefaultSignatures
07:49:32 <nilof> Like say fmap from return & bind, or in my case, foldl in terms of heap pop
07:49:34 <nilof> ah
07:51:24 <lyxia> it's cleaner to define your default implementation separately and let users use it explicitly, like with Functor/Applicative/Monad in base.
07:53:58 <zipper> In https://github.com/tibbe/haskell-style-guide/blob/master/haskell-style.md#data-types the writer says "Additionally, unpacking simple fields often improves performance and reduces memory usage"
07:54:04 <zipper> What does that even mean?
07:54:11 <zipper> What does unpacking mean?
07:55:43 <zipper> LOL tibbe is in this chan, what did you mean?
07:55:53 <lyxia> zipper: The record "Point Double Double" is represented as a struct with two pointers to Double
07:56:24 <lyxia> unpacking avoids the indirection and directly puts the doubles in the fields of the struct
07:57:38 <zipper> hmmm been so long since I looked at C++
07:57:50 <zipper> Can't remember structs clearly
08:01:46 <lyxia> zipper: in memory this is the difference between two pointers and two actual values.
08:04:10 <ertes> nilof: if (class (A a) => B a), then you don't need DefaultSignatures
08:04:32 <ertes> you can refer to the members of A regularly
08:05:23 <unclechu> hey guys, could someone explain me why my Travis-CI tests fail on `cabal install`? https://travis-ci.org/unclechu/haskell-qm-interpolated-string/jobs/209019272
08:06:20 <unclechu> I'd generated `.travis.yml` file using this tool: https://github.com/hvr/multi-ghc-travis
08:06:21 <unclechu> I also tried to write it by my bare hands in different ways but without any success
08:07:30 <lyxia> unclechu: haskell-src-exts failed to install. You can then see that it complains about not finding happy.
08:08:26 <unclechu> lyxia: I should specify `happy` dependency in my `.cabal` file?
08:09:11 <lyxia> I don't think so, but I don't have a solution yet.
08:09:37 <osa1> unclechu: add `build-tools: happy`
08:10:07 <lyxia> if you're not directly depending on it you shouldn't do that
08:10:38 <lyxia> apparently you need to tell travis to install it https://github.com/haskell-suite/haskell-src-exts/blob/master/.travis.yml#L18
08:11:00 <nilof> I'm implementing a heap typeclass, is there a way to ensure that the parameter of my heap type is always Ord?
08:12:36 <lyxia> Add the constraint on all methods    class Heap heap where .... insert :: Ord a => a -> heap a -> heap a ...
08:13:49 <bezirg> A silly question: does an (id x) can be optimized to x? or this breaks the lazy semantics?
08:14:00 <lyxia> nilof: though if you can't add them I'm not sure you can
08:14:18 <nilof> right, the problem is when I try to extend foldable
08:14:34 <mauke> bezirg: looks valid to me
08:15:04 <nilof> I can add ord a in front of my own methods, but I'm running into issues because my foldl relies on my pop method
08:15:30 <nilof> and foldl as declared in Foldable doesn't require Ord
08:15:38 <nilof> so I get a type error
08:15:57 <lyxia> then it's not a valid implementation of Foldable
08:16:09 <bezirg> mauke: thanks
08:17:37 <lyxia> nilof: you could technically add the Ord constraint into your heap datatype
08:18:00 <SpinTensor> Hi, here are two functions (http://pastebin.com/wNyMVPj3) and I thought the type def of both would mean the same, but they are not. why? First one works, second one gives compile error.
08:18:01 <osa1> nilof: why not add a`Ord` constraint to your instance declaration?
08:18:30 <lyxia> SpinTensor: Num is a type class, it's not a type.
08:18:40 <osa1> nilof: instance Ord a => Heap (HeapImpl a) where ...
08:19:06 <SpinTensor> lyxia: so i can't use a type class but i can say a is part of the type class and then use a?
08:19:12 <unclechu> lyxia: thanks, will try
08:19:28 <mauke> SpinTensor: well, an instance of the class. it's not really part of it
08:19:54 <osa1> nilof: similarly, instance Ord a => Foldable (HeapImpl a)
08:20:19 <SpinTensor> mauke: ah, ok. good to know. thanks. that actually explains a lot. 
08:20:32 <lyxia> osa1: Foldable has kind (* -> *) -> Constraint
08:20:43 <osa1> ops
08:21:02 <lyxia> MonoFoldable would work though
08:23:15 <tsahyt> how comes that GHC can prove that (41 :: Nat) does not unify with (2 * n), but it can't infer KnownNat n from the context KnownNat (2 * n)?
08:25:25 <geekosaur> seems to me that if it only knows that latter context and nothing else, it can't prove the former can't occur (which would make (KnownNat n) false)?
08:25:38 <geekosaur> also the machinery is not especially smart; there are plugins that improve it
08:26:39 <delYsid> Hmm, is there a recommended (because quite feature-complete) dbus client package?
08:26:47 <tsahyt> what do you mean with "the former can't occur"?
08:28:04 <geekosaur> if it doesn't know n, it can't prove n is even
08:29:38 <max3> why does stack fail on a warning? http://pastebin.com/dq0abVPw
08:29:39 <tsahyt> hmm
08:29:45 <max3> is there a way to get it to soldier on?
08:29:57 <tsahyt> what if I introduced a constraint n ~ 2 * m
08:30:09 <geekosaur> you might be interested in the ghc-typelits-* plugin packages btw
08:30:22 <shapr> max3: did you read /home/databrary/src/.stack-work/logs/blaze-markup-0.7.1.1.log ?
08:30:22 <tsahyt> http://hackage.haskell.org/package/ghc-typelits-knownnat
08:30:23 <geekosaur> they make ghc a bit smarter about this stuff
08:30:24 <tsahyt> this looks interesting
08:30:48 <max3> shapr, it's exactly that warning
08:31:06 <geekosaur> ghc-typelits-natnormalize also comes highly recommended for this kind of thing
08:31:14 <max3> shapr, http://pastebin.com/HDkgBcUq
08:31:24 <tsahyt> geekosaur: since I've never used a ghc plugin before, can I handle this properly with cabal? e.g. I want to use this in a library, can I somehow put this into the cabal file and automate the process of installing and loading the plugin for the build?
08:31:38 <geekosaur> that I don't know, Ive not used plugins either
08:31:56 <tsahyt> ok. thanks for the suggestion!
08:32:48 <geekosaur> max3, can you pastebin that log file shapr mentioned?
08:33:02 <geekosaur> ExitFailure (-11) can in some cases mean something segfaulted
08:33:08 <max3> geekosaur, i did http://pastebin.com/HDkgBcUq
08:33:10 <geekosaur> in which case the warnings may be a red herring
08:33:49 <shapr> max3: yeah, there's something else going on
08:34:05 <geekosaur> that's all of it? :( might make a segfault even more likely
08:34:24 <max3> and how can i figure out what exactly is going on?
08:36:04 <geekosaur> painfully :/ if I suspected a segfault and couldn't find anything logged for it I'd probably haul out strace (or check syslog but linux doesn't log them as usefully as e.g. freebsd does...)
08:36:35 <max3> ghc[16725]: segfault at 7eff09fd6640 ip 00007eff08cfe6bb sp 00007ffe0a06f870 error 4 in libHSrts_thr-ghc7.10.3.so[7eff08ce4000+67000]
08:36:38 <max3> in dmesg
08:36:48 <shapr> max3: or you could grab the source from git and try to build that repo separately?
08:37:10 <max3> this is the most brittle thing ever
08:37:20 <shapr> no u
08:37:33 <shapr> I mean, I think it could be the legacy code you've inherited, rather than Haskell itself.
08:38:07 <max3> mime-mail had a bug and snoyberg fixed it and bumped the version number
08:38:15 <shapr> for example, I'm able to use stack to install blaze-builder here on my work laptop
08:38:16 <max3> so this has nothing to do with my code
08:38:39 <max3> and this segfault is on stack build --only-dependencies
08:38:48 <shapr> I got the same version, blaze-markup 0.7.1.1
08:39:13 <max3> and it does work for me too - if i hit stack build --only-dependencies like 3 times
08:40:02 <shapr> max3: wait what?
08:40:16 <max3> shapr, if i rerun eventually it all builds
08:40:24 <shapr> max3: that sounds like it could be memory errors or possible disk corruption
08:40:31 <max3> it's in a docker
08:41:02 <drostie> sounds like a fun new feature, ghc --give-up-after=3
08:41:12 <max3> lol
08:41:43 <drostie> "ok fine you WANT that binary, you GOT that binary, don't say I didn't warn you!"
08:42:03 <MarcelineVQ> max3: the issue where you have to build multiple times to get the dependencies built was resolved for me by upgrading stack to 1.4.*    stack upgrade --git --source-only
08:42:20 <shapr> MarcelineVQ: what was that issue?
08:42:51 <MarcelineVQ> I'm not sure it was reported directly, but the newer stack handles custom build options better so it seemed to have fixed it by proxy
08:43:06 <MarcelineVQ> most commonly when it happened was with cairo and gtk2hs
08:43:49 <nilof> Ah, another question: I'm trying to specialize a method using  (buildheap xs) :: Ord a => ImplHeap a, but I get a type error where the compiler doesn't want to match t a1 with t a
08:43:57 <shapr> I sort of want to see the results of "stack dot --depth 2 --external" for databrary, but I'm afraid
08:44:18 <max3> MarcelineVQ, what does the --source-only flag do?
08:44:41 <geekosaur> nilof, lpaste the full code and full error message?
08:44:43 <geekosaur> @paste
08:44:43 <lambdabot> Haskell pastebin: http://lpaste.net/
08:45:38 <nilof> http://lpaste.net/353317
08:45:46 <MarcelineVQ> It's builds things locally instead of grabbing pre-built stack binaries, probably not neccesary here since --git should have a newer version number but if it didn't it may just grab binaries instead of actually fetching from git iirc
08:46:21 <max3> MarcelineVQ, this doesn't upgrade to nightly but the latest release right?
08:46:57 <MarcelineVQ> it upgrades to the current master branch of the stack git repo  https://github.com/commercialhaskell/stack
08:47:42 <nshepperd> nilof: you may need ScopedTypeVariables there
08:48:43 <max3> MarcelineVQ, is master stable? i don't understand their workflow (i'm used to gitflow where master is always a release)
08:49:29 <geekosaur> nilof, yes, you'd need ScopedTypeVariables *and* prefix the type signature of heapsort with "forall a."
08:50:05 <nshepperd> nilof: by default, type variables are contained to their type signature, so that the a in 'heapsort :: (Ord a, Foldable t) => t a -> [a]' is different to the a in '(buildheap xs) :: Ord a => LeftHeap a'
08:50:09 <geekosaur> you expliitly told it *not* to typecheck; the "a" in your type ascription has nothing to do with the one in the signature, and effectively tells ghc it doesn't know the type
08:50:29 <max3> haha upgrading stack failed too
08:50:38 <max3>     ghc: internal error: evacuate: strange closure type -129660600
08:50:43 <unclechu> lyxia: https://travis-ci.org/unclechu/haskell-qm-interpolated-string/jobs/209032172
08:50:44 <unclechu> now i added `happy` to install in `.travis.yml` https://github.com/unclechu/haskell-qm-interpolated-string/blob/feature/travis-ci-testing/.travis.yml but still have this error
08:50:51 <geekosaur> max3, you have a hardware issue most likely
08:51:00 <geekosaur> or your docker is really broken
08:51:09 <max3> really? you think?
08:51:15 <geekosaur> and corrupting the memory image in the container
08:52:18 <MarcelineVQ> max3: not sure, I don't upgrade often unless I have issues, it has been stable for me in usage. nominally there is a branch called stable that I imagine is for releases, it won't have the update that fixed the depdendency issue for me
08:53:02 <lyxia> unclechu: it seems you're missing the equivalent of this line https://github.com/haskell-suite/haskell-src-exts/blob/master/.travis.yml#L35
08:53:20 <geekosaur> basically "strange closure type" means one of: (a) you're using a buggy ghc prerelease (b) you have FFI and some *really* wild pointers (c) you have general memory corruption
08:54:24 <kadoban> max3: Can you run memtest86 or something like that without much trouble? That's usually where I start when impossible things are happening that suggest hardware failure.
08:54:27 <unclechu> lyxia: thanks again
08:54:49 <max3> kadoban, lemme see if reinstall docker helps
08:55:30 <nshepperd> if you suspect your machine might have faulty ram, you should reboot into memtest86+ and test it asap, because faulty ram tends to stomp all over your hard disk and destroy your data
08:55:44 <kadoban> That's usually where I end as well, since every time it's found a problem :-/ It always seems to be RAM failure. Though it's few data points, so that may not be representative.
08:55:51 <nshepperd> (also I hope you have backups)
08:57:15 <max3> i'll be shocked if it's corrupted memory
09:00:38 * geekosaur hs had enough issues (and talked with enough other people who have) with docker that he'd check that first. neat idea, but the "move fast, break stuff" model tends strongly toward the latter
09:04:45 <sidei> @help
09:04:45 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
09:05:02 <sidei> @list
09:05:02 <lambdabot> What module?  Try @listmodules for some ideas.
09:05:13 <max3> geekosaur, certainly it's not beyond the realm of possibility; after all golang is no haskell :)
09:05:18 <unclechu> lyxia: https://travis-ci.org/unclechu/haskell-qm-interpolated-string/jobs/209041415 kinda same story https://github.com/unclechu/haskell-qm-interpolated-string/blob/feature/travis-ci-testing/.travis.yml
09:05:37 <sidei> @help list
09:05:37 <lambdabot> list [module|command]. Show commands for [module] or the module providing [command].
09:06:17 <sidei> @pl f a b = (a+b)/2
09:06:17 <lambdabot> f = flip flip 2 . ((/) .) . (+)
09:06:26 <geekosaur> don't think the implementation langaueg matters here. too much low level stuff and types can;t save you (unless you go full Agda and I suspect *nobody* wants to write the proofs for page tables)
09:06:41 <lyxia> unclechu: we made progress, haskell-src-exts was built
09:07:18 <lyxia> unclechu: your version of cabal is too old
09:07:19 <_sras_> How can you output something like this `<div>Click <a href='#'>Here</a><div>` using lucid?
09:07:31 <lyxia> unclechu: "The package requires Cabal library version -any && >=1.18"
09:09:36 <suppi> div_ $ a_ [ href_ "#" ] "Here" -- maybe?
09:09:36 <unclechu> lyxia: yep, now some another ghc versions passed
09:09:50 <unclechu> first good news
09:10:02 <suppi> i'm not in front of a computer
09:18:46 <max3> geekosaur, indeed it was docker
09:19:23 <max3> actually i take that it back it hasn't gone all the way through yet
09:23:50 <twopoint718> I’m attempting to use `runResourceT` (`resourcet` pkg) in combination with `createPool` (`resource-pool` pkg) and things are starting to feel a little funky. Am I duplicating behavior here? Should I be using one or the other? In particular, I’m planning on setting up a connection to Neo4J using `haskell-neo4j-client`‘s `newConnection` function which just returns an `IO Connection`. My idea was to get the connection with that function,
09:23:51 <twopoint718>  then use `createPool` to manage the opening/closing for me. The issue arises when I want to close the connection. https://www.stackage.org/haddock/lts-6.11/haskell-neo4j-client-0.3.2.2/Database-Neo4j.html#v:newAuthConnection suggests that I use `runResourceT` to manually close the connection, but it would seem that I need a “primitive” close function to be able to `allocate` a ResourceT. I feel a little like I’m going in circles, any
09:23:51 <twopoint718>  ideas?
09:24:30 <twopoint718> (sorry for the long question. tl;dr has anyone used ResourceT in combination with resource-pool?)
09:26:24 <max3> geekosaur, yup docker
09:26:26 <max3> interesting
09:28:06 <geekosaur> not surprising. it's doing its own page table management for the container; even tiny bugs in that lead to seriously weird behavior
09:29:27 <brynedwards> twopoint718: it looks like the neo4j client uses http-conduit for connections, so it might to use http-conduit sessions instead
09:31:53 <unclechu> guys, how i can write condition for ghc version for preprocessing?
09:32:36 <twopoint718> brynedwards: could you elaborate a bit, I'm not sure I follow
09:32:41 <brynedwards> twopoint718: You can see here, a connection is just a http-conduit Manager and connection details https://hackage.haskell.org/package/haskell-neo4j-client-0.3.2.4/docs/src/Database-Neo4j-Http.html#newConnection
09:33:11 <brynedwards> Specifically, this https://hackage.haskell.org/package/http-conduit-2.2.3.1/docs/Network-HTTP-Conduit.html#t:Manager
09:34:14 <unclechu> i guess i found it: http://stackoverflow.com/questions/28292476/ghc-version-check-in-code#28292585
09:35:07 <brynedwards> As it says under manager, "If possible, you should share a single Manager between multiple threads and requests.
09:35:46 <brynedwards> I don't know if it's any different for neo4j, and the library doesn't seem to let you pass your manager
09:35:54 <brynedwards> Basically, I don't know, sorry =(
09:36:42 <geekosaur> unclechu, https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/phases.html#standard-cpp-macros
09:37:43 <twopoint718> brynedwards: well thanks for the pointer that does help, even if it tells me I have to reconsider what I was trying. Thanks!
09:43:07 <EvanR> so
09:51:27 <suica> how can I do something to the effect of `map 3 [(+1), (+2), ..]`? I figured it out yesterday  but now I can't remember
09:51:59 <osa1> > map ($ 3) [(+ 1)]
09:52:02 <lambdabot>  [4]
09:52:11 <suica> sweet, thanks
09:52:26 <farao> hi, I just started with haskell and am doing some exercises and I'm wondering how to split a list into two parts. I found "split" and "splitWhen" but they split the whole list. I am rather looking for an equivalent of: let part1 = takeWhile myFun xs; part2 = dropWhile myFun xs in ...
09:52:46 <glguy> :t span
09:52:48 <lambdabot> (a -> Bool) -> [a] -> ([a], [a])
09:53:08 <farao> cool, thanks! :-)
09:53:56 <byorgey> farao: span, break, splitAt
09:54:12 <byorgey> also partition
09:54:15 <farao> :t break
09:54:17 <lambdabot> (a -> Bool) -> [a] -> ([a], [a])
09:54:29 <byorgey> break is just the negation of span
09:54:45 <farao> ah ok! yeah, span is the one I'm looking for :-)
09:55:33 <shapr> max3: do you get consistent builds after reinstalling docker?
09:55:49 <max3> if 1 is enough to qualify as consistent then yes
09:56:27 <suica> :t [1,2] >>= (flip map) [(+1), (+2)] . (flip $)
09:56:30 <lambdabot> (Num (a1 -> (a -> a) -> c), Num a) => [a1 -> c]
09:57:42 <MarcelineVQ> that's quite the Num instance
09:58:05 <suica> I kind of expect that to give `[2, 3, 3, 4]`
10:00:20 <glguy> > [1,2] >>= (flip map) [(+1), (+2)] . (flip ($))
10:00:22 <glguy> so close
10:00:26 <lambdabot>  mueval-core: Time limit exceeded
10:00:30 <glguy> [2,3,3,4]
10:00:35 <glguy> ?undefine
10:00:35 <lambdabot> Undefined.
10:00:38 <glguy> > [1,2] >>= (flip map) [(+1), (+2)] . (flip ($))
10:00:42 <lambdabot>  [2,3,3,4]
10:03:15 <Xyliton> How do I iterate over the pixels in images generated by friday and/or juicypixels?
10:04:17 <MarcelineVQ> juicypixels has pixelMap iirc
10:04:56 <suica> glguy: thanks
10:05:15 <suica> i should probably just stick with map and concat
10:06:41 <MarcelineVQ> suica: you can also name your value for clarity    [1,2] >>= \x -> map ($ x) [(+1), (+2)]
10:09:06 <Xyliton> MarcelineVQ: I don't want to modify the image though
10:18:49 <thatguy> if I need to randomly resort my list often, is it better to use arrays?
10:23:33 <kadoban> thatguy: What does "randomly resort" mean? Is it always sorting by the same comparison function, or?
10:23:37 <_sras_> What is the best way to read some multiline content from stdin, like contents of a text file piped to the program?
10:53:43 <robotrafficcop> Hey all, I'm getting this weird error on "stack build" on a VPS I just spun up. It says that it can't get a file from S3. Maybe related to the recent outage? https://gist.github.com/wyager/e18f5832e2ed29c1f9ba3b197c52432f
10:54:18 <thatguy> kadoban: I meant a random shuffle but I found what I needed
10:59:13 <glguy> robotrafficcop: If your VPS can't resolve that hostname it's probably just misconfigured
11:02:02 <robotrafficcop> glguy: It resolves s3.amazonaws.com just fine. nslookup and ping both work
11:02:11 <robotrafficcop> Which makes me think it might be an issue with something on the Stack end
11:07:59 <robotrafficcop> Well, I tried rebooting, and that seemed to fix it. Typical! No particular reason that should have done anything. Thanks for the suggestion!
11:08:58 <robotrafficcop> Spoke too soon, still broken. Looks like it's doing a request in the background and it's timing out later in the build process
11:09:30 <marekw2143> hi, here: https://bitbucket.org/chessRepo/c7/src/a41bb7d3c99f1dfb1267ec633f898c35b585585e/main.hs?at=master&fileviewer=file-view-default#main.hs-168
11:09:45 <marekw2143> why there's need to be if - else in 168'th line, and not just simply let .. in ? 
11:24:31 <twopoint718> brynedwards: Thanks for the help. I was able to figure out a solution to my above problem. Briefly, I was able to extract the connection `Manager` inside the Neo4j `Connection` type. This has a `closeManager` function available that worked for being able to satisfy `createPool`. The slight catch is that closeManager is deprecated, but it'll work for my immediate issue.
11:26:13 <Geekingfrog> I'm having a weird HandshakeFailed error using Req to query www.youtube.com: http://lpaste.net/353322 (using arch-linux, stack and req-0.2.0). Any idea ?
11:41:50 <felko> how can i partially apply a parametrized type alias ?
11:42:35 <felko> for some types it is ok to type (F a) even if F a has not a * kind, but in case it doesn't work for some reason i don't know (paste incoming)
11:43:14 <Tuplanolla> Can't, felko.
11:43:44 <Tuplanolla> If the parameter is present in the definition, it must also be present in application.
11:44:20 <felko> is there a specific reason for that ?
11:44:30 <Tuplanolla> Yes, but I don't remember it.
11:48:01 <felko> Tuplanolla: ok it doesn't matter anyway, i can do what i want without, thanks
11:50:04 <Tuplanolla> I recall it's there to keep type-level lambdas out of the system.
11:50:31 <Tuplanolla> Those would have troublesome computability properties.
11:52:25 <felko> Tuplanolla: why ?
11:52:51 <Tuplanolla> Lambda calculus is Turing complete.
11:53:49 <felko> i agree that a type-level lambda calculus could lead to haskell black magic but is it problematic ?
11:55:02 <Tuplanolla> That depends on your view of problematic. It certainly is if you want to keep compilation decidable.
11:56:03 <felko> ok i understand, thanks
12:05:27 <unclechu> lyxia: thanks a lot for the help! now everything is green and i'm happy because i have completed everything i'd planned for today: https://hackage.haskell.org/package/qm-interpolated-string
12:06:05 <lyxia> unclechu: nice! you're welcome!
12:07:55 <lyxia> I'm pretty sure we already have Turing-completeness in types.
12:08:10 <monochrom> What does "qm" stand for there?
12:08:11 <lyxia> At least we have UndecidableInstances
12:19:14 <byorgey> monochrom: from the readme: 'm' in 'qm' means 'multiline'.
12:19:31 <byorgey> presumably the 'q' stands for 'quote' or 'quasiquote' or something like that
12:50:43 <kuribas> How do I force return () to be evaluated every time in "trace errStr (return ())"?
12:53:49 <monochrom> That "return()" is evaluated iff the whole "trace errStr (return())" is evaluated.
12:53:50 <ski> perhaps you want `errStr' outputted whenever this action is *executed* (not evaluated) ?
12:54:29 <kuribas> ski: yes
12:54:50 <kuribas> ski: it's not IO though, it's a State monad.
12:55:30 <ski> `State MyStateType' ?
12:55:41 <kuribas> yes
12:55:43 <monochrom> My iff sentence is still true for s/evaluate/execute/
12:56:38 <kuribas> :t unsafePerformIO
12:56:40 <lambdabot> error: Variable not in scope: unsafePerformIO
12:58:08 * ski was thinking of something along the same lines as `evaluate'
12:58:31 <ski> @type evaluate
12:58:33 <lambdabot> a -> IO a
13:00:03 <ski> (but presumably the difference doesn't make any difference in your case, in which case what monochrom said)
13:01:05 <kuribas> or maybe  const (return ()) var, where var is a variable in the monad? 
13:01:39 <ski> whatever `var' is, that is equal to just `return ()'
13:01:54 <ski> (not sure what you mean by "a variable in the monad")
13:02:18 <monochrom> That "return()" is evaluated iff the whole "const (return()) var" is evaluated. Similarly, executed.
13:02:44 <kuribas> ski: A variable that is only evaluated when the monad is executed.
13:02:57 <monochrom> Also, the var is ignored in all 4 cases.
13:03:10 <ski> monads are not run-time things, that can be executed or not
13:03:18 <ski> monadic actions can be executed, though
13:03:55 <ski> `var' is not evaluated when `const (return ()) var' is evaluated
13:04:37 <kuribas> ski: I don't care about var.
13:05:26 <kuribas> or "trace (const msg var) (return ())"?
13:05:34 <ski> i'm not sure why you mentioned `const' ..
13:06:57 <kuribas> I want to trick ghc into evaluating it...
13:07:52 <kuribas> Doesn't work if it inlines it to msg...
13:09:40 <ski> `const msg var' won't evaluate `var', regardless of inlining or not
13:10:18 <kuribas> ski: but it may evaluate the expression if var has changed...
13:12:11 <monochrom> No, const tricks GHC into not evaluating things.
13:12:29 <kuribas> ski: if const where a black box, it would try to evaluate it.
13:12:34 <monochrom> Why are you not talking about seq which does trick GHC into evaluating things?
13:13:20 <kuribas> monochrom: var `seq` trace msg (return ())?
13:13:27 <monochrom> var does not change, and const is not a black box.
13:13:37 <monochrom> I'm going to be blunt and ask "what are you smoking?"
13:14:09 <monochrom> That will evaluate var iff the whole thing is evaluated.
13:14:32 <lyxia> Show some code!
13:15:36 <ski> kuribas : even if `const' was in a library that was only loaded at run-time, `var' would still not be evaluated in `const (return ()) var'
13:16:15 <kuribas> ski: I only want the trace...
13:16:45 <kuribas> ski: ghc would try evaluating it, because it doesn't know var doesn't get evaluated.
13:17:49 <lyxia> kuribas: trace is already marked NOINLINE so it won't do funny things with inlining.
13:19:04 <ski> kuribas : no, it would not
13:19:46 <Aruro> is lense-like library should be part of haskell syntax?
13:20:29 <kuribas> lyxia: this is just a part of my code: http://lpaste.net/353329
13:20:59 <ski> unless we're talking about speculative evaluation of some sort, the traditional way to implement non-strict semantics is to *not* have argument expressions reduced before calling the function. instead the body of the function (or perhaps even what the caller decides to do with the result of the function) will determine when and if the arguments are reduced
13:21:45 <dolio> Note: GHC doesn't do speculative evaluation. :)
13:21:59 <monochrom> Yes, the evaluator expands the function body first. If the body doesn't mention a parameter, that parameter is ignored afterall.
13:22:22 <monochrom> This is why const is not going to be a black box like you think some imported C function is.
13:22:44 <monochrom> The evaluator will look inside.
13:23:22 <ski> in a sense, `const' is (or could as well be) "black-box", but it would still not have the operational semantics you were thinking
13:24:07 <kuribas> ski: const msg var, isn't a constant expression, when var is free...
13:24:16 <kuribas> ski: only after inlining.
13:24:38 <monochrom> This is not about inlining.
13:25:02 <kuribas> if const were a black box function, the evalutor wouldn't know it is constant.
13:25:13 <kuribas> So it would have to evaluate it.
13:25:29 <ski> no
13:25:42 <ski> it passes `msg' and `var', *unevaluated*, to `const'
13:25:49 <monochrom> There are many experiments you can perform to refute that hypothesis.
13:25:53 <ski> `const' then decides which of the arguments to evaluate
13:26:17 <kuribas> ski: now you are admitting it will evaluate const?
13:26:45 <ski> `const' itself (whose value is a function) will be evaluated, since it's the function expression in a function call
13:26:50 <monochrom> We have always asserted that "const" is evaluated. First.
13:27:06 <monochrom> Does not imply that the 2nd parameter will be evaluated. Ever.
13:27:36 <kuribas> monochrom: I don't care about the 2nd parameter...
13:27:39 <ski> `const' must be evaluated in order to determine the function body (with actual parameter expressions substituted for formal parameters) to continue evaluation at
13:27:44 <monochrom> You can define your own const-like function and turn off optimization and what-not. Everything we said will still hold.
13:28:10 <monochrom> OK, what do you care?
13:28:26 <kuribas> monochrom: that the debug trace gets outputted.
13:28:41 <monochrom> OK, it works for me. What's the problem?
13:28:47 * ski doesn't see a `const' in the paste
13:29:02 <ski> (if `DEBUG' isn't defined, then `debug' is equal to `flip const', however)
13:29:17 <kuribas> monochrom: well, const get inlined, so it isn't a black box...
13:29:36 <ski> even if it doesn't get inlined, it will still behave exactly the same
13:29:44 <monochrom> I don't see the relevance.
13:29:51 <kuribas> ok, I'll try...
13:29:59 <ski> `const msg (error "boom !")' won't evaluate the `error' call, e.g.
13:32:23 <monochrom> You have an experiment I can reproduce to unambiguously refute what I said?
13:36:50 <kuribas> monochrom: right, I tested it.  With (const msg freshVar), I see the trace, without only once.
13:37:22 <kuribas> monochrom: how would ghc now it cannot subsitute that with msg?
13:37:28 <nilof> Ah, you can't have several modules in the same file?
13:37:48 <kuribas> monochrom: does it know there is an trace or unsafePerformIO function?
13:38:15 <Tuplanolla> Your thought process is really difficult to follow, kuribas.
13:38:45 <jle`> nilof: correct
13:39:20 <kuribas> Tuplanolla: well, if I have 'debugM "mesg"', I see the trace only once.  If I use 'debugM (const "msg" freshvar)', I see it every time it is executed.
13:39:38 <kuribas> Tuplanolla: what keeps ghc from inlining const, and rewriting the second into the first?
13:40:25 <Tuplanolla> Is this from `hslogger`?
13:40:31 <Sh4pe> Hi folks! Quick question: I import Data.ByteString.Char8 as C. Then, the statement `newtype Foo = C.ByteString` causes this error: `Qualified name in binding position: C.ByteString`. I don't understand why and I can't find a fix myself
13:40:46 <lyxia> this would be so much easier if we had a minimal example.
13:40:50 <cocreature> Sh4pe: you need to give a name to the constructor of your newtype
13:40:59 <cocreature> "newtype Foo = Foo C.ByteString" will work
13:41:25 <Sh4pe> cocreature: Ah - I see. Thanks!
13:41:53 <kuribas> Tuplanolla: no...
13:42:56 <monochrom> kuribas, I still do not know how to reproduce your experiment. How do I reproduce your experiment?
13:43:26 <monochrom> Hell, how do I do so with little effort? (Too lazy to even "stack install stuff")
13:44:21 <kuribas> > traverse_ [1..4] $ \i -> trace "debug message" $ return ()
13:44:24 <lambdabot>  error:
13:44:24 <lambdabot>      • Couldn't match expected type ‘a0 -> f b0’
13:44:25 <lambdabot>                    with actual type ‘[Integer]’
13:44:45 <Itkovian> any idea why stack --compiler ghc-8.0.2 --stack-root=/usr/local/vpw/haskell/stack --extra-lib-dirs /usr/local/vpw/lib/ install split fails with a symbol from libgmp not foudn (which resides in /usr/local/vpw/lib/libgmp.a) 
13:44:56 <Itkovian> it seems like the extra lib is not passed to ghc
13:45:38 <Itkovian> however, when just running the stack ... ghc -- --make main.hs, it is found
13:46:10 <ezyang> Man, accelerate-llvm really is not easy to build 
13:47:53 <nilof> So stupid question: how do I import a module in a file that is in the same directory?
13:48:06 <monochrom> Just do it.
13:48:17 <monochrom> But mind filename cases (upper or lower).
13:49:56 <Athas> ezyang: if you manage to get it work with the LLVM-based GPU backend too, please let me know!
13:50:03 <ezyang> lol 
13:50:13 <ezyang> I got to a GHC panic and then gave up 
13:51:40 <nilof> ah, my ghci directory was set to the wrong directory, now everything works
13:52:05 <kuribas> monochrom: try this: http://lpaste.net/2846700419663527936
13:52:09 <monochrom> ghci has a ":cd" command
13:52:19 <davean> ezyang: I feel accelerate has never been well maintained, I've never managed to actually use it
13:52:36 <kuribas> monochrom: behaviour is different compiled from in ghci...
13:54:53 <kuribas> monochrom: the second gives 4 times "debug message", the first only once.
13:56:10 <monochrom> kuribas, I am in ghci, version 8.0.2, both give me 4 messages.
13:56:34 <kuribas> monochrom: try compiling it
13:56:47 <monochrom> OK. -O0? -O1? -O2?
13:56:50 <kuribas> -O2
13:57:18 <kuribas> ghc 8.0.1
13:57:26 <monochrom> OK, reproduced.
13:58:36 <kuribas> I would think ghc will inline const, and make the two equivalent.
13:59:50 <monochrom> But there are other moving parts. How do you know, for example, that optimizations didn't do something to traverse_ and affected this experiment too?
14:00:15 <monochrom> Or even [1..4]
14:00:54 <monochrom> Or the way (\i -> trace whatever) is optimzied or not optimized.
14:01:53 <kuribas> @src trace
14:01:54 <lambdabot> trace string expr = unsafePerformIO $ do
14:01:54 <lambdabot>     hPutStrLn stderr string
14:01:54 <lambdabot>     return expr
14:01:59 <monochrom> I mean, of course, "const" is the most visible difference syntactically, but you probably need to cross this with some other things too for a real difference to be manifested.
14:02:53 <monochrom> I don't think you can trust @src anymore. Look at Debug.Trace actual source code.
14:05:08 <kuribas> well, at least I have my trace messages :)
14:05:54 <monochrom> You will want to look at the Core code.
14:06:02 <codedmart> Anyone familiar with Pool here? I use it with RethinkDB. Which in most cases it works fine, but I have one instance `Changes` where it is a blocking operation. Basically it just sits and waits for an answer https://github.com/AtnNn/haskell-rethinkdb/blob/c7df4f219f1e7251629a9e90280f1ebdfed9ec8c/Database/RethinkDB/Network.hs#L407-L413. The problem is I get
14:06:03 <codedmart> this error `Left thread blocked indefinitely in an MVar operation` over and over. I have a hacky way around this by using `forkFinally` to just restart it, but that is not an optimal solution. Any thoughts/ideas? I am actually not sure if this is even a Pool problem. I assumed it had something to do with reaping
14:06:03 <codedmart> https://github.com/bos/pool/blob/master/Data/Pool.hs#L203, but I haven't used MVar's yet so could be way off base.
14:23:43 <monochrom> kuribas: "const is inlined or not" does not fully explain it, because in the Core code, there is no longer const or mention of i, it is always 'trace "debug message"'.
14:24:14 <kuribas> monochrom: right
14:24:53 <kuribas> monochrom: so ghc is keeping track of the fresh variable i, and makes sure the expression is evaluated every time...
14:26:02 <kuribas> monochrom: or something else to do with unsafePerformIO...
14:26:40 <monochrom> But it is true and I don't know why that in the no-const version, a top level CAF "xxx = trace "debug message" (return ())" is introduced, then reused by the loop. Whereas in the has-const version, the trace is not a CAF, it is re-created every iteration.
14:28:49 <kuribas> Does unsafePerformIO even have clear semantics?
14:29:04 <monochrom> Yes for GHC.
14:29:27 <jophish> Hi folks
14:30:53 <monochrom> I consider it unlikely that unsafePerformIO caused the difference.
14:32:03 <jophish> When do people find it appropriate to curry constraints to functions? i.e. `foo :: Eq a => Num a => a -> a -> a` instead of `foo = (Eq a, Num a) => a -> a -> a`
14:32:28 <monochrom> I consider it far more likely that the order of optimization stages caused the difference. Namely, my hypothesis: First looking for what you can factor out as CAFs, and only after perform simplication and discovering data independence.
14:32:43 <jophish> I have an intuition for where this is a nice thing to do, but am having trouble formalising it
14:34:00 <monochrom> So, for the no-const version: i is not mentioned anywhere syntactically, so factor out trace "dm" (return ()) as its own CAF first, call it xxx, now proceed to compile (\i -> xxx).
14:34:44 <monochrom> And for the has-const version: "Oh nothing to factor out as CAF". Only later to simplify const "dm" i to "dm".
14:34:51 <lyxia> jophish: what's an example where this is useful?
14:35:03 <monochrom> (And so no dependence on i after all, but the factoring ship has sailed.)
14:36:14 <jophish> lyxia: for example I might pass in a bunch of KnownNat constraints to a function after reifying them in a function taking a bunch of Naturals
14:36:31 <jophish> it's nice to highlight the similarities between these two functions by replacing the ->s with =>s
14:36:55 <jophish> admittedly this is a niche case, I'll try and think of a more compelling one
14:37:07 <kuribas> monochrom: this has the same bevaviour: http://lpaste.net/2846700419663527936
14:37:51 <jophish> These kind of signatures most often appear in the parts of our codebase which do a lot of type level computation and term -> type doohickery
14:39:06 <monochrom> Well yeah I'm just referring to the trace expression and whether it syntactically involves i or not.
14:39:45 <monochrom> No one will factor out "trace dm (return ()) >> return i" but the "trace dm (return ())" part can always be factored out.
14:40:22 <kuribas> but the inliner runs in many stages.
14:41:14 <monochrom> Yes, my hypothesis still has a lot of holes.
14:41:23 <kuribas> anyway idk, I am not a ghc expert...
14:41:26 <monochrom> But a lot other hypotheses are clearly worse.
14:42:00 <kuribas> I guess trace, unsafePerformIO, etc... will be always unpredictable.
14:42:12 <kuribas> It's isn't even the same in ghci and compiled.
14:42:40 <kuribas> In my case it's only for debugging, so that's fine.
14:42:49 <monochrom> To some extent, trace is intended to expose compiler mutilations.
14:43:58 <monochrom> It does not advertise itself as "I will show you what happens when faithfully following the vanilla naive lazy evaluation strategy".
14:44:22 <monochrom> It totally intends to show "what did the compiler decide to actually do"
14:44:55 <monochrom> But "compiler" does vary along the axis of ghci -> O0 -> O1 -> O2.
14:45:12 <bennofs> monochrom: doesn't trace inhibit at least some floating out optimization?
14:45:33 <monochrom> In fact, not just "compiler", also "run time system", at which point turning on or off profiling may matter, too.
14:46:25 <monochrom> I don't know. But it didn't inhibit this one.
14:47:22 <hpc> don't forget the llvm and javascript backends too
14:50:48 <monochrom> kuribas: Observe what happens when -fno-full-laziness
14:58:28 <Axman6> bgamari: hey, no I didn't. I might have a look at how the parser can be changed, seems the use of `double` might be more strict than the WKT language allows
15:00:09 <bgamari> Axman6, oh dear
15:00:25 <bgamari> Axman6, WKT isn't exactly the best-specified format I've written a parser for
15:00:33 <bgamari> so please do submit PRs
15:01:01 <bgamari> ideally I would start collecting some examples for a testsuite
15:23:08 <lpaste_> robkennedy revised “Classes on Functions - Why won't this typecheck?”: “Classes on Functions - Why won't this typecheck?” at http://lpaste.net/699260116473479168
15:23:43 <robkennedy> If anyone could look at that it'd help a lot
15:27:51 <robkennedy> In particular it's seeming to not unify `forall a. a -> o` where o is free
15:33:40 <lpaste_> robkennedy revised “Classes on Functions - Why won't this typecheck?”: “Classes on Functions - Why won't this typecheck?” at http://lpaste.net/699260116473479168
15:36:31 <rick_rustled> i can't for the life of me see how "seperating syntactic analysis from execution" makes any difference in terms of SICP's metaevaluator
15:36:36 <rick_rustled> https://mitpress.mit.edu/sicp/full-text/book/book-Z-H-26.html#%_sec_4.1.7
15:36:56 <rick_rustled> i see no gain in efficiency whatsoever
15:37:01 <rick_rustled> it seems like the same thing is happening either way; seperating analysis from execution seems inconsequential to me (i'm obviously missing something here)
15:43:11 <EvanR> syntactic analysis doesnt seem to have anything to do with execution to me
15:43:21 <EvanR> especially in the haskell channel, where even evaluation has nothing to do with execution
15:43:47 <hpc> the lexical syntax of comments, though?
15:43:50 <hpc> definitely execution
15:46:20 <lpaste_> glguy annotated “Classes on Functions - Why won't this typecheck?” with “Classes on Functions - Why won't this typecheck? (annotation)” at http://lpaste.net/699260116473479168#a7876565830081708032
15:46:40 <glguy> robkennedy: When you're making this much of a mess, mixing rank-n types in is easiest to manage under a newtype
15:47:15 <glguy> (that version loads)
15:50:32 <sphinxo>  So i'd like to make a version of State, where get and put take an additional param
15:50:54 <sphinxo>  so example usage would be {put True 10; put False 20} and then doing get 15 yields True, but get 25 would yield Fals
15:51:17 <Koterpillar> sphinxo: why not use a State over Map Int Bool?
15:52:18 <sphinxo> or (Ord a) Map a b ?
15:52:34 <Koterpillar> whatever suits you
15:53:10 <Koterpillar> then you can have convenience functions putKey :: k -> v -> State (Map k v) (), getKey :: k -> State (Map k v) (Maybe v)
15:53:56 <sphinxo> I'm not sure that's what I want
15:54:16 <Koterpillar> then what do you want?
15:54:20 <sphinxo> I want like a time traveling k/v store
15:54:40 <sphinxo> so for example put <k> <v> timestamp
15:54:47 <sphinxo> so for example put <k> <v> timestamp + 5
15:55:08 <sphinxo> and then get <k> timestamp + 3 would give me the first v
15:55:41 <Koterpillar> all of this is still a State over some structure
15:55:49 <sphinxo> actually yeah
15:55:59 <Koterpillar> not necessarily a Map, but you get to reuse the State instance
15:57:28 <sphinxo> but say it's not a Map, say I want to set the state to be x and <timestamp> and then set it to y at  <timestamp + 5> and then get it at timestamp + 3, which should give me x
15:57:47 <sphinxo> to be x *at <timestamp> 
15:57:50 <Koterpillar> right, so that's a data structure you can have
15:58:03 <Koterpillar> ...actually, still map
15:58:20 <Koterpillar> it has a "get the first key that's lower than X"
15:58:48 <sphinxo> ahh ok
15:59:01 <robkennedy> glguy: thanks. Don't understand how that fixed it
15:59:11 <sphinxo> Koterpillar: what's the name of that function?
15:59:44 <Koterpillar> sphinxo: lookupLT
15:59:51 <Koterpillar> (LE/GE/etc.)
16:00:05 <sphinxo> ahh wonderful
16:03:02 <glguy> robkennedy: The type 'o' can't float out of (forall i. c i => i -> o) because we don't know what c is
16:03:07 <glguy> c could have equality constraints
16:03:38 <glguy> and type families are not injective, so 'o' isn't available under FullOf'
16:07:37 <Axman6> bgamari: yeah the first definition I stumbled across was v1, which has een replaced by v2 which seems to be much better specified: http://docs.opengeospatial.org/is/12-063r5/12-063r5.html#13 in particular, it outlines what a <number> is, which the old one left unspecified... who even does that
16:07:55 <bgamari> heh
16:08:04 <bgamari> that may explain it
16:08:23 <bgamari> would you like to fix this or should i?
16:08:49 <Axman6> bgamari: I might give it a go if I have time, but today it least that's looking unlikely :)
16:09:09 <bgamari> I can have a look tonight
16:10:23 <Axman6> don't rush into it on my account though, I don't have a good usecase for it yet, just wanted a nicer structure for dealing with projection descriptions.
16:11:44 * Axman6 has grand but probably very ambitious plan to rewrite proj4 in Haskell
16:14:34 <bgamari> Axman6, that would be great
16:14:56 <bgamari> we could really use some better geospatial tools
16:15:17 * bgamari has done some hydrological modelling in Haskell and it was quite painful
16:15:39 <Axman6> yes,very much so. I was surprised how understandable proj4 actually is tbh
16:17:41 <robkennedy> How can I silence unused errors for data constructors (since I can't use `newtype F = _F {unF :: Int}`)
16:18:35 <glguy> You can export the data constructor
16:21:10 <robkennedy> Yeah, but it's an internal type. Seems like the hack will be to replace an unF site with the F syntax 
16:22:14 <glguy> It's an internal type for which you never construct a value?
16:22:56 <`Guest00000> there are no functions fractional :: Double -> Double and floor_f :: Double -> Double in Haskell????
16:22:57 <robkennedy> Or like, I have example values in my code I don't export called like `_example`, but I can't have example types called _Example
16:23:02 <`Guest00000> nooo
16:24:03 <Axman6> glguy: what do you want those functions to do?
16:24:11 <Axman6> uh, `Guest00000
16:24:29 <robkennedy> :t fromIntegral . floor :: Double -> Double
16:24:32 <lambdabot> Double -> Double
16:24:51 <`Guest00000> Axman6: return the fractional part  and return floor
16:24:58 <`Guest00000> robkennedy: but that's probably inefficient
16:25:05 <glguy> :t properFraction
16:25:07 <lambdabot> (RealFrac a, Integral b) => a -> (b, a)
16:25:51 <Axman6> `Guest00000: "probably" sounds like you haven't tested
16:27:16 <Axman6> :t truncate
16:27:18 <lambdabot> (RealFrac a, Integral b) => a -> b
16:27:21 <Axman6> hmm
16:28:26 <robkennedy> > properFraction pi
16:28:29 <lambdabot>  (3,0.14159265358979312)
16:51:40 <`Guest00000> so
16:51:54 <`Guest00000> i just tested it
16:52:05 <`Guest00000> and, as https://mail.haskell.org/pipermail/haskell-cafe/2008-January/038022.html says, those are slow
16:52:56 <`Guest00000> int2Double . double2Int is faster
16:53:05 <`Guest00000> but it's non-portable
16:57:57 <glguy> `Guest00000: You get that for free after optimizations
16:58:01 <glguy> test :: Double -> Double; test x = fromIntegral (truncate x :: Int) -- compiles to
16:58:31 <glguy> \x -> case x of D# y -> D# (int2Double# (double2Int# y))
16:58:52 <`Guest00000> that brings me to the question of how explicit the optimizations should be
16:59:00 <`Guest00000> because implicit = unreliable
16:59:41 <robkennedy> Man, `snd . properFraction` ought to be optimal. You could submit a PR to make `properFraction = (,) <$> intToDouble . doubleToInt <*> (\x -> x - doubleToInt x)` 
17:00:10 <glguy> robkennedy: that's already what it is
17:00:15 <glguy> if you specify Int
17:00:33 <`Guest00000> ohh
17:00:42 <robkennedy> Sorry, that doesn't typecheck, but you get what I mean
17:00:51 <robkennedy> glguy: tight
17:03:01 <`Guest00000> glguy: hmm no
17:03:24 <`Guest00000> i just tested snd . (properFraction :: Double -> (Int, Double))
17:03:49 <`Guest00000> has same slowness
17:04:01 <`Guest00000> well
17:04:05 <`Guest00000> will try -O...
17:05:21 <glguy> You forgot the optimization flag when timing the previous one?
17:06:31 <`Guest00000> ok
17:06:47 <`Guest00000> with optimizations, int2Double . double2Int seems slightly faster...
17:07:00 <`Guest00000> than snd . properFraction with Int
17:07:28 <glguy> fromIntegral . (truncate :: Double -> Int)
17:07:42 <glguy> for some reason the snd . properFraction version does an extra test
17:09:39 <`Guest00000> ok
17:09:41 <`Guest00000> thanks for replies
17:11:05 <`Guest00000> it's awful that  by default fromIntegral . truncate will specialize to Integer and be slower
17:12:22 <hpc> something for HaskellPrime maybe?
17:13:06 <hpc> specializing to Int is a bit of a concession, but maybe being explicit about numbers that large is better than being explicit about optimizations
17:19:25 <`Guest00000> but still
17:19:39 <`Guest00000> frac :: Double -> Double isn't even in prelude
19:15:44 <Koterpillar> Is there a library to ulimit one's process (specifically memory)?
19:16:55 <kadoban> There's RTS flags for that as I recall, if it's a haskell program. And I believe they can be compiled in.
19:17:40 <c_wraith> you can also set the maximum number of allocations for a specific forkIO thread 
19:18:58 <Koterpillar> there's some kind of a leak in non-Haskell code I'm calling via FFI
19:25:20 <Claudius1aximus> Koterpillar: you could FFI out to setrlimit() perhaps, not sure if there's a binding already
19:59:12 <xlaech> wow :) Didn't expect so much people in here
19:59:33 <kadoban> :)
20:04:30 <haskull> could someone with the latest ghc version test if https://hastebin.com/zihagukafi.hs causes a panic?
20:10:16 <jake___> @help
20:10:17 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
20:21:02 <deepfire> is there a typeclass that would give a least upper bound on pairs of Linear.V2.V2?  I.e. (V2 0 1) (V2 1 0) -> (V2 1 1)
20:21:36 <deepfire> I have tried to peruse the V2 class haddocks, yet to no avail..
20:24:26 <deepfire> I'm seeing Data.Lub, but is that all?
20:25:21 <deepfire> Data.Lub has no instances for V2.. not that they aren't trivial to provide, but if there already is such a class with instances, then why not..
20:26:07 <Claudius1aximus> haskull: no panic in ghci-8.0.2, just a type error
20:31:24 <sssilver> I'm so fucking annoyed, there's this guy in my company that keeps arguing that OOP is the only true way and exercising functional programming is "ignoring 40 years of programming research" and going back to 60ies
20:31:48 <sssilver> the worst part is that he reviews everyone's pull requests and just keeps imposing this crap
20:32:00 <Rotaerk> immediate aversion is the reaction I get from a lot of people the moment I start suggesting concepts related to FP
20:32:04 <erisco> this person sounds fictional
20:32:36 <sssilver> erisco I can actually paste slabs of arguments on slack
20:32:46 <sssilver> *from slack
20:32:49 <Koterpillar> wrap everything in appropriate Action<> classes or equivalents :P
20:33:35 <erisco> I trust you. A perfect FP antagonist is just unlikely
20:33:36 <sssilver> "why is this function an orphan?" is a question I had to answer today
20:34:03 <orion> ha
20:34:11 <Rotaerk> erisco, but imperfect ones are common?
20:34:16 <erisco> yes
20:34:29 <erisco> like the ones with aversion you meet ;)
20:34:35 <Rotaerk> heh
20:34:51 <erisco> though usually it is a dismissive "sounds cool"
20:35:11 <sssilver> I get it that people have opinions but I just hate this air of relentless self-righteousness
20:35:18 <deepfire> investment, danger, etc.
20:35:38 <Rotaerk> it's often dismissive until I cross a threshold and then it's SHUT UP
20:35:43 <sssilver> it's almost like he finally grasped the concept of polymorphism, and can't get enough
20:35:45 <Rotaerk> (over a long period of time)
20:36:32 <erisco> sssilver, people with strong convictions like that tend to not know a lot -- it is a natural consequence
20:37:41 <sssilver> we have a large number of junior programmers who can't tell if wisdom and experience or bullshit
20:37:49 <sssilver> and I just get so freaking annoyed
20:38:05 <sssilver> I need to learn to be bold and brash and stuff
20:38:33 <Rotaerk> well, it's a sign of the beginner when a person relies on rules of thumb (such as "best practices") to govern their decisions
20:38:55 <Rotaerk> it's the sign of an *expert* beginner when a person dogmatically adheres to these rules of thumb as dogma
20:39:14 <sssilver> he's not a beginner, he has like 15 years of experience shipping fairly large systems
20:39:17 <Rotaerk> (reference to http://www.daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/)
20:39:18 <erisco> the expert beginner, heh :P that is a keen description
20:39:45 <sssilver> the expert beginner aka "the professional that lacked talent"?
20:39:52 <orion> That's a great article.
20:39:55 <sssilver> *the experienced professional that lacked talent
20:40:42 <erisco> I haven't read that article, but to me that term sounds to the phenomenon of people being most confident when they know just a little bit
20:41:13 <erisco> confidence tends to go from "I know nothing" to "I know everything" to "I know little"
20:41:56 <Rotaerk> the article does mention the dunning kruger effect
20:42:01 <nshepperd> heh, "orphan" functions. this program needs more implicit state!
20:42:34 <johnw> for a list [Word8], how much memory is allocated for each Word8 stored?  I'm not sure how large the header blocks are on a 64-bit system, for example
20:43:14 <erisco> how could you possibly be satisfied with that answer johnw? :P the overhead on a byte will at least be another byte
20:43:31 <johnw> which answer?
20:43:45 <erisco> to your question
20:43:53 <johnw> I don't understand what you're saying then
20:44:00 <Rotaerk> lol
20:44:11 <johnw> I want to know how much memory is allocated by [0] :: [Word8]
20:44:29 <erisco> the answer is A. I am saying A >= 2 bytes, and based on that I am saying the price on a byte is too high
20:44:49 <johnw> erisco: I think you're answering a question I'm not asking
20:45:10 <johnw> I don't care that the overhead exists, I'm asking how much it is, exactly, in bytes
20:45:26 <johnw> or, alternatively, how to find that out
20:45:36 <johnw> I've forgotten what the Haskell equivalent to sizeof is...
20:47:43 <johnw> ah, @hackage ghc-datasize
20:48:29 <erisco> I think you want to know  sizeof [0] - sizeof []
20:48:43 <johnw> yeah, likely that
20:51:09 <Rotaerk> deepfire, could you do something like... liftA2 max (V2 0 1) (V2 1 0)
20:51:13 <Rotaerk> can't test it myself, at the moment
20:51:53 <Rotaerk> or replace liftA2 with mzipWith, since it's implemented as liftA2 for V2
20:53:08 <Rotaerk> > V2 0 1
20:53:11 <lambdabot>  error:
20:53:11 <lambdabot>      • Data constructor not in scope: V2 :: Integer -> Integer -> t
20:53:11 <lambdabot>      • Perhaps you meant variable ‘_2’ (imported from Control.Lens)
20:54:21 <nshepperd> johnw: i seem to recall it being 24 bytes per item
20:57:13 <deepfire> Rotaerk, thank you, that worked like a charm!
20:57:39 <Rotaerk> \o/
20:58:10 <deepfire> that's a good implementation for a HasLub instance : -)
20:58:25 <johnw> nshepperd: so, there's cons header, cons pointer to Word8, cons pointer to next cell; Word8 header, pointer to Word8 contents; Word8 data.  Unless the constructor syntax "W8# Word#" implies some kind of unpacking...
20:59:34 <nshepperd> or maybe it's more...oh wait, maybe 24 bytes is just list spine
20:59:46 <johnw> yeah, definitely 24 in spine
21:01:22 <nshepperd> so... 24 + 16 = 40 bytes? I think Word# is indeed unpacked
21:02:03 <johnw> hmm.. GHC.DataSize.recursiveSize says that [0] :: [Word8] uses 376 bytes of memory?
21:02:34 <johnw> and recursizeSizeNF is 600?
21:03:16 <ertes> is there a way to set link flags from the Main module via a pragma or some other means to specify a C dependency without cabal or command line?
21:03:23 <Rotaerk> how do you learn about these low level properties of haskell/ghc?
21:04:34 <nshepperd> johnw: `recursiveSize $! force ([1]::[Word8]` gives me 48 in ghci
21:05:07 <johnw> isn't that what recursiveSizeNF does?
21:05:16 <johnw> ah, $! makes the difference
21:05:40 <nshepperd> recursiveSizeNF looks like a mistake :/
21:05:46 <johnw> it does, weird numbers
21:05:58 <nshepperd> it applys `force` but doesn't actually evaluate the value
21:06:02 <johnw> so, 40 bytes per element, plus 8 for nil
21:08:01 <kadoban> 376 sounds pretty high, wonder how that adds up. Every possible piece like ... 3? could be a thunk, and then the actual required sizes of stuff? Hmm.
21:08:19 <johnw> nshepperd had it right with 24 + 16
21:10:22 <nshepperd> kadoban: in ghci it's probably a pointer to some extremely unoptimized code for building the list
21:11:17 <kadoban> Ahh
21:13:36 <nshepperd> especially with numbers, you've got a whole thunk just to call fromInteger in there
21:13:54 <nshepperd> (and then another one to build the integer i guess)
21:57:45 <sssilver> do you guys agree that the whole "haskell is hard, it'll brake your teeth" crap is very damaging and misleading and stifles proliferation? it almost seems like a guided narrative
21:58:09 <sssilver> I consider myself a below average programmer and it's so much easier for me to write bug free code in a language that won't allow me to mess up
21:58:39 <sssilver> than in a language where I, having my subpar brain, will forget to check for null, or modify state somewhere wrong and forget about it, etc
21:58:54 <sssilver> Why don't we pursue the Python narrative of "Haskell is programming for the rest of us"
22:01:03 <orion> Break your teeth? That's usually what I hear about C.
22:01:48 <sssilver> orion I think the common narrative is that Haskell is the apogee of programming language "hardness"
22:02:03 <sssilver> only the enlightened ones have the mental capability to even consider it, let alone approach it
22:02:08 <dminuoso> sssilver: In C you modify state wrong, in Haskell you reduce to a wrong value. You still get to make *that* mistake :P
22:04:03 <orion> sssilver: Unfortunately, most imperative programmers I speak with are just talented *enough* to get things working for business people. That's all you need of course.
22:08:31 <orion> They don't care about functional languages because they haven't been incentivized to care.
22:09:06 <sssilver> like people rave about Javascript because it's approachable by noobs and then sit down and flex their muscles to deal not just with everything being potentially nullable, but freaking nullable in MULTIPLE ways!
22:09:24 <sssilver> I still can't grok the difference between null and undefined in Javascript
22:09:40 <sssilver> I mean I can, but it's quite ridiculous
22:09:55 <MP2E> I think a big part of it is that the tutorials I read come at it from the perspective of understanding the language step by step, and IO comes later, usually accompanied by learning about typeclasses like Monad, Functor, Applicative. For a new user, this can feel like a lot of abstract stuff to take in for something as simple as pulling in input, transforming it in a simple way, and printing it out.
22:10:01 <MP2E> Of course actually *doing* that isn't a big deal at all
22:10:29 <orion> I think words like "noobs" are divisive.
22:11:31 <MP2E> I think there would be value in a tutorial/book that comes at it from the approach of writing outright imperative haskell at first to get the user off the ground running, and then later delve into the deeper stuff. Maybe there's even already something like this out there
22:12:16 <MP2E> I didn't have much issues learning Haskell as is, I just think it would be helpful to bring in people from other languages
22:13:10 <sssilver> MP2E that's roughly how Swift/Rust approach it, i.e. you start programming, and then they go "imagine if you could count on the fact that X will never be null"
22:13:21 <sssilver> "oh look, we actually have optionals for that!"
22:14:40 <sssilver> explaining optionals to an average person who had to do a null check in every function in their Objective C code is so much easier than explaining the Maybe monad in general terms
22:15:06 <sssilver> I think one issue is that Haskell books/people tend to approach explanations from a wider/more general angle
22:15:35 <sssilver> and there's value in approaching these things from a more narrow/practical angle
22:16:16 <haskull> How would you define a monad concisely, with words any programmer would know?
22:16:45 <sssilver> haskull I would probably not define a monad
22:17:02 <haskull> best I can do is something like "pass data between functions with nice syntax"
22:17:16 <sssilver> haskull interesting, that's not at all what I think when I think of monads :))
22:17:19 <orion> The syntax has nothing to do with the definition of a Monad.
22:17:30 <sssilver> I'd probably explain optionals in practical terms
22:17:46 <sssilver> e.g. letting the compiler infer what can be null and what cannot be
22:17:51 <sssilver> and then explain the concept of unwrapping an optional
22:17:59 <orion> haskull: The most concise, accurate, definition of a monad is the mathematical one. If you're a programmer and you don't understand (or don't *want* to understand) mathematical terms, I have to question your career choice.
22:18:10 <sssilver> e.g. peek in it to see whether there's value in it
22:18:25 <sssilver> and then perhaps suggest that the "unwrapping" could in fact be *any* action
22:18:46 <`Guest00000> haskull: monad is a container which has return and bind.
22:18:51 <`Guest00000> and what return and bind are
22:18:54 <`Guest00000> that's all
22:19:08 <Rotaerk> haskull, I think that when someone asks what a monad is, you should just say it's an abstract concept that requires sufficient exposure to examples in order to "get"
22:19:10 <`Guest00000> class of containers, okay
22:19:33 <Rotaerk> i.e. there's no quick way to make them go "oh, I get it"
22:19:50 <orion> Best definition of a Monad: http://hackage.haskell.org/package/base-4.9.1.0/docs/Control-Monad.html#t:Monad
22:19:54 <Rotaerk> well, at least not without misleading them
22:19:54 <sssilver> `Guest00000 I don't think of it as a container. I think of it as of a type that performs some action when acted upon.
22:20:06 <sssilver> `Guest00000 it doesn't have to contain anything at all
22:20:18 <Rotaerk> and the definition itself isn't sufficient for "getting" it
22:20:39 <Rotaerk> unless maybe you're just used to mathematical thinking or something
22:20:42 <orion> haskull: Moreover, you could start by introducing functors first, then applicatives, then maybe monoids, then monads.
22:20:54 <sssilver> I am completely barefoot when it comes to mathematics, but I successfully ship production Haskell code, and it helps me write bug-free programs that I can actually reason about
22:21:10 <`Guest00000> well
22:21:14 <sssilver> my Haskell programs are so much less squishy than my Python programs
22:21:21 <monochrom> There is one aspect any programmer would not know. Monadness is for things like "Maybe" and "Reader e", not "Maybe a" and "Reader e a". Most programmers do not already have words or concepts of this.
22:21:24 <`Guest00000> sssilver: i might mean functor instead of "container"
22:21:30 <orion> sssilver: I suspect that you may find beauty in the mathematics underpinning Haskell.
22:21:47 <sssilver> `Guest00000 a function in my book is a Java class with a single method called call() :))
22:21:50 <sssilver> *a functor
22:22:32 <monochrom> As a corollary, "container" is wrong. Most programmers' "container" refer to things like "List<T>" and "Vector<T>". Emphatically with the <T> there.
22:22:45 <sssilver> monochrom +1
22:22:53 <Rotaerk> yea, to monochrom's point, if you want to say "monad is a ___ with a return and a bind function", the ___ should be something to the effect of "a type of kind * -> *"
22:23:17 <Rotaerk> and people won't get even THAT without examples
22:24:41 <sssilver> Rotaerk I think that doesn't explain what a monad is, because "something that has a return and a bind function" is just stating properties, and that's not very helpful
22:25:04 <Rotaerk> yes, you need to explain by *showing*, with examples, and let them intuit the concept
22:25:36 <orion> sssilver: Many programmers I've met have a huge sense of entitlement when it comes to understanding. They think that if they don't understand a concept immediately without any serious study, it's my fault.
22:25:53 <Rotaerk> mainstream languages tend not to even support higher kinded types... I've even suggested that it'd be nice if C# supported them, and other C# programmers go "eh? why on earth would you want that?"
22:26:17 <sssilver> would you explain a chair by "something that has 4 legs and a flat surface attached to them"?
22:26:34 <monochrom> The reason why so many programming languages look like each other and copy each others' mistakes and stagnation is precisely because of this "everything must not exceed what programmers already know" mentality.
22:26:42 <Rotaerk> orion, that or it's just not something WORTH understanding, because they've done fine without it
22:26:43 <sssilver> that'd be pretty precise but also pretty useless to anyone who's trying to figure out what problem is chair trying to solve
22:27:14 <orion> Rotaerk: Indeed -- they are just good enough to get a job. They don't find value in going above and beyond the bare minimum.
22:27:51 <sssilver> orion I think a lot of people are actually too humble to question the quality of their tools, so they question their own skill
22:28:07 <sssilver> e.g. "my program in C++ is very buggy" ~> "I am not good a enough programmer"
22:28:27 <sssilver> and from there it goes to "if you're good enough, language is just a tool"
22:28:40 <orion> sssilver: How old are you? How old are the programmers you interact with regularly?
22:28:45 <Rotaerk> lol
22:28:50 <Rotaerk> "humble"
22:29:04 <sssilver> orion I'm 32, age of people I interact with varies from 25 to 50
22:29:27 <sssilver> I know what I say sounds wrong, but I think there's something to it
22:29:35 <orion> I'm 25. The programmers I interact with are 18-35.
22:30:00 <Rotaerk> I've met primarily arrogant programmers, and apathetic programmers
22:30:06 <Rotaerk> can't say I've met many humble ones
22:30:08 <orion> Rotaerk: Yes!
22:30:18 <monochrom> No, I don't think they question their own skill. I think they question each other's skill.
22:30:46 <sssilver> you can be arrogant because deep down you're compensating for the feeling of defeat
22:30:47 <monochrom> If you can't get "make" to work, you aren't the one questioning your IQ, someone else is.
22:31:27 <sssilver> monochrom that's a fair point
22:31:30 <pacak> But Haskell is hard.
22:31:39 <sssilver> pacak why?
22:31:43 <sssilver> C++ is fucking hard
22:31:53 <sssilver> anyone here that shipped any production C++ project and disagrees with me, please raise your hand
22:32:21 <sssilver> one, Haskell is small. It's a tiny language.
22:32:43 <Rotaerk> using C++ is hard, learning C++ is time consuming, but it's not that hard to understand conceptually
22:32:45 <sssilver> two, it doesn't have as many concepts to "understand" as your average multi-paradigm OOP language with bells and whistles
22:33:03 <sssilver> "so there are fundamental types and user types"
22:33:07 <sssilver> "and templates"
22:33:14 <sssilver> "and pointers, and pointer arithmetic"
22:33:32 <sssilver> "and exceptions and all that good stuff like throwing an exception in a destructor"
22:33:36 <Rotaerk> using haskell is kind of easy, learning haskell itself isn't that time consuming, but learning the concepts that let you excel in it is hard
22:33:40 <sssilver> "copy constructors, move semantics"
22:33:50 <pacak> sssilver: It allows much fancier abstraction compared to (probably not C++, but let's take ruby or javascript) and supports you in all those abstractions.
22:33:53 <haskull> My first real language (I'm not counting visual basic) was C++. Every couple years it just gets harder. Meanwhile, every other popular language is easy to pick up because of that. Haskell has been the biggest challenge for me since then.
22:34:14 <SexHendrix> hi guys, i have a feeling im missing a pattern that would make this problem less convoluted
22:34:24 <SexHendrix> i have a [[Int]]
22:34:37 <SexHendrix> which is a list of x,y coords effectively
22:34:38 <sssilver> the reason Haskell was a bit hard for me is because I approached it with the mindset of "this is gonna be the hardest thing ever", and I kept looking for a black cat in a dark room that wasn't there
22:35:02 <SexHendrix> i want to run down the list, doing an operation between each pair of points
22:35:06 <Rotaerk> SexHendrix, why not [(Int, Int)], then?  [[Int]] suggests each element can vary in length
22:35:38 <SexHendrix> Rotaerk: well yeah but in this problem i don't think it makes a difference
22:35:42 <Rotaerk> k
22:36:14 <SexHendrix> im pretty sure what i want is some type of fold
22:36:30 <SexHendrix> fn :: [[Int]] -> Int
22:36:37 <sssilver> SexHendrix "an operation between each pair of points"?
22:36:44 <sssilver> what does between mean here?
22:36:46 <Rotaerk> for example?
22:37:09 <SexHendrix> ok, well im using coordinate geometry to calculate the area of a polygon given the vertices
22:37:13 <sssilver> e.g. [(a, b)] an operation would be performed between a and b?
22:37:33 <sssilver> or [(a, b), (x, y)] it would be performed between (a, b) and (x, y), etc?
22:37:54 <SexHendrix> where A = (x1y2 - y1x2) + (x2y3 - y2x3) + ...
22:37:58 <pacak> sssilver: A while ago we had a competition with one guy to write a factorial computation. He used java, I used haskell hylomorphism. Haskell version worked way faster so he asked the source code to look at. It was something like 10 short lines - no imported functions, one functor, two algebras and that's about it. It took him 2 weeks to "understand" how this works and to implement the same in java. in 500+ lines.
22:38:29 <`Guest03> SexHendrix:  "an operation between each pair of points" does it mean pairs of adjacent points in the list or all possible pairs of points from list?
22:38:37 <SexHendrix> adjacent points
22:38:41 <geppettodivacin> SexHendrix: That can be done with a fold.
22:38:44 <SexHendrix> from start to end
22:38:58 <pacak> That was probably the second program I wrote with recursion schemes but ghc and type declarations helped a lot.
22:39:02 <SexHendrix> nice one
22:39:22 <geppettodivacin> The accumulator would store the previous value and the current calculated area.
22:39:37 <Rotaerk> and I think you *should* convert to [(Int, Int)]... simplifies the code
22:39:49 <SexHendrix> i agree
22:39:56 <SexHendrix> thanks
22:43:19 <`Guest03> SexHendrix: you need to fold the expression (zip l (tail l)), where l is initial list
22:43:57 <`Guest03> (zip l (tail l)) generates list of pairs of adjacent elements in l
22:44:35 <geppettodivacin> Ooh, I like that better than my solution.
22:45:03 <SexHendrix> i did it with the very ugly `zip (fmap head l) (fmap last l)`
22:47:22 <`Guest03> SexHendrix: your expression converts [[Int]] to [(Int, Int)]. where do you get [Int]'s as points from?
22:48:06 <`Guest03> if you need to convert them, i would do it with just "map (\[x, y] -> (x, y)) l"
22:48:27 <Cale> pacak: Of course, it would have been *really* embarrassing for Haskell to somehow lose at a competition for computing factorials ;)
22:48:47 <SexHendrix> example input comes in the string "0 0\n0 1\n1 1\n1 0"
22:49:00 <SexHendrix> into stdin
22:49:30 <SexHendrix> im thinking it through, ill be back if i get stuck
22:51:34 <SexHendrix> `words <$> lines input` gets it to [[String]] then i just rained read all over it to get the [[Int]] from before
22:52:08 <`Guest03> SexHendrix: yeah, i'd do like you did and then just convert as i said
22:52:28 <pacak> Cale: I don't recall what value was it but the idea was to compute them as a tree: ((1 * 2) * (3 * 4) ) * ... rather than 1 * (2 * (3 * 4 * (... to minimize number of expensive multiplications of multi-megabyte Integers
22:53:03 <`Guest03> plus you get program crash on invalid input data for free...
22:53:32 <`Guest03> if a line has less or more than 2 numbers
22:53:34 <monochrom> It is very easy to lose at a competition for computing factorials. Even with an optimizing compiler. See http://www.luschny.de/math/factorial/FastFactorialFunctions.htm
22:53:51 <SexHendrix> `Guest03: im assured it wont ;)
22:55:41 <pacak> "is  even fast up to 10000!." - I think we were using something like 1000000000000000000....
22:58:10 <monochrom> If you use GHC, you want to multiply two numbers of similar magnitude. You want to multiply two large numbers ASAP, not postpone it by multiplying a large number by a small number.
22:59:07 <monochrom> This is because GHC is going to call GMP for multiplication, and reaching the multiplication of two large numbers earlier means GMP uses the advanced multipliers earlier.
22:59:52 <monochrom> (Ideally you would rather call GMP's factorial function directly, which uses an even more advanced algorithm. But GHC doesn't expose this.)
23:02:03 <pacak> Let's assume every number in factorial is the same. If you split a huge list in half and take product of every half you'll get two numbers with N digits each - that would be one expensive multiplication and product will give 2N. Split every of those lists in half - there will be only N/2 digits and so on.
23:02:16 <SexHendrix> whenever i have to write a load of horrible functions to get from input to the datatype i want, i make a function called `magic` that is just all of them composed
23:02:30 <pacak> If you multiply them as a tree you'll get one multiplication of size N, 2 of size N/2, 4 of size N/4 and so on
23:02:50 <SexHendrix> then just `magic input`
23:02:51 <pacak> It's much cheaper than multiplying big number by small number N times
23:04:04 <SexHendrix> https://ptpb.pw/DKsV :]
23:07:29 <SexHendrix> input -> useful datastructure is my least favourite part of writing haskell
23:07:34 <`Guest03> ugh
23:07:40 <`Guest03> those lines on edges of triangles
23:21:31 <cocreature> SexHendrix: parsing inputs is always annoying :)
23:32:27 <malinoff> hi everyone, I can't google a way to inject non-code metadata (like build timestamp or Jenkins' BUILD_NUMBER) into a binary built by stack; maybe someone knows some way?
23:33:18 <cocreature> malinoff: you might want to look into how gitrev embeds the git version number https://hackage.haskell.org/package/gitrev
23:33:38 <malinoff> cocreature: thanks, I'll take a look
23:33:40 <Cale> malinoff: Template Haskell splices would do.
23:33:56 <cocreature> yeah that’s what gitrev uses
23:33:58 <Cale> You can perform IO from inside a splice.
23:35:11 <malinoff> Cale: awesome, thanks
23:36:52 <pacak> malinoff: CPP/TH
23:50:54 <quchen> Meta question. When I say »data Nat where Zero :: Nat; Succ :: Nat -> Nat«, how would I argue that Succ is already defined here, and not merely a statement of Succ’s type that has a value yet to be given (such as \_ -> 1)?
23:51:11 <quchen> In other words, where does the »uniqueness« of Succ come from?
23:51:46 <quchen> In a Haskell context this is clear (because well, Haskell works this way). But in type theory there is the same notation without the Haskell Report to fall back to.
23:52:20 <`Guest03> i don't quite understand this
23:53:03 <`Guest03> neither first part nor restatement
23:53:13 <quchen> If you give a mathematician »succ : ℕ -> ℕ«, then succ could be any function from ℕ to ℕ.
23:53:53 <quchen> But when we have a functional language (Haskell, Agda), the »succ« in a data definition gives us a unique way to go from one Nat to another.
23:54:29 <quchen> It’s not any general function from ℕ to ℕ, it’s »the successor function«. I’m wondering where that comes from.
23:54:35 <`Guest03> the succ gives an unique way because it is unique
23:54:42 <`Guest03> if you had Succ1, Succ2
23:54:51 <`Guest03> would no longer be unique
23:54:54 <quchen> Why is it unique? I can think of many other functions of type ℕ → ℕ.
23:56:09 <`Guest03> is your question "why does Succ denote the successor function instead of anything else?"?
23:56:21 <quchen> Yes, sounds right
23:57:15 <quchen> Is it maybe given not by the data definition alone, but also by the accompanying destructor (i.e. that you can pattern match on it), and the two are mutually inverse?
23:57:34 <`Guest03> i think we should distinguish the constructor and the function
23:57:53 <barrucadu> I think the fact that you can pattern match on the Succ is key
23:57:54 <`Guest03> defining the constructor (the element in the list of constructors) gives rise to a function
23:59:16 <dmwit_> quchen: you know about lfp def. of inductive types?
23:59:22 <quchen> LFP?
23:59:23 <ClaudiusMaximus> makes me think of https://en.wikipedia.org/wiki/Free_group#Examples and https://en.wikipedia.org/wiki/Word_%28group_theory%29
23:59:34 <dmwit> least fixed point
23:59:45 <quchen> dmwit: No, I don’t
23:59:50 <dmwit> okay
23:59:59 <dmwit> take any set
