00:26:11 <ahri> apologies in advance; i don't quite know how to express this: i'm familiar with the idea of composing two fmaps together to process a 2d list, and i wonder whether i can do something similar with foldr so that i can carry some state along while keeping the simplicity of having a function that operates only on the type contained within my 2d list. does this make sense? e.g. with my composed fmaps i can just 
00:26:11 <ahri> have a function 'a -> b' without caring about the structure. i'd like something like '(s, a) -> (s, b)' to carry state along, but still not care about the structure
00:35:17 <ski> ahri : something like `runState ((mapM . mapM) (state . process) my2dList) initialState', with `process :: a -> s -> (b,s)' ?
00:37:01 <ski> or `(mapAccumL . mapAccumL) process initialStte my2dList)', this time with `process :: s -> a -> (s,b)'
00:38:34 <ski> that's assuming you want to initialize the state once, then visit each element in turn, "sweeping" across the rows
00:39:54 <ski> if you want to do some extra processing inbetween the rows as well (possibly also involving the row index), affecting the state, then that's slightly more complicated, but should be possible as well
00:44:05 <halogenandtoast> When I do something like :t (>>) is there a way to get it to automatically replace `m` with IO for instance
00:44:08 <halogenandtoast> :t (>>)
00:44:10 <lambdabot> Monad m => m a -> m b -> m b
00:44:20 <halogenandtoast> and for this I mean in ghci, not lambdabt
00:45:36 <ahri> ski: sorry, i'm just looking all this up before i'm able to reply :)
00:49:35 <ahri> ski: mapAccumL looks like what i'm after. i'm a bit confused about the State monad at the moment so i'll try mapAccumL first!
00:49:41 <Maxdamantus> halogenandtoast: it would sort of be a lie if it replaced `m` with `IO`. It wouldn't be clear when you want it to lie to you by narrowing down the range of types.
00:50:27 <Cale> ahri: Another thing you can do is to use foldr like this:
00:50:55 <Cale> > foldr (\x xs s -> (x,s) : xs (s+1)) (const []) "hello" 0
00:50:59 <lambdabot>  [('h',0),('e',1),('l',2),('l',3),('o',4)]
00:51:15 <Maxdamantus> Theoretically, it could make sense to somehow denote a type-level application of that `m` parameter as `IO`.
00:52:17 <Maxdamantus> You can do that in Idris for example, but you would be explicitly passing it `IO` .. Haskell only lets you pass it implicitly.
00:52:32 <nshepperd> you can do :set -XTypeApplications
00:52:41 <nshepperd> then :t (>>) @ IO
00:53:02 <Maxdamantus> Mk, so that's GHC's version of that.
00:56:00 <ahri> Cale: i wondered about that, but i don't understand how i would compose that up to operate on a 2d list. there's something very lovely about (fmap . fmap) !
00:56:17 <nshepperd> 'f @ T' gives you f with the first type parameter in its type sig unified with (replaced by) T
00:58:02 <ski> ahri : there's also `mapAccumR' for "processing a list from the right" .. but presumably you want it the `mapAccumL' way
01:02:04 <Wizek> Hello. Am I reading the source for `bracket` correctly ( https://hackage.haskell.org/package/base-4.9.1.0/docs/src/Control.Exception.Base.html#bracket ) that the release function (called `after` in the source) is called twice if there was an exception?
01:03:30 <Cale> No, the exception is rethrown by onException, and will propagate outward, so the second after will never occur in that case.
01:04:09 <Wizek> Cale, I see
02:21:34 <Jinxit> regarding https://goo.gl/IT3NDD (not my question, but i have the same issue), is there really no neater solution that the ones presented?
02:30:28 <jgt> hey folks :) 
02:31:35 <jgt> in Shakespeare/Yesod, how do I render a widget? I have a `WidgetT site2 m2 ()`, and I need an `Html`
02:32:17 <jgt> I read in the documentation that a `WidgetT` is actually a `WriterT`, defined in a newtype
02:32:54 <jgt> do I have to do something like `runWriterT`?
02:33:29 <Rembane> Do you have a runWidgetT?
02:33:52 <jgt> Rembane: doesn't look that way
02:34:11 <jgt> but, I don't know, hence the question :) 
02:34:39 <jgt> (still a noob)
02:34:53 <Rembane> Me neither, I'm just doing informed guessing, speaking of which do you have a link to the documentation where the WidgetT is declared?
02:35:06 <jgt> https://hackage.haskell.org/package/yesod-core-1.4.32/docs/Yesod-Core-Widget.html
02:35:50 <jgt> oh‚Ä¶ perhaps I want `unWidgetT`? I'm looking at the source
02:37:08 <Rembane> That is promising.
02:39:07 <jgt> ok, I'm not even sure if I can use that
02:39:33 <Rembane> jgt: Some Template Haskell magic seems to be in play here, look at the first example: http://www.yesodweb.com/book/widgets
02:42:17 <jgt> ok, so if I use `defaultLayout`, then I at least have a `HandlerT site0 IO Html`
02:42:26 <Rembane> Cool
02:42:30 <Rembane> jgt: You could on the other hand go WidgetT -> PageContent -> Hamlet -> ByteString
02:42:36 <Rembane> jgt: Where the arrows are not function application arrows
02:43:07 <Rembane> jgt: You have a widgetToPageContent in Yesod.Widget. 
02:44:03 <jgt> I'd be happy ending up with a ByteString
02:44:10 <jgt> trying to think now how to formulate this
02:46:22 <Rembane> jgt: Cool, are you trying to render stuff to a page like in the examples in the Yesod book?
02:47:40 <jgt> Rembane: not exactly; the examples in the book are fine for rendering pages in a normal Handler flow, i.e., visitors making requests and receiving responses
02:48:14 <jgt> what I'm trying to do now is take a widget, with some html and css, and serialise that to a ByteString so I can pass it into my mailer
02:48:19 <SepakoRayl> hello everyone, any idea why stack exec sets -icanon ?
02:48:19 <jgt> for sending some html email
02:48:50 <geekosaur> SepakoRayl, it's trying to disable buffering, but the ghc runtime conflates that with character at a time mode
02:49:14 <geekosaur> there's an open bug about it
02:49:45 <SepakoRayl> it was very confusing because this happened even if i explicitely set LineBuffering
02:50:19 <SepakoRayl> It seems to work correctly with BlockBuffering though
02:50:20 <geekosaur> stack itself is setting NoBuffering, and what the program you run does is not relevant to it
02:50:49 <SepakoRayl> yes but it seems LineBuffering does not restore the icanon flag
02:51:09 <geekosaur> block buffering likely undoes what the runtime is doing though. Personally I think ghc should not have tried to conflate these; it will not only get it wrong in the way you are seeing, it just confuses things worse.
02:51:24 <Rembane> jgt: That's a reasonable use case.
02:51:50 <jgt> Rembane: glad I'm on the right track then :)
02:52:33 <SepakoRayl> do you guys know where I can read more aobut this ?
02:54:48 <geekosaur> https://github.com/commercialhaskell/stack/issues/2884
02:55:07 <Rembane> jgt: ^^
02:55:19 <SepakoRayl> ah it was this issue
02:56:05 <SepakoRayl> I guess I was just surprised that setting LineBuffering explicitely did not set icanon again
02:56:36 <geekosaur> I expect they forgot that case when adding the termios twiddling. Just another reason they shouldn't have done so in the first place.
02:57:21 <geekosaur> Also, since termios state is part of the terminal and not part of the program context, it's problematic when multiple programs are involved (here, stack and your program)
03:02:04 <SepakoRayl> this was how i found it, the program compiled with ghc worked as expected but stack exec messed everything up and afterwards even the original program did not run as exptected
03:03:33 <geekosaur> yes, probably left the terminal in the wrong mode, that is what I meant by "problematic when multiple programs are involved"
03:03:41 <geekosaur> in the shell:     stty sane
03:04:16 <geekosaur> (shells will not be affected unless you use one that doesn't use readline/editline for some reason)
03:16:00 <jgt> Rembane: looks like someone had a similar thought as me a couple of years ago: https://github.com/yesodweb/yesod/issues/699
03:17:43 <jgt> it's interesting that in his `htmlVersion`, he's just using a hamlet file, and not a widget
03:18:55 <Rembane> jgt: Yes indeed. 
03:27:01 <jgt> Rembane: I'm giving up the widget idea for now. I'll just stick everything in the same hamlet file, and worry about this widget stuff later
03:27:07 <ph88^> i don't understand why i have in the type signature on line 41 1 arrow, but in implementation on line 58 i need 3 arguments, can anyone explain?  https://bpaste.net/show/4ec41c1fcae7
03:27:26 <jgt> can't get sidetracked; gotta üö¢ some Haskell
03:28:35 <Chousuke> amusskekt1
03:28:38 <jgt> ph88^: I'm not sure, but I'm thinking something along the lines of partial application
03:28:44 <Chousuke> bah :(
03:29:15 <Chousuke> oh well, it was way past the time to change that particular password anyway
03:29:55 <ph88^> jgt, maybe i should maybe the second argument of kind * -> *  ?
03:30:32 <jgt> ph88^: actually forget what I said; I really have no idea
03:31:22 <ph88^> oh i thought you were onto something
03:33:42 <Rembane> jgt: That's a good plan. 
03:39:14 <jgt> ph88^: possibly, but I don't have a solid enough grasp of typeclasses. What stuck out to me was that you said there are ‚Äúthree arguments‚Äù, whereas I'm sure everything in Haskell only takes one argument. There's also this common case where arguments are passed to stuff, but you don't necessarily see them in any signature
03:42:53 <jgt> but also I could be confused about some of those points
03:43:32 <jgt> at this point, my Haskell advice should be taken with enough salt to disable a kidney
03:47:37 <ph88^> i usually use drinks for that
03:57:50 <ski> ph88^ : i'm pretty sure  LensLike' f eot a  is a type synonym of a function type
04:01:14 <ski> ph88^ : however, i'm suspecting that the (unused !) formal parameter `eot' in the `instance' declarations of "Code piece 3" should be removed (together with `eot ->' in the type signature in the `class' declaraion) ..
04:01:26 <ski> ph88^ : .. either that, or something should be passed in this position, in the calls to `eotTerminal' in the definientia
04:10:18 <ph88^> ski, thanks for your help, i will go over what you said as soon as i get to it, i have to leave immediately :/
04:16:04 <AWizzArd> Can I ‚Äûautomatically trace‚Äù function calls in ghci, without using the trace function? Similar to Lisp, where I can see the input and output arguments to each function call?
04:16:30 <AWizzArd> Automatic in the sense that I don‚Äôt need to touch the code, and don‚Äôt need to use breakpoints.
04:26:13 <mojjo> hi! I just created an instance of Num for a custom type. I can use it like this now: (Length 1) + (Length 1) --> Length 2 . However the same did not work for creating an instance of Fractional in order to use sqrt on the type as well. Can anybody help me out here?
04:50:35 * ski notes mojjo hasn't provided enough info for readers to be able to give any useful help
04:52:09 <irc2000> can we talk about humanity for a second?
04:52:46 <irc2000> i hate humanity
04:53:00 <ski> is this Haskell-related ?
04:53:05 <irc2000> we work hard to advance humanity.. meanwhile some gypsie is trafficking humans.
04:53:31 <irc2000> ski: well, I want to work on improving haskell
04:53:41 <irc2000> ski: but humanity is putting me off my mood
04:53:52 <ski> perhaps vent somewhere else about it ?
04:54:08 <irc2000> ski: about haskell? what other channel is more related to that
04:54:19 <irc2000> ski: now you're just being retarded man..
04:54:37 <cocreature> irc2000: please stop insulting people
04:54:51 <irc2000> cocreature: please stop fucking children.
04:54:56 <cocreature> @where ops
04:54:56 <lambdabot> byorgey Cale conal copumpkin dcoutts dibblego dolio edwardk geekosaur glguy jmcarthur johnw monochrom quicksilver Saizan shachaf shapr ski
04:54:56 --- mode: ChanServ set +q *!*@gateway/tor-sasl/irc2000
04:55:18 --- mode: ChanServ set +o dibblego
04:55:21 --- mode: dibblego set +b *!*irc2000@*gateway/tor-sasl/irc2000
04:55:22 --- kick: irc2000 was kicked by dibblego (irc2000)
04:55:28 <cocreature> thanks
04:56:19 --- mode: ChanServ set -q *!*@gateway/tor-sasl/irc2000
05:13:29 <centril> stupid racists... :/
05:13:31 <centril> anyways
05:16:00 <centril> For a set of (data) types A, and a set of types B, I have, \forall a \in A. \exists b \in B. a -> Maybe b
05:16:21 <centril> i.e: every type in A has a (partial) correspondence in some type in B.
05:17:05 <ski> `b' not depending on the input value in `a' ?
05:17:36 <centril> Also: for every type a in A, there exists a function :: a -> String   ("printTree")
05:17:52 <centril> ski: it depends on the value in a
05:18:16 --- mode: dibblego set -o dibblego
05:18:53 <ski> so i suppose you mean to say `\forall a \in A. a -> \exists b \in B. Maybe b' ?
05:19:07 <ski> or maybe `\forall a \in A. a -> Maybe (\exists b \in B. b)' ?
05:19:44 <centril> ski: ok ill stop with the formal version and just write english :P
05:21:02 <ski> in the last, there needn't exist a `b' for any value in `a'. in the penultimate, `b' would have to exist regardless of whether you get `Nothing' or `Just (...)'
05:21:27 * ski isn't quite seeing where this is going, though ..
05:21:29 <ski> .. go on
05:21:42 <centril> ski: So I have an AST with some types {a1, a2, a3} in A - and an AST with other types {b1, b2, b3} in B - and then, I have a partial function going from  a1 -> Maybe b1  , a2 -> Maybe b2,  a3 -> Maybe b3, ...
05:22:15 <centril> (one of these are the root node type of course...)
05:22:21 <centril> (in both A & B)
05:22:50 <ski> are `a1',`a2',`a3' types .. or data constructors ?
05:23:05 <centril> ski: data types
05:26:45 <centril> Now - for every (almost) type `a` in `A`, for its corresponding type `b` in `B` there is a constructor that is not representable in `a` - so `b -> a` must also be partial...  however, there is a function `a -> String` for every `a in A` which I'd also like to use for `b`, but I'd also like to "printTree" the constructor not in `a` ... but if I do `b -> Maybe a` , I can't do that because I've lost that
05:26:47 <centril> info...
05:27:34 <centril> so... can I reuse the code for  "printTree" for A  while injecting  some code for the special constructor in B ?
05:27:42 <centril> by any means... like template haskell ?
05:28:05 <centril> ski: I think im done elaborating now :P
05:29:16 * ski doesn't get the picture
05:29:33 <centril> ski: sec, I'll write some code so that you get it ;)
05:42:27 <lpaste_> Centril pasted ‚Äúmake-ski-get-the-picture‚Äù at http://lpaste.net/353671
05:42:35 <centril> ski: ^
05:47:26 <centril> ski: perhaps if I case match on the  b:s and then for BExpNotInA divert to a special logic, and otherwise convert and use printA ?
05:47:28 <ski> i suppose i would try factoring out the common parts
05:48:04 <centril> ski: I have no control over A or the printA ;)
05:48:09 <ski> centril : hm, i think you need open recursion for that
05:49:45 <centril> ski: hmm... what if I do this for every b in B ?
05:50:11 <ski> if you have e.g. `BPlus (BLit (BBool False)) BExpNotInA', if you just call `convB', it'll fail, so that you don't reuse the code in `printA' for `APlus',`ALit',`ABool'
05:50:33 <centril> right right
05:51:19 <centril> ski: what if I pass it a series of failure handlers for every level ?
05:51:30 <ski> to apply open recursion, you'd need to have some control over `printA', in order to make it call back into your code for recursive calls, iiuc
05:52:18 <centril> ski: can't I just have control over convB and add failure handlers for the case of Left ?
05:54:09 <ski> how will you reuse the code in `printA (APlus e0 e1) = "(" ++ printA e0 ++ " + " ++ printA e1 ++ ")"' (or whatever), for `BPlus' ?
05:54:31 <centril> oh right
05:54:35 <centril> crap
05:54:45 <ski> you need to get back control on the recursive calls (aka open recursion)
05:54:57 <centril> ski: can I still hack my way through this via meta programming ?
05:55:11 <ski> maybe, but i don't think it will be pretty
05:55:27 <centril> (where writing the template haskell doesnt take as long as rewriting printA to printB)
05:55:52 <centril> damn :/ this is most unfortunate
06:21:09 <Jinxit> trying this again: http://stackoverflow.com/questions/36978780/haskell-resolving-cyclical-module-dependency are there any other alternatives to the ones listed?
06:33:34 <Jinxit> cyclic module dependencies are absolutely killing my code to the point where i'm considering some sort of C-style #include
06:38:41 <joneshf-laptop> Jinxit, adding a type parameter isn't necessarily a bad thing.
06:39:13 <merijn> Jinxit: GHC supports recursive imports via hs-boot files
06:39:32 <merijn> Although I agree that it's unfortunate that it doesn't automatically do that, as required by the report
06:39:32 <joneshf-laptop> It's not a free solution, I'll give you that, but it's a fairly nice way to solve your problem.
06:39:50 <joneshf-laptop> And gives you some stuff.
06:40:36 <Jinxit> what are the benefits of adding (probably several in my case) type parameters to every type?
06:40:37 <joneshf-laptop> Also, depending on how you use the function, you could do something with an existential, so the type variable isn't known about.
06:40:57 <joneshf-laptop> But I think existentials are harder to work with.
06:41:22 <Jinxit> merijn: already broken one cycle with a hs-boot, i'd rather not go through that again
06:42:08 <Jinxit> i don't mean to sound entitled but if the code works as a single file but not spread out over multiple files it feels like a bizarre problem to have
06:42:21 <joneshf-laptop> Jinxit, S11001001 does a much better job  explaining it here than I could: https://youtu.be/BHjIl81HgfE
06:42:42 <Jinxit> can't look right now, but i'll watch it later, thanks
06:42:57 <joneshf-laptop> Right, it is 40 minutes :)
06:43:05 <Jinxit> yeah
06:45:35 <Jinxit> as a last resort: is there any obvious downside to a C-style include to merge everything into one module?
06:48:16 <merijn> Jinxit: Your compile times will go to shit and you can't do partial recompilation (so you'll always rebuild everything)
06:48:28 <merijn> Jinxit: Also, GHCs memory usage will probably increase too
06:48:35 <Jinxit> hm ok
06:48:58 <merijn> So, functional downsides? Not really. Pragmatic ones? Yes.
06:56:31 <joneshf-laptop> Why is JWT so hard? I just want to decode a thing.
06:57:00 <joneshf-laptop> well, and verify the signature.
06:58:59 <merijn> joneshf-laptop: What's JWT?
06:59:30 <joneshf-laptop> JSON Web Token
06:59:32 <joneshf-laptop> https://en.wikipedia.org/wiki/JSON_Web_Token
06:59:51 <merijn> ah, JSON, I'm already considering myself blissfully ignorant ;)
07:00:10 <joneshf-laptop> I'd never heard of it until about a month ago.
07:00:17 <joneshf-laptop> But apparently lots of programs use it.
07:01:19 <joneshf-laptop> openid, google, amazon, etc
07:02:13 <joneshf-laptop> But each library seems to have something missing :(.
07:02:26 <merijn> joneshf-laptop: Story of my life
07:02:37 <merijn> joneshf-laptop: Time to patch the least sucky one to do what you need and submit a PR ;)
07:03:34 <joneshf-laptop> That's the problem, the things each is missing is cryptography stuff. And I don't feel anywhere confident enough to do that :(
07:04:04 <joneshf-laptop> Sorry, I'm being too negative. You're right.
07:05:18 * ski . o O ( "100% and 80% solutions" by Olin Shivers in 1998-08 at <https://scsh.net/docu/post/sre.html> )
07:06:01 <merijn> ski: Well, if the 80% solution isn't awful you can incrementally approach 100% :)
07:06:21 <Tuplanolla> When I see that name I can only think of his famous preface, ski.
07:06:43 <merijn> It's why I try to submit patches/PRs for almost, but not quite, perfect tools. If everyone fixes little things we get awesome solutions :)
07:06:48 <ski> Shivers has also written some interesting papers
07:10:21 <ski> e.g. "Multi-return function call" (with David Fisher in 2006) at <http://www.ccs.neu.edu/home/shivers/citations.html#mrlc>, and "The anatomy of a loop: a story of scope and control" (in 2005) at <http://www.ccs.neu.edu/home/shivers/citations.html#mrlc>
07:14:44 <mojjo> consider a list [1,5,7,3] . I'm interested in the distances of the items next to each other. Like: map abs [5 - 1, 7 - 5, 3 - 7]  . What is a general approach for such things? I created a function 'part2' (http://pastebin.com/e9kBeHCp), which would produce [(1,5), (5,7), (7,3)] for the list and went on with this but maybe there's another path to go...
07:16:44 <lyxia> > [x - y | y : x : _ <- tails [1,5,7,3]]
07:16:49 <lambdabot>  [4,2,-4]
07:17:01 <lyxia> mojjo: How about that
07:17:27 <Adluc> fmap (\(x,y) -> y-x) $ zip a (drop 1 a)
07:18:20 <Adluc> > a = [1,5,7,3]; fmap (\(x,y) -> y-x) $ zip a (drop 1 a)
07:18:23 <lambdabot>  <hint>:1:3: error:
07:18:23 <lambdabot>      parse error on input ‚Äò=‚Äô
07:18:23 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
07:18:30 <Adluc> > let a = [1,5,7,3]; fmap (\(x,y) -> y-x) $ zip a (drop 1 a)
07:18:33 <lambdabot>  <hint>:1:59: error:
07:18:33 <lambdabot>      parse error (possibly incorrect indentation or mismatched brackets)
07:18:39 <ski> still missing `in'
07:18:50 <Adluc> > let a = [1,5,7,3] in fmap (\(x,y) -> y-x) $ zip a (drop 1 a)
07:18:52 <lambdabot>  [4,2,-4]
07:18:57 <Adluc> ^_^ thx
07:20:34 <mojjo> yes, the two solutionsa ae certainly much better! thx
07:21:10 <ski> mojjo : .. how about your `Fractional' question ?
07:22:47 <mojjo> oh, actaully very nice you are asking... Its indeed not solved yet... Alright, I'll provide some more details... 
07:23:05 <Adluc> mojjo: zipWith (flip (-)) a (drop 1 a)
07:24:47 <Darwin226> Adluc: Isn't this `zipWith (-) (dop 1 a) a`?
07:24:58 <mojjo> zipWith (-) (tail a) a
07:25:31 <ski> > zipWith (-) (tail []) []
07:25:34 <lambdabot>  *Exception: Prelude.tail: empty list
07:25:46 <ski> > zipWith subtract [] (tail [])
07:25:49 <lambdabot>  []
07:28:27 <Adluc> well, yes :)
07:31:56 <joneshf-laptop> That's more a problme with `tail` than with the suggestion, right?
07:32:41 <joneshf-laptop> > zipWith subtract (drop 1 []) []
07:32:44 <lambdabot>  []
07:34:08 <mojjo> ski: Thanks for asking. The Fractional issue is solved, I mixed it up with Floating. Writing the instance for the latter worked.. 
07:34:08 <joneshf-laptop> > let xs = [1, 5, 7, 3] in zipWith subtract (drop 1 xs) xs
07:34:10 <lambdabot>  [-4,-2,4]
07:36:16 <pie___> do you guys know any good haskell overview articles that you could show a physicist without a strong CS background? 
07:36:55 <joneshf-laptop> pie___, what do you want your physicist to know?
07:37:40 <ski> mojjo : .. if you had provided more information when you originally hinted at the problem, possibly someone would have been able to provide more swift help
07:42:10 <customminer> Hey, I'm using turtle to query a program which returns json to which I'm trying to Parse with aeson, the problem is that shell and inshell write the output one line at a time instead of just returning the full json chunk.. Is there a better shell package than turtle for handling json data? Thanks :) 
07:42:44 <pie___> joneshf-laptop, whether he might want to use it i guess
07:43:02 <johnw> customminer: I would be highly surprised if turtle didn't give you a way to read all the input into a single lazy ByteString
07:48:11 <customminer> johnw: ok, I'll look into that, thanks. 
07:48:28 <Redrield> I'm trying to configure a VSCode plugin that uses Intero, it uses 'stack ghci --with-ghc intero --no-build --no-load --ghci-options="-ignore-dot-ghci -Wall"' to spawn the Intero instance, and I'm getting this error when I try that https://hastebin.com/jelocikesu.tex
08:07:51 <nitrix> http://lpaste.net/353672 - Anyone can help me resolve this ideally without bruteforce?
08:08:00 <nitrix> Even better if the solution is in Haskell.
08:08:55 <nitrix> Or explained with Haskell.
08:09:30 <nitrix> I can't figure out the algebra because of that alternating thing.
08:13:44 <nitrix> I can easily rephrase the problem of present it differentely if needed, as I'm its author.
08:16:51 <lyxia> nitrix: there doesn't seem to be a unique solution
08:17:31 <lyxia> can't you just add one order of magnitude more beads at each round?
08:18:33 <nitrix> lyxia: So, my original attempt was to put one bead on one side, then I naively thought, let's keep adding 2 beads on each side, as there'll be one bead heavier and it'll rock back and forth.
08:18:59 <MitchellSalad> hello all, I have a codebase that is throwing deferred type errors, but I don't actually have them turned on... has anyone seen this before?
08:19:01 <nitrix> Until I quickly realised that at some point the fact that the heavy side gets multiplied by 3 and the light side by 4, it breaks.
08:19:08 <nitrix> So I need to add progressibely more beads.
08:19:26 <nitrix> lyxia: Order of magnitude?
08:19:42 <lyxia> nitrix: are you trying to add as few beads as possible?
08:19:46 <nitrix> lyxia: Yeah
08:20:05 <lyxia> okay, nevermind what I said then
08:20:15 <nitrix> lyxia: The actual real application of this problem is for the stock market :P
08:20:51 <nitrix> I was tempted to put a bounty on it :3
08:21:13 <nitrix> I'm sure I can figure it out via brute-forcing but it doesn't feel right. I'd love to have a formula.
08:21:38 <lyxia> I don't even see why you need "brute-forcing" here
08:22:17 <lyxia> you have x > y beads on each side, you want to add z beads to y, such that 4x < 3(z+y) ?
08:23:12 <nitrix> Correct.
08:24:07 <nitrix> But I'm interested in that sequence of Z's.
08:24:35 <nitrix> Or at least, the value of Z at any given round R.
08:26:13 <lyxia> by "brute-forcing" you mean computing the sequence one term after the other, as opposed to a magical formula that gives you Z at round n ?
08:26:35 <Jinxit> exactly how do i reify a Traversal in lens?
08:26:47 <nitrix> lyxia: Yeah. As I'm a more skilled with programs than with maths :P
08:27:02 <nitrix> lyxia: But this once, a formula would be really awesome.
08:27:59 <lyxia> nitrix: z is a linear combination of x and y, so there is in fact a more efficient algorithm for that
08:28:26 <nitrix> lyxia: Could that translate to a recursive function in Haskell or is there even better ways?
08:29:53 <lyxia> it's going to be a pretty simple program yes. Let me take my pen and paper.
08:31:02 <nitrix> Make sure you PM me your paypal too, for your time (:
08:31:05 <lyxia> nitrix: is z supposed to be an integer?
08:31:17 <nitrix> lyxia: Positive integer, yes.
08:31:41 <Jinxit> linear programming, no?
08:32:06 <nitrix> lyxia: So a natural number :)
08:32:43 <orion> Is it true that linear types = the value must be used at least once, and unique types = the value must be used at most once?
08:32:50 <lyxia> nitrix: I might only get an approximation
08:33:00 <Jinxit> isn't linear at most once?
08:33:44 <nitrix> lyxia: I don't mind if it's not as optimal as the linear growth allows you.
08:33:57 <nitrix> lyxia: As long as 4x < 3 (z+y) is maintained.
08:34:17 <Redrield> Someone?
08:34:50 <lyxia> In the linear Haskell paper "linear" is "exactly once"
08:34:57 <nitrix> lyxia: "Somewhat optimal" as much as working with naturals allows you is pretty much what I'm after.
08:35:20 <c_wraith> Jinxit: affine is at most once, linear is exactly once
08:35:26 <nitrix> lyxia: Maybe you can use doubles and ceil the result?
08:35:31 <Jinxit> indeed
08:41:42 <lyxia> nitrix: do you necessarily start from an empty scale
08:42:32 <nitrix> lyxia: Yus, which makes the first round pretty much always 1.
08:42:57 <nitrix> 4*0 < 3 * (1 + 0)
08:44:02 <nitrix> I quite confident the second round is also 2.
08:44:47 <AndreasK> Redrield: Sounds like an error with either a library or the setup, if you haven't already I would try to clean out your stack cache and set it up again to exlude the chance of some outdated file/lib messing up your setup.
08:45:15 <nitrix> 4*1 < 3*(2 + 0)
08:45:17 <AndreasK> Redrield: Or try with a newer lts version and see if it happens there as well
08:45:41 <lyxia> nitrix: it's <, not <=, right?
08:46:12 <nitrix> lyxia: It is, but does it affects the formula a lot or can it be changed later?
08:46:40 <nitrix> lyxia: It makes a difference between making a profit or breaking even in my case :P
08:47:05 <nitrix> Let's go with <
08:48:38 <pie___> so, if the haskell compiler is much "better" than say C compilers, why is it still relatively slower?
08:48:55 <pie___> i mean why are programs produced by it
08:49:07 <lyxia> nitrix: Using some general and flexible method I can have a pretty good upper-bound, I'm wondering whether you have a specific enough case such that using enough tricks lands you on an exact solution.
08:50:58 <AndreasK> pie___: How do you define better when comparing compilers for different languages?
08:51:34 <hpc> how do you compare?
08:51:46 <hpc> do you spend 6 months making a benchmark in C and another 6 months in haskell?
08:51:53 <hpc> or do you spend a day and a half on each
08:52:01 <hpc> or do you spend exactly enough time to write something correct
08:52:10 <hpc> and then see how fast those are
08:52:24 <hpc> also what benchmarks do you pick
08:52:54 <monochrom> I think pie___ means they read someone else wrote "better".
08:53:17 <hpc> ah
08:53:21 <monochrom> In which case why should I defend some anonymous author.
08:53:35 <pie___> :I im not saying youre wrong...
08:53:43 <pie___> in fact youre right
08:54:03 <pie___> i know its not a precisely defined comparison but if you want to write numeric code would it be fair to say haskell is inherently bad for that?
08:54:14 <pie___> and that c is better
08:54:20 <c_wraith> Not really.
08:54:21 <monochrom> Fortran.
08:54:25 <pie___> :P
08:54:36 <c_wraith> Fortran is good for numerical code.  C really isn't.
08:54:57 <monochrom> C is worse because its pointer features actually disable a lot of optimizations.
08:55:02 <lyxia> nitrix: at every step if x is the heavier side, at the next step the heavier side will be between 4x and 4x+3. So you get an exponential bound on the heavier side, and from that you can derive how much was added at every step.
08:55:21 <monochrom> (Of course, I mean "C is worse than Fortran" for this.)
08:55:27 <pie___> monochrom, ok so haskell is better than c for numerical code, so why is it slower? or is it not slower
08:55:40 <pie___> ok so c is worse than fortran.
08:55:55 <monochrom> Haskell's case depends on the programmer.
08:56:04 <c_wraith> Haskell can get pretty solid numerical performance, but you have to know a lot about what's going on.
08:56:24 <monochrom> GHC does its part, but the programmer needs to know how to trigger GHC into that.
08:56:41 <c_wraith> iirc, carter has been doing a lot of numerical work in Haskell
08:57:02 <pie___> haskell sounds disproportionately hard to optimize
08:57:13 <c_wraith> It's really not.  It's just different
08:57:20 <pie___> ok
08:57:20 <carter> c_wraith: I'm slowly resuming it too :)
08:57:28 <carter> Get the math right first
08:57:35 <carter> Then figure out stuff
08:58:12 <nitrix> lyxia: They are hedging positions (one buying, one selling). While a position is losing, the other position will be winning, the wins must outgrows the losses, so to achieve a profit, one side of the hedge is slightly bigger than the other. As the market reverses and the targets still aren't hit, it's possible that target B becomes more likely than A, so we increase the small hedge to make it the biggest
08:58:13 <nitrix> hedge, hoping it'll hit its target.
08:59:13 <nitrix> lyxia: It's not very easy to explain without all the pieces that makes it work in practice.
09:00:37 <metafoobar> nitrix,lyxia: can you give me some background on what you two are discussing? sounds very relevant to my interests
09:01:03 <nitrix> lyxia: That's very helpful. I should be able to derive from the growth how much was added with a bit of thinkering.
09:01:14 <nitrix> lyxia: Can you PM me?
09:04:13 <nitrix> metafoobar: lyxia has been helping me figure out the growth of positions for a strategy I've seen been used successfully used by some friends.
09:06:42 <nitrix> metafoobar: It's still in the early stages, but I'll definitely come back and thinker/share the results with you if you have an interest :)
09:10:33 <orion> 11:34:29 < lyxia> In the linear Haskell paper "linear" is "exactly once" -- link to paper?
09:11:36 <lyxia> http://www.microsoft.com/en-us/research/publication/retrofitting-linear-types/
09:11:51 <orion> thanks
09:15:31 <Redrield> How can I clear the stack cache?
09:15:44 <Tuplanolla> The what now?
09:16:32 <Tuplanolla> Oh, Stack.
09:16:34 <Redrield> I was told to clear my stack cache and recompile intero, because at the moment it's crashing
09:17:54 <Tuplanolla> See if there's a `.stack-work` directory nearby.
09:23:06 <Tuplanolla> For a moment there I thought you were talking about processor cache eviction.
09:25:36 <lyxia> nitrix: do you want a bound on the optimal strategy, or do you want one actual strategy? These are not quite equivalent.
09:28:22 <Redrield> I'm so confused .-. https://hastebin.com/gijiviseji.pas
09:29:48 <johnw> Redrield: I can't even see your code on hastebin without disabling all of my ad blocking
09:30:10 <int-e> right, this is the age of blank pastebins. it saves me a lot of trouble ;-)
09:30:16 <johnw> and that's after letting through cookies, scripts, and XHR in uMatrix
09:30:34 <Redrield> https://gist.github.com/Redrield/0d9f601ddc79039d5098365327aeec40
09:30:38 <johnw> gone are the days when text was just text
09:30:43 <johnw> Redrield: thanks :)
09:30:54 <johnw> ah, I don't use stack, sorry
09:33:18 <jgt> is it possible to get Stack to build just a single file?
09:33:28 <jgt> i.e., without building a full on project
09:34:30 <jgt> like, `echo "main = putStrLn \"foo\"" > foo.hs; stack build foo.hs`?
09:35:12 <jgt> obviously with the `module main where‚Ä¶`
09:36:35 <djfo> jgt: stack ghc foo.hs
09:38:10 <jgt> djfo: beautiful. Thanks!
09:38:51 <jgt> I'm writing scripts to be run on a remote server, and I don't want to have to install Stack on the remote machine just to run the one-time scripts
09:40:22 <jgt> and of course I don't want to do it in bash, because I know I will make a typo which will set everything on fire
09:43:57 <Jinxit> any lens veterans around? i can't seem to reify a traversal
09:45:32 <erisco> jgt, there is runhaskell
09:45:34 <Jinxit> do i just do "ReifiedTraversal' FromType ToType traversal"?
09:45:49 <jgt> erisco: what's the difference?
09:46:05 <glguy> Jinxit: No, what's the data constructor for ReifiedTraversal?
09:47:07 <erisco> jgt, I don't know exactly, but I think runhaskell is interpreted similarly to ghci
09:47:19 <nitrix> lyxia: Sorry, had to deal with something. Optimal strategy if you're still interested.
09:47:19 <Jinxit> glguy: i don't know
09:47:34 <glguy> Jinxit: OK, type into GHCi:   :info ReifiedTraversal
09:47:34 <erisco> someone told me it takes it to byte code, so whatever that means
09:47:39 <nitrix> lyxia: Err sorry, one actual strategy.
09:47:59 <nitrix> lyxia: The bound isn't too helpful.
09:49:05 <nitrix> lyxia: The goal in the end is having a function that gives the `z` for any `n` somewhat deterministically.
09:50:11 <lyxia> nitrix: that's actually the part I'm having trouble with :/
09:50:25 <nitrix> lyxia: We're in the same boat :P
09:50:53 <joneshf-laptop> Is there an easy way to go from an RSA public file to a `Crypto.JOSE.JWK`: https://www.stackage.org/haddock/lts-8.5/jose-0.5.0.2/Crypto-JOSE-JWK.html#t:JWK ?
09:50:59 <joneshf-laptop> Everything I've tried has lead to pain.
09:51:18 <nitrix> lyxia: It must be doable, right? If one can brute-force every z to find the optimal strategy, isn't that a sign there must be a formula?
09:51:50 <joneshf-laptop> short of using another language entirely to convert the RSA public file into a JWK and saving it.
09:51:52 <lyxia> I don't think so
09:51:54 <nitrix> lyxia: Worst case, I can do my naive approach and just hardcode a large array of z's :/
09:52:16 <Jinxit> glguy: i think i got it, thanks
09:53:42 <Jinxit> yeah compiles now :)
10:03:09 <ph88^> hello
10:03:16 <ph88^> ski, are you around ?
10:21:42 * ski looks at ph88^
10:23:59 <geekosaur> pie___, C is hard to optimize in the same ways if you are after ultimate speed; Fortran numeric programmers whine about it all the time
10:24:34 <pie___> guess we should learn from fortran haha ;)
10:24:38 <geekosaur> and don't get me started abut the few assembly language programmers left that complain about *all* compilers :)
10:24:44 <pie___> lol
10:24:54 <pie___> the demoscene is crazy man
10:25:10 <pie___> intros are very rad
10:25:45 <geekosaur> each has its strong points and weak points; in each, there are easy optimizations and hard ones. Haskell makes a number of otherwise hard optimizations much easier --- but loses on some of the ones that are easier with non-pure languages
10:26:34 <geekosaur> so the whole notion of comparing them is rather screwy and in many ways meaningless unless you can point to what exactly you are talking about, and sometimes even then
10:26:42 <pie___> id like to stick to haskell but i keep feeling ill probably end up needing to use matlab or something :P
10:26:53 <pie___> yeah i know/understand
10:27:21 <geekosaur> matlab's actually another example. if it didn't exist you'd be working in APL, which is much faster but ... well, APL.
10:27:37 <geekosaur> (and neither one is amenable to most optimizations...)
10:27:39 <pie___> yeah lol
10:27:49 <pie___> well, one hopes.
10:34:06 <Jinxit> is it possible to join two traversals into one? does it even make sense to do it?
10:35:18 <Jinxit> in lens
10:37:21 <ph88^> ski, i have a bit of a problem getting the bigger pictures together. You were right earlier that the eot argument is not used yet, this is because i don't know what to do with it, but i put it there because Code piece 1 also has it as it's first argument
10:38:06 <nitrix> @let findZ x y = head [z | z <- [1..], (4 * x) < (3 * (z + y))];    formula = unfoldr (\(x, y) -> let z = findZ x y in Just (z, (y+z,x))) (0, 0)
10:38:15 <lambdabot>  Defined.
10:38:54 <nitrix> > take 10 formula -- lyxia
10:39:00 <lambdabot>  [1,2,2,3,4,5,7,9,12,16]
10:39:08 <nitrix> :)
10:41:00 <ph88^> ski, i figured i should strive to get the types right first before i should get the implementation right. I already have difficulties grasping what i'm expressing here on the type level, let alone the implementation of the function :(
10:41:02 <lyxia> findZ is just a div or something
10:41:24 <ski> ph88^ : i think probably you don't want that `eor' argument at all
10:41:37 <ski> s/eor/eot/
10:41:51 <ph88^> ski, on line 6 there is a function that also expects eot as first argument, you see ?
10:42:02 <nitrix> lyxia: Myeah, or something. When your brain's off, lists comprehensions are awesome :P
10:42:25 <lyxia> nitrix: findZ x y = (4 * x - 3 * y + 2) `div` 3
10:42:49 <lyxia> oh wait you want <
10:42:59 <lyxia> nitrix: findZ x y = ((4 * x - 3 * y) `div` 3) + 1
10:43:24 <ph88^> ski, if i have eot as first argument i can do    eotTerminal . toEot    this is simular to the tutorial    genericSerialize = eotSerialize 0 . toEot    at url  https://generics-eot.readthedocs.io/en/latest/tutorial.html    that's why i think i need eot to be the first parameter
10:44:05 <nitrix> lyxia: Nice. All I needed was accurate numbers. Beyond 20 elements, it already gets ridiculously big.
10:44:19 <ski> ph88^ : i was thinking the lens thing was replacing this function from `eot'
10:44:41 <nitrix> lyxia: Just the 13th element, which I think is 121, is 1.21 lot. That's 121k $.
10:44:44 <nitrix> lyxia: It's a lot of money :P
10:44:57 <ph88^> ski, that's what my initial idea was too, but it didn't quite typecheck .. ok let me go back to the previous version of this and come back to you
10:45:02 <nitrix> lyxia: Anyway, I'll play with that. Thanks for the help :)
10:45:58 <nitrix> lyxia: PM me your paypal btw.
10:47:29 <nitrix> Get yourself a nice dinner or something (:
10:52:21 * ski disappears
10:53:14 * lerax is dead
10:53:24 <ph88^> ok bye ski :P
10:53:32 <nshepperd> Jinxit: you can compose traversals -- (.) :: Traversal' a b -> Traversal' s a -> Traversal' s b
10:53:40 <ph88^> i have to go soon too
10:53:49 <ph88^> i prepare my question for next time
10:54:09 <nshepperd> Jinxit: but maybe you're thinking of sequentially traversing the same thing? `Traversal' s a -> Traversal' s a -> Traversal' s a`?
10:54:56 <nshepperd> but I dunno how much sense that makes
10:58:02 <nshepperd> I think the result would have a Monad constraint if it was sequential, which makes it not a Traversal
10:59:08 <c_wraith> traverse implies a sequential ordering. 
11:15:31 <fresheyeball> hey out there
11:15:38 <fresheyeball> anyone using ghcid?
11:18:08 <cocreature> fresheyeball: I‚Äôve used it in the past, why?
11:24:46 <Jinxit> nshepperd: yeah i meant in sequence
11:24:57 <Jinxit> (and sorted, too)
11:25:07 <Jinxit> but i guess i'll change my plans
11:32:24 <pikajude> is there a library that transforms a NominalDiffTime into an English phrase
11:55:57 <andrei> How does one read/write global variables in c2hs?
12:59:04 <novakboskov> I have some problem understanding type synonyms instances overlapping. Is there anyone who is willing to clarify it? Code is basically from http://apfelmus.nfshost.com/articles/monoid-fingertree.html (Monoids - the grand unifier) and it is packed at http://lpaste.net/353688
13:03:56 <geekosaur> novakboskov, type synonyms are exactly that. you cannot make separate instances for them.
13:04:06 <geekosaur> newtypes are for use when you need distinct instances.
13:04:54 <Tuplanolla> Despite its name `TypeSynonymInstances` doesn't change this either, novakboskov.
13:05:00 <geekosaur> (I suspect apfelmus forgot to convert the original `type`s to `newtype`s.)
13:05:51 <geekosaur> looks like the post was cobbled together from various list posts, and that part of it fell through the cracks?
13:16:59 <metafoobar> nitrix lythia: do you guys have a Git repo or something with the code that you're working on? I'd love to take a look. Of course, I understand if your code is not for the eyes of the lay public :)
13:34:03 <deech> Hi all, I'm trying to profile a Haskell executable that statically links to a C library. `stack build` works but `stack build --library-profiling --executable-profiling` throws an error about not being able to find the C lib. Do I need to do something different when profiling?
13:34:14 <novakboskov> geekosaur, you think it should be something like http://lpaste.net/353690?
13:36:19 <cocreature> deech: what‚Äôs the exact error you‚Äôre seeings
13:36:22 <cocreature> *seeing?
13:36:46 <geekosaur> novakboskov, yes
13:37:04 <novakboskov> geekosaur: thanks!
13:37:07 <deech> cocreature: A linker error about not being able to find C lib.
13:37:11 <geekosaur> although I'd probably use record syntax in the newtypes rather than define accessors in where clauses; you will likely need them elsewhere as well
13:37:37 <geekosaur> you might compare how the standard Sum and Product newtypes work
13:38:33 <geekosaur> deech, but which C lib?
13:47:33 <deech> geekosaur: It's one I built locally. It's my fltkhs package (https://hackage.haskell.org/package/fltkhs). It build the C bindings in their own static library and links to it when building the executables.
13:48:18 <geekosaur> so not a C profiling base library? although still hard to tell. really, we need to see verbose build output including the link command
13:48:42 <int-e> bollu: mmm
14:02:00 --- mode: ChanServ set +o mauke
14:02:00 --- mode: mauke set -b *!~GK_1wm_SU@*
14:04:00 --- mode: mauke set -o mauke
14:04:59 <boxofdeath> whois bod)
14:05:02 <boxofdeath> omg
14:05:13 <boxofdeath> :(
14:06:49 <buttons840> can I have a type variable in a type alias?
14:07:28 <geekosaur> yes
14:08:03 <buttons840> `type A = Maybe x` gives me an error because x is undefined?
14:08:16 <monochrom> Make it: type A x = Maybe x
14:08:30 <buttons840> ah, ty
14:08:35 <ertes> buttons840: example: type Maybe2 a = Maybe (Maybe a)
14:08:56 <ertes> buttons840: a type variable can't come out of nowhere‚Ä¶  it must be bound, either by the alias itself or by a 'forall'
14:18:47 <buttons840> ertes: right, I guess the extreamly wrong case would be `type A = x` -- which doesn't provide a lot of insight to the compiler
14:26:49 <ertes> buttons840: a type alias is a type-level function, and the compiler doesn't know what you mean by "x" there
14:41:24 <mofasa_> is there some better pattern to use than: `f inp = if isJust $ runParser p1 inp then runParser p1 inp else runParser p2 inp`
14:42:09 <monochrom> runParser p1 inp <|> runParser p2 inp
14:42:24 <monochrom> in fact, runParser (p1 <|> p2) inp
14:42:39 <mofasa_> monochrom: it's in the implementation for <|>
14:42:57 <monochrom> Then use my first line.
14:43:23 <mofasa_> ah yes, since it uses <|> of Maybe, right
15:04:02 <ttoe> Any insights as to why exhaustiveness check at compile time doesn't warn me here: http://lpaste.net/2307285877706981376
15:04:51 <glguy> ttoe: You can turn on the non-exhaustive patterns warning if you want it
15:05:38 <ttoe> Oh, Ok I guess I expected not a warning, but that it won't compile to be accurate
15:06:22 <glguy> You can use -Wincomplete-patterns
15:07:05 <dmwit> If you want an error, you can then also use -Werror.
15:07:30 <Tuplanolla> How is that different from `-fwarn-incomplete-patterns`, glguy?
15:08:21 <dmwit> > (length "-Wincomplete-patterns", length "-fwarn-incomplete-patterns")
15:08:23 <lambdabot>  (21,26)
15:08:35 <dmwit> 20% shorter =)
15:08:48 <glguy> Tuplanolla: -fwarn-incomplete-patterns is old tech, not documented
15:08:59 <glguy> Mine is hip and new
15:09:21 <monochrom> heap and new are good friends.
15:09:29 <monochrom> until one day the heap becomes full.
15:12:00 <ttoe> I have these ghc-options in the cabal file:  -Wall -threaded -rtsopts -with-rtsopts=-N -Werror -Wincomplete-patterns
15:12:08 <ttoe> with all these flags i dont get anything
15:12:24 <ttoe> using stack
15:12:43 <glguy> ttoe: try cleaning and rebuilding
15:18:14 <ttoe> glguy: I deleted .stack-work and still have no luck
15:18:24 <glguy> You'll have to show more of the file then
15:20:38 <ttoe> http://lpaste.net/353692
15:21:17 <ttoe> thats all there is. Main.hs just calls gameLoop
15:22:40 <tswett_to_go> So, I'm trying to abuse Template Haskell.
15:22:50 <tswett_to_go> I mean, abuse is pretty much what it was made for, right? :)
15:22:54 <glguy> ttoe: and what warning were you expecting?
15:24:09 <ttoe> well, if line 40 is missing, there is no compile time warning/error about non exhaustiveness
15:24:42 <glguy> line 40 wasn't missing in what you pasted
15:24:55 <tswett_to_go> I have some code that automatically creates a class.
15:25:02 <tswett_to_go> I'm... trying to figure out what I actually want here.
15:25:16 <geekosaur> ttoe, the problem is that patterns in `do` desugar differently
15:25:31 <ttoe> glguy: i know, but i deleted it for fun and it worked until i hit another key at runtime
15:25:32 <geekosaur> missing patterns call fail, instead of throwing; the compiler lets this go because it's a feature
15:25:36 <ttoe> glguy: then it crashed
15:25:48 <geekosaur> (it is, for example, how you filter in list comprehensions, which use the same machinery)
15:26:00 <geekosaur> (or the list monad)
15:26:10 <hololeap> i am looking for a monad transformer that encapsulates the idea of a choice being made from the context of another monad, and then behaving based on this choice
15:26:11 <glguy> ttoe: these warnings work, so if you've got something wrong you'll have to give us all the information you have or figure it out locally
15:26:34 <glguy> things like the cabal file, command output, actual file you loaded
15:26:41 <geekosaur> I don't know if there's a separate warning for these
15:27:32 <hololeap> i tried making one with the data structure, `data Choice x m a = Choice (x -> m Bool) (x -> m a) (x -> m a)`, but i got stuck when trying to make the bind function for the Monad class.
15:27:42 <glguy> geekosaur: line 40 isn't do-notation pattern matching
15:28:36 <ttoe> Hm, strange, I'll fiddle around some more
15:29:25 <dmwit> hololeap: Eh, why a monad transformer? That's just a function.
15:29:44 <dmwit> :t \m l r -> m >>= \x -> if x then l else r
15:29:46 <lambdabot> Monad m => m Bool -> m b -> m b -> m b
15:30:24 <hololeap> dmwit: i dunno, masochistic intellectual curiosity?
15:31:06 <hololeap> i thought it was a good idea, but it turns out turning an idea into a working monad is hard
15:31:44 <dmwit> :t if'
15:31:46 <lambdabot> error:
15:31:47 <lambdabot>     ‚Ä¢ Variable not in scope: if'
15:31:47 <lambdabot>     ‚Ä¢ Perhaps you meant ‚Äòf'‚Äô (imported from Debug.SimpleReflect)
15:31:51 <dmwit> ?hoogle ifM
15:31:51 <lambdabot> Control.Monad.Extra ifM :: Monad m => m Bool -> m a -> m a -> m a
15:31:52 <lambdabot> Extra ifM :: Monad m => m Bool -> m a -> m a -> m a
15:31:52 <lambdabot> Bool ifM :: Monad m => m Bool -> m a -> m a -> m a
15:31:55 <dmwit> heh
15:32:18 <hololeap> dmwit: let me check that out
15:32:29 <tswett_to_go> I want to be able to write something like this: class MyThing a where { f :: a -> a; f_is_id :: $(call this parameter "x") a -> $(this represents a proof that f x = x) EqualityProof a }
15:33:12 <tswett_to_go> The resulting class would just be this stuff with the splices removed, but then other Template Haskell stuff would be able to go and look at the splices.
15:34:09 <dmwit> Haskell doesn't really have value-level equality proofs. That requires dependent types. You can sometimes fake it with GADTs and singletons.
15:34:35 <jle`> is there any nice library for representing/reifying Num-polymorphic functoins
15:34:44 <jle`> probably osmething similar to simple-reflect but more constrained
15:35:01 <jle`> i mean at the easiest level you could just make a tree with Integer's as leaves
15:35:01 <dmwit> tswett_to_go: You're probably going to have a much easier time writing this in Idris and using its Haskell FFI if you need to interface with Haskell code.
15:35:04 <tswett_to_go> Right. I don't actually want value-level equality proofs anyway; I just want to mark something as representing an equality proof.
15:36:04 <dmwit> jle`: I have wished for this occasionally as well. A `newtype` around `forall a. Num a => a` is almost it, even.
15:36:20 <jle`> well the reason i want one at the moment is for serialization purposes
15:36:24 <jle`> which miiiiight be a misguided reason
15:36:51 <jle`> but yeah i think i've seen a lot of libraries do their own newtype-over-RankN trick...i've done it myself a few times
15:36:55 <jle`> if there isn't one i'm just going to make it
15:37:03 <tswett_to_go> Here's a concrete question.
15:37:09 <dmwit> tswett_to_go: `data Decided a = Inequal a a | Equal a a` -- ?
15:37:33 <tswett_to_go> Is there shortcut syntax for this: $(transformClassSomehow [| class MyClass a where { class details omitted } |] )
15:38:59 <jle`> searhjcd for 'numeric' on hackage and browsed the 116 results and didn't see anything, so i'll just go and make one
15:41:50 <centril> how do you make associated types in type classes (open type family) injective ?
15:42:26 * geekosaur needs more sleep :(
15:43:17 <centril> i.e: what is the syntax ?
15:43:29 <centril> I currently have:  type Repr t :: *
15:45:18 <tswett_to_go> Does using "data" instead of "type" there do that?
15:45:43 <centril> tswett_to_go: that would create a data family iirc
15:45:50 <centril> I already have a data type
15:46:12 <pita> \quit
15:46:20 <centril> tswett_to_go: I could try it tho
15:46:48 <ttoe> glguy: Got it! Thanks! Had to add ghc-options to library settings as well \*_*/
15:46:49 <tswett_to_go> centril: are you trying to solve a "such-and-such is not injective" error caused by an ambiguity check?
15:46:56 <centril> tswett_to_go: yes
15:47:28 <tswett_to_go> centril: I don't think there's a way to "make a type family injective", but adding a Proxy parameter should fix your problem.
15:48:04 <centril> tswett_to_go: umh... https://ghc.haskell.org/trac/ghc/wiki/InjectiveTypeFamilies
15:49:03 <tswett_to_go> Well... I guess I don't know what I'm talking about, then. :)
15:49:12 <tswett_to_go> I don't know much about type families, so I'll quit guessing.
15:49:21 <centril> :P
15:49:34 <centril> tswett_to_go: well, now you have some reading to do
15:49:48 <dmwit> centril: Doesn't the page you linked also answer your question?
15:50:03 <dmwit> section "Proposed syntax"
15:50:35 <centril> dmwit: those are for explicit type families - i have a type class
15:51:12 <dmwit> No, they work with associated types, too.
15:51:19 <dmwit> I have just tested this to be sure.
15:51:27 <centril> dmwit: right, but what is the syntax ?
15:51:39 <dmwit> Same syntax. `type Foo a = b | b -> a` or similar.
15:51:50 <centril> dmwit: thanks
15:52:25 <centril> dmwit: oh... so you specify it on the instance and not on the family itself (in the class) ?
15:52:35 <centril> seems weird
15:52:37 <dmwit> No, specify it in the class.
15:52:58 <dmwit> I want to help, but I honestly don't know what you're confused about.
15:52:59 <centril> dmwit:  so   type Foo a :: * | b -> a  ?
15:53:15 <dmwit> ...no?
15:53:23 <dmwit> I typed the exact syntax above.
15:54:08 <centril> dmwit: sec
15:54:40 <nshepperd> centril: class Foo a where { type family Bar a = (bara :: *) | bara -> a }
15:54:45 <lpaste_> Centril pasted ‚Äúinjective associated types?‚Äù at http://lpaste.net/353695
15:55:11 <centril> nshepperd: oh, =) thanks
15:55:12 <dmwit> centril: `type Repr t = r | r -> t`...
15:55:22 <centril> dmwit: now i got it ^^
15:55:34 <centril> i was wondering where the b magically came from
15:55:39 <centril> confusing syntax :/
15:55:40 <nshepperd> huh, i didn't know you could leave off the 'family'
15:55:41 <dmwit> It magically comes from you. =)
15:55:57 <centril> dmwit:  ^^
15:56:04 <centril> dmwit: I do believe in magic
15:56:49 <dmwit> I think it's just shorter and less redundant than making the syntax be `type Repr t | (Repr t) -> t`
15:57:39 <lenec> Hello, I'm a complete functional programming noob, but I'm very intrigued by the paradigm... there are a lot of things I don't understand, but the most prevalent one is that I can't see how functional programming scales properly.
15:57:49 <lenec> http://www.codenewbie.org/blogs/object-oriented-programming-vs-functional-programming
15:57:55 <Tuplanolla> Scale wrt what?
15:57:56 <centril> dmwit: yes, but the  = symbol makes me believe I have to provide the type on the RHS from somewhere else
15:57:57 <lenec> gives an example case about raising salaries of employees.
15:58:08 <lenec> When I scale this example (by raising the salaries multiple times) in the OOP paradigm, it works really well. the complexity of the program doesn't increase as the amount of salary raises increases, but in the functional programming paradigm...?
15:58:19 <lenec> Would I end up with evenhappiereemmployees, evenmorehappieremployees, incrediblyhappieremployees... and so on? :S
15:58:30 <lenec> This increase of complexity doesn't make any sense to me. Everywhere I read about functional programming, it is claimed that functional programming can do everything OOP can do, but just in a different way.
15:58:39 <lenec> But if that means it will be at the cost of scalability, wouldn't that make the paradigm pointless? :S
15:58:58 <centril> lenec: any two turing equivalent languages can do what the other can, in principle
15:59:25 <dmwit> centril: I hate that argument. It completely ends any (useful) discussion about whether one language can be better than another.
15:59:33 <dmwit> We don't program in Brainfuck, thank ${DEITY}.
15:59:52 <dmwit> lenec: What does "scalability" mean to you?
16:00:07 <centril> dmwit: well, it's an important statement - not an argument... I don't believe that all languages are equal... quite the opposite actually
16:00:07 <Tuplanolla> I know some people make a living by programming in `printf` format strings, dmwit.
16:00:32 <ertes> lenec: if you're trying to *translate* OOP into FP, you will end up in an unhappy place
16:00:42 <dmwit> lenec: Presumably you are not writing code with a long list of hand-written rules about which employees get raises; this is input from elsewhere, right? So... you would use all the same techniques for parsing and iterating over that information in FP as you would in OOP.
16:01:06 <centril> dmwit: for example: I loathe golang a lot
16:01:22 <lenec> dmwit that when I increase the amount of salary raises I don't end up with extra (complexity adding) functions like evenhappieremployees etc.
16:01:26 <centril> ertes: until you start using lenses
16:01:36 <ertes> lenec: in FP problems are solved very differently, and in fact more so in *haskell FP*
16:02:06 <bartavelle> lenec, if all your employees are using haskell, they *will* end up even happier
16:02:07 <dmwit> lenec: You want more employees' salaries to change without writing more code? That seems unlikely for any language.
16:02:15 <bartavelle> no way to avoid that
16:02:20 <bartavelle> use OOP to get sad employees
16:02:23 <bartavelle> :p
16:02:39 <ertes> lenec: that means using different ways to structure your code altogether, and different abstractions
16:02:48 <centril> lenec: what is your OOP language of choice ?
16:02:51 <Welkin> OOPs
16:03:03 <Welkin> centril: erlang?
16:03:15 <centril> Welkin: wat? erlang is OOP now ?
16:03:44 <Welkin> it's off topic, but erlang is closer to the idea of message passing from smalltalk (oop) than jav oop
16:03:52 <Welkin> java oop*
16:04:05 <Welkin> there is an alan kay talk about it
16:04:13 <Welkin> (the inventor of oop)
16:04:51 <centril> Welkin: well... java oop is just C++ oop but restricted... c++ oop in turn is just making the receiver (self/this) implict and adding fancy syntax for it
16:04:59 <Welkin> java took the idea and twisted it into something horrible
16:05:08 <centril> if erlang is OOP, then so is haskell
16:05:16 <Welkin> it was a joke centril 
16:05:25 <centril> in fact, ill start calling haskell OOP from now on
16:05:28 <centril> Welkin: oh :P
16:05:30 <Welkin> we all know oop as java-oop these days, which erlang is certainly not
16:05:33 <centril> Welkin: wasnt clear ^^
16:05:35 <Welkin> erlang is very different from haskell though
16:05:42 <Welkin> so even your logic wouldn't make sense
16:05:43 <lenec> I don't mind writing more code... but calling employee1.RaiseSalary(50); employee1.RaiseSalary(150); employee1.RaiseSalary(30);... etc. in succession doesn't create new functions with weird names like incrediblyhappieremloyeesthatareevenhappierthanhappyemployees
16:06:04 <lenec> I hope we can all agree that such a function would be retarded
16:06:25 <Tuplanolla> Your understanding of different paradigms seems to be seriously misguided, lenec.
16:06:30 <Welkin> lenec: zipWith raiseSalary [employee1, employee1, ...] [50, 150, ...]
16:06:30 <dmj`> lenec: When you say ‚Äúscale‚Äù do you mean that you‚Äôll have to write more functions to change behavior? Like saying, ‚ÄúaddOne‚Äù, but now I have to define ‚ÄúaddTwo = addOne . addOne‚Äù.  If you begin writing a fair bit of haskell code, I think you‚Äôll see your capability for expression is far greater than anything OOP can afford, and safer. 
16:06:38 <lenec> and as I understand it right now... functional programming will force me to create such functions
16:06:38 <dmwit> lenec: writing `raiseSalary 50 . raiseSalary 150 . raiseSalary 30 $ employee1` also does not create new values with weird names. (Here `.` is function composition.)
16:06:50 <centril> lenec: OK, so OOP is:  subject.verb(objects...) - fp is:  verb(subject, objects...)
16:06:59 <dmwit> lenec: Indeed, writing a function doesn't create any new names at all. Only declarations can do that.
16:07:05 <Welkin> functions are first class
16:07:14 <Chousuke> FP vs. OOP is not about methods in my view, anyway.
16:07:17 <Welkin> they can be top level
16:07:17 <ertes> lenec: i'm reading the article, and the author doesn't really seem to understand what FP is‚Ä¶  even though the term FP itself is rather vague, there are some things that are clearly *not* FP
16:07:29 <Welkin> they are not ocntained inside functions (not "methods")
16:07:32 <Welkin> contained*
16:07:36 <ertes> "FP prefers to keep data in plain arrays and/or hashes and not ‚Äúcomplicate‚Äù data by mixing it with behavior."
16:07:44 <Welkin> lol, FP is an unknown term
16:07:46 <ertes> the latter part is true, but the former is nonsense
16:07:48 <centril> ertes: speaking of... what is "FP"?
16:07:55 <Welkin> it means something different to everyone
16:08:00 <ertes> centril: "what we do in haskell"
16:08:01 <Welkin> even FRP is a disaster
16:08:03 <centril> Welkin: yeah
16:08:09 <yushyin> Welkin: I always thought, is he really the inventor of oop? simula 67 is older and also had all those OOP features
16:08:16 <Welkin> "look at this FRP library in js" "Oh yeah, React is FRP"
16:08:18 <centril> ertes: oh, well maybe in this context
16:08:19 <Welkin> which it's not...
16:08:27 <Chousuke> to me, the important characteristic of functional programming is that you're thinking in terms of data transformations and function composition
16:08:39 <Welkin> map and filter do not make a functional language :P
16:09:07 <ertes> @let data Employee a = Employee { _name :: String, _salary :: a }  deriving (Eq, Foldable, Functor, Ord, Show, Traversable)
16:09:08 <lambdabot>  .L.hs:145:1: error:
16:09:08 <lambdabot>      ‚Ä¢ The default type ‚Äò()‚Äô is not an instance of ‚ÄòNum‚Äô
16:09:08 <lambdabot>      ‚Ä¢ When checking the types in a default declaration
16:09:19 <ertes> what?
16:09:21 <centril> Chousuke: that seems to be what most people do - but... doesnt really come out of lambda calculus per se...
16:09:21 <bartavelle> lenec, foldl' raiseSalary employee1 [50,150,30] -- see, it scales even better than "OOP", seriously this argument doesn't make much sense
16:09:37 <ertes> @undef
16:09:37 <lambdabot> Undefined.
16:09:40 <ertes> @let data Employee a = Employee { _name :: String, _salary :: a }  deriving (Eq, Foldable, Functor, Ord, Show, Traversable)
16:09:41 <lambdabot>  .L.hs:145:1: error:
16:09:41 <lambdabot>      ‚Ä¢ The default type ‚Äò()‚Äô is not an instance of ‚ÄòNum‚Äô
16:09:41 <lambdabot>      ‚Ä¢ When checking the types in a default declaration
16:09:44 <dmwit> lenec: Here is an analogue of your complaint for OOP. Hopefully you can see why I find it an unconvincing reason to avoid OOP: "Currently it looks if you have a different collection of employees who should each get a raise, you have to write different procedures for each collection. Like you have to write raiseBob() { bob.raise(); } and raiseBobAndAlan() { bob.raise(); alan.raise(); }. That doesn't seem like it scales."
16:09:56 <Welkin> for me, the minimum is: immutable data, referential transparency, strong static typing
16:09:56 <ertes> am i stupid?
16:10:04 <geekosaur> uhhh
16:10:05 <dmwit> lenec: While for an example it might be useful to name these two procedures, in any real application you would never do that.
16:10:11 <Welkin> you could easily add: all functions are curried
16:10:14 <geekosaur> somehow ExtendedDefaultRules got turned off?
16:10:37 <Tuplanolla> Why would ertes need such a thing there, geekosaur?
16:10:46 <lenec> so basically the article was misguiding?
16:10:49 <geekosaur> or only partially turned off. I have to guess this is someone tweaking Pristine.hs
16:10:52 <ertes> @let data V2 a = V2 !a !a  deriving (Foldable, Functor)
16:10:54 <lambdabot>  .L.hs:145:1: error:
16:10:54 <lambdabot>      ‚Ä¢ The default type ‚Äò()‚Äô is not an instance of ‚ÄòNum‚Äô
16:10:54 <lambdabot>      ‚Ä¢ When checking the types in a default declaration
16:10:57 <centril> Welkin: those are nice things to have, but... it's by no means "FP"... especially the last one about static typing
16:11:02 <ertes> yeah, something is wrong with lambdabot
16:11:16 <ertes> int-e: ^
16:11:21 <dmwit> lenec: I don't know. I didn't read it carefully. But I certainly think you took the wrong lesson from it.
16:11:37 <Welkin> centril: forgot first-class functions
16:11:39 <Chousuke> data goes in, transformed data comes out. easier with static typing and immutable data, but not impossible without :P
16:11:51 <Welkin> all the best fp languages are typed
16:11:58 <centril> Welkin: well, without that one, it's not FP
16:12:11 <geekosaur> or someone in /msg doing their own thing and not paying attention to the fact that L.hs global across all lambdabot "sessions"
16:12:18 <ertes> lenec: there is a misconception that FP is about not coupling data with functions‚Ä¶  while that is part of it, it's a small and rather uninteresting part
16:12:27 <ertes> lenec: the idea is to use functions to abstract
16:12:29 <lenec> the solution in the article was... I need to raise the salary of employees, so I'm going to make a new function called happieremployees... if I would repeat that I would end up with "weird" function names
16:12:33 <ertes> lenec: and abstract over functions
16:12:54 <Chousuke> lenec: you wouldn't make new functions, though.
16:13:04 <Chousuke> or rather, you would, but you wouldn't name them
16:13:07 <dmwit> lenec: I don't believe whatever was called `happieremployees` was a function.
16:13:10 <centril> Welkin: minimum: first-class functions  - you don't have to have ref transparency locally... just in your exports, or all hell will break loose
16:13:25 <centril> lenec: start here instead... http://learnyouahaskell.com/chapters
16:13:39 <Welkin> centril: the only language that is referentially transparent is haskell and other haskell-like languages
16:13:49 <lenec> dmwit everything in functional programming is a function right? :S
16:13:54 <Welkin> lenec: no
16:13:59 <Welkin> lenec: functions and values
16:14:01 <dmwit> lenec: No. Definitely not.
16:14:12 <ertes> lenec: every function is a value, but not every value is a function
16:14:17 <Rembane> And type classes, and data types and ...
16:14:22 <centril> Welkin: unsafePerformIO (blowUpHouse) :: ()  <-- pretend like nothing is wrong
16:14:25 <lenec> ohw than I'm fundamentally not understanding the subject
16:14:32 <lenec> then*
16:14:51 <Welkin> centril: it's called `unsafe` for a reason
16:15:07 <Welkin> that is not the default
16:15:12 <ertes> lenec: example: haskell has a functional exception mechanism‚Ä¶  'catch' is not a language construct, but a regular function‚Ä¶  now you can create your own abstraction for safely dealing with creating and cleaning up resources (e.g. file handles)
16:15:16 <centril> Welkin: yes, but it is a counterexample to the conjecture that haskell is referentially transparent
16:15:22 <Welkin> centril: but it is
16:15:30 <centril> Welkin: haskell is mostly ref transparent... but FFI makes it not so
16:15:30 <lenec> although that doesn't matter for the point I was trying to make... function or not... the article's solution was come up with a new name to raise the salary
16:15:47 <ertes> lenec: 'bracket' is a function that takes a resource creation action, a resource cleanup function and a resource user function
16:15:52 <lenec> btw the solution you guys gave me makes a lot more sense to me than the one in the article
16:15:59 <Welkin> centril: one exception that is not the defauolt way of using the language doesn't mean it is not
16:16:16 <ertes> lenec: then based on that you can write something like 'withFile' that takes a file path, opening mode and a user function for the handle‚Ä¶  and it will guarantee that the handle is cleaned up timely
16:16:18 <dmwit> Welkin: ...yes it does
16:16:24 <ertes> :t withFile
16:16:26 <lambdabot> error:
16:16:26 <lambdabot>     ‚Ä¢ Variable not in scope: withFile
16:16:26 <lambdabot>     ‚Ä¢ Perhaps you meant one of these:
16:16:31 <ertes> :t System.IO.withFile
16:16:33 <lambdabot> FilePath -> GHC.IO.IOMode.IOMode -> (GHC.IO.Handle.Types.Handle -> IO r) -> IO r
16:16:56 <ertes> lenec: this is a good albeit basic example of FP
16:16:56 <Welkin> so haskell is not referentially transparent, and javascript is not referentially transparent by your logic
16:17:05 <dmwit> correct
16:17:06 <Welkin> so haskell is the same as javascript in that regard, right? But that is totally wrong
16:17:06 <centril> Welkin: it does... if I for example claim to have a language that is consistent as a logic, and I can, in one tiny place prove that bottom is inhabited... then my whole language is not consistent as a logic
16:17:13 <dmwit> no
16:17:39 <dmwit> "Haskell is the same as Javascript in regards to referential transparency" does not follow from "Haskell is not referentially transparent" and "Javascript is not referentially transparent".
16:17:44 <Welkin> centril: but we are not writing a proof about it here
16:17:48 <centril> dmwit: indeed
16:17:50 <Welkin> we are talking about how to categorize
16:18:09 <centril> Welkin: haskell is __mostly__ referentially transparent ... at least good haskell
16:18:11 <Welkin> no need to be pedantic
16:18:30 <centril> Welkin: you call it pedantic, I call it being clear and exact ;)
16:18:40 <Welkin> language is not clear and exact though
16:18:45 <ertes> what does "referentially transparent" or "pure" mean?  to me it means that you can use equational reasoning safely
16:18:45 <Welkin> language is not math or logic
16:19:28 <ertes> in haskell equations exist and the basic laws of equations are supposed to hold‚Ä¶  if they don't hold for your library, i would consider that a bug
16:19:42 <centril> Welkin: https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence
16:19:44 <ertes> (and they can only fail to hold, if you use certain functions that are clearly marked as "unsafe")
16:20:09 <centril> still, there is:  https://pdfs.semanticscholar.org/a316/3d9097a87a713f0dd3f154f139e19dcb2a82.pdf
16:20:20 <centril> (Fast and Loose Reasoning is Morally Correct)
16:20:24 <ertes> in JS equations don't really exist, and it's very difficult to come up with such a notion that satisfies the basic equation laws
16:21:07 <centril> ertes: well... unless you prove bottom by recursion and whatnot... and without using anything marked as "unsafe"
16:21:23 <ertes> centril: no, haskell is still not a consistent logic
16:21:32 <centril> ertes: i know =)
16:21:34 <ertes> but it has equations, and you can use equational reasoning
16:22:00 <ertes> stuff like transitivity hold
16:22:00 <centril> ertes: I buy this argument, sorta...
16:22:25 <centril> ertes: I'd say: for all intents and purposes, haskell is ref transparent
16:22:33 <Welkin> lol
16:22:36 <Welkin> you changed your mind
16:22:39 <ertes> that doesn't really mean anything ;)
16:22:42 <Welkin> being absolutionist is not helpful here
16:22:47 <Welkin> this is not a math or logic debate
16:22:53 <centril> Welkin: no - I qualified my statement ;)
16:22:57 <Welkin> it's a casual discussion about how to categorize things
16:23:04 <centril> Welkin: ok, then I agree
16:23:47 <ertes> BTW, being a consistent logic comes at a high price‚Ä¶  not sure if i'd be willing to pay it‚Ä¶  for the purpose of practical software development i believe it should be optional
16:23:56 <Welkin> at least from a programmers perspective, it makes no difference
16:24:08 <Welkin> they just want some guarantees so they can do their work easier
16:24:37 <ertes> if you want to know what i'm talking about try to write haskell's 'forever' function in agda
16:24:39 <centril> ertes: well, you can modularize your language like Rust does with the  unsafe { .. } stuff
16:24:56 <centril> ertes: Agda is not a general purpose programming langauge
16:25:11 <centril> ertes: being able to be consistent as a logic in some parts, and not in others would be useful
16:25:29 <ertes> centril: it's not?  why not?
16:26:14 <centril> ertes: it's not used that way... noone runs agda programs, you type check them, and that's it
16:26:31 <ertes> that's not really relevant, is it?
16:26:36 <dolio> People have written web applications in Agda, I think.
16:26:54 <centril> dolio: poor souls :P
16:27:03 <ertes> yeah, there was a really basic web framework for agda‚Ä¶  it's called lemmachine
16:27:24 <centril> well, you can make even agda not consistent as a logic
16:27:38 <ertes> and there is even an FRP framework using linear temporal logic
16:27:40 <dmwit> That is a great name, but nothing about it screams "web framework" to me. =P
16:27:55 <ertes> yeah =)
16:28:06 <centril> a great name indeed
16:28:20 <centril> damn... i need to quit this discussion... im supposed to write a bachelor theis n stuff
16:28:26 <centril> taking up too much time :P
16:28:27 <ertes> dmwit: well, does "scotty" or indeed "spock"? ;)
16:29:06 <ertes> those remind me more of terrible technobabble and a certain womanizer =)
16:29:10 <dmwit> ertes: agreed, they don't either =)
16:29:25 <Welkin> lol
16:29:32 <Welkin> scotty = sinatra + warp
16:29:34 <Welkin> :P
16:29:44 <Welkin> and spock continues the star trek theme
16:30:04 <erisco> is there a documentation page to explain all these jokes?
16:30:17 <Welkin> in the scotty docs
16:30:18 <dmwit> Was Scotty a singer? I can't think of many Star Trek singers. The EMH, maybe.
16:30:22 <Welkin> it literally says that
16:30:33 <ertes> erisco: you're not a trekkie i take it
16:30:54 <erisco> not to the extent that I could string that relation together
16:32:44 <lenec> I think I understand FP a tiny little bit better now, thanks :)
16:32:58 <Welkin> lenec: have you read Richard Bird's sudoku solver?
16:33:18 <Welkin> it shows the concept of function pipeline and piece-meal programming
16:33:23 <ertes> since i haven't watched the original series i wouldn't really know most of those names either, if it weren't for a hilarious DS9 episode about tribbles =)
16:33:46 <Welkin> scotty and spock are main characters o.o
16:34:10 <Welkin> "beam me up, scotty!"
16:34:22 <erisco> in my nightmares I open a hatch and am buried by thousands of dead tribbles
16:34:31 <Welkin> wtf is a tribble
16:34:34 <lenec> Welkin thanks for the tip... I'll go read that now :)
16:34:36 <ertes> lenec: unfortunately noone can be told what FP is‚Ä¶  you have to‚Ä¶  you know‚Ä¶  learn haskell =)
16:34:37 <int-e> @let data V2 a = V2 !a !a  deriving (Foldable, Functor)
16:34:38 <lambdabot>  Defined.
16:34:54 <ertes> int-e: thanks
16:34:55 <int-e> some ghc 8.0.2 change...
16:35:31 <ertes> BTW, is TH enabled?
16:35:39 <int-e> no, of course not
16:35:56 <ertes> i thought so =)
16:36:04 <dmwit> lenec: Simon Peyton-Jones' paper on designing a DSL for financial contracts changed my life.
16:36:11 <ertes> @let data Employee a = Employee { _name :: String, _salary :: a }  deriving (Eq, Foldable, Functor, Ord, Show, Traversable)
16:36:13 <lambdabot>  Defined.
16:36:14 <dmwit> lenec: It's very approachable for a non-Haskeller.
16:36:35 <int-e> (TH allows arbitrary IO)
16:36:49 <ertes> > map (traverse +~ 10000) [Employee "alice" 5000, Employee "bob" 400]
16:36:51 <lambdabot>  [Employee {_name = "alice", _salary = 15000},Employee {_name = "bob", _salar...
16:36:52 <int-e> (at compile time)
16:38:04 <ertes> lenec: ^ that's an example of quite a few haskell/FP concepts coming together in order to get a nice abstraction for deep data access (lenses and traversals)
16:38:21 <erisco> oh, lens, what a simple topic to start with
16:38:26 <Welkin> lol
16:38:31 <Welkin> I still haven't really used lens
16:38:48 <dmwit> lenec: https://www.microsoft.com/en-us/research/publication/composing-contracts-an-adventure-in-financial-engineering/ in case you have trouble finding it from my keywords =P
16:39:23 <lenec> I was tempted to switch to Scala, but I like the syntax of Haskell more and now I met this community I'm sure I'll stick with Haskell. You guys seem like a very welcoming community :)
16:39:37 <ertes> lenec: and no, i don't expect you to understand this code right now‚Ä¶  it's just a small demo for the potential =)
16:39:38 <Welkin> lenec: I tried scala once, and it was painful
16:39:51 <Welkin> lenec: scala is nothing like haskell at all; it is java with a few nice features
16:47:51 <ogkloo> I feel like, for me at least, I'm bad at Scala because I'm bad at Java
16:49:46 <centril> lenec: if you are looking for something "in-between" OOP and FP, there is always Rust. Rust is a systems programming language with a lot of borrowed stuff from haskell: https://www.rust-lang.org/en-US/
16:50:17 <Tuplanolla> He's gone, centril.
16:50:26 <centril> Tuplanolla: i noticed
16:50:32 <centril> :(
16:50:53 <centril> but the comment applies to everyone tho
16:50:56 <centril> rust is nice
16:51:20 <Tuplanolla> Maybe one day I can get over the horrible syntax.
16:51:39 <centril> Tuplanolla: yes, the syntax could be more haskell-like
16:51:46 <centril> but it's too late for that methinks
16:51:56 <parsnip> if you have json with varying number of fields, what is best approach in haskell? 
16:54:04 <brynedwards> lens-aeson? Depends on what else you're doing
16:55:49 <Welkin> parsnip: you can parse it however you want in your FromJSON instance
16:55:57 <Welkin> wrap the optional field in Maybe
16:56:35 <parsnip> so still use record type and aeson? 
16:56:36 <centril> Tuplanolla: for example: specifying signatures separate from argument names like in haskell would be nice
16:56:43 <Welkin> parsnip: of course
16:56:51 <parsnip> thank you
17:02:26 <dolio> centril: Oh, they made all signatures in line?
17:02:36 <dolio> That's like the most persistent annoyance in Scala, I think.
17:02:51 <Welkin> it's like the same crap they did with swift
17:03:03 <Welkin> to make it more mainstream and generic of a language
17:03:34 <centril> dolio: http://rustbyexample.com/fn.html
17:03:53 <Welkin> languages made to appeal to everyone never do
17:04:08 <Welkin> because it actually appeals to no one at all
17:04:22 <centril> well, at least the return type is to the right and not like C, C++, Java
17:04:31 <Welkin> one reason I think elm (as a language) is a failure
17:04:41 <centril> where it is to the left
17:04:57 <centril> Welkin: is because purescript is better?
17:05:07 <Welkin> centril: you can just use haskell
17:05:12 <Welkin> no need for purescript
17:05:51 <centril> also, functions in rust are not autocurried (yet)
17:05:52 <Welkin> but yes, purescript is what elm should have been (mostly)
17:06:49 <centril> I guess the main motivation to why functions are not autocurried is because autocurrying makes the memory-behaviour of functions unclear
17:07:01 <centril> and rust is a systems programming language, so...
17:07:49 <centril> hopefully Rust gets ACTs (associated type constructors) soon, so you can have monads monads monads
17:12:02 <ertes> in such a way that you can write 'traverse' in rust?
17:12:36 <centril> ertes: I don't see why not
17:12:46 <ertes> because rust lacks higher-kinded polymorphism
17:12:50 <ertes> which makes monads pretty useless
17:13:07 <centril> ertes: it does currently, but it will be added, almost certainely
17:13:28 <Welkin> why bother though?
17:13:30 <ertes> that's also why i don't understand the hype some people seem to have with monads in C# or F#
17:13:36 <Welkin> why not just use a haskell DSL to generate C?
17:13:50 <ertes> you can have the monadic interface in most languages, but the real reason to use monads is so that you can abstract over them
17:14:04 <centril> ertes: obviously
17:14:09 <centril> ertes: see: http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/
17:14:32 <centril> and: http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/
17:14:39 <centril> and: http://smallcultfollowing.com/babysteps/blog/2016/11/04/associated-type-constructors-part-3-what-higher-kinded-types-might-look-like/
17:14:47 <centril> and: http://smallcultfollowing.com/babysteps/blog/2016/11/09/associated-type-constructors-part-4-unifying-atc-and-hkt/
17:17:23 <centril> iirc, HKTs are the reason you can't do   instance Monad ((Flip Either) a) where ...
17:18:53 <centril> Welkin: do you think you will get as good performance with a haskell DSL => C as with C directly ?
17:19:16 <centril> or are you basically encoding C in haskell ?
17:19:24 <ertes> that looks like a sepcial case of HKT
17:19:29 <Welkin> you output C code
17:19:32 <ertes> why not just implement HKT and be done with it?
17:19:42 <Welkin> there are several libraries for this in haskell already
17:19:45 <Welkin> mostly for embedded c
17:20:21 <Welkin> centril: you "compile" to c, so there is no haskell at runtime, obviously
17:20:44 <ertes> it seems to me like most languages go out of their way to keep HKT out of their language‚Ä¶  that's stupid
17:21:53 <centril> ertes: because: http://cstheory.stackexchange.com/questions/32260/decidability-of-parametric-higher-order-type-unification
17:22:13 <centril> (iirc)
17:22:15 <c_wraith> that's only an issue if you have arbitrary type functions
17:22:28 <centril> ertes: the posts explain their reasoning better than I can
17:22:37 <c_wraith> if you use only generative higher-kinded type constructors, the way base haskell does, that doesn't apply.
17:23:21 <c_wraith> Type families do lead to undecidable systems, which is why they are never considered the canonical type of something
17:24:03 <centril> c_wraith: generative HK TC being ?
17:24:34 <c_wraith> centril: generativity is the property that if f a ~ g b then f ~ g and a ~ b
17:24:49 <centril> c_wraith: ah
17:25:04 <ertes> centril: also undecidable ‚â† unsafe‚Ä¶  you just make sure not to use the undecidable subset of the language
17:25:25 <centril> ertes: right
17:25:27 <ertes> (or just insert a loop counter into the type-checker the way GHC does)
17:25:44 <centril> ertes: depth recursion limit ?
17:28:10 <ertes> centril: not sure, if that's enough
17:28:21 <centril> c_wraith:  is that the property that   f a ~ g b  => f ~ g   ,   or f a ~ g b <=> f ~ g   ?
17:28:45 <centril> (forall a b.)
17:28:45 <ertes> anyway, the point is that i don't see any real harm in undecidable type systems‚Ä¶  undecidable ‚â† unsafe
17:28:59 <centril> ertes: i agree
17:29:16 <centril> ertes: rust uses depth recursion limit iirc
17:29:38 <ertes> it does?  for what?
17:30:31 <centril> ertes: https://sdleffler.github.io/RustTypeSystemTuringComplete/  (+ proof that rust is turing complete @ type checking)
17:31:14 <centril> "In most cases where the typechecker hits the recursion limit, something‚Äôs wrong with your program and it won‚Äôt compile no matter what. Only if you‚Äôre really mucking with the type system ‚Äì like, say, writing seriously large Smallfuck programs with it ‚Äì then maybe you‚Äôll hit the recursion limit.
17:31:34 <dolio> You're not going to add higher-order unification to your type system and then fix it with a loop counter.
17:31:36 <centril> ===> \exists recursion limit
17:32:09 <c_wraith> I mean, GHC uses a recursion limit for the same reason when you enable UndecidableInstances.
17:32:26 <centril> c_wraith: right
17:33:02 <dolio> It's not just a problem of being able to write loops, it's a problem of all kinds of choice points being added to the type checking.
17:33:15 <c_wraith> But that's not why higher-kinded types work.
17:33:57 <dolio> So if you ever make use of the 'feature', it's likely going to be by annotating a lot more things.
17:34:12 <dolio> Which actually makes the overall experience worse than doing it like Haskell.
17:34:25 <centril> dolio: right
17:35:13 <centril> dolio: an example: rust doesn't have type inference for function definitions - i.e: they can't be elided since the type checking is much more local in rust (iirc)
17:36:25 <centril> anyways... it's an open discussion... nothing has been decided on which way to go (HKTs or ACTs)
17:38:46 <Tuplanolla> Every time I think about language design, I end up feeling that a consistently bad solution is better than an inconsistent but practical compromise.
17:39:08 <Tuplanolla> Is this a common obsession?
17:39:38 <centril> Tuplanolla: consistently bad solution = golang ?
17:40:01 <Tuplanolla> Not that bad.
17:40:14 <centril> Tuplanolla: :P
17:40:48 <Tuplanolla> Rather why have a type system at all if it can't be perfect.
17:40:53 <centril> Tuplanolla: had to pause for a second to parse the statement: "does she/he mean that golang isnt that bad, or that the solution shouldn't be as bad as golang"
17:41:28 <centril> now im unsure which one was intended
17:42:20 <Tuplanolla> I shall leave it that way since it's an unimportant tangent.
17:42:21 <ertes> i've found a nice way to trace in a similar way to Debug.Trace, but with the ability to print hole-style errors (i.e. with full scope)
17:42:59 <ertes> trace :: a -> b -> b
17:43:00 <ertes> trace h x = unsafePerformIO $ do (x <$ evaluate h) `catch` \(SomeException ex) -> x <$ print ex
17:43:08 <ertes> you use it like this:  trace _ myExpr
17:43:27 <centril> Tuplanolla: i never have this feeling... I consistently think that some small inconsistencies is better at some points than to have a consistently bad solution
17:43:29 <ertes> then whenever myExpr is evaluated, it displays everything in scope and then continues
17:43:35 <ertes> (needs -fdefer-types-holes)
17:45:31 <ertes> of course the usefulness may be limited due to how verbose GHC's error messages are
17:46:02 <centril> ertes: you still have to compile with the enable trace flag right ?
17:46:14 <centril> (forgot its name)
17:46:36 <ertes> centril: you need -fdefer-typed-holes
17:46:40 <ertes> nothing else should be needed
17:47:00 <centril> ertes: interesting!
17:47:04 <dolio> _ compiles to an exception that will show all the information it would print if you call `print` on it?
17:47:12 <Tuplanolla> That's pretty funny, ertes.
17:49:05 <Tuplanolla> Is the scope listing limited to five or however many items it is?
17:50:57 <ertes> Tuplanolla: indeed
17:51:01 <ertes> "(Some bindings suppressed; use -fmax-relevant-binds=N or -fno-max-relevant-binds)"
17:51:24 <ertes> well, also it only shows the types
17:51:45 <ertes> i don't see a way to show values as well without TH
17:51:50 <centril> ertes: this was useful, thanks
17:52:16 <ertes> centril: probably not that useful, but it can help to print hole errors and still continue
17:52:33 <centril> =)
17:52:35 <ertes> normally holes are fatal in pure code
17:52:48 <centril> well, interesting at least
17:54:22 <ertes> i should have called it 'unholy'
17:55:53 <centril> ertes: now you just need to combine it with a function called "union"
17:56:03 <centril> ertes: unholy . union
17:56:32 <Tuplanolla> Tracing a hole is generally known as spelunking, ertes.
18:00:32 <Tuplanolla> This function deserves to exist for the sake of this pun alone.
18:00:54 <ertes> printing a hole is generally known as burning
18:03:45 <ertes> CMYKP
18:04:15 <ertes> cyan, magenta, yellow, key, power
18:05:24 <ertes> (yes, i had to look up what the K stands for)
18:05:34 <MarcelineVQ> you need all those to beat castle adventure
18:06:15 <ertes> that's why i prefer doom‚Ä¶  you only need RGB
18:06:58 <cloudhead> what do people use for fast xml parsing these days?
18:07:12 <ertes> cloudhead: i use xml-conduit
18:07:12 <veeberz> Hello everybody. Can anyone recommend a haskell web framework for someone who wants to use haskell on the web just for kicks?
18:08:20 <ertes> veeberz: if 10 people answer your question, you will get 10 different recommendations
18:08:31 <Tuplanolla> How big kicks are we talking about here, veeberz?
18:09:10 <ertes> veeberz: servant may be the most kick-giving one right now (it does some fancy type-level things)
18:09:36 <cloudhead> ertes: thanks, hadn't seen that one
18:10:19 <ertes> cloudhead: depending on the application i might also use tagsoup
18:10:45 <ertes> but i don't know how fast that one is‚Ä¶  hasn't been a bottleneck for me so far
18:10:56 <centril> how do we quantify for-kickishness?
18:11:49 <cloudhead> ertes: yeah I have a 30gb file to parse, actually mainly need it to be event based because I can't hold it in memory
18:12:19 <centril> that's a big xml file o.O
18:12:28 <cloudhead> yeah it's a data dump heh
18:13:10 <centril> cloudhead: does it have to be XML? some other format might be terser and more efficient?
18:13:22 <cloudhead> I have no choice in the matter centril :/
18:13:29 <centril> :(
18:13:40 <cloudhead> unless I convert it with another tool to json or something
18:14:12 <cloudhead> but yeah, that probably won't help much
18:14:28 <cloudhead> hmm there's hexpat also
18:14:56 <michalrus> Hey, is there some code available to use in your tests that checks various laws of your custom Monads, Functors etc.?
18:15:01 <greymalkin> Is there any elegant way to deal with marshalling data from one Lazy ByteStrings to strict ones? I'm connecting Yesod and GraphViz -- Yesod likes strict, and GraphViz likes lazy, and I'm getting tired of writing "fromStrict" all over the place.
18:15:26 <centril> cloudhead: why not MessagePack ?
18:15:48 <centril> cloudhead: https://en.wikipedia.org/wiki/Comparison_of_data_serialization_formats
18:15:58 <ertes> cloudhead: xml-conduit has a streaming version (hence the name), but i haven't used it myself
18:15:59 <MarcelineVQ> michalrus: http://hackage.haskell.org/package/checkers is one
18:16:00 <cloudhead> centril: sure, but in any case I'll have to traverse the xml, so I may aswell just use it directly
18:16:06 <sophiag> hi. i'm trying to install pcre-light and getting an error message that pkg-config can't be found. i'm confused about what's going on here
18:16:07 <michalrus> MarcelineVQ: thank you! :)
18:16:11 <centril> cloudhead: right =)
18:16:28 <ertes> cloudhead: even streamed it may take long, so if you find a way to export the data in another format, do so
18:16:49 <ertes> i maintain that XML is neither machine- nor human-readable
18:17:02 <centril> ertes: yup
18:17:12 <centril> that about sums it up
18:18:06 <cloudhead> ertes: haha yes, indeed
18:18:24 <centril> for human readable TOML is nice
18:18:40 <ertes> cloudhead: if your data is inherently tabular, consider using CSV
18:18:51 <cloudhead> csv is great
18:18:54 <centril> BSON / MessagePack for machine dependending on if you need to send it over network or not
18:18:56 <cloudhead> wish it was in csv 
18:19:02 <ertes> it's about the fastest to parse format i can think of that has ready-made parsers in haskell
18:19:43 <centril> ertes: one is seldom so fortunate to have CSVs:able data
18:20:30 <ertes> cloudhead: if the XML is sufficiently uniform, you can write a small pseudo-XML converter without actually parsing XML
18:20:52 <ertes> if not, i'd go with JSON
18:20:59 <ertes> (or BSON i guess)
18:21:19 <cloudhead> ertes: ah you mean to just write a custom parser
18:23:08 <ertes> cloudhead: it's not the best idea in the world, but if this is a one-off job and the XML is very uniform, it may reduce parsing time by a significant factor
18:23:26 <cloudhead> yeah it's a clever idea
18:23:40 <cloudhead> since the xml is machine generated, it could work
18:23:52 <ertes> yeah‚Ä¶  "clever"‚Ä¶  in the bad sense‚Ä¶  usually i would scream at people for doing that =)
18:24:05 <cloudhead> but I'll try with an xml lib first since I don't want to go down that rabbit hole yet
18:24:08 <cloudhead> hehe
18:24:09 <cloudhead> s
18:24:11 <cloudhead> ye
18:28:22 <lpaste_> df pasted ‚Äúf‚Äù at http://lpaste.net/8260766833850712064
18:28:30 <lpaste_> df pasted ‚Äúf‚Äù at http://lpaste.net/4458148067241099264
18:28:37 <lpaste_> df pasted ‚Äúf‚Äù at http://lpaste.net/353697
18:33:41 <orion> Is (IO a) defined as a data type or a function?
18:35:15 <kadoban> IO a is a type. Value of that type are not functions
18:35:45 <Maxdamantus> Depending on the context, `IO` might be considered to be a function instead of a type.
18:35:55 <Maxdamantus> but `IO a` would be a type.
18:36:09 <glguy> IO is also a type
18:36:26 <orion> "That said, if you look at GHC's source code, you'll find that it represents IO a as a function looking like State# RealWorld -> (# State# RealWorld, a #)" http://stackoverflow.com/questions/9244538/what-are-the-definitions-for-and-return-for-the-io-monad
18:36:28 <Maxdamantus> Yeah, under some fuzzy use of the term "type" (which iirc the Haskell report does use)
18:36:56 <glguy> certainly not fuzzy, also yes it's the terminology haskell uses
18:37:23 <glguy> orion is asking about implementation details of IO
18:37:28 <Maxdamantus> Well, technically I think it makes sense to refer to things of kind * as "types".
18:37:42 <Maxdamantus> ie, things that values have the type of.
18:37:47 <glguy> sure, those are types too
18:37:49 <mbw> Hello everyone. Is there actually any *introductory* material about web-client programming with Haskell to be found anywhere? And I really do mean introductory, since: 1. I have no experience in languages like PHP, JS (I am stupid and need types!) or other languages used for these kind of tasks, 2. I have NO formal background in Computer Science. Most tutorials I have found seem to assume some experience. I 
18:37:51 <Maxdamantus> There is no value or even expression that has the type "IO"
18:37:55 <mbw> only want to be able (for example) to pull a website and extract all links to images, at least on that level for starters, while STILL being able to reason about what all that GET/POST stuff, XML/JSON, yada yada is all about. For now I am afraid I'll have to settle with something like "Web-Client Programming with Perl" and translate the examples...
18:38:05 <Maxdamantus> :t let x :: IO in x
18:38:06 <lambdabot> error:
18:38:06 <lambdabot>     The type signature for ‚Äòx‚Äô lacks an accompanying binding
18:38:15 <glguy> right, it's types with kind * that have values
18:38:21 <Maxdamantus> eh, let's try that again.
18:38:25 <Maxdamantus> > let x :: IO in x
18:38:27 <lambdabot>  error:
18:38:28 <lambdabot>      The type signature for ‚Äòx‚Äô lacks an accompanying binding
18:38:34 <Maxdamantus> Damn. They changed the error.
18:38:49 <Maxdamantus> That used to say "expected a type, but `IO` has kind * -> *"
18:39:26 <geekosaur> not sure that isn't the same issue as earlier; something's gone odd
18:39:49 <geekosaur> like, maybe that error is actually because we lost ScopedTypeVariables extension and therefore pattern bindings
18:39:55 <glguy> the distinction is about levels, values, types, kind s
18:40:37 <glguy> we don't claim that function values are not values
18:40:58 <Maxdamantus> Oh, oops, I'm silly.
18:41:01 <Maxdamantus> > let x = x :: IO in x
18:41:04 <lambdabot>  error:
18:41:04 <lambdabot>      ‚Ä¢ Expecting one more argument to ‚ÄòIO‚Äô
18:41:04 <lambdabot>        Expected a type, but ‚ÄòIO‚Äô has kind ‚Äò* -> *‚Äô
18:41:21 <Maxdamantus> The error is the same. GHC calls * a type.
18:41:35 <Maxdamantus> rather, it calls the type-level things that have kind * "types".
18:41:51 <glguy> well have to create a ticket to fix it
18:42:15 <Maxdamantus> tbh I'd rather fix the terminology in the Haskell report :(
18:42:27 <glguy> thanks for being honest
18:42:47 <geekosaur> keep in mind the Report was not written with type level hackery in mind
18:43:48 <geekosaur> although that argument leads to "in a more advanced world, more precision in terminology is needed"
18:44:07 <Maxdamantus> Well, if you read any papers about kind theory, I suspect they would try to avoid calling things with kind `* -> *` "types".
18:44:21 <Maxdamantus> and would instead try to reserve that word for things of kind `*`
18:44:23 <glguy> i wouldn't suspect that
18:44:49 <geekosaur> maybe early ones, for the same reason: nobody had had reason to work out the terminology yet
18:45:58 <Maxdamantus> * -> * is just a function
18:46:04 <glguy> again this is like arguing that functions aren't values, it doesn't make sense in a world like Haskell where there are so many interesting first class things
18:46:13 <Maxdamantus> Particularly, one that works at a type level (if there is such a distinction)
18:46:24 <geekosaur> "type function", yes
18:46:32 <geekosaur> ghc even uses that terminology in a few places
18:46:49 <glguy> no, * -> * is a kind, it's not a function, you can't apply it to anything
18:46:49 <geekosaur> ...and it's not surprising that parts of ghc still use 1998 type theory terminology
18:47:01 <Maxdamantus> glguy: I meant things of kind * -> *
18:47:14 <Maxdamantus> `* -> *` itself is a kind, yes.
18:47:30 <Maxdamantus> in the same way that `putStrLn "foo"` is not `IO ()`
18:47:32 <centril> glguy: sure you can... just not at the value level...
18:47:56 <centril> or well... something with kind * -> * can be applied
18:48:08 <glguy> centril, right
18:48:51 <glguy> next you'll tell me that with DataKinds enabled that 'Nothing isn't a type ,
18:49:03 <glguy> but it's a type with kind 'Maybe a
18:49:17 <ubsan_> not... really?
18:49:31 <glguy> yup, really
18:49:49 <glguy> err kind Maybe a, no '
18:49:52 <Maxdamantus> Idris> :t IO
18:49:52 <Maxdamantus> IO : Type -> Type
18:50:15 <Maxdamantus> and yes, if you had a type constructor that took a `Maybe a`, it would have `Maybe a` somewhere instead of `Type`
18:50:32 <ubsan_> glguy: Nothing doesn't follow the definition of Type
18:50:43 <glguy> don't forget that "type constructor" has nothing to do with kind
18:50:50 <ubsan_> it's not a category of things
18:50:54 <glguy> it's a category of names
18:51:10 <ubsan_> it's a value of the type Maybe a
18:51:26 <ubsan_> DataKinds just allows you to write type constructors which depend on values
18:51:28 <glguy> ubsan_: no, this is about data kinds
18:51:31 <geekosaur> wake me up if y'all ever settle on a common language :p
18:51:38 <ubsan_> it doesn't make the values into types
18:52:01 <glguy> no, it lifts the data type definition into the type level
18:52:14 <glguy> not the values themselves
18:52:21 <Maxdamantus> glguy: er .. if you're in favour of the Haskell report terminology it kind of does.
18:52:32 <Maxdamantus> From the report: > The symbol * represents the kind of all nullary type constructors.
18:52:50 <ertes> jophish: about vulkan: is it usable though?  if yes, i would contribute a small patch to fix the version bounds, if you don't have time to do it yourself
18:52:51 <nshepperd> well this is horribly confusing
18:52:54 <glguy> no the haskell report is quite clear that type constructor is a name category
18:53:08 <glguy> constructors and variables
18:53:22 <ertes> jophish: i'd like to experiment with the vulkan API
18:53:26 <Maxdamantus> glguy: "a name category"? You mean it refers to `Boolean` but not `Maybe Int`?
18:53:47 <ubsan_> glguy: what are the terms of type Nothing
18:53:54 <glguy> Maxdamantus: Yes, Int, and Maybe are type constructors
18:54:03 <Maxdamantus> glguy: what about `Maybe int`?
18:54:07 <Maxdamantus> er, `Maybe Int`*
18:54:10 <glguy> Maxdamantus: That's a type with kind *
18:54:20 <ubsan_> `*` == `type`
18:54:23 <ertes> jophish: i'm particularly interested in the compute part right now, although i'd also like to try vulkan graphics at some point
18:54:25 <Maxdamantus> glguy: but * is the kind of nullary type constructors.
18:54:36 <glguy> Yes and other things too
18:54:37 <ubsan_> it's just that haskell has weird syntax
18:54:51 <Maxdamantus> glguy: (according to the statement I quoted from the report)
18:55:12 <glguy> There are six kinds of names in Haskell: those for variables and constructors denote values; those for type
18:55:13 <glguy> variables, type constructors, and type classes refer to entities related to the type system; and module names
18:55:13 <glguy> refer to modules
18:55:16 <centril> ubsan_: i find  * -> * more terse than Type -> Type  
18:55:23 <ubsan_> centril: terse != better
18:55:34 <centril> in this case it is imo
18:55:43 <ubsan_> I also find non-purity more terse than purity ;0
18:55:46 <ubsan_> *;)
18:55:54 <ertes> centril: you know, i'm glad that Maybe is called Maybe and not "?"
18:56:04 <centril> ertes: haha :D
18:56:09 <ertes> although i wouldn't mind Either being called "+"
18:56:18 <ubsan_> centril: I'd like to point out, type theoretists like me *hate* that notation
18:56:25 <ubsan_> haskell infects people
18:56:29 <ubsan_> and gives them terrible syntax
18:56:38 <ubsan_> like `::`
18:56:52 <ubsan_> and `*`
18:57:03 <ertes> ubsan_: terse lists are more important than terse type annotations, i guess
18:57:17 <centril> ertes: nah, they're not
18:57:32 <ertes> and of course you should use recursive functions for lists everywhere
18:57:33 <centril> how often do you write type annotations and how often do you cons lists?
18:57:38 <ertes> foldr is evil
18:57:41 <nshepperd> f (a::b::c::xs) = ...  -- nah...
18:57:58 <ertes> centril: i'm being sarcastic
18:58:05 <centril> ertes: oh
18:58:11 <centril> ertes: sarcasm in text is hopeless
18:58:38 <ertes> nshepperd: f (a :: b :: c :: xs) = ‚Ä¶
18:58:40 <ertes> not that bad
18:58:50 <centril> ubsan_: im keeping * -> * tho, even tho it bugs you ^^
18:59:04 <ubsan_> centril: well, not like we can change haskell now
18:59:17 <centril> ubsan_: except that Type :: *
18:59:18 <ubsan_> centril: I'd love to replace it with idris though ;)
18:59:25 <ubsan_> centril: hmm?
18:59:41 <centril> ubsan_: GHC 8 added TypeInType
18:59:47 <ertes> when the kind system was designed, there used to be only one kind for concrete types‚Ä¶  why they chose to call it "*" instead of "T"?  beats me
18:59:49 <nshepperd> you can say Type in haskell now
18:59:51 <ertes> "*" is the worst choice
19:00:10 <centril> ertes: it looks pretty
19:00:16 <ertes> it looks horrible
19:00:21 <centril> giving a fuzzy feeling
19:00:29 <centril> ertes: who doesnt like starts?
19:00:31 <nshepperd> it's inconvenient because with typelits we want to use * for multiplication too...
19:00:40 <tswett_to_go> I dunno, the worst choice might have been a surrogate code point or something.
19:00:44 <ertes> i do like stars‚Ä¶  for products
19:00:55 <ubsan_> centril: so * :: *?
19:01:01 <centril> ubsan_: yes
19:01:11 <Maxdamantus> Is a surrogate codepoint a normal codepoint that requires a surrogate pair when represented in UTF-16?
19:01:21 <ubsan_> centril: are there implicit universes?
19:01:22 <tswett_to_go> Maxdamantus: no, it's one of the two things that makes up a surrogate pair.
19:01:30 <Maxdamantus> tswett_to_go: oh, those are code units.
19:02:03 <ubsan_> I'm not sure exactly how to say that
19:02:07 <Maxdamantus> Sorry, more technical terminology.
19:02:09 <nshepperd> it's illegal in utf-8
19:02:16 <centril> ubsan_: https://ghc.haskell.org/trac/ghc/wiki/DependentHaskell/Phase1
19:02:18 <ubsan_> gah there's a word I'm looking for
19:02:29 <ubsan_> implicit universe ordering
19:02:43 <nshepperd> Maxdamantus: isn't a code unit the representation in bits?
19:02:43 <ertes> ubsan_: cumulative?
19:02:51 <tswett_to_go> Yeah, officially, a surrogate code point can't be represented in any encoding.
19:02:52 <Maxdamantus> Right, the values that are used as the code units in UTF-16 surrogate pairs are not valid codepoints.
19:02:58 <ertes> ubsan_: idris does that
19:02:58 <centril> ertes: i thought that's what idris has
19:03:02 <Maxdamantus> (just because unicode has reserved those numbers)
19:03:07 <ertes> yes
19:03:14 <ertes> haskell doesn't do it though
19:03:18 <nshepperd> so it's a fake codepoint basically
19:03:19 <ertes> "TypeInType" is meant literally
19:03:28 <ertes> so indeed:  Type :: Type
19:03:32 <Maxdamantus> nshepperd: a code unit is the unit used in the encoding. eg, in UTF-8 the code units are the octets that make up the UTF-8 string.
19:03:43 <ubsan_> ertes: whether it's cumulative or not doesn't really matter, you just need some way to represent ordering so that `Type :: Type` is not literally true
19:03:44 <Maxdamantus> nshepperd: in UTF-16 they're the 16-bit integers that make up the UTF-16 string.
19:03:53 <ubsan_> although apparently, Haskell chooses not to do that
19:04:00 <centril> ubsan_: it's not consistent as a logic
19:04:05 <ertes> ubsan_: yeah, haskell doesn't
19:04:11 <ubsan_> centril: no it is not
19:04:22 <tswett_to_go> It's pretty obvious how surrogate code points *would* be encoded in UTF-8 and UTF-32. You just ignore the fact that you're supposed to check for them and reject them.
19:04:27 <ertes> it collapses all universes into one:  Type
19:04:36 <ubsan_> ertes: that annoys me
19:04:58 <centril> ubsan_: well, what's one more way of proving bottom when you already can do it ?
19:05:08 <ubsan_> centril: ... yeah, I guess :/
19:05:30 <centril> ubsan_: how mature is Idris?
19:05:36 <ubsan_> centril: fairly
19:05:40 <ertes> ubsan_: well, i don't see a way to add hierarchial universes to haskell easily‚Ä¶  they need quite a bit of extra type-level machinery
19:05:41 <ubsan_> nowhere near haskell levels
19:05:57 <centril> ubsan_: i guess im sticking with haskell for now then
19:06:05 <ubsan_> it needs a lot more library support, and better compilation output
19:06:19 <ubsan_> ertes: yeah, you're right
19:06:40 <centril> I guess I could not be a douche and contribute with the libs part...
19:06:40 <ertes> although if it were easy enough, there would be no real reason not to add them
19:07:05 <centril> libs aren't going to magically appear so to speak
19:07:39 <ertes> now that haskell introduced -XStrict, idris could introduce -XNonStrict
19:07:52 <centril> ertes: hah :P
19:08:04 <ertes> right now, forcing me to use Lazy everywhere, idris is not that appealing to me
19:08:15 <ubsan_> lol
19:08:17 <glguy> If you might be interested in Idris, it'd be worth joining #idris
19:08:20 <centril> ertes: I want a -XCompromise  flag too
19:08:21 <ubsan_> that's one of my favorite features of idris
19:08:30 <ubsan_> I dislike by-default lazy
19:09:20 <ubsan_> centril: I should probably do more idris, but now I'm working on my own hella-awesome language :D
19:09:22 <centril> ubsan_: how does dependent types + laziness factor into idris?
19:09:35 <ubsan_> centril: how do you mean?
19:09:47 <glguy> Idris is offtopic in #haskell, however
19:10:18 <centril> glguy: this is not strictly #idris, but rather #haskell compared to #idris
19:10:23 <tswett_to_go> Oh yeah, I've got a hella-awesome language.
19:10:59 <tswett_to_go> Unimplemented, of course. I don't, y'know, *do* stuff.
19:11:00 <ubsan_> tswett_to_go: mine is playing with dependent types + affine types in a systems language
19:11:00 <centril> ubsan_: like: apparently dependent types in haskell have been problematic to get right due to laziness (i dont know the details)
19:11:16 <centril> ubsan_: do tell... git repository ?
19:11:19 <tswett_to_go> My language is a database query language inspired by category theory.
19:11:25 <ubsan_> tswett_to_go: plus a helping of lvalue types, because that's one of my favorite things about C++
19:11:32 <tswett_to_go> Tables are objects. Foreign key columns are arrows.
19:11:46 <ubsan_> centril: the parser isn't even fully done yet lol
19:11:52 <ubsan_> mostly at this point it's design documents
19:11:58 <centril> oh
19:12:04 <ubsan_> sorry :3
19:12:20 <ubsan_> there's also a ton of crap on whiteboards
19:12:22 <ubsan_> <3 whiteboards
19:12:24 <centril> ill await it eagerly then
19:12:27 <tswett_to_go> I started implementing it in C#. Now that I've left it alone for a while, I'm thinking about whether Haskell might be a better option.
19:12:28 <ertes> ubsan_: i gave up trying to create such a language a long time ago, and recently i gave up on finding an alternative to haskell‚Ä¶  today i just use haskell for that sort of thing
19:12:33 <centril> ubsan_: yes, <3 whiteboards
19:12:59 <ubsan_> ertes: see, I'm coming from the other direction :)
19:13:12 <ubsan_> I want to bring dependent types to a Rust/C++-alike
19:13:18 <ubsan_> b/c I'm weird
19:13:26 <ertes> i briefly tried various schemes, but i can't program without a type system
19:13:26 <centril> ubsan_: i want that too
19:13:49 <centril> ubsan_: const-dependent types in rust is a nice start
19:13:56 <ubsan_> tswett_to_go: I really love rust as a compiler language
19:14:08 <ertes> makes me shout at the compiler:  "why are you so stupid?!  it's obvious that i want you to do *this*, and if you had a type system, you would know that, too!"
19:14:09 <centril> maybe we can get full dependent types in rust
19:14:17 <ubsan_> centril: I look at rust, and I don't think it'll ever really have full dependent types
19:14:26 <ubsan_> there are too many backwards compatibility things
19:14:54 <ubsan_> that we'd have to completely change if we were to get dependent types
19:15:09 <ertes> i had a look at rust, too, and immediately came back to haskell
19:15:17 <ertes> "still no HKT polymorphism"
19:15:23 <centril> i dont know the compiler details, so i guess you're right ubsan_
19:15:27 <tswett_to_go> ubsan_: hmm, that's an interesting idea. Compiling a database query language wouldn't necessarily make much sense. But Rust has the whole...
19:15:38 <tswett_to_go> I was going to say Rust has the whole "no runtime system" thing going for it, but does it really?
19:15:44 <ubsan_> tswett_to_go: uh, yes
19:15:44 <tswett_to_go> I don't remember if Rust gives you a garbage collector or what.
19:15:54 <ertes> also rust as a compiler language?  no way!  i want HKT there, too, because i want easy locally nameless binding
19:16:03 <ubsan_> Rust is at C++ speed
19:16:05 <ertes> a la the 'bound' library
19:16:12 <tswett_to_go> *nod*
19:16:22 <ubsan_> ertes: *shrug*
19:16:29 <lifter> So I've done my Haskell development in vim, Sublime, and most recently Atom. But Atom is (surprise) giving me performance issues and I'm looking to move to something else. These days Haskellers are raving about Intero, right? If I want to try Intero but stick to my familiar vim bindings, what's the best emacs for me?
19:16:51 <mbw> lifter: I would guess spacemacs.
19:16:52 * ubsan_ continues to use vim
19:17:02 <tswett_to_go> Say... I've been thinking about what parts of Haskell can just translate directly into C, without any garbage collector calls or anything like that.
19:17:08 * centril knows one vim command:  :q!
19:17:18 <ertes> lifter: do you use stack?
19:17:22 <lifter> Yep!
19:17:39 <ertes> lifter: because it's hard-wired into intero
19:17:42 <ubsan_> tswett_to_go: I feel that probably, affine types would help a lot here
19:17:55 <ubsan_> or no wait, they're linear types, aren't they
19:18:04 <ubsan_> well, linear arrows, at least
19:18:08 <lifter> OH! One more thing I forgot, I'd really like to have the ability to make multiple cursors if at all possible, like you can do w/ Sublime and Atom. Anyone know if you can do that in spacemacs?
19:18:08 <mbw> lifter: Also using Atom with only 4GB Ram and without a swap file is going to result in a bad time, so I get where you're coming from. What kind of issues do you have with vim + stack?
19:18:28 <ertes> lifter: yes, someone wrote an extension for that‚Ä¶  it's literally called multiple-cursors
19:18:37 <ertes> lifter: you can get it from MELPA, like most other things
19:18:39 <lifter> mbw: Honestly, I can't even remember why I switched from vim, ic might have been for the multiple cursor thing.
19:18:41 <tswett_to_go> Most Haskell types aren't "just a struct", but it's easy to create ones that are.
19:18:56 <ubsan_> tswett_to_go: hmm?
19:19:25 <ubsan_> tswett_to_go: a lot of haskell types can be done with tagged unions
19:19:27 <ertes> lifter: there is also an extension by the same guy to have multiple regions (emacs terminology for marked stuff)
19:19:28 <ubsan_> a la Rust
19:19:36 <tswett_to_go> Like, most Haskell types don't encode directly as a sequence of bytes of a specific length. Take, say, Maybe Int.
19:19:41 <mbw> lifter: Wouldn't block insertion mode (ctrl+v; shift+i/a) be a valid poor man's substitute for that kinda thing?
19:19:44 <lifter> ertes: I did actually use emacs way back in the day, too...
19:19:55 <tswett_to_go> That could be pretty complicated: Just (error "you can put a really long string here and you still simply have a Maybe Int")
19:20:06 <ertes> lifter: so you search for a piece of text or a regex and edit all instances of it at the same time
19:20:15 <ubsan_> tswett_to_go: struct { enum Tag { Nothing, Just } tag; ptrdiff_t data; };
19:20:18 <ertes> (i went back to macros though)
19:20:32 <ubsan_> (using ptrdiff_t as `Int`)
19:20:52 <lifter> ertes: Yeah.... you can go the all-regex route as well. Actually my regex foo has increased greatly since starting Haskell dev. :)
19:20:54 <ertes> lifter: BTW, just to provide some diversity: i use haskell-mode instead of intero with the very simple reason that i don't use stack =)
19:20:58 <tswett_to_go> ubsan_: so how do you encode Just (error "whatever") like that?
19:21:10 <ubsan_> tswett_to_go: that's... a thing?
19:21:14 <ubsan_> what?
19:21:33 <ubsan_> what's up with haskell error handling, does every monad just have implicit state or something?
19:22:01 <ubsan_> > Just (error "hi")
19:22:01 <lifter> ubsan_: There are exceptions and exception handling mechanisms.
19:22:03 <lambdabot>  Just *Exception: hi
19:22:05 <tswett_to_go> No... Haskell is just lazy.
19:22:15 <ubsan_> lifter: ugh, I forgot about that :/
19:22:15 <ertes> you can fix errors, too
19:22:18 <ertes> > fix error
19:22:20 <lambdabot>  "*Exception: *Exception: *Exception: *Exception: *Exception: *Exception: *Ex...
19:22:46 <ertes> proving that you need laziness to fix errors
19:23:10 <mbw> Also you can use c++ and variant types (boost::variant or std::any, C++17) or any (same case as with variant), which kind of goes into that direction.
19:23:20 <tswett_to_go> Anyway, if you had a strict Maybe type--call it Smaybe--then Smaybe Int would be what I'm calling "just a struct".
19:23:22 <lifter> ubsan_: It's not too bad in my experience, the hard part is that actually there are a handful of ways to deal w/ errors and it's a little overwhelming at first.
19:23:40 <tswett_to_go> It's one byte or whatever to indicate whether it's Nothing or Just, plus whatever it takes to make an Int.
19:23:58 <ubsan_> tswett_to_go: the strict subset of haskell is easily convertible, at least
19:24:12 <ubsan_> and anything that works under strictness
19:24:12 <ertes> tswett_to_go: i don't think that's true
19:24:22 <ubsan_> ertes: sure it is
19:24:25 <ubsan_> although it won't be a byte
19:24:34 <lifter> could be a single bit!
19:24:35 <ubsan_> it'll be max(byte, alignof(Int))
19:24:36 <ertes> even strict Maybe needs a few bytes
19:24:46 <ubsan_> ertes: why?
19:24:52 <ertes> most likely a whole machine word
19:24:57 <ertes> ubsan_: because GHC
19:25:20 <tswett_to_go> If you put the Int first, does that let you do it in only 9 (for 64-bit Ints) bytes?
19:25:32 <ubsan_> tswett_to_go: yeah, but the alignment still pulls the size out to 16
19:25:34 <lifter> Int size depends on architecture
19:25:35 <ubsan_> for arrays and such
19:25:41 <ertes> unless it can optimise the constructor away, it will probably take something like 4-8 bytes depending on target
19:25:47 <mbw> Plain-old enum does not make any guarantees about the type used internally, only that it's convertible to/from int. That's why they added enum classes to c++11.
19:25:48 <tswett_to_go> Hmm, right.
19:26:16 <centril> tswett_to_go ubsan_ ertes : damn guys, so much interesting happening in #haskell - so hard to study :P
19:26:30 <ubsan_> centril: muahahahaa
19:26:33 <tswett_to_go> I know, right?
19:26:37 <tswett_to_go> I'm supposed to put in 9 hours of work today.
19:26:38 <u-ou> !lurk
19:26:42 <tswett_to_go> It's 10:30pm and I haven't started yet.
19:26:48 <centril> tswett_to_go: hah :D
19:27:17 <tswett_to_go> I feel like tonight is going to have a Bitter End.
19:27:30 <centril> I'll just have to read the backlog later on and see what happened
19:27:38 <tswett_to_go> By which I mean that some time around 2am, I'll probably be going to the only 24-hour coffee shop in the city, the Bitter End.
19:27:46 <halogenandtoast> nshepperd: Thanks for you answer yesterday, I got caught up and didn't see it
19:27:47 <ertes> tswett_to_go: switch to your editor, open a haskell file, load it into GHCi
19:27:51 <centril> OK... im closing the to-IRC tmux attachment for now then
19:28:30 <ubsan_> tswett_to_go: sounds fun
19:28:31 <tswett_to_go> Is it really the only one? I'd say Grand Rapids is a medium-sized city; we really should have more than just one 24-hour coffee shop.
19:28:39 <ertes> tswett_to_go: if you have trouble doing that, get a second screen‚Ä¶  you can watch #haskell on it and still get stuff done
19:29:19 <tswett_to_go> "you can watch #haskell on it and still get stuff done" - nope, not possible under any circumstances. :)
19:29:20 <mbw> How about a tiling window manager? Been using i3 for about 2-3 years now and I am more than happy with it
19:29:37 <ertes> mbw: on an ultra-wide screen perhaps
19:29:38 <ogkloo> i3 is great
19:30:28 <barrucadu> I have #haskell open while working, and something catches my eye, and I stop working. It can't be done.
19:30:30 <ubsan_> y'all are keeping me from working on my parser
19:30:44 <ertes> with the haskell buffer on the left side and the haskell-process buffer on the right, my screen space is pretty much used up =)
19:30:47 <ubsan_> I've written it two times already, and I'm going in for a third
19:30:47 <u-ou> im reading the channel while playing emulators
19:30:49 <mbw> I usually have like 4-5 desktops open, each in full-screen with one terminal window open. Switching between those is something you become used to quickly.
19:30:55 <ubsan_> u-ou: ooh, what do you play?
19:31:02 <ubsan_> I've gotten super into kaizo lately :D
19:31:05 <u-ou> sonic rn
19:31:05 <tswett_to_go> Decisions, decisions. Should I work, or should I stay on my personal laptop watching this Karpathy neural net training on a picture of Gumball Watterson?
19:31:17 <tswett_to_go> At work I have a 3-display setup, and I really miss it when I'm not working.
19:31:22 <MarcelineVQ> good stuff, there's an #haskell-offtopic  channel for this line of convo though :>
19:31:33 <u-ou> what about haskell-blah!
19:31:39 <u-ou> that's the REAL offtopic channel
19:32:13 <ubsan_> you know what are really cool?
19:32:14 <ubsan_> lenses
19:32:42 <u-ou> my haskell is very rusty. haven't touched it in a while. going to read that book by bite-my-app
19:32:57 <ubsan_> u-ou: my haskell is also very rusty
19:32:59 <ubsan_> so is my C++
19:33:02 <ubsan_> and my idris :3
19:33:05 <u-ou> oh NO
19:33:09 <u-ou> :p
19:33:13 <tswett_to_go> Yeah, lenses are cool! I'm probably going to explicitly build them into my database language.
19:33:16 <u-ou> I can't believe I did that
19:33:49 <ertes> tswett_to_go: must be quite a powerful language
19:33:52 <mbw> I would've loved to try Agda, if it wasn't so opinionated about using emacs :(
19:33:52 <ubsan_> tswett_to_go: lenses are even cooler with linearity
19:33:54 <ertes> because you need one for lenses =)
19:34:03 <ubsan_> mbw: use a better language!
19:34:04 <ubsan_> like coq
19:34:05 <ertes> @src Lens
19:34:06 <lambdabot> Source not found. Your mind just hasn't been the same since the electro-shock, has it?
19:34:06 <ubsan_> or idris
19:34:08 <ubsan_> or lean
19:34:19 <ubsan_> what the heck? lol
19:34:21 <ertes> lambdabot: you got it, tsunderebot‚Ä¶
19:34:37 <mbw> I decided on learning coq... like next week or so...
19:34:46 <u-ou> i want to learn prolog
19:34:49 <tswett_to_go> ertes: yeah, it's powerful because it has lenses built into it. :J
19:35:01 <u-ou> and haskell :p
19:35:04 <ertes> @botcookie
19:35:04 <lambdabot> Unknown command, try @list
19:35:10 <ertes> @botsnack
19:35:11 <lambdabot> :)
19:35:18 <u-ou> heh
19:35:21 <u-ou> cute
19:35:24 <tswett_to_go> Unlike Haskell, which doesn't have lenses built into it, so obviously my language is strictly better than Haskell.
19:35:35 <ogkloo> where would I go to get ghci with ghc >v8
19:35:44 <ertes> lambdabot: picky, aren't you‚Ä¶
19:36:08 <ubsan_> tswett_to_go: linearity + lenses are cool, because you can optimize them down to lvalue writes
19:36:11 <ertes> ogkloo: what do you mean?
19:36:18 <mbw> ogkloo: Simplest would probably to install stack, then stack update && stack upgrade etc.
19:36:19 <ertes> ogkloo: GHCi comes with GHC
19:36:44 <mbw> Should result in a newer version than what comes with dist repos.
19:36:46 <tswett_to_go> Optimize down to lvalue writes. Note that my language is going to compile to Oracle SQL.
19:37:09 <ubsan_> tswett_to_go: D:
19:37:13 <ogkloo> ertes: so I've got stack 1.4, which I figured would have ghc v8, but running stack ghci gets me 7.10.3
19:37:24 <ogkloo> oh no wait I'm dumb
19:37:25 <ertes> tswett_to_go: exception handling is built into PHP, whereas in haskell it's a set of library functions‚Ä¶  so PHP is superior?
19:37:25 <tswett_to_go> ...and other versions of SQL. Oracle SQL is merely the most urgent target, because it sucks. :)
19:37:32 <tswett_to_go> ertes: yes, exactly!
19:37:46 <ertes> i see
19:37:54 <mbw> ogkloo: Did you change the resolver of the global project to a newer version?
19:38:24 <tswett_to_go> And I use Oracle SQL all the time at work, so I'm acutely aware of the exact ways in which it sucks.
19:38:25 <ogkloo> mbw: I think I need to go do some primer on stack, I am woefully behind on that
19:38:58 <ertes> i'm suppressing most of my PHP memories, but i distinctly remember implementing iteratees many years ago, when they were popular in haskell
19:39:12 <mbw> ogkloo: Should be inside .stack/global-project/stack.yaml
19:39:56 <tswett_to_go> No booleans, no empty strings, extremely verbose table lookup syntax. One gigantic syntactic construct used for almost everything, instead of having a separate construct for each feature.
19:40:20 <mbw> Wait, iteratees aren't popular anymore? I always thought I should learn those some day. Don't pipes and conduit abstract over those?
19:40:30 <ertes> mbw: no
19:40:41 <mbw> That clears it up then, I guess.
19:41:01 <ertes> mbw: they are a different streaming abstraction‚Ä¶  iteratees were abandoned, though i'm not exactly sure why
19:41:14 <ertes> however, pipes is definitely easier
19:41:22 <tswett_to_go> No first-class tuples, no obvious way to check nullable values for equality, easy to write nondeterministic code by accident.
19:41:24 <tswett_to_go> I'm going to stop now.
19:42:26 <mbw> Is there a valid reason to stick with Text/Bytestring.Lazy? I saw that wreq makes use of those internally, for instance.
19:43:22 <ertes> mbw: i still think learning them could expand your mind‚Ä¶  they were a very interesting way to handle streaming, which was in a number of ways *simpler* than the more modern transducer-based approach (conduit/machines/pipes)
19:43:54 <ertes> but they may be a bit difficult to understand at first
19:45:00 <ubsan_> has anybody checked out backpack?
19:45:12 <ertes> fun fact:  the snap framework still uses iteratees =)
19:45:20 <ubsan_> (sorry, I sometimes switch from thought to thought quickly)
19:45:33 <ertes> oh, wait, i'm wrong‚Ä¶  they switched to io-streams
19:45:52 <mbw> I'm afraid of what will happen if I keep expanding my mind...
19:46:05 <ubsan_> ertes: sounds delightfully C++-y :P
19:46:06 <ertes> they did that with 1.0 apparently
19:47:31 <systadmin> How come there's no while and for loops .-.
19:48:02 <ertes> systadmin: haskell doesn't have statements the way most other languages have‚Ä¶  instead it has first-class actions, and constructing looping actions is a matter of writing a function
19:48:22 <ertes> systadmin: for example (c >> d) is the action that first runs the action 'a', then the action 'b'
19:48:31 <ertes> so you can read (>>) as "and then"
19:48:41 <ubsan_> ertes: I would really hope that `c >> d` doesn't run `a` then `b`
19:49:03 <ertes> systadmin: forever action = action >> forever action  -- (forever action) is the action that first runs 'action' and then the action (forever action)
19:49:07 <tswett_to_go> I've been writing purely functional code in Scala, and I've been doing it mostly in an imperative style.
19:49:13 <tswett_to_go> Haskell is taking a little getting used to.
19:49:17 <systadmin> So I gotta learn to use recursions?!
19:49:18 <ertes> systadmin: does that make sense?
19:49:29 <systadmin> ertes: yep
19:49:54 <systadmin> so `forever` makes things run *forever*?
19:49:55 <ertes> systadmin: yes, understanding recursion is very helpful, even though you probably won't use it *directly* in most cases
19:50:08 <ertes> systadmin: forever doesn't really "make"‚Ä¶  it "is"
19:50:13 <mbw> systadmin: If you consider that Haskell makes a distinction between "functions" and something that can result in side effects in addition to returning a result, it makes sense that we don't use for loops. Since the canonical for loop is just a mapping from an iteration space to a sequence of side effects...
19:50:23 <orion> Is it accurate to call "(a, b)" a product of a and b, and "Either a b" a co-product of a and b?
19:50:26 <ubsan_> for : (initial : a) -> (cond : a -> Bool) -> (loop : a -> a)
19:50:38 <ertes> orion: the types?  yes
19:50:43 <tswett_to_go> You don't necessarily have to actually write recursive functions... but it might be the easiest way to go sometimes.
19:50:56 <mbw> orion: (,) is also sometimes called an anonymous product.
19:50:58 <ertes> orion: in fact it's super-accurate, because you said "a product" instead of "the product" =)
19:51:04 <mbw> or rather (a,b).
19:51:21 <ubsan_> for initial cond loop = case (cond initial) of True => for (loop initial) cond loop | False => initial
19:51:38 <ubsan_> type of for should be `a -> (a -> Bool) -> (a -> a) -> a`
19:51:47 <sophiag> ok, circling back to ask this again... can anyone shed some light on my attmpes to install prce-light with cabal are failing due to not being able ot find pkg-config? this came up because it's a dependency for ghc-core
19:51:56 <ertes> systadmin: note that you could bring back most of your control constructs from other languages as regular functions‚Ä¶  we do that for some things like exception handling
19:52:09 <tswett_to_go> ertes: of course, there's homotopy type theory, where you only have one of anything, and so it really is "the product"!... kind of.
19:52:17 <ertes> systadmin: for example 'catch' is a regular function in haskell
19:52:20 <ertes> :t catch
19:52:22 <lambdabot> Exception e => IO a -> (e -> IO a) -> IO a
19:52:39 <ertes> systadmin: (IO a) is the type of actions that result in a value of type 'a'
19:52:50 <ertes> it takes such an action and an exception-handler function
19:53:07 <ertes> (catch c f) is the action 'c' with exceptions caught by 'f'
19:55:06 <ertes> systadmin: however, you probably wouldn't want to bring 'for' loops back, because the way 'for' works depends a lot on the language's ability to have statements and state effects within those, which haskell doesn't have
19:55:49 <ertes> instead you have things like folds and unfolds, while have a similar purpose in haskell as for-loops have in other languages, but are far more domain-specific (and therefore often shorter and less error-prone)
19:55:56 <ertes> s/while/which/
19:56:41 <ertes> example:  mapM_ print [1..10]  -- print numbers from 1 to 10
19:57:28 <mbw> systadmin: Also, people try to avoid "naked recursion", which would be something like using goto. Instead you use "common patterns of recursion" which get used over and over. Maps/Folds/etc. are recursion combinators which abstract out these patterns and makes code easier to reason with. It's analogous to using for_each constructs instead of a naked for-loop, since in the latter, indices might be changed in 
19:57:34 <mbw> the loop body..
19:58:05 <mbw> (bringing goto into the game is probably a little harsh though...)
19:58:46 <Cale> You're certainly free to bring C-style for loops back yourself if you'd find them useful though -- it's easy enough to write one (but I wouldn't recommend it)
20:01:07 <c_wraith> It's actually kind of a pain to write something so general as to emulate every way a for loop can be abused.
20:01:31 <c_wraith> Like any sort  of for loop that mutates the loop variable in the body, for instance.
20:02:08 <ertes> c_wraith: the pain actually comes from using mutation in IO
20:02:13 <Cale> It's not that hard -- it's just a pain to use it
20:02:27 <ertes> and querying mutable variables
20:02:34 <ertes> C: x < 0
20:02:39 <c_wraith> I didn't say "hard".  I did say "pain"  :)
20:02:51 <ertes> haskell:  (< 0) <$> readIORef xRef
20:02:57 <Cale> Well, I mean, it's not a pain to write the loop construct itself
20:03:31 <ertes> it's better to have state in terms of either data structures or recursion =)
20:03:40 <c_wraith> Hmm.  I guess I consider the pain of using the construct to be part of the whole process.
20:04:21 <mbw> About that: I've been thinking. A loop over an array can have several kind of dependencies, like flow dependencies, anti dependencies, another one I forget, and loop-carried dependencies. Only the last one is a "true" dependencies, since others can be removed by throwing more memory at them (i.e. don't write an inplace algorithm, but return a new array). Then, any such loop is convertible to a recursive 
20:04:27 <mbw> function via doing a "reverse tail-call optimization". This tail-recursive function can be expressed via foldl. If I can THEN express this fold via fold/foldMap, is that a formal proof of the absence of a loop-carried dependency?
20:04:32 <c_wraith> then again, I wrote http://lpaste.net/revision/114261 and I have *no freaking clue* how it works now.  Though at least I know what it does.
20:05:25 <ertes> mbw: or in other words: the lambda calculus is as expressive as turing machines =)
20:05:47 <mbw> ertes: Well it was a question. There could be a mistake in my reasoning...
20:06:07 <mbw> The idea of course being that foldMap could be executed in parallel.
20:06:33 <ertes> c_wraith: hmm‚Ä¶  doesn't look too difficult to me, although parametricity helps a lot
20:07:15 <ertes> mbw: i'm not sure about the general case, but (foldMap f) can definitely be evaluated in parallel, *if* f is a monoid morphism
20:07:19 <c_wraith> ertes: mostly the details.  I know I did some weird CPS transform stuff for avoiding unnecessary copying, but I can't explain it now.
20:07:48 <ertes> mbw: (that's the basic idea of MapReduce put in algebraic terms)
20:08:55 <ertes> indeed, it should be true in general‚Ä¶  however, i don't know if your reasoning is correct, because i don't really get it =)
20:09:14 <mbw> ertes: yeah that's what I was thinking. But it all seems too easy :) Since fold respects monoidal structure, is foldMap f automatically a monoid homomorphism if I have proven that the Monoid created by f is a "real" monoid, i.e. a lawful citizen?
20:09:41 <ertes> (f a <> f b) <> (f c <> f d) = f a <> (f b <> (f c <> f d))
20:10:29 <mbw> ertes: What part of my reasoning is unclear?
20:11:58 <ertes> i think (foldMap f) is a monoid morphism, if f is a monoid morphism, but it's hard to prove, mostly because the laws are stated so vaguely
20:12:04 <tswett_to_go> mbw: foldMap f (xs ++ ys) = foldMap f xs `mappend` foldMap f ys, and foldMap f [] = mempty, right?
20:12:11 <tswett_to_go> That makes it a monoid homomorphism.
20:12:24 <ertes> tswett_to_go: for lists, yes
20:12:28 <mbw> Yes, monoids are mapped to monoids basically
20:12:46 <mbw> Since (++) = mappend for lists.
20:13:13 <mbw> So this can be generalized in the obvious way.
20:13:41 <ertes> mbw: the part that isn't clear to me is everything, mostly because i'm not familiar with the terminology =)
20:13:47 <mbw> (Though I rely on others for these kinds of generalizations, hence my question. I'm too scared of these kind of laws)
20:13:52 <mbw> Ah.
20:13:56 <mbw> The dependency stuff.
20:14:28 <mbw> It's basically the wild west of mutability and the reason that imperative languages struggle with parallelization, or rather proving its correctness.
20:14:37 <mbw> It's embarrassing really.
20:14:40 <mbw> Example
20:14:53 <ertes> hmm‚Ä¶  actually i'm not convinced that (foldMap f) is a monoid morphism in general, because weird things happen at infinity
20:14:54 <mbw> I have to parallelize Fortran programs using Openmp.
20:15:23 <mbw> There is no open-source tool reliably check for thread races. Even the ones that exist can give false positives.
20:15:35 <mbw> I can only pray for correctness.
20:15:53 <ubsan_> mbw: that's why I use Rust ;)
20:16:09 <mbw> Well ok, but I guess with infinity, you can formally proof that foldMap f bottom = bottom or something
20:16:37 <ertes> that's fine
20:16:50 <mbw> Fortran programmers are really conservative, unfortunately. The ones I know actually avoid anything newer than Fortran77, since it's probably slower....
20:17:10 <ubsan_> mbw: that's... insanity
20:17:20 <ubsan_> have they never seen the C++ talks?!
20:17:23 <ubsan_> (probably not...)
20:17:45 <mbw> "c++ is slow because it's object-oriented."
20:17:55 <ubsan_> zero-cost abstractions + using those abstractions = faster than hand-written
20:18:35 <ubsan_> yeah... inheritance oriented programming is a blight upon the world
20:18:42 <mbw> Well to be fair, in conjunction with some commercial compilers, those zero-cost abstractions are still somewhat finicky.
20:18:49 <ubsan_> thankfully, modern c++ does not use them
20:19:06 <mbw> The problem lies in the fact that people still don't recognize c++ as a multi-paradigm language.
20:19:13 <ubsan_> yeah
20:19:18 <ubsan_> using C++ as Java++ is a bad idea
20:19:21 <mbw> Resulting in people using that other language, called "C/C++".
20:19:34 <ubsan_> C with classes is nearly as bad
20:19:43 <mbw> Since every "modern" construct has to be object-oriented, right?
20:19:55 <ubsan_> maybe if you're from the 1990s...
20:20:13 <mbw> like I said, fortran77
20:20:23 <ubsan_> nowadays, it's generics-oriented
20:20:28 <ubsan_> which is much, much faster
20:21:17 <mbw> Yeah but only if implemented via multi-instantiation and not tag-dispatch or type-erasure, which is why generics get a bad rep
20:21:26 <ubsan_> eugh
20:27:27 <nshepperd> generics by code generation has its own problems. more code size -> more cache miss
20:27:33 <nshepperd> and no polymorphic recursion :(
20:27:59 <ertes> it's kinda ironic to say something like that in #haskell =)
20:28:32 <mbw> To be fair, I don't use polymorphic recursion in C++ that much :)
20:28:49 <ertes> mbw: i don't think you use it at all, because C++ doesn't have it ;)
20:29:34 <mbw> Also, you are free to use the dispatched-based runtime-polymorphism via virtual functions. 
20:30:42 <ertes> RankNTypes doesn't work with C++-style instantiation, i think, unless the compiler learns to instantiate monomorphic functions at use sites
20:30:43 <ertes> in any case C++ doesn't have it
20:32:21 <tswett_to_go> This talk of generics by code generation made me wonder if C# lets you write a program that generates infinitely many generic instantiations at runtime.
20:32:24 <tswett_to_go> The answer is yes, totally.
20:32:36 <nshepperd> there's lots of other great things about c++ though. like affine types! sort of
20:33:01 <ertes> everything in C++ is "sort of" =)
20:33:09 <mbw> To be quite frank, even after having come to love haskell, I still would try to avoid recursion in an imperative language, if only for the reason that without something as expressive as pattern matching, it's simply unidiomatic.
20:33:15 <tswett_to_go> Let me see what Haskell thinks of the same function...
20:33:21 <ubsan_> ertes: yeah
20:33:22 <tswett_to_go> :t let wibble x = wibble [x] in wibble
20:33:23 <lambdabot> error:
20:33:23 <lambdabot>     ‚Ä¢ Occurs check: cannot construct the infinite type: t3 ~ [t3]
20:33:23 <lambdabot>       Expected type: [t3] -> t2
20:33:25 <ubsan_> that's why one uses rust! :D
20:33:29 <nshepperd> mbw: oh yeah, and you can make the stack explode
20:33:30 <ertes> it has polymorphism, sort of, dependent types, sort of, first-class functions, sort of, ‚Ä¶
20:33:39 <nshepperd> ertes: hah!
20:33:44 <nshepperd> yeah
20:33:49 <tswett_to_go> :t let wibble :: a -> b; wibble x = wibble [x] in wibble
20:33:51 <lambdabot> a -> b
20:34:00 <monochrom> There is a mutual cycle between having while-loops and not having pattern matching.
20:34:01 <tswett_to_go> So you can do it in Haskell, but only with a type signature.
20:34:10 <mbw> What would be affine types, if I may ask?
20:34:30 <ertes> mbw: almost linear types
20:34:38 <nshepperd> mbw: in c++ they call it move semantics
20:35:15 <ertes> mbw: linear types require exactly one consumer, while affine types allow you to ignore the value
20:35:22 <tswett_to_go> :t let wibble x = wibble "hello" in wibble
20:35:25 <lambdabot> [Char] -> t
20:35:46 <ubsan_> monochrom: Rust :)
20:35:50 <tswett_to_go> I'm thinking about why the type inference algorithm doesn't infer the more general type for that.
20:36:26 <ubsan_> ertes: how does C++ not have first class functions?
20:36:49 <ertes> ubsan_: it has them
20:36:50 <ertes> sort of
20:36:53 <mbw> lol
20:37:05 <ubsan_> I mean, like, what would it have to change to not "sort of" have them
20:37:12 <monochrom> C++ has 1.5th class functions.
20:37:19 <c_wraith> C++ has operator()
20:37:25 <ubsan_> C++ has lambdas
20:37:29 <c_wraith> which lets you pretend to have first-class functions
20:37:30 <nshepperd> tswett_to_go: inference for polymorphic functions like 'let wibble x = wibble [x] in wibble' is equivalent to Rank2 inference, I think
20:37:34 <ubsan_> (or closures, really)
20:37:39 <mbw> ubsan_ The closest thing to it would in my opinion be std::function, which incurs some overhead. NOT Lambdas, since the type is only known to the compiler.
20:38:10 <ubsan_> mbw: so your definition of first-class functions is "std::function, but every function type is a std::function"
20:38:38 <ubsan_> like, otherwise, I have no idea what you're talking about lol
20:38:48 <tswett_to_go> I guess the inference algorithm must be using a rule like: since wibble is applied to a String, the type of wibble must be of the form String -> t.
20:39:00 <mbw> I wouldn't really go and "define" anything, since other people are more knowledgable. This is merely stating that lambdas do come with some restriction in c++.
20:39:23 <tswett_to_go> The fact that this results in a less general type doesn't matter.
20:39:42 <monochrom> I prefer my fuzzy logic stance of 1.5th class. :)
20:39:56 <ubsan_> mbw: the fact that lambdas don't have a name for the type is not actually... super... important?
20:40:08 <ubsan_> like, you can name the type of a specific lambda if you wish
20:40:21 <monochrom> Or maybe 1.414th class so you can say "hmm that's sqrt(2)"
20:40:28 <ubsan_> the reason that lambdas don't have normal type names is because of captures
20:41:13 <nshepperd> tswett_to_go: I don't know the actual details, but I noticed that if you rephrase such a recursive function in terms of a non-polymorphic function and fix, you end up needing a fix at Rank2 type
20:41:22 <nshepperd> tswett_to_go: to get the more general type
20:41:23 <ubsan_> without heap allocation, you can't have a lambda that captures these variables, and a different lambda that captures these other variables, and give them the same type
20:41:36 <monochrom> Or better yet, take a poll over a lot of programmers, "do you consider it 1st class or 2nd class?", then take the average.
20:41:48 <tswett_to_go> nshepperd: hmm... right. This doesn't work:
20:41:51 <tswett_to_go> :t fix (\x -> [x])
20:41:53 <lambdabot> error:
20:41:53 <lambdabot>     ‚Ä¢ Occurs check: cannot construct the infinite type: t ~ [t]
20:41:53 <lambdabot>     ‚Ä¢ In the expression: x
20:42:05 <ubsan_> so unless the argument is that you need implicit heap allocation to have first class functions, I'd argue your argument doesn't stand up ;)
20:42:37 <mbw> Yes, but a function that expects some function as argument (like std::sort), can do so either via template-parameter, std::function, or function pointer (or those member-function reference thingies). The template parameter does not give you a clue at what kind of function it expects. The function pointer cannot be inlined. std::function makes the type-signature clear (and more readable), bit is the most 
20:42:43 <mbw> inefficient alternative. If you don't care about efficiency, you don't use c++.
20:43:12 <ubsan_> mbw: so that's more to templates, and their inherent implicitness
20:43:15 <tswett_to_go> But... I'm trying to think what type signature you could add to that so that it does work.
20:43:22 <mbw> I uess so.
20:43:26 <mbw> *gues
20:43:32 <mbw> :/
20:43:35 <ertes> ubsan_: try to store a function with a closure in a data structure‚Ä¶  there is probably a way, but it's not the usual function pointer way
20:43:36 <ubsan_> you can always static_assert, or SFINAE, to make it more explicit
20:43:46 <tswett_to_go> Wait, that was the wrong expression.
20:43:56 <ertes> ubsan_: generally the type of a function with a closure is a different one from the type of a "regular" function in C++
20:44:04 <tswett_to_go> :t fix (\f x -> f [x]) -- doesn't work
20:44:05 <lambdabot> error:
20:44:06 <lambdabot>     ‚Ä¢ Occurs check: cannot construct the infinite type: t1 ~ [t1]
20:44:06 <lambdabot>       Expected type: [t1] -> t
20:44:24 <ubsan_> ertes: sure, but you can't solve that without implicit heap allocation anyways
20:44:29 <mbw> Well ok. But that's not really making things more explicit for the uninitiated.
20:44:29 <monochrom> tswett_to_go: I think you may like to look up "polymorphic recursion".
20:44:46 <ertes> ubsan_: right, and that's why C++ has first-class functions, sort of =)
20:44:52 <ubsan_> mbw: for the uninitiated, currying makes no sense either ;)
20:45:02 <mbw> In c++, no.
20:45:08 <ubsan_> ertes: then I disagree with your definitions of first class functions
20:45:34 <ubsan_> > Specifically, this means the language supports passing functions as arguments to other functions, returning them as the values from other functions, and assigning them to variables or storing them in data structures.
20:45:34 <mbw> If you asked me to actually "define" something, making a construct's use feel natural would probably be part of the definition of something begin "first-class".
20:45:36 <lambdabot>  <hint>:1:13: error: parse error on input ‚Äò,‚Äô
20:45:42 <ertes> ubsan_: if you broaden the definition, then suddenly C will also "have first-class functions"
20:45:49 <ubsan_> ertes: I would argue it does
20:46:05 <tswett_to_go> :t (fix :: ((forall a. a -> b) -> forall a. a -> b) -> forall a. a -> b) (\f x -> f [x]) -- works???
20:46:06 <ubsan_> the only issue with C functions is that you can't define them at any scope
20:46:07 <lambdabot> error:
20:46:07 <lambdabot>     ‚Ä¢ Couldn't match type ‚Äòa2‚Äô with ‚Äòa1‚Äô
20:46:07 <lambdabot>       ‚Äòa2‚Äô is a rigid type variable bound by
20:46:24 <ubsan_> and of course, in C++, you can, through the use of lambdas
20:46:27 <mbw> Also, they aren't polymorphic, not even via void pointers.
20:46:49 <ertes> ubsan_: my definition is that there is a certain type family for functions, functions can be created anywhere, close over variables in scope and all have this particular type
20:46:51 <mbw> You cannot define a generic map function that takes a unary function as argument in c.
20:47:06 <ertes> ubsan_: and yes, that inherently requires GC
20:47:11 <ertes> even unlambda and lazy k have GC
20:47:15 <ubsan_> ertes: then your definition is bad ;)
20:47:55 <ertes> ubsan_: my definition is based on logic‚Ä¶  free variables are a thing
20:48:46 <ertes> it would be weird if something that is lexically in scope suddenly goes out of scope‚Ä¶  although i'm used to that from my years-long struggle with arrows
20:49:47 <ertes> ubsan_: your definition is probably more inspired from the notion of function pointers‚Ä¶  but pretty much all languages have those, so your definition is actually quite useless =)
20:49:51 <mbw> ertes is entirely correct. A lambda in C++ can be converted to a function pointer IFF there is an empty capture clause (since it is then guaranteed to be implemented by a name-mangled run-of-the-mill function). Otherwise, a function object is created. But I don't think this warrants GC. Maybe I misunderstood?
20:50:25 <mbw> (capture clauses let you associate free variables as copy or reference with a lambda).
20:50:58 <ubsan_> oh, also, you can use `function_ref`, if you don't want overhead in your `std::function`
20:51:11 <ubsan_> ertes: I don't like garbage collection
20:51:43 <ubsan_> any definition which says "garbage collection is implicit overhead, so it's fine, but explicit overhead is not", doesn't sit right with me
20:51:55 <ertes> ubsan_: i do like it, because it generally does a better job than me at managing memory, because it can come up with cleverer reuse plans
20:52:09 <mbw> Just take it like what it is. A useful abstraction. I don't like memory leaks either.
20:52:11 <ertes> GC is not "overhead", it's a memory management scheme
20:52:21 <nshepperd> tswett_to_go: hm, I managed to do it but only by hiding the polymorphic bit in a newtype
20:52:29 <ubsan_> ertes: you can say that, but then you might wonder why linear typing is a thing ;)
20:52:43 <ubsan_> (hint: it's because GC is implicit overhead)
20:52:53 <Cale> That also isn't true
20:53:29 <ertes> ubsan_: linear typing would be useful in a language like haskell in order to use in-place updates for things like arrays
20:53:45 <ertes> not for better-informed GC, because GHC's GC is very well informed
20:53:51 <ertes> it doesn't need the help of linear types =)
20:54:08 <ubsan_> ertes: with linear types, a GC no longer needs to exist
20:54:14 <Cale> Huh?
20:54:16 <ubsan_> this is why C++ and Rust are so fast
20:54:17 <ertes> ubsan_: that's wrong
20:54:42 <ertes> ubsan_: it's still GC, but with a certain guarantee
20:54:49 <ubsan_> ertes: emm... no it isn't?
20:55:10 <mbw> Please let's not go down that road. Languages aren't fast (though I guess Italian is?)...
20:55:17 <ubsan_> scope-based resource management is not GC
20:55:21 <ertes> ubsan_: we could argue about the definition of GC, but it doesn't necessarily involve a heap and algorithms
20:55:22 <Cale> I suppose if you had a very annoying language in which every variable had to be linear, so you could never use anything more than once, you could avoid the need for a GC.
20:55:46 <ertes> ubsan_: you know how you use recursion in haskell to write something stateful?  GC is happening there on a very small scale
20:55:48 <ubsan_> Cale: just look at Rust or C++. They don't need a GC, because they have affine variables
20:56:19 <mbw> That doesn't make sense.
20:56:20 <ertes> ubsan_: but the resulting program may not use any heap memory or actual GC algorithms‚Ä¶  it's much more likely to do an in-place update
20:56:31 <ertes> and that's still GC, just very smart GC
20:56:35 <ubsan_> mbw: it's a really simple concept
20:56:37 <mbw> If this is about move semantics, shouldn't C++ have had garbage collection before c++11!?
20:56:39 <ertes> GC is not a library, it's a compiler feature
20:56:40 <nshepperd> I wouldn't describe what happens when a unique_ptr goes out of scope as 'garbage collection'
20:56:40 <ubsan_> I'm not sure how it doesn't make sense
20:56:59 <ubsan_> mbw: you can replace garbage collection in other ways
20:57:03 <ubsan_> like manual memory management
20:57:06 <Cale> ubsan: Last I checked, you could use variables more than once in those languages.
20:57:07 <ubsan_> or copy semantics
20:57:09 <mbw> Then I guess the concept of an affine variable still isn't clear to me.
20:57:32 <ertes> ubsan_: i think you have a major misconception on what GC is
20:57:35 <Cale> mbw: Certainly, how ubsan is using the word is unclear...
20:57:43 <ubsan_> ertes: tracing GC
20:57:50 <ubsan_> what people mean when they say "GC"
20:57:53 <ubsan_> like what Haskell uses
20:58:06 <ertes> ubsan_: only for certain long-lived values
20:58:14 <ertes> like values stored in data structures
20:58:26 <ubsan_> ertes: there are very clear definitions for what a GC is
20:58:34 <ubsan_> SBRM is not one of them
20:58:51 <ubsan_> mbw: go use Rust then?
20:59:00 <ertes> ubsan_: example:  f x = print x >> f (x + 1)
20:59:05 <ertes> ubsan_: does this use GC?
20:59:14 <ubsan_> ertes: I don't know, it depends on the implementation
20:59:27 <ubsan_> probably, because Haskell is box-happy
20:59:45 <mbw> Depends on whether it's used, first of things.
21:00:05 <ubsan_> true
21:00:14 <ubsan_> this is a very weird argument path that y'all are traveling down
21:00:14 <ertes> ubsan_: it does in haskell, yet it compiles to a tight loop that updates in-place
21:00:25 <c_wraith> I'd be surprised if that allocates when compiled with optimizations
21:00:27 <Cale> Also probably depends on the type of x
21:00:32 <Cale> yeah
21:00:56 <ertes> no allocations at all, but it still uses "GC", because it's not me managing the memory, it's GHC
21:00:59 <c_wraith> in fact, I've used loops like that to prevent the garbage collector from running. :)
21:01:01 <ubsan_> "GC sometimes doesn't happen, therefore... something"
21:01:06 <mbw> On the other hand, are you sure of that? After all, things like the "forM_ [1..] - bug" still aren't fixed...
21:01:31 <ubsan_> debate through confusion?
21:01:37 <ubsan_> this is a very strange tactic
21:01:39 <ertes> well, ok, it probably defaults to Integer, which will need allocation at some point
21:01:47 <ertes> but the universe will have collapsed before that happens =)
21:01:52 <Cale> I don't even know what is being debated here, exactly.
21:01:58 <ubsan_> Cale: honestly, I don't either
21:02:13 <ubsan_> I stated that linear types could be used to replace GC
21:02:15 <ertes> well, it's about linear types as a memory guarantee
21:02:29 <ubsan_> as seen in the affine replacements for GC seen in Rust and C++
21:02:38 <Cale> ubsan_: Well, I think that's pretty untrue -- you'll still want a GC to pick up things which aren't linear -- making everything linear is unreasonable.
21:02:53 <ertes> it's still GC to me, because there is no manual memory management, unless you consider the final consumer to be "explicit freeing"
21:02:53 <ubsan_> (noting that, of course, C++ doesn't have true affine types, but a fairly okay approximation)
21:03:13 <ubsan_> Cale: linearity + references = awesome
21:03:31 <ubsan_> ertes: but it's not GC
21:03:33 <nshepperd> ertes: you're arguing that c++ has a GC...?
21:03:35 <ubsan_> it's RAII
21:03:38 <Cale> ubsan_: Well, you *could* make everything linear, but that would come at the expense of Turing completeness, for example.
21:03:53 <ubsan_> Cale: that's why Copy types are a thing
21:04:00 <mbw> nshepperd: Actually, it does have an official ABI for implementing GC I think.
21:04:02 <nshepperd> anyway some things certainly do need to not be linear
21:04:05 <Cale> ubsan_: So then how do you clean those up?
21:04:08 <ubsan_> also, linear things are most definitely turing complete
21:04:10 <ertes> nshepperd: well, in a sense it does: each time you return from a function, the stack frame is freed for you =)
21:04:17 <nshepperd> like some fancy tree based data structures
21:04:23 <ubsan_> mbw: yes, it does. nobody has ever used it
21:04:42 <ubsan_> the boehm people wanted it to be added to the standard
21:04:46 <Cale> ubsan_: If everything must be used exactly once?
21:04:55 <ertes> anyway, i would like to have uniqueness types in haskell, not as an efficiency-related guarantee, but as a way to have a nicer interface to mutable arrays
21:04:58 <ubsan_> Cale: yeah
21:05:05 <Cale> ubsan_: How do you write a fixpoint combinator?
21:05:16 <ubsan_> :t fix
21:05:17 <lambdabot> (a -> a) -> a
21:05:28 <mbw> This all sounds like it would read like SSA compiler output...
21:05:58 <Cale> ubsan_: That's usually going to use its argument more than once. :P
21:06:00 <ertes> the rust people chose to have affine types, we chose to have a smart compiler =)
21:06:13 <ubsan_> Cale: I don't know. I've never tried to implement it.
21:06:21 <ubsan_> ertes: and you can see the difference in speed ;)
21:06:41 <ertes> ubsan_: can i?  my haskell code is pretty fast
21:06:57 <ubsan_> ertes: pretty fast != as fast as C, C++, and Rust
21:07:07 <MarcelineVQ> why not
21:07:26 <ubsan_> because it isn't
21:07:31 <MarcelineVQ> oh
21:07:34 <mbw> lol
21:07:36 <ertes> ubsan_: i'd challenge that, and in fact i've written code that ran faster than the equivalent code in C, compiled both with GCC and clang
21:07:48 <mbw> :t absurd
21:07:49 <lambdabot> Void -> a
21:07:50 <ubsan_> ertes: I'd like to see that code
21:08:03 <Cale> ubsan_: If you only have linear typed variables, then the amount of stuff you have never changes.
21:08:04 <ertes> ubsan_: http://lpaste.net/101980
21:08:05 <ubsan_> and I'd like to see the C compared to
21:08:15 <Cale> Your program runs in constant space, hooray!
21:08:15 <ertes> ubsan_: everything is linked from there
21:08:16 <ubsan_> Cale: there's actually this really great paper about this
21:08:29 <ubsan_> "The Computational Content of Isomorphisms"
21:08:44 <ubsan_> I haven't gotten to the part where they prove turing completeness, but apparently they do at some point
21:08:55 <Cale> Sometimes constant space is good enough
21:09:07 <ertes> ubsan_: the thing that makes haskell code slow is mostly the wrong choice in data structures and a somewhat unfortunate base library (with String as the default, etc.)
21:09:31 <ertes> ubsan_: but you can avoid all those things:  choose the right data structures and use ByteString/Text/Vector/‚Ä¶
21:09:42 <Cale> But usually people like to introduce something which allows unrestricted duplication of a resource
21:09:53 <ertes> in particular: FP is NOT about using lists for everything
21:10:02 <Cale> and as soon as you have that, ordinary lambda calculus embeds into your type theory
21:10:13 <Cale> (just stick that annotation on everything in sight)
21:10:22 <ubsan_> ertes: see, that does not look like haskell lol
21:10:29 <ertes> ubsan_: why not?
21:10:30 <ubsan_> Cale: you can do that
21:10:41 <Cale> What doesn't look like Haskell?
21:10:53 <ubsan_> but I find it more interesting to embed them in arrows :3
21:11:19 <Cale> ubsan_: Well, my point is, you have all the same reasons to want a GC for a linear type system as you do for plain lambda calculus.
21:11:34 <Cale> (so long as you have that unrestricted duplication operator)
21:11:40 <ubsan_> Cale: yeah, but you don't need it
21:11:45 <Cale> huh?
21:11:45 <ubsan_> you can embed it in arrows
21:11:56 <Cale> You don't need a GC for plain lambda calculus either
21:11:57 <ubsan_> that's the point of the paper
21:12:04 <Cale> You can just never deallocate anything
21:12:06 <Cale> problem solved
21:12:08 <ubsan_> ...
21:12:09 <ubsan_> w/e
21:12:13 <ubsan_> read the paper
21:12:13 <Cale> I guess
21:12:38 <ubsan_> ertes: to be fair, your short names do not help
21:12:44 <Cale> I don't think substructural type systems magically absolve you of the problem of managing memory in the real world.
21:12:50 <ubsan_> it's nearly impossible to read your code
21:12:55 <ubsan_> Cale: that's why you use RAII
21:13:19 <ubsan_> it not only solves memory management, it also solves resource management in the general case
21:13:22 <nshepperd> I don't know about this 'embedding in arrows' stuff, but making *everything* linear seems one cross too much to bear
21:13:37 <nshepperd> you'll pry my persistent data structures from my cold dead hands
21:13:46 <ubsan_> nshepperd: I mostly think it's cool
21:13:49 <Cale> nshepperd: Yeah, you need to know up front how much stuff you'll need
21:13:54 <ubsan_> I wouldn't argue to actually do everything with it
21:13:59 <mbw> I find it reasonably readable.
21:14:25 <ubsan_> ertes: you know you can factor stuff out into functions, right?
21:14:28 <ertes> ubsan_: i'm happy to explain them, if you ask which ones
21:14:36 <ertes> ubsan_: i think i did
21:14:43 <ertes> they're just not at the top level
21:14:55 <ubsan_> oh, I guess os
21:14:56 <ubsan_> *so
21:15:01 <ubsan_> I'm not the best at reading haskell
21:15:12 <ubsan_> alright, wbits1
21:15:16 <ubsan_> and wlog
21:15:19 <ubsan_> what do they do?
21:15:31 <ertes> > bitSize (undefined :: Word) - 1
21:15:33 <lambdabot>  63
21:15:40 <ubsan_> and what's this: `[e| b |]`
21:15:42 <ertes> number of bits in a Word - 1
21:16:00 <ertes> a Word has 2^6 = 64 bits
21:16:04 <ertes> wlog = 6
21:16:15 <ubsan_> ah, okay
21:16:29 <ubsan_> what's the [e| b |] thingy
21:16:32 <ertes> i could have used Word64, but i wanted it to run faster than the equivalent C on 32-bit architectures as well =)
21:16:48 <ubsan_> so this doesn't use infinite precision
21:16:49 <ubsan_> okay
21:17:00 <ertes> that one is template haskell syntax‚Ä¶  it was necessary at that point to make GHC evaluate it at compile time
21:17:05 <ertes> it's a static value
21:17:12 <ubsan_> what's this `arr <- Vsm.replicate (maxW + 1) (-1 :: Word)`
21:17:33 <Cale> That makes a vector consisting of maxW + 1 copies of -1
21:17:33 <ubsan_> is that just allocating an array of size maxW + 1, and filling it with -1s
21:17:34 <mbw> Seems to allocate an array
21:17:46 <ertes> yeah
21:17:53 <mbw> This is all fairly idiomatic.
21:18:16 <ertes> it's imperative, of course, but not in any way not "like haskell" =)
21:18:17 <Cale> Well, as idiomatic as something which does a bunch of bit hackery can be, anyway
21:18:22 <ubsan_> what's the C version
21:18:38 <MarcelineVQ> it's in the paste
21:18:57 <ertes> ubsan_: http://lpaste.net/101507
21:19:01 <ertes> look at the bottom
21:19:18 <ubsan_> oh, cool
21:20:12 <ubsan_> I wonder what the equivalent C++ implementation would be in terms of speed
21:20:27 <ertes> probably the same as the C version
21:21:01 <Cale> I wish dons' entire life were not consumed by his job
21:21:15 <mbw> no march=native
21:21:19 <Cale> He used to keep up the Haskell microbenchmarks on the shootouts
21:21:31 <ertes> i've also verified that GCC's output does in fact use proper bit operations
21:21:39 <Cale> and got Haskell basically to the top of the charts constantly :D
21:21:47 <ertes> and it was still slower‚Ä¶  not by much, but slower =)
21:21:57 <Cale> (And that's why we have stuff like ByteString now)
21:21:59 <ertes> my explanation is that GHC is very good at reusing memory statically
21:22:26 <mbw> There should be a way to use some intrinsics, if you're good at that.
21:22:44 <mbw> Though that's not vanilla C.
21:22:52 <ertes> mbw: i did actually test that, and it didn't make a difference (it's x86_64 anyway)
21:23:14 <ertes> mbw: it might make a difference on i386, if you're allowed to use some of the i686 instructions
21:24:49 <ubsan_> see, this is why I use C++: https://gist.github.com/ubsan/a771eb2ffeb4f13c854304e2b061ef5b
21:24:58 <ubsan_> it's by far the most readable of the three implementations
21:25:12 <Cale> ubsan: Does it perform the same?
21:25:29 <ubsan_> Cale: no idea, haven't tested it yet
21:25:41 <ubsan_> oh, wait, that's a static array
21:25:48 <ertes> ubsan_: of course‚Ä¶  i could have used on of the bit-vector libraries for that
21:26:14 <ertes> the 'vector' library has the unfortunate habit of representing a (Vector Bool) using a whole byte for each bit
21:26:23 <Cale> ertes: Did you try a version which used IOUArray of Bool?
21:26:23 <ubsan_> "unfortunate"
21:26:36 <ertes> Cale: yes, it was slightly slower
21:27:01 <Cale> Ah, possibly more readable though :)
21:27:03 <ertes> most likely due to index arithmetic
21:27:08 <Cale> ertes: iirc, IOUArray does the bit packing for you
21:27:13 <ertes> yes, but the point of this was to win against C =)
21:27:16 <Cale> right
21:27:19 <ertes> yes, it does
21:27:41 <ertes> Vector should do it, too‚Ä¶  i have no idea why it doesn't
21:27:48 <Cale> Yeah, hm
21:27:57 <ertes> perhaps that would be worth a pull-request some day
21:28:05 <Cale> I'm sure it would
21:28:54 <ertes> at that point (it's from a time when GHC 7.6 was fresh) there was one library on hackage that provided a Bit type with corresponding vector instances
21:29:06 <mbw> ubsan_: Do literals like const auto i = size_t(1000) work out as they should? This seems kinda weird to me, why not size_t i = 1000/1000ul or use decltype?
21:29:24 <ertes> but despite being more compact, it performed way worse than this manual method
21:29:34 <ubsan_> mbw: because auto is far more readable
21:29:36 <ertes> not just slightly worse the way IOUArray did, but *much* worse
21:29:44 <Cale> hm
21:30:10 <ertes> i think, it was this one: https://hackage.haskell.org/package/bitvec
21:30:22 <ertes> but there have been new releases since, so james may have fixed it
21:31:17 <ertes> mokus_: ^ (if you're interested)
21:31:29 <nshepperd_> auto i = size_t(2) is more readable than size_t i = 2?
21:32:27 <ubsan_> haha
21:32:28 <ubsan_> nice
21:32:37 <ubsan_> the bitset is too big for the stack, so it segfaults
21:32:40 <ubsan_> nshepperd_: um, yeah
21:32:47 <ertes> ubsan_: to conclude, GHC-haskell is not really slower than C/C++/rust, but there seems to be a lot of incentive not to use the best tool for the job
21:33:06 <ubsan_> ertes: honestly, if you're writing code like that, just write C++
21:33:14 <ertes> and sometimes i feel like a broken jukebox when the topic of data structures comes up in #haskell
21:33:27 <ertes> "do not use lists here"
21:33:31 <ubsan_> if you're writing code that actually looks nice in Haskell, it's going to be slower than nice code in C++ and Rust
21:33:43 <ubsan_> it's all a question of defaults
21:33:54 <Cale> Well, using lists inappropriately is common because (I think correctly) they're the first thing we teach to beginners.
21:33:59 <ertes> ubsan_: why?  i'm still taking advantage of haskell‚Ä¶  not necessarily in this small example, but in larger code i definitely do
21:34:21 <ubsan_> ertes: this is your example, though
21:34:33 <ubsan_> maybe I was wrong about not using haskell because it's not fast
21:34:40 <ubsan_> maybe I shouldn't use haskell because it's ugly
21:34:41 <Cale> and of course, you always have to weigh developer time vs. program time
21:34:47 <ubsan_> that's what I get from this sample ;)
21:35:06 <Cale> Stuff like Data.Map is so often good enough that it's not even funny :)
21:35:21 <ertes> ubsan_: it's ugly, because i'm doing all the bit-twiddling by hand‚Ä¶  and that can be fixed (by fixing the vector library)
21:35:39 <ertes> ubsan_: i just don't use bit vectors that much in practice, so i haven't contributed that particular patch yet =)
21:35:49 <ubsan_> ertes: look, I don't care if haskell can be as fast as C++ or Rust
21:35:49 <Cale> and of course, if we wanted to micro-optimise everything, we could replace individual uses of Data.Map with something trickier and more carefully selected
21:35:58 <ubsan_> I care if pretty haskell can be as fast as C++ or Rust
21:36:03 <ertes> ubsan_: yes, it can
21:36:19 <ubsan_> because I don't want to write like that
21:36:36 <Cale> ubsan_: The important thing which can't be appreciated through microbenchmarks is how things work out in the large
21:37:04 <ertes> ubsan_: this code is not representative of code beauty, although it is beautiful *for what it does*
21:37:05 <Cale> ubsan_: In the large, C++ programs are unmaintainable shit compared to Haskell programs.
21:37:08 <kadoban> I've spent a decent amount of time trying to write fast haskell for various uses. It's pretty easy to get within 2x or so of C++ speed. I usually don't have to go beyond that.
21:37:23 <ubsan_> Cale: you say that, but it's not really true anymore
21:37:32 <ubsan_> you're no longer up against C++03
21:37:37 <Cale> It will always be true
21:37:38 <ubsan_> you're up against C++14
21:37:50 <ubsan_> okay, whatever opinion floats your boat
21:37:52 <ertes> ubsan_: one thing that is really nice about haskell (and it shares that property with C++ to some degree):  free abstractions
21:38:03 <ubsan_> ertes: I've seen very little evidence of that
21:38:05 <Cale> Well, until C++ is unrecognisably different
21:38:05 <kadoban> ubsan_: There have been improvements, but it's still the same language it always was.
21:38:08 <ertes> free as in free bear, not free monad
21:38:12 <ertes> beer
21:38:15 <Cale> to the point that you're not going to want to call it C++ :)
21:38:31 <ubsan_> Cale: C++11 is a superset of C++03 as C++ is a superset of C
21:38:42 <ubsan_> it is basically a completely different language
21:38:51 <Cale> The things about C++ which have to change in order to make my complaints go away are pretty foundational in nature.
21:38:58 <ertes> ubsan_: the problem is that no example i could provide will satisfy you
21:39:13 <ubsan_> ertes: probably not
21:39:15 <kadoban> ubsan_: Those two lines you just typed seem pretty contradictory.
21:39:51 <ubsan_> kadoban: C++ is a completely different language from C, despite being mostly a superset
21:39:59 <ubsan_> added abstraction power means a lot
21:40:02 <ertes> ubsan_: i don't want to say that you're suffering from the blub paradox, but at this point i can only ask you to trust me that GHC produces very efficient code for idiomatic haskell
21:40:42 <ubsan_> ertes: I don't though. there's so much evidence against it
21:40:53 <ertes> ubsan_: is there?
21:41:00 <kadoban> ubsan_: Really? What evidence?
21:41:07 <mbw_> How dare you!
21:41:32 <Cale> You *really* want a garbage collector managing memory *most* of the time. Sure there are cases where you'd rather be careful and ensure that you're not allocating, or are carefully controlling allocation, but doing it everywhere just for the sake of the 1% of cases where it matters just spoils your ability to reason about things, ruins compositionality in various ways, and is just generally a waste of time.
21:41:57 <Cale> (programmer time, which is expensive)
21:42:21 <ertes> and i say it again:  GHC is smart enough that manual memory management (you can do it) rarely pays off
21:43:33 <ubsan_> ertes: there's a lot of benchmarks online, showing that C++ is faster than haskell
21:43:38 <nshepperd> micro optimization mostly doesn't matter outside of the inner loop anyway...
21:43:52 <nshepperd> use the right algorithm first
21:44:06 <Cale> Nevermind that you also *really* want equational reasoning
21:44:17 <ubsan_> the only benchmarks I've seen where Haskell is as fast as C or C++, is benchmarks where it's either unidiomatic (or unobvious) haskell (see, yours)
21:44:26 <ubsan_> or unidiomatic C, like http://lambda.jstolarek.com/2013/04/haskell-as-fast-as-c-a-case-study/
21:44:37 <ertes> ubsan_: it's easy enough to find just the right problem that GCC is better at than GHC
21:44:50 <ertes> ubsan_: except those aren't the problems i need to solve in practice
21:45:07 <ertes> microbenchmarks are mostly useless
21:45:21 <mbw> This. Even if I have to foreign call critical functions, the purity aspect, along with "safe" program transformations is way more important. Make it correct, first.
21:45:48 <mbw> (With _this_ being what Cale said.)
21:45:49 <ubsan_> I'd rather have lifetimes and ownership
21:45:52 <ertes> well, i'm more the kind of person who will solve correctness *and* efficiency at once
21:45:53 <Cale> The microbenchmarks are only useful in that they're able to show that in the small, you can make things really fast or really space-efficient when pressed.
21:46:02 <ertes> because retrofitting efficiency is actually surprisingly difficult
21:46:08 <Cale> They don't give any sense of the more important goal: maintainability of large projects.
21:46:16 <ubsan_> and retrofitting correctness is even harder
21:46:46 <ertes> i get correctness mostly from the way i solve problems in haskell anyway, so i can focus on efficiency right away
21:46:52 <Cale> It's maintainability of large projects and especially team efforts where Haskell really begins to shine.
21:47:04 <ubsan_> Cale: looking at LLVM or servo, I'd argue that C++ and Rust also shine quite brightly there
21:47:04 <ertes> and for the difficult stuff i can always write a test suite
21:47:15 <mbw> Also, the stuff where C/C++ programs have been really optimized is making heave use of vector intrinsics, cache-line and register blocking, and all that other good stuff. Do you do that on a daily basis?
21:47:46 <ertes> in any case correctness has never been a real problem to me since i switched to haskell‚Ä¶  but efficiency is, and i will admit one thing:  it takes a bit of experience to come up with efficient code in haskell
21:47:54 <ertes> but i don't think it's any different in other languages
21:48:05 <Cale> ubsan_: Haskell's type system and referential transparency give it so many advantages over these.
21:48:21 <ubsan_> Cale: lifetimes and ownership
21:48:24 <ubsan_> lifetimes, and ownership
21:48:28 <Cale> First of all, in terms of being able to understand quickly how to use other people's code
21:48:42 <ubsan_> (and besides, Rust is basically referentially transparent)
21:48:53 <Cale> "basically" isn't good enough ;)
21:48:58 <ubsan_> yeah, it is
21:49:01 <ubsan_> lol
21:49:11 <mbw> So I guess we did "go there", after all :(
21:49:24 <ubsan_> the only things you can change are implementation details which you shouldn't be able to see
21:49:34 <ertes> ubsan_: lifetimes and ownership are actually easy in haskell
21:49:38 <ubsan_> for example, a function which takes a `T: Clone` can optimize for `T: Copy`
21:50:02 <ertes> you need to understand sharing, but if you do, then you have a pretty clear idea where your values are and when they will cease to exist
21:50:18 <ertes> (and you really need to understand sharing in haskell)
21:50:21 <Cale> But it's really hard to explain what I mean with small examples.
21:50:40 <Cale> Only experience can really be convincing here, I think.
21:50:54 <Cale> (because all the most convincing examples involve programs which are large)
21:51:32 <ertes> example:  let f x' = \y -> x + y where x = x'^100000000 in map (f 3) [1..10]
21:51:33 <nshepperd> ubsan_: er, lifetimes and ownership are only one feature
21:51:37 <Cale> I can give anecdotes, but I'm not sure how convinced you ought to be by them
21:51:42 <ertes> i *know* that 3^100000000 will be computed only once
21:51:49 <ertes> and will go away after the map
21:51:52 <nshepperd> there are lots of activities one needs to do in programming apart from managing resources O_O
21:52:09 <Cale> yes
21:52:22 <ubsan_> ertes: I'd rather it be brought explicitly into the typesystem
21:52:25 <nshepperd> anyway, I think we've probably had enough programing language wars for one night?
21:52:41 <ertes> yeah, i agree
21:53:14 <ubsan_> damnit, I do not understand bash
21:53:32 <Cale> If our programs only did a bunch of allocation and deallocation of memory, and didn't do anything very complicated aside from that, perhaps we would all be crazy to be arguing with ubsan_ 
21:53:59 <ubsan_> Cale: I'd argue you're far more crazy to be arguing with me *because* your programs do a lot more
21:54:32 <Cale> I don't have time to give a shit about memory management 99% of the time.
21:55:02 <monochrom> The huge overhead of crossing FFI barriers is why you would use a high-maintenance language for the whole program even though you just need its fine-control for just 1% of the whole program.
21:55:18 <Cale> and the remainder of cases are not so hard to deal with, but I don't want to be wasting time that could otherwise be spent actually delivering meaningful value to the client on that.
21:55:27 <ubsan_> Cale: ...right
21:55:28 <ubsan_> exactly
21:55:40 <Cale> So that's why I program in Haskell
21:55:41 <nshepperd> haskell's (or is it GHC's?) ffi is so awesome <3
21:56:02 <ubsan_> GC and C are not the only two choices~
21:56:03 <kadoban> monochrom: Is there actually a huge overhead in that? (or was that sarcasm?)
21:56:05 <Cale> Because it optimises the 99% case
21:56:16 <ertes> nshepperd: i'd say it's good enough‚Ä¶  i prefer not to have to use it
21:56:17 <monochrom> It is a huge overhead. I'm serious.
21:56:30 <mbw> Like, totally serious?
21:56:36 <ertes> nshepperd: to such an extent that i will rewrite C libraries in haskell
21:56:46 <Cale> (and doesn't screw us in the 1% case)
21:57:26 <ertes> hsc2hs helps a lot, but it comes with its own problems‚Ä¶  so far i haven't solved the interactive development problem
21:57:36 <monochrom> If you just need to cross the boundary once every 2 seconds, it's OK, that is no big deal.
21:57:46 <ertes> which is, BTW, one of the most important reasons for me not to use C++ or rust:  interactive development
21:57:54 <kadoban> It's pretty much when you need to do it in a "tight loop" I suppose?
21:58:24 <ubsan_> so, 792 msec, over 100 trials, for the idiomatic C++ version
21:58:25 <monochrom> But good luck with "the innermost loop makes an FFI call per iteration, just so to call a machine-code subroutine that runs for 10 clock cycles"
21:58:41 <Cale> ubsan: and the other versions?
21:58:43 <ertes> ubsan_: what about my C code?
21:58:46 <kadoban> Ah. Yeah that I'm not surprised is a bad idea.
21:59:01 <ubsan_> ertes: I haven't tried them yet
21:59:03 <ubsan_> one sec
21:59:45 <nshepperd> hopefully you're not calling the FFI in your inner loop, because the FFI function *is* the inner loop
21:59:50 <ertes> ubsan_: remember that the timings in the paste are from 2014 =)
21:59:57 <monochrom> So that means you will want the whole innermost loop to be written in machine code. But then maybe the innermost loop has to worry about memory management and I/O and this and that... Now all your Haskell benefits go down the drain.
22:00:06 <ubsan_> emm
22:00:13 <ubsan_> I think I have an off-by-two error?
22:00:37 <ertes> ubsan_: my code produces the correct result, based on a comparison with what PARI/GP says
22:00:47 <ubsan_> ertes: yeah, I'm not sure what's wrong
22:01:05 <mbw> monochrom: But if it does syscalls, I/O and the like, this will be the bottle-neck anyway.
22:01:14 <ertes> ubsan_: did you initialise the first two bits?
22:01:23 <ertes> ah, nevermind
22:01:26 <ubsan_> ertes: https://gist.github.com/ubsan/a771eb2ffeb4f13c854304e2b061ef5b
22:01:27 <ertes> you skip them anyway
22:01:54 <monochrom> Some basically I'm saying the possibility (hopefully you aren't that unlucky) that the 1% of your program that needs fine-control is highly infectious in terms of dictating what language you end up using. It can spread.
22:01:57 <ubsan_> oh, I see what we did
22:02:03 <ubsan_> I include 1, and you don't include 2
22:02:10 <ubsan_> I think?
22:02:17 <ubsan_> well, I do include 1
22:03:12 <ubsan_> oh yeah, you didn't include 2
22:03:35 <ubsan_> I see what's happening
22:03:36 * ubsan_ fixes
22:03:46 <mbw> Ok, but I thought we were all aware that the situation "call this one computation-heavy loop with 1e20 iterations via FFI and all is good" exists only in theory.
22:03:50 <ertes> ubsan_: hmm?  i think i do include 2
22:04:00 <ubsan_> ertes: I was including both 0 and 1
22:04:23 <ertes> ubsan_: are you sure?  i don't see that
22:04:34 <ertes> ah, yes
22:04:37 <ertes> you're using array.count()
22:04:49 <ertes> in that case you need to initialise the first two bits to 0 explicitly
22:05:17 <ertes> ubsan_: that has to be slower than my version, because you're doing an extra iteration at the end
22:05:23 <ubsan_> ertes: yeah
22:05:34 <nshepperd> mbw: usually I have more like 1e5 iterations
22:05:48 <nshepperd> a respectable loop
22:05:49 <ubsan_> about 45 msec difference
22:06:36 <ertes> ubsan_: i would expect the bool-vector version to be on par with my C version
22:06:44 <ertes> mostly do to aggressive inlining
22:06:48 <ertes> *due
22:08:01 <ertes> also remember that i used -O3 -funroll-loops, which gave it a *major* speed boost
22:08:08 <ubsan_> ertes: without the extra loops, it's 32 msec faster
22:08:13 <ubsan_> err, extra loop
22:08:56 <ubsan_> it's 4 msec faster with -funroll-loops
22:09:06 <mbw> Was it -O3 or -funroll-loops or both that gave the speed-up? I remember reading something on Agner's site in which he recommended not to unroll loops on newer cpus with uop caches.
22:09:30 <ubsan_> with -funroll-loops, they're the same
22:09:31 <ertes> mbw: both‚Ä¶  it was on an i5, but i can no longer tell which one
22:09:34 <mbw> But that was last year and probably referring to knight
22:09:37 <ubsan_> 785 msec per loop
22:10:00 <ertes> it was already a few years old at that point
22:10:14 <ertes> so -funroll-loops may indeed be harmful on newer CPUs
22:10:25 <ubsan_> > Failed to load interface for ‚ÄòData.Vector.Storable.Mutable‚Äô
22:10:28 <lambdabot>  <hint>:1:30: error: lexical error at character '\8216'
22:10:31 <mbw> It's probably not a b&w thing, anyway.
22:10:32 <ubsan_> ertes: ?
22:10:44 <ertes> ubsan_: you need the 'vector' library
22:10:44 <Cale> ubsan_: Have to install the vector package
22:10:55 <ertes> ubsan_: go into a new directory and type:  cabal sandbox init
22:11:03 <mbw> It's only Data.Array that ships with GHC.
22:11:11 * monochrom cringes. The world is getting exciting. Unrolling loops can be slower?! What has the world come to?!
22:11:20 <ertes> ubsan_: then (in the same directory):  cabal install vector
22:11:27 <Cale> monochrom: haha
22:11:31 <mbw> I probably should look for the link to back that up :)
22:11:50 <monochrom> Next you're going to tell me procedure calls are cheaper than gotos.
22:12:05 <ertes> ubsan_: then use the following command:  cabal exec ghc -O2 ‚Ä¶
22:12:21 <ubsan_> I'll also do this same thing with Rust
22:12:27 <ertes> ubsan_: when you're done, you can just delete that directory, and everything will go away
22:12:33 <ubsan_> ertes: nice
22:12:39 <ubsan_> although I wish every language had cargo
22:12:42 <ertes> that's GC for you =P
22:12:56 <ubsan_> that is *so* manual memory management :P
22:13:12 <ertes> ubsan_: if you want it to be actual GC, use nix instead of cabal-install =)
22:13:24 <ubsan_> ertes: ugh, nix -.-
22:13:24 <ertes> but i don't want to impose another learning curve on you ;)
22:13:36 <ubsan_> nix is very weirdly popular in the rust community
22:13:59 <Cale> Nix is amazing when you have other people around to configure it on your behalf.
22:14:07 <monochrom> heh
22:14:07 <ubsan_> lol
22:14:31 <mbw> here: http://www.agner.org/optimize/blog/read.php?i=165
22:14:32 <monochrom> I guess we still need to hire sysadmins.
22:14:43 <Cale> I couldn't use it for my personal machines though
22:14:58 <Cale> But it's really nice for work projects
22:15:07 <mbw> A more general treatment is given here:http://www.agner.org/optimize/microarchitecture.pdf . It basically just boils down to not unrolling unnecessarily.
22:15:17 <ertes> well, nix is just a magical experience, literally‚Ä¶  every machine i come in contact with suddenly has a /nix directory appearing out of nowhere
22:15:26 <Cale> Never having to worry about whether I have the right versions of things, having super easy automated deployments to AWS, and so on.
22:16:06 <ertes> it's also nice for personal things‚Ä¶  if only not to have to be root to install stuff
22:16:15 <ubsan_> ertes: that's why I use brew ;)
22:16:20 <ertes> but it really shines for development and deployment
22:16:26 <ubsan_> but also, -fllvm is being annoying
22:17:00 <ertes> ubsan_: take brew, generalise it to *everything*, add a bunch of handy features, and you have nix‚Ä¶  and a life-long learning curve to climb =)
22:17:12 <ubsan_> ertes: yeah, yeah, I've gotten the sales pitch
22:17:15 <Cale> Nix' language should just be Haskell
22:17:28 <Cale> Here's what the plan should be:
22:17:41 <ubsan_> why doesn't ghc work with llvm 3.8 :[
22:17:46 <mbw> So basically it's about as complex as git, and people use 1% of it?
22:18:00 <Cale> 1) Write a Haskell combinator library which does the same thing as Nix.
22:18:29 <ertes> ubsan_: usually when i get a message like that i interpret it as: "dude, update your GHC already!"‚Ä¶  and usually my interpretation is correct =)
22:18:30 <Cale> 2) Write an interpreter/compiler for Nix expressions which translates them into the Haskell combinator library and allows .nix files to be used.
22:18:39 <Cale> 3) Gradually port nixpkgs.
22:18:48 <ubsan_> ertes: without -fllvm, it's .3 seconds slower
22:18:51 <ertes> Cale: unfortunately nix has magic
22:18:55 <mbw> ertes: No, the newest GHC also only supports 3.7 iirc.
22:19:02 <ertes> Cale: and nixpkgs uses that magic
22:19:07 <ubsan_> I don't feel like dealing with llvm + ghc things right now
22:19:11 <Cale> What do you mean by magic?
22:19:11 <ubsan_> ertes: could you do it for me?
22:19:35 <ertes> Cale: stuff you would need TH for
22:19:37 <tswett_to_go> I've been pondering the idea of making Haskell code callable from .NET code. There are two "obvious" ways to do it.
22:19:40 <ertes> Cale: like callPackage
22:19:50 <ertes> ubsan_: let me check
22:20:01 <tswett_to_go> One, compile the Haskell into .NET IL. Two, compile the Haskell into an ordinary library and write a .NET wrapper around it.
22:20:07 <ubsan_> the C++ should be done with `-O3 -std=c++14`
22:20:15 <ertes> hmm‚Ä¶  i have LLVM 3.9
22:20:23 <ertes> but let me try anyway
22:20:47 <ertes> You are using an unsupported version of LLVM! Currently only 3.7 is supported.
22:20:49 <ertes> nope, sorry
22:20:51 <tswett_to_go> I wonder how hard it would be to do a sort of middle ground.
22:20:57 <Cale> ertes: Well, it wouldn't bother me too much to have the interpreter interpret into IO actions.
22:21:08 <Cale> (or stuff involving them)
22:21:14 <tswett_to_go> Compile the Haskell into machine code but have it somehow use the .NET runtime system instead of the usual Haskell one.
22:21:23 <monochrom> middle ground is usually worst of both worlds...
22:21:47 <ertes> @remember monochrom middle ground is usually worst of both worlds...
22:21:47 <lambdabot> Okay.
22:21:55 <monochrom> hehe
22:22:09 <tswett_to_go> Well then, just go with the opposite middle ground. Compile it into .NET IL, but have it use the usual Haskell runtime system instead of the .NET one. :D
22:22:35 <ertes> tswett_to_go: at least that would allow .NET languages to have a type system
22:22:46 <monochrom> I think "somehow use the .NET runtime" is a lot of upfront investment.
22:23:16 <mbw> It's the "draw the rest of the owl" part.
22:23:21 <monochrom> I mean after you finish, I'm sure I'll benefit too, but oh boy will it take you 6-12 months.
22:24:00 <ertes> i think luite is crazier than that‚Ä¶  GHCJS is black magic
22:24:26 <monochrom> See what I mean by "1% of your program can contagiously dictate what language to use for the other 99%"? :)
22:24:54 <ertes> i thought that compiling GHC-haskell to JS was pretty much impossible for one person to do
22:25:17 <monochrom> Or at least "the FFI boundary is an annoyingly high overhead"
22:25:30 <Cale> ertes: Luite didn't know as well as you how hard it was
22:26:42 <ertes> in the sense that the bumblebee shouldn't physically be able to fly, but it doesn't know that, so it flies anyway?
22:26:43 <Cale> monochrom: At first I thought you were talking about runtime performance, but that interpretation makes a good deal more sense.
22:26:58 <ertes> (yes, i know that it's a misconception)
22:27:11 <monochrom> I was talking about runtime performance.
22:27:29 <monochrom> But I guess it generalizes too.
22:30:03 <ubsan_> man, Rust does not have a good bitset library
22:30:19 <Cale> For the runtime performance case, usually what appears to happen is that after having recognised the problematic situation, people break the abstraction barrier for a bit and work on new primitives for the high level language with which they can solve the problem effectively. ByteString is my favourite example of that -- it made a lot of things which were possible but generally infeasible in Haskell easy.
22:30:46 <monochrom> Yeah that's true.
22:31:29 <ertes> ubsan_: you mean i get to complain about how ugly your rust code is, and that it doesn't look like rust at all? =P
22:32:08 <ubsan_> ertes: lol, I'm just not gonna write it in rust
22:32:23 <ubsan_> rust seriously needs more generic programming
22:32:40 <Cale> Rust is the clear winner in this contest
22:32:42 <ertes> ubsan_: you should be able to translate the C version easily
22:32:55 <Cale> For having avoided it altogether
22:33:01 <ubsan_> ertes: yeah, but laaazy
22:33:11 <monochrom> Haha, was going to ask you if you meant that. :)
22:33:13 <ertes> too bad‚Ä¶  i would have liked to see how well rust does
22:33:22 <ubsan_> ugh, fiiiine
22:33:40 <ertes> wasn't that a fine piece of social engineering‚Ä¶
22:41:27 <mbw> Doesn't seem to be a productive language...
22:43:37 <ubsan_> mbw: well, this is not a strong area of Rust
22:43:50 <ubsan_> I basically have to use C
22:44:06 <tswett_to_go> I'm looking to see, if I wanted to modify GHC to compile to .NET IL, how far back in the process would I have to go...
22:44:18 <mbw> I'd just have said "it's still compiling" :)
22:44:56 <mbw> But then on the other hand, it won't be "idiomatic rust" I guess?
22:47:10 <tswett_to_go> Looks like the process is: text gets converted to a parse tree, that gets converted into Core, then STG, then C--.
22:48:08 <geekosaur> that's probably where you would do it. I'm given to understand the complex part is that .NET languages are expected to be able to activate each others' objects... which isn't even well defined in Haskell
22:48:33 <tswett_to_go> Which place is "that"?
22:49:07 <geekosaur> (there are a lot of .NET libraries you will not be able to interoperate with if you don't have objects that can communicate with other .NET objects. (COM?))
22:49:26 <geekosaur> usually after Cmm (which is not quite the same as C--)
22:49:56 <tswett_to_go> I mean, the fact that .NET languages can talk to each other's objects isn't much different from the fact that different .so libraries can call each other's functions and pass pointers between each other.
22:50:14 <ubsan_> ertes: https://gist.github.com/ubsan/a771eb2ffeb4f13c854304e2b061ef5b
22:50:58 <ertes> ubsan_: that's C++‚Ä¶  wrong link?
22:50:58 <geekosaur> it is, actually; cross-shared object calls are a simple low level interface, COM is a high level interface with complex underpinnings
22:51:20 <ubsan_> ertes: I put rust there too
22:51:36 <tswett_to_go> I'm not talking about COM, though, or any kind of IPC.
22:52:19 <spatial> I thought I can read and write to an array and return in like this http://lpaste.net/353699
22:52:42 <ubsan_> ertes: within 10 ms
22:53:02 <ubsan_> (it's 10 ms faster, but I'll chalk that up to variance)
22:53:11 <spatial> Is that right ? I don't find the written values.
22:53:55 <mbw> What does println!("{}"...) do?
22:54:04 <ubsan_> mbw: it prints :)
22:54:19 <mbw> yeah, but what does the exclamation mark do, and "{}"?
22:54:25 <mbw> I didn't run it.
22:54:26 <kadoban> {} is a format specifier, like %d, except not
22:54:34 <kadoban> the ! means it's a macro
22:54:49 <kadoban> It's part of the name
22:54:55 <ubsan_> kadoban: no it isn't
22:54:59 <mbw> ah, so it's a convention?
22:54:59 <ubsan_> it's a part of the invocation
22:55:15 <cocreature> spatial: where are you writing to the array? I don‚Äôt see it in your code
22:55:28 <ubsan_> the name of the macro is "println", the invocation is "!(...)", "!{...}", or "![...]"
22:55:31 <tswett_to_go> Anyway, if you "truly" compile Haskell to .NET, you'll probably want to represent Haskell types with .NET types which are as close as possible.
22:55:44 <cocreature> spatial: also returning the same IOArray that you get passed in is not useful. it‚Äôs a mutubale structure so the reference the caller passed in will just be updated
22:55:47 <kadoban> *shrug* I don't know rust especially well
22:55:53 <mbw> get_unchecked_mut I guess
22:56:04 <ubsan_> mbw: huh?
22:56:05 <spatial>      (nv,a) <- nextvalue player x a state  should have written to it and returned.
22:56:17 <tswett_to_go> Represent "Maybe String" as... Haskell.Maybe<Haskell.List<Haskell.Char>>
22:56:24 <mbw> Was referring to cocreature's question.
22:56:32 <mbw> oh wait
22:56:42 <ertes> thank you
22:56:45 <ubsan_> lol
22:56:59 <cocreature> spatial: how are you checking whether the values have been written?
22:57:22 <ertes> ubsan_: so it's 10 ms faster than C/C++?
22:57:39 <ubsan_> ertes: yeah, but I think that might be printf?
22:57:45 <ubsan_> I'm gonna test it again with rust using printf
22:57:55 <tswett_to_go> spatial: well, you're using one variable name to refer to two separate things. It would be less confusing if you wrote (nv,b) instead of (nv,a) and then used b instead of a on lines 11 through 14.
22:58:05 <mbw> Or just disable sync_with_stdio
22:58:30 <ertes> ubsan_: printf shouldn't really make a measurable difference
22:58:43 <spatial> So assume this is alright. Will change reference names.
22:59:30 <ahri> i have a "State" type for my game, and there are so many times when i come to write a bit of code to alter the state that i think "this only affects players, so i'll write it like: doSomething (State blah players) = State blah (somefunc players)" and that works for a while, until suddenly that somefunc turns out to need to alter the "blah" in there too. so i end up changing somefunc from "somefunc :: 
22:59:36 <ahri> [Player] -> [Player]" to "somefunc :: State -> Player -> State", so that i can search through the players, alter the right one, and alter the "blah" too, returning State as a whole. is this a normal process that more experienced Haskellers go through or am i being a dumb newbie?
22:59:43 <ubsan_> ertes: looks like they're all within 50 msec
22:59:50 <spatial> cocreature: Trying to print it. But thought code has semantic \issues.
22:59:50 <ubsan_> depending on how I play with stuff
23:00:02 <ubsan_> as I keep running it
23:00:22 <ubsan_> but I think C++ is the clear winner here
23:00:28 <cocreature> spatial: the main issue is imho that you are returning the array. that makes no sense unless you are creating a new array instead of just modifying the one that is passed as an argument
23:00:32 <ubsan_> because that code is actually nice to read lol
23:00:58 <geekosaur> ahri, at some point new Haskellers discover the State monad
23:00:59 <ertes> ahri: refactoring is of course normal, and you will need to do it in haskell as well
23:01:02 <Cale> ahri: In the large, the fact that the compiler helps you so much to make refactors when your expectations about the data model change is very helpful.
23:01:21 <spatial> cocreature: It is supposed to be mutable. It can't be ?
23:01:53 <tswett_to_go> spatial: an IOArray is mutable, but your code isn't attempting to mutate it.
23:01:56 <cocreature> spatial: it is mutable. what I‚Äôm saying is that returning the array after you mutated it is not useful since it‚Äôs still the same array that you got as an argument
23:02:06 <ertes> ahri: but it happens less often as you get better at haskell, and you will find ways to make your code more future-proof
23:02:26 <tswett_to_go> cocreature: I don't think it's the same array; the "a" which is returned isn't the same "a" as the argument.
23:02:39 <laudiacay> hey, does anyone have good resources about http things in haskell
23:02:48 <ahri> i get that refactoring is normal, but i'm sometimes torn between whether to just change to "somefunc :: [Player] -> ([Player], Blah)" out of laziness... but i think it's more readable to just deal with my State type
23:02:56 <spatial> tswett_to_go: I thought so too.
23:03:11 <laudiacay> also, TCP/IP operations (like making and sending packages to various IPs sorry i really don't know what im talking about but would like resources)
23:03:20 <cocreature> tswett_to_go: hm I guess it depends on the behavior of nextvalue. however, I would be surprised if it creates a new array. that kind of defeats the purpose of having a mutable array
23:03:34 <Cale> ahri: Also, if the common case is that most operations only act on players in some uniform way and don't touch the rest of the state, you might want to maintain that Player -> Player type for the functions which don't need anything more
23:03:40 <ertes> ahri: generally it pays off to combine data into smaller units
23:04:01 <Cale> ahri: Even if they ultimately get used by something of a more general type, this makes them individually easier to understand and test.
23:04:05 <ertes> ahri: i think that was misleading
23:04:11 <spatial> Let me debug some more as code semantics is ok.
23:04:17 <ertes> ahri: i meant it this way: smaller units are better than larger ones
23:05:44 <ahri> ertes: yeah, this is why outputing a tuple seems better in some ways; without access to the rest of the stuff in State i'm less likely to make a mistake in my code. but having this intermediate type (the tuple) that i then have to grab values out of via fst/snd is not particulrly nice to read
23:06:15 <Cale> ahri: Note that, for example, if it's common to just do something to all the Players
23:06:28 <ertes> ahri: you can just pattern-match
23:06:38 <ertes> ahri: let (y1, y2) = f x
23:06:40 <Cale> You can write a function (Player -> Player) -> ([Player], State) -> ([Player], State)
23:07:07 <Cale> (and really, you should define some data type for your complete game state -- it's important enough not to use pairs for that)
23:07:13 <mbw> that seems like something you could use mapAccum for.
23:07:23 <ertes> ahri: and yes, mapping functions are very useful
23:07:26 <Cale> Not even mapAccum
23:07:30 <ertes> ahri: (what Cale said)
23:07:35 <Cale> Just map -- it doesn't touch the State
23:07:40 <mbw> ah ok
23:09:01 <mbw> Then that function signature is confusing :)
23:09:45 <Cale> Well, if it was (p -> p) -> ([p], s) -> ([p], s)  you wouldn't expect it to affect the s part ;)
23:09:52 <Cale> But yeah
23:10:00 <spatial> Can I print in terminalstatep :: ( IOArray Int Double) -> Int -> IO Bool ?
23:10:41 <ahri> Cale: perhaps i've confused the issue; in my case i'm not using the State monad; State is my own type representing my whole game state
23:11:04 <Cale> ahri: I understood this by the fact that you weren't applying State to anything :)
23:13:34 <ertes> ahri: you should probably pick a different name anyway
23:13:41 <ahri> i was actually unaware that i could use 'let' for pattern matching, i had only used it in ghci
23:13:55 <ahri> ertes: yeah, i'll swap to GameState to avoid confusion
23:14:08 <ertes> ahri: you can pattern-match almost everywhere
23:15:27 <mbw> I thought "AppState" was what the cool kids are using.
23:15:41 <tswett_to_go> Can you have a statement like "(x,y) = (1,2)" at the top level?
23:15:50 <ertes> tswett_to_go: yes
23:16:34 <ertes> @let xs :: [Integer]; xs@[x1, x2, x3] = [2, 3, 5]
23:16:36 <lambdabot>  Defined.
23:16:39 <ertes> > x2
23:16:41 <lambdabot>  3
23:16:43 <ertes> @undef
23:16:43 <lambdabot> Undefined.
23:20:05 <spatial> What does this do ? do {      ; putStrLn $ "Is it a terminal step ?"      ; return result     }
23:20:23 <spatial> Semicolon
23:20:46 <spatial> I mean. It prints.
23:21:45 <Cale> spatial: Empty statements are discarded.
23:21:58 <Cale> It does the same thing as if that semicolon weren't there
23:30:27 <kshukla> I am trying to store input lines in a list then print the list: http://lpaste.net/353701 . "EOF" is the last line. I am not gettin any output. What am I doing wrong?
23:36:02 <geekosaur> when you rerun main, it gets a new "list" initialized to []
23:36:23 <geekosaur> you need to rewrite this so you can pass the current list to the recursive function
23:37:09 <mbw> kshukla: This should give you name-shadowing warnings with ghc -Wall
23:38:43 <mbw> Although that's probably not the definitive hint here. Like geekosaur said, main is a function of type "main :: IO ()", i.e. it does not actually take any arguments. You would need a function of type fun :: [String] -> [String], for example.
23:39:09 <geekosaur> I should have said "makes" instead of "gets"
23:39:20 <geekosaur> it does not inherit the old one, but creates a new one
23:39:23 <mbw> Or rather [String] -> IO [String]...
23:39:58 <mbw> also geekosaur, what is that <<loop>> error I encounter when trying to run this interactively?
23:40:24 <mbw> I'm sure I've read about this before, on the ghc site.
23:41:19 <geekosaur> right, line 8 doesn't do what you think
23:41:36 <geekosaur> 1. bindings are not mutable. The "list" on the left side is a *new* binding unrelated to the old
23:41:57 <geekosaur> 2. the "list" on the right side of the = is the same one as on the left
23:42:19 <geekosaur> and trying to bind something to an expression starting with itself is left recursion and will generate <<loop>>
23:42:27 <mbw> ah, so it's a let x = x in x kinda thing?
23:42:31 <geekosaur> exactly
23:42:47 <mbw> The error output could be more conclusive lol
23:43:29 <mbw> Or maybe that is not easy to implement? Because of indecidability or something?
23:43:55 <mbw> *undeci...
23:44:00 <geekosaur> usually that's all it knows; the STG reducer puts a placeholder into the thunk being evaluated which does (error "<<loop>>"), which will be thrown if the expression is re-entered during reduction
23:44:18 <geekosaur> this happens at runtime; the compile time information to say anything more no longer exists
23:44:43 <Cale> If you compile with profiling, you might get more
23:45:22 <mbw> That might also be an opportunity to test the new DWARF debug data that ghc seems to be able to create now.
23:46:43 <mbw> No such luck with gdb/-g.
23:46:51 <mbw> I'm probably doing it wrong.
23:47:43 <geekosaur> I think it's still not fully impleented; I recall more complete support being an 8.2 thing
23:48:34 <geekosaur> also, iirc there is an open stack bug report because it strips binaries and has no way to prevent it
23:50:41 <mbw> That's a problem. Also, compiling with -prof -auto-all and running via ./BinaryName +RTS -p doesn't change the output either.
23:51:20 <Cale> Try +RTS -xc
23:51:29 <kshukla> How to store input line by line in a list?
23:52:58 <mbw> Cale: This produces *** Exception blah bla stack trace \n Main.main.list,\n called from Main.main etc.
23:53:08 <mbw> Seems to be the way to go.
23:54:00 <mbw> kshukla: You can just use readFile, and then lines, which will split at the newline character.
23:54:05 <Cale> kshukla: There are a bunch of ways -- you can write something like  do xs <- getContents; ...  and then apply the lines function to xs to split it
23:54:32 <mbw> getContents reads from stdin.
23:54:37 <Cale> yeah
23:54:55 <Cale> You could write a recursive function which takes the list of lines seen thus far (probably in reverse order) and accumulates them
23:55:19 <Cale> (and uses getLine)
