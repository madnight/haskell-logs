00:10:02 <AndChat181649> any1 here
00:12:40 <cocreature> AndChat181649: lots of people are, just ask your question and stick around for a bit
00:17:35 <iqubic> Why am I awake at midnight?
00:17:47 <halogenandtoast> Because you're not alseep at midnight.
00:17:51 <halogenandtoast> *asleep
00:18:31 <iqubic> yes, but why? My school starts in a week, and I should get a better sleep cycle
00:18:37 <halogenandtoast> If I want to represent a map with areas adjacent to other areas should that just be a list of vertexes?
00:18:50 <iqubic> yes.
00:18:56 <iqubic> I believe so.
00:19:08 <halogenandtoast> and the vertexes should be tuples of areas?
00:19:45 <iqubic> Just imagine that you put a point in the middle of each area, you can connect those with vertices to show adjacency.
00:31:04 <tsahyt> After changing the cabal file to include a new package, is there some way to get ghci back on track without restarting it? I'm using stack if that makes a difference.
00:31:58 <cocreature> tsahyt: you could try ":set -package packagename" but even if that works it will reset a bunch of stuff so that you don’t gain anything over restarting
00:34:04 <tsahyt> hm, yeah that's what I thought. okay, thanks
00:39:32 <jle`> halogenandtoast: i think the mathematical structure you are thinking of is a 'graph'
00:39:50 <jle`> and a list of vertices is a common representation for graphs
00:43:26 <[exa]> what's the best way to typeset >>= in TeX?
00:44:10 <[exa]> (currently using \gg for >>)
00:45:01 <cocreature> [exa]: just use ">>=" verbatim in some code environment
00:45:40 <cocreature> I hate documents that use weird unicode representations for symbols in programming languages
00:47:12 <bvad> cocreature: I had to use a specification language at university where the book only contained the unicode reps, so when you actually had to write code in it you had no idea of knowing how to actually write it...
00:48:59 <[exa]> cocreature: well I'm trying to get it more math-like but the argument makes sense, will think about that :]
00:50:16 <cocreature> [exa]: math-like is fine if you’re talking about things on some abstract level. but if you are talking about actual code, then trying to make that more math-like is just silly
00:52:26 <dtornabene> quick question about some old code from Graham Huttons first "Programming in Haskell" book
00:54:17 <dtornabene> this code is throwing understandable infix errors https://dpaste.de/tSP5
00:55:10 <dtornabene> as in, can't use gte and lte both in the same line, my question is, how can (or even just, can I) I make this code compile, i tried parens to no avail
00:55:43 <cocreature> dtornabene: what is (^) supposed to be? conjunction?
00:56:00 <mud> dtornabene: Can't imagine that's supposed to be a ^, it's probably supposed to be &&, on in math notation it'd be the bigger triangle thing for conjunction, yeah.
00:56:23 <cocreature> another reason why books trying to use math notation for code is silly :)
00:57:24 <ventonegro> Very common in published papers :(
00:57:40 <dtornabene> cocreature: yes, exactly
00:59:12 <dtornabene> specifically i tried grouping the two sub expressions in parens and taking the conjunction of the two, ghci didn't like it
00:59:26 <cocreature> dtornabene: what did you use to take the conjunction of the two?
00:59:45 <cocreature> dtornabene: (^) is exponentiation of numbers not conjunction of booleans
01:00:16 <cocreature> > let isDigit c = c >= '0' && c <= '9'
01:00:18 <lambdabot>  <no location info>: error:
01:00:18 <lambdabot>      not an expression: ‘let isDigit c = c >= '0' && c <= '9'’
01:00:22 <cocreature> > let isDigit c = c >= '0' && c <= '9' in isDigit 3
01:00:27 <lambdabot>  error:
01:00:27 <lambdabot>      • No instance for (Num Char) arising from the literal ‘3’
01:00:27 <lambdabot>      • In the first argument of ‘isDigit’, namely ‘3’
01:00:35 <cocreature> > let isDigit c = c >= '0' && c <= '9' in isDigit '3'
01:00:37 <lambdabot>  True
01:00:46 <tsahyt> cocreature: but then I'd typeset a ^ b, as a with b as superscript
01:00:54 <ski> @type isDigit
01:00:56 <lambdabot> Char -> Bool
01:00:56 <tsahyt> that's commonly understood as exponentiation
01:01:14 <dtornabene> oh wow, i didn't know lambdabot could do that!
01:01:17 <dtornabene> thank you!
01:01:26 <cocreature> tsahyt: not sure what point you are trying to make
01:02:02 <tsahyt> cocreature: that there's a way to typeset things in a mathy fashion without ambiguity
01:02:18 <tsahyt> then again I only glanced at the conversation, so I might be just rambling randomly
01:03:02 <cocreature> tsahyt: I’m not saying you can’t typeset things in a mathy fashion without ambiguity. I’m saying that you are going to confuse people if you invent your own mathy symbols for things that already exist in programming languages under different symbols
01:03:32 <tsahyt> cocreature: I'd say that the prettified symbol for e.g. >>= is extremely common in Haskell related papers. it's not confusing imo.
01:03:52 <tsahyt> I mean sure if you just make stuff up as you go, that might be bad, but there are some well established conventions too
01:04:07 <cocreature> a prettified symbol for >>= is not that badbut if you use ∧ instead of && that’s bound to confuse programmers.
01:04:22 <cocreature> sure you can take the elitist approach and say that programmers shouldn’t read your papers anyway but that sucks
01:04:26 <mud> At least prettified >>= still looks like >>=
01:04:35 <dtornabene> cocreature: thank you very much, the symbols and font that Hutton uses in PiH I is more math-y, not the actual symbols used by ghc
01:05:42 <tsahyt> cocreature: I suppose as a rule of thumb the symbol should be identifiable as the glyphs it is supposed to represent
01:06:01 <tsahyt> personally I wouldn't be thrown off by /\, but I suppose some people might, yeah
01:07:22 <cocreature> well, apparently it was confusing for dtornabene 
01:07:27 <tsahyt> on the other hand /\ is such an incredibly common symbol, I don't think it's too much to ask of a reader to know what it means. it's all over boolean algebra, which is a topic that every programmer really should know about at least superficially.
01:07:52 <cocreature> but why should you use some weird math symbols if you’re displaying Haskell code
01:07:57 <cocreature> it just doesn’t make sense
01:08:00 <mud> tsahyt: But how would you know what it corresponds to in a particular programming language without being told?
01:08:44 <mud> It could be and, &&, actually /\, the symbol for that, some other random thing. It's just not that helpful even if you do know what it means.
01:10:51 <cocreature> if you diverge from the symbol used in the programming language, you should have a good reason to justify that and I don’t see that reason for ∧ over && apart from satisfying the urge that you really want to be a mathematician and not a computer scientist
01:10:59 <ski> @type (.&.)
01:11:01 <lambdabot> Bits a => a -> a -> a
01:11:20 <tsahyt> cocreature: I'd call it the urge to be a computer scientist and not a programmer
01:11:42 <cocreature> if you’re a computer scientist and you can’t handle (&&) then all hope is lost
01:12:08 <ski> what if you're a theoretical computing scientist ?
01:12:12 <ski> (only)
01:12:35 <cocreature> ski: if you are only a theoretical computing scientist, write pseudocode instead of Haskell code
01:13:02 <cocreature> this is about using math symbols if you are displaying code in real languages
01:13:18 <ski> fair enough
01:14:41 <cocreature> or at least mention somewhere that you are not using the standard symbols for the purposes of presentation instead of doing that silently
01:16:00 <dtornabene> cocreature: Hutton, as i understand it is a Computer Scientist but the text book (so far) has been written in a mix of math-y (logic, really) and actual syntax. Its definitely a little weird
01:16:19 <tsahyt> dtornabene: what book is that?
01:16:23 <dtornabene> I read a lot of math and CS books and I've never seen anyone do that before
01:17:02 <tsahyt> nvm, found it in the backlog
01:17:04 <dtornabene> tsahyt: https://www.amazon.com/Programming-Haskell-Graham-Hutton/dp/0521692695
01:17:35 <cocreature> I don’t think a book called “Programming in Haskell” has a good excuse for not using the standard Haskell symbols
01:17:45 <dtornabene> i agree!
01:18:24 <dtornabene> a bit taken aback that he used a symbol for exponentiation in the language for conjunction on the page, how strange!
01:18:57 <tsahyt> I'm partial to how code is typeset in richard bird's pearls of functional algorithm design
01:18:59 <dtornabene> but *shrug*, luckily you fine folks were here to help clear it up, thanks again, much appreciated
01:19:05 <tsahyt> I can't help it, I like nice typesetting
01:19:33 <dtornabene> i was *this close* to moving to his Thinking Functionally with Haskell, which I probably still will soon
01:20:25 <tsahyt> as a book to learn haskell with, Haskell Programming from First Principles is currently the most recommended one from what I can tell
01:20:37 <tsahyt> it's quite extensive
01:22:17 <Athas> I hear it's quite chatty and verbose, but I haven't read it yet.
01:22:26 <Athas> I like the new edition of Programming in Haskell pretty well.
01:23:00 <tsahyt> Athas: at over 1000 pages I bet it is, but that's not necessarily a bad thing for newcomers. It really depends on what kind of learner you are.
01:24:00 <tsahyt> I am looking forward to the intermediate and above level books that are in the works. The joy of haskell, and there was also some other one.
01:26:22 <Athas> Me too.  I have the impression that my own Haskell is quite old-fashioned.  I hope I can pick up some tricks.
01:27:15 <cocreature> Athas: easy, just vomit lens all over your code and it can be considered modern :)
01:28:19 <Athas> cocreature: I've considered it!
01:28:22 <pja_> cocreature: Ew.
01:28:45 <Athas> I have some places where I do essentially nested record updates, which is a little awkward without lens.
01:29:00 <cocreature> pja_: is that the sound of you vomiting lens over your code? :)
01:29:23 <pja_> cocreature: :)
01:29:37 <pja_> nb Are there any recommended intermediate Haskell texts these days?
01:29:50 <cocreature> “lens: come for the nested record updates, stay for Control.Lens.Plated and partsOf”
01:29:50 <pja_> Athas: 
01:29:56 <bobismijnnaam> hey guys, I have a design question if that's okay. i'm working on a toy compiler and I need to incorporate compile options into the pipeline (think -O2 et al.). my first thought was that the reader monad is a perfect fit. however I already use this here and there in the pipeline.
01:30:32 <bobismijnnaam> I'm not sure how well stacking identical monad transformers work, so I figured I'd factor/combine basic functionality (a la reader for compile options and either for error reporting) into my own monad, which then frees up all the basic monad transformers for other things.
01:30:36 <pja_> Athas: nested record update syntax is painful, agreed. I can't help but feel that records in general are a wart.
01:31:16 <Athas> pja_: Haskell records are totally a wart.  Like the module system, they were designed as the simplest serviceable thing, in the hope that something better would come along eventually.
01:31:24 <bobismijnnaam> (I read somewhere that GHC does this too) however, then I have to implement/maintain my own monad (transformer?). what do you guys think?
01:32:19 <cocreature> bobismijnnaam: stacking Reader works in principle but if you are using "mtl"-style typeclasses like MonadReader it doesn’t work anymore
01:32:21 <Athas> bobismijnnaam: you can define your own monad that as a mere 'newtype' wrapper around Reader.  Then define functions 'askOptEnv', 'askSomeOtherEnv', 'askTheThirdEnv' and so forth for projecting parts of the reader context.
01:32:49 <Athas> You can also define type classes 'HasOptEnv', 'HasSomeOtherEnv', etc. that define those methods.  That's a fairly common design.
01:32:51 <cocreature> usually "Reader (a,b)" works better than nesting Reader
01:33:02 <bobismijnnaam> cocreature: not using the typeclasses approach since I couldn't grok that. I guess I'll stay away from it then, stacking readers seems elementary to me
01:33:14 <pja_> On modules: has anyone got any comments (+ or - ) on backpack? Is it the “right thing”?
01:33:16 <bobismijnnaam> interesting
01:33:47 <Athas> pja_: Backpack is not the right thing from a clean slate perspective (maybe ezyang disagrees), but it is a good solution to real and current Haskell engineering issues.
01:33:48 <bobismijnnaam> Athas: that sounds like a good option.
01:34:28 <Athas> bobismijnnaam: there is conceptually nothing harmful about stacking Reader (unless you try to define duplicate MonadReader instances), but you really want to encapsulate them so you don't have to manually lift all your 'ask's.
01:35:28 <pja_> Athas: fair. I should get round to having a proper look at it.
01:36:04 <Athas> pja_: if you're lucky, you'll be able to benefit from it without having to actually understand it.  It's not really directly useful for application-level programming.
01:36:26 <bobismijnnaam> can I also newtype a monad transformer? I'd like my "new" monad to be composable with other monads. or does it have to be a base monad if I want to newtype it?
01:36:43 <Athas> bobismijnnaam: no, you can do it with a monad transformer as well.
01:36:54 <bobismijnnaam> cool. time to get hacking, thanks
01:37:12 <Athas> Good luck!
01:39:59 <pja_> Athas: it does seem a tad...hacky.
01:42:02 <Athas> pja_: yes.  It has to work within the constraints of a twenty year old language, _and_ its package management library.
01:42:34 <Athas> That's why I'm saying it's the best solution to the problem we have, but not likely not what you'd have designed from the start.
01:54:17 * hackagebot full-text-search 0.2.1.4 – In-memory full text search engine – https://hackage.haskell.org/package/full-text-search
02:10:18 <ertes-w> lo
02:18:04 <halogenandtoast> 'jle yeah, still trying to model it though
02:18:22 <halogenandtoast> jle`: no idea how I got the ` wrong
02:18:50 <halogenandtoast> It is a graph (an unweighted one at that). Just haven't used any graphs since college.
02:19:07 <halogenandtoast> Wondering if using Data.Graph makes sense
02:19:22 <halogenandtoast> but in Data.Graph a vertex is just an Int
02:19:53 <halogenandtoast> But the Graph is a Table aka (Array Vertex a) and [Vertex]
02:21:02 <halogenandtoast> which I think makes sense, but the functions for building graphs don't have a good way of specifying the table
02:21:29 <halogenandtoast> which kind of suckx
02:21:31 <halogenandtoast> *sucks
02:22:14 <halogenandtoast> oh nevermind its not a table and [Vertex] it's a Table [Vertex]
02:22:15 <halogenandtoast> derp
02:28:07 <AndChat181649> hey
02:28:10 <AndChat181649> any1 here
02:28:13 <AndChat181649> need help asap.
02:36:22 <testchan> AndChat: what help do you need ?
02:42:51 <tsahyt> is there some way to generate lenses that are only getters?
02:44:24 <tdammers> http://hackage.haskell.org/package/lens-4.15.4/docs/Control-Lens-Getter.html#t:Getter
02:44:58 <tdammers> tsahyt: ^
02:45:15 <tdammers> :t to
02:45:16 <lambdabot> (Functor f, Contravariant f, Profunctor p) => (s -> a) -> Optic' p f s a
02:45:17 <tsahyt> tdammers: yes that's what I want makeLenses to generate
02:45:25 <tdammers> oh right
02:45:48 <bartavelle> tsahyt: why not just use "to" with standard getters ?
02:46:19 <tdammers> why is it important for the generated lenses to only be getters?
02:46:45 <tsahyt> just a matter of information hiding. it's a read only data structure, I want no way to change it.
02:47:01 <bartavelle> dictator!
02:47:25 <tsahyt> bartavelle: it's more that I anticipate my own future stupidity
02:47:30 <tsahyt> it's not a public API
02:47:34 <tdammers> then don't pass mutable variables, and don't accept updated values?
02:47:54 <tsahyt> tdammers: what do you mean with the latter?
02:47:58 <tsahyt> how would I ensure that statically?
02:48:15 <tdammers> how would you expose a function that allows mutation?
02:48:38 <tdammers> you'd have to either pass an IORef around or something like that
02:48:54 <tdammers> or you'd have to have your API functions to accept updater functions or updated values as arguments
02:49:27 <tsahyt> tdammers: no I don't mean real mutation, I mean creating new versions that don't conform to some invariants, which would be possible with normal lenses
02:50:40 <kuribas`> tsahyt: by hiding the datatype, and providing only functions to access it.
02:51:04 <ventonegro> Isn't it exactly what he's doing?
02:51:06 <tsahyt> kuribas`: yes that's exactly what I want to do, just Getter lenses instead for any old accessor function
02:51:27 <tsahyt> the problem is how to restrict makeLenses (or equivalent) to outputting only Getters
02:51:36 <tsahyt> it should really be only a matter of changing the type signature
02:52:22 <tsahyt> umm. with Getting it'd be a matter of fixing f ~ Const
02:52:23 <kuribas`> tsahyt: write it out yourself?
02:52:38 <tdammers> I guess you have to write the lenses manually then
02:52:48 <tsahyt> hm that might end up quite labour intensive
02:52:54 <tdammers> that, or come up with a restricted type for the fields you want "read only"
02:53:20 <cocreature> tsahyt: why do you want getter lenses instead of standard accessor functions?
02:53:24 <tdammers> I'm assuming the real deal here is that you have a smart constructor that limits some fields to specific values, and you want to disallow changing them so that they alway stay at the original, valid, value
02:53:37 <cocreature> tsahyt: as bartavelle mentioned you can trivially convert the latter into the former using "to"
02:53:39 <tsahyt> cocreature: so that nobody on the outside can update the record, just read from it
02:54:01 <tdammers> I think it would help tremendously if you could paste an example data structure and requirements
02:54:30 * ski supposes there's some specific invariant that's supposed to hold for a value of this type
02:54:43 <tsahyt> tdammers: really *any* record, being created by some smart constructor, but all fields must be readable
02:55:28 <tsahyt> tdammers: without lens I'd just hide the constructor and export the accessor functions
02:55:28 <tdammers> ski: if it's just an invariant on a particular field, the right solution would be to create a new type for that field and constrain on the field type, not the record
02:55:37 <tsahyt> no it's *all* fields
02:56:14 <kuribas`> tsahyt: couldn't you simply do: restrictedLens = generatedLens; restrictedLens :: Getter s field
02:56:38 <tsahyt> sure, I'd just prefer to not do all that manually. but it looks like that is my only option after all
02:56:42 * ski . o O ( "The OCaml system - Chapter 7  Language extensions - 7.5  Private types" <https://caml.inria.fr/pub/docs/manual-ocaml/extn.html#sec220> )
02:57:05 <ski> tdammers : what tsahyt said
02:57:18 <ski> (on several fields, not just one field)
02:57:30 <tdammers> hmm, but are the constraints interdependent between fields?
02:57:48 <tdammers> as in, certain values are valid for field A only if field B meets some condition?
02:58:11 <tdammers> because if you can decide validity of each field individually, without considering the other fields, then I'd still go with per-field types
02:58:16 <cocreature> tsahyt: writing a bit of TH should be doable
02:58:19 <ski> or, more generally, some specific relation is expected to hold between values of some of the fields
02:58:33 <tdammers> yes, interdependent
02:59:16 <kuribas`> tsahyt: would generateUpdateableOptics help you?
02:59:35 <kuribas`> "his mode is intended to be used for types with invariants which must be maintained by "smart" constructors."
02:59:36 <tsahyt> tdammers: the specific case here is that I build a GUI, and want to export only FRP events (or functions consuming events) to interact with widgets, in order to hide the actual GUI work completely from the business logic. So I have a record with a lot of events in it, and I want to make sure that I never swap one event stream for another, since each field has a certain semantics to it that I can't really
02:59:38 <tsahyt> describe in types, at least not without monumentous effort
02:59:55 <tsahyt> kuribas`: oh this sounds good
03:00:06 <tsahyt> I'll give that a shot
03:01:06 * hackagebot xxhash-ffi 0.2.0.0 – Bindings to the C implementation the xxHash algorithm – https://hackage.haskell.org/package/xxhash-ffi
03:03:13 <tsahyt> perfect
03:03:21 <tsahyt> now future me cannot mess up as hard anymore
03:03:46 <tsahyt> kuribas`: thanks!
03:04:35 <kuribas`> tsahyt: np, I just did a search on the TH page :-P
03:05:01 <tsahyt> I should finally implement full text search into my doc viewer. hoogle alone isn't good enough sometimes.
03:13:24 <kuribas`> A traversable keeps the structure of the datatype, is there a typeclass which can change the structure?  like filtering a list?
03:14:48 <cocreature> kuribas`: https://hackage.haskell.org/package/witherable-0.1.3.4/docs/Data-Witherable.html#t:Witherable
03:15:11 <kuribas`> cocreature: nice :)
03:25:55 <halogenandtoast> If I want a graph where the nodes are some user defined type is there a good way of handling it, Data.Graph has Vertices as Ints, but I want to use my own type.
03:31:57 <kuribas`> :q
03:33:33 <Iceland_jack> :þ
04:01:30 <notfalling> I have a noobish question and I can't find the answer on google (probably because it's just too basic):
04:02:34 <notfalling> in haskell lists can contain only elements of the same type, so why can I make a list of functions with different types? like length [lenght, head]? Is it because functions are first class citizens?
04:03:01 <barrucadu> :t [length, head]
04:03:03 <lambdabot> [[Int] -> Int]
04:03:16 <barrucadu> In this case, length and head have the same type
04:03:37 <barrucadu> :t (length, head)
04:03:38 <lambdabot> Foldable t => (t a1 -> Int, [a] -> a)
04:04:54 <barrucadu> So if you're making a list with a '[a] -> Int' and a '[b] -> b', the compiler has to make the types match.  In this case, it sees 'b' must be equal to 'Int', because the functions have the same return type, and everything follows from that
04:05:13 <barrucadu> *because the functions must have the same return type
04:06:51 <pacak> Is there a version of ghc-events that is not written by idiots?
04:08:50 <ski> `length' has type `[a] -> Int' for any type `a'. therefore, in particular, it has type `[Int] -> Int'
04:08:50 <cocreature> is there a version of pacak that doesn’t include insults in questions?
04:09:12 <ski> `head' has type `[a] -> a' for any type `a'. therefore, in particular, it has type `[Int] -> Int'
04:09:29 <ski> notfalling : so, `length' and `head' *can* be used as having the same type
04:09:54 <ski> (this is just another angle of what barrucadu said)
04:11:38 <pacak> cocreature: I'm sure there is one somewhere. Trying to understand current design and why is it using up all the memory if eventlog gets longer than a few seconds worth of running time.
04:12:35 <notfalling> thank lambda/barrucadu/ski now  I understand ;-)
04:12:39 <notfalling> thank you*
04:18:51 <pacak> I'm afraid there's none :(
04:45:00 <boj> pacak: maybe the better approach is to fork and "solve" the problem (and indirectly understand the design decisons). to call any of your haskell peers (indirect as they may be) an "idiot" is insulting. we are all just trying our best here
04:46:07 <WinterFox[m]> Does `foo :: a -> a` mean the function can be used with any data type?
04:46:58 <boj> WinterFox[m]: the 'a's are polymorphic, so yes, they imply any type
04:48:29 <boj> your function must be able to handle that of course. if you try to `div` two Strings it will fail (and the compiler will tell you as much)
04:51:40 <WinterFox[m]> boj: That true of any types with lower case first letters right?
04:52:04 <boj> WinterFox[m]: types can only start with an upper case letter
04:52:42 <boj> but if i understand your question, yes, anything that is lower case is simply a polymorphic placeholder
04:53:05 <WinterFox[m]> Ah, thanks.
04:54:48 * hackagebot opench-meteo 0.1.1.0 – A Haskell implementation of the Swiss Meteo Net data API – https://hackage.haskell.org/package/opench-meteo
04:54:49 * hackagebot chart-unit 0.5.0 – Native haskell charts. – https://hackage.haskell.org/package/chart-unit
04:55:03 <ventonegro> WinterFox[m]: If `foo :: a -> a` then `foo` can only be `id`
04:55:11 <ventonegro> :t id
04:55:12 <lambdabot> a -> a
04:55:27 * ski disagrees with saying "the 'a's are polymorphic"
04:55:44 <boj> ski you are killing me here
04:56:02 * boj goes back to lurking for 2-3 years
04:56:11 <ski> i mean no offense
04:56:35 <boj> no, it's ok. i question my own answers as it is
04:56:39 <ski> just that precision of language is useful, when discussing such matters
04:57:11 <ski> `foo' is polymorphic. the types are not polymorphic
04:58:31 <ski> the `a's are type variables (or rather occurances of the same type variable). you can replace the type variable with any concrete type (as long as you do it consistently, iow replace all type variables in the type signature with the *same* type)
04:59:05 <ski> a signature like
04:59:09 <ski>   head :: [a] -> a
04:59:19 <ski> is really shorthand / abbreviation for
04:59:22 <ski>   head :: forall a. [a] -> a
04:59:35 <ski> which can be interpreted as meaning
04:59:37 <ski>   forall a.
04:59:40 <ski>     head :: [a] -> a
05:00:06 <boj> i can't say "all 'a's are polymorphic"?
05:00:07 <ski> iow, for all types `a', `head' *can* be considered as having / used with type `[a] -> a'
05:00:13 <ski> imho, no
05:00:29 <ski> polymorphism isn't involved at the type level here at all
05:01:10 <ski> `Nothing' is polymorphic. it can have type `Maybe Int', `Maybe [String]', `Maybe (IO ())', &c.
05:01:23 <AWizzArd> pure can only take one single item and move it into a list, i.e. pure 20 :: [Int]
05:01:40 <mekeor> ski: what about Just?
05:01:49 <ski> it's also polymorphic
05:01:54 <AWizzArd> How can this be done to import multiple items into a list, via Applicative functions.
05:02:09 <ski> it's the `forall' at the front of the type of a value, that indicates that that value is polymorphic
05:02:29 <mekeor> `Just :: a -> Maybe a` = `Just :: forall a. a -> Maybe a` = `forall a. Just :: a -> Maybe a`
05:02:41 <ski> i call a type of the form `forall a. ..a..' a `forall'-type, or a "universal type" (because `forall' is a universal quantification)
05:03:19 <lyxia> AWizzArd: use Alternative. pure 20 <|> pure 30 = [20,30]
05:03:22 <ski> i would change the first "=" into "is shorthand (in most situations) for"
05:03:29 <boj> ski: i still don't get it. aren't you replacing every 'a' with Int, [String], and (IO ()) - as long as the function satisfies an operation on the types present at compile time?
05:04:28 <mekeor> :t const undefined -- ventonegro 
05:04:29 <lambdabot> b -> a
05:04:41 <ski> boj : `Nothing' (the value) itself is polymorphic. its (most general type) `forall a. Maybe a' is not polymorphic
05:04:54 <ski> (and similarly for `Just',`head',&c. in place of `Nothing')
05:05:13 <ventonegro> mekeor: almost
05:05:14 <ski> boj : do you know about kinds ?
05:05:23 <ski> @kind Maybe Int
05:05:25 <lambdabot> *
05:05:29 <boj> ski: enough to run with you
05:05:31 <ski> @kind forall a. Maybe a
05:05:33 <lambdabot> *
05:05:35 <ski> @kind Maybe
05:05:37 <lambdabot> * -> *
05:05:41 <lyxia> ski: what is the right term for types of polymorphic values? "parametric"?
05:05:45 <ski> @kind Proxy
05:05:47 <lambdabot> k -> *
05:06:12 <ski> the unabbreviated kind of `Proxy' is `forall k. k -> *'. therefore `Proxy' *is* a polymorphic type
05:06:30 <ski> however, `Maybe Int',`forall a. Maybe a',`Maybe' are not polymorphic types
05:06:39 <ski> because they don't have a kind starting with `forall'
05:07:11 <ski> lyxia : as i said, i tend to either say "universal type", or `forall'-type
05:07:47 <ski> "parametric" is a term i apply to types taking arguments (iow type functions), like `Maybe',`Either'
05:08:14 <ski> (also `Either String')
05:08:26 <ski> boj : makes any sense ?
05:08:29 <boj> ski: you've made me question my assumption about what "polymorphism" has meant, since basically forever. what do we mean when talking to non-haskellers about 'a' when we talk about foo :: a -> a? ad-hoc polymorphism? parametric polymorphism?
05:09:09 <ski> (it doesn't really matter here what `Proxy' is for. as long as you understand that both `Proxy Int' and `Proxy Maybe' are valid (kind-correct) types, despite `Int' and `Maybe' having different kinds)
05:09:32 <boj> you've gone off the deep end, although much appreciated
05:09:33 <ski> `a' is just a type variable there
05:09:41 <mekeor> :t const undefined :: a -> a -- ventonegro 
05:09:42 <lambdabot> a -> a
05:09:48 <mekeor> :D
05:10:11 <ski> in *most* cases, such type variables are *implicitly* quantified (using `forall'), just after the `::' of the type signature
05:10:42 <ski> the exception is basically if the type variable is already in scope. then it's not implicitly `forall'ed
05:10:46 <mekeor> ski: what does polymorphic even mean? :D can you give a short definition?
05:10:47 <ski>   head :: [a] -> a
05:10:47 <boj> ski: pretend you are explaing that to a non-haskller
05:10:50 <ski> is short for
05:10:54 <ski>   head :: forall a. [a] -> a
05:10:55 <ski> but
05:11:05 <ski>   data Blah a = MkBlah ([a] -> a)
05:11:09 <ski> is *not* short for
05:11:12 <ski>   data Blah a = MkBlah (forall a. [a] -> a)
05:11:47 <ventonegro> mekeor: ;)
05:11:49 <ski> boj : type variables are closely *related' to polymorphism, and to parametric types
05:12:47 <lyxia> mekeor: a polymorphic value is one that has many types.
05:13:27 <boj> ski: but a lot of words and concepts that can't be conveyed without someone spending 3 months doing all of haskell book
05:13:28 <mekeor> ski: but `data Blah a = MkBlah ([a] -> a)` is short for `forall a. data Blah a = MkBlah ([a] -> a)`, right?
05:13:38 <ski> mekeor : in the context of Haskell. polymorphism usually means "parametric polymorphism". a value is parametrically polymorphic if it can be assigned many types, all captured by a general pattern, indicated by using type variables (and all instances of that ought to be valid types)
05:13:48 <ski> e.g.
05:13:58 <ski>   head :: [Int] -> Int
05:14:10 <ski>   head :: [(Bool,String)] -> (Bool,String)
05:14:13 <boj> you just concretely assigned things
05:14:24 <ski>   head :: [String -> IO ()] -> String -> IO ()
05:14:34 <mekeor> is `1 :: Num a => a` also called "polymorphic"?
05:14:49 <ski> mekeor : yes, "morally speaking". but we can't write that in Haskell, even with extensions
05:14:55 <ski> mekeor : yes
05:15:04 <ski> it has type `forall a. Num a => a'
05:15:25 <ski> this is a generalization, allowing constraints on the tyvars
05:15:33 <ski> this is sometimes called bounded polymorphism
05:16:34 <ski> boj : yes. in the end, people require both "general pictures", and examples, in order to learn
05:17:03 <mekeor> uhhhh. still don't get why "`Nothing :: forall a. Maybe a' is not polymorphic"... :D
05:17:06 <boj> so if 'foo :: a -> a' isn't polymorphic, what words am i searching for? i get the concepts, i don't get the words i should use here
05:17:32 <ski> examples to check whether one's interpretation of the general picture makes any sense (iow to correct it, when it's clear that it doesn't). examples are also needed to get experience to get to distinctions and the motivations for the general concepts
05:17:56 <ski> the general picture is also needed to further structure the examples and the experience they yield
05:17:56 <boj> sorry man, you are overexplaining
05:18:00 <ventonegro> boj: `foo` *is* polymorphic, `a` is just a type variable
05:18:51 <ski> mekeor : `Nothing' is polymorphic. `forall a. Maybe a' is not polymorphic
05:18:54 <boj> ventonegro: ok, so the correct way to explain this is that "foo" is polymorphic, but basically ignore the 'a's, they can be any type
05:18:55 <ski> (neither is `a')
05:19:29 <ski> i don't understand where you're going with "basically ignore the 'a's, they can be any type"
05:19:49 <boj> i am trying to find really basic terminology to explain that function
05:19:59 <ski> the type variables are an essential ingredient in the type of polymorphic operations
05:20:13 * ski nods
05:20:35 <boj> you've basically taken me to advanced CS level, which is much appreciated
05:20:35 <ski> the most basic distinction here is to clearly separate between values and types
05:20:46 <boj> but not something i can explain to my minions
05:20:58 <ski> (often stated as something living on "value level" or "type level")
05:21:30 <ski> sometimes people say something like "I want a function that takes Int, and ..."
05:21:51 <ski> while they really mean "I want a function that takes a value of type Int, and ..."
05:21:56 <ventonegro> boj: `foo` is polymorphic because it can take "many forms" depending on the concrete type instatiated for `a`
05:22:08 <ski> which could be abbreviated as "I want a function that takes *an* Int, and ..."
05:23:10 <ski> you seem to think that because `head' is polymorphic, and also `head :: forall a. [a] -> a' (i.e. the type of `head' is `forall a. [a] -> a'), then that means also `forall a. [a] -> a' is polymorphic -- this is not the case
05:23:30 <ski> (or if you don't think that, the way you use language seem to indicate that, at least)
05:23:31 <boj> ventonegro: i guess that is where i am confused. i made an example which stated that the 'a's are restricted based on my implementation which uses 'div', basically restricting us to Num. why do i not call this function "polymorphic"?
05:23:58 <ski> boj : can you cite the exact message(s) you're referring to ?
05:24:12 <ventonegro> boj: It is polymorphic
05:25:31 <boj> WinterFox[m] was asking about "foo :: a -> a", i said it's polymorphic, but of course if you try to 'div' two Strings the compiler will fail
05:25:58 <ski> <WinterFox[m]> Does `foo :: a -> a` mean the function can be used with any data type?
05:26:01 <ski> <boj> WinterFox[m]: the 'a's are polymorphic, so yes, they imply any type
05:26:13 <ski> what i objected to was calling `a' polymorphic
05:26:30 <ski> `foo' is surely polymorphic here, there's no problem there
05:26:37 <mekeor> ah, right, that makes sense!
05:26:44 <boj> ok, so "foo" is polymorphic
05:26:55 <ski> yes
05:27:19 <boj> we don't actually talk about the type parameters as being polymorphic
05:27:37 <ski> type variables live on the type level
05:27:39 <mekeor> foo is a polymorphic function on value level. and IO is polymorphic on type level?
05:27:55 <ski> with extensions, there can also be polymorphism on the type level. but that doesn't happen in this example
05:28:05 <ski> no, `IO' is not polymorphic, it's parametric
05:28:08 <ski>   IO :: * -> *
05:28:12 <ski> is comparable to
05:28:18 <ski>   not :: Bool -> Bool
05:28:22 <ski> neither is polymorphic
05:28:39 <boj> ok, so the mistake i seem to have made is that i wanted to say they are "parametric"
05:28:41 <mekeor> are there polymorphic things on type level?
05:28:42 <ski> `*' is a concrete kind, just like `Bool' is a concrete type
05:28:57 <ski> mekeor : yes, `Proxy :: forall k. k -> *' is an example
05:29:15 <ski> boj : yes. or "type function", if you prefer
05:29:50 <ski> unfortunately, quite often people (even ones who ought to know better) call e.g. `Maybe' a "polymorphic data type"
05:29:55 <ski> this is wrong, imho
05:30:03 <jcjf> What's the difference in meaning between `*` and `Constraint`?
05:30:23 <ski> the meaning of "polymorphic" there would be different from the meaning of "polymorphic" in "`head' is a polymorphic function"
05:30:33 <Iceland_jack> jcjf: Show :: * -> Constraint
05:30:43 <Iceland_jack> things to the left of => have kind Constraint
05:30:51 <ski> jcjf : the stuff to the right of `=>' must have kind `*'. the stuff to the left must have kind `Constraint'
05:30:56 <Iceland_jack> * is recently called Type
05:30:57 <mekeor> mekeor: so, Proxy takes a value of any type, and returns a type? is it a dependent type?
05:31:20 <ski> no, `Proxy' takes a *type* of any *kind*, and returns a type
05:31:32 <ski> `Proxy Int' and `Proxy Maybe' are examples
05:31:44 <mekeor> how do you know `k` is a kind-variable?
05:31:56 <boj> ski: i follow you, but sadly you have the advantage of viewing the conversation from the "ivory tower". this is meant as a slight, just semi-frustration at the over-explanation of advanced concepts (which i do get) while trying to find what was essentially basic terminology
05:32:01 <ski> mekeor : because Haskell doesn't have dependent types
05:32:08 <mekeor> i see :D
05:32:09 <boj> sorry, isn't meant as a slight
05:32:39 <ski> boj : i understand, and am aware of the problem
05:33:04 <mekeor> it's still fun tho, if you gotta understand something :)
05:33:18 <mekeor> s/gotta/come to/
05:33:20 <boj> ski: to be fair, i got a lot out of this. thank you for your patience
05:33:20 <ski> (part of the problem, from my/our POV, is also finding out what you know/understand, and what you're having difficulties with)
05:33:58 <ski> and that's one reason why, in cases like this, i try to be extra explicit and detailed, trying to avoid sloppy expressions
05:34:37 <ski> basically "trying to compare maps with you (figuring out how to translate between our different languages and experiences), until we find the disagreeing part"
05:34:38 <boj> my approach is different. before i launch into what i assume someone meant, find out what they meant, and assess their level. then try to adjust
05:35:25 <ski> i'm not claiming that my approach to helping people understand matters such as this is the best, even disregarding that different people learn best in different ways
05:35:43 <boj> indeed, there's no silver bullet
05:36:19 <ski> it's just the approach that rhymes with my personality (being a bit fussy with formality, &c.), viewpoint, &c.
05:36:22 * ski nods
05:37:19 <ski> (given more time, ior physical hands-on interaction, i'd probably give more examples as well)
05:37:31 <jcjf> I need help unpacking Show :: * -> Constraint
05:37:47 <jcjf> Show is a class that takes a type and returns a... type?
05:37:58 <mekeor> what do you call the type/kind of a kind-variable (like k in `Proxy :: forall k. k -> *`) ?
05:38:02 <geekosaur> a constraint on a type
05:38:05 <ski> it means that `Show' accepts a concrete type as argument, and returns a constraint (something you can plug to the left of `=>')
05:38:14 <geekosaur> er. that was for jcjf
05:38:47 <jcjf> Are all typeclassses of this form then?
05:39:12 <jcjf> They all return a constraint on a type?
05:39:13 <geekosaur> mekeor, depends who you ask :) it used to be called a "sort". but these days, with TypeInType, it's all been collapsed down so they're all types, one way or another
05:39:25 <geekosaur> jcjf, yes
05:39:25 <ski> mekeor : iirc, kinds doesn't allow application, &c., so there should only ever be one possibility, which doesn't need to be named then
05:39:55 <jcjf> geekosaur: Thanks (ski and Iceland_jack too!), it makes sense now
05:40:01 <ski> jcjf : some take multiple type arguments, though, before returning a constraint
05:40:20 <geekosaur> and before TypeInType, ghc had indeed exactly one sort: BOX
05:41:10 * mekeor searches the web for TypeInType extension
05:41:19 <jcjf> ski: Gotcha! It explains ghci's explanation of `:k Functor`
05:41:44 <jcjf> ski: Although that takes one type argument :)
05:42:09 <WinterFox[m]> What is this error?
05:42:09 <WinterFox[m]> Prelude> foo :: [a] -> a
05:42:10 <WinterFox[m]> <interactive>:4:1: error: Variable not in scope: foo :: [a1] -> a1
05:42:57 <ski> boj : fwiw, i try not to "launch into what i assume someone meant". rather i (often) try to address the language they're using, if i think it's likely to lead to misunderstandings, either because of lacking important distinctions, or because of using non-standard terminology
05:43:51 <geekosaur> WinterFox[m], a type signature without a matching binding. note that ghci requires you to put a binding and its type signature on the same line, using a semicolon as the separator; you can't do them on separate lines like you can in a file
05:44:23 <geekosaur> and if you ghci is too old (oh hai debian oldstable...), you may need to prefix it with "let"
05:44:35 <ski> (of course, some sloppiness is acceptable, if all the involved parties are likely to understand what is meant anyway. but there's a lower chance of this for newbies. also even if the interacting parties understand, onlookers may misunderstand)
05:45:05 <ski> jcjf : it takes one type argument, which itself expects one type argument :)
05:45:06 <boj> ski: no worries. i have clearly misused some terms over the years, you've helped clarify what i should really be saying
05:46:38 <jcjf> As someone not well-versed in terminology, it's hard to navigate the land mines while trying to express what's in your head
05:46:52 <AWizzArd> lyxia: thx
05:47:03 <ski> jcjf : yes, that's what we're here to try to help you with
05:47:13 <jcjf> Math stole so many common words like category and group :)
05:49:01 <ski> (boj : it may perhaps be that i'm unusually sensitive to inaccuracies and misuses of terminology)
05:49:58 * ski recalls reading the term "sensitive logicians" somewhere ..
05:52:12 <boj> ski: just to clarify one more time before i crash, given "foo :: a -> a" the *terminology* i seek is that "foo" is polymoprhic, and has parametric parameters, right?
05:52:20 <mekeor> WinterFox[m]: try something like "let foo :: [a] -> a; foo x = head x" in ghci
05:52:55 <mekeor> oh, i didn't know you can ommit the 'let'
05:53:08 <geekosaur> as of ghc8.0.1 you can
05:54:03 <mekeor> ghc grew so much. it feels like yesterday that it was a child. now it's adult and ripe.
05:54:09 <jcjf> Since ski is taking questions... why is it said that Haskell has coinductive types and not inductive types? I've spent many hours (on random days) casually trying to read up on the difference
05:54:46 <jcjf> For someone that has no intention of using Coq/Agda, it seems really hard to learn
05:55:13 <mekeor> jcjf: could you elaborate on that question with examples maybe?
05:55:19 <jcjf> I've read about "guarded recursion", but it still just feels like recursion
05:55:44 <dolio> Haskell types are both inductive and coinductive.
05:56:21 <jcjf> So is it more that Haskell doesn't *distinguish* between inductive and coinductive?
05:56:37 <Iceland_jack> They coincide
05:56:56 <dolio> Yes, they're the same thing, because of general recursion.
05:56:58 <epileptic> hey guys, a question: is the standard Haskell library is implemented in Haskell?
05:57:10 <ski> boj : i would mainly use the term "parameter" (in a type context) to express e.g. `a' in `data Maybe a = Nothing | Just a'. iow `Maybe' is a "parameterized" type (the parameter `a' in the body `Nothing | Just a' could be said to be *abstracted* (another terminology word) by the `a' to the left of the `=')
05:57:12 <epileptic> I want to see the actual implementation of some of the Prelude functions
05:57:21 <jcjf> Iceland_jack: I've read that before, that least and greatest fixed point coincide
05:57:50 <mekeor> epileptic: yes
05:57:56 <cocreature> epileptic: with a few exceptions it is. you can click the "source" links in haddock at the right, e.g., https://hackage.haskell.org/package/base-4.10.0.0/docs/Prelude.html#v:map
05:57:59 <ski> boj : while you could say that the type `a -> a' itself (with no implicit `forall's) has `a' as a parameter -- to *parameterize* it would require abstraction
05:58:23 <jcjf> I think the problem must be that in my head, all forms of self-referencing things seem inductive (data) or recursive (functions), so I can't distinguish between different types of self-reference
05:58:31 <mekeor> epileptic: e.g. you can read the source code of the Prelude module from the base package on hackage here: https://hackage.haskell.org/package/base-4.10.0.0/docs/src/Prelude.html
05:58:43 <mekeor> oops, cocreature was faster :D
05:58:53 <dolio> jcjf: Anyhow, recursion on inductive types lets you write functions that consume them, where each case recurses on smaller values than it received, more or less.
05:59:00 <ski> boj : this is similar to how in `x^2 + y', both `x' and `y' are parameters. but in `f x = x^2 + y', it has only been parameterized on `x'. `y' is considered "fixed" (meaning : bound in the surrounding context, somewhere)
05:59:03 <geekosaur> that said, in many cases you might prefer the definitions in the Haskell Language Report; they're designed for comprehensibility, ghc's versions are designed for performance and are often ... inscrutable
05:59:18 <epileptic> mekeor, cocreature: thanks both :)
05:59:51 <dolio> jcjf: And corecursion lets you write functions that build coinductive types, as long as the corecursive case is building a 'smaller' portion of the final value (so the case you're on has already produced something).
06:00:32 <ski> jcjf : if we imagine a language with general recursion, then (inductive) lists are necessarily finite, and walking down a list with recursion always terminates
06:00:46 <boj> ski: ok, you answered another question i had indirectly. thanks again for taking the time to explain this :)
06:01:55 <ski> boj : ooc, what was that othr indirect question ? :)
06:02:04 <dolio> jcjf: And in Haskell, you're allowed to corecursively produce things and inductively consume the same things.
06:03:01 <ski> jcjf : `foldr' is inductive/recursive, while `unfoldr' is `coinductive'/`corecursive'. in Haskell, they both refer to the same type of lists
06:03:21 <ski> in a total language, they wouldn't
06:04:43 <jcjf> So because the compiler lets me do "break down" and "build up" on the same type, I have simultaneous recursion and corecursion, while Coq explicitly separates inductive/recursion and coinductive/corecursion.
06:05:00 <dolio> Yes.
06:05:01 <ski> (by which i mean, total & productive. ensuring inductive values "terminate" and coinductive values "produce" ("are responsive", to use an UI, or protocols, metaphor))
06:05:57 <ski> jcjf : otoh, a *bounded* `unfoldr' (giving the maximum size of the output list as an argument) would be inductive (on that size argument), and it could produce an inductive list
06:06:52 <ski> similarly, giving a "cutoff"/"maxdepth" extra argument to `foldr' would allow that version to operate on a coinductive list
06:08:16 <jcjf> ski: That seems interesting, because isn't that cutoff a natural number (which is inductive)?
06:08:34 <ski> yes
06:09:06 <ski> in the former case, we're using it to limit the output to finite depth
06:09:21 <ski> in the latter case, to limit the part of the input we explore to finite depth
06:09:21 <dolio> It would be equivalent to writing a function that takes a natural number and a coinductive list, and gives an inductive list to fold on.
06:09:36 <ski> yes, iow `take'
06:09:37 <dolio> In both cases, I guess.
06:10:45 <jcjf> Ah, because one of them is treating the natural number "the other way"? Like... the greatest fixed point of X = 1 + X "minus" a finite number?
06:10:59 <ski> (btw, note that inductive data types aren't so much about finite values, as about finite-depth values)
06:11:26 <jcjf> I'm thinking like infinity except a finite number of values
06:11:51 <ski> (the breadth could still be infinite. you could have a tree type where every internal node has a countably infinite number of children, but the depth is finite, there are no infinite branches)
06:12:03 <ski> jcjf : nah
06:12:14 <ski> both of them are treating the natural number inductively
06:13:05 <ski> classically speaking, the greatest fixed point there amounts to adding an infinity element (`inf = Succ inf') to the ordinary naturals
06:13:52 <ski> (constructively speaking, we can't claim something that strong)
06:14:50 * ski isn't sure about what jcjf had in mind with the "except a finite number of values" bit
06:15:54 <jcjf> ski: You clarified by saying that both the extended foldr/unfoldr both use the natural number inductively
06:16:24 <ski> (in math, e.g. topology, a cofinite subset is a subset of some given set, whose complement is finite. what you said reminded me of that, but i suspect it's not what you're after ?)
06:17:36 <jcjf> ski: I was originally thinking that if corecursion could use a natural number inductively, then it couldn't be using recursion on the natural number itself (why would we call it corecursion then)? But it's more about what we *do* to the coinductive data type that classifies the operation as corecursion
06:17:42 <ski> btw, one way to implement/represent these "conaturals" (aka "generic convergent sequence") is as an increasing (infinite) sequence of bits
06:19:58 <ski> jcjf : well, the "extended `unfoldr'" i described would *be* inductively defined (on the bound) (and it'd generate an inductive list, instead of a coinductive one). and the "extended `foldr'" would (still) be inductively defined (on the cutoff) (but consume a coinductive list, rather than an inductive one)
06:20:26 <ski> given
06:20:40 <ski>   take :: Nat -> InfList a -> List a
06:20:58 <ski>   foldr :: (a -> o -> o) -> o -> List a -> o
06:21:13 <ski>   unfoldr :: (s -> Maybe (a,s)) -> s -> InfList a
06:21:16 <ski> we define
06:21:26 <jcjf> So it's not good to say "only corecursive functions and operate on coinductive types"
06:21:33 <jcjf> s/and/can
06:21:41 <ski>   cutoffFoldr :: Nat -> (a -> o -> o) -> o -> InfList a -> o
06:22:04 <ski>   cutOffFoldr n cons nil as = foldr cons nil (take n as)
06:22:06 <ski> and
06:22:30 <ski>   boundUnfoldr :: Nat -> (s -> Maybe (a,s)) -> s -> List a
06:22:48 <ski>   boundUnfoldr n step init = take n (unfoldr step init)
06:23:28 <ski> (and one could fuse the implementation of `take' with `foldr' respectively `unfoldr', in those definitions, should one want to)
06:24:00 <jcjf> ski: Thanks, this is very clear now
06:24:08 <ski> inductive data types are mainly about how we *consume* values of them
06:24:23 <ski> coinductive data types are mainly about how we *produce* values of them
06:24:36 <ski> (where by "mainly", i mean that the more interesting parts happen there)
06:25:26 <ski> building a new list from possible parts with `Nil' or `Cons' is trivial
06:26:02 <ski> diving one step deeper into an inf-list, determining whether we've hit the end or not (in which case we get more parts), is also trivial
06:27:09 <jcjf> Both are trivial and we can do them forever (non-termination)
06:27:17 <ski> btw, functions are quite similar to coinductive stuff
06:27:58 <ski> we define a function `f' in terms of what happens when we consume it, by applying it to an argument `x'. that will produce `f'
06:28:14 <jcjf> So like `a -> a -> a` and `a -> (a,a)`?
06:28:40 <ski> for streams (being coinductive), we likewise want to define them in terms of observations about what happens to them, when we prod them
06:28:44 <ski> if we imagine
06:28:50 <ski>   codata Stream a
06:28:52 <ski>     where
06:28:57 <ski>     Head :: Stream a -> a
06:29:03 <ski>     Tail :: Stream a -> Stream a
06:29:29 <ski> (this differs from `InfList' in that a `Stream a' *always* is infinite, not just *possibly*)
06:29:34 <ski> then we can define
06:29:42 <ski>   repeat :: a -> Stream a
06:29:50 <ski>   Head (repeat a) = a
06:30:00 <ski>   Tail (repeat a) = repeat a
06:30:07 <ski> which can also be expressed as
06:30:17 <ski>   repeat a = self  -- or `this', if you prefer
06:30:19 <ski>     where
06:30:23 <ski>     Head self = a
06:30:27 <ski>     Tail self = self
06:30:37 <ski> (that's more likely to run in constant space)
06:30:51 <ski> similarly, we have
06:31:03 <ski>   from :: Enum a => a -> Stream a
06:31:08 <ski>   Head (from n) = n
06:31:17 <ski>   Tail (from n) = from (succ n)
06:31:32 <ski> (in this case the argument (accumulator, if you will) acts like a state)
06:31:46 <ski> jcjf : makes any sense ?
06:32:04 <jcjf> The last bit about `from` I'm still consuming
06:32:11 <jcjf> The earlier stuff I understood
06:32:32 <ski> btw, Haskell doesn't have anything like this "message-dispatching" (aka "copatterns") syntax (but it would be nice, even in some non-recursive cases !)
06:32:53 <ski> Agda has some semi-recent experimental support for something like this
06:33:04 <ski> @google Andreas Abel copatterns
06:33:06 <lambdabot> http://www2.tcs.ifi.lmu.de/~abel/popl13.pdf
06:33:07 <lambdabot> Title: Copatterns
06:33:31 <ski> but i first learned about this (imho quite appealing style of definition) from Erik Poll
06:33:35 <ski> @where ErikPoll
06:33:36 <lambdabot> "Subtyping and Inheritance for Inductive Types" in 1997 at <http://www.cs.ru.nl/E.Poll/papers/durham97.pdf>,"Subtyping and Inheritance for Categorical Datatypes" in 1997 at <http://www.cs.ru.nl/E.
06:33:36 <lambdabot> Poll/papers/kyoto97.pdf>,"A Coalgebraic Semantics of Subtyping" in 2000 at <http://www.cs.ru.nl/E.Poll/papers/cmcs00.pdf>,later version of that in 2001 at <http://www.cs.ru.nl/E.Poll/papers/ita01.
06:33:36 <lambdabot> pdf>
06:33:39 <ski> (first two papers)
06:34:31 <ski> > enumFrom 12
06:34:33 <lambdabot>  [12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,...
06:35:05 <ski> (is what `from' was meant to do. except of course producing a stream)
06:35:45 <jcjf> Ok, it's obvious now
06:35:49 <jcjf> (not the papers!)
06:36:04 <jcjf> Thanks so much for taking the time to explain this
06:36:08 <ski> jcjf : anyway, the point is that `repeat a' and `from n' is defined, in terms of what happens when we apply the "destructors" (field extractors) `Head' and `Tail' to it
06:36:44 <ski> just like `repeat' is defined in terms of what happens when we "destruct"/observe it, by passing `a' as an argument to it
06:36:58 <ski> (and similarly for `from')
06:37:18 <jcjf> Right, you must define it *inside* the destructor
06:37:31 <ski> it's like pattern-matching, except inside-out :)
06:38:02 <ski> instead of checking what kind of input you get. you check what kind of demand is made on the output
06:38:30 <jcjf> Ah... the duality is becoming clearer
06:38:47 <ski> (and i tentatively call this "message-dispatching" syntax, because of its relation to object-orientation)
06:41:09 <ski> we can think of `repeat a' and `from n' as defining an object, giving implementations (methods) for what should happen (iow behaviour) when it receives `Head' and `Tail' messages
06:41:51 <ski> it's not a problem if we want these methods to take additional arguments, apart from the object itself (the coinductive data structure we're defining)
06:42:05 <ski> just make the field contain a function !
06:43:06 <ski> it's also not a problem if we want some (private, usually) mutable state associated with the object. we just allocate a couple of `IORef's, and make them in scope of the object definition, making at least some methods have an `IO' result type (so that they can read and write to these mutable locations)
06:43:55 <jcjf> This seems tantalisingly close to stuff I've read about existential types (I haven't completely understood these yet)
06:44:43 <ski> a "constructor" (in the OO sense) is then just a function (or action) that generates an object, possibly build using arguments to the contructor, possibly build inside `IO' (or whatever effect-tracker you prefer)
06:46:01 <ski> in this view, there's not that much difference (at least to an initial approximation) between a "constructor" and a class
06:47:10 <ski> things start to get a bit more involved, if we also want (implementation) inheritance
06:47:36 <ski> OCaml's object system are based on ideas like this (except, sadly not, "message-dispatching" syntax)
06:48:05 <ski> jcjf : existentials are related, yes (and related to closures)
06:48:29 <ski> (recall "closures are a poor man's objects", and it's converse "objects are a poor man's closures")
06:48:45 <ski> consider again `Stream a'
06:49:20 <ski> another way to represent the same data type is `exist s. (s,s -> (a,s))'
06:50:08 <jcjf> Ok... this looks like it's going into store comonad land :)
06:50:10 <ski> which is the same thing as `exists s. (s,s -> a,s -> s)', splitting the function into two
06:51:35 <ski> a stream consists of : (a) a hidden/internal state *type* `s'; (b) a "current state" of that state type; (c) a function that computes (possibly "extracts") the current/top/head element from the current state (given as argument); (d) a function that computes the next state, corresponding to the tail of the stream
06:52:21 <jcjf> A random number generator!
06:52:35 * ski smiles
06:52:39 <ski> @type random
06:52:42 <lambdabot> (RandomGen g, Random a) => g -> (a, g)
06:52:53 <ski> we could phrase `exist s. (s,s -> (a,s))' as `exist s. (s,s -> (,) a s)'. setting `f = (,) a', we have `exists s. (s,s -> f s)'
06:53:21 <ski> or, using more algebraic notation, `exists s. s * (s -> f s)'
06:53:45 <ski> (i could have said `f s ^ s' (exponentiation), instead of `s -> f s', but i'll refrain from doing that)
06:54:13 <ski> on the other side of things, abstractly the definition of `Stream a' sets it equal (or isomorphic) to `a * Stream a' (two fields)
06:54:53 <ski> however, `Stream a = a * Stream a' doesn't tell us whether we want the inductive (iow least) or the coinductive (iow greatest), or perhaps some other solution to this equation (in `Stream a')
06:55:37 <ski> so, to express that we want the coinductive (greatest) solution, we can use the greek symbol `nu' : `Stream a = nu s. a * s'
06:55:58 <ski> which reads : `Stream a' is the greatest `s' which is equal/iso to `a * s'
06:56:06 <ski> jcjf : makes any sense ?
06:56:25 <avfonarev> I have a silly question. For a change I wanted to try learn some lisp dialect. What could one recommend? A lot of people might suggest Clojure, but I do not want to rely on Java that much...
06:56:53 <jcjf> ski: I have to read that more slowly
06:56:53 <ski> one could write `Stream a = s where s = a * s' .. except that that again doesn't tell us whether we want least or greatest solution / fixed point
06:57:03 <jcjf> ski: I've seen people define Mu before, but not Nu
06:57:10 <ski> avfonarev : depends on what your goal is
06:57:23 <jcjf> ski: I have very little experience thinking about greatest fixed points
06:57:27 <ski> jcjf : `Mu'/`mu' is for least fixed point / inductive types
06:58:02 <avfonarev> To play around, spend some free time, write a toy web server or parsing application
06:58:17 <jcjf> ski: Yes, I've read that Mu and Nu are isomorphic
06:59:17 <ski> avfonarev : if you want to learn concepts (e.g. perhaps you're thinking about reading/doing SICP ?), then i'd suggest Scheme. it's quite small. apart from basic FP stuff (and the dynamic typing side of things), you'll learn about macros (and staged computation), and continuations (the latter isn't that easy to learn about elsewhere)
06:59:22 <jcjf> ski: Ah yes, I'm happy with your definitions
06:59:46 <ski> avfonarev : if your goal is more practical, then Common Lisp or Clojure may perhaps be more appropriate
07:00:00 <ski> (more libraries, if nothing else)
07:00:29 <ski> jcjf : `Mu' and `Nu' are isomorphic in Haskell, because Haskell doesn't distinguish between inductive and coinductive data types
07:01:05 <ski> jcjf : still, it's quite common to make these distinctions, when talking about the *intent* of a piece of Haskell code (which will tell you if it's supposed to work on infinite data or not, e.g.)
07:01:17 <ski> @where SICP
07:01:17 <lambdabot> http://mitpress.mit.edu/sicp/ | http://swiss.csail.mit.edu/classes/6.001/abelson-sussman-lectures/ | http://www.vex.net/~trebla/haskell/sicp.xhtml -- "Storage and Identification of Cabalized
07:01:17 <lambdabot> Packages"
07:01:52 <ski> avfonarev : if nothing else, you could start viewing the SICP videos above ^, see what you think. SICP itself is also available online
07:02:22 <avfonarev> ski: thanks! I think, that is a great suggestion
07:03:08 <ski> (note, i may be biased towards Scheme. you could try asking in #scheme,#lisp (for Common Lisp),#clojure,#emacs (for Emacs Lisp). i also str LilyPond uses a lisp)
07:04:08 * hackagebot jose-jwt 0.7.7 – JSON Object Signing and Encryption Library – https://hackage.haskell.org/package/jose-jwt
07:04:08 * hackagebot StringUtils 0.2.0.1 – String manipulation utilities – https://hackage.haskell.org/package/StringUtils
07:04:13 <ski> jcjf : anyway, since we set `f = (*) a', we have `Stream a = nu s. f s'
07:04:28 <avfonarev> ski: I strangely tend to agree with the Haskell community on many questions. This is why I asked here
07:05:17 <ski> jcjf : now, i'll make the general claim that for any functor `f', `nu s. f s' is isomorphic to `exists s. s * (s -> f s)' (or `exists s. (s,s -> f s)', if you prefer a more Haskelly notation)
07:06:19 <ski> jcjf : `nu s. f s' is basically `f (f (f (f (...))))', where there's (possibly) an infinite depth of `f's in each *value* of this type. we can (potentially) go as deep as we want into this
07:07:29 <jcjf> ski: I prefer the first form
07:07:42 <ski> jcjf : and having a value of type `exists s. s * (s -> f s)' means that we have some initial "seed" value of type `s' (which can't be directly observed). but we can apply the "state transition" function of type `s -> f s' as many times as we like ("we can (...) go as deep as we want") to any such value of type `s'
07:07:58 <jcjf> ski: Only because I like the kind of high school algebra you can do with it :)
07:08:11 <ski> each application of the state transition means going one layer further into `f (f (f (f (...))))'
07:09:06 <ski> iirc, it's not that hard to explicitly show that these two types are actually isomorphic (iow giving translation functions in both directions, and showing that they're inverses of each other)
07:09:29 <ski> depending on what you do, one form may be more convenient or efficient than the other
07:09:42 <jcjf> ski: One little detail I need clarified
07:09:48 <ski> shoot
07:10:12 <jcjf> I'd be happy if we have s -> fs applied for all s
07:10:22 <jcjf> Sorry I mean `s -> f s`
07:10:26 <jcjf> But we said exists s
07:10:51 <jcjf> So if I do s -> f s once, how do I know I'm allowed to do that again to the result?
07:11:23 <ski> well, a particular value of type `exists s. (s,s -> (Integer,s))' is `(0,\n -> (n,n+1))', where `s' in this case is `Integer'
07:11:49 <ski> there is no "for all s" here. `s' is specific (but hidden/abstract/opaque/forgotten)
07:12:23 <jcjf> How do we know `f s` is typed the same as `s`?
07:12:27 <ski> well, `f' was assumed to be a functor, therefore you can operate on the `s' inside `f s', e.g. from `s -> f s' (and itself) getting `s -> f (f s)'
07:12:35 <jcjf> Ah!!!
07:12:38 <ski> `f s' is generally not typed the same as `s'
07:12:46 <ski> (unless `f' is the identity functor)
07:12:59 <jcjf> I forgot about the very early claim... assuming f is a functor
07:13:06 <ski> yes. it's crucial
07:13:32 <ski> it means that we can't use this idea to represent `nu s. ..(s -> s)..
07:13:32 <mniip> ski, huh, I've never seen the nu quantifier notation before, is there anything I can read about it
07:13:37 <jcjf> So you've created the terminal coalgebra
07:14:09 <ski> `f'-coalgebra, yes
07:14:48 <jcjf> All this wacky terminology is finally starting to mean more than just words :)
07:14:50 <ski> mniip : hm, probably somewhere. `nu s. ..s..' is basically the same as `Nu (\s -> ..s..)', and similarly for `mu' and `Mu'
07:15:04 <mniip> ski, yes I figure, that's a handy notation
07:15:13 * ski can't recall any particular papers, offhand
07:15:15 <mniip> (though I know very little about nu/mu)
07:15:33 <mniip> something about them being the same in haskell
07:15:48 <byorgey> mniip: Jeremy Gibbons has a nice paper explaining the basics of an algebraic/categorical approach to programming, which builds up to discussing mu and nu
07:15:51 <ski> yes, but even in Haskell, we often conceptually want to think of them as different
07:15:56 <byorgey> let me see if I can find it
07:16:10 <ski> hence why people use separately defined `Mu' and `Nu', rather than using `Fix'
07:16:27 <ski> (it expresses the intent of the programmer)
07:16:35 <Psybur> Anybody know how to print the schema of an aeson Value?
07:17:18 <ski> jcjf : however, note that `mu r. f r' is also "basically" `f (f (f (f (...))))'. the difference is that for any value of this type, we only allow a finite number of `f' layers
07:17:52 <maerwald> ot: has anyone seen an iterative (bottom-up) merge sort algorithm that allows for deduplication during the merge step? It's trivial in the recursive version, but seems impossible in the iterative
07:18:25 <byorgey> mniip: maybe http://www.cs.ox.ac.uk/people/jeremy.gibbons/publications/acmmpc-calcfp.pdf is what I'm thinking of
07:18:35 <mniip> maerwald, any recursion can be rewritten into iteration with appropriate combinators
07:18:36 <ski> jcjf : e.g. `Mu Maybe', iow `mu r. 1 + r'. if `In :: f (Mu f) -> Mu f' is the data constuctor for `Mu', then we have `In Nothing',`In (Just (In Nothing))',`In (Just (In (Just (In Nothing))))',&c. as values of `Mu Maybe' (this is the (inductive) naturals)
07:19:08 <maerwald> mniip: "everything is possible"
07:19:40 <mniip> maerwald, well, try rewriting your recursive impl into an iterative one the dumb way
07:19:47 <mniip> and see if it comes out clever
07:20:34 <maerwald> I am using bottom-up mergesort
07:20:56 <ski> jcjf : now, i'd like to make a corresponding claim relating `mu' and `forall' : given a functor `f', `mu r. f r' is iso to `forall r. (f r -> r) -> r'
07:21:46 <ski> jcjf : example, `f r = 1 + a * r'. `mu r. f r' is `mu r. 1 + a * r' is (inductive) lists of elements of type `a'
07:21:55 <jcjf> ski: This looks like the Yoneda lemma (although I'm sure everyone says that)
07:23:03 <ski> jcjf : then `forall r. (f r -> r) -> r' is `forall r. (1 + a * r -> r) -> r' is (splitting alternatives) `forall r. (1 -> r) -> (a * r -> r) -> r' is (currying) `forall r. r -> (a -> r -> r) -> r'. with reordering arguments, this is the type of `foldr', partially applied to a list
07:23:17 <Big_G> Would someone be able to explain what the Data typeclass does? 
07:23:32 <Big_G> I read through the page on Hackage and am more confused than when I started
07:24:08 <ski> jcjf : so, modulo argument ordering, `foldr' converts from `mu r. 1 + a * r' to `forall r. (1 + a * r -> r) -> r' (the other direction is sometimes known as `build')
07:24:14 <ski> @type GHC.Exts.build
07:24:16 <lambdabot> (forall b. (a -> b -> b) -> b -> b) -> [a]
07:24:29 <ski>   build folder = folder (:) []
07:26:59 <jcjf> forall a exists b. (a -> b -> b) -> b ->b ->[a]
07:27:19 <jcjf> Just trying to unpack the higher ranked type
07:27:58 <ski> if you want to say `exists' there, you'll have to uncurry
07:29:10 <ski> hm, actually no, doesn't work anyway. nevermind
07:29:57 <Cale> Big_G: It lets you do various sorts of generic traversals of data types which are instances of it.
07:31:05 <jcjf> Oh duh, `->` associativity
07:31:27 <Cale> Big_G: https://www.microsoft.com/en-us/research/wp-content/uploads/2003/01/hmap.pdf might be useful
07:31:27 <jcjf> forall a exists b. ((a -> b -> b) -> b -> b) -> [a]
07:31:42 <ski> jcjf : there's possibly some relation to `Yoneda f a = forall b. (a -> b) -> f b' and `Coyoneda f b = exists a. f a * (a -> b)', but i don't see it
07:31:58 <Big_G> Thanks Cale. I'll see if I can get to reading that today
07:32:00 <ski> jcjf : ah, now i see what you're trying to do ..
07:32:21 <ski> jcjf : but now you're using non-constructive reasoning
07:33:38 <ski> (you can't do prenex normal form in constructive logic. you can't even do it in classical logic, if you allow empty domains (which, imho, you should, at least if you go multi-sorted (aka if you allow multiple (user) types))
07:34:15 <ski> jcjf : constructively, `(exists a. ..a..) -> ...' is iso to `forall a. (..a.. -> ...)'
07:35:02 <ski> jcjf : but you were trying to use the classical equivalence between `(forall a. ..a..) -> ...' and `exists a. (..a.. -> ...)' (the backward direction works, though, constructively)
07:35:40 <jcjf> Oh, so I snuck in an excluded middle somewhere
07:35:57 <ski> jcjf : one way of looking at it is that a rank-2 function of type `(forall a. ..a..) -> ...' can use its (polymorphic) argument many times, each time with a different concrete type substituted for `a'
07:36:38 <ski> (also, it's not clear how to, computationally, be able to "extract" such a concrete type, should the multiple instantiation problem be handled in some way)
07:37:18 <ski> of course, one approach to this would be to generalize the meaning of `exists' to include these scenarios (which is more or less what classical logic does)
07:37:19 <Psybur> Figured out my problem. decoded to Maybe Object instead of Maybe Value
07:38:08 <jcjf> ski: The old "I have a witness" vs "well it can't not be there"
07:38:33 <ski> basically, yes ..
07:39:12 <ski> .. however, in our case `exists' (and `forall') is (are) blind, and so the difference may not be quite as great as it would otherwise be
07:39:58 <ski> (we can't recover the actual type used, from a type variable, at run-time, because of type erasure (which yields parametricity))
07:41:06 <ski> jcjf : i should probably also here mention that of course `... -> (forall a. ..a..)' is iso to `forall a. (... -> ..a..)', and also interactions between `forall' / `exist' and conjunction, disjunction, and negation
07:41:16 <ski> (some of which only holds classically, not constructively)
07:42:06 <jcjf> OK, the constructive isomorphisms are too hard to keep track of (I'm not going to remember this in a week...)
07:42:55 <ski> jcjf : in dual-intuitionistic logic, the picture is basically "i'll accept anything, until it's been refuted) (cf. Popperian view of science) instead of the intuitionistic "i'll accept nothing, until it's been positively shown"
07:43:29 <ski> jcjf : getting a feel for how the computational implementation works, helped for me
07:44:09 <jcjf> That's why I really appreciated your `mu` and `nu` examples, as well as `repeat` and `from`
07:44:18 <ski> (or perhaps s/accept nothing/reject everything/)
07:44:29 * ski nods
07:45:52 <ski> jcjf : yoneda lemma (interpreted in this context) is about how `f a' (given a functor `f') is iso to `Yoneda f a', meaning `forall b. (a -> b) -> f b'
07:46:34 <ski> jcjf : while the dual is that `f b' is iso to `Coyoneda f b', meaning `exists a. f a * (a -> b)'
07:47:41 <ski> i like to think of these as weaker analogues of, in logic, `P (...)' being equivalent to `let x = ... in P x' can be expressed both as `forall x. x = ... -> P x' and as `exists x. x = ... /\ P x'
07:48:23 <jcjf> Ah... -> and /\ is very suggestive
07:48:24 <ski> (weaker because we restrict to a functor, and replace `=' by function/morphism arrow)
07:48:30 <jcjf> I didn't see the point in Haskell form :)
07:48:50 <jcjf> So this is curry-uncurry or tensor-hom
07:49:05 <jcjf> Maybe I should have written that uncurry-curry
07:49:56 <ski> (i don't quite see what you mean by "curry-uncurry" (or vice versa), in here)
07:52:31 <ski> (oh, and of course continuations are related to the `forall' form of `mu' here. also see `Codensity',`Density' .. and then right and left Kan extensions, `Ran',`Lan'. edwardk can probably explain the latter better)
07:53:07 <ski> (and `exists' and `forall' are also related to "ends" and "coends" in category theory. but i've not grokked this well, yet)
07:53:08 <jcjf> I had problems understanding ends and coends, so I'm not ready for that other stuff yet
07:53:18 <jcjf> jinx!
07:53:18 * ski nods
07:54:07 <jcjf> I don't have any background in higher mathematics, so I don't get intuition for words like section, retraction, wedge, pushout, pullback, etc.
07:54:24 <ski> happy to be able to bring across some understanding (as well as possibly improving my own, as well as presentation of it)
07:55:24 * hackagebot FormalGrammars 0.3.1.2, inline-java 0.7.0, jni 0.4.0, jvm 0.3.0
07:55:24 * hackagebot  → https://hackage.haskell.org/packages/recent
07:55:36 <ski> multiple inheritance of signatures, while allowing identification of equally-typed parts, is an example of pullback
07:56:04 <ski> (there's a book called "Category Theory for Software Engineering", which goes into stuff like this)
07:56:49 <jcjf> I think the example of a pullback that worked for me was the notion from a Rust project called pijul
07:57:32 <jcjf> It's a DVCS inspired by darcs, that tries to define commutative patches
07:57:37 <ski> pushout would be disjoint union of two variant types (or algebraic data types), except that we identify some of the constructors from one side with some (identically typed) on the other side
07:58:19 <ski> i think there's also specializations, at least of pullback, in database theory, but i haven't read about that yet
07:58:41 <jcjf> Can I tease out the pushout?
07:58:44 <dolio> Pullback is like a join.
07:59:26 <jcjf> Is it something like identifying the `Just` from Maybe with `Left` from `Either`?
07:59:48 <ski> `section' and `retraction' are quite simple. a retraction-section pair (or situation) `(r,s)' are morphisms such that `r . s = id'. the end
08:00:38 <ski> in this case, `s . r' is an idempotent. we think of `r' as some kind of "projection" from a "larger" object to a "smaller" one. and `s' as an injection back
08:01:58 <ski> the smaller one could consist of labels for groups inside the larger one (so, a partition). the section picks out a representative of each group (which must then be assigned the same group label we started with)
08:02:08 <ski> (btw, "group" here is unrelated to group theory)
08:02:47 <ski> it turns out `r' is an epimorphism (a generalization of surjection), and `s' is a monomorphism (a generalization of injection)
08:03:17 <ski> `read . show = id' could be thought of as a concrete example
08:03:44 <ski> (obviously ignoring the possibility of sending infinite input)
08:04:40 <ski> jcjf : yes, that would be possible. getting something like `data MaybeEither a b = Nothing | JustLeft a | Right b' as a result
08:05:16 <ski> (this is "multiple coinheritance of alternatives")
08:06:19 <ski>   data MaybeEither a b > Maybe a,Either a b
08:06:21 <ski>     where
08:06:27 <ski>     Just = Left
08:06:55 <ski> in a O'Haskell / Timber like notation
08:30:01 <reactormonk> edwardk, got a Grouping instance for Fix handy?
08:37:39 <reactormonk> compiles: -- instance Grouping1 f => Grouping (Fix f) where grouping = contramap unfix (grouping1 grouping)
08:38:56 <c_wraith> that looks more or less right.  Any newtype should behave something like that in Grouping, IIRC
08:39:10 <c_wraith> err.  more like IIUC
08:41:51 <eitan> How do I get haddock links to external libraries to work in documentation for my library on hackage? I've tried googling for instructions but they're very confusing. I feel like this shouldn't be hard...
08:45:29 <JuanDaugherty> is there really no good, readily usable IDE comparable to that of other langs for hs at this point?
08:46:46 <cocreature> eitan: are you uploading the docs yourself or letting the hackage builder build them for you?
08:47:11 <ertes-w> OT question: has anyone explored the application of abstract algebra to administrative problems like devops, networking and security?
08:47:18 <eitan> cocreature: I uploaded them myself, using a script...that may have been a mistake
08:47:20 <monochrom> http://haskellformac.com/ :)
08:47:29 <cocreature> eitan: which script?
08:49:50 <shapr> JuanDaugherty: I'd also like to find such an editor
08:49:51 <hexagoxel> eitan: did you build your deps with documentation enabled? do the generated docs look fine locally?
08:50:09 <shapr> Someone showed up at my Haskell Intro meetup yesterday without vi or emacs experience.
08:50:20 <eitan> cocreature: I don't remember where I got it, but here's a paste of the script: http://lpaste.net/4672161125050089472
08:50:39 <Rembane> shapr: How strange, which editor had they used?
08:50:43 <Rembane> shapr: ...before?
08:50:44 <JuanDaugherty> shapr, looking at the one for mac monochrom linked, apparently priced
08:51:07 <eitan> hexagoxel: the generated docs did look fine locally, it looks like that's the issue with the links (they imagine they're pointing to some locally generated docs)
08:51:22 <shapr> Rembane: he's just getting into coding, learning Python and Haskell at the same time.
08:51:22 <cocreature> eitan: that script is mostly obsolete, cabal has builtin support for this by now
08:51:26 <cocreature> eitan: take a look at https://github.com/ekmett/lens/blob/master/scripts/hackage-docs.sh
08:51:42 <cocreature> in particular --for-hackage is relevant
08:52:23 <eitan> cocreature: I'm using stack if that's relevant
08:52:36 <cocreature> eitan: you can’t use stack for uploading documentation to hackage
08:52:48 <eitan> cocreature: okey dokey
08:52:53 <JuanDaugherty> 25 bucks, not that bad but I don't want to be forced to use mac, prolly would leksah in that case
08:53:03 <JuanDaugherty> *would use
08:53:15 <eitan> lol, stack install cabal fails
08:53:19 <Rembane> shapr: Nice! That must a very interesting experience. 
08:53:19 <JuanDaugherty> unless it (haskellformac) is super well don
08:53:30 <JuanDaugherty> *done
08:53:42 <shapr> Rembane: yeah, he's an interesting person, just got out of the peace corps and wants to write educational software.
08:54:05 <Rembane> shapr: Oh, that is interesting indeed.
08:55:32 * hackagebot jvm-streaming 0.2.1 – Expose Java iterators as streams from the streaming package. – https://hackage.haskell.org/package/jvm-streaming
08:56:35 <JuanDaugherty> what's interesting about vague do good intent?
08:56:54 <eitan> cocreature: should I use the latest cabal-install-2.0?
08:56:59 <JuanDaugherty> within the context of institutions like the peace corp
08:57:55 <ventonegro> JuanDaugherty: If he's showing up and wants to learn, that's more than vague
08:58:10 <cocreature> eitan: that’s probably best but 1.24 should work as well
08:59:35 <monochrom> "want to write educational software" is neither vague nor do good intent.
08:59:55 * JuanDaugherty cabal installed cabal install 2; i guess stuff that uses it knows where to get iit
09:00:42 <monochrom> I write math educational articles like http://www.vex.net/~trebla/homework/epsilon-delta.html with the specific evil intent of saying that conventional teachers are doing it wrong!
09:00:49 <JuanDaugherty> didn seem to affect what shows as cabal install when you do cabal --version
09:01:05 <shapr> JuanDaugherty: yeah, he seems highly motivated and is willing to dig in. So I'll teach him everything I can, Python and Haskell both
09:02:06 <JuanDaugherty> shapr, very good, carry on
09:02:23 <shapr> He even picked up knitting in a really short time at my knitting circle.
09:02:36 <Rembane> Is he becoming a shapr clone?
09:02:47 <shapr> unlikely, he's not interested in unicycling or cartwheels
09:02:55 <monochrom> Heh
09:03:27 <JuanDaugherty> stuff what could break ur neck, don't want
09:04:05 <shapr> JuanDaugherty: meh, I picked up unicycling in my early 30s, and capoeira in my late 30s
09:04:27 <shapr> I was going to say that Haskell can break your brain, but I guess that's not really a health risk.
09:04:42 <dolio> It's a reward.
09:04:48 <Rembane> shapr: Aha! A Shiboleth!
09:05:11 <JuanDaugherty> i'm still trying to fully understand the no IDE thing
09:05:24 <JuanDaugherty> two b's 
09:05:55 <shapr> JuanDaugherty: I think most people got into Haskell after coding in other languages, so they're usually familiar with vim or emacs when they find Haskell.
09:06:35 <shapr> JuanDaugherty: have you tried leksah? I've heard it's the Haskell IDE like Python's IDLE, but I've not tried it.
09:06:43 <JuanDaugherty> yes 
09:06:47 * ski used Notepad, initially
09:07:02 <shapr> Is leksah a good option?
09:07:04 <JuanDaugherty> it's not bad, the build is a hassle
09:07:08 <shapr> hm, ok
09:07:21 <JuanDaugherty> and currently broken on head
09:07:55 <JuanDaugherty> tried the 0.15 binary on mac and it loaded but didn just work
09:07:55 <monochrom> It's economics, not technicality, that causes the lack of IDEs for Haskell.
09:08:34 <JuanDaugherty> i was a lil surprised to see eclipse fp totally abandoned
09:08:56 <JuanDaugherty> eveything is fucking economics
09:09:01 <eitan> I recently switched to visual studio code with the haskero plugin
09:09:11 <JuanDaugherty> base and damn superstructure
09:09:12 <shapr> eitan: works well?
09:09:30 <eitan> @shapr: well enough :-)
09:09:31 <lambdabot> Unknown command, try @list
09:10:15 <eitan> well enough
09:13:16 <monochrom> In fact, let me posit a stark prediction. Now that Richard Eisenberg has finished his PhD and is moving on, work on Dependent Haskell will stall, not followed up.
09:13:44 <c_wraith> That's actually in his schedule. :P
09:13:56 <HallaSurvivor> Hey! I'm doing some basic adventures in parallel, and for some reason I'm getting a "killed" after execution instead of a result
09:14:00 <HallaSurvivor> I'll attach my code in a sec
09:14:42 <HallaSurvivor> https://pastebin.com/bDpuMDRa
09:15:31 <HallaSurvivor> I'm also considering switching away from lists, but it looks like Sequences and Vectors are less easily parallelizable?
09:16:19 <HallaSurvivor> and is there a way to parallelize sum? Theoretically we can get log span, but I think I would have to implement it myself using either Seq or Vec...
09:16:23 <c_wraith> lists are actually not easily parallelizable at all
09:17:14 <[exa]> HallaSurvivor: vectorize before parallelization
09:17:35 <c_wraith> HallaSurvivor: if you want a data structure intended for parallel use, it might be worth investigating the repa library
09:17:50 <monochrom> "less easy" because no one has written a parList for Sequence and Vector.
09:18:05 <c_wraith> HallaSurvivor: if you use it correctly (takes some understanding), it will automatically parallelize quite a few things
09:18:11 <monochrom> But if you look at the code for parList, you'll laugh, it's so easy.
09:20:54 <HallaSurvivor> c_wraith: I've heard of repa, but it looks like a lot of overhead for something so simple. Killing a fly with a nuke
09:21:18 <HallaSurvivor> [exa]: Do you mean the Vector library? And then implement a parVector like monochrom mentioned?
09:23:14 <[exa]> HallaSurvivor: that was a generic advice :]
09:23:25 <[exa]> HallaSurvivor: anyways, you're splitting the work to 10^8 tiny workpieces?
09:24:29 <HallaSurvivor> [exa]: yup. It runs fine on 10^7, but 10^8 it gets hot for a bit then prints "Killed"
09:24:51 <[exa]> car analogy would be "planning too much"
09:25:06 <HallaSurvivor> I'll try switching to Vector, and using parTraversible instead of parList
09:25:13 <[exa]> noep
09:25:21 <[exa]> how many cores do you have?
09:25:28 <HallaSurvivor> 16
09:25:30 <[exa]> (less than 1000)
09:25:51 <[exa]> then splitting to more than 16 workpieces will only bring pain and suffering
09:26:00 <HallaSurvivor> fwiw, 10^8 has nothing to do with chunking for parallelism
09:26:11 <HallaSurvivor> this is an analytic integral solver, so 10^8 is a better approx of the true integral value
09:27:06 <HallaSurvivor> my GUESS is that using lists is taking up too much memory, and that's what's causing linux to kill the process
09:27:09 <HallaSurvivor> but idk
09:28:47 <mniip> HallaSurvivor, a list with 1e8 items?
09:28:48 <mniip> possibly
09:29:09 <HallaSurvivor> I'll switch to unboxed vectors and see what happens
09:29:27 <mniip> that's at least 6 gigabytes
09:29:31 <mniip> just for the spine
09:34:54 <[exa]> HallaSurvivor: chunking a list means instantiating it. You _really_ want to do it smarter
09:35:41 <[exa]> like, what about dividing the work to chunks of reasonable size yourself and instantiating the list only over chunk IDs?
09:36:18 <[exa]> also, your final sum is serial, so your performance will get amdahled
09:36:57 <HallaSurvivor> [exa]: Would you mind explaining more?
09:37:13 <HallaSurvivor> mniip: that... is probably the problem
09:40:18 <monochrom> Oh! 6GB. Yeah that is killable.
09:40:55 <[exa]> HallaSurvivor: sec
09:41:45 <[exa]> HallaSurvivor: good point is that it shouldn't consume 5 gigs of memory just for the first integration :]
09:44:54 <tyrathect> hello
09:45:12 <HallaSurvivor> hello!
09:45:23 <tyrathect> i am learning haskell out of curiosity
09:46:05 <tyrathect> i wonder, what is a typical domain where you would use it?
09:47:13 <JuanDaugherty> typically one with requirements for rigor
09:47:23 <c_wraith> tyrathect: generally, Haskell is good for software.
09:47:54 <JuanDaugherty> or the pretense of same as in finance where it's pretty much superfluous
09:48:23 <tyrathect> my company usually employs php for the colorful stuff, and erlang for the high performance/resilience problems
09:48:34 <JuanDaugherty> would in safety critical except they tend to be real time
09:49:56 <JuanDaugherty> huge in advanced software dev, like clafer
09:50:26 <JuanDaugherty> but no goddamned IDE! can you imagine that?!?!
09:51:43 <JuanDaugherty> (i.e. none that just works, is worth the time, and isn't on a priced platform)
09:51:54 <[exa]> HallaSurvivor: sorry still battling my parallel strategies to actually compute multicore-ish
09:52:22 <HallaSurvivor> lol, no worries! Now that I know it's primarily a memory thing I'm trying to find a way to eliminate the list using function calls
09:53:25 <[exa]> well, currently at this:
09:53:44 <[exa]> (danger ugly- https://pastebin.com/fYrDvbde )
09:55:42 * hackagebot ngx-export 0.7.0.1 – Helper module for Nginx haskell module – https://hackage.haskell.org/package/ngx-export
09:56:34 <nshepperd_> Seems to me HallaSurvivor really wants some parallel foldMap combinator. If you assume commutativity you can get it streaming by having the kth worker fold over every nth value starting with the kth
09:57:26 <nshepperd_> Ie. The transpose . chunksOf n trick
09:57:53 <nshepperd_> Not creating a list in the first place is also a fine strategy though...
09:58:09 <[exa]> whoa, parallel strategies are weirder than openmp :]
09:59:49 <HallaSurvivor> nshepperd_ A parallel foldMap would be lovely, haha. I can (thankfully) assume associativity and commutativity, so I'll try transpose . chunksOf n
10:00:09 <HallaSurvivor> though it's bothering me a bit that I can't come up with a way to do it without generating a list :/
10:01:27 <eitan> cocreature: Thanks for your help. External links are a little better now, but haddock appears to have trouble generating links to some packages like `generics-sop` and `monad-control`. Any notion how I can fix these?
10:01:30 <wz1000> JuanDaugherty: have you seen https://github.com/haskell/haskell-ide-engine
10:01:49 <nshepperd_> fmap (foldl' f z) (transpose $ chunksOf n [1..n]) `using` parList rseq
10:01:56 <[exa]> HallaSurvivor: what should be the result btw?
10:02:06 <nshepperd_> HallaSurvivor: oh, that's one thing. Wow 
10:02:10 <nshepperd_> Er
10:02:21 <[exa]> HallaSurvivor: I'm getting like 0.6149804852894764
10:02:22 <norc_> Okay so Im studying the do notation. Am I weird to consider >>=/>> to be much easier to read?
10:02:32 <HallaSurvivor> [exa] that's about right
10:02:33 <nshepperd_> Write parList rseq, not rpar
10:02:46 <nshepperd_> parList is already parallel
10:03:09 <wz1000> norc_: it because tedious with nesting if you have a complex data flow
10:03:20 <wz1000> do notation is much easier to read
10:03:23 <JuanDaugherty> wz1000, will check in a minute
10:03:46 <norc_> wz1000: Fair enough. Ill try to get used to it. :)
10:03:58 <[exa]> HallaSurvivor: then this gets the result in around 2.5s on 4 cores https://pastebin.com/tykVf4H9
10:04:07 <[exa]> HallaSurvivor: but it's the "simple" way :D
10:04:23 <HallaSurvivor> nshepperd_ do you mean chunksOf n [1..n]? or should the # chunks be different from the length of the list?
10:05:04 <shae> I like megaparsec 6+
10:05:32 <wz1000> I wonder if it could be a good idea to have a worker thread(or two) that evaluates random thunks as your program is running
10:06:22 <nshepperd> HallaSurvivor: er, right. chunksOf howManyCoresYouHave
10:06:35 <HallaSurvivor> cool cool
10:06:37 <[exa]> HallaSurvivor: oh a correction, there should be [0..1+(...)]
10:12:10 <JuanDaugherty> wz1000, tyvm! looks like what I was looking for.
10:12:40 <JuanDaugherty> (and had seen but that's how things work, context is everything)
10:12:57 <wz1000> JuanDaugherty: well, it is still very much a wip, so do report any bugs or missing features
10:13:24 <JuanDaugherty> Acknowledged.
10:13:35 <wz1000> 8.0 only for now, but 8.2 support should be coming soon
10:14:00 <JuanDaugherty> it'll build/run in 8.2 though?
10:15:19 * JuanDaugherty doesn't need support, just work to an appropriate level, which for a dev thing doesn't mean just works like something shrink wrapped
10:15:55 <JuanDaugherty> *just works to
10:18:36 <eitan> does anyone know how to get external package links to work with the `--for-hackage` option of `cabal haddock`? Some of the external links appear to work but some don't.
10:19:01 <wz1000> JuanDaugherty: it should build with the correct versions of the dependencies
10:19:29 * JuanDaugherty will give a whirl in a bit with stack
10:19:48 <wz1000> JuanDaugherty: see https://github.com/robrix/haskell-ide-engine/tree/ghc-8.2.1
10:19:54 <cocreature> eitan: sounds like you might have build without "documentation: True"
10:20:19 <cocreature> eitan: add that to your ~/.cabal/config
10:20:53 <JuanDaugherty> wz1000, Acknowledged, will start with that
10:21:34 <wz1000> JuanDaugherty: you would probably have a better experience if you use it with an 8.0.2 project since 8.2 support is still a wip
10:22:29 <JuanDaugherty> well by the time i get it integrated with my other eclipse workframe stuff ... .
10:22:44 <eitan> cocreature: doesn't seem to help
10:25:44 <cocreature> eitan: you’ll need to force a rebuild of all deps or at least the ones that cause problems
10:25:49 <cocreature> eitan: e.g. by nuking your sandbox
10:26:18 <eitan> wasn't even running in a sandbox, lol, man, it's been a while since I've used cabal :-)
10:26:37 <cocreature> eitan: try "ghc-pkg unregister name-of-dep-causing-problems"
10:29:21 <eitan> cocreature: I'm rebuilding in a sandbox...I'll try deregistering the global installs if this doesn't work
10:35:23 <eitan> cocreature: success! thanks so much...only missing link destination is for type equality `~`...not sure what that's about
10:36:08 <foojs> hi
10:36:13 <foojs> https://gist.github.com/linkin-park/1a55c4c45c7a90b597f271ded85ba153
10:39:03 <cocreature> eitan: now you’ll have to tell me what lib you’re working on :)
10:39:18 <foojs> wrong channel!
10:41:11 <ongy> can I create part of a pattern match with TH? Or match on a range of values in some way
10:41:50 <ongy> erm, a few branches of the possible branches of a `case of`
10:43:18 <eitan> cocreature: keep an eye on haskell reddit for an announcement in the next week or so
10:44:08 <nshepperd> http://lpaste.net/358120 << a newtype wrapper that makes foldMap strict and left associated
10:44:18 <JuanDaugherty> wz1000, is hs ide engine, microsoft dependent?
10:44:33 <HallaSurvivor> I switched to sequences, and it fixed everythin!
10:44:36 <HallaSurvivor> everything*
10:44:43 <HallaSurvivor> [exa] nshepperd_
10:44:58 <HallaSurvivor> memory usage is down, and so is the calculation time
10:45:15 <HallaSurvivor> I just wrote a parallel foldMap. Once someone said that's what I really wanted (which I realized that it was)
10:45:25 <HallaSurvivor> this way you never need to have the entire sequence in memory at once
10:45:42 <[exa]> HallaSurvivor: can you share the code btw? quite interested in seeing a less crude way than mine
10:45:51 <HallaSurvivor> yee
10:45:59 <eitan> msg cocreature i'm bad at irc, sorry, check out squeal-postgresql on hackage
10:46:01 <[exa]> (btw what speedup do you have against singlecore?)
10:46:05 <eitan> ack
10:46:09 <cocreature> eitan: looks pretty cool!
10:46:13 <wz1000> HallaSurvivor: no. the protocol we use to talk to editors was made by microsoft, but that is fully open source
10:46:18 <eitan> thanks, lol
10:46:27 <HallaSurvivor> https://pastebin.com/yZzvdWHq
10:47:29 * HallaSurvivor is confused by wz1000's comment
10:48:15 <[exa]> binary splitting, yay
10:49:49 <wz1000> HallaSurvivor: HIE has no link with microsoft
10:50:06 <cocreature> wz1000: I think you want to talk to JuanDaugherty not HallaSurvivor 
10:50:43 <wz1000> oops, sorry. 
10:50:53 * HallaSurvivor is less confused now
10:51:01 <HallaSurvivor> wz1000: no worries!
10:52:07 <JuanDaugherty> "We are currently focusing on using the Language Server Protocol as the interface via which we talk to clients." made me think that
10:53:07 <wz1000> JuanDaugherty: that is simply a common inteface to talk to editors, so we don't have to go and implement editor plugins from scratch for every editor
10:53:38 <wz1000> since many other languages are also using LSP and many editors already have LSP integration/plugins
10:53:46 <nshepperd> HallaSurvivor: intriguing
10:53:59 <nshepperd> i'd have thought data.sequence would be slower
10:54:09 <Zemyla> Question: On a 64-bit machine, will a program crash if you unsafeCoerce# a Double# into an Int#?
10:54:32 <HallaSurvivor> nshepperd: The log time split vs linear must be the deciding factor
10:55:52 * hackagebot composite-aeson 0.5.1.0, composite-aeson-refined 0.5.1.0, composite-base 0.5.1.0, composite-ekg 0.5.1.0, … and 1 more
10:55:52 * hackagebot  → https://hackage.haskell.org/packages/recent
10:57:42 <nshepperd> i suppose so, yeah
10:57:44 <Zemyla> Actually, if you unsafeCoerce# a Double# into an Int#, unsafeCoerce# a Double# -> a into an Int# -> a, and later pass the former into the latter?
10:59:44 <[exa]> HallaSurvivor: man, it still eats 2 gigs of memory :]
11:00:03 <Zemyla> HallaSurvivor: You should try using Data.Vector. splitAt is O(1) there.
11:00:22 <HallaSurvivor> Zemyla: I'm actually doing that right now! lol
11:00:41 <HallaSurvivor> weird, it ~doubled my runtime
11:01:03 <nshepperd> data.vector will still use lots of memory, because it has to create the whole thing
11:01:11 <HallaSurvivor> LOL
11:01:20 <HallaSurvivor> just switched to Data.Vector.Unboxed
11:01:24 <HallaSurvivor> shattered my times
11:01:25 <HallaSurvivor> like
11:01:30 <HallaSurvivor> kicked them down the stairs
11:01:54 <[exa]> HallaSurvivor: how fast for 10^7 ? :]
11:02:03 <erisco> indirection does that to people
11:02:22 <[exa]> there's running joke in our faculty about parallelization btw
11:02:49 <[exa]> there was a homework to reprogram some stuff for multicore and test it on 64 cores to achieve 64x speedup
11:03:02 <HallaSurvivor> [exa] 0.29s for the 10^7 case
11:03:02 <foojs> are you using haskell in your DEV ?
11:03:07 <foojs> are you using haskell in your DEV ?
11:03:17 <HallaSurvivor> [exa] and 3.0 even for the 10^8
11:03:31 <Zemyla> HallaSurvivor: How much if you say there's a minimum size for which you fold it sequentially?
11:03:31 <[exa]> HallaSurvivor: almost as good as the crude pmap version :] IMHO the rest is allocation overhead
11:04:11 <[exa]> now, it wasn't embarrasingly parallel so students got like 20-30x speedup, pretty cool
11:04:56 <[exa]> then my advisor called it all BS, rewrote it to avoid some indirection and got 600x speedup
11:05:28 <[exa]> (on singlecore)
11:06:04 <foojs> does haskell has much shorter syntax than most FP
11:06:21 <foojs> i just a code in hackerrank i'm like wow cool!
11:06:26 <foojs> saw**
11:06:40 <JuanDaugherty> [exa], did you mean %?
11:06:49 <[exa]> no, 600 times faster
11:06:59 <JuanDaugherty> ah
11:07:04 <erisco> [exa], I know a similar story about throwing more servers at web programs…
11:07:07 <mud> foojs: Probably depends. I think it might be a tad more concise than most, but I wouldn't think by a lot.
11:07:14 <Zemyla> Also, I find myself wondering what happens if you don't use a data structure at all, just have something with the signature parSum :: (Int -> Double) -> Int -> Int -> Double
11:07:17 <[exa]> erisco: involves php?
11:07:20 <[exa]> :]
11:07:23 <erisco> yup :)
11:08:24 <foojs> this is my erlang equivalent of the problem https://gist.github.com/linkin-park/6bfbdad80f014ef3d53d6e03f69784dc mud , i asked seniors for the review . So i can make my program better
11:09:03 <[exa]> JuanDaugherty: pipelined instruction with avoided cache miss is around 2000 times faster on usual cpus, so it was probably still suboptimal
11:09:38 <JuanDaugherty> [exa]: Acknowledged.
11:09:47 <foojs> i know there should be  a better way to do :!
11:10:10 <mud> foojs: Well, I can definitely beat that in haskell for concision for that problem, but I don't know erlang
11:10:44 <erisco> explain the problem in English, foojs
11:11:17 <foojs> https://www.hackerrank.com/challenges/fp-list-replication/problem
11:11:48 <mud> My version would just be: f n = concatMap (replicate n)
11:12:05 <foojs> but for you they give n and array
11:12:14 <mud> Yeah
11:12:19 <erisco> f = concatMap . replicate
11:12:29 <foojs> fir erlang we need to do X|Xs
11:13:30 <mud> erisco: Hm, ya
11:13:50 <foojs> hmmm
11:13:50 <erisco> and for no added generality, foldMap . replicate
11:14:01 <ongy> :t foldMap
11:14:03 <lambdabot> (Monoid m, Foldable t) => (a -> m) -> t a -> m
11:14:17 <foojs> erlang need to read input and do calc and do output
11:14:30 <foojs> since hackerrank dont support this lang !
11:14:48 <mud> Haskell does too, they just provide that for you. But it's not hard to do yourself as a haskeller at least as concisely as they have it.
11:15:13 <foojs> can you show equivlent of that in haskell
11:15:26 <foojs> reading input , do foo and output !
11:17:45 <foojs> k ill be leaving
11:17:56 <foojs> you comment in gist :)
11:17:59 <foojs> thanks all
11:18:53 <erisco> :t let replicateA 0 _ = empty; replicateA n x = pure x <|> replicateA (n - 1) x in foldMap . replicateA
11:18:55 <lambdabot> (Eq t1, Num t1, Alternative f, Monoid (f a), Foldable t) => t1 -> t a -> f a
11:19:40 <erisco> why is foojs gone
11:22:33 <ski> @type let replicateA n act = sequenceA (replicate n act) in replicateA
11:22:35 <lambdabot> Applicative f => Int -> f a -> f [a]
11:23:12 <erisco> that aint the same
11:23:40 <ski> hum, i suppose so
11:24:52 <ski> @type let replicateA n act = foldr (<|>) empty (replicate n act) in replicateA
11:24:53 <lambdabot> Alternative f => Int -> f a -> f a
11:24:59 <ski> @type let replicatePure n act = foldr ((<|>) . pure) empty (replicate n act) in replicatePure
11:25:00 <lambdabot> Alternative f => Int -> a -> f a
11:25:36 <ski> (is there a better word than "replicate" here)
11:26:09 <erisco> replicate is restricted to Int which made it unappealing, but a fold is a good idea
11:26:34 <ski> @type genericReplicate
11:26:35 <lambdabot> Integral i => i -> a -> [a]
11:27:46 <lavalike> @type (asum .) . replicate
11:27:47 <lambdabot> Alternative f => Int -> f a -> f a
11:28:00 <lavalike> almost
11:28:15 <ski> hmm .. i wonder whether quotient rings of `Integer' give non-negative results for `toInteger'
11:28:59 <ski> @type ((asum . map pure) .) . replicate
11:29:01 <lambdabot> Alternative f => Int -> a -> f a
11:29:17 <lavalike> @t flip $ (asum .) . flip replicate . pure
11:29:17 <lambdabot> Maybe you meant: tell thank you thanks thesaurus thx tic-tac-toe ticker time todo todo-add todo-delete type v @ ? .
11:29:28 <erisco> okay, Integral requires Enum... was wondering if that is how they avoided the Eq constraint
11:29:29 * ski isn't sure why the argument isn't wanted to be idiomatic, though
11:29:57 <ski> lambdabot : i suppose that's better
11:30:32 <ski> @type (asum .) . (. pure) . replicate
11:30:34 <lambdabot> Alternative f => Int -> a -> f a
11:30:52 <ski> (using a free theorem of `replicate', i expect)
11:30:56 <ski> @free replicate
11:30:58 <lambdabot> $map f . replicate x = replicate x . f
11:31:07 <erisco> asum ... fmap pure ... genericReplicate :: (Integral i, Alternative f) => i -> a -> f a
11:32:23 <ski>   ((asum . map pure) .) . replicate  =  (asum .) . (map pure .) . replicate  =  (asum .) . (. pure) . replicate  -- ignoring some fiddling with `.'
11:32:42 <ski> (or s/ignoring/omitting/)
11:33:10 <erisco> see, you all laugh, but it has uses
11:33:10 <ski> lavalike : er sorry, i meant to address you, not lambdabot
11:34:03 <ski> erisco : `...' or this `Alternative' variant of `replicateA', restricted to `pure' arguments ?
11:34:18 <lavalike> ski: hahaha
11:34:23 <erisco> please rephrase the question
11:34:29 * ski didn't even notice at first
11:35:21 <ski> you seem to be either (a) claiming that some `...' operator has its uses; or (b) claiming that your variant of `replicateA' has its uses
11:35:44 <erisco> well, replicateA specialises to replicate, so whatever uses replicate has plus maybe more
11:35:48 <erisco> but I was referring to ...
11:38:54 <ski> oh, it's some lens thing
11:39:24 <erisco> really?
11:39:29 <ski> @type (...)
11:39:30 <lambdabot> (Plated c, Applicative f) => LensLike f s t c c -> Over p f c c a b -> Over p f s t a b
11:39:35 <ski> says so on the label ?
11:39:55 <c_wraith> :t Tree
11:39:57 <lambdabot> error:
11:39:57 <lambdabot>     • Data constructor not in scope: Tree
11:39:57 <lambdabot>     • Perhaps you meant ‘True’ (imported from Data.Bool)
11:40:02 <ski> @type Node
11:40:03 <lambdabot> a -> Forest a -> Tree a
11:40:12 <c_wraith> Hmm, that's not the one I was looking for
11:40:15 <erisco> no idea about lens stuff
11:40:23 <rudol> newtype Nim = Nim {nimber :: Int} deriving (Eq, Ord)
11:40:30 * ski haven't delved into advanced optics, either
11:40:34 <rudol> and for its Monoid instance, 
11:40:35 * mekeor wonders what the haskell-indexer by google does: https://github.com/google/haskell-indexer
11:40:45 <rudol> mappend = (Nim .) . (. nimber) . xor . nimber  
11:40:56 <rudol> is beautiful and leads to elegance (for an algorithmic bestmove impl based on xor, as opposed to a gametree), 
11:41:06 <rudol> but I am not sure I could have come up with that mappend impl myself at this juncture in my Haskell/FP learning. 
11:41:16 <rudol> Could somebody share some insight on the thought process behind to coming up with such a mappend for type Nim, 
11:41:19 <erisco> ski, my  f ... g  is  \x1 .. xn -> f (g x1 .. xn)
11:41:25 <rudol>  eg following the types (given we know we need mappend :: Nim -> Nim -> Nim) and etc ...?
11:41:27 <ski> rudol : well .. i don't think that's that obvious and symmetric
11:41:54 <rudol> it's certainly not obvious to me
11:42:09 <ski> perhaps if `xor' was abstracted out of it, it'd be more clear
11:42:21 <ski> i know one way to make it clearer, anyway :
11:43:51 <ski> @let infixr 1 ~>; (~>) :: (a1 -> a0) -> (b0 -> b1) -> ((a0 -> b0) -> (a1 -> b1)); (pre ~> post) f = post . f . pre  -- one could name them `frobArg' and `frobRes' instead of `pre' and `post'
11:43:52 <lambdabot>  .L.hs:163:10: error:
11:43:52 <lambdabot>      Multiple fixity declarations for ‘~>’
11:43:52 <lambdabot>      also at  .L.hs:172:1-11
11:44:03 <ski> oh, already defined ?
11:44:05 <c_wraith> > (5, "hello") ^? _2 ... _Cons  -- here is an awful demonstration of (...)  It explains nothing!
11:44:06 <ski> @type (~>)
11:44:08 <lambdabot>  Just ('e',"llo")
11:44:08 <lambdabot> (a1 -> a0) -> (b0 -> b1) -> (a0 -> b0) -> a1 -> b1
11:44:12 <nshepperd_> There's no need to write everything pointfree
11:44:12 <ski> ok, fine
11:44:19 <erisco> I was just going to mention ~>
11:44:29 <ski> @let newtype Nim = MkNim {nimber :: Int} deriving (Eq,Ord)
11:44:31 <lambdabot>  Defined.
11:44:36 <erisco> (g .) . (. f)  is the  "do f before and g after"  pattern
11:44:50 <ski> @type (nimber ~> nimber ~> MkNim) xor
11:44:52 <lambdabot> Nim -> Nim -> Nim
11:45:00 <ski> rudol : how about that ^ ?
11:45:12 <erisco> there are also some fancier functions for doing stuff on newtypes, none of which I can remember
11:45:23 <erisco> because with newtypes the pattern of "unwrap, do a thing, then rewrap" is common
11:45:30 <erisco> nshepperd_, lies
11:45:38 <nshepperd_> mappend (Nim x) (Nim y) = Nim (x `xor` y)
11:45:48 <nshepperd_> >:)
11:45:48 <ski> erisco : aye, just a bit shorter and more to the point (and easier to nest)
11:46:08 <rudol> let me digest it a bit, thanks (still, admiring somebody else's clever  impl is quite different to writing it myself ) 
11:46:09 <ski> nshepperd_ : now, where's the fun in that ?!
11:46:50 <ski> @src SEC
11:46:51 <lambdabot> Source not found. And you call yourself a Rocket Surgeon!
11:46:52 * nshepperd_ neighs
11:46:56 <ski> @where SEC
11:46:56 <lambdabot> http://conal.net/blog/posts/semantic-editor-combinators/
11:47:03 <ski> rudol : that ^ might be useful
11:47:27 <erisco> you might also define an Applicative instance for Nim, if possible, and then  mappend = liftA2 xor
11:47:28 <ski> perhaps also the end of
11:47:30 <ski> @where TV
11:47:30 <lambdabot> http://www.haskell.org/haskellwiki/TV
11:48:18 <erisco> if a Nim was parameterised rather than just an Int
11:50:22 <ski> erisco : your `(...)' defined via a type class ?
11:50:37 <erisco> ski, yes
11:50:43 * ski figured
11:51:37 <ski> rudol : `(~>)' takes an "argument transformation" and a "result transformation", and combines them into a "function transformation"
11:51:57 <ski> rudol : similarly, `map' takes an "element transformation", and produces a "list transformation"
11:52:39 <erisco> it should be relatively straightforward to generate lift functions for newtypes
11:52:58 <erisco> seems obvious enough that a package probably already does this
11:53:58 <rudol> thank you, ski & erisco. PS can you reassure me that my questions are not too basic for this channel - I notice much of the discussion is on another level altogether.
11:54:43 <tdammers> rudol: that's fine, we've all been there
11:54:58 <ski> one can define `arg f = f ~> id' (aka `(. f)') and `res f = id ~> f' (aka `(f .)'). then `(Nim .) . (. nimber) . xor . nimber' could also be written as `res Nim . arg nimber . xor . nimber' (not that much different, except more mnemonic)
11:55:03 <rudol> I am wondering how I will leave there!
11:55:21 <rudol> but thanks, tdammers
11:55:21 <ski> rudol : not too basic. beginner questions are welcome
11:55:43 <erisco> rudol, when this channel is busy you can go to #haskell-beginner but there is no rule against asking beginner questions here
11:55:48 <ski> just ignore (or try to listen in) on discussions that are, for now, over your head
11:56:07 <merijn> After 5 years discussions are still regularly over my head :p
11:56:28 <rudol> sure, I find those fascinating, but the same applies - I can admire it, but probably not come up with it myself
11:56:32 <ski> if people are talking about more or less esoteric things that doesn't appear to have much direct connection with Haskell, feel free to interrupt with a more Haskell-related query
11:57:46 <ski> erisco : perhaps `newtype' ?
11:59:53 <ski> @where evolution
11:59:53 <lambdabot> http://www.willamette.edu/~fruehr/haskell/evolution.html
11:59:59 <erisco> ski, I am thinking of the family of functions like liftAn but for newtypes
12:00:02 <ski> rudol, fwiw, did you see that ^ yet ?
12:00:48 <erisco> so for each newtype N and for each arity P you have liftNP
12:02:10 <ski> mhm
12:04:03 <erisco> the newtype is particular because we know it has just one constructor and field
12:04:43 <rudol> ski - I clicked it; it's waiting for me in another tab. I am just first trying to ascertain if that mappend is really as simple as nshepperd_ says
12:06:46 <rudol> nshepperd_ so it's the eta reduction that made this look so "clever" (aka unintuitive)?
12:09:18 <rudol> so, presumably, nshepperd_'s non-point-free (is there a word for that) version could be derived, by pen and paper, from the point-free version I found
12:09:59 <mud> rudol: pointy is the informal word
12:10:06 <rudol> ;)
12:10:21 <rudol> the point pointy bird goes pointy pointy
12:10:45 <Zemyla> rudol: And the opposite is actually "pointless".
12:10:50 <rudol> s/point/pointy/
12:12:07 <mud> Zemyla: :-/
12:13:07 <ski> rudol,mud : or "pointful"
12:13:33 <mud> Thanks, that sounds like a better word
12:13:40 <ski> ("pointfree" is a synonym of "pointless")
12:13:58 <rudol> ski - OK, that can be googled
12:14:00 <erisco> and lights up my chat window every time
12:14:08 <ski> "points" refer not to the composition operator `.' (that'd be contrary), but to explicit inputs and outputs
12:14:24 <erisco> it is also called "tacit programming" or "tacit style"
12:15:01 <ski> there's also something called "wholemeal programming" which has some relation
12:15:31 <rudol> so is there anybody that would not prefer nshepperd_'s pointful, and very easy to understand impl in this case    mappend (Nim x) (Nim y) = Nim (x `xor` y)
12:15:31 <ski> rudol : ".. could be derived, .." -- yep
12:15:53 <erisco> that's a new one on me... initial hits suggest "wholemeal programming" is to think of the bigger problem
12:16:26 <rudol> Bird mentions that in terms of working against a whole list rather than its elements 
12:16:33 <mud> rudol: That's likely the best one, ya.
12:16:38 <pikajude> i need a way to check two cabal files for equality
12:17:22 <ski> <https://wiki.haskell.org/Sudoku#Sudoku_incrementally.2C_.C3.A0_la_Bird> mentions "Its also an excellent example of what has been termed wholemeal programming focusing on entire data structures rather than their elements."
12:17:31 <pikajude> there's not really a good way to do it is there
12:17:37 <sm> pikajude: cheap & quick: run them both through hpack-convert ?
12:17:43 <rudol> ski - exactl where I came across it
12:17:54 <pikajude> sm: does hpack-convert normalize the order of dependencies and stuff
12:18:03 <erisco> oh, I get it... a pun with piecemeal... I'm quick
12:18:21 <sm> pikajude: maybe, try it
12:19:02 <erisco> if I inject my own thoughts here then I say the enemy of this is the mindset of optimisations
12:19:04 <ski> e.g. instead of using explicit indexing or what-not, to access individual elements, one applies "collective" transformations over the whole
12:19:05 <pikajude> no, it doesn't
12:19:07 <pikajude> it just does map
12:20:02 <erisco> going bigger in the problem makes it simpler but probably gives up some optimisation opportunities
12:20:50 <ski> erisco : hm, not sure i realized the relation to "piecemeal"
12:20:59 <ski> (probably not)
12:22:38 <erisco> "Functional languages excel at wholemeal programming, a term coined by Geraint Jones. Wholemeal programming means to think big: work with an entire list, rather than a sequence of elements; develop a solution space, rather than an individual solution; imagine a graph, rather than a single path." Hinze ICFP'09
12:22:54 <ski> rudol : "so is there anybody that would not prefer .. pointful, .. in this case". in this case, i'd presumably prefer that (or maybe using a touch of message-dispatching syntax)
12:23:23 <ski> erisco : ty
12:23:35 <mud> erisco: I'm still not that sure what that actually means in practice :-/
12:23:42 <erisco> putting my own thought into this short description, we tend to get hung up on details
12:23:53 <mud> I think it's even been used is some book I read or skimmed, but I don't remember.
12:23:57 <erisco> we see the problem in front of us and try to maximize our information about it
12:24:06 <erisco> how do I exploit this facet and leverage that aspect and so forth
12:24:06 <ski> i suppose examples would be the in-bulk operations on (immutable) arrays (for lack of efficient singular (piecemeal) updates, if nothing else)
12:25:00 <ski> mud : in the graph case, i suppose it could mean to find all shortest paths, between any pair of nodes, rather than just between two given nodes
12:25:07 <erisco> and in all this effort we fail to see the broader picture
12:25:27 <erisco> the one with less detail, with less facts about the problem, because they may not all be relevant
12:25:51 <erisco> I see this happen with programmers trying to make certain optimisations
12:26:13 <erisco> they've latched onto a peculiarity of the specific example and are consumed by trying to exploit it
12:26:27 <rudol_> erisco - fyi, when I followed that link to #haskell-beginner, there was only 1 person in the room, and he knew no more (or less) than I!
12:26:43 <ski> rudol : forgot the trailing "s"
12:26:44 <mud> rudol_: It was supposed to have an s at the end
12:27:10 <erisco> rudol_, whoops, my IRC window cut off the 's'
12:27:55 <mud> -beginners I'm not sure is a great idea anymore though. It gets too quiet there almost and questions just die on the vine a lot more than they used to.
12:28:09 <mud> Worth a shot, but I would just ask here unless it's going poorly.
12:28:20 <sm> it was not different enough from #haskell
12:28:45 <erisco> but another place I see this connected is from what I heard from a disgruntled games programmer
12:28:49 <ski> sm : they try to have stricter rules about teaching
12:29:21 <sm> I found it not significantly different
12:29:28 * ski nods
12:29:31 <erisco> and he was advising that everyone stop thinking about the *common case* rather than exclusively the singular case
12:29:35 <mud> Well at one point it was strongly guided by bytemyapp and he was around a lot and there were many interested in the development of the haskell book, but some of that has fallen away now that the book is largely done.
12:29:36 <sm> still spans beginner to wizzard topics
12:29:48 <erisco> I mean everyone *start* thinking about the common case... derp
12:30:28 <erisco> so, he was saying, for example, do you have one vertex or millions of vertices? then write your program from the perspective of millions of vertices
12:30:36 <rudol_> I am happy here, and if you will just ignore any questions that are unsuitable I will eventually know the difference 
12:30:39 <erisco> do not, for example, write the program that works on one vertex and then repeat it a million times
12:30:59 <erisco> no one every has just one vertex, so why are we thinking about the problem that way
12:31:06 <erisco> no one ever has*
12:31:14 <orion> erisco: Are we tihkning about the problem that way?
12:31:19 <orion> thinking*
12:31:21 <ski> rudol_ : the basic rule here is "be nice, or else", fwiw
12:31:57 <erisco> this is particularly important thinking to writing efficient realtime programs, such as games
12:33:01 <erisco> orion, is who thinking about what in that way?
12:34:09 <orion> erisco: " do not, for example, write the program that works on one vertex and then repeat it a million times" <-- Is that really how the aforementioned game programmer sees us approaching problems?
12:34:35 <orion> If so, I'd be interested to see the specific interaction he had that led him to that conclusion.
12:34:45 * ski was reading it as how the aforementioned game programmer saw many other game programmers approaching problems
12:35:10 <erisco> orion, it was a talk given at a C++ conference. I don't know who the "us" was for the speaker, but presumably that is an opinion he has formed about the average programmer he encounters
12:35:22 <orion> Ah.
12:35:30 <orion> I thought he was complaining about Haskellers specifically.
12:37:08 <erisco> not sure how I'd find it again but I can try for a minute
12:38:40 <erisco> I *think* it is this one https://www.youtube.com/watch?v=rX0ItVEVjHc
12:39:17 <erisco> if you want to listen to some C++'ers get upset because the speaker is kinda saying C is all you need, stay for the questions :P
12:46:47 <orion> heh, thanks
12:48:13 <dolio> Why do you need C?
12:48:33 <Tuplanolla> It's all about the ffi.
12:48:35 <erisco> that is the talk that began my sympathies to real time programmers
12:48:55 <erisco> I realised from their perspective so many advances are happening but nothing applies to them
12:49:27 <eikke> is there anything like DefaultSignatures for associated types?
12:50:43 <dolio> Or alternately...
12:51:03 <erisco> all these new whizbang languages with garbage collectors and hardware abstraction are garbiage
12:51:50 <dolio> People at Intel wrote an entire C compiler designed to vectorize C code using SIMD instructions.
12:52:04 <infandum> Silly question: outside of records, what is the benefit of using lens? I tried an example of getting and setting a vector of maps, for instance, and the haskell version was shorter than the lens version
12:52:12 <dolio> Then edwardk wrote the same thing in C++ templates in a couple weeks.
12:52:36 <lyxia> eikke: just write a definition below, without the default keyword
12:55:15 <erisco> I like the idea of many embedded languages rather than reinventing syntax, compilers, type systems, many times over
12:56:08 <eikke> lyxia: got an example?
12:56:09 <dolio> Also there's people working on garbage collectors adequate for high frquency trading.
12:56:36 <dolio> I think if it's good enough for that, it's good enough for your 'real time' games.
12:57:12 <dolio> It's not free, though.
12:57:15 <erisco> well there is a difference between "working on" now and what the state has been for the last 20 years
12:57:50 <dolio> It's a product you can buy.
12:57:56 <lyxia> eikke: http://lpaste.net/358123
12:58:50 <orion> dolio: Do you think the current GC in the RTS is good enough to real time trading?
12:58:59 <dolio> In GHC? No.
12:59:18 <orion> What would need to happen for it to get to that level?
12:59:19 <dolio> This is a custom java runtime some company sells.
13:00:08 <dolio> It'd need to be completely redesigned to have latency guarantees. And I can't really even tell you how to do that.
13:00:28 <eikke> lyxia: where would DefaultT come from then?
13:01:11 <dolio> Maybe there are papers on what this company does, not sure.
13:01:25 <dolio> Also it's probably patented.
13:02:03 <erisco> you're not allowed to move electrons in certain patterns
13:02:09 <orion> Patents won't stop me.
13:02:32 <lyxia> eikke: it's whatever you want your default to be
13:02:33 <orion> If I had the knowledge and time to do that, I wouldn't let something as trivial as a patent stop me from doing it.
13:02:35 <dolio> orion: http://info.azul.com/2015-WEB-WP-C4-LP.html
13:02:43 <dolio> There's a form you can fill out to get their white paper. :)
13:03:16 <erisco> "I pledge allegiance to the patent office of the USA"
13:03:25 <eikke> lyxia: Ah, right. What if the default isn't fixed? My 'C' is a monad, the default rules are about MonadTrans-based instances
13:04:06 <dolio> orion: If you start now, maybe the patent will be expired by the time you finish. :)
13:04:27 <dolio> So you won't have to worry.
13:04:58 <eikke> lyxia: so in general I get (in the instances) things like 'type Foo (StateT s m) = Foo m'
13:05:32 <orion> dolio: Here's the whitepaper :) https://www.azul.com/files/wp_pgc_zing_v52.pdf
13:06:21 <dolio> What? They just try to trick you into getting spammed for a publically accessible link?
13:07:17 <dolio> Or publicly.
13:07:45 <lyxia> eikke: http://lpaste.net/358124 maybe? I'm not sure there is a very clean solution...
13:09:42 <lyxia> eikke: This is starting to look like MonadBase
13:11:00 <rudol_> ski, erisco thanks for the insight re "before and after" pattern. The ^ (semantic editor combinators) will take me longer to digest, but what I read here was very useful (and I can even, now, almost see how the types in the original, point-free version, line up!).  
13:15:52 <eikke> lyxia: thanks, I'll give that a try
13:17:08 <ski> rudol_ : yw (did you also look at the TV page ?)
13:18:03 <dolio> orion: This whitepaper is pretty light on the details.
13:19:09 <orion> dolio: Do you know of a toy Haskell program that could cause the GC to pause for a human-noticeable amount of time?
13:20:06 <dolio> Not off hand. I don't tend to write stuff where I'd care about that.
13:20:27 * dsal wants realtime haskell
13:21:16 <dolio> But, I mean, you need to think about stuff like...
13:21:19 <rudol_> ski - again, I had a quick look earlier and bookmarked it for later, thanks. I am not able to follow these articles, yet, as readily as somebody who already understands the motivation (through repeated exposure to related problems and their haskell solutions).
13:21:20 <dolio> > 1000/60
13:21:22 <lambdabot>  16.666666666666668
13:21:34 <orion> dsal: What is "realtime" Haskell?
13:21:53 <dolio> You have 16ms to do all your stuff for a frame at 60fps.
13:22:29 <dolio> So you need the amount of garbage collection time in a 16ms window to be capped such that it won't cause you to fail to do the work you have to do.
13:22:40 <mud> orion: realtime programming is when you have hard requirements that certain operations run in certain amounts of physical time at maximum. Something like that.
13:22:52 <dolio> And similar for higher frame rates.
13:24:30 <orion> How would you do that in other languages? Do you compile it to assembly and add up the number of CPU cycles required?
13:24:44 <dolio> Which version?
13:25:02 <erisco> saying games are hard realtime is probably wrong, but it is difficult to qualify
13:25:03 <mud> orion: You mostly don't. There's specialized tools/libraries you have to use. But yeah, something like that.
13:25:04 <dolio> For the hard deadlines version people do stuff like not using any heap allocation.
13:25:14 <ski> rudol_ : btw, fwiw, Conal Elliott (conal in here) is responsible for both those things
13:25:17 <dolio> And custom languages.
13:25:23 <mud> games are usually "soft realtime", which I'd have a hard time defining very well.
13:25:28 <dolio> Games are more low latency.
13:25:36 <erisco> the doesn't necessarily stop working because a frame is missed, which is what hard real time would suggest
13:25:53 <erisco> but missing some frames, depending on the frequency and pattern of, can go beyond just degrading the experience
13:26:03 <erisco> it can cause someone to throw it in the trash (i.e. Steam refund policy)
13:26:59 <erisco> I wear fancy pants and so my monitor does 144Hz, and thus a game has only 7ms to generate a frame
13:28:12 <erisco> i.e. I have decided I am even more picky than usual about framerates
13:28:41 <dolio> orion: This is a good talk edwardk told me about, by the way: https://www.youtube.com/watch?v=lJ8ydIuPFeU
13:28:46 <dolio> From a guy at Azul.
13:29:30 <erisco> the game that drops some frames when the user does some particular infrequent interaction is less of a problem
13:30:06 <ggVGc> afaik hard realtime doesn't usually mean very low latency
13:30:08 <ggVGc> rather the opposite
13:30:17 <erisco> the game that drops some frames every few seconds for the whole experience is a big problem
13:30:19 <ggVGc> you sacrifice latency to get constant latency
13:30:51 <erisco> hard real time, afaik, is neither about latency or throughput or frequency
13:30:58 <ggVGc> erisco: exactly
13:31:00 <erisco> it is about hitting deadlines
13:31:03 <ggVGc> it's about predictability
13:31:06 <ggVGc> right
13:31:28 <ggVGc> I mean, soft realtime is also about hitting deadline, it's just kind of okayu if you do
13:31:36 <ggVGc> like streaming a video
13:31:41 <ggVGc> or radio
13:31:49 <erisco> failure to hit a deadline is an utter failure of the system, i.e. the only utility of the system is when it meets deadlines
13:31:57 <ggVGc> not like sending data to your brakes on a car
13:32:06 <erisco> as you go softer it is just a degradation of experience rather than complete failure
13:32:56 <erisco> of experience or performance or however you're measuring the worth of the system
13:33:53 <erisco> or the signal to your air bags, yeah, stuff like that
13:36:50 <orion> dolio: In the paper they mention keeping a log of all memory accesses and (re-)marking areas of memory based on that.
13:38:06 <orion> "read barrier"
13:38:35 <dolio> Oh, that talk has very little to do with garbage collection, though.
13:38:39 <dolio> FYI.
13:38:41 <dolio> Just latency.
13:39:05 <dolio> Maybe if you search that guy's stuff enough, though, you'll find information about the garbage collection.
13:40:17 <rudol_> ski - I noticed that. Once I've given those articles the time and attention they deserve, and probably still find myself needing a hand, I might come back for further guidance. And, it looks like I'd get it too, from the author or whoever else is around. Thanks.
13:41:00 <erisco> but what we should be able to do is program in Haskell using Atom, or another embedded language, to solve these problems
13:42:24 <rudol_> erisco, I was using HaskForce, and just tried out Atom for this Nim project. It seems to work fine with the Haskell packages.
13:43:19 <erisco> I think we're talking about different things named "Atom", rudol_. I am talking about the embedded language called Atom.
13:43:49 <rudol_> erisco, even if you were talking about the editor, my comment was at a tangent ;)
13:46:42 <Rotaerk> hmm how is Atom an *embedded* DSL?
13:46:54 <Rotaerk> looks like it's just a DSL with haskell utilities for processing it
13:47:38 <erisco> you write the program with Haskell, and the resultant Haskell program outputs the Atom program
13:49:51 <Rotaerk> that sounds weird
13:50:07 <jared-w> Isn't that basically what a deep embedding is? Or is that still considered an EDSL?
13:50:13 <erisco> that's what deep embedding is
13:51:02 <jared-w> Thanks. I'm googling DSL/EDSL/etc right now since I've always been fuzzy on the differences and I feel like I should know that :p
13:54:22 <erisco> https://wiki.haskell.org/Embedded_domain_specific_language
13:55:43 <erisco> the intermediate representation, lets say the AST, is what makes it conducive to compiling
13:55:52 <Rotaerk> I always thought an EDSL was basically just a rich library for haskell, an alternative way of writing a haskell program
13:56:03 <erisco> it is
13:56:23 <Rotaerk> but this is something that produces a haskell program that produces a program that does what your code says to do
13:56:39 <erisco> but the idea of running the program to output another program is a natural thing you can do with a deep embedding
13:56:51 <Rotaerk> higher order programs
13:57:08 <Rotaerk> though I guess that's what compilers in general are
13:57:21 <Rotaerk> but in this case it's a const compiler...
13:57:30 <Rotaerk> only produces one program, rather than a program that's a function of input
13:57:31 <erisco> think of it this way... a compiler reads some source code and spits out some compiled code
13:57:56 <erisco> well, with a deep embedding, we've used GHC for the "read some source code" part of it
13:58:08 <erisco> then we run the program to do the "spit out some compiled code" part of it
13:58:09 <Rotaerk> and the type checking and such
13:58:16 <erisco> that's right
13:59:25 <erisco> we can use an existing language as the front end our new language, and that is a powerful thing
13:59:45 <erisco> because we needn't task ourselves with that busywork of defining new syntax and type systems and so forth
14:00:18 <erisco> I think the problem has been that you need a fairly sophisticated host language to make this worthwhile
14:00:42 <erisco> and to that end, Haskell's type system does a lot of work, and so does some of its syntax features
14:01:18 <erisco> with a type system that can do more and a syntax system that can do more, I think you'd have even more reason to use deep embeddings to make new languages
14:01:47 <erisco> mixfix notations would be a good addition, for example
14:15:17 <georgeP> Is there any difference between type `Ptr CInt` and type `Ptr (CInt)`? Or `IO Int` vs. `IO (Int)`?
14:15:35 <mauke> no
14:15:52 <mauke> other variants: (Ptr) CInt, (Ptr CInt), (Ptr) (CInt)
14:16:10 <georgeP> Ok
14:16:13 <erisco> ((Ptr) (CInt))
14:16:15 <mauke> > Nothing :: Maybe Int :: Maybe Int
14:16:17 <lambdabot>  <hint>:1:22: error: parse error on input ‘::’
14:16:19 <mauke> aww
14:16:45 <mauke> > (((Nothing :: Maybe Int) :: Maybe (Int)) :: (Maybe) Int) :: ((Maybe) (Int))
14:16:47 <lambdabot>  Nothing
14:17:01 <erisco> actually, (Ptr)(CInt), so now we have a technique to remove spaces from types
14:18:36 <mauke> > Nothing :: Maybe{--}Int
14:18:39 <lambdabot>  Nothing
14:19:04 <mauke> also works in C (struct/**/foo)
14:19:23 <mauke> but if you want to avoid comments in C, you have to get creative
14:20:03 <mauke> struct{int(a);char*b;}typedef(foo_t);foo_t(x);
14:20:28 <lavalike> mauke.min.c
14:24:40 <Just_Another> Am I actually posting something like this?
14:25:17 <Rotaerk> no, it's in your imagination
14:29:10 <trigone> hi! i'm reading a very interesting pdf on DSL using type classes (typed tagless final), and it said several time that haskell used a call-by-name type of non-strictness. i thought it used a call-by-need? and semantically, what's the difference bwn laziness and non-strictness?
14:29:40 <trigone> btw the pdf http://okmij.org/ftp/tagless-final/course/lecture.pdf 
14:32:10 <erisco> trigone, laziness is an implementation of non-strictness
14:32:51 <erisco> see https://stackoverflow.com/a/7141537/260584
14:36:25 <trigone> thx for the link. so, is haskell call by name or by value?
14:37:08 <erisco> I don't know anything about calling in Haskell
14:37:39 <erisco> sounds like an operational semantics thing and I don't know how that works
14:37:53 <whittle> trigone: My understanding is that that’s not a particularly relevant question: in Haskell you can’t alter any values, so the difference is academic. 
14:39:15 <trigone> whittle: well yeah but "what i wish i knew..." still says haskell is call-by-need (its ghc implementation, if you will), yet the pdf i was reading specifically said that haskell wasn't call-by-need, which makes things confusing...
14:40:31 <c_wraith> *haskell* only requires non-strict, by specification
14:40:40 <c_wraith> GHC is call-by-need
14:40:56 <trigone> ok thx!
14:41:34 <trigone> btw, how much is haskell2010 tied to ghc (in terms of specifications)?
14:41:51 <davean> it isn't, thats the point of a specification?
14:42:35 <c_wraith> technically, GHC no longer implements any Haskell specification.  That's...  another matter.
14:42:36 <trigone> well i wasn't actually sure of what the term haskell2010 referenced (a specification or an implementation)
14:43:13 <trigone> c_wraith: what do you mean?
14:43:34 <davean> trigone: the GHC implimentation is not specification compliant
14:43:47 <amx> trigone: the PDF itself says it's call-by-need in section 4.4
14:45:09 <trigone> amx: actually, i may misinterpret, but it says "Our evaluators so far have been call-by-name, inheriting the evaluation strategy from the metalanguage. We now show call-by-value and call-by-need (or, lazy) evaluators." (the metalanguage here is, i think, haskell)...
14:46:05 <c_wraith> I believe GHC has been out of compliance with the report since Show and Eq were removed as superclasses of Num.  But it's only really been significant since AMP
14:46:07 <amx> you are right, I should wear glasses
14:47:29 <jj15> I’ve been programming for over 10 years. Decided to learn Haskell. Feels like I’m learning programming all over again. Going through “Learn you a Haskell” at the moment.
14:48:17 <c_wraith> jj15: yes, that's basically what Haskell is.
14:48:24 <trigone> c_wraith: but then it means it creates its own standards right? possibly a better one, right? using hindsight and all...
14:48:39 <c_wraith> jj15: don't worry, eventually all your knowledge becomes relevant again.  You just need to work through some confusion first. :)
14:48:54 <jj15> Thanks c_wraith that’s good to know :)
14:49:07 <trigone> amx: the pdf isn't terribly clear anyway. i think that's what they say but i don't really get why they say that...
14:51:28 <pikajude> is there a way to get HUnit to show you a text diff, or a different testing library that does it by default?
14:56:23 <trigone> overall, regarding embedded DSLs, as i'm reading the pdf, i only find positive things relative to final implementation (vs ADT-based initial). is there a big tradeoff somewhere? or is it just young technology? (though it's from 2012 so i dunno)... esp wrt using DSL+free monad to implement effects, which vaguely seems a younger technique (though i'm not sure), but also less practical (wrt composition, esp, short of type wizardry), s
14:57:03 <robertkennedy> > fail "t" :: Either String Int
14:57:05 <lambdabot>  *Exception: t
14:57:09 <robertkennedy> So much for the tolerant left
14:57:49 <robertkennedy> Darn it I meant to capitalize Left now my shit post is ruined sorry chat
14:58:09 * hackagebot ethereum-rlp 0.1.0 – Ethereum Recursive Length Prefix Encoding – https://hackage.haskell.org/package/ethereum-rlp
15:13:01 <geekosaur> nicely snarky characterization of the Either dilemma >.>
15:13:11 <Welkin> Either dilemma?
15:13:17 <Welkin> you mean EitherT vs ExceptT?
15:13:29 <geekosaur> yeh
15:15:37 <dmwit> ExceptT doesn't do any better.
15:15:37 <geekosaur> and more generally whether it should treat both alternatives the same or not
15:15:45 <dmwit> > fail "t" :: Except String Int
15:15:47 <lambdabot>  ExceptT (Identity *Exception: t
15:17:23 <dmwit> > (throwError "t", throwError "t") :: (Either String Int, Except String Int)
15:17:25 <lambdabot>  (Left "t",ExceptT (Identity (Left "t")))
15:38:50 <Crinc> anyone around? :)
15:39:35 <lyxia> nope
15:42:27 <zachk> more and more people in here and less and less chat :(
15:43:43 <Welkin> they could be at work
15:43:48 <Welkin> pretending to work
15:43:55 <Welkin> or even doing actual work
15:44:15 <Welkin> or doing something more fun than irc
15:51:57 <Cale> If you have a question, asking is usually much better than asking to ask.
15:52:20 <Cale> (but maybe you just wanted a random conversation :)
15:54:12 <Zemyla> May I ask if I may ask a question?
15:54:33 <pikajude> nope
15:56:43 * hackagebot NoHoed 0.1.1, squeal-postgresql 0.1.1.1, store 0.4.3.2, yesod-alerts 0.1.1.0
15:56:43 * hackagebot  → https://hackage.haskell.org/packages/recent
16:33:59 <jj15> Confused on something: tell :: (Show a) => [a] -> String … What’s the purpose of the brackets? In the  I know [a] -> String means accepts a list of any type and returns a string. But I don’t understand the (Show a) part.
16:34:46 <mud> jj15: Just grouping. When you have multiple constraints, like (Num a, Show a) => then they're required, but for one it doesn't matter.
16:35:52 <jj15> Ah I see thanks.
16:37:55 <zachk> the Show a is a constraint that a must hold to
16:38:11 <jj15> I see this is mentioned in typeclass 101 in the learn you a haskell book.
16:39:02 <adelbertc> what is the difference between `dyn` and `vanilla` for Haskell code coverage (hpc) ?
16:41:03 <hpc> you rang?
16:41:48 <pikajude> how do I use wl-pprint to add linebreaks to a long string if the string doesn't fit in the document?
16:43:44 <pikajude> i could `intersperse softline . words` although that does sound a bit expensive
16:44:11 <hpc> it sounds like you just want a word-wrapping algorithm
16:44:34 <adelbertc> hpc: haha i meant hpc the haskell thing, unless you know something about that? :)
16:44:37 <hpc> depending on how softline is implemented, that might be the right way to go
16:44:43 <hpc> adelbertc: sadly no ;)
16:47:22 <pikajude> ok, i'll do softline tehn
16:47:24 <pikajude> then
16:47:26 <pikajude> whoops
16:48:25 <hpc> pikajude: what you have is an implementation of fewest-lines
16:49:03 <hpc> see https://en.wikipedia.org/wiki/Line_wrap_and_word_wrap#Algorithm and citations for FMTYEWTKA word wrapping
16:49:43 <pikajude> classic tex, using the minimum raggedness algorithm
16:50:05 <pikajude> don't know what fmtyewtka means
16:50:13 <hpc> far more than you ever wanted to know about
16:50:25 <hpc> and yeah, min raggedness is important for text that's justified
16:51:49 <pikajude> ok, so intersperse softline doesn't do the right thing at all
16:52:00 <pikajude> what i actually wanted was "fillSep"
16:52:04 <pikajude> don't know how that escaped my notice
16:52:46 <pikajude> if it's all softlines, and the entire text doesn't fit in the page width, *all* of them become linebreaks
16:53:01 <hpc> haha
16:54:16 <pikajude> shoutouts to whoever wrote wl-pprint, by the way
16:54:19 <pikajude> i'm sure it's a very complicated library
16:54:28 <pikajude> it's making my stylish-haskell-for-cabal-files very easy to write
16:54:46 <hpc> probably wadler and leijin ;)
16:55:04 <pikajude> well, and P
16:56:17 <pikajude> oh, here's a good one
16:56:41 <pikajude> a common cabal fileism is to put a long description on the next line after "description:" and indented a few spaces, but align a shorter description with all the other values in the file
16:56:47 <pikajude> how would one go about doing that with wl-pprint
16:59:02 <hpc> you might need to do that outside the module
16:59:15 <hpc> or, hmm
17:00:03 <pikajude> i might
17:00:35 <hpc> fillBreak is very close to what you want
17:01:43 <pikajude> fillBreak always produces a linebreak
17:01:52 <pikajude> because the integer argument i'd be giving it is the indent i want (2)
17:01:56 <pikajude> which "description" is of course longer than
17:02:13 <hpc> yeah
17:02:28 <hpc> it also needs you to give a number instead of knowing how wide the first column is
17:02:45 <pikajude> maybe i can institute a global haskell convention of always putting the description on the next line
17:03:09 <pikajude> doing it the "right" way requires me to know the desired output width and the width of the widest field in the main package description stanza
17:03:43 <hpc> i think the problem (for wl-pprint) is that you're aligning in both dimensions
17:03:56 <Lazersmoke> Does anyone know of a less horrible hack for using lens functions involving `MonadState` with `freer-effects`s `Eff '[State s]` than making an `instance MonadState MyState (Eff '[State MyState]) where` for concrete `MyState`, which isn't technically an orphan or undecidable because it is defined using a local type?
17:03:57 <hpc> imagine the text and labels in html-ish table cells
17:04:12 <hpc> you're aligning at the top, and you're aligning to the left
17:04:37 <pikajude> yep
17:04:51 <pikajude> but if my human brain can do it so easily, why is it so un-straightforward here
17:05:30 <hpc> it's so simple
17:05:35 <hpc> first we must program in a human brain
17:05:42 <hpc> why didn't we think of it before :D
17:05:56 <hpc> but yeah, i think you've just hit a point where this particular language falls down
17:06:09 <hpc> html does the same exact thing if you stick to divs
17:06:29 <pikajude> i've almost got it, i just need to pass around the user's requested max ribbon width all over the place
17:06:49 <hpc> oh, that makes it easier
17:06:53 <pikajude> or i could use a global IORef
17:06:57 <hpc> you don't have to come up with the number yourself
17:07:01 <pikajude> when's that ever hurt anyone
17:07:04 <hpc> haha
17:07:29 <hpc> honestly, (ReaderT :. IORef) is a pretty great type
17:07:53 <hpc> i think i got that right, imagine (:.) being (.) on types
17:08:04 <hpc> ReaderT (IORef s) a
17:08:10 <hpc> ReaderT (IORef s) IO a -- rather
17:09:06 <pikajude> no i'm talking about storing the requested width in a global ioref
17:09:39 <pikajude> which, actually, fixes everything
17:09:47 <hpc> as in using the unsafePerformIO top-level trick?
17:10:01 <pikajude> yea
17:10:06 <Gurkenglas> Lazersmoke, "modify $ l %~ f" isn't that much more horrible than "l %= f", so you could just use Eff's version of modify on "l %~ f"
17:10:09 <hpc> that's a terrible idea
17:10:16 <hpc> you can implement unsafeCoerce with that technique
17:10:19 <pikajude> works fine for a one-off command-line tool
17:10:39 <Lazersmoke> yeah I think that's what I'm gonna go with
17:11:19 <Lazersmoke> the version I just said doesn't actually work because you have to introduce extra plumbing to make it work for arbitrary effect lists anyway
17:14:56 <Lazersmoke> `modify $ someLongRecordNameYay %~ short . function . composition` looks better than `modify $ \p -> p {someLongRecordNameYay = short . function . composition $ someLongRecordNameYay p}`
17:18:59 <rudol_> I would like to know the thought process experienced haskellers go through to work out the types (by hand) of dm & md where dm = (. map); md = (map .)
17:19:51 <eitan> hello
17:20:02 <JuanDaugherty> yello
17:20:02 <zachk> hi
17:20:09 <eitan> hi :-)
17:21:07 <hpc> rudol_: it's a lot like how type inference does it automatically
17:21:14 <hpc> so for md (since it's easier)
17:21:16 <hpc> :t (.)
17:21:18 <lambdabot> (b -> c) -> (a -> b) -> a -> c
17:21:19 <hpc> :t map
17:21:21 <lambdabot> (a -> b) -> [a] -> [b]
17:21:31 <hpc> map is in the position of (b -> c)
17:21:32 <rudol_> so far so good :)
17:21:48 <hpc> so you make a constraint that (b -> c) = ((a -> b) -> [a] -> [b])
17:22:10 <hpc> or to disambiguate, since this will get confusing pretty quickly
17:22:23 <hpc> (b -> c) = ((a' -> b') -> [a'] -> [b'])
17:22:38 <hpc> if you split it out on (->) on both sides, you get
17:22:42 <hpc> b = (a' -> b')
17:22:51 <hpc> c = ([a'] -> [b'])
17:23:15 <hpc> now as your overall type, using (.) as the root of the expresison and applying map
17:23:23 <hpc> you get (a -> b) -> a -> c
17:23:48 <hpc> you have more specific values for b and c
17:24:04 <hpc> and the type you get is (a -> a' -> b) -> a -> [a'] -> [b']
17:24:09 <hpc> :t (map .)
17:24:10 <lambdabot> (a1 -> a -> b) -> a1 -> [a] -> [b]
17:24:25 <hpc> that first b should be b'
17:24:25 <mniip> consider the following
17:24:43 <mniip> if f :: a -> b and x :: c then f x :: (a ~ c) => b
17:25:00 <hpc> ^ this is a more technical explanation
17:25:04 <mniip> assuming a b c contain disjoint free variables
17:25:13 <mniip> or well, (a, b) and c
17:26:10 <rudol_> hpc - that's great, ty! And presumably, this scales to more complex terms, or are there some "tricks".
17:26:15 <mniip> md :: ((b -> c) ~ (a' -> b') -> [a'] -> [b']) => (a -> b) -> a -> c
17:26:41 <mniip> you can always simplify the f x type to be free of any equality constraints if there are no type families
17:26:51 <mniip> you just resolve the ~ equality structurally, recursively
17:27:06 <mniip> pretty much the Hindley-Millner process
17:27:56 <mud> rudol_: I like to start with unique type variables throughout the whole thing I'm trying to resolve, but ya that's pretty much it.
17:28:03 <mud> :t ((.), map)
17:28:04 <lambdabot> ((b -> c) -> (a -> b) -> a -> c, (a1 -> b1) -> [a1] -> [b1])
17:28:09 <mud> Like that
17:28:25 <mud> Except I usually just use different letters instead of a1, b1, etc. But whatever.
17:28:44 <mniip> mud, I like the letter yus
17:29:02 <rudol_> mud - is that alpha conversion
17:29:40 <mniip> rudol_, eeeeekinda, equality on polymorphic types lets you do that
17:29:47 <mud> Not sure what it's called. They're just arbitrary variables (except where they're equal in the same type annotation), so it doesn't matter what they are.
17:30:11 <mniip> (forall x. e) = (forall y. e[x\y])
17:31:01 <rudol_> mniip, mud - ty. I will try this out a bit. It certainly makes it harder to make mistakes if all the type vars have unique names 
17:31:50 <mniip> I usually can do it in my head without renaming or even spelling them out
17:32:00 <mniip> except, maybe, if higher kinded vars are involved
17:32:21 <mniip> traverse id, and the like
17:32:36 <rudol_> mniip - could you give an example of something more complex that pushes the limits of what you can do in your head?
17:33:02 <mniip> :t (traverse, join)
17:33:04 <lambdabot> (Applicative f, Monad m, Traversable t) => ((a -> f b) -> t a -> f (t b), m (m a1) -> m a1)
17:33:29 <mniip> it any combination thereof :p
17:33:52 <rudol_> so then you revert to the above techniques (if you wanted to do it by hand), right?
17:34:01 <mniip> sort-of
17:34:10 <mniip> have to spell the substitutions out explicitly
17:34:39 <mud> In practice, there's not a lot of point in doing it by hand really, to be perfectly honest. I'd usually just ask the compiler if I can't do it in my head.
17:34:58 <mniip> yes
17:35:02 <mniip> hole-driven programming
17:35:04 <mud> Usually you have some idea why you're asking though, like you know it's one of two functions and forget which one?
17:35:08 <mniip> I do that every so often
17:36:09 <rudol_> the first time I saw a video (or 2) on hhd, it looked like magic. It is quite amazing to me!  
17:36:22 <mniip> :t map negate $ traverse _ (replicate 3)
17:36:24 <lambdabot> error:
17:36:24 <lambdabot>     • Found hole: _ :: [a] -> [b]
17:36:24 <lambdabot>       Where: ‘b’ is a rigid type variable bound by
17:36:26 <rudol_> s/hhd/hole-drive
17:36:44 <mniip> hm, that's a bad example
17:37:22 <mniip> :t map (. negate) $ traverse _ (replicate 3)
17:37:24 <lambdabot> error:
17:37:24 <lambdabot>     • Found hole: _ :: [b] -> [c]
17:37:24 <lambdabot>       Where: ‘c’ is a rigid type variable bound by
17:37:32 <mniip> :t map (. negate) $ traverse id (replicate 3)
17:37:33 <lambdabot> (Traversable ((->) b), Num b) => [b -> b]
17:37:35 <mniip> yay
17:37:35 <rudol_> one video I watched showed that applicatives are composable, but the more focused one showed 33 examples
17:37:44 <rudol_> s/33/3
17:37:46 <mniip> except reader is not traversable
17:37:51 <mniip> :I
17:38:41 <rudol_> so he derived <*> for f (m a) where f and m are applicatives, using holes
17:39:12 <mniip> f <*> k = (<*>) <$> f <*> k
17:39:13 <mniip> amirite
17:39:44 <mniip> we're talking about (Applicative f, Applicative g) => Applicative (Compose f g) right?
17:39:58 <rudol_> mniip - tes
17:40:07 <rudol_> s/tes/yes
17:40:12 <mniip> ok, here's an applicative-related exercise
17:40:22 <rudol_> :)
17:41:03 <mniip> @let data Day f g a where Day :: (x -> y -> a) -> f x -> g y -> Day f g a
17:41:05 <lambdabot>  Defined.
17:41:22 <mniip> assoc :: Day f (Day g h) a -> Day (Day f g) h a
17:41:24 <mniip> assoc = _
17:42:58 <rudol_> is that GADT syntax - I haven't used those yet
17:43:15 <mniip> yes
17:43:39 <mniip> hmm
17:43:43 <mniip> forgetting something there
17:43:43 <prototrout> Same as: data Day f g a = Day (x -> y -> a) (f x) (g y)
17:43:45 <prototrout> no?
17:43:59 <mniip> prototrout, I think you need foralls to define that using boring syntax
17:44:02 <prototrout> no, because x and y
17:44:04 <prototrout> right
17:44:11 <mniip> yeah, forgetting (Functor f, Functor g, Functor h)
17:44:24 <mniip> be it in Day or in assoc
17:49:25 <rudol_> mniip - I am going back to the deriving types by hand thing first, but I have saved your challenge for a rainy day (when I read about GADTs), thank you.
17:56:03 <dmwit> mniip: Just working out the types of all the arguments in `assoc (Day a b (Day c d e)) = ...` is breaking my brain.
17:56:50 <rdococ> mou.
17:56:53 <mniip> dmwit, that's not what the pattern should be...
17:57:36 <mniip> oh
17:57:42 <mniip> nevermind, I overlooked that
17:57:54 <dmwit> What else could it be?
17:57:58 <rdococ> meow
17:58:08 <mniip> rdococ, i think you mean Mu
17:58:29 <dmwit> rdococ: Have you got a Haskell question?
17:58:57 <mniip> dmwit, when you're done with this construct an inverse!
17:59:18 <mniip> hint: one of these features (flip (.))
18:00:18 * hackagebot distributed-process 0.7.3 – Cloud Haskell: Erlang-style concurrency in Haskell – https://hackage.haskell.org/package/distributed-process
18:02:19 <rdococ> dmwit: not really, I just need friends :P
18:02:32 <rdococ> as in, friends that are here right now. :P
18:04:20 <dmwit> rdococ: Let's try to keep things on-topic. There are other channels devoted to idle chat.
18:04:32 <rdococ> Uh...
18:33:50 <dmwit> mniip: Okay, after playing with this a bit, I'm surprised this is possible at all. Are f,g,h really `Functor` and not `Applicative`?
18:36:19 <dmwit> If `assoc (Day fi gi (Day fi' hi ii)) = Day fo (Day fo' go ho) io` (`i` for input, `o` for output), it looks to me like `fo :: Day f g _1 -> _2 -> a` is forced, but I get to pick `_1` and `_2`. But then `_2` practically has to be `a`, because `Day f g _1` gives you nothing useful to work with -- essentially just a two-argument function whose return type you get to choose but whose arguments you don't, so you can't apply it anyway.
18:37:01 <dmwit> But if `_2 ~ a`, then we have a problem, because we will need to construct `io :: h a`, and we don't have the right stuff to do that.
18:42:43 <dmwit> Okay, I looked at kan-extensions. You got the definition of `Day` completely wrong.
18:43:39 <dmwit> It's `a -> (x,y)` not `x -> y -> a`.
18:53:59 <mniip> dmwit, yes
18:54:15 <mniip> dmwit, you're looking at contravariant Day
18:54:20 <mniip> the one I gave is covariant
18:56:54 <Welkin> when I hear about Day convolution, it makes me think of steve jobs and chiat day, the advertising company that made all the apple ads
19:05:05 <adelbertc> does anyone know what `vanilla` and `dyn` refer to here https://www.haskell.org/cabal/release/latest/doc/API/Cabal/Distribution-Simple-Hpc.html ?
19:09:40 <c_wraith> adelbertc: Vanilla means normal.  Dyn means dynamically-linked
19:11:06 <monochrom> vanilla is static no-profiling library (*.a). dyn is dynamic no-profiling library (*.so). There are two more: static profiling library (*.a again, but the filename has a "_p"); static debugging library (*.a again, filename has _d or _debug, I forgot).
19:11:22 <monochrom> Unfortunately there is no dynamic profiling.
19:12:40 <Lazersmoke> wewlad lens is pretty fucking lit
19:12:58 <MarcelineVQ> yeboi
19:13:06 <Lazersmoke> I thought it was just weird and overcomplicated
19:13:18 <Lazersmoke> but then I became a lens hex caster
19:14:12 <adelbertc> c_wraith: monochrom why does HPC run both by default?
19:14:22 <adelbertc> i just turned on --enable-tests and --enable-coverage and I see HTML outputs for both dyn and vanilla
19:14:47 <monochrom> I don't know HPC.
19:14:50 <dmwit> mniip: Oh, also I screwed up in a way that may mean `assoc` is implementable with your version, too. I'll have to play with it again after dinner!
19:14:55 <dmwit> mniip: Thanks for the brain-teaser.
19:15:28 <dmwit> mniip: (Where I said `fo :: Day f g _1 -> _2 -> a` above, I realized on the car ride home probably ought to be `fo :: _1 -> _2 -> a` which seems much more plausible.)
19:17:57 <mek42> in Haskell, is int(10)==float(10.0) ?
19:18:41 <erisco> > (10::Int) == (10::Float)
19:18:43 <lambdabot>  error:
19:18:43 <lambdabot>      • Couldn't match expected type ‘Int’ with actual type ‘Float’
19:18:43 <lambdabot>      • In the second argument of ‘(==)’, namely ‘(10 :: Float)’
19:19:03 <c_wraith> mek42: you could see that coming just given the type of (==)
19:19:23 <Lazersmoke> > fromIntegral (10::Int) == (10::Float)
19:19:26 <lambdabot>  True
19:19:44 <Lazersmoke> > (10::Int) == fromIntegral (10::Float)
19:19:45 <lambdabot>  error:
19:19:46 <lambdabot>      • No instance for (Integral Float)
19:19:46 <lambdabot>          arising from a use of ‘fromIntegral’
19:20:12 <Lazersmoke> > (10::Int) == round (10::Float)
19:20:14 <lambdabot>  True
19:20:37 <Lazersmoke> mek42: you need explicit conversions or else it won't even compile, but when it does compile, they are equal
19:20:39 <mek42> I thought this was the case
19:21:18 <mek42> so, one type needs to be cast into the other type?
19:21:45 <c_wraith> haskell doesn't have casting
19:21:54 <c_wraith> it has conversion functions.
19:21:56 <mniip> dmwit, thinking about it, it hasn't got an inverse but rather inverse up to extensional equality
19:22:04 <Lazersmoke> fromIntegral and round are just normal (overloaded) functions
19:22:13 <mniip> mek42, common misconception: (10 :: Int) is not a cast
19:22:26 <mniip> it's a type annotation restricting the type of a possibly polymorphic expression
19:22:35 <Lazersmoke> yeah, number literals are actually just :: Num a => a
19:24:21 <mek42> is it ok to compare Haskell behavior to other languages here or should that be done in #haskell-chat?
19:24:34 <Lazersmoke> If not for defaulting rules and some optimizations surrounding `x = x ==> f x = f x`, `10 == 10` would actually be ambiguous
19:24:55 <Lazersmoke> *mostly the defaulting rules
19:27:42 <dolio> Only the defaulting rules. :)
19:29:34 <mniip> Lazersmoke, no optimizations say anything about f x x though
19:30:16 <Lazersmoke> yeah, but it would be cool if they did :3
19:31:25 <Lazersmoke> but optimizations have to be anti-semantic, so they couldn't actually resolve that situation anyway
19:34:01 <Welkin> anti-semantic sounds too much like anti-semitic
19:34:32 <Lazersmoke> (that's the joke)
19:34:42 <Lazersmoke> it should really be a-semantic, though
19:36:32 <mek42> tyvm - this was helpful
19:57:23 * hackagebot swagger-test 0.1.0 – Testing of Swagger APIs – https://hackage.haskell.org/package/swagger-test
19:58:18 <mniip> dmwit, simple enough
19:58:27 <mniip> you can just copy fx/gy/hz over
19:58:30 <mniip> :t \(Day pza (Day xyp fx gy) hz) -> Day (\x (y, z) -> pza (xyp x y) z) fx (Day (,) gy hz)
19:58:32 <lambdabot> Day (Day t3 t2) t1 t -> Day t3 (Day t2 t1) t
19:58:49 <mniip> don't even need Functor
20:00:46 <mniip> the solution I had was much more complicated
20:23:50 <depois> alguem br? xd
20:25:11 <dmwit> mniip: Within five minutes of trying a second time, I got it. =)
20:25:25 <dmwit> (And it looks almost identical to yours, the only difference being I was associating the other way.)
20:32:49 <depois> alguem br? xd
20:32:49 <depois> alguem br? xd
20:33:21 <Axman6> depois: you ok?
20:33:49 <depois> Axman6: whait?
20:33:54 <Axman6> ah, looking for people in Brazil?
20:34:38 <Axman6> depois: https://wiki.haskell.org/User_groups/Brazil ?
20:34:50 <depois> ty bro xD
20:36:17 <Axman6> no worries :)
20:38:36 <koz_> Axman6: Are you from Brazil too?
20:38:43 <Axman6> no
20:38:45 <koz_> Or do you just happen to know how to speak Portuguese?
20:38:45 <Axman6> .au
20:38:52 <Axman6> Google does :)
20:38:57 <koz_> Ah, that'dbe why.
20:39:02 <koz_> Well, fair enough. I'm .nz myself.
20:39:09 <Axman6> and some guesswork lead me to try Portuguese
20:39:41 <Axman6> G'Day - you know Hamish or Stephen?
20:40:04 <Axman6> (Because Everyone in NZ [who knows Haskell] know everyone else)
20:41:09 <koz_> Axman6: Surprisingly, I dunno any other Haskellers in NZ.
20:41:12 <koz_> Literally.
20:41:37 <Axman6> D:
20:41:52 <Axman6> There's literally (probably) dozens of you
20:42:01 <Axman6> Dozens!
20:42:07 <koz_> Well, not at my university, that's for damn sure.
20:48:48 <Axman6> :(
20:49:00 <koz_> Axman6: Yeah, it's unfortunate.
20:49:29 <Axman6> I wouldn't be surprised if that were untrue though, assuming you've got a CS department
20:49:42 <koz_> We have a CS department, and I can assure you, it's true.
20:49:56 <koz_> This uni is a Microsoft shop to the gills; everyone is Java or C#, assuming they can program at all.
21:06:01 <jared-w> That's definitely not uncommon for a lot of Unis
21:06:55 <jared-w> My Uni is like <30 km away from Intel's largest fabrication plant so it's basically an Intel feeder school in a lot of ways. On the other hand, it has a pretty decently strong FP presence, so it's an interesting mix :)
21:08:15 <Axman6> IIRC Intel use a fair amount of FP internally
21:08:20 <Axman6> (well, non-zero anyway)
21:12:15 <mniip> heh, my uni used to have an intel department
21:12:24 <mniip> but then they left
21:12:38 <mniip> but then they bought a company that owned another department so effectively they're back!
21:14:09 <jared-w> nice! #hailCorporate
21:18:48 <koz_> jared-w: In our case, we're basically a degree mill for people to get low-end Microsoft tech support jobs.
21:18:56 <koz_> Our 'computer science' department is a name only. :P
21:19:23 <koz_> We recently got merged with engineering, and they're like, 10 times larger than we are at postgrad level. :P
21:19:29 <koz_> (because they do actual research work)
21:35:27 <halogenandtoast> koz_: my university was similar
21:35:41 <koz_> halogenandtoast: 'Was' meaning 'it's changed now', or 'was' meaning 'I'm not there anymore'?
21:35:51 <halogenandtoast> the later.
21:36:07 <koz_> halogenandtoast: A good thing then. What did you end up doing instead?
21:36:11 <koz_> (and how far did you go?)
21:36:45 <halogenandtoast> In university I just did a computer science undergrad.
21:36:55 <koz_> halogenandtoast: Ah, I see.
21:36:57 <halogenandtoast> I never did any graduate work.
21:37:08 <halogenandtoast> Not enough money ;-)
21:37:36 <halogenandtoast> Both me not having enough money, and being a graduate not producing any money.
21:37:48 <koz_> halogenandtoast: I hear you, on both counts...
21:37:53 <tomasino> I went to undergrad twice. The first time I felt kind of that same way. The second time I saw there were easy ways to fall into that pattern, do what they asked and not get much out of it. 
21:38:02 <halogenandtoast> I went into web development and I'm quite happy with it.
21:38:14 <tomasino> But I also saw opportunity to group up with the right crowd, some professors included, and push the limits
21:38:20 <tomasino> and that was a huge difference
21:38:20 <halogenandtoast> As a professional career path that is.
21:38:23 <koz_> tomasino: Working on that one, definitely.
21:38:57 <tomasino> there's value in the degree itself, mill or not
21:39:03 <tomasino> it's a gatekeeper document
21:39:13 <koz_> tomasino: I'm aware, believe me.
21:39:13 <tomasino> but once you get past your first job with it, nobody cares anymore
21:39:19 <tomasino> it's all about experience and what you bring to the table
21:39:35 <halogenandtoast> tomasino: depends on the path, a lot of web dev doesn't care about degree.
21:39:37 <tomasino> so, get the paper and get past that phase, but definitely get whatever you can out of the experience
21:39:51 <halogenandtoast> The most I've gotten out of my degree is that it allowed me to get a work visa more easily.
21:40:05 <tomasino> that's true, halo. There's lots of places where you can get in the door if you demonstrate some basic ability
21:40:29 <halogenandtoast> Doesn't hurt to have it though as a general rule.
21:40:35 <tomasino> koz_: what are you planning on doing after you're done
21:40:42 <koz_> tomasino: I wanna be a researcher.
21:40:49 <tomasino> definitely get the degree then
21:40:50 <koz_> That's why I'm at PhD level, lol.
21:40:51 <halogenandtoast> yup
21:40:53 <koz_> Yeah, I know.
21:41:07 <koz_> Workin' on it. :P
21:41:16 <tomasino> I found my course work much, much more engaging post-grad
21:41:31 <tomasino> and opportunity to push it was much more present
21:41:34 <halogenandtoast> tomasino: I'd believe that, kidn of wish I had done post-grad
21:41:40 <halogenandtoast> *kind
21:41:48 <halogenandtoast> but again, no money
21:42:06 <tomasino> i got lucky on the money aspect. couldn't have afforded it myself
21:42:08 <halogenandtoast> Dad passed away my first year of college and mom was a school teacher.
21:42:34 <halogenandtoast> So I had to work part time to support myself.
21:42:39 <tomasino> well, you're hanging out in #haskell, so I guess you made it work. :)
21:42:42 <halogenandtoast> And school + work was a bit much.
21:43:12 <tomasino> koz_: what area of research?
21:43:18 <halogenandtoast> tomasino: yeah, I'm doing alright. Wish I was doing more Haskell though...
21:43:40 <koz_> tomasino: Evolutionary algorithms, specifically for rule induction using logic synthesis.
21:43:58 <JuanDaugherty> from what?
21:44:06 <koz_> JuanDaugherty: What do you mean 'from what'?
21:44:21 <tomasino> sounds fun!
21:44:26 <JuanDaugherty> induction from environmental events generally?
21:44:41 <koz_> tomasino: Like all evolutionary algorithm work, it's both fun and frustrating, because every single solution is a special snowflake. :P
21:44:48 <koz_> JuanDaugherty: Normally, rule induction is from some data set.
21:44:58 <JuanDaugherty> i c
21:45:04 <koz_> The idea being that the data set gives you an incomplete view of the world, and the rules characterize said world.
21:45:08 <koz_> (well, as far as possible at least)
21:45:16 <koz_> (this is a tough problem even if you assume your data doesn't lie)
21:45:19 <koz_> (and it usually does)
21:45:37 <tomasino> You're just talking about the field in general, or applicative to bioinformatics specifically?
21:45:42 <tomasino> more general AI?
21:45:53 <koz_> tomasino: In general. My work is kinda a cross between logic, AI and data structures/algorithms.
21:46:02 <tomasino> very cool
21:46:09 <koz_> I'm essentially extending a result someone found for rule induction in the non-evolutionary sense.
21:46:20 <mniip> somehow ML/AI is my least favorite part of CS
21:46:21 <koz_> (basically, rule induction is equivalent to finding a minimal cover, which is basically logic synthesis)
21:46:39 <koz_> mniip: I can understand that, which is why what I do is mostly leaning on the logic and data structures/algorithms part.
21:46:51 <koz_> I went with evolutionary algorithms so that my supervisor would have half a clue wtf I'm doing. :P
21:47:36 <tomasino> doesn't sound like a degree mill. :)
21:47:44 <mniip> take an existing library, use existing methods, slap on a few heuristics, get terabytes of data, pour thousands of core-hours into it
21:48:00 <koz_> tomasino: I'm basically the only person doing anything of this sort.
21:48:04 <mniip> not interesting at all
21:48:07 <koz_> mniip: Yeah, from the practical end, it's definitely that.
21:48:22 <koz_> Especially nowadays, when the solution to any problem is 'throw a DRNN at it'.
21:48:29 <koz_> (and enough hardware to sink the Titanic)
21:49:35 <tomasino> I can see some fun in the expirementation in the application. There's a sense of discovery. But on the research side, you're inventing new techniques (or at least improving them). That's a whole different angle
21:49:41 <jared-w> koz_: that sucks, I'm sorry :/
21:49:56 * JuanDaugherty compares ai and ct on usefulness
21:50:02 <tomasino> I run a couple teams of web devs in advertising
21:50:06 <jared-w> (with regards to the degree mill comment)
21:51:05 <koz_> jared-w: Among all life's problems, I can think of many worse. :P
21:51:56 <tomasino> oh shoot, battery dying. Nice chatting folks. Night!
21:52:01 <koz_> Although today, I had to engage in the other grad student activity - marking stuff. :P
21:52:05 <koz_> See ya tomasino!
21:52:13 <koz_> (well, marking and prepping)
21:52:54 <jared-w> ahh, the beauty of grad life
21:53:13 <koz_> jared-w: Lol, 'beauty' isn't quite the word for 'helping someone teach basic data structures in Java'.
21:53:29 <koz_> 'Horror', 'frustration', 'wondering what is wrong with the world' are all more apt. :P
21:53:41 <jared-w> show me on the doll where the Java hurt you :(
21:53:51 * jared-w points to his soul
21:53:53 * koz_ points to everywhere. :P
21:53:56 <mniip> java is cool if you do it just right
21:54:11 <koz_> mniip: Yeah, namely 'disregard 90% of the language and then fake the remaining 10'.
21:54:38 <koz_> You know that, I know that, but teaching a roomful of second-years who've basically been told that Java is ${DEITY}'s gift to the world is frustrating.
21:54:55 <mniip> I got a lot of enjoyment during writing an IRC client for android
21:54:57 <jared-w> nah, more like "disregard 90% of the bullshit people do when writing Java, work only with people who also hate Java and avoid any codebase that enthusiastically mentions 'design pattern' in a comment somewhere"
21:54:59 <koz_> And the worst thing is, every explanation of why part X is awful touches on the peculiar awfulnesses of everything else.
21:55:16 <mniip> not to say I haven't got a lot of frustration
21:55:21 <mniip> but there were the good parts
21:55:22 <koz_> mniip: You and I clearly have very diferent definitions of the word 'enjoyment'.
21:55:46 <mniip> look https://github.com/mniip/bananapeel/blob/master/application/src/main/java/com/mniip/bananapeel/util/Hook.java
21:55:58 <mniip> a generic hook class that is shared between irc message hooks and client command hooks!
21:56:33 <mniip> class Sequence<C, D> extends ArrayList<Hook<C, D>> implements Hook<C, D>
21:56:38 <mniip> don't see stuff like that everyday!
21:56:49 * JuanDaugherty points to the dolls maven
21:57:06 <koz_> JuanDaugherty: Yeah, Java's tooling is also a peculiar and special kind of awful.
21:58:08 <jared-w> Java's tooling is actually pretty damn awesome if we forget that Maven exists
21:58:24 <koz_> jared-w: I really wanna know what your definition of 'pretty damn awesome' is, because it sure as hell isn't mine.
21:58:44 <jared-w> Like, the language is so utterly terrible and unwieldy that the only reason it even exists is because people have bent over backwards to make it usable by inventing all kindsa tooling
21:59:41 <jared-w> koz_: I don't know of any other language that has the kinda refactoring power you can get in intellij's Java IDE. Gradle is pretty neat. There's a lot of code generation stuff out there for Java as well and quite a few analysis tools and all that. Again, to compensate for its terrible shortcomings, but still, very impressive
22:01:52 <koz_> jared-w: I don't find any of them impressive. I won't even mention the fact that Gradle requires you to literally learn another language, which is actually much better than Java in basically every possible way.
22:01:54 <nshepperd> meh. i find all these fancy systems like gradle and ant annoying. they seem designed to personally offend me by preventing me from seeing what's actually going on
22:02:02 <koz_> Also what nshepperd said.
22:02:33 <koz_> I'm not even goign to mention the fact that IntelliJ's stuff uses an offensive amount of resources for what's basically a glorified text editor.
22:03:05 <jared-w> eh, that's valid. I suppose it's less the /quality/ of the tooling that I'm impressed by so much the sheer impressive amount of crap required to make Java 'usable' and the amount of effort people have put into doing so
22:03:28 <koz_> Yes, I would also be impressed with a rock sculpture made using only a rusty spoon.
22:03:42 <koz_> However, my first question would be 'Did the chisel factory have a shortage or are you just that oblivious?'.
22:16:14 <jared-w> lol, fair point
22:17:32 <koz_> Could someone please tell me if Data.Functor.Contravariant.Divisible has anything to do with divide-and-conquer algorithms, and if so, how they relate?
22:18:07 <slack1256> from I arm chair... no
22:18:18 <koz_> slack1256: ??
22:18:57 <slack1256> reading about that module, but knowing Functor and Contravariant I would say that no
22:19:24 <dmwit> koz_: I'm pretty sure that `divide` and `conquer` are just cute names, not clues about how they're intended to be used.
22:19:34 <koz_> dmwit: Really? That strikes me as odd.
22:19:45 <koz_> Well, in that case, what is the deal with Divisible?
22:19:56 <koz_> I'm kinda confused by it.
22:20:32 <slack1256> Applicative can be seen as a monoid for Functors
22:20:56 <slack1256> Contravariants are Functor with the arrow of the first argument flipped
22:21:20 <slack1256> Divisible can be seen as the analogous of Applicative for Contravariant
22:23:47 <koz_> slack1256: Let me see if I understood correctly. Applicative can be defined as a combination of unit :: f () and (**) :: f a -> f b -> f (a, b), as per https://wiki.haskell.org/Typeclassopedia#Alternative_formulation. So does that mean Divisible is that, but for Contravariants?
22:24:01 <koz_> Like, unit is conquer, and (**) is divide?
22:24:17 <dmwit> roughly, yes
22:24:29 <koz_> dmwit: OK, that at least makes some degree of sense.
22:24:38 <slack1256> (**) is analogous to divide yes. The correspondense between unit and conquer is messier
22:24:49 <koz_> slack1256: How come?
22:24:55 <slack1256> I don't like learning abstractions just by learning them
22:25:14 <slack1256> I would start by the examples and then generalize (argueably a harder job)
22:25:16 <koz_> slack1256: I guess I'm trying to get some kind of grip on what they're all supposed to be.
22:25:34 <slack1256> then start by the examples (instances)
22:27:47 <slack1256> oh cool, Predicate has an instance
22:27:49 <nshepperd_> koz_: i only know these from ekmett's talk on sorting functions - https://youtu.be/cB8DapKQz-I
22:27:56 <koz_> nshepperd_: Thank you - will watch!
22:28:00 <slack1256> that is one of the Contravariants I like
22:28:02 <koz_> I always enjoy Edward's talks.
22:28:03 <nshepperd_> I don't remember what they do though lol
22:28:13 <mac10688> anyone familiar with mysql-haskell? I'm trying to figure out a good way to write a query to saturate my models
22:29:09 <depois> buy ddos
22:30:06 <cocreature> mac10688: what do you mean by “saturating your models”
22:31:56 <mac10688> well I want to take the data from the query and start filling in my objects
22:33:02 <mac10688> https://hackage.haskell.org/package/mysql-haskell-0.8.1.0/docs/Database-MySQL-Base.html#v:query_
22:33:12 <mac10688> query_ :: MySQLConn -> Query -> IO ([ColumnDef], InputStream [MySQLValue])
22:33:27 <mac10688> I don't understand how I can get multiple rows from that type signature
22:33:45 <cocreature> you get it via the InputStream
22:34:28 <cocreature> e.g. https://hackage.haskell.org/package/io-streams-1.4.0.0/docs/System-IO-Streams-List.html#v:toList
22:34:47 <mac10688> ohhh
22:35:02 <mac10688> ohhh!!! bingo!
22:35:22 <mac10688> I think I can go from there now
22:35:31 <koz_> What's a good library in Haskell for infinite streams?
22:35:56 <slack1256> any streaming library works, no?
22:35:58 <cocreature> koz_: streams involving IO? otherwise just use a list
22:36:29 <cocreature> if IO is involved pipes,conduit,streaming,machines,…
22:36:52 <koz_> Machines?
22:37:02 <cocreature> yet another streaming library :)
22:37:11 <cocreature> @hackage machines
22:37:12 <lambdabot> http://hackage.haskell.org/package/machines
22:37:45 <slack1256> my current recomendation: for easy to setup learning and use -> streaming.
22:38:42 <slack1256> for sheer popularity on number conduit. For really nice compositional semantics (although sometimes confusing) pipes.
22:39:03 <slack1256> machines is a little raw, but has edward seal-of-approval(tm)
22:39:12 <koz_> slack1256: Thanks!
22:40:23 * monochrom is learning machines too. We can say "machine learning". :)
22:40:34 <koz_> monochrom: LOL!
22:40:56 <monochrom> Oh! Maybe I should check out streaming too. Never heard of it.
22:41:23 <slack1256> Maybe you should advertise yourself as "the guy that is doing machine learning of the kind that doesn't get funded"
22:41:46 <monochrom> haha much benchmark, so bar graph
22:42:09 <koz_> monochrom: LOL!
22:42:22 <koz_> The doge meme needs to be more widely deployed.
22:42:41 <slack1256> dogecoin rode that meme to oblivion
22:43:03 <slack1256> some took the meme more seriously, but now are doing ICOs (which are not funny)
22:43:13 <depois> buy ddos
22:43:16 <depois> BUY DDOS
22:43:17 <depois> ???
22:43:35 <slack1256> wat
22:43:45 <koz_> What slack1256 said.
22:43:59 --- mode: ChanServ set +q *!*@187-78-89-187.user.veloxzone.com.br
22:44:29 <halogenandtoast> So program design question, because I still can't decide how to model this. I'm trying to emulate a board game that has 9 asymmetrical factions. These factions each have a unique ability, unique units, unique power ups (which might give more unique abilities), but they also share a common set of actions and stats. Any suggestions on how to model that?
22:46:20 <koz_> I too am intrigued, as this is #relevanttomyinterests.
22:46:29 <mac10688> Maybe create a base class data type for shared characteristics and functions. and then a member for the different factions
22:46:33 <mac10688> I would try something like this
22:47:16 <mac10688> data baseClass = BaseClass { hp : Int, mana : Int, ... faction : Faction }
22:47:34 <mac10688> data Faction = Shaman | Wizards | Ogres
22:47:56 <mac10688> i don't know if my record syntax is right but hopefully it gets my point across
22:48:01 <mac10688> and naming could be better but oh well
22:48:17 <halogenandtoast> It's fine, I'll mess with nesting it like that.
22:48:27 <halogenandtoast> I kept thinking of the faction as top-level
22:48:59 <slack1256> nested records can be made manageble with lenses. 
22:49:03 <halogenandtoast> thanks for the suggestion, if it works out for me I'll let you know ;-)
22:49:32 <halogenandtoast> koz_: is it relevant to your interests because you know the game, or are just doing something similar?
22:49:38 <koz_> halogenandtoast: The latter.
22:49:44 <koz_> Or rather,thinking about it.
22:49:47 <koz_> But I think about a lot of things.
22:49:53 <halogenandtoast> Yeah I have that problem.
22:50:04 <nshepperd> instead of thinking of factions having unique abilities, you could also conceptualize it as all factions having the same set of abilities, some of which are conditional on what 'faction' bit the player has set
22:50:24 <nshepperd> this might help, or might not
22:50:31 <Axman6> you can use classy lenses to write code over all things which contain say the common attributes you're expecting: class HasFactionData a where factionData :: Lens a FactionData, hp :: Lens a Int, mana :: Lens a Int etc.
22:51:16 <halogenandtoast> Yeah I've considered just making each faction it's own data type and then have a class for shared behaviour / values
22:51:28 <Axman6> then you can define all your factions as different types, which contain FactionData, and have them all (trivially) instantiate the HasFactionData class, and write code over foo :: (HasFactionData a) = a -> Int -> Maybe a or whatever
22:53:44 <halogenandtoast> Alright I'm going to try a few of these things out.
22:57:53 * hackagebot movie-monad 0.0.0.0 – Plays videos using GStreamer and GTK+. – https://hackage.haskell.org/package/movie-monad
