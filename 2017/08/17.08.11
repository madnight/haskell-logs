00:00:09 * jared-w is about to write a python function that changes behavior depending on the type of the argument
00:00:16 * jared-w cries softly for he will never be clean again
00:00:22 <ab9rf> jared-w: you sad person you
00:00:49 <mibaz_1> Let me try and refine my predicament a bit
00:01:01 <ab9rf> jared-w: i have somewhere a ruby program, the core of which is a giant if consisting of "if x isinstanceof ...." over and over again
00:01:09 <pacak> Must to to the gym. It rains HARD. Sad person I am....
00:01:30 <jared-w> pacak: move to Portland and learn to suffer the rain like a true stoic :p
00:01:46 <jared-w> ab9rf: that sounds horrifying yet... expected? lol
00:01:48 <ab9rf> i used to work for a company with an office in portland
00:02:11 <ab9rf> i remember going to visit there and discovering that there were mushrooms growing in the parking lot
00:02:45 <jared-w> nice! lol, that sounds like Portland. It's a great place every now and then; overall I like it more than I dislike it; my girlfriend loves the area too so that helps
00:02:47 <jle`> mibaz_1: but yeah if you reammy mean for a function to only take a value of a type from a given constructor...it sounds like you just want the function to take the fields inside that constructor
00:03:05 <ab9rf> jared-w: it's too far north for me
00:03:11 <pacak> jared-w: I live in a place where it rains more often.
00:03:12 <ab9rf> jared-w: chicago is bad enough
00:03:37 <ab9rf> portland is like 3 degrees further north
00:03:54 <ab9rf> i really shouldn't live north of 40
00:04:09 <boj> i am about to move back to alaska :p
00:04:10 <jared-w> ab9rf: I personally love it up north. To me, you can always put on more clothing if you're cold... but if it gets too hot, after a while you can't get cooler without breaking the law :p
00:04:28 <boj> jared-w: exactly
00:04:37 <jared-w> boj: gonna buy an AK-47 as a going away present?
00:04:38 <pacak> me lives ~100km from equator
00:04:40 <ab9rf> jared-w: i don't deal well with the short winter days, i get SAD
00:04:47 <ab9rf> it's not the temperature
00:04:49 <ab9rf> it's the lack of sun
00:04:58 <boj> jared-w: no guns over here in japan :(
00:05:17 <jared-w> ahh, I gotcha. Do the happy lamps help at all with that? They help a lot for me
00:05:41 <jared-w> Portland would definitely suck for you though; we have so little sunlight Twilight was based in Portland-area because of it >_>
00:05:44 <ab9rf> jared-w: some but not enough
00:06:16 <jared-w> boj: sad day :(   You can definitely cure your ailment when you hop the border into Freedom-ska, though
00:06:18 <jle`> dmj` recently relocated to portland i believe
00:06:36 <jared-w> ಠ_ಠ jle` and dmj`? There are two of you?
00:06:37 <boj> jared-w: hah
00:06:45 <ab9rf> portland is nice, though. i've visited several times. nice downtown.
00:07:18 <dmj`> Yes, I'm a big Twilight fan as well
00:07:28 <jle`> yes we are the grave gang
00:07:32 <jle`> ^ jared-w 
00:07:36 <ab9rf> biggest downsides for me are not enough sun and no tornadoes
00:07:55 <boj> *no_ tornadoes? >.<
00:08:08 <jle`> tornadoes are a surprisingly efficient form of transportation
00:08:13 <jared-w> I'm more in the Hillsboro area for now, unfortunately. I'd like to live closer to downtown since that's where all the fun is. Ironically, when I was in high school I was really into working for Intel as a computer engineer. Now I'm all about the CS and the theory and I live right across the street from Intel.... 
00:08:18 <jle`> and also very little greenhouse gas emissions
00:08:22 <ab9rf> boj: you haven't lived until you've stood underneath a forming tornado
00:08:43 <jared-w> I've heard it's surprisingly fun. I kinda wanna do it sometime
00:08:59 <ab9rf> i had that chance a few years ago
00:09:00 <boj> ab9rf: i can only imagine. we just get rolled over by typoons over here
00:09:14 <ab9rf> boj: typhoons are too massive to be appreciated except from space
00:09:16 <dmj`> jared-w: jle` and I are related.
00:09:20 <boj> yeah :(
00:09:24 <ab9rf> dmj`: you can tell by the `
00:09:32 <dmj`> Separated at birth, reunited over IRC, backtick was merely a coincidence
00:10:08 <jared-w> Coincidence? More like mind reading amirite. That whole twin thing is pow'ful stuff
00:10:42 <ab9rf> "amirite" sounds like it should be a brand name for something
00:11:10 <jared-w> ab9rf: it'd be hilarious if it was a knockoff brand of `Emirates' branded stuff
00:11:17 <boj> "do you have stairs in your house?" is what i'd name my band
00:12:01 <jared-w> "Hi hungry, I'm band" is what I'd name mine
00:17:16 * hackagebot hw-balancedparens 0.2.0.0 – Balanced parentheses – https://hackage.haskell.org/package/hw-balancedparens
00:17:49 <boj> speaking of twins, is ertes-w yours jared-w ?
00:18:48 * boj assumes -w is some throwback to clan names, but realizes it could also mean "at work"
00:18:51 <jared-w> hah, nope. This was just the name format that was available on most platforms. I would've preferred jaredw (and then I'd be twinning with johnw) but it was usaully taken
00:19:12 <boj> ah :)
00:19:34 <jared-w> Never realized -w could be for 'at work'; that's clever
00:19:35 <fabian_> how am I supported to map over a non empty list? "(a -> b) -> NonNull [a] -> NonNull [b]"?
00:20:15 <ab9rf> fabian_: you want a type-level asserton that the list is nonempty?
00:20:32 <jared-w> Hmm... I'm not particularly tired, but something tells me I should attempt to go to bed so my girlfriend doesn't get super mad at how late I stayed up :p
00:20:40 <boj> good plan
00:21:02 <ab9rf> i will be glad when school starts and i can get to sleep at a reasonable hour
00:21:13 <ab9rf> only five more days
00:21:18 <jared-w> Plus I finally figured out how to get unstuck from what I'm working on, I think, so I'll let that marinate in my brain overnight
00:21:24 <boj> ab9rf: "reasonable" as in never because you are studying hard?
00:21:40 <ab9rf> boj: no, because my kids will have to go to bed at a reasonable hour 
00:22:01 <boj> ah, i mistook what you meant by school :)
00:22:13 <ab9rf> and they'll be out of the house most of the day so i get my quiet time during the day instead of having to wait for them to zonk out before i can unwind a bit so i can sleep
00:22:22 <jared-w> hah, gotcha. But still, why can't you go to bed while they're still awake? It took me a few years, but I finally trained my mom to do that around junior year of highschool
00:22:22 <boj> i go to bed with my almost 3yo so i can wake up at 5:30am to align with AK
00:22:56 <jared-w> boj: solid plan. I'm hoping to learn polyphasic sleep when I have kids. I figure with them waking me up 5 times a night anyway, it'll be good practice :p
00:23:21 <ab9rf> jared-w: because i can't go to sleep unless i get some time to decompress first, otherwise i just lie there unable to get to sleep. i could use booze but i don't like doing that, i always wake up with a headache
00:23:23 <boj> i kind of dig the morning person routine
00:24:11 <jared-w> ab9rf: meditation, noise canceling headphones, and yoga? ¯\_(ツ)_/¯ I mean, I'm sure what you've got works for you too, I just feel kinda bad if you're forced to stay up past when your kids go to sleep
00:24:41 <ab9rf> jared-w: it'll be better once school starts, i don't need as much decomp then
00:24:59 <jared-w> boj: I like it too. It makes me really sad because I am the complete opposite of a morning person. Every now and then it clicks and I'm a morning person for like 2 weeks and then it's back to 'o gawd am I awake yet' if I wake up before 10:30 :p
00:25:25 <ab9rf> jared-w: i'm the same way. but my natural clock is 30-31 hours
00:25:34 <boj> not enough time in a day, sigh
00:25:41 <ab9rf> it's REALLY hard to go to stay on a 24 hour cycle
00:25:54 * lolisa is a morning person, just in another time zone
00:26:01 <jared-w> ab9rf: oh damn, that's rough. How do you cope with that?
00:26:09 <ab9rf> jared-w: not well
00:26:33 <ab9rf> meanwhile my wife is one of those weird people who can sleep at the drop of a hat
00:26:44 <ab9rf> she slept in between contractions when she was in labor
00:26:52 <boj> lol
00:26:52 <jared-w> wow, that's impressive
00:27:46 <jared-w> boj: My favorite sleep schedule I was ever on was where I had a 3.5 hour nap from 8pm to 12:30am, a 1.5 hour nap from 4:30-6:00am and a 20 minute nap at 2pm.  I need more sleep than the average person due to being hard of hearing, but I was able to go really nicely on those ~5-6 hours of sleep a night. Plus, I was absurdly awake the entire time; blazingly mentally alert constantly, it was awesome.
00:28:09 <boj> this is my favorite hour. too late for the US, too early for EU. off topic, no problem
00:28:19 <jared-w> hah, same
00:28:21 <ab9rf> jared-w: i have a central auditory processing disorder which is part of why i need quiet time to decompress. listening to people talk is hard, and my son wants to talk ALL THE TIME
00:28:30 <MarcelineVQ> did you see that ludicrous display last night?
00:28:48 <Axman6> The ting about Aesenal if they always try to walk it in!
00:28:50 <jared-w> Unfortunately that sleep schedule was when I was a freshman in college and it slaughtered my socializing abilities so thoroughly that I eventually had to quit it to avoid depression due to isolation :p
00:28:57 <boj> MarcelineVQ: i may know what you mean, but which one?
00:29:57 * hackagebot DeepDarkFantasy 0.2017.8.11 – A DSL for creating neural network. – https://hackage.haskell.org/package/DeepDarkFantasy
00:30:24 <jared-w> ab9rf: interesting. I have almost the opposite, but in a different way. I have a /lot/ of bone damage in my ears, but I also have quite a bit of nerve damage too. However, even though I have tons of nerve and bone damage, I hear way beyond what I should be able to on paper because I'm very good at mentally decoding the hearing. ¯\_(ツ)_/¯
00:30:54 <jared-w> I totally get you on the listening being hard. I start shutting down after long conversations because it's just /so/ draining to have to force myself to comprehend what people are saying
00:31:06 <ab9rf> jared-w: i have no hearing loss, but i have to work hard to understand what people are saying and i'm hopeless in a high-noise environment
00:31:49 <jared-w> I know someone like that, actually. He was recommended hearing aids a few times but he doesn't need them because he has perfect hearing; it's all somehow lost when his brain tries to interpret it. Brains are weird :)
00:32:01 <boj> mmm, brains
00:32:23 <ab9rf> i didn't understand it until my half-brother was diagnosed with a CAPD and when someone explained what he had to me i realized i had the same thing
00:32:30 <ab9rf> (he's 18 years younger than i am)
00:33:15 <ab9rf> there's nothing to be done for it except cognitive awareness and mitigation strategies, which i had already figured out on my own, so it's just That Which Is
00:33:48 <ab9rf> i do have a nice collection of instrumental music though
00:34:06 <jared-w> In a high-noise environment, for me it depends. High noise for me is not what it is for others; I have very little way of knowing what noise is loud for people. Vacuum cleaners are very loud and obnoxious for me but not for others. Restaurants are incredibly difficult for me to hear in but normal people don't care. Planes? Totally fine for me; nobody else can hear on them though. Rock concerts or a strong
00:34:08 <jared-w> 'white' noise? I'm also fine even if it ruins everyone else's hearing.
00:34:13 <mibaz_1> My bro has auditory dislexia. Similar thing
00:34:19 <jared-w> hah, nice. Glad you've figured out how to cope with it :)
00:34:28 <cocreature> this channel is very -blah today ;)
00:34:34 <jared-w> Most all music is instrumental for me unless I sit down and memorize the lyrics
00:34:40 <foldr> cocreature: yeah, lots of noise here
00:35:17 <jared-w> We'll shut up when someone starts talking about some interesting FP stuff. Other than that, no shame in keeping the channel from dying at 1am :p
00:36:17 <mibaz_1> Ok what even am I thinking -> http://lpaste.net/357596
00:36:41 <foldr> mibaz_1: {-# LANGUAGE DataKinds #-}
00:36:41 <jared-w> Pretty sure you were thinking "how do I improve the types in tic tac toe" ;)
00:36:54 <jared-w> foldr: we're trying to avoid that :p
00:37:38 <mibaz_1> jared-w: an incredibly important pursuit
00:37:50 <boj> just waiting for a juicy haskell question i probably can't answer
00:38:06 <jared-w> mibaz_1: have you looked at paramaterized GADTs?
00:38:49 <mibaz_1> jared-w: umm, I read about them a while ago, let me reread the wiki article...
00:39:13 <jared-w> mibaz_1: another keyword you might want to look up is 'phantom types'
00:39:24 <jared-w> (same thing, basically)
00:39:34 <mibaz_1> jared-w: aren't phantom types a way to simulate dependent types?
00:40:18 <jared-w> Eh, they've always felt more like providing a bit more information and keeping boilerplate to a minimum. Anything related to GADTs is technically going down the road to dependent types
00:40:36 <foldr> mibaz_1: define "simulate"
00:40:36 <johnw> dependent types are "types dependent on terms"; phantom types are part of types dependent on types
00:40:50 <foldr> There are some problems that dependent types solve that can be solved without dependent types.
00:40:53 <foldr> There are problems that can't.
00:41:39 <jared-w> So, in a sense, you're correct. GADTs, phantom types, DataKinds, TypeFailies, yadda yadda, all sorta going down the road towards dependent types. (Not that all of those are able to give you all the power of dependent types)
00:42:06 <jared-w> TypeFamilies*
00:43:46 <mibaz_1> Will all those things die with dependent haskell, then?
00:43:53 <mibaz_1> 33 years from now
00:44:06 <jared-w> DH is actually targeted for ~2018-2019
00:44:35 <johnw> GADTs will still be there, but you'll get pi-types added on
00:44:36 <MarcelineVQ> it won't be that soon if richard doesn't get some poor fools to help but it's not forever-away
00:44:39 <johnw> datakinds should disappear
00:44:43 <johnw> and type families
00:44:52 <jared-w> And ideally all of those things are able to be done with dependent types and none of those extensions will be needed anymore (which is good; they've complicated Haskell a /lot/ for a moderate amount of expressiveness power)
00:44:52 <johnw> phantom types will not disappear (they're a different thing)
00:45:13 <Axman6> will the result be better than type families? I like type families
00:45:24 <johnw> the result will be way better: ordinary functions
00:45:33 <johnw> the ability to case on types
00:45:34 <Axman6> sounds good to me :)
00:45:39 <jared-w> In practicality... Most of those won't disappear, I think. Or at least they'll "disappear" in a way that allows old code to compile (ie in the backend rather than programmers losing ability to write type families). That's my guess
00:45:41 <johnw> well, case on type-level constructions I should say
00:45:45 <johnw> not case on sort Type
00:45:49 <boj> i had a hard time explaining to a friend why dependent types were useful. they understood the vector example that typically comes up, but didn't see the point. was at a loss to provide more solid "industry" answers
00:46:12 <boj> i guess that reflects my own total understanding...
00:46:38 <johnw> boj: imagine a type that encodes the fact that a list is actually sorted
00:46:51 <Axman6> or that a tree is actually balanced
00:47:06 <jared-w> boj: they're useful once someone considers the trinity of computing. Further, the vast amount of benefit from dependent types will be done on the library level
00:47:09 <Axman6> or that your operating system cannot crash >_>
00:47:10 <erisco> yeah, well, would help if the industry used dependent types more...
00:47:29 <johnw> or a function like foo :: pi. (b :: bool). if b then Float else Double
00:47:56 <johnw> but dependent types also introduce a LOT of complexity
00:48:01 <erisco> it is bizarre because once you see the ability of dependent types you realise the use on every little thing
00:48:03 <johnw> I don't think you'll ever just start using them everywhere
00:48:16 <erisco> well, you can see the need without knowing dts specifically
00:48:25 <foldr> dependent types introduce a lot of simplicity ;p
00:48:42 <jared-w> You can also use dependent types to create amazingly generic functions. For example, it's possible to use dependent types to create a function that can append heterogeneous lists together in a type-safe manner
00:48:45 <foldr> the tricky part is equality because you need to reduce terms for that
00:48:58 <erisco> the vast majority of code ever written has not been shown to work
00:48:58 <jared-w> You can use them to split heterogenous lists in a type-safe manner as well
00:49:05 <erisco> worse, it has never been specified how it should work
00:49:46 <erisco> people probably don't see this gaping vacancy because it is par for the course
00:50:06 <johnw> foldr: there's the data too.  Having dependent types are great and all, but manipulating dependently typed values, when there's multiple layers of dependency, not so much.
00:50:15 <jared-w> https://existentialtype.wordpress.com/2011/03/27/the-holy-trinity/ I'm also a fan of this particular article and the 'trinity of computation'
00:50:59 <jle`> mibaz_1: from what you pasted
00:51:01 <erisco> boj, I'd just Socratically have them realise they really don't know if their programs work
00:51:10 <boj> what do groups like mine writing boring "make some department's work 1% more efficient" gain with dependent types? i mean, the haskell refactoring story is already great, but we're not writing hard realtime systems which could impact people's lives
00:51:12 <jle`> it looks like you just want Spot = UL | UM | UR | ... ?
00:51:23 <jle`> and Board = (UL -> Piece) ?
00:51:25 <erisco> boj, then you say DTs are a formal system to help with that
00:51:37 <jle`> or a vector of Piece's indexed by Spot's ?
00:51:41 <jle`> * Board = (Spot -> Piece)
00:51:42 <jared-w> You can think of types as a way to write logical prepositions. With dependent types, you have access to a higher form of logic than with non dependent types
00:51:50 <jle`> something like an always full Map Spot Piece ?
00:51:57 <MarcelineVQ> boj: if you can describe what your function does in the type it becomes very diffuclt to write it wrong, the compiler also can guide you better
00:52:05 <jle`> i don't think you really want dependent types
00:52:20 <cocreature> MarcelineVQ: the problem is that it might also be very hard to write it correct :P
00:52:22 <foldr> Singleton types are the best types.
00:52:36 <MarcelineVQ> cocreature: currently that's very true
00:52:46 <erisco> Void, the only true singleton type
00:52:46 <MarcelineVQ> it'll depend how the dust settles :X
00:52:50 <mibaz_1> off the cuff gadts look like what I need
00:52:57 <boj> hmm, yeah. i kind of see it
00:52:58 <jle`> what
00:52:58 <foldr> erisco: totality ftw
00:53:00 <jle`> why
00:53:04 <erisco> foldr, hehe
00:53:07 <jared-w> Dependent types are equivalent to predicate logic
00:53:14 <jle`> mibaz_1: do you want a piece to be indexed by the spot it can belong in?
00:53:18 <cocreature> I don’t think that’s something that will ever fundamentally change. if you slap too many things in your types, you end up formally verifying your code and while I love formal verification it can be a ton of work
00:53:29 <jared-w> So you can express predicates at the type system with them, which I like a lot
00:53:30 <jle`> mibaz_1: i can't imagine what you'd use a GADT for
00:53:38 <MarcelineVQ> jared-w: I was under the impression that desrbes refinement types
00:53:41 <foldr> cocreature: quickcheck is often a decent approximation
00:53:43 <fabian_> ab9rf: It's a Data.NonNull from mono-traversable
00:53:55 <jle`> mibaz_1: do you want Pieces that are type-indexed by the spot they can go in?
00:53:59 <jared-w> MarcelineVQ: refinement types aren't generic predicates and predicate logic; they're a bit less powerful than that
00:54:01 <jle`> which is ... already of questionable utility
00:54:18 <foldr> can't be an engineer without approximating :P
00:54:19 <jle`> mibaz_1: what sort of type safety are you going for here?
00:54:20 <johnw> refinement types must be computable
00:54:53 <boj> cocreature: that was kind of my concern. i suppose they are more of a "right time, right place" kind of thing?
00:55:09 <boj> just because you have them doesn't mean using them all the time is correct
00:55:20 <boj> (for business, time, etc. reasons)
00:55:31 <cocreature> yeah
00:55:40 <jared-w> boj: but when they are there, you can pop up to that level whenever you need and then bring it back down.
00:55:43 <johnw> at least, that's the case with LiquidHaskell
00:55:59 <mibaz_1> jle`: a board specified by a "spot" type that can be passed to functions
00:56:03 <foldr> With infinite resources we would invest infinite resources in research and verification
00:56:11 <jle`> mibaz_1: and what would that Spot type encode?
00:56:15 <jared-w> For example, in Haskell today  you can use very simple and generic types or you can throw newtypes all over the place
00:56:19 <erisco> well I don't know... not formally verifying something stresses me out... so I am projecting some of my own insecurities into my evaluation
00:56:21 <boj> johnw: indeed. as a junkie i'm ready to dive right in. it's more about showing my minions why it's useful :)
00:56:26 <jle`> mibaz_1: what would it mean for a board to be parameterized by a spot
00:56:29 <boj> oops, meant jared-w 
00:56:30 <johnw> mibaz_1: yes, your Spot example could be done with just GADTs and DataKinds
00:56:35 <jle`> mibaz_1: is that spot...the last spot placed?
00:56:55 <jle`> you don't even need GADTs for spot-indexed pieces
00:57:01 <foldr> I want quotient types
00:57:08 <cocreature> erisco: it might be cheaper to reimburse people for the mistakes in your code than verifying that there are no mistakes :)
00:57:09 <mibaz_1> jle`: Kinda like this (If you didn't see it, sorry if you did): http://lpaste.net/357596
00:57:13 <jle`> we have quotient types, checkout Rational :)
00:57:19 <jared-w> boj: but really, I'd probably try to sell dependent types through potential library benefits
00:57:21 <jle`> mibaz_1: yes, that's what i'm looking at
00:57:30 <foldr> jle`: :(
00:57:30 <jle`> you want the board to be parameterized by a Spot in its type
00:57:44 <jle`> oh huh i didn't realize that Rational was a quotient type in more ways than one
00:57:46 <erisco> cocreature, I know, and that is why I struggle to find any job that seems like a good idea
00:57:50 <jared-w> libraries benefit from being able to write intricate, powerful, and incredibly flexible code--can you just imagine how souped up and 'roided out the lens library could be with full dependent types? lol
00:58:01 <jle`> it's a quotient type in that it normalizes to equality classes
00:58:10 <mibaz_1> jle`: Yeah that's right, I'm not quite understanding how to answer your question
00:58:10 <jle`> and it's also a quotient type in that it represents a rational quotient hehe
00:58:12 <jared-w> jle`: we have sucky quotient types. I want real ones :'(
00:58:25 <foldr> jared-w: I can only imagine how easy the documentation would be to understand :)
00:58:26 <jle`> mibaz_1: you say you want a Board parameterized by a Spot
00:58:29 <jle`> what would that Spot represent?
00:58:45 <jle`> like, having Vector parameterized by an Natural number, and that nat would be its length
00:59:13 <erisco> cocreature, I need something where the tolerance for mistakes is low to nil, but then the practices for that are probably unit testing
00:59:16 <mibaz_1> jle`: I think the answer is a Piece, the declaration of which I omitted in the pastebin
00:59:28 <erisco> try it for a few months, if it doesn't explode then ship it
00:59:28 <jle`> the Spot represents a piece?
01:00:02 <jle`> mibaz_1: so if you had 'Board UL', how is that different from a 'Board UR' ?
01:00:09 <erisco> FPE kicks in on the second year, but most of the customers will be upgraded to the new version by then...
01:00:12 <jle`> or a 'Board LL' ?
01:00:18 <jle`> what does the p in 'Board p' mean?
01:01:00 <mibaz_1> jle`: a board contains 9 spots, the board doesn't have a p
01:01:15 <jle`> but you said edarlier that you want a Board specified by a Spot type
01:01:29 <jle`> ...er, what do you think that means?
01:01:48 <mibaz_1> I may have misspoken; I don't have a solid picture in my mind of "Board specified by Spot"
01:02:06 <mibaz_1> In fact, upon further examination, I don't think I have any idea what that means.
01:03:06 * hackagebot oidc-client 0.3.0.1 – OpenID Connect 1.0 library for RP – https://hackage.haskell.org/package/oidc-client
01:03:32 <jle`> same
01:03:33 <mibaz_1> Spot adds a position context to a Piece, a Board contains 9 Spots (Pieces with position). The problem is in specifying that it has 9 _different_ spots
01:03:46 <foldr> nine type parameters
01:04:04 <jle`> mibaz_1: well if you have data Spot = UL | UM | UR | ...
01:04:07 <mibaz_1> I could just construct every board with the correct combination of spots... I don't want to have to
01:04:11 <jle`> then type Board = Spot -> Piece
01:04:28 <jle`> it sounds like you just want some sort of 'total' Map
01:04:33 <jle`> a Map where every key has a value
01:04:36 <jle`> then that's just Map Spot Piece
01:04:53 <mibaz_1> hmmmmmm.... You may be onto something
01:05:27 <jle`> `Spot -> Piece` has the right API but it might be a bit bad on performance, heh
01:05:42 <jle`> but there's
01:05:44 <jle`> @hackage total-map
01:05:44 <lambdabot> http://hackage.haskell.org/package/total-map
01:05:48 <boj> is mibaz_1 trying to define tic-tac-toe strictly in types? or just... "hello, world" tic-tac-toe?
01:05:49 <mibaz_1> performance is very important to me
01:06:12 <jle`> a more type-safe tic tac toe implementation
01:06:24 <ab9rf> high speed tic-tac-toe engines are critical to work security
01:06:28 <mibaz_1> boj: It actually already worked with a 2d list. Improving it now
01:06:33 <jle`> alternatively if you're willing to ditch the named spots
01:06:42 <jle`> you can use `Vector 9 Piece`, from the vector-sized library
01:07:02 <mibaz_1> jle`: I would love to ditch the named spots
01:07:10 <jle`> and then maybe type UL = 0, type UM = 1, type UR = 2
01:07:23 <boj> mibaz_1: nice. i only ask because sometimes people pop in here and just want to make something simple, and then we lay into them with things you'd only know after using the language for a decade :)
01:07:26 <jle`> ah, then yeah, you can do type Board = Vector 9 Piece
01:07:32 <jle`> @hackage vector-sized
01:07:32 <lambdabot> http://hackage.haskell.org/package/vector-sized
01:08:03 <mibaz_1> boj: haha that is true. Some guy popped in with a "what is this channel" and learned all about type theory ;)
01:08:06 <sbrg> mibaz_1: you could represent the board using Word64. That's what I did when I had to write a tic-tac-toe "AI" for a course
01:08:09 <jle`> or Vector 3 (Vector 3 Piece)
01:08:31 <sbrg> it's not quite as type-safe as the suggestions above though 
01:08:48 <jle`> the real benefit over this vs. a board with explicit positions is that now you can programmatically manipulate indices
01:09:04 <mibaz_1> sbrg: that could definitely work. I'm going for maximum type safety, however
01:09:18 <jle`> that is, Vector 3 (Vector 3 Piece) or Vector 9 Piece, instaed of Board = Board Piece Piece Piece Piece Piece Piece Piece Piece Piece
01:09:19 <mibaz_1> jle`: Yes that's preferable. I could easily up the board size
01:09:45 <jle`> the explicit fields method is technically the "same" structure, except you can't manipulate indices without a bunch of boilerplate
01:10:25 <ubsan_> why use Word64?
01:10:29 <ubsan_> I can imagine using Word32
01:10:37 <mibaz_1> jle`: let me think about it and look it over for a couple of minutes
01:10:38 <sbrg> if you want to support larger boards
01:10:43 <erisco> cocreature, so instead I think worthwhile work is making verification easier
01:10:45 <ubsan_> ah, okay
01:11:09 <sbrg> though Word64 will still limit you to 8x8. 
01:11:15 <jle`> the other way you could programmitically manipulate indices is of course with just [[Piece]], but then you lose type safety
01:11:23 <jle`> well, at least one layer of type safety
01:11:43 <ubsan_> sbrg: why don't more languages have bitsets :(
01:11:46 <erisco> the Musk motto... if you want it to succeed then it needs to be obviously better
01:12:14 <sbrg> heh
01:12:16 <ubsan_> imo, dependent types just haven't had long enough in the mindset of most programmers
01:12:22 <ubsan_> they're coming down the line
01:12:36 <erisco> we're still trying to hook the world on Haskell
01:12:43 <tdammers> we are?
01:12:51 <ubsan_> you don't need functional programming to have dependent types ;)
01:12:51 <tdammers> I thought we were trying to avoid success at all cost
01:13:09 <tdammers> you don't have to want dependent types to need functional programming
01:13:10 <evincar> Is there anything like "cata :: (Base t a -> a) -> t -> a" (from recursion-schemes) with a type like "(Base t a -> b) -> t -> b"?
01:13:17 <erisco> we're not all British
01:13:36 <ubsan_> (side note: I think some of the crazier aspects of dependent types are cool, but not necessary for a useful dependent system)
01:13:55 <evincar> I want to fold over a structure and return the same structure but with a different phantom type
01:13:59 <tdammers> erisco: thank God. I love me my coffee.
01:14:42 <evincar> That is, I have a function of type "Term 'Phase1 -> Term 'Phase2" and I want its implementation to be of the form "cata $ \ case { ... }"
01:15:12 <evincar> I guess I could just add some kind of cast, but...bleh
01:15:35 <mibaz_1> jle`: If I used a vector, how could I ensure that my function 'place :: Board -> Spot -> Piece -> Board' doesn't get bad indices? I think that really was my subconscious motivation here
01:15:54 <jle`> well now Spot is `Finite 9`
01:16:05 <jle`> which is an Integer from 0 to 8
01:16:17 <jle`> or, well, i guess more abstractly, a type with 9 inhabitants
01:16:19 <mibaz_1> Awesome I hadn't seen Finite
01:16:29 <jle`> so you'd write place :: Board -> Finite 9 -> Piece -> Board
01:16:39 <jle`> you might want something like `type Spot = Finite 9`
01:17:10 <mibaz_1> type Spot = (Finite 3, Finite 3), perhaps
01:17:20 <jle`> yeah if you're into that kind of stuff
01:17:33 <mibaz_1> My child's middle name will be tuple
01:17:45 <jle`> be careful about Finite though since it has a partial Num instance, because Num is awful
01:19:44 <mibaz_1> Ok I think that might be it. Lemme hack it up and see
01:20:00 <cocreature> erisco: making it easier it’s definitely worthwile work! I just have my doubts that it’s possible to get to the point where it actually makes sense for the majority of applications.
01:20:17 <cocreature> I’m more than happy to be proven wrong here ;)
01:20:23 <erisco> cocreature, I have zero doubts
01:20:40 <erisco> cocreature, the only doubt I have is for the relevancy of humans at the ultimate point
01:21:40 <cocreature> erisco: looking forward to your results :P
01:24:05 <erisco> cocreature, the first step is just making what already exists more presentable, and that is something Idris is tackling well
01:25:05 <erisco> but other than presentation the other vector is simply doing less work, and that requires a smarter system
01:25:12 <freeside> what takes longer to learn: straight haskell98, or all the ghc extensions?
01:25:16 <erisco> so then you have your proof tactics and SMT solvers and so forth
01:25:46 <erisco> but at some point we have to take a leap out of the closed domains and into something more general where intelligent guesses have to be made
01:25:54 <boj> freeside: you kind of need to know haskell98 to understand what the extensions do though, right?
01:26:30 <erisco> we're in a phase of defining where all the walls are and then solving all the problems within the box we built
01:26:37 <jle`> freeside: er, one is somewhat of a subset of the other
01:26:47 <freeside> sure. c = a + b; but i'm asking, b > a ?
01:26:52 <erisco> and if we can't do that then we build a different box
01:29:06 <freeside> assuming you already know haskell98, and that learning haskell98 took time t1, and assuming subsequently learning all the ghc extensions takes time t2, is t2 < t1, or t2 > t1, or t2 >>> t1
01:30:11 <foldr> What constitutes learning?
01:30:21 <foldr> At what point have you learned something?
01:31:29 <freeside> for purposes of this discussion, let us say Learning is Eq, Ord without needing Show
01:34:08 <erisco> foldr, you've learned something once you exhibit a different behaviour in the same circumstance
01:35:20 <erisco> freeside, I don't even know what all the GHC extensions are, but it varies a lot between them because some are just small syntax extensions
01:35:36 <erisco> freeside, whereas something like DataKinds opens a whole new possibility
01:36:08 <jle`> it doesn't really make sense to learn ghc extensions without learning haskell 98...
01:36:14 <jle`> this would be like learning Ord without learning Eq
01:36:18 <jle`> to use your metaphor
01:36:23 <erisco> furthermore, understanding Haskell 98 is not necessarily what you want... GHC understands Haskell 98 very well but it isn't out writing its own programs
01:38:05 <erisco> what you probably want is practice in applying Haskell to novel problems, and that is about learning the functional style
01:38:22 <jle`> yeah learning ghc extensions on their own is kind of silly/useless
01:38:35 <freeside> i never said i wanted to learn ghc extensions without learning haskell98.
01:38:56 <erisco> i.e. you want to be a machine that synthesizes Haskell programs from abstract problems
01:38:56 <freeside> i wanted to know which operation takes longer time.
01:39:04 <erisco> fueled by coffee
01:39:11 <freeside> i understand that one operation has another as a prerequisite. that is orthogonal to the question.
01:39:32 <freeside> booting your computer takes time. running a program takes time. you can't run a program until you've booted your computer. it is still possible to compare the two times.
01:39:50 <jle`> are you asking about (time to learn haskell + ghc extensions) - (time to learn haskell) ?
01:40:21 <freeside> yes, please, if it is necessary to phrase it that way
01:40:29 <jle`> just trying to clear up any ambiguity
01:40:56 <jle`> i'm not sure if it's really a meaningful endeavor to learn ghc extensions on their own on top of haskell 98, just to see what they're about
01:40:58 <foldr> There are more language extensions than there are no language extensions
01:40:58 <erisco> with something that clearly isn't a group
01:41:13 <jle`> i don't know how it could be done
01:41:23 <jle`> or to what degree of learning you'd want to achieve
01:41:33 <jle`> for example you can read about all of the ghc extensions in an afternoon
01:41:36 <jle`> from the GHC manual
01:41:40 <erisco> freeside, learning GHC extensions took me less time than learning Haskell
01:41:49 <ventonegro> freeside: I'd say Haskell98 takes longer
01:42:21 <jle`> but, from the time when i got proficient at haskell98 (maybe a few months?) to the time i was proficient at DataKinds (maybe a year or two?) there is a big difference
01:42:24 <jle`> but i waosn't continually learning one
01:42:44 <erisco> freeside, the extensions that took me the longest to figure out were GADTs, TypeFamilies, and DataKinds
01:42:50 <erisco> I still need a better grasp of RankNTypes
01:42:56 <freeside> gotcha
01:42:57 <foldr> There are so many extensions
01:42:59 <jle`> but i wasn't actively learning about DataKinds the entire year, i was writing other haskell and datakinds was just useful
01:43:06 <foldr> If you want to learn all of them it'll take a lot of time
01:43:26 <jle`> it doesn't make any sense really to learn about ghc extensions for the sake of learning them; they come up as you do your normal haskelling
01:43:35 <jle`> well, there are some GHC extensions that you might want to learn about for the sake of knowing them
01:43:38 <jle`> like TupleSections
01:43:41 <jle`> that one's pretty neat
01:43:56 <freeside> i'm just concerned about the unknown unknowns
01:44:00 <erisco> yeah but those extensions are so trivial you can learn them in an instant
01:44:07 <ubsan_> what's TupleSections?
01:44:10 <jle`> i wouldn't try to learn ghc extensions
01:44:18 <jle`> > (4,) "hello"
01:44:21 <lambdabot>  (4,"hello")
01:44:24 <jle`> ubsan_: it treats (,) like an operator
01:44:28 <ubsan_> oh what the what?
01:44:33 <jle`> you know, like
01:44:35 <jle`> > (4 +) 10
01:44:38 <lambdabot>  14
01:44:45 <jle`> > ("hello" ++) "world"
01:44:47 <lambdabot>  "helloworld"
01:44:54 <jle`> > filter (< 4) [1..10]
01:44:54 <sbrg> > (1,,3) 2
01:44:56 <lambdabot>  [1,2,3]
01:44:56 <lambdabot>  (1,2,3)
01:44:59 <foldr> > :t (,,,)
01:45:01 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
01:45:08 <ubsan_> :t (,)
01:45:10 <lambdabot> a -> b -> (a, b)
01:45:14 <foldr> :t (,,,)
01:45:16 <lambdabot> a -> b -> c -> d -> (a, b, c, d)
01:45:22 <ubsan_> ... interesting
01:45:23 <foldr> :t (,(),,())
01:45:26 <lambdabot> t1 -> t -> (t1, (), t, ())
01:45:33 <erisco> and apparently list sections got canceled, bummer
01:45:34 <jle`> i wouldn't really concern yourself with learning extensions for the sake of learning them.  usually if anything, you run into new ways to solve problems, and those ways might *require* extensions
01:45:43 <quchen> Here’s a list of all GHC 8.2 extensions. http://lpaste.net/357598
01:45:44 <jle`> freeside: but the extensions themselves don't help you solve your problem
01:45:45 <ubsan_> :t (,) (,)
01:45:47 <lambdabot> b1 -> (a -> b -> (a, b), b1)
01:45:48 <quchen> There are looooads.
01:46:12 <jle`> you don't learn an extension to solve a problem, you learn a new problem solving technique that might require enabling an extension or two incidentally
01:46:28 <ab9rf> jle`: oh, stop being so reasonble
01:46:31 <jle`> a new tool/approach
01:46:49 <ubsan_> what is Arrows
01:46:51 <jle`> but there are simple extensions that only really offer sugar/syntax
01:46:58 <jle`> like TupleSections
01:47:07 <jle`> or LambdaCase
01:47:10 <jle`> or MultiWayIf
01:47:24 <jle`> or UnicodeSyntax
01:47:26 <quchen> BangPatterns!
01:47:36 <jle`> they don't really offer any new language features
01:47:37 <foldr> RecordWildCards
01:47:57 <foldr> I wish MonadComprehensions worked with ApplicativeDo
01:47:58 <jle`> they aren't really an extension of haskell capabilities as much as an extension of the syntax
01:48:03 <foldr> Then, with RecordWildCards, you could write:
01:48:10 <jle`> or well, not even an extension of the syntax, just extra sugar
01:48:37 <foldr> [ User {..} | emailAddress <- foo, password <- bar ] :: AccValidation E User
01:49:06 <foldr> But, alas, monad comprehensions don't desugar to do notation but directly to bind :(
01:49:30 <ab9rf> foldr: sounds liek another extension is needed ;)
01:49:31 <jle`> alas poor monad
01:49:33 <jle`> i knew him well
01:49:43 <foldr> ApplicativeComprehensions \o/
01:50:55 <foldr> What happens if you enable both MonadComprehensions and ParallelListComp?
01:51:11 <ubsan_> seriously, what is Arrows
01:51:16 <jle`> the extension?
01:51:19 <ubsan_> yeah
01:51:20 <jle`> it's proc/do notation
01:51:32 <jle`> it's sort of a super niche thing that isn't worth learning until you find a library/api that uses it
01:51:38 <ubsan_> oohhhh
01:51:40 <ubsan_> okay
01:51:49 <foldr> Just use needle with PragmataPro instead :P
01:51:55 <bvad> jle`: Are arrows niche or is the extension?
01:52:13 <jle`> the extension and proc/do notation are niche
01:52:22 <ubsan_> wow, Haskell98 didn't have hierarchical modules :O
01:52:26 <jle`> arrows can't really be called niche because one instance is pretty commonly used
01:52:27 <ab9rf> i've only seen one or two things that actually use Arrows
01:52:32 <jle`> we use Arrow instances every day
01:52:34 <ab9rf> the syntax extension that is
01:52:40 <jle`> in fact almost all Haskell code uses an Arrow instance
01:52:42 <ab9rf> the Arrow typeclass is everywhere
01:52:43 <bvad> jle`: that was my impression as well
01:52:44 <quchen> Hopes for arrows were high once, people thought it could be the next Monad, but it didn’t come to that.
01:52:52 <jle`> but Arrow as an abstraction is niche.
01:52:58 <foldr> ubsan_: fun fact, in Haskell 98, \a -> a == b should parse as (\a -> a) == b but GHC implemented it incorrectly
01:53:00 <quchen> For a long time, arrow was a library for working with tuples.
01:53:02 <erisco> arr is upsetting
01:53:05 <quchen> No that we have Bifunctor, it’s not even that.
01:53:11 <ubsan_> foldr: ... eww
01:53:18 <jle`> well we still would like (&&&) somehow
01:53:44 <ubsan_> foldr: why would that be a thing -.-
01:53:44 <foldr> quchen: Arrow = Profunctor + Category
01:53:45 <evincar> I'm actually really fond of arrows now
01:53:51 <michi7x7> @pl \a b -> nub $ zip a b
01:53:51 <lambdabot> (nub .) . zip
01:53:53 <jle`> but yeah, the Arrow abstraction (and writing polymorphic Arrow functions) and designing types around Arrow functionality has faded away into obscurity in modern haskell
01:54:02 <jle`> except for niche applications
01:54:06 <evincar> They're great for a dataflow-oriented style of programming
01:54:22 <jle`> for the most part, most Arrow-based API's are now more naturally expressed as Applicative-based API's
01:54:23 <evincar> But the proc notation desugaring isn't very good
01:55:02 <jle`> there are still some corner cases where Arrow is a more natural fit or offers advantages over Applicative, but those cases are increasingly rare
01:55:08 <jle`> especially now that we have ApplicativeDo
01:55:34 <ab9rf> everything new is old again
01:55:34 <jle`> that knocked off one previous domain that Arrow might have had an advantage over Applicative
01:55:49 <quchen> tdammers: You’re at Well-Typed now?
01:58:40 <evincar> I dunno, my main gripe is that arrow notation (either with proc or the operators) just isn't very good
01:58:51 <evincar> The semantics are great
01:59:17 <evincar> It's basically a super-verbose embedding of a concatenative language
02:01:44 <evincar> Sequential composition is ">>>", parallel composition is "***", "dup" is "returnA &&& returnA"
02:02:25 <quchen> Is there any Backpack documentation in the GHC user’s guide?
02:02:46 <cocreature> quchen: afaik there isn’t
02:02:55 <quchen> Urgh
02:02:58 <cocreature> quchen: the best docs are a wiki page and ezyang’s blog
02:04:01 <quchen> Great :-/
02:04:18 <quchen> I guess it’s still very experimental then so they didn’t want to advertise it?
02:04:19 <Athas> Isn't Backpack part of the official GHC feature set now?
02:07:08 <evincar> The example from John Hughes's "Programming with Arrows", "Kleisli readFile >>> arr words >>> arr (filter (== w)) >>> arr length >>> print" is "readFile words [ w = ] filter length print" in a typical concatenative language :P
02:07:17 <evincar> *Kleisli print
02:07:41 <evincar> I'll quit evangelising though
02:07:48 <tdammers> quchen: yes
02:08:15 <freeside> mmm. thanks for the discussion.
02:09:09 <ab9rf> arr arr arr
02:09:19 <ab9rf> ahoy matey
02:10:19 <ubsan_> hello ab9rf 
02:10:31 <freeside> the reason i wanted to know how long all the extensions would take to learn, was because i'm having trouble formulating my logic in straight haskell98, so i thought maybe some extension would help solve my problem.
02:10:34 <ubsan_> is it international talk like a pirate day or smth
02:10:45 <ubsan_> freeside: maybe you should try coq ;)
02:11:02 <mibaz_1> Do I need datakinds to use vector-sized? Compiler is complaining at me
02:11:11 <freeside> my problem: it is possible to buy 5 pieces of mangoes, but it should not be possible to buy 3.4 liters of mangoes. and i am not sure how to express this in haskell. https://pastebin.com/tLj12P2x
02:11:31 <jle`> freeside: yeah, usually you would look for a technique to solve your problem, and which might require an extension.  but it's not the other way around
02:11:39 <ab9rf> why can't you buy 3.4 liters of mangoes?
02:11:39 <jle`> mibaz_1: you need DataKinds to use 9 as a type
02:11:59 <ab9rf> i had a quart of chicken in my fridge until this evening
02:12:27 <jle`> freeside: in general you look for the techniques themselves, and the extensions follow after
02:12:38 <mibaz_1> jle`: In that case, if I were trying to avoid datakinds (I'm not) I could essentially do the same thing with gadts, then, as other suggested, correct
02:12:42 <quchen> foldr: The \a -> a == b thing you mentioned above, why is that?
02:12:59 <jle`> mibaz_1: what do you mean the same thing
02:13:08 <jle`> you need DataKinds either way
02:13:12 <jle`> GADTs is the thing you don't need
02:13:18 <jle`> (if i understand your question correctly)
02:13:25 <evincar> Yeah, I would probably start with a GADT and then get rid of it...
02:13:39 <ab9rf> freeside: you probably need to subdivide "measure" into two subclasses
02:13:40 <mibaz_1> jle`: ah, so not exactly the same thing, but the same outcome by naming 'UL, UR...'
02:13:43 <ubsan_> (if you actually want to do this, I think a language with dependent types is a good option)
02:13:45 <quchen> foldr: Doesn’t a lambda extend as far as possible to the right?
02:14:07 <ubsan_> or, perhaps, using out-of-line things
02:14:09 <jle`> mibaz_1: there hasn't been anything suggested so far that needed GADTs, but there has been a lot that might have needed DataKinds
02:14:15 <jle`> and some that need neither
02:14:15 <evincar> That is, Pieces :: Int -> Qty 'Unit, Liters :: Float -> Qty 'Volume, Kilos :: Float -> Qty 'Mass or something like that
02:14:34 <ubsan_> I would probably use something like
02:14:57 <freeside> hm, the part i was having trouble with, was connecting up the generic unit of measure with the specific quantity. because i want to be able to say that gasoline is sold by the liter and not by the piece.
02:15:02 <mibaz_1> jle`: Someone suggested parameterized GADTs to address my pastebin initially, to avoid datakinds
02:15:30 <mibaz_1> I didn't look into it so I can't say I understood where they were going with that
02:15:31 <jle`> hm, i'm not exactly sure what was sugegsted, sorry
02:16:08 <mibaz_1> Oh well, I'm not scared of datakinds so the grind continueds
02:16:20 <mibaz_1> tomorrow though
02:17:12 <evincar> DataKinds is benign as extensions go
02:17:20 <evincar> Some are definitely malignant :P
02:17:25 <erisco> freeside, one thing you can do is newtype Integer, or whatever numeric type
02:18:26 <freeside> what i want is for Haskell to give me a type error if I try to use the wrong measure for a quantity, but i don't want to have to make Fruit a type, or Mango a type; that should happen at runtime.
02:18:35 <evincar> Is there a convenient way to swap out a phantom type parameter without unsafeCoerce?
02:19:10 <erisco> freeside, you have Litre as a type and Count as a type, say
02:19:36 <evincar> Like, if I have "BigRecursiveDataType Foo" and I want a "BigRecursiveDataType Bar", I can write a safe function where each case is of the form "Foo a b c -> Foo a b c"
02:19:47 <evincar> But it's boilerplatey
02:20:21 <erisco> freeside, what is mango then, a string?
02:21:47 <freeside> a mango is a data value which knows that it gets measured by the piece
02:23:41 <freeside> but only a purchase of mangos specifies just how many pieces are in the shopping cart.
02:25:07 <freeside> tell me i don't need dependent types for this
02:29:16 <evincar> You don't need dependent types for this
02:29:27 <druidofluhn> The way I would do it is have three data types, Count/Volume/Mass, with perhaps an Item data type that has a constructor for each of those
02:29:48 <druidofluhn> But then you run into the problem that you can't really have both volume and mass of rice, or mass and count of mangoes
02:30:02 <freeside> i only want one or the other, not both
02:30:21 <freeside> i'm okay with only letting rice be sold by the kg, not the l
02:30:30 <druidofluhn> Would that then work with some sort of CountLike/VolumeLike/MassLike type classes?
02:30:43 <ab9rf> druidofluhn: that's what i'm thinking
02:30:53 <jle`> you can do something simple with just phantom types
02:30:54 <druidofluhn> OK, I can't really see how you would do it with a single huge data type
02:31:08 <freeside> how would i do it with phantom types?
02:31:16 <ab9rf> however, i'm a moron, so i'm probably wrong
02:31:51 <jle`> data Item (m :: Measure) = Item Category String
02:31:57 <druidofluhn> ab9rf: I've not got that much Haskell experience and didn't get far through reading the Idris book (even though Edwin taught me Haskell)
02:32:36 <jle`> and data Purchase (m :: Measure) = Purchase (Item m) (Quantity m)
02:32:42 <jle`> hm but then i guess you need a GADT for quantity then
02:32:49 <jle`> so it's not as simple as phantom types
02:32:55 <freeside> mmm
02:32:59 <jle`> well
02:33:05 <jle`> actually you can index it by *
02:33:07 <druidofluhn> jle`: why both Category and String in the Item constructor?
02:33:09 <jle`> and have quantity be just any normal type
02:33:19 <jle`> druidofluhn: that was freeside's original design
02:33:23 <druidofluhn> Oh OK
02:33:32 <jle`> freeside: data Item m = Item Category String
02:33:50 <jle`> and if you had, say, newtype Liter = Liter Double
02:33:56 <jle`> then you have an "open" measure type
02:34:09 <jle`> where you can extend it with a measure of any type
02:34:25 <jle`> DataKinds + GADT's you would probably need if you wanted a closed measure type
02:34:52 <freeside> then how do i assert that Heineken is Beer, and Beer sold by the Liter?
02:35:05 <kuribas> freeside: Heineken is Beer?
02:35:13 <jle`> oh, is the quantty associated with the Category?
02:35:16 <freeside> yes
02:35:42 <freeside> Heineken is Beer. Beer is sold by the Liter. Therefore Heineken must be purchased by the Liter.
02:36:01 <jle`> hm, well, going back to no-gadt's no-datakinds
02:36:15 <jle`> assuming closed measures, open categories and values
02:36:34 <freeside> yes
02:37:08 <dkov> I can make this into a monad, right? https://pastebin.com/HZzVYM1x
02:37:15 <jle`> data Category = CPour String Double | CWeight String Double | CCount String Int
02:37:31 <jle`> data Item = Item Category String
02:37:54 <jle`> hm, but how would you restrict purchases
02:38:09 <Iceland_jack> dkov: Foo cannot be a Monad
02:38:50 <jle`> dkov: i don't think you want to write a monad for foo
02:39:04 <freeside> if you have Category CPour String Double then i have to say not only that Beer is sold by the liter, but that Beer is sold by the 2.5 liter.
02:39:06 <jle`> also by 'instance' you probably just mean value
02:39:24 <jle`> dkov: you might just want `State Foo`
02:40:02 <jle`> that is, a monad for (Foo -> (a, Foo)) functions
02:40:13 <jle`> but it looks like all you do is modify Foo's
02:40:20 <jle`> and you don't produce results out of them
02:40:24 <jle`> so you might really only need a Monoid
02:40:34 <jle`> like `Endo Foo`, a monoid for (Foo -> Foo) functions
02:40:49 <jle`> then you can write something like someFunction = foo "hello" <> bar 4 5
02:40:58 <kuribas> bah, cryptic python messages.  And people think the haskell typesystem is difficult...
02:41:50 <jle`> freeside: hm yes, then categroy might not be a good name for it
02:41:51 <MichaelBurge> I have some code that is infinite-looping. I wonder if there's a good workflow for debugging by writing a "termination proof" to find the error.
02:42:04 <jle`> indeed things might be simpler with GADTs and DataKinds here, maybe.  i hesitate to say so
02:42:25 <freeside> good luck solving the halting problem
02:42:44 <dkov> jle`: you are right, it is definitely a monoid an this solves the issue with the composition of functions like foo and bar
02:42:46 <freeside> okay, i will go read about DataKinds.
02:43:03 <jle`> freeside: you can do what i did earlier, and then have a GADT, data Quantity :: Measure -> Type where Pieces :: Int -> Quantity 'Count; Liters :: Double -> Quantity 'Pour; Kilos :: Double -> Quantity 'Weigh
02:43:14 <MichaelBurge> freeside: Are you talking about me? There are plenty of languages that allow them, like Coq and I think Idris
02:43:28 <jle`> freeside: and Category and Item would have phantom types of kind Measure
02:43:48 <freeside> okay, i will try this, thank you.
02:43:55 <jle`> data Item (m :: Measure) = Item (Category m) String
02:44:05 <jle`> data Category (m :: Measure) = Category String
02:44:45 <jle`> data Purchase = forall m. Purchase (Item m) (Category m) (Quantity m)
02:44:50 <dkov> jle`: what do you mean with i dont produce results out of them? In the actual code i produce a complex result out of Foo
02:44:51 <kuribas> MichaelBurge: often it's just something simply like a variable refering to itself.
02:45:05 <druidofluhn> MichaelBurge: Idris can mark a function as total (will always return a value for any input) but it can't do it for all functions
02:45:08 <jle`> dkov: i mean, you don't use any results except resulting Foo's
02:45:16 <jle`> dkov: your functions always just return Foos
02:45:23 <jle`> sorry, my terminology was not very clear
02:45:41 <druidofluhn> MichaelBurge: could it be something like `let x = f x` as kuribas mentioned?
02:45:47 <jle`> freeside: the only GADT you'd need is Quantity there
02:46:20 <dkov> jle`: in the actual code there are a lot of functions like f :: Foo -> .. -> Bar
02:46:39 <jle`> freeside: datakinds is a pretty simple extension; for something like data Bool = False | True, normally you get the type Bool and the values False and True.  but with DataKinds on, you also get (for free) a *kind* Bool and a *type* True, and a *type* False
02:46:54 <jle`> dkov: but how would that even be composed with foo and bar
02:47:11 <jle`> those functions do exist, but they aren't really a part of this transformation system you're talking about
02:48:16 <MichaelBurge> kuribas, druidofluhn: It's equivalent to a while loop that rewrites patterns in a syntax tree until it stops changing.
02:49:04 <kuribas> MichaelBurge: so trace each rewrite step?
02:49:18 <kuribas> MichaelBurge: with Debug.Trace.trace?
02:49:37 <druidofluhn> MichaelBurge: So the problem you're having is that you need to prove that the syntax tree will eventually stop being re-written?
02:49:55 <druidofluhn> MichaelBurge: or if you're just debugging, then Debug.Trace is your friend
02:50:59 <MichaelBurge> druidofluhn: Yes, that's it. A little complexity because there's e.g. a State monad with a "dirty bit" for performance reasons, and other practicalities.
02:51:47 <freeside> https://books.google.com.sg/books?id=NgRchoF9p3oC&pg=PA29&lpg=PA29&dq=decidable+converge+fixpoint&source=bl&ots=A-gXkMBph8&sig=SlXMILA8GXtsC4TDcWGeSo4mE9A&hl=en&sa=X&ved=0ahUKEwj31uji887VAhXMr48KHQ9fD9YQ6AEIJjAA#v=onepage&q&f=false
02:51:54 <kuribas> MichaelBurge: it's better to do correctness first, and then dirty performance tricks.
02:52:00 <freeside> looks like a decidability problem
02:52:08 <druidofluhn> MichaelBurge: this looks like you're trying to prove that your recursion has a base case then.
02:52:09 <freeside> does this propagation converge to a fixed point?
02:52:25 <kuribas> MichaelBurge: or otherwise factor out the dirty bits, so you can disable them for debugging.
02:52:27 <druidofluhn> I think that's what he's trying to prove, freeside 
02:53:16 <freeside> http://www.di.ens.fr/~cousot/COUSOTpapers/publications.www/CousotCousot-POPL-77-ACM-p238--252-1977.pdf
02:53:33 <freeside> good luck, i'm going back to my phanton mangoes
02:54:18 <druidofluhn> Episode I: The Phantom Mango
02:55:22 <druidofluhn> Followed by Episode II: Attack of the Scones
02:56:50 <dkov> jle`: thanks, I think i go with Monoid :)
02:57:03 <freeside> meanwhile MichaelBurge is wondering whether the series will ever end
02:57:13 <jle`> dkov: no problem!
02:57:17 <jle`> you might be interested in https://ocharles.org.uk/blog/posts/2013-02-12-quick-dsls-with-endo-writers.html as well
02:57:24 <jle`> it lets you use monoids with do notation
02:57:39 <jle`> in particular, your Endo Foo monoid
03:00:41 <dkov> jle`: oh well. that's exactly what my intention is
03:02:23 <freeside> nice
03:02:28 <jle`> :D
03:13:33 <freeside> in `data Category (m :: Measure) = Category String`, what extension do i need to enable to get the (m :: Measure) part to work?
03:14:44 <hexagoxel> freeside: KindSignatures
03:16:06 <freeside> thanks
03:22:47 <freeside> it still troubles me that plain haskell doesn't have a good way for me to talk about heineken, beer, and liters without having to add GADTs, DataKinds, and KindSignatures
03:23:49 <freeside> Haskell seems to suffer more than most languages the problem of "to be able to write this program you first need to create an extension to the compiler and for extra credit write an academic paper about it" lol
03:24:01 <freeside> maybe that's why there are so many compiler extensions
03:24:09 <Iceland_jack> freeside: I showed you one way yesterday without any compiler extensions
03:24:20 <freeside> i couldn't figure out your way. it didn't work for me.
03:24:35 <ubsan_> freeside: this is an issue I find a lot with language learners
03:24:50 <ubsan_> "I don't understand how to do it in language X, therefore, there is something wrong with language X"
03:25:16 <ubsan_> (when, in reality, usually you just don't understand that part of language X yet)
03:25:36 <freeside> heh, guilty as charged
03:25:45 <freeside> the question is whether all the extensions are part of the language or not
03:25:54 <ubsan_> they are part of a language
03:26:03 <freeside> the frustration comes from having worked through haskellbook.com which does not talk about them
03:26:04 <ubsan_> perhaps not the language described by the haskell report
03:26:10 * ubsan_ shrugs
03:26:20 <ubsan_> I feel like extensions were  a mistake, personally
03:26:39 <ubsan_> however, they're a part of the haskell landscape whether you like it or not, I guess
03:26:49 <freeside> well, i'm trying.
03:26:52 <ubsan_> they do seem pretty shitty tho
03:26:54 <michi7x7> any ideas for [(a,[b])] -> http://en.wikipedia.org/wiki/Special:Search?go=Go&search=(a,b) ... so [(a1,[b1,b2]),(a2,[b3,b4])] -> [ [(a1,b1),(a2,b3)], [(a1,b1),(a2,b4)], [(a1,b2),(a2,b3)], [(a1,b2),(a2,b4)] ] ? Sort of like a cartesian product on all http://en.wikipedia.org/wiki/Special:Search?go=Go&search=b
03:27:06 <michi7x7> *on all [ [b] ]
03:27:08 * ubsan_ just prefers to use languages which fit her mental model better
03:27:37 <ubsan_> I'm not actually sure why I'm in here, every time I attempt to use haskell I give up almost immediately and switch to idris or rust or C++
03:27:52 <ubsan_> (depending on what features I need)
03:28:00 <ubsan_> (that I'm missing in haskell)
03:29:28 * ubsan_ shrugs
03:29:32 <ubsan_> you should check out idris
03:29:45 <freeside> i should check out idris
03:29:53 <ubsan_> it's got cool stuff like strict semantics by default, and dependent types, and a sane type operator
03:29:58 <ubsan_> `::` arrrrgh
03:32:02 <freeside> i wonder how my problem could be solved in Idris.
03:32:15 <ubsan_> probably about how you'd expect
04:13:05 <freeside> still working on my mangoes. maybe i want TypeFamilies.
04:19:42 <guillaum1> which data structure are you using for persistent "vector like" with lot of modification ? An HashMap is roughly 12x times slower than a IOVector, a Sequence is 30x slower. I implemented something crappy https://gist.github.com/guibou/73c33d9e511385f4c52b313cb3d4d0e6#file-persistentarray-hs which is only 5 times slower than pure IOVector (but comes with no thread safe behavior and weirds performance if 
04:19:49 <guillaum1> old values are used). What is the "usual" solution ?
04:21:32 <freeside> https://hackage.haskell.org/package/bitwise ?
04:21:50 <freeside> i don't know if that's the usual solution though
04:27:02 <ezyang> quchen: There is comprehensive documentation on the signature format at https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/separate_compilation.html#module-signatures but a lot of Backpack lives in Cabal, which cannot really be discussed in the GHC manual. Unfortunately the Cabal manual entry is not written yet 
04:35:08 * hackagebot selda 0.1.10.1 – Type-safe, high-level EDSL for interacting with relational databases. – https://hackage.haskell.org/package/selda
04:53:24 <kuribas> What are you using for web programming?
04:57:11 <Athas> kuribas: Hakyll.
04:57:19 <Athas> (Probably not what you want.)
04:57:36 <kuribas> Athas: that's a static generator right?
04:57:54 <Athas> Yes.
04:58:22 <kuribas> hm, blaze seems popular, but it doesn't validate the html.
04:59:04 <bvad> kuribas: what are you looking for? "web programming" is a pretty broad term
04:59:46 <kuribas> bvad: I'd like to know which web frameworks are popular
05:00:08 <bvad> kuribas: If you're looking for frameworks, I think Yesod is a good bet 
05:00:15 <kuribas> right
05:00:48 <bvad> If you're looking for something lighter, I think Spock might be it 
05:01:48 <bvad> Also it's completely feasible to "roll your own" by combining smaller libraries, e.g. Servant with Blaze or whatever 
05:12:29 <Xandaros> Yesod is your classic "web framework" with server-rendered html and routing and everything. Servant is really neat if you just want an API. I personally like the approach of servant API on the server side and a purescript halogen frontend. The downside is that it won't work without JS enabled.
05:13:04 <Xandaros> servant+blaze is an interesting idea, though. I might play around with that at some point
05:15:00 <Xandaros> On an unrelated note: I need to work with monochrome (1-bit depth) images. Are there any pre-existing libraries for this? If not, suggestions on how I could represent such an image?
05:18:22 <bvad> Xandaros: https://hackage.haskell.org/package/base-4.10.0.0/docs/Data-Bits.html ? 
05:18:31 <Xandaros> xD
05:18:43 <bvad> Depends on what you want to do with the images ;) 
05:19:17 <Xandaros> Well, for now, rendering text and converting the format. For the latter, Data.Bits will certainly come in handy
05:19:41 <Xandaros> Eventually, I'd also like to render other things. Something similar to gloss would be ideal
05:21:28 <Xandaros> I can write the combinators myself if it comes to it, but I'm unsure about the best way to represent the image in memory. [[Bool]] is what comes to mind, but... ugh
05:22:16 <Xandaros> (To give some context: My end goal is to be able to control my G510 screen and print information on it)
05:25:51 <bvad> Xandaros: Depending on your performance needs, https://hackage.haskell.org/package/array-0.5.2.0/docs/Data-Array-ST.html#t:STUArray might be it 
05:28:06 <Xandaros> I guess I'll use that for now. Thanks :)
05:33:55 <orion> Could someone please help me understand this?: https://github.com/jwbuurlage/category-theory-programmers/blob/master/doc/02_categories.md#special-objects-arrows-and-functors
05:34:08 <orion> \begin{definition} An arrow $f: a \to b \in \mathcal{C}$ is a \textbf{monomorphism} (or simply mono), if for all objects $x$ and all arrows $g, h: x \to a$ and $g \neq h$ we have: $$f \circ g \neq f \circ h.$$ \end{definition}
05:34:54 <orion> In definition 1.6, they describe an epimorphism, but THAT definition looks just like the definition for monomorphism on wikipedia: https://en.wikipedia.org/wiki/Monomorphism
05:36:07 <kuribas> orion: LaTeX source isn't easy to read
05:37:48 <orion> https://github.com/jwbuurlage/category-theory-programmers/raw/master/doc/categories_for_programmers.pdf
05:38:03 <orion> Pages 13 and 14
05:38:35 <cocreature> they define an epimorphism by g.f=h.f → g=h. wikipedia defines a monomorphism by f.g=f.h → g=h
05:38:42 <cocreature> the difference is the side on which you can cancel
05:40:11 <orion> So you're saying that the monomorphism definition in the PDF is correct?
05:40:40 <cocreature> wait now you’re asking about the definition of monomorphism you just said “in definition 1.6 they describe an epimorphism”
05:41:45 <cocreature> they’re defining a monomorphism as g≠h→f.g≠f.h which is equivalent to f.g=f.h→g=h which is the definition wikipedia uses as well
05:41:46 <orion> I was confused about the definition of monomorphism, so I looked it up on wikipedia and saw that it was different.
05:42:15 <orion> Then I saw that the wikipedia definition was similar to the definition of epimorphism on the pdf and was more confused.
05:42:43 <orion> hmm
05:42:57 <orion> "g≠h→f.g≠f.h which is equivalent to f.g=f.h→g=h" <-- I have to digest that.
05:43:11 <jcjf> I always remember mono as the category theory version of "one to one"
05:43:23 <cocreature> "P->Q" is always equivalent to "not Q → not P"
05:43:28 <cocreature> at least in classical logic :)
05:44:47 <jcjf> That makes it easier to figure out which way the cancellation works
05:45:04 <jcjf> Your mileage may vary...
05:45:17 <ggVGc> how many miles per hour does haskell go
05:45:28 <cocreature> ggVGc: over 9000
05:45:36 <jcjf> Ok, your kilometrage may vary...
05:45:40 <ggVGc> cocreature: yes, but lazily
05:45:44 <ggVGc> so you don't get anywhere
05:46:03 <ggVGc> but there's a promise of being able to get anywhere
05:46:08 <jcjf> What's the dual of a creature?
05:48:12 <cocreature> jcjf: just turn all the arrows around
05:48:46 <jcjf> Hmm... mind blown
05:53:00 <ertes-w> alo
05:56:03 <foldr> Parsing config is a simple problem: you only need one GADT and one type family!
05:56:43 <bvad> foldr: Care to elaborate? Sounds interesting 
05:59:35 * hackagebot ngx-export 0.6.0.0 – Helper module for Nginx haskell module – https://hackage.haskell.org/package/ngx-export
05:59:35 <foldr> Basically doing this: https://medium.com/@jonathangfischoff/the-partial-options-monoid-pattern-31914a71fc67 but with a type family to remove the Last wrappers based on a type-level Bool
05:59:35 <bvad> foldr: thanks
05:59:35 <foldr> And then using free applicative with a GADT to turn that into both Optparse-applicative Parser (for CLI options) and into IO (for environment variables)
05:59:38 <foldr> The GADT is similar to: data Option a where Option :: Text -> Option (Last a)
06:00:13 <foldr> Maybe I'll blog about it
06:00:19 <bvad> You should
06:00:23 <bvad> I'd read it 
06:01:00 <foldr> type Options = FreeAp Option
06:01:06 <foldr> makeParser :: Options a -> Optparse.Parser a
06:04:08 <bvad> foldr: Free Applicative is actually quite interested 
06:04:11 <bvad> interesting even
06:04:24 <foldr> http://lpaste.net/1193124103599423488
06:09:23 <dminuoso> Beginner to Haskell here. If Maybe is an (endo)functor, what's the source/target category? Hask?
06:10:11 <phadej> yes
06:10:50 <foldr> Maybe takes an object `a' to an object `Maybe a'
06:10:52 <michi7x7> is there shiftR for Word64 ?
06:11:04 <foldr> And it takes a morphism `f : a -> b' to a morphism `fmap f : Maybe a -> Maybe b'
06:11:19 <foldr> And it preserves the structure (functor laws)
06:11:22 <foldr> therefore it's a functor
06:11:24 <cocreature> michi7x7: yes, shiftR :)
06:11:40 <cocreature> michi7x7: shiftR is a method of the typeclass Bits and there is an instance for Word64
06:11:56 <foldr> `f' and `fmap f' are both in Hask, so it's an endofunctor on Hask
06:12:06 <michi7x7> cocreature: yeah, had the arguments swapped :/
06:12:20 <foldr> alternatively it's a functor from Hask to a subcategory of Hask in which everything is lifted to Maybes
06:12:24 <dminuoso> foldr: Give me a minute to process that. :-)
06:13:25 * hackagebot fmt 0.4.0.0 – A new formatting library – https://hackage.haskell.org/package/fmt
06:14:06 <foldr> dminuoso: http://lpaste.net/7369380044109512704 horizontal arrows is functor
06:15:26 <foldr> Recall that a functor maps both objects and morphisms. Objects are types and morphisms are functions in Hask.
06:21:47 <dminuoso> foldr: Just to be clear, by morphism you are talking about something such as `odd :: Int -> Bool` right?
06:22:10 <foldr> dminuoso: Yes, a morphism is a function.
06:22:54 <foldr> And fmap takes a function and returns a new function in the "other category" (which in this case is also just Hask)
06:23:15 <foldr> fmap :: (a -> b) -> (Maybe a -> Maybe b)
06:30:51 <dminuoso> foldr: Wow, That just instantly clicked why this is a functor.
06:31:36 <mniip> there's actually a different more CT-friendly definition of a Functor
06:32:20 <dminuoso> foldr: Especially the reminder that functors map both objects and morphisms together with that last line were more concise and simpler than any 67th "monads explained with burritos on a racetrack" guide with stupid pictures.
06:32:47 <mniip> e.g this https://github.com/ekmett/hask/blob/master/src/Hask/Category.hs#L88-L91
06:33:06 <mniip> or mine https://github.com/mniip/Hask/blob/master/CT/Functor.hs#L13-L14
06:40:41 <jcjf> If you're learning Haskell, I'm not sure how well dense code like that helps you learn what a functor is.
06:41:25 <jcjf> I believe I know what a functor is, but the Haskell code makes me unpack more stuff to get to the conceptual content
06:41:54 <c_wraith> haskell is less abstract than category theory. :)
06:42:06 <dminuoso> jcjf: In pure category theory an endofunctor is fairly trivial. :)
06:42:25 <foldr> Is there a nicer way to write: maybe (AccSuccess Nothing) (fmap Just . f) <$> someIOAction?
06:42:36 <foldr> I have a feeling there's some nice combinator to do the Nothing/Just lifting
06:43:14 <dminuoso> jcjf: but yeah, its not helpful
06:43:50 <jcjf> I found functor categories very hard to get a feeling for, but they're so important for learning other stuff
06:44:08 <dminuoso> functor categories?
06:44:30 <jcjf> The category of functors between two categories
06:44:45 <foldr> ah, yes :) it's called traverse
06:45:41 <jcjf> Objects are functors, morphisms are natural transformations
06:46:18 <dminuoso> jcjf: Wait where did objects come from?
06:47:30 <jcjf> If I have two categories C and D, then I can consider the category of functors between them, by defining the objects of that category to be functors from C to D, and morphisms to be natural transformations between pairs of (compatible) objects
06:48:21 <jcjf> dminuoso: Like I said, if you're not used to it, it's overwhelming
06:48:24 <dminuoso> Ah no that makes sense.
06:49:49 <dminuoso> jcjf: Luckily I dived into elliptic curve mathematics a while back, so even the term `monoid` didn't even make me flinch. :)
06:50:43 <infandum> What's everyone's opinion on foundation? Is it worth switching to? Is backpack an alternative?
06:51:45 <dminuoso> jcjf: It was quite amusing that the condensed description `semigroup with an identity element` was all I needed to instantly understand what they meant. :-P
06:51:56 <c_wraith> infandum: for libraries, a custom prelude is almost never worth it.  For applications, if it's big enough that a start to feel pain, I just add a Prelude.hs to the project.
06:52:09 <dminuoso> Especially since I dont have an academic background, it was comforting.
06:53:27 <infandum> c_wraith: So it sounds like it's never worth it...
06:54:39 <freeside> OK, i'm giving up. i think that what i'm trying to do is a classic OO structure and shoehorning it into Haskell just doesn't make sense. thanks everybody for trying to help.
06:54:52 <c_wraith> infandum: it's worth it as an exploration, and maybe if you play with it you'll discover you like it enough to use it for your own projects.  That's a perfectly fine decision to make.
07:03:48 <infandum> c_wraith: I think it's an ambitious idea and perhaps worth exploring, but I'm a bit hesitant to do much in it because of all the work put into vector, bytestring, text, etc. that is cast aside
07:04:02 <infandum> The development team is smaller, basically
07:06:08 <c_wraith> that's the issue that all ambitious base replacements (or partial replacements) have
07:11:33 <cocreature> foundation looked too much like a kitchen sink lib for my taste
07:13:00 <infandum> cocreature: What's wrong with that? It seemed pretty fast to build.
07:14:10 <cocreature> infandum: I prefer smaller libs that I can easily swap out if something else comes along or if the author stops working on it
07:14:56 <cocreature> like why does foundation need a parser combinator lib, why does it need a module for uuids, …
07:15:37 <cocreature> I could get behind replacing bytestring, text and vector by a unified API. I’m not willing to throw everything overboard
07:16:24 <shapr> cocreature: clearly you need to make your own prelude replacement, the one true standard... what's that xkcd comic?
07:16:38 <cocreature> shapr: nah I’m happy with protolude
07:16:43 <shapr> heh, ok
07:16:47 <cocreature> it’s basically just reexports from base and text
07:16:58 <shapr> ah this is the one: https://xkcd.com/927/
07:17:09 <shapr> I'm really happy there's a profusion of prelude replacements
07:17:15 <mnoonan> I just wish more of the elementary tools for working with base types / classes were in Prelude. like "for" or "mapMaybe", for example.
07:17:18 <cocreature> so people won’t get too angry at me if I use it even in libs because the types are still all the same
07:17:29 <shapr> to me that signals the prelude changes were successful, well-received, and users are looking for more/other changes.
07:17:37 <cocreature> mnoonan: "for" is in base :)
07:17:40 <shapr> :t for
07:17:41 <lambdabot> (Applicative f, Traversable t) => t a -> (a -> f b) -> f (t b)
07:17:49 <cocreature> mnoonan: mapMaybe is too
07:17:53 <cocreature> oh you said prelude
07:17:55 <cocreature> nvm
07:17:57 <mnoonan> right :)
07:18:47 <mnoonan> actually, I think I'd be happy jamming as much of base into Prelude as possible before you start hitting name collisions
07:19:22 <mnoonan> but that might just be laziness
07:20:22 <cocreature> that’s pretty much protolude :)
07:20:31 <cocreature> well it’s a bit more but that’s most of it
07:20:50 <cocreature> the other big part is that it reexports Text which saves me one import in almost all modules
07:32:25 <quchen> How do I view the generated Core with Stack?
07:32:58 <quchen> stack build --options-ghc "-ddump-simpl -ddump-to-file" doesn’t seem to do what I want (no files generated)
07:33:16 <quchen> Aaah, nevermind.
07:33:30 <quchen> .stack-work is hidden and I didn’t include hidden folders in my search.
08:00:34 * hackagebot miso 0.7.0.0 – A tasty Haskell front-end framework – https://hackage.haskell.org/package/miso
08:16:11 <Younder> Why are functional transform op's called categories?
08:19:26 <c_wraith> Younder: they're not
08:20:00 <c_wraith> Younder: a category is a very specific structure
08:20:59 <c_wraith> Younder: functions form a category, but you would only refer to them as a category if you care about the fact that they have composition and that there's an id function
08:21:58 <Younder> It just seems to me that in Aristotean terms, they are not really a category.
08:22:17 <c_wraith> Aristotle has little to do with category theory
08:22:30 <Younder> To me categories ARE the arrows
08:23:13 <c_wraith> You don't really get to redefine a term and then complain everyone else is using it incorrectly.
08:23:53 <Younder> No, not really. I just are a bit puzzled by the name.
08:25:30 <c_wraith> I guess you could blame Mac Lane, but that work was done about 75 years back...
08:28:15 <Younder> c_wraith, Yes, I love his book on Algebra. If I understand anything at all about the use of categories it is through that book.
08:28:46 <geekosaur> categories as generalizations of sets, which up to that point were essentially the foundation of mathematics
08:29:45 <mniip> they are?
08:29:58 <Younder> You could just as well choose to use sequences. They are quivalent and sequences relate more naturally to the arrays of computers. But whatever..
08:30:11 <mniip> I thought they're just a natural byproduct of a synthetic morphism
08:30:21 <geekosaur> I don't think anyone cared about devices that didn't exist at the time
08:30:49 <Younder> Well maybe we should now then..
08:30:56 <mniip> I don't see the equivalence between sequences and categories....
08:32:40 <Younder> mniip, sequences and sets..
08:32:51 <Younder> categories e
08:33:00 <Younder> best relate to classes
08:33:08 <mniip> huh?
08:33:37 <mniip> can you try again with less handwaving?
08:34:37 <Younder> well take the ZF-sets. A soulution to the Russel paradox. You might just as well define a class set to be different from a object set. pdx avoided
08:35:38 <mniip> you mean NBG sets/classes?
08:35:54 <mniip> also how do sequences factor into this
08:35:59 <Younder> sorry for this foundations of math crap. Just working on some stuff for a new language.
08:36:07 <mniip> I think everyone defines sequences as functions from a cardinal
08:36:19 <mniip> I'm yet to see a synthetical sequence theory
08:37:05 <Younder> Works just fine you don't need indexes on every var. Instad the ps. is the index
08:38:22 <Younder> as 5*x^2+2*x'3 can be written as pol. grp. [5,2,3]
08:38:23 <mniip> ???
08:39:30 <ertes-w> Younder: what are you even trying to do?  i.e. what's wrong with categories, and how are you improving on them?
08:39:43 <Younder> Still tensors present a challenge. It is hard to write them without a set-index notation
08:40:11 <shapr> Younder: sounds like you need a blog
08:40:54 <Younder> categories are fine. Except perhaps the name. It's set's that are wrong. Everything in a computer is a sequence.
08:41:14 <shapr> Younder: have you built a blog? hakyll is really easy to use
08:41:17 <ertes-w> Younder: sequences can be explained in terms of sets
08:41:25 <Younder> yes, enough of this
08:41:49 <ertes-w> Younder: and if you don't like sets, perhaps you want types, where you can have a more direct encoding of sequences
08:41:49 <Younder> ertes-w, or the other way around which was my point
08:41:54 <sm> shapr: ha.. I wouldn't go that far..
08:42:14 <shapr> sm: well, I built a hakyll blog in a few hours, I enjoyed it.
08:42:45 <Younder> using fibred categories to attach types to objects is actually inspired
08:42:49 <sm> I've used it for years, but never found it *easy*
08:43:14 <ertes-w> shapr: i agree with sm…  hakyll is far from easy
08:43:35 <Younder> I don't think any of us do. We all have these WTF am I doing moments..
08:44:08 <shapr> Younder: have you tried Hakyll?
08:44:20 <Younder> no
08:44:28 <ertes-w> in fact i have dropped hakyll in favour of a Makefile + pandoc
08:44:46 <Younder> I douse pandoc
08:44:58 <sm> ertes-w: not tempted to try Shake ?
08:45:05 <shapr> ertes-w: oh, is your build script online somewhere?
08:45:29 <ertes-w> sm: my use case is so simple that shake would have been unnecessary engineering effort
08:45:36 <sm> make is really hard to beat sometimes
08:45:59 <shapr> Younder: are you on github?
08:46:07 <ertes-w> shapr: https://github.com/esoeylemez/esoeylemez.github.io/blob/master/Makefile
08:46:13 <ertes-w> not very sophisticated
08:46:47 <Younder> shapr: yes
08:47:04 <the_2nd> Is there a method to enumerate a sum type? e.g. MyType = Zero | One | Two ... such that f Zero == 0 etc
08:47:18 <ertes-w> the_2nd: see the Enum class
08:47:27 <ertes-w> the_2nd: it's derivable for simple enumeration types
08:47:29 <jcjf> Is it effective to take a given imperative algorithm, implement it with the ST monad, then try to FP'ify it later?
08:47:46 <jcjf> Particularly for someone like myself more familiar with imperative programming
08:47:54 <sm> it's relatively easy to make a minimal blog. Harder to make a modern wordpress-level blog, with robust feeds, tagging, next/prev links, and all that..
08:48:32 <the_2nd> ertes-w, thanks
08:48:36 <shapr> Younder: I think if you included references and links in a blog post about this stuff, I'd certainly have a better understanding
08:48:58 <ertes-w> jcjf: if you're under time pressure, sure, but if you're learning, perhaps just try to do the FP approach directly
08:49:44 <ertes-w> jcjf: also there are many haskell features you can't use (easily), if you restrict yourself to ST, like laziness
08:49:45 <jcjf> ertes-w: Makes sense. I assume this refactoring process wouldn't gain the usual "if it typechecks, then it must be correct"?
08:50:04 <masaeedu[m]> Is it off-topic to talk about other type systems?
08:50:07 <ertes-w> jcjf: it's usually easier to get the functional version right
08:50:14 <masaeedu[m]> Perhaps there's a dedicated channel
08:50:19 <ertes-w> jcjf: so if anything you're more likely to convert to a safer variant =)
08:51:19 * hackagebot hspec-multicheck 0.1 – A testing framework for Haskell using Hspec – https://hackage.haskell.org/package/hspec-multicheck
08:51:19 * hackagebot random-bytestring 0.1.1 – Efficient generation of random bytestrings – https://hackage.haskell.org/package/random-bytestring
08:51:31 <Younder> shapr, I'll get around to it.
08:51:51 <jcjf> If I need a heap queue with many millions of operations being performed on it, am I likely after an ephemeral data structure?
08:52:01 <shapr> Younder: please send me a link when you do, I get lost when you describe stuff :-(
08:52:01 <ehubinette> New SoH blog post on usability issues with linear Haskell: https://m0ar.github.io/safe-streaming/2017/08/11/usability-implications-of-linearity.html
08:52:15 <jcjf> I suppose I really mean the conceptual equivalent
08:53:24 <masaeedu[m]> What does "linearly typed" mean?
08:57:53 <epta> masaeedu[m]: https://ghc.haskell.org/trac/ghc/wiki/LinearTypes
09:05:35 <dminuoso> Is there a reason that class-wise a Monad is not an Applicative?
09:05:49 <mniip> yes
09:05:56 <mniip> you're using an outdated compiler
09:06:09 <dminuoso> Oh. :-)
09:07:09 <dminuoso> mniip, well outdated guides rather. None of the guides Im seeing talks about Applicative => Monad
09:07:13 <Younder> So basically no
09:07:17 <geekosaur> as of ghc 7.10 Monad requires Applicative. before that, ghc stuck to the standard, which defined Monad without either Functor or Applicative, the latter because it didn't exist at the time Monad was formalized
09:07:43 <geekosaur> this specifically includes Haskell '98 standard which is what most books and guides reference
09:07:50 <geekosaur> this specifically includes Haskell '98 standard which is what most books and guides reference
09:07:54 <Younder> ugh
09:08:14 <Younder> Anyhow GHC is the standard now
09:08:15 <geekosaur> (H2010 is a very small incremental revision)
09:08:45 <dminuoso> Younder, you mean the de-facto standard? I was led to believe that the Haskell 2010 report was the official definition
09:09:40 <geekosaur> Younder is of the school of thought that mplementations are the only standards that matter. Which is a great way to prevent new implementations
09:10:56 <geekosaur> (quite a few prospective new Haskell compilers have foundered on the shoals of "but ghc does X extension and we need it")
09:11:09 <mniip> the problem with standardizing haskell is that the tremendously complicated nonstandard type system extensions are used everywhere in haskell
09:11:14 <Younder> geekosaur, In some ways. There are probably 2 people who understand the GHC type parser.
09:11:55 <Younder> All the same Jones has been god at listening to his users
09:12:00 <mniip> either you standardize them and then any standard-fitting implementation becomes about as large as GHC, or you don't and the standard doesn't reflect the language
09:12:56 <Younder> god = good, jesus..
09:14:03 <ongy> not being TH compatible would probably be a huge issue. And I doubt TH compatiblity is easy
09:14:33 <Younder> TH?
09:15:58 <cocreature> mniip: that’s why I’m not sure what the purpose of haskell 2020 is tbh
09:16:15 <cocreature> it seems like a lost cause
09:16:16 <ongy> TemplateHaskell
09:17:18 <Younder> I like Lisp macro's. Obviously so did the creator of TH
09:17:38 <mniip> cocreature, like, the haskell98 typechecker can be implemented fairly shortly with a simple HM or something
09:17:57 <mniip> but if you want to support type families...
09:18:05 <mniip> fundeps... rankntypes?
09:18:39 <cocreature> I mean I would welcome a formal definition of the semantics implemented by GHC that is continuously updated as GHC changes
09:18:51 <Younder> The type system seems an obsticle to macro type constructions working at your advantage. Hence the lukewarm acceptance
09:19:07 <cocreature> but I got the impression that haskell2020 is going to be somewhere in the middle between haskell2010 and ghc haskell and that just seems useless for everybody
09:19:09 <Younder> just my 2 bits
09:23:43 <ventonegro> Younder: Unless the type checking is done at expansion time, it seems http://homedirs.ccs.neu.edu/stchang/pubs/ckg-popl2017.pdf
09:24:54 <Younder> interesting
09:28:40 <the_2nd> It seems like my O2 flag has no impact. Am I doing something wrong? cabal run and -O2 in ghc-options within the .cabal
09:29:27 <cocreature> the_2nd: cabal (or rather ghc) doesn’t rebuild if you just change the optimization level. I think that changed in 8.2 but before that you need to manually clear the old files or use -fforce-recomp.
09:36:40 <the_2nd> :/ no / little impact
09:37:17 <the_2nd> I have a Data.Map with my enum type and cache results there. Position -> MyEnum
09:37:34 <the_2nd> then read 400 values and write them to a .png
09:37:42 <cocreature> the_2nd: it should at least have an impact on compile time. if it doesn’t even have that you’re probably doing something wrong ;)
09:37:51 <the_2nd> end up with 100-150ms per run
09:38:12 <the_2nd> and feel like that's way too slow. But I'm out of ideas for optimization
09:38:39 <the_2nd> my next try would be writing it in Rust :D
09:38:46 <cocreature> you’ll have to show us some code if you’d like us to help
09:39:37 <the_2nd> I'll soon leave, but will do next time I work on it
09:40:21 <the_2nd> I fear I'll only be able to use Haskell where performance isn't super critical
09:40:47 <dolio> Cabal uses -O by default, and -O2 often doesn't give any benefit over -O.
09:42:02 <cocreature> in most cases you can make Haskell code perform quite well and if that doesn’t help there’s always the C ffi
09:42:30 <Younder> For what it's worth 02 does loop unrolling and constant propagation which can be detremental to performance. These days optimizing for size often gives the best reult. It lies in understanding that the l1 cache is only 64 bits so the loop has to fit in there
09:43:10 <Cale> Younder: In GHC?
09:43:37 <Cale> I'm pretty sure you're talking about GCC or something :)
09:44:05 <cocreature> given that ghc basically never unrolls loops, that seems likely :)
09:44:37 <Younder> Cale, in gcc
09:46:31 <nshepperd_> 64... bits? lol
09:46:45 <nshepperd_> 64 kb is normal
09:47:46 <cocreature> nshepperd_: fitting your inner loop in 64bits is quite a challenge!
09:47:47 <ongy> probably confused a cache line, and that's still 64kByte iirc
09:47:52 <ongy> erm, without the k
09:48:47 <nshepperd_> loop: jmp loop
09:48:58 <nshepperd_> Efficiently doing nothing :)
09:49:14 <ongy> heating the room
10:05:19 <SirJls> A very good evening to all!
10:05:42 <sm> well met SirJls!
10:07:33 <ertes-w> Younder: 64 *bytes* is the size of one L1 cache line…  the overall cache is usually much larger
10:07:55 <ertes-w> Younder: 64 bits cache would be pretty useless =)
10:08:02 <ertes-w> because it would be invalidated constantly
10:08:45 <ongy> 64bits cache? just add another register
10:11:13 <orion> Could someone provide a concrete example of an arrow f : a -> b and g, h : b -> x where g . f = f . g => g /= h?
10:12:21 <ertes-w> orion: in the (ℤ, +) monoid 3 + 5 = 5 + 3, but 3 ≠ 5
10:12:44 <ertes-w> however, the general proposition "g . f = f . g → f ≠ g" is not true
10:12:59 <ertes-w> 4 + 4 = 4 + 4, but 4 = 4
10:13:50 <ertes-w> orion: obviously such an example inplies that f and g are endomorphisms, which is why i chose a monoid as a simple example
10:13:57 <ertes-w> *implies
10:14:14 <orion> hmm, I think I screwed up my question.
10:14:54 <orion> f : a -> b and g, h : b -> x where g . f = h . f => g /= h
10:15:07 <orion> That's what I meant to write.
10:15:27 <ertes-w> orion: add quantifiers
10:15:37 <ertes-w> "i'm looking for … such that for all …"
10:16:35 <orion> ertes-w: I'm trying to digest the definition for epimorphisms. As such, I'm looking for a concrete example of what is an epimorphism and what is not so that I can compare them side by side.
10:17:08 <dolio> orion: Do you actually want the implication there, or the negation of the epimorphism condition?
10:17:33 <ertes-w> orion: you're looking for a non-epi morphism?
10:18:45 <dolio> If g = h, then g . f = h . f, so you should not be able to satisfy that implication.
10:19:03 <orion> I read the definition as, "If setting g . f equal to h . f implies that g = h, then we have an epimorphism." I want to know a concrete example of: "setting g . f equal to h . f implies that g /= h"
10:19:19 <orion> What would f, g, and h have to be for the implication to be that g and h are concretely not equal?
10:19:31 <ertes-w> orion: that's not the inversion of the epimorphism constraint
10:19:54 <orion> What is it?
10:20:17 <ertes-w> you're looking for an f such that there exist g and h, where g . f = h . f and g ≠ h
10:21:06 <ertes-w> the inversion of "for all x, P x" is "there exists x, such that not (P x)"
10:21:44 <dolio> And an example is: f = const True, g = not, h = const False.
10:22:13 <dolio> not . const True = const False . const True, but not /= const False.
10:23:24 <orion> dolio: That's exactly what I was looking for, thank you.
10:24:52 <ertes-w> "i'm looking for a number that is prime" = "i'm looking for x > 1, such that for all d, d > 1 and d < x → mod x d ≠ 0"
10:25:43 <ertes-w> "i'm looking for a number that is not prime" = "i'm looking for x > 1, such that there exists d, such that d > 1 and d < x and not (mod x d ≠ 0)"
10:26:14 <ertes-w> or more directly:
10:26:35 <ertes-w> "i'm looking for a number that is not prime" = "i'm looking for x > 1, such that there exists d, such that not (d > 1 and d < x → mod x d ≠ 0)"
10:26:40 <orion> ertes-w: My question was poorly phrased because I don't yet have an intuitive understanding of mathematical logic.
10:27:01 <ertes-w> orion: using a proof assistant helped me a lot with that
10:27:12 <ertes-w> i didn't have any logic background prior to that
10:27:23 <orion> Like Coq?
10:27:27 <ertes-w> yeah
10:28:36 <Rembane> Is running `stack install` superslow for you too?
10:28:58 <Rembane> I have 12Kb/s speed right now.
10:29:38 <ertes-w> it's super fast for me
10:29:41 <ertes-w> zsh: command not found: stack
10:29:42 <ertes-w>   real 0.002  user 0.000  krnl 0.002  cpu% 77%  mem 3m  stack install
10:29:43 <ertes-w> SCNR =)
10:30:00 <Rembane> :D
10:30:26 <Rembane> ertes-w: BTW, what OS/dist are you running?
10:30:57 <ertes-w> Rembane: GNU/linux, NixOS
10:31:40 <Rembane> ertes-w: Nice! Then I see why you have a nice experience without stack. :D
10:32:16 <ertes-w> well, you don't need NixOS to use nix…  i'm using nix for deployment on non-NixOS systems
10:32:41 <johnw> same here
10:33:19 <ertes-w> also honestly i don't think the cabal-install experience is as bad as people make it seem
10:33:28 <Rembane> ertes-w: But you need nix if you have nixOS?
10:33:40 <ertes-w> Rembane: what do you mean?
10:33:42 <ongy> cabal-install is fine
10:33:43 <sm> Rembane: stack or cabal install will be slow (especially) at 12k/s any time they have to download/build a bunch of dependencies/tools
10:33:59 <sm> but should be a lot quicker the second time
10:34:16 <Rembane> ertes-w: I mean that running nixOS means running nix as a package manager?
10:34:45 <Rembane> sm: Indeed. But it hasn't been this slow until yesterday.
10:34:46 <ertes-w> Rembane: you could probably run something else (but why would you?)
10:34:53 <Rembane> ertes-w: Indeed.
10:34:59 <ertes-w> one downside of cabal-install is that you need to compile everything yourself, but AFAIK stack has that, too
10:35:06 <Rembane> ertes-w: I was just toying around with implication arrows. :)
10:35:13 <Rembane> stack has that too
10:35:16 <ertes-w> hehe
10:35:35 <ongy> ask a gentoo person if that's a downside ;)
10:35:57 <Rembane> We could have a real party asking people stuff. :D
10:36:12 <ertes-w> ongy: i friend of mine is in the process of moving from gentoo to NixOS, after i convinced her that nix is basically portage done right =)
10:36:17 <Franciman> How can I specify, on OS X, that an haskell executable works at least with let's say OS X 10.9, because otherwise it assumes that the min version is 10.12 if I do SetFile -t APPL executable
10:36:30 <cocreature> ongy: you don’t even need a gentoo person for that. nix is pretty good at forcing mass rebuilds if you try to stay up2date
10:37:50 <ertes-w> cocreature: if you want to stay in sync with master, then yes, but most users should just use one of the channels, and then it doesn't happen
10:38:04 <ertes-w> by the time the channel is updated, hydra will already have built everything and run all tests
10:39:01 <cocreature> ertes-w: you’re making it seem better than it really is. the tests don’t cover that much of the haskell setup. e.g. ghcjs is completely broken atm in nixpkgs-unstable, various ghc 7.10 packages also just don’t built with their default config, …
10:40:14 <ertes-w> cocreature: in that case the proper response is to fix it =)
10:40:43 <cocreature> ertes-w: there is a reason I have 3 or 4 open prs on nixpkgs :)
10:40:47 <ertes-w> not much can be done about the 7.10 thing though, unless you want to establish something like LTS
10:41:26 <cocreature> it’s not the packages fault that they’re broken with 7.10. the problem is that hackage2nix doesn’t detect dependencies correctly
10:41:37 <cocreature> e.g. a lot of packages have a conditional dependency on semigroups
10:41:42 <cocreature> for ghc <= 7.10
10:41:43 <ertes-w> ah
10:42:14 <cocreature> there is some configuration-7.10.nix file where you can add such dependencies
10:43:17 <ertes-w> not sure how to fix that though…  probably by making hackage2nix smarter
10:43:55 <cocreature> yeah hackage2nix should generate different configurations for different compilers automatically imho
10:44:23 <cocreature> packages that compile with both ghcjs and ghc also tend to have conditional dependencies and hackage2nix doesn’t get this right
10:45:42 <mpickering> Do you know if peti has considered this cocreature ?
10:45:57 <ertes-w> i wonder if hackage2nix could just use cabal-install's algorithm
10:46:19 <mpickering> I've found it a little painful but quite manual work to get going
10:46:26 <cocreature> mpickering: no idea
10:46:37 <mpickering> but once you have a project set up, much easier to tweak things
10:46:43 <mpickering> I'm mainly using it with custom HEAD builds
10:47:16 <ertes-w> interestingly i've never hit this issue, even though i do test builds with 7.10
10:47:29 <cocreature> I was planning to use it with ghcjs and a week after I started using it, ghc 8.2, cabal-install 2.0 and lts 9.0 made it into nixpkgs-unstable and now everything is broken
10:47:58 <ertes-w> but since we're at 8.2 now i'm about to drop 7.10 support anyway
10:48:05 <ertes-w> 8.0 and 8.2 is good enough
10:53:19 <mpickering> cocreature: Was the problem the boot compiler
10:55:15 <srpx> Is there a standard name for the 2d, N-argument zipWith? I.e., `zipWith (+) 0 [[1, 2, 3, 4], [10, 10, 10, 10], [100, 100, 100, 100]] == [111, 112, 113, 114]`.
10:55:57 <cocreature> mpickering: the bootPkgs not the bootcompiler. first haddock was too new, then that got downgraded in nixpkgs but now it’s trying to use cabal-install-2.0 which apparently doesn’t support some solver that ghcjs-boot tries to use
10:56:26 <cocreature> mpickering: I have gotten it working and made PRs for everything but I have to admit it was a bit frustrating :)
10:58:08 <ertes-w> :t \f x0 -> foldr (zipWith f) (repeat x0)
10:58:10 <lambdabot> Foldable t => (a -> b -> b) -> b -> t [a] -> [b]
10:58:34 <ertes-w> srpx: ^ does that sound appropriate as a name?
10:59:13 <srpx> Foldable? Not really, why? Foldable is for 1d structures that can be folded like lists
10:59:20 <srpx> as far as I understand
10:59:40 <srpx> this is something different, it allows for example implementing transpose as `zipWith2d cons nil table`
10:59:46 <johnw> srpx: maybe not even like lists sometimes, since there's no requirement that you visit every member, or that what you generate is even in the original structure!
11:01:04 <ertes-w> > foldr (zipWith (:)) (repeat []) [[1..3], [4..6] [7..9]]
11:01:06 <lambdabot>  error:
11:01:06 <lambdabot>      • Couldn't match expected type ‘[Integer] -> [a]’
11:01:07 <lambdabot>                    with actual type ‘[Integer]’
11:01:07 <srpx> johnw: ouch why?
11:01:15 <johnw> srpx: because it's lawless
11:01:28 <johnw> people have tried giving it laws, there's past discussion on -cafe about it
11:01:45 <srpx> "because it's lawless" - rad
11:01:48 <srpx> but I see
11:02:14 <johnw> there's just a sort of gentleman's agreement that it does something like what you'd expect, without formally saying what that is
11:03:30 <ertes-w> > foldr (zipWith (:)) (repeat []) [[1..3], [4..6], [7..9]]
11:03:33 <lambdabot>  [[1,4,7],[2,5,8],[3,6,9]]
11:04:27 <Tuplanolla> That's nice.
11:04:31 <ertes-w> > foldr (zipWith (+)) (repeat 0) [[1..4], repeat 10, repeat 100]
11:04:33 <lambdabot>  [111,112,113,114]
11:05:33 <ertes-w> > foldl' (\xs dxs -> let ys = zipWith (+) xs dxs in ys `deepseq` ys) (repeat 0) [[1..4], repeat 10, repeat 100]
11:05:35 <lambdabot>  error:
11:05:35 <lambdabot>      Variable not in scope: deepseq :: [c] -> [c] -> [c]
11:05:43 <ertes-w> @let import Control.DeepSeq
11:05:45 <lambdabot>  Defined.
11:05:46 <ertes-w> > foldl' (\xs dxs -> let ys = zipWith (+) xs dxs in ys `deepseq` ys) (repeat 0) [[1..4], repeat 10, repeat 100]
11:05:49 <lambdabot>  [111,112,113,114]
11:06:20 <ertes-w> note: it's not 'transpose'
11:06:42 <ertes-w> > foldr (zipWith (+)) (repeat 0) [[1,2,3], [4,5], [6]]
11:06:44 <lambdabot>  [11]
11:06:49 <ertes-w> > transpose [[1,2,3], [4,5], [6]]
11:06:52 <lambdabot>  [[1,4,6],[2,5],[3]]
11:06:56 <ertes-w> err
11:07:04 <ertes-w> > foldr (zipWith (:)) (repeat []) [[1,2,3], [4,5], [6]]
11:07:07 <lambdabot>  [[1,4,6]]
11:07:42 <ertes-w> zipWith is intersection-like, where 'transpose' is union-like
11:09:25 <Tuplanolla> It's a shame this duality isn't leveraged more.
11:09:52 <Tuplanolla> Even the name `transpose` isn't that good.
11:10:42 <Tuplanolla> > uncurry (==) ((id &&& transpose . transpose) [[1, 2], [3, 4, 5], [6]])
11:10:45 <lambdabot>  False
11:11:37 <ertes-w> the 'linear' library makes that distinction in its Additive class
11:11:38 <ertes-w> https://hackage.haskell.org/package/linear-1.20.7/docs/Linear-Vector.html
11:11:48 <ertes-w> liftI for intersection-like, liftU for union-like
11:12:07 <ertes-w> *liftI2, *liftU2
11:13:02 <ertes-w> in fact it's easy to see from the types why my version couldn't even express the union-like behaviour of 'transpose'
11:13:25 <ertes-w> :t \f x0 -> foldr (zipWith f) (repeat x0)
11:13:28 <lambdabot> Foldable t => (a -> b -> b) -> b -> t [a] -> [b]
11:13:47 <ertes-w> union-like would force a = b
11:14:45 <ertes-w> err
11:14:48 <ertes-w> [a] = b
11:14:49 <mpickering> cocreature: I am confused by that PR, does ghc7103 not come bundled with Cabal-1.24? 
11:15:55 <cocreature> mpickering: the problem is cabal-install not Cabal. and cabal-install-2.0 even builds fine with Cabal-2.0 using ghc7103. it just isn’t supported by ghcjs-boot
11:16:07 <mpickering> OK
11:16:22 <Tuplanolla> On an unrelated note: which package should I use if I want some number theoretic utilities like fast factorizations?
11:17:25 <cocreature> mpickering: fwiw I might also be completely missunderstanding something but it seems to work with those prs™ :)
11:17:58 <ertes-w> Tuplanolla: arithmoi
11:19:25 <Tuplanolla> Looks good, thanks.
11:19:45 <mpickering> I don't think line 98 in your PR looks right. I thought boot libraries were usually set to null in the attribute set
11:20:32 <mpickering> If you patch ghcjs to use "modular" rather than "topdown" does the build work?
11:20:36 <mpickering> That would be a simpler fix
11:21:57 <Tuplanolla> Whoop, time to get swapped out again.
11:22:06 <cocreature> mpickering: without line 98 it tries to build cabal-install-1.24 against Cabal-2.0 which obviously files.
11:22:29 <cocreature> mpickering: good point, I was planning to try that but then got lost in the discussions in https://github.com/haskell/cabal/issues/3987 and forgot about that. I’ll have to give it another shot.
11:22:39 <cocreature> if only building ghcjs wasn’t so freaking slow …
11:24:10 <shapr> whoa
11:24:35 <Rembane> Matrix doesn't always crash, but when it does, it is the best crash in the world.
11:28:38 <tsahyt> is there such a thing as an indexed monad transformer? indexed in the sense of the indexed package.
11:28:40 <mpickering> cocreature: I can try on my server if you like
11:29:05 <cocreature> mpickering: no need, I’ll figure it out at some point :)
11:30:05 * hackagebot microlens 0.4.8.1 – A tiny lens library with no dependencies. If you're writing an app, you probably… – https://hackage.haskell.org/package/microlens
11:30:32 <tsahyt> the indexed package only has a TODO item that seems to be from 2008
11:42:24 <johnw> shapr: have you tried hpack?
11:55:13 <gremdrus> I'm using intero, and C-. is not going to the source. How do I fix that?
11:55:26 <JohannaHulten> Hi, I'm studing for an exam on Haskell, and looking at an old exam I have a question I can't find a solution to myself, anyone up for helping me? Rewrite the following function in point-free form, using neither lambda-expressions nor list comprehensions nor enumeration nor where clause nor let clause: g x y = [ y z | z <- [1..x]]
11:56:47 <Tuplanolla> That's a fun one, JohannaHulten. Do you know what `MonadComprehensions` does?
11:56:53 <ertes-w> JohannaHulten: start by replacing [ y z | z <- [1..x] ] into something that isn't a list comprehension
11:57:34 <ertes-w> s/replacing/rewriting/
12:00:14 <JohannaHulten> ertes-w: Yeah, I would, except I can't think of a way of doing it without needing to change the type or using where 
12:00:30 <ertes-w> JohannaHulten: hint: this list comprehension is basically just mapping the function 'y' over the list [1..x]
12:00:48 <adelbertc> how do i specify package flags in a cabal build file? e.g. i want to set the `fast` flag in aeson: https://hackage.haskell.org/package/aeson
12:02:22 <JohannaHulten> ertes-w: so map f [1..x] would be the same? And I guess that would actually be allowed per the question defenition. I was so stuck on needing to get rid of [1..x]
12:02:53 <ertes-w> JohannaHulten: that's correct…  now [1..x] is also syntactic sugar…  do you know what its raw form is?
12:03:57 <JohannaHulten> ertes-w: not that I can think of, mind you I have been studing for a few hours so might get a bit slow
12:04:14 <ertes-w> JohannaHulten: [1..x] = enumFromTo 1 x
12:04:44 <JohannaHulten> ertes-w: Oh, don't think I have seen that before
12:05:07 <ertes-w> JohannaHulten: but wait…  do you need to get rid of both function arguments?
12:05:30 <ertes-w> or just the 'y'?
12:06:18 <JohannaHulten> ertes-w: I need to get rid of both, but that could be flip map . (enumFromTo 1 ) ? 
12:06:31 <albeit> I am trying to parse a lazy text with Attoparsec.Text.Lazy, but when I have a line like "quotes <- sepBy1 parseQuote parseNewLine", the quotes list isn't being generated lazily (I have to wait till the entire file is parsed to get the first quote). Why is that?
12:07:11 <ertes-w> JohannaHulten: correct =)
12:07:26 <JohannaHulten> ertes-w: Thank you so so much, learned a few new things
12:08:08 <ertes-w> JohannaHulten: in general when doing equational reasoning, especially for rewriting, first get rid of syntactic sugar
12:08:35 <ertes-w> haskell is full of syntactic sugar
12:09:11 <JohannaHulten> ertes-w: Yeah, thanks. I've been doing a fair few of those questions, that was about the first that triped me upp, mostly because I didn't know how to get rid of [1..x]
12:09:33 <Tuplanolla> The version the compiler produces before optimizations involves `>>=`, JohannaHulten and ertes-w.
12:10:07 <ertes-w> Tuplanolla: xs >>= pure . f = map f xs
12:10:23 <Tuplanolla> Indeed.
12:13:15 <cheater> hello
12:13:21 <wickedshamansaid> hello
12:13:23 <wickedshamansaid> >
12:13:24 <cheater> is there a way to write haskell so that it runs on the erlang vm?
12:13:54 <wickedshamansaid> I actually don't know Haskell, I was trying to use a feature that I found online that explains Haskell. 
12:14:11 <wickedshamansaid> There is one particular use of IRC channels that is insanely useful, that I'd like to share.
12:14:11 <wickedshamansaid> On various programming language channels, there are ad-hoc expression evaluation bots that experienced people use to guide newcomers through the intricacies of the language. If you're new to Haskell, for example, what you can do is grab the logs for the past 3 years, grep for "> " (used to invoke the evaluator) and you have instant insight into how an experienced Haskeller's mind works. It can speed up your learning by a 
12:14:11 <wickedshamansaid> factor of 10 compared to reading papers / blogs / formal tutorials. I know because it did this for me.
12:14:17 <wickedshamansaid> https://news.ycombinator.com/item?id=7161236
12:14:36 <cheater> you can open a query with lambdabot and go wild
12:14:50 <cheater> that'll give you that functionality too
12:15:00 <wickedshamansaid> Thanks, I'll check it out
12:15:27 <Tuplanolla> For example `/msg lambdabot > 42 + 13`, wickedshamansaid.
12:17:11 <shapr> Anyone using leancheck for property testing?
12:17:48 <shapr> wickedshamansaid: yes, that pattern has gained popularity
12:21:58 <wickedshamansaid> Does anyone know of an excellent comprehensive Bash lexer in Haskell?
12:23:15 <Tuplanolla> For what purpose?
12:24:48 <wickedshamansaid> I'm looking for a solid Bash lexer to help fix Scintilla, it is using some precarious code now that has many errors with regards to here-docs. 
12:25:35 <Tuplanolla> Separate lexing is less common in Haskell land.
12:26:03 <Tuplanolla> Try Hackage's search anyway.
12:28:05 <wickedshamansaid> I saw a few of them, I'm not sure how thorough they are - I was hoping someone knows of one that is standout. 
12:29:28 <Tuplanolla> Chances are the most popular choice is complete and correct.
12:29:43 <wickedshamansaid> I see for instance, this one: https://hackage.haskell.org/package/highlighter2-0.2.5/docs/src/Text-Highlighter-Lexers-Bash.html#lexer 
12:30:05 <wickedshamansaid> Yet there is no apparent handling of here-doc's, Bash can be kind of complex. 
12:30:38 <Tuplanolla> @hackage language-bash
12:30:38 <lambdabot> http://hackage.haskell.org/package/language-bash
12:34:31 <wickedshamansaid> Thanks Tuplanolla, looks like it may be complete - I'll try it out. 
12:47:57 <orzo> ( (x:x), (x:xs) `seq` recurse) -- Can I rely on subexpression eliminiation to force the first component of the pair when the second is accessed?
12:51:25 <ertes-w> orzo: not like that
12:51:40 <ertes-w> orzo: let xs' = x:xs in (xs', xs' `seq` y)
12:52:01 <ertes-w> orzo: but that particular seq looks pointless to me
12:52:34 <orzo> why pointless?
12:52:51 <ertes-w> orzo: you're forcing (:)
12:53:08 <orzo> i meant to write (x:xs), which you seem to have guessed, but i see (x:x) in my scroll, heh
12:53:09 <ertes-w> but at that point it's already known that it's a (:)
12:55:13 <orzo> well the actual code was more like (x:xs, q) where (xs,q) was returned from recursion  The function is building a list and a value, and i dont want a pointless thunk stack
12:55:47 <ertes-w> orzo: the answer to your question is: if it has a name, it's shared
12:55:58 <ertes-w> that's why i gave your list a name (xs')
12:55:59 <orzo> ok
12:56:38 <ertes-w> if it already has a name (from e.g. from a pattern variable), you don't need to make a new one
13:01:07 <orzo> if i have pointless 'seq' in my code, in that the thing will always already be in whnf, will ghc make me pay a penalty for putting it there?
13:01:57 <ongy> 1$ for each useless seq
13:02:21 <orzo> i mean, it could blindly output code for checking the the evaluation status or something
13:02:27 <orzo> that'd be the sort of cost i'm talking about
13:04:29 <orzo> for example, if x > 5 then seq x 22 else 45, will ghc actually write code for that 'seq' ?
13:07:01 <Henson> does anybody here use Haskell in a business or industrial setting?  I'm thinking of porting a project (around 14k lines of code) from Python to Haskell and want to discuss why it might or might not be a good idea, to make sure I'm not going to shoot myself in the foot.
13:07:24 <Tuplanolla> If you're unsure, don't do it, Henson.
13:08:33 <Henson> Tuplanolla: Python is driving me crazy because it's low performance, terrible concurrency, and isn't type safe.  C++ would be an alternative, but makes me shudder when I think of programming in it and all of the errors that can be made compared to Haskell.
13:08:49 <Tuplanolla> The fact that it's Python and a meager 14 k doesn't change anything.
13:09:07 <srpx> So, we have this popular guy on the Brazilian programming community which had "Haskell" on its name
13:09:32 <srpx> He was very smart but never built anything particularly popular or successful
13:10:06 <srpx> A few weeks ago, we made a petition asking him to change his name from "Haskell" to "Java", which got enough likes so he did
13:10:07 <osfameron> Henson: in a business/industrial context, the *most important* question is whether your team is willing to maintain it or pay for the consultants to do it
13:10:36 <orzo> His actual name, or some forum handle?
13:10:39 <srpx> A few days after that, he released an app which is now a national success and news are talking about him
13:10:44 <srpx> Facebook name
13:11:14 <srpx> Sometimes I feel like the universe is just trying to tell us something lol
13:11:20 <orzo> you think his success was partly due to the name change?
13:11:36 <ozgura> with stack, is there a way to specify the destination path for binaries?
13:11:43 <srpx> No, but it was a funny coincidence, he never did anything popular for all the years he carried haskell on its name
13:11:50 <srpx> change his name to java, boom success
13:11:51 <orzo> maybe google or somebody punishes "haskell" over "java" as a search term or something
13:12:22 <MarcelineVQ> ozgura: did you ask stack?  stack --help
13:12:54 <ozgura> oh I had tried stack install --help
13:13:22 <srpx> also the fact the community went all the way to make a petition asking him to remove haskell from his name...
13:13:51 <Tuplanolla> The universe is saying you should stay away from Facebook communities and stop caring about other people's proprietary software, srpx. A subset of the universe that coincides with my location, anyway.
13:14:42 <Henson> osfameron: and I suppose developing and maintaining a Haskell program is much more expensive than a C++ one?  Even when you consider Haskell might make it easier to refactor and reduce stupid bugs?
13:14:44 <ongy> there's at least 2 people in this universe :)
13:14:53 <MarcelineVQ> ozgura: Oh weird that it doesn't tell you about the option there :(   it's  --local-bin-path
13:14:55 <srpx> Tuplanolla: what do you mean? I just found this history funny and decided to share it.
13:14:56 <ozgura> MarcelineVQ: thanks! though I am surprised stack install --help didn't mention --local-bin-path
13:15:05 <MarcelineVQ> ozgura: I agree
13:15:09 <Tuplanolla> Don't take me too seriously, srpx.
13:15:16 <ab9rf> Henson: porting an app from anything to haskell is usually not a great idea. rewriting it from spec, that mght be an idea, but porting.... not so much
13:15:20 <osfameron> Henson: you may be right, but it depends on your team, and whether your boss is willing to let you spend the time to make the experiment
13:15:45 <srpx> Tuplanolla: hello btw, you know who I am but I don't know who you are :) 
13:16:07 <osfameron> Henson: but it sounds like it's in Python rather than C++, why not keep it in Python?
13:16:16 <Henson> ab9rf: yeah, it wouldn't be a straight port, as the architecture would need to change a bit to do it in a haskell-way
13:16:26 <osfameron> and maybe rewrite some sections to take advantage of the more functional features
13:16:31 <ab9rf> Henson: does the python app work?
13:16:53 <Tuplanolla> I don't really know you, but I do know that you ask lots of plt questions I then stumble upon, srpx.
13:16:59 <orzo> i've experience porting, i do it in two phases, first i do a very ugly port using the continuation monad so i can translate code without neccessarily fully groking it, then i go over that thinking how i could write it better without the continuation monad
13:17:15 <ertes-w> Henson: the main question is: do *you* need to maintain it?
13:17:21 <orzo> i've had a lot of success with that approach
13:17:33 <Henson> ab9rf: yes it works, but it's not as performant as we want, and I absoutely hate the lack of typing
13:18:05 <ab9rf> Henson: i understand wanting it to be more performant
13:18:28 <orzo> isn't there a python compiler?
13:18:34 <ab9rf> orzo: meh
13:18:37 <orzo> maybe just compiling it would be enough
13:18:41 <Henson> osfameron: I started it in Python a few years ago because I thought Python was awesome.  Now that I've written the software in it, and need high performance and concurrency, I have come to realize that I hate Python and I shouldn't have used it in the first place.
13:18:59 <johnw> Henson: experience is wonderful
13:19:11 <Henson> orzo: python compilers are pieces of crap
13:19:24 <osfameron> Henson: I'm not trying to discourage you from writing Haskell ;-)  but you did ask about business/industrial context
13:19:35 <osfameron> but it really depends on how much freedom you have within that context
13:19:49 <Tuplanolla> You could repeat the same reasoning for transitioning from Haskell to GLSL, Henson.
13:19:50 <jared-w> There's also typed projects in Python to inject types into the language through comments or other such methods. Those might be worth looking at
13:19:55 <osfameron> if it's your decision, and you're confident in your ability to rewrite it before your boss shouts at you for wasting time, then go for it
13:20:12 <Henson> so the question is, what do I port it to?  I know C++ and realize it would be easy to find programmers for it.  But I also know that a LOT can do wrong with C++.  I've been coding in Haskell for several years now and really love it and functional programming, and am curious about giving it a try for the rewrite.
13:20:13 <ab9rf> Tuplanolla: heh
13:20:24 <orzo> i think javascript and scheme have typed variants
13:20:41 <albeit> If I'm folding over a list to generate a DList like "foldl' step mempty quotes; step quotes quote = quotes <> DList.singleton quotes", why isn't the DList generated lazily?
13:21:27 <orzo> Henson: what's holding you back?
13:21:38 <ertes-w> albeit: left folds of lists are *never* lazy
13:22:27 <albeit> @ertes-w: So should I just be using explicit recursion? (Left to right order of the list matters, so can't use foldr)
13:22:27 <lambdabot> Unknown command, try @list
13:22:45 <albeit> ertes-w: So should I just be using explicit recursion? (Left to right order of the list matters, so can't use foldr)
13:22:45 <ertes-w> albeit: your conclusion is wrong
13:22:50 <orzo> albeit: you expect foldl' to be lazy?
13:22:58 <jared-w> Henson: why do you want to port it?
13:23:10 <ertes-w> albeit: the "l" and "r" and foldl/foldr have nothing to do with the direction
13:23:22 <ertes-w> albeit: lists are *always* folded from left to right
13:23:26 <srpx> Tuplanolla: you said you're Brazilian, right?
13:23:39 <Tuplanolla> Not even slightly, srpx.
13:23:52 <srpx> Hmm I misunderstood you then
13:24:52 * hackagebot smartcheck 0.2.4 – A smarter QuickCheck. – https://hackage.haskell.org/package/smartcheck
13:25:31 <cheater> hi
13:25:43 <cheater> has something changed in ghci so that you don't have to type "let" any more?
13:25:50 <cheater> i am using 8.2.1
13:25:52 <Tuplanolla> Yes, cheater.
13:26:03 <cheater> when has this changed?
13:26:08 <cheater> and... why?
13:26:20 <Tuplanolla> In 8-series.
13:26:32 <albeit> ertes-w: I think I should have said the actual step is non-associative
13:26:46 <cheater> ok cool thanks
13:27:15 <albeit> ertes-w: Would it then be better to just use explicit recursion?
13:27:17 <ertes-w> albeit: let me put it this way: you can express foldl' in terms of foldr
13:29:23 <Henson> jared-w: to get away from Python, to gain type safety, functional programming style, performance, and concurrency.
13:30:19 <osfameron> Henson: do you *need* those things for this project?
13:30:26 <osfameron> is it a cost-effective use of your time?
13:30:43 <orzo> Henson, i don't know if portability is a concern, but haskell is a little harder to run on various devices and systems
13:31:29 <Henson> orzo: the thing holding me back is not knowing if it's a good idea.  The question for me really boils down to: do people not use Haskell in an industrial setting because it's not commonly used in industrial settings (a catch-22), or because it's very difficult and expensive to find people able to program in Haskell (perhaps I'm over-estimating the difficulty of Haskell compared to other languages)
13:31:42 <Henson> orzo: or because C++ and more common industrial choices like Java are actually better.
13:31:55 <erisco> Henson, the answer is: yes
13:32:28 <geekosaur> the nuanced answer is any or all of the above plus possibly other considerations, depending on project and environment
13:32:40 <Henson> orzo: I don't want to choose a language because it's "industry best practice".  I want to choose a language that's going to get the job done, will make the programmers happy and actually want to program in it, will get the job done well, and will result in a program that's fast and a code base that's elegant and easy to maintain and update.
13:32:48 <sqooq> Can I not constrain a variable in an ADT?
13:33:08 <Tuplanolla> Sounds like you've already made up your mind, Henson.
13:33:14 <erisco> sqooq, paste your code and your error
13:33:39 <sqooq> erisco: it's your advice about record syntax lmao
13:33:52 <sqooq> except I decided to make parts more general
13:33:56 <sqooq> rather than forcing them to be doubles
13:33:58 <orzo> henriksod: just do it. Haskell.
13:34:02 <orzo> fuck
13:34:17 <orzo> that was intended for Henson
13:34:18 <sqooq> data Note = Note { pch :: Num a => a,  oct :: Num a => a, dur :: Num a => a }
13:34:19 <erisco> there are many languages which are perfectly viable to be industry standards, they just aren't
13:34:22 <henriksod> Lol
13:34:29 <Tuplanolla> If you just want our approval, we can pony it up in a moment, Henson.
13:34:40 <henriksod> Well I do it :)
13:35:11 <ertes-w> sqooq: you can constrain individual constructors through a language extension, but i'm sure the correct answer in this case is to constrain your functions instead
13:35:13 <orzo> he's in a haskell room asking whether to port to haskell, he's not hear for a nuancd unbiased answer
13:35:13 <Henson> osfameron: I definitely need performance and concurrency, type safety is not necessary (but in my opinion highly desirable).
13:35:26 <orzo> he's here for enthusiastic cheerleading
13:35:33 <orzo> i say we give it
13:36:07 <sqooq> ertes-w, so just do `pch :: a` ?
13:36:18 <erisco> Henson, language choice is not a significant factor in whether your product succeeds or fails
13:36:19 <osfameron> orzo: heh, yeah, I did wonder whether to just say that
13:36:26 <Henson> Tuplanolla: haha, I've made up my mind for myself, but realize that what I think is a good idea might be actually be a good idea when you consider other things, which is why I'm coming to all of you for a sounding board.
13:36:29 <ystael> Henson: I lead a backend team at a small startup that has been using Haskell for about half a year. Only one of us (not me) was a professional Haskell dev prior. Our experience, boiled down to one tidbit, is that we have paid a larger up front investment in learning and design for most things than we would otherwise have, and what we get in exchange is zero fear of changes.
13:36:33 <ertes-w> sqooq: yes
13:36:44 <osfameron> Henson: but you never replied to "what does your boss/team think?"
13:37:04 <sqooq> ertes-w, k 
13:37:07 <ertes-w> sqooq: that also gives you a nice benefit
13:37:11 * Henson appreciates orzo's enthusiastic cheerleading
13:37:36 <ertes-w> sqooq: data Note a = Note { … }  deriving (Eq, Foldable, Functor, Ord, Show, Traversable)
13:37:49 <erisco> I really do not think inserting Haskell into a team where no one else knows Haskell is a good idea
13:37:50 <ertes-w> sqooq: gives you a whole bunch of useful functions for free
13:38:10 <osfameron> erisco: rarr!
13:38:13 <orzo> if you port to haskell, the whole room will dedicate hours of their time helping you with any troubles
13:39:02 <sqooq> ertes-w true
13:39:16 <sqooq> erisco: wanna keep helping me think about my weird function
13:39:26 <sqooq> I'm still stumped
13:39:42 <erisco> I will help you once you can accurately describe to me what it is supposed to do
13:39:53 <sqooq> I tried my best
13:39:59 <sqooq> I gave you the slideshow lmao
13:40:09 <erisco> but as I remember it, I was suggesting that you revise your approach to instead think about how the data is used
13:40:25 <sqooq> yes
13:40:26 <erisco> by understanding how you want to use the data you will more clearly see how to efficiently and conveniently represent it
13:40:43 <sqooq> thinking about it that way makes me want to add an extra field for Branch that contains length information
13:40:52 <sqooq> then I can just fmap length across the tree
13:40:57 <erisco> just looking at these annotated leaves by themselves it seems like a bad idea because it is expensive to change the tree
13:41:23 <erisco> to the extent it would probably be better to just recompute these factors as you need them rather than storing them
13:41:34 <erisco> but that depends on how often you need the factors ... that is why you need to consider how you use the data first
13:42:13 <Henson> osfameron: I am my own boss, so I get to make the decision.  I guess there are essentially three ways to go.  Keep it as is in Python and have a brittle, slow, and finnicky piece of software.  Write it in C++, which would be the proper industrial choice.  Write it in Haskell with certain parts in C/C++.  I am inclined to the Haskell and C/C++ solution becuase writing the whole thing in C/C++...
13:42:20 <sqooq> what do you mean recompute these factos? erisco
13:42:21 <Henson> osfameron: would make me sad.
13:42:32 <Tuplanolla> > (How about that lambdabot?)
13:42:34 <lambdabot>  Just do it!
13:42:46 <Tuplanolla> It's decided.
13:42:48 <erisco> Henson, that is not a natural conclusion from writing something in Python
13:43:01 <jared-w> Henson: how many lines of code is it and how long did it take to write it in Python the first time around?
13:43:08 <erisco> Henson, if the team made something brittle, slow, and finicky in Python the problem is the team, not the language
13:43:09 <osfameron> Henson: right.  so in that case:  it sounds like you want to do it in Haskell, are your own boss, and I'm sure haskell will work fine.  It'll probably be OK if you think it's the best use of your time.
13:43:12 <orzo> 14k, he told us
13:43:16 <erisco> Henson, and changing the language will not fix the team
13:43:43 <osfameron> yeah, but the team is him, 14k lines on ;-)
13:43:44 <jared-w> 14k? pffh, that's fine to rewrite. Anything under 10k is an immediate "sure why not"; anything under 20k is possible. Beyond that, I'd almost never think about rewriting something
13:43:44 <sqooq> erisco: Literally once I get duration information, as long as it takes into account rests and blanks, then I literally would not need the tree structure anylonger
13:43:51 <erisco> Henson, if you already have competent people then you need to look at your software development cycle
13:44:08 <sqooq> right now my function is ugly as crap and probably innefficient, but it works excluding Blanks and Rests
13:44:21 <ab9rf> 14 kloc is a tiny project
13:44:33 <erisco> Henson, maybe there is a breakdown of communication (are you having daily stand up meetings?), or maybe there are excessive regressions (are bugs reported and organised, and is appropriate time dedicated to fixing them?)
13:44:34 <Henson> osfameron: your assessment of the team is correct :-)
13:44:43 <orzo> then its a no brainer
13:44:44 <Henson> osfameron: but there's actually another member of the team now.
13:44:46 <orzo> go for it
13:44:56 <erisco> okay, well, sorry to say, but even if the team is one person then changing the language is not going to fix the problem :P
13:45:03 <ab9rf> yup
13:45:04 <orzo> does they otehr guy know/like haskel?
13:45:11 <orzo> scratch know
13:45:17 <orzo> does he want to know it?
13:45:20 <osfameron> erisco: yeah, but it's *not* same person.  He's now 14k lines more experienced :D
13:45:20 <orzo> :D
13:45:45 <ab9rf> hah
13:46:07 <erisco> but learning Haskell does teach excellent practices, so it is worth learning
13:46:13 <osfameron> (I'm not being mocking there, that's valid experience.  And if the codebase is wrong now, there's lessons (hopefully) learnt from that ;-)
13:46:14 <orzo> you got 14k lines, you want to write it in haskell, the other guy is like "I always wanted to learn haskell", go for it
13:46:18 <erisco> it will improve how you think about and design programs
13:46:45 <sqooq> god I love haskell
13:46:55 <sqooq> like I never got into programming so much
13:47:01 <sqooq> until I saw haskell and what it was about
13:47:08 <sqooq> and it's aesthetic af
13:47:26 <cheater> Henson: my experience is many people don't use haskell because there seems to be a learning curve associated with it that is steeper than going from say java to python.
13:47:50 <albeit> How can I get this function to output the list as it is generated? http://lpaste.net/357615
13:47:54 <orzo> that's true, it is steeper than i expected going in
13:48:02 <orzo> don't tell your teammate that though
13:48:04 <erisco> Henson, another mistake is to not have a specification before you begin writing code
13:48:04 <Henson> erisco: yeah, the problem with the team (myself) was I was relatively inexperiences as a software dev, I didn't feel like writing a massive test suite to deal with an untyped language, and the software has been a gradual evolution.
13:48:27 <cheater> well you still need to write tests in haskell
13:48:28 <cheater> just less
13:48:37 <erisco> Henson, depending on what you are doing it can be formal or informal, and thorough or vague, but it needs to be thought through at the beginning what it is you are going to create
13:48:41 <Henson> osfameron: you're totally right.  I'm not the same software developer I was 2 years ago when I started working on this.
13:48:41 <cheater> because a lot of bugs you'd test for just stop existing
13:49:23 <erisco> Henson, there is a strong urge to just start writing code and to figure everything out as you go, but as projects become larger that is a less and less tractable approach ... you just can't keep the whole thing in your head at once
13:49:39 <orzo> i don't relate with young coders who are intemidated by a "learning curve".  By the time I was 20, i thought I could learn any programming language in a week and wouldn't listen to such sily talk about "learning curves"
13:49:52 <lambdaGrp> :q
13:49:55 <erisco> Henson, a specification gives you a bird's eye view, i.e. something you can keep in your head, and guides your specific implementation. It is also an essential communication tool between other team members
13:49:59 <Henson> osfameron: the thing about Haskell is that is pretty much forces you to program in a way where you can't make a lot of the errors that easily crop up in other languages.  It's both wonderful and frustrating to program in.
13:50:12 <osfameron> yup
13:50:32 <orzo> well, haskell encourages newbies to make space leaks even when they are very competent memory management coders in c++
13:50:42 <erisco> the cheapest and fastest code is the code you never write, so spend some time to think first :)
13:51:01 <Henson> cheater: exactly
13:52:01 * hackagebot ivory-backend-c 0.1.0.7 – Ivory C backend. – https://hackage.haskell.org/package/ivory-backend-c
13:52:01 * hackagebot ivory 0.1.0.7 – Safe embedded C programming. – https://hackage.haskell.org/package/ivory
13:52:28 <Henson> erisco: I appreciate the advice, and agree with everything you're saying.  One thing that really helps in the small Haskell projects I've worked on as I've been learning it, is up front planning really pays off.
13:52:44 <orzo> newbies should probably be told to think of let x = ... as "malloc" and it's not freed until it's evaulated.  I remember writing code and thinking, well this bit wont be evaulated so it doesn't incure a cost, and I've seen other newbies make the same mistake
13:53:25 <iqubic> What is malloc??
13:53:35 <orzo> newbies from C will know
13:53:39 <orzo> it allocates memory
13:53:44 <geekosaur> memory manglement the C way
13:53:55 <Henson> orzo: he knows a little bit of Haskell, and is interested.  My main difficulty in learning Haskell was not having a mentor or somebody to talk to (sorry I didn't visit this channel earlier on!).
13:53:55 <iqubic> Ah, I see.
13:53:59 <maerwald> man malloc
13:54:17 <iqubic> Is there a differnece between C and C++? Which is better?
13:54:18 <maerwald> the one advantage of C over haskell
13:54:34 <Tuplanolla> They're completely different these days, iqubic.
13:54:57 <cocreature> is there a diference? yes which is better? that’s a question that you’re not going to get a useful answer for
13:54:58 <maerwald> C is a designed language, C++ is an evolved language
13:55:21 <iqubic> Who still uses C these days?
13:55:35 <maerwald> people who care about safety
13:55:38 <orzo> haskell FFI speaks C, not C++
13:55:42 <Tuplanolla> Good answer, maerwald.
13:56:07 <Tuplanolla> @google jens gustedt modern c book
13:56:08 <geekosaur> C is still the most portable FFI target
13:56:09 <lambdabot> https://gustedt.wordpress.com/2016/11/25/modern-c-is-now-feature-complete/
13:56:13 <Tuplanolla> Start there, iqubic.
13:56:26 <geekosaur> so most non-C uses it for communication with other languages/nn-native libraries
13:56:34 <geekosaur> including C++ via extern "C"
13:56:54 <ab9rf> it's possible to write a C++ library that only exposes C bindings
13:57:07 <orzo> i had a job where i was required to use objective-c, i used gcc's objective-c++ so i could get the smart pointers from c++
13:57:10 <Henson> orzo: thinking functionally is a mental reorganization that any new employee would have to do, if they don't already have it.  An experienced software dev told me that the Haskell core language is actually easier to understand than C++, and that new employees wouldn't have to understand how Monads, Applicative, and all those higher level abstractions actually work under the hood in order to be...
13:57:16 <Henson> orzo: able to start programming in them.
13:57:18 <cheater> is there a way to write programs in haskell (maybe with an EDSL) that will run on the erlang vm?
13:57:26 <albeit> Is there any way to implement the explicitly recursive function step2" with folds?
13:57:36 <sqooq> erisco: any last thoughts before I go?
13:57:38 <albeit> Is there any way to implement the explicitly recursive function "step2" with folds? http://lpaste.net/357616
13:58:01 <albeit> The "step" attempt clearly doesn't work the same...
13:58:04 <sqooq> erisco: I fixed up my data types a lot, but I'm still going the reverse of your advice. 
13:58:15 <sqooq> I'm making the types before understanding what I want to do
13:59:52 <orzo> henson, probably, but one clever haskeller might give the others trouble if he's the sort who likes to play with abstractions
14:00:28 <lyxia> albeit: there is but it seems cumbersome
14:00:47 <orzo> i hate languages that try to protect programmers from smarter programmers
14:00:55 <orzo> go-lang comes to mind. :|
14:01:09 <albeit> lyxia: I realize it's a trivial example, but is this a case where using explicit recursion is preferred?
14:01:24 <lyxia> it is
14:02:05 <albeit> lyxia: Thank you! Havent yet grasped when to use folds
14:03:09 * hackagebot irc-conduit 0.2.2.3 – Streaming IRC message library using conduits. – https://hackage.haskell.org/package/irc-conduit
14:06:42 <lyxia> > foldr (<>) d [a,b,c]  -- the simplest use case, you have a list and a binary operator.
14:06:44 <lambdabot>  a <> b <> c <> d
14:06:51 <orzo> instead of inflicting go-lang/java on us, maybe industry should make some kind of style-guide so we can use our favorite langauge while accomodating abstraction-impaired team-mates
14:07:32 <lyxia> > foldr (+) d [a,b,c]  -- with the brackets pls lambdabot
14:07:34 <lambdabot>  a + (b + (c + d))
14:11:24 <sqooq> guess not
14:11:26 <sqooq> bye y'all
14:11:30 <sqooq> <3
14:12:01 <orzo> albeit: it's probably worth wrapping your head around this wiki page, https://wiki.haskell.org/Foldl_as_foldr
14:14:59 <jared-w> albeit: When to use folds vs explicit recursion is really a matter of performance. If you don't care, use whichever is natural to you (but try to use folds whenever possible; they're often cleaner when you get used to them)
14:15:55 <orzo> foldr is often more performant than recursion due to optimization
14:15:58 <jared-w> albeit: as far as performance wise: folds are technically slower than explicit recursion, however because of the optimizations GHC can do, it can treat folds as a "list consumer" and if the thing they are folding is a well behaved "list producer", ghc is able to optimize away the intermediate data structure
14:16:50 <jared-w> If that inlining and rewriting from GHC does not trigger, folding will be slower than explicit recursion. That's why packages such as Data.Text have tons of inline and rewrite pragmas all over the place; their performance /depends/ on being able to wrangle GHC's rewriting and optimizing to be reliable
14:18:33 <orzo> i've encountered situation where i had a smallish function and I just could not write it using recursion in a way that out-competed foldr based on my benchmarks.  
14:18:34 <jared-w> But most of that is annoying technical details that don't (and shouldn't) matter to the programmer when they're writing code
14:19:15 <jared-w> orzo: likely because foldr was eliminating the intermediate data structure?
14:19:22 <jared-w> (or rather, GHC was)
14:19:49 <orzo> shrug
14:20:20 <orzo> but benchmark experiencde tells me not to assume recursion will compete with the optimized foldr
14:21:05 <albeit> orzo jared-w: Much appreciated, thanks
14:22:05 * hackagebot hexml-lens 0.2.0 – Lenses for the hexml package – https://hackage.haskell.org/package/hexml-lens
14:25:06 <Henson> thank you, everyone, for your opinions and insights into my question.  I appreciate it.
14:26:24 <orzo> i hope i didn't talk you into go-lang, Henson. :P
14:30:25 <Henson> orzo: no worries :-)
14:31:25 * hackagebot irc-client 0.4.4.4 – An IRC client library. – https://hackage.haskell.org/package/irc-client
14:35:42 <Henson> orzo: I love what Stephen Diel said here http://dev.stephendiehl.com/hask/#go : " Go is a language designed around the idea that language design has not advanced since 1970, while Haskell incorporates many ideas from modern research."
14:37:15 <jared-w> 70s might be a bit generous for go :p
14:37:50 <ab9rf> i see go as just NIH combined with "I the inventor of this language am a genius and therefore everything i say is right"
14:38:30 <jared-w> I see go as the solution to "we need a language that fits our company culture"
14:38:43 <jared-w> "why should I make one good messaging app when I can copy and paste it 6 times?" --> go
14:38:59 <ab9rf> jared-w: yes, it's very reflective of google's internal corporate culture
14:39:00 <orzo> "Go does not have an effect system".  What does he mean by effect system?
14:39:13 <ab9rf> jared-w: which is not a positive thing to say, google's internal corporate culture is deranged.
14:39:29 <adelbertc> has anyone expierneced segfault 11 w/ aeson ?
14:39:36 <ystael> ab9rf: is there any sufficiently large tech company whose internal corporate culture is _not_ deranged?
14:39:57 <ab9rf> ystael: probably not
14:40:53 <orzo> what do you mean about google, ab9rf? (maybe should answer in #haskell-offtopic)
14:41:59 <ab9rf> orzo: basically, it does IO through impure functions.
14:42:11 <orzo> heh
14:42:16 <Henson> orzo: a way of encapsulating side effects like in an IO monad
14:42:22 <Maxdamantus> orzo: an effect system is where operations are expressed as values that can be composed together to make larger oerations.
14:42:22 <orzo> oh
14:42:24 <ab9rf> orzo: (that's an answer to your prior question, not your most recent one)
14:42:45 <orzo> lol, i thought you guys were making some kind of clever analagy about google's corporate culture and it was a head scratcher
14:43:22 <ab9rf> orzo: wisdom often comes in curiously refreshing flavors
14:43:47 <toppler> I refuse to attend impure functions.
14:43:53 <orzo> lol
14:44:30 <ab9rf> orzo: do colorless green ideas sleep furiously in your penthouse?
14:45:06 <lyxia> adelbertc: that doesn't sound like a known bug
14:47:20 <hololeap> i'm curious about the use of the tilde (~) in this line of code: toBuffer = proc ~(a, b) -> do
14:47:50 <orzo> lazy pattern match, it means the (a,b) might be unevelatuated bottom
14:47:52 <erisco> hololeap, it makes the pattern match non-strict
14:48:21 <erisco> also known as an irrefutable pattern
14:48:26 <hololeap> so, is arrow notation strict by default then? which part is strict and how would it behave differently if it was lazy?
14:48:39 <orzo> patterns normally cause evaluation, yes
14:48:42 <erisco> pattern matching is strict
14:48:50 <hololeap> oh...
14:49:11 <erisco> if it is lazy then you get to go into the body without first matching the argument :)
14:49:43 <erisco> > let f ~(_,_) = "hello world" in f undefined
14:49:46 <lambdabot>  "hello world"
14:51:22 <erisco> so a consequence is that it always matches
14:51:26 <erisco> hence, irrefutable
14:52:21 <erisco> > let f ~(a,b) = length [a,b] in f undefined -- maybe that is more interesting
14:52:23 <lambdabot>  2
14:53:01 <hololeap> ok, i get it
14:53:42 <rjg_> hi i was wondering how i should use the shake-language-c extension together with the shake build system. I have looked at the example and source code but I couldn't really understand it.
14:54:01 <erisco> though it isn't just so you can pass undefined to stuff... it can be that you need the laziness to break what is otherwise a non-productive evaluation
14:55:34 <EvanR> let f ~(_,_) = "hello world" in f undefined
14:55:43 <EvanR> not a type error ?
14:55:56 <EvanR> oh undefined is the arg
14:56:05 <EvanR> brain fried
14:56:18 <erisco> rice
15:02:50 <orzo> i used to use "undefined" temporarily while writing code, for type checks and the like
15:03:17 <orzo> i even made an alias called "todo" which my syntax hilight would recognize
15:03:37 <orzo> but i had to scrap it because it's not enough info in the crash messages
15:03:48 <orzo> switched to "error"
15:03:59 <orzo> but it's sort of tedius having to provide the argument
15:04:59 <erisco> holes are a better way to have TODOs ... undefined is nice for demonstrating laziness
15:05:11 <orzo> holes didn't exist at the time
15:05:19 <erisco> do they now?
15:05:32 <orzo> now i use 8.0.1
15:05:47 <erisco> did they add holes? I haven't noticed
15:05:52 <orzo> i don't know
15:05:58 <orzo> there's type holes
15:06:02 <orzo> that's different
15:06:12 <orzo> partial type signatures
15:06:17 <orzo> that's handy
15:06:40 <orzo> what would a partial expression look like?
15:06:58 <orzo> use _ as a speical symbol?  What's the error crash?
15:07:16 <orzo> maybe _ is like error/undefined but provides more info in the crash
15:07:48 <orzo> i don't like _, actually we should juts put todo in the prelude and have it do that
15:08:05 <orzo> then syntax hilight will have an easier time showing you the gaps
15:08:50 <orzo> whatdo you think of that?
15:09:26 <orzo> we can have a compile switch to forcea compile fail if todo is used, for release builds
15:09:55 <boj> orzo: sounds like you are ready to hack on ghc :)
15:10:41 <orzo> maybe the compile should succede with a warning taht todo was used and not even output an executable
15:10:53 <orzo> heh
15:11:36 <orzo> nah, we'd need to test linking
15:11:39 <koala_man> what if I want to write a calendar to handle my daily todos
15:12:01 <orzo> koala_man: i guess import Prelude hiding (todo) :P
15:12:25 <lyxia> use  _todo  and compile with -fdefer-typed-holes
15:13:16 <orzo> hm, i should update my syntax hilight to recognize _todo
15:13:53 <lyxia> right _ usually counts as part of a word
15:17:08 <orzo> erisco: seems we've had holes for a while
15:17:37 <orzo> 7.8.1 at least, according to the manual
15:17:59 <toppler> I rely on typed holes to a worrying degree. I worry they're making me stupid.
15:18:02 <orzo> i need to break the "error" habbit heh
15:18:24 <MarcelineVQ> you only need to worry about that if the compiler is stupid too
15:18:59 <toppler> Yeah, when I try programming Scala, I'm in trouble.
15:19:22 <toppler> Not that Scala's compiler is stupid. It's trying to solve harder problems.
15:21:24 <orzo> updated syntax-hilight :)
15:53:05 <mibaz_1> Is there a cool way to get 'const' with two ignored arguments? Just did \_ _ -> something
15:53:12 <hpc> :t const const
15:53:14 <lambdabot> b1 -> a -> b -> a
15:53:25 <hpc> eh, just do the lambda
15:53:48 * EvanR shakes the @pl 8-ball
15:54:00 <EvanR> @pl (\_ _ -> 'a')
15:54:00 <lambdabot> const (const 'a')
15:54:26 <EvanR> @pl (\_ _ x -> x)
15:54:26 <lambdabot> const (const id)
15:54:33 <mibaz_1> the 8 never lies
15:55:25 <exio4> const . const 
15:55:31 <exio4> :t const . const
15:55:33 <lambdabot> a -> b1 -> b -> a
15:55:54 <EvanR> @pl (\x _ _ -> x)
15:55:54 <lambdabot> const . const
16:01:27 <mibaz_1> much better than the lambda
16:01:31 <mibaz_1> beautiful.
16:06:45 * hackagebot keysafe 0.20170811 – back up a secret key securely to the cloud – https://hackage.haskell.org/package/keysafe
16:12:08 <mbw> Is the errors package compatible with MonadThrow from exceptions, or can I import both without name-clashes? I think I would like to use the error package, since I find myself doing 'case mx of Nothing -> error "urk!" / throwIO this / Left that' all the time, while other functions I work with return a MonadThrow m => m a. Do I have to awkwardly juggle both packages?
16:13:55 <mbw> And do people use MonadFail yet?
16:14:17 <hpc> soon
16:14:54 <erisco> MarcelineVQ, the talk conal gave on overloading lambda was great
16:18:06 <MarcelineVQ> glad you enjoyed, I'm probably gonna need a couple rewatches myself, I've also got this other problem where Barry Jay's talk is making me look at a different kind of calculus entirely  https://www.youtube.com/watch?v=4i4SNvlWnmM
16:19:02 <erisco> I am glad there is an explanation of derivatives in there because I haven't a clue what they are
16:19:31 <MarcelineVQ> yeah I got pretty much lost on the non-lamda-calculus stuff onwards
16:19:35 <erisco> school gave me a sort of Chinese Room understanding...
16:20:26 <erisco> the concept of overloading lambda is clear to me, though I am not sure if CCCs is the way to do it
16:21:37 <erisco> I forget exactly but I think any finite number of combinators gives an expression exponentially larger than the LC notation
16:22:09 <erisco> in worst case
16:23:10 <erisco> in C# you can actually write lambdas and get the AST from them
16:23:36 <erisco> then you can compile this lambda however you want, and even emit code and run it
16:29:38 <a6a3uh> hi! what is the best way to generate list of arbitrary data? 
16:29:47 <a6a3uh> is it ok to do something like
16:29:52 <a6a3uh> unGen arbitrary (mkQCGen seed) 5
16:30:06 <a6a3uh> to generate list of length 5 for example
16:30:15 <erisco> did you try it? what happened?
16:30:25 <a6a3uh> or there is an easier and more correct way using Random library?
16:30:28 <a6a3uh> it works
16:30:56 <a6a3uh> but it uses QuickCheck that is for checking not for normal programming I believe
17:01:30 <mibaz_1> Do you guys put your types and instances in a file away from the functions that work on those types?
17:04:12 <boj> mibaz_1: usually when the types are used elsewhere as well, or could introduce a circular dependency
17:06:05 <Welkin> mibaz_1: you mean data and newtype declarations?
17:06:09 <boj> one of the drawbacks to that is if you change that file often, you end up rebuilding a lot
17:06:11 <Welkin> you can, but it depends on your program
17:06:36 <Welkin> there is no single way to structure your code
17:08:22 <mibaz_1> What I'm working on isn't big enough for it to matter, so I'll go with something and see how it works out
17:08:35 <mibaz_1> Later maybe I'll form an opinion on the issue.
17:19:47 <albeit> Is ~120 seconds reasonable for parsing with attoparsec a 500MB text file with a combination of integers and strings parsed?
17:20:24 <albeit> Or could that be an order of magnitude too slow?
17:23:06 <erisco> that's like, what, half a million 8 digit integers per second
17:24:38 <erisco> it sounds neither fast nor slow, just kinda meh
17:25:28 <ab9rf> albeit: depends on how much backtracking is rqeuired, i suppose
17:25:45 <ab9rf> and on yhour use case
17:26:26 <erisco> I wonder how much time is actually taken up by the conversion to Int
17:26:55 <ab9rf> erisco: depends on how it's done 
17:33:35 <erisco> albeit, if you need speed then try Happy
17:34:39 <iqubic> What does Happy do?
17:34:44 <ab9rf> it's a parser generator
17:34:51 <ab9rf> basically yacc for haskell, except rather brighter than yacc
17:35:16 <ab9rf> i'm not fond of it, but it has its use cases
17:39:19 <iqubic> What does that mean, a Parser generator.
17:39:30 <iqubic> I have no idea what yacc is.
17:40:01 <erisco> it means you give it a grammar and it gives you a Haskell program that parses that grammar
17:40:27 <iqubic> Odd. What parsing framework does Happy use?
17:40:54 <erisco> a medley of stuff, but I think it is primarily LR(1) ... you can read about it on their website
17:41:08 <iqubic> Like what library does the resulting program use?
17:41:11 <geekosaur> it does not compile to any of the parser combinators
17:42:14 <iqubic> Parsing is just advanced string searching right?
17:42:44 <erisco> it is about transforming a string to a tree
17:42:59 <iqubic> Huh, why do you say that?
17:43:36 <erisco> because the problem it solves is, given a sentence of a language, what are the parse trees for that sentence?
17:43:48 <iqubic> Oh. I see.
17:44:12 <erisco> so it is actually a tree search, where your search term is the sentence
17:44:16 <iqubic> I guess I don't know enough about parsers to understand this conversation.
17:45:01 <geekosaur> a parser takes a string and produces an abstract syntax tree representing the language contained within the string
17:45:43 <iqubic> What is an abstract sytax tree?
17:46:00 <erisco> well how about we start at grammars. are you familiar with BNF?
17:46:21 <iqubic> What does that stand for? I might know what it is.
17:46:32 <hodapp> iqubic: o hai, I saw you in #emacs too
17:46:35 <geekosaur> do you know Lisp or Scheme? they are both very simple encodings of an abstract syntax tree into a string, relying on parentheses to delimit AST nodes
17:46:41 <erisco> Backus-Naur Form
17:46:42 <iqubic> hodapp: I am also in there as well.
17:46:50 <iqubic> I know lisp, yeah
17:47:29 <iqubic> Well, I know elisp. But I get the point of how lisp is an AST.
17:47:42 <geekosaur> it also demonstrates why (a) we don't usually use raw ASTs in programming (b) why programming language compilers/intepreters are easier to implement when a program is represented as an AST
17:47:58 <geekosaur> (+ (* 3 5) 2)
17:48:03 <ab9rf> a parser doesn't strictly have to return an AST but most do
17:48:14 <hodapp> geekosaur: heyyy, some people LIKE code that looks like that!
17:48:34 <hodapp> mostly Lispers.
17:48:40 <erisco> some extra parens and it can be Haskell code!
17:48:49 <iqubic> Yep.
17:48:50 <erisco> > ((+) ((*) 3 5) 2)
17:48:52 <lambdabot>  17
17:48:56 <hodapp> o_O
17:49:00 <ab9rf> i like lisp-format as a representation but i don't like writing code in that format
17:49:09 <iqubic> So erisco how does that translate to grammer?
17:49:18 <mibaz_1> "parse it yourself!" -John McCarthy, 1958
17:49:19 <geekosaur> this has two AST nodes, and does not make you deal with precedence or associativity; this is encoded into the tree representation already. parsers deal with that encoding for you for languages which aren't already tree-like
17:49:26 <erisco> iqubic, how does what translate to grammar? BNF?
17:49:40 <ab9rf> do people still use the dragon book?
17:50:31 <iqubic> You know, I once wrote a parser in Java. It took something like "5 + 12 - 32 * 3" and converted it into RPN while maintaining order of operations.
17:50:52 <johnw> ab9rf: I've heard that some do
17:50:54 <MrHee> Hallo people! Seeking some help in the magical world of functional programming :) 
17:50:57 <geekosaur> (I should note that lisp/scheme isn't the only language like this; RPN languages like Forth and PostScript are also fairly close to AST form)
17:51:06 <johnw> MrHee: what sort of help?
17:51:12 <iqubic> geekosaur: Yeah, I realized that.
17:51:19 <erisco> MrHee, welcome to the council of functional wizards, how may we be of assistance?
17:51:41 <iqubic> So, erisco, you said that most parsers take a string an turn it into an AST?
17:51:53 <iqubic> But you first wanted to start with grammer.
17:52:36 <iqubic> So why did you bring up Lisp?
17:52:42 <iqubic> How does lisp relate to grammer?
17:52:49 <erisco> iqubic, BNF is a standard notation for grammars. From grammars you can understand the rest, it is the epicentre
17:52:57 <Welkin> maybe you type with a lithp
17:53:01 <iqubic> s/grammer/grammar/
17:53:17 <iqubic> I don't know BNF notation?
17:53:23 <iqubic> I don't
17:53:28 <erisco> Lisp has a grammar
17:53:41 <iqubic> It does??
17:53:42 <johnw> the Lisp language is somewhat unique in that it's also effectively the AST for that language
17:53:49 <erisco> yes, all programming languages do
17:54:01 <iqubic> Right. I suppose that makes sense
17:54:15 <erisco> and lets say that, in general, all languages do :)
17:54:26 <iqubic> Alright, where do we go from there?
17:54:29 <erisco> the grammar tells us the rules for how sentences are formed
17:54:32 <Welkin> just like all languages are statically typed
17:54:43 <Welkin> it's just that so-called "dynamic" ones have a single type
17:54:44 <MrHee> erisco, there is some code i forged with the sole power of my brain, but i find it hard to reason about its performance. There is some mich garbage floating around it takes a lot of time to collect. I assume it might have something to do with the, to me not well known workings, of lazyness
17:54:59 <ab9rf> iqubic: btw, it's "grammar" :)
17:55:03 <iqubic> I know
17:55:29 <Welkin> MrHee: post your code on lpaste
17:55:32 <erisco> a grammar consists of terminals, non-terminals, production rules, and a starting non-terminal
17:55:33 <Welkin> @lpaste
17:55:33 <lambdabot> Haskell pastebin: http://lpaste.net/
17:55:52 <iqubic> Alright.
17:55:57 <iqubic> I think I get that.
17:56:06 <iqubic> Can I have an example Erisco?
17:56:25 <ab9rf> Welkin: i saw someone use the term "unityped" for so-called "dynamically typed" languages
17:56:38 <Welkin> ab9rf: yes I've seen that too
17:56:43 <erisco> absolutely... conventionally s or S is our starting non-terminal. an example BNF grammar is  S ::= "a"
17:57:20 <iqubic> So the "sentence" as it were must start with 'a'
17:57:24 <dolio> Garbage collection is kind of a bad analogy.
17:57:29 <erisco> this grammar consists of the non-terminal S, the terminal "a" (denotes the letter a), the production rule S ::= "a", and the starting non-terminal S
17:57:34 <dolio> Because most algorithms don't pick up garbage.
17:58:11 <dolio> They pick up things that aren't garbage and then arrange for the garbage to go away regardless of how much there is.
17:58:28 <erisco> lets call this grammar G1, then we now want to know L(G1) i.e. the language of the grammar i.e. all the sentences (sometimes just called words, or strings) of the language
17:58:33 <ab9rf> most algorithsm dispose of their waste immediately, isnteasd of just tossing it aside as they go
17:58:51 <iqubic> erisco: Can you compose a sentence using G1?
17:58:56 <erisco> to do this we begin with the starting non-terminal and use production rules to replace non-terminals until we are only left with terminals
17:59:17 <erisco> so we start with S, then we only have one production rule, so I use that and now have "a"
17:59:18 <hodapp> ab9rf: was that someone Bob Harper or one of his fans?
17:59:32 <erisco> and so L(G1) is just the sentence "a"
17:59:45 <iqubic> Alright. Sounds good.
17:59:57 <iqubic> Can we have a more complex grammar system?
18:00:12 <erisco> we also want to know the parse tree for "a"
18:00:32 <erisco> the parse tree can be seen as our proof that "a" is actually in L(G1)
18:00:33 <iqubic> What is the parse tree fr "a"?
18:00:43 <iqubic> I see.
18:01:04 <erisco> so the top of the tree is our starting non-terminal, S, and branches are production rules we use
18:01:15 <erisco> so our tree, written in a line, looks like  S --> "a"
18:01:22 <iqubic> Sounds good.
18:01:46 <ab9rf> hodapp: don't recall
18:01:46 <iqubic> That is literally the only parse tree we have for L(G1)
18:01:47 <MrHee> here its is: http://lpaste.net/357619 a eratosthenes sieve. most of the runtime is spend with garbage collection (if i understand the benchmark output correctly)
18:02:19 <erisco> S ::= "a" | "b"  is a different grammar, call it G2, and L(G2) has two sentences, "a" and "b"
18:02:52 <erisco> x | y means "either x or y"
18:03:11 <iqubic> I figured that erisco
18:03:13 <erisco> so from the starting non-terminal S I can choose to make it "a" or I can choose to make it "b"
18:03:20 <iqubic> Right.
18:03:42 <iqubic> So the two sentences we have are: "a" and "b"
18:04:11 <erisco> S ::= "a" "b"   is another grammar, call it G3, and L(G3) is the sentence "ab"
18:04:14 <dolio> MrHee: I don't think laziness is your problem.
18:04:24 <dolio> Using really inefficient data structures is. :)
18:04:28 <iqubic> How does G3 work?
18:04:44 <iqubic> Why not write G3 as S ::= "ab"
18:04:46 <MrHee> ok, was just a wild guess. i'm pretty new to all this stuff
18:04:46 <iqubic> ??
18:04:50 <erisco> x y means "x then y"
18:04:56 <iqubic> I see.
18:05:08 <ab9rf> the use of !! makes me twitchy
18:05:14 <ab9rf> !! is not very performant
18:05:21 <iqubic> How is "a" "b" different from "ab"
18:05:22 <MrHee> and i was wondering where all the memory usage comes from
18:05:43 <ab9rf> MrHee: likely partially evaluated thunks
18:05:45 <dolio> `list \\ [p^2, p^2+p..max]` is also not great.
18:06:00 <erisco> iqubic, it depends on what our set of terminals are. "ab" might not be a terminal
18:06:12 <iqubic> Ah. I see.
18:06:22 <ab9rf> dolio: \\ is set difference? that's like what, O(n+m+log(nm)) or something?
18:06:25 <ab9rf> it's not cheap
18:06:37 <iqubic> So you can have a grammar where "a" "b" is terminal, but "ab" isn't
18:06:37 <MrHee> yup its supposed to be set difference
18:06:42 <erisco> iqubic, in PLs usually instead of individual characters we first tokenise and parse tokens instead
18:06:51 <dolio> It's set difference if there is at most one of each element in the list.
18:06:59 <erisco> iqubic, so we might have a token that represents the string "type" as a keyword, for example
18:07:03 <ab9rf> why not use filter?
18:07:21 <iqubic> Can we have a grammar with more than just one rule?
18:07:23 <ab9rf> the list is presumably monotonically increasing, so use takeWhile
18:07:24 <erisco> iqubic, you can have one where "a" is a terminal and "b" is a terminal but "ab" is not a terminal, yes
18:07:42 <dolio> Otherwise it removes the first copy, probably.
18:08:18 <ab9rf> i don't use \\ often, as you can tell
18:08:19 <dolio> Also for any element being removed that doesn't appear in the list, it's going to check the whole list.
18:08:24 <geekosaur> typically you have one "top level" rule which invokes subrules
18:08:34 <iqubic> Also in "a" "b" you might be able to replace both "a" and "b" with something else. But, for the same grammar "ab" is terminal
18:08:35 <dolio> So worst case it's n*m, probably.
18:08:35 <erisco> iqubic, well, we give all the productions for a non-terminal with the same rule, but we can have more than one non-terminal
18:08:42 <geekosaur> which may be recursive, either directly or mutually
18:08:44 <ab9rf> i'm much mor elikely to use filter, dropWhile/takeWhile, or something similar
18:09:09 <erisco> iqubic, you might also notate G2 as  S ::= "a"; S ::= "b"   where ';' denotes a line break
18:09:12 <dolio> filter would also be n*m.
18:09:39 <MrHee> i ran the programm with +RTS -s -p, here is the output: http://lpaste.net/357620 if i understand it correctly most of the time is not used for "calculation" so i was thinking the worst part is maybe not the performance of \\
18:09:55 <erisco> iqubic, life is interesting once we use non-terminals in a production, so for example G3 is S ::= "a" S | "b"
18:10:07 <erisco> iqubic, can you reason what L(G3) is?
18:10:23 <erisco> or are we on G4 now? I lost track :P
18:11:01 <dolio> MrHee: I guess the laziness angle is that your $! barely does anything.
18:11:33 <MrHee> oh, yeah it does not thats right. forgot to take it out
18:11:46 <dolio> !!pos will do more than the $! almost immediately.
18:11:56 <dolio> But anything beyond pos remains unevaluated.
18:12:36 <MrHee> the gc idea was as i said pretty random, i have really no idea how it works :) 
18:13:29 <dolio> Oh, but list!!pos isn't actually evaluated.
18:13:53 <Welkin> o.o
18:14:00 <dolio> So I take it back, you're doing bad lazy things, as well. :)
18:14:08 <Welkin> I don't like the way you write !!variable
18:14:22 <Welkin> it looks like double-negation with type coercion
18:14:32 <Welkin> let's ban !! from Prelude
18:15:25 <dolio> It's a combination, though.
18:15:25 <Welkin> it seems like beginners are attracted to this mistake of a function like moths to a lightbulb
18:15:35 <ertes> (!!) would be much more useful, if it were strict in the skipped elements
18:16:53 <dolio> It's possible that list \\ [p^2...] has to force p, which forces various other things in the accumulated list.
18:17:01 <MrHee> ok my reasoning was a bit like this: i have a bunch of recursive calls of "sieve" each time with the pretty big variable "list" if the variable "list" will not be evaluated till the last call (end of recursion) there might be a lot of big arrays floating around in memory. 
18:17:07 <dolio> So the $! is doing that.
18:17:17 <erisco> iqubic, for example, we start at S, then I use S ::= "a" S to get "a" S, now I can use it again to get "a" "a" S
18:17:18 <dolio> Instead of everything being completely lazy.
18:17:40 <ertes> @let usefulIndex = flip $ foldr (\x go n -> if n <= 0 then x else x `seq` go (n - 1)) (const (error "It's so short I can't find it!"))
18:17:42 <lambdabot>  Defined.
18:18:07 <ertes> > iterate (\x -> x^2 + 1) (0 :: Word) !! 100000
18:18:10 <lambdabot>  926155691629764698
18:18:12 <ertes> > iterate (\x -> x^2 + 1) (0 :: Word) !! 1000000
18:18:16 <lambdabot>  926155691629764698
18:18:22 <dolio> Well, they're not arrays.
18:18:27 <dolio> That's part of why this is so bad.
18:18:35 <dolio> They're linked lists.
18:18:40 <ertes> > usefulIndex 1000000 (iterate (\x -> x^2 + 1) (0 :: Word))
18:18:44 <lambdabot>  926155691629764698
18:18:53 <ertes> i'm kinda surprised that (!!) is so fast there
18:19:16 <MrHee> is there a better way to pick an element from a list other than !! ?
18:19:29 <ertes> MrHee: by index?
18:19:35 <Welkin> don't index a list
18:19:39 <Welkin> they are not made for that
18:19:45 <Welkin> use a different data structure
18:19:49 <ertes> Welkin: indexing a list is fine
18:19:58 <MrHee> yes by index
18:20:19 <evincar> Does anyone happen to know how to get Stack to install data-files in the "stack install" prefix (~/.local/bin)?
18:20:22 <ertes> it's the list-as-a-control-structure equivalent to a for-loop with a fixed number of steps
18:20:47 <Welkin> ertes: but you are not indexing in that case
18:20:54 <evincar> Currently Cabal's getDataFileName is returning a path in my .stack-work directory :/
18:21:00 <ertes> MrHee: the usefulIndex function i just defined is quite useful in the mildly common case where you construct a list to compute something iteratively, and then you index that list
18:21:08 <Welkin> you are destructuring the list and taking the head
18:21:17 <ertes> Welkin: what's the difference?
18:21:27 <Welkin> ertes: !! is a stupid function
18:21:37 <Welkin> it traverses the entire list from the beginning
18:22:04 <ertes> Welkin: what else should it do?
18:22:18 <Welkin> nothing, since it shouldn't exist
18:22:19 <erisco> jump lists
18:22:32 <erisco> has anyone implemented jump lists in Haskell? hm
18:23:26 <ertes> Welkin: check out the lucas-lehmer primality test for mersenne primes
18:23:37 <ertes> a strict variant of (!!) is *exactly* what you need there
18:23:58 <ertes> (!!) the way it's defined is not very useful, but a strict variant would be very useful for this sort of algorithm
18:24:51 <MrHee>  is there a way to "force" the evaluation of (!!) in some way? Or more general to pick an element of the list in a "non lazy" fashion?
18:25:28 <geekosaur> am tempted to say that if you don't want laziness, you should be using Vector instead of lists
18:25:35 <geekosaur> lists kinda *are* laziness
18:25:37 <ertes> MrHee: well, you could transform the list into one where (:) is made artificially strict
18:26:14 <ertes> @let strictSequence = foldr (\x xs -> x `seq` x:xs) []
18:26:15 <lambdabot>  Defined.
18:26:24 <ertes> if you apply strictSequence first, you can use the regular (!!)
18:26:31 <c_wraith> MrHee: you are aware that laziness isn't why !! is a problem, right?
18:26:51 <MrHee> c_wraith: no i am not 
18:26:52 <evincar> If you find yourself using a list as a *data* structure in Haskell, you're probably doing something wrong
18:26:58 <evincar> It's a great *control* structure
18:27:08 <ertes> MrHee: also note that right now two topics about lists are going on at the same time =)
18:27:10 <erisco> oh, apparently only I call them jump lists, well whatever, skip list it is
18:27:22 <dolio> l!!n is O(n).
18:27:27 <c_wraith> MrHee: !! is slow because [] is a singly-linked list.  Indexing into it requires traversing every element up until the target.  That's the reason why it's bad.
18:27:29 <ertes> MrHee: there is the "don't use lists for random access" topic, and there is the "(!!) is kinda useless by itself" topic =)
18:27:39 <MrHee> ertes: hmm maybe thats why i'm a bit confused
18:27:39 <erisco> tada, list with log n indexing http://hackage.haskell.org/package/skip-list
18:27:56 <ertes> MrHee: indexing lists is fine, if iteration is what you need
18:28:17 <ertes> MrHee: and i would encourage you to do it, but be aware that (!!) needs to be stricter
18:28:23 <c_wraith> Now..  a stricter version of iterate would be nice with !!
18:28:32 <c_wraith> ertes: shouldn't that strictness be in iterate?
18:28:42 <ertes> c_wraith: no, i would definitely not like that
18:28:47 <ertes> generate lazily, consume strictly
18:29:31 <c_wraith> ertes: !! is already strict.  The problem is in something like iterate
18:29:35 <ertes> c_wraith: what i don't like about strict iterate is that it would make (:) artificially strict in the head
18:29:44 <c_wraith> ertes: that's not what it means...
18:29:56 <ertes> c_wraith: hmm?  what does it mean?
18:30:08 <erisco> actually skip-list is a really new package... what a coincidence
18:30:21 <c_wraith> ertes: the idea for a stricter iterate is iterate f x = x `seq` (x : iterate f (f x))
18:30:35 <ertes> c_wraith: but that's what i just said
18:30:50 <ertes> pattern-matching on (:) forces the head
18:31:02 <c_wraith> ertes: Oh, I misread it.  But that's where the value in making it stricter is.
18:31:13 <ertes> c_wraith: i consider that to be an anti-pattern
18:31:30 <erisco> may as well abstract the :
18:31:33 <c_wraith> ertes: I consider it to be correct in most cases
18:32:07 <erisco> :t let iterate g f x = x `seq` (x `g` iterate g f (f x)) in iterate
18:32:09 <lambdabot> (t1 -> t -> t) -> (t1 -> t1) -> t1 -> t
18:32:15 <dolio> But your (!!) is tailor made to only be efficient for things that are exactly like iterate.
18:32:43 <dolio> But it's iterate that has the knowledge that forcing earlier elements is a benefit for the later ones.
18:32:44 <ertes> c_wraith: the problem i have with it is that you can no longer "trust" the list…  if you go by "construct lazily, consume eagerly", then you can reason locally about strictness
18:33:07 <c_wraith> ertes: I go by "generate correctly, consume correctly"
18:33:13 <erisco> heh, that is an amusing type
18:33:24 <erisco> @djinn (t1 -> t -> t) -> (t1 -> t1) -> t1 -> t
18:33:24 <lambdabot> -- f cannot be realized.
18:33:27 <c_wraith> ertes: "correctly" usually doesn't mean either fully strict or fully lazy
18:33:31 <evincar> One of the key benefits of laziness is that it's "anti-modular" though
18:33:31 <erisco> the co is real
18:33:48 <evincar> In the sense that performance details leak between functions
18:33:55 <evincar> It leads to more modular *code*
18:34:29 <erisco> ertes, I am abstracting : so that you have the option not to stick your strict value into a lazy field
18:34:30 <dolio> iterate doesn't actually have that knowledge, of course, because it depends on the function.
18:35:03 <c_wraith> dolio: I agree in that I don't want to replace iterate.  Just provide a second version so that the programmer can choose the correct one.
18:35:13 <ertes> c_wraith: well, we could debate that for hours…  i think 'iterate' is too general to know whether it should produce a fully or a partially lazy list
18:35:22 <mibaz_1> I see how forall is useful in data declarations, but when I look at, for example, this reflex function type, it seems useless to me: "switchPromptlyDyn :: forall t a. Reflex t => Dynamic t (Event t a) -> Event t a"
18:35:26 <mibaz_1> What am I missing there?
18:35:44 <c_wraith> mibaz_1: that forall is probably for the ScopedTypeVariables extension
18:35:55 <c_wraith> mibaz_1: since it is exactly the same as it would be if it was just implicit
18:36:02 <ertes> c_wraith: but i think we can agree on one thing: the base library is too biased toward completely strict functions =)
18:36:10 <ertes> err
18:36:15 <ertes> completely non-strict functions
18:36:18 <c_wraith> yes. :)
18:36:29 <erisco> but we can take the seq out too...   iterate g f x = x `g` iterate g f (f x)
18:36:35 <erisco> g can decide if it wants to be strict or not
18:36:58 <mibaz_1> c_wraith: Ok thanks, was making sure it was the same as it would be if it was implicit (as far as my usage of the library goes)
18:37:26 <dolio> Also none of you considered: iterate f x = x : (x `seq` iterate f (f x))
18:37:35 <c_wraith> mibaz_1: yeah, the thing is there are like 7 extensions that enable the forall keyword. :)
18:38:13 <ertes> dolio: that just puts the seq on the next (:), which is probably just a way to make it slower =)
18:38:33 <evincar> mibaz_1: It also affects TypeApplications: if you have "forall t a." then "switchPromptlyDyn @x" sets t ~ x, but if you have "forall a t." then it'd be a ~ x
18:38:35 <erisco> no, because the next : gets f x, not x
18:38:47 <dolio> Using iterate and (!!) is a way to make things slower than using functions that won't build a list.
18:39:02 <c_wraith> evincar: while true in general, the provided order is the same as it would be without an explicit forall
18:39:12 <ertes> dolio: they should fuse away
18:39:25 <ertes> 'iterate' is a build, and (!!) is a fold
18:39:26 <evincar> c_wraith: True, just giving another reason people use explicit foralls
18:40:10 <evincar> Bleh, if I can't figure out how to configure the install prefix with stack then I'll have to embed this file :/
18:40:31 <evincar> I guess I could make a custom installer...
18:40:56 <MrHee> first of all thanks for you comments everyone! Maybe you can verify the points that i think to have understood? The code is slow because: a) list a not a nice data structure for this, they are sloow b) there are maybe faster ways to do things such as the list difference \\ c) there is some lazy stuff going on since (list!!pos) is not evaluated till the end which is related to a) 
18:41:14 <dolio> ertes: !! will not fuse.
18:41:29 <dolio> Oh, wait, I guess it will.
18:41:30 <erisco> what is a list difference, hm ...
18:41:32 <c_wraith> evincar: are installing a haskell program from source?
18:41:52 <c_wraith> evincar: but you want it to be installed by a non-technical user?
18:41:57 <Welkin> erisco: //
18:42:19 <c_wraith> > [1..10] \\ [3..5]
18:42:21 <lambdabot>  [1,2,6,7,8,9,10]
18:42:22 <Welkin> :t Data.List.(//)
18:42:24 <lambdabot> error:
18:42:24 <Welkin> er
18:42:24 <lambdabot>     Not in scope: data constructor ‘Data.List’
18:42:24 <lambdabot>     No module named ‘Data’ is imported.
18:42:26 <Welkin> :t Data.List.(\\)
18:42:28 <lambdabot> error:
18:42:28 <lambdabot>     Not in scope: data constructor ‘Data.List’
18:42:29 <lambdabot>     No module named ‘Data’ is imported.
18:42:31 <erisco> huh, how would you describe that... it is interesting
18:42:32 <Welkin> what...
18:42:42 <c_wraith> Welkin: syntactically, the qualified name is *all* the operator
18:42:51 <c_wraith> :t (Data.List.\\)
18:42:52 <lambdabot> Eq a => [a] -> [a] -> [a]
18:42:54 <Welkin> erisco: it is the difference between two sets, where the sets are lists
18:43:01 <erisco> Welkin, nope
18:43:16 <evincar> c_wraith: The actual problem I have is that I have a compiler, and I'm not shipping binary releases (yet), so it's built from source; and I want to install both the compiler executable and the standard library files with "stack install"
18:43:21 <erisco> > [1,1] \\ [1]
18:43:24 <lambdabot>  [1]
18:43:28 <Welkin> okay, that's true
18:43:31 <erisco> if lists were sets then this is certainly not set difference
18:43:35 <c_wraith> evincar: ah, ok.  Yeah, I don't have a solution. :)
18:43:35 <Welkin> it only removes the first value found
18:43:44 <Welkin> but lists are not sets :P
18:43:45 <c_wraith> it's multi-set difference. :)
18:43:55 <erisco> no, because it is ordered too
18:44:02 <c_wraith> that's just an accident
18:44:13 <erisco> depends if you want it to be an accident
18:44:25 <erisco> I think having it keep the order like it does makes it interesting
18:45:12 <evincar> Cabal has a "data-files" package property that generates a "Paths_packagename" module which provides a function "getDataFileName", but it uses the absolute path to my .stack-work directory as a prefix; I want it to be relative to the install directory
18:45:16 <MrHee> that \\ removes just the first instance of an element is ok in this case, since the list that is reduced step by step contains each int just onece 
18:45:36 <erisco> > [1,2,1,2,1] \\ [1,1]
18:45:39 <lambdabot>  [2,2,1]
18:45:41 <erisco> it isn't just the first instance
18:45:59 <erisco> c_wraith is right that it can be understood as multiset difference so long as you don't care about the order
18:46:11 <c_wraith> It's easiest to fully specify it by just providing the code. :)
18:46:11 <evincar> So I'm trying to build with Cabal instead so I can "{cabal,runhaskell Setup.hs} configure --prefix=..."
18:46:51 <evincar> But I don't like saying "build with stack, unless you want to install, then build with cabal-install"
18:48:49 <erisco> > [1,2,1,2,1] \\ [2,1]
18:48:52 <lambdabot>  [1,2,1]
18:49:07 <erisco> okay, that is another important thing to see... didn't have to work like that
18:49:38 <erisco> actually I can't be sure of what happened, heh... bad test
18:49:44 <c_wraith> yeah, just specify it with code.  It's way more compact.
18:49:54 <erisco> > [1,2] \\ [2,1]
18:49:56 <lambdabot>  []
18:49:58 <sm> evincar: those paths are always going to be fragile, better to use file-embed sometimes IMHO
18:50:14 <Welkin> > [1,2,2,1] \\ [1,2]
18:50:16 <lambdabot>  [2,1]
18:51:42 <erisco> so the right argument seems to be understood as a multi set... i.e. the order is not significant
18:51:46 * hackagebot tcod-haskell 0.1.0.0 – Bindings to libtcod roguelike engine – https://hackage.haskell.org/package/tcod-haskell
18:52:27 <Welkin> erisco: it takes each element from the second list and does a linear search in the first. When it finds a match, it removes it and continues the loop
18:52:42 <Welkin> removes both*
18:52:44 <erisco> now we might consider the operation that removes the first n occurrences of an element from a list
18:52:51 <erisco> then the specification is simple
18:53:53 <Welkin> I don't find lists to be all that useful other than as control structures
18:54:03 <Welkin> I've only actually used list difference once, and it was really ugly
18:54:16 <Welkin> it could have been done better using a different data structure most likely
18:54:45 <sm> huh, I eat and breathe lists when programming haskell
18:55:44 <erisco> I think that is so specific that it might be the implementation though :P
18:55:58 <Welkin> sm: really? I find myself using Map as the most common container
18:56:15 <Welkin> or Vector
18:56:47 <Welkin> I suppose I do use lists when I get a result back from a database query
18:57:22 <Welkin> but not by choice, and I don't do anything with it other than push it along to some other process where the data is looped over
18:57:36 <Welkin> then it is just a control structure again
18:58:34 <Welkin> my favorite is still Data.Sequence.Seq
18:58:45 <Welkin> I could probably always find an excuse to use it
18:59:30 <evincar> sm: Yup, that's what I'm going with
18:59:48 <evincar> A single executable with all the data it needs is easier for deployment anyway
19:00:38 <Big_G> Is there a good way to use Haskell for shell scripting if the machine you want to run the script on doesn't have Haskell installed?
19:01:09 <pacak> Big_G: Sounds like a strange idea.
19:01:25 <sm> Big_G: "stack script" is the most robust way
19:01:34 <Welkin> Big_G: sure there is
19:01:42 <pacak> You can compile your "script" using static linking.
19:01:48 <Welkin> you don't nee the haskell compiler to run your compoiled code
19:01:49 <Welkin> compiled*
19:01:51 <Big_G> pacak, Agreed. The use case is that I like Haskell and want to use it but our enterprise machines may not have stack or Haskell installed 
19:01:57 <Welkin> you can write shell scripts using turtle
19:02:00 <Welkin> @hackage turtle
19:02:01 <lambdabot> http://hackage.haskell.org/package/turtle
19:02:10 <sm> Welkin: that's fine if machines are sufficiently compatible
19:02:24 <Welkin> as long as it's all linux
19:02:25 <pacak> Big_G: Don't pick a tool based on your likes. Pick a tool that fits better.
19:02:28 <Welkin> which is very likely
19:02:29 <Big_G> Welkin, I know about Turtle. How would that run though if the machine doesn't have Haskell?
19:03:15 <ab9rf> "the machine doesn't have haskell"? what does that mean?
19:03:23 <Welkin> it doesn't need haskell
19:03:24 <pacak> Big_G: Compile it and ship binaries.
19:03:30 <Welkin> you already compiled the program into binary
19:03:59 <Big_G> Do I need to know the architecture of the machine beforehand? 
19:04:04 <Welkin> sure
19:04:14 <ab9rf> yhou don't need anything at all to run a binary compiled using haskell, haskell produces standalone binaries.
19:04:34 <Welkin> if you compile it on one linux machine, it should run on any other linux machine
19:04:38 <Welkin> same with windows or mac
19:04:43 <sm> not true ab9rf. You need a machine of the same architecture, and several compatible C libs
19:04:51 <ab9rf> Welkin: depending on the configuration of the low-level compiler, i suppose
19:04:56 <sm> Welkin: you must not have tried this
19:05:00 <Welkin> sure, you might run into issues with system libraries
19:05:03 <iqubic> erisco: I get that there are many different grammars possible. What does that have to do with parsers???
19:05:04 <Welkin> but that depends on what you are doing
19:05:15 <Welkin> and you can always statically link/include them in your binary
19:05:17 <ab9rf> also, the executable may reference "standard library" (libc, etc.)
19:05:26 <erisco> iqubic, did you figure out what the language for the last grammar was?
19:05:29 <ab9rf> there's no haskell RTM library
19:05:51 <iqubic> erisco: I left to eat dinner so I haven't seen the last grammar.
19:05:51 <ab9rf> but ghc-produced binaries may reference other dynamically-loaded libraries
19:05:52 <Big_G> Exactly sm. The concern is that I build it on my Linux machine and it fails on Docker for example. 
19:06:04 <erisco> iqubic, G4 is S ::= "a" S | "b"
19:06:10 <ab9rf> Big_G: ghc has an option to build a fully-static image
19:06:10 <Welkin> sm: I have done this many times, compiling on a local machine and then pushing the binary to a server. I have run into issues with libraries not being installed
19:06:14 <sm> you'll build it on your modern machine and it'll fall over on a user's old debian machine
19:06:16 <sm> eg
19:06:23 <Welkin> and when I compiled with nix, I had to run nix on the target machine as well
19:06:27 <Welkin> so yes, it can be trouble
19:06:30 <Welkin> but in general, no
19:06:31 <sm> due to different versions of libwhatever
19:06:42 <ab9rf> these issues are endemic to all languages that compile to native code
19:07:14 <Big_G> Why would it be missing libraries on the host if you bring them all in the binary?
19:07:22 <Welkin> Big_G: it wouldn't
19:07:27 <Welkin> bt the default to dynamic linking
19:07:28 <iqubic> L(G4) is "ab" or "aab" or "aaab" or "aaaab" or "aaaaab" or ...
19:07:34 <Welkin> you can statically link though
19:07:52 <iqubic> One or more "a"s followed by a single "b"
19:07:56 <Big_G> Thanks all for the responses. I think I have a good idea. 
19:08:19 <sm> Big_G: for closer to posix-shell level portability, I recommend a bash script that installs stack (ie, stack's handy bash installer script) and the does your thing
19:08:31 <erisco> iqubic, yes, and now consider the parse trees for these sentences
19:08:32 <Welkin> if you really want to have a "shell script" that can be run on many different machines, then haskell is not the best tool
19:08:44 <Welkin> if you have one specific machine that you want it to run on, that should not be a problem
19:08:59 <ab9rf> or you need to write a llvm backend that generates bash code :)
19:09:01 <iqubic> erisco: There are infinitely many parse trees you could make.
19:09:13 <ab9rf> and tell ghc to use that llvm backend
19:09:26 <ab9rf> good luck with that idea
19:09:32 <erisco> iqubic, I just mean to look at what some of them look like. This is the one for "aaab" https://drive.google.com/open?id=12B65kqrgKBGhi3ELfSVaZck7Ss3gyL5Jggme741NJIk
19:09:51 <iqubic> Ah. I see.
19:09:59 <sm> Big_G: I am using this approach at http://hledger.org/download.html#b
19:10:14 <iqubic> and you can have as many S nodes as you want for G4
19:10:51 <erisco> iqubic, so now there are two correspondences we can make to Haskell
19:11:02 <iqubic> There are?
19:11:12 <erisco> iqubic, given a BNF grammar, we can readily define an AST
19:11:31 <erisco> iqubic, for G4 it looks like   data S = S1 Char S | S2 Char
19:11:45 <erisco> iqubic, notice the resemblance to S ::= "a" S | "b"
19:11:55 <iqubic> Right. I see how that works.
19:12:27 <erisco> so, the parse tree I showed you can be constructed as S1 "a" (S1 "a" (S1 "a" (S2 "b"))
19:12:51 <iqubic> Right. I see.
19:13:17 <erisco> this can be considered an AST, or abstract syntax tree
19:13:58 <erisco> an abstract syntax tree is a tree that represents the syntax abstractly. here there is no abstraction going on, but it can still be our AST
19:13:58 <iqubic> Alright. I understand how that works. You can do all sorts of weird stuff with grammar and ASTs.
19:14:15 <iqubic> Right. I got you.
19:14:34 <erisco> abstraction would be something such as converting [Char], a list of digits, to Int
19:15:01 <erisco> the other correspondence tells us how to derive a parser for a BNF grammar
19:15:17 <iqubic> It does??
19:15:47 <erisco> the parser for G4 is   s = S1 <$> char 'a' <*> s <|> S2 <$> char 'b'
19:16:02 <erisco> again notice the resemblance to  S ::= "a" S | "b"
19:16:18 <iqubic> That looks like some weird applicative and alternative stuff.
19:16:56 <erisco> juxtaposition, i.e. x y, i.e. "x then y", corresponds to <*>
19:16:57 <iqubic> What are S1 and S2?
19:17:14 <erisco> x | y i.e. "either x or y" corresponds to <|>
19:17:35 <erisco> S1 and S2 are constructors of the AST we just defined using the correspondence from the grammar
19:18:26 <iqubic> What do you mean? I don't see any definitions for S1 or S2.
19:18:47 <erisco> remember when I told you about  data S = S1 Char S | S2 Char  ?
19:19:44 <iqubic> No. I didn't actually.
19:20:02 <iqubic> So what is the type of s?
19:20:02 <erisco> oh, well you said "Right. I see how that works." after ;)
19:20:28 <erisco> depends on what parsing library you are using, but something like  Parser Char S
19:20:39 <iqubic> I see.
19:20:47 <iqubic> So what is the purpose of that parser?
19:20:54 <erisco> which means s is a parser on Char lists and constructs the S AST
19:21:20 <sumyunseal> i mite pick up haskel guys
19:21:20 <erisco> well, it does what parsers do :) so with a parser you can give it a string, such as "aaab"
19:21:32 <erisco> and it will give you back  S1 "a" (S1 "a" (S1 "a" (S2 "b")))
19:22:32 * hackagebot snap-server 1.0.3.0 – A web server for the Snap Framework – https://hackage.haskell.org/package/snap-server
19:22:32 * hackagebot snap-core 1.0.3.0 – Snap: A Haskell Web Framework (core interfaces and types) – https://hackage.haskell.org/package/snap-core
19:22:57 <erisco> I lead you through all the pieces to describe that this is what a parser does
19:23:12 <iqubic> Can you use a parser to take [[Char]] and turn it into [Maybe Int]?
19:23:32 <erisco> yes
19:24:23 <erisco> btw when I say "it depends on what parsing library you are using" I am referring specifically to parser combinators
19:24:38 <erisco> the way you use Happy is a bit different
19:24:53 <iqubic> ["H", "123", "E", "2"] --> [Nothing, Just 123, Nothing, Just 2]
19:24:58 <iqubic> Is that possible?
19:25:15 <erisco> yes
19:26:58 <iqubic> so why does: S1 <$> char 'a' <*> s <|> S2 <$> char 'b' use applicative and alternative combinators?
19:27:47 <erisco> because when you dig into trying to implement the two fundamental operations, i.e. "x then y" and "either x or y" you find that these operations take on the same types as <*> and <|> respectively
19:27:58 <iqubic> Ah. I see.
19:29:30 <iqubic> I'm sure the exact combinators used depend on which parsing library you end up using.
19:29:34 <erisco> and of course they also agree with the laws
19:30:02 <iqubic> What laws?
19:30:17 <erisco> the Applicative and Alternative laws
19:31:01 <erisco> all the parser combinator libraries are going to have the Applicative interface available
19:31:02 <iqubic> Ah.
19:31:24 <erisco> some also give you Monad which enables you to parse languages which cannot be represented with a BNF grammar
19:31:43 <iqubic> What language can't be repersented with BNF grammar?
19:31:55 <ab9rf> iqubic: C++
19:32:07 <iqubic> Why not?
19:32:13 <erisco> there is a hierarchy of languages called Chomsky's hierarchy
19:32:41 <ab9rf> i forget the reason, but it has to do with some constructs the parsing of which depends on how certain symbols were previously declared
19:32:43 <erisco> each tier has a description of the languages within in. BNF is a description of context-free languages
19:32:44 <iqubic> And what does that hierarchy list
19:33:13 <ab9rf> i could have given you a more precise answer ten years ago when i still remembered it :)
19:33:16 <iqubic> What is a context free language??
19:33:19 <erisco> as are pushdown automata
19:33:44 <erisco> iqubic, a context free language is one expressible with a BNF grammar or with a pushdown automata
19:34:11 <iqubic> That's a circluar definition.
19:34:35 <erisco> how so?
19:34:37 <iqubic> "BNF is a description of context-free languages" and "a context free language is one expressible with a BNF grammar"
19:34:44 <iqubic> You said both of those things.
19:34:45 <erisco> that is saying the same thing twice
19:35:08 <iqubic> Oh. So what is a context free language then?
19:35:24 <erisco> what I just told you :P
19:35:31 <iqubic> BNF can't deal with languages that have contex?
19:35:53 <erisco> you have to know specifically what "context" means here
19:36:11 <iqubic> I don't know what context means.
19:36:20 <erisco> so, a tier below context-free is regular languages
19:36:33 <iqubic> And what are regular languages?
19:36:44 <erisco> the regular expressions you use in programming languages are inspired by this but they've gone and added non-regular features
19:36:54 <iqubic> Ah. I see.
19:37:25 <erisco> a regular language is the empty string, or a terminal, or the concatenation of two regular languages, or the choice of two regular languages, or the Kleene star of a regular language
19:37:44 <iqubic> So a regular expression is a parser then??
19:37:55 <erisco> no, it is a grammar
19:38:14 <mibaz_1> should GHC.TypeLits and Data.Finite be used together or are they exclusive?
19:38:19 <iqubic> It is?
19:38:26 <iqubic> Oh, yeah it is.
19:38:43 <iqubic> Can you represent zero or more in BNF?
19:38:44 <erisco> the thing you give the regex to is the parser, like PCRE or smoething
19:38:55 <erisco> iqubic, all regular languages are context free languages, and so yes
19:38:57 <iqubic> Right. I got that.
19:39:15 <erisco> the hierarchy is just that... each layer higher subsumes the ones below
19:39:29 <mibaz_1> nvm Data.Vector.Sized makes it clear
19:39:29 <iqubic> How do you represent zero or more of an item in BNF notation?
19:39:33 <erisco> so a context free language is a regular language plus more
19:40:07 <erisco> iqubic, S ::= "a" S | ε
19:40:31 <erisco> I did not mention it, but epsilon denotes the empty sentence
19:40:46 <iqubic> I like this post: http://matt.might.net/articles/grammars-bnf-ebnf/
19:41:16 <iqubic> The first example given is a good example of a more complex grammar than we have been disscussing here.
19:41:29 <iqubic> It's the grammar of mathematical equations.
19:41:31 <erisco> well, it is easy to make things complicated :P
19:41:35 <iqubic> It is?
19:41:56 <erisco> larger grammars are just the same basics happening in larger quantity
19:42:07 <iqubic> Oh,
19:42:40 <iqubic> I remember a few months ago seeing a grammar for the prolog language. Not sure I can find it again though.
19:42:57 <erisco> above context-free you have context-sensitive
19:43:14 <iqubic> I see.
19:43:38 <erisco> "context" refers to the terminals and non-terminals which lie around a non-terminal
19:44:09 <iqubic> I like how that article has the grammar for BNF. So meta
19:44:15 <erisco> we can empower our grammar notation with this by allowing ourselves to write rules such as   "a" S "b" ::= "c"
19:44:59 <iqubic> What does that even mean?
19:45:30 <erisco> it means that to replace the non-terminal S with that rule it has to be preceded by "a" and succeeded by "b"
19:46:02 <erisco> so  xaSby  may become  xcy   but xbSay  cannot, for example
19:47:00 <iqubic> Ah. I see.
19:47:12 <iqubic> And how do we know that S is terminal?
19:47:20 <erisco> also it is required that all rules take a particular form, but you can read more on that if you are interested
19:47:34 <erisco> S is a non-terminal here
19:47:45 <erisco> in the notation, terminals are in quotes and nonterminals are not in quotes
19:47:48 <iqubic> Ah.
19:48:04 <iqubic> So why must all rules take a certain form?
19:49:08 <erisco> I cannot remember exactly. It may have to do with convenience of analysing the grammars, or it may be necessary to limit what languages we can express
19:49:35 <erisco> the form they have to take is that you cannot change the context
19:49:46 <erisco> so "a" S "b" ::= "b" S "a"  is a no-no
19:49:54 <iqubic> Ah.
19:49:55 <iqubic> I see.
19:50:39 <erisco> context sensitive languages can be recognised by Turing machines with finite tape, iirc
19:51:24 <erisco> then above that you have the recursively enumerable languages which is where all safeties are off
19:51:40 <erisco> you need a full Turing machine to recognise those
19:52:06 <erisco> "recognise" by the way means to determine if a given sentence belongs to the language
19:52:23 <ab9rf> erisco: and at that point the halting problem rears itself, iirc
19:52:33 <erisco> so, there is a relationship between languages and computing itself
19:52:48 <iqubic> I see. The halting problem is an issue.
19:53:42 <erisco> anyways, for Happy you are going to tell it your grammar (in something similar to BNF notation) and also your AST
19:53:59 <erisco> then it is going to output the parser as a Haskell program
19:54:06 <iqubic> Why do you need to give it an AST?
19:54:22 <ab9rf> you have to tell happy the type that the parser will generate
19:54:26 <ab9rf> which will NORMALLY be an AST
19:54:42 <erisco> it might derive one for you if you don't, I can't remember, but in practice you usually want something other than exactly the parse tree
19:54:55 <ab9rf> erisco: i don't think it can derive one for you.
19:55:00 <ab9rf> erisco: but i might be misremembering
19:55:58 <erisco> iqubic, maybe I should be more careful in my wording and say that you are giving it the definition for your AST, not a particular instance of an AST
19:56:11 <ab9rf> erisco: if you don't specify a type, the generated parser generates a value of type (), which is Generally Not Very Useful
19:56:30 <mnoonan_> erisco: that can’t be right.. isn’t a “turing machine with a finite tape” just a finite automaton?
19:56:33 <erisco> good for acceptance testing and not much else
19:56:44 <ab9rf> erisco: right.
19:57:23 <erisco> mnoonan_, I did not study context-sensitive languages nor Turing machines and so I do not know, just recalling this from memory
19:58:12 <erisco> mnoonan_, according to Wikipedia it is one of these things https://en.wikipedia.org/wiki/Linear_bounded_automaton
19:58:57 <koz_> Is there such a thing as a co-applicative?
19:58:58 <mnoonan_> ahh, finite but bounded by the input, rather than fixed
19:59:04 <iqubic> So anyone have a good parser tutorial, now that I understand what the heck they do.
19:59:42 <iqubic> How hard is it to write your own parser??
19:59:55 <koz_> iqubic: It's very very easy.
20:00:08 <iqubic> Why do you say that?
20:00:08 <erisco> you generally want to avoid that... either use a parser generator or use parser combinators
20:00:23 <koz_> iqubic: Read this: https://kunigami.blog/2014/01/21/an-introduction-to-the-parsec-library/
20:00:31 <erisco> if you write your own parser then you'd probably write a recursive descent parser with regexp mixed in
20:00:57 <erisco> well I suppose the language is confused again here...
20:01:29 <erisco> a parser for a specific grammar is something you can write by hand using a parser generator or parser combinators to help
20:01:59 <erisco> or you can write more intimately a recursive descent parser which incorporates regexp
20:02:01 <iqubic> Yeah. I get it.
20:02:03 <erisco> that is a common thing to do
20:02:26 <erisco> I tend to say "parser" synonymously with the things which generate them
20:02:54 <erisco> and I should not do that
20:04:23 <erisco> a parser generator takes a grammar and gives you a parser
20:04:29 <erisco> then you give a parser a string and it gives you an AST
20:04:59 <erisco> parser combinators are a way of writing your grammar so it is its own parser
20:05:07 <erisco> also known as "executable grammars"
20:06:30 <koz_> Also, is there some explanation somewhere on the differences between wfix, cfix and kfix for comonads?
20:12:03 <iqubic> Parsec's char function doesn't seem to return an AST
20:13:26 <iqubic> Oh wait, it does. But the parse function extracts values from that AST
20:14:59 <koz_> Is there such a thing as a co-applicative? <-- in case anyone missed it
20:20:22 <iqubic> This data declaration looks a lot like a BNF grammar description. http://lpaste.net/357621
20:23:44 <c_wraith> koz_: there's https://hackage.haskell.org/package/contravariant-1.4/docs/Data-Functor-Contravariant-Divisible.html but that's probably not what you mean
20:26:10 <erisco> koz_, well, you have copure :: f a -> a  and  cozip :: f (a, b) -> Either (f a) (f b)
20:27:17 <erisco> did I do that right? uncertified category theorist here
20:27:45 <c_wraith> No, that's not right
20:28:30 <c_wraith> cozip is not the reverse of zip :: (f a, f b) -> f (a, b)
20:28:35 <iqubic> :t evaluate
20:28:37 <lambdabot> a -> IO a
20:28:42 <erisco> f (Either a b) -> Either (f a) (f b)  ?
20:29:28 <erisco> that seems more sensible, anyways
20:29:57 <iqubic> I can actually right the implementation of that right now.
20:30:13 <c_wraith> iqubic: there are several wrong ways to write evaluate
20:30:28 <c_wraith> iqubic: the documentation actually tells you what the right way is, because there are *so many* wrong ways
20:31:01 <monochrom> IIRC it also gives an example of a wrong way.
20:31:08 <c_wraith> it does
20:31:31 <erisco> nonempty lists are coapplicative, if that definition is right
20:31:44 <erisco> not sure how the laws get all rearranged... will let someone else figure that out :)
20:31:44 <iqubic> c_wraith: I was refering to erisco's thing: f (Either a b) -> Either (f a) (f b)
20:31:52 <c_wraith> iqubic: oh. :)
20:31:58 <erisco> well you can't implement that... it is just a type
20:32:10 <erisco> you can implement it for a specific f, such as nonempty lists
20:36:07 <erisco> c_wraith, do you actually know the answer to this or just enough to know my guess was wrong?
20:36:30 <erisco> I don't actually know the mechanisms behind it, so I am just flipping arguments and taking duals at a whim :P
20:36:55 <erisco> maybe it should just be  f (a, b) -> (f a, f b)  but I don't know
20:37:12 <erisco> is cozip supposed to be an inverse of zip?
20:37:13 <c_wraith> I think that's what it has to be to match the pattern set by comonad
20:37:16 <mniip> can you even write evaluate without going unboxed
20:37:29 <mniip> oh, maybe you can
20:37:31 <c_wraith> mniip: sure.  use return and seq
20:38:12 <mniip> \x -> return x >>= \x -> x `seq` return x
20:38:33 <c_wraith> ack, the shadowing broke my brain
20:38:53 <mniip> something like this should produce an IO action without evaluating x
20:39:26 <erisco> ugh, not my only weakness! shadowed variables! noooo
20:40:26 * hackagebot hw-rankselect-base 0.2.0.1 – Rank-select base – https://hackage.haskell.org/package/hw-rankselect-base
20:42:21 <iqubic> mniip: can you write that without shadowing.
20:42:50 <c_wraith> erisco: oh!  https://hackage.haskell.org/package/comonad-5.0.2/docs/Control-Comonad.html#t:ComonadApply
20:43:18 <mniip> iqubic, you can alpha-rename it yourself
20:44:18 <c_wraith> erisco: that's interesting in that it's a subclass of Comonad, not a superclass
20:44:30 <koz_> erisco: copure is extract.
20:44:36 <erisco> does the hierarchy flip too? lol
20:44:40 <koz_> The other one - why is it Either?
20:45:03 <iqubic> @source evaluate
20:45:03 <lambdabot> Unknown command, try @list
20:45:10 <iqubic> @src evaluate
20:45:10 <lambdabot> Source not found. My pet ferret can type better than you!
20:45:24 <erisco> koz_, because (,) is product and coproduct is Either, but I don't know how to properly derive the "co" of something, especially in Haskell
20:45:53 <koz_> erisco: But where does (,) come in to splat? it's signature is f (a -> b) -> f a -> f b.
20:46:10 <c_wraith> erisco: well, first you start by deciding where the arrows are by drawing a picture.  Then you reverse the arrows. :)
20:46:17 <erisco> koz_, another way to define Applicative is with pure and zip :: (f a, f b) -> f (a, b)
20:46:24 <koz_> erisco: Ah, I see.
20:47:05 <koz_> So cozip would be f (Either a b) -> Either (f a) (f b) ?
20:47:10 <erisco> c_wraith, we'll have to ask edwardk when he is on
20:47:21 <erisco> koz_, that is just my guess, I don't know
20:47:31 <erisco> there is some way you get to Haskell stuff from category theory
20:47:33 <koz_> I'd be curious what its laws would be as well.
20:47:35 <erisco> Hask category something something
20:47:48 <erisco> and unless you know what that stuff is you won't be able to make the transformation properly
20:47:59 <koz_> I also never knew that Applicative has a definition based on pure and zip.
20:48:21 <c_wraith> koz_: to be fair, it's actually pure, fmap, and zip
20:48:30 <c_wraith> koz_: you need fmap to make it equivalent
20:48:46 <koz_> c_wraith: Yeah, fair enough. Like the monad with return and join.
20:48:52 <c_wraith> koz_: exactly
20:49:02 <koz_> c_wraith: That actually makes me see Applicative in a whole new light.
20:49:04 <koz_> Thanks!
20:49:14 <koz_> Well, c_wraith and erisco.
20:50:43 <koz_> Also, for comonads, I see wfix, cfix and kfix. What is the difference exactly?
20:50:50 <koz_> http://hackage.haskell.org/package/comonad-5.0.2/docs/Control-Comonad.html <-- here to be exact
20:50:58 <erisco> both  (f a, f b) -> f (a, b)  and  f (Either a b) -> Either (f a) (f b)  seem worth talking about
20:51:13 <erisco> sorry, I mean  f (a, b) -> (f a, f b)
20:51:29 <koz_> erisco: Agreed.
20:53:17 <erisco> well actually  f (a, b) -> (f a, f b)  is definable on Functors
20:53:36 <koz_> erisco: What do you mean?
20:53:52 <erisco> you just need Functor f to implement that
20:53:59 <orzo> (fmap fst x, fmap snd x)
20:54:12 <koz_> orzo: Yah, good point.
20:54:26 <koz_> But f (Either a b) -> Either (f a) (f b) you'd need more?
20:54:54 <iqubic> Alright I know see how parsec works
20:54:54 <erisco> yes, because there is no  Either a b -> a
20:55:10 <erisco> whereas there was a  (a, b) -> a
20:55:54 <koz_> erisco: Point taken.
20:56:15 <koz_> I'm gonna just try writing a couple of instances to see where the ideas lead me.
20:56:37 <iqubic> erisco: Am I right in saying that you can use haskell data to create ASTs like this: http://dpaste.com/3GE0FJ6
20:56:49 <erisco> Either (f a) (f b) -> f (Either a b)   is also definable on Functors
20:57:26 <erisco> iqubic, yes
20:57:55 <iqubic> erisco: Or rather that looks more like BNF notation
20:58:37 <iqubic> But you can parse a string like "123+234-23" into a TExpression.
20:59:10 <koz_> erisco: cozip should be named 'spread'.
20:59:34 <iqubic> And then you can use pattern matching to pick apart the AST to evaluate it if you'd like
20:59:54 <erisco> :t (zip, unzip)
20:59:56 <lambdabot> ([a1] -> [b1] -> [(a1, b1)], [(a, b)] -> ([a], [b]))
21:00:20 <erisco> oh that is for the case we already decided was uninteresting
21:00:27 <iqubic> Those aren't inverses of each other.
21:00:28 <erisco> hm, sure, call it spread :)
21:00:41 <koz_> erisco: so we have 'extract' and 'spread'.
21:04:00 <erisco> there is also  f (Either a b) -> (f a, f b)
21:04:24 <iqubic> Is it possible to write a function that takes a string like "( 1 + 3 * 4 ) + ( ( 3 + 1 ) * 7 )" and evaluates it according the order of operations?
21:04:39 <erisco> iqubic, yes
21:05:15 <koz_> erisco: But I don't think that makes it cozip.
21:05:17 <iqubic> Is it possible to write a function that takes a string like that a returns an RPN list of symbols, in the correct order?
21:05:41 <erisco> I am just thinking of possibly interesting types
21:05:43 <iqubic> So a function that parses and re-arrages the symbols
21:05:53 <koz_> erisco: Ah, I see.
21:05:55 <erisco> (f a, f b) -> f (Either a b)  seems odd
21:06:29 <ab9rf> erisco: yes, it does
21:06:34 <iqubic> Yeah I agree
21:06:46 <erisco> f (Either a b) -> Either (f a) (f b)  also seems odd... did you think of interesting instances koz_?
21:07:35 <erisco> iqubic, the impossible things here are just those which are either nonsense or incomputable
21:07:44 <koz_> erisco: NonEmpty and Stream.
21:07:54 <koz_> (which are both Comonads coincidentally)
21:08:59 <iqubic> So I can take that string and parse it, then evaluate it properly?
21:09:08 <erisco> what is the instance for either of those like, koz_?
21:09:30 <koz_> erisco: Let me sketch it.
21:09:32 <erisco> it seems for things like lists you could either collect all the a's or all the b's as sensible instances
21:09:45 <koz_> Lists can't be CoApps - extract is partial.
21:10:06 <erisco> I was just looking at spread alone
21:10:23 <erisco> but also I was saying NonEmpty and Stream are like lists
21:10:49 <erisco> iqubic, yes
21:11:47 <iqubic> How hard would it be?
21:12:12 <erisco> your hardest challenging will be figuring out how to do precedence properly
21:12:22 <erisco> but once you understand that it is easy
21:13:40 <iqubic> yeah. I have done this in Java, so I know the algorithm for precendece, but it might be hard to put into Haskell code.
21:14:22 <erisco> koz_, that is why I suggested  f (Either a b) -> (f a, f b)  because then we have a place for all the a's and b's we find
21:14:54 <koz_> erisco: Yeah, agreed, but I don't think that fits the bill for a cozip.
21:14:58 <erisco> though you might also think of it like Alternative for Either
21:15:00 <koz_> Assuming I understand the types correctly.
21:15:13 <iqubic> erisco: Look up shunting yard algorithm. That's how I'd deal with precedence.
21:15:13 <erisco> > Right "hello" <|> Left 0 <|> Right "world"
21:15:16 <lambdabot>  error:
21:15:16 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M123803793821...
21:15:16 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
21:15:32 <erisco> lambdabot says: Left 0
21:15:54 <erisco> so that sort of thing where if there is just one Left then you get all the a's, otherwise all the b's
21:16:02 <erisco> this is still an arbitrary instance but what can ya do
21:16:21 <erisco> iqubic, well, go for it
21:23:09 <koz_> erisco: http://lpaste.net/357622 <-- these, modulo syntax issues :P
21:27:33 <erisco> you'd have to know the laws to see if any Stream instance made sense
21:27:47 <erisco> even if it does not terminate there may be something law-abiding
21:29:44 <koz_> erisco: I was hoping for insights in this regard by writing these, but I have none.
21:30:31 <koz_> The problem is that the 'obvious' Stream definition diverges very easily - if you don't see a Right immediately, you basically have an impossible choice.
21:30:48 <koz_> s/Stream definition/Stream definition of spread/
21:36:49 <koz_> I think waiting around for edwardk may be the optimal solution. :P
21:37:16 <koz_> Problem Solving in Haskell: Wait for Edward Kmett to solve it better than you ever could. :P
21:39:12 <erisco> c_wraith already linked to edwardk's solution for coapplicative
21:39:33 <koz_> erisco: But I think c_wraith said that wasn't quite the same thing?
21:40:07 <erisco> it is this https://hackage.haskell.org/package/comonad-5.0.2/docs/Control-Comonad.html#t:ComonadApply
21:40:32 <koz_> Why is it that Comonad is weaker than ComonadApply, but Applicative is weaker than Monad?
21:54:32 <mniip> koz_, it is costronger
21:54:46 <koz_> mniip: I'm unsure if that's a joke or a serious answer.
21:54:51 <mniip> me neither
21:55:07 <koz_> mniip: Basically, I'll wait for Edward to chime in.
21:55:19 <dolio> Why is semigroup weaker than monoid, but semigroup + comonoid is stronger than comonoid?
22:01:43 <koz_> dolio: Wtf is a comonoid?
22:02:04 <dolio> It's the dual of a monoid.
22:02:35 <koz_> dolio: Is that an actual thing, or are you trying to make a point? I'm a bit confused.
22:03:07 <dolio> Yes, it's an actual thing, and I'm trying to make a point.
22:03:33 <koz_> dolio: That being that ComonadApply is comonad + applicative, and hence stronger?
22:03:36 <cocreature> I’m not sure I get the point. ComonadApply is not Applicative + Comonad
22:03:49 <koz_> And what cocreature said is why I'm confused.
22:03:55 <cocreature> hm maybe it is
22:04:01 <cocreature> well without the pure part
22:04:17 <cocreature> <@> looks like <*>
22:06:22 <dolio> The answer is that monad structure gives rise to applicative structure, and comonad structure doesn't.
22:06:59 <dolio> And requiring two structures is 'stronger' when one of them doesn't imply the other.
22:07:13 <koz_> Ah, I see.
22:08:18 <koz_> I guess my question was 'is there something comonad implies that's stronger than a functor, similar to how monad implies applicative?'.
22:08:25 <koz_> (well, my original question)
22:11:06 <mniip> there's contravariant day convolution
22:11:14 <mniip> if it makes a comonoidal category
22:11:26 <mniip> then what you get would be the dual of applicative
22:11:33 <koz_> mniip: Do you have a link to some Haskell or an explanation?
22:11:34 <mniip> but I have no idea how it would relate to comonads
22:11:36 <koz_> I'd love to read it.
22:12:16 <dolio> Comonads aren't contravariant, though.
22:12:26 <mniip> hm true
22:13:10 <cocreature> are contramonads a thing?
22:13:34 <mniip> I am guessing contravariant day convolution *does* give rise to a monoidal category
22:13:38 <dolio> Anyhow, you can dualize certain things, but they don't work out exactly like Applicative.
22:13:44 <mniip> but it's a contravariant endofunctor category
22:14:32 <dolio> Like, there's no dual of exponentials available so `f (a -> b) -> (f a -> f b)` doesn't obviously dualize.
22:14:40 <koz_> dolio: Yeah, I see that now. I'm just curious if anything liek what I described exists.
22:14:52 <koz_> If not, then that's OK. I'm just curious.
22:15:29 <mniip> by the looks of it,
22:15:30 <dolio> If you instead talk about `unit :: () -> f ()` and `pair :: (f a, f b) -> f (a, b)` ...
22:16:21 <dolio> Then you can ask for `counit :: f Void -> Void` and `sum :: f (Either a b) -> Either (f a) (f b)`
22:16:30 <dolio> Comonads have counit, obviously.
22:16:46 <koz_> dolio: Yeah - that's extract right?
22:16:54 <dolio> But you can't go back from counit to extract nicely in Haskell.
22:17:00 <mniip> the comonoid would look like 'f a -> a' and 'f a -> (forall b c. f b -> f c -> (a -> (b, c)) -> r) -> r'
22:17:08 <mniip> and here's your coapplicative
22:18:08 <mniip> now
22:18:13 <mniip> I have no idea what this means
22:18:34 <mniip> no wait hold on a sec
22:18:40 <dolio> Also I don't know if comonads automatically get you sum off hand.
22:18:50 <mniip> what is the identity of the contravariant day convolution?
22:18:58 <mniip> can't be Identity as it's not contravariant
22:19:19 <mniip> Proxy!
22:19:27 <mniip> 'f a -> Proxy a' is the co-pure
22:19:33 <mniip> which is not useful at all I guess
22:20:43 <koz_> mniip: Isn't 'Proxy a' just a type marker?
22:20:53 <koz_> So 'f a -> Proxy a' is 'tell me your type'?
22:20:57 <mniip> in haskell yes
22:21:05 <mniip> in category theory it's a constant functor
22:21:24 <dolio> It's like f a -> ()
22:21:31 <koz_> Ah, I see.
22:22:03 <koz_> That second thing looks terrifying. The 'f a -> (forall b c. ...' I mean.
22:22:39 <dolio> Anyhow, unit of day convolution is always the same.
22:22:46 <mniip> no?
22:22:48 <dolio> It's y(I).
22:22:52 <mniip> covariant unit is Identity
22:22:57 <mniip> contravariant is Proxy
22:24:58 <koz_> mniip: Could you link me to something about day (Day?) convolution? I'd like to investigate it a bit.
22:25:02 <dolio> Where y is the enriched Yoneda embedding, and I is the unit of the source category.
22:27:10 <iqubic> What the heck even is Day convolution?
22:27:23 <koz_> iqubic: Something I'm trying to understand too.
22:28:54 <dolio> https://ncatlab.org/nlab/show/Day+convolution
22:29:01 <dolio> You can try to read that.
22:29:14 <koz_> I guess it's hardcore category theory?
22:29:59 <ab9rf> what unit is core hardness measured in?
22:30:32 <MarcelineVQ> rockwell
22:30:58 <dolio> The things in category theory that specialize to Applicative are called (closed) monoidal functors.
22:31:27 <dolio> The category of monoidal functors is itself a monoidal category with day convolution as the tensor product.
22:31:27 <koz_> dolio: I remember from the Typeclassopedia that Applicatives are lax monoidal functors.
22:31:54 <koz_> dolio: Ah, I see.
22:31:54 <dolio> Oh, sorry.
22:32:11 <dolio> The category of _functors_ between certain monoidal categories is monoidal.
22:32:24 <dolio> And monoidal functors are monoids in that category.
22:36:26 <ab9rf> for some reason, talking about monoids makes me hungry
22:38:32 <dolio> The monoid structure on f gives you something that looks like, for covariant things, (I -> a) -> f a.
22:38:40 <dolio> And the other thing it gives you looks like:
22:38:43 <dolio> :t liftA2
22:38:45 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
22:39:14 <dolio> Except with more currying, and more abstract tuples.
22:40:29 <ab9rf> mmm, curried monoid. breakfast of champions.
22:40:52 <dolio> And Day convolution is like what you get if you package all the arguments to that into a single thing parameterized by f and c.
22:51:22 <mniip> the way I learned is that monads are monoids in the endofunctor monoidal category under composition
22:51:35 <mniip> and applicatives are monoids in the endofunctor monoidal category under day convolution
22:52:07 <dolio> Yeah.
22:52:22 <mniip> so like
22:52:32 <dolio> In the case of Haskell, I = (), and the tensor product is pairs.
22:52:46 <dolio> And (() -> a) is Identity a.
22:52:49 <mniip> f is a monad if you can construct morphisms I -> f and f (x) f -> f that satisfy the monoid laws
22:53:17 <mniip> where (x) is the composition and the -> morphisms (in End(Hask)) are obviously natural transformations
22:53:41 <mniip> dolio, I don't think the underlying category needs to be monoidal?
22:53:53 <mniip> you're interested in just the monoidal structure of the endofunctor
22:53:53 <mniip> s
22:54:09 <dolio> Day convolution requires monoidal structure.
22:54:39 <mniip> oh yes
22:54:41 <mniip> that one does
22:55:06 <mniip> it's essentially an end of a tensor product yes
22:55:14 <mniip> internal homs also, no?
22:55:31 <dolio> The general setting is that you have a monoidal category V with some extra structure, and a monoidal category C enriched in V.
22:55:50 <dolio> Then you can talk about Day convolution of functors from C to V.
22:56:16 <dolio> And it makes that category monoidal, and the monoids are monoidal functors.
22:56:23 <dolio> From C to V.
22:56:31 <mniip> hmm
22:56:39 <dolio> And When C = V = Hask, you get Applicative.
22:56:56 <mniip> not entirely sure how that works
22:57:09 <mniip> is day not an endobifunctor?
22:57:25 <mniip> or rather, is day f g not an endofunctor
22:57:31 <mniip> oh
22:57:33 <mniip> ohhh
22:57:34 <dolio> No.
22:57:34 <mniip> right
22:57:40 <dolio> It's also C to V.
22:57:55 <dolio> And y(I) is C to V.
22:58:35 <dolio> Or, I guess y would be the C^op case typically.
22:59:04 <dolio> But whatever, you partially apply the hom on the appropriate side.
22:59:04 <mniip> what's y again
22:59:12 <dolio> Yoneda embedding.
22:59:42 <dolio> C(I, -) or C(-, I), depending on which you want.
23:00:00 <dolio> The first is [C,V] and the second is [C^op,V].
23:03:40 <mniip> does *that* require internal homs
23:03:59 <dolio> No.
23:04:38 <dolio> C(I,-) is using the external hom of C in V.
23:05:10 <dolio> And Day convolution also uses the external hom and tensor product in V.
23:05:30 <mniip> ah
