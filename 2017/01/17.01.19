00:08:00 <shayan_> Can someone please help
00:08:12 <shayan_> I don’t understand what this means http://imgur.com/a/uOm5u
00:08:23 <shayan_> I’m in my-project directory. I have successfully installed snap init, here. Now does it want me to run “cabal install” and then “myproject -p 8000”?
00:08:36 <shayan_> This guide was posted in http://snapframework.com/docs/quickstart
00:08:50 <kadoban> shayan_: Seems like it, yes.
00:09:39 <lonokhov> shayan_: you can run `cabal build` and `./dist/build/myproject/myproject -p 8000` instead of polluting your $HOME/.cabal/bin
00:10:12 <lonokhov> shayan_: also you should use either cabal sandboxes or stack (or experiment with new-build if you feel adventurous)
00:10:59 <shayan_> lonokhov: When I try to run ./dist/build/myproject/myproject -p 8000, I get the following message in the terminal: Shayans-MacBook-Pro:tweet shayanbozorgmanesh$ ./dist/build/myproject/myproject -p 8000
00:10:59 <shayan_> -bash: ./dist/build/myproject/myproject: No such file or directory
00:11:23 <shayan_> lonokhov:  I don’t know how to use those, I am only following a guide :S
00:11:36 <lonokhov> shayan_: what the name you have given to your package?
00:12:10 <shayan_> lonokhov: Oh gosh — I should have read your message better.
00:12:21 <shayan_> it’s actually “tweet” instead of myproject
00:12:22 <shayan_> xD
00:13:58 <shayan_> lonokhov: still, when I type ./dist/build/tweet/tweet -p 8000, I get the following message: -bash: ./dist/build/tweet/tweet: No such file or directory
00:16:47 <lonokhov> shayan_: well, do you have that directory?
00:17:06 <lonokhov> shayan_: what happens if you run `cabal build`?
00:18:08 <lpaste> shayan_ pasted “cabal build” at http://lpaste.net/351416
00:20:04 <lonokhov> heh, I guess snap init has bitrotted a bit
00:21:53 <lonokhov> shayan_: can you paste contents of your tweet.cabal? it'll need some edits. 
00:22:04 <onmyway133> Hi
00:22:48 <shayan_> lonokhov: should i go into tweet.cabal and do ls?
00:23:31 <lonokhov> shayan_: tweet.cabal is a file, it describes how to build your project. Lists dependencies and such
00:23:55 <shayan_> lonokhov: understood
00:24:31 <lpaste> shayan_ pasted “tweet.cabal” at http://lpaste.net/351418
00:24:59 <lonokhov> shayan_: it's not the whole file
00:27:32 <shayan_> Sorry about that
00:27:33 <lpaste> shayan_ pasted “tweet.cabal” at http://lpaste.net/351419
00:38:26 <shayan_> lonokhov: not sure how to get the whole file copied :S
00:43:13 <shayan_> nice
00:43:16 <shayan_> i can only type
00:43:21 <shayan_> ppl on the floor sleeping
00:45:41 <lpaste> shayan_ pasted “tweet.cabal” at http://lpaste.net/351420
00:45:45 <shayan_> lonokhov: there it is the full one
01:13:16 <tsahyt> http://lpaste.net/3311254721032880128
01:13:24 <tsahyt> why does this never return a single element in ghci?
01:13:53 <tsahyt> of course I could use getRandoms in this particular case, but my actual use case is a bit more involved, using getSample from the distribution package etc
01:14:14 <tazjin> Are there any good resources describing GHC's type inference engine & performance implications of choices made in it?
01:14:20 <tazjin> failing at googling here :) 
01:17:22 <ertes> tsahyt: which 'm' are you using?
01:17:33 <tsahyt> ertes: in ghci it's IO I think
01:18:06 <tsahyt> but I'd really like this to work regardless of concrete monad. I want it to just give me an infinite stream that I can take elements from to my liking.
01:18:27 <ertes> tsahyt: IO is state-strict, so it's waiting for the recursive 'foo' to finish
01:18:40 <ertes> tsahyt: you need a lazy state monad
01:19:38 <ertes> > evalState (let go = liftA2 (:) (state (randomR (0, 9 :: Int))) go in go) (mkStdGen 0)
01:19:41 <lambdabot>  [3,3,3,8,0,7,1,1,1,6,3,0,2,0,4,5,0,1,5,2,2,6,0,5,6,9,0,9,1,0,7,2,3,4,0,0,0,8...
01:20:18 <ertes> tsahyt: Control.Monad.Random.Lazy should work, because it's effectively just StateT in disguise
01:20:26 <tsahyt> is there even any way to build an infinite stream in IO then?
01:20:37 <ertes> tsahyt: yes: unsafeInterleaveIO
01:20:47 <tsahyt> but that *only* works in IO again.
01:20:59 <tsahyt> so in effect I'd have to change the type signature
01:21:08 <ertes> nope, 'foo' is fine
01:21:11 <tsahyt> from MonadRandom m => ... -> m [a] to something concrete
01:21:21 <ertes> you just need to instantiate 'm' at a different monad
01:22:03 <tsahyt> hmm but say someone else uses this function, then it's kinda unsafe, isn't it?
01:22:16 <tsahyt> since it's effectively bottom in IO because it never terminates
01:23:29 <ertes> depending on 'm' it may diverge, yeah
01:23:58 <tsahyt> evalRandIO foo works
01:24:13 <ertes> to really solve this in general you need a coroutine-based approach like free/machines/pipes/…
01:24:33 <tsahyt> meh, not worth it for a toy implementation of markov chains
01:24:47 <ertes> why even MonadRandom?
01:24:53 <tsahyt> because it's very nice to work with
01:25:21 <tsahyt> and the distribution package that I use as well integrates nicely with it
01:26:07 <ertes> i find it easier to just fire up a StateT when necessary, although these days i usually go with mwc-random anyway
01:29:15 <tsahyt> ertes: I like how MonadRandom m => m T basically states that the T is a random variable.
01:29:58 <tsahyt> it makes it very easy to thread those things around etc, pass them as arguments, and so on. Yeah you can do the same with an ad-hoc StateT of course, but it's nice to have a package for that ready to go
01:30:47 <tsahyt> I've never looked enough into mwc-random to have an opinion on it
01:39:24 <maerwald> does anyone have a nice idea for an algorithm that is easy and can be used to show counter-intuitive hacking (e.g. improving performance, time complexity)? Matrix exponentiation in fibonacci is too much of a jump imo and you cannot expect anyone to get there by himself
01:41:01 <niklasb> maerwald: binary search?
01:41:53 <niklasb> if that by itself is already established, I think there are a lot of cases where it is unintuitive to think about binary search, but once you know it's a solution, it becomes really obvious
01:42:32 <maerwald> I don't see how binary search involves hacking
01:42:46 <niklasb> ok what do you mean by a hack :D
01:43:04 <tsahyt> I think the most "how the hell did they come up with that" moment I had when studying algorithm's was strassen's
01:43:26 <maerwald> abusing properties of the underlying problem to solve it, which isn't part of the classical solution
01:43:47 <xpika> Is there a way to force ghc to use the only typeclass instance it finds ?
01:44:00 <niklasb> I see, maerwald 
01:44:31 <maerwald> there was a haskell implementation of an algorithm (which I forgot), which did this, computing something in the "wrong" order which was very odd and relied on very specific properties
01:44:37 <tsahyt> maerwald: well with binary search you're using the property that the input is sorted, which isn't use in the classical (sequential) version
01:44:38 <maerwald> ofc when you look for something, you don't find it
01:44:49 <Rodenbach> In languages of the Lisp family there are objects called Keywords. Is it possible to introduce something similar to Haskell?
01:44:58 <niklasb> tsahyt: or in the general setting, the monotonicity of a function
01:45:04 <niklasb> or binary predicate
01:45:36 <niklasb> maerwald: sounds like every non-trivial DP
01:45:47 <jchia> How can I tell whether Data.Vector.modify will perform in-place modification? The documentation says "The operation will be performed in place if it is safe to do so ..". What does it mean by "safe"?
01:45:56 <niklasb> kunuth's trick is also really weird
01:46:07 <tsahyt> jchia: it's unsafe when the original value is used afterwards
01:46:38 <tsahyt> so when you don't use it anywhere afterwards and the compiler can somehow tell that, it will be in-place I suppose
01:47:20 <jchia> tsahyt: What does "afterwards" mean, since Haskell is lazy?
01:47:31 <niklasb> or meldable heaps, or fenwick trees, or ...
01:48:07 <jchia> tsahyt: I mean some value I expressed early may not be evaluated yet, if Haskell is being lazy. So if it's evaluated later, does it count as "afterwards"?
01:49:03 <tsahyt> hmm, well the problem with reasoning about this is that there's not really a concept of a reference. the part where you do modify might actually be in-place, on a copy created at some other point, etc. 
01:49:55 <tsahyt> but there are of course cases where it's pretty clear that it should be safe, say when you never hold on to the input of modify in a binding or elsewhere
01:51:29 <ocramz> hullo!
01:52:10 <magthe> ocramz: hi! :)
01:53:15 <tsahyt> jchia: you could always look at the core output for specific cases of course
01:55:50 <ocramz> Hej magthe :)
01:57:51 <lonokhov> shans_: 
01:58:07 <lonokhov> sorry
01:58:15 * lonokhov has fat fingers
02:00:07 <jchia> tsahyt: Thanks
02:15:06 <ertes> maerwald: a fast "next prime" function
02:15:57 <ertes> naive approach: find isPrime [x0..]
02:16:03 <ertes> fast approach: sieving
02:17:01 <Rembane> Is it a finite number of primes?
02:17:13 <Rembane> Or the first prime greater than X?
02:17:22 <niklasb> ertes: ahm, but isn't the former faster if isPrime is fast?
02:17:31 <ertes> nextPrime :: Integer -> Integer  -- nextPrime x >= x
02:17:37 <Rembane> Ah.
02:17:38 <niklasb> or what kind of sieve do you have in mind?
02:17:49 <quchen> Does anyone know what the »prediction context« of a Markov chain is? markov-chain uses this, but does not document its effect.
02:18:10 <ertes> niklasb: the latter is orders of magnitude faster, because it can use a compact bit array to eliminate most non-primes quickly
02:18:54 <ertes> quchen: the prefix sequence length
02:19:02 <quchen> ertes: ..?
02:19:22 <niklasb> ertes: but the expected number of isPrime calls is in O(log n) no? so the "naive" miller rabin would be O(log^2 n) or smth, so I don't really see how you can be orders of magnitude faster
02:19:35 <maerwald> ertes: that's interesting, but doesn't look like something one could have people figure out by themselves with a hint or two
02:19:44 <ertes> quchen: let that number be 3, then it calculates conditional probabilities like this:  given "abc", what's the probability that the next letter is 'd'?
02:19:49 <maerwald> unless they are mathematicians maybe
02:20:34 <quchen> ertes: Oh, so it’s a Markov chain from tuples-of-predecessors to successors, not just from one predecessor to successor
02:20:53 <ertes> niklasb: a good isPrime function does trial division first, because it can't access a sieve…  the sieving step eliminates all trial divisions
02:21:00 <ertes> niklasb: it reduces them to bit operations
02:21:04 <tsahyt> yes, it can be a markov chain with order > 1
02:21:18 <ertes> quchen: yeah
02:21:21 <tsahyt> coincidentally, that's what I've been spending my morning on
02:21:31 <ertes> quchen: and yeah, the technical term is "order" =)
02:21:33 <tsahyt> trying to fix pull the order of the chain into the type level
02:21:39 <tsahyt> s/fix pull/pull
02:21:42 <quchen> ertes: Funny, because that’s precisely what I wanted and considered adding myself :-)
02:22:19 <ertes> quchen: note that the size of your training data needs to grow exponentially with the order
02:22:24 <tsahyt> quchen, ertes: because it suddenly became relevant, http://lpaste.net/9138343843446390784
02:22:57 <tsahyt> this is far from tested or finished of course, but maybe someone can get something out of it in the context of this discussion here
02:22:58 <quchen> ertes: Sure
02:23:24 <tsahyt> quchen: the prediction context would be what I call a history then
02:24:08 <ertes> maerwald: i think most PE problems would be appropriate, even the very first one
02:24:31 <ertes> all of them have a slow brute-forcy way and a clever way using domain-specific knowledge
02:26:20 <ertes> maerwald: alternatively pick any of the easier mysterytwister crypto challenges…  most of them are about avoiding brute-force attacks
02:27:12 <ertes> this one is my favourite, but it requires some number theory knowledge to solve: https://www.mysterytwisterc3.org/en/challenges/level-ii/smartcard-rsa
02:37:44 <f-a> Hello, I am having trouble building zip-archive with cabal new-build http://pastebin.com/48SXZGei
02:38:23 <f-a> it seems to me "base" is already inside the .cabal file so I don't know what to tweak
02:41:05 <hvr> f-a: what cabal version did you use? this seems like a bug that's been already fixed in cabal HEAD
02:41:38 <f-a> hvr: cabal-install version 1.24.0.2
02:41:38 <f-a> compiled using version 1.24.2.0 of the Cabal library
02:45:10 <hvr> f-a: yep, this an old 1.24 bug that's was fixed last year, but not backported
02:45:24 <hvr> lemme workaround it
02:47:26 <hvr> f-a: if you `cabal get zip-archive` in about 5 minutes it should just work
02:48:22 <hvr> (after having done a 'cabal update' of course)
02:48:31 <f-a> thanks hvr , I will report the outcome!
02:49:16 <hvr> f-a: what I did was basically give (buggy) cabal 1.24 a  hint via `setup-depends: base, Cabal`
02:49:40 <hvr> zip-archive has a rather trivial Setup.hs script 
02:50:31 <f-a> hvr, the guardian angel of revisions
02:51:17 <f-a> hvr: that impacted some other packages (off the top of my head: darcs, yesod) so tres bien that it was fixed
02:51:50 <hvr> f-a: fwiw, if you use new-build, you should really use cabal HEAD until 2.0 is released
02:51:59 <hvr> there's been a lot of fixes to the new-build codepaths
02:52:03 <hvr> and improvements
02:52:30 <f-a> 1ml€ question, is there an expected release date for 2.0?
02:53:03 <f-a> (building now zip-archive, it works)
02:58:06 <tsahyt> can anyone think of some examples where having length indexed vectors is very useful? I'd like to play around with them some more but I'm already running out of ideas.
02:58:36 <tsahyt> specifically I'm looking at the vector-sized package
02:58:42 <merijn> tsahyt: Can statically prevent out of bounds issues
02:59:20 <merijn> tsahyt: For example, Tim Sweeney (from Epic Games fame) claims a significant fraction of their bugs could be eliminated by dependent vectors
02:59:42 <tsahyt> merijn: I mean some larger applications in which they can be part. e.g. I just implemented markov chains of statically known order, and used them to make sure that some invariants in my data structures always hold.
03:00:17 <merijn> tsahyt: Well, so the example from above would be "games" :p
03:00:32 <tsahyt> merijn: well that's a bit more than I can fit into an afternoon I think :p
03:01:04 <merijn> ;)
03:01:22 <merijn> tsahyt: Who knows! You could write Haskell bindings for Unreal 4!
03:01:32 <merijn> That way I can use haskell to play with it... :p
03:01:35 <tsahyt> on a related note, the vector-sized package seems pretty awesome really. it's really just a relatively thin wrapper around ordinary vectors with better types on top, so it should perform really well too. I haven't benchmarked it yet though.
03:02:14 <tsahyt> if I had the time that'd be worth considering. but then again I already tore out too much hair over my last C bindings, having to ensure things that I would take for granted if it was haskell code to begin with
03:07:07 <vaibhavsagar> I'm having a bit of a rough time with cabal, nix, and shadowed dependencies. Can someone help me?
03:14:12 <ocramz> Is there a way in QuickCheck to use a custom pretty-printing action in case of failure, rather than the printing the Show instance?
03:14:27 <ocramz> *rather than printing*
04:39:41 <somewone> is there a way to prebuild all LTS x.x stackage packages ?
04:42:04 <somewone> i'd like to prepare a docker image that prebuilds the packages for an ARM environment
04:42:34 <Axman6> somewone: I think there are docker images which come with all LTS packages prinstalled, but I'd be surprised if there's anything for ARM
04:43:09 <somewone> yeah I read about that, but like you said i fear there is nothing for ARM
04:43:53 <somewone> maybe I can find the Dockerfiles for those and figure out the process
04:44:09 <Axman6> I think your best bet would be to use something like qemu to build on a machine which can emulate faster than the actual hardware
04:44:13 <Axman6> and with more resources
04:44:27 <Axman6> does docker even work on ARM
04:44:29 <Axman6> ?
04:44:48 <somewone> that's what im doing right now, but it still takes ~ 1h 20min for the project to build, since i have to build all dependendies as well
04:45:14 <Axman6> but they should be cached no?
04:45:18 <somewone> it does, but i'm cross compiling since running on arm does take even longer, I think around 7h if I remember correctly
04:46:21 <somewone> I tried to cache them using a gitlab cache but somehow I didn't succeed 
04:46:55 <somewone> I guess that's the easier way to take though
04:47:58 <Axman6> are you cachine ~/.stack, ~/.ghc and ~/.cabal? that's what the recommended Travis setup does
04:48:35 <Axman6> caching*
04:48:42 <Axman6> see https://github.com/data61/foldl-statistics/blob/master/.travis.yml
04:49:30 <tabaqui1> what's the difference between Int and Int32?
04:49:53 <tabaqui1> Int may be changed in the future?
04:50:14 <merijn> tabaqui1: Int is unspecified size
04:50:26 <merijn> tabaqui1: Or rather, the report specifies int is *at least* 27 bits
04:50:27 <somewone> awesome thanks, so far I've cached only ~/.stack
04:50:45 <Axman6> isn't it at least 30 bits?
04:50:48 <tabaqui1> merijn: *32 bits
04:50:52 <merijn> tabaqui1: In practice the real size is implementation defined (64 bit for 64bit GHC and 32 bit GHC)
04:50:54 <tabaqui1> *30
04:50:56 <tabaqui1> right
04:51:05 <merijn> Axman6: Could be?
04:51:10 <Axman6> tabaqui1: it's not 32, because for a long time the two low order bits were used for tagging
04:51:25 <tabaqui1> ok, thanks
04:51:53 <merijn> 29bit
04:51:53 <Axman6> i'm not sure it's a rule, but Int roughly equates to int in C
04:52:09 <merijn> Axman6: It's definitely not a rule
04:52:17 <merijn> Axman6: And cost me 3 weeks of debugging to fix a crash on OSX
04:52:24 <Axman6> heh
04:52:38 <hpc> C's int barely knows what it is anyway
04:52:39 <Axman6> just use Int64 for everything
04:52:42 <Axman6> yeah
04:52:44 <merijn> Axman6: -2^29 - (2^29 - 1) is the minimal range for Int
04:53:06 <Axman6> oh yeah, it was 3 bits not 2
04:53:14 <merijn> Axman6, hpc: 64 bit GHC uses Int == 64bit, but 64bit C on OSX has 32bit int
04:53:25 <hpc> classic
04:53:43 <merijn> Axman6: It's not that they were used for tagging as much that they reserved the rights for implementors to actually use tagging
04:54:00 <hpc> i don't get to say this very often, so i might as well take the opportunity
04:54:03 <dramforever> Quite a few 64bit C... 'stuffs' have 32bit int IIRC
04:54:07 <hpc> windows has consistent behavior for that
04:54:18 <Axman6> so macOS isn't the only place where things can net nasty: https://blogs.oracle.com/nike/entry/ilp64_lp64_llp64
04:54:21 <merijn> hpc: Can't really blame the OS for that, imo
04:55:44 <merijn> hpc: There's a reasonably sane reason for it, in that the OSX userland went 64bit years before the kernel did, so if you want the 64bit userland to sanely communicate with a 32bit kernel you want your ABI to standardise on sizes that can be used directly for cross-kernel communication
04:56:14 <hpc> that only raises more questions
04:56:55 <merijn> hpc: Why? Why risk the breakage of moving to a kernel that's 64bit with all the potential breakage if you can just run 64bit applications (all anyone really cares about anyway) on a 32bit kernel?
04:57:10 <merijn> Since your 32bit kernels works and is battle-tested
04:57:37 <hpc> now you have a more complicated boundary between kernelspace and userspace
04:58:01 <merijn> hpc: In what way?
04:58:11 <hpc> and the OSX kernel is basically BSD
04:58:17 <merijn> hpc: It's really not
04:58:21 <merijn> hpc: The userland is BSD
04:58:25 <SexHendrix> userland is bsd
04:58:31 <SexHendrix> kernel is custom
04:58:37 <merijn> hpc: People who claim the kernel is need to read up on their history
04:58:37 <hpc> ah
04:58:54 <merijn> OSX is based on the mach microkernel
04:59:33 <SexHendrix> macos/darwin kernel is based on gnu mach (!)
04:59:51 <merijn> Pretty sure OSX isn't based on GNU mach
05:00:05 <SexHendrix> its called xnu
05:00:21 <merijn> Mach is originally from Carnegie Mellon
05:00:37 <merijn> GNU Hurd is also a mach derivative
05:01:03 <merijn> I'm pretty sure Darwin uses a different mach derivative from Apple
05:01:46 <merijn> XNU isn't related to GNU
05:01:59 <merijn> https://en.wikipedia.org/wiki/XNU
05:02:57 <SexHendrix> right you are
05:03:17 <SexHendrix> poor form of them to call it "xnu is not unix" :\
05:03:52 <SexHendrix> will be interesting in 20-50 years time when gnu finally release a stable version of hurd
05:04:19 <merijn> And now back to debugging an obscure issue with xml-conduit >.<
05:04:30 <merijn> This is combining my least favourites things in the world of programming...
05:04:41 <merijn> XML, debugging parsers and odd behaviour...
05:04:56 <hpc> all it needs now is that python statistics library you were using a few months ago
05:05:07 <merijn> hpc: Am still using, sadly
05:05:12 <hpc> aaaaaaaaaw yeah
05:05:17 <hpc> no wait, the other thing
05:05:17 <merijn> hpc: But I managed to reverse engineer the bollocks I need from it
05:05:34 <merijn> hpc: This is hobby stuff while I wait for my experiments to finish :p
05:06:25 <ertes> merijn: you can run 64-bit code on 32 bit natively?  with 64 bit addressing, 64 bit MMU and everything?
05:06:38 <merijn> ertes: It was 64bit hardware
05:06:52 <merijn> ertes: Obviously :) Can't run 64bit code on 32bit machines
05:07:05 <ertes> sure, i mean on 64 bit arch with a 32 bit kernel
05:08:01 <ertes> at least on x86 IIRC you can operate 64 bit registers, but you couldn't easily take advantage of a 64 bit address space
05:08:03 <merijn> ertes: you need some glue code, probably, but I don't see any fundamental problems
05:08:24 <merijn> Mostly, as you said, setting up memory mapping for processes
05:08:42 <ertes> also the instructions get longer, because there is a kind of "escape byte" for 64 bits, which means that the instruction cache has a harder time keeping things near the CPU
05:08:46 <merijn> But that's not particularly hard code and you only need to do it the hard way for 64bit processes
05:09:15 <merijn> ertes: Yes, many HPC applications actually have better performance using 32bit, rather than 64bit, contrary to popular believe
05:09:24 <hpc> me?
05:10:23 <joe9> Where can I get the slides of this presentation https://skillsmatter.com/skillscasts/6495-keynote-from-simon-peyton-jones
05:10:27 <niklasb> merijn: but the x86 instruction set is a subset of x86_64 no? so isn't that just a compiler issue? 
05:10:35 <joe9> I recall reading it somewhere but I cannot find it now.
05:10:38 <merijn> niklasb: No
05:10:53 <ertes> niklasb: only in your assembly language…  the opcode actually looks quite different
05:11:02 <merijn> niklasb: It's not a subset of x86_64 in any sensible way
05:11:22 <niklasb> but can I not just run x86 opcodes on an x86_64 processor
05:11:26 <merijn> x86_64 doesn't have segments, etc. and more processors
05:11:26 <ertes> niklasb: in other words your assembly language makes x86 appear to be a subset of x86_64 =)
05:11:34 <merijn> niklasb: You can, but not because it's a subset
05:11:50 <merijn> niklasb: The CPU has basically a hardware x86 emulator
05:12:05 <merijn> niklasb: Because nobody buys machines that aren't backwards compatible
05:12:07 <niklasb> ok I see
05:12:09 <ertes> i don't think you can…  IIRC the same opcodes actually refer to different register sizes depending on whether you're in protected or long mode
05:12:24 <ertes> that's why you need those prefix bytes i mentioned
05:12:31 <merijn> niklasb: You can basically (with ring0 access) change the mode it runs in
05:12:53 <merijn> I guess they still have "real" mode too (16bit)
05:12:58 <ertes> yeah, they do =)
05:12:59 <merijn> Not sure, though
05:13:07 <niklasb> of course, if you want to run your DOS applications
05:13:23 <ertes> the boot loader starts in real mode
05:13:31 <merijn> Hell, OSX had Rosetta for a while which let you run PowerPC on Intel
05:13:37 <niklasb> yeah I once had to reverse one of those ertes :/
05:13:37 <merijn> But that was software, afaik
05:13:40 <ertes> well, at least the BIOS boot loader
05:13:43 <niklasb> IDA was confuse
05:13:45 <niklasb> d
05:13:49 <ertes> UEFI might fix some of that
05:14:10 <hpc> i save all my DOS programs on a solid state drive
05:14:16 <hpc> no acronyms can chain me down!
05:14:43 <ertes> sometimes i miss the days of DOS programming in C++/assembly =)
05:15:08 <ertes> three LoC and you've got a graphics mode and a pointer to the video memory =)
05:15:14 <merijn> Anyway, back to haskell
05:15:34 <merijn> Is there a convenient way to step through library code without altering and recompiling it?
05:15:44 <merijn> I'm confused by wtf this code is doing
05:15:48 <hpc> gdb?
05:16:18 <hpc> i think for ghc to be able to do anything, it has to be compiled with debugging flags
05:16:29 <merijn> hpc: I don't expect gdb to be helpful for haskell code
05:16:34 <merijn> hpc: Sure, but I should have that
05:16:44 <merijn> I always set cabal to always build debug too
05:16:49 <niklasb> do they already generate dwarf? then it might be somewhat useful
05:17:12 <merijn> niklasb: GHC can generate dwarf, but I wanna step through code at a higher level than assembly >.<
05:17:35 <merijn> I wanna figure out why my middle parser magically seems to throw up on a tack that should be just fine...
05:17:44 <niklasb> cool, didn't even know that it possible
05:17:48 <hpc> merijn: i could never find a way to make runtime debugging more useful than just inserting print statements and doing static analysis in my head
05:17:55 <hpc> in any language
05:18:04 <merijn> I got pretty good with gdb for C/C++
05:18:22 <merijn> But still mostly did printf debugging
05:18:44 <merijn> hpc: Yeah, but the error (or at least my faulty assumption) seems to be "somewhere" inside conduit
05:18:57 <hpc> yeah, i think the closest i got was eclipse's java debugging, which was horridly slow and had obtuse keyboard shortcuts
05:19:01 <hpc> hmm
05:19:02 <merijn> hpc: So I'd be inserting prints in like 4 packages and recompiling all the time
05:19:19 <tabaqui1> why there is no "Countable" class in haskell?
05:19:21 <hpc> can you construct a smaller reproduction?
05:19:25 <tabaqui1> with length method
05:19:34 <merijn> hpc: It's already only like 5 lines
05:19:58 <tabaqui1> like lists, strings, maps, dicts, tuples...
05:20:08 <niklasb> tabaqui1: Foldable?
05:20:10 <Axman6> tabaqui1: what is the type of length?
05:20:14 <hpc> hmm
05:20:28 <Axman6> what unifies (Int,Bool,a) and [String]?
05:20:30 <tabaqui1> :t length :: t a -> Int
05:20:32 <lambdabot> error:
05:20:32 <lambdabot>     • Couldn't match kind ‘k1’ with ‘*’
05:20:32 <lambdabot>       ‘k1’ is a rigid type variable bound by
05:20:42 <Axman6> tabaqui1: that already exists
05:20:44 <tabaqui1> (,,) has length of 3
05:20:46 <Axman6> :t length
05:20:48 <lambdabot> Foldable t => t a -> Int
05:20:52 <tabaqui1> hmm,
05:21:00 <tabaqui1> then Data.Text is incomplete
05:21:04 <Axman6> (,,) has a length of 1 though
05:21:07 <niklasb> tabaqui1: it's not functor
05:21:22 <niklasb> i.e. it's not polymorpgic over a
05:21:25 <hpc> what is length in this context?
05:21:27 <tabaqui1> I mean, complete (,,) a b c has length of 3
05:21:29 <Axman6> (or, would if it had a Foldable isntance, can't remember if it does)
05:21:42 <ertes> tabaqui1: it depends on your definition of "length"
05:21:46 <ertes> > length (1,2,3)
05:21:50 <lambdabot>  error:
05:21:50 <lambdabot>      • No instance for (Foldable ((,,) t0 t1))
05:21:50 <lambdabot>          arising from a use of ‘length’
05:21:53 <ertes> what?
05:21:59 <ertes> > length ((1,2),3)
05:22:02 <lambdabot>  1
05:22:03 <Axman6> > length (True,False)
05:22:05 <lambdabot>  1
05:22:15 <ertes> seriously?  no instance for larger tuples?
05:22:19 <tabaqui1> ByteString isn't foldable
05:22:21 <Axman6> yeah :\
05:22:21 <hexagoxel> tabaqui1: what is the length of a one-tuple? always 1? :D
05:22:30 <tabaqui1> hexagoxel: of course
05:22:37 <hexagoxel> length ([1,2,3]) = 1 ?
05:22:43 <tabaqui1> yes
05:22:45 <Axman6> =)
05:22:49 <ertes> tabaqui1: anyway, there is mono-traversable, which attempts to provide a more generic 'length' among many other functions
05:22:54 <tabaqui1> err, 
05:22:59 <tabaqui1> ([1,2,3]) == [1,2,3]
05:23:01 <tabaqui1> >([1,2,3]) == [1,2,3]
05:23:07 <tabaqui1> > ([1,2,3]) == [1,2,3]
05:23:10 <lambdabot>  True
05:23:16 <ertes> tabaqui1: but unless you actually need to abstract over the type, i would just use T.length, B.length, etc.
05:23:22 <Axman6> tabaqui1: what you're asking for _seems_ simple, but in reality it isn't, without having essentially a class without laws. laws are what make classes useful
05:23:22 <tabaqui1> ok, one-tuple has no foldable instance
05:23:33 * hexagoxel feels bad for setting that trap
05:24:00 <Axman6> you basically end up with: class HasLength a where length :: a -> Int
05:24:17 <Axman6> and there's no useful laws that can be had there
05:24:21 <hexagoxel> but this still points to a valid issue, where constant-length results for tuples are inconsistent.
05:24:57 <Axman6> there's nothing I can really say that stops me making instance HasLength (a,b,c) where length _ = 0
05:25:27 <ertes> there are too many ways to interpret "length" for any one class to fit everybody's needs
05:25:57 <ertes> is length a fold?  is length a monoid morphism?  …?
05:26:09 <Axman6> the Foldable implementation is fairly sensible imo, it's at least consistent (thugh surprising in the case of tuples)
05:26:17 <tabaqui1> ertes: yes and no?
05:26:40 <ertes> tabaqui1: it depends who you ask and for what purpose
05:27:03 <ertes> class (Monoid a) => Length a where length :: a -> Sum Int
05:27:07 <ertes> this one has laws
05:27:25 <Axman6> also, what if we decided we actually wanted instance (HasLength a, HasLength b, HasLength c) => HasLength (a,b,c) where length (a,b,d) = length a + length b + length c
05:27:35 <ertes> length mempty = 0;  length (xs <> ys) = length xs <> length ys
05:28:10 <quchen> It’s a bit hard how »good« laws have to be in order to make a class useful. Default has a law that the default should not be bottom for inhabited types. OK, great, ummm
05:28:22 <quchen> (Does it even have that? Anyway, the point stands.)
05:28:32 <Axman6> well Default is basically lawless
05:29:02 <Axman6> just becaue there's a class doesn't mean it's well designed
05:29:55 <ertes> i don't consider laws to be the primary quality criterion…  IMO the most important ones are:  1. will you abstract over the class?  2. are there at least two instances?
05:30:07 <ertes> not every class represents some algebraic structure =)
05:30:33 <merijn> bleh, looks like an issue with a parser consuming too much, but fuck if I know why...
05:30:36 <ertes> think of ToHTML…  it's a useful class, because there are lots of instances and lots of ways to abstract over it
05:31:09 <ertes> Default on the other hand…  you never abstract over it, and for good reason:  "default value" doesn't really mean anything
05:31:31 <kuno_luno> Hey, fellow Haskellers!
05:31:36 <kuno_luno> What is the CPU overhead of turning on the profiler in Haskell? I want to have stack traces, but not if it means my program will be 15% slower.
05:31:41 <kuno_luno> Any ideas? :-)
05:34:22 <cocreature> kuno_luno: the last time I enabled profiling for a program it >2 times slower
05:34:31 <kuno_luno> Damn!
05:34:40 <ertes> is profiling necessary for stack traces?
05:35:01 <cocreature> depends on the kind of stacktraces you want
05:35:06 <cocreature> we have 3 different kinds
05:35:09 <kuno_luno> I thought it was? ertes. Either that, or infecting all your signatures with "HasSTackTrace"
05:35:11 <cocreature> the profiling based ones
05:35:14 <cocreature> the dwarf based ones
05:35:19 <cocreature> and the HasStackTrace ones
05:35:24 <kuno_luno> Go on... cocreature
05:37:51 <cocreature> kuno_luno: iirc https://hackage.haskell.org/package/base-4.9.1.0/docs/GHC-ExecutionStack.html uses dwarf so the overhead should be fairly small. however dwarf-based stacktraces are usually less precise than profiling-based ones
05:39:07 <cocreature> kuno_luno: it might also be worth trying to see the impact of enabling profiling for your specific program. if you reduce the detail of cost centres it might not be so bad
05:40:52 <merijn> ok, anyone with conduit experience, I think I realised my issue
05:41:01 <merijn> But I don't know how to fix it...
05:41:48 <kuno_luno> Thanks, cocreature. That helps a lot. :-)
05:41:55 <merijn> I basically have a sink of (Foo, Bar) tuples that uses "peek" to ensure it only grabs specific elements or terminates
05:43:07 <merijn> However, I only have "Bar" elements incoming, so I need to somehow "wrap" them with "(Foo,)", I, naively, did this by just doing "Conduit.map (Foo,) .| mySink", but presumably that map is pulling elements from the source, which means the "peek" inside the sink is pointless...
05:43:15 <merijn> So...how do I fix this?
05:45:32 <ertes> merijn: you could write a function:  Source m Bar -> Source m (Foo, Bar)
05:46:18 <merijn> ertes: No, because I don't have an explicit source
05:46:30 <merijn> ertes: And also, it would fuck up all the other combinators in xml-conduit
05:48:03 <ertes> merijn: alternatively write a function:  Sink (Foo, Bar) m -> Sink Bar m
05:48:37 <merijn> ertes: I'm not sure how to implement that, though?
05:49:02 * ertes is searching through the API
05:49:42 <Tuplanolla> I have a philosophical design problem. I'm using Repa to work with tiles on a periodic lattice, but I find myself doing more linear algebra in the shape-index space than the actual stuff stored in the arrays. Am I right to feel uncomfortable?
05:50:13 <ertes> merijn: ah, you could use 'mapInput' from Data.Conduit.Internal
05:50:45 <ertes> merijn: but i'm not sure why that function is considered internal…  be careful not to break any invariants…  conduit is an enigma
05:53:34 <merijn> ertes: Well if I can confirm this is indeed the issue, I can patch xml-conduit to solve my issue
05:55:47 <exio4> anybody knows how I could see which library calls h$open (w/ GHCJS)?
06:00:33 <merijn> ertes: Oh thank god, now it works...
06:01:21 <ertes> merijn: with mapInput?
06:01:25 <merijn> ertes: Yeah
06:01:31 <ertes> ok =)
06:02:04 <merijn> So I was right that my code was fine all along, except for not thinking about the fact that my "adapter" consumed input causing things to break
06:02:36 <merijn> With pipes I wouldn't have had this issue! *shakes fist*
06:07:12 <ertes> yeah…  i resisted the temptation to say: just use pipes =)
06:08:15 <orion> If you're implementing crypto in pure Haskell, are there mechanisms within the language to prevent timing attacks?
06:08:18 <merijn> ertes: I would, but the libraries I'm using are all conduit
06:08:30 <orion> Or do I need to drop down to C?
06:08:47 <merijn> orion: Rust, surely? ;)
06:12:43 <orion> Are you saying I can bind to Rust?
06:13:04 <merijn> orion: Pretty sure Rust has a C FFI, so yes
06:13:30 <merijn> orion: Calling Rust from Haskell's C FFI is (from Rust's perspective) identicall to being called from C
06:13:48 <merijn> So, unless you can't call Rust from C, you can do that
06:13:50 <mniip> except!
06:14:09 <mniip> except if rust's functions don't like being called from different threads
06:14:28 <merijn> mniip: Well, then you can still do it. You'll just become unhappy :)
06:15:32 <orion> But, many languages have a C FFI. Wouldn't that imply that Haskell can call into all of them?
06:25:39 <merijn> orion: Yes
06:26:42 <orion> ...with the help of a C "shim"?
06:26:58 <merijn> orion: "C FFI" is just code for "generate something that is sensible according to the C ABI", at the linker level everything is just symbols and binary anyway, so if you ensure both sides are understanding the code the same way (by using the right ABI), it Just Works
06:27:06 <merijn> orion: In most cases probably not
06:27:54 <merijn> orion: If you "foreign export" something from haskell the compiler will generate something that can be called like any C function, so if something else imports that as if it's a C function, they'd never know it was "Haskell all along!"
06:28:32 <merijn> orion: Which is exactly why no one bothers to implement anything else besides C FFI :p
06:29:11 <exio4> <_<
06:31:22 <ertes> merijn: you can convert between pipes and conduits
06:31:39 <merijn> ertes: How? Although that wouldn't help me here :)
06:32:59 <ertes> merijn: not sure how exactly, but they do use compatible (if not the same) underlying models
06:33:54 <ertes> going from pipes to conduit is pretty easy, but from conduit to pipes a bit more involved, because you need to handle leftovers somehow
06:35:28 <merijn> ugh...
06:35:39 <merijn> I wish GHC properly supported recursive imports
06:36:24 <quchen> Many parsers use a 4+-field ADT, e.g. Parsec has the 4 fields »consumed ok«, »consumed error«, »empty ok«, »empty error«. Can anyone explain the meaning of these to me?
06:37:00 <quchen> Most parsers look like (...) \cok cerr eok eerr -> (...) and I have trouble understanding their meaning.
06:37:42 <quchen> I think Trifecta has a similar type (in Böhm/Beraducci form, like Trifecta).
06:37:58 <quchen> Eh, like Parsec.
06:39:14 <ertes> quchen: what exactly confuses you?  the four cases or how they're represented?
06:40:12 <quchen> ertes: For example, what’s »consumed« and »empty«?
06:40:22 <orion> merijn: But, don't you need to call some HsInit function (or whatever) before calling any foreign exported function?
06:40:38 <quchen> I’m confused about this in general, but let’s try solving subproblems until everything hopefully clicks into place.
06:40:42 <ertes> quchen: parsers that fail might have already read some input, in which case (<|>) has different semantics
06:41:07 <ertes> quchen: p1 <|> p2  -- if p1 fails without consuming, then p2 is tried, but if p1 has already consumed input and fails, then the whole thing fails
06:41:52 <merijn> orion: oh, I suppose, yes
06:41:53 <quchen> I see, so I should look up how (<|>) works I guess.
06:41:59 <merijn> orion: But that only once
06:42:11 <ertes> quchen: example:  string "blah" <|> string "blubb"  -- now suppose the input is "blubb"
06:42:29 <ertes> quchen: let's say that 'string' is actually implemented character by character
06:43:01 <ertes> quchen: the left parser starts consuming:  'b', fine, then 'l', fine, but then 'u', failure!
06:43:24 <ertes> quchen: now because the left parser has consumed "bl" (so the remaining input is "ubb"), the whole thing fails
06:43:25 <quchen> ertes: I understand the part about consuming input, failing and all that, I’ve used it many times. My problem is the connection to that type/lambda, I don’t see how »conditional backtracking« fits in there.
06:43:59 <ertes> quchen: that's where 'try' comes in:  it keeps a log of the input its argument parser has consumed, and if it fails, it restores that input
06:44:07 <ertes> quchen: that's really all there is to it
06:44:29 <quchen> Is a consumed error a parser error that happens when we have already consumed input, and an empty error one that we can ignore, but have to add to our »could have been there« list for errors?
06:45:14 <ertes> quchen: an empty-failing parser is still a failing parser, but in that case (<|>) knows that the input is still intact, so it can try the next parser
06:46:32 <ertes> quchen: note that not all parser libraries work like that…  for example attoparsec has automatic backtracking…  (<|>) will take the role of 'try' in that case
06:46:42 <ertes> it will unconditionally keep a log of the input the left parser has consumed
06:47:10 <EvanR> joe9: lookup the %external thing in core
06:47:58 <EvanR> page 12 of this https://downloads.haskell.org/~ghc/6.12.2/docs/core.pdf says certain primitives and calls will cause side effects
06:49:07 <quchen> ertes: So a »Parser (\cok cerr eok eerr -> …)« parses something; if it’s successful and input has been consumed, then the continuation cok is applied to the result, if it’s not and input has been consumed, cerr is used; same procedure for non-consumed inputs, but using the other two?
06:52:27 <ertes> quchen: correct
06:56:05 <joe9> EvanR: Thanks. Can I mean that to understand that the purity of haskell is more of a parser/frontend enforcement, whereas Idris takes it even to the IR?
06:56:42 <EvanR> honestly you probably know more about idris IR
06:57:23 <EvanR> i havent read anything really (if it exists) on compiling idris
06:58:18 <ocharles_> Does anyone know if using Data.Scientific  is the same as using Fixed E6?
06:59:21 <EvanR> that doesnt seem right
06:59:54 <EvanR> Fixed E6 is an Integer with decimal point shifted over 6. scientific is mantisa and base 10 exponent
07:00:25 <EvanR> so total number of numbers is twice
07:00:31 <lystra> Hi. I just built ghc-8.0.2 on RHEL6 from source and am now building some Cabal packages. First up is text-1.2.2.1. I am selecting an out-of-tree installation directory via "runghc Setup.lhs configure --ghc --prefix=<blah>". The package is installed to <blah>/lib/x86_64-linux-ghc-8.0.2/text-1.2.2.1-FwvWBfkNJh1I1NMMegz0uY/.... How do I get the install path to be just <blah>/lib/text-1.2.2.1?
07:00:45 <ocharles_> Hmm, I guess Scientific could represent exactly what's in Fixed E6, but arithemetic on it could cause even more precision to come in
07:01:13 <EvanR> yeah theres an inclusion of Micro into Scientific
07:01:34 <quchen> ertes: Now I understand the fields, but not how they work, hehe. Back to reading source code I guess.
07:02:58 <EvanR> > 1/3 :: Micro
07:03:00 <lambdabot>  0.333333
07:03:08 <EvanR> > 1/3 :: Scientific
07:03:10 <lambdabot>  error:
07:03:10 <lambdabot>      Not in scope: type constructor or class ‘Scientific’
07:03:53 <EvanR> <bottom>
07:03:57 <ertes> quchen: just implement a simple parser yourself =)
07:04:32 <ertes> quchen: CPS/church is optional, if you decide to do that…  it's mostly an efficiency thing
07:05:08 <ertes> (and convenience, once you get used to it)
07:05:56 <hexagoxel> lystra: you probably need to set --libsubdir or one of those more specific flags.
07:06:10 <hexagoxel> lystra: https://www.haskell.org/cabal/users-guide/installing-packages.html#installation-paths
07:07:36 <merijn> Whoo! My parser is actually working, finally
07:07:49 <merijn> Now to clean up the mess of three days of debugging...
07:07:53 <exio4> merijn: congratz :p 
07:09:35 <klaptrap> hello?
07:09:41 <klaptrap> is there anyone out there?
07:09:43 <Rembane> Good morning klaptrap 
07:09:57 <klaptrap> am i allowed to be toxic af in here 
07:10:02 <klaptrap> (im new at irc)
07:10:03 <maerwald> lol
07:10:16 <klaptrap> I would really like to piss a nigga off 
07:10:19 <lystra> hexagoxel: Ok, will try those. I figured --libsubsubdir would add something under --libdir but I might be wrong.
07:10:22 <Rembane> klaptrap: No
07:10:24 <merijn> @where ops
07:10:24 <lambdabot> byorgey Cale conal copumpkin dcoutts dibblego dolio edwardk geekosaur glguy jmcarthur johnw monochrom quicksilver Saizan shachaf shapr ski
07:10:26 <klaptrap> oh
07:10:35 <quchen> ertes: Oh I wrote many »simple« parsers for teaching, but they were too simple :-/
07:10:41 <Rembane> klaptrap: If you are, you're out.
07:10:46 <klaptrap> rembane so is ther any server ;you know of where i can be as toxic as i want to?
07:10:51 <klaptrap> Like 4chan style?
07:11:02 <klaptrap> I understand. But are there any channels that you know about?
07:11:07 <quchen> ertes: i.e. the classical (string -> [(string, a)]) parsers
07:11:18 --- mode: ChanServ set +o dibblego
07:11:20 <JuanDaugherty> klaptrap, try #psychology
07:11:20 --- mode: dibblego set +b *!*981ab220@*.152.26.178.32
07:11:24 --- kick: klaptrap was kicked by dibblego (klaptrap)
07:11:28 <Rembane> klaptrap: Well, you can always write things down on a paper and burn it.
07:11:32 --- mode: dibblego set -o dibblego
07:11:45 <EvanR> burn before reading
07:11:56 <Rembane> Indeed. Write only.
07:12:07 <shapr> ah, beat me to it
07:13:13 <exio4> anyone here knows how I could pass a JS object around with the c-ffi emulation of GHCJS? :/
07:13:22 <asdfasdf0101> guys, why do i have to indent the inner `alloca` in "do\n     alloca $ \a ->\n    alloca $ \b ->" one level deeper than the outer? and if i omit `do`, both `alloca`s can have the same indentation level! what are the rules of indentation inside `do` anyway?
07:14:26 <merijn> asdfasdf0101: All you ever wanted or needed to know about identation: https://en.wikibooks.org/wiki/Haskell/Indentation
07:16:48 <hexagoxel> (the last paragraph of that wiki page seems most relevant here)
07:21:11 <orion> Let's say you've defined a Free Monad (DSL) and someone wrote a program in it. You want to define an instruction that "jumps" to a previous or future instruction. Is this mathematically impossible?
07:22:12 <anonus> is it possible to define a prism for type like data Foo = Bar a b | Baz a d | Boo e f  to access 'a' field?
07:22:46 <anonus> or prisms work only for tyeps like data Foo = Boo a | Baz b | Boo c ?
07:22:53 <merijn> hexagoxel: I think it's important to just know the rules for indentation completely
07:24:25 <asdfasdf0101> merijn: i'm afraid i still don't get it, could you please point me to the exact rule? "the golden rule" doesn't explain it to me, everything works also if i omit `do` and place the outer `alloca` more to the right than the inner one
07:24:26 <glguy> anonus, no that wouldn't make sense
07:24:58 <merijn> asdfasdf0101: Can you lpaste the code you have?
07:25:08 <glguy> you could make a prism that referred to the pair of fields (a,b) or to (a,d)
07:25:38 <merijn> Right, now we play the "wait for dependency to merge your changes" game
07:26:42 <anonus> glguy: so this means that prism should always be able to construct a 's' value out of 'a' (if we talking about Prism' s a) ?
07:27:14 <asdfasdf0101> merijn: sure! http://lpaste.net/351428
07:29:28 <anonus> but how then i could i make something lens-like to be able to get or set 'a' field in type above?
07:30:00 <anonus> so 'a' included in more than one constructor of type Foo
07:30:23 <merijn> asdfasdf0101: Because the alloca's are identented equally after a 'do' it's inserting a semicolon before every alloca
07:30:39 <tomus_> This a general CS question but #haskell is esp good at these. I have a massive hashmap. Keys are days. e.g. m[day] = x. Now for each x and a given day d I need to be able to access the following: latest day < d such that m[day] = x. I need to do this operation quite a lot. What is the optimal data structure for this operation?
07:31:09 <Cale> tomus_: It sounds like you want something like a priority search queue
07:31:48 <joshsyn> hello
07:31:49 <Cale> Oh, hmm
07:32:06 <Cale> (Thinking more carefully, I'm not sure)
07:32:08 <joshsyn> i am a visual person, I am thinking to learn a functional language
07:32:21 <joshsyn> wondering how easy it is to plot a graph in haskell
07:32:27 <hexagoxel> merijn: i dunno.. the wiki seems to bury the actual formalism in a random selection of guidelines :/
07:32:34 <asdfasdf0101> merijn: so? semicolons are bad? still don't really get it :-)
07:32:36 <niklasb> tomus_: keep another hashmap x -> [Day] and use a sorted array or other sorted DS for the righthand side
07:32:49 <merijn> asdfasdf0101: "\b -> ; x" is a syntax error
07:33:18 <asdfasdf0101> oh, it's so simple?! thank you! i get this now
07:33:24 <asdfasdf0101> merijn: cc
07:33:30 <tomus_> niklasb: doesn't that mean I need to walk that sorted array quite a lot?
07:33:42 <merijn> I'm actually surprised the first one works
07:33:47 <niklasb> tomus_: you can binary search in it in O(log n)
07:33:52 <niklasb> to find the predecessor of d
07:34:03 <tomus_> ah ok
07:34:18 <exio4> Cale: you have experience with GHCJS, right? do you know how I can pass JS objects around in Ptr(s)? trying to come up with a shim 
07:34:33 <asdfasdf0101> merijn: yeah, me too
07:34:33 <niklasb> of course if your data structure is dynamic you should use a dynamic ordered data structure, like a binary search tree/btree/2-3finger tree
07:35:23 <Cale> exio4: Hmm... I haven't tried that. It wouldn't surprise me at all to learn that you could though.
07:35:36 <SexHendrix> i have an assoclist, [(Char, Integer)] and a word [Char], and i want to turn the word into [Integer]
07:35:54 <SexHendrix> is there a handy dandy function that does this
07:36:01 <merijn> :t lookup
07:36:03 <lambdabot> Eq a => a -> [(a, b)] -> Maybe b
07:36:18 <exio4> Cale: yeah, there has to be a way I bet :/
07:36:27 <merijn> SexHendrix: "map (\c -> lookup c assoclist)" ?
07:36:53 <exio4> or mayMaybe :p 
07:36:56 <niklasb> :t mapMaybe (flip lookup assoclist)
07:36:58 <lambdabot> error:
07:36:58 <lambdabot>     Variable not in scope: assoclist :: [(a, b)]
07:37:02 <niklasb> ofc
07:38:16 <niklasb> > let f = mapMaybe . flip lookup  in f [('a', 1), ('b', 2), ('c', 3)] "aba"
07:38:19 <lambdabot>  [1,2,1]
07:38:44 <lystra> hexagoxel: --libsubdir="\$pkgid" --dynlibdir="\$libdir/\$pkgid" is just what we need. Thanks.
07:39:03 <Cale> exio4: If you can't, the usual trick is just to define some separate modules based on whether you're compiling with ghc or ghcjs.
07:40:23 <SexHendrix> ah flip is pretty useful
07:40:25 <SexHendrix> nice one
07:40:37 <SexHendrix> and so is mapMaybe, wow
07:40:49 <niklasb> SexHendrix: actually now that I look at it, it's probably not very readable to use flip here with (.) :D
07:41:05 * SexHendrix scuttles off to read more library functions
07:42:43 <exio4> Cale: I am trying to come up with a shim for a crypto library - and I wanna avoid rewriting half of the lib to use JSVal :P
07:43:37 <exio4> Cale: (I am trying to fix the dependencies of a library I am using)
07:43:55 <maerwald> crypto and js... funny combination
07:44:11 <tomus_> niklasb: I think that's good enough for me. x -> sorted([days]). Thank you!
07:44:20 <SexHendrix> going with mapMaybe (flip lookup assoc) word
07:44:33 <niklasb> tomus_: you need to use an array, not a list, just in case you were planning otherwise
07:44:46 <niklasb> or Data.Vector or whatever
07:44:54 <exio4> maerwald: don't ask me! =P
07:45:11 <tomus_> I am not writing haskell for this :)
07:45:19 <tomus_> this is production code acutally :)
07:45:30 <tomus_> (my company doesn't use haskell, sadly)
07:45:42 <niklasb> tomus_: ok I'm sorry to hear
07:46:03 <maerwald> exio4: it's like... imagine people doing online-banking via their web browser... oh wait, they do
07:46:13 <seequ> Is there a function that repeats MaybeT until it succeeds?
07:46:15 <SexHendrix> is it bad form to just write `lookup` instead of flip lookup
07:46:48 <niklasb> SexHendrix: good question. I guess both are kind of unintuitive in this case
07:46:55 <niklasb> I wouldn't use infix
07:47:09 <SexHendrix> mapMaybe (`lookup` assoc) word
07:47:48 <niklasb> I guess it comes down to preference
07:49:04 <Cale> SexHendrix: If you're doing repeated lookups, turn your association list into a Map first
07:49:20 <Cale> Or, just construct a Map in the first place, rather than that list.
07:49:49 <Cale> It has a nicer API than lists for the sorts of operations you're likely to want to do, and it'll be a lot faster.
07:49:57 <niklasb> Cale: a lot fast for 256 elements?
07:50:17 <niklasb> agreed though that lookup lists are generally not very cool
07:50:25 <Cale> niklasb: If you do more than a handful of lookups, probably.
07:50:42 <seequ> Ah, msum . repeat does the trick
07:50:56 <Cale> It shouldn't take all that many elements before Map beats an association list
07:52:05 <Cale> I don't know what the actual number is these days, but somewhere below a dozen :)
07:54:36 <saulfuhrmann> @pl \xs n -> take n xs ==> flip take
07:54:36 <lambdabot> flip flip (flip take) . ((==>) .) . flip take
07:55:16 <seequ> :t (==>)
07:55:18 <lambdabot> STestable prop => Bool -> prop -> Test.QuickCheck.Safe.SProperty
07:57:43 <SexHendrix> :t (===>)
07:57:44 <lambdabot> error:
07:57:44 <lambdabot>     • Variable not in scope: ===>
07:57:44 <lambdabot>     • Perhaps you meant one of these:
07:58:41 <seequ> Hmm. Can I somehow prove to Haskell that (runMaybeT . msum . repeat) can never return Nothing?
08:00:43 <exio4> seequ: you could write "msum . repeat" by hand with the right type, but it might not be what you want :P
08:00:59 <seequ> Not at all. :P
08:01:07 <Tuplanolla> This sounds like a job for `fromJust`, seequ.
08:01:12 <Cale> seequ: Probably you want to do the repetition on the outside?
08:02:14 <seequ> Tuplanolla: Well, there we go. Thanks.
08:02:27 <seequ> Cale: I wanted to abstract out the repetition logic.
08:02:45 <seequ> That function, by definition, can not return Nothing
08:03:41 <seequ> fmap fromJust . runMaybeT . msum . repeat
08:03:43 <seequ> :)
08:07:39 <seequ> Abstracting control structures is amazing.
08:07:50 <byorgey> seequ: indeed =)
08:14:16 <quchen> merijn: RFC https://github.com/quchen/articles/blob/master/fbut.md#indentation-and-sensitive-whitespace
08:15:35 <merijn> quchen: I think the 3rd one is always an error?
08:15:50 <quchen> merijn: Oh?
08:16:05 <merijn> quchen: Since it's not in the block of just (so after the closed case) but since it's idented further than case it'd be a continuation of that line
08:16:06 <quchen> Could be! Gotta catch my bus, @tell me everything you find or better, open a ticket :-)
08:16:08 <merijn> So
08:16:38 <merijn> @tell quchen so "case x of { Just y -> [y] } Nothing -> []" <- syntax error
08:16:39 <lambdabot> Consider it noted.
08:26:26 <jle`> seequ: if your input can't take return Nothing, then maybe the fromJust/fromMaybe should happen at the first level
08:26:45 <jle`> seequ: oh wait, sorry, misread
08:26:46 <jle`> nvm :)
08:27:10 <jle`> yeah, there's no way to prove that it'll *eventually* return Just
08:28:04 <merijn> jle`: to be fair, it might not :p
08:28:07 <seequ_> But hey, finally a legit use for an unsafe function!
08:28:29 <seequ_> merijn: hm?
08:28:31 <jle`> merijn: i'm assuming that seeuq_ 'knows' something about what they are applying the functions to
08:28:37 <EvanR> thats a good point, fromJust "isnt even wrong" when the function can only return Just or freeze up
08:28:56 <seequ_> jle`: I don't
08:28:59 <EvanR> itll provably never crash
08:30:03 <jle`> oh, i see the original point now
08:30:13 <jle`> it might not eventually return Just
08:30:16 <jle`> but it'll never return Nothing
08:30:25 <jle`> fun stuff
08:31:51 <EvanR> semidecidable life
08:31:57 <seequ_> Right, so returning a Maybe is just dumb
08:32:08 <jle`> well, returning anything is kind of questionable
08:32:50 <EvanR> "returns the right answer or never returns" comes up a lot and you can race threads to get real work done that way
08:33:04 <jle`> good point :)
08:33:51 --- mode: ChanServ set +o glguy
08:33:51 --- mode: glguy set +b-bo *!*@*/ip.152.26.178.32 *!*981ab220@*.152.26.178.32 glguy
08:35:24 <seequ_> EvanR: or in this case: ignoring illegal actions
08:36:19 <sm> johnw: nice space leak hunting! 
08:37:13 <sm> and I'd like to better understand your "be strict enough to reduce residency, but not so strict that you create too many thunks".
08:37:20 <sm> creating too many thunks would also increase the "residency" reported by top, I assume, so I think you are using that word in another sense ?
08:39:32 <sm> would this be another way of saying it: "be strict enough to keep your heap small, but not so strict that your stack grows too big" ?
08:41:38 <jle`> reads a little funny in my head.  because haskell's stack is on the heap, it sounds like "be strict enough to keep your heap small, but not so strict that your heap grows too big"
08:41:42 <jle`> :p
08:43:13 <haskell346> take 5 [1..]
08:43:32 <jle`> haskell346: @query lambdabot > take 5 [1..]
08:43:45 <jle`> @query lambdabot > take 5 [1..]
08:43:45 <lambdabot> Unknown command, try @list
08:43:49 <jle`> er, /query
08:43:55 <haskell346> @list
08:43:55 <lambdabot> What module?  Try @listmodules for some ideas.
08:45:27 <haskell346>  @pl \xs n -> take n xs
08:45:40 <Dark_cloud> what is script??
08:46:11 <SexHendrix> Dark_cloud: uwot
08:46:11 <sm> jle`: yes, that is a bit awkward
08:46:31 <Dark_cloud> SexHendrix what is script in computers 
08:46:43 <sm> we have some unclarity of language here
08:47:20 <SexHendrix> 0.o
08:47:46 <sm> we need a word for the memory a haskell program is using, that is not the stack
08:48:02 <maerwald> memory
08:48:05 <shapr> Cale: didn't you have a really cute swap function for mapping one chunk of data across a list of functions?
08:48:19 <seequ_> maerwald: +1
08:48:22 <sm> too vague, that includes stack
08:48:43 <maerwald> yes, because there is one :P
08:48:46 <shapr> heap is already used... what about a pile of memory?
08:49:19 <seequ> What exactly does stack mean in this case?
08:49:25 <haskell346> @pl \xs n -> take n xs
08:49:25 <lambdabot> flip take
08:49:33 <Cale> @let swing f c a = f ($ a) c
08:49:35 <lambdabot>  Defined.
08:49:42 <Cale> :t swing map
08:49:45 <lambdabot> [a -> b] -> a -> [b]
08:49:51 <Cale> :t swing partition
08:49:53 <lambdabot> [a -> Bool] -> a -> ([a -> Bool], [a -> Bool])
08:49:56 <shapr> Cale: ah, thanks!
08:50:15 <Cale> shapr: Though, if all you want is swing map, just use sequence
08:50:20 <Cale> :t sequence
08:50:22 <lambdabot> (Traversable t, Monad m) => t (m a) -> m (t a)
08:50:36 <Cale> :t sequence :: [e -> a] -> e -> [a]
08:50:38 <lambdabot> [e -> a] -> e -> [a]
08:50:43 <shapr> I was trying to figure out how to rewrite Clojure's juxt in Haskell
08:51:00 <sm> seequ: the part of memory used for holding thunks etc. as you call functions
08:51:15 <seequ> soo.. thunk memory
08:51:20 <haskell346> @pl \f x -> f x x
08:51:21 <lambdabot> join
08:51:27 <exio4> many operations on Integers are apparently not implemented in GHCJS :/
08:51:34 <sm> stack is the common term used by all languages
08:51:59 <seequ> Right, but it's ambiguous
08:52:01 <sm> I think that one is not ambiguous.. "heap" is the one we are overloading with two meanings
08:52:03 <Cale> sm: "heap"
08:52:06 <Cale> hm?
08:52:36 <sm> Cale: well, I'm going by what jle` said above: "stack is on the heap"
08:52:54 <sm> "haskell's stack is on the heap", rather
08:53:08 <Cale> Oh, well, that's true, though it's separately limited as well.
08:53:10 <maerwald> s/haskell/GHC/
08:53:16 <Cale> Yeah, GHC's
08:53:54 <Cale> Also, GHC's stack is weird if you're coming from the perspective of most language implementations, since it's not really easily regarded as a call stack.
08:54:00 <maerwald> probably just implementation-defined or is there a "spec"?
08:54:17 <maerwald> GHC memory layout or something
08:54:45 <Cale> Yeah, it's just implementation defined, the Report doesn't say anything about memory layout.
08:55:13 <maerwald> that I know, still wondering if GHC bothered to "spec" itself
08:55:56 <sm> without getting into the lower details, I'd just like to have some agreed-on terms for basic discussion of heap and stack, eg when debugging space leaks
08:57:21 <sm> could someone break down "a GHC program's stack is on the heap" a little more ? Here, "heap" is what ?
08:57:33 <sm> memory allocated from the OS, right ?
08:59:04 <sm> who calls that "heap" ? I have always thought of heap as the part of memory not used by stack
08:59:33 <EvanR> heap is memory managed by the GC
08:59:42 <EvanR> its really big
09:00:32 <EvanR> i dont know if the stack as in stack pointer is used at all
09:01:12 <sm> ok.. so the GHC program has a great big virtual memory space, the heap. And it has a stack, which uses up some portion of that heap
09:02:06 <Cale> EvanR: I'm pretty sure it is -- foreign calls demand that :)
09:02:25 <EvanR> oh yeah... C calling conventions
09:02:50 <Cale> EvanR: It's just that the chunks of memory that the stack pointer might be pointing in live inside the heap
09:02:56 <sm> if it were me, I'd call that whole space the program's allocated memory, containing heap + stack
09:03:28 <EvanR> saying "heap + stack" is really trying to imply to normal programming language users that its like C and its not
09:04:18 <EvanR> when you look at a dynamic language implementation, they will also separate things into heap + stack, even if its not the C stack
09:04:18 <sm> is it not a useful simplification for space leak discussions ?
09:04:30 <EvanR> because its pretty much emulating the way C works
09:04:42 <Cale> Well, the fact that the stacks live on the heap doesn't seem to affect things all that much in practice.
09:04:56 <Cale> C is irrelevant here
09:05:08 <EvanR> and in that case stack is on the heap there too
09:05:12 <Cale> Well, unless you're talking about performance of foreign calls or something
09:05:20 <EvanR> it seems like stack-is-on-the-heap is irrelevant
09:05:47 <sm> it came up as I tried, above, to unpack johnw's comment: "be strict enough to reduce residency, but not so strict that you create too many thunks"
09:06:00 <EvanR> for space leaks, isnt it enough to imagine an expression being reduced?
09:06:16 <sm> for better intuition I tried to simplify that to "be strict enough to keep your heap small, but not so strict that your stack grows too big"
09:06:17 <Cale> The GHC stack and the foreign call stack are the same stack, it's just that when you're thinking about how Haskell code interacts with that stack, it's rather unhelpful to think of it as a "call stack"
09:06:20 <EvanR> using Cale's trick for visualizing sharing
09:07:16 <EvanR> im amazed at how little i need to understand ghc to figure these things out
09:07:22 <Cale> When you get a stack overflow from Haskell code, it's almost always going to be pattern matches waiting on the stack for their scrutinee to be sufficiently evaluated to match a pattern
09:08:22 <Cale> There's also function applications which are waiting for the function to be sufficiently evaluated to apply, but those are almost never responsible for stack overflows, unless you're doing something contrived.
09:09:23 <saurabhnanda> has anyone used keter in production? it's not clear to me how to install keter. and what does it have to do with postgres.
09:09:30 <sm> my point is, I think to make learning/teaching how to track down space leaks easier, we need some clearer language/working abstractions
09:10:03 <Cale> I don't know if the problem is any sort of lack of language clarity
09:10:20 <sm> Cale, or: how would you explain johnw's use of "residency" above ?
09:10:44 <Cale> I think I missed that
09:10:53 <sm> <sm> it came up as I tried, above, to unpack johnw's comment: "be strict enough to reduce residency, but not so strict that you create too many thunks"
09:10:59 <sm> <sm> for better intuition I tried to simplify that to "be strict enough to keep your heap small, but not so strict that your stack grows too big"
09:12:28 <Cale> sm: Okay, so you have these runtime representations for expressions ("thunks") which live on the heap (along with the stacks, but the stack is not really what johnw is talking about at all there)
09:13:20 <Cale> sm: Sometimes, these expressions may be large and complicated
09:13:27 <Cale> (and take up lots of memory)
09:13:32 <Cale> while their result might be something small
09:14:14 <Cale> For example, you might have a huge expression of the form 1 + (1 + (1 + ... + (1 + 0)...))
09:14:19 <Cale> with a million 1's
09:14:59 <Cale> That could consume over a megabyte of space, while the eventual Int result would fit in little more than a machine word
09:15:48 <Cale> (honestly a little more, since Int is different from Int#, it's boxed)
09:16:02 <Cale> So, in cases like that, evaluating is profitable
09:16:26 <Cale> In other cases, the expression might be much smaller than what results when you evaluate it.
09:17:07 <Cale> Consider this program:
09:17:15 <sm> Cale: this is great, and I appreciate you going into the details and will profit from this.. but I'm most interested in..
09:17:24 <Cale> subsequences [] = [[]]
09:17:40 <Cale> subsequences (x:xs) = subsequences xs ++ map (x:) (subsequences xs)
09:18:38 <sm> is it possible to clarify this language (what is "residency" above ?) so that it's possible to have a basic intuition for space leak dynamics, without having to understand this level of detail
09:19:05 <Cale> sm: That's another generic term for "the amount of memory used by the program"
09:19:19 <Cale> At least as far as I'm aware
09:19:28 <sm> then john's phrase doesn't make sense
09:21:03 <Cale> sm: So, well, one thing I think johnw is referring to there is that the unevaluated expressions can hold references to other things on the heap: any free variables in them might be the last remaining reference to something
09:21:19 <sm> because isn't it then equivalent to "be strict enough to use less system memory, but no so strict that you use more system memory"
09:21:22 <Cale> and so after that expression gets evaluated, the garbage collector can clean up
09:21:37 <Cale> Yes, it basically is :D
09:22:49 <Cale> Evaluating stuff can both increase and reduce the total amount of memory needed, depending on what expression it is that you're evaluating and which things it refers to.
09:23:10 <nitrix> Is there a symbol for `unifies` ?
09:23:25 <Cale> So just being stricter doesn't always help you, it can make things worse.
09:23:36 <Tuplanolla> There's `~`, nitrix.
09:23:56 <nitrix> Tuplanolla: Wasn't that used by type equalities?
09:24:24 <Tuplanolla> Yes, it might not be exactly what you're after.
09:24:32 <nitrix> What I meant is more like in a casual discussion where I'd be tempted to say like:
09:24:57 <tabaqui1> Data.Array has O(n) asymptotic with append and cons operations
09:25:03 <sm> Cale: right, that we know well. I thought john had given a rule of thumb that gives a little guidance on that, but I'm not seeing that it does 
09:25:06 <tabaqui1> why so?
09:25:07 <nitrix> (+) (0 :: Int) `unifies as` :: Num Int => Int -> Int -> Int
09:25:10 <nitrix> As opposed to
09:25:21 <nitrix> (+) (0 :: Int) :: Num Int => Int -> Int
09:25:31 <tabaqui1> is this structure effective at all?
09:25:43 <sm> and he is conveniently absent :) any comments welcome later if you see this johnw
09:25:57 <nitrix> Tuplanolla: Essentially the TypeApplication extension but in casual lingo.
09:26:17 <nitrix> (+) @Int :: Num Int => Int -> Int -> Int
09:26:27 <Cale> sm: The usual rule of thumb that I use is to classify things into "small" and "large" roughly by the number of separately evaluatable parts that they have
09:26:28 <Tuplanolla> Huh.
09:26:37 <Cale> (note that this is distinct from the actual number of bytes)
09:26:39 <tabaqui1> *Data.Vector
09:26:43 <tabaqui1> my mistake
09:27:11 <Cale> sm: The stuff you usually want to be strict is where you have a "large" input, but a "small" output.
09:28:20 <sm> noted, thank you
09:28:25 <Cale> For example, this is what makes foldl' so good when you're producing something like an Integer
09:28:33 <Cale> You can't halfway-evaluate an Integer
09:29:08 <sm> I think that haskellers, en masse, will get better at understanding space leaks as we find and disseminate better simple language for talking about them
09:29:16 <Cale> and there's potentially a lot of separate bits of data going into the operation which we'll free up references to
09:29:55 <nitrix> Tuplanolla: I often break down step-by-step type inference to people and I want to show them the substitutions that happens when some arguments are added, but without removing that parameter from the type annotation, as that'd confuse them.
09:30:05 <sm> now I'm running out of steam and should pause :) thanks Cale, all
09:30:27 <nitrix> Tuplanolla: But at the same time, if I leave that parameter there in the type annotation, then I'm essentially lying about the expression's type.
09:30:34 <Cale> I don't think it really has to do with language -- we have all the words we need from a technical standpoint -- my distinction here with "large" and "small" isn't really formal or even something you'd necessarily want to try to make formal.
09:30:34 <EvanR> the kinds of space leaks that really need fixing, which are on their way to exhausting all memory, arent even about small and large objects, but doing things in a broken way, holding onto references
09:30:54 <EvanR> once you get into optimizing then the small and large things makes sense
09:31:14 <Tuplanolla> You'll have to come up with something new, nitrix.
09:31:26 <nitrix> Tuplanolla: e.g. I want to say `not True ::: Bool -> Bool -> Bool` rather than `not True :: Bool`
09:31:42 <nitrix> Tuplanolla: TypeApplication lets you do @Bool but that's on the type-level :/
09:31:59 <nitrix> I want a syntax for expressions :(
09:31:59 <Cale> However, I think more people could be exposed to what exists in the way of thinking about graph reduction.
09:32:20 <Tuplanolla> That doesn't seem like a good idea to me.
09:32:50 <Cale> One thing which contributed a lot to the way I thought about space usage of functional programs was this little demo that Dr. Kahl at McMaster University gave me of his HOPS programming language
09:33:03 <Cale> http://www.cas.mcmaster.ca/~kahl/HOPS/
09:33:08 <Cale> http://www.cas.mcmaster.ca/~kahl/HOPS/ANIM/index.html
09:33:32 <nitrix> Tuplanolla: People do type specialization / inference / unification exercises all the time, but they write it line-by-line.
09:33:49 <nitrix> Tuplanolla: It's missing the information of what arguments causes what to be inferred at such steps.
09:34:05 <Cale> HOPS is a graphical language where you actually draw your expression graphs, and evaluation acts on them directly, so you can see the space usage of your program: it roughly corresponds to the amount of space the graph takes to draw on the page
09:34:10 <Tuplanolla> Put them inline, nitrix?
09:34:29 <Cale> and evaluation is updating these graphs repeatedly, so you can watch the space usage grow and shrink as it proceeds
09:34:49 <exio4> nitrix: (not :: Bool -> Bool) True ? 
09:35:01 <Cale> This is all going on in GHC Haskell too, it's just we don't have really great visualisation tools for it.
09:35:18 <nitrix> Tuplanolla: (>>=) :: Monad m => m a -> (a -> m b) -> m b
09:35:32 <Cale> (Well, there are some things, but it's much harder to label the graph nodes with anything relevant to the programmer)
09:35:53 <nitrix> Tuplanolla: (>>= writeFile "filename") :: Monad IO => IO a -> IO ()
09:36:17 <nitrix> Tuplanolla: It's not good enough because you don't get to see the intermediary steps of the inference.
09:36:27 <nitrix> It's eliminated immediatly after because of the application.
09:36:38 <exio4> nitrix: s/IO a/IO String/ :P 
09:36:52 <nitrix> Is writeFile a String? Oh you're right.
09:37:40 <exio4> nitrix: can't you use/do something like ((>>=) :: Monad IO => IO String -> (String -> IO ()) -> IO ()) ? 
09:38:04 <Tuplanolla> I meant `(not :: Bool -> Bool) (True :: Bool) :: Bool`, nitrix.
09:38:09 <nitrix> exio4: These are beginners though :/
09:38:22 <nitrix> Tuplanolla: Yeah, exio4 is suggesting the same thing.
09:38:45 <nitrix> It feel like it'd be incomprehensible for a beginner.
09:39:39 <Tuplanolla> I feel like inventing more intermediate complications can only make it worse.
09:40:17 <nitrix> I mean, I can keep it the way I do things and explicitly say in english that it'll be inferred / specialized / substitued as, but it's repetitive and felt clumsy.
09:40:18 <Tuplanolla> This happened on our course with guillemets as "value of type" operators.
09:40:42 <Tuplanolla> We've stopped using them since.
09:40:57 <nitrix> Here, another problem I see often in discussion; I normally put code between backticks.
09:41:23 <nitrix> Because the english language uses `a` as well as we use `a` for type variables, so I feel the need is justified.
09:41:41 <nitrix> Yet, Haskell also uses backticks so it leads to really confusing sentences sometims.
09:42:33 <nitrix> I'm just trying to be consistent and help get better understood x]
09:44:50 <nitrix> Could be just OCD.
09:47:56 <drninjabatman> hello
09:48:30 <drninjabatman> Is there a way to add default  implementations to typeclass methods of existing typeclasses?
09:48:54 <thatguy> if I have a graph with two different kind of nodes (i.e. both are nodes and have neighboring nodes etc but both types have special properties which they store), what is the haskell way of implementing this?
09:49:38 <drninjabatman> eg for all `MyTC` instances `T` I want to be able to simply say `instance Traversible T;`
09:55:51 <hexagoxel> drninjabatman: `instance MyTC f => Traversable f where ..`
09:56:28 <hexagoxel> but you can't overwrite the default or you run into some overlapping mess.
09:58:24 <hexagoxel> this already is overlapping, isn't it..
09:59:48 <drninjabatman> hexagoxel hmm, you are right..
10:00:34 <hexagoxel> i don't think there is a nicer (non-overlapping) solution.
10:02:45 <drninjabatman> I was at least hoping that I would be able to have the user explicitly state `instance Traverible T` but that there would be a default implementation, but I can't guarantee that my typeclass will be the only one doing the hypothetical default implementation injection
10:02:48 <EvanR> thatguy: make a graph data structure that holds anything, then make plug a sum type for the two kinds in for the "anything"
10:03:03 <EvanR> make a sum type, plug it in
10:22:37 <t7> hey guys yesterday we were talking about guassian elimination 
10:22:46 <t7> turns out my matrix might not be square :(
10:23:44 <johnw> sm: hi
10:25:02 <Cale> t7: You're in luck, Gaussian elimination doesn't care about that.
10:27:13 <t7> huh
10:27:18 <t7> i read wikipedia wrong
10:44:46 <nshepperd1> But if your matrix isn't square you get a vector space of solutions rather than a single solution
10:46:04 <EvanR> no no no
10:46:46 <EvanR> a vector space must contain 0 vector
10:47:08 <nshepperd1> Assuming it's the right kind of "not square" after eliminating duplicate rows
10:47:29 <EvanR> two planes intersecting in a line doesnt need to go through the origin
10:47:30 <Zemyla> There aren't really laws for Foldable, are there?
10:47:39 <nshepperd1> If you have too many equations you get no solutions
10:48:30 <nshepperd1> EvanR: the vector space is the parametrisation in the left over variables
10:48:36 <EvanR> a point is a special case of the general affine space solution
10:49:09 <nshepperd1> I guess you can say affine space, whatever
10:49:28 <EvanR> just saying 0,0,0,0 isnt always a solution after you solve it
10:49:32 <nshepperd1> Zemyla: there's a law relating it to traversable...
10:50:41 <EvanR> two solutions added isnt necessarily a solution
10:50:59 <AWizzArd> I imported Data.Map as M  and defined   let x = M.fromList [("a", Just 10), ("b", Just 20), ("c", Nothing), ("d", Just 40)]        Now I would like to get 45 from  (M.lookup "d" x) + 5
10:51:26 <AWizzArd> Obviously that doesn’t work. How can I “unpack” the 40 from the two Just wrappers?
10:52:13 <EvanR> > join (Just (Just 40))
10:52:17 <lambdabot>  Just 40
10:52:25 <EvanR> > join (Just Nothing)
10:52:28 <lambdabot>  Nothing
10:52:35 <EvanR> > join Nothing
10:52:37 <lambdabot>  Nothing
10:52:57 <AWizzArd> In what Module can I find join?
10:53:16 <EvanR> > liftA2 (+) (Just 40) (Just 5)
10:53:18 <lambdabot>  Just 45
10:53:33 <t7> AWizzArd:  Control.Monad ?
10:53:44 <t7> i thought prelude...
10:55:51 <EvanR> theres also a total map package which lets you lookup stuff without Maybe
10:56:10 <Zemyla> EvanR: Isn't a total map just a Representable?
10:56:30 <AWizzArd> > join Just 40
10:56:32 <lambdabot>  error:
10:56:33 <lambdabot>      • Couldn't match expected type ‘Integer -> t’
10:56:33 <lambdabot>                    with actual type ‘Maybe a0’
10:56:49 <EvanR> Representable... a typeclass
10:57:04 <AWizzArd> Okay, more to learn I first have.
10:57:29 <EvanR> Zemyla: which operation on Representable is lookup?
10:58:04 <geekosaur> AWizzArd, mostly you have to learn when to use parentheses
10:58:09 <geekosaur> > join (Just 40)
10:58:12 <lambdabot>  error:
10:58:12 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M527264987333...
10:58:12 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
10:58:31 <geekosaur> mm, right, nothing to join there
10:58:37 <EvanR> AWizzArd: you wrote (join Just) 40, which is a type error
10:58:43 <Zemyla> EvanR: Index.
10:58:46 <Zemyla> index
10:59:12 <Zemyla> @let import qualified Data.Functor.Rep as R
10:59:14 <lambdabot>  .L.hs:94:1: error:
10:59:14 <lambdabot>      Data.Functor.Rep: Can't be safely imported!
10:59:14 <lambdabot>      The module itself isn't safe.
10:59:19 <AWizzArd> EvanR: yes okay, I see that. But still, with parens I would have expected it to work.
10:59:30 <AWizzArd> So, how can I add 5 to `Just 40`?
10:59:36 <AWizzArd> And get the Int 45?
10:59:52 <EvanR> Zemyla: i see, this goes way back to the Lookup class, a classic typeclass i remember everything saying is silly
11:00:00 <EvanR> everyone
11:00:36 <EvanR> so a total map is an Indexable
11:01:11 <Zemyla> EvanR: Well, a Functor f is Representable if f a is isomorphic to Rep f -> a.
11:01:20 <Zemyla> And that sounds like a total map to me.
11:01:56 <EvanR> Rep f ?
11:02:40 <EvanR> AWizzArd: liftA2 (+) (Just 40) (Just 5)
11:02:58 <EvanR> you can necessarily get 45
11:03:14 <EvanR> > liftA2 (+) Nothing (Just 5)
11:03:16 <lambdabot>  Nothing
11:04:08 <EvanR> Zemyla: if anything it sounds like a total map is basically a function
11:04:56 <Zemyla> That's what I was saying.
11:05:25 <EvanR> but you cant update a function as efficiently
11:07:30 <old1101> on this answer -> http://stackoverflow.com/a/6274016 I found "Haskell will permanently store any list elements that have been discovered -- that is important." to be confusing as HOW fibs references `0 : 1` at first
11:08:14 <EvanR> its also misleading-sounding
11:08:34 <EvanR> storage isnt a thing youre supposed to think about with pure code
11:08:49 <EvanR> its all a big expression to be evaluated step by step
11:10:15 <EvanR> old1101: fibs is used in the definition of fibs, so if the question is how anything has access to 0:1:... its because thats the first two elements of fibs
11:10:37 <EvanR> which is clear from the definition
11:12:21 <old1101> EvanR: but why and how "Haskell will permanently store any list elements that have been discovered"
11:12:33 <EvanR> i dont agree with that
11:12:56 <EvanR> at least in isolation
11:13:30 <old1101> recursion without arguments seems weird
11:13:39 <EvanR> right, this is not a function
11:13:46 <Tuplanolla> The term of interest is "constant applicative form", old1101.
11:13:47 <EvanR> its a recursively defined list
11:13:53 <geekosaur> ^
11:14:23 <EvanR> when the program starts, you can think of fibs as 0, 1, some code
11:14:53 <EvanR> if something evaluates the 4th element, itll then be 0, 1, 1, 2, some code
11:15:12 <EvanR> thats the operational way to think of it
11:16:36 <monochrom> x = 0:x is a simpler example.
11:16:49 <old1101> Tuplanolla, I'm seeing the wiki but perhaps this is too much for me hahah
11:17:25 <monochrom> The haskellwiki is written with great enthusiasm mostly.
11:17:44 <monochrom> Great enthusiasm means the author does not know that you don't understand.
11:18:18 <EvanR> i resemble that remark, often
11:18:25 <glguy> I don't know what you mean
11:18:36 <kadoban> xD
11:18:52 <old1101> monochrom: I noticed this a little hahah
11:19:04 <old1101> I'm mixing recursive functions with recursive lists, I think
11:19:18 <old1101> the latter uses memoization, right?
11:19:33 <monochrom> yes
11:20:33 <monochrom> the former memoizes too. just that it memoizes the one trivial thing that doesn't help you.
11:21:26 <monochrom> "f x = f (x-1)" memoizes the code for f. "\x -> f (x-1)". One copy is made and reuse.
11:21:33 <shayan_> Hi all, I am having trouble with this section of the snap installation tutorial: http://imgur.com/a/zzcke Specifically, in the terminal, I type “cabal install” and get a return message “cabal: --root-cmd is no longer supported, see
11:21:34 <shayan_> https://github.com/haskell/cabal/issues/3353”. Furthermore, by typing “myproject -p 8000”, I get the a return message “-bash: tweet: command not found”. Can anyone assist me in setting this up please
11:22:53 <Cale> Which user are you running cabal install as?
11:23:32 <shayan_> I suppose my main/admin?
11:23:55 <shayan_> I also have cabal in my path: /Users/shayanbozorgmanesh/Library/Haskell/bin:/Users/shayanbozorgmanesh/.cabal/bin:/Users/shayanbozorgmanesh/.cabal/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin
11:23:55 <old1101> recursive lists is a special topic on haskell? I can't find some docs about the case x = 0 : x
11:24:13 <monochrom> Not a special topic.
11:24:21 <Cale> > let x = 0 : x in x
11:24:24 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
11:24:55 <Cale> shayan_: ah, you're on MacOS, hmm
11:24:56 <monochrom> Most good books should have explained it. Even if not, you could experiment with it and see what it means.
11:24:57 <EvanR> old1101: any data structure acts like this
11:25:03 <shayan_> Cale:  Yes
11:25:59 <EvanR> you could have a recursively defined tree or graph structure
11:26:17 <Cale> shayan_: does the 'whoami' command work?
11:26:22 <Cale> I think it ought to
11:26:34 <shayan_> Cale: Yes: shayanbozorgmanesh
11:26:35 <shayan_> :D
11:26:57 <monochrom> that user name is so long, I thought it was a password
11:27:26 <shayan_> monochrom: haha it is full name
11:27:36 <Cale> oh well, I guess try  cabal build  instead
11:27:41 <glguy> shayan_: What version of cabal-install are you using?
11:27:52 <shayan_> this is tweet.cabal (tweet = myproject): http://lpaste.net/raw/351419
11:28:04 <glguy> cabal --version
11:28:26 <shayan_> cabal-install version 1.25.0.0
11:28:33 <shayan_> glguy: I think this might actually be the problem?
11:28:36 <glguy> You're using a development version of cabal-isntall
11:28:59 <glguy> You should be using a released version
11:29:23 <shayan_> glguy: Ah! Good call. I remember changing up the version by experimenting with a sandbox tutorial I found on the web the other day >_<
11:31:51 <drninjabatman> is there a good library implementing a deque
11:31:56 <shayan_> glguy: using cabal install cabal cabal-install in the terminal returns me an error
11:32:13 <drninjabatman> correction: an efficient deque
11:32:50 <Cale> drninjabatman: I typically just use Data.Sequence
11:33:12 <Cale> If that's not sufficiently efficient, then there's other stuff available on hackage which I could help you dig up
11:33:47 <Cale> Data.Sequence is internally a weird kind of inverted tree structure which provides fast access to both ends
11:35:22 <drninjabatman> Cale for now I just want it to be better than `head xs`/`xs++[x]` thnx!
11:41:27 <old1101> EvanR, monochrom thanks for the help :)) the fibonacci function was hidding the basics from me that I already know ): (the `x = 0 : x` did the trick)
11:48:22 <johnw> they said at this year's Fibonnaci conference that it was as good as the last two combined
11:48:41 <drninjabatman> I see there is some documentation online where Data.Queue is in base but on my installation ghc 8.0.1 it isn't, was it deprecated?
11:49:20 <drninjabatman> how can I check my version of base?
11:49:24 <monochrom> hahaha johnw
11:49:32 <johnw> drninjabatman: ghc-pkg list should tell you
11:49:42 <monochrom> @remember johnw they said at this year's Fibonnaci conference that it was as good as the last two combined
11:49:43 <lambdabot> Okay.
11:52:27 <maerwald> lol
11:52:35 <drninjabatman> thnx johnw
11:54:12 <codedmart> I am not seeing in `https://hackage.haskell.org/package/time-1.7.0.1/docs/Data-Time-Format.html` how to get `1st`, `2nd`, etc for the day?
11:55:47 <geekosaur> you don't, it's following posix which doesn't support that
11:56:02 <codedmart> Ah ok
11:56:46 <codedmart> geekosaur: You are an encyclopedia of knowledge. Thanks!
11:57:38 <geekosaur> likely because posix gave some thought to portability and the 1st/2nd etc. thing is specific to English and not really localizeable
11:58:29 <geekosaur> (other languages do do that kind of thing but not in a way you can package up in a date/time formatting API sanely)
12:03:55 <monochrom> I do hate it when it comes to 21st but 11th.
12:05:05 <EvanR_> uh lpaste may have adult content? https://twitter.com/edwinbrady/status/822167973918031873
12:05:06 <stobix> Well, why pick a base when you can do both base 10 and 12 simultaneously...
12:05:51 <monochrom> Doubly annoying when you write mathematics in English because the general statement is "the nth item of the sequence is n^2+5" but then when you plug in n=21 it suddenly is "21st" not "21th". Violates referential transparency or something.
12:06:13 <kadoban> Hah
12:06:29 <geekosaur> stobix, wasn't that the thinking that got us our time system (via the Sumerians liking base-60 for pretty much that reason)?
12:06:39 <EvanR_> natural language is a porcelain
12:07:02 <stobix> geekosaur: I guess. Or just "meh, they already did it - why redo it?"
12:07:26 <EvanR_> the time of day was the original web, were stuck with it forever
12:07:39 <stobix> At least English has gotten rid of base 20 when counting.
12:07:55 <EvanR_> sort of, "vigintillion"
12:08:16 <stobix> "four score and x" is no more.
12:09:17 <geekosaur> but you can switch to french and you still have quatre-vingt :p
12:09:26 <stobix> oh, the "-illion" thing. To think that it at one point were consistent.
12:09:52 <stobix> geekosaur: Yep, and Danish. And probably some other ones - of which most also have a word for "dozen".
12:11:00 <stobix> We could still count stuff as "x gross y dozen and z" if we really wanted.
12:11:35 <EvanR_> you could count in prime numbers
12:12:02 <EvanR_> then you could claim the language is provably hard
12:12:05 <stobix> I actually played around with having prime numbers as a number base-ish once. It got weird. :)
12:12:25 * stobix might have a Haskell module for it somewhere.
12:12:52 <ubsan> is there always a prime number between p and 2p ?
12:12:54 <EvanR_> as i understand it, the whole "deal" with number theory is that +1 and prime factorization dont mix
12:13:04 <monochrom> No, count in busy beaver numbers!
12:13:23 <stobix> 2 ~ 1, 3 ~ 10, 4 ~ 2, 5 ~ 100, 6 ~ 11 ...
12:13:37 <EvanR_> unique factorization into busy beaver numbers?
12:14:17 <ubsan> https://en.wikipedia.org/wiki/Proof_of_Bertrand's_postulate nice
12:14:24 <monochrom> No, I have an even better idea. Represent the number in Roman notation. Then Gödel-number that.
12:14:39 <stobix> Using base 1+i but only the numbers 0 and 1 covers a piece of the complex plane that kinda looks like a dragon curve.
12:15:37 <monochrom> Knuth's book also describes a Fibonacci base system.
12:15:55 <EvanR_> phinary is pretty cool
12:16:15 <stobix> monochrom: huh, cool. 
12:16:20 <EvanR_> dont ask how to convert to decimal though
12:16:36 <stobix> EvanR_: how do ... nevermind
12:16:41 <EvanR_> no idea
12:16:53 <kuribas> monochrom: The art of computer programming?
12:17:08 <nshepperd> playing with weird bases is actually a good idea, because sometimes you discover new data structures
12:17:21 <stobix> base π is kinda the same, I guess. 
12:17:45 <monochrom> yeah TAOCP
12:18:16 <nshepperd> like that uh, skew heap? or whatever it was called
12:18:29 <kuribas> Funny how TAOCP is about anything but the art of computer programming.
12:19:01 <frontendloader> kuribas: why would you say that
12:19:09 <monochrom> It does have AVL trees.
12:19:58 <kuribas> frontendloader: well, it's more about computer science than programming itself.
12:20:43 <kuribas> there's nothing about logic programming, for example.
12:20:51 <EvanR_> stobix: dunno about pi, but phi^2 = phi + 1, and 1/phi = phi - 1 lets you do some interesting stuff
12:23:07 <kuribas> EvanR: how is 1 represented in base phi?
12:23:47 <EvanR_> 1/phi + 1/phi^2 i think
12:25:31 <frontendloader> kuribas: yeah thats why it's the art of computer programming, not computer programming in practice
12:25:34 <eschnett> isn’t 1 == phi^0, and thus trivial?
12:26:09 <EvanR_> actually yes, but 1 has infinite other representations
12:26:34 <EvanR_> 1.00 = 0.11
12:26:47 <APic> Gesundheit.
12:27:39 <EvanR_> = 0.1011
12:28:00 <kuribas> frontendloader: I see it more as a very in depth review of selected topics from CS.  For example SICP has much more info about computation that isn't in TACP.
12:28:01 <EvanR_> = 0.101011
12:28:01 <EvanR_> = 0.10101010...
12:28:05 <sphinxo> is it possible to put template haskell inside template haskell?
12:28:16 * sphinxo famous last words
12:28:40 <frontendloader> SICP is a more practical book, yes
12:29:10 <kuribas> frontendloader: TACP is awesome, but I find the title slightly misleading.
12:29:17 <EvanR_> i feel like SICP is more art than art of computer programming
12:29:18 <joe9> Does UHC have uniqueness types?
12:31:09 <joe9> stumbled upon this interesting paper http://foswiki.cs.uu.nl/foswiki/pub/Hage/MasterStudents/improveduniquenesstypingforhaskell.pdf and want to check if the functionality described works on UHC/EHC
12:31:19 <kuribas> EvanR: what numbers whould you use in base phi?
12:32:32 <EvanR_> what do you mean
12:34:24 <sphinxo> ( what I mean is it possible to put a template haskell invocation inside a template haskell [|  |] )
12:37:21 <nitrix> Is there such thing as `class EqTwo t1 t2 where eq :: t1 -> t2 -> Bool; eq :: t2 -> t1 -> Bool` where one can kind of overload `eq` or do I have to necessary have a wrapper type?
12:37:35 <kuribas> EvanR: never mind
12:38:13 <kuribas> nitrix: how do you compare values from two different types?
12:38:26 <nitrix> Is there such thing as `class EqTwo t1 t2 where data Equatable = T1 t1 | T2 t2; eq :: Equatable -> Equatable -> Bool`
12:38:34 <nitrix> Can I do something crazy like this?
12:39:02 <EvanR_> yurg
12:39:13 <kuribas> nitrix: you can define a multiparameter typeclass?
12:39:23 <nitrix> kuribas: Sure.
12:39:35 <EvanR_> heterodecidable equality
12:39:50 <EvanR_> whats laws 
12:40:21 <seequ_> nitrix: but why would you?
12:40:36 <kuribas> nitrix: or use an isomorphism, then compare using Eq?
12:41:10 <nitrix> seequ_: I want to experiment with the idea of comparing types that aren't entirely isomorphic.
12:41:51 <uiop> nitrix: so you mean a homomorphism between them, fsvo homomorphism
12:42:11 <nshepperd> nitrix: why not eq :: t1 -> t2 -> Bool
12:42:12 <nitrix> I'm not sure what I mean, that's why I'm asking.
12:42:23 <seequ_> nitrix: right, but would something like this be more feasible? class EqTwo a b where eqt :: a -> b -> Bool
12:42:35 <nitrix> nshepperd: Sure, but then you're stuck with comparing the two types only in a given order.
12:42:48 <uiop> nitrix: i'd start with what my actual objective is in doing so
12:42:55 <nitrix> nshepperd: Oh way, I could have instance EqTwo A B and instance EqTwo B A, nevermind.
12:43:02 <uiop> nitrix: then work backwards to figuring out how to achieve it
12:43:21 <nitrix> uiop: You're approaching this simple curiosity all wrong.
12:43:36 <nitrix> I think I have my answer anyway.
12:44:08 <uiop> nitrix: really? so there is no objective?
12:44:30 <nitrix> uiop: Barely any. Maybe we need #haskell-rubber-ducks :)
12:45:19 <EvanR_> aimless style
12:46:01 <nshepperd> sometimes when you 'compare' two different types of things, what you are really doing is mapping them both into some third space and comparing the results
12:46:09 <nitrix> uiop: If you want the context, I was looking at Eq2 and noticed its only parameter of kind `* -> *`.
12:46:52 <stobix> EvanR_: oh, cool! Yeah, that base must get weird quickly. I kinda wonder if it's more useful than having i as a base.
12:47:30 <nitrix> uiop: Then I asked myself the question, couldn't we have a similar Eq2 but with multiple parameters? The order of the arguments t1 -> t2 was bothering me, and I was thinking of isomorphic contraptions until it just clicked a second ago one could just define two instances.
12:48:54 <EvanR_> havent thought of i as a base, wait how about both. base phi lets you write numbers of the form i + j*sqrt(5) in a finite way. i guess base i also gives you + k*sqrt(-1)
12:49:01 <nitrix> uiop: I know it's a weird simple realisation, but having reverse instances seems like it can have practical uses in more complicated situations.
12:49:39 <seequ_> nitrix: well, flip
12:49:53 <EvanR_> its only logical to consider Eq3 next
12:50:31 <seequ_> EvanR_: but EqTwo can be used to build it!
12:50:40 <EvanR_> can it?
12:51:05 <EvanR_> with Eq2 you can get any finite EqN
12:51:08 * stobix really wishes that Bool were a class. It would lead to some interesting generalizations.
12:51:34 <EvanR_> how about the Unit class
12:51:36 <seequ_> eq3 a b c = (eq2 a b) && (eq2 b c)
12:52:17 <seequ_> stobix:hmmm?
12:52:24 <EvanR_> but not && (eq2 a c) ?
12:52:28 <uiop> why not (eq2 a c) && (eq2 b c)
12:52:38 <EvanR_> you need all three imo
12:52:46 <uiop> yeah or all 3
12:53:01 <nitrix> Nested guards.
12:53:02 <EvanR_> i kind of am scared that you dont have eq2 a b = eq2 b a
12:53:10 <seequ_> EvanR_: I'd argue equality should be a transitive property ;P
12:53:13 <EvanR_> necessarily
12:53:21 <EvanR_> its not even symmetric here
12:53:39 <seequ_> True.
12:53:53 <uiop> i think the point is that all this talk is like more than beyond the point of no return down the rabbit hole of craziness :)
12:54:07 <stobix> seequ_: I can currently do stuff like (sin + cos) 3 if I define a Num instance, but I can't ever do stuff like (cos == sin) 3
12:54:15 <uiop> maybe i'm too pragmatic
12:54:15 <EvanR_> the point of no return would be EqOmega
12:55:01 <EvanR_> stobix: ... is that what you want a Bool class for
12:55:09 <stobix> EvanR_: ...mebbeh...
12:55:17 <EvanR_> thats bordering on javascript php 
12:55:44 <stobix> Oh, that's low...
12:55:51 <EvanR_> anything is a bool
12:56:43 <monochrom> I love omega. It's the point of a new future :)
12:56:55 <shayan_> Do most of you here use Stack?
12:57:18 <monochrom> err, maybe not the point, a point. there is always omega+omega and omega*omega.
12:57:19 <stobix> EvanR_: Ah, in JS you mean. Yeah, but in Haskell only things defined as bool would be.
12:57:37 * stobix kinda likes freedom of expression, especially the one haskell normally provides
12:59:17 <EvanR_> omega power tower omega
12:59:37 <sphinxo> I'm trying to choose between using persistent and groundhog as orms for a django style batteries included web framework i'm trying to make ( yes another one )
13:00:08 <sphinxo> Persistent seems more widely used, but I like the generics stuff that groundhog gives you
13:00:09 <EvanR_> can you make a frameworkless framework, ill use it
13:00:22 <stobix> EvanR_: as long as you can make a monad of it, you haven't reached the point of no return yet.
13:00:36 <EvanR_> -_-
13:00:40 <uiop> you should just make a framework framework factory
13:00:43 <stobix> \o/
13:00:56 <sphinxo> EvanR_: ok a set of utils to make writing straightforward crud stuff with less boilerplate
13:01:15 <sphinxo> ( a library then )
13:01:55 <sphinxo> something along the lines of django rest framework
13:02:13 <sphinxo> ( which is awesome btw (heresy?))
13:03:38 <sphinxo> can anyone give me any advice?
13:04:24 <Rembane> sphinxo: Regarding CRUD?
13:04:36 <sphinxo> yeah
13:04:48 <sphinxo> apart from using postgrest
13:04:51 <Rembane> sphinxo: Have you looked into Servant? https://haskell-servant.github.io/
13:05:57 <sphinxo> Rembane: yeah I was thinking about using that as the base
13:06:03 <sphinxo> currently just using wai
13:06:15 <niklasb> sphinxo: I've successfully used a combination of spock and admin-on-rest recently. The frontend was the annoying part in any case
13:06:29 <sphinxo> but I'm wondering how to do persistence of native adts
13:06:30 <niklasb> so I wasn't too worried about the backend
13:07:23 <ph88> when i have a  IO [a]  and a  a -> IO()  how can i change that into [IO a]  and execute the IO actions ?  i tried  mapM (\x -> putStrLn $ T.unpack $ printSource x) $ sample' (get :: Gen DesignFile)   but then i get   No instance for (Traversable IO) arising from a use of ‘mapM’
13:09:18 <adamCS> ph88: I think there's only one IO action there. The one you would need to execute to get your [a].  There's no list of actions to do.  
13:09:22 <geekosaur> as <- <IO [a] thing here>; mapM_ whatever as
13:09:45 <adamCS> ph88: sorry! Missed the a->IO()
13:11:49 <ph88> mapM_ worked  https://paste.fedoraproject.org/531087/14848602/  is it possible to do it in 1 command though ?
13:12:53 <geekosaur> (your IO [a] thing) >>= mapM_ whatever
13:13:21 <geekosaur> you should probably sit down and figure out how this stuff works
13:14:34 <cheater> hi how do you pronounce <$>?
13:14:47 <cheater> fmap i guess but is there another way?
13:14:48 <niklasb> less than dollar greater than
13:16:29 <ph88> ya you're right geekosaur 
13:16:33 <codedmart> What is the best option for a heterogeneous list in haskell? 
13:16:43 <geekosaur> codedmart, "don't"
13:16:44 <ph88> cheater, infix fmap
13:16:52 <geekosaur> there are several options but all of them are nasty
13:16:55 <EvanR_> ph88: whats great about that question is it can be phrased as a type signature
13:16:57 <Rembane> codedmart: Monoids!
13:17:01 <codedmart> Well ok.
13:17:14 <ph88> hows that
13:17:22 <codedmart> I can manage a different way.
13:17:25 <codedmart> Thanks!
13:17:58 <EvanR_> ph88: ? : [IO a] -> (a -> IO ()) -> IO ()
13:18:15 <EvanR_> @hoogle [IO a] -> (a -> IO ()) -> IO ()
13:18:19 <lambdabot> GHC.Conc.Sync sharedCAF :: a -> (Ptr a -> IO (Ptr a)) -> IO a
13:18:19 <lambdabot> System.IO.Utils lazyMapM :: (a -> IO b) -> [a] -> IO [b]
13:18:19 <lambdabot> GHC.HeapView.Debug findM :: (a -> IO Bool) -> [a] -> IO (Maybe a)
13:18:28 <EvanR_> aaaaand... its gone
13:18:33 <EvanR_> ? = forM_
13:21:08 <trevorriles> EvanR_: I think you had his question backwards in your type
13:21:16 <codedmart> Actually I am not sure how to do this. I need to rewrite a function from JS to Haskell. In JS it gathers numbers and strings into an array `[0, 1, 0, "asdf", "fdsa", 0]` and then md5's that array. 
13:21:34 <cheater> ph88 thanks
13:21:40 <trevorriles> @hoogle IO[a] -> (a -> IO()) -> [IO(a)]
13:21:41 <lambdabot> Foreign.Marshal.Utils maybeNew :: (a -> IO (Ptr b)) -> (Maybe a -> IO (Ptr b))
13:21:41 <lambdabot> Foreign.Marshal.Utils maybePeek :: (Ptr a -> IO b) -> Ptr a -> IO (Maybe b)
13:21:41 <lambdabot> Data.GI.Base.BasicConversions mapZeroTerminatedCArray :: (Ptr a -> IO b) -> Ptr (Ptr a) -> IO ()
13:21:57 * trevorriles shrugs
13:23:26 <geekosaur> codedmart, in normal Haskell you'd make a list of the results (that is, [md5 0, md5 1, md5 "asdf", ...]) --- can't use map because of the type mismatch
13:24:21 <geekosaur> and, the heterogeneous list solutions that exist are more oriented toward extensible records than general lists, because they're so painful to use as lists (for example, you won't be mapping stuff easily over them either)
13:24:25 <haskell570> Hello, I apologize for the beginner question but what does hSetBuffering stdout NoBuffering mean and why do I have to use it?
13:24:39 <codedmart> geekosaur: So are you saying if I md5 each item then md5 the resulting list of md5's it should match?
13:25:04 <Sonolin> haskell570 from what I understand, whenever anything is written to a buffer it will instantly be flushed to the screen
13:25:20 <Sonolin> haskell570 LineBuffering means it will be flushed when a linebreak is encountered
13:25:44 <geekosaur> haskell570, it does two things: (a) disable reading input / writing output only in complete lines (b) (at least on unixlikes) it switches the tty driver to character mode instead of line mode
13:26:41 <haskell570> So what happens if I don't use it?
13:26:43 * geekosaur dislikes that conflation, and there's a stack bug caused by it
13:26:56 <geekosaur> you type a character and it is ignored and not seen until you press return
13:27:24 <haskell570> so it would be like I type and it's invisible? Like when you type passwords in some terminals?
13:27:29 <joe9>  Is there an IRC channel for DDC (Disciplined Disciple Compiler)?
13:30:02 <geekosaur> haskell570, it will be echoed but the program will not see it
13:30:10 <geekosaur> (on unix/linux. windows is different)
13:44:16 <dmwit> haskell570: If you want the password-like invisible text entry, that's controlled by hSetEcho.
13:50:53 <dmwit> stobix: What would you want `(cos == sin) 3` to mean?
13:51:12 <dmwit> `cos 3 == sin 3`?
13:51:43 <dmwit> or `const False 3`? or what?
13:51:44 <codedmart> geekosaur: I am not sure I understand how to use MD5 from cryptohash. I mean I see it takes a bytestring, but if I `hash "[1, 2]"` it is the same as `md5("[1, 2]")` in JS. But I need `hash [1, 2]`?
13:52:27 <dmwit> codedmart: Presumably you will need to reimplement whatever JS's logic is for hashing non-bytestring types.
13:52:49 <hololeap> is there a cononical way to handle toEnum values which are out of range (when explicitly defining toEnum, not deriving)
13:53:07 <codedmart> dmwit: Hmm...
13:53:09 <geekosaur> > toEnum 3 :: Bool
13:53:12 <lambdabot>  *Exception: Prelude.Enum.Bool.toEnum: bad argument
13:53:18 <geekosaur> probably duplicate something like that
13:53:40 <geekosaur> (which is from `error`)
13:53:49 <dmwit> hololeap: Have you looked at the Fine Documentation?
13:53:58 <hololeap> dmwit: no...
13:54:04 <codedmart> dmwit: That might be over my head but I will look.
13:54:04 <dmwit> hololeap: Do. The answer is in there.
13:54:40 <hololeap> dmwit: what exactly are you referring to?
13:54:41 <geekosaur> codedmart, more or less what dmwit said. you can't meaningfully hash an actual Haskell list; the crypto hashes assume you have already marshalled Haskell types to something that is meaningful to not-Haskell
13:54:43 <dmwit> codedmart: Do you need to get the exact same answer as JS? (Are you interoperating with some JS?)
13:55:35 <codedmart> dmwit: I am trying to rewrite JS to Haskell. In other words I want to replace the JS code.
13:55:47 <dmwit> codedmart: That doesn't answer the question. =)
13:56:02 <codedmart> Yes I need to exact same answer.
13:56:02 <Koterpillar> codedmart: you are hashing a _string_ in JS
13:56:11 <codedmart> No I am not hashing a string in JS.
13:56:18 <codedmart> I am hashing an array.
13:56:18 <Koterpillar> codedmart: show the JS code again
13:56:41 <geekosaur> they didn't show the JS code
13:56:41 <dmwit> codedmart: If you need to get the same answer as JS, what makes you think you can avoid using the same algorithm as JS...?
13:57:01 <Koterpillar> codedmart: geekosaur: md5("[1, 2]") <-- if this is the JS code, then it is hashing a string
13:57:12 <codedmart> Ah I see what you are saying. I just assumed the MD5 package that was available in Haskell would have what I need.
13:57:16 <geekosaur> they were saying that their naïve interpretation of Haskell usage uses a String-like
13:57:41 <geekosaur> so gets the same result as hashing a string in JS would when they need to hash a JS array
13:58:01 <Koterpillar> I'm not convinced JS is hashing an array
13:58:19 <codedmart> Koterpillar: Let me look at the package code I use in JS.
13:58:35 <geekosaur> Koterpillar, that was specifically "if I hash "[1,2]" then I get the same result as JS hashing a string, not JS hashing an array" (well duh)
13:59:15 <Koterpillar> let's see the code...
13:59:37 <geekosaur> anyway, crypto hashes typically do not operate on internal representations (hashes for e.g. hashmaps do, but that's different)
13:59:51 <codedmart> This is the js code. I am looking through it now. https://github.com/pvorb/node-md5/blob/master/md5.js
13:59:54 <geekosaur> you normally crypto-hash something you can send around, which means a marshalled-for-export format
14:00:04 <dmwit> hololeap: "fromEnum and toEnum should give a runtime error if the result value is not representable in the result type. For example, toEnum 7 :: Bool is an error." https://hackage.haskell.org/package/base-4.9.1.0/docs/Prelude.html#t:Enum
14:00:17 <Koterpillar> codedmart: https://github.com/pvorb/node-md5/blob/master/md5.js#L18
14:00:36 <Koterpillar> codedmart: this is how your array would have been hashed, by calling toString() on it
14:00:54 <Koterpillar> codedmart: you now have to reimplement JS's Array.toString() in Haskell, and you'll be good
14:01:01 <geekosaur> this is especially important in JS as the internal representation for numbers is a double precision floating point format, which is not generally portable to different CPU architectures (e.g. x86 <-> ARM)
14:01:15 <Koterpillar> codedmart: consider converting the value to JSON in Haskell and JS instead
14:02:25 <dmwit> geekosaur: I think the conversion from FP to ASCII is specified carefully in IEEE754. So if it's toString'ing first it should be quite portable.
14:02:44 <codedmart> Koterpillar: I am reading that differently `!Array.isArray([1, 2])` is `false` so they assume it is a byte array already.
14:02:52 <geekosaur> yes, given toString. not using internal. which was exactly what I meant by marshalling
14:03:02 * dmwit nods agreement
14:03:16 <Koterpillar> oops. You're right
14:03:20 <geekosaur> and, why am I misspelling marshaling, sigh
14:03:57 <Koterpillar> codedmart: that's assuming you don't call md5("[1, 2]") as you said
14:04:16 <codedmart> That was an example. I do actually call md5([1, 2])
14:05:53 <codedmart> So should I use something like this https://hackage.haskell.org/package/memory-0.14.1/docs/Data-ByteArray.html
14:07:34 <geekosaur> I think you need to figure out what the JS code is doing when computing the hash of a list
14:08:40 <geekosaur> if you actually need exactly the same result as JS, I don't see how that package helps you; in fact it looks to me like that package is for a completely different purpose
14:09:57 <codedmart> I just assumed bytearray would translate over.
14:10:23 <geekosaur> assumptions are bad when looking for exact behavior
14:10:35 <dmwit> What does "translate over" mean, and why would a ByteArray be better than a ByteString?
14:10:45 <codedmart> geekosaur: You are right.
14:11:02 <codedmart> dmwit: I meant the JS code talks about ByteArray.
14:11:37 * dmwit mumbles something about alpha equivalence
14:15:37 <geekosaur> the problem is that "bytearray" is a fairly generic concept; you cannot assume ths package and JS mean the same thing unless the Haskell package specifically talks about JS compatibility (which it doesn't, as far as I can see)
14:18:38 <sphinxo> When people talk about lambda calc, abs = lambda right?
14:18:53 <byorgey> sphinxo: yep
14:19:01 <byorgey> it is a "lambda abstraction"
14:19:28 <sphinxo> thanks byorgey 
14:25:42 <sphinxo> what does this symbol mean? Π
14:25:48 <stobix> dwarders: the former, analoguous to (cos * cos + sin * sin) x ≡ 1 :)
14:26:44 <mniip> sphinxo, depends on the context
14:26:49 <mniip> could be 'product'
14:26:59 <mniip> or pi-quantification
14:27:28 <sphinxo> Π(x :  <type>) -> x
14:27:52 <mniip> dependent typing
14:27:56 <sphinxo> forall?
14:27:59 <mniip> pi-quantification it is
14:28:09 <mniip> no, forall is related but different
14:28:41 <dolio> I think Pi was used originally by Girard.
14:28:45 <dolio> For System F.
14:29:04 <dolio> It is not necessarily dependent types.
14:29:17 <dolio> Certainly he uses it in Proofs and Types.
14:29:36 <sphinxo> where can I find out more about pi quantification? mniip 
14:30:00 <mniip> https://en.wikipedia.org/wiki/Dependent_type
14:30:08 <sphinxo> oh, right
14:30:16 <mniip> that article mentions 'pi-types'
14:31:44 <sphinxo> aka dependent product types?
14:32:02 <monochrom> yes
14:32:51 <ski> beware : some people mean the same thing by "dependent product type" as what some other people mean by "dependent function type"
14:33:36 <sphinxo> wow I am so out of my depth, this is great, thanks everybody
14:34:06 <monochrom> It is also safe to call it "for all" because of the Curry-Howard correspondence.
14:34:27 <dolio> And again, depending on what you're reading, it might mean exactly the same sort of thing that is spelled "forall" in GHC.
14:37:57 <ski> if you write `A_0 + A_1' as `Sigma i : 2. A_i', `B_0 + B_1 + B_2' as `Sigma i : 3. B_i', &c.; and `A_0 * A_1' as `Pi i : 2. A_i', `B_0 * B_1 * B_2' as `Pi i : 3. A_i', &c. -- then this motivates calling these "dependent sum type", respectively "dependent product type"; the idea being that generalize from binary to `I'-ary, for an arbitrary type `I'
14:39:27 <lpsmith> Is there something along the lines of cabal new-install for when you want to just build some executable and put it in ~/.cabal/bin ? 
14:39:41 <lpsmith> With all the new goodness included?
14:41:15 <ski> however, another way to think of `Sigma i : I. C_i' is `(i :) I * C_i', and another way to think of `Pi i : I. C_i' is `(i :) I -> C_i', ..
14:41:29 <ski> .. the idea being that these are like the ordinary (binary) product and function types, except that the right factor type resp. the return type can now *depend* on the actual value of the left factor type resp. the argument type -- this is indicated by giving a *name* to that value in the left component of the type, allowing that name to occur in the right component of the type
14:42:50 <ski> note that if `C_i' in fact does not depend on `I', say `C_i = D', then `(i :) I * C_i' is `(i :) I * D' is `(_ :) I * D' is just the ordinary binary product type `I * D'; and also `(i :) I -> C_i' is `(i :) I -> D' is `(_ :) I -> D' is `I -> D' is just the ordinary function type
14:44:14 <ski> so, this motivates calling `(i :) I * C_i' (iow `Sigma i : I. C_i') a "dependent product type", and calling `(i :) I -> C_i' (iow `Pi i : I. C_i') a "dependent function type", since these are like the ordinary product and function types, but with an added dependency
14:44:20 <ski> sphinxo : does that help ?
14:47:33 <ski> (personally, i'd prefer something like "iterated sum/product type", for the first naming convention .. is there a better term to use than "iterated" here ? -- the term "dependent", imho, seem to be more about the second naming convention)
14:48:02 <ski> (iirc, someone used the term "flexible" for the first ..)
14:50:52 <t7> people still interested in my matrix problem: i think i found an interesting optimization
14:50:52 <monochrom> recursive
14:51:10 <t7> but its very domain specific
14:51:12 <Rembane> t7: Do please tell
14:51:52 <monochrom> unlimited
14:52:02 <t7> im doing like a dynamics simulation with a load of nodes held up by joints, i work out the push or pull of a all the joints to keep the nodes in place
14:52:02 <ski> monochrom : i don't see how that would adequately describe the general situation, with an arbitrary index type `I' ..
14:52:08 <t7> (the joint forces are my variables)
14:52:11 <ski> (re "recursive")
14:52:38 <ski> "unlimited" is somewhat better, i suppose
14:52:47 <t7> there are also special joints which are roots: they are only connected to one node (and the ground/static floor)
14:52:52 * ski . o O ( "definite" )
14:53:19 <monochrom> The rationale for "recursive" is that you are not going to entertain uncountable or uncomputable domains.
14:53:27 <t7> i think i can find the furthest nodes from the roots and just work out the forces for these joints, then do the next ones layer by layer
14:53:44 <ski> i don't see why `I' couldn't be the real numbers, e.g.
14:53:55 <t7> and because solving it is like O(n^3) at best i think this will be tons faster 
14:54:04 <monochrom> And you also said "iterated". How do you iterate the real numbers?
14:54:18 * ski nods
14:54:44 <ski> "iterated" would come from thinking of the "big sum/product" as "loops"
14:54:53 <t7> im probably missing some really easy optimal solution still :( 
14:54:54 <ski> hm .. perhaps one could simply use "indexed"
14:56:00 <monochrom> The conclusion is that you said "iterated" because you had one special well-founded relation, the < of the naturals, in mind. The logical generalization is that you allow all well-founded relations, therefore recursion.
14:56:08 <ph88> finally feel like i've got my quickcheck output under control :D
14:56:30 <ski> monochrom : hehe, hard to argue with that :)
14:57:00 <ski> my worry with "indexed" is that it's not clear enough what's indexed, what it means in this context
14:58:06 <monochrom> A nice realistic example is that the domain is the set of binary trees and you use structural recursion to obtain it.
14:58:16 <ski> (saying "ary" will probably confuse people. saying "`I'-ary" feels a bit clunky, especially when you'd prefer not to have to mention the index type/set)
14:58:31 <ski> "the domain" being `I' here ?
14:58:38 <monochrom> OTOH "unlimited" is an improvement over "flexible, arbitrary".
14:58:55 <monochrom> I think so? The domain of your index variable.
14:59:03 * ski nods
14:59:54 * ski just recalled the terminology distinction between finite intersection and "arbitrary" union, in toplology
15:00:37 <imaybetoxicbutih> Man
15:00:47 <imaybetoxicbutih> So I get unbanned from 4chan in like 13 hours
15:00:51 <imaybetoxicbutih> And im so excited
15:00:58 <ski> (fwiw, "flexible" was suggested by some researcher in some papers (FunMath))
15:00:59 <monochrom> yeah we're aiming at that. but I like "unlimited" better because it's my invention. Also analogy to cellphone companies and internet companies saying "unlimited calls, unlimited data".
15:01:15 <imaybetoxicbutih> there is this dude who had posted some animal abuse
15:01:26 <imaybetoxicbutih> cant wait to give that bitch a piece of my mind
15:01:31 <monochrom> imaybetoxicbutih, wrong channel.
15:01:33 <imaybetoxicbutih> stuff like that really irks me
15:01:33 --- mode: ChanServ set +o monochrom
15:01:33 --- mode: ChanServ set +q *!*@gateway/web/cgi-irc/kiwiirc.com/ip.24.178.175.156
15:01:54 --- mode: monochrom set -o monochrom
15:02:46 <ski> monochrom : hm, i think i'll have to chew on "unlimited" (also in topology, &c.) ..
15:02:46 <t7> imaybetoxicbutih: dont mention nanjing on the japanese boards
15:03:00 <monochrom> t7, wrong channel.
15:03:17 <EvanR_> ski: indexed by the real numbers, in a computable way, requires either all the indexes point to the same thing or the target domain have a non trivial connected region
15:03:29 <EvanR_> in which case indexing doesnt sound right
15:04:01 <ski> EvanR_ : "non trivial connected region" here means ?
15:04:11 <monochrom> Oh you know what, I have a cunning plan! Aribitrary unlimited indexed sum. :)
15:04:28 <ski> (and i'm not sure why indexing wouldn't sound right)
15:04:33 <EvanR_> ski: if f(x) != f(y), then f(x) and f(y) need to be connected
15:04:37 <EvanR_> because x and y are connected
15:04:42 <EvanR_> oh and if x != y
15:05:09 <EvanR_> i guess thats implied by f(x) != f(y)
15:05:13 <ski> `f : (x :) I -> C_i', here ?
15:05:19 <monochrom> I see mathematicians say "indexed by the real numbers" all the time (for example when they have an indexed family of sets).
15:05:24 * ski nods
15:05:25 <EvanR_> f : R -> X
15:05:45 <monochrom> In fact I think they are not afraid of indexed by the powerset of the powerset of R->R
15:05:46 <EvanR_> yeah but i thought we were talking about computable functions?
15:06:31 <monochrom> Oh, we're doing restrict-to-computable half of the conversation.
15:06:37 <EvanR_> ski: non trivial blah blah = a connected component with more than one "point"
15:06:50 * ski would prefer an .. ecumenical term, if reasonable
15:06:53 <EvanR_> my memory is limited to 25 lines
15:07:06 <monochrom> You're a finite state machine!
15:07:41 <EvanR_> indexed by the real numbers doesnt sound ecumenical
15:08:05 <SexHendrix> mods are asleep, quick post effectful functions
15:08:13 --- mode: ChanServ set +q *!*@2a01:7e00::f03c:91ff:fee0:e785
15:09:47 * johnw wakes up
15:10:42 <johnw> all postings here must take #haskell to a construction referring to the new comment, and the previous #haskell; no past comments may be changed
15:10:43 <Axman6> take that, random IPv6 address!
15:11:18 <ski> EvanR_ : consider a three-dimensional ball, which you stretch to a "sausage", then bend over so it forms a "U" shape. now cut it with planes so that above a certain point, you get two disconnected circles (up to deformation), below you get a single circle (up to deformation). the cutting level is the index (a real interval)
15:12:08 <mniip> johnw, how about this:
15:12:17 <EvanR_> ski: circle or ball?
15:12:22 <mniip> I'm tying the knot by referencing my past comment which references this future comment
15:12:41 <EvanR_> 2 balls above, 1 below
15:12:51 <johnw> mniip: I'm collecting that garbage right now
15:12:57 <ski> EvanR_ : a circle, not a circle circumference/perimeter .. hm, now that i think about it, i suppose it's normally called a "disk", sorry for the confusion
15:13:19 <ski> EvanR_ : or rather, as the index traverses from `0' to `1', the cutting level traverses from up to down, to up again. now it looks like it should be possible to select a curve through the "U" so that we pick one point from each slice (in a continuous/computable) way
15:13:19 <EvanR_> oh, two disks
15:14:01 --- mode: ChanServ set -q *!*@2a01:7e00::f03c:91ff:fee0:e785
15:14:48 <EvanR_> this is an elaborate way to say that the real line is "just" a collection of dedekind cuts glued together
15:15:08 <hololeap> i don't understand what the Int in readsPrec is used for
15:15:41 <Axman6> it's the precedence, basically it's used to decide if brackets should be added or not
15:16:28 <ski> EvanR_ : anyway, afaics, indexing the slices by real numbers (in an open interval, which is homeomorphic to the real line), seems to work just fine here. i'd be surprised if this doesn't work computably
15:17:18 <EvanR_> what is the function youre trying to define?
15:17:25 <EvanR_> R -> ?
15:17:48 <ski>   f : (x :) |R -> C_x
15:17:52 <EvanR_> i see you mapped to two disks or one
15:18:03 <EvanR_> except at the change over point
15:18:06 <ski> where `C_x' is the slice corresponding to index `x'
15:18:19 <ski> yes
15:18:53 --- mode: ChanServ set -q *!*@gateway/web/cgi-irc/kiwiirc.com/ip.24.178.175.156
15:19:03 <EvanR_> yeah so the target space of slices is connected
15:20:08 <ski> perhaps that's what you were trying to say/explain before (but i didn't really follow what you meant)
15:21:41 <EvanR_> the slice shape will be better approximated as you better approximate the real number
15:22:02 <EvanR_> but if you index Bool by reals, itll have to be a constant map
15:22:09 * ski nods
15:23:05 <ski> (index subsets of `Bool', i suppose you mean ?)
15:23:31 <EvanR_> were talking about mapping points to points
15:23:41 <EvanR_> before "points" were the slices
15:23:48 <EvanR_> here points are True or False
15:25:02 <ski> ok
15:25:27 <EvanR_> like the classic example R -> Bool, f(x) = x is rational
15:26:23 <EvanR_> i dont know if thats a topology example since its not continuous
15:29:03 * ski . o O ( "Rice's theorem for the universe" : "If there is an extensional `P : U -> 2' and types `X',`Y' with `P X =/= P Y', then WLPO holds" -- "The intrinsic topology of a Martin-Löf universe" by Martín H. Escardó in 2012-03 at <http://www.cs.bham.ac.uk/~mhe/papers/universe-indiscrete-and-rice.pdf> )
15:30:22 <mniip> is your universe riced enough
15:30:49 * ski . o O ( `-funroll-types' )
15:31:46 <EvanR_> this P X =/= P Y leading to omniscience principles keeps popping up!
15:31:55 <mniip> -finline-all-functions
15:32:01 <ski> you've seen it elsewhere ?
15:32:01 <EvanR_> what is the central source of this dogma
15:32:08 <EvanR_> yes, several places
15:32:34 <EvanR_> theres an exercise in the HoTT book about it
15:32:38 <monochrom> classical logic is the source of all wisdom :)
15:33:10 <EvanR_> it came up in the shunned #haskell-blah earlier today
15:33:43 * ski has forgot to join it
15:35:48 <EvanR_> constructing an omniscience principles seems like an unconstructive way to prove somethings unconstructive, kind of like "look a boogeyman QED"
15:36:28 <EvanR_> you cant get LEM from it
15:50:03 <ski> EvanR_ : afaiui, it's standard procedure for giving up trying to prove something constructively
15:50:22 <ski> (see "Brouwerian (counter-)example, Markovian (counter-)example")
15:50:55 <ski> (i don't understand the "an unconstructive way to prove somethings unconstructive" part ..)
15:52:53 <EvanR_> yes it goes back to brouwer saying, imagine a "sequence defined by a fleeing property"
15:54:04 <EvanR_> it seems like omniscience principle is considered unconstructive by fiat, because its "like looking at an infinite number of things"
15:54:25 <EvanR_> maybe i dont understand the mathematical aspect of that
15:55:35 <ski> i saw some argument that argued that it could be more plausible, given the idea of a (countably) infinite sequence of universes, one (bidirectionally) connected to the next, time going twice as fast in the next one, ...
15:55:42 <EvanR_> or maybe its just by definition, an effective procedure has to produce an answer in finite number of steps
15:56:39 <ski> (yes, but then there's the question : What does "finite" mean ?. or : What does "natural number" mean ?)
15:56:40 <EvanR_> oh yeah, quantum computer since democritus shoots holes in that idea
15:56:59 <EvanR_> quantum computing since democritus*
15:57:04 <ski> hm, iiuc, quantum computing wouldn't change this, or would it ?
15:57:09 <EvanR_> no
15:57:30 <EvanR_> but i havent gotten to the proof yet
15:57:44 <EvanR_> not that such a proof proves anything about real life
15:58:16 <ski> (iirc, Paul Taylor ("Practical Foundations of Mathematics") mentions three different definitions of "finite", used in categorical settings)
15:58:40 <EvanR_> yeah i think ive seen a total of 6 or 7 so far
15:58:47 <EvanR_> i saw a lot of references to that but no online version
15:59:09 <ski> (then i suppose i don't see what quantum computing has to do with Democritus. perhaps it's just meant as a jest)
15:59:34 <ski> EvanR_ : there is an online version, but fancy symbols are munged
15:59:48 <EvanR_> besides the fact that democritus invented atomic theory, the book is supposedly a big collection of "wtf"s together
15:59:48 * ski has borrowed it from the uni library
15:59:57 <EvanR_> oh right, yeah i cant read it
16:03:12 <ski> hm, this section <http://www.paultaylor.eu/prafm/html/s66.html>
16:04:11 <ski> "finitely enumerated","finitely presented","finitely generated"/"Kuratowski/Burali-Forti finite"
16:04:25 <EvanR_> http://math.andrej.com/2009/09/07/constructive-stone-finite-sets/
16:04:40 * ski nods
16:05:46 <EvanR_> so whats the "stone" thing... like this topic is boring or uninteresting?
16:06:09 <ertes> when would you use the omniscience principle?  i mean: you lose all the advantages of constructive math, and i see no obvious advantage over LEM/choice
16:06:17 <ski> EvanR_ : see <http://math.andrej.com/2009/09/07/constructive-gems-and-stones/>
16:06:59 <ski> ertes : if you can show that your conjecture implies an omniscience principle, then you give up hope of (constructively) proving it
16:07:22 <EvanR_> is your omniscience cloudy? upgrade to LEM today!
16:07:47 <ertes> ah, so you don't assume it for proofs
16:08:02 <EvanR_> it comes out of proofs
16:08:53 <ski> ertes : also, for *particular* domains (even for ones that look and feel "infinite" !), you can (constructively) *prove* some omniscience principles. see "Infinite sets that satisfy the principle of omniscience in any variety of constructive mathematics" by Martín H. Escardó in 2013-09 at <http://www.cs.bham.ac.uk/~mhe/papers/omniscient-journal-revised.pdf>, e.g.
16:09:08 <ski> this is related to
16:09:12 <ski> @where impossible
16:09:12 <lambdabot> <http://math.andrej.com/2007/09/28/seemingly-impossible-functional-programs/>,<http://math.andrej.com/2008/11/21/a-haskell-monad-for-infinite-search-in-finite-time/>
16:10:09 <ertes> yeah…  that immediately reminded me of seemingly-impossible
16:10:24 <ertes> interesting references…  thank you
16:11:39 <ski> for "finitely enumerated", we have an iso with a prefix of the naturals
16:11:46 <ski> for "finitely generated", we have a surjection from a prefix of the naturals
16:12:12 <EvanR_> theres an interesting diamond shape somewhere between 4 kinds of finite
16:13:03 <EvanR_> https://ncatlab.org/nlab/show/finite+set#properties_and_relationships
16:13:33 <ertes> i still haven't found a good intro into the topological/computational aspects of constructive math apart from what i've learned with agda
16:13:46 <EvanR_> im not sure which one is supercanonically called "kuratowski finite"
16:13:47 <ski> for "finitely presented", we have two prefices of the natural numbers, `n' names elements, surjectively, but not necessarily in an injective way; `k' names "laws"/"relations", iow pairs of elements of `n'
16:14:30 <ski> the object, together with the map from `n' to it, is a coequalizer of the two parallel maps from `k' to `n'
16:14:38 <ski> EvanR_ : the fourth ?
16:14:53 <ertes> so this stuff (including seemingly-impossible) is all pretty much black magic to me…  i *kinda* get why it works (it's infinite, yet finitely generated…  you just need to "catch up"), but not at all confident in my mental image
16:15:19 <EvanR_> subfinitely indexed is a combination of being an injection from a finite set and having a surjection to a finite set
16:15:40 <ertes> if anyone has a pointer to an introduction, i'd be very grateful
16:15:55 <EvanR_> i still dont get it completely
16:16:37 <EvanR_> i did find a "noob" overview of abstract stone duality, ill look for it after i eat dinner
16:16:46 <EvanR_> by bauer
16:18:48 <ski> ertes : for some strange reason, some things (like `(|N -> 2) -> 2', or `|N_inf' (the "generic convergent sequence")) that one'd think of as "infinite", behaves "finitely" in certain respects
16:19:53 <ski> ertes : at least for `(|N -> 2) -> 2',`(|N -> |N) -> 2', this requires (anti-classical principles like) bar recursion/induction, or at least the fan principle, iirc
16:20:03 <ski> @where topology
16:20:03 <lambdabot> "topology in Haskell" <http://www.haskell.org/pipermail/haskell/2004-June/014134.html> and "Synthetic topology of data types and classical spaces" <http://www.cs.bham.ac.uk/~mhe/papers/entcs87.(pdf|
16:20:04 <lambdabot> dvi|ps)> by Martn Escard
16:20:05 <ertes> ski: yeah, i've found a brief topological explanation for that somewhere, but didn't get it…  right now i have no idea how topology and computability are related
16:20:10 <ski> ertes : did you look at ^ yet ?
16:20:44 <ertes> "synthetic topology"!  i remember that term, and no, not yet…  i shall do so
16:21:08 <ski> we have a type/topology `Sierpinski' which has two inhabitants, `Terminates' and `_|_'. it has three open sets, the third one being the singleton of `Terminates'
16:21:18 <ski> (`_|_' means "doesn't terminate")
16:21:33 <ski> we can treat `Sierpinski' as some kind of truth-value type
16:22:18 <ski> a continuous/computable map from `X' to `Sierpinski' corresponds to an open set of `X'. a semi-observable "question"/"property"/"experiment"
16:22:55 <ski> we can easily build conjunction. disjunction requires "parallel or"
16:23:55 <ertes> and that gives us product types?
16:24:10 <ertes> along with the corresponding product topology
16:24:12 <ski> in topology, a space being Hausdorff means that distinct points have disjoint neigbourhoods
16:24:38 <ski> in terms of `Sierpinski', this means that there's a computable/continuous *apartness* map from `X * X' to `Sierpinski'
16:25:35 <ski> in toplology, a space being compact means that for any (arbitrary) family of opens, which together cover the space, there is a finite subfamily, which also covers the space
16:25:43 <ski> s/toplology/topology/
16:26:42 <ski> in terms of `Sierpinski', this means that there's a computable/continuous universal quantifier `forall_X : (X -> Sierpinski) -> Sierpinski' where `forall_X p = Terminates' iff `p x = Terminates' for every `x' in `X'
16:28:48 <ertes> that actually makes a lot of sense, if only intuitively…  i'll try to construct all of this myself
16:29:09 <ertes> thanks for that overview, it was very helpful!
16:29:14 * ski nods
16:30:37 <ski> monochrom,EvanR : ty for the discussion,criticism re "dependent","indexed","flexible","iterated","unlimited", earlier, btw
16:31:10 <ski> ertes : several of Martín Escardó's other papers are also interesting
16:31:22 * ski should probably head for bed
16:32:02 <ertes> ski: i wonder if this is mostly of theoretical interest, or there are actual practical applications other than seemingly-impossible
16:32:26 <ertes> (which i consider "of theoretical interest", too)
16:34:44 <dxtr> Can I 'print' to stderr somehow?
16:35:00 <ertes> dxtr: import System.IO, then use (hPrint stderr)
16:35:07 <dxtr> Alright
16:35:10 <Koterpillar> @src print
16:35:11 <lambdabot> print x = putStrLn (show x)
16:35:16 <Koterpillar> @src putStrLn
16:35:16 <lambdabot> putStrLn s = do putStr s; putChar '\n'
16:35:20 <Koterpillar> @src putStr
16:35:20 <lambdabot> putStr s = hPutStr stdout s
16:35:23 <Koterpillar> here you go
16:35:33 <dxtr> Thanks!
16:36:43 <ertes> you need System.IO anyway though, so might as well use hPrint =)
16:54:20 <dxtr> Do you guys like a challenge?
16:54:43 <Koterpillar> everyone likes challenges, not just guys
16:55:12 <markasoftware> sure
16:55:39 <dxtr> I'm toying around with codingame and I can only come up with a horrible solution for this. Hold on!
16:56:36 <dxtr> I would be interested to see what a proper solution would look like :)
16:57:44 <dxtr> Oh maybe it's possible to view it without an account
16:57:49 <dxtr> https://www.codingame.com/ide/puzzle/temperatures <- is that working?
16:58:07 <dxtr> I was preparing a paste of some sort :p 
17:00:18 <MarcelineVQ> you can try it in an incognito window to find out, that loads the default project set to c++
17:00:33 <dxtr> You can't switch to Haskell?
17:00:38 <MarcelineVQ> you can
17:00:52 <dxtr> http://lpaste.net/6755084899125821440 <- That's the paste I was preparing
17:02:16 <dxtr> I can't really come up with a way to simplify that pattern
17:03:02 <MarcelineVQ> are you aware of the abs function?
17:03:28 <Koterpillar> dxtr: `minimumBy`?
17:04:30 <dxtr> abs I knew about but it's one of those functions that I always forget about :)
17:04:47 <dxtr> minimumBy I didn't know about
17:05:49 <Koterpillar> you could also define newtype ClosestToZero = ClosestToZero Int and define Ord on it in a nice way
17:06:53 <markasoftware> dxtr: so I'm not the only one on codingame!
17:07:02 <markasoftware> dxtr: I'm 30th in code golf for temperatures ;)
17:07:40 <markasoftware> i can give you the secret code if you want ;)
17:10:23 <dxtr> markasoftware: Haha
17:12:18 <MarcelineVQ> your paste fails test 3 and 5 for me, were they supposed to?
17:23:02 <dxtr> No :p 
17:23:14 <dxtr> Or, well
17:23:23 <dxtr> Maybe
17:23:46 <dxtr> I hadn't even tried them yet
17:45:21 <Tyg13> does anyone know how to make one field of a record depend upon another, so to speak?
17:46:23 <Tyg13> for example, if I had a data type like `data Blah = Blah { position :: Point, radius :: Double, mkVertices :: Point -> Double -> [Point] }`
17:46:49 <Tyg13> and I wanted mkVertices to be computed on demand, but with the values of position and radius
17:48:10 <blair_> @help
17:48:10 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
17:48:15 <blair_> @help list
17:48:15 <lambdabot> list [module|command]. Show commands for [module] or the module providing [command].
17:48:22 <blair_> @help blair_
17:48:22 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
17:48:26 <Tyg13> lol
17:48:32 <Tyg13> how helpful
17:48:58 <blair_> Haha, oops. I thought it would capture it without sending to the channel
17:49:40 <geekosaur> use /query or /msg for that
17:50:22 <blair_> Dumb question... Is it possible to message myself? (I'm trying to test a feature in my IRC client)
17:51:27 <klub> Hello?
17:55:12 <Cale> klub: hello
17:56:04 <Cale> blair_: Just try it (yes, it's possible)
17:57:08 <klub> wia twut?
17:57:23 <dmj`> Tyg13: depends on what you mean by "depends on"
17:57:48 <blair_> Ha! Thanks Cale. The issue was that my messages to myself didn't give me a "highlight" or whatever. But I got weechat communicating with notify-send
17:58:57 <dmj`> Tyg13: data Foo a = Foo { fieldA :: a, fieldB :: Convert a }; where Convert is a type family. Here fieldB’s type would depend on fieldA’s type
17:59:24 <klub> sorry but im new to irc
18:00:14 <markasoftware> aren't all irc clients handcrafted?
18:00:57 <dyreshark> yeah, a machine-generated IRC client would probably be far more impressive
18:08:59 <geekosaur> Tyg13, since a field accessor is just a function, I'd just define a separate function instead of a field
18:09:09 <MarcelineVQ> dxtr: hehe, alright well when you've got them all passing let me know and I'll share my version if you're interested
18:09:33 <geekosaur> one that looks like a field accessor but actually computes the value given the record, instead of just projecting a field
18:16:50 <dmj`> Tyg13: yea it sounds like what you’re trying to do is define a method on a class that references private fields, I’d advise against this thinking, it sounds too OOP
18:20:16 <geekosaur> ^ that isn't just "down with OOP!"; Haskell is not OO and you can't actually do what you are asking for, in the way you are trying to do it
18:20:38 <geekosaur> a record is not an object, and does not have "methods" either public or private
18:21:32 <geekosaur> (typeclasses have methods, but are also not OOP as you are used to it and will bite you if you try to use them that way. as such, there are also no "private" typeclass methods)
18:26:03 <Cale> Wait, I had an answer for Tyg13: data Blah = Blah { mkVertices :: [Point] }
18:26:45 <Cale> blah position radius = Blah (... position ... radius ...)
18:28:40 <Cale> You can do OOP just fine
18:29:54 <Cale> You define a datatype which consists of all the "public" methods of your object, and then the "private" stuff is all held in parameters to functions that construct such records.
18:54:18 <polll> Is it possible to provide different types to zipWith3? I'd like to provide 2 randomly generated numbers and one specific integer to a data type. https://github.com/paullucas/sidewalk-hs/blob/master/Main.hs#L108
18:55:30 <jmcarthur> You can even define Tyg13's thing in terms of the other fields as request.   blah position radius = let self = Blah { position = position, radius = radius, mkVertices = f (position self) (position radius) } in self    -- but doing it this way is not very useful on its own
18:55:48 <jmcarthur> I messed up the definition, but the idea is there anyway.
18:56:07 <polll> (at the moment I'm providing 806 random numbers to 3 different arguments. I'd like to provide 2 of the arguments with 806 random numbers, and one argument with 806 of the same number)
18:57:03 <Axman6> polll: how about zipWith (\x y -> foo x y 7) xs ys?
18:57:27 <Axman6> if the value isn't changing, it doesn't need to be provided using zipWith
18:59:16 <polll> Thanks so much, Axman6!
19:01:08 <polll> Thanks so much, Axman6!
19:03:12 <Axman6> #haskell, people so nice they get thanked twice
19:07:23 <Koterpillar> is thanking idempotent?
19:11:51 <dyreshark> thanks for the question
19:47:32 <glguy> dxtr: Regarding your temperature paste: minimumBy (comparing (\x -> (abs x, negate x)))
19:48:50 <glguy> or even better... minimumBy (comparing abs <> comparing negate)
19:51:00 <ertes> i need Coyoneda with a cache, i.e. a variant of Coyoneda that does its best never to compute the value twice…  does anyone know of an implementation of that?
19:57:21 <ertes> ah, nevermind…  it wouldn't work anyway
20:06:38 <Henson> if you've created a shared library that exports Haskell functions to be called from C, it turns out that if you try using a sleep function in C, the signals sent within the Haskell runtime cause the sleep to be interrupted.  This same is true if you use Python's ctypes and call Haskell functions from Python while attemping to sleep.  Is there any way around this?  You can use a sleep function...
20:07:25 <Henson> that tells you how much time was remaining when it was interrupted (nanosleep in C, for example), but in Python there isn't.  Furthermore, if you call other libraries in either language, there's no way of knowing if they use sleeps that will be interrupted too early by the Haskell runtime.
20:08:19 <Henson> so it would seem to me that using Haskell functions from a shared object library is a bad idea if there's any possibility that sleep functions (or any functions sensitive to signals) would be called in the foreign language.
20:09:35 <geekosaur> +RTS -V0 is a workaround
20:12:19 <geekosaur> and yes, this is known and I filed a bug against systemd-networkd / dbus because it wasn't allowing for callers that use itimers (the haskell runtime is not the only thing that does this)
20:12:32 <geekosaur> leading to name resolution failures
20:13:35 <Axman6> Henson: if you're relying on sleep for timing, you're probably doing it wrong anyway. the more reliable way is to use an api that says what time to sleep until, and you can check when you get woken if you need to sleep more. not ideal though, might be considered a bug in GHC
20:14:57 <Henson> Axman6: good suggestion.  If I were only using my own code in such a way, I could rely on that, but third party libraries might not be doing that.
20:15:31 <geekosaur> this can't really beconsidered a bug in ghc, it's doing something entirely legitimate
20:16:05 <geekosaur> libraries / languages that use interruptible syscalls, including but not limited to sleep, must handle interruptions 
20:16:10 <Henson> geekosaur: does disabling the RTS clock have any serious side-effects?  The manual says that it causes context switches to happen much faster than normal, and I guess makes heap profiling not work.
20:16:35 <geekosaur> right, it'd break profiling and it changes thread behavior, but usually this is not a problem
20:19:34 <geekosaur> (it got used somewhat widely when ghc 7.2 was current because its runtime had a bug that caused it to fire the itimer far too often, so lots of people got to test +RTS -V0 as a workaround)
20:23:08 <Henson> geekosaur: ok, thanks for the suggestion.  This issue has brought to my attention for the first time that sleep calls can be interrupted!
20:39:32 <o`connor_> Is there an easier way to lift a function like `unless`?
20:39:39 <o`connor_> right now I have: ((liftM2 unless) (return True) (pure $ (putStrLn "hello world"))) >>= \x -> x
20:43:39 <glguy> o`connor_: How about... unless True (putStrLn "hello world")
20:43:44 <glguy> or: return ()
20:52:51 <polll> How would you do something like "case args of ["hello", ANYSTRING]" in haskell? Need to check the 2nd argument is a String
20:53:19 <Axman6> arguments are always strings
20:53:30 <Axman6> :t getArgs
20:53:32 <lambdabot> error: Variable not in scope: getArgs
20:53:38 <Axman6> @hoogle getArgs
20:53:41 <lambdabot> System.Environment getArgs :: IO [String]
20:53:41 <lambdabot> System.Posix.Env.ByteString getArgs :: IO [ByteString]
20:53:41 <lambdabot> System.Environment.Compat getArgs :: IO [String]
20:54:27 <o`connor_> polll: even if args is some arbitrary list [a], all the stuff in it are elements of a. 
20:54:52 <polll> Sorry, I should've been more specific. How do I make sure the first arg is a certain string, but the 2nd arg can be anything? 
20:55:12 <Axman6> you can use ["hello",x] as a pattern
20:55:32 <Axman6> (or, ("hello":x:_) if you are of with extra, ignored args)
20:55:43 <polll> Thanks again, Axman6!
20:55:45 <geekosaur> you may want an option parser instead of working with getArgs directly
20:55:54 <geekosaur> optparse-applicative is common
20:55:57 <Axman6> ["hello",x] is sugar for ("hello":x:[]) btw)
20:57:30 <Axman6> yeah if you want more than the simplest of option parsing, a libvrary like optparse-applicative will make your life a lot easier (though there are several topics you'll probably need to learn, such as Applicative)
20:58:37 <markasoftware> i know it's not a feature, but is it conceptually possible to use any arbitrary expression as a pattern if you had a very smart compiler?
20:58:51 <markasoftware> could any pure function be automatically "reversed"?
20:59:48 <dolio> No.
21:00:22 <pavonia> markasoftware: How would you reverse, say, "\x -> 1"?
21:00:48 <SexHendrix> \1 -> x
21:00:53 <SexHendrix> :^)
21:01:04 * markasoftware shudders
21:01:28 <markasoftware> interesting
21:03:50 <dolio> If you look into the typical foundations of mathematics, functions are defined as special types of relations. 'Running backwards' is like swapping the order of the things in a relation. But doing that to a function doesn't get you a function unless there are additional conditions on the relation.
21:04:36 <markasoftware> well, i guess if every input has a different output
21:04:39 <markasoftware> could you then reverse it?
21:04:49 <markasoftware> and it's deterministic
21:04:55 <markasoftware> well i guess all pure functions are deterministic
21:04:59 <dolio> That is called 'injective' and it is the criterion you need, yes.
21:05:09 <srk> that's the word :D
21:05:35 <dolio> However, just because classical mathematics says you can swap the relation and get a function doesn't mean it's feasible to compute.
21:06:33 <markasoftware> when would it not be?
21:06:36 <dolio> You could also imagine an environment (like logic programming) where the fact that reversing a functional relation doesn't give you a function doesn't matter.
21:06:51 <markasoftware> if you can reverse the very basic built-in haskell functions (which i think you can)
21:06:58 <dolio> Because computation itself isn't deterministic.
21:06:59 <markasoftware> then you can reverse things built on top of that step by step, no?
21:08:29 <codygman> Can yo uuse lenses for things like traversing abstract syntax trees? Specifically I'm using a library that gives a haskell representation of an AST and wondering how I can either use lens with it or derive lenses for it.
21:09:34 <dolio> There are people who study reversible computation, where the whole system is about building things in a way that can easily be run in both directions.
21:10:07 <dolio> See, for instance, Benjamin Pierce and Boomerang.
21:10:59 <dolio> I doubt starting with a language where things aren't necessarily reversible and expecting to detect the cases that are is going to work out.
21:12:40 <codygman> Any good tutorials for working with AST's and making it more convenient by making combinators?
21:13:18 <Axman6> isn't that just "programming in Haskell"? =)
21:13:58 <codygman> Axman6: Well I don't typically code with big nested ADT's and the way I know how to do common things seems quite verbose
21:34:18 <boris_rh> Hello, I have simple question about DataKinds. Here is code snippet: http://lpaste.net/351451
21:35:15 <boris_rh> And I wonder how polymorphic function convert can be implemented (I feel there must be a way)?
21:37:23 <dolio> boris_rh: I don't think you can make it with a type like that.
21:38:31 <dolio> A more accurate type would be `forall st. MyObject -> Maybe (ObjectInState st)`, and because st is quantified in that way, the implementation must be uniform for all choices of st.
21:39:13 <dolio> The eventual plan to have something more like dependent types would allow you to look at the value of st. But you cannot do that.
21:40:17 <boris_rh> dolio: Thanks, so my only option is to implement separate function for every possible state?
21:40:40 <dolio> So instead, you must do something like make a class that tells you which `st` value you have. Or create a GADT that you can analyze on the value level to tell you what the value of `st` is at the type level.
21:42:09 <boris_rh> I just wanted to have function that only accept object in particular state
21:42:28 <boris_rh> not sure I can do that with GADT
21:43:20 <dolio> Well, for instance, you could have 'data MyStateEvidence (st :: MyState) where State1E :: MyStateEvidence State1 ; ...'
21:43:53 <dolio> Then if you have `convert :: MyStateEvidence st -> MyObject -> Maybe (ObjectInState st)`, you can match on the first argument to figure out what `st` is.
21:47:07 <boris_rh> dolio, OK thanks, I will think about your advice, but it looks it also require explicit matching for every possible state
21:47:51 <boris_rh> @karma++ dolio 
21:47:51 <lambdabot> dolio's karma raised to 22.
22:14:47 <patientpl> hi
22:15:15 <patientpl> im trying to get a very simple hello world statement to compile and i copied the first example from the book and got a runtime erro
22:15:17 <patientpl> *error
22:15:27 <patientpl> i was hoping someone could look at this
22:15:37 <patientpl> :: String -> IO ()
22:15:37 <patientpl> x = putStrLn ("Hello, " ++ x ++ "!")
22:15:38 <glguy> Someone will, paste it to http://lpaste.net
22:15:44 <patientpl> gives runtime error
22:15:53 <glguy> patientpl: what do you think that means
22:16:02 <glguy> and what book are you looking at
22:16:02 <patientpl> sayHello.hs:1:1: error: parse error on input ‘::’
22:16:18 <patientpl> *sorry yes, i would use pastebin if the code wasnt a two-liner
22:16:40 <glguy> You'll need something like: sayHello x = putStrLn ("Hello, " ++ x ++ "!")    
22:16:45 <glguy> and sayHello :: String -> IO ()
22:16:49 <patientpl> glguy, you just input x and it says hello x. pretty straightforward i would think
22:17:18 <glguy> Looks like you left off the name of the thing you were defining
22:17:40 <patientpl> aaahhhh
22:17:59 <patientpl> the way they highlighted in the book, made it look like that was part of the command line, thanks a bunch
22:19:20 <patientpl> wait no that doesnt work either
22:19:28 <patientpl> sayHello :: String -> IO ()
22:19:28 <patientpl> sayHello x = putStrLn ("Hello, " ++ x ++ "!")
22:19:54 <patientpl> sayHello :: String -> IO ()
22:19:55 <patientpl> sayHello x = putStrLn ("Hello, " ++ x ++ "!")
22:19:59 <patientpl> shoot hold on
22:20:12 <patientpl> Prelude> load sayHello.hs
22:20:12 <patientpl> <interactive>:2:1: error:
22:20:12 <patientpl>     Variable not in scope: load :: t0 -> b0 -> c
22:20:12 <patientpl> <interactive>:2:6: error: Variable not in scope: sayHello
22:20:12 <patientpl> <interactive>:2:15: error: Variable not in scope: hs :: a -> b0
22:20:31 <patientpl> so the above is my function and the bottom part is the error..........something is still not right
22:20:43 <monochrom> it's :load, not load
22:21:07 <patientpl> darn ok
22:21:16 <patientpl> too tired for this i should just quit while im behind
23:38:27 <EvilMachine> Hi. I just thought about extending laziness and stream fusion to IO beyond Haskell’s inner world. E.g. with the source stream being a downloading archive, and the target stream being e.g. an unpacked file system accessed by other programs.
23:39:41 <EvilMachine> It sounds like a neat generalized way to develop software in, to accelerate everything, and I wonder how far it can be automated away so one doesn’t have to implement it oneself every time.
23:42:59 <fazil[m]> :D
23:43:59 <mfukar> kind of like unix, one would say
23:44:27 <fazil[m]> there is no emoji?
23:44:30 <EvilMachine> mfukar: beyond that, no?
23:44:51 * EvilMachine is thinking of Plan 9, and then some.
