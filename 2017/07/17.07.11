00:01:45 <EvanR> http://conal.net/blog/posts/notions-of-purity-in-haskell
00:02:23 <EvanR> > System.Info.os
00:02:26 <lambdabot>  error:
00:02:26 <lambdabot>      Not in scope: ‘System.Info.os’
00:02:26 <lambdabot>      No module named ‘System.Info’ is imported.
00:03:15 <cocreature> srhb: afaik it’s the shell that changes it
00:03:41 <quchen> How do I write my own Text.Printf instances? I thought it was opened some time ago, but it seems the main functionality is still private
00:04:11 <quchen> Ooh, nevermind.
00:04:28 <quchen> I overlooked the section »Extending To New Types«.
00:04:30 <quchen> :-S
00:14:48 <EvanR> in a comment of that post, they mention the possibility that a single functional program, during runtime, maybe have different threads experiencing different behaviors of Int
00:15:20 <EvanR> "thats crazy", except cloud haskell!
00:15:37 <EvanR> i wonder how they deal with it
00:15:45 <srhb> EvanR: "not" I suspect :-P
00:16:20 <EvanR> "dont use Int" ? :)
00:16:56 <mojjo> hi! Consider a simple 2D Vector Type: `data Vec a = Vec a a`. I'm looking for the proper typeclass abstraction, that would let me apply a binary function to the two elements of a vector. E.g.: `magic (+) (Vec 1 2)` --> 3
00:17:23 <merijn> EvanR: What's the name of the comment?
00:17:52 <EvanR> 8
00:18:03 <EvanR> i dont see a permalink link
00:18:33 <EvanR> http://conal.net/blog/posts/notions-of-purity-in-haskell#comment-402
00:19:04 <srhb> mojjo: fmap
00:19:20 <EvanR> the whole idea of Int is now really bugging me, more than before!
00:19:28 <srhb> mojjo: ie. Functor is that abstraction :)
00:19:42 <srhb> Er
00:19:44 <srhb> No
00:19:49 <srhb> I misread your request entirely
00:19:50 <merijn> EvanR: ah, that was a proposal, not something that happened yet
00:20:01 <EvanR> well, isnt this basically cloud haskell
00:20:17 <mojjo> srhb: Mh, my Functor instance already looks like this: `fmap f (Vec x y) = Vec (f x) (f y)`
00:20:19 <merijn> EvanR: Not quite, afaik
00:20:19 <srhb> mojjo: Foldable :)
00:20:46 <merijn> EvanR: I don't think cloud haskell gracefull handles communicating Int to other architectures, for one
00:20:47 <srhb> mojjo: then it would be `sum (Vec 1 2)`
00:20:51 <srhb> :t sum
00:20:52 <lambdabot> (Num a, Foldable t) => t a -> a
00:21:07 <mojjo> srhb: ahh, yes... this sound good..
00:21:41 <cocreature> the default implementation of sum is kind of shitty for most types so you probably want to overwrite it
00:21:44 <EvanR> now which type class will let me do sqrt(x^2 + y^2) :)
00:22:10 <cocreature> EvanR: I’m sure there is something in linear :)
00:22:19 <cocreature> https://hackage.haskell.org/package/linear-1.20.6/docs/Linear-Metric.html#v:norm
00:22:30 <srhb> That package is fantastic.
00:22:46 <mojjo> EvanR: ha, this is exactly the thing which lead me to my question :)
00:23:04 <EvanR> which type class will let me do f x y for some f!
00:23:18 <EvanR> er, any f
00:23:33 <srhb> EvanR: The other one was more fun :-P
00:27:52 <jared-w> cocreature: you can overwrite sum?
00:29:08 <EvanR> i know this was decided on in the 1980s A.D. but... still... what is the rationale for having Int (no number) have stochastic semantics instead of saying "there is an Int32 and an Int64 (among others), pick your poison"
00:29:27 <EvanR> which have predictable semantics
00:30:35 <merijn> EvanR: Int has predictable semantics, up 2^29 (iirc?)
00:30:59 <jared-w> It's "at least the range [-2^29 .. 2^29-1]"
00:30:59 <EvanR> ... yeah something like that, and thats not how its used in practice
00:31:02 <mojjo> srhb: well, if I implement `foldMap f (Vec x y) = f x `mappend` f y` I can do what you suggest: `sum (Vec 1 2)`, but how would I go for something not monoidal, say I'd like to get the aspect ratio of a vector, which would be x/y ?
00:31:04 <jared-w> which sounds terrible
00:31:29 <merijn> EvanR: Because we only really use GHC
00:31:35 <merijn> jared-w: Why does it sound terrible?
00:31:37 <EvanR> overflow is allowed and isnt an error and its not clear what happens
00:31:39 <cocreature> jared-w: yes it’s a class method
00:31:48 <jared-w> Right and left shifts also don't have C behavior, which seems odd
00:32:13 <merijn> jared-w: I think that's probably wise, as C behaviour is undefined for overflows, which is...bad
00:32:23 <jared-w> merijn: because "at least..." to me sounds like "we use the default int on your system. Hope you like guessing which range it is! Better hope your number overflow errors don't happen randomly on only certain computers"
00:32:33 <EvanR> i would like to call attention back to my question, merijn's remark should be construed as an answer or "questions wrong" answer
00:32:41 <EvanR> shouldnt*
00:32:45 <merijn> jared-w: Well, that's the same as C, isn't it?
00:33:03 <merijn> jared-w: int is defined to be "at least..." in C too
00:33:20 <jared-w> for the standard 'int', yeah. There's a reason I've never seen 'int' in real C code and only seen the sized standard ones used for "real" code
00:33:42 <merijn> jared-w: It's slightly less than 32 bits, because when the Haskell Report was specified they reserved some bits for tagging
00:33:45 <EvanR> the situation is similar to but not exactly the same as in C which predates the 1980s, that is true. still would like an explanation
00:33:45 <nshepperd_> In theory it's faster if you have a type with weakly constrained semantics like Int so you can use whatever's most efficient on the platform
00:33:48 <merijn> jared-w: The real crime isn't Int's definition
00:33:55 <merijn> jared-w: The real crime is Int being used everywhere
00:34:11 <merijn> jared-w: If all of base had simply used Integer the world would've been fine
00:34:28 <EvanR> nshepperd_: your program behaves in an underdefined way ... faster?
00:34:34 <merijn> jared-w: In "real" haskell you probably wanna use Integer or the sized versions of Int/Word anyway
00:34:58 <jared-w> Definitely an issue. Integer seems really slow, though? I see a lot of articles where they achieve quite a bit of speedup by using Int over Integer and other such optimizations
00:34:58 <EvanR> being used everywhere seems like the whole point?
00:35:00 <merijn> jared-w: But base makes that hard
00:35:05 <EvanR> otherwise, what use would it have?
00:35:22 <merijn> jared-w: Well, Int can be unboxed completely if GHC analysis things, which can have a lot of speedup
00:35:36 <merijn> jared-w: but in the grand scheme of things Integer is definitely *not* slow
00:35:43 <EvanR> Integer is not "really" slow
00:35:49 <nshepperd_> EvanR: you're supposed to check that your numbers are less than 2^29
00:35:55 <merijn> jared-w: It's just that "optimised unboxed Int" is like ultra super-duper fast
00:36:02 <nshepperd_> Then it's well defined and possibly faster
00:36:17 <EvanR> nshepperd_: an Int that crashes if your math goes above 2^29, now that would make me feel better
00:36:24 <merijn> > 2 ^ 570917597915795797975 :: Integer
00:36:31 <lambdabot>  mueval: ExitFailure 1
00:36:33 <merijn> aww
00:36:35 <EvanR> and would probably piss people off
00:36:37 <nshepperd_> The problem is, in practice people rely on the implementation defined behavior and you get bugs
00:36:40 <merijn> You're not helping my point here, lambdabot
00:36:48 <jared-w> > 2 ^ 2000 :: Integer
00:36:50 <lambdabot>  1148130695274254524232833201177681984022317702088695200477642736825766261392...
00:36:55 <jared-w> > 2 ^ 2000 :: Int
00:36:58 <lambdabot>  0
00:37:29 <EvanR> Int essentially acts like "unsafeInt"
00:37:50 <merijn> EvanR: I think Haskell needs a more Habit like version of number infrastructure
00:37:50 <EvanR> as if arrays had no bounds checks
00:37:50 <jared-w> EvanR: I'd still really like it if Integer was able to be much more readily unboxed and optimized at compiletime
00:37:53 <exio4> I often end up using Integer or WordN on my code :P 
00:38:08 <merijn> But I don't see Haskell changing to that (too breaking in backwards compat)
00:38:12 <merijn> And Habit seems to be dead
00:38:25 <jared-w> foldr (+) [1..N :: Int] shouldn't be way faster than foldr (+) [1..N :: Integer]
00:38:36 <jared-w> merijn: I don't think Habit is dead, it's just suffering from some lack of funding right now, iirc?
00:38:46 <merijn> jared-w: That would require something like dependent types to bound the size of the Integer
00:38:54 <merijn> jared-w: Well, that sounds dead to me :)
00:39:07 <merijn> jared-w: I've only seen a language spec, no implementation and that's years old
00:39:14 <EvanR> jared-w: Integer is currently implemented as a sum of Int (no number) and GMP 
00:39:21 <EvanR> so its not always incredibly slow
00:39:30 <jared-w> I believe most of the professors still are at PSU, so I could ask them about the status of it when school gets back in?
00:39:34 <EvanR> not sure what replacements for Integer do
00:39:37 <merijn> EvanR: The slowness is not the operations, it's the inability to unbox
00:39:57 <EvanR> i dont expect Int to be unboxed most of the time
00:40:00 <EvanR> or Floats
00:40:08 <EvanR> unless i try
00:40:21 <merijn> Well, if Int isn't unboxed it should be nearly the same as Integer, yes
00:40:25 <jared-w> Right, the unboxing would be great. I was sort of hoping that unboxing could happen from some sort of static analysis where they realize "oh the numbers never go above a certain range, so let's fit it in a faster number"?
00:40:46 <EvanR> automatic number theory :)
00:40:51 <jared-w> merijn: but, that wouldn't work, and dependent types would be more or less required?
00:41:25 <merijn> jared-w: That's what I meant earlier, yes
00:42:25 * hackagebot haskell-import-graph 1.0.2 – create haskell import graph for graphviz – https://hackage.haskell.org/package/haskell-import-graph
00:42:32 <EvanR> any sort of attempt to make Integer the default, with these optimizations or however, youd also need to IMO rename it to Int
00:42:38 <EvanR> because Integer is long as hell
00:43:51 <jared-w> yeah idk why we even have a difference between Int and Integer. It should just be Integer and IntX where X is the size. Haskell has a strong emphasis on beautiful abstractions and type safety and nothing screams "fuk ya type safety" like "well I guess the definition of Int is mostly about this size... probably"
00:44:04 <EvanR> we have Float and Double... and people live with their sins of choosing one or the other, or do insane CPP to make it a configuration option
00:44:22 <EvanR> yet have to accept this oddball Int situation
00:44:41 <EvanR> at the same time
00:44:48 <merijn> jared-w: Historical warts
00:44:52 * jared-w would enjoy seeing Float destroyed and burned in a fire, never to be seen again
00:45:00 <merijn> Oi!
00:45:05 <merijn> I need Float :(
00:45:09 <EvanR> what?
00:45:28 <EvanR> and do some weirdo thing with Double ? it might be 32 or 64 or 80 or 128 whatever?
00:45:30 * jared-w would also enjoy seeing "Historical Warts" lose its convincing flavor for being a reason why something still sucks
00:46:09 <EvanR> floating math is tricky enough without knowing your precision
00:46:22 <EvanR> without... NOT knowing
00:46:32 <merijn> jared-w: It's not convincing why it still sucks, it's an explanation of how the situation came to be. The reason for it *still* sucking is the fact that changing it would break all existing code
00:46:33 <EvanR> with knowing!
00:46:35 <jared-w> EvanR: Nah, there should be an IntX and a FloatX for bounded precision and an Int and Float for unbounded precision
00:46:47 <merijn> eh
00:46:58 <EvanR> ... im not sure unbounded float makes the same kind of sense
00:47:01 <merijn> Float is just C's "float" which actually does have a defined size
00:47:08 <jared-w> If you're going to have a non-arbitrary type, it just seems ridiculous to say "well it's only mostly not arbitrary"
00:47:14 <EvanR> merijn: not really!
00:47:19 <merijn> Unbounded float does not make sense no, although there's types that approach it
00:47:27 <merijn> EvanR: What not really?
00:47:28 <jared-w> C does this because C started as a huge ugly hack/glorified assembly port
00:48:14 <EvanR> what is the off topic fact of the matter, double is at least as big as float
00:48:26 <jared-w> EvanR: There exist arbitrary precision floating point libraries out there
00:48:41 <merijn> EvanR: wut...what you're saying is wrong in both C and Haskell
00:48:42 <EvanR> jared-w: yes, you choose a particular precision, it doesnt just go however far it pleases
00:49:04 <merijn> At least in GHC Haskell, but lemme grab the report to verify that it's the same there
00:49:34 <jared-w> True. I suppose it would be pretty interesting to use laziness + symbolic magic and see how far that gets you... But no, a particular precision would have to be chosen, you're right
00:50:20 <jared-w> Wolfram's language has real "arbitrary numbers" where you don't pick a precision, but that's a bit of an exception I think
00:50:43 <merijn> EvanR: Ok, the report doesn't define Float and Double to be the corresponding IEEE-754 types, but suggests that they *should* be. And GHC clearly documents that they *are*
00:50:59 <EvanR> its the same in C
00:51:39 <jared-w> anyway, I should probably stop derailing the conversation and head to sleep :p
00:51:59 <wz1000> There are implementations of exact real arithmetic in haskell
00:52:02 <merijn> EvanR: There you are *definitely* wrong, because I have the C11 standard open right there
00:52:07 <wz1000> http://www2.arnes.si/~abizja4/hera/
00:52:42 <jared-w> wz1000: exact real arithmetic?
00:52:47 <merijn> EvanR: Annex F.2, "The float type matches the IEC 60559 single format." "The double type matches the IEC 60559 double format."
00:52:48 <wz1000> https://www.youtube.com/watch?v=LJQgYBQFtSE
00:52:52 <wz1000> jared-w: ^
00:52:53 <jared-w> You need to be careful when mentioning the Reals :p
00:53:09 <EvanR> yeah later version of C may have defined it as literally IEEE
00:53:13 <wz1000> using continued fractions other techniques
00:53:18 <merijn> EvanR: IEC 60559 being the ISO numbering for IEEE-754
00:53:25 <EvanR> but originally!
00:54:01 <wz1000> jared-w: the stuff I'm talking about is capabale of dealing with *any* real number
00:54:02 <merijn> EvanR: Pretty sure C99 already had this, so maybe in C89, ANSI, or K&R. But those are stupid standards anyway
00:54:12 <Freundlich> merijn: The Annex is not normative so it doesn't matter what's in there.
00:54:16 <EvanR> also the 80-bit extended precision thing is not double precision
00:54:17 <merijn> Freundlich: It is
00:54:24 <Freundlich> C makes zero guarantees about float.
00:54:34 <EvanR> and you get different answers when its used
00:54:40 <merijn> Freundlich: C doesn't require float/double to exist, but IF it exists it must be IEEE-754
00:54:52 <jared-w> wz1000: really? There are real numbers that are not computable
00:55:08 <EvanR> jared-w: are there? :)
00:55:09 <merijn> Freundlich: I have the standard open on Annex F right now and it literally says "(normative)" right there below the annex title
00:55:25 <wz1000> jared-w: yes, ony the computable ones, sorry..
00:55:41 <Freundlich> merijn: Oh, so some parts of the annex are normative? I have never seen that before. That's confusing.
00:55:50 <jared-w> EvanR: Chaitin's constant, \Sigma_i^inf 2^{-BB(i)} wher BB is the busy beaver function, 
00:56:18 <merijn> Freundlich: Annex D, F, G, K, and L are normative
00:56:28 <EvanR> jared-w: we all know these stories
00:56:46 <EvanR> kind of like jack and the beanstalk
00:56:48 <jared-w> I'm just being pedantic and poking a bit of fun at wz1000, no worries :) Real numbers are way too weird
00:56:49 <wz1000> EvanR: computable reals can be mapped one-to-one and onto thes integers (that represent the TM that generates that number)
00:57:07 <EvanR> now computably though
00:57:11 <EvanR> not*
00:57:22 <wz1000> but the cardinality of the reals > cardinality of integers
00:57:26 <merijn> Freundlich: However, afaict, the reason they're annexes is because their optional, so implementations don't have to implement them
00:57:34 <EvanR> another story!
00:58:11 <EvanR> when we arbitrarily mix all meanings of existence what do you get
00:58:13 <Freundlich> merijn: But float itself is part of the language, so they don't have to implement the annex which means it's not guaranteed to be IEEE-754? I'm really confused now.
00:59:07 <EvanR> C predates IEEE-754, so it wouldnt have made sense to originally defined them that way
00:59:51 <merijn> Freundlich: hmmm, maybe only implementations that define "__STDC_IEC_559__" have to implement it
00:59:54 <EvanR> lucky, but acausal
00:59:58 <merijn> I wonder if posix guarantees that
01:00:31 <EvanR> does GHC take liberties with extended precision floats?
01:00:40 <Freundlich> I mean, it's similar for C++ where you can ask "is my float type IEEE-754 or not?".
01:01:15 <merijn> EvanR: Does GHC have extended precision floats?
01:01:41 <EvanR> i mean, you use Double and the code calculates with higher precision
01:01:46 <merijn> Freundlich: I suspect (but can't quickly find) that POSIX requires IEEE-754 and otherwise certainly all common ABIs will specify that
01:01:51 <EvanR> like your favorite language X
01:02:04 <Freundlich> merijn: Yes, probably.
01:02:31 <merijn> Since POSIX specifies other sane things about C too, like void* being able to store function pointers.
01:03:31 * hackagebot ghc-timers 0.1.0.0 – Provides bindings to functions starting and stopping the RTS timers – https://hackage.haskell.org/package/ghc-timers
01:04:12 <Enamex> Hello o/
01:06:37 <Enamex> Is there any comparison piece or comments on Peggy vs (Mega)Parsec? Or just Parsec's approach and PEG implementations in general (though I know of Peggy only). _
01:08:22 <`Guest00000> when thinking about implementing things in Haskell, i always end up thinking about ways to extend Haskell's data model to include some more explicitness and control over evaluation state
01:09:44 <merijn> `Guest00000: Why's that?
01:09:58 <`Guest00000> for example, today:
01:12:04 <`Guest00000> i need a type which stores an integer. this type is intended for computations where this integer is computed by repeatedly trying all integers upwards until we find one that is right
01:13:26 <`Guest00000> i can store it as [()] , where each new element denotes that the integer is larger than a tried one, and end of list denoted a successfl integer
01:13:39 <`Guest00000> but [()] is linear in size in memory
01:13:51 <`Guest00000> i want to optimize that
01:13:54 <merijn> huh, how does [()] make sense?
01:15:49 <`Guest00000> merijn: imagine [Bool] where all booleans before a certain one are False, then this certain boolean is True and then the list ends, because we don't need it. now, we can throw away True, because it's last; and because all bools are now False, we just use ()
01:16:10 <merijn> But why do you even need a list?
01:16:47 <`Guest00000> for recursion
01:16:59 <merijn> Why do you need a list for recursion?
01:17:12 <`Guest00000> sorry didn't mention
01:17:22 <`Guest00000> because usual Int's are wholly strict 
01:17:26 <merijn> You could just recurse with an integer
01:17:39 <`Guest00000> merijn: but only explicitly
01:17:50 <`Guest00000> i can use value recursion
01:17:55 <`Guest00000> with [()]
01:18:26 <`Guest00000> a thing needs info about its own result, but only partial
01:18:34 <erisco> sounds like you're talking about an integer where you do not necessarily know its true value but you know it is at least yea big
01:19:17 <YongJoon> exit
01:19:28 <EvanR> "It does make me think that perhaps the real numbers are problematic and cannot be taken for granted." -- chaitin
01:21:39 <erisco> `Guest00000, why only explicitly and what is "value recursion"?
01:21:44 <EvanR> cantor put them on too high a pedestal
01:22:12 <`Guest00000> erisco: value recursion is: l = 5 : l
01:22:15 <geekosaur> only if you think about it that way; one could argue diagonalization knocked them off it :)
01:22:15 <wz1000> `Guest00000: I think you need data Nat = Zero | Succ Nat
01:22:58 <erisco> I tried to take the reals seriously but when calculating pi it said 8008135
01:23:24 <`Guest00000> only explicitly because a usual Integer has only one level of strictness; once you know anything about it you know it fully
01:23:32 <geekosaur> and as for this, I'm unclear as to how this is not data Possible = AtLeast | Exactly; data SomeVal = SomeVal Possible Int
01:24:52 <erisco> `Guest00000, but "value" recursion as opposed to what? type recursion?
01:25:04 <EvanR> code recursion
01:25:48 <EvanR> recursive function "call"s
01:26:13 <EvanR> whats not opposed is type recursion
01:26:33 <EvanR> Nat = Z | S Nat
01:26:49 <EvanR> same form as value recursion
01:27:31 <erisco> `Guest00000, so what facts about an integer do you want to reveal without revealing the whole integer?
01:27:35 <`Guest00000> erisco: explicit iteration: of the form (last $ unfoldr f i)
01:27:54 <`Guest00000> erisco: Nat form is fine for me
01:28:17 <`Guest00000> [()] is isomorphic to Nat
01:28:20 <`Guest00000> so
01:28:42 <`Guest00000> i want a partially computed Nat to be stored as a big integer with a flag
01:28:51 <`Guest00000> and not linearly
01:29:19 <EvanR> you can also cut down on the size of an unary by using binary
01:29:24 <cocreature> data Nat = Zero | Add !Natural Nat
01:30:22 <erisco> Integer is logarithmic in space, and I still do not know what a partially computed Nat is
01:30:32 <EvanR> data Nat = Zero | Add Nat Nat | Mul Nat Nat | Pow Nat Nat
01:30:40 <erisco> what is partial about it? the same question is what do you want to know about the Nat that isn't the whole of the Nat
01:30:45 <EvanR> i guess that never gets anywhere
01:31:04 <`Guest00000> erisco: a partially computed Nat is e. g. S (S (S (*thunk*)))
01:31:06 <erisco> I am not saying this is a crazy wish, I just want to know exactly what information you're looking for
01:31:10 <EvanR> erisco: you could know its at least n
01:31:14 <`Guest00000> it's no less than 3
01:31:22 <`Guest00000> but it's still unknown otherwise
01:31:24 <cocreature> EvanR: you can get one via Pow 0 0 and then you can get the rest
01:31:31 <erisco> okay, so a minimum bound like I suspected earlier?
01:31:39 <EvanR> for some reason i figured Pow 0 0 is 0
01:31:41 <Enamex> Is there any way to get Stack on install on Linux without root? In user dir.
01:31:57 <erisco> if that is all you want to know then just store the minimum bound as Integer
01:32:16 <EvanR> or Natural
01:32:52 <`Guest00000> erisco: but then no value recursion
01:33:07 <erisco> what is this recursion you are looking for?
01:33:35 <`Guest00000> ?
01:33:51 <erisco> I am just as confused
01:34:15 <cocreature> `Guest00000: so what’s wrong with the type I showed you?
01:34:25 <minn> I need to tokenize some source files and analyze the resulting token sequences. The files contain Unicode identifiers. Knowing the line numbers and line offsets of each token is important. Is Alex my best choice (or should I use something else)?
01:34:30 <`Guest00000> i don't understand the phrase 'what is this recursion'
01:34:33 <`Guest00000> erisco
01:35:07 <erisco> I have never heard anyone specify that they want "value recursion", which I suspect is just "recursion", without any other qualifiers
01:35:12 <erisco> recurse on what?
01:35:38 <merijn> minn: I usually do both parsing and tokenisation using whatever parser combinator library
01:35:48 <`Guest00000> cocreature: you're proposing to store it as a lazy sum of strict naturals, right?
01:35:59 <cocreature> `Guest00000: right
01:37:45 <`Guest00000> then any algorithms wishing to raise the lower bound in small steps have to output those steps each time, which is just not better than Nat itself (asymptotically)
01:37:55 <minn> merijn: I never found parser combinators to be the right tool for lexical analysis, but I would be willing to give it a shot.
01:38:09 <EvanR> `Guest00000: moving goal posts?
01:38:14 <EvanR> you were concerned about the space usage
01:38:33 <cocreature> `Guest00000: I think you really need to provide some sample code demonstrating what you want to do. I don’t think anybody really understands the problem you’re trying to solve
01:42:13 <`Guest00000> EvanR: i'm talking about space
01:42:55 <EvanR> by what activity would you make progress in these computations
01:42:56 <`Guest00000> S (S (S (...))) turns into Add 2 (Add 2 (Add 2 (...)))
01:44:06 <EvanR> well, if thats true, you just cut space in half
01:44:24 <cocreature> and you can even run some compression function to get to Add 6 (..)
01:44:41 <erisco> that depends on how you represent 6
01:45:01 <`Guest00000> a compression function would only introduce delays to the stream, which could be fatal
01:45:02 <EvanR> a single careful pencil stroke
01:46:01 <EvanR> well, if you never evaluate it at all, you get perfect space usage, nothing!
01:46:17 <EvanR> indistinguishable from no program
01:48:15 <erisco> okay, shot in the dark, what about MyInt = [Integer] i.e. a list of increasing integers that better approximate the true value
01:49:27 <erisco> which is close to [()], only you have the aggregate sum as you go
01:50:20 <EvanR> someone already suggested data Hmm = Exactly Integer | AtLeast Integer Hmm
01:50:26 <erisco> it has the easy smart constructor of [0..n]
01:50:38 <erisco> or just [n] works, heh, if you already know n
01:50:59 <EvanR> [Integer] has the defect of allowing []
01:51:03 <erisco> yeah, same thing, other than that takes care of not being empty
01:51:09 <erisco> NonEmpty Integer... it is in base now I hear
01:51:27 <EvanR> bleh
01:53:04 <erisco> it is certainly more flexible than [()] because the integers do not have to be successors
01:53:20 <erisco> but might pay a bit more exploring a sum, say
01:53:46 <EvanR> improving numbers
01:53:55 <erisco> that sounds like a paper title
01:54:45 <EvanR> well, would be nice if the answers were converging to something
01:54:52 <EvanR> and you knew it
01:55:18 <EvanR> at this rate you can give someone the nonsense infinite Nat
01:55:53 <EvanR> the very inefficient bottom
01:55:57 <erisco> yeah... a list with length is doable
01:56:14 <erisco> the increasing bit maybe not
01:56:31 <EvanR> that might put too much strain on construction, having to know how many steps you will need to take
01:56:53 <`Guest00000> isn't MyInt analogous to Add !Natural Nat?
01:56:57 <EvanR> trivial if you start from the answer and work your way backward!
01:56:59 <erisco> it is more information than "not infinite", yeah
01:57:26 <`Guest00000> or Add Integer Nat
01:57:37 <erisco> `Guest00000, no, it is not addition
01:57:44 <EvanR> not infinite would be the proper amount of information i was talking about
01:57:54 <`Guest00000> but space usage is same
01:57:57 <erisco> [0,2,7,10,11]  represents the number 11
01:57:57 <`Guest00000> O(steps count)
01:58:13 <erisco> it is just a list of increasing integers where the last is the true value
01:58:56 <erisco> what is "steps count"?
01:59:44 <`Guest00000> a step is the event of algorithm producing a new summand or a new integer in the stream/sequence
02:00:03 <erisco> and why do you think it requires the same space?
02:00:07 <`Guest00000> a new step is, trivially, a new list element
02:01:11 <erisco> > sum [1..1000000]
02:01:14 <lambdabot>  *Exception: stack overflow
02:01:21 <erisco> is sum that stupid? -.-
02:01:24 <EvanR> yes
02:01:36 <Ke> <3
02:01:37 <erisco> > foldl' (+) 0 [1..1000000]
02:01:39 <lambdabot>  500000500000
02:01:52 <EvanR> unless you compile it?
02:01:53 <MarcelineVQ> :t sum
02:01:54 <lambdabot> (Num a, Foldable t) => t a -> a
02:01:55 <erisco> it didn't allocate a list of a million integers and then sum them
02:01:56 <MarcelineVQ> depends on the sum
02:02:13 <erisco> oh, they generalised to Foldable, okay
02:02:14 <`Guest00000> so, this sequence is either just stored, or somehow wound so that it'll be released from head as its inits become unneeded
02:02:27 <`Guest00000> sum [1..1000000 :: Int]
02:02:31 <`Guest00000> > sum [1..1000000 :: Int]
02:02:33 <lambdabot>  *Exception: stack overflow
02:02:36 <`Guest00000> nooo
02:02:37 <EvanR> erisco: effectively yes
02:02:46 <EvanR> it does
02:02:52 <erisco> well yes, but it didn't have it all around at once :P
02:03:05 <erisco> my "and then" was to indicate that the first happened completely before the second began
02:03:06 <merijn> erisco: sum wasn't strict before Foldable either
02:03:17 <EvanR> erisco: yeah, it does :)
02:03:27 <merijn> Which is dumb
02:03:28 <cocreature> the general sum in Foldable is even crappier than the one in the Foldable instance of []
02:03:34 <cocreature> the one in [] at least uses foldl
02:03:35 <erisco> EvanR, what are you on about?
02:03:42 <cocreature> so ghc can usually optimize it
02:03:47 <cocreature> the one in Foldable is a foldr
02:04:01 <cocreature> (or rather a foldMap but the default implementation of that is using foldr)
02:04:01 <EvanR> erisco: old foldl sum (if not optimized) essentially played out the whole list, then added up the terms
02:04:14 <EvanR> in the order
02:05:01 <EvanR> im not sure whats better foldl or foldr 
02:05:04 <EvanR> for sum
02:05:14 <cocreature> EvanR: ghc can optimize foldl to foldl' in most cases
02:05:19 <cocreature> it won’t optimize foldr to foldl'
02:05:22 <EvanR> besides that
02:05:29 <cocreature> well that’s a pretty important point
02:05:30 <EvanR> the unoptimized case
02:05:33 <cocreature> ah ok
02:05:35 <erisco> okay, whatever, point being that the memory use is not linear just because our representation may have n integers in it
02:05:57 <cocreature> erisco: but it was linear even before it was generalized
02:05:59 <cocreature> it was always crap
02:06:05 <erisco> not talking about sum
02:06:08 <EvanR> the particular point you mention was lost long ago
02:06:15 * erisco sighs
02:06:17 <EvanR> lol
02:06:40 <cocreature> oh sry
02:06:57 <EvanR> pop the conversation stack
02:09:57 <erisco> `Guest00000, yes, in practice the things which are not needed are forgotten
02:10:06 <`Guest00000> what does the value of the needed type provide as a current-least-bound API? either just a Nat, or the Add Nat Nat thing, or MyInt, in which case the whole thing is stored, or i don't know what
02:10:17 <erisco> I have to defer to someone who knows a lot more about GHC to indicate the ways in which that might happen
02:10:24 <`Guest00000> a function () -> MyInt
02:10:34 <ventonegro> Does anybody else declare <+> = mappend just to make it align?
02:10:57 <ventonegro> Asking for a friend
02:11:07 <erisco> to make it align with what? <*>?
02:11:25 <ventonegro> <*>, <$>, even with =
02:11:50 <MarcelineVQ> I just use spaces to align things, but I'm weird like that
02:11:54 <erisco> the way I format things wouldn't have those being aligned
02:12:16 <erisco> I align like with like
02:12:20 <merijn> erisco: If you have very large numbers of arguments you wanna linebreak and personally I start continuations with operators
02:12:25 <merijn> erisco: It's nice if those align
02:12:41 <`Guest00000> in which case something will be computed again and again in some cases
02:12:45 <ventonegro> MarcelineVQ: It looks ugly because it's "unbalanced" below tokens with an odd number of symbols
02:13:24 <merijn> ventonegro: I don't define it like that, but I understand your pain ;)
02:13:57 <ventonegro> merijn: :)
02:14:04 <`Guest00000> so
02:14:17 <merijn> My pet peeve is the seperator of forall is a single .
02:14:28 <merijn> Which means I can't nicely align long type signatures
02:14:35 <ventonegro> Case in point: http://lpaste.net/356856
02:15:20 <EvanR> $-signs....
02:15:30 <EvanR> gross
02:15:41 <merijn> ventonegro: Why "let in" instead of where?
02:15:54 <MarcelineVQ> I do however usually align let and in
02:16:03 <ventonegro> merijn: No reason
02:16:04 <merijn> I just don't use let and in ;)
02:16:15 <EvanR> let in usually messes everything up
02:16:18 <erisco> let me get my hands on that...
02:16:25 <EvanR> unless you used only let in, and lots of them
02:16:48 <EvanR> including multiple ins
02:17:15 <EvanR> (which you pretty much have to do in idris)
02:18:48 <EvanR> im about to rewrite your code, but i realize what im about to do could be automated...
02:19:05 <EvanR> i wish the automation was automatically automated already
02:19:55 <merijn> ventonegro: where makes everything better: http://lpaste.net/356856
02:20:21 <erisco> ventonegro, I annotated with more or less how I format my code http://lpaste.net/356856
02:20:24 <merijn> the top 2 still need to be improved, but still
02:20:46 <merijn> erisco: Mine is clearly superior ;)
02:20:57 <erisco> the empty comments are mostly so my indenter doesn't go on the fritz
02:21:09 <`Guest00000> > [x, y]
02:21:11 <lambdabot>  [x,y]
02:21:24 <`Guest00000> damn, it's so nice
02:21:32 <kuribas``> I benchmarked sum: http://paste.lisp.org/display/350562
02:21:43 <kuribas``> surprisingly foldr is faster than foldl
02:22:00 <merijn> ventonegro: Also, you should definitely switch and use "(strong . text $ show i)" or "strong . text . show $ i" over the current one with all $
02:22:05 <erisco> merijn, I was just worried about the whitespace, but I also changed some $'s because those drive me nuts :P
02:22:45 <erisco> in practice I do not often use let/in or if/then/else
02:23:05 <merijn> Yeah, I almost always use guards over if/then/else and where over let/in
02:23:07 <`Guest00000> imagine `type NoMemo t = () -> t; noMemo = const; getNoMemo = ($ ()); data NeededType = Value (NoMemo MyInt) OtherStuff` and that we want to define `x1` as a fixpoint for (\x -> *some expression with x*)
02:23:24 <`Guest00000> where x1 :: NeededType
02:23:50 <erisco> so you can see how I ident and align things for these structures, which is also why I left them in
02:23:58 <merijn> ventonegro: The reason being that it's easier to refactor compositions using . as opposed to $
02:24:32 <erisco> I also have a strict line length of... 80 I think
02:24:40 <EvanR> mine is the superiorest
02:24:41 <merijn> erisco: Same here
02:25:05 <erisco> then why doesn't yours fit...
02:25:16 <ventonegro> Thanks people for the style advice, came to complain, left with improvements
02:25:20 <ventonegro> :)
02:25:23 <erisco> apparently I am on 72! a strict length of 72 then :P
02:25:50 <erisco> it was whatever size barely fits into a quarter of my monitor
02:26:11 <merijn> ventonegro: I have important work to do, hence I'd much rather do simple code layout ;)
02:26:31 <jchia> Question about import ambiguity regarding (&). (&) is a fairly common operator. Why would Protolude define its own version conflicting with the one in Data.Function, which Control.Lens apparently reexports? That means I can't do unqualified imports of Protolude & Control.Lens and still use & without qualification? Is there something about the philosophy of Protolude that I'm missing? http://lpaste.net/356859
02:27:18 <merijn> jchia: Lens introduced (&) first, it was then moved into base because people thought it was useful without depending on base (and lens switched to re-exporting it)
02:27:42 <merijn> jchia: Perhaps protolude predates the move to base
02:28:02 <merijn> jchia: Since, & was only added in base in like ghc 7.8 or 7.10
02:28:03 <EvanR> line length clearly must be limited to 78 to account for line numbers, or the code cant be opened on <no one real>'s terminal
02:28:32 <merijn> jchia: You can use unqualified imports if you just hide one of the &
02:28:40 <merijn> jchia: i.e. "import Protolude hiding ((&))"
02:29:02 <jchia> merijn: OK. would it make sense for Protolude author to update the library to just reexport the one from base?
02:29:09 <merijn> jchia: Yes
02:29:17 <mniip> erisco, and what happens if you're in 9 layers of indentation/
02:29:17 <jchia> I normally just use it qualified, so I'm just curious.
02:29:21 <merijn> jchia: Presumably with some CPP to work with older versions
02:29:34 <merijn> jchia: I usually prefer hiding to qualified operators :)
02:29:48 <merijn> EvanR: What if you have more than 999 lines of code? :p
02:30:06 <EvanR> 99 really
02:30:17 <EvanR> i.e. a failed haskell file :)
02:30:19 <barrucadu> merijn: This is Haskell, nobody really needs more than 999 lines of code!
02:30:46 <merijn> jchia: Submit a PR to fix it! ;)
02:31:18 <merijn> jchia: Here's an example of how to use CPP to define something only for some versions of base: https://github.com/merijn/broadcast-chan/blob/master/BroadcastChan.hs#L205-L214
02:31:39 <merijn> jchia: Simply add a re-export of Data.Function.& for versions that have it and you should be done
02:32:12 <erisco> mniip, hopefully I wake up
02:32:23 <merijn> EvanR: For me it's not so much about having a single 80 char terminal, but split screening vim, ghci and irssi :p
02:33:39 <mniip> erisco, easier said than done
02:33:52 <mniip> you'd think it's that easy
02:34:07 <jchia> merijn: I'll try to when I have time this week.
02:34:54 <erisco> ventonegro, http://hackage.haskell.org/package/data-list-zigzag-0.1.1.0/docs/src/Data-List-ZigZag.html maybe there are some formatting ideas you like in there
02:35:00 <erisco> totally not just plugging my library
02:39:18 * hackagebot Hipmunk-Utils 0.1.0.0 – Useful functions for Hipmunk – https://hackage.haskell.org/package/Hipmunk-Utils
02:39:35 <erisco> hipmunk... oh brother
02:40:12 <ventonegro> erisco: I'll take a look, thanks
02:41:54 <erisco> particularly these are the interesting bits http://lpaste.net/356860
02:42:06 <erisco> I am not married to them but it is how I decided to do things
02:42:57 <erisco> the (p > 10) on line 10 should have been on its own line
02:43:02 <merijn> erisco: No type signatures, boo!
02:43:22 <erisco> they're snippets... there are type signatures I assure you :P
02:43:54 <erisco> so first one is a common case of composing a bunch of stuff which is too long for one line
02:44:10 <erisco> second case shows aligning operators with parentheses
02:44:13 <merijn> erisco: Line-wrapping signatures is a crucial part of proper line-wrapping :p
02:44:36 <erisco> last case is arguments too long for one line
02:45:06 <erisco> in C# it looks better because you have the additional ( , ) stuff
02:45:09 <`Guest00000> merijn: why is it easier to refactor compositions with .?
02:45:49 <erisco> merijn, none of the sigs got long enough in that project... let me look at another
02:46:06 <merijn> `Guest00000: if you have 'd . e . f . g . h $ x' then you can pick a random subexpression, i.e. 'f . g . h' and it will be well-typed, so you can move it into let/where binding
02:46:11 <erisco> I was never particularly happy with it
02:46:22 <`Guest00000> as for me, i think (f . g . h $ x) is somewhat superfluous compared to (f $ g $ h $ x) and i prefer the latter
02:46:51 <merijn> `Guest00000: 'd $ e $ f $ g $ h $ x' if you try to split of 'f $ g $ h' into a separate definition you get a type error
02:46:55 <erisco> well you're all wrong, it is one of (f . g . h) x or f (g (h x)) :P
02:47:29 <`Guest00000> erisco: i dislike ((()))
02:47:47 <erisco> they grow on you like love handles
02:48:12 <`Guest00000> i avoid low amounts of $'s though
02:48:26 <`Guest00000> sometimes
02:48:37 <`Guest00000> it depends on my mood....
02:51:35 <mniip> merijn, and the basis of <ap, const> is better because you can pick a random lambda and make it pointless
02:53:59 <erisco> merijn, I do this http://lpaste.net/356861
02:54:26 <erisco> if the context becomes too long then I break it per line like an import list
02:56:44 <`Guest00000> so
02:57:30 <erisco> the trailing => doesn't please me but I don't know what else to do with it... just sorta hangs out
03:00:18 <Enamex> I'm trying to get Stack working without needing root on Linux
03:00:31 <Enamex> Encountered an error just now while setting up GHC
03:00:53 <Enamex> The GHC located at <...> failed to compile a sanity check. Please see:
03:01:39 <Enamex> I'm seeing the link now but just in case there's a big show stopper that someone knows about since I couldn't find any instructions on setting up without root
03:39:09 <Enamex> GHC needs ld which needs gmp which needs sudo or be built from source which needs autoreconf which needs sudo (and /usr/local/lib needs sudo anyway)...
03:39:50 <Enamex> No hope of getting this working without bugging the sys admins, huh... They come by the end of northern hemisphere's summer.
03:40:18 <ventonegro> ld needs gmp?
03:40:49 <Ulrar> Enamex: I'm a bit surpised, I'm fairly sure I already used stack to get ghc
03:40:53 <Ulrar> And I never have sudo installed
03:41:33 <Ulrar> But I'm on gentoo so I might not have some ridiculous compile options on some dependencies like debian or others have, I guess
03:41:34 <ventonegro> I regularly use `stack` without `sudo`
03:41:37 <Enamex> ventonegro: The error I'm getting mentions an invocation of 'ld' with flag -lgmp
03:41:54 <Enamex> I'm getting the Stack errors only cause I'm trying to install GHC through it
03:42:03 <Ulrar> Enamex: That means it's trying to link using gmp, not that ld depends on it
03:42:11 <Enamex> And I don't have libgmp-dev installed, apparently
03:42:14 <ventonegro> Enamex: Ah, you don't have libgmp installed, which is needed by GHC
03:42:42 <Enamex> Ulrar: Yeah. I just listed things in the sequence I tried to break the need for root :(
03:43:23 <ventonegro> You can make it work with some tinkering, by using LD_LIBRARY_PATH and putting libgmp in some local directory
03:44:29 <ventonegro> `export LD_LIBRARY_PATH=${HOME}/.local/lib`, for instance
03:49:21 <ventonegro> Stack also has the `--extra-lib-dirs` flag, so you can point it to `${HOME}/.local/lib`
03:51:59 <Enamex> That's interesting
03:52:09 <Enamex> I'm still having trouble finding the libs though
03:52:12 <Enamex> For example:
03:52:58 <cocreature> ventonegro: does extra-lib-dirs work for the libs GHC needs? I thought it was only for the libs that are needed by the thing you are compiling
03:55:37 <Ulrar> Enamex: Just get the libgmp.deb file by hand, and un-tar it
03:55:43 <Ulrar> You'll have the lib in there
03:56:06 <Ulrar> (I assume debian or ubuntu from the package name you mentionned, but it'd work with the rpm just the same)
03:56:43 <Enamex> Ulrar: I tried that. The .so files that got out were broken symlinks
03:56:59 <Ulrar> One of those shouldn't be a symlink
03:57:05 <Enamex> Was so confused about this. Trying to search elsewhere.
03:57:08 <merijn> Ulrar: Why are you trying to compile GHC?
03:57:13 <Ulrar> merijn: I'm not
03:57:19 <Ulrar> You're mistaking who's trying :)
03:57:33 <merijn> eh, hmm
03:57:40 <merijn> Enamex: Why are you trying to build ghc?
03:57:46 <merijn> Ulrar: Reading scrollback is hard :p
03:57:53 <Ulrar> hehe
03:58:08 <cocreature> it sounds like Enamex is trying to run ghc not compile it
03:58:11 <Enamex> Ulrar: both libgmp.so and libgmpxx.so (the only .so in the .deb) are symlinks when extracted
03:58:18 <Ulrar> That's strange
03:58:26 <Enamex> I'm trying to install GHC through Stack
03:58:29 <cocreature> Enamex: symlinks to where?
03:58:31 <merijn> cocreature: Well in that case it's probably a GHC build for the wrong linux flavour
03:58:50 <merijn> Enamex: Where did you GHC come from?
03:58:53 <cocreature> merijn: no they just don’t have libgmp installed and they can’t install it because they’re not root
03:58:57 <Ulrar> I can send you a debian 8 /usr/lib/x86_64-linux-gnu/libgmp.so.10.2.0 if you want
03:59:09 <merijn> cocreature: Doesn't it ship with the bindist?
03:59:18 <cocreature> merijn: I don’t think so
03:59:19 <Enamex> cocreature: How do I query for the destination? It just opens an empty text editor instance when I double click it (although the icon and status say it's undeniably a broken link)
03:59:24 <Ulrar> ls -l
03:59:37 <Enamex> merijn: I'm just doing stack setup
03:59:55 <Ulrar> You'll have the target after the -> in ls -l's output
04:00:35 <Darwin226> Hey guys. Is there a compiler flag or something to automatically put a HasCallStack context on every function?
04:00:56 <Enamex> cocreature: ./libgmp.so -> libgmp.so.10.3.0
04:01:03 <merijn> Darwin226: I think the profiling runtime automatically has callstack info, even if functions don't have HasCallStack?
04:01:08 <merijn> Darwin226: not 100% certain, though
04:01:11 <cocreature> Enamex: alright so that’s the actual shared library
04:01:22 <Darwin226> merijn: Yeah but then I have to recompile
04:01:28 <Enamex> So I'm after a binary version of libgmp that comes with a version number in the name
04:01:33 <Darwin226> I'd be fine if it only annotated functions in my app
04:01:45 <Oddasat> Is it safe to assume that using DeriveGeneric for ToJSON and FromJSON instances will do the same thing as deriveJson from Data.Aeson.TH?
04:01:49 <cocreature> Enamex: it should be in the same folder and havet hat exact name
04:02:05 <Enamex> Sadly no
04:02:08 <Enamex> I have:
04:02:23 <merijn> Darwin226: It's probably the easiest way, though
04:02:29 <Enamex> libgmp.{so,a} and libgmpxx.{so,a}
04:02:51 <cocreature> Enamex: where exactly did you get that libgmp package from?
04:03:14 <Enamex> https://packages.ubuntu.com/trusty/libgmp-dev
04:03:44 <cocreature> you probably need the non-dev version too
04:03:50 <cocreature> or maybe only that
04:03:59 <barrucadu> The dev version depends on the non-dev version, though
04:04:09 <Enamex> I'm guessing this one: https://packages.ubuntu.com/trusty/libgmp10
04:04:14 <cocreature> barrucadu: that doesn’t help if you manually download files :)
04:05:04 <barrucadu> Oh, the files were manually downloaded, rather than the actual package installed?
04:07:50 <nvd> tls problem: I'm getting HandshakeFailed (Error_Protocol ("expecting server hello, got alert : [(AlertLevel_Fatal,IllegalParameter)]",True,HandshakeFialure))
04:08:27 <nvd> The server works in both curl and Chrome, but not with the tls library (Network.TLS)
04:09:36 <grmp> if your windows, you need to try with IE to grad the certificates
04:09:39 <grmp> *grab
04:09:49 <barrucadu> nvd: This suggests you might need to adjust the ciphers the client is willing to accept: https://github.com/vincenthz/hs-tls/issues/108
04:09:54 <Enamex> I put libgmp in a discoverable location and exported to the LD librarypath
04:10:06 <Enamex> Still fails in the linking stage in "GCC"?
04:11:38 <cocreature> what’s the exact error message
04:12:52 <Enamex>  /usr/bin/ld: cannot find -lgmp               collect2: error: ld returned 1 exit status             `gcc' failed in phase `Linker'. (Exit code: 1)
04:12:58 <Enamex> 3 lines
04:14:16 <cocreature> are you sure you have set ld library path correctly?
04:15:20 <cocreature> you might also need to include the symlinks. I’m not sure if ld automatically figures out the version suffixes or not
04:15:34 <cocreature> for easier testing you can just try to get "ld -lgmp" working before you go back to stack setup
04:16:22 <Enamex> I just tried this :D
04:16:41 <Enamex> So apparently ld isn't checking the path I exported in LD_LIBRARY_PATH
04:17:01 <erisco> monochrom, was it square brackets that denotes an ordered bunch?
04:17:13 <Enamex> Also this: https://stackoverflow.com/questions/4250624/ld-library-path-vs-library-path#comment37966883_4293671
04:17:14 <grmp> and maybe you need modify the simlink as it do not seems to point to the right version of the "no-dev"
04:17:14 <geekosaur> echo $LD_LIBRARY_PATH
04:17:43 <Enamex> grmp: The symlinks are all in order now. And geekosaur the path is set correctly
04:17:52 <geekosaur> you hope
04:18:10 <geekosaur> there's one specific thing I wanted to check for that you apparently would prefer I not know?
04:18:34 <geekosaur> in particular, EVERYTHING must be expanded. no $VARs, no ~
04:19:55 <Enamex> It works now...
04:19:57 <Enamex> I did nothing
04:20:04 <Enamex> __NOTHING___
04:21:19 <cocreature> I highly doubt that :)
04:23:02 <Enamex> But really ._.
04:23:15 <Enamex> I was getting the error from `stack setup`.
04:23:30 <Enamex> Then was inspecting ld -lgmp and trying the same command again.
04:23:35 <erisco> monochrom, found the book again... it is a semicolon that is used... okay
04:23:46 <Enamex> And it just worked. `ld -lgmp` still says it can't find gmp, though
04:24:46 * hackagebot simple-logging 0.2.0.2 – Logging effect to plug into the simple-effects framework – https://hackage.haskell.org/package/simple-logging
04:49:47 <bofh> Hi all! Updated ghc on Arch, now building xmonad gives me this: http://pasted.co/d6dba598
04:50:48 * hackagebot plot-light 0.1.0.6 – A lightweight plotting library, exporting to SVG – https://hackage.haskell.org/package/plot-light
04:52:02 <grmp> bofh, I think you need a static ghc
04:52:19 <yushyin> bofh: did you try ghc’s -dynamic flag?
04:53:11 <bofh> oh, really
04:53:15 <bofh> that helped :)
04:54:08 <bofh> thanks
04:54:26 <Darwin226> If I have a typeclass without methods, of a type familly with a Constraint result type, can those constraints "safely" be discarded with unsafeCoerce?
04:54:41 <fendor> hey, has someone experience with the accelerate package? I'm trying to compile a basic example
04:54:46 <Darwin226> (as opposed to normal constraints that can't because they require runtime dictionaries to be passed)
04:54:58 <Darwin226> s/of/or
04:56:12 <merijn> Darwin226: That sounds like a suspicious thing to want?
04:56:46 <Darwin226> merijn: Indeed, but I'm getting stuck with things like IsSubset (F a) (F a)
04:57:00 <Darwin226> where I know the thing holds for any `a` but I can't prove it
04:58:01 * hackagebot plot-light 0.1.0.7 – A lightweight plotting library, exporting to SVG – https://hackage.haskell.org/package/plot-light
05:00:27 <Darwin226> merijn: This specific case can be solved by putting a `IsSubset a a = ()` equation into the `IsSubset` typefamily but then it messes with solving the constraint in the general case
05:00:54 <Darwin226> because it tries to first check if the things are the same and it gets messy
05:03:44 <cocreature> write a typechecker plugin for resolving IsSubset constraints :)
05:05:00 <Darwin226> Hah! That's not even that far from what I was planing on doing. Unfortunately, they seem to be broken on Windows in 8.0.2
05:05:13 <Darwin226> fixed in the new release, but I can't really play with that atm
05:05:16 <nvd> barrucadu: my reading on that issue was that issue was about the tls library not supporting those ciphers which I don't think is the case here
05:06:34 <dano_> Hi, a complete beginner here. I would like to ask why, in GHCi, for ":t 3" I get "Num a => a" but for "let f = 3" and ":t f" I get "f :: Integer". Why the difference? Thanks
05:07:26 <nvd> dano_: "Num a => a" means "This value is of some number type, I don't know which"
05:07:47 <nvd> When you bound it to f, ghci guessed a type for it according to its defaulting rules
05:07:59 <nvd> And went "f is of the Integer type!"
05:08:57 <merijn> dano_: Monomorphism Restriction
05:09:34 <merijn> The real issue is the monomorphism restriction, which doesn't let things that look like non-functions be polymorphic unless explicitly annotated with a type
05:10:18 <quchen> dano_: Short version: the monomorphism restriction is a quirk of Haskell that works around the fact that some non-functions have to be reevaluated instead of being memoized in some cases.
05:10:44 <quchen> dano_: It only kicks in at the top level (and in where-blocks?) if you don’t have an explicit type signature.
05:11:05 <merijn> quchen: No type signature AND a lhs that doesn't look like a function
05:11:25 <[exa]> quchen: afaik in all binding groups
05:11:34 <quchen> Even let?
05:11:42 <dano_> Many thanks
05:12:58 <grmp> > let f :: Num a => a; f = 3
05:13:00 <lambdabot>  <no location info>: error:
05:13:01 <lambdabot>      not an expression: ‘let f :: Num a => a; f = 3’
05:13:05 <quchen> dano_: The problem is that if you have a function like »f x = x*2«, then you can’t memorize its result (because that might blow up your memory reeeally fast given how many functions Haskell uses). For constants, things that don’t take any arguments, we *can* memoize all their values (well, a constant is just a single value, not infinitely many like e.g. a function mapping).
05:13:39 <ventonegro> Enamex: weird, the ld man page cites LD_LIBRARY_PATH\
05:13:45 <ventonegro> https://linux.die.net/man/1/ld
05:13:55 <quchen> dano_: Now some things look like constants, for example »1«, but behind the scenes they’re polymorphic like you said – Num a => a – and type classes are like functions behind the scenes, only that the compiler inserts the Num »parameter« automatically.
05:14:17 <quchen> dano_: As a result, we sometimes get constants that have performance like functions, boo.
05:14:55 <quchen> dano_: The Monomorphism Restriction spots these cases, and makes the definitions monomorphic (e.g. Integer instead of Num a => a). That solves the performance issue.
05:15:28 <quchen> dano_: There have been countless discussions in the Haskell community whether that’s a good idea, but it looks like it’s here to stay for good. In practice, it’s rarely an issue to be honest.
05:17:33 <Darwin226> Hmm... So let's say I decide to implement this horribly unsafe `anyDict :: Dict c` function. Is there a way to pattern match on this Dict at the top level and bring the `c` constraint
05:17:35 <dano_> quchen: excellent, thanks a lot
05:17:37 <Darwin226> into scope for the whole module
05:20:47 <quchen> dano_: This might sound a bit quirky and awkward, but is really just the strange part of something awesome and fairly unique to Haskell: polymorphic constants.
05:21:11 <quchen> dano_: In other languages like Java and Rust, you cannot have a variable of type Option<A>, for example.
05:21:25 <quchen> In Haskell, we can!
05:21:40 <quchen> > let foo = Nothing in (foo :: Maybe Int, foo :: Maybe Char) in foo
05:21:43 <lambdabot>  <hint>:1:60: error: parse error on input ‘in’
05:21:47 <quchen> > let foo = Nothing in (foo :: Maybe Int, foo :: Maybe Char)
05:21:50 <lambdabot>  (Nothing,Nothing)
05:22:18 <quchen> In other languages, this would be an error, since the »foo« is monomorphized by the tuple’s first component, which clearly demands it to be a Maybe Int.
05:22:32 <marvin2> is foo `Maybe a'?
05:22:36 <quchen> Yes
05:22:39 <quchen> :t Nothing
05:22:41 <lambdabot> Maybe a
05:23:16 <quchen> Another familiar and important polymorphic constant is return/pure: it’s polymorphic in the Applicative
05:23:18 <quchen> :t pure
05:23:19 <lambdabot> Applicative f => a -> f a
05:23:37 <quchen> Well, »pure x« is a polymorphic constant for all x, to be more accurate.
05:24:38 * hackagebot postmark 0.2.0 – Library for postmarkapp.com HTTP Api – https://hackage.haskell.org/package/postmark
05:37:37 <orion> In this monad transformer for opaleye transactions, the author states: "There is no IO (but see 'unsafeIOToTransaction') since database transactions can't be combined with arbitrary other effects."
05:37:52 <orion> https://github.com/silkapp/girella/blob/master/src/Girella/Transaction.hs#L48
05:38:19 <orion> Does this mean that you couldn't, say, read a file from disk or print to the screen in the middle of a transaction>?
05:38:39 <nvd> barrucadu: figured it out, didn't realise you could change which ciphers tls accepted
05:38:53 <orion> And if that's the case, why would that be so? Why can't arbitrary IO be done inside a transaction?
05:38:59 <Darwin226> orion: How would you retry that without repeating the sideeffect?
05:39:03 <cocreature> orion: because you can’t roll it back
05:39:13 <merijn> orion: The uathor is saying that you *can* do it, using unsafeIOtoTransaction, but that it is unsafe
05:39:28 <merijn> orion: Transactions can be aborted/rerun, but you can't "unprint" to the terminal
05:39:46 <orion> Oh darn, I never considered that the transaction can be rerun.
05:40:39 <merijn> orion: Which is the exact same reason why STM doesn't allow IO :)
05:40:45 <orion> True.
05:41:03 <merijn> orion: Also, why STM is so hard/inefficient in other languages, since it's hard for other languages to forbid IO :)
05:42:15 <orion> I see.
05:42:39 <orion> I guess what I truly want is a way to throw a pure error inside a transaction rather than actual IO.
05:43:02 <merijn> What do you mean by "pure error"?
05:43:23 <orion> ExceptT and friends. synchronous.
05:43:40 <cocreature> just return some kind of Either Err a from your transaction?
05:43:50 <merijn> orion: But you can already use ExceptT?
05:44:02 <merijn> orion: That file has a Transaction instance for ExceptT
05:44:45 <orion> merijn: I'm not using the monad from that file to which I linked.
05:44:49 <orion> I was looking at opaleye-trans.
05:45:28 <cocreature> ExceptT Err Transaction a looks like it might still work
05:45:32 <merijn> orion: What are you using then?
05:46:11 <orion> merijn: opaleye-trans./
05:46:19 <orion> https://www.stackage.org/haddock/lts-8.22/opaleye-trans-0.3.5/Opaleye-Trans.html#t:OpaleyeT
05:46:42 <orion> I'm still hung up on what cocreature and I were discussing yesterday.
05:46:58 <cocreature> orion: so what’s wrong with ExceptT Err Transaction a?
05:47:31 <orion> cocreature: How would that work with OpaleyeT?
05:47:52 <merijn> orion: "runExceptT" get a transaction, pass that to the opaleye-trans functions?
05:47:59 <orion> Oh, hmm.
05:48:07 <cocreature> orion: runExceptT will give you a Transaction (Either Err a) and then you can use "transaction" to get an OpaleyeT
05:48:25 <orion> Yes, indeed.
05:49:24 <orion> I'll give that a try, but with the newfound knowledge that it makes no sense to do IO in these transactions.
05:50:15 <attheicearcade> is there a way to break type inference i.e. require a function to have a type signature? for example, I have a `newtype Id a = Id UUID` and a function `randomId :: IO (Id a)` which is ultimately used as `Id User`, `Id Product` etc. and I don't want to mix them up (the whole point of the phantom type). I know I can create `randomUserId :: IO (Id User)` and so on, is this my only option? I'd like to have to do `randomId :: IO (
05:51:15 * hackagebot json-tracer 0.0.1.0 – <i>Added by autotaker, Tue Jul 11 12:36:39 UTC 2017.</i> – https://hackage.haskell.org/package/json-tracer
05:51:39 <merijn> attheicearcade: Well, I think it might "just work", because if you try to use the same Id as both "Id User" and "Id Product" you'll get a type error
05:51:50 <merijn> attheicearcade: Since a single Id can't ever be both
05:52:08 <merijn> attheicearcade: So if you just make sure all functions consuming "Id" values have a specific phantom type that should work
05:52:43 <merijn> attheicearcade: Although that doesn't rule out accidentally creating a user id and passing it to something expecting a product
05:52:47 <attheicearcade> merijn: Yes, but in cases where I am generating new Ids the types are inferred and can be mixed
05:53:00 <attheicearcade> merijn: Exactly that
05:53:12 <merijn> attheicearcade: How many different types are you using with the phantom?
05:53:16 <merijn> attheicearcade: Just a handful?
05:53:37 <cocreature> attheicearcade: don’t export the constructor and make the creators non polymorphic
05:54:00 <cocreature> i.e. createUserId :: ID User
05:54:02 <merijn> cocreature: He just says he wants to know if there's a more efficient way than defining N different creators :)
05:54:19 <cocreature> oh nvm then :)
05:54:22 <attheicearcade> merijn: yes, at the current stage. I expect I will go with separate functions for each and hide constructors, but I was wondering if I can get away with defining one function
05:54:46 <merijn> attheicearcade: You can make it a bit better using a GADT, I guess. Not a whole lot less work, though
05:55:31 <merijn> "data IdType a where { UserId :: IdType User; ProdictId :: IdType Product }" and then "makeId :: IdType a -> IO (Id a)"
05:55:43 <merijn> Then you could do "makeId UserId" and have it work type-safely
05:56:07 <merijn> That would make it impossible to ever generate an Id without explicitly specifying it's type
05:56:43 <pd1> Hi! I have problems building a package. One of the dependencies "distributive" fails to configure.. ld can't find a bunch of libraries: (-lHSCabal-1.24.2.0 -lHSprocess-1.4.3.0 -lHSpretty-1.1.3.3 -lHSdirectory-1.3.0.0 -lHSunix-2.7.2.1 -lHStime-1.6.0.1 -lHSfilepath-1.4.1.1 -lHSbinary-0.8.3.0 -lHScontainers-0.5.7.1 -lHSbytestring-0.10.8.1 -lHSdeepseq-1.4.2.0 -lHSarray-0.5.1.1 -lHSbase-4.9.1.0
05:56:45 <pd1> -lHSinteger-gmp-1.0.0.1 -lHSghc-prim-0.5.0.0 -lHSrts_thr) Where can I get help? thank you
05:56:50 <merijn> attheicearcade: Not sure if that's much better than just having multiple functions, though
05:58:13 <cocreature> pd1: let me guess, archlinux?
05:58:24 <pd1> yes!
05:58:45 <merijn> pd1: arch broke shit
05:58:59 <merijn> pd1: I remember someone saying there was a way to fix it documented on their wiki
05:59:17 <Oddasat> what is the TemplateHaskell equivalent of this DeriveGeneric instance: instance FromJSON (Thing a)? deriveJson defaultOptions ''Thing doesn't seem to work. Thing is defined as: newtype Thing a = Thing Double deriving (Show, Generic).
05:59:18 <merijn> pd1: Other than that, the most helpful thing is probably to yell at the arch GHC maintainer to not break shit in the future
05:59:19 <tabaqui> do not mix cabal packages and archlinux libs
05:59:19 <tabaqui> I even think that the best way to handle libs
05:59:20 <tabaqui> is to use stack-bin and install whole haskell ecosystem using it
05:59:57 <cocreature> pd1: step 1. get a statically linked version of cabal from somewhere (e.g. the one from the arch repos from before the 8.0.2 updates)
06:00:13 <cocreature> pd1: step 2. nuke everything Haskell related that you installed via pacman except for ghc and ghc-static
06:00:21 <cocreature> pd1: step 3. yell at the maintainer for breaking shit
06:00:29 <merijn> cocreature: Why not just install the bindist?
06:00:57 <cocreature> merijn: I like not having to manage ghc myself :)
06:01:13 <merijn> cocreature: I like the bindist because it makes it easy to have multiple versions lying around :)
06:01:15 <ziman> pd1: the arch wiki explains how to fix it :)
06:01:33 <merijn> cocreature: Also, the only reliable way I've found to install GHC if you don't have a package manager :)
06:02:18 <pd1> Ok, I give it a try, thank you!
06:02:20 <ziman> pd1: you can either install ghc-static or put "executable-dynamic: True" in ~/.cabal/config: https://wiki.archlinux.org/index.php/Haskell#Problems_with_linking
06:02:30 <cocreature> installing ghc-static is not sufficient
06:02:57 <pd1> ok thanks
06:03:04 <cocreature> the “nuke everything haskell related” apart from ghc and ghc-static part is important
06:03:37 <pd1> so... remove .cabal, .ghc, and all the packages i can find?
06:03:41 <ziman> yes, I removed my ~/.ghc, too, but I'm not sure how important it is :)
06:03:46 <ziman> I didn't remove my ~/.cabal
06:04:03 <ziman> I spent quite some time figuring out why Idris would not build and it turns out that it's likely its build system that does not support dynamic libs because everything else seems to work
06:04:11 <cocreature> pd1: only the things that you installed via pacman matter. in particular, you can’t install cabal or anything else via pacman if you want to use static linking
06:04:12 <ziman> so you may run into other packages like that
06:04:25 <cocreature> the alternative is to stick with that stuff and use executable-dynamic: True
06:05:25 * hackagebot json-tracer 0.0.1.1 – A polymorphic, type-safe, json-structured tracing library – https://hackage.haskell.org/package/json-tracer
06:05:40 <ziman> I'm now on executable-dynamic: True, with a small LD_LIBRARY_PATH hack whenever I need to rebuild Idris, and everything seems to work well
06:11:48 <yushyin> ziman: what also works is using stack from the arch linux repository and let it handle all dev related stuff (so even ghc in various versions)
06:26:54 * hackagebot rot13 0.2.0.1 – Fast ROT13 cipher for Haskell. – https://hackage.haskell.org/package/rot13
06:30:23 <sproingie> can't say i've needed high-performance rot13 before.  good reference for string munging algorithms in general i guess.
06:31:13 <Clint> are there comprehensive benchmarks?
06:33:04 <onepl> is there any plausible way to write a functioning mobile app back-end just with using haskell
06:33:22 <sproingie> sure
06:33:49 <onepl> then may i ask what it is
06:33:58 <sproingie> backend is just any old web server.  scotty's good for a simple setup, yesod for all the bells and whistles
06:34:13 <sproingie> servant for something inbetween
06:34:33 <Enamex> Hmm.
06:35:02 <Enamex> Haskero needs Intero which is looking for curses?
06:35:24 <merijn> onepl: At least one Haskell game is on the app store and a few other prototypes exist, so yes
06:35:50 <sproingie> intero doesn't need curses, the project being loaded into intero does
06:36:01 <erisco> I see the end times coming... it is a flood of puns
06:36:29 <Enamex> I'm just doing stack install intero
06:38:20 <sproingie> emacs installs intero for me, so i don't follow all its deps.  guess it might have some transitive dep on curses somewhere in there
06:39:00 <sproingie> it's definitely not a direct dependency
06:39:18 <sproingie> oh it does have a haskeline dep, there's where curses is coming from
06:41:35 <Enamex> :[
06:42:04 <Enamex> Tangential : stack doesn't seem to have a way to list installed packages (globally or locally?)
06:42:59 <Enamex> sproingie: Also the error is quite bare. I don't know what version of curses it's looking for
06:43:42 <attheicearcade> Enamex: shouldn't that be "stack build intero" in the project directory?
06:43:43 <sproingie> probably 5 or 6, curses is pretty stable
06:44:17 <sproingie> the standard curses package for your OS should satisfy it.  if it's windows, it should skip curses entirely
06:44:32 <Enamex> attheicearcade: Isn't Intero like a library to be used by Haskero?
06:44:55 <sproingie> intero is a backend for several different IDEs
06:45:01 <Enamex> sproingie: I'm on Linux and it's erroring out. I'm quite constrained here :[ (no root or anything)
06:45:18 <Enamex> sproingie: Exactly
06:45:23 <sproingie> any decent linux box should have curses installed already.  might need the dev package.
06:45:32 <Enamex> So why do I put it in a specific project directory?
06:45:54 <sproingie> intero is usually installed per-project.  at least that's how the emacs integration works.
06:46:15 <Enamex> That sounds quite wasteful
06:46:32 <attheicearcade> Enamex: I seem to remember needing to run build instead of install to get haskero working. It was somewhere in the docs 
06:46:40 <sproingie> it's not that big.  stack caches it.
06:46:54 <bennofs> Enamex: it is useful to avoid conflicting dependencies. if you use different ghc versions per project there is no other wa
06:47:06 <sproingie> makes new project startup a little slow but it's a one-time cost
06:47:14 <ocramz> hai
06:47:44 <Enamex> Hmm. It's still giving me the errors when built in project.
06:47:49 <ocramz> do Arrows fuse? if I say `maximum &&& minimum` , does it do a single pass on the data?
06:48:03 <Enamex> attheicearcade: The setup page for Intero says to use build instead of install, yes
06:48:19 <Enamex> Curses doesn't come with Xubuntu or what...
06:49:03 <sproingie> if you don't have root you'll have to do a user install then point your C_INCLUDE_PATH, LIBRARY_PATH, and LD_LIBRARY_PATH at it
06:49:25 <Enamex> For curses?
06:49:28 <sproingie> yep
06:50:20 <sproingie> ocramz: doubt it, it's largely just maps+folds that fuse
06:54:57 <sproingie> my guess is xubuntu at least has curses installed, just not curses-devel
06:55:35 <sproingie> i imagine bash and anything else using readline depends on curses
06:57:13 * hackagebot med-module 0.0 – Parse song module files from Amiga MED and OctaMED – https://hackage.haskell.org/package/med-module
07:00:33 <Enamex> sproingie: I setup curses-dev manually. Stack still "error: curses library cannot be found"
07:02:05 <Enamex> It's a configure error in terminfo
07:02:49 <dogbitsman> Do you have examples of using the common read / write / state monads
07:04:42 <ventonegro> What variant of readFile should I use, when I want to force UTF-8 encoding?
07:05:32 <srhb> ventonegro: Read it as a ByteString first, then decode it as UTF-8.
07:05:33 <merijn> ventonegro: ByteString with explicit decode
07:05:37 <srhb> jinx
07:05:47 <ventonegro> heh
07:05:47 <merijn> Data.Text.Encoding has decode functions
07:05:50 <ventonegro> thanks
07:06:16 <Athas> ventonegro: there are also Data.Text versions of readFile that do that automatically.
07:06:23 <Athas> (If you are OK with IO exceptions on decode errors.)
07:06:40 <merijn> Athas: Are you sure that does UTF8?
07:06:48 <srhb> I don't think they do. Not from text anyway.
07:06:49 <merijn> Athas: I would assume that uses the RTS encoding
07:06:54 <srhb> Yep
07:07:14 <merijn> Athas: "Beginning with GHC 6.12, text I/O is performed using the system or handle's current locale and line ending conventions."
07:07:26 <Athas> Well, on any reasonable system the locale will be UTF-8!
07:07:56 <merijn> Athas: Just watch how many people have brokenly configured OSes..
07:08:10 <Athas> This is a good way to find those people so they can mend their ways.
07:12:29 <sproingie> chinese users may very well have gb18030 locale.  don't assume.
07:13:50 <sproingie> but if you're going to anyway (i do), then utf8 is a good assumption
07:15:10 <Enamex> So apparently tinfo was already installed but some -dev version hack was needed again \o/
07:15:43 <Enamex> So now intero is built in the project dir. But extension isn't working in VS Code
07:16:08 <Enamex> I need to push page on github listing all the steps I had to take today...
07:17:08 * hackagebot rattletrap 2.5.0 – Parse and generate Rocket League replays. – https://hackage.haskell.org/package/rattletrap
07:17:51 <Lokathor> any popular folds that aren't sum, product, and or all
07:18:10 <Lokathor> that is, that i could put in a list of example folds that the reader already would know about just not under the name "fold"
07:18:55 <codedmart> Anyone with amazonka experience here? I am trying to figure out why I am getting NoSuchKey error when trying to get a file. I have verified the region, bucket, and key. The file is there. The permissions are open so the file is accessible.
07:22:16 <Enamex> Actually I got a question that's quite irrelevant, perhaps. Is there a lively IRC channel for ML, the _language_?
07:23:22 <lightshadow> HI GUYS
07:24:29 * hackagebot Hastodon 0.1.0 – mastodon client module for Haskell – https://hackage.haskell.org/package/Hastodon
07:24:34 * erisco straightens his hair
07:25:35 <ventonegro> Athas: My process will not run in a terminal, I don't want to assume the encoding
07:25:48 <ventonegro> It's a straight oldie CGI program
07:26:42 <srhb> Lokathor: foldr mappend mempty?
07:26:54 <srhb> What's it called, mconcat?
07:27:13 <Lokathor> concat, yeah
07:27:22 <cocreature> Lokathor: https://hackage.haskell.org/package/foldl-statistics-0.1.4.6/docs/Control-Foldl-Statistics.html
07:27:40 <srhb> Lokathor: For sheer generality I think that one is great to have
07:27:41 <cocreature> Lokathor: max, min too
07:27:51 <Lokathor> ooh i'll use max and min
07:28:18 <cocreature> Lokathor: https://hackage.haskell.org/package/foldl-1.3.0/docs/Control-Foldl.html has a lot of simple folds
07:28:24 <erisco> no, mconcat is a special case for lists
07:28:34 <srhb> Oh
07:28:35 <erisco> the general one is called "fold"
07:28:42 <srhb> Ah, thanks.
07:29:08 <Lokathor> i don't need every example, I think max and min really finsihed off the list well
07:29:20 <Lokathor> since the fold in the tutorial is a kinda very weird max fold
07:29:26 <erisco> you have to import it from Data.Foldable
07:29:27 <lightshadow> hi guys
07:29:46 <srhb> lightshadow: Hello there.
07:30:16 <erisco> if this was the old Prelude then foldr would also be special to lists and the answer would be mconcat, heh
07:30:43 <Lokathor> http://lpaste.net/356865 well the actual fold looks like this :/
07:30:46 <Lokathor> stupid FOV
07:35:21 <cocreature> Lokathor: is the Sightline constructor strict in its arguments? otherwise foldl' won’t help you here
07:35:50 <srb> Is there a technical reason why `data` is needed for datatype declarations, when upper/lowercase is enough elsewhere?
07:36:01 <Lokathor> it... will be? it's not at the moment but seeing things be slow in a benchmark and then wondering how to go faster is part of the lesson
07:36:17 <cocreature> fair enough
07:36:36 <srhb> srb: I suppose not.
07:36:54 <srhb> srb: Though you'd still have to distinguish type and newtype.
07:36:58 <Lokathor> cocreature, also the predicate forces all the fields of the line anyway
07:37:02 <srhb> srb: Nice name, by the way, if a bit minimalist.
07:37:19 <Lokathor> oh no there's two of them now!
07:37:55 <Lokathor> I'm assuming that their names stand for SenioR Haskell Buddy and SenioR Buddy
07:37:59 <srhb> :-P
07:38:59 <srb> Not to ruin the mystique, but it's just my initials. Oh, and I like the fact that it reads as Serb as in Serbian.
07:39:01 <lyxia> srb: is   X = X   a data declaration or a pattern binding?
07:39:26 <srb> pattern binding?
07:39:34 <srb> do you mean like f X = X?
07:39:50 <lyxia> srb: somewhat. X = X is also syntactically valid
07:39:55 <srhb> lyxia: Isn't that a non-issue, just as with x = x ?
07:40:02 <Philonous> Even worse with type parameters: X a = X a 
07:40:24 <lyxia> Yeah Philonous's example is more useful
07:40:39 <srhb> that seems unambiguous to me as well.
07:40:51 <srb> what does X = X mean?
07:41:02 <srhb> data X = X
07:41:13 <lyxia> it's already valid syntax at the toplevel
07:41:24 <lyxia> it does nothing
07:41:28 <srb> but why?
07:41:42 <srb> how should I interpret it?
07:41:45 <lyxia> It's a special case of <pattern> = <expression>
07:41:51 <srb> Oh, I see
07:41:56 <Philonous> Like (x,y) = (3,4)  
07:42:04 <srb> yeah, it's obvious now.
07:42:46 <lyxia> I guess my X = X example was mostly confusing
07:42:49 <Athas> Is there a way, with stack, to load compiled modules from my package?
07:42:54 <Athas> 'stack ghci' is much too memory-intensive.
07:43:20 <Lokathor> stack ghci is how you do it unfortunately
07:43:41 <Athas> Hm, with 'stack exec ghci' I seem to be able to load it.
07:43:45 <Lokathor> how constrained could the system be? even an rpi can start stack ghci
07:43:59 <Henri> Can someone help me understand this type?
07:44:00 <Henri> newtype Compose f g a = Compose (f (g a))
07:44:00 <Lokathor> stack ghci is an alias for stack exec ghci, as far as i know
07:44:02 <Athas> Lokathor: it requires more than 16GiB of memory to load my program apparently, and that's all I've got.
07:44:19 <Lokathor> Athas, wow are you importing all of hackage? That sounds like a bug
07:44:39 <Athas> No, I am importing ~45SLOC of code, plus a Happy-generated parser.
07:44:44 <Athas> I think the parser is the biggest problem.
07:44:44 <Lokathor> Henri, what do you not get about the type
07:44:50 <Henri> the kind of Compose is (* -> *) -> (* -> *) -> *
07:44:51 <Athas> Er, ~45 KSLOC.
07:44:57 <srb> lyxia: I guess you could prevent constructors from conflicting with type names
07:45:02 <Henri> But if I want to construct a value of that type what is it
07:45:17 <Henri> Like I can't do Compose (List (List 5))
07:45:23 <Henri> Because it expects data constructors
07:46:07 <Henri> And functions all have kind *
07:46:07 <Lokathor> it's expecting type constructors
07:46:18 <Henri> That's what I figured
07:46:22 <Lokathor> so instead of 5 you'd put a type like Int
07:46:36 <Lokathor> if you're trying to say the type of something
07:47:03 <Henri> Hmm okay
07:47:23 <Henri> It just doesn't seem to really do anything either
07:47:23 <Lokathor> Compose [[Int]] should be valid
07:47:41 <Lokathor> most of the newtypes in that book don't do much when you first see them
07:47:56 <`Guest00000> no
07:48:03 <`Guest00000> Compose [] [] Int
07:48:06 <Henri> Yeah
07:48:10 <lyxia> Henri: Compose Maybe Maybe Int   is a value Constructor x   where   x :: Maybe (Maybe Int).  Let x = Just (Just 3).
07:48:10 <Lokathor> but Identity for example becomes important later, and PhantomData helps with keeping track of conversions
07:48:19 <`Guest00000> Compose [[5]]
07:48:30 <Lokathor> oh you can't have the [] wrap around?
07:48:47 <Lokathor> oh right, it needs the * -> * form :S
07:48:51 <`Guest00000> :k Compose
07:48:52 <lambdabot> error:
07:48:52 <lambdabot>     Not in scope: type constructor or class ‘Compose’
07:48:54 <petejohanson> jle`: Yeah, I'll try making it more specific and see if that works around that problem w/ existential types. Thanks.
07:49:03 <erisco> [[Int]] :: *, so that aint working
07:49:06 <Henri> Compose :: (* -> *) -> (* -> *) -> * -> * 
07:49:13 <`Guest00000> > newtype Compose f g a = Compose (f (g a))
07:49:15 <lambdabot>  <hint>:1:1: error: parse error on input ‘newtype’
07:49:22 <lightshadow> hey guys
07:49:23 <`Guest00000> well
07:49:35 <lyxia> @let newtype Compose f g a = Compose (f (g a))
07:49:37 <lambdabot>  Defined.
07:49:42 <Henri> So this is like type level composition?
07:49:51 <Henri> Instead of functional composition
07:49:54 <`Guest00000> yes, it is
07:50:02 <Lokathor> exactly
07:50:06 <Henri> God this stuff just gets higher and higher
07:50:13 <`Guest00000> > Compose [Just 5, Nothing] :: Compose [] Maybe Int
07:50:15 <lambdabot>  error:
07:50:15 <lambdabot>      • No instance for (Show (Compose [] Maybe Int))
07:50:16 <lambdabot>          arising from a use of ‘show_M44961436701266995323502’
07:50:17 <Lokathor> it doesn't stop from getting higher
07:50:18 <erisco> no, it doesn't actually
07:50:39 <`Guest00000> > (const ()) (Compose [Just 5, Nothing] :: Compose [] Maybe Int) -- typechecks
07:50:41 <lambdabot>  ()
07:50:42 <erisco> it stops at types thanks to TypeInType, iirc
07:51:16 <bubu> ciao
07:51:23 <Henri> Okay well I am gonna try to create the functor instance for Compose f g now
07:51:25 <bubu> !list
07:51:28 <Henri> You guys helped
07:51:29 <Henri> Thanks
07:52:29 * hackagebot find-clumpiness 0.2.1.3 – Find the clumpiness of labels in a tree – https://hackage.haskell.org/package/find-clumpiness
07:53:22 <lightshadow> hi guys
07:55:11 <Henri> I GOT IT
07:55:51 <Henri> It makes sense now
07:58:26 <mpickering> There's a real problem with the IsLabel class and people defining orphan instances for it 
07:59:41 <cocreature> that class is just way too general
08:00:28 <cocreature> and people use it to emulate type directed name resolution
08:01:20 <erisco> Henri, now define Flip, Const, Join
08:01:25 <lyxia> lightshadow: hi
08:01:36 <erisco> or just define S and K and call it a day
08:02:50 <erisco> just be careful or you'll program yourself right out of Haskell
08:08:57 * hackagebot octane 0.20.0 – Parse Rocket League replays. – https://hackage.haskell.org/package/octane
08:10:37 <lightshadow> hi
08:11:14 <endolphin> where do binaries installed via stack go?
08:12:55 <Athas> endolphin: $HOME/.local/bin
08:16:08 <Henri> Can someone give me a hint for writing the applicative instance for newtype Compose f g a = Compose (f (g a))?
08:17:11 <erisco> pure :: a -> Compose f g a; (<*>) :: Compose f g (a -> b) -> Compose f g a -> Compose f g b
08:21:09 <Henri> See the thing is I don
08:21:16 <Henri> I don't have a value of type a to work with
08:21:24 <Henri> Unless I use apply to get one?
08:21:26 <Henri> Hmm
08:21:51 <erisco> pure x = ...  where x :: a
08:22:36 <erisco> you must be working on (<*>) then
08:23:19 <Henri> Yeah I am
08:23:28 <Henri> pure was easy
08:23:35 <erisco> m :: f (g (a -> b)); n :: f (g a)
08:24:53 <erisco> peel the onion away. we know at some point we'll have  r :: g (a -> b); s :: g a  and need  t :: g b
08:24:57 <erisco> can we do that?
08:25:15 <Henri> Hmm
08:25:16 <Henri> Yes
08:25:20 <Henri> because of the applicative instance
08:25:21 <Henri> for g
08:25:42 <erisco> right, (<*>) :: g (a -> b) -> g a -> g b
08:26:20 <erisco> so now we need   (g (a -> b) -> g a -> g b) -> f (g (a -> b)) -> f (g a) -> f (g b)
08:26:31 <Henri> But where do we get m and n
08:26:37 <Henri> I guess n is easy
08:26:46 <erisco> well, say we generalise a bit
08:27:11 <Henri> n is just pattern matching (Compose n)
08:27:16 <erisco> (a -> b -> c) -> f a -> f b -> f c
08:27:26 <Henri> lift2
08:27:33 <Henri> liftA2
08:27:39 <erisco> well let me choose different letters... (x -> y -> z) -> f x -> f y -> f z
08:27:49 <endolphin> :t liftA2
08:27:51 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
08:27:57 <endolphin> oh, right
08:28:01 <erisco> yeah, and say we let x = g (a -> b), y = g a, and z = g b
08:29:07 <erisco> do you see the solution now?
08:29:22 <Henri> Hmm
08:29:24 <Henri> let me think for a minute
08:29:50 <Henri> Oh
08:30:12 <ADG> I want to define newtype Polynomial = Array Int Int but still use (!) operator..
08:30:42 <erisco> ADG, I don't think that makes much sense
08:31:04 <ADG> why I want to define (+) & (*) over poynomial so that's why
08:31:40 <ADG> newtype Polynomial = Poly (Array Int Int) deriving (Show) .. maybe this
08:31:50 <erisco> the point of ! is that the fields are evaluated before the constructor
08:32:03 <erisco> but the Polynomial constructor disappears entirely because it is a newtype
08:33:03 * hackagebot text-all 0.4.1.1 – Everything Data.Text related in one package – https://hackage.haskell.org/package/text-all
08:33:03 * hackagebot quantification 0.1.1 – Data types and typeclasses to deal with universally and existentially quantified… – https://hackage.haskell.org/package/quantification
08:33:43 <erisco> Polynomial ⊥ = ⊥  as they say
08:34:16 <lyxia> ADG: are you talking about BangPatterns or (!) as a function
08:34:37 <ADG> maybe I can pattern match the constructor and then use the operator?
08:34:39 <lyxia> or just strictness annotation in types
08:35:15 <erisco> yes you can do that
08:35:37 <erisco> f !(Polynomial p)  will be strict on p
08:36:43 <lyxia> It looks like ADG is talking about (!) the indexing operator.
08:36:51 <erisco> isn't that !! ?
08:37:09 <erisco> :t M.!
08:37:11 <lambdabot> error: parse error on input ‘M.!’
08:37:12 <lyxia> not for arrays/vectors
08:37:28 <erisco> okay, my bad
08:38:04 <ADG> see https://hastebin.com/iruwefefag.hs, I defined (<>)
08:38:29 <erisco> if ! is a type class member then you can use GeneralizedNewtypeDeriving to implement ! automatically
08:38:35 <erisco> otherwise you are going to have to do it yourself
08:39:04 <lyxia> ADG: import qualified Data.Array so that you can actually define (!)
08:42:11 <Henri> God I can't figure this otu
08:42:16 <Henri> I'm terrible at this
08:44:05 <shapr> Henri: it gets easier, but there's much frustration at first
08:44:35 <Henri> Is it bad if it takes me hours to do it
08:44:53 <shapr> I'm feel like I'm terrible at Haskell, and I've been doing it for fifteen years.
08:45:08 <shapr> There's always something new to learn, some other thing to understand.
08:45:13 <shapr> On the good side, it's never boring.
08:45:20 <[exa]> Henri: you made me do the same exercise, stuck as well
08:45:38 <Henri> Thanks for the support
08:45:44 <Henri> I'm gonna just work through it
08:45:45 <[exa]> type 2 support.
08:45:50 <Henri> Maybe start with a concrete version
08:45:54 <Henri> instead of abstract
08:46:10 <[exa]> List of maybes is a good instance imho
08:46:18 <Henri> What about ExactlyOne of ExactlyOne
08:46:23 <Henri> Little easier
08:46:51 <[exa]> I'd confuse which one is which
08:47:10 <[exa]> Maybe ExactlyOne starts to sound good
08:47:33 <Henri> True
08:47:47 <Henri> I'm gonna try that one and then get that generalised
08:48:18 <Henri> Coding in haskell feels actually difficult
08:48:51 <[exa]> thinking logically about logic that is hidden in types which are hidden in declarative computation is always difficult
08:50:37 <ventonegro> For Compose, remember that you have layers and that the function is at the innermost layer, so you have to bypass, or "inject", your operations into the "core"
08:50:57 <ventonegro> Remember that the layers are functors
08:51:28 <Henri> And injections are fmaps and applys?
08:52:00 <J0llyr0tten> which is a good channel to ask a fairly basic lambda calculus question?
08:52:24 <[exa]> J0llyr0tten: this
08:52:36 <J0llyr0tten> [exa]: cool
08:53:18 <[exa]> Henri: isn't there a law about relation of fmap and pure?
08:53:43 <[exa]> (just a wild guess, sorry)
08:53:56 <J0llyr0tten> can someone explain the steps of how     (\x. (\y. y x)) y       reduces to      \y1.y1 y
08:54:07 <J0llyr0tten> i'm playing around with http://www.itu.dk/people/sestoft/lamreduce/lamframes.html
08:55:24 <lyxia> alpha-rename   (\x. (\y1. y1 x)) y   beta-reduce   (\y1. y1 y)
08:56:04 <mniip> J0llyr0tten, you realise that (\x. x) and (\y. y) are, for all purposes, the same?
08:56:35 <J0llyr0tten> mniip: i do, just with the names changed
08:56:52 <J0llyr0tten> mniip: but apart from that , equivalent
08:57:01 <mniip> that kind of sameness is generally a useful quality, hence we have that in lambda calculus
08:57:06 <mniip> it's called alpha-equivalence
08:57:33 <Peaker> hey, now that the pretty package has its own Pretty class, is there any nice way to auto-derive it for most types via a Generic instance?
08:57:41 <[exa]> JoshS: the y from lambda is a completely other y than the other one. It's always best to randomly rename all captured variables
08:57:45 <Peaker> I tried GenericPretty but it's missing instances for tons of base types :-(
08:57:52 <[exa]> oh sorry, J0llyr0tten ^
08:57:52 <J0llyr0tten> i was just reading about it again on Stephen Diehl's tutorial http://dev.stephendiehl.com/fun/003_lambda_calculus.html
08:57:54 <Peaker> (and it is yet another Pretty class)
08:58:05 <J0llyr0tten> [exa]: what? no problemo
08:58:17 <mniip> J0llyr0tten, what lyxia said. In both expressions 'y' is a Free Variable
08:58:28 <Henri> fmap f x = pure f <*> x ? [exa]
08:58:31 <mniip> it's as if it's coming from outside
08:58:55 <J0llyr0tten> mniip: which causes the inner y's to be renamed ...
08:58:57 <[exa]> Henri: that could probably help us construct m (n a -> n b) from m (n (a->b))
08:59:02 <J0llyr0tten> mniip: ?
08:59:09 <Henri> Hmm
08:59:12 <mniip> it doesn't "cause"
08:59:22 <Henri> I'm trying on newtype ComposeC a = ComposeC (ExactlyOne (Optional a))
08:59:23 <Henri> rn
08:59:26 <[exa]> J0llyr0tten: the thing about captured variables is that their name don't matter
08:59:32 <mniip> the thing is that if you naively beta-reduced the expression the \y. would capture the other "y"
08:59:45 <[exa]> J0llyr0tten: (\x . a x) is the same as (\y . a y)
08:59:52 <mniip> [exa], "bound" is the name I think
09:00:06 <mniip> J0llyr0tten, hence, you cannot "simply" beta-reduce it
09:00:13 <mniip> you have to annotate that the two are different variables
09:00:21 <mniip> e.g by changing the name of the one you can change the name of
09:00:26 <[exa]> J0llyr0tten: problem is that it's not the same as (\x . b x) because you don't know what's outside -- b could have some completely other meaning
09:00:36 <[exa]> mniip: yeah, non-free. :]
09:00:40 <Peaker> The "prettiest" library isn't on hackage? :-(
09:00:46 <mniip> [exa], contrib!
09:00:50 <J0llyr0tten> mniip: gotcha, i'm writing my own Ruby implementation and i'm trying to get the same answer. i get      (\ [y] (y, x))
09:01:01 <Peaker> oh, it is pretty-compact
09:01:16 <[exa]> mniip: debian jokes crawling to category theory
09:01:37 <mniip> J0llyr0tten, eh. In an implementation you might wanna use a different strategy called de-bruijn indices
09:01:48 <mniip> it's devised exactly to avoid the name problem
09:02:11 <[exa]> bad thing about de-bruijn is that you need two different types for variables
09:02:20 <[exa]> which is in turn a good thing.
09:02:23 <mniip> [exa], you mean for FVs?
09:02:30 <[exa]> yep
09:02:38 <mniip> semi-true
09:02:59 <mniip> having implemented LC in lua I've had another type of variable which I've used for letrec and similar
09:03:16 <lyxia> What's the other type of variables for, [exa]?
09:03:35 <mniip> lyxia, in an expression like (\x. x y), the x turns into a de-bruijn index
09:03:37 <[exa]> lyxia: for named stuff that doesn't yet know its distance from its abstraction
09:03:40 <mniip> and the y is, well, unknown
09:04:00 <mniip> if y is not a part of a larger scope (if your LC supports that) you might have a problem
09:05:00 * hackagebot log-warper 1.1.3 – Flexible, configurable, monadic and pretty logging – https://hackage.haskell.org/package/log-warper
09:06:08 <lyxia> hmm... I prefer to think of terms together with a context Γ which is a list of types, then DeBruijn indices that point "outside" the term index into the list.
09:07:19 <lyxia> that way I don't need a second type
09:07:23 <mniip> lyxia, sure, like I said, if Г is induced by a larger scope
09:07:34 <mniip> but y might be a toplevel definition or something
09:07:44 <mniip> if your LC supports toplevel definitions
09:08:29 <lyxia> Ah okay.
09:08:49 <mniip> amazing how easy it is to implement a graph reduction machine without knowing you've implemented one
09:11:26 <Henri> [exa]: I got that part
09:11:37 <[exa]> Henri: I just got the thing to typecheck finally
09:11:40 <Henri> [exa]
09:11:49 <Henri> m (n a -> n b) from m (n (a->b))
09:12:02 <Henri> is simply (<$>) (<*>)
09:12:28 <[exa]> sounds better than mine actually
09:12:40 <mniip> :t fmap ap
09:12:42 <lambdabot> (Functor f, Monad m) => f (m (a -> b)) -> f (m a -> m b)
09:12:45 <mniip> \o/
09:13:07 <[exa]> i don't like short names for magic
09:13:10 <[exa]> like ap.
09:13:52 <Henri> So don't we just do that twice?
09:13:52 <dolio> Function application is magic?
09:14:14 <Henri> :t fmap (fmap ap)
09:14:15 <lambdabot> (Functor f, Functor f1, Monad m) => f1 (f (m (a -> b))) -> f1 (f (m a -> m b))
09:14:29 <Henri> nvm
09:14:32 <[exa]> ap is pure (<*>) ?
09:14:51 <Henri> ap = <*>
09:14:51 <mniip> ap = <*>
09:14:53 <ljhms> what is the most idiomatic way to do the following: (23, (Nothing, Just 34)) & _2 . _2 %~ Just . fromMaybe 40 & _2 . _1 %~ Just . fromMaybe 2 ? I.e. replace the target of a Lens' a (Maybe b) with a default value only if it is Nothing
09:15:16 <[exa]> weird, I need pure <*>
09:15:21 <mniip> ljhms, perhaps over (<|> Just ...) ?
09:15:25 <Henri> I think it's defined in terms of monads
09:15:38 <mniip> over (fromMaybe ...)
09:15:45 <[exa]> nyway, `ap` is defined on Monad :(
09:16:32 <Gurkenglas_> ljhms, are you sure you want the result to still be wrapped in Just? Also, maybe non can solve the problem that made you think you should ask that question
09:16:37 <lyxia> yeah ap is used to define (<*>) quickly
09:17:38 <[exa]> the problem about haskell is the condescending nature of the program
09:17:51 <Henri> Lol what do you mean
09:17:54 <Henri> condescending
09:17:58 <Gurkenglas_> mniip, you mean over _ (fromMaybe ...)?
09:18:02 <mniip> yes
09:18:16 <[exa]> I'm looking at my ap here, and it basically says "you have just spent more than one minute writing this?"
09:18:20 <mniip> I don't actually know lens, I'm just aware of what it can do :p
09:19:10 <Henri> yeah
09:19:24 <Henri> It is rather condescending when the incredibly hard to think of solutions are so short and sweet
09:19:33 <Henri> With no explanation
09:19:38 <mniip> Henri, that's math in general
09:19:38 <Henri> Or trivally*
09:19:48 <mniip> and haskell, is, well, that
09:19:56 <Henri> Yeah I'm a sophomore math major
09:20:02 <Henri> Going into sophomore year
09:20:11 <Henri> That's why I like haskell
09:20:17 <Henri> More mathematically than other languages
09:21:14 <ljhms> Gurkenglas_: I'm not sure. Preferrably I wouldn't, but I'm reading in a configuration file that can contain optional fields using Aeson's genericParseJSON, so (afaik) the datatype that holds the result needs to have the field wrapped in Maybe. I could use non every time I use the value, I suppose, but I'd much prefer setting all the default values at once
09:22:05 <ljhms> e.g. directly after parsing the file
09:23:00 <Henri> I GOT IT
09:23:01 <Henri> YES
09:23:28 <Henri> exa what'd you do?
09:23:32 <Henri> [exa]
09:24:35 <[exa]> Henri: C a <*> C b = C $ pure (<*>) <*> a <*> b
09:25:12 <[exa]> not sure if I want to test it
09:25:25 <Henri>  C f <*> C a = C $ (((<$>) (<*>)) f) <*> a
09:25:30 <Henri> That's how I go tit
09:26:03 <Henri> I think some laws convert one to the other
09:27:00 <[exa]> yeah it's exactly the conversion I mentioned between fmap and pure
09:27:17 <Henri> Yeah makes sense
09:27:20 <[exa]> cool.
09:27:26 * [exa] back to work
09:27:27 <Henri> I like that we got two different solutions
09:27:48 <unknownln> What about something like `C a <*> C b = C $ liftA2 (<*>) a b`
09:27:53 <unknownln> seems a little more readable to me
09:28:12 <Henri> Yeah that is more readable
09:28:18 <[exa]> yeah, that's for people who already used liftA2.
09:28:23 <Henri> I just can't think of it that way
09:32:33 <[exa]> I wonder that it wouldn't be hard to write a program that searches for such simple definitions automatically
09:33:17 <[exa]> like, there are just around 30 different thinkable identifiers, the size of the definition is probably going to be less than 10 applications
09:34:54 <ddk> hello all !!
09:35:15 <[exa]> o/
09:35:28 <ddk> is there someone who is familiar with the grenade library
09:36:50 <ddk> I am not getting how to define my own network or not getting how layers and shape work there ... is there someone who has used it for neural networks
09:38:16 <ddk> I have read the documentation several times and cannot find and other reading resource that's why I am asking same thing again and again here
09:38:33 <ddk> *and == *any
09:39:36 <[exa]> ddk: is there some example you want working but it failed?
09:39:56 <[exa]> the specification of the layers and connections is, well, a bit dense.
09:40:56 * hackagebot quickcheck-state-machine 0.1.0 – Test monadic programs using state machine based models – https://hackage.haskell.org/package/quickcheck-state-machine
09:41:12 <ddk> [exa]: actually I have to tweak the given example by the repo and use it for a neural network for XOR operations but until I get how to define my own network I can't
09:41:47 <ddk> so for now I have no examples other than provided by them
09:42:42 <[exa]> ddk: xor in the standard 2x2 backprop network?
09:43:27 <ddk> my original problem was to design and train a neural network to give outputs for boolean XOR using grenade
09:43:38 <ddk> [exa]: yes !!
09:44:42 <ddk> [exa]: but I am stucked for days ...getting grenade to use ... I asked here but no reply
09:45:12 <[exa]> ok well, on github they talk about neural zoo, could you find (in the source probably, or by :info Layer in ghci) what's the correct name for the "simple" neurons? imho it's the fullyConnected from the MNIST example
09:45:52 <ddk> [exa]: yes I think they call it fullyconnected
09:46:57 <[exa]> now what about: type SimpleNetwork = '[ FullyConnected 2 2 ]  '[ D1 2, D1 2]
09:47:12 <[exa]> I'm just guessing from what the github page looks like, but it looks straightworward
09:47:40 <[exa]> oh sorry, SimpleNetwork = Network '[ ....
09:48:23 <Henri> [exa] do you think Haskell is good for learning ML?
09:49:02 <grmp> you may need to learn ML first
09:49:08 <[exa]> ddk: if you look at the first example, they have their first "connection" as input D2 28 28 (which looks exactly like 28x28 images from mnist), last one is D1 10, one-dimensional vector
09:49:10 <ddk> [exa]: hmm its true
09:49:27 <[exa]> Henri: ML like the friend of O'CaML?
09:49:41 <cocreature> given the current discussion I think ml here is machine learning
09:49:51 <[exa]> oh so
09:49:54 <[exa]> nope
09:50:09 <cocreature> for actually learning how things work and implementing it yourself it’s not so bad
09:50:12 <Henri> No like machinelaernign
09:50:17 <cocreature> if you just want to use it, it’s pretty bad
09:50:21 <cocreature> we don’t have a lot of libs
09:50:25 <ddk> [exa]: so for me my network should look like something :
09:50:40 <cocreature> so I guess it depends on whether you want to learn how ML works or how you can use ML
09:50:50 <Henri> Both I'd say
09:50:55 <Henri> There aren't good libraries?
09:50:59 <cocreature> not really
09:51:20 <[exa]> oh so. :] nope, any language will do
09:51:21 <cocreature> I guess we have tensor flow bindings but I’m not sure how complete they are
09:51:35 <[exa]> Haskell might be more or less friendly to certain groups of users
09:51:36 <cocreature> there is not a haskell version of scipy
09:52:04 <cocreature> eh scikit
09:52:18 <ddk> [exa]: type MyNet = Network '[FullyConnected 2 2,FullyConnected 2 1] '['D1 2,'D1 2,'D1 1]
09:52:27 <[exa]> anyway best way to learn machine learning is to buy a parrot, teach it to read the numbers in 2 days and measure the difference in energy consumption
09:52:48 <[exa]> ddk: yes, two layers, that makes more sense.
09:53:05 <[exa]> Now you'll probably need some instance of MonadRandom to initialize the thing
09:53:16 <[exa]> I'd go with hoogle
09:54:16 * hackagebot http-conduit 2.2.3.2 – HTTP client package with conduit interface and HTTPS support. – https://hackage.haskell.org/package/http-conduit
09:54:25 <ddk> [exa]: I think its there a function RandomNetwork
09:54:42 <[exa]> ddk: yes, I'm just following the github example, seems reasonable so far
09:57:18 <ddk> [exa]: yes its working with random instance
09:57:21 <[exa]> ddk: I'd go with this http://hackage.haskell.org/package/MonadRandom-0.5.1/docs/Control-Monad-Random-Lazy.html#g:1
09:59:37 <[exa]> ddk: after you have the network initialized, you should be able to do something like: backPropagate theNetwork [0,1] [1]
09:59:54 <[exa]> and get a better-learned network using applyUpdate
10:00:21 <[exa]> which you should run several times for each input in random so that it does the actual neural learning part
10:00:26 <ddk> [exa]: here is the problem
10:01:24 <ddk> [exa]: backpropagate network is ok but [0,1] [1] is required in specific type which I am not getting
10:01:59 <ddk> [exa]: http://lpaste.net/356870
10:05:39 <[exa]> ddk: and the final function to run the whole thing to get the actual result should probably be runNet
10:06:08 <[exa]> ddk: https://github.com/HuwCampbell/grenade/blob/master/examples/main/feedforward.hs#L63
10:06:26 <grmp> so: backPropagate net [S1D 0, S1D 1] [S1D 1] ??
10:06:35 <[exa]> ^ there they convert the list to SA.vector
10:07:13 <[exa]> which actually stinks like scikit/numpy, so I guess it's gonna be right :]
10:07:22 <ddk> [exa]: yes its there but the thing is I am not getting how to get this type objects >> backPropagate y   :: S ('D1 2)      -> S ('D1 1) -> Gradients '[FullyConnected 2 2, FullyConnected 2 1]
10:08:02 <ddk> [exa]: y here is any network
10:09:20 * hackagebot json-tracer 0.0.1.2 – A polymorphic, type-safe, json-structured tracing library – https://hackage.haskell.org/package/json-tracer
10:09:23 <[exa]> ddk: backPropagate receives the network, inputs, desired outputs, and produces the gradients that are needed to be corrected at each layer
10:10:08 <ddk> [exa]: yes , but how to get inputs in those type -- my problem
10:10:23 <ddk> [exa]: also for the outputs
10:10:56 <ddk> [exa]:  rest things became now more or less clear
10:12:25 <[exa]> ddk: I'd try something like: inputs = S1D $ SA.vector [0,1]
10:12:57 <[exa]> no idea where S1D comes from though but I guess you can find it
10:13:13 <grmp> https://hackage.haskell.org/package/grenade-0.1.0/docs/Grenade-Core-Shape.html
10:13:29 <[exa]> yes.
10:14:13 <ddk> grmp: [exa] : I have read it  but its very confusing for me please help me a little more to solve this puzzle
10:14:46 <grmp> I don't think we can tell more..
10:15:24 <grmp> maybe SA means Numeric.LinearAlgebra.Static in the hmatrix package
10:15:35 <ddk> [exa]: hey S1D $ SA.vector [0,1] this worked
10:15:56 <ddk> [exa]: Thanks a lot ...... now I got a way to proceed ....
10:15:57 <[exa]> success!
10:16:00 <[exa]> :]
10:16:39 <[exa]> in the other example they have a similar construction of LearningParameters that you'll need
10:17:00 * [exa] has to go
10:17:19 <ddk> [exa]: I have no words ..to say about you I was too tensed from last 4-5 days
10:18:44 <grmp> maybe: "Next time I'll do my homeworks before asking!" ;)
10:18:50 <ddk> [exa]: yes now I can proceed , actually it is very important for me ... someone has asked me to implement the neural network as a test-project for Haskell job which is my dream
10:19:57 <ddk> grmp: I have never asked if I can do it ... well reading the documentation and failing to understand pays at last now I got the things where I was stucked
10:20:19 <ddk> thanks a lot to our supportive community !!
10:44:31 <EvanR> WHAT
10:44:37 <EvanR> -freverse-errors
10:56:17 <srhb> EvanR: Most useful thing ever.
11:00:48 <osa1> haha I implemented that :-)
11:02:09 <srhb> osa1++
11:08:54 <AWizzArd> I looked at RWST from the mtl package. Why is it part of mtl? It seems that it is just a re-packaged version of RWST from the transformers package.
11:09:16 <nshepperd_> That makes it so your program only compiles if it has type errors?
11:09:21 <glguy> AWizzArd: It's not repackaged, it's just reexported
11:09:37 <glguy> AWizzArd: You don't need mtl at all. mtl adds some typeclasses on top of transformers
11:09:38 <nshepperd_> Error: no type errors
11:09:51 <AWizzArd> glguy: ah okay, I see.
11:10:21 <geekosaur> AWizzArd, transformers is a general package usable by two different implementations of transformer typeclasses: based on functional dependencies, or based on type families
11:11:12 <geekosaur> mtl uses fundeps. at one point when the community was evaluating implementations, we had monads-fd and monads-tf, both built on top of transformers, for various reasons, fundeps won out and mtl-2.x uses them
11:12:37 <geekosaur> but type families have matured a bit since then and some projects do use transformer classes built on transformers with type families instead of mtl's fundeps
11:13:06 <dolio> mtl used fundeps before transformers existed.
11:13:31 <dolio> I think they won for the new mtl because they were a smaller difference from the old mtl.
11:13:58 <geekosaur> partly yes, partly people ran into some problems with TFs that have since been fixed
11:15:05 <geekosaur> (one in particular was thought to be a serious shortcoming in TFs, but turned out to be a simple bug combined with a theoretical flaw in fundeps(!) that people had gotten used to abusing
11:15:20 <geekosaur> not realizing that it was in fact type-unsafe)
11:17:11 <geekosaur> well, not really a theoretical flaw so much as a weakness in safety validation that is very expensive to fix
11:19:40 <[exa]> EvanR: -freverse-errors sounded a bit cooler than it is... :D
11:22:00 <erisco> > fix error -- so did this
11:22:02 <lambdabot>  "*Exception: *Exception: *Exception: *Exception: *Exception: *Exception: *Ex...
11:22:30 <erisco> maybe you have to put the two together...
11:24:13 <[exa]> :]
11:28:08 <Enamex> Thanks a lot to everyone who helped today o/ :D
11:49:44 <Peaker> So - what Pretty printing library/class exists that has instances for base and nice deriving for user data-types?  It seems none exists?
11:49:46 <Peaker> There's a mish mash of incompatible pretty printers, with various classes in various packages that each choose one of the incompatible implementations and usually lack many instances (for ByteStrings, Maps, etc)
11:49:46 <Peaker> is the situation as messy as it seems? :(
11:49:46 <glguy> Peaker: Any particular pretty printing format is likely to be application specific
11:49:47 <Peaker> glguy, The same can be said of the Binary class
11:49:47 <glguy> Yeah, that's also true
11:49:47 <Peaker> You can still do your own Pretty'ing or Put'ing/Get'ing
11:49:47 <glguy> for some nicer formatted Show debugging you can use http://hackage.haskell.org/package/pretty-show
11:49:47 <Peaker> currently, I'm tempted to just abuse Show :-(
11:49:47 <glguy> generally it's a bad idea to use the Binary for much
11:51:36 <Peaker> glguy, because of unexpected format changes with upgrades?
11:54:23 <glguy> It encodes to a generic, undocumented format only suitable for reloading by code using the same version and instances
11:55:03 <Guest43> Is there a builtin `or` and `and` lifted to functions `a -> Bool`? Best I could come up with is something like "(`any` [even, prime]) . flip ($)" which is not readable, or a lambda "\x -> even x || prime x" which if fine but would get redundant with a lot of predicates   
11:55:04 <glguy> It's fine for quick hacks
11:58:25 <lyxia> Guest43: https://hackage.haskell.org/package/monad-loops-0.4.3/docs/Control-Monad-Loops.html#v:andM
11:58:50 <lyxia> \x -> and [p x | p <- [even, prime]]
11:59:17 <lyxia> :t and . sequence [even, prime]
11:59:18 <lambdabot> error:
11:59:18 <lambdabot>     Variable not in scope: prime :: a -> Bool
11:59:28 <lyxia> :t and . sequence [even, ?prime]
11:59:30 <lambdabot> (?prime::a -> Bool, Integral a) => a -> Bool
12:02:57 <Gurkenglas_> flip (any . flip id)
12:03:03 <bsima> are list comprehensions considered "good haskell"? like how often do you use them in production code?
12:03:04 <Gurkenglas_> :t flip (any . flip id) -- whoops
12:03:05 <lambdabot> Foldable t => t (b -> Bool) -> b -> Bool
12:03:31 <ezyang> bsima: They're fine. 
12:03:40 <ezyang> sometimes if you ahve a really complicated one you should use do-notation instead 
12:03:49 <grmp> :t and . sequence [even, odd]
12:03:51 <lambdabot> Integral a => a -> Bool
12:05:33 <bsima> ezyang: ok, i asked because i've had a love-hate relationship with Pyhon list comprehensions
12:05:45 <bsima> sometimes completely clear, othertimes completely unreadable
12:07:05 <Peaker> bsima, they're sometimes nice when you pattern-match, like: lefts xs = [x | Left x <- xs]
12:07:33 <mnoonan> imo the haskell list comprehensions are quite a bit less noisy than the python counterparts
12:08:07 <Peaker> mnoonan, the difference isn't that big. Though Python list comprehensions lack "let"
12:09:06 <mnoonan> Maybe it's just me. I find the 'for's and 'if's distracting compared to <- and ,
12:09:12 <bsima> Peaker: oh good point, i haven't used 'em like that before
12:12:41 <Peaker> mnoonan, do you use syntax highlighting that marks "for" and "if" in a distinct color?
12:40:22 <EvanR> osa1++
12:41:10 <EvanR> [exa]: yeah you would hope it would be kind of like "undo mistakes"
12:41:28 <EvanR> we have to wait until GHC has time travel
12:52:46 <gamegoblin> Is there an existing function that would convert `Maybe a` into `m a` where m is MonadPlus? e.g. Nothing goes to mzero and `Just x` goes to `return x`
12:54:34 <grmp> Is it possible to do it by pattern matching?
12:55:12 <gamegoblin> (could be implemented as `maybe mzero return` )
12:55:23 <gamegoblin> was just wondering if there was an existing function I guess
12:58:12 <lyxia> I can't find any.
12:59:18 <gamegoblin> I’ve found it pretty handy in some current code I’m writing that uses a lot of list monadic stuff
12:59:30 <sproingie> Maybe is already an instance of MonadPlus, so anything existing would be along those lines
12:59:50 <gamegoblin> (could use the specialization maybeToList, which I am, but realized it could be more general)
12:59:57 <sproingie> as in, just use Maybe where you have a MonadPlus constraint and It Should Just Work
13:00:04 <sproingie> assuming that's how it's mapped to MonadPlus anyway
13:00:36 <lyxia> The question is about how to get the other way around.
13:00:58 <sproingie> not really how i read the question
13:16:10 <orion> Just by looking at this function, are you able to tell if, when an exception is thrown, it will be rethrown?: https://www.stackage.org/haddock/lts-8.22/postgresql-simple-0.5.3.0/src/Database.PostgreSQL.Simple.Transaction.html#withTransactionMode
13:20:13 <sproingie> you'd look up E.onException, which implies (vaguely) that it would rethrow
13:22:45 <sproingie> that's one place where checked exceptions would be handy.  or some effect system of that ilk.
13:23:58 <EvanR> onException is like finally which is like bracket which all do something and rethrow
13:24:09 <zomg> if I have a thread which reads data from a socket, and it gets an event handler function which is assigned to it from another thread
13:24:28 <zomg> I take it that if the reader thread calls this function, it'll be called in the context of the reading thread rather than the thread that put the function there?
13:24:47 <zomg> just want to confirm I'm understanding this correctly so I can forkIO the necessary bits so it won't choke the reader thread :P
13:24:50 <lyxia> yes
13:25:47 <zomg> lyxia: cool, in a system like this where you might have multiple event handlers being triggered from socket reads depending on what's being read, would the reader thread generally forkIO the listener or how would it be handled?
13:26:01 <zomg> haven't really done much this type stuff besides in javascript where's just callbacks all the way down :P
13:26:42 <EvanR> js is pretty oddball as far as this goes
13:27:38 <zomg> yeah, the IO is mostly elsewhere in JS so you don't really need to think of this
13:27:40 <EvanR> if you want the reader handler to finish before doing another one, seems like youd want the reader thread to do it
13:28:16 <zomg> it doesn't really matter in this instance - it's a websocket stream so I'd just want it to keep reading the messages that come in
13:28:26 <zomg> as it might potentially receive another message that needs to be handled by something else
13:29:18 <EvanR> if it doesnt matter, then not arrangement for even more threads is easier
13:29:33 <EvanR> in a loop, when you get enough bytes, execute the handler
13:30:31 <zomg> right, but in that case if the handler does something that takes a while to finish it wouldn't read anything until that's done
13:31:59 <zomg> if I wanted the reader to keep reading in the background, should the reader fork, or should the handling function be responsible for forking?
13:32:22 <zomg> just wondering which makes more sense in terms of how the code is structured :)
13:32:37 <EvanR> so it does matter
13:32:52 <EvanR> essentially we are playing guess the requirements
13:32:57 <zomg> ah, yeah it might matter - I've not really decided yet but want to understand any potential implications
13:32:58 <EvanR> higher, lower
13:33:14 <zomg> lol yeah, sorry if it's confusing :)
13:33:42 <zomg> it's the usual issue of "well I've done this before, but not in haskell" for me :P
13:34:19 <zomg> but yeah sounds like the idea I had on how it would work is correct
13:34:29 <EvanR> also usual, you may not have thought about it in such excruciating precision before haskell
13:34:45 <zomg> just not sure what would be the way to structure it in terms of where the thread gets forked - in the reader, or in the handler
13:34:48 <zomg> lol
13:34:54 <zomg> yeah probably not because javascript doesn't care so much :P
13:34:56 <EvanR> haskell doesnt have much support for do it then understand it later
13:35:18 <zomg> which is pretty much why I'm asking about it now before I dig the hole too deep
13:35:30 <EvanR> so far it sounds like a performance thing
13:36:03 <EvanR> add extra complexity to potentially handle parts of a stream faster
13:36:12 <zomg> right
13:36:40 <EvanR> at some point there was a FCGI lib that did this
13:36:44 <zomg> in some instances it might need to do some requests to a 3rd party api which is what can potentially take longer than it would take to receive more messages
13:37:01 <EvanR> since FCGI supports request multiplexing on a single connection, but many implementations dont bother
13:37:07 <zomg> most of the messages require very little processing
13:37:28 <EvanR> haskell kind of makes it sane to do it
13:39:21 <e_> haxx0r
13:39:35 <zomg> l44t h3xx0r
13:39:56 <EvanR> l55t, beat that
13:40:14 <zomg> you can't even pronounce that
13:40:16 <e_> one three three seven
13:40:17 <zomg> it's on an entirely different level
13:40:45 <jared-w> l55t? l shhhhhhh t. Bam, pronounced
13:40:58 <monochrom> 31337 is a prime number.
13:41:06 <e_> port
13:41:14 <e_> icq
13:41:25 <e_> for sniffing
13:41:35 <zomg> monochrom: it is? :P
13:41:46 <EvanR> yeah isnt that used in a popular RNG
13:42:28 <zomg> heh
13:42:51 <e_> can i get bnc producing?
13:45:23 <EvanR> whoevers chatbot this is, its not very good
13:46:06 <e_> TLS need
13:48:34 <bgamari> orion, ping
13:50:57 <orion> bgamari: Hey. I have a Servant application which uses Opaleye. I am getting very tired of "ask"ing for the DB connection and supplying it to every function. I'd like to just have it "ask"ed for at the right moment. This requires that withTransaction accept a MonadIO.
13:51:32 <orion> But according to lpsmith there are some concerns about async exceptions that I don't fully understand.
13:51:46 <orion> I'
13:52:38 <orion> I'm wondering if you have any suggestions for this. Should I grit my teeth and just pass the Connection many times all over the place, or is there a better solution?
13:52:53 <bgamari> ahh
13:52:57 <bgamari> yes, this issue
13:53:18 <bgamari> orion, I'm afraid that there isn't a great solution until something is accepted upstream
13:53:43 <orion> bgamari: Are there pending changes waiting to be accepted?
13:53:51 <bgamari> orion, which, as you noticed, there is some disagreement about
13:53:58 <bgamari> orion, there is
13:54:10 <orion> https://github.com/lpsmith/postgresql-simple/pull/195 <-- this?
13:54:21 <bgamari> orion, https://github.com/lpsmith/postgresql-simple/pull/195
13:54:22 <bgamari> yep
13:54:41 <bgamari> orion, if you ping leon there's a good chance he'll just merge it
13:54:53 <bgamari> last I spoke to him he sounded close to caving ;)
13:55:52 <bgamari> I personally think that `exceptions` is generally the more reasonable interface here, even if it may theoretically lack some generality
13:56:12 <orion> What is the exact technical issue?
13:56:33 <orion> I don't fully understand the comments in the issue/PR.
13:57:04 <orion> monad-control (et al) are esoteric concepts to me.
13:57:09 <jared-w> I think most of the friction is coming from the fact that exceptions lacks some theoretical generality which allows for it to be much easier to write instances of than monad-control
14:00:34 <orion> What specifically needs to be generalized?
14:00:47 <orion> Rather, what generality is lacking?
14:05:35 <jared-w> ¯\_(ツ)_/¯
14:06:36 * hackagebot plot-light 0.1.0.8 – A lightweight plotting library, exporting to SVG – https://hackage.haskell.org/package/plot-light
14:18:07 <Denommus`> hi
14:21:24 * hackagebot log-warper 1.1.4 – Flexible, configurable, monadic and pretty logging – https://hackage.haskell.org/package/log-warper
14:21:24 * hackagebot plot-light 0.1.0.9 – A lightweight plotting library, exporting to SVG – https://hackage.haskell.org/package/plot-light
14:53:49 <ironChicken> in groundhog select, it seems that i have to refer to column names for constraints by some sort of constructor
14:58:12 <iqubic> What is groundhog select
14:58:15 <iqubic> ??
15:04:57 <ironChicken> groundhog is a library for database access, and select is a function is includes for doing SQL SELECT queries
15:05:13 <ironChicken> "ghc: panic! (the 'impossible' happened)"
15:06:35 <lyxia> ironChicken: do you have some code to make your problem more concrete
15:10:10 <ironChicken> lyxia: for the groundhog thing? i've got a ton of very application-specific code
15:11:16 <Tuplanolla> You either found a bug in GHC or did something ridiculously stupid, ironChicken. That's all we can tell from your description.
15:11:42 <hpc> or both!
15:11:55 <ezyang> no, ghc's never supposed to panic, so the user is never wrong. 
15:12:30 <Tuplanolla> You can get it to panic with unsafe functions and a bit of luck.
15:12:46 <bbear> hello
15:12:48 <ironChicken> actually, i think i may have worked out what's going on: i think groundhog uses template haskell to generate types from *my* type's field names; i was making the TH, err, "call" in one module and hoping to be able to import the new types generated into another module
15:13:20 <ironChicken> it looks like those TH-generated types don't get exported
15:13:35 <bbear> is it true  ? Functor -> Applicative Functor -> Monoïd and Functor -> Applicative Functor -> Monad and Monad -> MonadPlus <- ApplicativeFunctor ?
15:13:53 <ironChicken> and then when i tried doing the TH "call" in the module where i actually wanted to generated types to be available, i got the panic
15:14:43 <ironChicken> anyway, i guess i'll need to abstract out a simple version of this
15:15:38 <lyxia> bbear: what
15:15:44 <ironChicken> because no one's going to understand what on earth i'm talking about
15:16:11 <bbear> if something is a Monoïd then it's also an applicative functor ?
15:16:36 <Clint> bbear: did you mean Monad?
15:16:38 <hpc> out of curiosity, why do you spell it with a double-dotted i?
15:16:53 <bbear> That's from french
15:16:56 <bbear> monoïde
15:17:11 <bbear> it's the same 
15:17:49 <bbear> why don't you say a monoïde is just kind of, something, with, like a left-and-right associative operation and a neutral element ?
15:18:05 <bbear> it would be more natural to me.
15:18:34 <geekosaur> MonadPlus is actually Alternative, I think?
15:20:23 <lyxia> bbear: although given a monoid you can associate it to an applicative functor, it's somewhat unusual to say that a monoid *is* an applicative functor
15:20:54 <lyxia> especially since in Haskell they correspond to types of different kinds
15:21:33 <gamegoblin> If i’ve got a `a -> m a` and I want to apply this function to a starting `a` N times to get a final `m a`, is there a function that already does this?
15:21:52 <gamegoblin> Something kind of like monadic iterate I guess?
15:22:00 <gamegoblin> and I ony want the final value
15:22:02 <lyxia> bbear: http://hackage.haskell.org/package/base-4.9.1.0/docs/Data-Monoid.html "types with an associative binary operation that has an identity"
15:23:14 * Clint sighs.
15:23:26 <gamegoblin> Clint: ?
15:23:36 <ironChicken> would people expect TH-generated types to be exported from a module?
15:24:09 <Clint> gamegoblin: didn't someone answer this question the other day?
15:24:20 <gamegoblin> Clint: dunno, I wasn’t on here the other day
15:24:28 <Clint> weird
15:24:33 <lambdamu_> gamegoblin: iterate (flip (>>=) f)
15:24:42 <gamegoblin> lambdamu_: fancy
15:25:07 <lambdamu_> gamegoblin: straightforward :D
15:25:16 <iqubic> lambdamu_: try "iterate (=<<)"
15:25:18 <gamegoblin> Isn’t there a version of >>= that already has its arguments reversed? 
15:25:21 <gamegoblin> yeah that
15:25:32 <iqubic> :t iterate (=<<)
15:25:34 <lambdabot> error:
15:25:34 <lambdabot>     • Occurs check: cannot construct the infinite type: a ~ m a
15:25:34 <lambdabot>       Expected type: (m a -> m b) -> m a -> m b
15:25:42 <iqubic> :t iterate (=<<) f
15:25:43 <lambdabot> error:
15:25:43 <lambdabot>     • Occurs check: cannot construct the infinite type: a ~ m a
15:25:43 <lambdabot>       Expected type: (m a -> m b) -> m a -> m b
15:25:53 <iqubic> Or not that.
15:26:14 <lambdamu_> Well of course you can use =<< and save the flip
15:26:24 <iqubic> You can't actually.
15:26:33 <lambdamu_> sure you can
15:26:42 <Tuplanolla> :t \ f -> iterate (f =<<)
15:26:43 <lambdabot> Monad m => (a -> m a) -> m a -> [m a]
15:26:54 <iqubic> Alright, there we go.
15:27:19 <Tuplanolla> :t iterate . (=<<) -- It's just this.
15:27:21 <lambdabot> Monad m => (a -> m a) -> m a -> [m a]
15:27:31 <iqubic> Tuplanolla: We only want the last value though.
15:27:45 <gamegoblin> well, I want the Nth value, specifically
15:28:07 <lambdamu_> if only there were a function for that
15:28:18 <iqubic> :t (iterate . (=<<)) !! n
15:28:20 <lambdabot> error:
15:28:20 <lambdabot>     • Couldn't match expected type ‘[a]’
15:28:20 <lambdabot>                   with actual type ‘(a0 -> m0 a0) -> m0 a0 -> [m0 a0]’
15:28:30 <iqubic> :t  n !! (iterate . (=<<))
15:28:32 <lambdabot> error:
15:28:32 <lambdabot>     • Couldn't match expected type ‘[a]’ with actual type ‘Expr’
15:28:32 <lambdabot>     • In the first argument of ‘(!!)’, namely ‘n’
15:28:45 <iqubic> :t \n -> n !! (iterate . (=<<))
15:28:47 <lambdabot> error:
15:28:47 <lambdabot>     • Couldn't match expected type ‘Int’
15:28:47 <lambdabot>                   with actual type ‘(a0 -> m0 a0) -> m0 a0 -> [m0 a0]’
15:28:57 <iqubic> :t \n -> (iterate . (=<<)) !! n
15:28:58 <lambdabot> error:
15:28:59 <lambdabot>     • Couldn't match expected type ‘[a]’
15:28:59 <lambdabot>                   with actual type ‘(a0 -> m0 a0) -> m0 a0 -> [m0 a0]’
15:29:05 <iqubic> I don't get this at all.
15:29:08 <iqubic> I'm sorry
15:29:08 <gamegoblin> I decided to just do it the boring way and landed at
15:29:09 <gamegoblin> iterateM :: Int -> (a -> m a) -> a -> m a 
15:29:10 <gamegoblin> iterateM 0 _ x = return x
15:29:11 <gamegoblin> iterateM n f x = f x >>= iterate (n-1) f
15:29:42 <iqubic> That's fine
15:29:53 <gamegoblin> not nearly as fancy as some point free voodoo though ;)
15:30:03 <iqubic> No, but it looks nice
15:30:18 <Tuplanolla> :t (!!) .: iterate . (=<<) -- Needs more dot again.
15:30:19 <lambdabot> Monad m => (a -> m a) -> m a -> Int -> m a
15:30:31 <iqubic> What does .: do?
15:30:34 <lambdamu_> gamegoblin: The best solution is the one that works and you can come up with yourself
15:30:39 <iqubic> :t (.:)
15:30:40 <lambdabot> (Functor f1, Functor f) => (a -> b) -> f1 (f a) -> f1 (f b)
15:30:48 <iqubic> Oh. I see now
15:30:56 <Tuplanolla> It's the owl operator, iqubic.
15:31:22 <iqubic> Is that what it's called?
15:31:24 <iqubic> Why?
15:31:31 <jared-w> Its other form is  (.).(.)
15:31:33 <Tuplanolla> Stare at `(.:) = (.) . (.)` for a moment.
15:31:53 <jared-w> It's also known by more lewd names, but most people don't say those out loud :p
15:32:06 <iqubic> The boob operator?
15:32:21 <CrazedProgrammer> lol
15:32:39 <iqubic> :t (.) . (.)
15:32:41 <lambdabot> (b -> c) -> (a1 -> a -> b) -> a1 -> a -> c
15:32:52 <iqubic> How the heck does that work?
15:33:21 <jared-w> I googled this literally not even 2 hours ago
15:33:23 <Tuplanolla> The expression `f .: g` expands to `(f .) . g`.
15:33:26 <jared-w> https://stackoverflow.com/questions/15029843/how-can-i-understand
15:33:30 <jared-w> https://stackoverflow.com/questions/17972422/how-does-haskells-boobs-operator-work-in-plain-non-functional-english
15:34:33 <lambdamu_> The owl is (.)$(.) though, according to the wiki
15:34:41 <lambdamu_> :t (.)$(.)
15:34:42 <lambdabot> (a1 -> b -> c) -> a1 -> (a -> b) -> a -> c
15:34:59 <infinity0> does anyone have a "picture explanation" of what an adjoint is
15:35:27 <jared-w> I think there's just multiple owl operators out there. I've only ever seen (.).(.) and not the $ version, though
15:35:41 <Tuplanolla> @google bartosz milewski adjoint functor
15:35:43 <lambdabot> https://bartoszmilewski.com/2016/04/18/adjunctions/
15:35:49 <Tuplanolla> Look there, infinity0.
15:36:12 <infinity0> ah, thanks
15:36:54 <lambdamu_> infinity0: I would look at galois connections first which are as general but more intuitive since they only talk about posets
15:37:14 <lambdamu_> s/as general/no as general/
15:38:56 <alhariel> newtype Foo = Foo Int -- how do i make this an instance of QuickCheck's Arbitrary class?
15:39:46 <OwlEquation> clear
15:39:58 <lambdamu_> alhariel: You can "inherit" the Arbitrary instance from Int with GeneralizedNewtypeDeriving
15:40:21 <alhariel> but how would i do it manually
15:42:18 <lambdamu_> alhariel: Can you be more specific? You have to construct a generator Gen Foo for the aribitrary implementation
15:42:33 <lambdamu_> alhariel: But you probably know that
15:42:51 <geekosaur> instance Arbitrary Foo where arbitrary = Foo . arbitrary
15:44:12 <lyxia> s/\./<$>/
15:44:13 <geekosaur> if you don't want the defualt shrink: shrink (Foo a) = fmap Foo (shrink a)
15:44:19 <monochrom> I love Galois connections. :)
15:44:27 <geekosaur> hm, yeh
15:44:35 <geekosaur> probably same there too
15:44:49 * geekosaur ... feh. not a good day
15:44:54 <infinity0> think i'll work through the first 17 chapters of bartosz' blog first :)
15:45:15 <monochrom> Haha 17 chapters.
15:45:51 <alhariel> thanks XD
15:46:06 <alhariel> i dont really get why but it works XD
15:50:27 <Pamelloes> Is there a good comparison of parsing libraries I can read?
15:55:45 <dmwit> Which would you prefer: `maybe [] (:[])` or `toList`?
15:57:13 <infinity0> for the boobs operator, the sequence of steps that i found easiest to follow was to keep expanding `(.) f` because f's type remains constant when you keep doing (.).(.).(.) etc, so you can see the pattern more easily
15:57:15 <infinity0> http://lpaste.net/356876
16:21:55 * hackagebot language-ecmascript 0.17.2.0 – JavaScript parser and pretty-printer library – https://hackage.haskell.org/package/language-ecmascript
16:24:59 <infinity0> lambdabot: unpl id
16:25:34 <infinity0> @unpl id
16:25:34 <lambdabot> (\ x -> x)
16:25:46 <infinity0> @pl \f g h x -> f (g (h x))
16:25:47 <lambdabot> (. (.)) . (.) . (.)
16:26:00 <infinity0> @pl \f g h j k x -> f (g (h (j (k x))))
16:26:00 <lambdabot> (. ((. ((. (.)) . (.) . (.))) . (.) . (.) . (.))) . (.) . (.) . (.) . (.)
16:26:18 <infinity0> wonder if that can be simplified..
16:26:19 <geekosaur> "@pl: a bit dotty"
16:26:39 <infinity0> point "less"
16:26:57 <Tuplanolla> @pl \ f g x -> f (g x)
16:26:57 <lambdabot> (.)
16:27:38 <infinity0> so i can see that id f = \x -> f x, (.)f = \g x -> f (g x), (.)((.) f) = \h y x -> f (h y x) and the pattern continues
16:27:41 <Tuplanolla> The way this tool decides to nest those dots is strange.
16:28:21 <infinity0> was wondering what combination would make the other pattern continue, \x -> f x, \g x -> f (g x), \g h -> f (g (h x))
16:31:59 <Tuplanolla> @unpl (.)
16:31:59 <Tuplanolla> @unpl ((.) .) . (.)
16:31:59 <Tuplanolla> @unpl (((.) .) .) . ((.) .) . (.)
16:31:59 <lambdabot> (\ f g x -> f (g x))
16:31:59 <lambdabot> (\ x x0 g0 x1 -> x (x0 (g0 x1)))
16:31:59 <lambdabot> (\ x x0 x1 g1 x2 -> x (x0 (x1 (g1 x2))))
16:32:09 <Tuplanolla> Like so, infinity0.
16:33:01 <infinity0> that seems simpler than the @pl output, how did you do it?
16:33:10 <Tuplanolla> By feel.
16:33:45 <infinity0> ((((n-times .) .) .) n-times) . (expression for n-1) from the looks of it
16:34:00 <infinity0> very impressed if you did that in your head just now!
16:34:54 <infinity0> @unpl ((((.).).).) . (((.) .) .) . ((.) .) . (.)
16:34:54 <lambdabot> (\ x x0 x1 x2 g2 x3 -> x (x0 (x1 (x2 (g2 x3)))))
16:35:40 <Tuplanolla> I've been on sufficiently many pointless adventures.
16:35:56 <infinity0> hehe
16:38:10 <infinity0> ah ((.).) is the same as the owl operator
16:39:42 <jared-w> lambdabot uses a pointfree genreation algorithm that does not include any simplification steps, iirc
16:40:41 <geekosaur> it actually has some but they're not very good
16:41:02 <geekosaur> with a very complex expression it'll sometimes tell you it gave up on simplification
16:59:28 <Pamelloes> If I'm processing a file using Parsec, but I need to do some preprocessing before running the parser, how can I make sure that any errors report their position in the original file instead of the processed file?
17:01:05 <kadoban> What sort of preprocessing? Can you encode it all in parsec instead of doing the preprocessing?
17:01:59 <lyxia> Pamelloes: you might include tokens in the post-processed stream that update the current position
17:04:38 <Pamelloes> I'm replacing triglyphs and removing escaped newlines using iterated calls to replace
17:05:36 <Pamelloes> Is there an easy way to integrate this into the parser?
17:40:41 <mikail_> can anyone recommend good resources for creating DSLs in Haskell?
17:51:03 <Axman6> mikail_: what sort of DSLs?
17:51:45 <Axman6> using GADTs is usually an excellent place to start though, and many of the examples of their use are in creating some sort of language
17:53:51 <mikail_> Axman6, I am not sure - I am totally newbie so would be learning from ground up. Main impetus is possibly to hack my own for creating smart contracts (blockchain stuff)
17:54:34 <mikail_> would like to know the theory behind DSLs, what makes a good DSL, how Haskell helps in these aspects
17:54:58 <mikail_> everyone keeps telling me Haskell is a great language for creating DSLs
17:55:02 <mikail_> ;)
17:55:50 <Axman6> well, it is, but there's also a lot of external knowlegde needed too (about languages and about your domain, ocourse)
17:55:56 <Axman6> of course*
18:13:22 <plugin> I have a DemoteRep Float from the singltons package that I need to get to a Float.  Data.Coerce.coerce doesn't seem to yield any joy, anyone know how I might do this?
18:17:08 <c_wraith> plugin: as far as I can tell, a DemoteRep Bool *is* a Bool
18:17:26 <c_wraith> plugin: The same for DemoteRep Float and Float, of course
18:18:33 <c_wraith> plugin: unless there is no SingKind instance for Float
18:19:08 <glguy> plugin: How'd you get a DemoteRep Float?
18:25:06 <glguy> plugin: Send the messages to #haskell
18:28:02 <glguy> plugin: there aren't any type level Floats to demote
18:29:17 <c_wraith> I wondered if that might be the case.
18:29:48 <c_wraith> Though I also wondered if singletons did something clever to get around that.
18:37:07 <plugin> Ah, It looks like treating DemoteRep Float like a float and actually adding all the correct instances fixes things
18:38:01 <plugin> for reference, DemoteRep a is what comes back when you pull a SingI a into scope with a pattern match
18:45:35 <zwild> Hi, I'm new here. Could someone tell me the pros and cons of compiler writing between Haskell and OCaml?
18:46:47 <Axman6> not really, they would use some different techniques, but you can't really make connects about arbitrary nonexistant things
18:46:48 <monochrom> Haskell pro: better for purely functional algorithms. cons: worse for imperative algorithms.
18:47:06 <monochrom> OCaml pro: better for imperative algorithms. cons: worse for purely functional algorithms.
18:47:55 <Axman6> pretty much all of the choices you could make in one language you could make in the other, the languages doesn't really restrict how a compiler would be implemented in it
18:48:01 <Axman6> made*
18:48:21 <trigone> hi, just to check? fmap g ma == ma >>= return . g
18:48:30 <Axman6> yep
18:48:47 <Axman6> IIRC that's one of the laws for Monad too
18:48:52 <Axman6> or, related at least
18:48:59 <monochrom> Yeah.
18:49:02 <trigone> Axman6: thx
18:49:57 <zwild> Thanks.
18:50:14 <trigone> is there no (flip . fmap) predefined? to respect the sequential order when order there is  
18:50:23 <trigone> sorry flip fmap
18:51:28 <Axman6> there's <&>
18:51:35 <Axman6> :t (<&>)
18:51:36 <lambdabot> Functor f => f a -> (a -> b) -> f b
18:51:45 <Axman6> really useful for lens code
18:52:15 <trigone> Axman6: from Data.Functor?
18:53:32 <trigone> cuz importing Lens seems... weirdish
18:53:43 <trigone> i mean if it's only for this.
18:53:52 <Axman6> not sure where it's defined, it's super useful for lens though
18:54:19 <trigone> apparently it's only in Control.Lens.Lens
18:54:59 <trigone> in terms of style, would you recommend importing one tool like that from whatever module even if it's really not the topic?
18:55:15 <trigone> the topic of the code that imports
18:55:36 <glguy> trigone: I wouldn't add a dependency on lens in order to get <&>, but I wouldn't hesitate to import that module for <&> if I already depended on lens
18:56:04 <Welkin> o.o
18:56:12 <Welkin> that is absurd
18:56:17 <trigone> glguy: ok...
18:56:17 <Welkin> just define it yourself
18:56:23 <Welkin> & = $
18:56:26 <Welkin> er
18:56:31 <Welkin> (&) = flip ($)
18:56:37 <Welkin> (<&>) = flip (<$>)
18:56:40 <glguy> and set the correct fixity
18:59:09 * hackagebot shakers 0.0.26 – Shake helpers. – https://hackage.haskell.org/package/shakers
18:59:45 <trigone> Welkin: feels like reinventing the wheels to not import the whole car, but then... i think that given haskell's propensity to high reusability, functions should be much more fluidly accessible to importing than that... it's like as soon as you try to connect two source files, you lose all the mathematical abstraction
19:00:05 <trigone> of the language
19:01:44 <Welkin> why would you import something you can write with 2 words?
19:02:20 <Welkin> Also, I don't see why anyone would ever use & or <&> outside of lens
19:02:23 <Welkin> it doesn't make sense
19:02:45 <c_wraith> Welkin: people beg for & to exist all the time.
19:03:05 <c_wraith> Welkin: mostly F# programmers, for some reason...
19:04:17 <pacak> It's nice if you want to make your code unreadable.
19:07:46 <glguy_> The nice thing about the & version is that it combines nicely with a lambda
19:11:28 <Eduard_Munteanu> It might make sense with a minimal lens package.
19:11:28 <glguy_> whatever <&> \x -> stuff x y z
19:11:28 <Eduard_Munteanu> We should really have configurable packages and dependencies, I suppose.
19:14:20 <trigone> infixl means a `f` b `f` c `f` d == (a f (b f (c f d))) ? do pretend i put the agrave quotes everywhere
19:15:15 <glguy_> No that isn't infixl
19:16:23 <trigone> oh nvm i mixed up between <&> and <$>, and they're obviously associative in opposite directions
19:17:03 <trigone> btw, something defined as infix (without L/R) will refuse to be associative or is there a default?
19:17:20 <glguy_> Refuse
19:17:42 <trigone> glguy_: k thx
19:18:42 * hackagebot filter-logger 0.1.0.0 – Filterable request logging as a wai middleware. Change what data is logged and… – https://hackage.haskell.org/package/filter-logger
19:18:42 * hackagebot preamble 0.0.45 – Yet another prelude. – https://hackage.haskell.org/package/preamble
19:19:56 <trigone> say i want to mix =<< and <$> together, as in
19:19:58 <trigone> f <$> g <$> h =<< ma
19:20:24 <trigone> will that be parsed appropriately aka f <$> (g <$> (h =<< ma))
19:20:45 <johnw> trigone: I always use parens in that case, if just for the sake of future readers
19:20:55 <glguy> trigone: No, that's not correct
19:20:56 <johnw> anytime *you* have to think about precedence rules, use parens
19:21:11 <pacak> For the sake of future myself...
19:21:16 <glguy> It would be parsed:   ((f <$> g) <$> h) =<< ma
19:21:40 <trigone> johnw: yeah i suppose you're right... but i was just wondering, as they're both right-associative and of identical level of precedence
19:21:57 <glguy> trigone: <$> is not right associative, and not identical precedence
19:22:04 <glguy> not identical to =<<
19:22:05 <trigone> glguy: no i think you're wrong. <$> is right associative
19:22:14 <glguy> trigone: That's incorrect
19:22:21 <johnw> knowledge battle!
19:22:42 <Welkin> johnw: epic rap battleeeeeeeeeeeeeeee!
19:22:52 <trigone> then what's the type of (f <$> fa) if it's not Functor f => f b?
19:23:04 <glguy> Types have nothing to do with this question
19:23:26 <glguy> trigone: Open GHCi and you can type    :info <$>
19:24:38 <trigone> glguy: i stand corrected. <&> was left associative, which i found logical, and so i thought that was the case for $ too.
19:24:41 <trigone> <$>
19:25:24 <glguy> Yes, both <&> and <$> are left associative, but not the same precedence
19:26:24 * hackagebot filter-logger 0.2.0.0 – Filterable request logging as a wai middleware. Change what data is logged and… – https://hackage.haskell.org/package/filter-logger
19:26:45 <trigone> there's still very little logic in it. ($) in (f $ g $ h $ a) is rightfully right associative, and what's the point of having (f <$> ma) <$> mb parsed without parentheses. it's not as if you'd expect every result of fmap to be function to be mapped over something else... this is absurd
19:27:07 <glguy> Yeah, it's either absurd or you don't understand it
19:27:17 <glguy> <$> is intended to be mixed with <*>
19:27:24 <johnw> trigone: you could think of it as having to do with the "order of effects"
19:27:37 <glguy> and in that context of    f <$> a <*> b   , left associative makes the most sense
19:27:58 <glguy> trigone: You typically won't use two <$> together
19:28:10 <Welkin> but you might use <$$>
19:28:12 <glguy> instead you'd write:   f . g <$> a
19:28:16 <trigone> glguy: it couldn't be tweaked with precedences so that (f <$> a) be grouped before the rest?
19:28:19 <Welkin> which is fmap . fmap
19:28:19 <Welkin> :D
19:28:38 <glguy> trigone: No, it doesn't need to be tweaked
19:28:46 <trigone> glguy: hm, yes, point free notation does do the trick
19:28:52 <Welkin> trigone: have you seen $> or <$ yet?
19:28:55 <glguy> as it happens: f . g <$> a   is the same as   f <$> g <$> a
19:28:56 <trigone> glguy: i meant in the meaning of "couldn't have been"
19:29:56 <trigone> Welkin: yes?
19:31:33 <trigone> Welkin: i don't get how that could be useful here
19:32:22 <glguy> trigone: What problem are you trying to solve?
19:34:24 <trigone> glguy: i'm not trying to solve anything. i was wondering the best way to fmap two times in a row using symbolical operators. the point free method is the best.
19:34:50 <glguy> trigone: Like I mentioned you can actually just use <$> twice
19:35:07 <glguy> > (+1) <$> (*2) <$> [1..10]
19:35:09 <lambdabot>  [3,5,7,9,11,13,15,17,19,21]
19:35:29 <glguy> It just doesn't have the associativity you thought
19:36:29 * hackagebot wolf 0.3.22 – Amazon Simple Workflow Service Wrapper. – https://hackage.haskell.org/package/wolf
19:36:29 * hackagebot loup 0.0.11 – Amazon Simple Workflow Service Wrapper for Work Pools. – https://hackage.haskell.org/package/loup
19:40:47 <trigone> glguy: hm i had forgotten fmap for Functor (-> a) was (.)
19:46:49 <trigone> Maybe has an instance for MonadPlus? with mzero = Nothing?
19:49:38 <Cale> trigone: for (->) a
19:49:53 <pacak> > mplus mzero mzero :: Maybe ()
19:49:55 <lambdabot>  Nothing
19:50:06 <Cale> trigone: and yeah, Maybe is an instance of MonadPlus
19:50:38 <Cale> > mplus (Just 5) (Just 7)
19:50:40 <lambdabot>  Just 5
19:50:45 <trigone> Cale: yeah i misspelled it
19:50:45 <Cale> > mplus Nothing (Just 7)
19:50:47 <lambdabot>  Just 7
19:51:55 <trigone> it acts in the conceptual spirit of an "or", right?
19:52:07 <monochrom> Yes.
19:53:53 <trigone> if i wanted the equivalent of an "and" on Maybe, would that be something like a monoid?
19:55:01 <glguy_> More like Monad
19:55:09 <Cale> liftM2 something ?
19:55:26 <monochrom> Yeah.
19:55:43 <monochrom> So it just needs Applicative? :)
19:55:56 <monochrom> (Also, "or" just needs Alternative? :) )
19:56:07 <Cale> yeah
19:56:14 <trigone> monochrom: i think you're right
19:56:29 <Cale> Of course, once you know that it's Maybe, the difference is a bit of a moot point
19:59:09 <trigone> Cale: what do you mean moot?
20:00:53 <trigone> how is mfilter supposed to be used in a do block?
20:00:58 <Cale> trigone: Well, the Alternative operations empty and <|> are implemented the same way as mzero and mplus for Maybe
20:01:17 <Cale> and using Applicative via liftA2 will amount to the same thing as liftM2 for Maybe
20:01:28 <Cale> But Applicative/Alternative are a little bit more general
20:01:55 <trigone> Cale: i got what you meant
20:03:06 <Cale> x <- mfilter someCondition someAction
20:05:18 <trigone> Cale: yes, no that's not what i meant but i realized what i meant was impossible
20:08:51 <jared-w> I love learning organically
20:09:02 * jared-w finally got around to groking corecursion and codata
20:09:49 <iqubic> What is corecursion?
20:09:57 <jared-w> the dual to recursion
20:10:14 <iqubic> How does it work?
20:10:30 <jared-w> Recursion can be thought of taking a data structure and breaking it down in a defined way to get to the base case. Corecursion, then, starts from a base case and builds up an infinite result in a structured way
20:10:41 <iqubic> Huh???
20:10:49 <iqubic> How?
20:11:07 <jared-w> So for example, the integer factorials, as a recursive function, would be something like: fact 0 = 1; fact n = n * fact (n-1)
20:11:20 <iqubic> Sure.
20:11:54 <iqubic> how about corecursion?
20:11:56 <jared-w> A corecursive function would have:  (\(n,f) -> (n+1, f*(n+1))) `iterate` (0,1)
20:12:05 <iqubic> Huh???
20:12:11 <trigone> the monadic laws guarantee (ma == ma >>= return), right? as in, no additional "monadic effect" added no matter the monad?
20:12:27 <iqubic> yes.
20:12:35 <jared-w> which will generate a list [(0,1) , (1,1), (2, 2*1), (3, 3*2*1), (4, 4*3*2*1), ...]
20:13:20 <trigone> jared-w: so, you replace recursion by laziness?
20:13:52 <trigone> and you get results by exploring the infinite structure?
20:15:10 <jared-w> one sec, gotta roll up the windows in my car so it doesn't get soaked by sprinklers
20:15:23 <trigone> :t iterate
20:15:25 <lambdabot> (a -> a) -> a -> [a]
20:15:26 <jared-w> http://blog.sigfpe.com/2007/07/data-and-codata.html  <-- I'm reading this if anyone wants a better explanation than I can provide
20:16:38 <trigone> you say corecursive *function*, but where's the function?
20:17:16 <jared-w> the function I gave was a lambda function example from a wikipedia page :p
20:19:02 <Pamelloes> How can I insert a character to a parsec stream mid parse?
20:21:09 <iqubic> :t (\(n,f) -> (n+1, f*(n+1))) `iterate` (0,1)
20:21:11 <lambdabot> Num a => [(a, a)]
20:21:18 <trigone> oh you meant the lambda... nice blogpost btw
20:22:00 <iqubic> jared-w: can you take that function and turn it into factorial n?
20:22:19 <iqubic> like how do you retrieve the factorial associated with a given n?
20:22:27 <Axman6> Pamelloes: that sounds like a very odd thing to do
20:22:31 <jared-w> fibs = 1 : 1 : zipWith (+) fibs (tail fibs) -- this is the corecursive form of fibbonaci sequence
20:23:09 <jared-w> iqubic: it's a infinite stream of factorials. You can generate all the factorials up to some number n and then take the last value
20:24:22 <iqubic> :t zipWith
20:24:24 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
20:25:11 <jared-w> > zipWith (+) [1..5] [100..105]
20:25:13 <lambdabot>  [101,103,105,107,109]
20:25:53 <iqubic> I see how that works.
20:26:09 <jared-w> fibs here is of type [num], so zipWith (+) zips fibs with the tail of fibs. It's quite neat :p
20:26:19 <iqubic> What baffles me is that lists can be defined recursivelu like this:
20:26:34 <iqubic> > let ones = 1:ones in ones
20:26:36 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
20:26:49 <iqubic> That's recursive and lazy.
20:27:03 <jared-w> That's not recursively, that's corecursively
20:27:21 <MarcelineVQ> corecursive?
20:27:29 <jared-w> At least I believe it's corecursive?
20:27:42 <Welkin> looks recursive to me
20:28:02 <jared-w> ones = 1 : ones -- should be corecursive since it's building up from abase case?
20:28:05 <mniip> he is correct, it is corecursive
20:28:06 <Welkin> jared-w: for a fibonacci function, I prefer another format that is more clear
20:28:09 <MarcelineVQ> neato
20:28:20 <Welkin> > let fib a b = a : fib b (a + b) in fib 0 1
20:28:22 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
20:28:45 <mniip> recursive is defining a consumer for a complicated case in terms of consumers for simpler/base cases
20:29:01 <jared-w> ahh, that's much clearer
20:29:13 <mniip> corecursive the defining a producer (a datum) for a base case in terms of more complicated producers
20:29:15 <jared-w> I do like how neat zipWith is, though :p
20:29:48 <MarcelineVQ> mniip: what does more complicated producers mean?
20:29:53 <trigone> Welkin: you'd have to use tail to remove the 0 (right?), and then it's a bit clunky...
20:29:55 <Welkin> mniip: too much jargon
20:30:01 <mniip> we define 'ones' in terms of '1:ones'
20:30:06 <iqubic> :t zipWith
20:30:07 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
20:30:09 <Welkin> trigone: no, the 0 belongs
20:30:10 <MarcelineVQ> mniip: thank you
20:30:20 <iqubic> zip = zipWith (,)
20:30:25 <jared-w> > let fib a b = a : fib b (a + b) in fib 1 1 -- shouldn't that also work?
20:30:27 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
20:30:31 <trigone> Welkin: ok, if you say so, i don't remember the def of fibonacci
20:30:48 <iqubic> :t zipWith (,)
20:30:49 <lambdabot> [a] -> [b] -> [(a, b)]
20:30:52 <iqubic> :t zip
20:30:53 <lambdabot> [a] -> [b] -> [(a, b)]
20:30:57 <trigone> jared-w: yeah, clearly
20:31:02 <iqubic> Yep. That's how that works.
20:31:04 <jared-w> Fibonacci is merely defined in terms of the relationship of numbers to each other in the sequence. You can start with whatever "seed" of fibonacci you want
20:31:19 <Welkin> recursive functions work down to a base casse, whereas corecursive functions work up from a base case?
20:31:24 <mniip> jared-w, there's a canonical choice thoghg
20:31:32 <Welkin> that seems like a sensible explanation
20:31:51 <iqubic> jared-w: the lucas numbers start with 2,1,3,4,7,11...
20:31:52 <jared-w> Which is 1 and 1 iirc, although I've seen 0 and 1 as well
20:31:53 <mniip> Welkin, somewhat
20:32:02 <mniip> corecursive stuff doesn't have to be a function
20:32:23 <Axman6> @oeis  2,1,3,4,7,11
20:32:31 <lambdabot>  https://oeis.org/A000032 Lucas numbers (beginning at 2): L(n) = L(n-1) + L(n...
20:32:31 <lambdabot>  [2,1,3,4,7,11,18,29,47,76,123,199,322,521,843,1364,2207,3571,5778,9349,15127...
20:32:32 <Welkin> I've always thought of it all as being recursive
20:33:00 <jared-w> It's "recursive" if your only concept of recursion is "self refferential function"
20:33:42 <mniip> actually I just looked it up on wikipedia and familiarized myself with it in 30 seconds
20:33:56 <jared-w> But such a definition muddies the waters a bit too much for me. For example, that definition makes it seem impossible to have "unbounded computation" without allowing any recursion whatsoever
20:34:38 <Welkin> in a lazy language there are no unbounded computations
20:34:44 <Welkin> unless you explictly force evaluation
20:35:03 <mniip> is that a joke on "in a lazy language there is no computation"?
20:35:10 <mniip> because on a serious level that's not true
20:35:13 <trigone> Welkin: well it's kind of the point, you do end up doing that at some point don't you
20:35:19 <trigone> (forcing evaluation)
20:35:29 <jared-w> "Sure", but how do you allow an open ended loop that behaves well in a mathematical sense?
20:35:46 <mniip> Welkin, regardless of the normalization strategy, 'fix id' reduction doesn't terminate
20:36:29 <jared-w> Or, to restate in more concrete terms, how can you allow a function like `sum = foldr (+)` to be a well defined function without screwing up your ability to handle infinity?
20:37:11 <mniip> sum :: (N -> R) -> R   is not a well-defined function in mathematics itself
20:37:56 <jared-w> right, 'well defined' was probably a poor choice of words
20:38:16 <jared-w> "doesn't break spectacularly on infinity" is probably a better phrase :p
20:38:16 <trigone> jared-w: technically that depends on whether you see sum as being a process you can interrupt whenever you want or not... if you see intermediate results as existing or not at all
20:38:53 <jared-w> trigone: a co-recursive definition of sum would do that explicitly
20:39:07 <trigone> jared-w: you mean, handle intermediate results?
20:39:12 <jared-w> > sum [1..] -- will not give me intermediate results whatsoever
20:39:19 <lambdabot>  mueval: ExitFailure 1
20:40:24 <trigone> jared-w: yeah, because sum was not defined for that. it's sort of normal. it's like buying a cake at the cakemaker but expecting to be allowed to get the partially cooked dough so you can either eat it as such or cook it further at home.
20:40:25 <jared-w> > let sum' (0,n) = (0,0) : sum' (0,n+1) in sum' (0,1)
20:40:27 <lambdabot>  [(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,...
20:40:33 <trigone> lol
20:40:36 <mniip> I must mention that scanl 0 (+) is both a recursive consumer and a corecursive producer
20:40:46 <jared-w> whoops, messed that up
20:40:48 <trigone> there is a bug in your sum i believe
20:41:00 <trigone> :t scanl
20:41:02 <lambdabot> (b -> a -> b) -> b -> [a] -> [b]
20:41:18 <mniip> scanl is exactly that kinda stuff
20:41:25 <mniip> > scanl 0 (+)  [1,2,3,4,5]
20:41:27 <lambdabot>  error:
20:41:27 <lambdabot>      • Could not deduce (Num a0)
20:41:27 <lambdabot>        from the context: (Num ((a1 -> a1 -> a1) -> a -> a1 -> a1 -> a1),
20:41:27 <jared-w> oh yeah I just threw that up on the fly and hoped I did it right cause I forgot about scanl
20:41:30 <mniip> oops
20:41:35 <mniip> > scanl (+) 0  [1,2,3,4,5]
20:41:37 <lambdabot>  [0,1,3,6,10,15]
20:41:47 <jared-w> > scanl (+) 0 [1..]
20:41:49 <lambdabot>  [0,1,3,6,10,15,21,28,36,45,55,66,78,91,105,120,136,153,171,190,210,231,253,2...
20:41:50 <trigone> mniip: i see, interesting
20:41:56 <jared-w> that would be the corecursive form of `sum`
20:42:16 <mniip> that's a bad statement
20:42:24 <mniip> like I said above, it is also recursive
20:42:29 <Axman6> > let x = scanl (+) 1 (1:x) in x
20:42:31 <lambdabot>  [1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,1771...
20:42:33 <mniip> it dismantles the input list recursively
20:42:52 <jared-w> oh, right
20:42:54 <Axman6> > let x = scanl (+) 1 x in x
20:42:56 <lambdabot>  [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,2...
20:44:03 <jared-w> > fibs = 1 : scanl (+) 1 fibs -- I thought this was neat too
20:44:05 <lambdabot>  <hint>:1:6: error:
20:44:06 <lambdabot>      parse error on input ‘=’
20:44:06 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
20:44:08 <trigone> :t guard
20:44:09 <lambdabot> Alternative f => Bool -> f ()
20:44:19 <jared-w> > let fibs = 1 : scanl (+) 1 fibs -- I thought this was neat too
20:44:21 <lambdabot>  <no location info>: error:
20:44:21 <lambdabot>      not an expression: ‘let fibs = 1 : scanl (+) 1 fibs -- I thought this wa...
20:44:27 <Axman6> needs in too
20:44:46 <jared-w> *sigh* too used to my ghci just letting me define stuff without let and in
20:44:49 <pacak> > fix (1 : scanl (+) 1)
20:44:51 <lambdabot>  error:
20:44:51 <lambdabot>      • Couldn't match expected type ‘a -> a’
20:44:51 <lambdabot>                    with actual type ‘[Integer]’
20:45:02 <Axman6> GHCi doesn't allow that does it?
20:45:10 <jared-w> > let fibs = 1 : scanl (+) 1 fibs in fibs -- i swur t'gawd, lambdabot
20:45:12 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
20:45:12 <Axman6> well, it still needs let right?
20:45:26 <mniip> > let x = scanl (\m n f z -> m f (n f z)) id x in map (\f -> f (+1) 0) x
20:45:28 <lambdabot>  [1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,*...
20:45:30 <jared-w> `fibs = 1 : scanl (+) 1 fibs` works just fine in my ghci
20:45:35 <trigone> AX3L[m]: yeah, but it's a do-block let
20:45:45 <geekosaur> Axman6, as of ghc 8 you don't need 'let'
20:45:58 <Axman6> oh nice
20:46:19 <trigone> mniip: what was it supposed to be?
20:46:43 <mniip> Axman6's power series code but in terms of endofunction iterators
20:46:45 <pacak> > fix $ (1:) . scanl (+) 1
20:46:47 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
20:47:00 <mniip> aka the church encoding of nats
20:47:01 * Axman6 redirects response to trigone
20:47:24 <jared-w> > let fibgen (x,y) = x : fibgen (y, x+y) in fibgen (0,1) -- This should be a completely co-recursive definition I think
20:47:26 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
20:47:30 <mniip> > let x = scanl (\m n f z -> m f (n f z)) id (id:x) in map (\f -> f (+1) 0) x
20:47:32 <lambdabot>  [1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,1771...
20:47:36 <mniip> and this is fibs
20:47:50 <trigone> mniip: i'll have to trust you on the word. i understand most terms but beyond that it's a bit too fuzzy
20:47:56 <mniip> I doubt I can make it more slow than basically unary counting
20:48:11 <Axman6> I'm sure you could if you tried
20:48:22 <Axman6> turn it into a search problem
20:48:25 <mniip> yeah
20:48:36 <mniip> maybe if there's some algorithm that can produce 0s and 1s so that 1s sum to fibs
20:49:08 <geekosaur> quick, to the oeis-mobile!
20:49:13 <jared-w> make it a genetic algorithm for even more slowness
20:50:43 <EvanR> slowest algorithm contest?
20:51:25 <jared-w> while (1) wait; then do algorithm -- lawyer'd
20:51:41 <Axman6> that's not a productive algorithm
20:51:50 <EvanR> might not count according to <definition of algorithm>
20:51:58 <mniip> EvanR, I'm sure I can fit fibs nicely into the ackermann function
20:52:21 <trigone> Axman6: well if you're not in any hurry, productivity's not that important :P
20:52:24 <gamegoblin> https://en.wikipedia.org/wiki/Busy_beaver
20:53:11 <EvanR> the reason busy beavers dont win each year is no one can tell you what the relevant busy beaver number is
20:53:57 <EvanR> also its funny that "busy" is equating with "really really slow" here
20:54:26 <EvanR> keep that in mind next time the employees use "busy" as an excuse
20:54:40 <mniip> EvanR, actually...
20:54:56 <mniip> I have an LC implementation in lua which can produce fibs
20:55:02 <mniip> it does so extremely slowly
20:55:18 <EvanR> impressive
20:55:21 <mniip> I think it can do 8 in like 5 seconds
20:55:24 <jared-w> nice
20:55:25 <trigone> LC?
20:55:30 <mniip> lambda calculus
20:55:50 <mniip> crap! it's on another hdd
20:56:01 <EvanR> its on another cloud
20:56:16 <jared-w> Create a LC implementation that has a 10 second pause in between every substitution step?
20:56:32 <trigone> jared-w: i think that'd count as cheating
20:56:39 <sproingie> write it in bash
20:56:41 <mniip> no! I found it
20:56:44 <jared-w> sweet!
20:57:02 <EvanR> you know we never use actual runtime as the basis for checking efficiency!
20:57:16 <EvanR> you identify some most relevant unit of work
20:57:22 <Pamelloes> Is there an mconcat for alternatives or do I have to implement it myself?
20:57:30 <glguy> :t asum
20:57:31 <lambdabot> (Alternative f, Foldable t) => t (f a) -> f a
20:57:32 <hrumph> is it possible to define a monad using kleisli composition and return?
20:57:39 <Pamelloes> Thanks!
20:57:55 <trigone> EvanR: how do you compare across languages, especially when you have to copy a paradigm inexistent in another language by default?
20:58:27 <jared-w> You use cannonical representation, rewrite that into a turing machine, and compare the length of the tape obviously /s
20:59:09 <EvanR> dont compare across languages
20:59:40 <jared-w> But, really, if you're comparing across languages you either care about theoretical complexity/time in which case you're going to use some form of big-O notation and stop there. Or you care about real-world complexity/time in which case you benchmark it and then stop there. Either way, most comparisons are pretty useless :p
21:01:06 <sproingie> hrumph: sure, that's the categorical definition
21:01:19 <trigone> EvanR: then that does not work well with lua vs something else, does it? anyway at some point, unless you develop tools to compare, you'll probably want a good runtime above all. theoretical speed is of no use if you actually need your program to be faster
21:01:39 <EvanR> huh... slowest language speed? not what i was talking about
21:02:06 <EvanR> languages dont even have speed
21:02:45 <sproingie> languages with one standard runtime are said to have a speed, that of the runtime.  in other news, welcome to colloquial english
21:03:00 <EvanR> they dont even have a speed
21:03:05 <mniip> hmm, remembering how to run it... is a challenge
21:03:28 <EvanR> important when engineering boss asks you for the speed, and wants a number
21:03:39 <EvanR> you provide a number, and a fixed question
21:03:42 <sproingie> 42
21:03:53 <jared-w> EvanR was knocking me for my intentional abuse of irrelevant factors to "slow down" the algorithm (adding sleep(10) everywhere)
21:04:15 <trigone> jared-w: oh right got it
21:04:28 <mniip> oh but of course
21:04:33 <mniip> I don't have Show Pair
21:05:08 <jared-w> No language has a speed and thus no algorithm is magically "faster" or "slower"; you need to define what you mean by "faster/slower" and how you're gonna measure that and so on
21:05:39 <mniip> haha
21:05:41 <Welkin> languages do have a speed
21:05:48 <sproingie> on this planet, people use shorthands to describe "a typical idiomatic solution on the runtime of language X" by saying "language X"
21:05:49 <Welkin> it's based on how the compiler writes the machine code
21:06:08 <sproingie> it may be sloppy and imprecise but that's life
21:06:17 <trigone> jared-w: pragmatically though, you need to tell the speed of an algorithm based on the language and the implementation of said language (and algorithm)
21:07:11 <sproingie> i'll confidently state that bash is slower than C
21:07:39 <trigone> in fact, are algorithms really independent from the paradigm of the pseudo-code used to define them? i don't know much of algorithms, but many of them for example are written in a very imperative way
21:08:02 <trigone> but maybe it's just one way to see a more abstract concept of algorithmics or whatever
21:08:10 <trigone> s/see/represent/
21:08:44 <mniip> http://tcpst.net/eoz6.gif
21:09:05 <jared-w> trigone: sure. You can define quicksort serially or in a parallel fashion. Same function, much differnt pseudo-code, and different time and computational complexities associated with each
21:09:33 <mniip> EvanR, ^
21:09:50 <jared-w> The algorithm is perfectly independent from the pseudo-code but the complexity (or some other measurement) is gotten "from" the pseudo-code as it relies on the implementation
21:10:03 <sproingie> depends on the pseudocode.  my own pseudocode tends to use map rather than loops
21:10:10 <jared-w> mniip: nice
21:11:10 * hackagebot shakers 0.0.27 – Shake helpers. – https://hackage.haskell.org/package/shakers
21:12:42 <mniip> you can familiarize yourself with the implementation as well as what the modest stdlib looks like https://bpaste.net/show/638165d60368
21:13:39 <mniip> it's a curious language...
21:13:57 <mniip> dynamically typed but with type classes that try to mimic haskell's
21:15:25 <jared-w> Any reason why you did it in Lua?
21:16:46 <mniip> a few
21:16:57 <mniip> it had to be not-haskell and not-c
21:17:25 <trigone> mniip: why?
21:17:38 <mniip> LC interpreters get boring quick
21:17:46 <mniip> LC interpreters in haskell get boring quick
21:17:54 <mniip> LC interpreters in C get confusing quick
21:18:04 <trigone> lol ok got it
21:18:10 <mniip> also I had an idea
21:18:18 <mniip> the dynamically typed typeclass stuff
21:18:25 <mniip> it was a damn nice idea
21:18:34 <trigone> dynamically typed, that entails what in the end? i kinda forgot pre-haskell world
21:18:38 <mniip> it has little formalism beside it
21:19:13 <jared-w> dynamically typed can be a cheap way to mean "well typed but the compiler does everything for you"
21:19:29 <mniip> well, imagine a dynamically-typed language
21:19:43 <mniip> typeclasses can be translated into polymorphic functions
21:19:53 <mniip> but! there's no translation for a function like "return"
21:20:21 <mniip> my system gives "return" a special deferred typeclass thingy type
21:20:38 <mniip> when it's evaluated in a certain context it might assume a type
21:20:44 <trigone> jared-w: i think that's more "inferred types" or something
21:21:00 <jared-w> trigone: what's the difference? :p
21:21:30 <jared-w> Sure, there's a difference, but you can handwave in one direction or the other if you want to. It's your language after all
21:21:42 <trigone> jared-w: well a priori dynamically typed is what haskell is not supposed to be. esp, the types are not supposed to be known at compile time, right?
21:22:13 <trigone> inferred just means you don't have to write the types. dynamic means the types are assessed at runtime, i believe
21:22:28 <trigone> mniip: i admit i did not understand you example
21:23:28 * hackagebot preamble 0.0.46 – Yet another prelude. – https://hackage.haskell.org/package/preamble
21:23:37 <Pamelloes> I'm trying to create an expression of the form (Monad m, Traversable t) => (a -> m b) -> m (t a) -> m (t b). Based off of the type signatures of join and fmap . traverse, it looks like join . fmap . traverse should work, but instead I get a complicated type error I don't quite understand. What am I doing wrong?
21:26:02 <trigone> :t traverse
21:26:04 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
21:27:27 <trigone> i think maybe:  yourexp f mta = mta >>= traverse f
21:27:42 <trigone> at least that'd be my guess by following the types... but then i'm not sure
21:28:09 <mniip> trigone, well, suppose, 'eq' is defined as
21:28:13 <mniip> \x -> \y -> \(Eq eq)[x; y] -> eq x y
21:28:53 <Lokathor> requesting the inline-rust TemplateHaskell module be made and put on hackage :3
21:29:17 <mniip> when a term \(Cls var)[e1; e2; e3] ->... is reduced, e1, e2, e3 are checked for constructors, and if any is found, the respective constructor is used to lookup an instance dictionary for that constructor and that dictionary is bound to var
21:29:21 <trigone> Pamelloes: actually, maybe you can reconnect my possible solution with your attempt with the definition of (>>=) in terms of join and fmap which i forgot
21:29:44 <mniip> therefore, this term can be resolved as soon as either x or y is evaluated to a con
21:29:57 <mniip> and that con chooses the typeclass instance
21:30:09 <Pamelloes> trigone: Hmm, I was playing around with that earlier, I'll see if that works
21:31:14 * hackagebot sensu-run 0.2.0 – A tool to send command execution results to Sensu – https://hackage.haskell.org/package/sensu-run
21:31:44 <mniip> similarly, we have
21:31:47 <mniip> \k -> \f -> \(Monad bind)@[f; k] -> bind k f
21:32:25 <mniip> that '@' tells that if f and k fail, it is possible that the use site context can determine the instance dictionary
21:32:28 <jared-w> Lokathor: You want inline Rust in haskell?
21:33:07 <Lokathor> jared-w, probably better than inlineing C in haskell
21:33:20 <trigone> mniip: i understand better the idea of dynamicity. it truly means the overloaded method is not resolved until runtime. in fact what i wondered was, what's the advantage of having a dynamic typing? esp are there cases for which you can't do away with statically-resolved polymorphism (if that is the correct way to put it)?
21:33:45 <mniip> I'm not necessarily saying there are advantages of dynamic types
21:33:55 <mniip> I just had a particular idea about dynamic types and typeclasses
21:34:10 <trigone> mniip: no, i did not say you did, but that was my implicit question when trying to remember what dynamic typing could mean
21:34:27 <jared-w> Lokathor: It's "better" only if you can optimize and take advantage of Rust's and Haskell's expressive type systems. Unfortunately, there are a /lot/ of differences between the type systems and it makes such interop really difficult to be efficiently done. I'd imagine both will likely talk to each-other through C for a while yet
21:34:39 <mniip> because the theme of problems with 'pure' and 'return' in unidirectionally infrerred programming languages
21:34:42 <trigone> mniip: i didn't really get your @ thingy, what do you mean by context?
21:34:52 <mniip> and dynamic typing is seemingly unidirectionally inferred
21:35:00 <mniip> however this one simple trick!
21:35:03 <Lokathor> jared-w, i mean you know that rust can compile to C compatible 1:1 stuff already, right?
21:35:34 <jared-w> Right, but that's because rust's type system is expressive enough that you can strip out all the useful stuff and compile down to a dumb language like C
21:35:40 <Pamelloes> trigone: Got it :) (\f -> (=<<) (traverse f))
21:35:47 <mniip> trigone, ok, imagine something like 'pure'
21:36:00 <jared-w> Going from a very expressive language like Haskell requires doing a similar stripping-down to C, but then you can't build back up to the expressiveness that Rust allows
21:36:08 <mniip> in a dynamically typed language 'pure' cannot return anything without being explicitly told what type it's called at
21:36:19 <Lokathor> jared-w, you're not using rust to the limit when you treat it like "just C", but you're still getting a better deal than C itself
21:36:46 <mniip> I have 3 instances of Applicative in my toy language, which one should 'pure Unit' use?
21:36:49 <trigone> Pamelloes: yeah that's equivalent to my solution too :) in vaguely point-free notation
21:37:34 <jared-w> You'd need some translation layer between Rust and Haskell that translates between lazy, strict, different representations of types, traits, impls, typeclasses, yadda yadda. If you're just using it through the C layer the only thing you get is better memory safety. Which, while cool, is not nearly as strong a benefit inside a Haskell codebase for most people
21:37:35 <trigone> mniip: Unit == (), that is, a sort of dummy constructor?
21:37:55 <mniip> data Unit = Unit;
21:38:05 <mniip> sorry my 50-line parser cannot afford fancy syntax
21:38:11 <Lokathor> and the C-style speed boost, which is probably also what you're after if you're calling inline-c
21:38:27 <mniip> 50 lines of lua not haskell mind
21:38:35 <trigone> mniip: lol no i was just wondering
21:38:37 <Pamelloes> trigone: Oh, yep! I don't know why I didn't notice your solution worked in the first place
21:38:46 <Lokathor> (which might not really be a speed boost because ghc can't optimize FFI calls yada yada you always need a benchmark yada yada but you get my point)
21:39:42 <mniip> trigone, anyway, in haskell you have bidirectional type inference. 'pure ()' returns a somewhat concrete term of a polymorphic type that can later be instantiated to a specific applicative
21:40:04 <mniip> in my dynamic types I make a fairly similar thing happen except with dynamic types
21:40:26 <mniip> pure returns a term that just waits to be used in a specifically typed context
21:40:28 <jared-w> Rust is often slower than C when writing highly idiomatic and safe code because of extra allocations and extra steps you take that C programmers skip as "unnecessary" (like properly handling unicode). That speed slowdown doesn't matter when you can take advantage of it through the entire pipeline all the way down to bare metal, but the penalty bubbles up through the FFI and introduces a lot more slowdown
21:40:31 <jared-w> than you'd think because of how heavily both Rust and Haskell depend on all-knowing-optimizing
21:40:40 <mniip> it cannot reduce before that
21:40:58 <Lokathor> perhaps so
21:41:11 <jared-w> Not to say that I don't want Rust and Haskell interop, I really do, I just think it's going to require a *lot* of work to make it work well enough to be "clearly" better than inline-C
21:41:26 <Lokathor> oh well
21:41:32 <Lokathor> i'll just program roguelikes then
21:41:57 <trigone> Pamelloes: well it's like math (or when you try finding your car keys), sometimes you just need a fresh mind on the problem :)
21:42:15 <jared-w> or alcohol
21:42:36 <trigone> mniip: i see, that's pretty cool
21:43:13 <mniip> oh oh oh  my language has IO!
21:43:14 <Pamelloes> jared-w: True that
21:44:08 <mniip> you can write...
21:44:09 <mniip> bind getLine putStrLn
21:44:17 <mniip> and it will do monad magic
21:44:18 <trigone> mniip: did you not make the "lazy type-evaluating" the default one, and then consider that in some cases, the "type evaluation" happens right away? mind you that depends if your language is lazy or not at all
21:44:49 <mniip> it is lazy in the sense of call by name evaluation strategy
21:44:52 <jared-w> I read an interesting article on how Monadic IO in haskell is really just a stopgap and that we need something better, a true 'fix' to the problem of impurity without resorting to "using impurity in a contained box"
21:45:33 <mniip> jared-w, I hear some ideas of free monads on FFI
21:45:55 <mniip> that would make IO an algebraic constructor and unsafePerformIO a....thing
21:46:16 <jared-w> oooh interesting
21:46:20 <trigone> mniip: not call by need? there's a difference right? i recently heard of it. call by name means inputs are short-circuited by default, right?
21:46:20 <mniip> I'm not sure how that applies in practice though with a lot of code depending on current IO structure
21:46:46 <jared-w> between that and algebraic effects, I think there's some really interesting stuff out there developing
21:48:23 <mniip> trigone, call by name I believe
21:48:42 <jared-w> It makes me think that there's some next-level paradigm of understanding composition of things where we can handle effects, IO, purity, etc., all in a more elegant and powerful way. Perhaps there's not and there's merely different ways of thinking about the same general thing, but I'm still interested in seeing what happens :)
21:49:22 <mniip> jared-w, it might be interesting but practice is super hard to accomodate form
21:49:50 <mniip> I mean even with 99.9% of haskell code using just the monad interface of IO, that's that 0.1% which is used literally everywhere
21:50:06 <mniip> e.g bytestring, text, vectors
21:50:07 <trigone> used everywhere where?
21:50:16 <trigone> oh right
21:50:39 <mniip> take a look at bytestring code sometime
21:51:03 <mniip> see how *that* can be rewritten in any nice "algebraic effects" or "free ffi monads"
21:51:46 <skiddieproof> is there a ghci command to print the constructors of a datatype?
21:51:50 <trigone> mniip: i'm thinking, we should make two concepts of IO, one being the deep exterior, and one being any data structure strictly internal, provided immutability is assured. but then maybe there's no way to separate them?
21:52:04 <mniip> skiddieproof, :info can do that
21:52:30 <skiddieproof> mniip: thanks
21:52:32 <mniip> trigone, are you suggesting we remove mutability backdoors too?
21:53:17 <trigone> mniip: what's that?
21:53:56 <trigone> mniip: you mean stuff to directly manipulate pointers and so on?
21:54:13 <mniip> :t GHC.Prim.writeArray# -- this for example
21:54:14 <lambdabot> GHC.Prim.MutableArray# d a -> GHC.Prim.Int# -> a -> GHC.Prim.State# d -> GHC.Prim.State# d
21:54:31 <mniip> no, directly manipulating pointers is bad
21:54:35 <trigone> mniip: sorry, i'm not knowledgeable in that yet
21:54:40 <mniip> let the GHC GC do that
21:55:33 <trigone> mniip: yeah i do know that
21:56:34 * hackagebot miso 0.2.0.0, sbp 2.2.8, wolf 0.3.23
21:56:34 * hackagebot  → https://hackage.haskell.org/packages/recent
21:57:01 <jared-w> Basically, in the current implementation of Haskell, it is an ugly truth that Haskell is implemented on mutable, imperative "von-neumann" hardware
21:57:41 <trigone> jared-w: well it's ugly if you were expecting better
21:57:49 <jared-w> Because of this, somewhere along the line, all the pretty functional code has to be converted into equivalent dirty mutating code in order to be even remotely efficient in any way, shape, or form
21:58:28 <trigone> jared-w: what's the problem with that? i like haskell's IO abstraction as values, makes things nicely abstract
21:58:33 <jared-w> trigone: it's ugly because it doesn't *have* to be that way and *could* be better. Von-neumann is already a convenient lie we tell ourselves and has been for over a decade
21:59:47 <mniip> trigone, observe this snippet, https://bpaste.net/show/39daeff6f3e2
21:59:49 <jared-w> Von-neumann is a lie, linear execution order is a lie, no program has access to all of the hardware for unlimited time like they pretend to, etc. The processor actively abuses branch prediction and about a billion other things to try and speed up programs that pretend they're implemented on hardware from the 60s
22:00:10 <mniip> anything but idiomatic haskell code
22:00:31 <mniip> but this demonstrates that there are many interesting backdoors worth considering besides IO
22:00:35 <jared-w> Assembly code is also increasingly a lie thanks to microcode on processors
22:00:39 <mniip> and all of them exist for a reason as they are used
22:01:00 <pacak> Also caches and memory access cost.
22:01:31 <jared-w> So if the processors lie to the code and the code lies to the computer and everyone's lying about everything... maybe there's a way that involves being honest about things and seeking a more functional way that's grounded in math rather than guessing, folklore, tradition, and experimental validation
22:02:19 <iqubic> What is codata?
22:02:27 <trigone> jared-w: you literally sound like a new age priest, it's pretty amusing... i don't judge your message mind you, since i don't know a thing about von neumann and so on
22:02:39 <iqubic> I kinda get corecursion from earlier, but what is codata?
22:02:59 <mniip> jared-w, join the cult of the bound variable now1
22:03:14 <jared-w> hah, trigone, it does sound a little nuts to be honest
22:03:14 <trigone> mniip: it would demonstrates it if i knew of hash notation and so on, because so far it's mostly gibberish (sorry, gibberish#)
22:03:41 <mniip> trigone, if you bind (x, f) = mkPair, then f is a function that indicates whether x has been evaluated
22:03:50 <jared-w> mniip: where's the newsletter?
22:04:05 <trigone> jared-w: my first thought reading you is this very conformist "but then i prayed to my computer and it always did what i wanted, so how could it have lied to me all this time?"
22:04:46 <trigone> mniip: a function taking what as argument?
22:05:02 <trigone> mniip: or does it just have a variable result depending on when evaluated?
22:05:08 <mniip> yes
22:05:30 <trigone> and x is just a label here right?
22:05:55 <iqubic> :t mkPait
22:05:57 <lambdabot> error: Variable not in scope: mkPait
22:05:58 <iqubic> :t mkPair
22:05:59 <lambdabot> error: Variable not in scope: mkPair
22:06:03 <jared-w> iqubic: https://www.tac-tics.net/blog/data-vs-codata I'm reading this now since you reminded me I didn't really know what codata was at first either
22:06:12 <jle`> jared-w: this argument is like saying that all of mathematics, abstract algebra, calculus, real analyses, etc. is a lie, because it's often done by biological brains
22:06:45 <trigone> mniip: actually, i don't really get it, do you bind it after you defined x? or maybe it does not matter and it may even depend on the specific namespace/shadowing?
22:07:00 <mniip> jared-w, take a look at the CBV website http://mniip.com:8080/
22:07:03 <trigone> (at the time of calling f)
22:07:13 <iqubic> OCaml lacks infinite lists. What a rip off.
22:07:15 <jared-w> I wouldn't say lie so much as perhaps "done inefficiently"
22:07:42 <jared-w> that under construction gif, oh gawd, what a flash back
22:07:45 <jle`> there's no fundamental flaw in mathematics that occurs due to humans who try to process it
22:08:17 <jared-w> iqubic: https://www.reddit.com/r/programming/comments/61tpol/data_vs_codata/ read the pendantic first comment :p
22:08:17 <mniip> jared-w, guess what it's being served directly from a Universal Machine emulator
22:09:18 * hackagebot loup 0.0.12 – Amazon Simple Workflow Service Wrapper for Work Pools. – https://hackage.haskell.org/package/loup
22:09:36 <iqubic> does haskell have a codata keyword?
22:09:44 <Axman6> no
22:09:44 <jared-w> Nope
22:09:49 <MarcelineVQ> idris does :>
22:09:56 <jared-w> so does Agda
22:10:14 <iqubic> Right. I can't read properly. The author said that was fictious.
22:10:34 <jared-w> wow, the cultWeb site has been visited 5 times since '99?
22:10:49 <Axman6> integer overflow?
22:11:08 <cocreature> least and greatest fixedpoints coincide in Haskell so there is no difference between data and codata
22:11:32 <jared-w> no the website is basically an empty joke
22:11:43 <trigone> if the number had reached 10, one could have pretended it was written in a very large base
22:11:58 <mniip> jared-w, a very elaborate joke though
22:12:10 <mniip> I don't suppose you know what Universal Machine is
22:14:32 <trigone> mniip: from wikipedia, a universal machine looks like a universal interpreter
22:14:37 <mniip> nah
22:14:44 <mniip> I'm referring to ICFP 2006
22:14:50 <trigone> mniip: k then i'll leave it to you
22:15:46 <mniip> the ICFP 2006 programming contest had contestants implement an emulator for a certain simple 32-bit architecture
22:16:06 <mniip> so that they could run the "codex" - an unknown program
22:16:26 <mniip> the fun part is that the codex appears to be actually a unix-like OS
22:16:37 <mniip> with users and programs and nontrivial stuff
22:16:41 <jared-w> yeah I'm looking up the website now :)
22:16:45 <jared-w> http://boundvariable.org/index.shtml pretty neat stuff
22:17:08 <mniip> one of the not very soon discovered easter eggs was that...
22:17:18 <mniip> if you type 'telnet localhost 80' in the shel
22:17:33 <jared-w> you get star wars?
22:17:40 <mniip> 80
22:17:44 <mniip> that's the HTTP port
22:17:47 <mniip> you get this website
22:18:07 <mniip> hence my comment that this website is served live from an actual UM emulator
22:18:22 <jared-w> hah gotcha. So many layers...
22:18:37 <mniip> I suspect I've written the fastest UM emulator
22:19:01 <trigone> written in what?
22:19:14 <mniip> good question
22:19:22 <mniip> I suspect the answer is C and machine code
22:19:28 <mniip> and bits of assembly
22:19:43 <mniip> https://github.com/mniip/um32/blob/master/umjitv2.c
22:19:49 <mniip> hopefully this answers your question
22:20:32 <jared-w> Whenever I think I'm nerdy, I come here to remind myself how much of a basic dweeb I am
22:20:44 <trigone> mniip: oh joy! :P
22:21:49 <trigone> mniip: do you think one could write that in haskell without losing too much speed? and without it being as much or more unreadable?
22:21:57 <mniip> unlikely
22:22:07 <trigone> mniip: that's a shame
22:22:10 <mniip> I'm working very close to the bare metal there
22:22:38 <mniip> can't afford neither the ffi barrier nor manual entry/exit from the highly organized haskell rts
22:22:39 <trigone> mniip: yeah yeah but sometimes haskell can do that too... though i'm not sure it can do assembly-level stuff
22:22:40 <jared-w> yeah there's inline assembly, switch statements, yadda yadda. No way you can hit that with haskell
22:22:57 <mniip> jared-w, nononono, you see that EMIT?
22:23:07 <jared-w> The real issue is the FFI barrier and the entry/exit from haskell's RTS
22:23:09 <mniip> that's me emitting machine code bytes into executable memory
22:23:25 <jared-w> ಠ_ಠ
22:23:47 <iqubic> Are there are any good tutorials on how and why you'd use FFI in haskeel?
22:23:56 <trigone> mniip: that's a just-in-time compiler-interpreter or something?
22:23:57 <jared-w> I thought that was just some function pointer arithmetic lol
22:24:08 <iqubic> jared-w: Case statements are Switch statements.
22:24:28 <mniip> trigone, just in time binary translator I guess
22:24:53 <jared-w> iqubic: well one string library I'm thinking of recently was calling out to C to perform many of their string manipulations such as computing the hamming distance
22:25:05 <skiddieproof> is there a way to make an 'empty' instance of Read? Something like `instance Read Type where readsPrec x s = empty`
22:25:08 <iqubic> Ah.
22:25:15 <trigone> mniip: yeah obviously compiler is a big word since there's no parsing etc
22:25:27 <iqubic> I'm not sure what the hamming distance is.
22:25:29 <jared-w> they only just recently switched to pure Haskell because the FFI barrier provided enough of a slow-down that they could compete with FFI-C by using optimized haskell
22:25:41 <jared-w> hamming distance is number of 1s in the binary representation of some string
22:25:50 <cocreature> iqubic: there are two main reasons 1. you can’t get your Haskell code as fast as you need it and 2. you want to use some existing library that is not written in Haskell from your Haskell code
22:25:56 <Axman6> :t readsPrec
22:25:58 <lambdabot> Read a => Int -> ReadS a
22:26:13 <Axman6> @hoogle ReadS
22:26:14 <lambdabot> Prelude type ReadS a = String -> [(a, String)]
22:26:14 <mniip> skiddieproof, do you want to always fail?
22:26:14 <lambdabot> Text.ParserCombinators.ReadP type ReadS a = String -> [(a, String)]
22:26:14 <lambdabot> Text.Read type ReadS a = String -> [(a, String)]
22:26:36 <skiddieproof> i just want my code to compile, it dosen't use read ever
22:26:46 <Axman6> readsPrec _ = \s -> []
22:26:46 <mniip> why do you define Read then?
22:26:53 <jared-w> cocreature: forgot to ask. Do you have any good resources to learn about least/greatest fixpoint from? Wikipedia wasn't super enlightening for me
22:27:14 <mniip> skiddieproof, curiously, 'readsPrec x s = empty' appears to be well-typed and does exactly as you wish
22:27:28 <mniip> because of the Alternative instance of [], empty = []
22:27:30 <skiddieproof> :t empty
22:27:32 <lambdabot> Alternative f => f a
22:27:48 <skiddieproof> ha
22:27:49 <mniip> :t empty ++ "foo"
22:27:51 <lambdabot> [Char]
22:27:51 <cocreature> jared-w: I’m currently reading pfpl myself which explains this stuff. it’s great but not exactly a light read (at least for me)
22:27:57 <mniip> > empty ++ "foo"
22:27:59 <lambdabot>  "foo"
22:28:15 <iqubic> :t wrap
22:28:17 <lambdabot> error: Variable not in scope: wrap
22:28:35 <iqubic> That must be an xmonad thing.
22:28:37 <jared-w> PFPL lol alright. I have that one downloaded and wasn't sure if I should read it since Bob Harper wrote it :)
22:28:56 <iqubic> It's of type: wrap :: String -> String -> String
22:29:05 <jared-w> It sounds like a good book, it's a shame he's such a controversial windbag on the internet
22:29:09 <cocreature> jared-w: I like harper :)
22:29:29 <cocreature> I don’t always agree with what he says but usually he has very good arguments for his points
22:29:37 <iqubic> wrap start end x = start ++ x ++ end 
22:29:43 <jared-w> I like him too, for what it's worth -- for pretty much the same reasons as you :p
22:30:03 <iqubic> What is PFPL?
22:30:07 <jared-w> Although last time I mentioned him on here someone did rightfully point out how he was being a tad dishonest in some of his views which, understandably, could alienate the haskell community a bit
22:30:16 <jared-w> PFPL = Practical Foundations for Programming Languages
22:30:20 <cocreature> jared-w: and that book is not as polemic as his blogposts :)
22:30:34 <jared-w> I'd hope not :p
22:31:30 <jared-w> mniip: I like your website. Very shiny
22:32:24 <jared-w> You should probably change the haskell link to link to https://en.wikipedia.org/wiki/Haskell_(programming_language) rather than just Haskell though; otherwise it gives you a ton of potential pages
22:32:27 <iqubic> What's a cofunction, is that even a thing?
22:32:44 <mniip> jared-w, that might have changed since I've written that
22:32:53 <jared-w> Pretty sure there's a dual for most, if not all, things out there
22:33:20 <jared-w> mniip: yeah it seems like it. I remember Haskell used to redirect to the language rather than a generic list of all pages with "haskell" in the title
22:33:32 <Axman6> A cofunction is like a function but it accepts values as its result and produces them as its inputs
22:33:40 * Axman6 not really I made that up
22:33:53 <iqubic> Axman6: I was hoping that was real.
22:33:56 <jared-w> damn you had me solidly on board with that for a few seconds
22:34:30 <mniip> Axman6, clearly cofunctions are pairs
22:34:39 <mniip> pairs are left adjoint to the function functor
22:35:08 <mniip> I'm not entirely false either
22:35:40 <mniip> a function is a degenerate case of a pi-type, and a pair is a degenerate case of a sigma-type
22:36:36 <jared-w> Degenerate case? So pi-types are the more general representation of what functions are merely a special case of?
22:37:01 <mniip> well- not really
22:37:13 <mniip> pi types are usually defined in terms of a type family
22:37:18 <mniip> which can be a function
22:37:35 <mniip> if that family is a pi-type you get an infinite chain of pi-types yielding no useful result
22:37:39 <iqubic> I love learning new things
22:38:03 <Axman6> iqubic: have you learned Google yet? it's pretty neat =)
22:38:15 <jared-w> https://en.wikipedia.org/wiki/Degeneracy_(mathematics) ooh neat, didn't know this was a thing
22:38:28 <iqubic> Axman6: I think I have learned that.
22:38:41 <Axman6> I think you're getting better at it too, thanks ;)
22:40:21 <iqubic> You think I'm getting better Thanks for noticing
22:41:08 <jared-w> It's getting so passive aggressive in here I'm starting to crave latkes
22:42:23 <iqubic> I like Latkes. I like all jewish food.
22:43:05 <nshepperd_> https://en.m.wikipedia.org/wiki/Cofunction trigonometry D:
22:43:52 <jared-w> that's the wrong co
22:44:19 <jared-w> we're interested in the dual of a function from a category theory perspective
22:45:11 <jared-w> They're using co as a concept of relating functions by complementary angles
22:46:08 <jared-w> (sine and *co*sine are the same function, just translated by pi/2)
22:46:24 <nshepperd_> Just reverse the little arrows telling you which way to go around the unit circle
22:46:37 <nshepperd_> In the, uh, unit circle category
22:46:56 * Axman6 summons edwardk for advice on what a cofunction might be, and prepares to learn way more than he expected
22:48:00 <mniip> here's another attempt
22:48:18 <mniip> a function is such a relation R such that forall x, exists unique y, xRy
22:48:31 <mniip> a cofunction is such a relation R such that exists unique x, forall y, xRy
22:48:38 <johnw> Axman6: perhaps https://ncatlab.org/nlab/show/comorphism
22:49:02 <johnw> "A mapping associated with a morphism that, when applied to every member of the morphism, results in the same value as the morphism applied to the image of every member."
22:49:36 <Axman6> That's less fun than my made up definition :P
22:49:44 <johnw> isn't it always though?
22:49:46 <Axman6> (but also makes sense)
22:50:07 <Axman6> In case you missed it: A cofunction is like a function but it accepts values as its result and produces them as its inputs
22:51:26 <Axman6> ie, covariant in its input and contravariant in its output
22:51:29 <Axman6> (yes it makes no sense)
22:51:55 <nshepperd_> It's a function made of antimatter
22:55:20 <mniip> a cofunction is a point in the preimage of a cohomology coprofunctor V -> C^op x C with C a V-coenriched cocategory
22:56:11 * jared-w is not sure if this is a purposely obtusified joke or if he is just dumb
22:56:50 <mniip> intended as a joke but I wouldn't be surprised if some of these constructions exist
22:57:15 <geekosaur> ("co-gesundheit")
22:57:37 <mniip> coachoo
22:58:08 <jared-w> Shoud I reply with "co-bless-you" or is that equivalent to "go jump in a lake"?
22:58:26 <mniip> geekosaur already co-replied with co-gesundheit
22:58:31 <mniip> co-already
22:58:44 <jared-w> go jump in a lake :p
22:59:36 <mniip> I just found the word impoverish in a thesaurus and I think we should call it impoverished category theory
22:59:38 <iqubic> What is going on here?
22:59:57 <mniip> iqubic, jokes
22:59:59 <jared-w> co-humor
23:00:20 <iqubic> co-my-god, really?
23:00:56 <iqubic> jared-w: so in other words, this as serious as can be?
23:01:41 <jared-w> iqubic: nah it's just humor with the arrows reversed. We tell the joke and then we laugh because we're the only ones that get it and the normal people deadpan us and look at us weird
23:01:52 <mniip> you're all coconuts
23:02:08 <grmp> hello all, I'm trying to enhance the documentation for Yi, if you have a little time, feedbacks and advices are welcome!
23:02:15 <grmp> here: https://github.com/yi-editor/yi
23:02:37 <Lokathor> http://lpaste.net/356884 once again i'm left with a totally weird loop, and it feels like a higher order function should be doing it for me, but oh well
23:04:06 <jared-w> hmm... what's the function doing?
23:04:14 <Lokathor> uh.. kinda a fold
23:04:48 <Lokathor> it goes through each View, which are kept in order by external invaraints, and testing lines within the View with that predicate, belowOrCollinearPoint
23:05:19 <Lokathor> i wrote it a year ago, and looking at it now i can instantly see that it should at least be dropping the head off the list each time instead of linear looking up the thing it wants
23:05:40 <Lokathor> better to get the new verion fully working before trying to thinker with it i think
23:05:58 <Lokathor> larger context (old version): https://github.com/Lokathor/ludolib/blob/master/bench/Util/PPFOVBoxed.hs
23:06:22 <jared-w> good lord, that visitCoord function
23:08:15 <Lokathor> ah, you noticed that did you
23:08:33 * Lokathor adjusts collar
23:09:09 <jared-w> calcViewIndex just looks wrong. "If no view is appropriate to the Location specified then the number returned is the length of the list" so... why? Doesn't that impose some needing to check if the viewIndex isn't the length in order to determine that the result of the function is useful?
23:09:24 <jared-w> Lokathor: lol it's all good. Trust me, I've wrote shittier stuff :p
23:10:25 <Lokathor> we're checking a location, and when we get there we see if any active view sees it, so we calculate a view index, and returning the length of the list is the "found nothing" case
23:10:30 <Lokathor> so... it should be Maybe Int, really
23:11:14 <Lokathor> line 306 covers this horribly unhaskellish way to handle data :P
23:12:38 <jared-w> yeah... Maybe Int
23:12:49 <jared-w> then you can just lift over the maybe and do really nice stuff with that :p
23:13:57 <Lokathor> aw man and i'm doing individual element updates in a list
23:13:58 <Lokathor> oh nooooo
23:14:05 <jared-w> To me it seems you should just have some calculating of the view and if it works, Just result. Otherwise nothing.
23:14:16 <jared-w> lol
23:14:46 <Lokathor> yes i think i can walk the list until it's empty and then Nothing when it is
23:14:59 <grmp> can the bottomRight argument in the go function be omitted? (as it never changed)
23:15:23 <Lokathor> yes it can be, good catch
23:16:16 <Lokathor> "a smart compiler will just skip passing that in the generated code anyway"
23:16:20 <jared-w> I also personally hate if than else so I always seek to eradicate the shit out of it whenver I see it in code or want to write it :p
23:17:04 <Lokathor> well there's another version that's with ST and as many manually unboxed Int# values as I could muster
23:17:07 <jared-w> Lokathor: "Code is written for the human. Don't make their job needlessly difficult just because the compiler is smarter than them" :p
23:18:11 <jared-w> Also, is there a reason you have no way to update views other than manually? Your visitCoord is like 4 functions all in one
23:18:50 <Lokathor> well
23:18:59 <Lokathor> "that's how the python example that i copied did it"
23:19:20 <Lokathor> always the most well thought out reason
23:19:48 <jared-w> lol fair enough. Python tends to skew towards super long functions since nobody takes it seriously as a real programming language (in my experience)
23:20:04 <Lokathor> but oh, those python defenders
23:20:14 <Lokathor> "i've worked on several large projects in python, it wasn't hard"
23:20:16 <Lokathor> ohh
23:20:17 <jared-w> plus function calls aren't "free" like they are in Haskell, so abstraction is really painful and modularity gets kinda discouraged
23:20:44 <Lokathor> well okay, so there's like 6 possible cases here
23:20:59 <Lokathor> is the real problem
23:21:03 <mnoonan_> it seems like Data.List’s findIndex would go a long way here
23:21:46 <Lokathor> a tile might be non-blocking
23:21:56 <Lokathor> or it could be blocking, in one of the following ways, http://www.xmission.com/~tyrecius/five-cases.png
23:24:01 <grmp> views argument may be skipped too, replaced by activeViews in the predicate
23:24:15 <mnoonan_> in fact, isn’t that just “findIndex (\view -> steepLine view `belowOrCollinearPoint` bottomRight)” followed by weird handling of the Nothing case?
23:25:20 <mnoonan_> fromMaybe (length views) $ findIndex (\view -> steepLine view `belowOrCollinearPoint` bottomRight) views
23:25:39 <jared-w> did we just replace a pargraph of code with a one liner?
23:26:00 <Lokathor> oh boy, the me of a year ago is embarassed
23:26:14 <Lokathor> I'll try that oneliner in a bit
23:26:15 <mnoonan_> maybe i got the condition flipped, but whatever :)
23:26:39 <MarcelineVQ> man, that report findIndices version, so beautiful. I always forget to use comprehensions :X
23:27:41 <jared-w> MarcelineVQ: what version are you talking about?
23:27:49 <MarcelineVQ> findIndices p xs = [ i | (x,i) <- zip xs [0..], p x]
23:28:01 <MarcelineVQ> https://hackage.haskell.org/package/base-4.9.1.0/docs/src/Data.OldList.html#findIndices
23:29:19 <jared-w> hah, compared to the inlined one with magic hashes
23:30:20 * hackagebot numhask-range 0.0.3 – Numbers that are range representations – https://hackage.haskell.org/package/numhask-range
23:30:20 <MarcelineVQ> unboxed Int is pretty swifty
23:31:02 <Lokathor> MarcelineVQ, you don't have a benchmark you can't POSSIBLY make such baseless claims without a benchmark at hand at all times
23:32:11 <jared-w> Considering their definition is commented with "efficient definition" and they only use the list comprehension if they absolutely have to... :p
23:32:57 <MarcelineVQ> jared-w: know what that build function is about?
23:32:57 <Lokathor> naw, just a person was throwing up a storm the other day when i said that ST was faster than not ST and I'd done the benchmarks in the past
23:33:12 <jared-w> ahh gotcha
23:33:14 <Lokathor> but since i didn't have them *in my hands* right then they said i was spreading misinfo
23:33:26 <Lokathor> i was like "wow chill"
23:33:40 <jared-w> MarcelineVQ: it involves consumer/producer optimizations with foldr
23:33:56 <MarcelineVQ> what does that mean?
23:34:00 <Lokathor> foldl and foldl' are done with foldr right? so do i get the same opts?
23:34:12 <quchen> No, no and no
23:34:17 <jared-w> in combination with magic hash in order to turn the entire thing into an optimized assembly loop with machine registers
23:34:33 <jared-w> quchen: was I totally off the mark?
23:34:42 <Lokathor> :(
23:34:47 <Axman6> foldl can be implemented with foldr (as can any function over lists), but it is not implemented using foldr
23:34:57 <Lokathor> awh
23:35:03 <quchen> jared-w: That was just about the foldl'foldrfoldl comment. foldl is not defined in terms of foldr.
23:35:12 <quchen> And you don’t get »the same opts«, whatever that means.
23:35:12 <jared-w> ahh gotcha
23:35:31 <Lokathor> and if i need to consume a list from the front i kinda need foldl or foldl'?
23:35:44 <quchen> foldr also consumes a list from the front.
23:35:58 <jared-w> > foldr (^) [1..5]
23:36:00 <lambdabot>  error:
23:36:00 <lambdabot>      • No instance for (Typeable t0)
23:36:00 <lambdabot>          arising from a use of ‘show_M571259934004303549530343’
23:36:09 <jared-w> > foldr (^2) [1..5] -- am dumb
23:36:11 <lambdabot>  error:
23:36:11 <lambdabot>      • No instance for (Typeable t0)
23:36:11 <lambdabot>          arising from a use of ‘show_M771106424897501815130354’
23:36:17 <MarcelineVQ> > foldr1 (^) [1..5]
23:36:23 <Lokathor> so if you flip the operation's argument order you can always use foldr instead of foldl?
23:36:24 <lambdabot>  mueval: ExitFailure 1
23:36:45 <jared-w> >foldr (^) 1 [1..5] 
23:36:54 <quchen> Lokathor: you can define foldl(') using foldr, but not the other way round.
23:36:56 <Lokathor> let me put this another way: when should you *clearly not* use foldr
23:37:00 <quchen> foldl f z xs  =  foldr (\y ys acc -> ys (f acc y)) id xs z
23:37:50 <quchen> On the other hand, foldl never terminates for infinite inputs, while foldr might.
23:37:52 <jared-w> ಠ_ಠ why does that foldr (^) break everything?
23:38:02 <MarcelineVQ> :t foldr
23:38:03 <lambdabot> Foldable t => (a -> b -> b) -> b -> t a -> b
23:38:31 <Lokathor> i've got a foldl' in my program that must always terminate anyway, should i consider it be a foldr perhaps?
23:38:34 <jared-w> oh nvm it's just really stupidly large
23:38:40 <MarcelineVQ> because you missed providing the base case
23:39:07 <quchen> jared-w: Your computation contains numbers far larger than there are particles in the universe.
23:39:09 <MarcelineVQ> it's not supidly large is it? it's just 1, it's just annoying to compute
23:39:10 <jared-w> nah I fixed it, I was just wondering why 1^2^3^4^5 was hanging until I realized what an absurd number that was
23:39:51 <Lokathor> which way does ^ gruop again
23:39:57 <jared-w> Depends on foldl vs foldr
23:40:02 <MarcelineVQ> infixr8
23:40:16 <quchen> > length (show (4 ^ 5))
23:40:19 <lambdabot>  4
23:40:21 <quchen> > length (show (3 ^ 44 ^ 5))
23:40:22 <Lokathor> 1^(2^3) ?
23:40:27 <jared-w> > foldl' (^) 1 [1..5] -- is just fine
23:40:28 <lambdabot>  mueval-core: Time limit exceeded
23:40:29 <lambdabot>  1
23:40:31 <quchen> Woops, stray »4« there
23:40:53 <quchen> Anyway, that tower is going to contain 2^3-digit many digits in its normal form. :-)
23:40:59 <jared-w> foldr (^) 1 [1..5] will hang for damn near forever :p
23:41:30 <quchen> Depends on the type of 1, really.
23:41:56 <quchen> If it’s an Int you get modular arithmetic and it might terminate soon-ish.
23:42:22 <jared-w> I used Int and got an error due to negative exponent. I'm guessing from overflow
23:42:32 <grmp> Int saves us
23:43:07 <quchen> Yeah ^ isn’t really suitable for int-to-the-power-of-int
23:43:46 <quchen> > foldr (^) 1 [1..5] :: Word
23:43:48 <lambdabot>  1
23:43:54 <quchen> Hope you’re happy now :-þ
23:44:19 <jared-w> Half happy, half "why tf did that work"
23:44:33 <quchen> > 4 ^ 5 :: Word
23:44:35 <lambdabot>  1024
23:44:38 <quchen> > 3 ^ 4 ^ 5 :: Word
23:44:40 <lambdabot>  11359380750133874689
23:44:43 <quchen> > 2 ^ 3 ^ 4 ^ 5 :: Word
23:44:46 <lambdabot>  0
23:45:01 <Axman6> correct!
23:45:12 <jared-w> ah, gotcha 
23:45:15 <Axman6> 3 ^ 4 ^ 5 ^ 6 :: Word
23:45:17 <Lokathor> which might folks think is better, (Int,Int) for locations, or a custom Location type?
23:45:18 <Axman6> > 3 ^ 4 ^ 5 ^ 6 :: Word
23:45:20 <lambdabot>  1
23:45:28 <quchen> Lokathor: Custom
23:45:30 <jared-w> Lokathor: I'm a fan of custom location type
23:45:34 <MarcelineVQ> Lokathor: custom or maybe V2
23:45:39 <Axman6> yeah usually a custom one
23:45:50 <Axman6> or V2 from linear, yeah
23:46:01 <Lokathor> V2 is a good suggestion
23:46:09 <jared-w> Tuples, to me, should be used when you just want some super quick temporary structure. Not really for some core data structure in a game :p
23:46:10 <Lokathor> those are strict unpacked right?
23:46:19 <Lokathor> V2 i mean
23:46:29 <Axman6> I think they;'re strict, but not unpacked
23:46:30 <jared-w> @src V2
23:46:30 <lambdabot> Source not found. I don't think I can be your friend on Facebook anymore.
23:46:41 <Axman6> because they're polymorphic
23:46:41 <Lokathor> lambdabot laying it down
23:46:44 <jared-w> It's ok, lambdabot, I never loved you anyway
23:46:50 <Lokathor> the burns!
23:47:08 <jared-w> https://hackage.haskell.org/package/linear-1.20.6/docs/Linear-V2.html
23:47:16 <jared-w> seems it's V2 !a !a so not unpacked but strict
23:48:19 <cocreature> ghc automatically unpacks strict fields if you compile with optimizations
23:48:31 <Lokathor> true
23:48:48 <Lokathor> V2 is a strong canidate for cleanup then
23:48:50 <jared-w> oh neat, good to know
23:48:57 <pacak> It unpacks small strict fields, not all of them.
23:49:10 <jared-w> It's got a ton of optimizing done to it, too. Half the code is litered with inline and optimizations n shit
23:49:13 <cocreature> oh nvm that’s polymorphic anyway
23:49:16 <cocreature> so it can’t be unpacked
23:49:17 <Lokathor> https://github.com/Lokathor/pcgen-hs/blob/master/src/Data/PCGen.hs#L41
23:49:42 <jared-w> cocreature: I was excited for a second :(
23:50:02 <Lokathor> cocreature, it doesn't make a specialized version that it then unpacks?
23:50:07 <cocreature> no
23:50:11 <Lokathor> :((((((
23:50:13 <cocreature> ghc never specializes types
23:50:25 <Lokathor> i feel personally attacked
23:50:27 <cocreature> it might completely eliminate the type and then unbox things
23:50:35 <cocreature> but it won’t make a specialized unboxed version of that type
23:50:47 <Lokathor> how often does it unbox tuples?
23:50:59 <pacak> About never?
23:51:03 <pacak> Tuples are lazy
23:51:10 <Lokathor> dageriffic
23:51:16 <cocreature> well the strictness analyzer can still kick in and unbox things
23:51:29 <pacak> And polymorphic
23:51:37 <jared-w> V2 is strict though, so that's another win for that over tuples I guess :p
23:51:54 <cocreature> I wonder how often we actually use lazy tuples
23:52:18 <Lokathor> alllll the time
23:52:23 <cocreature> lazy tuples seem to be one of the primary reasons for space leaks ime
23:52:26 <jared-w> using them for key,value pairs with Data.Map?
23:52:28 <pacak> Today I wrote some code that relies on tuple being lazy for efficiency.
23:52:57 <MarcelineVQ> was it also with foldr?
23:53:00 <Lokathor> here's a q, in this lambda, (\p -> getTerrainAt p d), would it be at all worth investigating switching the getTerrainAt argument order so that you could eta reduce or whatever it's called
23:53:10 <Lokathor> would that make it a CAF, and... do some sort of magic i forget about
23:54:18 <MarcelineVQ> CAF's would be at the very last spot in most lists I'd be inclined to make about efficiency, ymmv
23:54:39 <MarcelineVQ> I'm sure it matters, but it's not worth caring if it matters until it matters ;>
23:55:00 <Lokathor> well right now i only use it in 3 places, i'd prefer to change it before i used it in 333 places
23:55:01 <pacak> MarcelineVQ: Nope.  (a -> (b, b)) -> IntMap a -> (IntMap b,  IntMap b)
23:55:18 <MarcelineVQ> pacak: neat, a split?
23:55:38 <jared-w> alrighty, bedtime. See y'all. Gl making your ludolib suck less, Lokathor 
23:56:11 <Lokathor> it might eventually
23:56:12 <MarcelineVQ> it'll get there. the ultimate goal of any craftsman, suck less
23:56:34 <marvin2> I'd reorder arguments not for efficiency but for convenience sake, assuming  (\p -> getTerrainAt p d) is more common than getTerrainAt p
23:56:52 <jared-w> anyway, let me know how that one liner worked out, Lokathor :p
23:56:55 <pacak> MarcelineVQ: For every a there are two variants of b. function ensures that you have to provide both cases and it makes two maps the same size from one.
