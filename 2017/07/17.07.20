00:06:44 <Axman6> @hoogle (a -> Bool) -> [a] -> ([a],[a])
00:06:44 <lambdabot> Prelude span :: (a -> Bool) -> [a] -> ([a], [a])
00:06:44 <lambdabot> Prelude break :: (a -> Bool) -> [a] -> ([a], [a])
00:06:44 <lambdabot> Data.List span :: (a -> Bool) -> [a] -> ([a], [a])
00:22:49 <frerich> Hi all! Is anybody here familiar with making hdevtools (I'm on version 0.1.5.0) pick up a ghc which was installed via stack? My issue is that 'hdevtools check <somefile>' always bails out with 'Cabal error: The program 'ghc' version >=6.4 is required but it could not be found.'
00:23:18 <frerich> I thought it's maybe a PATH issue (I'm on macOS), but alas even putting e.g. $HOME/.stack/programs/x86_64-osx/ghc-8.0.2/bin into the PATH (such that just 'ghc' works) doesn't seem to help.
00:25:58 <mud> frerich: Maybe it needs a more specific GHC version than the error message suggests? Just a guess though.
00:32:07 <frerich> Hm, I just thought that maybe it's actually a cabal problem (given that the error message says 'Cabal error: ...') but installing cabal via 'stack install cabal-install' didn't seem to help.
00:35:35 <tsmish> frerich: Have you tried stack exec?
00:36:59 <merijn> frerich: When are you getting this "Cabal error:" message?
00:37:23 <frerich> tsmish: Yes, that does not seem to  make a difference. :-/
00:37:25 <frerich> merijn: When running 'hdevtools check <somesourcefile>'
00:38:06 <frerich> I just found something interesting: hdevtools check *does* work if I just invoke it for e.g. /tmp/hello.hs. It does not seem to work if I run it for source code which is in a stack project (i.e. which I created via 'stack new ...')
00:38:06 <merijn> frerich: hmm, that's odd. Which version of Cabal do you have?
00:38:16 <merijn> frerich: I have a suspicion why
00:38:53 <frerich> merijn: 'stack exec -- cabal --version' says it uses cabal-install version 1.24.0.2
00:39:00 <merijn> frerich: hdevtools uses Cabal (the library) as dependency, so it only really works when the project you're trying to use hdevtools with is being built using the same Cabal version
00:39:09 <merijn> frerich: Cabal version, not cabal-install :)
00:39:22 <merijn> frerich: hdevtools uses Cabal, not cabal-install
00:39:31 <frerich> merijn: Oh...
00:39:45 <merijn> Although cabal --version should report Cabal version too :)
00:40:02 <frerich> The exact output is:
00:40:05 <frerich> ➜  /tmp stack exec -- cabal --version
00:40:05 <frerich> cabal-install version 1.24.0.2
00:40:05 <frerich> compiled using version 1.24.2.0 of the Cabal library
00:40:41 <frerich> merijn: Now, I don't know whether this is the version of the Cabal library which hdevtool uses.
00:40:47 <merijn> frerich: Do you know how to run the ghc-pkg equivalent of stack?
00:41:13 <frerich> merijn: I must admit, I don't (I'm also oblivious to what 'ghc-pkg' would be, ahem).
00:42:29 <merijn> frerich: ghc-pkg outputs GHC's package registry, showing the installed packages registered with ghc (so you can check if you have multiple Cabal versions installed), but I don't use stack, so I dunno how I'd go about checking with stack :)
00:42:51 <merijn> Alternatively, you could simply try rebuilding/installing hdevtools with the same stack config you're using for the broken project
00:42:57 <merijn> And see if that fixes it
00:44:15 <frerich> merijn: Hm, I guess I could try that. For what it's worth, I can reproduce this with a 'dummy' project which is merely a copy of some sort of template stack uses, too. E.g. 'stack new dummy simple && hdevtools check dummy/src/Main.hs' triggers the same issue.
00:45:19 <frerich> merijn: FWIW, 'hdevtools --version' says 'hdevtools: version 0.1.5.0 (ghc-8.0.2-x86_64-darwin, cabal-1.24.2.0)' and that last version number (despite using a lower-case 'C' for 'Cabal') looks exactly like the version of Cabal which my projects seem to use.
00:45:31 <merijn> frerich: You could also try ghc-mod, which I think is more robust against "multiple cabal versions"
00:46:04 <merijn> hdevtools, unfortunately, isn't all that robust nor well-maintained
00:52:39 <asdaljlsd> i didnt kno facebook was for minors.....
00:52:48 <asdaljlsd> ??
00:53:11 <bvad> asdaljlsd: Huh?
00:53:25 <asdaljlsd> it developed filters.....
00:53:42 <asdaljlsd> cant even say fuck on it?
00:54:13 <merijn> This seems...highly off-topic?
00:54:26 <asdaljlsd> point me in the right direction, im drunk.
00:54:30 <asdaljlsd> pleaseeeeeeeeeeeeeeeee
00:55:03 <asdaljlsd> cuase i dont think theres a topic about problem solving?
00:55:28 <asdaljlsd> like....eh wont quit trying to fuck my ass.....and im a dude....
00:55:35 <asdaljlsd> which room?
00:56:06 <asdaljlsd> i must be here already?
00:56:23 <asdaljlsd> can admin change room name?
00:57:19 <asdaljlsd> do i leave my phone number?
00:57:34 <asdaljlsd> what if your all into anal sex too.....
00:57:38 <asdaljlsd> omfg.....
00:57:46 <merijn> @where ops
00:57:46 <lambdabot> byorgey Cale conal copumpkin dcoutts dibblego dolio edwardk geekosaur glguy jmcarthur johnw monochrom quicksilver Saizan shachaf shapr ski
00:58:28 --- mode: ChanServ set +o dibblego
00:58:32 --- mode: dibblego set +b *!*@adsl-74-248-45-94.pfn.bellsouth.net
00:58:35 --- kick: asdaljlsd was kicked by dibblego (asdaljlsd)
00:58:41 <bvad> Thank you 
00:58:45 --- mode: dibblego set -o dibblego
00:59:06 <yoneda> thanx dibblego
00:59:38 <dibblego> np
01:03:01 <ertes-w> the right direction →
01:12:00 <frerich> merijn: Thanks! ghc-mod looks powerful, but alas I now see that Syntastic (A Vim plugin I use) removed support for ghc-mod a while ago since ghc-mod apparently requires being invoked from the project root (or something like that, I did not fully grok the GitHub issue discussion).
01:12:40 <merijn> frerich: I know your pain, I use syntastic too. I saw there's a syntastic alternative that does support ghc-mod, though lemme see if I can find it
01:12:58 <frerich> merijn: I just saw 'ghcmod-vim', maybe that's something...
01:13:31 <yushyin> merijn: neomake?
01:13:55 <merijn> Yes, neomake is the one, I think
01:15:50 <tsmish> merijn: Have you seen neco-ghc? It is neocomplete plugin.
01:16:28 <merijn> tdammers: I've seen it, but I don't use neocomplete. I've tried it a few times, but I end up never actually using it
01:16:39 <merijn> s/tdammers/tsmish
01:18:28 <yushyin> tsmish: you do not need a completion engine, I use neco-ghc as omnifunc for vim
01:57:40 <halogenandtoast> I've spent a long time looking at this problem and I haven't been able to interpret the error. I'm basing my code on something a former coworker wrote for doing joins with Persistent/Esqueleto: https://gist.github.com/halogenandtoast/d50d73b6d6116a53241be5507e058dbf
01:57:54 <halogenandtoast> Can anyone shed some light on what's wrong here?
02:02:39 <merijn> halogenandtoast: I only have a rather unhelpful comment that I gave up on trying to understand Esqueleto and just went with hand-written SQL and persistent's rawSql API
02:04:35 <merijn> halogenandtoast: I've been MUCH happier since
02:05:14 <halogenandtoast> merijn: yeah, I'd believe it.
02:05:18 <halogenandtoast> Which is unfortunate.
02:07:01 <ertes-w> i went one step further and gave up persistent as well
02:07:37 <ertes-w> unless they have made *major* improvements since the last time i tried to use it (disclaimer: it was years ago), it would just drive me nuts
02:08:53 <merijn> ertes-w: I already implemented my entire schema and data import using persistent, so that'd mean rewriting a bunch of stuff for no particular reason. Especially since I use persistent's streaming query interface a lot
02:10:06 <ertes-w> merijn: sure…  luckily i was in an early stage of development
02:10:26 <Yotam> I have a stack project on D: that uses hmatrix. But I installed the c libraries on the stack msys which screwed the paths. How can I change them?
02:14:34 <ertes-w> but it's not just persistent…  it seems like all libraries that try to abstract "databases" have the same issue: ultimately they are always more expensive than modelling your application and then writing the database backends yourself
02:16:29 <halogenandtoast> To me it seems like all of the SQL libraries are a bit rough around the edges.
02:17:11 <halogenandtoast> People have mentioned some good about OpalEye, but I don't know how I'd integrate it with Yesod and every time I try to look at the documentation of OpalEye I get a little confused
02:17:27 <merijn> Opaleye is also postgres only, sadly
02:17:43 <merijn> I saw another library similar to Opaleye recently, but I forgot the name
02:17:58 <merijn> ah, Selda
02:18:55 <halogenandtoast> I don't know why but this kind of stuff seems like something Haskell should be able to excel at
02:19:36 <halogenandtoast> use a relational algebra
02:19:39 <merijn> halogenandtoast: Someone has to write it :)
02:20:40 * hackagebot microstache 1.0.1 – Mustache templates for Haskell – https://hackage.haskell.org/package/microstache
02:21:05 <halogenandtoast> Maybe I'll toy with something, I'm not super skilled with Haskell yet, but maybe this is the thing that solves that problem.
02:24:59 <tdammers> "SQL Library" is a bit ambiguous, there are at least 3 concerns related to SQL databases that would deserve libraries
02:26:31 <tdammers> 1) DB connectivity, 2) interfacing between application data structures and SQL queries, 3) managing database schemas
02:26:49 <halogenandtoast> I'll start with 1 and work to 3
02:27:03 <tdammers> opaleye sits in spot 2 though
02:27:24 <halogenandtoast> yes
02:27:46 <tdammers> also, for 1) we already have fairly OK solutions
02:28:22 <halogenandtoast> tdammers: my problem is I'm "unhappy" with #2
02:28:45 <tdammers> halogenandtoast: same here, but then, I haven't really seen a satisfactory solution in *any* language
02:29:05 <tdammers> also, I believe that making your code type-safe against the DB schema is a fallacy
02:29:19 <ertes-w> halogenandtoast: the only way i can see opaleye working as an abstraction is when it's postgres-only, and that seems to be the case
02:29:35 <tdammers> the DB schema is intrinsically external to the application code, you should not rely on any particular schema at all
02:29:42 <tdammers> the database is an external resource
02:29:51 <ertes-w> halogenandtoast: but then i can only imagine using it as a backend library, because i rarely use networked databases these days (usually sqlite)
02:30:01 <halogenandtoast> tdammers: sure, then maybe the solution is something kind of like Aeson
02:30:08 <halogenandtoast> but for query results
02:30:17 <ertes-w> tdammers: i completely disagree about that
02:30:42 <ertes-w> tdammers: the database schema is specific to the application and backend
02:30:43 <tdammers> query results are easy - you define mappings from result set rows to native data structures, and then type inference does the rest
02:31:11 <phz_> hey
02:31:17 <tdammers> ertes-w: it is, but database schema and the application's expectations both evolve, and you want them to be loosely coupled
02:31:26 <tdammers> so that you can deploy independently
02:31:26 <ertes-w> sure
02:31:26 <phz_> is there a slack application / a way to have a REPL in slack?
02:31:34 <merijn> tdammers: The query interface should enforce matching the schema, though
02:31:56 <tdammers> merijn: matching the *expected* schema
02:32:05 <tdammers> but you still need to be prepared for a different schema
02:32:11 <merijn> tdammers: Why?
02:32:39 <merijn> tdammers: It should match the schema with what the program thinks is in the DB and error out/check for migration path if there's a mismatch
02:32:45 <tdammers> because guaranteeing that the database and the application always get deployed in concert is tight coupling and makes your system brittle
02:33:19 <merijn> tdammers: If a column is expected to be Int, but it isn't the query should fail unless there's fallback code
02:34:50 <tdammers> merijn: my issue with this is that 1) modeling arbitrary database schemas in the type system is a very complex task, and 2) such type safety guaratees aren't anywhere near as useful as they are for application code itself, because you only control one side of the interface
02:35:30 <ertes-w> tdammers: there are a number of ways to deal with schemas…  mine is usually: at startup ensure that the fields i expect to be there are actually there, then continue
02:35:40 <ertes-w> in other words i dispensed with the idea of schema versions
02:35:58 <tdammers> ertes-w: agree 100%, schema versions are crap
02:36:18 <tdammers> "structurally typed interfaces" :)
02:36:43 <tdammers> anyway, I'm a big fan of the "hard types on the inside, lenient interfaces on the outside" approach
02:36:56 <ertes-w> yeah, exactly
02:37:07 <tdammers> as far as SQL query management goes, I prefer writing SQL as SQL, and defining the mappings manually and explicitly
02:37:22 <tdammers> with a thin convenience layers for boring standard CRUD stuff
02:37:26 <ertes-w> that is also why i actually considered switching to MongoDB at some point, but quickly abandoned that idea
02:38:02 <tdammers> the relational model is fine, especially when you can sprinkle in some document stuff ala Postgres JSONB when it's appropriate
02:38:41 <ertes-w> the main reason i dropped the idea was the lack of proper transactions
02:39:47 <tdammers> my preferred approach is using (blatant plug here) yeshql - write SQL as SQL, manually add type annotations, and have the library generate plain old IO functions that represent queries directly
02:40:12 <tdammers> and then you can have those functions accept and return typed data, as long as appropriate ToSqlRow / FromSqlRow instances exist
02:41:22 <tdammers> and then to deal with standard CRUD stuff, one line of TH for each table / entity to generate getFoobarByID, getFoobarByBaz, insertFoobar, updateFoobar, deleteFoobar
02:47:28 <merijn> tdammers: So how do you deal with columns changing types? Hope you remember to update the type annotation?
02:48:06 <ertes-w> simple: never change column types =)
02:48:22 <ertes-w> it's a recipe for disaster
02:48:26 <merijn> ertes-w: Right, because I always know my schema when I start :)
02:48:43 <merijn> Clearly you're using databases way different from me :)
02:48:43 <ertes-w> no, schema extensions are fine, but never change the type of a column
02:49:55 <merijn> ertes-w: I don't always know what type I want ahead of time
02:50:28 <ertes-w> merijn: prefer to add a new column and phase out the old one…  it's easy enough for your backend to support both columns and prefer one over the other
02:50:35 <ertes-w> never change column types
02:51:37 <merijn> ertes-w: I'm only dealing with SQLite embedded databases, so I have 0 reason to fix my schema that much ahead of time
02:52:00 <ertes-w> merijn: fix?
02:52:50 <merijn> ertes-w: fix as in considering it unchangeable
02:53:33 <ertes-w> but it's not unchangable
02:53:40 <ertes-w> the only constraint is that you never change column types
02:53:53 <merijn> ertes-w: Yes, which is too limiting for exploratory development
02:54:33 <ertes-w> merijn: why?
02:56:15 <merijn> ertes-w: because I might try something with column type A, decide it's not working, replace it with something else, rinse and repeat
02:56:31 <merijn> Keeping all failed experiments bloats my schema, code, and makes life in general a pain in the ass
02:56:49 <tdammers> one thing to remember is that column types and Haskell field types do not correspond 1:1
02:57:11 <tdammers> so, for example, the column type could change from JSON to TEXT, but on the Haskell side, I might have had Text already
02:57:44 <tdammers> meaning that often, I can afford for type changes to happen on one side only
02:58:02 <tdammers> in fact, this is the preferred approach - change only one side of the interface at a time
02:58:11 <tdammers> nullability is another example
02:58:21 <tdammers> suppose I have a nullable column, but I want to get rid of nullability
02:58:58 <ertes-w> merijn: you can do that during development
02:59:07 <tdammers> first step is to change the application code to still accept nulls, but never produce any
02:59:22 <ertes-w> merijn: but when you deploy the type becomes fixed…  in the next iteration you can play around again with a new column
02:59:24 <tdammers> then the next step is to change the database to get rid of any actual nulls
02:59:33 <ertes-w> merijn: it's really not a big deal
02:59:37 <merijn> ertes-w: I do research, there's no such thing as deploying
02:59:53 <merijn> ertes-w: So I don't give a shit about past schema's beyond my current code working
03:01:52 <ertes-w> merijn: well, then you don't have production systems crashing because of bad schema assumptions, but i certainly do, and that's why i work under this constraint =)
03:02:17 <tdammers> oh, also, another concern is when you have multiple application servers connecting to the same database
03:02:30 <ertes-w> exactly
03:02:38 <tdammers> this practically rules out "check the schema at startup, and if it doesn't match, migrate"
03:03:02 <tdammers> because then you have version A running on server 1, and version B running on server 2, and they both keep cross-migrating the schema under each other's butt
03:03:11 <ertes-w> schema extensions are fine, as long as either they don't come with new constraints, or you enforce those constraints on the database side
03:03:43 <tdammers> having the application server automatically migrate the schema is still bad
03:04:14 <ertes-w> i know some people who don't allow "raw" SQL because of this…  they do everything with stored procedures
03:04:26 <ertes-w> tdammers: ALTER TABLE ADD is fine
03:04:43 <ertes-w> if it fails, your application crashes, the process supervisor restarts it, and then it works
03:05:14 <ertes-w> and the only way it might fail is in a race with another process doing migrations at the same time
03:05:18 <tdammers> the thing is, in a load-balanced setup, you want to restart your application servers one by one
03:05:33 <tdammers> not have them crash all at the same time and then rely on the supervisor to restart them
03:06:42 <ertes-w> if you restart them one by one, you won't even run into this issue…  app 1 migrates, apps 2 and 3 find that the desired schema is already a subset of the existing schema
03:07:02 <ertes-w> it only happens when two applications try to migrate concurrently
03:07:05 <tdammers> I prefer doing DB migrations in a separate step
03:07:17 <tdammers> if only for troubleshooting and rollbacks
03:07:17 <kuribas> Why do I get • No instance for (Bounded (Maybe Int)) arising from a use of ‘mconcat’ ?
03:07:23 <kuribas> what does Bounded have to do with mconcat?
03:07:31 <tdammers> deploy DB - stuff fails - "oh drat, lemme roll that back"
03:07:42 <tdammers> deploy app - stuff fails - "oh drat, lemme roll that back"
03:07:45 <tdammers> however
03:07:57 <ertes-w> tdammers: i want everything to work out of the box
03:08:00 <tdammers> deploy app, auto-migrate DB - stuff fails - "?"
03:08:08 <tdammers> ertes-w: we all want that
03:08:32 <tdammers> oh, also, I don't want the public-facing web application to have the keys to the kingdom
03:08:57 <tdammers> migration is done from a separate environment, with separate credentials that have DDL permissions
03:09:13 <tdammers> the app itself gets limited credentials
03:10:58 <kuribas> hm, I suppose it comes from Min
03:28:24 <merijn> yushyin: btw, so do you use neomake?
03:34:52 <frerich> Hm, I always thought that OverloadedStrings just allows getting rid of e.g. pack/unpack calls when dealing with Data.Text, but now I see that it allows pattern matching, as in http://lpaste.net/357063
03:35:36 <frerich> I don't really understand why that works now :-}
03:41:20 <otini> Hi, now testing GHC 8.2.1rc3. Anyone else having issues with `cabal new-run`?
03:42:04 <quchen> ReinH: Any news? :-)
03:42:19 <otini> # cabal new-run
03:42:29 <otini> Up to date
03:43:20 <otini> rawSystem: runInteractiveProcess: exec: does not exist (No such file or directory)
03:44:11 <otini> cabal new-run fails although cabal new-run works fine
03:56:33 <ertes-w> tdammers: it does for me though…  i've set everything up such that you can "just do stuff"…  if you want service X to run, you just start service X
03:57:03 <ertes-w> no need to do any migrations or setup work beforehand
04:03:30 * hackagebot yesod-core 1.4.35.1, yesod-form 1.4.13, yesod-test 1.5.8
04:03:30 * hackagebot  → https://hackage.haskell.org/packages/recent
04:13:16 <tdammers> ertes-w: that's a great approach for a more service-oriented architecture, where each database belongs to exactly one service
04:28:26 <mpickering> otini: I didn't think it was implemented yet. Which version of cabal are you using?
04:28:40 <mpickering> The way I do it atm is "cabal new-build" and then copy the executable path and run it
04:31:22 <merijn> mpickering, otini: Also, hvr's cabal-plan can output the executable paths for you
04:31:30 <mpickering> otini: See https://github.com/haskell/cabal/pull/4586
04:32:15 <mpickering> It would be better to be in cabal as I needed a programmatic portable way for a makefile. 
04:33:29 <mpickering> otini: https://github.com/haskell/cabal/projects/4#card-3356212
04:36:07 <ertes-w> tdammers: we have instances of shared databases
04:38:27 <ertes-w> tdammers: the way this works is that each application knows about the subset of the overall schema that it needs to do its work, and when you start it, that subset is set up, if it didn't already exist
04:38:57 <ertes-w> that's why the "no column type changes!" rule exists
04:40:49 <danilo2> Hello guys! I'm optimizing my code now and I usually use many StateT transformers because it makes the design very modular. The problem is that I've discovered it introduces a very big slowdown. I was able to make it much faster by increasing the flag value -funfolding-use-threshold
04:41:28 <danilo2> However I would love to make several StateT behave as fast as single one. I've been reading the Apfelmus "article" exactly about this topic: https://github.com/HeinrichApfelmus/optimize-monad-trans
04:42:06 <danilo2> And there is explanation why several StateT are not optimized exactly to the same code as single one: "n the first variant, the computation run m x i shared over several values for y, while in the second variant, the computation run m x is recomputed for every invocation with a value y ..."
04:42:40 <danilo2> However I'm wondering if there is any magic way to tell GHC that it should treat this particular "run" function as something very very cheap and inline it
04:43:25 <tdammers> ertes-w: still leaves you with the keys-to-the-kingdom problem
04:44:13 <Sh4rPEYE> What does the function `reads` do? The documentation is unclear to me
04:44:16 <ertes-w> tdammers: what is it?
04:44:40 <tdammers> ertes-w: that your public-facing web application has database access that allows for DDL queries
04:45:16 <hpc> Sh4rPEYE: it returns every parse of the string, with any extra output that wasn't parsed
04:45:19 <hpc> it also doesn't error on failure
04:45:24 <hpc> > reads "five" :: Int
04:45:27 <lambdabot>  error:
04:45:27 <lambdabot>      • Couldn't match expected type ‘Int’
04:45:27 <lambdabot>                    with actual type ‘[(a0, String)]’
04:45:28 <hpc> er
04:45:31 <ertes-w> danilo2: narrow the scope of inner state instances
04:45:34 <hpc> > reads "five" :: [(Int, String)]
04:45:36 <lambdabot>  []
04:45:39 <hpc> > reads "5five" :: [(Int, String)]
04:45:42 <lambdabot>  [(5,"five")]
04:45:46 <ertes-w> danilo2: i.e. don't nest them too deeply
04:46:02 <ertes-w> danilo2: 'zoom' from the lens package can help you there
04:46:02 <Sh4rPEYE> Oh, got it. Thanks.
04:46:28 <Sh4rPEYE> > reads "13something" :: [(Int, String)]
04:46:30 <lambdabot>  [(13,"something")]
04:46:59 <ertes-w> > execState (zoom _1 (id += 3)) (3, 4)
04:47:01 <lambdabot>  (6,4)
04:47:57 <danilo2> ertes-w: what do you mean by "narrow the scope" ? I've written a newtype over StateT which allows me to access different states with using of expliccte type signatures, like `get @Foo` or `get @Bar`. I need to be able to access both `Foo`, `Bar` and `Baz` but I also want this code to be composable, so if somebpdy want to build stakc without Baz he could do it
04:49:40 <ertes-w> danilo2: well, the idea is that you start from a composite state, but the individual components don't need to know the full state type…  they should work on their substate, correct?
04:50:28 <danilo2> ertes-w: correct! I want just these states to be "composable" and bring these components "into scope", but they are completely independend and because of that I do not want the performance to be affected
04:51:10 <danilo2> ertes-w: explaining it even better
04:53:05 <danilo2> ertes-w: Let's tell my library provides 10 different StateT layers that user can freely compose. He could create functions that use only 1, or 2, or 3, etc states, but these states are independent. He also uses some predefined functions that use some of the states (function foo uses state 1 and 2, while function bar uses state 4,5 and 6). This way he could compose fine tuned solution for himselft
04:53:31 <ertes-w> danilo2: 'zoom' allows you to zoom into a particular component of the state and access it in isolation…  the main difference is that individual components have a clear idea of what their substate type is, they just don't know that it's actually part of a larger state
04:53:46 <ertes-w> danilo2: example:
04:54:44 <ertes-w> > execState (do zoom _1 (modify ("Hello " ++)); zoom _2 (modify (1 +))) ("world!", 41)
04:54:46 <lambdabot>  ("Hello world!",42)
04:56:05 <danilo2> ertes-w: I understand. So in fact your solution is to remove all the StateT layers and use just a "tuple" and access these different components (that I currently keep in different StateT) using zoom ?
04:57:08 <danilo2> ertes-w: so instead of having (StateT Foo (StateT Bar (StateT Baz m)) a) you want me to have (StateT (Foo,Bar,Baz) m a) ?
04:58:08 * hackagebot neko-obfs 0.1.0.0 – a TCP tunnel with packet length obfuscation – https://hackage.haskell.org/package/neko-obfs
05:05:31 <otini> mpickering: thanks! Indeed it was merged quite recently.
05:06:04 <otini> mpickering: my version is 2.1.0.
05:06:39 <otini> can't switch to HEAD right now, but never mind it's good to know that this is fixed
05:08:33 <ertes-w> danilo2: yeah, pretty much
05:09:00 <ertes-w> danilo2: you can compose the state any way you want…  remember that lenses can access more complicated patterns than just components of product types
05:09:17 <ertes-w> danilo2: in fact 'zoom' even works with traversals, which is quite nice
05:09:34 <ertes-w> > execState (zoom both (modify (1 +))) (2, 3)
05:09:36 <lambdabot>  (3,4)
05:09:40 <danilo2> ertes-w: Ok, but it is "not-a-real" solution for me, because it does not give user the ability to compose everything using just many "runStateT". It will work, so yeah it is some kind of a solution, but hackish for me. 
05:09:58 <danilo2> ertes-w: However, the real question for me is how to make StateT stack optimize as good a single State
05:10:13 <danilo2> ertes-w: and I just want even outr of curiosity know why it is / is not possible
05:10:42 <danilo2> regarding to (https://github.com/HeinrichApfelmus/optimize-monad-trans) it could be possible, but ghc doesnt optimize a variable, because it does not know that "run" state operation is cheap
05:10:58 <danilo2> if this is the case, would it be sufficient to tell ghc that it is cheap (somehow) ? 
05:11:37 <ertes-w> danilo2: it probably boils down to how many optimisation passes you do, and to the strictness properties of your state monad
05:13:05 <danilo2> ertes-w: I'm using strict pass, I use "inline" literaly everywhere in my test cases and my compilation flags are: -threaded -funbox-strict-fields -O2 -flate-dmd-anal -fdicts-cheap -fdicts-strict -fconstraint-solver-iterations=100 -funfolding-use-threshold=10000 -fexpose-all-unfoldings -fsimpl-tick-factor=1000  -funbox-strict-fields
05:13:28 <danilo2> (sorry, the -fdicts-cheap -fdicts-strict) are not enabled
05:13:44 <danilo2> so as you can see, there is everything we can do in terms of optimization, or am I wrong ?
05:14:08 <ertes-w> danilo2: i'm also not convinced that your approach is more composable
05:15:08 * hackagebot mikrokosmos 0.3.0 – Lambda calculus interpreter – https://hackage.haskell.org/package/mikrokosmos
05:15:35 <ertes-w> danilo2: i believe the optimisations do work as they should, but they don't cover things like loops
05:16:57 <danilo2> ertes-w: I also belive they work like they should. The question is rather if it is even somehow possible, nto in current GHC state, but in general - if we could introduce some mechanism to make monad transformers optimize away
05:17:18 <danilo2> *monad transformers - at least stateT transformers which are straightforward to optimize "by hand"
05:18:38 <ertes-w> danilo2: we have all of that already…  the trouble is that these things become hard to optimise as soon as fixed points are involved
05:18:54 <ertes-w> optimising across 'fix' is really difficult
05:19:40 <danilo2> ertes-w: so if I remove all the fixed points from StateT implementation, would it be possible ?
05:19:44 <ertes-w> danilo2: try to use a CPS-transformed state transformer
05:20:03 <ertes-w> that might help
05:20:21 <ertes-w> danilo2: i.e. wrap each layer in a layer of Codensity
05:20:42 <ertes-w> danilo2: it's not about fixed points in the StateT implementation, but about fixed points in your code
05:21:04 <Sh4rPEYE> hpc: Why is `reads` returning a list? It always just parses the number in the front anyway
05:21:10 <danilo2> ertes-w: In my example (the benchmarks) I removed already all the fixed points
05:22:07 <ertes-w> danilo2: so no recursion at all?
05:22:16 <danilo2> ertes-w: would you be so nice and explain the idea about codensity better? Are there any CPS based monad transformers out there?
05:22:44 <ertes-w> note that 'traverse_' and 'replicateM_' are also recursive
05:24:00 <danilo2> ertes-w: here is my complete (short) benchmark:
05:24:01 <danilo2> http://lpaste.net/357066
05:24:43 <danilo2> ertes-w: State.Layered is just a wrapper around StateT allowing to access different states using the @-syntax, so if I write `get @Foo` it will lift exactly so many times to acess Foo state
05:25:02 <danilo2> ertes-w: anyway the same results I get using normal state with lifts (I can prepare such file)
05:25:07 <ertes-w> danilo2: newtype CStateT s m a = CStateT { runCStateT :: forall r. (a -> s -> m r) -> s -> m r }
05:26:07 <ertes-w> danilo2: your benchmark uses recursion over StateT
05:26:17 <danilo2> ertes-w: thats right
05:26:47 <ertes-w> in fact it uses just the right trade-off between length of computation and number of recursion layers:  you have very short manipulations done very often
05:27:40 <danilo2> ertes-w: yes, I just want to measure this particular effect. I know that normally it would not be so important, but in some cases it will be used somehowe like this and I want to measure this behavior. What is interesting
05:27:44 <ertes-w> now the idea of wrapping Codensity around is to flatten those "humps" that are created by left-associating (>>=)
05:28:03 <ertes-w> and those are created by every layer of fixed points
05:28:03 <ertes-w> (among other things)
05:28:21 <danilo2> ertes-w: with just State it runs in 1ms, with 1 StateT it runs in 2.3 ms with 2 StateT it Runs in 2.32 ms and with 3 StateSt it runs in 2.34 ms
05:28:22 <ertes-w> in some cases this can lead to asymptotic speedups
05:28:41 <danilo2> I dont understand why these differences between 0 and 1 are sodifferent than the others
05:29:08 <ertes-w> how to apply:  instead of using StateT S (StateT T (StateT U M)) use Codensity (StateT S (Codensity (StateT T (Codensity (StateT U M)))))
05:29:09 <ertes-w> you can find Control.Monad.Codensity in the package 'kan-extensions'
05:29:18 <danilo2> ertes-w: interesting! So In fact using CPS State could helpm me here. Why we do not use CPS mtl ?
05:29:30 <ertes-w> a single layer of Codensity around everything might suffice
05:29:48 <ertes-w> it depends on your lifting patterns
05:30:03 <danilo2> ertes-w: I;ve already found it however it is not clear to me how I can use it with StateT. I have to think abotu it / diig around
05:30:08 <ertes-w> because CPS comes at a cost
05:30:27 <ertes-w> for example nobody has figured out how to implement MonadFix for a CPS monad yet
05:31:08 <ertes-w> you literally just wrap Codensity around it
05:31:09 <ertes-w> no need to do anything else
05:32:09 <ertes-w> (flip runStateT u0 . flip runStateT t0 . flip runStateT s0) becomes (flip runStateT u0 . lowerCodensity . flip runStateT t0 . lowerCodensity . flip runStateT s0 . lowerCodensity)
05:32:48 <ertes-w> the world's easiest algorithmic optimisation =)
05:32:48 <ertes-w> you just say "do it" =)
05:48:12 <danilo2> ertes-w: very interesting! (sorry I've got a call) 
05:48:40 <danilo2> ertes-w: hmm why it optimizes this code? what it exactly does fto GHC that GHC can run it faster
05:50:44 <ertes-w> danilo2: first of all, does it work?
05:51:00 <danilo2> ertes-w: I'm testing it right now, so I dont know yet!
05:51:04 <merijn> hmm, I wish Chart had more raster image outputs :\
05:51:13 <merijn> PNG isn't ideal
05:55:50 <danilo2> ertes-w: actually it does make everything slower
05:55:55 <danilo2> ertes-w: here are the results:
05:57:50 <danilo2> ertes-w: http://lpaste.net/357067
05:58:14 <ertes-w> danilo2: some of the layers may be unnecessary…  try using only one layer
05:58:14 <ertes-w> Codensity (StateT S (StateT T (StateT U M)))
05:58:36 <ertes-w> as i said, it depends on your lifting patterns
05:59:37 <danilo2> Ok I just run tests with 1 layer
05:59:47 <danilo2> btw ertes-w using these layers made the ties grow exponentialy
06:00:24 <danilo2> Ok, using 1 layer makes everything slower of constant factor of ~4 
06:07:20 <danilo2> ertes-w: moreover I jsut tried in the same example using CPS State (https://hackage.haskell.org/package/mtl-c-0.1.1/docs/Control-Monad-State-CPS.html) and it works around 40x slower than the mtl version
06:11:09 <ertes-w> that's weird
06:12:46 <davr0s> is there a way to share the 'destructuring' to access record elements across many functoins, in a manner similar to OOP, eg
06:13:11 <davr0s> maybe something like a 'with' construct,
06:13:16 <ertes-w> danilo2: mtl-c is using a really weird argument order for its StateT
06:14:26 <ertes-w> danilo2: i would use this instead:  newtype StateT s m a = StateT { runStateT :: forall r. (a -> s -> m r) -> s -> m r }
06:14:26 <ertes-w> davr0s: 'zoom' from the 'lens' package
06:14:56 <davr0s> data Foo =Foo A B           foo::Foo->..       foo (Foo a b)  =...         bar (Foo a b) = ....       -- imagine many functions that destructure 'Foo'..
06:15:12 <davr0s> ok i have not touched 'lens' yet..
06:15:17 <ertes-w> > execState (zoom _1 (modify (^2) >> modify (1 +))) (10, 20)
06:15:19 <lambdabot>  (101,20)
06:15:28 <danilo2> ertes-w: hmm Ok Ill try to implement it by myself. Strange there is no good implementation of cps statet though
06:15:43 <danilo2> ertes-w: by the way, I'm really thankfull for your time and this conversation
06:16:09 <ertes-w> davr0s: without lenses the way to do it would be to write 'with' functions yourself
06:16:16 <ertes-w> davr0s: withFst f (x, y) = (f x, y)
06:17:02 <ertes-w> danilo2: i have written a library of CPS transformers myself years ago, but it's unmaintained now and has been for many years
06:17:07 <ertes-w> danilo2: it's called 'contstuff'
06:17:50 <ertes-w> it might still compile though
06:52:24 <danilo2> Hi! Could anybody expaln to me one mystery? If I use pointfree in my functions they run about 40 times slower than without pointfree. HOWEVER If I define the (.) operator in the same file they run as fast as without pointfree. Moreover, if I define this operator somwehere else (and of course it has INLINE pragma) it again is slow
06:52:34 <danilo2> Does it mean that GHC ignores this INLINE pragma ?
06:56:10 <kuribas> danilo2: do you use -O ?
06:56:11 <kuribas> danilo2: I am pretty sure it would inline (.)
06:57:44 <danilo2> kuribas: I'm using -O2
06:57:44 <geekosaur> .oO { Core or it didn't happen }
06:58:07 <danilo2> geekosaur: I can give you the code
06:58:17 <danilo2> It's small (1 file + 1 benchamrk file)
06:59:03 <danilo2> geekosaur: I'm not too familiar with core to inspect it really well now, but will it be ok if I upload you the files?
06:59:14 <merijn> ooh...bravo for Chart, it seems it's significantly faster than gnuplot
07:00:12 <geekosaur> well, put it somewhere others can see it. I'm not necessarily the right one to inspect it, but I know it won't go very far without that level of detail
07:00:28 <geekosaur> also, which ghc version
07:00:48 <danilo2> geekosaur: sure, 8.0.2
07:00:54 <danilo2> I'll make it available in a moment
07:04:30 <danilo2> geekosaur: ok, i need to clean it up from dependencies. I thought it would be easier. I've got a skype call right now but after it I would upload it and notify you
07:05:07 <geekosaur> ok
07:13:21 <et4te> hey guys, i'm using stack and getting an error trying to use a docker image (Running /usr/sbin/groupadd -o --gid 4 group4 exited with ExitFailure 9), stack version 1.4.0, lts-8.17
07:13:57 <et4te> anyone else have a problems when building derived images?
07:17:03 <bvad> et4te: Isn't it just telling you that you're trying to create a group that already exists?
07:17:51 <bvad> Well, a group with a gid that's already been used?
07:18:32 <et4te> bvad: yeah it is, but thats when i run docker start
07:18:44 <et4te> as in, i just followed the stack instructions and it fails
07:18:48 <bvad> et4te: which base image? 
07:20:11 <et4te> bvad: fpco/stack-build lts-8.17
07:20:52 -frerich(~frerich@kde/raabe)- Did anybody ever test whether it's more efficient to use 'S.toList . S.fromList' instead of 'map head . group . sort'?
07:21:08 <et4te> bvad: I run this with it: stack --docker-container-name=xx --docker-persist exec --plain bash
07:21:14 <bvad> et4te: are you trying to build in a container, or are you trying to build a container to run (e.g. `stack image container`)? 
07:21:27 <et4te> trying to build a container to run
07:21:40 <et4te> but from an image that i augment from the base
07:21:50 <et4te> cos the base image doesn't have certain deps that i need
07:22:30 <ertes-w> frerich: the former is almost certainly more efficient if there are duplicates
07:22:44 <ertes-w> the more duplicates there are the more efficient the former is
07:22:54 <bvad> et4te: I haven't actually used stack to run the containers, only to build them. Either way you probably shouldn't need to use fpco/stack-build as it's huge
07:22:55 <ertes-w> (in comparison)
07:25:04 <geekosaur> frerich, as ertes-w says, it'll depend on the use case. I'll also add that for larger lists sending it to a Set and back will be faster... but if you are running into that then you probably shouldn't be using lists in the first place
07:25:23 <et4te> bvad: building the container is what i'm after, i'm new to stack + docker so maybe i'm missing something obvious
07:26:04 <mud> geekosaur: Why for larger lists, out of curiosity?
07:26:29 <geekosaur> because Haskell lists are simple linked lists, and are best used simply as iterators
07:26:55 <bvad> et4te: I'm using this as a base image for running Haskell programs: https://gist.github.com/bjarkevad/2117a4106267a847f69a6e1dd5e724ac 
07:27:14 <geekosaur> often if you are using a larger list, it's more than just an iterator (in particular, if you are using (!!) at all on a large list then you are using the wrong data type)
07:27:38 <et4te> bvad: that looks like a much smaller image! :D
07:27:45 <bvad> <10MB :) 
07:28:24 <bvad> it should probably be updated to alpine:3.6 though
07:28:41 <mud> Right, but aren't Sets something even more complicated than linked lists?
07:29:03 <geekosaur> yes, but that complexity comes with a speedup for large lists
07:29:52 <ertes-w> mud: 'sort' will construct at least a list of n items in memory, where n is the length of the initial list (including the duplicates)
07:30:05 <ertes-w> that turns the list into an actual linked list in memory
07:31:38 <geekosaur> again, a Haskell list is a linked list. not a vector or array. it's *slow* for anything other than simply popping off the first element
07:31:52 <mud> Right, but S.fromList will similarly construct its actual thing in memory right? It makes sense to me intuitively that that'd be faster when there's many duplicates, but otherwise I didn't have any intuition of what large size would cause one to prefer.
07:33:50 <geekosaur> also can be extremely wasteful if list elements are small (so, String uses a LOT more memory than Text for strings longer than about 8 characters, in addition to being slower for e.g. searching)
07:37:52 <lambdamu> I'd like to define a fixpoint computation like this http://lpaste.net/357070, it doesn't work I assume because filtering a Map/HashMap isn't lazy enough, is there a map like data structure where this would work or is this fundamentally a bad idea?
07:38:52 <ertes-w> mud: note that n is the best case…  it's more around n * log n, just like a set, but less efficient, because it's all based on list traversal
07:39:53 <ertes-w> mud: i would expect the set variant to beat the sorting variant in all cases, except in trivial ones, where not only there aren't any duplicates, but also the list is pretty much already sorted
07:41:03 <merijn> ertes-w: I'd only expect that in the case of linked list, like here
07:41:24 <merijn> ertes-w: I know from experience that if you have an array the sort then process solution can be MUCH faster :)
07:44:10 <cloudhead> is there a way to avoid the "The main module to load is ambiguous. Candidates are:
07:44:20 <cloudhead> message when loading ghci
07:44:28 <cloudhead> that doesn't involve passing extra flags?
07:44:35 <cloudhead> ie: a default main
07:44:35 <merijn> cloudhead: How are you loading things?
07:44:48 <merijn> Because I've never seen that message
07:45:09 <cloudhead> merijn: just `stack ghci` or `stack build --test`
07:45:17 <cloudhead> oh hmm
07:45:28 <cloudhead> basically I have two main modules, one for the exe, and one for the tests
07:45:35 <cloudhead> I thought that was pretty standard
07:45:46 <mud> cloudhead: Doesn't it tell you how to specify I thought?
07:46:16 <cloudhead> yeah I'd have to do 'stack ghci bitcoin:exe:bitcoin-exe'
07:46:36 <cloudhead> but was hoping I could configure that to be the default for example
07:46:53 <mud> Ah. I don't know personally
07:46:57 <cloudhead> it gets pretty gnarly with ghcid, because I end up having to do
07:47:09 <cloudhead>  ghcid -c 'stack ghci --test bitcoin:test:bitcoin-test' --test main
07:47:26 <merijn> I don't use stack, so not much help with that :)
07:47:34 <merijn> Maybe #stackage knows?
07:48:07 <mud> ( #haskell-stack )
07:48:18 <AndiK> Never got that warning with stack either
07:48:36 <cloudhead> hm weird
07:48:52 <cloudhead> but you have projects with executables + tests?
07:49:10 <cloudhead> could you perhaps point me to a cabal file so I can see if I'm doing anything strange
07:50:02 <AndiK> cloudhead: http://lpaste.net/5519036441398607872
07:50:18 <AndiK> cloudhead: It's the stack template that includes tests
07:50:26 <AndiK> g2g now hope it helps
07:50:30 <cloudhead> thanks AndiK 
07:54:53 <rostero> this is an issue on a purescript package, but i was wondering if someone in here had an idea:  https://github.com/krisajenkins/purescript-remotedata/issues/3
07:56:00 <rostero> https://github.com/krisajenkins/purescript-remotedata/blob/master/src/Network/RemoteData.purs#L30
07:57:50 <ertes-w> merijn: well, in this case the array still needs to be fully allocated and sorted, including all duplicates…  it starts out being much faster at zero duplicates, but its relative performance would drop as you add duplicates
07:59:00 <paf31> rostero: maybe you want #purescript ?
07:59:13 <merijn> ertes-w: Sure, but honestly I don't think it'd be a significant drop unless you start seeing 20-30% duplicates or more
07:59:25 <ertes-w> merijn: probably even more
08:00:29 <ertes-w> merijn: if the values are simple (like numbers or short unboxed vectors), i would expect the array-based solution to be faster even at 500% duplicates
08:00:39 <merijn> :)
08:01:23 <ertes-w> mostly thanks to better cache behaviour, so the figure could change dramatically after a certain array length threshold (a few MiBs)
08:02:29 <mpickering> quchen: With prettyprinter is it possible to pretty print an ast whilst annotating the tree with the positions it was printed to? 
08:03:35 <danilo2> geekosaur: Are you still here ? 
08:03:35 <danilo2> :)
08:03:43 <geekosaur> yes
08:03:54 <danilo2> ok, so here it is: https://github.com/luna/dependent-state/tree/irc-testing
08:04:31 <danilo2> geekosaur: if you download it and run `stack build --stack-yaml stack-develop.yaml bench dependent-state:layered-state-benchmark`
08:04:43 <danilo2> geekosaur: then the test/bench/Main will be executed
08:06:09 <danilo2> geekosaur: if in the Control/Monad/State/Layered.hs file you change lines 90-107 (all the "put's") to pointfree, it is 40 times slower. If you paste there (.) definition, it gets fast again
08:06:42 <danilo2> geekosaur: by definition I mean: (.) :: (b -> c) -> (a -> b) -> a -> c; (.) f g = \x -> f (g x) ; {-# INLINE (.) #-}
08:09:19 <danilo2> geekosaur: anyway if you'll find 5 minutes time to check it out I would be thankfull as hell, because I feel dump seing whats happening here. 
08:09:26 <danilo2> *dumb
08:09:30 <Cale> danilo2: That's interesting. Sounds like cross module inlining isn't working or something.
08:09:37 <danilo2> Cale: exactly
08:10:10 <danilo2> Cale: please look at the flags I provide to stack: https://github.com/luna/dependent-state/blob/irc-testing/stack-develop.yaml
08:11:02 <danilo2> Cale: including -O2 and -funfolding-use-threshold=10000. In my opinion they should not even affect function that is marked INLINE, cause it should be inlined. However even if its not marked so, these flags should raise the cost treshold high enough
08:11:50 <danilo2> Cale: should I report is as a bug? Or am I missing something ?
08:12:16 <danilo2> Cale: few lines higher I told how you can execute it if you want to try it (jsut run: `stack build --stack-yaml stack-develop.yaml bench dependent-state:layered-state-benchmark`)
08:14:18 * hackagebot persistable-record 0.4.2.0 – Binding between SQL database values and haskell records. – https://hackage.haskell.org/package/persistable-record
08:21:43 <geekosaur> sigh primary nnetwork is being annoying here
08:26:32 <danilo2> geekosaur: I've posted all the links and instruction how to test it above (if youre interested in it) :)
08:31:46 <quchen> mpickering: Hmm?
08:32:18 <quchen> mpickering: With the position it was printed to? What does that mean? You want the output to be annotated with »this word is in line 5«?
08:33:03 <quchen> mpickering: That should be possible, yes – you’d have to write your own renderer that keeps track of how much was printed so far.
08:34:36 <quchen> mpickering: renderIO is a good example of how to write a renderer by hand, https://github.com/quchen/prettyprinter/blob/master/prettyprinter/src/Data/Text/Prettyprint/Doc/Render/Text.hs#L78
08:35:46 <quchen> mpickering: If you use some state to keep track of how many characters you’ve printed and how many newlines there were, you can render based on where you currently are.
08:37:20 <quchen> bollu: Did you find the issue with the ASM generator?
08:38:29 <ehubinette> For anyone interested, I have written a new blog post for my Summer of Haskell project, about how we can make linear monads and get them to play nice with functor, applicative and do-notation. https://m0ar.github.io/safe-streaming/2017/07/20/homegrown-linear-monads.html
08:38:55 <ehubinette> (hope it's OK to promote in here, I figured there may be some interest (: )
08:39:13 <c_wraith> ehubinette: definitely cool to promote it here
08:39:19 <ventonegro> ehubinette: definitely
08:40:00 <ehubinette> Well then I suggest you check out the earlier posts as well while you are at it!
08:40:19 <ehubinette> There is a linked reddit thread as well for potential questions and hopefully even answers
08:41:36 <ehubinette> The previous one is a 101 to linear types, and their relevance to making the streaming library safer. We can do this by disabling access to earlier stream states through linearity in the monad :) 
08:54:56 <ertes-w> ehubinette: is this haskell?  where does the linear arrow come from?
08:56:19 <c_wraith> ertes-w: it's a ghc extension that's currently in development.  ehubinette is one of the people working on it.
08:56:31 <ertes-w> we're really getting linear types?!
08:56:42 <c_wraith> yep
08:56:47 <ertes-w> wow, i'm excited =)
08:57:03 <ertes-w> i didn't think it would happen
08:57:06 <dolio> ehubinette: Some of those seem weirdly limited.
08:57:18 <mniip> is it planned to be merged into upstream?
08:57:48 <ertes-w> will it come with in-place update as well?
08:57:55 <ertes-w> or just a type safety feature?
08:57:58 <dolio> Like, why is LFunctor linear in the (linear) function?
08:58:34 <c_wraith> ertes-w: it's just an optional type-system feature.  You could of course build libraries around it that do in-place updates
08:58:37 <dolio> It kind of makes sense to have (a -o b) -> ([a] -o [b]), a functor between categories of linear maps.
08:58:49 <ertes-w> LFunctor should really be (a -o b) -> (f a -o f b), right?
08:58:52 <dolio> ([] being the functor.)
08:58:59 <ertes-w> yeah
08:59:21 <ertes-w> c_wraith: that's already a huge improvement…  i'm really excited now =)
08:59:44 <ertes-w> will it support uniqueness, too?
09:17:14 <dolio> Actually, maybe [] isn't a rich enough type to really say everything.
09:18:04 <dolio> Like, the interesting thing is that (a -o b) -> ([a] -o [b]) is kind of linear in the entire structure of the list.
09:19:05 <ehubinette> Well, the guys at Tweag I/O are working with Simon PJ and some other dudes on a retrofitted linear types solution, the GHC fork is here: https://github.com/tweag/ghc/tree/linear-types
09:19:14 <dolio> Every element and the whole spine.
09:19:24 <dolio> But it's not applicative in the same way.
09:19:30 <ehubinette> I'm working as an intern-ish in building a PoC (the streaming library), and helping them find and work on issues etc 
09:19:49 <ehubinette> ertes-w: mniip: 8.4 is the current GHC target
09:20:01 <dolio> I think it may be a monad, with pure :: a -o [a] and extend :: (a -o [b]) -> ([a] -o [b]) in the same sense as the functor.
09:20:04 <ertes-w> thanks
09:21:27 <ehubinette> ertes-w: No uniqueness, but you can model it with some linear continuation hacking :) 
09:21:46 <ehubinette> ertes-w: I explained this a bit in the 101-post, with further scrutiny here: https://www.reddit.com/r/haskell/comments/6ievrg/safe_streaming_with_linear_types_an_introduction/dj98aeu/?context=10000 
09:22:29 <ehubinette> how we can prevent aliasing with linear types that is, but it's not very pretty. Can probably be used internally for this tho (: 
09:24:45 <ehubinette> ertes-w: check the readme of the tweag/linear-types repo, I've written a guide there on how to use a pre-compiled version of the fork with stack+docker :)
09:25:10 <phadej> dolio: my gut feeling says that every current Functor would have (a -o b) -> (f a -o f b), informally "if you `f` some a, you better use it in the result too"
09:26:15 <dolio> I guess the monad I'm talking about is: MultList a ~= T (+) (a (x) MultList a)
09:26:23 <ehubinette> dolio: there may be other solutions than mine of course, but I have not gotten more expressive variants of LFunctor to play nice with LMonad & LApplicative. On its own, sure, but to fit in the class heriarchy: not so much 
09:27:15 <ehubinette> I wanted to preserve being able to use everything functor on all linear monads, and since I needed to constrain LMonad first (to solve my issues with streaming), those constraints bubbled back up to the applicative and functor
09:27:16 <dolio> ehubinette: Yeah, the ones you wrote down might be interesting, too. I guess that's the problem with modalities.
09:28:54 <ehubinette> but yes, I agree it's kinda crippled, but at least for streaming they inhabited enough \o/
09:32:26 <ehubinette> dolio: I do agree with your point, but again I have not gotten that to unify with the LMonad in a neat way :/
09:32:58 <ehubinette> This is also how I argue in the blog post; would be nice, but does not fit the heriarchy (but there are surely other ways to do that too)
09:33:02 <phadej> ehubinette: do you have data LState s a = LState { runLState :: s -o (a, s) }  examples somewher?
09:33:16 <ehubinette> phadej: locally :)
09:33:41 <phadej> can you have (->) versions of LFunctor for that?
09:33:53 <ehubinette> I'll be tinkering with it in the upcoming days, it's pretty tricky since you can't get a linear state
09:34:12 <phadej> ehubinette: "cannot get a linear state"?
09:34:40 <ehubinette> Like, if you have the state linear, you cant 'get' it, because the type get :: s -o (s,s) is broken
09:35:01 <ehubinette> But it's possible to get the unrestricted parts of the state, which is what I'm trying to get working neatly
09:35:02 <phadej> yeah, that's the point of LState, you can only modify :: (s -o s) -> m ()
09:35:08 <monochrom> I am skeptic about being linear about the "a". Looks like collateral damage.
09:36:16 <ehubinette> monochrom: in LMonad? Well since a ~ m a we can't allow an unrestricted continuation, because that enables free copying of the effects; the very thing I need to prevent
09:36:47 <monochrom> Oh, ah.
09:37:08 <ehubinette> yah, so that sucks. I tried to get it working the way you suggest for a while before I realised this :)
09:38:15 <mpickering> danilo2: What am I meant to be looking at with these instructions?
09:38:21 <mpickering> The line numbers don't seem to be right either
09:38:31 <mpickering> which benchmark is meant to be slow etc..
09:38:47 <phadej> is so that your monadic operations are -> m !a so you can reuse values multiple times, but the LMonad is linear
09:39:02 <phadej> your monadic operations could be *
09:42:03 <Zemyla> Hey everyone *hugs*
09:42:09 <Zemyla> Wait, wrong channel. :V
09:42:28 <MarcelineVQ> appreciated though
09:44:11 <ehubinette> phadej: Nah, we can do better than only modify. Apparently I nuked my code snippets on this in todays git cleanup reh, but you can wrap parts of the state in unrestricted contructors, this way you can allow free access to these values in the state, but the state _itself_ is linear
09:46:34 <ehubinette> phadej: something along these lines: https://gist.github.com/m0ar/8fe390fc68702381b5b217771a6e459a
09:46:48 <ehubinette> just a sketch but I think it would type check
09:48:11 <ehubinette> phadej: regarding the "m !a" thing I am not sure, I think we need to use unrestricted values (just strictness does not do much), which limits in the same way at non-linear arrows
09:48:24 <danilo2> mpickering: I updated it
09:48:30 <danilo2> mpickering: here is the description: https://ghc.haskell.org/trac/ghc/ticket/14001#comment:2
09:48:52 <ehubinette> But I'm too tired to dwell into that now, but hit me up if you'd like to discuss it some other day 
09:48:53 <danilo2> mpickering: sorry, I was sure nobody is looking at it now here
09:49:10 <danilo2> mpickering: is it clear enough now?
09:49:24 <ehubinette> Zemyla: naw, hugs <3 
09:49:29 <mpickering> tbh it is not a very good ticket as I had to write a cabal file as well and add loads of extensions to get it to compile
09:49:32 <mpickering> looking again..
09:58:17 <danilo2> mpickering: you do not have to. Just use `stack` command as described in the ticket
09:58:33 <danilo2> mpickering: cabal will be generated automatically. it is a complete, working example
09:59:46 <mpickering> "Compiler version mismatched, found ghc-8.2.0.20170507 (x86_64), but expected minor version match with ghc-8.0.2 (x86_64) (based on resolver setting in /Users/matt/Documents/haskell/dependent-state/stack-develop.yaml)." 
10:00:22 <mpickering> I also have ghc-8.0.2 in my path
10:00:32 <danilo2> mpickering: run `stack --stack-yaml stack-develop.yaml setup` and everything will be ok 
10:00:33 <danilo2> :)
10:01:21 <mpickering> No.. I don't want to download a 100mb binary 
10:01:52 <danilo2> if so, just export PATH in such wat that ghc 8.0.2 will be seen as ghc
10:02:03 <mpickering> anyway, I have compiled everything now and can run the benchmarks
10:02:12 <danilo2> mpickering: great!
10:02:22 <danilo2> mpickering: thanks for looking at it :)
10:02:23 <mpickering> There are lots of them, which ones should I look at?
10:02:25 <MarcelineVQ> can try   compiler: ghc-8.2.0.20170507   in your stack.yaml
10:03:01 <glguy> The current 8.2.1 rc is 8.2.0.20170704
10:03:09 <danilo2> mpickering: in fact everything shows the slowdown , especially these with names ending with 1R / 2R / 3R
10:03:18 <MarcelineVQ> might not be enough tho, I've not done that by itself
10:03:46 <danilo2> 1R is the single monad abowe state, 2R is 2-depth monad stack and so on
10:03:58 <MarcelineVQ> usually it's been with something else, like  source build  http://lpaste.net/357071
10:04:03 <mpickering> ok
10:04:15 <danilo2> mpickering: so you can break tests after the first 4 /6 outputs
10:04:32 <mpickering> I want to look at the core so want to only run one really
10:04:40 <danilo2> run the 3R
10:04:53 <mpickering> "3R trans (10e6)" "monad transformers overhead" will work?
10:05:09 <danilo2> `3R trans (10e6)` 
10:05:15 <danilo2> this one will be the best
10:07:24 <bollu> did anyone hear back from haskell implementors workshop?
10:07:29 <bollu> there's no info up on the website either
10:07:32 <bollu> but the deadline is DUE
10:07:33 <bollu> due*
10:14:55 <mpickering> danilo2: Are the line numbers right in the description?
10:25:50 <gargawel> Hi! This is puzzling me: why does the non-tail recursive implementation of filter in GHC.List blow the stack ?
10:26:22 <gargawel> *not blow the stack
10:28:18 <AndiK> gargawel: Can you link the code? But I assume it either allocates on the heap or gets optimized into tail recursion by the compiler.
10:29:11 <geekosaur> actually the notion of tail recursion is not defined the way you would expect from an imperative background
10:29:16 <cocreature> there is no callstack in Haskell
10:29:20 <mpickering> gargawel: See there is a RULE for filter, "filter"     [~1] forall p xs.  filter p xs = build (\c n -> foldr (filterFB c p) n xs)
10:29:23 <gargawel> AndiK: Yup. it's there. https://hackage.haskell.org/package/base-4.9.1.0/docs/src/GHC.List.html
10:29:37 <danilo2> mpickering: they shoudl be, brb I ll check it
10:29:38 <geekosaur> (*everything* is "tail recursive" in the procedural/imperative sense)
10:29:47 <gargawel> mpickering: Aha ! That makes sense.
10:29:57 <gargawel> geekosaur: that's cheating. :p
10:30:19 <danilo2> mpickering: yes, they are right
10:30:29 <mpickering> Which commit are you working from?
10:30:31 <cocreature> mpickering: even without the rule it wouldn’t blow the stack, no?
10:30:42 <danilo2> mpickering: is there any problem with them ?
10:31:13 <gargawel> Additional questsion: why isn't it written in tail-rec style ? If I had to guess, I would say it doesn't play well with fusion, but that's just an intuition.
10:31:18 <mpickering> ah, it's my fault because I had to add language pragmas to make it compile
10:31:18 <mpickering> sorry
10:31:44 <mpickering> cocreature: I don't know 
10:32:38 <danilo2> mpickering: no need to be sorry. Im thanful that you look at it. These pragmas are in stakc config. Next time I can upload it with generated cabal file, it will be easier for people not using stack
10:34:24 <cocreature> gargawel: 1. tail recursive implementations often don’t play well with lazyness (e.g. foldl doesn’t work with infinite lists) and 2. why would you do that? it shouldn’t be any faster in Haskell (for filter)
10:35:20 <mpickering> ok I can finally reproduce it now
10:35:23 <mpickering> 1ms vs 40ms
10:35:25 <cocreature> in fact you probably end up appending to the end of the list in a tail recursive implementation which would be even slower
10:35:49 <cocreature> or append to the front and reverse at the end which is still slower
10:36:10 <gargawel> cocreature: in fact I think I understand. you can do without appending but reversing, which would probably allocate the whole list.
10:36:28 <gargawel> so yeah, bad with laziness indeed.
10:38:25 <ReinH> The tail recursive version necessarily scrutinizes the entire spine of the list.
10:38:30 <ReinH> The foldr version does not.
10:38:32 <cocreature> in general if you can produce parts of your result immediately, that’s almost always preferable in a lazy language
10:38:39 <ReinH> Even without foldr/build fusion, the foldr version is superior.
10:38:43 <gargawel> ReinH: yes, that's what I meant.
10:38:59 <gargawel> Thanks guys :)
10:39:01 <ReinH> > take 10 . filter even $ [1..]
10:39:03 <lambdabot>  [2,4,6,8,10,12,14,16,18,20]
10:39:07 <ReinH> This works without fusion.
10:39:53 <ReinH> Being productive (via guarded recursion) is more important here, as cocreature says.
10:40:40 <gargawel> I see.
10:41:24 <ReinH> What fusion does is deforest the computation so that intermediate computations don't create extra lists just to consume them.
10:41:55 <Athas> Also, fusion is the optimisation with the coolest name.
10:42:16 <ReinH> Lazy evaluation is all that is needed for the above to only produce 20 elements of [1..]
10:42:31 <ReinH> The 21st element is never demanded.
10:42:53 <cocreature> Athas: and contrary to nuclear fusion we don’t even need to wait 50 years until we get to use it!
10:43:11 <ReinH> @src filter
10:43:12 <lambdabot> filter _ []     = []
10:43:12 <lambdabot> filter p (x:xs)
10:43:12 <lambdabot>     | p x       = x : filter p xs
10:43:12 <lambdabot>     | otherwise = filter p xs
10:43:27 <ReinH> What fusion does is prevent these (:) from constructing intermediate lists. They are fused away.
10:44:21 <ReinH> Well, whenever possible.
10:47:09 <Athas> cocreature: also, it works at room temperatures (unless your machine is overclocked)!
10:47:35 <danilo2> mpickering: I'm happy that you reproduce it
10:53:25 <tabaqui> how can I use quantification with type multiplication?
10:53:27 <tabaqui> like 
10:53:40 <tabaqui> data Foo = forall a, forall b . (Show a, Ord b) => Foo a b
10:54:22 <tabaqui> I get syntax error with any "forall" combination, and don't see answer on "Language options" page
10:54:32 <geekosaur> forall a b.
10:54:51 <tabaqui> it works, thanks
10:55:04 <cocreature> whether that existential is actually what you want is another question :)
10:56:46 <tabaqui> it is not related to multiplication, yeah
11:00:08 <tabaqui> maybe you know?
11:00:23 <tabaqui> is there any special word for structure like treap?
11:00:30 <tabaqui> more precisely:
11:01:02 <tabaqui> double indexed structure with fast search/insert/delete by any first index
11:01:16 <tabaqui> and with fast searching for the smallest by second index
11:01:37 <dolio> Priority search queue?
11:02:04 <tabaqui> dunno, there is such term in English
11:02:06 <tabaqui> ?
11:02:15 <dolio> Yes, that is a think people talk about.
11:03:24 <tabaqui> oh, someone has written psqueues supported these operations
11:11:05 <shubham> Hi all
11:13:21 <shubham> Hello
11:14:23 <shubham> I am beginner to Haskell. I am facing problem for importing Data.List  
11:15:38 <lyxia> shubham: what problem
11:16:13 <shubham> lyxia : I am using stack
11:16:45 <glguy> That's easy to fix
11:16:53 <cocreature> while some might claim that this is a problem, in general it isn’t :)
11:17:02 <shubham> lyxia : I am unable to import Data.List
11:17:16 <tabaqui> stack uses cabal
11:17:27 <cocreature> shubham: you need to be a bit more specific. what exactly are you running and what is the exact error message you’re seeing?
11:17:34 <tabaqui> you should check that stack finds correctly your project .cabal file
11:18:02 <glguy> Let's wait until we see the input and error messages before guessing too much
11:18:32 <tabaqui> and anyway, data.list belongs to base, so you haven't to import smth
11:18:37 <shubham> module Lib     where  import Data.List
11:18:38 <tabaqui> *anyth
11:18:53 <shubham> this is my header
11:19:00 <glguy> shubham: You can paste the code and error messages to lpaste.net
11:19:28 <shubham> Lib.hs:67:12: error: parse error on input ‘where’
11:19:32 <shubham> this is Error
11:19:58 <glguy> OK, now paste all the code to lpaste.net and the whole error message
11:20:17 <glguy> Lib.hs:67:12: tells you the file, line and column
11:20:40 <glguy> but you won't need to pare down the paste to just that character
11:20:58 <monochrom> Yes! Why not! :)
11:22:28 <shubham> glguy : http://lpaste.net/357075
11:22:32 <monochrom> Any sufficiently advanced and experienced expertise is indistinguishable from ESP.
11:22:54 <cocreature> shubham: that file doesn’t even have a line 67 so I’m pretty sure you are not showing us everything here
11:23:44 <shubham> concreature : I put there only headers of file. should I put whole code? Ok
11:24:01 <cocreature> shubham: well the error is in line 67 so we are going to need to see that line
11:24:02 <monochrom> is why beginners think that we are telepathic
11:24:10 <cocreature> but it might be related to other stuff so just show us everything
11:24:13 <monochrom> and why end-users think that we know their passwords
11:25:20 <Tuplanolla> They learn this expectation from proprietary software that installs rootkits on their machines.
11:25:51 <shubham> concreature : http://lpaste.net/357076
11:26:05 <shubham> glguy : http://lpaste.net/357076
11:26:30 <tabaqui> shubham: you didn't define what MakeBox actually do
11:26:40 <cocreature> shubham: you are missing the actual definition of makeBox, you are defining things in a where clause but you are not defining what the result of makeBox should be
11:26:55 <monochrom> Perhaps we should start requiring askers to install our rootkits.
11:27:31 <cocreature> a rootkit that posts the code that people are asking about to lpaste would save a lot of time for the people trying to answer questions :)
11:27:59 <tabaqui> you can create fake Prelude with all necessary backdoors
11:28:06 <shubham> concreature : ohh.. sorry for my small misteak
11:28:14 <tabaqui> and with mess of *haskell* code
11:28:16 <monochrom> Also there are cabal and stack problems that require digging deep into their disks and their .bashrc's to troubleshoot.
11:28:39 <tabaqui> so any new haskell programmer doesn't notice the trick
11:28:40 <Tuplanolla> Finally a reason to use the package name `prelewd`!
11:29:01 <shubham> concreature : thank you . It is working
11:41:49 <max3> if i want to pass flags to configure does this mean the devel flag is on? ./configure -f devel?
11:41:50 <max3> or this
11:41:53 <max3> ./configure -f -devel
11:51:56 <srhb> max3: Often yes. depends on the script though. What is it?
11:52:13 <max3> srhb, yes which? first or second
11:53:03 <srhb> max3: Honestly, both are possible, though I see the first quite often. Again, it depends on the script. If you can point us at it, we can try to determine it. Usually Haskell programs don't ship with one.
11:53:09 <max3> https://github.com/databrary/databrary/blob/master/databrary.cabal
11:53:35 <srhb> Oh, cabal configure?
11:54:55 <srhb> max3: The readme says: if you want turn on the development flag (which does various things - search this repo for DEVEL) then you can run cabal configure -- -f devel
11:55:10 <max3> that's my read me
11:55:15 <max3> it's actively being changed by me
11:55:21 <max3> it used to say pass -- -f -devel
11:55:29 <max3> because i assumed the sane thing
11:55:53 <max3> test in bash this line https://github.com/databrary/databrary/blob/master/dev#L13
11:56:14 <max3> says passing -p turns on the - in front of devel (-p for production)
11:57:41 <srhb> max3: The cabal manual is unusually dense on this topic...
11:57:53 <max3> lol
11:58:09 <srhb> max3: Actually I would assume that -- goes before anything passed on directly to ghc, so that shouldn't be it I guess
11:58:15 <max3> s/cabal/*Haskell*/g
11:58:36 <max3> um
11:58:37 <srhb> Oh, no, that's --ghc-options. Snarf. I don't know.
11:58:58 <max3> i have no clue
11:59:28 <max3> setup is part of ghc isn't it?
11:59:58 <srhb> cabal configure -f devel should be right
12:01:01 <max3> how can i tell if it worked without running the app and recognizing that the right #ifdefs fired
12:01:28 <srhb> max3: Give it an erroneous ghc option or something?
12:01:47 <max3> don't understand
12:02:29 <max3> what does --user do?
12:03:37 <srhb> max3: if flag(debug) ghc-options: -this-causes-a-build-error
12:03:45 <max3> ah
12:04:14 <srhb> max3: Works for me.
12:04:31 <max3> lemme see
12:08:10 <vimalloc> If liftA or liftM would both work, is there one that should be preferred to be used.
12:08:43 <srhb> vimalloc: I tend to go with functor before applicative before monad.
12:08:51 <Tuplanolla> Yeah, `fmap`, vimalloc.
12:09:09 <vimalloc> It was actually a liftA2 I'm using. Can that be done with fmap?
12:09:23 * vimalloc should figure that out actually
12:09:28 <vimalloc> good learning experience probably
12:09:51 <srhb> vimalloc: <$> and <*>, so applicative.
12:09:59 <srhb> Oops, sorry.
12:10:12 <vimalloc> You're good, I was just trying that exact thing before you said it
12:10:18 <vimalloc> good to know i'm on the right track :)
12:10:29 <srhb> vimalloc: At that point it just becomes a matter of style. :)
12:10:30 <Tuplanolla> It's good to always pick the narrowest interface, vimalloc.
12:10:35 <Tuplanolla> This isn't specific to Haskell either.
12:10:55 <vimalloc> That makes sense
12:12:36 <vimalloc> To make sure I have this down, comparing `(:) <$> thing1 <*> thing2` to `liftA2 (:) thing1 thing2`, they are both applicatives (due to <*>) and so are basically equilivant, right?
12:12:59 <Tuplanolla> @src liftA2
12:12:59 <lambdabot> liftA2 f a b = f <$> a <*> b
12:13:08 <vimalloc> awesome :)
12:13:15 <vimalloc> Thanks everyone
12:13:41 <Tuplanolla> There's a nice connection here.
12:13:48 <mpickering> danilo2: I think I found the problem
12:15:07 <Tuplanolla> Applicative is a generalization of functor in the following sense: if functors lift with arity 1, applicatives lift with arities from 0 to infinity.
12:15:59 <Tuplanolla> See if you can guess what `liftA0` would look like.
12:16:52 <danilo2> mpickering: really ? Oh thats great!
12:16:54 <danilo2> what is it?
12:17:04 <danilo2> mpickering: I have to learn how to debug core btw
12:17:11 <mpickering> You (.) you defined is different to the one in base
12:17:16 <danilo2> this is on my todolist for ages but I need to do it soon
12:17:30 <mpickering> I didn't get far with looking at the core, it was quite big so I was reducing and realised 
12:17:34 <vimalloc> Tuplanolla: would it basically be id? `liftA0 a = a` 
12:17:36 <danilo2> mpickering: I'm almost sure I copied it from base
12:17:45 <mpickering> It is, but you have Strict enabled :P
12:18:00 <danilo2> mpickering: oh my god
12:18:47 <Tuplanolla> Not quite, vimalloc.
12:19:30 <danilo2> mpickering: that's insane. 
12:19:56 <mpickering> If you add a bang to the x parameter then you get the same performance without Strict
12:22:03 <danilo2> mpickering: I'm so thankful that you investigated it. How can I repay you for that? I was sitting scrathcing my head whats going on for the last day until I asked about it here. By the way - why it gives such performance boost? should we use strict implementation by default ?
12:22:48 <mpickering> I don't know exactly, still trying to reduce it down
12:23:11 <mpickering> Making (.) stricter would possibly break a lot of programs 
12:23:44 <EvanR> does builder use a strict (.) ?
12:24:06 <Tuplanolla> Would you like a hint, vimalloc?
12:24:35 <danilo2> mpickering: I have to go offline for 30mins, I;ll be bck then (just fyi)
12:25:01 <vimalloc> Yes please :) My current thought is the function still has to be there, but if it was wouldn't it just be an fmap, which is liftA1?
12:25:21 <Tuplanolla> :t liftA2
12:25:21 <Tuplanolla> :t liftA1
12:25:21 <Tuplanolla> :t liftA0
12:25:24 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
12:25:24 <lambdabot> Applicative f => a -> f a
12:25:24 <lambdabot> Functor f => (a -> b) -> f a -> f b
12:25:39 <phadej> they came in wront order :P
12:25:52 <Tuplanolla> One also has `Functor` as a constraint. Oh well.
12:27:03 <vimalloc> OH
12:27:12 <Tuplanolla> Does it look familiar?
12:27:16 <vimalloc> it wouls basically be 'pure' or 'return' wouldn't it? Just wrap it in the 'box'
12:27:26 <Tuplanolla> Indeed.
12:27:29 <vimalloc> Yay! 
12:27:37 <vimalloc> Thanks Tuplanolla :)
12:28:22 <wuschel> Hi, is there an alternative to elm in Haskell that spits out small and fast compiled target files?
12:28:35 <wuschel> It seems there is GHCJS, and Miso. 
12:28:39 <wuschel> Any experience with them?
12:29:17 <Tuplanolla> If you're feeling adventurous, there's another way to motivate applicative too, vimalloc.
12:30:13 <vimalloc> Tuplanolla: Do tell. I feel like have a basic understanding of functors/applicatives/monads, but the knowledge hasn't really 'solidified' if that makes sense. 
12:30:22 <vimalloc> the more I can dig into this the better I'll be I think
12:30:50 <mizu_no_oto> wuchel: There's also Purescript, though like Elm it's a language that's similar to Haskell.
12:30:52 <Tuplanolla> First implement `unit :: Applicative f => f ()` and `zipA :: Applicative f => (f a, f b) -> f (a, b)` in terms of `pure` and `<*>`. Then do the same thing in reverse. This shows that these formulations are equivalent.
12:31:06 <mizu_no_oto> ^ wuschel, rather
12:31:18 <vimalloc> Tuplanolla: I'll give that a shot, thanks :)
12:31:20 <Tuplanolla> That's sometimes useful.
12:31:42 <Tuplanolla> In terms of practical use, that is.
12:32:06 <EvanR> im kind of... well fully confused by this: http://lpaste.net/357077
12:32:06 <wuschel> mizu_no_oto: Thanks. What packge would you recommend to start with? I can't get Elm to install under my Xubuntu systems (seems to be an npm problem), and I would like to experiment a bit with functional front end programming.
12:32:15 <EvanR> i tried to make a "strict ." but it doesnt seem to work
12:33:03 <mizu_no_oto> ^ wuschel: what sorts of things do you care about?  For example, do you care about the readability of the generated JS?
12:34:10 <wuschel> mizu_no_oto: No, actually, I mostly care that the stuff 1) works and 2) is perhaps a bit battle proven. 
12:34:21 <mizu_no_oto> How much experience do you have in general with FP?
12:34:42 <wuschel> Just working through a beginner Haskell book and wanted to fool around a bit. 
12:35:03 <wuschel> As a break, so to say. I am a beginner Schemer, though (50% SICP).
12:36:24 <monochrom> EvanR: May I rename your (.) to o? It will be easier to talk about. You have "o = (three parameter function)" and you're only using it as "!f = o undefined undefined". which is \x -> seq undefined (seq undefined (...
12:36:41 <wuschel> mizu_no_oto ^
12:37:52 <mizu_no_oto> I've heard some good things about reflex (https://github.com/reflex-frp/reflex-platform) with ghcjs, though I've not used it myself.  http://purescript-pux.org/ is pretty nice in Purescript.
12:38:29 <mizu_no_oto> Though purescript is definitely much less mature than ghc is.
12:38:39 <cocreature> what I don’t get is why "!f . !g = \x -> f (g x)" is also not bottom for "undefined . undefined"
12:39:03 <wuschel> mizu_no_oto - thank you for the suggestion. I will have a look. :^)
12:39:12 <monochrom> Oh, that one I can't explain :)
12:39:35 <cocreature> I thought I understood the problem in EvanR’s version but then I tried the one I just showed and now I’m just confused :/
12:39:47 <jared-w> cocreature: is . slightly magic or something?
12:40:02 <monochrom> OMG it's true!
12:40:18 <monochrom> Now I have to read the user's guide for real.
12:41:27 <cocreature> jared-w: no I tried other symbols
12:41:52 <cocreature> even "f . g = seq f (seq g (\x -> f (g x)))" doesn’t work
12:41:58 <cocreature> I’m clearly missing something here
12:42:26 <phadej> cocreature: it is?
12:42:28 <phadej> > let o f g = \x -> f (g x) in (o undefined undefined) `seq` ()
12:42:30 <lambdabot>  ()
12:42:34 <phadej> > let o !f !g = \x -> f (g x) in (o undefined undefined) `seq` ()
12:42:36 <lambdabot>  *Exception: Prelude.undefined
12:42:46 <cocreature> wait what, where did I screw up oO
12:42:59 <jared-w> Not enough bang annotations I think?
12:43:46 <cocreature> huh, ghci is behaving weirdly
12:44:38 <cocreature> if I define it in a single let it breaks, if I first define "let (...) !f !g = seq f (seq g (\x -> f (g x)))" and then run "seq (undefined ... undefined) ()" it doesn’t break
12:44:49 <dolio> cocreature: How did you get that to parse?
12:44:53 <monochrom> Yeah.
12:45:12 <cocreature> dolio: huh? I just typed it in ghci
12:45:20 <dolio> !f . !g = \x -> f (g x)?
12:45:40 <cocreature> no literally the two lines I just showed in quotes
12:45:56 <dolio> Oh, okay.
12:46:50 <ghci> try doing let > let f . g = map(\x -> f ( g x ))
12:47:10 <cocreature> wow ghci can talk
12:48:45 <monochrom> This is gay. "o !f !g = \x -> f (g x)". If I enter that into ghci by hand, then "o undefined undefined `seq` 5" is 5. If I put that into a file and :load, then "o undefined undefined `seq` 5" is an error.
12:49:49 <[exa]> interpreters.
12:50:27 <monochrom> It happens to "p f g = seq f (seq g (\x -> f (g x)))" too
12:50:29 <koala_man> doesn't sound happy at all
12:50:44 <Tuplanolla> Should I start sweating now?
12:51:01 <monochrom> GHC 8.0.2
12:51:15 <monochrom> Oh, one last thing.
12:51:41 <monochrom> At the ghci prompt, no difference between "p f g = seq f (seq g (\x -> f (g x)))" and "let p f g = seq f (seq g (\x -> f (g x)))"
12:52:31 <cocreature> hm I was trying to figure out the difference between putting the x at the left of the equal sign and at the right by looking at core but I can’t spot the difference. any ideas http://lpaste.net/357079 ?
12:53:23 <cocreature> it looks like the x is always left of the case statments
12:54:37 <dolio> ghc 7.6 doesn't work this way.
12:54:46 <Unicorn_Princess> I'd like to render sprites, text boxes, menus, handle user input, as well as play simple sounds, for a 2D game I'll use to experiment on. what libraries do you reccommend? Helm? I took a look at https://wiki.haskell.org/Applications_and_libraries/GUI_libraries and https://wiki.haskell.org/Game_Development but really can't decide
12:55:18 <dolio> Starts in 7.10.
12:55:41 <lamefun> What's the best solution to the module dilemma? http://lpaste.net/2546856129820884992
12:55:51 <Unicorn_Princess> I'm not looking for a whole 'game engine', at least not one I can't just take the gui/graphics/sound parts in isolation and ignore the rest, tho, since I want to experiment with different architectures, not conform to how an engine wants me to write
12:56:10 <Unicorn_Princess> be back later, but I'll read everyting
12:56:12 <geekosaur> cocreature, I have a vague recollection of something along those lines changes around then
12:56:19 <mpickering> cocreature: If you add INLINE pragmas then what do the unfoldings look like?
12:56:21 <geekosaur> not very helpful I guess
12:56:45 <monochrom> cocreature: Haha you know what I get? ".... = ..."
12:58:15 <lamefun> Is CPP the only solution?
12:58:27 <cocreature> mpickering: is there some special option that I need to pass after adding the INLINE pragmas to see the unfoldings?
12:59:13 <mpickering> -O
13:01:00 <dolio> Why does it happen in ghci -O0, though?
13:01:06 <dolio> Is it still doing eta expansion there?
13:02:05 <mpickering> It appears to be
13:02:20 <cocreature> mpickering: http://lpaste.net/357080 sat-args is different so I guess that makes sense now
13:02:57 <EvanR> cocreature: i am similarly confused
13:03:50 <cocreature> EvanR: well the good news is that outside of ghci it behaves as I would expect it, i.e., putting the x on the left means that f and g won’t be forced while putting it on the right forces them
13:03:54 <cocreature> ghci is just weird
13:04:01 <EvanR> interesting
13:04:29 <dolio> So it only occurs in ghci?
13:05:18 <cocreature> it seems to only occur when defining it in ghci as a standalone definition (via a let or using the new stuff where you can omit the let), when you just call it after loading it from a file in ghci it works fine
13:05:27 <cocreature> and using let + in also seems to work as you would expect
13:05:44 <dolio> Weird.
13:05:44 <EvanR> silly ghci
13:06:54 <cocreature> and whether you use bang patterns or seq makes no difference
13:07:09 <EvanR> "your interactive intepreter behaves differently from your compiled code upon both your houses"
13:07:25 <cocreature> so it’s not just doing something weird when desugaring bang patterns when defining things in ghci
13:07:44 <cocreature> *starts opening issue*
13:12:26 <max3> in `\ (<>) a b c -> a <> a <> b <> c` is the <> a lambda parameter?
13:12:47 <byorgey> max3: yes
13:13:04 <max3> that's cute
13:13:19 <byorgey> > ( \ (<>) a b c -> a <> a <> b <> c)  (+) 1 3 4    -- this is   1 + 1 + 3 + 4
13:13:21 <lambdabot>  9
13:14:25 <geekosaur> you know that thing where you an turn an operator into a function by wrapping it in parens? it's just that. it works generally, not just as function application syntax
13:15:38 <max3> so () is an operator then?
13:16:19 <cocreature> in case anyone wants to follow potential discussions, here’s the issue I just opened https://ghc.haskell.org/trac/ghc/ticket/14002
13:17:27 <EvanR> cocreature: nice
13:17:35 <geekosaur> er?
13:17:46 <geekosaur> > (+) 1 2 -- this
13:17:49 <lambdabot>  3
13:18:00 <geekosaur> turning operator + into a function
13:19:02 <geekosaur> or more generally,  () around an operator-syntax identifier makes it non-operator syntax, and `` around a non-operator-syntax identifier makes it operator syntax
13:20:04 <EvanR> y `f x` z though...
13:20:31 <glguy> :q
13:24:40 <trigone> hi, i'm wondering why haskell does not allow two functions with the same name in the same module provided they have different types. it would help terseness wouldn't it?
13:26:25 <bitonic> trigone: type-directed resolution is not so obvious
13:26:37 <geekosaur> because then you lose type inference, or at least it gets a lot messier
13:26:40 <bitonic> in haskell there is the expectations of very strong type inference
13:26:42 <geekosaur> and unreliable
13:27:10 <c_wraith> it's really nice for every expression to have exactly one most general type. 
13:27:29 <wayne> trigone: typeclasses may provide the functionality you want in a safer way
13:28:08 <c_wraith> some extensions give that up already, and they can make things awkward by doing so. (*cough* GADTs *cough*) 
13:28:16 <trigone> is it really unsafe if it just can't compile in case the type cannot be inferred, after which you can just add some type signatures here or there?
13:28:43 <trigone> i was just wondering
13:29:15 <c_wraith> trigone, enable overloaded record fields and see how painful the lack of inference can get. 
13:29:22 <wayne> trigone: how would you infer the type of an overloaded function?
13:29:40 <wayne> i don't think the current type system would be able to give one definition
13:30:00 <trigone> wayne: well i'd hope that one of its arguments would resolve nicely. yes maybe it's not possible i don't know
13:35:18 <monochrom> Class methods are already in this situation. Except a lot more tidy because an error message can just remind you of the class name, rather than doing the Java thing which is to list all 1 million known variations just to prove to you "I can't find what you want".
13:36:00 <monochrom> People really love overloading because of their background and habit from other languages.
13:36:08 <monochrom> Sometimes I love it too.
13:36:56 <monochrom> But an error message or two, from those other languages which don't organize their overloadings into type classes, reminds me why it is bad intuition afterall.
13:37:16 <trigone> monochrom: well i'm wary of using typeclasses when the semantics is wrong. it's just sometimes i'd love to not have to imply the types of arguments in the function name, and just put a small name that makes sense in the context of application...
13:37:18 <dolio> It's nice with type classes, as long as you don't do something super ad-hoc, which you still can.
13:37:29 <dolio> But otherwise I don't think it's too great.
13:37:41 <trigone> monochrom: i suppose :)
13:37:48 <trigone> dolio: super ad-hoc?
13:37:52 <Tuplanolla> Overloading is great when you don't have polymorphism or type inference.
13:38:09 <dolio> class CouldBeAnything t where operation :: t
13:38:12 <monochrom> Basically if you never make mistakes, there are a lot of programming language advancements we can do here-and-now.
13:38:27 <monochrom> For example, suppose you never make mistakes, then you don't need types...
13:38:27 <dolio> Then fill in a ton of arbitrary types for however you want to overload operation.
13:38:47 <trigone> dolio: ha yeah i see ^^
13:39:41 <dolio> There are other ways to be really ad-hoc.
13:39:57 <trigone> monochrom: yeah well i do make mistakes
13:39:58 <dolio> Like, you can encode C-like arithmetic type promotion in classes.
13:40:07 <dolio> But I don't think it's actually a good idea.
13:40:17 <trigone> dolio: what's that?
13:40:36 <dolio> Like Int + Int :: Int, Int + Double :: Double, etc.
13:41:43 <Tuplanolla> What would you expect `(-42 :: Int8) < (13 :: Word8)` to produce, trigone?
13:41:51 <trigone> monochrom: hm i see... i think at least
13:42:06 <monochrom> For the special case of "two record types clashing field names", I would go for row polymorphism.
13:42:26 <trigone> Tuplanolla: no idea, does it even work? i'm not familiar anymore with the low level numer types
13:42:41 <trigone> row polymorphism?
13:42:43 <Tuplanolla> It does, unfortunately, trigone. Not in my code though.
13:43:04 <trigone> :t (<)
13:43:06 <lambdabot> Ord a => a -> a -> Bool
13:43:19 <trigone> Tuplanolla: aren't both types supposed to be identical?
13:43:37 <Tuplanolla> Yes, but we were talking about C-like promotion here, trigone.
13:43:55 <trigone> > (maxBound :: Int8) == (maxBound :: Word8)
13:43:58 <lambdabot>  error:
13:43:58 <lambdabot>      • Couldn't match expected type ‘Int8’ with actual type ‘Word8’
13:43:58 <lambdabot>      • In the second argument of ‘(==)’, namely ‘(maxBound :: Word8)’
13:44:25 <Tuplanolla> With such rules, it would be promoted to `((256 - 42) :: Word8) < (13 :: Word8)`, which would then evaluate to `False`.
13:44:27 <trigone> Tuplanolla: oh i see. would that require a typeclass with two parameters?
13:45:01 <trigone> Ord a b => a -> b -> Bool ?
13:46:09 <dolio> Things like that also tend to make inference worse.
13:46:19 <dolio> Which was already mentioned.
13:46:39 <dolio> Because now knowing that you're comparing two things doesn't tell you they're the same type.
13:46:54 <EvanR> "do what i mean" wins over "do what i say" when do-what-i-mean has a unique solution
13:47:09 <trigone> dolio: yes, everything is harder to deduce
13:47:19 <dolio> So 'x < 5' is ambiguous. 5 could be defaulted, hopefully to a type that makes sense for what you wanted.
13:47:36 <trigone> EvanR: ?
13:47:59 <trigone> dolio: yes i understand
13:50:38 <trigone> EvanR: i didn't get what you meant
13:51:08 <EvanR> do what i mean gets a bad rap especially when it doesnt do what you mean, because its too stupid
13:51:28 <EvanR> type classes avoid this by having a unique solution
13:52:24 <millew> does anyone know of any other higher-order functional programming languages other than haskell?
13:52:50 <hexagoxel> cocreature: you can simplify #14002 to » let func f = seq f f «
13:52:58 <XorSwap> millew: ocaml?
13:53:12 <EvanR> javascript?
13:53:20 <Tuplanolla> Does Clojure count, millew?
13:53:23 <hexagoxel> cocreature: i.e. that one has the same behaviour
13:54:03 <millew> thank you, xorswap, tuplanolla
13:54:39 <EvanR> what are examples of functional programming languages that are "not higher order" ?
13:54:56 <dolio> EvanR: Does it have proper tail calls yet? I don't think we can allow it until then.
13:55:37 <EvanR> agreed... but thats not really clarifying the topic
13:55:40 <mclark1129> dolio: I now have the mental image of Gandalf shouting "YOU SHALL NOT PASS!"
13:55:47 <iqubic> Hello folks
13:56:49 <XorSwap> EvanR: forth?
13:57:03 <tdammers> clojure doesn't count, it's only semi-functional
13:57:16 <iqubic> What are we talking about?
13:57:32 <XorSwap> shoot, what even defines a functional language besides the general feel of it?
13:58:09 <dolio> viml
13:58:14 <Tuplanolla> Not being dysfunctional, XorSwap?
13:58:27 <EvanR> i dont care, what is "higher order" ?
13:58:42 <XorSwap> EvanR: functions as first class values, I'd assume
13:58:47 <tdammers> XorSwap: highly debated topic, but it usually amounts to one of two definitions: a) a language that has functions, which means Haskell, PureScript, and Idris are in, but OCaml, Clojure, Common Lisp, Scheme, JS, etc, are out
13:58:48 <dolio> Greater than first-order. :)
13:59:04 <iqubic> Higher order means accepts functions as inputs and returns functions as outputs
13:59:13 <EvanR> XorSwap: when i did that, javascript was suddenly ejected, disproving that hpyothesis :)
13:59:15 <tdammers> or b) a language that somehow supports a functional programming style in some vague sense
13:59:20 <hexagoxel> cocreature: i might have been confused in my above statement (sorry)
13:59:41 <XorSwap> well, JS can sort of be made functional by force if you want
13:59:41 <tdammers> higher-order functions are a pretty trivial feature
13:59:52 <bitonic> trigone: if you want to play with a language that does type-directed resolution + subtyping + a hindley-milnerish type system, try scala. you'll understand why it's a bad idea
13:59:53 <tdammers> by that logic, even Java is a functional language
13:59:53 <EvanR> XorSwap: "higher order"
14:00:11 <EvanR> tdammers: right, which is why the question seems sort of nonsense
14:00:35 <EvanR> lexical scope is kind of non trivial, and js managed to pull that one off
14:00:35 <trigone> bitonic: maybe someday but honestly i believe you on the word. and i'm not really attracted to scala from what i heard. java, bleh
14:00:53 <tdammers> EvanR: this is why I think the only sensible definition of "functional programming language" is the one that is equivalent to "pure functional programming language"
14:01:03 <EvanR> no true functional language
14:01:16 <trigone> EvanR: i still did not get your mean vs say thingy. can you repeat without metaphors, or with example?
14:01:19 <EvanR> ah... lets invent a new category "true functional programming language"
14:01:30 <tdammers> although I'm willing to bend a little and accept languages in which you can write procedures and functions, but at least such that you can tell the compiler what is what, and doing it wrong is an error
14:02:04 <Tuplanolla> So... GNU C, tdammers?
14:02:07 * geekosaur smells a new bikeshed and a herd of oncoming painters...
14:02:08 <EvanR> trigone: ... apparently its approaching 100F in here, so i have to leave for now
14:02:13 <dolio> How about if I ban all the people conducting this pointless conversation after the original questioner has already said "thank you"? :)
14:02:17 <EvanR> but the idea was not that complicated
14:02:30 <trigone> what's that in celcius?
14:02:31 <tdammers> Tuplanolla: how so? Do they have functions in C now?
14:02:36 <XorSwap> you can write lazy functional programs in C, gimme a sec to find it
14:02:42 <EvanR> 40C or something
14:02:51 <Tuplanolla> They have `__attribute__ ((__pure__))` for that, tdammers.
14:02:57 <trigone> EvanR: well could be worse
14:03:08 <tdammers> Tuplanolla: oh, cool... in a strange painful way...
14:03:13 <trigone> EvanR: but ok nvermind
14:03:14 <AndiK> Is there a way to make auto complete for auto generated lenses work with ghc-mod?
14:03:34 <mclark1129> Maybe a better question would be, are there any other languages that can abstract over typeclasses?
14:04:00 <XorSwap> ok here http://www.ioccc.org/2013/endoh1/endoh1.c
14:04:04 <trigone> geekosaur: lol the bikeshed paradox is probably the truest informal theorem ever found
14:04:16 <XorSwap> #include that at the beginning and end, and you can program in SKI calculus
14:04:27 <tdammers> mclark1129: there's PureScript, obv, which is extremely similar to Haskell with a bunch of GHC extensions enabled by default
14:04:33 <dolio> Every other language that has type classes is almost Haskell.
14:04:44 <dolio> To my knowledge.
14:04:47 <geekosaur> curry, which is more or less haskell reimagined as a logic language
14:05:13 <trigone> are typeclasses really unique to haskell? how do other similar languages do ad-hoc polymorphism, esp monads, etc?
14:05:25 <iqubic> Monads are wonderful
14:05:42 <tdammers> in some sense, dependently typed languages like Idris might be considered - no typeclasses, but you can fill the same niche and then some with higher-order types
14:05:46 <XorSwap> huh, could you do monads in Python?
14:05:51 <geekosaur> mostly they don't. most examples of monads in other languages are painful and inflexible.
14:06:09 <tdammers> XorSwap: yes, of course, it's just terribly clumsy, verbose, and boils down to an honor system due to the lack of types
14:06:09 <XorSwap> I imagine that might help for more procedural programmers to understand
14:06:09 <dolio> There are many languages that have things that are similar to type classes, and might even be called "type classes" by the language, but they aren't Haskell's type classes in essential ways.
14:06:41 <trigone> dolio: are there better systems? not that i have trouble with haskell classes
14:06:47 <tdammers> XorSwap: and no, it doesn't help at all, because it'll be so clumsy and the syntax will be so awkward that nobody in their right minds will even consider the idea that this may be something worth looking into
14:07:03 <XorSwap> ah
14:07:09 <ystael> I have used monads in Clojure. It wasn't a good idea.
14:07:22 <dolio> Well, I don't think they're better. I guess many people do, though, because they break from type classes in the same way.
14:07:39 <tdammers> indeed; even in Clojure, which touts itself as "functional", Haskell-style abstractions tend to lead to disappointment
14:08:48 <trigone> dolio: break from type classes in the same way?
14:09:11 <ystael> tdammers: I wanted, more or less, a combination of ExceptT, StateT, and IO. I got it, basically, but the price was the stack traces were even more godawful than Clojure's standard.
14:09:23 <dolio> trigone: So, one of the essential parts of type classes is that there is exactly one instance for any choice of types.
14:09:31 <dolio> Or, not exactly. At most.
14:10:05 <dolio> So you don't have to worry about the implicitly resolved stuff being different in different contexts.
14:10:17 <dolio> Most other languages with similar systems throw that out.
14:10:44 <trigone> dolio: so, they use the system but without the safety on?
14:11:01 <dolio> And certain designs using type classes do not work when you get rid of that.
14:11:21 <Tuplanolla> Hey, dmwit. I just noticed that the `wrap` function we discussed on 2017-05-22 was wrong.
14:12:19 <iqubic> Tuplanolla: that's not a date that has passed for me.
14:12:37 <Tuplanolla> There are two lines in the three-dimensional domain where it produces an incorrect result.
14:13:17 <trigone> it's incredible how much haskell is truly irreplaceable. you can find five or six OO languages with similar speeds and functionalities but you can't find two haskell-fast and safe functional languages, it seems...
14:13:31 <dolio> trigone: Well, in some situations it's not a matter of safety. But there are some things you can build where the property of type classes make things safe (so to speak) that otherwise wouldn't be.
14:13:39 <mclark1129> iqubic: What timezone are you in that hasn't had May 22, 2017?
14:14:44 <trigone> mclark1129: lol, it's not such a small world after all.. unless we finally contacted another planet via IRC
14:14:56 <iqubic> mclark1129: I'm stupid I thought July was month 5
14:15:02 <iqubic> I feel stupid
14:15:14 <boj> ah, so not some country ahead of new zealand. ok :)
14:15:20 <monochrom> mclark1129: Perhaps a small country that finally switched from the Julian calendar to Gregorian very recently :)
14:16:08 <trigone> i wonder if israel has some special calendar, i heard they had one before the christian one (obviously)
14:17:01 <EvanR> trigone: do-what-i-say and do-what-i-mean are two olde schoole "philosophies" of user interface. either you need to be explicit about what you want, and its a pain in the ass. or you say less and hope the app does what you want and not what you dont
14:17:09 <monochrom> Yeah, the Jewish calendar has a lot of lunar cycles in it. The Chinese calendar too.
14:17:11 <dolio> GHC has the other things, too. It calls them "implicit parameters," and pretty much no one uses them.
14:17:29 <EvanR> the type class mechanism transcends this by making what you want not ambiguous
14:17:34 <trigone> EvanR: i .... see, i think...
14:17:50 <EvanR> but sometimes it actually is ambiguous, and you get a compiler error
14:18:00 <EvanR> at least its not what you dont want
14:18:01 <monochrom> The Chinese calendar inserts leap months to sync back with the seasonal cycle.
14:18:20 <dolio> I guess implicit parameters are a little less convenient at the edges than type classes.
14:18:44 <dolio> But making them actually work like type classes can be no picnic as well.
14:19:52 <trigone> EvanR: yeah, explicit is rather better...
14:20:20 <trigone> dolio: what're those implicit parameters?
14:20:55 <dolio> :t let foo x = x + ?y in foo
14:20:56 <lambdabot> (Num a, ?y::a) => a -> a
14:21:06 <trigone> monochrom: calendars are always a mess...
14:21:46 <EvanR> luckily theres a "free calendar" that rules them all
14:21:47 <trigone> dolio: not sure to understand at all
14:21:51 <EvanR> the day numbers
14:21:54 <trigone> EvanR: really?
14:21:55 <dolio> > let foo x = x + ?y ; bar = (let ?y = 2 in foo 3) in bar
14:21:58 <lambdabot>  5
14:22:17 <EvanR> each day is some integer, zero is arbitrarily chosen to be some day in the past
14:22:19 <monochrom> Ah but days are out of sync with the seasonal cycle too.
14:22:44 <trigone> EvanR: i think we started cutting time into pieces for the same reason we pile money into heaps
14:22:51 <monochrom> No actually it is even worse than that.
14:22:54 <EvanR> calendars arent really about time
14:22:55 <dolio> trigone: When you use a variable that begins with a question mark, it becomes a parameter that you don't have to explicitly pass around.
14:23:05 <dolio> And appears in the type like a class.
14:23:33 <dolio> And gets propagated around like a class.
14:23:52 <trigone> dolio: i... think i get it... can you pattern match on it to choose what to do depending on it?
14:23:53 <dolio> And the way you say what the implicit value is is with that let binding.
14:24:02 <monochrom> Time is SI-defined by atomic clock. Its cycle is out of sync with everything we care about. Days, moon, sun, Earth's orbit, everything.
14:24:14 <trigone> dolio: can you use the where binding?
14:24:21 <dolio> Yes.
14:24:45 <dolio> I wonder if top level works, too.
14:24:53 <trigone> monochrom: yes but the whole world is a mess then. still for practical purposes some things can be ignored
14:24:54 <EvanR> days predate atomic clocks by at least a few million days
14:25:05 <EvanR> the day is the fundamental unit
14:25:31 <Tuplanolla> @let wrap a b n = let c = b - a in (n % c + c - a % c) % c + a -- This was the previous definition.
14:25:32 <lambdabot>  .L.hs:191:34: error:
14:25:32 <lambdabot>      Ambiguous occurrence ‘%’
14:25:32 <lambdabot>      It could refer to either ‘Data.Ratio.%’,
14:25:37 <monochrom> No, cesium predates Earth by billions of days.
14:25:43 <dolio> Okay, no, top level doesn't work.
14:26:02 <EvanR> thats basically useless to calendars
14:26:15 <EvanR> TAI is just an annoyance
14:26:32 <Tuplanolla> > wrap 0 255 1 :: Word8 -- It fails here.
14:26:34 <lambdabot>  0
14:26:53 <monochrom> The fine-tuning fallacy.
14:27:17 <EvanR> the count of days doesnt care about real time, the earth slowing down and all
14:27:25 <EvanR> its abstract
14:27:43 <trigone> i'm not sure why people bother having scientific debates when the issue has nothing to do with science, and it's just a pragmatic dilemma
14:28:11 <monochrom> No, it's an astrology debate. :)
14:28:11 <EvanR> the clients shop opens at exactly 3:00 PM platonic time :)
14:28:38 <trigone> what's platonic time?
14:28:50 <EvanR> they will not change their hours in response to a correction by some french dudes with radioactive junk
14:28:52 <Unicorn_Princess> does anyone have any experience with Helm? I'm having a hard time finding any documentation except the reference at hackage
14:29:42 <monochrom> It's not just the French. The British and the Americans are accomplices too.
14:29:43 <EvanR> trigone: TimeOfDay in the time package
14:29:55 <trigone> EvanR: french with radioactive junk? what you talking about?
14:30:02 <monochrom> So you have to invoke "some imperialistic dudes".
14:30:16 <EvanR> ok i will
14:31:51 <monochrom> I wonder if the two of us can negotiate a compromise. Because then we can have "platomic time" and the best of both worlds.
14:33:38 <EvanR> plato vs democritus
14:33:47 <monochrom> haha that's great
14:34:57 * hackagebot exact-real-positional 0.0.0 – Framework for Exact Real Arithmetic in the Positional Number System – https://hackage.haskell.org/package/exact-real-positional
14:35:13 <iqubic> I think platonic time should be the same as utc.
14:35:31 <iqubic> What does wrap do?
14:35:35 <iqubic> @src wrap
14:35:35 <lambdabot> Source not found. It can only be attributed to human error.
14:35:45 <trigone> in september i'll go to the university, and there are programming courses. of course they're all about OO, C and OCamel a bit. i'm rather bad at programming outside of haskell. are there manuals to help haskellers code measurably well in non-haskell languages?
14:36:13 <monochrom> I am learning the "machines" library.
14:36:42 <mud> trigone: Just pretend you're in IO always, and that's about it. Also some OO crap.
14:36:45 <glguy> monochrom: Do you have something you'd like to use it to do?
14:36:53 <boj> trigone: you already know the fundamentals, you'll be fine
14:37:00 <monochrom> No.
14:37:12 <trigone> mud: i have nightmares that look like that...
14:37:37 <Tuplanolla> The hardest part about C is that you're programming for a machine that doesn't exist, trigone.
14:37:54 <EvanR> and anyone you ask for help insists it does !
14:38:06 <EvanR> and it probably doesnt act like your actual target platform
14:38:15 <trigone> boj: i don't think i'll drown but i'd like to feel comfortable in non-functional languages
14:38:25 <trigone> Tuplanolla: what does that entail for me?
14:38:32 <monochrom> OCaml is actually interesting.
14:38:46 <jared-w> F# is almost interesting :p
14:38:52 <monochrom> On several unrelated fronts, too.
14:39:10 <bsima> monochrom: what do you like about Ocaml?
14:39:12 <jared-w> Rust is the language I'm most interested in after Haskell right now
14:39:15 <trigone> monochrom: there won't be much of it though. and i'm afraid i'll keep expecting haskell goodness and then crash down
14:39:15 <monochrom> It has the SML module system which is interesting on the module-system axis.
14:39:20 <shlevy> When defining a new mtl-style class, is there a good list of transformers to lift your class through, assuming you can do so lawfully? Just the ones in 'transformers'?
14:39:26 <Tuplanolla> It means you'll get to exercise your attention to detail, trigone.
14:39:34 <monochrom> Its OO story is a fresh and honest view on the OO axis.
14:39:42 <jared-w> OCaml has OO?
14:40:01 <monochrom> Its record-type story makes Haskell envy.
14:40:03 <trigone> Tuplanolla: yeah, i already coded in C. it's just... i never liked writing code before haskell
14:40:09 <bsima> OO is one of its biggest selling points for industry
14:40:17 <trigone> monochrom: is it a smalltalk-like OO?
14:40:24 <monochrom> No.
14:40:39 <trigone> well then i'm not sure it's that worth it but maybe
14:40:45 <monochrom> It's part row-polymorphism, part subtyping.
14:40:55 <jared-w> It's unfortunate how big of a selling point OO is. I really don't a lot of what came with OO :/
14:41:26 <monochrom> Actually I may be wrong, it may be all row-polymorphism and open-variants on steroid.
14:41:38 <EvanR> what industry likes about OO probably doesnt overlap much with whats cool about OO
14:41:42 <trigone> monochrom: i don't know about those concepts anyway
14:41:53 <monochrom> Well, you could look them up.
14:41:55 <jared-w> trigone: you probably do, just not by those names
14:42:02 <trigone> EvanR: what would be either?
14:42:07 <trigone> jared-w: well that was what i meant
14:42:18 <jared-w> subtyping, for example, is more commonly known as "inheritance hierarchies" iirc
14:42:38 <trigone> monochrom: sure, i'll do so later... but it's more the C and java that's gonna bother me i think
14:42:45 <monochrom> But "open variants" means: Recall how in Haskell after you have coded up a sum type, it's fixed? Open variants means you can add a few more cases after the fact.
14:43:15 <jared-w> Java is really good to learn just to understand what it means for a language to have industrial strength tooling. The tooling in Java is god-tier because the language demands it due to being so incredibly shitty and unwieldy
14:43:19 <trigone> monochrom: like javascript's dynamically-modifiable objects? or phython's classes?
14:43:48 <monochrom> No for the first. I don't know python.
14:43:51 <trigone> jared-w: and with the good tooling, does it actually become usable? or at least enjoyable?
14:43:53 <EvanR> sounds like a bad paradox to get into, make the language better and people have less incentive to make "god tier" tooling?
14:44:10 <EvanR> should we switch to malbolge to get outer-god tier tooling?
14:44:14 <dedgrant> jared-w: Still arguable whether class inheritance should be lightly compared subtyping, as open recursion complicates it, no?
14:44:21 <monochrom> But with 0.8 probability I say not python's classes either. python does very dangerous hack to get its class system.
14:44:22 <trigone> EvanR: commercial languages are harder to change than IDEs
14:44:33 <jared-w> trigone: "enjoyable" and "usable" are really subjective. I find Java to be less painful for me than C because of how powerful the tooling is
14:44:44 <monochrom> I mean all those __xxx__ secret things.
14:44:48 <EvanR> commericial language?
14:44:59 <EvanR> commercial language... like someone is selling a C++ compiler?
14:45:10 <trigone> EvanR: like haskell tries to avoid success
14:45:19 <jared-w> probably commercial language as in "convince the boss to use language X for everything"
14:45:42 <EvanR> you must be talking about "language users will not think, only do what some company says. the company that invented it"
14:45:53 <EvanR> but that probably makes a lot of open source languages commercial
14:46:01 <jared-w> One thing Java and C++ did /really/ well was convince pointy-haired bosses that they were the second coming
14:46:19 <trigone> EvanR: it's maybe not the right term. i just meant that whenever  the language is controlled by pragmatism, they prefer not adding new things or changing old things if you can just pay more progammers to handle shitty language
14:46:48 <monochrom> I have this idea of pitching Haskell as "a premium quality language".
14:47:10 <EvanR> i have noticed pragmatic people avoiding "shitty quality, low cost" at all cost
14:47:39 <trigone> EvanR: pragmatism depends on your purposes: if it's easy coding, you're in haskell. if it's money, you're in java/etc
14:48:09 <EvanR> when i retire and get a java job, ill have to see if this is true
14:48:31 <EvanR> or something else is going on with java
14:48:39 <dedgrant> java / c / ... COBOL *cough* ...
14:48:40 <trigone> EvanR: something else?
14:48:54 <EvanR> why people think it makes sense for purpose X
14:49:01 <EvanR> and it stays around
14:49:49 <trigone> EvanR: you'd have to learn history because right now it's the standard and nobody cares of its quality, it just can't pragmatically be replaced anymore (not in existing projects)
14:50:54 <monochrom> The problem with general-purpose languages, eh? Clearly it makes sense for purpose X. It's general-purpose.
14:50:58 <trigone> i think it's the fact that at the time Java/C++ became the standard, you needed high speed bc of less fast hardware, and functional languages were not as optimized, esp not haskell
14:51:26 <EvanR> a corporate contact assures me they are 100% and using it for new projects
14:51:31 <EvanR> 100% java
14:52:03 <vimalloc> So, I'm sure it's something small, but I've been staring at this for a while and cannot figure it out. This is a stripped down version of what I'm working on: https://gist.github.com/vimalloc/c65e52d9a9597df78d31ba4be727d93a  I'm getting an error "Expected type: [(Int, Int, Int)] -> [Island] / Actual type: [(Int, Int, Int)] -> Either String [Island]", and I don't understand why the expected type [Island]
14:52:06 <vimalloc> instead of Either String [Island] (which is the type defined in the fuctions). 
14:52:12 <iqubic> I think Haskell could be used for a startup if tried.
14:52:13 * monochrom is against stereotypes such as "Java -> enterprise", "PHP -> web", "so, Haskell -> what?"
14:52:22 <vimalloc> I don't suppose anyone right off hand could point me in the correct direction here?
14:52:40 <EvanR> "Haskell -> futzing around in your moms basement reimplementing STLC again"
14:52:41 <trigone> EvanR: i think that new projects are still linked to old ones, and adding a language is not that easy
14:52:44 <Tuplanolla> Did you solve the applicative thing yet, vimalloc?
14:52:47 <monochrom> Haskell can be for web and PHP can be for enterprise and Java can be for machine learning just fine.
14:52:57 <boj> i'm pushing my team towards haskell in what is effectively a big enterprise microsoft shop
14:53:06 <vimalloc> Tuplanolla: I haven't started working on that yet, but am planning on it when I get home :)
14:53:32 <Tuplanolla> I'll be gone by then, so I'll just explain why it's interesting now.
14:53:33 <vimalloc> Got distracted by lunch and actual work I needed to do at work :P
14:53:40 <monochrom> I be damned if someone got PHP to work for firmware in your car, but why not.
14:53:52 <EvanR> oh god
14:54:02 <monochrom> >:D
14:54:12 <vimalloc> monochrom: Reading that gave me shivers
14:54:18 <vimalloc> Not in a good way
14:54:39 <Tuplanolla> Once you have `zipA`, you can easily define its inverse `unzipA :: Applicative f => f (a, b) -> (f a, f b)`.
14:54:45 <monochrom> Well the status quo of using C for that is not really better.
14:55:06 <EvanR> C isnt a template language.. oh ...
14:55:07 <Tuplanolla> This suggests that applicative can be thought of as a pointed thing that commutes with the product.
14:55:31 <Tuplanolla> You'll see then, vimalloc.
14:56:07 <vimalloc> Tuplanolla: Thanks :) I'll ponder that with more brain power tonight
14:56:23 <monochrom> Oh interesting, the "machines" library goes Data.Machine not Control.Machine
14:57:02 <monochrom> Control.Category and Data.Machine. Cats and dogs living together.
15:00:57 <trigone> vimalloc: is there not a problem with your top definition of createIslands? you map over an Either with a function (createGame) that looks like a kleisli arrow (a -> f b) instead of (a -> b). but maybe i'm off my game
15:02:15 <trigone> trigone: oh never mind, <$> must be over the function functor or something
15:03:58 <trigone> though i think given the nature of your functions, using monadic functions should be more appropriate, no? createIslands x = createIslandsGo x >>= createGame
15:04:44 <vimalloc> It does work with monands, an updated example like so: https://gist.github.com/vimalloc/c65e52d9a9597df78d31ba4be727d93a
15:05:09 <jle`> vimalloc: the two things you gave aren't the same thing
15:05:40 <jle`> just try expanding the types
15:05:43 <jle`> you'll see why
15:06:17 <vimalloc> Expanding the types?
15:06:22 <vimalloc> like :t in repl?
15:06:26 <jle`> yeah, write out the types of your things in your code
15:06:35 <jle`> like, what type does (<$>) have there?
15:06:36 <trigone> vimalloc: well, try checking if every parameter matches the expected type of the function
15:06:38 <jle`> what type do you think it has?
15:06:50 <jle`> what type do you think <$> is supposed to be there?
15:07:57 <max3> does anyone here have any experience with obsidian systems in nyc?
15:07:57 <trigone> vimalloc: and try recognizing the different functions expected by fmap/ap/bind, respectively (a->b), f (a->b) and (a -> f b). all your functions take pure arguments of various types and end up into the Either monad, so their type is more or less (a-> f b) with f = Either String
15:08:09 <vimalloc> My thought was that createIslandsGo would return 'Left' or 'Right', and the fmap would just pass on the value if it was Left or unbox the value if it was Right and apply that as an arg to createGame, 
15:08:47 <jle`> vimalloc: sure
15:08:53 <jle`> but try writing out the types
15:08:55 <jle`> using types
15:09:03 <jle`> (instead of english)
15:09:14 <jle`> natural language is pretty bad at describing things like this :)
15:09:39 <bollu> max3 Cale works there
15:09:41 <jle`> (<$>) :: Functor f => (a -> b) -> f a -> f b
15:09:53 <trigone> vimalloc: but you built createGame :: [Island] -> Either String Game  instead of say createGame [Island] -> Game. the former must be >>=ed, the latter can be fmapped
15:09:54 <jle`> and you're giving createGame and createIslandsGod
15:10:09 <jle`> the type of createGame is [Island] -> Either String Game
15:10:15 <max3> Cale you around?
15:10:27 <Cale> hi
15:10:39 <jle`> so here, (<$>) :: Functor f => ([Island] -> Either String Game) -> f [Island] -> f (Either String Game)
15:10:54 <jle`> vimalloc: here i'm just matching up the type variables
15:10:59 <vimalloc> trigone: aaah. Ok, that makes sense
15:11:01 <max3> Cale, what's the name of the MIT project you guys are rehabilitating ?
15:11:02 <vimalloc> Thanks for walking me throught that
15:11:03 <jle`> now, let's look at the second argument you're applying it to
15:11:21 <trigone> vimalloc: mind you, Either is not the easiest monad to meet when you're not fully comfortable with functors/monads. maybe first you could use Maybe, and then replace it with Either String in a second step?
15:11:23 <vimalloc> (coming to fp after years of imperative program is seriouly mind bendy)
15:11:24 <jle`> createislandsGo :: [(Int, Int, Int)] -> Either StringIsland]
15:11:35 <jle`> can you fit that into the type of (<$>)? 
15:11:49 <jle`> if you try, you'll start seeing why it doesn't make sense
15:12:11 <jle`> you need to fit `[(Int, Int, Int)] -> Either String [Island]` into `f [Island]`, somehow
15:12:15 <jle`> by picking the right 'f'
15:12:32 <jle`> you'll see that there is no 'f' you could possibly pick that would match that
15:12:53 <vimalloc> Ok, that makes more sense now. 
15:12:55 <jle`> if the types aren't working out, it helps to step back and think about what assumptions you're making about the types
15:13:08 <jle`> our brains are very bad typecheckers
15:13:19 <vimalloc> It seems like writing them out like that would be a very smart thing to do :P
15:13:20 <jle`> well, in our heads, at least
15:13:22 <vimalloc> hehe
15:13:30 <vimalloc> Thanks for all the help everyone. <3
15:13:31 <max3> my brain is a great type checker when i can see all the types in front of me
15:13:43 <jle`> i think the main issue here is that you might be dropping a point by accident
15:13:47 <Cale> max3: I'm not sure exactly. There was a thing for the CBMM which I was involved in a bit, but I haven't been working closely on the MIT side of things lately.
15:14:08 <jle`> vimalloc: you probably were "thinking" of doing ` crateIslands i = createGame <$> createIslandsGo i`
15:14:13 <trigone> vimalloc: i also think it'd be easier to read and reason with a few synonyms for all these lists of tuples which make a lot of white noise (just so the landscape is a bit clearer, then you can replace the aliases)
15:14:14 <max3> Cale, yea exactly that's the department. Seebas or something
15:14:16 <jle`> vimalloc: and thought that you could drop the 'i' ?
15:14:39 <jle`> vimalloc: from `createIslands <$> createIslandsGo i`, you can see then that you're using (<$>) instead of (=<<)
15:14:40 <max3> Cale, found it
15:14:42 <vimalloc> jle`: I was thinking exactly that.
15:14:43 <max3> https://github.com/CBMM/CBaaS
15:14:48 <jle`> vimalloc: (<$>) maps an (a -> f b)
15:14:49 <jle`> er sorry
15:14:52 <jle`> (<$>) maps an (a -> b)
15:14:57 <jle`> (=<<) maps an (a -> f b)
15:15:16 <jle`> (<$>) :: (a ->   b) -> f a -> f b
15:15:23 <jle`> (=<<):: (a -> f b) -> f a -> f b
15:15:23 <Cale> max3: Ah, that's not even the thing I was involved with ;)
15:15:30 <Cale> max3: But yeah, rings a bell.
15:15:43 * vimalloc needs to just keep <$>, <*>, and =<< open on hoogle at all time
15:16:19 <jle`> the differences are admittedly subtle
15:16:29 <jle`> especially coming from a programming culture where these sorts of conversions are always implicit
15:17:07 <vimalloc> psh, I'm coming from many years of writing sudo-code (python) and getting away with it :P
15:17:09 <jle`> like, some combinators in other languages might let you map both an (a -> f b) and an (a -> b) using the same combinator
15:17:13 <jle`> cause like, magic
15:17:25 <trigone> jle`: what? conversions between a->b and a->fb?
15:17:55 <trigone> jle`: really? oh right, automatically unboxing and so on
15:17:59 <hpc> writing sudo-code is a good way to get to the root of a problem
15:18:14 <jle`> trigone: more like polymorphic dispatch
15:18:30 <vimalloc> Don't get me wrong, I <3 python. But it's a very different beast then haskell
15:18:31 <jle`> "automatic joining" of Maybe's, for instance
15:18:32 <trigone> jle`: yeah, that's what i meant in very bad terms
15:18:49 <jle`> some languages have a mapping combinator for the 'Maybe' type that will automatically squish nested Maybe's
15:19:06 <jle`> so you can map an (a -> b) and an (a -> Maybe b) over a Maybe a, and you'll get a Maybe b each time
15:19:08 <jle`> fun stuff
15:20:08 * hackagebot stratosphere 0.5.0 – EDSL for AWS CloudFormation – https://hackage.haskell.org/package/stratosphere
15:22:59 <trigone> are there any attempts at translating, say, haskell, in relatively idiomatic C, even if that means literally trying to understand the purpose of the program beyond laziness and purity?
15:23:16 <trigone> i meant automatic translating
15:24:32 <trigone> or rather, automated (using a compiler, well a transpiler)
15:26:38 <trigone> are there cool books/tutorials on haskell specifically focused on types, in a wouldbe exhaustive way?
15:26:50 <MarcelineVQ> there's C DSL's which product subsets of C from haskell code
15:27:26 <MarcelineVQ> haskell ivory and copilot come to mind
15:28:08 <filwisher> If I'm using ExistentialQuantification, what's the syntax for constaining two existentially quantified variables by two separate classes? 
15:28:38 <filwisher> eg. I'm trying `forall a b. (Stmt a, Expr b) => ...`
15:28:48 <trigone> filwisher: did you try using two forall in a row? i don't know much about it though
15:30:40 <MarcelineVQ> filwisher: doesn't look like a bad start, what's the whole code?
15:30:41 <trigone> MarcelineVQ: ivory looks like writing C code with haskell syntax... not sure you gain that much. i mean yes you gain type safety, but it's still pretty C-lumsy and messy to read
15:31:00 <filwisher> Ah, it's compiled now!
15:31:06 <trigone> MarcelineVQ: what does dsl mean?
15:31:10 <filwisher> I think I didn't save it
15:31:18 <MarcelineVQ> domain specific language
15:31:47 <MarcelineVQ> It's when you write a language for a specific purpose
15:32:19 <trigone> MarcelineVQ: hm, but does that not imply that we're doing all the job of writing C in haskell? adding a haskell-layer of advantages but without staying abstract from the C procedural way?
15:33:49 <trigone> i mean doing the job manually (instead of writing idiomatic, maybe limited, haskell, and getting readable, non-lazy, etc, C at the end)
15:34:48 <MarcelineVQ> I'm not quite sure what you're looking for. What is 'adding a haskell layer of advantages' if it isn't abstracting?
15:36:59 <MarcelineVQ> I'm probably just misunderstanding, don't worry too much about it, but things like ivory might lead you in a good direction even if they're not what you're after
15:37:04 <trigone> MarcelineVQ: well you add type safety but for the rest, apparently, you write procedural C in haskell clothes without having the leisure of writing functionally, purely, immutably, and having the compiler translate all this into non-functional, non-pure, mutable C. basically i'm wondering if there's been a magical idiomatic haskell -> idiomatic c translator
15:37:30 <trigone> s/$/invented/
15:37:42 <MarcelineVQ> so something like, the ghc compiler?
15:38:04 <trigone> MarcelineVQ: lol i did say *idiomatic*. pretty sure you can't pass the ghc's output as handcoded C
15:38:25 <MarcelineVQ> Not sure, but that's the direction I'd peer into to learn about the subject
15:38:53 <trigone> MarcelineVQ: say someone asks me to write a C program, and i'd prefer writing it in haskell but not have the result look like i didn't write C in the first place
15:39:04 <ab9rf> you can probably take LLVM IR output and reconstitute it into C, but that would be ugly.
15:39:30 <trigone> ab9rf: ugly bad
15:39:41 <ab9rf> doesn't ghc still compile to C--?
15:39:57 <MarcelineVQ> Well now that's a more fun approach, I've thought the same about C# and python, I'd be looking into DSL's to learn about making that sort of transition
15:40:20 <trigone> ab9rf: but the resulting program is still meant to handle thunks and other stuff you'd never implement in C directly
15:40:28 <MarcelineVQ> I now know that's not really what you're after, but it'd be a good place to learn
15:40:30 <ab9rf> trigone: well, duh
15:40:35 <hpc> it would also heavily reference the RTS
15:40:40 <trigone> what's a fun approach?
15:40:51 <ab9rf> trigone: i used to use the chicken scheme compiler, which compiles to C but it's the World's Ugliest C code
15:41:11 <MarcelineVQ> The working in haskell to do a job you were payed to do in c approach :>
15:41:15 <trigone> ab9rf: caution, some might try fighting for that title
15:41:35 <ab9rf> there's a PHP-to-C translator called phc that generates compilable C code, but each PHP file is compiled to a single C function containing a ginormous switch statement.
15:41:50 <trigone> MarcelineVQ: yeah ^^
15:41:57 <ab9rf> basically it converts the PHP file into a finite state machine, and then generates a C function that implmenets that FSM
15:42:10 <trigone> ab9rf: for a PHP program that's actually an improvement :P
15:42:11 <ab9rf> at least, that's what it appeared to be doing to me, i didn't look at it that hard.
15:42:14 <ab9rf> trigone: yes
15:44:00 <trigone> it's a bit paradoxical how fast it became acceptable to transpile to js from a plethora of different new dialects, but with C/C++ you still can't easily just choose the language of your choice to do whatever job... of course it's quite harder to bind haskell with C than it is to bind coffeescript with js
15:44:21 <ab9rf> trigone: that's because javascript is a "machine language" for browsers
15:44:55 <ab9rf> it's similar to how document description languages "compile" to postscript
15:45:00 <hpc> trigone: it's part of a general culture in javascript to program in literally anything but javascript
15:45:23 <ab9rf> because postscript is what the printer speaks, and you don't have a choice
15:45:28 <hpc> you don't have to look hard to find people who are "jquery developers" that couldn't tell you how javascript's OO model works
15:45:31 <ab9rf> (well, you do: you can also use PCL.)
15:45:46 <ab9rf> hpc: you presume that javascript's OO model works
15:46:01 <trigone> hpc: believe me i do know
15:46:10 <ab9rf> but yeah, i get your point
15:46:24 <ab9rf> javascript is, for many applications, an IR at this point
15:46:33 <trigone> ab9rf: what's IR
15:46:41 <ab9rf> intermediate representation
15:47:06 <trigone> ab9rf: like bytecodes and so on?
15:47:13 <ab9rf> intermediate between source code and machine code/bytecodes/etc.
15:47:30 <hpc> in some ways haskell is the same way, but with enough abstraction power that the community has been able to manage with libraries
15:47:36 <ab9rf> although the asm.js subset is closer to a "machine language" for a somewhat odd virtual machine
15:47:41 <trigone> ab9rf: ok, so "theoretically readable", as in plain text even if it's compiled JS
15:47:46 <trigone> i mean transpiled
15:47:48 <hpc> and the extension mechanism, so if you need a language with more power than haskell, you just add that power to haskell
15:48:04 <jared-w> To expand on the IR thing, most people when making new languages, compile/transpile to two main targets now: LLVM and/or JS
15:48:19 <ab9rf> hpc: it also helps that haskell users tend to be the sort who will abstract at the drop of a hat
15:48:53 <trigone> ab9rf: technically they dno't have a choice (i think)
15:48:56 <jared-w> asm.js and web assembly is designed to help people target web browsers as a compilation target without having to take huge performance penalties
15:49:11 <trigone> jared-w: what's LLVM?
15:49:14 <jared-w> trigone: Haskell users have plenty of choice when it comes to abstraction levels. The big thing for Haskell is that abstraction is /free/ compared to other languages 
15:49:20 <ab9rf> jared-w: don't forget JVM
15:49:24 <jared-w> LLVM is the clang compiler
15:49:30 <ab9rf> jared-w: it's falling out of favor, but is by no means dead yet
15:49:32 <hpc> "low level virtual machine"
15:50:00 <hpc> llvm isn't the clang compiler
15:50:02 <vimalloc> iirc you can compile to llvm bytecoe and then have that compiled directly to asm.js
15:50:03 <jared-w> Very few people target the JVM for their special language as a compilation target. It's a highly restricted assembly language and makes too many things too difficult. But you're right that JVM is definitely one of the bigger 3 targets
15:50:12 <ab9rf> only if it's llvm-clang
15:50:14 <vimalloc> The future is a strange place
15:50:14 <hpc> it was originally a replacement code generator for gcc
15:50:30 <jared-w> hpc: you're right, m'bad.
15:50:33 <ab9rf> or clang-llvm, i forget which order they're in :)
15:50:35 <trigone> jared-w: pragmatically i don't think you can debug your code without knowing of monads, types, typeclasses, and at that point you proved that in theory you can learn basic but still very abstract stuff, so there's no reason you can't learn more, and then why would you not?
15:50:52 <hpc> it's a general machine language target, and you can almost write in it directly without going insane ;)
15:51:02 <ab9rf> jared-w: the JVM-based language sare those that are targeting niches in the existing, very large, JSEE market.
15:51:17 <ab9rf> jared-w: and, to a degree, android, although android is its own very weird universe
15:51:29 <hpc> the "front end" compiles from a high-level language to llvm - ghc, gcc, and clang are all front-ends in various ways
15:51:34 <vimalloc> Then you have scala.js, which takes code that originally targets the jvm and turns it into javascript instead :P
15:51:43 <trigone> hpc: so... it's like upgraded assembly?
15:51:44 <hpc> the back end compiles from llvm to assembly
15:51:51 <hpc> yep
15:52:13 <ab9rf> trigone: more or less. IRs tend to be "somewhat" architecture-independent
15:52:23 <ab9rf> but not as much as their source languages
15:52:31 <trigone> ab9rf: so a downgraded C then?
15:52:37 <jared-w> LLVM is turning out to be the "ideal" platform-independent assembly language
15:52:47 <ab9rf> trigone: well, that would be C--, which is an IR that has some use. ghc used, or at least used to use, C--
15:52:50 <hpc> it's different enough from C that i wouldn't make that comparison
15:52:56 <jared-w> trigone: if anything, it's an upgraded C. C used to be what people targeted but that's because you could compile with GCC and GCC ran on damn near everything
15:53:06 <hpc> especially since llvm was written as an IR for C in the first place
15:53:16 <trigone> hpc: i didn't imply it was derived from it, more like, where it was located on the scale of abstraction
15:53:22 <ab9rf> http://www.cs.tufts.edu/~nr/c--/index.html
15:53:46 <jared-w> trigone: it's below C as an abstraction level. It's /barely/ above "real" assembly
15:53:46 <ab9rf> LLVM is fairly decent for C but is troublesome with other languages, especialyl when it comes to calling convnetions
15:54:05 <ab9rf> iirc LLVM is really just aseembly with computer-assisted registered scheduling
15:54:15 <trigone> if haskell can be compiled to C, why is it less portable than C code?
15:54:33 <trigone> i mean i didn't hear that you could compile haskell on as many platforms as gcc
15:54:50 <ab9rf> trigone: the RTS has to be ported to each platform
15:55:10 <ab9rf> it's really hard to write an RTS that is architecture-independent, unles syou want it to really suck.
15:55:55 <trigone> ab9rf: i think i see... you could make an independent one but it'd be very slow, just like C code is not completely independent if you want it to work well, right?
15:56:21 <ab9rf> that's part of it, at least.
15:56:42 <trigone> why is there no attempt at adding other supports beyond js in browsers?
15:56:43 <ab9rf> there are also OS-dependent and platform-dependent aspects to the RTS
15:56:50 <ab9rf> trigone: network effect
15:56:51 <koala_man> trigone: haha, there are so many
15:57:19 <vimalloc> Using web assembly, someone got a native python (pypi) running in the browser :P
15:57:20 <ab9rf> trigone: there are endless efforts but people don't want to have to install Some Random Extension in order to use your website
15:57:32 <vimalloc> Problem is it takes a while to download the js and run.
15:57:47 <trigone> ab9rf: why can't it be default in mozilla/crome/etc?
15:57:54 <trigone> i mean installed by default
15:57:59 <hpc> just use the web assembly linux kernel, and then install it with your favorite package manager!
15:58:02 <vimalloc> http://pypyjs.org/
15:58:06 <ab9rf> trigone: because they have no incentive to add another component to their environments
15:58:21 <sbrg> there's also some wasm stuff that runs .NET in the browser
15:58:35 <sbrg> very experimental, and not at all complete or anything
15:58:36 <sbrg> but still
15:58:44 <ab9rf> it took what, almost a decade, to get the major browser supplies to converge (to the degree they have) on javascript?
15:59:19 <ab9rf> and even now there are differences in the JS implementation and in the HTML DOM between browsers.
15:59:37 <trigone> ab9rf: most times, on the length of a decade, it's easier to add a new language than modify an existing but very immutable one
15:59:48 <trigone> ab9rf: don't remind me
15:59:49 <ab9rf> trigone: yes, but you have to convince people to use it
16:00:00 <trigone> ab9rf: google coulda done it, i think
16:00:13 <ab9rf> no, because microsoft and apple wouldn't have gone along with it
16:00:20 <koala_man> ab9rf: you had DHTML and VBscript in IE, Dart in Chrome with a transpilation shim, P/NaCl in chrome which is now being phased out, asm.js in Firefox aiming to be backwards compatible with js but a good compilation target
16:00:47 <trigone> ab9rf: depends, if the language were not proprietary
16:00:57 <koala_man> I mean trigone 
16:01:04 <ab9rf> trigone: microsoft would have impelmented a "proprietary extension" 
16:01:26 <ab9rf> that was part and parcel of their business model in the late 1990s through the mid 2000s.
16:01:46 <trigone> ab9rf: still coulda been better than js... is it me or microsoft haskell has a weirdly normal ring?
16:01:56 <ab9rf> lock out competitors through arbitrary incompatibilities.
16:02:17 <ab9rf> a lot of haskell work has been done at microsoft labs.
16:02:32 <ab9rf> my first encounter with haskell was through a microsoft labs project
16:02:38 <ab9rf> (that i read about, not that i was part of)
16:02:47 <geekosaur> but ms research is not ms's business wing
16:02:59 <koala_man> is spj still at ms labs?
16:03:04 <geekosaur> (and msr has been known to regret the business side taking over their stuff...)
16:03:09 <trigone> ab9rf: i know... it's kinda weird to me but it's mostly bc i don't like the OS
16:03:35 <trigone> geekosaur: will there be a divorce?
16:03:46 * geekosaur knows the developer of sharepoint. it was ... a very different beast before the business side discovered it
16:03:57 * trigone test
16:04:26 <trigone> sharepoint?
16:04:28 <geekosaur> trigone, probably not. the business side is pretty much why msr can afford to play around with stuff like ghc
16:05:36 <trigone> geekosaur: yeah, it's kinda sad when you think ab it... it feels like code laundering (making good code out of the money gotten from bad code)
16:05:38 <geekosaur> likewise, before there was msr, there was bell labs --- which did cool stuff, but could only do so because it was funded by the telco monopoly
16:06:38 <trigone> is F# really functional? i heard they had monads, but what's the diff with haskell?
16:06:57 <trigone> s/'s the diff/'re the differences/
16:07:19 <geekosaur> trigone, historically that was how a lot of non-commercial/government/military stuff happened. for example composers and artists existed because they had (usually governmental) patrons
16:07:41 <geekosaur> f# started out as ocaml for .net
16:08:02 <trigone> geekosaur: really?? so it's not related to C#?
16:08:22 <ab9rf> only in the sense that it targets the .NET CLR.
16:08:27 <geekosaur> ^
16:08:37 <trigone> ab9rf: so, like scala targets Java?
16:08:46 <trigone> i mean JVM
16:08:46 <ab9rf> scala targets the JVM, not Java.
16:09:13 <geekosaur> more or less, yes. but the clr is actually better designed for multiple languages; the jvm is pretty much designed to run java and nothing else
16:09:17 <koala_man> the java virtual machine, not the java programming language (as Sun wanted it in their trademark guidelines)
16:09:35 <geekosaur> that clojure, scala, etc. work on it is somewhere between lucky and a miracle :p
16:10:15 <trigone> i heard ocaml was mostly procedural with an addition of functional that didn't really make it truly functional (but then the definition is fuzzy). if you had to compare ocaml and common lisp or other non-pure functional langs?
16:10:56 <geekosaur> ocaml is not really procedural. it's in the ML language family. what it *is* is impure, like most of the non-Haskell members of the ML family
16:11:12 <geekosaur> it also has an OO interface which is relatively rarely used
16:12:46 <trigone> geekosaur: why do people choose other functional languages beside haskell. i understand the academic languages' appeal (proof assistants etc) but i don't get the desire for closure/scala/ocaml...  common lisp or standard ml... are there advantages?
16:13:28 <trigone> geekosaur: does ocaml have haskell-like ADTs too beside OO?
16:13:29 <geekosaur> existing libraries, availability of programmers who know it well
16:13:31 <ab9rf> the JVM's invokedynamic bytecode seems to me to be a ginormous hack
16:13:41 <cheater> hi. can someone suggest a good tool for quickly solving a set of equations and inequalities? i want to solve a (large) set of equations vor vars v1..vn what have constraints, such as a var is >= or <= a constant, or for vars vi..vk they must stay in some sort of constrained proportion to each other.
16:13:41 <MarcelineVQ> scala's advantage is java libs I would guess, not knowing if that's the case
16:13:42 <geekosaur> trigone, yes
16:13:42 <ab9rf> and JVM type erasure is a bodge.
16:14:14 <geekosaur> yes, both scala and f# benefit enormously from being able to use existing jvm resp. clr libraries
16:14:29 <hpc> ghc has type erasure too
16:14:44 <ab9rf> MarcelineVQ: yeah, pretty much. i use scala occasionally, simply because scala is typically terser than java for the same code, and thus easier to undersatand
16:14:45 <geekosaur> hpc, but it's not what jvm calls "type erasure"
16:14:49 <geekosaur> which is ... pretty wtf
16:14:57 <ab9rf> java code has a very high boilerplate fraction
16:15:00 <geekosaur> (jvm's that is)
16:15:31 <ab9rf> but really the only thing i use scala for is writing minecraft mods :)
16:15:41 <Gurkenglas> How do I correctly turn [State (Vector a) b] into State (Vector a) b, when each mutation in the list is small?
16:15:52 <ab9rf> (which is forced to be JVM by the underlying environment.)
16:15:53 <trigone> so if i don't have professional requirements to use the java/microsoft world, there's no real interest in switching or even adding to haskell?
16:16:12 <sbrg> ab9rf: I've had to write some scala professionally, and most of it feels ... half-assed. all the abstractions don't really seem to fit together very well, and I just miss haskell. 
16:16:21 <ab9rf> sbrg: yup, same here.
16:16:25 <trigone> cheater: i personally didn't get what you mean
16:16:45 <sbrg> and then there's universal equality which is horrible
16:16:48 <sbrg> and implicits
16:16:50 <sbrg> gah
16:16:58 <ab9rf> sbrg: it's a fairly half-assed language, but if you have to target the JVM, it's preferable to using Java, at least for me.
16:17:27 <sbrg> ab9rf: Yeah, I'd take anything over java really. But I've really started to like clojure, even though it's not statically typed
16:17:57 <trigone> sbrg: even js?
16:18:02 <ab9rf> sbrg: clojure is a lisp, and i have developed an aversion to lisps :)
16:18:26 <trigone> what's good with lisp languages vs haskel? 
16:18:52 <EvanR> you cant hate on lisp itself, its very old
16:18:57 <sbrg> trigone: haha no, not that. i was referring to JVM languages mostly. 
16:18:59 <ab9rf> EvanR: so am i :)
16:19:01 <EvanR> computer stuff has been a long and hard journey
16:19:06 <Tuplanolla> Aesthetics, I'd say, trigone.
16:19:07 <EvanR> people didnt know what they were doing
16:19:33 <trigone> sbrg: kay :P
16:19:42 <ab9rf> i still don't know what i'm doing
16:19:57 <EvanR> but you can question whether lisp fans should upgrade by now
16:20:01 <trigone> EvanR: pfh, those taking decisions didn't care you mean, because money
16:20:05 <sbrg> I kind of lack the right terms to describe this, but I really like languages which are very expressive and have powerful abstractions. I think many lisps(including clojure) fit this very well. Homoiconicity is really cool
16:20:21 <EvanR> :(
16:20:33 <Tuplanolla> I'd like Haskell more if it had Lisp's syntax.
16:20:45 <EvanR> :(
16:20:46 <cheater> trigone: i want to solve a set of equations and inequalities on some variables.
16:20:55 <MarcelineVQ> define a lisp pp :D
16:20:56 <cheater> trigone: i would like a lib or tool for that.
16:21:22 <EvanR> https://github.com/haskell-lisp/liskell
16:21:58 <trigone> cheater: oh right, math, sorry i was in another place. i personally don't know...
16:22:28 <trigone> Tuplanolla: is it not easier to read without parentheses?
16:22:58 <Tuplanolla> Maybe, but the metaprogramming story is worse.
16:24:35 <EvanR> i didnt understand how metaprogramming even worked without separating abstract and concrete
16:24:36 <trigone> Tuplanolla: true, but i think it came from the fact that it's harder to reason with a program that program itself. not even sure how it handles types and so on, unless all the metaprograming is static ofc
16:24:59 <trigone> EvanR: what do you mean
16:25:09 <EvanR> abstract vs concrete syntax
16:25:30 <sbrg> Tuplanolla: yeah it's hard to beat homoiconicity when it comes to metaprogramming
16:25:32 <EvanR> im not sure anyone thinks these are different in lisp
16:25:53 <EvanR> because they look the same
16:25:58 <trigone> EvanR: you mean the part of code that metaprograms vs the rest?
16:26:06 <EvanR> no
16:26:09 <sbrg> also, if any of you do front-end development in react, you should really give clojurescript + reagent a try. it takes like 1 min to set up via leiningen, and you get hot reloading and it's just glorious
16:27:10 <trigone> is rust usable? as in stable enough, truly usable for reasonably any project?
16:28:18 <iqubic> sbrg: is it functional?
16:28:34 <sbrg> yes, clojure is functional
16:28:43 <sbrg> immutable by default, etc. 
16:30:00 <vimalloc> trigone: kinda? It is stable ish, but a lot of rust libraries seem to use features that aren't marked as stable, so...
16:30:28 <vimalloc> I've only dabbed in rust for a couple months. I really like what it can do, and I *really* don't like writing code in it
16:31:09 <trigone> vimalloc: hm :/ maybe i'll wait 1-3years then... really, is it more uncomfortable than C or just hard bc low level?
16:31:17 <iqubic> Is rust functional?
16:31:43 <vimalloc> rust is not functional. I find rust much harder to write then C, but on the flip side you send up with much safer code then C
16:31:50 <trigone> iqubic: nah, i heard it got its own special way of doing things. compared to haskell, it got type safety in common i think
16:32:18 <iqubic> Is rust weird?
16:32:55 <trigone> iqubic: it's got new ideas. weirdness is in the eye.
16:33:22 <vimalloc> I would qualify rust as weird. But the weirdness leads to some really neat ideas
16:33:55 <iqubic> who here recomends rust as a language to learn?
16:34:14 <trigone> haskell's weird for non-haskellers. to me, java is weird, so is bash, jquery...
16:34:23 <iqubic> Not neccisarily to use, but just as a thing to learn
16:34:23 <vimalloc> I haven't used it in ~6 months, but my overall biggest complaint with it was the compiler error messages were terrible. That may have improved
16:34:28 <sbrg> learn everything
16:34:33 <sbrg> as much as you can
16:34:43 <koala_man> I know bash inside out, but it's still really weird
16:34:44 <sbrg> especially languages in different paradigms
16:34:44 <vimalloc> trigone: Good point. Haskell is also weird to me :)
16:34:51 <Tuplanolla> I was unhappy with the standard library and gave up on it, iqubic.
16:34:58 <vimalloc> koala_man: ++
16:35:22 <iqubic> Tuplanolla: are you happy with Haskells prelude + standard library?
16:35:26 <sbrg> koala_man: yeah, but bash is weird like a mutated animal near chernobyl
16:35:45 <iqubic> I also think bash is weird, despite using a linux box
16:35:49 <Tuplanolla> A bit more, iqubic.
16:36:24 <trigone> someone who thinks bash is not weird... would be weird
16:36:28 <vimalloc> srhb: hahaha
16:37:28 <sbrg> parsing bash is undecidable
16:37:34 <geekosaur> bash is what you get when some deranged individual gets the idea of trying to treat a glorified job control language as a real programming language
16:37:50 <sbrg> http://www.oilshell.org/blog/2016/10/20.html for those interested
16:39:10 <trigone> geekosaur: well perl is sometimes meant to replace it but...
16:39:56 <Tuplanolla> Haskell is lacking many useful fundamentals like integer roots and logarithms, modular arithmetic for floating-point numbers, hypercubical indexing and certain combinators that pop up in various utility libraries, iqubic.
16:40:21 <Tuplanolla> There are libraries for most of these, but they still ought to be in `base`.
16:40:24 <geekosaur> bash wants to be python. perl is more the result of a necromancy spell cast over a pile of random language syntax :p
16:41:48 <trigone> Tuplanolla: well as long as the library exist... it's kinda hard to make a not-too-large base because you never really know what's truly standard. not everybody does math calculus. (i think) by contrast i don't get why so many monad stuff have to be imported instead of being in prelude
16:42:36 <Tuplanolla> I want number theory in the standard library, because programming at any level is mostly that.
16:42:49 <iqubic> Yeah. I feel you
16:43:26 <sbrg> Tuplanolla: I don't think those things necessarily belong in base. At least the language itself is expressive enough to allow for such things to be implemented as libraries. The other day, I read a post that proposed a change to the JS base language to add syntax which just allows for less cumbersome function composition
16:43:36 <sbrg> it was literally just an operator. 
16:43:42 <vimalloc> I cannot stand perl, but at least there is libraries for just about everything in the cpan. But same thing can be said for python, and at least that has a more reasonable syntax (and real exceptions)
16:43:46 <trigone> geekosaur: bash wants to be python?? what does that mean? apt description of perl if the legends are true...
16:43:48 <sbrg> Thank god we're not there, is my point
16:45:13 <iqubic> Are there any typeclasses in prelude?
16:46:00 <trigone> iqubic: prelude is mostly importing, i think... and creating constants like otherwise... but maybe
16:46:05 <geekosaur> Num
16:46:13 <geekosaur> and its subsequents
16:46:30 <trigone> geekosaur: really? why would they not put it in a separate module?
16:46:36 <sbrg> https://www.stackage.org/haddock/lts-8.23/base-4.9.1.0/src/Prelude.html 
16:46:48 <sbrg> just imports GHC.Num and re-exports Num and friends
16:47:09 <geekosaur> I suppose one could ask "do you mean Haskell or do you mean ghc?"
16:47:10 <sbrg> but yes, the way you 'get' Num is by importing the Prelude
16:47:29 <monochrom> I don't think bash is weird. But I'm just ignorant, not weird.
16:47:31 <geekosaur> *Haskell* has at least: Num and friends, Monoid, Monad, Functor
16:47:50 <geekosaur> monochrom, bash only gets weird when you try to use it as a general purpose programming language
16:48:04 <trigone> sbrg: hm i see... if you write a custom Prelude, will it work less well or slower if you still just copy paste (parts of) the code?
16:48:06 <monochrom> Oh heh I never tried that.
16:48:38 <geekosaur> and the reason Haskell has them there is because it's somewhat difficult to do anything useful without them
16:48:45 <monochrom> I had some program I started with bash, but soon after (feature creep) I switched over to Haskell wholesale.
16:48:49 <sbrg> trigone: Plenty of custom preludes out there. I don't think they work less well or slower, but that depends on a lot of things and people's opinions, I guess.
16:49:29 <geekosaur> so Control.Monad isn't the definition of Monad, but it is various useful things for Monad. likewise Either is defined in the Prelude, you don't need Data.Either unless you want some extra utility functions
16:49:54 <trigone> sbrg: yeah... it's something slightly annoying with haskell's math background. sometimes you don't care if two things are mathematically equivalent, you just want to know if the compiled versions will work as well... it's not as easy to get such answers
16:50:41 <monochrom> \∩/ Opinions determine program speed.
16:50:46 <geekosaur> I have had to force Bourne shell to be a general programming language (older engineering workstations if you had to do anything complex before /usr was mounted...). it taught me to switch to a real programming language early whenever possible
16:51:06 <sbrg> monochrom: Haha. I meant the "less well" part
16:51:23 <sbrg> I wish that were true though
16:51:55 <geekosaur> oh, and a backup script that had to run on sunos 4, solaris 2+, hp/ux, aix, linux, ...
16:51:59 <monochrom> No. You don't want to wish that Donald Trump's opinion determines whether N = NP. :)
16:52:02 <trigone> sbrg: not sure you would, if the opinion of *others* would also influence your program :P
16:52:04 <louispan> @monochrom: Would you consider the 'Which' type in my haskell data-diverse library an "open variant"? You can add new cases after the fact (http://hackage.haskell.org/package/data-diverse-0.8.1.0/docs/Data-Diverse-Which.html)
16:52:04 <lambdabot> Unknown command, try @list
16:52:15 <geekosaur> (that amounted to a demonstration of why autoconf is the monster it is :p )
16:52:22 <sbrg> monochrom, trigone: good points
16:52:53 <monochrom> Then again, P vs NP is too hard, maybe we should really just ask him. :)
16:53:29 <sbrg> I think explaining what P vs NP even means to Trump is harder to solve than the halting problem
16:53:58 * sbrg stops politicking
16:53:58 <louispan> @monochrom: Actually a better example of extending a 'Which' is here (https://github.com/louispan/data-diverse/blob/master/test/Data/Diverse/WhichSpec.hs#L133)
16:53:59 <lambdabot> Unknown command, try @list
16:54:19 <sbrg> louispan: @ starts a command for lambdabot. normally on IRC, you just do "guy: <text>"
16:54:45 <louispan> sbrg: Whoops, sorry, I'm still new to IRC
16:55:02 <sbrg> no worries
16:55:03 <trigone> sbrg: is it that hard? i bet he'll just divide both sides of the equation by P and that'll be all
16:55:11 <Tuplanolla> How do you pronounce sbrg by the way?
16:55:17 <sbrg> i don't lol
16:55:32 <koala_man> he's certainly good at dividing
16:55:32 <sbrg> in my head I guess it's just "s b r g"
16:55:44 <trigone> koala_man: lol
16:55:50 <sbrg> it's basically an acronym for my first and middle name
16:55:53 <Tuplanolla> How about Snoyberg?
16:56:02 <sbrg> lmao, no I'm not snoyberg
16:56:06 <trigone> strasbourg
16:56:25 <sbrg> huh I have literally never considered that it could expand to that
16:56:29 <Tuplanolla> You're now part of the Simon--Snoyberg condensate.
16:56:30 <monochrom> louispan: I think yes.
16:56:45 <trigone> what's a condensate?
16:57:01 <sbrg> as long as it entails some kind of hivemind where I can borrow from their brains, that's fine by me
16:57:25 <hpc> trigone: the categorical dual to an ndensate
16:57:54 <sbrg> you guys are on fire tonight
16:58:00 <trigone> hpc: don't talk while eating
16:58:41 <trigone> hpc: ha lol i just realized it was a joke
16:59:25 <trigone> how would you pronounce ndensate
16:59:29 <louispan> monochrom: so now it's possible to have open variants in haskell too :)
17:00:03 <trigone> louispan: is that related to dependent typing?
17:00:45 <trigone> seriously what's a condensate?
17:01:35 <Tuplanolla> It's a bad material physics joke.
17:01:39 <trigone> google says "liquid collected by condensation"... how do you make liquid simon's?
17:01:52 <trigone> Tuplanolla: vs immaterial?
17:02:05 <louispan> trigone: No, I was referring to a record/variant library I created called data-diverse
17:02:09 <cheater> can someone suggest a good json parsing library? preferably one that doesn't pull in lens.
17:02:45 <sbrg> aeson is the defacto json library I'd say
17:02:52 <sbrg> and I don't think lens is a dependency?
17:02:55 <louispan> trigone: I didn't know that adding cases to a variant after the fact is called an open variant
17:03:05 <ReinH> aeson-lens exists so aeson doesn't have to have a lens dependency
17:03:10 <ReinH> it's a lot nicer to use with lenses though
17:03:42 <cheater> ok, thanks
17:03:55 <cheater> my data only has a few fields, so i'm fine without lenses
17:05:02 * hackagebot ratel 0.3.4 – Notify Honeybadger about exceptions. – https://hackage.haskell.org/package/ratel
17:05:05 <trigone> i heard lens was very long to compile, why is that? btw, comparison of time of compilation between haskell and c?
17:05:27 <Tuplanolla> It has lots of dependencies.
17:05:28 <hpc> lens is the top of a huge pyramid of abstractions
17:05:36 <monochrom> Simply a lot of code. (lens itself and all the other libraries it uses.)
17:06:01 <Tuplanolla> Microlens is a bit leaner, but comes with dirty orphans.
17:06:04 <sbrg> Hmm. I haven't tried compiling lens on my new machine yet. 
17:06:14 <sbrg> it'd be like a rite of passage
17:06:15 <monochrom> https://ro-che.info/ccc/23
17:06:48 <trigone> i'm surprised there's that much code, is that sign there's some difficulty writing it in haskell?
17:07:10 <trigone> monochrom: thanks to you i finally understand that comics
17:07:21 <monochrom> :)
17:08:08 <monochrom> Oh actually it's just 20 libraries.
17:08:26 <trigone> monochrom: 20 modules or 20 packages?
17:08:35 <monochrom> packages
17:08:52 <monochrom> I think I should try timing it for real.
17:08:53 <trigone> monochrom: and that's not a lot?
17:09:23 <trigone> i thought ghc only included what was needed though, is everything really needed whenever lenses are used?
17:09:38 <Tuplanolla> If your mission statement is to compose "families of lenses, isomorphisms, folds, traversals, getters and setters", it's not a surprise there's a lot of work to do.
17:11:15 <ReinH> There's a lot of code because there's a lot of things to code.
17:11:46 <trigone> ReinH: you mean to potentially code using it?
17:11:57 <monochrom> Oh, it seems actually the other 19 libraries are fast to build. It's lens itself taking a while.
17:12:18 <Gurkenglas> All the inlining, maybe?
17:12:26 <trigone> is it in active development?
17:12:36 <ReinH> No, I mean lens contains a lot of things
17:12:53 <ReinH> So it can contain a lot of code without implying that it takes a lot of code to write things in Haskell
17:13:11 <monochrom> Also taking GHC a lot of memory. 900MB now.
17:13:13 <ReinH> Is lens in active development? Yes. Daily.
17:13:15 <trigone> ReinH: so you meant let x = (there's a lot of code) in x because x?
17:13:23 <ReinH> trigone: Uh. No?
17:13:33 <monochrom> So yeah it has high-complexity code.
17:13:37 <Gurkenglas> monochrom, may some recursive dependencies already be built?
17:13:37 <trigone> ReinH: sorrry i did not read the next stuff
17:14:06 <trigone> monochrom: you mean during compilation?
17:14:13 <monochrom> Yes.
17:14:31 <ReinH> 900MB is not a lot of memory for GHC ;)
17:14:40 <monochrom> About 3-4 minutes.
17:15:26 <monochrom> If you build it on a rented virtual machine of 512MB memory, it will take forever.
17:15:51 <hpc> @quote .cost.
17:15:51 <lambdabot> SimonMarlow says: This is the largest program (in terms of memory requirements) I've ever seen anyone run using GHC.  In fact there was no machine in our building capable of running it, I had to
17:15:52 <lambdabot> fire up the largest Amazon EC2 instance available (68GB) to debug it - this bug cost me $26.
17:16:10 <monochrom> haha
17:16:24 <ReinH> I had an issue with an 8GB instance go into swap
17:17:38 <trigone> ReinH: hm :/
17:17:41 <sbrg> 68GB? Did the bug boot up the JVM and compile a scala program?
17:18:16 <monochrom> haha
17:22:27 <arahael> Why does cabal build a setup.hs file, which then builds the program? Isn't this a catch-22?
17:22:39 <arahael> How does cabal know how to build the haskell build script?
17:23:17 <geekosaur> normally it's not a problem because the build script is just simple hooks into the Cabal library.
17:23:18 <ReinH> hpc: That sounds exactly right.
17:23:29 <geekosaur> there are exceptions though and they cause both cabal-install and stack problems
17:24:10 <arahael> geekosaur: Could you elaborate?
17:24:11 <geekosaur> but they're also somewhat hard to fix; there are things like gtk bindings that are effectively unstable so must be generated on the fly by something
17:24:34 <arahael> geekosaur: That's exactly what I'm wondering: What builds the builder?
17:25:04 <ReinH> the builder builder
17:25:05 <ReinH> next questino
17:25:21 <pacak> there's runhaskell - interpreter.
17:25:26 * arahael glares at ReinH.
17:25:56 <EvanR> in the beginning there was the fix builder
17:26:00 <pacak> ReinH: Builders all the way down?
17:26:16 * Clint chokes.
17:26:18 <geekosaur> the point is most builders don't need anything special so cabal/stack just run ghc on it (and manual installs generally use runghc instead of compiling it first)
17:26:31 <arahael> I mean, if I had a C++ project, what's stopping me from writing a *C++ application* to do the build?
17:26:37 <arahael> Tha'ts the same thing, isn't it?
17:26:56 <EvanR> arent there several of those
17:26:58 <geekosaur> arahael, the mechanism is borrowed from Python
17:27:16 <geekosaur> you might as well ask how they get away with it :)
17:27:41 <arahael> geekosaur: So, setup.hs is considered to be a script, then?  But no, Python doesn't get away with it, they use automake to build python.
17:28:06 <geekosaur> arahael, installable python modules have a Setup.py
17:28:41 <geekosaur> if you are asking why ghc needs ghc to bootstrap itself, that's a different question
17:28:43 <arahael> geekosaur: (I suppose you're saying that python applications use a setup.py file, which is the old way of doing it (they're moving to an init script instead), but, those scripts are still interpreted by the systme python, and you don't end up with a build in any case - you end up with a package.
17:29:16 <arahael> geekosaur: Python doesn't first compile setup.py, and then call that to compile the project.
17:29:18 <geekosaur> could you explain what youy think the difference between those is?
17:30:16 <geekosaur> arahael, you seem to think that Setup.hs is somehow needing to build ghc for itself, or that it needs to have the package you are installing already present? neither is true
17:30:29 <geekosaur> if you don't mean either of those then I have no idea what you think is going on
17:30:46 <geekosaur> (and whatever it is probably isn't going on)
17:30:47 <arahael> geekosaur: I don't mean either of those things.
17:30:58 <geekosaur> then what do you think the problem is?
17:31:15 <arahael> geekosaur: Unlike a python project, I don't actually have to compile it to use it, at all.
17:31:28 <arahael> geekosaur: I mean, sorry - a python project doesn't need to be compiled to use it, at all.
17:31:56 <geekosaur> you still have not made clear why you think there is a problem
17:32:13 <arahael> A haskell project, presumeably, has a sufficiently complicated setup that merits it's own, program-specific, build system.
17:32:21 <geekosaur> sometimes
17:32:34 <arahael> This is so that the build system knows how to get modules, do template-haskell crap, etcetera, etcetera.
17:32:37 <geekosaur> there is a library called Cabal that is installed when you install ghc
17:32:46 <arahael> But, setup.hs is itself a haskell project.
17:33:17 <geekosaur> Setup.hs is mostly invocation of things in that library with "hooks" to e.g. tell it about additional (non-Haskell) dependencies and such
17:33:35 <arahael> Ok, so there's an implicit assumption that you only do things that are very, very simple?
17:33:40 <monochrom> arahael, 99% of setup.hs's out there do not need any extra libraries.
17:33:40 <geekosaur> yes
17:33:54 <geekosaur> (which is violated by a very, very few packages)
17:34:39 <arahael> So, in theory, I could just do the same thing to a C++ project, with the constraint that 'setup.cpp' can be compiled and run with literally nothing more than a 'clang++ setup.cpp && ./a.out'?
17:35:08 <arahael> (And for which, conveniently - by design - we also have a fairly useful librrary calle dcabal to assist us with this)
17:35:37 <geekosaur> in theory yes. in practice C and C++ require you to do a horrendous lot of work to identify C/C++ library dependencies, which is so complex that tools like autoconf and cmake were developed to do it 
17:35:54 <arahael> I'm content with the theory for this. ;)
17:36:03 <geekosaur> and both are infamously (although differently) complex and cranky and annoying
17:36:38 <arahael> Arguably, the haskell equivalent was solved using cabal and stack.
17:36:48 <geekosaur> ghc's package system makes most of that go away, so you can often get away with a setup.hs which is 1 line calling into Cabal library with defaults
17:37:08 <arahael> Makes sense now. :)
17:37:15 <monochrom> Well, it induces the opposite problem.
17:37:22 <arahael> monochrom: Eh?
17:37:52 <geekosaur> the main reason cabal and stack exist is that ghc has rather strict dependencies on libraries --- because it does cross-module inlining which basically means most of the source code for your library is part of its binary interface, so you can't really provide a 100% stable ABI :/
17:37:54 <monochrom> Namely, you can't just dump a few *.so files into your /usr/local/lib and then expect GHC to know they exist.
17:38:13 <monochrom> Whereas you can, with C compilers and linker.
17:38:38 <monochrom> C projects idea of "look for libraries" is just doing an ls to find *.h and *.so
17:38:44 <monochrom> Untrue for GHC.
17:38:49 <geekosaur> (much like if you speed up C code by using a lot of cpp macros instead of functions, you likewise have lots of unexpected dependencies in your ABI. KDE used to do this and regretted it, you had to recompile pretty much everything using kde for a kdelibs bug fix)
17:38:53 <arahael> monochrom: Arguably, you also can't in C++.
17:39:02 <arahael> monochrom: Due to the lack of a standard ABI.
17:39:21 <monochrom> If you haven't registered a library with ghc-pkg, then the library does not exist. Period. Does not matter how many files you dump into /usr/local/lib
17:39:28 <geekosaur> as of c++11 there is a standard abi as per-platform annexes
17:39:41 <monochrom> Police state vs free country.
17:39:42 <geekosaur> I've seen the x86/x86_64 and arm annexes
17:40:07 <monochrom> In Canada, you can roam free on the street. No one is going to check your ID.
17:40:19 <arahael> geekosaur: Do you have a reference?
17:40:37 <monochrom> In Hong Kong, if you don't carry ID when you roam the street, it is an offense.
17:41:09 <geekosaur> this is why you can mix C++11 or later code from clang++ and g++ on linux. (you can't on os x but that is because apple refuses to support c++11 with gcc, because it's (l)gpl3 and their lawyers consider it toxic. legal, not technical, issue)
17:41:50 <arahael> geekosaur: Apple barely uses gcc anymore, it's all clang now.
17:42:33 <zomg> monochrom: as much as that might be true, if the police want you to identify yourself and you can't or refuse, you might get in trouble regardless of country... but obviously the amount of trouble would probably be higher in HK :P
17:42:44 <geekosaur> arahael, yes, and the gpl3 issue is why
17:43:57 <arahael> geekosaur: If you hvae a reference to the ABI, I'm still interested in reading  it. :)
17:44:33 <pimlu> how do I see what types a haskell function is allocating the most once I know it has a high %alloc?
17:46:00 * geekosaur is trying to find it again
17:46:23 <geekosaur> all I am finding id people asking about abi compat between c++11 and c++14/c++17
17:46:35 <geekosaur> shoulda boockmarked it before it got buried >.<
17:46:51 <adamCS> pimlu: Are you using profiling?
17:47:13 <pimlu> yeah, I'm looking at the .prof file
17:47:24 <pimlu> specifically this program doesn't spend a lot of time with the values sitting in memory
17:47:35 <pimlu> I'm pretty sure it's allocating and throwing stuff away really quick
17:47:47 <adamCS> do memory profiling.  Instead of -pa, use -hc (for instance)
17:47:51 <pimlu> so I can't use the charts from http://book.realworldhaskell.org/read/profiling-and-optimization.html
17:48:43 <adamCS> you'll get a ".hp" file and from that you can see all sorts of things.  You can break it down by cost center, by module and by type.  And combinations thereof.
17:49:06 <adamCS> you might also want to install hp2pretty, to turn the hp files into svg charts
17:49:59 <adamCS> if you know what cost center (function) is doing the allocating, you can profile with "+RTS -hy -hc<YourFunctionName>"
17:51:01 <adamCS> that tells you the types that are being allocated by the cost-center you named.  the <YourFunctionName>" is wahtever showed up in the .prof so "+RTS -hy -hcfoo" or whatever.
17:51:44 <adamCS> You also ,ight try "hd" instead of "hy"  One is types and one is constructors (always forget which is which) and they can both be useful.
17:52:15 <adamCS> Another useful thing is to do "+RTS -hb -hcfoo" which will tell you something about the lifecycle of those allocations.
17:52:44 <adamCS> pimlu: https://downloads.haskell.org/~ghc/7.0.3/docs/html/users_guide/prof-heap.html
17:54:26 <pimlu> that seems useful, but wait, is all of this for sampling live allocations already in the heap, though?
17:54:55 <pimlu> as in, not counting the act of allocating over time of types by particular functions
17:55:32 <adamCS> I think it samples all of that but I'm not totally sure what you mean.
17:55:41 <adamCS> give it a shot and see if it helps?
17:56:03 <pimlu> alright
17:56:24 <pimlu> what I'm trying to say is, my program uses barely any heap at all, it just spends a lot of time allocating and throwing away stuff on the heap
17:56:52 <pimlu> so I'm not sure if I'm measuring the right thing
17:58:59 <Axman6> is there a connonical name for flip (.) apart from arrow's >>>?
18:00:13 <geekosaur> mrf. so it looks like the platform compat thing is not standard-mandated but informal, and was started by the ia64 platform spec for c++11 and later adopted by x86/x86_64 and arm
18:00:35 <monochrom> It is no longer arrow's >>>. It's category's >>>. Take a look at Control.Category.
18:08:26 <adamCS> pimlu:  I think it'll help.  You might need to fiddle with the sampling rate.
18:09:07 <pimlu> alright, well I just finished installed hp2pretty so we'll see how it goes
18:15:47 <pimlu> huh...  I guess it is using heap... definitely very helpful, time to figure this out lol
18:17:30 <adamCS> pimlu: Good luck!
18:18:58 <Guest43> Anybody got good haskell performance debugging tips? I just want to see how it's spending all its time... preferably from ghci
18:19:53 <Cale> Guest43: Have you tried the GHC profiler?
18:20:08 <Cale> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html
18:20:54 <fizbin> Or even start with https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/sooner.html#faster-producing-a-program-that-runs-quicker
18:22:08 <fosskers> Hey all, if you had to pick, would you rather beform math ops across a billion `Integer` or a billion `Scientific`?
18:22:30 <fosskers> s/beform/perform
18:24:07 <Guest43> Cale fizbin: thanks! It's definitely a bug hunt, so I'll check out -prof
18:24:24 <zomg> fosskers: seems that the answer to that would depend on whether you care about performance vs accuracy and other factors like that
18:25:03 <fizbin> Does anyone have a "mapM" variant of "mapMaybe"? I'm looking for something with the signature (a -> m (Maybe b)) -> [a] -> m [b] that I guess is equivalent to a mapM followed by a (map $ filter isJust) followed by (map $ map fromJust), only more efficient.
18:25:19 <fosskers> zomg, performance i'd say
18:25:51 <zomg> fosskers: I'm by no means an expert but at least to me it seems Integer would perform better - although I'm sure someone else can provide an answer to that with a higher likelihood of it being correct =)
18:26:01 <fosskers> heh, thanks
18:30:04 <c_wraith> fosskers: it depends so much on your use case. If you have fixed precision needs that are far less than the necessary range, Scientific gets you huge benefits.
18:30:23 <zomg> fizbin: wouldn't something like mapM and catMaybes work quite easily?
18:30:32 <c_wraith> fosskers: But if you need full precision over your range, I'm going to bet on Integer
18:31:32 <fizbin> zomg: Yeah. I'd been thinking of mapM and (fmap $ mapMaybe id), but I think mapMaybe id *is* catMaybes.
18:33:15 <pacak> :t mapMaybe
18:33:17 <lambdabot> (a -> Maybe b) -> [a] -> [b]
18:33:18 <pacak> :t catMaybes
18:33:20 <lambdabot> [Maybe a] -> [a]
18:33:21 <pacak> Nope.
18:33:32 <pacak> Hmm.... with id - yes.
18:33:44 <pacak> @src catMaybes
18:33:44 <lambdabot> catMaybes ls = [x | Just x <- ls]
19:34:02 * hackagebot vty 5.16 – A simple terminal UI library – https://hackage.haskell.org/package/vty
19:39:50 <codedmart> If I have a function `func :: (a, b) -> c`. Is there a function I can apply so I can have `anotherFunc :: a -> b -> c`?
19:40:04 <codedmart> If that makes sense. Like untuple the first argument.
19:41:23 <geekosaur> :t curry
19:41:25 <lambdabot> ((a, b) -> c) -> a -> b -> c
19:44:02 <jared-w> https://jaredweakly.com/blog/halfway-there/ woo, midterm blog update
19:44:36 <Welkin> :t curry . curry
19:44:38 <lambdabot> (((a, b), b1) -> c) -> a -> b -> b1 -> c
19:45:17 <Welkin> jared-w: that giant v-shaped header freaks me out
19:46:59 <jared-w> Welkin: it's a little weird, yeah. It's supposed to look much better with a header image but I never got around to putting one up there
19:50:31 <codedmart> Can't you turn this into point free `func a b = otherFunc (a, b)` -> `func = otherFunc . (,)`?
19:51:20 <jared-w> @pl func a b = func' (a,b)
19:51:20 <lambdabot> func = (func' .) . (,)
19:51:55 <codedmart> Ah that is what I was missing.
19:51:57 <codedmart> Thanks!
19:52:01 <jared-w> np
19:54:11 <geekosaur> was there a problem with using curry otherfunc?
19:54:14 <geekosaur> :t curry ?f
19:54:15 <lambdabot> (?f::(a, b) -> c) => a -> b -> c
20:41:47 <slack1256> any informal guide to reading core? ie what to look for?
20:43:56 * hackagebot pdfname 0.2 – Name a PDF file using information from the pdfinfo command – https://hackage.haskell.org/package/pdfname
20:44:09 <c_wraith> slack1256: there's a lot of bookkeeping noise, try to tune it out. The most important thing to note in general is that in core, case *always* causes evaluation, even if there are no patterns, and let *always* causes a heap allocation.
20:44:18 <MarcelineVQ> possibly, there's some info in ghc source as well,  https://github.com/ghc/ghc/blob/master/docs/core-spec/core-spec.pdf   https://github.com/ghc/ghc/tree/master/docs/core-spec    https://github.com/ghc/ghc/blob/master/compiler/coreSyn/CoreSyn.hs
20:47:15 <glguy> c_wraith: unless it's a let for some # kinded thing...
20:47:58 <c_wraith> oh, yeah those.  Also, I suppose there are cases where a later step might elide a heap allocation as an optimization
20:47:59 <glguy> Because every rule needs some exceptions
20:48:41 <glguy> I like -dppr-case-as-let
20:58:33 <slack1256> got it
21:29:03 <cheater> hi
21:29:47 <EvanR> pong
21:30:25 <cheater> i'm trying to use cassowary-haskell, and i compiled a simple example found here: https://github.com/athanclark/cassowary-haskell   this is my code: http://sprunge.us/TDJS   however it compiles with these errors: http://sprunge.us/aFbh   i'm not sure why that is. does anyone have ideas?
21:32:39 <EvanR> what is the type of (.*.)
21:36:26 <cheater> ok so the type seems to be: (.*.) :: LinAst -> Rational -> LinAst
21:36:48 <cheater> now when i tried something like this, there were no complaints: equ0 = (EVar "x") .*. (5) .==. ELit 0
21:37:54 <EvanR> yeah so Double cannot work
21:38:02 <EvanR> if it says Rational there
21:38:05 <cheater> yeah, stupid docs. hrm.
21:38:48 <EvanR> (i love how thanks to types i can diagnose this issue without know jack shite about linear solvers)
21:39:28 <cheater> yeah i did that in parallel to you
21:39:34 <cheater> but what you said reinforced my thinking
21:39:53 <cheater> i thought maybe i'm doing something wrong, because the docs can't be wrong, right? ... :)
21:41:47 <EvanR> what docs
21:43:41 <geekosaur> actually the text above the example in the readme is correct, it's the type annotation in the following example that is wrong and contradicts the text (which talks about how sometimes a :: Rational annotation is needed) 
21:43:56 <geekosaur> kwality...
21:53:37 <iqubic> Is there a guide to mutable haskell anywhere?
21:54:03 <pacak> Mutable haskell? Oh noes....
21:54:26 <pikajude> i'm going to put a package on hackage that reexports every widely used module on hackage, but with the Data and Control prefixes removed
21:54:58 <iqubic> pacak: Isn't an MVar mutable? Or no?
21:55:15 <pacak> pikajude: acme-everything ?
21:55:55 <pikajude> pacak: acme-please-stop-it
21:56:20 <pacak> iqubic: Hmm... Not in a sense shit is mutable in javascript.
21:56:45 <iqubic> So how can you ever share data between threads?
21:57:34 <pacak> MVar, IORef, Chan, STM
21:57:47 <iqubic> Are there guides on how those all work?
21:58:11 <iqubic> What I really want is a guide on concurrent haskell.
21:59:39 <pacak> :t takeMVar
21:59:40 <lambdabot> error: Variable not in scope: takeMVar
21:59:41 <pacak> :t putMVar
21:59:43 <lambdabot> error:
21:59:43 <lambdabot>     • Variable not in scope: putMVar
21:59:43 <lambdabot>     • Perhaps you meant ‘putChar’ (imported from Prelude)
21:59:48 <pacak> Ugh.
21:59:58 <iqubic> It's not in lambdabot's scope
22:00:14 <pacak> iqubic:  http://chimera.labs.oreilly.com/books/1230000000929/index.html
22:00:41 <iqubic> I'll just skip the parallelism stuf for now.
22:00:43 <iqubic> I think.
22:01:00 <iqubic> :t forkio
22:01:01 <lambdabot> error: Variable not in scope: forkio
22:01:07 <iqubic> :t forkIO
22:01:08 <lambdabot> error: Variable not in scope: forkIO
22:03:15 <iqubic> So in Haskell a program terminates if the main thread ends? Even if other threads are still going?
22:03:50 <boj> yes
22:04:29 <iqubic> Why is that?
22:04:35 <iqubic> Is that useful?
22:05:09 <boj> i think most languages do this. the main thread is the primary coordinator, once you lose control of that the threads probably have no sane way to stay in sync anymore
22:05:37 <iqubic> Oh. Right.
22:08:24 <geekosaur> much of it is actually the OS; the main thread owns the process, when it exits the process is reaped --- other threads therefore lose
22:08:48 <pacak> Depends on OS.
22:09:00 <parsnip> hello, trying to rely on a haskell app for an on-the-go workflow, so i'd like to bring down the install time down from what could be an hour or two. 
22:09:08 <pacak> Long time ago in a galaxy far away... TSR programs in DOS....
22:09:35 <pacak> parsnip: Statically linked binary.
22:09:49 <parsnip> maybe gzip is the way to go. (oh dear, thinking out loud, possibly answering my own question.)
22:09:54 <geekosaur> the old LinuxThreads implementation could avoid this since threads were actually processes with some amount of sharing. but this made conforming to various standards including POSIX threads effectively impossible (Linux eventually gave up and implemented POSIX threads in the kernel)
22:10:05 <parsnip> pacak: you mean just move the binary around between fresh OSes? 
22:10:38 <parsnip> docker doesn't actually speed up builds right, it still has to build? 
22:11:35 <pacak> parsnip: Right. Docker is a virtual machine without a virtual machine.
22:11:37 <boj> parsnip: well, technically it builds in layers, so you can bootstrap pretty far
22:11:54 <geekosaur> pacak, I don't count TSRs because they more or less are primitive kernel modules. the TSR process itself terminated, its memory continued in use ("TSR" - Terminate and Stay Resident) and any future use of that memory had to come about through hooking interrupts, either the DOS INT 21H or a device IRQ
22:11:56 <mud> Well, you could just distribute your thing as a docker image I guess, but I would imagine that's not generally a great idea.
22:12:11 <mud> (may not actually be correct, I find docker confusing)
22:12:35 <geekosaur> actually a fair number of things are distributed as, or at least available as, docker images these days
22:13:39 <mud> Ya, I know it's done more than occasionally, I'm just unclear when it's a good idea. I think usually when it's fairly complicated in some sense?
22:13:41 <iqubic> What is a docker image??
22:14:03 <boj> iqubic: a deep rabbit hole. avoid unless you are into devops
22:14:10 <iqubic> I'm really not
22:14:59 <geekosaur> mud, not always, if someone is using docker for development sandboxes --- common for web shops --- it's easy to roll up a dev image minus the dev tools layer. and then plug such images together to make a multi-component application server
22:15:45 <boj> parsnip: stack has a docker option which is pretty useful. it will do your full build locally in a docker container, each layer staying persistent so you can skip doing full builds. it will they dump out a binary you can copy around (if that is your goal)
22:16:10 <parsnip> but at that point, why not stick the build in s3? 
22:16:50 <boj> i don't follow
22:17:21 <parsnip> i don't see how docker helps, but then, i know next to nothing about docker. 
22:17:36 <boj> it can help reduce build times, if that is your goal
22:17:42 <geekosaur> mostly it "helps" iff you buy into the whole docker ecosystem
22:18:40 <pikajude> key word iff
22:18:40 <boj> it does more than that of course, but kind of beyond the scope of haskell
22:19:11 <iqubic> I though Stack was used for building Haskell projects.
22:19:14 <iqubic> Am I wrong
22:19:15 <iqubic> ?
22:19:20 <boj> you are correct
22:19:20 <parsnip> i am using stack
22:19:38 <parsnip> but install looks like 4 hours for hledger-web
22:19:46 <iqubic> Why the heck is that?
22:19:51 <parsnip> small VPS
22:20:03 <parsnip> how portable are binaries? 
22:20:17 <parsnip> if i build it on ubuntu 16.04, will it work on 17.04, or macos? 
22:20:24 <cocreature> definitely not macos
22:20:34 <cocreature> maybe 17.04 if you’re lucky
22:20:54 <parsnip> okay, so i build it once or twice a year and keep it in an s3
22:21:36 <parsnip> i _could_ build it in a local VM or turn up the settings on the VPS temporarily
22:22:08 <boj> if you don't need to build often those are decent approaches
22:23:31 <parsnip> nope, just want to build my habits with controlling my spending :)
22:24:04 <parsnip> i do miss haskell though, at least i've solved the RAM issue on VPS with some instructions for adding swap
22:24:33 <parsnip> sm: o/
22:26:52 <parsnip> hmm, i had a binary sitting in macos directory, it works in macos, i think i had build it in vagrant, copied it to VPS ubuntu, and it seems to work. maybe binaries work across UNIX-likes. 
22:27:42 <xormor> parsnip, some Ubuntu binaries work in Debian.
22:28:26 <parsnip> am i using the word binary incorrectly? 
22:29:10 <parsnip> s/binary/a file thingy/g
22:29:25 <vimalloc> If it's something interpreted (like a Python script) I'm not surprised that it just worked on macos and Linux. If it is actually a compiled binary I would be more surprised
22:29:50 <geekosaur> parsnip, os x doesn't recognize linux elf binaries, nor does linux recognize os x mach-o binaries
22:30:17 <parsnip> i thought i had built this file thingy with stack install in vagrant, then copied it to my host computer. 
22:30:17 <pikajude> if you built it in vagrant it's probably an elf binary yeah
22:32:06 <geekosaur> vagrant's a wrapper for a virtual machine, so decent chance it was running some linux
22:32:20 <parsnip> yes, sorry, ubuntu in vagrant
22:33:01 <geekosaur> I would not expect it to run directly in the host but I could imagine configuration that recognized it and ran it inside vagrant
22:34:22 <parsnip> no way, all i did was `scp vagrant:hledger-web .`
22:34:33 <parsnip> iirc^tm
22:35:01 <pikajude> wow
22:35:03 <pikajude> no kidding
22:35:08 <pikajude> what happens if you run `file` on it
22:35:24 <parsnip> hledger-web: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=01868c672460d8f6cc585f41b9128906d1ac6b7f, stripped
22:35:34 <parsnip> oh f, i'm sorry
22:35:53 <Axman6> @pl \(n,mv) -> case mv of Nothing -> Nothing; Just v -> object [ n .= v ]
22:35:53 <lambdabot> (line 1, column 33):
22:35:53 <lambdabot> unexpected '>'
22:35:53 <lambdabot> expecting operator
22:36:09 <parsnip> `hledger-web` is probably calling the brew version, i am deeply embarassed, but i learned it better that way
22:36:24 <Axman6> eh? o.O
22:36:39 <pacak> Axman6: { }
22:37:00 <Maxdamantus> @pl \case mv of Nothing -> case mv of Nothing
22:37:00 <lambdabot> id
22:37:45 <iqubic> Maxdamantus: id seems more straightforward
22:38:34 <geekosaur> actually I would be surprised if @pl handled case expressions in general, since patterns are prone to introduce points
22:38:37 <pikajude> yep, that's what we call an elf binary
22:39:13 <iqubic> :t maybe
22:39:15 <lambdabot> b -> (a -> b) -> Maybe a -> b
22:39:17 <geekosaur> Axman6, pikajude, also note that . is usually either absent from $PATH or at/close to the end of it
22:39:32 <iqubic> :t either
22:39:33 <lambdabot> (a -> c) -> (b -> c) -> Either a b -> c
22:39:44 <c_wraith> ...  I was going to make a dwarf of gnome joke, but they both are the names of technologies where they might reasonably be called X binaries.
22:39:51 <c_wraith> dwarf *or* gnome
22:39:56 <Maxdamantus> Security note: don't put relative paths like "." into $PATH
22:40:58 <c_wraith> for optimal security, don't even turn your computer on
22:41:29 <geekosaur> DWARF is the spec for ELF debug symbols >.>
22:41:33 <pikajude> my favorite security note is C#
22:42:17 <parsnip> or vwa, enjoy the haskell! 
22:42:56 <c_wraith> that is an odd spelling of au revior
22:43:13 <c_wraith> ... I can't spell french words either
22:43:22 <systemfault> Au revoir!
22:43:37 <pikajude> oh, that's what that was supposed to be
22:43:41 <c_wraith> I alway do that with oir in french.
22:44:26 <geekosaur> phonics?
22:44:57 <c_wraith> phonics are great when you know the language of origin for each word
22:47:33 <c_wraith> Unless the language you're speaking has mangle the original pronunciation badly, like in words like "karaoke"
22:48:24 <iqubic> care-e-o-kee
22:48:50 <Maxdamantus> carry oaky
22:49:10 <iqubic> not car-ah-oke
22:49:20 <pacak> カラオケ
22:49:21 <boj> kah-rah-oh-kay is how they say it over here in Japan
22:49:29 <cocreature> if I have a version string "5.0.0git-…" and I want to strip everything after and including "git" (if it is present), what’s the best way to do that using only "base"?
22:49:36 <c_wraith> the funny thing is the japanese pronunciation is easier. :)
22:50:21 <iqubic> It's Japenese for "Empty Orchestra" if I remember that one episode of How I Met Your Mother correctly
22:50:25 <mud> Japanese pronunciation is *very* easy compared to most languages. At least if you have the hiragana/katakana or something that maps to it.
22:50:43 <pacak> cocreature: takeWhile + isDigit?
22:50:50 <geekosaur> > span (`elem` "0123456789.") "5.0.0git-..."
22:50:52 <lambdabot>  ("5.0.0","git-...")
22:51:07 <boj> damn
22:51:11 <geekosaur> or takeWhile with that predicate, or ...
22:51:16 <cocreature> ah good point, I was looking at something to search for "git" but that seems to be annoying using only base
22:51:19 <cocreature> thanks!
22:51:26 <iqubic> geekosaur: can you also remove the git part if that exists?
22:51:39 <geekosaur> > fst $ span (`elem` "0123456789.") "5.0.0git-..."
22:51:42 <lambdabot>  "5.0.0"
22:51:51 <geekosaur> also see my comment about takeWhile
22:52:00 <geekosaur> > takeWhile (`elem` "0123456789.") "5.0.0git-..."
22:52:02 <pacak> Or mine. Also about takeWhile
22:52:02 <lambdabot>  "5.0.0"
22:52:06 <cocreature> yeah I’ll use takeWhile
22:52:22 <iqubic> Yeah, that seems to work.
22:52:56 <iqubic> Somehow I thought he wanted to strip the stuff that was the numbers + git
22:53:18 <iqubic> and leave him with only the stuff that he didn't show in his example.
22:53:23 <pacak> Japanese pronunciation is easy, everything else is not.
22:53:24 <cocreature> and I hope llvm doesn’t come up with some weird output for --version that breaks that :)
22:54:10 <iqubic> Is it possible to call arbitrary shell functions from haskell
22:54:29 <iqubic> Like shellCMD :: String -> IO String
22:55:26 <pacak> :t system
22:55:28 <lambdabot> error: Variable not in scope: system
22:55:49 <peddie> iqubic: have you considered googling "haskell call shell command"?
22:55:52 <pacak> lambdabot: (ಠ_ಠ)
22:56:06 <pacak> iqubic: No, it's impossible to call from haskell to shell.
22:56:37 <xuanrui> Unless you cross the abstraction barrier and do something unsafe I guess?
22:57:48 <tikhon> What's the canonical solution for limiting the memory usage of a Haskell program?
22:58:06 <iqubic> Well System.Process works for me.
22:58:10 <tikhon> Ideally, I want to be able to kill a thread when it goes above some memory limit.
22:58:24 <iqubic> From within the program?
22:58:24 <pacak> iqubic: Then why are you asking?
22:58:30 <iqubic> I don't know
22:58:37 <iqubic> I need to learn how to google.
22:58:38 <tikhon> from within the program, ideally
22:58:57 <iqubic> I need to stop getting answers spoon fed to me.
23:00:46 <tikhon> I found an old wiki page that suggest using some functionality from System.Posix.Resource, but I don't know if that's a good option
23:01:19 <pacak> tikhon: +RTS -M
23:02:55 <tikhon> pacak: that seems like a good option
23:03:21 <tikhon> But is there a way to do it from within the Haskell program itself? I'm not sure how reasonable that is.
23:04:30 <tikhon> I want to run a few instances of a job that might require too much memory, and only kill the ones that go over some limit.
23:06:34 <tikhon> aha, I found a relevant Stack Overflow answer, if anyone else is curious: https://stackoverflow.com/questions/42353661/may-i-limit-memory-usage-per-function-monad-thread-in-haskell
23:06:36 <tikhon> amusingly I got it from the Stack Overflow search rather than Google
23:10:05 <EvanR> yeah thats a good one
23:10:25 <EvanR> combined with other features you could use it to run untrusted code
23:10:41 <EvanR> (like lambdabot does)
23:12:49 * hackagebot fold-debounce 0.2.0.6 – Fold multiple events that happen in a given period of time. – https://hackage.haskell.org/package/fold-debounce
23:13:03 <tikhon> in this case it's mostly trust code—it just sometimes uses way too much memory :)
23:13:40 <tikhon> I am a bit worried about measuring allocation rather than the live memory usage though.
23:14:52 <tikhon> the moral of the story is that even your own code shouldn't count as "trusted"
23:17:40 <EvanR> allocation limit is really more like a time limit
23:17:49 <EvanR> rather than a memory limit
23:18:30 <EvanR> but it does serve as a grossly bounded memory limit too
23:19:30 * hackagebot wikicfp-scraper 0.1.0.9 – Scrape WikiCFP web site – https://hackage.haskell.org/package/wikicfp-scraper
23:23:22 <tikhon> EvanR: that makes sense
23:23:28 <tikhon> Is there a more direct way to measure memory specifically?
23:24:46 <tikhon> In particular, I wouldn't want to stop jobs that don't need too much memory but just happen to be really slow.
23:26:12 <tikhon> Or is trying to control memory usage like that fundamentlaly difficult or inadvisable?
23:28:02 * hackagebot wild-bind-x11 0.1.0.7 – X11-specific implementation for WildBind – https://hackage.haskell.org/package/wild-bind-x11
23:33:05 * hackagebot viewprof 0.0.0.6 – Text-based interactive GHC .prof viewer – https://hackage.haskell.org/package/viewprof
23:39:19 <trikl[m]> I'm looking for something like foldl but which returns a list of intermediate results too
23:39:51 <mud> scanl
23:40:15 <trikl[m]> Thanks mud!
23:40:29 <iqubic> I just now figured out what scanl does.
23:40:44 <iqubic> :t scanl
23:40:45 <lambdabot> (b -> a -> b) -> b -> [a] -> [b]
23:41:29 <iqubic> > scanl (*) 0 (take 5 [1,2..])
23:41:31 <lambdabot>  [0,0,0,0,0,0]
23:41:34 <pacak> iqubic: wow
23:41:37 <iqubic> > scanl (*) 1 (take 5 [1,2..])
23:41:39 <lambdabot>  [1,1,2,6,24,120]
23:42:04 <iqubic> that the list of factorials.
23:42:16 <iqubic> > scanl (*) 1 (take 5 [2,3..])
23:42:19 <lambdabot>  [1,2,6,24,120,720]
23:42:25 <iqubic> There we go.
23:42:37 <iqubic> First few factorials as found by haskell
23:52:17 <tikhon> nice thing with laziness is that we could also write that as
23:52:31 <tikhon> > take 5 $ scanl (*) 1 ([2,3..])
23:52:34 <lambdabot>  [1,2,6,24,120]
