00:45:45 <Myrl-saki> This is the first time I encountered a "no smaller than the instance head" error. I've already searched it, but I don't know exactly what causes it. What does it mean?
00:46:43 <cocreature> Myrl-saki: it means that GHC could not figure out that resolving constraints for this instance can not lead to an infinite loop
00:47:07 <Myrl-saki> cocreature: What's the fix?
00:47:10 <cocreature> Myrl-saki: this does not mean that it will lead to an infinite loop, GHC is just not very smart here so it might be totally fine and you can just turn on UndecibaleInstances
00:47:21 <cocreature> Myrl-saki: depends on your code, can you show it?
00:47:22 <Myrl-saki> cocreature: Ah.
00:47:40 <cocreature> it might be an actual bug in your code or it might be GHC being too stupid to figure out your code
00:48:00 <Myrl-saki> http://ix.io/ydf
00:48:03 <Myrl-saki> It's too simple.
00:48:06 <Myrl-saki> It should be a bug on my code.
00:48:17 <Myrl-saki> Oh right. `Discord` doesn't have an instance yet.
00:48:27 <cocreature> the problem is "MonadIO m => Discord m"
00:48:33 <cocreature> m is not smaller than m
00:48:40 <cocreature> so it could lead to an infinite recursion
00:49:10 <cocreature> if you have something like "Eq a => Eq [a]", a is smaller than [a] so you can’t run into an infinite loop
00:49:42 <Myrl-saki> Oh.
00:50:04 <Myrl-saki> cocreature: That, or `Discord m => MonadHttp m` ?
00:50:10 <cocreature> eh probably the latter
00:50:25 <cocreature> yeah the latter
00:50:30 <cocreature> but the same argument applies
00:50:53 <cocreature> imagine you had "instance MonadHttp m => Discord m" somewhere else
00:50:59 <Myrl-saki> Right.
00:51:21 <systemfault> If I want to understand the usage of "forall" in haskell, what should I google for?
00:51:38 <Myrl-saki> cocreature: Thanks.
00:51:44 <cocreature> Myrl-saki: in this case it’s probably fine and you can just turn on UndecidableInstances and hope for the best
00:52:13 <Myrl-saki> cocreature: I'll just try to write specific code then change it if it breaks.
00:52:29 <Myrl-saki> Err
00:52:38 <Myrl-saki> Slowly change it to more general if there's a need.
00:52:51 <cocreature> systemfault: there are 2 or 3 (depending on how you count) different uses of forall in Haskell so it depends on which forall you are interested in :)
00:53:17 <systemfault> Let's start with the most common usage (extensions?)
00:54:21 <cocreature> the simplest usage is ExplicitForAll https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html?highlight=explicit%20forall#ghc-flag--XExplicitForAll
00:54:27 <systemfault> If I understand what I've read so far, you can write any type signature using forall but it's only actually useful when used in conjunction with some extentions
00:54:35 <systemfault> Thanks, will read :)
00:54:52 <cocreature> no you can’t, you need at least one extension
00:55:04 <systemfault> Ah
00:55:15 <cocreature> ExplicitForAll just changes syntax it doesn’t allow you to do anything you can’t do without it
00:55:39 <cocreature> RankNTypes allows you to put "forall" in places other than the beginning of a type signature
00:56:03 <cocreature> ScopedTypeVariables allows you to refer to type variables quantified using forall in the body of a definition
00:56:21 <cocreature> and finally ExistentialTypes allows you to put forall around a constructor to get an existential
00:56:43 <systemfault> Oh wow, which one of the usage should I look at first?
00:57:11 <cocreature> it really depends on what you want to do
00:57:11 <mauke> ScopedTypeVariables, because it doesn't introduce any fancy new concepts
00:57:20 <mauke> so it's probably the easiest to understand
00:57:20 <cocreature> ExplicitForall is even simpler
00:57:25 <mauke> well, OK :-)
00:57:37 <mauke> I wasn't counting that one
00:57:52 <cocreature> ExplicitForall is a useful first step before going to RankNTypes
00:58:02 <cocreature> save ExistentialTypes for the end
00:58:11 <systemfault> Thank you
00:58:43 <mauke> :t fmap
00:58:44 <lambdabot> Functor f => (a -> b) -> f a -> f b
00:59:13 <mauke> this type uses a bunch of type variables
00:59:54 <mauke> they're implicitly universally quantified, meaning that fmap works for any types a/b/f you choose (as long as f is a Functor)
01:00:33 <mauke> we can make that explicit by writing fmap :: forall a b f. Functor f => (a -> b) -> f a -> f b
01:00:51 <Myrl-saki> This might be a bit OT, but billstclair1 seems to be a bot that just copies anyone's name.
01:01:04 <mauke> copies how?
01:01:14 <Myrl-saki> mauke: Copy in the sense that they add a suffix.
01:01:32 <systemfault> I see but until I add an extension... something other than "ExplicitForall", it's fairly useless, right?
01:01:48 <osa1> http://lpaste.net/356620 <- anyone have any intuition on why this doesn't terminate?
01:01:53 <mauke> systemfault: right
01:04:32 <cocreature> osa1: are you asking why the deadlock detection doesn’t kick in? because threadDelay maxBound will just run a long time
01:05:38 <mauke> but why doesn't it detect that it's blocked forever on an mvar and raise an exception?
01:06:05 <osa1> cocreature: the other thread that's blocked in readMVar shoud've got an exception, I think. that doesn't happen.
01:08:48 <mauke> maybe it thinks var is still live?
01:09:18 <osa1> mauke, cocreature: it fails as expected if I remove `race`
01:09:26 <mauke> oh, fun
01:09:36 <osa1> `doWork stop_ref = Right <$> (readMVar stop_ref `catch` \(e :: SomeException) -> print e)` <- this works
01:12:30 <osa1> OH
01:12:50 <osa1> hmm no nvm
01:15:23 <cocreature> hm not quite sure what’s keeping the reference alive here
01:25:07 * hackagebot cabal2nix 2.3 – Convert Cabal files into Nix build instructions. – https://hackage.haskell.org/package/cabal2nix
01:35:04 <osa1> I'd expect `race a blockForever` to by same as `Left <$> a`
01:35:07 <osa1> s/by/be
01:36:26 <sphalerite> Is there a way to encode a destructive transformation of a value, which doesn't allow reuse of the value afterwards, in Haskell's type system? Like in rust https://insanitybit.github.io/2016/05/30/beyond-memory-safety-with-types
01:37:16 <sphalerite> or C++'s std::move
01:38:33 <ReinH> Haskell doesn't have affine types.
01:39:19 <kaol> Sounds like a contravariant functor.
01:41:47 <ReinH> What?
01:42:09 <slack1256> you could make values created on a context not capable of escaping to the outer context with an existential trick like in ST
01:46:23 <ReinH> Oleg's monadic regions might be of interest http://okmij.org/ftp/Computation/resource-aware-prog/region-io.pdf
01:49:42 <ReinH> But immutability usually makes this a non-issue
01:53:37 <slack1256> any package that generates gnu GLOBAL indexes for haskell?
01:56:38 <ReinH> I think people mostly use ctags.
01:57:42 <cocreature> https://github.com/aloiscochard/codex is quite popular but I think it also only supports ctags
02:01:51 <slack1256> codex looks really nice
02:02:53 <cocreature> yeah I should start integrating it in my workflow
02:05:59 <cocreature> the great thing about codex is that it doesn’t just generate tags for your project but also for its dependencies
02:06:23 <cocreature> so you can jump to definitions in those packages really easily
02:22:54 <slack1256> that is what is says, but how does it do it? I could not have the dependencies on my system
02:23:03 * slack1256 goes to craft an example sandbox
02:23:23 <cocreature> “This tool download and cache the source code of packages in your local hackage”
02:23:40 <cocreature> it will just download them
02:53:32 <cocreature> huh, is there no monadic/applicative map for Set? it obviously can’t be an instance of Traversable but I was hoping for something specialized to Set
02:56:37 <cocreature> well, map for Set is fromList . map f . toList anyway so I guess the benefit of providing a version of mapM as well is small
02:56:57 <cocreature> a mapMMonotonic on the other hand would make sense
03:15:15 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:20:15 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:25:15 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:30:15 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:33:46 <Gurkenglas> In what situations would an unlawful Functor/Traversable instance for Set produce unexpected/inconsistent behavior? Something like traverse duplicating or fusing actions based on how many rewrite rules fire?
03:35:17 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:36:37 <Gurkenglas> :t \f -> fmap S.fromAscList . traverse f . S.toAscList
03:36:38 <lambdabot> (Applicative f, Eq a) => (a1 -> f a) -> S.Set a1 -> f (S.Set a)
03:40:15 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:45:15 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:49:39 <Myrl-saki> Gurkenglas: No Ord class? wut?
03:49:53 <Myrl-saki> :t S.fromAscList
03:49:54 <lambdabot> Eq a => [a] -> S.Set a
03:49:58 <Myrl-saki> Waaaa
03:50:09 <Gurkenglas> :t S.fromDistinctAscList
03:50:10 <lambdabot> [a] -> S.Set a
03:50:27 <Myrl-saki> :t S.fromList
03:50:29 <lambdabot> Ord a => [a] -> S.Set a
03:50:34 <Myrl-saki> This is weird man.
03:50:48 <Myrl-saki> I feel violated.
03:51:48 * hackagebot crypt-sha512 0 – Pure Haskell implelementation for GNU SHA512 crypt algorithm – https://hackage.haskell.org/package/crypt-sha512
03:51:48 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:52:58 <Axman6> those functions rely on the user forefilling the precondition that the input is prdered/ordered and distinct
03:53:49 <Myrl-saki> Axman6: Yeah.
03:55:24 <Myrl-saki> Axman6: I get that it's like that, because it's more general. But IMO it's semantically broken, because there's no concept of ascending.
03:56:29 <Axman6> eh?
03:56:35 <Myrl-saki> Axman6: In terms of human semantics.
03:57:35 * hackagebot crypt-sha512 0 – Pure Haskell implelementation for GNU SHA512 crypt algorithm – https://hackage.haskell.org/package/crypt-sha512
03:57:35 * hackagebot safecopy-migrate 0.1.0.0 – Making SafeCopy migrations easier – https://hackage.haskell.org/package/safecopy-migrate
03:58:05 <Gurkenglas> ghcjs isn't wall-clean ( http://sprunge.us/BZMe ), is it prudent to submit a pr in that direction? What about https://github.com/ghcjs/ghcjs/pull/439 ?
04:02:35 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:02:35 * hackagebot  → https://hackage.haskell.org/packages/recent
04:06:46 <SaraDR> Hi everyone! .. I'm totally new, trying to use pattern matching, well, guarding. What does the signature definition look like, if I need something to be both Num, and Ord? .. e.g. foo :: (Eq n) => n -> n -> n
04:07:09 <SaraDR> Is there no such thing as 'both', and Num already has Ord?
04:08:09 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:08:09 * hackagebot  → https://hackage.haskell.org/packages/recent
04:09:00 <SaraDR> I could guess, that the problem is I'm doing both Eq, and Or, and passing Num also includes float, which.. don't have.. Eq? Just random guessing by now lol
04:09:09 <SaraDR> Ord*
04:10:15 <Gurkenglas> SaraDR, "(Num a, Ord a) =>", but Num already implies Ord
04:10:49 <Axman6> Gurkenglas: does it still?
04:10:50 <SaraDR> Gurkenglas, yeah I kind of expected it to. But for several they are just comma seperated like that? Cool!
04:11:30 <Gurkenglas> And Ord implies Eq. Which means Float has Eq. And you can already tell how good that is.
04:12:03 <SaraDR> Comparing floating points? What could go wrong :|
04:12:18 <SaraDR> Well, thanks for the help Gurkenglas! 
04:12:27 <Gurkenglas> :t \x -> x < 2 * x -- Wait no it doesn't!
04:12:29 <lambdabot> (Num a, Ord a) => a -> Bool
04:12:38 <Gurkenglas> Damn you brain
04:12:38 <joel135> Is there a large set of haskell exercises with unit tests for checking one's answers?
04:13:38 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:13:38 * hackagebot  → https://hackage.haskell.org/packages/recent
04:13:55 <Gurkenglas> http://hackage.haskell.org/package/base-4.9.1.0/docs/Prelude.html#t:Ord "class Eq a => Ord a where" <- Ord implies Eq
04:18:38 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:18:38 * hackagebot  → https://hackage.haskell.org/packages/recent
04:20:54 <AWizzArd> Do Haskell devs regularly use Writer/WriterT? I would imagine that it is interesting for learning purposes, to study monads and transformers, but production logging could possibly use some level of IO?
04:21:32 <cocreature> AWizzArd: yeah, I never use writer
04:22:08 <cocreature> AWizzArd: the problem with using writer for logging purposes is also that you can’t stream the logs. you need to execute everything and only then you can send the logs somewhere
04:22:16 <cocreature> which is usually not what you want
04:22:18 <AWizzArd> Indeed.
04:22:18 <Axman6> Writer has significant problems too (mainly, unavoidable memory leaks) - I prefer free(r) monads for that
04:22:38 <cocreature> tbf, you can solve those using something like writer-cps
04:22:40 <riaqn> Hi, I have some question regarding conduit. I want a function f :: (a, Sink a m) -> Sink a m, for (f x s), I want to prepend x to the sink.
04:23:09 <riaqn> say f x s = t. Then I want to pipe (x ++ t) to s
04:23:30 <Axman6> do you mean to have atuple there?
04:23:34 <Axman6>  tuple*
04:23:43 <riaqn> Axman6: talking to me?
04:23:46 <Axman6> yes
04:23:59 <riaqn> no, it's just prepending x to the sink.
04:24:28 <riaqn> That is, the behaviour of t is exactly as s, except x is piped to s uncondionnally.
04:24:30 <Axman6> did you mean to write f (x,s)?
04:24:54 <riaqn> Axman6: oh yeah, sorry for the typo.
04:24:56 <cocreature> riaqn: so are you trying to implement f or are you given an f? I don’t quite understand your question
04:25:07 <riaqn> cocreature: implementing f.
04:25:22 <riaqn> I can only make it only if m is IO.
04:26:02 <pierrot> Is there any notation for the composition of a function n times? Suppose I have data Nat = Zero | Succ Nat. Then the number 3 would be (Succ . Succ . Succ) Zero. I'd like something more compact like (Succ^3) Zero
04:27:00 <riaqn> pierrot: should not hard to define your own.
04:28:00 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:28:00 * hackagebot  → https://hackage.haskell.org/packages/recent
04:28:04 <pierrot> riaqn: thanks
04:28:05 <riaqn> iter n f x = if n == 0 then x else f (iter (n-1) f x)
04:30:09 <cocreature> riaqn: how about "f (x, s) = (yield x >> Conduit.map id) .| s"
04:32:27 <riaqn> cocreature: this looks promising. The retuning type is (Sink a m), right?
04:32:35 <cocreature> yes
04:32:55 <cocreature> well "Sink a m r". Sink a m is missing a parameter
04:33:18 <riaqn> cocreature: yeah, I'm omiting details here.
04:34:23 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:34:23 * hackagebot  → https://hackage.haskell.org/packages/recent
04:34:38 <cocreature> I think hackagebot is broken
04:35:21 <riaqn> cocreature: it type checks! thanks
04:36:22 <riaqn> for some reason I forgot the existance of ConduitM, which is both capable of producing and consuming.
04:39:23 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:39:23 * hackagebot  → https://hackage.haskell.org/packages/recent
04:39:43 <cocreature> hackagebot: help
04:39:52 <cocreature> well I guess that’s not how I figure out who’s running it
04:40:00 <cocreature> ah whois
04:44:23 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:44:23 * hackagebot  → https://hackage.haskell.org/packages/recent
04:49:23 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:49:23 * hackagebot  → https://hackage.haskell.org/packages/recent
04:54:23 * hackagebot cabal2nix 2.3.1, crypt-sha512 0, safecopy-migrate 0.1.0.0
04:54:23 * hackagebot  → https://hackage.haskell.org/packages/recent
04:54:32 <ongy> should we get it kicked?
04:54:58 <cocreature> I opened an issue on github but kicking it until it’s fixed might be a good idea
04:55:18 <ongy> @where ops could you kindly remove hackagebot for now? It's a bit spammy
04:55:18 <lambdabot> byorgey Cale conal copumpkin dcoutts dibblego dolio edwardk geekosaur glguy jmcarthur johnw monochrom quicksilver Saizan shachaf shapr ski
04:55:26 <cocreature> it’s kind of ironic that the person who was running hackagebot before stopped doing so because of the same problem
04:55:38 <ongy> it being broken/spammy?
04:55:46 <cocreature> repeating itself
04:55:55 --- mode: ChanServ set +o dibblego
04:56:00 --- mode: dibblego set +q hackagebot!*@*
04:56:09 <cocreature> thanks dibblego 
04:56:13 <vektorweg1> what was the lang extension to allow sharing of (constrained) type variables in where/let clause function definitions? 
04:56:16 --- mode: dibblego set -o dibblego
04:56:24 <dibblego> np
04:56:34 <cocreature> vektorweg1: ScopedTypeVariables
04:57:36 <vektorweg1> cocreature: thank you
05:11:09 <trigone> hi, i was wondering if there was a way to avoid rewriting for every single file all of the most basic imports for the most basic libraries... but i don't want to make my own prelude, because i'd like to still be able to choose between two libraries' function, using qualified. or is there a way to export with different qualified prefixes directly?
05:12:06 <heebo> hi im using a package on hackage but i cant find the source code repo for the package, how can i find it?
05:18:40 <srhb> heebo: If it's not listed, google!
05:18:44 <srhb> heebo: Which package is it?
05:20:24 <trigone> what do you do with imports? you just write down half a page of misc imports everytime? there's no way to make it shorter?
05:21:46 <cocreature> heebo: if you want the source of a released version, there is a “Downloads” link somewhere at the bottom of the page. if you want the git repo or whatever, googling is all you can do and it might simply not be public
05:22:26 <cocreature> trigone: I use a custom prelude per project which is based on protolude + a bunch of reexported stuff specific to the project at hand
05:24:44 <michalrus> Hey! I’ve got a syntax question. How can I do this:
05:24:46 <michalrus> > let minus = liftM2 (-) in (Just 5) `minus` (Just 3)
05:24:48 <lambdabot>  Just 2
05:24:50 <michalrus> But without the binding?
05:25:00 <Axman6> trigone: many projects have a sort of custom prelude which is just a bunch of module Project.Common (module X) where; import Foo.Bar as X; import Baz.Quux as X; import Data.Text as X (Text) etc.
05:25:02 <michalrus> Like:
05:25:04 <michalrus> > (Just 5) `liftM2 (-)` (Just 3)
05:25:05 <lambdabot>  <hint>:1:18: error: parse error on input ‘(’
05:25:07 <cocreature> michalrus: you can’t do that
05:25:11 <michalrus> Oh. :(
05:25:34 <beepbeep_> I don't understand why the following results in a parse error: https://gist.github.com/aaronmu/f30bfd7f89452376b469605bd6221fce
05:26:14 <Axman6> beepbeep_: you can't indent function definitions at the top level
05:27:08 <beepbeep_> Axman6, that confuses, I have multiple function definitions in that file and they're all indented, it's only this function that is a problem.
05:27:23 <beepbeep_> Axman6, I'll paste the entire file! :)
05:28:00 <beepbeep_> Axman6, https://gist.github.com/aaronmu/f30bfd7f89452376b469605bd6221fce#file-foo-hs-L107
05:28:07 <beepbeep_> that's how the file actually looks
05:28:44 <Axman6> if that's valid, I've learned something new (please don't do that)
05:29:14 <Tuplanolla> Sure you can do that.
05:29:35 <beepbeep_> Axman6, it's all good as long as it's consistent :)
05:29:53 <Axman6> I've been wriing haskell for about 10 years, and I've literally never seen anyone do that
05:30:02 <Axman6> well, it's very inconsistent
05:30:23 <beepbeep_> consistency only exists within a context! :D
05:30:25 <beepbeep_> anyway
05:30:33 <beepbeep_> I have indented it exactly the way you like it
05:30:39 <beepbeep_> same result
05:31:02 <Axman6> and if you commont out that function?
05:31:02 <Tuplanolla> It's the empty `Char` literal, beepbeep_.
05:31:11 <trigone> thanks cocreature, Axman6. so if i do that, can i still use say X.foo of the module X that i would import in Common?
05:31:11 <Tuplanolla> There's no such thing.
05:31:18 <Axman6> oh right, well done Tuplanolla
05:31:34 <beepbeep_> Tuplanolla, yeah, it is, but how do I return an empty char?
05:31:39 <beepbeep_> or does that not exist?
05:31:41 <Tuplanolla> You don't.
05:32:00 <Axman6> trigone: if you import Common as C then you can use C.foo where foo is something exported by one of the modules imported into Common
05:32:08 <trigone> beepbeep_: use maybe to imply some absence of value perhaps 
05:32:14 <Axman6> there' no such thing as an empty Char
05:32:28 <Tuplanolla> > Nothing :: Maybe Char -- Here's the closest approximation.
05:32:30 <lambdabot>  Nothing
05:32:30 <beepbeep_> trigone, Axman6, Tuplanolla, check, I understand! :)
05:32:40 <beepbeep_> thx for the help
05:34:09 <trigone> Axman6: but then i cannot reference the old modules, everything is hidden behind Common. it's not inherently a bad thing, just, i gotta pay attention to what i imported in Common to know what function i'm using. it's okay as long as i don't require, say, both Lazy and String BS... in which case there's no real solution is there?
05:34:30 <trigone> i mean i have to import them in every module
05:35:51 <trigone> it would be great to be able to do import Common (BS, BL), and use BS and BL as prefixes that would qualify the functions of both modules imported via common
05:36:53 <trigone> is there no way to qualify with a prefix that would survive the exportation, something like BS_foo and BL_foo?
05:37:48 <Axman6> no
05:38:25 <trigone> it's a shame
05:38:35 <Clint> is it
05:39:17 <Axman6> write a proposal for an extension =)
05:40:37 <trigone> Axman6: haha i would not know how to do so. plus i heard the haskell module sys was known to be less practical than for other languages. as such, i bet there are several proposals to meliorate it (in this way or others). but of course that would mean perhaps more change than changing the way things are imported/exported
05:41:30 <Axman6> not sure if backpack is something that will help
05:42:00 <Gurkenglas> Why'd building miso fail? http://sprunge.us/ceXj 
05:42:44 <cocreature> Gurkenglas: the errom sesage seems pretty clear, you don’t have alex installed
05:42:54 <trigone> i think the sadest part is that since the import/export statements are intrinsically metaprogamming (they change the meaning of the rest of the program), i think that what is lacking is a way to create functions at that metaprogramming level. then you could compile the functions to get statically a list of imports, which would amount, in a way to CPP or perhaps templates (but i heard you could not write statements with templates, so 
05:43:47 <Gurkenglas> Ah, "fatal: program alex is required but was not found" was the relevant line. Can I make stack fix this?
05:44:12 <Tuplanolla> It's always a compromise between flexibility and amenability to static analysis, trigone.
05:44:19 <cocreature> Gurkenglas: try "stack install alex" and make sure that ~/.local/bin or wherever stack places binaries on windows is in your path
05:44:55 <cocreature> Gurkenglas: it might also be configuration error. I thought stack automatically installed some build-tools, specifically alex and happy but I might be wrong here
05:45:24 <cocreature> maybe it doesn’t work for ghcjs or something like that
05:45:24 <Gurkenglas> Ah, okay. Is it a good idea to post an issue to miso that they should add alex as a prerequisite for stack to build?
05:46:45 <cocreature> Gurkenglas: looking closer at the log, it seems to fail when setting up ghcjs not when building miso so I don’t think miso can do anything here
05:48:25 <Gurkenglas> Then I suppose if I posted an issue to miso they would have pressed some button that redirects the issue to their ghcjs dependency?
05:49:17 <cocreature> not sure what button you’re talking about
05:50:03 <heebo> thanks guys, the package is ConcurrentUtils
05:50:27 <Gurkenglas> I'm not sure either, the button is metaphorical. I infered its existence from that I would design it that way
05:50:54 <cocreature> there is no way to transfer github issues to a different repo
05:51:30 <Gurkenglas> Then I suppose the button is to tell me to post the issue to ghcjs instead :P
05:51:43 <Gurkenglas> http://sprunge.us/ANIP lol I guess I should install alex outside that project
05:52:58 <trigone> backpack seems kinda good but a bit weird too, not really what i was thinking about. i don't really get its signature thingy. seems like it would demultiply even more classes and types... but maybe i don't get exactly the type of issue it's made for
05:52:58 <cocreature> you should probably make an issue in the stack repo telling them to fix the way they setup ghcjs
05:55:10 <trigone> Tuplanolla: i did not mean dynamically defining imports based on the program's content or whatever. more like, allowing something as trivial as map (import-qualified) $ zip [ByteString, ByteString.Lazy] [BS, BL]. in other terms, writing import statements in a ... well functional style instead of that stupid imperative style :P
05:55:57 <Tuplanolla> Would you allow recursion, trigone?
05:56:19 <cocreature> that reminds me I need to try to push anthony’s shortimport syntax proposal to the new proposal process
05:56:21 <cocreature> I really want that
05:57:30 <trigone> Tuplanolla: why not, what's the problem? you'd just have to consider the statements of imports as its own little program.
05:58:00 <cocreature> trigone: so how do you import function that you want to use when defining imports? :)
05:58:06 <trigone> it's like C preprocessor: it's basically static, it's done even before the program becomes something else than pure string (unless i'm wrong)
05:58:14 <Tuplanolla> Will such programs terminate and how much memory will they need, trigone?
06:00:00 <trigone> Tuplanolla: actually, in which case would you need recursion? as for memory... well it's compile time, everything's permitted! just kiddin. i don't really get why there would be any trouble given that basically the only thing that preprocessor would have to do is generate a small list of strings, each one being an import. hardly the heavy work thing, would it be
06:00:51 <Tuplanolla> Someone would implement Brainfuck with it and then the compiler would catch fire.
06:01:26 <Gurkenglas> Kay, posted an issue to stack, https://github.com/commercialhaskell/stack/issues/3243
06:01:42 <cocreature> well we already have TH so I’m not sure that would actually make things worse
06:03:23 <cocreature> the “you can now no longer guarantee that compilation terminates”-argument is a strawman. if you actually care about things terminating, you need some kind of timeout anyway since you want it to terminate within a somewhat reasonable timeframe
06:03:23 <Tuplanolla> I still agree that there should be some sort of uniformity across different stages of execution.
06:04:29 <Tuplanolla> Unfortunately no language I know has six compilation stages with first-class modules.
06:06:00 <Tuplanolla> (Metaprogram and "actual" program compilation and execution on both host and target systems.)
06:08:57 <Tuplanolla> Eight, even, if jit compilation is added to the mix.
06:09:42 <trigone> Tuplanolla: yet that would be trivial to implement. we could do as C does with CPP: every metaprog code is commented with a special symbol, hash or otherwise. mind you, the task is so trivial i doubt you would need a whole small language. a couple of functions would do, which in truth would mostly amount to a more terse way to import. and if someone implements brainfuck nonetheless, i doubt it will be for production usage! ^^
06:10:23 <cocreature> trigone: if you want cpp, you can just use cpp in Haskell :)
06:10:27 <trigone> in fact the issue is not about allowing functions, because in truth there's virtually nothing to do, and using zip or map would only separate things that should really be side by side for clarity
06:10:41 <trigone> cocreature: i don't want cpp :P or at least i don't think so...
06:11:03 <Tuplanolla> The thing is that we don't follow the "wrong results fast" philosophy here, so things that don't have good foundations don't get implemented, trigone.
06:19:09 <Myrl-saki> Errr...
06:19:15 <pierrot> riaqn: I finally defined an infix operator (#) :: (a -> a) -> Int -> (a -> a) such that f#n = if n==0 then id else f . (f#(n-1))
06:19:21 <Myrl-saki> `handleHttpException :: HttpException -> m a ` under a class.
06:19:30 <Myrl-saki> How do I do that?
06:19:31 <pierrot> then I did things like (Succ#3) Zero
06:19:36 <Myrl-saki> There's no a anywhere else.
06:22:49 <Gurkenglas> cocreature, what's obviously the culprit this time? http://sprunge.us/eKCX 
06:22:58 <trigone> i think the best would be to use a block instead of a line-by-line isolated statement. it would just mean rewriting, but honestly even for readability: 
06:24:00 <trigone> Tuplanolla: why do you say that? i did not say, let's all jump into the sinking ship, i just said "what if...". i'm firmly of the opinion that, if at the implementation time, you need to be rigorous and ruthless, at the time of having ideas, you gotta allow any idea the time to prove itself or not :)
06:24:16 <trigone> here's my idea of a better import syntax: https://pastebin.com/Pr75rfbG
06:25:33 <Myrl-saki> Gurkenglas: I'll have to ask.
06:25:38 <Myrl-saki> Gurkenglas: How does it feel to be programming in C?
06:25:43 <Myrl-saki> Gurkenglas: s/C/Windows/
06:26:55 <Gurkenglas> Whenever I don't have to use terminals its fine, whenever I have to use terminals it's as bad as when I try to use terminals in Linux, and Windows pretty much only requires me to use terminals when I'm doing something that's made by and for Linux people.
06:27:22 <Myrl-saki> You know.
06:27:32 <Myrl-saki> I think I should try not using Vim/Emacs.
06:28:28 <trigone> i'm laughing out loud, what's happening: The group you are attempting to view (Haskell-cafe) has been identified as containing spam, malware, or other malicious content. Content in this group is now limited to view-only mode for those with access.
06:28:40 <trigone> tha's what google tells me
06:29:42 <trigone> you know, when i see pages and pages of import/exports, i'm tempted to think that we should separate those things in a file right beside, and merge both when the time comes to compile...
06:29:56 <trigone> a tiny bit like .h and .c (i said tiny)
06:30:24 <mnoonan> Does anybody know what became of the GSOC project to make a SWIG module for Haskell?
06:30:29 <Gurkenglas> trigone++, the more we act like it's obvious that the programmer shouldn't be manually assembling the imports the sooner someone might be tricked into writing something that brings that about
06:31:07 <ongy> and then you realize that namespaces clash
06:31:12 <Myrl-saki> Gurkenglas: What editor do you use?
06:31:58 <Gurkenglas> Myrl-saki, about a month ago I started using emacs, before that I used notepad and lpaste and lambdabot's query
06:32:13 <Myrl-saki> Oh.
06:32:38 <Gurkenglas> Every few months I tried to set up some sort of haskell ide and failed horribly
06:32:39 <ongy> that sounds like fun
06:33:01 <ongy> how many did you try? the only one I know of (that's not editor+tools) is leksah
06:33:26 <Myrl-saki> ongy: I've worked with both Vim and Emacs.
06:33:36 <Myrl-saki> ongy: I find Emacs's integration to be top notch as always.
06:33:41 <Gurkenglas> leksah and atom and sublime-text and intellij
06:33:45 <ongy> if only emacs had a nice editor :)
06:33:49 <maerwald> haha
06:33:50 <trigone> Gurkenglas: i agree. sometimes i hate sugar syntax, but sometimes it's just a question of having chosen haskell for it being terse... and finding out pages of imports for every single middle size library... it's weird
06:33:52 <ongy> intellij works with Haskell?
06:34:08 <maerwald> some say sublime is nice as well with haskell, I remember Cale using it
06:35:07 <Myrl-saki> Wait, what does leksah use?
06:35:10 <Myrl-saki> rendering.
06:35:18 <Gurkenglas> <ongy> and then you realize that namespaces clash <- most nameclashes don't clash on the types, and lots of the time you use more than one identifier from the same module, so it should be possible
06:35:46 <trigone> does anybody know why haskell-cafe is tagged to be malware-filled by google?
06:36:06 <Gurkenglas> (intellij and leksah and sublime-text and atom and emacs in ascending order of how far I got with them)
06:36:54 <maerwald> it's sad that the yi backend in leksah is most of the time broken afair
06:36:57 <maerwald> unless that changed
06:37:01 <maerwald> because the GtkSourceEditor sucks
06:37:36 <Gurkenglas> Why doesn't stack build miso here? http://sprunge.us/eKCX 
06:38:39 <Gurkenglas> (I mv'd https://github.com/dmjio/miso/blob/master/stack/ghcjs801/stack.yaml into the top level)
06:40:37 <Gurkenglas> Could we use codex to have go-to-definition when viewing .hs files on github?
06:55:08 <cocreature> Gurkenglas: System.Posix.Signals is in the unix package which doesn’t work on windows (who would have thought). but I’m not sure why it tries to use this
07:46:54 <AWizzArd> Is MonadPlus roughly a Monad that also is a Monoid?
07:54:53 <Eduard_Munteanu> AWizzArd, not exactly... it is a monoidal structure but not in the typical sense. If you know Alternative it's just like that.
07:55:23 <bollu> cocreature ping
07:55:31 <bollu> dude, building LLVM IR in haskell is super painful :(
07:55:46 <bollu> I'm actually tempted to swith to C++ just because I have IRBuilder
07:56:08 <Eduard_Munteanu> > Nothing `mplus` Just 'a'
07:56:10 <lambdabot>  Just 'a'
07:56:26 <Eduard_Munteanu> > Nothing `mplus` Just 'a' `mplus` Just 'b'
07:56:29 <lambdabot>  Just 'a'
08:00:05 <cocreature> bollu: pong
08:00:15 <bollu> cocreature is there an IRBuilder like interface?
08:00:27 <cocreature> what exactly do you mean by that?
08:00:31 <cocreature> but the answer is probably no
08:00:44 <bollu> cocreature well, the LLVM IRBuilder style of building the IR is very pleasant
08:01:02 <bollu> so you can mimic that with some monadic interface that maintains some state: what's the current basic block, etc. 
08:01:43 <bollu> cocreature something like this, perhaps? https://github.com/bollu/tiny-optimising-compiler/blob/master/src/ProgramToIR.hs#L160
08:02:02 <cocreature> right, most people seem to build their own monadic interfaces on top of llvm-hs. I’m not yet sure if there is really something that works for all of them so for now I’m fine with leaving this to user code
08:02:17 <bollu> :( I see
08:02:22 <bollu> cocreature is there anything I can steal? :D
08:02:26 <bollu> cocreature from some other project
08:03:24 <cocreature> veggies has something
08:07:38 <AWizzArd> Eduard_Munteanu: okay good, I will then have a look at `Alternative` first.
08:09:08 <hc> any recommendation for a stable haskell ide that runs well on either osX or nixos? (-:
08:10:16 <nicootto> Hi guys, can someone tell my why "((+1).)id 1" works fine but "(+1).id 1" doesn't (I don't understand the error console shows)  
08:11:03 <hc> insert a $ in front of the 1
08:12:26 <hc> it's a problem of operator precedente, I think. You're calling (+1) with 3 parameters in the second case
08:12:46 <hc> *precedence
08:13:09 <Tuplanolla> Think again.
08:14:23 <Eduard_Munteanu> nicootto, ((+1).) id 1   is  (\y -> (\x -> x + 1) . y) id 1   while the other is   (\x -> x + 1) . (id 1)
08:15:56 <Eduard_Munteanu> The latter is pretty much (\x -> x + 1) . 1 so it probably says it can't convert a number literal to a function
08:17:12 <Eduard_Munteanu> > (+1) . 1
08:17:14 <nicootto> Thanks you all. I'll take a carefully look to those lambda expressions and try to understand how it works, I'm missing it 
08:17:14 <lambdabot>  error:
08:17:14 <lambdabot>      • No instance for (Typeable a0)
08:17:14 <lambdabot>          arising from a use of ‘show_M533761613214151206927307’
08:17:50 <Eduard_Munteanu> nicootto, remember that function application binds tighter than any infix operator
08:19:14 <Eduard_Munteanu> Only record syntax binds tighter than function application.
08:21:25 <nicootto> Ok, I get that, thanks!! 
08:21:58 <Gurkenglas> I hear stack doesn't build miso here ( http://sprunge.us/eKCX ) because unix doesn't build on Windows. Is there a way around that? Where in miso's dependency tree is unix?
08:32:52 <tsahyt> When working with JSON data using aeson, and objects that have fields named id or some other common name, is there a way to define records with prefixed accessor names and still generate ToJSON/FromJSON instances that do not emit/consume the prefix?
08:33:27 <tsahyt> e.g. Foo { fooId :: Int }, Foo 10 --> { id : 10 } --> Foo { fooId = 10 }
08:34:49 <cocreature> tsahyt: yes, use genericParseJSON and customize the options
08:47:26 <tsahyt> cocreature: thanks!
08:48:27 <deech> Hi all, does anyone know where I can find a full specification of where Haskell supports explicit character curly-brace-semi-colon syntax?
08:49:01 <bollu> is this type illegal? data Log = Log { unLog :: [forall a. Doc a] } deriving(Monoid)
08:49:05 <bollu> if so, why?
08:51:48 <cocreature> bollu: it’s illegal because the b in [b] and "forall a. Doc a" don’t unify. that’s called impredicative types and while we have an extension of that name in GHC it’s almost completely broken so it probably doesn’t help
08:52:29 <ph88> hey guys
08:53:06 <ph88> can i name my modules whatever i want ? or should i namespace them ?
08:54:32 <bollu> hm, I see
08:54:34 <bollu> unfortunate
08:54:38 <bollu> cocreature any workarounds?
08:59:26 <cocreature> bollu: make a newtype
08:59:37 <cocreature> newtype Foo = Foo (forall a. Doc a)
08:59:40 <bollu> ahh
08:59:47 <bollu> cocreature so that the b in [b] can unify with Foo?
08:59:54 <ph88> hi cocreature i finished my function with the vector offset thing, you wanna see ?
09:00:07 <cocreature> yep because Foo s no longer quantified
09:00:13 <cocreature> ph88: sure why not :)
09:00:20 <Gurkenglas> Could ImpredicativeTypes be implemented using RankNTypes by first desugaring all data declarations to constructions of (->)? Like [a] is forall b. (a -> b -> b) -> b -> b
09:01:11 <bollu> cocreature I see
09:01:17 <bollu> cocreature that's.. weird, though? I don't understand
09:01:24 <bollu> cocreature what's the actual typechecking problem
09:01:31 <bollu> if it can infer b ~ Foo ~ forall a. Doc a
09:01:46 <ph88> cocreature, https://bpaste.net/show/f3452a042c4a i didn't really clean it up that well .. i think i'm not even going to use it. Because i have another algorithm giving the exact same results which is half the size in lines of code and it has the same performance
09:02:31 <ph88> i thought this one might be faster but it's not :(
09:02:32 <cocreature> bollu: the "forall a. Doc a" part is in the Foo _constructor_ not the Foo _type_.
09:02:49 <cocreature> bollu: but I’m not too familiar with the problems with impredicative types myself
09:04:24 <bollu> right
09:04:29 <bollu> cocreature ah
09:04:35 <bollu> cocreature I see
09:04:47 <bollu> @tell quchen: simplexhc moved to prettyprinter :) 
09:04:47 <lambdabot> Consider it noted.
09:06:09 <tsahyt> @hoogle (Monad m, Foldable t) => (a -> m [b]) -> t a -> m [b]
09:06:10 <lambdabot> Control.Monad foldM :: (Foldable t, Monad m) => (b -> a -> m b) -> b -> t a -> m b
09:06:10 <lambdabot> Data.Foldable foldlM :: (Foldable t, Monad m) => (b -> a -> m b) -> b -> t a -> m b
09:06:10 <lambdabot> Monad foldM :: (Foldable t, Monad m) => (b -> a -> m b) -> b -> t a -> m b
09:14:02 <Phyx-> Gurkenglas: likely you can replace things from unix with base or process
09:22:09 <Darwin226> Hey guys. Say I have a GADT with a type parameter of some kind K and each constructor is tagged with a distrinct type of kind K. Is there a way to optimize away the construction/deconstruction? Basically treat every constructor as a newtype
09:25:32 <dredozubov> Darwin226: what do you mean by "optimize"? Are you referring to runtime boxing? I'm not sure I understand what you mean.
09:26:16 <Darwin226> dredozubov: Yes. Basically, each of those constructors could be represented as a separate newtype and then there wouldn't be any runtime overhead in using them
09:26:33 <Darwin226> but for various reasons it makes sense to put the in the same GADT and tag them with unique types
09:26:58 <dredozubov> you can't do that with GADTs or ADTs
09:27:45 <Darwin226> dredozubov: Maybe not directly but perhaps there's some unsafe magic that can be done?
09:28:28 <lyxia> define a newtype hide its constructor, expose pattern synonyms.
09:31:33 <lyxia> you will need unsafeCoerce, you may have trouble with existentials, and many will say not to do it
09:32:32 <Darwin226> I'm not sure I get what you mean
09:32:51 <Darwin226> Can pattern synonyms "mimic" a GADT?
09:33:53 <lyxia> actually no it won't work. :/
09:36:44 <cocreature> I vaguely remember seeing some weird tricks for simulating GADTs with pattern synonyms
09:40:29 <srpx> A class w/ join and fmap is equivalent to Monad right?
09:40:43 <srpx> And pure
09:41:02 <monochrom> Yes.
09:42:02 <monochrom> m >>= k = join (fmap k m)
09:42:27 <srpx> monochrom: just making sure ty :)
09:43:13 <Gurkenglas> Phyx-, I don't even know where it uses unix
09:43:43 <Gurkenglas> Is there a tool that shows me the dependency tree of a package?
09:46:59 <Phyx-> Gurkenglas: just remove the unix and see where it fails :)
09:49:46 <geekosaur> Gurkenglas, ghc-pkg dot?
09:49:49 <cocreature> the error is coming from GHCi/Signals so I think the problem occurs when stack tries to setup ghcjs not in miso or any of its dependencies
09:49:50 <Gurkenglas> Phyx-, how do I "remove the unix"? The thing that says "unix" is the build failing at a module from the unix package
09:51:19 <cocreature> Gurkenglas: https://github.com/ghcjs/ghcjs/issues/559
09:51:32 <cocreature> and https://github.com/ghcjs/ghcjs/issues/548
09:51:36 <Phyx-> Gurkenglas: I assume miso is a package? just remove it from the cabal file
09:51:45 <cocreature> looks like you’re out of luck unless you want to fix ghcjs
09:51:52 <Gurkenglas> unix isn't in miso's cabal file, I assume its in a recursive dependency
09:52:06 <Gurkenglas> "stack exec ghc-pkg dot" says "GHCJS does not yet have its boot packages installed.  Use "stack setup" to attempt to run ghcjs-boot.", looks like ghcjs is failing, not miso
09:52:14 <cocreature> the problem has nothing to do with miso directly, it’s in ghcjs
09:52:24 <cocreature> miso just results in stack trying to build ghcjs
09:52:29 <cocreature> and apparently that doesn’t work atm
09:53:09 <Phyx-> hmm ok
09:54:20 <Gurkenglas> Sounds like it could work with <8.0 ghc
09:56:46 <Phyx-> I don't understand why those modules are failing though
09:57:02 <Phyx-> though I don't get the build process of ghcjs
10:02:28 <seashell> hi?
10:02:57 <Myrl-saki> Hallo?
10:10:28 <dmj`> yea  getting ghcjs is going to be tough w/o nix
10:11:17 <dmj`> miso is on hackage but it might not have hit a channel yet
10:11:19 <dmj`> nix-shell -p 'haskell.packages.ghcjs.ghcWithPackages (p: with p; [ miso ])'
10:11:26 <dmj`> should be all that’s needed to get an environment
10:13:41 <dmj`> Gurkenglas: if you clone it, then call nix-build it should build everything including tests + examples, (examples might fail if you’re on osx though, since I think the phantomjs derivation is still broken — so that can be commented out).
10:15:00 <dmj`> Gurkenglas: if you want to use stack, I’ve had luck with this stack.yaml file, https://github.com/dmjio/miso/blob/master/stack/ghcjs7103/stack.yaml
10:15:03 <Gurkenglas> dmj`, are you aware that I'm on Windows?
10:15:13 <dmj`> Gurkenglas: no, I was not :) 
10:16:04 <dmj`> Gurkenglas: but if stack can acquire ghcjs on windows it should be possible it seems 
10:16:26 <Gurkenglas> Can I tell stack to use some sort of cache strategy instead of either running stack clean or not?
10:19:06 <dmj`> Gurkenglas: I’m not sure, everytime I’ve installed ghcjs from stack, it had to do a full rebuild
10:19:15 <dmj`> er, a full build of ghcjs itself
10:21:22 <Gurkenglas> I think I wasn't clear: stack in general is using a lot of hard drive space for the packages it's built in order to hasten build times. I could run stack clean and go back to the other extreme of that trade-off. Can I tell it to choose some other point on the space-speed tradeoff curve?
10:21:42 <Gurkenglas> *the spacetime curve :)
10:22:19 <cocreature> no
10:22:53 <cocreature> also stack clean will only clean your local packages not dependencies so it might not save as much space as you would like
10:23:12 <Gurkenglas> Am I making sense in thinking that it should be able to get ~80% of the speedup with 20% of the space, given an appropriate caching strategy, such that this is merely not implemented?
10:23:48 <Gurkenglas> cocreature, even if I run stack clean outside a project?
10:24:08 <monochrom> You are making sense. Send a pull request.
10:25:25 <cocreature> Gurkenglas: I don’t think stack clean does anything outside of a project. maybe it cleans extra-deps that you specified in your global project but that should be it
10:28:28 <Gurkenglas> Shouldn't I make an issue instead? Having the guy who thought of it and the one who implements it the same person misses out on Ricardian advantage
10:29:29 <cocreature> there is an issue for a "stack gc" command somewhere which seems related
10:31:40 <Gurkenglas> Hm, I suppose LRU would be a fine strategy, implying I can just sort the directory where stack keeps its prebuilt stuff by timestamp and delete a half.
10:33:37 <Gurkenglas> Because to minimize total time used in the future, you want to throw something out iff it'll never again be used, which sounds like the one that hasn't been used for the longest time. Is space taken always proportional to time required for building?
10:36:17 <Gurkenglas> Because if 80% of the space is taken by packages that would take 20% of the time to rebuild, that's what we'd want to throw out
10:38:00 <geekosaur> not always proportional, no. TH tends to make a big time bump for relatively little size bump
10:38:16 <geekosaur> and is the sort of thing you really want to cache in most cases
10:48:47 <lamefun> Why are laziness space leaks even a problem? Can't the runtime simply start evaluating stuff when things get out of hand?
10:49:56 <geekosaur> evaluating stuff *is* the problem
10:50:00 <monochrom> Will it terminate?
10:50:11 <geekosaur> eval this - wait I have to do this first - wait I have to do this first - ... BOOM
10:50:22 <monochrom> That too.
10:50:32 <geekosaur> (each "wait I have to..." putting something on the pattern stack to come back to later)
10:51:48 <monochrom> My view is heretic and unpopular. Why is it even called space leak?
10:52:19 <geekosaur> and while you might go work out the leaves and force those first, that can defeat sharing and give you a different space leak
10:52:29 <monochrom> But programmer terminology is a whole history of blaming something else.
10:53:25 <monochrom> If my mistake causes a wrong answer, it is called a bug. If my mistake causes too much space, it is called a leak.
10:53:31 <geekosaur> also if this is regarding excessive sharing, just evaluating stuff won't clear up the space
10:53:32 <monochrom> It is never my fault.
10:53:38 <kadoban> monochrom: What should it be called instead?
10:54:03 <monochrom> MEA CULPA
10:54:48 <Tuplanolla> Physics analogy: it's not a leak since the process is reversible.
10:55:21 <monochrom> Actually I don't quite understand why it is reversible, but heh.
10:55:43 <Tuplanolla> You don't lose the pointer, so waiting long enough should resolve it.
10:55:53 <monochrom> Ah! That.
10:57:55 <lamefun> Will {-# LANGUAGE Strict #-} become default soon then?
10:58:27 <monochrom> No.
10:58:47 <ongy> what does that do?
10:58:49 <geekosaur> lamefun, will other languages make infinite loops impossible soon then?
10:59:11 <geekosaur> the language cannot think for you, the language cannot solve the halting problem for you, do not blame the language
10:59:22 <monochrom> Even the tamer StrictData is nowhere near becoming default soon. And it already has an ardent supporter.
11:00:17 <lamefun> Can I make infinite loops impossible in Haskell? Is there an extension for that?
11:00:54 <monochrom> This is not going well.
11:00:59 <geekosaur> no, no it is not
11:01:13 <Clint> are we in an infinite loop
11:01:16 <drdo> No extension need. f = f
11:01:18 <monochrom> But {-# LANGUAGE NoStrict #-} makes fewer infinite loops.
11:01:27 <drdo> Oh *impossible*
11:01:35 <cocreature> monochrom: how so?
11:01:40 <monochrom> Laziness!
11:01:47 <cocreature> oh I missed the No
11:01:52 <monochrom> hehe!
11:01:52 <cocreature> and was very confused for a moment
11:02:19 <monochrom> {-# LANGUAGE NoNoMonomorphismRestriction #-} :)
11:02:48 <drdo> It's certainly possible to make a language that makes infinite loops impossible
11:03:09 <geekosaur> it's just not going to be very useful
11:03:11 <drdo> What's hard is making a language that lets you express lots of things while still retaining that property
11:03:12 <monochrom> Laziness has space leaks. Eagerness has time leaks.
11:03:24 <monochrom> Actually even that is an oversimplification.
11:03:26 <Tuplanolla> @google coq -"au vin"
11:03:27 <lambdabot> https://coq.inria.fr/
11:03:27 <drdo> geekosaur: Why not?
11:03:40 <Tuplanolla> May I interest you in this language, lamefun?
11:03:48 <lamefun> monochrom: but if a program wastes 10 mins, it can still run after that, but if it wastes 10GB and the OS has less, it will crash.
11:04:20 <monochrom> "print (map sin [1..n])" This is O(1) space in lazy Haskell, Ω(n) space in eager SML. I call eager SML a space leak.
11:04:35 <monochrom> TIME IS MONEY
11:04:44 <geekosaur> drdo, consider that most programs that take input do so until an external trigger (usually the end of a data stream) tells them to stop. from the program's standpoint, this is an infinite loop; it cannot tell when, or even if, the stream will end
11:04:53 <monochrom> money that can buy more RAM.
11:05:15 <TristanBKildaire> Downloadram.com
11:05:23 <drdo> geekosaur: so? that can easily be isolated to a very small part of the program
11:05:37 <monochrom> My hourly salary is about $40. If you make me wait one hour, you lose the opportunity cost of buy a gig or two of RAM.
11:05:55 <TristanBKildaire> Sorry I meant this http://www.downloadmoreram.com/download.html
11:06:04 <geekosaur> drdo, the read itself maybe, but what of the knock-on effects? for most people, that's the meat of the program
11:06:21 <drdo> geekosaur: I have no idea what you are on about
11:06:28 <geekosaur> and where your infinite read becomes possibly infinite space or possibly infinite processing
11:06:45 <geekosaur> drdo, then you need to think things through a bit better
11:09:05 <lamefun> What are knock-on effects?
11:09:16 <c_wraith> geekosaur: you can still do things like what several of Conor McBride's languages do.  Make IO codata, check for termination over data and productivity over codata
11:09:46 <monochrom> drdo, my inexperienced perspective is that the Kleene recursion theorem already states that every program "can be" rewritten into this somewhat normal form: Only one potentially infinite loop (at most) as the outermost loop; inside you have a terminating program, it is guaranteed because the inside is a primitive recursive function.
11:10:13 <monochrom> And now the fact that you never rewrite your actual code into this form says something about ergonomics.
11:10:27 <monochrom> I.e., does this form even look natural?
11:10:47 <c_wraith> monochrom: isn't that basically Node.js?
11:10:58 <monochrom> har har har  hehehe
11:11:37 <monochrom> I'm afraid not. In the loop body, you still use general javascript, not primitive recursive javascript.
11:12:57 <drdo> monochrom: I think it's fairly straightforward for most programs
11:13:10 <drdo> In fact, that's usually done in practice for simple organisation
11:13:20 <c_wraith> drdo: but not at all pleasant.  you end up creating giant state machines
11:13:28 <monochrom> Yes and no.
11:13:32 <c_wraith> drdo: which is the source of my joke about node.js
11:13:50 <drdo> I don't use node.js
11:13:56 <drdo> Or even know how it is
11:14:01 <monochrom> Suppose your whole program consists of 10 parts. FSVO parts.
11:14:13 <monochrom> I am pretty sure that each part is in Kleene normal form.
11:14:25 <drdo> FSVO?
11:14:32 <c_wraith> (for some value of)
11:14:36 <drdo> right
11:14:38 <monochrom> I am also pretty sure that you keep it 10 Kleene normal forms but not merge them into one single Kleene normal form.
11:15:36 <monochrom> And so the Monochrom Fractal Theorem implies that you will want a pervasively-general-recursive language anyway.
11:15:54 <drdo> monochrom: Clearly haskell is a counterexample to your claim
11:16:02 <monochrom> (The Monochrom Fractal Theorem states that your program organization is fractal.)
11:16:08 <drdo> If you substitute this normal form with purity
11:18:02 <Lokathor> so
11:18:07 <Lokathor> do folks still use return?
11:18:16 <monochrom> I think I do.
11:18:17 <Lokathor> or have we all switched to pure?
11:18:45 <geekosaur> depends on whether you cre about backward compatibility or not
11:18:57 <Tuplanolla> Always `pure` for new stuff.
11:18:59 <monochrom> You are encouraged to use "pure" in new code. Don't worry about religiously cleansing "return" in old code.
11:19:27 <monochrom> But "return" is here to stay, so don't worry about using it in new code either.
11:19:34 <nshepperd_> You can put your program in kleene normal form by turning it into an interpreter that runs the original program, with each loop iteration executing a single instruction
11:19:56 <monochrom> AMP Wars Episode 6: The Return of Return
11:19:59 <c_wraith> nshepperd_: sounds like building a giant state machine to me.
11:20:03 <nshepperd_> This doesn't make your job easier in any way whatsoever
11:21:50 <monochrom> I recently did something along the same line. Turn a non-tail recursion into a loop plus stack.
11:22:00 <monochrom> via CPS then defunctionalization!
11:22:10 <Lokathor> so here's the thing: I'm not sure why "use 'pure' in new code" is much of a strong argument
11:22:57 <nshepperd_> I think building a giant state machine is unhelpful in pretty much the same way. You're just turning direct code into "indirect" code, without necessarily illuminating anything about the termination properties you actually care about
11:22:59 <monochrom> I have a weak argument. It's nice to shrink terminology.
11:22:59 <Lokathor> like, unless there's a plan to *cut return from the definition of Monad* then it seems fairly pointless, particular when your block is for a particular type
11:23:07 <fresheyeball> what is more like the empty set? () or Void ?
11:23:29 <Tuplanolla> It's shorter and allows you to pretend that `return` has been deprecated, Lokathor.
11:23:54 <Lokathor> maybe i'll use pure some of the time
11:24:10 <Lokathor> when I can get those sick ApplicativeDo desugarings going on
11:24:30 <monochrom> Yeah "pure" is shorter :)
11:24:53 <monochrom> Also it's nicer to require beginners to just learn one word "pure" at the beginning.
11:25:11 <monochrom> fresheyeball: Void.
11:25:21 <Lokathor> well they're going to see "return" in code they look at, almost assuredly, so they might as well learn it also
11:26:00 <monochrom> Better later than sooner.
11:26:46 <Lokathor> perhaps we should take out return in GHC 12.6
11:27:25 <fresheyeball> monochrom: thanks
11:27:44 <fresheyeball> I was getting confused to whether the empty set conceptually could also be treated as a value
11:28:33 <Lokathor> my tutorial only uses return in two places, i suppose i could make it be pure instead
11:28:34 <monochrom> Set theory is the world's first dependent typing system.
11:30:49 <Lokathor> @src (.)
11:30:49 <lambdabot> (f . g) x = f (g x)
11:30:53 <Lokathor> :t (.)
11:30:55 <lambdabot> (b -> c) -> (a -> b) -> a -> c
11:47:42 <haski> Hi all, is there a way to save save values within a global variable?
11:48:39 <ahri> hi, i'm trying to run '$ stack install apply-refact' and it needs GHC 8.2, i tried with the nightly and lts-8.8 resolvers but i still can't get it to install. am i misunderstanding something?
11:48:52 <Lokathor> haski, there is such a way. why do you want to do this?
11:49:31 <Lokathor> ahri, i think lts 8.8 is GHC 8.0
11:49:53 <haski> Lokathor i've a function where its not allowed to change the parameters. And i would like to print a binary tree and add a "-" for every additional level.. so i would like to save the current level
11:50:25 <haski> and depending and that level print the corresponding number of "-"
11:50:34 <Lokathor> ah, what does your function look like? the one you can't change the paramaters of? and have you considered writing a sub-function that you can pass your own paramaters to?
11:51:09 <Lokathor> generally, adding a global variable is a harsh crime, and 5 years in the gulag if you don't have a very good reason for it
11:51:17 <ahri> Lokathor: hm, is there some clever way in which i can find out which lts correlates to a given version of GHC?
11:51:49 <Lokathor> ahri, https://www.stackage.org/ has a little bit in the bottom left, it lists the latest lts for each recent GHC
11:52:08 <geekosaur> ahri, ghc 8.2 isn't eve released yet
11:52:15 <ahri> huh, i must've missed that
11:52:23 <geekosaur> there's a release candidate
11:53:13 <ahri> geekosaur: that was the second part of my puzzlement... googling for ghc 8.2 only turned up candidates. i wonder then why apply-refract's released version depends on it
11:54:28 <ahri> and given that the latest lts only supports 8.0.2, how on earth can i install it?!
11:55:52 <ahri> its github page specifies 'stack --resolver=nightly install apply-refact' as the installation command, but this doesn't work as nightly only has 8.0.2 in it
11:56:21 <kadoban> ahri: You'd have to install that version of GHC yourself and then either use the ghc-only resolver for that, or use whatever the newest nightly/lts is and config it to be able to use your GHC version.
11:57:07 <kadoban> ahri: Is there an older version that doesn't require GHC 8.2?
11:58:25 <ahri> kadoban: i'll check that next. i'm not going to install a candidate and mess around just for one package!
11:59:23 <kadoban> Ya, I wouldn't either.
12:07:54 <d34df00d> Hi!
12:08:22 <d34df00d> I asked a couple of days ago about a mutable vector of mutable vectors - thanks for help, that indeed worked, and gave something like 1.5-2x speedup for my task!
12:08:31 <d34df00d> But now I have a couple more questions.
12:09:26 <CodeWeaverX> Greetings.... I've been putzing around with GHC primops.  Used to be that functions like (<#) used to return a boolean... now they return an int.  I could once use them in pattern guards, but no longer... what's the best practice for this?  case statements?
12:09:53 <d34df00d> 1. Doing `traverse Data.Vector.unsafeFreeze <=< Data.Vector.unsafeFreeze` apparently freezes the outer vector first, and then traverse has to do its job in a usual immutable way. Is that correct? If so, is there a way to freeze the inner vectors first? I ask as now 'traverse' shows as top CPU consumer in the profile, and it's also responsible for ~10% of allocations.
12:12:08 <d34df00d> 2. The general problem I'm solving is, having some form of an expression tree defining a state machine, I try to build a transitions table for it. So, I recurse down that tree and prepend tripled (State, Input, State) to a usual list (prepending should be very fast), and once I'm done I collect everything I've pushed into one giant vector of vectors (indexed by source state, with the value being a vector of (Input, State) pai
12:13:09 <d34df00d> ski: oh, you're here, and you helped me last time, hence pinging you!
12:13:29 <monochrom> I desperately need an alternative [x..y] syntax such that it excludes y.
12:18:08 <CodeWeaverX> Ahh, found the trac ticket involving the primops change.  Interesting.
12:19:25 <TristanBKildaire> I think I will learn some Haskell these holidays whilst I am abroad. Starting with Learn You A Haskell
12:19:38 <TristanBKildaire> Is that a good place to start off from?
12:20:09 <monochrom> Uncertain. It's a great preview of full-feature-film-length.
12:20:26 <monochrom> General consensus is you will be able to read but not write.
12:20:52 <monochrom> There are exceptions. A few people know how to create their own exercises. They do well. (They do well under anything anyway.)
12:21:13 <monochrom> But otherwise it's passive spectatoring.
12:21:42 <monochrom> I am one of those few exceptions. In fact I learn from The Gentle Introduction. LYAH didn't even exist.
12:22:22 <TristanBKildaire> The Gentle Introduction?
12:22:24 <TristanBKildaire> Is that a book?
12:22:27 <monochrom> No.
12:22:37 <monochrom> It's the first Haskell tutorial.
12:22:51 <TristanBKildaire> ah. Do you have a link to it?
12:22:58 <monochrom> https://www.haskell.org/tutorial/
12:22:58 <bbear> general advice is to not stick to one place or one tutorial. Jump across several of them
12:23:06 <TristanBKildaire> Yeah
12:23:18 <monochrom> The 3rd book you read is the best book.
12:23:20 <bbear> if you struggle to learn a notion then go to another resource.
12:23:23 <TristanBKildaire> Nah I feel you there. I shall not marry a specific tutorial.
12:24:03 <monochrom> But the downside is that another author does things in another order and therefore different assumptions on you.
12:24:16 <TristanBKildaire> Yeah
12:24:35 <monochrom> (Well, not a problem if you read all 3 completely.)
12:27:04 <TristanBKildaire> I will try to get good with Haskell. I come from an imperative and procedural world but I would like to try something different.
12:32:31 <TristanBKildaire> Thanks for the help guys
12:38:42 <mstruebing> TristanBKildaire: it definitely change the way you think about programming problems
12:39:17 <TristanBKildaire> Would it help to design things better in imperative programs?
12:39:35 <TristanBKildaire> Just wondering if it affects your thinking in other paradigms in a positive way
12:39:39 <geekosaur> yes
12:39:54 <TristanBKildaire> Cause I have heard that
12:41:03 <Rembane> But it will also make you angry that other languages don't have the niceties Haskell have.
12:41:17 <unknownln> I think maybe my favorite thing about learning haskell is that it taught me to better recognize common patterns that show up over and over, by way of making those explicit with typeclasses
12:41:38 <TristanBKildaire> Ah okay
12:41:42 <d34df00d> Makes it harder to communicate with some of the colleagues thinking that everything is an object (in OO sense).
12:42:04 <unknownln> and then as Rembane said, then I get frustrated that I can't program at the same level of abstraction as in haskell :P
12:42:31 <TristanBKildaire> But the frustration is part of the fun XD
12:42:41 <TristanBKildaire> Atleast it allows you to say I love x for y
12:42:57 <monochrom> Oh, we mean the frustration when you return to other languages.
12:42:59 <TristanBKildaire> Unless you are in a work environment, I can understand the stressbthere then
12:43:29 <TristanBKildaire> Yeah
12:43:30 <monochrom> I don't think "argh Java doesn't have Either" is a fun kind of even disappointment.
12:44:01 <monochrom> Today I was just reading up and using StreamTokenizer (java.io) again.
12:44:19 <Rembane> Almost all languages have null makes me want to topple the world.
12:44:25 <TristanBKildaire> I love languages so everything is fun. Except visual basic - that doesn't look fun (that syntax with case sensitivity is hell).
12:44:50 <TristanBKildaire> And how did that go monochrom?
12:44:57 <monochrom> After 20 years, it's still: "call void nextToken(). Then look at the ttype field. If it's T_NUMBER, go read the nval field for the number; if it's T_WORD, go read the sval field for the word..."
12:45:27 <TristanBKildaire> I don't mind null but maybe you guys xan invert my opinions ;)
12:45:32 <Rembane> Java... is nasty.
12:45:36 <Rembane> IMO
12:45:54 <Rembane> TristanBKildaire: If you don't have null you can never get a NullPointerException
12:46:08 <monochrom> In Haskell it's just "data Token = I'mNumber Double | I'mWord String | ..." and nextToken could have been "Token nextToken()".
12:46:20 <TristanBKildaire> that's true. But I just make sure to catch its occurences.
12:46:44 <monochrom> Scala gives you that ability at least. (Not sure its stream tokenizer library does it actually.)
12:46:50 <Rembane> TristanBKildaire: Indeed, if you know that it will occur.
12:47:03 <TristanBKildaire> But I can understand not wanting to have to do that at all.
12:47:16 <monochrom> I don't mind null but null is not enough.
12:47:19 <TristanBKildaire> Yeah.
12:47:26 <monochrom> Like my tokenizer example.
12:47:30 <TristanBKildaire> Hopefully the module is well documented.
12:47:45 <TristanBKildaire> If not then you have to catch it out with paranoid constructs
12:49:55 <TristanBKildaire> I am already enjoying peaking at the pdf of the Haskell tutorial. Looks very interesting and fun.
12:50:53 <c_wraith> which tutorial?  We've got an issue of too many of them.  It's almost as bad as php. :)
12:51:52 <rcat> how can I pass extra flags to ldd and gcc on cabal? I'm using new-build but 'extra-include-dirs' and 'extra-lib-dirs' look pretty much broken/ignored 
12:52:14 <rcat> I just need to specify manually -I include_dir -L lib_dir
12:52:48 <paolino> compiling with -O2 and -O1 I have a different result than -O0 
12:52:51 <c_wraith> rcat: well, new-build isn't done yet.  that's why it's not just build.  It's possible it really doesn't consider those yet.
12:53:08 <TristanBKildaire> I am going to Amsterdam and Portugal and can't wait to fall asleep to reading this document.
12:53:18 <monochrom> Yeah, could you fall back to old build?
12:53:30 <rcat> ok, will try :)
12:53:43 <TristanBKildaire> c_wraith: The Haskell haskell-98.pdf thing. Let me find the link
12:53:44 <sepakorayl> I want a monadic java-like finally, how would I go about it? Continuation? https://thepasteb.in/p/vghOVwJEBAZu3
12:53:49 <rcat> I'm just getting addicted to being able to build anything without deps-hell!
12:53:59 <monochrom> Ah
12:54:13 <paolino> some 0s becomes  -9223372036854775807 with optimizations on
12:54:19 <sepakorayl> the returns are wrong
12:54:26 <TristanBKildaire> This one
12:54:29 <TristanBKildaire> https://www.haskell.org/tutorial/
12:54:32 <monochrom> There is a way for passthru flags. It's just more obscure.
12:54:51 <rcat> I like obscure things
12:54:52 <c_wraith> sepakorayl: at a first glance, it looks kind of like you want MaybeT
12:55:26 <c_wraith> TristanBKildaire: that's not a bad intro, but nearly everyone agrees "gentle" might not be the most accurate description of it. :)
12:55:47 <sepakorayl> c_wraith won't it ignore the restoring state operations if renameA fails?
12:55:52 <TristanBKildaire> More like "painful"
12:56:08 <TristanBKildaire> Just kidding. It's probably gentle in the eyes of the creators.
12:56:36 <monochrom> I have never used them, so I don't know how. But it looks like --PROG-option and --PROG-options, where PROG can be ghc or gcc.
12:56:55 <c_wraith> TristanBKildaire: just go to other sources if you get stuck.  A different viewpoint will help
12:57:25 <monochrom> Be warned that it is possible that you have to --ghc-option(s)='please tell gcc to so and so' rathan than directly --gcc-option(s)
12:57:39 <monochrom> but do a "cabal new-build --help" for some fun
12:58:16 <monochrom> Actually maybe cabal is smart enough to convert --gcc-option(s) to ghc options.
12:58:31 <paolino> any clue on what can happen to Ints when -O1/-O2 instead than -O0 ?
12:58:37 <TristanBKildaire> Thanks c_wraith
12:58:50 <TristanBKildaire> Will do.
12:58:51 <monochrom> Some unboxing can happen, paolino.
12:59:10 <c_wraith> sepakorayl: ah, I see.  Nothing strikes me offhand, but there must be something out there.
12:59:46 <monochrom> If I have a loop of f x = f (x - 1), where x is Int, -O1 will loop over Int# directly and not bother to rebox then unbox.
12:59:59 <Lokathor> monochrom, updated to use pure just for you <3 https://lokathor.gitbooks.io/using-haskell/content/roguelike/week-2-graphics-and-dungeon-basics.html
13:00:07 <monochrom> haha
13:00:29 <paolino> monochrom but that should leave a 0  a 0 not make it a -9223372036854775807
13:00:32 <cocreature> paolino: do you have a reasonable small testcase?
13:00:53 <paolino> cocreature, I think I cannot share this code :-/
13:01:19 <c_wraith> paolino: are you converting between Double and Int?
13:01:40 <paolino> using properFraction
13:02:18 <TristanBKildaire> Can I write general purpose things in Haskell. Like give me an example of something general purpose that is written in Haskell.
13:02:26 <Lokathor> pandoc
13:02:38 <Naughtmare[m]> pkill Xorg
13:02:45 <Naughtmare[m]> sudo pkill Xorg
13:02:46 <Naughtmare[m]> google
13:03:01 <TristanBKildaire> google as in I should google it or google?
13:03:08 <c_wraith> paolino: with -O0, the optimized conversion functions don't get used.  You're likely doing something that's very order-of-operation dependent with Doubles, and the different conversion functions are causing them to run in different orders
13:03:13 <monochrom> google: command not found
13:03:19 <c_wraith> TristanBKildaire: eh, that's spam.  Not advice for you.
13:03:23 <monochrom> sudo: Access denied.
13:03:34 <monochrom> pkill: process not found
13:03:50 <Clint> i like how monochrom executes in LIFO
13:03:56 <monochrom> :)
13:04:01 <monochrom> @bots
13:04:01 <lambdabot> :)
13:04:08 <cocreature> monochrom: nah, "[sudo] password for Naughtmare[m]" is the right answer
13:04:36 <monochrom> Maybe. But I was jumping right into "can't find you in my /etc/sudoers"
13:05:00 <TristanBKildaire> LINO - Last in Never Out.
13:05:01 <TristanBKildaire> Now that's the best.
13:05:34 <paolino> c_wraith, properFraction $ fromIntegral (x * s) / fromIntegral (sum xs) is the only conversion part
13:05:37 <TristanBKildaire> LIRO. Last In Random Out.
13:05:38 <TristanBKildaire> Okay I will stop.now
13:06:06 <monochrom> Why did they coin LIFO not FILO?
13:06:43 <TristanBKildaire> Because Idk.
13:06:54 <TristanBKildaire> You would say the same if it were thr other way round would you not?
13:07:04 <monochrom> True.
13:07:42 <Lokathor> writing to /dev/null is webscale
13:07:46 <Lokathor> let me tell you
13:07:53 <TristanBKildaire> I don't mind. One can understand them both. I prefer both (worst use of "prefer")
13:11:57 <ClaudiusMaximus> paolino: properFraction gives me weird values for NaN or Infinity or -Infinity when optimisation is on, ie minBound :: Int (instead of 0 with -O0) - but your value is minBound + 1 :: Int
13:22:53 <c_wraith> paolino: you're almost certainly doing something wrong in your floating point operations
13:23:11 <c_wraith> paolino: probably a division by zero
13:23:16 <paolino> yep
13:25:16 <paolino> without optimizations the min 0 Inf was giving 0 with optimisation I had negative result going through the min
13:26:55 <paolino> but yeah, my bug. Thanks
13:42:23 <Gurkenglas> Trying to build miso with https://github.com/dmjio/miso/blob/master/stack/ghcjs7103/stack.yaml in the top level folder on Windows goes wrong like so http://sprunge.us/jbbJ , what happened?
13:47:57 <Gurkenglas> More precisely, my ghc builds ansi-terminal, but my ghcjs doesn't http://sprunge.us/HMeA 
13:54:27 <dundon> I'm trying to declare a type with this, but for some reason my type signature is getting a "variable not in scope" error ......cipher :: Int -> String -> String
13:54:48 <dundon> How can that be wrong?
13:58:09 <pavonia> dundon: Looks fine, the problem seems to be elsewhere
13:59:18 <dundon> Thanks Pavonia, it's a head scratcher
14:01:12 <pavonia> Paste more context
14:01:16 <pavonia> @lpaste
14:01:16 <lambdabot> Haskell pastebin: http://lpaste.net/
14:04:30 <dundon> the complete error is 
14:04:31 <dundon> <interactive>:1:1: error:     * Variable not in scope: cipher :: Int -> String -> String     * Perhaps you meant `either' (imported from Prelude)
14:05:32 <n_blownapart> hello I guess the spaces are passed over, i.e. they are not counted. But how does that work? The sentence is passed into the parameter, with spaces... https://ptpb.pw/Ontx (posted this on beginners channel as well)
14:06:30 <dundon> http://lpaste.net/356638
14:09:11 <n_blownapart> dundon that is quite odd, I just tried to use that cypher to make contact, but couldn't get it to compile
14:10:39 <dundon> Same error?
14:12:49 <n_blownapart> sorry is the error somewhere I missed dundon ?
14:13:07 <dundon> <interactive>:7:1: error:     * Variable not in scope: cipher :: Int -> String -> String     * Perhaps you meant `either' (imported from Prelude)
14:13:37 <dundon> It thinks either is more appropriate for some reason
14:13:42 <n_blownapart> dundon, I'm pretty sure that's it. it was earlier today
14:14:06 <pavonia> dundon: How do you load that module? It works fine here
14:14:22 <n_blownapart> I'm a noob, I was looking for advice from the author
14:14:45 <pavonia> n_blownapart: What's the problem exactly with you code?
14:14:51 <pavonia> your*
14:15:14 <dundon> Maybe it's that instead of loading the module, we've been running from the repl
14:15:26 <n_blownapart> I get error listed above by dundo*n 
14:17:16 <pavonia> Oh, you're trying to run that code directly in GHCi? The syntax is a bit different there
14:17:36 <pavonia> If you want to define a function, it's "let cipher ..."
14:18:15 <pavonia> You should load the module via ":load Cipher.hs" or so instead
14:18:43 <dundon> Yes, loading the module works. What's the difference doing it at the prompt?
14:18:59 <dundon> *difference between
14:19:31 <pavonia> GHCi is like a large do-block but with some extra syntax added
14:20:24 <dundon> it can't do a type signature in the "do" format, you mean?
14:20:58 <lyxia> pavonia: let is optional now
14:21:03 <lyxia> in ghci
14:21:06 <dundon> or like because it's wrapped in a do (operator?), it can't define a type signature
14:21:32 <pavonia> dundon: You can, but the syntax is different: let cipher :: String; cipher = "foo"
14:21:48 <dundon> ah, makes sense. Thanks lyxia and pavonia
14:22:09 <pavonia> lyxia: For type signatures too?
14:22:57 <lyxia> ah I see it thinks it's an expression
14:23:00 <lyxia> pavonia: nevermind
14:25:43 <n_blownapart> it compiled with stack. I got that blasted "update indices" thing again. pavonia dundon . it doesn't return an email address or anything. what to do?
14:27:15 <pavonia> Sorry, I don't know about stack. Do you get an executable from it?
14:27:23 <dundon> [17:25] <dundon> hi there, I saved the code under a filename with the ".hs", set the current directory to the appropriate location, then used -- .load /file/location/file.hs [17:26] <dundon> When the module was loaded, I then called the function main
14:27:36 <dundon> the output was the email address
14:32:36 <Gurkenglas> On my Windows, ghc builds ansi-terminal, but my ghcjs doesn't, what happened? http://sprunge.us/HMeA 
14:34:13 <geekosaur> ghcjs foreign calls expect to call javascript, not C?
14:35:04 <bbear> is ghc buggy ?
14:35:12 <bbear> how can you tell if you'd find a bug ?
14:35:37 <kadoban> bbear: Almost every piece of software has *some* bugs. But GHC is relatively quite stable in that regard. I've yet to find one.
14:36:21 <kadoban> Usually bugs seem to result in GHC panics, or sometimes segfaults
14:36:59 <bbear> you don't have kind of mutation in data structure if you write weird constructs or things like that ?
14:39:11 <kadoban> Not sure what you mean, like corrupted memory?
14:39:20 <bbear> not corrupted
14:39:29 <bbear> you know the kind of thing lazy evaluation do
14:39:45 <bbear> can lazy evaluation perform actually some mutability on data structure ?
14:39:56 <bbear> ie evaluation may change the state of the program
14:40:18 <bbear> not sure what i'm saying
14:41:42 <Gurkenglas> geekosaur, would one have to rewrite System.Console.ANSI.Windows.Foreign to use js primitives, or would there be another way to get Windows to ultimateily build miso?
14:42:33 <geekosaur> the former, most likely. or figure out a way to FFI from Javascript to C and then ghcjs-FFI to the resulting JS wrappers
14:59:39 <n_blownapart> hi I'm still getting errors while trying to run this  prog that returns an unencrypted email address. the error is truncated to not reveal author's name. http://lpaste.net/356638
15:05:37 <geekosaur> it compiles here. are you typing it into ghci? if so and you have a pre-8.0 ghc then you need to use 'let' on definitions
15:06:33 <Welkin> since whe do you not need `let`?
15:06:50 <monochrom> GHC 8.0
15:06:54 <geekosaur> as I said
15:07:05 <geekosaur> "if you have a pre-8.0 ghc then..."
15:07:22 <n_blownapart> Welkin, no clue. thanks all. I'm using ghci from stack. > 8.0
15:07:33 <monochrom> People believe in the scam called "speed reading".
15:07:37 <Welkin> that seems like an odd change
15:07:52 <n_blownapart> pardon?
15:07:58 <monochrom> Why is the prompt "$"?
15:08:30 <Welkin> bash
15:08:36 <n_blownapart> sorry I just shortened it because the output is riddled with the authors name
15:08:56 <geekosaur> an offset-1 caesar cipher isn't exactly obscuring much :p
15:09:05 <Welkin> :set prompt λ
15:09:25 <n_blownapart> Welkin, that goes in .bashrc ?
15:09:29 <Welkin> no
15:09:32 <n_blownapart> vim
15:09:35 <Welkin> it's a ghci command
15:10:17 <n_blownapart> where do I get the character ?
15:10:30 <Welkin> what character?
15:10:31 <Welkin> copy it
15:10:42 <Welkin> :set prompt "λ "
15:10:52 <n_blownapart> oh ok, can I set it permanently?
15:11:27 <Welkin> I think so, in .ghci maybe
15:12:05 <monochrom> I see that changing prompt is more urgent than troubleshooting the error.
15:12:11 <Welkin> lol
15:12:35 <n_blownapart> monochrom, absolutely :) sorry, no , so its my version of ghci
15:14:20 <n_blownapart> monochrom, so if I type let at each function, that should work?
15:16:10 <monochrom> Multiple-line functions are more complicated than that.
15:16:23 <monochrom> Simplest is use :load since you already have it.
15:16:46 <geekosaur> you haven't really provided enough information considering that is a compile time error but it compiled fine here
15:16:51 <geekosaur> ...wait
15:16:59 <geekosaur> parse error at input...
15:17:07 <geekosaur> are you trying to run that *in* bash?
15:17:14 <geekosaur> use runghc
15:17:40 <n_blownapart> hold on thanks
15:17:52 <monochrom> It's why I asked about 
15:17:56 <monochrom> It's why I asked about $
15:18:14 <geekosaur> actually I get 'syntax error near unexpected token' from bash here
15:18:18 <n_blownapart> I've used :l and :load in prelude in the correct dir
15:19:25 <geekosaur> this whole thing just sounds wrong...
15:19:33 <monochrom> OK, how about a step-by-step no-presumption non-telepathic walk through of how to get that error?
15:20:03 <n_blownapart> monochrom, hold on let me rename the file
15:20:32 <n_blownapart> another geezer got it to work here, dun*don
15:23:29 <n_blownapart> https://ptpb.pw/CxcB   << using :load in prelude 
15:24:15 <n_blownapart> prelude> :load encrypt.hs
15:24:41 <geekosaur> indentation
15:25:02 <geekosaur> you pasted that into something and it autoindented, looks like
15:25:33 <geekosaur> indentation matters in haskell, everything from line 3 on is a continuation of line 2
15:25:59 <n_blownapart> sorry again, I thought I was pasting the error
15:31:31 <n_blownapart> geekosaur, trying to correct it thanks kindly
15:33:26 <n_blownapart> geekosaur, thanks that worked. now off to grovel elsewhere. :)
15:37:48 <davr0s> could haskell be given enough information (e.g. through specially annotated eager functions in the IO monad) to generate critical loops that are directed to not generate garbage (e.g: imagine some iterator taking generator functions with various restrictions, such that it is known all temporaries can be stuffed into a special temporary pool , asside from all the tracing malarkey going on elsewhere) 
15:39:23 <davr0s> maybe there would be some monadic way of marking data that exists in certain specific pools,
15:40:28 <davr0s> e.g. imagine implementing 'pure game update' via double buffering, where some outer loop clearly marks 'previous frame state', 'next frame state' (output being generated) and 'non-escaping temporaries' (who are hence known not to generate data that ever needs to be traced)
15:41:11 <geekosaur> https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.2.1#Back-endandruntimesystem
15:41:16 <geekosaur> "\
15:41:22 <geekosaur> whoops, sorry
15:41:35 <davr0s> And similarly .. "render" (given a game-state in a clearly marked pool , non-escaping temporaries , but output through a rendering API..)
15:42:11 <davr0s> programming in haskell is rather addictive..
15:42:24 <davr0s> it would be nice to write pure programs and then annotate them to run fast.
15:42:53 <ertes> davr0s: as long as GHC can statically determine the life-time of an object, you can rely on it to release the memory promptly, especially in the case of a recursive function (like a game's main loop)
15:42:55 <davr0s> annotations that cannot affect program semantics, only performance
15:43:33 <geekosaur> anyway you want to look at the first item at that link, compact regions
15:43:53 <davr0s> ertes culturally i have a deep distrust of garbage collectors , but i will try to remember 'immutability creates some opportunity for the GC to make assumptions not availalbe in other languages' 
15:44:13 <ertes> geekosaur: i thought we had those in 8.0 already…
15:44:25 <davr0s> just as haskellers feel dirty seeing mutation/side effects... i feel dirty using a language based on a garbage collector.
15:44:47 <geekosaur> no, they didn't make 8.0. some of the setup work did
15:44:54 <Welkin> lol davr0s what
15:44:54 <ertes> ah, ok
15:45:30 <ertes> davr0s: GHC's memory manager is rather reliable…  in most cases it will do exactly what you would have done in a language with manual memory management, and in some cases it will even improve on that by reusing allocated memory directly
15:45:44 <davr0s> C++ background.. i see a big dividing line between "GC-based languages" and "C, C++, (and now rust)"
15:46:14 <davr0s> ertes i can well imagine it does what is kind of ok most of the time, 
15:46:20 <ertes> davr0s: it's only when non-static memory management becomes necessary (like objects stored in a long-lived data-structure) that things become less predictable
15:46:40 <Welkin> davr0s: what exactly are you doing though?
15:46:42 <davr0s> but i would still feel much better with explicit annotations at a major juncture 
15:46:55 <Welkin> in most cases, there is no reason to care at all about memory management
15:47:07 <Welkin> let the gc handle it
15:47:13 <davr0s> Welkin i am exploring really. if i want to do anything serious i will jump back to C++, but i like the ideas of the pure-functional world.
15:47:20 <Welkin> what is "serious"?
15:47:30 <ertes> davr0s: compact regions are that, but honestly, i trust GHC a lot to just do the right thing
15:47:38 <Welkin> the only reason to care about memory management is for embedded systems with tight requirements
15:47:50 <ertes> davr0s: i've come from a C++ background, too =)
15:48:00 <davr0s> my background is gamedev, to me 'serious' would be 'any language that could have handled the scenarios i've dealt with in anger'
15:48:27 <davr0s> sometimes .. never mind garbage collection, even dynamic memory management feels dirty.
15:49:07 <Welkin> it's greater levels of abstraction that allow you as the programmer to be more efficient and not waste your time with tedious things like managing memory
15:49:16 <davr0s> dynamic memory management = a system that does not know it's load up-front, hence may have unpredictable performance
15:49:18 <ertes> davr0s: coming from a C++ background you might remember the old saying: "the compiler almost certainly writes better code than the programmer most of the time"
15:49:36 <ertes> do you agree with that saying?
15:49:43 <Welkin> with haskell, you also abstract away any concept of execution order unless you want to specifically sequence something
15:49:44 <davr0s> ertes sure, i realise 90% of the code needn't be manually controlled to such a level
15:50:16 <davr0s> nonetheless i am interested in the ability to handle/control that last 10% where it really does matter.
15:50:31 <ertes> davr0s: haskell takes this a few levels further:  code generation, memory management, multi-threading
15:50:38 <ertes> well
15:50:40 <ertes> GHC-haskell does
15:50:46 <davr0s> and i am interested in the possibility of a language that can handle both cases, e.g. you can write elegantly, then narrow down with annotations to make key parts fast.
15:51:02 <ertes> well, then you'll have to wait for 8.2 =)
15:51:15 <davr0s> i definitely like the idea that haskell code is more composable than anything else.
15:51:33 <davr0s> i did work on 'toolchains' which of course haskell could easily have handled.
15:52:05 <davr0s> but part of why we used c++ was the abiltiy to move code between engine & tools.. but there might be other ways around that (generating schemas)
15:52:32 <davr0s> in some ways a lot of engine dev was "condition assets until the runtime is trivial"
15:52:40 <davr0s> haskell could certainly be used for asset-conditioning
15:55:31 <Welkin> I just watched a jonathon blow talk about programming languages
15:55:47 <davr0s> i follow some of those, i agree with 90% of what he says
15:55:49 <Welkin> so many talks about the cargo culting of c++ in game dev
15:56:50 <davr0s> in his early talks he dismissed 'modern c++' because it's focussed on dynamically allocated std::vectors etc... he mentions what i just said about 'dynamic memory allocation' even being dirty
15:57:00 <davr0s> as i remember he wants support for concatenated allocations
15:57:16 <davr0s> he also says "GC isn't suitable"
15:57:22 <Welkin> lol
15:58:22 <davr0s> i've used 'blobs' for level data, ie. tools just condition big blobs of memory, you load them as is, and the only 'dynamic memory management' going on is well defined pools
15:58:47 <exio4> what could cause the mouse to be ignored? 
15:58:51 <davr0s> the complexity of C++ is aimed at managing complex datastructurse which are going to be slow anyway
15:58:55 <exio4> I had a game, had to kill it and now I cannot click
15:59:03 <exio4> the mouse moves but clicks don't work
15:59:26 <Welkin> exio4: using what for the input?
15:59:26 <exio4> $ xkill
15:59:27 <Welkin> sdl?
15:59:28 <exio4> Select the window whose client you wish to kill with button 1....
15:59:30 <exio4> xkill:  unable to grab cursor
15:59:39 <exio4> uhh, sorry, wrong channel - didn't see it was #haskell
15:59:42 <Welkin> lol
15:59:51 <exio4> Welkin: I have no idea :D
16:01:58 <davr0s> https://www.youtube.com/watch?v=TH9VCN6UkyQ&list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO 47:00 onward, he makes syntactic mistakes but part of his point is that even std::vector<T> is too general and you still need to drop back to direct memory management tricks, making blobs with concatenated allocations ... ahead of time knowledge about what wont change
16:02:22 <davr0s> there isn't a good way in C++ to pass control an individual vector with higher context,
16:02:49 <davr0s> e.g. you could say " a mesh is an array of vertices and a vector of indices", but there's higher level informaiton connecting the vertices & indices *in the mesh*.
16:03:35 <davr0s> forget the syntax mistakes he makes, i dont think he bothered to learn C++11  properly
16:03:43 <davr0s> but his overall points are good
16:04:39 <geekosaur> exio4, I'd switch to a terminal, possibly on a virtual console instead of X11, and make sure the program is dead; looks to me like the server still thinks it is there and has a pointer grab active
16:05:12 <ertes> davr0s: my personal opinion nowadays is that this attitude is misguided…  i fully agree with everything chandler carruth says about efficiency, but that's about where it stops
16:05:47 <davr0s> i totally understand why std::vector and garbage collectors are prevalent
16:05:56 <davr0s> they're good for 90% of use cases.
16:06:32 <davr0s> nonetheless the use cases remain where time and space are critical
16:06:41 <ertes> davr0s: i think your main mistake is to put a number of that
16:06:46 <ertes> "90%"
16:06:57 <davr0s> anything can be quantified
16:07:05 <davr0s> and we can talk about ballparks
16:07:12 <davr0s> it could be 10%, 50%, 90%, 99.999%
16:07:35 <davr0s> if it was 99.99% then we could say 'near enough all the time'
16:07:43 <geekosaur> sounds like a game programmer, in which case there's a reason game consoles exist. realtime programming on a general purpose OS goes only so far
16:08:19 <davr0s> yes, and there's other use cases where the same issues do re-appear, e.g.
16:08:21 <ertes> sure, but that doesn't really help…  what if, when you reach that "other side of the mark" (regardless of whether it is at 50% or 99.999%), what will your options be?  will you really need those annotations?  or will this in reality just be a tight loop, where GHC will just do the right thing anyway?
16:08:25 <davr0s> realtime control 
16:08:49 <Welkin> I hardly ever have to think about time or memory as a web dev, because it just doesn't matter, since the network is so slow anyway, and the computer is fast
16:09:12 <davr0s> the full challenge would be , 'can you do retro gamedev in haskell' .. e.g. could you make something run to high quality on a playstation 1
16:09:35 <davr0s> of course today, you have more leeway,
16:09:49 <Welkin> you can do full 3d games in the browser today
16:09:51 <Welkin> in javascript
16:09:53 <davr0s> nonetheless, if you could handle that then you know you could eliminate C in other use cases
16:10:05 <davr0s> Welkin that is true but 
16:10:23 <ertes> davr0s: here is a little experiment i wrote that does full shading in software in real-time, while using some high-level abstractions including FRP: http://lpaste.net/170277
16:10:26 <maerwald> if there is any future of eliminating C++ in gamedev, haskell is not it and rust has a long way to go
16:10:30 <davr0s> what happens in console gamedev is -  it's understood to be GPU centric,  so the platform uses the weakest possible CPU
16:10:44 <davr0s> as such the CPU side is still critical.. you must not stall the GPU waiting for the CPU
16:10:55 <Welkin> haskell is a general purpose (research) language
16:10:55 <davr0s> this is so the machine they build can be 90% GPU 
16:11:05 <Welkin> it's purpose is to advance the art of programming
16:11:11 <davr0s> absolutely, and what I talk about is ideas... 'what if..'
16:11:14 <ertes> davr0s: this program doesn't have dynamic collections, so GHC knows statically when to free stuff, and it does a wonderful job at that
16:11:31 <ertes> well, it does have them, but only on a small scale
16:11:42 <davr0s> I'm sold on the idea of describing what your program should do at the highest possible level
16:11:49 <ertes> dynamic collections is exactly where you would need those annotations, but then it's also where you couldn't use them
16:12:13 <davr0s> i think you should indeed be able to seperate the description of  behaviour , from how it maps onto time and space
16:12:15 <maerwald> davr0s: depends, if you go to a high enough level you may lose the possibility to reason about certain things
16:12:31 <davr0s> sure some of the complexity is inevitably about time and space
16:12:58 <davr0s> nonetheless,  the pure-functional ideas resonate with me a lot; graphcis and physics is essentially functional
16:14:04 <ertes> i disagree about haskell not being suitable for game dev
16:14:20 <davr0s> well ertes if it is, great
16:14:21 <maerwald> the way I can reason about memory in rust is magnitudes more powerful than anything in haskell, but I have little knowledge about side effects, because they are usually everywhere anyway... and it's debatable whether you actually care
16:14:35 <davr0s> i would be delighted if i was proved wrong on all this. haskell is a joy to write
16:15:00 <ertes> it's more like nobody has really tried it before, and i strongly believe that haskell will work for game dev
16:15:05 <davr0s> but the full challenge would be: can you use it to get the same quality out of a highly constrained scenario , like a playstation 1
16:15:07 <maerwald> sure people have tried it
16:15:08 <ertes> even on high levels of abstraction
16:15:27 <ertes> maerwald: point me to a game that is really CPU-heavy
16:15:36 <maerwald> I know of 2 companies that tried and both went bankrupt, other than that... there's just a thesis writing a quake engine
16:15:38 <davr0s> its possible that with heavy work being on the GPU these days, you might be able to do a PC game
16:16:00 <ertes> maerwald: those companies had very small games…  haskell was not the problem there
16:16:09 <ertes> the games worked
16:16:25 <davr0s> ertes  games might not be CPU heavy seomtimes... but that points to a different problem - i.e. it's on the wrong platform :)
16:16:35 <maerwald> that's probably guessing, but the existence of frameworks, known technology and manpower matters
16:16:46 <davr0s> dedicated game consoles have the weakest possible processor to run the game, such that the hardware budget goes into the GPU
16:17:01 <maerwald> if you are the pioneer in some area, you have to be ready to do pioneer work, uh
16:17:07 <ertes> davr0s: well, one thing haskell is really good at is embedded DSLs…  for example GPipe, a haskell graphics library, has an EDSL for shaders, which is really nice
16:17:09 <davr0s> maerwald yes developper experience matters
16:17:38 <maerwald> davr0s: exactly and the experience, knowledge and frameworks in C++ would much more easily carry over to something like rust
16:17:44 <maerwald> for haskell, that's a completely different world
16:17:44 <davr0s> ertes i would like to look into all that.
16:17:50 <davr0s> maerwald yes i'm looking at Rust aswell.
16:17:53 <ertes> maerwald: yes, that indeed matters…  if anyone chooses to do commercial game dev in haskell, it's likely because they love haskell
16:18:06 <ertes> but also the business model matters
16:18:20 <davr0s> it's possible rust is the right balance, i think of it as cleaned-up C++.  it has the right defaults i.e. 'globals are unsafe'
16:18:25 <maerwald> you have to solve problems no other game dev company has had before probably, because well, uh
16:18:30 <davr0s> it has mutation, but *constrained* mutation
16:19:00 <davr0s> i'm really just exploring now. if i wanted to do work i'd go straight back to C++
16:19:00 <ertes> davr0s: rust is very different from haskell…  they were inspired by haskell to some degree, but not much
16:19:12 <davr0s> ertes yes i do see rust being more like cleaned up C++
16:19:14 <ertes> davr0s: you shouldn't really compare them
16:19:19 <ertes> yeah
16:19:32 <ertes> rust may be D Done Right in a sense
16:19:51 <ertes> but it's definitely not Haskell For Systems
16:20:03 <davr0s> there is one similarity, : traits/typeclasses.  there Rust prepared me for haskell
16:20:18 <davr0s> the last time i looked at haskell i found it bewildering.  
16:20:39 <davr0s> after a bit of rust its making more sense (because rust presents typeclass-like ideas in a familiar C++ -esque syntax)
16:21:24 <ertes> yeah, now with haskell you can actually exploit that abstraction power by virtue of higher-kinded polymorphism =)
16:21:34 <Lokathor> ertes, Hasekll will probably work for gamedev exactly how Java and C# do, which is to say "fineish but you can't push the limits of the machine too much"
16:21:36 <Welkin> commercial game dev is just the worst industry in software
16:22:17 <ertes> Lokathor: i'm not convinced that's true…  consider that the heavy lifting is moved to the GPU anyway, and haskell is especially good at EDSLs
16:22:22 <Welkin> no one is actually using anything other than c++ (or c# in the case of indie games on unity) anyway
16:22:25 <ertes> java and C# suck at EDSLs
16:22:40 <maerwald> and now you gotta pay an extra smart guy for writing said EDSLs
16:22:44 <EvanR> i still dont see the parallels between rust and haskell at all
16:22:54 <Lokathor> Welkin, Java and C# are way big because that's how lots of mobile games are made
16:22:56 <Welkin> EvanR: there are none
16:22:57 <ertes> yes, game dev in haskell is expensive in every sense of the word
16:23:01 <davr0s> ertes if you can generate the interfacing between the CPU and GPU (how shader/compute-kernel parameters are setup) that would be interesting
16:23:03 <ertes> C++?  just buy an engine
16:23:12 <ertes> haskell?  have fun writing the engine basically from scratch
16:23:17 <davr0s> ertes   rust macros can do that well IMO
16:23:25 <EvanR> ertes: just buy lambdacube :)
16:23:27 <maerwald> EvanR: some people feel that traits are similar to typeclasses
16:23:36 <Lokathor> EvanR, type system mostly
16:23:45 <maerwald> and that's about it
16:23:45 <ertes> EvanR: lambdacube is hardly a full game engine =)
16:24:03 <EvanR> "game engine"
16:24:10 <EvanR> 3D graphics engine?
16:24:12 <ertes> davr0s: the EDSL thing goes deeper: you write haskell code, and then there is a kind of "compiler" that translates it into, say, a compute shader
16:24:15 <Welkin> the worst part of game development is all the programming
16:24:25 <ertes> davr0s: but the code doesn't just look like haskell, it *is* haskell
16:24:26 <Lokathor> ^
16:24:32 <davr0s> ertes fair enough, if you can generate to that level, that would be truly awesome
16:24:40 <ertes> davr0s: with all abstraction capabilities you're used to:  functions, type classes, etc.
16:24:48 <maerwald> davr0s: you need extra smart people for that, like... really
16:25:02 <EvanR> you dont need smart people to hack some licensed C++ engine?
16:25:02 <maerwald> when all you want to do is keep a deadline, uh :P
16:25:16 <EvanR> wheres the disconnect here
16:25:41 <maerwald> I think someone misunderstood something here
16:25:52 <EvanR> also, you dont spend a billion dollar budget developing with C++? :)
16:26:07 <ertes> so with all that in mind:  who will write games in haskell?  haskell enthusiasts who are really just having fun with the potential for generating some money from that
16:26:10 <maerwald> you get enough C++ devs anywhere, look up the tiobe index
16:26:24 <ertes> the game is secondary…  it's really a tech experiment
16:26:37 <maerwald> yeah
16:26:41 <EvanR> so its not really about being smart
16:26:50 <EvanR> or more or less smart
16:27:01 <Welkin> the smart game developer will not use c++ either
16:27:06 <Lokathor> well i'm making my own tech experiment game myself, so i understand a bit of what's being said
16:27:09 <ertes> in other words: it doesn't matter that you need smart people to write EDSL code…  your colleagues will be smart anyway, because they will be haskell enthusiasts =)
16:27:14 <Welkin> there will use game maker
16:27:14 <maerwald> EvanR: well, if one tries to misunderstand really hard, he always can :P
16:27:16 <Welkin> and not have to program
16:27:33 <Welkin> or only need to write some scripts for their game entities in a language like lua or *script
16:27:35 <maerwald> ertes: so C++ devs are not smart?!
16:27:39 <ertes> and it probably doesn't even matter than the *business* part doesn't work out
16:27:45 <ertes> maerwald: no, C++ devs are smart, too
16:27:46 <maerwald> (following up on EvanRs argument :P)
16:27:58 <EvanR> if you people were really smart, you would reinvent haskell properly to be even better and use that!
16:28:27 <colonelj> anyone used purescript?
16:28:28 <EvanR> QED
16:28:31 <Welkin> colonelj: yes
16:28:36 <colonelj> is it good?
16:28:37 <Welkin> it's great
16:28:50 <MarcelineVQ> EvanR: I'm taking names for such a thing, I'm leaning towards Idris, do you think people will like a language like haskell named idris?
16:28:51 <maerwald> why reinvent when you can invent something new
16:28:52 <Welkin> I evaluated several alternatives, including elm and ghcjs
16:28:58 <Welkin> I prefer purescript right now
16:29:03 <ertes> maerwald: but if someone knows how to write haskell (like, really), then you can pretty much count on them being smart
16:29:13 <EvanR> idris isnt really that
16:29:17 <ertes> not because haskell requires smart people, but because smart people are drawn to it
16:29:38 <colonelj> I thought I knew how to write haskell sort of, until space leaks
16:29:41 <Welkin> MarcelineVQ: not Coque?
16:29:41 <colonelj> now I know nothing
16:29:47 <maerwald> ertes: well, you could say the same about C++ ;)
16:29:59 <maerwald> or rust
16:30:00 <ertes> maerwald: and that's why i think C++ devs are smart, too ;)
16:30:01 <maerwald> or...
16:30:01 <Welkin> colonelj: space leaks? never run into them
16:30:24 <EvanR> but yeah a select few people have made other languages, i wasnt really serious
16:30:34 <colonelj> maybe the libraries I'm using just don't work?
16:30:40 <colonelj> hmatrix in particular
16:31:09 <EvanR> yeah your library may be to blame
16:31:19 <maerwald> always blame the library!
16:31:19 <colonelj> all I'm trying to do is compute a few covariance matrices and it's like *BOOM*
16:31:21 <EvanR> there was an annoying leak in gloss, now fixed
16:32:01 <colonelj> I went all deepseq on the code and stuff, no effect
16:32:08 <maerwald> ertes: I'd much rather be interested in a tech experiment where you build the language in rust and code the game logic in haskell, but I fail to see how that will beautifully merge
16:32:11 <EvanR> probably not the right thing to do
16:32:11 <Welkin> does `linear` provide the same functionality as `hmatrix`?
16:32:18 <maerwald> s/language/engine/ dafuq
16:32:30 <ertes> maerwald: i don't think that would work well
16:32:41 <colonelj> well I'm pretty desperate to make this not shit and nothing is working
16:32:46 <davr0s> ertes one point about haskell is, there was a phase were the console platforms really could not handle any sort of pointer-chasing (in order processors)
16:33:06 <EvanR> colonelj: what happened so far when you tried to get help here
16:33:09 <colonelj> my gut instinct is to rewrite it all in C++ or some language where I have a fkn clue what's going wrong
16:33:20 <davr0s> i get the impression the default behaviour of haskell is pointer-chasing heavy
16:33:45 <davr0s> again thats arguably a platform error, because what they did was chose a bad CPU that was really designed as a DSP lol
16:33:55 <maerwald> ertes: well, rust libraries can expose a C API
16:34:10 <colonelj> EvanR: people gave links to blogs, and I read them and tried some stuff
16:34:24 <EvanR> i mean did you show anyone evidence of the problem
16:34:33 <EvanR> code, profiles
16:34:43 <colonelj> the heap usage profile looks like a big triangle
16:34:53 <colonelj> code is not very shareable
16:35:10 <EvanR> are you sure its not supposed to look like a big triangle
16:35:11 <ertes> maerwald: yeah, but if you write the engine in rust, then you get into C-calling-back-into-haskell land
16:35:18 <ertes> maerwald: it's not pretty there
16:35:23 <colonelj> not one that goes up to 1GB no
16:35:38 <colonelj> I'm only trying to compute 500 3x3 matrices
16:35:48 <EvanR> without code... this will be pretty hard to diagnose
16:35:50 <colonelj> everything else is intermediate calculations
16:36:48 <colonelj> I want that intermediate stuff to be thrown away and I still don't see how it gets to be 1GB
16:36:49 <ertes> davr0s: that could be fixed, and is fixed to some extent (by unordered-containers)…  the problem is that traditional data structures (such as those from 'containers') use no bucketting at all
16:37:15 <ertes> davr0s: which means that trees are a few levels deeper than necessary, and instead of jumping around in an array you chase pointers
16:37:29 <EvanR> colonelj: profiling has a bunch of options to identify what and why stuff is being kept around
16:37:34 <Welkin> there are unboxed arrays
16:37:39 <Welkin> you can use them if you wish
16:37:47 <Welkin> and other unboxed types
16:37:54 <ertes> davr0s: GHC actually does a good job to ensure that at least the individual chunks are close together in memory, so you can benefit more from inner caches, but still there is a lot of room for improvement
16:37:54 <colonelj> EvanR: arch linux just got it's GHC upgraded so I can't really try anything out right now
16:38:05 <EvanR> why not?
16:38:19 <colonelj> need to recompile all the packages and stuff
16:38:24 <EvanR> :(
16:38:27 <Welkin> colonelj: why would you install ghc through your package manager?
16:38:33 <Welkin> that's usually the worst option for haskell
16:38:44 <Welkin> install using stack, or nix
16:38:46 <colonelj> I install everything through the package manager on arch
16:38:46 <EvanR> stack can install a ghc preetty fast
16:38:48 <Welkin> my preference is nix
16:38:50 <Welkin> no need to ocmpile
16:38:54 <Welkin> just download precompiled binaries
16:39:00 <ertes> davr0s: there is also the problem that GHC code generally requires twice the cache size to deliver the same performance, because of how its current GC works, but that's being worked on right now
16:39:10 <EvanR> colonelj: well if youre not able to actually try stuff...
16:39:21 <Welkin> colonelj: linux package manager lag behind badly
16:39:38 <Clint> sometimes
16:39:49 <colonelj> EvanR: what sort of stuff is there to try?
16:40:16 <EvanR> profiling has a bunch of options to identify what and why stuff is being kept around
16:40:24 <Welkin> if you want to profile, you have to compile your libraries and project with the correct options
16:40:44 <colonelj> I was using stack build --profiling --library-profiling --executable-profiling
16:40:45 <EvanR> if the problem is in your code, that might not be necessary
16:40:49 <ertes> davr0s: i suggest that you just write some non-trivial projects in haskell just to get a feeling for it
16:40:52 <EvanR> well good
16:41:18 <ertes> davr0s: reasoning about GHC-haskell performance definitely requires experience
16:41:39 <davr0s> ertes as an excercise i might try again doing things like BSP generators or something
16:42:11 <davr0s> tristrip generators.. mesh clustering..
16:42:19 <EvanR> colonelj: excuse me for observing, repeatedly complaining about space usage in a program whose code you wont provide, on a system you cant haskell on, ... seems counter productive
16:42:34 <davr0s> stuff like that .. done offline anyway so there's no waste in learning haskell for it
16:42:56 <colonelj> EvanR: I can it's just that I'd need to wait a while to get it up and running again
16:43:04 <ertes> davr0s: yeah, that's a good starting project, but you should also add a non-batch program to your exercise list
16:43:18 <ertes> davr0s: perhaps a doom level editor or something like that
16:43:19 <davr0s> oh that reminds me:   hoogle is amazing,   but is there anything like the idea of finding functions by their inverses
16:43:49 <davr0s> ertes yeah i was also thinking about trying to write a 3d modeller of sorts in haskell,
16:44:34 <ertes> i should write a step-by-step tutorial for 'rapid' at some point =)
16:44:38 <davr0s> the interfacing with event loops for ui looks sort of messy but conversely anything transforming data looks awesome
16:44:43 <Welkin> davr0s: why not write a web server?
16:44:53 <Welkin> web api*
16:45:20 <ertes> i think davr0s is interested in computation/memory-heavy applications
16:45:29 <davr0s> i've never dealt with web-stuff much, maybe 'foreignlanguage" + 'foreign domain' is too much, but i'm open to suggestions
16:45:34 <Welkin> that is one of haskell's great strengths, web servers
16:45:45 <Welkin> it's pretty much all I use haskell for these days
16:45:53 <davr0s> thhis being the 21st century maybe i should look into that more :)
16:45:59 <EvanR> before you write a video game, you have to write a game engine, before you write a game engine, you have to write a 3d modeler, because you write the 3d modeler, you need to write a new language, before you write a new language you need a new text editor!
16:46:04 <EvanR> ad infinitum
16:46:31 <davr0s> EvanR well i'm at least accepting haskell as a starting point :)
16:46:35 <ertes> one thing i love about haskell is how it embraces constructive mathematics practically
16:46:41 <ertes> see the 'ad' library for example =)
16:47:00 <EvanR> yeah i would probably use haskell at the non existent end of that infinite list to get starte
16:47:34 <davr0s> ertes actually now i remember, here's some rambling to consider:-
16:47:48 <EvanR> rebuilt a new computer from raw ore.... with haskell!
16:48:02 <davr0s> if you start with a datastructure, you render it,    lets say f(s) is your renderer;
16:48:18 <davr0s> now you condition your scene offline,  lets say thats 'g'   s' = g(s)
16:48:30 <ertes> davr0s: i think the model editor is a great idea…  you will be facing all of the engineering challenges we talked about:  data structures, memory management, etc.
16:48:37 <davr0s> your renderer should produce the same result,    f(s) = f'(g(s))
16:48:44 <ertes> web apps tend to…  not *do* much
16:48:54 <ertes> they are really just database interfaces most of the time
16:49:11 <davr0s> so basically what i'm talking about is encoders and decodes, and composing them
16:49:26 <davr0s> the way i see engine dev is you're transforming data to simplify the final 'f'
16:49:52 <davr0s> this sounds tome like the sort of thing pure functional ideas should be able to help with
16:50:11 <davr0s> that composition, verifying things are still valid etc.. expressing  the constraints that should hold
16:50:24 <EvanR> verifying things are *still* valid ??
16:50:37 <ertes> you mean (f' s = f (g s)), not (f s = f' (g s)), right?
16:50:40 <EvanR> like, running the verifier twice?
16:50:44 <davr0s> render(raw_data)      render_optimized(  optmize_data(  raw_data )  )   // optimise happens offline
16:51:07 <davr0s> ah of course yes, the parentheses inthe right place
16:51:20 <ertes> davr0s: preserving invariants across composition is one of the points of the algebraic abstractions we use
16:51:26 <ertes> monoids, monads, categories, etc.
16:51:48 <davr0s> so maybe there's formal ways of expressing   'this encoder and this decoder should match up'
16:52:07 <ertes> ideally:  render s = render (optimise s)
16:52:19 <EvanR> render = render . optimize :)
16:52:25 <EvanR> optimize is optional
16:52:47 <EvanR> decode . encode = Just
16:52:47 <ertes> 'optimise' should act as the identity function under 'render'
16:52:50 <davr0s> i'm also interested in this concept for function discovery,  e.g. imagine if you could search for functions by writing the inverse - sometimes the inverse is easier
16:53:01 <Welkin> "inverse"?
16:53:04 <Welkin> what is that?
16:53:05 <davr0s> "find me a function from the library that is the inverse of this.."
16:53:15 <ertes> davr0s: "find" or "generate"?
16:53:17 <Welkin> inverse of a -> b is b -> a?
16:53:17 <EvanR> :t fromChunks
16:53:18 <lambdabot> error:
16:53:18 <lambdabot>     • Variable not in scope: fromChunks
16:53:18 <lambdabot>     • Perhaps you meant one of these:
16:53:23 <EvanR> is toChunks
16:53:24 <Welkin> o.o?
16:53:27 <davr0s> Welkin in this example,  an inverse would be the decoder for an encoder, or vica versa
16:53:30 <ertes> davr0s: because we already have composable isomorphisms
16:53:50 <EvanR> do you mean you want to write the signature backwards in your search?
16:53:54 <davr0s> ertes generate ideally,  but if thats an intractable problem  - just imagine function/inverse pairs as a search tool
16:54:17 <davr0s> of course there might be many potential inverses
16:54:38 <EvanR> Welkin: the (right) inverse of a function f would be a g s.t. f . g = id
16:54:50 <davr0s> EvanR  more than that:    basically    x= f.g x   - here's 'f', find me 'g'
16:55:09 <EvanR> you mean heres a predict library function?
16:55:14 <EvanR> or arbitrary code
16:55:17 <ertes> davr0s: https://hackage.haskell.org/package/ad
16:55:24 <EvanR> predefined*
16:55:25 <ertes> davr0s: it's not about inverses
16:55:31 <ertes> davr0s: but about derivatives
16:55:37 <davr0s> ok interesting
16:55:50 <ertes> davr0s: kinda magic, if you don't know how it works =)
16:55:51 <Tuplanolla> I think J could derive inverses for some functions.
16:55:56 <davr0s> i also saw something really interesting for clojure, where you search for functios by giving example input and output
16:56:13 <davr0s> "give me  'f'  such that   f [1,2,3] = [3,2,1]
16:56:20 <ertes> davr0s: you give it a formula as a regular numeric haskell expression, and it gives you the derivative…  it's *not* meta-programming, but just a regular library
16:56:36 <davr0s> interesting stuff
16:56:55 <ertes> davr0s: some could be done (and to some extend has been done) for isormophisms
16:57:05 <ertes> or even just mono- and epimorphisms
16:57:24 <ertes> *extent
16:58:13 <ertes> i wonder if…
16:58:16 <ertes> @let import Numeric.AD
16:58:17 <lambdabot>  .L.hs:139:1: error:
16:58:17 <lambdabot>      Failed to load interface for ‘Numeric.AD’
16:58:17 <lambdabot>      Perhaps you meant
16:58:20 <ertes> too bad =)
16:58:41 <davr0s>  imagine 'a realtime renderer' being 'a peice of haskell code to encode something, which generates C source for decoding it at runtime"
16:58:59 <EvanR> sounds good :)
16:59:09 <EvanR> rendering DSL
16:59:17 <Rembane> Hm... Feltspar?
16:59:29 <EvanR> but why C source, why not shader source
16:59:29 <ertes> or GPipe
16:59:34 <davr0s> for example,   starting point - a polygon soup with material index per triangle;
16:59:45 <ertes> GPipe is that, but generates GLSL instead of C =)
17:00:06 <davr0s> the 'optimization' is a sort, now imagine it generates the equivalent loops to traverse (set the material per batch, render the componetns of that batch)
17:03:10 <davr0s> a lot of my friends are just using C# these days e.g. unity (where the underlying engine is still C++)
17:03:44 <davr0s> thats not really satisfying for me :) 
17:04:32 <ertes> your friends probably just want to make a game =)
17:05:18 <davr0s> yes it is pragmatic.
17:05:46 <davr0s> of course we had the 'c++ / lua' combo in the past, i can see c# + c++ lets you move that divide 
17:05:59 <davr0s> c# doesnt' really interest me though
17:06:37 <Welkin> c# doesn't interest me either
17:06:43 <Welkin> write your whole game in lua using love
17:06:44 <Welkin> :D
17:07:04 <Welkin> like I said before, the problem with game development is programming
17:07:26 <systemfault> What do you mean? It's a tech problem?
17:07:28 <davr0s> my focus right now isn't actually making a game, it's "trying some new ideas / learning something new."
17:07:36 <Welkin> no one wants to make a physics engine, and a renderer, and mess with opengl, they just want to quickly make a game
17:07:58 <systemfault> Ah, yeah... writing everything from scratch is just too much work
17:12:09 <colonelj> my stack build isn't working any more, anyone understand this error: "base must match >=3 && <10, but the stack configuration has no specified version (latest applicable is 4.9.1.0)" and several similar
17:12:25 <colonelj> it says "Recommended action: try adding the following to your extra-deps" but when I tried doing that it had no effect
17:12:38 <colonelj> also when I did 'stack solver' it said to delete those
17:14:09 <geekosaur> are you on arch? are you using the system compiler?
17:14:19 <colonelj> yes, it was working before...
17:14:29 <geekosaur> and then you upgraded to ghc8.0.2 and it broke
17:14:35 <colonelj> pretty much
17:15:01 <colonelj> I don't understand what the errors mean
17:15:01 <geekosaur> since you;re already using stack, your best bet is likely to switch to letting stack manage the compiler and removing the arch-installed one
17:15:15 <geekosaur> the errors mean the arch ghc maintainer is an idiot.
17:15:47 <geekosaur> specifically they removed the static libraries but did not reconfigure ghc for dynamic haskell libraries, so now it can't find anything because it won't use the dynamic libs that are the only ones installed
17:16:40 <colonelj> urgh
17:16:53 <monochrom> This is why I hate those distro party lines.
17:17:52 <geekosaur> you could also install the ghc-static package which will get you past *this* problem, but you will continue to have problems with any Haskell libraries installed via pacman
17:18:03 <monochrom> For another example, the Red Hat/Fedora party line means fragmenting GHC beyond recognition.
17:18:12 <geekosaur> (because they didn't bother to make static lib packages for those, only for the base libraries)
17:18:55 <EvanR> i dont really understand why each distro, even ones that are duplicates of another distro, must have a duplicate package management system and team to maintain the universe
17:19:29 <monochrom> I am actually OK with a duplicate team.
17:19:29 <EvanR> seems like a waste
17:20:20 <EvanR> and theres no way out, because as soon as you reject this and do it yourself, you just became another team
17:20:24 <monochrom> Ubuntu takes stuff from Debian, but the presence of Ubuntu's own team actually implies that things are significantly more tested and less breaking.
17:20:52 <pacak> Debian is stable, just ancient.
17:21:00 <geekosaur> likewise mint takes from ubuntu, but 90% of the packages are directly from ubuntu and just get extra testing with the mint environment
17:21:04 <colonelj> geekosaur: so are you saying uninstall ghc and install ghc-static and it should work?
17:21:15 <Clint> pacak: not this month it's not
17:21:43 <monochrom> I got this from a conversation with a sysadmin friend. I said I routinely "apt-get upgrade" and just said yes and never ran into a problem. The friend said you couldn't do this on Debian.
17:21:45 <geekosaur> colonelj, no, if you insist on using arch's ghc package then you either remove it and get ghc somewhere else, OR you ALSO install ghc-static AND expect to run into further breakage later
17:22:04 <Clint> monochrom: your friend is confused
17:22:08 <geekosaur> monochrom, that usually works with debian stable. testing and especially sid/unstable, not so much
17:22:16 <colonelj> geekosaur: ok I'll install ghc-static as well and see what happens
17:22:51 <geekosaur> things should not make it into debian stable without being fully tested so apt-get upgrade should just work
17:23:14 <colonelj> this GHC stuff on arch is supposed to be tested :)
17:23:34 <geekosaur> "supposed to be:
17:23:45 <geekosaur> since the whole haskell ecosystem is currently broken, apparently not
17:23:48 <colonelj> geekosaur: I'm still getting the same error...
17:23:48 <geekosaur> (on arch)
17:24:03 <monochrom> Observation trumps ideology.
17:24:20 <yushyin> works for the arch packages, works if you use stack for development stuff
17:24:22 <monochrom> Screw ideology.
17:24:24 <colonelj> fuck it time to -Rr this bitch
17:24:27 <yushyin> so yeah, no broken, just different
17:24:31 <yushyin> not*
17:24:50 <colonelj> ok -Rr doesn't work
17:25:18 <colonelj> oh -Rs I meant 
17:25:19 <MarcelineVQ> did you mean Rs? -Rsdd
17:25:35 <monochrom> Well, usually you can't just stay purely arch-installed, you will want to "stack install" some day.
17:26:43 <colonelj> d'oh, stack depends on ghc
17:26:57 <monochrom> \∩/ @remember geekosaur since the whole haskell ecosystem is currently broken
17:27:19 <monochrom> Don't even use arch's stack then.
17:27:26 <systemfault> stack depends on ghc?
17:27:31 <systemfault> I don't think so.
17:27:32 <EvanR> stack can be installed without ghc, breaking the time loop
17:27:36 <yushyin> systemfault: sure for the rts
17:27:49 <geekosaur> arch's stack package probably does, yes
17:27:50 <monochrom> stackage.org gives you a way to download the original authoritative official stack binary, no?
17:27:52 <yushyin> if you dynlink the rts
17:28:01 <geekosaur> and since they switched to dynamic for everything..
17:28:28 <EvanR> making the dependency tree cyclic is the only aesthetic way to do it
17:28:37 <monochrom> Did I say this is why I hate distro party lines and ideologies.
17:28:53 <systemfault> I just remember using stack on osx/windows/linux and it was stack that downloaded ghc and everything. hmm
17:29:01 <EvanR> yep
17:29:27 <colonelj> how about... I just suffer the pain of having two copies of GHC installed
17:29:39 <colonelj> what's the incantation to undo the incantation that makes stack use the system GHC
17:29:40 <EvanR> you can have as many as you want with stack!
17:29:41 <monochrom> Why are people so afraid of installing software from outside of their distro?!
17:29:59 <Clint> because only my distro is trustworthy
17:30:14 <systemfault> monochrom: Because they "usually" don't follow the distro convention and install stuff everywhere.
17:30:22 <systemfault> Stack is totally fine though.
17:30:24 <MarcelineVQ> if you invoke stack commands with  stack --no-system-ghc [the rest]  you can probably get away with it
17:30:27 <EvanR> to be fair, are we sure arch wont revolt and implode if you try to use stuff outside the distro
17:30:47 <colonelj> stack config set system-ghc --global false
17:31:02 <monochrom> If arch implodes on me, I'll just switch to Ubuntu. It's a free market.
17:31:19 <EvanR> just saying it might explain the phenomenon
17:31:22 <monochrom> And apparently arch is also aware of that, so it has no incentive to implode on me.
17:31:24 <EvanR> taking the question literally
17:31:43 <colonelj> it's pretty easy in arch to package up your own installation if you want to
17:32:00 <colonelj> that's how the whole Arch User Repository thing works so well
17:33:02 <EvanR> installing everything myself works so well, but i cant tell you why
17:33:35 <colonelj> it's just nice to have stuff going through the package manager even if it's your own installation
17:33:41 <monochrom> Works for me too and I can tell you why. Because "./configure --prefix=/usr/local/haskell/ghc-8.0.2" exists.
17:33:50 <Welkin> I install software from shell scripts on the internet
17:34:01 <EvanR> package manager manager manager manager...
17:34:14 <EvanR> i love management
17:34:15 <Welkin> curl https://nixos.org/nix/install | sh
17:34:26 <colonelj> "This will not interfere with any system-level installation." she says
17:34:28 <Welkin> same with homebrew
17:34:53 <EvanR> i have ghc install on osx 3 ways right now, including stack. stack is not interfering
17:35:21 <colonelj> sausage 3 ways
17:36:30 <systemfault> colonelj: With stack, you don't run ghc/ghci/etc directly, you have to use stack: stack ghc/stack ghci etc...
17:36:30 <EvanR> the whole idea of "installing" is really kind of the origin sin
17:36:38 <colonelj> systemfault: I know but thanks
17:36:50 <colonelj> I use it like this at work
17:36:55 <EvanR> where a windows installer would take all day with a progress bar "installing", which was vague at best on what it was doing
17:37:10 <EvanR> people thought it was a fundamental action of computing
17:37:24 <EvanR> once you have to install stuff, you then need a way to manage installations
17:37:25 <monochrom> heh
17:37:57 <EvanR> then when you have this loose exe that "just works" people are confused about what to do with it
17:38:06 <EvanR> need to enhance the manager to allow installation
17:38:12 <colonelj> it's a virus!
17:38:29 <Welkin> it's a virile young program
17:38:40 <Welkin> that just wants to ensure its contined existence
17:38:51 <Welkin> continued*
17:39:20 <EvanR> BeOS kicked ass by just not having any of this
17:39:33 <monochrom> Oh! What did it do instead?
17:39:44 <EvanR> loose exes
17:40:11 <monochrom> It means static linking, doesn't it?
17:40:20 <EvanR> probably
17:40:34 <EvanR> or using standard OS dynamic libs
17:40:56 <monochrom> That could work.
17:42:56 <colonelj> so EvanR when this finishes installing all this crap again, what are the incantations needed to derive any useful information about space leaks?
17:43:29 <EvanR> they are contained herein https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html
17:43:52 <colonelj> would you like to highlight any in particular?
17:43:54 <EvanR> make sure you say the incantations exactly or you might cause evil dead
17:44:06 <colonelj> you mean evil undead?
17:44:34 <colonelj> or evil deed?
17:44:43 <MarcelineVQ> There were some pretty good links and opinion on the topic of space yeaks yesterday as I recall
17:44:51 <EvanR> https://www.youtube.com/watch?v=zgvXtexdgAM
17:45:12 <colonelj> I don't think my CPU can handle youtube whilst installing haskell libraries
17:45:30 <colonelj> meh lets give it a go
17:46:19 <EvanR> -hr is retainer profiling, -hb is biographical profiling, 
17:46:40 <EvanR> MarcelineVQ: yeah colonelj mentioned that there were links 
17:47:21 <yushyin> colonelj: fiy, I let the system stack install local ghcs for my devstuff and it works ok in arch and it’s fine this way because I need different ghc versions anyway
17:47:28 <yushyin> fyi
17:48:57 <colonelj> yeah I'm doing that if I read you right
17:49:17 <monochrom> MarcelineVQ: I think they were in fact all answers to colonelj but look how much progress since then!
17:49:17 <colonelj> I just don't really want dozens of GHC installs on my machine
17:49:31 <Welkin> colonelj: you will have several
17:49:40 <Welkin> use nix package manager
17:49:43 <EvanR> no true version of GHC...
17:49:44 <Welkin> no compiles
17:49:59 <colonelj> I don't want another package manager
17:50:05 <Welkin> nix is different
17:50:11 <EvanR> you need a package manager manager!
17:50:11 <MarcelineVQ> monochrom: Yeah, sometimes answers get bound up in poster-cruft and fart sniffing, but they're often in there somewhere.
17:50:17 <monochrom> In fact it looks like a Pilgrim's Regress because we're going back to installing compilers.
17:50:30 <Welkin> what do the pilgrims have to do with this?
17:50:57 <monochrom> Haskell pilgrims.
17:51:05 <geekosaur> that reference is too old for these young'uns
17:51:09 <yushyin> colonelj: well, I thought so too, but I ended up needing different ghc versions anyway
17:51:21 <EvanR> @quote pilgrim
17:51:21 <lambdabot> danderson says: the path to [Haskell] enlightenment is long, but the previous pilgrims have opened nice little pubs along the way, so it's a pleasant trip
17:51:26 <monochrom> OK, Power Ranger reboot.
17:52:13 <Welkin> who were the haskell pilgrims?
17:52:24 <Welkin> are you talking about before haskell was created?
17:52:36 <monochrom> dons and tibbe
17:53:04 <Welkin> I still don't get how that relates
17:54:15 <monochrom> I digress.
17:54:30 <Clint> i regress
17:54:41 <colonelj> I ingress
17:54:42 <Welkin> I progress
17:55:42 <colonelj> Package blah uses a custom Cabal build, but does not use a custom-setup stanza... etc. blah blah blah * many
17:56:20 <exio4> geekosaur: it was dead, I just did xdotool key XF86Ungrab and it worked
17:56:57 <colonelj> EvanR: so these retainers and biographies, what are they?
17:57:02 <geekosaur> exio4, then that sounds like an X server bug; any grabs held by a client should be removed automatically
17:57:39 <EvanR> who is holding, what stage of life stuff being held is in
17:57:54 <exio4> geekosaur: yeah, I think it was something with the X11 server + gpu driver (I am running X11 inside a container and sometimes weird stuff happens)
17:58:02 <exio4> geekosaur: no idea how to reproduce it though
17:58:08 <EvanR> that profiling guide explains it all
17:58:20 <exio4> I tried the same thing again and it didn't bug 
17:58:22 <colonelj> it seems like a fairly partial explanation to me
17:58:30 <EvanR> mine? yes
17:58:44 <EvanR> so is your problem
17:59:00 <colonelj> do these profiling options actually allow you to relate stuff back to the code?
17:59:06 <EvanR> maybe youd settle for a partial solution!
17:59:17 <EvanR> yes, did you try them?
17:59:26 <colonelj> Progress: 54/56
18:00:22 <colonelj> would be useful if the profiler page had more example diagrams
18:00:41 <EvanR> of what
18:00:49 <colonelj> different graphs
18:01:17 <EvanR> you can generate many yourself
18:01:29 <colonelj> I am anticipating doing that
18:02:26 <colonelj> finally it's compiling my app
18:04:41 <colonelj> btw does anyone know how to get the 'gs' command to rotate the page on screen so I can actually read it?
18:06:05 <geekosaur> you don't generally use gs directly if you need to control the result, use a proper viewer instead. gv, eog/eom, etc.
18:06:13 <EvanR> gs?
18:06:21 <geekosaur> ghostscript, I am assuming
18:06:31 <geekosaur> and its display output drivers are basically for debugging
18:06:33 <geekosaur> not general use
18:06:36 <EvanR> right, i noticed the guide doesnt recommend using gs
18:08:04 <colonelj> is 'gv' ghostviewer?
18:08:16 <geekosaur> ghostview, yes
18:12:13 <colonelj> ok so I can get the same big triangle profile I got before
18:12:30 <colonelj> and ghostview has a button to rotate the image
18:12:39 <EvanR> is your code secret or what
18:13:14 <EvanR> also do you have screenshots
18:13:26 <colonelj> it's not super secret or anything
18:14:12 <colonelj> I'll try -hy
18:16:55 <colonelj> ok so all the memory is made up of ARR_WORDS
18:17:10 <EvanR> try -hr
18:18:14 <EvanR> 7.4.2.1. Hints for using retainer profiling
18:19:11 <colonelj> yeah that sounds useful
18:20:23 <colonelj> ok this -Hr graph looks very strange
18:21:16 <colonelj> and it mostly is at 4MB
18:23:31 <colonelj> it's not really showing me the 1GB
18:23:55 <EvanR> did you run it for the same amount of time
18:24:00 <EvanR> do you want to post a screenshot
18:24:12 <colonelj> yeah I don't have any screenshot stuff installed one min
18:24:18 <colonelj> and yes it took as long
18:30:39 <colonelj> ok the screenshot thing isn't working too well but here https://i.imgur.com/0I75jX6.png
18:30:57 <colonelj> (was trying to make it save to the clipboard and paste it somewhere)
18:31:06 <colonelj> (just made it directly save to imgur using the GUI tool)
18:32:01 <colonelj> EvanR: so anyway this is only showing the narrow strip along the bottom presumably
18:32:56 <colonelj> https://i.imgur.com/KSeOVp6.png the normal heap profile
18:34:00 <EvanR> something looks screwy with this output
18:34:01 <colonelj> I'll try -hb
18:38:17 <colonelj> https://i.imgur.com/3HiACAA.png biographical output EvanR
18:41:24 <EvanR> https://mail.haskell.org/pipermail/glasgow-haskell-users/2010-June/018906.html INHERENT_USE documentation :)
18:41:47 <EvanR> so i think you established its holding onto arrays
18:42:00 <EvanR> maybe that seemed obvious, but not it is obvious!
18:42:12 <EvanR> only by looking at code can anyone help explain why
18:45:19 <colonelj> might as well try hd
18:45:31 <EvanR> you could also try to reproduce the effect with more minimal code and post that
18:46:34 <EvanR> what do you think would happen if i asked ##c++ to explain a memory leak or segfault but i could not give any code
18:47:19 <colonelj> I'm asking for ways to debug it now to have it solved for me
18:47:49 <EvanR> it seems like a basic misunderstanding of haskell 
18:48:13 <colonelj> maybe it is, but I obviously couldn't tell you
18:48:28 <EvanR> this is pointless
18:49:22 <colonelj> yep just says ARR_WORDS again
18:49:52 <monochrom> I would answer EvanR's question directly and not dodge it. Teach us how people troubleshoot space in C++ or Java, so we know what we're missing.
18:50:16 <monochrom> Although I suspect that in the Java case they just don't, they request the boss to buy more RAM and be done.
18:50:47 <EvanR> assuming you want any progress whatsoever, maybe you could give a hint?
18:51:00 * EvanR presses the hint button
18:52:52 <colonelj> ok whatever I'll show you the data analysis code since I think that's where the problem is
18:53:34 <colonelj> http://lpaste.net/6145664808311062528
18:53:55 <colonelj> calcReturns and meanReturns works nice and fast without issues
18:54:06 <colonelj> the results of those get fed to returnCovMatrix
18:54:43 <EvanR> how about a main function which reproduces the bad memory performance
18:55:18 <EvanR> or input data to test one of these functions with
18:56:48 <colonelj> I knew you'd be asking for more
18:56:55 <colonelj> you want something you can actually run
18:57:26 <Lokathor> yes, would help
18:57:57 <EvanR> its 4 functions which return something, they cant really hold onto anything by themselves
18:58:14 <EvanR> there would have to be a loop thats running for 40 seconds to figure out where the holding is happening
18:58:34 <colonelj> there's no loop
18:58:48 <EvanR> hmm. well i guess if one of these functions is taking 40 seconds, they could be responsible
18:59:20 <colonelj> the first two finish almost instantly
18:59:56 <EvanR> :t ($!!)
18:59:57 <lambdabot> error:
18:59:57 <lambdabot>     • Variable not in scope: $!!
18:59:57 <lambdabot>     • Perhaps you meant one of these:
19:00:33 <colonelj> it's like $! but deepseq
19:01:48 <EvanR> not that this is explaining anything, but using $!! everywhere might be causing worse performance
19:02:06 <EvanR> returnCovMatrix takes a list, you want that list to be generated lazily if possible
19:02:25 <EvanR> and $!! on a transpose is probably messing that up
19:02:40 <EvanR> deepseqing lists is probably really bad
19:03:16 <colonelj> I don't deepseq the input to returnCovMatrix if you actually read the code
19:04:05 <EvanR> im talking about the output of calcReturns
19:04:09 <colonelj> anyway adding the $!! didn't make any difference that I could tell
19:04:12 <EvanR> line 19
19:04:18 <mnoonan> are meanReturns and returnCovMatrix both getting applied to the output of calcReturns?
19:04:26 <EvanR> later on 36 youre doing it again
19:04:47 <EvanR> instead of consuming a lazy list, you ask it to fully materialize the whole thing first
19:05:16 <mnoonan> (and is there a time profile somewhere that I missed?)
19:05:53 <colonelj> mnoonan: meanReturns gets the output of calcReturns and returnCovMatrix gets the output of both
19:06:44 <mnoonan> so the list getting returned from calcReturns can’t be used like a stream, and has to stick around. could that explain what you’re seeing?
19:06:59 <EvanR> yeah so if it werent already doing all these deepseqs, then you will have this big list of timeseries in memory because of that
19:07:36 <EvanR> to begin processing the vector it will first need to traverse the list, and it wont be consumed since you still need it
19:08:51 <colonelj> like I said... the first two functions execute quickly and produce results on screen for the means
19:09:02 <colonelj> the space leak happens AFTER that
19:09:30 <EvanR> maybe try creating "two copies" of the timeseries, use one for the means, and use one for the covmatrix call
19:09:35 <EvanR> and removing all the deepseqs
19:09:52 <EvanR> since its so fast to produce
19:10:27 <colonelj> ok
19:10:37 <EvanR> you will consume one to get a vector, then consume the other AFTER, and hopefully have nothing much in memory
19:11:18 <monochrom> Oh this is basically "sum xs `div` length xs"?
19:11:26 <EvanR> maybe
19:12:15 <EvanR> would be a nice time for "dupThunk" !
19:12:35 <colonelj> btw, is it ok if I do "let smth = blah in let smth2 = doSmth blah in
19:12:37 <monochrom> Yeah Oleg will like that too.
19:12:57 <colonelj> " rather than just writing "let smth2 = doSmth blah"
19:13:05 <EvanR> sure
19:13:07 <colonelj> as in if I don't use the let again will it not be kpet lying around
19:13:30 <EvanR> do you mean let smth = blah in let smth2 = doSmth smth in"
19:13:38 <monochrom> I don't think it's that simple.
19:13:52 <colonelj> yeah I meant that
19:14:15 <monochrom> Doesn't look like any difference to me.
19:14:16 <mnoonan> there might be a second sum xs `div` length xs thing going on in returnCovMatrix
19:14:30 <EvanR> theres no diff
19:14:36 <EvanR> blah might be a big expression though
19:15:11 <monochrom> Unless 'smth' is mentioned twice, there is no difference.
19:15:40 <EvanR> the corresponding thing on line 33 is just, "blah" is a really big expr
19:15:46 <monochrom> And if 'smth' is mentioned twice, you actually incur the risk of another "sum xs `div` length xs" again. (Look how xs is mentioned twice!)
19:15:48 <EvanR> so you can put it in a let to separate it
19:16:25 <colonelj> ok so now I've got it calling calcReturns <$> samps twice in main
19:16:28 <pikajude> what hscolour stylesheet is used on hackage, and how can I use it?
19:16:33 <colonelj> one for the means and ones for the covariance matrix
19:16:37 <pikajude> does anyone know
19:17:24 <pikajude> specifically for base
19:18:04 <ackpacket> Any serious tools or well known websites built using haskell?
19:19:12 <geekosaur> https://downloads.haskell.org/~ghc/latest/docs/html/libraries/base-4.9.0.0/src/hscolour.css
19:19:33 <pacak> ackpacket: ghc, pandoc.
19:19:42 <EvanR> git-annex
19:19:44 <pacak> git annex
19:20:13 <pacak> It's used in finance industry.
19:20:14 <EvanR> nikki and the robots
19:20:22 <pikajude> geekosaur: http://hackage.haskell.org/package/base-4.9.1.0/docs/src/GHC.Unicode.html
19:20:25 <pikajude> definitely not
19:20:32 <pikajude> although those class names are also different
19:20:51 <pikajude> so, apparently it was a different haddock version or something
19:20:56 <pacak> ackpacket: facebook?
19:21:07 <geekosaur> looks like it may be custom
19:21:07 <ackpacket> pacak, facebook uses haskell?
19:21:13 <pikajude> it does
19:21:14 <EvanR> pacak: serious tools only please
19:21:20 <pikajude> not for main front of site though
19:21:21 <geekosaur> http://hackage.haskell.org/package/base-4.9.1.0/docs/src/style.css http://hackage.haskell.org/package/base-4.9.1.0/docs/src/highlight.js
19:21:31 <pikajude> gross
19:21:32 <pacak> ackpacket: They do in spam filtering system for example.
19:21:50 <ackpacket> pacak, you work there?
19:22:01 <pacak> ackpacket: Nope, but I work in finance.
19:22:27 <pacak> EvanR: You right, facebook is probably not a serious tool.
19:22:28 <colonelj> EvanR: doesn't look like any improvement after repeating the calcReturns bit
19:22:56 <ackpacket> I use haskell at work and I'm proficient enough to get my day-to-day done reasonabley cleanly without any blockers.  But I'm trying to convince myself it's worth setting aside time and learning it to a... more expert level.  Part of that consideration is how much my opportunity set opens up in the job market
19:24:02 <pacak> ackpacket: Don't do it. Less competition - higher my salary is.
19:27:39 <d34df00d> I missed such a good discussion about performance, eh.
19:28:27 <colonelj> the last recommendation was to recompute everything so you don't reuse the same stream lol
19:28:48 <colonelj> ok EvanR I've done it so I recalculate the returns 3 damned times and calculate the means twice
19:28:54 <colonelj> this has got to be more efficient
19:29:16 <The_Kinaesthetic> hi
19:29:31 <d34df00d> So I'm gonna repeat my question from a few hours before: I have a mutable vector of mutable vectors, and I want to get an immutable one of immutable ones. I was suggested to do "traverse Data.Vector.unsafeFreeze <=< Data.Vector.unsafeFreeze", but it seems to freeze the outer vector first, leading to excessive copying for freezing internal vectors, it seems. Amirite? If so, is it possible to do the freezes in the other order?
19:29:51 <The_Kinaesthetic> I defined a tree datatype as such->  data Tree a = B [Tree a] | L a
19:30:22 <The_Kinaesthetic> I'm curious what the a in "Tree a" actually signifies since Tree itself never actually gets a value, only "L a"
19:30:34 <The_Kinaesthetic> And omitting that a causes errors so it seems necessary
19:31:03 <colonelj> it signifies a type
19:31:14 <colonelj> of what can go inside your tree
19:32:51 <monochrom> If you use "Tree Int" then you can put Int's in your leafs, for example B [L 1, L 2]
19:33:12 <pacak> The_Kinaesthetic: This means all the trees inside this tree must be of the same type as this tree.
19:33:19 <monochrom> Go into ghci and enter: :type B [L 'x', L 'y']
19:33:27 <The_Kinaesthetic> ahhh
19:33:32 <monochrom> you should get "Tree Char" because 'x' and 'y' are Char
19:33:49 <monochrom> Also, "leafs" trumps "leaves".
19:34:08 <The_Kinaesthetic> you are correct
19:34:23 <monochrom> "leaves" is ambiguous anyway. "monochrom leaves" --- does that mean monochrom is going away, or does it just mean he's verbifying "leave"?
19:34:34 <monochrom> err, verbifying "leaf"!
19:34:54 <monochrom> Damn English.
19:35:10 <The_Kinaesthetic> why is it that a type constructor isn't needed for something like "data happiness = sad | happy | blissful" or 
19:35:19 <colonelj> ok I'm going to try not trusting let, and then giving up
19:35:32 <monochrom> sad, happy, and blissful are the data constructors there.
19:35:40 <geekosaur>  because they have no inner values with parameterized types (or indeed at all)
19:35:51 <monochrom> Oh, misread.
19:35:53 <The_Kinaesthetic> so type constructors are only needed for inner values?
19:36:10 <The_Kinaesthetic> Does that mean i can do "data Tree = B [Tree] | Int" ?
19:36:21 <The_Kinaesthetic> I should probably just try it rather than asking lmao
19:36:25 <monochrom> data Tree = B [Tree] | L Int
19:36:42 <The_Kinaesthetic> what I did seemed to have worked
19:36:47 <monochrom> You need a type variable iff you go polymorphic.
19:36:55 <monochrom> That's a different Int.
19:37:07 <The_Kinaesthetic> ?
19:37:17 <monochrom> Have you see "data XX = XX"?
19:37:22 <geekosaur> you created a data constructor (enum, if you will) called "Int"
19:37:29 <geekosaur> it does not take an Int value
19:37:30 <geekosaur> it's just a name
19:37:31 <monochrom> The two XX's are distinct.
19:37:34 <The_Kinaesthetic> o
19:37:58 <The_Kinaesthetic> oooo
19:38:03 <The_Kinaesthetic> ok i think I understand now
19:38:04 <The_Kinaesthetic> Danke
19:38:04 <monochrom> with your version all you can do is "B [L Int, L Int, L Int]". No L 5.
19:38:11 <monochrom> err
19:38:17 <tput> In a data declaration, the thing on the left of the equals sign is a type constructor (it names a type). The stuff on the right are the data constructors (they name the kinds of data that type can contain).
19:38:17 <monochrom> with your version all you can do is "B [Int, Int, Int]". No L 5.
19:38:18 <The_Kinaesthetic> Yes, I understand
19:38:36 <The_Kinaesthetic> I think the values will always be tuples
19:38:41 <The_Kinaesthetic> for my purposes
19:38:48 <The_Kinaesthetic> but I'll leave it polymorphic for now
19:38:54 <The_Kinaesthetic> Thanks!!
19:54:24 <dmwit> wrengr_away: I'm sending a mail to the address you have listed on c.h.o, but I thought I'd also ping you here just in case you don't receive mail there any more.
19:56:26 <dmwit> (Ping me back if that's the case and I'll send you the information in whatever better way you tell me.)
19:57:30 <heebo> i have a [[Int]] and I want it such that there are no duplicate permutations 
19:57:44 <heebo> can anyone think of an elegant way to do this?
19:57:47 <dmwit> :t nubBy (\xs ys -> sort xs == sort ys)
19:57:49 <lambdabot> Ord a => [[a]] -> [[a]]
19:58:15 <dmwit> But it's probably going to be better to just not generate duplicate permutations in the first place.
19:59:06 <dmwit> Also, depending on how production-ready you want this to be, look into a decorate-sort-undecorate-based method to avoid quadratic behavior and frequent re-sorting.
20:00:08 <dmwit> :t \perms -> M.elems $ M.fromList [(sort xs, xs) | xs <- perms]
20:00:09 <lambdabot> Ord a => [[a]] -> [[a]]
20:00:28 <dmwit> That way will be much more efficient. I should have just said that one first. =P
20:01:00 <dmwit> > M.elems . M.fromList . (sort &&& id) $ [[3,7,5],[7,5,3],[1,2,4]]
20:01:02 <lambdabot>  error:
20:01:02 <lambdabot>      • Couldn't match type ‘([[Integer]], [[Integer]])’ with ‘[((), a)]’
20:01:02 <lambdabot>        Expected type: [[Integer]] -> [((), a)]
20:01:35 <dmwit> :t sort &&& id
20:01:36 <lambdabot> Ord a => [a] -> ([a], [a])
20:01:42 <dmwit> oh
20:01:47 <dmwit> > M.elems . M.fromList . map (sort &&& id) $ [[3,7,5],[7,5,3],[1,2,4]]
20:01:49 <lambdabot>  [[1,2,4],[7,5,3]]
20:02:09 <heebo> awesome thanks
20:40:25 <suzu> is ghc-8.0.1 the latest ghcjs for stack?
20:43:17 <colonelj> EvanR: I found a way to reduce the heap usage by 20% by using the mTm function
20:43:52 <EvanR> whats the mTm function
20:44:22 <arahael> "man to man"?
20:46:01 <colonelj> matrix transpose multiplied by the same matrix
20:46:22 <colonelj> and it outputs a hermitian so I don't need to bother using 'sym'
20:46:40 <colonelj> which is probably where the saving is
20:47:03 <colonelj> I'm wondering if the way I'm using fmap over my sample set is causing it to hold onto everything
20:47:31 <colonelj> I maybe need to write a strict version of fmap for samples
20:47:47 <colonelj> deepseqly strict
20:52:38 <dmwit> Automatic differentation is way cool. Is there an automatic integration?
20:53:24 <colonelj> did what I just say make any sense :S
21:00:39 <EvanR> colonelj: no i think youre usage of deepseq on lists is causing a lot of extraneous memory usage
21:00:43 <EvanR> your*
21:01:17 <colonelj> the graphs disagree with you though, it made no difference
21:01:30 <EvanR> you have no hope of reducing it if you put the deepseqs there
21:01:35 <EvanR> is the difference
21:01:57 <colonelj> I want to somehow break up the computations of each sample set
21:01:58 <EvanR> its like putting more weight in your balloon that youre trying to make fly
21:02:06 <EvanR> its not going to help it fly
21:02:48 <colonelj> is liftA2 a b c better than a <$> b <*> c
21:02:55 <EvanR> its the same thing
21:03:16 <colonelj> it's not though is it?
21:03:23 <pacak> @src liftA2
21:03:23 <lambdabot> liftA2 f a b = f <$> a <*> b
21:03:36 <EvanR> haskell takes its '=' seriously :)
21:04:01 <colonelj> ok lol
21:05:52 <EvanR> a strict map doesnt really make sense
21:06:25 <EvanR> either you are consuming a lazy list 1 by 1, or you did something to cause the whole list to be generated, and thats that
21:06:42 <colonelj> yeah but then when you map it it becomes lazy again
21:07:06 <EvanR> which is good
21:07:19 <colonelj> is a <$> b <*> c the same as (a <$> b) <*> c
21:07:22 <ReinH> I told you deepseq was a bad idea days ago
21:07:24 <monochrom> Yes.
21:07:29 <EvanR> what would be bad is if you keep generating whole lists in each intermediate step, like other languages
21:07:43 <colonelj> ReinH: I haven't seen any empirical evidence so far
21:07:49 <EvanR> instead you want to be lazy at each step
21:07:51 <ReinH> Has it fixed your problem?
21:08:10 <colonelj> it makes it easier to see where stuff is happening
21:08:19 <EvanR> you can fix your problem with deepseqs everywhere
21:08:22 <EvanR> cant**
21:08:34 <colonelj> ok well, how do I fix the problem
21:08:44 <ReinH> One of these days someone will believe me rather than proving it to themselves weeks later by trying to preove me wrong.
21:08:46 <EvanR> remove them all, then figure out where the problem is
21:09:01 <colonelj> but then everything gets evaluated last minute
21:09:12 <ReinH> This is the purpose of the original link I gave you.
21:09:14 <EvanR> youre trying to reduce memory usage
21:09:24 <monochrom> ReinH: You need to migrate to debating over climate change instead. :)
21:09:28 <ReinH> To figure out what evaluations should be connected and enforce those space invariants
21:09:36 <EvanR> in which case evaluation will go faster, and right when its supposed to
21:09:47 <ReinH> Step one is, again, actually thinking about your problem
21:09:53 <ReinH> not just trying things randomly until something works
21:09:56 <monochrom> In the face of overwhelming evidence, the human mind steels its resolve and reject.
21:10:17 <ReinH> monochrom: sometimes there's no substitute for experience.
21:10:23 <colonelj> ReinH: I don't find your comments too helpful because the only way I've managed to reduce anything so far is by simplifying the code
21:10:36 <ReinH> Yes, simplifying the code is one good way to find things.
21:10:47 <EvanR> simplifying the code is a good first step to understanding the code
21:10:57 <ReinH> Reducing your problem to a minimal test case should have been the very first thing you did
21:10:58 <EvanR> and being able to post it to get help
21:11:03 <colonelj> by using deepseq I can see that the expectation part is irrelevant
21:11:17 <EvanR> by leaving deepseq there, youll never get better memory performance
21:11:26 <colonelj> it didn't make it worse
21:11:30 <EvanR> im not sure if you fully understand what it does?
21:11:38 <colonelj> it reduces to normal form
21:11:39 <EvanR> its use is antithetical to what youre supposedly trying to do
21:11:51 <colonelj> the graphs say it makes no difference
21:11:56 <colonelj> it just changes the time when evaluation happens
21:12:03 <EvanR> true
21:12:20 <EvanR> when your car is broken, hitting with a hammer does not fix it
21:12:35 <EvanR> it remains broken
21:12:47 <EvanR> keep hitting it?
21:12:57 <monochrom> This is a very sad conversation.
21:12:59 <colonelj> look when I find the problem and fix it I can remove the deepseqs
21:13:00 <ReinH> The mechanic is a good analogy.
21:13:25 <ReinH> If you go to a mechanic with a broken car and they say "Oh, your distributor needs to be replaced", do you then argue with them for days that it's really the spark plugs?
21:13:26 <EvanR> you wont detect a fix with the deepseqs there
21:13:58 <ReinH> What we're trying to tell you is that the deepseqs are hiding the problem.
21:14:03 <monochrom> Why are we even arguing?
21:14:11 <ReinH> But go ahead, do what you've been doing. Just don't expect different results.
21:14:44 <colonelj> why is it not useful to force evaluation of something?
21:14:49 <MarcelineVQ> monochrom: shucks buster, it's because people care about other people here
21:14:50 <monochrom> I posed the challenge "teach us how the Java or C++ people have any better tools or methods for this" and so far no one meets it. I rest my case.
21:14:55 <EvanR> a take away from this, i think is a good general rule, just dont use deepseq on lists
21:15:08 <EvanR> it uses a bunch of memory for no reason
21:15:11 <ReinH> colonelj: because finding out *which things* in particular need to be strict is probably the problem.
21:15:17 <ReinH> And deepseq prevents you from being able to do that
21:15:39 <ReinH> It's like playing a game of whack-a-mole by blowing up the whole game
21:16:06 <MarcelineVQ> it's like tears in the rain
21:16:23 <colonelj> ReinH: I'm trying to get to a solution...
21:16:45 <ReinH> Why are you even here arguing with us if you're so sure we don't know what we're talking about?
21:16:53 <ReinH> It doesn't make sense.
21:16:56 <ReinH> If you know what to do, go do it.
21:17:02 <ReinH> If you don't, why are you refusing to listen to us?
21:17:08 <EvanR> colonelj: the way haskell programs avoid memory usage is by using lazy evaluation. in the case of a list, you dont want to actually generate a list at all. you want to process the items in the list 1 by 1. to do this, you have to avoid forcing the whole list and avoid remembering the list items
21:17:20 <colonelj> I understand that
21:17:35 <EvanR> so there is no reason to force a whole list before going on
21:17:43 <colonelj> but if I need to use the same list multiple times I don't see how it helps not to strictly evaluate it for later
21:18:04 <monochrom> Then don't use a list.
21:18:06 <EvanR> there is an answer to that, but its irrelevant
21:18:07 <colonelj> e.g. the returns vectors I use those multiple times
21:18:17 <ReinH> I feel like the mere fact that I showed up days later to the exact same argument is a pretty good indicatoin that this isn't going anywhere.
21:18:57 <ReinH> We're going to keep offering suggestions. You're going to keep ignoring our suggestions while at the same time insisting that they don't help. It's futile.
21:19:06 <ReinH> I would like to talk about something else.
21:19:22 <monochrom> A fully fledged out list in memory has a very high constant multiplier overhead. 24n bytes and this is just the list structure itself, i.e., even "replicate n [()]" is already this big.
21:19:23 <colonelj> I haven't heard any suggestions recently except for 'remove the deepseqs' even though I know they make no difference
21:19:35 <EvanR> vectors are generally more memory efficient, and cant be lazily produced
21:19:39 <ReinH> You already know everything. That's the problem.
21:19:42 <EvanR> so it makes sense to force those something
21:19:44 <EvanR> sometimes
21:19:52 <colonelj> I am using vectors
21:20:10 <EvanR> colonelj: thats not true, i also suggested generating the input lists twice
21:20:19 <EvanR> no, youre using lists critically in several places
21:20:27 <ReinH> If I am right that the deepseqs prevent you from analyzing the problem then there's no point in suggesting anything else until they are removed.
21:20:39 <monochrom> Selective listening bias.
21:20:43 <colonelj> fine I'll remove them again if you want, but I don't know what to do after that
21:21:02 <ReinH> Remove code until the problem stops. Find a minimal test case.
21:21:10 <EvanR> what happened when you generated the input list twice? or did you do that while not removing the deepseqs
21:21:20 <ReinH> If you do that, there's a decent chance that the last code you removed is related to the problem.
21:21:30 <colonelj> I had all the deepseqs removed and generated everything multiple times, same space leak
21:21:37 <ReinH> LOL
21:21:41 <EvanR> ok
21:21:42 <monochrom> My father knows how to play this game too. He does something wrong, then goes on to say "I don't recall it" and his conscience is feeling very good about his innocence.
21:21:51 <ReinH> I never suggested that removing the deepseqs would fix anything
21:21:53 <ReinH> come on
21:22:10 <EvanR> i included removing deepseqs with an attempt to improve the memory
21:22:19 <EvanR> since otherwise, it wouldnt matter
21:22:26 <ReinH> It would matter.
21:22:46 <colonelj> ok I'm removing the deepseqs again
21:22:47 <ReinH> deepseq obliterates everything strictness-related in its view.
21:24:08 <ReinH> The best way to solve memory leaks, in lieu of a smoking gun, is to divide and conquer.
21:24:20 <EvanR> i assure you that if you post a minimal test case of the offending performance, someone will carefully explain why its happening and probably help fix it
21:24:21 <ReinH> Split up your program into smaller programs and see which one(s) exhibit the leak.
21:24:39 <EvanR> theyre not going to just give you a fixed program without telling you what was wrong
21:24:42 <colonelj> I already know that the leak is in returnCovMatrix
21:24:48 <colonelj> and I showed the code for that
21:24:54 <EvanR> im not sure you proved that
21:24:54 <ReinH> How do you know that?
21:24:59 <ReinH> Laziness makes it hard to know that.
21:25:10 <EvanR> well, there was no laziness in that code at all
21:25:12 <colonelj> well it wasn't lazy when I had the deepseqs in
21:25:34 <colonelj> the memory leak and computations all happen within returnCovMatrix inside the fmap
21:25:39 <EvanR> but you didnt prove that thats whats causing the space issue
21:25:49 <arahael> To flip the table about...
21:25:57 <ReinH> If the deepseqs didn't change the memory consumption then it's likely that the problem isn't *when* you're evaluating but *what* you're evaluating.
21:26:33 <arahael> colonelj: If you're so certain that the problem is in returnCovMatrix...  And that the test case you provided doesn't exhibit the problem *because* it's not lazy; why not make it non-lazy in the application as well?
21:26:58 <colonelj> I think I did that already
21:27:01 <EvanR> the "test case" does exhibit the problem
21:27:14 <ReinH> Where's the code for this test case?
21:27:16 <colonelj> ok the deepseqs are gone and I recompiled
21:27:31 <ReinH> preferably with and without the deepseqs
21:27:46 <EvanR> colonelj: how large is the dataset? how large is the output array?
21:27:59 <ReinH> Nothing guarantees that the deepseqs were used correctly.
21:28:17 <EvanR> ReinH: http://lpaste.net/6145664808311062528
21:28:41 <colonelj> I have 500 samples of time series consisting of 51 price ticks for 3 assets
21:28:44 <EvanR> the triangle shape, with the lack of info so far, could just be the filling up of the output vector
21:29:03 <EvanR> and its literally what you asked for
21:29:12 <colonelj> it's not because when I simplified the code the triangle is now 20% less high
21:29:33 <EvanR> yeah so you might be holding onto itermediate arrays
21:29:49 <colonelj> it is holding onto intermediate stuff obviously, I want it to stop doing that
21:29:50 <EvanR> which might be happening in the outside code
21:29:56 <EvanR> thats running these 4 functions
21:30:51 <EvanR> youre also probably holding onto the payloads of the various lists 
21:31:05 <ReinH> I'm assuming that the storable vectors are the pinned heap
21:31:23 <colonelj> fresh screenshot https://i.imgur.com/wQCumUR.png
21:32:00 <EvanR> Matrix being regular data constructors wrapping the arrays
21:32:04 <ReinH> Well, you're creating a bunch of vectors.
21:32:19 <colonelj> the output is only the matrices
21:32:30 <colonelj> so the rest of it looks like garbage
21:32:30 <EvanR> internally there are vectors
21:32:45 <EvanR> well how much output data is there?
21:32:52 <colonelj> 500 3x3 matrices
21:33:01 <EvanR> of what, Doubles
21:33:10 <ReinH> you convert them to and from lists, you map them. You're creating a bunch of garbage.
21:33:15 <colonelj> so 500 * 9 * 8 bytes = 36KB
21:33:41 <EvanR> if any of those Doubles points into your intermediate or source data, they wont be collected
21:33:55 <EvanR> not sure if hmatrix does that
21:34:37 <ReinH> AFAI can tel, the space leak isn't due to laziness at all.
21:34:43 <ReinH> You're just creating a lot of garbage.
21:34:53 <ReinH> So it isn't surprising that deepseq didn't change much
21:35:09 <EvanR> and its not be collected until the very end
21:35:25 <EvanR> cant be right
21:36:16 <ReinH> This code creates a ton of garbage by using storable vectors in a way that I'm pretty sure doesn't allow much fusion.
21:36:17 <EvanR> ReinH: if intermediate data (TimeSeries) is being materialized as a big list, then consumed (twice), itll stick around the whole time... thats one issue
21:36:29 <ReinH> The problem isn't laziness. That was a red herring.
21:36:34 <ReinH> The problem is just the garbage you create.
21:36:44 <colonelj> why doesn't it get cleaned up?
21:36:59 <ReinH> It does get cleaned up. When it's no longer needed.
21:37:01 <EvanR> it should be cleaned up if you consume it properly
21:37:15 <EvanR> and dont create it up front
21:37:24 <EvanR> and its not pointing into existing large vectors
21:37:27 <ReinH> Storable vectors are already unboxed. They can't have laziness-based space leaks in their values.
21:37:40 <EvanR> ok good. that still leaves your big list of TimeSeries
21:38:02 <EvanR> and the lists generated inside of covmatrix
21:38:12 <ReinH> The space leak is ByteArray#s
21:38:24 <EvanR> thats probably what is in TimeSeries
21:38:30 <ReinH> That's the storable vectors.
21:38:49 <EvanR> and which of these two words = ARR_WORDS
21:38:57 <ReinH> You just create a ton of storable vectors and results depend on them so they can't be collected until you get a result
21:39:05 <ReinH> ARR_WORDS is ByteArray#
21:39:48 <ReinH> It's an array of words.
21:39:58 <colonelj> bytes aren't words
21:40:06 <ReinH> https://stackoverflow.com/questions/7241470/what-is-arr-words-in-a-ghc-heap-profile
21:40:22 <ReinH> Do you honestly want to argue with me about every damn thing?
21:40:41 <monochrom> Proof by trusting "meaningful" names, no less.
21:40:53 <colonelj> no I'm just saying semantically ARR_WORDS doesn't mean ByteArray to me
21:41:02 <colonelj> there's not much to argue about there anyhow
21:41:16 <EvanR> thats why i asked
21:41:22 <ReinH> That's why I told you what it is.
21:41:41 <colonelj> well great, so it's ByteArrays
21:41:48 <ReinH> It's the vectors.
21:41:57 <colonelj> the storable ones right?
21:42:00 <ReinH> Yes.
21:42:00 <EvanR> i bet they use words instead of individual bytes for memory efficiency
21:42:04 <ReinH> As I keep saying.
21:42:08 <EvanR> and we cant tell
21:42:20 <colonelj> hmatrix library uses storables too
21:42:28 <ReinH> You are creating a ton of storable vector garbage with all your toList and fromList and map
21:42:37 <ReinH> storables are fine
21:42:45 <ReinH> I'm not saying storables are bad.
21:42:54 <ReinH> I'm saying the way you are using them is creating all this garbage
21:42:59 <ReinH> monochrom: have you looked at the code??
21:43:02 <EvanR> we dont have the updated code, but your final calculation is multiplying some matrix by its transpose right
21:43:07 <monochrom> No. Should I?
21:43:09 <ReinH> Sorry, my ? is sticky
21:43:12 <colonelj> well I tried to simplify it and this is as far as I've got
21:43:17 <ReinH> monochrom: actually, probably not.
21:43:22 <colonelj> EvanR: yeah I use mTm for that now
21:43:34 <monochrom> It's OK, my 4 key is anti-sticky too, we all have suboptimal keyboards :)
21:43:55 <colonelj> those vectors I think are 51x3 which isn't all that big
21:44:04 <colonelj> and you get a 3x3 as result
21:44:07 <ReinH> What is TimeSeries?
21:44:17 <monochrom> I just finished a medium-long day of hybridized Haskell and Java programming!
21:44:17 <colonelj> it's just a wrapper for a vector
21:44:30 <colonelj> with some dates included
21:44:42 <EvanR> colonelj: and the input to that operation is a "fromRows <list>" and the list being forced early
21:45:02 <EvanR> causing unnecssary materialization
21:45:11 <monochrom> It is because I gave out a shortest-path (single-source, Dijkstra's) assignment, so I needed to furnish test cases and actually check my solution.
21:45:25 <ReinH> monochrom: It has a list of storable vectors what are zipWith a storable vector map and one of the argument lists is created by toList on another storable vector.
21:45:25 <colonelj> EvanR: I took the deepseqs out
21:45:31 <EvanR> ok good
21:45:34 <colonelj> I can repaste if you want
21:45:51 <monochrom> So I coded up a Haskell solution (cheating, I just call up fgl), and a Java solution too. Also, a Haskell program to generate random test cases.
21:47:10 <EvanR> i am kind of interesting to doing some numeric haskell stuff, and getting it to not use 1G of memory at once, so i am interested to know the full scope of this calculation
21:47:16 <monochrom> That sounds so XYZ problem.
21:47:31 <EvanR> if not, one day i will get into the same situation, and none of what i do will really matter to you
21:47:40 <monochrom> I respect "list of whatever" but it must be used in a streaming fashion only
21:48:25 <colonelj> fromRows takes a list, I can't change that
21:48:28 <monochrom> And of course there is always the angle "you're using a space-wasteful algorithm to begin with".
21:48:48 <EvanR> yeah fromRows will consume a list
21:48:49 <colonelj> fromRows :: Element t => [Vector t] -> Matrix t
21:48:56 <EvanR> row by row, not force it first
21:49:02 <ReinH> monochrom: it contains a Vector.toList of a Storable.zipWith a Storable.toList of a Storable.zipWith.
21:49:17 <monochrom> I know of a space-wasteful algorithm written in SML. The code syntactically looks like what you would write in Haskell.
21:49:20 <EvanR> then youll get a matrix once its done
21:49:51 <monochrom> That code on Haskell would run in O(1) space, and in SML 128MB.
21:50:05 <EvanR> the matrix ought to be idependent, and whatever went into its creation can be collected, assuming its not used somewhere else
21:50:12 <EvanR> we dont have the test framework code, so no way to know
21:50:21 <colonelj> you can see it in the function
21:50:25 <monochrom> (It's n-Queen's problem using forward constraint propagation.)
21:50:46 <monochrom> (using [] to emulate nondeterministic choice)
21:50:46 <ReinH> Yeah, what is fromRows and what is tr?
21:50:48 <EvanR> yeah it uses ultimately m and rets
21:50:56 <colonelj> fromRows :: Element t => [Vector t] -> Matrix t
21:51:01 <colonelj> tr is transpose
21:51:12 <colonelj> hopefully it just switches which is the minor axis
21:51:25 <ReinH> "hopefully"
21:51:28 <EvanR> probably doesnt
21:51:34 <colonelj> why wouldn't it?
21:51:42 <EvanR> for speed
21:51:57 <colonelj> it's O(1) to flip the major/minor orientation
21:52:10 <EvanR> if you make all your matrix loops slower by checking that bit 
21:52:22 <colonelj> you just have different loops
21:52:26 <colonelj> it uses LAPACK internally
21:52:31 <EvanR> oh really
21:53:03 <monochrom> Does LAPACK have O(1) transpose? Seriously? Citation needed.
21:53:17 <ReinH> Wait, your claim is that transpose is O(1)?
21:54:20 <colonelj> it's just changing the interpretation of the same memory
21:54:33 <monochrom> I take it you mean you don't know.
21:55:17 <colonelj> http://www.netlib.org/lapack/lapacke.html#_array_arguments
21:55:59 <monochrom> Does tr actually does just that and nothing more?
21:56:06 <EvanR> for large rectangular matrices, i still think thats not a good way to do it
21:56:32 <EvanR> potentially jumping between pages for each iteration
21:57:01 <monochrom> With large matrices you're sitting between a lot of space and a lot of time.
21:57:02 <colonelj> should only need two pages open at a time to do the matrix mult the long way no?
21:59:26 <EvanR> ime haskell libs dont try tricky optimizations like that, they opt to just copy stuff
21:59:57 <colonelj> so you think the space leak is because of the library?
22:00:23 <EvanR> no
22:00:28 <ReinH> Did anyone say that?
22:01:12 <EvanR> how many covmatrices are you generating and printing out ?
22:01:15 <EvanR> 500 ?
22:01:23 <colonelj> just one
22:01:29 <ReinH> I still think the space leak has something to do with all the zipping and mapping and toListing and fromListing of lists of storable vectors that you do.
22:02:01 <colonelj> I don't do very much of that in returnCovMatrix though :S
22:02:11 <colonelj> there's one VS.toList
22:02:14 <ReinH> What
22:02:16 <EvanR> so you call that once
22:02:45 <colonelj> returnCovMatrix gets called 500 times and I average the results using 'expect' at the bottom there
22:02:58 * EvanR backtracks
22:03:03 <ReinH> zipWith (\(TimeSeries rs _ _) (CCReturn mean) -> VS.map (\(CCReturn r) -> r - mean) rs)
22:03:25 <EvanR> colonelj: now i think that whatever calls returnCovMatrix is holding onto stuff that should be collected during that period
22:03:52 <colonelj> let cov_samps = returnCovMatrix <$> rets_samps <*> m_samps
22:04:14 <EvanR> ... what is the definition of rets_samps, m_samps
22:04:18 <EvanR> wheres the loop
22:04:22 <colonelj> let rets_samps = calcReturns <$> samps
22:04:26 <colonelj> let m_samps = meanReturns <$> rets_samps
22:04:31 <EvanR> whats the definition of samps
22:04:44 <ReinH> How large are these lists?
22:04:52 <colonelj> 500 samples
22:04:55 <ReinH> How large are these vectors and storable vectors?
22:05:21 <colonelj> m_samps is only 3 prices for each sample
22:05:32 <colonelj> rets_samps is 50 returns per sampl
22:05:43 <EvanR> if <$> is vector fmap, you could combine these if its not doing so automatically
22:06:10 <EvanR> im still not clear how the loop and expect work
22:06:20 <ReinH> How did you determine that returnCovMatrix is the source of the space leak?
22:06:27 <EvanR> and im thinking if you could paste the code, explaining it line by line wont be faithful
22:06:34 <EvanR> couldnt
22:07:22 <colonelj> http://lpaste.net/8183399083981930496
22:07:31 <ReinH> The munging between vectors and lists is probably preventing anything from fusing. I wouldn't be surprised if there was some combinatorial explosion of vector creation going on somewhere. Indeed, there pretty much as to be.
22:07:49 <EvanR> is that inside a main ?
22:07:58 <EvanR> compiled with -O2 and executed?
22:08:19 <colonelj> that's inside main
22:08:37 <EvanR> and then it ends?
22:08:45 <colonelj> ya
22:08:59 <EvanR> does it begin, main = do ?
22:09:08 <colonelj> ofc
22:09:14 <EvanR> just wondering why you omitted it
22:09:15 <colonelj> actually this is inside main2
22:09:55 <colonelj> since I had to make the rest of main polymorphic in the time period
22:11:24 <EvanR> returnCovMatrix <$> rets_samps <*> m_samps
22:11:55 <ReinH> Is that applicative instance a cartesian product by chance?
22:11:58 <EvanR> how... does this work when returnCovMatrix takes a list and a vector
22:12:07 <EvanR> ah
22:13:04 <monochrom> @type (\a b c -> a <$> b <*> c)
22:13:05 <lambdabot> Applicative f => (a1 -> a -> b) -> f a1 -> f a -> f b
22:13:07 <colonelj> cartesian product... that wouldn't be good
22:13:42 <ReinH> I don't know what applicative that is since I don't know the types involved
22:13:48 <EvanR> im not sure what the intention of <$> <*> is there
22:13:57 <EvanR> a ziplist, a product...
22:14:08 <monochrom> I'm more bold and cynical. I'm sure the intention is cargo culting.
22:14:31 <colonelj> I did a newtype deriving from a V.Vector
22:14:37 <monochrom> Does the program even output a correct answer?
22:14:38 <colonelj> so it's probably whatever V.Vector's applicative instance is
22:14:45 <colonelj> monochrom: that's a good question
22:14:49 <ReinH> What.
22:14:56 <monochrom> hahaha I win
22:14:58 <EvanR> what is the type ?
22:15:14 <ReinH> The program doesn't... even... work?
22:15:18 <EvanR> true, i guess this is not grossly premature optimization :)
22:15:21 <EvanR> now*
22:15:35 <monochrom> Well, we haven't proved that yet. I have only casted doubt.
22:15:42 <ReinH> Remember: If it doesn't have to work, it can meet any other criteria.
22:15:58 <EvanR> if it doesnt work, at least we can make it more memory efficient
22:16:04 <EvanR> delete most of the lines
22:16:06 <ReinH> Sure, just never run it.
22:16:17 <ReinH> Then it is optimally memory efficient.
22:17:24 <colonelj> so what does the applicative instance for data.vector do?
22:17:28 <EvanR> yeah i dont want to pull any more teeth
22:17:38 <ReinH> Wow.
22:17:47 <monochrom> I don't know. Does lambdabot have vector? We can try here.
22:18:05 <ReinH> it's cartesian product.
22:18:09 <EvanR> o_O
22:18:10 <ReinH> It's derived from its concatMap monad instance.
22:18:23 <EvanR> good to know
22:18:39 <ReinH> Here I am telling you that you're creating a bunch of garbage, probably by combinatorial explosion of creating vectors
22:18:43 <monochrom> To be sure, natural wise choice.
22:19:00 <ReinH> And now you're telling me that you used a cartesian product of vectors and you didn't even know what it did?
22:19:25 <EvanR> didnt know *that* it did
22:19:29 <ReinH> This is not a space leak.
22:19:43 <ReinH> It is using the space you told it to use.
22:20:08 <EvanR> posting the code would have revealed this days ago im sure
22:20:10 <monochrom> I've been saying that all my life. (Technically, only since I learned Haskell.)
22:20:18 <EvanR> what have you got to lose but days
22:20:21 <ReinH> If you want it to stop using so much memory, tell it to do something else.
22:20:32 <ReinH> Preferably something that you actually understand.
22:20:33 <colonelj> yeah I think I just want a zipWith
22:20:49 <colonelj> but I don't think there's any typeclass for that?
22:20:59 <EvanR> they both need to be lists or vectors
22:21:07 <EvanR> of the same length
22:21:16 <monochrom> Why do you need a type class? Just call zipWith.
22:21:17 <EvanR> not one list and one vector
22:21:37 <EvanR> lists fuse, vectors fuse
22:21:43 <EvanR> lists and vectors dont fuse
22:22:01 <monochrom> Oh one of them is a list and the other is a vector? How did that happen?
22:22:14 <EvanR> returnCovMatrix arg1 is a list, arg2 is a vector
22:22:24 <monochrom> More XY problems from the past and more new XY problems for the future I guess.
22:22:25 <ReinH> monochrom: It happened by liberally sprinkling toList and fromList around as needed
22:22:31 <EvanR> how the <$> <*> worked im still kind of unsure
22:22:51 <ReinH> We can't debug your program if you don't even know how it works.
22:22:59 <EvanR> i can debug it with code
22:23:15 <ReinH> Well, I probably could too, but I don't suppose they want to see my rate sheet.
22:23:20 <monochrom> Right, so the result is probably Vector (Vector X) or Vector [X] or something.
22:23:38 <ReinH> monochrom: it starts out with [Vector X]
22:23:43 <ReinH> And then things get weird.
22:23:52 <colonelj> rets_samps and m_samps are both Samples
22:23:59 <colonelj> which are made up of V.Vector
22:24:00 <ReinH> Well, actually there are both storable and regular vectors
22:24:03 <colonelj> so they're both V.Vector
22:24:06 <colonelj> what's the problem?
22:24:15 <ReinH> so maybe it's [V (SV X)] or something.
22:24:29 <EvanR> i have no idea
22:24:34 <colonelj> these are vectors of vectors, and vectors of lists
22:24:37 <ReinH> What's the problem? Well, the fundamental problem is that you have no idea what you are doing.
22:24:48 <EvanR> ah
22:24:56 <colonelj> yes I do, I just used the cartesian product applicative by accident
22:24:58 <EvanR> liftA2 over a "samples" 
22:25:02 <ReinH> 'by accident'
22:25:04 <ReinH> Ok.
22:25:10 <EvanR> one is a samples of lists of timeseries, one is a samples of vectors
22:25:22 <colonelj> yuss
22:25:24 <EvanR> and you combine them using cartesian product
22:25:31 <ReinH> You managed to contradict yourself in a single sentence though, so that was cool.
22:25:58 <EvanR> so it takes 40 seconds to do 500 * 500 matrix calculations
22:26:03 <ReinH> Well, this has been fun.
22:26:08 <monochrom> I contradicted myself in front of the great Sir Tony Hoare. I think mine was a greater achievement.
22:26:36 <colonelj> did he point it out to you?
22:27:16 <monochrom> He was guest to our CS department. We were in a meeting up around a table, and the usual "introduce yourself" you can imagine.
22:27:39 <monochrom> I was kind of the meeting organizer so I said "I introduce those who don't introduce themselves".
22:27:47 <EvanR> lol
22:28:03 <ReinH> I am also a member of the set that contains all sets except itself, since you asked.
22:28:04 <monochrom> probably s/the/a/ because I organized one aspect but some profs organized some other aspects.
22:28:29 <EvanR> those who don't introduced aselves?
22:28:40 <colonelj> amselves
22:28:50 <EvanR> ok
22:29:26 <kadoban> monochrom: Nice
22:29:50 <ReinH> Technically, it would have only replaced the first instance of "the" since it was not s/re/g
22:30:07 <EvanR> where was the other one
22:30:19 <ReinH> The one he intended to replace.
22:30:25 <EvanR> oh, why was i only looking inside quotes
22:30:35 <EvanR> thats the opposite effect of quotes
22:30:38 <ReinH> But you can surmise that it was before the one in question ;)
22:30:39 <colonelj> made the same mistake lol
22:31:26 <ReinH> monochrom: Congratulations, you are technically correct.
22:31:39 <ReinH> Which, as everyone knows, is the best kind of correct.
22:31:40 <halogenandtoast> Doing my monthly check for companies in Tokyo, anyone doing Haskell in Tokyo with open positions?
22:31:47 <EvanR> is there a way to pack Integer into a matrix
22:32:34 <EvanR> sanely
22:33:19 <colonelj> I think I'm going to write a ZipList form of Applicative (Samples a)
22:33:37 <EvanR> just write a zipWith function for that type
22:34:16 <colonelj> nah I'll do it the hard way
22:34:19 <colonelj> zipWith is ugly
22:34:40 <EvanR> it already exists even zipWith :: (a -> b -> c) -> Vector a -> Vector b -> Vector c
22:34:55 <monochrom> Too much typeclassing and newtyping may disable optimizations.
22:35:31 <monochrom> It is always fun to scaremonger those who performancemonger.
22:35:59 <EvanR> what is even the point of the Samples newtype
22:36:01 <colonelj> EvanR: how do I use it with my newtype?
22:36:15 <colonelj> it's to carry semantic information in the types
22:36:34 <EvanR> like, with phantom parameters?
22:36:48 <colonelj> yeah except I don't have one in this case... so you raise a good point
22:37:24 <colonelj> I originally wrote this in my dependently typed language and I had a dependent length attached to it
22:37:35 <EvanR> zipWith f (Samples xs) (Samples ys) = Samples (zipWith f xs ys)
22:37:46 <EvanR> homomorphic
22:38:17 <EvanR> you have a dependently typed language?
22:38:32 <colonelj> yeah it's called starpial
22:38:42 <colonelj> still in design phase though
22:39:05 <colonelj> I might write a parser soon
22:44:50 <Axman6> halogenandtoast: curious who's on your list. I did an internship at Tsuru, can't remember who else was around back then
22:45:45 <johnw> how did you write something in a dependently-typed language you don't have a parser for?  Did you thought compile it? :)
22:46:10 <colonelj> yeah that's what I do
22:46:22 <c_wraith> johnw: that's the best compiler.  It never complains about trivial errors.
22:46:38 <colonelj> if I find errors I instantly fix the code
22:46:46 <colonelj> bet you wish your compiler did that!
22:47:19 <c_wraith> ghc used to delete the files if you had a type error, thus fixing it.
22:47:42 <colonelj> "this is a load of garbage" -- DELETE
22:48:08 <EvanR> they need to bring that feature back
22:48:11 <colonelj> I should maybe consider doing that with some of my older code which no longer compiles
22:48:19 <EvanR> haskell hardcore mode
22:48:27 <colonelj> haha yeah it would enforce proper version control usage
22:48:47 <c_wraith> using version control to restore deleted code is basically save-scumming.
22:48:50 <c_wraith> don't do that.
22:51:16 <colonelj> damn Data.Vector doesn't have a repeat :(
22:52:39 <ReinH> c_wraith: here is the javascript version https://github.com/mattdiamond/fuckitjs
22:52:49 <MarcelineVQ> colonelj: repeat?
22:52:59 <EvanR> repeat produces an infinite list
22:53:24 <ReinH> johnw: With an embedded DSL, with bonus points for languages like Idris that let you define your own syntax!
22:53:25 <EvanR> if you had an infinite Vector the length function wouldnt be well typed
22:53:36 <ReinH> I think there's some confusion here about what a Vector is?
22:53:45 <EvanR> i hope so!
22:54:05 <colonelj> but I want a fricking ZipList applicative for vector
22:54:09 <wwizzy> is it possible to bring rust-style borrowing/ownership/lack of GC to haskell?
22:54:11 <ReinH> The length function would be as well typed as it is for lists.
22:54:28 <ReinH> colonelj: unfortunately, you cannot have one.
22:54:43 <EvanR> good point, length is broken as it is
22:54:52 <ReinH> You should just use zipWith, like we repeatedly suggested
22:54:58 <EvanR> by the power of falso anything is true
22:55:16 <colonelj> ReinH: I'll have to concede on that one then
22:55:20 <c_wraith> wwizzy: you basically have to give up laziness, which seems like far too great a cost.
22:55:23 <colonelj> that really sucks though lol
22:55:40 <EvanR> not really
22:55:52 <ReinH> It's a limitation of Vector, but not an unexpected one.
22:55:57 <wwizzy> c_wraith: didn't simon peyton jones say laziness as a default was a bad idea?
22:56:18 <colonelj> he was probably joking if/when he said that
22:56:41 <c_wraith> wwizzy: he said he didn't know if they'd do it again.  That's hardly the same thing.
22:56:47 <ReinH> Borrowing and lack of GC are not the same thing.
22:57:03 <c_wraith> wwizzy: anyway, laziness is *really* important for code reuse.
22:57:16 <wwizzy> i see
22:57:29 <ReinH> There's a proposal to add linear types to GHC
22:57:37 <Axman6> yeah, I feel laziness by default is the right default, it's often easy to figure out when you need strictness
22:57:42 <halogenandtoast> Axman6: I only have 2 on my list Tsuru and Arow
22:57:44 <ReinH> There are also ways of managing resource lifecycle in user-space, like Oleg's monadic regions.
22:57:49 <ReinH> And various fancy indexing schemes.
22:58:16 <wwizzy> can haskell "propagate" strictness?
22:58:18 <halogenandtoast> Axman6: How as Tsuru, I've been eyeballing them.
22:58:24 <halogenandtoast> s/as/was/
22:58:25 <ReinH> Even if lazy-by-default isn't the best choice, there are already plenty of languages that are not lazy-by-defaut.
22:59:21 <Axman6> I really enjoyed it, great people, but I'm not sure who's still there these days, I know several of the people I worked with moved onto other things
22:59:26 <EvanR> i want to see compact regions used in a game
23:00:02 <Axman6> yeah compact regions plus more deterministic resource usage (ie, the regions stuff from above) could be really interesting
23:00:35 <EvanR> (and have the performance benchmarked)
23:00:35 <c_wraith> compact regions have value, but it's...  limited.  They don't help with state churn.  They really help for big graphs that don't change very often, though.
23:00:53 <EvanR> yes i keep imagining using it for "2fort" :)
23:01:06 <ReinH> compact regions are cool, but not what I was talking about.
23:01:10 <Axman6> c_wraith: well, sort of, you can add to a Compact
23:01:13 <pacak> Lazy by default made it so that you'll have to deal with side effects in some intelligent way - otherwise you have no ideas what stuff is going to execute. That resulted in early versions of haskell having main :: String -> String and later - monads and other fancy burritos in a type system.
23:01:32 <c_wraith> Axman6: if you don't mind things never getting freed...  :)
23:01:35 <Axman6> so, you can do functional updates and know any shared values will also be in the same Compact
23:02:02 <ReinH> String -> String?
23:02:19 <c_wraith> I think that was the type of main in super-early haskell.  pre-1.0
23:02:26 <EvanR> main :: [ICommand] -> [OCommand]
23:02:30 <Axman6> c_wraith: well, that's something I think many apps can deal with happily - memory is cheaper than GC's of large rarely chaged structures in many places
23:02:33 <c_wraith> It was just a stream processsor
23:02:41 <pacak> Or something along those lines. It was taking a string and producing a string.
23:02:41 <ReinH> Don't you mean [Response] -> [Request]?
23:03:01 <c_wraith> that came later
23:03:03 <EvanR> backwards?
23:03:08 <c_wraith> no, that's correct.
23:03:12 <EvanR> wow
23:03:16 <pacak> Yea, I'm talking about super early version.
23:03:17 <c_wraith> The program produces requests, and gets reponses
23:03:19 <ReinH> Ah, 1.2 http://haskell.cs.yale.edu/wp-content/uploads/2011/01/haskell-report-1.2.pdf
23:03:28 <EvanR> and the responses had IDs so you could match them up?
23:03:29 <EvanR> crazy
23:03:44 <c_wraith> EvanR: also easy to deadlock if you didn't use laziness perfectly. :)
23:04:05 <c_wraith> don't ever wait for a response to a request you haven't issued yet!
23:04:18 <Axman6> wwizzy: what do you mean by "propogate stictness"?
23:04:24 <EvanR> you might not get a response anyway!
23:04:32 <ReinH> There's this small matter that your programs must be meticulously written to respect the directionality of the arrow of time.
23:05:37 <wwizzy> Axman6: so if i define fn1 fn2 fn3 as functions which execute lazily
23:05:57 <monochrom> Yes, it was main :: [ICommand] -> [OCommand], moduling naming.
23:05:57 <wwizzy> and then i define fn4 = fn1 fn2 fn3, can i annotate fn4 as strict
23:06:18 <Axman6> what does it mean to be strict in this case? fn4 doesn't take any arguments
23:06:20 <wwizzy> and then have calls to fn1 fn2 fn3 be executed in a strict manner
23:06:21 <monochrom> I also seem to recall that it was in 1.0-1.2 approximately.
23:06:35 <wwizzy> don't take what i'm writing too literally
23:06:47 <Axman6> wwizzy: I feel you may not have a good grasp on what it means for somthing to be strict btw. 
23:07:10 <monochrom> Also, [OCommand] -> [ICommand], if you think carefully.
23:07:23 <wwizzy> wwizzy: ok, that's totally possible,... my perception was that haskell stores pending computation as "thunks" and
23:07:28 <wwizzy> whoops
23:07:42 <monochrom> There are CPS wrappers over [OCommand] -> [ICommand], so if you go the CPS way, you actually don't run into deadlocking.
23:07:47 <wwizzy> Axman6: my understanding is that haskell stores pending computations as "thunks" and then 
23:08:19 <wwizzy> Axman6: at some point a function call will cause some or all of the thunks to be evaluated
23:08:47 <EvanR> thats not what causes it
23:08:53 <ReinH> wwizzy: if it doesn't take any arguments then it is not a function.
23:08:55 <monochrom> No, a pattern matching causes it.
23:09:06 <wwizzy> ok
23:09:10 <ReinH> All functions in Haskell are of type a -> b for some a and b.
23:09:22 <wwizzy> but something has to initiate the pattern matching
23:09:29 <EvanR> that something is the OS
23:09:30 <monochrom> There are other causes but focus on pattern matching first.
23:09:36 <colonelj> EvanR: this is what the heap profile looks like now if you're interested https://i.imgur.com/U4i2ZA0.png
23:09:38 <EvanR> it wants to know what letter to show on the terminal
23:09:51 <ReinH> Everything interesting in Haskell desugars to case
23:10:12 <monochrom> At the whole-program level, an output command kickstarts the rest.
23:10:31 <EvanR> you could make a metal machine that fundamentally demands results with a top level case analysis
23:10:42 <monochrom> Because the output command either causes pattern matching (of a list, say) or needs to print an Int.
23:11:09 <monochrom> Oh actually at the abstract level "print an Int" goes through one pattern matching first so there.
23:11:19 <wwizzy> ok
23:11:39 <wwizzy> but at some point something says giveMeNextCharacter
23:11:42 <EvanR> whatever isnt needed to get the constructor for the pattern match, isnt ever evaluated
23:11:46 <EvanR> hopefully isnt thunked either
23:12:07 <EvanR> wwizzy: perhaps a monkey turning the computers crank?
23:12:20 <EvanR> or hitting enter
23:12:23 <wwizzy> haha
23:12:32 <ReinH> monochrom: is it time for @where lazy yet?
23:12:34 <EvanR> or have a drinking bird do it
23:12:39 <EvanR> however
23:12:45 <EvanR> you probably want events to drive stuff instead
23:12:49 <EvanR> interrupts
23:12:50 <monochrom> Yes.
23:13:01 <ReinH> @where lazy
23:13:01 <wwizzy> okay you are probably correct that i don't quite know enough to state my question accurately
23:13:02 <lambdabot> http://www.vex.net/~trebla/haskell/lazy.xhtml
23:13:06 <monochrom> I'm reluctant because I want to improve and finish it.
23:13:09 <ReinH> You should read that.
23:14:58 <ReinH> wwizzy: If you're interested in how thunks work, I also recommend ezyang's http://blog.ezyang.com/2011/04/the-haskell-heap/
23:15:48 <EvanR> i cant help to wonder how explicitly managed memory competes with the performance of gc? :)
23:16:02 <EvanR> you spend all kinds of time doing memory management code
23:16:10 <monochrom> Competes favourably because no one dares to free(), ever.
23:16:22 <EvanR> oh really?
23:16:30 <monochrom> I'm exaggerating.
23:16:43 <EvanR> in C, i try not to malloc, thats true
23:16:49 <arahael> Well...
23:16:54 <arahael> free() has a cost.
23:17:03 <monochrom> But supposedly reference counting is faster than all our elaborately precise GC algorithms.
23:17:10 <EvanR> i dont believe that
23:17:14 <ReinH> Similarly, it's not the fall that kills you.
23:17:28 <arahael> reference counting is *maybe* faster if you are single threaded, and don't do much reference passing.
23:17:44 <EvanR> ah C++ like ref counting
23:17:47 <EvanR> not python style
23:18:05 <arahael> EvanR: What do you mean, c++ like ref counting? You either have it, or you don't.
23:18:22 <arahael> C++ does have references, though, but it doesn't use ref counts for htose (unless you use the ref counting smart pointers)
23:18:23 <EvanR> you either do it seldomly, intentionally in specific places, and have no loops
23:18:28 <arahael> Anyway, they all have a cost.
23:18:38 <EvanR> or you do it literally everywhere and have a backup cycle collector
23:18:58 <arahael> The advantage of GC is that, essentially, the free() is done as a neat side effect of essentially failing to observe that the memory is being used.
23:19:26 <monochrom> It is subtle. Combination of fast reference counting and only doing things favourable to reference counting and trying to use more local vars less heap altogether.
23:19:49 <monochrom> It translates to more human work and more errors.
23:19:57 <monochrom> But oh boy is it faster.
23:20:26 <monochrom> At least none of those copying-collector and double-buffering business.
23:20:37 <arahael> monochrom: Right - faster because they've effectively been able to optimise some of the ref counts out.
23:20:59 <EvanR> its faster even in the light of "64G ram should be enough for anyone" ?
23:21:09 <wwizzy> i would have thought that all memory-related programming language problems would have been solved in the 1980s or somesuch,... maybe even some kind of special purpose ASIC on ram modules for handling this stuff
23:21:22 <arahael> EvanR: It does play a bit better with COW memory, compared with a naive mark and sweep GC.
23:21:32 <arahael> EvanR: (Well, ok - much better - in that particular case)
23:21:33 <EvanR> you do have fancy virtual memory now that we didnt have in 1980s
23:21:52 <arahael> EvanR: You still had LISP in the 1980's.
23:22:03 <wwizzy> yeah but GC wasn't "solved"
23:22:11 <arahael> No, not as such.
23:22:12 <EvanR> GC was invented!
23:22:21 <wwizzy> indeed
23:22:31 <arahael> Introducing C++ to this conversation makes it really difficult though.
23:22:37 <EvanR> and now people are trying to uninvent it :)
23:22:55 <arahael> Because C++ has RAII, which, those of us who like the language really like.
23:23:16 <arahael> Using RAII, you consider memory to be meh...  Just another resource, and the language quite elegantly deals with it.
23:23:45 <arahael> A GC, by contrast, deals *only* with memory (or, via finalizers - other resources - very badly)
23:25:49 <EvanR> i have this picture of people with 64G of ram writing programs that take 9k of ram to run
23:26:05 <arahael> EvanR: People actually sometimes do that, deliberately.
23:26:13 <MarcelineVQ> good
23:26:22 <EvanR> and then i see my haskell program take 50k :)
23:26:23 <arahael> EvanR: Because they try to get the critical portion to run in the CPU cache, and not hit the slow system memory.
23:26:27 <MarcelineVQ> people that make web-browsers should aim for 9k
23:27:07 <EvanR> there will always be some very expense very limited very fast memory
23:27:28 <EvanR> when we have 9k of registers, programming will regress back to that ? after tech singularity :)
23:27:48 <EvanR> we use RAII
23:28:00 <arahael> The current game changer, iirc, is massive concurrency.
23:28:04 <monochrom> 9k of registers exceeds 4k TV already.
23:28:49 <wwizzy> EvanR: software these days is bloatware
23:29:51 <pacak> wwizzy: It's a tradeoff between resources needed to develop it vs resources needed to run it.
23:30:15 <EvanR> how browsers got this way by being easy to develop....
23:30:32 <monochrom> Oh God, gift boxes and gift cards.
23:30:37 <wwizzy> "browsers" could more closely resemble lynx
23:30:56 <wwizzy> and if i want to see a video or image or something, i'd press a button
23:31:03 <pacak> EvanR: I don't think anybody _fully_ understands how any major browser works
23:31:08 <EvanR> but how would ads work
23:31:30 <arahael> I'd be happy when Flash is gone. :(
23:31:42 <arahael> Flash just became more subtle, and more hidden.
23:31:53 <pacak> But hey, you can take a browser, slap in some javascript crap on top - a new chat client is born. And people are willing to pay for this crap.
23:32:05 <EvanR> how would my friends company install spyware on your computer and sell time on it on a legal market
23:32:14 <wwizzy> haha
23:36:35 <arahael> The sad thing, is that links is also tight, and includes javascript
23:49:48 <EvanR> ah yeah SPJ said maybe lazy by default wasnt the best. also he said haskell is useless!
23:49:57 <EvanR> who is this guy
23:50:36 <Axman6> speaking of registers... anyone following along with the development of the Mill CPU? so cool
23:51:21 <Axman6> that SPJ guy is a sleeper agent for the javascript cabal. he let slip once he wants Haskell to avoid success at all costs!
23:52:12 <EvanR> heard of it
23:52:21 <Axman6> we've let him get in too deep imo, he's right at the centre of everything these days!
23:52:36 <Axman6> somehow, he managed to be there at the very beginning!
23:52:58 <wwizzy> ok so im not wrong :P
23:53:06 <EvanR> queue the spooky haskell committee photo with someone who looks just like him
23:53:22 <MarcelineVQ> time travel is insidious
23:53:46 <zomg> > that SPJ guy is a sleeper agent for the javascript cabal.
23:53:48 <lambdabot>  <hint>:1:58: error:
23:53:49 <lambdabot>      parse error (possibly incorrect indentation or mismatched brackets)
23:53:56 <zomg> Sounds plausible, if you reverse his initials they clearly stand for Javascript Pro Simon
23:54:04 <Axman6> see, lambdabot knows what's up!
23:54:15 <wwizzy> https://vimeo.com/216330850
23:54:17 <Axman6> oh my god, it's all so obvious
23:54:38 * Axman6 double wraps his tin foil hat
23:54:47 <wwizzy> you guys should fund tyrone to say why haskell is better than scala
23:55:04 <cuddly[m]> ^
23:55:34 <MarcelineVQ> ha ha ha ha
23:55:58 <Axman6> What a ridiculous idea, no one would actually do that
