00:01:22 <kuribas> Don't haskell programmers care about performance?
00:03:12 <Lokathor> eh
00:03:24 <Lokathor> you'd be surprised how much they assume that GHC will handle it
00:03:39 <cocreature> well we did have the Haskell “quicksort” on the main webpage until not so long ago iirc
00:04:00 <Lokathor> https://www.dropbox.com/s/qff45n1hxoazvid/Screenshot%202017-07-22%2001.00.57.png?dl=0 look, creatures!
00:04:15 <cocreature> Lokathor: but are there also cocreatures?
00:04:26 <Lokathor> enemies are: globals, rustacians, and undefineds
00:04:35 <kuribas> Lokathor: yay, ghc can turn O(n^2) into O(n log n)!
00:04:51 <Lokathor> globals can see super far, rustacians are so fast they can attack twice sometimes, and undefineds explode if you touch them
00:05:37 <cocreature> kuribas: it can turn it into O(1) if you never evaluate it!
00:06:27 <kuribas> cocreature: so can any language...
00:06:41 <Lokathor> kuribas, not so!
00:07:22 <cocreature> lazyness allows you to get away with it a bit more often :)
00:08:09 <EvanR> it also turns O(1) into O(log n)
00:08:16 <EvanR> (array -> map)
00:08:21 <EvanR> the great equalizer
00:08:29 <kuribas> or hashmap -> map
00:09:26 <ongy> and I'd say that answer is the prettiest and can be understand at one glance. It always depends on what you want to do. For an interview (which is the hook of that question) I'd probably go with something similar unless explicitly asked to think about performance
00:10:26 * hackagebot x509 1.7.1 – X509 reader and writer – https://hackage.haskell.org/package/x509
00:10:42 <cocreature> kuribas: I don’t think foldl' is sufficiently strict in your solution. it will only evaluate the tuple constructor not the arguments inside the tuple
00:11:54 <Lokathor> deepseql
00:12:16 <kuribas> ongy: I am pretty sure performence in such questions would give extra points.
00:12:38 <kuribas> ongy: unless the interviewer is stupid and doesn't understand the better solution.
00:12:46 <Lokathor> whop
00:12:51 <ongy> not sure. hanging on performance could also be considered premature optimizing and unreadable
00:12:57 <Lokathor> "unless the interviewer is stupid" is a bad path to go down
00:13:28 <kuribas> ongy: using O(n) instead of O(n^2) is not premature optimization
00:14:00 <kuribas> cocreature: perhaps, I didn't really do any optimizations on my code.
00:15:47 <EvanR> i recall these questions being (implicitly) a combination of "fastest possible algorithm" and "whatever interviewer looked up prior to the interview"
00:17:22 <EvanR> dont use deepseq in a foldl' tuple, use bang patterns
00:18:05 <EvanR> in general using deepseq that does anything means you failed to use bang patterns at some point
00:18:09 <kuribas> cocreature: even so, my solution is much faster than the other ones.
00:18:52 <kuribas> If I wanted the fastest performance I'd use a vector or mutable hashmap in the ST monad.
00:19:17 <cocreature> kuribas: oh don’t get me wrong, I was not trying to say your solution is worse than the others and in fact I prefer it (although I haven’t taken too long to look at them). I just get really annoyed when I see potential spaceleaks in programs :)
00:19:23 <kuribas> I try to avoid quadratic code anywhere, even if it's pretty...
00:19:36 <Lokathor> oh boy i tried a mutable hash map in ST over a plain Set in a STRef the other day
00:19:38 <Lokathor> did not go well
00:19:43 <Lokathor> like, 4x as slow
00:19:48 <kuribas> cocreature: oh right
00:20:48 * hackagebot naqsha 0.2.0.0, x509-util 1.6.3, x509-validation 1.6.8
00:20:48 <EvanR> theres a mutable hashmap ?
00:20:48 * hackagebot  → https://hackage.haskell.org/packages/recent
00:21:18 <kuribas> Lokathor: yes, performance can be unintuitive
00:21:47 <cocreature> that reminds me that I still wanted to see if I could hack unboxed hashtables in the hashtables package
00:22:17 <Lokathor> EvanR, hashtables package
00:23:21 <kuribas> https://hackage.haskell.org/package/hashtables
00:24:11 <cocreature> development of that package sadly seemed to have slowed when I last looked at it
00:24:31 <EvanR> Lokathor: ah not a hashmap then
00:24:45 <EvanR> hashtables specifically is notorious 
00:25:05 <Lokathor> oh nooooo
00:25:05 <EvanR> not sure whats wrong with it
00:25:06 <Lokathor> ah well
00:25:47 <cocreature> EvanR: other languages tend to call hashtables hashmaps so there is not really a clear distinction here
00:26:10 <cocreature> I think Java’s HashMap is a hashtable with expected O(1) access iirc
00:26:16 <EvanR> i guess we dont have a package called hashmap, Data.HashMap is in unordered-containers
00:26:27 <EvanR> and not a hash table
00:27:45 <cocreature> the imperative languages just use hashtables for everything anyway so there is not much need for a hashmap :)
00:28:08 <EvanR> or any other data structure what so ever, is my experience
00:28:39 <EvanR> similar to the usual feature of "one true number type"
00:28:52 <cocreature> they still use arrays sometimes
00:29:24 <EvanR> perhaps only through a magic poorly understood alternative backend of the hashtable
00:29:37 <EvanR> lua, js, _
00:30:12 <kuribas> But log(n) isn't much worse than O(1) mostly
00:30:30 <EvanR> heh... famous last words
00:30:57 <EvanR> or is it the constant factors
00:31:04 <cocreature> kuribas: that’s true from an asympotic point of view but hashtables can sometimes be significantly better due to cache locality
00:31:14 <Lokathor> famous last constant factors
00:31:28 <EvanR> so why did haskells hashtables package flop?
00:31:42 <kuribas> log(numbers of atoms in the universe) is only 260
00:31:43 <cocreature> EvanR: it flopped?
00:32:09 <EvanR> it had poor performance against other containers at the time
00:32:25 <Lokathor> EvanR, python uses both dict and list
00:32:43 <kuribas> maybe something could be build using this?  https://hackage.haskell.org/package/compact-mutable
00:32:45 <EvanR> python has these two things, but no one knows what they are really implemented as
00:32:47 <cocreature> huh I thought that was some predecessor package to hashtables
00:32:51 <EvanR> i suspect both are hashtables
00:32:54 <EvanR> or arrays
00:33:50 <Lokathor> EvanR, their list is an arraylist, and their dict is probably a hashtable
00:33:59 <EvanR> what is an array list ?
00:33:59 <Lokathor> what's the diff between a hashmap and a hashtable?
00:34:15 <cocreature> java’s arraylist is c++’s vector
00:34:22 <EvanR> youd think someone would have come up with consistent terminology by now :)
00:34:32 <EvanR> and C++ vector is ?
00:34:54 <EvanR> an array ? :)
00:34:58 <cocreature> EvanR: a wrapper around an array with ammortized O(1) append
00:34:58 <Lokathor> yes but
00:35:02 <Lokathor> yeah
00:35:21 <kuribas> Lokathor: in haskell hashmap is an immutable container.  In imperative languages it's the same as hashtable I guess.
00:36:06 <cocreature> the Haskell HashMap is still some kind of tree structure which uses hashes of the keys
00:36:45 <EvanR> hashmap is "Hash Array Mapped Trie (HAMT)" https://github.com/tibbe/unordered-containers/blob/master/docs/developer-guide.md
00:37:04 <EvanR> its a funny tree that doesnt get very deep
00:37:10 <EvanR> based on hashing
00:37:24 <cocreature> the developer guide that johan added recently is a pretty good read
00:38:25 <EvanR> is that what i linked, seems consistent
00:38:46 <cocreature> yep
00:39:28 <EvanR> "This package must be faster than ordered-containers, or it wouldnt exist" QED
00:39:45 <EvanR> its optimized even in its marketing!
00:39:59 <dysfun> dear god can you lot stop saying 'dysfunctional' while i'm away? it highlights me
00:41:18 <kuribas> EvanR: I suppose it's only faster for variable length things, like strings.
00:42:34 <EvanR> from what ive seen IntMap and HashMap Int are kind of in a speedracer back and forth
00:43:10 <EvanR> but IntMap has more functionality
00:44:10 <kuribas> Does a HashMap not need rotation for balance?
00:46:26 <EvanR> the guide i linked sort of goes into how it works
00:46:28 <kuribas> dysfun: set your client to match whole words only?
00:51:29 <kuribas> How can a hashtable be O(1)?  Does it resize when the bins are too full, like vector does?
00:53:38 <EvanR> it doesnt seem to do any rotation
00:54:48 <kuribas> yeah
00:55:06 <EvanR> if the hashtable was using int keys, and the hash function is identity, then you dont get collisions at all :)
00:55:45 <EvanR> but you need to resize and hope no one uses maxBound - 9 for instance
00:56:54 <EvanR> i always had the feeling hash tables with O(1) lookup was some bald face lie
00:57:58 <EvanR> where as log n for Data.HashMap lookup is a technical truth
00:58:16 <kuribas> It could be ammortized O(1), like vector append
00:58:34 <kuribas> oh right, lookup doesn't need resizing
00:59:34 <dysfun> kuribas: i'm on irssi, how do i do that?
00:59:37 <Lokathor> shame that haskell doesn't allow whitespace based import lists
00:59:49 <Lokathor> or record declarations / list literals
00:59:53 <kuribas> dysfun: I have no idea, sorry...
01:03:50 <Athas> ezyang: is there a writeup of how the current state of Backpack differs from the POPL paper?
01:08:52 <kuribas> Couldn't an mutable hashtable be simply (Data.Vector.Mutable.Vector [a])?  Or would that be inefficient?
01:09:21 * EvanR checks to see if that is literally what it is in hashtables
01:11:23 <kuribas> Well Data.Vector.Mutable.Vector [(k, v)]
01:12:22 <EvanR> it is not that simple
01:14:14 <EvanR> instead of a list of kv pairs, its two mutable arrays, one of keys one of values, in a given bucket
01:15:24 <EvanR> and i suspect all 3 hashtables in here are more complex than a classic hashtable
01:15:46 <kuribas> so MV.Vector (MV.Vector (k, v))?
01:16:03 <EvanR> its using Data.Primitive.Array
01:16:08 <kuribas> right
01:16:26 <EvanR> marray#
01:17:07 <EvanR> er MutableArray#
01:17:13 <Athas> m'array
01:18:18 <EvanR> kuribas: so MA (MA k, MA v)
01:18:46 <EvanR> with some other stuff, counters
01:23:19 <EvanR> ah the basic one is (MA k, MA v) with some counters to know when to resize, which rehashes everything
01:37:45 * hackagebot slug 0.1.7 – Type-safe slugs for Yesod ecosystem – https://hackage.haskell.org/package/slug
01:37:45 * hackagebot relational-query 0.8.6.0 – Typeful, Modular, Relational, algebraic query engine – https://hackage.haskell.org/package/relational-query
01:48:01 <trigone> Regarding terminology, is it appropriate to say that a functor/monad is (in haskell) a type constructor (with special properties)? If so, what would be an agnostic definition of a type constructor?
01:48:49 <trigone> I meant, an agnostic term for a type constructor, especially in the world of Math
01:50:04 <mrkgnao> a "function at the type level" that takes some types and makes a new one
01:50:21 <mrkgnao> Int is a type, and Maybe Int is another, so Maybe "constructs types"
01:50:30 <mrkgnao> kinda circular, I think :(
01:50:35 <EvanR> yes it is
01:51:17 <EvanR> Maybe :: * -> *
01:52:11 <EvanR> you could say the Maybes are a type-indexed family of types
01:52:50 <EvanR> or its a family of types parameterized by a type
01:56:28 <EvanR> trigone: we have the luxury of making up brand new types like Maybe and list out of nowhere, but in a simpler theory you could get by with only a few type formers, such as Unit is a type, cartesian product of two types is a type, disjoint sum of two types is a type, and a way to do recursion
01:57:59 <kuribas> if Maybe is a type constructor, than isn't the Functor instance a constraint on a type constructor?
01:58:14 <EvanR> Bool = Unit + Unit, Maybe Bool = Unit + Bool, [Bool] = Mu t . Unit + (Bool x t)
01:58:44 <EvanR> :k Functor
01:58:46 <lambdabot> (* -> *) -> Constraint
01:59:11 <EvanR> constraint from a 1-ary type ctor
02:00:17 * hackagebot relational-query 0.9.3.0 – Typeful, Modular, Relational, algebraic query engine – https://hackage.haskell.org/package/relational-query
02:01:38 <EvanR> trigone: this kind of stuff is done in type theory, and seems to be a ways outside normal math, its sort of a foundation
02:02:53 * kuribas looks forward to dependend types in haskell
02:03:21 <trigone> EvanR: ctor = constructor? also, in your examples of types with Unit, etc, what's Mu standing for?
02:03:31 <EvanR> least fixed point
02:03:40 <EvanR> t stands for "this type"
02:04:07 <EvanR> recursion without being recursive
02:04:28 <trigone> EvanR: hm, ok... why the need for Mu t in List's def?
02:04:29 <EvanR> Nat = Mu t . Unit + t
02:04:37 * Maxdamantus feels like there should be a way to do anonymous sum types.
02:04:41 <EvanR> list is a recursive type, using itself in its definition
02:05:07 <Maxdamantus> (as a primitve, rather than having to invoke something like `Either`)
02:05:12 <EvanR> agreed
02:05:43 <Axman6> Maxdamantus: that's actually coming in GHC 8.2
02:05:52 <Maxdamantus> and `Either a b` should just be a name (possibly wrapping (ala `newtype`)) for some sum 
02:05:52 <EvanR> what o_O
02:05:55 <Axman6> to allow unboxed sum types
02:06:30 <Axman6> type Foo = (# Int | Bool | Text #) -- I think this is the syntax
02:06:46 <trigone> i'm not sure how you'd actually construct values of an anonymous sum type? aka what would you use instead of Left/Right?
02:07:01 <Axman6> then you can match on (# i ||#), (#|b|#) and (#||t#)
02:07:11 <EvanR> hahaha
02:07:13 <EvanR> nice
02:07:27 <Axman6> not sure if that exact syntax made it
02:08:16 <lyxia> what's unboxed about this
02:08:49 <Maxdamantus> trigone: you could have names for the tags, though they would always just be thought of as equivalent to, eg, some indices.
02:09:22 <Maxdamantus> imo you should be able to do the same thing with products.
02:09:35 <Maxdamantus> (foo: 42, bar: 43)
02:10:04 <trigone> what is the advantages of anonymous ADTs?
02:10:12 <trigone> s/is/are/
02:10:14 <Maxdamantus> then a sum values might look something like `[:foo 42, :bar 43]`
02:10:21 <Maxdamantus> s/a //
02:10:45 <Maxdamantus> Theoretical simplicity.
02:11:23 <trigone> Maxdamantus: aka?
02:11:33 <Maxdamantus> It just seems weird that in Haskell the `data` construction forces you to create a sum and a product for each of those sum members.
02:12:38 <Maxdamantus> (you can just pretend that you're creating only one or the other by making a sum with one member, or a sum with products that each has one member)
02:13:18 <Maxdamantus> trigone: what aka?
02:13:48 <trigone> i'm not sure to understand what you mean by "create a sum and a product for each of those sum members."
02:13:49 <EvanR> {foo=42, bar=43} is a thing in an alternate reality
02:14:19 <EvanR> <foo Int|bar Int> extensible variant in an alternate reality
02:14:19 <Maxdamantus> trigone: `data Foo = Bar Int` is a sum of products.
02:14:52 <Maxdamantus> trigone: it just happens that it's a sum of size 1 where each sum member is a product of size 1.
02:14:56 <trigone> Maxdamantus: yeah, so?
02:15:56 * hackagebot derive-storable 0.1.1.0 – Derive Storable instances with GHC.Generics. – https://hackage.haskell.org/package/derive-storable
02:16:56 <trigone> what would be different without naming the lambda data constructors?
02:17:06 <EvanR> i dont get sum that looks like [:foo 42, :bar 43]
02:17:08 <Maxdamantus> trigone: it just feels like it's stuffing a bunch of concepts unnecessarily into a single construction, then you just have to configure it to use some "defaults" for the things you don't care about.
02:17:14 <trigone> scratch the lambda thing
02:17:20 <Maxdamantus> EvanR: it's a list of sum values.
02:17:26 <EvanR> yeah ctors are decidedly not lambdas
02:17:36 <Maxdamantus> analogous to [Left 42, Right 43]
02:17:37 <EvanR> Maxdamantus: yeah so this is like extensible variants
02:17:42 <trigone> EvanR: i think Maxdamantus meant product there
02:17:50 <Maxdamantus> trigone: no, I meant sum.
02:17:50 <EvanR> no he meant list
02:18:20 <Maxdamantus> also note that it's not clear that :foo and :bar are the only tags in the sum type.
02:18:29 <EvanR> right
02:18:37 <Maxdamantus> So that constraint will probably come from the typing context.
02:18:45 <EvanR> it could be extensible
02:19:17 <Maxdamantus> Yeah, maybe. I'd have to think about that a bit more.
02:19:21 <EvanR> https://www.microsoft.com/en-us/research/publication/extensible-records-with-scoped-labels/
02:19:29 <EvanR> see the section on variants
02:20:51 <EvanR> now if you have records, and if you have variants of this form... suddenly... you have ADTs :)
02:20:55 <EvanR> we reinvented the wheel
02:21:11 <EvanR> you actually get more thanks to the extensibility
02:21:36 <trigone> still not certain to have understood why omitting names for data constructors but using "tags" is making things "theoretically simple."
02:21:42 <Maxdamantus> Wheel v1.1.0
02:21:56 <EvanR> trigone: whats being omitted here is the name of the type
02:22:23 <Maxdamantus> and the need for the sum members to be explicit products.
02:22:27 <EvanR> the type is {foo : Int, bar : String} and < foo Int | bar String >
02:22:52 <EvanR> for record and variant repsectively
02:23:18 <EvanR> dont look now though, to get enum types back, you need to do < foo () | bar () >
02:23:23 <trigone> EvanR: hm ok... so you'd do the equivalent of creating temporary data constructors in-site for temporary sums/products
02:23:41 <EvanR> not really temporary, just unnamed
02:23:51 <EvanR> the type isnt a name, its a structure
02:25:04 * Maxdamantus has been intending for his language to have tuples as syntactic sugar for records, where the field names are just the numbers 0 to 10 (inclusive)
02:25:20 <trigone> EvanR: well technically if you want to reuse it in another function, you'd have to copy structure + tags everywhere, which basically could not be more absurdly verbose, right?
02:25:46 <Maxdamantus> so `(foo, bar: baz, qux)` is just syntactic sugar for `(0: foo, bar: baz, 1: qux)`
02:25:51 <EvanR> you could bind this type to a variable
02:26:16 <EvanR> just like you dont want to name every sub expression in your code, but sometimes you definitely want to
02:26:47 <trigone> Maxdamantus: hm i see, yes if there are conventions for tags then i guess it's more flexible. but i wonder if you'd not have trouble with inferred typing (assuming it's a property of your language)
02:26:49 <EvanR> let Bool = < T | F >
02:26:53 <EvanR> in
02:27:22 <EvanR> trigone: in the paper i just linked, they show how to infer the types, and make it row-polymorphic
02:27:38 <Maxdamantus> trigone: there isn't any additional inference issue to such records (over the anonymous tuples you have in Haskell)
02:27:44 <trigone> EvanR: yeah but i won't have the time to read it now, i believe you though :)
02:27:57 <EvanR> :(
02:28:01 <Maxdamantus> (there are obviously additional issues for the sum/variant types)
02:28:06 <EvanR> this paper exists so you dont have to believe me
02:28:21 <EvanR> Maxdamantus: covered
02:28:22 <trigone> Maxdamantus: hm i guess so
02:28:37 <Maxdamantus> EvanR: right. Didn't mean to imply they're not solvable. Just that they don't appear in Haskell.
02:28:43 <trigone> EvanR: but religion is always so much more fun
02:29:06 <Maxdamantus> Since sum types and their members are always statically associated with a declaration.
02:29:07 <EvanR> math is not religion... but i guess cs is sometimes not really math
02:29:23 <EvanR> and maybe a million years ago math was religion... so nevermind
02:30:44 <EvanR> polymorphic extensible variants solves at least 19 teams communicating with different exception types
02:30:47 <trigone> EvanR: how could math be a religion... millions years ago?
02:30:59 <EvanR> and perhaps extensible effects
02:31:08 <trigone> i'm not sure there were humans millions of years ago...
02:31:17 <Maxdamantus> (btw, the reason my syntactic sugar works for 0 to 10 (inclusive) is because those are just normal identifiers, but `11` is syntactic sugar for `{1*10} + 1`)
02:31:53 <EvanR> er... ok
02:32:02 <EvanR> im ok with 11 also being a "normal" identifier
02:32:16 <trigone> what does row-polymorphic means
02:32:28 <Maxdamantus> You can put single quotes around it to get an identifier.
02:32:41 <EvanR> it means you can quantify over all rows
02:32:48 <EvanR> so the real question is whats a row
02:32:58 <Maxdamantus> `a` and `'a'` just mean the same thing .. `'hello world'` is an identifier that has a space in it.
02:33:00 <EvanR> a row is part of the type of a record
02:33:25 <Maxdamantus> Should be able to just construct an identifier corresponding to any sequence of octets.
02:33:27 <trigone> i meant to ask, is there another use of the symbol ` in haskell beyond allowing infix position?
02:34:07 <EvanR> > let (``) = (+) in 3 `` 1
02:34:09 <lambdabot>  <hint>:1:7: error: parse error on input ‘`’
02:34:13 <EvanR> guess not
02:34:17 <trigone>  Maxdamantus i'm frightened when you need to allow spaces in identifiers...
02:34:39 <Maxdamantus> trigone: well, it just follows logically.
02:35:15 <Maxdamantus> trigone: I wouldn't have Haskell's syntax that lets you write `(a + b) = ..` or `(+) a b = ..`
02:35:15 <EvanR> Maxdamantus: how about the empty identifier : )
02:35:26 <trigone> sorry i didn't follow everything
02:35:32 <Maxdamantus> So you'd instead just write `'+' a b = ..`
02:36:08 <Maxdamantus> and then "a + b" is syntactic sugar for "a `'+' b" (changed code quoting style)
02:36:23 <Maxdamantus> EvanR: sure.
02:36:28 <EvanR> nice
02:36:36 <Maxdamantus> No reason to exclude it.
02:36:44 <EvanR> can sugar for it be _
02:36:55 <EvanR> '' looks like spooky monster in the dark
02:36:55 <Maxdamantus> No.
02:37:25 <trigone> Maxdamantus: that's actually pretty smart. and you could end up with a terribly efficient obfuscating method.
02:37:32 <EvanR> theres a good reason to exclude it
02:37:55 <trigone> Maxdamantus: or a way to put comments as dummy values 'this is just to say hello' = 1
02:38:15 * Maxdamantus happens to have actually implemented all this stuff already.
02:38:22 <trigone> I think '' could be used instead of _
02:38:41 <EvanR> i demand the bikeshed be changed after the fact
02:38:44 <Maxdamantus> though it doesn't have a type system, since figuring out how that works is harder.
02:39:16 <EvanR> funny trigone has already jumped to the comments
02:39:26 <Maxdamantus> trigone: you can just write string literals if you want comments.
02:39:46 <trigone> Maxdamantus: ha true, never thought of doing so
02:39:47 <Maxdamantus> It would pretty much be wrong to use identifiers.
02:40:07 <Maxdamantus> Since it's not correct to just put random identifiers in code .. you can't refer to things that are not defined.
02:40:20 <Maxdamantus> > iWonderIfThisWorksAsACommentInHaskell
02:40:22 <lambdabot>  error:
02:40:22 <lambdabot>      Variable not in scope: iWonderIfThisWorksAsACommentInHaskell
02:40:40 <trigone> Maxdamantus: you have to assign a value to it
02:40:50 <Maxdamantus> Oh right, missed that bit.
02:41:23 <Maxdamantus> Anyway, I'd probably just have actual comments eventually.
02:42:08 <EvanR> lambdamoo had actual comments, but if you wanted them to survive the program storage process (compile-decompile cycle) you would need to use string literals instead
02:42:22 <EvanR> so the comments were useless
02:42:55 <ab9rf> what fresh hell did i just walk into?
02:42:56 <Maxdamantus> The existing implementation actually generates a huge amount of code because the comments are big string literals that are compiled into something like: '"' {':' 97 '[]'}
02:43:16 <EvanR> ab9rf: a language that allows empty string as identifiers
02:43:17 <Maxdamantus> (and then those applications are compiled, obviously)
02:43:40 <ab9rf> EvanR: to each their own, i suppose
02:43:44 <EvanR> haha
02:43:49 <EvanR> im on board
02:43:55 <ab9rf> can't be worse than befunge
02:43:56 <Maxdamantus> (note that `97` is syntactic sugar for `{'+' {'*' 9 10} 7}`)
02:44:18 <EvanR> in my language, i just allow any integer
02:44:29 <EvanR> 10 is not special snowflake
02:44:53 <Sepakorayl> Yo
02:45:01 <Maxdamantus> So if you write `829374234`, someone has to have bound that identifier to something?
02:45:38 <ab9rf> so now everything is an identifier?
02:45:39 <Maxdamantus> In this system, the expectation would be that something similar to prelude would define 0, 1, 2, 3, ... 10
02:45:40 <EvanR> i dont know whats going on anymore
02:45:59 <Sepakorayl> 'sup?
02:46:14 <EvanR> i allow integers, an there arent any identifiers
02:46:17 <Maxdamantus> and then everything else is just syntactic sugar for some application of '+' and '*' and those 0..10 identifiers.
02:46:24 <ab9rf> if 97 is sugar for whatver the hell that was, what is az sugared to?
02:46:41 <Maxdamantus> az?
02:46:50 <ab9rf> what about a9? 9a?
02:47:04 <trigone> ab9rf: in my language, even whitespace is an identifier :P
02:47:06 <EvanR> yeah i started with the raw data, havent even thought about sugar
02:47:13 <trigone> just kiddin
02:47:14 <Maxdamantus> a9 is a normal identifier, 9a is a syntax error.
02:47:33 <ab9rf> and 97 is some freaky weird thing?
02:47:55 <Sepakorayl> Are we discussing compilers;
02:47:55 <Maxdamantus> 97 is not an identifier. It's syntactic sugar for {'+' {'*' 9 10} 7}
02:47:58 <ab9rf> 9 is an identifier, but 97 is a weird thing.
02:48:02 <EvanR> i wonder what the use of expanding into decimal is
02:48:12 <EvanR> rather than, normal notation, or binary
02:48:47 <ab9rf> i assume you have a special case for 10, since your definition of your moon sugar uses 10, which would be sugared to a definition that includes itself.
02:48:56 <Maxdamantus> The unquoted identifier syntax is basically: /[a-zA-Z][a-zA-Z0-9]*/
02:49:03 <Maxdamantus> er
02:49:04 <EvanR> yes 0 through 10 are special
02:49:12 <EvanR> there are 11 special things
02:49:18 <ab9rf> none of which is 11
02:49:21 <Maxdamantus> /[a-zA-Z][a-zA-Z0-9]*|[0-9]|10/
02:49:22 <EvanR> no
02:49:26 <EvanR> 11 = 10 + 1
02:49:35 <EvanR> totally redundant
02:49:35 <ab9rf> i'm not convinced of the merits of this idea
02:49:39 <EvanR> hahaha
02:49:50 <ab9rf> i'm sure it would be (a) very slow to compiler (b) completely self-obfuscating
02:49:53 <Maxdamantus> Well, you don't have to hardcode `Num` into the language.
02:50:09 <Maxdamantus> It's just part of the standard library.
02:50:09 <ab9rf> which makes it an ideal esolang, i suppose
02:50:32 <EvanR> how would 0 - 10 be defined in the prelude?
02:51:03 <Maxdamantus> I imagine there would be a Num class with 0–10 as members.
02:51:03 <trigone> wait why 10 is a special case?
02:51:13 <EvanR> it has two digits...
02:51:35 <EvanR> Maxdamantus: 0 to 10 are then identifiers?
02:51:35 <trigone> so does 11, so why is the former its own kingdom but 11 is just 10+1?
02:51:41 <Maxdamantus> trigone: because {'+' {'*' 9 10} 7} is nicer than {'+' {'*' 9 {'+' 9 1}} 7}
02:51:59 <Maxdamantus> EvanR: yes.
02:52:05 <EvanR> oh
02:52:07 <EvanR> right
02:52:39 <trigone> Maxdamantus: lol when in rome: why don't you hardcode a meaning of positional numeration instead?
02:53:08 <EvanR> well my syntax allows 135234523455 in there, which means that integer
02:53:08 <trigone> something like 10 -> [1,0] -> 0*10^0+1*10
02:53:20 <EvanR> but i see that integer math is no walk in the park to just defined
02:53:43 <EvanR> i havent gotten to that point
02:53:56 <Maxdamantus> trigone: because that uses three special operators and it's not as nice to define recursively.
02:54:11 <EvanR> base 10 is still kind of weird
02:54:12 <Maxdamantus> note that `123` is syntactic sugar for `12*10 + 3`
02:54:16 <trigone> Maxdamantus: hm... but do you need recursion if it's just to create tags?
02:54:50 <trigone> Maxdamantus: er...
02:54:50 <Maxdamantus> trigone: I mean it's not as nice to define the sugar recursively (like above)
02:55:41 <trigone> technically you can recurse too: 123 = 3 + 10*(2 + 10*(1))
02:56:10 <trigone> ok lol that's what you do
02:56:21 <EvanR> if 10 is a Num... what does it mean for e.g. a Nibble type
02:56:31 <trigone> what's Nibble?
02:56:40 <EvanR> one hex digit
02:56:48 <trigone> EvanR: seriously?
02:56:48 <EvanR> er
02:57:05 <EvanR> in which case it works, its just ten
02:57:10 <EvanR> how about a half nibbl
02:57:18 <ab9rf> niblet
02:57:25 <Maxdamantus> > let s "01" = "10"; s [n] = [n]; s (n:ns) = "(" ++ s ns ++ ")*10 + " ++ [n] in s $ reverse "123"
02:57:27 <lambdabot>  "((1)*10 + 2)*10 + 3"
02:57:42 <trigone> EvanR: no, in hexa, 10 = 16
02:57:53 <EvanR> ... i... no
02:58:09 <trigone> 10 = 1*base + 0 = 16
02:58:31 <ab9rf> you are giving me a headache and that's not fair, i just spent an hour refactoring a 3500-line C++ class.
02:58:56 <Maxdamantus> EvanR: do you expect `10` in Haskell to mean something special for a hex type?
02:59:04 <trigone> in hexa, 10 is represented by A, 11 is B etc till 15, then 16 being the base, you end up with the first number with two digits, 10
02:59:08 <EvanR> so lazy ML was painstakingly forged from primodial ore... to create proto haskell. suddenly programming languages started looking a lot different based on what was nice to implement from in haskell. then Maxdamantus made this language that is nice to impleemnt in haskell
02:59:08 <Maxdamantus> 10 :: Nibble
02:59:11 <trigone> justl ike 10 is 2 in base 2
02:59:16 <ab9rf> you need to have a special symbol for ten
02:59:18 <Maxdamantus> I'd expect that to still be the number after 9.
02:59:24 <Maxdamantus> rather than 16
02:59:27 <EvanR> suddenly languages start to look totally weird based on what is easy to make in Maxdamantus's language :)
02:59:47 <trigone> Maxdamantus: how do you write 16 in base 16?
02:59:56 <EvanR> f
03:00:01 <EvanR> er
03:00:17 <Maxdamantus> trigone: fromHex "10"
03:00:17 <EvanR> 10, but i was asking about the number ten earlier
03:00:46 * exferenceBot works again
03:00:49 <EvanR> and not "tenH" which is asinine
03:00:58 <trigone> EvanR: you lost me
03:01:12 <EvanR> trigone: his class has methods 0 1 2 3 4 5 6 7 8 9 and 10
03:01:17 <Maxdamantus> I would actually add syntax for selected bases like hex, but it wouldn't be particular to any hex type.
03:01:28 <EvanR> decimal digits ... and something for ten
03:01:35 <ab9rf> i'd suggest using the unicode for roman nimeral ten (U+2169) but my font doesn't seem to have that character in it :)
03:01:36 <Maxdamantus> `0x10` would just be syntactic sugar for `16`
03:01:50 <ab9rf> Ⅹ
03:02:00 <EvanR> > text "\2169"
03:02:03 <lambdabot>  ࡹ
03:02:06 <EvanR> > text "\u2169"
03:02:09 <srhb> > 0x10
03:02:09 <lambdabot>  <hint>:1:8: error:
03:02:09 <lambdabot>      lexical error in string/character literal at character 'u'
03:02:11 <lambdabot>  16
03:02:20 <EvanR> > text "\x2169"
03:02:22 <lambdabot>  Ⅹ
03:02:35 <ab9rf> sadly, i get the question-box for that character
03:02:43 <trigone> Maxdamantus: yeah cuz it's all so sugary... i'm not sure the strategy is truly sound but whatever, your language
03:02:50 <EvanR> ab9rf: https://mail.haskell.org/pipermail/haskell-cafe/2011-August/094531.html
03:02:51 <ab9rf> it's not in the symbol font i use for terminals
03:03:43 <trigone> Maxdamantus: who could possibly output that unique symbol with a normal keyboard?
03:04:01 <Maxdamantus> trigone: what unique symbol? I didn't say anything about a unique symbol.
03:04:05 <EvanR> i cant tell if that post is serious but they can go up to 3999 in roman numerals
03:04:10 <trigone> sorry i meant EvanR 
03:04:15 <ab9rf> EvanR: i'm not sure either
03:04:25 <ab9rf> EvanR: but i can advise on how to go past 3999 :)
03:04:43 <EvanR> the question is if anyone will ever need to
03:05:06 <Maxdamantus> Too bad there's no representation for 0 in Roman numerals.
03:05:06 * EvanR attempts to place ancient person hat on
03:05:42 <EvanR> are you sure you need 0 ? :)
03:05:48 <ab9rf> unicode code points U+2180 (1000), U+2181 (5000), U+2182 (10000), U+2187 (50000), and U+2188 (100000) will get you to 399,999
03:06:07 <EvanR> ... roman numerals look like goddamned normal letters 
03:06:18 <ab9rf> not for 5000 and up :)
03:06:56 <trigone> EvanR: well at the time they *were* letters
03:06:57 <ab9rf> ↁ is 5000, ↂ is 10,000, ↇ is 50,000, and ↈ is 100,000
03:07:26 <trigone> ab9rf: nobody counted above 5000 at the time :P
03:07:43 <EvanR> those characters are making me dizzy
03:07:53 <EvanR> (they look like tight spirally spirals)
03:08:05 <EvanR> more spirals, the more magnitude
03:08:34 <ab9rf> they;re just doubly and triply nested Ds for the 5s doubled up back to back for the 10s.
03:08:56 <trigone> they look like cells in duplication process
03:09:03 <ab9rf> ↀ is an alternative sumbol for 1000
03:09:17 <EvanR> alternative SVMBOL
03:09:21 <ab9rf> in theory you could do a triple-nested one for 500,000 but there's no unicode codepoint for that
03:09:46 <ab9rf> er, quadruple-nested, rather, sorry
03:09:52 <EvanR> no thanks
03:10:00 <trigone> ab9rf: in theory you could switch to other forms of notation since nobody will *ever* read a 500,000+ number in roman numerotation
03:10:11 <EvanR> the idea must have been to discourage people from using such big numbers
03:10:18 <ab9rf> trigone: OUR NOTATION MUST BE CATHOLIC
03:10:25 <EvanR> like syntactic saccharine
03:10:29 <trigone> EvanR: i think so too! plus even the emperor could not check the result of the bank
03:10:32 <trigone> banker
03:10:55 <ab9rf> the romans even had a WORD for 10,000
03:11:06 <Maxdamantus> In Greek notation, I think 500,000 would just be some particular letter on top of a capital pi.
03:11:10 <EvanR> a myriad?
03:11:11 <ab9rf> well, thje greeks did, and the romans stole it
03:11:37 <Maxdamantus> oh, capital mu, not capital pi.
03:11:38 <ab9rf> (romans were good at stealing stuff from the greeks)
03:11:46 <trigone> ab9rf: technically they didn't steal it, they invaded it
03:11:58 <trigone> at least i think so
03:12:02 <EvanR> i want to hear more esolang idas
03:12:09 <EvanR> from the current millenium
03:12:45 <trigone> EvanR: do you know about the shakespear language?
03:12:58 <trigone> sorry i may have badly written it
03:13:00 <EvanR> i mean, serious
03:13:03 <ab9rf> the craziest thing i've heard of lately is that someone managed to implement a turing-complete state machione using intel exceptions, thereby allowing an intel processor to, in theory, compute without ever successfully executing an instruction
03:13:23 <EvanR> k thats kind of funny
03:13:50 <trigone> EvanR: http://shakespearelang.sourceforge.net/report/shakespeare/
03:14:12 <EvanR> perhaps you could run intel in a certain wait to cause thermal overload and the feedback from recovery can implement turing machine
03:15:19 <EvanR> Maxdamantus: so not a fan of peano eh
03:17:13 <ab9rf> http://www.cs.dartmouth.edu/~sergey/wm/woot13-bangert.pdf
03:17:19 <davr0s> are there any demo-programs that test the behaviour of rusts gc in the realtime case, e.g. per-frame trace of garbage generated etc, pehaps in some simple animation example (particle system)
03:17:32 <davr0s> 'update a bunch of particles with some non-trivial intermediate calcualtion' 
03:17:41 <EvanR> maybe ask in the rust channel?
03:17:44 <davr0s> oops i mean Haskell not rust
03:17:56 <davr0s> context switch
03:18:41 <Maxdamantus> EvanR: for desugaring? No.
03:19:27 <trigone> Maxdamantus: what are you writing your language in?
03:19:33 <Maxdamantus> EvanR: because it's much harder to optimise `1234567` to a single `int` value in C if it desugars to `S (S (S (S ...)))`
03:19:38 <trigone> i mean your compiler/interpreter
03:20:10 <Maxdamantus> trigone: the random thing I wrote a few years ago happens to be written in JavaScript and it compiles to (very inefficient) JavaScript.
03:21:07 <trigone> Maxdamantus: wait, you implemented in JS anonymous ADTs?
03:21:24 <trigone> i mean a language with anonymous ADTs in JS
03:21:34 <trigone> (using JS)
03:21:55 <Maxdamantus> Maybe. I'll check. I might have forced them to have names.
03:22:38 <trigone> Maxdamantus: weird choice...
03:22:44 <Maxdamantus> Right. The current implementation is somewhere in the middle, because it's dynamically typed.
03:23:03 <kuribas> ab9rf: does that save power?
03:23:33 <Maxdamantus> It lets you write an expression like `@union{ cons, empty }`, which just gives you back a structure with `.cons` and `.empty` as single functions.
03:24:25 <Maxdamantus> and the syntax for discriminating the members looks like: foo.{ cons (h, t): ..; empty (): ..; }
03:25:16 <kuribas> Speaking about turing machines (offtopic): https://www.youtube.com/watch?v=E3keLeMwfHY
03:25:36 <EvanR> trigone: js does have a few mechanisms to "just do stuff" programming wise, and a billion support systems instantly available
03:26:27 <trigone> EvanR: true, and a very simple way to make graphical small apps
03:26:37 <EvanR> Maxdamantus: well... 1234567 could be itself
03:26:48 <EvanR> its already "optimized"
03:27:06 <EvanR> trigone: im going for a graphical big app right now
03:27:12 <EvanR> with nwjs
03:27:19 <trigone> EvanR: nwjs?
03:27:27 <EvanR> yes
03:27:34 <Maxdamantus> EvanR: it can't be itself if someone has defined 0, 1, 2, 3, 4, 5, 6, 7 and 10 in the current scope to be something weird.
03:27:49 <Maxdamantus> or + and *
03:28:04 <EvanR> yes 2 would fall under the same category
03:28:11 <EvanR> 2 is 2, but cant also be something weird
03:28:18 <EvanR> such is life
03:28:23 <trigone> EvanR: yeah but at some size i'm not sure html makes things simpler than other graphical stuff... so many compatibility stuff, quite the nightmare to me...
03:28:28 <trigone> EvanR: what's nwjs?
03:29:03 <EvanR> i have no doubt its better than other graphical stuff
03:29:22 <EvanR> one reason why newer APIs are using it instead of old 2D tech
03:29:40 <EvanR> nw.js
03:29:50 <Maxdamantus> Right, but if it just compiles in the way I described, it should be pretty easy to do a couple levels of inlining to get a simple expression like `(1*10 + 2)*10 + 3`, where the numbers and operators there are just considered to be numbers/operators in a target system like C or JS.
03:29:51 <EvanR> i cant tell you, because im unconscious
03:30:23 <Maxdamantus> (and when you assume those are just the operators/numbers in C/JS, you can rewrite that constant expression to `123`)
03:30:31 <Maxdamantus> (or just let the C compiler do it)
03:31:03 <EvanR> what happens if the target system has no notion of the number 10
03:31:17 <trigone> Maxdamantus: er... if the purpose is to get back to 123, what's the point of not just Reading the number?
03:31:42 <Maxdamantus> trigone: because it doesn't necessarily correspond to an actual C int.
03:31:57 <Maxdamantus> trigone: eg in Haskell, `Num` instances include `Rational` and `Double`
03:31:58 <trigone> plus with JS you transform strings into numbers even when you don't want to... but i'm so tired i may just be right beside everything
03:32:19 <Maxdamantus> trigone: you can't just produce a Rational from an int.
03:32:38 <Athas> I wonder if there was any discussion about the instances for Float/Double, given how infinities and NaN tend to mess things up.
03:32:39 <trigone> Maxdamantus: i see... but once you got a C int you can always translate into whatever you want. it's still a base.
03:32:50 <Maxdamantus> You can just produce a Word32 from an int though, so Word32 should be reasonably optimal.
03:33:02 <Athas> I was pretty unhappy when I discovered bugs due to the toRational method turning infinities into finities!
03:33:30 <EvanR> yeah that makes no sense
03:33:48 <trigone> Maxdamantus: hm... and that works better if you have a decomposition with + and *?
03:34:54 <Maxdamantus> trigone: it works better than just having composition with succ.
03:35:04 <EvanR> i do like the idea that integers are "really" of the form described here, as a arithmetic grammar
03:35:14 <EvanR> and that can be "functored" to whatever system
03:35:37 <Maxdamantus> trigone: even if you can't inline everything for some reason, you can at least lift the expression up so it's only evaluated once (assuming the overall expression is pure and (relatively) closed)
03:35:42 <EvanR> but i still dont see how that is different from doing it with just place-value notation
03:35:45 <EvanR> or list of digits
03:35:56 <EvanR> scratch the list
03:36:01 <trigone> Maxdamantus: ok nevermind, too tired to think. gotta sleep, bye :)
03:36:26 <Maxdamantus> if you're instead compiling things as a bunch of succs, `1234567890123` will create a massive compilation output if it fails to inline.
03:36:37 <EvanR> def not succs
03:36:55 <EvanR> in the case of C... 1234567 compiles to itself
03:37:44 <EvanR> also what about negatives ?
03:37:45 <Maxdamantus> Well, in C, 1234567 probably ends up as its binary representation in some operand of some machine instruction.
03:38:06 <EvanR> but if you are targeting C, you cant deliver exactly that, whatever it is
03:38:12 <EvanR> you have to print source code
03:38:24 <Maxdamantus> Haven't thought much about negatives.
03:38:45 <EvanR> -2 -1 -0 0 1 2 :)
03:50:51 <fendor> hey, when using classy-prelude, is it somehow possible to easily derive certain instances for type classes for newtypes of simple types? for example `newtype MyMap = MyMap Map Int Int`
03:51:43 <fendor> i want to be able to write something like this `foo :: MyMap -> Maybe Int; foo = lookup 5`
03:53:48 <cocreature> fendor: can you link to the definition of lookup? I can’t find it in classy-prelude
03:54:26 <cocreature> ah found it
03:54:50 <fendor> cocreature, i'm not sure if this is the right function, what i mean is, i want to be able to use type class functions on the newtyped type
03:55:13 <fendor> in this case, work directly on a map, although it is wrapped in a newtype
03:55:20 <cocreature> fendor: in most cases that’s possible via GeneralizedNewtypeDeriving. However, there is a type family involved here which means it probably doesn’t work
03:55:37 <cocreature> there are some improvements in 8.2 for that but I think only for associated type families and Key is a separate type family
03:55:53 <fendor> yeah, I got to the same conclusion
03:55:59 <fendor> ah dang it
03:56:10 <cocreature> maybe you can derive Key itself in 8.2
03:56:22 <fendor> so, one would have to write its own boilerplate code :( 
03:59:14 <cocreature> for other typeclasses that don’t involve type families GeneralizedNewtypeDeriving should do the job
03:59:27 <cocreature> not sure how many typeclasses that applies to in classy-prelude
03:59:38 <fendor> thats a pity, since classy-prelude uses a lot of typeclasses with type families
03:59:59 <fendor> therefore, in this project, it is almost impossible to derive anything like that
04:00:13 <fendor> would there be a possibility with template haskell?
04:00:47 <cocreature> sure
04:00:50 <fendor> for example define the neccessary type family attributes like Elemet, and then derive it?
04:01:10 <fendor> is there a library? because i am certainly unsuitable to do this on my own :D 
04:01:49 <cocreature> I don’t know of any lib for that but I’ve never looked for one either so that doesn’t mean a lot :)
04:02:12 <fendor> ok, thanks, i will try to find something :D 
04:05:45 <int-index> This code compiles http://lpaste.net/357101, but if I change the definition of 'Functor' for the commented one, it results in an error. 
04:05:55 <int-index> I expect both definitions to work, is this a bug?
04:09:25 * hackagebot numeric-ode 0.0.0.0 – Ode solvers – https://hackage.haskell.org/package/numeric-ode
04:41:30 <sepakorayl> assume I have a conversion function :: t a -> Either [CustomError] t b. How can log things into left conveniently? Currently I convert a Writer (Maybe) value.
04:43:56 <sepakorayl> Is there a netter approach ?
04:46:56 <cocreature> sepakorayl: I’m not entirely sure I understand your question but if you want to accumulate several errors, you might be looking for something like https://hackage.haskell.org/package/either-4.4.1.1/docs/Data-Either-Validation.html
04:47:11 <cocreature> which is basically Either but the Applicative instance uses the Monoid instance fo combine values
04:47:18 <cocreature> so if you use [CustomError] it will concatenate them
04:47:18 <sepakorayl> yea I basically want to accumulate errors inside the function
04:48:24 <sepakorayl> Woo nice
04:48:46 <sepakorayl> how can I search hackage for such things?
04:49:11 <cocreature> not sure how you would search for that without knowing it’s name tbh
04:49:21 <sepakorayl> or in general be exposed to all these packages
04:50:04 <cocreature> ask questions here and hope someone points you at them :)
04:50:29 <sepakorayl> btw it seems I could had searched for "either left monoid" and it's the first reddit result
04:52:26 <sepakorayl> in any case thanks
04:52:43 <pacak> Are there any places where you can import concatMap specialized to lists? in recent versions?
04:53:10 <cocreature> pacak: hoogle claims that GHC.OldList works
04:54:06 <pacak> cocreature: Hmm... Yea, works.
04:54:20 <pacak> That is a strange place....
04:54:44 <cocreature> dunno, it’s old in the sense that we generalized it so it makes somewhat sense :)
04:56:41 <pacak> I kind of expected to see versions specialized to List in Data.List. Because name kind of hints. And Prelude can reexport whatever it wants to.
04:57:03 <cocreature> yeah the fact that Data.List is not specialized to lists is weird
05:18:02 <sepakorayl> It seems that validation is not a monad
05:21:32 <cocreature> it can’t be. try writing an instance
05:23:05 <sepakorayl> https://hackage.haskell.org/package/either-4.4.1.1/docs/Data-Either-Validation.html
05:23:34 <cocreature> I meant it can’t be an instance of Monad not that it can’t be that there is no Monad instance
05:23:52 <sepakorayl> ah okay
05:25:20 <sepakorayl> that makes it impractical for my usecase /I think/
05:25:27 <sepakorayl> I am really not sure though
05:27:31 <sternmull> could someone try to explain this expression to me: http://dev.stephendiehl.com/fun/003_lambda_calculus.html#recursion It probably easy to understand... but i don't get it.
05:30:55 <osa1> anyone know what's going on here: http://lpaste.net/357105 it seems like persistent is forgetting to generate some instances...
05:33:47 <pacak> osa1: derive generic pragma?
05:34:10 <pacak> osa1: -ddump-splices,  -ddump-to-file
05:34:29 <srhb> And/Or perhaps explicitly deriving it for Log
05:34:51 <pacak> Problem with snoyman's creation is that it's not really haskell.
05:35:05 <osa1> pacak: derive generic is enabled project-wise
05:35:14 <osa1> I already have splices dumped to a file but can't make sense of it
05:36:40 <pacak> Feels like instance for ToJSON for (Key a) is missing
05:36:50 <osa1> yeah but why does it even need that?
05:37:24 <osa1> basically persistent in lts-8.23 is completely broken. it can't even generate code for `[persistLowerCase| Tbl field Int |]`
05:39:12 <pacak> Hmmm...
05:39:16 <osa1> whaaat. it failed with lts-7.14 too. I have another project that defines a large schema using persistent-template in lts-7.14 and it compiles & runs fine.
05:39:36 <jonge> anyone ever done something with haskell and SOAP/WSDL?
05:39:48 <pacak> osa1: Can you paste splices somewhere?
05:40:00 <desudesusempai> is haskell the javascript of tomorrow?
05:40:00 <osa1> sure
05:40:14 <desudesusempai> meaning is it a truly progressive and enabling language that promotes equality?
05:40:24 <osa1> pacak: http://lpaste.net/357106
05:40:28 <desudesusempai> What's the reactjs of haskell?
05:40:32 <desudesusempai> I feel I should become a guru
05:40:45 <pacak> desudesusempai: Haskell is older than javascript.
05:41:31 <desudesusempai> sure sure sure, but javascript is of course a more progressive and enabling language that helps us fight against our unconscious biases
05:42:46 <desudesusempai> For example, static typing is clearly a ridiculously biased cis-hetero-normative concept.
05:42:55 <srhb> desudesusempai: Please stop.
05:42:55 <pacak> osa1: So it tries to derive ToJSON/FromJSON - most likely depending on DeriveAnyClass extension
05:42:56 <desudesusempai> *enter javascript stage left*
05:43:04 <osa1> pacak: ahhhhhhhhhhh
05:43:09 <desudesusempai> ok srhb 
05:43:12 <pacak> osa1: line 188
05:43:14 <desudesusempai> stay in the past~
05:44:28 <osa1> pacak: I'm confused.. I already had DeriveAnyClass enabled and I had to disable it to make this work. how does that `deriving` line work without DeriveAnyClass?
05:45:14 <pacak> DeriveAnyClass means you can type deriving (Show, Eq, Bar), it will derive Show and Eq usual way then will type instance Bar Foo
05:45:19 <pacak> with no body
05:45:34 <osa1> sure
05:45:48 <osa1> so for ToJSON and FromJSON to work I need that pragma
05:45:49 <pacak> relying either on generics or simply by throwing runtime exceptions
05:46:14 <pacak> Yes, but I imagine it's enabled project wise as well
05:46:32 <osa1> I disabled it completely to make it work.. if I enable project-wise it fails as before
05:46:36 <osa1> that's why I'm confused
05:48:40 <pacak> Hmmm...
05:48:45 <pacak> Which ghc?
05:49:06 <osa1> pacak: lts-8.23
05:49:21 <pacak> osa1: Non-bullshit version?
05:49:21 <osa1> so 8.0.2
05:49:40 <pacak> I think they did something to DeriveAnyClass around that time...
05:49:57 <pacak> But it shouldn't break stuff this way
05:50:01 <osa1> there's -XDerivingStrategies work but I'm not sure if it changes the default behavior
05:50:12 <osa1> that'd be backwards incompatible
05:50:55 <pacak> https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/GenericDeriving 
05:51:30 <osa1> that's a lot of tickets ... anyway
05:52:26 <pacak> Yea. I wonder.... derive standalone generic instance for  Key Log?
06:25:34 <marrenarre> I am trying to use Haskell Stack, but running `stack setup` gives me the message `Unable to find installation URLs for OS key: linux64-ncurses6-nopie`.
06:26:13 <bitonic> marrenarre: do you have some custom `stack.yaml`, specifying some custom compiler/
06:31:03 <marrenarre> bitonic: No, this is after removing the `~/.stack` directory.
06:31:28 <cocreature> marrenarre: let me guess, you’re on archlinux?
06:31:28 <bitonic> marrenarre: the local `stack.yaml` could also specify a custom compiler
06:31:37 <marrenarre> cocreature: Indeed.
06:31:37 <sternmull> i have the same problem on Arch
06:31:41 <tsmish> marrenarre: https://github.com/commercialhaskell/stack/issues/3268
06:31:56 <marrenarre> bitonic: This is not for any particular project. I am in my home directory.
06:32:17 * bitonic hides
06:32:51 <wz1000> marrenarre: installing ncurses5-compat-libs from the aur fixed it for me
06:34:12 <sternmull> i really hope this gets fixed in the official packages. I can't install ncurses5-compat-libs from AUR because it conflicts with other packages. I hoped somebody would fix it quickly. But now it remains unfixed for over a week or so :(
06:34:15 <marrenarre> bitonic: I am not sure why you are hiding. :)
06:34:51 <marrenarre> tsmish, wz1000: Thank you, I will install that.
06:37:19 <ltielen> i can confirm, ncurses5-compat-libs fixed it for me a few days ago
07:01:34 <marrenarre> Seems to work perfectly – thank you!
07:02:25 <trikl[m]> :t on
07:02:26 <lambdabot> (b -> b -> c) -> (a -> b) -> a -> a -> c
07:02:37 <trikl[m]> :i on
07:02:55 <trikl[m]> I can't find where on lives :S
07:03:57 <tsmish> @hoogle on
07:03:57 <lambdabot> Data.Function on :: (b -> b -> c) -> (a -> b) -> a -> a -> c
07:03:57 <lambdabot> System.Glib.Signals on :: object -> Signal object callback -> callback -> IO (ConnectId object)
07:03:57 <lambdabot> Text.Regex.TDFA.Common on :: (t1 -> t1 -> t2) -> (t -> t1) -> t -> t -> t2
07:05:05 * trikl[m] adds hoogle as a search engine
07:05:34 <marrenarre> This is really a beginners’ question, but how come it lives in both Data.Function and Text.Regex.TDFA.Common? It seems to have the same type in both.
07:05:57 <marrenarre> (I know Data.Function.on is the one I am probably looking for most of the time.)
07:09:54 <ezyang> Athas: Maybe my thesis is the best writeup atm 
07:12:40 <Athas> ezyang: oh yes, there is a Related Work section.  Thanks!
07:19:43 <Athas> ezyang: does not look like much was lost.  I consider the absence of recursive packages to be a feature!
07:20:23 <jonge> i have a list of [(Strict)ByteString] and i would like to consume it with constant space usage. is it possible to somehow make a function that does [(Strict)ByteString] -> (Lazy)ByteString ?
07:22:31 <int-e> jonge: there's fromChunks in Data.ByteString.Lazy
07:22:48 <oisdk> marrenarre Text.Regex.TDFA probably needed the function before it was in base, so wrote it themselves. 
07:23:02 <jonge> int-index: wow i must be pretty blind to not have seen that. sorry and thanks!
07:23:11 <jonge> * int-e
07:24:34 <int-e> jonge: well the type signature in the haddock generated documentation isn't very helpful. (it says [ByteString] -> ByteString)
07:24:44 <oisdk> marrenarre It looks like the one in Text.Regex.TDFA was added 11 years ago, so that would make sense. https://github.com/ChrisKuklewicz/regex-tdfa/blame/master/Text/Regex/TDFA/Common.hs#L31
07:25:13 <jonge> int-e yeah i think that might have been part of the reason why i didnt see it. i was lost in the bytestring builder document pages 
07:37:49 <ezyang> Athas: Haha :)	SPJ pushed hard for us to not include them at the beginning and I listened 
07:40:45 <Athas> ezyang: I actually rather like your thesis in general.  Concise and too the point.  Reinforces my desire not to have my own thesis end up as a bloated 200-page behemoth.
07:50:52 <jmcarthur> Do join points affect the way I should code? That is, is there some optimization I might have been applying by hand, perhaps without even realizing, that I no longer need to do?
07:51:30 <ezyang> jmcarthur: Are you actually in the habit of applying optimizations by hand? :) 
07:51:44 <jmcarthur> It depends on what you mean by "applying optimizations."
07:52:08 <jmcarthur> Sometimes one will write code in a certain style just because it is expected to be handled better by the compiler.
07:52:17 <jmcarthur> That's what I'm trying to ask about.
07:52:40 <ezyang> the paper mentions that you don't need Skip constructors anymore in stream fusion 
07:52:42 <Welkin> that's a silly way to program
07:52:57 <ezyang> Athas: Ask your advisor about it first :) 
07:53:22 <jmcarthur> Welkin: Why is it silly? I don't mean this justifies writing everything to be like C or something.
07:53:36 <ezyang> Athas: David was OK with a short Backpack thesis because the implementation code is it's own relatively large thing (that's not in the thesis, unlike more theory ones) 
07:53:42 <jmcarthur> ezyang: Yeah, I know that, but I am not sure how to generalize from this.
07:54:28 <jmcarthur> The fact that you can omit Skip in stream fusion seems to imply there may be something deeper here.
07:54:57 <Welkin> jmcarthur: code should be for the programmer, not the compiler
07:55:20 <jmcarthur> Welkin: You're making a false dichotomy. Code can be for both.
07:56:05 <Welkin> alright then, it shouldn't be at the expense of the programmer
07:56:21 <jmcarthur> I never said that was a good idea.
07:56:59 <Athas> ezyang: well, my own thesis is based on an implementation comprising 45000 lines of Haskell, so I hope it'll be OK.
07:58:39 <ezyang> :) 
08:02:25 <ongy> you are going to have to rubber duck that code in your thesis :P
08:06:03 <Athas> Man, I have a philosophy of never showing any implementation/Haskell code in papers (or theses).
08:06:36 <Athas> In my first paper, I papered over poor exposition by showing samples of the implementation.  Never again...
08:12:00 <nshepperd_> We don't need Skip constructors any more?
08:12:30 <MitchellSalad> can someone help me understand the behavior of this program? (sample runs at the bottom) http://lpaste.net/357108
08:13:19 <MitchellSalad> i would expect the main thread to be able to promptly kill the child whether or not it's masking async exceptions
08:13:28 <MitchellSalad> since waitForProcess is interruptible
08:17:05 <glguy> MitchellSalad: Why do you think waitForProcess is interruptible?
08:18:08 <MitchellSalad> glguy: https://github.com/haskell/process/blob/master/System/Process.hs#L732
08:18:29 <MitchellSalad> and it's not just a hackage vs. HEAD issue :)
08:21:34 <glguy> MitchellSalad: I think that being an interruptible FFI import isn't the same kind of interruptible as pertains to masking
08:22:01 <glguy> Normal blocking FFI calls can't be interrupted with a throwTo, but these can
08:22:07 <glguy> independent of masking
08:22:51 <MitchellSalad> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ffi-chap.html#interruptible-foreign-calls
08:23:00 <glguy> Yeah, that's what I was looking at
08:23:19 <MitchellSalad> hm, but you say this does not pertain to masking?
08:23:32 <glguy> Your code seems to show that, and the documentation doesn't mention masking
08:24:46 <MitchellSalad> i think it would be very surprising if the 'interruptible' keyword of foreign imports and the 'interruptible' masking state were not related :)
08:24:54 <glguy> surprise!
08:25:56 <MitchellSalad> the 'throwTo' documentation in Control.Exception suggests they are
08:26:07 <MitchellSalad> they are one and the same, that is
08:29:29 <marrenarre> oisdk: Ah, that makes sense. Thank you.
08:30:19 <MitchellSalad> oh, I'm mistaken, throwTo says nothing about masking state
08:31:40 <glguy> MitchellSalad: My reading of the documentation (and my tests just now) indicate that safe vs interruptible has to do with the blocking behavior of being in the FFI at all
08:31:58 <glguy> A safe FFI call can't be interrupted by a throwTo independent of masking state
08:32:21 <glguy> and an interruptible one can be interrupted by a throwTo, as long as exceptions aren't masked
08:32:27 <qmm> what is the recommended method for checking that a file exists? BS.readFile "foo.txt" will result in an exception if "foo.txt" doesn't exist
08:32:45 <qmm> Maybe there's a way of catching exceptions that I'm not aware of yet
08:33:10 <glguy> MitchellSalad: Oh, actually it seems that interruptible FFI calls are allowing me to kill them while under mask_
08:33:27 <MitchellSalad> doesn't my code snippet show the opposite behavior?
08:33:43 <glguy> MitchellSalad: but it's a very strange behavior. the call returns and execution continues after it
08:33:55 <MitchellSalad> can you share the code?
08:33:57 <glguy> so perhaps it's related to a signal being sent to hte process
08:34:02 <glguy> I was testing with sleep
08:34:05 <qmm> nvermind, found out there are plenty of articles on handling exceptions
08:34:24 <glguy> (but sleep stops sleeping if signals happen, I'm trying to disable them with -V0 for testing, but that might not be enough to get them all)
08:36:30 <glguy> OK, so my interruptible FFI call isn't interruptible when masked as far as throwTo was concerned, but the RTS was sending a signal which woke up the sleep is all
08:37:24 <MitchellSalad> okay, hmm
08:37:35 <glguy> I'm just playing with this test harness http://lpaste.net/805691897149390848
08:37:52 <glguy> I need a better blocking function though :)
08:40:07 <glguy> MitchellSalad: Steping back one layer, perhaps structure your code to call ''terminateProcess :: ProcessHandle -> IO ()'' instead of trying to kill the thread?
08:40:50 <glguy> or move the waitForProcess into its own thread that sends some result to an MVar and if you want to stop the waiting, kill the thread waiting on the other end of that MVar
08:43:15 <MitchellSalad> yah, thanks
08:43:51 <Axman6> So I've been watching lots of videos from the C++now conference this year, and one thing that keeps coming up again and again is haskell - maybe I'm picking talks which are more likely to be Haskell related, but it's been 3-4 talks so far
08:44:25 <Axman6> people finally realising the advantages persistent data structures give you for example
08:47:29 <cocreature> I went to a talk about fp in c++ at the local c++ user group not too long ago and for some reason it was mainly about compile-time fibonacci
08:47:43 <Tuplanolla> I've also seen those, but from my point of view it suggests that people are using C++ for all the wrong purposes, Axman6.
08:48:08 <Axman6> how so?
08:49:27 <Axman6> the demo showing a text editor which worked fine with GB sized files with instant undo was pretty interesting
08:50:04 <cocreature> Axman6: that sounds interesting, do you have a link?
08:50:29 <Tuplanolla> It's not realtime or hpc, so why bother?
08:51:02 <Axman6> cocreature: https://www.youtube.com/watch?v=ZsryQp0UAC8
08:51:07 <cocreature> thanks!
08:51:22 <Axman6> we're so postmodern
08:51:35 <Axman6> (so, we totally need this vector library in Haskell btw
08:51:37 <Axman6> )
08:54:43 <WarmCookie> Are there antecedents of the Actor model implemented in Haskell?
08:55:09 <Axman6> you mean like distributed-process?
08:56:03 <WarmCookie> Isolated computations that only communicate via messages (which lends itself nicely to distributed computing yeah).
08:57:48 <xenog> WarmCookie, I am working on an actor library for my Haskoin project at the moment: https://github.com/xenog/nqe.
08:58:14 <xenog> It is very experimental, and you may just want to look at it for fun. If you are serious go for Cloud Haskell.
08:58:17 <Axman6> that basically describes what distributed-process aims to give you
08:58:35 <Tuplanolla> Surely local actors are quite different from distributed actors.
08:58:45 <Axman6> (distributed-process is what used to be known as Cloud Haskell)
08:58:50 <xenog> I just wanted something simpler for use locally.
08:59:18 <xenog> Not that distributed-process cannot be used locally, since it is very flexible.
08:59:47 <WarmCookie> xenog: That's promising. It's probably enough for me to get a glance of the moving parts involved (which is really what I'm after).
08:59:50 <Axman6> the nice thing about distributed process is that you can treat computations on the same machine differently, so you can have shared state if doing so makes sense
09:00:21 <Axman6> d-p basically implements Erlang's OTP but with the added benefit of type safety
09:00:28 <WarmCookie> xenog: Much appreciated (:
09:01:14 <WarmCookie> I am aware of Cloud Haskell, but never heard of distributed-process; I'll check that one too. Thanks Axman6, Tuplanolla.
09:01:49 <Axman6> it the same thing
09:01:55 <Axman6> it's*
09:03:14 <nshepperd> if you only want to do it locally, you could just fork some threads and throw some Chans at it
09:03:29 <Axman6> agreed
09:03:55 <nshepperd> there's not much to the "actor model" really
09:04:07 <cocreature> and you probably should do this in that case
09:05:22 <xenog> What I did with NQE was emulate the Erlang model a bit, for ease of use.
09:07:18 <xenog> I used to do things with threads and channels, but once the project grows a bit there are some pains that can be solved using a model like Erlang/OTP with single mailboxes that involve pattern matching "cursors" to the mailbox contents.
09:08:51 <sproingie> i always found actors more fun than practical
09:30:00 <jmcarthur> nshepperd: See the join points paper for info on why we don't need Skip anymore.
09:44:59 <danilo2> Hello guys! I'm profiling some critical code and I want to achieve as close to metal performance as possible. Could anybody explain to me / give me any hints, why these 2 functions are not optimized the same way (the state version runs 10x slower): http://lpaste.net/357112
09:45:43 <danilo2> I'm asking if theere is any way for ghc to optimize it the same way, if there are any obvious reasons why not (that I do not see). I will inspect core if there is no obvious explanation of course
09:47:30 <danilo2> I can (and would love to) provide full source code with criterion benchmarks, however I cut it down to be more clear
09:47:41 <fosskers> hey all
09:48:00 <fosskers> can't quite get my types wrangled here
09:48:44 <fosskers> http://lpaste.net/357113
09:49:11 <fosskers> The compiler tells me: Could not deduce (Fooable a0) arising from a use of 'unfoo' from the context (Fooable a)
09:49:53 <glguy> fosskers: There's no way to know what type you had in mind for unfoo to have on the last line
09:50:22 <fosskers> right, how can I convince the type checker to just use my original `a`?
09:50:30 <glguy> replace 'map unfoo . mystery . map foo' with 'works'
09:51:14 <fosskers> i guess so eh. In my real app that might not be quite as performant, but it would work
09:51:30 <glguy> in a real app works could inline and it wouldn't matter
09:51:55 <fosskers> true
09:51:59 <fosskers> thanks
09:52:19 <fosskers> quick check though: there's otherwise no way to tell the type checker "hey just trust me here"
09:52:29 <fosskers> ?
09:52:31 <glguy> Trust you what?
09:52:38 <fosskers> to use the original `a`
09:52:59 <monochrom> It is not about trust. It is about communication.
09:53:00 <fosskers> manual annotating didn't seem to work
09:53:03 <danilo2> fosskers: the typechecker doesnt know what you mean. It cannot trust you because you havent told it what you mean. You could provide type by hand
09:53:03 <glguy> The way to do that is to write type signatures like works has
09:53:21 <glguy> so that you've communicated the desired type to the compiler
09:57:00 <glguy> We can indicate intent like this http://lpaste.net/357113
09:57:09 <glguy> or use scoped type variables
10:00:05 <glguy> http://lpaste.net/357113 
10:01:00 <glguy> http://lpaste.net/357116 using asTypeOf
10:01:40 <glguy> There you go, 4 options :)
10:03:21 <glguy> doesnt = length . ((map unfoo . mystery . map foo) `asTypeOf` id)
10:03:38 <glguy> extra "asTypeOf" version
10:04:05 <fosskers> I think I've landed on something good, thanks
10:07:00 <WilliamHamilton> hi, is there a known combinator to modify nubBy to accept a `a -> a -> IO Bool` as the comparison function, or should I roll my own?
10:15:23 <runeks> What's the extension that allows me to write @Show instead of "Show a => a"?
10:16:06 <ezyang> TypeApplications, probably? 
10:16:45 <HoloIRCUser3> Hi, i just encountered that print 1.0 really prints 1.0 despite 1.0 is typeclass fractional. Can anyone explain how this works? Is there some default order of types and Haskell takes the first in case of ambiguity? Or is this a print instance for all fractionals (if this at all makes sense)
10:18:17 <cocreature> HoloIRCUser3: if you enable -Wall GHC will tell you what it choses
10:18:24 <glguy> schlichtanders: Are you asking how 1.0 defaulted to Double?
10:18:30 <cocreature> schlichtanders: the default is to use Double
10:19:02 <schlichtanders> Thanks a lot! why is it double? Is there a rule?
10:19:21 <cocreature> schlichtanders: yes, take a look at https://www.haskell.org/onlinereport/decls.html#sect4.3.4
10:19:46 <cocreature> you can actually overwrite it but it’s extremly rare to do so ime
10:20:01 <glguy> schlichtanders: https://www.haskell.org/onlinereport/haskell2010/haskellch4.html#x10-790004.3.4
10:20:14 <cocreature> especially since most Haskellers tend to compile their code with -Wall so they’ll just add explicit type declarations to silence the warning
10:20:20 <glguy> Oh, I didn't look to see cocreature had pasted it
10:20:36 <schlichtanders> Awesome. Thanks for the references. Exactly such I was looking for but couldn't find them!
10:20:54 <monochrom> Not exactly. 98 vs 2010.
10:23:00 <cocreature> I don’t think the contents of that section changed in 2010 :)
10:23:21 <monochrom> Right.
10:23:31 <schlichtanders> Actually I use Haskell mainly for reading and understanding it as a hobby, but if I will compile my first code I hope I remember the -Wall flag :-)
10:25:19 <skiddieproof> I am trying to build cabal-install, using the bootstrap.sh file, and am getting the error : 'Failed to load interface for Codec.Compression.GZip' 'Perhaps you haven't installed the profiling libraries for package zlib-0.6.1.2'. Any ideas? I am sure that zlib is installed. What does profiling have to do with simply installing cabal-install?
10:26:30 <tippenein> If anyone can help me understand how to get my type constraints right. There's some code, example, and error here: http://lpaste.net/357118
10:28:03 <tippenein> essentially it's just supposed to insert some db entries at the start and end of a task, so I have a a reader for the config and I believe I just need to specify for runTask that it can also write to the db
10:28:37 <tippenein> any tips are appreciated even if the tip is delete it all and try again
10:29:19 <tippenein> I got in a little over my head by following the compiler suggestions
10:32:59 <glguy> tippenein: If you can have this instance, then you don't need a typeclass: instance MarioTask a where
10:33:37 <glguy> So the fix would be to delete the typeclass and rename runTask' to runTask
10:34:06 <glguy> and nothing seems to actually use the backend type variable, so you can remove that
10:38:11 <tippenein> cool. I took out the type signaturs too, but there's an implied BaseBackend backend ~ SqlBackend where it's erroring on backend being ambiguous
10:38:32 <tippenein> that's why I was trying to add it into the runTask constraints
10:40:50 <danilo2> Hello guys! I'm profiling some critical code and I want to achieve as close to metal performance as possible. Could anybody explain to me / give me any hints, why these 2 functions are not optimized the same way (the state version runs 10x slower): http://lpaste.net/357112
10:40:57 <danilo2> I'm asking if theere is any way for ghc to optimize it the same way, if there are any obvious reasons why not (that I do not see). I will inspect core if there is no obvious explanation of course
10:42:18 <danilo2> I even implemented super-minimal state version (http://lpaste.net/357122) but it is still 10 times slower than without using it. I cannot understand why ghc does not optimize it, it is just a wrapper over a lambda that couldb e fully nilined
10:42:20 <boxscape> when I use getContents in ghci, ^D doesn't end the input. Is there a way to get around that?
10:42:42 <glguy> don't use getContents in ghci
10:42:54 <boxscape> ok
10:48:04 <rostero> any ideas why i'm getting an amiguous type variable error:  https://gist.github.com/rostero1/43b42017e71a31720016a8f7f3607f63
10:49:03 <runeks> ezyang: I was hoping TypeApplications would allow me to write e.g. "@HasConfig -> @HasConn -> IO ()" instead of "(HasConfig cfg, HasConn conn) => cfg -> conn -> IO ()", but that doesn't look like it's the case. Is there no extension that allows this?
10:49:16 <zomg> rostero: I think it's because it can't deduce what `e` is in `RemoteData String e`
10:49:16 <runeks> in the type signature, that is
10:49:49 <rostero> i see.  i should probably write my own show then, right?
10:50:01 <geekosaur> rostero, just because you did not use the Failure constructor does not mean that a value of type RemoteData String e0 does not have the e0
10:50:10 <geekosaur> you will still have the problem
10:50:51 <geekosaur> ghci uses extended defaulting to allow it to infer e0 ~ (). compiled programs typically don't
10:51:15 <rostero> that explains why it was working there
10:51:18 <runeks> rostero: replace 'show $ Success "hi"' with "show (Success "hi" :: RemoteData a ())" and it should work
10:51:46 <rostero> thanks
10:51:59 <runeks> "show" can't know how to print a "RemoteData a e" unless it knows Show is defined for both a and e, which it doesn't unless it knows what e is.
10:52:35 <runeks> in my example I just set the error type to ()
10:53:07 <runeks> which doesn't affect Success
10:56:19 <monochrom> It can be the same problem with a simple "print []".
10:56:39 <millew> Hello, I'm new to haskell and having trouble with one of my functions can someone help
10:57:11 <monochrom> ghci sidesteps that with "oh I'm going to instantiate [a] to [()]". But this is non-standard behaviour.
10:57:39 <Tuplanolla> It's a fantastic feature for QuickCheck.
10:57:47 <monochrom> When ghci differs from compilation, ghci is always wrong.
10:58:38 <millew> import qualified Data.Map as Map  type IntMap = Map.Map Int  addFive :: IntMap Int addFive n = (n+5)
10:59:06 <Tuplanolla> @check \ xs -> xs == reverse xs
10:59:09 <lambdabot>  +++ OK, passed 100 tests.
10:59:43 <Welkin> @check \n -> succ n == n + 1
10:59:44 <geekosaur> millew, consider using a paste site of some kind, it's less confusing
10:59:45 <lambdabot>  +++ OK, passed 100 tests.
10:59:47 <geekosaur> @paste
10:59:47 <lambdabot> Haskell pastebin: http://lpaste.net/
10:59:50 <geekosaur> ^ preferred
11:00:13 <monochrom> millew: "Map Int Int" is completely unrelated to Int->Int.
11:00:14 <__monty__> I'm considering switching from stack to nix for haskell development because I like the ideas behind nix and because binaries would be welcome since I'm working on an aging machine and install/compile times get ridiculous once you hit swap. Three questions: 1) Does nix cover stackage or maybe even hackage or would I end up using nix+cabal or nix+stack? 2) Would the equivalent of a cabal file or 
11:00:20 <__monty__> stack.yaml+cabal file be a package? 3) How about things like cabal sandbox and stack ghci, are there equivalents?
11:00:49 <Welkin> __monty__: slow down and use some punctuation
11:00:54 <monochrom> I may also ask where you got your idea from.
11:00:55 <millew> geekosaur, I will try pasting the separate lines
11:01:03 <millew> import qualified Data.Map as Map
11:01:04 <geekosaur> not into the channel
11:01:07 <millew> type IntMap = Map.Map Int
11:01:13 <millew> addFive :: IntMap Int
11:01:16 <Welkin> lol
11:01:16 <millew> addFive n = (n+5)
11:01:22 <monochrom> haha this is a very determined person.
11:01:31 <geekosaur> because now there's otjer messages interspersed into it
11:01:38 * monochrom does not negotiate with people of strong convictions.
11:02:29 <__monty__> Welkin: I had it typed up so splitting would've been a bother. I'll admit it's not a prize winning piece of prose.
11:02:29 <Welkin> is that what they call terrorists nowadays?
11:02:42 <monochrom> No. But terrorists are special cases, obviously.
11:03:17 <monochrom> But where you see me saying "determined" or "with strong conviction", it's just a diplomatic way to say "stubborn".
11:03:47 <millew> Well I am pretty determined to see where I have gone wrong, I uploaded the code here https://justpaste.it/198dn
11:03:53 <monochrom> And you see why there is no point negotiating.
11:04:20 <monochrom> Is there any reason why Data.Map is involved and your type sig is not a simple "Int -> Int"?
11:04:51 <Boomerang> Data.Map is not `map`
11:04:52 <millew> I am reading something about types and typeclasses and I would like to get the hang of them
11:04:55 <Welkin> lol
11:05:03 <Younder> Well Int->Int is a bit limiting..
11:05:04 <Welkin> Map is a hash table
11:05:15 <Welkin> (technically, the implementation is a tree)
11:05:19 <monochrom> Data.Map isn't a typeclass.
11:05:43 <millew> It is a type?
11:05:51 <monochrom> Yes.
11:06:03 <danilo2> Hello guys! Is there any well implemented CPS State? I've found some info here about "adaptive state monads" (https://www.reddit.com/r/haskell/comments/8hbgu/an_adaptive_state_monad_40_faster_than_our_best/) but all the links already expired
11:07:18 <boxscape> millew what do you know about Map?
11:07:24 <lyxia> danilo2: Isn't   StateT s (Cont r) a   it?
11:08:08 <millew> boxscape I know it is a module the has functions that deal with mappings
11:08:27 <monochrom> lyxia: I think it means CPSing "s -> (a,s)"
11:09:14 <danilo2> lyxia, I think monochrom is right here, the CPS should be applied to the underlying function.
11:09:28 <boxscape> millew: map is very similar to a list like this: [(4, "one thing"), (5, "another thing"), (25, "a third thing")], where you associate a value (in this case, a string), to a key (in this case, an integer). You are trying to write a function though, not a structure like this
11:09:37 <boxscape> I should write "Map", not "map"
11:10:04 <lyxia> monochrom: which means what
11:10:08 <Welkin> Data.Map
11:10:34 <monochrom> Maybe s -> (a -> s -> r) -> r
11:10:44 <danilo2> btw lyxia , monochrom : I understand why CPS should be more performant and I understand a lot how GHC optimizes stuff, but I still cannot understand why GHC does not optimize normal State monad as good as pure code - it just makes some tuples and unpacks them, which could theoretically be done durong compilation time. Is CPS State a solution for it in GHC ?
11:10:47 <Younder> ergo a type since it is written with a caps .. (Duh)
11:11:21 <monochrom> danilo2: My guess is that if you have recursion, GHC gives up.
11:11:35 <lyxia> Isn't it   StateT s (Cont r) a
11:12:33 <lyxia> StateT s (Cont r) a   ~   s -> Cont r (a, s)   ~   s -> ((a, s) -> r) -> r   where (~) means Coercible
11:12:34 <monochrom> Well, I guess not true, I have recursive Int-using code that GHC optimizes to Int#
11:12:44 <glguy> so the difference is the extra (,)s
11:13:06 <monochrom> Oh! I didn't expand out the Cont.
11:13:38 <Younder> You can have recursive type definitions
11:13:40 <monochrom> should have asked a computer instead of trusting myself
11:13:48 <monochrom> @unmtl StateT s (Cont r) a
11:13:48 <lambdabot> s -> (a -> s -> r) -> r
11:13:52 <heebo> is anyone able to use igraph with stack, when i try to add it as a dependency i get the following...
11:14:01 <heebo> https://gist.github.com/4fbf9f46eaf4a62148517164381c75d8
11:14:07 <danilo2> monochrom: that would explain the difference. However, let's consider I'm creating some really low-level stuff - I need to iterate over list of things and "parse them" (like in the pasted example: http://lpaste.net/357112). I want to use State, because it makes much more modular code. Is there any wayt to make it as fast as the first version? I'm learning how to use Haskell in critical code right now
11:14:36 <monochrom> I don't know.
11:16:40 <Younder> danilo2, What would be the meaning of in-lining recursive code?
11:16:58 <danilo2> lyxia: hmm, that's interesting. By the way, If anybody knows - why GHC is not able to completely optimize away these tuples in state monad? It is creating them and unpacking only to pass 2 variables independently
11:18:07 <Younder> You can transform to a loop. But a infinite in-lining would waste all RAM.
11:18:24 <monochrom> danilo2: I think I will want to see what code causes this.
11:18:28 <danilo2> Younder: I'm not asking about inlining recursive code. Of course it is very problematic and we cannot evan define it in a single, clear way. I'm wondering if we are able to optimize these functions the same: http://lpaste.net/357112. State is much more mpodular to use and theoretically I do not see why GHC cannot understand that theese tuples in state are just passing values and cut them out
11:19:01 <monochrom> (I'm too lazy to think up my own examples!)
11:20:59 <danilo2> monochrom: Of course :) Laziness is good for us all! :) Are you talking about code that shows the difference? In fact I'm trying to use State in a VERY similar way to this mini code: http://lpaste.net/357112  (only the rules are bigger - this code matches only on 'a')
11:21:28 <danilo2> monochrom: however I've got also a full code that is executable with benchmarks in criterion. I think I will try to inspect core in a moment, however I'm not yet good at it
11:21:56 <monochrom> Well, the thing is I don't know whether you're looking at the core code of that paste verbatim, or you're looking at the core code of the use site after inlining.
11:22:36 <monochrom> Well OK I guess you're observing timing differences.
11:23:09 <monochrom> Does the use site use m = State [Char]?
11:24:21 <danilo2> monochrom: yes, I'll paste here the full code, I'll clean it up. Its short
11:25:09 <rostero> if I change `data RemoteData a e` to `data RemoteData e a` and then use `main = putStrLn $ show (Success "hi" :: RemoteData () a)` I get an error that a is ambiguous, where it worked before when it was flipped
11:25:40 <rostero> works when I change a to String, but I don't understand why it doesn't work when all I did was flip it around
11:26:17 <rostero> Before I had `RemoteData a ()`
11:26:38 <heebo> rostero: what type is a?
11:27:05 <monochrom> Genetic programming? Random mutations of your code to see what happens? (Why else would you swap two type variables like that?)
11:28:21 <rostero> heebo: https://gist.github.com/rostero1/4abd61bcf371584f0abb70cf6a763937
11:29:46 <heebo> rostero: so it knows that a will be the same type as the first argument to the Success constructor
11:30:42 <heebo> because of the data declaration, 
11:31:04 <danilo2> monochrom: here is the full source code. The state version runs 10x slower than pure one: http://lpaste.net/357135
11:31:19 <heebo> but when you swap them and give success the type signature RemoteData a () it has no way to infer the variable a
11:31:27 <danilo2> monochrom: the extensions on top of the file are not all necessary, they are just a "standard" extensions I enable in my cabal files 
11:32:56 <monochrom> This is fantastic. Highest extension-to-code ratio ever.
11:33:03 <rostero> thanks
11:33:17 <heebo> monochrom: extensions are turing complete
11:33:35 <danilo2> monochrom: I just wanted to paste it as fast as I can no to make you wait ;)
11:33:57 <Welkin> gotta go fast
11:34:22 <monochrom> Oh wait I don't have criterion yet.
11:35:16 <danilo2> monochrom: anyway, I use them in a big prooject, so it was the easiest way to me to just use them while testing new code. I believe they are not affecting performance in any way (maybe the performance of compiltion), however, are they harmfull to you in any way ? :)
11:36:53 <heebo> anyone know a good tutorial for cutting my teeth on dependant types?
11:37:21 <monochrom> Oh, extensions? No, I don't mind them.
11:39:34 <jle`> heebo: i have this series from abuot a year ago https://blog.jle.im/entry/practical-dependent-types-in-haskell-1.html
11:39:37 <danilo2> monochrom: sorry, I just understood your sentence about high extensions-code ratio as something that is just wrong :)
11:42:34 <heebo> jle`:thanks
11:46:35 <jle`> heebo: no problem, hope it's helpeful! i also link to some more tutorials too within it
11:46:53 <monochrom> danilo2: OK, it is real strange. The State case, it keeps trampolining between (# a, b #) and (a, b).
11:47:43 <danilo2> monochrom: would you be so nice and tell me how you have checked it? Using core? I just want to learn this to better understand whats going on by myself
11:48:18 <monochrom> Yes, core.
11:48:55 <danilo2> monochrom: what's even fancier, if you use a very simple implementation of state, like this one (http://lpaste.net/357139) the results are exactly the same
11:49:50 <danilo2> monochrom: if we see sometihng like this in core, and we've got suc ha simple code (using this simple state implementation makes it even simlper), what could we do to make it faster / understand whats happening to better prevent this "jumping" between boxed and unboxed tuples?
11:50:06 <monochrom> Oh man criterion's dependencies are still building. This is taking longer than building lens.
11:50:51 <danilo2> monochrom: -.- I know. However if you are nto using stack, sstack solves this problem. If you once build it, it will use it in every project later if the version matches
11:51:21 <bash0r> Hi everybody, the last few days I learnt a lot about object algebras. But how can we efficiently take use of this pattern in Haskell (directly speeking of "finally tagless" here)?
11:52:06 <danilo2> monochrom: anyway we do not need criterion here. You can use these functions without it this way: `    print =<< (void $ eval $ Strict.evalState mtlStateListParser_a (genChain_a 1000000))` in main
11:52:19 <danilo2> and measure time by just timing the tunning program
11:52:40 <monochrom> Yeah I'm letting "statistics" build in the background under a "nice".
11:52:45 <danilo2> (criterion does just that many times and computes additional values)
11:53:31 <monochrom> It hasn't finished. I'm ignoring it now and doing my own "george s = evalState smlStateParser_a s" so I can look at core.
11:53:50 <danilo2> monochrom: just use this line in main: `print =<< (void $ eval $ Strict.evalState mtlStateListParser_a (genChain_a 1000000))`
11:53:51 <monochrom> Yeah I think recursion confuses GHC.
11:55:09 <monochrom> To some extent the "s -> (a -> s -> r) -> r" mentioned in the other thread may help.
11:56:48 <danilo2> monochrom: im still testing cpsed veriosns. However, this code needs recursion - i want to go over the list of items and "parse"-like them. What do you mean by "confuses"? Recursion is the basic "primitive" of code in haskell, so how can we prevent ghc fro mthis boxing / unboxing of these tuples? :(
11:59:42 <monochrom> Recursion gets into the way of many optimizations. Optimization authors have to write harder analysis algorithms. Sometimes a lot of effort spent and still little gain.
11:59:55 <hexagoxel> danilo2: SPECIALIZE pragma gets rid of any difference, too.
12:00:10 <hexagoxel> i.e. {-# SPECIALIZE mtlStateListParser_a :: StateS.State [Char] Bool #-}
12:00:43 <Tuplanolla> Join us now on RECURSION-HATERS.
12:00:56 <hexagoxel> so you probably pay for the abstraction to any `m`.
12:01:16 <monochrom> For the tip of the iceberg, recursion cancels out any INLINE pragma.
12:02:21 <danilo2> hexagoxel, Tuplanolla, monochrom : Oh, right. Specialize pragma makes it fast! Is there ANY way to tell GHC to make automatic "Specialize pragmas' in a code that needs to be as fast as possible? (I dont care about compilation times)
12:02:24 <monochrom> A far-reaching consequence of that is that if you look at the rewrite rules in Data.List (or GHC.List?) for list fusion, they basically say "ignore the source code altogether". Because the source code is recursive.
12:03:25 <danilo2> monochrom: recursion prevents in if we use specialize pragma on recursive functions right? However if we've got non-recursive function A which uses function B with INLINE pragma, B will be inlined into A even if A is used in a recursive function X, right?
12:03:39 <monochrom> I don't understand this.
12:03:59 <danilo2> monochrom: Sorry, I will describe it better
12:04:12 <monochrom> No no! I mean I don't understand why GHC is doing this.
12:04:35 <danilo2> monochrom: ah! :)
12:04:59 <Tuplanolla> The structure of the call site should not affect inlining in that way, danilo2.
12:05:00 <monochrom> Well I guess SPECIALIZE exists for a reason.
12:05:13 <Tuplanolla> "Should" in the sense that there's no theoretical reason for it to do so.
12:05:16 <danilo2> Anyway, let's consider I've got a code that needs the best optimizations available. Are wwe able to ask ghc to make specializations for all the functions we use there?
12:06:27 <danilo2> Tuplanolla: If I've got a function f and g, both non-recursive. if `g` uses `f` and `f` has INLINE pragma, `f` will be inlined in `g` even if `g` is used in some recursive `h`. This is my understanding of things.
12:07:02 <Tuplanolla> If `f` is not large, danilo2.
12:07:27 <danilo2> monochrom: to my understanding, we can use Specialize to be sure sometihng is specialized if we earlier used INLINABLE pragma. however, it could be done automatically (at least hteoretically). If we've got functions with INLINE pragma, they are available for specialization in .hi files
12:07:37 <monochrom> No. I have "fanny s = pureListParser_a s". And you already have an INLINE on pureListParser_a. Still, the core code says "fanny = \s -> pureListParser_a s".
12:08:34 <danilo2> Tuplanolla: even if its large, INLINE pragma would make it inline. INLINABLE pragma would make it available for specialization in .hi files and GHC wooudl inline it if its "not too large" However INLINE pragma is stronger and it will be inlined always, right ?
12:08:43 <danilo2> Tuplanolla: I'm almost sure GHC dos say this
12:08:56 <Tuplanolla> Throw `-funfolding-use-threshold1000 -funfolding-keeness-factor1000` at it and try again.
12:09:32 <hexagoxel> oh, if you just do a trivial indirection to a local binding, you get good speed without SPECIALIZE .. that's ridiculous.
12:09:51 <danilo2> monochrom: because `pureListParser_a` is recursive. I was talking about `f` as non-recursive function 
12:10:11 <monochrom> Ah OK right.
12:11:24 <danilo2> Tuplanolla: I was already using these settings (exacltty with 1000 numbers). I was using EVERY ghc flag to test if it will work
12:11:46 <Tuplanolla> I'm out of my depth then.
12:11:46 <hexagoxel> »mtlStateListParser_a = go where go = $original_body« is faster than »mtlStateListParser_a = $original_body«.
12:11:59 <danilo2> Tuplanolla: they do nitot affect it. The SPECIALIZE pragma does. Anyway, GHC manual tells us that INLINE pragma will inine the function no matter how big it is unless it's recursive etc
12:12:15 <danilo2> hexagoxel: what?
12:12:30 <hexagoxel> danilo2: exactly, please test it :p
12:13:46 <danilo2> hexagoxel: I do not get any performance boost 
12:14:57 <danilo2> Tuplanolla, monochrom: So is there any "Trick" to ask GHC  for automatic specialization? If not, or we don't know, where can we ask about it? GHC channel ?
12:15:32 <hexagoxel> danilo2: not faster, but as fast as with the specialize
12:15:42 <Tuplanolla> You're going to need a compiler whisperer for that, danilo2.
12:16:40 <danilo2> hexagoxel: when using SPEICALIZE pragma, pureListParser_a is 10x faster (As fast as pure version). When using the ... go where go = ... version I got no performance boost at all
12:17:31 <danilo2> Tuplanolla: Sorry, english is no my native language, so trying to understand you better, are you talking it is just impossible or that we need to ask somebody really deeply involved in the process of creating GHC ?
12:17:46 <danilo2> hexagoxel: could you just paste your code ?
12:17:56 <Tuplanolla> The latter, danilo2.
12:18:45 <danilo2> Tuplanolla: oh ok! :) I think I'll prepare a small code to show and I'll ask on the GHC channel then in about 15-30 mins
12:19:44 <danilo2> monochrom: do you understand why without specialization GHC keeps jumping between packed / unpacked tuple ?
12:20:00 <monochrom> I don't. Especially since after what hexagoxel observed.
12:20:48 <danilo2> I cannot replicate hexagoxel results. hexagoxel would you be so nice and paste your code?
12:20:53 <hexagoxel> sec
12:21:14 <monochrom> I'm having "handel s = Strict.evalState mtlStateListParser_a s  where <copy the code of mtlStateListParser_a here, even with the very-general type sig>".  It is as fast as pureListParser_a. Even a bit faster but I won't count on that.
12:22:04 <monochrom> So if you put it under a "where" all the good things happen. If you put it at top-level, they want you to fill in an application form to get SPECIALIZE. I don't understand it.
12:22:11 <hexagoxel> danilo2: did you replace the >> .. with >> go ?
12:22:35 <ReinH> GHC optimizations become arcane pretty quickly
12:22:37 <hexagoxel> otherwise it won't work (sorry, did not mention that bit above)
12:22:53 <hexagoxel> danilo2: also, i have annotated the paste
12:23:24 <danilo2> monochrom, Tuplanolla, hexagoxel : I've got one more, VERY strange thing. if we use `mtlStateListParser_a :: State.MonadState [Char] m => m Bool` and specialize pragma, it is fast. if we use `mtlStateListParser_a :: Strict.State [Char] Bool` it is slow ... how could it even be?
12:23:50 <monochrom> Oh heh, now that's downright criminal :)
12:24:00 <hexagoxel> danilo2: have you tried specializing that one? :D
12:24:06 <Tuplanolla> Sounds like the compiler has trust issues, danilo2.
12:24:19 <hexagoxel> the identity "specialization"
12:24:35 <danilo2> Tuplanolla: it can trust me, Im an engineer
12:24:42 <danilo2> :D
12:24:51 <danilo2> I'm tryinfg to specialize that one ...
12:25:47 <ReinH> What optimization level are you using?
12:26:03 <ReinH> I've seen perverse cases where -O2 is slower in the wild.
12:26:14 <danilo2> ReinH: "-threaded -funbox-strict-fields -O2 -fconstraint-solver-iterations=100 -funfolding-use-threshold=10000 -fexpose-all-unfoldings -fsimpl-tick-factor=1000 -flate-dmd-anal"
12:26:53 * hexagoxel is using -O2 -threaded
12:27:01 <danilo2> Ok, so here are some final thoughts, hexagoxel, Tuplanolla, monochrom 
12:27:14 <danilo2> 1) hexagoxel is right, using ... = go where go = ... makes things faster 
12:27:24 <trigone> hi, anyone around knowing of the free monad?
12:27:28 * hexagoxel confirms that the non-specialize-pragma-specialized function is slow
12:27:32 <danilo2> 2) if using `mtlStateListParser_a :: State.MonadState [Char] m => m Bool` and SPEICLAIZE pragma, makes things faster
12:27:34 <ReinH> trigone: Just ask your question.
12:27:55 <danilo2> 3) `mtlStateListParser_a' :: Strict.State [Char] Bool` is SLOW unless we tell `{-# SPECIALIZE mtlStateListParser_a' :: Strict.State [Char] Bool #-}` then it is fast again ...
12:28:13 <ReinH> So you have to specialize it to... itself?
12:28:41 <monochrom> I'm doing merely -O
12:28:44 <Tuplanolla> With proper strictness `-fno-liberate-case` may avoid code duplication and allow some other optimizations to fire, danilo2. Why not try that one while you're at it?
12:28:51 <trigone> I'd like to know if the usage of the free monad is at least partially similar to Lists (the latter respectively to monoids), that is, to do stuff akin to zipping, folding, mapping, etc.
12:28:53 <hexagoxel> danilo2: i can confirm all those observations.
12:28:53 <danilo2> ReinH: yes, after specializing it to itself its 10 times faster
12:29:04 <ReinH> danilo2: cool.
12:29:42 <c_wraith> trigone: not really.  Have you looked at the free package, and the functions provided by Control.Monad.Free?
12:30:15 <trigone> c_wraith: no actually... it could indeed be an obvious starting point
12:30:49 <ReinH> trigone: Do you know the definition of the free monad?
12:31:04 <c_wraith> trigone: it'll give you some idea.  It'll also make you say "what?" a bunch of times, as the docs talk about sections and retractions and other CT things that you've probably never bothered to learn about.  (I sure haven't)
12:31:07 <danilo2> ReinH: no, its not :(
12:31:15 <danilo2> ReinH: * its not cool. 
12:32:15 <danilo2> ReinH: changing -O2 to -O1 does not affect anything here
12:32:44 <danilo2> monochrom, ReinH, hexagoxel, Tuplanolla: I think I'm going to make GHC ticket out of it. I'll send you link to it
12:33:27 <trigone> ReinH: the one thing that speaks to me on the subject is comparing lists with it, seeing it as the freest monad/monoid, which somehow "preserves its constituents in isolation" instead of smashing them into a value that has no memory of the values it was built from...
12:33:34 <hexagoxel> has anyone tested this on ghc-8.2.1rc ?
12:33:55 <danilo2> hexagoxel: are you asking about the topic with states ? Id so I'd be more than interested in it
12:34:01 <monochrom> Build criterion for a 2nd time?! Thanks but no thanks. :)
12:34:27 <qmm> cabal: Encountered missing dependencies:
12:34:28 <qmm> postgresql-simple >=0.5.2.1 && <=0.5.3.0
12:34:31 <hexagoxel> yeah, still at this topic :)
12:34:47 <trigone> it could be naive but iter looks a bit like fold, cutoff a bit like drop...
12:35:02 <ReinH> trigone: do you know its Haskell definition? data Free f a = ???
12:35:12 <qmm> i have this in the cabal file , postgresql-simple >= 0.5.2.1 && <= 0.5.3.0
12:35:23 <qmm> how might i resolve this issue?
12:35:36 <cocreature> qmm: cabal install --only-dependencies
12:36:02 <danilo2> does anybody have ghc form HEAD compiled and can test this issue for us? If not, I'm going to make it, but Id prefer not to compile ghc now
12:36:29 <hexagoxel> danilo2: i only had rc1, and could not even get the deps to build atm. but it is the one thing i might bother checking before filing. i am installing rc3 right now.
12:36:50 <qmm> cocreature: amazing. how did you know that would work?
12:37:05 <qmm> is the cabal user guide the best place to learn how to use cabal efficiently?
12:37:05 <cocreature> qmm: I’ve been using cabal for a while :)
12:37:06 <danilo2> hexagoxel: what deps? The only dep here is mtl, criterion etc could be thrown away
12:37:11 <qmm> :)
12:37:31 <danilo2> hexagoxel: would you be so nice and check it on rc3?
12:37:52 <cocreature> I never really read the guide. I just picked up bits and pieces as I went along and only use the guide as a reference when I’m looking up something specific
12:37:58 <trigone> ReinH: well i have the definition here. it makes moderate intuitive sense. Free f a = Pure a | Free (f (Free f a))
12:39:34 <danilo2> hexagoxel: anyway if the deps does not compile, you can test it WITHOUT any deps, just use this State definition: http://lpaste.net/357139
12:39:35 <ReinH> In a computational sense, Free f a allows you to construct f-shaped, a-valued ASTs.
12:40:26 <monochrom> I also want to mention that "george s = runCont (Strict.evalStateT mtlStateListParser_a s) id" is pretty fast.
12:40:50 <ReinH> monochrom: When in doubt, yoneda?
12:41:02 <monochrom> As in, 1.4 times of pure, but at least not as bad as 10 times.
12:41:29 <trigone> ReinH: i'm sure it makes sense once you actually know already how it works... first i'd like to know, once you build a monadic value of that free monad, what do you do with it in very practice?
12:41:50 <danilo2> monochrom: please note that if we use SPECIALIZE prama, or hexagoxel trich, we got THE SAME performance as pure
12:42:03 <monochrom> Yeah, that's even better.
12:43:07 <monochrom> So mine is an "honorable mention" no more no less. :)
12:43:18 <danilo2> monochrom: thats very cool, because we know it is doable. I'm so happy about it. Whats more interesting, I was able yesterday to make some ghc flags and code optimizations to make StateT transformers (independent how many you use) workj as fast as single one
12:43:28 <hexagoxel> danilo2: am using a slighly bloated "snippet test project" :) rc3 seems to work though, but might take a bit to compile the deps. will report when done.
12:43:43 <ReinH> trigone: you turn it into some other monad action by interpreting it
12:43:44 <danilo2> monochrom: if we get this working I will probably have "receipt" on using as many StateT transformers as you want that are fully optimized away
12:43:55 <ReinH> and then you use that monad action
12:44:12 <monochrom> receipt? license?
12:44:21 <danilo2> hexagoxel: Thank you, I'll be waiting for any further info and then I will fill the bug report
12:44:23 <hexagoxel> danilo2: btw, did you get my message i send you like yesterday?
12:44:30 <ReinH> Free constructions allow you to define multiple interpreters for the same AST: one for calculating, one for printing, etc.
12:45:07 <danilo2> monochrom: "receipt" = set of ghc flags . I ment "receipt" how to cook this example in GHC 
12:45:10 <trigone> ReinH: so, it's a kind of folding, with respect to it, isn't it? it's like lists which allow you to choose however you want the list's content to be eventually combined
12:45:21 <monochrom> recipe!
12:45:35 <danilo2> hexagoxel: Ah I did, I'm sorry I havent found time (yet) to reply 
12:45:41 <ReinH> trigone: Yes, this is a similar property of free structures: they can be turned into other structures by "interpreting" them.
12:45:45 <ReinH> foldr interprets lists
12:46:02 <danilo2> woudl you be so nice and pm me with your mail? It will be easier for me to reply there and discuss it better
12:46:06 <ReinH> foldMap is probably the better analogy
12:46:23 <ReinH> To the extent that lists are free monoids (they almost are), foldMap interprets them as some other monoid.
12:46:29 <danilo2> hexagoxel: you could as well write me mail at wojciech@luna-lang.org
12:46:33 <trigone> ReinH: yeah, i used fold in a loose sense
12:46:39 <trigone> ReinH: they aren't free monoids?
12:46:48 <ReinH> Infinite lists are annoying.
12:46:53 <monochrom> You say "catamorphism" and be both general and precise. :)
12:46:58 <ReinH> monochrom: :)
12:47:12 <trigone> ReinH: hm i see... so would be infinite computations for free monads i suppose?
12:47:17 <ReinH> Probably.
12:47:32 <monochrom> catmorphism :: Fish f => (f a -> a) -> Meow f -> a
12:47:38 <ReinH> I'm not sure if anyone has determined whether Free f a is actually the free monad, or just close enough if you ignore bottoms.
12:48:27 <Tuplanolla> Considering the mess that is free monoids, the answer is most likely no.
12:48:39 <monochrom> I'm pretty sure you have to ignore bottoms. (famous last words.)
12:48:46 <ReinH> bottom makes everything a mess
12:49:14 <monochrom> Bottom makes everything lifted again.
12:49:32 <ReinH> :t \xs -> flip fmap xs
12:49:34 <lambdabot> Functor f => f a -> (a -> b) -> f b
12:49:37 <ReinH> such yoneda wow
12:50:09 <cocreature> ReinH is secretly bob harper and is trying to trick Haskellers into using a strict language instead
12:50:25 <trigone> ReinH: it's maybe a wrong intuition, but i wonder if it's possible to build a stack of monads by "zipping" isolated "computation lists"?
12:50:40 <trigone> who's bob harper?
12:50:59 <ReinH> cocreature: Maybe I'm secretly Edwin Brady
12:50:59 <cocreature> a type theory research who’s not particularly fond of Haskell :)
12:51:28 <trigone> cocreature: what does he like instead?
12:51:51 <ReinH> cubical type theory
12:52:05 <monochrom> He likes strict by default, non-strict optional.
12:52:09 <trigone> ReinH: i meant as programming language
12:52:10 <cocreature> sml
12:52:11 <ReinH> refinement logics
12:52:54 <cocreature> ReinH: edwin has been a lot less vocal on the strict vs lazy subject afaict :)
12:53:27 <ReinH> cocreature: Well, he tried to add laziness inference to Idris. It was more or less successful.
12:53:47 <ReinH> It's a cool idea, at least.
12:53:58 <ReinH> Making laziness a type and then inferring it.
12:54:04 <trigone> what's the fastest language at least as haskell-ish as haskell?
12:54:11 <ReinH> Haskell.
12:54:16 <ab9rf> ^^
12:54:26 <ab9rf> haskell is not particularly slow
12:54:34 <ReinH> Haskell is extremely fast
12:54:40 <ab9rf> although it's possible to write slow code in haskell, that's true in any language
12:54:40 <cocreature> how can a language be as haskell-ish as Haskell and not be Haskell itself?
12:54:41 <ReinH> Far faster than it has any right to be.
12:54:41 <MarcelineVQ> languages don't have speeds
12:54:41 <Tuplanolla> I hear Clean has been used for fast things and it's a bit like Haskell, trigone.
12:54:47 <trigone> you misunderstood me, i meant the second fastest after haskell
12:55:08 <ReinH> Well, you said ">= haskell", which haskell is.
12:55:36 <haroldcarr> Does anyone have a Text.Parsec based combinator for parsing and returning a URL?
12:56:08 <trigone> MarcelineVQ: :P animals either but i would still never try to beat a cheetah on the off-chance it'd have a sprained ankle
12:56:41 <trigone> ReinH: ok, then "it's my fault you misunderstood me." happy? can you answer now? ^^
13:01:00 <trigone> Tuplanolla: Clean does seem nice. is it comparably as fast as haskell? what's the size of its libraries/communities?
13:01:01 <ybit> unsure if i recall correctly, but is there work being done or completed which helps with name collissions or ambiguities in records?
13:01:13 <Tuplanolla> Don't ask me, trigone.
13:01:42 <trigone> Tuplanolla: Sorry, i did not want to evoke a painful subject...
13:02:04 <trigone> how fast is idris compared to haskell?
13:03:29 <ybit> trigone: i'm very curious to see its runtime evolve. currently it isn't focused on speed, though things may have or may be changing. i don't keep up :) there is an older issue on github about this
13:03:43 <c_wraith> ybit: there is work being done, but it's not very usable yet.
13:03:56 <ybit> c_wraith: neat-o! 
13:04:17 <Tuplanolla> It's just that I haven't used it enough to know, trigone. The Clean community probably knows better.
13:04:22 <ReinH> trigone: not as fast
13:04:43 <trigone> is idris strictly more powerful and "well done" than haskell? like, if idris were as fast and was as big as regards libraries/communities, would there be still a place for haskell in the world?
13:04:50 <c_wraith> ybit: https://ghc.haskell.org/trac/ghc/wiki/Records/OverloadedRecordFields/DuplicateRecordFields is what has been implemented so far.  There is more work necessary, as that's so painful to use it's actually worse than not using it. :)
13:04:51 <trigone> Tuplanolla: np it was just a joke :)
13:05:20 <ReinH> No, Idris is not strictly better than Haskell.
13:05:26 <Welkin> lol
13:05:31 <Welkin> they are different
13:05:35 <Welkin> one is not "better"
13:05:49 <trigone> Welkin: shortcut to mean "better for certain tasks"
13:05:56 <Welkin> idris is like a dependently typed haskell that is strict by default
13:05:57 <ReinH> Yes, Idris is better for certain tasks.
13:05:57 <jmcarthur> Idris is stricter than Haskell.
13:05:58 <Tuplanolla> Huh huh, "strictly" better.
13:06:06 <Welkin> also, for real world usage, haskell is most definitely better
13:06:09 <Welkin> it has a strong ecosystem
13:06:10 <ReinH> Like doing things with dependent types.
13:06:35 <ReinH> "Strictly more powerful or 'well done'" is not a shortcut for "better for certain tasks"
13:06:37 <ReinH> It is the opposite.
13:07:09 <nfd9001> Category theory question: I'm failing to understand how this fails associativity of composition https://upload.wikimedia.org/wikibooks/en/6/65/Not-a-cat.png
13:07:10 <ReinH> It is "not worse for any tasks".
13:07:23 <nfd9001> If anyone could poke me in the right direction, that'd be super
13:07:45 <ReinH> nfd9001: surely there's some context with that image?
13:07:46 <ybit> c_wraith: https://github.com/idris-lang/Idris-dev/issues/812#issuecomment-33598587 is the comment that i was remembering and which made me excited about the future of the idris rts
13:07:58 <trigone> it's strict, but has it still an aspect of "evaluation on demand"? like if you have a function with an unused parameter, will it be evaluated?
13:08:13 <nfd9001> ReinH:  https://en.wikibooks.org/w/index.php?title=Haskell/Category_theory&stable=0 Second question, first section.
13:08:26 <ReinH> trigone: No, because then it would not be strict.
13:08:26 <ybit> c_wraith: heh, thanks for sharing! i _thought_ there was some work around that
13:08:31 <ReinH> It has optional non-strictness.
13:08:40 <ReinH> Enforced by the types.
13:08:41 <trigone> ReinH: originally i started with the question of wether it was better/more powerful for *all* tasks, hence the shortcutness.
13:08:50 <ReinH> That's... that's not what shortcut means.
13:09:09 <trigone> ReinH: ok then it's not a shortcut, i don't care
13:09:12 <nfd9001> All the other exercises are making sense, I'm just failing to wrap my head about how this fails any of the category rules
13:09:21 <ReinH> Well, if you want to communicate with others, you should care about what the things you say mean.
13:09:46 <nfd9001> https://xkcd.com/1860/ might be relevant?
13:10:07 <trigone> ReinH: sorry mom, i'll just stay silent in my corner over there ->>>> corner
13:10:11 <ReinH> nfd9001: I don't see why it fails to be a category.
13:10:36 <Tuplanolla> It looks like a category to me, nfd9001.
13:10:52 <nfd9001> ReinH: hmm, I thought I was going mental or something
13:10:58 <ReinH> I don't see why associativity would fail
13:11:09 <trigone> nfd9001: lol
13:11:22 <trigone> nfd9001: (wrt xkcd)
13:12:14 <nfd9001> and I don't see any problems with the other laws. There's ID and it's transitive/closed
13:12:24 <ReinH> There isn't much that you can compose, but (f . g) . h = f . (g . h)
13:12:42 <ReinH> and the ids can't be a problem by definition
13:13:07 <ReinH> it seems pretty easy to exhaustively show that the arrows are associative.
13:13:13 <ReinH> so I don't get it
13:13:19 <cocreature> f.g.h = id.h=h but by associativity it’s also f, so f = h and I think that diagram is supposed to suggest that f and h are distinct
13:14:03 <cocreature> that diagram is supposed to show all arrows even compositions if I understand the text correctly, so f.g=id has to hold because there is no other arrow a -> a
13:14:07 <cocreature> and the same for g.h
13:14:29 <cocreature> at least that’s the only way I can make sense of that diagram
13:14:38 <Tuplanolla> That's a lot of assumptions.
13:14:52 <cocreature> well f.g=id is written in the text above
13:15:01 <ReinH> Well yes, f . g = id is obviously true
13:15:14 <byorgey> cocreature: yes, I think that's what that exercise is getting at
13:15:15 <ReinH> But I don't see why that says that h can't exist.
13:15:16 <cocreature> f≠h is the only assumption I’m making here
13:17:39 <byorgey> I remember doing that exercise a long time ago.  Honestly I never found it all that useful/enlightening, because no one ever makes a category this way (by first positing some objects and arrows and then seeing whether there is a sensible way to define composition).
13:18:30 <Younder> Play as you go, you will get it eventually.
13:18:58 <nfd9001> mmmkay. The other exercises haven't really been giving me any problems, just that one
13:19:07 <Peaker> ghci 8.0.2 lets me type: "x = 1" with no error, but it is ignored? wat?
13:19:33 <lyxia> type "x"
13:19:56 <byorgey> nfd9001: I think cocreature is right though, did you understand the explanation?  f = f.id = f.g.h = id.h = h, but f and g are distinct in the picture
13:19:56 <geekosaur> Peaker, ghci 8.x made "let" optional
13:20:27 <nfd9001> byorgey: f and h are distinct, yeah
13:20:38 <byorgey> Peaker: it is not ignored.
13:20:58 <byorgey> nfd9001: right, f and h, yes
13:21:10 <nfd9001> yeah, i'm getting it now
13:21:11 <byorgey> f and g are distinct too but that's not the point =)
13:21:33 <nfd9001> i guess i was assuming they were equal too
13:21:47 <nfd9001> thank you
13:23:01 <nfd9001> and thank you cocreature, super super
13:25:05 <Peaker> byorgey, http://lpaste.net/8879027526433767424 yes they are
13:26:55 <EvanR> "establish a category from this junk sudoku"
13:28:35 <glguy> Peaker: what's in your .ghci file?
13:28:48 <Peaker> :set -fobject-code +c
13:29:06 <glguy> OK, that's responsible
13:29:18 <Peaker> ?
13:29:21 <glguy> !
13:29:27 <monochrom> What is +c?
13:29:42 <Peaker> monochrom, collects type info, used by haskell-mode to let you see any subexpr type, etc, quickly
13:29:49 <glguy> +c is for type information, but that's not the problem
13:29:55 <glguy> -fobject-code is
13:30:06 <Peaker> monochrom, ghci answers queries like: type of subexpr in this range in file
13:30:23 <Peaker> (huge productivity boost, IME :-) )
13:30:45 <glguy> +c is how editor plugins like dante work to tell you the type at your cursor
13:30:46 <monochrom> Interesting
13:31:33 <Peaker> glguy, so.. -fobject-code breaks ghci features silently? :(
13:31:39 <glguy> :-S
13:33:00 <geekosaur> it's somewhat surprising that it doesn't break ghci completely, actually
13:33:30 <geekosaur> in fact I think it took a fair amount of work to have it even this functional; ghci expects bytecode
13:33:34 <Peaker> it's the only way to get the haskell-mode load functionality to not re-start from scratch each time, iirc
13:33:50 <Peaker> geekosaur, but "let" works
13:34:03 <Peaker> let x = 5 -- works,  x = 5 -- silently ignored
13:34:21 <geekosaur> interesting. might report it
13:34:40 <glguy> Peaker: See if there's a ticket, or add one. Seems like if let can work then it should be able to work without
13:36:04 <geekosaur> there are too many unexpected interactions between things. (some months back someone was trying to add unboxed tuple support to ghci and discovered a place in the runtime where it (a) knew ghci didn't create them, so (b) reused a function in such a way that it used an unboxed tuple in ghc and a boxed one in ghci, so if you added unboxed tuples to ghci then it had no idea whether what it was handed was boxed or not
13:36:18 <geekosaur> uuuuuugly...)
13:37:09 <Peaker> the GHC code is full of ugly kludges. At least the build system part is horrible
13:39:06 <nfd9001> eww
13:41:08 <geekosaur> they're working on the build system, at least
13:41:14 <geekosaur> think hadrian is finally slated for 8.4
13:41:27 <Tuplanolla> Now, compared to GCC...
13:42:01 <Welkin> hadrian?
13:42:18 <monochrom> Neato about :set +c. Also didn't know emacs haskell-mode already uses it. (haskell-mode-show-type-at, but by default not binded to a key so I didn't notice.)
13:42:58 <Unode> is there anything like a settings file where I could add a few things I'd like to have loaded/set on ghci by default?
13:43:02 <Welkin> what now about +c?
13:43:11 <Welkin> Unode: .ghci I think
13:43:22 <geekosaur> Unode, https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html#the-ghci-and-haskeline-files
13:43:37 <Unode> geekosaur: thanks
13:44:17 <monochrom> So now next time people ask "how to ask ghci for the type of a local thing?" I cannot say "can't". :)
13:44:44 <monochrom> Although, it would be cruel to tell them "you have to hand-enter the line number and the column number..." :)
13:45:28 <dolio> monochrom: That hard part is figuring out which column numbers to enter.
13:45:39 <dolio> The hard part, even.
13:45:42 <monochrom> But it does seem that C-c C-t is just using :type or equivalent, so no local types.
13:46:18 <monochrom> Yeah but it does looks like you have some leeway, i.e., you can try a wider interval and it will be OK.
13:46:32 <monochrom> But yeah recall that ghci's column numbers start from 0.
13:46:42 <monochrom> Err wait, no.
13:46:47 <dolio> monochrom: It seems very precise to me.
13:47:20 <monochrom> Well I have a "y = x * x", in which the "y" is (5,5)-(5,6)
13:47:24 <dolio> If you want the real answer, and not the 'default case' answer.
13:47:32 <monochrom> I entered :type-at 5 4 5 7 and it's OK.
13:48:10 <EvanR> positions in the buffer have a type? o_O
13:48:29 <monochrom> Yeah! Before a position refers to a subexpression.
13:48:42 <EvanR> hahaha
13:48:51 <monochrom> s/Before/Because/
13:49:14 <EvanR> which sub expression?
13:49:24 <monochrom> Although, :type-at doesn't come with contraints like Num, even if it's there. (My code is "f x = y + y where y = x*x"
13:49:41 <EvanR> the smallest one?
13:49:50 <EvanR> wouldnt that be the variable or operator...
13:50:04 <dolio> monochrom: Hmm, okay, it is more lenient than I thought.
13:50:16 <monochrom> Why don't you give it a try?
13:50:40 <geekosaur> Welkin, https://github.com/snowleopard/hadrian
13:50:45 <dolio> But if your end column is part of the expression you want, it won't work.
13:50:55 <dolio> It has to be the column after, at least.
13:51:08 <monochrom> Have a "y + y" somewhere but deliberately give an interval for "y +" only and see what happens. Personally I don't care about pathelogical inputs.
13:51:39 <monochrom> Yeah dolio that one is a GHC convention I'm familiar with.
13:51:46 <dolio> Ah, okay.
13:51:54 <monochrom> I think it has been that way since the dawn of GHC?
13:52:07 <geekosaur> well, I guess it will be merged in 8.4 but will probably not be fully functional and almost certainly not replacing the current system
13:52:46 <monochrom> At any rate when I did ":all-types" I see things like "(5,5)-(5,6)" for a single letter "y" so it's highly discoverable and learnable.
13:52:56 <dolio> monochrom: There's also :loc-at, which will give you the information to jump to local definitions.
13:53:24 <monochrom> Oh neat
13:54:51 <Welkin> so hadrian is meant to replace cabal?
13:55:22 <Welkin> oh, only for building ghc
13:55:45 <Welkin> I suppose it is a reference to the Hadrian of Hadrian's Wall
14:00:18 <AlainODea> Appropriate given the G in GHC is Glasgow
14:03:23 <geekosaur> ghc doesn't use cabal, it uses make
14:03:41 <geekosaur> or perhaps I should say it shamelessly and confusingly abuses make
14:09:16 <AlainODea> geekosaur: that summarizes it well.
14:10:06 <Athas> What is the biggest Haskell program that uses cabal?
14:10:53 <hpc> by what measure?
14:11:05 <EvanR> the greatest haskell program
14:11:07 <hpc> pandoc is probably the most popular
14:12:24 <AlainODea> Athas: something commercial probably. The school of haskell is a pretty large system when you factor in all of its dependencies. I think the commercial stuff has to be bigger SLOC-wise
14:12:26 <Athas> Lines of code.  I'm just curious whether cabal scales to something huge, I guess.
14:13:10 <AlainODea> cabal handles lens and yesod so it seems to scale well. Both have pretty elaborate dependencies
14:13:11 <Athas> Although the trend for factoring into smaller packages probably prevents the growth of million-line Haskell programs.
14:14:18 <danilo2> hexagoxel, monochrom, Tuplanolla : https://ghc.haskell.org/trac/ghc/ticket/14013#ticket
14:14:29 <geekosaur> LoC is probably not the best measure for this, unless you mean of .cabal files; number of dependencies counts for more
14:14:50 <Tuplanolla> Cool beans, danilo2.
14:15:30 <Tuplanolla> That's a hefty bunch of extensions though. Do you really need them all?
14:15:35 <danilo2> Tuplanolla: even cooler in rc3, hexagoxel: checked it out and the "bad" performance is a LOT worse than in 8.0.2
14:15:49 <monochrom> ooohhhh
14:16:22 <danilo2> Tuplanolla: No i do not need them (I told about it on the top of this ticket). Are they confusing? If so I will extract the code to separate project and test which one are important
14:16:54 <Welkin> anything that uses lens :P
14:17:02 <AlainODea> Athas: not sure what SLOC GHC can handle in a single package. I don't think it's limited, but I haven't tested it
14:17:03 <Tuplanolla> I always cut my tickets until nothing can be cut anymore, danilo2.
14:17:14 <Welkin> Tuplanolla: Zeno's paradox?
14:17:18 <EvanR> interesting, if youre used to programming a certain kind of haskell, you could just enable all the typical extensions and never look back
14:17:27 <Tuplanolla> Not a continuum, Welkin.
14:17:30 <EvanR> not knowing or caring which are being used
14:17:54 <EvanR> zeno works without a continuum 
14:18:26 <danilo2> Tuplanolla: well, ok, I'll do it now
14:20:10 <AlainODea> zeno's paradox ends with "whatever, ship it"
14:20:28 <hpc> @remember AlainODea zeno's paradox ends with "whatever, ship it"
14:20:28 <lambdabot> I will never forget.
14:21:09 <danilo2> Tuplanolla: oh well, it seems no extension is needed at all
14:21:29 <danilo2> Tuplanolla: youre right it will only confuse readers
14:22:19 <EvanR> haha
14:37:11 <monochrom> Yeah zeno just needs density.
14:38:35 <skiddieproof> Can someone give me a keyword to search about ':|' notation as used here : data Stream a = a :| Stream a
14:39:14 <monochrom> Is it OK if I point you to Haskell syntax reference?
14:39:23 <skiddieproof> please
14:39:39 <Tuplanolla> The keyword is "data constructor", skiddieproof.
14:39:40 <skiddieproof> I've never heard of it
14:39:52 <skiddieproof> Thanks
14:40:09 <danilo2> skiddieproof: it is NonEmpty list constructor :)
14:40:12 <EvanR> > let j = 0 :+ 1 in j**2
14:40:14 <lambdabot>  (-1.0) :+ 1.2246467991473532e-16
14:40:28 <EvanR> > let j = 0 :+ 1 in j**2 :: Complex Integer
14:40:30 <lambdabot>  error:
14:40:30 <lambdabot>      • No instance for (RealFloat Integer) arising from a use of ‘**’
14:40:30 <lambdabot>      • In the expression: j ** 2 :: Complex Integer
14:40:32 <EvanR> :(
14:40:36 <bollu> the ":" thing is a trick
14:40:48 <monochrom> https://www.haskell.org/onlinereport/haskell2010/haskellch4.html#x10-690004.2.1  and pay most attention to the "(infix conop)" line
14:40:55 <danilo2> skiddieproof: wait, no, its not, sorry. I was thinking it is not custom constructor definition
14:41:01 <bollu> ":" is considered a valid literal for data constructors so list sytax works IIRC
14:41:02 <monochrom> However, to see what conop means, you need to read Chapter 2.
14:41:41 <skiddieproof> Helpful as always, thanks!
14:42:10 <monochrom> Hrm I get interested. What's the difference between btype and atype?
14:43:23 <monochrom> Ah, btype is possibly juxtaposition.
15:08:47 * hackagebot loc-test 0.1.3.0 – Test-related utilities related to the /loc/ package. – https://hackage.haskell.org/package/loc-test
15:08:47 * hackagebot loc 0.1.3.0 – Types representing line and column positions and ranges in text files. – https://hackage.haskell.org/package/loc
15:32:21 <slack1256> Is anybody able to run qtah-examples on nixos?
15:33:11 <slack1256> I think qtah depends on qt's xcb module. It seems nixos doesn't ship with it (although it should). I don't know about qt internals to know this
15:34:26 <Welkin> is there any reasonable gui library on linux?
15:35:19 <hpc> would you believe "no"? :P
15:35:43 <slack1256> depends on what you mean by reasonable
15:35:45 <Welkin> or maybe, on any platform
15:36:01 <slack1256> old gtk2hs for me was reasonable
15:36:02 <Welkin> I haven't used the windows gui libs, or cocoa beyond iOS
15:36:11 <Welkin> it's very oop though
15:36:31 <Welkin> I have heard good things about imgui
15:37:29 <Welkin> using a web browser doesn't seem too bad, except for all the overhead
15:37:37 <Welkin> like electron
15:47:09 <EvanR> nw.js
15:47:25 <EvanR> so far its like toolkit nirvana
15:51:06 <Welkin> lol
15:51:10 <Welkin> don't search nwjs on youtube
15:51:28 <Welkin> supposedly it means something ghetto
15:51:53 <Welkin> and is also a fencing competition?
16:46:01 <chokboy> Hello, I'm having some trouble with type families and I was hoping to get an answer here of at least what I should be googling.
16:46:50 <chokboy> Instead of computing a concrete type, I'd like to compute a type with a constraint.
16:47:01 <chokboy> for instance, if we have:
16:47:10 <chokboy> type family Foo a :: * where
16:47:14 <chokboy>     Foo Int = Int
16:47:19 <chokboy> i'd like instead something like
16:47:28 <chokboy>     Foo Int = (Num a) => a
16:51:05 <chokboy> is this possible?
16:51:36 <lyxia> no
16:53:05 <lyxia> chokboy: How about newtype AnyNum = AnyNum (forall a. Num a => a), and then Foo Int = AnyNum
16:56:32 <mniip> chokboy, you might try something
16:56:36 <mniip> like
16:56:44 <andross> what is the correct way of doing something like `ReaderT (a, b, c) IO d` where b and c are actually parameters?
16:56:59 <mniip> type family Foo a b :: Constraint where Foo Int b = Num b
16:57:11 <andross> IO (a -> b -> d) doesn't make much sense
16:57:19 <mniip> and use (b ~ X) equality constraints with that
16:57:43 <mniip> andross, IIRC ReaderT is implemented as the exact opposite of that
16:57:52 <mniip> @unmtl ReaderT (a, b, c) IO d
16:57:52 <lambdabot> a -> b -> c -> IO d
16:58:42 <chokboy> lyxia: yes, i think i'm going to go with that. thank you
16:58:58 <andross> how can i avoid using this tuple?
16:59:22 <mniip> chokboy, do note that it you try to do (+) :: AnyNum -> AnyNum -> AnyNum you'll run into trouble
16:59:43 <mniip> as opposed to (Foo Int b) => b -> b -> b
17:01:45 <imPure> Is it possible to limit a rewrite rule so it only fires once?
17:02:30 <chokboy> mniip: ah, i see. thank you!
17:18:26 * hackagebot numhask 0.0.5 – A numeric prelude – https://hackage.haskell.org/package/numhask
17:23:07 <bbear> Hi
17:23:15 <bbear> do you know of a good reference book for Haskell ?
17:25:15 <MarcelineVQ> bbear: https://www.haskell.org/onlinereport/haskell2010/
17:30:20 <bbear> what is the difference between haskell2010 and the other stuff ? I would like to find the source eventually if it was possible.
17:30:40 <MarcelineVQ> which other stuff?
17:32:40 <MarcelineVQ> if you want to see source code of commonly used things you can go here  http://hackage.haskell.org/package/base  and look at the different modules, there's a link to the source on the top right of each module's page
17:34:27 <bbear> I mean this : https://www.haskell.org/onlinereport/haskell2010/ and that https://www.haskell.org/onlinereport/
17:34:33 <bbear> Nevermind I foudn it darcs get http://darcs.haskell.org/haskell2010-report
17:36:07 <bbear> darcs is slo
17:36:12 <MarcelineVQ> I'm not sure what all is different but some differences are mentioned here https://www.haskell.org/onlinereport/haskell2010/haskellli2.html#x3-5000
17:38:59 <bbear> I wanted an epub version but this is clearly a nogo the source is in Latex
17:39:02 <bbear> :(
17:39:09 <bbear> Don't want to spend too much time on this
17:39:12 <bbear> it's getting late.
17:41:13 <Welkin> bbear: there is something called pandoc
17:41:20 <Welkin> it converts between all kinds of formats
17:41:27 <Welkin> you can generate your own epub
17:42:01 <MarcelineVQ> pandoc's latext to epub isn't super, afaik, there's some chain of tools out there that can get it done though, latext to html to epub maybe with math rendered to images
17:42:23 <Welkin> epub is html
17:42:31 <Welkin> you can convert from latex to epub
17:42:51 <MarcelineVQ> yeah but last I checked pandoc leaves out latex math stuff
17:43:08 <MarcelineVQ> could be better now, dunno
17:43:22 <Welkin> another option is to render the latex to pdf
17:43:27 <Welkin> and just read that
17:44:40 <bbear> yes, but for an e-reader that is not great. I'll have to do some tweaking to use pandoc, indeed.
17:44:43 <bbear> Thanks for the tips.
17:45:07 <Welkin> pdf is fine if you have a large display with a high resolution
17:45:14 <Welkin> like an ipad air or pro
17:45:48 <MarcelineVQ> I turn the pdfs sideways to read on a reader, otherwise you're forever scrolling or squinting
17:46:11 <MarcelineVQ> *scrolling horizontally
17:46:34 <Welkin> not diagonally?
17:47:34 * hackagebot matrices 0.4.5 – native matrix based on vector – https://hackage.haskell.org/package/matrices
17:48:34 <Welkin> does anyone use cloud haskell?
17:48:48 <Welkin> or is it called distributed haskell now?
17:56:12 <Lokathor> what's the max number of thigns in a tuple?
17:56:14 <Lokathor> like 16?
17:56:36 <MarcelineVQ> 62
17:56:49 <Welkin> 63?
17:56:59 <MarcelineVQ> on paper anyway, I've not tried making a 62-tuple
18:00:24 <glguy> Welkin: yeah
18:01:16 <geekosaur> often there are no typeclass instances for n-uples where n > 15 though
18:01:22 <geekosaur> n-tuples
18:03:31 <glguy> testing in GHC 8.0.2 there doesn't seem to be an obvious limit
18:03:41 <MarcelineVQ> :t (1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
18:03:42 <lambdabot> error:
18:03:42 <lambdabot>     A 63-tuple is too large for GHC
18:03:42 <lambdabot>       (max size is 62)
18:04:03 <glguy> it can typecheck larger ones, however
18:04:46 <glguy> Oh, :info can process larger ones for some reason
18:05:03 <c_wraith> what's the max-size tuple that can be lifted with DataKinds?
18:05:21 <macrover> :t 1,1
18:05:22 <lambdabot> error: parse error on input ‘,’
18:05:38 <macrover> :t (1,1)
18:05:39 <lambdabot> (Num t, Num t1) => (t1, t)
18:08:37 * geekosaur wonders if anyone has tested the old core dump that led to that 62 limit, actuallt
18:12:08 <Wizek__> Anyone knows of a nice and simple website where I could put a markdown-formatted .lhs file which would show as rendered and syntax-highlighted html on one hand, while also keeping the original source file around so that anyone may execute it if they wish?
18:13:08 * hackagebot numhask 0.0.7 – A numeric prelude – https://hackage.haskell.org/package/numhask
18:13:09 * hackagebot numhask 0.0.6 – A numeric prelude – https://hackage.haskell.org/package/numhask
18:14:53 <mjolnir_> need your 2 cents
18:15:40 <mjolnir_> If you had the choice to learn haskell or scala first, what would you choose? Pros, cons
18:15:42 <imPure> I'd like to demote whether or not a constraint is matched, e.g. if constraint matches return True, otherwise return False. Is this possible?
18:15:55 <EvanR> great question for the haskell channel
18:15:57 <EvanR> haskell first
18:16:28 <mjolnir_> I'm asking it on the #scala and #haskell channels to get perspectives
18:16:42 <EvanR> i hope they say haskell first too :)
18:17:00 <parsnip> i'm writing python, but how would a Haskeller factor the following:
18:17:20 <imPure> mjolnir_1: http://hammerprinciple.com/therighttool/items/haskell/scala
18:17:29 <parsnip> i have a list of a, [a], and f :: a -> b, g :: b -> c, so...
18:17:57 <vagrant1> hello world
18:18:02 <vagrant1> hello
18:18:04 <parsnip> no wei
18:18:06 <EvanR> do you mean, you have 4 things, in that order
18:18:10 <imPure> Here's a good one: I WOULD RECOMMEND MOST PROGRAMMERS LEARN THIS LANGUAGE, REGARDLESS OF WHETHER THEY HAVE A SPECIFIC NEED FOR IT
18:18:10 <imPure> 85%  15%
18:18:13 <imPure> Haskell 57 out of 67 picked Haskell over Scala
18:18:33 <Axman6> can we quit the snark?
18:18:33 <parsnip> that's not a good onw
18:18:38 <parsnip> s/onw/one/
18:18:51 <Axman6> parsnip: what do you want to do with those functions?
18:19:20 <macrover> , arrays
18:19:28 <parsnip> i want to offer to the user the ease of deciding when to just do f, just do g, just do an element a, and element b, or a list of either
18:19:36 <mjolnir_> imPure great link
18:19:46 <parsnip> in python, that would be difficult to say, so i came here
18:20:15 <parsnip> s/and element/an element/
18:20:29 <EvanR> so you could express the choice with a sum type of 4 cases
18:20:36 <parsnip> whoa
18:20:45 <Axman6> (or more than 4)
18:21:03 <parsnip> haha, i hate that i can't just go with Haskell
18:21:22 <Axman6> I still don't quite understand what you want though
18:21:29 <mjolnir_> <imPure> What's the best haskell book you've read when you first started learning
18:21:40 <dolio> Yeah, what does "do f" mean?
18:22:03 <parsnip> basically, i'm taking csv bank format, massaging it, then converting to ledger format. i might want to do one file or more, and i might want to do both steps or one. 
18:22:06 <Axman6> there's very little "doing in Haskell
18:22:24 <parsnip> so that's a, [a], b, [b], f, g, or f and g. 
18:22:40 <parsnip> s/f and g/g . f/
18:22:50 <imPure> mjolnir_: I learned from Learn Yourself a Haskell.
18:23:20 <imPure> mjolnir_: However, others find it more difficult. https://wiki.haskell.org/Tutorials
18:23:41 <parsnip> LYAH is an excellent small first step
18:23:53 <mjolnir_> <imPure> someone recommended http://haskellbook.com/
18:23:57 <imPure> mjolnir_: We use Haskell where I work, and hire a lot of hardware engineers who have to learn Haskell. They tend to like that first tutorial.
18:24:21 <Lokathor> are there articles on how GHC lays out data in memory
18:24:55 <parsnip> how would a pythoner say describe my problem as concisely as i described it in haskell? 
18:25:03 <parsnip> s/say //
18:25:12 <imPure> mjolnir_: That's a good one... Learn from that one. Also check out this link: http://dev.stephendiehl.com/hask/
18:25:58 <Axman6> Stephen's page is fantastic, required reading once you've learned the basics imo (and then constantly referred to as you learn more)
18:26:35 <imPure> Lokathor: Not aware of one, but we shared this around the office recently: http://blog.ezyang.com/2011/05/anatomy-of-a-thunk-leak/
18:26:55 <Axman6> there's likely to be some info on the ghc trac wiki
18:27:21 <Lokathor> there's a person trying to claim that it's impossible to know how anything works in compiled haskell without absolute proof of it
18:27:21 <parsnip> seems like 6 cases
18:27:51 <Lokathor> for example, the docs say that a tuple is two pointers to heap objects, but that's somehow not proof enough
18:28:10 <Lokathor> i think that i should just avoid the crazy i guess
18:28:35 <mjolnir_> great resources, I'm gonna check them out. Thanks guys
18:28:56 <imPure> mjolnir_: No problem. Good luck.
18:29:01 <Lokathor> mjolnir_, avoid LYAH, use HaskellBook.com
18:29:07 <EvanR> impossible to know without proof... sounds kind of like flat earther speak
18:29:46 <Lokathor> their ultimate claim is that (,,) is an unnecessary type, and that it should be sugar for (,(,)) and so on for more tuple layers as well
18:29:57 <EvanR> that is how it is in idris
18:30:06 <imPure> Anyone here have experience with core plugins, rewrites, or template haskell? I'm trying to achieve something relatively simple and failing with the heavy tools...
18:30:07 <EvanR> a chain of boxes
18:30:14 <Axman6> Lokathor: a good rule of thumb is that there's a 1 Word header per heap object, plus one pointer for each non unpacked field and the siz of any packed fields
18:30:26 <Axman6> exact layout I'm not sure about though
18:30:29 <parsnip> 6 cases, f, g, g.f, and are they acting on a list
18:30:41 <Lokathor> ah, but then they claim that (,(,)) can be flattened by the compiler and the overhead removed because *handwave*
18:30:50 <EvanR> sure
18:30:55 <dolio> No, it can't.
18:30:57 <parsnip> or 3, pretend a single element is in a list
18:30:59 <EvanR> ?
18:31:03 <dolio> That is not a semantics-preserving transformation.
18:31:07 <Lokathor> exactly
18:31:48 <dolio> They don't need to read docs, they can just try it out in GHCi and figure out that those two things aren't isomorphic.
18:32:02 <EvanR> ok (9, ⊥) vs (9, , ) ... you can represent it
18:32:06 <EvanR> cannot
18:32:17 <imPure> It would be nice if we could require certain memory behaviors, e.g. like this person did with compute in Agda: https://www.twanvl.nl/blog/agda/sorting
18:34:57 <Lokathor> wait what's the actual difference between the former and the latter EvanR ?
18:35:14 <EvanR> the triple there isnt isnt well formed?
18:35:18 <EvanR> isnt even
18:35:56 <dolio> (a,(b,c)) has (x, ⊥) and (x, (⊥, ⊥)) but (a,b,c) only has (x, ⊥, ⊥).
18:35:57 <EvanR> you could say (9,⊥,⊥) is the same as (9, (⊥,⊥)) but theres no equivalent of (9, ⊥)
18:36:01 <parsnip> if there's a directory of type a, one of b, and one of c, how do i know which directory the user gave me? 
18:36:24 <EvanR> parsnip: are you trying to implement a variant in python?
18:37:17 <Lokathor> dolio, so converting to nested tuples adds in more possible bottoms?
18:37:24 <EvanR> you can use a tuple like ("tag1", v1) ("tag2", v2) etc
18:37:38 <dolio> Yes.
18:37:54 <parsnip> user will have original csv from bank in directory a. they can massage the data and result will be in directory b. then then will apply ledger conversion and have directory c. i want to clean up my script so i'm trying to think like haskell. 
18:38:20 <EvanR> im skeptical that variants will help you ... give your language
18:38:26 <parsnip> python
18:38:26 <EvanR> given*
18:38:31 <parsnip> oh
18:38:48 <parsnip> yeah, that's like, at IO level, or something
18:38:57 <EvanR> wwwwhaa?
18:39:04 <Axman6> well, the tools you'd use in Haskell don't exist in Python. I would start be using phantom types to label those directories if that's necessary
18:39:06 <dolio> If you don't want that to happen, you need a special tuple type that is strict in the argument you use for nesting.
18:39:11 <parsnip> i mean, why should haskell types care which directory it is
18:39:28 <Axman6> you can make haskell care, with pangtom types :)
18:39:35 <Axman6> phantom*
18:40:04 <dolio> But even then, there are disadvantages.
18:41:04 * hackagebot websockets 0.12.1.0 – A sensible and clean way to write WebSocket-capable servers in Haskell. – https://hackage.haskell.org/package/websockets
18:41:34 <dolio> I'm no expert, but I've heard ML doesn't even just nest tuples.
18:41:49 <dolio> a * b * c is not (a * b) * c nor a * (b * c).
18:42:17 <EvanR> BigCross(a, b, c)
18:42:27 <ReinH> See also the difference between strict and lazy writer
18:51:15 <parsnip> is there a prettier named triplate from the scientific, scifi, fantasy or programming community than `source`, `intermediate` and `sink`? 
18:51:33 <parsnip> *triplet
18:52:04 <Axman6> earth, wormhole, andromeda
18:59:42 <Welkin> andromeda?
18:59:46 <Welkin> what about the sombrero galaxy?
18:59:49 <Welkin> or the eagle galaxy?
19:00:29 <parsnip> and then the other problem is, a may be a list of files with overlapping dates, say in the filenames maybe, and they might just be converted 1-to-1 to the set of b, that is [a] -> [b], but then there may be some deduplication before [c]
19:00:34 <parsnip> argh
19:01:05 <parsnip> Welkin: i think that's outside of the scope of this text
19:01:52 <parsnip> frak, how do you maintain a set of csv bank records
19:02:24 <mniip> parsnip, mono- iso- and epi-?
19:02:25 <Welkin> oh
19:02:27 <Welkin> maybe those are nebula
19:02:37 <parsnip> and design their conversion in a sensible way, even assuming the underlying conversion tool will prevent deduplication
19:02:50 <Welkin> eagle nebula :P
19:02:58 <parsnip> maybe i really should convert this to haskell :)
19:03:58 <bbear> I love haskell
19:04:08 <Welkin> we all do
19:04:13 <Lokathor> parsnip, if you're suggesting reducing the amount of Python in the world by replacing it with Haskell
19:04:15 <Lokathor> then yes please
19:04:34 <bbear> actually haskell code is terser than python code
19:04:57 <parsnip> definitely
19:05:10 <parsnip> but haskell takes forever to build
19:05:41 <bbear> That's not really an issue, you can run code in ghci 
19:06:00 <parsnip> but dependencies still need to be there, no? 
19:06:01 <bbear> Build time -- oh yes, but then you can split your application in several modules, etc ?
19:06:16 <bbear> you can do dynamic linking as far I know.
19:06:48 <parsnip> i tried to build hledger-web on a small VPS, and it seemed like it was going to take half a day before i decided to copy it from local
19:07:24 <Welkin> you only get what, a single core and 512 mb ram?
19:07:26 <Welkin> that sucks
19:07:26 <c_wraith> parsnip: that usually comes from the system linker using too much memory
19:07:41 <Welkin> either build locally or use something comparable to your local machine
19:07:41 <bbear> that is probably a docker isolated environment.
19:07:46 <c_wraith> parsnip: systems that make gold the system linker can usually build haskell progrems in less memory far faster
19:07:59 <Lokathor> make gold?
19:08:18 <c_wraith> yes, you can set your system linker to be gold instead of ld
19:08:20 <parsnip> bbear: docker isolated? it's an EC2 nano
19:08:34 <parsnip> or micro or whatever
19:08:45 <Lokathor> c_wraith, what does that mean and how do i do that?
19:08:53 <Lokathor> like "gold" is the name of the program?
19:09:08 <bbear> ha okay
19:09:14 <geekosaur> possibly ld.gold
19:09:18 <AlainODea> intero makes it easy to do tight cycle TDD. Write a change, reload and run tests. It also integrates with GHCi to bring dependencies into scope. Initial compile can be slow, but a full build is rarely needed after the first during development. Haskell is a compile and deploy language, like C# or Java. It's not a interpret on the fly lang like Python or Ruby.
19:09:21 <c_wraith> Lokathor: gold is a reimplementation of ld that drops support for tons of esoteric platforms in exchange for being smaller and simpler (and using a lot less memory)
19:09:26 <bbear> still there's a lot of overhead in those things. Not really build machines.
19:09:33 <parsnip> ah, nice
19:09:52 <sproingie> where "esoteric" is anything not ELF
19:09:56 <parsnip> i do not need esoteric platforms, just ubuntu
19:10:06 <parsnip> and maybe macos
19:10:08 <sproingie> nothing against gold there, it's just very specific
19:10:18 <parsnip> but at least macos i don't reinstall very often
19:10:24 <c_wraith> Lokathor: making it the system linker varies depending on the system.
19:10:34 <Lokathor> hmm
19:10:51 <parsnip> so if i _do_ start using Docker, gold might speed up even there? 
19:11:07 <parsnip> i had to learn how to add an EBS as swap
19:11:08 <AlainODea> just change the ld in the settings file in the root of the GHC install to gold
19:11:14 <mniip> sproingie, if by "very specific" you mean can be used in 99.9% of the invocations... But I do very well understand that it isn't an appropriate replacement
19:11:40 <Welkin> typically, you don't want to compile on a server anyway
19:11:51 <Welkin> unless you have a decent build server
19:12:07 <Lokathor> AlainODea, where might that be on linux using stack?
19:12:09 <bbear> whatwhat is (<>) ?
19:12:15 <Welkin> bbear: mappend
19:12:19 <parsnip> bbear: or what is <>
19:12:37 <AlainODea> Lokathor: hmm. Probably /usr/local/lib/ghc-8.0.2/settings I think
19:12:54 <parsnip> bbear: () and `` are inverses of each other in haskell
19:13:03 <AlainODea> booting my VM to check.
19:13:03 <bbear> () ?
19:13:08 <parsnip> bbear: so 1 + 1 vs (+) 1 1
19:13:28 <parsnip> bbear: and map f [x] and f `map` [x]
19:13:28 <bbear> yes I know
19:13:31 <Welkin> wrapping an operator in () is a way of making it a prefix function
19:13:36 <bbear> but what is <> ?
19:13:41 <Welkin> wrapping a normal function in `` makes it an infix function
19:13:48 <Welkin> bbear: <> is mappend
19:13:55 <parsnip> what is standard way to find out, hoogle/ 
19:14:00 <bbear> why doing :t (<>) doesn't work ?
19:14:05 <bbear> :t (<>)
19:14:07 <lambdabot> Monoid m => m -> m -> m
19:14:15 <Welkin> you need to have Data.Monoid imported
19:14:19 <bbear> ye
19:14:50 <bbear> do you know of good uses for mappend ?
19:15:00 <sproingie> anything that uses a monoid
19:15:06 <Welkin> lol
19:15:11 <parsnip> @instances Monoid
19:15:14 <lambdabot> (), (S.Set a), (a -> b), (a, b), All, Alt f a, Any, Const a b, Dual a, IO a, Identity a, Maybe a, Ordering, Product a, Sum a
19:15:21 <Welkin> > "hello" <> " world"
19:15:23 <lambdabot>  "hello world"
19:15:41 <Welkin> > [1,2] <> [3,4]
19:15:44 <lambdabot>  [1,2,3,4]
19:15:44 <bbear> why isn't it better (or not) to use (++) ?
19:15:50 <sproingie> <> is more general
19:15:59 <sproingie> > Nothing <> Just 123
19:16:00 <parsnip> :t (++)
19:16:01 <Welkin> <> will work on anything with a Monoid instance
19:16:01 <lambdabot>  error:
19:16:01 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M877223150344...
19:16:01 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
19:16:02 <lambdabot> [a] -> [a] -> [a]
19:16:16 <hrumph> hi
19:16:31 <parsnip> was that telling me that ++ works when it is a list? 
19:16:42 <parsnip> so there are monoids that are not lists. strings are lists. 
19:17:05 <bbear> getProduct( Product 2 <> Product 3)
19:17:16 <hrumph> does IO in pure functional languages really make sense? The way I see it, for the IO monad, if the compiler decided to evaluate IO statements out of order then it would break the IO monad
19:17:41 <bbear> hrumph: the compiler doesn't do such things as far I know.
19:18:00 <mniip> hrumph, there's an important distinction between evaluating IO and executing it
19:18:02 <hrumph> therefore if you use the IO monad, the code you write is *not* a mathematical statement about what's going to happen
19:18:09 <mniip> compiler might do the former but not the latter
19:18:10 <Maxdamantus> the way IO is implemented in GHC is basically a hack that happens to work correctly.
19:18:25 <Maxdamantus> There is a perfectly sensible way of interpreting IO.
19:18:54 <mniip> uh, nothing in hrumph's question referenced the way IO is implemented in GHC
19:19:13 <Maxdamantus> Might just be the way I interpreted it.
19:19:23 <Maxdamantus> Because in GHC, IO operations are pretty much unapplied functions afaik
19:19:34 <Maxdamantus> which just take some sort of unit value.
19:19:39 <mniip> ehh
19:19:40 <mniip> kinda
19:19:41 <mniip> yes
19:20:11 <hrumph> mniip if you write "do {print "hello"; print "world"},    if print "world" were evaluated first then the output of the program would be worldhello
19:20:13 <Maxdamantus> but there's another way of modelling it, which doesn't rely on implementation details.
19:20:16 <sproingie> the model of IO or other impure data in pure functional programs is to see it passing a hidden "RealWorld" parameter around
19:20:21 <c_wraith> hrumph: the thing is, Haskell as a language (ignoring internal stuff and unsafePerformIO) has no means of actually doing anything with IO values
19:20:36 <mniip> hrumph, do you mean, let x = print "world" in x `seq` do print "hello"; x
19:20:38 <geekosaur> sproingie, that's the hack and it's ghc specific
19:20:43 <mniip> hrumph, then you are incorrect
19:20:45 <Welkin> hrumph: those are explicitly sequenced
19:21:13 <Welkin> a haskell program is one big expression
19:21:13 <sproingie> geekosaur: it still fits the concept of pure functional, so long as you accept the restriction that RealWorld is more or less a linear type
19:21:21 <parsnip> okay, i attempt to write haskell again
19:21:28 <Welkin> it doesn't matter when each part is reduced/evaluated
19:21:35 <dolio> sproingie: No, it doesn't.
19:21:38 <hrumph> the actual output is a side effect of evaluating print "world" so if the compiler decides it wants to do some bottum up evaluation then the output will be bad
19:21:55 <bbear> print "World" is not even a value
19:21:56 <mniip> hrumph, see above
19:22:02 <bbear> how would it be evaluated ?
19:22:14 <c_wraith> hrumph: there is no "actual output" at the Haskell level
19:22:14 <geekosaur> hrumph, you can think of IO in a pure program as being purely building chains of IO opcodes. these chains are sequenced by means of an implicit data dependency enforced by IO's Monad instance, and the resulting chains are the result of main. You can then think of the runtime as executing those chains, separately from the pure evaluation of your program
19:22:16 <bbear> :t print
19:22:17 <lambdabot> Show a => a -> IO ()
19:22:21 <mniip> hrumph, print "world" :: IO () doesn't output "world" when it's evaluated
19:22:31 <mniip> hrumph, but rather when it is executed as a part of the main :: IO () action
19:22:32 <c_wraith> hrumph: it's just an expression representing a (compound) IO action
19:23:27 <Maxdamantus> imo the `RealWorld` explanation isn't a very good one for describing how real programs might run on real systems.
19:23:35 <c_wraith> hrumph: this is the same as saying [1,2,3] is a single list of values rather than a magical mutable value that is sometimes 1, 2, or 3
19:23:48 <bbear> also x=do {print "foo"; print "bar"} is also equivalent to x=(print "foo">>print "bar")
19:24:06 <mniip> hrm
19:24:11 <mniip> we don't have an irc bot that can do IO
19:24:14 <mniip> :(
19:24:20 <Maxdamantus> The better explanation is simply that an `IO` operation represents an operation (eg "I want to print the string `world`") with a continuation (give me the result of that operation, and I'll give you another operation)
19:24:33 <bbear> :t (print "foo">>print "bar")
19:24:35 <lambdabot> IO ()
19:24:58 <Maxdamantus> So you can have an external system that keeps performing the currently represented operation, then passing it to the continuation to get the next IO operation.
19:25:14 <bbear> I think the chaining operator ensures that the operations are performed sequentially
19:25:25 <mniip> uh
19:25:31 <hrumph> geekosaur, ok that's interesting. i was probably wrong in my understanding of what was going on
19:25:33 <mniip> I think we flooded them with irrelevant information
19:25:58 <dolio> sproingie: Basically, `T -> (T, A)` is not a good enough type (regardless of T) to sensibly capture the semantics of `IO A` without adding effects to the semantics of functions, which is the thing we want to avoid.
19:26:13 <mniip> hrumph, the important thing is, IO doesn't execute when it is *evaluated*
19:26:16 <c_wraith> yes, everything about the implementation of IO was irrelevant.
19:26:19 <mniip> > getLine `seq` ()
19:26:21 <lambdabot>  ()
19:26:25 <c_wraith> The semantics are the important part
19:26:51 <hrumph> mniip yes i think ggekosaur explained it as best as it can be explained. the compiler is building a chain of operations
19:27:15 <hrumph> or not the compiler, the run time i guess
19:27:20 <Axman6> in haskell, you describe what you want an interpreter to execute
19:27:54 <sproingie> in any language you're doing that
19:28:03 <sproingie> the separation is just a little more explicit in haskell
19:29:26 <EvanR> im never really sure what im doing in other languages :)
19:29:39 <EvanR> its kind of a stream of consciousness
19:36:19 <AlainODea> Lokathor: sorry for the delay it's in /usr/lib/ghc/settings (you can set the ld command to /usr/bin/gold )
19:36:49 <c_wraith> you do have to make sure it's installed, too
19:36:52 <c_wraith> :)
19:38:15 <Lokathor> AlainODea, no such file
19:38:22 <Lokathor> i think stack stores GHC elsewhere
19:38:35 <Lokathor> c_wraith, gold is installed
19:38:36 <AlainODea> I think you're right. Let me retry
19:45:09 <AlainODea> Lokathor: ~/.stack/programs/x86_64-linux/ghc-8.0.2/lib/ghc-8.0.2/settings (or possibly another version of GHC if you're using a different resolver than lts-8.23)
19:46:16 <Lokathor> ("ld command", "/usr/bin/ld"), --> ("ld command", "/usr/bin/gold"),  ?
19:46:57 <AlainODea> Yes, assuming you have binutils-gold (or equivalent for your distro) installed
19:47:11 <Lokathor> there's another option down that says "ld is GNU ld"
19:47:16 <Lokathor> do i have to make that say NO now?
19:47:39 <AlainODea> I'm not sure.
19:48:41 <geekosaur> I think not, since it's supposed to be a drop-in replacement
19:49:00 <Lokathor> neat let's give it a try\
19:49:58 <Lokathor> hmm
19:50:07 <Lokathor> it's not finding ghc?
19:50:20 <Lokathor> it wants a nopie version of ghc
19:50:28 <Lokathor> i wonder if i messed something up here or there
19:51:42 <AlainODea> still using stack build? Let me try it here
19:52:03 <Lokathor> well it downloaded a version of GHC it likes and it's installing that now
19:52:43 <AlainODea> k :)
19:53:01 <AlainODea> Changing just the ld command as you described above worked for me.
19:54:56 <AlainODea> stack new my-project && cd my-project/ && stack --install-ghc build && vim ~/.stack/programs/x86_64-linux/ghc-8.0.2/lib/ghc-8.0.2/settings && stack clean && stack build # edit the settings file and save with ESC :wq
19:56:15 <Welkin> what is "gold"?
19:56:52 <AlainODea> gold is a alternative object linker for compiled code (an alternative to ld) often resulting in faster builds using less memory
19:57:16 <AlainODea> faster to build, not faster to run. Runtime speed is unaffected as far as I understand
20:00:28 <Lokathor> huh
20:00:46 <Lokathor> i think that DigitalOcean might have changed my effective cpu out from under me when i didn't notice?
20:01:05 <Lokathor> i'm trying to figure out what nopie ghc is compared to normal ghc, and it seems like maybe it's a cpu thing?
20:01:29 <Welkin> what is nopie?
20:01:46 <Lokathor> i have no actual idea
20:01:58 <Welkin> compiling on a server sucks unless you have pretty strong specs
20:02:13 <exio4> Lokathor: unrelated to what you said, you made me remember I have to pay for my vps :p 
20:02:25 <geekosaur> don't build as a position-independent executable
20:02:29 <Lokathor> yeah well the server has the strongest specs among my x64 linux machines (read as: it's my only x64 linux machine)
20:02:48 <Welkin> Lokathor: dual boot
20:02:57 <Lokathor> Welkin, ew gross, you turn off your computer?
20:03:08 <Welkin> I have multiple computers
20:03:15 <Lokathor> geekosaur, i dunno all I know is that stack started using it
20:03:30 <geekosaur> actually it's ubuntu and maybe a couple other linux distributions that started using it
20:03:47 <Lokathor> my droplet is debian something
20:03:56 <geekosaur> and this leads to link failures with ghc because it doesn't generate position independent code for executables
20:04:04 <geekosaur> with the correct relocations
20:04:24 <geekosaur> so the final link fails when the distribution has configured its ld for position independent executables
20:04:27 <Lokathor> good thing that stack picks the nopie version of ghc for me
20:05:27 <geekosaur> the ghc devs had to put out an emergency release that gave ld the right options to disable PIE linking, and then stack had to be updated to use that (and equivalent backports) release on platforms that needed it
20:06:18 * geekosaur also had a ghc settings file patch sitting around for a while in lpaste for people who were tripping over it, that hacked in the necessary options in the right places...
20:20:03 <Lokathor> oh dag
20:20:13 <Lokathor> also it's still compiling ;_;
20:20:30 <Lokathor> i could pay for more ram, but i'll just watch netflix longer during total recompiles instead
20:21:30 <danilo2> Hi! Does anybody know why (Vector.Unboxed.Vector Char).takeWhile is 30% slower than Data.Text.takeWhile? I thought that Vectors are just wrappers over pure arrays, but Text does it somehow better.
20:22:43 <Welkin> Text is not an array of characters
20:23:06 <Welkin> it has a more convoluted implementation
20:24:03 <Welkin> "a Text value is represented as packed UTF-16 data"
20:24:05 <danilo2> Welkin: if you look at the underlying implementation it uses Array of Word16. Of course it is not a simple array of characters, because it uses UTF16 as the model. However, comparing char by char should be faster when we know the constant offset between elements, so Unboxed Vector of Chars should win, shouldnt it ?
20:24:06 <Welkin> http://hackage.haskell.org/package/text-1.2.2.2/docs/Data-Text.html
20:24:14 <Lokathor> seems to build and run
20:24:24 <Lokathor> https://lokathor.com/ shows the hello world screen
20:24:43 <AlainODea> woot!
20:24:50 <AlainODea> I can load it here too
20:24:56 <Welkin> I don't see why it matters
20:25:01 <Welkin> 30% difference is nothing
20:25:23 <Lokathor> thiiiirty percent is nothing?
20:25:26 <Welkin> yes
20:25:29 <Lokathor> whew
20:25:44 <Welkin> anything less than order of magnitude makes no difference
20:25:53 <danilo2> Welkin: You don't see why it matters its 30% faster? I'm curious where it comes from. As a Haskeller I want to know how to write performant code and I want to know what is happening there
20:25:57 <Welkin> even 2 orders of mangitude
20:26:08 <AlainODea> Welkin: WAT? Facebook has a custom implementation of CString to get something like 5% memory efficiency improvement. 30% is outlandishly exciting
20:26:13 <Welkin> because the computer is fast
20:26:21 <Lokathor> "twice as fast doesn't matter" -welkin, 2017, the IRC user with unlimited CPU and RAM i guess
20:26:39 <Welkin> it depends on the context
20:26:40 <danilo2> Welkin: the computer is fast ? ugh
20:26:48 <Welkin> for what I write, performance is almost never a consideration
20:26:56 <systemfault> Same for me... (Web dev)
20:26:56 <boj> for what *you* write, heh
20:26:58 <danilo2> Ok, I'm just curious whats happening there. How is it done that it is much faster than unboxed Vectors
20:27:00 <Welkin> because it doesn't matter
20:27:08 <Lokathor> Welkin, games programmers will murder you in your sleep for even 5% gains :3
20:27:12 <Welkin> yes
20:27:21 <Welkin> game programmers love to talk about these things
20:27:29 <Welkin> in web programming, we don't care
20:27:41 <Lokathor> save the planet pal
20:27:41 <boj> "just throw another dozen servers at it"
20:27:43 <AlainODea> It means 30% more CPU time spent on making $$
20:27:45 <Lokathor> use less electro
20:28:21 <boj> i worked on social games with 500k+ daily active users. it was basically web programming. we definitely cared about 30% performance :p
20:28:21 <mniip> Welkin, errr?
20:28:32 <mniip> what about reducing page load time from 1.3ms to 1.1ms
20:28:54 <Welkin> mniip: page load time, yes, but 1 ms? only in your dreams
20:29:09 <Welkin> we'll be happy to get anything close to 2 seconds
20:29:29 <boj> 2 second?!
20:29:29 <Welkin> the network is so damn slow
20:29:37 <AlainODea> reducing page load time from 1 second to 700ms puts it in the realm of near instantaneous and can dramatically boost conversion rates if it's a consumer-facing marketing or ecommerce site
20:29:42 <Welkin> that it makes other optimizations pretty pointless
20:30:03 <danilo2> Guys, by the way, does anybody know where it comes from? :D 
20:30:29 <Welkin> saving 100 ms on your server but then having a 2 second page load time makes little to no difference
20:30:50 <danilo2> Welkin .... 100ms is not 30% of 2seconds
20:30:55 <danilo2> as far as I know
20:30:58 <danilo2> :P
20:31:05 <Welkin> danilo2: those are not the same operation
20:31:14 <Welkin> the 2 seconds is the network
20:31:25 <boj> maybe Welkin is from a country on 2g networks so is pretty jaded to the whole thing
20:31:40 <danilo2> But not everybody is web developer. I do not have "web overlay here" and for me 30% is real 30% 
20:31:54 <Welkin> bo`no, in the US
20:32:00 <Welkin> which doesn't have great internet anyway
20:32:04 <pacak> 30% that's a lot.
20:32:30 <pacak> Even 3% is nothing to ignore.
20:32:48 <danilo2> It's funny to discuss if 30% is a lot or not, but in fact I'm much more interested in a fact where it comes from :P Does anybody have any clue / idea ?
20:32:55 <ByronJohnson> Welkin: What does?
20:33:10 <pacak> danilo2: do some profiling
20:33:34 * pacak is kind of happy with internets in Singapore
20:34:02 <danilo2> pacak: I did, I put these two functions in criterion and get those results. I can compile them down with +RTS -p and see whats going on really under the hood, but the chance that somebody did it befora are rather big
20:35:26 <pacak> criterion will give you only absolute numbers which is nice when you compare different optimizations but it won't tell where difference comes from. +RTS -p will help to figure out later.
20:35:37 <Welkin> it also doesn't matter if you have external systems you rely on that are slow as hell
20:35:58 <Welkin> there is only so much under your control on the web, at least
20:36:13 <danilo2> pacak: definitely. I prefer to ask sometimes before digging so deep, because there is high propability somebody did it before and know the answer
20:36:37 <pacak> danilo2: This way you'll never learn to dig...
20:37:18 <danilo2> pacak: I'm not trying to learn to dig, rather I'm trying not to spent next 3 hours doing it if somebody knows the answer :)
20:37:29 <Welkin> pacak: your name reminds me of pacal, the incan ruler
20:37:52 <AlainODea> a small part of practical systems where performance matters is interactive. The interesting performance stuff is within the walls of your DC or VPC where you have reliable low-latency networks
20:38:01 <Welkin> oh, I meant mayan
20:39:34 <pacak> Welkin: :)
20:39:46 <geekosaur> danilo2, fwiw I think Text can use a specifically optimized takeWhile, but unboxed Vectors would have to rely on RULES firing in the right places to avoid intermediates?
20:40:06 <boj> danilo2: glancing a the implentations, they seem similar. Text has rewrite rules which allow for fusion it seems, so maybe that is the difference?
20:41:17 <danilo2> geekosaur, boj: that would be very interesting, however both Text as well as Vector have takeWhile functions, they both seem to be optimized for that. If Vector does it worse, that is a very interesting case
20:42:59 <geekosaur> Text always knows the underlying type is UTF16. Vector has to at minimum indirect through a typeclass, which is why it would need RULES to optimize
20:43:54 <danilo2> geekosaur: hmm, do you think that even if Vector is a data family and it has newtype instance for Vector Char, its type class would not be inlined in a phase before firing these rules? 
20:44:15 <geekosaur> it might be, it might not. that's kinda the problem
20:44:25 <danilo2> geekosaur: this is insanely interesting for me, because it shows that we cannot still make haskell polymorphic when caring about the speed
20:44:25 <geekosaur> this stuff has proved to be tricky in the past
20:45:06 <danilo2> geekosaur: very interesting. Cool, thanks for these insights. I'll try to dig deeper, however this fact is something to remember when dealing with text
20:45:28 <dolio> What did you benchmark?
20:46:33 <geekosaur> well. someone who is motivated enough can overhaul RULES, and maybe upstream the result. Text has had multiple rounds of that, maybe unboxed Vector needs another pass
20:49:11 * hackagebot chart-unit 0.4.1 – Native haskell charts. – https://hackage.haskell.org/package/chart-unit
20:49:11 * hackagebot numhask-range 0.0.4 – Numbers that are range representations – https://hackage.haskell.org/package/numhask-range
20:49:32 <danilo2> dolio: I've generated sequence of 10^7 chars 'a' as a Text and as Unboxed Vector of Chars and used takeWhile (=='a') from both packages
20:49:55 <danilo2> dolio: (of course the generaiton was done prior to time measurments as a criternion env)
20:50:00 <dolio> Okay.
20:50:14 <dolio> I think the answer is the fusion for text is better.
20:50:59 <dolio> vector will always build a new array, but text will just slice the existing array.
20:51:17 <danilo2> dolio: nope, vectors have slices too
20:51:25 <danilo2> dolio: they are O(1) without any mem cpy
20:51:43 <dolio> You didn't use slice.
20:51:46 <dolio> You used takeWhile.
20:52:01 <dolio> vector takeWhile rewrites into streaming takeWhile into a new array.
20:52:04 <danilo2> dolio, geekosaur , moreover, what fusion could take place here? takeWhile just compares every element and shifts to the next one. There is nothing to be fused, am I wrong ?
20:52:18 <danilo2> dolio: oh really? 
20:52:22 <dolio> text takeWhile rewrites into streaming takeWhile, then rewrites back into a loop.
20:52:47 <dolio> Well, actually vector doesn't rewrite into that, that's how takeWhile is defined.
20:54:16 <danilo2> dolio: yeah, even the docs mention it: `O(n) Yield the longest prefix of elements satisfying the predicate without copying.` in fact I dont thing rewriting would take 30% of the computations
20:56:17 * hackagebot perf 0.1.2 – low-level performance statistics – https://hackage.haskell.org/package/perf
20:56:17 * hackagebot perf 0.1.1 – low-level performance statistics – https://hackage.haskell.org/package/perf
20:56:53 <danilo2> dolio, geekosaur : thanks for clarification. I'm still super curious about this topic, but you put some important light on it, thank you! :)
21:00:30 <ReinH> Data.Vector.takeWhile is Data.Vector.Generic.takeWhile, which is Data.Vector.Fusion.Bundle.takeWhile inside a unstream/streamm convolution, which is Data.Vector.Fusion.Bundle.Monadic.takeWhile, which is Data.Vector.Fusion.Bundle.Monadic.takeWhileM (return . f), which is Data.Vector.Fusion.Stream.Monadic.takeWhileM with some extra bookkeeping, which is implemented in terms of Stream and Step, which...
21:02:11 <dolio> Yeah, exactly.
21:03:06 <dolio> Anyhow, it's kind of a tradeoff, because text will keep your 10^7 characters worth of memory resident even if only the first character is 'a'.
21:03:50 <dolio> But in this case `takeWhile (=='a')` is the identity, so it's optimal.
21:04:04 <dolio> And vector does the worst possible thing you could do.
21:04:49 <dolio> And vector's representation is also larger.
21:05:02 <dolio> By 100%, I think.
21:05:13 <geekosaur> isn't this about unboxed vectors though?
21:05:45 <dolio> Yeah, so it's going to use 4 bytes per character instead of 2. Or maybe 3 bytes, I don't know.
21:09:15 <systemfault> How difficult is it to go from "State" to "ST" if I ever need? I started writing a CPU emulator.
21:10:09 <ReinH> ST isn't a direct replacement for State.
21:10:42 <systemfault> So it wouldn't be trivial.
21:11:05 <ReinH> No, you would have to write things for ST
21:11:21 <ReinH> State and ST are different monads.
21:11:22 <dolio> Yeah, 4 bytes.
21:12:18 <danilo2> dolio: sure, it will take more memory but if in this particuallar code I care much more about performance than about memory, I'd logically prefer to use unboxed vectors of chars over anything slower
21:12:29 <Cale> However, if you want to write some code which could work in both State and ST, it's possible to do that by just taking "get" and "put" as parameters, and writing the code in an arbitrary monad
21:12:58 <Cale> You can then supply readSTRef r and writeSTRef r in the case of ST.
21:13:23 <systemfault> Cale: I'm still a beginner... I understand State well at this point but have never used ST...
21:13:48 <systemfault> Thought it would be nicer to write my emulator in a pure way at first...
21:14:07 <systemfault> But if passing from State to ST requires a rewrite... I might go directly with ST
21:14:21 <Eduard_Munteanu> If you're using things like arrays or vectors, since they've been mentioned earlier, you probably want to rewrite those using ST equivalents to get true mutability.
21:14:31 <parsnip> Cale: you gave them to me before, and i have them as single images, but do you or the internet maintain copies of the fold, mapaccuml, etc diagrams you made? 
21:14:49 <ReinH> Some are on wikipedia.
21:15:07 <parsnip> Cale: maybe if thos can be linked from somewhere like a haskell or wikipedia site. 
21:15:50 <parsnip> ah, i found the smaller ones and big one in my dropbox
21:15:54 <Cale> parsnip: I usually have them on my webserver, but that's down at the moment... I really need to RMA this motherboard.
21:16:32 <parsnip> return merchandise? 
21:17:32 * hackagebot doctest 0.11.4 – Test interactive Haskell examples – https://hackage.haskell.org/package/doctest
21:17:40 <parsnip> http://imgur.com/HrhnpYK
21:20:16 <Cale> parsnip: Yeah, machine won't POST at all. I tested the powersupply, and it seems to be generating the correct voltages.
21:21:30 <Welkin> a thunderstorm is brewing here
21:21:52 <Welkin> saw the lightning, then a few seconds later, a boom that sounded like a bomb went off
21:22:01 <parsnip> ~ 3 miles
21:22:18 <Welkin> when it is really close, the whole building shakes
21:22:39 <parsnip> i prefer paper towels
21:23:18 <Welkin> doesn't venus have crazy lightning storms?
21:23:26 <Welkin> or is that jupiter?
21:23:57 <parsnip> is pointing out how big the big bang was just trolling? 
21:30:47 <MarcelineVQ> how big was it?
21:33:48 * hackagebot eliminators 0.2 – Dependently typed elimination functions using singletons – https://hackage.haskell.org/package/eliminators
21:33:48 * hackagebot yesod-static 1.5.3.1 – Static file serving subsite for Yesod Web Framework. – https://hackage.haskell.org/package/yesod-static
21:36:28 <parsnip> MarcelineVQ: contrary to popular belief, it was actually pretty small, but the rate of expansion or the amount of energy or something was pretty small. it was probably bigger than an explosion in Hollywood. 
21:37:00 <parsnip> *but the .. was pretty big
21:37:41 <Welkin> there was no bang
21:37:55 <Welkin> because there was no universe until after the big bang
21:38:37 <MarcelineVQ> after?
21:38:47 <Welkin> yes
21:38:57 <Welkin> it was the birth of the universe
21:39:08 <MarcelineVQ> Why do people talk about the big bang with a tense?
21:39:16 <parsnip> Welkin: was it instantaneous? 
21:39:24 <parsnip> MarcelineVQ: ha
21:39:37 <Welkin> MarcelineVQ: because it was the beginning of time
21:39:48 <parsnip> "it was"
21:40:13 <parsnip> Welkin: 21:38 <parsnip> Welkin: was it instantaneous?
21:40:25 <parsnip> damnit, cleared the text, need to unbind that
21:40:59 <parsnip> second bigeest annoyance after accidental pastes
21:41:00 <geekosaur> one could argue it is ongoing and we are part of it...
21:41:03 <Welkin> it was not instantaneous because of the speed of light
21:41:27 <parsnip> Welkin: oh, you've made my trolling job harder
21:41:46 <parsnip> Welkin: okay, within the cone...
21:41:58 <parsnip> are you saying it is instantaneous
21:42:42 <parsnip> geekosaur: yes, that was clearly suggested above, but now we have to trap Welkin into admiting that. 
21:46:40 <danilo2> I know this might be a very naive question, but what are the pros / conses when thinking about (pkg primitive) Data.Primitive.ByteArray vs (pkg array) Data.Array.Unboxed ?
21:56:29 <losthaskeller> Hey people. Any nix users around?
21:56:34 <losthaskeller> I'm having trouble building a library that depends on the `assert` package
21:57:25 <losthaskeller> Nix parser complains: error: syntax error, unexpected ASSERT, expecting '}'
21:57:39 <losthaskeller> Seems like assert is a special nix keyword
21:57:41 <losthaskeller> Any thoughts?
22:06:51 <rowmal> j
22:10:26 <danilo2> Hi! Does anybody know what is the corelation between Data.Array and Data.Primitive.Array? They both use GHC's Array# under the hood. Interesting fact: Data.Vector uses Primitive.Array, while Data.Text uses Data.Array. 
22:18:24 * hackagebot online 0.2.0 – online statistics – https://hackage.haskell.org/package/online
22:23:45 <mniip> is it possible to tell cabal where the shared libraries can be found?
22:24:02 <glguy> --extra-lib-dirs ?
22:32:52 <glguy> GHC 8.2.1's out https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/8.2.1-notes.html
22:42:27 <osa1> wooo \o/
22:43:09 <osa1> "SCC annotations can now be used for declarations." nice! I'd forgotten about this!
22:47:00 <osa1> hmm I wonder if -XMultiWayIf layout rule bug is included, I can't see it in the release notes
22:47:06 <osa1> (I should just download and try)
22:50:22 <cocreature> oh nice AppendSymbol
22:50:38 <cocreature> I wanted that a few times
22:54:15 <mniip> weird
22:54:26 <mniip> cabal produces libraries like libHSprimitive-0.6.2.0-3LLl5mgvnzmG5e6Ritz9w7-ghc8.3.20170629.so
22:54:33 <mniip> but expects libraries like libHSprimitive-0.6.2.0-3LLl5mgvnzmG5e6Ritz9w7.so
22:54:51 <mniip> is there something I'm doing wrong?
22:57:44 <osa1> nice, MultiWayIf layout rule bug fix is included. I feel like I'm the only user of this feature :p
22:57:51 <cocreature> mniip: maybe you need a newer version of cabal?
22:58:04 <mniip> 2.0.0.0
22:58:08 <mniip> can't get newer than this
22:59:57 <cocreature> well you are using an unreleased version of GHC so an unreleased version of cabal does not seem that absurd :)
23:00:22 <mniip> 2.0.0.0 *is* that unreleased version of cabal
23:00:42 <cocreature> nope 2.1.0.0 is the master branch
23:01:52 <cocreature> anyway I’m not being helpful here, sorry
23:04:35 <osa1> hmm `set promp2` in my .ghci no longer works, I'm wondering if this is expected or a bug
23:04:40 <osa1> prompt2*
23:04:53 <osa1> (with ghc-8.2.1)
23:04:55 <mniip> oh huh
23:04:56 <glguy> osa1: There seemed to be a new setting
23:05:10 <mniip> cocreature, well the one submoduled from ghc head is 2.0.0.0
23:05:19 <glguy> prompt prompt-cont-function prompt-cont prompt-function
23:05:19 <osa1> hmm OK, can't see it in notes
23:05:47 <cocreature> osa1: https://phabricator.haskell.org/D2084 seems like it is probably responsible
23:06:23 <cocreature> apparently prompt-cont is now the new option
23:07:03 <osa1> right, thanks. relevant manual chapter: https://downloads.haskell.org/~ghc/8.2.1/docs/html/users_guide/ghci.html#ghci-cmd-:set prompt-cont
23:08:04 <cocreature> and my ghc 8.2.1 build is finished \o/
23:17:16 <jle`> \o/
23:24:45 <jle`> whoa is pattern synonym exhaustiveness checking in ghc 8.2
23:25:29 <cocreature> I think so
23:26:18 <cocreature> nice I build my 8.2 with lld support enabled by default and it seems to help a lot when linking the tests in llvm-hs
23:28:03 <mniip> hmm
23:28:16 <mniip> that feeling when it worked just right
23:28:19 <mniip> and then it breaks so bad
23:58:11 <osa1> anyone know why this fails http://lpaste.net/357152 but `instance Functor Identity where fmap f = coerce f` works?
