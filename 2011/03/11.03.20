00:00:08 <NemesisD> Saizan: /usr/lib/ghc-7.0.2/package.conf.d\n/home/michael/.ghc.x86_64-linux-7.0.2/package.conf.d\naeson-0.1.0.0
00:00:20 <NemesisD> bingo
00:00:32 <NemesisD> what should i be using? i just installed today
00:00:51 <Saizan> try cabal update && cabal install aeson
00:01:13 <Saizan> it should pick the newest version, unless there's a "preference" for the older in the package index
00:01:42 <NemesisD> ah
00:01:47 <NemesisD> yeah i didn't even know i had ghc 7
00:01:53 <NemesisD> rolling-updated
00:01:58 <Saizan> "cabal update" refreshes the index of available packages
00:02:34 <lispy> Currently only about 4 packages show up in the preference that Saizan mentioned.  naeson isn't one of them
00:03:11 <Saizan> it's aeson :)
00:03:12 <lispy> oh, I can't read.  aeson still isn't in there
00:03:19 <lispy> I read \n literally
00:05:39 <NemesisD> Saizan: hmm, is the example on the docs shorthand? http://hackage.haskell.org/packages/archive/aeson/0.3.1.1/doc/html/Data-Aeson.html#t:FromJSON the string keys are supposed to be Text i think...
00:06:14 <NemesisD> erm by shorthand i mean not to be taken literally
00:06:17 <Saizan> maybe it's using the OverloadedString extension
00:07:11 <Saizan> which desugars string literals "foo" to fromString ("foo" :: String)
00:07:43 <malosh> Hi. I know how to profile an executable using the profiling versions of the libraries, but how to profile the library itself ?
00:08:37 <NemesisD> ahh you're right
00:09:00 <Saizan> you've to recompile the library with -auto-all in ghc-prof-options: to get cost centres about it
00:09:06 <malosh> ok thanks
00:31:41 <NemesisD> i would be super helpful if aeson had even a single example of parsing string -> FromJSON type
00:35:09 <Saizan> you're supposed to use the json parser with attoparsec, it seems
00:37:03 <Saizan> well, to get a Value
00:39:46 <Xilon> Saizan: Hmm can't see why attoparsec would be involed. Result is a custom aeson type, not the attoparsec one
00:40:59 <Saizan> Xilon: there are 2 Parser types involved here, one is about extracting things from Value, which will give you a Result with fromJSON
00:41:21 <Saizan> Xilon: the other is the type of "json" which produces a Value out of text
00:43:01 <Xilon> Saizan: ah, indeed
00:43:21 <NemesisD> it seems to provide fromJSON but i can't get the types to work out
00:45:11 <Xilon> You'd need attoparsec's 'parse', using the 'json' parser. Then use the resulting Value for fromJSON
00:49:28 <Saizan> sigh, a new type for just Either String feels just bothersome
00:51:30 <NemesisD> Xilon: i think i'm starting to understand but the types don't quite match up, parse json jsonstring returns a Data.Attoparsec.Internal.Result, not a Value
00:52:07 <Xilon> Indeed
00:53:04 <Xilon> NemesisD: you can pattern match to get the result, or just use maybe/eitherResult
00:58:45 <ski>   data Tree a = Tip
00:58:52 <ski>               | Node (Tree a) a (Tree a)
01:00:07 <ski>   data d Tree a / d a * da = InLeft  (d Tree a / d a * da) a (Tree a)
01:00:11 <ski>                            | InElem  (Tree a) da (Tree a)
01:00:14 <ski>                            | InRight (Tree a) a (d Tree a / d a * da)
01:00:56 <ski> where `d Tree a / d a * da' would be written as something like `DTree a da' in actual Haskell syntax
01:01:59 <NemesisD> oh my! no compile errors
01:02:40 <ski> `DTree a da' represents a `Tree a', where one of the `a' elements has been replaced by a `da' value (e.g. `()' (so a context) or `a' (so a zipper) or `d a / d b * db' which means that some `b' inside this particular `a' has been replaced by `db')
01:04:17 <ski> cf. with `\v v0 -> d f(v) / d v * v0' having type `|R^m >-> (|R^m >-lin-> |R^n)' when `f : |R^m >-> |R^n'
01:06:10 <ski> so, if you have a `Folder f' type representing a "file system" of normal "files" of type `f', and `Workspace w' represents a workspace with windows of type `w'
01:07:09 <ski> then a workspace with a window in focus is `let w = Window in d Workspace w / d w * Window'
01:07:49 <ski> which is the same as `DWorkspace Window Window'
01:08:43 <ski> and a folder system with a workspace in focus, with a window in focus is `let f = Workspace in d Folder f / d f * let w = Window in d Workspace w / d w * Window'
01:09:08 <ski> s/f = Workspace/f = Workspace Window'
01:09:24 <ski> which is the same as `DFolder (Workspace Window) (DWorkspace Window Window)'
01:09:30 <jonkri> which is like the superior darcs integration to emacs? :)
01:09:56 <ski> (and the last `Window' here could be replaced by something that also expresses a focus *within* that window)
01:10:14 <ski> jonkri : hm, how do you mean ?
01:11:25 * ski hasn't tried to interact with darcs in emacs, so don't know how that works ..
01:11:43 <jonkri> ski, i see that there are some options available, and i would like to know if someone can recommend one over the other
01:11:59 <jonkri> s
01:12:04 <Saizan> you wouldn't use "d Tree a / d a * a" as a zipper directly though, because the 'da' is as deeply nested as in Tree a, right?
01:12:43 <ski> Saizan : yea, i was only talking up to isomorphism above. in practice, you would probably want to invert most of the structure, for efficient local access and movement
01:13:14 <ski> the insight i got though was to add a second linear parameter for `DFoo', as compared to `Foo'
01:13:36 <ski> so that we can differentiate over several layers of separately specified collections
01:14:17 <ski> i.e. the marked element might not be element we're really interested in; it can be another kind of collection, where we are marking something inside that
01:14:48 <ski> and then how this compares to `f : |R^m >-> |R^n |- \Nabla f : |R^m >-> (|R^m >-lin-> |R^n)'
01:15:23 <NemesisD> odd attoparsec error: "failed reading: satisfyWith"
01:15:48 * Saizan is not familiar with \Nabla
01:15:50 <ski> or, if you prefer : if `\Gamma , v : |R^m |- e : |R^n', then `\Gamma , v : |R^m |- d e / d v : |R^n <-lin-< |R^m'
01:16:13 <jonkri> is there a way to call handshake' in the case, avoiding an extra variable: "t <- handshake' h s; case t of"
01:16:34 <Saizan> jonkri: no
01:16:59 <jonkri> ok :)
01:18:16 <ski> Saizan : <http://en.wikipedia.org/wiki/Del>,<http://en.wikipedia.org/wiki/Gradient>,<http://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant>
01:18:36 <ski> Saizan : i probable should have written `\Del' or something, but i couldn't recall that name atm
01:18:58 <Saizan> ski: thanks
01:19:21 <ski> Saizan : that it, it is only an accident that `f : |R >-> |R |- D f : |R >-> |R' is more or less right
01:19:24 * Saizan never managed to get a good intuition for what dx was
01:19:51 <Saizan> ski: oh
01:19:58 <Saizan> ski: this sounds quite interesting
01:20:26 <ski> Saizan : in general (at least with `|R^n' spaces, for natural numbers `n') when you use `D' / `\Del' / `\Gradient', you don't get that `D f' has the same type as `f'
01:22:08 <ski> if `f' is an "analytical" function from an `m'-dimensional euclidean space to an `m'-dimensional euclidean space, then `D f' / `\Del f' will be an analytical function from the `m'-dimensional space to the space of *linear* functions from the `m'-dimensional vector space to the `n'-dimensional vector space
01:22:31 <ski> and application of a linear function corresponds to multiplying with that argument (i.e. a vector)
01:23:23 <NemesisD> weee, it parses! thanks for the help everyone, i can sleep at last
01:24:52 <Saizan> ski: ah, so * in d Tree a / d a * a is this matrix multiplication?
01:25:02 <ski> in physics, you can see this as : consider a function `f' from `Horizontal position' to `Altitude', then `D f' is not a function from `Horizontal position' to `Altitude', but instead a function from `Horizontal position' to a *linear* function from `Horizontal position (differences)' to `Altitude'
01:26:06 <ski> Saizan : so `f' is an altitude map, and when you differentiate it, you get something that both wants the point to measure the slope in *and* a vector (i.e. `Horizontal position (difference)') which measures in which direction from this point you want to measure the slope
01:26:38 <ski> usually this vector is normalized, so has length one (relative to some unit), but it could be any vector, including the zero vector
01:27:21 <ski> Saizan : yes i think `*' in `d Tree a / d a * da' corresponds to multiplying the matrix with the vector
01:27:55 <ski> of course, `da' here is just an ordinary type/number, i just named it `da' for suggestive reasons
01:28:27 <ski> making sense of the `d Tree a' and `d a' in `d Tree a' and `d a' is harder .. i'm not yet sure of the right way to think of this
01:30:01 <ski> (though SDG (Synthetic Differential Geometry, see the book by Anders Kock, and i think Lawvere has some papers) may be useful to make sense of this .. SDG uses intuitionistic logic together with a subspace of `|R' : `|D = {x : |R | x^2 = 0}' which is not provably the same as `{0}' to be able to reason about "differentials")
01:31:19 <ski> Saizan : in any case, i generally treat `d ..x.. / d x' as a macro for `D (\x |-> ..x..) x' (or  (\x |-> ..x..)' x  if you prefer)
01:32:13 <Saizan> ski: yeah, me too, but sometimes you see people doing algebraic manipluations with 'dx' that always feels weird
01:32:29 <Saizan> ski: though i guess in SDG that'd be normal
01:32:47 <opqdonut> mostly its just shorthand for switching variables
01:32:54 <Saizan> (except you can't divide by dx)
01:33:37 <ski> so `d ..x.. / d x' *rebinds* `x' in `..x..' : note that `let y = ..x.. in d ..x..y.. / d x' is in general not the same as `d (let y = ..x.. in ..x..y..) / d x' -- this is the difference between "partial derivative" and "total derivative"
01:33:41 <opqdonut> but "naked" differentials are very useful in analysis
01:33:59 <Saizan> if we take * (the kind) instead of |R, what would be |D ?
01:35:05 <ski> i'm not quite sure .. but sigfpe (aka dpiponi) had an idea about a type `D' such that `D * D' is isomorphic to `0' (but `D' itself isn't)
01:35:34 <opqdonut> don't you mean D . D?
01:35:36 <ski> so, assume first we use some kind of linear type system, where we can express that some variables are to be used exactly once
01:35:49 <ski> (`D * D' in Haskell being `(D,D)')
01:35:50 <opqdonut> ah, different
01:36:06 <ski> opqdonut : yeah, this was re the `|D' type in SDG
01:36:20 <opqdonut> (the usual requirement for the d operator in differential geometry is d.d = const 0
01:36:45 <ski> now, we add the extra spice that not only are we going to use values of `D' as resources that can (well, *must*) be used exactly once
01:37:03 <ski> opqdonut : hm, that might be related somehow .. ty
01:37:23 <ski> not only that, but we also only have a limited stock of values in `D' to begin with
01:37:41 <ski> as opposed as to us being able to use `Zero' in `Nat' as many times we like
01:37:54 <opqdonut> (I was just thinking about what d could be for ADTs)
01:38:08 <ski> so, since it is impossible to have to values from `D' at the same time, `D * D' is isomorphic to `0'
01:39:03 <Saizan> ah, weird
01:39:28 <ski> and then we can use the isomorphism  f (a + D) = f a + D * f' a  to characterize  f'  (the derivative of `f')
01:40:52 <ski> so, if `f' is `Tree', then `Tree (a + D)' means that each element is either an `a' element, or a `D' element; but since there can only be at most one value of type `D', we either have no `D' values in the tree, i.e. the `f a' case
01:40:58 <ski> or we have exactly one `D' value in the tree, i.e. the  D * f' a  case
01:41:20 <ski> (we get back the same `D' value, and the rest is the derivative of `f', with the element type set to `a')
01:42:25 <ski> btw, SDG uses `f (x + d) = f x + d * D f x' to characterize the derivative `D f' of `f' (here `d' is an element of `|D', and `d' corresponds to the `D' type above)
01:43:30 <ski> so, you're possibly right that `D' doesn't belong in `*', but in some other kind, say `@', of types where we only have a limited stock of values in them, or something like that
01:43:34 <ski> i'm not sure
01:44:02 <ski> Saizan : note that in SDG, we don't talk about `d x' and `d y', we talk about `d', which is just an ordinary variable of type `|D'
01:44:06 <ski> e.g.
01:44:24 <ski>   forall x,y : |R. (forall d : |D. d * x = d * y) => x = y
01:44:30 <ski> is a useful cancellation law
01:45:15 <ski> the only point in `|D' we can point at is `0', and we can't divide by zero, but we can still divide by an "universally quantified `d'" :)
01:45:42 <Saizan> heh :)
01:46:18 <dolio> Why are you allowed to do that?
01:46:18 <ski> `|D' should be thought of as a subset of `|R' around `0' which is large enough to contain `0' (but it contains no real number which is apart from `0') -- it is an infinitesimally long open interval around `0'
01:47:01 <ski> this means that functions of type `|D >-> |R' correspond *both* to a point of `|R' *and* a slope (but no 2nd-order derivative)
01:47:35 <ski> (every function in SDG is smooth, i.e. infinitely differentiable)
01:47:35 <ddarius> Which is exactly what the (very simply case of the) Lawvere-Kock axiom states.
01:47:42 <ski> indeed
01:48:05 <ski>   alpha : |R^2 >-> (|D -> |R)
01:48:23 <ski>   alpha (k,m) = \d |-> k * d + m
01:48:39 <ski> the Lawvere-Kock axiom states that `alpha' is an isomorphism
01:48:57 <ddarius> ski: You should set up SCIM or something by the way.
01:49:26 <ski> if we allow classical logic, then we can show that `|D' is `{0}', and that the axiom is false .. but with intuitionistic logic, everything works fine :)
01:50:13 <ski> dolio : i don't recall atm how to prove that cancellation law, but it should follow from that axiom
01:51:32 * ski looks up `SCIM' at WP
01:52:24 <Saizan> \d -> d*x = \d -> d*x + 0 ~ (x,0) 
01:52:56 <Saizan> so (forall d : |D. d * x = d * y) means (x,0) = (y,0)
01:53:39 <ski> yeah, that looks right
01:53:57 <ski> ddarius : for entering unicode symbols ?
01:54:03 <ddarius> Yes.
01:54:13 <ski> ok
01:54:22 <ddarius> I can write \Gamma and get Γ.
01:54:30 <ski> nice
01:56:11 <dolio> And it'll only crash your programs an extra once an hour or so.
01:56:29 <ddarius> I've had little trouble with SCIM.
01:56:43 <ddarius> Other than the default table for the LaTeX mode is a little wonky and incomplete.
01:56:46 <dolio> I haven't really given it a go on a year or two.
01:57:06 <dolio> It used to give me problems, though.
01:57:45 <Saizan> you could just use .Xcompose
01:59:20 <dolio> How do you have a site listing your 70+ laptop models without a way to narrow the list down by various criteria?
02:00:44 <ddarius> dolio: In the military the answer to such questions is easy: lowest bidder.
02:02:32 <dolio> It's dumping out nice stuff like this most of the time, too: "... clearTimeout(intControlsbreadcrumbsSysWordingCheckId); } } function ProductGroupAll(xml){ ..."
02:10:03 <ski> opqdonut : "\"naked\" differentials are very useful in analysis" -- indeed, and therefore i want formal rules for manipulating them (or at the very least a translation to epsilon/delta- or SDG- reasoning)
02:12:00 <ski> similarly, i've seen definitions of `f(x) -> b  when  x -> a' (as a single primitive expression), but then people go on to do stuff like `x -> 0  =>  sin x -> 0  =>  ...', or even `x -> foo  <=>  y -> bar', which i have no idea what it means
02:14:59 <ski> (btw, i *do* think i have a working understanding of what `d y / d x' means (as opposed to `d ..x.. / d x'))
02:15:20 <ddarius> ski: http://geocalc.clas.asu.edu/pdf/DIF_FORM.pdf
02:17:20 <ski> ddarius : ty
02:19:05 <ski> (that is "Differential Forms in Geometric Calculus" by David Hestenes in 1993)
02:20:20 <xpika> > let applyN f n v = case n of 0 -> v;n -> applyN f (n-1) (f v) in applyN (+1) 0 10
02:20:21 <lambdabot>   10
02:20:58 <xpika> is there a function like this that already exists?
02:21:19 <dolio> No.
02:22:41 <ski> @type let applyN f n v = case n of 0 -> v;n -> applyN f (n-1) (f v) in applyN
02:22:41 <lambdabot> forall t t1. (Num t1) => (t -> t) -> t1 -> t -> t
02:23:04 <ski> i would possibly flip the `f' and `n' arguments
02:24:08 <ddarius> foldlNat.  Should be stricter.
02:26:23 <ski> do you mean making it properly curried (i.e. moving the recursion out of the `\v -> 's ?) ?
02:27:03 <Saizan> you want to force (f v) before the recursive call
02:28:04 <ski> hm .. oh .. well, i'd consider making it non-accumulating instead
02:31:02 <ski> @type let foldNat 0 _ = id; foldNat (n+1) f = f . foldNat n f in foldNat  -- i.e.
02:31:03 <lambdabot> forall t b. (Integral t) => t -> (b -> b) -> b -> b
02:31:33 <ski> hm
02:31:42 <ski> @type let f (x+1) = x in f
02:31:42 <lambdabot> forall t. (Integral t) => t -> t
02:31:52 <ski> @type let x + 1 = 1 in x
02:31:53 <lambdabot> Expr
02:32:04 <ski> @type let (x + 1) = 1 in x
02:32:05 <lambdabot> forall t. (Integral t) => t
02:32:19 <ski> (just checking that that's where `Integral' came from)
02:38:52 <augur> > let (x + 1) = 1 in x
02:38:52 <lambdabot>   <no location info>: Parse error in pattern
02:39:01 <pastorn> writing an asm grammar for BNFC
02:39:20 <shachaf> @karma n+k
02:39:20 <lambdabot> n+k has a karma of 0
02:39:28 <ski> Prelude> let (x + 1) = 1 in x
02:39:28 <ski> 0
02:39:35 <pastorn> it's not possible to create a grammar matching a Word16 unless using 65000 lines, is it?
02:40:03 <ski> Prelude> let (x + 1) = 0 in x
02:40:03 <ski> *** Exception: <interactive>:1:4-14: Irrefutable pattern failed for pattern (x+1)
02:40:10 <shachaf> pastorn: ?
02:40:40 <pastorn> shachaf: one of the operands is a 16-bit number, can that be expressed in BNF?
02:50:54 <ski> > '\SP'
02:50:54 <lambdabot>   ' '
02:52:14 <paolino> is it possible to print the ABI with cabal install --dry-run ?
02:54:29 <paolino> ok, I have to projects, installing them one ofter another they insist on recompiling some packages, which means they don't agree with the ABI ?
02:54:37 <paolino> *two
03:01:58 <adlsaks> hey - would anybody here be willing to answer a question about typing? 
03:02:23 <dolio> Probably.
03:02:32 <adlsaks> :)
03:03:00 <adlsaks> Aim is to make a function that gives a list of complex numbers in return for a complex number
03:03:01 <sipa> maybe, but you won't be sure until you ask tge question
03:03:09 <adlsaks> mandelbrot :: Complex -> [Complex] 
03:03:16 <sipa> ok
03:03:23 <adlsaks> I think this should work
03:03:27 <adlsaks> mandelbrot c = take 10 (iterate (\z -> z**2 :+ c) 0)
03:03:40 <adlsaks> problem is (I think), z's inferred type isn't complex
03:03:53 <adlsaks> What am I doing wrong? 
03:03:55 <sipa> just +, not :+
03:03:55 <dolio> Use +
03:04:07 <dolio> :+ is the constructor for complex numbers.
03:04:27 <paolino> :t 1:+ 2
03:04:28 <lambdabot> forall t. (RealFloat t) => Complex t
03:04:32 <sipa> :t (:+)
03:04:33 <lambdabot> forall a. (RealFloat a) => a -> a -> Complex a
03:04:47 <Entroacceptor> > (1:+2)+(2:+2)
03:04:48 <lambdabot>   3.0 :+ 4.0
03:04:51 <paolino> :i Complex
03:05:07 <paolino> @src Complex
03:05:07 <lambdabot> data (RealFloat a) => Complex a = !a :+ !a
03:05:27 <adlsaks> hrmm- that gives me "`Complex' is not applied to enough type arguments
03:05:31 <adlsaks>     Expected kind `??', but `Complex' has kind `* -> *'"
03:05:52 <adlsaks> am I supposed to pattern match the real and im parts separately? 
03:06:03 <Entroacceptor> no, you're supposed to supply a floating type
03:06:40 <sipa> adlsaks: what line?
03:06:40 <paolino> Complex Double -> [Complex Double]
03:07:24 <adlsaks> sipa: Type definition line
03:07:35 <adlsaks> paolino - thanks, will try.... 
03:07:45 <paolino> @kind Complex
03:07:46 <lambdabot> * -> *
03:08:05 <paolino> @kind Complex Double
03:08:06 <lambdabot> *
03:09:04 <adlsaks> paol: Ah- yes, I'm starting to see :P 
03:09:27 <paolino> I think you must write signatures with * kinded types, but I ask here to be sure
03:12:23 <ski> > (read . ('\"' :) . (++ "\"") . concatMap ('\\':) . words) "NUL SOH STX ETX EOT ENQ ACK BEL BS HT LF VT FF CR SO SI" :: String
03:12:25 <lambdabot>   "\NUL\SOH\STX\ETX\EOT\ENQ\ACK\a\b\t\n\v\f\r\SO\SI"
03:12:26 <ski> > (read . ('\"' :) . (++ "\"") . concatMap ('\\':) . words) "SI DLE DC1 DC2 DC3 DC4 NAK SYN ETB CAN EM SUB ESC FS GS RS US DEL" :: String
03:12:28 <lambdabot>   "\SI\DLE\DC1\DC2\DC3\DC4\NAK\SYN\ETB\CAN\EM\SUB\ESC\FS\GS\RS\US\DEL"
03:12:51 <ski> > (map ord . read . ('\"' :) . (++ "\"") . concatMap ('\\':) . words) "NUL SOH STX ETX EOT ENQ ACK BEL BS HT LF VT FF CR SO SI"
03:12:52 <lambdabot>   [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
03:13:03 <ski> > (map ord . read . ('\"' :) . (++ "\"") . concatMap ('\\':) . words) "SI DLE DC1 DC2 DC3 DC4 NAK SYN ETB CAN EM SUB ESC FS GS RS US DEL"
03:13:04 <lambdabot>   [15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,127]
03:13:27 <ski> > (read . ('\"' :) . (++ "\"") . concatMap (("\\^" ++) . (: [])) . map chr) [64 .. 79] :: String
03:13:28 <lambdabot>   "\NUL\SOH\STX\ETX\EOT\ENQ\ACK\a\b\t\n\v\f\r\SO\SI"
03:13:36 <ski> > (read . ('\"' :) . (++ "\"") . concatMap (("\\^" ++) . (: [])) . map chr) [80 .. 95] :: String
03:13:37 <lambdabot>   "\DLE\DC1\DC2\DC3\DC4\NAK\SYN\ETB\CAN\EM\SUB\ESC\FS\GS\RS\US"
03:13:53 <paolino> aren't function on Complex slower than they  should be, defined as a datatype? newtype should perform better
03:13:58 <ski> > '\^?'
03:13:58 <lambdabot>   <no location info>:
03:13:58 <lambdabot>      lexical error in string/character literal at chara...
03:14:12 <ski> > ['\SO','H']
03:14:13 <lambdabot>   "\SO\&H"
03:14:23 <ski> > '\SOH'
03:14:24 <lambdabot>   '\SOH'
03:14:57 <ski> hm, forgot `SP'
03:15:10 <ski> > '\SP'
03:15:11 <lambdabot>   ' '
03:16:10 <adlsaks> paolino: are you asking me? 
03:16:29 <paolino> no
03:16:34 <paolino> I asked.
03:17:01 <ski> if `newtype' was used, one would have to wrap a pair (or something)
03:17:53 <paolino> when there is one only constructor, it is at least correct
03:17:54 <adlsaks> > take 5 (iterate (\z -> z**2 + 1) 0)
03:17:54 <lambdabot>   [0.0,1.0,2.0,5.0,26.0]
03:18:21 <ski> no, `newtype's must have a single data constructor, with a single *argument*
03:18:30 <paolino> > take 5 (iterate (\z -> z**2 + 1) 0) :: [Complex Double]
03:18:31 <lambdabot>   [0.0 :+ 0.0,NaN :+ NaN,NaN :+ NaN,NaN :+ NaN,NaN :+ NaN]
03:19:08 <ski> (`newtype Complex a = a :+ a' would not be accepted)
03:19:09 <adlsaks> Yeah - it gives the wrong result - not sure why 
03:19:16 <paolino> right, tuples are slow as datatypes
03:19:28 <ski> depends, i think
03:19:56 <ski> in this case, you probably want the two components to be strict, so the usual non-strict pair wouldn't be appropriate
03:20:30 <ski> (but if you need non-strict pairs, then using strict pairs instead can make your program fail to terminate)
03:21:20 <paolino> strict pairs are more efficient  than datatypes ?
03:21:52 <ski> it depends on whether you want the parts strict or not
03:22:00 <ski> a nonterminating program is very inefficient
03:22:08 <mreh> is this enough code to diagnose the memory leak here? http://hpaste.org/44905/memory_leak
03:22:33 <adlsaks> paolino: Do you know why the NaNs happened above when you gave it the Complex Double type?
03:23:00 <ski> > 0 ** 2 :: Complex
03:23:01 <lambdabot>   Expecting an ordinary type, but found a type of kind * -> *
03:23:05 <ski> > 0 ** 2 :: Complex Double
03:23:05 <lambdabot>   NaN :+ NaN
03:23:09 <ski> > 0 ^ 2 :: Complex Double
03:23:10 <lambdabot>   0.0 :+ 0.0
03:23:19 <ski> adlsaks : try s/* 
03:23:22 <ski> er
03:23:26 <mreh> readSetFile parses an image into an associative list and then stuffs that into an array, but my heap profiling shows loads of []
03:23:27 <ski> s/** 2/^ 2/
03:23:41 <ski> @type (^)
03:23:42 <lambdabot> forall a b. (Num a, Integral b) => a -> b -> a
03:23:44 <ski> @type (^^)
03:23:44 <lambdabot> forall a b. (Fractional a, Integral b) => a -> b -> a
03:23:46 <ski> @type (**)
03:23:47 <lambdabot> forall a. (Floating a) => a -> a -> a
03:24:23 <ski> `(^)' is for natural exponents, `(^^)' for integer exponents, and `(**)' is for exponents of the same type as the base
03:25:00 <adlsaks> ski: beautiful, thank you :) 
03:25:29 <paolino> > take 5 (iterate (\z -> z^2 + 1) 0) :: [Complex Double]
03:25:29 <lambdabot>   [0.0 :+ 0.0,1.0 :+ 0.0,2.0 :+ 0.0,5.0 :+ 0.0,26.0 :+ 0.0]
03:25:41 <paolino> black point
03:26:22 <paolino> *pixel
03:27:38 <ski>   x ** y               = exp (log x * y)
03:27:41 <ski> > phase 0
03:27:42 <lambdabot>   0.0
03:27:48 <ski> > magnitude 0
03:27:49 <lambdabot>   Ambiguous occurrence `magnitude'
03:27:49 <lambdabot>  It could refer to either `Data.Complex.ma...
03:27:57 <ski> > Data.Complex.magnitude 0
03:27:58 <lambdabot>   0.0
03:28:53 <paolino> > o ** 2
03:28:54 <lambdabot>   o**2
03:29:00 <paolino> > 0 ** 2
03:29:00 <lambdabot>   0.0
03:29:07 <adlsaks> :P
03:29:24 <ski> > 0 ** 2 :: Complex Double
03:29:25 <lambdabot>   NaN :+ NaN
03:29:29 <adlsaks> Thanks very much for the help Paolino and ski :P 
03:29:37 <ski> > let x ** y = expC (logC x * y); expC (x:+y) = expx * cos y :+ expx * sin y where {expx = exp x}; logC z = log (magnitude z) :+ phase z in 0 ** 2
03:29:38 <lambdabot>   Ambiguous occurrence `magnitude'
03:29:38 <lambdabot>  It could refer to either `Data.Complex.ma...
03:29:45 <ski> > let x ** y = expC (logC x * y); expC (x:+y) = expx * cos y :+ expx * sin y where {expx = exp x}; logC z = log (Data.Complex.magnitude z) :+ phase z in 0 ** 2
03:29:45 <lambdabot>   NaN :+ NaN
03:29:57 <ski> something in that definition makes this not work
03:30:11 <paolino> > log 0
03:30:12 <lambdabot>   -Infinity
03:30:28 <ski> adlsaks : generally, you should consider using the exponentiation operators in the order `(^)',`(^^)',`(**)'
03:30:42 <adlsaks> :) 
03:31:11 <mreh> :t o**2
03:31:11 <lambdabot> Expr
03:31:24 <ski> :t 0 ** 2
03:31:25 <lambdabot> forall t. (Floating t) => t
03:31:56 <ski> > 0 * log 0
03:31:57 <lambdabot>   NaN
03:32:38 <paolino> > exp (log 0)
03:32:39 <lambdabot>   0.0
03:32:48 <ski> > phase 0  -- this seems wrong, no ?
03:32:49 <lambdabot>   0.0
03:32:56 <paolino> > exp (log 0 * 2)
03:32:56 <lambdabot>   0.0
03:33:01 <ski> > (log 0 :+ 0) * 0
03:33:02 <lambdabot>   NaN :+ NaN
03:34:01 <paolino> > exp (-Infinity)
03:34:02 <lambdabot>   Not in scope: data constructor `Infinity'
03:34:18 <augur> what is yesod, exactly
03:34:27 <ski> > case (log 0 :+ 0) * 0 of x :+ y -> exp x * cos x :+ exp x * sin y
03:34:28 <lambdabot>   NaN :+ NaN
03:34:39 <ski> > read "-Inf" :: Double
03:34:40 <lambdabot>   *Exception: Prelude.read: no parse
03:34:49 <ski> > exp / log 0
03:34:49 <lambdabot>   Overlapping instances for GHC.Show.Show (a -> a)
03:34:49 <lambdabot>    arising from a use of `...
03:34:53 <ski> > exp (log 0)
03:34:53 <lambdabot>   0.0
03:35:17 * ski doesn't know about `yesod'
03:35:34 <sordina> Does anyone know why I might be getting the following link error with cairo? I just cabal-installed everything (os x):  ld: warning: in /opt/local/lib/libcairo.dylib, file was built for unsupported file format which is not the architecture being linked (i386)
03:35:45 <paolino> yesod is a web framework
03:36:14 <mreh> hmm, is sordina what is your target instruction set?
03:36:51 <sordina> mreh: How do I check?
03:37:07 <Saizan> sordina: your ghc builds 32bit binaries but your C cairo lib is built for 64bit
03:37:22 <mreh> sordina: uname -a
03:37:40 <paolino> os x
03:37:56 <mreh> that's an operating system, not an instruction set
03:38:28 <paolino> ok, I thought os x has only one
03:38:51 <sordina> It's just listed as i386, but I thought I'd downloaded the 64 bit haskell platform.
03:39:38 <mreh> I think that would be listed as ix86_64 if you were on a 64bit machine
03:39:40 <mreh> not sure
03:40:03 <mreh> mine is i686, i'm on a 32 bit machine
03:40:25 <mreh> as the *nix boffins
03:40:27 <mreh> ask*
03:40:29 <sordina> mm
03:41:20 <sordina> is there a way I can check what architecture /opt/local/lib/libcairo.dylib is built against?
03:41:22 <mreh> but anyway, what you've downloaded would work if you were on a 32 bit machine, so download the cairo 64 libraries
03:41:58 <mreh> unless I misunderstand that error message
03:42:11 <mreh> I think Saizan already gave you all the advice you need
03:42:38 <sordina> ah okay. Thanks guys
03:42:46 <Saizan> i think (i386) is the "architecture being linked" which is not the arch libcairo is built for
03:42:57 <Ptival> that's the way I understand it too
03:43:35 <paolino> all these constraints in cabal files, just make the projects fight and cabal install fail, deleting them often resolves problems, not fair
03:44:37 <mreh> they're not fighting, they just incompatible given a set of constraints
03:44:46 <mreh> loosening them often helps
03:45:02 <mreh> removing redundancies is always good
03:45:20 <paolino> mreh: it means the authors have too much responsability ?
03:46:07 <paolino> asking the end user to randomly play with constraints is wrong anyway
03:46:13 <mreh> paolino: they have a responsibility to keep their code within major revision numbers compatible
03:47:40 <paolino> mmh, I think that cabal should contain the exact versions needed to compile. The rest should be machine decided
03:48:28 <mreh> cabal will go for the newest it can within the constraints in my experience
03:49:14 <paolino> if it needs a new package or anyway ?
03:49:57 <mreh> if it's available
03:53:33 <paolino> anyway, I always have to fiddle with constraints, making rough guesses. Or make a new user for each project wants to recompile part of my package database
03:53:49 <paolino> so cabal install --dry-run -v 
03:54:12 <mreh> you can have multiple versions installed
03:54:15 <paolino> control there is no recompilation scheduled
03:54:36 <mreh> of a package
03:55:09 <paolino> mreh, this is not my experience, in fact I installed hakyll and it broke my project
03:55:17 <Skola> although Haskell syntax seems pretty straightforward to me, is there something like an "official" style guide, like Python's PEP 8?
03:55:35 <paolino> mreh: I installed my project and it broke hakyll
03:56:29 <paolino> mreh: I deleted ~/.ghc/ deleted all constrains and now they live together
03:57:34 <paolino> it's a shame that the new cabals are not good for haskell-platform 2010 :)
03:57:44 <paolino> as they were before
04:00:51 <paolino> time to learn cabal-dev
04:01:31 <ski> Skola : i'm not sure whether anyone has written any such .. but there are some things that are considered good style, and sometimes there's several competing opinions
04:02:27 <Skola> alright, do you know of any articles/guides on the matter?
04:02:57 <ski> Skola : one such is that either (a) you don't use tabs for indentation at all; or you always use tabs for indentation (and then you should break line after layout-introducing words like `do',`let',`where')
04:03:34 <adlsaks> > :t abs(2 :+ 3)
04:03:35 <lambdabot>   <no location info>: parse error on input `:'
04:03:36 <Skola> ok
04:03:45 <ski> @type abs (2 :+ 3)
04:03:45 <lambdabot> forall t. (RealFloat t) => Complex t
04:03:56 <ski> @type abs
04:03:57 <lambdabot> forall a. (Num a) => a -> a
04:04:00 <Skola> currently I don't use any tabs
04:05:04 <ski> then, usually we use `camelCase' rather than `words_separated_by_underscores'
04:06:09 <Skola> yeah, got that down too, though at first reluctantly, having read too many bad JS
04:06:15 <adlsaks> ski: Stupid question, but that type above says that the type of abs is complex, yeah? 
04:06:16 <Skola> too much*
04:06:33 <adlsaks> @type abs (2 :+ 3) 
04:06:34 <lambdabot> forall t. (RealFloat t) => Complex t
04:06:39 <pastorn> Doin a regex
04:06:57 <ski> then there's more semantical things like trying to put the arguments to a function in order from least-commonly-varied to most-commonly-varied, to be able to use partial application more
04:06:59 <pastorn> so X* means a sequence of X of length 0 to Inf
04:07:05 <pastorn> what does X+ mean?
04:07:14 <paolino> adlsaks: Complex t
04:07:26 <ski> @type abs `asTypeIn` \abs -> abs (2 :+ 3)
04:07:27 <lambdabot> forall t. (RealFloat t) => Complex t -> Complex t
04:07:35 <ski> @type abs `asTypeIn` \abs -> abs (2 :+ (3 :: Double))
04:07:36 <lambdabot> Complex Double -> Complex Double
04:07:39 <ski> adlsaks : ^
04:07:51 <adlsaks> @type magnitude(2 :+ 3) 
04:07:52 <lambdabot>     Ambiguous occurrence `magnitude'
04:07:52 <lambdabot>     It could refer to either `Data.Complex.magnitude', imported from Data.Complex
04:07:52 <lambdabot>                           or `Data.VectorSpace.magnitude', imported from Data.VectorSpace
04:08:01 <adlsaks> @type Data.Complex.magnitude(2 :+ 3) 
04:08:02 <lambdabot> forall t. (RealFloat t) => t
04:08:27 <paolino> :t asTypeIn
04:08:27 <ski> paolino : usually `X^*' would only be finite sequences of `X's
04:08:27 <lambdabot> forall a b. a -> (a -> b) -> a
04:08:42 <ski> paolino : and `X^+' be finite, non-empty, sequences of `X's
04:09:40 <paolino> X+ is at least one X
04:09:44 <ski> (`asTypeIn' is just a trick of mine to easier see which instance of a polymorphic type a polymorphic operation gets in a particular use)
04:09:48 <ski> yes
04:10:30 <adlsaks> :)
04:10:40 <ski> (s/polymorphic type/universally quantified type/ i suppose, to nitpick myself)
04:11:26 <ski> paolino : btw, the `*' there is called the "Kleene star"
04:11:36 <pastorn> politik: cool, thanks :D
04:11:56 <ski> (note that `X^*' is basically `[X]' in Haskell terms (thinking only of the finite values))
04:12:24 <paolino> @type show `asTypeIn` \s -> s 4
04:12:25 <lambdabot> forall a. (Num a) => a -> String
04:12:41 <paolino> @type show `asTypeIn` ($4)
04:12:42 <lambdabot> forall a. (Num a) => a -> String
04:13:38 <ski>   asTypeIn :: a -> (a -> b) -> a
04:13:38 <ski>   a `asTypeIn` _ = a
04:13:50 <ski> @type asTypeOf
04:13:50 <lambdabot> forall a. a -> a -> a
04:13:53 <ski> @src asTypeOf
04:13:53 <lambdabot> asTypeOf = const
04:14:00 <paolino> yes, pastorn is really interested in regex actually, but np
04:14:39 <ski> paolino : oh, sorry, confused your name with `pastorn'
04:14:42 <ski> pastorn : ^
04:15:41 <pastorn> ski: i'm writing a BNF for a 40+ year old assembler language
04:15:48 <ski> heh
04:15:48 <pastorn> pre-VAX stuff
04:15:55 <ski> (which architeture ?)
04:16:14 <pastorn> ski: Interdata 16 bit
04:16:42 <pastorn> instead of having instructions with addressing modes documented you have one instruction for each addressing mode
04:16:43 <ski> pastorn : re `0' to `65535', you could probably manually do a few rules to express only those numbers
04:17:05 <pastorn> ski: bah, i'll leave it to the assembler to do "type" checking
04:17:09 <pastorn> well, more like sanity
04:19:25 <knobo`> Is there a simple way to extend a server application (like this: http://hpaste.org/44906/extend_with_thread_pool) with a connection/thread pool to speed up processing? 
04:20:22 <ezyang> knobo`: The GHC RTS will automatically maintain a "thread pool" for you. 
04:20:32 <ezyang> since forkIO generates green threads, which are many-to-one mapped to OS threads. 
04:21:05 <ezyang> As for a connection pool, that depends on what your app is supposed to do. 
04:21:15 <ezyang> Usually the client maintains a connection pool, not the server... 
04:21:43 * FauxFaux peers at ezyang.
04:22:09 * ezyang peers back. 
04:24:20 <knobo> ezyang: any where I can read about how GHC RTS maintains the "tread pool"?
04:25:38 <ezyang> knobo: What kind of information are you interested in? 
04:26:15 <jix> knobo: do you want to limit the number of connections at the same time or only limit the number of system threads?
04:27:21 <knobo> I found what I was looking for: The downside of having lightweight threads is that only one can run at a time, so if one thread blocks in a foreign call, for example, the other threads cannot continue
04:27:22 * ski . o O ( "When you gaze long into the abyss, the abyss also gazes into you." )
04:28:22 <jix> knobo: multiple haskell threads can run at the same time.. just not more than there are system threads
04:28:32 <ezyang> knobo: That's... probably a little misleading, in this context. 
04:28:41 <ezyang> What are you really trying to do? 
04:29:02 <jix> knobo: usually you set the number of system threads to the number of cpus you have. There can't be more running at the same time anyway.
04:29:55 <knobo> Isn't read and write operation blocking the other treads?
04:30:20 <ezyang> knobo: Foreign calls means something very specific. 
04:30:30 <ezyang> Read write operations are handled specially by GHC's IO manager. 
04:31:44 <knobo> Thanks for the information.
04:31:46 <ezyang> What will happen then is that your thread will get suspended waiting for the IO call to resolve, and another thread will get to run. 
04:31:56 <ezyang> Don't worry too much about FFI for now. 
04:32:08 <Gertm> What would be a good book to explore category theory a bit without a huge math background? (a slower paced book preferably)
04:32:11 <jix> knobo: basically haskell is doing the same thing you'd do in a high performance server (using a thread pool and epoll for IO) automatically for free
04:32:32 <ezyang> Gertm: How much maths do you have? 
04:32:48 <knobo> Great! :)
04:33:00 <Gertm> ezyang: real math has been a while,.. 10 years since I got my degree, so I'm rusty
04:33:39 <ezyang> Rusty is a bit different from absence entirely :-) 
04:34:13 <Gertm> it is :)
04:34:17 <knobo> Is there a simple way I could benchmark my server application?
04:34:19 * geheimdienst applies WD-40 to Gertm
04:34:39 <ezyang> knobo: No. Benchmarks are complicated affairs and require careful thought. 
04:34:59 <Gertm> so ezyang, do you have a book suggestion? :)
04:35:04 * Gertm thanks geheimdienst
04:35:18 <ezyang> I can say what I'm working through, though it may not necessarily be for you. 
04:35:23 <Gertm> shoot!
04:35:49 <ezyang> I'm working on Awodey's Category Theory (there should be a PDF floating round the net), but it's math-y (less-so than MacLane, but still mathy) 
04:36:22 <ezyang> I sort of got a basic handle on the basic ideas up to natural transformations using "A Gentle Introduction to Category Theory: A Calculational Approach" by Fokkinga 
04:36:36 <Gertm> ezyang: yeah, I was reading that too, it's doable.. Also found introduction to category theory in four easy movements
04:36:46 <ezyang> haven't heard that one before. 
04:36:50 <Gertm> fokkinga eh? Need to look for that
04:36:59 <Gertm> ezyang: they are course notes from a uni professor iirc
04:37:41 <ezyang> yeah, Awodey's profess to be "MacLane for everyone else" 
04:37:56 <ezyang> I can't necessarily give it a recommendation yet, though :-) 
04:38:44 <Gertm> ezyang: thanks for the fokkinga suggestion, that seems nice to start out with, I'll move to awodey after that.
04:39:28 <knobo`> argh... lost connection there for a second..
04:39:34 <knobo`> Did I loos any comment?
04:40:55 <micrypt> knobo`: Only a "thank you" message.
04:46:28 <adlsaks> don't suppose anybody knows how to create a continuous RGB color table? 
04:46:58 <adlsaks> ie; list of tuples where each pair of adjacent tuples looks to be a similar color
04:47:00 <Zao> Depends on what you mean.
04:47:03 <jix> adlsaks: sampling any volume filling curve should work
04:47:39 <Zao> adlsaks: I'd sample a range of HSV values.
04:48:27 <jix> adlsaks: I assumed you wanted all colours in that list
04:48:48 <adlsaks> ah - 
04:48:51 <adlsaks> > Data.Colour.RGBSpace.HSV
04:48:52 <lambdabot>   Not in scope: data constructor `Data.Colour.RGBSpace.HSV'
04:49:33 <knobo`> thank you
04:50:22 <knobo`> Does it make it easier to benchmark an application that only runs on local computer? (no external clients)
04:51:13 <adlsaks> jix: Could you give me something regarding a volume filing curve that I can put into google?  The obvious choice didn't work for me :/
04:57:53 <jix> adlsaks: search for space filling curves (the 2d version) higher dimensional variants are also called multidimensional space filling curves
04:58:25 <jix> The hilbert curve is a popular one
05:01:58 <ski> Gertm : "Conceptual Mathematics" by Lawvere and Schanuel might be interesting, if you have a basic math understanding
05:05:19 <Gertm> thanks ski 
05:06:29 <adlsaks> @type hsv `asTypeIn` \hsv -> hsv 0.5 0.5 0.5
05:06:30 <lambdabot> Not in scope: `hsv'
05:07:50 <_mpu> hi, can I improve (concat $ intersperse " " $ init l) ++ " :" ++ last l
05:09:34 <_mpu> @pl \s -> init s ++ " " ++ last s
05:09:34 <lambdabot> liftM2 (++) init ((' ' :) . last)
05:10:15 <Axman6> _mpu: describing what you want would be helpful (not just the code, the description of what it should do)
05:11:31 <_mpu> well this code does what it should do, intersperse a list of strings with " " everywhere except at the last time where it must be " :"
05:13:12 <Axman6> well, firstly, intersperse " " is just unwords, so that should make it a little simpler
05:14:38 <adlsaks> hrmm- can I put a 'where' clause in the middle of a do monad? 
05:14:39 <adlsaks> ie: 
05:14:56 <adlsaks> in the middle of a set of statements...
05:14:59 <sipa> no
05:15:05 <Axman6> use a let statement
05:15:09 <sipa> but you can use let there
05:15:16 <adlsaks> ok
05:15:16 <Axman6> it's exactly what you're asking for
05:17:14 <Axman6> in do blocks, let statements don't have an 'in' after them: do { x <- foo; let y = x ^ 4; f y }
05:18:14 <adlsaks> Yup, thanks, worked
05:19:08 <dankna> that precise issue took me forever to understand when I was new
05:19:28 <dankna> the error you get may have improved, but at the time it was (what else) a type error, and not one that made sense to a newcomer :)
05:20:58 <adlsaks> Does ghc give errors besides type errors? ;) 
05:21:14 <hpc> adlsaks: it has been rumored to :P
05:22:37 <dankna> absolutely.  it also gives "infinite type" errors!
05:23:07 <paolino> and missing instances
05:23:18 <Xilon> It gives syntactic errors
05:23:28 <Xilon> Though it's usually indentation :P
05:23:31 <dankna> true.
05:23:42 <dankna> it even SAYS in the syntax error that it's probably indentation :)
05:24:14 <paolino> a gentle wtf
05:24:23 <dankna> yep
05:25:11 <Xilon> Got to love the (almost) lack of runtime errors though
05:25:33 <Axman6> anyone else thing that GHC should start giving warnings for using tabs in haskell source (for indentation only though)
05:25:35 <dankna> that's very true
05:25:39 <dankna> Axman6: YES
05:25:57 <Axman6> maybe in Haskell2011
05:25:59 <dankna> cabal-install considers tabs illegal
05:26:07 <dankna> yeah, or even just add a LANGUAGE flag for it
05:26:13 <paolino> it always gets me
05:26:14 <dankna> NoTabs
05:26:21 <Xilon> Axman6: Where else would you use tabs (besides comments maybe)?
05:26:22 <dankna> with the default being Tabs
05:26:28 <dankna> string literals
05:26:34 <Xilon> \t?
05:26:50 <dankna> well, bottom line is you're right - tabs should be disallowed everywhere :)
05:27:00 <hpc> i prefer \t to typing the whole tab
05:27:03 <dankna> the second most troublesome character, after \n
05:27:05 <Axman6> Xilon: comments and lining up = signs was the only place i could thing of. but indentation is the only place that it breaks things i think
05:27:16 <adlsaks> Well, if anybody wants a very slow Mandelbrot set renderer, look no further
05:27:18 <paolino> mh, I like tabs, I can re-indent pieces faster
05:27:22 <dankna> adlsaks, congratulations
05:27:24 <Xilon> Axman6: tabs shouldn't be used for aligning either way ;)
05:27:33 <adlsaks> ... in other news, what do folks recommend for profiling? 
05:27:34 <Axman6> sure
05:27:35 <dankna> paolino: editors can provide "soft tabs" as an abstraction, and good ones do
05:27:44 <adlsaks> dankna: thanks :) 
05:27:57 <dankna> adlsaks, read the GHC manual chapter on profiling, and I suspect that this is actually not "other news" but strongly related :)
05:28:03 <Axman6> not just good ones, any decent one
05:28:07 <Xilon> dankna: havn't really seen _good_ ones, but vim and emacs provide decent ones
05:28:25 <dankna> Xilon: well, the caveat to "good editors do X" is "there are no good editors in existence" :D
05:29:02 <dankna> but TextWrangler and its commercial version BBEdit, on the Mac, provide good soft tabs
05:29:14 <hpc> commercial text editor?
05:29:15 <dankna> though not perfectly how I'd do them
05:29:17 <paolino> dankna: can you send me the vim instruction, I've used them long time ago, but I didn't like them, delete was just deleting a space
05:29:18 <dankna> yes
05:29:20 <hpc> it WOULD be on a mac
05:29:21 <adlsaks> dankna: Yes.  I suspect adding an OpenGL renderer to spin the set was a bad idea
05:29:39 <dankna> paolino: it's been about ten years since I used Elvis, and I never used Vim except as one-off things, sorry.
05:29:43 * Axman6 prefers TextMate
05:30:04 <dankna> adlsaks: no that should have been okay....
05:30:17 <dankna> adlsaks: though what I would do is render to a texture and then rotate the texture
05:30:41 <ion> :set et sw=2 sts=2 for indentation by two spaces, > for indenting more, < for indenting less.
05:30:42 <hpc> i don't know the command to set soft tabs, but wouldn't s/\t/    /g work?
05:30:43 <paolino> it deletes four spaces when you press delete key ?
05:30:55 <ion> :%retab to convert tabs to spaces after the :set command./
05:30:56 <adlsaks> dankna: I've gone from recalculating from scratch on every frame.  I wonder why it's so slow ;) 
05:31:00 <dankna> hpc: yes, indeed, it would.  the intersection of very picky people (who might be willing to pay for a text editor) and Mac users is significant.
05:31:16 <paolino> hpc that is what I do
05:31:24 <dankna> they get away with murder on the pricing, too, it costs like $150
05:31:25 <paolino> well the other way around :P
05:31:35 <Axman6> hpc: no
05:31:58 <dankna> adlsaks: I regret that I lack the time to look at it, but you can profile, anyhow
05:32:22 <Axman6> hpc: since tab lines things up with the next tabstop, if you have a tabstop of 4, then "  \t" would be come "      " instead of "    "
05:32:34 <Axman6> (6 spaces instead of 4)
05:32:34 <adlsaks> dank: I was just being silly 
05:32:47 <Xilon> I wonder if/when editors will start using elastic tabstops http://nickgravgaard.com/elastictabstops/
05:32:48 <ion> If you have "  \t" in your code, something’s wrong. :-P
05:32:57 <hpc> ^
05:33:33 <paolino> so does delete key deletes the tabulation when it's soft tab ?
05:33:39 <Axman6> well, it was just an example. \t doesn't map to a fixed number of tabs
05:33:42 <Axman6> uh spaces
05:33:55 <Axman6> paolino: it does in textmate i think
05:34:45 <paolino> this is a must for me, if it deletes a space, tabs works better
05:35:02 <ski> dankna : editors can also provide ways to display tab characters per the wishes of the user :)
05:35:06 <Xilon> paolino: in vim it will remove the spaces as if they were tabs
05:35:15 <Xilon> Can't recall how emacs works, I think the same way
05:35:24 * paolino retries
05:35:41 <dankna> ski: yes, but it's not worth the trouble :(
05:35:41 * Axman6 -> Sleep
05:35:49 <Xilon> ski: which is why they shouldn't be used for aligning stuff, and in haskell you align stuff quite often (so you'd need "\t\t   foo"
05:36:19 <ski> paolino : i think using tabs for indentation is ok, if you use only tabs (no spaces) for indentation, and always break line after layout-introducing keywords (`do',`let',`where',&c.) (except maybe if your indentation block all fits on one line)
05:36:41 <ski> i don't use tabs for indentation myself, but i know a few people in here does the above
05:36:50 <mauke> I've stopped using tabs in haskell because haskell doesn't use indentation
05:37:00 <mauke> it's just not how the syntax works
05:37:04 <Xilon> mauke: erm what?
05:37:10 <ski> s/indentation/layout/ :)
05:37:11 <mauke> haskell is all about making things line up
05:37:26 <Xilon> ah, yeah
05:38:25 * hpc alternates between lining things up and using two spaces, depending on what would break an 80x24 terminal window
05:38:33 <ski>   (setq-default indent-tabs-mode nil)  ; emacs, don't put tabs in my buffers
05:38:40 <hpc> or my fingers ;)
05:39:20 <mauke> :set sw=4 sts=4 et
05:39:32 * ski usually both makes things line up, and indent new levels with two spaces (if nothing else is more appropriate)
05:39:51 <dankna> yes, that's roughly what I do, ski
05:40:18 <ski> (including making `=' and sometimes brackets and commas line up)
05:40:25 <dankna> I model it mentally as the different options having different "badnesses" and try to pick the least-globally-bad one ala what TeX does.
05:40:43 <hpc> dankna: haha
05:40:46 <dankna> I'd like an editor that modelled it that way too
05:41:00 <paolino> Xilon: can you tell me the vim settings ?
05:41:06 <hpc> a text editor, or a document editor like word?
05:41:10 <dankna> hpc: at which?  the intersection significant remark? :)
05:41:32 <hpc> the "badnesses"
05:41:57 <hpc> dankna: in a text editor, that approach would be problematic, since it takes control away from the one who is typing
05:42:08 <hpc> in something like word, it would be pretty great
05:42:14 <dankna> well.
05:42:25 <dankna> I guess I want an editor that blurs the boundaries a little - provides manual override but...
05:42:34 <dankna> takes that concern away from me a little
05:43:01 * hpc likes the feature in eclipse, where you can make whitespace show up as light gray symbols
05:43:12 <hpc> a -> arrow for tabs, frex
05:44:25 <mauke> :set list
05:44:45 <hpc> i wish visual studio had that, since valve loves mixing tabs and spaces in the source engine code
05:44:50 <dankna> yes, TextWrangler/BBEdit has had that since forever
05:44:59 <Xilon> paolino: I believe it does it by default, just use spaces (:set expandtabs)
05:45:28 <paolino> there is smarttab to control BS 
05:46:26 <paolino> with expandtabs BS doesn't work
05:47:28 <Xilon> I have autoindent, smarttab, et, shiftround
05:49:12 <paolino> thanks, shiftround is useful
05:50:34 * paolino stops using tabs and wear the white fleece
06:00:49 <paolino> mauke: we should change ghc syntax error in "probably code is not line up properly"
06:02:18 <paolino> in correct language, maybe
06:22:33 <BW^-> when communicating with the C/FFI world, is the IO monad used to guarantee sequential behavior?
06:24:03 <Axman6> what do you mean?
06:24:37 <Axman6> you have to use the IO monad when using the FFI (you can hide this if you use unsafePerformIO, and this is its intended use, but only if the code is actually pure)
06:25:40 <burp> um, does foreign imported code always have to be in IO?
06:26:06 <BW^-> hm. ok. i may have more questions, for instance..
06:26:18 <BW^-> is there any good way to force strict evaluation in haskell?
06:26:22 <burp> can't you just do something like, foreign import ccall "foo" cFoo :: CInt → CInt?
06:26:23 <Axman6> burp: i believe so.
06:26:44 <BW^-> at points i could be beneficial in order to ensure particular RAM/CPU use characteristics
06:26:58 <BW^-> such as ensuring you'll get particular responsiveness characteristics of the app
06:27:13 <Axman6> foo !x = ... forces the evaluation of x to WHNF
06:27:34 <Axman6> there's also plenty of other ways to do it
06:28:09 <BW^-> axman6: which are they
06:28:10 <BW^-> ?
06:28:25 <Axman6> huh?
06:28:45 <BW^-> which are the plenty of other ways to do it
06:29:10 <Axman6> oh, well there's also deepseq to evaluate structures, there's the evaluate function which runs in IO and tells the RTS to evalate a value
06:29:29 <hpc> :t evaluate
06:29:30 <lambdabot> Not in scope: `evaluate'
06:29:31 <Axman6> you can use seq
06:29:34 <hpc> @hoogle evaluate
06:29:34 <lambdabot> Control.Exception evaluate :: a -> IO a
06:29:34 <lambdabot> Control.OldException evaluate :: a -> IO a
06:29:34 <lambdabot> Test.QuickCheck evaluate :: Testable a => a -> Gen Result
06:29:43 <BW^-> hm ok
06:29:53 <hpc> why is evaluate in IO, if all it does is rnf?
06:29:57 <BW^-> how much can you code in haskell without defining a type?
06:30:00 <Axman6> to give you better answers we'd have to know what you're trying to do
06:30:05 <Saizan> hpc: it doesn't rnf
06:30:11 <Axman6> hpc: it's not the same thing
06:30:14 <BW^-> i mean.. i want to define a procedure that returns something..
06:30:22 <BW^-> it takes five arguments of whatever type
06:30:28 <Saizan> hpc: it's in IO because the point is to tie the evaluation to the order of side effects
06:30:34 <BW^-> (something as in whatever type)
06:30:45 <hpc> Saizan: ah, okay
06:30:48 <BW^-> without even specifying that it returns / takes Dynamic
06:30:58 <Axman6> o.O
06:31:00 <hpc> Saizan: oh, that would make sense, if it was in exception
06:31:10 <hpc> so you can actually catch errors in pure code
06:31:30 <BW^-> is this doable at all? i got the impression that currently it's not.. there's lots of talk that haskell is statically typed and that's it
06:31:59 <hpc> BW^-: you want it to take 5 arguments of any type?
06:32:06 <BW^-> hpc: yes
06:32:12 <hpc> that would be a -> b -> c -> d -> e -> Whatever
06:32:14 <Axman6> i think the point is that you use it when say you're calculating a value in another thread and passing it using an MVar/Char, and you've got the exception handling code in the forked thread. you call evaluate on it to make sure exceptions are thrown at the right time
06:32:18 <mauke> f _ _ _ _ _ = ()
06:32:40 <Axman6> f _ _ _ _ _ = undefined
06:32:43 <BW^-> hpc,mauke: so you can code haskell without defining types for each argument/variable/return type, ro?
06:32:44 <BW^-> or?
06:32:49 <hpc> :t let f _ _ _ _ _ = () in f
06:32:49 <lambdabot> forall t t1 t2 t3 t4. t -> t1 -> t2 -> t3 -> t4 -> ()
06:32:51 <Axman6> seems to better match the question :P
06:32:51 <mauke> what do you mean by "defining types"?
06:33:10 <hpc> BW^-: you can make it polymorphic
06:33:17 <hpc> BW^-: look at const, for example
06:33:18 <Axman6> BW^-: if you leave the types out, they will be inferred
06:33:19 <hpc> :t const
06:33:19 <lambdabot> forall a b. a -> b -> a
06:33:21 <hpc> @src const
06:33:21 <lambdabot> const x _ = x
06:33:21 <mauke> I think it's much simpler
06:33:53 <BW^-> mauke: i mean without mentioning in the code what type must be passed / returned - it could be any
06:34:03 <BW^-> axman6: always, no exception?
06:34:04 <hpc> oh, that's inference
06:34:05 <mauke> BW^-: yes, that Just Works
06:34:14 <mauke> BW^-: ok, there are exceptions
06:34:19 <BW^-> mauke: like what?
06:34:20 <BW^-> hmm
06:34:25 <mauke> polymorphic recursion and various extensions to H98
06:34:27 <hpc> the Dreaded Monomorphism Restriction
06:34:30 <Axman6> :t let f x y z = (z, y) in f
06:34:30 <lambdabot> forall t t1 t2. t -> t1 -> t2 -> (t2, t1)
06:34:43 <BW^-> hpc: what's it about?
06:34:56 <mauke> :t pi
06:34:57 <lambdabot> forall a. (Floating a) => a
06:34:57 <sshc> I have a deeply nested dependency (executable depends on A, which depends on B, which depends on C, etc.), and having to rebuild each one of those tends to be tedious.  If I dynamically link the executable and build shared libraries, will I be able to skip rebuilding all the intermediate libraries?
06:35:14 <BW^-> hmhm ok
06:35:36 <mauke> BW^-: when you just put 'x = pi' in a file, it will make x a Double, basically
06:35:38 <Axman6> sshc: only things that have changed or rely on things that have changed should be recompiled
06:35:43 <mauke> but pi itself is more general
06:35:52 <BW^-> axman6: the way to force evaluation you proposed (WHNF), is this an "all-round" solution using which i could ultimately make an app completely strictly evaluated ??
06:35:55 <BW^-> aaalmost at least
06:36:07 <mauke> this can be avoided by adding a tytpe signature to x or disabling the MR
06:36:09 <BW^-> i.e. bring its evaluation order to the same as in a strict language i.e. javascript and alike
06:36:34 <Axman6> BW^-: you're asking to very different and unrelatyed questions, pick one, and stick to it until you've got the answer you want :P
06:36:40 <Axman6> I'm going to sleep
06:36:48 <BW^-> axman6: i have lots of questions
06:36:49 <BW^-> :)
06:37:14 <sshc> Axman6: The problem is that I have to reconfigure (and re-build-and-install) each of the libraries higher in the hierarchy, because otherwise GHC considers those packages to be broken and won't expose them.
06:37:33 <BW^-> mauke: aha.. hm.. could it being Double make a problem?   how avoid witha type signature,   would there be any problem with disabling the MR?
06:38:28 <hpc> BW^-: polymorphic top-level values have to be recomputed when they take a different type
06:38:36 <hpc> or sometimes if they take the same type, i don't really know
06:38:47 <hpc> the MR stops the recomputation at the price of polymorphism
06:39:15 <Saizan> s/polymorphic/with a typeclass context in their type/
06:39:24 <hpc> yeah, that
06:39:28 <BW^-> hmhm ok
06:39:44 <hpc> you just have to be a bit more careful, if your thing needs speed
06:39:46 <BW^-> does GHC/other haskells typically have some kind of command line prompt / REPL?
06:39:50 <hpc> yes
06:39:51 <hpc> ghci
06:40:03 <BW^-> where you feed code live into the environment with the full power of compiled code basically
06:40:08 <BW^-> and get the responses printed out
06:40:09 <hpc> ghci is the quintessential example of how to make a kickass REPL
06:40:10 <BW^-> immediately
06:40:21 <ndrsndrs> also: sorry if someone already said this, but i didn't see; the times that the MR kicks in are definitions with no arguments
06:40:47 <hpc> (arguments here is used very specifically)
06:40:52 <aristid> BW^-: ghci does not compile code, it interprets it. but you can load compiled code into ghci, so you have the full haskell environment available
06:40:58 <hpc> (f x = x has arguments, while f = \x -> x does not
06:40:59 <hpc> )
06:41:10 <ndrsndrs> so `f = (+ 3); g x = x + 3' => f :: Int->Int; g :: Num a => a -> a
06:41:12 <ndrsndrs> yes, sorry
06:41:15 <BW^-> hmhm ok
06:41:17 <ndrsndrs> i mean, arguments on the LHS
06:41:52 <BW^-> would you say that you can force strictness in evaluations as much as to give excellent control of an app's CPU/RAM characteristics, without cluttering the code?
06:42:10 <opqdonut> yes
06:42:14 <BW^-> how?
06:42:22 <opqdonut> but mostly it's not necessary, or can be done by just choosing the right data structures
06:42:34 <hpc> it's complicated, and can sometimes be a bit voodoo
06:42:42 <opqdonut> that too
06:42:43 <opqdonut> but so called "bang patterns" are a nice way of introducing strictness
06:42:46 <BW^-> hpc: why complicated, why voodoo?
06:42:52 <hpc> the strictness of a thing depends on the strictness of what calls the thing
06:43:11 <hpc> so you can have a big list that is difficult to generate
06:43:15 <hpc> call it bigList
06:43:21 <BW^-> aha right
06:43:24 <opqdonut> BW^-: also, GHC is pretty good at doing strictness analysis. this partially obviates the need for manual annotations
06:43:27 <hpc> and "print bigList" will work swimmingly
06:43:36 <hpc> but "print (last bigList)" will stack overflow
06:43:38 <BW^-> yes obviously at the root of your evaluation something needs to force/make the thing eval
06:43:59 <BW^-> hm ok
06:44:15 <BW^-> ast stack overflow, what happens, the app prints "Stack overflow" and terminates to the OS and that's it?
06:44:19 <BW^-> *at stack o..
06:44:23 <hpc> pretty much
06:44:35 <BW^-> is there any way around it?
06:44:44 <mauke> allocate more stack first
06:44:46 <hpc> profiling and tweaks
06:45:16 <hpc> and more stack, though in my experience, running out of stack means *RUNNING OUT OF STACK*
06:45:33 <BW^-> ok
06:45:52 <BW^-> is the profiler a combined debugger?
06:46:09 <hpc> don't think so
06:46:12 <BW^-> i mean, could you make it provenly stop right at the stack overflow thing and show you the complete state of the app there
06:46:19 <BW^-> so you could easily resolve what to fix
06:46:35 <Saizan> running out of stack usually means there's something wrong with your code, though there are times where you're just going to use the heap instead (if you don't want to use a larger stack)
06:46:50 <BW^-> ah..
06:46:59 <BW^-> there is a stack-heap distinction? what's it about?
06:47:15 <BW^-> local variables are on the stack, separately allocated on the heap, or what?
06:47:18 <hpc> iirc, the stack is for thunks and the heap is for things that you save to use
06:47:22 <sshc> Agh, I spent all day yesterday installing the packages I need (they took much longer than usual to build and install), and now I need to reinstall them because of a bunch of dependency problems.
06:47:40 <BW^-> hpc: thunks and their local vars?
06:47:42 <hpc> or rather, stack is for thunks currently being evaluated
06:47:46 <mauke> local variables, how cute
06:47:46 <opqdonut> sshc: that's cabal for you... I just had to recompile the world with profiling
06:47:56 <Saizan> BW^-: the stack is basically recording what demanded the forcing of the current thing that's being evaluated
06:48:01 <opqdonut> sshc: and there's no automated way for that, one just has to try and see what it complains about next
06:48:03 <BW^-> aha
06:48:12 <Saizan> thunks live on the heap. the stack might have pointers to those
06:48:50 <BW^-> hm ok.. so the stack is more for the evaluator's internal work..
06:48:50 <sshc> opqdonut: Mm, thanks, I'm glad it's cabal's fault
06:49:07 <BW^-> i suppose it's dynamically allocated, so you really never care about it anyhow - stack overflow == heap overflow?
06:49:19 <hpc> BW^-: no; the two are different
06:49:34 <sshc> Not glad that cabal has those issues.
06:49:35 <sshc> 1
06:49:36 <Saizan> the stack is separate, and artificially limited
06:49:38 <hpc> unless you are running the haskell program over your entire RAM, and the stack and heap collide :P
06:49:50 <BW^-> hpc,saizan: how come, why?
06:50:01 <hpc> no idea
06:50:14 <hpc> this is getting too close to implementation details for me
06:50:22 <BW^-> aha.. i understand..
06:50:33 <BW^-> though generally i suppose it's autoconfigured and you don't need to care anyhow?
06:50:48 <opqdonut> mostly you don't need to care. if you get a stack overflow there's a bug
06:50:57 <BW^-> k
06:51:08 <BW^-> if you get heap overflow, does the app terminate always then also?
06:51:14 <Saizan> yes
06:51:23 <BW^-> ok
06:51:30 <BW^-> so no way to catch it, it's always fatal.. hm k
06:51:30 <Saizan> well, you can catch the exception, if you want
06:51:30 <hpc> from what i hear, in C you can recover from a heap overflow?
06:51:39 <hpc> ie, by just not allocating, or waiting to allocate
06:51:42 <BW^-> hpc: malloc returns null i think
06:51:49 <mauke> hpc: not really
06:51:54 <BW^-> hpc: so you do whatever you want to, the OS said no that's it :)
06:52:07 <mauke> BW^-: has that ever happened to you?
06:52:13 <Saizan> http://www.haskell.org/ghc/docs/latest/html/libraries/base-4.3.1.0/Control-Exception.html#t:AsyncException
06:52:24 <mercury^> You can try allocating again later, or do something else instead.
06:52:26 <BW^-> mauke: i didn't try, i admit
06:52:27 <mauke> C itself doesn't specify stack/heap
06:52:35 <BW^-> but i know c-based environments that can handle heap overflows
06:52:41 <mauke> in practice, the stack is protected against overflow by a bad hack
06:52:52 <mercury^> For example if you have another algorithm that does not need space you can use that instead.
06:52:59 <mauke> linux will by default "overcommit" memory
06:53:10 <mauke> meaning malloc will never return NULL in practice
06:53:17 <BW^-> saizan: so if there's a heap overflow i could catch the exception and handle it that way in several cases.. though if stack overflow it always terminates. k
06:53:33 <hpc> mauke: ew
06:53:35 <BW^-> mauke: you mean it'll eat all swap space first?
06:53:38 <mauke> you just get killed if you try to access it while there's no real memory available
06:53:52 <mercury^> mauke: that is not true.
06:53:54 <BW^-> mauke: oh
06:53:57 <BW^-> aha?
06:54:02 <Saizan> BW^-: stack overflow throws an exception too, it seems
06:54:11 <BW^-> saizan: aha k nice
06:54:16 <hpc> apparently GHC doesn't throw heap overflow exceptions?
06:54:23 <mercury^> malloc will return 0 on linux and you never get terminated for accessing memory returned by malloc
06:54:23 <mauke> mercury^: what happens?
06:54:34 <Saizan> stack overflow should cure itself with an exception :)
06:55:03 <BW^-> i've read complaints about that in real-world haskell apps you end upp juggling with monads = a mess. what do you say about this?
06:55:14 <hpc> not a mess
06:55:22 <aavogt> the real world could be a mess
06:55:25 <mm_freak> mauke: on a 32 bit system try to allocate 3 GiB two times
06:55:36 <mauke> mercury^: http://www.gnu.org/software/gnusound/Documentation/ar01s05.html#id2572059 http://www.mjmwired.net/kernel/Documentation/vm/overcommit-accounting
06:56:16 <mauke> mm_freak: that proves nothing
06:56:45 <hpc> monads are only ugly if you make them ugly
06:56:46 <mm_freak> mauke: it shows that overcommitment has its limits, too, so malloc can fail
06:57:04 <BW^-> aavogt: how, why?
06:57:15 <BW^-> hpc: why not?
06:57:27 <mauke> mm_freak: yes, but in practice you won't allocate a single GB object
06:57:49 <hpc> BW^-: here's an example of decidedly not-ugly moandic code: http://98.169.17.243:8000/blog/view.cgi?id=5
06:57:52 <mauke> BW^-: what's a monad?
06:57:57 <mercury^> mauke: on my system at least overcommit is not enabled.
06:57:58 <hpc> and more: http://98.169.17.243:8000/blog/view.cgi?id=9
06:58:20 <mauke> mercury^: I said "by default"
06:58:24 <BW^-> aavogt,hpc: i got the impression something like this.. if you want to combine several pieces of code that each have sequential order to them, and make a bigger composition of these pieces that has a sequential aspect to it in the big whole, then there'd at some point be a mess, with the increasing complexity of your code.. something like that.. what do you say?
06:58:24 <mm_freak> mauke: if your program runs amok, it can happen…  just that in C heap overflows are far less common than in haskell
06:58:54 <BW^-> mauke: a monad is a way to make stateful behavior without doing any mutation
06:59:02 <mm_freak> BW^-: no
06:59:07 <mauke> BW^-: that sounds ... weird
06:59:07 <BW^-> not?
06:59:10 <hpc> BW^-: sounds like you have been listening to someone who doesn't know how much haskell
06:59:14 <BW^-> or.. that's a use, no?
06:59:16 <BW^-> hehe
06:59:17 <Jafet> Overcommit exists because some silly programs need it to be
06:59:21 <mauke> BW^-: the type "list" is a monad
06:59:25 <BW^-> well, this is why i'm here now obviously :)
06:59:27 <mauke> BW^-: so are functions
06:59:27 <mm_freak> BW^-: that's just one of the many applications of the monad concept
06:59:29 <Feuerbach> mercury^: "on my system at least overcommit is not enabled" differs from "malloc will return 0 on linux and you never get terminated for accessing memory returned by malloc"
06:59:53 <hpc> BW^-: learn you a haskell is the site for you v
06:59:55 <hpc> @where lyah
06:59:55 <lambdabot> http://www.learnyouahaskell.com/
07:00:00 <hpc> ^
07:00:14 <jkarlson> Feuerbach: you still may run out of memory by stack allocations
07:00:28 <mercury^> Feuerbach: as I have not disabled it specifically, it seemed a reasonable assumption that my system behaves as if it were a default.
07:00:44 <mm_freak> BW^-: you can use monads to express even complicated control flow naturally
07:00:50 <jkarlson> I think linux doesn't allocate mmaps even if you set overcommit to 0
07:01:02 <jkarlson> I don't think...
07:01:03 <mauke> mercury^: you said "never", not "by default"
07:01:15 <BW^-> so what's the ultimate definition of a monad?
07:01:22 <BW^-> from your perspective
07:01:41 <mauke> BW^-: a type constructor M with two operations, return :: a -> M a and (>>=) :: M a -> (a -> M b) -> M b
07:01:55 <mercury^> It also has to satisfy some constraints…
07:02:04 <Jafet> @quote monads.are
07:02:04 <lambdabot> psykotic says: [monads aren't hard] they're just monoids on the category of endofunctors over some category, what's the big deal?
07:02:07 <BW^-> mauke: i can't read haskell syntax as of yet, if you want to you can explain that :)
07:02:16 <mauke> BW^-: what's the point?
07:02:21 <aavogt> BW^-: if you write the separate pieces with some concrete Monad, like    ReaderT r IO, StateT s IO,  and then need to combine the two that's a bit of noise
07:02:51 <mm_freak> BW^-: imagine a C++ where you can overload the operators '=' and ';' in combination
07:03:10 <mm_freak> that's about how monads would look like in C++
07:03:33 <aavogt> you could push that noise into those individual definitions by writing those definitions with type      (MonadReader r m, MonadIO m) => m ...
07:03:39 <BW^-> hmm
07:03:40 <aavogt> assuming you use mtl
07:03:52 <mauke> mm_freak: I think that would be "do" notation
07:04:03 * aavogt may have the parameters wrong on that class
07:04:04 <mm_freak> mauke: exactly
07:04:07 <timestart> can someone explain this error i'm getting with GADTs? http://hpaste.org/44907/odd_type_error?pid=44907&lang_44907=literatehaskell
07:05:15 <BW^-> hmhm ok
07:06:06 <BW^-> a separate question, is there anything like parameterization in haskell? i.e., you pass a value "silently" within the current environment..   http://98.169.17.243:8000/blog/view.cgi?id=5 writes that he needs to pass around the database handle everywhere and that that is a pain, though if there's parameterization that'd not be needed.. just make a parameter and pass the right handle in it everywhere
07:06:18 <mm_freak> > do x <- [10,20,30]; y <- [x-1, x+1]; guard (y /= 21); return y
07:06:19 <lambdabot>   [9,11,19,29,31]
07:06:24 <aavogt> arguing over what is a monad isn't addressing how to organize programs
07:06:37 <opqdonut> BW^-: the reader monad is a way of doing that
07:06:45 * hackagebot attoparsec-iteratee 0.2.1 - An adapter to convert attoparsec Parsers into blazing-fast Iteratees  http://hackage.haskell.org/package/attoparsec-iteratee-0.2.1 (GregoryCollins)
07:06:56 <opqdonut> it represents an environment that's accessible everywhere
07:07:04 <mm_freak> BW^-: that would be a state or reader monad
07:07:19 <aavogt> @hackage reflection is broken (?) with the most recent ghc, but there's also -XImplicitParams on ghc
07:07:19 <lambdabot> http://hackage.haskell.org/package/reflection is broken (?) with the most recent ghc, but there's also -XImplicitParams on ghc
07:07:19 <BW^-> hm ok
07:07:45 <BW^-> what's the variable scoping in haskell like? i know of C:s, javascript/php:s and scheme's as of yet
07:07:51 <Saizan> timestart: i'd ask on the ghc users list, it's either an infelicity or a bug of type checking
07:08:02 <mauke> BW^-: C's and scheme's scoping is the same
07:08:12 <mauke> javascript and php are similar
07:08:12 <aavogt> BW^-: ModuleName.variableName
07:08:22 <mauke> BW^-: haskell is like C/scheme
07:08:31 <BW^-> mauke: yes, except for that in scheme you easily create new scopes..
07:08:36 <BW^-> hm
07:08:38 <BW^-> hm
07:08:38 <mauke> BW^-: just like in C
07:08:39 <BW^-> maybe not true
07:08:47 <mm_freak> BW^-: there are global variables and pattern matching, basically
07:08:49 <BW^-> right, as in c you can always do { } - which creates a new scope
07:08:56 <mauke> (and unlike pascal)
07:09:10 <mm_freak> and let and where
07:09:12 <mauke> hmm, I think pascal's scoping is mostly like javascript
07:09:19 <BW^-> hm k
07:09:34 <mm_freak> mauke: javascript has this annoying auto-global scoping
07:09:34 <BW^-> within haskell's module system, i suppose the global variables are global within the module..
07:09:47 <BW^-> and any beneficiary module gets access to the globals of another module only if it imports it?
07:09:47 <mm_freak> if you forget to define a variable as local, it gets global
07:10:15 <ion> In Haskell, variable definitions both above and below in the same scope are visible to code.
07:10:20 <mauke> mm_freak: yes, that's a misfeature
07:10:27 <BW^-> hmhm ok
07:10:40 <mm_freak> BW^-: if the source module exports and the destination module imports
07:10:47 <BW^-> mm_freak: k
07:10:49 <ion> (And in parent scopes, of course)
07:11:05 <BW^-> there's only global variables & patterns basically - so the patterns contain the lets and so on for the local variables etc?
07:11:08 <mm_freak> ion: except for 'do' notation
07:11:16 <mm_freak> unless you use recursive do
07:11:18 <ion> mm_freak: Well, it’s not the same scope.
07:11:25 <ion> Even if the indentation matches.
07:11:56 <ion> It’s basically sugar for lambdas within lambdas.
07:12:06 <BW^-> ion: the pattern matching?
07:12:13 <mm_freak> ion: well, in many cases there would be nothing wrong, so a way around that would be nice
07:12:20 <ski> timestart : .. strange
07:12:46 <aavogt> @undo do Just y <- x; y
07:12:46 <lambdabot> x >>= \ a -> case a of { Just y -> y; _ -> fail ""}
07:12:47 <BW^-> hm ok
07:13:02 <BW^-> data type definitions, can they be global and local also?
07:13:11 <BW^-> i.e., is Everything scoped?
07:13:16 <aavogt> @where report
07:13:16 <lambdabot> http://www.haskell.org/onlinereport/
07:13:22 <mm_freak> ion: i often have a function, of whose arguments i calculate something to pass to a local function…  if i define that function using 'let', i don't have to pass them
07:13:26 <mm_freak> with 'where' i have to
07:13:33 <mm_freak> slightly annoying, but i can live with that
07:13:41 <c_wraith> BW^-: data type definitions can only be at the top level within a module.  they don't need to be exported by the module, though
07:14:12 <ion> It wouldn’t mind local data type definitions. They would be useful in ghci and with lambdabot. :-)
07:14:13 <BW^-> c_wraith: k
07:14:23 <BW^-> :)
07:14:45 <BW^-> in C++ sometimes you get PITS type incompatibilities between libraries you use.. i believe even for strings this exists
07:14:54 <mm_freak> i'd have a lot of uses for local datatypes
07:15:03 <mm_freak> they would be a great feature
07:15:08 <aavogt> > let f x = r where y = x+1; r = y + 1 in f 0
07:15:08 <lambdabot>   2
07:15:34 <BW^-> with haskell's type system, are there occasions when two types that are basically the same thing, require lots of wrapper code and CPU force, to convert between the two?
07:15:35 <ski> BW^- : unfortunately local data type (and class and instance) declarations are not allowed (yet, at least)
07:15:46 <aavogt> mm_freak: in that code, what is different from you 'where' issue?
07:16:03 <mm_freak> BW^-: those are the cases where i use the ScopedTypeVariables extension
07:16:10 <c_wraith> BW^-: conversion between isomorphic types is usually cheap, if not free
07:16:13 <mm_freak> almost 90% of my code uses it
07:16:35 <ski> mm_freak : `let' vs. `where', in conjunction with `do' ?
07:16:50 <mm_freak> ski: mostly, but not always
07:17:15 <ski> *nod*, sometimes it's lambdas
07:17:21 <BW^-> hm ok
07:17:29 <ski> (or list comprehensions, i suppose)
07:17:35 <mm_freak> global x = let y = f x in local y   where local = …
07:18:00 <BW^-> i didn't grasp haskells type system yet - so i got you can make enums, and you can make records and lists with particular types specified for the slots.
07:18:19 <mm_freak> alternatively i can define 'y' in the 'where' clause or 'local' in the 'let' clause, but that's ugly
07:18:19 <BW^-> can you store closures in variables?
07:18:25 <mm_freak> BW^-: yes
07:18:28 <BW^-> k.
07:18:46 <mm_freak> BW^-: there is no difference between 'function' and 'value'
07:18:49 <BW^-> can you define method kind of procedures?
07:18:53 <mm_freak> functions are a value of a specific type
07:18:55 <dankna> BW^-: yes, but bear in mind that it's not really a closure in the Lisp sense because there's no possibility to mutate captured bindings (because there's no possibility to mutate anything)
07:19:01 <ziman> hello, why is (f longList = \y -> y + avg where avg = average longList) much more efficient than (f longList y = y + avg where avg = average longList)? It obviously memoizes the average — but why? Is there a general rule why this works that way?
07:19:08 <BW^-> dankna:
07:19:08 <BW^-> k
07:19:30 <BW^-> mm_freak: do they (closures/procedures) have a common type name?
07:19:33 <aavogt> mm_freak: it's ugly to not mix let and where?
07:19:36 <mm_freak> BW^-: if you mean to use OOP in haskell, you can, but you don't get C++-like polymorphism easily
07:19:39 <mauke> BW^-: do you mean... functions?
07:19:52 <BW^-> mauke: yes, both that don't close and that close over variables
07:19:54 <ziman> well — the usage is to call (f myLongList) many times
07:20:08 <mauke> BW^-: how is that a useful distinction?
07:20:16 <mm_freak> aavogt: yes, because i like to separate functions from what they are used for
07:20:29 <aristid> ziman: f myLongList can share the (lazy) avg value in the first version. there is no sharing in the second version
07:20:36 <mm_freak> 'where' for helper functions, 'let' for the actual expression
07:20:56 <aristid> ziman: and GHC mostly refrains from sharing automatically because it also has disadvantages (not in this case)
07:21:29 <rwbarton> ziman: it might help to rewrite with 'let' if it's not clear why there is a difference in sharing
07:21:36 <BW^-> mm_freak: c++-like polymorphism, as in class inheritance and interfaces?
07:21:45 <mm_freak> BW^-: as in overloading
07:21:47 <mauke> since when does C++ have interfaces
07:22:08 <hpc> mauke: since you can make a constructor crash the program?
07:22:09 <BW^-> ah sorry.. java does
07:22:18 <mm_freak> mauke: in C++ an "interface" is just a class, because you have multi-inheritance
07:22:58 <BW^-> mm_freak: aha.. hm. does haskell have multiple dispatch?
07:23:13 <mauke> BW^-: wouldn't it be easier to just learn haskell?
07:23:33 <mm_freak> BW^-: you can emulate all features in haskell, but if you want to do OOP, then it's better to use an OOP language
07:23:33 <hpc> a language is not the sum of its features
07:23:45 <mm_freak> haskell is a multi-paradigm language, but OOP is one of its weaker ones
07:24:16 <BW^-> mm_freak: ah no no.. i'm not looking for that necessarily.. i'm just trying to get a clue of what haskell is like
07:24:31 <hpc> BW^-: haskell is like math that runs on a computer
07:24:32 <mm_freak> BW^-: functional programming is its main paradigm
07:24:35 <hpc> question answered :P
07:24:35 <BW^-> heard a lot and read certain things, but didn't really get it, that kind of thing
07:24:54 <mauke> BW^-: now you're reading more things
07:25:03 <mauke> I think to really get it, you need to do it
07:25:03 <hpc> BW^-: the only way to "get it" is to learn the language and see what you can do with it
07:25:05 <ski> ziman : the difference is between `let avg = ... in \y -> ..y..avg..' and `\y -> let avg = ... in ..y..avg..'
07:25:08 <BW^-> hehe. i know scheme very well so i know a lot of the concepts.
07:25:52 <mauke> (wait until you've seen constructor classes and return type based overloading)
07:26:03 <mauke> .oO( and oleg teleporting values through the type system )
07:26:11 <mm_freak> BW^-: haskell programming uses a compositional style…  mostly you take computations and compose them…  at the end you pass some value into that composition, which makes one of your program components or the final program
07:26:28 <ion> mauke: Teleporting values through the type system? URL/reference please. :-)
07:27:21 <c_wraith> Isn't that implicit parameters?
07:27:24 <mauke> ion: http://okmij.org/ftp/Haskell/types.html#Prepose  http://mauke.dyndns.org/stuff/papers/prepose.pdf
07:27:27 <ion> Thanks
07:27:46 <BW^-> mm_freak: i'm with you
07:27:46 <mm_freak> ah, reflection and reification
07:28:13 <mm_freak> i've read that, and it sounds great, but i'd rather use a state/reader monad
07:28:14 <BW^-> what's the upper limit for what haskell's type system can describe? i mean, at what level of complexity of data does the code needed to describe it become cluttered
07:28:33 <ziman> ski, how simple, thanks!
07:28:40 <ziman> aristid, rwbarton, thank you too
07:29:13 <mm_freak> BW^-: well, i don't see any limits
07:29:41 <BW^-> mm_freak: what about trees of all kinds of different types for instance :) maybe that'd be a tree of the Dynamic type ..
07:29:43 <mm_freak> if the object described is complicated, then its code may be complicated, too, unless you — again — use composition
07:29:51 <mm_freak> nope
07:30:00 <mm_freak> read about existential types
07:30:06 <BW^-> k
07:30:09 <ion> Some languages have more expressive types. For instance, you can’t use Haskell’s type system to restrict a value into natural numbers between 0 and 42.
07:30:16 <mauke> does anyone actually use Dynamic in real code?
07:30:23 <hpc> mauke: i hope not
07:30:31 <BW^-> hehe k.
07:30:56 <BW^-> do you view haskell's type system as the perfect one, in 50 years it'll be the same? or do you see value of any developments?
07:31:02 <mm_freak> mauke: never did
07:31:10 <mauke> BW^-: it's far from perfect
07:31:19 <mauke> but I don't think there is a perfect type system
07:31:32 <ion> Except in C, of course.
07:31:35 <mm_freak> BW^-: if it were perfect, we wouldn't have the numerous type system extensions
07:31:43 <mauke> you have to balance various contradicting factors
07:32:00 <mm_freak> BW^-: but it's probably nearer to perfection that most languages used in the real world
07:32:30 <geheimdienst> to me, the important thing is the type system is way more helpful than the one of c#, java, or the like
07:32:48 <BW^-> hmm k.. what can you see as possible imperfections? what's the system extensions typically about?
07:33:21 <mm_freak> BW^-: i mostly use TypeFamilies, ScopedTypeVariables and sometimes RankNTypes
07:33:40 <mm_freak> occasionally i also need FlexibleInstances and FlexibleContexts
07:34:04 <ski> @where+ prepose "Implicit configurations -- or, type classes reflect the values of types" by Oleg Kiselyov,Chung-chieh Shan in 2004-08 at <http://okmij.org/ftp/Haskell/types.html#Prepose>,<http://mauke.dyndns.org/stuff/papers/prepose.pdf>
07:34:04 <lambdabot> I will remember.
07:34:13 <mm_freak> but unless you know and understand the type system i can't explain what those extensions are about
07:37:40 <BW^-> thanks guys.. brb45min
07:38:49 <ion> Hehe, the source of Data.Dynamic is pretty. “blahblah unsafe blahblahblah unsafe blah unsafe blahblahblah unsafe blah”
07:38:54 <ion> (as expected)
07:39:56 <ourfrank> Hi, I'm using gtk. How do I set an event handler for when a button is clicked? How do I unset that handler?
07:40:34 <ourfrank> I see the onClicked function is deprecated.
07:44:44 <ourfrank> Okay, so setting a click handler is done like this: (button `on` buttonClicked $ ioAction)
07:45:19 <ourfrank> However, I still don't know how a click handler is "unset", or deleted.
07:47:24 <ski> ourfrank : maybe you also want to try with #xmonad ?
07:47:44 <ski> (or maybe i was guessing wrong)
07:47:59 <aavogt> xmonad doesn't use gtk
07:54:11 <ourfrank> Ah, I've found it. These functions are defined in System.Glib.Signals, in case anyone from the future is wondering.
07:54:58 * Jafet hopes to whatever god there is that gtk won't be the future.
07:55:44 <ManateeLazyCat> Jafet: What are you talking about? :)
07:57:56 * hackagebot hsini 0.1 - Package for user configuration files (INI)  http://hackage.haskell.org/package/hsini-0.1 (MagnusTherning)
08:03:49 <ski> aavogt : ah, ok
08:06:20 <monochrom> death is the future.
08:07:37 <c_wraith> Death is just a feeling
08:08:04 <sipa> or rather the lack thereof
08:16:24 <edon> it isn't possible on one STM to write TVar 'x' and wait on TVar 'y', while another thread reads 'x' does some IO and writes back on 'y'? It seems like the thread waiting on 'y' doesn't allow the other thread to do io and write on 'y'. 
08:17:41 <paolino> TChan y
08:17:53 <paolino> ?
08:18:40 <paolino> how you wait a TVar ?
08:19:51 <gwern> so, anyone want to read and review http://www.gwern.net/haskell/Archiving%20GitHub.html ?
08:19:58 <Cale> What would it mean to wait on a TVar?
08:20:03 <edon> paolino: oh sorry, it's a TMVar, not a TVar
08:20:06 <Cale> ah
08:20:45 <Cale> edon: Well, if a TMVar is empty, then reading it will cause a retry of the transaction.
08:20:46 <paolino> never seen a TMVar, is it in STM ?
08:20:51 <Cale> yes
08:21:23 <Cale> http://hackage.haskell.org/packages/archive/stm/2.2.0.1/doc/html/Control-Concurrent-STM-TMVar.html
08:22:05 <paolino> oh, I always did that by hand, good to know
08:22:38 <Cale> edon: What idea are you trying to represent here? You could separate it into 2 transactions in each thread, but then you might as well be using plain MVars
08:23:41 <paolino> edon, that will livelock, because you never write to TVar x
08:24:37 <rwbarton> this basically can't be possible by the definition of atomically.  For example, how do we know that "some IO" won't kill the thread
08:25:00 <gwern> @pl f x = "https://github.com/languages/Haskell/created?page=" ++ show x
08:25:00 <lambdabot> f = ("https://github.com/languages/Haskell/created?page=" ++) . show
08:25:21 <opqdonut> huh?
08:25:45 <edon> Cale: yes, i don't want to show the intermediate state, so i want to atomically write 'x', and read 'y'. While another thread reads 'x' writes on 'y'. But the second thread doesn't seem to be able to read it.
08:26:19 <paolino> edon, atomic operations are sequential
08:26:57 <rwbarton> in order for the atomic operation to happen, 'y' has to already have a value, but how can you ever get to that point
08:27:18 <paolino> but there is no way to order those 2
08:29:06 <rwbarton> I'm assuming you have somethink like atomically $ do { write x; read y } vs. do { atomically (read x); some other stuff; atomically (write y) }
08:30:03 <rwbarton> if so there's no way for either atomically statement to progress
08:30:15 <rwbarton> because, well, they're atomic
08:30:19 <edon> ah i see, i should obviously think this through, thanks guys :)
08:33:52 <Palmik> Interesting, hayoo finds a lot more functions than hoogle
08:34:47 <jmcarthur> hayoo searches hackage
08:35:00 <MasseR> Wherein hoogle search a few packages besides base
08:35:02 <gwern> @hoogle (a,b,c) -> b
08:35:02 <lambdabot> Data.Typeable typeOf3 :: Typeable3 t => t a b c -> TypeRep
08:35:02 <lambdabot> Data.Typeable typeOf2Default :: (Typeable3 t, Typeable a) => t a b c -> TypeRep
08:36:08 <Palmik> MasseR, I see, thanks 
08:36:14 <ManateeLazyCat> It's absurd, #debian kick me just i use Ubuntu?
08:36:38 <Palmik> the weird thing is, that I can for example find the package on hoogle, but not it's functions
08:36:45 <Palmik> but on hayoo I can
08:36:50 <paolino> Data.Tuple.Utils.snd3:: (a, b, c) -> b
08:38:09 <paolino> ManateeLazyCat: don't tell them
08:38:59 <ManateeLazyCat> paolino: I just ask a question at #debian, but not about Debian or Ubuntu, just a tool problem, the administrator kick me out after i said i use Ubuntu.
08:39:01 <ManateeLazyCat> It's wrong?
08:39:30 <Palmik> Kick ManateeLazyCat, he uses Ubuntu!
08:39:33 <hpc> #debian is for debian questions :P
08:39:34 <Palmik> :D
08:39:57 <ManateeLazyCat> hpc: But i'm not ask question about Ubuntu speical problem. 
08:40:05 <hpc> i use ubuntu, but only because somehow it's the only thing that can get networking to work on this laptop
08:40:09 <ManateeLazyCat> hpc: I just ask any "server speed test tool". 
08:40:34 <paolino> debian licence was too liberal , if these are the effects
08:40:58 <ManateeLazyCat> hpc: I don't care war between Ubuntu and Debian, i just ask a very basic problem, any system can use, debian administrator can't do that.
08:41:26 <hpc> but #debian wouldn't be the place for those questions, because it isn't debian-specific
08:41:39 <Palmik> Just get over it and ask the question elsewhere :)
08:41:41 <ManateeLazyCat> hpc: What? 
08:42:01 <hpc> if any system can use what you are asking about, it isn't a debian question
08:42:19 <hpc> just like you wouldn't be asking for C++ help here
08:42:19 <ManateeLazyCat> hpc: But he can't kick me out.
08:42:35 <opqdonut> I'd guess the #debian folk are sick and tired of people asking ubuntu questions
08:42:43 <opqdonut> that might be the reason for the aggressive reaction
08:42:44 <ManateeLazyCat> hpc: I ask a .deb tool that not debian-sepcial problem? 
08:42:59 <ManateeLazyCat> hpc: I'm not ask how to use rpm package at #debian.
08:43:16 <ManateeLazyCat> I just feeeling it's absurd
08:43:19 <opqdonut> even though ubuntu used .deb packages, it is _not_ debian
08:43:29 <hpc> ^
08:43:41 <opqdonut> many things work differently in ubuntu, and #debian probably has a lot of people asking ubuntu questions
08:43:43 <hpc> ask the question in #ubuntu, if that's the distro you use
08:43:57 <Saizan> anyhow channel operators can do as they please
08:44:53 <paolino> against spammer and offensive people I guess
08:44:57 <hpc> kicking people too lazy to join the right channel is justifiable imo
08:45:06 <ManateeLazyCat> I'm not asking Ubuntu question, i think most .deb package can running on botn Debian and Ubuntu. I'm asking at #debain about .deb tool, because i think people at debian know much more.
08:45:25 <paolino> which is correct
08:45:51 <dankna> I don't think it's correct that .deb packages are agnostic to the distribution they're made for
08:46:14 <hpc> if it were correct, ubuntu wouldn't have its own repos
08:46:44 <ManateeLazyCat> I don't want to talk, bad feeling, i can't join #debian, damn it.
08:46:47 <ourfrank> What is this ".deb tool" you were asking about?
08:46:56 <paolino> I mean it's correct that debian people have more knowledge
08:47:18 <hipsterpumpkin> dankna: sorry to be annoying, but what are your plans regarding the cross-compilation in GHC project? need help with it?
08:47:22 <ion> paolino: What a strange idea.
08:47:35 <ManateeLazyCat> ourfrank: I'm writing package manager, so i want to some tool to test speed of server, so i ask in #debian: which server tool do you use, guys?
08:47:53 <dankna> hipsterpumpkin, my plans are to continue working on it until it's done :) I currently have to rewrite my first patch per the feedback I got on it.
08:47:54 <ManateeLazyCat> Actually, tool to test speed of mirror.
08:48:16 <dankna> hipsterpumpkin, I could absolutely use help although I'm not sure offhand what tasks I can give you to do.  are you experienced at working in very large codebases?  how long have you been using Haskell?
08:48:16 <hipsterpumpkin> dankna: :D
08:48:43 <ManateeLazyCat> ourfrank: And someone ask me which OS i use, i said, Ubuntu, but it's not the key, i just want to listen suggestions from debian guys.
08:48:44 <hipsterpumpkin> couple of years now :) and yeah, have some experience
08:48:58 <hipsterpumpkin> but anyway, just let me know if there's anything you need
08:49:16 <dankna> great!  well, I can probably give you a task or something to do, let's take this to #ghc so people can see it in scrollback
08:49:18 <paolino> ion, debian is a more a system for hackers than ubuntu ?
08:49:31 <ManateeLazyCat> paolino: I don't think so.
08:50:04 <ion> One would think the Ubuntu folks would need to know a *bit* about the system to be able to create a derivative distribution. :-) A lot of the system folks are both Ubuntu *and* Debian developers.
08:50:12 <ManateeLazyCat> paolino: I think Ubuntu do many great work, at least like hpc said, it can make network connect in my laptop
08:51:00 <paolino> then ask #Ubuntu
08:51:16 <ManateeLazyCat> I don't want ask anymore
08:51:19 <ManateeLazyCat> Go to sleep.
08:51:36 <anthony_> hello
08:53:02 <osoleve> could someone help me understand what's wrong with this code?
08:53:05 <osoleve> http://codepad.org/llOP7naX
08:53:52 <hpc> osoleve: the syntax of case is "case expr of pattern -> expr; pattern -> expr;..."
08:54:00 <hpc> a pattern isn't an expression
08:54:09 <parcs> how would one open a file for writing at particular offsets without truncating it? WriteMode truncates the file, and AppendMode disallows seeking...
08:54:18 <hpc> what you want is guards
08:54:32 <osoleve> okay, let me rewrite really quickly
08:54:56 * ManateeLazyCat pasted "above" at http://paste2.org/get/1313616
08:54:57 <ManateeLazyCat> osoleve: ^^^^
08:55:04 <paolino> ReadWriteMode ?
08:55:45 <osoleve> thanks, ManateeLazyCat 
08:55:47 <ManateeLazyCat> osoleve: Like above 
08:55:47 * ManateeLazyCat pasted "above" at http://paste2.org/get/1313619
08:55:48 <ourfrank> osoleve: Also, ['=','<','>'] is the same as "=<>".
08:55:49 <osoleve> and hpc
08:55:55 <ManateeLazyCat> osoleve: http://paste2.org/get/1313619
08:56:09 <ManateeLazyCat> osoleve: Above is correct, i forgot convert -> to =
08:56:34 <ManateeLazyCat> osoleve: You can replace last line with : | otherwise = 5
08:56:36 <parcs> paolino: nope, same as WriteMode
08:57:04 <hpc> you have to replace the last line with otherwise
08:57:07 <hpc> x isn't a Bool
08:57:17 <hpc> @src otherwise
08:57:17 <lambdabot> otherwise = True
08:57:23 <paolino> parcs, what you should read if is truncated ?
08:57:35 * ManateeLazyCat pasted "last version" at http://paste2.org/get/1313620
08:57:36 <osoleve> okay, thanks guys
08:57:36 <ManateeLazyCat> osoleve: Above, last version
08:57:41 <hpc> lol
08:58:00 <paolino> parcs, that is broken
08:58:04 <ManateeLazyCat> hpc: I have IRC edit/copy/upload/comment tool.
08:58:05 <ManateeLazyCat> :)
08:58:33 <ManateeLazyCat> hpc: So fast to modified/share code in IRC. ;) 
08:58:53 <parcs> paolino: the file that i'd open already contains data. i'd like to overwrite some of that data at specific offsets
09:00:40 <ManateeLazyCat> What, paste2.org is down?
09:01:11 <aavogt> > let oso x = fromMaybe 5 $ lookup x $ concat $ zipWith (map . flip (,)) [1..] ["=<>","+-","*/%","^!"] in map oso (concat ["=<>","+-","*/%","^!"])
09:01:12 <lambdabot>   [1,1,1,2,2,3,3,3,4,4]
09:01:12 <ManateeLazyCat> I copy so many code, link is wrong? Maybe paste2.org change url rule.
09:02:03 <mauke> parcs: I'm looking at the code, and it only seems to call truncate if mode == WriteMode
09:02:14 <paolino> parcs: I think  ReadWriteMode is the one, and f it doesn't work it's broken, maybe I'm wrong
09:02:31 <osoleve> aavogt: you just broke me
09:03:00 <ManateeLazyCat> osoleve: Sorry, paste2.org looks change server side,
09:03:07 <ManateeLazyCat> osoleve: My share link is broken.
09:03:29 <osoleve> s'all gravy, i have a working function now :>
09:03:49 <ManateeLazyCat> osoleve: http://pastebin.com/VtbmLtpX
09:03:50 <parcs> hmm, maybe my tests failed. let me try again
09:05:42 <cheater99> is dynamic typing a goodi dea?
09:06:14 <mauke> is it that time again
09:06:19 <copumpkin> cheater99: http://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/
09:06:51 <parcs> paolino, mauke: indeed, you are right. thanks
09:06:58 <paolino> parcs: on my system t works
09:09:24 <parcs> paolino: yep, same here. i didn't correctly interpret the results of my test the first time
09:09:40 <paolino> good
09:10:33 <gwern> Did I miss anything obvious in making the script shorter that isn't in evil golfing territory? http://www.gwern.net/haskell/Archiving%20GitHub.html#the-script-golfed
09:10:48 <cheater99> golfing ...
09:10:54 <BW^-> in ghci, if there's an exception or you press CTRL+C, can you get a copy of the current environment?
09:11:10 <BW^-> i.e. the current value of all variables in all stack frames, something like that, + possibility to introspect them also
09:11:14 <BW^-> from the prompt
09:11:59 <mauke> in the debugger, probably
09:12:42 <BW^-> mauke: which is the debugger?
09:13:04 <mauke> http://haskell.org/ghc/docs/6.10.2/html/users_guide/ghci-debugger.html
09:13:09 <parcs> gwern: you don't need spaces between infix operators
09:13:42 <gwern> parcs: that's a little too far into golfing for me :) I could put everything on one line, I don't 'need' 15
09:13:48 <parcs> also use <$> instead of fmap. it avoids the need for parentheses and is one character shorter
09:13:59 <parcs> also it looks more cryptic ;)
09:14:02 <hpc> and you save the spaces :P
09:14:02 <parcs> gwern: oh i se
09:14:07 <gwern> doesn't <$> require an import?
09:14:10 <hpc> though real men let (.) = fmap
09:14:14 <parcs> yeah
09:14:24 <gwern> parcs: well, then <$> is a net negative then
09:14:47 <hpc> imports count?
09:15:06 * hpc is tempted to make a golf package on hackage now
09:15:16 <hpc> "import Golf" gets you all sorts of cheaty stuff
09:15:19 <gwern> hpc: to my mind, they do
09:15:28 <hpc> lol
09:15:42 <opqdonut> hpc: shouldn't it be import G?
09:15:47 <opqdonut> :P
09:17:57 <hpc> haha
09:26:12 <cheater99> gwern: hey. that's a reeeeeaallly nice article! i like it so much! have you written any more?
09:26:35 <gwern> cheater99: yes, a few are linked in it; the full list is on the toplevel page
09:36:01 <pastorn> in BNFCs regexps, is ('x'|'X') === ["xX"] ?
09:38:25 <ski> i'm not sure, but isn't the square brackets for optional stuff ?
09:38:37 * ski doesn't have BNFC fresh in memory
09:39:08 <pastorn> Char of characters (in single quotes), defined ’\’’ ((char - ["’\\"]) | (’\\’ ["’\\nt"])) ’\’’
09:39:13 <pastorn> ^^^ from the manual
09:39:18 * hackagebot hatt 1.1 - A truth table generator for classical propositional logic.  http://hackage.haskell.org/package/hatt-1.1 (BenedictEastaugh)
09:39:43 <pastorn> i thought it was "one of"
10:28:28 <pastorn> here is one from the C grammar:
10:28:30 <pastorn> token Long ["123456789"] digit * ('l'|'L');
10:28:39 <gwern> cheater99: the top level link is http://www.gwern.net/index.html#computing if you haven't figured it out yet
10:29:47 <ndrsndrs> usually in EBNF, [foo] is an optional foo; i haven't used BNFC but i thought that it used the normal BNF syntax
10:30:08 <ndrsndrs> never mind, i should finish reading the scrollback
10:30:09 <ndrsndrs> sorry
10:40:03 <benmachine> sup guys
10:40:56 <ndrsndrs> hello
10:46:53 * ski . o O ( "inf gals" ? )
10:47:18 <benmachine> :O sexism
10:47:21 <benmachine> ...possibly
10:48:05 <BW^-> do you guys see any language very much like Haskell but which might be more powerful than it in certain respects or whatever, Clean for instance?
10:49:23 <ion> Agda, Erlang.
10:49:28 <BW^-> also, are there any subsets/extensions of the language you find particularly exciting?
10:50:37 <benmachine> some of the extensions to haskell are so widespread as to be almost standard
10:51:26 <Eduard_Munteanu> LOL, well, that's because GHC itself is pretty much the only Haskell compiler for most people :)
10:51:54 <BW^-> benmachine: like whcih?
10:52:06 <benmachine> Eduard_Munteanu: there do exist other compilers
10:52:12 <benmachine> but GHC does have a lion's share of the market
10:52:23 <benmachine> BW^-: eeeerm, not sure >_>
10:52:24 * rtharper would not be able to use Haskell for anything with bang patterns, existential types, rank 2 types..
10:52:32 <Eduard_Munteanu> Sure, but I don't know if they're ready for production use.
10:52:37 <benmachine> bang patterns are easy to "fake"
10:52:50 <rtharper> benmachine: indeed, they're just so sad not to have
10:53:09 <benmachine> I don't actually like them very much :P
10:53:14 <Eduard_Munteanu> rtharper: you mean 'without'
10:53:29 <rtharper> Eduard_Munteanu: sure I do!
10:53:29 <benmachine> they add silly restrictions like not being able to define ! infix
10:53:36 <BW^-> what's the absolute base functionality/syntax of the haskell language? i mean, if you strip most extra libraries and ultimately uneededed stuff in the runtime library away, what's left then?
10:53:42 <rtharper> Eduard_Munteanu: yes, indeed, I do
10:54:06 <rtharper> BW^-: functions and datatype declarations?
10:54:13 <ndrsndrs> benmachine: you can with spaces in the definition
10:54:14 <Eduard_Munteanu> Lambda calculus :P
10:54:15 <rtharper> and type classes!
10:54:21 <Eduard_Munteanu> (some form of it)
10:54:28 <ndrsndrs> `f !x` defines f, `f ! x` defines (!)
10:54:35 <benmachine> ndrsndrs: I actually don't think you can, but I'm willing to be proven wrong
10:55:11 <Philippa_> Eduard_Munteanu: you need let and case too
10:55:26 <ndrsndrs> nevermind
10:55:26 <Philippa_> BW^-: do you need to do any IO?
10:55:31 <ndrsndrs> that used to work, i'm sure...
10:55:52 <Philippa_> (most of the type system stuff is directly necessary, FWIW: you lose expressive power without it)
10:56:42 <ndrsndrs> wait, i'm thinking of the $ in TH. sorry :)
10:56:44 <BW^-> philippa_: without it - no
10:56:57 <osoleve> how do i test that a variable is a number?
10:57:22 <Eduard_Munteanu> osoleve: look at its type?
10:57:33 <ndrsndrs> ...an irc client for emacs? :D
10:57:40 <Eduard_Munteanu> osoleve: what exactly do you mean?
10:58:10 <osoleve> i'm writing a parser, and i need to check if the data passed is a number
10:58:30 <osoleve> so like type a == Num
10:58:32 <osoleve> ?
10:58:33 <Eduard_Munteanu> osoleve: ok, so you want to test whether a string encodes a number?
10:58:38 <ion> Define number. A positive natural number? A decimal number with scientific notation?
10:58:40 <Eduard_Munteanu> osoleve: no, you can't do that.
10:58:57 <osoleve> a positive natural number, for now
10:59:00 <osoleve> keeping it simple
10:59:26 <Eduard_Munteanu> osoleve: you can't have a fully polymorphic 'a' and treat it as a Num.
10:59:37 <benmachine> Eduard_Munteanu: you're answering the wrong question I think :P
10:59:52 <benmachine> osoleve: do you actually need to know what the number *is*, or just check it is a number?
10:59:54 <Eduard_Munteanu> Honestly I don't know what the question is :)
10:59:56 <Philippa_> BW^-: without IO, you need let, case, lambda, abstraction, variables and all the datatype and class machinery
11:00:04 <osoleve> i just need to check that is *is* a number
11:00:13 <benmachine> Philippa_: what is "abstraction" in this context?
11:00:22 <benmachine> osoleve: is 0001 a number?
11:00:23 <Philippa_> oops, I meant to write application :-)
11:00:26 <ndrsndrs> osoleve: what is it currently? a string?
11:00:27 <benmachine> oh right
11:00:45 <osoleve> i'm hopefully going to have it tokenized as a number, but i guess it is a string
11:00:48 <osoleve> sure
11:01:06 <Eduard_Munteanu> osoleve: then it's not something encoded in the type.
11:01:11 <ndrsndrs> then, `all isDigit`?
11:01:18 <benmachine> osoleve: so a string is a number if it is a lot of digits stuck together
11:01:29 <ndrsndrs> or something ReadS related since you'll need the value in a minute anyway
11:01:48 <ndrsndrs> there are some number-parsing things in the Numeric module
11:01:51 <osoleve> okay, what if i assume it is a number and not a string?
11:02:21 <Eduard_Munteanu> This is way too vague.
11:02:37 <osoleve> just... i have a variable, x
11:02:49 <osoleve> i want to check if x is a positive natural number
11:02:51 <Eduard_Munteanu> osoleve: what's its type?
11:02:58 <osoleve> that's what i want to know
11:03:30 <tromp__> no, that's what you decide beforehand
11:03:43 <ndrsndrs> where are you getting this value?
11:03:52 <osoleve> an equation inputted by the user
11:04:37 <Eduard_Munteanu> You could be reading it as a String, or even converting to a number at the same time.
11:04:49 <Eduard_Munteanu> Can you copy-paste some code?
11:04:59 <Eduard_Munteanu> @where hpaste
11:04:59 <lambdabot> http://hpaste.org/
11:05:05 <benmachine> osoleve: user input is basically always a string
11:05:08 <osoleve> it's in its infancy right now
11:05:19 <osoleve> i could give you the scheme code i'm translating, haha
11:05:30 <benmachine> osoleve: you can parse it to a specific kind of number, in which case you will get a type that is "number-or-parse-failure" approximately
11:05:45 <Eduard_Munteanu> osoleve: well the problem isn't the Scheme code, but your approach to encoding the same thing in Haskell.
11:06:31 <osoleve> okay. so given a string, how do i test if it is a number?
11:06:42 <osoleve> is it all isDigit x, as said before?
11:06:54 <Eduard_Munteanu> That should work, albeit only for naturals.
11:07:05 <mauke> matches ""
11:07:05 <ndrsndrs> better Numeric.readDec or so
11:07:05 <osoleve> that's all i want it to work for for now
11:07:13 <osoleve> thanks, sorry for the confusion
11:07:26 <Eduard_Munteanu> > all isDigit "4523556"
11:07:27 <lambdabot>   True
11:07:36 <Eduard_Munteanu> > all isDigit "45yyz23556"
11:07:37 <lambdabot>   False
11:07:40 <osoleve> > all isDigit ""
11:07:40 <lambdabot>   True
11:07:43 <osoleve> crap.
11:07:54 <ndrsndrs> > all isDigit "" && notNull ""
11:07:54 <lambdabot>   Not in scope: `notNull'
11:07:57 <ndrsndrs> derp
11:08:04 <ndrsndrs> > all isDigit "" && not (null "")
11:08:05 <lambdabot>   False
11:08:23 <Eduard_Munteanu> @hoogle read
11:08:24 <lambdabot> Prelude read :: Read a => String -> a
11:08:24 <lambdabot> Text.Read read :: Read a => String -> a
11:08:24 <lambdabot> module Text.Read
11:08:49 <Eduard_Munteanu> (if you want to do the conversion)
11:09:20 <ion> > liftM2 (&&) (all isDigit) (not . null) ""
11:09:22 <lambdabot>   False
11:09:23 <BW^-> how do you anticipate that Haskell will develop the next 10 years, what's the key things that may happen?
11:11:54 <Eduard_Munteanu> Its purpose is world domination. :P
11:15:43 <Eduard_Munteanu> BW^-: but really, you might want to take a look at Agda, Coq or Epigram if you're interested in more research-y languages.
11:18:23 <Philippa_> BW^-: more extensions get standardised, bigger libraries, more attempts to integrate 'faked' dependently-typed programming well syntactically
11:18:49 <Eduard_Munteanu> Yeah, faked dependent types is almost here.
11:18:53 <ourfrank> When looking at arrows, there is (first) and there is (second). Is there an arrow that applies a function to both elements of the tuple? I'm looking for (a b c -> a (b b) (c c)). I know I can make one, but I was wondering if there's an in-built one.
11:19:06 <joe6> any thoughts on this error, please? http://sprunge.us/agAW
11:19:12 <Eduard_Munteanu> Basically that Peano/Naturals sugar.
11:21:02 <benmachine> ourfrank: (f *** g) applies f to the first and g to the second, so (f *** f) does what you want
11:22:10 <benmachine> joe6: it's a bug, probably? you could submit it as it asks or go ask #ghc maybe
11:24:46 <ourfrank> benmachine: I didn't know about that one, but it still requires me to use f twice. I was wondering if there was something like (\a -> first a . second a) already there.
11:24:57 <mwc> What ever happened to the proposal to put some light autoconf functionality into cabal? Stuff like checking to see if a given shared lib/DLL can be linked, and seeing if a particular symbol is in it
11:25:18 <benmachine> ourfrank: not that I know of. there's 'join (***)' though
11:25:24 <benmachine> :t join (***)
11:25:24 <lambdabot> forall (a :: * -> * -> *) b c. (Arrow a) => a b c -> a (b, b) (c, c)
11:25:28 <Eduard_Munteanu> Mm, was that ever planned for?
11:26:17 <Eduard_Munteanu> Cabal doesn't encode non-Haskell deps anyway.
11:27:14 <mwc> Eduard_Munteanu: example is checking to see what ABI version is provided in a shared lib when building FFI bindings. Putting it in cabal means that it's more portable to windows. dcoutts made noises about doing that at one time
11:44:34 <Saizan> Eduard_Munteanu: there's extra-libraries and pkgconfig-depends actually
11:53:54 <parcs> @hoogle <<
11:53:54 <lambdabot> Text.Html (<<) :: HTML a => (Html -> b) -> a -> b
11:53:54 <lambdabot> Text.XHtml.Frameset (<<) :: HTML a => (Html -> b) -> a -> b
11:53:54 <lambdabot> Text.XHtml.Strict (<<) :: HTML a => (Html -> b) -> a -> b
11:54:57 * hackagebot roots 0.1.1.0 - Root-finding algorithms (1-dimensional)  http://hackage.haskell.org/package/roots-0.1.1.0 (JamesCook)
11:55:39 <hpc> Text.Html is a pretty bad interface, imo
11:58:57 <BW^-> what optimizations does ghc/haskell compilers typically do?
11:59:08 <BW^-> how much of the code does it try to evaluate on compile time, for instance?
11:59:26 <copumpkin> almost none
11:59:36 <copumpkin> in fact, actually none I think
11:59:54 <BW^-> oh really, are you sure?
12:00:12 <copumpkin> http://neilmitchell.blogspot.com/2010/07/rethinking-supercompilation.html and https://github.com/batterseapower/chsc are the main efforts on that front
12:00:17 <BW^-> so if i do a foldl + for a list with the elements 1-1000, it'll all wait until runtime to be evaluated?
12:00:27 <BW^-> cool, thx
12:00:31 <Eduard_Munteanu> I suppose it does some basic constant folding.
12:00:34 <copumpkin> depends what backend you do
12:00:43 <copumpkin> Eduard_Munteanu: not even that, I think. It will once hoopl is fully integrated
12:00:50 <Eduard_Munteanu> Ouch.
12:00:53 <copumpkin> however, the underlying code gen might do this
12:00:57 <copumpkin> llvm or the c backend
12:01:03 <copumpkin> with sufficiently high optimization 
12:01:18 <Eduard_Munteanu> Mm, what does it have to do with code generation?
12:01:24 <copumpkin> but the kind of code GHC outputs makes it hard for the usual compile-time evaluators in those compilers to do much
12:01:42 <copumpkin> if it's a static computation in haskell, it's still a static computation in the generated code
12:01:54 <copumpkin> a lower-level compiler can still see that
12:01:55 <Eduard_Munteanu> Stuff like 3 * 4 could be done at a sufficiently high level AFAICT.
12:02:03 <copumpkin> yes, but it isn't, is all I'm saying
12:02:04 <Eduard_Munteanu> Ah.
12:02:18 <BW^-> is there any way to describe strings or byte-vectors, as exactly that instead of as linked lists?
12:02:24 <BW^-> (of char/byte)
12:02:32 <copumpkin> describe?
12:02:38 <copumpkin> you mean for literals/ static data in your program?
12:02:39 <Eduard_Munteanu> BW^-: arrays?
12:02:46 <mwc> BW^-: ByteStrings or arrays
12:03:16 <Eduard_Munteanu> @hoogle STUArray
12:03:16 <lambdabot> Data.Array.ST data STUArray s i e
12:03:16 <lambdabot> Data.Array.ST castSTUArray :: STUArray s ix a -> ST s (STUArray s ix b)
12:03:16 <lambdabot> Data.Array.ST runSTUArray :: Ix i => ST s (STUArray s i e) -> UArray i e
12:03:41 <Eduard_Munteanu> or STArray, or IOArray etc.
12:03:57 <BW^-> hm aha
12:04:07 <parcs> what is the equivalent in haskell of sh's $0?
12:04:09 <BW^-> when i inline a string in haskell code, it gets translated to a linked list of char though, right?
12:04:25 <copumpkin> parcs: from System.Environment, getArgs
12:04:28 <copumpkin> @hoogle getArgs
12:04:28 <lambdabot> System.Environment getArgs :: IO [String]
12:04:40 <copumpkin> wait, is $0 the program name or the first argument?
12:04:42 <Eduard_Munteanu> Mm does getArgs return the exe name?
12:04:44 <parcs> getArgs gives me $@
12:04:53 <copumpkin> then there's getExecutableName or something like that
12:04:56 <copumpkin> @hoogle executableName
12:04:56 <lambdabot> No results found
12:05:13 <copumpkin> getProgName :: IO String
12:05:29 <copumpkin> it won't give you the full path
12:06:33 <parcs> that's good enough :D
12:12:58 <BW^-> copumpkin: ..right? ordinary haskell strings are char lists right?
12:13:02 <BW^-> linked list of char
12:13:30 <copumpkin> yeah
12:13:46 <copumpkin> well, static strings are flattened I think
12:14:06 <copumpkin> try putting a static string literal into your program and running strings on it
12:19:40 <BW^-> copumpkin: ok. if at runtime i want strings to be flattened also, is there any straightforward way to use char arrays (flattened form) instead?
12:19:44 <BW^-> i mean.. for all string handling
12:20:35 <copumpkin> why do you want it? to talk to foreign libraries?
12:20:38 <BW^-> i'm asking as i could suppose this would save a lot of ram for large blocks of data
12:20:40 <copumpkin> there's different things
12:20:49 <copumpkin> oh, well use something like Text or ByteString then
12:20:56 <BW^-> ok
12:20:58 <copumpkin> depending on how accurate you want to be on human language/unicode
12:21:12 <BW^-> unicode yes, so each char needs to be 32bit
12:21:20 <aristid> preflex: seen gwern
12:21:21 <preflex>  gwern was last seen on #haskell 1 hour, 52 minutes and 45 seconds ago, saying: cheater99: the top level link is http://www.gwern.net/index.html#computing if you haven't figured it out yet
12:21:23 <copumpkin> well, 20.8 bits :P
12:21:29 <copumpkin> but Text will give you that
12:21:29 <aristid> gwern: how many haskell github repos do you have locally?
12:21:34 <copumpkin> @hackage text
12:21:34 <lambdabot> http://hackage.haskell.org/package/text
12:21:40 <BW^-> are there lots of support functions - regexp, substr, etc - that take Text or Byte..eh?..String?
12:21:53 <copumpkin> a fair number, yeah
12:22:07 <BW^-> nice thx
12:22:25 <aristid> copumpkin: i wonder if they did any benchmarks before choosing a 16-bit representation.
12:22:33 <copumpkin> he did
12:22:36 <copumpkin> ask bos
12:22:55 <aristid> i believe you
12:22:56 <copumpkin> he also developed criterion specifically to be able to measure text's performance :P
12:23:19 <aristid> copumpkin: i was just wondering because in other languages, utf-16 is more of a historical accident
12:23:30 <aristid> because unicode USED to have only 16 bits in total
12:23:30 <copumpkin> I think he considered it a decent compromise
12:23:32 <copumpkin> others disagree
12:23:34 <gwern> aristid: it was something like 2000
12:23:34 <copumpkin> yeah
12:24:18 <aristid> gwern: hmm, that might be comprehensive
12:24:37 <BW^-> if i want to distribute a haskell app, what executable size are we typically talking about?
12:25:29 <aristid> BW^-: a few megabytes
12:25:39 <gwern> BW^-: depends. darcs is 6M, pandoc is 11M, and gitit pulls in the ghc api and so winds up at 25M
12:25:45 <copumpkin> depends if you use static linkage or not
12:25:51 <copumpkin> which was the only option until recently
12:25:59 <copumpkin> with dynamic linkage you'll get more reasonable executable sizes
12:26:23 <BW^-> aristid,gwern: in a distributed binary i suppose darcs and pandoc would not be needed??
12:26:34 <aristid> BW^-: no?
12:26:37 <BW^-> i mean.. it's only for an app coded in haskell.. the user is not supposed to have access to any app development functionality
12:26:38 <BW^-> not?
12:26:47 <aristid> BW^-: i think gwern used darcs and pandoc as examples
12:26:49 <BW^-> it could maybe even be statically linked all of it to one .exe or alike..
12:27:15 <gwern> BW^-: my point was that darcs and pandoc are mature well developed apps so unless you're doing very complex things or linking in the ghc api, you can expect 0-11M
12:27:24 <BW^-> gwern: ah ok
12:27:41 <BW^-> sorry i thought you meant they'd be bundled with the app anyone'd make
12:28:12 <parcs> BW^-: you can compile the libraries with the flag -fsplit-objs to potentially lower the size cost of static linking
12:28:15 <BW^-> what's the lower and upper intervals, depending on how much of the runtime library you include?
12:28:23 <BW^-> i think i read someone squeezed it down to 600kB
12:28:43 <parcs> you can also strip the binary (i think ghc does this automatically), and also run "upx" utility on it
12:29:35 <Eduard_Munteanu> If you do dynamic linking you can go quite low, like <20KiB or so
12:29:49 <Eduard_Munteanu> It makes sense if you distribute multiple executables.
12:30:54 <BW^-> eduard_munteanu: if so, how large would the dynlibs/.dll.s be`?
12:30:54 <pastorn> Eduard_Munteanu: is it possible to turn on dynamic linking?
12:31:16 <pastorn> Eduard_Munteanu: especially when using imports from libraries binding to C
12:31:27 <pastorn> (like SDL, so i can use it without licensing issues)
12:31:31 <ion> -rwxr-xr-x 1 ion ion 14236 2011-03-20 21:32 Main
12:31:44 <ion> main = putStrLn "o hai", ghc -dynamic
12:32:50 <ion> stripped: -rwxr-xr-x 1 ion ion 9772 2011-03-20 21:33 Main
12:33:42 <Eduard_Munteanu> BW^-: for a single exe they'd be just as large overall.
12:34:19 <Eduard_Munteanu> pastorn: mm, I haven't tried with FFI myself, but dynamic linking does work
12:34:20 <ion> Has anyone implemented a kind of -split-objs for the runtime?
12:34:24 <Eduard_Munteanu> i.e. -dynamic
12:34:46 <ion> so you could link (statically) only the parts you use from the runtime.
12:35:28 <BW^-> eduard_munteanu,ion: and how large would the .dll/dynlib be?
12:36:40 <Eduard_Munteanu> BW^-: I suppose the rest upto those 0-11MiB
12:36:58 <BW^-> ok.. it'd be nice to know more in detail
12:37:13 <parcs> nice for what?
12:37:16 * hackagebot hlibgit2 0.1 - Bindings to libgit2 v0.1.0-265-gb5c5f0f  http://hackage.haskell.org/package/hlibgit2-0.1 (SakariJokinen)
12:38:13 <pastorn> I need some help with theoretical TH if anyone's up for it...
12:40:57 <pastorn> So i'm using BNFC to generate my parser
12:41:20 <pastorn> and in my parser i have a regex for matching bitmasks (this is for an assembler language)
12:41:23 <pastorn> token   Bits    '%'(["01"] | (["01"]["01_"]+["01"]));
12:41:40 <pastorn> the _ is to be ignored, it's just there to help structure the code
12:41:45 <parcs> BW^-: the base dynlib is 11M
12:41:47 <ion> Why not Parsec, btw?
12:42:08 <pastorn> this construct will return a String to me
12:42:25 <pastorn> something i don't really like... i'd like to be able to get a [Int] back, or something similar
12:42:35 <pastorn> the same goes for my definition of a hex:
12:42:48 <pastorn> -- 0xa01b 0XA01b Xa01B $A01B a01bh are all valid:
12:42:50 <pastorn> token   Hex     ((('0'? ["xX"])|'$') (digit|["abcdef"]|["ABCDEF"])+)
12:42:52 <pastorn>                 | ((digit|["abcdef"]|["ABCDEF"])+ 'h');
12:43:19 <BW^-> parcs: k thx
12:43:40 <pastorn> ion: because i don't need it
12:43:45 <BW^-> parcs: so the guy who got it squeezed it into 600KB must have used some kind of tree shaker or alike
12:43:48 <pastorn> (except for this nuicanse)
12:46:16 <appamatto> would it be possible to program at the type level of a language like Haskell using the value-level language?
12:46:58 <appamatto> in other words, to have no type-level dsl?
12:47:56 <appamatto> For example, the most specific type of 1 would be 1, and Int would be a less-specific but still valid type.
12:48:35 <Saizan> bringing in subtyping would be a mess
12:48:37 <copumpkin> you want subtyping w
12:48:43 <copumpkin> ith singleton types, I think
12:48:50 <copumpkin> you'd get scala
12:49:03 <copumpkin> which isn't as bad as you might think, but isn't clean
12:49:05 <appamatto> hoa, scala does this? That's awesome
12:49:11 <Saizan> it has singleton types?
12:49:30 <copumpkin> supposedly
12:49:34 <copumpkin> I'm not sure how well they actually work
12:49:44 <appamatto> iwhy is it not clean?
12:50:08 <copumpkin> there's not really any consistent theory of the type system. It's just kind of a bunch of stuff thrown into a pot and mixed up
12:50:13 <copumpkin> things you might expect to work don't
12:50:16 <copumpkin> inference fails half the time
12:50:47 <Saizan> yeah, subtyping tends to have a big hit on type inference
12:50:49 <copumpkin> the compiler implementation is terrifying and the guy leading it thinks FP is a fad and isn't very open to changing things to make FP easier
12:50:51 <appamatto> well, it would have to if it's that powerful
12:51:00 <copumpkin> appamatto: it fails even for simple cases
12:51:18 <copumpkin> type information flows left to right in function calls, for example
12:51:33 <copumpkin> and currying a function or rearranging its arguments is a common way to avoid putting type annotations in
12:51:37 <copumpkin> since it'll fail to infer things if you don't
12:51:54 <copumpkin> it's not clean, but isn't too painful to work wtih
12:52:36 <appamatto> interesting. Why doesn't Haskell do subtypes? It seems like 1 would be a nice type to have.
12:53:04 <copumpkin> lots of things would be nice to have
12:53:08 <copumpkin> but they break your inference
12:53:09 <appamatto>  10
12:53:39 <copumpkin> designing a good language is often about leaving out features to make the whole thing more consistent
12:54:11 <copumpkin> I want a dependent haskell with subtyping, effect system, and substructural types (all varieties, with substructure polymorphism)
12:54:19 * hackagebot unix-bytestring 0.3.2 - Unix/Posix-specific functions for ByteStrings.  http://hackage.haskell.org/package/unix-bytestring-0.3.2 (WrenThornton)
12:55:04 <ndrsndrs> i want a haskell where i can just type `main = do it` and it works
12:55:13 <copumpkin> don't be silly!
12:55:20 * hackagebot unix-bytestring 0.3.2.1 - Unix/Posix-specific functions for ByteStrings.  http://hackage.haskell.org/package/unix-bytestring-0.3.2.1 (WrenThornton)
12:55:23 <ndrsndrs> sorry
12:55:43 <Eduard_Munteanu> Bah, inference is overrated.
12:56:26 <appamatto> copumpkin, okay, what is substructure polymorphism and what is an effect system? :p
12:56:44 <copumpkin> appamatto: something I just made up!
12:57:02 <copumpkin> but I want to be able to annotate a type variable with what kind of substructural typing rules I want to apply to it
12:57:05 <appamatto> btw, if you wanted your types to infer, wouldn't you just use the inferable subset?
12:57:14 <copumpkin> "this variable must be used 3 or more times"
12:57:21 <copumpkin> "no more than 2 times"
12:57:28 <appamatto> ah, I see
12:57:30 <appamatto> linear types
12:57:33 <Eduard_Munteanu> Semi-uniqueness typing ? :)
12:57:38 <copumpkin> linear types are a particular variety of substructural types
12:57:45 <copumpkin> an effect system tracks arbitrary effects you specify
12:57:46 <appamatto> yes
12:57:48 <copumpkin> like what DDC has
12:58:02 <appamatto> you'd favor that over monad?
12:58:15 <copumpkin> they're not mutually exclusive
12:58:22 <copumpkin> I'd still use monads for other things
12:58:45 <appamatto> i/hilight
12:59:40 <hai> is there a haskell library to convert mp3 to wav?
12:59:49 <TTimo> so the use of a preprocessor is an accepted practice for managing site / platform / build type configurations ?
13:00:30 <copumpkin> TTimo: I don't think anyone likes it, but it's definitely common
13:00:34 <GreaseMonkey> idunno, there might be an mpg123 binding or something
13:01:52 <GreaseMonkey> hai: some info: http://hackage.haskell.org/packages/archive/mp3decoder/0.0.1/mp3decoder.cabal
13:02:17 <GreaseMonkey> apparently it's quite slow, though :(
13:02:17 <appamatto>  10
13:03:10 <hai> GreaseMonkey, is there any another? Google only points others formats to wav, not mp3
13:03:34 <GreaseMonkey> <hai> is there a haskell library to convert ***mp3 to wav***?
13:04:17 <GreaseMonkey> if there's one which simply decodes MP3 to a raw stream, it should be fairly easy to encapsulate that as .wav
13:05:14 <hai> that kind of comment simply shows i need more study...
13:08:57 <jonkri> can i use this outside of the io monad? http://hackage.haskell.org/packages/archive/xml-enumerator/0.2.0.2/doc/html/src/Text-XML-Enumerator-Document.html#fromEvents
13:10:51 <GreaseMonkey> damn i was going to link to a wave file format thing
13:10:56 <ddarius> Eduard_Munteanu: Global inference may be overrated but, at least, local inference is probably underrated.
13:11:56 <sphynx> hi! I'm solving Project Euler problems in Haskell for warming up a little bit before facing serious problems :) I'm working on problem #14 now, here is the code: https://gist.github.com/878631 and here is the link to the problem: http://projecteuler.net/index.php?section=problems&id=14
13:12:23 <sphynx> I've used State monad for memoizing values and managed to run the program in ~23 seconds
13:12:42 <sphynx> which is better than 5+ minutes with naive bruteforce approach without memoization
13:13:06 <sphynx> but still, when running with -sstderr I see that GC time is 75% :(
13:13:25 <sphynx> what else can be done here to make the program run even faster than this?
13:13:57 <sphynx> I tried to play with strictness and BangPattern, but it seems this is not a problem here, so it didn't improve performance at all
13:14:32 <timestart> tried using IntMap? (or is overflow a problem?)
13:14:48 <sphynx> yes, overflow is a problem there
13:15:33 <sphynx> 64-bit integers would be enough, but not 32 :(
13:17:09 <opqdonut> try using "insertWith' const" instead of "insert"
13:17:26 <opqdonut> and also, profile the program so you'll see what is allocating most
13:18:28 <sphynx> I profiled it, but hardly can understand what this means :) Int and Map are occupying equally the same size in memory
13:19:05 <opqdonut> no not a heap profile, a normal profile with -p
13:19:12 <opqdonut> it gives you allocation amounts too
13:19:20 <sphynx> I did this too :)
13:19:24 <opqdonut> (you'll also see what's slowing it down)
13:19:25 <opqdonut> well?
13:19:44 <sphynx> it said that most allocating function was "collatz" ;)
13:19:50 <opqdonut> one thing that might be worth trying also is using Word64 instead of Integer, but that should only be smallish constant factor
13:19:51 <sphynx> but it's not surprising at all :)
13:20:03 <sphynx> let me profile it once more
13:20:21 <sphynx> because I did this before refactoring to State monad (earlier I used my own state passing, w/o monads)
13:20:31 <opqdonut> add some cost centres by hand
13:20:52 <opqdonut> especially one for the "let len' = len + 1 in modify (M.insert n len')"
13:21:37 <opqdonut> btw, you could also say "modify (M.insertWith' (+) n 1)"
13:21:38 <sphynx> ok, thanks, give me some time :)
13:21:51 <opqdonut> yeah sorry for the brain dump
13:21:58 <opqdonut> I'll be back later ->
13:22:13 <sphynx> it's not very fast since running time is 25 seconds and even more in profiling mode :)
13:23:38 <opqdonut> (hmm, scratch that insertWith' thing, I misread)
13:23:40 <sphynx> well, "collatz" is 90% of time and allocation
13:23:43 <jonkri> which is the simplest monad for (pure) use with http://hackage.haskell.org/packages/archive/enumerator/0.4.7/doc/html/src/Data-Enumerator.html#run_ ?
13:24:02 <sphynx> I haven't added cost centres, but turned on -caf-all
13:24:45 <sphynx> will try now with a cost centre near "let len' = len + 1 in modify (M.insert n len')"
13:24:50 <gnut_> hi all
13:25:08 <gnut_> does ghc have shared library support now for macs?
13:29:44 <sphynx> hm, is it possible to add SCC pragmas inside do-expression?
13:29:51 <sphynx> it didn't appear in .prof at all
13:30:04 <sphynx> or it is allowed only for functions?
13:30:52 <sphynx> I mean smth like: do { let x = 1; {-# SCC "modify" #-} modify (....); return ... }
13:31:06 <benmachine> sphynx: I'd be surprised if it wasn't possible, but I don't know
13:31:34 <sphynx> I added this stuff, but it didn't appear in my .prof file for some reason, will try once more
13:31:45 <Taslem> How many Modules do large programs typically consist of?
13:32:08 <osoleve> is there a way to have optional parameters to a function?
13:32:08 <sphynx> will try this way: modify ({-# SCC "insert" #-} M.insert n len')
13:32:29 <timestart> osoleve: use Maybe
13:32:31 <mauke> osoleve: not directly
13:32:41 <mauke> timestart: why not use two functions?
13:32:47 <benmachine> mauke: not even via evil-printf-tricks? :P
13:33:00 <mauke> benmachine: that's not very direct
13:33:06 <benmachine> hmm, k
13:33:13 <mauke> oleg has done it, of course
13:34:51 <Saizan> keyword arguments too, btw
13:36:21 <Taslem> Anyone here used Haskell networking before?
13:36:27 <mauke> yes
13:37:37 <benmachine> Saizan: what does that even mean, record syntax?
13:37:55 <Taslem> -_- Anyone who can HELP ME, I mean?
13:38:03 <mauke> with what?
13:38:04 <copumpkin> Taslem: ask your question
13:38:09 <sphynx> hm, this works: "case ({-# SCC "lookup" #-} M.lookup n table) of", but this doesn't add a cost centre: "modify ({-# SCC "ins" #-} M.insert n len')"
13:38:24 <sphynx> strange :(
13:38:33 <Taslem> "Anyone here used Haskell networking before?"   I don't know where to start, because I haven't really touched networking much in other languages.
13:38:40 <Taslem> Firstly, any modules/libraries I need to use it.
13:39:08 <benmachine> Taslem: your original question was hard to answer in any other way than yes or no; we expected you to follow it up with more
13:39:12 <copumpkin> @hackage network
13:39:12 <lambdabot> http://hackage.haskell.org/package/network
13:39:17 <benmachine> so there's no need to be all -_- about it
13:39:27 <Taslem> Is there anything built into prelude for it?
13:39:32 <copumpkin> no
13:39:34 <mauke> into prelude?!
13:39:46 <ddarius> benmachine: My "expectations" (and by that I mean desires and hopes) would be that such questions would not be asked in the first place.
13:39:50 <Taslem> Or rather, with prelude, i should say.
13:39:50 <benmachine> neither prelude nor the base libraries, I think
13:40:02 <osoleve> how do I use Maybe? :/
13:40:02 <Taslem> Hm, I'll check.
13:40:02 <copumpkin> the platform comes with it though
13:40:08 <mauke> I recommend Network.Socket.ByteString
13:40:08 <Taslem> Oh,really?
13:40:10 <osoleve> not in scope: data constructor 'Maybe'
13:40:13 <benmachine> osoleve: pattern-matching
13:40:15 <copumpkin> osoleve: depends what you want to do with it...
13:40:18 <mauke> osoleve: you use it as a type
13:40:21 <mauke> not a value
13:40:22 <benmachine> osoleve: oh, the constructors are Just and Nothing
13:40:28 <benmachine> :t Just
13:40:28 <lambdabot> forall a. a -> Maybe a
13:40:42 <Eduard_Munteanu> @src Maybe
13:40:42 <lambdabot> data Maybe a = Nothing | Just a
13:40:53 <Taslem> Thanks, that should do it.
13:41:09 <copumpkin> let us know if you have any particular questions
13:42:35 <Saizan> benmachine: curried :)
13:42:54 <benmachine> Saizan: bluh? ok :P
13:43:29 <Saizan> benmachine: foo Keyword value OtherKeyword otherValue ... End
13:43:38 <benmachine> ahh
13:43:41 <Saizan> that's how you call it
13:43:44 <benmachine> awesome :D
13:43:53 <Saizan> and you can give them in different orders etc..
13:44:11 <sphynx> opqdonut: hehe, changing to Word64 increased running time from 22s to 26s, so I'm reverting back
13:44:53 <pr> :t guard
13:44:54 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
13:45:12 <parcs> sphynx: which data structure are you using
13:45:37 <sphynx> parcs: Data.Map
13:46:14 <parcs> try the HashMap in the unordered-containers package
13:46:44 <sphynx> is it possible to use Integer/Word64 as a key there?
13:46:48 <parcs> yep
13:46:54 <sphynx> Int is too small, so I can't use Data.IntMap
13:47:04 <sphynx> ok, I'll try now
13:47:26 <Taslem> Can someone explain the data constructor for Sockets?
13:47:27 <Taslem> http://hackage.haskell.org/packages/archive/network/2.2.1/doc/html/Network-Socket.html#t%3ASocket
13:48:45 <sshc> Aghhhhhhhrgrrrgh
13:48:57 <Zao> Well aaaargh'd.
13:48:57 <mauke> Taslem: no
13:49:31 <sshc> AFter two *days* of trying to get a working setup with several hackage packages install, there's *still* a shit-load of dependency errors
13:52:09 <sphynx> parcs: Wow, 11 seconds instead of 22!
13:52:25 <sshc> All I've done after uninstalling GHC and cabal yesterday morning is itrying to install those packages from hackage that I'd had installed before
13:53:39 <monochrom> I see the reason for mauke's answer. If you already know unix socket low-level details, you may find a few fields occasionally useful to extract, but then you also need little help; if you don't already know, the fields are useless to you anyway.
13:53:40 <timestart> eventually you come up with an alias for cabal install that adds 400 --constraints and it mostly works, still have to check with --dry-run though
13:53:44 <parcs> sphynx: nice!
13:54:39 <sshc> Taking approximately 8 hours to "install" those packages for the first time (and ending up with dependency errors) doesn't help ith the frustration much
13:55:04 <drhodes> sshc: are you on a linux system?
13:55:41 <sshc> drhodes: Arch linux, GHC 7.0.2, cabal-install version 0.10.2 using version 1.10.1.0 of the Cabal library
13:55:49 <sshc> timestart: I've never used or seen those flags with cabal
13:56:17 <drhodes> ok, well are you using the package manager for ghc?
13:56:20 <Zao> Heh, trying to use the 7 series for anything serious is ... suboptimal.
13:56:38 <sshc> drhodes: Yep, pacman -S ghc cabal-install
13:56:55 <drhodes> sshc: because a few weeks ago I broke down and finally stopped using the package manage for anything haskell.
13:57:08 <drhodes> and life is good.
13:57:46 <monochrom> I think arch's packages are mostly fine. (an exception among linux distros, of course)
13:57:52 <drhodes> even cabal.  got a fresh binary cabal-install, a fresh binary ghc. installed everything from scratch with custom paths.
13:58:03 <sshc> Hmm, I'll try that
13:58:10 <sshc> All I've used pacman for is to install ghc and cabal-install
13:58:48 <monochrom> however my http://www.vex.net/~trebla/haskell/sicp.xhtml#unsafeInterleave still applies. don't interleave.
13:58:53 <sshc> drhodes: Do you suggest instaltling from their darcs repos?
13:59:19 <drhodes> sshc: I didn't, I just grabbed the binaries, they worked fine.
13:59:35 <sshc> drhodes: From where?
13:59:43 <drhodes> one second please
14:00:25 <drhodes> sshc: http://haskell.org/ghc/download_ghc_7_0_2#distros
14:00:38 <BrianHV> if I have a list and I want to make a new list with the items at two given indices swapped, is there a nice way of doing that?
14:00:39 <drhodes> sshc: and: http://hackage.haskell.org/trac/hackage/wiki/CabalInstall
14:02:04 <monochrom> no nice way. consider using an array.
14:02:39 <osoleve> what does it mean if the expected type is t0?
14:03:00 <mauke> not much
14:03:11 <aristid> osoleve: usually the message should say more about t0, then
14:07:06 <osoleve> all it says about t0 is Expected type [[t0]] Actual Type [Char]
14:07:22 <sshc> drhodes: How can I completely uninstall GHC, cabal and all of the packages to start from scratch (again (but this time knowing I'm doing it the right way))?
14:08:26 <Saizan> well, then it means it wants a list of lists, but it doesn't have any opinion on what the elements of those should be
14:09:34 <aristid> osoleve: it needs a list of lists, but you give it a string.
14:09:43 <monochrom> "Expected type [[t0]] Actual Type [Char]" means your code has a logical contradiction
14:09:46 <aristid> (a string is a list of Char)
14:09:51 <osoleve> so i should surround it with []
14:09:57 <drhodes> sshc: what I did was $mlocate ghc | grep ...  it took a while to purge the system. As I recall there were a few resistant package dug in like alex and happy.
14:09:57 <aristid> maybe
14:12:38 <monochrom> look inside .cabal/bin for alex, happy, or generally executables installed by "cabal install"
14:13:14 <monochrom> however, for libs, .cabal/lib is insufficient, you want .ghc
14:13:44 <BMeph> osoleve: You "should" figure out 1) What you want to do; 2) What you're really asking for; 3) How to change (2) to better resemble (1). ;)
14:14:00 <osoleve> will do, boss :)
14:14:16 <sshc> monochrom: I'm planning on removing ~/.ghc and ~/.cabal entirely, but  what about globally installed packages?
14:14:32 <monochrom> /usr/local
14:15:23 <monochrom> well, if "global" means "pacman", I don't know. if "global" means "cabal install --global" or "runghc Setup.hs", /usr/local
14:15:31 <BMeph> osoleve: I say it that way, because you may want to add 'concat' somewhere, instead of placing some brackets at random. ;)
14:15:45 <sshc> monochrom: I only want to remove hackage packages and GHC
14:15:54 <sshc> monochrom: I though there was much more than anything haskell-related in /usr/local
14:16:23 <monochrom> yeah, I do not mean "rm -rf /usr/local". I mean "do your search in /usr/local"
14:16:24 <joe6> i am reading about applicative and is the usage of monad outdated? is the trend to use applicative?
14:16:47 <parcs> sshc: pacman -Rcn ghc cabal-install
14:17:01 <joe6> or is there a situation where applicative is useful but not a monad?
14:17:02 <parcs> that removes ghc and cabal-install and all packages that depend on it
14:17:08 <monochrom> "ls /usr/local/bin" and decide
14:17:41 <monochrom> unfortunately "is /usr/local/bin/happy really happy?" is computationally undecidable
14:18:22 <BMeph> joe6: Haskell is full of academics. We decide what to use based on what the task is, not by what's "popular." ;p
14:18:51 <DRMacIver> That doesn't sound like a terribly accurate representation of academia :)
14:19:25 <copumpkin> certain branches of academia are more faddish than others
14:19:45 <copumpkin> sjanssen: so you're at well-typed these days?
14:20:03 <joe6> how about the usage of arrows or Pointed? Are they well used?
14:20:14 <copumpkin> Pointed is pretty unexciting, to me and others
14:20:22 <BMeph> DRMacIver: Hmmph. I'd've expected a different answer from someone whose name sounds like "MacGyver"... ;p
14:20:23 <joe6> Arrows seem to pop up in a lot of discussions here..
14:20:24 <copumpkin> Arrows are a little too strong to be interesting, too
14:20:37 <Twey> It may be uninteresting, but it's hella useful.
14:20:45 <copumpkin> but I use some of the combinators in the Control.Arrow module all the time
14:20:50 <joe6> copumpkin, what do you mean by "strong"?
14:20:50 <copumpkin> Twey: pointed?
14:21:08 <copumpkin> joe6: the arr method in Arrow forces the Arrow to basically be a subcategory of hask
14:21:20 <Twey> Yep
14:21:37 <Twey> Arrows aren't useful.  All the uses for Arrow are pretty contrived.  >.>
14:21:51 <DRMacIver> BMeph: It actually doesn't. It's just spelled that way. Also MacGyver was definitely not an academic. :) 
14:21:53 * BMeph thinks that many of the Arrow ought to be in 'Data.Tuple', if there isn't a separate 'Data.Pair' module.
14:22:01 <copumpkin> DRMacIver: are you related?
14:22:08 <joe6> Twey, really? They seeem to pop up quite a bit in #haskell discussions.
14:22:10 <DRMacIver> copumpkin: Yes. To many people.
14:22:21 <copumpkin> :P
14:22:44 <joe6> BMeph, really, so, arrows are mostly for tuple manipulations?
14:22:55 <hpc> joe6: pretty much
14:23:00 <Twey> joe6: The function instance of Arrow is used a lot, but that's just because it's handy for tuples
14:23:10 <Twey> I can't think of many other Real uses
14:23:12 <Twey> Maybe XHT
14:23:17 <BMeph> joe6: No, but it almost feels as if tuple manipulations are for Arrows. ;)
14:23:18 <Twey> Er
14:23:19 <Twey> HXT
14:23:22 <monochrom> MacGyver was friendly to academics.
14:23:30 <hpc> incidentally, hask is also the only intuitive instance of Arrow
14:23:49 <hpc> kleisli is hard to wrap your head around, and you really might as well just use (>=>)
14:23:52 <Eduard_Munteanu> HXT incidentally uses its own implementation, it seems.
14:24:37 <Eduard_Munteanu> Erm, by Hask there do you actually mean (->)?
14:25:01 <Eduard_Munteanu> as in...
14:25:04 <hpc> Eduard_Munteanu: yes
14:25:05 <Eduard_Munteanu> :t (>>>)
14:25:05 <lambdabot> forall (cat :: * -> * -> *) a b c. (Control.Category.Category cat) => cat a b -> cat b c -> cat a c
14:25:25 <Twey> Eduard_Munteanu: I don't think so… it's an instance of Arrow, at least, isn't it?
14:25:30 <joe6> i read the typeclassopedia and got lost after the Functor & Pointed. Need to get my head around the Comonad, Applicative, Alternative, Foldable and Traversable.
14:25:48 * hackagebot hS3 0.5.5 - Interface to Amazon's Simple Storage Service (S3)  http://hackage.haskell.org/package/hS3-0.5.5 (GregHeartsfield)
14:25:51 <Eduard_Munteanu> I'd rather say Arrows are Categories, just like (->) is a Category, isn't it so?
14:26:37 <joe6> what is Hask?
14:26:38 <Eduard_Munteanu> joe6: it's useful to consider Functor, then Pointed, then Applicative, then Monad.
14:26:53 <hpc> joe6: Hask is (->)
14:26:56 <Eduard_Munteanu> For Comonad you might go the Copointed route.
14:27:07 <Eduard_Munteanu> I'd say Hask is *  :)
14:27:14 <hpc> joe6: bookmark this: http://98.169.17.243:8000/blog/view.cgi?id=8
14:27:20 <Eduard_Munteanu> Isn't it?
14:27:25 <hpc> joe6: once you understand monads, go back to that post and you will get categories
14:27:48 <hpc> Eduard_Munteanu: the arrow is (->) and the objects are *
14:28:04 <Eduard_Munteanu> Ah, makes sense.
14:28:16 <Eduard_Munteanu> hpc: is that a permalink? I thought you were on a dynamic IP thingy
14:28:18 <hpc> morphisms from object to object are a -> b
14:28:19 <joe6> hpc, i am also reading and doing the exercises in "all about monads". So, would you recommend "all about monads" -> categories?
14:28:34 <hpc> Eduard_Munteanu: oh right, lol
14:28:48 * hackagebot GLFW-b 0.0.2.4 - GLFW bindings  http://hackage.haskell.org/package/GLFW-b-0.0.2.4 (BrianLewis)
14:28:53 <Eduard_Munteanu> hpc: do yourself a favor and get dyndns :P
14:28:55 <hpc> joe6: i recommend not getting ahead of yourself ;)
14:28:57 <joe6> should it be "typeclassopedia" -> "all about monads" -> categories?
14:29:06 <hpc> Eduard_Munteanu: oh fine
14:29:15 <Eduard_Munteanu> It works fine on Linux, I use ddclient with it.
14:30:06 <joe6> is there something as "All about Monads" for Functor, Pointed, etc? I like the "All about Monads" exercises. 
14:30:11 <dixie> hmmm, very stupid question. I would like to split list (xs) into parts with same size (n) and the rest. I can write simple recursive function using take or span, but isn't there something already? 
14:30:34 <joe6> The exercises help in a deeper understanding of the subject, I believe.
14:31:01 <sphynx> joe6: have you read TypeClassoPedia?
14:31:05 <Eduard_Munteanu> I'm not sure, though Typeclassopedia should be fine.
14:31:16 <Eduard_Munteanu> There isn't much about Functor and Pointed though.
14:31:27 <joe6> sphynx, yes, I have it before me, as we speak.
14:31:28 <mercury^> Most other typeclasses are not as hard to understand.
14:31:31 <BMeph> dixie: Look up the "split" package on hackage. :)
14:31:51 <sphynx> joe6: there are nice Further reading subsections in every section of it
14:31:53 <joe6> sphynx, there are exercises in it, but more "implementation" style..
14:32:03 <joe6> sphynx, yes there are.
14:32:18 <sphynx> joe6: I'm reading it too :)
14:32:46 <Eduard_Munteanu> mercury^: I wouldn't be so sure about Edward's stuff :P
14:34:27 <hpc> Eduard_Munteanu: http://headprogrammingczar.dyndns.org:8000/blog/
14:34:29 <hpc> better? :P
14:35:04 <sphynx> but yes, "Further reading" section for functors is very small. Applicative, Monad and Monoid will be better :)
14:35:24 <dixie> BMeph: thanks! I know the split package but I used it for splitting using delimiter. Seems splitEvery is what I'm looking for.
14:36:04 * BMeph gives dixie a Commemorative Cup! ;p
14:36:51 <Eduard_Munteanu> hpc: yay
14:37:02 <joe6> what about using "Pure" instead of "return".
14:37:33 <joe6> Does anyone do that? I like the usage of "Pure" given that it has less mental baggage (to me).
14:37:49 <Eduard_Munteanu> joe6: yep
14:38:21 <Eduard_Munteanu> joe6: it's considered appropriate not to make a whole monad if all you need is an Applicative.
14:40:16 <mreh> are there compiler options i need to enable before parallel strategies start to take effect?
14:40:32 <monochrom> -threaded
14:40:44 <hpc> and i think you specify how many threads you want
14:41:01 <mreh> will seq work regardless?
14:41:07 <hpc> of course
14:41:18 <monochrom> pseq is preferred
14:41:27 <mreh> $#!
14:41:32 <hpc> pseq and par become no-ops when you aren't threaded
14:41:45 <monochrom> but I guess in practice seq isn't too far from pseq
14:42:02 <hpc> er, i think pseq becomes seq
14:44:18 <mreh> i was still seeing my program leak masses of memory, bollocks
14:44:51 <mercury^> mreh: :(
14:44:57 <mercury^> Try making datatypes strict.
14:45:42 <mreh> i was hoping rnf would work
14:46:21 <mreh> specifically "using (seqList rnf)" so the evaluation was outermost lazy
14:46:54 <joe6> this is a very interesting blogpost, http://headprogrammingczar.dyndns.org:8000/blog/view.cgi?id=5
14:48:02 <monochrom> figuring out memory usage is a whole-program analysis. do not think a localized "using (seqList rnf)" is informative.
15:02:57 <Ptival> :pl \(x,y,z) -> x
15:03:04 <Ptival> @pl \(x,y,z) -> x
15:03:05 <lambdabot> (line 1, column 6):
15:03:05 <lambdabot> unexpected ","
15:03:05 <lambdabot> expecting letter or digit, operator or ")"
15:03:05 <lambdabot> ambiguous use of a non associative operator
15:03:34 <Ptival> ?
15:04:12 <mercury^> @pf f(x,y,z) = x
15:04:12 <lambdabot> Maybe you meant: bf pl
15:04:19 <dmbarbour> Hello. I'm trying to support some non-parametric types for performance - i.e. processing arrow with pairs (a (f,s) (f',s')) as a pair of arrows (under the hood). Are there any ideas on how to support these non-parametric types? 
15:04:37 <Ptival> @pl f (x,y,z) = x
15:04:37 <lambdabot> (line 1, column 11):
15:04:37 <lambdabot> unexpected "="
15:04:37 <lambdabot> expecting variable, "(", operator or end of input
15:05:07 <mercury^> I think it's broken.
15:05:12 <Ptival> :(
15:05:13 <ddarius> dmbarbour: Use data/type families.  That was one of their original use-cases.
15:05:22 <ddarius> dmbarbour: See the DPH papers.
15:05:30 <Ptival> @pl \x -> x
15:05:30 <lambdabot> id
15:05:42 <Ptival> @pl \(x,y) -> x
15:05:42 <lambdabot> fst
15:05:45 <Ptival> @pl \(x,y,z) -> x
15:05:45 <lambdabot> (line 1, column 6):
15:05:46 <lambdabot> unexpected ","
15:05:46 <lambdabot> expecting letter or digit, operator or ")"
15:05:46 <lambdabot> ambiguous use of a non associative operator
15:05:49 <Ptival> huhu
15:06:15 <Ptival> @pl \(x,(y,z)) -> x
15:06:15 <lambdabot> fst
15:06:24 <Ptival> @pl \((x,y),z) -> x
15:06:24 <lambdabot> fst . fst
15:07:20 <dmbarbour> ddarius: I need to handle pairs non-parametrically, but everything else parametrically. It's the "everything else" bit that I'm having trouble with. Do you know if a 'default' type is supported with type familes?
15:09:14 <dmbarbour> ddarius: (Just noting: I am familiar with type familes, but haven't been able to finagle them to work here.)
15:13:43 <dmbarbour> Hmmm... maybe I should rebuild a variation on the entire 'Control.Arrow' typeclass just so I can inject a sensible type family for (***) and (&&&) instead of pairs.
15:14:03 <copumpkin> you can't partially apply type families
15:14:14 <copumpkin> oh you wouldn't take it as a parameter?
15:14:50 <mreh> does ghci not like parallel strategies?
15:14:53 <dmbarbour> copumpkin: well, taking it as a parameter seems good, too.
15:15:15 <mercury^> I have a silly question on category theory that is not being answered in #(not-)math. Would it be ok to post it here?
15:15:24 <hpc> @hoogle par
15:15:24 <lambdabot> Control.Parallel par :: a -> b -> b
15:15:24 <lambdabot> Text.Html paragraph :: Html -> Html
15:15:24 <lambdabot> Text.XHtml.Frameset paragraph :: Html -> Html
15:15:29 <copumpkin> mercury^: sure, or ##categorytheory
15:15:45 <hpc> mreh: works for me
15:16:02 <copumpkin> mreh: "not like" is fairly underspecified
15:16:03 <mreh> Couldn't match expected type `Control.Parallel.Strategies.Eval
15:16:03 <mreh>                                     (Maybe (Array (Integer, Integer) Double, Bool))'
15:16:06 <mreh>            against inferred type `()'
15:16:09 <hpc> why ##categorytheory and not #categorytheory?
15:16:10 <dmbarbour> copumpkin: though I'm not very fond of how multi-parameter type classes interact with type inference, so I mostly have been using dedicated types.
15:16:12 <mercury^> I am terribly confused right now. Someone please point out the mistake in the following: 2-functors preserve units and counits, and therefore adjoint pairs. Hence Ho: TopCat -> Cat preserves adjoint functors. Since limits are adjoint to precomposition in TopCat and since homotopy limits are adjoint to the image of precomposition under Ho, ordinary limits in Top are also homotopy limits.
15:16:14 <mreh> compiles fine
15:16:27 <mreh> ghci doesn't want to compile it
15:16:28 <mercury^> thermoplyae: by precomposition I mean the following: you have a topological category T (= Top). Then hom(D,T) is a topological category for any small category D, and the functor D \to * induces a functor T = hom(*, T) \to hom(D,T). The left adjoint of this functor is the colimit functor, the right adjoint is the limit functor.
15:16:40 <mercury^> Similarly, if you consider Ho(hom(D,T)) and Ho(hom(*,T)) you get homotopy limits and colimits (by their property of representing homotopy commutative cones).
15:18:21 <Eduard_Munteanu> You meant to say that in #math?
15:18:26 <joe6> does anyone upgrade ghc frequently? How do you manage the cabal packages when you do that?
15:18:43 <mercury^> Eduard_Munteanu: no, here; see above.
15:18:46 <copumpkin> I rebuild it
15:19:04 <djahandarie> mercury^, ##categorytheory has all the relevant people in it for these sort of questions, for future reference. :)
15:19:13 <Eduard_Munteanu> Ah, I knew a thermoplyae in #math.
15:19:13 <mercury^> Ok. :)
15:19:14 <djahandarie> I see this has already been noted
15:19:14 <copumpkin> mercury^: I feel that the people who could answer that might not be around now, and this channel is active enough that they won't notice it otherwise. ##categorytheory would probably be better 
15:20:52 <joe6> copumpkin, rebuild what? ghc? or cabal packages?
15:20:57 <copumpkin> the packages
15:21:22 <joe6> copumpkin, how often do you upgrade ghc?
15:21:30 <copumpkin> pretty often :)
15:21:48 <copumpkin> more often than it gets released
15:21:53 <benmachine> heh
15:22:10 <joe6> i have noticed that it is a pita to rebuild packages with cabal given all the errors the packages spew out. Do you patch the packages?
15:22:23 <joe6> copumpkin, what is your current ghc version?
15:22:31 <copumpkin> Glasgow Haskell Compiler, Version 7.1.20110123, stage 2 booted by GHC version 7.0.1
15:22:49 <copumpkin> yes, I patch them
15:23:00 <copumpkin> especially with the fix in GHC that breaks bangpatterns
15:23:05 <copumpkin> and flexibleinstances
15:23:13 <mreh> heh, "fix"
15:23:15 <copumpkin> well, fixes them, but breaks many packages that have been using them wrong
15:23:32 <mreh> how do you use them wrongly?
15:23:47 <copumpkin> you don't turn them on when you should be
15:23:54 <hpc> the day never ends for the hackage package fixer
15:24:00 <copumpkin> GHC silently accepted bang patterns on the first argument even if BangPatterns were off
15:24:25 <copumpkin> or something like that
15:24:34 <mreh> WHAT?!
15:24:46 <copumpkin> that was the fix I mentioned :P
15:25:03 <copumpkin> it also let you write some things that would normally require FlexibleInstances with FlexibleInstances turned off
15:25:21 <copumpkin> so the 7.2 release will break lots of stuff
15:25:27 <copumpkin> but in a trivially fixable manner
15:25:38 <joe6> copumpkin, any thoughts on this error, please? http://sprunge.us/MHTZ . I opened up a ticket with ghc, but just wondering if you have come across it.
15:26:04 <copumpkin> nope, sorry :/
15:26:12 <copumpkin> have you tried on a more recent build than 0209?
15:27:22 <mreh> can I heap profile a specific cost centre in the execution of a whole program?
15:28:03 <monochrom> yes, but I forgot the exact commands
15:28:25 <mreh> a quick glance at the man page was not conclusive
15:28:28 <mreh> i'll read further
15:28:43 <monochrom> man page is not enough. "ghc user guide".
15:29:30 <monochrom> http://www.haskell.org/ghc/docs/7.0-latest/html/users_guide/index.html  accept no substitutes. (except for ghc version)
15:29:58 <mreh> that fresh ghc taste
15:30:04 <gwern> > (800 / 3) * 1.2
15:30:05 <lambdabot>   320.0
15:32:09 <gwern> >  (((723 / 51.27) * 60) / 3) * 1.2
15:32:10 <lambdabot>   338.4435342305441
15:32:19 <gwern> >  ((((723 / 51.27) * 60) / 3) * 1.2) / 60
15:32:19 <lambdabot>   5.640725570509068
15:33:01 <gwern> any guesses what I'm calculating there?
15:33:37 <mreh> theses CC profiling outputs also have suspiciously few numbers of CC stacks
15:34:52 <Taslem> Does whitespace marginally increase interpretation time?
15:35:10 <monochrom> just parse time
15:36:01 <Taslem> Thought so.
15:36:23 <shachaf> Taslem: Whitespace in Haskell code?
15:36:33 <apoliiton> Does anyone know if gtk2hs is broken in windows? I've followed the instructions but I get stuck on installing gio + pango dependencies.
15:46:52 <monochrom> contrapumpkin :: (a -> b) -> Smash b -> Smash a
15:47:04 <contrapumpkin> :(
15:47:15 <gwern> wait, how does that work
15:47:36 <aristid> @hoogle (a -> b) -> f b -> f a
15:47:37 <lambdabot> Data.IntMap updateMax :: (a -> a) -> IntMap a -> IntMap a
15:47:37 <lambdabot> Data.IntMap updateMin :: (a -> a) -> IntMap a -> IntMap a
15:47:37 <lambdabot> Data.Sequence adjust :: (a -> a) -> Int -> Seq a -> Seq a
15:48:03 <gwern> aristid: I mean, if I have a->b, how can I go backwards and take a 'b' and return an 'a'?
15:48:06 <monochrom> type Smash x = x -> Pumpkin
15:48:06 <gwern> unless a=a
15:48:10 <gwern> er a=b
15:48:12 <contrapumpkin> gwern: any contravariant functor
15:48:44 <contrapumpkin> say I have newtype Moo b a = Moo (a -> b)
15:48:55 <contrapumpkin> I can write an instance of Contravariant for it
15:49:30 <contrapumpkin> I can write (a -> b) -> Moo c b -> Moo c a
15:49:43 <monochrom> recall that US'economy Money takes in money rather than contains money. newtype US'economy x = US (x -> US'Economy x)
15:50:14 <aristid> gwern: it kind of makes sense, doesn't it? :)
15:50:26 <contrapumpkin> or more obviously, newtype Pred a = Pred (a -> Bool)
15:50:29 <aristid> monochrom: bad joke :P
15:50:31 <contrapumpkin> (a -> b) -> Pred b -> Pred a
15:50:46 <TheZimm> contrapumpkin are you who i think you are?
15:50:54 <aristid> contrapumpkin: Pred is just Moo Bool :)
15:50:55 <contrapumpkin> TheZimm: depends who you think I am, but probably :)
15:51:01 <aristid> although i think Moo is a bad name
15:51:04 <contrapumpkin> aristid: I know, but giving it a meaningful name might help
15:51:04 <TheZimm> :D
15:51:06 <monochrom> this is also an extreme way to argue why "how to get String from IO String" is futile. it doesn't trap a String, there is nothing to extract.
15:51:17 <TheZimm> contrapumpkin emock said youre supposedly really good at math
15:51:18 <contrapumpkin> monochrom: how about your other question
15:51:22 <contrapumpkin> about extracting IO from IO String
15:51:27 <TheZimm> (if youre who i think you are)
15:51:28 <contrapumpkin> TheZimm: compared to these guys, not at all :P
15:51:32 <TheZimm> heh
15:51:41 <Zao> monochrom: I blame the "halp, trapped in the IO monad" lambdacat.
15:51:58 <copumpkin> @quote monochrom extract
15:51:58 <lambdabot> No quotes match. Sorry about this, I know it's a bit silly.
15:52:38 <monochrom> IO wants to be free
15:52:42 <Zao> http://spl.smugmug.com/Humor/Lambdacats/trapd-in-IO-monad-plz-help/960526421_MnNqB-O-1.jpg
15:52:57 * copumpkin wonders what a language that allowed values of *->* types would be like
15:53:27 <monochrom> each javascript function is a value of *->* type
15:53:55 <copumpkin> how so?
15:54:06 <monochrom> dynamic typing
15:54:07 <lispy> I asked this last night, but not many people were around.  I'm getting, "newBoundTask: RTS is not initialised; call hs_init() first" when my program exits.  It's just a normal haskell program but it does use a external C library and I think that library may use threads.
15:54:21 <monochrom> in fact also dynamic argument numbers
15:54:31 <lispy> ghc 7.0.2 and windows 7, FWIW
15:54:44 <lispy> Maybe I should ask in GHC?
15:54:46 <lispy> er, #ghc
15:55:02 <copumpkin> how are you talking to the external C library?
15:55:06 <sphynx> opqdonut: are you here? :)
15:56:20 <lispy> copumpkin: just normal FFI imports.  The binding is here: https://github.com/bsl/GLFW-b/blob/master/src/Graphics/UI/GLFW.hsc
15:57:31 <lispy> So, last night Saizan was thinking that possibly one of the callbacks was getting entered after things were shutdown.  This is possible.  I use 'forever $ GLFW.waitEvents >> GLFW.swapBuffers" an the end of main to keep the main thread from exiting
15:57:44 <lispy> I could use an mvar instead
15:57:49 <lispy> But, I thought that seemed messy
15:57:53 <copumpkin> lispy: it does something fairly unsafe in there, but I doubt that's what's wrong
15:57:54 <copumpkin> https://github.com/bsl/GLFW-b/blob/master/src/Graphics/UI/GLFW.hsc#L977
15:58:00 <copumpkin> those things should all be marked noinline
15:58:11 <lispy> copumpkin: Oh, right, I made that change locally.
15:58:19 <lispy> I haven't sent a patch to the author yet though
15:59:50 <copumpkin> a lot of the foreign import calls could probably be marked as safe/unsafe (whichever one isn't the default) too
15:59:57 <copumpkin> if they don't call back into haskell
16:00:26 <lispy> Most of them used to be unsafe but there was a bug or two with that and I asked the author to make them 'safe'
16:00:37 <copumpkin> ah
16:00:45 <copumpkin> that naming really sucks
16:00:45 <lispy> I think most of them can actually return at funny times.
16:01:19 <lispy> oh, safe/unsafe should be reentrant/non-reentrant?
16:01:39 <copumpkin> yeah, or just something that isn't so ambiguous
16:01:41 <lispy> I should merge again and then send him the NOINLINE patch
16:02:56 <copumpkin> can I see the code you call it with?
16:04:47 <lispy> Yeah, give me a sec
16:07:25 <lispy> copumpkin: http://hpaste.org/44910/aoeu
16:12:31 <copumpkin> lispy: I'm going to guess your shutdown logic is a bit convoluted
16:12:32 <copumpkin> keyPressed GLFW.KeyEsc True = exitWith ExitSuccess
16:12:36 <copumpkin>      GLFW.setWindowCloseCallback shutdown
16:12:58 <copumpkin> shutdown calls exitWith and so does keyPressed
16:13:16 <copumpkin> and shutdown is a callback from closing the window
16:13:26 <copumpkin> seems like a rather confusing sequence of events that happens right there
16:13:35 <lispy> So, you think calling exitWith twice may be causing this?
16:13:58 <copumpkin> I'd put some prints in to see exactly what sequence that happens in
16:14:02 <copumpkin> but yeah, possibly
16:14:13 <copumpkin> if I were the GHC RTS guy
16:14:21 <copumpkin> I would not design exitWith to be called twice :P
16:17:00 <lispy> copumpkin: ah, thanks.  That was the issue.
16:17:11 <copumpkin> cool!
16:17:21 <lispy> copumpkin: I changed keyPressed to call shutdown (duh!  should have been that way initially) and the problem goes away
16:17:32 <copumpkin> cool
16:17:36 <copumpkin> yeah, that makes more sense
16:17:45 <lispy> Yeah, I don't know why I would duplicate the exit logic
16:18:24 <lispy> This is nice though.  I'm updating my opengl examples to depend on OpenGLRaw (the api more closely matches OpenGL) and removing the GLUT dependency
16:18:59 <cheater00> how can you realize cooperative multitasking in haskell?
16:19:40 <copumpkin> GHC is already doing that for you ;)
16:19:47 <copumpkin> why do you want it?
16:20:16 <cheater00> because i don't want multithreading.
16:20:17 <copumpkin> seems like you could make a Cont-like Monad for skipping around a bit
16:20:27 <copumpkin> GHC haskell already gives you threading without OS threads
16:20:55 <cheater00> yes, and i don't want multithreading.
16:20:58 <copumpkin> ...
16:21:03 <copumpkin> why not?
16:21:18 <cheater00> why not use C?
16:21:22 <copumpkin> o.O
16:21:37 <companion_cube> cheater00, you mean, like lwt for ocaml ?
16:21:38 <cheater00> you want to use haskell, but really, why not just use C?
16:21:45 <copumpkin> cheater00: I think you're confused here
16:21:47 <cheater00> companion_cube: never used lwt
16:22:02 <mauke> cheater00: what do you want?
16:22:03 <cheater00> companion_cube: do you know twisted for python?
16:22:14 <copumpkin> oh, you want real painful cooperative multitasking
16:22:19 <copumpkin> you gonna ask about node.js? 
16:22:26 <cheater00> ?
16:22:33 <cheater00> not really, why should i?
16:22:39 <copumpkin> the kind where you need to worry about taking too long between yielding? :o
16:22:43 <mauke> copumpkin: actually I want predictable multi-IO
16:22:54 <mauke> copumpkin: getting that with threads is non-trivial
16:22:57 <copumpkin> yeah
16:22:58 <cheater00> copumpkin: that's the "cooperative"
16:23:09 <copumpkin> cheater00: my question is why do you want to worry about yielding explicitly?
16:23:10 <cheater00> as opposed to "forced"
16:23:26 <cheater00> copumpkin: it's an alternative way of doing things.
16:23:27 <companion_cube> copumpkin, you're not forced to write "yield" in a cooperative threading
16:23:35 <copumpkin> companion_cube: I know, but you're effectively thinking about it
16:23:41 <companion_cube> it can be monadic 0:-)
16:23:50 <mauke> companion_cube: what operations will yield internally?
16:24:19 <companion_cube> every IO invocation, for example
16:24:33 * companion_cube is reading the lwt page, in fact, and it seems pretty cool
16:24:44 <mauke> companion_cube: that's basically what already happens with ghc threads
16:24:50 <cheater00> basically what i want is to be able to define coroutines
16:25:00 <cheater00> and just iterate through all registered coroutines
16:25:03 * copumpkin shrugs
16:25:09 <benmachine> cheater00: iteratees are a bit like coroutines, I think?
16:25:09 <copumpkin> it's not impossible
16:25:16 <cheater00> benmachine: yes
16:25:25 <copumpkin> cheater00: is this because it's a conceptually easier model for your application, or because of performance concerns?
16:25:28 <cheater00> benmachine: but how do i loop around and call one, then the 2nd, and so on?
16:25:38 <benmachine> cheater00: ... the usual way?
16:25:39 <aristid> cheater00: forkIO
16:25:42 <mauke> cheater00: with a loop?
16:25:44 <cheater00> copumpkin: it's because it is a different model
16:26:01 <benmachine> forever mapM or something
16:26:07 <copumpkin> then you can probably model it with a Cont-like thing
16:26:09 <cheater00> benmachine: aha ok
16:26:21 <cheater00> copumpkin: what's a Cont-like thing?
16:26:30 <copumpkin> @unmtl Cont r a
16:26:30 <lambdabot> (a -> r) -> r
16:26:38 <copumpkin> @type callCC
16:26:39 <lambdabot> forall a (m :: * -> *) b. (MonadCont m) => ((a -> m b) -> m a) -> m a
16:26:47 <benmachine> copumpkin: ∀ x, you can probably model x with a Cont-like thing?
16:26:53 <copumpkin> benmachine: :P true
16:26:54 <cheater00> oh you mean call/cc
16:26:57 <cheater00> nah, i don't want cc
16:27:11 <copumpkin> well, if you impose enough arbitrary restrictions on the problem it's not going to be possible
16:27:33 <cheater00> there are examples of this happening without call/cc
16:27:42 <copumpkin> then follow them
16:27:48 <cheater00> they're not in haskell
16:28:04 <cheater00> that's why i come here to ask, in #haskell, you know
16:28:10 <cheater00> :)
16:28:29 <copumpkin> I've told you how I'd do it in Haskell
16:28:32 <mauke> are the concepts so different?
16:28:39 <copumpkin> just because you do it in other ways in other languages doesn't mean those are applicable to haskell
16:28:44 <mauke> you just keep a list of functions and call them
16:29:03 <copumpkin> I'm sure they probably are applicable to haskell, but might not be a very natural way to do it, anyway
16:29:35 <cheater00> mauke: yah
16:30:02 <cheater00> mauke: i'm just asking because i'm fairly new to haskell and i can't fully imagine how i'd do it
16:30:08 <copumpkin> the point is remembering where you left off
16:30:08 <cheater00> but i guess i have an inkling now :)
16:30:26 <mauke> I did something like that in OCaml once
16:30:35 <benmachine> cheater00: well, a coroutine is basically a function and some saved state, they're really nothing magic
16:30:47 <cheater00> benmachine: yeah, i understand that part
16:30:53 <benmachine> and co-operative multitasking in the way you describe is basically lots of coroutines, no?
16:31:06 <jmcarthur> benmachine: that definition sounds like a closure
16:31:09 <copumpkin> http://hackage.haskell.org/package/Coroutine
16:31:10 <cheater00> benmachine: but i don't understand, if you have say a set of coroutines, how do you loop around it indefinitely? that's probably something super-basic.
16:31:14 <copumpkin> there you go
16:31:27 <benmachine> jmcarthur: is it wrong though? :P
16:31:33 <copumpkin> that package has some extra stuff though
16:31:46 <benmachine> cheater00: can you tell me how you'd loop indefinitely around anything?
16:32:01 <cheater00> jmcarthur: i think you mean to say that a coroutine has static context.
16:32:09 <cheater00> benmachine: not in haskell no
16:32:32 <benmachine> cheater00: ah, well, that's a question you want to ask then, instead of about coroutines/multitasking specifically
16:32:47 <benmachine> cheater00: you can do it with recursion easily enough, or there are combinators like 'forever' and friends
16:32:49 <monochrom> there is something wrong about "I want to use haskell (specifically ghc) and I want to avoid threads", with high probability.
16:32:53 <cheater00> benmachine: well, i thought the problem was already solved on a higher level :)
16:33:03 <mauke> cheater00: yeah, threads
16:33:24 <cheater00> mauke: nah
16:33:28 <benmachine> cheater00: so *then* you're asking if there are libraries which hold on to your coroutines for you and shuffle through them in a convenient way?
16:33:37 <mauke> this is what threads do
16:33:40 <benmachine> heh
16:33:44 <benmachine> it really is
16:33:47 <copumpkin> GHC's threading mechanism does this
16:33:51 <copumpkin> that's what I was trying to say before :P
16:33:53 <benmachine> maybe haskell threads should not be called threads
16:33:57 <benmachine> even though that's what they are
16:34:01 <cheater00> benmachine: it's not what threads do
16:34:05 <benmachine> they should be called warm fuzzy things
16:34:09 <copumpkin> cheater00: have you looked at GHC's threading implementation?
16:34:16 <mauke> cheater00: why not?
16:34:25 <monochrom> well the java world has no problem calling green threads "threads" either.
16:34:42 <cheater00> because threads still can end up blocking on things whereas with coroutines you'll have thought things through really
16:34:51 <copumpkin> cheater00: we block just fine
16:35:02 <copumpkin> it doesn't hold up other things though :P
16:35:08 <mauke> cheater00: huh?
16:35:14 <cheater00> and on the other hand, threads can switch the context at the most inconvenient time
16:35:28 <lispy> If you have multiple Executables mentioned in your .cabal file do they shared the build-depends?  That seems to be happening here but I think it's a bug.
16:35:30 <cheater00> so you'll have a huge object hanging around in memory
16:35:41 <mauke> cheater00: context switching is less inconvenient if you don't have mutable variables
16:35:43 <cheater00> whereas if you explicitly define where the yield should be you can avoid this problem
16:36:10 <cheater00> mauke: that's fine, you still don't want 200 mb objects hanging around.
16:36:12 <mauke> what huge object?
16:36:43 * cheater00 resists making a "huge object" joke.
16:36:55 <cheater00> :)
16:37:04 <monochrom> if you omit "-threaded", threads become cooperative multitasking. in fact there are ways to write a thread that doesn't yield at all.
16:37:14 <copumpkin> fix id
16:37:37 <benmachine> it might be reasonable to want only one thread running at once wrt memory concerns
16:37:50 <benmachine> as in, let each computation run to completion before starting another
16:37:51 <copumpkin> we should distinguish GHC thread from OS thread
16:38:01 <lispy> :t let alone = fix id in forever alone
16:38:02 <lambdabot> forall (m :: * -> *) b. (Monad m) => m b
16:38:05 <cheater00> benmachine: on a single processor, only one thread is running at a time anyways.
16:38:24 <jmcarthur> cheater00: why not threads though?
16:38:38 <cheater00> jmcarthur: why aren't you using perl though?
16:38:40 <copumpkin> cheater00: that doesn't mean I can't block reading a haskell socket and do stuff in another GHC thread though
16:38:43 <benmachine> jmcarthur: he did say some things just up there ^^
16:38:47 <mauke> cheater00: I am using perl
16:38:56 <cheater00> mauke: and yet you're still using haskell
16:38:57 <monochrom> anyway, you now know there are coroutine libs and there is cps.
16:38:59 <benmachine> cheater00: no need to be flippant :P
16:39:07 <cheater00> mauke: as it turns out perl wasn't the final answer after all!
16:39:08 <cheater00> :)
16:39:11 <mauke> cheater00: and?
16:39:12 <copumpkin> cheater00: do you realize that?
16:39:35 <jmcarthur> benmachine: i didn't find any reasons
16:39:36 <cheater00> copumpkin: yes, i realize that
16:39:49 <copumpkin> cheater00: okay, just making sure :) so you acknowledge that blocking is not an issue with GHC's threading
16:39:52 <copumpkin> you're just worried about memory?
16:40:00 <mauke> cheater00: we've got stuff that works well and is supported by libraries and does pretty much what you describe
16:40:08 <mauke> cheater00: so ... why?
16:40:22 <cheater00> mauke: because it is not what i describe.
16:40:29 <jmcarthur> cheater00: what does perl have to do with this at all?
16:40:31 <copumpkin> I can almost understand wanting super fine-grained cooperative multitasking
16:40:31 <mauke> cheater00: what are the differences?
16:40:43 <copumpkin> but then if you keep comparing us to C or perl as a rhetorical insult
16:40:45 <mauke> cheater00: what exactly do you need?
16:40:50 <copumpkin> then I'm puzzled
16:40:55 <BW^-> do you experience liveness problems in haskell sometimes, i.e. it delayed the evaluation of some expensive calculation, until right after the user made a command and is now waiting lots for response?
16:40:57 <copumpkin> because manually dealing with all your yield points seems pretty low-level
16:41:18 <monochrom> while I admit "want haskell and avoid threads" has only a high probability but not 1 of being wrong (I know there are exceptions), "want haskell, avoid threads, and be high-level" pushes it too far and is a definite oxymoron. I'm sorry, controlling cooperative multitasking yourself is low-level by definition, control freak.
16:41:28 <jmcarthur> copumpkin: even if you're wanting the scheduling to be fine-grained, we have a yield action :)
16:41:40 <copumpkin> jmcarthur: yeah, but you can't stop it from yielding when you don't want it to
16:41:42 <phreak> interact f = do s <- getContents; putStr (f s) <-- what is interact?
16:41:47 <cheater00> mauke: what i want to reach is: final control over how multitasking happens; an easier model of sharing data than normally it happens in threads; a callback-based framework
16:41:48 <copumpkin> @src interact
16:41:48 <lambdabot> interact f = do s <- getContents; putStr (f s)
16:41:54 <mauke> phreak: exactly that
16:42:03 <phreak> what does it do?
16:42:06 <phreak> i don't know haskell yet
16:42:06 <mauke> cheater00: why?
16:42:10 <copumpkin> phreak: it asks for stdin, runs a function, and prints it to stdout
16:42:17 <jmcarthur> not sure i consider that a really bad problem though. i can't think of any cases where i'd really want to prevent it from yielding
16:42:23 <cheater00> jmcarthur: threads (forced multitasking) are to cooperative multitasking what haskell is to language X
16:42:26 <copumpkin> jmcarthur: yeah, it seems pretty arbitrary
16:42:30 <phreak> oh
16:42:36 <jmcarthur> cheater00: wtf?
16:42:41 <mauke> cheater00: no, it isn't
16:42:48 <copumpkin> I have a feeling we're being trolled
16:42:53 <jmcarthur> cheater00: you have some massive misunderstanding of what threads are then
16:42:56 <cheater00> copumpkin: ???
16:43:19 <copumpkin> [07:40:32 PM] <copumpkin> cheater00: okay, just making sure :) so you acknowledge that blocking is not an issue with GHC's threading
16:43:19 <copumpkin> [07:40:35 PM] <copumpkin> you're just worried about memory?
16:43:20 <copumpkin> is that it?
16:43:22 <jmcarthur> cheater00: threads are nothing more than separate processes which may communicate with each other. they are a programming abstraction to make your code easier to follow
16:43:22 <monochrom> interact example: main = interact (show . length . lines)
16:43:42 <BMeph> copumpkin: I think you just got "Trick-trolled"! ;p
16:43:53 <cheater00> jmcarthur: describe the definition of cooperative multitasking as opposed to forced multitasking and show me that threads are the former.
16:44:00 <jmcarthur> huh?
16:44:04 <copumpkin> cheater00: can you respond to my question?
16:44:13 <jmcarthur> you're asking me to demonstrate some arbitrary point that has nothing to do with what i said
16:44:14 <mauke> cheater00: threads are callback based; I don't understand the part about usual data sharing; why do you need final control?
16:44:19 <monochrom> time-slicing gets you tick-tolled :)
16:44:44 <cheater00> copumpkin: i have answered your question. the answer is that i'm describing a completely different programming model. forcing your habit as the single true way of doing things is not constructive.
16:44:58 <jmcarthur> cheater00: threads fit both of those terms (although i would say "preemptive multitasking" instead of "forced multitasking")
16:45:13 <cheater00> mauke: the memory "issue" is one example
16:45:14 <copumpkin> cheater00: it just sounds like you keep joking that we might as well write in C (ultimate insult) if we don't want to manually handle all yield points...
16:45:20 <mauke> cheater00: what memory issue?
16:45:23 <copumpkin> cheater00: which seems almost oxymoronic
16:45:24 <monochrom> "why not use C" is a really good question. you want your model? use C, it fits better.
16:45:34 <cheater00> jmcarthur: no, no they don't. the two terms are disjoint.
16:45:39 <mauke> monochrom: not hugs?
16:46:03 <monochrom> it is really not copumpkin forces his model on you. more like haskell forces its model on you.
16:46:03 <Adamant> @karma monochrom 
16:46:03 <lambdabot> monochrom has a karma of 16
16:46:09 <cheater00> copumpkin: you misunderstood what i meant there.
16:46:13 <Adamant> monochrom++
16:46:15 <copumpkin> cheater00: but sure, if you want a lower-level programming model, you're welcome to implement it the way I described earlier.
16:46:17 <BW^-> is there any way to make a list with mixed variable types in it?
16:46:31 <copumpkin> cheater00: anyway, I linked to the coroutines package on hackage
16:46:33 <cheater00> copumpkin: i never said i wanted a lower-level programming model.
16:46:36 <mauke> BW^-: what would you do with such a list?
16:46:39 <copumpkin> cheater00: yet you described one
16:46:49 <jmcarthur> cheater00: "cooperative threading" vs. "premptive threading". they are threads in both cases
16:46:54 <copumpkin> cheater00: one where things that the RTS can reasonably do a good job at something is something you want to handle manually
16:46:58 <ian_mi> maybe HList
16:47:02 <mauke> cheater00: you said "final control". that is low-level
16:47:06 <cheater00> jmcarthur: i think you're confused about what i asked about
16:47:14 <jmcarthur> indeed i am. i still don't see the point
16:47:32 <copumpkin> cheater00: somehow we're all magically confused at what you want :) perhaps it was the original question that was unclear
16:47:34 <cheater00> jmcarthur: i think you jumped in a bit too late
16:47:40 <jmcarthur> i read the backlog
16:47:40 <Axman6> cooperative multitasking used to be used on pre X Mac OS, where each process would define when it could be swapped out (which would lead to the whole system freezing if a process froze)
16:47:51 <jmcarthur> you never said why you don't want threads
16:47:54 <Axman6> i think early windows used it too
16:48:09 <jmcarthur> any time somebody asked why, you responded with some weird quip about C or Perl
16:48:10 * monochrom learned cooperative multitasking from windows 3.x
16:48:10 <cheater00> jmcarthur: read the backlog again, i have about three times now.
16:48:22 <mauke> cheater00: no
16:48:33 <jmcarthur> cheater00: vague analogy to C or Perl is not an answer to the question
16:48:35 <cheater00> mauke: no what?
16:48:38 <mauke> cheater00: you haven't
16:48:41 <cheater00> jmcarthur: three other times.
16:48:49 <jmcarthur> please quote it?
16:48:50 <mauke> cheater00: AFAICS you haven't responded to <mauke> cheater00: threads are callback based; I don't understand the part about usual data sharing; why do you need final control?
16:48:57 <mauke> or that "memory issue"
16:48:59 <BW^-> mauke: still, is there any way to do that
16:49:01 <Axman6> cheater00: may i ask what your question is?
16:49:03 <BW^-> ian_mi: hoW?
16:49:09 <cheater00> mauke: i can only speak with one person at a time.
16:49:10 <mauke> BW^-: do what?
16:49:18 <mauke> cheater00: maybe you shoulda used threads
16:49:20 <BW^-> mauke: a list with elements of mixed types
16:49:27 <Axman6> BW^-: you don;t want a list with mixed types in it
16:49:30 <mauke> BW^-: that's not "do", that is "be"
16:49:34 <mauke> BW^-: what would you do with such a list?
16:49:37 <cheater00> mauke: i hope you understand that it takes time to consider your question and answer it?
16:50:10 <copumpkin> I'd hope that you would have an answer to why you want something before asking for it
16:50:33 <cheater00> the most basic answer was that it's a different programming model that i want to try out
16:50:35 <copumpkin> and, more annoyingly, making quips about C and perl when being questioned about it
16:50:38 <cheater00> that's good enough for me
16:50:46 <copumpkin> and I've answered the actual question
16:50:51 <cheater00> if it's not good enough for anyone in here, in the end they don't have to help me further
16:50:55 <cheater00> that's fine
16:50:58 <jmcarthur> i'm not sure how different it really is
16:51:02 <copumpkin> the rest of the discussion was about why you thought you needed it
16:51:02 <cheater00> any help is appreciated
16:51:11 <jmcarthur> cooperative multitasking is just about the same thing, but with explicit yields
16:51:25 <jmcarthur> (also, you still aren't guaranteed that garbage collection you mentioned)
16:51:26 <Axman6> can someone repeat cheater00's question? I'm curious
16:51:28 <companion_cube> cheater00, i have the feeling that you have some predjudice against regular threads
16:51:49 <mauke> correct me if I'm wrong, but aren't threads in hugs cooperative?
16:51:50 <copumpkin> there's also http://hackage.haskell.org/package/monad-coroutine
16:51:54 <companion_cube> whereas haskell threads are green, and thus probably lightweight enough for your needs
16:51:55 <copumpkin> which doesn't have session types piled in
16:52:02 <cheater00> Axman6: i'm just wondering how to do in haskell a callback-based cooperative multitasking scheme based on coroutines that explicitly yield, rather than yield when preempted.
16:52:24 <jmcarthur> i simple way would be to have a Big Lock shared by all threads
16:52:32 <jmcarthur> s/i /a /
16:52:39 <copumpkin> http://random.axman6.com/blog/?p=231
16:52:40 <Axman6> cheater00: http://random.axman6.com/blog/?p=231 ?
16:52:45 <Axman6> bam!
16:52:46 <Axman6> ha
16:52:48 <copumpkin> http://blog.sigfpe.com/2009/11/programming-with-impossible-functions.html
16:52:53 <copumpkin> :)
16:52:59 <Axman6> i didn't write that by the way, blackh did
16:53:27 <cheater00> Axman6: that's cool
16:53:47 <cheater00> Axman6: now you guys need to continue implementing the rest of twisted ;)
16:53:56 <Axman6> ?
16:54:02 <ddarius> Why would we want Twisted?
16:54:09 <Axman6> what's twisted?
16:54:10 <copumpkin> next up, node.js
16:54:12 <copumpkin> :)
16:54:14 <mauke> Axman6: POE in python
16:54:16 <copumpkin> node.hs
16:54:19 <Axman6> POE?
16:54:20 <jeffz`> has someone compiled a tour of libraries one should have on their radar beyond the standard library, like iteratee?  there are too many haskell libraries.
16:54:27 <jmcarthur> looks like some sort of IO system
16:54:27 <mauke> Axman6: twisted in perl
16:54:29 <jmcarthur> which we don't need
16:54:39 <jmcarthur> because GHC's threading implementation is just that awesome
16:54:55 <monochrom> "<cheater00> how can you realize cooperative multitasking in haskell?" and allow me to skip to "<cheater00> and on the other hand, threads can switch the context at the most inconvenient time <cheater00> so you'll have a huge object hanging around in memory"
16:54:58 <ddarius> Twisted is an event-based web framework or something like that for Python.
16:55:14 <Axman6> so, what we already have in GHC?
16:55:20 <jmcarthur> sounds like
16:55:23 <aristid> Axman6: but without threads!
16:55:30 * copumpkin 's knee jerks
16:55:36 <cheater00> twisted is not a web framework.
16:55:41 <Axman6> you can treat ghc's threads as just callbacks :\
16:55:41 <cheater00> twisted is not an IO system.
16:55:47 <lispy> Oh, you have to say cabal-vesion: >= 1.8 to have your build-depends behave correctly.
16:55:48 <jmcarthur> cheater00: it's an "event" system, i know
16:55:56 <ddarius> Sorry "network engine"
16:55:59 <cheater00> twisted is not an event system.
16:56:03 * copumpkin revs up his engine
16:56:09 <cheater00> twisted is not a network engine..
16:56:13 <mauke> but POE is
16:56:13 <copumpkin> "Twisted is an event-driven networking engine written in Python and licensed under the MIT license."
16:56:18 <mauke> clearly twisted is inferior
16:56:21 <ddarius> Perhaps you are talking about a different Twisted."
16:56:33 <copumpkin> "Twisted is a networking engine written in Python, supporting numerous protocols. It contains a web server, numerous chat clients, chat servers, mail servers, and more."
16:56:33 <cheater00> yes, i know what it says there - it's quite an outdated description
16:56:34 <cheater00> :)
16:56:35 <Axman6> cheater00: my car is not a donkey. that doesn't tell you what my car is
16:56:40 <cheater00> there's much more it does :)
16:56:53 <mauke> cheater00: that doesn't invalidate the other stuff
16:56:56 <aristid> Axman6: your car is pretty similar to a donkey IMO
16:56:58 <jmcarthur> so it's really just a collection of networking protocols then?
16:57:02 <monochrom> candidly, when I use gtk2hs, I turn all its traditional event-loop yadayada back to threads.
16:57:04 <copumpkin> this is why we avoid negation as input in constructive logic
16:57:06 <cheater00> mauke: sure, but i'm just saying it's not "just" that
16:57:14 <mauke> cheater00: no, that's not what you're saying
16:57:16 <ddarius> "Python is not a programming language because you can edit text files with it."
16:57:18 <cheater00> actually, sorry if i worded that wrongly
16:57:18 <Axman6> aristid: well, not owning a car would make that quite difficult :P
16:57:28 <cheater00> i think you're right
16:57:29 <companion_cube> copumpkin, maybe this is not a constructive chan :>
16:57:39 <copumpkin> companion_cube: we're pretty constructive in here, usually
16:57:43 <copumpkin> @djinn a -> Not (Not a)
16:57:43 <lambdabot> f a b = b a
16:57:51 <copumpkin> @djinn Not (Not a) -> a
16:57:51 <lambdabot> -- f cannot be realized.
16:57:53 <copumpkin> see?
16:57:57 <Axman6> cheater00: it usually is -_-
16:58:05 <lispy> lots of constructive logic talk anyway
16:58:07 <copumpkin> @djinn Either a (Not a)
16:58:07 <lambdabot> -- f cannot be realized.
16:58:09 <copumpkin> :(
16:58:18 <copumpkin> @djinn Not (Not (Either a (Not a))
16:58:18 <lambdabot> Cannot parse command
16:58:22 <copumpkin> @djinn Not (Not (Either a (Not a)))
16:58:22 <lambdabot> f a = void (a (Right (\ b -> a (Left b))))
16:58:40 <jmcarthur> heh
16:58:42 <monochrom> I fact I seriously gave a stab to this event-loop cooperative mumble jumble on http://www.haskell.org/haskellwiki/Gtk2Hs/Tutorials/Intro
16:59:00 * copumpkin goes back to normal and binary obfuscation
16:59:02 <jmcarthur> i have also implemented coroutines in haskell
16:59:04 <copumpkin> *norma
16:59:08 <jmcarthur> was much slower than ghc threads :)
16:59:25 <copumpkin> jmcarthur: clearly your implementation was lacking!
16:59:28 <jeremie> @djinn a -> 1
16:59:28 <lambdabot> Cannot parse command
16:59:31 <monochrom> "In the early days when concurrent programming was not popular, the forefathers decided to use this event dispatch loop" is a way to say "now we know better"
16:59:37 <copumpkin> @djinn a -> ()
16:59:37 <lambdabot> f _ = ()
16:59:42 <jmcarthur> it was a pretty typical continuation-based implementation
16:59:47 <cheater00> Axman6: what i like about it is that it can done quite a lot of different things - anything that needs to happen time-critically
17:00:21 <cheater00> Axman6: for example, because you explicitly define the chunks of your coroutines, you can even prove things about the timing of your system. with threads it might or might not be possible..
17:00:23 <copumpkin> cheater00: the event-based nature of it or the actual coroutine stuff?
17:00:25 <cheater00> or difficult
17:00:31 <copumpkin> ah
17:00:42 <cheater00> copumpkin: well the coroutine stuff is what enables this one thing i mentioned
17:00:47 * ddarius has implemented coroutines with threads.
17:00:51 <mauke> so you think you can prove timing properties of your program
17:00:54 <jmcarthur> cheater00: how does it enable it?
17:00:59 <mauke> hah
17:01:08 <jmcarthur> oh n/m
17:01:11 <jmcarthur> i see what you said now
17:01:13 <ddarius> mauke: The next reality TV show?
17:01:22 <benmachine> cheater00: haskell is bad at hard real-time, I've heard
17:01:27 <benmachine> the GC kind of screws it up
17:01:29 <cheater00> copumpkin: but i like that it's built around callbacks, because it allows you to think about the multitasking differently
17:01:34 <jmcarthur> i'm still not sure i see how, but i at least see that there could be something feasible about it
17:01:38 <ddarius> benmachine: That's true of most GCed language implementations.
17:01:43 <cheater00> mauke: not for all programs, but for some certainly
17:01:52 <benmachine> ddarius: it is, yes
17:01:55 <jmcarthur> benmachine: but cheater00 is comparing it to python, which means this issue is obviously not as time-critical as he thinks
17:01:55 <TTimo> well java has struggled with that for a while
17:02:07 <jmcarthur> since python will suffer from the same issues
17:02:20 <TTimo> benmachine: do you have some references to that particular problem in haskell (scheduling)
17:02:24 <mauke> cheater00: allow me to remain skeptic
17:02:25 <cheater00> jmcarthur: there are different levels of time criticality.
17:02:35 <benmachine> TTimo: nope, sry :P just heard rumour
17:02:38 <cheater00> mauke: you need my allowance? :)
17:02:39 * benmachine not an expert
17:02:41 <alpounet> TTimo, a thread on haskell-cafe
17:02:48 <alpounet> including a message from Simon Marlow
17:02:59 <jmcarthur> i find it doubtful that you'd need to control the granularity of concurrent threads but not the GC
17:03:00 <TTimo> python's GC isn't too bad .. or at least I haven't seen it be as bad as java's but it's not a terribly good benchmark
17:03:12 <mauke> cheater00: things that will screw it up: GC, cache, swap, other processes, me
17:03:31 <alpounet> TTimo, http://www.haskell.org/pipermail/haskell-cafe/2010-March/073942.html
17:03:35 <jmcarthur> control over the former doesn't even solve the "memory issue" you mentioned earlier, without also having control over the latter
17:03:46 <TTimo> ty I'll read through that
17:04:00 * monochrom respects mauke for including himself as a potential problem
17:04:12 <ddarius> TTimo: Python uses reference counting (though I think a full GC may have since been added?).  Java GCs are actually rather good and popular JVM implementations have incremental GCs as well.
17:04:14 <mauke> monochrom: I like to send SIGSTOP to random processes
17:04:19 <monochrom> haha
17:04:19 * benmachine hugs mauke 
17:04:52 <cheater00> other processes can be reniced. swap can be disabled, not sure how cache can kill things. when GC becomes a problem so big that the things i normally do start timing out, there's something wrong with my program or environment
17:05:01 * Axman6 discovered SIGSTOP recently, it makes life a lot nicer on OS X when mds decided it needs to index everything on your harddrive while on battery
17:05:04 <jmcarthur> or your code
17:05:16 <Axman6> sudo killall -STOP mds # yay
17:05:21 <monochrom> we need to remember that PEBKAC far shadows any problems of imperfect automatic mechanisms (schedulers, gc)
17:05:23 <jmcarthur> well i guess program can be code. i interpreted it as "RTS" but see that that may be wrong
17:05:59 <mauke> cheater00: isn't it the same with GC/threads?
17:06:01 <jmcarthur> cheater00: perhaps a better question would have been "how can i keep my GC cost lower?" then
17:06:33 <jmcarthur> because i really doubt that going with coroutines is the answer
17:06:52 <cheater-> sorry, daily disconnect i guess
17:07:00 <cheater-> jmcarthur: look, coroutines is one way of doing things
17:07:08 <jmcarthur> how does it even solve the problem?
17:07:16 <cheater-> jmcarthur: just like haskell is one way of doing things, perl another, c another, python another
17:07:30 <cheater-> different ways work for different situations
17:07:37 <jmcarthur> i can see that, but then you keep saying things about the "memory problem" and stuff
17:07:48 <mauke> .oO( haskell for threads, perl for not-threads )
17:07:58 <cheater-> and you want to know how it solves this "memory problem"?
17:08:02 <jmcarthur> yes
17:08:06 <cheater-> it doesn't
17:08:11 <mauke> in #perl the consensus is "whatever you do, don't use perl's threads"
17:08:13 <jmcarthur> ... then why mention it?
17:08:14 <cheater-> what i mentioned is a possible situation
17:08:32 <Axman6> (Haskell for threads, perl for "no, my code's not compiling, it's just running")
17:08:36 <cheater-> which may happen in threads where you cannot control it, and may happen in coroutines where you can control it
17:09:08 <mauke> ok, can anyone explain to me what this "memory issue" is?
17:09:11 <Axman6> but haskell threads are so close to being coroutines anyway
17:09:40 <ddarius> In fact, without the threaded RTS, Haskell threads are essentially coroutines.
17:09:47 <Axman6> aye
17:09:52 <jmcarthur> mauke: allocate large object in thread A with intent to deallocate it quickly, but then get preempted by thread B, so the object has to stick around until thread A wakes up again.
17:10:03 <TTimo> jmcarthur: I would really want to be able to manage my GC's cost with some granularity .. the problem with java was the "GC storms" where the GC would start to hold locks and purge things, without you having much to say about it, and not knowing for how long it will go. Cassandra has those problems, where the GC on one node in the cluster goes crazy for a while .. the expectation is that it never happens on all the nodes at the same
17:10:06 <Axman6> you just get coroutines running on multiple cores for free when you turn on -Nn
17:10:30 <jmcarthur> mauke: of course in haskell you don't do deallocation manually anyway, and the GC is also decoupled from threads
17:10:41 <monochrom> "memory issue": a thread has allocated much memory. now it is ready to deallocate though (or rather, lose the ref so gc will deallocate). but just before it gets to deallocate (or lose thread), it is pre-empted, and is not scheduled for another month.
17:10:46 <gwern> > 5000 / 60
17:10:47 <lambdabot>   83.33333333333333
17:11:06 <monochrom> s/lose thread/lose ref/
17:11:11 <jmcarthur> well, you do manual deallocation in some cases i guess
17:11:22 <jmcarthur> but that's "low level" type stuff
17:11:23 <cheater-> jmcarthur: you deallocate manually by exiting from the context where that thread is
17:11:28 <cheater-> er
17:11:31 <cheater-> where that object is.
17:11:37 <jmcarthur> cheater-: the GC still won't necessarily fire then
17:11:41 <monochrom> yes, the objection is "pre-empted just before it manually deallocates, "
17:11:43 <mauke> cheater-: that's not deallocation
17:11:58 <cheater-> mauke: yeah. i know it was a simplification from my side
17:12:13 <monochrom> and yes, the objection is also "pre-empted just before exiting the relevant context"
17:12:51 <monochrom> but quite frankly the real problem is "and not re-scheduled for another month" and I don't see that happening.
17:12:52 <jmcarthur> i could see the desire to do this if you could also control the GC
17:12:56 <cheater-> well, the situation here is that if you get preempted at the wrong moment, you can't GC the big object, so you have to swap it out
17:13:00 <cheater-> which is obviously very bad
17:13:06 <mauke> how often does this occur in practice?
17:13:23 <mauke> given that the memory allocator is an entry point to the select loop
17:13:59 <cheater-> mauke: ever noticed ms word 2010 does exactly the same thing as ed, but requires a computer 10^6 times faster? ;)
17:14:10 <cheater-> mauke: that sort of question is why ;)
17:14:16 <mauke> cheater-: no, I haven't
17:14:17 <monochrom> if you make sure other threads also get pre-empted, your thread will be re-visited promptly and your losing ref, exiting context etc will happen just as promptly
17:14:32 <monochrom> is ms word 2010 written in haskell?
17:14:32 <cheater-> mauke: just a joke, but with a little grain of truth
17:15:00 <mauke> the big object is only a problem if another thread tries to allocate more
17:15:09 <ddarius> Ironically, some of the issues with Word may be due to too little concurrency.
17:15:17 <mauke> allocating more leads to preemption
17:15:24 <jmcarthur> i don't understand the ms word argument. are you claiming that the problem is that we are going with higher level abstractions which are inherently slower?
17:15:41 <ddarius> One could also pin the object in real memory.
17:16:02 <ddarius> jmcarthur: You don't understand it because it is nonsensical.
17:16:18 <jmcarthur> argument by analogy tends to be that way
17:16:27 <monochrom> yeah, what mauke says. if another thread tries to allocate, scheduler goes back to your thread actually, and your deallocation kicks in.
17:17:04 <cheater-> jmcarthur: no, i'm saying that there's those little questions and little issues that "don't happen too often", but in the end when a huge amount of small issues amass they end up growing to the visible difference in required processing power to reach the same functionality
17:17:14 <monochrom> and yeah, everyone please seek to break every analogy and render it useless
17:17:26 <monochrom> @quote monochrom analog
17:17:26 <lambdabot> No quotes match. Maybe you made a typo?
17:17:29 <cheater-> monochrom: what if before i deallocate i do just enough processing that my thread has to yield again?
17:17:30 <monochrom> @quote monochrom analogy
17:17:30 <lambdabot> No quotes match. I am sorry.
17:18:26 <cheater-> so let's say thread t1 allocates object O1, then does some processing, then is preempted. then t2 allocates O2. then t1 does a bit more processing, then t2 starts processing O2, and O1 has to be swapped out.
17:19:33 <jmcarthur> cheater-: again, works great *as long as you can control the GC*
17:19:42 <jmcarthur> to solve that issue, i mean
17:19:55 <cheater-> but you can't GC either O1 or O2
17:19:59 <cheater-> they have to co-exist
17:20:09 <jmcarthur> due to the premption, yes, i see that
17:20:12 <monochrom> jmcarthur means your solution
17:20:16 <jmcarthur> but coroutines alone are not enough to solve it
17:20:19 <jmcarthur> you must also control the GC
17:20:24 <cheater-> yes i understand this
17:20:41 <cheater-> but when you run out of memory, this is what happens: 1. GC is invoked 2. swapping happens
17:20:52 <cheater-> at least that's what i understand would normally happen
17:21:00 <ddarius> At any rate, it sounds like the real "problem" is swapping out the "large" object.  So just don't allow it to be swapped out.
17:21:09 <cheater-> so where in the example above you start swapping, the analog in coroutines would just GC
17:21:26 <cheater-> ddarius: and do what? start writing down bits on my napkin? :)
17:21:39 <cheater-> two objects of 200 mb, you have 300 mb ram available..
17:21:40 <ddarius> cheater-: Other allocations can either fail or block.
17:22:11 <benmachine> ddarius: what if the two threads each need two 100MB things, and there's 200MB available?
17:22:28 <cheater-> yeah, let's have the allocation fail and implement this super-complex locking mechanism so that we don't go crazy writing this program
17:22:46 <kniu> Is it me, or is Robert Harper kind of a blowhard?
17:22:53 <ddarius> benmachine: You get a failure if all threads are blocked.
17:22:57 <cheater-> benmachine: i hadn't thought about this. why do you ask?
17:22:58 <monochrom> what is blowhard?
17:23:12 <copumpkin> kniu: slightly
17:23:17 <cheater-> monochrom: an extrovert.
17:23:17 <ddarius> benmachine: Though yes, naively done it could lead to deadlock.
17:23:23 <ddarius> Well, starvation.
17:23:28 <benmachine> cheater-: it's a situation in which running one thread and then the other would work but running them both at once woudl fail in a way that blocking-on-OOM wouldn't fix
17:23:39 <monochrom> @wn extrovert
17:23:41 <lambdabot> *** "extrovert" wn "WordNet (r) 2.0"
17:23:41 <lambdabot> extrovert
17:23:41 <lambdabot>      adj : characterized by extroversion [syn: {extravert}, {extroverted},
17:23:41 <lambdabot>             {extraverted}, {extrovertive}, {extravertive}]
17:23:41 <lambdabot>      n : (psychology) a person concerned more with practical
17:23:43 <lambdabot>          realities than with inner thoughts and feelings [syn: {extravert}]
17:23:45 <lambdabot>          [ant: {introvert}]
17:23:45 <cheater-> benmachine: ahh ok.
17:23:58 <cheater-> monochrom: think "marketing team"
17:24:00 <benmachine> ddarius: solution: buy more RAM
17:24:01 * benmachine nods
17:24:17 <cheater-> benmachine: yes, that's a good example to think about
17:24:30 <cheater-> thanks for bringing it up :)
17:24:34 <benmachine> I think my solution is a good one :P
17:24:47 <cheater-> what's your solution?
17:24:53 <monochrom> marketing people don't seem practical or realistic to me. except for their own paychecks, of course.
17:24:56 <benmachine> more memory >_>
17:24:57 <cheater-> oh
17:25:01 <cheater-> :(
17:25:02 <cheater-> lol
17:25:04 <kniu> Man
17:25:05 <benmachine> the RAM manufacturers gotta feed their kids
17:25:36 <ddarius> benmachine: Maybe they will start a war in Silicon Valley and raise the price of barrels of RAM.
17:25:47 <kniu> Second proggit shitstorm this week due to this guy.
17:25:47 <cheater-> haha.
17:26:07 <cheater-> kniu: what's proggit?
17:26:25 <kniu> reddit.com/r/programming
17:26:53 <cheater-> oh.
17:27:16 <dolio> Harper is right, and he's not afraid to say so. :)
17:27:45 <monochrom> shitstorm? did harper say anything wrong?
17:28:15 <cheater-> heh who's harper now_
17:28:17 <cheater-> ?
17:28:17 <dolio> Not wrong. Unpopular, perhaps.
17:28:29 <cheater-> some known troll?
17:28:34 <monochrom> harper's home page is http://www.cs.cmu.edu/~rwh/
17:28:44 <cheater-> looking!
17:28:47 <dolio> He's a badass programming languages researcher.
17:28:56 <dolio> And teacher, I guess.
17:29:09 <monochrom> alright, saying nothing wrong and still a shitstorm reflects the quality of the audience rather.
17:29:35 <kniu> well
17:29:40 <kniu> he's technically right
17:29:54 <dolio> The best kind of right.
17:29:56 <Adamant> "the very best king of right"
17:29:59 <Adamant> kind
17:30:01 <Adamant> gah
17:30:12 <kniu> the attitude is what bothers people
17:30:15 <Adamant> dolio got me and I misspelled
17:30:41 <Adamant> kniu: I was going to attribute it to a Engineercrat 3rd class
17:32:18 <Axman6> cheater-: regarding your earlier questions, i should have mentioned the event package, which lets you give event callbacks to libevent, which might be what you were after
17:32:29 <cheater-> cool
17:32:32 <cheater-> looking!
17:33:17 <cheater-> this? http://hackage.haskell.org/package/control-event
17:33:39 <Axman6> no, one sec
17:33:57 <cheater-> ok!
17:34:05 <cheater-> (i'll have to go to sleep soon though)
17:35:06 <jmcarthur> i'm liking harper's blog, personally
17:35:25 <copumpkin> he's a little overassertive for my liking, but I generally agree with what he says
17:35:32 <alpounet> liking it too
17:36:56 <Axman6> cheater-: this is the one, but that is now the IO manager in GHC. there's no difference between using haskell threads and using this library, except ease of use: https://github.com/tibbe/event
17:37:23 <jmcarthur> i'm tired of people being all relativistic about computer science. "I may have differing opinions, but whatever works for you is right for you..."   there are a few things where heated debate amounts to nothing more than bikeshedding, but i don't think harper has touched any of those issues in his blog so far, and having an assertive opinion is direly needed in the areas he has touched
17:37:25 <cheater-> :)
17:38:10 <copumpkin> I mean things like "you probably went to CMU"
17:38:11 <copumpkin> :P
17:38:17 <jmcarthur> because right now most people in the field are running around and screaming "fire!" instead of looking for an extinguisher
17:38:24 <jmcarthur> on some of these issue
17:38:31 <jmcarthur> and then there are others like dynamic typing, of course :P
17:38:38 <copumpkin> and also, I'd have pre-empted some of the counterarguments people have used against that dynamic typing article
17:38:44 <jmcarthur> agreed
17:38:57 <copumpkin> otherwise it just doesn't look like he's considered his position fully
17:38:57 <jmcarthur> i think his biggest flaw is overestimating his readership :(
17:39:27 <cheater-> you can never overestimate readership
17:39:46 <cheater-> http://tvtropes.org/pmwiki/pmwiki.php/Main/ViewersAreMorons
17:41:18 <jmcarthur> in a field which should be intellectual and open-minded but is, in reality, quite superstitious and dogmatic, yes, you can overestimate your readership
17:41:24 <monochrom> please don't call a correct assertion "an assertive opinion". it is not an opinion; it is the correct answer.
17:41:55 <jeffwheeler> Can I write a client application that uses the 'authenticate' package, or is that intended for the server-side part of it?
17:41:56 <jmcarthur> monochrom: yeah i thought about correcting myself on that after saying it, but thought it might just be more line noise if i did
17:42:10 <monochrom> calling every statement "opinion" is equivalent to the relativisitism problem.
17:42:14 <jeffwheeler> I'd assume I could write client-side apps, but it depends on 'wai' and similar server stuff.
17:42:17 <jmcarthur> agreed
17:42:27 <jmcarthur> i succumbed to the very thing i was complaining about
17:44:06 <cheater-> jmcarthur: oh sorry, i'm sleepy, i meant you can never underestimate.
17:44:28 <cheater-> anyways, thanks for the links and the ideas to whoever gave input earlier
17:44:41 <cheater-> i'm off to watch some tv while drifting to sleep :)
17:48:07 <alpounet> jmcarthur, on the other hand, he better overestimate rather than underestimate his readership
17:48:55 <ezyang> I have the following statement: Consistency of intuitionistic propositional logic is equivalent to "there exists a proposition which is intuitionistically invalid." I don't believe it. Can someone convince me otherwise? 
17:50:38 <monochrom> I don't see any attitude problem in Harper's blog article. The tone is even humorous, not acidic. I haven't examined his replies to people's replies for attitude problems.
17:52:09 <ddarius> ezyang: Define "intuitionistically invalid."
17:52:38 * hackagebot cuda 0.3.2.2 - FFI binding to the CUDA interface for programming NVIDIA GPUs  http://hackage.haskell.org/package/cuda-0.3.2.2 (TrevorMcDonell)
17:52:51 <ezyang> The notation specifically used is |/- P (a turnstile with a slash through it). Let me dig up the def. 
17:53:32 <dolio> ezyang: P = false.
17:54:01 <ddarius> exists /= forall
17:54:15 <ezyang> Ahh. 
17:55:05 <carlo_au> seafood: do you guys at Nicta use Haskell?
17:55:06 <ezyang> I guess the next thing I should convince myself is that there isn't any case where some statement is not derivable, but false is. But that can't happen due to the principle of explosion. *phew* 
17:55:14 <dolio> Not all intuitionistic logics would necessarily have a false atom, though, so the statement you cited is more general.
17:55:31 <seafood> carlo_au:  Indeed we do.
17:55:41 <monochrom> what is the principle of explosion?
17:55:48 <monochrom> (great name hahaha)
17:55:56 <ddarius> forall a. false => a
17:55:59 <carlo_au> seafood: what sort of stuff? (if I may ask)
17:56:04 <Axman6> seafood: where're you based? Sydney or Canberra?
17:56:10 <monochrom> oh I see. thanks.
17:56:18 <ezyang> dolio: Oh? Don't boolean algebras have to have top and bottom elements? 
17:56:27 <seafood> carlo_au: Axman6: Based in Sydney. We are using it to program GPUs at the moment.
17:56:38 <copumpkin> forall a. a => false
17:56:44 <monochrom> an intuitionistic logic is only required to be a heyting algebra.
17:56:49 <seafood> We have an embedded domain specific compiler that we are using to generate CUDA code and hopefully OpenCL in the future.
17:56:54 <dolio> ezyang: You mean Heyting algebras? :)
17:56:56 <ezyang> ...huh. 
17:57:21 <Axman6> seafood: you (and anyone else who's using haskell ay NICTA) should come along to our haskell hackathon later this year
17:57:23 <ezyang> I must admit, I don't really understand why I need the Heyting Algebra formalism :-) 
17:57:24 <copumpkin> forall a. a => true, too
17:57:29 <dolio> Anyhow, there can be some variation in what you take the primitive connectives of your logic to be.
17:57:39 <Axman6> seafood: are you working with Manuel?
17:57:46 <monochrom> but even without caring about that, you get to define the grammar of your logic's syntax, you get to omit a symbol for "false".
17:57:50 <dolio> Taking 'false' as a nullary one is just one possibility.
17:58:01 <seafood> Axman6: For sure! And yes, I work with Manuel. PLS@UNSW is a collaborator on our project.
17:58:02 <copumpkin> ezyang: to get rid of double negation or LEM
17:58:17 <seafood> Axman6: I was at the last hackathon by the way.
17:58:36 <Axman6> oh? what was your name? i didn't recognise the nick
17:58:39 <ezyang> copumpkin: Hmm? 
17:58:45 <dolio> ezyang: Maybe there's no 'false', but '0 = 1' can serve the same purpose, for instance.
17:58:49 <Axman6> s/was/is/, I'm assuming it hasn't changed :P
17:58:51 <copumpkin> ezyang: you mean why a heyting algebra over boolean algebra?
17:59:02 <ezyang> copumpkin: No, I mean, why algebras at all :-) 
17:59:16 <monochrom> to please the algebraists
17:59:23 <copumpkin> ezyang: it's just a model :P
17:59:38 <ezyang> This is me being slightly sore, because I spent this afternoon proving properties about lattices instead of reading about C-H :-/ 
17:59:39 <seafood> Axman6: I go by Sean Seefried in meatspace
17:59:40 <tawe> @src (++)
17:59:40 <lambdabot> []     ++ ys = ys
17:59:40 <lambdabot> (x:xs) ++ ys = x : (xs ++ ys)
17:59:40 <lambdabot> -- OR
17:59:40 <lambdabot> xs ++ ys = foldr (:) ys xs
17:59:54 <monochrom> lattices > C-H
17:59:55 <seafood> Axman6: Where is this year's hackathon going to be?
18:00:21 <seafood> Axman6: And we are referring to AusHack aren't we? 
18:00:22 <Axman6> Hopoefully in the city, blackdog might be able to get us a place at his work hopefully
18:00:27 <Axman6> yeah
18:00:35 <Axman6> AusHac2011
18:00:36 <ezyang> dolio: I think what you described is a trivial algebra, which isn't very interesting? 
18:00:44 * monochrom feels that C-H is overrated and often used misleadingly
18:01:02 <Axman6> need to talk to ivanm about it again, we need to start organising soon
18:01:02 <ezyang> Perhaps :-) 
18:01:10 <copumpkin> preflex: seen dolio
18:01:11 <preflex>  dolio was last seen on #haskell 2 minutes and 25 seconds ago, saying: ezyang: Maybe there's no 'false', but '0 = 1' can serve the same purpose, for instance.
18:01:23 <copumpkin> wtf
18:01:31 <copumpkin> is my client /ignor'ing dolio?
18:01:38 <dolio> Is it?
18:01:43 <copumpkin> lol
18:01:50 <copumpkin> yeah
18:01:56 <copumpkin> I wonder when that happened
18:02:07 <accel> i wonder how much money can be made
18:02:11 <accel> wrong channel
18:02:15 <accel> #haskell is for academic stuff; sorry
18:02:27 <dolio> ezyang: When did I describe a trivial algebra?
18:02:30 <monochrom> there is an academic answer for that, too.
18:02:32 <Adamant> NO, IT IS YOU WHO ARE WRONG
18:02:37 <ezyang> dolio: When you set 0 = 1? 
18:02:43 <accel> monochrom: what's the academic answer?
18:02:44 <Axman6> seafood: any work being done on OpenCL at all? Manuel mentioned he was more interested in it since his new MacBook Pro has an AMD GPU :P
18:02:50 * accel was thinkgina bout releasing bsd licensed games
18:02:50 <ezyang> I might have misunderstood. 
18:02:51 <dolio> ezyang: No, I mean, you can use '0 = 1' for your "false statement."
18:02:52 <accel> on the apple store
18:02:57 <ezyang> ah, I see. 
18:02:57 <seafood> Axman6: None so far.
18:02:59 <dolio> Instead of some atom "false".
18:03:03 <Axman6> :(
18:03:16 <Axman6> the work AMD are doing with OpenCL and haskell looks quite promising
18:03:24 <Axman6> wish they'd release it
18:03:33 <dolio> ezyang: Or if you're more controversial, you can use a proposition that is true in classical mathematics, but you personally disagree with.
18:03:37 <monochrom> you can estimate how many printing presses are in good shape in the world, and how much they can print at what speed, therefore how much money they can print if they are all used so simultaneously.
18:03:53 <ezyang> hahaha 
18:04:37 <monochrom> hahahah dolio++
18:05:21 <ddarius> (F = G) OR (F /= G)
18:05:32 <ezyang> Mmm, topological spaces form heyting algebras... 
18:05:38 <ezyang> I think I might like categorical logic... 
18:05:49 <ddarius> Many things form Heyting algebras.
18:05:49 <copumpkin> ezyang: all the cool kids are doing it
