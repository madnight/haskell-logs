00:10:19 <mgsloan> https://bugs.launchpad.net/ubuntu/+source/haskell-platform/+bug/742052
00:10:49 <mgsloan> pretty sure that ubuntu is trying to undermine haskell.. doing a good job of avoiding success!
00:11:32 <ivanm> heh
00:11:47 <mgsloan> I take it that the issue is that all of the 1337 people are arching it up, so the problem doesn't get fixed
00:13:47 <sebz> is there a name for (\f x -> f x)?
00:14:01 <ivanm> ($)
00:14:20 <sebz> thanks
00:15:02 <olsner> or id
00:15:36 <sebz> @ty (\f x -> f x)
00:15:36 <lambdabot> forall t t1. (t -> t1) -> t -> t1
00:15:50 <mgsloan> seriously.  It's pretty sad that the repo hasn't been fixed even though a guy's posted up a ppa
00:15:50 <sebz> @ty id
00:15:51 <lambdabot> forall a. a -> a
00:16:09 <Eduard_Munteanu> (id f) x
00:16:09 <hvr> ...are there examples somewhere about using bos' text-format package?
00:16:18 <mgsloan> afaict, anyone upgrading from lucid to natty will end up with broken haskell
00:16:37 <Eduard_Munteanu> id f x
00:17:39 <davidbe> mgsloan: exactly my reason why I changed distro...
00:17:55 <Eduard_Munteanu> Arch and Gentoo seem to have reasonable Haskell support.
00:19:06 <davidbe> I advice Arch Linux too
00:24:58 * hackagebot egison 0.3.0.0 - An Interpreter for the Programming Language Egison  http://hackage.haskell.org/package/egison-0.3.0.0 (SatoshiEgi)
00:32:07 <jesse_> hi
00:34:30 <jesse_> I've a problem with lazy evaluation: my datatype is instance of monad and monadio, but the monadic functions ( Int -> GL() ) were not evaluated by ghc. I've tried to add some strictness to my bind(>>=) operation via case, but that doens't works too.
00:35:29 <jesse_> http://pastebin.com/2QEJGwEp (I know, my monad looks like shit. :P )
00:35:31 <mauke> The paste 2QEJGwEp has been copied to http://hpaste.org/48457
00:36:19 <mgsloan> davidbe - yeah, I've arched before, it was definitely good
00:36:50 <mgsloan> but I was worried about wireless drivers 'n such like that
00:36:58 <wae> arch = awesome distro
00:37:45 <ion> “is equal to” ≠ “is”
00:38:17 <wae> ion: arch is an awesome distro :p
00:38:28 <jesse_> Has anyone an idea how i can force my monad to be executed?
00:38:36 <wae> simple, no politics, and it's all up to you
00:38:53 <wae> and it's not "all" up to you like gentoo
00:39:03 <wae> it's just the right level of control/simplicity, I guess
00:39:32 <wae> in gentoo, suicide is still encouraged, for instance :p
00:41:52 <Saizan> jesse_: strictness has nothing to do with IO side-effects being executed or not
00:42:08 <Saizan> (unless you start using unsafeInterleaveIO)
00:42:20 <Saizan> jesse_: how is GL defined?
00:44:44 <Eduard_Munteanu> Maybe   Arch ∈ awesome_distros
00:45:40 <ivanm> mgsloan, Eduard_Munteanu: blah!
00:46:28 <jesse_> Saizan: Okay, I thought I can force the compiler via strictness to execute something. ( GL{ runGL :: (a, [IO ()], GLState, IO a) } )
00:47:53 <ion> Define “execute something”.
00:48:00 <Eduard_Munteanu> jesse_: how would you? You can only 'seq' to WHNF
00:48:04 <Saizan> jesse_: no, to make the side-effects described by a value of type IO X be executed you've to make that value a part of main
00:48:36 <Saizan> jesse_: usually by composing it with other actions using IO's >>=
00:49:00 <Eduard_Munteanu> But having something of type 'IO x' in WHNF doesn't get you that.
00:50:14 <Saizan> where WHNF means Weak Head Normal Form, i.e. the value has been evaluated enough to tell its outermost constructor
00:50:31 <jesse_> k.
00:52:28 <Saizan> e.g. "main = let GL (_,_,_,m) = foo in m" this program would execute the IO action in the fourth field of foo but the ones in the list of the second argument are ignored
00:53:16 <jesse_> Ah, okay. thx
00:56:29 <jesse_> Saizan: Big thanks. The program works. :P
00:57:31 <Saizan> jesse_: cheers :)
00:58:12 * Saizan wonders if we have a standard article on building your own monads
00:58:59 <jesse_> Saizan: Hehe, that was not my problem. I think my problem was that I forgot haskell's way of lazy evaluation.
00:59:24 <Saizan> heh, ok
01:02:46 <mrcarrot> dons: it would be very nice of you if you updated your irc bot tutorial to not use the deprecated way of doing exception handling
01:03:38 <mrcarrot> dons: it is still working, but a friend is doing his first haskell program ever with it, and it is unecessary to have a stumbling block for newcomers
01:03:47 <Saizan> or anyone with an haskellwiki account, i guess?:)
01:04:04 <ivanm> does anyone know of a function that will partition an Int into a specified number of Ints? i.e. length (partition n c) == c, sum (partition n c) == n
01:05:04 <mustelo> ivanm, there's more than one partition for a given choice of n and c?
01:05:27 <ivanm> sorry, that should be for all of them
01:05:43 <jinji> is here anyone familier with union types?
01:06:00 <ivanm> all ((==) c . length) (partition n c) && all ((==) n . sum) (partition n c)
01:06:02 * hackagebot digestive-functors 0.1.0.1 - A general way to consume input using applicative functors  http://hackage.haskell.org/package/digestive-functors-0.1.0.1 (JasperVanDerJeugt)
01:06:36 <mustelo> ivanm, you should write that youself, it's not too bad. the only sticking point is how you count duplicates: is [1,2] == [2,1]?
01:07:14 <ivanm> yeah, but before I start writing it I was hoping one already existed ;-)
01:07:38 <mustelo> ivanm, I'm sure. partition is the right name for it; google.
01:07:40 <sebz> partition n c = n : replicate (c-1) 0
01:07:54 <jinji> ivanm?
01:07:58 <jinji> is here anyone familier with union types?
01:08:41 <mustelo> sebz, one down, quite a few to go
01:09:01 <ivanm> jinji?
01:09:02 <sebz> I'm sure I misunderstand the problem
01:09:18 <jinji> ivanm?
01:09:29 <sebz> is the idea to give the number or partitions or generate all partitions or what?
01:09:34 <ivanm> mustelo: I have a function for partitioning in general, but filtering based upon length doesn't sound right ;-)
01:09:36 <mustelo> partition :: Integer -> Integer -> [[Integer]]
01:09:44 <ivanm> jinji: hey, you question-marked  me first!
01:10:01 <sebz> mustelo: ah k
01:10:13 <jinji> ivanm: are u familier about union types?
01:10:34 <ivanm> sebz: when partitioning an integer, it prodices a list/set such that the sum of it is the original value
01:10:48 <ivanm> jinji: I don't even know what a union type is
01:11:11 <ivanm> though IIRC harper had a blog post recently about how lazy langs like Haskell don't do them properly (whilst they _do_ do sum types properly)
01:11:16 <jinji> ivanm: if you have regular types
01:11:42 <ivanm> and what is a regular type? :p
01:12:01 <jinji> regular expression as type: :)
01:12:30 <sebz> ivanm: you want a function that will list all partitions of n of length c, rather than return a particular one that works, right?
01:12:31 <ivanm> uhhhhh..... wtf?
01:12:43 <ivanm> sebz: yup
01:15:02 <sebz> @pl \f x -> f $ g x
01:15:02 <lambdabot> (. g)
01:15:03 * osfameron is quite impressed by mathjax (tex maths layout in javascript for all browsers)
01:15:15 <sebz> hah
01:15:16 <sebz> duh
01:16:00 <osfameron> jinji: it sounds like you want to ask a specific question
01:16:35 <jinji> maybe
01:17:25 <mustelo> ivanm, the best I can think of is to generate lists of length c-1 which sum to less than n, then tack on the difference. that should be better than the naive length-filtering approach
01:19:04 <ivanm> mustelo: yeah, but having it ordered would be preferable
01:19:16 <ivanm> the combinat package seems to have a function that does this; I'm going to see how it does it
01:19:48 <ivanm> (I'd prefer not to use the package itself as I've already ended up re-defining some of the functions it had because I didn't like how it did them)
01:24:47 <ivanm> @hoogle (a -> m Bool) -> [a] -> m Bool
01:24:47 <lambdabot> Prelude concatMap :: (a -> [b]) -> [a] -> [b]
01:24:47 <lambdabot> Data.List concatMap :: (a -> [b]) -> [a] -> [b]
01:24:47 <lambdabot> Prelude (=<<) :: Monad m => (a -> m b) -> m a -> m b
01:25:00 <ivanm> huh, was hoping for a monadic version of all
01:25:19 <ivanm> though I suppose the simplest version would be liftM and . mapM p
01:26:12 <quicksilver> ivanm: yes. "and <$> mapM p"
01:26:29 <quicksilver> good example of where an infix fmap is a nice thing to have
01:26:38 <Saizan> ?type \p -> and <$> mapM p
01:26:38 <lambdabot>     Couldn't match expected type `Bool' against inferred type `[b]'
01:26:39 <lambdabot>       Expected type: [a] -> [Bool]
01:26:39 <lambdabot>       Inferred type: [a] -> [[b]]
01:26:46 <Saizan> ?type \p xs -> and <$> mapM p xs
01:26:47 <lambdabot> forall a (f :: * -> *). (Monad f, Functor f) => (a -> f Bool) -> [a] -> f Bool
01:27:41 <Saizan> it won't short-circuit though, (which might not matter depending on what your 'm' is)
01:27:52 <ivanm> State
01:28:09 <ivanm> specifically, lazy State
01:28:15 <ivanm> so that should short-circuit, right?
01:28:35 <quicksilver> I think so yes.
01:30:36 <Saizan> i suspect that forcing the state from a subsequent put would force the whole input list to be traversed
01:31:32 <jesse_> der_eq: TU Braunschweig? :P
01:32:00 <ivanm> well, the list would most likely be short anyway
01:33:36 <der_eq> jesse_: indeed :)
01:34:03 <Saizan> s/put/get/ -- btw
01:38:02 <ivanm> Saizan: why would it?
01:38:59 <quicksilver> Saizan: lazy State is quite good at avoiding work
01:39:28 <Saizan> mapM f (x:xs) = liftM2 (:) (f x) (mapM f xs) -- so you've to figure out what mapM f xs is to tell what the state is going to be after it
01:39:57 <Saizan> and that will in turn pattern match on xs, recursively
01:40:06 * hackagebot seclib 0.5 - A lightweight library for Information-flow security in Haskell  http://hackage.haskell.org/package/seclib-0.5 (AlejandroRusso)
01:40:11 <quicksilver> yes, it will force the spine of the list
01:40:21 <quicksilver> but I think it might avoid excuting actions it doesn't need to
01:41:38 <ivanm> Saizan: oh, right
01:41:48 <Saizan> it similarly has to compute enough of f x to give the produced state to the recurive call, which might be very little depending on what f is though
01:41:53 <ivanm> Saizan: I think you'd still want put though, not get like you later changed it to ;-)
01:42:24 <ivanm> and I'm really only using the State monad as a Reader monad atm anyway (I _might_ be using it for memoisation purposes later on, which is why it's currently State)
01:42:32 <Saizan> no, get is how you observe the state
01:43:22 <Saizan> a put just after the mapM which doesn't depend on the result of the mapM would actually prevent all this forcing
01:43:25 <Saizan> 9
01:44:11 <ivanm> Saizan: a put within the mapM would possibly change the State though
01:46:19 <Saizan> yeah, the possibility of a put within is what makes the evaluation necessary if you are later using a get to observe the state :)
01:48:01 <hvr> mrcarrot: ...and while at it maybe the RWH chapter on exceptions as well... :)
01:48:37 <mrcarrot> hvr: maybe.. i have not checked it up. i just checked up this bot because of this friend that wants to make a bot for himself
01:50:27 <Saizan> it's a pain that once you start using monads it's much harder to have composable HOFs
01:51:46 <Eduard_Munteanu> They are composable, it's just the same old pain when mixing the two kinds of HOFs
01:52:09 <Eduard_Munteanu> :t (<=<)    -- I mean
01:52:10 <lambdabot> forall b (m :: * -> *) c a. (Monad m) => (b -> m c) -> (a -> m b) -> a -> m c
01:52:25 <Saizan> what do you mean?
01:52:59 <Eduard_Munteanu> You can compose monadic functions of a given type fine, but mixing them (or with non-monadic functions) is where it gets painful
01:53:19 <Saizan> yeah, sorry, i meant usefully composable :)
01:53:42 <iwtu_> my I ask? I don't see, what it is wrong http://codepad.org/RJSFDeAZ
01:54:47 <balor> is there a library function [Char] -> XML ?
01:54:58 <Saizan> in ML it's fine to have "all p = and . map p" but you don't because the end result is not as good as the explicitly short-circuiting recursion
01:55:27 <ivanm> balor: to do what?
01:55:50 <Eduard_Munteanu> XML parsing presumably.
01:55:54 <balor> ivanm, that given an string representation of some XML, generates XML
01:55:56 <ivanm> yeah
01:56:10 <balor> Eduard_Munteanu, d'oh
01:56:12 <ivanm> balor: well, most XML libraries would have something like that...
01:59:19 <balor> Ah, I need String -> HSP.XML specifically
02:05:09 <iwtu_> any idea? I think that in the code http://codepad.org/RJSFDeAZ adjust receive a type and return the same type. But obiously not
02:07:07 <quicksilver> iwtu_: I think the problem is not there. I think the problem is in the type of 'x'
02:07:35 <quicksilver> iwtu_: what type do you imagine/expect 'x' has ?
02:07:52 <chaoflow> would you recommend haskell for platform independent GUI programming (win/linux/mac)? I found wxHaskell (last news from 2009) and gtk2hs which seems more alive.
02:08:14 <quicksilver> gtk2hs doesn't support native mac
02:08:20 <quicksilver> otherwise they are both reasonable choices.
02:08:26 <quicksilver> wxHaskell is certainly not dead.
02:08:48 <iwtu_> quaestor, x should has some Ord type
02:09:07 <iwtu_> quicksilver, , x should has some Ord type
02:09:47 <quicksilver> hmm. I misread. looks again
02:10:48 <quicksilver> iwtu_: ok, the first parameter to Seq.adjust is supposed to be a function
02:10:54 <quicksilver> iwtu_: but you're giving it a map?
02:11:01 <chaoflow> quicksilver: thx
02:11:24 <quicksilver> iwtu_: also, the function 'adjust' you define ignores its parameter 'm' is that intended?
02:12:01 <iwtu_> quicksilver, yes.
02:13:46 <quicksilver> iwtu_: OK, to you understand my point about Seq.adjusts first argument needs to be a function?
02:14:01 <quicksilver> iwtu_: but (adjust item) is not a function, it's a map.
02:14:25 <iwtu_> quicksilver, I do. I am trying to figure out now how fix it
02:14:39 <quicksilver> iwtu_: I think maybe you just wanted to pass 'adjust' not 'adjust item'
02:14:48 <quicksilver> iwtu_: 'adjust' is a function.
02:15:03 <quicksilver> ...but it's very odd to call "Seq.adjust" with a function which ignores its first argument.
02:15:33 <iwtu_> I have thought too. But it is not enough. Yes.
02:18:39 <dmedvinsky> Hey guys, I was wondering what's the best way to parse an date formatted like "1 5 111 1 1" which stands for "1st of June 2011 01:01". Here's what I've come up with so far: https://github.com/dmedvinsky/strave/blob/master/src/main.hs#L22
02:19:10 <iwtu_> quicksilver, thanks for pointing me
02:21:06 <iwtu_> quicksilver, and probably it's all wrong. I have rewrite that
02:22:50 <quicksilver> iwtu_: you might choose names differently ;) having 'adjust' and Seq.adjust was confusing.
02:36:00 <dafis> how do I find out what causes a stack overflow?
02:36:17 <jesse_> Recursion?
02:36:51 <dafis> possibly, but which one?
02:37:19 <zygoloid> "how do I find out what causes a stack overflow?" "start by finding out what causes a stack overflow."
02:37:24 <jesse_> ack
02:38:02 <dafis> no stack overflow with ghc-6, btw, only with 7
02:38:37 <ivanm> profile?
02:38:43 <jesse_> platform?
02:38:54 <ivanm> test individual functions in ghci?
02:39:04 <dafis> jesse_: linux, both x86 and x86_64
02:40:09 <dafis> ivanm: -hT shows a lot of TSO and Blackhole with 7, not with 6, otherwise only the expected stuff,
02:40:24 <ivanm> huh
02:40:30 <ivanm> ask ezyang? :p
02:41:01 <dafis> ivanm: compiling for profiling doesn't reveal anything, only the expected things, no lag, drag, void
02:42:31 <zygoloid> run in a debugger?: )
02:43:40 <dafis> zygoloid: if I knew how to use debuggers, I'd be more optimistic ;)
02:45:24 <Phyx-> hmm think i'll have to go by home.. my server is not responding.. while cleaning i must have accidently pulled a cable..
02:45:29 <Phyx-> ooops
02:49:11 --- mode: ChanServ set +o Saizan
02:49:29 --- mode: Saizan set -q cheater*!*@*
02:49:37 --- mode: Saizan set -o Saizan
02:59:27 <erus`> litterate haskell is pretty cool then :)
02:59:34 <erus`> irony...
03:14:00 * ivanm grumbles at filterM being slower than get'ing the value used for the predicate once and doing the filtering purely
03:34:29 <Peaker> dafis: did you get help with your stack overflow?
03:34:43 <iwtu_> quicksilver, I have a better code but again some problem. I don't like very solotion through case ... of... is same nicer way? http://codepad.org/TOMuSvwx
03:36:44 <dafis> Peaker: nothing which helped me
03:38:13 <Peaker> dafis: did anyone suggest profiling? (heap, retainer, etc)
03:38:33 <Peaker> dafis: do you know the mechanics behind stack use, and what causes overflows?
03:38:46 <Peaker> (Haskell recursion doesn't cause it in general, only in particular cases)
03:38:48 <dafis> Peaker: sure, but I've done that already, didn't reveal anything
03:39:05 <Peaker> dafis: surely you've had a lot of thunks built up at some point?
03:39:57 <dafis> Peaker: no thunks showing in the profiles, my data structures are strict, I have bang patterns all over the place
03:43:27 <Peaker> dafis: bang patterns may make stack overflows MORE likely in many cases :)
03:43:27 <Peaker> dafis: can you show the code?
03:43:36 <iwtu_> allright. any idea how to solve it nicer than ... case ... of .. http://codepad.org/TOMuSvwx ?
03:44:08 <dafis> Peaker: hang on a minute, pasting
03:44:27 <Peaker> dafis: I'm not sure I can help, I'm on a train and my journey ends soon :)
03:47:05 <dafis> Peaker: http://hpaste.org/48462
03:47:38 <dafis> overflows when sieving from roughly 1.4*10^13 and upwards
04:09:54 * hackagebot splot 0.2.0 - A tool for visualizing the lifecycle of many concurrent multi-staged processes.  http://hackage.haskell.org/package/splot-0.2.0 (EugeneKirpichov)
04:40:17 <Peaker> hmm.. I'm getting a profile output in monochrome... what makes it colorful?
04:42:28 <ezyang> -c
04:42:29 <Saizan> -c
04:43:05 <Peaker> thanks
04:43:11 <Peaker> why would the default use monochrome?
04:44:30 <ezyang> I dunno, but would be an easy patch...
04:48:43 <Peaker> dafis: did you figure it out.. I've just started toying around with the profile of your code
04:48:55 <Peaker> dafis: I'm not an expert on profiling
04:53:40 <dafis> Peaker: Not figured it out, but some tracing output makes the overflow go away, however, bang patterns or seq'ing there don't
04:53:45 <jesse_> Has anyone an idea how to convert Ptr( Ptr() ) to [[a]]?
04:54:13 <jesse_> Ptr(Ptr()) == void**
04:54:43 <benmachine> :t peek
04:54:44 <lambdabot> Not in scope: `peek'
04:54:53 <benmachine> @hoogle peek
04:54:53 <lambdabot> Foreign.Storable peek :: Storable a => Ptr a -> IO a
04:54:53 <lambdabot> Foreign.Marshal.Array peekArray :: Storable a => Int -> Ptr a -> IO [a]
04:54:53 <lambdabot> Foreign.Marshal.Array peekArray0 :: (Storable a, Eq a) => a -> Ptr a -> IO [a]
04:55:07 <benmachine> jesse_: I imagine it would involve peekArray
04:55:33 <jesse_> Okay, thx. The other problem is: How can i pass an empty void** to the c-function.
04:56:40 <benmachine> an empty void**? what does that mean?
04:56:44 <benmachine> a nullPtr?
04:57:04 <benmachine> probably what the C function thinks of as empty depends on the C function
04:57:26 <benmachine> maybe that'll be a null, maybe it'll be a pointer to a null pointer, maybe it'll be a size parameter of 0
04:58:52 <jesse_> benmachine: Yes, void** should be null
05:00:19 <benmachine> @hoogle nullPtr
05:00:19 <lambdabot> Foreign.Ptr nullPtr :: Ptr a
05:02:05 <jesse_> benmachine: thx
05:06:46 <Cadynum> i just had a really annoying error with udp sockets on windows. my application worked fine in linux but failed on windows with "recvFrom: failed (Invalid argument WSAEINVAL)"
05:06:49 <Cadynum> it turns out udp sockets on windows needs to have something sent on them before you can recvFrom on them. perhaps this could be noted somewhere in the Network.Socket documentation
05:07:02 <Peaker> dafis: are you sure the banging patterns force the same things as the traces?
05:07:59 <dafis> Peaker: pretty much, tracing outputs two Integers, putting a bang on exactly these doesn't help
05:08:33 <benmachine> Cadynum: that sounds really odd
05:08:34 <dafis> Peaker: nor does checking them in a gurd
05:08:54 <dafis> *guard
05:09:03 <Peaker> dafis: the preprocessor stuff makes it hard to see what code is in use ...
05:09:14 <benmachine> Cadynum: how did you work that out?
05:09:22 <Peaker> dafis: maybe you can put it all in one module without preprocessor stuff -- it will help people help?
05:09:23 <benmachine> Cadynum: also, network issue tracker is here if you want it https://github.com/haskell/network
05:09:27 <Cadynum> benmachine, what made it really fun was that i forkIO'd a thread sending data, which means sometimes it worked and sometimes it failed.
05:09:47 <Cadynum> http://openvpn.net/archive/openvpn-users/2005-01/msg00560.html
05:10:03 <Cadynum> after i made sure of that something was sent all the time it has been working
05:10:21 <Cadynum> sent before recvd
05:10:32 <benmachine> Cadynum: it sounds like binding the socket would also work?
05:11:38 <dafis> Peaker: I'm far away from the preprocessor stuff, way down (line ~198) in 'munch', the tracing would output c and pr
05:12:19 <Peaker> dafis: so you had:  (!c, !pr, i) = ... ?
05:12:49 <dafis> Peaker: and sometimes also !i, and c `seq` pr `seq` ..
05:13:20 <Peaker> dafis: I think you want pseq for eagerness.. seq is for strictness (though maybe they are always the same?)
05:13:45 <sanjoyd> "Foundations of Object Oriented Programming" seems to have a decent description of System F.
05:13:52 <dafis> Peaker: now, if I have an (if c < 0 then trace ... else id) $ munch h' ds, no overflow
05:13:53 <Peaker> dafis: so, c `seq` pr `seq` findMulIx p      did not work, but    trace (show c ++ " " ++ show pr) $ findMulIx p    did work?
05:14:22 <dafis> Peaker: no, c `seq` pr `seq` much h' ds
05:14:28 <dafis> *munch
05:15:31 <Peaker> yeah, what I wrote makes little sense :)
05:15:53 <Peaker> dafis: what's in the trace string?
05:16:50 <Cadynum> benmachine, what would a bound socket imply that an unbound doesn't?
05:16:59 <dafis> Peaker: "Pushing " ++ show c ++ ", " ++ show pr
05:18:13 <Peaker> dafis: that's weird!  does pseq have the same behavior as seq?
05:18:34 <dafis> Peaker: not yet tried, wait a moment
05:19:06 * hackagebot eurofxref 0.1.0 - Free foreign exchange/currency feed from the European Central Bank  http://hackage.haskell.org/package/eurofxref-0.1.0 (StephenBlackheath)
05:19:08 <Peaker> not sure if there's a difference in practice, but pseq is supposed to be about eagerness/operational behavior (like you need here) and seq is supposed to be about denotational semantics
05:19:24 <Peaker> (whether things are bottom or not)
05:20:33 <dafis> Peaker: pseq works
05:21:25 <Peaker> dafis: not sure what bang patterns on the c and pr cause -- I mean, when do they cause the evaluation to be forced?
05:21:36 <benmachine> Cadynum: I'm not sure, I think it means outgoing packets all come from a port you choose
05:21:45 <Peaker> when you have something like: f = .... where (!a, !b) = ...           <-- when are a and b forced?
05:21:53 <benmachine> they might do that anyway, it's possible that the first packet you send binds you to a random port
05:21:57 <benmachine> I don't really remember
05:22:07 <benmachine> (address and port)
05:22:44 <Cadynum> benmachine, okey
05:22:44 <lysgaard> I've made an overlay network that works over lan. I've been using the IP of each node on the LAN as an identifier. Now i want to do it over the internet and i see two problems. How do i get past routers etc. Multiple nodes can have the same IP, and how can i uniquely identify each node on the network when I no longer can use just the IP?
05:22:49 <Peaker> dafis: my experiences with bang patterns have not been good either...
05:22:54 <dafis> Peaker: used to be evaluated when f was entered
05:22:59 <Peaker> at least with mindlessly throwing them around :)
05:23:05 <Peaker> dafis: you sure?
05:23:13 <dafis> Peaker: my experiences have been very good up to now
05:23:43 <dafis> Peaker: not 100% sure
05:25:22 <Peaker> dafis: aha, if you use:  ... where !a = ...   it causes that. If you use:  ... where (!a, !b) = .. it doesn't.  But.. if you use:   where !(!a, !b) = ... it does cause it to be evaluated
05:25:43 <Peaker> dafis: try that?
05:26:35 <dafis> Peaker: d'oh
05:27:08 <Botje> lysgaard: mac address.
05:27:23 <Botje> lysgaard: or you fast-forward to 2015, where everyone has a globally reachable ipv6 address
05:27:45 <dafis> Peaker: works
05:30:43 <ion> lysgaard: Can you get every user to deploy IPv6? In a lot of setups it’s rather trivial, just a matter of enabling Teredo. Windows does it natively and on Unix-ish systems Miredo just works™.
05:31:28 <dankna> well, sure, it's trivial on the client nodes
05:31:31 <dankna> it's hard on the routing :(
05:31:42 <lysgaard> How does IPv6 make every node behind a router accessible?
05:31:53 <dankna> by having a larger address space such that NAT is not needed
05:32:05 <arw__> ISPs will supposedly hand out IPv6 subnets real to dialup customers "real soon now"
05:32:31 <arw__> lysgaard: every node behind a router will have a routable address
05:32:59 <arw__> lysgaard: beware that "router" does not mean the same thing as "NAT" or "NAPT"
05:33:11 <lysgaard> arw__: Ah, so that when i buy a connection from an ISP I no longer get 1 IP, but one for each device connected to my router.
05:33:37 <ion> You get a routable subnet.
05:33:40 <lysgaard> arw__: Does a router perform NAT then?
05:33:43 <Jafet> Yes, then ISPs can track all the devices you use!
05:33:45 <arw__> lysgaard: you will continue to get 1 IPv4 address, but in addition you will get an ipv6 subnet (usually /64).
05:34:01 <Jafet> And we'll have hardware firewalls again.
05:34:10 <ion> NAT is evil – a necessary evil with IPv4, but never again with IPv6.
05:34:13 <arw__> lysgaard: and the router will continue to perform ipv4 NAT i guess, but ipv6 NAT will be useless.
05:34:42 <lysgaard> arw__: Ah, I see
05:34:45 <arw__> Jafet: there is such a thing as IPv6 privacy extensions
05:36:04 <arw__> Jafet: the more worrying possibility is the assignment of static subnets instead of the current "whatever the dhcp gives you"
05:36:31 <arw__> Jafet: so you won't be able to track devices, but you can track customers.
05:36:32 <lysgaard> Ok, so when IPv6 arrives we're golden, but before. How does one connect to a computer behind NAT?
05:36:42 <arw__> lysgaard: you don't.
05:36:57 <ion> With NAT hole punching, which is a nasty kluge to work around the nasty kluge that is NAT.
05:37:05 <lysgaard> arw__: Then how does programs like Bittorrent work?
05:37:09 <arw__> lysgaard: there are some very weird nat traversal techniques, but none of them work reliably.
05:37:22 <arw__> lysgaard: the device inside the NAT connects to the outside.
05:37:32 <arw__> lysgaard: because the other direction is not possible
05:37:44 <ion> lysgaard: Very poorly unless they get to tell the router to forward some ports inside the NAT using NAT-PMP or UPnP.
05:38:10 <ion> BitTorrent doesn’t work very well with NAT hole punching because it uses TCP extensively.
05:38:35 <lysgaard> ion: So one has to do port forwarding on the "router"/NAT ?
05:38:43 <arw__> bittorrent is also one of the first protocols to use ipv6 extensively for that very reason
05:39:10 <ion> Many consumer routers that do NAT also do NAT-PMP/UPnP.
05:39:11 <arw__> lysgaard: yes, but in some cases that port-forwarding can be automatically initiated via e.g. UPnP.
05:39:38 <lysgaard> Is there any way to do this via Haskell, UPnP or NAT-PMP?
05:39:49 <arw__> lysgaard: but it can't be initiated from the outside of course, the device on the inside has to order the forwarding on the router.
05:40:34 <lysgaard> I understand, wow you guys know a lot =)
05:42:35 <ion> NAT hole punching allows two peers behind separate NATs (without such port forwarding) to take advantage of a third, connectable party to open a direct connection between each other, but that’s somewhat flaky and only works on certain types of NAT. But it’s a good fallback to try when there’s no publicly routable address and forwarding can’t be set up with NAT-PMP/UPnP.
05:43:10 <ion> Sorry, :%s/NAT hole punching/UDP hole punching/g
05:43:57 <arw__> yes, if your protocol works with udp and the NAT device in question cooperates.
05:45:17 <arw__> you can search for some descriptions of what 'skype' does in that regard. its rather nasty and complicated
05:46:22 <arw__> in a nutshell, it scans the NAT for udp ports where the state detection of the NAT can be fooled into assuming an open 'connection' (which UDP doesn't really have)
05:47:29 <ion> I’m under the impression this product, which was bought and opensourced by Google, has a working implementation of the nasty stuff you need to do for the whole port mapping with UDP hole punching fallback thing. http://en.wikipedia.org/wiki/WebRTC
05:47:33 <saml> hey, how would you generate a sitemap were each resource (/foo/bar)  could have unbound number of direct children... and resource depth can be unbound?
05:48:09 <saml> write a lazy sitemap generator.. that outputs list of resources given /  to stream.
05:48:25 <saml> you cannot blow up memory please
05:49:00 <arw__> saml: sort by priority/alphabet/usage and only output the top100?
05:49:08 <JuanDaugherty>  UDP hole punching fallback thing
05:49:30 <saml> arw__, how would you sort? you need to walk entire resource tree at root
05:49:53 <saml> do it for me. i'm out of ideas. my stuff blows memory (theoretically)
05:50:29 <arw__> saml: possibly, but e.g. if you have usage data, there will always be stuff below some cutoff which you can ignore. so you exclude it at the stage when you collect the usage data.
05:50:37 <arw__> saml: or when you generate the resources
05:50:55 <saml> requirement is to walk entire resource tree.
05:51:15 <saml> let's say you are implementing  find  or grep.
05:51:34 <ion> https://sites.google.com/site/webrtc/faq#TOC-Why-should-I-use-WebRTC- “Includes and abstracts key NAT and firewall traversal technology using STUN, ICE, TURN, RTP-over-TCP and support for proxies.”
05:51:36 <saml> how would you implement it lazily so that memory usage is constant.
05:51:49 <saml> would you serialize to disk?
05:53:16 <saml> JuanDaugherty, NAT usually have limits of number of clients
05:53:20 <ion> That’s what i’d look at initially if i needed to get through NATs. Implementing all that by my own would be a huge project.
05:53:59 <JuanDaugherty> saml, acknowledged.
05:54:11 <saml> sorry i thought you responded to my question.
05:59:16 <emacstheviking> Are there any good haskell socket tutorials out there?
06:04:40 <gienah> emacstheviking: chap 27 of real world haskell is on network programming
06:05:22 <TRYGVIS> emacstheviking: http://book.realworldhaskell.org/read/sockets-and-syslog.html
06:07:20 <emacstheviking> I have the book, all six pages are packer with networking!! LOL I was looking for something a little easier like a simple echo server... I guess I should read it again and have a go... sometimes I just like reading tutes instead of doing it! Like watching TV chefs!
06:07:45 <ion> http://hpaste.org/48307
06:08:31 <emacstheviking> sweeeeeet! Thanks for that. I am going to read that now! :)
06:09:26 <gienah> emacstheviking: this blog post mentions that attoparsec is really useful for the protcol stuff: http://jlouisramblings.blogspot.com/2010/04/haskell-vs-erlang-for-bittorent-clients.html
06:09:53 <benmachine> with the relevant extensions turned on, is this supposed to work? comment env{..} = return Response{..}
06:10:03 <benmachine> I'm getting src/Main.hs:13:12: Empty record update of: env
06:10:29 <benmachine> it's not even in a context where you could possibly update it, it's a pattern
06:10:38 <ion> (Peaker pasted that a couple of days ago.)
06:11:28 <edwardw> please, can somebody copy that blog to gist or something? I can't access blogpost now
06:11:40 <edwardw> ...blogspot
06:14:17 <benmachine> ok I am an idiot
06:14:22 <benmachine> and forgot how record patterns work
06:16:13 <erus`> data blah = blah { something :: Int }
06:16:51 <ski> edwardw : ask jlouis ?
06:17:05 <erus`> > let data blah = blah { something :: Int } in something (blah 1337)
06:17:05 <lambdabot>   <no location info>: parse error on input `data'
06:17:19 <edwardw> ski: seems he's not around
06:17:32 <benmachine> erus`: you can't do data declarations except at the top level, and constructors need to be uppercase
06:17:54 <erus`> not in my world
06:18:09 <gienah> edwardw: set to expires in 1 hour the blogspot text of the url I posted above: http://pastebin.com/WhimEtVJ
06:18:11 <mauke> The paste WhimEtVJ has been copied to http://hpaste.org/48467
06:18:31 <gienah> so much for the expire in one hour :-/
06:18:53 <edwardw> gienah: got it. thank you so much, man
06:21:18 <ski> edwardw : <http://github.com/jlouis/combinatorrent> and <http://github.com/jlouis/etorrent> are mentioned in the comments
06:21:54 <edwardw> ski: heh, I'm one contributor to the later
06:22:17 <edwardw> ski: just need to re-read jlouis's blog since I'm learning some haskell now
06:23:11 <edwardw> ski: trying to get my head around iteratee i/o now. it is like magic, i'd say
06:24:27 <emacstheviking> I was reading the yesod site again (started doing a site with it for practice) and he has some very good articles on iteratees on the wiki. Very enlightening, allbeit way over my head at times!
06:24:51 * ski notes edwardw /= edwardk
06:25:09 <edwardw> :D
06:25:50 <Jafet> Edward “We met?”
06:26:07 <edwardw> I don't think so
06:26:33 <ion> /nick edwardi
06:26:55 <edwardw> emacstheviking: blogspot again.  :\  I can't access that right now
06:37:19 * hackagebot comonad-transformers 1.8.0 - Comonad transformers  http://hackage.haskell.org/package/comonad-transformers-1.8.0 (EdwardKmett)
06:37:21 * hackagebot data-lens 1.8.0 - Haskell 98 Lenses  http://hackage.haskell.org/package/data-lens-1.8.0 (EdwardKmett)
06:37:50 <emacstheviking> Another question: DSL-s! I mailed to the beginners list the other day about wanting to do Android development using Haskell *somehow*. It could be writing a simple parsec driven thing that code-generates Java to avoid bolier plater or it could be clever than that... the trouble is, being a haskell newbie I am not sure where to start. I *can* do android!
06:37:55 <matthiasgorgens> Does anyone have a nice, idiomatic topological sort (in Haskell) lying around?  I'm preparing a talk about how to read Haskell, and the code I came up with for that example isn't as nice as I had hoped for.
06:38:19 * hackagebot data-lens-template 1.8.0 - Utilities for Data.Lens  http://hackage.haskell.org/package/data-lens-template-1.8.0 (EdwardKmett)
06:38:21 <edwardk> matthiasgorgens: it is lying around in Data.Graph in containers but it is hardly idiomatic
06:38:52 <matthiasgorgens> edwardk, ok.  coming up with any old implementation is quite simple.
06:39:00 <matthiasgorgens> edwardk, even a linear one.
06:39:27 <matthiasgorgens> edwardk, I guess I will have to think harder and then just publish it myself. ;o)
06:39:33 <edwardk> =)
06:39:42 <edwardk> i have some code for it, but its over in scala i'd have to port it back
06:40:03 <edwardk> in haskell i just use the data.graph one usually. i don't think i ever added topsort to my graphs package
06:40:19 <matthiasgorgens> edwardk, perhaps generating _all_ topological sorts would lead to cleaner code?
06:40:48 <edwardk> i only tend to use the one from a given vertex
06:40:54 <matthiasgorgens> edwardk, that would be a bit like producing all permutations, but with some of them filtered out.
06:40:59 <edwardk> that is what i use to do reverse mode AD in my automatic differentiation library
06:41:12 <edwardk> and since it is implemented in ST, it'd be hard to prune
06:41:18 <matthiasgorgens> AD = automitac differentation?
06:41:24 <edwardk> yeah
06:41:33 <edwardk> see package 'ad' =)
06:41:35 <wli> edwardk: Were you saying yesterday that you've got Gröbner code floating around?
06:41:49 <edwardk> wli: some. i keep meaning to package it
06:41:56 <zygoloid> Größner?
06:42:26 <edwardk> whenever i figure out how i'm going to take over the world with free modules and vector spaces, it'll go in that ;)
06:42:59 <wli> edwardk: Bear with me a moment.
06:44:49 <edwardk> brb, trying to get finished updating some packages before being inundated with links ;)
06:46:00 <wli> There are only 2 links.
06:47:56 <benmachine> what do people have good experiences with when it comes to writing CGI?
06:48:20 <Clint> Network.CGI
06:48:23 <edwardk> =)
06:48:50 <dankna> direct-fastcgi, but I'm the author
06:49:25 <benmachine> dankna: ah I saw that, it looked nice
06:49:30 <dankna> oh thanks! :D
06:49:38 <benmachine> but if fastcgi is not available on my server, will it do slowcgi? :P
06:49:42 <osfameron> is there an equivalenet of the new CGI-like APIs for Py/Ruby/Perl?
06:49:44 <dankna> no, unfortunately not
06:49:54 <benmachine> ho hum
06:49:55 <emacstheviking> Would there be a good case for using fast-cgi as opposed to say yesod or one of the other frameworks?
06:49:55 <osfameron> er, Rack for Ruby, Plack for Perl, I forget what the Python one is called... PSGI?
06:50:09 <dankna> but you should really be using fastcgi.  there are minor speedups that it causes for a number of reasons, but the big reason is that you can cache database connections and other resources across invocations.
06:50:25 <benmachine> yeah I'm not planning on using databases
06:50:29 <benmachine> this is a very simple application
06:50:34 <osfameron> WSGI was the Python one
06:50:34 <dankna> yesod and the other frameworks, as I understand it, can use either cgi or fastcgi internally
06:50:41 <emacstheviking> aha!
06:51:03 <dankna> benmachine: okay, then CGI may be adequate to your needs.  it would be an interesting project to clone the direct-fastcgi interface for cgi, but not one I'm interested in doing :)
06:51:06 <benmachine> osfameron: there's hack, which is apparently a port of rack, but I'm not sure how good it is
06:51:07 <emacstheviking> I am still learning yesod, it was the only one that cabal deemed good enough to build without "issues"
06:51:14 <benmachine> dankna: noted
06:51:33 <matthiasgorgens> edwardk, thanks for the short overview of graph packages.
06:51:38 <osfameron> benmachine: heh, shoulda guessed what the name would be ;-)
06:51:43 <benmachine> :)
06:51:54 * benmachine has a look at yesod
06:52:06 <benmachine> woo for giant dependency lists :P
06:52:34 <dankna> indeed :/
06:52:42 <edwardk> matthiasgorgens: mine is mostly for implementing large imperative algorithms over potentially huge graphs stored out of main memory
06:56:01 <nus> wli, how is the rewrite going?
06:56:36 <wli> nus: Not really going anywhere, but the rational regression by-product is mostly trivial as far as I can tell.
06:57:42 <nus> wli, have you seen AERN-RnToRm package?
06:58:16 <wli> nus: Checking it out.
07:02:10 <wli> nus: Looks pretty cool. I'm more interested/obsessed with rational functions (esp. of the "non-homogeneous" kind; i.e. when you have f : R^n -> R^m as rational functions, you don't get it by back-mapping from a projective plane of polynomial-component functions over R^(m+1), or otherwise, that the components aren't required to share common denominators).
07:03:02 <edwardk> rational functions via hermite-pade approximants are a large part of my current obsession as well
07:03:35 <wli> Clarify Hermite-Padé?
07:04:03 <edwardk> http://www.cs.uwaterloo.ca/~glabahn/Papers/tenerife.pdf
07:04:18 <edwardk> they do so more succinctly than i can over irc
07:04:45 <edwardk> my major application so far is sequence guessing: http://mathinfo06.iecn.u-nancy.fr/papers/dmAG431-434.pdf
07:06:10 <edwardk> the main tool i've been playing with is http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.1668
07:06:59 <edwardk> but basically there are several generalizations of pade approximants to multiple variables, and that one works pretty well
07:07:35 <edwardk> and there are some general techniques that span over that one and others
07:07:40 <enolan> I can't get the curl binding to work with HTTPS. It returns (CurlHttpReturnedError,"") every time, while cli curl works fine.
07:07:52 <enolan> anyone encountered this?
07:09:16 <wli> edwardk: Going over it.
07:09:22 * hackagebot data-lens-fd 1.8.0 - Lenses  http://hackage.haskell.org/package/data-lens-fd-1.8.0 (EdwardKmett)
07:12:01 <wli> edwardk: I'm largely biting on granite wrt. ensuring nonsingular denominators of approximants to real functions, specified as (potentially Hermite) interpolants over some knots (but specifiable in other ways, too).
07:13:46 <edwardk> well, the poles are the price you pay for rational approximation
07:14:26 * hackagebot hascat-setup 0.2 - Hascat Installation helper  http://hackage.haskell.org/package/hascat-setup-0.2 (FlorianMicheler)
07:14:30 <wli> e.g. ODE solver spits out t_k, y_k, y_k', y_k'', line up rational functions with some level of continuity interpolating all this, and watch the denominators have roots in the sub-intervals they're interpolants for.
07:15:47 <edwardk> have you tried playing with the degree of your numerator and denominator to see if you can get the poles out of the way?
07:15:57 <wli> edwardk: I'm seeing semi-algebraic systems in Stetter's "Numerical Polynomial Algebra" as ways of coping with this somewhat, provided that I can come up with representations where the inequalities prevent poles while maintaining sufficient generality.
07:16:17 <edwardk> that is a bit outside my ken at this point
07:16:27 * hackagebot hascat-lib 0.2 - Hascat Package  http://hackage.haskell.org/package/hascat-lib-0.2 (FlorianMicheler)
07:16:29 * hackagebot hascat-system 0.2 - Hascat System Package  http://hackage.haskell.org/package/hascat-system-0.2 (FlorianMicheler)
07:16:31 * hackagebot hascat 0.2 - Hascat Web Server  http://hackage.haskell.org/package/hascat-0.2 (FlorianMicheler)
07:16:35 <aleator> Stupid question. If I fork someones bsd-licenced hackage-package, what should the LICENSE file say?
07:16:54 <edwardk> aleator: it should include the bsd license somewhere ;)
07:17:09 <wli> edwardk: I can generally get rid of the poles doing that by hand, but don't have an algorithmic way of doing this.
07:18:09 <edwardk> pick a maximum degree for the pade approximant, [n,m], then iterate over all combinations starting at [m,n] down diagonals to [1,1] checking for 0s in the target interval
07:18:27 <edwardk> er 0s in the denominator that is
07:19:08 <edwardk> this 'try all the things approach' seems to be what a lot of folks do, gfun uses it for instance, though they are trying to find nicer forms for recurrences, etc.
07:19:48 <wli> edwardk: Hmm. Things come out in different ways. I usually have n sub-intervals, each with a particular rational function, perturbing the degree type of one sub-interval may not interact well with the others.
07:20:26 <edwardk> i'm just getting up to speed on piecewise rational function approximations, so i may not be much help
07:20:37 <wuxingbo> howto load 2 none-dependent .hs files into ghci? I'd like it to be like ':m +'.
07:20:58 <edwardk> i started with piecewise chebyshev, then started to slide in the pade machinery at the suggestion of jacques carette.
07:21:45 <Phyx-> wuxingbo: pass them both as arguments to ghci or :l ?
07:21:53 <edwardk> i wish i could find more information on the relaxed chebyshev pade approximants that are used in mathematica to get better approximations over an interval
07:22:01 <edwardk> but its mathematica so its a black box
07:22:20 <wli> edwardk: There's a trick that reduces the degrees of the individual constraints for 1D affairs, I did something of a writeup http://proxima.lp0.eu/~wli/decay.pdf
07:23:10 <edwardk> neat. added to the pile (near the top) =)
07:23:30 <wuxingbo> Phyx-: it doesn't work, only the first file is loaded. (though it say all loaded).
07:23:34 <wli> edwardk: It doesn't generalize to curves in R^n or m-dimensional surfaces in R^n, though.
07:23:48 <edwardk> ah well
07:23:57 <edwardk> i'm playing almost entirely over R these days
07:24:25 <ezyang> edwardk: Random question: do you know what the free monad for (a -> r) -> r corresponds to (the same way the free monad for Id is Peano Nats, etc.)
07:24:38 <wli> edwardk: Well, bear with me, geometric continuity for space curves in R^n. Parametric continuity clearly just does the 1D case n-fold.
07:24:42 <edwardk> Free (Cont r) ?
07:25:12 <ezyang> Yeah, I'm just wondering if that's isomorphic to something we know about.
07:25:27 * hackagebot comonads-fd 1.8.0 - Comonad transformers using functional dependencies  http://hackage.haskell.org/package/comonads-fd-1.8.0 (EdwardKmett)
07:26:12 <ski> @unmtl Free (Cont r)
07:26:13 <lambdabot> Free (Cont r)
07:27:06 <Phyx-> wuxingbo: after that you can bring it into scope with :m +
07:27:18 <edwardk> ezyang: playing with it now
07:27:31 <ezyang> Oops :-)
07:28:15 <emacstheviking> enolan: care to expand... I just tried a simple get and it worked, what library versions etc do you have ?
07:28:17 <edwardk> ezyang: it appears to just be Cont giving you access to some of your >>='s
07:28:23 <edwardk> ezyang: looks expensive
07:29:06 <ezyang> Yes. My real reason for wondering about this is because I have a monad implementation that I suspect is Free Cont, not Cont.
07:30:31 <edwardk> ezyang: ok. lets take it apart. first Free (Cont r) is pretty slow. so lets speed it up and get an insight
07:30:39 <edwardk> using the Yoneda Rec stuff from my blog you get
07:30:56 <edwardk> forall s. (a -> s) -> (((s -> r) -> r) -> s) -> s
07:31:22 <edwardk> where the latter looks kind of like one of the usual continuation passing style combinators, control.
07:31:57 <edwardk> 'given an a -> s, and a function from ~~s -> s, i'll give you an s.
07:32:15 <enolan> emacstheviking, haskell binding is 1.3.7
07:32:32 <edwardk> i picked dolio's brain for some of that
07:32:43 <ezyang> It's a kind of odd control structure, some sort of shortcut/double-negation elimination?
07:33:32 <ski> ezyang : where did `Free (Cont r)' come from ?
07:33:53 <ezyang> ski: Unsure. I just thought it might be kind of interesting.
07:33:55 <edwardk> ezyang: you need to supply it your double negation eliminator
07:34:30 <edwardk> to use it you pass it a function from a -> s, and a function from ~~s -> s.
07:34:47 <cheater__> hi
07:35:03 <ski>   data Free (Cont r) a = Return a | JoinLift (Cont r (Free (Cont r) a))  -- hm
07:35:08 <edwardk> at least for the Yoneda (Rec (Cont r)) version
07:35:22 <edwardk> the Free version is a lot harder to see through
07:35:28 <enolan> emacstheviking: hmm, I have libcurl3-gnutls-7.21.3-1ubuntu1.2 and libcurl4-openssl-dev-7.21.3-1ubuntu1.2 and libcurl3-7.21.3-1ubuntu1.2
07:35:38 <enolan> There's no libcurl3-dev package
07:36:19 <ski> edwardk : so the `a' type doesn't need to admit a double-negation-eliminator, it only needs to be able to be converted into a type which does .. hm
07:36:30 <edwardk> yeah
07:36:31 <wli> edwardk: http://proxima.lp0.eu/~wli/spline.pdf describes G^2 geometric continuity for n-dimensional rational space curves, which is nightmarish. C^2/parametric continuity is trivial and is just the decay.pdf -described quadratic constraints vs. the dimensionality-dependent nightmares in spline.pdf
07:36:54 * ski wonders which types admit such eliminators
07:36:57 <emacstheviking> enolan: lets go private
07:37:37 <ezyang> If I use a monad with right-associative binds to build up something, and bad things (space-wise) happen, this doesn't have anything to do with free monads, right?
07:38:18 <edwardk> correct. free monads always explode space wise, there is no renormalization step!
07:39:07 <ski> using the CPS tricks, things will get recomputed, if you reuse them, iirc
07:39:16 * benmachine somewhat annoyed to find the cgi package doesn't really export the stuff he needs for parsing CGI multipart input
07:39:23 <edwardk> wli: if i don't respond its not because i'm not interested. mostly coz i'm hacking on a package atm
07:39:24 <ezyang> Blegh. I'm not at the stage of understanding where I can properly phrase these questions.
07:39:37 <wli> edwardk: No sweat.
07:39:45 <benmachine> or wait, does it
07:39:53 <edwardk> benmachine: fork! fork! fork! fork! its not like we have too many web frameworks or anything ;)
07:40:34 <benmachine> edwardk: :P it is a bit of a minefield
07:40:39 <geheimdienst> edwardk: we don't have enough web frameworks written by myself. ergo, fork.
07:40:40 <geheimdienst> ;)
07:41:11 <ezyang> ...this is really weird. This monad is efficient if you left-associate, but not if you right-associate.
07:42:29 <geheimdienst> following the tried and trusted approach of "this code totally wasn't written by me, i absolutely should rewrite it"
07:42:32 <ezyang> I've never seen this before.
07:43:41 <ski> @type mfix . (Control.Concurrent.forkIO .)
07:43:42 <edwardk> ezyang: write it up ;)
07:43:42 <lambdabot> (GHC.Conc.ThreadId -> IO ()) -> IO GHC.Conc.ThreadId
07:43:55 <ezyang> Working on it :-)
07:45:41 <benmachine> @type mfix (Control.Concurrent.forkIO . Control.Concurrent.killThread)
07:45:42 <lambdabot> IO GHC.Conc.ThreadId
07:45:47 * benmachine wonders what that does
07:45:56 <benmachine> probably nothing actually :(
07:48:20 <edwardk> @type let bomb = Control.Concurrent.forkIO bomb >> bomb in bomb
07:48:21 <lambdabot> IO ()
07:48:27 <wli> edwardk: The numerical methods for solving systems of multivariate polynomial equations and semi-algebraic systems (such systems in conjunction with systems of multivariate polynomial inequalities, potentially with solution sets of higher dimensions than zero) are not anywhere near as standard as the bonehead linear algebra which is all that piecewise polynomials require.
07:48:57 <edwardk> true enough
07:50:17 <benmachine> fix $ forever . forkProcess
07:50:20 <benmachine> or something
07:50:37 <edwardk> well, you want the bomb to be used twice
07:50:59 <benmachine> hm?
07:51:16 <edwardk> in what i'm forking and in the current thread
07:51:23 <benmachine> yes
07:51:31 <benmachine> the forever takes care of that, no?
07:51:43 <edwardk> hrmm
07:51:46 <edwardk> seems so
07:52:41 <wli> edwardk: This may present a problem of getting libraries for solutions of systems of multivariate polynomial equations and semi-algebraic systems. There are other numerical analysis issues like constrained optimization via sequential quadratic programming that don't have adequate libraries, probably some others lacking any libraries whatsoever.
07:53:42 <wli> (Note that available constrained optimization library code is severely restricted in the forms of the constraints supported.)
07:53:58 <edwardk> yeah my main problem is that i've been trying to build simple stuff that is obviously correct and highly polymorphic
07:54:30 * hackagebot free 1.8.0 - Monads for free  http://hackage.haskell.org/package/free-1.8.0 (EdwardKmett)
07:55:18 <wli> SQP constrained optimization code (nonlinear programming) exists only in Fortran that I can tell.
07:55:48 <edwardk> that is because all the numeric analysts went to fortran to die
07:57:31 * hackagebot recursion-schemes 1.8.0 - Generalized bananas, lenses and barbed wire  http://hackage.haskell.org/package/recursion-schemes-1.8.0 (EdwardKmett)
07:59:17 <benmachine> edwardk: you just skipped like twelve major versions? :P
07:59:27 <edwardk> yeah. been busy. ;)
07:59:39 <edwardk> actually was synchronizing version numbers across some packages to make it clearer what version things are
07:59:50 <benmachine> mm, makes sense
08:00:03 <edwardk> this way my 1.8 stuff works with my 1.8 stuff across the board
08:00:14 <wli> edwardk: Well, basically, no one expert enough in numerical analysis has gone about porting it to any sort of C-callable library form or any advanced programming language library, either.
08:00:22 <edwardk> otherwise while upgrading i need to keep a sheet of paper with 20 version #'s on it
08:00:31 <benmachine> heh
08:00:39 <edwardk> wli: well, this sort of thing is why octave will forever carry around libcruft
08:00:46 <k0ral> hi, is there a way to combine the dynamic recompiling provided with Dyre's library and the Paths_<project> module ?
08:01:05 <edwardk> k0ral: not that i know of. Dyre is pretty limited
08:01:35 <wli> edwardk: R and octave clearly want it, but no one's gone about doing it.
08:02:36 <wli> (Actually it's been several years since I've checked in on this, but generally things don't move very fast for all this.)
08:02:43 * Athas thinks hlint is becoming way too pedantic. :-(
08:02:56 <edwardk> athas?
08:03:28 <Athas> It's just harder to quiet those 'reduce duplication' warnings!
08:03:32 * hackagebot keys 1.8.0 - Keyed functors and containers  http://hackage.haskell.org/package/keys-1.8.0 (EdwardKmett)
08:03:45 <edwardk> ah
08:04:21 <Athas> And its warnings about module exports are weird.
08:12:23 <wli> Conceptually the zero-dimensional multivariate polynomial system solution case is actually pretty stupid.
08:16:03 <wli> Multiplication by some (properly chosen, with some subtleties, but mostly just retrying because it works for almost every combination, typically chosen as an integer linear combination of single-variable monomials of the first degree) polynomial modulo the Gröbner basis acts as a linear operator whose eigenvalues one finds. The eigenvalues are mostly ignored; the eigenvectors are then the values of the monomials on the zeros corresponding to them, and 
08:16:59 <erus`> is that even english?
08:18:06 <wli> Well, determined from components of the eigenvectors, as there are ratios floating around.
08:18:13 <wli> erus`: Yes.
08:18:23 <littlebobby> jesus, I've spend maybe 8 hours reading about lisp vs. haskell (I intend to learn both in the long run). talk about being productive :-)
08:18:45 <sanjoyd> littlebobby: just start with one?
08:18:50 <littlebobby> well, I've also watched a tech talk by peter seibel
08:18:55 <erus`> start with scheme
08:19:08 <rostayob> erus`: why?
08:19:11 <erus`> littlebobby: watch simon peyton jones talks an haskell too
08:19:13 <littlebobby> sanjoyd, sure, that wasn't the point. It has just been an interesting read
08:19:19 <littlebobby> erus`, thanks
08:19:27 <Athas> I need a data structure that is much like the normal list zipper with a hole (the "current" element), but also able to quickly move the hole to the beginning or end of the sequence.
08:19:28 <rostayob> littlebobby: I'd start with haskell :P
08:19:35 <mrcarrot> :)
08:19:37 <mrcarrot> me too
08:19:41 <Athas> I have considered simply using a deque for the before/after lists.  Do you have a bette rsuggestion?
08:20:11 <develhevel> test
08:20:17 <littlebobby> erus`, I started reading little schemer (and will continue at some point) but recently discovered "the haskell road to logic, math and programming" and that just seems too interesting to read any other book before it
08:20:49 <littlebobby> my lacking math background concerned me for too long now
08:20:57 <rostayob> littlebobby: I'd suggest SICP for scheme and LYAH/Programming in haskell for haskell
08:21:08 <wli> edwardk: The hard parts come in where solution sets of dimension higher than zero and semi-algebraic systems (i.e. combinations of equality and inequality constraints on multivariate polynomials) come in.
08:21:08 <rostayob> LYAH is really nice
08:21:29 <erus`> lyah is ok but it didnt teach me how to structure a real program
08:21:46 <erus`> when i say real program i mean any old simple text IO program
08:21:54 <hpaste> Clint pasted “lb” at http://hpaste.org/48471
08:22:00 <sanjoyd> I liked LYAH because of the emphasis on getting the basics right.
08:22:06 <Clint> which extension is that asking for ^?
08:22:17 <rostayob> erus`: well lyah teaches you haskell... I think you can stand on your feet after that and look for the stuff you need
08:22:17 <mrcarrot> what is lyah?
08:22:23 <rostayob> mrcarrot: learn you a haskell
08:22:39 <mrcarrot> ah, learn you a haskell for great good :)
08:22:39 <wli> Learn You A Haskell, a long Haskell tutorial.
08:23:29 <matthiasgorgens> athas, how about two deques?
08:23:47 <littlebobby> what I intended to say initially is that I find it refreshing to read about lisp & haskell. the signal to noise ratio seems to be a lot higher than when reading about other languages
08:23:49 <erus`> rostayob: After coming from a C++ background it took a while for it to click that a 'main loop'  was just a recursive function
08:23:53 <erus`> then i was away :)
08:24:23 <rostayob> erus`: I don't think that something that teaches you haskell should start off teaching you how to do IO
08:24:39 <ski> @where LYAH
08:24:39 <lambdabot> http://www.learnyouahaskell.com/
08:24:43 <Athas> matthiasgorgens: two for each side?
08:24:47 <mrcarrot> littlebobby: the interesting thing is that you can basically write haskell with lisp syntax
08:24:53 <erus`> im still a noob so i'll take your word for it
08:24:56 <matthiasgorgens> athas, one for each side of the hole, I'd suppose.
08:24:57 <monochrom> eh? IO is fine
08:25:10 <Athas> matthiasgorgens: right, that's my idea so far as well.
08:25:37 <wli> Is there a way to silence glpk's messages from its solver?
08:25:44 <Clint> the answer was -XScopedTypeVariables
08:25:44 <matthiasgorgens> athas, I guess you need a deque that's also concatenable.
08:25:54 <mrcarrot> littlebobby: http://newartisans.com/2009/03/hello-haskell-goodbye-lisp
08:26:01 <rostayob> monochrom: IO is fine, but you're still using a monad. I like the order in programming in haskell
08:26:04 <littlebobby> mrcarrot, I've just read that :-)
08:26:08 <matthiasgorgens> rostayob, for- and while- loops are just recursive, too.
08:26:31 <matthiasgorgens> it's just that most languages don't cope very well with general tail-recursion, so they introduce weird special cases with special syntax.
08:26:37 <matthiasgorgens> like those loops.
08:27:16 <rostayob> matthiasgorgens: usually with recursive you mean recursive in terms of function calls
08:27:51 <matthiasgorgens> rostayob, really? I use recursive for anything whose definition includes itself.
08:27:58 <matthiasgorgens> like loops or linked lists.
08:28:03 <matthiasgorgens> or trees.
08:28:15 <matthiasgorgens> or induction.
08:28:29 <rostayob> matthiasgorgens: yeah ok, but when talking of programming languages
08:28:34 <matthiasgorgens> rostayob, and even in C, you also have recursive data structures.
08:28:51 <matthiasgorgens> and not only recursive functions.
08:28:59 <rostayob> matthiasgorgens: sure
08:29:31 <quicksilver> normally when discussing programming languages we're talking about syntactic recursion.
08:29:42 <quicksilver> a C for(;;) loop is not syntactically recursive
08:29:42 <rostayob> but when you say "recursion" in the context of programming languages you *usually* mean recursion in functions
08:29:50 <ezyang> Claim: It is not in general possible to convert code that uses binds right-associatively into code that uses binds left-associatively. That is to say, restricting yourself to binds on the lhs reduces power.
08:29:54 <ezyang> Is this true?
08:30:21 <ezyang> It's clearly not true when the computation is fully known in advance, but what about when you do something conditional?
08:30:46 <matthiasgorgens> quicksilver, i can live with that implicit assumption.
08:32:00 <matthiasgorgens> quicksilver, by the way, would you call Forth's recurse keyword to be syntactic recursion?
08:32:29 <matthiasgorgens> See http://www.taygeta.com/forth_intro/colon2.htm#Return for an example.
08:33:19 <fxr> @whatis mixmap
08:33:19 <lambdabot> I know nothing about mixmap.
08:33:26 <quicksilver> matthiasgorgens: yes, I believe I would.
08:33:37 <quicksilver> matthiasgorgens: but I agree that it's rather different in feel.
08:34:35 <fxr> @whatis mixin
08:34:35 <lambdabot> I know nothing about mixin.
08:34:42 <fxr> @google mixin Cook
08:34:43 <lambdabot> http://us.randstad.com/content/findjobs/job-details/index.xml?id=81280&currentPage=1&WT.mc_id=jr&__version=1
08:34:43 <lambdabot> Title: Compound Mixing Cook in Carrollton, GA - Randstad
08:35:41 <matthiasgorgens> quicksilver, I guess in Forth the recurse keyword is closer to "continue" in Python loops.  But I guess it's just a matter of definition if you say Forth's recurse is syntactic recursion.
08:36:25 <quicksilver> matthiasgorgens: I think so, yes. Forth's execution model brings rather close to the surface the unification between recursion and iteration.
08:36:50 <quicksilver> matthiasgorgens: in haskell and C we have the notion that a *stupid* compiler would compile them quite differently so it feels like a real difference - although a smart compiler may not.
08:38:31 <JuanDaugherty> a c compiler doesn't need to be smart
08:38:40 <JuanDaugherty> it's practially an assembler
08:38:55 <JuanDaugherty> c++ is a little different
08:39:07 <JuanDaugherty> *practically
08:40:11 <wli> JuanDaugherty: If you've ever tried to do register allocation and stack space allocation and reuse on x86-32, you'd know better. Or, for that matter, floating point codegen for i387 FPU's.
08:40:16 <JuanDaugherty> only langs like Haskell that are trynna to fool Mother Nature need to be "smart"
08:41:12 <Tomsik> I don't think a C++ compiler needs to be smarter than a C compiler
08:41:25 <Eelis> JuanDaugherty: i think dozens of highly sophisticated optimization passes in Clang/GCC/etc beg to differ
08:41:30 <wli> It does in ways having to do with language features.
08:41:30 <matthiasgorgens> JuanDaugherty, mother nature?
08:41:36 <Tomsik> all the class can be easily translated I think
08:41:43 <Eelis> Tomsik: C++ is several orders of magnitude harder to compile than C.
08:41:45 <Tomsik> and templates are just substitution
08:42:00 <JuanDaugherty> matthiasgorgens, before your time or US-centric
08:42:09 <Eelis> Tomsik: writing a C compiler is a nice homework exercise. writing a C++ compiler is a horrendous undertaking
08:42:27 <quicksilver> good C compiler are pretty smart though.
08:42:33 <Tomsik> Eelis: What's more complicated besides syntax?
08:42:37 <matthiasgorgens> juanDaugherty, actually with all the crazy stuff that CPUs do nowadays, like branch prediction and speculative evaluation, you can argue that CPUs are trying to re-cover the fundamental functional program out of the assembly/machine language they are given.
08:42:47 <Phyx-> and writing a Haskell compiler is a fun hobby
08:42:50 <quicksilver> but a correct-but-not-particularly-clever C compiler is easy.
08:42:53 <JuanDaugherty> Alen Holub's "Compiler Design in C" has the best c compiler compiler I've ever seen. Unfortunately it's out of print.
08:42:56 <matthiasgorgens> juandaugherty, what do you mean with US-centric?
08:42:58 <Eelis> Tomsik: "besides syntax"? semantics, of course
08:43:03 <quicksilver> mind you  a correct-but-not-particularly-clever haskell compiler is also not that hard.
08:43:23 <azaq23> for starters, c++ templates are not "just substitution" but turing complete
08:43:36 <wli> Eelis: Depends on for what CPU architecture.
08:43:39 <matthiasgorgens> quicksilver, writing a lambda-calculus compiler (or even simpler an SKI calculus compiler) is relatively easy.
08:43:50 <JuanDaugherty> matthiasgorgens, I mean assuming a steeping in US Culture, the reference was to a well known commercial of more than 30 years ago about margarine
08:43:55 <matthiasgorgens> quicksilver, of course haskell adds syntax and lots of type trickery.
08:44:23 <matthiasgorgens> juandaugherty, oh, i'm neither that old nor steeped into US culture.
08:44:58 <HairyDude> How do I install profiling libraries on Fedora?
08:45:02 <Phyx-> matthiasgorgens: most of Haskell's syntax is syntactical sugar
08:45:19 <matthiasgorgens> phyxs-, yes, but you still have to write a parser for it.
08:45:49 <Phyx-> matthiasgorgens: true
08:46:08 <matthiasgorgens> if you just want to have some short fun, and don't want to bother with syntax, stick to SKI
08:46:13 <matthiasgorgens> and then perhaps lambda calculus.
08:46:17 <thoughtpolice> Tomsik: templates are a hell of a lot more complicated than 'substitution', and you pretty much can't do shit with C++ code unless you have full semantic analysis of the translation unit - parsing just doesn't cut it, because you can parse incorrectly unless you've also done such analysis
08:46:23 <matthiasgorgens> you'll still have to implement GC and friends.
08:47:06 <thoughtpolice> Tomsik: clang was a good C compiler for quite a while before they implemented C++ support. it wasn't trivial, it took a hell of a lot of work from several people over years (including people on the C++ committee.) can you tell me all the ridiculous name resolution/overloading rules for C++? that's pretty much insanity as well
08:47:14 <matthiasgorgens> thoughtpolice, yeah, C++ has just horrible syntax (from a parsing perspective).  somebody should do a S-Expression alternative instead.
08:48:07 <Tomsik> I guess you're right
08:48:16 <thoughtpolice> yeah, it's horrible because you have to tightly weave semantic analysis into the parser essentially. clang for example is structured like a library, and there is one part for semantic analysis called the 'Sema' library, and you pretty much have to be in that part of the compiler to do ANYTHING meaningful with C++
08:48:21 <edwardk> Tomsik: C++ is at least an order of magnitude messier to compile than C.
08:48:31 <quicksilver> C++ templates can embed arbitrary compilation at compile time
08:48:40 <quicksilver> that alone tells you something about the complexity of the compiler
08:48:53 <quicksilver> s/compilation/computation/
08:49:04 <edwardk> yeah. they were accidentally turing complete. (whoops!) ;)
08:49:28 <quicksilver> edwardk: OOPS I ACCIDENTALLY THE WHOLE TARPIT
08:49:47 <edwardk> matthiasgorgens: actually lots of scheme compilers have s-expression representations for c or c++ code emission
08:49:56 <thoughtpolice> quicksilver: did you have to accidentally it *with the most verbose syntax in the world*?
08:50:06 <edwardk> thoughtpolice: hahahaha
08:50:31 <edwardk> that is what they get for trying to sneak it into the cracks of existing c syntax for the most part ;)
08:50:48 <quicksilver> thoughtpolice: I HERD YOU LIKED VERBOSE SO I PUT A SYNTAX INSIDE YOUR SYNTAX SO YOU CAN COMPILE WHILE YOU LEX
08:51:23 * quicksilver . o O ( my hobby, conducting conversations entirely in the most annoying memes the internet has devised )
08:51:25 <wli> C++ is pretty ugly, but compiler back ends are being vastly underappreciated in this discussion. Instruction selection and register allocation are not trivial.
08:51:44 <thoughtpolice> edwardk: funnily enough i actually interviewed @ apple, and i interviewed with a guy on the C++ committee who was really nice. invariably we ended up landing on this subject, and i basically just told him (compared to haskell) "you can do most of the same things with the type-language in C++, it's just so verbose and painful and looks like crap so nobody does it" and he was like "yeah, totally"
08:51:49 <quicksilver> wli: I think the point was that a naive but correct backend is easy?
08:52:02 <quicksilver> wli: a good backend is hard and an excellent backend is many many man years.
08:52:07 <wli> Sorry, also stack space management.
08:54:46 <nus> given sufficiently sane machine architecture, sufficiently correct backends are almost noop (-;
08:55:27 <wli> nus: Trouble is, the machine architecture people actually have 99.99% of the time is not sane.
08:55:47 <edwardk> thoughtpolice: =) i've had similar discussions with a number of folks from the boost team at the gsoc mentor summit =)
08:56:06 <wli> Well, maybe not so much anymore but x86-32 will kill you.
08:56:09 <thoughtpolice> edwardk: i've talked to the boost guys a few times too (we contracted boostpro a few times here @ work)
08:57:01 <edwardk> preflex: xseen sjoerd_visscher
08:57:02 <preflex>  sjoerd_visscher was last seen on freenode/#haskell 2 days, 17 hours, 53 minutes and 25 seconds ago, saying: looks like it, Google found it
08:58:17 <thoughtpolice> i think that instruction selection and register allocation can actually be pretty simple honestly (tiling, and a linear scan allocator or something even more braindead can be done) if you ignore the fact it'll perform terribly in the face of many common kinds of control flow etc
08:58:48 <wli> The trouble with stack space also comes up, which was a big issue in the kernel. Non-overlapping live variable lifetimes need to reuse stack space, but this is awkward in many C compilers.
08:58:56 <thoughtpolice> of course, the 'common' kinds of control flow also end up being the hardest to compile anyway (diamond based CFGs,) sooooo....
08:59:12 <wli> And blowing the stack this way in kernels has been a real issue in the past.
08:59:45 <edwardk> just appy a tracing jit, and you get all your registers from inside the loops anyways ;)
08:59:55 <thoughtpolice> wli: yeah i can see that being a concern
08:59:59 <edwardk> so you can use a pretty cheap register allocation strategy
09:00:12 <thoughtpolice> edwardk: yeah, tracing JITs are actually pretty easy to implement from the compilation standpoint i think
09:00:20 <thoughtpolice> you only need to do a handful of simple optimizations on a linear block of IR
09:00:24 <edwardk> yeah.
09:00:37 <thoughtpolice> no inlining needed - it happens automatically!
09:00:39 <wli> thoughtpolice: Something more like GURRR integrated register allocation and instruction selection and maybe also integer linear programming -based affairs are more appropriate.
09:00:41 <edwardk> you _can_ do some serious optimizations if you can amortize them over enough iterations
09:01:07 <edwardk> one of my recurring experiements has been playing with tracing jits for the spineless tagless gmachine
09:01:22 <thoughtpolice> edwardk: been talking to nominolo lately? :)
09:01:26 <edwardk> mainly because the STG as implemented uses a couple of indirect jumps to evaluate thunks for case analysis
09:01:33 <edwardk> i've been playing with this for about 3 years now
09:02:13 <edwardk> i was getting towards a solution when matt morrow bailed off the scene and cost me my main avenue of insight into the ghc bytecode internals ;)
09:02:35 * thoughtpolice wonders what happened to mmorrow...
09:02:42 <thoughtpolice> life, ofc.
09:03:10 <edwardk> yeah i think copumpkin tracked him down all the way to a phone number at some point
09:03:23 <thoughtpolice> copumpkin would of course do that :P
09:03:25 <edwardk> i had lost his somewhere along the way when my phonereset =/
09:03:33 <dolio> He tracked him down to one of his friends.
09:03:52 * wli hasn't passed on contact info to #haskell and #haskell-blah crew and probably should.
09:04:01 <dolio> Who said he also hadn't heard from him for a while, and his family wouldn't tell anyone anything.
09:04:08 <thoughtpolice> edwardk: i've been thinking a lot about tracing JITs lately though (i've been talking to mike pall, which i'm still not convinced isn't a brilliant group of people as opposed to one man.) luajit continuously blows my mind
09:04:13 <thoughtpolice> dolio: :(
09:04:20 <dolio> But the running theory was that he'd moved to the mountains or something.
09:04:21 <edwardk> hah
09:04:50 <ski> (.. done a Grothendieck ?)
09:04:53 <edwardk> i actually have the bulk of the machinery for a tracing jit for x86-64 assembly to x86-64 assembly
09:05:00 <dolio> ski: Something like that.
09:05:03 <edwardk> but i haveno time to work on it
09:05:29 <edwardk> unlike hp dynamo rio i'm not trying to be invisible to user-space, but instead be a cooperative opt-in jit
09:05:31 <thoughtpolice> edwardk: yeah i actually looked it up on your github yesterday as a matter of fact. reason was because i was wondering why tracing JITs aren't applied to machine code more, considering dynamo was originally a JIT for PA-RISC ASM
09:05:42 <edwardk> yeah
09:05:51 <edwardk> i have some odds and ends that never made it up into that repo
09:06:23 <thoughtpolice> i think i concluded (off hand) that the 'portable VM + fast jit if applicable' approach is a bit more palatable i suppose
09:06:30 <edwardk> yeah
09:06:41 <wli> An integrated instruction selection and register allocation library could actually be made rather generic. The GURRR paper describes the generality of the architecture.
09:06:52 <dolio> The x86 JIT is pretty devious.
09:06:55 <edwardk> my goal if i get back around to it is just a cheap haskell to stg compiler, and a simple tracing jit for that bytecode rep
09:07:29 <edwardk> i have to admit the part i'm proudest of in the x86-64 jit is the way it steals control of a pthread
09:07:34 <thoughtpolice> wli: looks like a cool paper, i'll read into it some
09:08:03 <thoughtpolice> 'steals control of a pthread'? SOUNDS DEVIOUS
09:08:16 <edwardk> well, it has to interpret your pthread for you.
09:08:25 <edwardk> but it starts out with you running it normally
09:08:32 <zygoloid> thoughtpolice: you interviewed with Doug Gregor?
09:08:38 <thoughtpolice> zygoloid: yeah actually
09:08:38 <edwardk> so i need to steal it, but i don't want to trap all syscalls and do that kind of crap
09:08:52 <thoughtpolice> zygoloid: doug is such a nice guy. it was a lot of fun talking to him about haskell/c++
09:09:15 <dolio> Well, I meant more the, "I JIT x86, so slip me under any x86 program to make it go faster," aspect.
09:09:17 <edwardk> so i jump way down the stack, stuff all the registers away, then spawn an interpreter thread and join with it. on returning i pull all the registers out of the structure and iret my way back in between any two instructions
09:09:17 <thoughtpolice> i think doug left boostpro for apple before we ended up contracting boostpro, so that was actually the first run in i had with him i think
09:09:37 <zygoloid> thoughtpolice: :) i've not met him in person, but he's great to work with
09:10:05 <edwardk> then the interpreter is living in its own pthread so the libpthread stuff doesn't get confused, it has its own errno, etc. but it can still work with your virtualized gs segment, etc for thread locals
09:10:23 <thoughtpolice> zygoloid: i was kind of freaking out when i heard he was going to interview me ('zomg i will get owned',) but no he's totally awesome and easy to talk to.
09:10:29 <edwardk> dolio: yeah. that was the part that made me happiest by way of comparison to dynamo
09:10:54 <edwardk> yeah i had a similar reaction to being interviewed by erik meijer at one point =)
09:12:35 <wli> Tackling more interesting languages would be a good test of a compiler architecture. Haskell, Mercury/Curry/Oz/$SOME_LOGIC_LANGUAGE, Verilog/VHDL/$SOME_DATAFLOW_LANGUAGE(!), and (of course) C++/Smalltalk/Eiffel/$SOME_OOP_LANGUAGE front ends would prove quite interesting and more enlightening to all have going in parallel even if things are inferior in various respects vs. the llvm approach of basically "everything is vaguely C-like underneath."
09:14:19 <edwardk> i like llvm a lot. i do wish i could get more control over stack layout though.
09:18:20 * Athas is implementing a two-dimensional grid as a zipper and wondering whether it's worth the effort.
09:19:40 <edwardk> athas: i usually just use a pointer comonad
09:19:51 <edwardk> assuming the grid is fixed size
09:21:41 <Athas> edwardk: as in http://hackage.haskell.org/packages/archive/comonad-extras/0.1.1/doc/html/Control-Comonad-Store-Pointer.html ?
09:21:50 <xinming> Does hackage honors the rsync? Since downloading the 150M tar ball each day isn't the way to go IMHO. :-)
09:23:25 <parcs> i suggested an rsync mirror a couple of months ago
09:23:33 <parcs> but no it doesn't have one
09:25:18 <edwardk> athas: that'd be the one.
09:25:26 <wli> Oh, yeah, is there a Fourier-Motzkin lib anywhere?
09:26:07 <edwardk> athas: pos tells you where you are. peek lets you look at neighbors. then you can use extend, etc. to do cellular automata/image-filter-style *everything changes at once* transitions
09:26:20 <edwardk> seek repositions the head
09:27:09 <edwardk> peeks and seeks do relative offsets
09:27:48 <matthiasgorgens> edwardk, sounds nifty.
09:27:49 <Athas> And they raise errors when they fail.
09:27:52 * wli remembers loopo and hsloopo and remembers having some sort of trouble with some lib it depends on.
09:28:11 <Athas> Also, my grid is not rectangular, but a ragged diamond, so I think my hand-rolled solution is better.
09:28:11 <matthiasgorgens> edwardk, i should rewrite some project euler solutions with that.
09:28:18 <Athas> It's probably comonadic, though.
09:28:37 <matthiasgorgens> (though they are closer to dynamic programming than to cellular automata.)
09:28:50 <edwardk> athas: fair nuff. do you have a canonical notion of a location in the diamond?
09:29:25 <Athas> What do you mean by canonical notion?
09:29:46 <edwardk> matthiasgorgens: i'm adding code for representable state monads and representable store monads right now. the representable stores will be basically a more general purpose version of the pointer comonad athas looked at
09:29:59 <edwardk> i mean, can you talk about the coordinate of a cell or do you just have local information?
09:30:31 <xinming> parcs: Ok, thanks.
09:30:57 <xinming> parcs: Does anyone give the reason for that decision?
09:31:04 <Athas> Both, but I could do without the coordinates.  A cell contains four pointers to the cells above and beside it (or Nothing, if it's on the border).
09:31:12 <taotree> What's the most efficient way to skip all values in a Chan and just get the most recent one
09:31:24 <Athas> Well, without the coordinates, you'd have problems, as the data structure is infinite.
09:31:27 <edwardk> well, with the coordinate then the representable version of store would be a closer fit is all
09:32:06 <edwardk> taotree: replacing it with an mvar ;)
09:32:33 <taotree> edwardk, that makes sense, thanks
09:32:41 <ski> or maybe a `SampleVar' ?
09:32:46 <edwardk> or that
09:33:06 <ski> @hoogle SampleVar
09:33:06 <lambdabot> module Control.Concurrent.SampleVar
09:33:06 <lambdabot> Control.Concurrent.SampleVar type SampleVar a = MVar (Int, MVar a)
09:33:06 <lambdabot> Control.Concurrent.SampleVar emptySampleVar :: SampleVar a -> IO ()
09:33:28 <parcs> xinming: no decision was made, my suggestion was just ignored :P maybe there isn't enough demand to warrant the potential work involved
09:34:40 <kakos> Okay, my brain is drawing a blank.  What's the term for taking advantage of currying to do away with needing to put parameters on your function definitions, i.e. "foo x = bar 1 2 3 x" vs "foo = bar 1 2 3"?
09:34:51 <taotree> ok, so the primary difference with a SampleVar is just writing to it doesn't block if it's filled
09:35:03 <byorgey> kakos: that's usually called "eta reduction"
09:35:12 <taotree> which is what I would want, so SampleVar it is
09:35:21 <ski> kakos : maybe you're looking for "extensionality" or "eta-reduction" ?
09:38:26 <edwardk> eta-reduction
09:38:43 <taotree> hmm... SampleVar isn't quite what I want, though, because readSampleVar empties it.
09:40:06 <taotree> So, TVar is probably what I want
09:40:47 <RichardBarrell> taotree: are you just trying to have an atomically-modified variable without incurring synchronisation?
09:41:38 * ski . o O ( `atomicModifyIORef :: IORef a -> (a -> (a, b)) -> IO b' )
09:42:09 <RichardBarrell> Yeah, AIUI atomicModifyIORef fires off a memory barrier but doesn't block threads. That'd be what you want if you're trying to do what I just said.
09:42:39 <taotree> RichardBarrell, I have producer-consumer single value type of situation where there is leniency in the consumer getting the precise "most recent" value
09:43:21 <taotree> ok, there are so many things to choose from :)
09:44:35 <ozataman> anyone have an idea why I keep getting "unknown symbol `_ZTV8BSSource'" errors when I do cabal install on my ubuntu server and never when I do so on my Mac laptop? It happens when TH kicks in and loads a package with FFI bindings...
09:44:53 <ski> @type (. ((snd &&& fst) .: runState)) .  Data.IORef.atomicModifyIORef
09:44:54 <lambdabot> forall a a1. GHC.IORef.IORef a1 -> State a1 a -> IO a
09:48:07 <wli> Where did one-dimensional optimization go in hmatrix' GSL bits, I wonder?
09:49:09 <nus> ozataman, the linux version of the package is miscompiled?
09:49:35 <ozataman> nus: that's what I thought, but I think everything is in PATH and when I compile with GHC, it all works
09:49:41 <ski> @let withSTRef :: (forall s. STRef s st -> ST s a) -> State st a; withSTRef body = state (\st0 -> runST (do ref <- newSTRef st0; a <- body ref; st1 <- readSTRef ref; return (st1,a)))
09:49:41 <lambdabot>   TypeOperators is not enabled
09:51:02 <ozataman> nus: driving me crazy that when I do a proper cabal install, TH traces and loads the entire dependency chain and hangs when it gets to the snappy compression library, which has FFI
09:53:48 <ezyang> Has there been any work using IVars for nondeterministic concurrency? (Par monad is using it for deterministic parallelism)
09:54:18 <nus> ozataman, find out how the cabal-install GHC invocation is different from your manual compile?
09:55:57 <ozataman> Apparently, someone else has run into the exact same problem: http://www.haskell.org/pipermail/haskell-cafe/2010-December/087748.html
09:56:03 <ozataman> not sure what the solution is though
10:03:04 <b0fh_ua> Hello! I want to reverse a number w/o lists, like : 123->321. So far I'm trying to write it as: f x = if x < 10 then x else f ( x `div` 10) * 10 + x `mod` 10, which makes it exactly the same value as it was. But I'm not sure how to transform this expression to reverse the order of items?
10:03:11 <b0fh_ua> *digits
10:04:18 <dmwit> b0fh_ua: There are several questions recently answered just like this on Stack Overflow.
10:04:25 <dmwit> Take a look there.
10:04:47 <b0fh_ua> thx
10:06:46 <b0fh_ua> dmwit: mm, can you please point me to the exact solution? only can find versions with lists (
10:07:45 <dmwit> Wait, what's wrong with lists?
10:08:34 <ski> rewrite the lists to continuations ?
10:08:46 <nus> ozataman, does 'cabal-install snappy' work by itself?
10:09:00 <ozataman> nus: yep, it sure does
10:09:09 <b0fh_ua> dmwit: nothing wrong with lists actually, just want to use plain old recursion )
10:09:23 <b0fh_ua> ski: I don't think that I really need a continuation here
10:09:53 <byorgey> if you write a version with an intermediate list you might be able to apply "deforestation" techniques to remove the intermediate list structure
10:09:55 <b0fh_ua> for instance to reverse 123 we need: ((3+0)*10+2)*10+1
10:10:06 <ski> b0fh_ua : maybe not, but why not introduce a couple of continuations, where you can ?
10:10:08 <nus> ozataman, do you have the failing build log?
10:10:18 <byorgey> ski: hehe
10:12:38 <hpaste> ozataman pasted “build log” at http://hpaste.org/48476
10:12:42 <byorgey> b0fh_ua: why are you trying to do it without lists? just as a learning exercise?
10:14:50 <b0fh_ua> byorgey: yeah
10:15:14 <ozataman> nus: here is the ghc call: /usr/local/bin/ghc --make -o dist/build/omni-raw-mapper/omni-raw-mapper -hide-all-packages -fbuilding-cabal-package -package-conf dist/package.conf.inplace -i -idist/build/omni-raw-mapper/omni-raw-mapper-tmp -i. -idist/build/autogen -Idist/build/autogen -Idist/build/omni-raw-mapper/omni-raw-mapper-tmp -optP-include -optPdist/build/autogen/cabal_macros.h -odir dist/build/omni-raw-mapper/omni-raw-mapper-tmp -hidir d
10:15:14 <ozataman> ist/build/omni-raw-mapper/omni-raw-mapper-tmp -stubdir dist/build/omni-raw-mapper/omni-raw-mapper-tmp -package-id base-4.3.1.0-1554f26e1cc1c87f47464e927dddbd20 -package-id binary-0.5.0.2-375ca49304e384b0f3fccaec5e24f6c6 -package-id bytestring-0.9.1.10-100304f3bd3acb14c76d97b6a012f091 -package-id containers-0.4.0.0-8781485edb2ac0db733a9f9c72e27945 -package-id csv-enumerator-0.8.2-0f0e716f6e324a6b19ecb7f32375f497 -package-id deepseq-1.1.0.2-6
10:15:15 <ozataman> 77f443f43caba0d312ab80199d4a233 -package-id derive-2.5.2-0cfb120f60627022f163740281841862 -package-id http-types-0.6.5-ff09df1d5c79507cfc44c40b91bf9a8e -package-id mapreduce-simple-0.2.1-01643417e286bb2c83ccd0a82dd721d1 -package-id mtl-2.0.1.0-91f62d81c946aa60137dcc008e554a3a -package-id old-locale-1.0.0.2-cc522edd16b73a70b897598c5f5d20c7 -package-id redis-0.11-7bc9f7eb9a99ea0fcef1c59f00a153ca -package-id safe-0.3-6b3d9288c85856a04a797a1c4a
10:15:16 <ozataman> e336ee -package-id time-1.2.0.3-4f1bed38bdf37d398ba8f4311cbdac4a -O -rtsopts -XHaskell98 -XOverloadedStrings -XTemplateHaskell ./Mapper.hs
10:15:19 <ozataman> ooops - sorry everyone
10:15:26 <zygoloid> holy cow
10:15:50 <byorgey> b0fh_ua: well, if you want to do it with plain recursion, you will need to carry along some extra information somewhere
10:16:00 <parcs> b0fh_ua: do you want the solution?
10:16:16 <byorgey> b0fh_ua: suppose I have 123 and decompose it into  12  and 3.  If I recursively reverse 12 into 21, now I have to put together 21 and 3 to get 321
10:16:21 <dmwit> > let f = fst . go 1; go n x | x < 10 = (x,n) | otherwise = let (x', n') = go (n*10) (x `div` 10) in ((x `mod` 10) * n' + x', n') in f 1234
10:16:23 <lambdabot>   9001
10:16:28 <byorgey> but you don't know what power of 10 to multiply 3 by
10:16:54 <byorgey> so you need to return some extra information about what power of ten you are currently working with, then project out the answer at the end.
10:17:25 <dmwit> > let f = fst . go 1; go n x | x < 10 = (x,n) | otherwise = let (x', n') = go (n*10) (x `div` 10) in ((x `mod` 10) * (n' `div` n) + x', n') in f 1234
10:17:26 <lambdabot>   4321
10:17:29 <parcs> > let f x 0 = x; f x y = f (10 * x + y `mod` 10) (y `div` 10); g = f 0 in g 435
10:17:30 <lambdabot>   534
10:17:31 <ski> > fix (\f x acc -> if x == 0 then acc else f ( x `div` 10) (acc * 10 + x `mod` 10)) 123 0
10:17:32 <lambdabot>   321
10:18:13 <byorgey> ah, right, accumulating the answer in another parameter is a more elegant way to do it
10:18:13 <parcs> > let f x 0 = x; f x y = f (10 * x + y `mod` 10) (y `div` 10); g = f 0 in g 4350
10:18:13 <zygoloid> > let f = go 0 where go r 0 = r; go r n = go (10 * r + n `mod` 10) (n `div` 10) in f 1234
10:18:14 <lambdabot>   534
10:18:14 <lambdabot>   4321
10:18:49 <ski> (the accumulator can be seen as a somewhat-degenerate continuation)
10:18:55 <mietek> Is Data.Sequence suitable for doing a binary search on it?
10:19:18 <byorgey> ski: right, you're basically inlining the fact that you are just going to end up passing id as the initial continuation?
10:19:26 <ski> yeah :)
10:19:37 <monochrom> (if you defunctionalize the continuation version, you may get the accumulator version)
10:20:02 <dolio> mietek: It should be all right.
10:20:03 <nus> ozataman, was /home/ubuntu/.cabal/lib/snappy-0.2.0.0/ghc-7.0.3/HSsnappy-0.2.0.0.o from the log generated by your manual invocation of 'cabal-install snappy' ?
10:20:12 <zygoloid> > read . reverse . show $ 1234 :: Integer -- cheat!
10:20:14 <lambdabot>   4321
10:20:16 <ozataman> nus: yes, should be
10:20:19 <ski> with lists, you can often replace a continuation `(foo ++)' with just `foo'
10:20:39 <b0fh_ua> well, not sure that I completely understand the solution :)
10:20:55 <dolio> mietek: However, using a finger tree directly might be better than binary search.
10:21:08 <byorgey> mietek: no, but finger trees, the data structure underlying Data.Sequence, gives you a really elegant way to do logarithmic-time search
10:21:12 <dolio> With an appropriate measure.
10:21:21 <mietek> Right
10:21:38 <mietek> I hoped to avoid implementing finger trees myself
10:21:39 <nus> ozataman, unpack, configure and run tests on snappy, I believe it's misbuilt.
10:21:48 <byorgey> mietek: oh, you don't have to implement them yourself
10:21:48 <dolio> There's a package for them.
10:21:49 <dmwit> mietek: You would probably like finger trees better.
10:22:00 <dmwit> Oh man, I'm way slow today.
10:22:00 <ozataman> nus: how come it works fine when I compile manually with ghc --make?
10:22:03 <byorgey> http://hackage.haskell.org/package/fingertree
10:22:04 <mietek> I thought Data.Sequence is the finger tree package :)
10:22:22 <mietek> Ah, nice
10:22:26 <mietek> Thanks
10:22:49 <nus> ozataman, define 'it works'?
10:23:02 <dolio> Data.Sequence specializes a bunch of things for performance concerns, presumably.
10:23:11 <ozataman> nus: as in snappy is able to do its job several thousand times a second when I compile my program with ghc --make
10:26:21 <o1iver> Hi
10:27:50 <o1iver> I have a problem creating my first haskell library :-). It is looking good (I just looked at the HTTP lib for cabal files etc), but it is still not running because of some strange dependency error. I am using the Happy Parser Generator, but it keeps saying: At least the following dependencies are missing: happy ==1.18.6
10:28:51 <byorgey> o1iver: have you installed happy?
10:28:58 <jonkri> o1iver, try cabal install happy, and if that doesn't work: cabal install happy-1.18.6
10:29:09 <jonkri> or modify your cabal file and remove the version number
10:29:10 <hpaste> ost pasted “dep err” at http://hpaste.org/48477
10:29:20 <byorgey> o1iver: if you have already done 'cabal install happy', the problem may be that it was installed in ~/.cabal/bin
10:29:39 <o1iver> I have already installed happy
10:29:54 <byorgey> o1iver: what OS are you using?
10:30:10 <o1iver> byorgey: yes it installed in ~/.cabal/bin
10:30:15 <o1iver> byorgey: ubuntu
10:30:47 <byorgey> o1iver: ok. so you either need to add ~/.cabal/bin to your $PATH, or edit your ~/.cabal/config file to tell cabal to install things somewhere other than ~/.cabal/bin and reinstall happy
10:30:58 <byorgey> well, or just move the happy executable
10:32:23 <o1iver> byorgey: I am looking at the cabal config file.... how can I set the flag to do a global install instead of a user install?
10:32:39 <byorgey> o1iver: why would you want to do that?
10:32:52 <thoughtpolice> byorgey: you have to specify to use the global package db at configure time, but usually you don't want to do that
10:32:55 <thoughtpolice> er
10:32:57 <thoughtpolice> i meant to send that to oliver
10:33:22 <o1iver> so you would rather install in user mode, but add the install location to the path right?
10:33:24 <byorgey> o1iver: you can set it by changing the 'user-install:' field from True to False, but this is not recommended
10:33:44 <byorgey> right, or change the install location to something that is already on your $PATH
10:34:05 <o1iver> byorgey: ok I will do that now. cheers!
10:34:52 <hpaste> “Ben Gamari” pasted “New GC churn” at http://hpaste.org/48478
10:35:36 <kmc> it's often claimed that learning Haskell makes you a better programmer in any language
10:35:44 <kmc> what are some other things to learn with a similar effect?
10:35:58 <bgamari> Yet another instance of GC churn in a different (simpler) program this time
10:35:58 <bgamari> http://hpaste.org/48478
10:36:02 <bgamari> Any ideas?
10:36:14 <dylukes> "It's often claimed that learning Lisp ..."
10:36:20 <dylukes> I'm sure you could come up with plenty
10:36:33 <bgamari> I'm clearly missing some facet of writing efficient haskell
10:36:44 <dylukes> "It's often claimed that learning recursion requires learning recursion."
10:37:07 <ski> kmc : well, if you haven't already, you ought to learn logic programming
10:37:30 <kmc> ski, *nod* i've dabbled a bit
10:37:44 <kmc> ski, what language would you recommend?
10:37:46 <kmc> prolog? mercury?
10:38:02 <Botje> profanity
10:38:10 <sully> dylukes: the shirts I made for my high school's computer team back in the day had a "In order to understand recursion you must first understand recursion joke" on them
10:38:15 <sully> ... in Java
10:38:20 <dylukes> >_>
10:38:36 <ski> kmc : i recommend learning Prolog first, desipte its (many) warts, because it's *the* logic programming language
10:38:40 <Botje> "imagine a joke about recursion here"
10:38:49 <sully> my tastes in programming languages have changed a bit in the last 5 years
10:39:17 <ski> kmc : Mercury is a nice cleaned-up version of Prolog in many ways, though in some aspects it's less flexible (because of static mode system)
10:39:21 <nus> ozataman, when you manually ghc --make which object file does the '_ZTV8BSSource' symbol come from?
10:39:37 <kmc> preflex, zdec _ZTV8BSSource
10:39:37 <preflex>  _ZTV8BSSource
10:39:51 <dmwit> bgamari: You probably want foldl' rather than foldl, and readData is much more simply written readData h = fmap (map read . lines) (hGetContents h)
10:40:27 <ski> sully : for the worse or for the better ? ;)
10:40:59 <dmwit> bgamari: In fact, readData is probably even better omitted, and the first two lines written "xs <- fmap (map read . lines) (readFile fIn)" instead.
10:41:02 <sully> I mean, I'm a functional weenie now, so probably better? :P
10:41:16 <dmwit> (Not that those two changes will change the behavior of the program. It's just better code reuse. =)
10:41:46 <bgamari> dmwit: Good point about foldl'
10:42:05 <ski> kmc : Mercury adds a static type system, and a static mode and determinism system to Prolog, adding algebraic data types, parametric polymorphism, existentials, type classes, functions, automatic mode-based reordering for better "reversability" of predicates/functions
10:42:07 <bgamari> My strictness sense clearly needs some maturing
10:42:23 <dmwit> bgamari: As for that, is there a reason you're doing a left-fold?
10:42:33 <ski> kmc : oh, and adds declarative I/O as well (more like Clean's uniqueness typing than Haskell's monads, though)
10:42:57 <bgamari> dmwit: Nope
10:43:05 <bgamari> dmwit: Left starts at the beginning of the list, no?
10:43:26 <dmwit> Both foldl and foldr start at the beginning of the list.
10:43:26 <ski> left-folds are tail-recursive, and hence can't be incremental
10:43:48 <sully> kmc: there is also twelf, which adds dependent types and theorem proving
10:43:50 <kmc> you can't operate on lists without starting at the beginning :)
10:43:51 <sully> twelf is hax.
10:44:01 <kmc> sully, ah, cool.  i know of twelf but didn't know it's considered a logic language
10:44:07 <kmc> makes sense with what i've seen, though
10:44:20 <sully> it is, although you generally don't use it for logic programming
10:44:28 <sully> you generally use it for theorem proving
10:44:52 <sully> but theorems are proved by specifying a relation as the types of constants
10:45:01 <sully> which are then interpreted as a logic program
10:45:08 <sully> and if the logic program is total then the theorem holds
10:45:27 <sully> so if twelf can verify its totality, you're good
10:46:47 <dmwit> bgamari: Does that even type-check? Where does putWord64le come from?
10:47:01 <dmwit> (In my "binary" documentation, putWord64le returns a Put, not a Builder.)
10:47:01 <bgamari> dmwit: Ahh, I see. I definitely misunderstood the difference between foldl and foldr
10:47:29 <nus> ozataman,  find /usr/lib/ghc-7.0.3 ~/.cabal -type f -name \*.o|xargs nm  |grep _ZTV8BSSource
10:47:52 <bgamari> dmwit: http://hackage.haskell.org/packages/archive/binary/0.5.0.2/doc/html/Data-Binary-Put.html
10:48:05 * sully always gets tripped up in the order of arguments to the function in foldl in haskell
10:48:06 <bgamari> Oops
10:48:13 <sully> because it is the reverse of what it is in ML
10:48:18 <dmwit> putWord64le :: Word64 -> Put, according to that page
10:48:35 <bgamari> dmwit: Yep, hence the oops
10:48:41 <ozataman> nus: 0000000000000000 V _ZTV8BSSource
10:48:46 <bgamari> dmwit: rather, http://hackage.haskell.org/packages/archive/binary/0.5.0.2/doc/html/Data-Binary-Builder.html
10:48:50 <sully> also in ML :: is cons and : is type ascription
10:48:58 <dmwit> ah
10:49:08 <shachaf> > foldr f z [a,b,c,d]
10:49:09 <lambdabot>   f a (f b (f c (f d z)))
10:49:10 <shachaf> > foldl f z [a,b,c,d] -- sully
10:49:11 <lambdabot>   f (f (f (f z a) b) c) d
10:49:13 <nus> ozataman, err, add -A to nm
10:49:31 <ozataman> nus: /home/ubuntu/.cabal/lib/snappy-0.2.0.0/ghc-7.0.3/HSsnappy-0.2.0.0.o:0000000000000000 V _ZTV8BSSource
10:50:10 <sully> woah, lambdabot can do that? that's pretty sexy
10:50:24 <kmc> sully, yep.  http://hackage.haskell.org/package/simple-reflect
10:50:49 <dmwit> bgamari: Anyway, I recommend using the Put monad. It would handle all of this nonsense for you, all you have to write is:
10:51:02 <dolio> sully: The worst part is if you look at the type. foldr uses b as the result type and a as the element type, and foldl does the opposite.
10:51:08 <sully> yeah.
10:51:26 <dmwit> let bs = runPut (mapM_ putWord64le xs)
10:51:28 <sully> so, like, "graphically", haskell's types make more sense
10:51:45 <sully> because if you are folding from the left, the accumulator should be on the left, or something
10:52:06 <kmc> Put is a silly monad
10:52:18 <sully> but when it comes to "presenting a consistent interface", SML's types for foldl and foldr make more sense
10:52:18 <dmwit> (and then bs is already a ByteString, so no conversion needed on the next line)
10:52:22 <bgamari> dmwit: Alright, excellent
10:52:39 <sully> (well, except that the function takes a tuple instead of being curried, which is fucking lame)
10:52:45 <bgamari> dmwit: I thought there must be a better way than my approach
10:52:57 <dmwit> This boils down to the same thing as your approach, really.
10:52:59 <parcs> kmc: why is put a silly monad?
10:53:20 <dolio> Same reason Writer is a silly monad.
10:53:23 <kmc> when was the last time you wrote a Put action with type other than (Put ())?
10:54:02 <parcs> hah, true
10:54:14 <sully> what is the Put monad?
10:54:14 <kmc> it's basically using "do" as a syntax for monoids
10:54:27 <dmwit> Are there even any primitives that return a type other than (PutM ())?
10:54:29 <kmc> sully, http://hackage.haskell.org/packages/archive/binary/0.5.0.2/doc/html/Data-Binary-Put.html
10:54:34 <bgamari> dmwit: Except the result allocates kilobytes of memory, not gigabytes
10:54:40 <kmc> in fact, yeah, I meant "PutM ()" not "Put ()"
10:54:50 <dmwit> bgamari: =)
10:55:02 <kmc> anyway using "do" as a syntax for monoids is silly
10:55:04 <dolio> @type tell
10:55:05 <lambdabot> forall w (m :: * -> *). (MonadWriter w m) => w -> m ()
10:55:10 <dolio> See? Useless.
10:55:18 <kmc> not to say it's evil or useless, though
10:56:22 <benmachine> dolio: I don't see Writer as useless, especially as a transformer
10:56:43 <ski> sully : well, SML (as opposed to OCaml) generally seems to prefer tupled rather than curried arguments, unless there's some non-trivial computation going on in between the curried arguments
10:56:51 <parcs> @hoogle PutM
10:56:51 <benmachine> you can have operations that tell something and return something else
10:56:51 <lambdabot> Control.Concurrent.MVar putMVar :: MVar a -> a -> IO ()
10:56:51 <lambdabot> Network.CGI outputMethodNotAllowed :: (MonadIO m, MonadCGI m) => [String] -> m CGIResult
10:56:51 <lambdabot> Control.Concurrent.MVar tryPutMVar :: MVar a -> a -> IO Bool
10:56:57 <benmachine> whereas nothing returns anything in Put
10:57:13 <dmwit> I don't think Hoogle indexes the "binary" package.
10:57:16 <sully> ski: that's only half true; it's a bit inconsistent
10:57:26 <ski> sully : yeah, `map', e.g.
10:57:26 * benmachine reckons do {putThing; putThing} could/should be mconcat [putThing,putThing]
10:57:38 <benmachine> pretty much the same amount of syntax involved
10:57:39 <sully> ski: the basis library prefers tupled arguments (except for things like map, half of foldl/r)
10:57:41 <o1iver> byorgey: hey... so I changed my install dir (to something in my $PATH), reinstalled everything, but it is still giving me same error
10:57:42 <dmwit> or (putThing `mappend` putThing)
10:57:46 <kmc> then people would have to learn two scary words that start with 'M'!
10:57:52 <kmc> one is enough
10:57:54 <o1iver> At least the following dependencies are missing:
10:57:54 <o1iver> happy ==1.18.6
10:57:57 <sully> ski: and binary operations take tupled arguments
10:57:57 <dmwit> With a nice operator for `mappend`, that wouldn't even be that bad.
10:58:02 <byorgey> o1iver: what do you get when you type 'which happy'?
10:58:03 <dmwit> putThing <+> putThing
10:58:05 <dolio> benmachine: I don't see it as useless, either. I just like to play devil's advocate to the 'Put is silly' people. :)
10:58:07 <kmc> dmwit, like (++)?
10:58:13 <dmwit> Or (++), yes.
10:58:14 <sully> ski: but every SML programmer I know basically curries everything
10:58:14 <dolio> Because PutM or whatever is just a specialized Writer.
10:58:18 <dmwit> As in Caleskell.
10:58:21 <o1iver> /usr/bin/happy
10:58:27 <ski> sully : yeah, actually i think that (binary operations) is often a nice thing
10:58:28 <dolio> Of course, I pretty much never use Writer.
10:58:32 <benmachine> dolio: oh, I see. I suppose so, but I suspect that Put isn't used like that in practice
10:58:42 <dylukes> Caleskell?
10:58:45 <dylukes> .__.
10:58:45 <o1iver> you know maybe the problem is that i actually installed happy with apt-get before (dunno what I was thinking then)
10:58:56 <sully> ski: there also isn't good syntax for curried lambdas; you have to write "fn x => fn y => ...", which is pretty lame
10:58:57 <bgamari> dmwit: Thanks for your help!
10:58:57 <benmachine> dmwit: I prefer mconcat with the list because commas are so low precedence
10:59:01 <dmwit> :t (++) -- dylukes
10:59:02 <dolio> benmachine: No. In practice it's used to hijack do notation for monoids.
10:59:02 <lambdabot> forall m. (Monoid m) => m -> m -> m
10:59:18 <dmwit> benmachine: fair point
10:59:26 <dylukes> dmwit: …and?
10:59:32 <ski> sully : *nod*, does some implementation borrow this from OCaml ?
10:59:37 <FUZxxl> :t fmap fmap fmap
10:59:38 <lambdabot> forall (f :: * -> *) a b (f1 :: * -> *). (Functor f, Functor f1) => (a -> b) -> f (f1 a) -> f (f1 b)
10:59:46 <FUZxxl> :t fmap fmap fmap fmap
10:59:47 <lambdabot> forall (f :: * -> *) (f1 :: * -> *) a b (f2 :: * -> *). (Functor f, Functor f1, Functor f2) => f (f1 (a -> b)) -> f (f1 (f2 a -> f2 b))
10:59:51 <FUZxxl> :t fmap fmap fmap fmap fmap
10:59:52 <lambdabot> forall a (f :: * -> *) a1 b. (Functor f) => (a1 -> b) -> (a -> a1) -> f a -> f b
10:59:56 <dmwit> dylukes: And, Cale is responsible for the hacks that make that true in \bot.
11:00:00 <sully> ski: I think it is an artifact of when the language was created, where for strict languages tupled arguments really were faster (now we have uncurrying optimizations and it doesn't matter, so....)
11:00:04 <dmwit> :t (.) -- also this one, for example
11:00:04 <sully> ski: hm?
11:00:05 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
11:00:11 <edwardk> :t flip
11:00:12 <lambdabot> forall (f :: * -> *) a b. (Functor f) => f (a -> b) -> a -> f b
11:00:19 <edwardk> i think that one is ski's
11:00:25 * hackagebot representable-functors 1.8.0 - Representable functors  http://hackage.haskell.org/package/representable-functors-1.8.0 (EdwardKmett)
11:00:44 <ski> edwardk : yeah :)
11:00:47 <ski> # fun x y -> x + y;;
11:00:47 <ski> - : int -> int -> int = <fun>
11:00:50 <ski> sully : ^
11:01:01 <dylukes> dmwit: I see.
11:01:32 <sully> ski: yeah, I wish we had that
11:01:46 <sully> ski: SML needs a language revision badly
11:01:50 <ski> dmwit : `fmap ...' works just as soon as you do `Functor (rho ->)'
11:02:12 <ski> sully : is Successor ML being worked on ?
11:02:18 <edwardk> @tell sjoerd_visscher i added representable store and state to representable-functors
11:02:18 <lambdabot> Consider it noted.
11:02:30 <sully> ski: not really :(
11:02:32 <sully> we'll see
11:02:44 <sully> so, Karl Crary and Bob Harper at CMU dream of a new revision
11:03:23 <sully> and I'm starting as a grad student in the PL group there this fall, and I'd be happy to work on it
11:03:26 <sully> but we'll see
11:03:27 <sully> I dunno
11:03:36 <dylukes> sully: I should come visit :P
11:03:58 <o1iver> byorgey: so any ideas...? Happy is installed... Its working (I can generate a parser), but it still says dependency missing
11:03:59 <dylukes> I hope I can get into/pay for CMU :\
11:04:07 <sully> dylukes: you're a Pittsburgh-area high-schooler, right?
11:04:10 <dylukes> Yeah.
11:04:12 <dylukes> I've stupidly let me grades slip to A-'s
11:04:13 <ski> sometimes i would like to declare some infix operators as curried, others as tuples, and yet others as curried the other way around
11:04:39 <ski> s/tuples/tupled/
11:04:44 <sully> I'm not sure how much that will hurt you?
11:04:52 <sully> I dunno, my high school didn't have +s and -s, so...
11:04:53 <dylukes> I mean, I've got course rigor on my schedule.
11:05:00 <dylukes> That's about a 90%
11:05:10 <sully> I got a lot of A-s that showed up as As
11:05:12 <dylukes> I took 3 AP's this year, I was going to take 4, but they didn't fit.
11:05:30 <o1iver> byorgey: strange thing is... if I remove the dependency from the cabal file it will run, but when I try to import it somewhere else it wont work
11:05:30 <sully> what year are you?
11:05:36 <dylukes> Going into senior year...
11:05:40 <sully> ok
11:05:45 <sully> are you applying to MIT?
11:05:59 <dylukes> No, why?
11:06:04 <sully> (like 90% of the people in CMU's CS department are MIT rejects)
11:06:15 <dylukes> hahaha, I didn't think I was quite good enough to make MIT.
11:06:26 <dylukes> I could apply if I felt like it I suppose, just to see.
11:06:42 <sully> CMU's CS department really is just as good
11:06:44 <dolio> I applied.
11:06:53 <edwardk> plus CMU believes in types.
11:06:54 <dylukes> Yeah, MIT has an engineering focus I don't care for.
11:06:59 <sully> yeah
11:07:02 <edwardk> MIT doesn't start believing in types into you hit your grad program
11:07:11 <sully> CMU loves its types
11:07:18 <sully> we teach ML to freshmen now
11:07:26 * hackagebot adjunctions 1.8.0 - Adjunctions  http://hackage.haskell.org/package/adjunctions-1.8.0 (EdwardKmett)
11:07:28 <dylukes> That's great.
11:07:29 <dolio> I doubt I could have feasibly gone there even if I'd gotten in.
11:07:40 <dylukes> See, this is why I'm trying to convince my parents I don't want to end up at, say, Pitt.
11:07:41 <sully> we now teach basically no "practical" languages :P
11:07:47 <dolio> At least, without accumulating a lot of debt.
11:07:51 <dylukes> sully: You've just made me want to get in much, much more.
11:07:56 <dylukes> :P
11:08:26 <parcs> why pay for college when you can learn everything you can possible want on the internet?
11:08:28 <dylukes> I'm pretty much interested in taking a theoretical comsci track, and potentially minoring in something to do with foreign language… (if it fits)
11:08:35 <dylukes> parcs: Professors.
11:08:39 <dylukes> Projects, etc
11:08:47 <dylukes> real world interactions which can't be so feasibly created online.
11:08:47 <sully> but I think the only languages we require people to deal with now are C0 (our custom imperative intro language), C, and SML
11:08:51 <sully> we'll see how well this works out :P
11:08:58 <dylukes> I should learn SML :\
11:09:02 <parcs> well sufficient enough discipline, you don't need professors and/or assigned projects
11:09:06 <sully> the idea is that if we teach students to think like programmers, the rest will fall out
11:09:07 <edwardk> parcs: coz when the economy has a downturn, it makes it easier to get the next job
11:09:10 <dolio> C isn't practical anymore?
11:09:11 <parcs> with*
11:09:13 <dolio> Maybe not.
11:09:17 <kmc> i heard CMU's undergrad CS program is basically nonstop orgies
11:09:17 <dylukes> sully: That's true.
11:09:17 <sully> no, it is
11:09:23 <sully> it shouldn't be
11:09:36 <dylukes> sully: My greatest achievement is convincing my high school CS teacher to try to integrate some Scala at the end of the year.
11:09:38 <parcs> edwardk: that's a valid point
11:09:40 <dylukes> That's as good as I could get.
11:09:51 <edwardk> parcs: it was why i went degree-collecting in the end ;)
11:09:51 <dylukes> I couldn't sell him on anything else, despite the fact he knows ML/Maple...
11:09:52 <sully> so, this scheme is probably worse for people who can't pick up some of the extra more practical stuff on their own
11:09:55 <sully> I dunno
11:10:02 <sully> kmc: that's not really true
11:10:20 <sully> but I mean, I guess the only thing that really got dropped from the curriculum is Java
11:10:24 <dylukes> thank
11:10:25 <dylukes> god.
11:10:33 <dylukes> Pitt's curriculum is entirely Java now. XD
11:10:35 <kmc> i can only assume that C0 is named the same way as C89 and C99 and therefore that it's the systems language used by Jesus himself
11:10:47 <dylukes> Or at the turn of the century.
11:10:57 <sully> there is now an optional "Object Oriented Design" class
11:11:04 <mgsloan> probably depends on your way of approaching it, but as someone who knew CS relatively well before college, going to college for the subject has been relatively unrewarding
11:11:11 <sully> that will probably fill a CS elective
11:11:13 <dolio> All about coalgebras, I'm sure.
11:11:20 <sully> so, I was a good programmer before I went to CMU
11:11:26 <dylukes> btw, do you know a "David Eckhardt"
11:11:29 <sully> and now I'm a better programmer and a good computer scientist
11:11:35 <sully> dylukes: yeah, I've TAed for him for 3 years
11:11:41 <dylukes> heh, just wondering
11:11:47 <kmc> imo CS in college isn't about the courses specifically
11:11:57 <dylukes> my friend Chaz knows him, and he was apparently looking for someone who knows Cocoa, so he referred me to him, for what I don't know.
11:11:58 <kmc> it's just about someone forcing you to learn things
11:12:01 <kmc> you still learn on your own
11:12:04 <dylukes> I haven't gotten any sort of email from him.
11:12:10 <dolio> kmc: It's about the drinking?
11:12:12 <dylukes> Chaz is involved in the voting machine thing...
11:12:17 <sully> ah, ok
11:12:18 <mgsloan> CMU seems good - been talking to people here at OPLSS from CMU
11:12:18 <sully> interesting
11:12:45 <sully> Eckhardt roped me into going and monitoring Allegheny County's validation of voting machine firmware
11:12:59 <mgsloan> kmc - true, it's definitely about your approach.  When the subject is quite a lot of work, though, it can really suck the time out of your extracurricular pursuits
11:13:01 <sully> which is, validating the the firmware on some of the machines was the firmware that was supposed to be there
11:13:16 <sully> (the known buggy firmware that was supposed to be there)
11:13:24 <dylukes> hehe
11:13:51 <sully> he's the Operating Systems professor
11:14:02 <sully> I was an OS TA for many semesters
11:14:12 <sully> CMU has basically the most hardcore OS class I'm familiar with
11:14:28 <dylukes> That sounds good actually.
11:14:28 * hackagebot representable-tries 1.8.0 - Tries from representations of polynomial functors  http://hackage.haskell.org/package/representable-tries-1.8.0 (EdwardKmett)
11:14:33 <dylukes> I'd love to take it :\
11:14:52 <dylukes> See, the reason I'm applying to CMU is, when I look at the curriculum, *there are so many courses I'd like to take*
11:15:01 <dylukes> (among other reasons)
11:15:39 <kmc> sully, yeah, CMU's OS class is infamous
11:15:43 <kmc> how does it compare to MIT 6.828?
11:15:48 <sully> the core project is "Write a kernel that runs on x86 hardware with multithreading and memory protection and a preemptible kernel. Basically from scratch. In six weeks."
11:16:15 <sully> kmc: I think MIT's OS class is mostly on rails; that is, you fill out the bodies of functions and the design has been done for you?
11:16:30 <kmc> largely true
11:16:32 <dylukes> sully: That sounds insane.
11:16:34 <sully> and also the kernel doesn't need to be preemptible; you just disable interrupts while running in the kernel
11:16:34 <dylukes> but fun
11:16:42 <kmc> though each lab requires you to do at least one "challenge problem" which is less well-specified
11:16:55 <sully> we give you a syscall ABI
11:17:04 <sully> and then you need to satisfy it
11:17:13 <dylukes> sounds like a real wheat-from-the-chaff type course.
11:17:32 <kmc> dylukes, yep, and even the wheat will blame it years later for permanent physical and psychological damage
11:17:38 <sully> heh!
11:17:41 <kmc> maybe i will attempt the CMU course next
11:17:47 <sully> well, there's a reason it isn't a required course
11:17:48 <kmc> how much of the necessary materials are available online?
11:17:55 <dylukes> kmc: I don't see *any*.
11:17:55 <dylukes>  
11:17:58 <dylukes> I'm looking now >_>
11:18:04 <dylukes> ah here we go
11:18:10 <dylukes> http://www.cs.cmu.edu/~410/projects.html
11:18:16 <kmc> 6.828 is at http://pdos.csail.mit.edu/6.828/2010/
11:18:18 <sully> kmc: they used to all be up, but then I think university policy made the professor put the downloads behind a login-wall?
11:18:25 <kmc> sucks
11:19:29 <sully> so, we do a pretty good job of ramping up to the kernel
11:20:04 <sully> p0 is a solo project writing a stack tracer that runs on linux and isn't allowed to crash due to a malformed stack or an invalid user pointer or whatnot
11:20:49 <dylukes> I wish I could find some sort of lectures here. I kind of want to try p0
11:20:58 <sully> p1 is a solo project writing a video game that runs on the bare metal (the core part being a video driver and a keyboard driver)
11:20:58 <dylukes> dunno if it'd work on OS X, I could install vm
11:21:20 <sully> p2 is a pair project writing a thread library that runs on top of a Pebbles kernel; we provide a reference kernel binary
11:21:24 <sully> p3 is the kernel
11:21:32 <sully> p4 is a small extension to your project 3 kernel
11:21:54 <sully> (or, if you aren't sufficiently done with p3, you take a 0 on p4 and do p3extra, which is an extra week to do p3)
11:22:27 <dylukes> This sounds like one of those courses it might be good to kind of… do in advance
11:23:07 <sully> I mean, it's definitely doable
11:23:21 <dylukes> See, I'd have no idea where to start with p0
11:23:30 <dylukes> seems like a decent thing to try to do over the next week though
11:23:41 <sully> we generally get between 1 and 4 /good/ kernels every semester?
11:24:24 <sully> and then a lot of "You got a bunch of things wrong, but you got more things right, and this generally shows a bunch of thought, and it's a hard class, so good job."
11:24:53 <sully> and then a lot of "This is really pretty bad, but at least you probably learned a lot, right?"
11:24:59 <sully> and then a handful of "Dude, what the fuck?"
11:25:06 <kmc> "F is for effort"
11:25:08 <thoughtpolice> "no idea where to start" <- yes, that's the beginning of the process known as learning i recall.
11:25:21 <dylukes> sully: If I go through the lectures prior to p0, do you think p0 would be doable?
11:25:29 <thoughtpolice> sully: all about equal? or is there a depressing amount of "what the fuck"
11:25:30 <sully> maybe
11:25:35 <dylukes> I mean, I'm going to have to resort to the googlemonster inevitably...
11:25:42 <sully> I don't remember how much we cover
11:25:50 <sully> p0 assumes you took the class before OS
11:25:58 <dylukes> which was?
11:26:04 <kmc> thoughtpolice, it's hard to learn if you actually have no idea where to start
11:26:04 <sully> which covers things like assembly and what the stack looks like and whatnot
11:26:10 <kmc> learning is an incremental process
11:26:14 <dylukes> Oh, I know the basics of that, but not thoroughly enough :\
11:26:34 <kmc> i think if i were teaching a class on "assembly and what the stack looks like and whatnot" it would involve a lot of writing exploits
11:26:45 <sully> you don't really need to know a lot of assembly for p0, but you definitely need a pretty solid understanding of the stack
11:26:50 <sully> kmc: it involves a little bit of that
11:26:55 <kmc> which is a seriously great way to learn assembly, stack layout, how dynamic libs work, system calls, etc etc
11:26:55 <sully> one of the labs is reverse engineering
11:27:00 <kmc> i might just make them play http://io.smashthestack.org:84/
11:27:02 <sully> and another is writing buffer overflows
11:27:03 <thoughtpolice> kmc: yeah. i already have a hard enough time with it these days, i've just always an autodidact for a long time (which probably isn't uncommon, here)
11:27:08 <thoughtpolice> *been
11:27:25 <sully> thoughtpolice: there is probably less "what the fuck" than most of the rest?
11:27:35 <dylukes> sully: My understanding of the stack is "its a region of memory with a series of frames extending downward, with a stack pointer to the top element"
11:27:36 <thoughtpolice> kmc: reverse engineering is the way I learned assembly, it's a great way to go about it. security is mighty fun
11:27:37 <dylukes> I think thats about it.
11:27:46 <dylukes> to the bottom element*
11:27:50 <sully> thoughtpolice: although I was always known as the TA that happened to get the shitty luck and get all the crappy ones
11:28:15 <sully> thoughtpolice: like the one semester where my median kernel grade was equal to the minimum kernel grade between all the other graders
11:28:23 <thoughtpolice> sully: bummer. i only ask because while I didn't take OS courses, it always roughly fell into the same categories like you outlined, only there were lots and lots and lots of "WTFs"
11:29:17 <sully> dylukes: yeah, P0 will require knowing specifics of the stack layout
11:29:31 <dylukes> hm, anything I should look at in that regards?
11:29:42 <sully> hm, I'm not actually sure
11:29:47 <sully> smashing the stack for fun and profit? :P
11:29:50 <thoughtpolice> dylukes: i agree with kmc when he says exploits and security and whatnot. there are books on this
11:30:08 <thoughtpolice> the one i learned from that's quite old now but still relevant is jon erickson's book, i can't remember the name.
11:30:19 <dylukes> this one?
11:30:19 <dylukes> http://en.wikipedia.org/wiki/Hacking:_The_Art_of_Exploitation
11:30:21 <sully> yeah, and you need to be familiar with assembly
11:30:24 <thoughtpolice> also, phrack is pretty invaluable, but you need some experience because lots of the stuff in the more recent years is quite hardcore
11:30:27 <thoughtpolice> dylukes: yes
11:30:32 <dylukes> I'm relatively okay with assembly.
11:30:39 <kmc> dylukes, you might have fun playing that 'io' game
11:30:47 <dylukes> I can't really write it, but I can read through an understand it.
11:30:55 <thoughtpolice> yeah, smash the stack has been around forever too. they have lots of good exercises
11:30:58 <kmc> i got to level 25; i can give you tips through there
11:31:00 <sully> so if you are familiar with assembly it shouldn't be too hard to figure out what the C calling convention looks like
11:31:00 <thoughtpolice> there were a few other places that did similar stuff
11:31:02 <kmc> and they have their own IRC channel
11:31:08 <kmc> just don't say anything bad about C on that channel
11:31:13 <thoughtpolice> ever?
11:31:15 <kmc> or they will cut you like a prison bitch
11:31:16 <dylukes> kmc: what game?
11:31:22 <kmc> http://io.smashthestack.org:84/
11:31:30 <dylukes> hm
11:31:42 <sully> OS involves writing some assembly, but not that much
11:31:54 <sully> I tell students that the purpose of assembly is to get back into C
11:31:55 <thoughtpolice> dylukes: things like this are an excellent way to get familiar with ABIs, stacks, and generally more familiar with security/C programming
11:32:00 <mietek> Anyone familiar with the fingertree package?
11:32:12 <kmc> sully, do people in the CMU OS class end up writing monolithic or microkernels or what?
11:32:12 <sully> and then in the PL class I TAed I told students that the purpose of C is to get back into ML or Haskell
11:32:30 <sully> kmc: the design is essentially monolithic
11:32:34 <kmc> sully, and in the theorem proving class the purpose of Haskell is to get back into Agda
11:32:56 <sully> kmc: although the total size of the code students have to write is generally between 3000 and 6000 lines as reported by sloccount
11:33:03 <sully> so in a sense it is pretty "micro"
11:33:09 <kmc> oh, that's quite small
11:33:09 <dylukes> alright… i'll read the read me now then
11:33:11 <kmc> the kernel in 6.828 has an interesting design
11:33:14 <dylukes> oh, I have to go to my internship in a second
11:33:19 <dylukes> I guess when I get back I'll get to playing this
11:33:25 <kmc> they call it an 'exokernel'... i'm not totally sure what that means, or to what degree it's a term that exists outside MIT
11:33:27 <sully> it's basically a minimal monolithic kernel
11:33:36 <kmc> but it's a microkernel where userspace gets a lot of direct control of the paging unit
11:33:47 <kmc> so (for example) you implement copy-on-write fork() largely in userspace
11:33:52 <sully> http://www.cs.cmu.edu/~410/p2/kspec.pdf is the syscall interface
11:34:00 <sully> cool.
11:34:04 <dolio> kmc: I've heard it before. And I don't troll through OS courses.
11:34:13 <kmc> the handler that copies write-faulted shared pages is userspace code, kinda like a UNIX signal handler
11:34:24 <proq> kmc: doesn't exo mean "outside of"?
11:34:29 <kmc> yeah
11:34:38 <sully> we have userspace fault handlers now, actually
11:34:44 <sully> that is new as of last semester
11:34:55 <sully> and so the autogrow stack is done in userland
11:34:57 <kmc> (one of the small but mind-bending bits of assembly is the code to get from the user trap handler context back to the normal user code's registers and stack, without going through the kernel)
11:34:57 <pikhq_> proq: In an exokernel, pretty much all of the normal facilities of a kernel are actually outside of the kernel.
11:35:04 <pikhq_> proq: So, it actually does make sense.
11:35:18 <sully> but zero-fill-on-demand and copy-on-write still basically need to be done in the kernel
11:35:23 <sully> (we don't require copy-on-write, though)
11:35:29 <kmc> moooooo
11:36:03 <sully> oh, also, most of the "what the fuck" in the class comes from masters students
11:36:15 <dylukes> ?
11:36:23 <dylukes> brb
11:36:29 <dylukes> I'm going to have to leave for my internship now ^^
11:36:41 <dylukes> thanks kmc/thoughpolice/sully
11:36:51 <sully> dude, isn't it like 2PM for you?
11:36:53 <sully> oh, too late
11:37:19 <olsner> unless this eventually concludes as "and that's why the kernel is a zygohistomorphic prepromorphism", I think you've gone a bit off topic :)
11:37:34 <pikhq_> And that's why GHC is the best kernel.
11:37:54 <sully> a bit
11:38:02 <sully> I wind up explaining CMU's OS course in a lot of channels.
11:38:04 <olsner> pikhq_: that works too
11:38:06 <sully> usually it is off topic :P
11:38:06 <thoughtpolice> it's #haskell at 2pm in the afternoon on a tuesday. for some reason i don't find the discussion surprising, even if OT
11:38:23 * sully should be working
11:38:30 <o1iver> Hey. I have a problem that some code that work perfectly in interactive mode or imported directly no longer works when build is with cabal "unknown symbol" error. What is usually the cause of this?
11:38:44 <sully> oh, I was in the middle of a build and I didn't notice when it failed
11:38:47 <sully> oops
11:38:53 <kmc> olsner, does it work when you build with --make?
11:38:57 <tommd> o1iver: If you are using GHC < 7 then use --make
11:38:57 <thoughtpolice> sully: compilers are still a good excuse to take time off :P
11:39:06 <olsner> kmc: usually does, yeah
11:39:16 <kmc> err
11:39:22 <kmc> i meant to ask o1iver
11:39:23 <kmc> sorry
11:39:25 <olsner> :)
11:39:32 <tommd> darn number names!
11:39:44 <sully> thoughtpolice: this is especially true because I am working on a bootstrapped language that doesn't know about incremental compilation yet
11:40:06 <tommd> We should all just go by numbers (concatMap (show . fromEnum))
11:40:14 <o1iver> actually I am "installing" with cabal, so how do I add that flag there?
11:40:14 <thoughtpolice> sully: i'm getting pretty excited about rust at this point - i saw macros went in just today :)
11:40:34 <o1iver> I am trying to create a library to use somewhere else
11:40:37 <sully> little macros just went in today
11:40:50 <tommd> o1iver: Does this use a C library?
11:41:00 <tommd> Are the missing symbols from a C library?
11:41:04 <thoughtpolice> do big macros expand to more code? :P
11:41:14 <sully> well, I think it is a very restricted system
11:41:27 <sully> they are currently desigining the next thing
11:41:38 <o1iver> no...pure haskell (although it does use a parser generated by Happy and the symbol has someting to do with some Happy generated code : "unknown symbol `XGenzm0zi0zi1_XGenziParserziHappyParser_notHappyAtAll_closure'"
11:41:39 <thoughtpolice> ah.
11:41:43 * hackagebot kan-extensions 1.8.0 - Kan extensions, the Yoneda lemma, and (co)density (co)monads  http://hackage.haskell.org/package/kan-extensions-1.8.0 (EdwardKmett)
11:41:52 <edwardk> added Co and church-encoded Free
11:41:55 <thoughtpolice> preflex: zdec XGenzm0zi0zi1_XGenziParserziHappyParser_notHappyAtAll_closure
11:41:56 <preflex>  XGen-0.0.1_XGen.Parser.HappyParser_notHappyAtAll_closure
11:41:59 <sully> rust's process seems to be involving adding lots of features and then removing lots of features :P
11:42:16 <o1iver> thoughtpolice: whats preflex?
11:42:33 <thoughtpolice> oliver: it's a bot. it just decoded the mangled name of the symbol
11:42:36 <tommd> preflex: who are you?
11:43:01 <thoughtpolice> oliver: i'm willing to bet that in some package you are forgetting to specify some module as part of either the 'exposed-modules' or 'other-modules' field
11:43:07 <o1iver> ok I see
11:43:12 <thoughtpolice> i say this, because someone ran into something yesterday that i think was eerily like this :)
11:43:20 <monochrom> yes
11:44:03 <thoughtpolice> sully: yes, seems to be in quite a state of flux, but i'm not surprised. i'm rooting for you guys :>
11:44:15 <o1iver> well in Cabal I only export the modules that I want to use externally right?
11:44:40 <thoughtpolice> oliver: yes, but anything else needs to be put in the 'other-modules' field
11:44:55 <thoughtpolice> it won't be exposed, but it needs to be there so it can properly be included in the final archive and whatnot
11:45:15 <o1iver> thoughtpolice: ah... ok. Didnt know that. I will try that and see if it works
11:46:44 <o1iver> thoughtpolice: ok... great. That fixed it
11:46:51 <thoughtpolice> np
11:47:16 <o1iver> thoughtpolice: so for further reference. Every module in a package must be in either "Exposed-modules" OR "Other-modules"
11:47:19 <o1iver> ?
11:47:24 <monochrom> yes
11:47:25 <thoughtpolice> yep
11:47:51 <thoughtpolice> o1iver: the thing is, cabal doesn't warn you, so you won't see a problem until you try to link your program against that library :P
11:48:20 <monochrom> cabal cannot warn you
11:48:30 <o1iver> thoughtpolice: yeah that would have been my next question. STrange thing that cabal doesnt warn, considering that its an easy mistake (especially when maintaining) and renders the library useless
11:48:44 * hackagebot pointed 1.8.0 - Haskell 98 Pointed and copointed data  http://hackage.haskell.org/package/pointed-1.8.0 (EdwardKmett)
11:48:53 <Clint> which genetic algorithm libraries are most worth using?
11:49:01 <o1iver> monochrom: why? Could it not just check all imports and then warn if either of those are not exported?
11:49:47 <monochrom> imagine what it takes for you to know. ask yourself can cabal do it.
11:50:15 <monochrom> first method: you wrote the package yourself. well cabal doesn't know how to write any package, let alone your package
11:50:41 <dmwit> > 0.15 * 255
11:50:41 <monochrom> second method step one: parse source code file to find out what is imported. well cabal doesn't parse.
11:50:41 <lambdabot>   38.25
11:50:55 <o1iver> monochrom: ok, if it doesnt parse then it cannot know
11:51:03 <dmwit> > 0.85 * 255
11:51:03 <lambdabot>   216.75
11:51:06 <dmwit> > 0.85 * 256
11:51:07 <lambdabot>   217.6
11:51:12 <thoughtpolice> wait, then how does cabal tell you that you're using some package that isn't explicitly listed in its build-depends field?
11:51:15 <o1iver> thanks for the explanation and the help guys
11:51:16 <thoughtpolice> does it get GHC to tell it somehow?
11:51:32 <thoughtpolice> (i actually have never thought about this)
11:52:12 <monochrom> second method second step: for each imported module, be able to guess whether it is part of the same package or else from a depended package by looking into directories... well cabal doesn't do that either, not to mention that the guess cannot be perfect
11:53:34 <monochrom> the second method can be easily confounded by conditional imports
11:54:45 * hackagebot ad 1.1.0 - Automatic Differentiation  http://hackage.haskell.org/package/ad-1.1.0 (EdwardKmett)
12:03:15 <dankna> @hoogle hash
12:03:15 <lambdabot> Trace.Hpc.Util data Hash
12:03:15 <lambdabot> Network.HTTP.Headers class HasHeaders x
12:03:15 <lambdabot> Data.HashTable hashInt :: Int -> Int32
12:04:07 <monochrom> cabal doesn't know that your build-depends is incomplete either.
12:04:26 <monochrom> at "cabal build", ghc finally finds out
12:07:58 <monochrom> as for how come ghc knows enough to say "Perhaps you need to add `mtl' to the build-depends in your .cabal file", that's probably because of the -fbuilding-cabal-package flag
12:08:26 <monochrom> yes there is a conspiracy between them!
12:10:56 <dmwit> Cabal could warn you.
12:11:06 <dmwit> It could look at your directory tree for *.hs files.
12:11:14 <monochrom> indeed you can reproduce this experiment yourself: normally the GHC API package (ghc) is hidden. write "module X where import GHC" and try "ghc -c -fbuilding-cabal-package X.hs". suddenly its error message talks about ".cabal" too!
12:11:46 <shachaf> GHC knows about Cabal now?!
12:11:53 <shachaf> Blatant favoritism on the part of the judges.
12:12:02 <monochrom> yes, conspiracy!
12:12:11 <dmwit> Though I would certainly want the option to turn off that feature for projects with big directory trees.
12:13:41 <Kaidelong> why can't djinn prove ~(a /\ b) => ~a \/ ~b
12:13:55 <Kaidelong> is intuitionistic logic unable to prove that?
12:14:00 <dmwit> Because that's not valid in intuitionistic logic.
12:14:02 <monochrom> because there is a counter-model
12:14:32 <monochrom> if you know kripke structures for intuitionistic logic, I can show you
12:14:38 <Kaidelong> not yet
12:14:46 <Kaidelong> anyway that's interesting
12:16:03 <balor> Is there a haskell analogue of the JavaScript decodeURIComponent :: String -> String anywhere?
12:16:25 <balor> it translates %20 in URIs to spaces and all that jazz
12:16:42 <monochrom> it's a multiple-world thing. so, a counter-model for a classical logic statement is just one world. for an intuitionistic logic statement you may need several related worlds. and so...
12:16:47 <monochrom> @quote monochrom Kripke
12:16:47 <lambdabot> monochrom says: There are truths, damn truths, and Kripke structures.
12:16:55 <azaq23> @hoogle URI
12:16:56 <lambdabot> module Network.URI
12:16:56 <lambdabot> Network.URI data URI
12:16:56 <lambdabot> Network.URI URI :: String -> Maybe URIAuth -> String -> String -> String -> URI
12:17:20 <balor> azaq23, thanks
12:18:28 <Kaidelong> having a proof of that two things cannot be true at the same time doesn't give you a proof that one of them is false?
12:19:04 <monochrom> does in classical logic. doesn't in intuitionistic logic
12:19:34 <Kaidelong> hmm, does that extend to any constructive logic?
12:19:53 <monochrom> in intuitionistic logic, someone would ask, "but do you know which one?", and you would answer, "I don't know", and he/she would say, "then that's no proof"
12:19:54 <Kaidelong> because if it does it kind of makes sense
12:19:59 <monochrom> yes
12:20:07 <xplat> @remember quicksilver < quicksilver> C++ templates can embed arbitrary computation at compile time < quicksilver> that alone tells you something about the complexity of the compiler < edwardk> yeah. they were accidentally turing complete. (whoops!) ;) < quicksilver> edwardk: OOPS I ACCIDENTALLY THE WHOLE TARPIT
12:20:07 <lambdabot> Done.
12:20:20 <augur> ehh
12:20:26 <augur> monochrom: isnt linear logic constructive
12:20:46 <monochrom> why so many spaces in e.g. "< quicksilver>" "< edwardk>"
12:20:50 <monochrom> I don't know
12:20:56 <Eduard_Munteanu> What's this stuff with "accidentally"? I've seen people say that by mistake occasionally. :)
12:21:26 <shachaf> monochrom: irssi inserts those, possibly so a nick will stay the same length with an @/+ in front.
12:21:28 <Eduard_Munteanu> monochrom: irssi puts a space in there
12:22:42 <azaq23> Eduard_Munteanu: http://knowyourmeme.com/memes/i-accidentally
12:22:54 * Eduard_Munteanu looking, thanks
12:23:34 <o1iver> Hey. Quick question about exceptions. Let's say I have a pure function that can throw an exception (say head), how can I very easily return a Maybe type depending on wether or not the exception was thrown (not using IO like catch)?
12:24:15 <shachaf> o1iver: Ideally you'd use a safe head function :: [a] -> Maybe a.
12:24:43 <Eduard_Munteanu> Ah, so it's either really common or intentional.
12:24:43 <shachaf> In general that sort of exception is evil and shouldn't be used.
12:24:49 <o1iver> shachaf: but what if I can't change the funtion that may throw the exception?
12:25:19 <shachaf> I don't think you can catch it without unsafePerformIO.
12:25:21 <Tomsik> @type safeHead
12:25:21 <lambdabot> Not in scope: `safeHead'
12:25:22 <parcs> wrap it in another function
12:25:36 <shachaf> @ty listToMaybe
12:25:37 <lambdabot> forall a. [a] -> Maybe a
12:25:59 <Eduard_Munteanu> > listToMaybe [1,2,3,4]
12:26:00 <lambdabot>   Just 1
12:26:23 <o1iver> parcs: yeah, but then how do I catch it there without going unpure?
12:26:36 <monochrom> you can only use IO to catch it. and even then you have to code it carefully, not naïvely
12:26:39 <shachaf> You can't. Catching exceptions isn't pure.
12:26:44 <shachaf> It depends on evaluation order.
12:26:56 <o1iver> shachaf: ok that makes sense
12:27:24 <parcs> o1iver: you don't. you make sure only good input gets fed into the wrapped function
12:27:50 <parcs> but you'd have to know the implementation details of the function, i guess
12:27:55 <tommd> o1iver: safeHead is just listToMaybe from Data.Maybe, but there is a 'safe' package with all sorts of safeness.
12:28:38 <o1iver> parcs: well actually its a parser that may throw the exception, so unless I parse before parsing [;-p] that wont work
12:28:51 <o1iver> tommd: I am looking at the safe package now. thanks
12:28:52 <Kaidelong> ah interesting
12:29:06 <Kaidelong> because you can't construct a proof from an abscence of a proof, excluded middle doesn't work either
12:29:10 <monochrom> proper parsers offer many options for telling you about parse errors
12:29:29 <monochrom> such as Either or Maybe
12:29:42 <o1iver> monochrom: yes, but I am trying to get a proof of concept going :-). BUt I guess I will have to take the time...
12:30:13 <parcs> o1iver: yeah, then you're out of luck
12:30:42 <monochrom> you're making it a proof of misconcept if you don't include proper error reporting
12:31:25 <monochrom> especially since it is only 1% more work
12:32:27 <o1iver> monochrom: I am fixing the error handling now, but its a work/reward ratio thing you know...
12:32:42 <nus> ozataman, the manual 'ghc --make' invocation you've mentioned to work, is it on the same project using TH or is it something other non-TH'y just using 'snappy' ?
12:33:15 <monochrom> work/reward ratio is what gets us into buggy software and global warming
12:33:25 <monochrom> because the reward system is all wrong
12:33:26 <ozataman> nus: it is the exact same project. however, it has no need to load snappy, as snappy is really used by an underlying library that ghc --make does not feel the need to load
12:35:30 <o1iver> monochrom: ok, well the thing is. I only have limited time (my free time) and I am building something that may not be useful to anybody after all, so thats my risk-work-reward relationship. But I agree with you in general
12:35:41 <monochrom> reward for software that looks great in controlled demos but has latent bugs to trick users two days later. (great scam if you ask me.) reward for electric appliances that "does more" at the expense of using more electricity.
12:37:21 <o1iver> monochrom: at least in those cases you have proven that people *do* use it :-)
12:38:50 * hackagebot reflection 0.4.0 - Functional Pearl: Implicit Configurations  http://hackage.haskell.org/package/reflection-0.4.0 (EdwardKmett)
12:38:52 <augur> ezyang: oh oh whats trickier?! :D
12:39:14 <edwardk> reflection now just uses Proxy instead of Tagged.
12:39:20 <augur> hey edwardk
12:39:23 <edwardk> makes it easier when using multiple sets of proxies
12:39:25 <edwardk> yo
12:39:33 <augur> so
12:39:36 <edwardk> i noticed you got a chance to catch up with koninkje
12:39:36 <augur> question answering time :D
12:39:40 <edwardk> haha
12:40:02 <augur> yeah, koninkje's cool.
12:40:26 <rlin> hey is anyone there?
12:40:33 <augur> no
12:40:38 <kmc> no, all 781 of us are bots
12:40:39 <rlin> lol
12:40:52 <augur> and we're in the same house
12:40:57 <augur> or was that a movie
12:41:00 <burp_> kmc: you forgot ChanServ
12:41:04 <rlin> k..
12:41:07 <monochrom> same cloud. more trendy
12:41:14 <kmc> rlin, did you have a Haskell question?
12:41:17 <rlin> yeah
12:41:33 <ezyang> augur: Continuations... with mutation.
12:41:34 <rlin> i just started learning haskell a few hours ago. i'm a complete beginnner when it comes to functional programming but i have a few years of programming experience
12:41:39 <augur> ezyang: whaaa
12:41:43 <rlin> and i tried using the Real World Haskell book
12:41:53 <ezyang> Actually, mutation without continuations. I suspect things would be better if we had continuations though...
12:41:53 <rlin> i dont like it though
12:41:56 <augur> rlin:
12:41:58 <rlin> i need recommendations on another resource
12:41:59 <augur> @where lyah
12:41:59 <lambdabot> http://www.learnyouahaskell.com/
12:42:13 <rlin> looks nice
12:42:19 <rlin> any other good resources i should be aware of?
12:42:33 <augur> @where google
12:42:33 <lambdabot> I know nothing about google.
12:42:36 <kmc> @google try haskell
12:42:38 <lambdabot> http://tryhaskell.org/
12:42:38 <lambdabot> Title: Try Haskell! An interactive tutorial in your browser
12:42:38 <augur> nope!
12:42:58 <monochrom> don't forget generally www.haskell.org
12:43:00 <rlin> lambdabot: done that already
12:43:08 <rlin> k
12:43:15 <rlin> im off, back to haskell
12:43:19 <rlin> cya
12:43:19 <kmc> #haskell is the best resource :)
12:43:21 <rlin> & thanks
12:43:25 <augur> rlin: lambdabot is a bot :P
12:43:31 <danharaj> did he address lambdabot :p
12:43:34 <luite> rlin: be aware that the authors of real world haskell hang around in this channel, they'll hate you for not liking their book ;)
12:43:39 <luite> oh too late
12:43:40 <augur> hes gone folks
12:44:05 <monochrom> prior non-FP experience may be a liability not an asset
12:44:22 <augur> monochrom: i had prior non-FP experience but then i watched sicp
12:44:53 <monochrom> unless you can launch a virtual machine in your mind as a clean slate for learning this haskell thing. (I did.)
12:45:13 <augur> according to dan dennett, language might be a virtual machine.
12:45:16 <augur> i dont think hes right.
12:45:35 <krawczyk> Well,  just fix your definition...
12:45:53 <monochrom> sicp's way of starting gives you strong incentives to launch a virtual machine
12:46:54 <monochrom> whereas the very name "real world haskell" does the opposite
12:47:09 <kmc> my brain came with VMX disable in the bios :/
12:47:12 <kmc> i could fix it but i have to reboot
12:47:25 <krawczyk> I can remember somebody asking "What is reality...?"
12:48:08 <krawczyk> @:type map
12:48:09 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
12:48:18 <krawczyk> @map (+1) [1,2,3,4]
12:48:19 <lambdabot> http://www.haskell.org/hawiki/HaskellUserLocations
12:48:36 <monochrom> LYAH's cartoons give you a moderate incentive to launch a virtual machine, since you feel you're reading a fairy tale rather than "so how to translate C to this"
12:48:40 <nus> ozataman, the problem is GHCI (which is used by TH) cannot currently load object files which contain weak symbols, so it appears that cabal is somehow adding the superfluous dependency in.
12:49:25 <kmc> we should make a Haskell tutorial which uses classic techniques of surrealist cinema to dissociate the reader from everyday reality
12:49:45 <augur> ezyang: so whats a continuation with mutation
12:49:51 <shachaf> kmc: Sounds like you could get some great monad analogies in that one.
12:49:59 <monochrom> hehe
12:50:00 <nus> ozataman, what's in harrahs-omniture.cabal?
12:50:11 <kmc> i mean LYAH is weird and zany but mostly in that predictable Internet "zombie bacon robot pirate ninja" way
12:50:19 <kmc> too comfortable
12:50:29 <dilinger> i find the LYAH (paper) book to be more legible; the color illustrations and black backgrounded text in the html version is a bit hard to read
12:51:37 <luite> the pdf version doesn't have those black backgrounds
12:51:45 <luite> but it does have color illustrations!
12:52:35 <fxr> hmm comonads
12:52:51 <kmc> hmm
12:55:45 <nus> cohmm
13:05:36 <krawczyk> :type _|_
13:05:44 <krawczyk> @:type _|_
13:05:45 <lambdabot> parse error on input `|'
13:06:09 <augur> :t _|_
13:06:09 <lambdabot> parse error on input `|'
13:06:30 <augur> :t undefined
13:06:31 <lambdabot> forall a. a
13:07:27 <kmc> _|_ isn't Haskell syntax
13:07:34 <kmc> it's the ASCII substitute for ⊥
13:07:38 <kmc> pronounced "bottom"
13:07:52 <kmc> means any expression which does not evaluate successfully
13:07:58 <kmc> e.g. due to infinite loop or throwing an exception
13:07:59 <krawczyk> kmc: aahhh, thanks! I just could not remember...
13:08:04 <siracusa> > let ⊥ = undefined in ⊥
13:08:05 <lambdabot>   <no location info>: parse error on input `
13:08:24 <siracusa> > let (⊥) = undefined in (⊥)
13:08:25 <lambdabot>   *Exception: Prelude.undefined
13:08:38 <kmc> that way it looks more like a butt
13:08:43 <nus> krawczyk, what's the context?
13:09:05 <danharaj> > let unsafePerformButts = undefined in unsafePerformButts
13:09:06 <lambdabot>   *Exception: Prelude.undefined
13:09:22 <monochrom> ⊥ is theory
13:09:47 <kmc> i know _|_ confused me for a long time reading haskell-cafe
13:09:56 <Kaidelong> so here are 30 exercises I came up with for a friend: http://pastebin.com/YF780QMn
13:09:56 <kmc> I wonder if Haskell has more jargon / weird symbols that are hard to look up
13:09:58 <mauke> The paste YF780QMn has been copied to http://hpaste.org/48488
13:09:59 <kmc> compared to other languages
13:10:05 <Kaidelong> probably some errors in it
13:10:13 <krawczyk> <embarressed> I had seen it somewhere and could not remember what the heck this thing was...
13:10:53 <monochrom> yes, haskell has relatively more. but only because other languages have fewer than necessary
13:10:57 <Kaidelong> like the lack of a closing comment at the end
13:10:59 <nus> kmc, (.).(.) ?-)
13:11:31 <kmc> i don't mean things like "monad"; the opposite problem holds there
13:11:36 <kmc> too easy to google :)
13:11:39 <monochrom> for example ⊥ is just as important in scheme, f#, ... but they keep quiet about it
13:12:06 <kmc> > (length "⊥", length "NullPointerException")
13:12:07 <lambdabot>   (1,20)
13:12:11 <kmc> seems about the right ratio
13:13:31 <dolio> monochrom: Not if you ask Bob Harper.
13:14:10 <o1iver> Hey. I am just wondering about error handling in general. Let say I want to get some expression from user input, I then run it through a Lexer and then through a Parser and then do something based on the ouput. How do you handle errors in this case? Short of using Maybes everywhere? Is this where you kind of have to go monadic?
13:14:38 <o1iver> Something may go wrong in the lexer, the parser or the following computations...
13:16:05 <kmc> yeah, parsers and the like frequently return «Either ParseError t»
13:16:20 <kmc> or you can invent some custom error-handling type rather than using Either
13:16:32 <o1iver> ok I see...
13:17:09 <kmc> like Maybe but you can carry around information about the error
13:17:34 <kmc> you never "have to" go monadic
13:17:42 <kmc> "Monad" is just the name of a generic interface to lots of unrelated types
13:17:53 <kmc> you can mostly accomplish things through the type-specific interfaces instead
13:18:19 <kmc> but the monad interface is popular in practice because a) it's well-designed, and b) there's syntactic sugar for it
13:18:37 <o1iver> kmc: yes, but I guess that Monad is a solution to a common problem. So using something like Either/Maybe in too complicated a way, will lead you to, in the end, say "ok, smarter to create some monadic data type now"
13:18:48 <kmc> Either and Maybe are monads
13:18:51 <o1iver> kmc: yes
13:18:54 <o1iver> kmc: and yes
13:19:01 <kmc> so i don't understand the contrast
13:19:49 <o1iver> kmc: well you have to kindof restructure your program in a monadic way (compare to using cases/pattern matching for Maybe/Either)...
13:20:00 <kmc> that's not related to being a monad
13:20:04 <o1iver> kmc: I mean I am a beginner, so this is just my current understanding...
13:20:09 <kmc> that's related to whether or not the type exports its constructor
13:20:13 <kmc> constructors*
13:20:20 <kmc> you can pattern-match on Maybe and Either because they do
13:20:34 <kmc> if i made a error-handling type that doesn't export its constructors, you couldn't pattern-match on it
13:20:46 <kmc> you'd have to use whatever API i provide, which might or might not include a Monad instance
13:20:50 <kmc> but that's irrelevant
13:20:56 <o1iver> kmc: what I mean is that currently I am doing quite a bit of checking wether it's just or Nothing and return Just (f a) or Nothing, which I guess is what the monadic >>= is for right?
13:21:09 <kmc> that is what the Monad instance for Maybe does, yes
13:21:21 <kmc> @src Maybe (>>=)
13:21:21 <lambdabot> (Just x) >>= k      = k x
13:21:22 <lambdabot> Nothing  >>= _      = Nothing
13:21:48 <kmc> if you're doing «case x of Just y -> Just (f y); Nothing -> Nothing»
13:21:57 <kmc> that's equivalent to «fmap f x»
13:22:25 <danharaj> hmm... if free monads are essentially substituting trees into trees, what are free comonads?
13:22:32 <kmc> my point was that it's usually incorrect to say "i have this problem, perhaps monads will solve it"
13:22:43 <kmc> because "Monad" does not solve anything; it is an API, not an implementation
13:23:03 <byorgey> danharaj: ripping upside-down trees out of upside-down trees?
13:23:13 <danharaj> o1iver: You're already using the Maybe monad. You're just not using the API or the syntactic sugar.
13:23:15 <kmc> the more valid train of thought is "i have this problem, the Maybe type appears to solve it, and oh look, I can use the 'Monad' interface with that"
13:23:21 * byorgey has not actually thought about it ;)
13:23:44 <danharaj> byorgey: In general I think of monads as substitution. What's the categorical dual of substitution :p
13:24:01 <kmc> > text $ reverse "substitution"
13:24:02 <lambdabot>   noitutitsbus
13:24:09 <Eduard_Munteanu> Sounds latin :P
13:24:19 <danharaj> sounds like
13:24:24 <o1iver> kmc: yes, I understand this. But what I mean is that I think this is a normal beginner process. You don't "get" Monads so you try to do it differently, but in the end, anything that requires multiple ordered computations that may fail at some point it becomes "nicer" to use a monadic data type and the consequent syntatic sugar...
13:24:25 <danharaj> no two tits bus
13:24:31 <Eduard_Munteanu> Heh.
13:24:37 <sully> monochrom: the difference is that in a strict language, you can never actually "get your hands on" _|_
13:24:58 <ezyang> This seems to be a rather useless(?) monad: http://hpaste.org/48489
13:25:21 <sully> monochrom: in haskell you can hand bottom to a function (or, more insidiously, hand something like Succ(Succ(Succ(_|_))) to a function)
13:25:28 <o1iver> kmc: and yes, I am using Maybe, so I already am using a data type that is an instance of Monad (as danharaj says)
13:26:08 <gwern> > sum [2015,267,79,28,1151,1323,9,153,57,7,0,24,14,8,70,2,44,53,1,4,0,0,15,0,0,166,0,0]
13:26:09 <lambdabot>   5490
13:26:12 <gwern> wow
13:26:23 <sully> monochrom: whereas in a strict language, the function never gets the argument, so it isn't meaningful to talk about how it handles bottom
13:26:31 <gwern> the 2008 imdb says there were 5,490 movies made in 1917. that's pretty impressive
13:26:48 <Eduard_Munteanu> I think looking at cojoin in stuff like cellular automata is instructive for comonads.
13:27:26 <kmc> ezyang, can you implement liftIO?
13:27:29 <Eduard_Munteanu> Maybe that yields a "cotree-ish" interpretation.
13:29:29 <danharaj> ezyang: Is that really a monad? Does it satisfy all the laws?
13:30:59 <dolio> danharaj: No.
13:31:40 <kmc> liftIO x = R (x >>= newIORef)
13:32:42 <kmc> i think R, without exporting its data constructor, plus instance Monad, plus instance MonadIO, would be equivalent to IO
13:32:50 <kmc> because each IORef is single-use-only
13:34:12 <kmc> so the question is, what "primitives" would you add for additional fun things?
13:34:30 <ski> ezyang : `newtype R a = R { runR :: IORef a -> IO () }' might be more interesting ..
13:34:55 <monochrom> in SML, define "fun f0 n = f0 n" and "fun s f 0 = ()  | s f n = f (n-1)". the sequence f0, s f0, s (s f0), s (s (s f0))... each packages a dose of ⊥'s. you can hand them over to other functions, for example "map (s (s f0)) [0,1,2]". although you cannot pass around naked ⊥'s, there are tricks
13:35:39 <kmc> ski, is that even a Functor?
13:35:48 <kmc> reference cells are usually trouble
13:36:07 <Eduard_Munteanu> Well, you can only pass \bot to const-like stuff
13:36:15 <Eduard_Munteanu> i.e. functions ignoring that argument
13:36:21 <benmachine> it'd be contravariant, wouldn't it?
13:36:23 <ski> kmc : well, replace `IORef' with `CoYonedaOp IORef', if you prefer
13:36:32 <Eduard_Munteanu> (naked \bot I mean)
13:37:20 <ski> benmachine : `IORef' is invariant, but `CoYonedaOp f' is contravariant (and `CoYoneda f' is covariant)
13:37:20 * benmachine thought \bot was referring to λbot i.e. lambdabot
13:37:31 <monochrom> this is the problem with latex fanatics
13:37:54 <Eduard_Munteanu> monochrom: it's the same thing in agda-mode
13:38:01 <kmc> oh dear, naked robots and latex fetishes
13:38:12 <Eduard_Munteanu> It kinda makes sense to have similar abbreviations.
13:38:16 <monochrom> well then the agda-mode people are latex fanatics too
13:38:30 <Eduard_Munteanu> benmachine: ah, no :)
13:38:45 <monochrom> also you should "$\bot$" not just "\bot"
13:39:48 * monochrom has no sympathy for latex notation on irc. http://www.vex.net/~trebla/symbols/refute-anti-unicode.html
13:39:51 <nus> sully, re bottoms strictness i.e. reduction order is irrelevant, it's lazyness/eagerness which matters.
13:40:07 * hackagebot eurofxref 0.1.1 - Free foreign exchange/currency feed from the European Central Bank  http://hackage.haskell.org/package/eurofxref-0.1.1 (StephenBlackheath)
13:40:42 <nus> implement force/delay and you've got your share.
13:40:55 <Eduard_Munteanu> Yeah, I suppose I should try to use Unicode more often
13:41:00 <Eduard_Munteanu> on IRc.
13:41:06 <Eduard_Munteanu> s/c/C/
13:41:29 <sully> nus: lazyness/eagerness is basically a question of reduction order, though: do we reduce the argument before or after we beta-reduce
13:42:33 <sully> monochrom: it's true, you do wind up with that sort of case
13:42:50 <sully> to prove map correct you need to have a totality condition on the function
13:43:38 <nus> sully, we *evaluate* when we're forced, otherwise we slack.
13:44:17 <sully> yeah
13:44:25 <sully> I'm not sure we are saying anything different here?
13:46:33 <nus> sully, the reduction order doesn't matter, if it's not forced, i.e. requesting value/postponing evaluation allows you to "hit"/"miss" bottoms.
13:48:15 <nus> evaluate a n-thunk strictly, you might not hit the bottom for m < n thunks
13:53:16 <edwardk> preflex: xseen wli
13:53:16 <preflex>  wli was last seen on freenode/#haskell 4 hours, 5 minutes and 14 seconds ago, saying: Where did one-dimensional optimization go in hmatrix' GSL bits, I wonder?
13:53:30 <sully> so, I'm not entirely sure what we're arguing about
13:53:58 <sully> either you are assuming I don't understand lazy evaluation and trying to explain it to me, or we are quibbling over the definition of "evaluation order"
13:54:59 <nus> sully, <sully> monochrom: in haskell you can hand bottom to a function ...  whereas in a strict language, the function never gets the argument, so it isn't meaningful to talk about how it handles bottom
13:55:46 <dolio> In a strict language, all functions handle bottom the same way.
13:56:07 <edwardk> f _|_ = _|_
13:56:10 <sully> in a strict language, bottom is lifted over everything, when it happens
13:56:23 <sully> it's not really the /function/ handling bottom
13:56:24 <nus> there might happen a situation in a strict language when "the fuction" gets a "bottom"
13:56:31 <nus> the function*
13:57:06 <sully> like, when a function starts being evaluated, it has all of its arguments, and all of its arguments are values
13:57:20 <ski> nus : no
13:57:24 <sully> you can never have bottom in a variable, because variables name values
13:59:19 <dolio> Bottom comes from denotational semantics. There's no "starting to be evaluated" there.
13:59:29 <nus> sully, how do you pass a bottom to a function in a non-strict language?
13:59:51 <dolio> And the denotation of functions in strict languages are likely to be strict functions on the liftings of the domain and codomain to domains.
14:00:35 <dolio> Unless you use something more like Kleisli arrows in the lifting monad.
14:01:18 <sully> nus: 'f undefined' will do it in haskell
14:01:37 <nus> undefined isn't 'bottom' per se
14:02:02 <nus> sully, likewise you could pass a delayed exception in a strict language
14:02:37 <sully> yes, you can simulate laziness in a strict language
14:02:39 <nus> or a delayed non-termination
14:02:42 <sully> but if you want strictness, you can actually have it
14:03:25 <wli> I'm around, was in bathroom sorry.
14:03:26 <lambdabot> wli: You have 1 new message. '/msg lambdabot @messages' to read it.
14:03:49 <sully> dolio: ok, I wlil rephrase: when you beta reduce, the argument must be a value; it thus can't be bottom
14:03:52 <sully> *will
14:04:00 <nus> sully, as dolio mentioned _|_ has denotational, not operational semantics
14:04:03 <roconnor> I don't know how to build non-trivial immutable circular data structures in a strict langauge.
14:04:07 <roconnor> I don't think it is possible.
14:04:19 <sully> roconnor: you use mutable data structures
14:04:25 <sully> and backpatch
14:04:43 <sully> it isn't beautiful.
14:04:50 <roconnor> no
14:04:57 <roconnor> because the resulting structure isn't immutable
14:05:12 <sully> oh, yeah, I missed immutable
14:05:36 <benmachine> roconnor: could you make a mutable structure that worked and then "freeze" it, or does that not count?
14:05:56 <roconnor> I guess that might be acceptable
14:06:05 <kapper> Is there a nice way to patternmatch lists so that you get the tail? What i do is this : f n (x:xs:y) = y. But this gives me y as a list and the rest as elements of the list. What i woud like is to split like so, [1,2,3] -> x:xs = [1,2] y = 3 instead of x = 1, xs = 2, y = [3]
14:06:09 <sully> I mean, you can always do it by simulating laziness
14:06:25 <roconnor> I mean you can use modules to make it appear to be immutable too, but it is helpful, I think, if the compiler knows it is immutable.
14:06:38 <Eduard_Munteanu> kapper: not in a single step
14:06:42 <benmachine> kapper: you can't pattern-match the tail of a list, no
14:06:52 <benmachine> kapper: in the case of infinite lists you might not have a tail :P
14:06:57 <kmc> kapper, not really.  lists are built by consing onto the head, so pattern-matching the tail is always uglier / less efficient
14:07:11 <kmc> GHC's ViewPatterns extension would make the syntax nicer though
14:07:24 <kmc> > let f (reverse -> (x:y:xs)) = (x,y) in f "abcde"
14:07:25 <lambdabot>   ('e','d')
14:07:28 <benmachine> if you use a Data.Sequence instead of a list you can do it
14:07:35 <Eduard_Munteanu> However you can write something like    tail [x] = x   and fill the rest of the cases
14:07:49 <kmc> right, lists are not a good datastructure for random access, where here "random" means "anywhere other than the head" ;P
14:07:53 <sully> nus: I will admit that I am not entirely clear on the distinction; I am used to defining the behavior of languages by giving inference rules that define how they step; which is that?
14:08:01 <benmachine> we're all using the name "tail" quite poorly
14:08:05 <ski> roconnor : for trivial cases (i.e. all cycles are apparent, lexically), OCaml supports `let rec'
14:08:07 <roconnor> oh, lambdabot has view patterns
14:08:10 <benmachine> that's usually used to mean "everything except the head"
14:08:12 <Eduard_Munteanu> Yeah, indeed.
14:08:25 <roconnor> ski: yes.
14:09:13 <ski> roconnor : it might be possible to generalize tail-call-modulo-cons to work across user-defined functions
14:09:18 <sully> ok, what I am used to is apparently "structural operational semantics"
14:10:02 <ski> roconnor : you can do basically this in Prolog. if you don't want to allow uninstantiated variable aliasing, i think Mercury can do it in a few cases
14:10:03 <roconnor> What I really like is twanvl's KMP implementation in Haskell.
14:10:17 <mjrosenb> roconnor: KMP?
14:10:19 <kmc> can i see?
14:10:31 <ski> mjrosenb : Knuth-Morris-Pratt ?
14:10:53 <mjrosenb> while we are discussing things that we want, I want disjunctive patterns in haskell
14:10:57 <roconnor> http://twanvl.nl/blog/haskell/Knuth-Morris-Pratt-in-Haskell
14:11:10 <ski> mjrosenb : yeah, wanted that one a long time
14:11:37 <ski> mjrosenb : i also want SML's `local <decls> in <decls> end'
14:12:36 <ski> sully : yeah, that's a kind of operational semantics
14:14:00 <kapper> Ok. thanks. Im pretty new to Haskell. What is the equivalent datastructure to a Haskell list in say C?
14:14:07 <ski> roconnor : hm .. i wonder whether you could use recursive modules (presumably with functors) to create immutable cycles
14:14:23 <ski> kapper : a single-linked list, more or less
14:14:49 <kmc> kapper, you can't learn Haskell by analogy to other languages
14:14:55 <kmc> that said, yes, it's roughly a linked list
14:15:14 <kmc> the Haskell spec does not mandate how to implement it
14:15:27 <sully> kmc: well, unless the other language is ML or lisp, in which case you can actually get pretty far learning haskell by analogy :P
14:15:35 <kmc> sully, Lisp?
14:15:49 <kmc> you mean the dynamically typed, strictly evaluated language with pervasive metaprogramming?
14:15:51 <cdsmithus> kapper: Haskell's lists are singly linked lists... but the elements are functions that only compute the next bit when it's needed (but then remember it so they don't have to compute it again if it's used later)
14:15:57 <sully> well, lisp you'll only get a little bit of the way
14:16:02 <sully> you'll get the functional part
14:16:06 <cdsmithus> I meant the nodes, not the elements
14:16:11 <kmc> sure, but Python and Javascript are 'functional' too
14:16:28 <sully> yeah, but you don't learn to think like a functional programmer when you use them
14:16:40 <sully> and you do when you use lisp
14:16:41 <kmc> you might
14:16:48 <kmc> first-class functions are very idiomatic in Javascript
14:17:00 <kmc> for callbacks
14:17:01 <cdsmithus> You do when you use Scheme.  Common Lisp... depends on who you learn it from
14:17:10 <kmc> similarly, tons of Lisp code uses pervasive mutation
14:17:12 <sully> cdsmithus: that's true
14:17:14 <kmc> shrug
14:17:21 <sully> knowing some scheme accelerated my learning of SML
14:17:28 <sully> and knowing SML vastly accelerated my learning of haskell
14:17:34 <kapper> Ok. Cool. I do know that Haskell is quite different. I'd just like some intuition about how the list structure actually works. For now.
14:17:41 <ski> cdsmithus : except the elements are not functions ..
14:18:10 <kmc> sully, I'd agree that SML is a closer fit, you at least get the "static types don't have to suck" part
14:18:11 <Eduard_Munteanu> kapper: data List a = Nil | Cons a (List a)
14:18:24 <sully> ski: I mean, secretly they are
14:18:33 <sully> but it isn't clear that you need to tell that to a beginner
14:18:47 <osaunders> I really don’t get why you need a table to match substrings
14:18:51 <sully> (I mean, they don't have to be, fundamentally, but...)
14:18:53 <Eduard_Munteanu> kapper: it's just a datatype like that
14:18:54 <ski> sully : hehe, i'd agree that they are procedures, in a typical implementation
14:19:05 <sully> kmc: right
14:19:16 <cdsmithus> I did mean C functions... not math functions.  The questions was to transalte into C terms
14:19:24 <Eduard_Munteanu> kapper: so [1,2,3] is just like Cons 1 (Cons 2 (Cons 3 Nil))
14:19:30 <sully> kmc: you get "how to think like a functional programmer using polymorphism, type inference, and algebraic data types"
14:20:12 <sully> so when I got to haskell I skimmed that stuff to figure out the syntax and dove into typeclasses and monads and friends
14:20:30 <ski> sully : .. and get to use a quite powerful module system :)
14:20:51 <sully> right
14:21:05 <cdsmithus> sully: right, you definitely get a lot of the type stuff.  But you miss the ability to think about your program in completely denotational terms (whithout a lot of special casing anyway)
14:21:06 <Eduard_Munteanu> Sorry if you didn't get to datatypes yet and this makes no sense :)
14:21:57 * sully badly wants to be able to combine the power of SML's module system with the convenience of haskell's typeclasses
14:22:22 <sully> cdsmithus: sure, but you do get to think about your program in formal, well-defined terms
14:22:27 <Phyx-> my laptop just decided to invert all pixels
14:22:30 <sully> which is better than you get most of the time
14:23:02 <Eduard_Munteanu> sully: Agda has parametrized modules and something like typeclasses, plus some other goodness (or badness, it depends :D)
14:23:18 <sully> Eduard_Munteanu: agda is also terrifying
14:23:24 * sully needs to spend some more time with it
14:24:09 <wli> Eduard_Munteanu: Parametrized modules and typeclasses? I've got to use it now.
14:24:15 <thebilgerat> trying to install scion using cabal ghc, is version 7.  cabal install scion gives "There is no available version of ghc that satisfies >=6.10 && <6.12"
14:24:30 <Eduard_Munteanu> wli: not quite typeclasses
14:24:52 <Eduard_Munteanu> Not in Haskell's sense. They're restricted in comparison to those.
14:25:05 <thebilgerat> only solution found on google was to download the file direct and install - this fails too.  End goal is to get EclipseFP to work
14:25:29 <Eduard_Munteanu> But pretty much interchangeable in many cases.
14:25:49 <Eduard_Munteanu> e.g. Show
14:26:23 <sully> so, "derives" isn't really part of "typeclasses"
14:26:23 <wli> Eduard_Munteanu: Argh, if Agda can do it, why can't Haskell?
14:26:42 <Eduard_Munteanu> sully: yeah, unfortunately
14:26:47 <Eduard_Munteanu> That might be fixable though.
14:26:52 <sully> it's just an extra convenience
14:27:29 <Eduard_Munteanu> wli: Agda's typeclasses (actually they're called non-canonical implicits (or some other newer name, recently)) are a new addition to the language.
14:27:36 <Eduard_Munteanu> They're just another sort of implicit arguments.
14:27:42 <Eduard_Munteanu> They're available in the latest darcs, AFAIK not in any release.
14:28:09 <sully> ah
14:28:15 <Eduard_Munteanu> wli: wait what can Agda do and not Haskell?
14:28:26 <sully> lots of things!
14:28:30 <sully> prove program termination :P
14:28:38 <sully> hm, with my new laptop I'll actually be able to build agda and not go crazy
14:28:40 <wli> Eduard_Munteanu: Parametrized modules and typeclasses.
14:28:41 <Eduard_Munteanu> Yeah, but I'm unsure what he meant :)
14:28:52 <Eduard_Munteanu> Mmm... Haskell does typeclasses :)
14:28:53 <sully> not swap constantly
14:28:55 <osaunders> In reference to http://twanvl.nl/blog/haskell/Knuth-Morris-Pratt-in-Haskell I ask, why do I need a table when I can do this https://gist.github.com/1052344
14:29:00 <Eduard_Munteanu> Heh.
14:29:13 <sully> linking agda was taking 1 gb of memory
14:29:18 <sully> just linking it!
14:29:35 <Eduard_Munteanu> Well that just wasn't there when Haskell was designed I presume.
14:30:00 <Eduard_Munteanu> sully: it still takes a *lot* of memory to typecheck some things.
14:30:05 <kmc> osaunders, does your qSubStr have the same runtime as the KMP implementation
14:30:44 <osaunders> I don’t know
14:30:53 <osaunders> Would a table make it faster?
14:30:54 <sully> KMP is O(n+m)
14:31:07 <kmc> "The core idea of the algorithm is that we only want to process each character of both strings once"
14:31:11 <kapper> Eduard_Munteanu: It makes SOME sense. Still, learning Haskell being used to C is a challenge i think. But thanks.
14:31:32 <Eduard_Munteanu> kapper: don't worry, I came to Haskell straight from C too :)
14:31:40 <osaunders> kmc: I /think/ mine satisfies that
14:31:51 <kmc> osaunders, looks like you don't have that property, because the "otherwise" case for qSubStr takes (n:needle) and recursively calls with (n:needle)
14:31:57 <kmc> (you could use an @-pattern there, by the way)
14:32:03 <osaunders> Ah
14:32:08 <kmc> (to save a little allocation)
14:32:24 <kmc> what you wrote looks more like a straightforward substring search
14:32:32 <osaunders> Yeah, it is
14:32:35 <kmc> KMP is not the simplest substring algorithm
14:32:38 <sully> no, his takes linear time
14:32:40 <kmc> but it performs better (in theory at least)
14:32:42 <sully> but is subsequence
14:32:56 <sully> not substring
14:32:57 <osaunders> What would the performance of mine be?
14:33:05 <kmc> oh, right
14:33:12 <sully> yours is linear, but wrong
14:33:13 <mjrosenb> oh, so ghc won't create @ as an optimization?
14:33:20 <sully> or rather, it is a correct implementation of a different function
14:33:24 <sully> :P
14:33:35 <kmc> > let qSubStr [] _ = True; qSubStr _ [] = False; qSubStr (n:needle) (h:haystack) | n == h = qSubStr needle haystack | otherwise = qSubStr (n:needle) haystack in "ace" `qSubStr` "abcde"
14:33:36 <lambdabot>   True
14:33:36 <osaunders> mjrosenb: Good questions, I want to know that too
14:33:39 <kmc> me too
14:34:48 <osaunders> kmc: Damn
14:35:26 <osaunders> I knew I should have quickchecked it. I would have but I couldn’t remember the boilerplate I needed
14:35:38 <kmc> the KMP article has it :)
14:35:43 <sully> you could have also just written three tests or so :P
14:35:58 <kmc> this is a nice article
14:36:11 <dons> mrcarrot: it is a wiki page, you could fix it directly!
14:36:21 <kmc> not sure about this datatype being a product rather than a sum
14:36:29 * osaunders has been a bad programmer
14:36:29 <kmc> but the idea works well
14:37:23 <kmc> oh, it makes sense that way later
15:02:21 <fxr> gmm google+
15:06:14 <monochrom> @tell chrisdone chrisdone oh evil chrisdone, your haskell-json silently ignores my "import DoesNotExist" and reports "OK"
15:06:14 <lambdabot> Consider it noted.
15:23:31 <danharaj> How many machine instructions is `round' or `truncate' on x86?
15:23:45 <danharaj> I suppose that's ill posed.
15:23:52 <danharaj> round :: Double -> Int
15:25:26 <danharaj> (also on GHC 7)
15:30:47 <thoughtpolice> round is type-classed but it seems to resolve to GHC.Float inside base
15:31:00 <thoughtpolice> let's see what the asm says tho
15:31:24 <danharaj> I checked some GHC tickets from wayback when and it seems like there are rewrite rules that apply and turn it into a cmath call.
15:33:53 <thoughtpolice> hm, it seems to be calling into GHC.Float in order to pull out the round function, which i presume works over unboxed doubles or whatnot. you'd need to look at the ASM for the base library in that case, since the instructions won't exist inside your object file you produce
15:35:11 <danharaj> I suppose I can just check the base source to see what they do. I'm almost certain it's a primop.
15:35:13 <danharaj> thanks.
15:37:32 <Egbert5e9> i wonder what is the best data structure for this kind of thing
15:37:57 <Egbert5e9> i want to represent a playlist with metadata
15:39:00 <Egbert5e9> so a single item will be data VideoItem = VideoItem { file :: String, ... }
15:39:34 <Egbert5e9> how should it be for the whole list?
15:40:04 <Egbert5e9> newtype PlayList = PlayList { ...something }?
15:40:09 <parcs> [VideoItem]
15:40:26 <Egbert5e9> no newtype?
15:40:42 <Egbert5e9> just a simple list, okay
15:40:53 <vold_> I don't really see the point in a new type. you could do 'type Playlist = [VideoItem]'
15:41:04 <Peaker> If it's really big: you could have a bunch of Maps for the various properties: Map FileName VideoItem, Map Artist VideoItem, ...
15:41:12 <danharaj> Egbert5e9: Do you want random access?
15:41:30 <Peaker> Egbert5e9: what kind of access will you have?
15:41:33 <Egbert5e9> danharaj: what does it mean?
15:41:53 <Egbert5e9> Peaker: i'm sorry, i don't know what Map is
15:42:39 <Egbert5e9> Peaker: i just want to save it into a db and display it on a table
15:43:02 <Peaker> Egbert5e9: what db?
15:43:10 <blackh> Egbert5e9: Map is a dictionary held in memory implemented as a tree, so it's efficient to look things up, etc, based on a key.
15:44:09 <Egbert5e9> Peaker: to be honest, i've never touched db's before
15:44:18 <Egbert5e9> Peaker: i imagine it'll be sqlite
15:44:33 <Egbert5e9> blackh: ah
15:44:55 <Egbert5e9> blackh: where does it sit? i the module tree
15:45:14 <blackh> Egbert5e9: It's in the standard libraries in a module called Data.Map
15:45:33 <blackh> It's just for storing in memory, so it's not much use for random database access.
15:45:34 <Egbert5e9> ah
15:45:53 <Egbert5e9> sqlite will take care of it for me, right?
15:46:17 <Egbert5e9> oh, and.. what sqlite module should a total newbie learn?
15:47:42 <blackh> Egbert5e9: Yes, it should do the trick. There are lots of sqlite libraries on Hackage (http://hackage.haskell.org/). I can't tell you which is best, but I expect you'll find some are good and some are not.
15:54:40 * hackagebot aws 0.0.4 - Amazon Web Services (AWS) for Haskell  http://hackage.haskell.org/package/aws-0.0.4 (AristidBreitkreuz)
15:59:41 <Egbert5e9> so i want this playlist to fill up with metadata, but it won't happen quickly because i have to retrieve it off the internet
16:00:14 <mietek> How can I specify the number of tests generated by quichCheck?
16:00:19 <Egbert5e9> can you give me a general way of updating the playlist with metadata as new data is retrieved?
16:05:08 <o1iver> Hey. Is the function application (i think thats what its called) function ($) implemented in haskell? Can I see the source code for that?
16:06:06 <ski> @src ($)
16:06:06 <lambdabot> f $ x = f x
16:06:53 <o1iver> ski: ha okay. For some reason I couldnt see the source in GHC.Base. Thanks
16:07:13 <wli> edwardk: BTW the trick for quadratic constraints gets very very useful when there are situations where neighboring intervals can be considered fixed, e.g. online algorithms like I described in my writeup.
16:07:27 <ski> there's also an `infixr 0 $' associated with that
16:07:50 <mietek> quickCheckWith stdArgs {maxSuccess = 1000}
16:07:54 <mietek> Aha
16:17:33 <o1iver> ski: ok cheers
16:45:47 <danharaj> if I have an int that I know fits in 24 bits, am I guaranteed that if I convert it into a Float that there is no loss of precision?
16:47:50 <cdsmithus> Not guaranteed, but it's very probable.  The Haskell Report declares that Float having the IEEE range and porecision is "desirable"
16:47:57 <cdsmithus> but doesn't require it
16:48:47 <danharaj> how about on x86 with GHC?
16:49:03 <danharaj> I'll just test it
16:49:43 <cdsmithus> danharaj: Yes, should be fine
16:50:27 <danharaj> Maybe what I'm doing is slightly hackish.
16:50:55 <cdsmithus> Well, signed should be fine.  Unsigned, it would have to fit in 23 bits, I believe
16:52:38 <danharaj> I doing comp geometry without exact arithmetic, so my idea is to store geometry as integral grid points. I am bounding them to fit within 24-bits so that when I want to use them in intermediate calculations, I can convert them to Doubles and be guaranteed to have a minimum level of precision. I'm being careful that my algorithms only require 2*B bits of precision to operate correctly.
16:54:10 <danharaj> If I knew how -fexcess-precision behaved, it would be nice to have even more extra precision to work with.
16:55:08 <cdsmithus> Doubles, or Floats?  If you're using Double then you have even more precision available...
16:55:29 <cdsmithus> Double is more than 32 bits; I don't recall exactly how much
16:55:40 <danharaj> Double is 53 bits for the significand on x86
16:56:09 <danharaj> So by storing my points as 24-bit integers, I have 29 bits of extra precision.
16:57:26 <cdsmithus> So that should be true in GHC on all supported platforms too, assuming that's the IEEE standard (which I'm sure it is)
16:57:32 <danharaj> It is.
16:57:58 <cdsmithus> Again, the spec only says it's "desirable", but in practice you can assume it's the case with GHC
16:58:04 <danharaj> excess precision is sketchy.
16:58:52 <danharaj> on x86, it should be the 80-bit format, which has 64 bits for the significand.
16:59:32 <cdsmithus> Yes, but only for intermediate results stored in FPU registers, right?
16:59:47 <cdsmithus> I'm a bit unsure on those details
17:00:27 <danharaj> yeah, so it wouldn't be so useful.
17:00:48 <danharaj> too bad there's no long double in GHC that stores the whole 80-bit value.
17:12:06 <othiym23> happy Tau Day, everybody: http://tauday.com/
17:13:20 <byorgey> happy tau day, othiym23 =)
17:14:31 <kmc> > 2 * pi
17:14:31 <lambdabot>   6.283185307179586
17:14:41 <kmc> @let τ = 2*pi
17:14:42 <lambdabot>  <local>:4:0:
17:14:42 <lambdabot>      Multiple declarations of `L.<stderr>: hPutChar: invalid ar...
17:14:45 <kmc> > τ
17:14:47 <lambdabot>   6.283185307179586
17:14:49 <kmc> nice, someone beat me to it
17:16:45 <parcs> *ahem*
17:16:56 <hpc> > π
17:16:57 <lambdabot>   Not in scope: `
17:17:00 <hpc> :(
17:17:03 <othiym23> BURRRN
17:17:04 <hpc> @let π = pi
17:17:04 <lambdabot>  Defined.
17:26:57 <byorgey> > τ
17:26:59 <lambdabot>   6.283185307179586
17:27:06 <byorgey> > π
17:27:07 <lambdabot>   "\964/2"
17:27:26 <byorgey> heh
17:27:32 <Luke> what data structure should I use for what would essentially be a map sequenced/sorted by it's keys?
17:27:45 <dankna> er, Data.Map, right?
17:27:57 <Luke> how would I specify how the keys are sorted/traversed?
17:27:58 <dankna> it is already sequenced by its keys, that's why it requires Ord for them
17:28:04 <Luke> ah
17:28:12 <dankna> oh, you would need a newtype with a custom Ord instance if you wanted to override an existing Ord instance
17:28:15 <Luke> I'll look at instance Map Ord
17:28:26 <Luke> would a "type" work?
17:28:33 <byorgey> wait, you want to sort a list of maps?
17:28:36 <dankna> no, because that makes a synonym
17:29:02 <dankna> byorgey: that wasn't how I read what he wants - he wants a map which also has an ordering attached.  which is just Data.Map from containers.
17:29:05 <Luke> byorgey: no more like a map where it's keys can be traversed in a certain order. sounds like that's already the case
17:29:14 <byorgey> Luke: ok, yes, right.
17:30:12 <Luke> sorry I wasn't too clear on what I'm looking for (even to myself)
17:30:30 <byorgey> Luke: for example, Data.Map.assocs returns all the key/value pairs in a map sorted in ascending order by key
17:30:42 <Luke> hmm
17:30:48 * Luke looks
17:31:28 <byorgey> and I would assume the Traversable/Foldable instances for Map let you traverse the map in ascending order by key
17:31:33 <byorgey> although the documentation does not say that
17:32:29 <Luke> yeah i'm playing with that now
17:32:37 <Luke> looks like Traversable is for traversing in a monad or something?
17:33:19 <byorgey> in any Applicative, actually
17:33:34 <byorgey> but that works for monads too
17:35:32 <Luke> oh Traversable is mappable and foldable
17:38:45 <byorgey> Luke: well, it's a bit more than that, the important point is that it happens in an Applicative context, so you get to observe the order of the traversal and even have the processing of previous elements affect the processing of later ones
17:41:00 <edwardk> preflex: xseen ski
17:41:01 <preflex>  ski was last seen on freenode/#haskell 1 hour, 33 minutes and 36 seconds ago, saying: there's also an `infixr 0 $' associated with that
17:41:30 * ski tiredly nods in edwardk's general direction
17:42:00 <edwardk> i have a 2 line programming challenge. Can somebody figure out the implementation for listen in https://github.com/ekmett/kan-extensions/blob/master/Control/Monad/Co.hs ?
17:42:33 <edwardk> i transformed Co into a comonad-to-monad-transformer-transformer
17:42:44 <edwardk> so given any comonad you can get a monad-transformer
17:42:57 <edwardk> i'm about to blog the details, but wanted the full set of combinators
17:43:33 <edwardk> it just got one step too meta for me to hold in my brain without food
17:44:29 <byorgey> well that's saying something!
17:44:37 <edwardk> =)
17:45:08 <edwardk> i also need to figure out lifting for Monaderror
17:45:30 <edwardk> it is basically the ContT monad transformer if that helps
17:45:40 <edwardk> just with an extra w (…) mucking up the works
17:45:47 <byorgey> edwardk: maybe at hac phi we can sit down and hash out an outline for a document explaining your semigroupoid/category/etc. packages
17:45:55 <edwardk> sounds good
17:46:15 <edwardk> i'm rushing around trying to get the new hierarchy ironed out before then
17:47:04 <edwardk> the fact that i can make a monad transformer out of any comonad should indicate to folks there are no magical comonads. in fact they are less powerful than monads in many ways
17:47:22 <kmc> but are they.... more co-powerful?
17:47:28 <edwardk> =P
17:47:30 * ski . o O ( `listen :: (Comonad w,MonadWriter e m,MonadWriter e (CoT w m)) => CoT w m a -> CoT w m (a, e)' )
17:47:32 <hpc> ^.^
17:47:53 <edwardk> ski: yeah
17:47:56 <hpc> kmc: they are co-more powerful
17:48:08 * ski is trying to see if this `listen' will write itself
17:48:13 <kmc> they are more lufrewop
17:48:31 * ski is too tired to actually understand what this will do, though
17:48:39 <edwardk> ski: the key will be exploiting the ability to choose the r for which you runCoT the underlying m.
17:48:42 <hpc> ski: listen = const undefined -- wrote itself
17:49:00 <edwardk> hpc: =P
17:49:15 <othiym23> :t const
17:49:16 <lambdabot> forall a b. a -> b -> a
17:49:25 <hpc> const x _ = x
17:49:32 <edwardk> i was able to get pass to work on the line above, so there should be enough room to plumb it through
17:49:36 <othiym23> aha
17:49:53 <othiym23> so const = K?
17:49:58 <hpc> indeed
17:50:05 <edwardk> othiym23: yep
17:50:11 <hpc> id=I, const=K, i think S=(<*>)
17:50:15 <hpc> and Y=fix
17:50:23 <edwardk> hpc: s is flipped a bit
17:50:41 <othiym23> is Haskell's type system weird enough to allow Y to be expressed in terms of SKI?
17:50:42 <kmc> Y=fix extensionally
17:50:57 <kmc> the Y combinator is a particular lambda term
17:50:59 <ski> `S' is `ap', yes
17:51:00 <kmc> it is not well-typed in Haskell
17:51:03 <edwardk> othiym23: no, we have an occurs check that bites you
17:51:07 <hpc> othiym23: haskell is typed, period
17:51:20 <kmc> but you can write other extensionally-equivalent things
17:51:24 <hpc> the SKI Y combinator can only be expressed in untyped calculi
17:51:24 <ddarius> hpc: Scheme is typed, period
17:51:27 <othiym23> I've been trying to figure it out in Scala and I haven't proven that it's *not* possible yet, but the type gymnastics are pretty heinous and I've cornered myself a couple times
17:51:31 <ddarius> hpc: You are wrong.
17:51:36 <ski> othiym23 : you can more or less do it, using `newtype Santa a = S (Santa a -> a)'
17:51:40 <hpc> eh?
17:51:53 <kmc> there's a good reason for that name too :)
17:52:00 <edwardk> othiym23: you _can_ typecheck it in scala through some dubious means
17:52:21 <edwardk> othiym23: but that is just because scala's type system lets you do all sorts of things the designers never intended
17:52:22 <ski> hpc : also, it's easy to do in `ocaml -rectypes'
17:52:24 <othiym23> edwardk: good to know. has anyone done it in a public place?
17:52:48 <edwardk> othiym23: i worked it out with runar bjarnason at some point. he blogged some subset of it
17:52:48 <othiym23> edwardk: that's sort of the point of trying to abuse it into allowing me to express Y
17:53:16 <edwardk> othiym23: well, when you go to actually _use_ it you'll have even odds of the compiler bottoming out ;)
17:53:33 <othiym23> edwardk: I took dobblego's encoding of SKI in Java and translated it into Scala simply enough, and got about 2/3 of the way through the derivation before my brain went crosseyed
17:53:34 <edwardk> we had an entire untyped lambda calculus in the type system
17:53:44 <ddarius> edwardk: Isn't that just a corollary from going to actually use Scala?
17:53:52 <edwardk> ddarius: yes =)
17:54:00 <othiym23> I've seen doing SKI / Y in the type system (I think on Rúnar's blog), but not directly in Scala itself
17:54:23 <_o1iver> Can I pattern match in a one line lambda function?
17:54:30 <ddarius> _o1iver: Yes.
17:54:32 <edwardk> term level with subtyping you can always lift up via object, so its kinda boring
17:54:35 <ddarius> But only one alternative.
17:54:45 <_o1iver> ddarius: how?
17:55:00 <ddarius> > (\(Just 3) -> 4) Nothing
17:55:00 <lambdabot>   *Exception: <interactive>:3:1-14: Non-exhaustive patterns in lambda
17:55:23 <_o1iver> ddarius: multiple patterns?
17:55:30 <edwardk> ski: any luck?
17:55:42 <_o1iver> ddarius: I guess one pattern would always throw the Non-exhaustive error right?
17:57:04 <ski> edwardk : still cranking the wheel ..
17:57:05 * hackagebot csv-enumerator 0.9.0 - A flexible, fast, enumerator-based CSV parser library for Haskell.  http://hackage.haskell.org/package/csv-enumerator-0.9.0 (OzgunAtaman)
17:57:22 <ddarius> Just have Djinn do it for you.
17:57:45 <edwardk> ddarius: you need to figure out a guess at what rank 2 type you need to instantiate some type to
17:57:51 <edwardk> djinn falls short in this case
17:57:55 <wli> edwardk: Parametrically continuous space curves like you'd use for ODE's still have the quadratic constraint trick that works, which in certain cases where, say, the first n knots are predetermined and the (n+1)st is to have a rational set up for its interval results in linear continuity constraint equations because all the quadratic terms are cross products of one sub-intervals variables with another's.
17:57:59 <ddarius> Make a better Djinn.
17:58:23 <othiym23> edwardk: I'd ask you to elaborate on the subtyping / lifting bit, but I'm afraid I wouldn't be able to follow your explanation ;)
17:58:37 <edwardk> wli: i'm going to need to rewind to get context =)
17:58:43 <hpc> othiym23: don't worry, nobody follows his explanations
17:58:48 <hpc> except perhaps the great SPJ :P
17:59:03 <edwardk> SPJ doesn't do comonads ;)
17:59:09 <edwardk> wadler does though
17:59:10 <othiym23> I find edwardk's blog a little easier to follow a lot of the time than sigfpe's
17:59:26 <edwardk> That is one of the nicest compliments I've ever received ;)
17:59:41 * ddarius finds sigfpe's blog quite a bit more interesting than edwardk's.
17:59:49 <kmc> snap
17:59:56 <edwardk> hah
17:59:57 <othiym23> daaag
18:00:09 <othiym23> it's a lot more random, for sure
18:00:19 <edwardk> sok, ddarius has heard most of my rants in person
18:00:35 <ddarius> edwardk: I'm still waiting for some substructural logic.
18:00:40 <edwardk> that and it updates a lot more regularly than i do ;)
18:00:46 <othiym23> his stuff on comonads and game logic and differentiation of types pretty much are the bees' knees
18:00:47 <edwardk> ddarius: hah i KNEW you were going to say that
18:01:37 <ddarius> My room smells like a tire.
18:01:50 <kmc> ddarius, did you leave the tire stove on?
18:02:30 <o1iver> so any ideas about this lambda pattern matching? Or should I just define it seperately?
18:03:36 <o1iver> wikibooks says its possible, but not how :-p
18:04:13 <hpc> > (\Just x -> x) (Just 5)
18:04:13 <aavogt> > (\ m @ ~(Just a) -> if isJust m then a else 4 ) Nothing
18:04:14 <lambdabot>   Constructor `Data.Maybe.Just' should have 1 argument, but has been given 0
18:04:14 <lambdabot>   4
18:04:41 <hpc> > (\x -> case x of (Just y) -> y; Nothing -> 6) Nothing
18:04:42 <lambdabot>   6
18:05:16 <aavogt> now you've overdone the parentheses :p
18:05:24 <kmc> o1iver, \x -> case x of ...
18:05:33 <kmc> unfortunately there's no sugar for that, though it has been proposed
18:05:36 <o1iver> hpc: I see how you could do it with case, but from what I read it seems like the "better" solution is to use pattern matching for checking data constructors
18:05:42 <o1iver> kmc: ok
18:05:48 <o1iver> thanks again guys!
18:05:49 <kmc> o1iver, 'case' is pattern matching
18:05:54 <kmc> you can also use local "let" instead of lambda
18:06:24 <kmc> > map (let f Nothing = 3; f (Just x) = x in f) [Nothing, Just 4]
18:06:24 <lambdabot>   [3,4]
18:06:36 <kmc> in this case i would lift the "let" out and do "... in map f ..."
18:06:41 <o1iver> ok true, well I honestly don't know how to describe what I meant then ;-p
18:06:44 <kmc> but in other cases "let f ... in f" could be useful
18:07:10 <o1iver> yes, that "looks" nicer than the case
18:07:13 <o1iver> thanks
18:07:43 <kmc> usually there is somewhere nearby to attach a "where" or "let" that looks natural
18:07:58 <ddarius> > map (let in sin) [0..]
18:07:59 <lambdabot>   [0.0,0.8414709848078965,0.9092974268256817,0.1411200080598672,-0.7568024953...
18:08:23 <kmc> ha
18:09:19 <o1iver> ddarius: what is going on there? "let in "?
18:09:29 <kmc> empty let
18:09:31 <ski> hum, now i got down to `(e -> m r) -> (m (e -> r))' ..
18:09:32 <kmc> > let { } in 3
18:09:33 <lambdabot>   3
18:11:37 <hanDerPeder> how can I do hiding with a function like $=, hiding ($=) doesnt seem to work
18:12:03 <kmc> (($=))
18:12:08 <kmc> hiding (foo, ($=), bar)
18:12:09 <ski> > (\(Just 2 -> 3)) (Just 4)  -- hpc, like this
18:12:09 <lambdabot>   <no location info>: parse error on input `)'
18:12:19 <kmc> as in other contexts, the name of an infix operator used by itself is surrounded in parentheses
18:12:26 <ski> er, maybe
18:12:32 <ski> > (\(Just 2) -> 3) (Just 4)
18:12:33 <lambdabot>   *Exception: <interactive>:3:1-14: Non-exhaustive patterns in lambda
18:12:42 <aavogt> other contexts like declaring infix
18:12:49 <kmc> yeah, not there
18:12:55 <kmc> kind of should be imo
18:13:09 <hanDerPeder> kmc: thanks
18:13:22 <ski> edwardk : my logic programming engine got stuck on `(e -> m r) -> (m (e -> r))'
18:16:11 <hpc> ski: assuming Monad m, that's not a possible function
18:16:24 <edwardk> hpc: yeah you don't necessarily have to go that way though
18:16:24 <hpc> the (e -> r) value doesn't depend on the value of e
18:16:33 <ski> hpc : hence why i got stuck ..
18:18:08 * hackagebot kan-extensions 1.9.0 - Kan extensions, the Yoneda lemma, and (co)density (co)monads  http://hackage.haskell.org/package/kan-extensions-1.9.0 (EdwardKmett)
18:19:14 <ski> edwardk : btw, if you have `CoYoneda', do you also have `newtype Foo f a = forall b. MkFoo (a -> b) (f b)' ?
18:19:37 <edwardk> i have a data version of that one
18:19:40 <ski> (i'm not sure what to call that .. maybe `CoYonedaOp' or something ?)
18:19:48 <edwardk> oh
18:19:50 <edwardk> wait
18:19:51 <dmwit> edwardk: Think I can convince you to give a talk at Hac Phi on the computational meaning of the Yoneda lemma...?
18:19:52 <ski> heh, yeah s/newtype/data/, ues
18:19:54 <edwardk> no
18:20:04 <edwardk> dmwit: hah, perhaps
18:20:06 <edwardk> brb food
18:21:01 <ski> edwardk : just as `CoYoneda' (as well as `Yoneda', but in another way) can be made to improve something into a covariant functor, this `Foo' improves things into contravariant functors
18:22:15 <ski> e.g. `type IOReadRef = CoYoneda IORef' and `type IOWriteRef = CoYonedaOp IORef'
18:22:17 <edwardk> i seem to recall starting to add it then deciding it was silly ;)
18:23:03 <edwardk> partially for want of a good name, good set of applications and for a good place to put it
18:23:20 <ski> ok
18:23:23 <edwardk> Data.Functor.Yoneda.Contravariant.Contravariant gets long ;)
18:23:36 <Saizan> edwardk: i guess using m's >>= is cheating? listen m = CoT $ \ k -> listen (runCoT m (fmap (\ _ -> return) k)) >>= extract k
18:23:59 <edwardk> saizan: no it isn't use whatever you need ;)
18:24:26 <ski> Saizan : my knee-jerk-reaction is that `_' is wrong
18:24:55 <Saizan> ski: i'm discarding it there but using it outside
18:25:33 <augur> edwardk!
18:25:58 <Saizan> it's a bit in the spirit of listen m = Codensity $ \k -> lowerCodensity m >>= k
18:26:06 <augur> oh god stop with the codensity
18:26:10 <augur> it doesnt make sense D:
18:26:14 <edwardk> hah
18:26:15 <Saizan> but i needed a w shell here, so i reused the one of k
18:26:41 <edwardk> the worry is that we're shedding and readding the shell instead of preserving it
18:26:43 <Saizan> err, listen m = Codensity $ \k -> listen (lowerCodensity m) >>= k
18:26:47 <edwardk> can we extend the action somehow?
18:27:15 <ski> (edwardk : heh, even you say "preserve", when you're not thinking about it ! ;)
18:27:26 <edwardk> ski: =P
18:28:29 <edwardk> http://www.reddit.com/r/haskell/comments/ibvwe/monad_transformers_from_comonads/
18:28:45 <Saizan> the problem is that you get one of the arguments for the callback only from outside of m
18:29:25 * ski tried using `(=>>)', but got stuck otherwhere ..
18:29:28 <edwardk> *nods*
18:29:42 <edwardk> glad to see it isn't an obvious solution ;)
18:30:03 <edwardk> i still need catchError and callCC =)
18:30:19 <ski> it might be possible to do with some clever instantiation of the polymorphic `r'
18:30:33 <Saizan> btw, i'm so spoiled by agda-mode i postulated a bunch of things in an agda file just to get the interactiveness
18:30:38 <ski> i tried first instantiating it to `r', then to `e -> r', but neither appeared to work
18:31:01 <edwardk> yeah, with pass i was able to use (r',e)
18:33:01 <edwardk> on an unrelated note the same kind of trick can be used to insert a comonad in the middle of a left kan extension. but its boring =(
18:33:25 <ski> same kind of trick as .. ?
18:33:33 <edwardk> you get exists r. (w (r -> a), r)   — which is ~ w a
18:33:45 <edwardk> how i permuted the right kan extension to get Co.
18:34:48 <ddarius> What's wrong with "preserve"?
18:34:50 <edwardk> Given w = f . g, f -| g, then that type ~ Density f ~ Lan f f a ~ f . g ~ w
18:35:04 <edwardk> ddarius: nothing. just don't want to go back through and rebikeshed everything again
18:35:30 <Egbert5e9> is it reasonable to read from a database, do something to the data, then write back to the database immediately for every operation or should i keep stuff in memory?
18:35:38 <ski> edwardk just prefers sticking to bad terminology ;)
18:36:22 <edwardk> i left enough other things float that it is a good idea to hold a few things constant so folks have SOME idea what i'm rambling about ;)
18:36:32 <edwardk> er let
18:36:39 <ddarius> Egbert5e9: It depends on context.
18:36:47 <Egbert5e9> figured it is
18:37:11 * ski . o O ( `lwt <decls> in <expr>' )
18:37:43 <augur> ski: you and your thought bubbles
18:38:24 <edwardk> ski: anyways, that and the fact that there are no dual contravariant adjunctions on hask that are at all interesting conspire to keep me from being able to do any meaningful transformation from a monad into a comonad.
18:38:54 <edwardk> i do have _some_ hope that there might be a way to transform a bind-transformer into a comonad, since that seems sufficient to rule out all the bad monads
18:39:14 <edwardk> but i'm somewhat dubious
18:39:20 * ski didn't get where `a' came from ..
18:41:56 * ski is too tired to think clearly, commencing shut-down
18:42:00 <ddarius> The same place x comes from in f = f(x)
18:42:08 <edwardk> g'night. ski
18:42:13 <edwardk> thanks
18:42:42 * ddarius always overrode shutdowns in Mech Warrior 2.
18:43:12 <edwardk> ddarius: just run triple-strength myomer and hover around 9 heat. you can lop heads off easy.
18:58:05 <avartanian> Ain't it glorious.
18:58:34 <ivanm> what is?
18:58:45 <edwardk> yes
18:58:50 <acowley> very
19:01:09 <ivanm> I'm currently creating (Int,Int) values by using something like: foo w b = do (w'',b'') <- [(w',b') | w' <- [1..w], b' <- [1..b]]; rst <- foo (w-w'') (b-b'')
19:01:24 <ivanm> and "return $ (w'',b'') : rst" on the end
19:02:27 <ivanm> how can I create that list such that it's in decreasing order? AFAICT I need to do something smart for the b' <- [1..b] case depending if w' == w or not
19:04:28 <avartanian> Instead of [1..b] do an uncurry of b over (-1)?
19:04:37 <acowley> You want a lexicographically decreasing list of the cartesian product of the nats bounded by the arguments?
19:04:53 <avartanian> Sorry: unfold, not uncurry.
19:05:48 <ivanm> acowley: if I understand what you're saying, then yes ;)
19:05:59 <ivanm> avartanian: why -1 ?
19:06:37 <avartanian> Subtract 1 from b until you reach 1, then terminate?
19:07:23 <ivanm> acowley: more specifically, I'm wanting to create lists of specified length such that (sum . map fst $ lst) <= w and (sum . map snd $ lst) <= b for some provided w,b bounds
19:07:28 <avartanian> ivanm: Nevermind. That's a pretty dumb idea of mine.
19:08:54 <acowley> Something like this? Controlling Ergodic Bodies Using Linear LTL
19:08:55 <acowley> err
19:08:59 <acowley> foo x y = liftM2 (,) [x,x-1..1] [y,y-1..1]
19:10:00 <ivanm> @type foo x y = liftM2 (,) [x,x-1..1] [y,y-1..1]
19:10:01 <lambdabot> parse error on input `='
19:10:06 <ivanm> @type let foo x y = liftM2 (,) [x,x-1..1] [y,y-1..1] in foo
19:10:07 <lambdabot> forall a1 a2. (Enum a2, Num a2, Enum a1, Num a1) => a1 -> a2 -> [(a1, a2)]
19:10:21 <ivanm> > let foo x y = liftM2 (,) [x,x-1..1] [y,y-1..1] in foo 6 4
19:10:21 <lambdabot>   [(6,4),(6,3),(6,2),(6,1),(5,4),(5,3),(5,2),(5,1),(4,4),(4,3),(4,2),(4,1),(3...
19:10:59 <kmc> linear linear temporal logic?
19:11:18 <ivanm> acowley: hmmm.... doesn't seem possible to enforce the sum constraints
19:11:21 <acowley> I know... I'm glad it's no longer on my clip board!
19:11:33 <ivanm> oh, and I should have mentioned that repeats are allowed :s
19:11:42 <acowley> ivanm: sorry, I didn't notice that later message you wrote
19:12:05 <acowley> kmc: I can only assume it was linear before being linear was cool
19:12:22 <ivanm> I suppose I could use something like you suggested, filter out those pairs that are unsuitable for what I need (I have external constraints on which pairs are allowed) and then attempt to create those partitions that suit my criteria...
19:19:21 <ivanm> acowley: any suggestions then? AFAICT I'd need to pass around a "maximum allowable value" to be used for the case w' == w
19:27:35 <acowley> ivanm: how about this
19:27:37 <acowley> ivan w b = (,) <$> [w',w'-1..1] <*> [b',b'-1..1]
19:27:37 <acowley>   where w' = s w
19:27:38 <acowley>         b' = s b
19:27:40 <acowley>         s x = (round (sqrt $ 1 + 8 * fromIntegral x) - 1) `div` 2
19:27:41 <acowley>  
19:28:15 <ivanm> what's the s function for? :/
19:28:21 <ivanm> oh, the other predicate?
19:28:27 <acowley> well, I'm not sure it's quite what you want
19:28:47 <acowley> but this one has the property that sum (nub . map fst $ lst) <= w
19:28:58 <acowley> and likewise for b
19:29:06 <ivanm> where does that come in?
19:29:17 <ivanm> and I don't want nub to be in there...
19:29:22 <acowley> I think I called it s because it's the solution to a quadratic equation
19:29:26 <ivanm> (in the constraints)
19:29:47 <acowley> yeah, the problem there is that you're introducing a dependency between the constraints
19:30:15 <acowley> some more thought could get it to come out right
19:30:16 <ivanm> so there's no real nice way of doing this... yippee to passing around more arguments! :s
19:30:27 <acowley> no, I think what I just pasted is close
19:30:55 <acowley> the next step is that rather than computing "s w" and "s b" you'd pick bounding one
19:31:21 <acowley> I'm not sure exactly how that would work
19:32:22 <ivanm> > let  s x = (round (sqrt $ 1 + 8 * fromIntegral x) - 1) `div` 2; enumDown x = enumFromThenTo x (x-1) 1; foo w b = (,) <$> enumDown (s w) <*> enumDown (s b) in foo 6 4
19:32:22 <lambdabot>   [(3,2),(3,1),(2,2),(2,1),(1,2),(1,1)]
19:32:53 <ivanm> acowley: yeah, either I didn't explain what I need/want properly or you didn't understand what I said :p
19:33:43 <acowley> It's my subconscious inventing puzzles to solve to avoid my own work
19:33:53 <ivanm> heh
19:34:00 <acowley> note that the sum of unique fst coordinates sums to 6 and the sum of snd coordinates sums to less than 4!
19:34:10 <ivanm> heh
19:43:21 <mjrosenb> :t ap
19:43:22 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
19:44:38 <kmc> > even `filter` [1..10]
19:44:39 <lambdabot>   [2,4,6,8,10]
19:44:51 <kmc> > succ `map` [1,5,8]
19:44:52 <lambdabot>   [2,6,9]
19:45:44 <mjrosenb> @src ap
19:45:45 <lambdabot> ap = liftM2 id
19:45:53 <mjrosenb> @src liftM2
19:45:53 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
19:46:12 <mjrosenb> "great"
19:50:28 * hackagebot local-address 0.0.1 - Functions to get local interface address  http://hackage.haskell.org/package/local-address-0.0.1 (KeiHibino)
20:17:21 <shash> shabby
20:27:38 <kmc> so if i redefined List's (>>=) to be spine-strict on its left arg
20:27:48 <kmc> would that essential give breadth-first search instead of depth-first?
20:27:52 <kmc> essentially*
20:28:49 <c_wraith> not usefully, I think.
20:28:59 <c_wraith> I mean, it would make evaluation order breadth-first
20:29:15 <c_wraith> but results would still be returned as from a depth-first traversal
20:29:20 <c_wraith> which doesn't really sound like an improvement
20:29:28 <kmc> guess so
20:29:45 <kmc> can you code a BFS MonadPlus?
20:31:04 <ddarius> Yes.
20:31:36 <ddarius> Heck, except that it doesn't satisfy the monad laws, you can just have a binary tree be the MonadPlus and traverse it however you like.
20:31:58 <kmc> *nod*
20:32:01 <ddarius> (MonadPlus laws)
20:45:37 <edwardk> hrmm i never did add a monadplus for http://hackage.haskell.org/packages/archive/graphs/0.3.2/doc/html/Data-Graph-Algorithm-BreadthFirstSearch.html#t:Bfs ;) but i'm betting that isn't what you meant
20:46:12 <d7> Hum
20:46:13 <edwardk> ddarius: besides, no one can agree on the monadplus laws ;)
20:46:14 <d7> "  [  -2ms] Total compile time"
20:46:26 <d7> Seems like I get negative timings a lot
20:46:31 <d7> on osx with haskell
20:46:46 <ion> OSX is that fast.
20:46:46 <edwardk> ddarius: great. patent your time travel device!
20:47:13 <edwardk> er d7
20:47:27 <d7> ion: ha.
20:47:44 <Martty> thats not a minus
20:47:54 <Martty> its an optical illusion
20:47:55 <d7> It's a speed line.
20:48:27 <Martty> its the eleventh digit
20:55:01 <kmc> haha
20:57:41 <ddarius> edwardk: They can agree that they should form a monoid.
21:00:16 <ion> Time travel devices should form a monoid?
21:01:09 <edwardk> ddarius: progress! =)
21:08:26 <wli> edwardk: Up for Faà di Bruno affairs for geometric continuity?
21:08:37 <edwardk> about to fall over actually
21:08:56 <wli> edwardk: No sweat.
21:13:12 <edwardk> okay, i'll bite
21:13:33 <edwardk> faa di bruno gives a generalized chain rule. geometric continuity i'm pretty comfortable with
21:17:50 <wli> edwardk: If you've seen that before then my by-hand computations aren't going to be too enlightening.
21:18:40 <wli> edwardk: http://proxima.lp0.eu/~wli/spline.pdf for space curves and (much less content) http://proxima.lp0.eu/~wli/surface.pdf
21:19:26 <wli> edwardk: The spline one I'm in the midst of figuring out the degree of the individual constraints.
21:21:15 <ivanm> @type flip compare
21:21:16 <lambdabot> forall a. (Ord a) => a -> a -> Ordering
21:21:24 <edwardk> that being the bit where you said 'the expressions are preposterously enormous'?
21:22:05 <wli> edwardk: That one goes about clearing denominators. In any event, the phenomenon that's notable is that some of the shape parameters can be eliminated, and the ones that can't are determined by the lower order continuity's constraints which determine them in odd ways.
21:22:15 <wli> edwardk: It says that somewhere in there, yeah.
21:23:26 <wli> edwardk: So (surface.pdf) the G^2 constraints depend on shape parameters from the G^1 constraints, which don't have a very convenient formula (though sorts of ones can be made, relying on the linear dependency).
21:24:04 <edwardk> *nods* i used to do a lot of implicit surface stuff like this, but it was a LONG time ago
21:25:43 <edwardk> ok. i've parsed those two links
21:25:48 * hackagebot egison 0.3.0.1 - An Interpreter for the Programming Language Egison  http://hackage.haskell.org/package/egison-0.3.0.1 (SatoshiEgi)
21:25:48 <wli> edwardk: There's also a general phenomenon not farted around with where things end up not really constrained any more than "somewhere in the tangentspace generated by the parameter partials" and the rest is some godawful Faà di Bruno nightmare subtracted from plain old parameter derivatives.
21:26:08 <edwardk> heh
21:27:20 <wli> edwardk: It's a little atypical in the way linear algebra constraints are used that makes it hard to use as, say, constraints in an optimization problem.
21:27:52 <edwardk> i need to bring the two halves of what i know on this topic together. i spent a long time playing around with nurbs, etc. but that was before i understood the math behind everything. now i need to go back and put what i know with the intuition i had
21:28:58 <wli> edwardk: Some of the issues raised in Jörg Peters' handbook paper about special vertices I've yet to get a grip on, but after some smoke clears I might be able to clear denominators and talk about things to feed into a Gröbner grinder.
21:29:36 <wli> edwardk: Probably a big important thing though is rewinding back to the 1D case for parametric continuity on space curves or actual 1D cases.
21:30:27 <edwardk> well, you do take the edge down to a single t to trace out the curve at least
21:30:49 <wli> edwardk: There I have a trick to keep the constraints (a) quadratic (b) all monomials are cross products of coefficients from different but adjacent sub-intervals.
21:31:32 <wli> edwardk: So, if say the first n subintervals have their approximants fixed and a new knot comes in, continuity with the old one is in fact linear.
21:32:05 <edwardk> though usually you'll be floating just this side of fixed
21:32:47 <wli> It's restrictive, yeah, but it at least gets something close to the polynomial case where it's just linear algebra.
21:33:00 <edwardk> *nods*
21:33:22 <pcr> L
21:33:50 <pcr> test
21:33:55 <edwardk> how strong is your differential geometry?
21:34:22 <wli> edwardk: That trick to get everything quadratic (if for no other reason than keeping the degrees of the individual constraints down) is what I really want to find analogues of if I can figure it out. Geometrically continuous space curves instead of parametrically continuous ones, surfaces, etc.
21:34:40 <ddarius> edwardk: Speaking of which, you should read "Clifford Algebras to Geometric Calculus" if you never did.
21:34:40 <wli> edwardk: Not particularly, but I know some basics.
21:34:54 <wli> ddarius: What should I read?
21:34:55 <ivanm> I'm sure I've seen this before but forget how it was done: what's a function that of type [[a]] -> [[a]] that creates every way of taking an element from each-sublist?
21:35:10 <edwardk> Hestenes?
21:35:28 <ddarius> edwardk: Hestenes and Sobczyk, yes.
21:35:34 <edwardk> yeah, I obsessed about that back in college
21:35:38 <benmachine> ivanm: possibly sequence?
21:35:47 <ivanm> benmachine: heh, yeah, just worked that out :p
21:35:50 <ivanm> thanks anyway though
21:35:55 <benmachine> > sequence [[1,2,3],[50,60],[100,200]]
21:35:56 <lambdabot>   [[1,50,100],[1,50,200],[1,60,100],[1,60,200],[2,50,100],[2,50,200],[2,60,10...
21:36:00 <edwardk> rather fond of GA
21:36:31 <edwardk> wli: i only mentioned it because you craved more succinct notation. they have a lot of it ;)
21:36:34 <ddarius> There are a couple of things in that book that I haven't seen anywhere else.
21:36:46 <edwardk> ?
21:37:32 <wli> edwardk: Some of it may be unfortunately related to Faà di Bruno and rational functions.
21:41:56 <ddarius> edwardk: I found the shape operator sections reasonably interesting and unique.
21:43:56 <edwardk> hrmm. i can't seem to find my copy =(
21:46:44 <ddarius> edwardk: Walter Grandy Jr.'s "Entropy and the Time Evolution of Macroscopic Systems" is also interesting, but it gets pretty hairy pretty quick.  'turns out when you don't use phenomenological approximations, the math gets really heavy, really quick.
21:47:40 <edwardk> isn't that what physics is? lets just cut off this taylor series after a couple of terms here or there, or let the infinities and the zeroes cancel out and move on ;)
21:49:27 <ddarius> This is in the stastical mechanics realm (in particular it is a theory of non-equilibrium statistical mechanic), so there are less Taylor series.
21:50:14 <danharaj> and more partition functions :p
21:50:17 <ddarius> (Or rather there are probably more Taylor series, but you have to be a bit more clever than just truncating them.)
21:51:13 <edwardk> hah
21:54:54 <hpaste> mbuf pasted “parse error on input '->'” at http://hpaste.org/48494
21:56:42 <ivanm> mbuf: why do you expect that to work?
21:56:48 <ivanm> are you wanting a lambda function in there?
21:57:07 <ivanm> catch (\e -> ... )
21:57:12 <mbuf> ivanm: from the documentation, it says I must get 'Caught ThisException' to be printed
21:57:45 <mbuf> *Main> throw ThisException catch e -> putStrln ("Caught " ++ show (e :: MyException))
21:57:52 <ivanm> yeah, that's a typo in the documentation
21:57:58 <mbuf> ivanm: ahh!
21:58:30 <mbuf> ivanm: so what is the fix for it?
21:58:33 <ivanm> throw ThisException `catch` \e -> putStrLn (\"Caught \" ++ show (e :: MyException))
21:58:44 <ivanm> oh, un-escape those quotes though
21:58:46 <ivanm> throw ThisException `catch` \e -> putStrLn (\"Caught \" ++ show (e :: MyException))
21:58:56 <ivanm> gah, stupid quassel keeps sending it when I want to edit it! :@
21:59:10 <ivanm> throw ThisException `catch` \e -> putStrLn ("Caught " ++ show (e :: MyException))
22:00:53 <mbuf> ivanm: ambiguous occurrence `catch' It could refer to either `Prelude.catch', imported from Prelude or `Control.Monad.CatchIO.catch', imported from Control.Monad.CatchIO; I need to use the latter
22:01:05 <kmc> import Prelude hiding (catch)
22:01:13 <ivanm> ^^ what kmc said
22:01:19 <shachaf> ^^ what ivanm said
22:01:20 <ivanm> have that at the beginning of your import list
22:01:25 <ivanm> @slap shachaf
22:01:25 <lambdabot> stop telling me what to do
22:01:29 <ivanm> grrrrr.....
22:01:30 <mbuf> ivanm: shachaf ivanm thanks
22:01:44 <kmc> ^^ what shachaf said
22:02:02 * ivanm reports the error to libraries@
22:02:10 <shachaf> If there's anyone who needs @slapping, it's kmc, not me.
22:02:19 * shachaf isn't responsible for any cycles.
22:02:31 <kmc> is not each edge equally responsible for the cycle?
22:03:32 <shachaf> If the graph is mutable and each node has one outgoing edge that it controls, the party that mutated it last is responsible.
22:05:20 <ivanm> shachaf: hey, I slapped you before kmc made it a cycle!
22:05:30 <shachaf> Commands don't count.
22:05:31 <ivanm> well, tried to anyway...
22:06:13 * ivanm grumbles at not quite being able to understand the code he wrote about an hour ago
22:16:54 * hackagebot double-conversion 0.2.0.0 - Fast conversion between double precision floating point and text  http://hackage.haskell.org/package/double-conversion-0.2.0.0 (BryanOSullivan)
22:16:56 * hackagebot blaze-textual 0.2.0.0 - Fast rendering of common datatypes  http://hackage.haskell.org/package/blaze-textual-0.2.0.0 (BryanOSullivan)
22:16:58 * hackagebot text-format 0.3.0.2 - Text formatting  http://hackage.haskell.org/package/text-format-0.3.0.2 (BryanOSullivan)
22:17:43 <rata_> hi
22:17:54 * hackagebot text 0.11.1.3 - An efficient packed Unicode text type.  http://hackage.haskell.org/package/text-0.11.1.3 (BryanOSullivan)
22:18:34 <Axman6> 'lo
22:19:09 <rata_> would there be any difference in performance between "f (ARec{fieldName=fn}) = length fn" and "f = length . fieldName"?
22:19:48 <kmc> probably not
22:19:50 <kmc> did you measure one?
22:20:18 <mjrosenb> rata_: i usually assume that the ghc optimizer is smart enough to make those two equivalent
22:21:02 <ivanm> bos31337: so does double-conversion supercede the Reader stuff in text?
22:21:29 <bos31337> ivan: no
22:21:43 <bos31337> right now, i only interface to the rendering side
22:21:52 <ivanm> ahhh
22:22:02 <ivanm> so it's faster than T.pack . show ?
22:22:06 <rata_> kmc: no, I didn't
22:22:15 <rata_> mjrosenb: thanks =) I hope so too
22:22:20 <bos31337> ivan: yeah, about 30x faster
22:22:23 <ivanm> *sigh* and of course the problem with deeply-recursive functions inside a State monad is that they're almost impossible to test :/
22:22:30 <bos31337> uh ivanm, i mean
22:23:37 <ivanm> bos: will it be combined into text at some point though?
22:27:03 <ivanm> bos: isn't it rather fugly to be copying and using a C library though?
22:27:32 <ivanm> distro maintainers tend to get rather annoyed with that (admittedly, that's more for things like libraries being copied by web browsers, etc.)
22:46:55 <ivanm> is it faster to limit how many gets you do from a State monad even if you don't do any puts in between?
22:47:33 <Axman6> well i doubt they'll be optimised away, so it mightn't be a bad idea to reduce them
22:47:42 <Axman6> the advantages are probably limited though
22:48:07 <ivanm> hooray, I have once again managed to make my program faster whilst producing more results than I need :s
22:52:00 <aleator> If I have a Ptr Foo, how do I get a Ptr (Ptr Foo) ?
22:52:16 <ivanm> @hoogle Ptr
22:52:17 <lambdabot> module Foreign.Ptr
22:52:18 <lambdabot> Foreign.Ptr data Ptr a
22:52:18 <lambdabot> Foreign.Ptr ptrToIntPtr :: Ptr a -> IntPtr
22:52:32 <ivanm> @hoogle a -> Ptr a
22:52:33 <lambdabot> Foreign.ForeignPtr unsafeForeignPtrToPtr :: ForeignPtr a -> Ptr a
22:52:33 <lambdabot> Prelude id :: a -> a
22:52:34 <lambdabot> Data.Function id :: a -> a
22:52:38 <ivanm> bah
22:52:46 <kmc> aleator, castPtr?
22:53:03 <kmc> aleator, in general the problem "how do I write a function of type A -> B" is underspecified
22:53:14 <kmc> what do you actually want to do?
22:53:43 <kmc> do you need to allocate a reference cell where a pointer can live, and return a pointer to that cell?
22:53:48 <kmc> if so, how long does the cell need to remain alive?
22:54:12 <aleator> kmc: I've got a c lib that I'm writing a binding for. The finalizers need **Foo whereas ForeignPtr finalizers are *Foo.
22:54:50 <kmc> right, but what do those pointers mean?
22:54:54 <kmc> how will they be used?
22:55:00 <kmc> the types alone don't tell the whole story
22:55:33 <aleator> If I read things correctly, the c-lib will make the original pointer null after freeing the content.
22:56:03 <kmc> as a way of indicating success / as a silly safety measure?
22:56:22 <aleator> Silly safety measure would be my guess.
22:56:33 <kmc> ok well anyway
22:56:39 <kmc> you'll need to allocate space for it to write into
22:56:46 <kmc> but it won't last longer than the lifetime of the finalizer
22:56:51 <kmc> so you can use 'alloca'
22:57:08 <kmc> longer than the duration of the call to the finalizer, i mean
22:58:11 <kmc> or how about Foreign.Marshal.Utils.with
22:59:01 <aleator> kmc: Hmm.. with could work. I'll try that. Thanks!
22:59:16 <kmc> :)
23:03:07 <aleator> kmc: I feel silly not realizing that I need alloca..
23:03:38 <aleator> But seems to work. Now I'd need to find out how to easily test if the value actually gets freed..
23:05:57 * edwardk &
23:26:06 <mgccl> so I just realized for function f x y, f x is a partial application... it is different from function g x, h x, and I do (g . h), a function composition... god took me so long to figure out they are different...
23:28:50 <aleator> Gah. If I have Vector (Vector Foo), where Vector is of storable kind, how do I get Ptr (Ptr Foo)?
23:31:28 <arlenik> is Haskell's grammer context-free or context-sensitive?
