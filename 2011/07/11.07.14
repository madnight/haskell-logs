00:33:40 * hackagebot case-insensitive 0.3 - Case insensitive string comparison  http://hackage.haskell.org/package/case-insensitive-0.3 (BasVanDijk)
00:44:05 <Saizan> mwc: there's OverloadedString
00:56:18 <quicksilver> mwc: there is QQ syntax. It's slightly syntactically heavy but it works.
01:09:36 <erus`> im creating a minimal functional language
01:09:54 <erus`> without any if statements or any of that crap
01:10:12 <erus`> like haskell but tiny
01:11:08 <synonymous> erus`: like minhs?
01:11:34 <arcatan> like lazy-k?
01:12:32 <erus`> I cant find anything on google for minhs
01:12:54 <synonymous> me neither=)
01:14:01 <synonymous> we used to hack on a compiler for one of the courses a few years ago, and it was called minhs. let me dig up some course notes
01:16:05 <erus`> mine will output C++ code. kinda like a retarded coffeescript
01:16:55 <synonymous> i think minhs was interpreting the code right away. not really a compiler
01:23:23 <tantalum> erus`: One really simple project would be to make yet another lisp using haskell
01:24:00 <erus`> pfff
01:24:07 <erus`> im half way through
01:31:23 <synonymous> erus`: k, apparently minhs was Don Stewart's effort to create a compiler for teaching. It's used in the assignments so the complete source code isn't really available. I've got a few tarballs in different flavours and some documentation for it, if you are interested.
01:31:51 <maurer_> w/in 44
01:49:54 <erus`> > let x:xs = [1..] in x
01:49:55 <lambdabot>   1
01:59:05 * hackagebot dclabel-eci11 0.1 - Dynamic labels to assign confidentiality and integrity levels in scenarios of mutual distrust  http://hackage.haskell.org/package/dclabel-eci11-0.1 (AlejandroRusso)
02:10:39 <ketil> Is 'newtype Foo = Foo Bool' more efficient than 'data Foo = Bar | Zot'?  Or are there any other reasons to prefer one over the other?
02:11:28 <merijn> The latter is clearer (if the constructors have properly descriptive names)
02:13:48 <zygoloid> the former is slightly more efficiently convertible to Bool :)
02:15:38 <chylli> is there a way to read the document of installed package locally ? like perldoc in perl, etc
02:16:01 <merijn> @hoogle a -> Bool
02:16:01 <lambdabot> Test.QuickCheck.Batch isBottom :: a -> Bool
02:16:01 <lambdabot> Network.BufferType buf_isEmpty :: BufferOp a -> a -> Bool
02:16:01 <lambdabot> Network.BufferType buf_isLineTerm :: BufferOp a -> a -> Bool
02:16:21 <merijn> There's no "convert to bool" typeclass? Bummer
02:17:16 <Botje> toEnum . fromEnum ?
02:17:25 <shachaf> @slap Botje
02:17:25 * lambdabot decomposes Botje into several parts using the Banach-Tarski theorem and reassembles them to get two copies of Botje!
02:18:07 <adrake> that's quite the slap
02:29:49 <ketil> merijn, zygoloid : also, I can derive Enum on the ADT, but not on the newtype.  Maybe with a langauge pragma?
02:31:57 <Botje> .oO(deriving Enum should just use the Enum instance of the wrapped type, surely?)
02:34:03 <helmut> hi. i wrote a software about 3 years ago and now it no longer compiles, because ghc eats way more main memory than the system has. do you know a workaround?
02:34:35 <roconnor> helmut: did you compile with -O2 ?
02:34:45 <helmut> no
02:35:59 <flux> workaround: add more swap :)
02:36:02 <helmut> and why the heck does ghc need like 2G of main memory to compile a simple 500 line haskell file?
02:36:22 <zygoloid> ketil: GeneralizedNewtypeDeriving
02:36:38 <roconnor> helmut: wait, the memory problem is with compiling?
02:36:43 <helmut> roconnor: yes
02:36:47 <roconnor> :O
02:37:20 <ketil> Yes, right.  I'd rather be conservative, though.
02:38:00 <erus`> my code is looking really ugly allready :(
02:38:02 <adrake> helmut, I suspect knowing more about the contents of the file may be more helpful -- I routinely compile files much larger than that and use much less memory
02:38:53 <hpaste> erus` pasted “ugly” at http://hpaste.org/49031
02:42:53 <Botje> erus`: it's nicer if you line up the = with the | in your type declaration
02:43:48 <Botje> erus`: you should use pattern matching more
02:44:05 <erus`> where?
02:44:22 <zygoloid> wow, i love this hpaste stepeval thing
02:44:41 <zygoloid> i especially love how its prelude is presented hpaste-style, including hlint hints :)
02:45:22 <Botje> i may have spoken too soon
02:45:30 <Botje> hmm, food time :)
02:48:21 <Botje> for example in getType
02:48:21 <Botje> getType (TypeSpecify:ty:ts) = ...
02:48:21 <Botje> getType (_:ty:ts) = (process ty, ts)
02:48:21 <Botje> << foo
02:48:21 <Botje> d
02:48:21 <Botje> i'll see if i can clean it up a bit, maybe
03:29:32 <erus`> ah
03:29:34 <erus`> i see
03:42:57 <helmut> adrake: sorry for afk. i was waiting for my computer to stop swapping.
03:43:11 <helmut> adrake: actually the 500 line file (alex generated) compiles.
03:43:35 <helmut> however now not even frown manages to generate the parser within the main memory. *sigh*
03:50:47 <dca> could a haskell monad be roughly described as . (dot) operator overloading (in C++ terms) ?
03:52:01 <merijn> dca: Dot in the sense of "foo.bar().baz().xyzzy()"?
03:52:19 <sipa> it can be described as many things, but if you want to compare it to something in C++, i guess it's a callback function
03:52:26 <dca> merijn: yes
03:53:29 <merijn> dca: As far as I understand C++ overloading that feels sorta similar, yes
03:54:26 <erus`> can i have a more obscure monad analogy please
03:55:10 <dca> yes, yes go with it :)
03:56:01 <merijn> dca: I don't really like monad analogies I'd recommend just looking up what the Maybe and List monads do and then you'll go "Ooooh...is that all?!"
03:56:48 <merijn> Learn You a Haskell has a nice explanation of both I think
03:59:16 <erus`> @type fail
03:59:17 <lambdabot> forall (m :: * -> *) a. (Monad m) => String -> m a
04:01:44 <Botje> erus`: still interested in making your code prettier?
04:01:53 <erus`> yar
04:02:06 <Botje> lines 57 -- 58 can be rewritten using splitAt
04:02:48 <erus`> @type splitAt
04:02:49 <lambdabot> forall a. Int -> [a] -> ([a], [a])
04:05:41 <erus`> i is neater but it adds a line of code
04:06:05 <merijn> Oh noes!
04:06:08 <ion> Is there something wrong with adding a line of code?
04:06:13 <ion> implicitly
04:06:23 <merijn> ion: Crippling cost of disk storage these days
04:06:40 <Shammah> > sqrt(2)
04:06:41 <lambdabot>   1.4142135623730951
04:07:50 <erus`> more to read = longer it takes to understand
04:07:55 <ion> merijn: Why store on disk when you can store IN THE CLOUD?
04:09:11 <merijn> erus`: That's empirically not true
04:09:16 <hpaste> Botje annotated “ugly” with “rewrote parse” at http://hpaste.org/49031#a49036
04:09:30 <merijn> I have seen 100 line code which is significantly easier to read then 130 character code
04:09:39 <Botje> erus`: taking the line apart using a splitAt is nicer, imo
04:09:53 <erus`> Botje: yeah it looks much better
04:10:49 <ion> We should remove all type annotations from our code since more to read is equal to longer it takes to understand.
04:10:50 <merijn> For example, someone implemented an IP stack in 139 characters, I'll bet a longer version is easier to read :p
04:11:33 <erus`> Botje:
04:11:52 <erus`> does your folr still read top to bottom (eg index 0 forwards?)
04:12:15 <Botje> erus`: yes
04:12:26 <erus`> cool
04:12:32 <erus`> whats an unfold :|
04:12:36 <Botje> at least if i understood your code correctly
04:12:58 <Botje> unfold is a function that keeps going as long as that function returns Just
04:13:10 <Botje> you start from a seed value (your list of lines)
04:13:19 <Botje> and each time you check if the list is empty -> if so stop
04:13:34 <Botje> if it's not empty, you use parseStatement to produce a statement and a new seed value
04:14:05 <Botje> (your parseStatement unfortunately puts the seed value in the first position, so i need to to swap the tuple around)
04:14:14 <erus`> ah ok
04:17:22 <hpaste> Botje annotated “ugly” with “rewrote parse (annotation)” at http://hpaste.org/49031#a49037
04:18:01 <Botje> (note: all my annotations are untested)
04:20:23 <erus`> (l @(Line indent ts) : ls)     i have never seen that
04:20:30 <erus`> looks handy
04:21:19 <Botje> this way you can pattern match 'into' the l while still binding it to a variabl
04:21:21 <Botje> e
04:26:55 <mm_freak> does anyone have an idea how to process a dynamic system with animas/yampa?  dynamic in the number of signals
04:26:56 <Botje> erus`: i will just take a go at readDefinitionVars and then go back to work :)
04:27:35 <mm_freak> basically i have SF [X] [X], but can't really make use of that, because there is no ArrowChoice instance for SF
04:29:37 * hackagebot tagged 0.2.2.1 - Provides newtype wrappers for phantom types to avoid unsafely passing dummy arguments  http://hackage.haskell.org/package/tagged-0.2.2.1 (EdwardKmett)
04:30:19 <erus`> Botje: the other bits work well :)
04:33:29 <mm_freak> or to state the question more generally, if A is an arrow without ArrowChoice and i have 'processAll :: A [X] [Y]' and 'processOne :: A X Y', is there a way to apply processOne to all list elements from processAll?
04:33:34 <hpaste> Botje annotated “ugly” with “rewrote parse (annotation) (annotation)” at http://hpaste.org/49031#a49039
04:33:35 <mm_freak> intuitively it appears to be impossible
04:33:56 <Botje> and I smell that there's an unfoldr behind readDefinitionVars too
04:34:13 <mm_freak> yesterday i already failed to write 'mapA :: Arrow a => a b c -> a [b] [c]'
04:35:21 <dmwit> mm_freak: eh, mapA doesn't even have the type you reuqested in your previous sentence
04:35:40 <dmwit> Oh, I get it.
04:35:45 <dmwit> Let's see...
04:35:48 <mm_freak> dmwit: i can write that mapA function with ArrowChoice, but not with the general Arrow
04:36:09 <mm_freak> but the ArrowChoice instance is precisely what's missing for the SF arrow
04:37:34 <hpaste> Botje annotated “ugly” with “rewrote parse (annotation) (annotation) (annotation)” at http://hpaste.org/49031#a49040
04:37:37 <dmwit> Oh, yup.
04:37:46 <Botje> erus`: there, that's my final attempt
04:37:49 <dmwit> The whole point of arrows is that they don't allow data-dependent control-flow.
04:37:53 <dmwit> Right?
04:37:53 <Botje> does that look nice enough for you? :)
04:38:06 <dmwit> (They're a bit like Applicative in that regard.)
04:38:11 <mm_freak> dmwit: they do with ArrowChoice
04:38:15 <dmwit> Yes.
04:39:24 <mm_freak> i wonder if it's difficult to write ArrowChoice for SF
04:39:44 <mm_freak> but i don't even really get the internals of SF
04:41:50 <erus`> works a tread, thanks Botje
04:44:26 <burbul> Does anyone know why I might be getting a "Could not find module `Text.ParserCombinators.Parsec':"  message  when I have a .cabal file with "build-depends: base -any, containers -any, parsec -any" ? (I have 3.1.1 installed, too.)
04:44:26 <lambdabot> burbul: You have 1 new message. '/msg lambdabot @messages' to read it.
04:49:13 <burbul> (I can import it fine from GHCi, but I'm working inside Leksah, which means I have to use cabal... )
04:49:26 <dmwit> burbul: Maybe you should check which version it's choosing to match your -any.
04:50:16 <dmwit> Not that any version seems to be missing that module.
04:50:18 <dmwit> So never mind.
04:52:12 <burbul> dmwit: how would I go about checking that? (Presumably I have to get out of Leksah and use the command line... )
04:52:31 <dmwit> oh, uh, I dunno
04:52:38 <dmwit> cabal configure --verbose or something like that, I guess
04:53:03 <dmwit> Yeah, that seems to work here.
04:54:51 <burbul> "Dependency parsec ==3.1.1: using parsec-3.1.1"
04:55:41 <dmwit> burbul: The only thing I can think of is that you misspelled the module name somehow, but if you copied-and-pasted the error, then that doesn't seem true.
04:55:44 <dmwit> So I don't know.
04:56:58 <burbul> thanks anyway
04:57:51 <dmwit> burbul: Try another thing.
04:58:14 <dmwit> burbul: Try separately "cabal configure --global --verbose" and "cabal configure --user --verbose"
04:58:34 <dmwit> Perhaps Leksah is using a different setting there than the default (though I wouldn't really know why it would).
05:04:17 <burbul> both say "Dependency parsec ==3.1.1: using parsec-3.1.1"
05:09:52 <burbul> 'cabal build' works fine...
05:09:58 <burbul> so it's Leksah
05:15:28 <Axman6> is there a better way for a thread to kill itself than myThreadID >>= killThread?
05:15:54 <Saizan> does that even work?
05:16:03 <Axman6> i believe so
05:16:23 <dmwit> "undefined" is a few characters shorter
05:16:43 <dmwit> error"" is shorter still
05:16:54 <dmwit> fail""
05:16:55 <Axman6> not exactly a clean death though
05:17:00 <dmwit> Oh man, this is getting better and better.
05:17:13 <Axman6> also this is for the implementation of fail =)
05:17:18 <Botje> \5->4
05:17:38 <dmwit> haha
05:17:45 <dmwit> But you have to apply it to make it die. =(
05:18:51 <dmwit> 1/0
05:18:53 <Axman6> I'm writing something that I'm not sure if people will find useful, what I'm calling a futures library. lets you fork off threads and get a reference to the eventual result, which cal also be used to check on the thread's progress
05:18:59 <Axman6> can*
05:21:49 <hpaste> Axman6 pasted “Futures library” at http://hpaste.org/49041
05:22:34 <Axman6> anyone care to take a look? i don't know if anyone would find it useful or not
05:28:01 <Axman6> :(
05:28:38 <Botje> Axman6: hah! a colleague was just discussing how futures are monads
05:29:06 <Botje> would you happen to know a paper that explains this?
05:29:18 <Botje> I feel it's so obvious /someone/ must have written it
05:29:52 <Axman6> no... i just made it up after lightly skimming http://torquebox.org/news/2011/07/08/the-future-is-now/ and thinking that it would be pretty trivial to implement the same soft of functionality in haskell
05:31:10 <Axman6> heh, i love how the comments are all saying that it's amazing and brilliant
05:31:23 <Botje> yeah, it's sad.
05:31:35 <erus`> @type const
05:31:35 <lambdabot> forall a b. a -> b -> a
05:31:39 <Botje> eventually they will catch up, i guess
05:31:45 <Axman6> yeah
05:31:56 <Axman6> i implemented that in about half an hour without really thinking about it
05:31:57 <merijn> Future's sounds remarkably like deferred's in Python's Twisted...
05:32:18 <merijn> Which is just a fancy name for a callback with some mangling around it
05:32:27 <Axman6> just trying to think about what types i wanted everything to have was the hardest part
05:32:33 <lunaris> @pl \a b c k -> k a b c
05:32:33 <lambdabot> (flip .) . flip . flip id
05:33:34 <Axman6> i feel that this framework could be put to great use in something like a file download app, where the progress would be the percent downloaded, with the result being... the result =)
05:33:49 <merijn> Oh, a Java framework...that explains why they're so excited about old news
05:34:09 <Axman6> i thought it was ruby, the syntax looked like it...
05:34:22 <fasta> merijn: yep, 40 year old stuff.
05:34:25 <merijn> TorqueBox is a small adaptation layer on top of Java application server from JBoss, JBoss AS.
05:34:32 <merijn> according to their FAQ
05:34:58 <Axman6> "TorqueBox is a new kind of Ruby application platform that integrates popular technologies such as Ruby on Rails, while extending the footprint of Ruby applications to include built-in support for services such as messaging, scheduling, and daemons."
05:35:20 <merijn> It's Ruby in Java apparently
05:35:24 <merijn> That's even worse >.>
05:35:35 <Axman6> yah
05:35:36 <Watermind> categoricaly, what do you call  return . f  ?
05:35:49 <Axman6> almost fmap?
05:35:50 <merijn> @pl \f -> return . f
05:35:50 <lambdabot> (return .)
05:35:52 <Axman6> >_>
05:35:54 <Watermind> i.e.  I feel tempted to call it a lifting
05:36:06 <Watermind> but lifting are what occur at the type level
05:36:07 <merijn> hmm
05:36:22 <Watermind> so Maybe a   is a lifting of  a with a the lifting monad Maybe
05:36:28 <arcatan> heh, i'm just working on a C++ project with many ad-hoc, informally-specified, bug-ridden futures
05:37:07 <fasta> arcatan: so, not Boost? ;)
05:37:13 <Axman6> @quote Axman6.C++
05:37:13 <lambdabot> No quotes match. I've seen penguins that can type better than that.
05:37:18 <Axman6> @quote Axman6 C++
05:37:18 <lambdabot> Axman6 says: <vegai> anyone intimate with HDBC.Sqlite3? <Axman6> only if it buys me a drink
05:37:25 <Axman6> @quote Axman6 C++
05:37:25 <lambdabot> Axman6 says: and smilies make code run faster
05:37:32 <Watermind> but so categorically, what do call wraping something with a return
05:37:34 <Axman6> -_-
05:37:35 <Axman6> @quote Axman6
05:37:35 <lambdabot> Axman6 says: <vegai> anyone intimate with HDBC.Sqlite3? <Axman6> only if it buys me a drink
05:37:37 <Axman6> @quote Axman6
05:37:37 <lambdabot> Axman6 says: <vegai> anyone intimate with HDBC.Sqlite3? <Axman6> only if it buys me a drink
05:37:41 <Axman6> gah
05:37:48 <Axman6> "Axman6: well, if C++ is anything to go by, the next Haskell will have lambdas and easy concurrency!" is the one i was after
05:37:53 <Axman6> from the HWN =)
05:38:14 <Watermind> the "return" morphism is eta, the unit of the monad, but the action of composing with return is called... ?   :S
05:38:16 <arcatan> fasta: yup
05:38:42 <erus`> i would like to meet someone who learned haskell as their first programming language
05:38:56 <merijn> arcatan: Isn't everything in C++ ad-hoc, informally-specified and bug-ridden?
05:39:22 <Watermind> merijn: haskell is informally specified as far as I know :P
05:39:43 <Watermind> merijn: or does it have any formal operational or denotational semantics these days?
05:39:46 <merijn> Watermind: Haskell98 and Haskell2010 are pretty rigidly specified afaik
05:39:52 <Axman6> i thought it had a fairly clear specification?
05:40:04 <Watermind> merijn: Axman6: I don't know... where is it?
05:40:11 <Axman6> Watermind: those are implementation dependant i believe
05:40:16 <dino-> I was just perusing the source of Data.List and wondering why some things, like reverse, are implemented both as a fold (for the #ifdef USE_REPORT_PRELUDE case) and as an explicit recursion.
05:40:19 <Watermind> Axman6: so there you go
05:40:34 <dmwit> eh?
05:40:39 <Watermind> Axman6: implementation dependent = not formally specified
05:40:44 <dmwit> There's no formal operational semantics for Haskell?
05:40:45 <Axman6> sure
05:41:00 <Watermind> dmwit: I'm asking... not as far as I know... but I may be wrong
05:41:21 <Axman6> all the H98 report says is (among other things) that haskell is a non-strict language
05:41:26 <Axman6> @where report
05:41:27 <lambdabot> http://www.haskell.org/onlinereport/
05:41:32 <Axman6> Watermind: read that =)
05:41:35 <Watermind> dmwit: I know it didn't use to, because the ML side was always using that argument
05:42:26 <Watermind> Axman6: point me to the section with the formal semantics and I will
05:42:42 <Axman6> Watermind: I've never read it, how would i know where it is =)
05:42:53 <Watermind> Axman6: as fair as I know... there isn't one ;)
05:47:29 <dmwit> http://www.haskell.org/onlinereport/exps.html#case-semantics looks promising, but as you say, the rest of the semantics are informal
05:47:36 * dmwit is surprised
05:48:18 <dmwit> By the way, "the action of composing with return" could have several meanings.
05:48:58 <dmwit> "m >>= return" doesn't have a name, because it's equal to "m" as an axiom of being a monad
05:49:35 <dmwit> "m >>= return . f" has a name; in Haskell that name is fmap, but in CT it's usually not referred to explicitly, just given by the name of the functor involved.
05:49:51 <dmwit> So that would be Ff(m) for functor F.
05:50:33 <dmwit> If you said "functor F maps f to g", people would know what you meant, and I guess that's where the "fmap" name came from -- "functor map".
05:51:05 <dmwit> "return . f" all by itself doesn't have a name either, I guess.
05:52:22 <frerich> It's depressing how little fun C++ became now that I know Haskell a bit better. I always think "Oh this would be much nicer in Haskell...". Maybe some sort of Wiki page with C++ tricks to translate Haskell features to C++ would be nice so that one can at least transport some of the conciseness.
05:52:24 <dmwit> "f >=> return" also doesn't have a name, for the same reason "m >>= return" doesn't.
05:53:27 <sipa> :t (m >>= return)
05:53:28 <lambdabot>     Couldn't match expected type `m a' against inferred type `Expr'
05:53:28 <lambdabot>     In the first argument of `(>>=)', namely `m'
05:53:28 <lambdabot>     In the expression: (m >>= return)
05:54:01 <dmwit> :t \m -> m >>= return
05:54:01 <lambdabot> forall (m :: * -> *) a. (Monad m) => m a -> m a
05:54:44 <Axman6> i thought it had the name 'monad identity' =)
05:54:53 <erus`> frerich: i agree
05:54:54 <Axman6> or 'monad identity law'
05:54:57 <dmwit> The law has a name.
05:54:59 <dmwit> The action does not.
05:55:21 <Axman6> details
05:55:55 <mm_freak> frerich: i made the mistake to try to port haskell features to other languages, and it doesn't really pay off
05:56:02 <zygoloid> frerich: i'm working on a non-member operator() extension which gives you something a bit like monads
05:56:16 <mm_freak> for example monads are great in haskell, but not at all great in C++
05:56:16 <benmachine> dmwit: isn't it called 'f'? :P
05:57:06 <frerich> mm_freak: Was there anything which worked out okayish?
05:57:24 <mm_freak> frerich: it all worked, but it was not exactly fun to use
05:57:26 <dylukes> I tried to implement currying in C++.
05:57:28 <dylukes> That was fun :)
05:57:41 <dylukes> Well, in Obj-C++…
05:57:41 <zygoloid> (also i have a proper parametric polymorphism extension in the pipeline)
05:57:44 <frerich> mm_freak: Yeah I guess the hwole point is to make things nicer to read/write than without it ahem...
05:57:44 <dylukes> didn't quite get it sadly.
05:57:46 * hackagebot factory 0.0.0.2 - Rational arithmetic in an irrational world.  http://hackage.haskell.org/package/factory-0.0.0.2 (AlistairWard)
05:57:54 <zygoloid> dylukes: oh, that was you? :)
05:57:59 <mm_freak> i ported monads (in the sense of haskell monads, i.e. with the implied generality) to C++ and C#
05:58:03 <dylukes> This was a couple days ago zygoloid
05:58:08 <mm_freak> and i ported almost-iteratees to PHP
05:58:09 <dylukes> I still have one "key" issue to work out.
05:58:17 <dylukes> Namely, how to actually construct the smaller closures ^^;
05:58:23 <mm_freak> (only "almost", because it used a trampoline under the hood instead of continuations)
05:58:35 <zygoloid> dylukes: ah, there was someone on the clang ML trying to mix variadic templates and blocks a while back for currying purposes
05:58:48 <dylukes> Actually yeah, one way I considered,
05:58:56 <mm_freak> dylukes: currying is actually surprisingly easy to implement in C++1x
05:59:09 <dylukes> Well, I was trying to do it in pure C/ObjC...
05:59:17 <mm_freak> forget it ;)
05:59:19 <frerich> It's alreayd useful to write C++ with a "functional" mindset but yeah, it would be nice to have things like currying or type inference. Actually, I believe the latter becomes easier with C++1x (with the new semantic of the "auto" keyword)
05:59:21 <dylukes> I ended up having to use a small C++ hack to get ()()()… syntax working.
05:59:26 <mm_freak> it's possible, but not anywhere near nice
05:59:29 <dylukes> Yeah.
05:59:34 <dylukes> One thing I considered though,
05:59:46 <zygoloid> frerich: the trouble is, C++ still basically only has a one-directional information flow when inferring types
05:59:57 <dylukes> was using a variadic/recursive curry function, and then passing a runtime-dynamic number of parameters using inline asm.
06:00:14 <dylukes> as in, pushing the argument pointers manually :P.
06:00:17 <zygoloid> (there are exceptions for overload resolution when taking addresses of functions etc, but not useful exceptions)
06:00:25 <dylukes> hehe. It was an interesting idea...
06:00:34 <mm_freak> dylukes: currying in C++1x is really straightforward now that it has closures
06:00:40 <dylukes> they're not closures really...
06:00:47 <dylukes> well, not automatic closures.
06:00:59 <dylukes> And, I was doing this in C with the clang blocks extension.
06:01:06 <mm_freak> no?  i think you can tell them which variables to take with them
06:01:13 <dylukes> Right.
06:01:19 <mm_freak> that's all you need
06:01:22 <dylukes> Clang blocks automatically close over anything used in them.
06:01:24 <dylukes> w/e, close enough
06:01:36 <dylukes> here
06:01:37 <dylukes> https://gist.github.com/1082410
06:01:45 <Axman6> doesn't using [=] do the same in C++0x?
06:01:49 <dylukes> I never worked out that internal bit :\.
06:02:05 <mm_freak> well, your problem is that you have to specify what is part of the closure
06:02:10 <mm_freak> that's not as nice as haskell lambdas
06:02:35 <mm_freak> but i think there are actually few languages with closure inference
06:02:43 <dylukes> C is, surprisingly, one of them ;)
06:02:48 <dylukes> It even infers return type.
06:02:53 <mm_freak> C?
06:02:59 <zygoloid> Axman6: iirc __block variables get their lifetime extended (ie, proper closures are formed)
06:03:05 <mm_freak> since when does C have closures?
06:03:13 <dylukes> It's an extension in Clang.
06:03:18 <dylukes> id concat = ^(NSString *a, NSString *b){
06:03:18 <dylukes>             return [a stringByAppendingString:b];
06:03:18 <dylukes>         };
06:03:21 <Axman6> since Apple implemented them
06:03:22 <mm_freak> then it's not C
06:03:25 <zygoloid> dylukes: Obj-C you mean
06:03:27 <erus`> can i set the precedence of my infix function?
06:03:29 <frerich> I thought it's Objective C
06:03:31 <dylukes> zygoloid: No, it's C.
06:03:41 <zygoloid> dylukes: blocks are part of objective-c
06:03:47 <dylukes> zygoloid: No, you're wrong :)
06:03:49 <Axman6> C, C++ and Objective-C can all use the blocks extension
06:03:56 <Axman6> zygoloid: no they're not
06:03:58 <dylukes> zygoloid: The blocks technically match the structure of an Objective-C object, but they're a C extension.
06:03:59 <mm_freak> dylukes: that's not C, it's a C-like language
06:04:04 <Axman6> lib dispatch is a puerly C library
06:04:07 <dylukes> mm_freak: No, its C with an extension.
06:04:13 <mm_freak> that's not C
06:04:17 <zygoloid> dylukes: they are a part of the objective-c 'standard'
06:04:19 <Axman6> purely*
06:04:21 <dylukes> zygoloid: No they're not.
06:04:39 <mm_freak> ok, then haskell is lazy k with an extension ;)
06:04:40 <dylukes> http://clang.llvm.org/docs/BlockLanguageSpec.txt
06:04:50 <mm_freak> and C# is brainfuck with an extension =)
06:05:00 <dylukes> mm_freak: It's not even a change to the language.
06:05:07 <dylukes> Blocks are rewritten into structures at compile time.
06:05:09 <Axman6> blocks is a compiler feature. it's like inline functions in GCC
06:05:11 <dylukes> It's really just sugar.
06:05:14 <mm_freak> dylukes: it's a change to the C standard
06:05:21 <dylukes> … No, it's an extension.
06:05:22 <mm_freak> an extension that is
06:05:22 <Axman6> mm_freak: yes
06:05:33 <dylukes> Then, none of us are really using Haskell either,
06:05:35 <Axman6> well, yeah, an extension is more accurate
06:05:38 <dylukes> because of GHC extensins.
06:05:41 <mm_freak> dylukes: standard-compliant C compilers can't compile it, so it's not C, period
06:05:52 <dylukes> mm_freak: Which compiler is "standards-compliant"?
06:05:57 <Axman6> none
06:06:07 <mm_freak> dylukes: gcc --std=c99 comes close
06:06:10 <Axman6> maybe some of the smaller ones, like pcc or tcc
06:06:10 <dylukes> The bottom line is, any production quality C code, is GNU99 or MSVC99
06:06:19 <dylukes> mm_freak: gcc is anything but standards compliant.
06:06:25 <Axman6> indeed
06:06:27 <dylukes> It implements optimizations which go against the standard.
06:06:36 <dylukes> But, no one cares because GNU sets its own standard (GNU99(.
06:06:51 <mm_freak> dylukes: it implements all standard features of C, and yet it can't compile your code
06:06:55 <mm_freak> so your code is not standard
06:07:05 <mm_freak> and yes, most of us use non-standard haskell
06:07:06 <dylukes> I never said it was.
06:07:08 <dylukes> Also, Clang is a fully featured, almost-100% compatible C89/99/1X compiler.
06:07:10 <Axman6> mm_freak: yes it can, Apple added blocks to GCC too
06:07:18 <dylukes> Axman6: Oh yeah good point :).
06:07:29 <dylukes> and clang is not a "restricted apple platform"
06:07:31 <mm_freak> Axman6: with --std=c99?
06:07:47 <Axman6> i think it works with something like -fblocks
06:07:51 <Axman6> not sure
06:07:56 <dylukes> Axman6: no, it'll work with --std=c99
06:08:01 <Axman6> nor do i care. it's an amazingly useful extension
06:08:06 <dylukes> GCC will only throw an error/warning if you have -pedantic turned n.
06:08:09 <Ke> you can always break that with -Ofast
06:08:24 <dylukes> apple's blocks extensions is ridiculously useful, yeah.
06:08:29 <mm_freak> if you disable nonstandard features via --std=c99 (which even disables TCO!) and reenable all the features by other flags, then the --std=c99 is pretty meaningless =)
06:08:34 <dylukes> And, it's not changing the language, it's purely sugar.
06:08:42 <mm_freak> anyway, there is a standard describing the language C
06:08:48 <dylukes> No one uses it.
06:08:56 <dylukes> Period.
06:09:02 <dylukes> If you're on Linux, you're using GNU99.
06:09:13 <zygoloid> dylukes: hmm, right you are. i thought they'd added it as a 'blessed' obj-c extension :)
06:09:13 <dylukes> If you're on Windows, you're using MSVC
06:09:26 <dylukes> zygoloid: No, it's a C extension :).
06:09:29 <mm_freak> dylukes: are you questioning the point of standards?
06:09:34 * sipa always use -std=c99
06:09:36 <dylukes> mm_freak: Yeah, pretty much.
06:09:45 <dylukes> While they certainly are useful and keep the language "in check"
06:09:47 <zygoloid> dylukes: yes, i know that now :)
06:09:48 <dylukes> They're never kept too.
06:09:49 <mm_freak> well, then why do we need HTTP?
06:10:00 <dylukes> mm_freak: Because HTTP is a platform in of itself.
06:10:02 <mm_freak> every web service could just as well provide their own protocol along with a custom program =)
06:10:11 <dylukes> mm_freak: The 90's showed that wasn't a good idea.
06:10:12 <Axman6> mm_freak: are you suggesting we should all stop using GHC?
06:10:18 <mm_freak> no, HTTP is not a platform, it's a standard
06:10:21 <zygoloid> dylukes: but that was never in question. the question was, is it an official part of obj-c? and it's not :)
06:10:28 <Axman6> becausd it implements plenty of non-standard extensions
06:10:33 <Axman6> because*
06:10:34 <dylukes> Well guys, I think #haskell should only be for talking about the standard language, to appease mm_freak.
06:10:45 <dylukes> So, if you want to talk about non-standard haskell, please take it to #ghc or #not-haskell
06:10:46 <mm_freak> Axman6: i never said that extensions are bad
06:10:56 <mm_freak> Axman6: my point is that C has no closures
06:10:59 <Axman6> then what's your argument then?
06:11:04 <Axman6> ok?
06:11:07 <mm_freak> if your language has closures, you're not talking about C
06:11:18 <dylukes> Of course we are.
06:11:21 <Axman6> GNU C has closures
06:11:23 <dylukes> It's C with extensions.
06:11:34 <quicksilver> There is a difference in conventional usage.
06:11:35 <mm_freak> just like if your language has GADTs, then you're certainly not talking about haskell
06:11:45 * frerich apologizes for starting an argument about whether C has blocks or not or what by praising Haskell features :-}
06:11:48 <quicksilver> when people talk about "haskell" they generally *do* include widely used language extensions.
06:11:54 * rothwell claws at own face
06:11:54 <dylukes> frerich: Don't worry.
06:12:00 <quicksilver> when people took about "C" they are generally *not* talking about a language with closures.
06:12:01 <dylukes> mm_freak: You're being an obnoxious pedant.
06:12:13 <dylukes> quicksilver: That's changing quite rapidly.
06:12:16 <quicksilver> perhaps.
06:12:18 <dylukes> Even Apache is using libdispatch/blocks.
06:12:18 <Axman6> quicksilver: no, because it's a new extension =)
06:12:43 <Axman6> the FreeBSD guys have seen how useful libdispatch is and are looking for ways to use it
06:12:59 <mm_freak> dylukes: then microsoft is an obnoxious pedant too for breaking standards all the time and making the life of developers hard
06:13:05 <zygoloid> dylukes: blocks are still very much in a minority. even c99 is still in a minority among c programmers
06:13:08 <dylukes> mm_freak: Actually, Microsoft is pretty damn nice to developers.
06:13:19 <dylukes> The "Microsoft hates developers" mantra is kind of outdated.
06:13:23 <dylukes> Well, correction,
06:13:31 <dylukes> they're nice to developers on their own platforms.
06:13:40 <zygoloid> microsoft hates portability :)
06:13:46 <Ke> microsoft wants developers to use C# and silverlight
06:13:48 <dylukes> zygoloid: No, they hate other platforms.
06:13:49 <mm_freak> dylukes: are you sure?  i remember times of MsgWaitForMultipleObjectsEx =)
06:13:51 <Ke> not C
06:14:00 <zygoloid> dylukes: the two are not mutually exclusive
06:14:01 <dylukes> Ke: Also true.
06:14:23 <dylukes> Silverlight has always had a "creepy" factor to me.
06:14:34 <dylukes> Because well, it's a portable CLR.
06:14:39 <dylukes> Not creepy in a bad way.
06:14:41 <mm_freak> dylukes: anyway, you shouldn't talk about C when talking about that language, because if you talk about C, then i expect to be able to compile it with a C compiler
06:14:55 <dylukes> mm_freak: You can compile it, with two of the largest and most popular compilers :).
06:15:00 <dylukes> GCC, as well as Clang.
06:15:02 <mm_freak> i.e. CCompiler c => c instead of SomeSpecificCompiler
06:15:38 <mm_freak> dylukes: i can't pass forall c. CCompiler c => c to a function expecting OneOfTheTwoOfTheLargestCCompilers ;)
06:15:41 <Axman6> GCC, LLVM-GCC and Clang all support blocks on OS X
06:15:58 <dylukes> Axman6: Not just OS X...
06:15:59 <Axman6> and there's some support on FreeBSD too
06:16:07 <dylukes> clang supports them on any platform it runs on.
06:16:13 <dylukes> They're not anything special underneath.
06:16:26 <Axman6> i thought they needed a special runtime
06:16:31 <dylukes> Just a structure (which matches the ObjC object structure) with some signature information and a function pointer.
06:16:31 <mm_freak> btw, haskell is a good example…  GHC indeed doesn't compile code with nonstandard extensions by default
06:16:37 <dylukes> Nope, they don't need any additional runtime at all.
06:16:46 <mm_freak> and i think that's very good and any compiler doing it differently is illbehaved
06:16:55 <dylukes> Ah, well, apparently they do for Block_copy() and Block_release().
06:17:05 <Axman6> must just be libdispatch that needs it then
06:17:05 <mm_freak> i blame the developers of C compilers for not going with the standard by default
06:17:14 <Axman6> the standard is lacking
06:17:15 <dylukes> mm_freak: Why? The standard is defficient.
06:17:44 <mm_freak> dylukes: the haskell standard is defficient in many ways too, yet that's fine with us
06:17:51 <mm_freak> what's wrong with the C developers
06:17:51 <dylukes> Just because one canary has a bigger, more useful beak than another, does not make it not a Canary.
06:17:57 <dylukes> mm_freak: Right, and we use extensions :)
06:18:02 <mm_freak> they have #pragma, just like we have {-# #-}
06:18:09 <Axman6> mm_freak: blocks are also an extension...
06:18:16 <Axman6> what's your point?
06:18:34 <mm_freak> Axman6: i already made my point
06:19:23 <Axman6> that it's a good thing to have extensions for Haskell and not complain, but if you do the same thing with C, that's somehow evil?
06:19:26 <mm_freak> dylukes: again, i have absolutely no problem with extensions…  i use them myself
06:19:50 <dylukes> Well, apparently you do, because even if a feature is implemented by the major C compilers, you refuse to acknowledge it.
06:19:57 <dylukes> Hell, Haskell only has ONE major compiler.
06:20:04 <mm_freak> Axman6: no, it's a good thing to have extensions and to use them, but the compiler shouldn't accept them by default
06:20:23 <dylukes> mm_freak: Wrong.
06:20:34 <mm_freak> dylukes: i acknowledge it, but not as a standard
06:20:35 <dylukes> mm_freak: Some of these are so useful, they're on by default. And if you're a pedant...
06:20:42 <dylukes> there's a flag for you! (-pedantic or -pedantic_errors)
06:20:45 <mm_freak> "extension" is just a nicer word for "nonstandard feature"
06:20:54 <dylukes> That's the definition of extension.
06:20:57 <dylukes> -___-
06:21:09 <Axman6> GCC accepts things that are non-standard by default....
06:21:36 <mm_freak> dylukes: honestly i can understand why those things are on by default in C
06:21:56 <dylukes> mm_freak: Another example,
06:22:00 <dylukes> it's "valid" to do
06:22:07 <dylukes> static int a = 1, 2, 3;
06:22:08 <mm_freak> but i still don't see that is C
06:22:11 <zygoloid> mm_freak: the trouble is that 'compatibility' turns out to be a very compelling argument for enabling extensions by default
06:22:18 <Axman6> is __attribute((foo)); a C thing? or a GCC thing?
06:22:20 <mm_freak> just like i don't see "data Void;" as haskell
06:22:21 <dylukes> mm_freak: Does that look valid to you?
06:22:26 <dmwit> Yes.
06:22:29 <zygoloid> Axman6: __attribute__ is a gcc thing
06:22:29 <dylukes> Axman6: its __attribute__(( )).
06:22:30 <dmwit> , is an operator
06:22:34 <dylukes> dmwit: It's actually not.
06:22:41 <dylukes> it would be inside a function!
06:22:52 <dylukes> static variables at the file scope have to have a constant expression assigned to them.
06:23:01 <dylukes> Expressions involving the , operator are not considered constant by the standard.
06:23:02 <mm_freak> dylukes: i'm not exactly sure, but it looks like standard C defining a static int a = 1 and resulting in 3
06:23:09 <dylukes> mm_freak: No, it assigns 3.
06:23:11 <Axman6> but GCC accepts that without you having  to turn on an extension :o
06:23:12 <dylukes> , is basically <*
06:23:14 <dmwit> Okay, I didn't know that. But that means nothing.
06:23:22 <zygoloid> dylukes: static int a = 1, 2, 3; is not legal in any context in C or C++.
06:23:22 <Axman6> dylukes: not *>?
06:23:25 <dmwit> I've been surprised by Haskell before, too.
06:23:30 <dmwit> "surprising" /= "bad"
06:23:30 <dylukes> It's an example of something "non-standard" we take for granted.
06:23:35 <dylukes> Axman6: No, it takes the value on the right.
06:23:41 <dylukes> so 1,2,3 evaluated to 3.
06:23:50 <zygoloid> dylukes: the top-level comma is always a separator between declarators in that context.
06:23:56 <dylukes> zygoloid: Wrong.
06:24:06 <dylukes> It's the comma operator.
06:24:15 <dylukes> try it out with -pedantic on :)
06:24:16 <mm_freak> dylukes: i don't know the precedence rules here, but with other precedence it could mean (static int a = 1), 2, 3
06:24:22 <dylukes> mm_freak: Wrong again.
06:24:28 <dylukes> 1,2,3 is an expression.
06:24:40 <dylukes> = binds as weakly as possible.
06:24:41 <dmwit> I don't get it. What's your argument here?
06:24:43 <zygoloid> dylukes: it would be a comma-expression. which is not a valid initializer.
06:24:49 <dmwit> "extensions are useful so they should be enabled by default"?
06:24:58 <dylukes> What my point is,
06:25:02 <Axman6> dylukes: *> runs the thing on the left and returns the thing on the right...
06:25:02 <dmwit> There's a warrant I'm missing there -- why should all useful things be enabled by default?
06:25:03 <mm_freak> dylukes: i'm not sure what your point is
06:25:06 <dylukes> zygoloid: actually, it is a valid initializer.
06:25:20 <dylukes> The point is, at the static scope, the initializer must be a constant expression, which 1,2,3 is not
06:25:21 <dylukes> and yet,
06:25:24 <dylukes> all major compilers allow it.
06:25:28 <quicksilver> dylukes: "static int a = 1, 2, 3;" is not accepted by my GCC or my G++.
06:25:45 <dmwit> I don't buy the "everybody does it, so everybody *should* do it" argument, either.
06:26:07 <dylukes> write it as static int a = (1, 2, 3);
06:26:12 <dmwit> The question at hand is: *should* compilers demand (and accept) code that conforms to the standard by default?
06:26:15 <dylukes> I guess precedence does take hold in that scope.
06:26:22 <dylukes> dmwit: Right.
06:26:24 <quicksilver> dylukes: also, can you moderate your tone slightly? There are less aggressive angles to take than repeatedly saying "You're wrong" and "Wrong again".
06:26:25 <mm_freak> dylukes: that's not the argument here…  we are talking about features, not bugs
06:26:35 <dylukes> quicksilver: yeah, sorry
06:26:37 <dylukes> anyways
06:26:40 <dylukes> static int a = (1, 2, 3); is invalid standard C.
06:26:40 <mm_freak> nonstandard features should be explicitly enabled in my narrow view of the world
06:26:43 <dylukes> But, it makes sense.
06:26:48 <dmwit> I'm not sure I'm convinced by either side, but I'm extra unconvinced by your side. =P
06:26:51 <dylukes> So, should it be enabled by default?
06:27:01 <dylukes> Since, the constant value can be determined at compile-time.
06:27:10 <zygoloid> dylukes: basically, an initializer has to be an assignment-expression, which the use of the comma operator is not
06:27:17 <mm_freak> dylukes: i don't know what is "constant" by the C standard
06:27:23 <Axman6> i don't get why __attribute__ is ok in GCC, but using blocks in Clang is evil
06:27:25 <mm_freak> after all you can write:  static int a = 1 + 1;
06:27:27 <zygoloid> constant-ness is irrelevant
06:27:33 <dylukes> Okay, be quiet for a second.
06:27:35 <dylukes> I'll explain nthis,
06:27:45 <dylukes> whether or not an expression is "constant" is very well defined by the C standard.
06:27:47 <quicksilver> "static int a = (1, 2, 3);" is accepted by my G++ but not by my GCC.
06:27:48 <dylukes> 6.3 I think?
06:27:52 <mm_freak> Axman6: i think __attribute__ is actually standard
06:27:54 <dylukes> static int a = 1 + 1; is fine as well.
06:27:59 <dylukes> Since 1+1 is a constant expression.
06:28:06 <dylukes> Basic arithmetic is considered constant.
06:28:13 <mm_freak> the standard permits semantics-changing stuff by __*__, IIRC
06:28:24 <burbul> Has anyone used Leksah?
06:28:32 <dylukes> Now, within the scope of a function, you can have non-constant expressions as initializers obviously,
06:28:43 <dylukes> but at the static scope, you cannot, since they're… static.
06:28:52 <burbul> I keep getting a "Setup: You need to re-run the 'configure' command. The version of Cabal being used has changed (was Cabal-1.10.1.0, now Cabal-1.10.2.0)." message, despite completely reinstalling it...
06:29:07 <dylukes> Also, it's section 6.6 of the speciifcation.
06:29:08 <mm_freak> dylukes: i mean why is 1+1 constant but (1,2) not?
06:29:08 <dylukes> My bad.
06:29:17 <dylukes> mm_freak: Because the specification says so :).
06:29:21 <mm_freak> i see
06:29:28 <dylukes> "An integer constant expression117) shall have integer type and shall only have operands that are integer constants, enumeration constants, character constants, sizeof expressions whose results are integer constants, "
06:29:37 <dylukes> "Constant expressions shall not contain assignment, increment, decrement, function-call, or comma operators, except when they are contained within a subexpression that is not evaluated.115)"
06:30:10 <dylukes> The reason is because , is supposed to denote evaluation sequencing at runtime.
06:30:14 <dylukes> But, most compilers recognize that 1,2,3 is going to be constant anyways, and allow it.
06:30:43 <dmwit> dylukes: Okay, here's a question. Why would you want the compiler to accept that by default?
06:30:52 <ocharles> hey Peaker, around at all, or are you working?
06:30:53 <dmwit> It seems like a darn stupid thing to do in any real code.
06:30:57 <dylukes> Because it's logically constant. If it didn't accept it you'd be somewhat confused.
06:31:09 <dmwit> If somebody wrote that, I'd be somewhat confused.
06:31:13 <dylukes> It's a simplification though, let me give a more complex example.
06:31:13 <zygoloid> dylukes: that's not a good argument for ignoring the standard, and ignoring portability.
06:31:20 <dmwit> And I'd be mad that the compiler let them write it, too, probably.
06:31:31 <zygoloid> however, it turns out that, like MS, GNU don't like portability either (at least, not portability to non-GNU platforms)
06:32:04 <EvanR> is there a good haskell dev environment for windows?
06:32:06 <dmwit> Look, nobody's arguing that the C standard is well-written, or even that people should write to the standard.
06:32:22 <dmwit> What we're arguing is that deviations from the standard should be explicitly marked as such.
06:32:26 <dmwit> What could be so bad about that?
06:32:30 <dylukes> dmwit: mm_freak was saying thar.t
06:32:34 <dylukes> dmwit: I don't mind that at all.
06:32:39 <dylukes> I like GHC's way of doing extensions.
06:33:11 <dylukes> But, I think the reason it's not done in C, is because extensions are used so frequently, it becomes a hassle to mark every single file as such.
06:33:37 <quicksilver> zygoloid: s/don't like/don't consider a higher priority than other things they work on with limited resources/
06:33:41 <dmwit> 09:26 < mm_freak> Axman6: no, it's a good thing to have extensions and to use them, but the compiler shouldn't accept them by default
06:33:49 <quicksilver> zygoloid: not that I want to sound like an apologist ;) But there is always lots to work on.
06:33:57 <dmwit> mm_freak was *not* saying that people should always write to the standard, he was explicitly saying the obvious.
06:34:10 <dmwit> err... s/obvious/opposite/
06:34:26 <quicksilver> I suspect the raisin for C is hysterical
06:34:38 <quicksilver> C standards were slow in coming, C compilers were slow in supporting standards
06:34:39 <benmachine> quicksilver: the raisin d'etre?
06:34:42 <Axman6> the reason Clang accepts blocks by default a purely pragmatic: they're very useful, and Apple are starting to use them more and more in their frameworks, for good reason
06:34:44 <quicksilver> people just wanted to write code.
06:34:53 <zygoloid> quicksilver: i don't think it's a priorities thing. gcc added enabled-by-default extensions because the kernel folks wanted them, and they didn't care about portability to other compilers
06:35:13 <zygoloid> Axman6: clang does not accept blocks by default. :)
06:35:22 <Axman6> you sure?
06:35:23 <quicksilver> zygoloid: interesting, although I don't understand. The kernel folks control their own makefile they could add -fblah easily enough.
06:35:32 <zygoloid> Axman6: yup. tried it earlier :)
06:35:34 <Axman6> ah, -fblocks
06:35:48 <dylukes> zygoloid: what platform are you on?
06:35:54 <Axman6> so... THIS ARGUMENT HAS BEEN FOR NOTHING!
06:35:59 <benmachine> *gasp*
06:36:00 <zygoloid> Axman6: well, the message says: "compile with -fblocks or pick a deployment target that supports them"
06:36:27 <zygoloid> so maybe it's on-by-default on Apple, or maybe Apple's build of llvm enables them by default, or...
06:36:28 <dylukes> It accepts them by default for me.
06:36:32 <dylukes> on OS X.
06:36:42 <dylukes> the default deployment target here supports them though.
06:36:46 <Axman6> but probably not on other platforms
06:36:59 <dylukes> mm_freak: Clang has appeased your wishes!
06:36:59 <zygoloid> what a surprise, Apple doesn't care about portability either :)
06:37:00 <dylukes> egads.
06:37:02 <benmachine> I think C compiling counts as -blah material
06:37:12 <benmachine> personally
06:37:15 <dylukes> zygoloid: Just between ARM and x86, thats about it :).
06:37:18 <dylukes> And only on their kernel
06:37:25 <mm_freak> quicksilver: haskell standards are not coming exactly much faster than C standards, yet we have no problem with mentioning extensions explicitly
06:37:37 <dylukes> Though, strangely enough, the Objective-C runtime has been portable to WIN32 for years.
06:37:41 <dylukes> and Win64 I think now.
06:37:48 <zygoloid> benmachine: http://hpaste.org/steps/49034?expr=s+1234&submit=Submit
06:37:52 <Axman6> mm_freak: they're coming yearly now...
06:37:54 <quicksilver> mm_freak: because the haskell committee very specifically had standardisation in mind.
06:37:56 <zygoloid> (in case you're interested in stepeval bugs)
06:37:59 <dylukes> They haven't open-sourced any version of the runtime though recently.
06:38:13 <quicksilver> mm_freak: you could say that a large part of the haskell project was a standardisation effort.
06:38:18 <benmachine> zygoloid: that's not exactly a bug :P
06:38:26 <benmachine> it's unimplemented and told you
06:38:34 <Axman6> dylukes: they'll probably have to when lion is released
06:38:40 <dylukes> Axman6: ?
06:39:00 <dylukes> Not really. The Objective-C runtime's written in C, presumably compiled with clang, and not dependent on *anything*.
06:39:06 <benmachine> zygoloid: I'd like to support that but I haven't come up with a good way of showing the matching of a function
06:39:13 <dylukes> As long as they're not using GCC, they don't have to open source it at all.
06:39:15 <benmachine> in terms of mutating an expression
06:39:17 <Axman6> dylukes: what's it licence?
06:39:30 <dylukes> Axman6: Exclusive copyright by Apple.
06:39:38 <benmachine> possibly should just introduce a local case expression
06:39:41 <dylukes> But, remember, Objective-C is not a standardized language.
06:39:43 <zygoloid> benmachine: is the guard the problem?
06:39:48 <dylukes> Apple's runtime extends the definition in any case.
06:39:53 <dylukes> the original definition, that is.
06:39:57 <benmachine> zygoloid: patterns and guards in functions are both the problem
06:39:59 <dylukes> It's also a very easy language to implement.
06:40:03 <benmachine> zygoloid: in case expressions, you just drop false guards
06:40:19 <mm_freak> anyway, my original point was that C with extensions is not C, it's C-like…  IMO that's an important difference
06:40:20 <zygoloid> benmachine: yeah, desugaring to case would be fine i think
06:40:26 <Axman6> i thought it was interesting that they introduced 'Objective-C 2.0', and hnow they've added a whole bunch of stuff for lion, without a version increment =)
06:40:39 <dylukes> mm_freak: I think I disagree with that point though. It still is C. It's not standard-C, but it's still C.
06:40:46 <mm_freak> because you cannot expect a C-like language other than C to compile with a C compiler
06:40:51 <dylukes> Axman6: They haven't actually change much :\
06:40:52 <benmachine> zygoloid: it's not really ideal but it might do. personally I'm inclined to think that stepeval should have a different sort of UI entirely
06:40:58 <benmachine> probably a graphical one
06:41:00 <zygoloid> Axman6: more interesting than version 2.0 being a successor to versions 3 and 4? :)
06:41:03 <EvanR> mm_freak: how important is that really
06:41:08 <dylukes> A handful of runtime functions for zeroing weaks.
06:41:11 <dylukes> That's about it.
06:41:15 <quicksilver> I think it is time for the what-shall-we-call-C discussions to move to #haskell-blah or elsewhere.
06:41:26 <Axman6> agreed
06:41:27 <mm_freak> EvanR: just as important as the fact that you cannot expect elements from a monoid to be invertible
06:41:31 <mm_freak> so monoids are not groups
06:41:51 * hackagebot acid-state 0.4.3 - Add ACID guarantees to any serializable Haskell data structure.  http://hackage.haskell.org/package/acid-state-0.4.3 (DavidHimmelstrup)
06:42:06 <mm_freak> even if the monoid is infinitely large and only one element is not invertible, it's still not a group
06:42:23 <arw__> has anybody around here used ATS? any comments?
06:42:36 <mm_freak> and anyone claiming that it is will be shot by any reasonable mathematician
06:42:45 <Axman6> i remember looking at ATS and thinking it looked horrible =)
06:42:51 <EvanR> mm_freak: imagine that the math culture went insane and called all monoids groups, and there were really two kinds of groups, real groups and technically monoids-only ;)
06:43:18 <mm_freak> EvanR: then the point of standardization would truly be destroyed ;)
06:43:24 <EvanR> indeed
06:43:29 <EvanR> welcome to reality!
06:44:07 <mm_freak> all people blame visual C++ for not being C++, but when it comes to non-standard C, they have no problem
06:44:26 <benmachine> all people, huh
06:44:33 <mm_freak> it's just stupid
06:44:46 <benmachine> all people are stupid
06:45:09 <mm_freak> benmachine: as you see, not using language properly leads to misunderstandings
06:45:13 <mm_freak> that's exactly my point
06:45:23 <arw__> Axman6: well, yes. the inline-C really makes it look weird...
06:45:40 <Axman6> it was the dependant types that made it look horrible to me
06:45:43 <mm_freak> "it's just stupid" is not the statement you interpreted
06:46:06 <EvanR> the point of standardization has eluded me, having worked in web stuff for a few years. most people complain about standards but its not even close to relevant to the work. because browsers dont use standards anyway
06:46:10 <zygoloid> i wonder just how far from the mark "all people" is here
06:46:12 <Axman6> the example of doing insertion sort or something which guaranteed the result was sorted was pretty... horrible looking
06:46:34 <mm_freak> EvanR: it's not as bad as it used to be 10 years ago
06:46:39 <benmachine> Axman6: as I recall it, it wasn't helped by some really bad decisions in the syntax highlighter
06:46:41 <zygoloid> EvanR: well, fixing that seems to be a major design goal of HTML5
06:46:56 <mm_freak> since now there are other browsers, people refrain from using internet explorer extensions
06:46:58 <benmachine> I think the web development situation used to be a lot worse
06:47:20 <benmachine> even if browsers and designers only loosely adhere to standards, there is some pressure at least not to run off on your own
06:48:00 <arw__> zygoloid: depends. some statements about HTML5 beeing a 'living standard' (read: nobody will ever be able to implement it) sound pretty worrying in that regard.
06:48:23 <erus`> is the guy who wrote lambda script on here?
06:48:27 <benmachine> arw__: I thought that was really weird but I think it kind of makes sense
06:48:28 <arw__> zygoloid: more like HTML5 will be the former chaos, written down as a chaotic standard.
06:48:32 <EvanR> benmachine: the pressure is on making stuff that will work in currently existing browsers
06:48:51 <zygoloid> arw__: yeah, that's true. on the other hand, specifying what happens to malformed pages (ie, the web) is a major advance
06:48:56 <mm_freak> anyway, i think we went way off-topic
06:49:04 <EvanR> not really standards, or, its own defacto standard
06:49:09 <benmachine> mm_freak: the original topic was already off-topic :P
06:49:27 <zygoloid> ultimately, the point seems to be that Haskell does this right and most other languages do it wrong :)
06:49:36 <mm_freak> benmachine: i think the concept of "original topic" on IRC is flawed anyway =)
06:49:43 <benmachine> has anyone submitted anything for haskell2012
06:49:46 <EvanR> original sin
06:49:56 <benmachine> -XOriginalSin
06:49:59 <mm_freak> zygoloid: true =)
06:50:23 <mm_freak> but to get this back on topic, i wonder how far GHC without extensions adheres to the standard
06:50:41 <mm_freak> it seems to be pretty compliant
06:50:52 <quicksilver> they certainly accept bug reports for where they fail
06:51:08 <quicksilver> although they have, very occasionally, kept a compliance failure in for backwards compatibility.
06:51:11 <benmachine> there are a few known deviations I think
06:51:22 <zygoloid> how would people act if -fglasgow-exts became the default?
06:51:52 <zygoloid> i can't imagine many people would be happy
06:52:18 <benmachine> http://www.haskell.org/ghc/docs/7.0-latest/html/users_guide/bugs-and-infelicities.html
06:52:41 <mm_freak> zygoloid: i'd be happy, if some of the extensions would make it into the standard
06:53:19 <mm_freak> notably TemplateHaskell, QuasiQuotes, UndecidableInstances and ImplicitParams
06:53:25 <mm_freak> no, that was just a joke =)
06:54:18 <mm_freak> i'm mostly talking about RankNTypes and ScopedTypeVariables
06:54:30 <benmachine> http://www.haskell.org/ghc/docs/7.0-latest/html/users_guide/sooner-faster-quicker.html "Don't derive/use Read unnecessarily: It's ugly and slow."
06:54:38 * benmachine didn't know this was a thing
06:54:43 <mm_freak> sometimes i would also like to have TupleSections and PackageImports in the standard
06:55:03 <mm_freak> because cabal is not part of the standard, and there is no standard way to tell one module from another
06:55:45 <mm_freak> benmachine: Read is really slow, not only because it uses String
06:55:52 <mm_freak> it's even slow for something using String
06:56:19 <benmachine> mm_freak: packages aren't even in the standard at all, are they?
06:56:26 <benmachine> so it would be odd to put packageimports in
06:56:31 <mm_freak> benmachine: good point
06:56:38 <dmwit> benmachine: Is there a "cabal build --quickly" that takes the advice on that page? =P
06:57:01 <EvanR> mm_freak: on the subject of String, ive run into problems before loading a large file with it. ByteString fixed it. but Text.JSON only accepts String, problem?
06:57:09 <mm_freak> there should be a "cabal install --quickly", which makes use of the eight cores i have =)
06:57:48 <mm_freak> EvanR: i don't see how that could be a problem, as long as you don't load the whole file
06:58:02 <EvanR> that would be the point
06:58:20 <benmachine> do lazy IO, everyone loves lazy IO
06:58:23 <EvanR> you cant decode part of a file
06:58:31 <EvanR> with JSON
06:58:49 <mm_freak> EvanR: i don't see why not
06:58:59 <EvanR> because the file contains a single json object
06:59:09 <mm_freak> yes, the JSON object can be in memory fully
06:59:13 <EvanR> i know
06:59:15 <mm_freak> but the file doesn't have to be
06:59:25 <EvanR> so lazy io it is?
06:59:34 <mm_freak> i see no problem with parsing JSON sequentially in constant space
06:59:45 <mm_freak> either that or some saner approach like iteratees
07:00:03 <EvanR> so Text.JSON?
07:00:07 <EvanR> out the window
07:00:46 <mm_freak> if Text.JSON insists on having the entire string input in memory, then yes
07:00:55 <mm_freak> out the window
07:01:10 <EvanR> id rather not use magic lazy loading
07:01:19 <EvanR> i didnt even know that was recommended for something like this
07:01:52 <flux> I guess lazy loading is acceptable if you provide a way to indicate IO error as well?
07:02:03 <flux> although maybe not that great in any case :)
07:02:15 <EvanR> as far as i know the only way is to have the program crash in response to an error ;)
07:02:43 <mm_freak> flux: lazy IO is fine, if the resulting value is forced, before the scope of the exception handler is left
07:03:00 <flux> mm_freak, can't you convert the exceptions into some value?
07:03:01 <mm_freak> but that's often blurry, and personally i prefer iteratees over lazy IO
07:03:20 <mm_freak> flux: what would be the type of getContents then?
07:03:32 <mm_freak> getContents :: [Either SomeException Char]?
07:03:33 * EvanR gah @ libs that just accept String
07:03:35 <mm_freak> + IO
07:03:55 * edwardk waves hello,
07:03:58 <flux> mm_freak, you could choose if error means truncating the data, or if there is something like [Value 'a', Value 'b', Exception] perhaps
07:04:01 * mm_freak waves back
07:04:21 <mm_freak> flux: then you would have a poor form of iteratees
07:04:34 <mm_freak> you could just use the right thing =)
07:04:49 <flux> mm_freak, that might be, but at least you would have escaped the IO monad? disclaimer: I don't know what are iteratees :)
07:04:57 <EvanR> is there a way to take any parser that takes String and use it with iteratees? ;)
07:05:01 <mm_freak> flux: iteratees escape the IO monad
07:05:12 <flux> well, it sounds like a good solution then
07:05:18 <mm_freak> flux: iteratees are some kind of generalized lists…  lists generalized to coroutines
07:05:30 <monadic> EvanR: You mean with Parsec? I think parsec-iteratee might be able to do that
07:05:30 <EvanR> flux: note that id rather not reimplement a json parser ;)
07:05:41 <EvanR> monadic: nah
07:05:53 <flux> evanr, just refactor it ;)
07:06:00 <EvanR> lol.
07:06:12 <mm_freak> EvanR: for a quick solution just use lazy IO and force the resulting JSON value, all of that inside an exception handler
07:06:23 <monadic> EvanR: What about using Aeson? IIRC it depends on Attoparsec which does partial parsing and fits well with iteratees
07:06:30 <flux> it'd seem to me a language like haskell would be great for automatic refactoring
07:06:31 <mm_freak> if you want to do it right, write Text.BetterJSON =)
07:06:37 <flux> but I guess the tools don't exist :)
07:06:39 <EvanR> monadic: ill have to check Aeson
07:06:53 <Botje> flux: like HaRE?
07:07:07 <monadic> EvanR: http://hackage.haskell.org/packages/archive/aeson/0.3.2.9/doc/html/Data-Aeson-Parser.html is the Attoparsec parser for Aeson
07:07:19 <mm_freak> flux: refactoring is not so much demanded for haskell, because of the missing large-scope-variables
07:07:22 <flux> botje, perhaps. appears that it hasn't been updated for a year, though.
07:07:31 <monadic> EvanR: But I think attoparsec only accepts bytestrings
07:07:38 <Botje> could be
07:07:49 <Botje> i don't follow it
07:07:49 <mm_freak> there is attoparsec-text
07:07:55 <mm_freak> or text-attoparsec, i don't remember
07:08:01 <EvanR> monadic: accepting bytestring rather than string would solve the memory issues
07:08:10 <monadic> mm_freak: Well that too, what I mean to say is it doesn't support [Char] if he wantst hat
07:08:20 <EvanR> usually not a problem to load a several megabyte file into a bytestring
07:08:31 <flux> mm_freak, I think some simple 'extract local function into a global function' or 'move function to another file' would be useful refactorings
07:08:40 <mm_freak> monadic: parsing [Char] is something you do to solve haskell exercises =)
07:08:47 <flux> and perhaps some heavy-dutier as well, "convert into monadic code"
07:08:57 <Watermind> dmwit:  yes I meant  (return . )   basically this is what I want,  if the result of an operation returns the same value x, you say the result is its "identity"...  but if you're working in a kleisli category this identity is eta, i.e. return in haskell lingo
07:09:05 <mm_freak> flux: i see
07:09:05 <EvanR> yeah im complaining about parsers that accept [Char]
07:09:11 <monadic> I'm surprised the JSON library isn't updated to Parsec3. It still uses that ugly CharParser.
07:09:36 <mm_freak> EvanR: Text would be more reasonable than ByteString
07:09:44 <mm_freak> i always view ByteString as binary data
07:09:49 <EvanR> ok
07:09:56 <EvanR> not familiar with Text
07:10:00 <mm_freak> Text is encoding-sensitive
07:10:01 <EvanR> do parsers like it?
07:10:06 <mm_freak> and uses double the amount of memory =)
07:10:40 <monadic> mm_freak: If it uses double memory, why is it more reasonable?
07:10:42 <Watermind> dmwit:  so basically I was looking for a name for the action of transforming    x  in  Maybe x
07:10:43 <mm_freak> Text is like ByteString (given a constant encoding, they are in one-to-one correspondence), but it knows characters, not bytes
07:10:51 <Watermind> dmwit: opss... Just x
07:11:06 <mm_freak> monadic: because when parsing sequentially that doesn't really matter
07:11:28 <mm_freak> unless you are doing extremely-high-performance-parsing you shouldn't notice the difference
07:11:36 <EvanR> 2x memory on a pc doesnt really matter
07:12:22 <monadic> mm_freak: I guess I'm wondering, what the advantage is
07:12:28 <monadic> mm_freak: I've seen the Text module but never used it
07:12:42 <EvanR> monadic: well the parser can be written to look for characters rather than specifically encoded (utf8) byte patterns
07:13:04 <benmachine> Text is only double the amount of memory on ASCII inputs surely
07:13:13 <benmachine> if there's unicode involved it'll be less than that
07:13:29 <Axman6> monadic: you can parse unicode data with Text without having to worry about the details of unicode
07:13:45 <monadic> Axman6: Ahh. Okay.
07:14:00 <Axman6> with ByteString, you need to know what bytes signify that the current character is more than a single byte long
07:14:01 <poucet> What is sun-chie's website again?
07:14:09 <benmachine> Text in principle *could* be utf8 bytestrings underneath, but in practice it's utf16 because (iirc) that turned out to be faster
07:14:20 <monadic> On a side note, is there any interest in merging Parsec and Attoparsec? Seems to me like Attoparsec is a faster version of Parsec with a Stream Bytestring instance
07:14:32 <benmachine> monadic: parsec has a stream bytestring instance already
07:14:40 <monadic> benmachine: I know, and its slower
07:14:46 <benmachine> attoparsec however, can't do strings at all iirc?
07:14:54 <ziman> Data.Text is being rewritten to Utf8, afaik
07:14:58 <benmachine> so they really solve different problems
07:15:03 <Axman6> attoparsec is designed for quickly parsing bytestrings, nothing more
07:15:12 <ziman> i've seen a blogpost about it this morning
07:15:15 <Axman6> it doesn't support anywhere near as many features as parsec i believe
07:15:16 <benmachine> it would be nice if parsec became resumable though
07:15:32 <benmachine> it would also be nice if I could ever work out how to use uu-parsinglib
07:15:45 <Axman6> oh yeah, attoparsec is also an iteratee in disguise =)
07:15:47 <mm_freak> monadic: the advantage depends on the application
07:15:51 <ocharles> awww, all of pointed depends on GHC 7 :(
07:16:08 <mm_freak> monadic: it's not advantagous for an IRC proxy, but for parsing mails it is
07:16:13 <quicksilver> ziman: experimentally I believe.
07:16:56 <mm_freak> monadic: and with a tighter encoding you wouldn't have O(1) length or O(1) indexing
07:17:12 <mm_freak> for example Text with UTF-8 would use less memory, but would certainly be slower for most purposes
07:17:53 <mm_freak> (and could even use more memory for some languages)
07:18:13 <edwardk> actually Data.text in utf8 is looking pretty good performance wise
07:18:16 <ziman> quicksilver, yes: http://jaspervdj.be/posts/2011-07-10-text-utf8-initial-results.html
07:18:37 <EvanR> whoever suggest Aeson, youre the man
07:18:48 <EvanR> this looks way simpler and better than Text.JSON
07:18:50 <mm_freak> edwardk: as long as you don't use length or indexing
07:19:35 <mm_freak> indexing a UTF-8 Text is O(n), while with 16 bit unicode it's O(1)
07:19:44 <edwardk> Data.Text is shit for dealing with length as well. recall its UTF16. you neglect plane 1
07:19:52 <edwardk> it can't index either.
07:19:56 <edwardk> its O(n) indexing as well
07:20:02 <mm_freak> huh?
07:20:21 <edwardk> > fromEnum (maxBound :: Char)
07:20:22 <lambdabot>   1114111
07:20:35 <edwardk> > fromEnum (maxBound :: Word16)
07:20:36 <EvanR> mm_freak: er, what about yeah non BMP
07:20:36 <lambdabot>   65535
07:20:53 <edwardk> unicode code points are 21 bits
07:21:13 <EvanR> 1.21 jiggabits
07:21:19 <edwardk> java's unicode implementation was early and conflated 16 bit characters with code points.
07:21:42 <edwardk> this is why to actually use unicode _correctly_ in java you have to count off by codepoints and do all sorts of crazy hackery
07:21:55 <mm_freak> edwardk: oh, indeed
07:21:57 <edwardk> Data.Text indexes by codepoint, not 16 bit word
07:21:59 <mm_freak> ok, sorry for talking shit
07:22:15 <EvanR> edwardk: considering javas attitude with memory, i dont see why they didnt just use utf32
07:22:18 <mm_freak> i thought the 16 bit representation would cover all characters
07:22:44 <arw__> nope. and there are characters consisting of more than one code point.
07:22:55 <EvanR> arw__: false?
07:22:56 <mm_freak> indeed
07:22:58 <edwardk> the performance differences between Data.Text in UTF16 and UTF8 have to do with the fact that one has to only 2 ways to deal with 1 or 2 word codepoints, and the other has to branch up to 4 to deal with 1,2,3 or 4 byte codepoints.
07:23:07 <arw__> EvanR: combining characters?
07:23:26 <EvanR> arw__: its still not one character
07:23:41 <EvanR> there are canonicalizations you can do though to make it one character, precomped
07:23:44 <EvanR> precombined
07:23:47 <edwardk> and the fact that Data.Text using UTF8 could memory map in more sources, because something like only 20% of your data sources are encoded UTF16, while close to 50% are in UTF8.
07:24:17 <arw__> EvanR: nope, there are glyphs which can only be represented by combining characters.
07:24:24 <EvanR> arw__: no
07:24:38 <mm_freak> then i wonder why they're not using a 24 bit representation
07:24:48 <EvanR> whatever glyph you think youre representing its a unicode character in that case
07:24:49 <edwardk> mm_freak: alignment and precedent
07:24:56 <mm_freak> or 32 bits
07:24:57 <EvanR> isnt a
07:25:05 <EvanR> mm_freak: yeah thats what i said
07:25:26 <EvanR> use 32bits
07:25:41 <edwardk> mm_freak: keep in mind when these standards (UCS2,4,UTF8,16,32) were being bandied about that alphas were still around, and they couldn't do unaligned loads at all
07:26:12 <EvanR> dont forget utf9
07:26:33 <edwardk> =P
07:26:53 <edwardk> would have been awesome on the PDP10!
07:27:11 <mm_freak> i think for most applications that one possible branch is not much better than the four possible branches of UTF-8
07:27:22 <edwardk> mm_freak: exactly
07:28:08 <EvanR> also the japanese utf8 bloat isnt really a problem, they just use shift-jis ;)
07:28:16 <EvanR> problem solved
07:28:18 <edwardk> mm_freak: there are some other subtle differences as well. one thing worth exploring is the fact that currently data.bytestring uses foreignptrs, so they can be pinned, while data.text uses ByteArray#'s which can't be pinned except during construction
07:28:45 <mm_freak> edwardk: "pinned"?
07:29:09 <edwardk> mm_freak: to hand a bytestring off to FFI you just say "don't move this" to the GC.
07:29:17 <mm_freak> ah, ok
07:29:20 <edwardk> to hand a Data.Text fragment off to the OS you have to copy it into a new buffer.
07:29:38 <mm_freak> why can't ByteArray#s be pinned?
07:29:44 <edwardk> If you use Data.Text's ICU support it copies like 3 times.
07:29:47 <edwardk> they aren't designed to be
07:30:43 <mm_freak> does the GC move stuff around while an FFI call is running?
07:31:11 <edwardk> so one of the avenues we've been exploring with Data.Text is to see if using the foreignptr approach nets a better result, but that requires macro benchmarks because the impact of using bytestring's approach is that bytestring uses mallocForeignPtr which puts it in always-pinned memory ANYWAYS and then makes pinning a noop
07:32:02 <edwardk> the only stuff the foreign world interacts with is stuff that is pinned in some way.
07:32:09 <mm_freak> why would the GC move stuff around anyway?  to remove fragmentation?
07:32:13 <edwardk> foreignPtr's you've grabbed a Ptr out of, etc
07:32:15 <edwardk> yes
07:32:37 <edwardk> keep in mind until memory usage gets high copy collection has much nicer asymptotics than mark/sweep
07:32:46 <edwardk> because you only pay for the live set
07:32:57 <mm_freak> yeah, ok
07:33:27 <mm_freak> well, luckily i never had to concern myself with those details
07:33:52 <mm_freak> my programs seem to perform very well with the mostly idiomatic code i write
07:36:31 <hpaste> erus` pasted “math with lists ” at http://hpaste.org/49043
07:38:15 <dmwit> Watermind: Transforming the x in Just x doesn't use (return .), it uses (>>= return .), which was one of the other options I proposed.
07:38:35 <dmwit> Watermind: It's called fmap in Haskell, and named by just naming the functor (e.g. Maybe) in category theory.
07:38:38 <ion> erus: You’re still using the + operator.
07:39:49 <erus`> oh damn
07:39:54 <Axman6> Icewing: only to add Ints...
07:39:57 <erus`> i had concat before
07:40:14 <Axman6> uh, ion*
07:41:26 <ion> erus: Try implementing the operators with natural numbers on type level instead, that’s a cooler (and potentially actually useful) excercise. :-)
07:41:28 <EvanR> i tried Data.Aeson.toJSON on a double value and it caused floating point exception and crashed ghci :(
07:41:44 <EvanR> er encode 3.14 or encode (toJSON 3.14)
07:41:46 <Axman6> heh
07:43:02 <ketil> This still current: http://www.haskell.org/haskellwiki/Performance/Data_types ?
07:44:36 <Axman6> ketil: any part specifically?
07:45:17 <quicksilver> ketil: it looks accurate to me, yes.
07:45:26 <ketil> using newtype wrapping ints instead of algebraic data types for performance reasons.
07:45:28 <quicksilver> although I wouldn't bother with the enumeration advice in 3.3 myself.
07:46:22 <gkreimer> !seen burp
07:46:29 <ketil> quicksilver, yes, that part, specifically. :-)
07:46:58 <Axman6> seems like odd advice to me, but might be correct nonetheless
07:47:29 <ketil> Seems like a decent compiler should be able to optimize both cases similarly - if anything, the ADT is more limited, and should optimize better.
07:47:47 <EvanR> tracking the problem to Blaze.Text double
07:47:51 <quicksilver> ketil: I wouldn't be entirely surprised to hear it's better in some cases.
07:48:04 <quicksilver> ketil: although there are other cases where an optimisation called 'SpecConstr' would apply to the ADT
07:48:11 <quicksilver> (and wouldn't apply to the int)
07:48:32 <Axman6> it would be nice if GHC represented enumerations like that as ints
07:48:36 <quicksilver> it's certainly a micro optimisation I wouldn't consider making until I was sure that was a bottleneck.
07:57:51 <erus`> is some some kind of functional processor in existance?
07:58:13 <c_wraith> The reduceron.
07:58:40 <Phyx-> hmm does anyone know what's wrong here? http://pastebin.com/iW1Q1FGJ
07:58:41 <mauke> The paste iW1Q1FGJ has been copied to http://hpaste.org/49046
07:59:38 <c_wraith> the single ' in the name of st_a1
07:59:41 <c_wraith> err
07:59:49 <c_wraith> st_a1'
07:59:57 <c_wraith> I believe that screws up CPP
08:00:04 <c_wraith> since that's not lexically valid in c
08:01:22 <Phyx-> hm
08:01:28 <Phyx-> c_wraith: thanks c_wraith
08:01:34 <c_wraith> Phyx-: also, foo <- return $ bar
08:01:37 <c_wraith> that's silly
08:01:41 <Phyx-> yeah i know
08:01:44 <c_wraith> :)
08:01:49 <Phyx-> but i can't generate a let there
08:02:03 <Phyx-> well i could, after redoing the generator a bit
08:02:07 <Phyx-> but i just wanna test now
08:02:15 <quicksilver> isn't cpphs supposed to be like cpp, but aware of haskell lexical conventions?
08:02:39 <c_wraith> supposed to, maybe, but there is plenty of valid haskell the CPP extension pukes on.
08:02:55 <quicksilver> ah
08:03:06 <Phyx-> but ghc doesn't use cpphs does it?
08:03:29 <Axman6> no, it just uses the system cpp
08:03:40 <c_wraith> well, that explains it
08:04:16 * Phyx- changes the codegen to be able to produce lets
08:04:18 <quicksilver> you can ask GHC to use cpphs though
08:04:34 <Phyx-> oh, how?
08:04:44 <quicksilver> -cpp  -pgmPcpphs  -optP--cpp
08:04:57 <quicksilver> cpphs is intended to be used in this way.
08:05:01 <quicksilver> http://www.cs.york.ac.uk/fp/yhc/dependencies/cpphs/docs/#how
08:05:35 <Phyx-> isn't -cpp deprecated now?
08:07:03 <quicksilver> I don't know. That website is obsolete but I can't find the new cpphs website
08:07:08 <exeter> quick Q: any good system F tutorial? I'm a bit stuck reading the wiki page (as soon as I reach the "Logic and predicates" section)
08:07:33 <quicksilver> the new website should be http://haskell.org/cpphs/ but that appears to have got lost in the merge
08:07:41 <quicksilver> preflex: seen malcolmw
08:07:41 <preflex>  malcolmw was last seen on #haskell 19 days, 21 hours, 18 minutes and 9 seconds ago, saying: GHC has a CSE pass, but it is usually turned off
08:08:07 <dankna> cpphs is GPL, we can't use it as part of GHC.  I think.
08:08:39 <Phyx-> i'm currently using cpphs with cabal
08:08:46 <Phyx-> by using a .cpphs file
08:08:59 <Phyx-> but i wanted to avoid having to do .cpphs -> .hsc -> .hs
08:09:10 <Phyx-> so i just enabled the GHC CPP Pragma
08:09:27 <Guest40272> http://hackage.haskell.org/trac/ghc/wiki/KindSystem
08:09:41 <Guest40272> This seems kind (heh) of crazy.
08:10:01 <Guest40272> What comes after sorts?
08:11:33 <dankna> phylums.
08:11:50 <Guest40272> seriously?
08:11:55 <dankna> no, I made that up :)
08:12:32 <c_wraith> if you just use dependent typing, it's types all the way up. :)
08:12:45 <c_wraith> because then types are values.  the type of a type is just another type. :)
08:13:13 <quicksilver> you sometimes see the word 'variety' used
08:13:18 <quicksilver> or simply 'higher sorts'
08:13:21 <quicksilver> (or indeed 'higher kinds')
08:13:41 <c_wraith> yes.  when's GHC getting higher-kinded polymorphism again? :)
08:14:45 <Phyx-> 17:19:18 < c_wraith> if you just use dependent typing, it's types all the way up. :) <--- ^_^
08:15:32 <Saizan> c_wraith: "higher-kinded polymorphism" is already taken for what haskell has: forall (m :: * -> *) . ... afaict
08:15:42 <c_wraith> oh, right.
08:15:54 <c_wraith> What did I mean.  Oh, right, kind polymorphism
08:16:43 <djahandarie> Why does dependent types mean "types all the way up"?
08:16:50 <djahandarie> You still normally have distinctions between the sorts
08:17:06 <benmachine> http://www.reddit.com/r/dependent_types/comments/dqlan/russells_paradox_in_agda_using_typeintype/
08:17:14 <djahandarie> And "all the way up" seems to imply an infinite tower of universes
08:18:44 <benmachine> http://code.haskell.org/Agda/test/succeed/Hurkens.agda <- why Set : Set is a bad idea, aiui
08:23:06 <mokus> if we got kind polymorphism, i wonder how much longer it would be before we started asking for kind^2 polymorphism
08:23:37 <mokus> not to say kind polymorphism wouldn't be great, i just genuinely wonder how long it would be "enough"
08:23:44 <quicksilver> benmachine: hmm, looks like that HTTP server needs to set UTF8 headers on that.
08:23:46 <Botje> maybe moore's law also applies to type systems..
08:23:54 <quicksilver> benmachine: unless it's my browser being stupid.
08:23:57 <edwardk> djahandarie: looks like i'll be getting in a couple hours before you. switched to a flight, since it looks like it'll cost 1/3rd as much to fly in and out, and save hours.
08:24:24 <edwardk> saved by copumpkin's awesome travel deal finding skills
08:24:52 <djahandarie> Hmmmmmm
08:25:28 <Guest40272> oh jeez
08:25:59 <OceanSpray> Well, why stop at three levels?
08:26:20 <Phyx-> lol, so why do you guys do when you meet up? throw fluffy lambdas at eachother?
08:26:29 <mokus> OceanSpray: exactly
08:26:29 <benmachine> quicksilver: worksforme
08:26:35 <edwardk> phyx-: sometimes
08:26:52 <EvanR> anyone have experience with the win32 bindings? :)
08:26:56 <OceanSpray> In fact, it seems to me that there doesn't need to be some sort of syntactic distinction between the type language and any kind^n language
08:27:05 <edwardk> phyx-: i think shapr's are razor sharpened though, so you have to be careful that he doesn't reach into the wrong bag
08:27:09 <djahandarie> Flying is more of a pain in the ass though. Will probably just stick with amtrak
08:27:21 <mokus> nope, just a heirarchy of universes like in intuitionistic type theory
08:27:28 <Phyx-> edwardk: :O
08:27:37 <OceanSpray> Types aren't turing complete or predicative, so the quickest way to get EVERYTHING is to have a means of "lifting" types to the kind level.
08:27:44 <Phyx-> lol, I would like to see that
08:28:10 <OceanSpray> and lifting kind(n) to the kind(n + 1) level
08:28:15 <OceanSpray> and so on and so forth
08:28:29 <EvanR> djahandarie: watch out for derailings!
08:28:32 <djahandarie> CoC is impredicative. Martin-Lof TT has a predicative hierarchy
08:28:34 <mokus> GADKs ;)
08:28:38 <EvanR> but i agree its more peaceful
08:28:47 <OceanSpray> I meant in Haskell, rather
08:29:47 <dylukes> Could someone explain to me what impredicative vs predicate means?
08:30:07 <OceanSpray> take types as we have them now, what with the quantification and the type families basically being type-level functions,
08:30:17 <Phyx-> djahandarie: but then you'll miss getting groped by the TSA
08:30:18 <OceanSpray> use some syntax to lift them up levels
08:30:28 <OceanSpray> boom, you got the infinite tower of universes.
08:30:52 <djahandarie> OceanSpray, there is some work in this area for Haskell already
08:31:04 <djahandarie> Without syntax, though.
08:31:15 <OceanSpray> oh?
08:31:27 <djahandarie> Originally it was going to collapse the type and kind level, but apparently that has changed so I'm not sure what's happening anymore...
08:31:45 <poucet> @hoogle [a] -> [a]
08:31:45 <lambdabot> Prelude cycle :: [a] -> [a]
08:31:45 <lambdabot> Prelude init :: [a] -> [a]
08:31:45 <lambdabot> Prelude reverse :: [a] -> [a]
08:31:55 <OceanSpray> "collapsing" as in * : *
08:32:04 <zygoloid> dylukes: http://tinyurl.com/6fjftot
08:32:09 <edwardk> heya poucet, long time no see
08:32:16 <dylukes> Thanks much.
08:32:27 <djahandarie> dylukes, if a sort is predicative, that means a family of types in that sort is not a type in the sort and cannot be applied on itself.
08:32:36 <OceanSpray> or "collapsing" as in creating an analogous new kind every time you define a new type?
08:32:45 <dylukes> Does TaPL cover the STLC (and maybe System F?)
08:32:53 <dylukes> Wait. Of course it covers STLC.
08:32:54 <dylukes> >_>
08:33:05 <dylukes> Wouldn't make much sense if it just covered the untyped...
08:33:13 <edwardk> dylukes: =) yes of course
08:33:14 <djahandarie> dylukes, it covers both, I think. But I haven't read it.
08:33:32 <dylukes> I should keep reading that. I have time now heh.
08:36:04 <djahandarie> dylukes, if you're looking for something else to read also, you should try Pierce's software foundations book (which is free and online).
08:37:00 <djahandarie> It's mainly about Coq, but you normalization proofs for STLC as a part of it
08:37:41 <djahandarie> s/you/you do/
08:37:59 <mokus> does anyone know whether there's a standalone library that just defines something like HaXml's "OneOfN" types? (generalization of Either to many arities)
08:40:30 <OceanSpray> mokus, isn't that just an algebraic datatype?
08:40:57 <mokus> yes, but a polymorpic N-cotuple
08:41:54 <Phyx-> hmm, either i'm confused, or ghc is..
08:44:18 <mokus> if there isn't one I don't mind throwing one together, just wouldn't want to duplicate something that simple
08:55:07 <Phyx-> instances are still automatically exported / imported right?
08:55:25 <benmachine> Phyx-: right
08:55:42 * Phyx- wonders why ghc is saying it can't find an instance then
08:56:05 <benmachine> Phyx-: how is it saying it
08:56:31 <Phyx-> No instance for (Hs2lib-0.4.9:WinDll.Debug.Stack.Stackable Stack)
08:56:32 <Phyx-> ***       arising from a use of `toNative'
08:57:06 <Phyx-> but it's finding pushStack, so the module which exports that instance is in scope..
09:00:19 <quicksilver> Phyx-: note the version number in the error.
09:00:40 <Phyx-> quicksilver: i removed and rebuild the library
09:00:41 <quicksilver> Phyx-: I *think* when it goes to the trouble of saying the version number, it means two different versions of that class are both in the project.
09:00:46 <quicksilver> I could be wrong.
09:01:08 <quicksilver> but I think that means you have an instance of Hs2lib-something.else:WinDll.Debug.Stack.Stackable, just not 0.4.9
09:01:34 <Phyx-> it might be possibly picking up the one on my path..
09:01:50 <Phyx-> i'm testing the library on a sample file, which happens to have the original in it's path..
09:02:29 <Phyx-> *moves*
09:02:47 <Phyx-> heh
09:02:57 <Phyx-> quicksilver: yeah.. that was it :/
09:03:04 <quicksilver> hurrah :)
09:03:41 <Phyx-> I'm slipping... I shouldn've known that :/
09:05:31 <Watermind> just one more question about names...  how do you call functions  f : () -> A    or categorically speaking, morphisms  f : 1->A
09:06:17 <Watermind> it should have something to do with "points"... but I don't remember any particular name
09:06:50 <siracusa> I'd say "initial" something, but not sure
09:07:56 <Watermind> siracusa: hmm that seems related with an initial object rather than a terminal one
09:08:10 <shapr> edwardk: razor lambdas?
09:08:12 <Watermind> i.e.  f : Void -> A
09:08:44 <Watermind> I'm talking about a function/morphism from the terminal type/object
09:09:39 <quicksilver> Watermind: morphisms 1->A are sometimes called 'elements' or 'points'
09:09:47 <quicksilver> because, in Set they are precisely that.
09:09:55 <sanjoyd> Suggestions on implementing a control flow graph (for a toy imperative language) in Haskell?
09:10:01 <quicksilver> so in other categories we sometimes think they are 'analogous' to elements.
09:10:05 <sanjoyd> Any nice things I should be aware of?
09:10:21 <Watermind> quicksilver: right... I wasn't sure if it was just 'point' or some longer name with point on it
09:10:56 <ion> sanjoyd: Do you mean something like graphviz would output?
09:11:10 <Watermind> quicksilver: by the way what about   1-> TA where T is a monad?  do you just call it a point in the kleisly category or is there some name you're aware of?
09:11:19 <Watermind> "kleisli"
09:12:00 <sanjoyd> ion: probably. I need to be able to manipulate the CFG in memory.
09:12:43 <ion> sanjoyd: This may or may not be helpful, but i used the graphviz package to generate <http://heh.fi/haskell/functors/>: https://github.com/ion1/functors/blob/master/Functors.hs
09:14:43 <Saizan> sanjoyd: seen hoopl?
09:14:49 <sanjoyd> Saizan: no, will do.
09:15:15 <sanjoyd> I remember reading Peyton Jones talking about a way to represent a CFG as a Zipper in GHC.
09:15:24 <sanjoyd> (In Coders at Work).
09:15:30 <sanjoyd> I'll probably check that out too.
09:16:02 <quicksilver> Watermind: no, I'm not aware of a special name although I wouldn't be *that* surprised to hear there was a special name.
09:16:16 <sanjoyd> Oh, okay; he could have been talking about Hoopl itself.
09:17:44 <Watermind> quicksilver: yeap, pretty much what I thought :) thanks
09:18:43 <edwardk> shapr: wasn't sure, between the machete collection and all. besides i'm pretty sure you've thrown them on channel at least ;)
09:19:45 <edwardk> shapr is the only person i know of who just decides to drive across the country with a car full of machetes
09:20:53 <zygoloid> which country?
09:21:26 <edwardk> the US
09:21:30 <dylukes> hahaha
09:26:05 <shapr> edwardk: haha
09:26:08 <cizra2> Hi
09:26:32 <shapr> @remember edwardk shapr is the only person i know of who just decides to drive across the country with a car full of machetes
09:26:33 <lambdabot> It is forever etched in my memory.
09:26:39 <cizra2> > let my_min = head . sort
09:26:40 <lambdabot>   not an expression: `let my_min = head . sort'
09:26:40 <cizra2> @type my_min
09:26:41 <lambdabot> Not in scope: `my_min'
09:26:49 <cizra2> What's the syntax to define functions for lambdabot?
09:27:21 <cizra2> I'm interested in seeing lambdabot's opinion of the type of my_min, defined as I tried above.
09:27:48 <akosch> I think there is a vim plugin for showing the unicode lambda symbol in haskell source instead of '\', but I forgot what it was called... anyone using it?
09:27:53 <ion> :t head . sort
09:27:53 <lambdabot> forall a. (Ord a) => [a] -> a
09:28:06 <cizra2> ion: Nah, I want it to define and remember the function.
09:28:19 <ion> @define myMin = head . sort
09:28:29 <ion> Hm, i guess not.
09:28:33 <cizra2> @type myMin
09:28:33 <lambdabot> Not in scope: `myMin'
09:28:33 <ion> @let myMin = head . sort
09:28:35 <lambdabot>  Defined.
09:28:37 <cizra2> @type myMin
09:28:37 <lambdabot> forall a. (Ord a) => [a] -> a
09:28:43 <cizra2> oh? cool
09:29:14 <cizra2> Just for the sake of experiment, would anyone care to do the same in ghci? It has a rather ... unexpected result.
09:30:42 <ion> cizra2: :set -XNoMonomorphismRestriction
09:31:03 <cizra2> ion: hehe, no need. I was just very very surprised when I saw this, as was my advisor, a Haskell expert.
09:31:19 <ion> http://www.haskell.org/haskellwiki/Monomorphism_restriction
09:31:24 * cizra2 nods
09:33:54 <fazzone> what is the unexpected result?
09:34:07 <ion> It defaults the polymorphic a into ()
09:34:12 <cizra2> my_min :: [()] -> ()
09:34:35 <kmc> @check \xs -> xs == reverse xs
09:34:36 <lambdabot>   "OK, passed 500 tests."
09:36:17 <applicative> ghci didn't used to have that default, it seems to me, so it was surprising the first time one saw it...
09:37:18 <cizra2> Why did Haskell choose the empty tuple to represent Unit/void/NULL?
09:37:54 <fazzone> why not?
09:39:19 <ion> Do the authors of fgl, Martin Erwig and Ivan Lazar Miljenovic, happen to be here?
09:39:48 <cizra2> fazzone: As good as any choice, but somebody obviously made it.
09:40:03 <EvanR> cizra2: its not an empty tuple, its just spelling
09:42:06 <cizra2> EvanR: Ah, so the choice is the other way around? Choosing () to be the syntax for Unit?
09:42:32 <EvanR> that would make sense to me
09:42:38 <EvanR> because its not a tuple
09:42:57 <applicative> EvanR, why not a 0-ple?
09:43:05 <EvanR> is such a thing even possible
09:43:09 <EvanR> why not a -1 ple
09:43:29 <monochrom> mathematicians define 0-ple to be unit anyway
09:43:30 <applicative> a function is a -1ple.
09:43:47 <EvanR> o_O
09:43:50 <EvanR> brain explode
09:43:54 <mokus> interpreting tuples as products, a 0-tuple makes sense and would have exactly one element
09:44:18 <mm_freak> applicative: a function is a duple
09:44:29 <applicative> a duple?
09:44:40 <ion> A number of languages seem to use () one way or another. http://en.wikipedia.org/wiki/Unit_type#In_programming_languages
09:44:46 <monochrom> see also my http://www.vex.net/~trebla/homework/empty.html for guidance on how to treat the 0 case
09:45:18 <mm_freak> applicative: mathematically a function is a subset of a product of two sets
09:45:21 <applicative> I was thinking, absurdly, that (a,b) stores two things, () stores 0 things,  and (a -> b) eats things
09:45:33 <mm_freak> that's really absurd =)
09:46:29 <mm_freak> well functions as tuples don't make much sense in haskell, because you can't sensibly define relations in terms of tuples
09:46:39 <mokus> functions as exponentials make a lot more sense
09:46:40 <mm_freak> only full products
09:47:17 <monochrom> there is an adjunction between storing and eating, between tupling and ->. you are on to it.
09:48:24 <monochrom> adjunction is a general way to say "inverse"
09:48:41 <danharaj> not really
09:49:44 <arw__> with matrices, M^adj = M^-1 is a special case, e.g.
09:53:38 <monochrom> the category theory adjunction, not the matrix adjunction
09:54:17 <monochrom> they are as related as "natural transformation" and "natural number"
09:55:08 <arw__> that overloaded terminology will make me go crazy, someday.
09:55:13 <applicative> hm, there you are isn't (_,a) adjoint to (a -> _) so functions are kind of negative tuples. ....
09:56:06 <mokus> no, the relation between tuples and functions is more like the reltion between 2^x and x^2
09:56:06 <EvanR> this is a brilliant new realm of maths
09:56:27 <monochrom> yes applicative
09:56:38 <applicative> my mental horizons are really expanding now that I have the idea of a negative tuple
09:57:33 <mercury^> monochrom: actually, they are related a bit more via categorification of linear algebra.
09:59:15 <mercury^> monochrom: 2^x and 2*x, rather.
10:01:34 * hackagebot iptadmin 1.0.1 - web-interface for iptables  http://hackage.haskell.org/package/iptadmin-1.0.1 (EvgenyTarasov)
10:18:49 <arw__> http://www.ats-lang.org/DOCUMENTATION/proginats/HTML/x594.html <- wtf. how could you even begin to imagine a way to write that more unelegantly?
10:26:37 <Shammah> hey
10:26:51 <fazzone> Is there a neater/pointfree way to write a function g :: [a] -> [a] than g f (a:b) = f a : b  -- apply function f to the first element of the list and leave the rest untouched?
10:27:36 <Shammah> what is the difference between    let x = negate $ tan $ cos 50   and   let x = negate . tan . cos 50
10:28:03 <fazzone> $ is application, . is composition
10:28:21 <danharaj> well, first of all, the second will be a type error
10:28:22 <fazzone> $ takes a function and a value, and gives you the answer -- . takes two functions and give you a new function
10:28:26 <danharaj> :t negate . tan . cos 50
10:28:26 <lambdabot> forall a (f :: * -> *). (Floating a, Floating (f a), Functor f) => f a
10:28:29 <danharaj> wait what.
10:28:33 <Shammah> oh
10:28:34 <conal> :)
10:28:44 <danharaj> :t cos 50
10:28:45 <lambdabot> forall t. (Floating t) => t
10:28:51 <danharaj> :t tan . cos 50
10:28:52 <lambdabot> forall a (f :: * -> *). (Floating a, Floating (f a), Functor f) => f a
10:28:53 <mokus> :t (.)
10:28:54 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
10:28:59 <danharaj> oh right
10:29:01 <danharaj> Caleskell
10:29:04 <Shammah> so $ fills it in while . turns it into 1 function?
10:29:11 <fazzone> Pretty much, yeah
10:29:19 <Shammah> ah, that explains, thanks!
10:29:34 <danharaj> Shammah: (f $ x) is like (f x).
10:29:43 <danharaj> except the binding is less tight.
10:29:45 <siracusa> :t negate Prelude.. tan Prelude.. cos 50
10:29:46 <lambdabot> forall b a. (Floating b) => a -> b
10:29:47 <Shammah> aha
10:29:49 <conal> danharaj: type-checks even in ghc haskell
10:29:57 <conal> danharaj: negate . tan . cos 50 :: (Floating (a -> c), Floating c) => a -> c
10:30:04 <danharaj> heh
10:30:22 <danharaj> Unreasonable instances aside.
10:30:29 * conal often uses the numeric instances for functions
10:30:41 <danharaj> actually that's not too unreasonable.
10:31:00 <conal> which work uniformly for all applicatives, not just (->) a
10:31:28 <benmachine> (caleskell *is* ghc haskell, it just has a modified prelude)
10:31:44 <mokus> it'd be less unreasonable if Eq and Show weren't included in Num
10:31:45 <danharaj> then it's not ghc haskell. The prelude is part of the standard.
10:32:11 <benmachine> danharaj: importing the prelude qualified is
10:32:18 <benmachine> or importing it hiding whatever
10:32:29 <conal> mokus: yep.
10:32:30 <danharaj> well whatever
10:32:34 <benmachine> it doesn't really have a modified prelude, it just has different imports
10:32:42 <danharaj> the point is that LambdaBot has a hip and edgy composition operator.
10:32:46 <benmachine> sure
10:33:02 <benmachine> but she doesn't do anything particularly dark and devious 'sall I'm saying
10:33:11 <conal> i'd rather LambdaBot used Category's (.)
10:36:21 <mokus> anyone know approximately how far off ghc 7.2 is?
10:36:32 <flux> arw__, I begun reading it, and at least they have an excuse: "Clearly, the functions board_get and board_set are defined in a rather unwieldy fashion. This is entirely due to the use of tuples for representing board configurations. If we could use an array to represent a board configuration, then the implementation would be much simpler and cleaner. However, we have not yet covered arrays at this point."
10:36:47 * mokus is wondering whether to wait for it or build a 'safe haskell' ghc from HEAD
10:39:31 <flux> arw__, but at least it cannot over-index :). no idea what 'bd' does though..
10:41:24 <arw__> bd is a tuple of 8 ints where they encode the queens' positions. each int is a row.
10:41:42 <arw__> the bd.6 syntax extracts the 6th element from bd
10:43:13 <flux> oops, indeed
10:44:17 <arw__> i'm still trying to decide wether the language is a little weird or just the book...
10:47:43 <dmwit> mokus: Probabyl better asked in #ghc.
10:48:23 <mokus> dmwit: thanks, forgot they had their own channel
11:09:26 <fazzone> Is there a way to do sort-of fall-through-ish behavior with pattern matches?
11:10:36 <scooty-puff> you could produce an int for like conditions, then case <...> of on that result again
11:10:42 <scooty-puff> not very good of a way though..
11:11:42 <fazzone> Yeah, but that's not really fall-through, because you have to go through the first step (generate the int) to get to the second place
11:14:19 <kmc> fazzone, do some 'let' or 'where'
11:15:09 <fazzone> More detailed problem description: I'm reading an assembly source file, and I want to do certain things with all the various types of jump instructions (jmp, jge, jz, etc)...Ideally, I would be able to patten match on the "j" and fall through if the opcode isn't a jump instruction
11:15:30 <kmc> oh
11:15:34 <kmc> you might want a real parsing library then
11:15:40 <kmc> that's what they do
11:15:46 <kmc> i recommend Parsec
11:16:16 <fazzone> I s'pose...seems like overkill though
11:16:40 <arw__> its. not. your code will look a lot nicer than with pages of 'case' statements.
11:16:47 <kmc> anything other than assembly language is overkill
11:17:22 <kmc> i think it's important to distinguish between "this thing is actually clumsy for my purpose" and "this thing does more than i need but is still useful for what i'm doing"
11:18:07 <hpaste> fazzone pasted “Fall-through?” at http://hpaste.org/49049
11:25:31 * ski idly wonders why one'd only want to move constants into the `PC' register
11:26:03 <fazzone> ski: It's a re-write of a static-checker-thing someone else wrote in VB
11:26:19 <mekeor> "Functional programming requires that functions are first-class, which means that they are treated like any other values and can be passed as arguments to other functions or be returned as a result of a function. Being first-class also means that it is possible to define and manipulate functions from within other functions." ( http://www.haskell.org/haskellwiki/Functional_programming ) -- what does the last sentence mean?
11:26:21 <fazzone> so...I don't know?
11:26:31 <ski> yeah, but would one want to add such a restriction ?
11:27:19 <kmc> mekeor, uh, it means what it says? which part is not clear?
11:27:20 <ski> mekeor : e.g. `makeAdder a = add_a where add_a b = a + b'
11:27:21 <arw__> mekeor: that you can have functions that operate on functions and create or change them?
11:27:54 <fazzone> I dunno, seems ratuer stupid actually...You can only jump to constant values, so mov-into-PC is actually sometimes necessary
11:28:03 <mekeor> how can a function change another function??
11:28:08 <fazzone> It can't
11:28:19 <kmc> it can return a new function based on an old one
11:28:19 <fazzone> it can give you another function that depends on the input-function
11:28:35 <mekeor> kmc: i agree, yep
11:28:38 <arw__> mekeor: ok, thats a little imprecise of me. you can use an input function and return a changed output function.
11:28:57 <mekeor> yep.
11:29:14 <mekeor> sth like map, e.g., right?
11:29:17 <kmc> sure
11:29:25 <mekeor> ic, thanks :)
11:29:50 <kmc> your code can also update a mutable variable whose contents are a function
11:29:55 <arw__> !t flip
11:30:01 <ski> fazzone : i think it would be better to parse the code into an AST, and then do the static-checking on that instead ..
11:30:06 <kmc> which is "changing a function" in different imprecise terms
11:30:37 <mekeor> kmc: can u give an example, pls?
11:30:49 <kmc> @wn u
11:30:49 <lambdabot> *** "u" wn "WordNet (r) 2.0"
11:30:50 <lambdabot> u
11:30:50 <lambdabot>      adj : (chiefly British) of or appropriate to the upper classes
11:30:50 <lambdabot>            especially in language use
11:30:50 <lambdabot>      n 1: a nitrogen-containing base found in RNA (but not in DNA) and
11:30:51 <lambdabot> [5 @more lines]
11:30:59 <fazzone> ski: probably, but an AST for assembly would pretty much be a table, or at best [(Instruction, [Operand])]
11:31:00 <mekeor> u=you
11:31:03 <kmc> oh
11:31:25 <mekeor> :)
11:31:31 <kmc> mekeor, giving an example in Haskell is not the easiest
11:31:48 <ski> fazzone : more or less, yes. but it's not clear to me that e.g. `all isDigit src' is correct there
11:31:48 <mekeor> oh :)
11:32:04 <kmc> mekeor, because mutable variables are not the default
11:32:53 <mekeor> kmc: oh, right :D hehe
11:33:19 <ski> fazzone : also, with an AST, you could factor all the `jne',`jeq',&c. instructions to a single instruction with a field describing which variant it is
11:33:48 * Lymee is summoned by a djahandarie 
11:33:53 <djahandarie> :-)
11:34:02 <djahandarie> Now read http://learnyouahaskell.com
11:34:05 <djahandarie> And ask questions :D
11:34:08 <Lymee> Am I obligated now?
11:34:12 <ski> fazzone : "WHY is jmp differnet from call" -- different in what way ?
11:34:26 <fazzone> ski: Well, it's supposed to warn you when you're using just a number -- without a # you mean that value of that location in memory, which is probably not what you want (use a label)
11:34:51 <fazzone> ski: you 'call #labal' but 'jmp label'
11:34:54 <djahandarie> Lymee, if that encourages you to do it... yes ;)
11:35:35 <ski> fazzone : well, what if the memory address is an input ?
11:36:39 <mokus> call means to store a return address and then jmp
11:36:45 <Lymee> Eh? I thought "jmp" and "call" should be the same except one pushes an address to the stack.
11:36:48 <mokus> either can be inderect
11:36:57 <fazzone> You mean, what if that memory address has special meaning?  The assembler has a C-like preprocessor that gives labels to special addresses
11:37:06 <Lymee> s/I thought//
11:37:50 <ski> fazzone : no, i mean if the memory address isn't known until run-time, so is passed in a register (say), to the routine
11:38:23 <fazzone> Yeah, call is just shorthand.  But the MSP430 (chip i'm using) is RISC, so jumps are done with offsets, while call moves a register directly into the PC
11:38:30 <ski> (think higher-order subroutines)
11:38:37 <fazzone> ski: Well then (all isDigit) isn't true, is it?
11:39:05 <kmc> sometimes call stores to a register rather than the stack
11:39:13 <kmc> in RISC architectures
11:39:24 <mokus> yea, in PPC there's a dedicated 'link register' for that purpose
11:39:32 <fazzone> MSP430 pushes the address to the stack
11:39:36 <kmc> the callee is responsible for pushing the link register if he/she is not a leaf function
11:39:57 <ski> fazzone : how complicated can effective addresses be here ?
11:40:51 <fazzone> ski: for reference: http://sites.google.com/site/arch1utep/home/msp-430/full-msp430-instruction-set
11:44:00 <fazzone> ski: re: " memory address isn't known until run-time, so is passed in a register" -- Are we talking about the non-constant MOV'd into PC warning, or the not-using a # sign for numerical constants warning?
11:45:46 <ski> the former
11:46:39 <fazzone> Yeah, so if the address isn't known until run-time, how can it be a constant, as in "MOV 12345, PC" ?
11:47:45 <ski> i was thinking more of `MOV R1,PC' or something like that
11:48:27 <fazzone> Yeah, so then the predicate (all isDigit) isn't true of the token "R1", so you don't get the warning
11:48:54 <ski>   checkAddressMode ("mov" : [src,"PC"]) = if head src == '#' then Nothing else Just "MOV x, PC -- missing #"
11:48:58 <ski> that one will still hit
11:49:28 <Lymee> ASM discussion in #haskell...
11:49:40 <Lymee> Exact opposites much?
11:49:47 <ski> well, Haskell code manipulating assembler :)
11:49:51 <fazzone> Oh, yeah -- I do actually agree with you on that -- I think I'll remove that check, it's rather strange
11:50:12 <Lymee> ski, still opposites.
11:50:43 <ski> fazzone : it might be a "make sure you really want to do this"-warning, but in some cases this is fully legitimate, is what i'm trying to say
11:51:25 * ski idly wonders whether Lymee started with LYAH yet :)
11:51:52 <Lymee> I remember reading some of it a few years ago but remembering nothing of it.
11:51:53 <fazzone> ski: I agree
11:51:53 <Lymee> >.>
11:52:06 <Lymee> How transferable is Scala knowledge to Haskell?
11:52:49 <ski> fazzone : i.e. it might be nice if you could individually turn this warning on or off, or maybe even give some annotation in the source to exclaim that you want this
11:52:56 <kmc> Lymee, learning Haskell by analogy to another language is generally a bad idea
11:53:01 <kmc> but Scala is closer than some
11:53:35 <Lymee> kmc, a lot of the concepts there seem quite similar to what exists in Haskell.... except only those concepts exist in Haskell.....
11:54:11 <ski> fazzone : anyway, i would still recommend replacing the instruction and lists of operand strings with a proper AST. at least i would feel much more comfortable manipulating that
11:54:50 * djahandarie just walked in, but thinks that an AST is probably the right way to do any manipulation of ASM
11:54:56 <fazzone> ski: Probably a good idea -- I haven't gotten around to learning Parsec yet and I hear good things about it
11:56:15 <fazzone> I mean, the reason I didn't go for it immediately is because you don't really (in my view) gain much more benefit by structuring it into an AST -- there's not much structure to take advantage of
11:56:46 <Lymee> ASM? Syntax /tree?/
11:56:53 <Lymee> This is a joke, right?
11:56:57 * Lymee runs
11:57:22 <Chaze> it sounds kinda weird indeed. why would you reconstruct a tree from asm?
11:57:25 <ski> well, a list is a degenerated tree :)
11:59:00 <fazzone> Well, even with assembly, it's still a good idea to lex it so you get to work with token-types instead of strings (I agree my code is deficient in this regard) -- But you don't get a lot of benefit from stuffing it into a tree.  Like I said, the structure would pretty much look like [(Instruction, [Operand])]
11:59:47 <kmc> depends what you're doing
11:59:52 <kmc> sometimes you want a graph of basic blocks
12:00:03 <kmc> that's not really syntax, though
12:00:19 <ski> you could probably do `[exists operands. (Instruction operands,operands)]' ..
12:01:04 <ski> (so each instruction would know how many operands it took)
12:01:14 <kmc> could be a GADT also?
12:01:22 <ski> yeah, that's what i meant
12:01:40 <fazzone> What
12:02:13 * ski wonders whether doing a GADT like that would have any advantage over bundling the operands inside the instructions already
12:02:48 <mokus> it could save you from having to write a separate instruction enumeration
12:03:22 <fazzone> Why would you need to have more than one instruction type?
12:04:07 <mokus> you wouldn't with the [(Instr, [Arg])] encoding, but you would if Instr contained the arguments
12:04:07 <ski> fazzone : very roughly, i meant something like :
12:04:45 <ski>   data Instruction :: * -> *
12:04:51 <ski>     where
12:04:57 <ski>     JMP :: Instruction Operand
12:05:03 <ski>     MOV :: Instruction (Operand,Operand)
12:05:05 <ski>     ...
12:05:24 <fazzone> So what about RET?  Instruction () ?
12:05:36 <ski> though this would be better if you changed it to not allow the second operand of `MOV' to be an immediate constant
12:05:40 <ski> fazzone : aye
12:06:34 <ski> so you could get some static guarantees guarding against malformed instruction-operands-pairs
12:07:01 <ski> of course, you could also do
12:07:13 <fazzone> the design is nice -- Things like that make the assembler error out though, so no point expending effort to check for them
12:07:41 <ski>   data InstructionWithOperands = JMP Operand
12:07:43 <ski>                                | MOV Operand Operand
12:07:46 <ski>                                | ...
12:08:52 <ski> the previous GADT-version is in some sense more powerful -- the question is more or less whether there's any use for that extra power -- otherwise you might as well use the latter version
12:09:45 <ski> fazzone : *nod*, the idea being to make it impossible to express malformed code in the AST, so you can concentrate on the more interesting stuff
12:11:15 <ski> mokus : hm, i'm not sure what you mean ..
12:11:23 <fazzone> ski: yup.  Same reason, no point in expending effort to check syntax because the input has already been run through the assembler so it's guaranteed syntactically valid
12:12:00 <mokus> ski: well, in some places you may want a type that is instruction without operand - in the GADT+existentials case, that's easy, but in the ADT case it would require a separate type
12:12:31 <ski> ah ok. yes, that's a good point
12:13:50 <fazzone> What do you mean by GADT+existentials?
12:14:12 <ski> the `data Instruction :: * -> * where ...' above is a GADT-style data type definition
12:15:17 <dankna> wait, how do you get an instruction-without-operand type out of that?
12:15:30 <dankna> that sounds interesting/useful
12:15:32 <fazzone> Instruction ()
12:15:32 <ski> if you have then basically `type InstructionWithOperands = exists operands. (Instruction operands,operands)' (you'll need a bit clumsier actual syntax), then you'll get `[InstructionWithOperands]' as your type of lists of instructions
12:15:33 <ocharles> What's the desirable way to use random values in my code? For example, I have a function: insertBook :: Book -> Model (WithGid Book) which inserts a book into the database generating a new random GID for it
12:15:50 <dankna> ah!  gotcha
12:15:56 <ski> dankna : `exists operands. Instruction operands'
12:16:00 <ocharles> Model being a specialization of IO. I'm wondering if I just give up more referential transparency and update the random generator state, or if insertBook should take something else
12:16:14 <ski> `Instruction ()' is the type of instructions which have no operands (like `RET')
12:16:43 <mokus> incidentally, the 'exists operands. (Instruction operands,operands)' is "DSum Instruction" in my recently-released dependent-sum package
12:16:45 <EvanR> ocharles: if Model is IO something, then just use randomIO
12:17:06 <dankna> nice trick, have to remember it
12:17:09 <ocharles> EvanR: yea, it is
12:17:26 <EvanR> so you arent referentially transparent in the first place ;)
12:17:27 <ski> mokus : btw, `exists i. (f i,g i)' is more generally useful
12:17:35 <ocharles> EvanR: I know, that's why I said give up even more
12:17:39 <ocharles> which I know doesn't really make sense
12:17:40 <ocharles> :)
12:17:45 <EvanR> its like more preganant though
12:17:58 <ocharles> preganant?
12:17:59 <ski> `IO' is referentially transparent ..
12:18:01 <EvanR> pregnant
12:18:04 <mokus> ski: yea, i thought about going that route but i found that the large majority of the time I use it, 'g' would be Identity
12:18:09 <ocharles> yea, I still don't know what you mean by that though
12:18:12 <mokus> so I decided to opt for the simpler version
12:18:17 <ocharles> insert a book will make a baby? :P
12:18:25 <ski> mokus : you could make a shotcut
12:18:36 <fazzone> Not sure what the exists operands. is for -- Why do you need that?
12:18:43 <EvanR> ocharles: id just question why you need io to insert a book into something
12:18:59 <ski> fazzone : just `Instruction operands' has `operands' as a free variable
12:19:02 <mokus> ski: true... I'm open to changing the library if it'd be more popular with 2 type params
12:19:02 <EvanR> unless its a networked bookcase or something
12:19:08 <ocharles> EvanR: it's inserting into a postgresql database
12:19:25 <mokus> ski: but i do find it's pretty nice to be able to match on "Foo :=> bar"
12:19:27 <EvanR> then you could even tell sql to generate the id
12:19:34 <ski> fazzone : in some cases that doesn't matter (you can often make code polymorphic in that), but sometimes you really want to bind `operands'
12:19:36 <fazzone> ski: Yes, so how is exists operands. Instruction operands any differnet?
12:19:41 <mokus> ski: (without the Identity noise)
12:19:42 <ocharles> EvanR: I normally do, I should check if PG can do v4 uuid's
12:19:58 <EvanR> v4 or whatever
12:20:17 <ski> fazzone : different from what ?
12:20:22 <ski> fazzone : from `Instructions operands' ?
12:20:26 <fazzone> ski yes
12:20:30 <ocharles> it can, but I need an extension. hrm, I guess that's still more desirable than DB logic in my haskell code
12:20:36 <ski> fazzone : the latter has `operands' as a free variable
12:20:45 <fazzone> And the former doesn't ?
12:20:55 <ski> aye
12:21:00 <fazzone> ski: The difference being that with the
12:21:10 <fazzone> *existential quantifier, you can't use Instruction by itself?
12:21:14 <ski> fazzone : `foo :: Foo -> Instruction operands' is very different from `foo :: Foo -> exists operands. Instruction operands'
12:22:00 <fazzone> Okay, but how is it different?
12:22:31 <kmc> http://mainisusuallyafunction.blogspot.com/2010/10/quantification-in-haskell.html
12:22:46 <ski> fazzone : the former would normally be interpreted to mean `foo :: forall operands. Foo -> Instruction operands', and here the *caller* will decide what type `operands' should be and `foo' will have to return an `Instruction operands' for *that* type `operands' which the caller chose
12:23:17 <ski> fazzone : in the `foo :: Foo -> exists operands. Instruction operands' case, the *callee* `foo' will decide the type `operands' (so it can basically return any instruction it feels like)
12:23:30 <dankna> really I wish they were called callerpicks and calleepicks rather than forall and exists
12:23:59 <fazzone> So you can't pattern-match on 'Instruction a' if you use exists?
12:24:01 <ski>   calleepicks f g. fmap f . fmap g = fmap (f . g)  -- ? :)
12:24:11 <ski> (s/callee/caller/)
12:24:12 <kmc> they should be AbstractTypeFactory and ParametrizedTypeVisitor
12:24:22 <kmc> then Haskell will finally catch on in The Enterprise
12:24:29 <dankna> ugh haha
12:25:48 <ski> fazzone : that's irrelevant from the point here. the point is that someone must decide which type `operands' should be. either the caller or the callee can decide that, and the behaviour is very different depending on who does it
12:26:09 <EvanR> kmc: when gtk works in windows... and does not suck...
12:26:46 <EvanR> who the hell came up with these bindings
12:26:48 <ski> fazzone : in your case, typically you'd either work with (a) an `exists operands. (Instruction operands,operands)', i.e. an instruction with compatible operands
12:27:14 <ski> fazzone : or (b) an `exists operands. Instruction operands', which is just an instruction without operands
12:28:03 <ski> fazzone : in some cases, you could rewrite those to use `forall' instead of `exists', but that's not a change in semantics
12:28:46 <ski> (those cases generally being when you take the instruction (maybe times operands) as input)
12:29:10 <ski> fazzone : oh, and `exists' is just pseudo-synax (currently) :)
12:29:55 <dolio> So is forall.
12:31:06 <parcs> i'll be happy once i can use ∃
12:31:15 <dolio> Or did that get added to 2010?
12:31:19 <dolio> I forget now.
12:34:16 <fazzone> When is forall not superfluous?
12:34:41 <benmachine> > let ∃ = 4 in ∃
12:34:41 <lambdabot>   <no location info>: parse error on input `
12:34:47 <benmachine> > let (∃) = 4 in (∃)
12:34:48 <lambdabot>   4
12:34:49 <fazzone> i.e. when can you not eliminate the string "forall. " from a type declaration (presuming you have a Something =>)
12:34:51 <benmachine> woo
12:35:02 <benmachine> > (∃)
12:35:02 <lambdabot>   Not in scope: `
12:35:08 <benmachine> hm.
12:35:17 <ski> fazzone : higher-rank types
12:35:21 <dolio> > let (∃) = (+) in 5 ∃ 6
12:35:22 <lambdabot>   11
12:35:23 <EvanR> > let (+) = 4 in (+)
12:35:23 <lambdabot>   4
12:35:34 <ski> (also locally scoped type variables (grmbl))
12:35:43 <mokus> @type runST
12:35:44 <lambdabot> forall a. (forall s. ST s a) -> a
12:35:47 <fazzone> > let 2 = 3 in 2+2
12:35:47 <lambdabot>   4
12:35:52 <ski> fazzone : see `runST' ^
12:36:03 <mokus> the forall a. there can be dropped, but not the forall s.
12:36:04 <ski> the `forall s. ' can't be elided
12:36:20 <benmachine> ski: do you dislike the syntax for scoped type variables
12:36:31 <fazzone> hm, i'll read more
12:36:34 <ski> benmachine : yes
12:36:52 <benmachine> ski: why
12:36:59 <benmachine> and/or what would you suggest
12:37:00 <mokus> i've always thought 'let a :: *; ...' would be a nice way of introducing explicitly scoped type vars
12:37:11 <benmachine> mokus: where would you put it?
12:37:22 <ski> benmachine : (a) if anything, type variables should scope over the declaration when *not* using `forall' and *not* scope over it when using `forall'
12:37:28 <mokus> 'myfunc = ... where a :: * -> *', etc
12:37:38 <monochrom> even in math, "for all" is better off as skeptic-pick, and "for some" is better off as prover-pick, too
12:37:53 <ski> benmachine : (b) though i'm still not sure i'd like to couple type signatures with definitions in that way
12:38:26 <mokus> yea, implicitly scoped type vars would be ok with me too
12:38:41 <benmachine> personally I was never that keen on scoped type variables
12:38:48 <benmachine> I've never found them absolutely essential
12:38:54 <mokus> TBH i have no qualms about it the way it is either, and rarely use them
12:38:58 <ski> benmachine : i.e. one could interpret `foo :: Foo a -> Bar a; foo = ..a..' as  `forall a. {foo :: Foo a -> Bar a; foo = ..a..}'
12:39:41 <benmachine> ski: hmm. I wonder how scopedtypevariables interact with typesigs like a, b :: forall ...
12:39:47 <ski> benmachine : if you have local definitions that use some non-local variables, and you want to give type signatures for them, then you need locally scoped type variables
12:39:59 <ski> benmachine : *nod*
12:40:19 <benmachine> ok I can see mokus' idea making a bit more sense
12:40:24 <ski> (otoh, binding local type variables with type ascriptions in patterns is just fine, imo)
12:40:39 <benmachine> it would be nice if we could have let decls in decls
12:41:03 <mokus> there's a lot of things that would be nice in let bindings
12:41:08 <mokus> foreign imports for one
12:41:27 <mokus> instances definitions too, though that could easily get pretty confusing
12:41:50 <erus`> is let like lambda reduce?
12:42:11 <benmachine> I don't like the sound of local instance declarations
12:42:20 <benmachine> that sounds like it could lead to suffering
12:42:28 <mokus> yea, it most definitely could
12:42:37 <ash__> has anyone ever tried to write a MOP (like CL has) for haskell? Just curious
12:42:43 <ski> mokus : would `let a :: * in ..a..' mean `exists a :: *. ..a..' or `forall a :: *. ..a..' ?
12:43:16 <mokus> well, scoped type variables is all about introducing skolem variables isn't it?
12:43:21 <mokus> so i'd think 'exists'
12:43:33 <benmachine> ski: I just understood it to mean "in what follows, usage of 'a' as a type variable means the same thing"
12:43:33 * ski stares blankly
12:43:50 <ski> mokus : with that argument, i'd expect you to reach the opposite conclusion ..
12:44:03 <mokus> for forall, you don't need scoped type vars in the first place
12:44:19 * ski ponders
12:44:58 <mokus> what you're saying is that 'a' is a concrete type that is fixed within the scope of the definition, ie an existentially quantified type
12:45:20 <ski> hm, i might have posed the wrong question
12:45:40 <ski> i suppose typically the use would be like `let a :: *; ..a.. in ...'
12:46:02 <mokus> yea
12:46:26 <mekeor> what are closures? :]
12:46:57 <ski> mekeor : an implementation technique for functions (and other delayed values)
12:47:00 <mokus> in some sense you could say it's forall in the first ... and exists in the second, unless i've got my brain on inside out
12:47:10 <mokus> which is quite possible, i've had more coffee today than usual
12:47:47 <mokus> it's been a long time since i thought about that syntax idea actually
12:47:55 <ski> in `let forall a :: *. ..a.. in ...' we'd have a guarantee of `..a..' being generic in `a'
12:48:19 <ski> while in `let exists a :: *. ..a.. in ...' we'd just know that `a' bound some type in `..a..'
12:48:24 <mekeor> ski: err.. do you talk to me?
12:48:29 <monochrom> I'm pretty sure Skolem invented several things and so two things called "skolem" could mean opposite things because he invented them all
12:48:43 <ski> mekeor : heh, not really, just above :)
12:49:17 <mekeor> ski: ok :D
12:49:30 <monochrom> in fact, "skolemization" alone converts between ∀ and ∃ so it is about both
12:49:34 <mokus> true, i was referring to the constants introduced when eliminating existentially quantified variables
12:49:38 <mekeor> ski: could you maybe give me an example for a closure? (in haskell, of course :D)
12:50:03 * hackagebot reactive-banana 0.4.1.0 - Small but solid library for  functional reactive programming (FRP).  http://hackage.haskell.org/package/reactive-banana-0.4.1.0 (HeinrichApfelmus)
12:50:16 <ski> mekeor : well, it's an implementation-thing
12:51:03 * hackagebot reactive-banana-wx 0.4.1.0 - Examples for the reactive-banana library, using wxHaskell.  http://hackage.haskell.org/package/reactive-banana-wx-0.4.1.0 (HeinrichApfelmus)
12:51:48 <ski> mekeor : but consider `makeAdder a = add_a where add_a b = a + b' -- one common way to implement `makeAdder' is that when given an argument `a', it will bundle up `a' (and also `(+)') together with the piece of code `\b -> a + b', so that if anyone called that function with a value `b', it would look in the "bundle" for the value of `a' (and `(+)') to use
12:53:10 <ski> assuming we call `makeAdder 5', then the closure generated is basically `let a = 5; (+) = primAddInt in \b -> a + b'
12:53:33 <ski> (assuming we're adding `Int's and `primAddInt' is the addition function on them)
12:53:46 * ski wonders whether anything of this makes any sense to mekeor
12:54:10 <mekeor> but i could simpler say "makeAdder a= +a", couldnt i?
12:54:20 <ski> of course
12:54:27 <ski> it's basically the same thing
12:54:44 <monochrom> under the hood, you still have closures
12:54:49 <ski> `(+) a' still has to recall the value of `a' to use
12:54:55 <mekeor> er.. hmm.. i still dont really get it :/
12:55:11 <ski> do you know any assembler (or C) ?
12:55:18 <mekeor> C, yep
12:55:32 <ski> well, in C, functions can't really be closures
12:55:43 <kmc> mekeor, try to write a C function with function pointers such that ( f(x) )(y) = x+y
12:55:50 <monochrom> well let's use alphanumeric variables all along. I write "\x -> f x y", someone has to figure out whose f and whose y they should be
12:57:00 <monochrom> now, the compiler knows by tracing lexical scoping, of course. it still has to record what it figures out into code. "closure" is a common way to record that
12:57:23 <mekeor> kmc: well, i'm not a professional Cprogrammer, :P, so i cant do that (if it's possible at all)
12:57:57 <mekeor> monochrom: hmm
12:58:04 <ash__> whats the type of y and x?
12:58:05 <ski> mekeor : consider `typedef struct { void *environment; int (*)(*code)(void *,int)} endo_int;'
12:58:10 <kmc> mekeor, once 'f' returns, it has to remember x somewhere
12:58:28 <kmc> mekeor, this business of closures is a basic functional programming idea
12:58:32 <kmc> you can read a lot about it online in many languages
12:58:34 <ski> mekeor : this is meant to approximate `typedef exists<T> struct { T *environment; int (*)(*code)(T *,int)} endo_int;'
12:59:17 <ski> mekeor : the idea being that a value of type `endo_int' should represent a function of type `int -> int', but we want to allow these functions to depend on other run-time data, so we need to simulate closures
12:59:43 <hpaste> Burbly pasted “Parsec parser” at http://hpaste.org/49052
12:59:49 <EvanR> monochrom: supercombinators ftw ;)
13:00:21 <burbul> I'm trying to write a Parsec parser that accepts a string beginning and ending with a quote... could someone tell me if this is right?
13:00:23 <burbul> http://hpaste.org/49052
13:00:23 <mokus> EvanR: using supercombinators just moves closure info from the heap to the stack doesn't it?
13:00:50 <burbul> (I'm not very confident about using if inside a do block, and also I'm not sure if 'mzero' is the appropriate way to reject input.)
13:00:57 <mekeor> ski, kmc, monochrom: thank you so far :)
13:00:57 <EvanR> i dont know about heap or stack, but it means you only need to implement partial evaluation rather than closure
13:01:13 <EvanR> partial application
13:01:24 <burbul> (Presumably there's a way to generate a specific error message... would 'fail' be appropriate ?)
13:01:41 <gwern> how unusual, no vandalism on hawiki today
13:02:19 <Cale> burbul: I wouldn't really call that *using* parsec... you're just using the usual list manipulation functions rather than using the parser
13:02:42 <burbul> I'm going to chain that together into more complex parsers
13:03:11 <burbul> I would have liked to build it directly out of simpler parsers, but I had some difficulty due to the greediness of 'many'
13:03:31 <Cale> quoted = do char '"'; text <- many $ noneOf " \t\n\""; char '"'; return text
13:04:02 <Cale> That doesn't handle escapes of course
13:04:03 <burbul> No, the thing inside the quotes is allowed to include a quote itself
13:04:13 <burbul> That's why the greediness of many is a problem
13:04:20 <burbul> I.e.
13:04:21 <burbul> """
13:04:23 <burbul> Is legitimate
13:04:25 <mauke> then how do you know where the string ends?
13:04:32 <burbul> It's followed by whitespace
13:04:46 <Cale> er, then why have quotes at all?
13:04:48 <mauke> what the fuck
13:05:09 <burbul> To distinguish it from something else...
13:05:12 <ski> mekeor : so, we could e.g. write `int twice_code(void *environment,int n) {return call_endo_int(*((endo_int *)environment),n); }  endo_int twice(endo_int f) { endo_int ff = {malloc(f),&twice_code}; return ff; }'
13:05:59 <ski> mekeor : with `int call_endo_int(endo_int f,int n) {return f.function(f.environment,n); }' to call `endo_int's
13:06:12 <mekeor> oh my god.
13:06:15 <ski> (of course this doesn't handle deallocation)
13:06:24 <mekeor> O_O
13:06:28 <mekeor> ski: wow.
13:06:47 <monochrom> this is a very ill-designed grammar. hell, not designed at all. evolved.
13:06:49 <burbul> (In a particular domain, category names are presented without "" and tokens are presented with "")
13:07:03 <mekeor> ski: you seem to be quite professional; but, well, i'm a noob and just a youth trying to learn haskell... >.>
13:07:12 <burbul> monochrom: were you replying to me?
13:07:16 <monochrom> yes
13:07:50 <ski> mekeor : in Haskell terms, assume we had a function type similar to C's function : `(#->)', so that you couldn't write `makeAdder :: Int #-> (Int #-> Int); makeAdder $# a = add_a where add_a $# b = a + b'
13:07:56 <burbul> Escaping the " would have caused other headaches.
13:08:55 <burbul> Regardless, I think that unless a non-greedy equivalent of "many" exists I have to build a primitive parser
13:09:02 <ski> mekeor : we could recover the usual "closure-enabled" functions from this, using `data a -> b = forall environment. Closure $# (environment,(environment,a) #-> b)'
13:09:07 <burbul> Like the one I pasted in
13:09:20 <mekeor> ski: sorry. i dont understand anything. it seems that i first have to learn more of the basics.. :)
13:09:52 <burbul> But I'm not sure what the appropriate way to fail is ...
13:10:09 <monochrom> I'm pretty sure "non-greedy many" = return () and "non-greedy many1" = char.
13:10:28 <ski> mekeor : ok. the simple version is, with functions like in C, you can't do `makeAdder a = (+) a' or `makeAdder a = add_a where add_a = a + b' directly, i.e. you can't "compute new functions at run-time (i.e. depending on run-time data)"
13:11:17 <burbul> Sorry, I'm really new to Haskell, and I'm not sure I follow that... in a general regex, if you write
13:11:26 <burbul> a.*b
13:11:29 <ski> mekeor : the only thing you can do (barring actually generating new code, i.e. like machine code, at run-time) is pass around already existing functions
13:11:44 <burbul> That will match against axzyb
13:11:56 <burbul> Because it will use backtracking to prevent the .* matching the b
13:11:59 <monochrom> many is not regex
13:12:01 <burbul> As I understood it that was not the case for
13:12:06 <burbul> many in parsec
13:12:10 <mekeor> ski: oh..kay. ic. (more or less)
13:12:15 <ion> monochrom: parse (nonGreedyMany (char 'a') <* char 'b' <* eof) "" "aaaaab" should result in "aaaaa"
13:12:17 <burbul> -- i.e. it doesn't do any backtracking
13:12:20 <monochrom> right, many in parsec is not regex
13:12:24 <burbul> right
13:12:46 <burbul> Sorry, possibly I shouldn't have said non-greedy many -- rather " backtracking many"
13:12:52 <monochrom> so I'm pretty sure "non-greedy many" has nothing to do with "non-greedy regex"
13:13:08 <burbul> yes -- my fault for putting it badly
13:13:23 <ski> mekeor : the ability to do this kind of things is sometimes called "having closures", since that's the usual implementation of it
13:13:56 <burbul> (I was actually thinking in terms of greedy algorithms vs backtracking algorithms  rather than greedy regex vs nongreedy regex)
13:14:06 <Cale> (I will scream at you if you talk about closures as if they were a language feature and not an implementation mechanism though)
13:14:16 <ski> mekeor : if you had an implementation that passed around expression trees (or, $DEITY forbid, strings), then you could let `makeAdder 5' return `\b -> 5 + b' (i.e. generate code where you've replaced the `a' by `5')
13:14:32 <burbul> Anyway, is 'mzero' the right way to fail?
13:15:09 <burbul> [ Actually, a better question: is there an easy way to get hold of the source of a particular function? If I could have looked up the source of e.g. 'oneOf' then I could have figured out what to do myself... ]
13:15:22 <ski> mekeor : but doing this substitution all the time is unnecessarily inefficient : it's better to delay the substitution until someone wants to access the `a' in `\b -> a + b' -- so we've reinvented variable accesses :)
13:16:16 <ion> @hackage parsec
13:16:16 <lambdabot> http://hackage.haskell.org/package/parsec
13:16:37 <ion> burbul: The Haddock documentation has links to each function’s sauce.
13:16:45 <ion> See the link.
13:16:59 <burbul> ah -- thanks!
13:17:03 <monochrom> ion, parse (many (char 'a') <* char 'b' <* eof) "" "aaaaab" already gives "aaaaa"
13:17:09 <ski> mekeor : so instead of passing around `\b -> 5 + a' we pass around a pair of `a = 5' and `\b -> a + b', i.e. a pair of environment and code, which is what is called a closure. this way we can avoid having to modify and/or generate new code at run-time, we only have to generate new environments to bundle up with the "static" code
13:18:49 <ion> monochrom: But parse (many (char 'a')) "" "aaaaab" doesn’t give "", which would match the regexp-style non-greedy ‘many’ behavior.
13:19:47 <ion> Of course, one should avoid *? and +? even in regexps since there tend to be much better ways to do it. :-)
13:19:48 * ski . o O ( mmm, ss )
13:20:24 <burbul> -- I didn't mean greedy/non-greedy in the regex sense; I meant greedy as opposed to backtracking. It was a very bad choice of terminology.
13:20:24 <monochrom> by what definition of nongreedymany should parse (nongreedymany (char 'a')) "" "aaaaab" give ""?
13:20:42 <monochrom> notice that in particular there is no eof requirement
13:21:28 <monochrom> ReadP's many supports backtracking. ReadP comes with ghc
13:21:29 <ocharles> hrm, brain's stopped working. If I have: newtype MyIO a = MyIO { runMyIO :: IO a }, how do I do something like: myRandom :: MyIO Int  myRandom = randomIO :: IO Int ?
13:21:38 <ocharles> MyIO deriving Monad and MonadIO, that is
13:21:44 <ion> burbul: I think the main ways to do failures in Parsec are unexpected, fail and (<?>), all of which take an error message string.
13:22:22 <mauke> ocharles: myRandom = MyIO randomIO
13:22:36 <ocharles> hrm, I'm sure I tried that...
13:22:42 <ion> >> [/^a*?b$/, /^a*?/].map {|re| re.match "aaab" }
13:22:42 <ion> => [#<MatchData "aaab">, #<MatchData "">]
13:23:27 <ion> Putting parentheses around both a*?s: => [#<MatchData "aaab" 1:"aaa">, #<MatchData "" 1:"">]
13:23:39 <burbul> monochrom, ion: thank you. I *think* this is the only place where I need backtracking, so I will probably stick with Parsec --- but it's useful to know about ReadP for the future.
13:23:40 <Cale> ocharles: or:  MyIO { runMyIO = randomIO }
13:23:54 <ocharles> ok that works. next question is how to do something like: myRandom = do { random <- MyIO randomIO; return $ random + 1 }
13:23:59 <ocharles> that feels a bit clunky
13:24:05 <ocharles> is that the right way though?
13:24:20 <ocharles> (still doing MyIO randomIO)
13:24:23 <ion> (+1) <$> MyIO randomIO
13:24:35 <ocharles> ok, but you still have to use MyIO to create the MyIO value
13:24:37 <Cale> Or fmap (+1) (MyIO randomIO)
13:24:40 <Cale> (same thing)
13:24:43 <ocharles> I wasn't sure if there was something that did that automagically
13:24:44 <Cale> yeah
13:24:59 <Cale> What's the idea behind this anyway?
13:25:02 <ocharles> (yea, I'd probably use applicative)
13:25:26 <ocharles> Cale: I have Model Book, and I need to generate a UUID inside it. V4 is random, so I need to be able to get a Model UUID
13:25:27 <ocharles> I think, anyway
13:25:38 <ocharles> will paste more code when I get something that works, and you can all tell me how horribly wrong it is :)
13:25:58 <burbul> Looks like there exist both parserFail and parserZero -- parserFail  is probably what I want
13:26:55 <burbul> [ in fact, fail msg = parserFail msg ]
13:27:27 <EvanR> isnt <?> used in parsec for error messages
13:28:10 <ion> It’s a combinator that sets your own error message to the left-hand side parser if it fails.
13:28:12 <EvanR> wtf is this signature from wxhaskell
13:28:16 <EvanR> start :: IO a -> IO ()
13:28:41 <Cale> ocharles: In general, if you have a MonadIO instance, you can use liftIO to turn an IO action into a value in that monad.
13:29:54 <ocharles> Cale: https://gist.github.com/1083378 is what I've ended up with
13:30:07 <EvanR> and if your io action is MonadIO m => m a, you dont need liftiO
13:30:14 <Cale> EvanR: Looks like a generic wrapper for the main action which runs the GUI
13:30:28 <EvanR> Cale: what is the meaning of the a?
13:30:38 <Cale> EvanR: probably initialising/cleaning up stuff before and after
13:30:50 <Cale> It's a type parameter which is unconstrained
13:30:58 <Cale> so you know that start doesn't make use of the value
13:31:05 <EvanR> so i guess it cant mean much at all
13:31:17 <Cale> It just means that the IO action you pass it can return whatever result it wants and that result is ignored.
13:31:26 <Cale> (enforced by the type system)
13:31:31 <EvanR> interesting
13:31:45 <EvanR> if it was forced to return (), seems like it would serve the same purpose
13:31:53 <Cale> sure, but less convenient
13:32:33 <ion> :t void
13:32:33 <lambdabot> Not in scope: `void'
13:32:36 <ion> @hoogle void
13:32:36 <lambdabot> Foreign.Marshal.Error void :: IO a -> IO ()
13:32:44 <parcs> :t forkIO -- speaking of which
13:32:45 <lambdabot> Not in scope: `forkIO'
13:32:48 <Cale> You'd end up doing silly things like that ^^
13:34:47 <parcs> `start` is secretly just `const (return ())`
13:35:04 <ion> Hah
13:38:58 <ion> If everything in Prelude that takes a monad but ignores its result value used m () instead of m a for the parameter, that would force you to make the discarding of the result value explicit if you want to give something with a non-() result value to such a function, potentially revealing programming errors.
13:40:16 <ash__> in haskell, can you have a function that returns void?
13:40:29 <Cale> Depends what you mean by void?
13:40:31 <sipa> :t const ()
13:40:32 <lambdabot> forall b. b -> ()
13:40:52 <siracusa> () is not void, it's unit
13:41:09 <Cale> and () really has *two* elements
13:41:18 <Cale> If you're counting bottom :)
13:41:19 <ash__> just thinking of say an init function, it may not have a result that is meaningful, but you need to run it at least once
13:41:26 <ion> Say, if bracket had the type IO a → (a → IO ()) → (a → IO b) → IO b, you could do bracket f hClose g (because hClose :: Handle → IO ()) but you’d have to use void in bracket f (void hGetContents {- nonsensical -}) g
13:41:46 <Saizan> () is the sierpinski space, for the topology oriented
13:41:47 <Cale> ash__: Oh, in practical terms, if an IO action has no interesting result, then we use IO ()
13:42:05 <djahandarie> @quote xplat subobjects
13:42:05 <lambdabot> xplat says: im in ur Sierpinski space, classifyin' ur subobjects
13:42:27 <ion> Because hGetContents as that parameter is probably an error
13:43:01 <ion> You get rid of a type error and simultaneously document “yes, i want hGetContents here” by using “void” (or “() <$” or whatever).
13:43:54 <Cale> ion: But most of the time, it's just annoying, and doesn't catch an error except that you need to use void/ >> return ()
13:44:08 <Cale> (at least in my experience)
13:44:28 <Cale> If I needed the value, I'll notice when I don't have it in the following code
13:46:58 <mekeor> What's faster?: `f x = x^2' or `g x = x*x' ?
13:47:37 <Cale> The latter if anything, but not significantly so.
13:47:40 <parcs> @src (^)
13:47:41 <lambdabot> x ^ 0            =  1
13:47:41 <lambdabot> x ^ n | n > 0    =  f x (n-1) x
13:47:41 <lambdabot>   where f _ 0 y = y
13:47:41 <lambdabot>         f x n y = g x n
13:47:41 <lambdabot>           where g x n | even n  = g (x*x) (n `quot` 2)
13:47:43 <lambdabot>                       | otherwise = f x (n-1) (x*y)
13:47:45 <lambdabot> _ ^ _            = error "Prelude.^: negative exponent"
13:47:48 <mokus> I've always been annoyed by it, bit in my experience g is usually measuarably faster
13:48:24 <parcs> mekeor: x*x, marginally
13:48:24 <mokus> I've always felt (^) should be inlined for small exponents, but it isn't (or at least wasn't last i checked)
13:52:53 <ash__> isn't there an assembly instruction that does powers?
13:53:09 <jedai> ash__: Yes, for floating points
13:53:20 <jedai> ash__: or rather it does exponential
13:54:04 <mekeor> thank you, Cale, parcs, mokus.
13:58:01 <mekeor> is it actually possible to make a tuple with only one element? liek (x) or so? is (x) right?
13:58:13 <mekeor> :t (x)
13:58:14 <lambdabot> Expr
13:58:16 <shapr> Do any of the Haskell webdev frameworks do well with AJAXy JSON/REST APIs?
13:58:23 <benmachine> mekeor: no
13:58:33 <benmachine> (x) is the same as x
13:58:42 <benmachine> there is no one-tuple, there wouldn't really be any point
13:58:51 <mekeor> benmachine: ic. ok :)
13:59:09 <benmachine> (unlike other languages with tuples, haskell can't define tuple-generic functions, so it's not useful to generalise to the single-element case)
13:59:37 <benmachine> ok, you *can* define tuple-generic functions, but not in an interesting way
14:00:03 <luite_> shapr: yesod claims to :p
14:00:43 <luite_> shapr: though the difference with snap is probably not that big
14:01:29 <luite_> shapr: what specific features were you looking for?
14:03:02 <shapr> luite_: easy marshalling from some sort of secondary storage to a client that wants JSON
14:03:44 <fxr> @k (->)
14:03:44 <lambdabot> Maybe you meant: karma karma+ karma- karma-all keal kind . ? @ v
14:03:55 <fxr> @kind (->)
14:03:55 <lambdabot> ?? -> ? -> *
14:04:39 <luite_> shapr: oh you should be able to do that quite easily with both, if you use Aeson for serializing your data to JSON
14:04:41 <benmachine> @keal
14:04:41 <lambdabot> i need math friendly compiler to compile for jvm or flash
14:05:23 <shapr> benmachine: exactly!
14:05:34 <shapr> benmachine: I can't believe keal was on-topic for once, what's up with that?
14:05:41 <benmachine> :P
14:06:02 <luite_> shapr: yesod might be a little easier if you have urls like /products/categoryid/productname
14:06:09 <shapr> luite_: Basically, I want to write the server side for mobile apps.
14:06:27 <ben_m> Something like Sinatra (Ruby) or Dancer (Perl) would be quite cool to have for Haskell.
14:07:00 <mm_freak> ben_m: what's that?
14:07:08 <luite_> shapr: since it lets you handlers like getProduct :: Integer -> Text -> Handler RepJson     (getProduct categoryId productName = do ... )
14:07:17 <ben_m> mm_freak, very simple web frameworks
14:07:20 <luite_> +write
14:07:22 <shapr> I'm working with Python's Django right now. It has some good points, but I very much wish it were written in Haskell.
14:07:33 <ben_m> mm_freak, http://www.sinatrarb.com/ has a good overview
14:07:35 <luite_> shapr: and it automatically parses the path
14:07:41 <shapr> luite_: that is nifty
14:07:45 <mm_freak> ben_m: "very simple"?  what's the difference to the existing haskell web frameworks?
14:10:34 <ben_m> mm_freak, imagine something like 'get "/:name" (\name -> "Hello, " ++ name ++ "!")' and then you could browse to localhost/foo and it would return "Hello, foo!"
14:10:55 <mm_freak> ben_m: something like that is possible with happstack
14:10:58 <luite_> shapr: it doesn't do the same (yet) for get parameters though. a disadvantage (According to some) is that yesod forces you to to have your application conform to their rules, routes are defined in an external file, or quasiquoted
14:11:12 <mm_freak> but why would that be good?  for hello world it's certainly great, but for anything nontrivial?
14:11:27 <ben_m> mm_freak, sometimes all you need is something trivial
14:11:35 <mm_freak> i mean there is an esoteric language specifically designed to write the shortest hello world program =)
14:11:57 <luite_> shapr: while snap lets you do it more in your own way, using just plain old haskell, thereby losing some convenience
14:12:08 <luite_> don't know about happstack and web-routes :)
14:12:38 <ben_m> mm_freak, I'll check out Happstack though. Don't really need it right now, but it's one of the frameworks I haven't looked at yet.
14:13:59 <shapr> luite_: HAppS originally routed url directly to function in a big monster list.
14:14:47 <luite_> shapr: anyway for RESTful things in yesod you'd typically have something like /products/#Integer/#Text ProductsR GET POST DELETE PUT  in your routes file, and then it calls getProductsR :: Integer -> Text -> Handler a, postProductsR :: Integer -> Text -> Handler a  etc for you
14:15:16 <shapr> luite_: sounds quite handy to me.
14:16:02 <shapr> luite_: What about serialization? HAppS had its own, and Django uses an external db... not sure which I like better.
14:16:19 <luite_> shapr: where the a is the response type, you can have Handler RepJson if you just respond with JSON, but there are also handlers for multiple representations, you can make both a HTML and a JSON representation in an single handler, and yesod chooses the correct one according to the request headers
14:17:03 <luite_> shapr: you mean persistence?
14:17:40 <shapr> luite_: yah
14:17:56 <shapr> luite_: Huh, html and json in the same handler is quite nifty.
14:17:59 <luite_> shapr: snap has a mongodb extension, yesod comes with persistent (which can use sqlite, mongodb, postgresql backends), but neither really force you to use a single library
14:18:29 <burbul> :t (>@>)
14:18:30 <lambdabot> Not in scope: `>@>'
14:19:08 <shapr> burbul: :: [Fish]
14:19:23 <burbul> Hmm... why didn't that work? the interweb says >@> is an ' object composition operator '
14:19:40 <luite_> shapr: I find persistent quite handy, you define your data type (in some special quasiquoted format) and it generates all haskell types for you, including things to easily query things. it automatically creates your tables and updates them if you change your data types
14:20:21 <luite_> so if you add a field to a data type, it will add the corresponding column to your postgresql table for example
14:20:23 <shapr> whoa, HaskellDB style?
14:20:26 <shapr> wow
14:21:05 <luite_> the types of queries you can do with it are somewhat limited though, a big update is coming where it borrows a lot of things from groundhog
14:21:28 <luite_> but it's still not really suitable for heavily relational data (though it can do simple joins)
14:21:59 <luite_> but it should be ok for most boring data manipulation tasks, and you can still use "real SQL" for the rest :)
14:29:10 <mm_freak> ben_m: i use yesod, but happstack is also a good framework
14:29:12 <luite_> shapr: anyway I don't think either of the frameworks is mature enough to immediately get huge productivity gains compared to more established frameworks in other languages. but that should get better with time :)
14:29:47 <shapr> luite_: I dunno... refactoring a bunch of Python code stresses me out, even with my comprehensive unit test suite.
14:29:54 <mm_freak> i like the general idea of happstack that a webserver is just the sum of simpler webservers
14:30:07 <shapr> I miss being able to encode structure in the types.
14:30:44 <luite_> shapr: yeah as your application gets larger the benefits of haskell will probably get more noticeable but at first you have to struggle with unfinished api's, poorly documented code, missing features and other stuff :)
14:32:10 <shapr> Yah, I fought against that with Zope in 2001 or so. I'd be much happier fighting those problems in Haskell.
14:33:16 <wli> Speaking of documenting code, LaTeX-style literate code vs. haddock is ... clunky.
14:33:32 <shapr> wli: Tried lhs2TeX?
14:34:05 <wli> shapr: If I hadn't, how would I observe an issue?
14:34:44 <wli> lhs2TeX pukes on the comments haddock needs.
14:36:33 <luite_> shapr: anyway both irc channels have been very helpful for me (my website uses both yesod and snap, for different parts)
14:37:05 <ash__> are there any good libraries for multi-dimensional arrays?
14:37:13 <luite_> repa?
14:37:32 <luite_> other than that, the regular arrays are indexed by Ix
14:37:50 <luite_> which lets you create multi-dimensional arrays easily, just use tuples
14:38:06 <ash__> ya, i saw that, to use a tuple as the index
14:41:59 <mm_freak> what is a good FRP library for writing games with many objects?  for me it's important that the FRP system can be stepped manually…  it should NOT be tied to any particular graphics package
14:42:30 <mm_freak> i give up with animas…  without the ArrowChoice instance it's useless
14:43:00 <mm_freak> on the other hand the arrowic concept is really awesome
14:46:23 <shapr> luite_: thanks for the help!
14:47:51 <dmwit> Hm, what's the difference between Monad m => a -> m b and Monad m => m (a -> b)?
14:48:26 <dmwit> :t \mab a -> do { f <- mab; return (f a) }
14:48:27 <lambdabot> forall t (m :: * -> *) b. (Monad m) => m (t -> b) -> t -> m b
14:48:32 <dmwit> That's one direction.
14:49:11 <hpc> the 'effects' of the former type can vary based on the 'a' passed
14:49:14 <hpc> they can't in the latter
14:49:26 <parcs> :t join .: fmap
14:49:26 <lambdabot> forall (m :: * -> *) a a1. (Monad m, Functor m) => (a1 -> m a) -> m a1 -> m a
14:49:36 <dmwit> I see.
14:49:46 <dmwit> Yes, I see that writing the other direction is rather harder.
14:50:31 <dmwit> I suppose if the "a" and "b" really are universally quantified they're probably the same somehow.
14:50:44 <dmwit> But they aren't in my case, so that's a moot point. =P
14:50:45 <Saizan> mm_freak: seen reactive-banana? i haven't tried it but apfelmus's blog make it sound promising
14:51:26 <Jester_Racer> Hi everyone! I need in advice: if I want to represent a chess table in haskell, which data type is the best choice? Arrays or list or else?
14:51:33 <Jester_Racer> *an
14:52:07 <EvanR> on windows is the default behavior to not static link/
14:52:24 <c_wraith> Jester_Racer: for what kind of program?  The best answer for a high-performance chess engine is entirely different from the best answer for homework.
14:53:15 <dmwit> :t let f :: Monad m => (forall a b. a -> m b) -> m (a -> b); f amb = do { b <- amb (); return (const b) } in f
14:53:16 <lambdabot> forall (m :: * -> *) a b. (Monad m) => (forall a1 b1. a1 -> m b1) -> m (a -> b)
14:53:19 <dmwit> nice
14:53:46 <Jester_Racer> c_wraith: for a lightweight home project :) I've already tried 2 dimensional lists (lists in lists), but it didn't look like the best choice
14:54:06 <dmwit> Yeah, but that's really trivial. That's really just saying that (forall a b. a -> m b) is isomorphic to (m b).
14:55:44 <c_wraith> Jester_Racer: I'd probably still try to use list of lists.  *shrug*
14:55:54 <Jester_Racer> c_wraith: but you can tell me what would you use in a high-performance chess engine, I'm curious
14:56:16 <hpc> i would use arrays
14:56:31 <hpc> (probably not ideal, though)
14:56:31 <c_wraith> Jester_Racer: high performance chess engines use an array of 64-bit unsigned int.  one for each type of piece and color.  It just is "where pieces of this type are".
14:56:53 <hpc> do you really need 64 bits?
14:57:00 <dolio> There are 64 squares.
14:57:21 <c_wraith> That's a *horrible* representation for homework :)
14:57:26 <hpc> that would mean 64 ints, not 64-bit ints
14:57:33 <dolio> No.
14:57:44 <c_wraith> hpc: each int is a bitmask
14:58:01 <hpc> im lost
14:58:06 <dolio> 7? 64 bit words.
14:58:11 <Jester_Racer> c_wraith: sounds interesting. is there any library for bitmasks in haskell?
14:58:13 <c_wraith> 7 per side.
14:58:17 <c_wraith> 14 total
14:58:17 <dolio> Oh, right.
14:58:20 <hpc> oh
14:58:37 <hpc> so you have the rook int, the knight int, etc
14:58:42 <c_wraith> @hoogle Data.Bits
14:58:42 <lambdabot> module Data.Bits
14:58:42 <lambdabot> Data.Bits class Num a => Bits a
14:58:42 <lambdabot> Data.Bits bitSize :: Bits a => a -> Int
14:58:59 <dolio> Yeah. Black rook, white rook, etc.
14:59:10 <Jester_Racer> thank you all, I'll check it out
14:59:32 <dankna> okay, so, like, I'm seeing something weird when I profile.  20% of my program's time and space usage are attributed to a single top-level function, but if I set a cost center to the body of that function, the body is not where the cost is!
15:00:07 <luite_> c_wraith: why 7?
15:00:19 <dolio> 7 types of pieces.
15:00:29 <hpc> rook, knight, bishop, queen, king, pawn
15:00:31 <dankna> I thought it might be that it was evaluation of a thunk forced by the function, but wouldn't that still be attributed to some code /in/ the function?
15:00:36 <c_wraith> ok, 6
15:00:38 <c_wraith> I can't count
15:00:39 <c_wraith> :)
15:00:41 <Jester_Racer> :D
15:00:42 <hpc> oh, and en-passante pawns
15:00:42 <luite_> ok oh
15:00:47 <hpc> perhaps?
15:00:55 <dankna> not the right way to model en-passante
15:01:00 <dankna> because what about the castling rule
15:01:08 <hpc> yeah
15:01:10 <c_wraith> yeah, en-passant and castling require a bit of history
15:01:30 <c_wraith> because whether they are legal or not doesn't depend solely on board position
15:01:33 <dolio> Apparently I can't count, either.
15:01:43 <dankna> well, you can consider that as an attribute of board state
15:01:50 <dankna> "these pieces have never moved"
15:01:58 <hpc> only one pawn can be en-passant per turn, so that could be a byte indicating the position of the vulnerable pawn
15:02:13 <hpc> and another bit for the king
15:02:34 <hpc> and that's the board
15:02:59 <c_wraith> you'd need to track whether each rook has moved or not
15:03:04 <c_wraith> two more bits per color. :)
15:03:05 <dankna> also it depends slightly on whether you intend to generalize this to Chess variants - if so, I can conceive of a variant where a pawn could return to its starting position after leaving it, in which case you would not want it to be able to double-move again
15:03:08 <hpc> two bits then
15:03:09 <hpc> heh
15:03:21 <dankna> but if you want to stay with stock rules that doesn't come up
15:03:32 <Jester_Racer> ok, I'm lost: why do you have to track if they've moved?
15:03:54 <c_wraith> Jester_Racer: castling can only be done if neither the rook being moved nor the king has already moved
15:04:03 <dankna> because the castling rule states that both the king and the rook in question cannot have moved, prior to the castle that moves both of them
15:04:08 <hpc> http://en.wikipedia.org/wiki/Castling
15:04:11 <Jester_Racer> c_wraith: oh yes, sorry, I've forgot about that
15:04:14 <wli> Grand chess, 3D chess, Chinese chess, shogi, isn't there some Windows program that accommodates them all, plus is scriptable with new variants?
15:04:20 <hpc> http://en.wikipedia.org/wiki/En_passant
15:04:23 <dankna> wli: why Windows?
15:04:40 <dankna> Chess is already three dimensional - x, y, t :)
15:04:45 <wli> dankna: That's just what the program that does it is ported to or written for.
15:05:04 <dankna> adding z makes it four-dimensional
15:05:16 <dankna> I want a chess game that is played on a non-orientable manifold!
15:05:49 <c_wraith> mobius chess seems implementable
15:06:02 <dankna> yeah :D
15:06:13 <c_wraith> klein chess would be tougher.
15:06:24 <dankna> I saw a Go program once that drew a toroidal board
15:06:30 <dankna> it looked trippy
15:06:38 <wli> dankna: Dimensionality's an artifact of human convenience layouts. Big bags of places are really it, with no dimensionality since it's discrete.
15:06:40 <dankna> but that's orientable, of course
15:06:50 <dankna> wli: yes, that's fair enough
15:06:54 <c_wraith> eh.  toroidal boards aren't that interesting in practice, especially for go.
15:07:06 <dankna> agreed - in Go it's all about the corners anyway
15:07:10 <dankna> now, a board with more corners? heh
15:07:27 <wli> Zillions of Games or some such is what it's called.
15:07:30 <dankna> what topology keeps the four-liberties-around-a-point property but has more than four corners?
15:07:35 <hpc> make an 8-cornered go board on a sphere
15:07:42 <dankna> ah!  there you go
15:07:46 <ash__> does repa have mutable arrays?
15:08:12 <dankna> hpc: actually how does that work precisely?
15:08:28 <wli> dankna: It takes a game description and then acts as an arbitrator of move legality/etc.
15:08:44 <dankna> wli: sounds neat, I like it.  auto-visualization would be pretty nifty too.
15:08:48 <hpc> danka: http://mathworld.wolfram.com/SphericalTriangle.html
15:09:40 <hpc> hmm, doesn't look like it's possible to do 8 corners
15:09:45 <hpc> definitely at least 5 though
15:09:53 <dankna> hmmm
15:09:55 <dankna> fascinating
15:10:35 <hpc> non-euclidean geometry ftw
15:11:04 <EvanR> i propose to you that i can cover a sphere in nothing but 4 corner shapes
15:11:41 <hpc> i suspect so
15:11:54 <EvanR> got a solution?
15:12:13 <c_wraith> depends on your definition of "corner"
15:12:17 <hpc> you didn't say i would be covering the sphere :P
15:12:20 <hpc> you do it
15:12:25 <EvanR> haha
15:12:44 <c_wraith> also, are all line segments required to be spherical line segments, rather than curves?
15:13:01 <dankna> no, curves are fine (how could you tell)
15:13:06 <c_wraith> I mean, I can completely cover a sphere in 2-corner and 3-corner shapes, trivially.
15:13:10 <EvanR> in my imagined solution, they are line segments, not curvy
15:13:32 <EvanR> i mean spherical
15:14:12 <c_wraith> dankna: easy.  each line segment on a sphere must make a great circle if extended all the way around.  If it does not, it's a curve.
15:14:35 <c_wraith> dankna: this means lines of longitude are lines, but parallels are *not* lines, for instance.
15:14:43 <c_wraith> parallels are actually curves
15:14:45 <dankna> ah, hm, yes
15:14:58 <dankna> interesting definition
15:15:00 <EvanR> ah then nevermind
15:15:03 <EvanR> curves it is
15:15:24 <c_wraith> it's the definition that follows from the minimal redefinition of euclidean geometry to spherical geometry :)
15:16:30 <EvanR> take the globe with latitude logitude lines as normal, the top and bottom are covered in triangles right? ok, draw another latitude line make a new set of squares and reducing the area covered by the triangles. repeat forever, youre done!
15:17:23 <c_wraith> Heh.  That solution bugs me because there's always an area covered with triangles.
15:17:33 <EvanR> not in the limitting case
15:17:36 <hpc> better one
15:17:44 <hpc> line on the prime meridian, line on equator
15:18:01 <hpc> and another line perpendicular to both
15:18:05 <hpc> now you have 8 triangles
15:18:16 <hpc> make 4 4-gons
15:18:47 <EvanR> ok
15:19:17 <c_wraith> oh.  you can trivially make each triangle into a 4-gon.
15:19:21 <c_wraith> That's not too tough.
15:19:34 <c_wraith> at least, not since the triangles are all equilateral
15:19:57 <EvanR> uhm
15:20:06 <c_wraith> heh.  equilater with 90º angles at each corner
15:20:10 <c_wraith> spherical geometry is fun
15:20:16 <c_wraith> err, equilateral
15:20:18 <dankna> indeed
15:20:59 <c_wraith> anyway, with a 90-90-90 triangle on a sphere, you can turn it into 3 quadrilaterals by extending a line segment from the center of each edge to the center of the triangle.
15:21:02 <EvanR> hpc: i just drew it on paper, seems it works
15:21:35 <EvanR> if i have the connections between triangles correct
15:21:43 <hpc> c_wraith: that's cool
15:24:00 <EvanR> hpc: you know what this means right, if you can subdivide this so its covered in more than 8 'squares' then you can make spherical minecraft
15:24:14 <hpc> :D :D :D
15:24:18 <hpc> wait, no
15:24:35 <hpc> you would have to be able to extend Z all the way down to the core
15:24:39 <hpc> i think
15:24:50 <EvanR> ah right, that sucks
15:24:59 <EvanR> its just as bad as having it be triangular at the poles
15:25:30 <hpc> there's larger problems though
15:25:33 <dolio> Minecraft hits bedrock after a while.
15:25:40 <hpc> dividing by zero when you calculate gravity at the core, for example
15:25:46 <EvanR> lol
15:25:56 <hpc> so yeah, bedrock i can approve of
15:26:05 <EvanR> when you go into the planet, gravity decreases linearly
15:26:05 <dankna> MAGMA
15:26:07 <dankna> with magma men
15:26:18 <EvanR> until its zero at the center
15:26:39 <hpc> i don't mean real gravity, i mean which way is down
15:27:02 <EvanR> haha
15:27:08 <hpc> im assuming gravity is held constant because you could excavate the world and fuck with the environment
15:27:09 <EvanR> it turns into a flight simulator at 0
15:27:27 <ben_m> Minecraft :: Time t => t -> ()
15:27:41 <hpc> lol
15:27:56 <hpc> data () = Minecraft | WoW?
15:28:12 <hpc> er, Minecraft Time | WoW Money
15:28:18 <ben_m> Heh :D
15:33:16 <Lemmih> ?ask roconnor Is the code in a repository yet?
15:33:16 <lambdabot> Consider it noted.
15:37:28 <copumpkin> Lemmih: yes
15:37:43 <copumpkin> darcs get http://r6.ca/Purecoin/ iirc
15:39:38 <roconnor> Lemmih: not all the code is in there yet
15:39:38 <lambdabot> roconnor: You have 1 new message. '/msg lambdabot @messages' to read it.
15:40:58 <gwern> copumpkin: permission denied'
15:43:41 <gwern> > logBase 2 21500000
15:43:42 <lambdabot>   24.357833324026274
15:46:42 <roconnor> gwern: really?
15:46:56 <gwern> roconnor: what, you don't believe me about the error? fine
15:47:12 <gwern> roconnor: http://imgur.com/9DCm9
15:47:41 <ion> He said “darcs get http://r6.ca/Purecoin/”
15:47:54 <roconnor> oh ya
15:47:58 <roconnor> there is no webpage there
15:49:05 <gwern> oh, so you can't browse it - but it darcs gets! well of course...
15:49:32 <Peaker> what's an efficient way to dropWhile (=='\n') on a ByteString's end, in reverse?  i.e:  reverse . dropWhile (..) . reverse -- but efficient?
15:53:29 <c_wraith> Peaker: spanEnd seems appropriate
15:54:47 <Peaker> I'm always confused by span/break -- since it's just a not between them -- it would be nicer if it was just called splitWhen or something like that
15:54:54 <Peaker> (and no need for the not'd one)
15:55:11 <c_wraith> ok, then, breakEnd
15:55:12 <c_wraith> :)
15:55:32 <Peaker> c_wraith: thanks :)
15:57:41 <Peaker> interesting, it appears in all documentation of my bytestring version, but ghci isn't finding it
15:58:01 <Peaker> oh, I'm on lazy bytestrings
15:58:09 <Peaker> this thing is only for strict ones..
15:59:59 <Peaker> hmm.. lazy bytestring has "index" in O(chunks) -- but if I use it on consecutive indexes, it's better to get the chunk at index and iterate that, but there's no API for that
16:00:35 <luite_> toChunks and work with the list?
16:00:42 <hpc> you can get the chunk size, then drop?
16:00:48 <hpc> (i think that's in the api)
16:00:53 <Peaker> yeah, of course, but it could be nice to use an index directly to find a chunk
16:01:24 <Peaker> I guess I can take/drop and then iterate the chunks from whichever edge
16:03:13 <luite_> Peaker: oh I thought you just needed to drop some at the end?
16:06:55 <Peaker> luite_: no, that's a different thing
16:07:07 <Peaker> luite_: I'm toying around with a binary-searcher for lines in a big text file
16:07:26 <Peaker> so given some offset, I need to iterate backwards to find \n and iterate forwards to find \n
16:07:57 <Peaker> I'm mmap'ing a bunch of files and I want them "concat'd" in a big bytestring, therefore it is nice to use a lazy bytestring so I can just concat the mmap's cheaply
16:08:22 <luite_> oh right
16:09:07 <Peaker> currently I just iterate from a given offset naively with multiple calls to "index" but that's not efficient
16:09:52 <Peaker> now after using trace some, I really wonder why there are not more trace combinators that I always have to define...  traceId prefix x = trace (prefix ++ show x) x
16:09:54 <luite_> why not splitAt?
16:10:14 <Peaker> luite_: Yeah, that's better than my take/drop suggested above
16:10:16 <wli> Peaker: Keep count before emitting.
16:11:06 <wli> Or do a pass of RLE, then only emit the expanded char if it's not the last RLE'd bundle and the char isn't '\n'
16:11:18 <Peaker> It's also nice to have:   traceAround :: (Show in, Show out) => String -> (in -> out) -> (in -> out) ; traceAround funcName f = traceId ("Result of " ++ funcName) . f . traceId ("Argument to " ++ funcName)
16:11:31 <Peaker> wli: not sure what RLE has to do with it?
16:11:50 <wli> Peaker: You probably changed subjects while I was disconnected.
16:12:01 <Peaker> ah, Yes
16:12:18 <Peaker> there's breakEnd which does exactly that, efficiently
16:12:34 <Peaker> so.. who do I turn to to add Debug.Trace combinators?
16:14:40 <luite_> Peaker: you must repent for your impure thoughts!
16:14:59 <wli> Peaker: Where is breakEnd from?
16:15:05 <Peaker> Data.ByteString
16:15:54 <wli> Sounds like something that should exist for lists... no big deal, anyway.
16:16:21 <c_wraith> well.  it's efficient for bytestrings.  less so for lists
16:17:18 <wli> Unclear what the semantics are.
16:19:20 <wli> Not too hard, still; just refuse to emit until the predicate fails. If list end is reached before that, refuse to emit.
16:20:01 <Peaker> for lists I think it's just as efficient to do: reverse . dropWhile ... . reverse
16:20:21 <luite_> wli: that's quite different?
16:20:38 <wli> Peaker: That would be grossly inefficient.
16:20:59 <Peaker> wli: lists are grossly inefficient for this :-)
16:21:10 <wli> They're not.
16:21:43 <Peaker> well, reverse . dropWhile ... . reverse   will make a couple of extra unnecessary lists compared with a specialized recursion
16:23:30 <shachaf> If there was a function safeInitLast :: [a] -> Maybe ([a],a), you could use that with Data.List.Split.splitOn.
16:24:45 <aavogt> the function doesn't exist because they don't want to encourage being really slow?
16:25:14 <Peaker> > let   removeEndJunk isJunk = foldr (\x rest -> case rest of Nothing | isJunk x -> Nothing | otherwise -> Just [x] ; Just rest -> Just (x:rest)) Nothing   in   removeEndJunk (=='x') "Hexxo worldxx"
16:25:15 <lambdabot>   Just "Hexxo world"
16:25:42 <shachaf> aavogt: As long as init and last exist, there's no excuse for not having a function which returns both.
16:25:46 <Peaker> Efficient junk remover with lists
16:26:07 <shachaf> Wait, I completely misunderstood the problem at hand anyway.
16:27:15 <Peaker> Hmm.. I'm not getting a trace line I really should be getting.. weird
16:29:28 <Peaker> Are GHC 6.12.3 optimizations allowed to make a trace not appear when it is forced?
16:30:05 <c_wraith> potentially under some circumstances
16:30:05 <Peaker> When I turn on optimizations, some of the traces disappear...
16:31:47 <aavogt> ghc isn't supposed to do much CSE
16:32:02 <aavogt> Peaker: how about you try -O -fno-cse?
16:32:32 <aavogt> maybe there are other optimizations that could make a trace dissapear
16:32:54 <Peaker> aavogt: thanks, now that I really know it's the optimizations and not me being crazy, it's less important :)
16:33:31 <Peaker> it's something like:   case something of Just ... -> ... ;  Nothing -> trace "bah" Nothing          and the "bah" never appears even though the result Nothing is forced
16:33:58 <shachaf> http://hackage.haskell.org/trac/ghc/wiki/Commentary/EvilMangler
16:33:59 <shachaf> :-(
16:34:42 <hpc> it has an omnibenevolent mangler?
16:34:53 <luite_> the evil mangler is now hiding in your closet
16:35:26 <Peaker> hmm.. Lazy Bytestring doesn't have breakEnd -- because it assumes it may be infinite and it makes less sense. But I may have a finite Lazy ByteString just so I don't have to concat the large chunks in it
16:36:13 <Peaker> and so I have no good way of doing breakEnd efficiently and easily -- I can do: reverse . toChunks  and then walk the chunks, but that's no fun...
16:36:43 <luite_> hmm, it does have other things that don't work for infinite bytestrings
16:46:32 <mm_freak> Saizan: i folllowed the thread about reactive-banana…  the author specifically said that it's currently not very useful for animations
16:47:03 <Saizan> mm_freak: ah, fair enough
16:47:04 <mm_freak> i need FRP for simulations of dynamic systems…  i think i'll try with elerea
16:47:45 <mm_freak> or perhaps i should write to the animas/yampa devs about whether it's possible to write the ArrowChoice instance
16:56:32 <hpaste> wli pasted “BEL.hs” at http://hpaste.org/49056
16:57:05 <wli> I got pulled away for a while on several occasions between the pertinent discussion and now.
16:57:26 <edwardk> mm_freak: "i need FRP for…" <— now you have two problems ;)
16:57:50 <hpc> ha!
16:58:24 <hpc> > do "i need FRP for…" <— now you have two problems
16:58:25 <lambdabot>   Not in scope: `now'Not in scope: `you'Not in scope: `have'Not in scope: `tw...
16:58:30 <wli> How do you use the lhs2TeX -generated LaTeX from several Haskell source files within a single document again?
16:59:02 <wli> Also is there a less kludgey way to have haddock in LaTeX-style literate source than %if False around code blocks with the Haddock comments?
16:59:44 <mm_freak> edwardk: well, in the same way i need haskell to breathe =)
16:59:53 <mm_freak> it makes me know that there are still some sane people out there
16:59:55 <wli> opening and closing code blocks dedicated to Haddock comments is painful.
17:02:37 * monochrom is disillusioned about latex and so no longer suffers these problems
17:03:30 <wli> monochrom: Then you suffer the lack of LaTeX
17:04:22 <ion> @check \a (xs :: [Integer]) -> pure (pure a) <*> xs == pure (pure a) =<< xs
17:04:23 <lambdabot>   Parse error in pattern at "->" (column 22)
17:04:49 <ion> @check \a xs -> pure (pure a) <*> xs == pure (pure a) =<< xs `const` (xs :: [Integer])
17:04:50 <lambdabot>   Precedence parsing error
17:04:50 <lambdabot>      cannot mix `Control.Applicative.<*>' [infixl ...
17:05:25 <ion> @check \a xs -> (pure (pure a) <*> xs == pure (pure a) =<< xs) `const` (xs :: [Integer])  -- fffuuuu
17:05:25 <lambdabot>   Precedence parsing error
17:05:26 <lambdabot>      cannot mix `Control.Applicative.<*>' [infixl ...
17:05:44 <ion> Ok, enough flooding.
17:06:32 <hpaste> wli annotated “BEL.hs” with “BEL.hs (annotation)” at http://hpaste.org/49056#a49057
17:06:49 <ion> Huh, hadn’t noticed before that == has the same precedence as <*>.
17:06:50 <Peaker> ok, coming back to my find newline forward/backward function -- I can't seem to find an elegant way to do it.. funnily, in C it would have been easy :-)
17:08:04 <monochrom> array indexing is easy, yeah
17:08:32 <pikhq_> It's a heck of a lot easier to do certain forms of transformations on mutable arrays than on immutable lists, yeah.
17:11:27 <ion> > intercalate "," . unfoldr (\((second (drop 1) . break (== ',')) -> (as,bs)) -> (as,bs) <$ listToMaybe bs) $ "foo,bar,baz,quux"
17:11:29 <lambdabot>   "foo,bar,baz"
17:12:46 <ion> > intercalate "," . unfoldr (\(break (== ',') -> (as,bs)) -> (as, tail bs) <$ listToMaybe bs) $ "foo,bar,baz,quux"
17:12:48 <lambdabot>   "foo,bar,baz"
17:15:37 <wli> Linear programming and Fourier-Motzkin elimination are pressing issues. Like many pressing issues, going nowhere. Perhaps non-convex quadratically-constrained quadratic programming crops up, too.
17:16:50 <ion> @check let breakEnd c = intercalate [c] . unfoldr (\(break (== c) -> (as,bs)) -> (as, tail bs) <$ listToMaybe bs) in \c pre post -> not (c `elem` post) ==> breakEnd c (pre ++ [c] ++ post) == pre
17:16:50 <lambdabot>   Parse error at "->" (column 60)
17:16:52 <Peaker> Is Data.ByteString.concat efficient? Will it allocate just one result string of the right length immediately? Or will it be as inefficient as foldr append empty ?
17:17:32 <Axman6> i have a feeling it only does one allocation. check the source =)
17:17:37 <wli> ion: Drop it on hpaste when you're happy with it. My ability to decipher one-liner affairs has declined substantially over the past 3 years.
17:17:50 <ion> @check let breakEnd c = intercalate [c] . unfoldr (\xs -> let (as,bs) = break (== c) xs in (as, tail bs) <$ listToMaybe bs) in \c pre post -> not (c `elem` post) ==> breakEnd c (pre ++ [c] ++ post) == pre
17:17:51 <lambdabot>   No instance for (Test.QuickCheck.Testable
17:17:51 <lambdabot>                     (Test.QuickCh...
17:18:52 <Peaker> since it's in ghc now, it's harder to check the source..
17:19:28 <Peaker> ah, there are source links on hackage
17:19:36 <Peaker> yep, it allocates once
17:22:00 <ion> @check let breakEnd c = intercalate [c] . unfoldr (\xs -> let (as,bs) = break (== c) xs in (as, tail bs) <$ listToMaybe bs) in \c pre post -> ((c :: Word8) `elem` post) || (breakEnd c (pre ++ [c] ++ post) == pre)
17:22:00 <lambdabot>   "OK, passed 500 tests."
17:22:20 <ion> wli: breakEnd c =
17:22:23 <ion> whoops
17:22:54 <ion> wli: breakEnd c = intercalate [c] . unfoldr (\(break (== c) -> (as,bs)) -> (as, tail bs) <$ listToMaybe bs)
17:23:19 <wli> ion: It needs to keep count of how many repetitions.
17:23:28 <ion> Repetitions?
17:23:47 <wli> ion: You can't seriously need me to explain that.
17:25:41 <wli> > let breakEnd c = intercalate [c] . unfoldr (\(break (== c) -> (as,bs)) -> (as, tail bs) <$ listToMaybe bs) in breakEnd 'f' "asdfasdffff"
17:25:42 <lambdabot>   "asdfasdfff"
17:34:12 <ion> > let breakEnd p = init . concat . unfoldr (\(break p -> (as,bs)) -> (as ++ [head bs], tail bs) <$ listToMaybe bs) in breakEnd isSpace "foo bar\tbaz\nquux"
17:34:13 <lambdabot>   "foo bar\tbaz"
17:36:35 <dmwit> ion: quux seems to have disappeared!
17:37:09 <dmwit> Oh, I see, that was the point.
17:41:00 <wli> ion: I've got one.
17:41:04 <wli> > let breakEnd c s = let chunks = groupBy ((==) `on` (== c)) s in last . init $ zip (inits chunks) (tails chunks) in breakEnd 'f' "asdffasdffff"
17:41:06 <lambdabot>   (["asd","ff","asd"],["ffff"])
17:41:47 <dmwit> > let breakEnd c s = let chunks = groupBy ((==) `on` (== c)) s in last . init $ zip (inits chunks) (tails chunks) in breakEnd 'f' "asdffasdffffasd"
17:41:49 <lambdabot>   (["asd","ff","asd","ffff"],["asd"])
17:42:03 <dmwit> wli: Hm, maybe not quite what you were hoping for. =)
17:42:04 <wli> > let breakEnd c s = let chunks = groupBy ((==) `on` (== c)) s in first concat . last . init $ zip (inits chunks) (tails chunks) in breakEnd 'f' "asdffasdffff"
17:42:05 <lambdabot>   ("asdffasd",["ffff"])
17:42:45 <dmwit> What's the specification of the function we're trying to write?
17:43:08 <wli> One last time:
17:43:09 <wli> let breakEnd c s = let chunks = groupBy ((==) `on` (== c)) s in (concat *** head) . last . init $ zip (inits chunks) (tails chunks) in breakEnd 'f' "asdffasdffff"
17:43:48 <wli> dmwit: Like Data.ByteString.breakEnd only for lists. ion specialized it to (== c) for characters
17:43:59 <Peaker> dmwit: I'd love to have an elegant function that can find newline before and after an offset in lazy-bytestring -- returning the range of the line (including corner cases of end-of-string)
17:45:59 <dmwit> The breakEnd you wrote does not behave like the breakEnd from ByteString.
17:46:13 <wli> dmwit: It was ion's.
17:46:40 <wli> dmwit: I wrote http://hpaste.org/49056#a49057
17:46:54 <Peaker> hmm.. I just realized -- I need a zipper of a lazy bytestring, rather than the lazy bytestring itself
17:47:03 <Peaker> is there a lazy bytestring zipper?
17:47:24 <Peaker> I am implementing a lazy-bytestring binary search of textual lines
17:47:52 <dmwit> wli: It can be written more lazily. Are you interested in a lazier implementation?
17:47:56 <Peaker> the binary predicate is allowed to return "don't know" so need to move forward
17:48:11 <wli> dmwit: Sure. Might also help to be more efficient generally.
17:50:32 <wli> dmwit: (To clarify, this is not something in which I've got anything invested, not ego, not time, not even much interest.)
17:51:27 <wli> dmwit: I think using the Writer instance on Sequence might help with the (++ [c]) affairs.
17:52:04 <Peaker> it's pretty annoying to have to do:  SBS.length bs   rather than "OO syntax" of  bs.string.   A structural editor would resolve that nicely...
17:52:33 <wli> ion: for a fun one, reverse the characters within individual words while maintaining the order of the words overall.
17:53:18 <c_wraith> wli: you mean more efficiently than the obvious way?
17:53:19 <wli> ion: That's one where preserving whitespace structure is crucial.
17:53:27 <fazzone> unwords . map reverse . words ?
17:53:28 <c_wraith> oh, you do.
17:53:44 <wli> c_wraith: Which needs to happen more efficiently than obvious?
17:53:59 <wli> fazzone: Does not preserve whitespace structure.
17:54:23 <c_wraith> wli, that last requirement was absent in the original problem structure.
17:54:32 <wli> c_wraith: I don't really care about it, I just got asked it in an interview.
17:54:54 <wli> c_wraith: I got hammered about it during the interview, hmm.
17:56:06 <c_wraith> If I was trying to do it efficiently, I'd do it with direct recursion using ShowS-style stuff.  It'd take a few lines of code, but it'd be obvious and pretty efficient.
17:56:09 <proq> wli: I've been asked to do that exercise before too.  oddly enough, never needed to do it in real life
17:56:29 <c_wraith> nothing involving String in haskell is all that efficient anyway :)
17:56:38 <wli> groupBy ((==) `on` isSpace) seems relevant.
17:57:52 <wli> concatMap (\s -> if any isSpace s then s else reverse s) . groupBy ((==) `on` isSpace) ?
17:58:54 <Peaker> @type splitOn " "
17:58:55 <lambdabot> Not in scope: `splitOn'
17:59:01 <Peaker> @type Data.List.Split.splitOn " "
17:59:02 <lambdabot> Couldn't find qualified module.
17:59:09 <cmccann> String is plenty efficient if you're actually using it as a list of characters, particularly if laziness is useful
17:59:31 <wli> > concatMap (\s -> if any isSpace s then s else reverse s) $ groupBy ((==) `on` isSpace) "is anybody out there"
17:59:32 <lambdabot>   "si ydobyna tuo ereht"
17:59:38 <Peaker> cmccann: when is anyone ever "actually using it as a list of characters"?
18:00:03 <Peaker> cmccann: you can mostly reduce the listy use to mapping/filtering/etc which can happen more efficiently on Text
18:00:29 <cmccann> Peaker, not very often, agreed
18:00:43 <jmcarthur> i think fusion a pretty good substitute for laziness, oftentimes
18:01:09 <cmccann> I'm just noting that String isn't inherently terrible in any way, it's just inherently terrible for working with moderately large chunks of text that are all in memory at the same time
18:01:56 <cmccann> jmcarthur, well, fusion is basically a hardcore optimization of the ideally lazy case, isn't it? instead of incremental steps, condense them all into one
18:01:57 <jmcarthur> it's a pretty terrible default string type though
18:02:06 <dpratt71> I have a 'fun' project in mind that involves implementing a binary wire protocol; I'm thinking I need to brush up on the network and attoparsec packages; anything else I should investigate?
18:02:49 <jmcarthur> cmccann: in a sense it's the advantages of strict data types with the advantages of laziness
18:03:21 <Peaker> btw, that reminds me -- Iteratee uses chunks to avoid any per-step overheads. But with proper fusion, the list of chunks may actually incur more overhead than just running the inlined step pipeline
18:03:22 <jmcarthur> cmccann: it's like laziness without the overhead of a ton of thunks
18:03:28 <cmccann> jmcarthur, default string handling tends to be terrible in lots of places, as evidenced by the existence of "string builder" classes. I mean, come on, seriously?
18:03:32 <Peaker> I was wondering if Iteratee's chunking is really a good idea in all cases
18:04:04 <luite_> or if Iteratee is a good idea at all ;p
18:04:33 <cmccann> and yes, successful stream fusion tends to be pretty much the best-case scenario when it's applicable at all, it's really very nice
18:04:41 <jmcarthur> Peaker: aren't the chunks intended for limiting the number of IO operations?
18:05:10 <cmccann> yeah, the motivating example for iteratees was to replace lazy IO, so the chunking reflects "read N bytes at a time"
18:05:21 <luite_> is there an inherent cost in a a -> IO b compared to a -> b?
18:05:27 <Peaker> jmcarthur: Well, there are actually 2 layers of chunking, say you're enumerating a socket -- each read yields a ByteString of some size, and then there's a Chunks data constructor that groups a bunch of bytestrings together
18:05:43 <cmccann> there are other cases where chunking is useful, too, but I don't know if it's ideal to chunk everywhere all the time
18:06:08 <luite_> at least chunking should make performance much more predictable
18:06:17 <Peaker> jmcarthur: it might be meant to save IO, but it is not necessarily expensive.. I think the "chunk" stuff stuck deep in Iteratee (rather than an extra layer if at all) is a mistake
18:06:25 <luite_> the problem with fusion is that when it doesn't work, performance is horrible :)
18:06:32 <Axman6> @pl liftIO f = FutureAct $ \ref -> liftIO f
18:06:32 <lambdabot> liftIO = fix ((FutureAct . const) .)
18:06:35 <jmcarthur> yeah
18:06:38 <Axman6> heh
18:06:45 <Axman6> @pl liftIO f = FutureAct $ \ref -> liftIO' f
18:06:45 <lambdabot> liftIO = FutureAct . const . liftIO'
18:06:46 <cmccann> luite_, the problem with optimizations is that when they don't work, your code isn't optimized ;]
18:07:20 <jmcarthur> cmccann: luite_ means that if you write code that is intended to fuse but it doesn't then you are often worse off than if you had written it in a simpler way in the first place
18:07:21 <luite_> cmccann: yeah something like that :)
18:07:26 <jmcarthur> i think
18:07:48 <cmccann> yeah, I got that, was just being snarky
18:08:40 <cmccann> a lot of optimizations involve objectively making the code worse in some other way, though, which is what I was sort of getting at
18:08:56 <Peaker> if we had more interactive coding environments, it would be much easier to see through optimizations, and see whether things are fused
18:10:05 <Peaker> Also, we could build our build systems interactively as programs, and see them apply to our code. Then it would be relatively easy to explicitly apply optimizers on our code -- and see the result directly
18:10:09 * cmccann often wonders about the practicality of encoding efficiency bounds and/or optimization requirements into a type system
18:10:58 <cmccann> obviously would be insanely awkward and/or impossible in Haskell in general, though there are some examples out there
18:11:33 <cmccann> (e.g., monad vs. applicative on infinite streams, heh)
18:12:06 <cmccann> er, by which I mean the ziplist-style instances, not the standard list monad
18:14:21 <cmccann> or really, the entire class of pointwise zippy applicative instances, which I think all have monad instances given constraints on the values
18:14:40 <cmccann> and which are all horribly inefficient except for I suppose the Reader monad, if you include it
18:15:59 * cmccann considers whether it's harder to optimize (>>=) vs. (<*>) for reader... they're obviously the same function, but (>>=) seems like it might complicate the intermediate expressions
18:18:40 <Peaker> cmccann: I think as a first step, making optimizations transparent would be a great deal of help
18:19:24 <jonkri> on debian's wiki page for gnu hurd [ http://wiki.debian.org/Debian_GNU/Hurd ] [ http://news.slashdot.org/story/11/07/14/2141229/Watch-Out-Linux-GNU-Hurd-Coming ], they mention ghc6. are they talking about ghc ghc? :)
18:25:57 <edwardk> cmccann: in the keys package I have a Zippable class that describes the 'zippy' applicatives
18:26:29 <cmccann> I thought I remembered that, but hadn't gone looking yet
18:26:53 <cmccann> mostly it was on my mind recently because of something on stack overflow a while back, about exercises in an old version of the Applicative paper
18:31:50 <Axman6> jonkri: I'd guess so, gnat mentioned below is the GNU Ada compiler
18:33:28 <tyutyu> hi
18:34:00 <Peaker> btw.. since a Zip class is really equivalent to Applicative (at least without pure), I think: A) probably a bad idea to duplicate classes for different instances, better duplicate newtypes.  B) if you do it, at least use the same method signatures
18:34:18 <wli> Polymorphic native Haskell linear programming looks like it's back in the cards.
18:34:24 <djahandarie> Peaker, different laws.
18:34:49 <Peaker> djahandarie: more restrictive laws in the case of Zip?
18:34:54 <djahandarie> Yeah, IIRC.
18:35:06 <djahandarie> We discussed this some time ago, though I don't remember what we decided. :(
18:35:09 <Peaker> djahandarie: then make it an empty law-class extension..
18:35:38 <Peaker> or at least, make it as similar as possible to Applicative, if it can be similar (rather than have superficial differences mask out the the deep similarity)
18:36:25 <NemesisD> is there a way to join a list of independent io operations into 1? mplus has the right type signature but there doesn't seem to be a monadplus instance for io
18:37:08 <aavogt> @ty msum
18:37:09 <lambdabot> forall (m :: * -> *) a. (MonadPlus m) => [m a] -> m a
18:37:35 <NemesisD> whoops meant msum, same issue, no instance of io
18:37:41 <aavogt> @ty \x -> sequence (x :: [IO a])
18:37:41 <lambdabot>     Inferred type is less polymorphic than expected
18:37:41 <lambdabot>       Quantified type variable `a' is mentioned in the environment:
18:37:42 <lambdabot>         x :: [IO a] (bound at <interactive>:1:1)
18:37:53 <aavogt> @ty \x -> sequence (x `asTypeOf` (undefined :: [IO a]))
18:37:54 <lambdabot> forall a. [IO a] -> IO [a]
18:38:59 <Peaker> NemesisD: mplus is for catching exceptions, mostly
18:39:05 <Peaker> NemesisD: what kind of join do you want?
18:39:06 <aavogt> @ty \x -> Data.Foldable.fold (x `asTypeOf` (undefined :: [IO a]))
18:39:07 <lambdabot> forall a. (Monoid (IO a)) => [IO a] -> IO a
18:39:15 <Peaker> NemesisD: just execute them all, one by one?
18:41:07 <aavogt> @ty foldM (\a b -> do b <- b; return (a `mappend` b)) mempty
18:41:07 <lambdabot> forall a (m :: * -> *). (Monad m, Monoid a) => [m a] -> m a
18:41:25 <NemesisD> oh it looks like all this monad tomfoolery is unnecessary, i'm trying to set up some specs with Hspec. each describe block that describes a group of tests has a type IO [IO SPEC], the runner is IO Specs -> IO a
18:41:52 <NemesisD> the library provides: descriptions:: [IO [IO Spec]] -> IO [IO Spec] which is exactly what i need
18:42:33 <aavogt> @ty liftM concat . sequence
18:42:33 <lambdabot> forall a (m :: * -> *). (Monad m) => [m [a]] -> m [a]
18:43:52 <Balahla> Need help with gtk2hs...
18:48:11 <Balahla> I just can not get gtk2hs installed.
18:48:25 <monochrom> os?
18:49:18 <Balahla> Sorry. Windows Seven.
18:50:15 <Balahla> I've tried several tutorials, but is not working...
18:50:23 <monochrom> then you may have to settle for ghc 6.12.3
18:50:47 <Balahla> It does not work with the last ghc version?
18:51:36 <monochrom> http://deltadiaz.blogspot.com/2011/03/on-windows-how-to-install-gtk.html
18:52:02 <monochrom> some problem with the combination of windows+ghc 7+gtk2hs
18:52:08 <Balahla> I have the ghc 7.0.3 installed.
18:52:21 <Balahla> Hum.
18:52:53 <Balahla> Well. Back to the 6.12.3, then. Thanks.
18:53:38 <wli> I'm getting Scanners-style head explosions attempting to understand linear programming even though I knew what was going on at one point.
18:55:09 <monochrom> hmm http://www.mail-archive.com/haskell-cafe@haskell.org/msg88098.html says he can get ghc 7.0.2 to work
18:55:53 <copumpkin> wli: what about it?
18:59:41 <wli> copumpkin: I'm completely lost in Golub & van Loan's presentation of the algorithm.
19:00:34 <wli> copumpkin: Bulirisch & Stoer's actually, sorry.
19:00:41 <luite> which algorithm?
19:00:55 <wli> luite_: Simplex I think.
19:01:15 <wli> Checking Golub & van Loan real quick.
19:02:03 <copumpkin> all I really know about the simplex algorithm is that it can crawl around the outer "surface" of the simplex because solutions will be out there :)
19:02:20 <ion> > let breakEnd p xs = case breakAfter p xs of { (as,e@[]) -> (e,as); (as,bs) -> first (as ++) . breakEnd p $ bs }; breakAfter p = go where { go e@[] = (e,e); go (x:xs) | p x = ([x],xs) | otherwise = first (x:) . go $ xs } in breakEnd isSpace "foo bar\tbaz\nquux"
19:02:21 <lambdabot>   ("foo bar\tbaz\n","quux")
19:03:01 <luite> oh probably work out a few tableaux manually? or do you want to understand some specific optimization?
19:03:19 <wli> luite_: I'm having trouble absorbing the overviews.
19:03:29 <NemesisD> oh jeeze
19:03:40 <Balahla> I tried "cabal install gtk" and get ... depends on glib-0.12.0 wich failed to isntall
19:04:03 <NemesisD> Main.hs: This ELF file contains no symtab. Main.hs: Main.hs: panic! (the 'impossible' happened)
19:05:09 <luite> it probably helps if you just do a few steps by hand? but I guess usually you don't really need to care about the algorithm if you just use it
19:05:48 <wli> luite_: I can't just use it because the libs for it aren't polymorphic and I need to use them for more than bootstrapping.
19:05:55 <jonkri> Axman6, that's cool :)
19:06:13 <luite> you need to implement your own lp solver in haskell?
19:06:31 <monochrom> are you following http://deltadiaz.blogspot.com/2011/03/on-windows-how-to-install-gtk.html ?
19:06:51 <luite> I've made a simplex one, but it's terrible since it copies the entire matrix every iteration :)
19:07:21 <wli> luite_: I think what I'm on about is that even though the normal Remez affairs don't want linear programming in their inner loops, the Remez for my weirdo stuff doesn't have real exchange algorithms, so ends up using it to "brute force" the issue.
19:07:31 <wli> luite_: Is it polymorphic in the numerical type?
19:07:49 <luite> I think it's only for Rational
19:08:10 <wli> No go, then. I need it for the multiple-precision floating point stuff.
19:08:37 <luite> it probably isn't useful for any practical problem anyway (I wanted it for exact results to use in some proofs)
19:08:57 <wli> I basically need to say "Do this in N-tuple precision and I'll worry about downgrading to Double later."
19:09:19 <wli> Probably retrying with higher precisions until the results are good enough.
19:09:21 <luite> well apart from speed issues, Rational should be fine then ;p
19:09:55 <wli> luite_: Okay, how are things like sn(k,x), sin(x), exp(x), etc. supposed to deliver rational results?
19:10:59 <edwardk> wli: the remez algorithms are on my todo list for the algebra package
19:11:00 <luite> you don't use during the lp optimization do you? so you can just approximate them first
19:11:11 <dmwit> wli: Sorry, I got distracted. I'm back now, give me a sec.
19:13:14 <monochrom> strange number 3.141591234
19:13:16 <wli> edwardk: Well, the best uniform C^d piecewise rational approximant is another matter entirely.
19:14:19 <Love12> Hi
19:15:24 <luite> wli: but I made my implementation mainly as an experiment and for learning how the algoritm works. you could use the glpk exact simplex algorithm instead if you decide to go that way
19:15:34 <Love12> Hi
19:16:25 <wli> In lieu of legitimate Remez I was going to just have huge meshes and linear program the errors on the meshes.
19:16:32 <wli> luite_: Huh?
19:17:17 <luite> wli: huh what? :p
19:19:48 <wli> luite_: glpk can't be used. Quad precision etc. aren't available.
19:19:51 <luite> wli: if the precision of the hmatrix-glpk package is not enough, then you can make new bindings that use Rational, so that you don't lose any precision in the LP optimization.
19:20:06 <luite> wli: glpk has an exact simplex algorithm, with rational numbers
19:20:18 <hpaste> dmwit pasted “for wli” at http://hpaste.org/49058
19:20:42 <dmwit> *Main Data.Char> breakEnd isSpace ("aoseunth aosenuth    aoeunth" ++ undefined)
19:20:42 <dmwit> ("aoseunth aosenuth    *** Exception: Prelude.undefined
19:20:55 <dmwit> (so it's pretty lazy)
19:21:35 <luite> wli: it might be too slow for your purpose, probably much slower than quad precision float, but it just might be fast enough. try a few LP's before writing new bindings :p
19:21:50 * kmc hi-fives dmwit
19:25:59 <wli> luite_: Speed isn't the issue, it's precision. What on earth to do with full-blown arbitrary-precision rational arithmetic for higher transcendental functions is a rather difficult to answer question. Perhaps more difficult to answer than grinding out simplex.
19:26:36 <luite> wli: you don't need those things during the simplex runs, since everything will be encoded in your constrains and objective function, as rationals
19:26:43 <edwardk> wli: there are always lennarts CReals
19:27:04 <luite> so just approximate the transcendental stuffs first, then run simplex and see if the results is satisfactory
19:27:22 <luite> ugh too many typo's
19:27:45 <luite> hehe I wonder how a CReal based simplex algorithm would perform :)
19:28:02 <wli> CReals leave the same questions unanswered, as there's no idea when to stop iterating.
19:28:33 <dmwit> psh, who needs a real Eq instance when you have INFINITE PRECISION
19:30:06 <luite> wli: how would a polymorphic multiple precision algorithm solve this problem then?
19:31:01 <wli> luite_: The normal algorithms just use the epsilon machine precision for the higher-precision type as part of their affairs and so on.
19:31:25 <wli> luite_: It works just like Double, with maybe a different machine precision.
19:32:12 <luite> wli: the input of an exact simplex algorithm is a matrix with rational components, the output is a vector with rationals. no rounding is done, ever
19:32:36 <wli> Rounding needs to be done. It's relied upon.
19:33:23 <wli> Devising homebrew algorithms for the special functions is basically deriving new mathematical results. You can see where that's going.
19:33:34 <luite> which special functions?
19:35:32 <wli> It's meant to do it for numerous of them so as to be faster than the real algorithms. Circular, logarithmic, and exponential are obviously there, but gamma, zeta, Mathieu, Lamé, elliptic, and so on all crop up (well, elliptic parameter problems thwart things).
19:36:20 <luite> you mean you have constraints like   0 <= x_n <= exp(a/b) ?
19:36:46 <luite> and you cannot use a rational approximation before feeding them into the linear programming solver?
19:36:48 <wli> No, like the faux Remez is approximating sin(x).
19:37:09 <Raymod> hello. can anyone assist me? I'm stuck in simple cabal install =( Just installed HP 2009.2.0.2, trying to do "cabal install base-4.1.0.0" and it says the strange error "cabal.EXE: Distribution\Client\Dependency\TopDown.hs:170:37-73: Non-exhaustive patterns in lambda"
19:37:50 <dmwit> cabal-install'ing base is Not Recommended
19:37:52 <wli> I only get the deviations down to 1.0e-5 or thereabouts using glpk with Double on fine meshes.
19:37:53 <dmwit> Upgrade GHC instead.
19:37:58 <aspect> ]n
19:38:17 <luite> I'm kind of confused what exactly the problem is....
19:38:47 <Raymod> oh okay. How to know which version corresponds to what platform?
19:39:31 <dmwit> "ghc-pkg list base" will show what version is associated with your install of GHC.
19:39:57 <wli> luite: C^d piecewise rational approximants calculated by linear programming to enforce |f(x_i)-p_k(x_i)/q_k(x_i)|<=E for fine {x_i} meshes.
19:40:27 <wli> luite: Then hoping it beats down the deviations between points on the mesh with no real proofs.
19:40:35 <Raymod> it says "C:/Program Files/Haskell Platform/2009.2.0.2\package.conf:
19:40:58 <dmwit> ...and that's it?
19:45:21 <twb> Is this the best channel to look for code.haskell.org (nun) admins in?
19:47:51 <edwardk> luite: basically wli is tackling much the same problem that i am
19:50:38 <wli> There's a way to eliminate a couple of vars from Bernstein reps.
19:52:18 <edwardk> twb: yes
19:52:35 <wli> q_k(x) = \sum_{i=0}^{d_q} q_{k,i} B_{d_q,i}(x) then p_k(x) = q_{k,0} y_{k-1} B_{d_p,0}(x) + q_{k,d_q} y_k B_{d_p,d_p}(x) + \sum_{i=1}^{d_p-1} p_{k,i} B_{d_p,i}(x)
19:53:17 <Raymod> thank you. I think I'll try again later
19:53:24 <twb> edwardk: I'm trying to disable autoindexing; "Options -Indexes" in ~/public_html/.htaccess, but doing so turns my entire dir into 500 errors
19:53:29 <wli> Gets you C^0 for free and without quadratic constraints; probably the only way to proceed with linear programming as the only tool.
19:53:42 <luite> edwardk: hehe I guess I need to read more about what both of you are trying to do then :)
19:54:27 <edwardk> twb: i'm not one, but they are mostly in here ;)
19:54:53 <twb> edwardk: do you know what nicks to invoke?
19:55:13 <wli> luite_: http://proxima.lp0.eu/~wli/remez.pdf
19:55:15 <edwardk> luite: i've been playing with pade approximants, with an eye towards piecewise pade approximants with nice conditions at the boundaries
19:55:17 <hpaste> NemesisD pasted “Nonspecific Monad” at http://hpaste.org/49059
19:55:36 <edwardk> luite: wli has mostly been playing with boundary conditions
19:56:07 <NemesisD> could someone look at that and help me figure out why it isn't recognizing the return True as an IO Bool but rather an m0 bool ?
19:56:24 <NemesisD> apologies for the profanity in the code, i thought I'd censored that
19:58:24 <cmccann> NemesisD, why would it? Doesn't seem to be anything constraining its type.
19:58:50 <dmwit> eh
19:58:57 <dmwit> I don't think that error is saying what you think it is saying.
19:59:24 <dmwit> err... then again maybe it is =P
19:59:30 <NemesisD> cmccann: doh
20:00:15 <luite> wli: hehe you've linked that before, maybe I should properly read it for once :p
20:04:02 <wli> luite_: No, I wrote this afresh, but I've had that material in other writeups.
20:04:14 <wli> luite_: Albeit substantially less well-organized.
20:05:12 <wli> luite_: Refresh BTW.
20:09:56 <wli> luite_: I'm very unhappy with the bound in (10). I needed something in terms of epsilon or something.
20:10:51 <wli> luite_: It's also very difficult to get any mileage out of max_x |r'(x)-f'(x)|
20:12:30 <luite> wli: hold on I'm not there yet :)
20:12:47 <twb> I think I will just email the sysadmins
20:17:35 <wli> Changing clothes ordeal time.
20:24:51 <hpaste> fragamus pasted “newb requesting help” at http://hpaste.org/49061
20:27:26 <dmwit> fragamus: ehh... runStateT doesn't apply to the return type of runListT.
20:27:42 <dmwit> runStateT expects a StateT, but runListT returns an MList'.
20:28:05 <fragamus> lemme look at that
20:29:07 <fragamus> hmm if I replace the print $ gah   with print $ 5   it compiles and runs
20:29:42 <fragamus> so it would seem that the compile is OK with the previous line
20:29:52 <fragamus>         gah <- (runStateT (runListT (runRandT (schlock 9999) g)) 1.234)
20:29:55 <dmwit> Eh, sorry, I misread the type of runListT.
20:30:10 <dmwit> Still, runStateT gives you an MList', not an MList.
20:30:24 <dmwit> ...and definitely not a normal [a] list.
20:30:25 <fragamus> oh
20:30:40 <fragamus> can you help me
20:30:41 <dmwit> So you should definitely check out the MList and MList' types to make sure you understand what's really going on there.
20:30:58 <fragamus> I assure you, I have no clue what's going on anywhere
20:31:00 <fragamus> but
20:31:00 <dmwit> data MList' m a = MNil | a `MCons` MList m a
20:31:01 <dmwit> type MList m a  = m (MList' m a)
20:31:13 <fragamus> I still need to make progress
20:31:23 <dmwit> runListT :: ListT m a -> MList m a
20:31:43 <fragamus> From a high level, I THINK I have constructed something that has a list of states
20:31:53 <dmwit> So, running the action you get out of runListT gives you the head of the list, and a stateful computation to compute the tail of the list.
20:32:17 <dmwit> Running that stateful computation again gives you the head of the list, and another stateful computation for the tail of the list.
20:32:20 <dmwit> etc.
20:32:33 <fragamus> oh ok.
20:34:58 <fragamus> so i get a tuple?
20:35:24 <dmwit> No, you get an MList'.
20:36:30 <wli> luite_: Back.
20:36:54 <fragamus> And the semantics of an Mlist' is that it only computes the first value right
20:36:56 <dmwit> I'm a bit surprised that the library doesn't offer some function like "force :: MList m a -> m [a]".
20:37:12 <dmwit> MList' is a type.
20:37:24 <dmwit> So I'm not sure what exactly you mean by "it only computes x".
20:37:28 <dmwit> It doesn't compute anything.
20:37:35 <fragamus> ok sorry
20:38:35 <fragamus> I'm kind of lost, but I want to make a "force :: MList m a -> m [a]"
20:39:50 <dmwit> Alright, well, ask yourself: what things can you do with an MList m a?
20:40:02 <dmwit> (= m (MList' m a))
20:40:18 <fragamus> fmap?
20:40:50 <dmwit> Yes. Anything else?
20:41:36 <fragamus> head, tail, that kind of crap?
20:41:42 <dmwit> Not exactly.
20:41:51 <dmwit> head, tail, and that kind of crap operate on lists.
20:41:55 <platzhirsch> hey you guys, missed you
20:42:04 <dmwit> Hiya, platzhirsch.
20:42:11 <dmwit> fragamus: I'll give you a hint. =)
20:42:13 <dmwit> ?src Monad
20:42:13 <lambdabot> class  Monad m  where
20:42:13 <lambdabot>     (>>=)       :: forall a b. m a -> (a -> m b) -> m b
20:42:13 <lambdabot>     (>>)        :: forall a b. m a -> m b -> m b
20:42:13 <lambdabot>     return      :: a -> m a
20:42:13 <lambdabot>     fail        :: String -> m a
20:42:46 <fragamus> hmmm pondering
20:42:49 <wli> luite_: Refresh. Still there BTW?
20:42:58 <luite> yeah
20:43:42 <dmwit> fragamus: ...which of those functions can take an "m (MList' m a)" as an argument?
20:43:52 <wli> luite_: Anything needing fixups, clarifications, etc.?
20:44:24 <fragamus> bind?
20:44:24 <wli> luite: Or, for that matter, expanding on?
20:44:33 <dmwit> fragamus: Yep.
20:44:44 <dmwit> fragamus: Okay, so there's at least two things we can use: fmap or (>>=).
20:44:58 <dmwit> fragamus: Let's look at what the types of the other argument to these things would have to be to get what we want.
20:45:13 <fragamus> mkay
20:45:18 <dmwit> We want "MList m a -> m [a]".
20:45:35 <dmwit> Or rather, we have an "MList m a", and we want an "m [a]". That's a better way to say it, I think.
20:45:39 <dmwit> We start with either
20:45:49 <dmwit> fmap {- ??? -} mlist
20:45:50 <dmwit> or
20:45:56 <dmwit> mlist >>= {- ??? -}
20:46:08 <dmwit> Unifying types for these things, we can find that we want
20:46:28 <dmwit> fmap {- ??? :: MList' m a -> [a] -} mlist
20:46:29 <dmwit> or
20:46:45 <dmwit> mlist >>= {- ??? :: MList' m a -> m [a] -}
20:46:53 <dmwit> Which of those two looks most feasible to you?
20:47:17 <luite> wli: dunno, I follow most of it, though I need to check what (3) does
20:47:33 <fragamus> I am going to save this conv and study it hard. I request that you continue even though I am way behind
20:47:50 <dmwit> Oh.
20:48:00 <luite> haven't read the bit about Bernstein polynomials though
20:48:03 <wli> luite: It's an inductive argument that the continuity constraints can be reduced to quadratic.
20:48:05 <dmwit> This wasn't meant to be mysterious, so let's go slowly enough that we're together. =)
20:48:47 <fragamus> mlist >>= {- ??? :: MList' m a -> m [a] -}
20:48:55 <dmwit> Yeah, that looks more feasible to me, too.
20:49:07 <dmwit> But let's start from the beginning and make sure we're on the same page.
20:49:18 <dmwit> The goal is to write a function of type "MList m a -> m [a]".
20:49:24 <dmwit> We're going to use type-directed programming.
20:49:36 <dmwit> A bit like the way we might write this function in Agda or Coq, but without the automation to help us.
20:49:47 <dmwit> Since the thing has a function type, the first thing we do is make a lambda...
20:49:55 <luite> wli: yeah I know that, and I see how the conclusion follows from 3, just not how 3 follows from 2 yet
20:49:56 <dmwit> "\mlist -> {- ??? -}"
20:50:03 <fragamus> :)
20:50:16 <dmwit> Then, we know we want to return something of type "m [a]", so we annotate that...
20:50:25 <dmwit> "\mlist -> {- ??? :: m [a] -}"
20:50:59 <wli> luite: (3) follows from (2) just by treating the quotient as the product of its numerator and the reciprocal of its denominator, then using the Leibniz rule for repeated differentiation of a product.
20:51:00 <dmwit> The only thing in scope when writing "???" is "mlist :: MList m a", where "MList m a" is actually "m (MList' m a)"
20:51:05 <dmwit> So we can expand the type...
20:51:28 <dmwit> "\mlist :: m (MList' m a) -> {- ??? :: m [a] -}"
20:51:30 <dmwit> Together so far?
20:52:14 <luite> wli: oh ok, guess I just need to work out a simple one (or just assume that it's correct ;p )
20:52:37 <fragamus> yah
20:52:41 <dmwit> cool
20:52:49 <dmwit> So, now, we identified two possible ways forward.
20:53:12 <wli> luite: http://en.wikipedia.org/wiki/Leibniz_rule_%28generalized_product_rule%29
20:53:32 <dmwit> "\mlist :: m (MList' m a) -> fmap {- ??? -} mlist" or "\mlist :: m (MList' m a) -> mlist >>= {- ??? -}"
20:53:48 <dmwit> Now, we can look at the types of fmap and (>>=) to help us identify the type of (???) in each case:
20:53:51 <dmwit> :t fmap
20:53:52 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
20:54:37 <dmwit> Now we know "f a" is "m (MList' m a)", since that's the type of mlist.
20:54:40 <luite> wli: bah wikipedia makes everything too easy ;)
20:54:49 <shachaf> This is a bit of a silly thing to measure, but why is a so much faster than b in <http://hpaste.org/49062>?
20:54:53 <dmwit> And we know "f b" is "m [a]", since that's the type of the result we're trying to get.
20:54:53 <fragamus> yes i c
20:54:58 <wli> luite: Clarified, refresh.
20:55:33 <dmwit> So we can unify those, and write in particular fmap :: Functor m => (MList' m a -> [a]) -> m (MList' m a) -> m [a]
20:55:51 <dmwit> So the hole in the first option should be annotated like that:
20:56:01 <dmwit> \mlist -> fmap {- ??? :: MList' m a -> [a] -} mlist
20:56:09 <dmwit> We can do the same process for the second guy.
20:56:11 <dmwit> :t (>>=)
20:56:11 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
20:57:04 <dmwit> "m a" = "m (MList' m a)", and "m b" = "m [a]", so making those substitutions, "(>>=) :: m (MList' m a) -> (MList' m a -> m [a]) -> m [a]".
20:57:15 <fragamus> i like
20:57:23 <dmwit> Which means the second hole should be annotated like that:
20:57:35 <dmwit> \mlist -> mlist >>= {- ??? :: MList' m a -> m [a] -}
20:58:07 <dmwit> Now we can realize that this second hole is much more likely to be possible, so let's focus on writing something of type (MList' m a -> m [a]).
20:58:24 <dmwit> It's a function type, so start with a lambda...
20:58:36 <dmwit> \mlist -> mlist >>= \mlist' -> {- ??? -}
20:58:49 <dmwit> Can you see what the type of the (???) ought to be?
20:59:05 <fragamus> m [a] ?
20:59:09 <dmwit> yep!
20:59:12 <dmwit> Cool.
20:59:29 <dmwit> So we now have two things in scope: an MList m a (which we already used) and an MList' m a.
20:59:35 <dmwit> So my bet is we should use the second one.
20:59:54 <dmwit> We've got data MList' m a = MNil | MCons a (MList m a), so maybe we should pattern match...
21:00:26 <dmwit> \mlist -> mlist >>= \mlist' -> case mlist' of MNil -> {- ??? -}; MCons x mxs -> {- ??? -}
21:00:48 <dmwit> I bet you can write the MNil case. =)
21:01:03 <dmwit> (???) :: m [a], and we want it to be "like" an empty list somehow.
21:01:05 <fragamus> MNil -> []
21:01:09 <dmwit> Almost!
21:01:12 <dmwit> MNil -> return []
21:01:17 <fragamus> yah
21:01:46 <dmwit> How about the MCons case?
21:02:01 <dmwit> (Hint: recurse.)
21:02:32 <dmwit> By the way, the things in scope now are: mlist :: MList m a (used); mlist' :: MList' m a (used); x :: a; mxs :: MList m a
21:02:55 <dmwit> Oh, and since we're recursing, maybe we'd better name this instead of doing a lambda.
21:02:58 <dmwit> So the current context is
21:03:20 <dmwit> force mlist = mlist >>= \mlist' -> case mlist' of MNil -> return []; MCons x mxs -> {- ??? -}
21:04:02 <dmwit> force :: MList m a -> m [a]; x :: a; mxs :: MList m a
21:04:40 <fragamus> -> ??? : x:force mxs
21:04:53 <dmwit> Again, almost.
21:05:00 <dmwit> fmap (x:) (force mxs)
21:05:02 <luite> wli: oh by the way it's easy to see that the conclusion is sufficient for 3, but is it necessary?
21:05:14 <dmwit> or liftM (x:) (force mxs) if you like
21:05:19 <fragamus> ok
21:07:10 <wli> luite: Pretty much yes. All the lower-order derivatives of the numerator vanish, leaving only the last term with t=m, and then the denominators can't interfere with it (they're assumed nonvanishing/etc.).
21:07:23 <fragamus> force mlist = mlist >>= \mlist' -> case mlist' of MNil -> return []; MCons x mxs -> fmap (x:) (force mxs)
21:07:47 <dmwit> Looks good to me.
21:08:08 <fragamus> thank you
21:08:51 <dmwit> Welcome to type-directed development! =)
21:09:06 <fragamus> yes I see you have a method
21:09:40 <dmwit> hm
21:10:02 <dmwit> That wording suggests that you don't understand/like/feel comfortable with the method
21:10:05 <dmwit> =)
21:11:20 <luite> wli: sorry for asking stupid questions here, but why do they vanish? :p
21:11:37 <wli> luite: Induction hypothesis.
21:12:29 <luite> oh k
21:13:58 <wli> luite: The base case of 0th derivatives is just C^0 continuity, clearing denominators in p_k(x_{k+1})/q_k(x_{k+1}) = p_{k+1}(x_{k+1})/q_{k+1}(x_{k+1}).
21:17:10 <luite> wli: hehe I find it hard to read latex code from irc, but it's clear now
21:17:32 <wli> luite: There's no code there, it's just a LaTeX math doc.
21:18:10 <wli> luite: Refresh again, I guess.
21:19:03 <Axman6> if you have something of type f a b, where f a is a monad, what's the name of the b?
21:21:49 <luite> it's called the filling of the burrito
21:22:50 <Axman6> if you have something of type f a b, where f a is a monad, what's the name of the b? (in case that didn't get through before i disconnected)
21:23:06 <Axman6> i want to call it the return type of the monad, but I'm sure that not right
21:23:43 <NemesisD> is there a simpler way to define a read instance? I can't quite derive it. basically, read "group" = Group, read "person" = Person
21:26:50 <kmc> s/,/;/ and you're done
21:27:17 <kmc> oh, no, because "read" isn't actually the typeclass method
21:27:54 <kmc> see http://www.haskell.org/ghc/docs/7.0-latest/html/libraries/base-4.3.1.0/Text-ParserCombinators-ReadP.html
21:28:34 <wli> luite: Refresh. Further comments?
21:29:21 <kmc> :t const (\y -> [(x,"") | x <- ?f y])
21:29:22 <lambdabot> forall t t1 b. (?f::t -> [t1]) => b -> t -> [(t1, [Char])]
21:30:25 <NemesisD> whuuu
21:30:34 <Samuel> how is Haskell different from F#
21:30:55 <Samuel> I am trying to learn a new function language
21:31:16 <Samuel> but I am not sure where to direct my investement
21:31:26 <shachaf> @google haskell vs f#
21:31:27 <lambdabot> http://stackoverflow.com/questions/44961/what-are-the-primary-differences-between-haskell-and-f
21:31:27 <lambdabot> Title: programming languages - What are the primary differences between Haskell and F#? ...
21:31:37 <Samuel> F# seems to pick the steam, but yet Haskell is pretty known as well
21:31:51 <ion> It’s lazy, it’s pure, has better syntactic sugar for monads, ...
21:31:58 <NemesisD> kmc: what is ?f
21:31:58 <Axman6> Samuel: Haskell will teach you better practices, like separating IO from pure computations
21:32:33 <Samuel> would python be categorized as a functional language too?
21:32:48 <luite> wli: but I think you can still run a rational simplex algoritm if you take into account the approximation error from f(t_i) to rational. you just get a slightly weaker bound (or you have to run the simplex again with the rounds in the other direction).
21:32:50 <Axman6> it has functional aspects
21:33:03 <Axman6> python is a 'do everything' language
21:33:23 <Axman6> i understand its support for functional programming isn't that great though
21:34:38 <ion> It doesn’t even have a non-crippled lambda.
21:34:56 <kmc> NemesisD, the syntax?
21:35:05 <Samuel> from reading the article, it mentions that Haskell is not strongly typed!
21:35:21 <kmc> Samuel, Python is a functional language in the sense of "has first-class functions", but so is nearly every language other than Java and C and C++
21:35:23 <MatrixFrog> ?! what article is that? (sorry i just got here)
21:35:24 <lambdabot> Maybe you meant: . ? @ v
21:35:36 <kmc> "strongly typed" so muddled a term as to be useless
21:35:41 <kmc> i think bcpierce has a quote about that
21:35:54 <Axman6> Samuel: Haskell has imo the best type system around
21:36:23 <MatrixFrog> i feel like the more haskell i learn, the more Java (which is what i use at work) just makes me sad
21:36:27 <kmc> yes
21:36:32 <kmc> that is a common sentiment
21:36:34 <NemesisD> kmc: yeah that code sample you gave is beyond me
21:36:37 <kmc> learning Haskell is bad for your job satisfaction
21:36:44 <kmc> NemesisD, that's okay, it's not useful anyway
21:36:46 <MatrixFrog> well certainly common in #haskell i would think
21:36:50 <kmc> ?x is an "implicit parameter", a GHC extension
21:36:50 <lambdabot> Maybe you meant: . ? @ v
21:36:55 <kmc> basically dynamically-scoped variables
21:37:21 <kmc> > let { f y = ?x + y } in (let ?x = 4 in f 5)
21:37:22 <lambdabot>   9
21:37:55 <rekahsoft> > 1 + 1
21:37:56 <lambdabot>   2
21:37:58 <rekahsoft> reakky
21:38:08 <rekahsoft> wow thats sweet..never knew lambdabot did that^ lol
21:38:17 <kmc> that it evaluates Haskell expressions?
21:38:20 <rekahsoft> evaluatuon of expressions like in ghci lol
21:38:20 <NemesisD> kmc: i'm about this close from just not using read. its a shame that what i need is sooo close to the derived read
21:38:25 <rekahsoft> toally awesome
21:38:42 <kmc> that's one of the most often used lambdabot features
21:38:42 <NemesisD> or maybe just upcasing the first letter of the source string and then using the derived read.
21:38:45 <kmc> along with :t for getting types
21:38:49 <Samuel> it is lazy evaluation
21:38:55 <kmc> what is Samuel?
21:39:59 <wli> luite: The problem with that idea has to do with the computational methods for special functions. They simply do not work with arbitrary-precision rationals.
21:40:19 <Samuel> Haskel is Lazy, I know what it means, but Idon't truley know how this could effect my problem solving ability :)
21:40:50 <MatrixFrog> well it can be handy to deal with lists like [1..]
21:41:07 <Samuel> in the link that was posted here, "Lazy evalution" in Haskell makes it to solve complex issues
21:41:19 <Samuel> that is true
21:41:29 <MatrixFrog> in non-lazy languages you can do similar things but it's a bit more awkward sometimes
21:42:02 <luite> wli: I don't understand. the only thing thats possibly irrational is f(t_i) right? can't you approximate that within some epsilon by a rational number?
21:42:14 <cmccann> lazy evaluation isn't useful for solving problems you have so much as it's useful for not unnecessarily solving problems you don't have
21:42:15 <kmc> > let odds = 1 : map (+1) evens; evens = map (+1) odds in odds  -- Samuel
21:42:16 <lambdabot>   [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,5...
21:42:26 <Samuel> I will give it shot :)
21:42:33 <kmc> laziness and recursion go well together
21:42:45 <MatrixFrog> can someone repost the link in question? sounds cool
21:42:46 <Samuel> i was more incline to learn Python
21:42:47 <luite> wli: assuming you choose rational t_i and rational epsilon
21:42:48 <kmc> you can define your answer assuming you already have the answer
21:42:53 <kmc> Samuel, you should learn both
21:42:59 <Samuel> but I should also try haskwell
21:43:00 <kmc> Python will be useful right away
21:43:05 <kmc> Haskell will be useful after you've studied it for years
21:43:06 <Samuel> any good tutorials
21:43:11 <kmc> in the meantime, Haskell will be fun and mind-expanding
21:43:14 <kmc> @where lyah
21:43:15 <lambdabot> http://www.learnyouahaskell.com/
21:43:15 <Samuel> good book or well documented API
21:43:16 <kmc> @where rwh
21:43:16 <lambdabot> http://www.realworldhaskell.org/blog/ http://book.realworldhaskell.org/read/
21:43:19 <kmc> both of these Samuel
21:43:25 <kmc> API docs at http://www.haskell.org/ghc/docs/7.0-latest/html/libraries/index.html
21:43:26 <sanjoyd> Samuel: just don't expect to learn Haskell the same way you learn Python.
21:43:31 <kmc> libraries at http://hackage.haskell.org/packages/archive/pkg-list.html
21:43:32 <Samuel> thanks a bunch
21:43:36 <shachaf> @where books
21:43:36 <lambdabot> See `LYAH',`RWH',`YAHT',`HR',`wikibook'
21:43:41 <shachaf> Hmm.
21:43:47 <MatrixFrog> nice
21:43:58 <azaq23> Samuel: For python, see the tutorial on docs.python.org, it's the best tutorial for python available, and official too
21:44:12 <Samuel> thank you
21:45:00 <confab> Samuel: I'm coming from python as well, it's an interesting adventure, though not that different in some respects
21:45:28 <wli> luite: Evaluation algorithms for generalized continued fractions, for instance, rely on playing funny games with the machine precision.
21:46:03 <luite> wli: I don't see where you need machine precision here. everything could be arbitrary precision rational
21:46:35 <wli> luite: Termination criteria for many other special function -related algorithms are also based on the machine precision. Without a floating point number representation you're in a vacuum as far as trying to evaluate the special functions you're trying to calculate the Remez approximations for.
21:47:08 <azaq23> confab: "In some respects" being a very strong qualifier; one some levels, it is, on others, it just isn't (dynamic typing and the python object hierarchy vs haskell types for instance)
21:47:32 <wli> luite: You need it to evaluate the f(t_i) because you'd have to devise original mathematics in order to brew up algorithms not relying on machine precision to evaluate the special functions you're trying to get the Remez approximants for calculated!
21:48:39 <confab> azaq23: i meant that to be vaguer than it might have come out :)
21:49:27 <wli> luite: Without a machine precision the repertoire of special functions one can calculate is very, very limited. (sin(x), exp(x), not too much else)
21:49:28 <kmc> i think Python and Haskell seem quite similar if you're used to Java or C++
21:49:53 <luite> wli: just to be clear. you're trying to approximate f(x) with a piecewise rational function r(x), but you cannot even compute that function to any desired degree of accuracy? what hope is there then?
21:50:03 <luite> that funtion = f(x)
21:50:48 <kmc> Haskell's good static types and Python's no static types are the same kind of improvement over a Java-ish type system
21:50:50 <wli> luite: You can compute it so long as you've got a machine precision. N-tuple precision floating point is fine. Arbitrary-precision rationals breaks all the algorithms except for maybe circular and exponential.
21:51:05 <kmc> except that Haskell gives you a lot more
21:52:06 * wli is hard-pressed to see the resemblance between Haskell and Python apart from that they're Turing complete. They're totally different paradigms. But that's neither here nor there.
21:52:18 <cmccann> uh. they both have list comprehensions?
21:52:33 <cmccann> and whitespace blocks
21:52:41 <mee> good type inference gets typing out of your hair in much the same way duck typing does?
21:52:42 <cmccann> I think those are the usual points of similarity people point out :D
21:52:49 <kmc> neither Haskell and Python is a paradigm
21:52:54 <kmc> both of them support multiple paradigms
21:52:56 <wli> cmccann: Perhaps too superficial to count for me.
21:53:05 <kmc> any decent general-purpose programming language does
21:53:08 <cmccann> wli, precisely my point~
21:53:23 <kmc> i think this "paradigm" idea really is worse than useless
21:53:58 <wli> kmc: Python's imperative (OO) and Haskell's functional. I suppose I could point people in the directions of Mercury or Prolog, and maybe Verilog, too, for still more paradigms.
21:53:58 <kmc> Python and Haskell are both a lot more succinct / expressive than Java or C
21:54:16 <kmc> wli, i write lots of functional code in Python, and lots of imperative code in Haskell
21:54:26 <kmc> it's a very natural thing to do
21:54:35 <kmc> what "paradigm" you use should be a property of the problem, not of the language
21:54:53 <luite> wli: well as long as you have some error bounds on the computed function value at some point, then you have your epsilon :) but this part has nothing to do with the approximation you're describing right? this is just about how to compute the value of f(x) for some x
21:55:08 <cmccann> being OO doesn't really add anything tangible without a static type system, anyway. it might make some idioms more convenient, but that's syntax and style more than anything else
21:55:20 <kmc> right, I also do statically typed OOP in Haskell
21:55:34 <luite> wli: unless it's actually something else, I'd just leave it at that, and just assume that it can be computed.
21:55:35 <kmc> any decent language lets you do all of these things
21:55:51 <wli> luite: Yes, it's how the f(x) are computed. You could set it up to play with rationals and it would be useless because you couldn't do any f(x)'s you want, but otherwise "work."
21:55:52 <cmccann> kmc, but at that point you do hit a tangible distinction in that OOP usually implies a notion of subtyping, which isn't intrinsic to Haskell
21:56:12 <kmc> yeah, OOP means different things depending on who you ask
21:56:21 <kmc> i guess it was a popular buzzword in the 90's and so got attached to lots of things
21:56:44 <kmc> but there's a school of OOP that says "if you're doing dynamically-checked downcasts, you're Doing It Wrong"
21:56:46 <wli> luite: You can't assume that. It doesn't work in a vacuum. It has to work with the functions and their methods of computation.
21:56:47 <cmccann> kmc, yes, and I certainly have my own favorite definition :]
21:56:50 <kmc> and from that view the subtyping is less important
21:57:02 <kmc> also you can have dynamically checked downcasts in Haskell, see Control.Exception
21:57:05 <kmc> but it's not the same
21:57:30 <cmccann> kmc, dynamically checked downcasts isn't subtyping, it's "not having static types"
21:57:43 <kmc> well Java and C++ both allow it
21:57:55 <kmc> i guess the way i think about OOP, interfaces are the types
21:58:05 <kmc> that's the way i do OOP in Haskell, anyway
21:58:29 <NemesisD> RelaxNG specs can be annoyingly inprecise when you're parsing the xml into a typed language
21:58:51 <kmc> anyway, I think the similarities between Haskell and Python are not hard technical design features but some general sense of "this language lets me express what i want without a pile of irrelevant bullshit"
21:58:59 <cmccann> kmc, my preferred interpretation is of OO style as roughly encoding data by behavior instead of structure, i.e. the other half of the expression problem roughly speaking
22:00:01 <cmccann> which fits in nicely with the idea popular in some OO circles of using subtype polymorphism for control flow, which equates pretty directly to a church encoding of a sum type, i.e., the cases of a pattern match :]
22:00:53 <kmc> *nod*
22:00:58 <cmccann> except that by abstracting over the cases you gain extensibility in adding cases later
22:00:58 <kmc> aka "the visitor pattern"?
22:01:03 <cmccann> (again, the expression problem)
22:01:08 <luite> wli: hmm, I'm still not truly following... say you want to calculate f(x) for some rational x. then there isn't some n such that you can guarantee that the error is at most 2^(-n) ?
22:01:09 <confab> kmc: i think that's kinda what i meant
22:01:22 <confab> though on a more abstract level than that
22:01:28 <kmc> *nod*
22:01:33 <cmccann> yeah, the visitor pattern is basically reversing the above encoding in a clumsy way when what you really want is pattern matching :]
22:01:34 <kmc> i've found that the functional programming community and the rest of the programming world usually have two completely different terms for the same idea
22:01:48 <kmc> which leads to a lot of arguments where two people kind of argue past each other
22:01:51 <kmc> yeah
22:01:56 <wli> luite: No, they muck with the machine precision and use it as a constant parameter all over the place.
22:01:58 <kmc> i should learn Scala
22:02:09 <cmccann> there are cases where trying to cram the above encoding into Haskell leads to really awkward code as well, so there's a definite duality
22:02:19 <kmc> which is a very OOPy language with subtyping which also has algebraic data and pattern matching
22:02:23 <kmc> "yeah, he was from everywhere"
22:02:28 <wli> luite: "Machine precision" being related to the floating point data type one's using.
22:02:52 <cmccann> the more I hear people talk about Scala the more it starts to sound like a "worst of both worlds" compromise to be honest :[
22:03:17 <confab> so far i'm really liking the syntax of haskell though
22:03:27 <luite> wli: what's the use of a function where any evaluation can be incorrect to an arbitrary, unknown, degree?
22:03:56 <confab> it's elegant and terse
22:03:58 <wli> luite: It's not unknown. It's parametrized by the floating point type.
22:03:59 <cmccann> especially since I think it actually handles parameter variance for the subtyping relation correctly, which seems to be too complicated for most programmers to understand
22:04:02 <confab> pythonic if you will ;)
22:04:07 <luite> wli: isn't that enough?
22:05:00 <luite> wli: if your require 2^(-20) error at some point, and you need double precision for that, then use double precision to calulate the value, if you need 2^(-30) and quad precision, calculate it again with quads
22:05:14 <wli> > let eps = head . dropWhile (\x -> 1.0 + x > 1.0) $ iterate (/2) 1.0 in eps
22:05:16 <lambdabot>   1.1102230246251565e-16
22:05:57 <wli> luite: And how do you get quads? You can't, not without libs. Hence the need for the polymorphic bit.
22:06:01 <cmccann> kmc, have you seen http://lambda-the-ultimate.org/node/3668 ?
22:06:39 <wli> Woops, that's half of it.
22:07:11 <luite> wli: oh quite possible, but you only need them to calculate f. once you have the values for f, and their error boudns, then the rest can be done with rationals
22:07:12 <wli> > let eps = head . dropWhile (\x -> 1.0 + x/2 > 1.0) $ iterate (/2) 1.0 in eps
22:07:14 <lambdabot>   2.220446049250313e-16
22:08:17 <wli> luite: That would be insanely clunky. Also unclear how easy switching types based on dispatch on error bounds is. That's really ugly.
22:08:41 <kmc> cmccann, yes, it's the only language i know of which explicitly has covariant and contravariant subtyping of type parameters
22:09:04 <kmc> i'm generally wary of saying things i understand are too "complicated for average programmers" -- that way lies Java
22:09:28 <cmccann> kmc, don't Java and C# both support that to some extent? insofar as they botch it up in places and lose type safety, but that's nothing new.
22:09:42 <kmc> i think not as correctly
22:09:52 <kmc> tbh i don't know that much about Java and C# even though i talk smack about them constantly here
22:10:10 <cmccann> I think they both do the same wrong thing with arrays, if nothing else
22:10:14 <luite> wli: hmm, I don't see why... the only thing you need is a function evalF :: Rational -> Int -> Rational, f x n, where it gives you a Rational that's at most 2^(-n) from the true value. your whole approximation algorithm uses rationals then
22:10:20 <Kaidelong> I had to learn the distinction for C# once
22:10:21 <kmc> as far as I understand C# has the full picture of that sort of language, and Java is a crippled subset designed by a committee that looked down on its target audience
22:10:27 <Kaidelong> and have promptly forgot it
22:10:32 <Kaidelong> but I suppose I can look it up again
22:11:27 <cmccann> and, yes, I'm being somewhat snide about it being "too complicated". Variance is a natural result of having parameterized types and subtyping, which both Java and C# do, so I'm implying that they're too difficult for most programmers to use properly :P
22:11:31 <luite> wli: whoops make that evalF x n
22:12:20 <luite> wli: something that wraps your true f and approximates it using all the unholy numeric methods it needs :)
22:12:28 <cmccann> (to be fair, keeping parameter variance straight is kind of awkward, particularly in the presence of mutability, and I think it creates more headaches than it solves, but the problem there is using subtyping everywhere for no good reason)
22:12:39 <wli> luite: Dispatching on the precision to figure out the N in N-tuple precision required, and then use a data-dependent choice of multiple precision floating point types to achieve that, then converting that back to Rational is what you're saying?
22:12:51 <wli> luite: How do you even do data-dependent types like that?
22:14:32 <luite> wli: hmm, so the goal is to make a haskell library that approximates a haskell function that you know nothing about, by a piecewise rational one?
22:14:44 <wli> luite: I guess I can use the rational linear programming bit given that much... but...
22:15:10 <wli> luite: Mostly, yes. It's assumed C^0([a,b]) at the very least, maybe even C^d.
22:15:48 <wli> luite: BTW do you see the non-convex quadratically constrained quadratic program in there?
22:17:33 <luite> wli: ok, it was kind of unclear what the context was
22:17:59 <luite> I think you need at least some additional assumptions, or reservations about the accuracy of the result then
22:18:16 <wli> luite: Linear programming may very well not be enough if I want even C^0 continuity of the approximant.
22:19:49 <luite> wli: really? that's encoded as an equality constraint is it?
22:20:33 <wli> luite: Equation (15) right at the end of the writeup, if you've refreshed.
22:20:50 <kmc> cmccann, yeah, facts like "subtyping, polymorphic containers, and mutability interact awkwardly" are far from obvious
22:21:30 <kmc> but even established results are consistently ignored by those designing new languages
22:21:47 <cmccann> well, it's not awkward at all if you have a polymorphic mutable container, it can't vary at all
22:22:33 <cmccann> which is why nobody would do something ridiculous, like make a arrays of A a subtype of arrays of B just because A is a subtype of B
22:22:39 <cmccann> because that would be stupid and unsafe
22:23:04 <luite> wli: ah right
22:23:55 <kmc> "But I have a Ph.D. in Mathematics, and I'm sure a Circle is a kind of an Ellipse! Does this mean Marshall Cline is stupid? Or that C++ is stupid? Or that OO is stupid?"
22:24:29 <wli> luite: What do you know about nonconvex quadratically constrained quadratic programming?
22:24:54 <djahandarie> Almost as much as I know about redundantly constrained redundant programming.
22:25:20 <luite> not too much, I only know a bit about convex and a slight generalization quasiconvex
22:26:18 <wli> luite: I'm pretty sure these aren't convex.
22:26:27 <cmccann> kmc, immutable circles are a subtype of immutable elipses, and a write-only reference to an ellipse is a subtype of a write-only reference to a circle
22:26:38 <cmccann> kmc, for some reason this confuses people :?
22:27:40 * djahandarie originally thought "quadratic programming" was something similar to linear types where you could only use a variable twice, but then realized he was sorely mistaken after a google search
22:28:07 <luite> hehe quadratic types, interesting :p
22:28:31 <Rotaerk_> cmccann, that's not really, generally, true
22:28:39 <wli> djahandarie: More analogous to the degree in "linear programming"
22:28:49 <djahandarie> Right.
22:29:00 <djahandarie> Just had my mind in the wrong mode...
22:29:04 <cmccann> Rotaerk_, how so?
22:29:18 <Rotaerk_> cmccann, depends on what your circle type or class is/does
22:30:12 <cmccann> Rotaerk_, no it doesn't. Any circle is also an ellipse, by definition. If the object is immutable, you can always convert Circle -> Ellipse
22:30:28 <cmccann> the conversion is only problematic with mutable objects, where an ellipse can be modified to no longer be circular
22:30:43 <kmc> should i be ashamed for writing a view pattern like (splitAt 8 -> ((take 8 . (++ repeat 0)) -> ys, zs))
22:31:15 <shachaf> kmc: Maybe slightly.
22:31:32 <kmc> a secondary goal of this code is to piss off C macho dudes
22:31:37 <kmc> so i'm fine with it
22:31:47 * shachaf isn't sure how that's related.
22:31:57 <luite> wli: but I'm going to sleep now first and think about it some more tomorrow. thanks for the explanations
22:32:03 <wli> luite: AIUI Sequential Quadratic Programming (SQP) is lacking even in GSL/etc.; all there is is some Fortran snippet on netlib.org
22:32:11 * hackagebot ascii 0.0.2.2 - Type-safe, bytestring-based ASCII values.  http://hackage.haskell.org/package/ascii-0.0.2.2 (MichaelSnoyman)
22:32:19 <wli> luite: Alright, rest easy.
22:32:20 <shachaf> kmc: A padToWith helper function or something of that sort might be reasonable.
22:32:25 <kmc> yeah
22:32:32 <cmccann> a proper subtyping relation essentially asserts the existence of an implicit conversion Subtype -> Supertype that's total and preserves behavior
22:32:34 <kmc> frankly it would be a lot cleaner with separate 'take' and 'drop'
22:33:11 * hackagebot authenticate 0.9.1.7 - Authentication methods for Haskell web applications.  http://hackage.haskell.org/package/authenticate-0.9.1.7 (MichaelSnoyman)
22:34:13 * hackagebot wai-extra 0.4.0.3 - Provides some basic WAI handlers and middleware.  http://hackage.haskell.org/package/wai-extra-0.4.0.3 (MichaelSnoyman)
22:34:15 * hackagebot wai-test 0.1.0.1 - Unit test framework (built on HUnit) for WAI applications.  http://hackage.haskell.org/package/wai-test-0.1.0.1 (MichaelSnoyman)
22:34:18 * hackagebot warp 0.4.1.2 - A fast, light-weight web server for WAI applications.  http://hackage.haskell.org/package/warp-0.4.1.2 (MichaelSnoyman)
22:34:20 * hackagebot yesod-core 0.8.3.1 - Creation of type-safe, RESTful web applications.  http://hackage.haskell.org/package/yesod-core-0.8.3.1 (MichaelSnoyman)
22:34:30 <Rotaerk_> cmccann, if circles and ellipses are *objects* though, i.e. records of functions, then the subtype relationship between the two depend on the supported functions
22:35:14 <Rotaerk_> i.e. if circle and ellipse are classes
22:35:18 <luite> wli: still I think it would be best to set the numerical issues of computing f(x) aside for now, and assume a bounded first derivative or maybe bounded variation, work out the approximation based on that, and later see what restrictions you can remove
22:36:24 <wli> luite: I think my whole linear programming affair was a huge mistake because I forgot about the nonlinear constraints.
22:36:44 <cmccann> Rotaerk_, it's always possible to define a deliberately broken class hierarchy, if that's what you mean, but there's no sensible operation on an ellipse that isn't also sensible on a circle
22:37:11 <cmccann> allowing, of course, for correct variance in the types of member functions
22:38:11 <luite> wli: yes those seem hairy :) maybe you can work out a bit better what constraints exactly you have, make a table?
22:38:14 <Rotaerk_> cmccann, "set major radius" doesn't make sense for circle
22:38:25 <cmccann> Rotaerk_, that's why I specified immutability at least twice, yes
22:38:27 <Rotaerk_> so if ellipse has that, circle can't be a subclass
22:38:44 <Rotaerk_> cmccann, but there are mutating operations that wouldn't break that relationship...
22:38:57 <wli> luite: That much I have substantial prior experience with and can just go to work on writing up. I'll probably have that by tomorrow night (the day will be fraught with practical concerns).
22:38:57 <luite> anyway, really going to sleep now
22:39:06 <wli> luite: Rest easy.
22:39:13 <luite> thanks
22:40:54 <Rotaerk_> my point is that mutability isn't sufficient to break the "a circle is an ellipse" relationship
22:40:55 <cmccann> Rotaerk_, yes, I don't think I said otherwise
22:41:27 <cmccann> anyway, I was talking mostly about mutable references
22:41:40 <cmccann> er, said otherwise about some mutations preserving the relationship
22:42:13 <Rotaerk_> well anyway, bed time
22:42:17 <cmccann> my intent was to say that immutability is sufficient to preserve the relation, while mutable references are sufficient to violate it
22:42:22 <cmccann> restricted mutation is more complicated
22:42:27 <Rotaerk_> true
22:42:57 <cmccann> all evidence for my assertion that variance is too complicated for most programmers, otherwise this wouldn't be so hard to say clearly :[
22:43:12 * cmccann gets a headache from worrying about variance too easily
22:44:53 <cmccann> though for the Haskell-minded, covariance corresponds pretty closely to having a valid Functor instance
22:46:01 <copumpkin> and if you have a Contrafunctor/Contravariant
22:46:03 <copumpkin> guess what that is
22:46:07 <copumpkin> :P
22:46:17 <cmccann> copumpkin, gee I have no idea
22:47:40 <cmccann> contravariant parameters tend to show up as write-only mutable references, which sort of goes to show why a Contrafunctor class doesn't seem to get much mileage in Haskell
22:48:06 <copumpkin> it's really for anything in a negative position
22:48:14 <cmccann> well, yeah
22:48:28 <copumpkin> newtype Pred a = Pred (a -> Bool)
22:48:34 <copumpkin> instance Contravariant Pred
22:49:37 * cmccann nods
22:50:13 <cmccann> data structures with type parameters that end up in negative position seem to be less common, though that's a really nice example
22:51:35 <copumpkin> well, parsers are covariant functors
22:51:45 <copumpkin> serializers would be contravariant
22:52:07 * cmccann nods
22:52:16 <copumpkin> but yeah, I guess they aren't as common :(
22:52:55 <cmccann> copumpkin, probably doesn't help that lacking a standard Contrafunctor/whatever class makes people less likely to notice them
22:53:03 <copumpkin> yeah
22:53:07 <copumpkin> my first reaction to them
22:53:19 <copumpkin> was "how the hell could you write an instance with a method of that signature??"
22:53:21 <copumpkin> :P
22:53:23 <cmccann> haha
22:53:28 <cmccann> yeah, same here pretty much
22:54:26 <cmccann> and it's still hard to think of motivating examples that aren't just trivial specializations of (-> r)
22:56:14 <copumpkin> the first one I wrote was for folds from http://squing.blogspot.com/2008/11/beautiful-folding.html
22:56:41 <copumpkin> a combinator library of data serializers would also not really be a trivial function
22:57:02 <cmccann> copumpkin, yeah, that's probably the best example I've heard so far
22:59:05 <azaq23> so; if there's a type which has a functor instance, covariance is if I can say that, in given type variables a and b, a being a subtype of b means also that the functorized f a and  f b also preserves this notion, so that f a is also a subtype of f b, whereas this wouldn't be normally defined? And in the contravariant case, that f b is a subtype of f a?
22:59:05 <azaq23> And this is related to functors due to the "structure preserving" property?
23:00:31 <cmccann> azaq23, the subtyping relation gives an implicit conversion such that if a < b, you can conjure up a function a -> b
23:00:58 <cmccann> so for a functor f, given the implicit conversion a < b, you can conjure up a conversion f a -> f b in the obvious way
23:01:17 <cmccann> so f a < f b as well
23:01:21 <azaq23> ah makes sense yes
23:01:23 <cmccann> modulo some handwaving
23:02:04 <cmccann> whereas contravariance would be a contravariant functor f such that given a < b, you can conjure up a conversion f b -> f a, thus f b < f a
23:03:12 <cmccann> azaq23, a contravariant functor being one with a function like "contramap :: (a -> b) -> (f b -> f a)", the most obvious example being function pre-composition
23:03:38 <cmccann> e.g., giving "contramap :: (a -> b) -> ((b -> r) -> (a -> r))
23:05:05 <cmccann> things tend to get thorny when dealing with this in a language where subtyping relations are only defined directly on records of functions with mutable internal state, but the idea is basically the same
23:08:04 <dobblego> edwardk: why not rename &&& on Lens to the two possible versions?
23:09:18 <cmccann> ok, anyway, enough about subtyping and parameter variance
23:09:28 <cmccann> I'm still not even convinced it's useful in practice anyway
23:09:34 <cmccann> and I need to get some sleep :T
23:09:46 <azaq23> cmccann: thank you :)
23:11:07 <cmccann> though I still have a hard time taking seriously a language that has subtyping as a defining characteristic and bungles it completely
23:11:13 <cmccann> not to name names or anything >:I
23:11:21 <cmccann> but oh well
23:11:50 <dobblego> please name names
23:12:12 <cmccann> ...heh
23:12:30 <java> hi all
23:12:43 * cmccann was obviously complaining about C#, anyway ;]
23:14:19 <cmccann> and dobblego, I'm well aware you're one of the last people who needs to be told about how languages mangle subtyping and variance :P
23:14:39 <dobblego> there was once a time when I was very lonely in that respect
23:15:14 <cmccann> though honestly I actually find it most hilarious (and sad) that Eiffel gets it not just wrong, but explicitly and deliberate backwards in some cases
23:16:01 <cmccann> I mean, we all expect java, C#, and their ilk to not be type safe
23:16:12 <NemesisD> i've got to represent a date that may or may not have a year, year and month, or year and month and day, i'm not sure if i should represent it as a (Int, Maybe Int, Maybe Int) or Date Int (Maybe Int) (Maybe Int)
23:16:43 <dobblego> NemesisD: I would use an abstract data type
23:17:09 <cmccann> but Eiffel likes to talk up correctness and whatnot and then it makes such an obvious, blatant error :[
23:17:16 <cmccann> it's like they're not even trying
23:18:02 <dobblego> I see ongoing errors in other languages, where it's like they are in fact trying, but trying to fail
23:18:30 <dobblego> it is as if, there is no lesson to learn, except for the lesson that there are no more lessons
23:18:54 <NemesisD> dobblego: would it be more appropriate to do PartialDate Int (Maybe Int) (Maybe Int)  or something more like OnlyYear Int | YearAndMonth Int Int | YearMonthDay Int Int Int
23:19:14 <dobblego> NemesisD: I would hide the constructors and use whatever makes it easiest to write the API
23:19:36 <NemesisD> ok
23:19:39 * cmccann is suddenly struck by the desire to reread the webcomic A Lesson Is Learned (But The Damage Is Irreversible)
