00:06:17 <ketil> Any idea where 'darcs send' gets my (i.e. the sender's) email address?
00:12:19 <Saizan> from the environment variable DARCS_EMAIL
00:16:09 <ClaudiusMaximus> any recommended a way to handle nested graphs with ports?  by which i mean each node has a number of distinguishable inputs and outputs, and nodes might either be atomic or be a graph of other nodes
00:18:23 <ClaudiusMaximus> the only algorithm i need is topological sort, which i found in fgl, but the port stuff i'm not so sure on - would it make sense to have this information in edge labels?
00:22:25 <mustelo> ClaudiusMaximus, edge labels are certainly sufficient, right?
00:23:59 <ClaudiusMaximus> mustelo: yes, and thinking about it, they'd be useful elsewhere in the program i have in mind
00:42:35 <donri> are e.g. functor "laws" enforced in the language / the definition of the typeclass?
00:43:09 <Saizan> no
00:44:10 <Saizan> there isn't a good way within haskell to convince the compiler that they hold
00:45:11 <donri> am i right to think "laws" are kinda like eiffel contracts?
00:45:12 <ketil> Saizan, about DARCS_EMAIL, I thought it would be sufficient to set ~/.darcs/author?  But apparently, darcs generates its own (bogus) address when DARCS_EMAIL isn't set.
00:46:47 <erus`> how can i solve the halting problem?
00:46:55 <Saizan> ketil: i wouldn't know, i guess you could check the manual
00:47:22 <ketil> Yes.. when everything else fails :-)
00:47:33 <Saizan> erus`: approximatively
00:48:18 <ketil> I googled, and found one that says _darcs/prefs/author overrides the env var - I'm not sure why ~/.darcs/author wouldn't also.
00:48:29 <ketil> But I see now that it's an old page, will check a newer one.
00:49:09 <Jafet> erus`: catch NonTerminationException
00:51:00 <frerich> Are there plans to have a new version of the Haskell language, which maybe incorporates some common language extensions? I find OverlappingInstances very useful, I can't even see a downside to it - it'd be nice if the language would just work like that straight away :-)
00:52:19 <Saizan> there is the haskell prime process, which since 2010 is supposed to produce a new standard incorporating some well proven extensions every year
00:53:11 <Saizan> OverlappingInstances is very controversial as it is, there are some tamer refinements in consideration though
00:53:30 <Saizan> the last discussion on the haskell prime mailing list is about this
00:53:38 <Jafet> I find IncoherentInstances very useful, I can't even see a downside to it
00:53:54 <frerich> ;->
00:54:15 <frerich> Well at least for my projects, OverlappingInstances always seemed to just do the Right Thing(tm)
00:54:30 <Saizan> you can write prolog's var/1 with IncoherentInstances
00:56:01 <Saizan> OverlappingInstances if not used very carefully can break the global consistency of instances, i.e. you might end up with different parts of your code using different instances for the same type
00:57:28 <frerich> Hm. I do wonder how it works when writing a module which uses OI but a client code importing that module does not use that extension.
00:58:52 <Saizan> the presence of OI matters only where you're defining the instances
00:59:59 <donri> hm bug in lyah? "import qualified Foldable as F"
01:00:57 <Saizan> why bug?
01:01:13 <kfish> Data.Foldable
01:01:24 <Saizan> ah, true
01:02:52 <donri> bottom of monoids chapter
01:02:54 <Jafet> Or feature request?
01:06:31 <Roklobsta> hmm, does this channel hold all the world's haskell programmers?
01:07:00 <Lemmih> Roklobsta: Nearly.
01:07:35 <donri> haha
01:07:49 <Roklobsta> i am not a haskell programmer so don't count me.
01:08:24 <Lemmih> Roklobsta: Too late. You've already been counted.
01:08:37 <Botje> you'll have to learn haskell now.
01:09:14 <Roklobsta> yes.  Well, I'd like to dive into the deep end and write a network server and data processor in haskell
01:09:24 <permagreen> I just like to play around with programming languages. I'm mostly in here just in here to learn what I can
01:09:31 <Roklobsta> that deals with clients in the cloud.
01:09:46 <Jafet> Haskell's depths are not bounded above
01:10:04 <Jafet> Or should I say below
01:10:41 <Roklobsta> is haskell programming nirvana or do I need to smoke a doobie before I get stuck in?
01:11:08 <Botje> eh, it's nice.
01:11:12 <Jafet> @quote cocaine
01:11:12 <lambdabot> No quotes match. Take a stress pill and think things over.
01:11:15 <permagreen> You don't need to, but it helps
01:11:18 <Jafet> @quote heroin
01:11:18 <lambdabot> roconnor says: <roconnor> merijn: I got into Haskell from Coq. <xplat> that's like getting into drinking through heroin.
01:11:36 <int-e> Haskell has its dark corners. We like to believe that it has fewer than other programming languages :)
01:11:37 <Jafet> (Coqaine?)
01:12:46 <int-e> And it may spoil you forever for other programming languages that force you to write all sorts of boilerplate code before you can get real work done.
01:13:14 <donri> java likes to abstract abstractions into concrete abstractions and haskell likes to abstract concrete abstractions into abstract abstractions
01:13:35 <Roklobsta> just had a look at apt-cache - haskell as an sqlite driver.  nice
01:13:50 <permagreen> The most annoying gotcha I find myself running into is division. Twice now I've spent ages trying to debug some strange type error only to realize I was using the wrong division function.
01:14:05 <Roklobsta> it's not overloaded /?
01:14:28 <Botje> if you want 5 / 2 = 2 like in C, you have to ask for it explicitly.
01:14:37 <Roklobsta> well, i'll do some reading.
01:14:39 <Jafet> It is overloaded on types--not meanings.
01:14:43 <ClaudiusMaximus> > (1/7, 1/7, 1/7) :: (Float, Double, Rational)
01:14:44 <lambdabot>   (0.14285715,0.14285714285714285,1 % 7)
01:15:03 <Roklobsta> ok, i'll say one word.  F#.  Will you all start frothing?
01:15:06 <Jafet> Many languages have separate names for fractional and integer division.
01:15:27 <Jafet> No, you'll have to troll much better than that
01:15:34 <Roklobsta> Erlang.
01:15:44 <permagreen> Yeah, I know that. Now.
01:16:00 <donri> COBOL.
01:16:38 <Botje> hey, cobol on cogs is the industry's leading web framework!
01:16:55 <Roklobsta> It's a shame you can't get Haskell for Arduino.
01:17:25 <Botje> you can get it on the iPhone, Android, and FPGA's
01:17:30 <Botje> good enough for now.
01:18:42 <Jafet> I thought that if you used Haskell, iPhone would get YOU!!
01:19:50 <Roklobsta> I am strictly a C monkey with embedded system experience only.  I have much to learn...
01:20:52 <zomg> Just keep at it, I think it's rather rewarding once you start to understand how it works
01:21:52 <donri> start with lyah if you didn't know it already
01:21:54 <donri> @lyah
01:21:54 <lambdabot> Unknown command, try @list
01:21:57 <zomg> I mostly work with PHP at work and after learning Haskell on my spare time I keep seeing how much nicer many structures would be written in it instead of PHP =)
01:22:33 <Jafet> Be careful, you might end up writing third-order anonymous functions in PHP
01:22:54 <eikke> I've been playing around with GADTs and tried to implement a list-with-length type, which sort-of works (head and tail behave as expected), but I got 2 questions
01:23:06 <eikke> code at https://gist.github.com/1167607
01:23:11 <zomg> Jafet: I already wrote a small lib which lets me do some foldr/filter/map type things more easily :D
01:23:21 <eikke> 1. fromList doesn't type-check, I wonder whether it can be implemented at all
01:23:42 <eikke> 2. can I use (:) instead of `cons` somehow? defining (:) the most obvious way seems not to work
01:24:01 <Jafet> Well, (:) would shadow (Prelude.:)
01:24:14 <eikke> which is why I import Prelude qualified
01:24:26 <Jafet> Other than that, I presume it's allowed
01:24:53 <donri> zomg: weird definition of rewarding; like working in a chinese factory and watching a documentary on the work conditions in the google hq
01:25:11 <Jafet> If it's not allowed, there's the olegism (:::)
01:25:24 <Jafet> (Martian greeting operator)
01:26:06 <eikke> Jafet: still struggling... and g2g now, meeting :/
01:26:25 <Jafet> I don't know much about GADTs, but you might need a Nat type family or something to type out fromList
01:26:53 <Roklobsta> do i need to forget all the old data abstractions and concepts that i use in C?
01:27:21 <Jafet> Nope, you'll just see those abstractions more clearly once you remove the C from them
01:27:39 <Roklobsta> well, i mean like pointers, linked lists etc.
01:28:10 <bragh> argh. 'cabal install yi' fails because it can't find happy version >= 1.17, but it's in my path and 'happy -v' works fine. happy doesn't show up in 'ghc-pkg list' though, would registering it with ghc-pkg fix it?
01:28:24 <eikke> Jafet: thanks, will try some more
01:28:27 <Jafet> Pointers are a way to have indirection and referencing, which are free in Haskell
01:28:45 <Jafet> You don't need to pull out as much hair to accomplish those things here
01:28:51 <hnsz> Roklobsta: You should just try and see :)
01:29:16 <Saizan> bragh: no, programs don't get registered with ghc-pkg
01:29:25 <huangyi> linked list is like the most important structure in haskell.
01:29:41 <Botje> Roklobsta: data List a = Nil | Cons a (List a) -- boom, linked list
01:29:43 <Jafet> Well, one kind of linked list
01:29:56 <Botje> parameterized, too
01:30:03 <Saizan> bragh: there's probably a problem with your $PATH, but you can override the search using --with-happy=path/to/happy
01:30:38 <bragh> Saizan: ah, I see. thanks. could there be something with cabal using some other path than my own?
01:31:49 <Saizan> bragh: that could happen if you haven't export'ed it, another problem might be that you have the character ~ in there
01:31:57 <Saizan> you should use $HOME instead
01:33:07 <bragh> Saizan: thank you! that seems to have fixed it
01:33:47 <Jafet> echo 'PATH=~/.cabal/bin:$PATH' >> ~/.zshrc
01:34:26 <bragh> Jafet: i had ~/.cabal/bin in my path before, i replaced it with $HOME/.cabal/bin and now it works
01:34:49 <bragh> seems to be this (now i find the answer after i get the fix): http://comments.gmane.org/gmane.comp.lang.haskell.cafe/74150
01:36:23 <Jafet> ~ only gets expanded at the beginning of a word, or something like that
01:36:47 <Jafet> Bah, sh-mucks.
01:41:08 <Roklobsta> OK I'll learn me a Haskell and lurk here.
01:43:48 <mux> welcome to the zoo!
01:48:29 * hackagebot iso3166-country-codes 0.20110810.4 - A datatype for ISO 3166 country codes  http://hackage.haskell.org/package/iso3166-country-codes-0.20110810.4 (JonFairbairn)
01:53:37 <Roklobsta> Has anyone written "Haskell by Osmosis" yet?
01:54:03 <blackh> That's a great idea!
01:55:05 <dankna> If you write that book
01:55:10 <dankna> I promise to sleep with it under my pillow
01:55:17 <dankna> at least, if it's a paperback
01:55:33 <dankna> a hardback would probably mess up my neck
01:56:01 <Botje> then use it as a monitor stand]
01:56:06 <dankna> true
01:56:12 <dankna> but I use a laptop, and failing that a Mac
01:56:16 <dankna> monitor stands are irrelevant :)
01:56:21 <Botje> laptop stand, then
01:56:29 <dankna> heathen, laptops belong in laps
01:56:39 <Botje> laptop lap stands
01:56:41 <Botje> -s
01:56:44 <luite> doesn't a laptop under your pillow work/
01:56:45 <dankna> mm
01:56:46 <dankna> maybe
01:56:50 <luite> with a pdf of course
01:56:51 <dankna> no, because that might damage the laptop
01:57:02 <luite> then you have a lousy laptop :p
01:57:17 <dankna> yes, after doing that to the poor piece of hardware, it would be
01:58:25 <Botje> bloody cyberbums use their laptops as pillows.
01:58:51 <luite> I don't sleep on my laptop, but I do often use my ipad to read in bed, often falling asleep
01:59:00 <luite> and it holds up surprisingly well :)
01:59:01 <dankna> yeah, that's different
01:59:45 <dankna> out of curiosity, how do you hold it when doing that?
01:59:54 <dankna> I haven't found a good posture (I haven't got an iPad though)
02:01:40 <luite> depends, if I lie on my back, then I rest it on my legs usually, or a little closer in both hands, elbows on the bed
02:01:51 <dankna> hmm
02:02:03 <luite> on my side, often with one corner on the bed
02:02:15 <dankna> yeah, the latter sounds like it would work better for me
02:02:25 <aspect> what's the best tool for a newbie to build a simple parser in?  I like Hutton's monadic parser combinators and translated them into Scheme a while ago, but not sure I want to re-transcribe the article just to provide a string representation for my objects
02:02:27 <dankna> my neck complains when I try to sit up in bed
02:02:47 <dankna> aspect: Parsec is popular, but I personally dislike it for being O(too much)
02:02:54 <luite> it's easier to hold than most books :)
02:02:59 <dankna> fair :)
02:03:10 <mux> I've had a very good experience with attoparsec
02:03:29 <dankna> note that my objection to Parsec is a categorical objection to all LL parsers
02:03:46 <dankna> and note that you can still get lots of work done with it :)
02:04:10 <erus`> how can i represent a static n*n Matrix in a nice way (in code)
02:04:16 <erus`> so it looks like a table
02:04:23 <Botje> you format it like one
02:04:28 <luite> dankna: do you use linux on your laptop?
02:04:33 <dankna> no, OS X, why?
02:05:34 <luite> oh my laptop is dying and I probably need a new one. thinking of macbook, but I'd like to run linux. and I saw tht you have a macbook on the hac phi pictures :)
02:05:37 <aspect> the grammar I'm parsing is incredibly simple.  Not regular, as it's recursive, but there's no need for lookahead, no token nesting
02:05:51 <dankna> ah, yes, haha :)
02:06:01 <dankna> I've booted it into Knoppix
02:06:13 <dankna> (for recovering it - quite a story there, but never mind)
02:06:18 <dankna> it seemed to work fine
02:06:38 <dankna> aspect: then Parsec-like tools should be fine.  pick one that speaks to you and go with it :)
02:06:39 <erus`> can i have a literal map?
02:07:11 <dankna> there's a page that explains to you how you can set up a tri-boot thingy
02:07:21 <dankna> I would strongly caution you to use Disk Utility, and not parted, to do your partition editing
02:07:47 <luite> well, maybe OS X will also be fine for haskell dev, with virtual machines for linux where necessary
02:07:50 <aspect> ah, and it's monadic style very reminiscent of Hutton's paper.  That's great :)
02:08:01 <dankna> that's the strategy I've taken, but it comes down to what you enjoy working in
02:08:31 <dankna> I like VMWare Fusion a lot, but I haven't tried the competitor whassname, and might like it just as much.
02:08:38 <luite> unfortunately the entry level mbp 15" has a cpu with no iommu, so access to hardware in a vm is more limited
02:08:47 <dankna> hmm, true
02:08:52 <luite> and the other one is too expensive
02:08:59 <Saizan> erus`: you can do myMap = Data.Map.fromList [(k1,v1),(k2,v2), ...]
02:09:05 <dankna> well, what are you doing that requires access to hardware?
02:09:17 <luite> probably nothing at the moment :
02:09:19 <luite> :)
02:09:22 <dankna> haha okay
02:11:04 <kamekura> hi all. Can anyone explain me why Data.Ord.PartialOrd cmp's return Maybe Ordering, instead of defining a new PartialOrdering?
02:11:23 <kamekura> and why gt returns Maybe Bool instead of Bool?
02:11:51 <Botje> probably so you can chain multiple PartialOrds together using monoids.
02:12:16 <kamekura> documentation says "We use Maybe instead of defining new types PartialOrdering and FuzzyBool because this way should make the class easier to use. " but I can't see how that is easier
02:13:15 <kamekura> ok but you could do that with a PartialOrdering that is like Ordering plus a Uncomparable value, right?
02:14:22 <kamekura> in stardard notation,  a >=  b is either true or false, regardless of whether >= is total or partial ordering
02:16:37 <kamekura> if no one contradicts me, I must be right (jk)
02:19:25 <Rotsor> kamekura, how do you think >= should decide whether to return true or false if the values are not comparable?
02:20:34 <bragh> Rotsor: trial by combat
02:21:16 <Rotsor> @pl (\f g h x = f (g x) (h x))
02:21:16 <lambdabot> (line 1, column 11):
02:21:16 <lambdabot> unexpected "="
02:21:16 <lambdabot> expecting pattern or "->"
02:21:26 <Rotsor> @pl (\f g h x -> f (g x) (h x))
02:21:27 <lambdabot> liftM2
02:23:14 <ski> Rotsor : if they are not comparable, it should yield `False'
02:23:57 <Rotsor> ski, Why is that?
02:24:33 <ski> because if `a' is incomparable to `b', then it is not the case that `a' is greater than or equal to `b'
02:24:59 <ski> `a >= b' should be `True' when `a' is greater than or equal to `b', and `False' otherwise
02:26:01 <Rotsor> hmm, okay, but that would mean (a >= b) /= not (a < b)
02:26:16 <ski> indeed
02:26:25 <ski> that is a thing of total orders
02:27:34 <ski> one of the simplest non-total orders is the product order of two non-trivial orders
02:28:14 <ski> there `(a0,b0) >= (a1,b1)  =  a0 >= a1 && b0 >= b1'
02:29:47 <Rotsor> the simplest non-total order seems to be x >= y = False :)
02:29:49 <ski> so `(5,10) >= (4,6)' is `True', and all of `(5,10) >= (4,15)',`(5,10) >= (8,6)',`(5,10) >= (9,15)' are `False'
02:30:23 <ski> Rotsor : well, that doesn't satisfy the reflexivity axiom : `forall x. x >= x  =  True' :)
02:30:35 <Rotsor> ah :)
02:30:50 <ski> a partial order must satisfy reflexivity, transitivity, and anti-symmetry
02:31:11 <ski> a pre-order must have reflexivity and transitivity, but doesn't need anti-symmetry
02:32:32 <ski> e.g. we can define an ordering `divides x y = True <=> exists k. x*k = y'
02:32:41 <Rotsor> Ah, x >= y = True then!
02:33:11 <ski> Rotsor : that is a valid pre-order, but it's only a valid partial order if your type has at most one element :)
02:33:38 <Rotsor> Indeed
02:34:08 <ski> anti-symmetry says `forall x y. x >= y && y >= x  =  True  =>  x = y'
02:35:03 <Rotsor> ... where "=" is what? I always have trouble when asking myself this question.
02:35:11 <ski> i.e., the only way in which two things can both compare to `True' with the other one, is if they're the same thing
02:35:19 <ski> where `=' is equality
02:35:54 <Rotsor> but having used "==" I don't trust the word "equality" anymore :D
02:36:13 <ski> well, `==' is the function that computes equality
02:36:25 <ski> equality is not always computable
02:36:48 <ski> but you can talk about anti-symmetry, regardless
02:37:06 <ski> `x = y' means that you can prove them to be the same
02:37:30 <ski> `x == y = True' means that you can prove that the `==' Haskell function can *compute* that they are the same
02:37:39 <ski> > [0 ..] == [0 ..]
02:37:43 <lambdabot>   mueval-core: Time limit exceeded
02:38:07 <ski> those infinite lists are the same, but we can't compute with `==' to see that, we have to realize that on our own
02:39:02 <Rotsor> Indeed. Do you use Agda btw? :)
02:39:19 <ski> anyway, the `divides' relation i mentioned about is a pre-order, but is not a partial order
02:39:27 <ski> Rotsor : sometimes
02:39:41 * mustelo was hoping for "i'm a guy who prefers coq"
02:39:47 <Eduard_Munteanu> Rotsor: there's #agda too ;)
02:39:56 <Eduard_Munteanu> Heh.
02:40:04 <ski> e.g. `divides 2 n' holds when `n' is even
02:40:19 <erus`> > agda is a mind fuck
02:40:19 <lambdabot>   Not in scope: `agda'Not in scope: `is'Not in scope: `mind'Not in scope: `fu...
02:42:04 <ski> > map (2 `divides`) [0,2 ..]
02:42:06 <lambdabot>   [True,True,True,True,True,True,True,True,True,True,True,True,True,True,True...
02:42:22 <Rotsor> ski, I don't see how a `divides` b and b `divides` a is possible when a/=b
02:42:39 <ski> > (2 `divides` (-2),(-2) `divides` 2)
02:42:41 <lambdabot>   (True,True)
02:43:04 <Rotsor> Ah! I thought about zero :)
02:43:47 <Rotsor> Eduard, thanks, I'll definitely visit #agda! :)
02:44:05 <ski> > map (0 `divides`) [-5 .. 5]
02:44:07 <lambdabot>   [False,False,False,False,False,True,False,False,False,False,False]
02:44:13 <ski> > map (`divides` 0) [-5 .. 5]
02:44:14 <lambdabot>   [True,True,True,True,True,True,True,True,True,True,True]
02:44:18 <ski> > map (1 `divides`) [-5 .. 5]
02:44:20 <lambdabot>   [True,True,True,True,True,True,True,True,True,True,True]
02:44:23 <ski> > map (`divides` 1) [-5 .. 5]
02:44:24 <lambdabot>   [False,False,False,False,True,False,True,False,False,False,False]
02:44:55 <ski> one (and minus one) divides everything
02:45:09 <ski> only one and minus one divides one (and minus one)
02:45:29 <ski> everything divides zero -- so zero is the "largest" element in the division ordering
02:45:50 <ski> and only zero is divided by zero
02:46:18 <Entroacceptor> oh, why is that?
02:46:29 <ski> which ?
02:46:44 <Entroacceptor> that 0 `divides` 0 = True
02:47:11 <ski> well
02:47:19 <ski>   divides x y = True  <=>  exists k. x * k = y
02:47:37 <ski> so, that gets translated to `exists k. 0 * k = 0'
02:48:01 <ski> and there certainly exists a number `k' which multiplied with zero yields zero
02:48:18 <ski> (there is no *unique* such number, but the definition didn't require that)
02:49:33 <Entroacceptor> mh, ok
02:50:58 <ski> we can define logical connectives, of sorts, using `divides'
02:51:19 <ski> well, s/define/characterize/
02:52:27 <Rotsor> You mean like check whether some set of booleans is a subset of another?
02:53:10 <ehamberg> 5
02:53:28 <ski> i mean like
02:53:32 <ski>   forall d x y.
02:53:39 <ski>            d `divides` (x /\ y)
02:53:45 <ski>     <=>    d `divides`  x
02:53:50 <ski>         /\ d `divides`       y
02:54:15 <ski> here `d',`x',`y' are numbers (integers, though natural numbers works as well)
02:54:33 <ski> and `x /\ y' is supposed to be some number computed from `x' and `y'
02:54:44 <ski> the question is, which number is it ?
02:55:07 <ski> `x /\ y' is a "conjunction" of sorts, of the numbers `x' and `y'
02:55:30 <m4dnut> hi
02:57:09 <Rotsor> And why would we want to do that? :)
02:57:23 <ski> it may perhaps help to know that  forall d. d `divides` foo <=> P d' can here be read as "`foo' is the largest `d' such that `P d' holds"
02:57:39 <ski> Rotsor : well, you may (or may not) think it's fun :)
02:57:42 <ski> lo m4dnut
02:59:05 <Rotsor> I see now :)
02:59:54 <ski> so what is e.g. `15 /\ 21', then ?
03:00:24 <Rotsor> > lcm 15 21
03:00:25 <lambdabot>   105
03:00:36 <ski> not quite :)
03:01:48 <Rotsor> oh, divides both...
03:01:53 <Rotsor> common divisor divides both
03:02:05 <ski> (counterproof : `105' divides itself, but `105' divides not even one of `15' and `21', much less both of them)
03:02:18 <Rotsor> :D
03:02:37 <Rotsor> so that should be 3 then
03:02:42 <ski> yeah, it's the greatest common divisor
03:02:43 <ski> right
03:03:53 <ski> if we write it as `(2^0 * 3^1 * 5^1 * 7^0 * ...) /\ (2^0 * 3^1 * 5^0 * 7^1 * ...)' we can see that it takes the "pointwise" `min' of the exponents in the prime factorization
03:04:42 <ski> in the normal boolean logic with truth-values `0' and `1', conjunction is `min'
03:05:04 <ski> so, in some sense, this is a kind of non-standard truth-values for logic
03:06:05 <ski> you may guess that "disjunction" becomes least common multiple
03:06:19 <ski> one can try to figure out what, if anything, implication becomes
03:06:37 <Rotsor> What about x -> y? Or simply (not x)? :)
03:07:11 <ski> well, in logic, truth should follow from anything
03:07:25 <ski> here zero is divides by anything, so zero is out truth
03:07:28 <int-e> x -> y is "x divides y".
03:07:30 <Rotsor> Indeed
03:07:31 <ski> s/out/our/
03:07:47 <ski> int-e : no, it should be a number, not a judgement
03:08:16 <ski> and one (and minus one) divides anything, so that's our truth(s)
03:08:23 <int-e> ski: no. -> is really the order relation underlying boolean algebra as a lattice.
03:08:30 <ski> er. no, falsities
03:08:41 <ski> int-e : i'm talking about a `->' connective, here
03:09:06 <ski> (and i think Rotsor was, as well)
03:09:13 <Rotsor> Indeed I was
03:09:28 <int-e> well, that doesn't exist - there are no complements
03:10:48 <ski>   forall x d m.
03:10:54 <ski>         (d /\ x) `divides` m
03:10:55 <ski>     <=> d `divides` (x --> m)
03:11:09 <ski> is the characteristic property that it ought to satisfy
03:11:42 <ski> and you're right that it doesn't exist
03:11:55 <ski> i.e. it doesn't exist for most `x's and `m's
03:12:34 <Rotsor> Can you prove false from a decision function for it?
03:12:55 <ski> i'm not sure what you mean
03:13:51 <Rotsor> Is it easy to prove that it doesn't exist?
03:16:53 <int-e> let x = 2, m = 1. Then the lhs is true exactly when d is odd. x --> m must be divisible by all odd numbers, hence equal 0. But if (x --> m) = 0 then even d divide (x --> m) as well, and the lhs and rhs are still not equivalent.
03:19:03 <int-e> (in fact (d /\ x) `divides` m always has d = 1 (mod x) as solutions, so (x --> m) must be 0 if it exists. Then the rhs is true for all d, and so must be the lhs, which only happens if x divides n)
03:20:28 <Rotsor> nice
03:20:34 <Rotsor> May I ask a functional programming-related question?
03:20:37 <Rotsor> :)
03:21:18 <Rotsor> I have read a paper on data type differentiation by Conor McBride...
03:21:28 <minh> Hi there, I need to solve (i.e. get the boolean value) of some rather simple First-Order-Logic terms. What's the best way to do this inside a haskell program?
03:21:40 <merijn> Rotsor: And you're still sane? :)
03:21:58 <Rotsor> merijn: you tell me!
03:22:16 <merijn> That name inspires fear and terror in everyone I know :p
03:22:36 <incluye> > let triangle = scanl1 (+) [1..] in take 10 triangle
03:22:37 <lambdabot>   [1,3,6,10,15,21,28,36,45,55]
03:22:42 <incluye> so that's how you do it
03:22:46 <Rotsor> The paper is quite scary, but the idea is very simple and useful!
03:23:04 <Botje> minh: sounds like you want the list monad.
03:23:22 <minh> Botje: list monad?
03:23:23 <merijn> Rotsor: Which paper was that? I don't think I read the one you're talking about now
03:23:31 <minh> Botje: How does the list monad relate to that?
03:23:35 <Rotsor> The Derivative of a Regular Type is its Type of One-Hole Contexts
03:23:59 <Botje> > let solutions = do { a <- [False, True]; b <- [False, True]; guard (a && b); return (a,b) } in solutions -- all values a and b for which a && b holds
03:24:00 <Rotsor> Wow, why is it colored? :)
03:24:01 <lambdabot>   [(True,True)]
03:24:05 <merijn> Nope, doesn't sound familiar but feel free to try asking anyway :p
03:24:06 <Botje> minh: ^ ^
03:24:48 <Rotsor> So, the paper proposes the technique to automatically derive zippers for any data structure
03:25:17 <minh> Botje: hm, funny :-) But actually, i really need a way to solve those FOL-terms. Do I really need to call out to coq or something similiar?
03:25:26 <merijn> (btw, there is also a #epigram, a lot quieter there but people tend to be more familiar with conor's papers)
03:25:35 <PatrickRobotham> minh: Use resolution?
03:25:39 <Botje> oh, first order logic .. buh
03:25:43 <PatrickRobotham> minh: Or tableaux?
03:25:45 <Botje> sorry, misread
03:26:15 <ski> Rotsor : .. however, istr that coimplication exists here
03:27:09 <minh> PatrickRobotham: the solving of those terms is just a tiny part of a bigger project. I am really not supposed to solve these by hand. ANY help is really appreciated!
03:27:46 <PatrickRobotham> minh: http://www.cs.yale.edu/homes/cc392/report.html
03:28:41 <Luqman> Hello
03:28:47 <minh> PatrickRobotham: thanks. I already looked into that. But it's pure FOL. Besides that I also need some basic arithmetic reasoning :-(
03:29:26 <Luqman> Does Mark Lentczner frequent this channe?
03:29:27 <Rotsor> So, they say that zipper is a derivative of the data type, and is built syntactically using the same rules used in calculus: const' = 0; x' = 1; (y + z)' = y' + z'; (y*z)' = y'*z + z'*y; and so on with + being the Either, * being the (,), 0 being the empty type and 1 being the ()
03:29:31 <Luqman> channel*
03:29:31 <minh> PatrickRobotham: e.g. stuff like "x>5 => x+1>6"
03:31:26 <ski> minh : hehe, so it's not pure FOL, but something like Peano Arithmetic
03:31:27 <minh> ski: I guess so
03:31:27 <minh> ski: Might calling out so prolog be a good idea????
03:31:52 <ski> maybe, i'm not sure
03:32:02 <ski> do you need constraint solving ?
03:32:31 <minh> ski: sorry, I don't understand what you mean by "constraint solving" (not my mother tongue)
03:33:06 <ski> do you want to reduce `x > y /\ y > x' to `False' e.g., without any more information given on `x' and `y'
03:33:22 <minh> ski: Anyway, I think prolog can do the kind of solving I need to do? And I found "hwwip" on hackage, which allows embedded prolog in haskell
03:33:25 <PatrickRobotham> minh: http://smtlib.org/
03:33:33 <minh> ski: that's right
03:33:34 <ski> do you want to reduce `x * x = 9' to `x = 3 \/ x = (-3)' ?
03:33:39 <minh> ski: just boolean solving
03:34:21 <ski> well, `x > y /\ y > x' is not just boolean solving
03:34:50 <ski> Rotsor : .. yes ?
03:35:19 <minh> PatrickRobotham: thank you for the link. will possibly consider that as well
03:35:26 <Rotsor> So, when differentiating (list x = 1 + x * list x) we get to (list' x = 0 + list x + list' x)
03:36:00 <Rotsor> We throw away 0 obviously, but then author somehow jumps to list' x = list x * list x
03:36:02 <minh> ski: no, I just have Implications, negation and arithmetic rules
03:36:37 <minh> ski: oops, again: I just have Implication, negation, AND, OR and arithmetic rules
03:36:52 <minh> ski: the formulas to be proofed are closed
03:37:02 <ski> Rotsor : it should be  list' x = 0 + 1 * list x + x * list' x
03:37:20 <Rotsor> shi, oh, sorry, my mistake
03:37:30 <Rotsor> ski, sorry, one more mistake
03:37:56 <ski> (minh : the "arithmetic rules" makes it not just boolean solving)
03:38:32 <Rotsor> minh, do you have quantifiers? like "for all" and "exists"?
03:38:48 <minh> ski: yeah, right. What i meant by "boolean solving" is that I'm just interested in the RESULT (whether the given implication is true)
03:38:54 <minh> Rotsor: no
03:39:05 <Rotsor> If not, isn't it just evaluation of boolean formula?
03:39:19 <ski> minh : what if it's not plain true or false ?
03:39:37 <ski> minh : i.e. if the truth value depends on the numerical value of free variables ?
03:39:53 <minh> Rotsor: yeah...kind of. As I said: Just Implications, OR, AND, negation and basic arithmetic rules
03:40:09 <Rotsor> minh said that there is no quantifiers, thus no free variables. Right?
03:40:10 <minh> ski: the formulas are CLOSED
03:40:15 <minh> Rotsor: right
03:40:24 <ski> ok, so no variables at all, then ?
03:40:34 <ski> sounds easy, to me
03:40:34 <Rotsor> So just use &&, || and friends then
03:41:05 <minh> Rotsor: and handling the implication?
03:41:30 <Rotsor> write your own x --> y = not x || y
03:41:53 <ski> @let False ==> _ = True; _ ==> True = True; _ ==> _ = False
03:41:54 <lambdabot>  Defined.
03:42:41 <ski> Rotsor : which page ?
03:43:04 <Rotsor> 7
03:43:06 <Rotsor> second column
03:43:09 <minh> Rotsor, ski: alright...let me give this a try
03:43:29 <minh> Rotsor, ski: I'll hit you guys back...thank you very much for now
03:43:40 <Rotsor> > False ==> False &&& False
03:43:41 <lambdabot>   Couldn't match expected type `a b c'
03:43:41 <lambdabot>         against inferred type `GHC.Boo...
03:43:46 <Rotsor> > False ==> False && False
03:43:47 <lambdabot>   False
03:44:01 <Rotsor> What should the value be? :)
03:44:52 <ski> > False ==> (False && False)
03:44:53 <lambdabot>   True
03:45:17 <Rotsor> The question stays
03:45:19 <Botje> not in list context.
03:45:23 <Botje> oops
03:45:29 * ski wonders what McBride means by underlining stuff
03:45:51 <Rotsor> Underlining means "rename variables there"
03:46:08 <Rotsor> But I think he has an error in at least one of the underlinings
03:46:30 <Rotsor> If I understood correctly, that is
03:46:33 <Saizan> where?
03:46:59 <Rotsor> Saizan: You mean the error?
03:48:29 <Saizan> i mean the whole thing :)
03:48:42 <Rotsor> The Derivative of a Regular Type is its Type of One-Hole Contexts
03:48:43 <edwardk> ddarius: yes, its a bilinear form, and please, feel free.
03:48:43 <lambdabot> edwardk: You have 1 new message. '/msg lambdabot @messages' to read it.
03:48:47 <edwardk> @messages
03:48:48 <lambdabot> ddarius said 4h 44m 14s ago: I think I'll write that paper on (some of) the ideas in your algebra package.
03:49:00 <Rotsor> By Conor McBride
03:49:23 <Saizan> thanks
03:49:29 <ski> <http://strictlypositive.org/calculus/><http://strictlypositive.org/diff.pdf>
03:51:25 <edwardk> ddarius: re the motion blur trick that is actually a fairly well known technique in stochastic rendering
03:52:07 <int-e> ski: see section 2.2; ___z introduces an extra variable z to the context, which you can then bind by mu, for example.
03:53:40 <ski> hm
03:55:20 <int-e> Rotsor: anyway I don't think it's immediate - you have list' x = \mu z -> list x * (x * z); the trick is that you can factor out the 'list x' from the base case: list x * (\mu z . 1 + (x * z)) = list x * list x
03:56:50 <ski> ok, `(...)_z' is basically `ignore z in ...'
03:57:20 <Rotsor> int-e: but how to you factor it out? you have to unfold infinitely many layers of recursion of list to do that in a naive way
03:57:20 <int-e> yeah and (... | z = foo) means 'let z = foo in ...'.
03:57:31 <ski> (Taylor uses that construction, to explain quantifiers)
03:57:43 <ski> int-e : yeah, that i knew :)
03:59:18 <Rotsor> It's easy to see how list x * list x is a fixed point of the said function, but how does one get to it? :)
04:00:27 <int-e> Rotsor: You could prove it by induction: for xs in  \mu z -> list x + (x * z) (sorry, messed this up above), you have either xs \in list xs = list xs * 1 or xs \in x * list' xs = (by inductive hypothesis) x * list x * list x. and indeed list x + x * list x * list x = list x * list x.
04:00:45 <int-e> I mess up too much :/
04:02:06 <int-e> Rotsor: Correcting typos: You could prove it by induction: for xs in  \mu z -> list x + (x * z) (sorry, messed this up above), you have either xs \in list x  or xs \in x * list' x = (by inductive hypothesis) x * list x * list x. and indeed list x + x * list x * list x = list x * (1 + x *  list x) = list x * list x.
04:05:11 <Rotsor> int-e: Thank you
04:05:58 <tomberek> hello
04:07:21 <tomberek> anyone familiar with ContT? Would that be useful in removing unneeded allocation in ST?
04:08:13 <Rotsor> By the way, is there a generic way to convert let f = fix (...) in fix (something using f) into something using exactly 1 fix?
04:08:32 <Rotsor> I thought that might be a key to untangling the list/list' combo
04:08:43 <ski> tomberek : define "unneeded allocation"
04:10:21 <tomberek> ski: I am trying to sequence many applications of  a -> ST s a... currently doing a version of foldM with a counter to do it, recursing on   f a >>= go (n-1), but I am allocating something and that is slowing it down.  The function should not need to allocate.
04:11:19 <mm_freak_> tomberek: ContT allows you to have arbitrary control structures…  it will not change what your code does
04:11:24 <Xaphiosis> is it possible to construct a module hierarchy such that when a user imports qualified Path.To.My.Module as M, M.InternalModule1 automatically comes into scope without importing Path.To.My.Module.InternalModule1?
04:11:25 <tomberek> ski: unrolling the application manually like this:   f a >>= f >>= f... etc.   helps by a factor equal to the number of unrollings
04:11:30 <int-e> one thing to keep in mind is that ContT isn't much of a monad transformer - it's Cont (so a monad regardless of 'm') with a restricted return type.
04:11:50 <mm_freak_> Xaphiosis: export InternalModule1 from Path.To.My.Module
04:11:59 <int-e> (where by "return type" I mean 'r' in Cont r a ... probably should use another term, any suggestions?)
04:12:10 <tomberek> int-e: mm_freak_: I only read some stuff about it, so was wondering if it would help
04:12:11 <mm_freak_> Xaphiosis: module Module (module IntermalModule1, …) …
04:12:40 <ski> mm_freak_ : hm, that's not the same thing, is it ?
04:12:56 <mm_freak_> ski: "that"?
04:13:05 <tomberek> ski: i have created a modifiable doubly linked list using STRefs, and I'd like to traverse it, this should not allocate, right?
04:13:23 <Xaphiosis> mm_freak_: does Module have to import InternalModule1 then?
04:13:46 <mm_freak_> Xaphiosis: yes
04:13:54 <ski> mm_freak_ : i thought `module Module (module IntermalModule1, ...)' would reexport the contents of `IntermalModule1', as opposed to `Module' exporting `IntermalModule1' itself
04:14:02 <Xaphiosis> mm_freak_: but then I get all the name conflicts I wanted to avoid
04:14:06 <tomberek> ski: in fact, I'm using loebM from your posts on sigpfe's blog, it's working nicely
04:14:27 <mm_freak_> Xaphiosis: ah, no, that's not possible
04:14:32 * ski doesn't recall posting anything about `loebM' on sigfpe's blog
04:14:53 <mm_freak_> you will have to import InternalModule1 explicitly or export wrappers around InternalModule1
04:15:02 <ski> tomberek : no, that shouldn't need to allocate, by itself
04:15:06 <tomberek> ski:  http://blog.sigfpe.com/2006/12/tying-knots-generically.html
04:15:28 <Xaphiosis> that is a pity, I have quite a few files that start with a bunch of qualified imports with a long common path
04:15:53 <tomberek> i use loebM to tie the knots in the structure in ST s, can't use loeb for that
04:15:53 <ski> int-e : "answer" or "result" type ?
04:16:08 <ski> int-e : possibly inserting a "final ", as well
04:16:56 <Xaphiosis> for example: import qualified Sound.ALSA.Sequencer.* where * is Client,Port,Event,Address,RealTime,Queue,Queue.Status ... just to confirm, there's no way to shorten this?
04:18:12 <mm_freak_> tomberek: note that STRefs are still boxed
04:18:26 <mm_freak_> i don't know if that helps, because i have no time to read the code right now
04:18:44 <ski> tomberek : oh, so i apparently did :)
04:18:53 <mm_freak_> but people often forget that STRefs/IORefs don't remove laziness
04:18:56 <tomberek> mm_freak_ : i suspect you are right, though I've tried UNPACK, er, not even sure if that is applicable
04:19:02 * ski tries to understand what this `loebM' does
04:19:03 <tomberek> tried strictness
04:19:44 <ski> Xaphiosis : unfortunately, Haskell lacks a real module system
04:20:12 <tomberek> ski: here's what i'm working on now, i'd appreciate any help.... the structure created is good, but traversing is slowed by allocation for some reason
04:20:15 <hpaste_> tomberek pasted “loebM with iterM” at http://hpaste.org/50618
04:20:43 <tomberek> not by much, i can get 100,000,000 steps of traversing per second, not bad, but could be better
04:20:55 <Xaphiosis> ski: that's ok, it has one of the best module systems I've seen so far, I'm just good at running up against limitations of things. thanks for the confirmation.
04:21:21 <tomberek> after I fix this, I can start modifying the structure as well
04:22:02 <Jafet> Haskell with ML modules would be like the Protoss-zerg hybrid
04:22:54 <merijn> Jafet: "Crushed by hordes of siege tanks"? Or is that not the way you imagined the analogy going?
04:24:02 <Jafet> I can't imagine siege tanks forming any sort of horde
04:24:21 <Jafet> They can't even crush things, for that matter
04:24:22 <ski> Xaphiosis : look to the MLs (SML and O'Caml) for a good module system :)
04:24:46 <mm_freak_> tomberek: you don't need pragmas
04:24:50 <mm_freak_> you need only seq
04:24:54 <merijn> Jafet: A gross oversight in SC, I admit. At least in C&C you could run over people with tanks :>
04:25:00 <mm_freak_> let y = f x in y `seq` writeSTRef …
04:25:18 <tomberek> mm_freak_ : i've tried a few, not sure were to put them exactly, none I've tried so far have helped
04:25:35 <Jafet> writeSTRef ref $! f x
04:26:57 <Xaphiosis> ski: I do use SML, but somehow never thought of its module system as better... the functors are really cool though; that language sometimes really lives up to the name Sado-Masochistic Language though
04:27:25 <tomberek> mm_freak_, Jafet:  next = readSTRef.next_     ->   next a = readSTRef $! (next_ a)    doesn't change anything in runtime or memory usage
04:27:30 <tomberek> or is that not right?
04:28:15 <int-e> I thought SML's module system makes it very easy to hide code. Open a few modules, call a function, let the programmer guess where it came from ...
04:28:18 <tomberek> next_ is just a record selector returning a type of STRef s a
04:28:53 <Jafet> WHNF-strictness is redundant in readSTRef, since it's already as strict as its caller
04:28:54 <int-e> (I guess the answer to this problem is "don't do that, then", but it wasn't my own code ...)
04:28:59 <ski> int-e : yeah, you should rather use `structure F = Frobnication', instead of `open'
04:29:11 <ski> hehe
04:29:56 <int-e> (especially since the second open might open a top-level module /or/ some nested module inside a previously opened one ... horrible :/)
04:30:16 <Xaphiosis> int-e: yes, that would count as "sadistic". we try to abbreviate structure names as ski suggested, unless there's a clear environment available (say, in haskell, the prelude is open)
04:32:30 <Xaphiosis> then again it's possible to "do it wrong" in any language... my first haskell attempt at an LZSS (de)compressor compressed 4kb in about 40 seconds; the profiler proudly showed several terabytes went through the GC
04:33:39 <hpc> haha, awesome
04:41:18 <mm_freak_> tomberek: it makes little sense to force when reading
04:41:22 <mm_freak_> you should force before writing
04:41:54 <tomberek> mm_freak_, so far i only write once, that's not a problem during traversal (but I'll keep that in mind for when I add mutations)
04:42:40 <donri> is there a/what is the difference between fmap, and bind to a composite with return? Just 9 >>= return . (*10); fmap (*10) $ Just 9
04:42:53 <donri> is it only coincidence they're the same with Maybe here?
04:43:06 <tomberek> mm_freak_: basically, unrolling manually helps the compiler optimize piping some  things, I just can't figure out a less ugly way to coerce that optimization
04:43:06 <zhasha> Am I understanding correctly that GHC compiled binaries doesn't use haskell-specific runtime libraries? All I see linked into my helloworld executable is libgmp and libffi apart from a few standard C libraries
04:43:18 <mm_freak_> tomberek: what's the reason for using ST anyway?
04:43:39 <kmc> zhasha, GHC has a runtime library but it gets statically linked by default
04:43:52 <kmc> ditto for any Haskell libraries you import
04:44:08 <mm_freak_> donri: by law the following holds:  fmap f c >>= r = c >>= r . f
04:44:14 <mm_freak_> that's a law, so it's always true
04:44:27 <tomberek> mm_freak_ : this is a doubly linked list, I can make one without ST, but it cannot be changed without rebuilding the entire thing every time... I want O(1) traversal, O(1) update, and O(1) insert (all operations at focus / 'finger')
04:45:05 <zhasha> kmc: so that means in writing software in haskell, you don't incur the wrath of a 100MB worth of runtime gunk and virtual machine crap as we know and absolutely detest from languages like Java and .NET?
04:45:15 <donri> mm_freak_: not sure that's the same as what i did though?
04:45:15 <ski> donri : stated in another way, the law is `liftM f ma  =  return . f =<< ma'
04:45:25 <ski> where `liftM' is `fmap'
04:45:26 <kmc> zhasha, no, it just means that stuff is baked into your binary
04:45:48 <kmc> compile a Haskell "hello world" and look at how big the binary that comes out of GHC is
04:45:55 <zhasha> that'd explain why helloworld is 700kB :P
04:46:00 <kmc> only?
04:46:05 <ski> @pl Just 9 >>= return . (*10)
04:46:05 <lambdabot> (10 *) `fmap` Just 9
04:46:08 <kmc> i'm surprised it's that small :)
04:46:22 <kmc> zhasha, but it's true that GHC produces native compiled code ahead-of-time, while Java and .NET implementations produce native code on the fly
04:46:24 <donri> what's @pl
04:46:29 <kmc> i actually think the latter approach is better in general
04:46:37 <kmc> and would like to see GHC get a sophisticated JIT backend
04:47:04 <ski> @help pl
04:47:04 <lambdabot> pointless <expr>. Play with pointfree code.
04:47:10 <tomberek> mm_freak_ : i couldn't figure out a way to 'fingerize' a graph structure
04:47:26 <ski> donri : it tries to "simplify" the code given to it
04:47:42 <ski> (your notion and its notion of "simplify" may differ)
04:47:47 <zhasha> kmc: it's great for cross platform binaries I guess, but the whole idea of running a pseudo-vm around my code I think is just undesirable in general
04:47:49 <donri> same thing as hpaste uses?
04:47:56 <ski> no
04:48:11 <tomberek> @pl iterate (f >=>) (return $!) !! n
04:48:12 <lambdabot> iterate (f >=>) (return $!) !! n
04:48:23 <tomberek> @pl iterate (f >=>) return !! n
04:48:23 <lambdabot> iterate (f >=>) return !! n
04:48:31 <kmc> zhasha, if your compiler is running at the same time as your program, it can do much more aggressive optimization
04:48:32 <Athas> Can someone give me the skinny on how functional dependencies and type families are related?  They seem to solve much of the same problem to me.
04:48:40 <donri> @pl ['h','e','l','l','o']
04:48:40 <lambdabot> "hello"
04:48:44 <donri> (:
04:48:52 <kmc> zhasha, not only profile-directed optimization, but optimizations that aren't even sound in general (you just bail to the un-optimizied code if your preconditions fail)
04:48:56 <ski> @pl \f g x y -> f (g x) (g y)
04:48:57 <lambdabot> join . ((flip . ((.) .)) .) . (.)
04:49:06 <tomberek> Athas: they do. i think most (all?) func deps can be written in tyep families
04:49:34 <zhasha> kmc: you still face potentially massive startup costs
04:49:48 <Athas> tomberek: are both planned to be supported indefinitely?
04:49:59 <kmc> yeah
04:50:03 <Athas> I used functional dependencies at first, but type families seem nicer and more general.
04:50:12 <tomberek> Athas: they are different ways of solving the same problem. I think the pendulum is swinging towards type families as the better solution, but it seems both are 'locked in' to GHC
04:50:17 <kmc> you can cache compiled traces persistently, or just only use JIT on long-running programs
04:50:19 <donri> could an aot/jit hybrid model make sense, does that exist?
04:50:36 <kmc> for Haskell JIT is not "necessary" for good performance, the way it is with Javascript or Lua
04:50:41 <kmc> but i think there are still some big gains to be had
04:50:46 <kmc> donri, sure
04:50:59 <donri> http://morepypy.blogspot.com/2011/08/pypy-is-faster-than-c-again-string.html
04:51:07 <donri> ^ jit benefits
04:51:18 <kmc> where's my C JIT
04:51:20 <Athas> What about non-toy examples?
04:51:22 <zhasha> kmc: a kind of FatELF approach with native code compiled in and an optional JIT backend (if installed) would be absolutely tits
04:52:08 <kmc> what i think is *really* cool is that an interpreter running inside a tracing JIT automatically becomes a tracing JIT
04:52:20 <kmc> and a lot of programs are interpreters, even if their designers don't think of them that way
04:52:29 <Athas> Also, Python's string interpolation is a language feature, is it not?  That seems easier to JIT-optimise than printf, which contains a parser written in C.
04:52:48 <kmc> they're both library functions at some level
04:52:48 <donri> python doesn't have string interpolation
04:52:58 <kmc> it's calling str.__mod__ or whatever
04:52:59 <donri> it's string formatting, probably using the same C functions
04:53:30 <donri> well duno about that last part
04:54:10 <tomberek> ski: I'm out of ideas, I allocate during the traversal. I don't know how much that is slowing things down, but I'd like to speed it up if possible. A more elegant solution that manually unrolling
04:54:31 <donri> and yes the point is that jit can optimize in places aot can't as easily
04:55:06 <donri> or at all, e.g. code acting on i/o
04:55:17 <zhasha> is it a goal of GHC to eventually have runtime optimizations?
04:55:53 <mm_freak_> tomberek: you may be interested in zippers
04:56:17 <tomberek> mm_freak_ : i am.. i could not think of a way to 'zipperize' a graph structure
04:56:42 <mm_freak_> there is a way to derive (in the literal sense) zippers from arbitrary data structures
04:56:55 <mm_freak_> search for zippers in the wikibooks
04:57:27 <roconnor> mm_freak_: are you making a joke about derivatives?
04:57:40 <tomberek> mm_freak_ : and that would be even better, avoid ST...... there is, I'm not sure how to apply it.  Yeah, i've read most of that, got lost near the deriving part of it.  It's a derivative-related operation.
04:57:41 <ski> tomberek : well, i did more or less something zipper-like for a small adventure game, with a graph for the room map
04:58:12 <roconnor> mm_freak_: anyhow, the introduction to "Clowns to the Left, Jokers to the Right" says how to make a zipper for any recursive data type.
04:58:15 <tomberek> ski: i would be very interested (still curious about my problem, from a knowledge standpoint)
04:58:38 <ski> tomberek : however, that simple approach only works for acyclic graphs -- for cyclic ones, one would have to do more work
04:58:55 <roconnor> mm_freak_: rumour has it that if you use thrists instead of lists you can get zippers for any structure.
04:59:08 <tomberek> ski: ah, yeah, i could make it work for acyclic, not cyclic... hence my use of loeb, then loebM
04:59:15 * kmc wonders if Conor McBride has seen Reservoir Dogs
04:59:15 <ski> tomberek : btw, `nextFirst a = next a >>= \f -> return (head  f)' is the same as `nextFirst a = liftM head (next a)'
04:59:37 <tomberek> ski, yes, i have commented out because there's a speed difference
05:00:32 <tomberek> ski:  hm... or at least there was last time i checked, i guess they're the same now
05:01:03 <ski> tomberek : btw, i might generalize to `data RGraph ref = SNode {  prev_  :: ref [SGraph s] ... }', that way you can set `ref' to `STRef s' or `IORef', but you can also "freeze" the data-structure by setting `ref' to `Identity' -- i'm not sure whether that would be useful for you, though
05:01:54 <mm_freak_> roconnor: making fun of?  why?
05:02:04 <ski> for fun ?
05:02:21 <tomberek> ski: very interesting,,, good idea.  It is true that I'd like a SGraph s -> Graph    function. I was thinking reifyGraph would do it, but your solution makes sense
05:03:46 <tomberek> ski: i'll have to play with that a bit more to truly understand it
05:03:52 <roconnor> mm_freak_: because you use differentiation as a step to compute zippers
05:04:00 <ski> (btw, in your `loebM', you can remove the `let r = ... in r', leaving the `...')
05:04:01 <Saizan> roconnor: does "any recursive datatype" include species?
05:04:24 <tomberek> ski:  ??, i have loebM f = mfix $ \a -> mapM ($ a)  f
05:04:30 <roconnor> Saizan: it includes types of the form mu F for any differentiable functor F.
05:04:48 <mm_freak_> roconnor: yes, hence "in the literal sense"
05:04:56 <tomberek> ski: in plain old loeb, the let ... in.. structure is needed to have a circular structure as opposed to creating an infinite one
05:05:21 <ski> tomberek : i mean in the comment :)
05:05:23 <roconnor> mm_freak_: a zipper for mu F is ([dF] * mu F) IIRC
05:05:43 <tomberek> ski: oh, yeah, that paste is polluted with some older versions of stuff as I've been trying to speed it up
05:07:28 <mm_freak_> roconnor: yes, now why would i make fun of that?
05:08:40 <roconnor> mm_freak_: well, I thought you may have already known the answer since you made the joke. :)
05:10:14 <tomberek> ski: i also tried a "square and multiply" and "doubling" of the actions. They seem to have no effect.
05:11:07 * ski isn't sure he understands the problem
05:13:14 <tomberek> ski: when i run it, there is allocation going on. Eg: with 200,000,000, i get 4609 GC's with 2Gb allocated to heap.  I don't know why it is allocating.  The "unrolled by 10" technique gets 461 GC's and 241 Mb allocated to heap, and is mucho faster.
05:13:22 <mm_freak_> roconnor: which joke?
05:14:04 <ski> (`do x <- loebM (slist 100); return $ head x' could be written as `do x:_ <- loebM (slist 100); return x' .. or you could `liftM head', if you prefer)
05:14:12 <tomberek> ski; so that is hinting to me that I am creating and destroying structure.  An intermediate structure that I'd like to 'fuse' away
05:15:08 <ski> (similarly `line <- getArgs' and then later `head line' could be replaced by `arg:_ <- getArgs' and later `arg')
05:15:25 <roconnor> <mm_freak_> there is a way to *derive* (in the literal sense) zippers from arbitrary data structures
05:16:18 <tomberek> ski: ya, good points, thanks for looking btw, this also helps me improve the style of the code for readability
05:17:14 <benmachine> ski: one of the advantages of doing the pattern matching in the do-notation is it becomes an IO error if it fails
05:17:29 <benmachine> so it's a bit more deterministic
05:17:32 <benmachine> well
05:17:35 <benmachine> deterministic is the wrong word
05:17:46 <benmachine> but it's a bit more easy to understand the ordering wrt the other IO operations
05:17:58 <benmachine> probably you already know this? :P
05:18:00 <ski> i might write
05:18:02 <ski>   slist n = (`map` [0 .. n-1]) $ \i z -> do ...
05:18:03 <ski> instead
05:18:10 <tomberek> copy
05:18:14 <mm_freak_> roconnor: that wasn't a joke actually
05:18:23 <ski> (you could use `flip', instead of doing a right section, if you prefer)
05:19:05 <ski> benmachine : yeah, hopefully the error message is better
05:19:09 <benmachine> that too
05:19:38 <mm_freak_> benmachine: ~(arg:_) <- getArgs
05:19:43 <mm_freak_> ;)
05:19:47 <mm_freak_> now that was a joke
05:24:12 * ski wants to fit a comonad into `loebM'
05:24:21 <tomberek> ski: agreed
05:24:59 <kmc> i'm writing a program now that has this line:  args@(~(elf_file:_)) <- getArgs
05:25:11 <ski> tomberek : hm, i'm not convinced your `slist' is doing the right thing
05:25:12 <kmc> it's kind of the worst pattern i've ever written
05:25:23 <ski> more specifically, i think it's probably doing the wrong thing
05:25:23 <kmc> no, wait, that was probably something with nested view patterns
05:25:26 <saml> is llvm binding for nix only? not on windows?
05:25:29 <frerich> ski: "`f` x" is called a right section, and "x `f`" would be a left section (and a right section could also be done using "flip f x")? I always wondered what this way of infix usage of some function to avoid using flip was called.
05:26:10 <tomberek> ski: uh oh... i though i had that part nice..  I know that I have a true knot as opposed to an infinite structure
05:26:30 <ski> frerich : hm, now that i think of it, `(+ foo)' would perhaps more usefully be called a *left* section
05:28:23 <frerich> ski: What does "section" refer to - the given value to which a function is applied, or the omitted value wchi parametrizes the resulting function?
05:28:28 <kmc> i would not expect any agreement on which one is left and which one right :)
05:28:38 <tomberek> ski: and it should only run once, trace seems to confirm that
05:28:39 <kmc> "section" is the syntactic construct (+ e) or (e +)
05:28:44 <ski> frerich : now that i think of it, i'm not sure which one it traditionally refers to
05:28:50 <sanjoyd> What is left for you is right for the compiler.
05:29:00 <ski> kmc : yes, but which of them is a left section, and which is a right section ? :)
05:29:09 <kmc> ah, because the compiler is inside the computer, looking back at me
05:29:24 <tomberek> kmc: the compiler is IN the compuer?
05:29:37 <sanjoyd> It is in your head.  There is no compiler.
05:29:56 * sanjoyd likes making pointless zen'ish statements.
05:30:07 <tomberek> it's so simple!
05:30:07 <Jafet> Don't stare too long into the compiler
05:30:07 <Axman6> kmc: compiler left and right is the same as stage left and right
05:30:12 <roastbird> why is it called a section? isn't a section an inverse?
05:30:25 <ski> i'm not sure
05:30:27 <kmc> "And how in the return of the gaze / She can return you the face / That you are staring from"
05:31:22 <ski> (a section in CT is a "pre-inverse" (commonly called "right-inverse"))
05:32:35 <tomberek> ski: so i came to suspect the higher order function, iter (or iterM probably is a better name) needs to be improved, but I can't figure out how.    Then again, it could be something else, strictness, unpacking.. ?
05:32:54 <fryguybob> saml: I kicked the tires on llvm on windows and it seemed to work fine.
05:32:58 <tomberek> hi edwardk
05:33:09 <erus`> is there a packageable ghci i could use to add haskell scripting to another application?
05:33:11 <edwardk> heya tom, long time no see
05:33:19 <Jafet> @hackage hint
05:33:19 <lambdabot> http://hackage.haskell.org/package/hint
05:33:28 <tomberek> yeah, been busy,, but i'm back into it, causing problems
05:33:28 <kmc> erus`, look at 'hint', 'mueval', 'plugins', and the GHC API
05:33:30 <saml> fryguybob, nice. i built llvm using cmake and mingw.
05:33:35 <saml> did you blog ?
05:33:43 <kmc> erus`, also look at 'dyre' for xmonad-style configuration
05:33:45 <edwardk> tomberek: did you see i wound up releasing a "graphs" library at some point?
05:33:51 <erus`> but im using C++ :D
05:33:55 <tomberek> edwardk: I'm still working on it   :)
05:33:55 <ski> wrt distributing operations, if `forall x0 x1 y. (x0 + x1) * y = (x0 * y) + (x1 * y)', we say that `(* y)' distributes over `(+)', or that `*' *left*-distributes over `(+)'
05:33:59 <erus`> i could just wrap hint
05:34:12 <Jafet> Why use C++?
05:34:43 <fryguybob> saml: No, and I used some prebuilt binaries.  dons posted some particular speed up he was getting and so I tried to see if I could get the same and I did.  I spent at most a half hour on it.
05:34:46 <erus`> because it takes me days to write anything in haskell
05:34:48 <tomberek> edwardk: in fact, i'm trying something right now, having a problem.... i have a mutable doubly linked graph structure in ST. It seems to work fine, but I'm allocating during traversal. I'm trying to figure out if I can speed it up.
05:34:54 * frerich puts on his asbestos underwear
05:35:01 <erus`> and i wanna prototype this game quickly
05:35:18 <ski> the idea being that we sometimes want to generalize to express `forall x y0 y1 z. f (x,(y0 + y1),z) = f (x,y0,z) + f (x,y1,z)' as `f' distributing over `+' in its middle argument
05:35:19 <edwardk> are you changing the shape of the graph?
05:35:23 <saml> fryguybob, okay i'll try
05:35:31 <hpaste_> tomberek pasted “loebM with iterM” at http://hpaste.org/50619
05:35:35 <tomberek> edwardk: ski has been helping me out, cleaning up a few things
05:35:37 <saml> if ghc backend is llvm, why isn't llvm binding part of ghc distribution?
05:36:01 <sanjoyd> I thought GHC compiled to C--.
05:36:04 <edwardk> very pointer heavy
05:36:04 <kmc> because GHC itself does not use the LLVM bindings
05:36:11 <kmc> though there's a project to fix that
05:36:23 <edwardk> sam1: llvm is just one backend of many
05:36:27 <kmc> sanjoyd, Cmm is the last intermediate language in GHC, before assembly, LLVM, or bastard-C
05:36:32 <tomberek> edwardk: yes, i couldn't figure out a way to 'zipperize' a graph
05:36:46 <kmc> (it's not quite the same as the documented language named C--)
05:37:00 <sanjoyd> tomberek: edwardk I too have been stuck on modelling a CFG on Haskell.
05:37:08 <kmc> GHC:  Haskell -> Core -> Cmm -> LLVM -> machine code
05:37:09 <tomberek> edwardk:  i can create a doubly linked graph, but it wouldn't be mutable or updatable without re-creating the whole thing
05:37:18 <sanjoyd> My current approach involves pushing basic blocks, popping them and committing them.
05:37:23 <sanjoyd> I'm looking for something more elegant.
05:37:30 <tomberek> sanjoyd: CFG?
05:37:36 <sanjoyd> tomberek: control flow graph.
05:37:40 <tomberek> ah
05:37:41 <sanjoyd> kmc: oh, okay.
05:37:41 <edwardk> tomberek: how dense is the graph?
05:37:45 <Jafet> Sure it can be mutable, as long as you don't use direct references
05:37:53 <edwardk> tomberek: e.g. node count and edge count?
05:37:57 <sanjoyd> kmc: I thought GHC just call gcc.
05:38:10 <edwardk> sanjoyd: tried using applicatives?
05:38:20 <edwardk> sanjoyd: ah control flow
05:38:20 <sanjoyd> edwardk: no, will look into it.
05:38:27 <edwardk> misparsed as context free grammar
05:38:41 <sanjoyd> How ironic. :D
05:38:41 <edwardk> sanjoyd: have you seen hoopl?
05:38:48 <Jafet> These days, ghc basically calls gcc to link
05:38:48 <sanjoyd> edwardk: no.  Again, will do.
05:38:55 <tomberek> edwardk: not really specified yet, i am thinking long term about evolving neural networks, but i've been sidetracked in thinking about graphs
05:39:45 <edwardk> tomberek: i still strongly believe in storing shape separately from data. if you had the graph shape as some big messy doubly linked thing, and just stuffed the values in an array with an int index into that array from the shape you could traverse very very cheaply
05:40:20 <ski> tomberek : hm, ok, `slist' is probably ok
05:40:46 <tomberek> edwardk: yes, i'd like to do that shape/data split, it makes sense (some of all this is me also trying to learn)....  but growing the array?
05:40:52 <ski> edwardk : reinventing GC ?
05:40:58 <edwardk> sanjoyd: yeah i definitely think the hoopl approach is probably the most straightforward
05:41:07 <edwardk> ski: meh, he already has to pay a lot to shuffle the graph
05:41:10 <kmc> sanjoyd, gcc doesn't know about Cmm or C--
05:41:13 <edwardk> ski: and it makes a huge difference in allocation
05:41:28 <kmc> sanjoyd, these days the C backend for GHC is deprecated
05:41:36 <edwardk> ski: he isn't pointing to the graph nodes, just putting the values off to one side, so he can fmap over his graph in O(n) instead of paying for all the edges
05:41:37 <kmc> in 7.2 it's only available in the super slow compatibility mode
05:41:41 <kmc> and not built by default
05:41:43 <sanjoyd> kmc: oh.
05:41:57 <sanjoyd> So now GHC directly emits LLVM IR / assmebly?
05:41:57 <kmc> but as Jafet said, it'll still call gcc to link
05:42:00 <kmc> yes
05:42:02 <sanjoyd> Does it still use the STG model?
05:42:05 <kmc> or machine code directly
05:42:08 <kmc> yes
05:42:12 <edwardk> sanjoyd: yes
05:42:14 <kmc> though it's evolved a lot since the original STG papers
05:42:25 <kmc> hmm, i guess STG is another language between Core and Cmm?
05:42:27 <tomberek> edwardk: traverse quickly i can do with a knot tying.  i'd like to update not only the values, but the structure as well. (i do agree though that a shape/data split is elegant)
05:42:28 * kmc doesn't recall exactly
05:42:29 <hpaste_> “hope this is helpful” annotated “What's wrong with this?” with “What's wrong with this? (annotation)” at http://hpaste.org/50600#a50620
05:42:29 <sanjoyd> I've only read the first one my Simon Peyton Jones.
05:42:32 <sanjoyd> s/
05:42:35 <edwardk> the llvm backend wins a bit on some tight vector inner loops
05:42:37 <sanjoyd> s/my/by/
05:42:50 <edwardk> tomberek: ah, then you're probably stuck with this fgl-like monstrosity
05:43:10 <edwardk> kmc: yes
05:43:13 <kmc> sanjoyd, getting good performance out of the "C" backend required GCC specific hacks, plus textual assembly postprocessing with a Perl script named the "Evil Mangler"
05:43:17 <kmc> that's why it's deprecated now :)
05:43:30 <sanjoyd> Oh.
05:43:32 <tomberek> edwardk:  exactly, so I thought to make deal with the devil and try STRef's
05:43:33 <kmc> in 7.2 the Evil Mangler is gone and you can only compile via super slow but semi-standard C
05:43:40 <ski> @quote evil.mangler
05:43:41 <lambdabot> Pseudonym says: All hail the Evil Mangler!
05:43:44 <kmc> "unregisterized"
05:43:54 <ski> @quote evil.mangler
05:43:54 <lambdabot> jmcarthur says: <shachaf> What have [SPJ and JaffaCake] ever done for Haskell? <jmcarthur> evil mangler?
05:43:55 <edwardk> kmc: though the benefits of the evil mangler have faded over time, its now down in sub 5% territory
05:44:07 <kmc> edwardk, really??
05:44:07 <tomberek> edwardk: though in the end, all this is, is a zipper.. Can one zipperize a graph? i can't think of a way
05:44:11 <edwardk> kmc: dynamic pointer tagging kind of ate its lunch
05:44:36 <kmc> with -fvia-C you need the Evil Mangler or else you're stuck with the mini-interpreter, right?
05:44:45 <ski> tomberek : i think it should be possible, but i haven't worked it out
05:44:48 <kmc> while (f = f()) ;
05:44:51 <kmc> for tail calls
05:44:52 <rostayob> wait, as far as I knew the evil mangler is no more
05:44:53 <edwardk> well the mangler is responsible mostly for tables_next_to_code
05:45:04 <ski> kmc : trampoline :)
05:45:07 <edwardk> or at least what used to be the mangler i lost track
05:45:20 <kmc> rostayob, scroll up
05:45:35 <rostayob> ah ok
05:45:44 <kmc> i thought it was responsible for a) tables next to code, b) snipping out C function prologues / epilogues, c) tail calls
05:45:45 <sanjoyd> tomberek: I vaguely remember reading some relation between algebraic differentiation and constructing zippers.
05:45:51 <kmc> maybe the tail calls are just straight-up GCC inline asm
05:46:03 <edwardk> yeah those too
05:46:05 <tomberek> ski: i've been thinking about it, it's a hard one, it becomes not a zipper, but a tangle of chains. Then you insert a stick and lift it up by a node, you'll still have links connecting one side to the other, making me think you need the double links
05:46:26 <tomberek> sanjoyd: true, applying that proved to be beyond me, perhaps i shall revisit
05:46:30 <edwardk> the tables_next_to_code was the piece that slowly lost importance
05:46:35 <kmc> *nod*
05:46:38 <ski> tomberek : yeah, the problem is the cycles, especially cycles that join each other
05:46:44 <tomberek> ski, aye
05:46:48 <sanjoyd> tomberek: same here.  I know there is some relation, but I could not make much sense out of it in practice.
05:46:49 <edwardk> nowadays i'd be willing to write an STG implementation that didn't bother
05:47:05 <kmc> just write a tracing JIT ;)
05:47:26 <edwardk> thats the (background) plan =)
05:47:40 <edwardk> i still love how well the STG traces
05:47:44 <tomberek> sanjoyd, or it only works for a tree-like, infinite structure version, as opposed to one where the knots are tied.
05:48:11 <sanjoyd> Maybe.
05:48:13 <kmc> so every use of (^) or (^^) with a literal right-hand argument is going to invoke defaulting?
05:48:28 <edwardk> kmc: sounds right
05:48:31 <kmc> :(
05:48:43 <edwardk> hey did put it in the language for a reason
05:48:45 <edwardk> er they
05:48:53 <kmc> it still makes me sad though
05:49:06 <kmc> and making 'default' a reserved word is still not okay ;)
05:50:46 <tomberek> ski: (still wondering about the zipper'd graph) would any Iteratees, enumerable, etc be applicable to this? I was wondering about ContT for a bit.
05:51:16 <ski> kmc : would you prefer `Integer' (or `Natural' in the `(^)' case) ?
05:51:30 <kmc> i don't know
05:51:39 <kmc> maybe i'd prefer a lightweight syntax for non-overloaded literals
05:52:24 <ski> maybe `123#I' and similar ..
05:53:00 <kmc> i'd even go with C-style "123i"
05:53:17 <ski> tomberek : not knowing much about `Iteratee's or `Enumerable's, i can't comment on those
05:53:22 <Jafet> C++ has some kind of literal overloading
05:53:28 <edwardk> tomberek: the main messy part is your need to edit the shape of the graph
05:53:30 <ski> tomberek : i'm still not sure why you were thinking of invoking `ContT'
05:53:52 <edwardk> tomberek: otherwise your current representation looks very much like an edge zipper
05:53:56 <tomberek> ski: i read something about it improving the speed of other monads, could be wrong
05:54:09 <edwardk> tomberek: not applicable here
05:54:22 <edwardk> tomberek: the benefit is right association, and its more tied to codensity than to contT
05:54:23 <ski> well, it auto-right-associates `(>=>)'
05:55:14 <edwardk> ContT is easily misapplied, but your monad here (if such is even involved) isn't free, and mostly stays the same size, so i wouldn't expect to see any benefit from right association
05:55:29 <tomberek> edwardk: i'm unfamiliar with 'edge zipper',  but a zipper-like interface IS my goal.  because a lot of graph algorithms are easy to express in that format. It's at least something I want to try.
05:56:20 * ski would like some way of doing one-pass least-fixed-point computation on graphs
05:56:45 <tomberek> ski: translation?  hehe
05:56:52 <ski> hm ?
05:57:01 <ski> oh
05:57:17 <ski> like computing live variables in a control-flow graph
05:57:51 <tomberek> not sure what that means, is that running a single transformation from the point of view of every node? sounds like a comonad, i actually have that implemented somewhere else.  me and edwardk have talked about that a while back.
05:58:10 <ski> it's like a fold on the graph
05:58:28 <tomberek> ski, yeah, neural network-style?
05:58:52 <ski> i wasn't thinking about neural networks in particular
05:59:10 <ski> (it might be applicable for some things there, i dunno)
05:59:18 <tomberek> but one application would be the evaluation of a neural network?
05:59:33 <ski> maybe ?
05:59:53 * ski doesn't recall very much on how neural networks work, and what one does with them
06:01:34 <tomberek> ski: it sounds like we're talking about same thing, different vocab.  It seemed like a comonadic thing to me.
06:01:41 <ski> but the point is to avoid ugly imperative updating of a set by adding more elements to it
06:02:32 <ski> i want to define the set partially in terms of itself, and after all the constraints from the graph have been sorted out, what's not definitely in the set is definitely *not* in the set
06:02:38 <ski> hence least-fixed point
06:02:59 <tomberek> ah, interesting
06:03:46 <ski> (hm, i suppose it ought to be "least fixed-point", actually)
06:04:49 <confound> unfixed-pointest
06:05:03 * ski is confounded
06:05:38 <ski> tomberek : yeah, i wouldn't be suprised if comonads popped up
06:05:57 <ski> looking at your (well, mine i suppose)
06:06:06 <ski>   loebM :: MonadFix m => [[a] -> m a] -> m [a]
06:06:35 <ski> it's irritating to have to compute `z!!((i-1) `mod` n)' and `z!!((i+1) `mod` n)'
06:07:21 <ski> so the `[a]' "callback input" might in this case more usefully be `([a],a,[a])'
06:07:22 <Rotsor> ski, the fixed point is "least" not in the sense of size, but rather in the sense of bottomness. It's as close to bottom as possible.
06:07:57 <tomberek> ski: ya, but it's only once, i don't think that is the source of my difficulties.  Though i've learned a lot simply trying to use loebM, i though you guys dismissed it too quickly on sigpfe's blog.
06:08:24 <tomberek> ski: hm......
06:08:46 <edwardk> tomberek: yes, we talked about this as the way to evaluate a neural network timestep as a single 'extend' of the neural network graph, but it was probably a year ago
06:09:02 <ski> Rotsor : yeah, i was here talking about least in the Hoare preorder on subsets
06:09:04 <Rotsor> ski, sorry, I think I misunderstood, I thought you meant Haskell's fix
06:09:58 <tomberek> edwardk: yep, i'm searching my gmail for that.... i got busy this year, stopped haskelling, still curious about the topic, still learning
06:11:30 <ski> anyway, `([a],a,[a])' is `(d [a] / d a) * a'
06:11:51 <ski> and `((d [a] / d a) *)' is a comonad, i think
06:12:37 <stulli> If i delete my .cabal folder do i have a 'clean state'?
06:12:45 <edwardk>  i have a zipper comonad somewhere
06:12:58 <tomberek> ski: erg... let me parse.....  is this in the sense that any zipper is a comonad,, er, yeah, what edward said
06:13:11 <ski> tomberek : hehe, i had forgotten i had even invented it :)
06:13:18 <edwardk> ah http://hackage.haskell.org/packages/archive/comonad-extras/2.0/doc/html/src/Control-Comonad-Store-Zipper.html
06:13:40 <edwardk> it works a bit differently than zippers you are used to
06:14:08 <edwardk> i have another lens based zipper lying around somewhere as well
06:14:28 <dcoutts> stulli: no, the packages are registered in ~/.ghc
06:16:03 <stulli> dcoutts: Ok, thanks. So i can delete .ghc aswell and it would do no harm?
06:16:08 <ski> tomberek : anyway, what i was thinking about was that it would in many cases make more sense if `loeb'/`loebM' used "relative addressing", i.e. it got the full result centered around the result it is to compute
06:16:23 <tomberek> edwardk: your packages are always very interesting and have very applicable structures, I just end up getting lost. Though I have the suspicion that applying your category-heavy framework should allow for interesting optimizations.
06:16:28 <dcoutts> stulli: that'll make ghc forget about all per-user registered packages
06:16:49 <stulli> dcoutts: Excellent, that's exactly what i want
06:16:59 <ski> tomberek : if we're thinking about well-orderings, it would only get the structure at the strictly smaller locations, though
06:17:00 <tomberek> ski: i saw something like that in a post recently,   it was loeb, but referenced things in relation to itself
06:17:25 <tomberek> ski, yes, the example I saw could only look in one direction in a list
06:17:32 <ski> (and that interpretation might be closer to the original one)
06:19:05 <ski> if we consider `[] ([] a -> a) -> [] a' in modal logic with kripke semantics, where the worlds are the natural numbers, and the accessibility relation is `(<)', then it becomes strong/complete induction on natural numbers
06:19:57 <tomberek> ski, the relative referencing:  http://banbh.blogspot.com/2007/08/relative-spreadsheets.html
06:20:46 <tomberek> ski: btw, your last comment is completely un-parse-able to me.
06:21:45 <ski> ok, so they do `U (U x -> x) -> U x'
06:22:00 <tomberek> um,,, yes
06:22:02 <ski> i would possibly still do `[U x -> x] -> [U x]'
06:22:17 <ski> er, rather `[U x -> x] -> [x]'
06:22:48 <int-e> ski: what'd you do with the U?
06:23:32 <ski> each function in the list would get a "zipper" centered around the result it is to generate
06:25:01 <ski> you might not have a specific function/element that you'd care to single out
06:25:03 <edwardk> ski: another view of this is just as a form of memoized store comonad
06:25:19 <edwardk> using a representable-trie or other shape as the graph itself
06:25:34 <ski> but each function should still get the list of results, with its own result singled out, so it can easily navigate from that using `prev',`next', or whatnot
06:26:15 <ski> memoized how ?
06:26:17 * tomberek is letting ski and edwardk figure it all out. Waiting for wisdom to percolate out.....
06:27:08 <edwardk> well i'm heading off to interview someone in a few minutes so the wisdom will all be pouring forth from ski
06:27:12 * ski figures that'd have to be edwardk being responsible for the wisdom in that case :)
06:27:21 <tomberek> uh oh
06:27:22 <Eduard_Munteanu> Hah.
06:27:22 <ski> hahaha
06:28:01 <tomberek> perhaps i'll play with uloeb a bit, see what comes of it
06:28:09 <edwardk> re memoized, all i was indicating was that if you have a representable functor f, with representation s, then you can implement the store comonad (s -> a, s) as (f a, s)
06:28:28 <edwardk> so 'f' is the shape, of the graph, and 's' is the current focus
06:28:41 <edwardk> then you can do relative/global addressing by changing s
06:29:07 <edwardk> and the vocabulary for working with the store comonad, pos, peek, seek, etc. all applies
06:29:25 <ski> having to say `U _ _ rr = uloeb fibSpreadsheet' is ugly, in that code
06:29:51 <ski> and the `repeat 0' in `fibSpreadsheet = U (repeat 0) 1 (repeat (at (-1) + at (-2)))' is even wrong :)
06:30:10 <mysticc>  Can any one refer some references on arrows
06:30:12 <tomberek> i'll be saving those comments for future translation into English,, too bad Google doesn't have a edwardk -> Standard English in Translate
06:31:01 <ski> tomberek : `loeb' comes from provability logic, which is a specific modal logic
06:31:46 <tomberek> sure, i saw how sigpfe went from the conception of the type from logic, to the actual function
06:32:20 <ski> tomberek : if you interpret the formula in kripke semantics, with natural numbers as worlds, and accessability being `<', then you get "complete induction"
06:32:48 <tomberek> omg
06:33:00 <ski> you can interpret it on any well-founded set, and then you get transfinite / well-founded induction on that set
06:33:24 <ski> a predicate on natural numbers is the same as an infinite stream
06:33:32 <ski> so, in that setting, we get
06:33:46 <ski>   loeb :: Stream ([a] -> a) -> Stream a
06:34:02 <ski> where the `[a]' represents the finite number of elements that comes before the current element
06:34:21 <ski> (preferably in backwards order, for efficiency of local access/navigation)
06:34:27 <tomberek> ok, i can follow that
06:34:55 <tomberek> many kinds of filters can be implemented with that
06:34:56 <ski> if you replace `[a]' by `([a],a,Stream a)', then you have a zipper on those streams
06:35:50 <companion_cube> is everyone on this chan a professional logician ?
06:35:51 <ski> you can also replace it by `Stream a', to get an anti-causal feedback
06:36:04 <ski> companion_cube : not yet
06:36:11 <tomberek> companion_cube: just grab onto something and hold on
06:36:44 <ski> companion_cube : you probably have to apply to some logic courses first
06:36:58 <ski> (or read lots of papers/books on it)
06:37:07 <companion_cube> i had logic courses, but never heard of kripke semantics :)
06:37:13 <companion_cube> i had to search it on wikipedia
06:37:26 <ski> kripke semantics is used (mainly) for modal logic
06:37:27 <tomberek> i'm following the idea of Stream, and i see how loeb makes zippers for acyclic structures
06:37:47 <ski> can also be used for intuitionistic logic, via Gdel's (?) modal interpretation of intuitionistic logic
06:39:40 <ski> tomberek : well, as soon as `Cxt a' in `T (Cxt a -> a) -> T a' includes the `a' (directly or indirectly) the function is to generate, you get inconsistency, i.e. potential for cyclic structures
06:40:36 <tomberek> copy
06:41:04 <companion_cube> looks like CPS
06:41:20 <ski> as long as your locations are well-ordered, there can be no cycles
06:42:13 <ski> of course, one of the points here is to replace a collection `Loc -> a' with a static set of locations with a general `T a', where some locations might or might not exist, in a particular collection
06:42:31 <ski> i'm not sure how to think of this in terms of kripke semantics, then
06:42:49 <ski> (if `Loc' is `Natural', then `Loc -> a' is of course `Stream a')
06:43:32 <ski> companion_cube : i'm not sure where you see the CPS ..
06:43:34 <tomberek> sure, loeb could diverge or fail when the references are incorrect or ill-formed
06:44:00 <companion_cube> ski: (Ctx a -> a) -> a  is a CPS-like Ctx a, right ?
06:44:19 <ski> yeah .. in terms of well-founded induction, we're wanting a least fixed-point recursive type
06:44:29 <ski> but if we want graphs, then we don't want that
06:44:36 <tomberek> ski: would probably want to build a proper functional graph to make sure it is well formed, then send it through loeb to tie the knots
06:45:05 <ski> companion_cube : hm, there might perhaps be a connection, though note the intervening `T' above
06:46:32 <ski> (the original `loeb' had to do with creating a cycle, indirected through a quotation)
06:46:35 <companion_cube> indeed
06:47:12 * ski suspects edwardk could probably tell what the connection is
06:47:27 <ski> (or maybe roconnor)
06:48:16 <ski> creating an immutable cyclic structure is no problem in Haskell
06:48:35 <ski> the problem is when we want to `map' or `fold' over it, e.g.
06:49:04 <ski> or when we want to do a local modification, and have that modification reflected on all "equal" positions, which one can reach by traversing cycles
06:50:16 <tomberek> yep, and because a node can be reached from multiple nodes, those pointers need to update, and the change percolates through the entire structure
06:50:35 <ski> i think either using mutation (like `STRef s') or using a zipper of some kind is probably the way(s) to do the latter
06:50:58 <companion_cube> in the case of graphs, a different representation (like adjacency lists) can help solving circularity, am i right?
06:51:12 <tomberek> ski, yeah, but I couldn't figure out the zipper. So i thought I'd learn ST and try the STRef route
06:51:15 <tomberek> companion_cube: true
06:51:35 <ski> one can imagine cutting up a cyclic graph into an acyclic one, with each cut referencing the "other side" through the (unique) path in the remaining uncut graph
06:51:46 <companion_cube> seems to me that this is another example of "every problem can be solved by adding a level of indirection"
06:51:50 <tomberek> companion_cube: but the original intent was to have zipper-like behavior, O(1) traverse and update
06:52:06 <companion_cube> oops :)
06:52:29 <ski> but then as one traverses these cuts, one would need to traverse around, and maybe shorten this path, and i think there's some non-canonical choices to be made
06:53:01 <ski> so, then one might hope for O(1) amortized traverse
06:53:02 <tomberek> ski: if we end up having to refactor the whole graph in acyclic sections every time an update is made, we don't gain anything
06:53:30 <tomberek> ah, an amortized solution.....  i'd have to think on that
06:53:31 <ski> well, we might gain convenience
06:53:43 * hackagebot RNAwolf 0.3.0.0 - RNA folding with non-canonical basepairs and base-triplets.  http://hackage.haskell.org/package/RNAwolf-0.3.0.0 (ChristianHoener)
06:53:59 <ski> but i'm not sure how it would work to add new connections to the graph
06:54:42 <ski> i.e. visit one node, somehow remember a reference to it, traverse to another node, add a direct link from that node to the earlier node which you have a reference to
06:55:53 <tomberek> in adding a direct link you either propagate the update everywhere, or do it destructively.
06:55:54 <ski> (btw, with bi-directional edges, one'd like a forward-then-backward traverse to not incur two restructure operations directly after each other)
06:56:32 <ski> (and a bi-directional edge really ought to be two uni-directional edges, whose compositions are the identity)
06:56:33 <tomberek> ski: that sounds like a rule?   next . prev = id ?
06:57:21 <ski> well, that wouldn't express the "no-double-restructure", would it ?
06:58:05 <ski> i mean, `reverse . reverse = id', for finite lists
06:58:16 <tomberek> ah, i see
06:58:35 <tibbe> anyone familiar with Debian HP packaging?
06:58:43 * hackagebot RNAwolf 0.3.0.1 - RNA folding with non-canonical basepairs and base-triplets.  http://hackage.haskell.org/package/RNAwolf-0.3.0.1 (ChristianHoener)
06:59:55 <ski> one can imagine a restructure operation, along a (cut-open) cycle, to split the cycle in two parts, putting one part before the cut, the other after it
07:00:49 <ski> maybe one'd want a `dejaVu' operation on nodes ?
07:01:04 <ski> or would it be enough with that built-into `map' and `fold' ?
07:01:24 <tomberek> unsure
07:05:48 <tomberek> ski: in the end, i figure a good compromise is to use STRef's, be able to define an algorithm, use runST, then freeze it to make a pure graph.  So using imperative on the inside, but still function on the outside.
07:08:13 <tomberek> ski: i just ran into this optimization question, though I suspect 100,000,000 steps of traversal / second isn't bad, or should stay with it and try to get faster?
07:09:13 <ski> tomberek : well, if you only need to modify the graph in the initialization phase, sure
07:09:45 <Cale> tomberek: Using actual cycles to make a graph datastructure is not usually as useful as representing a graph with something like Map Vertex (Set Vertex)
07:09:51 <ski> i'm not sure what your efficiency problem is exactly
07:09:57 <tomberek> well, with this solution, i should still be able to modify it
07:10:07 <ski> *nod*
07:10:17 <tomberek> ski: right now it's just the ST composition, not graph related
07:11:03 <Cale> and using some immutable map datastructure with good operations on it somewhat alleviates the need/desire to use ST and the like
07:12:00 <tomberek> Cale: Yeah, that is actually index-able, etc. I'm just trying out stuff, learning.. ran into that optimization with ST.    The idea in my head was to make a 'zipper graph' with this technique. O(1) traversal, local update, local insert
07:12:59 <Cale> A troublesome thing is that infinite things are indistinguishable from cyclic things if you don't explicitly represent the adjacency information somehow, and it's impossible to do almost any transformation on a cyclic thing without inadvertently turning it into an infinite one.
07:14:18 <ski> tomberek : hm, what do you mean by "ST composition" ?
07:14:23 <tomberek> Cale: that's exactly the conundrum I found myself in.  Do you think it is possible to make a zipper of a cyclic graph?
07:14:34 <tomberek> ski: the unrolling of iter or iterM
07:14:48 <Cale> tomberek: It depends on what you mean by 'cyclic graph'
07:15:16 <ski> a cyclic graph is not the same as the infinite tree unrolling of it ;)
07:15:17 <tomberek> ski:    where f a >>= go (n-1)    is allocating half as much as    f a >>= f >>= go (n-2)
07:15:47 <Cale> tomberek: wait, wasn't it the other way around?
07:15:59 <tomberek> Cale,ski: ah, but I came across the knot tying where it turns an infinite tree urolling into true cyclic
07:16:04 <tomberek> Cale, yes... other way around
07:16:26 <Cale> Yeah, that's just inlining, there's not much you can do about that.
07:16:53 <Cale> The latter code is in a better form for inlining and simplification by GHC.
07:16:54 <tomberek> i just though loeb was awesome, and so I tried applying it, it might not really be the best option, but it's cool nonetheless
07:17:11 <ski> tomberek : yeah, that allocation thing sounds strange -- i can't say i understand the issue atm
07:17:12 <Cale> The knot tying thing doesn't turn an infinite graph into a cyclic one
07:17:35 <Cale> It turns a finite piece of information encoding how things should be tied together into a cyclic structure.
07:17:56 <tomberek> Cale, yesh, i have this branch, f a >>= f >>= f >>= f >>= f >>= f >>= f >>= f >>= f >>= f >>= go (n-10)   it seems to work well, but ugly as sin
07:17:57 <chrisdone> i tried using loeb to solve sudoku grids but it doesn't support the backtracking necessary
07:18:12 <tomberek> Cale: correct, encoding -> cyclic, my bad
07:18:27 <ski> well, if it indirects through `STRef s', then it is still "a finite piece of information encoding how things should be tied together", in a way
07:18:42 <Cale> Tying knots is usually not as useful as you'd think -- unless you'd be just as happy with the infinite structure.
07:18:44 * hackagebot language-c 0.4.2 - Analysis and generation of C code  http://hackage.haskell.org/package/language-c-0.4.2 (BenediktHuber)
07:18:55 <ski> (just as it would be if it indirected through indices into some external `Map')
07:19:40 <tomberek> Cale: you might be right, but i'd be allocating (more?) during a traversal of the infinite version?
07:21:45 <rtharper> @src unfoldr
07:21:46 <lambdabot> unfoldr f b  = case f b of
07:21:46 <lambdabot>    Just (a,new_b) -> a : unfoldr f new_b
07:21:46 <lambdabot>    Nothing        -> []
07:22:15 <tomberek> Cale: could I store alongside this structure a Map? something like (Map Index (SGraph s) , SGraph s)  ?  allows fast operations at the focus/finger, but also indexing etc?
07:22:48 <Cale> tomberek: Well, fast reads maybe
07:23:07 <Cale> tomberek: If you want to modify anything, you have to reconstruct your entire cyclic thing
07:23:09 <tomberek> yeah, any modification would have to go through Map anyway
07:23:12 <Cale> Because that's just how it is.
07:23:15 <tomberek> ya
07:23:18 <tomberek> grrrr
07:23:33 <Cale> Well, it's immutable.
07:24:08 <Cale> and if you can reach point A from point B, you can't change point A without also changing point B
07:24:25 <Cale> (because point B isn't the same anymore if point A is different)
07:25:06 <Cale> So it's typically easier and faster just to store everything in a finite map structure of some type.
07:25:12 <hpaste_> roastbird pasted “Question: Is a pair of Monads a Monad?” at http://hpaste.org/50625
07:25:27 <frerich> Sorry for the enter/leave noise.
07:25:36 <tomberek> Cale: ya, and the haphazard structure of a graph precludes the simple and easy tricks... i'm still hoping for a flash of insight, though i suspect a true zipper graph to be impossible
07:25:54 <Cale> roastbird: that's not a pair of monads
07:26:07 <Cale> There's only one monad m
07:26:38 <Cale> Values of type P a b are pairs of m-actions.
07:27:10 <roastbird> Cale: you're right. pair of monadic values from the same monad?
07:27:11 <Cale> tomberek: Well, you can still make a zipper of sorts.
07:27:17 <Cale> yeah
07:27:39 <Cale> roastbird: So first off, what is the parameter type of the new monad? b?
07:27:51 <tomberek> Cale, ski: for now though, imagine I wasn't working on graphs, I'd still like to think I can get performance out of GHC without having to manually unroll the repeated application of a function (for now it's just traversal, but it could be anything including modification and update)
07:27:51 <roastbird> i'm always being corrected for my language here. hrm.
07:28:01 <Cale> roastbird: You want to make P a into a monad?
07:28:02 <tomberek> Cale: "still make a zipper of sorts" how so?
07:29:15 <tomberek> roastbird: looks like a bi-monad,  i'm not sure if that's a term
07:29:22 <Cale> tomberek: Well, pull one vertex and its adjacency information out of the map structure and put it alongside the Map (though probably this isn't really worth doing, since accesses into most good map structures are fast enough that nobody's going to care about the difference between that and constant time)
07:29:37 <roastbird> (P a b) into something that has a do-notation
07:30:03 <Cale> roastbird: probably not.
07:30:17 <Cale> roastbird: hmm
07:30:21 <Cale> Well...
07:30:24 <rwbarton> the normal do-notation wouldn't capture your K thing very well
07:30:28 <tomberek> Cale,, ah, that's what fgl does...   it uses the concept of (Graph-without-Context, Context) where Context = (node,edges)
07:30:46 <Cale> data P a = P (m a) (m a)
07:31:01 <tomberek> data P m a = ...?
07:31:04 <Cale> let's at least try to do this so that it has an appropriate kind ;)
07:31:05 <Cale> yes
07:31:13 <Cale> data P m a = P (m a) (m a)
07:31:15 <tomberek> then instance Monad (P m)?
07:31:19 <Cale> instance Monad (P m) where
07:31:20 <ski> roastbird : sounds like something a bit a like a monad on `Hask * Hask' ..
07:31:21 <roastbird> i keep getting the feeling that it can't be done, that's why i keep trying
07:31:32 <Cale>   return v = P (return v) (return v)
07:31:54 <roastbird> heh uh...
07:32:09 <rwbarton> what roastbird has is a very simple kind of monad on Hask * Hask though, at least at first glance
07:32:21 <rwbarton> since it doesn't "mix the factors" at all
07:34:40 <roastbird> Cale: data P m a = P (m a) (m a) ... it's not the same right?
07:34:41 <Cale>   (P x y) >>= f = P (do v <- x; let P l r = f v; l) (do v <- y; let P l r = f v; r)
07:34:50 <Cale> It's not the same
07:35:13 <Cale> It's simpler, but (P m) at least has the right *kind* to be a monad.
07:35:24 <roastbird> rwbarton: i thought so at the start too... but m (a,b) ? that doesn't work :(
07:35:26 <rwbarton> isn't this just ReaderT Bool m
07:35:30 <Cale> Monads are all type constructors with one type parameters
07:35:33 <Cale> parameter*
07:35:36 <rwbarton> what Cale wrote I mean
07:36:11 <Cale> rwbarton: Yeah, hopefully.
07:36:30 <rwbarton> roastbird: it might help to give an example of the kind of program you'd want to write in this modified do-notation
07:36:49 <rwbarton> when would you not just write (do ..., do ...)?
07:37:50 <Cale> also, your >>>>= doesn't typecheck
07:38:09 <Cale> f :: a -> m a', but x :: m a, so you can't write f x
07:38:26 <Cale> You can write f =<< x though.
07:40:48 <roastbird> oops. i did mean x >>= f and y >>= g
07:41:13 <roastbird> rwbarton: perhaps when i want to
07:41:26 <roastbird> p1' = do {    ar <<- a  ;   br <<- b  ;   return (ar ++++ br)  }
07:41:39 <Cale> What is <<- ?
07:41:44 <Cale> What type is ar?
07:41:49 <rwbarton> what is ++++
07:41:54 <roastbird> or foo ar br, or something like that
07:42:11 <rwbarton> your K type doesn't let you do that
07:42:32 <Cale> roastbird: If x :: P a b, and I write v <<- x in your notation, what is the type of x?
07:42:36 <Cale> er of v
07:43:16 <Cale> v :: (a,b)?
07:44:29 <roastbird> uhh... (V a b) i guess?
07:44:49 <Cale> What's V a b?
07:45:06 <roastbird> (a,b) would be enough in what i was trying to do, but it wouldn't really be general
07:45:22 <Cale> Normally in do notation, if I have x :: m a, and I write v <- x, then v :: a
07:46:24 <roastbird> well, V a b = (a,b), but (a,b) can't be separated out? because a can only be used for the first of the pair, and b can only be used for the second of the pair
07:47:02 <Cale> My suggestion would be to immediately give up on trying to shoehorn what you're trying to do into being a monad just for the do-syntax, and instead try to write a library of operations, and if it happens to be a monad then great, and if not, you still have the operations you want.
07:49:03 <roastbird> but.... i suspect that it cannot be done. i just don't know how to prove it.
07:49:17 <Cale> Well, what cannot be done?
07:49:25 <Cale> There's nothing which looks like a monad here yet.
07:49:40 <roastbird> trying to shoehorn a pair of monadic actions into being a monad
07:49:40 <Cale> My thing is a monad, albeit a somewhat boring one.
07:50:15 <Cale> Well, a pair of monadic actions will at best give rise to a monadic action.
07:50:21 <Cale> Not a monad :)
07:50:35 <Cale> (because we don't have dependent types, so types can't depend on values)
07:50:52 <Cale> A monad is a thing which constructs types from other types
07:51:08 <Cale> first and foremost
07:51:19 <roastbird> what stops us from allowing M (a,b)?
07:51:22 <Cale> and in addition to that, there are some operations available on those constructed types
07:51:30 <Cale> m (a,b) is perfectly okay
07:51:44 <Cale> pairM :: m a -> m b -> m (a,b)
07:51:48 <Cale> pairM = liftM2 (,)
07:52:36 <roastbird> i mean well, P (a,b), P :: * -> *?
07:52:57 <mm_freak_> roastbird: that's fine
07:53:00 <Cale> If P :: * -> *, then (a,b) :: *, and so that's fine.
07:53:01 <mm_freak_> (a, b) :: *
07:53:24 <mm_freak_> (,) :: * -> * -> *
07:53:34 <mm_freak_> P (a,b) = P ((,) a b)
07:53:37 <Cale> But remember that if P is a monad, you can't constrain P to only work on pair types.
07:54:10 <Cale> (formally, it's a monad on Hask itself, and not on any other category, and in particular, not on a subcategory of Hask)
07:54:24 <Cale> When you write the instance of Monad, you'll write
07:54:28 <Cale> instance Monad P where
07:54:55 <Cale>   return = ... -- something of type  a -> P a  which is polymorphic in a
07:55:24 <Cale>   (>>=) = ... -- something of type P a -> (a -> P b) -> P b which is polymorphic in a and b
07:56:33 <Cale> Right?
07:56:51 <roastbird> how about... P :: (*,*) -> * ?
07:56:58 <Cale> nope
07:57:04 <Cale> Can't be done.
07:57:14 <Cale> At least, the Monad class isn't for that.
07:57:35 <Cale> There is no kind (*,*) -> * (at least not yet)
07:57:48 <Cale> and if P :: * -> * -> *, then it's the wrong kind to be a monad.
07:57:51 <roastbird> Tuple2 t => P t :: * -> *?
07:58:37 <Cale> Also, if you have a monad of some sort, then it's got to be an endofunctor on some category, so you're more likely to have a monad (*,*) -> (*,*), in some system where that makes some kind of sense.
07:59:22 <benmachine> tuple kinds, whee :P
08:00:07 <tomberek> odd, i don't see what you would do with tuple kinds......  something that is two types at once?, [*] would be non-deterministic types?
08:00:26 <Cale> tomberek: It might just be the product kind
08:00:58 <roastbird> i second Cale, or at least that's all i had in mind
08:01:23 <Cale> So, the types in (*,*) are just pairs of types whose values are pairs of values, and the functions between them are just pairs of functions.
08:01:46 <roastbird> two types at once would be sum kind?
08:02:33 <Cale> roastbird: I guess so. There's a weird kind of punning going on here -- there's a question about whether types of kind (*,*) actually have any values at all, or whether those values are pairs.
08:03:04 <Axman6> (Maybe a, Either b c) = Nothing | Just a | Left b | Right c?
08:03:08 <Cale> When we write (a,b) in Haskell, it looks like a pair of types, but it's actually also the product type.
08:03:40 <Cale> Axman6: wat
08:03:47 <Cale> I guess you could sum them
08:03:58 <Cale> That would be even stranger than taking a product :)
08:04:02 <Axman6> i missed most of the conversation, but that seems like it's something that could be useful
08:04:25 <Cale> Unioning them would be awkward and make type inference really hard.
08:04:45 <Axman6> yeah
08:04:55 <Cale> Of course, there are lots of type constructors of two parameters we could presumably automatically use on a pair of types.
08:05:08 <Cale> But maybe the right thing is not to auto-apply any of those.
08:05:30 <Cale> and just say that (a,b) has no values when a and b are types (you'd have to write the product type some other way now)
08:06:15 <roastbird> Cale: but if there's (*,*) or anything that can constraint the type to pairs... i would be able to make it a monad! just not over Hask, but only pairs
08:06:25 <Cale> If we weren't so happy with currying, we might have Product :: (*,*) -> * and Sum :: (*,*) -> *
08:06:40 <tomberek> hm
08:06:43 <Cale> roastbird: yeah, I guess
08:06:56 <Cale> roastbird: You have to automatically adjust the types of the methods too...
08:07:16 <Cale> roastbird: and then whenever you use (>>=), the compiler has to infer which subcategory of Hask you mean.
08:08:14 <Cale> and, can you use monadically polymorphic things with this new "Monad instance"? :)
08:08:20 <roastbird> Cale: it would be possible to fit (*,*,...,*) into one type parameter. then *->* stuff can be used. (Without using forall a b. and case to take it out or weird stuff like that)
08:08:26 <Cale> (even if they do computations internally which don't use pairs)
08:08:28 <Cale> ?
08:08:42 <Cale> roastbird: Here's a more common problem which is related:
08:08:51 <Cale> It would be really nice to have an instance of Monad for Set
08:08:54 <roastbird> hm... but why wouldn't it? the compiler has always inferred
08:09:12 <Cale> But all of the operations on Sets require Ord instances of the type parameter
08:09:21 <Cale> (because Sets are internally binary trees)
08:10:00 <Cale> But we'd need to write  return :: a -> Set a  and  (>>=) :: Set a -> (a -> Set b) -> Set b
08:10:02 <Cale> which we can't do
08:10:16 <Cale> because we need an Ord instance on a and b which we don't necessarily have
08:11:14 <Cale> (we might be able to write return, but certainly not >>=, which internally has to do a union of a bunch of sets.)
08:11:35 <roastbird> hmmmmmm..... just because it must be on Hask, but not a subset of Hask?
08:11:41 <Cale> yep
08:11:51 <Cale> and if we change the Set datatype so that it contains a dictionary of Ord operations when you construct it
08:11:57 <Cale> the problem flips around :)
08:12:20 <Cale> So (>>=) becomes no problem then because you are given the Ord dictionaries inside the Set datastructures
08:12:46 <Cale> But return becomes an issue, because you can't tell when writing a -> Set a that a has an Ord instance.
08:13:34 <roastbird> .
08:13:40 <Cale> So, that's just tough. There is a clever way around the problem by deferring the operations.
08:14:08 <Cale> But you end up with something that might as well just be the list monad, where at the very end, you form a Set of the results.
08:14:20 <Cale> (so Set a vs. [a] buys you nothing)
08:14:53 <roastbird> is this limit fundamental to haskell? i.e. it can't be changed?
08:14:58 <Cale> (http://hackage.haskell.org/package/rmonad)
08:15:21 <roastbird> that we can't place constrains on types? or do (*,*)?
08:15:21 <Cale> Well, it's not an easy problem, even conceptually.
08:15:52 <Cale> Because one thing about typeclasses is that you can form various compositions of the typeclass methods which then become polymorphic.
08:16:03 * ski thinks a pair of types `(Int,Bool)' has no values (at least not in a normal sense)
08:16:33 <Cale> So it's not just the typeclass methods alone which are polymorphic and you can write new versions of them which have lots of new constraints
08:17:12 <Cale> But all the operations defined in terms of those are polymorphic too, and it's impossible to tell from their type alone whether they internally preserve all the constraints you might need.
08:17:46 <Cale> For example, in the case of Set, I might have an operation (Monad m) => m String -> m Integer
08:17:56 <Cale> which seems externally like it'd be okay
08:18:04 <Cale> Set String -> Set Integer seems plausible
08:18:19 <Cale> But what if internally it constructs a value of type m (String -> String)
08:18:33 <Cale> Set (String -> String) isn't reasonable
08:18:40 <Cale> because String -> String has no Ord instance
08:19:13 <roastbird> then, it's rejected?
08:19:15 <Cale> So, if you want to do this correctly, you have to expose at the type level all the types at which m is applied.
08:19:42 <Cale> Well, there's no way to tell, because, say, the module is already compiled, and all that's left are some code pointers and some types in the module interface file.
08:19:54 <Cale> But the type signatures don't tell you what types m was internally applied at.
08:20:02 <Cale> Unless we extend the type system to make it do that
08:20:16 <Cale> and if we do, then suddenly our types balloon out to ridiculousness
08:20:34 <EvanR-work> more than they already have ;)
08:20:40 <Cale> because all the internal types at which m is applied have to be kept around in constraints which most of the time are irrelevant
08:20:42 <EvanR-work> what feature exactly are we talking about?
08:21:14 <Cale> EvanR-work: Nothing in particular, we're talking about the trouble defining restricted instances of Monad (for things like Set)
08:22:09 <EvanR-work> defining a monad instance for a data type which has restrictions
08:22:23 <Cale> The RMonad library gives us a way to write those constraints
08:22:30 <Cale> which is about as good as you can ask for
08:22:35 <EvanR-work> Set itself has restrictions?
08:22:35 <roastbird> but without a type system, it would be possible, and makes sense at the same time?
08:22:40 <Cale> no
08:22:49 <tomberek> cale: all this is because Set needs ord. so what if there was a non-ord- requiring Set. And set simply used the Ord version whenever possible, but defaulted back to the other
08:22:52 <Cale> because monads are just about impossible to use without a type system
08:23:35 <EvanR-work> tomberek: Set doesnt require Ord
08:23:35 <Cale> Because in order to be convenient to use, the implementations of return and (>>=) at the call sites need to be determined based on the types at which they're used.
08:23:49 <int-e> Cale: btw, laziness also helps -- a strict >> is awkward.
08:23:54 <Cale> Or else you end up passing around another parameter defining the instance of the monad operations you want, and it's awful.
08:23:57 <EvanR-work> you just cant do anything with Set (String -> String)
08:24:46 <Cale> tomberek: How do you take the union of two sets of things with no Ord instance?
08:24:58 <Cale> tomberek: Just store both of the sets side by side? :)
08:25:05 <Cale> Might as well use lists.
08:25:10 <copumpkin> we need presets
08:25:23 <copumpkin> http://ncatlab.org/nlab/show/preset
08:25:35 <Cale> A lot of thought has gone into this problem, and nobody has a *really* good answer about what to do.
08:25:36 <tomberek> yep, use the lists when a doesn't have Ord
08:25:40 <copumpkin> sound really useful
08:25:49 <EvanR-work> tomberek: thats silly
08:25:51 <copumpkin> tomberek: how would you look things up?
08:25:56 <copumpkin> do you have an Eq at least?
08:26:14 <Cale> But RMonad is about as decent an approach as I can imagine at the moment.
08:26:35 <Cale> you end up with things like   filterM :: (RMonad m, Suitable m [a], Suitable m Bool) => (a -> m Bool) -> [a] -> m [a]
08:26:36 <tomberek> i have no idea, i'm making this up as i go along, i guess you can't
08:26:56 <Cale> rather than   filterM :: (Monad m) => (a -> m Bool) -> [a] -> m [a]
08:27:30 <Cale> and note that the Suitable constraint won't go away when you apply filterM to a parameter
08:27:42 <Cale> if it's something polymorphic
08:28:37 <tomberek> so then you get constrain pollution
08:28:40 <Cale> Only when the monad m is finally specified, it'll go away
08:28:41 <Cale> yeah
08:28:43 <tomberek> constraint
08:28:57 <Cale> liftM2 :: (RMonad m, Suitable m a1, Suitable m a2, Suitable m r) => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
08:28:57 <roastbird> hm..... that's a lot of work for getting do notation for a pair of monadic actions
08:29:14 <Cale> So yeah, you might be able to use RMonad in your case
08:29:45 <rwbarton> doesn't the RMonad thing only work for full subcategories though
08:30:16 <Cale> Oh, right, you don't just have a subcategory though
08:30:28 <Cale> er...
08:30:45 <Cale> Your arrows are pairs of functions
08:30:52 <Cale> So that's really quite different.
08:31:58 <Cale> Basically, as soon as you want to write code in a category that's not the category of Haskell types and functions, you're going to have a hard time, at least if you want to use built-in stuff.
08:32:11 <roastbird> yea well.... guess i'll revisit this again next decade.
08:32:23 <Cale> roastbird: What do you need it for anyway?
08:32:29 <Cale> What does your library do?
08:33:41 <Cale> roastbird: It's certainly possible to stick your pairwise operations in their own typeclass
08:33:46 <roastbird> Cale: Actually, i don't really need it. My library generates Javascript code, and it uses a monad. The code comes in a pair:
08:34:18 <roastbird> the code that should be at the top level, that's before everything else (the library initialization and stuff), and the code that comes after, the everything else
08:34:27 <Cale> okay
08:34:37 <Cale> So, like a call to bracket
08:35:02 <Cale> :t bracket
08:35:03 <lambdabot> Not in scope: `bracket'
08:35:06 <Cale> ah
08:35:11 <tomberek> you guys know much about Iterator/Iteratee/enumerator? would something like be able to allow GHC to optimize away intermediate structures?
08:35:42 <roastbird> bracket?
08:35:48 <Cale> bracket :: IO a -> (a -> IO b) -> (a -> IO c) -> IO c
08:36:17 <Cale> bracket acquireResource releaseResource useResource
08:36:49 <ezyang> tomberek: I don't believe any of the current iteratee libraries do fusion at the moment.
08:36:52 <roastbird> oh yes. quite similar to that.
08:37:37 <tomberek> ezyang: dang
08:37:41 <roastbird> that's the end step. (m a, m b) -> m b  -- no release
08:37:45 <Cale> bracket has the nice property that it handles exceptions and ensures that the resource is freed.
08:38:33 <roastbird> the difference is that for acquireResource, bracket has it all defined upfront, but for generating code, the initialization code needs to be extended as more of the target-language's libraries are used
08:39:14 <EvanR-work> in bracket what is the purpose of b
08:39:28 <Cale> EvanR-work: You can tell from the type that it's discarded.
08:39:35 <EvanR-work> so useless
08:39:39 <roastbird> so the state needs to be kept as a monad or something, and then it comes as a pair of something. in my case, it would be nice if it was a pair of monads, with do notation. but alas.
08:39:48 <mm_freak_> tomberek: at least in the enumerator library intermediate structures should vanish quickly
08:40:04 <mm_freak_> they still need to be created and destroyed, but they shouldn't persist, if used properly
08:40:13 <glguy> EvanR-work: it's really frustrating to have to throw in an extra (return ()) because someone forgot to make the type general enough
08:40:33 <Cale> EvanR-work: right. People have been doing this incorrectly lately, but generally, here's the rule for "unneeded" types
08:40:36 <edwardk> @remember JaffaCake In the beginning there were 8 registers, and That Was Enough For Everyone.
08:40:37 <lambdabot> It is stored.
08:40:45 <EvanR-work> glguy: ah but... the code ends up looking like javascript with 'dangling functions'
08:40:59 <Cale> If the type parameter occurs in a positive position, then you want to use (), and if it occurs in a negative position, you make it an arbitrary type
08:41:03 <tomberek> mm_freak_, hm I don't thing I have a problem with the structures sticking around, I'd like to just fuse them away
08:41:06 <glguy> EvanR-work: No, it looks like Haskell where you don't have to end with a return :)
08:41:29 <EvanR-work> Cale: whats positive and negative there
08:41:33 <Cale> In a -> b, the b is in a positive position and a is in a negative position
08:42:19 <ezyang> tomberek: Iteratees tend to allocate less than their list counterparts. Are you sure allocation is the problem?
08:42:20 <EvanR-work> what about functions that return IO ()
08:42:28 <ezyang> (due to chunking)
08:42:38 <Cale> In (a -> b) -> c, the b is in negative position, and the a is in positive position again (negative of a negative)
08:42:51 <mm_freak_> tomberek: you can't, because the structures represent the current iteratee state
08:42:59 <tomberek> ezyang : enumerator seems to be for IO, can it be used for ST?    no, i'm not sure
08:43:23 <Cale> I can probably come up with a proper recursive definition :P
08:43:37 <Cale> But I won't bother if it's already pretty clear what I mean.
08:43:42 <tomberek> mm_freak_ : ah, i was hoping one of those might be able to do 'unrolling' for me
08:43:48 <edwardk> tomberek: you don't really have anything to iteratee over though
08:43:53 <EvanR-work> Cale: so getChar should be IO a ?
08:43:56 <EvanR-work> er
08:43:57 <EvanR-work> putchar
08:44:07 <EvanR-work> putChar :: Char -> IO a
08:44:09 <glguy> EvanR-work: no, putChar actually returns
08:44:22 <glguy> fail :: String -> m a    because it does not
08:44:31 <Cale> The a there is in positive position, so you make it ()
08:44:50 <Cale> according to my rule
08:44:51 <EvanR-work> this rule is crazy
08:44:58 <Cale> How so?
08:45:22 <Cale> Suppose putChar took an extra parameter it didn't care about
08:45:27 <edwardk> the benefit of using the () in positive position is you don't lie
08:45:30 <Cale> putChar :: Char -> a -> IO ()
08:45:30 <mm_freak_> tomberek: if you really want to get rid of all intermediary structures, you have to use the 'iteratee' package, which uses CPS
08:45:49 <Cale> this time, the a is in negative position, and so you want to leave it polymorphic
08:46:02 <edwardk> mm_freak_: it still isn't clear to me how the iteratees help his traversal, he needs the graph structure
08:46:07 <tomberek> mm_freak_ : pulling up hackage,, reading ,, learning
08:46:09 <glguy> EvanR-work: you don't have to memorize this rule. Type inference will do it for you
08:46:22 <EvanR-work> uhm no
08:46:22 <mm_freak_> edwardk: i think, we went on to a new topic =)
08:46:32 <edwardk> i really do need to write up how iteratees aren't a monad.
08:46:39 <EvanR-work> you write type sigs for top level stuff
08:46:41 <edwardk> and how to fix them
08:47:00 <glguy> EvanR-work: you can use type inference to compute those top-level type signatures
08:47:04 <EvanR-work> if i wrote an IO command that didnt have useful info, couldnt i make it IO a and return undefined
08:47:20 <Cale> EvanR-work: well, the inferred types will be correct with regard to this rule, usually, provided you write sensible code
08:47:23 <tomberek> mm_freak_,edwardk : ah, i think I misunderstood what iteratee meant... yes, i was thinking of applying this to my graph traversal in ST
08:47:29 <Cale> EvanR-work: that's unsafe then
08:47:40 <EvanR-work> how so
08:47:42 <edwardk> tomberek: red herring. won't help
08:47:45 <glguy> EvanR-work: you are misunderstanding why the 'b' in bracket was not a ()
08:48:03 <EvanR-work> glguy: so far, cale has only said that it was a rule, not why to use that rule
08:48:06 <Cale> EvanR-work: Well, "unsafe" in that the result is undefined
08:48:10 <EvanR-work> so far i see the choice as arbitrary
08:48:24 <glguy> EvanR-work: try to write bracket yourself (without specifying the type signature)
08:48:32 <tomberek> edwardk: thanks, that's why I ask, you guys help me avoid wasted time...... what about some other CPS transform?
08:48:44 <glguy> EvanR-work: it is a short function and should help you see what's going on
08:48:46 <mm_freak_> edwardk: why are iteratees not a monad?  given you don't put back
08:48:50 <EvanR-work> glguy: i wrote bracket like functions before, and ive done ()
08:48:56 <Cale> EvanR-work: If something is a parameter that you don't care about, then it might as well accept a value of any type. If something is a result that you don't care about, make it () so that things which, say, print it, don't choke.
08:48:59 <glguy> EvanR-work: don't specify the type
08:49:15 <EvanR-work> glguy: i understand that you have a rule that says that, please dont repeat yourself
08:49:27 <glguy> EvanR-work: I'm not talking about Cale's rule
08:49:35 <edwardk> mm_freak: the problem is that the type is too big. return a >>= f where f returns Done a (something non-empty) violates the first monad law
08:49:36 <glguy> EvanR-work: I'm talking about how Haskell type inference works
08:49:44 <Cale> EvanR-work: The rule is essentially "be generous in what you accept, and conservative in what you produce"
08:49:55 <EvanR-work> Cale: ok, but thats not what bracket does
08:50:04 <EvanR-work> glguy: i was not
08:50:04 <Cale> EvanR-work: it is what bracket does
08:50:08 <edwardk> mm_freak: you can fix them making it so that the iteratee type itself is 'shrinkwrapped' to the right type, and that you switch to a bigger non-monadic step type to feed it data for enumerating
08:50:12 <glguy> @src bracket
08:50:13 <lambdabot> bracket before after thing = block $ do
08:50:13 <lambdabot>     a <- before
08:50:13 <lambdabot>     r <- catch (unblock (thing a)) (\e -> do { after a; throw e })
08:50:13 <lambdabot>     after a
08:50:13 <lambdabot>     return r
08:50:18 <edwardk> mm_freak: this has the benefit that bind becomes cheaper
08:50:51 <Cale> EvanR-work: bracket generously accepts a polymorphic function as its parameter because it doesn't care about the result of the action returned by the function
08:51:06 <EvanR-work> ok
08:51:17 <EvanR-work> that makes more sense than a random rule ;)
08:51:32 <Cale> It's the same thing
08:51:48 <Cale> The rule is just a restatement and generalisation of this
08:52:07 <EvanR-work> so if i understand your last thing, only the far right should have () and everything else is polymorphic
08:52:26 <edwardk> the It type I use in trifecta manages to be a real monad, but it gives up the iteratee space guarantees, in exchange for other nice guarantees about seeking. you can strike a middle ground
08:52:46 <edwardk> mm_freak_: the 'given you don't put back' is a cheating caveat ;)
08:52:46 * ski idly wonders whether the category of sets have enough invectives
08:54:07 <monochrom> @type const
08:54:08 <lambdabot> forall a b. a -> b -> a
08:54:30 <EvanR-work> in (a -> b) -> c, b is negative?
08:54:33 <Cale> EvanR-work: In ((a -> b) -> c) -> (d -> e), the positive positions are b, e, and the negative positions are a, c, d
08:54:48 <glguy> EvanR-work: elliottt wrote a tool which tells you which positions in a type are positive and negative. I'll ask him if its available
08:54:57 <Cale> in (a -> b) -> c, the b is negative, a and c are positive
08:55:14 <EvanR-work> so youd say make b IO ()
08:55:20 <EvanR-work> er
08:55:21 <Cale> If F is a covariant functor, then in F a, the a is positive
08:55:25 <EvanR-work> yes
08:55:40 <Cale> and if F is a contravariant functor, then in F a, the a is negative
08:56:50 <Cale> yeah, so in (a -> b) -> c, if we didn't care about any of it, we'd make a and c into (), and leave b polymorphic
08:57:06 <Cale> a and c are things "produced" by the function we're defining
08:57:13 <Cale> and b is something "consumed"
08:57:32 * EvanR-work scratches head
08:57:44 <EvanR-work> how is a produced, and b consumed
08:57:59 <Cale> Because when we apply the function we're given, we supply the argument
08:58:12 <Cale> So we supply (), given that we're being ignorant of it
08:58:20 <Cale> rather than undefined, which is mean
08:58:40 <Cale> (because any accidental evaluation of undefined will cause the program to crash)
08:59:02 <EvanR-work> (not sure how you can accidentally evaluate something with any type)
08:59:05 <Cale> if we're not using the result of the function, then it's okay for that function to produce undefined as a result, and we note that by making it completely polymorphic
08:59:12 <Cale> seq, for instance
08:59:17 <EvanR-work> cheating
08:59:37 <Cale> Well, in special cases, things are not quite this general ;)
09:00:13 <EvanR-work> in (a -> b) -> c, we supply a (a -> b), not ()
09:00:27 <Cale> f :: (a -> b) -> c
09:00:38 <Cale> f g = g ...
09:00:47 <Cale> Whatever we put in "..." here
09:00:57 <Cale> will be supplied to the function g that we're given
09:01:12 <EvanR-work> ()
09:01:13 <Cale> So it's like an "output" of our function
09:01:17 <Cale> yeah
09:01:21 <Cale> So if we give ()
09:01:26 <Cale> f :: (a -> b) -> c
09:01:29 <Cale> f g = g ()
09:01:37 <Cale> now g has to take () as a parameter
09:01:38 <EvanR-work> and g returns any type
09:01:52 <Cale> yeah, well, that's bad
09:02:18 <monochrom> you have to relax the meaning of "produce" for this, or alternatively you have to accept classical logic, i.e., (c->r)->r produces c iff ((q implies false) implies false) produces a proof of q.
09:02:18 <Cale> (assume this definition is incomplete, since we're not supposed to care about the result of g :)
09:02:30 <mysticc> What is overloaded string extension in ghc
09:03:02 <Cale> mysticc: It lets you define instances of the IsString class which define a conversion from String, so that you can write polymorphic string literals
09:03:19 <Cale> mysticc: So you can have  "hello" :: ByteString  or  "hello" :: Text
09:03:32 * monochrom accepts classical logic and has no problem with (c->r)->r producing c. it's CPS after all
09:03:37 <mm_freak_> edwardk: i see
09:03:49 <mm_freak_> well, yes…  the cheating is what i was getting it
09:04:09 <mm_freak_> it has already bitten me once, because i didn't know that iteratees aren't monads
09:04:11 <Cale> f g = let v = g () in ()
09:04:23 <Cale> :t let { f g = let v = g () in () } in f
09:04:24 <lambdabot> forall t. (() -> t) -> ()
09:04:36 <EvanR-work> ok
09:04:38 * ski . o O ( <http://www.patrickblackburn.org/uploads/6/2/8/3/6283774/4577023.jpg> )
09:04:44 <Cale> note how the positive positions ended up with (), and the negative position ended up with a polymorphic type :)
09:05:07 <EvanR-work> ((a -> b) -> c) -> d
09:05:07 <ski> monochrom : even when `r' is `Void' ?
09:05:39 <monochrom> well ((q implies false) implies false) is using Void for r
09:05:52 <rwbarton> especially when r is Void, I'd think
09:06:13 <Cale> :t let { f g = let v = g (\k -> ()) in () } in f
09:06:14 <lambdabot> forall t t1. ((t -> ()) -> t1) -> ()
09:06:48 <EvanR-work> but then you dont need to have the in ()
09:07:01 <Cale> Well, gotta produce something
09:07:09 <Cale> and it's not supposed to be the result v
09:07:14 <EvanR-work> :t let { f g = let v = g (\k -> ()) in g () } in f
09:07:15 <lambdabot>     Couldn't match expected type `()' against inferred type `t -> ()'
09:07:16 <lambdabot>       Expected type: () -> t1
09:07:16 <lambdabot>       Inferred type: (t -> ()) -> t2
09:08:14 <Cale> The code ends up looking contrived because we don't usually ignore so many paramters and results all at the same time :)
09:08:42 <Cale> But basically, wherever I need a value, I use ()
09:08:58 <Cale> whenever I need a lambda, I don't use the parameter to the lambda, but I also don't pattern match on ()
09:09:21 <EvanR-work> pattern matches on () was what i was gonig to try as an example
09:10:18 <Cale> We could take that to be a pattern match on _
09:10:24 <Cale> instead
09:10:42 <EvanR-work> ((t -> ()) -> t1) -> ()
09:10:59 <Cale> :t \f g _ -> f (\_ -> g ())
09:11:00 <lambdabot> forall t t1 t2 t3. ((t1 -> t2) -> t3) -> (() -> t2) -> t -> t3
09:11:15 <EvanR-work> yeah so why you chose to ignore some of the params
09:11:16 <Cale> hmmm...
09:11:24 <EvanR-work> also er
09:11:28 <Cale> oh
09:12:00 <Cale> well, some of my type variables have gotten unified there :P
09:12:12 <EvanR-work> :t \g -> ()
09:12:13 <lambdabot> forall t. t -> ()
09:12:24 <Cale> :t \f g _ -> let v = f (\_ -> g ()) in ()
09:12:25 <lambdabot> forall t t1 t2 t3. ((t1 -> t2) -> t3) -> (() -> t2) -> t -> ()
09:12:38 <EvanR-work> :t \g -> g ()
09:12:40 <lambdabot> forall t. (() -> t) -> t
09:13:05 <Cale> yeah, if you return the result, of course, it'll have the same polymorphic type
09:13:46 * hackagebot fclabels 1.0.2 - First class accessor labels.  http://hackage.haskell.org/package/fclabels-1.0.2 (SebastiaanVisser)
09:14:08 <saml> http://lists.grok.org.uk/pipermail/full-disclosure/attachments/20110820/848b4dca/attachment.obj    can you port this to oneliner?
09:14:43 <EvanR-work> :t \g -> let x = x in g x
09:14:44 <lambdabot> forall t t1. (t -> t1) -> t1
09:15:04 <EvanR-work> :t \g -> let v = g () in ()
09:15:05 <lambdabot> forall t. (() -> t) -> ()
09:15:24 <EvanR-work> uhg
09:15:54 <Cale> :t callCC
09:15:55 <lambdabot> forall a (m :: * -> *) b. (MonadCont m) => ((a -> m b) -> m a) -> m a
09:16:21 <Cale> heh
09:16:37 <roastbird> ?
09:18:58 <Cale> That has a polymorphic b in positive position.
09:20:05 <roconnor> edwardk: ping
09:20:45 <Cale> but by construction, you can't use the b :)
09:21:00 <EvanR-work> Cale: still not sure why it matters for ((a->())->a)->a and not (((t->a)->t)->t)->t ;)
09:21:05 <edwardk> pong
09:21:27 <edwardk> your ping made a multi-protocol hop through a nearby pumpkin
09:21:42 <Botje> peer-to-pumpkin communication
09:22:01 <roconnor> edwardk: today I had a want to create a collection of projection functions in a representable functor.  Have anything like that?  Does this make sense?
09:22:11 <edwardk> yeah, asymmetric routing table though, the response didn't go back through the pumpkin
09:22:13 <Cale> EvanR-work: well, this is a special case, because you never have access to the result
09:22:22 <Cale> even if it looks like you do
09:22:25 <edwardk> roconnor: not sure i'm parsing what you mean
09:22:30 <Cale> > runCont (do callCC (\ret -> do v <- ret 5; return (v + v))) id
09:22:30 <roconnor> (Representable f) => f (forall a. f a  -> a)
09:22:31 <lambdabot>   5
09:22:48 <Cale> The 'v' there has type b in the type of callCC
09:22:52 <roconnor> edwardk: for example: (fst, snd)
09:22:56 <roconnor> @type (fst, snd)
09:22:57 <lambdabot> forall a b a1 b1. ((a, b) -> a, (a1, b1) -> b1)
09:23:04 <Cale> and we can do stuff with it, but it won't amount to anything because that code is dead
09:23:05 <edwardk> ah yes
09:23:09 <edwardk> i have thought about this
09:23:37 <roconnor> oh good
09:23:46 <edwardk> at least for the parametric case, pair is a little off
09:23:56 <roconnor> is it definable for any represtable functor?
09:23:56 <edwardk> but for data Pair a = Pair a a, yes
09:24:02 <edwardk> hrmm
09:24:05 <roconnor> edwardk: ya, my (fst, snd) is too polymorphic
09:24:44 <edwardk> well, lets see, every Representable functor is Keyed, so you can get a name for the location, the problem was one of performing the update 'efficiently'
09:25:02 <edwardk> so for representable-tries, yes, but for representable-functors, 'not efficiently' is what i currently believe
09:25:07 <roconnor> edwardk: actually even better woudl be (Representable f) => f (Lens (f a) a)
09:25:12 <edwardk> yeah
09:25:22 <edwardk> or ideally the impredicative
09:25:33 <edwardk> Representable f => f (forall a. Lens (f a) a)
09:25:35 <roconnor> ya
09:25:39 <roconnor> that's what I meant to write
09:25:54 <edwardk> this is what i was talking about when i talked about using lenses as keys
09:26:10 <roconnor> oh
09:26:14 <edwardk> =)
09:26:19 <roconnor> I guess keys don't need to be Eq?
09:26:26 <edwardk> yeah
09:26:39 <roconnor> scary
09:26:45 <edwardk> heh
09:27:01 <edwardk> i use higher order keys for things like covectors
09:27:09 <roconnor> so f(forall a. Lens (f a) a) *is* the universal element when lenses are keys
09:27:19 <edwardk> (a -> r) -> r for instance
09:27:32 <Cale> > runCont (do callCC (\ret -> do v <- ret 5; undefined `seq` return (v + v))) id
09:27:33 <lambdabot>   5
09:27:44 <edwardk> assuming each lens points to itself
09:27:50 <roconnor> right
09:27:53 <Cale> (just to prove that we really can't use v here)
09:28:03 <roconnor> er I guess I just gave the type of the universal element
09:28:09 <roconnor> not the element itself
09:28:25 <edwardk> roconnor: fun?
09:28:47 <edwardk> roconnor: btw- i went through and implemented the unboxed and cps'd lenses, but i haven't implemented all the downstream stuff so they aren't on hackage yet
09:29:14 <roconnor> edwardk: Are these all the natural lenses of type forall a. (f a) -> a?  I guess so.
09:29:23 <roconnor> edwardk: are the cps'd or unboxed lenses faster?
09:29:38 <edwardk> the snap guys were going to benchmark and get back to me
09:29:41 <edwardk> i haven't touched base
09:29:47 <roconnor> :)
09:30:08 * roconnor is excited to be making useful contributions
09:30:09 <edwardk> you are welcome to pull from the unboxed branch of https://github.com/ekmett/data-lens/tree/unboxed and try them yourself
09:30:33 <edwardk> i had a cps'd version somewhere, but the unboxed one was a nice thought =)
09:30:33 <roconnor> heh, I have no idea how to benchmark anything.  I'm a theoritician
09:30:59 <edwardk> the main change that i made was defining 'runLens' in cps fashion in the Lens class
09:31:11 <edwardk> that way all the combinators are parametric in their choice of lens representation
09:31:23 <roconnor> yes
09:31:28 <edwardk> e.g. https://github.com/ekmett/data-lens/blob/unboxed/Data/Lens/Combinators/Trans/State/Lazy.hs
09:31:32 <roconnor> it will be a good interface for Haskell 2012 :)
09:31:35 <edwardk> nothing there cares how i implement lenses
09:31:56 <edwardk> which means i can make data-lens-fclabels and data-lens-accessor to provide instances for third-party lens apis
09:32:05 <roconnor> this is very good
09:32:16 <edwardk> and then they can compete on their relative performance merits
09:33:15 <mysticc> is there any distinction between [char] and String ??
09:33:23 <EvanR-work> type String = [Char]
09:33:26 <edwardk> mysticc: no
09:33:45 <edwardk> mysticc: String is just an alias
09:35:13 <mysticc> edwardk: ["hello"] can this be type inferred as something else other than [String] too ??
09:35:33 <EvanR-work> with overloaded string literals
09:35:56 <mysticc> EvanR-work: ok got it ... thanks ...
09:36:00 <edwardk> ["hello"] :: [String] but overloaded string literals can make it any FromString a => [a]
09:36:12 <edwardk> er IsString or whatever the class is
09:36:13 <int-e> then it will be IsString a => [a]
09:37:08 <mysticc> and one more thing how to know the inferred type of a function from inside ghc ...?? In ghci I can do :t ..
09:37:34 <Nisstyre> mysticc: why would you need to do that?
09:37:48 <mysticc> Nisstyre: just wondering
09:37:59 <edwardk> mysticc: the best hack that i have is to either remove the type signature and then use :type from ghci, or use {-# LANGUAGE ImplicitParams #-} and put ?foo in my code where i need a type signature
09:38:02 <Nisstyre> mysticc: The type checking is done prior to compiling
09:38:51 <Nisstyre> so idk how you would get the inferred signatures in your actual program when it runs
09:38:56 <EvanR-work> switch(typeof(expr)){ ;)
09:38:57 <edwardk> @type 1 + fromIntegral ?huh
09:38:59 <lambdabot> forall t a. (Num t, ?huh::a, Integral a) => t
09:39:06 <Nisstyre> maybe some kind of preprocessor thing
09:39:27 <edwardk> nisstyre: you can use :type from ghci if you import the module
09:39:29 <roconnor> Nisstyre: generally speaking types are erased after compiling
09:39:38 <Nisstyre> that's what I said
09:39:42 <EvanR-work> Typeable
09:39:58 <roconnor> Nisstyre: ah sorry
09:40:58 <roconnor> is that another earthquake or am I just jittery now?
09:41:02 <Rotsor> Is there no way to pattern match on all the constructors of the type with 0 constructors? :) I'd like something like (case x of {})
09:42:00 <roastbird> what do i lose if i don't use do notation?
09:42:11 <edwardk> readability
09:42:12 <roconnor> roastbird: not much
09:42:29 <EvanR-work> if its a short expression it might be more readable with >>=
09:44:25 <roastbird> undo do { va =<< a ; vb =<< b ; return f a b }
09:44:40 <c_wraith> Rotsor: You can't have a value of a type with zero constructors...  So, no, you can't pattern match such a value.
09:44:47 <roconnor> @undo do { va <- a ; vb <- b ; return f a b }
09:44:48 <lambdabot> a >>= \ va -> b >>= \ vb -> return f a b
09:45:06 <roastbird> what do i lose if i don't use do notation, and i can't nest functions in the style of       a >>= \ va -> ... ?
09:45:24 <roconnor> Was 0 contsuctors types made legal in Haskell 2010?
09:45:33 <c_wraith> roastbird: do notation is strictly syntactic sugar. the *only* thing you lose by not using it is (sometimes) readability
09:45:33 <int-e> convenience. you can still use let ...
09:45:34 <roastbird> do i have to end up using arrows?
09:45:59 <rwbarton> you never have to use any type class, you could just say what you mean directly
09:46:03 <EvanR-work> don't _ = return ()
09:46:08 <rwbarton> not sure what you are trying to do
09:46:31 <int-e> roconnor: yes
09:46:54 <EvanR-work> is haskell 2010 out yet
09:46:57 <c_wraith> @undo do { x' <- x ; y' <- y ; f x' y' }
09:46:58 <lambdabot> x >>= \ x' -> y >>= \ y' -> f x' y'
09:48:14 <roastbird> hello rwbarton again. Cale convinced me that i can't get do notation for a pair of monadic actions (m a, m b).
09:48:48 <Cale> roastbird: okay, but you know, it's not that bad, you can invent other combinators for making whatever you want to do convenient.
09:48:55 <roastbird> so without do notation, it might look like... (a, b) >>>> (c, d) >>>>= (f, g)
09:49:26 <Cale> yeah, perhaps
09:49:32 <EvanR-work> foo (x, y) = x >> y
09:49:39 <roastbird> Cale: i don't know. i mean, i can't do (a,b) >>>>= \ x -> ...;
09:49:49 <int-e> EvanR-work: again, yes. http://www.haskell.org/definition/haskell2010.pdf
09:49:59 <Cale> roastbird: Well, sure, but there's no way you'd be able to do that with do notation either
09:50:11 <Cale> (think about it)
09:50:29 <EvanR-work> you got arrows on the brain
09:50:37 <Cale> Unless you want x to be a pair, and then it's just that the type of >>>>= is wrong
09:54:16 <Botje> you?
09:54:18 <Botje> oops
10:00:40 <Rotsor> roconnor: the data type "data Empty" compiles. It does not have any constructors, right?
10:01:09 <edwardk> data Empty requires {-# LANGUAGE EmptyDataDecls #-}
10:01:31 <roconnor> Rotsor: that isn't legal Haskell '98, but I'm told it is legal Haskell 2010
10:01:46 <bscarlet> Is there any way to write the identity type constructor?
10:02:06 <edwardk> bscarlet: you can make newtype Id a = Id a
10:02:09 <roconnor> (It is also legal Haskell 1.4, which in may regards was superiour to Haskell 98)
10:02:37 <roconnor> bscarlet: or you can use existing one in transformers
10:03:51 <bscarlet> edwardk, roconnor: those are newtypes. I need something of kind * -> * to put in an instance declaration that will actually return the same type it's given.
10:03:53 <Rotsor> Indeed, if I put {-# LANGUAGE Haskell98 #-} it stops compiling
10:04:09 <roconnor> bscarlet: those are newtypes
10:04:31 <monochrom> @kind
10:04:32 <lambdabot> parse error (possibly incorrect indentation)
10:04:40 <monochrom> @kind Identity
10:04:41 <lambdabot> * -> *
10:04:44 <monochrom> there
10:06:14 <bscarlet> roconnor: Yes, a newtype is of kind * -> *, but it's not the actual identity. Id x is different from x.
10:06:25 <frerich> I tried to write a polymorph version of 'getLine' so that I can easily read integers or whatever. However, ghc doesn't like my code at http://hpaste.org/50630 saying "Could not deduce (a1 ~ m0 a0) from the contest (Read a)" - unfortunately, I don't know what that means. Can anybody shed some light?
10:06:46 <edwardk> bscarlet: no you can't
10:06:47 <roconnor> bscarlet: you cannot make instance declarations without using a newtype or some very scary langauge flags.
10:07:01 <edwardk> bscarlet: that is the whole point of newtypes
10:07:10 <bscarlet> edwardK, roconnor: Okay, thanks.
10:07:11 <gwern> @remember frezik "The compiler accepted it, why can't you?"
10:07:11 <lambdabot> Good to know.
10:07:24 <bscarlet> roconnor: What very scary language flags, pray?
10:07:25 <Botje> frerich: you are aware of readLn?
10:07:32 <roconnor> bscarlet: I don't know :)
10:07:42 <bscarlet> roconnor: Okay, that is scary.
10:07:48 <frerich> Botje: Euhm, no... let me google...
10:07:56 <roconnor> some sort of TotallyUnsafeOverlappingUnsafeInstances
10:07:58 <copumpkin> frerich: your issue is that you want scoped type variables
10:08:16 <copumpkin> frerich: otherwise, just leave out the ::
10:08:20 <frerich> Botje: Oh, I guess I reinvented readLn. Thanks for pointing that out!
10:08:21 <roconnor> actually, I'm told some of these flags are relatively safe
10:08:21 <copumpkin> and it'll figure that shit out for you
10:08:26 <roconnor> I've never used any of them
10:08:32 <copumpkin> frerich: haskell is smarter!
10:08:38 <Botje> frerich: and the error is because your :: scopes over teh entire line, not just the read s part
10:08:52 <frerich> Ooooh.
10:08:53 <copumpkin> Botje: it's because a is a fresh type variable there
10:08:59 <frerich> I somehow thought it's just for 'read s' because I used $
10:09:02 <Botje> oh?
10:09:07 <Botje> brr :(
10:09:16 <copumpkin> Botje: well, you're right too
10:09:21 <Botje> I can see why it's handy, though.
10:09:22 <copumpkin> it is scoping the entire line, I think
10:09:29 <copumpkin> but it's also a fresh type variable
10:09:40 <Botje> frerich: you don't need the type annotation :)
10:09:42 <int-e> @src ($)
10:09:43 <lambdabot> f $ x = f x
10:09:49 <Botje> you already gave it at the top
10:09:51 <glguy> frerich: also, check out readIO, it makes sure that the failed parse is caught immediately
10:09:53 <glguy> :t readIO
10:09:54 <lambdabot> forall a. (Read a) => String -> IO a
10:10:17 <copumpkin> frerich: even fancier, you could leave out the type annotation at the top, and it would infer the type you gave it!
10:10:19 <int-e> @type getLine >>= readIO
10:10:21 <lambdabot> forall b. (Read b) => IO b
10:10:35 <copumpkin> :t read <$> getLine
10:10:36 <lambdabot> forall a. (Read a) => IO a
10:10:54 <frerich> copumpkin: That a bit too much behind-the-scenes-magic for a newbie like me :-)
10:11:04 <int-e> copumpkin: yeah. I incorporated glguy's suggestion
10:11:41 <int-e> frerich: giving top-level type signatures is good practice anyway
10:12:57 <int-e> (for documentation, and to localise type errors which might otherwise pop up in non-offending code, because the offender was type-checked first ...)
10:12:57 * glguy likes having top-level type signatures up until he wants to make a sweeping change to the file
10:13:23 <frerich> Botje: Thanks for pointing out readLn, that's exactly the function I attempted to write, I didn't realize it's already there!
10:13:33 * int-e thinks the second part is rather important, especially when making sweeping changes ;)
10:14:23 <Botje> frerich: I managed to miss it for quite a while too :)
10:21:46 <tomberek> .
10:23:20 <bscarlet> how about a type level equivalent of const?
10:24:00 <bscarlet> e.g. something of kind * -> * for which the result is always, say, ().
10:24:46 <benmachine> @hoogle Const
10:24:47 <lambdabot> Control.Applicative newtype Const a b
10:24:47 <lambdabot> Control.Applicative Const :: a -> Const a b
10:24:47 <lambdabot> Prelude const :: a -> b -> a
10:25:21 <benmachine> bscarlet: newtype Const a b = Const { getConst :: a } iirc
10:25:27 <bscarlet> benmachine: again, a newtype. Oh well.
10:25:33 <tomberek> how is       f a = liftM head (g a)     different from do  r:_ <- g a; return r   ?
10:25:49 <benmachine> bscarlet: type-level functions are scary :P you could try writing a type family?
10:26:15 <benmachine> tomberek: the latter will call the monad's 'fail' method if the pattern match is unsuccessful
10:26:32 <bscarlet> benmachine: Yeah, but I'm already using MultiParamTypeClasses and even _I_ don't like mixing them with type families. :-)
10:26:40 <benmachine> so for example, in the Maybe monad you will get Nothing
10:27:02 <benmachine> bscarlet: aw, go on
10:27:03 <tomberek> benmachine,,,, ok, what about allocation? because using the do version takes my GC's from 4601 down to 1
10:27:05 <benmachine> see if you can find a bug :P
10:27:11 <tomberek> benmachine, i'm in ST monad
10:27:20 <benmachine> tomberek: it's probably stricter
10:27:28 <benmachine> or something.
10:27:30 <benmachine> I don't really know
10:27:38 <monochrom> head is lazier than pattern matching in do
10:27:39 <tomberek> benmachine: it seems to get rid of all the allocation, but actually runs slower!
10:27:50 <benmachine> interesting
10:27:51 <benmachine> that can happen sometimes
10:27:54 * frerich realizes that he got spoiled by all those oh-so-funny "FAIL!" pictures on the interweb as he reads Haskell code which calls the "fail" function.
10:27:59 <frerich> I can never read it the same way again.
10:28:01 <benmachine> :P
10:28:06 <monochrom> more precisely, liftM head is lazier than pattern matching in do, too
10:28:52 <monochrom> liftM head blah = do { y <- blah; return (head y) }
10:28:58 <tomberek> monochrom: but why would the do version run slower?, can i get best of both worlds? runs fast, no allocation?
10:29:18 <monochrom> that depends on which monad
10:29:31 <tomberek> ST
10:30:21 <tomberek> i was blown away, those two version perform the same task, but one is faster with more heap usage, the other is slower, but no heap usage
10:30:59 <dolio> r:_ <- g a ; return r has a branch.
10:31:01 <monochrom> do { blah; return () } is both faster and smaller
10:31:33 <dolio> g a >>= \v -> case v of r:_ -> return r ; _ -> fail "whatever"
10:31:41 <tomberek> dolio: yeah, do you think that extra branch instruction is causing the issues? is there a way to get the same effect, but no branching?
10:32:37 <dolio> That may be why it's slower, I'm not really sure.
10:32:56 <tomberek> it makes sense, it's an additional check
10:32:57 <monochrom> head y has a branch, too
10:33:09 <tomberek> ok, then i have no idea
10:33:19 <dolio> Yeah, but it may not be in his main loop.
10:34:39 <tomberek> i basically apply that function many many many times
10:35:01 <tomberek> so using the liftM or the a:_ version seems to matter
10:35:27 <monochrom> perhaps wrong and unfair measurement. perhaps the measurement was main = runST (do r:_ <- blah; return r) >> putStrLn "done" vs main = runST (liftM head blah) >> putStrLn "done", which is comparing apple with rolls royce
10:35:27 <erus`> lets say i have data Vertex = Vertex Vec3 [Vertex] can i check if a shape is solid (has no holes) ?
10:35:29 <dolio> Is there more fleshed out code somewhere to look at?
10:36:06 <monochrom> perhaps there is no context, no fleshed out code
10:36:06 <tomberek> dolio: of course, one moment
10:37:04 * monochrom is tired of asking for context. if people don't give it, they don't like to give it
10:37:46 <roconnor> erus`: that type seems strange
10:38:09 <rwbarton> I think he means he has a graph embedded in 3D
10:38:44 <madhadron> erus`, Hmm.  In 2D it's trivial.  In 3D I haven't thought about it.
10:38:52 <roconnor> erus`, rwbarton: to represent polytopes you want a notion of vertex, edge, and *face*.
10:39:10 <rwbarton> yes, I am not sure what he is thinking of by "hole"
10:39:31 <madhadron> rwbarton, Handle on a coffee mug
10:39:36 <mercury^> erus`: do you consider a sphere to have a hole?
10:39:39 <madhadron> There's a pretty standard topological definition of a hole
10:39:45 <roconnor> erus`: then depending on the type of hole you want you can either check that the polytope equation holds (every edge is both traversed forward and backwards once)
10:39:52 <rwbarton> well his datatype is not the type of mugs :P
10:39:56 <roconnor> erus`: or you can compute the genus from euler's formula
10:40:18 <erus`> a sphere is solid and has no holes
10:40:22 <madhadron> roconnor, Oh right, Euler.  The easy way.  I had forgotten about that.
10:40:22 <erus`> as is a cube
10:40:23 <rwbarton> erus`, you might look into persistent homology
10:40:33 <mercury^> Then you seem to be interested in the first betti number.
10:41:08 <roconnor> erus`: does a donut have a hole?
10:41:31 <erus`> no
10:41:57 <mercury^> He wants to check whether the space is simply connected.
10:41:59 <rwbarton> hmm maybe the answer is that nothing has a hole!
10:42:00 <roconnor> erus`: then you want a collection of oriented faces (which consists of a cycle of edges)
10:42:03 <erus`> What word am i looking for?
10:42:17 <rwbarton> can you give us an example where the answer is yes?
10:42:25 <roconnor> erus`: then check that each edge occurs in exactly two faces, with opposite orientations in each face.
10:42:26 <erus`> a cube with no top
10:42:27 <madhadron> erus`, You're asking if a space consists of disjoint pieces?
10:42:35 <monochrom> closed surface
10:42:39 <mercury^> Heh, a cube with no top is simply connected.
10:42:43 <erus`> if i can see the back of a face then it has a hole
10:42:47 <Cale> A sphere has a 2-hole, but no 1-hole.
10:43:01 <rwbarton> you want to know whether it has a boundary perhaps
10:43:17 <rwbarton> as a 2-manifold(-possibly-with-boundary)
10:43:26 <roconnor> erus`: or if you are feeling lazyish you can "add" up all the oriented edges and make sure the sum is 0.
10:43:35 <mercury^> Maybe he wants to know whether the object is its convex hull?
10:43:47 <roconnor> mercury^: I don't think convexity is the issue
10:43:56 <mercury^> roconnor: how do you explain the cube then?
10:43:57 <monochrom> donut is not its convex hull
10:44:09 <Cadynum> if i want to use the endian functions like ntohl and htonl on windows, what do i need to do? on linux i just do: foreign import ccall unsafe "ntohl" ntohl :: Word32 -> Word32. But it gives "un
10:44:13 <Cadynum> defined reference to `ntohl'" on windows
10:44:26 <madhadron> erus`, Do you want to know if a shape an inside and an outside, then?
10:44:26 <hpaste_> tomberek pasted “a:_ <-  vs liftM head” at http://hpaste.org/50631
10:44:35 <erus`> madhadron: yes
10:44:39 <glguy> A single triangle would have a "hole" by erus`'s definition, assuming I understand correctly
10:44:41 <roconnor> mercury^: a cube with the top missing has a hole because the 4 top edges only belong to one face.
10:44:54 <roconnor> well each edge only belongs to one face
10:44:58 <tomberek> dolio: monochrom: it's still kinda ugly, so i'll answer any confusion that there may be
10:45:06 <mercury^> roconnor: so a square has a hole too?
10:45:12 <roconnor> mercury^: yep
10:45:18 <rwbarton> erus`: as soon as you have a notion of face you can just check whether there are any edges that are in only one face
10:45:19 <erus`> erm i mean a shape is 'solid'
10:45:20 <roconnor> a rather large one :D
10:45:23 <madhadron> erus`, What if the shape consisted of a pair of nonintersecting, closed cubes?
10:45:36 <madhadron> Or are you only allowing simply connected shapes?
10:46:14 <erus`> connected by vertices
10:46:16 <roconnor> erus`: but above all else, you want to add a notion of an (oriented) face to your data structure.  This will make your life infinitely easier.
10:46:28 <rwbarton> yes
10:46:30 <erus`> roconnor: with a normal?
10:46:37 <madhadron> erus`, No need for a normal
10:46:41 <madhadron> This is topology, not geometry
10:46:45 <roconnor> erus`: if you want.  As long as you have at least 3 edges you can compute a normal.
10:47:04 <roconnor> erus`: the order of the 3 edges will determine the orientation
10:47:05 <erus`> roconnor: how will i know if it points inside or out?
10:47:10 <erus`> ah ok
10:47:39 <madhadron> erus`, roconnor's statement that you check for any edges that adjoin only one face is what you want, I think
10:48:20 <roconnor> erus`: life will be easier still if you require that a face have exactly 3 edges, but this isn't strictly necessary.
10:48:55 <erus`> ah that doesnt seem too hard :)
10:48:59 <roconnor> erus`: but if faces can have 4 or more edges, then you have to worry about making sure all the edges are in one plane.
10:49:24 <tomberek> dolio: monochrom: is http://hpaste.org/50631 making any sense or is it too much of a jumble at this stage? I can try to refactor to get isolate the liftM head vs a:_ difference
10:50:06 <roconnor> erus`: when you join two faces next to each other, their edges "cancel" because they have opposite orientaions.
10:50:22 <roconnor> erus`: when you join all faces, and all the edges cancel, you have a solid.
10:51:00 <roconnor> erus`: or possibly many solids as madhadron points out.
10:51:30 <erus`> ok
10:51:33 <roconnor> you also might have degenerate solids of 0 volume.
10:51:56 <madhadron> roconnor, I was going to ask him about concentric solids, but he seemed to think he would only have simple connected 2-manifolds
10:52:51 <roconnor> but it is probably best to live with degenerate solids of 0 volume, because excluding them would actually make things more complicated.
10:53:44 <roconnor> ... you can also have solids of negative volume.
10:53:47 <erus`> roconnor: so my first step is to make tris?
10:53:54 <erus`> or edges?
10:54:01 <roconnor> erus`: ya, I'd start with faces.
10:54:18 <hpaste_> erus` pasted “test data” at http://hpaste.org/50632
10:54:19 <roconnor> erus`: if you want you can even leave edges implict and just define a face by the (oriented aka ordered) points.
10:54:42 <erus`> im not sure how to order them in this format :|
10:55:19 <roconnor> erus`: I forget what is standard.  clockwise for outward facing and counterclockwise for inward facing I think.
10:55:26 <roconnor> erus`: it doesn't matter as long as you are consistent.
10:55:49 <madhadron> erus`, Probably depends on your community and nationality.  And if you're Wigner or not.
10:55:57 <madhadron> Err...to roconnor
10:56:03 <roconnor> hmm
10:56:07 <erus`> yeah but i only define neighbors
10:56:15 <roconnor> if I use the right hand rule, it says that counter-clockwise is outward facing
10:56:25 <madhadron> roconnor, Wigner used the left hand rule consistently (:
10:56:26 <roconnor> erus`: are you right-handed or left-handed?
10:56:32 <erus`> right
10:56:58 <erus`> i would have to explicitly define the triangles to make them ordered no?
10:57:12 <roconnor> okay, hold out your right hand and curl your fingers slightly into a c and stick out your thumb towards yourself.
10:57:20 <rwbarton> you have to explicitly define them in any event
10:57:26 <madhadron> erus`, Yes, you would.  But you're going to anyway.
10:57:38 <roconnor> erus`: your fingers point counter-clockwise and your thumb is pointing to you
10:57:57 <madhadron> (Computational geometry is one of those things that everyone assumes is simple, until they actually try it.)
10:58:02 <roconnor> erus`: if you go with the right-hand rule then a counter-clockwise order of points is a face facing outwards towards you.
10:58:10 <roconnor> erus`: (this is the opposiste rule that I mentioned above)
10:59:14 <erus`> but i only have vertices and the vertices they are neighbors of :O
10:59:55 <roconnor> erus`: someone will need to turn this list into faces.  ... not the easiest task in the world.
10:59:58 <rwbarton> then you're stuck
11:00:20 <rwbarton> for example, what you pasted defines the edges of a tetrahedron, how can we know which of the 4 faces are supposed to be there
11:00:29 <rwbarton> and it matters to your answer
11:00:35 <erus`> shortest path
11:00:46 <rwbarton> what?
11:00:49 <roconnor> I don't think shortest path will necessairly work.
11:01:19 <erus`> if two points share a neighbor then they make a tri?
11:01:38 <roconnor> erus`: do you know that all your faces are triangles?
11:01:56 <erus`> in this case yes
11:02:02 <erus`> but maybe not in the future
11:02:26 <madhadron> erus`, Since you are interested in whether there is a missing face of your polytope, you must define the faces.
11:02:33 <roconnor> erus`: if you know that all your faces are triangles and you know there are no degeneracies and you know that there are no disconnected components, then you might be able to tackle this with some work.
11:02:44 <madhadron> Otherwise you only find out what your face constructing algorithm does
11:03:32 <tomberek> dolio: monochrom: ok, i've narrowed it to this difference:    ~(a:_)  and (a:_)
11:04:11 <erus`> yep i think i need tris
11:04:21 <roconnor> erus`: I don't know the best way of doing this by you can assign a face to the first triangle you find, and then try to assign the remaining faces by orienting its neighbours in a compatable way until you have oriented all your faces.
11:04:39 <roconnor> erus`: then you should compute the signed volume of the result (which isn't so hard to compute).
11:04:52 <roconnor> erus`: if it is negative you can flip the orientation of all your faces to make it postive.
11:05:07 <tomberek> (a:_ somehow avoids allocation, but is slower.   ~(a:_) allocates to the heap, but is faster nontheless
11:05:14 <erus`> roconnor: good idea
11:05:50 <roconnor> erus`: this is not an easy task on the whole.
11:06:03 <madhadron> erus`, But on that tetrahedron, what would the difference be between an open tetrahedron and a closed one as currently represented?
11:06:10 <roconnor> erus`: it would be much better if you can convince your data source to give you the faces in the first plac.e
11:10:32 <tomberek> .
11:10:45 <edwardk> preflex: xseen nominolo
11:10:45 <preflex>  nominolo was last seen on freenode/#ghc 4 hours, 16 minutes and 16 seconds ago, saying: it's probably simple
11:11:01 <Jeanne-Kamikaze> is IORef the only tool to write mutable data structures ?
11:11:11 <edwardk> no
11:11:18 <roconnor> Jeanne-Kamikaze: STRef and STArray are actually the prefered way.
11:11:19 <tomberek> preflex: xseen sigpfe
11:11:19 <preflex>  Sorry, I haven't seen sigpfe
11:11:27 <erus`> is there a built in to check if two lists contain the same items (maybe in a different order) ?
11:11:34 <Jeanne-Kamikaze> can you tell me if you think this is ugly: http://codelink.info/~jeanne/uploads/Octree.txt ?
11:11:40 <roconnor> Jeanne-Kamikaze: though even better is not to use Mutable data structues :)
11:11:45 <edwardk> Jeanne-Kamikaze: you can also use STM, MVars, various channels, etc.
11:11:58 <edwardk> Jeanne-Kamikaze: yes, ugly =/
11:12:10 <edwardk> there is little reason to make that mutable
11:12:20 <Jeanne-Kamikaze> it brought down GC time to 2.7% though
11:12:22 <edwardk> just make an immutable octree
11:12:23 <tomberek> Jeanne-Kamikaze; for a tree like that, you probably don't need Refs
11:12:29 <Jeanne-Kamikaze> the immutable octree uses 30% GC time
11:12:42 <edwardk> fair nuff
11:12:50 <madhadron> erus`, Sort them both and then compare them element by element
11:12:54 <edwardk> the result is going to be a lot harder to reason about though
11:12:56 <madhadron> erus`, Any other solution reduces to that.
11:13:03 <Jeanne-Kamikaze> indeed, took me 1 hour to write though
11:13:06 <Jeanne-Kamikaze> and I can't even read it
11:13:12 <Jeanne-Kamikaze> *it
11:13:28 <roconnor> Jeanne-Kamikaze: hopefully your immutable octree could be optimized; but you are right that a mutable octree will likely be somewhat faster, but at a cost of flexibility.
11:13:51 * hackagebot haskell-src-meta 0.5 - Parse source to template-haskell abstract syntax.  http://hackage.haskell.org/package/haskell-src-meta-0.5 (JonasDuregard)
11:13:52 <Jeanne-Kamikaze> the "problem" with STRef is that newSTRef seems to be creating a copy of the value I pass to it
11:13:53 * hackagebot type-equality 0.1.0.2 - Type equality, coercion/cast and other operations.  http://hackage.haskell.org/package/type-equality-0.1.0.2 (ErikHesselink)
11:13:56 <koala_man> madhadron: maybe the elements are Eq but not Ord
11:14:00 <roconnor> Jeanne-Kamikaze: but definitely prefer STRef to IORef
11:14:00 <edwardk> for one thing you could flatten the children pointers, etc. the current representation has a lot of 'fat'
11:14:22 <edwardk> Jeanne-Kamikaze: it doesn't STRefs and IORefs are all but indistinguishable
11:14:28 <tomberek> Jeanne-Kamikaze; less GC time is not always better. I'm kinda confused right now because of a STRef structure that is either fast but has GC, or slow with no GC's at all
11:15:00 <madhadron> koala_man, Ah yes.  Then you're stuck running the pairwise comparisons and it's O(n^2)
11:15:06 <Jeanne-Kamikaze> but what's the point of calling newSTRef on the octree if that's just gonna duplicate it ?
11:15:26 <roconnor> Jeanne-Kamikaze: lists are not a great choice for fixed sized containers.
11:15:27 <edwardk> @hpaste
11:15:28 <lambdabot> Haskell pastebin: http://hpaste.org/
11:15:28 <madhadron> Well, probably not quite n^2, since you could try to pop the elements
11:15:57 <koala_man> pop the elements?
11:16:02 <hpaste_> edwardk pasted “a cheesy immutable octree” at http://hpaste.org/50633
11:16:25 <roconnor> Jeanne-Kamikaze: using STRef over IORef won't make your code any different other than the ability to use it outside of the IO monad.
11:16:26 <madhadron-away> koala, When you find a match for the current element in the second list, pass on the second list with that element removed for the next search
11:16:37 <edwardk> woops that one wasn't mine
11:16:37 <roconnor> Jeanne-Kamikaze: it will be almost a search and replace.
11:16:38 <edwardk> one sec.
11:17:05 <koala_man> madhadron-away: that's still O(n^2), isn't it?
11:17:44 <edwardk> wow, i can't paste code tp hpaste i get 'a web handler threw an exception. Details: Ambiguous infix expression.
11:17:45 <edwardk> lol
11:17:49 <roconnor> Jeanne-Kamikaze: it will also reassure users of your octree that the functions won't format their harddrives.
11:17:52 <erus`> ok roconnor so if i had a list of triangles, now i just have to make edges and check the all have a face either side?
11:18:04 <copumpkin> preflex: seen chrisdone
11:18:04 <preflex>  chrisdone was last seen on #haskell 4 hours and 14 seconds ago, saying: i tried using loeb to solve sudoku grids but it doesn't support the backtracking necessary
11:18:25 <tomberek> roconnor: good point, ST just seems safer
11:18:27 <edwardk> https://gist.github.com/1168855
11:18:29 <roconnor> erus`: a face on the other side with the edge having opposite orientation.
11:18:44 <Jeanne-Kamikaze> roconnor, but what's the point of using STRef if newSTRef makes a copy ?
11:18:48 <edwardk> https://raw.github.com/gist/1168855/34f77f05abc5cb0e7d371486c046bd65f32fd134/octree is the unclipped version
11:19:01 <edwardk> Jeanne-Kamikaze: flattening the pointers to the children like that should help quite a bit
11:19:01 <tomberek> Jeanne-Kamikaze: use modifySTRef
11:19:03 <Jeanne-Kamikaze> or am I missing something
11:19:08 <roconnor> Jeanne-Kamikaze: newIORef also makes a copy (of a pointer).
11:19:12 <maloi> data Oct a = Oct !a !a !a !a !a !a !a !a what does the ! mean?
11:19:15 <Jeanne-Kamikaze> oh
11:19:19 <Jeanne-Kamikaze> the pointer only ?
11:19:26 <edwardk> 'strict'
11:19:40 <roconnor> maloi: it is a strictness flag that says that if Oct is forced then all the members of Oct will be forced at the same time.
11:19:41 <Jeanne-Kamikaze> so I'd be mutating the octree passed as a parameter ?
11:19:56 <roconnor> Jeanne-Kamikaze: everything in Haskell is passed by reference.
11:19:56 <maloi> ohh thanks
11:20:05 <edwardk> maloi: by doing it that way you don't have to worry about the environment holding on to lots of garbage until it gets forced
11:20:33 <roconnor> Jeanne-Kamikaze: the only things that make signficant copies are freeze and thaw. AFAIK.
11:20:42 <maloi> i think i need to read more about lazyness oO
11:21:17 <roconnor> maloi: I think of it as a tool for making a complex strucuture behave more like a primitive structure.
11:21:20 <zygoloid> maloi: if you've left understanding laziness until you need to know about it, then you already understand it
11:21:31 <edwardk> that version was rather repetitive because i didn't have access to all the code the guy i was mocking it up for was using for AABBs, etc.
11:21:48 <hnsz> Implement a lazy merge sort in an imperative language, it's fun :)
11:21:56 <roconnor> maloi: anyhow focus on correctness first.  Those !'s are a performance optimization.
11:22:08 <roconnor> *are just a performance
11:22:16 <Luqman> Hello
11:22:17 <maloi> oh ok
11:22:28 <maloi> zygoloid: :D
11:22:46 <edwardk> the UNPACK's and !'s in there all exist to reduce pressure on the garbage collector and to avoid building big thunks
11:22:46 <Luqman> I've been trying to create a cross compiling ghc
11:22:52 <Luqman> but am having some trouble
11:23:02 <edwardk> in practice i find that to be a much better technique than STRef'ing a structure to death
11:23:27 <edwardk> and forcing myself to work with it in a single threaded, ephemeral, imperative fashion
11:23:39 <roconnor> edwardk: a right, that may have been Jeanne-Kamikaze's original performance problem.
11:23:43 <byorgey> Luqman: try #ghc
11:23:43 <tomberek> edwardk: thx.......
11:23:48 <edwardk> yeah
11:23:58 <Luqman> thank you
11:24:03 <Jeanne-Kamikaze> ok thanks, I'm reading the code edwardk pasted
11:24:05 * roconnor wants to upload a strictified version of PSQueue.
11:25:05 <edwardk> i'm thinking about adding an explicitly separate priority/value heap to my heaps package
11:25:12 <edwardk> that would at least justify the plural
11:25:34 <roconnor> edwardk: can I search as well?
11:25:58 <edwardk> roconnor: nah, it is a brodal-okasaki heap, it gives up the structure flexibility you need for search to get O(1) merge
11:26:33 <roconnor> O(1) merge is good
11:26:34 <edwardk> basically its a relaxed bootstrapped skew binomial heap
11:26:44 <edwardk> asymptotically optimal for all heap operations
11:26:51 <roconnor> I have no idea what that is, but sounds great.
11:27:38 <edwardk> brodal figured out how to implement an imperative heap with provably optimal asymptotics. later on okasaki worked with him to make a functional version that attained the same asymptotics
11:27:45 <edwardk> but which used a different bag of tricks
11:27:49 <roconnor> :)
11:28:20 <edwardk> bootstrapping gives the O(1) merge, the skew binomial bit gives the other performance numbers, the relaxed form lets it denormalize a bit to make nicer constant factors
11:28:31 * roconnor wants a Map structure that is optimized for operations and optimized for high amounts of sharing.
11:28:37 <edwardk> but makes the code nigh impenetrable…. and i wrote it ;)
11:28:49 <edwardk> eh i have a hash consed' IntSet ;)
11:29:14 <edwardk> but no maps yet
11:29:27 <roconnor> edwardk: does it have hight amounts of sharing?
11:29:39 <edwardk> roconnor: i should hope so. its perfectly hash consed.
11:29:50 <roconnor> what is hash consed?
11:30:01 <elliott> http://en.wikipedia.org/wiki/Hash_consing?
11:30:04 <edwardk> yes
11:30:24 <edwardk> hash consing turns comparison for structural equality into comparing for pointer equality
11:30:43 <edwardk> by ensuring that any two structures that are structurally equal are pointers to the same structure
11:30:57 <edwardk> that is the purpose of my intern package
11:31:12 <edwardk> it lets you have O(1) intset comparisons
11:31:19 <edwardk> and maximizes sharing
11:31:19 <elliott> I should polish off that interning library I wrote ages ago...
11:31:42 <edwardk> i have one now that leaks a bit, and a new one that is region based that is almost ready for release
11:32:24 <edwardk> i was using it heavily in trifecta for a while, but it didn't net a big enough space improvement to warrant it given the typical usage pattern
11:32:43 <kmc> see also http://en.wikipedia.org/wiki/Flyweight_pattern
11:32:59 <kmc> this is my personal favorite example of how every concept in programming has at least two different, equally unhelpful names
11:33:52 <elliott> edwardk: hmm... oh, the "intern" package is yours
11:33:58 <elliott> I think I looked at that but dismissed it for some reason
11:35:07 <roconnor> edwardk: I want sharing of the internal strucutre of the Map, not the data
11:35:38 <roconnor> sharing the data is not so hard in Haskell
11:35:43 <roconnor> (though not so easy)
11:35:52 <edwardk> roconnor: it shares the structure as well
11:36:18 <edwardk> roconnor: its a patricia trie, the branches are in a normal form
11:36:33 <edwardk> it is built up layer by layer via hash consing
11:36:49 <hpaste_> erus` pasted “is shape solid?” at http://hpaste.org/50636
11:36:51 <edwardk> so every subtree that is the same is shared between intsets
11:37:00 <erus`> roconnor: does that look ok to you
11:37:15 <erus`> seems to work for basic shapes and doesnt work for open ones
11:37:39 <elliott> edwardk: it would be nice to have something that transformed any structure into a hash-consed one... I guess that's pretty easy really
11:37:47 <elliott> (given abstracted-out type recursion blah blah blah)
11:37:48 <roconnor> erus`: one sec
11:38:07 <edwardk> elliott: yes the new version will have an Interned Mu
11:38:26 <edwardk> that requires my new region machinery
11:38:42 <elliott> hmm, clearly I need to think of an advantage to mine that isn't "only a few pages of code"
11:38:54 <mdmkolbe> Are the "build-depends" for Cabal 0.10.2.0 borked?  If the base4 flag is set but not the base3 flag it, looks like it will require "base >=4 && base < 3" which is impossible.  Am I missing something here?  (See http://hackage.haskell.org/packages/archive/Cabal/1.10.2.0/Cabal.cabal for the dependencies)
11:38:55 <roconnor> edwardk: how much tree rotation is done when elements are deleted (and inserted) as this is what breaks sharing in Data.Map.
11:39:26 <edwardk> roconnor: none, this is a patricia trie. it always achieves the same nornal form
11:39:32 <mdmkolbe> FYI, I found this when trying to bootstrap a new cabal-install
11:39:41 <edwardk> its a crit bit tree
11:39:58 <edwardk> i can't do the same for Data.Map
11:40:03 <elliott> edwardk: does your intern library let you use any store for the interned items?
11:40:05 <edwardk> but for Data.IntMap its fine
11:40:09 <elliott> Data.Map, a hash table, etc.
11:40:17 <elliott> mine seems to have something along those lines...
11:40:18 <edwardk> elliott: internally it uses a hashmap
11:40:45 <elliott> right, mine abstracts that out... dunno if that's worthwhile at all though
11:40:46 <edwardk> the old version did so out of lack of flexibility, the new one uses a hashmap per 'region'
11:40:59 <roconnor> erus`: you need to check that the edge on the other face has an opposite orientation.
11:41:15 <edwardk> in practice, its not, because the hashmap wins for anything non trivial and by construction you have at least 2-3 values even in the flattened description
11:41:15 <roconnor> erus`: other than that it is acceptable, though a little inefficent.
11:41:27 <edwardk> and its getting faster with the HAMT changes in hashmap
11:41:35 <erus`> what do you mean by 'opposite orientation'
11:41:39 <roconnor> edwardk: interesting
11:42:00 <erus`> that the points are in the opposite order ?
11:42:30 <roconnor> erus`: Tri p1 p2 p3 and Tri p2 p1 p4 are properly adjacent but Tri p1 p2 p3 and Tri p1 p2 p4 are not
11:42:34 <edwardk> roconnor: heh for a sec there i was mistaking you for wren, who wrote bytestring trie, trying to figure out why you didn't know there was a normal form
11:42:44 <kamaji> Where are things like exp() ?
11:43:04 <roconnor> erus`: also Tri p1 p2 p3 and Tri p1 p4 p2 are properly adjacent but Tri p1 p2 p3 and Tri p2 p4 p1 are not.
11:43:06 <edwardk> elliott: do you try to garbage collect the backing store?
11:43:07 <elliott> :t (^)
11:43:08 <lambdabot> forall a b. (Num a, Integral b) => a -> b -> a
11:43:11 <elliott> :t (**)
11:43:12 <lambdabot> forall a. (Floating a) => a -> a -> a
11:43:13 <elliott> kamaji: there?
11:43:19 <roconnor> erus`: ya, that the points are in opposite order.
11:43:29 <erus`> hmm this is gonna be a pain to test
11:43:29 <kamaji> elliott: ok, math constants then? :P
11:43:35 <elliott> :t pi
11:43:37 <lambdabot> forall a. (Floating a) => a
11:43:41 <elliott> kamaji: there?
11:43:45 <edwardk> :t exp
11:43:46 <lambdabot> forall a. (Floating a) => a -> a
11:43:49 <elliott> edwardk: hmm, not at present, but I think it would be possible
11:44:08 <edwardk> elliott: that was where i ran into trouble. my original design worked…. up until i started putting around 500k elements in it
11:44:11 <elliott> Mine uses the hash tables from the hashtables library in IO, so it could ostensibly do more efficiently as far as the raw hash table lookups go
11:44:13 <byorgey> mdmkolbe: what version of GHC do you have? and what version of cabal-install were you trying to bootstrap?
11:44:15 <kamaji> umm
11:44:15 <roconnor> erus`: actually it can be pretty easy
11:44:15 <elliott> erm, inserts, not lookups
11:44:16 <kamaji> could be :D
11:44:16 <edwardk> elliott: that was why i invented the region approach
11:44:17 <elliott> at least space-wise
11:44:23 <elliott> edwardk: heh
11:44:34 <elliott> edwardk: I think I could do it with the weak pointers stuff quite easily
11:44:40 <edwardk> elliott: so be very careful about it
11:44:44 <edwardk> that was exactly what i used to do
11:44:47 <edwardk> it doesn't work =P
11:44:58 <elliott> huh, why not?
11:45:09 <byorgey> mdmkolbe: I just today successfully bootstrapped cabal-install, including building Cabal-1.10.2.0
11:45:15 <mdmkolbe> byorgey: GHC 7.2.1, cabal-install 0.10.2.0
11:45:23 <ocharles> In ghci, how do I load a file, but keep my current scope? I basically want to import Repl.hs into whatever is currently loaded (it provides some testData type definitions)
11:45:29 <edwardk> no good way to keep the pointer alive during an equality comparison. you get the identity of one side, then you go to compare the other and by the time you get there you can have garbage collected the other reference and assigned a new id
11:45:39 <roconnor> erus`: isEdgeOf p1 p2 tri = (p2,p1) `elem` edges tri where edges (Tri pA pB pC) = [(pA, pB), (pB, pC), (pC, pA)]
11:45:41 <ocharles> :l Repl.hs replaces the scope with the Repl module, but :m +Repl.hs says it can't find the module
11:45:43 <byorgey> mdmkolbe: I'm pretty sure for GHC 7.2 you need a darcs version of cabal-install
11:45:55 <edwardk> so you wind up with horrible manually cached 'live ids' which destroy performance by 3 orders of magnitude
11:46:03 <elliott> ocharles: :m +Repl?
11:46:07 <roconnor> erus`: though I'd be tempted to write my own Edge type.
11:46:11 <elliott> edwardk: ah
11:46:14 <edwardk> elliott: the effect only occurs under VERY high load
11:46:23 <ocharles> elliott: Ah, I think the problem is that Repl.hs is actually in ../repl/Repl.hs
11:46:25 <ocharles> but, I'm in src
11:46:26 <byorgey> mdmkolbe: hmm, no, looks like I'm wrong
11:46:28 <ocharles> so it can't find it
11:46:40 <elliott> ocharles: you can use :cd or fiddle with the import path
11:46:46 <ocharles> yep
11:46:56 <elliott> edwardk: what's this, using libraries for actual work? :)
11:47:06 <elliott> edwardk: I was happy micro-optimising my pointer comparisons
11:47:11 <edwardk> i was using an array of hash maps to spread the load and reduce the choke point
11:47:24 <ocharles> changing directory causes all loaded modules to be unloaded, so I think putting it in src or fiddling with the import path is my only option
11:47:31 <edwardk> but that only helped if i didn't have to hold the live set
11:47:48 <byorgey> mdmkolbe: hmm, actually, I'm not sure, it seems others have had problems with GHC 7.2 + cabal-install 0.10.2 although the GHC page claims it should work with cabal-install 0.8 or later
11:48:15 <mdmkolbe> byorgey: Do you see what I'm talking about in the Cabal.cabal file?  (It seems to have changed between Cabal 1.6.0.3 and 1.8.0.4)
11:48:29 <roconnor> erus`: also don't use tabs.
11:48:42 <edwardk> the new approach uses the same array of iorefs to hash maps (but no longer to weak pointers), but gives one hash table to each 'region' and uses the reflection trick to build a dictionary that only contains the array of hash maps
11:48:44 <erus`> roconnor: is my triangle wrong
11:48:52 <mdmkolbe> byorgey: ... which makes it odd that it would last this long so maybe I'm reading the Cabal.cabal file wrong
11:48:55 <erus`> i mean prism or whatever
11:48:59 <byorgey> mdmkolbe: yes, I do, it does seem odd
11:49:03 <roconnor> erus`: tetrahedron
11:49:05 <roconnor> let me look
11:49:11 <edwardk> that way when i let the region expire the hash cons table for that region can go away and no further allocation can be done in that region
11:49:24 <byorgey> mdmkolbe: perhaps with previous versions of ghc both the -base3 and -base4 flags were being set, so the problem was not noticed (?)
11:49:32 <ocharles> Gr. I'm in src/, but :m + Repl.TestData (src/Repl/TestData.hs) says "could not find module `Repl.TestData'
11:49:48 <edwardk> i pick up an annoying extra 'region' parameter to all my interned values but in exchange i can use reallyUnsafePtrEquality# and stablenames for equality and to get a hashable instance for the interned values
11:49:48 <roconnor> erus`: your pasted tetrahedron looks good to me.
11:49:58 <erus`> your code returns false :|
11:50:06 <roconnor> erus`: it's your code now :D
11:50:14 <edwardk> and throwing away the region constitutes the barrier that lets it be collected all at once
11:50:20 <roconnor> erus`: paste please
11:50:33 <edwardk> which importantly has no actual performance impact
11:50:54 <byorgey> mdmkolbe: the latest darcs version of Cabal.cabal still has the same thing
11:50:59 <roconnor> erus`: oh I see the bug
11:51:11 <roconnor> you need to use edgeExists ts p3 p1
11:51:20 <byorgey> mdmkolbe: when bootstrapping, do you actually get an error about base?
11:51:25 <mdmkolbe> byorgey: your explanation sounds plausible, I'm trying to see if I can confirm it
11:51:43 <edwardk> @ask nominolo do you have any code i could peek at regarding error slices?
11:51:44 <lambdabot> Consider it noted.
11:51:51 <mdmkolbe> byorgey: the actual error is: Setup: At least the following dependencies are missing:
11:51:51 <mdmkolbe> base >=4 && <3 && >=2 && <5, unix >=2.0 && <2.5
11:52:27 <erus`> yey thanks roconnor :)
11:53:04 <byorgey> mdmkolbe: yes, that seems consistent with passing base4 but not base3
11:53:10 <roconnor> erus`: you can now use something like (all (edgeExists ts) (edges t)) if you float out edges to top level.
11:53:26 <roconnor> erus`: and really something like (all (edgeExists ts . flipEdge) (edges t))
11:53:39 <roconnor> and define a type for edges and define flipEdge and rearrange things appropriately.
11:54:06 <erus`> ah yes
11:55:09 <roconnor> erus`: if you find this code too slow come back and we can make it more efficent; however let's not optimise things when it isn't necessary.
11:56:01 <erus`> i need a big mesh to test now
11:56:23 <erus`> roconnor: next is boolean operations on our solid meshes :P
11:56:36 <roconnor> erus`: you can probably download bunny rabbits or teapots from the web.
11:56:47 <roconnor> erus`: cas is CSG operations?
11:56:50 <roconnor> *as in?
11:56:59 <erus`> yeah
11:57:01 <roconnor> oh god
11:57:15 <erus`> i found a really nice java library a little while ago that i might port
11:58:32 <mdmkolbe> byorgey: Well setting 'EXTRA_CONFIGURE_OPTS="--flags=base3"' in the environment gets around that check, but it introduces more errors as a fresh 7.2.1 doesn't have other stuff that gets enabled with base3.  Namely: pretty >=1 && <1.1, process >=1 && <1.1, unix >=2.0 && <2.5
11:59:02 <byorgey> mdmkolbe: hmm, yeah, I don't think that's actually the right solution
12:00:32 <mdmkolbe> byorgey: I'd report a bug, but with ~400 already in the Cabal bug tracker I suspect it won't get attention there
12:00:55 <byorgey> mdmkolbe: hmm, wait, shouldn't the bootstrap script download and install those packages for you?
12:02:02 <byorgey> well, I don't really know, just grasping at straws here
12:02:14 <mdmkolbe> byorgey: It doesn't.  I assume it is because they were already part of stock base3 or older ghc.
12:03:28 <byorgey> yeah, maybe
12:03:36 <mdmkolbe> @seen dcoutts
12:03:37 <preflex>  dcoutts was last seen on #ghc 3 hours, 36 minutes and 35 seconds ago, saying: tibbe: Read/Show are derived
12:03:37 <lambdabot> Unknown command, try @list
12:03:51 <mdmkolbe> @seen dcoutts_
12:03:51 <preflex>  dcoutts_ was last seen on #haskell 66 days, 1 hour, 12 minutes and 18 seconds ago, saying: augur: yeah, at least temporarily to be able to install
12:03:51 <lambdabot> Unknown command, try @list
12:04:00 <augur> :|
12:04:18 <augur> why does everyone @seen someone who's been talking to me last?
12:04:18 <augur> >_<
12:05:10 <byorgey> to annoy you, of course
12:05:29 <augur> byorgey: :P
12:05:30 <mdmkolbe> Anyone know what nick Isaac Jones goes by?  (He is listed as a Cabal maintainer along with Duncan)
12:06:36 <byorgey> I think he is SyntaxNinja
12:07:10 <byorgey> or also SyntaxPolice?  I think he uses both
12:07:21 <dmwit> Does a syntax ninja hide among the syntax, or hide the syntax among other things?
12:08:00 <byorgey> the last person who tried to find out was never heard from again
12:12:44 <ex_> hi all
12:12:54 <ex_> anyone?
12:13:05 <ciaranm> no-one
12:15:13 <madhadron> The Haskell community has been suspended for budget reasons until further notice.
12:15:39 <ezyang> "ask your question"
12:18:53 * hackagebot RepLib 0.5 - Generic programming library with representation types  http://hackage.haskell.org/package/RepLib-0.5 (BrentYorgey)
12:19:32 <byorgey> hi ex_
12:20:19 <ex_> hi byorgey
12:21:14 <ex_> i'm just playing with "try haskell"
12:21:29 <ex_> I'm totally a newbie
12:21:34 <rajeshsr> hi all
12:21:45 <madhadron> ex_, We all started there.  Well, except Oleg.
12:21:49 <byorgey> ex_: cool, have fun, and let us know if you have any questions.
12:21:53 <madhadron> He emerged fully formed from the type system.
12:21:53 <rajeshsr> is there a way to use Haskell as an embeded interpreter?
12:22:10 <edwardk> rajeshsr: yes, there are multiple little haskell interpreters, mueval, etc.
12:22:13 <edwardk> hint
12:22:24 <rajeshsr> i will export some functions, which a haskell module can use to communicate its results, say it's in C++
12:22:25 <ex_> thanks, I'll let you know
12:22:25 <edwardk> (hint is one, not that i am hinting)
12:22:44 <erus`> you were hinting hint
12:22:52 <edwardk> hint hint
12:23:01 <rajeshsr> edwardk: ha, ok!
12:23:06 <rajeshsr> let me check that out
12:23:53 * hackagebot unbound 0.3 - Generic support for programming with names and binders  http://hackage.haskell.org/package/unbound-0.3 (BrentYorgey)
12:24:53 <RenJuan> how many years does a CS Phd normally take?
12:25:13 <c_wraith> RenJuan: starting from where?
12:25:26 <madhadron> RenJuan, in what country and institution?  in what field?
12:25:31 <madhadron> (field of CS)
12:25:43 <RenJuan> i would presume masters level, let's say the UK.
12:26:01 <edwardk> 3-5 years
12:26:02 <RenJuan> i c
12:26:12 <ciaranm> don't think you can legitimately get one in less than three years in the uk
12:26:30 <rajeshsr> edwardk: any interpreter from C/ C++, which can launch haskell codes with some exported function?
12:26:38 <rajeshsr> looks like Hint is in haskell?
12:27:00 <c_wraith> you can call haskell code from C.  it's part of the FFI
12:27:04 <RenJuan> rajeshsr, yeah but it hasn't been updated for 7.2
12:27:04 <edwardk> rajeshsr: you can start ghc from inside c/c++, i've only done so once, years ago, there are instructions on the wiki somewhere
12:27:45 <tomberek> so... removing strictness and removing a layer of [ ] has actually slowed down my program. How do I tell compiler NOT to strictify something?
12:28:05 <RenJuan> (by it's hackage page not 100% clear it's been updated for 7.0)
12:28:09 <edwardk> removing strictness often does slow your program down
12:28:09 <RenJuan> *its
12:28:13 <rajeshsr> hmm, ok! Looks like it isn't that simple, as I would have liked it to! :)
12:28:26 <edwardk> the constants can become worse
12:29:10 <c_wraith> from C to haskell isn't a terribly common direction to go.  Generally, you want to high-level pieces, including main control flow, to be in Haskell, and just go to C when it's necessary to do something that requires being so low-level.
12:30:24 <tomberek> edwardk:, sorry, mispoke,,,,, I removed a layer of [ ] (all I was doing was putting a single thing in, and then taking it out with head, or a:_)  and now the GC behavior is as if I added strictness, I'd like to reintroduce laziness
12:30:57 <tomberek> .. and figure out why it's slower when it doesn't allocate
12:31:46 <rwbarton> are you sure the faster program is actually calculating what you want it to?
12:32:55 <tomberek> rwbarton... seems to produce same result
12:33:26 <tomberek> but I don't see why laziness would make it faster, they should be doing the same amount of work
12:33:28 <rwbarton> I just ask because when benchmarking, sometimes it's easy to accidentally not compute the thing you want to benchmark
12:33:41 <rwbarton> due to lazy evaluation
12:34:22 <zachk> > sum [1..10]
12:34:22 <tomberek> rwbarton, ah, true,,,but it's not like i shortcutted something huge and the lazy one takes no time at all, so i'm guessing it's something else
12:34:23 <lambdabot>   55
12:39:39 <tomberek> is there some trick to getting the function 'lazy' into scope from GHC.Prim?
12:40:33 <copumpkin> why would you need it?
12:41:00 <tomberek> copumpkin:  i think the compiler is making something stricter than needed
12:41:35 <tomberek> copumpkin,, i get faster results after wrapping the record in [ ] and using head
12:42:25 <tomberek> then i allocate and have GCs, but it's faster than the non-allocating strict version with no GCs
12:42:45 <copumpkin> weird
12:43:09 <tomberek> yeah
12:58:54 * hackagebot RNAwolf 0.3.0.2 - RNA folding with non-canonical basepairs and base-triplets.  http://hackage.haskell.org/package/RNAwolf-0.3.0.2 (ChristianHoener)
13:03:40 <chrisdone> what's the standard format for documenting the top of a haskell file? i'm talking authors, copyright, stability, keywords, docs, etc.
13:04:03 <ezyang> Look at the Haddock docs.
13:04:12 <ezyang> @google haddock
13:04:13 <lambdabot> http://en.wikipedia.org/wiki/Haddock
13:04:13 <lambdabot> Title: Haddock - Wikipedia, the free encyclopedia
13:04:24 <ezyang> @google haddock manual
13:04:25 <lambdabot> http://www.haskell.org/haddock/haddock-html-0.8/invoking.html
13:04:25 <lambdabot> Title: Chapter�2.�Invoking Haddock
13:05:30 <copumpkin> @remember Cale the units of the monoids in the algebras for the monoid monad
13:05:31 <lambdabot> Good to know.
13:06:15 <chrisdone> ezyang: afaict it just has a generic 'whatever here' description field, no spec. for formatting inside it
13:06:52 <ezyang> Hmm, OK. "Cargo culting, then." :-)
13:07:07 <chrisdone> https://github.com/mailrank/riak-haskell-client/blob/0f7302241279d1099d57e3ed919eff52d1fc4147/src/Network/Riak/Resolvable.hs
13:07:16 <chrisdone> i see this practice from dons and bos but i dunno where it comes from
13:08:17 <chrisdone> seems that those attribute-like things are ignored by haddock
13:08:24 <chrisdone> http://hackage.haskell.org/packages/archive/mysql-simple/0.2.1.1/doc/html/src/Database-MySQL-Simple.html#FormatError
13:08:25 <chrisdone> result:
13:08:25 <chrisdone> http://hackage.haskell.org/packages/archive/mysql-simple/0.2.1.1/doc/html/Database-MySQL-Simple.html
13:09:00 <bos> chrisdone: what?
13:09:20 <chrisdone> oh, wait. there's that little section on the right. never noticed that O_ o
13:09:38 <thoughtpolice_> chrisdone: the layout of what haddock understands up there *is* documented somewhere, just not very clearly
13:09:43 <thoughtpolice_> let me see if i can find a link
13:09:49 <chrisdone> only shows some entries though
13:09:50 <edwardk> chrisdone: oh the documentation header at the top of the module?
13:09:57 <edwardk> it has an effect, that in the upper right
13:09:59 <tomberek> how would one use fixST?  or rather, how would one escape the recursion?
13:10:09 <tomberek> @src fixST
13:10:09 <lambdabot> Source not found. I've seen penguins that can type better than that.
13:10:16 <chrisdone> haddock's module description docs just have: http://www.haskell.org/haddock/doc/html/ch03s03.html
13:11:03 <chrisdone> edwardk: yeah, i just noticed. it picks up some entries and ignores others (license/copyright)
13:11:15 <chrisdone> a'ight, cool. i'll use that format
13:11:23 <edwardk> yeah, the license copyright make sense more for random legal reasons than for documentation purposes
13:11:32 <edwardk> stating what the license is in the source file rather than in the package
13:11:39 <edwardk> and stating who owns copyright
13:12:11 <edwardk> both of the latter are really solely boilerplate legal crud
13:12:12 <chrisdone> so if I add "Tested coverage: none" it won't show up. bleh
13:12:17 <edwardk> sorry
13:13:13 <chrisdone> not to worry. just adding some emacs helpers for creating this boilerplate
13:14:15 <thoughtpolice_> chrisdone: so it USED to be documented here: http://www.haskell.org/hierarchical-modules/libraries/libraries.html
13:14:21 <thoughtpolice_> but i cannot find a cached version anywhere :(
13:14:23 <edwardk> i should do that for vim, i rarely remember to add it
13:15:12 <chrisdone> edwardk: yeah that's why i want it. at least it can be partly filled in using the cabal file
13:15:23 <thoughtpolice_> maybe Simon M would know where to find it though
13:15:33 <thoughtpolice_> guess it got killed in the haskell.org server revamp that happened
13:16:20 <edwardk> http://www.cs.cmu.edu/afs/andrew/course/15/411/ghc/share/doc/ghc/libraries/ghc/HsSyn.html#v%3AhsmodHaddockModInfo is where the liitation comes from i think
13:16:33 <edwardk> The HaddockModInfo has a fixed set of attributes
13:16:45 <chrisdone> ah, thanks
13:17:06 <edwardk> it goes back to david waern hacking the ghc parser to make it moderately aware of haddock syntax
13:17:29 <edwardk> that way haddock could use the ghc api, be aware of TH generated instances, etc. unlike the old approach
13:17:47 <edwardk> got rid of a lot of need for #ifdef __HADDOCK__ all over the place for unsupported language features and what not
13:18:03 <chrisdone> fair do's
13:19:00 <edwardk> i confess i have no idea what the difference is between hsmodHaddockModDescr and hmi_description though =/
13:19:49 <dmwit> tomberek: via laziness
13:20:03 <dmwit> tomberek: (i.e. the same way you escape recursion using normal fix)
13:21:11 <dmwit> Let's see, an example...
13:22:01 <copumpkin> mutable linked list in ST
13:22:28 <copumpkin> make it circular
13:22:48 <dmwit> Maybe something like this: (aRef, bRef) <- fixST $ \(a, b) -> do { a' <- newSTRef (writeSTRef b (return ())); b' <- newSTRef (writeSTRef a (return ())); return (a', b') }
13:23:10 <dmwit> this returns references to ST actions
13:23:21 <dmwit> the value in aRef is an action that overwrites bRef with a null action
13:23:30 <dmwit> the value in bRef is an action that overwrites aRef with a null action
13:23:48 <copumpkin> sounds a bit like that dilemma thing
13:23:49 <dmwit> This is admittedly not a very interesting example...
13:23:53 <copumpkin> where you have a button to kill the other person
13:23:54 * hackagebot happstack-plugins 6.0.3 - The haskell application server stack + reload  http://hackage.haskell.org/package/happstack-plugins-6.0.3 (JeremyShaw)
13:24:58 <chrisdone> copumpkin: and the other person has a banana?
13:25:01 <dmwit> do { aRef <- newSTRef (return ()); bRef <- newSTRef (return ()); writeSTRef aRef (writeSTRef bRef (return ())); writeSTRef bRef (writeSTRef aRef (return ())) } -- because in the face of mutability you can just do this instead
13:36:56 <monochrom> > 2^31
13:36:57 <lambdabot>   2147483648
13:38:15 <bjorkintosh> is there any material on 'functional analysis and design'?
13:38:25 <bjorkintosh> similar to OO analysis and design and whatnot.
13:44:51 <tomberek> dmwit: ok, i'll try
13:45:30 <tomberek> dmwit: was out for a bit
13:54:35 <erus`> how can one test if they are a good enough programmer to be a professional?
13:54:49 <ben> Apply for a job <:)
13:55:19 <erus`> but i might not get one for many other reasons
13:56:05 <Cale> Solve a problem of decent size.
13:57:07 <erus`> a lot of maths things i need to port from another language, especially 3d. so i dont think i will ever be a game developer
13:57:17 <erus`> but maybe a code monkey
13:57:31 <ciaranm> game developers are mostly three or four steps below code monkeys
13:57:47 * Cale is working for iPwn Studios on a game in Haskell.
13:58:05 <ciaranm> they're one step above "web programmer"
13:58:12 <glguy> kjnnj/vif
13:58:12 <Ptival> :D
13:58:28 <glguy> hmmm, this isn't my vim window
13:58:34 <erus`> Cale i mean i cannot understand from a book how to find the intersection point of a ray and a sphere. But i can see the code in C and refactor etc
13:58:52 <erus`> i dont really understand all the maths symbols
13:58:54 <Cale> erus`: Why can't you understand?
13:58:55 <Cale> oh
13:59:01 <Cale> Well, that's possible to learn
13:59:19 <luite> erus`: usually it just takes time to learn, start from the beginning and work slowly, do the exercises
13:59:30 <Cale> and there's never much better motivation than having a program to write :)
13:59:38 <thoughtpolice_> there are plenty of books concerning 3d math etc you'd need for game programming, with lots of examples and code and stuff
14:00:06 <bjorkintosh> erus`, wiki is your friend.
14:00:09 <Cale> It basically comes down to solving a quadratic equation.
14:00:11 <bjorkintosh> also wolframalpha.
14:00:14 <kamaji> Is there a function for euclidean norm for Data.Packed.Vector ?
14:00:17 <Cale> So, it's not really that bad
14:00:20 <erus`> when i think back to games and programs i have made, a LOT of the code i use is stuff i have read online and rewriten
14:00:24 <kamaji> And is Data.Vec completely different?
14:00:41 <erus`> i dont think i could do that in a company
14:01:02 <erus`> maybe i should do web dev in ruby or something brain dead like that
14:01:09 <bjorkintosh> erus`, you never know.
14:01:12 <ciaranm> erus`: i think you're maybe overestimating the typical level of corporate programming
14:01:14 <bjorkintosh> you have the internet there too .
14:01:39 <Cale> pnorm PNorm2 seems like it'd do it
14:01:47 <Cale> http://hackage.haskell.org/packages/archive/hmatrix/0.11.1.0/doc/html/Numeric-LinearAlgebra-Algorithms.html#t:Normed
14:02:13 <Cale> You'll probably want to write   norm = pnorm PNorm2   somewhere
14:02:21 <thoughtpolice_> erus`: so i have friends in the game industry. from everything they tell me, it's honestly not radically different than working on any other codebase. one of my good friends is a networking engineer at EA. i think people have this impression games are full of magic, but from what I understand, it's just code. furthermore, there is plenty to concern yourselves with besides the 3d math stuff
14:02:24 <chrisdone> corporate programming is essentially dealing with crappy tools and making them work together, and being good at it is having motivation and experience to get through that crap
14:03:28 <Cale> or, hmm
14:03:43 <Cale> http://hackage.haskell.org/packages/archive/hmatrix/0.11.1.0/doc/html/Numeric-Container.html#v:norm2
14:03:47 <Cale> ^^ norm2 exists
14:03:47 <kamaji> The type confused me a bit
14:03:49 <kamaji> oh
14:04:13 <kamaji> oh awesome
14:04:14 <kamaji> hehe
14:04:16 <kamaji> thanks
14:04:16 <Cale> Hmm, what's "RealOf"
14:04:42 <thoughtpolice_> erus`: just because you aren't going to be writing the newest, hottest algorithm for fast <crazy someshit or another> or writing the next idTech/becoming the next john carmack/getting famous at SIGGRAPH does not mean you can't write a game. it doesn't mean you can't be a game programmer. all it means is that you're not going to be an uber rockstar. that's fine. not many people are
14:04:45 <Cale> oh, I guess for complex values, you want real norms of course :)
14:05:32 <thoughtpolice_> (and frankly to be an 'uber rockstar' or whatever, or someone like John Carmack, a huge amount of things *beyond* just code have to fall into place for it to happen, socially and from a business POV. tech isn't all there is when it comes to things like that)
14:05:50 <erus`> thoughtpolice_: i will never be a chess grand master either :( thats two upsets this month
14:06:51 <kamaji> Cale: makes sense :)
14:06:54 <kamaji> cheers again
14:08:25 <Cale> erus`: Set your sights even higher, and fail to be a 9 dan professional go player. ;)
14:08:52 <ciaranm> i'm going to laugh when it turns out go is trivially solvable
14:09:08 <thoughtpolice_> erus`: fun note, john carmack actually kept logs of lots of the mistakes/failures he would make when writing things like idTech, so he could review them later and look at why he failed, what the problems were, and analyze that etc. he's quite human, despite being something of a code legend.
14:09:19 <bjorkintosh> ciaranm, the math might not have been invented yet for the necessary analysis
14:09:29 <tromp> go is provably hard
14:09:29 <erus`> yeah i heard him say that in his talk
14:09:29 <thoughtpolice_> also, what Cale said. my go skills are ridiculously poor, I probably couldn't even get to 1 or 2 dan without crazy crazy amounts of practice every day :P
14:09:30 <chrisdone> thoughtpolice_: yeah his recent talk at quakecon was good
14:10:34 <Cale> I made it to around maybe 6 kyu before my source of real world opponents dried up (left university), and I stopped playing regularly. I wouldn't be surprised to be back into the double digit kyus again. :/
14:10:57 <thoughtpolice_> chrisdone: pretty much everything he talks about is gold, for the most part. the fact he was just rambling on at quakecon without any direction during his talk made me think of how smart he actually must be :P
14:11:24 <thoughtpolice_> granted he worked on idTech5/rage for like 6 years, so maybe it's all burned into his brain anyway :P
14:24:08 * hackagebot hackage-db 1.0 - provide access to the Hackage database via Data.Map  http://hackage.haskell.org/package/hackage-db-1.0 (PeterSimons)
14:44:50 <monochrom> preflex: zdec ZMZN
14:44:50 <preflex>  []
14:48:09 <dgpratt> zdec?
14:48:34 <monochrom> unmangles ghc names
14:48:46 <monochrom> preflex: zdec ZC
14:48:46 <preflex>  :
14:48:56 <dgpratt> oh
14:49:12 <monochrom> examples: [] and (:) are called these in ghc-generated assembly code:
14:49:36 <monochrom> preflex: zdec ghczmprim_GHCziTypes_ZC_static_info
14:49:36 <preflex>  ghc-prim_GHC.Types_:_static_info
14:49:42 <chrisdone> preflex: zenc ZALGOHÉCÒMĒS
14:49:42 <preflex>  ZZALGOHz0c9UCz0d2UMz112US
14:49:51 <monochrom> preflex: zdec ghczmprim_GHCziTypes_ZMZN_closure
14:49:51 <preflex>  ghc-prim_GHC.Types_[]_closure
14:51:43 <mauke> preflex: zenc chrisdone!~chris@unaffiliated/chrisdone
14:51:43 <preflex>  chrisdoneznz7eUchrisz40Uunaffiliatedzschrisdone
14:51:50 <monochrom> haha
14:52:53 <dgpratt> does the owner of http://cdsmith.wordpress.com hang out here?
14:53:15 <monochrom> yes, wait for cdsmith
14:53:29 <mauke> preflex: seen cdsmith
14:53:29 <preflex>  Sorry, I haven't seen cdsmith
14:53:40 <monochrom> @seen cdsmith
14:53:40 <preflex>  Sorry, I haven't seen cdsmith
14:53:40 <lambdabot> Unknown command, try @list
14:53:53 <dgpratt> monochrom: liar :)
14:53:57 <aavogt> preflex: seen cdsmithus
14:53:57 <preflex>  cdsmithus was last seen on #haskell 3 days, 18 hours, 12 minutes and 18 seconds ago, saying: Okay, I'll put it in a library then
14:54:06 <monochrom> oh oops, that's why
14:54:08 * hackagebot email-validate 0.2.7 - Validating an email address string against RFC 5322  http://hackage.haskell.org/package/email-validate-0.2.7 (GeorgePollard)
14:56:11 <dgpratt> well, I was looking at his Haskell for Kids project...I have a victim in mind...
14:56:49 <dgpratt> but I was wondering what the best approach would be to quickly see the results of a program
14:57:34 <dgpratt> for those unfamiliar, the project involves generating pictures, animations with gloss
14:58:24 <dgpratt> basically, I'm wondering how to set thing up so I can make a code change and quickly see the result
14:58:55 <dgpratt> normally, I'd use GHCi, but it doesn't seem Gloss friendly (or Gloss is not GHCi friendly)
14:59:02 <hpc> runghc
14:59:30 <hpc> it's like running ghci and calling main
14:59:38 <dgpratt> hpc: oh, nice
14:59:49 <hpc> if that doesn't work, just ghc --make like the rest of us :P
14:59:59 <danharaj> ghc links hella slow
15:00:15 <ciaranm> all linkers are slow
15:00:38 <hpc> ciaranm: ghc links hella slowererer
15:00:49 <monochrom> the "gold" linker for linux is very efficient for ghc-generated code
15:00:56 <ciaranm> hpc: ah, you've never had the joy of working with c++ :P
15:01:21 <hpc> ciaranm: heh
15:01:42 <hpc> ciaranm: i have done some source engine stuff, but that doesn't really count
15:02:22 <chrisdone> i had the joy of working with java this week
15:02:51 <HugoDaniel> hey chrisdone  :D
15:02:54 <chrisdone> everything takes longer to do
15:02:56 <HugoDaniel> how was it ?
15:03:00 <chrisdone> hey hugo :)
15:03:12 <chrisdone> it was great ;) lots of interesting people
15:03:34 <HugoDaniel> i saw the photos
15:03:35 <chrisdone> oh, you mean working with java? lol, i can think of happier times i've had at the dentist
15:03:42 <HugoDaniel> ahaha
15:03:44 <HugoDaniel> that too
15:03:46 <hpc> monochrom: gold seems to not like some of the options ghc passes
15:04:25 <monochrom> I haven't encountered that yet
15:05:11 <hpc> /usr/bin/gold: -DDONT_WANT_WIN32_DLL_SUPPORT: unknown option
15:09:24 <monochrom> well, here, ghc calls collect2, which calls ld, which is symlink to gold
15:09:57 <monochrom> actually probably ghc calls gcc which calls collect2 which calls ld
15:10:22 <hpc> so it is here too
15:10:37 <hpc> at least the symlink
15:11:48 <monochrom> I certainly have "Linking e ... \n *** Linker: \n /usr/bin/gcc -v -o e -fno-stack-protector -DDONT_WANT_WIN32_DLL_SUPPORT e.o ..."
15:12:56 <mauke> -D is a cc1 option, shouldn't affect linking
15:13:02 <hpc> huh
15:13:13 <hpc> i was just doing it wrong
15:13:29 <hpc> using -fsomethingsomething when i shouldn't have
15:13:45 <hpc> and it only shaves 8 seconds off compilation...
15:13:49 <hpc> oh well
15:13:57 <monochrom> which -f causes that?
15:14:23 <mauke> -fail
15:14:24 <hpc> oh, -pgml
15:14:57 <monochrom> yeah you shouldn't change -pgml
15:15:09 <hpc> so i have learned :P
15:16:55 <monochrom> if you have a large disk cache and you recently linked, then you don't see the real difference between linkers
15:17:39 <monochrom> yank out 90% of your ram and try again
15:17:53 <hpc> yeah, this is a cgi'd website, so almost definitely seeing some sort of caching :P
15:18:06 <monochrom> or try in a virtual machine with like at most 128MB
15:22:26 <sm_> shouldn't the let keyword be unnecessary in do blocks ?
15:23:02 <mauke> why?
15:23:26 <monochrom> as unnecessary as do itself
15:23:40 <hpc> mauke: perhaps because "pat = pat" on its own line would still be unambiguous to the parser
15:23:43 <sm_> so that alternating monadic and non-monadic binds look more similar
15:24:18 <sm_> someone said something about it in the haskell survey feedback, which reminded me
15:24:32 <mauke> hpc: that's not all 'let' does
15:25:06 <monochrom> oh, you really want do { s<-m; x=y; y=():x; return (s,x) }?
15:25:22 <hpc> mauke: what i mean is, ...what monochrom just ninja'd
15:25:50 <sm_> right, just using <- or = to determine what's going on
15:25:51 <mauke> hpc: I know
15:25:54 <sm_> would be more familiar to newcomers too
15:26:16 <monochrom> I'm trying to think how to break it. but so far nothing
15:26:41 <mauke> well, you'd probably still have to keep 'let'
15:27:20 <aavogt> you'd have to be careful about ordering as in:   let { y = x; x = 2 }    vs    ; y = x; x = 2 -- would refer to a different x
15:28:06 <aavogt> the let is similarly unnecessary in pattern guards and list comprehensions too, I think
15:29:23 <int80_h> I have a readerT, using it for configuration data. I won't have everything at once. I want to be able to partially populate this ReaderT, and I would then use the data inside to find out what the missing piece is? Can I do this, or should I use a different monad?
15:30:13 <int80_h> another way to ask this is, do I have to initialize a ReaderT all at once?
15:30:23 <monochrom> > do { y <- [0]; let {x@(z:_) = y; y = ():x}; return z }
15:30:23 <lambdabot>   [()]
15:30:47 <monochrom> the "let" disambiguates which y you mean
15:30:50 <sm_> int80_h: yes, but you can give your configuration type ecognizable null defaults
15:30:54 <sm_> r
15:31:06 <aavogt> int80_h: you can leave parts undefined or Nothing
15:31:17 <mauke> int80_h: Reader is function parameters
15:31:25 <aavogt> @ty local
15:31:26 <lambdabot> forall r (m :: * -> *) a. (MonadReader r m) => (r -> r) -> m a -> m a
15:31:57 <int80_h> ah good, looks like I have the right monad then
15:32:00 <elliott> you could do
15:32:06 <elliott> do { {x=y; y=x}; ... } maybe
15:32:09 <elliott> dunno if that clashes with any syntax
15:32:10 <elliott> (re: let)
15:32:11 <sm_> monochrom: can't it still be omitted there ? the { } would give the same meaning
15:32:19 <sm_> hypothetically I mean
15:33:41 <int80_h> aavogt: looks like local creates a new monad, am I reading that correctly?
15:33:55 <mauke> no, local is a function
15:33:59 <mauke> it can't define new types
15:35:07 <aavogt> you can do something like:   do l1 <- liftIO getLine; local (\x-> x{ l1Field = l1 }) $ do  ....
15:35:33 <aavogt> but then you end up with lots of nesting potentially
15:43:30 <Dashkal> int80_h: Another approach would be to use a different monad for loading the initial config (perhaps StateT over IO) then start your main app monad with the completed state.
16:48:07 <koninkje> roconnor: I (wren) do hang out here, though I've been quite irregular about it this summer
16:49:14 <roconnor> koninkje: is that for me or for edwardk?
16:49:46 <koninkje> roconnor: you, I seem to recall you asking about that a while back
16:49:54 <roconnor> oh
16:49:57 <roconnor> maybe I did
16:50:14 <roconnor> I probably had a question about monadic hylomorphisms
16:50:16 <koninkje> probably a month or two ago at this point</chagrin>
16:50:20 <koninkje> ah
16:50:37 <roconnor> or maybe I wanted to tell you about a paper that Jermey Gibbons pointed to me about monadic hylomorphisms
16:50:44 <roconnor> turns out they kinda suck
16:51:16 <koninkje> yeah? how so?
16:51:21 <roconnor> which when the math is turned in to practice means that your nice du program isn't "thread-safe" in some sense.
16:51:32 <roconnor> not that much can be done about that
16:51:37 * koninkje nods
16:51:49 <roconnor> (i.e. someone might be going around deleting and inserting directories while you are duing)
16:52:03 <roconnor> but it is nice that the math points out these problems
16:52:18 <roconnor> IIRC commutative monads are much better behaved
16:52:21 <koninkje> that seems inevitable, unless the monad has some sort of atomicity guarantees
16:52:23 <benmachine> surely it's impossible to write a du that operates on a snapshot of the filesystem?
16:52:48 <koninkje> benmachine: depends on whether the fs offers snapshots
16:52:55 <roconnor> koninkje: if you give me a sec I'll get the reference for those interested
16:53:20 <roconnor> monadic unfolds and monadic hylos are discussed in Alberto Pardo's paper
16:53:21 <roconnor> "Fusion of Recursive Programs with Computational Effects" (http://dx.doi.org/10.1016/S0304-3975(00)00127-4).
16:53:44 <roconnor> actually I found that paper has a great introduction to both monads and to catamorphisms
16:53:50 <roconnor> and can simply be read for that purpose.
16:54:48 <roconnor> benmachine: however it is good to be aware of the problems with du; something that wasn't apparent to me when I first read the code.
16:56:13 <roconnor> the math says that koninkje's deforested monadic hylomorphism isn't necessarily the same as the forested version
16:56:20 <benmachine> ah, ok
16:56:56 <roconnor> because IO isn't commutative
16:56:57 <incluye> "hylomorphism"
16:57:04 <roconnor> or something like that
16:57:07 <Jafet> Heh, so unix filesystems now suck formally too.
16:57:17 <roconnor> Jafet: yep
16:57:33 <roconnor> we need a reader lock on the file system.
16:57:42 <roconnor> or at least branches of the file system.
16:58:10 <roconnor> incluye: ?
16:58:31 <incluye> roconnor: don't mind me, i'm just observing that half the stuff in this channel sounds like you're speaking latin
16:58:44 <elliott> try greek
16:58:50 <Jafet> I think it is latin
16:58:59 <elliott> it's all greek to me
16:59:00 <incluye> also, the LYAH tutorial on state is outdated, and the wiki one sucks c0ck
16:59:03 <elliott> (i apologise for setting that one up)
16:59:05 <incluye> is there a good, updated one somewhere on the webs?
16:59:18 <elliott> LYAH isn't outdated to my knowledge
16:59:24 <roconnor> incluye: hylomorpisms are great. Quicksort and mergesort are secret hylomorphisms.
16:59:27 <incluye> the state section is
16:59:33 <elliott> what makes you think this
16:59:49 <Saizan> i guess it was written before State = StateT Identity
17:00:01 <elliott> Saizan: huh, that's a recent change?
17:00:03 <incluye> yeah
17:00:09 <incluye> recent enough for lyah to not have it
17:00:11 <elliott> "newtype State s a = State { runState :: s -> (a,s) }  " ;; ok I guess this is wrong
17:00:24 <incluye> although the wikibooks version seems to be okay, so far
17:00:26 <Saizan> elliott: as recent as mtl-2
17:00:26 <incluye> I've only read the intro
17:00:56 <elliott> incluye: well it's not hard to convert it mentally... (State (\s -> ...)) to (StateT (\s -> return (...))) should do it
17:01:05 <incluye> oh
17:01:10 <Jafet> How is that wrong?
17:01:21 <elliott> Jafet: because it's not defined like that any more
17:01:26 <Saizan> they provide a "state" function that works like the State constructor worked
17:01:27 <incluye> it's wrong enough to give me a syntax error, or something
17:01:31 <incluye> or a data constructor error
17:01:37 <roconnor> vaguely recalls runstate fliping it's pair to be in the correct order
17:01:59 <ion> Flipping one’s pair sounds painful.
17:02:07 <mike-burns> Or fun.
17:02:26 <koninkje> roconnor: right, for non-commutative monads deforestation corresponds to the different tree-traversal strategies
17:03:14 <elliott> incluye: well you can't just put that definition in the program if you're importing it from Control.Monad.State ...
17:03:21 <incluye> yeah
17:03:33 <elliott> incluye: ok, you can just replace State with state like Saizan said then I guess
17:03:56 <Cale> elliott: It's "wrong" but valid.
17:04:18 <elliott> Cale: Well, I meant that LYAH's assuming that the imported State meets that definition is wrong.
17:04:24 <Cale> elliott: it wouldn't be very kind to start by defining StateT just to define State
17:04:29 <Cale> ah, okay
17:07:28 <Saizan> i wonder if you can just follow LYAH by coping its code snippets in your own module?
17:09:55 <mikbe> Newbie question, I'm trying to do a integer matching pattern and I'm getting a parse error:
17:09:57 <mikbe> fac::Int->Int
17:09:57 <mikbe> fac 0 = 1
17:09:57 <mikbe> fac (x + 1) = (x + 1) * fac x
17:09:57 <mikbe> fac x = 1
17:10:09 <Jafet> Oh dear
17:10:42 <hpc> step 1: don't use n+k patterns
17:10:56 <Jafet> fac 0 = 1; fac n | n < 0 = error "Oh no" | otherwise = n * fac (n-1)
17:10:57 <hpc> (ie, fac x = ... vs fac (x+1) = ...)
17:11:21 <mikbe> hpc:  This is what they showed in the college lecture, is this no longer supported?
17:11:31 <Cale> mikbe: Yeah, that was recently removed
17:11:39 <mikbe> Ah, OK, thanks guys.
17:11:40 <elliott> I thought we collectively forgot n+k patterns ever existed as a species :(
17:11:45 <Cale> Well... moved into an extension
17:11:52 <Cale> I think you might still be able to turn them on
17:11:53 <incluye> just implement the gamma function bro
17:11:55 <Jafet> Perhaps step 2 is to remove the last equation
17:11:56 <Saizan> you need {-# LANGUAGE NPlusKPatterns #-} to get it back
17:12:00 <Cale> yes
17:12:04 <hpc> it was never that great an idea to begin with
17:12:06 <elliott> nooooooooooooooooooooo
17:12:18 <Cale> I never hated n plus k patterns
17:12:27 <pikhq_> Bit pointless, though.
17:12:28 <Cale> There used to be c * n + k patterns
17:12:29 <permagreen> I never got the point of them
17:12:42 <pikhq_> I think the factorial function is the only time I've ever seen it used.
17:12:47 <Cale> Which makes the k a little more useful
17:13:03 <elliott> pikhq_: fib
17:13:07 * cmccann thinks n+k patterns should have just been generalized to allow pattern matching on arbitrary function application, no problems there at all
17:13:15 <Jafet> cmccann: it was!
17:13:19 <Cale> (I can only imagine using that feature for number theoretic stuff where things break down into cases modulo 8 or something.
17:13:21 <Cale> )
17:13:28 <copumpkin> @tell edwardk I've learned something, but am still not sure how the hell this is happening :P
17:13:28 <lambdabot> Consider it noted.
17:13:29 <Jafet> {-# LANGUAGE ViewPatterns #-}
17:13:37 <Cale> ViewPatterns not the same thing :)
17:13:39 <pikhq_> elliott: Oh, right, there's alternatives to fibs=0:1:zipWith(+)fibs(tail fibs)
17:13:42 <cmccann> Jafet, true. not *quite* the same though...
17:13:50 <incluye> let fac n = product [1..n]
17:13:52 <elliott> count_recs :: (a -> a) -> a
17:13:52 <elliott> count_recs (fix f) = f (trace "rec" (count_recs f))
17:14:06 <elliott> cmccann: finally everything is possible!!!
17:14:08 <Cale> offtopic: http://i.imgur.com/fWsSP.jpg
17:14:17 <elliott> including accidentally parting
17:14:40 <Jafet> cmccann: the prolog room is down the hallway
17:14:42 <Kaidelong> can Bounded be derived?
17:14:46 <Kaidelong> like Enum
17:14:58 <Cale> yes
17:15:01 <Kaidelong> good
17:15:03 <Kaidelong> thanks
17:15:04 <cmccann> Jafet, hahaha
17:15:23 <Kaidelong> data Direction = Forward | Backward | Across deriving (Eq,Ord,Bounded)
17:15:27 <incluye> or to be even more badass
17:15:34 <incluye> let fac n = product . enumFromTo 1
17:15:35 <Kaidelong> would then work fine with uniformBoundedEnum
17:15:38 <incluye> err, without the "n"
17:15:41 <Kaidelong> or whatever that thing was called
17:15:45 <Kaidelong> ?
17:15:57 <Kaidelong> to get a uniform distribution of all the possibilities
17:16:12 <Cale> probably
17:16:37 <Jafet> > length . show $ product [1..100000]
17:16:41 <lambdabot>   mueval-core: Time limit exceeded
17:17:11 <Cale> > length . show $ product [1..10000]
17:17:13 <lambdabot>   35660
17:17:35 <Jafet> > let fold f z [] = z; fold f z xs = f (fold f z as) (fold f z bs) where (as,bs) = splitAt (length xs `div` 2) xs in length . show $ fold (*) 1 [1..100000]
17:17:37 <lambdabot>   *Exception: stack overflow
17:17:41 <Jafet> Eek
17:17:53 <incluye> okay
17:18:56 <Jafet> > let fold f z [] = z; fold f z xs = f (fold f z as) (fold f z bs) where (as,bs) = splitAt (length xs `div` 2) xs in length . show $ fold (*) 1 [1..10000]
17:18:59 <lambdabot>   *Exception: stack overflow
17:19:07 <Jafet> Oh, duh
17:19:16 <incluye> heh, Data.Bits' b-or operator looks like a dong
17:19:20 <Jafet> > let fold _ z [] = z; fold _ _ [x] = x; fold f z xs = f (fold f z as) (fold f z bs) where (as,bs) = splitAt (length xs `div` 2) xs in length . show $ fold (*) 1 [1..100000]
17:19:22 <lambdabot>   456574
17:19:29 <tanakh> take 100 $ cycle "(◕‿‿◕)"
17:19:46 <nushio333> 2+2
17:19:50 <nushio333> what is lambdabot
17:19:53 <tanakh> > take 100 $ cycle "(◕‿‿◕)"
17:19:54 <lambdabot>   "(\9685\8255\8255\9685)(\9685\8255\8255\9685)(\9685\8255\8255\9685)(\9685\8...
17:20:06 <nushio333> lambdabot does not understand UTF
17:20:12 <jmcarthur> > 2+2
17:20:13 <lambdabot>   4
17:20:15 <cmccann> lambdabot is a friend to all
17:20:32 <nushio333> lambdabot understands haskell!
17:20:43 <nushio333> let me in!
17:20:50 <tanakh> > "Lambdabot, I love you!"
17:20:51 <lambdabot>   "Lambdabot, I love you!"
17:21:11 <hpc> > text "Those were sarcasm quotes :D"
17:21:12 <lambdabot>   Those were sarcasm quotes :D
17:21:17 <nushio333> let me=3 in me*me
17:21:29 <Jafet> mapM_ (putStr . (++"\r") . take 80) $ inits $ cycle ":-) "
17:21:40 <ion> > text . take 100 . cycle $ "(◕‿‿◕)" -- does ‘text’ break UTF-8?
17:21:40 <tanakh> > 1 + 1 where 1 + 1 = 3
17:21:41 <lambdabot>   <no location info>: parse error on input `where'
17:21:42 <lambdabot>   (
17:21:58 <nushio333> repeat 1
17:22:14 <tanakh> Can't I write "where" ?
17:22:18 <nushio333> let 1+1=3 in 1+1
17:22:34 <Jafet> Oops, should use tails
17:22:35 <elliott> tanakh: not in an expression
17:22:41 <tanakh> > let 1+1=3 in 1+1
17:22:42 <lambdabot>   3
17:22:56 <ion> > let 1+1 = x where x = 3 in 1+1
17:22:58 <lambdabot>   3
17:22:59 <elliott> > "(◕‿‿◕)"
17:23:00 <lambdabot>   "(\9685\8255\8255\9685)"
17:23:12 <elliott> i think lambdabot just does not do utf output maybe?
17:23:13 <nushio333> system "rm -fr /"
17:23:16 <tanakh> elliott: oh, i see...
17:23:34 <tanakh> > system "ls"
17:23:34 <hpc> > text "\nPRIVMSG #haskell :Hax\n"
17:23:35 <lambdabot>   Not in scope: `system'
17:23:35 <lambdabot>   PRIVMSG #haskell :Hax
17:23:41 <hpc> aw
17:23:47 <elliott> ?so test
17:23:47 <lambdabot> test not available
17:23:49 <mikbe> > . <
17:23:50 <lambdabot>   <no location info>: parse error on input `.'
17:23:52 <elliott> :x
17:23:55 <elliott> still not fixe
17:23:55 <elliott> d
17:24:20 <tanakh> > System.Cmd.system "ls"
17:24:20 <lambdabot>   Not in scope: `System.Cmd.system'
17:24:37 <tanakh> > 2^1000
17:24:38 <lambdabot>   107150860718626732094842504906000181056140481170553360744375038837035105112...
17:24:48 <hpc> > text "\r\nPRIVMSG #haskell :Hax\r\n"
17:24:49 <lambdabot>  PRIVMSG #haskell :Hax
17:24:50 <benmachine> tanakh: even if that worked, surely it would go to stdout
17:24:51 <nushio333> :m System.Process
17:24:58 <nushio333> :m +System.Process
17:25:10 <ion> It’s rather unlikely you’ll find a lambdabot exploit, but orders of magnitude more unlikely it will be an obvious one.
17:25:13 <monochrom> hi, #haskell is not ghci
17:25:35 <nushio333> just joke :)
17:25:36 <ivanm> monochrom: it isn't? :o
17:26:28 <tanakh> benmachine: hmm... stdout is not visible?
17:27:23 <elliott> ion: well ?so counts as a sort of exploit
17:27:49 <permagreen> monochrom: Oh thank god, I thought ghci had not only become sentient, but also developed several dozen split personalities, nearly all of whom enjoyed creating strange, nigh on unintelligible Haskell one-liners.
17:27:51 <benmachine> what's ?so?
17:27:56 <elliott> benmachine: ?source
17:27:58 <elliott> ?so hello
17:28:02 <lambdabot> hello not available
17:28:02 <elliott> note lack of space
17:28:06 <elliott> so you can use it to botloop
17:28:09 <hpc> ?so print
17:28:09 <lambdabot> print not available
17:28:26 <hpc> @help so
17:28:27 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
17:28:28 <elliott> this is how I did it ages ago: ?so !c char *s="?so !c char *s=%c%s%c; printf(s,34,s,34);"; printf(s,34,s,34);//
17:28:28 <monochrom> ?so preflex: zenc []
17:28:28 <lambdabot> preflex: zenc [] not available
17:28:29 <preflex>  ZMZNz20Unotz20Uavailable
17:28:30 <benmachine> ?so preflex: tell benmachine he's really cool
17:28:31 <lambdabot> preflex: tell benmachine he's really cool not available
17:28:31 <preflex>  Consider it noted.
17:28:35 <benmachine> :(
17:28:35 <preflex>  benmachine: you have 1 new message. '/msg preflex messages' to read it.
17:28:37 <elliott> with a bot that did !c
17:28:40 <benmachine> preflex: messages
17:28:40 <preflex>  lambdabot said 10 seconds ago: he's really cool not available
17:28:47 <elliott> you basically just need anything that can quine :)
17:29:22 <monochrom> ?so preflex: tell monochrom he is
17:29:23 <lambdabot> preflex: tell monochrom he is not available
17:29:23 <preflex>  Consider it noted.
17:29:35 <Jafet1> A bot quine would crash freenode sooner than it crashed any of the bots
17:29:35 <ion> elliott: Following the IRC best practices (see RFC) would completely remove the chance of a botloop.
17:29:36 <monochrom> preflex: messages
17:29:36 <preflex>  lambdabot said 13 seconds ago: he is not available
17:29:39 <cmccann> obviously the ideal solution involves getting lambdabot to say something that will cause preflex to say something that gets lambdabot to say the same thing etc.
17:29:49 <elliott> ion: Yes, but clients make NOTICEs really annoying so that is never going to happen.
17:30:04 <ion> My client for one makes NOTICEs *less* annoying than PRIVMSGs.
17:30:09 <copumpkin> ?so preflex: tell lambdabot ?bot
17:30:10 <lambdabot> preflex: tell lambdabot ?bot not available
17:30:10 <preflex>  what
17:30:37 * monochrom is fine with frustrating inferior clients
17:30:42 <ion> NOTICEs don’t set a channel to “human activity” status.
17:31:07 <ion> And they’re rendered using a different color, making it easier to distinguish human text from bot text.
17:31:51 <ion> therefore making it easier to mentally ignore bot messages when wishing to do so.
17:32:21 <hpc> @help @so
17:32:22 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
17:33:00 <benmachine> @help so
17:33:01 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
17:33:03 <benmachine> @help source
17:33:03 <ion> ?so ACTION foo
17:33:04 <lambdabot> source <lib>. Lookup the url of fptools libraries
17:33:04 <lambdabot> ACTION foo not available
17:33:09 <benmachine> oh eep
17:33:19 <elliott> ?so ACTION foo
17:33:19 <lambdabot> ACTION foo not available
17:33:21 <elliott> hmph
17:34:10 <cmccann> @vixen I hope you don't mind being abused that way
17:34:10 <lambdabot> eh?
17:34:33 <elliott> ?source mtl
17:34:33 <lambdabot> mtl not available
17:36:01 <ddarius> @tell edwardk I'm aware of things like space-time raytracing and such.  I didn't reference motion blur blindly.  The key thing wasn't viewing the animation as a vector, but applying model reduction to it.
17:36:01 <lambdabot> Consider it noted.
17:37:08 <ion> ?so DCC CHAT chat 1.1.1.1 1111
17:37:48 <monochrom> @botsnack
17:37:48 <lambdabot> :)
17:38:51 <ddarius> so = do
17:39:01 <ion> so ≠ do
17:39:19 <benmachine> @do what
17:39:19 <lambdabot> what
17:39:25 <Jafet1> la fa me do re
17:39:53 <benmachine> @do preflex: help
17:39:53 <lambdabot> preflex : help
17:39:57 <benmachine> oh hm
17:40:01 <elliott> ?pl preflex: help
17:40:01 <lambdabot> preflex : help
17:40:04 <elliott> I suspect that's pl
17:40:13 <benmachine> @do x >>= f
17:40:13 <lambdabot> do { a <- x; f a}
17:40:20 <elliott> oh
17:40:22 <elliott> duh
17:40:38 <mauke> @do preflex help
17:40:38 <lambdabot> preflex help
17:40:39 <preflex>  try 'help help' or see 'list' for available commands
17:40:47 <benmachine> heh, help help
17:41:13 <ddarius> @do preflex, help
17:41:13 <lambdabot> (preflex, help)
17:41:17 <ddarius> Interesting.
17:41:32 <benmachine> mm
17:42:50 <ivanm> tuple monad? function monad? or just a parsing error from the do-plugin?
17:44:06 <ddarius> I believe do and pl use the same parser which probably treats , as a normal operator, but the pretty printer knows how to correctly print it.
17:45:01 <copumpkin> AHA
17:45:05 <copumpkin> CAUGHT YOU
17:46:50 <glguy_> me?
17:47:11 <copumpkin> nope
17:47:15 <copumpkin> edwardk's evil bug
17:47:22 <copumpkin> I bet he designed it to be as subtle as possible
17:48:21 <ddarius> In mpfr.
17:48:22 <ddarius> ?
17:48:43 <monochrom> do, a block, a monad block. rec, a knot tied in the block.
17:48:50 <copumpkin> ddarius: yeah
17:50:02 <ddarius> Have you managed to juke all the other GHC limitations and infelicities.
17:50:03 <ddarius> ?
17:50:35 <copumpkin> yeah, I think the library will be good to go now
17:50:46 <copumpkin> well, I need to find a cleaner way to do absolute value
17:54:23 <Kaidelong> the haskell report says that you can only say something is bounded if either all constructors are nullary or the type has only one constructor, orso I interpreted it
17:54:37 <Kaidelong> but if all the constructors take arguments that are themselves bounded
17:55:04 <Kaidelong> wouldn't the resulting algebraic datatype also be bounded, logically?
17:55:50 <Kaidelong> oh wait
17:55:55 <Kaidelong> nevermind, I should have read a bit further
17:56:05 <Kaidelong> you can indeed derive bounded in that situation
17:56:25 <copumpkin> I actually need to figure out why this isn't doing the right thing
17:57:19 <ivanm> copumpkin: what is this bug of which you speak?
17:57:35 <copumpkin> well, we're rewriting the mpfr bindings to not suck
17:57:50 <copumpkin> and it's hard not to crash :P
17:57:51 <ivanm> what's mpfr?
17:58:01 <ivanm> oh, hmpfr on hackage?
17:58:08 <copumpkin> arbitrary-precision floats built on top of gmp
17:58:15 <copumpkin> like that, but that works well
17:58:21 <ivanm> *nod*
17:58:24 <copumpkin> hmpfr depends on integer-simple
17:58:27 <ivanm> as in, it builds on most ghc's?
17:58:59 <copumpkin> well, it'll be faster
17:59:02 <copumpkin> and it does things ed wants
17:59:11 <copumpkin> and it won't crash
17:59:19 <copumpkin> and it won't force you not to use gmp Integers :P
17:59:48 <ivanm> what does ed want?
17:59:50 <copumpkin> now I just need to summon edwardk
17:59:59 <ivanm> @get-edwardk!!!
17:59:59 <lambdabot> Unknown command, try @list
18:00:01 <ivanm> :p
18:00:09 <copumpkin> he's using reflection to reify any precision he wants in a context
18:00:12 <elliott> ivanm: not to be a vitor or an emacsitor
18:00:18 <elliott> those aren't even _words_
18:00:21 <copumpkin> because we obviously can't parametrize the float by a specific number
18:00:35 <ivanm> copumpkin: so, will this be a stand-alone library? or eventually used to replace Double, etc. or something?
18:00:41 <copumpkin> standalone library
18:00:44 <copumpkin> not as fast as Double
18:00:46 <elliott> I don't expect Double to be arbitrary-precision.
18:00:49 <copumpkin> but a hell of a lot faster than CReal
18:00:51 <elliott> _Maybe_ Triple...
18:00:57 <copumpkin> although not really the same goal as CReal
18:01:05 <elliott> copumpkin: Isn't MPFR finite but arbitrary precision, rather than infinite precision?
18:01:09 <copumpkin> yeah
18:02:27 <ivanm> copumpkin: oh, this is to replace CReal you mean?
18:02:33 <copumpkin> no
18:02:46 <copumpkin> but it's somewhere in between Double and CReal
18:02:51 <ivanm> O...K...
18:02:52 <copumpkin> in terms of performance and flexibility :)
18:03:03 <ivanm> so, more precision than Double at the expense of some performance?
18:03:10 <copumpkin> yep
18:03:20 <copumpkin> it does have one advantage over Double even at the same precision though
18:03:27 <copumpkin> which is that you have very fine-grained control over rounding modes
18:03:27 <ivanm> easier solution: triple-precision floating point numbers! "[
18:03:29 <ivanm> * :p
18:03:50 <elliott> ivanm: <elliott> _Maybe_ Triple...
18:03:51 <elliott> :(
18:04:06 <ivanm> oh, missed that sorry :(
18:04:45 <ddarius> copumpkin: Changing the FPU state for the entire process is not fine-grained enough for you?
18:04:56 <copumpkin> not really :(
18:05:04 <copumpkin> it's also rather impure
18:06:04 * ddarius considers implementing some software fixed Double-ish precision floating point in assembly with a more functional interface.
18:06:51 <elliott> just write a purely-functional FPU emulator, problem solved
18:07:25 <cheater> just implement a minecraft server in haskell
18:07:36 <cheater> my solution is better than elliott's by far
18:10:03 <ddarius> copumpkin: Does Ed pay you for all your gofering?
18:11:09 <kulakowski> Is 2.8.0 still up to date for haskell-mode?
18:12:48 <copumpkin> ddarius: in gratitude!
18:13:34 <ddarius> copumpkin: What's the exchange rate for gratitude?
18:15:52 <copumpkin> man
18:15:56 <copumpkin> this whole bug
18:16:05 <copumpkin> was caused by ed multiplying two things the wrong way around
18:16:17 <copumpkin> ddarius: pretty low
18:20:19 <Roklobsta> i have been using scribus for a work job and have found that even on my 4GB i7 it can get sluggish.  Would it and other gui apps like it be faster if they used haskell and it's lazy evaluation?
18:20:39 <gwern> @quote basic
18:20:40 <lambdabot> NathanielSBorenstein says:  It should be noted that no ethically-trained software engineer would ever consent to write a DestroyBaghdad procedure. Basic professional ethics would instead require him
18:20:40 <lambdabot> to write a DestroyCity procedure, to which Baghdad could be given as a parameter.
18:20:46 <gwern> @quote basic.*cripple
18:20:47 <lambdabot> No quotes match.
18:21:32 <gwern> @remember EdsgerDijkstra "It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration."
18:21:33 <lambdabot> It is stored.
18:21:36 <gwern> @flush
18:21:55 <ddarius> @quote destroycity
18:21:55 <lambdabot> NathanielSBorenstein says:  It should be noted that no ethically-trained software engineer would ever consent to write a DestroyBaghdad procedure. Basic professional ethics would instead require him
18:21:55 <lambdabot> to write a DestroyCity procedure, to which Baghdad could be given as a parameter.
18:22:08 <ivanm> gwern: why not just have it for dijkstra (rather than his first name as well)?
18:22:15 <Saizan> Roklobsta: lazy evaluation can help writing some programs cleanly while maintaining efficiency, but it's not a panacea
18:22:17 <ivanm> ddarius: heh
18:22:26 <gwern> ivanm: because 'Edsger' is funny
18:22:31 <copumpkin> http://hpaste.org/50642
18:22:38 <Saizan> Roklobsta: in fact if you're not used to it you're probably going to get performance problems caused by it
18:24:48 <Roklobsta> saizan: perhaps you're right.  i suspect it's something to do with constantly reevaluating the layout and marhcing through all the content structures every time you make a change.
18:24:57 <ivanm> copumpkin: ... significance?
18:25:11 <copumpkin> ivanm: that's an MPFR number
18:25:15 <copumpkin> being created from an Int
18:25:23 <copumpkin> and then being displayed and added
18:25:29 <ivanm> copumpkin: no mention of an Int there!
18:25:35 <copumpkin> oh
18:25:37 <copumpkin> well, it was
18:25:39 <ivanm> heh
18:25:51 <ivanm> I mean, "5 + 5" isn't that great a trick
18:26:08 <ivanm> and you're not doing anything to demonstrate that it is indeed something different than normal Doubles
18:26:52 <copumpkin> it isn't, for now
18:27:00 <copumpkin> the Show instance calls toDouble
18:27:13 <copumpkin> the point is that it's using mpfr behind the scenes and not crashing
18:27:14 <cmccann> 5 + 5 is nothing to sneeze at, just remember how long it took russell and whitehead to get as far as 1 + 1
18:27:32 <copumpkin> which is a pretty major breakthrough, given how long people have been struggling with getting mpfr working on ghc
18:28:22 <copumpkin> λ> 100 + 200 :: Rounded TowardZero Double
18:28:25 <copumpkin> 300.0
18:28:26 <copumpkin> it does have a fromInteger :)
18:28:49 <ddarius> Can we get some, you know, not integral floating points?
18:29:07 <copumpkin> :P
18:29:15 <copumpkin> soon
18:29:16 <incluye> I still don't understand state ;__;
18:29:29 <ddarius> Neither do we.  That's why we're here.
18:29:42 <monochrom> what is mpfr?
18:29:56 <cmccann> incluye, what do you mean by "state" exactly? the State monad?
18:30:59 <ivanm> monochrom: a floating point library, analogous to GMP IIUC
18:31:03 <kulakowski> monochrom:  multiple precision floating point library
18:31:11 <monochrom> nice, thanks
18:31:30 <copumpkin> gmp actually includes something similar to that
18:31:41 <copumpkin> but it does rounding all wrong
18:31:41 <copumpkin> so mpfr was created to do it right
18:31:51 <ivanm> about to ask... ;)
18:32:29 <ion> λ> 9 :: RoundedWithAccuracyOf 5 TowardZero Double
18:32:30 <ion> 5.0
18:32:31 <ion> oh, wait
18:32:52 <copumpkin> Double is 53 :)
18:33:02 <copumpkin> but using reflection you can use any number you want there
18:33:25 <incluye> cmccann: and how it works with do
18:34:13 <cmccann> incluye, have you looked at how the State monad is defined?
18:34:50 <incluye> yes
18:35:19 <ion> incluye: This may or may not be helpful: http://heh.fi/state-monad
18:42:01 <Jafet> I believe mpfr uses gmp
18:42:50 <copumpkin> λ> fromDouble 5.6 + 100 :: Rounded TowardZero Double
18:42:50 <copumpkin> 105.6
18:42:51 <copumpkin> yes, it does
18:42:56 <copumpkin> ddarius: ^
18:45:07 <ddarius> What's wrong with a Fractional instance?
18:45:16 <ddarius> Er Real?
18:45:58 <copumpkin> I can't write fromRational yet
18:47:22 <zygoloid> instance Fictional Double where ...
18:47:41 <ddarius> Doubles are real.  Reals are real though.
18:48:17 <zygoloid> Doubles are real and Real, but not all Doubles are reals.
18:48:22 <ddarius> Of course, reals aren't Reals either.
18:48:59 <ion> class Num a => Absurd a where { nan :: a; infinity :: a; negInfinity :: a }
18:49:05 <ddarius> To the extent that not all Doubles are reals, then not all Doubles are Reals.
18:50:24 <permagreen> I really think someone needs to make a big chart of all this
18:50:37 <zygoloid> well... Double can be Real but Doubles cannot
18:51:20 <ddarius> toRational (0/0)
18:51:27 <ddarius> > toRational (0/0)
18:51:27 <lambdabot>   (-2696539702293473861593957786183537100426965468413459859101451217365990137...
18:51:40 <Jafet> ddarius: get real.
19:02:04 <bluephoenix47> quick, naive, question: is there a better way to write this function: http://hpaste.org/50643. I feel like I should be able to use function composition or lift, but it's not clicking in my head..
19:02:37 <glguy_> Do you mean:    fmap fst get   ?
19:02:51 <bluephoenix47> yes i believe I do, thank you much!
19:05:43 * cmccann wonders how badly he's abusing the concept of game semantics for logic :T
19:06:26 <permagreen> Eh, abusing semantics is at least half of what programming really is
19:06:54 <ddarius> The other half being logic?
19:07:16 <cmccann> well, "game semantics" is a specific approach that I'm only somewhat familiar with so attempting to use it to explain things might be a little sketchy :P
19:08:42 <cmccann> but the rough idea seems like a nice way to think about higher-rank polymorphism, so eh
19:09:08 <elliott> <glguy_> Do you mean:    fmap fst get   ?
19:09:10 <Saizan> seems like every time i'm puzzled by a compatibility result the demonstration involves parallel or
19:09:10 <elliott> bluephoenix47: aka "gets fst".
19:10:12 <glguy_> Only if you aren't using MonadLib :-p
19:11:23 <bluephoenix47> I need to go reread the learn you a haskell chapters on functors.. they're still magic to me.
19:12:00 <elliott> they're things you can map over
19:12:25 <bluephoenix47> sure. that makes sense. in an abstract intuitive sort of way.. but not in a 'I can definitely apply this at will' sort of way
19:13:35 <permagreen> Have you read the Typeclassopedia? That really helped me grok the concept of functors, monads, and all that malarky.
19:14:00 <bluephoenix47> I'll take a look, thanks.
19:14:49 <ion> This doesn’t teach functors per se, but it tries to show the relationship between functors, applicative functors and monads via an example. http://heh.fi/haskell/functors/
19:15:25 <bluephoenix47> book marked both for future reading :)
19:17:06 <elliott> ion: I don't really like the "Run [...] replacing the result" language there
19:17:19 <elliott> it does not seem to generalise well to many sorts of functor, e.g. lists
19:17:47 <ion> elliott: Yeah, i should figure out a better way to say it that covers both containers and computations.
19:24:24 <Saizan> ion: show how containers are just memo-tables for computations first :)
19:26:24 <ion> Yeah, MemoIO is Map (RealWorld, Action) a :-P
19:27:14 <Saizan> i wouldn't consider IO a container
19:27:34 <copumpkin> what's the difference between CAString and CString?
19:27:37 <copumpkin> in Foreign.C.String?
19:28:06 <Gracenotes> hm
19:28:19 <Jafet> Saizan: it contains the RealWorld!
19:28:50 <Gracenotes> copumpkin: related to locale encoding I think
19:28:57 <Jafet> http://www-users.cs.york.ac.uk/susan/joke/3.htm#fence
19:29:36 <Axman6> copumpkin: the CAString functions seem to be ignorant of unicode
19:29:49 <copumpkin> oh, CString spits stuff out as utf8?
19:29:50 <Axman6> look at the 'Using 8-bit characters' section
19:30:14 <Gracenotes> but it's also ignorant of whatever nightmare encoding used by whichever version of windows  you have
19:30:18 <ion> jafet: haha
19:30:20 <Gracenotes> it seems
20:02:04 <hpaste_> Raeez pasted “SCC” at http://hpaste.org/50644
20:04:14 <synesthesia> In the above code implementing Tarjan's algorithm I get "No instance for (Applicative (ST s))" (line 108), but I'm fairly certain an instance is being declared (via import Control.Applicative)
20:04:24 <synesthesia> is there anything I'm blatantly missing?
20:05:09 <synesthesia> correction: in the pasted code it's line 72 that's troublesome
20:05:25 <copumpkin> for a long time, ST didn't have an applicative instance
20:05:31 <copumpkin> you may have an older GHC?
20:05:53 <synesthesia> copumpkin: 7.0.3?
20:05:58 <copumpkin> not sure
20:06:16 <synesthesia> I'll try defining the instance myself, but that makes me unhappy ;-/
20:06:25 <Gracenotes> not too future-proof
20:06:26 <copumpkin> you shouldn't have to
20:06:35 <Gracenotes> or uh present-proof
20:06:56 <Saizan> maybe it's defined somewhere else
20:07:41 <monochrom> no instance Applicative (ST s) in ghc 7.0.3
20:09:21 <synesthesia> yeah, just going through hackage's docs on the latest base
20:10:27 <synesthesia> does this mean that ST's applicative instance is always orphaned?
20:10:49 <monochrom> if someone implements it in a 3rd module, it's orphaned
20:12:06 <synesthesia> hmm, right
20:12:33 <Axman6> synesthesia: visited = (/= 0)
20:12:49 <synesthesia> Axman6: yeah, it's really just for readability right now
20:12:57 <synesthesia> Axman6: and the underlying rep may change
20:13:05 <Axman6> ok
20:13:49 <synesthesia> but thx; a lot of this code is overly verbose; I still need to get to the refactoring bit
20:13:51 <bobzhang> hi, all I forgot which extension let ghci to print type signature with explicit _forall_, does anyone remember it? thank you :)
20:14:22 <shachaf> bobzhang: -fprint-explicit-foralls?
20:14:32 <Saizan> ExplicitQuantification maybe
20:14:32 <bobzhang> shachaf: let me have a try
20:14:39 <Axman6> bobzhang: try :set -f<tab>
20:15:04 <shachaf> Axman6: "Display all 214 possibilities? (y or n)" isn't *that* helpful.
20:15:10 <Axman6> >_>
20:15:39 <Saizan> i was thinking of ExplicitForAll, but that's not it
20:15:51 <bobzhang> :set -fprint-explicit-foralls
20:16:06 <bobzhang> shachaf: thanks :)
20:16:35 <applicative> hm, how do I get 7.2 to stop giving me the explicit forall?
20:17:13 <azaq23> There's also -XExplicitForAll, which enables you to use explicit forall's in type signatures, while -fprint-explicit-foralls only prints them
20:17:18 <cmccann> bobzhang, still having fun with quantifiers, I take it :]
20:18:09 <bobzhang> cmccann: thanks for your nice answer :-)
20:19:19 <cmccann> bobzhang, that's the easiest way for me to think about nested quantifiers like that, so glad you enjoyed it
20:19:38 <shachaf> cmccann and his mysterious answers.
20:19:55 <cmccann> shachaf, this one had movie quotes, though
20:19:58 * shachaf considers starting to read StackOverflow.
20:20:01 <cmccann> that's always a bonus
20:20:34 <Gracenotes> shachaf: read isn't too bad, especially if you go by tags you're interested in
20:20:49 <Gracenotes> and top questions too. but I would stop there though :.
20:20:51 <Saizan> game semantics are nice, but explicit type abstraction/application might be better
20:21:35 <cmccann> Saizan, I like the game semantics-flavored perspective for figuring out whether something can work, or why it can't
20:21:52 <cmccann> but I prefer thinking in terms of explicit type application otherwise
20:22:13 <applicative> wow people are contradicting oleg a lot one -cafe these days.
20:22:15 <monochrom> http://www.vex.net/~trebla/weblog/any-all-some.html  game semantics
20:24:06 <applicative> hm, specifically Miguel Mitrofanov has taken to contradicting oleg.
20:24:19 * applicative studies
20:24:35 <cmccann> Saizan, that's actually part of why I wrote out the quantifiers to look like type arguments in the recent SO answer, not sure if you actually saw that or were just talking about game semantics in general
20:25:21 <byorgey> cmccann: do you have a link to this SO answer you're talking about?
20:25:28 <monochrom> type argument is good for intuitionism only
20:25:47 <cmccann> byorgey, http://stackoverflow.com/questions/7178919/how-to-make-callcc-more-dynamic/7180154#7180154
20:25:55 <byorgey> I had recently been pondering the possibility of writing a blog post about types-as-games
20:26:10 <cmccann> basically informally reasoning in game semantics style to show why codensity doesn't allow callCC
20:26:15 <Saizan> cmccann: in general
20:26:20 <cmccann> with a bit of silliness at the end
20:27:48 <Gracenotes> I feel vaguely like I'm missing large swaths of the conversation here
20:27:59 <Gracenotes> :P
20:29:00 <byorgey> cmccann: cool, thanks
20:29:27 <Gracenotes> that is one cool answer
20:30:02 <cmccann> byorgey, no prob. I wanted to conclude by quickly doing the same on the regular continuation monad to show why callCC does work there, but I didn't have time :T
20:30:13 <cmccann> exercise for the reader I guess
20:30:28 <Guest42233> is there a special way to get "set" functions the way record syntax handles "get"
20:30:53 <ivanm> Guest42233: there are a few libraries that let you do that
20:31:06 <ivanm> but inbuilt, the best you have is: foo { bar = ... }
20:31:13 <ivanm> i.e. no inline functions
20:32:58 <Guest42233> thanks
20:33:09 <Gracenotes> I forget, are there any Haskell' proposals along the lines of record syntax overhaul?
20:34:15 <copumpkin> ezyang: you around?
20:34:59 <ivanm> Gracenotes: since Haskell' is about standardising what's there usually, I doubt it
20:35:11 <ivanm> big thing IIRC is what the overhaul should look like
20:35:31 <ivanm> which is why we have the status quo (from when Haskell was being designed)
20:37:57 <Gracenotes> ah. yeah. haskell prime trac is still filled with all kinds of fun stuff
20:38:39 <Saizan> cmccann: what inspired your bending the rules sections?
20:39:41 <Saizan> i.e. is there any way to actually bend them like that?
20:39:48 <cmccann> Saizan, just the general principle that you can often do that sort of thing in Haskell, even when it's not actually a good idea
20:40:02 <Gracenotes> I guess djinn can be seen in a game semantic context
20:40:05 <cmccann> I'm not sure if the type arguments could actually be juggled that way or not, but I wouldn't be surprised
20:40:28 <Saizan> it'd break runST, i think
20:40:54 <Gracenotes> it's a general niceness of using a language which encourages the use of total functions. to state it blandly.
20:41:21 <cmccann> also, if memory serves me the actual callCC for the Cont monad loops things around a bit like that, but it works there because all the result types are identical
20:41:44 <cmccann> so it was partly an attempt to fail at imitating the weird program flow that callCC ought to have
20:42:03 <Saizan> my objection is only about the types
20:42:28 <Saizan> callCC for Cont doesn't attempt anything like referring to a type variable "out of scope"
20:43:02 <cmccann> I'm pretty sure that actually doing what I did in that section, if it is possible, would involve much more complicated manipulations than the handwaving I did
20:44:28 <Saizan> if you could manage that then you could leak STRef's from runST, runST @ (STRef that_s Int) (/\ that_s -> newSTRef 1) :: STRef that_s Int
20:45:32 <cmccann> you'd never be able to use the STRef though
20:46:01 <cmccann> any type leaked like that would have to be existential or otherwise impossible to unify with anything
20:46:31 * applicative worries: "<interactive>:0:6:  My brain just exploded"
20:48:11 <cmccann> in fact, if you look at the first bit of hand-waving I did about bending the rules, all the type abstractions have vanished but there are still "variables" floating around; there's no way you could do anything with that type at that point
20:48:13 <Saizan> but why wouldn't i be able to say let r = runST @ (STRef that_s Int) (/\ that_s -> newSTRef 1); x = runST @ Int (/\ that_s -> readSTRef r) ?
20:48:58 <Saizan> anyhow, i guess i'll jsut leave the burden of the proof to you :)
20:49:11 <cmccann> Saizan, because after leaking it'd be a specific s. You can only use runST on a polymorphic s, that's why it's safe
20:50:04 <Saizan> i'm saying that the bending of the rules you propose looks a lot like allowing me to do that, but since it's handwavy i guess i can't play that card
20:52:32 <cmccann> Saizan, yes, do note that I'm still not sure if it'd be possible, just that I don't immediately see why it would be absolutely impossible
20:53:10 <cmccann> but it would be more convoluted than the handwaving is if it is, and I'm reasonably certain you'd never be able to accomplish anything that way.
20:53:27 <cmccann> you'd just end up with a lot of types you'd never be able to use
20:57:01 <cmccann> Saizan, if you'd like I can try to work through an example at some point and see what I can come up with
20:57:13 <cmccann> though existentials sorta give me a headache :[
20:57:42 <Saizan> i think i'm seeing how to do it in agda with --type-in-type and --no-termination-check
20:58:09 <Saizan> well, not for the callCC type though
21:00:14 * cmccann isn't familiar enough with Agda to help much on that front, alas
21:00:54 <Saizan> if you have f :: x => y => (z => y) -> y; you can say let z = f z Set id
21:01:58 <Saizan> i guess you can do without --type-in-type by just making y : Set1
21:03:08 <Saizan> of course, if f used x to make up that z it's going to loop
21:03:26 <cmccann> yes, I doubt any of this is remotely well-founded
21:03:48 <cmccann> explicitly so with my second handwavy example
21:06:15 * cmccann figures that doing it in Haskell would require an extra layer of quasi-CPS transformation so that the feedback happens in a smaller scope to contain the existentials
21:07:07 <cmccann> and that it would only end up looking like my example if you handwaved undoing the CPS transform (which would let the existentials out)
21:07:25 <Saizan> i think the cps would disrupt any knot-tying, even if f collaborates
21:07:47 <Saizan> though maybe not if we project stuff out twice
21:07:48 <cmccann> that's the part I'm uncertain of, yes
21:08:36 <cmccann> I have a vague sense that it could work and can't immediately see clear reasons why it should or shouldn't
21:09:03 <dolio> What's going on?
21:09:45 <cmccann> dolio, arguing about whether some handwavy nonsense is impossible or just useless
21:10:05 <dolio> Right. But what handwavy nonsense?
21:10:18 <cmccann> dolio, original context was something I posted on SO
21:10:20 <Saizan> dolio: weird stuff like f :: (x : Set)(y : Set1) -> ((z : Set) -> y) -> y; let z = f z Set id, but in haskell
21:10:33 <cmccann> dolio, http://stackoverflow.com/questions/7178919/how-to-make-callcc-more-dynamic/7180154#7180154
21:11:02 <cmccann> specifically whether my "bending the rules" stuff is actually well-defined or just complete nonsense
21:11:09 <dolio> Huh, my window manager is going haywire...
21:11:54 <Saizan> a puny window manager can't stand such weirdness
21:12:27 <cmccann> dolio, I didn't worry about it in the SO answer since I only used it to illustrate that it wouldn't work for the purpose at hand anyway, so it being impossible to begin with doesn't really weaken the point
21:14:13 <cmccann> (note that the question itself is basically why codensity doesn't support call/cc, but that's not terribly relevant)
21:17:05 <cmccann> looks like my type abuse killed dolio's computer :[
21:17:35 <cmccann> dolio, sorry if my type abuse killed your connection there
21:17:55 <dolio> Nah, it was all my windows showing up black for some reason.
21:18:07 <dolio> All the new ones, anyway.
21:18:16 <cmccann> did you see the other stuff I said about the context of the SO question?
21:18:22 <dolio> Yes.
21:18:24 <cmccann> k
21:18:39 <dolio> Anyhow, if you limit yourself to forall r. (a -> r) -> r ....
21:18:45 <dolio> That type is isomorphic to a.
21:19:29 <dolio> So the type of callCC becomes isomorphic to ((a -> forall b. b) -> a) -> a.
21:20:25 <cmccann> yeah, but that's not the part that Saizan and I were talking about a bit ago
21:21:07 <dolio> I guess I had that part on the brain, and have no scrollback.
21:21:30 <dolio> Something about ST.
21:21:53 <Saizan> dolio: if you look at the two "bending the rules" at the end of the article
21:22:23 <cmccann> as part of the SO answer showing why there was no way around the inability to write callCC for codensity I handwaved some stuff that Saizan objected to
21:22:34 <Saizan> dolio: cmccann is proposing to "play" a type that it's going to be "played" by its opponent later
21:22:44 <cmccann> so the question is whether something like that could typecheck at all
21:23:25 <cmccann> there's certainly no sensible implementation and the second example clearly diverges if it is possible
21:23:44 <dolio> Ah.
21:24:43 <Saizan> s/it's/is/
21:26:09 <cmccann> since my goal was simply to show that it wouldn't work anyway I didn't worry about justifying it in the answer, but I'm still not convinced that something along those lines can't be accomplished, if only via extra layers of indirection
21:29:17 <copumpkin> λ> 50412152153263252633473 + 61231253253524 :: Rounded TowardZero Double
21:29:17 <copumpkin> 4.4272191900460974e20
21:29:36 <cmccann> these lambda ghci prompts seem to be spreading.
21:29:40 <copumpkin> yeah
21:29:57 <copumpkin> I got tired of the prompt containing the loaded modules
21:30:02 <copumpkin> as it was filling up a lot of the real estate
21:30:19 <ddarius> Stop loading modules.
21:30:21 * cmccann currently has his prompt set to "∀x. x ⊢"
21:30:27 <copumpkin> lol
21:30:40 <cmccann> it seemed like a good idea at the time.
21:31:23 <dolio> cmccann: You can smuggle a choice of type variable out of scope in an existential. But there's no way to use it for much.
21:31:47 <copumpkin> @src Real
21:31:47 <lambdabot> class  (Num a, Ord a) => Real a  where
21:31:48 <lambdabot>     toRational      ::  a -> Rational
21:31:52 <cmccann> dolio, that was roughly my contention as the "best-case" scenario
21:32:01 <copumpkin> I love that class
21:32:03 <dolio> And the lack of non-strict matching on existentials in GHC would be a problem for any knot tying.
21:32:49 <dolio> Not that the knot tying would matter.
21:34:37 <cmccann> I still get headaches when existentials are involved so I'll take your word for it :T
21:35:10 <copumpkin> it'd be nice if we could export constructors only for patterns
21:35:14 <copumpkin> and not for construction
21:35:26 <ddarius> An existential is just the dual game of a universal.
21:35:27 <copumpkin> I want to be able to take a Ratio apart nicely
21:35:37 <ddarius> copumpkin: That would be nice.
21:35:45 <dolio> Well, it's not like you would know that the type you get out in the existential is the same as the one that the opponent chooses, or would have any way of proving that.
21:36:27 <ddarius> I applied one of those space-faring bananas and I wanted to hide the Place constructor, but doing that leads to all kinds of unavoidable non-exhaustive match warnings.
21:36:51 <cmccann> dolio, true, I was sort of assuming an "outside" perspective that knows what types get chosen in some sense. like I said, very handwavy
21:37:43 <ddarius> The opponent is antagonistic, you don't need to know what type they chose, you just know it's not the one you want unless their hand is forced.
21:38:37 <cmccann> ddarius, the idea here was finding some way to defer "your" choice of type in order to choose the same one the opponent choses in a later move
21:38:43 <cmccann> note that anything useful can be done with the result, of course
21:38:55 <cmccann> s/note/not
21:39:12 * hackagebot intel-aes 0.2.0.0 - Hardware accelerated AES encryption and RNG.  http://hackage.haskell.org/package/intel-aes-0.2.0.0 (RyanNewton)
21:46:40 <glguy_> tommd: Are you around?
22:08:56 * ddarius should endeavor to make all his communications consist solely of punctuation.
22:09:11 <copumpkin> ???
22:09:12 * hackagebot intel-aes 0.2.1.0 - Hardware accelerated AES encryption and Random Number Generation.  http://hackage.haskell.org/package/intel-aes-0.2.1.0 (RyanNewton)
22:09:13 <copumpkin> !
22:09:29 <cmccann> ‽
22:09:31 <dolio> Can you write J programs that will print out what you want to say?
22:09:43 <dolio> Without any alphanumeric characters.
22:11:01 * cmccann didn't realize you could actually use alphanumeric characters in J programs
22:11:29 <dolio> I'm pretty sure the names you can give to your functions are alphanumeric.
22:11:46 <dolio> Which makes them stick out from the rest of the program in an unsightly way.
22:12:24 <cmccann> that would explain why I don't recall any. the example code I've seen certainly focused quite heavily on punctuation.
22:15:43 <copumpkin> well, I have lots of stuff for edwardk now, at least
22:15:48 <copumpkin> pity he isn't around
22:16:22 <dolio> Is it all working now?
22:16:32 <dolio> No crashing the second time you do things?
22:16:35 <copumpkin> nope
22:16:38 <copumpkin> all is good
22:16:41 <copumpkin> I can do basic arithmetic
22:16:42 <dolio> Nice.
22:16:46 <copumpkin> I have a fractional instance, a num instance
22:16:49 <copumpkin> and a few other things
22:16:55 <copumpkin> the Show is still doing toDouble before showing
22:17:12 <copumpkin> I'm trying to use their string generator but it outputs shit in a weird way
22:17:28 <copumpkin> I guess it's to be internationalization-friendly
22:17:42 <copumpkin> but they output digits only, and give you an int for where the decimal should be
22:18:49 * Saizan replaces copumpkin's dots with commas
22:23:16 <copumpkin> :)
22:23:33 <copumpkin> hmm, I foresee slight problems
22:23:56 <ddarius> map intToDigit (take decimal ds) ++ "." ++ map intToDigit (drop decimal ds)
22:24:05 <copumpkin> yeah, that's what I do
22:24:30 <copumpkin> it isn't perfect output though, as their function doesn't seem to be spitting out a - sign
22:24:42 <copumpkin> and also for special values and so on
22:24:56 <Gracenotes> not having a decimal place sounds pretty mesopotamian.
22:25:06 <Gracenotes> i18n, kicking it back a few millenia
22:25:14 <Gracenotes> s/place/symbol/
22:26:28 * cmccann considers changing his ghci prompt to ☃ ⊢
22:28:00 <ivanm> cmccann: is that a lightbulb?
22:28:08 <cmccann> no
22:28:11 <cmccann> it's a snowman
22:28:55 <varun> @cmccann that's an excellent idea
22:28:56 <lambdabot> Unknown command, try @list
22:29:35 <cmccann> I'm pretty sure that most proofs would be improved by including a unicode snowman
22:29:52 <varun> I concur! :D
22:31:29 <Gracenotes> I tried to find the latex symbol for the snowman. I don't recommend googling "latex snowman"
22:31:40 <cmccann> ahahahaha
22:32:43 <varun> hahahaha
22:33:17 <varun> Now I'm curious. I'm going to google "latex snowman".
22:33:35 <hpaste_> Kevin pasted “use aeson to decode this string” at http://hpaste.org/50645
22:34:36 <kevin> Hi, anyone knows how to use aeson to decode this string : http://hpaste.org/50645
22:34:53 <kevin> sorry the format is a little massy
22:38:58 <Rotsor> Why doesn't the following compile? data family F :: * -> *; data instance F Int = Bool; test :: F Int -> Bool; test = id
22:39:20 <Rotsor> It says that F Int and Bool are different types. What is F Int if it's not a Bool then?
22:39:43 <cmccann> don't data families need a data constructor and such?
22:39:59 <cmccann> you seem to be trying to define it like a type synonym family
22:40:19 <Rotsor> Ah, is "Bool" a data constructor name here?
22:40:43 <cmccann> Quite possibly it is being interpreted that way, yes
22:41:06 <cmccann> i haven't actually used data families much so I'm not sure how it behaves in all cases
22:41:20 <Rotsor> This works, yes: test :: F Int -> (); test Bool = ()
22:41:27 <Rotsor> Thank you :)
22:41:49 <cmccann> no prob
22:42:12 <Saizan> kevin: is it supposed to be json?
22:42:30 <kevin> yes, it is json.
22:42:31 <cmccann> Rotsor, helping people with weird type issues is practically what I'm here for :P
22:42:42 <absz> Is there a version of writeArray which is strict in the array elements?  Alternatively, is there a strict mutable array which doesn't require unboxed elements?
22:42:47 <kevin> I think aeson is a pretty good lib to decode json string
22:42:54 <Saizan> yep
22:43:31 <Saizan> ?type writeArray
22:43:32 <lambdabot> Not in scope: `writeArray'
22:43:38 <Saizan> ?hoogle writeArray
22:43:39 <lambdabot> Data.Array.MArray writeArray :: (MArray a e m, Ix i) => a i e -> i -> e -> m ()
22:44:03 <kevin> The format is a little messy, you can copy it to http://json.parser.online.fr/, and see a nicely formatted version
22:44:12 * hackagebot intel-aes 0.2.1.1 - Hardware accelerated AES encryption and Random Number Generation.  http://hackage.haskell.org/package/intel-aes-0.2.1.1 (RyanNewton)
22:44:13 <Saizan> absz: you can make a strict version yourself: writeArray' arr i e = writeArray arr i $! e
22:44:24 <Saizan> or add deepseq if you want more strictness
22:44:31 <bos> is there a simple predefined function to tell whether a Double has no fractional part?
22:45:02 <Saizan> ?type properFraction
22:45:03 <lambdabot> forall a b. (RealFrac a, Integral b) => a -> (b, a)
22:45:13 <absz> Saizan: Of course, thanks.  Trying that.
22:45:23 <Saizan> > properFraction 1.0
22:45:24 <lambdabot>   (1,0.0)
22:45:32 <bos> Saizan: cheers
22:45:53 <Rotsor> cmccann, doing s/data/type/ and changing F :: * -> * to F x :: * helps too.
22:46:18 <cmccann> Rotsor, indeed it would, though that changes the behavior of things rather dramatically
22:46:47 <cmccann> lack of injectivity, need to use it fully applied, &c.
22:47:14 <Saizan> kevin: ah, so you want help decoding the already-parsed-json into something like an haskell ADT?
22:47:30 <kevin> yes,
22:47:40 <cmccann> Rotsor, I'm not sure which style you actually need, though
22:47:49 <kevin> I only know how to decode simple string. This is too complicated,
22:47:54 <Rotsor> cmccann, me neither :)
22:48:02 <kevin> anyone can give me a direction?
22:49:23 <cmccann> Rotsor, data families create a new, unique type specific to the type parameters, which is useful for when you really have an auxiliary type closely associated with something else
22:49:25 <huangyi> You need to write an instance for your ADT
22:49:30 * Saizan never used aeson himself
22:49:57 <cmccann> whereas type synonym families can juggle types around without having to be associated with anything in particular, but there are more limitations on how you use them
22:50:01 <kevin> Yeah, I know I have to write an instance of fromJSON.
22:50:19 <kevin> but this seems to be too complicated.
22:51:09 <huangyi> kevin: you can read my code as an example, i used aeson to implement a simple json rpc library. https://github.com/yihuang/haskell-json-rpc/blob/master/Network/JsonRpc/Protocol.hs
22:51:38 <kevin> huangyi: OK, thanks, I'll check that.
22:51:52 <huangyi> kevin: there are combinators which make the task easier.
22:52:57 <kevin> huangyi: I'm afraid that is still too hard for me.
23:04:47 <_Ray_> foldr ((:) . f) [] == map f, right?
23:05:04 <Veinor> @type \f -> ((:) . f) []
23:05:04 <lambdabot> forall a a1. ([a1] -> a) -> [a] -> [a]
23:05:08 <Veinor> @type \f -> foldr ((:) . f) []
23:05:09 <lambdabot> forall a a1. (a1 -> a) -> [a1] -> [a]
23:05:11 <Veinor> yep
23:05:51 <_Ray_> cool :) I think I get why people get horny at pointfree style
23:06:26 <cmccann> _Ray_, just remember that foldr substitutes its arguments in place of the list's constructors
23:06:56 <cmccann> so for foldr f z, given a list x:y:[] it becomes f x (f y z)
23:07:03 <_Ray_> right, so replacing : by f, and [x] by f x x_0, where x_0 is passed
23:07:17 <_Ray_> or even better, [] by x_0
23:07:50 <cmccann> so if you have (:) . f that's \x -> (f x :), so you get (f x :) ((f y :) [])
23:08:13 <cmccann> which is f x : f y : [] or just [f x, f y]
23:08:20 <_Ray_> right
23:08:21 <Gracenotes> I am getting good vibes from (f x :)
23:08:44 <cmccann> of course, the type signature pretty much tells you the same thing, but that's still a nice way to think about foldr
23:09:33 <cmccann> Gracenotes, yes, much better than gloomy operators like :| or :/
23:10:15 <shachaf> > foldr f z [a,b,c]
23:10:16 <lambdabot>   f a (f b (f c z))
23:10:34 <cmccann> heh
23:10:40 <cmccann> that is a nice gimmick
23:13:25 * _Ray_ doesn't understand what is happening in that line
23:13:43 <_Ray_> I think it's understanding things as types but... wha?
23:14:02 <_Ray_> foldr isn't a functor, it doesn't take types, it takes values :s
23:14:16 <cmccann> it's some sort of nefarious trickery in lambdabot
23:14:35 <cmccann> I forget how it works though.
23:14:38 <shachaf> > x
23:14:39 <lambdabot>   x
23:14:40 <shachaf> > f x
23:14:41 <lambdabot>   Ambiguous type variable `a' in the constraints:
23:14:42 <lambdabot>    `GHC.Show.Show a'
23:14:42 <lambdabot>      a...
23:14:45 <shachaf> > f x :: Expr
23:14:46 <lambdabot>   f x
23:14:48 <_Ray_> > foldl f z [a,b,c]
23:14:50 <lambdabot>   f (f (f z a) b) c
23:14:54 <Gracenotes> heh. how it mostly works.
23:15:38 <_Ray_> ah, I finally made intuitive how to know which fold is which
23:15:46 <_Ray_> foldr starts at the right
23:15:53 <_Ray_> foldl at the left
23:16:08 <Gracenotes> that's deceptively simple!
23:16:25 <shachaf> foldr (+) 0 [a,b,c] === a + (b + (c + 0))
23:16:35 <Gracenotes> there may be some deception involved as well >_>
23:16:42 <shachaf> foldl (+) 0 [a,b,c] === (((a + b) + c) + 0)
23:16:46 <shachaf> Er.
23:16:47 <_Ray_> yep
23:16:50 <shachaf> That's not right.
23:16:51 <_Ray_> err
23:16:52 <_Ray_> a+0
23:16:56 <shachaf> Yes.
23:16:56 <_Ray_> then +b, then +c
23:17:04 <shachaf> Actually, 0+a. :-)
23:17:14 <shachaf> (((0 + a) + b) + c)
23:17:33 <Gracenotes> it gets more fun with non-associative functions
23:17:33 <cmccann> foldr starts at the right in the sense that it actually starts at the left with the right-hand part being the result you'll get from evaluating the rest of it
23:17:36 <_Ray_> hrm, 0 + a. I guess it makes sense
23:17:53 <shachaf> + is a bad example because it's commutative.
23:18:03 <shachaf> I should've used a non-commutative operator like (*). :-)
23:18:13 <_Ray_> cmccann, well, in ye olde eager languages, foldr would compute the rightmost expression first
23:18:15 <cmccann> whereas foldl starts from the left in the sense that it uses the left part plus the next bit on the right, so you don't actually get anything at all until you reach the right-most end
23:18:18 <Gracenotes> shachaf: pick a typeclass, any typeclass
23:18:27 <_Ray_> or just -
23:18:34 <_Ray_> - isn't even associative
23:18:40 <shachaf> True.
23:18:43 <Gracenotes> A good exercise: write take in terms of foldr.
23:18:49 <Gracenotes> make it work for infinite lists too.
23:19:12 <shachaf> Gracenotes: myTake n l = take n (foldr (:) [] l)
23:19:13 <Gracenotes> you can do drop as well
23:19:17 <cmccann> _Ray_, yes, which is why I'm pointing it out. why foldr works the way it does with lazy lists is pretty counterintuitive at first
23:19:36 <Gracenotes> shachaf: where foldr is the only function which does list pattern matching. naughty!
23:19:42 <_Ray_> hrm, yes, foldr with infinite lists shouldn't work.... hrmph
23:20:02 <Rotsor> You can't write tail with foldr though, which is unfortunate :)
23:20:11 <shachaf> Rotsor: Sure you can.
23:20:28 <Axman6> > foldr (flip const) undefined [1,2,3]
23:20:28 <cmccann> you can write any list function with foldr if you bend over backwards far enough
23:20:29 <lambdabot>   *Exception: Prelude.undefined
23:20:32 <Rotsor> O(N) tail is not a tail :D
23:20:33 <Axman6> bleh
23:20:52 <shachaf> Rotsor: True, but that's not what I said.
23:20:54 <Gracenotes> a rather important property of foldr and foldl is how they response to infinite lists
23:21:04 <_Ray_> does foldr work with infinite lists?
23:21:10 <_Ray_> oh
23:21:10 <Axman6> > foldr1 (flip const) undefined [1,2,3]
23:21:12 <lambdabot>   *Exception: Prelude.undefined
23:21:12 <_Ray_> wait, yes, it can
23:21:17 <_Ray_> if the function doesn't need some of its arguments
23:21:22 <Axman6> > foldr1 (flip const) [1,2,3]
23:21:24 <lambdabot>   3
23:21:27 <_Ray_> a + b always needs b, but f x y may not need to evaluate y
23:21:43 <_Ray_> so even if y is an unevaluated thunk, it'll still work
23:21:55 <Gracenotes> can foldl also stop prematurely?
23:22:11 <cmccann> _Ray_, mostly it matters if foldr produces a result that's recursive inside a constructor
23:22:23 <shachaf> Gracenotes: data List a = Nil | Cons a (List a); listTake _ Nil = Nil; listTake n (Cons x xs) = Cons x (listTake (n-1) xs); listToHaskellList = ...; myTake n = listToHaskellList . take n . foldr (:) []
23:22:28 <cmccann> _Ray_, the trivial case being foldr (:) [], which is exactly as lazy as the original list
23:22:37 <_Ray_> right
23:22:49 <_Ray_> as more terms need to be evaluated, foldr will recurse down the list
23:22:54 <_Ray_> it needn't really ever reach a base case
23:23:00 <shachaf> > foldl f z [a,b,c] -- Gracenotes: See for yourself.
23:23:01 <lambdabot>   f (f (f z a) b) c
23:23:26 <_Ray_> if f _ c = 5, then foldl needn't go on
23:23:40 <Axman6> > foldl (flip const) undefined [1,2,3]
23:23:42 <lambdabot>   3
23:24:07 <frerich2> A function 'playTurn :: Game -> (Game -> IO Turn) -> IO Game' is impure, right? But a function 'playTurn :: Monad m => Game -> (Game -> m Turn) -> m Game' is pure (But potentially impure, depending on what monad is used), right?
23:24:34 <shachaf> frerich2: That depends on what you mean by "impure".
23:24:38 <Gracenotes> > foldl (\_ _ -> 5) 10 [1..]
23:24:41 <shachaf> It's a perfectly pure function.
23:24:51 * Axman6 awaits the technicalities of purity
23:24:53 <cmccann> _Ray_, and in many cases only one element of the list matters at a time, so the whole thing happens in constant space, which is quite nice
23:24:54 * Gracenotes pokes lambdabot 
23:25:03 <_Ray_> right
23:25:07 <lambdabot>   thread killed
23:25:08 <shachaf> frerich2: But in most senses that it can be said to be impure, so can the second one.
23:25:40 <frerich2> shachaf: 'impure' as in 'does not guarantee referential transparency'.
23:25:51 <shachaf> frerich2: The function is perfectly referentially transparent. :-)
23:25:58 <cmccann> IO actions are referentially transparent
23:25:59 <shachaf> For the same arguments you'll always get the same IO value.
23:26:09 <Gracenotes> so if you're trying to find the maximum element of a list using max, foldl(') is likely better
23:26:40 <shachaf> Or foldl1('). :-)
23:26:48 <Gracenotes> also, shachaf, that's some pretty code you have there. I'd definitely pay for its dinner.
23:26:49 <frerich2> shachaf: But - if the 'playTurn' function happens to evaluate the second argument (a function yielding an IO Turn) and then executes the IO Turn action, it may have side effects; but it could have different side effects depending on what the action actually does, no?
23:27:28 <shachaf> frerich2: playTurn can't execute any IO actions -- only the RTS can do that. :-)
23:27:37 * shachaf attempts to stop being annoying.
23:27:37 <cmccann> what is this "executing an IO action" business?
23:27:45 <cmccann> IO actions are just opaque values you pass around for fun
23:27:47 <shachaf> I'm not sure what you mean, though.
23:27:58 <cmccann> any further meaning you assign to them is between you and the runtime ;]
23:28:08 <frerich2> Well I know that IO actions are plain simple values just like other values, I can pass them around and whatever.
23:28:40 <frerich2> In fact, any monadic value.
23:29:11 <shachaf> The word "monadic" there is bothering me.
23:29:25 <shachaf> "Monads" in general have even less to do with impurity than IO does.
23:29:36 <frerich2> Yes, I understood that much.
23:29:48 <cmccann> IO is a degenerate sort of monad in that, other than details like being executed by the runtime, doesn't do anything other than the bare minimum specified by the Monad type class
23:30:05 <Gracenotes> and... dunno if this logicks at all, but an IO action does, based on the atomicity of the bind function in Monads, include all IO actions which follow it
23:30:08 <cmccann> so dealing with an arbitrary monad is much like using IO in that you have an opaque monad and can't do anything else with it
23:30:29 <Axman6> @hoogle evaluate
23:30:30 <lambdabot> Control.Exception evaluate :: a -> IO a
23:30:30 <shachaf> cmccann: Well, you have quite a lot of IO primitives.
23:30:30 <lambdabot> Control.OldException evaluate :: a -> IO a
23:30:30 <lambdabot> Test.QuickCheck evaluate :: Testable a => a -> Gen Result
23:30:57 <Feuerbach> cmccann: not all monads are opaque. E.g. Maybe
23:31:14 * frerich2 thinks if you treat IO actions as plain values and you're just chaining actions all the time and the only piece of code which actually executes something (like main) is the RTS, then every function is pure, and hence every function is impure, so the distinction is not useful.
23:31:26 <cmccann> shachaf, none of which you can inspect in any meaningful way except via IO. including the FFI, IO is a monad with an unbounded number of opaque primitives
23:31:31 <shachaf> Feuerbach: I think cmccann meant "artbirary monad" as in "all you know is that it's a monad", i.e., forall m. Monad m => ...
23:31:40 <shachaf> cmccann: Well, sure.
23:31:43 <frerich2> shachaf: I had this 'IO is impure' embolished into my brain wires all the time, and now I'm not sure anymore why.
23:31:48 <_Ray_> How does Haskell support rank n polymorphism?
23:31:56 <shachaf> Gracenotes: It's not *strictly* required to, is it? :-)
23:32:29 <shachaf> frerich2: Here's a data type declaration I like: data IO = Done | PutStrLn String IO | GetLine (String -> IO)
23:32:33 <cmccann> frerich2, IO is treated as pure by a sleight of hand. In practice, it's impure. But nothing you can do with pure code can tell that it is.
23:32:49 <shachaf> This is pretty similar to the Haskell IO type, except more limited. :-)
23:32:51 <Gracenotes> shachaf: one day, there will be a Haskell where bindIO is not the base IO primitive, but rather joinIO
23:32:56 <Rotsor> frerich2, As I understand it, I/O itself is impure, functions manipulating values describing it (IO) are pure.
23:33:11 <_Ray_> Isn't bind id = join?
23:33:14 <shachaf> Gracenotes: I may have misunderstood your question.
23:33:28 <_Ray_> or something like return . id or something
23:33:35 <cmccann> actually, let me dig something up, hm
23:33:44 <Gracenotes> yeah, but join isn't the opaque-ish one
23:34:13 <shachaf> _Ray_: >>= id
23:34:17 <Gracenotes> shachaf: dunno. it's late, man. I'm on the east coast now. I'm three hours behind.
23:34:18 <cmccann> see here for my thoughts on IO and arbitrary monads: http://chat.stackoverflow.com/transcript/message/1280091#1280091
23:34:32 <cmccann> particularly the really really long part several messages down
23:34:40 <cmccann> the bit where I talk a lot
23:34:50 <Rotsor> shachaf, in your IO data type there is no Bind, nor Join constructor, so it's not good enough
23:35:16 <shachaf> Rotsor: Sure, it's not as general as Haskell's IO.
23:35:26 <shachaf> It's purposefully simplified.
23:35:27 <_Ray_> and now for something scary and inflamatory, categorical notions of functorial covariance, as applied to C++. http://fedelebron.com/categorical-view-covariance-and-contravariance-c
23:36:25 <Gracenotes> is this in the category of C++ types?
23:36:37 <cmccann> _Ray_, is that about co/contra-variance in subtyping relations?
23:36:48 <_Ray_> yes to both
23:37:09 <frerich2> shachaf: Thanks for your feedback, that's some interesting food for thought :-)
23:37:22 <_Ray_> also took some time to realize (->) is Hom
23:37:46 <Gracenotes> skimming, it seems to draw parallels between covariant subtypes and functors, also with contravariant
23:37:58 <cmccann> yes, it works the same way
23:38:04 <_Ray_> indeed, though c++, for some reason, hasn't implemented parameter covariance
23:38:07 <_Ray_> err, contravariance
23:38:26 <cmccann> the implicit conversion to a supertype is what gets mapped through the functor
23:38:38 <_Ray_> right, the function witnessing the subtyping
23:38:46 <_Ray_> like fst :: (a, b) -> a witnesses (a, b) being a subtype of a
23:39:09 <cmccann> contravariant parameters are those appearing in contravariant position, it works just like a Contrafunctor class in Haskell would
23:39:43 <_Ray_> it's sort of unfortunate that Haskell doesn't have subtyping, I bet it could make a killing out of these things
23:39:55 <cmccann> subtyping complicates type inference badly, alas
23:39:59 <Gracenotes> "killing"? of the type-checker? :P
23:40:07 <_Ray_> that too
23:40:20 <_Ray_> I don't know how hard it'd be to add subtyping to hindley milner
23:40:25 <Gracenotes> you can only tempt the lambda cube so far
23:40:36 <Gracenotes> without getting into crazy land
23:40:46 <cmccann> _Ray_, how hard it is depends on whether you expect it to still work after you're done
23:41:22 <cmccann> you can't really add anything to H-M without losing full type inference, like GHC already does with various extensions
23:41:34 <cmccann> so it's just a question of how many annotations can you tolerate
23:42:34 <shachaf> Type inference is overrated.
23:42:39 <Gracenotes> subtyping at least exists with typeclasses. not very flexible-y
23:43:02 <cmccann> I don't think that's really subtyping in any meaningful sense
23:43:13 <_Ray_> well, even without subtyping, haskell still has more power in its typesystem than PHP has in its programs :p
23:43:25 <cmccann> it's also hard to talk about a proper top/bottom type in Haskell
23:43:37 <_Ray_> ffs the other day I saw a typewise fixpoint combinator
23:43:43 <_Ray_> ridiculous
23:43:49 <shachaf> Why is that ridiculous?
23:44:05 <shachaf> Of all the things you can do in Haskell's type system to complain about, that one seems perfectly reasonable.
23:44:07 <_Ray_> far too powerful a typesystem if you can make a lazy fixpoint combinator
23:44:08 <Gracenotes> moooooo
23:44:08 <shachaf> s/perfectly //
23:44:21 <_Ray_> (and I don't quite grasp it)
23:44:23 <cmccann> newtype Fix f = Fix { break :: f (Fix f) }
23:44:43 <cmccann> or do you mean something horrible, like encoding the true Y combinator using type families and undecidable instances?
23:44:55 <cmccann> which actually works btw
23:45:03 <cmccann> you can make GHC diverge that way
23:45:09 <cmccann> it's good fun
23:45:12 <cmccann> the first time, at least
23:45:13 <shachaf> _Ray_: It works very similary to the value-level fixed-point combinator. :-)
23:45:27 <shachaf> cmccann: I suspect there are easier ways to make GHC diverge with UndecidableInstances.
23:45:43 <cmccann> shachaf, actually it's harder than you might think
23:46:00 <cmccann> it tends to bail out quickly because of the shallow stack for resolving type nonsense
23:46:13 <_Ray_> cmccann, you mean you can make a compilation not stop?
23:46:22 <shachaf> Yes.
23:46:22 <cmccann> you have to trick it into going into an infinite loop that doesn't grow the stack
23:46:29 <shachaf> cmccann: Ah, I suppose that's true.
23:46:40 <shachaf> A Haskeller might consider a stack overflow to count as "diverging". :-)
23:47:16 <cmccann> my favorite technique is to encode a lazily-infinite type and let GHC spend eternity making it bigger. memory lasts a lot longer than GHC's type class stack
23:47:23 <shachaf> _Ray_: Anyway, are you referring to Mu (cmccann's Fix)?
23:47:38 <_Ray_> yes, that's very similar to what I had seen, I think
23:47:47 <shachaf> _Ray_: Well, where does it not make sense?
23:47:59 <shachaf> Take Mu Maybe, for instance.
23:47:59 * _Ray_ isn't comfortable enough with newtype to tell
23:48:11 <_Ray_> I understand data
23:48:12 <shachaf> Use data instead of newtype if you prefer; it's very similar (though less appropriate).
23:48:54 <shachaf> "Mu Maybe" is equivalent to "data Foo = Foo (Maybe Foo)"
23:49:06 <_Ray_> so data Fix f = Fix { break :: f (Fix f) }, here we are using two different notions of 'Fix', this could be written as data Fix f = Constructor { break :: f (Fix f) }, right?
23:49:08 <Gracenotes> newtype is mostly important with pattern matching behavior
23:49:18 <shachaf> Which is equivalent to lazy naturals, i.e. data Nat = Z | S Nat; do you see why?
23:49:27 <shachaf> _Ray_: Yep.
23:49:46 <_Ray_> Intuitively I see it, "maybe there's a previous natural"
23:49:57 <_Ray_> (or it may be "just zero")
23:49:59 <shachaf> _Ray_: Well, just think of the value it could have:
23:50:13 <shachaf> Foo Nothing, Foo (Just (Foo Nothing)), Foo (Just (Foo (Just (Foo Nothing)))), etc.
23:50:18 <_Ray_> ah, right, Foo (Just Foo (Just Foo (Nothing)))
23:50:36 <Rotsor> And (Fix . Either) should be equivalent to [] then...
23:50:44 <shachaf> Similarly, "Mu []" is the type of rose tree skeletons.
23:50:48 <_Ray_> what does Fix . Either mean?
23:50:56 <shachaf> data Tree = Tree [Tree]
23:51:05 <Rotsor> By . I mean composition on the level of types
23:51:22 <cmccann> ah, here we go
23:51:23 <_Ray_> hrm, I think I see it
23:51:27 <cmccann> _Ray_, http://hpaste.org/49196
23:51:29 <cmccann> :]
23:51:42 <_Ray_> the second "Tree" would be the "tying the knot" thing
23:51:51 <_Ray_> because it is equal to Fix f, but Fix f is already Fix
23:51:59 * shachaf isn't sure what _Ray_ means there.
23:51:59 <_Ray_> err, well, not Fix
23:52:20 <cmccann> general recursion is overrated anyhow. if it ain't broke, don't fixpoint it.
23:52:29 <shachaf> Ah, good old cmccann and his large family of types.
23:52:42 <Gracenotes> fixpoint fibonacci can be fun though
23:52:59 <_Ray_> Fix Tree = Fix { break :: Tree (Fix Tree) }, correct?
23:53:14 <_Ray_> incidentally, what would Fix { whatever } mean?
23:53:14 <Gracenotes> no more fun than just using explicit codata, but, um, we're not aiming for crowd-winning entertainment
23:53:35 * _Ray_ has pushed the hpaste link to his stack, btw
23:53:51 * shachaf isn't certain off-hand what the fixed point of trees would be.
23:54:09 <Gracenotes> can we say 'hypertrees' and call it a day?
23:55:16 <Axman6> cmccann: that's pretty cool :)
23:55:22 <cmccann> shachaf, yes, it's a very extended family. you should see the family reunions.
23:55:46 <cmccann> Axman6, which part, the bit where it makes GHC hang?
23:56:06 <shachaf> Axman6: I agree. cmccann doesnt afraid of anything
23:56:12 <Axman6> well, that's fun, but the whole thing i cool
23:56:16 <Rotsor> _Ray_, if you are asking about the curly braces syntax -- it is just an alternative way of listing the data constructor arguments, which allows to name them
23:56:18 <Gracenotes> shachaf: Mu [] should be able to have the same values as Mu [], I suppose?
23:56:23 <Gracenotes> er, as Mu Tree
23:56:46 <_Ray_> Rotsor, I was, yes. So the constructor Fix takes one argument, which must be of type f (Fix f)?
23:56:47 <Gracenotes> assuming you can diagonalize the tree into a list.
23:57:04 <shachaf> Yes.
23:57:05 <Rotsor> _Ray_, yes
23:57:17 <cmccann> Axman6, I've got about three implementations of type-level expression evaluators along similar lines. I always get distracted trying to fake kind annotations in a useful way and never finish anything though.
23:57:17 <Gracenotes> ..which might not be possible if there are infinite forests and stuff I guess
23:57:25 <_Ray_> so data Fix f = Fix f (Fix f)
23:57:38 <shachaf> data Fix f where { Fix :: f (Fix f) -> Fix f }
23:57:46 <cmccann> I should probably get one of them cleaned up to put in my ongoing type hackery collection on github though.
23:58:21 <Rotsor> _Ray, no, data Fix f = Fix (f (Fix f))
23:58:26 <Axman6> cmccann: can you make something akin to lambda calculus?
23:58:40 <cmccann> Axman6, yes and no
23:58:41 <olsner> Axman6: isn't that what he just did?
23:58:56 <Axman6> well, SKI isn't quite the same
23:58:56 <cmccann> no in that lambda abstractions will never work the way you might want them to
23:59:13 <edwardk> copumpkin: what was it!?
23:59:13 <edwardk> preflex: xseen copumpkin
23:59:13 <lambdabot> edwardk: You have 2 new messages. '/msg lambdabot @messages' to read them.
23:59:13 <preflex>  copumpkin was last seen on freenode/#haskell 1 hour, 34 minutes and 34 seconds ago, saying: and also for special values and so on
23:59:21 <edwardk> @messages
23:59:21 <lambdabot> copumpkin said 6h 46m 5s ago: I've learned something, but am still not sure how the hell this is happening :P
23:59:21 <lambdabot> ddarius said 6h 23m 31s ago: I'm aware of things like space-time raytracing and such. I didn't reference motion blur blindly. The key thing wasn't viewing the animation as a vector, but applying
23:59:21 <lambdabot> model reduction to it.
23:59:39 <_Ray_> Rotsor, in that sense, Fix f is the unique type X such that X = Fix (f X)?
23:59:41 <cmccann> Axman6, yes in that combinator calculus is equivalent of course, and you can do a lot to make a pointfree style that's usable instead of just SKI
