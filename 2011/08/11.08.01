00:00:40 <theorbtwo> (There was a spate of worrying about algorithmic complexity attacks as a form of DoS a few years back.  If you know the hashing algo of a hashmap, and can control the keys, you can force it into worst-case scenerio pretty easily.  You need to rehash when any hash slot gets too full, rather then only when you have more then N entries.)
00:01:05 <Eduard_Munteanu> I'm also not prepared to shove hashtables out the window on the premise they're not O(1), hence tries are just as good for any problem.
00:01:20 <avartanian> kmc that's lovely. thanks so much.
00:01:54 <theorbtwo> There may be room for comprimise between a diffarray and a straight array.  When you have more then N levels of diff, you copy the whole thing into a new base array, and start diffing again from there.
00:02:05 <theorbtwo> Tuning it would be rather difficult, though.
00:02:25 <Eduard_Munteanu> An example scenario is having code which does a limited number of inserts, but looks stuff up very often.
00:03:11 <Eduard_Munteanu> Not to mention hashtables are relatively easy to implement if you can make some assumptions about the data set.
00:48:03 <Heraklit> I have created a program which uses the Conrol.Exception.bracket command. This program is configured to start automatically as a background job in linux. Unfortunately the cleanup-branch of bracket is only executed if I terminate the process with SIGINT. So if I shutdown my OS the cleanup-branch is not executed. What shall I do?
00:52:34 <NihilistDandy> alias shutdown to send a SIGINT to it before shutting down? :D
00:53:38 <Ptival> Heraklit: use update-rc.d to run the command at stop/reboot time?
00:53:48 <olsner> make the program respond to SIGTERM?
00:56:53 <PhillipA> installHandler softwareTermination (Catch (killThread foo)) Nothing
00:57:13 <Heraklit> Well, I added this program to the KDE-autostart-script in directory ~/.kde/Autostart. I don't know how to change the kill-signal to SIGINT/SIGTERM during shutdown. I also wonder, whether the branch command might be the proper command...
00:57:46 <Heraklit> installHandler? Which packet?
00:58:35 <PhillipA> unix
00:58:52 <Heraklit> is there a corresponding windows packet?
00:59:01 <PhillipA> no, windows doesn't have signals
00:59:30 <Heraklit> yes of course, but a way to do the same on windows
00:59:42 <PhillipA> define "the same"
01:00:18 <Heraklit> appropriate program terminaten during shutdown
01:00:44 <PhillipA> hmm, no idea
01:01:01 <Heraklit> I will have a look at package unix first
01:12:16 <Heraklit> Yes, I think installHandler is the correct command
01:12:19 <Heraklit> thank you PhilipA
01:22:34 * hackagebot blaze-html 0.4.1.5 -   http://hackage.haskell.org/package/blaze-html-0.4.1.5 (JasperVanDerJeugt)
01:26:05 <erus`> has anyone solved the snail problem in haskell?
01:26:29 <erus`> eg 1 2 3 4 5 6 7 8 9 -> 1 2 3 8 9 4 7 6 5
01:28:34 * hackagebot blaze-html 0.4.1.6 -   http://hackage.haskell.org/package/blaze-html-0.4.1.6 (JasperVanDerJeugt)
01:35:25 <Heraklit> whats the snail problem, can you explain it?
01:38:32 <XniX23> could anyone explain me why: let s = head . tail, s "abc". works while: head . tail "abc" doesn't?
01:38:56 <opqdonut> function application binds the tightest
01:40:17 <XniX23> opqdonut: so he was trying to do: head . (tail "abc") ?
01:40:55 <Heraklit> or better head . tail $ "abc"
01:41:49 <Heraklit> or (head . tail) "abc"
01:43:02 <XniX23> $ means, evaluate the right side first?
01:43:25 <benmachine> not exactly
01:43:29 <benmachine> $ is just an operator
01:43:40 <benmachine> in fact it does nothing at all
01:43:44 <benmachine> f $ x = f x
01:43:53 <benmachine> it's only used to split things up a bit
01:43:59 <benmachine> it has very low precedence
01:45:17 <XniX23> benmachine: like this? head . tail $ "abc" == (head . tail) ("abc") ?
01:45:40 <benmachine> yes
01:45:42 <benmachine> pretty much
01:45:55 <XniX23> ty very much
01:47:03 <int-e> > let r = transpose . reverse; s 1 = [[1]]; s n = ([1..n] :) . r . ([n+1..2*n-1] :) . r . map (map (+(2*n-1))) $ s (n-1) in s 4
01:47:04 <lambdabot>   [[1,2,3,4],[12,13,14,5],[11,16,15,6],[10,9,8,7]]
01:51:24 <gienah> benmachine: haskell-src-meta seems to build fine with ghc 7.2rc1 with minor tweaks, sent you a pull request :-)
01:51:45 <benmachine> gienah: thanks, I'll have a look
01:52:12 <benmachine> what's the FlexibleInstances thing about? is 7.2 deciding more instances are flexible?
01:52:15 <benmachine> (as it were)
01:52:35 <gienah> benmachine: ghc 7.2 rc1 gives a compiler error that says it wants it
01:52:48 <benmachine> sure, but do you know why?
01:52:51 <benmachine> (just curious)
01:53:04 <benmachine> oh wait I think I know this
01:53:07 <gienah> no I just add it then its happy :-)
01:53:51 <benmachine> oh heh, I think this is the fix for a bug I reported actually :P
01:54:12 <gienah> that's good (glad you know why)
01:55:24 <erus`> guys i need to read the elements of a list in a clockwise spiral
01:55:33 <erus`> any tips (without telling me the solution)
01:55:45 <benmachine> a clockwise spiral?
01:55:48 <benmachine> what does that even mean?
01:55:56 <erus`> 1 2 3 4 -> 1 2 4 3
01:56:16 <ion> f [a,b,c,d] = [a,b,d,c]
01:56:18 <erus`> 1 2 3 4 5 6 7 8 9 -> 1 2 3 8 9 4 7 6 5
01:56:19 <benmachine> that is an incomplete specification
01:57:14 <ion> I don’t see the pattern.
01:57:22 * edwardk waves hello
01:57:27 <erus`> benmachine: take the list and make it square
01:57:35 <erus`> 1 2\n3 4
01:57:43 <benmachine> erus`: so the list must have a square number of elements?
01:57:44 <erus`> now read clockwise in a spiral
01:57:51 <erus`> benmachine: yeah
01:57:53 <benmachine> ok
01:58:04 <benmachine> but then I'd expect
01:58:16 <benmachine> 1 2 3 4 5 6 7 8 9 -> 1 2 3 6 9 8 7 4 5
01:58:21 <ion> ditto
01:58:42 <edwardk> erus: take the list, turn it into an n x n array, and then define the 4 stages of the loop and recurse
01:59:04 <benmachine> an array definitely seems like a good first step
02:00:33 <shachaf> @google traverse array in spiral pattern
02:00:34 <lambdabot> http://stackoverflow.com/questions/1655685/traverse-2d-array-in-spiral-pattern-using-recursion
02:00:34 <lambdabot> Title: Traverse 2D Array in Spiral pattern using recursion - Stack Overflow
02:00:41 <shachaf> What do you know, a link with a Haskell solution.
02:00:49 <shachaf> Of course lists are suboptimal for this, but still.
02:00:55 <benmachine> shachaf: we weren't supposed to give a solution :P
02:01:06 <shachaf> Oh.
02:01:15 <shachaf> Well, the link has tips too, I'm sure.
02:02:12 <shachaf> That solutioln is actually neat, though.
02:03:48 <ion> An array with an associated window and coordinate transformation function would be interesting for that case. reverse and transpose would just return the same array with a modified transformation function.
02:05:36 <erus`> i was never gonna come to that solution on my own
02:05:41 <erus`> how depressing
02:05:50 <edwardk> erus: one sec pasting the array solution
02:05:53 <ion> As for splitting vertically to get the first line and the rest: return the array twice with the appropriate windows.
02:06:59 <shachaf> erus`: Then write another solution. :-)
02:07:11 <shachaf> erus`: There certainly several other very different solutions I could think of.
02:07:18 <Claudius1aximus> isn't "same array with modified transformation function" pretty much the point of repa?
02:07:40 <ion> claudius1aximus: Cool, good to know.
02:07:54 <Claudius1aximus> asking because i'm not sure :)
02:09:32 <ClaudiusMaximus> not sure if it would apply here, though
02:10:07 <ClaudiusMaximus> ouch, my cairo-using program asploded... user error (invalid matrix (not invertible))
02:12:22 <erus`> i have noticed a pattern
02:12:36 <benmachine> gienah: do you want a release with your pull request in it?
02:13:29 <edwardk> @hpaste
02:13:29 <lambdabot> Haskell pastebin: http://hpaste.org/
02:13:48 <hpaste> erus` pasted “pattern” at http://hpaste.org/49736
02:13:48 <hpaste> edwardk pasted “for erus” at http://hpaste.org/49737
02:14:05 <edwardk> erus: something like that should work (i didn't test it though)
02:14:26 <edwardk> er those bounds should be <=
02:14:54 <hpaste> edwardk annotated “for erus” with “for erus (<= in ok)” at http://hpaste.org/49737#a49738
02:15:53 <edwardk> basically it just walks in one of the bounds each time as it sweeps left to right up and down
02:16:02 <edwardk> this should handle the non-square case as well
02:16:27 <shachaf> edwardk: That seems like a pretty verbose way to do it.
02:16:47 <edwardk> shachaf: mayhap, but it is explicit and obviously fast
02:16:58 <edwardk> well, up to the ++'s
02:18:04 <edwardk> the one from the link is reversing lists over and over again
02:18:26 <edwardk> and transposing a lot
02:18:28 <erus`> how can i double a list? e.g. 1,2,3 becomes 1,1,2,2,3,3
02:18:39 <erus`> is there a built in for that?
02:18:42 <shachaf> edwardk: Right, but I meant on arrays.
02:18:49 <coppro> is there a way to do "in-place" modification of things in a Set other than by fromList $ concatMap?
02:18:58 <shachaf> > [1,2,3] >>= replicate 2
02:18:58 <lambdabot>   [1,1,2,2,3,3]
02:19:13 <edwardk> > [1,2,3 >>= \x -> [x,x]
02:19:13 <lambdabot>   <no location info>: parse error (possibly incorrect indentation)
02:19:24 <edwardk> > [1,2,3] >>= \x -> [x,x]
02:19:25 <lambdabot>   [1,1,2,2,3,3]
02:19:31 * shachaf tries to figure out how to make an array.
02:19:31 <benmachine> coppro: "in-place" is kind of a weird idea with immutable data structures :)
02:19:49 <coppro> benmachine: that's qhy it's in quotes
02:19:50 <coppro> *why
02:19:55 <edwardk> @type arrayList
02:19:55 <lambdabot> Not in scope: `arrayList'
02:20:00 <edwardk> @type array
02:20:00 <lambdabot> forall i e. (Ix i) => (i, i) -> [(i, e)] -> Array i e
02:20:04 <edwardk> @type listArray
02:20:05 <lambdabot> forall i e. (Ix i) => (i, i) -> [e] -> Array i e
02:20:15 <benmachine> coppro: ok so what exactly do you mean
02:20:23 <benmachine> there's a Set.map isn't there?
02:20:35 <quicksilver> > join((concat.).zipWith (\x y->[x,y])) [1,2,3]
02:20:36 <lambdabot>   [1,1,2,2,3,3]
02:20:50 <edwardk> so find two factors of your list length that make it mostly square then you can use listArray
02:21:31 <benmachine> quicksilver: that's um, an interesting approach
02:21:46 <coppro> benmachine: oh, so there is
02:21:50 <coppro> yeah, that's what I was looking for
02:21:56 <quicksilver> benmachine: yes, bit daft really.
02:22:22 <quicksilver> > concat.transpose.(\x->[x,x]) $ [1,2,3]
02:22:24 <lambdabot>   [1,1,2,2,3,3]
02:22:25 <edwardk> schachaf: i leave it as an exercise for the reader to difference list that so it doesn't pay for so many ++'s
02:22:26 <quicksilver> much better.
02:22:33 <benmachine> hah
02:23:13 <shachaf> edwardk: An exercise for what?
02:23:27 <edwardk> the spiral thing i put up
02:24:26 <erus`> ok now i have a [Int], i want to 'take' from a list for each of the items in Int, but i want the items dropped from the list after taking
02:24:36 <erus`> lol
02:24:39 <erus`> jibberish
02:25:32 <edwardk> i get the feeling we're doing erus`'s homework
02:25:34 <erus`> @hoogle [Int] -> ([Int] -> [Int])
02:25:34 <lambdabot> Data.List (\\) :: Eq a => [a] -> [a] -> [a]
02:25:34 <lambdabot> Data.List intersect :: Eq a => [a] -> [a] -> [a]
02:25:34 <lambdabot> Data.List union :: Eq a => [a] -> [a] -> [a]
02:25:35 <shachaf> edwardk: Also, yours is counterclockwise. :-)
02:25:54 <edwardk> shachaf: well, you just caught my trap ;)
02:26:05 <erus`> edwardk: i wish i was still at school
02:26:54 <coppro> style question: in multiline list comprehensions, do you guys prefer to put the closing ] on its own line (aligned with | and commas) or not
02:27:04 <edwardk> schachaf: anyways, is it, left to to right, down, right to left, then back up. looks clockwise to me
02:27:44 <benmachine> coppro: in multiline list comprehensions I prefer to throw them away and write it with do, but that's just me :P
02:27:46 <edwardk> coppro: when they go multiline, yes
02:27:55 <shachaf> edwardk: Running it on (listArray ((0,0),(2,2)) "abcdefghi") gives "adghifcbe".
02:29:53 <edwardk> that is because listArray is filling it in by columns
02:30:04 <shachaf> Ah, makes sense.
02:30:06 <edwardk> array ((0,0),(2,2)) [((0,0),'a'),((0,1),'b'),((0,2),'c'),((1,0),'d'),((1,1),'e'),((1,2),'f'),((2,0),'g'),((2,1),'h'),((2,2),'i')]
02:31:41 <benmachine> edwardk: wait, which are you thinking is the column number/row number?
02:32:17 <edwardk> well, i wrote it as (x,y) (col,row) — you can feel free to transpose that
02:32:24 <benmachine> oh
02:32:28 <benmachine> I'm more used to (row,col)
02:32:36 <edwardk> sure
02:32:48 <benmachine> or I spent months training myself to be used to that because it was what everyone seemed to use :P
02:33:08 <edwardk> just go to fortran, and then the convention i used above is right ;)
02:46:44 * hackagebot intern 0.2.2 - Efficient hash-consing for arbitrary data types  http://hackage.haskell.org/package/intern-0.2.2 (EdwardKmett)
02:47:43 <quicksilver> ah, it's that edwardk up to his impure tricks again.
02:47:48 <coppro> What's the minimal complete definition of enum?
02:47:51 <coppro> *Enum
02:48:04 <Jafet> Everything, I'm guessing
02:48:08 <Jafet> @src Enum
02:48:08 <lambdabot> class  Enum a   where
02:48:08 <lambdabot>     succ                     :: a -> a
02:48:08 <lambdabot>     pred                     :: a -> a
02:48:08 <lambdabot>     toEnum                   :: Int -> a
02:48:08 <lambdabot>     fromEnum                 :: a -> Int
02:48:10 <lambdabot> [3 @more lines]
02:48:23 <Jafet> Er, maybe not everything
02:49:00 <Jafet> Yeah, you need those four at the least
02:49:08 <coppro> arg, damn you lack of dependent types
02:49:23 <coppro> also a google informs me you only need fromEnum and toEnum
02:49:38 <coppro> presumably succ = toEnum . (+1) . fromEnum
02:49:41 <coppro> and the like
02:49:42 <Jafet> succ is a round-trip? Ew.
02:49:50 <quicksilver> as long as your type is <= Int in size, yes
02:50:18 <edwardk> quicksilver: maybe impure, but memory efficient =)
02:50:27 <Jafet> I wonder why Int instead of Integer
02:50:47 <coppro> hmm
02:51:26 <edwardk> jafet: paranoia about efficiency
02:51:53 <Jafet> They were doing it wrong then. They should have been paranoid about generality
02:51:57 <quicksilver> edwardk: are there any docs for it? the hackage page doesn't help much
02:52:16 <edwardk> quicksilver: not yet. i have an example of its usage in the repo
02:52:32 <edwardk> https://github.com/ekmett/intern/blob/master/examples/Term.hs
02:53:06 <edwardk> i'm building a more complex example of using it over multiple types for a lambda calculus, to show the time vs. memory trade-off
02:53:52 <quicksilver> edwardk: what's the need for 'unintern'?
02:54:10 <edwardk> basically chris casingho complained about how agda wasn't hash consed in memory, and agda is notorious for its memory consumption, so since i was spending some time at this hackathon playing with a little dependently typed quasiquoter, i thought it'd be nice to solve the general hashconsing problem for the kinds of terms i care about
02:54:27 <edwardk> there isn't strictly a need for it, except if you don't want to expose your interned constructors
02:54:34 <edwardk> then you can use it as a form of safe view.
02:54:56 <edwardk> since they can't do anything dangerous with the resulting uninterned constructors except intern them once they are modified
02:55:10 <quicksilver> hmm
02:55:22 <quicksilver> why do you need to define the Term data structure three times?
02:55:27 <edwardk> if you expose your actual constructor you risk someone violating the invariants, but get nicer pattern matching
02:56:12 <edwardk> the Term data type is the one that has the identities sprinkled through it. the Uninterned Term lacks those, the Description is the flat key used to index the hash map.
02:56:46 <quicksilver> the Description appears to have identities instead of subterms
02:56:51 <quicksilver> is that what you mean by 'flat'?
02:56:59 <edwardk> the Description cannot be a newtype wrapper or you will never free the references, so it has to unpack the outermost constructor or if you have multiple constructors has to basically copy them, but should dumb down any internal copies of structures to just ids
02:57:02 <edwardk> yeah
02:57:10 <edwardk> the descriptions can be compared in O(1)
02:57:17 * quicksilver nods
02:57:29 <coppro> @hoogle Bits a -> Int
02:57:29 <lambdabot> Warning: Unknown type Bits
02:57:29 <lambdabot> Data.Generics.Schemes gdepth :: GenericQ Int
02:57:29 <lambdabot> Data.Generics.Schemes glength :: GenericQ Int
02:57:40 <coppro> @hoogle Data.Bits.Bits a -> Int
02:57:41 <lambdabot> Parse error:
02:57:41 <lambdabot>   --count=20 "Data.Bits.Bits a -> Int"
02:57:41 <lambdabot>                  ^
02:57:41 <quicksilver> edwardk: does it appear to work well in practice?
02:57:42 <edwardk> the base terms are used as arguments only inside your smart construcotrs
02:57:44 <coppro> :/
02:57:48 <Jafet> @hoogle Bits a => a -> Int
02:57:48 <lambdabot> Data.Bits bitSize :: Bits a => a -> Int
02:57:48 <lambdabot> Data.Bits complement :: Bits a => a -> a
02:57:48 <lambdabot> Data.Generics.Schemes gdepth :: GenericQ Int
02:57:55 <quicksilver> certainly this is an area that some people have criticised ghc/haskell for more than once
02:58:01 <edwardk> so far so good. i found at least one ghc bug while implementing it
02:58:07 <quicksilver> always a good metric :)
02:58:14 <Jafet> I don't know any Bits that isn't an Integral, anyway.
02:58:29 <Jafet> (NB: Bits is a typeclass)
02:58:41 <edwardk> that is that ghc flips its lid about {-# UNPACK #-} pragmas on terms that reference their own type, even if they only do so via a phantom type
02:59:27 <edwardk> another issue was that i was attaching finalizers to unevaluated thunks then evaluating them, and the finalizer wasn't being forwarded, so i had to seq some stuff to make everything happy.
03:00:05 <edwardk> i trac'd both issues, the former is definitely a bug, the latter is more dubious than anything
03:01:01 <edwardk> quicksilver: i was hoping to get the boilerplate reduced by adding some template haskell, i just haven't taken the time to write it
03:01:34 <edwardk> one place i get a huge win for it is by interning huge bytestrings that i use a lot.
03:01:55 <quicksilver> edwardk: GHC doesn't support finalizers very well :)
03:02:12 <edwardk> Data.ByteString.Interned is great for my usage pattern where i store the actual file contents in a bytestring, then want to compare them quickly
03:02:20 * quicksilver nods
03:02:31 <edwardk> sok, the finalizer is just there so i don't have to reinvent gc manually
03:02:32 <quicksilver> in a way it's a shame it can't be more transparent
03:02:43 <quicksilver> but it would be hard to keep it transparent and referentially transparent.
03:02:45 <quicksilver> (irony!)
03:02:51 <edwardk> yeah
03:03:21 <edwardk> you may choose to morally object to some of the instances i give you on Id's as well, since they vary over time
03:04:36 <edwardk> quicksilver: oh, and that unintern method has been factored out into another class. i need to update the example
03:05:22 <quicksilver> edwardk: I was looking at the docs for 2.0 when I asked that; hackage not having built docs for 2.2 yet
03:07:27 <edwardk> the homepage link goes to the github repo
03:08:59 * hackagebot intern 0.2.2.1 - Efficient hash-consing for arbitrary data types  http://hackage.haskell.org/package/intern-0.2.2.1 (EdwardKmett)
03:09:05 <hpaste> jaspervdj pasted “digestive functors: view vs errors” at http://hpaste.org/49739
03:09:42 <edwardk> there are some annoying caveats you need to keep track of, like the Uninterned type should be pretty strict, because intern winds up invoking intern while it has an mvar open, it'll block on itself, etc.
03:10:14 <edwardk> i found that when i made vars that used interned strings for names, and terms which could include the interned vars, etc.
03:18:12 <shachaf> edwardk: So I think your solution seems verbose mainly because working with arrays in Haskell seems verbose. :-)
03:33:19 <edwardk> schachaf: sure. though i challenge you to benchmark it against the transpose and reverse after every character version ;)
03:33:58 <shachaf> edwardk: Come on, comparing it to lists isn't even fair.
03:33:58 <edwardk> should be something like O(n) vs. O(n^3)
03:34:36 <edwardk> well i payed a linear amount of extra code, for cube rooting the runtime. ;)
03:34:42 <erus`> is there something like enum where succ last = first?
03:35:15 <quicksilver> erus`: no, although I have written it more than once
03:35:17 <edwardk> erus`: no, but you can always use (+1) on things that wrap around like Int
03:36:15 <quicksilver> :t let cycle x = if x == maxBound then minBound else succ x in cycle
03:36:16 <lambdabot> forall a. (Enum a, Eq a, Bounded a) => a -> a
03:36:26 <quicksilver> erus`: ^^ like that, I have written more than once
03:36:30 <quicksilver> cycle is not a good name for it ;)
03:36:41 <erus`> ok cool
03:37:00 <erus`> my solution for the spiral list thing is about 100 lines thus far :P
03:39:04 <edwardk> erus`: you did see the solution i hpasted right?
03:39:12 <erus`> yeah
03:41:06 <erus`> array *** Exception: Error in array index
03:41:17 <erus`> can i get the index that causes this?
03:42:22 <edwardk> erus' you can get the bounds of the array, and manually check inRange before you call !
03:42:35 <erus`> ah man
03:59:25 <hpaste> erus` pasted “snail problem” at http://hpaste.org/49741
03:59:29 <erus`> finished :D
04:02:34 <buntfalke> Hi
04:03:03 <buntfalke> What's suited to model larger functional projects? There's UML for e.g. C++, but it's not that good for a Haskell-based project -- any suggestions?
04:03:42 <ciaranm> buntfalke: you should first decide whether you need a formal modelling tool
04:03:55 <buntfalke> Inb4: No, I'm not a diagram fetishist, but it surely helps communicating what's meant if the type of boxes and figures drawn by everyone is defined, and "if you fail to plan, plan to fail"
04:03:59 <Jafet> UML models large projects by enlarging them
04:04:07 <Jafet> Are you sure you want that
04:04:35 <ciaranm> crc cards seem to work pretty well with haskell
04:04:40 <buntfalke> Jafet: As I said. It helps to sketch things up on paper first, and it helps to have some common base on how to do that
04:04:52 <buntfalke> ciaranm: thanks, will have a look.
04:04:53 <ciaranm> so long as you don't stick too closely to any supposed spec for them
04:05:30 <Jafet> Some people try to do as much as they can in the type system
04:05:45 <ciaranm> the type system is your friend
04:06:04 <int-e> > let r = transpose . reverse; s 1 = [[1]]; s n = ([1..n] :) . r . ([n+1..2*n-1] :) . r . map (map (+(2*n-1))) $ s (n-1) in text . tail . unlines . map (>>= printf "%3d") $ s 4
04:06:06 <lambdabot>    1  2  3  4
04:06:06 <lambdabot>   12 13 14  5
04:06:06 <lambdabot>   11 16 15  6
04:06:06 <lambdabot>   10  9  8  7
04:06:25 <Jafet> Well, those people are more than friends with it...
04:06:36 <ciaranm> friends with benefits!
04:07:59 <erus`> do people write code like that in real life>
04:08:01 <erus`> ?
04:08:18 <ciaranm> they write code like that in academia. dunno if that counts as real life.
04:08:36 <buntfalke> Talking about it: The type system: In object-orientation, a class defines functions operating on known data types. In Haskell, typesystem defines operations on types -- why isn't haskell called "object oriented"?
04:08:37 * ivanm sees ciaranm in here then double checks which channel he's in
04:09:15 <int-e> erus`: probably not on a single line. but the basic idea of building a spiral pattern by prepending rows and rotation (transpose . reverse  rotates a rectangular field encoded as a list of lists), I might actually do that.
04:09:26 <Jafet> buntfalke: object-orientedness involves a lot more than classes and functions.
04:09:32 <Jafet> http://paulgraham.com/reesoo.html
04:09:47 <Jafet> People disagree on what exactly it involves, but it generally involves a lot more than that.
04:09:54 <int-e> erus`: as long as performance is not an issue. (it's a cubic time algorithm for a problem that can obviously be solved in quadratic time)
04:10:20 <buntfalke> Jafet: thanks
04:10:31 <erus`> @t transpose
04:10:31 <lambdabot> Maybe you meant: tell thank you thanks thx ticker time todo todo-add todo-delete topic-cons topic-init topic-null topic-snoc topic-tail topic-tell type . ? @ ft v
04:10:38 <erus`> :t transpose
04:10:38 <lambdabot> forall a. [[a]] -> [[a]]
04:11:32 <ciaranm> i can't help thinking there's probably a really nifty recursive snail
04:12:02 <int-e> > (transpose [[1,2],[3,4]] {- reflect at the main diagonal -}, reverse [[1,2],[3,4]] {- reflect horizontally -}) -- and the composition of that gives a rotation by 90 degrees.
04:12:02 <lambdabot>   ([[1,3],[2,4]],[[3,4],[1,2]])
04:12:04 <Jafet> In particular, Haskell doesn't have stuff like record subtyping, and its implementations don't care much about encapsulating representations
04:14:10 <Jafet> Haskell with structural typing could be interesting, though
04:15:00 <ciaranm> c++0x concepts were going to be a lot like that, before they got nuked
04:15:32 <ion> erus: This returns the proper index given an array size and a 2D coordinate (components between 0 and size−1): https://gist.github.com/1117980
04:16:12 <ion> That should work very well with REPA backpermute.
04:16:58 <Jafet> C++0x is what you get when you take a bunch of neat new ideas about programming and whisper them to the next guy in the committee, who then whispers it on and on until it reaches the printer
04:17:24 <ciaranm> sadly true
04:18:19 <Jafet> And then everyone looks at the draft standard printout and wonders what the ideas were
04:19:11 <Jafet> buntfalke, do you have a particular large functional programming project in mind?
04:22:17 <kamaji> Possibly dumb question: why do foldl1 and foldr1 give the same results for this: foldr1 (.) [(+2), (*10)] 10
04:22:48 <Jafet> 10 is a function?
04:22:51 <kamaji> shouldn't the +2 come first for foldl1?
04:22:54 <Jafet> Oh
04:22:59 <ClaudiusMaximus> > foldr1 (.) [f, g] x
04:23:01 <lambdabot>   f (g x)
04:23:06 <ClaudiusMaximus> > foldl1 (.) [f, g] x
04:23:07 <lambdabot>   f (g x)
04:23:31 <kamaji> why isn't f applied first for foldl?
04:23:48 <ion> :t foldr1
04:23:51 <lambdabot> forall a. (a -> a -> a) -> [a] -> a
04:23:51 <ion> :t foldl1
04:23:55 <lambdabot> forall a. (a -> a -> a) -> [a] -> a
04:23:57 <ion> Meh, better:
04:23:59 <ion> :t foldr
04:24:00 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
04:24:00 <ion> :t foldl
04:24:01 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
04:24:08 <ion> (a -> b -> b) vs. (a -> b -> a)
04:24:20 <Jafet> (.) is associative
04:24:42 <ion> I.e. the accumulator comes in different parameters in the variants.
04:24:53 <int-e> > foldl ($) [f, g] x
04:24:54 <lambdabot>   Occurs check: cannot construct the infinite type: b = b1 -> b
04:24:59 <int-e> > foldl (flip ($)) [f, g] x
04:25:00 <lambdabot>   Couldn't match expected type `[[t] -> [t]]'
04:25:00 <lambdabot>         against inferred type `...
04:25:04 <Jafet> > foldr1 f [1..5] :: Expr
04:25:04 <lambdabot>   f 1 (f 2 (f 3 (f 4 5)))
04:25:07 <Jafet> > foldl1 f [1..5] :: Expr
04:25:08 <lambdabot>   f (f (f (f 1 2) 3) 4) 5
04:25:42 <Eduard_Munteanu> > map ($) [f, g] x :: Expr
04:25:43 <lambdabot>   Couldn't match expected type `SimpleReflect.Expr
04:25:43 <lambdabot>                           ...
04:26:16 <ion> erus: Did you notice the link?
04:26:33 <int-e> > (foldl (flip ($)) x [f, g, h], foldr ($) x [f, g, h])
04:26:34 <lambdabot>   (h (g (f x)),f (g (h x)))
04:27:37 <Eduard_Munteanu> That was stupid :)
04:27:45 <kamaji> still a bit lost :P
04:28:39 <Jafet> kamaji: there is no difference between (f . g) . h and f . (g . h)
04:28:42 <kamaji> oh wait I think I get it
04:28:59 <kamaji> I thought foldr went from the right-most item of the list
04:29:32 <Jafet> foldr works left-to-right, and foldl right-to-left.
04:29:47 <int-e> > take 10 $ foldl1 (.) (repeat (1:)) []
04:29:51 <lambdabot>   mueval-core: Time limit exceeded
04:29:53 <int-e> > take 10 $ foldr1 (.) (repeat (1:)) []
04:29:55 <lambdabot>   [1,1,1,1,1,1,1,1,1,1]
04:30:00 <kamaji> Jafet: but there is a difference between g . f and f . g
04:30:03 <kamaji> which is what I thought I was doing
04:30:06 * Jafet slaps int-e's bottom
04:30:19 <int-e> ouch. just saying, is all.
04:30:25 <Jafet> kamaji: but there is no g . f anywhere
04:30:28 <int-e> foldr1 is lazier than foldl1
04:31:06 <kamaji> Jafet: I basically wanted to take a list, [f, g, h] and get a function (h . g . f)
04:31:17 <Jafet> Then you wanted to (flip (.)).
04:31:33 <kamaji> I don't understand foldl and foldr very well
04:31:44 <Jafet> Evaluate them by hand and you will
04:31:58 <int-e> > foldl1 (flip (.)) [f, g, h] x
04:31:58 <Botje> eval: foldl (+) 0 [a,b,c]
04:32:00 <lambdabot>   h (g (f x))
04:32:03 <Botje> > foldl (+) 0 [a,b,c]
04:32:03 <lambdabot>   0 + a + b + c
04:32:08 <Botje> > foldr (+) 0 [a,b,c]
04:32:09 <lambdabot>   a + (b + (c + 0))
04:32:40 <hpaste> ciaranm pasted “too many newlines” at http://hpaste.org/49742
04:32:45 <ciaranm> ^^ i never quite figured out haskell's indenting rules... do i really need all those newlines in there (short of using {}s)?
04:32:49 <Jafet> And not like these bums, who use lambdabot to evaluate them by hand
04:33:14 <kamaji> ok, the paper is out~
04:33:15 <opqdonut> ciaranm: you don't need a newline after "where" or "do"
04:33:26 <opqdonut> ciaranm: I usually prefer to put a newline before "where", though
04:33:28 <ciaranm> opqdonut: then it moans about "empty do"
04:33:37 <Jafet> ciaranm: the stuff in the do block have to be indented after the do keyword
04:33:46 <ciaranm> ah
04:33:57 <ciaranm> that's even less readable :(
04:33:59 <hpaste> opqdonut annotated “too many newlines” with “too many newlines (annotation)” at http://hpaste.org/49742#a49743
04:34:05 <Jafet> That's a general rule of indentation
04:34:37 <kamaji> right, so the L/R refers to which argument to the function rather than which end of the list?
04:34:58 <ciaranm> i don't think i ever saw the indentation rules properly defined anywhere... think i just picked them up by looking at stuff and usually it works how i expect
04:35:28 <opqdonut> my annotation shows how I'd indent that
04:35:53 <int-e> Heh I actually prefer the original version.
04:35:59 <ciaranm> opqdonut: mm. the massive indenting on the return looks weird to me.
04:36:05 <opqdonut> if the do block were more complex I'd add a return before "do"
04:36:16 <ivanm> I'd typically start the [x,y] after the where
04:36:34 <Jafet> kamaji: look carefully at the lambdabot examples above; they completely describe the behaviour of the folds
04:36:50 <ivanm> (as in a new line)
04:36:53 <Jafet> Unfortunately, trying to explain the folds in words generally makes a mess of things
04:37:24 <int-e> see also http://foldr.com/ and http://foldl.com/ :)
04:37:26 <Jafet> ciaranm: if you think that code veers too quickly to the right, you haven't been reading enough code!
04:37:38 <mike-burns> If it looks ugly, define a helper function.
04:38:01 <ciaranm> Jafet: heh. i'm hopping around between languages lots at the moment. don't think anything else i've encountered indents that much.
04:38:16 <quicksilver> as it happens, ciaranm's example will look nicer with a list comp I think
04:38:32 <int-e> ... so I went and defined a helper function. It was ugly. I created a new module to encapsulate the function. But the code didn't get any prettier. ... :)
04:38:37 <ion> @tell erus` Updated (fixed some warnings since i had forgot to use -Wall). https://gist.github.com/1117980
04:38:37 <lambdabot> Consider it noted.
04:39:30 <kamaji> Jafet: Ok i think i've got it... I'm going to play around a bit though
04:39:33 <kamaji> cheers all
04:39:47 <hpaste> Jafet annotated “too many newlines” with “too many newlines (annotation) (annotation)” at http://hpaste.org/49742#a49744
04:40:14 <ciaranm> quicksilver: ooh, you're right about list comprehensions
04:40:15 <int-e> (... then I rewrote the code from scratch. The result was a mess of unspeakable horror. ... a programmer's nightmare.)
04:40:25 <mike-burns> Heh.
04:41:30 <hpaste> ciaranm annotated “too many newlines” with “too many newlines (annotation)” at http://hpaste.org/49742#a49745
04:42:21 <ciaranm> still... i feel like there should be some gratuitous monadery in there somewhere
05:03:24 <mietek> Is transformers part of the Haskell Platform yet?
05:04:09 <quicksilver> mietek: yes. http://lambda.haskell.org/hp-tmp/docs/2011.2.0.0/index.html
05:28:46 <joseanpg> :t Monad
05:28:48 <lambdabot> Not in scope: data constructor `Monad'
05:29:02 <joseanpg> :i monad
05:29:16 <joseanpg> :i Monad
05:30:17 <Eduard_Munteanu> @index Monad
05:30:17 <lambdabot> Control.Monad, Prelude, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont, Control.Monad.Error, Control.Monad.List
05:44:20 <tomh-> hmm if I do a cabal install for a program and it sais it misses 'uniplate -any' while it is listed in 'ghc-pkg list', what could be the problem (macosx)?
05:45:27 <dschoepe> tomh-: Are you trying to install something system-wide and have uniplate installed for your user only?
05:45:53 <tomh-> I just run runhaskell Setup.lhs configure
05:46:23 <tomh-> not sure which parts are systemwide
05:46:40 <int-e> tomh-: try  cabal configure  or  runhaskell Setup.lhs configure --user?
05:46:51 <tomh-> thanks lemme try
05:47:02 <int-e> (Cabal the library has different defaults than cabal(-install) the program)
05:47:02 <tomh-> looks like ghc-pkg list indeed returns user-specific packages
05:47:15 <int-e> And Setup.(l)hs is an interface to the former.
05:47:52 <tomh-> is there a way to install cabal packages systemwide?
05:49:09 <int-e> cabal install --global, but you must have write permissions. (and you risk messing up your global ghc installation, so that only a complete reinstall of ghc will recover from it, if you're not careful.)
05:50:22 <tomh-> ill take my chances :)
05:50:23 <tomh-> thanks
05:50:27 <int-e> (that being said I tend to use global installs exclusively because the confusion between user and global package databases has its own problems.)
05:55:07 <Negi> I heard some C people saying that "lazy evaluation = lazy programming"
05:55:24 <dafis> YAGNI is lazy programming
05:55:27 <Negi> are you guys gonna take that kind of trash talk
05:56:06 <Axman6> Negi: yes, and laugh while they take 10 times longer to implement the same things we can =)
05:56:38 <Negi> is that really true though
05:56:51 <Axman6> sure
05:56:55 <erus`> yes if you have been coding in haskelkl for atleast 8 years
05:56:55 <lambdabot> erus`: You have 1 new message. '/msg lambdabot @messages' to read it.
05:57:11 <Axman6> 8? more like 1
05:57:54 <Negi> the category theory relevant to haskell is extremely easy.. why is it presented in such an intimidating way in haskell?
05:58:37 <Negi> For instance, a monad based at A is a monoid in the strict monoidal category of endofunctors (with composition being the monoidal product) on A
05:58:56 <Negi> In haskell, it's some crazy nonsense
05:59:25 <coppro> Negi: How many average programmers have heard "monoidal" or "endofunctor" before, much less used them?
05:59:45 <dafis> 15
05:59:48 <Negi> an endofunctor is a functor from A to itself
05:59:49 <dafis> maybe 16
06:00:08 <coppro> Negi: /I/ know what they are
06:00:10 <Negi> and a strict monoidal category is a category with a product on objects
06:00:15 <yottis> depends on what counts as "average" :)
06:00:24 <Negi> and a strict monoidal unit
06:00:38 <coppro> Negi: but your random programmer does not
06:00:45 <yottis> and probably _all_ programmers have used them, not just explicitly realizing it
06:00:59 <Negi> (thankfully, we can do monads without the coherence issues that we have with strong monoidal categories)
06:01:11 <coppro> and, moreover, it is entirely possible to code Haskell, even well, without even knowing of the existence of the word endofunctor
06:01:15 <Axman6> are you trolling or what?
06:01:35 <Negi> but not without knowing the word functor
06:01:48 <coppro> actually, yes, you can do that too
06:01:49 <benmachine> you can definitely program in haskell without knowing any category theory whatsoever
06:02:08 <coppro> can't think of the last time I used either Functor or fmap in a real program
06:02:22 <benmachine> oh I use them all the time
06:02:23 <yottis> programming and knowing category theory seem almost conflicting :)
06:02:30 <benmachine> but I don't need to know what they *mean* :P
06:02:39 <coppro> benmachine: I know they're useful. I just haven't actually used them
06:02:41 <dafis> coppro: including Applicative and <$> ?
06:03:04 <dafis> or Monad and liftM?
06:03:08 <yottis> i know some basic concepts, but knowing more feel rather counterproductive - i don't think the time investment is worth it
06:03:08 <Negi> fwiw, yoneda became a computer scientist basically right after his description of the Ext functors
06:03:17 <coppro> dafis: none of those involve the word 'functor' anywhere
06:03:27 <Negi> a monad is a functor =.=
06:03:38 <sipa> :t (<$>)
06:03:39 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
06:03:44 <coppro> Negi: no it's not
06:03:52 <dafis> coppro: sure, just wanted to find out what you meant by not having used Functor or fmap
06:03:58 <Negi> coppro, yes it is
06:04:00 <coppro> Negi: haven't you looked at the typeclass hierarchy?
06:04:17 <benmachine> coppro: it depends what you mean by "monad", "functor", and "is a" :P
06:04:20 <Negi> if you're telling me that monads are not functors, then you are stupid
06:04:28 <benmachine> Negi: no need to take that tone
06:04:39 <tomh-> http://www.haskell.org/wikiupload/8/85/TMR-Issue13.pdf there is a nice article about category theory
06:05:07 <Negi> monads are not only functors, but endofunctors =.=
06:05:35 <coppro> http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#g:9
06:05:54 <Negi> if monads in haskell are not functors, then haskell should be revised so they are
06:05:55 <quicksilver> let's not argue about definitions, it's a waste of energy.
06:05:59 <benmachine> Negi: sure, but something in haskell can be an instance of Monad without being an instance of Functor
06:06:15 <benmachine> (many people think this is silly)
06:06:23 <quicksilver> monads are functors (mathematical); haskell Monads are not required to be Functors but should be.
06:06:25 <Negi> Then haskell's "typeclass hierarchy" is wrong
06:06:29 <coppro> (I happen to concur. I was just trolling)
06:06:37 <karlicoss1> how can i compare floating point variables with specified precision. I mean - is there a standard function, for example, greaterEps epsilon var1 var2?
06:06:39 <coppro> it is not wrong
06:06:41 <Negi> yeah
06:06:44 <coppro> it is simply suboptimal
06:06:54 <quicksilver> karlicoss1: abs (a-b) < epsilon
06:06:55 <Negi> no, it's morally, ethically, and aesthetically wrong
06:07:01 <dafis> karlicoss1: no standard function
06:07:05 <parcs> haha
06:07:15 <Axman6> wow
06:07:21 <coppro> Negi: k, so there's this organization I want you to meet. They might like your approach to things.
06:07:23 <karlicoss1> quicksilver: dafis: thanks
06:07:32 <Axman6> quicksilver: can we kick this guy yet? obvious (informed) troll is obvious
06:07:55 <Negi> who informed on me?
06:08:04 <MHD> Actually, to bud in in this discussion, Are the any Haskell Monads that can't be defined a functor?
06:08:09 <coppro> Negi: http://bit.ly/tB45
06:08:13 <coppro> Negi: now stop being a fuck
06:08:18 <Axman6> MHD: no, fmap = liftM
06:08:29 <MHD> exactly
06:08:52 <MHD> so isn't this all a bit pointless?
06:08:55 <Negi> lol, you clearly don't understand jokes
06:09:04 <Negi> @coppro
06:09:04 <lambdabot> Unknown command, try @list
06:09:15 <Axman6> we understand funny jokes...
06:09:27 <Axman6> time wasting nonsense isn't funny though
06:09:34 <coppro> I only laugh at funny ones
06:09:35 <MHD> Axman6: +1 sick burn
06:09:36 <Negi> claiming that something like a typeclass hierarchy could even be morally wrong
06:09:39 <coppro> Oh, Axman6 beat me to it
06:09:41 <dafis> Axman6: sometimes it is
06:09:49 <Negi> is obviously a joke
06:09:51 <Negi> duh
06:09:53 <coppro> Negi: no, it's not
06:09:55 <quicksilver> the meta-discussion is much more noisy than the original problem. Can we drop it, please.
06:10:37 <Negi> I don't understand how it could be understood to be anything but a joke =.=
06:11:06 <Axman6> because there are plenty of dumb fucks out there that do actually spout shit like that
06:11:38 * Negi cannot imagine that those people are not just kidding
06:11:53 <Axman6> go outside sometime
06:12:08 <dafis> Negi: believe it, a lot of them aren't pretending
06:12:13 <sipa> they can be kidding, they can deliberately be trying to cause controversy, they can be stupid
06:12:17 <Negi> I can't imagine anyone caring that deeply about a typeclass hierarchy
06:12:29 <EvanR7> one true heirarchy doesnt make much sense
06:12:43 <sipa> it's very hard to distinguish between those in a text-only medium
06:12:45 <EvanR7> removing the ability to redefine stuff would be morally wrong ;)
06:13:38 <Negi> Can haskell compute the nondegenerate simplices of a product of finite simplicial sets more easily than some other program?
06:13:57 <Negi> err
06:14:00 <Negi> language
06:14:08 <Negi> since it's category-theory-based and all
06:14:52 <Axman6> Can Haskell be used to find a way to stop Negi being such a douchbag, and reduce his self illusionary belief that he is in fact not a pathetic troll?
06:15:41 <Negi> and the question can be phrased categorically as asking for the full subcategory of the category of elements of the product spanned by the monomorphisms
06:16:07 <Negi> (since simplicial sets are presheaves on the simplex category, that is)
06:16:27 <Negi> Also, does haskell support a category of sets?
06:17:18 <Negi> (presheaves of sets, that is, functors Delta^op->Set)
06:17:35 <Negi> If haskell can talk about things like that, I'm actually interested
06:18:56 <Negi> because a lot of the annoying problems in writing programs to do computations like that is actually coming up with a model that you can program
06:19:19 <Negi> but if haskell supports category theory, perhaps it's easier to write things natively and such
06:20:01 <coppro> Haskell isn't really category-theory based
06:22:14 <MHD> Negi: Can I ask you a question?
06:22:45 <MHD> Negi: How long have you been programming haskell?
06:24:55 <Negi> not ever
06:25:03 <Negi> I have never programmed in anything
06:25:16 <frerich> Hmm, does it make sense to translate an eventloop system in a program written in an imperative language into a function where the 'event dispatcher' function gets an (possibly infinite) list of events, and that dispatcher function calls itself recursively? Or isn't that a good idiom in Haskell (or any functional language, for that matter)?
06:25:16 <Axman6> so why on earth are you here?
06:25:23 <Negi> well, I once wrote a shitty program to draw the 4th barycentric subdivision using processing.org
06:25:33 <JuanDaugherty> to put the Category Kibosh on Yous!
06:25:33 <Negi> because I couldn't draw it
06:25:41 <frerich> I just thought that it would be nice, but I don't know how to implement the 'wait for next event' part, so that the dispatcher function waits for a new event to be added to the event list, if any.
06:25:52 <EvanR7> frerich: it sounds good except you didnt specify a way to stop it when the program needs to end
06:25:56 <frerich> Or actually, now that I think about it, instead of having a list of events, a 'getNextEvent' function is probably all that's needed.
06:26:12 <JuanDaugherty> you fakers of the Mathesis you
06:26:20 <frerich> EvanR7: I was thinking of having a magical 'quit' event.
06:26:28 <quicksilver> frerich: I don't like the infinite list of events idea, because it can't possibly exist in advance
06:26:30 <Negi> I dunno, I thought that maybe haskell was useful
06:26:33 <EvanR7> frerich: for the purpose of ending the handler thread?
06:26:38 <frerich> EvanR7: Yep
06:26:47 <quicksilver> therefore you are probably inherently interleaving IO there into that list
06:26:47 * Negi is a category theorist
06:26:53 <MHD> Negi: Haskell is useful because it is a Turing complete language with a nice syntax
06:27:00 <benmachine> frerich: a possibly-infinite list of events doesn't sound likely to me
06:27:02 <EvanR7> frerich: well youll need to come up with other, different, magical ways to end other threads like it
06:27:08 <quicksilver> I think that's an ugly idea, but you're not alone in liking it
06:27:13 <benmachine> frerich: getNextEvent sounds more sensible
06:27:17 <quicksilver> there are some FRP libraries written along those general lines.
06:27:26 <EvanR7> translate the event handler directly from the imperative system
06:27:26 <MHD> Negi: It lets you do the same things as other languages but with a different syntax that looks like mathematic formulae if you squint
06:27:27 <benmachine> oh I'm basically saying what quicksilver said
06:27:33 <benmachine> serves me right for skimreading
06:27:35 <quicksilver> benmachine: happens all the time :)
06:27:44 <Negi> well, has anyone ever attempted to implement category theory as a programming language or something
06:27:51 <benmachine> quicksilver: :P
06:27:58 <Negi> I dunno, I guess like a CAS for category theory or something
06:28:00 <EvanR7> math isnt a programming language
06:28:03 <Negi> ya
06:28:03 <MHD> Negi: If you want to do category theoretic things, then haskell is probably a good choice
06:28:06 <Negi> but it's better
06:28:30 <MHD> Negi: But remember that haskell is a real programming language that programmers write software in.
06:28:41 <coppro> I don't think Haskell would be better for modeling computations on categories, really
06:28:53 <Negi> oh..
06:28:56 <MHD> Negi: Maybe haskell is for you, meybe it isn't, you won't know until you try
06:28:58 <Negi> then what's all the fuss about
06:29:15 <coppro> Haskell applies category-theoretical concepts in common APIs
06:29:20 <Negi> oh
06:29:23 <Negi> that sounds awful
06:29:28 <coppro> it's quite nice actually
06:29:36 <MHD> Better than it sounds
06:29:53 <Negi> I don't know what an api is though
06:30:08 <MHD> Application Programmers Interface
06:30:23 <MHD> The stuff that lets you do something more interesting than arithmetic
06:30:24 <JuanDaugherty> dayum
06:30:30 <Eduard_Munteanu> Negi: if you're interested in theorem proving you might want to take a look at Agda
06:30:30 <Negi> yeah but somehow that means nothing if you've programmed as little as I do
06:30:53 <Eduard_Munteanu> However I'm not sure what a CT-oriented CAS would do.
06:30:55 <Negi> as I have, rather
06:31:01 <coppro> Negi: basically the way Haskell applies category theory is by allowing abstractions within the code
06:31:14 <MHD> Negi: Learning to program in ANY language will make you better at math.
06:31:24 <coppro> for instance, many langauges have an abstraction to deal with containers of objects
06:31:28 <JuanDaugherty> wtf is CAS?
06:31:33 <Negi> yeah but it won't make me better at math than doing math
06:31:36 <coppro> since there are certain things all containers have in common (namely, they contain things)
06:31:38 <Negi> computer algebra system
06:31:43 <JuanDaugherty> ah
06:32:01 <coppro> Haskell has abstractions for category-theoretical concepts, like functors and monads
06:32:05 <Eduard_Munteanu> @google Maxima
06:32:05 <JuanDaugherty> some of the best of those tend to be in lisp
06:32:05 <lambdabot> http://maxima.sourceforge.net/
06:32:05 <lambdabot> Title: Maxima, a Computer Algebra System
06:32:06 <Axman6> think mathematics of expensive TI calculators
06:32:09 <coppro> which, due to historical accident, are not actually related
06:32:18 <Eduard_Munteanu> (for example)
06:32:43 <Negi> wearing my category-theorist-hat, I think that is an affront to my field
06:32:50 <erus`> @google recursion
06:32:50 <EvanR7> lol
06:32:50 <lambdabot> http://en.wikipedia.org/wiki/Recursion
06:32:50 <lambdabot> Title: Recursion - Wikipedia, the free encyclopedia
06:32:55 <coppro> it's an affront t making code shorter too
06:32:59 <coppro> *to
06:32:59 <Negi> but wearing me not-being-a-troll hat, I just find it annoying
06:33:07 <frerich> quicksilver, benmachine, EvanR7: Sorry, I might have overlooked some of your replies (thanks!) in this chat, quite a bit of traffic right now. Anyway, you all agree that using a list of events is not as nice as having a recursive event dispatcher function which is given some sort of 'fetch next event' function which either yields an event, or some value which indicates that the event loop should terminate?
06:33:12 <MHD> Negi: Go read this http://learnyouahaskell.com/, then come back to us
06:33:13 <coppro> I don't think anyone likes it the way it is
06:33:27 <coppro> it's just that going and changing it would break everyone's code
06:33:27 <Negi> then why don't you just fix it?
06:33:43 <MHD> Negi: Also, you are a purist trying to convert other purists.
06:33:43 <sipa> what would 'fixing' mean?
06:33:46 <sipa> just changing it?
06:33:53 <EvanR7> frerich: hide the imperative i/o parts of the code away from the good stuff, including the event dispatch system. just translate it directly from the original C code or whatever
06:34:00 <coppro> breaking people's code is like the #2 programming sin
06:34:09 <saati> Negi: lots of old code depends on how things are
06:34:10 <coppro> #1 is writing code
06:34:20 <MHD> There is no Perfect in programming, only Good Enough
06:34:22 <erus`> #3?
06:34:28 <Negi> sure, then in the latest version of the compiler, change it, but allow it to be compiled in compatibility mode with a flag
06:34:29 <Eduard_Munteanu> There are alternate Prelude implementations which are more math-oriented/correct
06:34:31 <EvanR7> MHD: unless im writing the code
06:34:31 <coppro> sipa: It would hopefully not matter for most code
06:34:40 <coppro> Negi: Then people would just turn on the flag
06:34:43 <coppro> and you've gotten nowhere
06:34:46 <Negi> some peopel
06:34:51 <coppro> every language has this problem
06:34:52 <sipa> the perfect is the enemy for the good
06:34:56 <sipa> *of
06:34:57 <Eduard_Munteanu> Negi: it's not about the compiler
06:35:01 <Negi> yeah but so is the bad
06:35:07 <coppro> oh, and there are multiple Haskell compilers
06:35:07 <Eduard_Munteanu> It's just the standard library.
06:35:09 <Negi> the bad is the enemy of the good too
06:35:10 <MHD> Negi: You are a religious person trying to convert other religious people...
06:35:14 <coppro> and multiple standard libraries
06:35:23 <MHD> Negi: You feel strongly and we feel strongly.
06:35:27 <Negi> I'm not religious
06:35:34 <Negi> I'm not even advocating a viewpoint
06:35:41 <MHD> Negi: It's a metaphor
06:35:45 <Negi> no
06:35:55 <Negi> I mean in this back-and-forth we're having this fine morning
06:35:58 <MHD> Negi: You think category theory is bad in a language like haskell
06:35:59 <Negi> I have not taken a position
06:36:04 <Negi> what no
06:36:05 <MHD> Negi; We think it is great
06:36:21 <sipa> your viewpoint is that adhering to the mathemetically reality of functors and monads is the highest good
06:36:33 <Negi> sure
06:36:37 <sipa> few people will disagree that that would be a good thing
06:36:37 <Axman6> you haven't taken a position? ha
06:36:44 <MHD> Ours is that Category theoretic abstractions are awesome
06:36:55 <MHD> No one will yield in this discussion
06:36:58 <Negi> can haskell deal with 2-categories?
06:36:58 <sipa> but most people won't consider it priority compared to other problems, like backward compatibility
06:37:00 <nihtml`> @pl f n = length . filter (==n)
06:37:00 <lambdabot> f = (length .) . filter . (==)
06:37:03 <Axman6> "This thing I have never used is shit because it's not perfect" is most certainly a position
06:37:14 <Negi> I don't think I ever asserted it
06:37:17 <MHD> So why don't we drop it, so that Negi can go do his mathematics thing
06:37:18 <Negi> (that it was shit)
06:37:19 <erus`> is there a haskell in haskell compiler/interpretter ?
06:37:26 <MHD> And we can go do our Haskell thing
06:37:34 <sipa> erus`: ghc is written in haskell
06:37:40 <quicksilver> erus`: well, ghc is that to some extent. What did you mean exactly?
06:37:41 <Axman6> erus`: see mueval, it's what lambdabot uses
06:37:43 <coppro> Negi: Haskell has no real representation of an arbitrary category more than any other
06:38:13 <Negi> sure, but why couldn't you implement it?
06:38:22 <Negi> using lazy evaluation
06:38:27 <sipa> @hoogle category
06:38:27 <lambdabot> module Control.Category
06:38:27 <lambdabot> Control.Category class Category cat
06:38:27 <lambdabot> Data.Char data GeneralCategory
06:38:28 <erus`> i thought ghc was written in C :S
06:38:29 <Negi> you have axioms and such
06:38:38 <Axman6> erus`: no
06:38:47 <Axman6> GHc is almost entirerly written in haskell
06:38:53 <coppro> Negi: Haskell doesn't do category theory that way. It's certainly implementable, it's just not what Haskell uses category theory for
06:38:58 <coppro> Negi: I apologize for saying this...
06:39:01 <Axman6> GHC* entirely*
06:39:04 <coppro> but Haskell applies category theory
06:39:09 <erus`> Axman6: whats the other language?
06:39:32 <Axman6> the RTS has a lot of C (because it needs to to be able to do things like IO)
06:39:37 <MHD> Negi: Won't you please stop pestering us about this?
06:39:46 * Negi scratches his head
06:39:54 <MHD> Negi: Nothing good comes of this discussion
06:39:58 <Negi> MHD I wasn't pestering anyone
06:40:01 <Negi> are you like 12 years old
06:40:02 <coppro> MHD: he and I are having a reasonable conversation
06:40:04 <Axman6> Negi: Haskell was not written to please you. accept that and move on
06:40:14 <Negi> I am not fucking complaining, you idiot
06:40:19 <Negi> I am asking about haskell
06:40:22 <erus`> trololol
06:40:26 <MHD> Negi: I'm 18, thank you
06:40:29 <JuanDaugherty> if it's implemented category theory maybe it should be called "MacLane"
06:40:44 <Eduard_Munteanu> @hoogle trololol
06:40:45 <lambdabot> No results found
06:40:47 <coppro> Negi: I'm trying to think of a good way to explain how Haskell uses category theory
06:40:47 <Eduard_Munteanu> @google trololol
06:40:48 <MHD> Negi: And I am beginning to doubt that you are intending to have a constructive discussion
06:40:48 <lambdabot> http://trololololololololololo.com/
06:40:48 <lambdabot> Title: TROLOLOLOLOLOLOLOLOLOLO
06:40:50 <Negi> okay, then stop whining at me incessantly like a schoolgirl
06:41:01 <Negi> I was talking to coppro
06:41:01 <quicksilver> let's focus on discussing programming and possibly programming languages
06:41:09 <quicksilver> leave the rest out please
06:41:38 <erus`> autism is loosely coupled with programming
06:41:39 <JuanDaugherty> did somebody mention theres a #category-theory?
06:41:44 * Axman6 resists the urgh to make more snarky comments
06:41:47 <EvanR7> erus`: hehe
06:41:48 <djahandarie> There is a ##categorytheory
06:41:52 <coppro> Negi: I think we should move to private conversation
06:41:58 <geheimdienst> Axman6: thanks
06:42:08 <Axman6> erus`: heh, using that word in here gets you into trouble (rightfully so though)
06:42:28 <Negi> yeah, because the whiners in here have PTSD from all of the actual trolls that come in here
06:42:34 <benmachine> Axman6: rightfully so?
06:43:00 <Axman6> Negi: we get very few trolls, you're the first i've seen in a very long time
06:43:17 <benmachine> oh we get fairly many trolls, but we're usually quite good at dealing with them and don't rise to it
06:43:23 <Axman6> and don't delude yourself into thinking you're not one
06:43:24 <benmachine> lots of you dropped the ball on that this time :p
06:43:28 <JuanDaugherty> that's my perception, lisp gets a lot more
06:43:33 <sipa> coppro, Negi: as an attempt to explain... (some) haskell (libraries) are based on category theory from a design point of view - that doesn't make it particularly good (nor bad) for modelling category theoretical concepts itself in the language
06:43:39 <benmachine> Axman6: "delude yourself" is inflammatory language if you ask me
06:43:49 <Axman6> it probably is
06:44:04 <benmachine> sipa: however, the fact that lots of people interested in CT are also interested in haskell gives us good library support
06:44:11 <benmachine> or at least, might do, I've never tried
06:44:13 <osfameron> that trolololololo link is excellent.  So at least *something* good came out of the previous discussion, thanks.
06:44:17 <Axman6> but if you enter a channel and within minutes multiple people are calling you a troll, and you still think you aren't one, you're deluding yourself
06:44:27 <benmachine> Axman6: no, you're trolling :P
06:44:32 <quicksilver> #haskell-blah is a great place for meta-discussions, #haskell isn't.
06:44:39 <benmachine> ok ok
06:44:40 <Eduard_Munteanu> I'm still unsure what he's after.
06:44:44 <quicksilver> if you want to discuss what is and what isn't a troll, please find somewhere else to do so.
06:45:09 <benmachine> so guys, is http-enumerator usable for lightweight work? or is it soemthing to be used only when you need its power?
06:47:33 * Axman6 -> sleep, doesn't need this shit when he's as sick as a dog
06:50:26 <byorgey> Negi: I don't know what it would mean for Haskell to "support 2-categories" in general, but it does support one particular 2-category called Hask
06:50:26 <lambdabot> byorgey: You have 3 new messages. '/msg lambdabot @messages' to read them.
06:50:48 <byorgey> Negi: objects are types; 1-morphisms are functions between types; and 2-morphisms are polymorphic functions
06:51:23 <djahandarie> 2-morphisms are polymorphic functions? Haven't seen that before
06:51:29 <Eduard_Munteanu> Something like Agda might be better if you're interested in working with arbitrary categories.
06:51:46 <benmachine> data ResponseNextStep = ... | DieHorribly String
06:51:50 * benmachine giggles
06:51:57 <benmachine> (Network.HTTP)
06:52:24 <byorgey> djahandarie: aren't they?
06:52:34 <byorgey> polymorphic functions correspond to natural transformations
06:52:57 <byorgey> I might be confused
06:53:13 <byorgey> oh, wait, yes, I am confusing levels, sorry
06:53:40 <karlicoss1> is there a compile option to disable trace output?
06:53:54 <byorgey> Hask is like Set, whereas NT's are 2-morphisms in Cat
06:54:24 <byorgey> karlicoss1: trace output? like from Debug.Trace?
06:54:40 <karlicoss1> byorgey: yep
06:55:01 <byorgey> karlicoss1: no, I don't think so.  There is nothing special about the Debug.Trace module as far as the compiler is concerned
06:55:08 <Eduard_Munteanu> So what are polymorphic functions? Just particular arrow sets?
06:55:24 <karlicoss1> byorgey: there is, it avoids IO :)
06:55:44 <byorgey> karlicoss1: no, trace and friends are just implemented with unsafePerformIO
06:56:02 <byorgey> the compiler just provides unsafePerformIO, it does not know anything about Debug.Trace
06:56:27 <byorgey> Debug.Trace is designed just for inserting quick debugging statements that you take out again once you have found the bug
06:56:45 <byorgey> if you want a real logging framework you should use something like hslogger
06:57:31 <karlicoss1> byorgey: thanks, logging is what i am searching for
06:57:42 <byorgey> http://hackage.haskell.org/package/hslogger
06:57:50 <hpaste> kizzx2 pasted “fundep confusion” at http://hpaste.org/49746
06:58:43 <erus`> could a stack based language be pure?
06:58:52 <byorgey> Eduard_Munteanu: well, yes, but they are much more special than that
06:59:25 <Eduard_Munteanu> I think I heard something about natural transformations in that context too.
06:59:29 <byorgey> Eduard_Munteanu: in particular they always correspond to natural transformations
06:59:30 <Eduard_Munteanu> Maybe parametricity?
06:59:34 <byorgey> yes, exactly
06:59:36 <Eduard_Munteanu> Ah.
07:00:11 <byorgey> intuitively, parametricity says that polymorphic functions must "behave uniformly" for all type arguments
07:00:22 <EvanR7> erus`: if youre talking about the stack being a state, you can have 'pure' state, like State
07:00:27 <byorgey> and this is the intuitive content of the notion of natural transformation as well
07:00:47 <kizzx2> hello, i wonder why this compiles ?? http://ideone.com/JEUVN              i thought the whole point of fundep `a b -> c` is to restrict c in terms of a and b? (read this from wikibooks)
07:01:00 <Eduard_Munteanu> Is there any article describing that correspondence in detail? I don't think Wadler's paper does that, IIRC.
07:01:15 <Eduard_Munteanu> s/article/resourse/
07:01:21 <Eduard_Munteanu> *resource, bah :)
07:01:51 <bscarlet> kizzx2: what do you think should go wrong?
07:01:51 <byorgey> kizzx2: the fundep 'a b -> c' means that for a given choice of a and b, there cannot be two instances with different c's
07:02:29 <kizzx2> byorgey: thanks, that's a new concept me
07:04:27 <kizzx2> this wikibook page https://secure.wikimedia.org/wikibooks/en/wiki/Haskell/Advanced_type_classes uses such an example              "fundep can prevent nonsensical instance of Mult, such as         instance Mult Matrix Matrix (Maybe Char) where"
07:04:36 <kizzx2> however, that example compiles with FlexibleInstances
07:05:47 <quicksilver> kizzx2: yes, it prevents such a nonsensical instance IF you've already written the correct instance first :)
07:06:09 <quicksilver> so if you'd already written instance Mult Matrix Matrix Matrix then the Maybe Char one would be an error.
07:06:40 <kizzx2> quicksilver: o thats it, thanks!
07:06:52 <kizzx2> so it's a restriction among multiple instances
07:07:12 <quicksilver> exactly.
07:10:14 <kizzx2> great, totally clear now :)
07:13:24 <saati> what happens when a functor does not keep the functor laws?
07:13:51 <quicksilver> the world ends.
07:13:55 <quicksilver> or, nothing.
07:14:00 <dafis> one second earlier
07:14:00 <Jaak> it's just no longer a functor in mathematical sense
07:14:07 <kizzx2> saati: i suppose functor functions like fmap and friends break down and you can't predict what they'll do
07:14:11 <quicksilver> it's actually quite hard to write one which violates them badly
07:14:23 <quicksilver> due to fmap being polymorphic
07:14:26 <mokus> is it even possible?  I thought the functor laws were satisfied by free theorems for the type of fmap?
07:14:30 <dafis> and code expecting that all instances adhere to the laws will break when using it
07:14:55 <saati> i'm thinking about a quad-tree that drops objects that are out of the roots bounding box
07:15:17 <saati> fmap (g . h) won't be fmap g . fmap h if you scale somethng up than down
07:16:13 <saati> oh okay i can't make it a functor
07:16:26 <saati> because of the typeclass restrictions right?
07:16:35 <benmachine> mokus: I think if you prove one then you prove the other
07:16:37 <benmachine> I forget which
07:16:44 <benmachine> or maybe that's not true
07:16:55 <benmachine> but anyway they are easy to break for some types
07:16:57 <parcs> :t let fmap _ _ = Nothing in fmap :: (a -> b) -> Maybe a -> Maybe b
07:16:58 <lambdabot> forall a b. (a -> b) -> Maybe a -> Maybe b
07:17:01 <mokus> yea, i guess i was just mistaken on that anyway, fmap id == id seems easy enough to violate
07:17:13 <benmachine> e.g. instance Functor [] where fmap f xs = reverse (map f xs)
07:17:27 <benmachine> but
07:17:35 <benmachine> mostly they are hard to break /by accident/
07:17:58 <benmachine> there's usually exactly one correct instance, and it can be written mechanically
07:18:01 <benmachine> hence DeriveFunctor
07:19:14 <byorgey> fmap id = id   implies   fmap (f . g) = fmap f . fmap g
07:19:25 <byorgey> via the free theorem/parametricity for the type of fmap
07:19:36 <byorgey> but it is possible to write a Functor instance for which  fmap id /= id
07:20:47 <bscarlet> saati: why build the dropping into the data structure? Would it suit your purposes to make your quadtree a look like Map Coord a (in terms of its interface) and do the dropping as an explicit operation?
07:20:48 <byorgey> this is actually a nice result in practice; if you write a Functor instance you need only check that fmap id = id, which is usually very easy to check
07:21:52 <Eduard_Munteanu> Presumably such a Functor goes to functor prison :P
07:22:16 <Jaak> and forever shall it map bottoms
07:22:31 <Eduard_Munteanu> fmap, even
07:23:35 <quicksilver> byorgey: it's quite hard to write a functor instance for which fmap id /= id in a remotely interesting way.
07:23:55 <quicksilver> obvoiusly fmap f = undefined is possible
07:24:07 <saati> bscarlet: thanks, good idea
07:24:08 <ezyang> i,i unsafeCoerce#
07:24:33 <byorgey> fmap f [] = []; fmap f (x:xs) = f x : f x : fmap f xs    is my favorite example
07:24:34 * hackagebot fuzzytime 0.7.4.1 - A 'ten past six' style clock  http://hackage.haskell.org/package/fuzzytime-0.7.4.1 (KamilStachowski)
07:24:42 <byorgey> I don't know if you would consider that "remotely interesting"
07:25:12 <quicksilver> byorgey: oh, clever.
07:25:17 <Jaak> what about fmap for singleton type? i think you can fail with strictness quite easily
07:26:30 <byorgey> quicksilver: but duplicating/deleting elements is about the only thing you can do
07:26:42 <byorgey> or switching around their order
07:26:45 <Jaak> if |fmap f = Unit . f . unUnit| then |fmap id \bot != \bot|
07:27:02 <c_wraith> != ??  you mean /= ?
07:27:11 <Jaak> aye
07:27:41 <mokus> c_wraith: doesn't matter, /= wouldn't yield false in that case anyway so it's obviously an outside-the-language inequality
07:28:55 <byorgey> Jaak: true.  In fact, I don't even know whether my statements earlier about free theorems hold in the presence of _|_
07:29:12 <byorgey> if you care about strictness and undefined then you have to be a bit more careful.
07:30:06 <mokus> c_wraith: and by false of course I mean True ;)
07:35:32 <benmachine> you could break a Functor instance by composing either before or afterwards with any fully polymorphic function f a -> f a
07:35:39 <benmachine> (non-identity)
07:36:04 <benmachine> well, due to free theorems, before = afterwards I guess :P
07:40:39 * hackagebot HROOT 0.5.0.3 - Wrapper for ROOT  http://hackage.haskell.org/package/HROOT-0.5.0.3 (IanWooKim)
07:41:00 <totimkopf1> hi guys :)
07:42:01 <byorgey> hi totimkopf1
07:42:11 <Ke> how do I state type on a <- mallocArray 1
07:42:20 <benmachine> Ke: type of what?
07:42:23 <Ke> a
07:42:28 <quicksilver> a <- mallocArray 1 :: IO something
07:42:31 <quicksilver> where something is the type of a
07:42:36 <Ke> thanks
07:42:38 <quicksilver> is the h98-compliant way
07:42:47 <quicksilver> you don't normalyl need to because something else will force the type
07:42:51 <quicksilver> (in most common use cases)
07:42:58 <totimkopf1> are functional languages more resource intensive than non-functional languages? because of the high abstraction?
07:43:00 <quicksilver> you can use -XPatternSignatures to put a type directly on the a.
07:43:29 <benmachine> totimkopf1: abstracted languages are often more resource-intensive than non-abstracted languages
07:43:29 <quicksilver> totimkopf1: typically, yes, although not as much as you'd think - and it's perhaps more because of the relative immaturity of the compilers than anything else.
07:43:44 <benmachine> but functional langauges aren't generally worse than, say, python or ruby
07:43:47 <benmachine> if anything they can be better
07:44:04 <benmachine> (assuming for the moment that you don't think python/ruby is functional)
07:44:40 <totimkopf1> benmachine: yes, I'm aware that those languages aren't functional
07:44:55 <totimkopf1> they're slow because they're interpreted I guess?
07:45:02 <benmachine> totimkopf1: it depends what you think of as functional
07:45:29 <benmachine> oh also, pedants will point out that languages aren't slow, implementations are :)
07:45:34 <totimkopf1> xpath, haskell, scheme...hmm
07:46:00 <benmachine> so it doesn't necessarily make sense to say that "haskell is faster than python" but rather "GHC is faster than cpython"
07:46:04 <benmachine> if you see what I mean
07:46:17 <benmachine> although, some languages are more amenable to optimisation than others
07:46:23 <totimkopf1> yes, putting blame on the compilers/interpreters
07:46:56 <sipa> benmachine: aren't some languages inherently slower than others?
07:47:23 <benmachine> sipa: hmm. maybe.
07:47:28 <sipa> like a turing machine has a higher best-case complexity (in number of execution steps) for some algorithms than a ram machine
07:47:43 <benmachine> well, those are machines, not languages :)
07:47:52 <danharaj> Machines and languages are not different.
07:47:54 <sipa> you can consider them to be languages, i guess
07:48:15 <quicksilver> measuring execution steps is tied to a model of machine, though
07:48:16 <benmachine> danharaj: but in theory a compiler could compile a program written for a turing machine to one written for a ram machine or vice versa, right?
07:48:24 <quicksilver> while all turing complete languages can be compiled into each other
07:48:33 <quicksilver> so any can be compiled to any appropriate machine
07:48:46 <benmachine> right
07:48:47 <quicksilver> it's more compilation techniques than languages which have hard complexity limits
07:49:48 <sipa> compiling a turing machine into a ram machine with better complexity will on itself take at least as long as the turing machine would need to do it in the first place, i guess
07:49:56 <sipa> for general programs
07:50:22 <benmachine> sure, but compiling can take as long as you like :P
07:50:34 <sipa> oh in that case
07:50:42 <quicksilver> benmachine: not so :)
07:50:49 * benmachine frequently writes programs that have a shorter runtime than compilation time
07:50:54 <quicksilver> benmachine: formal complexity theorists will always include the cost of compilation
07:51:07 <quicksilver> otherwise you can special case the compiler to produce constant-time running for key examples
07:51:15 <benmachine> hm, ok
07:51:35 <sipa> or for all possible inputs, if the compilation step is allowed to take infinite time and memory
07:51:43 <quicksilver> if prog == "ultimate question" then putStrLn "putStrLn \"42\"" else ...
07:51:54 <benmachine> quicksilver: but surely that would be a slow program?
07:51:57 <benmachine> in general
07:52:15 <quicksilver> well
07:52:16 <benmachine> you can special case for certain examples but why would you want to
07:52:22 <mux> seven and a half million years
07:52:29 <quicksilver> for more interesting examples imagine a compiler which precomputes massive lookup tables
07:52:57 <mokus> special casing is enough to provide a sublanguage known to be optimized on the target machine
07:53:09 <benmachine> quicksilver: but that would take large amounts of memory, no?
07:53:18 <quicksilver> yes
07:53:21 <quicksilver> depends on model, etc.
07:53:24 <mokus> so as long as the end programer only uses those special cases they can be sure of getting the better runtime complexity offered by the target machine
07:53:35 <sipa> it may just involve running the program after compilation on a few inputs
07:53:36 <quicksilver> in general these things only matter in order to exclude clever tricks :)
07:53:41 <benmachine> heh
07:53:43 <sipa> and breaking off after some time passed
07:54:52 <mokus> for that matter, the "special case" can just be a single interpreter for a RAM-machine
07:55:01 <benmachine> well, anyway. I think it's fair to say that python lets you do so much weird reflection stuff that probably a given program would need more time and space in order to do all that plumbing
07:55:22 <mokus> and so long as your program consistse of just that interpreter and the data for it, "optimization" consists of ignoring that interpreter and compiling the code it would have interpreted
07:55:27 <benmachine> any program with an eval that accepts user input is also going to be very difficult to optimise extensively
07:56:07 <quicksilver> benmachine: just embed the optimiser!
07:56:12 <benmachine> :o
08:01:40 <mokus> benmachine: if you're referring to my suggestion, the eval wouldn't be accepting user input - it would be accepting a hard-coded program as data inside the outer program
08:02:06 <stobix> Hm. I just told ghci to do something really stupid, brute-forceish and memory-hogging. Pressing ^C made it stop calculating, but it refuses to let go of the memory it ate. Can I tell it to garbage collect somehow? :)
08:02:58 <benmachine> mokus: I'm not, I'm referring to the idea that "python is slow"
08:03:20 <benmachine> stobix: which GHC version are you using?
08:03:23 <quicksilver> stobix: garbage collectoin won't let go of the memory
08:03:34 <quicksilver> IIRC, ghc will never let go of memory
08:03:38 <quicksilver> although it will re-use it
08:03:44 <quicksilver> except in some very recent version
08:04:04 <mokus> benmachine: ah, ok.  I tend to agree, especially if the eval's environment has to be able to access things in scope at eval's call site
08:04:36 <mokus> if it doesn't though, then existence of eval need not make the outermost scope slow
08:04:37 <benmachine> mokus: yeah, that was what I was thinking - your ability to inline, throw away metadata, whatever, is limited
08:04:38 <stobix> benmachine: 6.10.4
08:04:44 <roconnor> What's the difference between Naperian functors and Representable functors (in Haskell)?
08:04:59 <benmachine> stobix: ah, back then GHC didn't release memory to the OS, sorry
08:05:00 <mokus> benmachine: yea, you have to be able to reflect an awful lot on demand
08:05:06 <stobix> quicksilver: oh. :/
08:05:18 <benmachine> stobix: I think GHC 7 does
08:05:36 <stobix> benmachine: oh, shucks. And I just downgraded it to get the haskell platform installed..
08:05:45 <benmachine> stobix: :o why would you do that?
08:05:48 <quicksilver> stobix: well it doesn't matter in practice
08:05:50 <benmachine> there are platforms for later versions I am sure
08:06:03 <quicksilver> stobix: you shouldn't really care how much memory ghci is holding on to
08:06:13 <quicksilver> assuming you're using an OS with virtual memory
08:06:24 <bscarlet> (and have swap)
08:06:35 <stobix> benmachine: not in portage, I think. :) But I'll ask on #gentoo-haskell...
08:06:56 <benmachine> gentoo is pretty good at keeping up, I think?
08:06:56 <mokus> stobix: it's probably in the haskell overlay by now, though i'm not 100% sure of that
08:07:12 <benmachine> even *ubuntu* is on 6.12 by now >_>
08:07:29 <benmachine> (although you might need 7 actually)
08:07:30 <mokus> benmachine: the main portage usually lags a bit, but there's a haskell overlay which is usually pretty close to the bleeding edge
08:07:44 <benmachine> mokus: oh right, that's probably what I meant
08:08:15 <stobix> quicksilver: The thing I'm concerned with is that I still have very little free RAM left. I guess ghc hasn't been swapped out or something, perhaps...
08:08:43 <benmachine> it only gets swapped out when you need it, doesn't it?
08:09:05 <stobix> I DO need it. :)
08:09:27 <bscarlet> stobix: pages are swapped out, not processes.
08:09:43 <quicksilver> stobix: on a virtual memory system 'free RAM' is not a useful concept
08:09:48 <quicksilver> you will often appear to have no free RAM
08:10:07 <quicksilver> but when you try to use something, the OS will discard some not very recently used pages
08:10:16 <quicksilver> and magically you'll have more space
08:10:24 <sipa> a good operating system should always try to use all your RAM
08:10:39 <quicksilver> the natural running state of a VM OS is around zero free ram - the RAM will contain disk caches + footprints of all your most recently used apps
08:12:35 <ptd> :t (\(f :: x -> x) -> f)
08:12:36 <lambdabot>     A pattern type signature cannot bind scoped type variables `x'
08:12:36 <lambdabot>       unless the pattern has a rigid type context
08:12:36 <lambdabot>     In the pattern: f :: x -> x
08:13:32 <ptd> :t (\f -> f) :: (x -> x) -> x -> x
08:13:33 <lambdabot> forall x. (x -> x) -> x -> x
08:13:54 <ptd> What's wrong with "(\(f :: x -> x) -> f)"
08:14:09 <stobix> quicksilver: well, that discarding process takes a lot of time, and makes everything runs slowly. Having to wait ~10-30 minutes instead of just shutting down the program going haywire does not really float my boat, so to say.
08:14:24 <quicksilver> stobix: it shouldn't be anything like that
08:14:53 <quicksilver> pages which are already in sync with their disk copy can be discarded with no work; zero pages can be discarded with no work.
08:15:04 <quicksilver> other pages just have to be written to disk which is a few seconds work at most.
08:15:30 <bscarlet> quicksilver: but loading everything else that got swapped out to make room back in does take time.
08:15:46 <stobix> exactly
08:16:18 <quicksilver> yes
08:16:27 <mokus> and that time is unavoidable: it has to be taken whether the program that stole the memory is still running or not
08:16:46 <quicksilver> as mokus said. That had to happen even if ghci *did* return the memory it jsut took
08:16:53 <quicksilver> you already swapped them out when ghci was big.
08:16:56 <mokus> so if the fact that ghci is still running makes a difference, then ghci is probably not actually done with the memory you think it's done with
08:17:01 * stobix is a little sad that he didn't take the course in operating systems. would have been good to really know in-depth how these things work...
08:17:49 <stobix> mokus: that's the thing! ghc think it's not yet done with the memory, eventhoungh it should be.
08:18:07 <stobix> so I get a lot of swapping back and forth as I swap back and forth between programs
08:18:28 <mokus> stobix: I don't know about current versions of GHC, but in older ghci's anything that is bound by a 'let' at the prompt will be retained forever
08:18:34 <benmachine> stobix: upgrade to GHC 7 because it's awesome anyway :P
08:18:35 <byorgey> ptd: giving a type annotation to an expression is different than giving one to a pattern
08:18:38 <mokus> or at least until the next :lead
08:18:41 <mokus> :load, that is
08:18:51 <byorgey> ptd: the former is part of haskell98; the latter requires an extension
08:18:56 <bscarlet> stobix: ghc must be not just holding but regularly touching the memory pages for the kernel not to see it as a good candidate for paging out.
08:19:09 <byorgey> ptd: however, I don't understand that particular error message
08:19:29 <mokus> bscarlet: if the memory is live then it's going to be touched by ghc's garbage collector
08:20:54 <bscarlet> mokus: if it's garbage, then it should migrate to some sort of free-space pool where the collector doesn't look, yes?
08:21:26 <mokus> bscarlet: my point is that if it was ever let-bound then it's not garbage, at least in older GHC's (not sure when or if that has changed)
08:21:55 <roconnor> @ask edwardk What's the difference between Naperian functors and Representable functors (in Haskell)?
08:21:56 <lambdabot> Consider it noted.
08:22:08 <stobix> benmachine: I might just do that. :) I only installed "the haskell platform" because I'm a noob and wanted to play around with Data.FingerTree. Cabalish things should work on GHC 7, right?
08:22:13 <mokus> bscarlet: but yes, if it truly is garbage then it will end up 'compacted' to a large chunk of free space
08:23:26 <benmachine> stobix: yes, cabal-install is how I do things
08:24:45 <bscarlet> mokus: stobix said he interrupted computation with ^C. Where would that leave this value (what would ghci do with a let bound value the computation of which was interrupted?)?
08:25:57 <quicksilver> bscarlet: I think that would be GC-able, I think the binding wouldn't have been made yet
08:26:02 <quicksilver> I'm not 100% sure.
08:26:25 <mokus> bscarlet: it probably depends how it was bound: if it was 'let foo = ...' and then he tried to evaluate it with "...> foo", it would still be retained
08:26:52 <bscarlet> mokus: sounds quite plausible.
08:26:55 <mokus> bscarlet: on the other hand, if it was just something he typed at the prompt, Ctrl-C would have prevented it being bound to "it" so it shouldn't have been retained
08:38:32 <aruns> hep
08:38:34 <aruns> help
08:38:36 <aruns> ?
08:38:46 <aruns> :q
08:38:49 <aruns> ?
08:39:04 <karlicoss1> i asked about standard haskell classes and found a perfect diagram. Maybe someone might find it useful. http://upload.wikimedia.org/wikipedia/commons/e/ee/Classes.png
08:39:54 <benmachine> karlicoss1: doesn't mention Rational :o
08:40:22 <Phyx-> aruns: ?
08:40:42 <Ke> does bounded make sense without Ord or Enum
08:40:52 <coppro> without Ord, no, without Enum, yes
08:41:12 <dafis> benmachine: Rational's not a class I've heard of
08:41:18 <benmachine> dafis: it's a type
08:41:34 <sipa> maybe it should mention Ratio :)
08:41:41 <benmachine> sure, whatever :P
08:41:47 <eikke> are there any Haskell libraries to work with Integer's in a field modulo N, providing implementations of things like pow (mod N), inverse,... ?
08:41:59 <dafis> benmachine: yup, hadn't looked at it, it's giving instances too, that's what you meant
08:42:03 <sipa> @hackage modpow
08:42:03 <lambdabot> http://hackage.haskell.org/package/modpow
08:42:15 <sipa> heh
08:42:20 <sipa> @hoogle modpow
08:42:20 <lambdabot> No results found
08:42:37 <eikke> ty
08:42:41 <benmachine> @hackage does this even have to be a valid URL
08:42:41 <lambdabot> http://hackage.haskell.org/package/does this even have to be a valid URL
08:42:54 <sipa> eikke: no, i didn't help you at all :)
08:43:03 <eikke> just realized when opening the link :)
08:43:54 <benmachine> eikke: I imagine they're somewhere but I don't know where; you could try http://hackage.haskell.org/package/#cat:math
08:44:23 <benmachine> or maybe they're not
08:44:27 <benmachine> maybe there's a gap in the market :o
08:44:35 <eikke> heh :)
08:44:43 <byorgey> eikke: perhaps try http://hackage.haskell.org/package/factory
08:44:53 <eikke> implemented some functions myself now, but they might be highly under-performing
08:44:55 <byorgey> I haven't taken a close look at it yet but it seems like it may have what you want
08:45:00 <dmwit> http://hackage.haskell.org/packages/archive/numbers/2009.8.9/doc/html/Data-Number-Fixed.html perhaps?
08:45:16 <dmwit> Or is that going the other direction?
08:45:40 <benmachine> byorgey: hm, looks like that was uploaded last week but hackage docs still haven't been built?
08:45:50 <byorgey> benmachine: indeed.  not sure why.
08:46:07 <eikke> dmwit: don't think that's what I'm lookign for... looks like floating stuff :)
08:47:18 <milktrader> let a = 10
08:47:27 <milktrader> let b = 100
08:47:40 <milktrader> a / b
08:47:48 <milktrader> doesn't wok
08:48:04 <milktrader> i mean it doesn't work in haskell terminal
08:48:38 <milktrader> I usually use R for this sort of thing but I figured since I'm learning Haskell, why not?
08:48:53 <nlogax> i think it defaults to Integer
08:49:07 <nlogax> @type (/)
08:49:08 <lambdabot> forall a. (Fractional a) => a -> a -> a
08:49:11 <milktrader> also tried a `div` b ; let c = a/b
08:50:15 <mysticc> milktrader: use let a = 10 :: Double
08:50:41 <mysticc> milktrader: and similarly for b
08:51:41 <milktrader> mysticc: that works! -- now what's going on here?
08:52:35 <mysticc> milktrader: Haskell guesses the type of a as Integer but doing :: Double make it explicitly of type Double
08:52:35 <milktrader> goes to type casting obviously
08:53:07 <mysticc> milktrader: You can use :t to check for type of a before and after ..
08:53:33 <milktrader> but you can divide two integers ... the output must also be an integer, is that it?
08:53:59 <mysticc> milktrader: check :t (/)
08:54:11 <mysticc> milktrader: Only defined for class fractional
08:54:39 <milktrader> ah, that's what the cryptic line meant
08:54:47 <mysticc> milktrader: and Integer has no instance in class fractional
08:55:18 <milktrader> good, thanks for the help, it makes perfect sense now.
08:55:51 <mysticc> milktrader: Haskell is strongly typed language ,, so remember to check types ... :)
08:56:27 <milktrader> it's a good way to find out by trying things out. I'm sure I read it but it went in one ear, out the other
08:59:55 <mysticc> Any one know where the module Text.regex gone ?? or I need in ghc 7.0.3 .. Do I need to install it manually ??
09:00:25 <mysticc> sorry it was Text.Regex
09:03:51 <mysticc> Got it from cabal anyways ..
09:33:59 <ion> erus`: Added some additional comments to my solution to the spiral array problem.
09:34:29 <erus`> i dont like your solution
09:34:36 <erus`> its not grity and dirty enough
09:36:38 <erus`> (i couldnt fully grok how it worked, but the code was very elegant)
09:37:02 <ion> It’s based on computing the spiral index based on the array coordinate mathematically.
09:37:52 <ion> indexTri does the calculatin for any of the coordinates within the triangle shown in the documentation. indexFor' then tries indexTri for four 90-degree rotations.
09:38:32 <BlankVerse> someone plz explain this reverse          =  foldl (flip (:)) []
09:39:01 <benmachine> BlankVerse: do you understand what foldl does?
09:39:08 <BlankVerse> benmachine: yep
09:39:22 <int-e> flip (:) is )\as a -> a : as)
09:39:28 <benmachine> BlankVerse: ok, does it help if I write foldl (\a x -> x:a)
09:39:28 <int-e> sorry, flip (:) is (\as a -> a : as)
09:39:33 <kmc> > foldl f z [a,b,c]
09:39:33 <lambdabot>   f (f (f z a) b) c
09:39:47 <benmachine> foldl (\a x -> x:a) []
09:39:57 <ion> > foldl (flip f) z [a,b,c]
09:39:58 <lambdabot>   f c (f b (f a z))
09:40:00 <kmc> > flip (:) (flip (:) (flip (:) [] a) b) c
09:40:01 <lambdabot>   [c,b,a]
09:40:18 <hpaste> ash__ pasted “Confused about Monads” at http://hpaste.org/49747
09:40:49 <kmc> most people who say they're confused about monads aren't ;P
09:40:54 <kmc> ash__, what's the problem?
09:41:04 <BlankVerse> benmachine: thanks
09:41:13 <benmachine> foldl (\a x -> x:a) [] [1,2,3] -> foldl (\a x -> x:a) (1:[]) [2,3] -> foldl (\a x -> x:a) (2:1:[]) [3] -> foldl (\a x -> x:a) (3:2:1:[]) [] -> 3:2:1:[]
09:41:19 <ash__> I am having an issue with a monad, I am not sure how to explain it, but basically, getRandR -> Rand g Double
09:41:23 <BlankVerse> benmachine: and lamdabot is awesome ... is it written in haskell?
09:41:25 <int-e> kmc: how can you not be confused? there are so many of them ;)
09:41:31 <kmc> BlankVerse, yes
09:41:36 <kmc> the ##c++ eval bot is also written in Haskell :D
09:41:38 <benmachine> BlankVerse: yes, but quite old haskell that nobody completely understands :P
09:41:39 <ash__> but I want to take that and put it into a list like: Rand g [(Double, Bool)]
09:41:46 <BlankVerse> kmc: is it opensource?
09:41:53 <ion> @hackage lambdabot
09:41:53 <lambdabot> http://hackage.haskell.org/package/lambdabot
09:42:08 <kmc> ash__, i think instead of "changeTime + getRandomR foo" you want "do x <- getRandomR foo; return (changeTime + x)"
09:42:10 <benmachine> @help
09:42:10 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
09:42:14 <benmachine> @list
09:42:14 <lambdabot> http://code.haskell.org/lambdabot/COMMANDS
09:42:16 <kmc> or (changeTime +) `fmap` getRandomR foo
09:42:45 <benmachine> @source
09:42:45 <lambdabot>  not available
09:42:47 <singpolyma> Hey all: is there a shorter way to write this: http://pastie.org/2304703
09:42:50 <benmachine> hm.
09:42:59 <int-e> kmc: or do you mean that half of the time the question is really about IO and 1/3 of the time it's about the do syntax? :-)
09:43:18 <kmc> int-e, or HOFs or polymorphism or type classes
09:43:19 <ash__> kmc: thanks, that fixed it, i was struggling with that for a while
09:43:30 <kmc> singpolyma, we only got 2 lines; it's incomplete
09:43:53 <kmc> singpolyma, anyway i think you want algo <- key_algorithms `fmap` get
09:43:53 <monochrom> perhaps that is the only 2 lines
09:44:06 <kmc> depending on the type of 'key_algorithms' this might let you drop the type annotation too
09:44:40 <monochrom> no, "algorithm" /= "key_algo"
09:44:42 <BlankVerse> is there anything like makeflags when building packages from source in cabal?
09:44:53 <BlankVerse> i have 8 cores but only 1 is used
09:45:09 <kmc> BlankVerse, cabal uses ghc --make which can't build in parallel yet
09:45:15 <kmc> this is a feature i'd like as well
09:45:28 <benmachine> it's being worked on I believe
09:45:34 <BlankVerse> kmc: what do you mean by ghc --make?
09:45:52 <BlankVerse> kmc: i have all my ghc compiling parallel
09:45:58 <kmc> BlankVerse, you do?
09:46:07 <BlankVerse> kmc: say for example kernel or other packages from ABS
09:46:19 <kmc> what I mean by "ghc --make" is the flag "--make" as passed to the Glorious Glasgow Haskell Compiler, and documented in said manpage
09:46:25 <kmc> i'm not sure what else I could mean
09:46:34 <kmc> you're compiling a kernel with ghc?
09:46:53 <BlankVerse> oops srry for the goofup .... i though gcc :P
09:47:00 <kmc> it's okay :)
09:47:07 <kmc> anyway ghc --make is nice, but it doesn't do parallel compilation
09:47:20 <kmc> you can build GHC *itself* in parallel
09:47:27 <kmc> because they use Makefiles
09:47:31 <BlankVerse> using ghc?
09:47:35 <kmc> yes
09:47:43 <kmc> ghc is the only compiler that can build ghc
09:47:49 <ash__> you could just use a normal makefile and specify the individual compile commands using the ghc if you want parallel compilation, right?
09:47:51 <BlankVerse> awesome
09:47:54 <kmc> yes ash__
09:47:58 <kmc> but it's more work
09:48:06 <singpolyma> kmc: Thanks!  fmap seems to be doing what I want
09:48:21 <kmc> singpolyma, you can use (<$>) from Control.Applicative as a infix synonym for fmap
09:48:44 <kmc> ghc supports a -M flag that helps you generate makefiles
09:49:07 <kmc> part of the point of ghc --make is to save the effort of re-parsing those .hi files on every compilation
09:49:15 <kmc> you lose that with a Makefile system
09:49:22 <kmc> but it might be worth it for parallelism
09:49:51 <BlankVerse> is there any source browser for cabal packages?
09:49:53 <parcs> is it possible to construct a function to convert term-level nats to the type level?
09:50:18 <kmc> parcs, no, because the former doesn't exist until runtime
09:50:28 <kmc> BlankVerse, Hackage has source
09:50:28 <parcs> damn
09:50:45 <kmc> pick your favorite package, click the "Source" links inside its haddock docs
09:52:10 <kmc> parcs, you can write TermNat -> Maybe (TypeNat n)
09:52:18 <kmc> which amounts to guessing the nat at compile time
09:53:11 <kmc> the type (Maybe t) is kind of useless from a curry-howard perspective though
09:54:15 <singpolyma> What about something like : http://pastie.org/2304741 ?
09:54:40 <kmc> TypeConstructor `fmap` get
09:55:05 <kmc> fmap :: (a -> b) -> M a -> M b
09:57:19 <singpolyma> oh, wow
09:57:43 <Cale> Usually if I use fmap I write it prefix: fmap Foo get  and I use <$> if I want to write it infix:  Foo <$> get
09:58:05 <monochrom> you don't use "Foo . get"? :)
09:58:22 <kmc> haha
09:58:23 <Cale> I would use Foo . get if it were in the Prelude.
09:58:34 <kmc> sometimes infix reads better but i don't want a Applicative import
09:58:37 <kmc> mostly for small files
09:58:47 <kmc> for any large module i'm going to import Applicative anyway :)
09:59:13 <ion> singpolyma: The relationship of <$> (fmap) and =<< (monad bind) among others http://heh.fi/haskell/functors/
09:59:56 <Eduard_Munteanu> kmc: some terms are compile-time constants though.
10:00:27 <kmc> yeah, I don't know a way to turn a compile-time constant term nat into a type nat
10:01:17 <Eduard_Munteanu> I guess the ultimate reason is we don't have dependent types.
10:01:55 <kmc> yeah
10:02:23 <kmc> with DT, terms and types are of the same syntactic class
10:02:30 <singpolyma> kmc, ion, Cale: cool, so that's working well for me.  What if I have a type contructor with multiple arguments?  or worse yet, a record based type contructor?
10:02:37 <kmc> and an implementation will do β-reduction inside types at "compile time"
10:02:56 <Cale> singpolyma: I think you're confusing the words "type constructor" and "data constructor"
10:02:57 <kmc> singpolyma, liftM3 Ctor getX getY getZ
10:03:10 <Cale> Type constructors construct types, so they only occur on the right side of ::
10:03:11 <kmc> or: Ctor <$> getX <*> getY <*> getZ
10:03:18 <singpolyma> Cale: I could be confusing all kinds of things.  this is my second week in haskell
10:03:33 <Eduard_Munteanu> kmc: yeah, or just carry around whatever variable you passed in
10:03:33 <Cale> Data constructors are the ones which construct values
10:03:39 <ion> (liftA3 f a b c is defined as f <$> a <*> b <*> c which is the same as pure f <*> a <*> b <*> c)
10:04:01 <Cale> yeah, liftAn or liftMn will work for that
10:04:27 <Cale> (they're the same except the liftAn are more general)
10:04:31 <hatds> pure f <*> = f <$> is assuming the sensible applicative/functor law iirc
10:04:39 <Cale> Or you can use <$> and <*> together
10:05:01 <singpolyma> so, <$> ... <*>  is better because it's not bound to a fixed number, yes?
10:05:18 <byorgey> hatds: (pure f <*>) = (f <$>) is itself a law that ought to hold of Applicative instances
10:05:19 <ion> Either is fine. Pick based on aesthetics.
10:05:23 <Cale> yeah
10:05:39 <kmc> singpolyma, I like liftA* because there's less syntactic noise
10:06:20 <hatds> byorgey: right the 'sensible' thing, but not defined as such
10:06:22 <ion> OTOH if you need () around every action with liftA*, the <$> <*> being infix might be nicer.
10:06:28 <kmc> dependent types have a reputation for being complicated, but they're actually simpler than a type system like Haskell's
10:06:34 <byorgey> hatds: right
10:06:35 <kmc> (especially Haskell + GHC extensions)
10:06:52 <kmc> there's fewer kinds of things and fewer rules
10:06:58 <kmc> what you lose is stuff like inference
10:07:23 <Eduard_Munteanu> Oh, you do?
10:07:30 <ion> singpolyma: Do you understand <*>?
10:07:41 <Eduard_Munteanu> Well, excluding rank-k types, k >= 3.
10:08:19 <byorgey> kmc: dependent types have a reputation for being confusing, not complicated
10:08:22 <roconnor> (pure f <*>) = (f <$>) is almost a free theorem.
10:08:39 <byorgey> kmc: and they can be confusing precisely *because* there are fewer kinds of things
10:08:52 <byorgey> you end up making a lot more level errors
10:08:57 <kmc> yeah
10:09:03 * kmc hates level errors...
10:09:05 <byorgey> don't get me wrong, I love dependent types =)
10:09:47 <Eduard_Munteanu> What if you limit yourself to just a couple of levels?
10:09:55 <kmc> Eduard_Munteanu, there is only one level
10:10:03 <kmc> so you're already limited that way
10:10:19 <Eduard_Munteanu> Like types depending on terms, without extending that to other sorts.
10:10:43 <byorgey> Eduard_Munteanu: but if you have types depending on terms then you will surely need kinds as well, to classify such types...
10:11:43 <Eduard_Munteanu> byorgey: yes, but do you really need dependent kinds as well?
10:12:04 <byorgey> Eduard_Munteanu: no.
10:12:15 <byorgey> Eduard_Munteanu: but making such a distinction leads to a much more complex system
10:12:17 <Eduard_Munteanu> That's what Coq and Agda allow you to do.
10:12:20 <byorgey> although it may be easier to understand
10:12:21 <Eduard_Munteanu> Ah.
10:12:44 <kmc> to me that sounds not like a restriction of DT, but like a completely different thing
10:12:51 <kmc> again, in DT you only have one level to begin with
10:13:02 <kmc> so it's already "restricted to a few levels"
10:13:03 <Eduard_Munteanu> How much of DT you can infer if you don't use higher rank types?
10:13:04 <byorgey> "dependent types" can mean a lot of different things
10:13:05 <kmc> Eduard_Munteanu, have you seen Omega?
10:13:09 <Eduard_Munteanu> kmc: how so?
10:13:12 <Eduard_Munteanu> Mm, no.
10:13:22 <Eduard_Munteanu> kmc: what level is that?
10:13:27 <byorgey> what I would call a "full-spectrum dependent type system" is often presented in terms of a single syntactic class
10:13:35 <byorgey> but I don't think that is *required*
10:13:45 <kmc> Omega is not dependently-typed, but allows you to introduce algebraic data at any level
10:14:03 <kmc> so terms are classified by types which are classified by kinds which are ...
10:14:29 <Eduard_Munteanu> Ah, so you can only depend on stuff at the same level, to say so?
10:14:32 <kmc> but you can have datakinds as well
10:14:43 <kmc> yeah
10:14:57 <Cale> You can generally infer DT based on sentry count around 6:00-6:30. ;)
10:15:03 <Cale> (sorry)
10:15:12 <roconnor> @type traverse
10:15:12 <lambdabot> Not in scope: `traverse'
10:15:14 <kmc> you have functions from types to types, and they can pattern-match type-level data
10:15:35 <kmc> i suppose this also has a single syntactic class
10:16:19 <Eduard_Munteanu> kmc: note in stuff like Agda you have an arbitrary number of levels
10:16:55 <byorgey> there is some confusion here between semantic and syntactic levels.
10:17:10 <Eduard_Munteanu> Basically, value : Type : Set : Set 1 : Set 2 : ...
10:17:16 <byorgey> Agda has only one *syntactic* level: there is only a single class of expressions.
10:17:30 <Eduard_Munteanu> Oh.
10:17:42 <kmc> Eduard_Munteanu, right, but each one can depend on things below it
10:17:52 <kmc> types can depend on values
10:17:52 <kmc> which Omega disallows
10:17:54 <byorgey> but it has many semantic levels, where we say that x has level n if the judgment |- x : Set n  holds  (or something like that)
10:21:34 <karlicoss1> i have a list, and i want to generate a list of all pairs with elements, belonging to the list, but elements in a pair mustn't be elements with equal index. what's most haskell'ish way to generate such a list? for example, for [1, 2] list [(1, 2), (2, 1)] should be generated, for [1, 1] should be [(1, 1), (1, 1)] (elements can be equal, we just don't consider elements with equal index).
10:21:47 <karlicoss1> sorry if my english is bad :)
10:22:33 <kmc> :t join (liftM2 (,)) "abc"
10:22:34 <lambdabot> [(Char, Char)]
10:22:38 <kmc> > join (liftM2 (,)) "abc"
10:22:39 <lambdabot>   [('a','a'),('a','b'),('a','c'),('b','a'),('b','b'),('b','c'),('c','a'),('c'...
10:23:17 <saml> > lift your hands up
10:23:18 <lambdabot>   Ambiguous occurrence `lift'
10:23:18 <lambdabot>  It could refer to either `Control.Monad.Trans....
10:23:24 <karlicoss1> @hoogle liftM2
10:23:24 <lambdabot> Control.Monad liftM2 :: Monad m => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
10:23:27 <kmc> lift your skinny fists like antennas to heaven
10:23:34 <saml> > put your hands up in the sky
10:23:34 <lambdabot>   <no location info>: parse error on input `in'
10:23:43 <kmc> > map (\((_,x),(_,y)) -> (x,y)) . filter (\((i,_),(j,_)) -> i /= j) . join (liftM2 (,)) . zip [0..] $ "abc"
10:23:44 <lambdabot>   [('a','b'),('a','c'),('b','a'),('b','c'),('c','a'),('c','b')]
10:23:52 <byorgey> karlicoss1: your english is fine =)
10:24:11 <roconnor> karlicoss1 wants the off diagonal elements?
10:24:12 <dafis> > let foo [] = []; foo (x:xs) = map ((,) x) xs ++ foo xs in foo [1,2,3] >>= \(a,b) -> [(a,b),(b,a)]
10:24:13 <lambdabot>   [(1,2),(2,1),(1,3),(3,1),(2,3),(3,2)]
10:24:42 <karlicoss1> byorgey: i often get confused with articles and prepositions :)
10:24:51 <Cale> let select [] = []; select (x:xs) = (x,xs) : [(y,x:ys) | (y,ys) <- select xs] in do (x,xs') <- select [1..10]; (y,xs'') <- select xs'; return (x,y)
10:24:52 <kmc> > let xs = "abc"; ps = zip [0..] xs in [ (x,y) | (i,x) <- ps; (j,y) <- ps; i /= j ]
10:24:53 <lambdabot>   <no location info>: parse error on input `;'
10:24:55 <Cale> > let select [] = []; select (x:xs) = (x,xs) : [(y,x:ys) | (y,ys) <- select xs] in do (x,xs') <- select [1..10]; (y,xs'') <- select xs'; return (x,y)
10:24:55 <lambdabot>   [(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(2,1),(2,3),(2,4),(...
10:25:03 <kmc> > let xs = "abc"; ps = zip [0..] xs in [ (x,y) | (i,x) <- ps, (j,y) <- ps, i /= j ]
10:25:04 <lambdabot>   [('a','b'),('a','c'),('b','a'),('b','c'),('c','a'),('c','b')]
10:25:14 <roconnor> kmc: :)
10:25:20 <kmc> karlicoss1, i think the list comprehension is pretty easy to understand
10:25:25 <Ptival> wow you're killing the poor karlicoss1 :D
10:25:44 <kmc> but obviously there are a lot of ways to solve this one :)
10:25:57 <dafis> Ptival: we've once been described as a swarm of helpful piranhas
10:26:00 <byorgey> karlicoss1: that's quite understandable.  Fortunately, those are often semantically redundant. =)
10:26:14 <roconnor> the real question is how lazy we want this function to be
10:26:36 <karlicoss1> kmc: yeah, seems simple :)
10:26:56 <roconnor> karlicoss1: are you sure you want both ('a','b') and ('b','a') in the list?
10:27:07 <kmc> it's actually a lot nicer than the points-free version i came up with first
10:27:09 <kmc> too much time here...
10:27:19 <Ptival> dafis: you guys are the worst... craving for helping people, how anti-egoist!
10:27:33 <roconnor> Ptival: we just like code golf
10:27:45 <karlicoss1> roconnor: no, but it's pretty easy to modify kmc's solution to drop them
10:27:57 <kmc> > let xs = "abc"; ps = zip [0..] xs in [ (x,y) | (i,x) <- ps, (j,y) <- ps, i < j ]
10:27:58 <lambdabot>   [('a','b'),('a','c'),('b','c')]
10:28:11 <kmc> but i think there's another nice way to do that one
10:28:19 <kmc> which dafis gave?
10:29:20 <karlicoss1> byorgey: that's why i like esperanto language. But very few people speak it :(
10:29:31 <kmc> > let f [] = []; f (x:xs) = map ((,) x) xs ++ f xs in f "abc"
10:29:31 <lambdabot>   [('a','b'),('a','c'),('b','c')]
10:29:54 <kmc> is there a fold-like HOF that captures this pattern?
10:30:12 <kmc> i.e. use the tail of the list "now" but also recurse on the tail?
10:31:01 <dafis> kmc: folding on "tails xs" could probably be used
10:31:17 <kmc> this should be more efficient than the list-comprehension one, also
10:31:25 <kmc> dafis, ah, yeah
10:31:34 <dafis> although in this case, map is used, not a fold
10:32:06 <Cale> > do (x:xs) <- tails [1..10]; (y:xs') <- select xs; return (x,y)
10:32:07 <lambdabot>   Not in scope: `select'
10:32:15 <Cale> > do (x:xs) <- tails [1..10]; (y:xs') <- xs; return (x,y)
10:32:16 <lambdabot>   No instances for (GHC.Num.Num [t], GHC.Enum.Enum [t])
10:32:16 <lambdabot>    arising from a use...
10:32:20 <Cale> > do (x:xs) <- tails [1..10]; (y:xs') <- tails xs; return (x,y)
10:32:21 <lambdabot>   [(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(2,3),(2,4),(2,5),(...
10:32:27 <roconnor> kmc: and lazier?
10:32:30 <Cale> > do (x:xs) <- tails [1..4]; (y:xs') <- tails xs; return (x,y)
10:32:31 <lambdabot>   [(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]
10:32:33 <kmc> > let inpt = "abcd" in [ (x,y) | (x:xs) <- tails inpt; y <- xs ]
10:32:34 <lambdabot>   <no location info>: parse error on input `;'
10:32:37 <kmc> gah
10:32:40 <kmc> > let inpt = "abcd" in [ (x,y) | (x:xs) <- tails inpt, y <- xs ]
10:32:40 <lambdabot>   [('a','b'),('a','c'),('a','d'),('b','c'),('b','d'),('c','d')]
10:44:51 * hackagebot pandoc 1.8.2.1 - Conversion between markup formats  http://hackage.haskell.org/package/pandoc-1.8.2.1 (JohnMacFarlane)
10:47:19 <kmc> ok, i'm doing a little "haskell and why you should care" talk, based around the theme of composability
10:48:08 <kmc> topics i cover so far: declarative programming, equational reasoning, laziness, fusion, static types, pattern matching, parametricity, QuickCheck, EDSLs (parser example), first-class IO, concurrency, GHC IO manager, STM, pure parallelism
10:48:19 <kmc> any big omissions?
10:50:07 <byorgey> woah, how long is this talk?
10:51:01 <c_wraith> sounds like 4 hours, at the moment
10:51:45 <ion> Since you’re talking about QuickCheck, parsing and IO. it might (or might not) be nice to give a quick example of how fmap works with all of them.
10:52:13 <c_wraith> but so far, he's avoided talking about typeclasses!
10:52:22 <c_wraith> one of his main goals was to not mention them, so far as I can tell
10:52:29 <NihilistDandy> Indeed
10:55:03 <darrint> This is OT but does anyone know if google's "guava" library for Java has an equivalent to Data.List zip?
10:59:04 <tommd> darrint: I don't know that library, but "zip" is sometimes named "combine"...
11:01:26 <Cale> I think most Java programmers would just write a loop and index both lists with an int.
11:02:41 <Cale> Does Java have a standard Pair type even?
11:03:00 <Eduard_Munteanu> If you're going to sell Haskell without actually trying to teach it on spot, then I guess you can show basic examples of all those things in like 20-30 mins
11:03:05 <Cale> (or does the library you're using hava a Pair type?)
11:03:08 <kmc> Java programmers would write an AbstractDoubleListElementCombinationFactory
11:03:09 <Cale> have*
11:03:14 <Cale> lol
11:03:17 <kmc> right, Eduard_Munteanu has the idea
11:03:33 <kmc> you can't teach Haskell in one hour, no matter how boring and simplistic you make it
11:03:46 <kmc> better to present examples of why it's worth learning on your own
11:03:54 <darrint> Cale: Can't find a pair type. I did think to look. That does seem important to the type of the function I'd be looking for.
11:03:58 <kmc> and at that rate you can move pretty fast
11:04:22 <Cale> darrint: Yeah, it's pretty impossible to represent zip without a pair type :)
11:04:45 <Cale> You might be able to do zipWith, but hah, not in Java.
11:05:04 <Cale> (I'm sure you actually could do it, but it would be horrid)
11:05:16 <silver> Cale, no pait type, but there is Map.Entry<K, V>
11:05:21 <darrint> Cale: Standard Java maps have an entry type but I don't see that used in Guava (or not in the right spot). There might be a listofpairs type I haven't spotted yet though. Thanks.
11:05:23 <silver> pair*
11:06:13 <Eduard_Munteanu> kmc: maybe you can mention DPH as an upcoming development?
11:06:26 <darrint> They have bimaps.
11:06:53 <kmc> Eduard_Munteanu, not a bad idea
11:07:02 <Eduard_Munteanu> I mean, even the FP-naive crowd hails the implications of FP in parallelism.
11:07:15 <hatds> kmc: maybe this is already in your agenda but I would show how laziness and higher order functions make "loops" radically nicer
11:07:41 <c_wraith> most of the "fp in parallelism" stuff turn out to be wrong anyway. >_>
11:08:39 <kmc> hatds, yeah, i have an example sort of like that
11:08:51 <silver> Eduard_Munteanu, not all of them, my team lead argued with me that FP-language won't give any edge in parallelism
11:09:21 <kmc> the audience is pretty sophisticated; I don't expect them to be dazzled by the 80-year-old concept of a lambda abstraction
11:09:40 <Eduard_Munteanu> Yeah, it's not like DPH got any impressive results.
11:10:15 <Eduard_Munteanu> In the end I still think it boils down to micromanaging critical sections and locking granularity.
11:10:28 <c_wraith> DPH is, well, explicitly data-parallel.  That helps, when your algorithms are data parallel.
11:10:39 <kmc> i think STM is more compelling, if I'm to pick between the two
11:10:43 <c_wraith> But when they're not...  You need better algorithms.
11:11:56 <Eduard_Munteanu> How fast is STM really? I haven't looked into it in great detail.
11:12:18 <c_wraith> It's pretty good when there's little/no contention
11:12:18 <kmc> It Depends ™
11:12:28 <kmc> i'm not even talking about STM performance, though
11:17:34 <Eduard_Munteanu> I hope it's not using atomic memory ops for everything, no?
11:18:13 <c_wraith> Not at all.
11:18:15 * Eduard_Munteanu looks for details on the implementation
11:18:20 <c_wraith> it's optimistic locking
11:18:44 <kmc> Eduard_Munteanu, how would that work, anyway?
11:18:48 <c_wraith> it tracks what cells it reads from and writes to, then when the transaction finishes, rolls back and retries if any of those were changed during the transaction
11:18:58 <thoughtpolice> certain things in GHC boil down to atomic ops - IIRC atomicModifyIORef basically boils down to 'cas'. the RTS does it to. but the STM implementation does not
11:19:04 <monochrom> @pl \x y -> True
11:19:04 <lambdabot> const (const True)
11:19:10 <c_wraith> Uh, changed by a different transaction
11:19:16 <kmc> Eduard_Munteanu, the whole point of STM is that you can combine *multiple* operations and make them atomic together
11:19:32 <Eduard_Munteanu> Ah.
11:19:36 <kmc> if you're only doing (atomically $ readTVar ...) you might as well not use STM
11:19:48 <Eduard_Munteanu> kmc: for some things it probably would, but even so it'd be really slow.
11:20:13 <kmc> i'm trying to understand what you mean by "using atomic memory ops for everything"
11:20:32 <kmc> you can't implement STM simply by implementing each readTVar / writeTVar with an atomic memory op
11:20:49 <kmc> you can of course implement locking, journaling, and lots of other concurrency schemes in terms of atomic memory ops
11:20:53 * roconnor wishes double was part of the Monoid class.
11:21:16 <kmc> i guarantee you there are atomic memory ops somewhere in the stack of code that makes up the STM implementation
11:21:45 <c_wraith> roconnor: You mean Sum or Product?
11:21:47 <Eduard_Munteanu> Ah, yeah, it probably doesn't make much sense unless we're talking small transactions.
11:21:57 <roconnor> c_wraith: I mean (x `mappend` x)
11:22:04 <kmc> Eduard_Munteanu, how would you do it for small transactions?
11:22:24 <c_wraith> roconnor: my point is that there are two options, and the Sum and Product newtypes exist to distinguish them
11:22:37 <Eduard_Munteanu> kmc: well, depending on the CPU, you can overwrite some values directly using an atomic write.
11:22:58 <Eduard_Munteanu> (note locks also need some sort of atomic op)
11:23:02 <roconnor> c_wraith: I want a method double x = x `mappend` x to be a class method of Monoid.  (the name doesn't have to be double.)
11:23:21 <Eduard_Munteanu> E.g., on x86, a 32-bit value.
11:23:21 <c_wraith> roconnor: oh.  wow, I read that backwards. :)
11:23:25 <roconnor> c_wraith: because for many of my monoids I can more efficently implement double than x `mappend` x
11:23:35 <kmc> Eduard_Munteanu, yeah.  so how do you implement «atomically (writeTVar x 1; writeTVar y 2)» that way?
11:24:24 <Eduard_Munteanu> In that case you can't, at least not without doing some sort of locking or journalling.
11:24:32 <kmc> right
11:24:37 <kmc> in all the cases where STM is interesting
11:25:27 <Eduard_Munteanu> < Eduard_Munteanu> I hope it's not using atomic memory ops for everything, no?   -- was a bit too far reaching
11:25:44 <kmc> it's meaningless too
11:25:58 <kmc> every concurrency scheme is going to rely on atomicity of *some* memory operation
11:26:15 <kmc> e.g. the ops implementing your locks or journals
11:26:25 <Eduard_Munteanu> Yeah.
11:26:29 <dmwit> roconnor: Sounds like this calls for.... MORE typeclasses!
11:27:13 <dmwit> class Monoid m => Double m where double :: m -> m; double = join mappend
11:27:58 <roconnor> dmwit: I'm going to just slip it into my Group class like a wuss.
11:28:32 <singpolyma> sorry for all the n00b questions today, but I have another one.  I'm trying to map an operation using get over a list: http://pastie.org/2305123
11:28:33 * roconnor is tempted to rename his Group class as Zmodule.
11:30:24 <kmc> :t sequence
11:30:25 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
11:30:26 <kmc> :t mapM
11:30:27 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
11:30:28 <kmc> singpolyma, ^^^^
11:30:40 <kmc> @src mapM
11:30:40 <lambdabot> mapM f as = sequence (map f as)
11:33:48 <Eduard_Munteanu> Is House still alive?
11:34:12 <singpolyma> kmc: hmm, so, I've got it working with that.  what exactly does mapM do?
11:34:30 <kmc> Eduard_Munteanu, yeah but the show jumped the shark years ago
11:34:56 <kmc> singpolyma, better to ask what "sequence" does
11:34:56 <Eduard_Munteanu> No, not the show :). House the OS.
11:35:11 <singpolyma> kmc: hmm, yeah.  that makes sense.  looking that up now...
11:35:11 <kmc> it takes a list of monadic actions and binds them together in order
11:35:22 <kmc> returning an action which produces the list of results
11:35:26 <kmc> @src mapM
11:35:26 <lambdabot> mapM f as = sequence (map f as)
11:38:05 <singpolyma> Yeah.  cool.  thanks :)
11:54:17 <saml> hi why no where in ghci?
11:54:19 <BlankVerse> isPalindrome xs = xs == reverse xs , whats wrong ?
11:54:38 <saml> > some where over the rainbow = some; some = 1
11:54:38 <lambdabot>   <no location info>: parse error on input `where'
11:55:23 <kmc> BlankVerse, why don't you tell us what's wrong?
11:55:29 <kmc> are you getting an error message?
11:55:31 <kmc> function doesn't work?
11:55:42 <BlankVerse> No instance for (Eq a) arising from a use of `=='
11:55:56 <kmc> did you put a type signature on it?
11:56:04 <kmc> you shouldn't need to
11:56:08 <kmc> but if you do, it has to be correct
11:56:12 <BlankVerse> oops got it
11:56:15 <BlankVerse> kmc: thanks
11:56:15 <kmc> :t let isPalindrome xs = xs == reverse xs in isPalindrome
11:56:15 <lambdabot> forall a. (Eq a) => [a] -> Bool
11:56:17 <kmc> :)
11:56:19 <dmwit> saml: where is not for expressions, sadly
11:56:46 <saml> > let isPalindrome xs = and $ zipWith (==) xs (reverse xs) in isPalindrome "ada"
11:56:46 <lambdabot>   True
11:57:06 <augustss> hi
11:57:11 <saml> why where is not expression?
11:57:17 <saml> hi augustss . welcome
11:57:28 <dmwit> saml: Because it would be awful.
11:57:29 <kmc> saml, because that's how it's defined in the Haskell standards
11:57:34 <kmc> use "let" instead
11:57:45 <saml> i heard gurus use point free + where
11:57:46 <augustss> Does anyone remember where to find an STM implementation that is just in terms of cuncurrent haskell?
11:57:49 <saml> and let is for noobs
11:57:59 <dmwit> (foo where { blah = barf; baaz = quux }) (foo' where { blah' = barf'; baaz' = quux' }) -- unreadable
12:00:03 <kmc> saml, you heard wrong
12:01:19 <saml> kmc, http://stackoverflow.com/questions/1983047/good-haskell-coding-standards   stackoverflow is always right!
12:01:51 <kosmikus> augustss: Frank Huch did that IIRC
12:02:12 <kmc> you went from "Too many let-bindings is a [bad] sign" to "let is for noobs"
12:02:56 <XniX23> i know thats not haskell related question but as im not getting the answer on py channel i'll just ask here. Its about designing big projects (framework or cmd or programming language), how do i know how to design the structure? Like class inheritance in python lets say or whatever that would be in haskell. Is there a good book on that?
12:03:53 <kmc> you can summarize that as "What's a good book on software engineering?"
12:03:57 <kmc> i don't know of one
12:04:24 <kosmikus> augustss: http://www-ps.informatik.uni-kiel.de/~fhu/projects/stm.pdf
12:04:33 <kosmikus> augustss: not sure if there's any code to download, though
12:06:45 <Botje> XniX23: haskell doesn't have classes or subtyping.
12:06:52 <Botje> XniX23: the best way to learn design is by doing.
12:07:26 <Botje> XniX23: plan to throw the first one away, you will anyway :)
12:08:31 <XniX23> Botje: so its basicaly trial and error..
12:09:15 <Botje> basically.
12:09:31 <Botje> you can learn a bit by looking at other people's code and studying eg. design patterns
12:10:01 <Botje> but the brunt of design knowledge (at least for me) comes from simply banging out code and evaluating which parts are good and which parts could be improved
12:11:20 <bscarlet> XniX23: what constitutes good software design is often highly context dependent.
12:11:20 <dmwit> Q: "How do I design big programs well?" A: "Design some big programs badly, then don't do that."
12:12:59 <XniX23> dmwit: hahahahah
12:13:58 <thoughtpolice> "Good judgment comes from experience; experience comes from bad judgment." - brooks
12:14:55 <kmc> Q: "How do I learn to be a doctor?" A: "Feed random substances to your patients and notice which ones die."
12:15:32 <bscarlet> XniX23: Botje's right about reading other people's code. That way you can at least get easy help with the "design big programs badly" part.
12:15:32 <dmwit> That's a fair point.
12:15:37 <kmc> Q: "How do I learn to build bridges?" A: "Build some bridges that fall down, and then don't do that."
12:15:47 <dmwit> Perhaps there is some domain knowledge we can pass on.
12:15:57 <kmc> i can't tell whether you're all ignorant of the actual principles of software engineering (because I am too), or whether the field is really such a lost cause as you're making it out to be
12:16:18 <kmc> but we know how to teach people to build bridges that mostly don't fall down
12:16:33 <dmwit> But I've read some such attempts, and (perhaps because I'm so dense) it's never helped until I've fallen afoul of going against the advice contained there.
12:16:43 <kmc> it is not necessary for each individual civil engineer to actually build some bridges that fall down
12:17:10 <bscarlet> kcm: really? Not even models in classes?
12:17:51 <bscarlet> s/kcm/kmc/
12:18:17 <sutabi_> Anyone know which database is supported best in haskell?
12:18:18 <kmc> it does seem to me that industry programmers confound the questions of "How do I design good programs?" and "How do I work around specific flaws in the Java language specification?"
12:18:51 <Philippa> kmc: the field has mostly been that fucked up
12:18:56 <augur> merp
12:18:59 <augur> any good papers to read?
12:19:00 <kmc> as if you had all this theory about building bridges, but nobody acknowledges that it's only applicable to bridges made of paper
12:19:06 <kmc> and that bridges made of steel might be designed differently
12:19:13 <Philippa> we're okay in the small, but in the large? We're only really starting to talk about it in useful terms
12:19:24 <augur> or blog posts?
12:19:33 <int-e> kmc: software is often assembled from pieces that don't fit together. you don't build bridges that way either. you also don't make late changes to a bridge (like, oh, surely it will work if we leave out the pier in the middle! or "I bet putting a skyscraper on top of it will make it look even better!) ... while the same is common practice in software engineering
12:19:55 <kmc> yeah, I don't mean to imply that software engineering is exactly like civil engineering
12:20:08 <kmc> i'm just suggesting that "give up" is probably not the best answer to the problem of how to engineer software
12:20:23 <kmc> by analogy with other fields that used to be random trial and error
12:20:29 <kmc> but now are things one can teach
12:21:34 <kmc> all of this "it can't be taught, you have to learn it yourself through practice" sounds to me like alchemy or crackpot traditional medicine
12:21:47 <bscarlet> I, at least, wasn't suggesting either giving up or using random trial and error. Looking at and reading other software projects can be incredibly instructive.
12:22:04 <int-e> software engineering is essentially risk management - you have costs from software failures (as a rule, small, but there are a lot of exceptions), cost from testing, cost from designing and even redesigning parts of the software, and a market that typically demands new features from your software. It's not that we don't have ways of producing good, safe, bug-free software - it's that it ends up in places where we don't see...
12:22:10 <int-e> ...it like embedded systems in automobiles.
12:22:21 <kmc> yeah, that's an important point
12:22:32 <kmc> we have low standards for quality in most software
12:22:35 <kmc> so that's what we get
12:23:07 <kmc> the Space Shuttle software isn't written by 20-year-old Red Bull guzzling all nighter ninja rockstar cowboy coderzzzz
12:23:30 <kmc> it's written by middle-aged engineers who wake up at 9 AM and go to meetings and write thick, boring specification docs
12:24:15 <bscarlet> kmc: Yet skill is involved - in an industry of pure automation, that which can be defined too clearly gets automated out of the human part of the process, which tends to select for the hard-to-define parts.
12:24:18 <sutabi_> kmc thats priceless haha
12:25:00 <kmc> http://www.fastcompany.com/magazine/06/writestuff.html
12:25:30 <chrisdone> is (+) strict?
12:25:42 <bscarlet> kmc: and it's not unreasonable that practice be at least part of how one acquire a skill.
12:25:43 <kmc> chrisdone, it's a typeclass method
12:25:46 <dmwit> chrisdone: For some types, yes.
12:25:50 <int-e> Ah, another insight: Software isn't written to be used but to be sold. :) (Exaggerating of course)
12:25:53 <dmwit> (most types, actually)
12:26:02 <chrisdone> dmwit: int, integer, builtins?
12:26:06 <erus`> how does one make a strict function?
12:26:12 <dmwit> chrisdone: Yes, strict for those.
12:26:17 <chrisdone> thought so
12:26:20 <dmwit> erus`: using primops (e.g. seq)
12:26:20 <kmc> erus`, by pattern-matching on your argument
12:26:29 <kmc> seq is not the fundamental way
12:26:35 * dmwit feels foolish now
12:26:54 <kmc> > let f (Just x) = (); f Nothing = () in f undefined
12:26:55 <lambdabot>   *Exception: Prelude.undefined
12:27:00 <kmc> ^^^^ strict function
12:27:08 <kmc> f is strict ifff f ⊥ = ⊥
12:27:13 <kmc> haha ifff
12:27:19 <kmc> i have invented a new logical connective
12:27:24 <int-e> iff and only iff!
12:27:30 <kmc> please notify the american mathematical society
12:27:56 <int-e> (which expands to  if and only if and only if and only if  but avoids the ambiguous parse :-) )
12:28:02 <thoughtpolice> ergo, f = const undefined is strict
12:28:06 <kmc> chrisdone, in GHC, (I# x) + (I# y) = I# (addInt# x y)
12:28:07 <thoughtpolice> :P
12:28:08 <kmc> or whatever
12:28:13 <kmc> so yeah it pattern matches
12:28:45 <jerji> is it inadvisable for any reason to learn haskell from Hudak's SOE book? I'm having trouble getting SOEGraphics setup (OSX) and I just wanted some validation that this route is still good and well. most of the links I've found are several years old
12:29:05 <chrisdone> i was just reading SICP about implementing a lazy language and one way they suggest is primitive operations being strict
12:30:16 <chrisdone> seems like haskell does that (via pattern matching but all the same)
12:30:43 <chrisdone> kmc: is the I# a box?
12:30:54 <augur> anyone? :(
12:30:56 <XniX23> kmc: so you're saying that there is a better way than trial and error just that no one actually put it in a paper yet?
12:31:00 <parcs> seq is pretty fundamental..
12:31:01 <chrisdone> (as in 'unboxed integers' said by dons)
12:31:06 <augur> surely there have been good blogposts lately!
12:31:17 <kmc> XniX23, no, barrels of ink have been spilled about this subject
12:31:23 <kmc> I don't know which of it is crap
12:31:31 <kmc> I don't think anyone in this room is an expert in that field
12:31:40 <kmc> (please jump in if you are!)
12:32:07 <kmc> XniX23, one thing I mentioned is that a lot of the "design patterns" literature comes down to fixing flaws in C++ or Java, and not anything more fundamental than that
12:32:11 <thoughtpolice> chrisdone: yes, int is defined something like 'data Int = I# Int#'
12:32:14 <thoughtpolice> where Int# is unboxed
12:32:16 <kmc> I'd hope the bedrock principles of software engineering could apply to most languages
12:32:25 <chrisdone> thoughtpolice: makes sense
12:32:27 <thoughtpolice> so the I# constructor is effectively the box, and x in kmc's example would be an Int#
12:34:43 <thoughtpolice> chrisdone: for a little more detail you can check the terminology on the top of this page, fwiw - http://hackage.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects
12:35:26 <chrisdone> thoughtpolice: ah, good page. thanks
12:35:58 <thoughtpolice> that page is generally loaded with useful info, but you probably don't need to care about most of it :P
12:36:22 <thoughtpolice> chrisdone: i think unboxed tuples are the real 'magical' unboxed type, because they effectively put things directly in registers, IIRC
12:36:50 <thoughtpolice> there are more restrictions on the usage of unboxed tuples than other unboxed tuples, though
12:36:53 <benmachine> kmc: the way I see it, we've been building bridges for millenia, but there are people who have been around longer than mainstream software engineering
12:36:58 <thoughtpolice> er, 'unboxed types, though'
12:37:05 <Cale> We just need to turn software engineering into a branch of mathematics, and then we'll be able to teach it.
12:37:20 <Cale> (like we've already done with computer science)
12:37:29 <kmc> i don't think that will happen
12:37:39 <kmc> engineering is about messy real-world tradeoffs under uncertainty
12:37:40 <bscarlet> I don't think it makes sense.
12:37:41 <Cale> Categorical software engineering ;)
12:37:49 <benmachine> Cale: are we any good at teaching computer science yet?
12:37:55 <Cale> benmachine: In theory
12:38:06 <benmachine> hahaha
12:38:12 <benmachine> close enough right :P
12:38:32 <benmachine> I've never done "real" CS so I'll not judge
12:38:39 <benmachine> but I remember reading a study about how
12:38:56 <benmachine> after their first term, people were just as good at working out how variables work as they were before
12:39:14 <benmachine> and various academics went "this shows understanding of variables is innate"
12:39:27 <benmachine> and I went "no, this shows your first term is complete rubbish"
12:39:30 <chrisdone> thoughtpolice: i'm messing about with simple haskell->js compilation. it seems easier when you already have garbage collection and closures and scope, just a matter of getting the evaluation model right
12:39:45 * hackagebot narc 0.1.1 - Query SQL databases using Nested Relational Calculus embedded in Haskell.  http://hackage.haskell.org/package/narc-0.1.1 (EzraCooper)
12:39:56 <benmachine> chrisdone: if you get that right I will give you a big hug
12:39:58 <chrisdone> nested relational calculus? sounds sexy
12:40:02 <luite> chrisdone: for which compiler?
12:40:04 <thoughtpolice> chrisdone: you may like to know there's an ongoing project to add a JS backend to GHC :)
12:40:11 <kmc> and an existing backend for UHC
12:40:12 * benmachine still upset about how JS makes x + 1 - 1 different from x - 1 + 1
12:40:13 <thoughtpolice> that 'mostly works' at the moment iirc
12:40:33 <luite> yes all of them "mostly work", which means "useless in practice" :p
12:40:40 <benmachine> ( http://hpaste.org/49647 )
12:40:45 <chrisdone> what luite said
12:40:52 <thoughtpolice> https://github.com/the-real-blackh/ghc/
12:41:11 <thoughtpolice> that master branch has all the work in it. hamish has brought up merging it before, i don't really know if anybody took the time to reply and look at it
12:41:25 <thoughtpolice> the code was originally part of ghcjs and did work. ghcjs used the GHC API to do its compilation
12:41:28 <thoughtpolice> so this is just an integration of that
12:41:39 <chrisdone> luite: no plans. i'm just dabbling, i've never implemented a lazy language or written a compiler
12:42:27 <thoughtpolice> luite: well, you can use the standard libs and all the other goodies with this one. :) i don't think the tree is properly fingerprinted though, so it may have broken a little since work was done
12:42:28 <chrisdone> thoughtpolice: i've seen ghcjs which is still incomplete and produces big and scary output. i'm not sure what project you just linked as my connection's very fickle tonight
12:42:45 <thoughtpolice> chrisdone: https://github.com/the-real-blackh/ghc/
12:43:00 <chrisdone> yeah i saw the link, but i can't view it. i'm surprised IRC is still connected
12:43:04 <thoughtpolice> oh
12:43:19 <chrisdone> is it different to ghcjs?
12:43:38 <thoughtpolice> chrisdone: it's basically work that merges ghcjs's backend (which was standalone) directly into GHC itself
12:43:47 <chrisdone> ah, ok
12:43:47 <thoughtpolice> they've done other parts of work on it though
12:43:51 <thoughtpolice> you'd honestly have to look at the commit list
12:43:58 <thoughtpolice> i do believe it also has JS FFI support among other things
12:44:57 <thoughtpolice> an, and hamish updated it just about a month ago. but ghc changes fast. :)
12:45:11 <chrisdone> does it have an IO monad or a JS monad? i think the former is confusing and the latter would make more sense
12:45:55 <thoughtpolice> i'm not particularly sure on all the details, tbqh. again you'd have to look at the actual commit list as opposed to mainline GHC to exactly see everything they've done
12:46:25 <thoughtpolice> the original author pretty much abandoned it. they integrated it and made improvements, but to what extent i can't tell you with complete accuracy
12:46:59 <thoughtpolice> alternatively, if stephen blackheathe shows up you could ask him :)
12:47:05 <thoughtpolice> preflex: seen blackdog
12:47:06 <preflex>  blackdog was last seen on #haskell 6 days, 11 hours, 53 minutes and 16 seconds ago, saying: ion: *groan*
12:48:08 <Ke> wonder if there is an extension that makes ghc print out the cause of pattern mismatch
12:48:29 <Ke> if instance of show exists
12:48:44 <XniX23> kmc and all others who participated in a longer than expected debate, thank you, i think i get it a little better now :)
12:48:55 <chrisdon`> ~_~
12:50:37 <chrisdon`> Don't zonk skolems; eliminates a debug WARNING  -- simonpj
12:50:42 <chrisdon`> got it; never zonk skolems
12:50:48 <kmc> @quote skolems
12:50:48 <lambdabot> chrisdone says: anyone got a fixed version of the split library for ghc7? some Tolkienesque error messages about skolems escaping
12:51:11 * chrisdon` chuckles
12:54:51 <jerji> can anyone answer my question about Haskell: School of Expression earlier?
12:55:26 <chrisdon`> there's the lambdascript language -- you guys seen that?
12:55:28 <Cale> jerji: There *might* be a newer soe package on hackage
12:55:46 <Cale> jerji: At least, there was, I don't know exactly how up to date it is
12:55:57 <Cale> So you might be able to cabal install soe
12:56:22 <jerji> okay
12:57:12 <jerji> I've messed around with a couple of the ones there but I'm still lacking understanding of the basic file system structure of how cabal and mac ports install software, so it's possible I just have some wires that need to be connected better. I did install soegtk as well as HGL (both packages are listened in the "soe" search on Hackage)
12:57:27 <jerji> mostly I just wanted to make sure I'm not running into a dead-end
12:57:43 <jerji> seems like a pretty cool book and I'd like to work through it-- especially excited about the music stuff at the end
12:59:10 <acowley> Does anyone know if the ByteString builder is going to get better at concatenating short bytestrings in the near future?
12:59:19 <acowley> err, Binary.Builder I mean
12:59:36 <byorgey> jerji: try this instead: http://haskell.cs.yale.edu/?page_id=276
12:59:52 <byorgey> they're working on a new book based around music =)
13:01:28 <benmachine> the thing with guards is
13:01:36 <benmachine> you can't make, like, a guard tree
13:02:06 <benmachine> to reflect if b1 then if b2 then e1 else e2 else e3
13:02:53 <dmwit> f | b1 = case () of { _ | b2 -> e1 | otherwise -> e2 } | otherwise = e3
13:03:03 <jerji> byorgey: wow, that's pretty cool. thanks
13:03:04 <thoughtpolice> acowley: is it slow at concatenating short bytestrings? i do believe dcoutts_ et al have plans for a new Builder type that they hope can resolve some issues (including giving binary the ability to do incremental, CPS-style parsing like cereal/attoparsec)
13:03:20 <thoughtpolice> i may be misremembering, but I do know some people are doing a bit of work on this. you should probably ping them :)
13:03:21 <acowley> it's slow for what seems like a painfully silly reason
13:03:27 <acowley> it flushes every time you append a BS
13:03:42 <acowley> if you mconcat . map singleton over a string, you can get 2x performance
13:03:48 <acowley> for short strings
13:04:00 <acowley> blaze-builder seems to handle things much better
13:04:15 <tantalum>  /connect efnet.cs.hut.fi
13:04:24 <thoughtpolice> acowley: yeah, i think they're taking some of the new Builder stuff from blaze. i think. again, ask dcoutts_, he knows more :)
13:04:32 <acowley> so I added a blaze-builder dependency to haxr some time ago, and I'm revisiting the issue now to see if we could just use Binary
13:05:02 <acowley> Using the Binary builder with mconcat and singleton leaves me with higher variance in microbenchmarks
13:05:13 <acowley> so I'm inclined to keep using blaze
13:08:52 <jerji> byorgey: thanks again for the link, this is very exciting!
13:13:03 <chrisdon`> :t enumFromTo
13:13:03 <lambdabot> forall a. (Enum a) => a -> a -> [a]
13:13:15 <c_wraith> > enumFromTo () ()
13:13:15 <lambdabot>   [()]
13:23:03 <roconnor> > enumFromTo minBound maxBound
13:23:03 <lambdabot>   [()]
13:23:10 <albertid> Can I export everything that I import from a module?
13:23:15 <kmc> yes
13:23:24 <kmc> module Foo ( module Bar ) where { import Bar }
13:24:20 <albertid> thanks
13:33:48 <ash__> so… I have a C module I am calling from haskell via ffi, it prints debug messages on occasion and they are happening out of sync with the messages from haskell, is that because of laziness? or not flushing buffers perhaps?
13:34:19 <kmc> probably buffering
13:34:33 <benmachine> libc does its own buffering
13:34:38 <kmc> laziness would imply that your IO is driven by Haskell evaluation
13:34:40 <benmachine> I imagine haskell does its own buffering
13:34:45 <kmc> which is never the case unless you cheat and use unsafePerformIO or something
13:34:52 <benmachine> kmc: possible if the import signatures are wrong
13:34:58 <kmc> or FFI-import your C functions without IO in the type
13:34:59 <kmc> yeah
13:35:15 <sipa> ash__: if possible, you can call setbuf(stdout,NULL) in the C code
13:35:25 <sipa> to prevent output buffering by livcx
13:35:27 <sipa> *libc
13:35:38 <kmc> you can make that call from Haskell, even
13:35:42 <monochrom> import foreign f :: Int->Int  but f does a printf, that can be fun
13:36:19 <ash__> well, i defined it as CString -> IO CInt
13:36:23 <monochrom> then again if that's just a debugging printf, we don't usually mind
13:36:41 <benmachine> monochrom: we mind if it's still there in production :P
13:36:42 <monochrom> ah, IO CInt is buffering then
13:37:15 <ash__> ya, I copy my debug messages to a log file, so they are fine there, just odd when I noticed they were out of order
13:37:42 <kmc> this can also happen with threads
13:37:45 <kmc> even without doing FFI
13:38:00 <kmc> if two Haskell threads output messages, there is no guarantee about how they interleave
13:38:15 <hpaste> ash__ pasted “simple out of order io” at http://hpaste.org/49753
13:38:29 <ash__> ^ is a 3~4 (significant line) example of it
13:38:32 <monochrom> outputting to file has more buffering funniless than outputting to terminal, by default
13:38:41 <monochrom> err, s/funniless/funniness/
13:38:42 <rvn_> why
13:40:08 <monochrom> because by default, I/O libraries go "if your handle is terminal then line-buffer else block-buffer"
13:47:55 <byorgey> jerji: great =)
13:50:56 <ash__> adding in a stdio.h fflush(NULL) (null causes it to flush all open output buffers)  lets everything print in order
13:54:55 <darrint> ash__: That makes sense.
13:56:00 <stobix> hm. I don't think cabal likes me:
13:56:00 <stobix> Configuring Cabal-1.8.0.6...
13:56:00 <stobix> setup: At least the following dependencies are missing:
13:56:00 <stobix> base >=4 && <3 && >=1 && <5, filepath >=1 && <1.2
13:56:01 <ddarius> @google "categorical software engineering"
13:56:02 <lambdabot> http://answers.yahoo.com/question/index?qid=20081202131141AA9pGBr
13:56:02 <lambdabot> Title: Who earns more and which one takes longer to study? - Yahoo! Answers
13:56:14 <ddarius> @google "categorical software engineering" goguen
13:56:14 <lambdabot> No Result Found.
13:56:21 <ddarius> @google categorical software engineering goguen
13:56:21 <lambdabot> http://en.wikipedia.org/wiki/Joseph_Goguen
13:56:22 <lambdabot> Title: Joseph Goguen - Wikipedia, the free encyclopedia
13:57:02 <kmc> base >=4 && <3 && >=1
13:57:03 <kmc> brilliant
13:57:42 <stobix> could you fetch that base version for me, please? ;)
13:57:48 <ddarius> All your paradoxical base are belong to us
13:57:52 <stobix> haha
13:58:13 <NihilistDandy> kmc: Where did you see that?
13:58:19 <kmc> just above
13:58:30 <NihilistDandy> Oh, I see it
13:58:46 <NihilistDandy> Delightful
14:01:45 <stobix> "break you a haskell, for great good!"
14:04:20 * hackagebot statestack 0.1 - Simple State-like monad transformer with saveable and restorable state  http://hackage.haskell.org/package/statestack-0.1 (BrentYorgey)
14:05:20 * hackagebot narc 0.1.2 - Query SQL databases using Nested Relational Calculus embedded in Haskell.  http://hackage.haskell.org/package/narc-0.1.2 (EzraCooper)
14:07:50 <danharaj> hum, I have to wonder why Haskell is so much more readable with single letter names whereas java needs GetFactoryMonstrosityFactorySingletonAdapters.
14:08:24 <NihilistDandy> danharaj: OOP naming conventions? :D
14:08:45 <c_wraith> danharaj: because java has types that shouldn't be types - they exist for organization, rather than because you want to represent them.
14:08:59 <monochrom> because "Just (a,b) : c" has explicit structure regardless of what a,b,c mean
14:09:52 <monochrom> whereas if you translate java to haskell it's all "do { m; n; o; p }" and has no explicit structure when you don't recall what m,n,o,p mean
14:11:02 <ddarius> Locality
14:11:23 <monochrom> and so you have the same problem if you do everything in IO
14:12:33 <stobix> hm, wonder if it would be a good idea to implement lojban in haskell in some way...
14:12:44 <monochrom> for example "sendmesg :: String -> IO ()" and "putStrLn :: String -> IO ()" rely totally on naming to differentiate
14:13:00 <NihilistDandy> stobix: The answer is no
14:13:16 <stobix> NihilistDandy: oh? Better with perl then? ;)
14:13:20 <NihilistDandy> lol
14:13:32 <stobix> (perligata etc)
14:16:13 <ddarius> "Programming, in its broadest sense, is problem solving." - Paul Hudak  This is exactly my view.
14:17:53 <byorgey> stobix: http://hackage.haskell.org/package/lojban
14:18:07 <stobix> ooo
14:18:18 <byorgey> appears to be abandoned, but might still work
14:18:54 <ddarius> Lambdabot used to have a lojban command, but I think it just shelled out to some program.
14:18:58 <stobix> "programming is art" -- me
14:19:31 <danharaj> A blog post comparing programming to tending a garden once got high on /r/programming.
14:19:40 <danharaj> Man that thing sucked.
14:19:58 <ddarius> Good thing /r/programming is dead now
14:20:09 <danharaj> intellectually or operationally?
14:20:10 <stobix> hm. a module to extract meaning of lojbanic words from jbovlaste. Not really what I was after...
14:20:50 <ddarius> danharaj: I was just taking advantage of your referential ambiguity.  I've never followed reddit.
14:21:32 <danharaj> Honestly I just stick around for /r/haskell, but I like to pretend I'm better than the rest of the site on occassion.
14:22:00 <dsj36> there's always /r/circlejerk
14:23:44 <joseanpg> Good night
14:24:47 <joseanpg> someone knows simple Monad examples different of Maybe, etc?
14:26:05 <Cale> > let dict = [(0,1),(1,4),(2,3),(3,5),(4,5)] in do x <- lookup 0 dict; return x
14:26:06 <lambdabot>   Just 1
14:26:16 <Cale> > let dict = [(0,1),(1,4),(2,3),(3,5),(4,5)] in do x <- lookup 0 dict; y <- lookup x dict; return y
14:26:17 <lambdabot>   Just 4
14:26:31 <Cale> > let dict = [(0,1),(1,4),(2,3),(3,5),(4,5)] in do x <- lookup 0 dict; y <- lookup x dict; z <- lookup y dict; return z
14:26:32 <lambdabot>   Just 5
14:26:44 <Cale> > let dict = [(0,1),(1,4),(2,3),(3,5),(4,5)] in do x <- lookup 0 dict; y <- lookup x dict; z <- lookup y dict; w <- lookup z dict; return w
14:26:44 <lambdabot>   Nothing
14:27:19 <Cale> joseanpg: That's not a great example, but shows how you can use the Maybe monad to chain potentially-failing things.
14:27:42 <joseanpg> thanks Cale
14:27:56 <Cale> (instead of writing lots of  case ... of Nothing -> Nothing; Just x -> case f x of ...
14:27:59 <Cale> )
14:28:29 <danharaj> joseanpg: You can think about the identity monad too if you want. You just wrap everything in a newtype declaration and define return as wrapping, and (>>=) as unwrapping and then applying the function. It's not a very interesting monad, but it can help intuition building.
14:29:29 <Cale> Are you looking for examples of monad usage in general, or just Maybe?
14:29:37 <joseanpg> in general
14:29:40 <bscarlet> > let dict = [(0,1),(1,4),(2,3),(3,5),(4,5)] in do x <- lookup 0 dict; y <- lookup x dict; z <- lookup y dict; w <- lookup z dict; v <- lookup w dict; return v
14:29:40 <lambdabot>   Nothing
14:29:57 <Peaker> joseanpg: The list monad is very similar to the Maybe monad, except instead of having just 0 or 1 values, you have N values and when you have >1 value, each of them is tried in turn
14:30:06 <Peaker> Cale: I think he asked for non-Maybe examples
14:30:18 <Cale> > do x <- [1,2,3]; y <- [4,5]; z <- [6,7,8]; return (x,y,z)
14:30:18 <lambdabot>   [(1,4,6),(1,4,7),(1,4,8),(1,5,6),(1,5,7),(1,5,8),(2,4,6),(2,4,7),(2,4,8),(2...
14:30:25 <Cale> > do x <- [1,2,3]; y <- []; z <- [6,7,8]; return (x,y,z)
14:30:26 <lambdabot>   []
14:30:26 <joseanpg> you are right Peaker :)
14:30:31 <Cale> > do x <- [1,2,3]; []; z <- [6,7,8]; return (x,y,z)
14:30:32 <lambdabot>   []
14:30:46 <Cale> > do x <- [1,2,3]; if even x then [] else [4,5]; z <- [6,7,8]; return (x,y,z)
14:30:46 <lambdabot>   [(1,y,6),(1,y,7),(1,y,8),(1,y,6),(1,y,7),(1,y,8),(3,y,6),(3,y,7),(3,y,8),(3...
14:30:53 <Cale> > do x <- [1,2,3]; y <- if even x then [] else [4,5]; z <- [6,7,8]; return (x,y,z)
14:30:54 <lambdabot>   [(1,4,6),(1,4,7),(1,4,8),(1,5,6),(1,5,7),(1,5,8),(3,4,6),(3,4,7),(3,4,8),(3...
14:31:03 <joseanpg> but all Cale and danharaj is good for me too
14:31:03 <Cale> (lol, lambdabot "helping out" there ;)
14:31:40 <Cale> > do x <- [1,2,3]; guard (odd x); z <- [6,7,8]; return (x,z)
14:31:41 <lambdabot>   [(1,6),(1,7),(1,8),(3,6),(3,7),(3,8)]
14:31:41 <joseanpg> I'm taking note of all
14:31:51 <Peaker> joseanpg: Reader monad is also very simple (except the syntax is confusing to beginners!):   instance Monad ((->) env) where return x = \env -> x   ;  env_to_a >>= a_to_env_to_b = \env -> a_to_env_to_b (env_to_a env) env
14:32:09 <Cale> So, the list monad is all about making selections in all possible ways. It's identical to list comprehensions
14:32:31 <Cale> I think those variable names actually make the code harder to read than single letter variables would be
14:32:57 <Peaker> Or using less annoying names:  instance Monad ((->) r) where return x = \env -> x ;   a >>= f   =   \env -> f (a env) env
14:32:58 <Cale> > (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z)) "hello"
14:32:59 <lambdabot>   ("hello","olleh","HELLO")
14:33:11 <ddarius> s/a/m/g
14:33:14 <joseanpg> Cale is efficient think comprehnsions as monad operation?
14:33:24 <Peaker> Cale: I agree it's harder for me, but I think maybe for a beginner it would be slightly easier (not sure though)
14:33:31 <danharaj> joseanpg: Comprehensions are exactly monad expressions.
14:33:36 <danharaj> For lists, at least.
14:33:47 <Peaker> Cale: If the types aren't obvious to you at all, as a beginner, maybe encoding them in the name helps (but again, I'm not sure...)
14:33:49 <danharaj> (Also GHC let's you use comprehension syntax for arbitrary monads)
14:34:03 <Peaker> It could be nice to visualize the values with their types nicely.. a good Haskell IDE could do that
14:34:21 <joseanpg> but that implies using too concats, isn't it?
14:34:40 * monochrom just used the list monad to brute-force a The 11th Hour puzzle today :)
14:34:46 <Cale> Peaker: Ryan just gave me his start on that sort of thing today -- a little gtk2hs program which loads up the source, and prints types of things in the terminal when you click them.
14:34:59 <danharaj> joseanpg: concat is part of the monad structure of list.
14:35:02 <danharaj> :t concat
14:35:02 <lambdabot> forall a. [[a]] -> [a]
14:35:11 <danharaj> :t join
14:35:11 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
14:35:31 <Peaker> Cale: cool, though it could be even nicer to visualize it graphically-nearby somehow
14:35:43 <kmc> it kind of sucks that a full half of that type signature is a) not Haskell 98 b) irrelevant
14:36:05 <danharaj> Yeah.
14:36:05 <Cale> Peaker: yeah, it's just a quick hack for now, but might eventually turn into an IDE :)
14:36:06 <danharaj> :\
14:36:10 * ddarius prefers explicit quantification, though the kind signature is a bit much.
14:36:36 * ddarius wishes Haskell didn't have implicit quantification.
14:36:52 <danharaj> implicit quantification tripped me up when I was learning, I think.
14:36:55 <Peaker> ddarius: Implicit quantifications are convenient :)
14:37:02 <kmc> i'm okay with explicit quantification as long as i can write ∀
14:37:02 <Peaker> HM principal types are soo common
14:37:14 <Peaker> how do you write that without copy&paste?
14:37:40 <kmc> http://mainisusuallyafunction.blogspot.com/2010/10/typing-mathematical-characters-in-x.html
14:38:40 <Cale> I can type ∀ by pressing Ctrl-Space and then Ctrl-Alt-Space until I'm in TeX mode and then \forall
14:39:01 <Eliel> Cale what monad is that last example using? ghci tells me "No instance for (Monad (->) [Char]))
14:39:14 <Cale> Eliel: import Control.Monad.Instances
14:39:22 <Cale> Eliel: it's the (->) [Char] monad
14:39:42 <byorgey> More generally ((->) e) is a monad for any type e
14:39:44 <Cale> It's just that for hysterical raisins, that Monad isn't in the Prelude
14:40:09 <Cale> (->) e a = e -> a
14:40:17 <Cale> So:
14:40:29 <Cale> return :: a -> m a  --->   return :: a -> (e -> a)
14:40:32 <Cale> and return = const
14:40:51 <kmc> Cale, it's for good reasons imo
14:41:05 <kmc> if you have that instance, a lot more typos will type check
14:41:29 <Cale> (>>=) :: m a -> (a -> m b) -> m b  --->  (e -> a) -> (a -> e -> b) -> (e -> b)
14:41:41 <kmc> @djinn (e -> a) -> (a -> e -> b) -> (e -> b)
14:41:41 <lambdabot> f a b c = b (a c) c
14:42:00 <joseanpg>  [x+y|x<-[1,2],y<-[1,2,3]] is the equal to [1,2] >>= (\x->[1,2,3] >>= (\y->return (x+y))) ?
14:42:08 <kmc> yes
14:42:20 <Eliel> what kind of typoes would it allow to typecheck?
14:42:21 <kmc> it's also equal to do { x <- [1,2]; y <- [1,2,3]; return (x+y) }
14:42:38 <kmc> Eliel, putChar >> putChar
14:42:45 <kmc> as a typo for putChar 'x' >> putChar 'y'
14:42:56 <Cale> But it probably just moves the type error a bit
14:42:58 <kmc> in ((->) r), (f >> g) is valid but useless
14:43:02 <Peaker> But you're likely to have  putChar >> putChar 'x'  or such
14:43:06 <Cale> rather than actually letting the whole program typecheck
14:43:16 <kmc> i've seen examples where the whole program checked
14:43:31 <Cale> I can imagine there might be some
14:43:39 <Peaker> It could be nice to have WARNING RULES like rewrite rules, but issue warnings (uselessness of (>>) for reader, etc)
14:43:44 <joseanpg> there are two concats there, isn't it?
14:43:57 <Peaker> I guess hlint could possibly do that
14:44:13 <Cale> joseanpg: Yeah, x >>= f is the same as concatMap f x is the same as concat (map f x)
14:44:26 <Eliel> this ((->) r) monad looks pretty neat. Can it do other tricks than giving one parameter to multiple functions at once?
14:44:38 <Cale> Eliel: Nope, that's basically all it does
14:44:40 <joseanpg> it builds many lists
14:44:51 <kmc> that's what (>>=) does and so that's the only trick, in a sense
14:45:01 <Cale> join :: m (m a) -> m a   --->  (e -> e -> a) -> (e -> a)
14:45:04 <Cale> is useful
14:45:16 <Cale> joseanpg: sort of
14:45:23 <joseanpg> I thinked that comprehension was like two nested loops
14:45:27 <Cale> joseanpg: Though those lists won't ever be entirely in memory
14:45:31 * hackagebot error-location 0.1.5 - error functions that show file location information  http://hackage.haskell.org/package/error-location-0.1.5 (GregWeber)
14:45:41 <Cale> joseanpg: because they're lazy, and their elements quickly become garbage
14:45:48 <Eliel> I'll probably stick to Control.Arrow for when I only need to apply one parameter to two functions at once :)
14:45:56 <Cale> also, list fusion rules will eliminate most of them if you turn optimisations on
14:45:59 <Eliel> consider this only when I need more :)
14:46:03 <Peaker> Eliel: it's all about implicitly passing around an argument all over the place.. It's called the "Reader" or "Environment" monad because it allows everyone read-only access to a parameterized "global" environment (not really global, only in the scope of the bound things)
14:46:11 <Cale> So, don't try to reason about the performance unless you have to ;)
14:46:14 <parcs> the applicative instance is useful too
14:46:27 <ddarius> ... is the same as join (fmap f x)
14:46:51 <joseanpg> Cale: list fusion rules? what's that?
14:47:02 <Eliel> Peaker: this is about this ((->) r) monad, right?
14:47:10 <Cale> things like   map f . map g --> map (f . g)
14:47:38 <Cale> The list library tells the compiler about some fairly general source to source translations it can do to speed things up
14:47:48 <ddarius> Cale: I don't think list fusion will make asymptotic differences in either running time or, in most cases, live memory.
14:47:50 <Cale> and it will do them if you set -O2
14:48:06 <Cale> ddarius: agreed, it's only a constant factor
14:48:14 <joseanpg> that is the functor law isn't it?
14:48:18 <Cale> joseanpg: yes
14:48:25 <Cale> joseanpg: But it's also good for performance ;)
14:48:49 <Cale> because it eliminates construction of intermediate list cells
14:49:37 <joseanpg> do you have some link about it?
14:50:08 <Cale> http://www.haskell.org/ghc/docs/7.0.3/html/users_guide/rewrite-rules.html -- well, here's the GHC feature being used...
14:50:25 <ddarius> There are piles and piles of papers on various fusion schemes.
14:50:32 * hackagebot error-location 0.1.5.1 - error functions that show file location information  http://hackage.haskell.org/package/error-location-0.1.5.1 (GregWeber)
14:50:34 <kmc> @google lists to streams to nothing at all
14:50:35 <lambdabot> http://portal.acm.org/citation.cfm?id=1291199
14:50:35 <lambdabot> Title: Stream fusion
14:50:45 <Cale> ah, excellent, yes, that paper is good
14:50:47 <joseanpg> what is that!!!
14:51:01 <Cale> er, except not that link to it
14:51:13 <joseanpg> lambdabot is incredible
14:51:15 <joseanpg> hehehe
14:51:16 <Cale> http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.104.7401
14:51:23 <sipa> @vixen are you incredible?
14:51:24 <lambdabot> yes, i am
14:51:28 <sipa> QED.
14:51:32 <Cale> http://gernot-heiser.org/~dons/code/papers/stream-fusion/icfp088-coutts.pdf
14:51:37 <Cale> ^^ more specifically :)
14:51:42 <joseanpg> thanks
14:51:47 <ddarius> Albeit that is not the scheme used by GHC.
14:51:50 <Cale> oh, dang
14:51:54 <Cale> that link is dead
14:51:56 <ddarius> Though there is a library that does use it.
14:52:00 <Peaker> Eliel: yeah
14:52:10 <Cale> http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=19709CBCB971F36E99671797632513B8?doi=10.1.1.104.7401&rep=rep1&type=pdf
14:52:11 <ddarius> I don't know what "gernot-heiser" is.
14:52:18 <Cale> ^^ thankfully, there's a cached version
14:52:40 <ddarius> Wow, a citeseer link.  Not even a citeseerx one.  That link is live?
14:53:17 <Cale> yes, seemingly
14:56:50 <joseanpg> another question
14:57:05 <joseanpg> liftM is fmap, isn't it?
14:57:21 <kmc> yes
14:57:48 <Cale> With only a slightly different type
14:58:13 <Cale> It can be used as the implementation of fmap for anything with an instance of Monad
14:58:15 <joseanpg> Cale: could you explain that please?
14:58:27 <joseanpg> aa, yes
14:58:53 <Cale> liftM f x = return . f =<< x
14:59:03 <Cale> Or:
14:59:13 <Cale> liftM f x = do v <- x; return (f v)
14:59:18 <joseanpg> what is =<< ?
14:59:30 <Cale> f =<< x = x >>= f
14:59:46 <joseanpg> umm
14:59:46 <kmc> v =<< x = x >>= v
15:00:02 <Cale> (now it's really symmetrical ;)
15:00:13 <kmc> it's just (>>=) backwards
15:00:14 <Cale> joseanpg: so it's just a flipped over version of >>=
15:00:20 <joseanpg> (=<<) is the klesili star !
15:00:25 <Cale> yes
15:00:28 <joseanpg> very interesting
15:00:30 <parcs> :t let f = flip f in f
15:00:30 <lambdabot> forall a b. a -> a -> b
15:00:35 <kmc> @src kleisli
15:00:35 <lambdabot> Source not found. It can only be attributed to human error.
15:00:38 <kmc> @src Kleisli
15:00:38 <lambdabot> Source not found. Maybe if you used more than just two fingers...
15:00:52 <joseanpg> Kleisli
15:02:04 <parcs> :t fix (\f -> flip f)
15:02:05 <lambdabot> forall a b. a -> a -> b
15:02:28 <joseanpg> why Haskell designer don't use "Kleisli triples" term and call it Monad?
15:02:44 <Cale> joseanpg: Because that's old-fashioned terminology
15:03:09 <joseanpg> but a Kleisli triple is not the same
15:03:19 <Cale> Er...
15:03:22 <Cale> Is it not?
15:03:31 <Nimatek> Sounds cooler.
15:03:33 <ddarius> joseanpg: It's just a different presentation of the same concept.
15:03:35 <joseanpg> no
15:04:38 <Cale> joseanpg: perhaps you mean the Kleisli composition way of doing it?
15:04:44 <Cale> :t (<=<)
15:04:44 <lambdabot> forall b (m :: * -> *) c a. (Monad m) => (b -> m c) -> (a -> m b) -> a -> m c
15:05:09 <Peaker> I was really surprised that the 1965 paper (next 700 PL's) had used the term "monadic function composition" (from memory) to describe how the pure functional side would not be problematic for repeatedly modifying some state
15:05:10 <Cale> Oh, I see
15:05:16 <joseanpg> Kleisli: (T, eta, *)
15:05:26 <joseanpg> Monad: (T,eta,mu)
15:05:26 <Peaker> If they knew that in 1965, what took so long?
15:05:28 <Cale> yeah, there is a Kleisli triple definition here on Wikipedia which is different from (T,eta,mu)
15:05:30 <Cale> yeah
15:05:39 <Cale> The difference is inconsequential though
15:05:48 <Cale> They're like two different definitions of the same concept
15:05:55 <joseanpg> with monad eta, mu are natural transformations and T is functor
15:06:08 <joseanpg> with kleisli T is a simple map
15:06:12 <Cale> right
15:06:15 <Cale> as it is here
15:06:25 <stobix> :t ( ++ " " ++ )
15:06:26 <lambdabot> parse error on input `)'
15:06:29 <stobix> :/
15:06:31 <joseanpg> Haskell monads are kleisli triples
15:06:43 <sipa> :t (\x y -> x ++ " " ++ y)
15:06:43 <lambdabot> [Char] -> [Char] -> [Char]
15:06:47 <ddarius> Peaker: What Landin did, though, was not really akin to monadic style.
15:06:52 <Cale> But every Kleisli triple gives rise to a unique monad and every monad gives rise to a unique Kleisli triple
15:06:57 <Cale> So they're the same thing.
15:06:58 <joseanpg> yes
15:07:06 <joseanpg> are equivalent
15:07:09 <joseanpg> not the same
15:07:10 <joseanpg> :)
15:07:23 <kmc> "same" and "equivalent" are equivalent
15:07:31 <joseanpg> equal?
15:07:32 <sipa> but they're not the same :)
15:07:35 <Peaker> ddarius: I'm trying to figure out what we know now about monadic compositions/etc that they didn't know then.. there discussion from the 60's in http://www.thecorememory.com/Next_700.pdf seems awfully close to discussions Haskell intermediates would have these days
15:07:52 <Cale> joseanpg: Once you have a library that defines all the other things in terms of whatever primitives you chose, they're pretty much the same :)
15:08:11 <joseanpg> with liftM ... yes
15:08:17 <Cale> joseanpg: We also have join (= mu)
15:08:33 <joseanpg> I forget it, yes
15:08:45 <Cale> I also like defining monads in terms of (<=<)
15:08:48 <Cale> and return
15:08:55 <sipa> :t (<=<)
15:08:56 <lambdabot> forall b (m :: * -> *) c a. (Monad m) => (b -> m c) -> (a -> m b) -> a -> m c
15:08:58 <joseanpg> Next_700 is the Landin's paper?
15:08:58 <Cale> Because the laws work out nicely
15:09:08 <Cale> The laws are that it forms a category ;)
15:09:14 <Cale> return <=< f = f
15:09:16 <joseanpg> but why Monad instead the Kleisli
15:09:19 <Cale> f <=< return = f
15:09:21 <Cale> and
15:09:23 <Peaker> ddarius: what did Landin do?
15:09:30 <Cale> (f <=< g) <=< h = f <=< (g <=< h)
15:09:46 <Cale> joseanpg: Because it doesn't matter. ;)
15:10:13 <Cale> joseanpg: Actually, a lot of people want join in the definition of the Monad class and a superclass constraint for Functor
15:10:23 <joseanpg> Iumm
15:10:25 <ivanm> Cale: Monads won the terminology war!
15:10:40 <ivanm> s/Cale/joseanpg/
15:10:46 <Cale> ivanm: Actually, Kleisli triples also could have won, in a sense
15:10:59 <Cale> Because we define monads using their Kleisli triples
15:11:05 <Cale> But it's no big deal :)
15:11:06 <joseanpg> Kleisli won, with other name
15:11:13 <Peaker> it's pretty bizarre seeing a paper where TCO is not conventional wisdom :)
15:11:48 <Cale> What is TCO? ;)
15:12:17 <joseanpg> Why the link to ISWIN?
15:12:26 <Peaker> Tail-call-optimization
15:12:35 <Cale> Oh, how do you do that? ;)
15:12:40 <joseanpg> hehehe
15:13:49 <Peaker> at least there was *some* progress since the 60's :)
15:14:17 <Cale> .oO(My next question will be "What is the stack?")
15:14:48 <joseanpg> (don't forget "What is the heap?")
15:15:17 <ddarius> Peaker: Well, I may be thinking of an Algol 60 context where there was something sort of like a state token but it was more that statements had values so that sequential composition was const.
15:15:44 <ddarius> Peaker: Also note that Landin was a rather smart cookie.
15:16:08 <Peaker> ddarius: It seems like Landin is a Haskeller sent back in time to the 60's talking to these pure-functional skeptics
15:16:23 <joseanpg> I don't undertand "smart cookie"
15:16:58 <ddarius> Well certainly he is a precursor to much of the purely functional work.  ISWIM more or less captured ML/Haskell syntax.
15:17:05 <joseanpg> ISWIM isn't call-by-need
15:18:06 <ddarius> If you reduce lambda terms with the usual rewriting rules, you will get "TCO" for free.
15:18:07 <Cale> joseanpg: "one smart cookie" is just an idiom for someone clever, not sure where it came from
15:18:47 <joseanpg> Cale: thanks
15:19:41 <joseanpg> In Haskell TCO is disappointing
15:20:13 <kmc> indeed
15:20:15 <Cale> joseanpg: It doesn't apply
15:20:21 <Cale> because there's no stack
15:20:30 <Cale> or at least, no call stack
15:20:32 <ddarius> Cale: There's no stack in C.
15:20:34 <kmc> in Haskell we care about whether a function is productive, not whether it's tail-recursive
15:20:49 <ddarius> Tail call optimization is just as critical to Haskell as it is to Scheme.
15:21:02 <Cale> is it really?
15:21:08 <joseanpg> yes
15:21:10 <Cale> Well, what exactly are you referring to by that?
15:21:20 <ddarius> Cale: Yes.  foldl would use O(n) stack without TCO.
15:21:22 <joseanpg> but in Haskell there are two points
15:21:35 <Cale> ddarius: on which stack?
15:21:52 <Cale> @src folfl
15:21:52 <lambdabot> Source not found.
15:21:53 <Cale> @src foldl
15:21:53 <lambdabot> foldl f z []     = z
15:21:53 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
15:22:02 <ddarius> Cale: On the same stack that doesn't exist in C, yet overflows.
15:22:25 <joseanpg> the "engine" must eval the thunks and it needs a stack
15:22:29 <Cale> foldl immediately replaces itself with different parameters
15:22:35 <Cale> there's no TCO to be done
15:23:02 <joseanpg> foldr
15:23:03 <ddarius> Cale: The same is essentially true of the equivalent Scheme expression.
15:23:07 <Cale> You're just replacing one graph with another
15:23:09 <joseanpg> @src foldr
15:23:09 <lambdabot> foldr f z []     = z
15:23:09 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
15:23:16 <ddarius> The implementation of "replacing oneself with different parameters" is the TCO.
15:23:23 <ddarius> That's what TCO does.
15:23:23 <joseanpg> what do you see there?
15:23:26 <Cale> Well, how else would you do it?
15:23:32 <joseanpg> in foldr
15:23:43 <Cale> How would you implement it without that "TCO"
15:23:44 <joseanpg> foldr f z (x:xs) = f x (foldr f z xs)
15:23:51 <ddarius> Cale: The same way typical C compilers do it is also perfectly viable for Haskell.
15:23:55 <joseanpg> you need a stack
15:24:03 <joseanpg> in foldl
15:24:08 <joseanpg> @src foldl
15:24:08 <lambdabot> foldl f z []     = z
15:24:08 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
15:24:13 <Cale> You mean introduce a spurious extra stack which you never actually need?
15:24:16 <joseanpg> TCO !
15:24:24 <Cale> You don't need a stack
15:24:29 <ddarius> Cale: I agree.
15:24:32 <Cale> because evaluation is outermost first
15:24:59 <joseanpg> the thunks builds a stack
15:25:10 <Cale> Let's rewrite foldl in a bit lower level...
15:25:18 <ddarius> Evaluation doesn't need to be outermost first and even if you do innermost first you will get TCO with the "naive" rewrite rules.
15:25:26 <benmachine> so TCO in haskell is tail-call-not-doing-it-a-stupid-way
15:25:35 <Cale> foldl f z xs = case xs of [] -> z; (x:xs') -> foldl f (f z x) xs'
15:25:40 <ddarius> I don't consider TCO an optimization, rather lacking it is breaking the semantics of functions.
15:25:48 <benmachine> tail call non-pessimisation
15:25:57 <ddarius> benmachine: TCO in any language is "tail-call-not-doing-it-a-stupid-way."
15:26:05 <kmc> ddarius, so you consider thunk-updates themselves a form of TCO?
15:26:19 <Cale> there is a stack which builds up by one step if the list parameter needs to be evaluated
15:26:22 <Cale> but that's it
15:26:46 <ddarius> kmc: Actually, thunks can lead to trampolining obviating the need for TCO in certain cases (i.e. even if you did use C-style calling.)
15:27:08 * kmc is amused by the variety of different things called "trampolines"
15:27:24 <Cale> after the list parameter is evaluated, the pattern immediately gets matched and so the stack doesn't build up any higher, and the expression reduces to foldl of some stuff
15:27:45 <Cale> So the max stack height induced by foldl itself is 1
15:28:10 <Cale> I don't understand how to implement outermost-first evaluation with C style calling
15:28:19 <Cale> Those concepts don't mash together well in my head
15:28:57 <Cale> and so I don't understand what TCO even means in the context of an evaluator which is evaluating outermost first
15:29:05 <joseanpg> foldl (+) 0 [1,2,3]  ---- foldl (+) (0+1) [2,3]  ------ foldl (+) (0+1+2) [3] ----- foldl (+) (0+1+2+3) []  ---- (0+1+2+3)
15:29:05 <ddarius> Cale: It would be completely reasonable for me to compile foldl to a C function that takes thunks as arguments and calls itself recursively.
15:29:48 <joseanpg> @src foldr
15:29:48 <lambdabot> foldr f z []     = z
15:29:48 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
15:29:51 <Cale> ddarius: uh, I guess.
15:30:03 <Cale> ddarius: okay
15:30:21 <ddarius> Cale: There nothing special about outermost first here.  Needing TCO is just as much of non sequitur in eager languages.
15:31:38 <ddarius> If you knew the lambda calculus, the behavior of C would be surprising regardless of whether you knew the call-by-name lambda calculus or the call-by-value lambda calculus.
15:31:53 <c_wraith> languages that introspect the call stack make TCO interesting...
15:32:06 <c_wraith> and java happens to be one of those languages.
15:32:06 <Cale> I suppose if you implement an eager language using graph reduction, it'll automatically not have that problem, it's just that many C implementations are really dumb.
15:32:44 <ddarius> Languages that introspect the call stack tend to break every nice property.  TCO wouldn't even be ambiguous or non-deterministic in that context.
15:32:48 <ddarius> Though perhaps undesirable.
15:33:31 <ddarius> Cale: As I said earlier, if you simply do the by-hand β-reduction rewrites, neither eager or lazy evaluation will "lack TCO."
15:33:45 <joseanpg> Cale: graph reduction ... exists an easy introduction? (I have Peyton Jones book)
15:34:09 <Cale> joseanpg: hmmm
15:34:24 <ddarius> c_wraith: Also, one of the main "barriers" to TCO in Java was security checks, but those can be done in constant space in, what seems to me, a completely obvious manner.
15:36:46 <joseanpg> Cale, ddarius : what do you say about http://www.haskell.org/haskellwiki/Stack_overflow?
15:40:19 <Cale> joseanpg: You can get a stack overflow in GHC Haskell, but the stack that's overflowing isn't a call stack :)
15:40:29 <Cale> joseanpg: It's a pattern matching stack
15:41:05 <Cale> (whose entries are essentially case expressions waiting for their scrutinee to be evaluated enough that they can match a constructor)
15:41:20 <joseanpg> interesting
15:42:44 <joseanpg> Cale: that statement is very important
15:42:47 <Cale> With things like (+) it's a little hard to see that way, but you can think of (+) for Integer as pattern matching both its arguments (with an infinite case expression ;)
15:43:08 <NihilistDandy> I like the word "scrutinee"
15:43:23 <kmc> me too NihilistDandy
15:43:26 <Cale> Or, I suppose, you can look into the real implementation, which pattern matches a constructor to get an unboxed result.
15:44:16 <joseanpg> (LEARNING!!!)
15:44:18 <joseanpg> hehehe
15:44:22 <roconnor> whee.  I pulled the (Monad m) => Foo -> m Bar trick for partial functions and ended up using it with the Maybe, List and Either String monads!
15:45:07 <c_wraith> roconnor: not on GHC 7!
15:45:20 <roconnor> what happens on GHC 7?
15:45:22 <c_wraith> also, String is the wrong kind, can't be a monad.
15:45:32 <roconnor> (Either String) monad
15:45:38 <c_wraith> oh.
15:45:44 <c_wraith> right, that's what's different in GHC 7
15:45:53 <roconnor> ...
15:45:53 <c_wraith> fail = error in the Either monad
15:46:00 <c_wraith> because it's now Either a, instead of Either String
15:46:21 <hatds> :t maybe (fail "") return
15:46:21 <NihilistDandy> That stack overflow article is pretty great
15:46:22 <lambdabot> forall (m :: * -> *) a. (Monad m) => Maybe a -> m a
15:46:23 <roconnor> how does cereal cope?
15:47:03 <c_wraith> Which is part of why I don't like the "m Foo" thing.  It's abusing fail, and the more things get cleaned up in the libraries, the less useful it becomes.
15:47:10 <ddarius> joseanpg: I wrote (most) of that wiki page.
15:47:48 <roconnor> cereal makes extensive use of the (Either String) monad
15:48:24 <c_wraith> fail does something different, but Either a is still a monad.
15:48:32 <roconnor> oh crap
15:48:43 <roconnor> it doesn't actually use the (Either String) monad
15:48:47 <roconnor> that is just the result of run
15:48:52 <roconnor> *runGet
15:49:09 <ddarius> It would be ill-advised to actually use the Either String monrad.
15:49:18 <roconnor> indeed
15:49:35 <c_wraith> that's what people who advocate the "m Foo" return pattern are advocating, though.
15:49:41 <roconnor> okay, so that means fail is now totally useless?
15:49:43 <joseanpg> ddarius: that page is very good
15:49:48 <roconnor> i mean
15:49:59 <roconnor> how is fail different from mzero?
15:50:02 <c_wraith> roconnor: as it should be.  error should be the only correct implementation of fail.
15:50:16 <roconnor> so
15:50:23 <c_wraith> fail takes an argument, mzero does not
15:50:29 <c_wraith> that's the whole difference
15:50:38 <roconnor> how is fail different from const mzero
15:50:50 <hatds> technically, fail is tied to pattern matching semantics in a "do generator"
15:50:56 <joseanpg> ddarius: perhaps it can include Cale comment: You can get a stack overflow in GHC Haskell, but the stack that's overflowing isn't a call stack :) It's a pattern matching stack
15:51:25 <roconnor> c_wraith: Most instance of MonadPlust do not call error from fail
15:51:26 <roconnor> okay
15:51:42 <c_wraith> roconnor: indeed, which I think is wrong.
15:51:46 <roconnor> so fail calls error for non MonadPlus and calls const mzero for MonadPlus
15:52:19 <roconnor> and this hack is used to get monadic patter matching to do some interesting things when failing
15:52:21 <c_wraith> It enables cute code.
15:52:24 <hatds> it'd be nicer to remove fail and make any usage of "p <- do something" introduce a MonadZero constraint if p could fail
15:52:40 <c_wraith> But I think the fact that it enables cute code is a good reason to *not* have it.
15:52:40 <ddarius> joseanpg: It's a wiki.  Feel free to edit it.
15:52:41 <roconnor> hatds: ya
15:52:52 <c_wraith> @src catMaybes
15:52:52 <lambdabot> catMaybes ls = [x | Just x <- ls]
15:52:57 <c_wraith> see?  That's cute.
15:53:02 <c_wraith> But that's all.
15:53:28 <c_wraith> It's cute, but very opaque.  It wouldn't be any less efficient to have it not depend on fail.
15:53:36 <roconnor> okay how do I solve this problem
15:53:40 <kmc> let's just get MonadFail
15:54:07 <hatds> we don't need fail, mzero and empty...
15:54:19 <hatds> we hardly even need anything more than empty
15:54:37 <roconnor> when I do foo :: Foo -> m Bar, I call fail in Foo giving a nice error message so that I can tell when I combine a whole buch of partial functions, which one failed.
15:54:47 <roconnor> now I cannot pull this trick anymore.
15:54:52 <roconnor> Should I use throw instead of fail?
15:54:56 <hatds> just do Foo -> Maybe Bar
15:55:19 <roconnor> hatds: ya but now the person combining all the partial functions needs to anotate himself which functions fail.
15:55:27 <hatds> roconnor: callers can say "maybe (fail "") return" if they are in a monad that makes sense for that call site
15:55:53 <roconnor> hatds: ya but taht fail string gets duplicated to everyone who cares to do this
15:56:00 <roconnor> that doesn't seem very modular
15:56:16 <hatds> roconnor: then they can say "maybe empty pure" ;)
15:56:35 <roconnor> but then they get no information about what failed
15:57:05 <roconnor> eventually this message may want to get into a log somewhere
15:57:45 <hatds> roconnor: then use a richer datatype than Maybe
15:57:52 <roconnor> like (Either String)
15:58:05 <roconnor> maybe I should use throw everywhere
15:58:36 <roconnor> and those who want Maybe can do (either fail return) to make into a Maybe or a List
15:58:38 <hatds> there's no reason imho not to use Maybe (or a custom datatype) as the core function, all have the throwing variants built ontop :)
15:58:48 <roconnor> hatds: yes there is!
15:59:05 <joseanpg> Cale: It's a pattern matching stack whose entries are essentially case  expressions waiting for their scrutinee to be evaluated enough  that they can match a constructor
15:59:16 <roconnor> hatds: cause everyone who calls the function returning Maybe has to annotate the call with a string to hold the error description.
15:59:20 <joseanpg> that is weak head normal form, isn't it?
15:59:35 <hatds> roconnor: that's why you provide the throw variant in your module
15:59:35 <roconnor> hatds: I don't know, maybe this is a good thing.
15:59:43 <roconnor> hatds: wait, write two functions?
16:00:16 <Cale> joseanpg: yes
16:00:17 <hatds> roconnor: don't copy and paste.. one wraps the other
16:00:23 <roconnor> right
16:00:29 <roconnor> but two of every partial function?
16:01:32 <hatds> it's up to you to decide how "convenient" you want your exported functions to be. Only one of those functions is actually hard to write though
16:01:48 <joseanpg> Cale: "With things like (+) it's a little hard to see that way,  but you can think of (+) for Integer as pattern matching  both its arguments "
16:02:09 <kmc> with inductive naturals it's quite easy to see it that way
16:02:10 <joseanpg> (+) is a built-in, whnf too, no?
16:02:19 <roconnor> hatds: perhaps the caller of the partial function is in a better position to give an error message
16:02:20 <joseanpg> (+) is a built-in, also whnf , no?
16:02:23 <kmc> joseanpg, (+) is a type-class method
16:02:31 <kmc> it's implemented differently for each type
16:02:34 <joseanpg> ummm
16:02:36 <roconnor> hatds: this (Error String) monad is from the mtl?
16:02:44 <kmc> the implementations for standard Prelude numeric types are not specified by the Report
16:02:49 <kmc> in GHC they all do algebraic pattern-matching
16:02:59 <joseanpg> ok
16:03:06 <kmc> to whnf yes
16:03:10 <joseanpg> thanls kmc
16:03:19 <c_wraith> @src Int
16:03:19 <lambdabot> data Int = I# Int#
16:03:20 <hatds> roconnor: if your function is partial for only one reason (like lookup) then use a Maybe.  If not, then you can write a richer datatype to describe why the result didn't contain a value.
16:03:41 <kmc> you can make a type where (+) is not even whnf-strict
16:03:44 <hatds> roconnor: if that richer datatype is just Either String then do that
16:04:01 <roconnor> hatds: I'm not going to write a million data types for these error cases without polymorphic variants.
16:04:02 <joseanpg> @src Num (+)
16:04:02 <lambdabot> Source not found. Take a stress pill and think things over.
16:04:10 * kmc imagines something complicated with 'lub' such that ⊥ * 0 = 0 * ⊥ = 0
16:04:11 <joseanpg> @src Int  (+)
16:04:11 <lambdabot> Source not found. Sorry about this, I know it's a bit silly.
16:04:58 <roconnor> hatds: thanks for the discussion
16:05:12 <hatds> roconnor: You have a million distinct error strings?  :)
16:05:13 <roconnor> hatds: I'm coming around to your point of view
16:05:22 <joseanpg> kmc, very interesting
16:05:26 <roconnor> hatds: yep.
16:05:39 * roconnor lost count after two
16:06:15 <hatds> roconnor: if the strings are already written then use Either String a or domain specific variant that is equivalent
16:07:51 <hpaste> tech2 pasted “collatz conjecture” at http://hpaste.org/49754
16:08:37 <tech2> Hi all, just trying to get my head around syntax mostly so was wondering how I'd get rid of the repeated fromIntegral (length y) in my paste?
16:08:54 <c_wraith> tech2: in that case, I'd use a where clause
16:09:16 <tech2> as would I, if it weren't in the list comp, how would I do so for that?
16:09:17 <c_wraith> oh, nevermind, y is defined inside the comprehension
16:09:26 <c_wraith> list comprehensions are just do blocks
16:09:27 <hatds> :t genericLength
16:09:28 <lambdabot> forall b i. (Num i) => [b] -> i
16:09:28 <c_wraith> use a lit
16:09:31 <c_wraith> err, let
16:09:40 <tech2> I tried using let but the errors I was getting was a bit hard to comprehend
16:09:44 <joseanpg> Cale, ddarius : http://www.haskell.org/haskellwiki/Stack_overflow
16:10:30 <hpaste> c_wraith annotated “collatz conjecture” with “collatz conjecture (annotation)” at http://hpaste.org/49754#a49755
16:10:48 <joseanpg> now I must print that page again ;)
16:11:53 <roconnor> instance (Error e) => Monad (Either e) where is part of the mtl.  So why is it that upgrading to GHC 7 changes this?
16:12:01 <tech2> c_wraith, does that work for you? I'm sure I tried something very much like it and got errors like: starter.hs:52:112: parse error on input `)'
16:13:11 <tech2> c_wraith, hrmm, okay, now I have to work out how I was breaking it before :) thanks.
16:13:18 <c_wraith> tech2: it compiles.  seems to go into an infinite loop
16:13:23 <c_wraith> tech2: but it compiles :)
16:13:50 <tech2> c_wraith, the loops intentional, it's just to find longer and longer values for the collatz conjecture, just a toy really but a way of me learning
16:14:38 <tech2> c_wraith, if you were to rewrite it, have I done anything wrong, or overtly inefficiently?
16:14:54 <ddarius> :t fix ($) -- Haskell's escape hatch
16:14:55 <lambdabot> forall a b. a -> b
16:15:18 <c_wraith> I'd try to figure out how to break bigger into multiple expressions.  It's really opaque at the moment.
16:15:37 <tech2> c_wraith, yeah, I was mostly just trying to get it working :|
16:16:15 <monochrom> @type fix id
16:16:16 <lambdabot> forall a. a
16:17:13 <tech2> c_wraith, thanks for your time.
16:17:21 <c_wraith> you're welcome
16:18:22 <benmachine> roconnor: because ghc 7 base provides an instance that would overlap if mtl didn't do what it was told
16:27:00 <stobix> Is there any way of folding over a very larg list without it taking up huge amounts of memory? It makes sense in my world for 'foldr max 0 biggestListEver' to "throw away" each element it has used after using it. Can I tell haskell to do this somehow?
16:27:53 <Jafet> :t foldl'
16:27:53 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
16:27:56 <Jafet> :t maximum
16:27:57 <lambdabot> forall a. (Ord a) => [a] -> a
16:28:58 <stobix> hm?
16:29:03 <stobix> :t foldl
16:29:04 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
16:29:09 <stobix> :t max
16:29:10 <lambdabot> forall a. (Ord a) => a -> a -> a
16:29:17 <Jafet> foldr does throw away the elements. It just also builds up a large thunk of max (max (max ...))
16:30:04 <roconnor> foldl is almost never used.  It is only useful for defining reverse.
16:30:13 <stobix> oh. and foldl doesn't in this case?
16:30:27 <roconnor> foldl also builds up a big thunk
16:30:31 <roconnor> but foldl' doesn't
16:30:38 <roconnor> (in this case)
16:30:55 <roconnor> @src maximum
16:30:55 <lambdabot> maximum [] = undefined
16:30:55 <lambdabot> maximum xs = foldl1 max xs
16:31:03 <roconnor> hmm
16:31:25 <Axman6> @src foldl
16:31:25 <lambdabot> foldl f z []     = z
16:31:25 <lambdabot> foldl f z (x:xs) = foldl f (f z x) xs
16:31:26 <joseanpg> Cale: Peyton Jones call it "the spine stack"
16:31:26 <Axman6> @src foldl'
16:31:27 <lambdabot> foldl' f a []     = a
16:31:27 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
16:31:38 <hatds> yep, I remember the frustration for having to write my own module for maximum, sum, etc.
16:31:47 <joseanpg> page 202
16:31:59 <hatds> maximum', maximumBy', minimum', minimumBy' etc. :)
16:34:14 <Jafet> > maximum [1..1000000]
16:34:15 <lambdabot>   *Exception: stack overflow
16:34:46 <Jafet> > let max' !a = max a in foldr1 max' [1..1000000]
16:34:47 <lambdabot>   *Exception: stack overflow
16:34:59 <Jafet> > let max' !a = max a in foldl1 max' [1..1000000]
16:35:00 <lambdabot>   *Exception: stack overflow
16:35:52 <Cale> what is max'?
16:36:03 <Cale> er, oh, tss
16:36:07 <stobix> :)
16:36:15 <Cale> max is already strict
16:36:24 <Cale> > foldl1' max [1..1000000]
16:36:25 <lambdabot>   1000000
16:36:50 <stobix> @src foldl1'
16:36:50 <lambdabot> Source not found. My mind is going. I can feel it.
16:36:54 <c_wraith> foldr is very bad with strict functions.  just like foldl is very bad with non-strictness
16:37:02 <Axman6> > foldl1' max [1..10000000] :: Int
16:37:03 <lambdabot>   10000000
16:37:07 <Axman6> > foldl1' max [1..100000000] :: Int
16:37:10 <lambdabot>   100000000
16:37:34 <jnhnum1> @src foldl1'
16:37:35 <lambdabot> Source not found. I am sorry.
16:37:38 <ddarius> roconnor: There's nothing wrong with defining reverse with foldl'.
16:37:55 <stobix> @src foldl1
16:37:56 <lambdabot> foldl1 f (x:xs) = foldl f x xs
16:37:56 <lambdabot> foldl1 _ []     = undefined
16:38:05 <stobix> oh
16:39:38 <stobix> hm
16:39:46 <stobix> > length [1..100000000]
16:39:49 <lambdabot>   100000000
16:40:05 <stobix> (that's something, at least...)
16:41:03 <Cale> In an ideal world, these problems would be auto-solved by strictness analysis, and if you turn on optimisations, actually a lot of them are.
16:42:50 <ddarius> Cale: The problem with that logic is many times the extra strictness you add is changing semantics (in a way you do not care about.)  The compiler doesn't have that freedom.
16:42:58 <joseanpg> Is CAF a fundamental concept?
16:43:08 <Cale> ddarius: yes
16:43:18 <Cale> joseanpg: kinda?
16:43:18 <kmc> joseanpg, not that fundamental
16:43:32 <kmc> the definition of a CAF exists outside particular implementations
16:43:44 <kmc> but it's not so relevant unless you're looking at implementation details
16:43:44 <Cale> It's not something you should normally have to know about, but CAFs are lumped together by the default profiling options.
16:43:49 <hatds> thinking about space usage in Haskell is the equivalent to thinking about the program counter in C
16:44:03 <zmv> (\be.eb)(\fx.f(f x))(\fx.f(f x)) is eventually reduced to (\fx.f(f x)), right?
16:44:18 <hatds> well, both space and spine-stack I guess
16:44:20 <joseanpg> I don't understand it very well
16:44:43 <kmc> joseanpg, it's a thunk defined at the top level of a file
16:44:58 <kmc> or nearly so
16:45:49 <joseanpg> This is the source of my problems: http://neilmitchell.blogspot.com/2009/02/monomorphism-and-defaulting.html
16:45:49 <Cale> zmv: I hope not...
16:46:19 <joseanpg> zmv: not
16:46:43 <Cale> zmv: I'm fairly sure it should reduce to a function equivalent to (\f x -> f (f (f (f x))))
16:46:54 <zmv> oh
16:46:56 <Axman6> zmv: i think that becomes (\fx.f (f (f (f x))))) no?
16:47:01 <Axman6> too late
16:47:07 <Axman6> Caaaallllleeeee!
16:47:10 <zmv> I thought I had typed (\fx.fx) as the last term
16:47:15 <zmv> >_<
16:47:18 <Cale> It's  (\b e -> e b) twice twice
16:47:23 <Cale> -> twice twice
16:47:26 <zmv> yeah
16:47:52 <Axman6> what comes after thrice?
16:47:52 <zmv> I thought I had typed (\be.eb)(\fx.f(fx))(\fx.fx)
16:48:13 <zmv> frice?
16:48:30 <Cale> nothing, apparently
16:49:16 <Axman6> "Nothing! These three are the only words of their type, and no further terms in the series have ever existed." according to the Oxford dictionaries website :(
16:49:43 <Axman6> sounds liek a conspiracy to me
16:50:34 <kmc> a bold claim
16:50:52 <zmv> maybe zerice?
16:52:05 <Cale> once, twice, thrice, quarce, quince?
16:53:27 <Axman6> the 50th thing is surerly quince jam
16:53:39 <Axman6> surely*
16:53:45 <ddarius> Quinces are weird.
16:53:47 <Cale> even surerly
16:53:59 <Cale> surestly
16:54:00 <Axman6> surerestly
16:54:22 <Axman6> most sureish
16:54:38 <joseanpg> I dont understan this: " if the constant has class constraints on it (i.e. is Num a => a, instead of a) then it isn't a CAF because the class constraints act like implicit arguments"
16:54:49 <Cale> joseanpg: yes
16:55:06 <Cale> joseanpg: That is, it's not really a constant, but secretly a function of the typeclass dictionary
16:55:06 <joseanpg> Cale, could yo explain it?
16:55:22 <hatds> think of (Num a) => a   as (a -> a -> a) -> a, where the first argument is "+"
16:55:26 <Cale> It's natural to think of this in terms of the implementation
16:55:51 <Cale> When you have a typeclass, the class itself is compiled into a record datatype for holding the implementations of the typeclass methods
16:56:06 <Cale> and the instances are compiled into functions on and values of those record datatypes
16:56:24 <Cale> and anything with a typeclass constraint is compiled into a function of those additional parameters
16:56:33 <Cale> so  sort :: (Ord a) => [a] -> [a]
16:56:43 <Cale> gets compiled into   sort :: Ord a -> [a] -> [a]
16:57:25 <Cale> and, say,  maxBound :: (Bounded a) => a
16:57:34 <Cale> gets compiled to   maxBound :: Bounded a -> a
16:57:46 <NihilistDandy> So is it more correct then to define constants (if they're really meant as constants) without the constraint?
16:58:01 <Cale> So because these things are implemented as functions, they don't behave like constants with regard to memoisation.
16:58:15 <Axman6> where Bounded a has all the implementations of the class Bounded for each type that implements it?
16:58:24 <Cale> NihilistDandy: well... it depends if you care more about the polymorphism or the performance.
16:58:25 <joseanpg> now I see
16:58:42 <Cale> Axman6: yes
16:58:49 <NihilistDandy> Cale: Polymorphism -> Use the constraint, Performance -> Don't?
16:58:53 <Cale> for the type a
16:58:58 <Cale> NihilistDandy: yeah
16:58:58 <Axman6> NihilistDandy: if you know what type they should be, then you shoudl mark it as that type
16:59:13 <NihilistDandy> Ah, good
16:59:14 <joseanpg> could you give an example of a false CAF?
16:59:23 <NihilistDandy> That's a good distinction to keep in mind
16:59:38 <Cale> Well, supposing that the monomorphism restriction is turned off, something like
16:59:44 <Cale> n = product [1..1000]
16:59:53 <Cale> will get an inferred type of
16:59:58 <Cale> n :: (Num a) => a
17:00:04 <Cale> and thus not be memoised
17:00:24 <Cale> With the MR turned on, it's forced to be monomorphic and will be defaulted to Integer
17:00:31 <joseanpg> aaaaaaaaaaaa
17:00:34 <joseanpg> now
17:01:03 <Axman6> and will sit around as an expession something like n = \type -> product [fromInteger 1 :: type .. fromInteger 10000 :: type]
17:01:15 <Axman6> sort of
17:01:25 <Cale> (defaulting is a hack, which only applies to numerical things whose class context only involves prelude classes)
17:01:43 <Cale> Or:
17:02:05 <NihilistDandy> I really should get better at reading Core
17:02:11 <Cale> n = \numOps -> product numOps [fromInteger 1 numOps .. fromInteger 10000 numOps]
17:02:14 <Cale> er
17:02:18 <Cale> yes
17:03:05 <Cale> and then whenever you use n at some monomorphic type, the dictionary of Num operations for that type will be passed in
17:03:06 <joseanpg> what happens with that 'n'?
17:03:13 <Cale> So if you have...
17:03:19 <Cale> main = print (n :: Integer)
17:03:24 <Cale> It becomes
17:03:36 <Cale> main = print (n numOps_Integer)
17:03:47 <joseanpg> ok
17:03:54 <Cale> where numOps_Integer is the implementation of (+), (*), fromInteger, etc. for the Integer type
17:04:33 <Cale> This doesn't rely on having the explicit type signature, it happens after typechecking, where you know all the types of the expressions.
17:04:58 <Cale> (so applying a function Integer -> Integer to n would also be enough to force the dictionary to be passed in)
17:05:20 <Cale> But if you apply something polymorphic, like a function (Num a) => a -> a
17:05:30 <Cale> then the dictionary will be passed along
17:05:37 <Cale> (to both)
17:05:53 <NihilistDandy> Aha
17:07:06 <joseanpg> Very very thanks to all
17:07:24 <joseanpg> Now is time for sleep
17:07:56 <joseanpg> See you tomorrow
17:09:14 <hatds> Is this right?  data "Foo a = Foo Bool a"  won't have the same memory footprint as "data Bar a = BarTrue a | BarFalse a" even if I tell GHC to unpack the Bool and even though GHC will share all True's and False's in my program.
17:09:45 <Jafet> > let snail n = r n <$> [1..n] where r k 1 = [1..k]; r k i | i==k = [3*k-2, 3*k-3 .. 2*k-1] | True = [4*k-2-i] ++ map ((4*k-4) +) (r (k-2) (i-1)) ++ [k+i-1] in snail 6
17:09:47 <lambdabot>   [[1,2,3,4,5,6],[20,21,22,23,24,7],[19,32,33,34,25,8],[18,31,36,35,26,9],[17...
17:09:53 <hatds> or are they essentially the same modulo the memory footprint for one global True and False?
17:10:43 <Jafet> hatds: I believe UNPACK just makes the Bool occupy one word instead of two
17:11:54 <hatds> I feel like ghc could be doing better, no?
17:12:08 <Jafet> Of course, that's made up by a bit more code whenever you deconstruct Bar
17:12:13 <Jafet> Or construct it, for that matter
17:12:47 <Jafet> Strictly speaking, ghc should be using one bit for !Bool. But that's not gonna happen.
17:12:58 <hatds> in my situation I need to pattern match on the Bool everytime I match on the Foo
17:13:22 <ddarius> hatds: So wouldn't Bar be more natural anyway?
17:13:43 <Jafet> If you're worried about space usage, consider packing it yourself
17:13:45 <hatds> ddarius: yes, but now say the situation is with 2 or 3 Bools
17:14:44 <ddarius> I would say that if you are encoding stuff into a bunch of Bools you are probably doing something wrong.
17:14:50 <hatds> my example is probably unclear... I suppose I don't always pattern match on the Bools
17:23:05 <shapr> yay! working code!
17:23:10 <shapr> and unexpected Swedish people!
17:23:19 <c_wraith> what about socks?
17:23:35 <ddarius> Swedish people can be difficult to spot sometimes.
17:23:58 <shapr> ddarius: these Swedes had a six-foot tall double-bass, and they were speaking loud Swedish.
17:24:17 <shapr> c_wraith: SockSummit is over, but my girlfriend is sitting here knitting on a sweater now.
17:24:41 <shapr> I talked to a knitting chart software seller, they gave me the business card of the author.
17:24:55 <shapr> Man, I haven't written Haskell code in loooong :-(
17:25:02 <shapr> but this very simple Haskell code works, yay!
17:25:26 <hpc> shapr: it's like riding a bicycle
17:25:37 <shapr> hpc: wear safety equipment?
17:25:40 <hpc> (everyone says you can't forget, but then you do and break a femur)
17:25:50 * ddarius suspects shapr hasn't ridden a bicycle in a loooong time as well.
17:26:15 <shapr> ddarius: haha, true that!
17:26:16 <ddarius> hpc: I think if you managed to forget how to ride a bicycle, you wouldn't be able to get to femur-breaking speed.
17:26:30 <hpc> ddarius: you underestimate the steepness of my driveway
17:26:41 <hpc> fortunately, the story underestimates the durability of femurs :D
17:27:00 <Jafet> unsafeBreakFemur
17:27:01 <ddarius> Getting on the bike and going is usually the hard part.
17:27:17 <shapr> so, I have first order working...
17:30:20 * ddarius contemplates where to get a fruit smoothie at 9 at night in the greater Boston area.
17:30:32 <hpc> @unmtl StateT a (StateT b (ErrotT c IO)) a
17:30:33 <lambdabot> a -> b -> ErrotT c IO (a, a, b)
17:30:36 <hpc> delightful!
17:30:50 <kmc> ErgotT?
17:31:04 <hpc> @unmtl StateT a (StateT b (ErrorT c IO)) a
17:31:04 <lambdabot> a -> b -> IO (Either c (a, a, b))
17:31:07 <jedai> @type forever
17:31:08 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b
17:31:11 <hpc> even more delightful
17:31:54 * kmc has put together what he thinks is a pretty good presentation about why Haskell is worth learning, without once mentioning monads or type classes
17:32:20 <MarconM> good night
17:32:26 <ddarius> Now throw it away, because, why do we need to convince people to learn Haskell?
17:32:42 <MarconM> i want to learn haskell
17:32:43 <Entroacceptor> rather fix the issues with it
17:32:45 <NihilistDandy> kmc: I'm very excited
17:32:47 <MarconM> how i start \o
17:33:04 <kmc> ddarius, I wouldn't have evaluated the presentation if it had not been demanded
17:33:10 <kmc> MarconM, tryhaskell.org
17:33:12 <NihilistDandy> MarconM: Well, first you need to think about type classes and monads...
17:33:12 <kmc> and then LYAH and RWH
17:33:14 <NihilistDandy> :D
17:33:14 <kmc> @where LYAH
17:33:14 <lambdabot> http://www.learnyouahaskell.com/
17:33:15 <kmc> @where RWH
17:33:16 <lambdabot> http://www.realworldhaskell.org/blog/ http://book.realworldhaskell.org/read/
17:33:24 <kmc> don't think about type classes and monads ;P
17:33:26 <geheimdienst> kmc: i disagree with ddarius, i think your presentation is cool and useful
17:33:35 <kmc> thanks geheimdienst
17:33:37 <MarconM> ok
17:33:39 <kmc> maybe you should wait until you see it
17:33:49 <ddarius> kmc: That doesn't answer my question.
17:33:55 <kmc> all i promise is that the slides will be less ugly than SPJ's slides on the same topic
17:33:59 <kmc> not that the content will be better :)
17:33:59 <MarconM> how use xmonad here ?
17:34:05 <MarconM> #who
17:34:07 <xispirito> lol
17:34:11 <MarconM> who use xmonad here ?
17:34:11 * kmc does
17:34:15 <MarconM> lol
17:34:29 * NihilistDandy used to
17:34:32 <MarconM> xispirito: get out .... u use windows
17:34:38 <MarconM> lol
17:34:41 <xispirito> liar
17:34:45 <MarconM> auehauehuaheaueh
17:35:01 * ddarius first (and only) used ion on Windows.
17:35:12 <shachaf> ddarius: Inside an X server window?
17:35:16 <ddarius> shachaf: Yes.
17:35:19 <MarconM> 0.0
17:35:22 <xispirito> 0.0
17:35:37 <shachaf> > 0.3 - (0.2 + 0.1)
17:35:37 <lambdabot>   -5.551115123125783e-17
17:35:41 <kmc> Ø.Ø
17:36:26 <hpc> > Ø . Ø
17:36:27 <lambdabot>   Not in scope: data constructor `
17:36:48 <kmc> > let ø = succ in ø (ø 3)
17:36:48 <lambdabot>   5
17:37:20 * MarconM confuse
17:37:30 * ddarius doesn't think that  was APL for succ, but it's been a while since he last looked at a list of APL operators.
17:39:12 <hpc> im mostly just thinking of being able to use Ø as a constructor for set types
17:39:34 <kmc> ;P
17:42:39 <MarconM> where i get tuto for class
17:43:05 <kniu> what
17:43:12 <MarconM> nothing
17:43:34 <MarconM> kniu: i wanna learn haskell ... how i start
17:43:42 <MarconM> wht i have to learn first
17:43:52 <parcs> english
17:43:56 <MarconM> lol
17:44:00 <MarconM> i know
17:44:03 <MarconM> \o
17:44:13 <geheimdienst> @where lyah
17:44:13 <lambdabot> http://www.learnyouahaskell.com/
17:44:22 <MarconM> lambdabot: thanks
17:44:24 <geheimdienst> MarconM: start with this
17:44:27 <MarconM> ok
17:45:44 <kmc> MarconM, before that, http://tryhaskell.org/
17:45:58 <ddarius> Where I get diacetylated (5α,6α)-7,8-didehydro-4,5-epoxy-17-methylmorphinan-3,6-diol
17:46:02 <MarconM> kmc: i am there .... but what i do
17:46:09 <c_wraith> ddarius: http://pipeline.corante.com/archives/things_i_wont_work_with/
17:46:46 <ddarius> c_wraith: I hope that Derek won't work with this, but not due to it's explosive capacity.
17:47:20 <c_wraith> ddarius: some things he refuses to work with because they stink instead!
17:47:55 <ddarius> c_wraith: There was no thio in there.  No sulfur.
17:48:39 <ivanm> preflex: seen byorgey
17:48:40 <preflex>  byorgey was last seen on #haskell 3 hours, 9 minutes and 3 seconds ago, saying: More generally ((->) e) is a monad for any type e
17:49:01 <ddarius> More generally ((,) e) is a comonad for any type e.
17:53:18 <ivanm> ddarius: strangely enough, that isn't the information I was hoping to find out... ;)
17:55:40 <johannes_> hello
17:56:10 <kmc> hi johannes_
17:56:38 <kmc> "exactly as generally, ((,) e) is a comonad for any type e."
17:57:30 <ddarius> ivanm: Of course not because it's obvious since ((->) e) -| ((,) e) and so the monad structure of ((->) e) gets transported across the adjunction to a comonad structure on ((,) e) (and vice versa.)
17:57:50 <johannes_> hmm.. i don't know if this is the place to ask.. i have some questions about lambda calculus.. .. not haskell specifically but..
17:58:02 * ivanm wonders if ddarius has been taking lessons from edwardk...
17:58:10 * kmc left his adjunction transporter in his other time machine
17:58:27 <kmc> johannes_, it's a fine place to ask, in my opinion
17:58:34 <ddarius> ivanm: In this particular area, it's more the other way around.
17:58:44 <ivanm> heh, fair enough
17:58:49 <ivanm> so it's _your_ fault! :p
17:59:27 <ddarius> Yes, this probably all started when Ed was wondering what Kan extensions would look like in Haskell.
17:59:39 <johannes_> ok.. first question.. in this book i'm reading . a lot of times i see expressions like \xy.x
17:59:51 <ddarius> I mean, if we ignore all that recursion scheme stuff before-ish then.
18:00:06 <johannes_> instead of \x.\y.x that is
18:00:24 <kmc> johannes_, yeah, that's a common shorthand
18:00:33 <johannes_> ah. ok so it is correct
18:00:49 <Jafet> > (\x y -> x) 1
18:00:50 <johannes_> it is just shorthand for \x.\y
18:00:50 <lambdabot>   Overlapping instances for GHC.Show.Show (t -> t1)
18:00:50 <lambdabot>    arising from a use of ...
18:00:59 <Jafet> > (\x y -> x) 1 error
18:01:00 <lambdabot>   1
18:01:05 <kmc> unless they define it elsewhere, i would assume «λxy. x» means «λx. λy. x»
18:01:11 <Jafet> > (\x -> \y -> x) 1 error
18:01:12 <lambdabot>   1
18:01:24 <kmc> > error `seq` ()
18:01:25 <lambdabot>   ()
18:01:50 <johannes_> ok.. the other thing i am thinking here is
18:02:06 <johannes_> expressions like \x.\y.xy
18:02:16 <johannes_> xy should always be read as application
18:02:19 <kmc> yeah
18:02:21 <johannes_> x applied to y
18:02:27 <johannes_> x as algorithm and y input
18:02:29 <kmc> function x applied to argument y
18:02:30 <johannes_> right?
18:02:30 <kmc> yes
18:02:34 <johannes_> and never x * y
18:02:38 <kmc> right
18:02:42 <kmc> unless they define it otherwise
18:02:50 <kmc> :t \x -> \y -> x y
18:02:51 <lambdabot> forall t t1. (t -> t1) -> t -> t1
18:02:51 <augur> copumpkin!
18:02:59 <johannes_> so . technically is stuff like \x.\y.x + y correct
18:03:05 <johannes_> \x.\y.(x+y)
18:03:16 <kmc> johannes_, sometimes
18:03:25 <kmc> for syntactic consistency you might prefer to say \x. \y. (+ x y)
18:03:37 <johannes_> ok.. but then it is confusing
18:03:42 <kmc> not really
18:03:43 <johannes_> since xy could be read x * y
18:03:44 <augur> johannes_: are we talking pure lambda calculus?
18:03:54 <kmc> johannes_, but one wouldn't read xy as x * y in a lambda calculus
18:03:55 <johannes_> yes... this is not haskell now
18:04:03 <augur> then no.
18:04:08 <johannes_> ok,, yes i understand that
18:04:13 <zmv> also
18:04:13 <johannes_> but then how come x + y is allowed
18:04:15 <augur> i mean. they're valid lambda terms
18:04:19 <zmv> \xy.(+ x y)
18:04:28 <augur> but they dont do anything.
18:04:32 <zmv> yes
18:04:49 <kmc> johannes_, \x. \y. (+ x y) is fine by me; it has a free variable +
18:04:57 <augur> indeed
18:04:59 <kmc> if you allow your variable names to include symbols
18:05:05 <kmc> then it's consistent with everything else
18:05:14 <kmc> «\x. \y. (x + y)» is a little weird
18:05:16 <johannes_> ok.. so the plus is a combinator term or?
18:05:22 <kmc> but is how many practical languages like Haskell work
18:05:23 <augur> no
18:05:25 <augur> its just a symbol
18:05:29 <augur> like x and y are symbols
18:05:36 <kmc> johannes_, well, for example, you could define addition on church numerals
18:05:40 <zmv> you can "+" as \mnfx.mf(nfx)
18:05:42 <zmv> yes
18:05:42 <kmc> you could call it "add" or you could call it "+"
18:05:47 <kmc> it doesn't really matter
18:05:57 <kmc> since this is math and not programming, syntactic questions don't have perfectly sharp answers
18:06:04 <kmc> it's just whatever you can write and still be understood
18:06:09 <augur> infix is not valid, however
18:06:11 <augur> in the pure lc
18:06:28 <kmc> e ::= x | λx. e | (e e)
18:07:11 <johannes_> ok.. thanks a lot anyway.. i appreciate the help
18:10:20 <parcs> i'm getting a 'file too short' error when linking a lib in ghci yet linking that same lib through ghc works fine
18:10:37 <parcs> is anyone familiar with this pecularity
18:10:50 <parcs> peculiarity*
18:11:52 <parcs> "Loading package ncurses-0.2 ... can't load .so/.DLL for: panel (/usr/lib/libpanel.so: file too short)"
18:12:54 <kmc> buh
18:12:55 <parcs> pecularity sounds better when you say it out loud
18:12:55 <kmc> what OS?
18:12:59 <parcs> linux
18:13:18 <hexie> hello
18:13:25 <kmc> you ran the ghc-produecd binary?
18:13:26 <kmc> hi hexie
18:13:27 <geheimdienst> have you tried running ghc with moar verbose to determine if it uses ncurses in exactly that version and accesses exactly that file?
18:13:37 <geheimdienst> parcs: ^^
18:13:42 <parcs> kmc: yes it ran fine
18:13:48 <kmc> ghci includes its own dynamic linker
18:14:04 <hexie> already i see talent O.o
18:14:05 <kmc> so it's not totally surprising to have linker bugs in ghci that don't show up in compiled code
18:14:49 <kmc> parcs, did you ask #ghc and/or look for an open bug?
18:14:54 <kmc> which GHC version?
18:14:58 <parcs> 7.0.3
18:15:00 <kmc> did you try older / newer?
18:15:19 <parcs> no
18:15:52 <parcs> actually the ghc-produced binary links /usr/lib/libpanelw.so
18:16:00 <parcs> not libpanel.so
18:16:07 <geheimdienst> i guess that's a first clue
18:17:46 <hexie> is it hard to understand binary?
18:18:13 <kmc> hexie, nope
18:18:18 <kmc> parcs, wide-character version, maybe?
18:18:19 <parcs> hexie: it's relatively simple
18:18:23 <parcs> kmc: yeah
18:19:19 <hexie> so, where do i start learning about how to read it?
18:21:10 <kmc> http://en.wikipedia.org/wiki/Binary_numeral_system
18:21:25 <parcs> and libHSncurses-0.2-ghc7.0.3.so links to libncursesw.so.5
18:22:06 <parcs> so the 'problem' is that ghci attempts to link the normal ncurses libs instead of the wide-character ones
18:22:19 <epdtry> parcs: is libpanel.so maybe a linker script and not an actual binary?
18:23:01 <parcs> epdtry: it is! its contents: INPUT(-lpanelw)
18:23:47 <parcs> maybe ghci doesn't know what to do with linker scripts?
18:23:56 * ddarius still thinks a Swedish libpanelw.so would solve the problem.
18:24:01 <epdtry> parcs: seems like it
18:24:04 <ddarius> It doesn't.
18:26:11 <mustelo> I'm writing a simple assembler that's using parsec for parsing and I can't quite figure out the right balance of how much to encode in the type system vs just plain strings. for example, is it best to have a data type which has a constructor for each opcode, or just to look those up based on strings?
18:28:54 <hexie> i think i would rather pick up on coding *_* I need somewhere very simple to start.
18:29:13 <kmc> hexie, what brings you to the #haskell channel?
18:29:27 <hexie> just looking...
18:29:34 <kmc> googled "programming chat"? :)
18:29:45 <hexie> nah, just chat
18:29:56 <hexie> XD
18:30:00 <kmc> Haskell is generally regarded as one of the more difficult programming languages, but also very rewarding
18:30:10 <kmc> to some degree the difficulty is that it's unlike other languages
18:30:20 <kmc> so you are actually in a better position if you're starting fresh
18:30:41 <hexie> i like better positions
18:31:36 <hexie> so, it's like learning a ne language enteirly?
18:31:37 <NihilistDandy> Haskell's not hard. Pshaw. :D
18:31:54 <hexie> darn no spell check
18:32:43 <ddarius> mustelo: You can have your cake and eat it too.
18:32:54 <hexie> so, would anyone like to start me off? i am very interested already.
18:33:04 <mustelo> ddarius, care to elaborate?
18:33:08 <Jafet> Spiel cheque
18:33:10 <kmc> hexie, http://tryhaskell.org/
18:33:17 <ivanm> @where lyah
18:33:17 <lambdabot> http://www.learnyouahaskell.com/
18:33:18 <kmc> hexie, then http://learnyouahaskell.com/chapters
18:33:21 <ivanm> hexie: ^^
18:33:56 <Jafet> Man, ghci on windows still sucks
18:34:21 <hexie> my favorite text editor is notepad :D
18:34:23 <Jafet> I suppose the solution is to put ghc in the VM
18:34:24 <hatds> mustelo: I would wrap the values in constructors.  It might, however, be tricky to decide whether each opcode gets 1 con or if many opcodes get mapped to 1 constructor with some fields..
18:34:32 <ivanm> IIRC, winghci wasn't too bad, when using it on some student's laptops
18:34:42 <Jafet> ivanm: no tab completion!
18:34:48 <Jafet> Well, tab completes history, not names.
18:34:58 <ivanm> Jafet: true; I'm out of the habit though since ghci in emacs doesn't have tab-completion
18:35:00 <Jafet> And C-c interrupting is screwed up.
18:35:12 * ivanm wonders if chrisdone's emacs stuff for haskell has tab-completion...
18:35:19 <hatds> C-c doesn't really work on windows with ghci either
18:35:27 <hexie> i think i need to start tomorrow, i'm really sleep deprived and hungry.
18:35:42 <NihilistDandy> winghci is awful, but the regular one invoked from cmd is all right if you set things up to not be ugly
18:36:14 <ivanm> is the ugliness partially at least from the ugliness of cmd.exe ?
18:36:17 <ddarius> mustelo: You could, if it made sense, use an untyped representation that's flexible and avoids the need for encoding and use a phantom type to provide more detailed types.  But, if you wanted to do that, you'd probably want to do it at a different level.
18:36:23 <NihilistDandy> ivanm: I also miss tab-completion in ghci with emacs. I usually give up and just invoke it in a shell
18:36:35 <alpounet> hexie, well, notepad++ (not notepad) has Haskell syntax highlighting
18:36:38 <mustelo> ddarius, what do you mean "at a different level"?
18:36:41 <ivanm>  NihilistDandy: heh
18:37:21 <hexie> notepad for general purpose, it's great for editing small stuff that would not appear anywhere else
18:37:22 <NihilistDandy> C-c C-l (type first few letters of function) TAB
18:37:23 <NihilistDandy> ARGH
18:37:29 <ddarius> mustelo: Unless you are doing very little manipulation, you probably don't want the opcodes to just be strings.
18:37:59 <ddarius> @karma notepad
18:37:59 <lambdabot> notepad has a karma of 78
18:38:41 <mustelo> ddarius, yeah, probably right, thanks. what would an alternative "untyped" representation look like?
18:38:44 <monochrom> hahaha
18:38:47 <hexie> hope it's worth 90 mb off of my 500 gb hard drive :S
18:38:50 <Jafet> @karma notepad++
18:38:50 <lambdabot> notepad++ has a karma of 0
18:39:49 <hexie> already i know i might enjoy this
18:40:16 <hexie> or me sitting at my computer screen miserbly with pizza hanging out of my moth
18:40:23 <hexie> *mouth
18:40:52 <siracusa> notepad++++
18:41:11 <monochrom> @karma notepad++
18:41:12 <lambdabot> notepad++ has a karma of 1
18:41:16 <monochrom> success!
18:41:25 <monochrom> notepad++++
18:42:02 <hexie> i wish i had a 250MB per second internet speed
18:42:15 <nexx> notepad++++
18:42:43 <NihilistDandy> notepad----
18:43:02 <monochrom> @karma notepad--
18:43:02 <lambdabot> notepad-- has a karma of -1
18:43:29 <NihilistDandy> Poor notepad--
18:43:33 <NihilistDandy> No one loves it
18:43:50 <hexie> i have a karma of OVER 9000 for kiking a kat...
18:43:56 <NihilistDandy> You
18:43:57 <parcs> okay i made ghci load the appropriate library (libpanelw) and not it segfaults :)
18:43:58 <Cale> Plain notepad is among the few editors I would recommend people programming in Haskell stay away from, since it has no feature to automatically turn tabs into spaces.
18:43:59 <NihilistDandy> ... what?
18:44:08 <NihilistDandy> Oh, "kicking"
18:44:16 <hexie> yes
18:44:25 <NihilistDandy> I thought that was some kind of anti-Semitic thing
18:44:30 <NihilistDandy> :D
18:44:42 <hexie> so, what can i make in haskell?
18:44:52 <NihilistDandy> Anything computable
18:45:03 <hexie> nice
18:45:27 <NihilistDandy> What do you want to do?
18:45:58 <hexie> i'll go make a nastier version of the morris worm
18:46:08 <hexie> just kidding of corse...
18:46:11 <NihilistDandy> @faq
18:46:11 <lambdabot> The answer is: Yes! Haskell can do that.
18:46:31 <hexie> i'll go try that
18:46:59 <NihilistDandy> It might be more fun to model Morris dancing
18:47:14 <NihilistDandy> Probably not, but you could write a thesis about it
18:47:28 <parcs> can anyone on a distro other than arch linux try cabal-installing the 'ncurses' package and attempt to link the library through ghci?
18:48:02 <NihilistDandy> Does OS X count?
18:48:20 <parcs> yep
18:48:54 <hexie> i don't like macs
18:49:08 <NihilistDandy> I don't like OS wars that go nowhere
18:49:40 <hexie> that is why we should do research
18:49:57 <hexie> true os war, not flame war
18:50:15 <parcs> hurd wins hands down ;)
18:50:43 <nexx> singularity ftw
18:51:05 <NihilistDandy> minix~
18:51:13 <hexie> lets just make a perfect os
18:51:18 <NihilistDandy> @
18:51:20 <NihilistDandy> It is done
18:51:25 <MarconM> 0.0
18:51:30 <MarconM> perfect OS
18:51:37 <NihilistDandy> That only makes sense if you hang out in #esoteric
18:51:50 <hexie> combine all of them
18:51:57 <Jafet1> I use maxix
18:51:59 <NihilistDandy> hexie: That would make the worst one
18:52:20 <hexie> why?
18:52:41 <ivanm> the insecurity of windows, the perception of linux and the customisability of OSX
18:52:45 <ivanm> ;)
18:53:10 <Jafet1> Then you get the computer system used in Tron
18:53:33 <hexie> ease of windows, security of linux, and style of osx
18:54:42 <nexx> would prefer the security of bsd
18:55:04 <hexie> linux is sufficiient for most purposes
18:55:24 <NihilistDandy> parcs: I guess it can't find my ncurses :(
18:55:56 <parcs> NihilistDandy: what kind of error are you getting?
18:56:12 <NihilistDandy> * Missing C library: ncursesw
18:56:27 <NihilistDandy> So I added extra-lib-dirs and extra-include-dirs
18:56:35 <NihilistDandy> With the appropriate prefixes
18:56:45 <NihilistDandy> And it still wouldn't find them :/
18:57:15 <hexie> i wanted an aleinware with all the extras, but it was OVER 9000!!!
18:57:54 <NihilistDandy> I suppose I'll just have to build one up special from source
18:58:11 <hexie> mabe...
18:58:12 <kmc> hexie, i've heard these jokes OVER 9000 TIMES
18:58:17 <parcs> NihilistDandy: does the mac ship with ncursesw?
18:58:35 <hexie> yup, and iv'e said it OVER 9000 TIMES
18:58:47 <NihilistDandy> It doesn't appear so, now that I've looked through the usual directories
18:59:01 <Jafet> > fix (("OVER ("++) . (++")"))
18:59:02 <lambdabot>   "OVER (OVER (OVER (OVER (OVER (OVER (OVER (OVER (OVER (OVER (OVER (OVER (OV...
18:59:17 <NihilistDandy> ncurses, but no ncursesw
18:59:22 <NihilistDandy> Guess I have some source to grab
19:00:02 <hexie> too much math :O
19:00:17 <Jafet> Leave quickly, before you get infected
19:00:33 <kmc> math?
19:00:39 <kmc> you mean like this
19:00:42 <kmc> > 9000 * 2
19:00:42 <lambdabot>   18000
19:00:46 <hexie> yes
19:00:49 <elliott> What's a good name for (\b m -> b >>= flip when m)? (and the same with when -> unless). I've been using whenM/unlessM, but those are kind of ugly.
19:01:26 <hexie> i need some sort of personall teaching
19:01:33 <kmc> elliott, *shrug* ugly how?
19:01:39 <kmc> uglier than mapM, filterM, zipWithM, etc?
19:01:49 <kmc> i would go with whenM and unlessM for consistency
19:01:56 <kmc> in fact they may already be in some hackage package under those names
19:02:26 <elliott> kmc: Well, my intuition is that whenM implies that the _action_ would be monadic, whereas it's the condition. Of course, the action being monadic is essential to when itself, so this doesn't make any sense, but that's how they "feel" to me.
19:02:53 <kmc> :t filterM
19:02:54 <lambdabot> forall a (m :: * -> *). (Monad m) => (a -> m Bool) -> [a] -> m [a]
19:03:08 <elliott> yeah
19:03:09 <dolio> I think we're dangerously close to having American flag sort.
19:03:12 <elliott> so just like the [a] is non-monadic there
19:03:21 <elliott> I'd expect the Boolean to be non-monadic in whenM
19:03:24 <hexie> too confusing for right now. darn.
19:03:28 <elliott> Bool
19:03:30 <hexie> *me
19:03:37 <geheimdienst> whem!
19:03:38 <kmc> elliott, filterM has (m Bool)
19:04:02 <elliott> kmc: that's true... but say <x> means "function with final return value of x":
19:04:10 <elliott> mapM :: <m b> -> [a] -> m [b]
19:04:18 <elliott> filterM :: <m Bool> -> [a] -> m [a]
19:04:24 <kmc> hexie, were you interested in learning Haskell? were the resources we linked enough for you to get started?
19:04:28 <elliott> zipWithM :: <m c> -> [a] -> [b] -> m [c]
19:04:37 <elliott> the actual values being operated on are always non-monadic
19:04:54 <kmc> but you already know what 'when' is
19:05:00 <elliott> when :: Bool -> <m ()> -> m () ... so it feels like when is /already/ whenM
19:05:05 <kmc> if you know what 'when' is, what else could whenM possibly be?
19:05:08 <elliott> and whenM would be... Bool -> m (m ()) -> m ()?
19:05:09 <hexie> not really, i need something much easeir, to get me in the "zone"
19:05:15 <elliott> kmc: nothing, but it still feels like inconsistent naming
19:05:18 <kmc> hexie, okay, try Python
19:05:18 <elliott> with the other Ms
19:05:46 <hexie> python..ok, i'll start there and come back later to this
19:05:47 <Jafet> wham
19:05:54 <kmc> hexie, just a warning: programming is hard no matter what language you use
19:06:15 <monochrom> vcr programming was hard enough
19:06:17 <kmc> in Python it is easy to write correct or incorrect programs
19:06:28 <kmc> in Haskell it is hard to write correct programs and much harder to write incorrect ones
19:06:36 <hexie> i know, i know. i'm just wanting to know how this stuff works.
19:06:49 <elliott> kmc: I don't find writing correct programs in Haskell to be difficult
19:07:01 <elliott> at least, not the kind of programs you could write in Python ;-)
19:07:30 <geheimdienst> elliot: i find your initial remark interesting, but in the end, i'd still go with whenM. the M variant of a function is for when you need moar monad. "when" takes a Bool, you need moar monad, use whenM. another argument: i find it consistent that zipM, mapM, whenM all take an "m a" as their first argument
19:07:32 <Jafet> You write programs without type checking in Haskell? That sounds difficult!
19:07:52 <elliott> geheimdienst: Yeah, whenM is alright as names go... it still feels a bit wrong to me, but it's at least evocative.
19:08:11 <monochrom> Dynamic-oriented programming: everything is a Dynamic!
19:08:28 <dolio> Is it personable?
19:08:41 <monochrom> yes
19:08:50 <geheimdienst> minefield-oriented programming. things blow up unexpectedly.
19:09:15 <monochrom> conal and his detonative programming :)
19:09:22 <ivanm> does anyone know of a more efficient way of doing combinations of n elements from a list xs (allowing repeats) than the "normal" approach of taking 1..n copies of x and recursing?
19:09:52 <Jafet> Dynamic is a pretty cool guy, eh is flexible and isn't conform to anything
19:10:14 <hexie> i just need something to do once i have learned something
19:10:19 <NihilistDandy> geheimdienst: Vim user, eh?
19:10:20 <kmc> Dynamic is too safe
19:10:25 <kmc> put unsafeCoerce around everything
19:10:28 <Jafet> ivanm: sorry, didn't my code work?
19:10:32 <Jafet> @quote kmc head
19:10:32 <lambdabot> No quotes match. Wrong!  You cheating scum!
19:10:45 <Jafet> Oh, it the other k
19:10:48 <Jafet> @quote ksf head
19:10:48 <lambdabot> No quotes match. Sorry about this, I know it's a bit silly.
19:11:06 <ivanm> Jafet: hmmm?
19:11:09 <geheimdienst> with the minefield joke i was actually thinking of dynamic languages. they only tell you about the type conflicts when it's too late, at runtime
19:11:25 <Jafet> @quote <kmc> head
19:11:25 <lambdabot> <kmc> says: head [] = peek . intPtrToPtr . fromIntegral . unsafePerformIO . randomRIO $ (0, 2^32)
19:11:35 <ivanm> I have a working implementation; it's just that profiling currently reveals it's the 3rd-most expensive/used function
19:11:41 <monochrom> dynamite languages :)
19:11:47 <mauke> needs more unsafePerformIO
19:11:48 <ivanm> so I'm hoping there exists a more efficient version that magically makes it faster :p
19:12:17 <Jafet> ivanm: your algorithm sounds like it's just about asymptotically optimal
19:12:29 <ivanm> yeah, thought so
19:12:43 <Jafet> If you're very clever about sharing, you could save a factor of (length xs), but that's piddly
19:12:44 <ivanm> just about every other algorithm I can find uses swapping array indices
19:13:52 <Jafet> I think the code I showed you previously was clever about sharing, but I don't remember.
19:14:15 <int80_h> where does package.conf live?
19:14:30 <int80_h> this is a ghc file I'm guessing
19:14:36 <int80_h> or rather a cabal file
19:14:43 <ivanm> Jafet: using [n,n-1..1] instead of just [1..n] ?
19:14:45 <Jafet> .ghci?
19:14:52 * ivanm remembers _someone_ showing some code, but not who
19:15:13 <ivanm> int80_h: ~/.ghc/ for local
19:15:16 <Jafet> ivanm: if you wanted the combinations to follow the order in xs, yes
19:15:22 <NihilistDandy> parcs: Problem solved. Got ncursesw built, and the lib
19:15:25 <Jafet> Er yeah, .ghc/
19:15:25 <ivanm> global is in /usr/lib/ghc-$version/ I think
19:15:33 <NihilistDandy> What should I send through ghci to mirror your result?
19:15:33 <Jafet> ghc-pkg list should tell you the paths
19:15:46 <ivanm> Jafet: doesn't really matter tbh
19:16:09 <Jafet> Well, xs has to be sorted anyways
19:16:35 <ivanm> it does? I'm doing it on values that don't have an Ord instance
19:17:06 <Jafet> The ordering doesn't matter, but equivalent elements have to be adjacent
19:17:38 <ivanm> right; my input list doesn't have any duplicates
19:17:58 <ivanm> and I'm actually outputting [(a,Int)] so number of copies in the output is encoded directly
19:18:57 <parcs> NihilistDandy: nice :) try doing `UI.NCurses.runCurses (return ())` within ghci and see if it succeeds
19:19:22 <NihilistDandy> All linking completed
19:19:24 <hpaste> Jafet pasted “perms” at http://hpaste.org/49756
19:19:29 <Jafet> Oh, the code I gave you was for permutations
19:20:01 <parcs> damn, so my system is at fault :\
19:20:08 <parcs> thanks NihilistDandy
19:20:19 <NihilistDandy> No problemo. Sorry for the bad news
19:20:28 <ivanm> Jafet: heh
19:20:36 <NihilistDandy> What versions of ncurses, ghc, and c2hs are you using?
19:20:55 <ivanm> I ended up finding byorgey's multiset-combs package, and its permutation function seems to be quite fast
19:21:42 <parcs> NihilistDandy: ghc 7.0.3, latest c2hs and ncurses 5.9
19:22:10 <parcs> what about you?
19:22:19 <NihilistDandy> Hmm. Well, other than the fact that I'm using ghc 7.0.4 and ncurses 5.7, we're basically in line
19:22:28 <NihilistDandy> I don't know how much changed in those releases
19:22:39 <roconnor> hmm, an (abelian) group of prime order is a (1-d) vector space.
19:22:52 <parcs> hm
19:23:07 <roconnor> oh I guess that an group of prime order is (isomorphic to) Z_p
19:24:28 <NihilistDandy> roconnor: Correctr
19:24:30 <NihilistDandy> *Correct
19:26:00 <roconnor> Heh.  I was looking at this elliptic curve.  It doesn't look a lot like Z_p at first glance.
19:35:55 <NihilistDandy> Group's will do that
19:35:58 <NihilistDandy> *Groups
19:38:30 <NihilistDandy> This is actually pretty good
19:38:30 <NihilistDandy> http://www.reddit.com/r/explainlikeimfive/comments/j4ohk/explain_the_pnp_problem_li5/
19:42:23 <ivanm> is it possible to use ghc-core with a cabal file?
19:42:40 <ivanm> e.g. I'm using cabal to build my project; do I really have to now go and explicitly "build" it to use ghc-core ?
19:42:45 <ivanm> s/e.g./i.e./
19:42:55 <Jafet> NihilistDandy: I approve of telling five-year-olds about LSD
19:43:10 <NihilistDandy> Jafet: HOW ELSE WILL THEY LEARN, MAN?
19:43:37 <Jafet> I bet that's where many children's shows come from, anyway.
19:45:12 <NihilistDandy> I hope so. Everyone should have an experience with it. Just tell them it makes them a better programmer/mathematician/homeopath and it'll go over gangbusters
19:46:28 <kmc> are you talking about LSD or Haskell?
19:47:13 <NihilistDandy> Aren't they isomorphic?
19:47:43 <kmc> a wise man once said that the entire world can be described as convex combinations of drugs, math, and cardboard
19:48:09 <NihilistDandy> @remember kmc wisdom <kmc> a wise man once said that the entire world can be described as convex combinations of drugs, math, and cardboard
19:48:09 <lambdabot> Done.
19:48:30 <NihilistDandy> derp
19:48:54 <NihilistDandy> @remember kmc a wise man once said that the entire world can be described as convex combinations of drugs, math, and cardboard
19:48:54 <lambdabot> It is forever etched in my memory.
19:48:57 <roconnor> what does cabal-dev do for me?
19:49:10 <kmc> @forget kmc wisdom <kmc> a wise man once said that the entire world can be described as convex combinations of drugs, math, and cardboard
19:49:10 <lambdabot> Done.
19:50:33 <kmc> programming languages are mostly made of cardboard with a little math
19:50:47 <kmc> Haskell has more math and drugs and less cardboard
19:50:57 <kmc> C++ is entirely cardboard and drugs (not the good kind)
19:51:51 <NihilistDandy> "Boost", indeed
19:52:24 <kmc> haha
19:52:59 <kmc> that does sound like a street name for hillbilly meth
19:53:19 <NihilistDandy> You say that like there are other kinds of meth~
19:53:41 <kmc> NihilistDandy, you can get prescribed methamphetamine for ADHD in the US
19:53:48 <kmc> it's rarer than Adderall but not unheard of
19:53:54 <ivanm> roconnor: if you don't use a lot of customised versions of libraries or work on different projects with conflicting dependencies (e.g. needing parsec-2 and parsec-3 for different projects), not much IMHO
19:54:09 <NihilistDandy> I'd like to hope that eventually all the Haskell cardboard will be replaced with more drugs and math soon enough :D
19:54:15 <NihilistDandy> kmc: O_O
19:54:28 <kmc> NihilistDandy, as long as it's code running on real machines there will still be lots of cardboard :/
19:54:32 <roconnor> ivanm: if I use projects with conflicting dependencies, how will cabal-dev help me?
19:54:32 <NihilistDandy> I've seen people get regular old amphetamine, but meth... yeesh
19:54:44 <NihilistDandy> kmc: DAMN THE REAL MACHINES
19:55:00 <ivanm> roconnor: since you don't install packages globally but per-project, you don't have to worry about something linking against the wrong version of parsec/mtl/etc.
19:55:03 <NihilistDandy> We just need more lambdas!
19:55:12 <kmc> lambda the ultimate cardboard
19:55:31 <NihilistDandy> *,
19:55:39 <roconnor> ivanm: don't I specific the version of parsec et. al. in my cabal configuration file anyways?
19:55:41 <monochrom> why "cardboard"?
19:55:42 <NihilistDandy> Or perhaps (,)
19:55:49 <kmc> anyway yeah, meth is Schedule II, the top classification (Schedule I) is reserved for the really dangerous drugs like marijuana
19:56:14 <NihilistDandy> kmc: Yeah, I noticed that rather ridiculous incongruence. Even cocaine is Schedule II
19:56:43 <kmc> tl;dr is that drug laws make no sense
19:56:55 <NihilistDandy> BUT IT'S THE DEVIL'S HARVEST, KMC
19:57:02 <NihilistDandy> Also, cf. Portugal
19:57:22 <NihilistDandy> Near-perfect counterpoint to the War on Drugs
19:57:31 <kmc> pot is illegal in the US because it was a way to stick it to the Mexicans back in the 1930's
19:57:43 <kmc> (that's why it's called "marijuana" in the US and "cannabis" everywhere else)
19:57:53 <NihilistDandy> And coke's illegal because of jazz
19:58:08 <monochrom> roconnor, a popular use of cabal-dev is to help test "does my lib work given parsec 2?" "does my lib work given parsec 3?" "in fact, does my lib work given parsec 2.0.x, 2.1.x, 2.2.x, 2.3.x...?"
19:58:09 <NihilistDandy> Well, because of "jazz musicians rapin' all the white wimmenz"
19:58:32 <roconnor> I see
19:59:04 <ivanm> is there a way to get the output from -ddump-simpl to get saved to a file rather than stdout ?
19:59:27 <Ori_B> Hi. Haskell newb here.
19:59:34 <kmc> hi Ori_B
19:59:48 <Ori_B> I was wondering if there was a decent way of generating an infinite list such that
20:00:05 <Ori_B> x !! n = f (x !! n - 1)
20:00:18 <ivanm> > iterate succ 0
20:00:19 <lambdabot>   [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,...
20:00:19 <monochrom> it's "iterate f x0"
20:00:28 <Ori_B> ah, sweet.
20:00:53 <roconnor> @hoogle (a -> a) -> a -> [a]
20:00:53 <lambdabot> Prelude iterate :: (a -> a) -> a -> [a]
20:00:53 <lambdabot> Data.List iterate :: (a -> a) -> a -> [a]
20:00:53 <lambdabot> Data.Generics.Schemes everywhere :: (a -> a) -> a -> a
20:03:54 <Ori_B> and is there a way of checking if an algebraic type (terminology?) is a specific one?
20:04:08 <Ori_B> eg, 'data Foo = Bar | ...'
20:04:20 <Ori_B> takeWhile (== Bar) list
20:04:40 <hatds> if Foo is an instance of Eq then you can say (==Bar)
20:04:52 <Ori_B> ok, that can be done.
20:05:00 <roconnor> if you append "deriving Eq" to then end of your data declairation, then you can use == like that.
20:05:17 <ivanm> pattern matching!
20:05:33 <Ori_B> ivanm: clunky for a takeWhile, but a reasonable alternative :)
20:06:03 <ivanm> Ori_B: it's sometimes preferable to write a helper function that uses pattern matching instead of ==
20:06:05 <hatds> Ori_B: but perhaps you might be thinking of data Foo = Bar a b | Baz x y.   Then the comparison function (== Bar) doesn't type check.  You'd have to write an isBar :: Foo -> Bool function (using pattern matching)
20:06:19 <ivanm> especially if you can't derive Eq for some reason (e.g. one of the fields has a function component)
20:07:02 <ivanm> @tell Baughn with haskell-mode, it seems that ghc-core-create-core doesn't know where the root of the project is (as it can't find other modules within the same hierarchy); is this fix-able?
20:07:02 <lambdabot> Consider it noted.
20:07:23 <ivanm> Ori_B: e.g. see the isNothing, null, etc. functions
20:07:24 <hatds> Is there a typeclass for which (==) = const True?  I just realized you could use that to make working with fields that are functions easier
20:07:38 <ivanm> that sounds like a horrible idea
20:07:52 <ivanm> hatds: though I think you mean "instance" not "typeclass" :p
20:08:01 <hatds> whoops, yea
20:08:02 <dmwit> > undefined == (undefined :: ())
20:08:03 <lambdabot>   *Exception: Prelude.undefined
20:08:10 <dmwit> > undefined == (undefined :: Void)
20:08:10 <Ori_B> great, thanks for the help.
20:08:10 <lambdabot>   Not in scope: type constructor or class `Void'
20:08:22 <hatds> horrible instances of Eq (and show) are useful for debuging (e.g., cyclic datastructures)
20:08:49 <ivanm> for Show, that means you need to write a better instance rather than relying on the default
20:09:02 <ivanm> i.e. find a way of making it non-cyclic
20:09:11 <Ori_B> oh, also, is there a shortcut syntax for lots of patterns to match?
20:09:22 <Ori_B> foo p1 = ...
20:09:25 <Ori_B> foo p2 = ...
20:09:29 <Ori_B> also gets a touch clunky
20:09:37 <Ori_B> but it seems like '|' is for guards
20:09:42 <parcs> case .. of
20:09:51 <ivanm> Ori_B: you mean without saying "foo" all the time?
20:09:53 <Ori_B> yeah.
20:09:58 <ivanm> in that case, use a case statement like parcs said
20:10:01 <parcs> '|' can be used too
20:10:20 <ivanm> I generally prefer explicit pattern matching in functions, unless I want a shared where clause
20:10:51 <parcs> > let foo x | Just _ <- x = True | otherwise = False in Foo (Just ())
20:10:52 <lambdabot>   Not in scope: data constructor `Foo'
20:10:58 <parcs> > let foo x | Just _ <- x = True | otherwise = False in foo (Just ())
20:10:59 <lambdabot>   True
20:11:18 <kmc> :t toConstr
20:11:19 <lambdabot> forall a. (Data a) => a -> Constr
20:11:21 <parcs> Ori_B: read about 'pattern guards'
20:11:37 <kmc> > ((==) `on` toConstr) (Just 3) (Just 5)
20:11:38 <ivanm> how do I suppress --make now that it's automatic in ghc-7 ?
20:11:38 <lambdabot>   True
20:11:40 <hatds> :i Constr
20:11:41 <kmc> > ((==) `on` toConstr) (Just 3) Nothing
20:11:42 <lambdabot>   False
20:12:01 <int80_h> ghci tries to load two different versions of the network package. One of them doesn't exist on my server. cab list doesn't list it, and package.conf doesn't have it. Where would ghci be getting the idea that I have two versions of network, and I want both of them loaded?
20:12:14 <NihilistDandy> @where core
20:12:14 <lambdabot> I know nothing about core.
20:12:27 <NihilistDandy> Anyone have a recommendation for learning about Core?
20:12:41 <kmc> uh, there are some presentations about it
20:12:45 <kmc> but i forgot how to find :(
20:12:54 * NihilistDandy is possessed of sadface
20:13:00 <int80_h> kmc: any ideas?
20:13:43 <Ori_B> hm. I also think I saw an example somewhere that used '++' list concatenation patterns...
20:13:48 <Ori_B> is that possible for string prefix matching?
20:13:51 <parcs> nope
20:13:55 <Ori_B> ok.
20:14:01 <ivanm> NihilistDandy: as in ghc-core? I'm trying to work that out atm :p
20:14:06 <ivanm> http://stackoverflow.com/questions/6121146/reading-ghc-core
20:14:08 <NihilistDandy> ivanm: Yes, indeed
20:14:11 <kmc> Ori_B, you can't use (++) in patterns directly, because it's not a data constructor
20:14:13 <Ori_B> so the best I can do is 'a' : 'b' : 'c' : xs
20:14:20 <NihilistDandy> ivanm: Consider it upvoted :D
20:14:24 <hatds> :t isPrefixOf
20:14:25 <Ori_B> if I want to do a prefix match?
20:14:25 <lambdabot> forall a. (Eq a) => [a] -> [a] -> Bool
20:14:53 <parcs> Ori_B: or isPrefixOf within a guard if your pattern match is simple
20:15:28 <NihilistDandy> Ah, perhaps I'll have to read SPJ's paper on System FC
20:15:42 <ivanm> NihilistDandy: bah, I'm not upvoting it, just reading it ;)
20:15:58 <NihilistDandy> Oh, I thought it was your question :D
20:16:06 <NihilistDandy> Still, it'll be in my history now, so I won't lose it
20:16:36 <hatds> > case "hello world" of { ("hello":xs) -> True; _ -> False}
20:16:37 <lambdabot>   Couldn't match expected type `GHC.Types.Char'
20:16:37 <lambdabot>         against inferred type...
20:16:45 <hatds> huh, never noticed that before
20:16:57 <ivanm> NihilistDandy: nah, it was started by tibbe
20:17:01 <hatds> it seems inconsistent
20:17:04 <NihilistDandy> *SPJ's paper_s_
20:17:24 <kmc> :t "hello" : ?xs
20:17:25 <lambdabot> (?xs::[[Char]]) => [[Char]]
20:17:26 <ivanm> hatds: that would work if xs was of type [String]
20:17:44 <hatds> ivanm: ah yes, of course
20:17:47 <hatds> nvm
20:17:54 * ivanm stares at 11000 lines of core, not knowing where to start...
20:18:35 <gwern> ivanm: "Begin at the beginning and go on till you come to the end: then stop."
20:19:09 <NihilistDandy> You may try the process in reverse, but you will not get very far.
20:19:39 <Jafet> > let stripPrefix xs ys = let (x,y) = splitAt (length xs) ys in if xs==x then Just y else Nothing in case "hello world" of { stripPrefix "hello" -> Just xs -> Just xs; _ -> Nothing }
20:19:40 <lambdabot>   <no location info>: Parse error in pattern
20:19:45 <ivanm> gwern: how did I know someone would say something along those lines? ;)
20:20:00 <ivanm> it seems -dsuppress-all is no longer a ghc flag...
20:20:11 <gwern> ivanm: because you've read Carroll and know programmers often read Carroll?
20:20:17 <ivanm> no
20:20:35 <ivanm> I meant along the lines of "start at the top"
20:20:42 <ivanm> or something equally as "helpful" ;)
20:21:16 <gwern> ivanm: well, that joke was old when carroll wrote that line
20:21:58 <int80_h> ghci tries to load two different versions of the network package. One of them doesn't exist on my server. cab list doesn't list it, and package.conf doesn't have it. Where would ghci be getting the idea that I have two versions of network, and I want both of them loaded?
20:22:09 <ivanm> OK, and it seems ghc's man page lies: I tried to use -dppr-noprags, but it didn't like that
20:22:12 <int80_h> that is, where should I check for issues?
20:22:50 <ivanm> int80_h: can you paste the actual error somewhere?
20:23:09 <ivanm> I would normally start with "ghc-pkg list | grep -i network" but you say you've checked package.conf already...
20:24:49 <Ori_B> hm, one inconvenience with isPrefixOf -- I want to actually use the rest of the list, instead of the prefix.
20:26:34 <Ori_B> is there a relatively elegant way to do that?
20:26:43 <Ori_B> prefix match, and get the /rest/ of the list?
20:27:00 <ivanm> given core output, how can I tell which of the functions with the same prefix is the one that is so expensive in my profiling results?
20:27:08 <ivanm> Ori_B: maybe in the split package...
20:27:12 <ivanm> or somethign like that
20:27:17 <ivanm> not in the prelude that I know of
20:27:22 <dmwit> drop (length prefix) wholeThing
20:27:25 <NihilistDandy> Ori_B: flip (isPrefixOf)~
20:27:47 <ivanm> NihilistDandy: huh? what's the point of the parens and ~ there?
20:27:51 <NihilistDandy> Nothing
20:28:09 <NihilistDandy> I just have a lisp
20:28:21 <parcs> :t stripPrefix
20:28:21 <lambdabot> forall a. (Eq a) => [a] -> [a] -> Maybe [a]
20:28:35 <dmwit> brillant
20:28:48 <parcs> Ori_B: foo xs | Just rest <- stripPrefix ... = ...
20:28:53 <hpaste> int80_h pasted “linker error” at http://hpaste.org/49757
20:29:23 <int80_h> ivanm: there you go :)
20:29:30 <parcs> @src stripPrefix
20:29:30 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
20:29:47 <gienah> ivanm: maybe you could add cost centre annotations to some of the expressions in the functions
20:30:28 <ivanm> int80_h: and "ghc-pkg list | grep -i network" doesn't show anything?
20:30:43 <ivanm> maybe try "ghc-pkg cache"
20:31:03 <ivanm> gienah: hmmm...
20:31:29 <int80_h> checking
20:31:33 <gienah> ivanm: http://www.haskell.org/ghc/docs/7.0-latest/html/users_guide/profiling.html#id613460
20:31:46 <ivanm> yeah, found the docs already ;)
20:31:48 <ivanm> thanks though
20:32:27 <int80_h> ivanm: ghc-pkg shows broken packages. network-2.3.0.2 and 2.3.0.4
20:32:38 <int80_h> ivanm: I've Loading package base ... linking ... done.
20:32:41 <ivanm> so they _are_ installed and in package.conf !
20:32:50 <ivanm> ghc-pkg unregister network
20:33:18 <int80_h> ivanm: when I go to uninstall network 2.3.0.2 I get "no such package found"
20:33:36 <ivanm> with a dash?
20:33:47 <NihilistDandy> int80_h: How do you not have network 2.3.0.2 in {prefix}/lib
20:33:49 <NihilistDandy> ?
20:33:52 <ivanm> "ghc-pkg unregister network-2.3.0.2"
20:34:53 <Ori_B> parcs: huh, do I need to import something for stripPrefix?
20:35:26 <NihilistDandy> @hoogle stripPrefix
20:35:26 <lambdabot> Data.List stripPrefix :: Eq a => [a] -> [a] -> Maybe [a]
20:36:56 <Ori_B> thanks. hackage showed it on the same page as a variety of other list functions that seem to be included by default...
20:37:18 <int80_h> ivanm: I just broke a bunch of stuff by removing that. haskel-platform for one. Will I need to recompile?
20:37:20 <NihilistDandy> No problemo
20:37:37 <NihilistDandy> int80_h: You should be fine
20:37:42 <NihilistDandy> Maybe
20:40:01 <int80_h> hmm so far so good
20:40:09 <int80_h> thanks :)
20:40:50 <gienah> ivanm: ghc inlining functions probably often helps to make things run faster, but trying to understand the core for huge functions seems difficult, so maybe it might help to disable inlining while trying to figure out what is running slow
20:41:01 <ivanm> gienah: *nod*
20:41:34 <ivanm> I'm trying to work out whether this has a high profile cost because a) it's expensive/inefficient, b) it gets called so often or c) some mixture of the two
20:42:45 <Ori_B> hrm... Data.List.Split... should that be a part of the core Haskell libraries?
20:42:50 <Ori_B>     Could not find module `Data.List.Split':
20:43:01 <hatds> it's a separate package
20:43:13 <Ori_B> ah :/
20:44:09 <hatds> the module namespace is organizational in what they do, rather than what modules come bundled with what
20:45:48 <NihilistDandy> Else you'd load an enormous amount of code everytime you imported Data.List or Control.Monad
20:46:49 <ivanm> a lot of which would clash
20:47:18 <ivanm> e.g. mtl-2 vs monads-tf
20:47:24 <NihilistDandy> With hilarious results
20:47:25 <ivanm> s/-2//
20:47:38 <ivanm> you find the results hilarious? :/
20:47:50 <hatds> I was referring to Data.List.* not being available in one place, not that they don't export recursively
20:49:08 <ivanm> right
20:49:49 <NihilistDandy> I'm sorry, I'm busy picking up my brains. The Core output on some simple code seems to have scared them out of my brain
20:49:55 <NihilistDandy> *head
20:50:11 <danharaj> Error cannot construct infinite type brains = brain brains
20:50:32 <danharaj> oh god what have I become
20:50:39 <danharaj> a douche bag who thinks GHC error messages are funny. :[
20:51:24 <NihilistDandy> lol
20:52:15 <RayNbow> @faq Can Haskell turn ppl into douchebags?
20:52:16 <lambdabot> The answer is: Yes! Haskell can do that.
20:52:27 <danharaj> some of us start that way before we learn.
20:53:43 <NihilistDandy> Others have to pick up the craft
20:54:06 <danharaj> Although they'd be better suited learning Ruby. ololololo
20:55:32 <NihilistDandy> snap.js
21:01:11 <elliott> Is there a way to pause a thread to resume it later, outside of keeping an MVar for whether it's running or not that the thread blocks until it's True?
21:05:25 <kmc> elliott, forever (threadDelay maxBound)
21:05:32 <kmc> then interrupt it with an async exception
21:05:34 <kmc> and catch that
21:05:44 <kmc> however I think the MVar solution is nicer -- what's wrong with that?
21:06:07 <elliott> Nothing, I was just checking :)
21:07:20 <hatds> depending on what state the thread carries you could simply kill the thread and recreate another later
21:07:57 <kmc> that too :)
21:08:19 <kmc> elliott, you can wait on other things, like Chans or QSem
21:08:28 <RayNbow> kmc: is it safe to do threadDelay maxBound?
21:08:59 <kmc> what do you mean?
21:09:44 <RayNbow> well, in some Python project I saw the following comment: # time.sleep(sys.maxint) has "issues" on 64bit architectures;
21:10:07 <RayNbow> (the only problem is, the project didn't specify what exactly the issue is)
21:10:15 <kmc> i don't see the relevance
21:10:33 <elliott> kmc: actually, nicely I can just use an (MVar ())
21:10:36 <elliott> don't even need a boolean
21:11:03 <kmc> afaik (threadDelay maxBound) is a safe way to delay for an unspecified amount of time between 8.9 minutes and 292,277 years
21:11:14 <elliott> haha
21:11:31 <elliott> erm, Int has no maximum size
21:11:32 <elliott> does it?
21:11:32 <RayNbow> ah wait
21:11:35 <markamber> so, I need to install haskell and run things like cabal with 128-256 MB of ram, I know of an option called splitobjs, so I compiled ghc on my current machine with the 'quickest' configuration, that included the splitobjs, and now I am transferring it to my VPS, but I cannot get haskell to build, because it wants profiling for monad tranformers, and I did not compile ghc with that, what is the workaround?
21:11:38 <RayNbow> > maxBound :: Int
21:11:39 <lambdabot>   9223372036854775807
21:11:48 <elliott> as in, Int could be arbitrarily big
21:11:54 <elliott> as long as it's finite
21:11:59 <kmc> yeah true
21:12:07 <kmc> the upper bound of that is based only on implementations i know
21:12:36 <kmc> the Report only says that the range is at least [-2^29 .. 2^29 - 1]
21:12:51 <NihilistDandy> markamber: Recompile transformers with profiling
21:13:36 <NihilistDandy> I dunno. Just guessing
21:13:40 <NihilistDandy> Probably wrong
21:14:14 <markamber> NihilistDandy, I cannot compile transformers, it says that I do not have the profiling config file er somethin, I will paste,  hold on
21:15:52 <markamber> https://gist.github.com/1119610
21:15:58 <markamber> that ^^ is the error
21:16:49 <NihilistDandy> Oh. I guess you have to recompile base with profiling, then.
21:16:52 <NihilistDandy> How inconvenient
21:18:40 * hackagebot hermit 0.0 - Haskell Equational Reasoning Model-to-Implementation Tunnel  http://hackage.haskell.org/package/hermit-0.0 (AndyGill)
21:19:36 <Ori_B> hm, is there any reading on idiomatic error handling in Haskell?
21:19:37 <ivanm> NihilistDandy: s/base/ghc/
21:19:47 <NihilistDandy> derp.jpg
21:20:01 <NihilistDandy> Ori_B: LYAH, RWH?
21:20:03 <ivanm> Ori_B: RWH's chapter isn't bad, but out-of-date
21:20:10 <ivanm> (it doesn't cover the new extensible exceptions)
21:20:15 <ivanm> not sure about LYAH; haven't read it
21:20:41 <NihilistDandy> The online version handles error handling better than the print, I think, but YMMV
21:21:02 <tommd> LYAError: Unhandled exception.
21:22:16 <elliott> Is the GPIpe library still maintained? It was last updated in September 2010. It still builds, though.
21:22:33 <markamber> isn't there a way to not have to rebuild ghc
21:23:11 <Cale> elliott: Gergely Patai (who works for us), sounds like he's working on it.
21:23:44 <NihilistDandy> markamber: Not really, judging by that error
21:23:50 <elliott> Cale: Well, that's cool. I'm considering ditching my current OpenGL code and migrating to it, since OpenGL is so ugly. The GLUT dependency bothers me, though.
21:23:50 <Cale> elliott: (not for us, but you never know, perhaps at some point we may try to use it)
21:24:00 <NihilistDandy> You'll only have to build the profiling half, IIRC
21:24:19 <NihilistDandy> Assuming you haven't killed the whole directory from which you compiled in the first place
21:24:24 <markamber> NihilistDandy, how is that going to work
21:24:30 <markamber> change the options
21:24:35 <markamber> and just make again
21:24:47 <NihilistDandy> Yeah, I think that's basically it
21:24:58 <ivanm> hmmm.... permuting lists of 4 values is taking about 36% of my runtime...
21:25:02 <markamber> NihilistDandy, I will try it
21:25:17 <NihilistDandy> ivanm: That's unpleasant
21:26:15 <Cale> elliott: They're apparently going to use it in LambdaCube
21:26:16 <ivanm> yup
21:26:26 <Cale> (if they're not already using it)
21:26:28 <ivanm> I'm hoping it's just because it gets called so often
21:26:59 <NihilistDandy> ivanm: Code?
21:27:10 <Cale> It looks like currently the lambdacube on Hackage is using OpenGLRaw
21:27:11 <elliott> Cale: I looked at LambdaCube; a bit heavy for my tastes, but that's just me.
21:27:17 <ivanm> well, not quite the current version, but: http://code.haskell.org/~ivanm/dangd/
21:27:32 <ivanm> NihilistDandy: I'm generating graphs (well, technically, only trees at this stage)
21:27:42 <ivanm> so you've been warned! :p
21:28:01 <pikhq> ... Seriously, "My 'quit message' is this weeaboo for no good reason"? Nice work. :P
21:28:02 <NihilistDandy> Where am I looking for the code in question?
21:28:15 <pikhq> @tell twofish ... Seriously, "My 'quit message' is this weeaboo for no good reason"? Nice work. :P
21:28:15 <lambdabot> Consider it noted.
21:31:21 <NihilistDandy> ivanm: How do you export permutations from D.G.P.DangD.Common when I see no definition of permutations?
21:31:47 <ivanm> NihilistDandy: it's from Math.Combinatorics.Multiset
21:31:49 <ivanm> @hackage multilset-comb
21:31:49 <lambdabot> http://hackage.haskell.org/package/multilset-comb
21:31:52 <NihilistDandy> Ah, okay
21:32:21 <ivanm> to be more specific: doing "concatMap permutations" is 36% of the runtime
21:32:24 <argiopeweb> "Is there a better way" question: I'm currently creating a large number of threads by partially applying forkIO as a parameter to replicate then mapping over it to complete the function (I.E. replicate 500 forkIO >>= mapM_ (\t -> t 50)). Is there a better way to do this (already existing abstraction, for instance)?
21:32:28 <kmc> weeaboo! weeaboo!
21:32:39 <markamber> I cannot find how to compile with profiling, anyone know?
21:32:48 <markamber> I am talking about ghc still
21:32:49 * ivanm goes to check out the ebuild
21:33:02 <argiopeweb> markamber: It's in real world haskell. Compile with -prof and -auto-all and -caf-all to start.
21:33:28 <markamber> argiopeweb, will any of those override my desire to use splitobjs
21:33:40 <markamber> and what else can I do to allow me to run with less memory usage
21:33:46 <ivanm> argiopeweb: he wants to build GHC, it's a configuration option
21:34:03 <argiopeweb> Ah, I stand corrected. My apologies for jumping into a pre-existing conversation.
21:34:10 <kmc> argiopeweb, I'm a bit confused... the goal is to spawn 500 identical threads, or what?
21:34:17 <ivanm> markamber: AFAICT, it should do it by defualt: http://hackage.haskell.org/trac/ghc/wiki/Building/QuickStart
21:34:33 <ivanm> maybe check your ./configure options?
21:34:45 <markamber> ivanm, so you are talking about profiling or splitobjs now
21:35:01 <argiopeweb> This being said, last time I built GHC (~1.5 months ago?) it built profiling by default without a hitch.
21:35:33 <ivanm> NihilistDandy: the actual call is in DangD.hs; not sure of the line number but it's "let mSms == concatMap mkPerms sms"
21:35:35 <markamber> because my goal is low memory usage, I dont care about the profiling thing at this point, this is for my deploy server, if I do profiling it will be on my development server here at home (aka my desktop)
21:35:53 <ivanm> (I've currently split the map mkPerms bit off from the concatMap though)
21:35:54 <NihilistDandy> ivanm: Yeah, I found it a moment ago
21:35:57 <ivanm> markamber: profiling
21:36:04 <markamber> well what else could be causing that error
21:36:20 <markamber> ivanm, what, did I spell it wrong
21:36:35 <markamber> I am not that good with spelling
21:37:01 <NihilistDandy> @src mkPerms
21:37:01 <lambdabot> Source not found. stty: unknown mode: doofus
21:37:12 <ivanm> NihilistDandy: its's in the where clause... ;)
21:37:21 <ivanm> markamber: I seem to have lost your paste; do you still have it?
21:37:29 <NihilistDandy> Oh, derp
21:37:35 <markamber> https://gist.github.com/1119610
21:37:40 <markamber> still on the clipboard
21:37:54 <NihilistDandy> I'm blind, you see, and Haskell doesn't translate to Braille~
21:38:16 <ivanm> markamber: in that case, don't build transformers, etc. with profiling support
21:38:27 <kmc> argiopeweb, so what's your forkIO expression doing?
21:38:35 <ivanm> if that was from cabal-install, disable the appropriate line in ~/.cabal/config
21:38:42 <ivanm> NihilistDandy: :o
21:39:02 <markamber> ivanm, how do I not build transformers, and transformers is only something I will need for profiling then right, or not really but we will just say so
21:39:20 <ivanm> markamber: what command gave you that error line?
21:39:24 <ivanm> s/line/
21:39:42 <markamber> ivanm, hmm
21:40:10 <argiopeweb> kmc: It's mildly contrived, but essentially yes. I'm in the "let's sneak Haskell into the workplace without the Java fanboys flipping out" mode, and I was asked to write a program to test expected deployment loads on a new server. So, I'm connecting to it x # of times for static ongoing connections, and n # of times as transient connections. If I see a pattern twice, it needs abstraction.
21:40:13 <markamber> ivanm, make
21:40:27 <ivanm> oh, when building ghc itself?
21:40:32 <ivanm> that's weird...
21:40:35 <kmc> :t replicateM
21:40:36 <lambdabot> forall (m :: * -> *) a. (Monad m) => Int -> m a -> m [a]
21:40:38 <kmc> :t replicateM_
21:40:39 <lambdabot> forall (m :: * -> *) a. (Monad m) => Int -> m a -> m ()
21:40:41 <markamber> ivanm, no, haskel platform
21:40:44 <ivanm> ahhhh
21:40:53 <ivanm> so you want to disable profiling support for the platform then
21:40:53 <argiopeweb> haha, that seems like what I've been looking for.
21:40:58 <kmc> argiopeweb, so how about replicateM_ 500 (forkIO hitServer)
21:41:01 <kmc> :)
21:41:11 <argiopeweb> kmc: That's the cleanness I've been looking for.
21:41:18 <kmc> remember that your program exits when 'main' exits, even if other threads are still running
21:41:22 <argiopeweb>     (return $ replicate 500 forkIO) >>= mapM_ (\t -> t $ withHandledSocketDo trashSocketInput) is just so ugly.
21:41:24 <markamber> ivanm, really, I just want to lower memory usage, and that might be something I have to do as a result of compiling ghc with splitobjs
21:41:33 <kmc> if you want joinable threads, you can use http://hackage.haskell.org/packages/archive/spawn/0.2/doc/html/Control-Concurrent-Spawn.html
21:41:36 <kmc> or one of the other similar libs
21:41:37 <ivanm> markamber: *nod*
21:41:46 * argiopeweb should have realized there's be a *M_ function...
21:41:46 <markamber> ivanm, I am on a VPS with 128-256MB of memory
21:41:48 <kmc> or implement it yourself in a few lines
21:42:01 <markamber> and that 256 is when others are not using it,
21:42:05 <ivanm> AFAICT though, you seem to have built ghc without profiling support but the platform is trying to be built _with_ profiling support
21:42:14 <ivanm> markamber: I've heard that using the gold linker can help with that
21:42:26 <ivanm> as that's usually where high memory usage comes from
21:42:29 <markamber> ivanm, I am all ears
21:42:37 <ivanm> maybe you need to ask on #ghc though for this problem....
21:42:49 <ivanm> @google ghc gold linker
21:42:51 <lambdabot> http://hackage.haskell.org/trac/ghc/ticket/4862
21:42:52 <lambdabot> Title: #4862 (Enable usage of gold linker with GHC) – GHC
21:42:53 <markamber> ivanm, I thought haskell and ghc were the same
21:43:00 <kmc> Haskell is a standardized language
21:43:04 <kmc> GHC is its most popular implementation
21:43:08 <ivanm> markamber: #ghc is the channel talking about the actual compiler
21:43:18 <ivanm> the people there would know more about the specifics than we would
21:43:19 <kmc> it's not "the" compiler -- there are others
21:43:20 <markamber> ivanm, I will try there
21:43:25 <kmc> Haskell is a standardized language
21:43:26 <markamber> did not know
21:43:41 <kmc> but yeah GHC is by far the most popular implementation of Haskell
21:43:44 <ivanm> kmc: admittedly, just about everyone just uses ghc + its extensions... :p
21:43:48 <drdo> kmc: It is still pretty much "the" compiler
21:43:57 <kmc> and implements a great many extensions beyond standard Haskell
21:43:57 <ivanm> it's the defacto compiler
21:43:58 <ivanm> not the dejure
21:44:26 <hatds> markamber: can't you compile your package without profiling if you don't mind?
21:44:42 <argiopeweb> Yeah, there's my problem... I need to actually read through Control.Monad.
21:44:54 <kmc> get back to me when GHC has extensible records, first-class existentials, top-level IO, region inference, whole-program compilation, or a bytecode interpreter in portable ANSI C
21:44:54 <argiopeweb> kmc: Thanks, as always. You're always a great help.
21:44:58 <kmc> :)
21:45:09 <kmc> or a supercompiler
21:45:11 <ivanm> hatds: the problem seems to be how to configure the haskell platform build system to not use profiling
21:45:12 <kmc> or ...
21:45:21 <ivanm> kmc: why, what do you use?
21:45:31 <kmc> there's a lot of interesting stuff going on in the Haskell world outside GHC
21:45:57 <argiopeweb> kmc: There is supercompiler work being done for GHC, isn't there?
21:45:59 <kmc> yes
21:46:05 <hatds> ivanm: haskell platform doesn't do anything special that you can't do with the Setup.hs files if I understand correctly
21:46:07 <NihilistDandy> ivanm: Nice use of Latin
21:46:15 <markamber> hatds, well sure, I would not know that though
21:46:27 <markamber> hatds, like how would you do that
21:46:39 <ivanm> hatds: right, but how do you pass those values through to them (technically through to runhaskell Setup.hs configure) using ./configure && make ?
21:46:42 <hatds> markamber: it's surprisingly simple to install a cabal package with the Setup.hs files
21:46:48 <hatds> one sec
21:46:54 <drdo> what the hell is a supercompiler?
21:46:59 <kmc> ivanm, there's actually a lot of standard Haskell code and even more if you allow a few widely-implemented extensions like Rank2Types
21:47:03 <NihilistDandy> @wiki supercompiler
21:47:03 <lambdabot> http://www.haskell.org/haskellwiki/supercompiler
21:47:10 <ivanm> hatds: yes, but the platform ships as a large tarball built + installed using autotools + make
21:47:13 <NihilistDandy> @google supercompiler
21:47:14 <lambdabot> http://c2.com/cgi/wiki?SuperCompiler
21:47:14 <lambdabot> Title: Super Compiler
21:47:22 <kmc> it's dumb to say that GHC is the end-all of Haskell compilers when there are all these useful features it's missing
21:47:30 <kmc> that other implementations already have
21:47:38 <hatds> hatds: all the autotools/etc. are in cabal itself no?
21:47:40 <SharkMonkey> kmc, is there an implementation with extensible records?
21:47:45 <kmc> Hugs has them
21:47:45 <hatds> er ivanm
21:47:53 <ivanm> hatds: no
21:47:58 <ivanm> they just call Cabal-the-library
21:48:14 <kmc> we keep saying "wouldn't it be great if we had extensible records" but Hugs does and nobody ever talks about it
21:48:20 <ivanm> kmc: who has whole-program compilation?
21:48:23 <kmc> JHC
21:48:38 <hatds> if you have cabal working you should be able to "install the haskell platform" by manually using cabal on each package
21:48:39 <ivanm> I thought JHC was only usable for a small number of programs, even those in pure H98
21:48:40 <kmc> also LHC
21:48:43 <ivanm> at least performance-wise
21:48:50 <kmc> ivanm, did I say otherwise?
21:48:53 <ivanm> LHC is just an alternate backend to GHC though, isn't it?
21:49:01 <ivanm> kmc: OK, so which implementation do you actually use then?
21:49:03 <kmc> i didn't say "let's all use JHC for everything"
21:49:05 <kmc> ivanm, I use GHC
21:49:10 <kmc> you're missing my point
21:49:24 <ivanm> because they way you said it made it sound like there was an alternate implementation that was usable and comporable to GHC
21:49:33 <ivanm> kmc: nah, I think I've got it
21:49:36 <kmc> cool
21:49:37 <ivanm> we're too GHC-centric
21:49:45 <ivanm> which I agree with
21:49:59 <mustelo> ...but...but spj wrote ghc!
21:50:29 <ivanm> mustelo: last I checked, SPJ never claimed to be omnipotent, etc.
21:50:33 <markamber> no real activity on the ghc channel, ivanm, hatsd you were saying things that I could do to compile this, what are the options?
21:50:41 <mustelo> ivan, no need to claim it when it's obvious.
21:50:47 <ivanm> markamber: ./configure --help
21:50:56 <ivanm> see how to disable profiling support
21:51:01 <markamber> ivanm, on what? haskell package or ghc
21:51:06 <ivanm> platform
21:51:17 <markamber> ok, leeme take a look
21:51:27 <ivanm> @tell kmc another item to add to your list: IIRC, HBC was meant to let you define data types, etc. in its interpreter!
21:51:27 <lambdabot> Consider it noted.
21:51:40 <hatds> markamber: runghc Setup.hs configure  will configure without profiling by default
21:52:01 <markamber> hatds, hmm, will give it a try
21:52:19 <hatds> markamber: options reference for cabal setup.hs files: http://www.haskell.org/cabal/users-guide/#building-and-installing-a-package
21:52:42 <NihilistDandy> ivanm: Welp, I've got no ideas. I sort of don't follow mkPerms :|
21:52:48 <ivanm> hatds: except he's not using runghc Setup.hs
21:53:01 <ivanm> NihilistDandy: didn't say it here hoping for help; I was just a bit incredulous ;)
21:53:11 <NihilistDandy> Haha
21:53:19 <ivanm> hatds: he's using autotools + make to configure the haskell platform
21:53:34 <hatds> I jumped into the convo a bit late to catch that then
21:53:39 <NihilistDandy> I know, but I like to try :D
21:53:40 <markamber> hatds, where is setup.hs
21:53:47 <markamber> the one that you runghc
21:54:08 <ivanm> markamber: hatds got mixed up with building haskell packages in general
21:54:33 <markamber> ivanm, let me give you a more complete output of the command, I bet it will help
21:54:51 <cwl> which module contains (==>)
21:54:54 <ivanm> markamber: in scripts/config there's a line "ENABLE_PROFILING=YES"
21:54:59 <ivanm> try changing that to NO
21:55:10 <ivanm> and then doing make
21:55:13 <cwl> how to search a function?
21:55:21 <ivanm> @hoogle (==>)
21:55:21 <lambdabot> Test.QuickCheck (==>) :: Testable a => Bool -> a -> Property
21:55:27 <ivanm> @where hoogle
21:55:27 <lambdabot> http://haskell.org/hoogle
21:55:31 <ivanm> @where hayoo
21:55:32 <lambdabot> http://holumbus.fh-wedel.de/hayoo/hayoo.html
21:55:52 <ivanm> cwl: ^^ hayoo also searches all of hackage; hoogle's results only search the platform by default but are usually more reliable
21:55:54 <dobblego> how might I get lambdabot to autojoin a channel?
21:56:02 <markamber> ivanm, http://paste.ubuntu.com/656877/
21:56:04 <ivanm> dobblego: ask one of the admins for lambdabot
21:56:07 <ivanm> lispy I think
21:56:10 <markamber> yes I changed paste things
21:56:14 <cwl> thanks ivanm
21:56:42 <markamber> whatever comes up first when I type paste in any search on my computer launcher thing (synapse, like gnome do)
21:56:43 <ivanm> markamber: did you change that file?
21:56:52 <markamber> ivanm, no, just more complete
21:57:11 <markamber> ivanm, you mean the one you said to, got it
21:57:11 <ivanm> ./configure --disable-profiling
21:57:22 <ivanm> markamber: ^^ or just that command (I think)
21:57:32 <markamber> ivanm, that was too easy
21:57:36 <ivanm> or ./configure --enable-profiling=no
21:57:44 <ivanm> then do make
21:58:08 <markamber> ivanm, the first one seemed to work
21:58:28 <ivanm> yeah; in general you probably _shouldn't_ directly edit the output from ./configure... :p
21:58:50 <ivanm> but I missed the --disable-FEATURE stuff when looking through ./configure --help before
21:58:53 <ivanm> :s
22:02:14 <cwl> @where bail
22:02:14 <lambdabot> I know nothing about bail.
22:02:43 <NihilistDandy> @where ball
22:02:43 <lambdabot> I know nothing about ball.
22:02:51 <NihilistDandy> @where bell
22:02:51 <lambdabot> I know nothing about bell.
22:03:35 <ivanm> the @where plugin requires someone to add that item first
22:03:39 <ivanm> @help where+
22:03:39 <lambdabot> where+ <key> <elem>. Define an association
22:05:05 <NihilistDandy> ivanm: I know
22:05:08 <NihilistDandy> I was playing a game
22:05:10 <NihilistDandy> :D
22:05:15 <ivanm> heh
22:05:24 <NihilistDandy> How many single letter changes until I get some information
22:05:26 <NihilistDandy> ?
22:05:40 <ivanm> heh
22:07:52 <siracusa> "lhs2TeX.exe: Maybe.fromJust: Nothing" -- using partial functions is bad!
22:09:22 <ivanm> well, I tend to use fromJust a lot in the code I'm hacking on recently... because if you followed the preconditions required for that function to work, then the Maybe values internally should always be Just
22:11:29 <siracusa> Okay, using partial functions without following the preconditions is bad!
22:31:08 <ivanm> @src mapAccumL
22:31:09 <lambdabot> mapAccumL _ s []        =  (s, [])
22:31:09 <lambdabot> mapAccumL f s (x:xs)    =  (s'',y:ys)
22:31:09 <lambdabot>    where (s', y ) = f s x
22:31:09 <lambdabot>          (s'',ys) = mapAccumL f s' xs
22:43:43 <kosmikus> siracusa: agreed, it's bad. where's the bug report?
22:44:17 <siracusa> No bug reported yet
22:48:02 <siracusa> kosmikus: Oh, you're one of the developers?
22:48:41 <kosmikus> siracusa: yes
22:54:17 <siracusa> kosmikus: I'm using version 1.15, not sure if it's already fixed in later versions: I did something like %subst comment c = "\phantom{" value "}\mbox{" c "}" where I wanted "value" to be rendered as if it were a source code identifier. This doesn't seem to be allowed in %subst and that's where the error occurred.
22:55:22 <kosmikus> siracusa: that's quite possible to trigger an error
22:56:45 <kniu> has anybody read this paper?
22:56:46 <kniu> http://research.microsoft.com/en-us/um/people/daan/download/papers/hml.pdf
22:57:11 <kniu> I'm just wondering what the author means
22:58:19 <kniu> when he says that HML^F is "less expressive" than plain HML
22:58:22 <kosmikus> kniu: I think I read it, but quite some time ago.
22:58:47 <kniu> both type systems can express System F fully since they're both impredicative, right?
22:59:07 <kniu> so the "less expressive" statement is purely about convenience?
22:59:55 <kosmikus> kniu: probably. but I really don't remember all these different type system abbreviations.
23:00:04 <kniu> hm.
23:01:23 <kosmikus> siracusa: I can confirm the bug.
23:16:40 <ivanm> OK, so I ran my program a couple of hours ago, and it took under 5 min to run
23:16:54 <ivanm> now when I go to run it it's still going after 7 min... wtf?
23:17:10 <ivanm> I've noticed this a few times recently: the program is slower than it was originally until I recompile it
23:17:17 <ivanm> any ideas why?
23:17:52 <coppro> disk caching?
23:18:09 <coppro> and/or paging
23:18:12 <NihilistDandy> Is there a dark wizard in your house?
23:18:23 <coppro> try running it again immediately after another run
23:18:32 <NihilistDandy> Or after slaying the wizard
23:18:46 <argiopeweb> NihilistDandy: Will it work if you just run out said wizard?
23:19:16 <argiopeweb> After all, wizard slaying can be a messy business.
23:19:19 <NihilistDandy> argiopeweb: As long as you speak the right incantation at the door
23:19:20 <drdo> I'm pretty sure the spells only go away if a wizard dies
23:19:40 <NihilistDandy> But I think it's some obscure Perl nonsense, so it's probably easier just to kill him
23:19:40 <ivanm> OK... and my laptop just died :/
23:19:41 <ivanm> *sigh*
23:19:49 <ivanm> (overheating issue I think...)
23:20:08 <argiopeweb> Oh, nobody told me Perl was involved. That completely changes things.
23:20:08 * ivanm takes it as a sign that he should head off home now and get some food
23:20:28 <ivanm> what perl? I'm not using any perl!
23:21:58 <argiopeweb> Is it worth my time and effort to use nested where statements so that I don't have to pass non-variable parameters around in a recursive function, or has the optimizer gotten smart enough to do that for me?
23:28:49 <kosmikus> siracusa: https://github.com/kosmikus/lhs2tex/issues/7
23:29:17 <MaskRay> How can I set the maximal running time of runInterpreter in Language.Haskell.Interpreter?
23:30:24 <MaskRay> A simple  timeout 1 $ return . runInterpreter $ setImports ["Prelude","Data.Function","Data.List"] >> eval "fix((0:).scanl(+)1)"  won't work
